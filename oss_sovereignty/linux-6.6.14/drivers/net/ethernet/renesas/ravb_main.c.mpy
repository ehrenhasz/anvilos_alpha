{
  "module_name": "ravb_main.c",
  "hash_id": "a7a5c493ff1d85407a5521fa096376b7c61e8ae5766cb5d2229bdef7b449b81b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/renesas/ravb_main.c",
  "human_readable_source": "\n \n\n#include <linux/cache.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/if_vlan.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/net_tstamp.h>\n#include <linux/of.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/reset.h>\n#include <linux/math64.h>\n\n#include \"ravb.h\"\n\n#define RAVB_DEF_MSG_ENABLE \\\n\t\t(NETIF_MSG_LINK\t  | \\\n\t\t NETIF_MSG_TIMER  | \\\n\t\t NETIF_MSG_RX_ERR | \\\n\t\t NETIF_MSG_TX_ERR)\n\nstatic const char *ravb_rx_irqs[NUM_RX_QUEUE] = {\n\t\"ch0\",  \n\t\"ch1\",  \n};\n\nstatic const char *ravb_tx_irqs[NUM_TX_QUEUE] = {\n\t\"ch18\",  \n\t\"ch19\",  \n};\n\nvoid ravb_modify(struct net_device *ndev, enum ravb_reg reg, u32 clear,\n\t\t u32 set)\n{\n\travb_write(ndev, (ravb_read(ndev, reg) & ~clear) | set, reg);\n}\n\nint ravb_wait(struct net_device *ndev, enum ravb_reg reg, u32 mask, u32 value)\n{\n\tint i;\n\n\tfor (i = 0; i < 10000; i++) {\n\t\tif ((ravb_read(ndev, reg) & mask) == value)\n\t\t\treturn 0;\n\t\tudelay(10);\n\t}\n\treturn -ETIMEDOUT;\n}\n\nstatic int ravb_set_opmode(struct net_device *ndev, u32 opmode)\n{\n\tu32 csr_ops = 1U << (opmode & CCC_OPC);\n\tu32 ccc_mask = CCC_OPC;\n\tint error;\n\n\t \n\tif (opmode & CCC_GAC)\n\t\tccc_mask |= CCC_GAC | CCC_CSEL;\n\n\t \n\travb_modify(ndev, CCC, ccc_mask, opmode);\n\t \n\terror = ravb_wait(ndev, CSR, CSR_OPS, csr_ops);\n\tif (error) {\n\t\tnetdev_err(ndev, \"failed to switch device to requested mode (%u)\\n\",\n\t\t\t   opmode & CCC_OPC);\n\t}\n\n\treturn error;\n}\n\nstatic void ravb_set_rate_gbeth(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tswitch (priv->speed) {\n\tcase 10:                 \n\t\travb_write(ndev, GBETH_GECMR_SPEED_10, GECMR);\n\t\tbreak;\n\tcase 100:                \n\t\travb_write(ndev, GBETH_GECMR_SPEED_100, GECMR);\n\t\tbreak;\n\tcase 1000:               \n\t\travb_write(ndev, GBETH_GECMR_SPEED_1000, GECMR);\n\t\tbreak;\n\t}\n}\n\nstatic void ravb_set_rate_rcar(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tswitch (priv->speed) {\n\tcase 100:\t\t \n\t\travb_write(ndev, GECMR_SPEED_100, GECMR);\n\t\tbreak;\n\tcase 1000:\t\t \n\t\travb_write(ndev, GECMR_SPEED_1000, GECMR);\n\t\tbreak;\n\t}\n}\n\nstatic void ravb_set_buffer_align(struct sk_buff *skb)\n{\n\tu32 reserve = (unsigned long)skb->data & (RAVB_ALIGN - 1);\n\n\tif (reserve)\n\t\tskb_reserve(skb, RAVB_ALIGN - reserve);\n}\n\n \nstatic void ravb_read_mac_address(struct device_node *np,\n\t\t\t\t  struct net_device *ndev)\n{\n\tint ret;\n\n\tret = of_get_ethdev_address(np, ndev);\n\tif (ret) {\n\t\tu32 mahr = ravb_read(ndev, MAHR);\n\t\tu32 malr = ravb_read(ndev, MALR);\n\t\tu8 addr[ETH_ALEN];\n\n\t\taddr[0] = (mahr >> 24) & 0xFF;\n\t\taddr[1] = (mahr >> 16) & 0xFF;\n\t\taddr[2] = (mahr >>  8) & 0xFF;\n\t\taddr[3] = (mahr >>  0) & 0xFF;\n\t\taddr[4] = (malr >>  8) & 0xFF;\n\t\taddr[5] = (malr >>  0) & 0xFF;\n\t\teth_hw_addr_set(ndev, addr);\n\t}\n}\n\nstatic void ravb_mdio_ctrl(struct mdiobb_ctrl *ctrl, u32 mask, int set)\n{\n\tstruct ravb_private *priv = container_of(ctrl, struct ravb_private,\n\t\t\t\t\t\t mdiobb);\n\n\travb_modify(priv->ndev, PIR, mask, set ? mask : 0);\n}\n\n \nstatic void ravb_set_mdc(struct mdiobb_ctrl *ctrl, int level)\n{\n\travb_mdio_ctrl(ctrl, PIR_MDC, level);\n}\n\n \nstatic void ravb_set_mdio_dir(struct mdiobb_ctrl *ctrl, int output)\n{\n\travb_mdio_ctrl(ctrl, PIR_MMD, output);\n}\n\n \nstatic void ravb_set_mdio_data(struct mdiobb_ctrl *ctrl, int value)\n{\n\travb_mdio_ctrl(ctrl, PIR_MDO, value);\n}\n\n \nstatic int ravb_get_mdio_data(struct mdiobb_ctrl *ctrl)\n{\n\tstruct ravb_private *priv = container_of(ctrl, struct ravb_private,\n\t\t\t\t\t\t mdiobb);\n\n\treturn (ravb_read(priv->ndev, PIR) & PIR_MDI) != 0;\n}\n\n \nstatic const struct mdiobb_ops bb_ops = {\n\t.owner = THIS_MODULE,\n\t.set_mdc = ravb_set_mdc,\n\t.set_mdio_dir = ravb_set_mdio_dir,\n\t.set_mdio_data = ravb_set_mdio_data,\n\t.get_mdio_data = ravb_get_mdio_data,\n};\n\n \nstatic int ravb_tx_free(struct net_device *ndev, int q, bool free_txed_only)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tstruct net_device_stats *stats = &priv->stats[q];\n\tunsigned int num_tx_desc = priv->num_tx_desc;\n\tstruct ravb_tx_desc *desc;\n\tunsigned int entry;\n\tint free_num = 0;\n\tu32 size;\n\n\tfor (; priv->cur_tx[q] - priv->dirty_tx[q] > 0; priv->dirty_tx[q]++) {\n\t\tbool txed;\n\n\t\tentry = priv->dirty_tx[q] % (priv->num_tx_ring[q] *\n\t\t\t\t\t     num_tx_desc);\n\t\tdesc = &priv->tx_ring[q][entry];\n\t\ttxed = desc->die_dt == DT_FEMPTY;\n\t\tif (free_txed_only && !txed)\n\t\t\tbreak;\n\t\t \n\t\tdma_rmb();\n\t\tsize = le16_to_cpu(desc->ds_tagl) & TX_DS;\n\t\t \n\t\tif (priv->tx_skb[q][entry / num_tx_desc]) {\n\t\t\tdma_unmap_single(ndev->dev.parent, le32_to_cpu(desc->dptr),\n\t\t\t\t\t size, DMA_TO_DEVICE);\n\t\t\t \n\t\t\tif (entry % num_tx_desc == num_tx_desc - 1) {\n\t\t\t\tentry /= num_tx_desc;\n\t\t\t\tdev_kfree_skb_any(priv->tx_skb[q][entry]);\n\t\t\t\tpriv->tx_skb[q][entry] = NULL;\n\t\t\t\tif (txed)\n\t\t\t\t\tstats->tx_packets++;\n\t\t\t}\n\t\t\tfree_num++;\n\t\t}\n\t\tif (txed)\n\t\t\tstats->tx_bytes += size;\n\t\tdesc->die_dt = DT_EEMPTY;\n\t}\n\treturn free_num;\n}\n\nstatic void ravb_rx_ring_free_gbeth(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tunsigned int ring_size;\n\tunsigned int i;\n\n\tif (!priv->gbeth_rx_ring)\n\t\treturn;\n\n\tfor (i = 0; i < priv->num_rx_ring[q]; i++) {\n\t\tstruct ravb_rx_desc *desc = &priv->gbeth_rx_ring[i];\n\n\t\tif (!dma_mapping_error(ndev->dev.parent,\n\t\t\t\t       le32_to_cpu(desc->dptr)))\n\t\t\tdma_unmap_single(ndev->dev.parent,\n\t\t\t\t\t le32_to_cpu(desc->dptr),\n\t\t\t\t\t GBETH_RX_BUFF_MAX,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t}\n\tring_size = sizeof(struct ravb_rx_desc) * (priv->num_rx_ring[q] + 1);\n\tdma_free_coherent(ndev->dev.parent, ring_size, priv->gbeth_rx_ring,\n\t\t\t  priv->rx_desc_dma[q]);\n\tpriv->gbeth_rx_ring = NULL;\n}\n\nstatic void ravb_rx_ring_free_rcar(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tunsigned int ring_size;\n\tunsigned int i;\n\n\tif (!priv->rx_ring[q])\n\t\treturn;\n\n\tfor (i = 0; i < priv->num_rx_ring[q]; i++) {\n\t\tstruct ravb_ex_rx_desc *desc = &priv->rx_ring[q][i];\n\n\t\tif (!dma_mapping_error(ndev->dev.parent,\n\t\t\t\t       le32_to_cpu(desc->dptr)))\n\t\t\tdma_unmap_single(ndev->dev.parent,\n\t\t\t\t\t le32_to_cpu(desc->dptr),\n\t\t\t\t\t RX_BUF_SZ,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t}\n\tring_size = sizeof(struct ravb_ex_rx_desc) *\n\t\t    (priv->num_rx_ring[q] + 1);\n\tdma_free_coherent(ndev->dev.parent, ring_size, priv->rx_ring[q],\n\t\t\t  priv->rx_desc_dma[q]);\n\tpriv->rx_ring[q] = NULL;\n}\n\n \nstatic void ravb_ring_free(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tunsigned int num_tx_desc = priv->num_tx_desc;\n\tunsigned int ring_size;\n\tunsigned int i;\n\n\tinfo->rx_ring_free(ndev, q);\n\n\tif (priv->tx_ring[q]) {\n\t\travb_tx_free(ndev, q, false);\n\n\t\tring_size = sizeof(struct ravb_tx_desc) *\n\t\t\t    (priv->num_tx_ring[q] * num_tx_desc + 1);\n\t\tdma_free_coherent(ndev->dev.parent, ring_size, priv->tx_ring[q],\n\t\t\t\t  priv->tx_desc_dma[q]);\n\t\tpriv->tx_ring[q] = NULL;\n\t}\n\n\t \n\tif (priv->rx_skb[q]) {\n\t\tfor (i = 0; i < priv->num_rx_ring[q]; i++)\n\t\t\tdev_kfree_skb(priv->rx_skb[q][i]);\n\t}\n\tkfree(priv->rx_skb[q]);\n\tpriv->rx_skb[q] = NULL;\n\n\t \n\tkfree(priv->tx_align[q]);\n\tpriv->tx_align[q] = NULL;\n\n\t \n\tkfree(priv->tx_skb[q]);\n\tpriv->tx_skb[q] = NULL;\n}\n\nstatic void ravb_rx_ring_format_gbeth(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tstruct ravb_rx_desc *rx_desc;\n\tunsigned int rx_ring_size;\n\tdma_addr_t dma_addr;\n\tunsigned int i;\n\n\trx_ring_size = sizeof(*rx_desc) * priv->num_rx_ring[q];\n\tmemset(priv->gbeth_rx_ring, 0, rx_ring_size);\n\t \n\tfor (i = 0; i < priv->num_rx_ring[q]; i++) {\n\t\t \n\t\trx_desc = &priv->gbeth_rx_ring[i];\n\t\trx_desc->ds_cc = cpu_to_le16(GBETH_RX_DESC_DATA_SIZE);\n\t\tdma_addr = dma_map_single(ndev->dev.parent, priv->rx_skb[q][i]->data,\n\t\t\t\t\t  GBETH_RX_BUFF_MAX,\n\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\t \n\t\tif (dma_mapping_error(ndev->dev.parent, dma_addr))\n\t\t\trx_desc->ds_cc = cpu_to_le16(0);\n\t\trx_desc->dptr = cpu_to_le32(dma_addr);\n\t\trx_desc->die_dt = DT_FEMPTY;\n\t}\n\trx_desc = &priv->gbeth_rx_ring[i];\n\trx_desc->dptr = cpu_to_le32((u32)priv->rx_desc_dma[q]);\n\trx_desc->die_dt = DT_LINKFIX;  \n}\n\nstatic void ravb_rx_ring_format_rcar(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tstruct ravb_ex_rx_desc *rx_desc;\n\tunsigned int rx_ring_size = sizeof(*rx_desc) * priv->num_rx_ring[q];\n\tdma_addr_t dma_addr;\n\tunsigned int i;\n\n\tmemset(priv->rx_ring[q], 0, rx_ring_size);\n\t \n\tfor (i = 0; i < priv->num_rx_ring[q]; i++) {\n\t\t \n\t\trx_desc = &priv->rx_ring[q][i];\n\t\trx_desc->ds_cc = cpu_to_le16(RX_BUF_SZ);\n\t\tdma_addr = dma_map_single(ndev->dev.parent, priv->rx_skb[q][i]->data,\n\t\t\t\t\t  RX_BUF_SZ,\n\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\t \n\t\tif (dma_mapping_error(ndev->dev.parent, dma_addr))\n\t\t\trx_desc->ds_cc = cpu_to_le16(0);\n\t\trx_desc->dptr = cpu_to_le32(dma_addr);\n\t\trx_desc->die_dt = DT_FEMPTY;\n\t}\n\trx_desc = &priv->rx_ring[q][i];\n\trx_desc->dptr = cpu_to_le32((u32)priv->rx_desc_dma[q]);\n\trx_desc->die_dt = DT_LINKFIX;  \n}\n\n \nstatic void ravb_ring_format(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tunsigned int num_tx_desc = priv->num_tx_desc;\n\tstruct ravb_tx_desc *tx_desc;\n\tstruct ravb_desc *desc;\n\tunsigned int tx_ring_size = sizeof(*tx_desc) * priv->num_tx_ring[q] *\n\t\t\t\t    num_tx_desc;\n\tunsigned int i;\n\n\tpriv->cur_rx[q] = 0;\n\tpriv->cur_tx[q] = 0;\n\tpriv->dirty_rx[q] = 0;\n\tpriv->dirty_tx[q] = 0;\n\n\tinfo->rx_ring_format(ndev, q);\n\n\tmemset(priv->tx_ring[q], 0, tx_ring_size);\n\t \n\tfor (i = 0, tx_desc = priv->tx_ring[q]; i < priv->num_tx_ring[q];\n\t     i++, tx_desc++) {\n\t\ttx_desc->die_dt = DT_EEMPTY;\n\t\tif (num_tx_desc > 1) {\n\t\t\ttx_desc++;\n\t\t\ttx_desc->die_dt = DT_EEMPTY;\n\t\t}\n\t}\n\ttx_desc->dptr = cpu_to_le32((u32)priv->tx_desc_dma[q]);\n\ttx_desc->die_dt = DT_LINKFIX;  \n\n\t \n\tdesc = &priv->desc_bat[RX_QUEUE_OFFSET + q];\n\tdesc->die_dt = DT_LINKFIX;  \n\tdesc->dptr = cpu_to_le32((u32)priv->rx_desc_dma[q]);\n\n\t \n\tdesc = &priv->desc_bat[q];\n\tdesc->die_dt = DT_LINKFIX;  \n\tdesc->dptr = cpu_to_le32((u32)priv->tx_desc_dma[q]);\n}\n\nstatic void *ravb_alloc_rx_desc_gbeth(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tunsigned int ring_size;\n\n\tring_size = sizeof(struct ravb_rx_desc) * (priv->num_rx_ring[q] + 1);\n\n\tpriv->gbeth_rx_ring = dma_alloc_coherent(ndev->dev.parent, ring_size,\n\t\t\t\t\t\t &priv->rx_desc_dma[q],\n\t\t\t\t\t\t GFP_KERNEL);\n\treturn priv->gbeth_rx_ring;\n}\n\nstatic void *ravb_alloc_rx_desc_rcar(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tunsigned int ring_size;\n\n\tring_size = sizeof(struct ravb_ex_rx_desc) * (priv->num_rx_ring[q] + 1);\n\n\tpriv->rx_ring[q] = dma_alloc_coherent(ndev->dev.parent, ring_size,\n\t\t\t\t\t      &priv->rx_desc_dma[q],\n\t\t\t\t\t      GFP_KERNEL);\n\treturn priv->rx_ring[q];\n}\n\n \nstatic int ravb_ring_init(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tunsigned int num_tx_desc = priv->num_tx_desc;\n\tunsigned int ring_size;\n\tstruct sk_buff *skb;\n\tunsigned int i;\n\n\t \n\tpriv->rx_skb[q] = kcalloc(priv->num_rx_ring[q],\n\t\t\t\t  sizeof(*priv->rx_skb[q]), GFP_KERNEL);\n\tpriv->tx_skb[q] = kcalloc(priv->num_tx_ring[q],\n\t\t\t\t  sizeof(*priv->tx_skb[q]), GFP_KERNEL);\n\tif (!priv->rx_skb[q] || !priv->tx_skb[q])\n\t\tgoto error;\n\n\tfor (i = 0; i < priv->num_rx_ring[q]; i++) {\n\t\tskb = __netdev_alloc_skb(ndev, info->max_rx_len, GFP_KERNEL);\n\t\tif (!skb)\n\t\t\tgoto error;\n\t\travb_set_buffer_align(skb);\n\t\tpriv->rx_skb[q][i] = skb;\n\t}\n\n\tif (num_tx_desc > 1) {\n\t\t \n\t\tpriv->tx_align[q] = kmalloc(DPTR_ALIGN * priv->num_tx_ring[q] +\n\t\t\t\t\t    DPTR_ALIGN - 1, GFP_KERNEL);\n\t\tif (!priv->tx_align[q])\n\t\t\tgoto error;\n\t}\n\n\t \n\tif (!info->alloc_rx_desc(ndev, q))\n\t\tgoto error;\n\n\tpriv->dirty_rx[q] = 0;\n\n\t \n\tring_size = sizeof(struct ravb_tx_desc) *\n\t\t    (priv->num_tx_ring[q] * num_tx_desc + 1);\n\tpriv->tx_ring[q] = dma_alloc_coherent(ndev->dev.parent, ring_size,\n\t\t\t\t\t      &priv->tx_desc_dma[q],\n\t\t\t\t\t      GFP_KERNEL);\n\tif (!priv->tx_ring[q])\n\t\tgoto error;\n\n\treturn 0;\n\nerror:\n\travb_ring_free(ndev, q);\n\n\treturn -ENOMEM;\n}\n\nstatic void ravb_emac_init_gbeth(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tif (priv->phy_interface == PHY_INTERFACE_MODE_MII) {\n\t\travb_write(ndev, (1000 << 16) | CXR35_SEL_XMII_MII, CXR35);\n\t\travb_modify(ndev, CXR31, CXR31_SEL_LINK0 | CXR31_SEL_LINK1, 0);\n\t} else {\n\t\travb_write(ndev, (1000 << 16) | CXR35_SEL_XMII_RGMII, CXR35);\n\t\travb_modify(ndev, CXR31, CXR31_SEL_LINK0 | CXR31_SEL_LINK1,\n\t\t\t    CXR31_SEL_LINK0);\n\t}\n\n\t \n\travb_write(ndev, GBETH_RX_BUFF_MAX + ETH_FCS_LEN, RFLR);\n\n\t \n\travb_write(ndev, ECMR_ZPF | ((priv->duplex > 0) ? ECMR_DM : 0) |\n\t\t\t ECMR_TE | ECMR_RE | ECMR_RCPT |\n\t\t\t ECMR_TXF | ECMR_RXF, ECMR);\n\n\travb_set_rate_gbeth(ndev);\n\n\t \n\travb_write(ndev,\n\t\t   (ndev->dev_addr[0] << 24) | (ndev->dev_addr[1] << 16) |\n\t\t   (ndev->dev_addr[2] << 8)  | (ndev->dev_addr[3]), MAHR);\n\travb_write(ndev, (ndev->dev_addr[4] << 8)  | (ndev->dev_addr[5]), MALR);\n\n\t \n\travb_write(ndev, ECSR_ICD | ECSR_LCHNG | ECSR_PFRI, ECSR);\n\travb_write(ndev, CSR0_TPE | CSR0_RPE, CSR0);\n\n\t \n\travb_write(ndev, ECSIPR_ICDIP, ECSIPR);\n}\n\nstatic void ravb_emac_init_rcar(struct net_device *ndev)\n{\n\t \n\travb_write(ndev, ndev->mtu + ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN, RFLR);\n\n\t \n\travb_write(ndev, ECMR_ZPF | ECMR_DM |\n\t\t   (ndev->features & NETIF_F_RXCSUM ? ECMR_RCSC : 0) |\n\t\t   ECMR_TE | ECMR_RE, ECMR);\n\n\travb_set_rate_rcar(ndev);\n\n\t \n\travb_write(ndev,\n\t\t   (ndev->dev_addr[0] << 24) | (ndev->dev_addr[1] << 16) |\n\t\t   (ndev->dev_addr[2] << 8)  | (ndev->dev_addr[3]), MAHR);\n\travb_write(ndev,\n\t\t   (ndev->dev_addr[4] << 8)  | (ndev->dev_addr[5]), MALR);\n\n\t \n\travb_write(ndev, ECSR_ICD | ECSR_MPD, ECSR);\n\n\t \n\travb_write(ndev, ECSIPR_ICDIP | ECSIPR_MPDIP | ECSIPR_LCHNGIP, ECSIPR);\n}\n\n \nstatic void ravb_emac_init(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\tinfo->emac_init(ndev);\n}\n\nstatic int ravb_dmac_init_gbeth(struct net_device *ndev)\n{\n\tint error;\n\n\terror = ravb_ring_init(ndev, RAVB_BE);\n\tif (error)\n\t\treturn error;\n\n\t \n\travb_ring_format(ndev, RAVB_BE);\n\n\t \n\travb_write(ndev, 0x60000000, RCR);\n\n\t \n\travb_write(ndev, 0x7ffc0000 | GBETH_RX_BUFF_MAX, RTC);\n\n\t \n\travb_write(ndev, 0x00222200, TGC);\n\n\travb_write(ndev, 0, TCCR);\n\n\t \n\travb_write(ndev, RIC0_FRE0, RIC0);\n\t \n\travb_write(ndev, 0x0, RIC1);\n\t \n\travb_write(ndev, RIC2_QFE0 | RIC2_RFFE, RIC2);\n\n\travb_write(ndev, TIC_FTE0, TIC);\n\n\treturn 0;\n}\n\nstatic int ravb_dmac_init_rcar(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint error;\n\n\terror = ravb_ring_init(ndev, RAVB_BE);\n\tif (error)\n\t\treturn error;\n\terror = ravb_ring_init(ndev, RAVB_NC);\n\tif (error) {\n\t\travb_ring_free(ndev, RAVB_BE);\n\t\treturn error;\n\t}\n\n\t \n\travb_ring_format(ndev, RAVB_BE);\n\travb_ring_format(ndev, RAVB_NC);\n\n\t \n\travb_write(ndev,\n\t\t   RCR_EFFS | RCR_ENCF | RCR_ETS0 | RCR_ESF | 0x18000000, RCR);\n\n\t \n\travb_write(ndev, TGC_TQP_AVBMODE1 | 0x00112200, TGC);\n\n\t \n\travb_write(ndev, TCCR_TFEN, TCCR);\n\n\t \n\tif (info->multi_irqs) {\n\t\t \n\t\travb_write(ndev, 0, DIL);\n\t\t \n\t\travb_write(ndev, CIE_CRIE | CIE_CTIE | CIE_CL0M, CIE);\n\t}\n\t \n\travb_write(ndev, RIC0_FRE0 | RIC0_FRE1, RIC0);\n\t \n\travb_write(ndev, 0, RIC1);\n\t \n\travb_write(ndev, RIC2_QFE0 | RIC2_QFE1 | RIC2_RFFE, RIC2);\n\t \n\travb_write(ndev, TIC_FTE0 | TIC_FTE1 | TIC_TFUE, TIC);\n\n\treturn 0;\n}\n\n \nstatic int ravb_dmac_init(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint error;\n\n\t \n\terror = ravb_set_opmode(ndev, CCC_OPC_CONFIG);\n\tif (error)\n\t\treturn error;\n\n\terror = info->dmac_init(ndev);\n\tif (error)\n\t\treturn error;\n\n\t \n\treturn ravb_set_opmode(ndev, CCC_OPC_OPERATION);\n}\n\nstatic void ravb_get_tx_tstamp(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tstruct ravb_tstamp_skb *ts_skb, *ts_skb2;\n\tstruct skb_shared_hwtstamps shhwtstamps;\n\tstruct sk_buff *skb;\n\tstruct timespec64 ts;\n\tu16 tag, tfa_tag;\n\tint count;\n\tu32 tfa2;\n\n\tcount = (ravb_read(ndev, TSR) & TSR_TFFL) >> 8;\n\twhile (count--) {\n\t\ttfa2 = ravb_read(ndev, TFA2);\n\t\ttfa_tag = (tfa2 & TFA2_TST) >> 16;\n\t\tts.tv_nsec = (u64)ravb_read(ndev, TFA0);\n\t\tts.tv_sec = ((u64)(tfa2 & TFA2_TSV) << 32) |\n\t\t\t    ravb_read(ndev, TFA1);\n\t\tmemset(&shhwtstamps, 0, sizeof(shhwtstamps));\n\t\tshhwtstamps.hwtstamp = timespec64_to_ktime(ts);\n\t\tlist_for_each_entry_safe(ts_skb, ts_skb2, &priv->ts_skb_list,\n\t\t\t\t\t list) {\n\t\t\tskb = ts_skb->skb;\n\t\t\ttag = ts_skb->tag;\n\t\t\tlist_del(&ts_skb->list);\n\t\t\tkfree(ts_skb);\n\t\t\tif (tag == tfa_tag) {\n\t\t\t\tskb_tstamp_tx(skb, &shhwtstamps);\n\t\t\t\tdev_consume_skb_any(skb);\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tdev_kfree_skb_any(skb);\n\t\t\t}\n\t\t}\n\t\travb_modify(ndev, TCCR, TCCR_TFR, TCCR_TFR);\n\t}\n}\n\nstatic void ravb_rx_csum(struct sk_buff *skb)\n{\n\tu8 *hw_csum;\n\n\t \n\tif (unlikely(skb->len < sizeof(__sum16)))\n\t\treturn;\n\thw_csum = skb_tail_pointer(skb) - sizeof(__sum16);\n\tskb->csum = csum_unfold((__force __sum16)get_unaligned_le16(hw_csum));\n\tskb->ip_summed = CHECKSUM_COMPLETE;\n\tskb_trim(skb, skb->len - sizeof(__sum16));\n}\n\nstatic struct sk_buff *ravb_get_skb_gbeth(struct net_device *ndev, int entry,\n\t\t\t\t\t  struct ravb_rx_desc *desc)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tstruct sk_buff *skb;\n\n\tskb = priv->rx_skb[RAVB_BE][entry];\n\tpriv->rx_skb[RAVB_BE][entry] = NULL;\n\tdma_unmap_single(ndev->dev.parent, le32_to_cpu(desc->dptr),\n\t\t\t ALIGN(GBETH_RX_BUFF_MAX, 16), DMA_FROM_DEVICE);\n\n\treturn skb;\n}\n\n \nstatic bool ravb_rx_gbeth(struct net_device *ndev, int *quota, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct net_device_stats *stats;\n\tstruct ravb_rx_desc *desc;\n\tstruct sk_buff *skb;\n\tdma_addr_t dma_addr;\n\tu8  desc_status;\n\tint boguscnt;\n\tu16 pkt_len;\n\tu8  die_dt;\n\tint entry;\n\tint limit;\n\n\tentry = priv->cur_rx[q] % priv->num_rx_ring[q];\n\tboguscnt = priv->dirty_rx[q] + priv->num_rx_ring[q] - priv->cur_rx[q];\n\tstats = &priv->stats[q];\n\n\tboguscnt = min(boguscnt, *quota);\n\tlimit = boguscnt;\n\tdesc = &priv->gbeth_rx_ring[entry];\n\twhile (desc->die_dt != DT_FEMPTY) {\n\t\t \n\t\tdma_rmb();\n\t\tdesc_status = desc->msc;\n\t\tpkt_len = le16_to_cpu(desc->ds_cc) & RX_DS;\n\n\t\tif (--boguscnt < 0)\n\t\t\tbreak;\n\n\t\t \n\t\tif (!pkt_len)\n\t\t\tcontinue;\n\n\t\tif (desc_status & MSC_MC)\n\t\t\tstats->multicast++;\n\n\t\tif (desc_status & (MSC_CRC | MSC_RFE | MSC_RTSF | MSC_RTLF | MSC_CEEF)) {\n\t\t\tstats->rx_errors++;\n\t\t\tif (desc_status & MSC_CRC)\n\t\t\t\tstats->rx_crc_errors++;\n\t\t\tif (desc_status & MSC_RFE)\n\t\t\t\tstats->rx_frame_errors++;\n\t\t\tif (desc_status & (MSC_RTLF | MSC_RTSF))\n\t\t\t\tstats->rx_length_errors++;\n\t\t\tif (desc_status & MSC_CEEF)\n\t\t\t\tstats->rx_missed_errors++;\n\t\t} else {\n\t\t\tdie_dt = desc->die_dt & 0xF0;\n\t\t\tswitch (die_dt) {\n\t\t\tcase DT_FSINGLE:\n\t\t\t\tskb = ravb_get_skb_gbeth(ndev, entry, desc);\n\t\t\t\tskb_put(skb, pkt_len);\n\t\t\t\tskb->protocol = eth_type_trans(skb, ndev);\n\t\t\t\tnapi_gro_receive(&priv->napi[q], skb);\n\t\t\t\tstats->rx_packets++;\n\t\t\t\tstats->rx_bytes += pkt_len;\n\t\t\t\tbreak;\n\t\t\tcase DT_FSTART:\n\t\t\t\tpriv->rx_1st_skb = ravb_get_skb_gbeth(ndev, entry, desc);\n\t\t\t\tskb_put(priv->rx_1st_skb, pkt_len);\n\t\t\t\tbreak;\n\t\t\tcase DT_FMID:\n\t\t\t\tskb = ravb_get_skb_gbeth(ndev, entry, desc);\n\t\t\t\tskb_copy_to_linear_data_offset(priv->rx_1st_skb,\n\t\t\t\t\t\t\t       priv->rx_1st_skb->len,\n\t\t\t\t\t\t\t       skb->data,\n\t\t\t\t\t\t\t       pkt_len);\n\t\t\t\tskb_put(priv->rx_1st_skb, pkt_len);\n\t\t\t\tdev_kfree_skb(skb);\n\t\t\t\tbreak;\n\t\t\tcase DT_FEND:\n\t\t\t\tskb = ravb_get_skb_gbeth(ndev, entry, desc);\n\t\t\t\tskb_copy_to_linear_data_offset(priv->rx_1st_skb,\n\t\t\t\t\t\t\t       priv->rx_1st_skb->len,\n\t\t\t\t\t\t\t       skb->data,\n\t\t\t\t\t\t\t       pkt_len);\n\t\t\t\tskb_put(priv->rx_1st_skb, pkt_len);\n\t\t\t\tdev_kfree_skb(skb);\n\t\t\t\tpriv->rx_1st_skb->protocol =\n\t\t\t\t\teth_type_trans(priv->rx_1st_skb, ndev);\n\t\t\t\tnapi_gro_receive(&priv->napi[q],\n\t\t\t\t\t\t priv->rx_1st_skb);\n\t\t\t\tstats->rx_packets++;\n\t\t\t\tstats->rx_bytes += pkt_len;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tentry = (++priv->cur_rx[q]) % priv->num_rx_ring[q];\n\t\tdesc = &priv->gbeth_rx_ring[entry];\n\t}\n\n\t \n\tfor (; priv->cur_rx[q] - priv->dirty_rx[q] > 0; priv->dirty_rx[q]++) {\n\t\tentry = priv->dirty_rx[q] % priv->num_rx_ring[q];\n\t\tdesc = &priv->gbeth_rx_ring[entry];\n\t\tdesc->ds_cc = cpu_to_le16(GBETH_RX_DESC_DATA_SIZE);\n\n\t\tif (!priv->rx_skb[q][entry]) {\n\t\t\tskb = netdev_alloc_skb(ndev, info->max_rx_len);\n\t\t\tif (!skb)\n\t\t\t\tbreak;\n\t\t\travb_set_buffer_align(skb);\n\t\t\tdma_addr = dma_map_single(ndev->dev.parent,\n\t\t\t\t\t\t  skb->data,\n\t\t\t\t\t\t  GBETH_RX_BUFF_MAX,\n\t\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\t\tskb_checksum_none_assert(skb);\n\t\t\t \n\t\t\tif (dma_mapping_error(ndev->dev.parent, dma_addr))\n\t\t\t\tdesc->ds_cc = cpu_to_le16(0);\n\t\t\tdesc->dptr = cpu_to_le32(dma_addr);\n\t\t\tpriv->rx_skb[q][entry] = skb;\n\t\t}\n\t\t \n\t\tdma_wmb();\n\t\tdesc->die_dt = DT_FEMPTY;\n\t}\n\n\t*quota -= limit - (++boguscnt);\n\n\treturn boguscnt <= 0;\n}\n\n \nstatic bool ravb_rx_rcar(struct net_device *ndev, int *quota, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint entry = priv->cur_rx[q] % priv->num_rx_ring[q];\n\tint boguscnt = (priv->dirty_rx[q] + priv->num_rx_ring[q]) -\n\t\t\tpriv->cur_rx[q];\n\tstruct net_device_stats *stats = &priv->stats[q];\n\tstruct ravb_ex_rx_desc *desc;\n\tstruct sk_buff *skb;\n\tdma_addr_t dma_addr;\n\tstruct timespec64 ts;\n\tu8  desc_status;\n\tu16 pkt_len;\n\tint limit;\n\n\tboguscnt = min(boguscnt, *quota);\n\tlimit = boguscnt;\n\tdesc = &priv->rx_ring[q][entry];\n\twhile (desc->die_dt != DT_FEMPTY) {\n\t\t \n\t\tdma_rmb();\n\t\tdesc_status = desc->msc;\n\t\tpkt_len = le16_to_cpu(desc->ds_cc) & RX_DS;\n\n\t\tif (--boguscnt < 0)\n\t\t\tbreak;\n\n\t\t \n\t\tif (!pkt_len)\n\t\t\tcontinue;\n\n\t\tif (desc_status & MSC_MC)\n\t\t\tstats->multicast++;\n\n\t\tif (desc_status & (MSC_CRC | MSC_RFE | MSC_RTSF | MSC_RTLF |\n\t\t\t\t   MSC_CEEF)) {\n\t\t\tstats->rx_errors++;\n\t\t\tif (desc_status & MSC_CRC)\n\t\t\t\tstats->rx_crc_errors++;\n\t\t\tif (desc_status & MSC_RFE)\n\t\t\t\tstats->rx_frame_errors++;\n\t\t\tif (desc_status & (MSC_RTLF | MSC_RTSF))\n\t\t\t\tstats->rx_length_errors++;\n\t\t\tif (desc_status & MSC_CEEF)\n\t\t\t\tstats->rx_missed_errors++;\n\t\t} else {\n\t\t\tu32 get_ts = priv->tstamp_rx_ctrl & RAVB_RXTSTAMP_TYPE;\n\n\t\t\tskb = priv->rx_skb[q][entry];\n\t\t\tpriv->rx_skb[q][entry] = NULL;\n\t\t\tdma_unmap_single(ndev->dev.parent, le32_to_cpu(desc->dptr),\n\t\t\t\t\t RX_BUF_SZ,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tget_ts &= (q == RAVB_NC) ?\n\t\t\t\t\tRAVB_RXTSTAMP_TYPE_V2_L2_EVENT :\n\t\t\t\t\t~RAVB_RXTSTAMP_TYPE_V2_L2_EVENT;\n\t\t\tif (get_ts) {\n\t\t\t\tstruct skb_shared_hwtstamps *shhwtstamps;\n\n\t\t\t\tshhwtstamps = skb_hwtstamps(skb);\n\t\t\t\tmemset(shhwtstamps, 0, sizeof(*shhwtstamps));\n\t\t\t\tts.tv_sec = ((u64) le16_to_cpu(desc->ts_sh) <<\n\t\t\t\t\t     32) | le32_to_cpu(desc->ts_sl);\n\t\t\t\tts.tv_nsec = le32_to_cpu(desc->ts_n);\n\t\t\t\tshhwtstamps->hwtstamp = timespec64_to_ktime(ts);\n\t\t\t}\n\n\t\t\tskb_put(skb, pkt_len);\n\t\t\tskb->protocol = eth_type_trans(skb, ndev);\n\t\t\tif (ndev->features & NETIF_F_RXCSUM)\n\t\t\t\travb_rx_csum(skb);\n\t\t\tnapi_gro_receive(&priv->napi[q], skb);\n\t\t\tstats->rx_packets++;\n\t\t\tstats->rx_bytes += pkt_len;\n\t\t}\n\n\t\tentry = (++priv->cur_rx[q]) % priv->num_rx_ring[q];\n\t\tdesc = &priv->rx_ring[q][entry];\n\t}\n\n\t \n\tfor (; priv->cur_rx[q] - priv->dirty_rx[q] > 0; priv->dirty_rx[q]++) {\n\t\tentry = priv->dirty_rx[q] % priv->num_rx_ring[q];\n\t\tdesc = &priv->rx_ring[q][entry];\n\t\tdesc->ds_cc = cpu_to_le16(RX_BUF_SZ);\n\n\t\tif (!priv->rx_skb[q][entry]) {\n\t\t\tskb = netdev_alloc_skb(ndev, info->max_rx_len);\n\t\t\tif (!skb)\n\t\t\t\tbreak;\t \n\t\t\travb_set_buffer_align(skb);\n\t\t\tdma_addr = dma_map_single(ndev->dev.parent, skb->data,\n\t\t\t\t\t\t  le16_to_cpu(desc->ds_cc),\n\t\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\t\tskb_checksum_none_assert(skb);\n\t\t\t \n\t\t\tif (dma_mapping_error(ndev->dev.parent, dma_addr))\n\t\t\t\tdesc->ds_cc = cpu_to_le16(0);\n\t\t\tdesc->dptr = cpu_to_le32(dma_addr);\n\t\t\tpriv->rx_skb[q][entry] = skb;\n\t\t}\n\t\t \n\t\tdma_wmb();\n\t\tdesc->die_dt = DT_FEMPTY;\n\t}\n\n\t*quota -= limit - (++boguscnt);\n\n\treturn boguscnt <= 0;\n}\n\n \nstatic bool ravb_rx(struct net_device *ndev, int *quota, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\treturn info->receive(ndev, quota, q);\n}\n\nstatic void ravb_rcv_snd_disable(struct net_device *ndev)\n{\n\t \n\travb_modify(ndev, ECMR, ECMR_RE | ECMR_TE, 0);\n}\n\nstatic void ravb_rcv_snd_enable(struct net_device *ndev)\n{\n\t \n\travb_modify(ndev, ECMR, ECMR_RE | ECMR_TE, ECMR_RE | ECMR_TE);\n}\n\n \nstatic int ravb_stop_dma(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint error;\n\n\t \n\terror = ravb_wait(ndev, TCCR, info->tccr_mask, 0);\n\n\tif (error)\n\t\treturn error;\n\n\terror = ravb_wait(ndev, CSR, CSR_TPO0 | CSR_TPO1 | CSR_TPO2 | CSR_TPO3,\n\t\t\t  0);\n\tif (error)\n\t\treturn error;\n\n\t \n\travb_rcv_snd_disable(ndev);\n\n\t \n\terror = ravb_wait(ndev, CSR, CSR_RPO, 0);\n\tif (error)\n\t\treturn error;\n\n\t \n\treturn ravb_set_opmode(ndev, CCC_OPC_CONFIG);\n}\n\n \nstatic void ravb_emac_interrupt_unlocked(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tu32 ecsr, psr;\n\n\tecsr = ravb_read(ndev, ECSR);\n\travb_write(ndev, ecsr, ECSR);\t \n\n\tif (ecsr & ECSR_MPD)\n\t\tpm_wakeup_event(&priv->pdev->dev, 0);\n\tif (ecsr & ECSR_ICD)\n\t\tndev->stats.tx_carrier_errors++;\n\tif (ecsr & ECSR_LCHNG) {\n\t\t \n\t\tif (priv->no_avb_link)\n\t\t\treturn;\n\t\tpsr = ravb_read(ndev, PSR);\n\t\tif (priv->avb_link_active_low)\n\t\t\tpsr ^= PSR_LMON;\n\t\tif (!(psr & PSR_LMON)) {\n\t\t\t \n\t\t\travb_rcv_snd_disable(ndev);\n\t\t} else {\n\t\t\t \n\t\t\travb_rcv_snd_enable(ndev);\n\t\t}\n\t}\n}\n\nstatic irqreturn_t ravb_emac_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *ndev = dev_id;\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tspin_lock(&priv->lock);\n\travb_emac_interrupt_unlocked(ndev);\n\tspin_unlock(&priv->lock);\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void ravb_error_interrupt(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tu32 eis, ris2;\n\n\teis = ravb_read(ndev, EIS);\n\travb_write(ndev, ~(EIS_QFS | EIS_RESERVED), EIS);\n\tif (eis & EIS_QFS) {\n\t\tris2 = ravb_read(ndev, RIS2);\n\t\travb_write(ndev, ~(RIS2_QFF0 | RIS2_QFF1 | RIS2_RFFF | RIS2_RESERVED),\n\t\t\t   RIS2);\n\n\t\t \n\t\tif (ris2 & RIS2_QFF0)\n\t\t\tpriv->stats[RAVB_BE].rx_over_errors++;\n\n\t\t \n\t\tif (ris2 & RIS2_QFF1)\n\t\t\tpriv->stats[RAVB_NC].rx_over_errors++;\n\n\t\t \n\t\tif (ris2 & RIS2_RFFF)\n\t\t\tpriv->rx_fifo_errors++;\n\t}\n}\n\nstatic bool ravb_queue_interrupt(struct net_device *ndev, int q)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tu32 ris0 = ravb_read(ndev, RIS0);\n\tu32 ric0 = ravb_read(ndev, RIC0);\n\tu32 tis  = ravb_read(ndev, TIS);\n\tu32 tic  = ravb_read(ndev, TIC);\n\n\tif (((ris0 & ric0) & BIT(q)) || ((tis  & tic)  & BIT(q))) {\n\t\tif (napi_schedule_prep(&priv->napi[q])) {\n\t\t\t \n\t\t\tif (!info->irq_en_dis) {\n\t\t\t\travb_write(ndev, ric0 & ~BIT(q), RIC0);\n\t\t\t\travb_write(ndev, tic & ~BIT(q), TIC);\n\t\t\t} else {\n\t\t\t\travb_write(ndev, BIT(q), RID0);\n\t\t\t\travb_write(ndev, BIT(q), TID);\n\t\t\t}\n\t\t\t__napi_schedule(&priv->napi[q]);\n\t\t} else {\n\t\t\tnetdev_warn(ndev,\n\t\t\t\t    \"ignoring interrupt, rx status 0x%08x, rx mask 0x%08x,\\n\",\n\t\t\t\t    ris0, ric0);\n\t\t\tnetdev_warn(ndev,\n\t\t\t\t    \"                    tx status 0x%08x, tx mask 0x%08x.\\n\",\n\t\t\t\t    tis, tic);\n\t\t}\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic bool ravb_timestamp_interrupt(struct net_device *ndev)\n{\n\tu32 tis = ravb_read(ndev, TIS);\n\n\tif (tis & TIS_TFUF) {\n\t\travb_write(ndev, ~(TIS_TFUF | TIS_RESERVED), TIS);\n\t\travb_get_tx_tstamp(ndev);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic irqreturn_t ravb_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *ndev = dev_id;\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tirqreturn_t result = IRQ_NONE;\n\tu32 iss;\n\n\tspin_lock(&priv->lock);\n\t \n\tiss = ravb_read(ndev, ISS);\n\n\t \n\tif (iss & (ISS_FRS | ISS_FTS | ISS_TFUS)) {\n\t\tint q;\n\n\t\t \n\t\tif (ravb_timestamp_interrupt(ndev))\n\t\t\tresult = IRQ_HANDLED;\n\n\t\t \n\t\tif (info->nc_queues) {\n\t\t\tfor (q = RAVB_NC; q >= RAVB_BE; q--) {\n\t\t\t\tif (ravb_queue_interrupt(ndev, q))\n\t\t\t\t\tresult = IRQ_HANDLED;\n\t\t\t}\n\t\t} else {\n\t\t\tif (ravb_queue_interrupt(ndev, RAVB_BE))\n\t\t\t\tresult = IRQ_HANDLED;\n\t\t}\n\t}\n\n\t \n\tif (iss & ISS_MS) {\n\t\travb_emac_interrupt_unlocked(ndev);\n\t\tresult = IRQ_HANDLED;\n\t}\n\n\t \n\tif (iss & ISS_ES) {\n\t\travb_error_interrupt(ndev);\n\t\tresult = IRQ_HANDLED;\n\t}\n\n\t \n\tif (iss & ISS_CGIS) {\n\t\travb_ptp_interrupt(ndev);\n\t\tresult = IRQ_HANDLED;\n\t}\n\n\tspin_unlock(&priv->lock);\n\treturn result;\n}\n\n \nstatic irqreturn_t ravb_multi_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *ndev = dev_id;\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tirqreturn_t result = IRQ_NONE;\n\tu32 iss;\n\n\tspin_lock(&priv->lock);\n\t \n\tiss = ravb_read(ndev, ISS);\n\n\t \n\tif ((iss & ISS_TFUS) && ravb_timestamp_interrupt(ndev))\n\t\tresult = IRQ_HANDLED;\n\n\t \n\tif (iss & ISS_ES) {\n\t\travb_error_interrupt(ndev);\n\t\tresult = IRQ_HANDLED;\n\t}\n\n\t \n\tif (iss & ISS_CGIS) {\n\t\travb_ptp_interrupt(ndev);\n\t\tresult = IRQ_HANDLED;\n\t}\n\n\tspin_unlock(&priv->lock);\n\treturn result;\n}\n\nstatic irqreturn_t ravb_dma_interrupt(int irq, void *dev_id, int q)\n{\n\tstruct net_device *ndev = dev_id;\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tirqreturn_t result = IRQ_NONE;\n\n\tspin_lock(&priv->lock);\n\n\t \n\tif (ravb_queue_interrupt(ndev, q))\n\t\tresult = IRQ_HANDLED;\n\n\tspin_unlock(&priv->lock);\n\treturn result;\n}\n\nstatic irqreturn_t ravb_be_interrupt(int irq, void *dev_id)\n{\n\treturn ravb_dma_interrupt(irq, dev_id, RAVB_BE);\n}\n\nstatic irqreturn_t ravb_nc_interrupt(int irq, void *dev_id)\n{\n\treturn ravb_dma_interrupt(irq, dev_id, RAVB_NC);\n}\n\nstatic int ravb_poll(struct napi_struct *napi, int budget)\n{\n\tstruct net_device *ndev = napi->dev;\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tbool gptp = info->gptp || info->ccc_gac;\n\tstruct ravb_rx_desc *desc;\n\tunsigned long flags;\n\tint q = napi - priv->napi;\n\tint mask = BIT(q);\n\tint quota = budget;\n\tunsigned int entry;\n\n\tif (!gptp) {\n\t\tentry = priv->cur_rx[q] % priv->num_rx_ring[q];\n\t\tdesc = &priv->gbeth_rx_ring[entry];\n\t}\n\t \n\t \n\travb_write(ndev, ~(mask | RIS0_RESERVED), RIS0);\n\tif (gptp || desc->die_dt != DT_FEMPTY) {\n\t\tif (ravb_rx(ndev, &quota, q))\n\t\t\tgoto out;\n\t}\n\n\t \n\tspin_lock_irqsave(&priv->lock, flags);\n\t \n\travb_write(ndev, ~(mask | TIS_RESERVED), TIS);\n\travb_tx_free(ndev, q, true);\n\tnetif_wake_subqueue(ndev, q);\n\tspin_unlock_irqrestore(&priv->lock, flags);\n\n\tnapi_complete(napi);\n\n\t \n\tspin_lock_irqsave(&priv->lock, flags);\n\tif (!info->irq_en_dis) {\n\t\travb_modify(ndev, RIC0, mask, mask);\n\t\travb_modify(ndev, TIC,  mask, mask);\n\t} else {\n\t\travb_write(ndev, mask, RIE0);\n\t\travb_write(ndev, mask, TIE);\n\t}\n\tspin_unlock_irqrestore(&priv->lock, flags);\n\n\t \n\tpriv->rx_over_errors =  priv->stats[RAVB_BE].rx_over_errors;\n\tif (info->nc_queues)\n\t\tpriv->rx_over_errors += priv->stats[RAVB_NC].rx_over_errors;\n\tif (priv->rx_over_errors != ndev->stats.rx_over_errors)\n\t\tndev->stats.rx_over_errors = priv->rx_over_errors;\n\tif (priv->rx_fifo_errors != ndev->stats.rx_fifo_errors)\n\t\tndev->stats.rx_fifo_errors = priv->rx_fifo_errors;\nout:\n\treturn budget - quota;\n}\n\nstatic void ravb_set_duplex_gbeth(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\travb_modify(ndev, ECMR, ECMR_DM, priv->duplex > 0 ? ECMR_DM : 0);\n}\n\n \nstatic void ravb_adjust_link(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct phy_device *phydev = ndev->phydev;\n\tbool new_state = false;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&priv->lock, flags);\n\n\t \n\tif (priv->no_avb_link)\n\t\travb_rcv_snd_disable(ndev);\n\n\tif (phydev->link) {\n\t\tif (info->half_duplex && phydev->duplex != priv->duplex) {\n\t\t\tnew_state = true;\n\t\t\tpriv->duplex = phydev->duplex;\n\t\t\travb_set_duplex_gbeth(ndev);\n\t\t}\n\n\t\tif (phydev->speed != priv->speed) {\n\t\t\tnew_state = true;\n\t\t\tpriv->speed = phydev->speed;\n\t\t\tinfo->set_rate(ndev);\n\t\t}\n\t\tif (!priv->link) {\n\t\t\travb_modify(ndev, ECMR, ECMR_TXF, 0);\n\t\t\tnew_state = true;\n\t\t\tpriv->link = phydev->link;\n\t\t}\n\t} else if (priv->link) {\n\t\tnew_state = true;\n\t\tpriv->link = 0;\n\t\tpriv->speed = 0;\n\t\tif (info->half_duplex)\n\t\t\tpriv->duplex = -1;\n\t}\n\n\t \n\tif (priv->no_avb_link && phydev->link)\n\t\travb_rcv_snd_enable(ndev);\n\n\tspin_unlock_irqrestore(&priv->lock, flags);\n\n\tif (new_state && netif_msg_link(priv))\n\t\tphy_print_status(phydev);\n}\n\n \nstatic int ravb_phy_init(struct net_device *ndev)\n{\n\tstruct device_node *np = ndev->dev.parent->of_node;\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct phy_device *phydev;\n\tstruct device_node *pn;\n\tphy_interface_t iface;\n\tint err;\n\n\tpriv->link = 0;\n\tpriv->speed = 0;\n\tpriv->duplex = -1;\n\n\t \n\tpn = of_parse_phandle(np, \"phy-handle\", 0);\n\tif (!pn) {\n\t\t \n\t\tif (of_phy_is_fixed_link(np)) {\n\t\t\terr = of_phy_register_fixed_link(np);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\tpn = of_node_get(np);\n\t}\n\n\tiface = priv->rgmii_override ? PHY_INTERFACE_MODE_RGMII\n\t\t\t\t     : priv->phy_interface;\n\tphydev = of_phy_connect(ndev, pn, ravb_adjust_link, 0, iface);\n\tof_node_put(pn);\n\tif (!phydev) {\n\t\tnetdev_err(ndev, \"failed to connect PHY\\n\");\n\t\terr = -ENOENT;\n\t\tgoto err_deregister_fixed_link;\n\t}\n\n\tif (!info->half_duplex) {\n\t\t \n\t\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_10baseT_Half_BIT);\n\t\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_10baseT_Full_BIT);\n\t\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_Pause_BIT);\n\t\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_Asym_Pause_BIT);\n\n\t\t \n\t\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_1000baseT_Half_BIT);\n\t\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_100baseT_Half_BIT);\n\t}\n\n\tphy_attached_info(phydev);\n\n\treturn 0;\n\nerr_deregister_fixed_link:\n\tif (of_phy_is_fixed_link(np))\n\t\tof_phy_deregister_fixed_link(np);\n\n\treturn err;\n}\n\n \nstatic int ravb_phy_start(struct net_device *ndev)\n{\n\tint error;\n\n\terror = ravb_phy_init(ndev);\n\tif (error)\n\t\treturn error;\n\n\tphy_start(ndev->phydev);\n\n\treturn 0;\n}\n\nstatic u32 ravb_get_msglevel(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\treturn priv->msg_enable;\n}\n\nstatic void ravb_set_msglevel(struct net_device *ndev, u32 value)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tpriv->msg_enable = value;\n}\n\nstatic const char ravb_gstrings_stats_gbeth[][ETH_GSTRING_LEN] = {\n\t\"rx_queue_0_current\",\n\t\"tx_queue_0_current\",\n\t\"rx_queue_0_dirty\",\n\t\"tx_queue_0_dirty\",\n\t\"rx_queue_0_packets\",\n\t\"tx_queue_0_packets\",\n\t\"rx_queue_0_bytes\",\n\t\"tx_queue_0_bytes\",\n\t\"rx_queue_0_mcast_packets\",\n\t\"rx_queue_0_errors\",\n\t\"rx_queue_0_crc_errors\",\n\t\"rx_queue_0_frame_errors\",\n\t\"rx_queue_0_length_errors\",\n\t\"rx_queue_0_csum_offload_errors\",\n\t\"rx_queue_0_over_errors\",\n};\n\nstatic const char ravb_gstrings_stats[][ETH_GSTRING_LEN] = {\n\t\"rx_queue_0_current\",\n\t\"tx_queue_0_current\",\n\t\"rx_queue_0_dirty\",\n\t\"tx_queue_0_dirty\",\n\t\"rx_queue_0_packets\",\n\t\"tx_queue_0_packets\",\n\t\"rx_queue_0_bytes\",\n\t\"tx_queue_0_bytes\",\n\t\"rx_queue_0_mcast_packets\",\n\t\"rx_queue_0_errors\",\n\t\"rx_queue_0_crc_errors\",\n\t\"rx_queue_0_frame_errors\",\n\t\"rx_queue_0_length_errors\",\n\t\"rx_queue_0_missed_errors\",\n\t\"rx_queue_0_over_errors\",\n\n\t\"rx_queue_1_current\",\n\t\"tx_queue_1_current\",\n\t\"rx_queue_1_dirty\",\n\t\"tx_queue_1_dirty\",\n\t\"rx_queue_1_packets\",\n\t\"tx_queue_1_packets\",\n\t\"rx_queue_1_bytes\",\n\t\"tx_queue_1_bytes\",\n\t\"rx_queue_1_mcast_packets\",\n\t\"rx_queue_1_errors\",\n\t\"rx_queue_1_crc_errors\",\n\t\"rx_queue_1_frame_errors\",\n\t\"rx_queue_1_length_errors\",\n\t\"rx_queue_1_missed_errors\",\n\t\"rx_queue_1_over_errors\",\n};\n\nstatic int ravb_get_sset_count(struct net_device *netdev, int sset)\n{\n\tstruct ravb_private *priv = netdev_priv(netdev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn info->stats_len;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void ravb_get_ethtool_stats(struct net_device *ndev,\n\t\t\t\t   struct ethtool_stats *estats, u64 *data)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint num_rx_q;\n\tint i = 0;\n\tint q;\n\n\tnum_rx_q = info->nc_queues ? NUM_RX_QUEUE : 1;\n\t \n\tfor (q = RAVB_BE; q < num_rx_q; q++) {\n\t\tstruct net_device_stats *stats = &priv->stats[q];\n\n\t\tdata[i++] = priv->cur_rx[q];\n\t\tdata[i++] = priv->cur_tx[q];\n\t\tdata[i++] = priv->dirty_rx[q];\n\t\tdata[i++] = priv->dirty_tx[q];\n\t\tdata[i++] = stats->rx_packets;\n\t\tdata[i++] = stats->tx_packets;\n\t\tdata[i++] = stats->rx_bytes;\n\t\tdata[i++] = stats->tx_bytes;\n\t\tdata[i++] = stats->multicast;\n\t\tdata[i++] = stats->rx_errors;\n\t\tdata[i++] = stats->rx_crc_errors;\n\t\tdata[i++] = stats->rx_frame_errors;\n\t\tdata[i++] = stats->rx_length_errors;\n\t\tdata[i++] = stats->rx_missed_errors;\n\t\tdata[i++] = stats->rx_over_errors;\n\t}\n}\n\nstatic void ravb_get_strings(struct net_device *ndev, u32 stringset, u8 *data)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tmemcpy(data, info->gstrings_stats, info->gstrings_size);\n\t\tbreak;\n\t}\n}\n\nstatic void ravb_get_ringparam(struct net_device *ndev,\n\t\t\t       struct ethtool_ringparam *ring,\n\t\t\t       struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tring->rx_max_pending = BE_RX_RING_MAX;\n\tring->tx_max_pending = BE_TX_RING_MAX;\n\tring->rx_pending = priv->num_rx_ring[RAVB_BE];\n\tring->tx_pending = priv->num_tx_ring[RAVB_BE];\n}\n\nstatic int ravb_set_ringparam(struct net_device *ndev,\n\t\t\t      struct ethtool_ringparam *ring,\n\t\t\t      struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint error;\n\n\tif (ring->tx_pending > BE_TX_RING_MAX ||\n\t    ring->rx_pending > BE_RX_RING_MAX ||\n\t    ring->tx_pending < BE_TX_RING_MIN ||\n\t    ring->rx_pending < BE_RX_RING_MIN)\n\t\treturn -EINVAL;\n\tif (ring->rx_mini_pending || ring->rx_jumbo_pending)\n\t\treturn -EINVAL;\n\n\tif (netif_running(ndev)) {\n\t\tnetif_device_detach(ndev);\n\t\t \n\t\tif (info->gptp)\n\t\t\travb_ptp_stop(ndev);\n\t\t \n\t\terror = ravb_stop_dma(ndev);\n\t\tif (error) {\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"cannot set ringparam! Any AVB processes are still running?\\n\");\n\t\t\treturn error;\n\t\t}\n\t\tsynchronize_irq(ndev->irq);\n\n\t\t \n\t\travb_ring_free(ndev, RAVB_BE);\n\t\tif (info->nc_queues)\n\t\t\travb_ring_free(ndev, RAVB_NC);\n\t}\n\n\t \n\tpriv->num_rx_ring[RAVB_BE] = ring->rx_pending;\n\tpriv->num_tx_ring[RAVB_BE] = ring->tx_pending;\n\n\tif (netif_running(ndev)) {\n\t\terror = ravb_dmac_init(ndev);\n\t\tif (error) {\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"%s: ravb_dmac_init() failed, error %d\\n\",\n\t\t\t\t   __func__, error);\n\t\t\treturn error;\n\t\t}\n\n\t\travb_emac_init(ndev);\n\n\t\t \n\t\tif (info->gptp)\n\t\t\travb_ptp_init(ndev, priv->pdev);\n\n\t\tnetif_device_attach(ndev);\n\t}\n\n\treturn 0;\n}\n\nstatic int ravb_get_ts_info(struct net_device *ndev,\n\t\t\t    struct ethtool_ts_info *info)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *hw_info = priv->info;\n\n\tinfo->so_timestamping =\n\t\tSOF_TIMESTAMPING_TX_SOFTWARE |\n\t\tSOF_TIMESTAMPING_RX_SOFTWARE |\n\t\tSOF_TIMESTAMPING_SOFTWARE |\n\t\tSOF_TIMESTAMPING_TX_HARDWARE |\n\t\tSOF_TIMESTAMPING_RX_HARDWARE |\n\t\tSOF_TIMESTAMPING_RAW_HARDWARE;\n\tinfo->tx_types = (1 << HWTSTAMP_TX_OFF) | (1 << HWTSTAMP_TX_ON);\n\tinfo->rx_filters =\n\t\t(1 << HWTSTAMP_FILTER_NONE) |\n\t\t(1 << HWTSTAMP_FILTER_PTP_V2_L2_EVENT) |\n\t\t(1 << HWTSTAMP_FILTER_ALL);\n\tif (hw_info->gptp || hw_info->ccc_gac)\n\t\tinfo->phc_index = ptp_clock_index(priv->ptp.clock);\n\n\treturn 0;\n}\n\nstatic void ravb_get_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\twol->supported = WAKE_MAGIC;\n\twol->wolopts = priv->wol_enabled ? WAKE_MAGIC : 0;\n}\n\nstatic int ravb_set_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\tif (!info->magic_pkt || (wol->wolopts & ~WAKE_MAGIC))\n\t\treturn -EOPNOTSUPP;\n\n\tpriv->wol_enabled = !!(wol->wolopts & WAKE_MAGIC);\n\n\tdevice_set_wakeup_enable(&priv->pdev->dev, priv->wol_enabled);\n\n\treturn 0;\n}\n\nstatic const struct ethtool_ops ravb_ethtool_ops = {\n\t.nway_reset\t\t= phy_ethtool_nway_reset,\n\t.get_msglevel\t\t= ravb_get_msglevel,\n\t.set_msglevel\t\t= ravb_set_msglevel,\n\t.get_link\t\t= ethtool_op_get_link,\n\t.get_strings\t\t= ravb_get_strings,\n\t.get_ethtool_stats\t= ravb_get_ethtool_stats,\n\t.get_sset_count\t\t= ravb_get_sset_count,\n\t.get_ringparam\t\t= ravb_get_ringparam,\n\t.set_ringparam\t\t= ravb_set_ringparam,\n\t.get_ts_info\t\t= ravb_get_ts_info,\n\t.get_link_ksettings\t= phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings\t= phy_ethtool_set_link_ksettings,\n\t.get_wol\t\t= ravb_get_wol,\n\t.set_wol\t\t= ravb_set_wol,\n};\n\nstatic inline int ravb_hook_irq(unsigned int irq, irq_handler_t handler,\n\t\t\t\tstruct net_device *ndev, struct device *dev,\n\t\t\t\tconst char *ch)\n{\n\tchar *name;\n\tint error;\n\n\tname = devm_kasprintf(dev, GFP_KERNEL, \"%s:%s\", ndev->name, ch);\n\tif (!name)\n\t\treturn -ENOMEM;\n\terror = request_irq(irq, handler, 0, name, ndev);\n\tif (error)\n\t\tnetdev_err(ndev, \"cannot request IRQ %s\\n\", name);\n\n\treturn error;\n}\n\n \nstatic int ravb_open(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct platform_device *pdev = priv->pdev;\n\tstruct device *dev = &pdev->dev;\n\tint error;\n\n\tnapi_enable(&priv->napi[RAVB_BE]);\n\tif (info->nc_queues)\n\t\tnapi_enable(&priv->napi[RAVB_NC]);\n\n\tif (!info->multi_irqs) {\n\t\terror = request_irq(ndev->irq, ravb_interrupt, IRQF_SHARED,\n\t\t\t\t    ndev->name, ndev);\n\t\tif (error) {\n\t\t\tnetdev_err(ndev, \"cannot request IRQ\\n\");\n\t\t\tgoto out_napi_off;\n\t\t}\n\t} else {\n\t\terror = ravb_hook_irq(ndev->irq, ravb_multi_interrupt, ndev,\n\t\t\t\t      dev, \"ch22:multi\");\n\t\tif (error)\n\t\t\tgoto out_napi_off;\n\t\terror = ravb_hook_irq(priv->emac_irq, ravb_emac_interrupt, ndev,\n\t\t\t\t      dev, \"ch24:emac\");\n\t\tif (error)\n\t\t\tgoto out_free_irq;\n\t\terror = ravb_hook_irq(priv->rx_irqs[RAVB_BE], ravb_be_interrupt,\n\t\t\t\t      ndev, dev, \"ch0:rx_be\");\n\t\tif (error)\n\t\t\tgoto out_free_irq_emac;\n\t\terror = ravb_hook_irq(priv->tx_irqs[RAVB_BE], ravb_be_interrupt,\n\t\t\t\t      ndev, dev, \"ch18:tx_be\");\n\t\tif (error)\n\t\t\tgoto out_free_irq_be_rx;\n\t\terror = ravb_hook_irq(priv->rx_irqs[RAVB_NC], ravb_nc_interrupt,\n\t\t\t\t      ndev, dev, \"ch1:rx_nc\");\n\t\tif (error)\n\t\t\tgoto out_free_irq_be_tx;\n\t\terror = ravb_hook_irq(priv->tx_irqs[RAVB_NC], ravb_nc_interrupt,\n\t\t\t\t      ndev, dev, \"ch19:tx_nc\");\n\t\tif (error)\n\t\t\tgoto out_free_irq_nc_rx;\n\n\t\tif (info->err_mgmt_irqs) {\n\t\t\terror = ravb_hook_irq(priv->erra_irq, ravb_multi_interrupt,\n\t\t\t\t\t      ndev, dev, \"err_a\");\n\t\t\tif (error)\n\t\t\t\tgoto out_free_irq_nc_tx;\n\t\t\terror = ravb_hook_irq(priv->mgmta_irq, ravb_multi_interrupt,\n\t\t\t\t\t      ndev, dev, \"mgmt_a\");\n\t\t\tif (error)\n\t\t\t\tgoto out_free_irq_erra;\n\t\t}\n\t}\n\n\t \n\terror = ravb_dmac_init(ndev);\n\tif (error)\n\t\tgoto out_free_irq_mgmta;\n\travb_emac_init(ndev);\n\n\t \n\tif (info->gptp)\n\t\travb_ptp_init(ndev, priv->pdev);\n\n\t \n\terror = ravb_phy_start(ndev);\n\tif (error)\n\t\tgoto out_ptp_stop;\n\n\tnetif_tx_start_all_queues(ndev);\n\n\treturn 0;\n\nout_ptp_stop:\n\t \n\tif (info->gptp)\n\t\travb_ptp_stop(ndev);\n\travb_stop_dma(ndev);\nout_free_irq_mgmta:\n\tif (!info->multi_irqs)\n\t\tgoto out_free_irq;\n\tif (info->err_mgmt_irqs)\n\t\tfree_irq(priv->mgmta_irq, ndev);\nout_free_irq_erra:\n\tif (info->err_mgmt_irqs)\n\t\tfree_irq(priv->erra_irq, ndev);\nout_free_irq_nc_tx:\n\tfree_irq(priv->tx_irqs[RAVB_NC], ndev);\nout_free_irq_nc_rx:\n\tfree_irq(priv->rx_irqs[RAVB_NC], ndev);\nout_free_irq_be_tx:\n\tfree_irq(priv->tx_irqs[RAVB_BE], ndev);\nout_free_irq_be_rx:\n\tfree_irq(priv->rx_irqs[RAVB_BE], ndev);\nout_free_irq_emac:\n\tfree_irq(priv->emac_irq, ndev);\nout_free_irq:\n\tfree_irq(ndev->irq, ndev);\nout_napi_off:\n\tif (info->nc_queues)\n\t\tnapi_disable(&priv->napi[RAVB_NC]);\n\tnapi_disable(&priv->napi[RAVB_BE]);\n\treturn error;\n}\n\n \nstatic void ravb_tx_timeout(struct net_device *ndev, unsigned int txqueue)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tnetif_err(priv, tx_err, ndev,\n\t\t  \"transmit timed out, status %08x, resetting...\\n\",\n\t\t  ravb_read(ndev, ISS));\n\n\t \n\tndev->stats.tx_errors++;\n\n\tschedule_work(&priv->work);\n}\n\nstatic void ravb_tx_timeout_work(struct work_struct *work)\n{\n\tstruct ravb_private *priv = container_of(work, struct ravb_private,\n\t\t\t\t\t\t work);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct net_device *ndev = priv->ndev;\n\tint error;\n\n\tif (!rtnl_trylock()) {\n\t\tusleep_range(1000, 2000);\n\t\tschedule_work(&priv->work);\n\t\treturn;\n\t}\n\n\tnetif_tx_stop_all_queues(ndev);\n\n\t \n\tif (info->gptp)\n\t\travb_ptp_stop(ndev);\n\n\t \n\tif (ravb_stop_dma(ndev)) {\n\t\t \n\t\travb_rcv_snd_enable(ndev);\n\t\tgoto out;\n\t}\n\n\travb_ring_free(ndev, RAVB_BE);\n\tif (info->nc_queues)\n\t\travb_ring_free(ndev, RAVB_NC);\n\n\t \n\terror = ravb_dmac_init(ndev);\n\tif (error) {\n\t\t \n\t\tnetdev_err(ndev, \"%s: ravb_dmac_init() failed, error %d\\n\",\n\t\t\t   __func__, error);\n\t\tgoto out_unlock;\n\t}\n\travb_emac_init(ndev);\n\nout:\n\t \n\tif (info->gptp)\n\t\travb_ptp_init(ndev, priv->pdev);\n\n\tnetif_tx_start_all_queues(ndev);\n\nout_unlock:\n\trtnl_unlock();\n}\n\n \nstatic netdev_tx_t ravb_start_xmit(struct sk_buff *skb, struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tunsigned int num_tx_desc = priv->num_tx_desc;\n\tu16 q = skb_get_queue_mapping(skb);\n\tstruct ravb_tstamp_skb *ts_skb;\n\tstruct ravb_tx_desc *desc;\n\tunsigned long flags;\n\tdma_addr_t dma_addr;\n\tvoid *buffer;\n\tu32 entry;\n\tu32 len;\n\n\tspin_lock_irqsave(&priv->lock, flags);\n\tif (priv->cur_tx[q] - priv->dirty_tx[q] > (priv->num_tx_ring[q] - 1) *\n\t    num_tx_desc) {\n\t\tnetif_err(priv, tx_queued, ndev,\n\t\t\t  \"still transmitting with the full ring!\\n\");\n\t\tnetif_stop_subqueue(ndev, q);\n\t\tspin_unlock_irqrestore(&priv->lock, flags);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tif (skb_put_padto(skb, ETH_ZLEN))\n\t\tgoto exit;\n\n\tentry = priv->cur_tx[q] % (priv->num_tx_ring[q] * num_tx_desc);\n\tpriv->tx_skb[q][entry / num_tx_desc] = skb;\n\n\tif (num_tx_desc > 1) {\n\t\tbuffer = PTR_ALIGN(priv->tx_align[q], DPTR_ALIGN) +\n\t\t\t entry / num_tx_desc * DPTR_ALIGN;\n\t\tlen = PTR_ALIGN(skb->data, DPTR_ALIGN) - skb->data;\n\n\t\t \n\t\tif (len == 0)\n\t\t\tlen = DPTR_ALIGN;\n\n\t\tmemcpy(buffer, skb->data, len);\n\t\tdma_addr = dma_map_single(ndev->dev.parent, buffer, len,\n\t\t\t\t\t  DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ndev->dev.parent, dma_addr))\n\t\t\tgoto drop;\n\n\t\tdesc = &priv->tx_ring[q][entry];\n\t\tdesc->ds_tagl = cpu_to_le16(len);\n\t\tdesc->dptr = cpu_to_le32(dma_addr);\n\n\t\tbuffer = skb->data + len;\n\t\tlen = skb->len - len;\n\t\tdma_addr = dma_map_single(ndev->dev.parent, buffer, len,\n\t\t\t\t\t  DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ndev->dev.parent, dma_addr))\n\t\t\tgoto unmap;\n\n\t\tdesc++;\n\t} else {\n\t\tdesc = &priv->tx_ring[q][entry];\n\t\tlen = skb->len;\n\t\tdma_addr = dma_map_single(ndev->dev.parent, skb->data, skb->len,\n\t\t\t\t\t  DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ndev->dev.parent, dma_addr))\n\t\t\tgoto drop;\n\t}\n\tdesc->ds_tagl = cpu_to_le16(len);\n\tdesc->dptr = cpu_to_le32(dma_addr);\n\n\t \n\tif (info->gptp || info->ccc_gac) {\n\t\tif (q == RAVB_NC) {\n\t\t\tts_skb = kmalloc(sizeof(*ts_skb), GFP_ATOMIC);\n\t\t\tif (!ts_skb) {\n\t\t\t\tif (num_tx_desc > 1) {\n\t\t\t\t\tdesc--;\n\t\t\t\t\tdma_unmap_single(ndev->dev.parent, dma_addr,\n\t\t\t\t\t\t\t len, DMA_TO_DEVICE);\n\t\t\t\t}\n\t\t\t\tgoto unmap;\n\t\t\t}\n\t\t\tts_skb->skb = skb_get(skb);\n\t\t\tts_skb->tag = priv->ts_skb_tag++;\n\t\t\tpriv->ts_skb_tag &= 0x3ff;\n\t\t\tlist_add_tail(&ts_skb->list, &priv->ts_skb_list);\n\n\t\t\t \n\t\t\tskb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;\n\t\t\tdesc->tagh_tsr = (ts_skb->tag >> 4) | TX_TSR;\n\t\t\tdesc->ds_tagl |= cpu_to_le16(ts_skb->tag << 12);\n\t\t}\n\n\t\tskb_tx_timestamp(skb);\n\t}\n\t \n\tdma_wmb();\n\tif (num_tx_desc > 1) {\n\t\tdesc->die_dt = DT_FEND;\n\t\tdesc--;\n\t\tdesc->die_dt = DT_FSTART;\n\t} else {\n\t\tdesc->die_dt = DT_FSINGLE;\n\t}\n\travb_modify(ndev, TCCR, TCCR_TSRQ0 << q, TCCR_TSRQ0 << q);\n\n\tpriv->cur_tx[q] += num_tx_desc;\n\tif (priv->cur_tx[q] - priv->dirty_tx[q] >\n\t    (priv->num_tx_ring[q] - 1) * num_tx_desc &&\n\t    !ravb_tx_free(ndev, q, true))\n\t\tnetif_stop_subqueue(ndev, q);\n\nexit:\n\tspin_unlock_irqrestore(&priv->lock, flags);\n\treturn NETDEV_TX_OK;\n\nunmap:\n\tdma_unmap_single(ndev->dev.parent, le32_to_cpu(desc->dptr),\n\t\t\t le16_to_cpu(desc->ds_tagl), DMA_TO_DEVICE);\ndrop:\n\tdev_kfree_skb_any(skb);\n\tpriv->tx_skb[q][entry / num_tx_desc] = NULL;\n\tgoto exit;\n}\n\nstatic u16 ravb_select_queue(struct net_device *ndev, struct sk_buff *skb,\n\t\t\t     struct net_device *sb_dev)\n{\n\t \n\treturn (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP) ? RAVB_NC :\n\t\t\t\t\t\t\t       RAVB_BE;\n\n}\n\nstatic struct net_device_stats *ravb_get_stats(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct net_device_stats *nstats, *stats0, *stats1;\n\n\tnstats = &ndev->stats;\n\tstats0 = &priv->stats[RAVB_BE];\n\n\tif (info->tx_counters) {\n\t\tnstats->tx_dropped += ravb_read(ndev, TROCR);\n\t\travb_write(ndev, 0, TROCR);\t \n\t}\n\n\tif (info->carrier_counters) {\n\t\tnstats->collisions += ravb_read(ndev, CXR41);\n\t\travb_write(ndev, 0, CXR41);\t \n\t\tnstats->tx_carrier_errors += ravb_read(ndev, CXR42);\n\t\travb_write(ndev, 0, CXR42);\t \n\t}\n\n\tnstats->rx_packets = stats0->rx_packets;\n\tnstats->tx_packets = stats0->tx_packets;\n\tnstats->rx_bytes = stats0->rx_bytes;\n\tnstats->tx_bytes = stats0->tx_bytes;\n\tnstats->multicast = stats0->multicast;\n\tnstats->rx_errors = stats0->rx_errors;\n\tnstats->rx_crc_errors = stats0->rx_crc_errors;\n\tnstats->rx_frame_errors = stats0->rx_frame_errors;\n\tnstats->rx_length_errors = stats0->rx_length_errors;\n\tnstats->rx_missed_errors = stats0->rx_missed_errors;\n\tnstats->rx_over_errors = stats0->rx_over_errors;\n\tif (info->nc_queues) {\n\t\tstats1 = &priv->stats[RAVB_NC];\n\n\t\tnstats->rx_packets += stats1->rx_packets;\n\t\tnstats->tx_packets += stats1->tx_packets;\n\t\tnstats->rx_bytes += stats1->rx_bytes;\n\t\tnstats->tx_bytes += stats1->tx_bytes;\n\t\tnstats->multicast += stats1->multicast;\n\t\tnstats->rx_errors += stats1->rx_errors;\n\t\tnstats->rx_crc_errors += stats1->rx_crc_errors;\n\t\tnstats->rx_frame_errors += stats1->rx_frame_errors;\n\t\tnstats->rx_length_errors += stats1->rx_length_errors;\n\t\tnstats->rx_missed_errors += stats1->rx_missed_errors;\n\t\tnstats->rx_over_errors += stats1->rx_over_errors;\n\t}\n\n\treturn nstats;\n}\n\n \nstatic void ravb_set_rx_mode(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&priv->lock, flags);\n\travb_modify(ndev, ECMR, ECMR_PRM,\n\t\t    ndev->flags & IFF_PROMISC ? ECMR_PRM : 0);\n\tspin_unlock_irqrestore(&priv->lock, flags);\n}\n\n \nstatic int ravb_close(struct net_device *ndev)\n{\n\tstruct device_node *np = ndev->dev.parent->of_node;\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct ravb_tstamp_skb *ts_skb, *ts_skb2;\n\n\tnetif_tx_stop_all_queues(ndev);\n\n\t \n\travb_write(ndev, 0, RIC0);\n\travb_write(ndev, 0, RIC2);\n\travb_write(ndev, 0, TIC);\n\n\t \n\tif (info->gptp)\n\t\travb_ptp_stop(ndev);\n\n\t \n\tif (ravb_stop_dma(ndev) < 0)\n\t\tnetdev_err(ndev,\n\t\t\t   \"device will be stopped after h/w processes are done.\\n\");\n\n\t \n\tif (info->gptp || info->ccc_gac) {\n\t\tlist_for_each_entry_safe(ts_skb, ts_skb2, &priv->ts_skb_list, list) {\n\t\t\tlist_del(&ts_skb->list);\n\t\t\tkfree_skb(ts_skb->skb);\n\t\t\tkfree(ts_skb);\n\t\t}\n\t}\n\n\t \n\tif (ndev->phydev) {\n\t\tphy_stop(ndev->phydev);\n\t\tphy_disconnect(ndev->phydev);\n\t\tif (of_phy_is_fixed_link(np))\n\t\t\tof_phy_deregister_fixed_link(np);\n\t}\n\n\tcancel_work_sync(&priv->work);\n\n\tif (info->multi_irqs) {\n\t\tfree_irq(priv->tx_irqs[RAVB_NC], ndev);\n\t\tfree_irq(priv->rx_irqs[RAVB_NC], ndev);\n\t\tfree_irq(priv->tx_irqs[RAVB_BE], ndev);\n\t\tfree_irq(priv->rx_irqs[RAVB_BE], ndev);\n\t\tfree_irq(priv->emac_irq, ndev);\n\t\tif (info->err_mgmt_irqs) {\n\t\t\tfree_irq(priv->erra_irq, ndev);\n\t\t\tfree_irq(priv->mgmta_irq, ndev);\n\t\t}\n\t}\n\tfree_irq(ndev->irq, ndev);\n\n\tif (info->nc_queues)\n\t\tnapi_disable(&priv->napi[RAVB_NC]);\n\tnapi_disable(&priv->napi[RAVB_BE]);\n\n\t \n\travb_ring_free(ndev, RAVB_BE);\n\tif (info->nc_queues)\n\t\travb_ring_free(ndev, RAVB_NC);\n\n\treturn 0;\n}\n\nstatic int ravb_hwtstamp_get(struct net_device *ndev, struct ifreq *req)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tstruct hwtstamp_config config;\n\n\tconfig.flags = 0;\n\tconfig.tx_type = priv->tstamp_tx_ctrl ? HWTSTAMP_TX_ON :\n\t\t\t\t\t\tHWTSTAMP_TX_OFF;\n\tswitch (priv->tstamp_rx_ctrl & RAVB_RXTSTAMP_TYPE) {\n\tcase RAVB_RXTSTAMP_TYPE_V2_L2_EVENT:\n\t\tconfig.rx_filter = HWTSTAMP_FILTER_PTP_V2_L2_EVENT;\n\t\tbreak;\n\tcase RAVB_RXTSTAMP_TYPE_ALL:\n\t\tconfig.rx_filter = HWTSTAMP_FILTER_ALL;\n\t\tbreak;\n\tdefault:\n\t\tconfig.rx_filter = HWTSTAMP_FILTER_NONE;\n\t}\n\n\treturn copy_to_user(req->ifr_data, &config, sizeof(config)) ?\n\t\t-EFAULT : 0;\n}\n\n \nstatic int ravb_hwtstamp_set(struct net_device *ndev, struct ifreq *req)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tstruct hwtstamp_config config;\n\tu32 tstamp_rx_ctrl = RAVB_RXTSTAMP_ENABLED;\n\tu32 tstamp_tx_ctrl;\n\n\tif (copy_from_user(&config, req->ifr_data, sizeof(config)))\n\t\treturn -EFAULT;\n\n\tswitch (config.tx_type) {\n\tcase HWTSTAMP_TX_OFF:\n\t\ttstamp_tx_ctrl = 0;\n\t\tbreak;\n\tcase HWTSTAMP_TX_ON:\n\t\ttstamp_tx_ctrl = RAVB_TXTSTAMP_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\treturn -ERANGE;\n\t}\n\n\tswitch (config.rx_filter) {\n\tcase HWTSTAMP_FILTER_NONE:\n\t\ttstamp_rx_ctrl = 0;\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_EVENT:\n\t\ttstamp_rx_ctrl |= RAVB_RXTSTAMP_TYPE_V2_L2_EVENT;\n\t\tbreak;\n\tdefault:\n\t\tconfig.rx_filter = HWTSTAMP_FILTER_ALL;\n\t\ttstamp_rx_ctrl |= RAVB_RXTSTAMP_TYPE_ALL;\n\t}\n\n\tpriv->tstamp_tx_ctrl = tstamp_tx_ctrl;\n\tpriv->tstamp_rx_ctrl = tstamp_rx_ctrl;\n\n\treturn copy_to_user(req->ifr_data, &config, sizeof(config)) ?\n\t\t-EFAULT : 0;\n}\n\n \nstatic int ravb_do_ioctl(struct net_device *ndev, struct ifreq *req, int cmd)\n{\n\tstruct phy_device *phydev = ndev->phydev;\n\n\tif (!netif_running(ndev))\n\t\treturn -EINVAL;\n\n\tif (!phydev)\n\t\treturn -ENODEV;\n\n\tswitch (cmd) {\n\tcase SIOCGHWTSTAMP:\n\t\treturn ravb_hwtstamp_get(ndev, req);\n\tcase SIOCSHWTSTAMP:\n\t\treturn ravb_hwtstamp_set(ndev, req);\n\t}\n\n\treturn phy_mii_ioctl(phydev, req, cmd);\n}\n\nstatic int ravb_change_mtu(struct net_device *ndev, int new_mtu)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\n\tndev->mtu = new_mtu;\n\n\tif (netif_running(ndev)) {\n\t\tsynchronize_irq(priv->emac_irq);\n\t\travb_emac_init(ndev);\n\t}\n\n\tnetdev_update_features(ndev);\n\n\treturn 0;\n}\n\nstatic void ravb_set_rx_csum(struct net_device *ndev, bool enable)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&priv->lock, flags);\n\n\t \n\travb_rcv_snd_disable(ndev);\n\n\t \n\travb_modify(ndev, ECMR, ECMR_RCSC, enable ? ECMR_RCSC : 0);\n\n\t \n\travb_rcv_snd_enable(ndev);\n\n\tspin_unlock_irqrestore(&priv->lock, flags);\n}\n\nstatic int ravb_set_features_gbeth(struct net_device *ndev,\n\t\t\t\t   netdev_features_t features)\n{\n\t \n\treturn 0;\n}\n\nstatic int ravb_set_features_rcar(struct net_device *ndev,\n\t\t\t\t  netdev_features_t features)\n{\n\tnetdev_features_t changed = ndev->features ^ features;\n\n\tif (changed & NETIF_F_RXCSUM)\n\t\travb_set_rx_csum(ndev, features & NETIF_F_RXCSUM);\n\n\tndev->features = features;\n\n\treturn 0;\n}\n\nstatic int ravb_set_features(struct net_device *ndev,\n\t\t\t     netdev_features_t features)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\treturn info->set_feature(ndev, features);\n}\n\nstatic const struct net_device_ops ravb_netdev_ops = {\n\t.ndo_open\t\t= ravb_open,\n\t.ndo_stop\t\t= ravb_close,\n\t.ndo_start_xmit\t\t= ravb_start_xmit,\n\t.ndo_select_queue\t= ravb_select_queue,\n\t.ndo_get_stats\t\t= ravb_get_stats,\n\t.ndo_set_rx_mode\t= ravb_set_rx_mode,\n\t.ndo_tx_timeout\t\t= ravb_tx_timeout,\n\t.ndo_eth_ioctl\t\t= ravb_do_ioctl,\n\t.ndo_change_mtu\t\t= ravb_change_mtu,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n\t.ndo_set_features\t= ravb_set_features,\n};\n\n \nstatic int ravb_mdio_init(struct ravb_private *priv)\n{\n\tstruct platform_device *pdev = priv->pdev;\n\tstruct device *dev = &pdev->dev;\n\tstruct phy_device *phydev;\n\tstruct device_node *pn;\n\tint error;\n\n\t \n\tpriv->mdiobb.ops = &bb_ops;\n\n\t \n\tpriv->mii_bus = alloc_mdio_bitbang(&priv->mdiobb);\n\tif (!priv->mii_bus)\n\t\treturn -ENOMEM;\n\n\t \n\tpriv->mii_bus->name = \"ravb_mii\";\n\tpriv->mii_bus->parent = dev;\n\tsnprintf(priv->mii_bus->id, MII_BUS_ID_SIZE, \"%s-%x\",\n\t\t pdev->name, pdev->id);\n\n\t \n\terror = of_mdiobus_register(priv->mii_bus, dev->of_node);\n\tif (error)\n\t\tgoto out_free_bus;\n\n\tpn = of_parse_phandle(dev->of_node, \"phy-handle\", 0);\n\tphydev = of_phy_find_device(pn);\n\tif (phydev) {\n\t\tphydev->mac_managed_pm = true;\n\t\tput_device(&phydev->mdio.dev);\n\t}\n\tof_node_put(pn);\n\n\treturn 0;\n\nout_free_bus:\n\tfree_mdio_bitbang(priv->mii_bus);\n\treturn error;\n}\n\n \nstatic int ravb_mdio_release(struct ravb_private *priv)\n{\n\t \n\tmdiobus_unregister(priv->mii_bus);\n\n\t \n\tfree_mdio_bitbang(priv->mii_bus);\n\n\treturn 0;\n}\n\nstatic const struct ravb_hw_info ravb_gen3_hw_info = {\n\t.rx_ring_free = ravb_rx_ring_free_rcar,\n\t.rx_ring_format = ravb_rx_ring_format_rcar,\n\t.alloc_rx_desc = ravb_alloc_rx_desc_rcar,\n\t.receive = ravb_rx_rcar,\n\t.set_rate = ravb_set_rate_rcar,\n\t.set_feature = ravb_set_features_rcar,\n\t.dmac_init = ravb_dmac_init_rcar,\n\t.emac_init = ravb_emac_init_rcar,\n\t.gstrings_stats = ravb_gstrings_stats,\n\t.gstrings_size = sizeof(ravb_gstrings_stats),\n\t.net_hw_features = NETIF_F_RXCSUM,\n\t.net_features = NETIF_F_RXCSUM,\n\t.stats_len = ARRAY_SIZE(ravb_gstrings_stats),\n\t.max_rx_len = RX_BUF_SZ + RAVB_ALIGN - 1,\n\t.tccr_mask = TCCR_TSRQ0 | TCCR_TSRQ1 | TCCR_TSRQ2 | TCCR_TSRQ3,\n\t.rx_max_buf_size = SZ_2K,\n\t.internal_delay = 1,\n\t.tx_counters = 1,\n\t.multi_irqs = 1,\n\t.irq_en_dis = 1,\n\t.ccc_gac = 1,\n\t.nc_queues = 1,\n\t.magic_pkt = 1,\n};\n\nstatic const struct ravb_hw_info ravb_gen2_hw_info = {\n\t.rx_ring_free = ravb_rx_ring_free_rcar,\n\t.rx_ring_format = ravb_rx_ring_format_rcar,\n\t.alloc_rx_desc = ravb_alloc_rx_desc_rcar,\n\t.receive = ravb_rx_rcar,\n\t.set_rate = ravb_set_rate_rcar,\n\t.set_feature = ravb_set_features_rcar,\n\t.dmac_init = ravb_dmac_init_rcar,\n\t.emac_init = ravb_emac_init_rcar,\n\t.gstrings_stats = ravb_gstrings_stats,\n\t.gstrings_size = sizeof(ravb_gstrings_stats),\n\t.net_hw_features = NETIF_F_RXCSUM,\n\t.net_features = NETIF_F_RXCSUM,\n\t.stats_len = ARRAY_SIZE(ravb_gstrings_stats),\n\t.max_rx_len = RX_BUF_SZ + RAVB_ALIGN - 1,\n\t.tccr_mask = TCCR_TSRQ0 | TCCR_TSRQ1 | TCCR_TSRQ2 | TCCR_TSRQ3,\n\t.rx_max_buf_size = SZ_2K,\n\t.aligned_tx = 1,\n\t.gptp = 1,\n\t.nc_queues = 1,\n\t.magic_pkt = 1,\n};\n\nstatic const struct ravb_hw_info ravb_rzv2m_hw_info = {\n\t.rx_ring_free = ravb_rx_ring_free_rcar,\n\t.rx_ring_format = ravb_rx_ring_format_rcar,\n\t.alloc_rx_desc = ravb_alloc_rx_desc_rcar,\n\t.receive = ravb_rx_rcar,\n\t.set_rate = ravb_set_rate_rcar,\n\t.set_feature = ravb_set_features_rcar,\n\t.dmac_init = ravb_dmac_init_rcar,\n\t.emac_init = ravb_emac_init_rcar,\n\t.gstrings_stats = ravb_gstrings_stats,\n\t.gstrings_size = sizeof(ravb_gstrings_stats),\n\t.net_hw_features = NETIF_F_RXCSUM,\n\t.net_features = NETIF_F_RXCSUM,\n\t.stats_len = ARRAY_SIZE(ravb_gstrings_stats),\n\t.max_rx_len = RX_BUF_SZ + RAVB_ALIGN - 1,\n\t.tccr_mask = TCCR_TSRQ0 | TCCR_TSRQ1 | TCCR_TSRQ2 | TCCR_TSRQ3,\n\t.rx_max_buf_size = SZ_2K,\n\t.multi_irqs = 1,\n\t.err_mgmt_irqs = 1,\n\t.gptp = 1,\n\t.gptp_ref_clk = 1,\n\t.nc_queues = 1,\n\t.magic_pkt = 1,\n};\n\nstatic const struct ravb_hw_info gbeth_hw_info = {\n\t.rx_ring_free = ravb_rx_ring_free_gbeth,\n\t.rx_ring_format = ravb_rx_ring_format_gbeth,\n\t.alloc_rx_desc = ravb_alloc_rx_desc_gbeth,\n\t.receive = ravb_rx_gbeth,\n\t.set_rate = ravb_set_rate_gbeth,\n\t.set_feature = ravb_set_features_gbeth,\n\t.dmac_init = ravb_dmac_init_gbeth,\n\t.emac_init = ravb_emac_init_gbeth,\n\t.gstrings_stats = ravb_gstrings_stats_gbeth,\n\t.gstrings_size = sizeof(ravb_gstrings_stats_gbeth),\n\t.stats_len = ARRAY_SIZE(ravb_gstrings_stats_gbeth),\n\t.max_rx_len = ALIGN(GBETH_RX_BUFF_MAX, RAVB_ALIGN),\n\t.tccr_mask = TCCR_TSRQ0,\n\t.rx_max_buf_size = SZ_8K,\n\t.aligned_tx = 1,\n\t.tx_counters = 1,\n\t.carrier_counters = 1,\n\t.half_duplex = 1,\n};\n\nstatic const struct of_device_id ravb_match_table[] = {\n\t{ .compatible = \"renesas,etheravb-r8a7790\", .data = &ravb_gen2_hw_info },\n\t{ .compatible = \"renesas,etheravb-r8a7794\", .data = &ravb_gen2_hw_info },\n\t{ .compatible = \"renesas,etheravb-rcar-gen2\", .data = &ravb_gen2_hw_info },\n\t{ .compatible = \"renesas,etheravb-r8a7795\", .data = &ravb_gen3_hw_info },\n\t{ .compatible = \"renesas,etheravb-rcar-gen3\", .data = &ravb_gen3_hw_info },\n\t{ .compatible = \"renesas,etheravb-rcar-gen4\", .data = &ravb_gen3_hw_info },\n\t{ .compatible = \"renesas,etheravb-rzv2m\", .data = &ravb_rzv2m_hw_info },\n\t{ .compatible = \"renesas,rzg2l-gbeth\", .data = &gbeth_hw_info },\n\t{ }\n};\nMODULE_DEVICE_TABLE(of, ravb_match_table);\n\nstatic int ravb_set_gti(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tstruct device *dev = ndev->dev.parent;\n\tunsigned long rate;\n\tuint64_t inc;\n\n\tif (info->gptp_ref_clk)\n\t\trate = clk_get_rate(priv->gptp_clk);\n\telse\n\t\trate = clk_get_rate(priv->clk);\n\tif (!rate)\n\t\treturn -EINVAL;\n\n\tinc = div64_ul(1000000000ULL << 20, rate);\n\n\tif (inc < GTI_TIV_MIN || inc > GTI_TIV_MAX) {\n\t\tdev_err(dev, \"gti.tiv increment 0x%llx is outside the range 0x%x - 0x%x\\n\",\n\t\t\tinc, GTI_TIV_MIN, GTI_TIV_MAX);\n\t\treturn -EINVAL;\n\t}\n\n\travb_write(ndev, inc, GTI);\n\n\treturn 0;\n}\n\nstatic int ravb_set_config_mode(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint error;\n\n\tif (info->gptp) {\n\t\terror = ravb_set_opmode(ndev, CCC_OPC_CONFIG);\n\t\tif (error)\n\t\t\treturn error;\n\t\t \n\t\travb_modify(ndev, CCC, CCC_CSEL, CCC_CSEL_HPB);\n\t} else if (info->ccc_gac) {\n\t\terror = ravb_set_opmode(ndev, CCC_OPC_CONFIG | CCC_GAC | CCC_CSEL_HPB);\n\t} else {\n\t\terror = ravb_set_opmode(ndev, CCC_OPC_CONFIG);\n\t}\n\n\treturn error;\n}\n\n \nstatic void ravb_parse_delay_mode(struct device_node *np, struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tbool explicit_delay = false;\n\tu32 delay;\n\n\tif (!of_property_read_u32(np, \"rx-internal-delay-ps\", &delay)) {\n\t\t \n\t\tpriv->rxcidm = !!delay;\n\t\texplicit_delay = true;\n\t}\n\tif (!of_property_read_u32(np, \"tx-internal-delay-ps\", &delay)) {\n\t\t \n\t\tpriv->txcidm = !!delay;\n\t\texplicit_delay = true;\n\t}\n\n\tif (explicit_delay)\n\t\treturn;\n\n\t \n\tif (priv->phy_interface == PHY_INTERFACE_MODE_RGMII_ID ||\n\t    priv->phy_interface == PHY_INTERFACE_MODE_RGMII_RXID) {\n\t\tpriv->rxcidm = 1;\n\t\tpriv->rgmii_override = 1;\n\t}\n\n\tif (priv->phy_interface == PHY_INTERFACE_MODE_RGMII_ID ||\n\t    priv->phy_interface == PHY_INTERFACE_MODE_RGMII_TXID) {\n\t\tpriv->txcidm = 1;\n\t\tpriv->rgmii_override = 1;\n\t}\n}\n\nstatic void ravb_set_delay_mode(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tu32 set = 0;\n\n\tif (priv->rxcidm)\n\t\tset |= APSR_RDM;\n\tif (priv->txcidm)\n\t\tset |= APSR_TDM;\n\travb_modify(ndev, APSR, APSR_RDM | APSR_TDM, set);\n}\n\nstatic int ravb_probe(struct platform_device *pdev)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tconst struct ravb_hw_info *info;\n\tstruct reset_control *rstc;\n\tstruct ravb_private *priv;\n\tstruct net_device *ndev;\n\tint error, irq, q;\n\tstruct resource *res;\n\tint i;\n\n\tif (!np) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"this driver is required to be instantiated from device tree\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\trstc = devm_reset_control_get_optional_exclusive(&pdev->dev, NULL);\n\tif (IS_ERR(rstc))\n\t\treturn dev_err_probe(&pdev->dev, PTR_ERR(rstc),\n\t\t\t\t     \"failed to get cpg reset\\n\");\n\n\tndev = alloc_etherdev_mqs(sizeof(struct ravb_private),\n\t\t\t\t  NUM_TX_QUEUE, NUM_RX_QUEUE);\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tinfo = of_device_get_match_data(&pdev->dev);\n\n\tndev->features = info->net_features;\n\tndev->hw_features = info->net_hw_features;\n\n\terror = reset_control_deassert(rstc);\n\tif (error)\n\t\tgoto out_free_netdev;\n\n\tpm_runtime_enable(&pdev->dev);\n\terror = pm_runtime_resume_and_get(&pdev->dev);\n\tif (error < 0)\n\t\tgoto out_rpm_disable;\n\n\tif (info->multi_irqs) {\n\t\tif (info->err_mgmt_irqs)\n\t\t\tirq = platform_get_irq_byname(pdev, \"dia\");\n\t\telse\n\t\t\tirq = platform_get_irq_byname(pdev, \"ch22\");\n\t} else {\n\t\tirq = platform_get_irq(pdev, 0);\n\t}\n\tif (irq < 0) {\n\t\terror = irq;\n\t\tgoto out_release;\n\t}\n\tndev->irq = irq;\n\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\n\tpriv = netdev_priv(ndev);\n\tpriv->info = info;\n\tpriv->rstc = rstc;\n\tpriv->ndev = ndev;\n\tpriv->pdev = pdev;\n\tpriv->num_tx_ring[RAVB_BE] = BE_TX_RING_SIZE;\n\tpriv->num_rx_ring[RAVB_BE] = BE_RX_RING_SIZE;\n\tif (info->nc_queues) {\n\t\tpriv->num_tx_ring[RAVB_NC] = NC_TX_RING_SIZE;\n\t\tpriv->num_rx_ring[RAVB_NC] = NC_RX_RING_SIZE;\n\t}\n\n\tpriv->addr = devm_platform_get_and_ioremap_resource(pdev, 0, &res);\n\tif (IS_ERR(priv->addr)) {\n\t\terror = PTR_ERR(priv->addr);\n\t\tgoto out_release;\n\t}\n\n\t \n\tndev->base_addr = res->start;\n\n\tspin_lock_init(&priv->lock);\n\tINIT_WORK(&priv->work, ravb_tx_timeout_work);\n\n\terror = of_get_phy_mode(np, &priv->phy_interface);\n\tif (error && error != -ENODEV)\n\t\tgoto out_release;\n\n\tpriv->no_avb_link = of_property_read_bool(np, \"renesas,no-ether-link\");\n\tpriv->avb_link_active_low =\n\t\tof_property_read_bool(np, \"renesas,ether-link-active-low\");\n\n\tif (info->multi_irqs) {\n\t\tif (info->err_mgmt_irqs)\n\t\t\tirq = platform_get_irq_byname(pdev, \"line3\");\n\t\telse\n\t\t\tirq = platform_get_irq_byname(pdev, \"ch24\");\n\t\tif (irq < 0) {\n\t\t\terror = irq;\n\t\t\tgoto out_release;\n\t\t}\n\t\tpriv->emac_irq = irq;\n\t\tfor (i = 0; i < NUM_RX_QUEUE; i++) {\n\t\t\tirq = platform_get_irq_byname(pdev, ravb_rx_irqs[i]);\n\t\t\tif (irq < 0) {\n\t\t\t\terror = irq;\n\t\t\t\tgoto out_release;\n\t\t\t}\n\t\t\tpriv->rx_irqs[i] = irq;\n\t\t}\n\t\tfor (i = 0; i < NUM_TX_QUEUE; i++) {\n\t\t\tirq = platform_get_irq_byname(pdev, ravb_tx_irqs[i]);\n\t\t\tif (irq < 0) {\n\t\t\t\terror = irq;\n\t\t\t\tgoto out_release;\n\t\t\t}\n\t\t\tpriv->tx_irqs[i] = irq;\n\t\t}\n\n\t\tif (info->err_mgmt_irqs) {\n\t\t\tirq = platform_get_irq_byname(pdev, \"err_a\");\n\t\t\tif (irq < 0) {\n\t\t\t\terror = irq;\n\t\t\t\tgoto out_release;\n\t\t\t}\n\t\t\tpriv->erra_irq = irq;\n\n\t\t\tirq = platform_get_irq_byname(pdev, \"mgmt_a\");\n\t\t\tif (irq < 0) {\n\t\t\t\terror = irq;\n\t\t\t\tgoto out_release;\n\t\t\t}\n\t\t\tpriv->mgmta_irq = irq;\n\t\t}\n\t}\n\n\tpriv->clk = devm_clk_get(&pdev->dev, NULL);\n\tif (IS_ERR(priv->clk)) {\n\t\terror = PTR_ERR(priv->clk);\n\t\tgoto out_release;\n\t}\n\n\tpriv->refclk = devm_clk_get_optional(&pdev->dev, \"refclk\");\n\tif (IS_ERR(priv->refclk)) {\n\t\terror = PTR_ERR(priv->refclk);\n\t\tgoto out_release;\n\t}\n\tclk_prepare_enable(priv->refclk);\n\n\tif (info->gptp_ref_clk) {\n\t\tpriv->gptp_clk = devm_clk_get(&pdev->dev, \"gptp\");\n\t\tif (IS_ERR(priv->gptp_clk)) {\n\t\t\terror = PTR_ERR(priv->gptp_clk);\n\t\t\tgoto out_disable_refclk;\n\t\t}\n\t\tclk_prepare_enable(priv->gptp_clk);\n\t}\n\n\tndev->max_mtu = info->rx_max_buf_size - (ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN);\n\tndev->min_mtu = ETH_MIN_MTU;\n\n\t \n\tpriv->num_tx_desc = info->aligned_tx ? 2 : 1;\n\n\t \n\tndev->netdev_ops = &ravb_netdev_ops;\n\tndev->ethtool_ops = &ravb_ethtool_ops;\n\n\t \n\terror = ravb_set_config_mode(ndev);\n\tif (error)\n\t\tgoto out_disable_gptp_clk;\n\n\tif (info->gptp || info->ccc_gac) {\n\t\t \n\t\terror = ravb_set_gti(ndev);\n\t\tif (error)\n\t\t\tgoto out_disable_gptp_clk;\n\n\t\t \n\t\travb_modify(ndev, GCCR, GCCR_LTI, GCCR_LTI);\n\t}\n\n\tif (info->internal_delay) {\n\t\travb_parse_delay_mode(np, ndev);\n\t\travb_set_delay_mode(ndev);\n\t}\n\n\t \n\tpriv->desc_bat_size = sizeof(struct ravb_desc) * DBAT_ENTRY_NUM;\n\tpriv->desc_bat = dma_alloc_coherent(ndev->dev.parent, priv->desc_bat_size,\n\t\t\t\t\t    &priv->desc_bat_dma, GFP_KERNEL);\n\tif (!priv->desc_bat) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Cannot allocate desc base address table (size %d bytes)\\n\",\n\t\t\tpriv->desc_bat_size);\n\t\terror = -ENOMEM;\n\t\tgoto out_disable_gptp_clk;\n\t}\n\tfor (q = RAVB_BE; q < DBAT_ENTRY_NUM; q++)\n\t\tpriv->desc_bat[q].die_dt = DT_EOS;\n\travb_write(ndev, priv->desc_bat_dma, DBAT);\n\n\t \n\tINIT_LIST_HEAD(&priv->ts_skb_list);\n\n\t \n\tif (info->ccc_gac)\n\t\travb_ptp_init(ndev, pdev);\n\n\t \n\tpriv->msg_enable = RAVB_DEF_MSG_ENABLE;\n\n\t \n\travb_read_mac_address(np, ndev);\n\tif (!is_valid_ether_addr(ndev->dev_addr)) {\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"no valid MAC address supplied, using a random one\\n\");\n\t\teth_hw_addr_random(ndev);\n\t}\n\n\t \n\terror = ravb_mdio_init(priv);\n\tif (error) {\n\t\tdev_err(&pdev->dev, \"failed to initialize MDIO\\n\");\n\t\tgoto out_dma_free;\n\t}\n\n\tnetif_napi_add(ndev, &priv->napi[RAVB_BE], ravb_poll);\n\tif (info->nc_queues)\n\t\tnetif_napi_add(ndev, &priv->napi[RAVB_NC], ravb_poll);\n\n\t \n\terror = register_netdev(ndev);\n\tif (error)\n\t\tgoto out_napi_del;\n\n\tdevice_set_wakeup_capable(&pdev->dev, 1);\n\n\t \n\tnetdev_info(ndev, \"Base address at %#x, %pM, IRQ %d.\\n\",\n\t\t    (u32)ndev->base_addr, ndev->dev_addr, ndev->irq);\n\n\tplatform_set_drvdata(pdev, ndev);\n\n\treturn 0;\n\nout_napi_del:\n\tif (info->nc_queues)\n\t\tnetif_napi_del(&priv->napi[RAVB_NC]);\n\n\tnetif_napi_del(&priv->napi[RAVB_BE]);\n\travb_mdio_release(priv);\nout_dma_free:\n\tdma_free_coherent(ndev->dev.parent, priv->desc_bat_size, priv->desc_bat,\n\t\t\t  priv->desc_bat_dma);\n\n\t \n\tif (info->ccc_gac)\n\t\travb_ptp_stop(ndev);\nout_disable_gptp_clk:\n\tclk_disable_unprepare(priv->gptp_clk);\nout_disable_refclk:\n\tclk_disable_unprepare(priv->refclk);\nout_release:\n\tpm_runtime_put(&pdev->dev);\nout_rpm_disable:\n\tpm_runtime_disable(&pdev->dev);\n\treset_control_assert(rstc);\nout_free_netdev:\n\tfree_netdev(ndev);\n\treturn error;\n}\n\nstatic int ravb_remove(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\tunregister_netdev(ndev);\n\tif (info->nc_queues)\n\t\tnetif_napi_del(&priv->napi[RAVB_NC]);\n\tnetif_napi_del(&priv->napi[RAVB_BE]);\n\n\travb_mdio_release(priv);\n\n\t \n\tif (info->ccc_gac)\n\t\travb_ptp_stop(ndev);\n\n\tdma_free_coherent(ndev->dev.parent, priv->desc_bat_size, priv->desc_bat,\n\t\t\t  priv->desc_bat_dma);\n\n\travb_set_opmode(ndev, CCC_OPC_RESET);\n\n\tclk_disable_unprepare(priv->gptp_clk);\n\tclk_disable_unprepare(priv->refclk);\n\n\tpm_runtime_put_sync(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\treset_control_assert(priv->rstc);\n\tfree_netdev(ndev);\n\tplatform_set_drvdata(pdev, NULL);\n\n\treturn 0;\n}\n\nstatic int ravb_wol_setup(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\t \n\travb_write(ndev, 0, RIC0);\n\travb_write(ndev, 0, RIC2);\n\travb_write(ndev, 0, TIC);\n\n\t \n\tsynchronize_irq(priv->emac_irq);\n\tif (info->nc_queues)\n\t\tnapi_disable(&priv->napi[RAVB_NC]);\n\tnapi_disable(&priv->napi[RAVB_BE]);\n\travb_write(ndev, ECSIPR_MPDIP, ECSIPR);\n\n\t \n\travb_modify(ndev, ECMR, ECMR_MPDE, ECMR_MPDE);\n\n\treturn enable_irq_wake(priv->emac_irq);\n}\n\nstatic int ravb_wol_restore(struct net_device *ndev)\n{\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\n\tif (info->nc_queues)\n\t\tnapi_enable(&priv->napi[RAVB_NC]);\n\tnapi_enable(&priv->napi[RAVB_BE]);\n\n\t \n\travb_modify(ndev, ECMR, ECMR_MPDE, 0);\n\n\travb_close(ndev);\n\n\treturn disable_irq_wake(priv->emac_irq);\n}\n\nstatic int __maybe_unused ravb_suspend(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tint ret;\n\n\tif (!netif_running(ndev))\n\t\treturn 0;\n\n\tnetif_device_detach(ndev);\n\n\tif (priv->wol_enabled)\n\t\tret = ravb_wol_setup(ndev);\n\telse\n\t\tret = ravb_close(ndev);\n\n\tif (priv->info->ccc_gac)\n\t\travb_ptp_stop(ndev);\n\n\treturn ret;\n}\n\nstatic int __maybe_unused ravb_resume(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct ravb_private *priv = netdev_priv(ndev);\n\tconst struct ravb_hw_info *info = priv->info;\n\tint ret = 0;\n\n\t \n\tif (priv->wol_enabled) {\n\t\tret = ravb_set_opmode(ndev, CCC_OPC_RESET);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t \n\n\t \n\tret = ravb_set_config_mode(ndev);\n\tif (ret)\n\t\treturn ret;\n\n\tif (info->gptp || info->ccc_gac) {\n\t\t \n\t\tret = ravb_set_gti(ndev);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\travb_modify(ndev, GCCR, GCCR_LTI, GCCR_LTI);\n\t}\n\n\tif (info->internal_delay)\n\t\travb_set_delay_mode(ndev);\n\n\t \n\travb_write(ndev, priv->desc_bat_dma, DBAT);\n\n\tif (priv->info->ccc_gac)\n\t\travb_ptp_init(ndev, priv->pdev);\n\n\tif (netif_running(ndev)) {\n\t\tif (priv->wol_enabled) {\n\t\t\tret = ravb_wol_restore(ndev);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t\tret = ravb_open(ndev);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\travb_set_rx_mode(ndev);\n\t\tnetif_device_attach(ndev);\n\t}\n\n\treturn ret;\n}\n\nstatic int __maybe_unused ravb_runtime_nop(struct device *dev)\n{\n\t \n\treturn 0;\n}\n\nstatic const struct dev_pm_ops ravb_dev_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(ravb_suspend, ravb_resume)\n\tSET_RUNTIME_PM_OPS(ravb_runtime_nop, ravb_runtime_nop, NULL)\n};\n\nstatic struct platform_driver ravb_driver = {\n\t.probe\t\t= ravb_probe,\n\t.remove\t\t= ravb_remove,\n\t.driver = {\n\t\t.name\t= \"ravb\",\n\t\t.pm\t= &ravb_dev_pm_ops,\n\t\t.of_match_table = ravb_match_table,\n\t},\n};\n\nmodule_platform_driver(ravb_driver);\n\nMODULE_AUTHOR(\"Mitsuhiro Kimura, Masaru Nagai\");\nMODULE_DESCRIPTION(\"Renesas Ethernet AVB driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}