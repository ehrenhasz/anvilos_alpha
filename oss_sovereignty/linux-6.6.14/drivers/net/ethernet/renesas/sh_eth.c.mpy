{
  "module_name": "sh_eth.c",
  "hash_id": "824e6b9fc69a11266c8446ac4cb9f20db9d5f96ca78a0e2202d8e21f3ec07df2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/renesas/sh_eth.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/interrupt.h>\n#include <linux/dma-mapping.h>\n#include <linux/etherdevice.h>\n#include <linux/delay.h>\n#include <linux/platform_device.h>\n#include <linux/mdio-bitbang.h>\n#include <linux/netdevice.h>\n#include <linux/of.h>\n#include <linux/of_net.h>\n#include <linux/phy.h>\n#include <linux/cache.h>\n#include <linux/io.h>\n#include <linux/pm_runtime.h>\n#include <linux/slab.h>\n#include <linux/ethtool.h>\n#include <linux/if_vlan.h>\n#include <linux/sh_eth.h>\n#include <linux/of_mdio.h>\n\n#include \"sh_eth.h\"\n\n#define SH_ETH_DEF_MSG_ENABLE \\\n\t\t(NETIF_MSG_LINK\t| \\\n\t\tNETIF_MSG_TIMER\t| \\\n\t\tNETIF_MSG_RX_ERR| \\\n\t\tNETIF_MSG_TX_ERR)\n\n#define SH_ETH_OFFSET_INVALID\t((u16)~0)\n\n#define SH_ETH_OFFSET_DEFAULTS\t\t\t\\\n\t[0 ... SH_ETH_MAX_REGISTER_OFFSET - 1] = SH_ETH_OFFSET_INVALID\n\n \n__diag_push();\n__diag_ignore(GCC, 8, \"-Woverride-init\",\n\t      \"logic to initialize all and then override some is OK\");\nstatic const u16 sh_eth_offset_gigabit[SH_ETH_MAX_REGISTER_OFFSET] = {\n\tSH_ETH_OFFSET_DEFAULTS,\n\n\t[EDSR]\t\t= 0x0000,\n\t[EDMR]\t\t= 0x0400,\n\t[EDTRR]\t\t= 0x0408,\n\t[EDRRR]\t\t= 0x0410,\n\t[EESR]\t\t= 0x0428,\n\t[EESIPR]\t= 0x0430,\n\t[TDLAR]\t\t= 0x0010,\n\t[TDFAR]\t\t= 0x0014,\n\t[TDFXR]\t\t= 0x0018,\n\t[TDFFR]\t\t= 0x001c,\n\t[RDLAR]\t\t= 0x0030,\n\t[RDFAR]\t\t= 0x0034,\n\t[RDFXR]\t\t= 0x0038,\n\t[RDFFR]\t\t= 0x003c,\n\t[TRSCER]\t= 0x0438,\n\t[RMFCR]\t\t= 0x0440,\n\t[TFTR]\t\t= 0x0448,\n\t[FDR]\t\t= 0x0450,\n\t[RMCR]\t\t= 0x0458,\n\t[RPADIR]\t= 0x0460,\n\t[FCFTR]\t\t= 0x0468,\n\t[CSMR]\t\t= 0x04E4,\n\n\t[ECMR]\t\t= 0x0500,\n\t[ECSR]\t\t= 0x0510,\n\t[ECSIPR]\t= 0x0518,\n\t[PIR]\t\t= 0x0520,\n\t[PSR]\t\t= 0x0528,\n\t[PIPR]\t\t= 0x052c,\n\t[RFLR]\t\t= 0x0508,\n\t[APR]\t\t= 0x0554,\n\t[MPR]\t\t= 0x0558,\n\t[PFTCR]\t\t= 0x055c,\n\t[PFRCR]\t\t= 0x0560,\n\t[TPAUSER]\t= 0x0564,\n\t[GECMR]\t\t= 0x05b0,\n\t[BCULR]\t\t= 0x05b4,\n\t[MAHR]\t\t= 0x05c0,\n\t[MALR]\t\t= 0x05c8,\n\t[TROCR]\t\t= 0x0700,\n\t[CDCR]\t\t= 0x0708,\n\t[LCCR]\t\t= 0x0710,\n\t[CEFCR]\t\t= 0x0740,\n\t[FRECR]\t\t= 0x0748,\n\t[TSFRCR]\t= 0x0750,\n\t[TLFRCR]\t= 0x0758,\n\t[RFCR]\t\t= 0x0760,\n\t[CERCR]\t\t= 0x0768,\n\t[CEECR]\t\t= 0x0770,\n\t[MAFCR]\t\t= 0x0778,\n\t[RMII_MII]\t= 0x0790,\n\n\t[ARSTR]\t\t= 0x0000,\n\t[TSU_CTRST]\t= 0x0004,\n\t[TSU_FWEN0]\t= 0x0010,\n\t[TSU_FWEN1]\t= 0x0014,\n\t[TSU_FCM]\t= 0x0018,\n\t[TSU_BSYSL0]\t= 0x0020,\n\t[TSU_BSYSL1]\t= 0x0024,\n\t[TSU_PRISL0]\t= 0x0028,\n\t[TSU_PRISL1]\t= 0x002c,\n\t[TSU_FWSL0]\t= 0x0030,\n\t[TSU_FWSL1]\t= 0x0034,\n\t[TSU_FWSLC]\t= 0x0038,\n\t[TSU_QTAGM0]\t= 0x0040,\n\t[TSU_QTAGM1]\t= 0x0044,\n\t[TSU_FWSR]\t= 0x0050,\n\t[TSU_FWINMK]\t= 0x0054,\n\t[TSU_ADQT0]\t= 0x0048,\n\t[TSU_ADQT1]\t= 0x004c,\n\t[TSU_VTAG0]\t= 0x0058,\n\t[TSU_VTAG1]\t= 0x005c,\n\t[TSU_ADSBSY]\t= 0x0060,\n\t[TSU_TEN]\t= 0x0064,\n\t[TSU_POST1]\t= 0x0070,\n\t[TSU_POST2]\t= 0x0074,\n\t[TSU_POST3]\t= 0x0078,\n\t[TSU_POST4]\t= 0x007c,\n\t[TSU_ADRH0]\t= 0x0100,\n\n\t[TXNLCR0]\t= 0x0080,\n\t[TXALCR0]\t= 0x0084,\n\t[RXNLCR0]\t= 0x0088,\n\t[RXALCR0]\t= 0x008c,\n\t[FWNLCR0]\t= 0x0090,\n\t[FWALCR0]\t= 0x0094,\n\t[TXNLCR1]\t= 0x00a0,\n\t[TXALCR1]\t= 0x00a4,\n\t[RXNLCR1]\t= 0x00a8,\n\t[RXALCR1]\t= 0x00ac,\n\t[FWNLCR1]\t= 0x00b0,\n\t[FWALCR1]\t= 0x00b4,\n};\n\nstatic const u16 sh_eth_offset_fast_rcar[SH_ETH_MAX_REGISTER_OFFSET] = {\n\tSH_ETH_OFFSET_DEFAULTS,\n\n\t[ECMR]\t\t= 0x0300,\n\t[RFLR]\t\t= 0x0308,\n\t[ECSR]\t\t= 0x0310,\n\t[ECSIPR]\t= 0x0318,\n\t[PIR]\t\t= 0x0320,\n\t[PSR]\t\t= 0x0328,\n\t[RDMLR]\t\t= 0x0340,\n\t[IPGR]\t\t= 0x0350,\n\t[APR]\t\t= 0x0354,\n\t[MPR]\t\t= 0x0358,\n\t[RFCF]\t\t= 0x0360,\n\t[TPAUSER]\t= 0x0364,\n\t[TPAUSECR]\t= 0x0368,\n\t[MAHR]\t\t= 0x03c0,\n\t[MALR]\t\t= 0x03c8,\n\t[TROCR]\t\t= 0x03d0,\n\t[CDCR]\t\t= 0x03d4,\n\t[LCCR]\t\t= 0x03d8,\n\t[CNDCR]\t\t= 0x03dc,\n\t[CEFCR]\t\t= 0x03e4,\n\t[FRECR]\t\t= 0x03e8,\n\t[TSFRCR]\t= 0x03ec,\n\t[TLFRCR]\t= 0x03f0,\n\t[RFCR]\t\t= 0x03f4,\n\t[MAFCR]\t\t= 0x03f8,\n\n\t[EDMR]\t\t= 0x0200,\n\t[EDTRR]\t\t= 0x0208,\n\t[EDRRR]\t\t= 0x0210,\n\t[TDLAR]\t\t= 0x0218,\n\t[RDLAR]\t\t= 0x0220,\n\t[EESR]\t\t= 0x0228,\n\t[EESIPR]\t= 0x0230,\n\t[TRSCER]\t= 0x0238,\n\t[RMFCR]\t\t= 0x0240,\n\t[TFTR]\t\t= 0x0248,\n\t[FDR]\t\t= 0x0250,\n\t[RMCR]\t\t= 0x0258,\n\t[TFUCR]\t\t= 0x0264,\n\t[RFOCR]\t\t= 0x0268,\n\t[RMIIMODE]      = 0x026c,\n\t[FCFTR]\t\t= 0x0270,\n\t[TRIMD]\t\t= 0x027c,\n};\n\nstatic const u16 sh_eth_offset_fast_sh4[SH_ETH_MAX_REGISTER_OFFSET] = {\n\tSH_ETH_OFFSET_DEFAULTS,\n\n\t[ECMR]\t\t= 0x0100,\n\t[RFLR]\t\t= 0x0108,\n\t[ECSR]\t\t= 0x0110,\n\t[ECSIPR]\t= 0x0118,\n\t[PIR]\t\t= 0x0120,\n\t[PSR]\t\t= 0x0128,\n\t[RDMLR]\t\t= 0x0140,\n\t[IPGR]\t\t= 0x0150,\n\t[APR]\t\t= 0x0154,\n\t[MPR]\t\t= 0x0158,\n\t[TPAUSER]\t= 0x0164,\n\t[RFCF]\t\t= 0x0160,\n\t[TPAUSECR]\t= 0x0168,\n\t[BCFRR]\t\t= 0x016c,\n\t[MAHR]\t\t= 0x01c0,\n\t[MALR]\t\t= 0x01c8,\n\t[TROCR]\t\t= 0x01d0,\n\t[CDCR]\t\t= 0x01d4,\n\t[LCCR]\t\t= 0x01d8,\n\t[CNDCR]\t\t= 0x01dc,\n\t[CEFCR]\t\t= 0x01e4,\n\t[FRECR]\t\t= 0x01e8,\n\t[TSFRCR]\t= 0x01ec,\n\t[TLFRCR]\t= 0x01f0,\n\t[RFCR]\t\t= 0x01f4,\n\t[MAFCR]\t\t= 0x01f8,\n\t[RTRATE]\t= 0x01fc,\n\n\t[EDMR]\t\t= 0x0000,\n\t[EDTRR]\t\t= 0x0008,\n\t[EDRRR]\t\t= 0x0010,\n\t[TDLAR]\t\t= 0x0018,\n\t[RDLAR]\t\t= 0x0020,\n\t[EESR]\t\t= 0x0028,\n\t[EESIPR]\t= 0x0030,\n\t[TRSCER]\t= 0x0038,\n\t[RMFCR]\t\t= 0x0040,\n\t[TFTR]\t\t= 0x0048,\n\t[FDR]\t\t= 0x0050,\n\t[RMCR]\t\t= 0x0058,\n\t[TFUCR]\t\t= 0x0064,\n\t[RFOCR]\t\t= 0x0068,\n\t[FCFTR]\t\t= 0x0070,\n\t[RPADIR]\t= 0x0078,\n\t[TRIMD]\t\t= 0x007c,\n\t[RBWAR]\t\t= 0x00c8,\n\t[RDFAR]\t\t= 0x00cc,\n\t[TBRAR]\t\t= 0x00d4,\n\t[TDFAR]\t\t= 0x00d8,\n};\n\nstatic const u16 sh_eth_offset_fast_sh3_sh2[SH_ETH_MAX_REGISTER_OFFSET] = {\n\tSH_ETH_OFFSET_DEFAULTS,\n\n\t[EDMR]\t\t= 0x0000,\n\t[EDTRR]\t\t= 0x0004,\n\t[EDRRR]\t\t= 0x0008,\n\t[TDLAR]\t\t= 0x000c,\n\t[RDLAR]\t\t= 0x0010,\n\t[EESR]\t\t= 0x0014,\n\t[EESIPR]\t= 0x0018,\n\t[TRSCER]\t= 0x001c,\n\t[RMFCR]\t\t= 0x0020,\n\t[TFTR]\t\t= 0x0024,\n\t[FDR]\t\t= 0x0028,\n\t[RMCR]\t\t= 0x002c,\n\t[EDOCR]\t\t= 0x0030,\n\t[FCFTR]\t\t= 0x0034,\n\t[RPADIR]\t= 0x0038,\n\t[TRIMD]\t\t= 0x003c,\n\t[RBWAR]\t\t= 0x0040,\n\t[RDFAR]\t\t= 0x0044,\n\t[TBRAR]\t\t= 0x004c,\n\t[TDFAR]\t\t= 0x0050,\n\n\t[ECMR]\t\t= 0x0160,\n\t[ECSR]\t\t= 0x0164,\n\t[ECSIPR]\t= 0x0168,\n\t[PIR]\t\t= 0x016c,\n\t[MAHR]\t\t= 0x0170,\n\t[MALR]\t\t= 0x0174,\n\t[RFLR]\t\t= 0x0178,\n\t[PSR]\t\t= 0x017c,\n\t[TROCR]\t\t= 0x0180,\n\t[CDCR]\t\t= 0x0184,\n\t[LCCR]\t\t= 0x0188,\n\t[CNDCR]\t\t= 0x018c,\n\t[CEFCR]\t\t= 0x0194,\n\t[FRECR]\t\t= 0x0198,\n\t[TSFRCR]\t= 0x019c,\n\t[TLFRCR]\t= 0x01a0,\n\t[RFCR]\t\t= 0x01a4,\n\t[MAFCR]\t\t= 0x01a8,\n\t[IPGR]\t\t= 0x01b4,\n\t[APR]\t\t= 0x01b8,\n\t[MPR]\t\t= 0x01bc,\n\t[TPAUSER]\t= 0x01c4,\n\t[BCFR]\t\t= 0x01cc,\n\n\t[ARSTR]\t\t= 0x0000,\n\t[TSU_CTRST]\t= 0x0004,\n\t[TSU_FWEN0]\t= 0x0010,\n\t[TSU_FWEN1]\t= 0x0014,\n\t[TSU_FCM]\t= 0x0018,\n\t[TSU_BSYSL0]\t= 0x0020,\n\t[TSU_BSYSL1]\t= 0x0024,\n\t[TSU_PRISL0]\t= 0x0028,\n\t[TSU_PRISL1]\t= 0x002c,\n\t[TSU_FWSL0]\t= 0x0030,\n\t[TSU_FWSL1]\t= 0x0034,\n\t[TSU_FWSLC]\t= 0x0038,\n\t[TSU_QTAGM0]\t= 0x0040,\n\t[TSU_QTAGM1]\t= 0x0044,\n\t[TSU_ADQT0]\t= 0x0048,\n\t[TSU_ADQT1]\t= 0x004c,\n\t[TSU_FWSR]\t= 0x0050,\n\t[TSU_FWINMK]\t= 0x0054,\n\t[TSU_ADSBSY]\t= 0x0060,\n\t[TSU_TEN]\t= 0x0064,\n\t[TSU_POST1]\t= 0x0070,\n\t[TSU_POST2]\t= 0x0074,\n\t[TSU_POST3]\t= 0x0078,\n\t[TSU_POST4]\t= 0x007c,\n\n\t[TXNLCR0]\t= 0x0080,\n\t[TXALCR0]\t= 0x0084,\n\t[RXNLCR0]\t= 0x0088,\n\t[RXALCR0]\t= 0x008c,\n\t[FWNLCR0]\t= 0x0090,\n\t[FWALCR0]\t= 0x0094,\n\t[TXNLCR1]\t= 0x00a0,\n\t[TXALCR1]\t= 0x00a4,\n\t[RXNLCR1]\t= 0x00a8,\n\t[RXALCR1]\t= 0x00ac,\n\t[FWNLCR1]\t= 0x00b0,\n\t[FWALCR1]\t= 0x00b4,\n\n\t[TSU_ADRH0]\t= 0x0100,\n};\n__diag_pop();\n\nstatic void sh_eth_rcv_snd_disable(struct net_device *ndev);\nstatic struct net_device_stats *sh_eth_get_stats(struct net_device *ndev);\n\nstatic void sh_eth_write(struct net_device *ndev, u32 data, int enum_index)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu16 offset = mdp->reg_offset[enum_index];\n\n\tif (WARN_ON(offset == SH_ETH_OFFSET_INVALID))\n\t\treturn;\n\n\tiowrite32(data, mdp->addr + offset);\n}\n\nstatic u32 sh_eth_read(struct net_device *ndev, int enum_index)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu16 offset = mdp->reg_offset[enum_index];\n\n\tif (WARN_ON(offset == SH_ETH_OFFSET_INVALID))\n\t\treturn ~0U;\n\n\treturn ioread32(mdp->addr + offset);\n}\n\nstatic void sh_eth_modify(struct net_device *ndev, int enum_index, u32 clear,\n\t\t\t  u32 set)\n{\n\tsh_eth_write(ndev, (sh_eth_read(ndev, enum_index) & ~clear) | set,\n\t\t     enum_index);\n}\n\nstatic u16 sh_eth_tsu_get_offset(struct sh_eth_private *mdp, int enum_index)\n{\n\treturn mdp->reg_offset[enum_index];\n}\n\nstatic void sh_eth_tsu_write(struct sh_eth_private *mdp, u32 data,\n\t\t\t     int enum_index)\n{\n\tu16 offset = sh_eth_tsu_get_offset(mdp, enum_index);\n\n\tif (WARN_ON(offset == SH_ETH_OFFSET_INVALID))\n\t\treturn;\n\n\tiowrite32(data, mdp->tsu_addr + offset);\n}\n\nstatic u32 sh_eth_tsu_read(struct sh_eth_private *mdp, int enum_index)\n{\n\tu16 offset = sh_eth_tsu_get_offset(mdp, enum_index);\n\n\tif (WARN_ON(offset == SH_ETH_OFFSET_INVALID))\n\t\treturn ~0U;\n\n\treturn ioread32(mdp->tsu_addr + offset);\n}\n\nstatic void sh_eth_soft_swap(char *src, int len)\n{\n#ifdef __LITTLE_ENDIAN\n\tu32 *p = (u32 *)src;\n\tu32 *maxp = p + DIV_ROUND_UP(len, sizeof(u32));\n\n\tfor (; p < maxp; p++)\n\t\t*p = swab32(*p);\n#endif\n}\n\nstatic void sh_eth_select_mii(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu32 value;\n\n\tswitch (mdp->phy_interface) {\n\tcase PHY_INTERFACE_MODE_RGMII ... PHY_INTERFACE_MODE_RGMII_TXID:\n\t\tvalue = 0x3;\n\t\tbreak;\n\tcase PHY_INTERFACE_MODE_GMII:\n\t\tvalue = 0x2;\n\t\tbreak;\n\tcase PHY_INTERFACE_MODE_MII:\n\t\tvalue = 0x1;\n\t\tbreak;\n\tcase PHY_INTERFACE_MODE_RMII:\n\t\tvalue = 0x0;\n\t\tbreak;\n\tdefault:\n\t\tnetdev_warn(ndev,\n\t\t\t    \"PHY interface mode was not setup. Set to MII.\\n\");\n\t\tvalue = 0x1;\n\t\tbreak;\n\t}\n\n\tsh_eth_write(ndev, value, RMII_MII);\n}\n\nstatic void sh_eth_set_duplex(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tsh_eth_modify(ndev, ECMR, ECMR_DM, mdp->duplex ? ECMR_DM : 0);\n}\n\nstatic void sh_eth_chip_reset(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\t \n\tsh_eth_tsu_write(mdp, ARSTR_ARST, ARSTR);\n\tmdelay(1);\n}\n\nstatic int sh_eth_soft_reset(struct net_device *ndev)\n{\n\tsh_eth_modify(ndev, EDMR, EDMR_SRST_ETHER, EDMR_SRST_ETHER);\n\tmdelay(3);\n\tsh_eth_modify(ndev, EDMR, EDMR_SRST_ETHER, 0);\n\n\treturn 0;\n}\n\nstatic int sh_eth_check_soft_reset(struct net_device *ndev)\n{\n\tint cnt;\n\n\tfor (cnt = 100; cnt > 0; cnt--) {\n\t\tif (!(sh_eth_read(ndev, EDMR) & EDMR_SRST_GETHER))\n\t\t\treturn 0;\n\t\tmdelay(1);\n\t}\n\n\tnetdev_err(ndev, \"Device reset failed\\n\");\n\treturn -ETIMEDOUT;\n}\n\nstatic int sh_eth_soft_reset_gether(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ret;\n\n\tsh_eth_write(ndev, EDSR_ENALL, EDSR);\n\tsh_eth_modify(ndev, EDMR, EDMR_SRST_GETHER, EDMR_SRST_GETHER);\n\n\tret = sh_eth_check_soft_reset(ndev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tsh_eth_write(ndev, 0, TDLAR);\n\tsh_eth_write(ndev, 0, TDFAR);\n\tsh_eth_write(ndev, 0, TDFXR);\n\tsh_eth_write(ndev, 0, TDFFR);\n\tsh_eth_write(ndev, 0, RDLAR);\n\tsh_eth_write(ndev, 0, RDFAR);\n\tsh_eth_write(ndev, 0, RDFXR);\n\tsh_eth_write(ndev, 0, RDFFR);\n\n\t \n\tif (mdp->cd->csmr)\n\t\tsh_eth_write(ndev, 0, CSMR);\n\n\t \n\tif (mdp->cd->select_mii)\n\t\tsh_eth_select_mii(ndev);\n\n\treturn ret;\n}\n\nstatic void sh_eth_set_rate_gether(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tif (WARN_ON(!mdp->cd->gecmr))\n\t\treturn;\n\n\tswitch (mdp->speed) {\n\tcase 10:  \n\t\tsh_eth_write(ndev, GECMR_10, GECMR);\n\t\tbreak;\n\tcase 100: \n\t\tsh_eth_write(ndev, GECMR_100, GECMR);\n\t\tbreak;\n\tcase 1000:  \n\t\tsh_eth_write(ndev, GECMR_1000, GECMR);\n\t\tbreak;\n\t}\n}\n\n#ifdef CONFIG_OF\n \nstatic struct sh_eth_cpu_data r7s72100_data = {\n\t.soft_reset\t= sh_eth_soft_reset_gether,\n\n\t.chip_reset\t= sh_eth_chip_reset,\n\t.set_duplex\t= sh_eth_set_duplex,\n\n\t.register_type\t= SH_ETH_REG_GIGABIT,\n\n\t.edtrr_trns\t= EDTRR_TRNS_GETHER,\n\t.ecsr_value\t= ECSR_ICD,\n\t.ecsipr_value\t= ECSIPR_ICDIP,\n\t.eesipr_value\t= EESIPR_TWB1IP | EESIPR_TWBIP | EESIPR_TC1IP |\n\t\t\t  EESIPR_TABTIP | EESIPR_RABTIP | EESIPR_RFCOFIP |\n\t\t\t  EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_RRFIP |\n\t\t\t  EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_TC1 | EESR_FTC,\n\t.eesr_err_check\t= EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |\n\t\t\t  EESR_RFE | EESR_RDE | EESR_RFRMER | EESR_TFE |\n\t\t\t  EESR_TDE,\n\t.fdr_value\t= 0x0000070f,\n\n\t.trscer_err_mask = TRSCER_RMAFCE | TRSCER_RRFCE,\n\n\t.no_psr\t\t= 1,\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.hw_swap\t= 1,\n\t.rpadir\t\t= 1,\n\t.no_trimd\t= 1,\n\t.no_ade\t\t= 1,\n\t.xdfar_rw\t= 1,\n\t.csmr\t\t= 1,\n\t.rx_csum\t= 1,\n\t.tsu\t\t= 1,\n\t.no_tx_cntrs\t= 1,\n};\n\nstatic void sh_eth_chip_reset_r8a7740(struct net_device *ndev)\n{\n\tsh_eth_chip_reset(ndev);\n\n\tsh_eth_select_mii(ndev);\n}\n\n \nstatic struct sh_eth_cpu_data r8a7740_data = {\n\t.soft_reset\t= sh_eth_soft_reset_gether,\n\n\t.chip_reset\t= sh_eth_chip_reset_r8a7740,\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_gether,\n\n\t.register_type\t= SH_ETH_REG_GIGABIT,\n\n\t.edtrr_trns\t= EDTRR_TRNS_GETHER,\n\t.ecsr_value\t= ECSR_ICD | ECSR_MPD,\n\t.ecsipr_value\t= ECSIPR_LCHNGIP | ECSIPR_ICDIP | ECSIPR_MPDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  0x0000f000 | EESIPR_CNDIP | EESIPR_DLCIP |\n\t\t\t  EESIPR_CDIP | EESIPR_TROIP | EESIPR_RMAFIP |\n\t\t\t  EESIPR_CEEFIP | EESIPR_CELFIP |\n\t\t\t  EESIPR_RRFIP | EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_TC1 | EESR_FTC,\n\t.eesr_err_check\t= EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |\n\t\t\t  EESR_RFE | EESR_RDE | EESR_RFRMER | EESR_TFE |\n\t\t\t  EESR_TDE,\n\t.fdr_value\t= 0x0000070f,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.gecmr\t\t= 1,\n\t.bculr\t\t= 1,\n\t.hw_swap\t= 1,\n\t.rpadir\t\t= 1,\n\t.no_trimd\t= 1,\n\t.no_ade\t\t= 1,\n\t.xdfar_rw\t= 1,\n\t.csmr\t\t= 1,\n\t.rx_csum\t= 1,\n\t.tsu\t\t= 1,\n\t.select_mii\t= 1,\n\t.magic\t\t= 1,\n\t.cexcr\t\t= 1,\n};\n\n \nstatic void sh_eth_set_rate_rcar(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tswitch (mdp->speed) {\n\tcase 10:  \n\t\tsh_eth_modify(ndev, ECMR, ECMR_ELB, 0);\n\t\tbreak;\n\tcase 100: \n\t\tsh_eth_modify(ndev, ECMR, ECMR_ELB, ECMR_ELB);\n\t\tbreak;\n\t}\n}\n\n \nstatic struct sh_eth_cpu_data rcar_gen1_data = {\n\t.soft_reset\t= sh_eth_soft_reset,\n\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_rcar,\n\n\t.register_type\t= SH_ETH_REG_FAST_RCAR,\n\n\t.edtrr_trns\t= EDTRR_TRNS_ETHER,\n\t.ecsr_value\t= ECSR_PSRTO | ECSR_LCHNG | ECSR_ICD,\n\t.ecsipr_value\t= ECSIPR_PSRTOIP | ECSIPR_LCHNGIP | ECSIPR_ICDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ADEIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_RRFIP |\n\t\t\t  EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_FTC | EESR_CND | EESR_DLC | EESR_CD | EESR_TRO,\n\t.eesr_err_check\t= EESR_TWB | EESR_TABT | EESR_RABT | EESR_RFE |\n\t\t\t  EESR_RDE | EESR_RFRMER | EESR_TFE | EESR_TDE,\n\t.fdr_value\t= 0x00000f0f,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.hw_swap\t= 1,\n\t.no_xdfar\t= 1,\n};\n\n \nstatic struct sh_eth_cpu_data rcar_gen2_data = {\n\t.soft_reset\t= sh_eth_soft_reset,\n\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_rcar,\n\n\t.register_type\t= SH_ETH_REG_FAST_RCAR,\n\n\t.edtrr_trns\t= EDTRR_TRNS_ETHER,\n\t.ecsr_value\t= ECSR_PSRTO | ECSR_LCHNG | ECSR_ICD | ECSR_MPD,\n\t.ecsipr_value\t= ECSIPR_PSRTOIP | ECSIPR_LCHNGIP | ECSIPR_ICDIP |\n\t\t\t  ECSIPR_MPDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ADEIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_RRFIP |\n\t\t\t  EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_FTC | EESR_CND | EESR_DLC | EESR_CD | EESR_TRO,\n\t.eesr_err_check\t= EESR_TWB | EESR_TABT | EESR_RABT | EESR_RFE |\n\t\t\t  EESR_RDE | EESR_RFRMER | EESR_TFE | EESR_TDE,\n\t.fdr_value\t= 0x00000f0f,\n\n\t.trscer_err_mask = TRSCER_RMAFCE,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.hw_swap\t= 1,\n\t.no_xdfar\t= 1,\n\t.rmiimode\t= 1,\n\t.magic\t\t= 1,\n};\n\n \nstatic struct sh_eth_cpu_data r8a77980_data = {\n\t.soft_reset\t= sh_eth_soft_reset_gether,\n\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_gether,\n\n\t.register_type  = SH_ETH_REG_GIGABIT,\n\n\t.edtrr_trns\t= EDTRR_TRNS_GETHER,\n\t.ecsr_value\t= ECSR_PSRTO | ECSR_LCHNG | ECSR_ICD | ECSR_MPD,\n\t.ecsipr_value\t= ECSIPR_PSRTOIP | ECSIPR_LCHNGIP | ECSIPR_ICDIP |\n\t\t\t  ECSIPR_MPDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_RRFIP |\n\t\t\t  EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check       = EESR_FTC | EESR_CD | EESR_TRO,\n\t.eesr_err_check = EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |\n\t\t\t  EESR_RFE | EESR_RDE | EESR_RFRMER |\n\t\t\t  EESR_TFE | EESR_TDE | EESR_ECI,\n\t.fdr_value\t= 0x0000070f,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.gecmr\t\t= 1,\n\t.bculr\t\t= 1,\n\t.hw_swap\t= 1,\n\t.nbst\t\t= 1,\n\t.rpadir\t\t= 1,\n\t.no_trimd\t= 1,\n\t.no_ade\t\t= 1,\n\t.xdfar_rw\t= 1,\n\t.csmr\t\t= 1,\n\t.rx_csum\t= 1,\n\t.select_mii\t= 1,\n\t.magic\t\t= 1,\n\t.cexcr\t\t= 1,\n};\n\n \nstatic struct sh_eth_cpu_data r7s9210_data = {\n\t.soft_reset\t= sh_eth_soft_reset,\n\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_rcar,\n\n\t.register_type\t= SH_ETH_REG_FAST_SH4,\n\n\t.edtrr_trns\t= EDTRR_TRNS_ETHER,\n\t.ecsr_value\t= ECSR_ICD,\n\t.ecsipr_value\t= ECSIPR_ICDIP,\n\t.eesipr_value\t= EESIPR_TWBIP | EESIPR_TABTIP | EESIPR_RABTIP |\n\t\t\t  EESIPR_RFCOFIP | EESIPR_ECIIP | EESIPR_FTCIP |\n\t\t\t  EESIPR_TDEIP | EESIPR_TFUFIP | EESIPR_FRIP |\n\t\t\t  EESIPR_RDEIP | EESIPR_RFOFIP | EESIPR_CNDIP |\n\t\t\t  EESIPR_DLCIP | EESIPR_CDIP | EESIPR_TROIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_RRFIP | EESIPR_RTLFIP |\n\t\t\t  EESIPR_RTSFIP | EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_FTC | EESR_CND | EESR_DLC | EESR_CD | EESR_TRO,\n\t.eesr_err_check\t= EESR_TWB | EESR_TABT | EESR_RABT | EESR_RFE |\n\t\t\t  EESR_RDE | EESR_RFRMER | EESR_TFE | EESR_TDE,\n\n\t.fdr_value\t= 0x0000070f,\n\n\t.trscer_err_mask = TRSCER_RMAFCE | TRSCER_RRFCE,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.hw_swap\t= 1,\n\t.rpadir\t\t= 1,\n\t.no_ade\t\t= 1,\n\t.xdfar_rw\t= 1,\n};\n#endif  \n\nstatic void sh_eth_set_rate_sh7724(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tswitch (mdp->speed) {\n\tcase 10:  \n\t\tsh_eth_modify(ndev, ECMR, ECMR_RTM, 0);\n\t\tbreak;\n\tcase 100: \n\t\tsh_eth_modify(ndev, ECMR, ECMR_RTM, ECMR_RTM);\n\t\tbreak;\n\t}\n}\n\n \nstatic struct sh_eth_cpu_data sh7724_data = {\n\t.soft_reset\t= sh_eth_soft_reset,\n\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_sh7724,\n\n\t.register_type\t= SH_ETH_REG_FAST_SH4,\n\n\t.edtrr_trns\t= EDTRR_TRNS_ETHER,\n\t.ecsr_value\t= ECSR_PSRTO | ECSR_LCHNG | ECSR_ICD,\n\t.ecsipr_value\t= ECSIPR_PSRTOIP | ECSIPR_LCHNGIP | ECSIPR_ICDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ADEIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_RRFIP |\n\t\t\t  EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_FTC | EESR_CND | EESR_DLC | EESR_CD | EESR_TRO,\n\t.eesr_err_check\t= EESR_TWB | EESR_TABT | EESR_RABT | EESR_RFE |\n\t\t\t  EESR_RDE | EESR_RFRMER | EESR_TFE | EESR_TDE,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.hw_swap\t= 1,\n\t.rpadir\t\t= 1,\n};\n\nstatic void sh_eth_set_rate_sh7757(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tswitch (mdp->speed) {\n\tcase 10:  \n\t\tsh_eth_write(ndev, 0, RTRATE);\n\t\tbreak;\n\tcase 100: \n\t\tsh_eth_write(ndev, 1, RTRATE);\n\t\tbreak;\n\t}\n}\n\n \nstatic struct sh_eth_cpu_data sh7757_data = {\n\t.soft_reset\t= sh_eth_soft_reset,\n\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_sh7757,\n\n\t.register_type\t= SH_ETH_REG_FAST_SH4,\n\n\t.edtrr_trns\t= EDTRR_TRNS_ETHER,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  0x0000f000 | EESIPR_CNDIP | EESIPR_DLCIP |\n\t\t\t  EESIPR_CDIP | EESIPR_TROIP | EESIPR_RMAFIP |\n\t\t\t  EESIPR_CEEFIP | EESIPR_CELFIP |\n\t\t\t  EESIPR_RRFIP | EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_FTC | EESR_CND | EESR_DLC | EESR_CD | EESR_TRO,\n\t.eesr_err_check\t= EESR_TWB | EESR_TABT | EESR_RABT | EESR_RFE |\n\t\t\t  EESR_RDE | EESR_RFRMER | EESR_TFE | EESR_TDE,\n\n\t.irq_flags\t= IRQF_SHARED,\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.hw_swap\t= 1,\n\t.no_ade\t\t= 1,\n\t.rpadir\t\t= 1,\n\t.rtrate\t\t= 1,\n\t.dual_port\t= 1,\n};\n\n#define SH_GIGA_ETH_BASE\t0xfee00000UL\n#define GIGA_MALR(port)\t\t(SH_GIGA_ETH_BASE + 0x800 * (port) + 0x05c8)\n#define GIGA_MAHR(port)\t\t(SH_GIGA_ETH_BASE + 0x800 * (port) + 0x05c0)\nstatic void sh_eth_chip_reset_giga(struct net_device *ndev)\n{\n\tu32 mahr[2], malr[2];\n\tint i;\n\n\t \n\tfor (i = 0; i < 2; i++) {\n\t\tmalr[i] = ioread32((void *)GIGA_MALR(i));\n\t\tmahr[i] = ioread32((void *)GIGA_MAHR(i));\n\t}\n\n\tsh_eth_chip_reset(ndev);\n\n\t \n\tfor (i = 0; i < 2; i++) {\n\t\tiowrite32(malr[i], (void *)GIGA_MALR(i));\n\t\tiowrite32(mahr[i], (void *)GIGA_MAHR(i));\n\t}\n}\n\nstatic void sh_eth_set_rate_giga(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tif (WARN_ON(!mdp->cd->gecmr))\n\t\treturn;\n\n\tswitch (mdp->speed) {\n\tcase 10:  \n\t\tsh_eth_write(ndev, 0x00000000, GECMR);\n\t\tbreak;\n\tcase 100: \n\t\tsh_eth_write(ndev, 0x00000010, GECMR);\n\t\tbreak;\n\tcase 1000:  \n\t\tsh_eth_write(ndev, 0x00000020, GECMR);\n\t\tbreak;\n\t}\n}\n\n \nstatic struct sh_eth_cpu_data sh7757_data_giga = {\n\t.soft_reset\t= sh_eth_soft_reset_gether,\n\n\t.chip_reset\t= sh_eth_chip_reset_giga,\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_giga,\n\n\t.register_type\t= SH_ETH_REG_GIGABIT,\n\n\t.edtrr_trns\t= EDTRR_TRNS_GETHER,\n\t.ecsr_value\t= ECSR_ICD | ECSR_MPD,\n\t.ecsipr_value\t= ECSIPR_LCHNGIP | ECSIPR_ICDIP | ECSIPR_MPDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  0x0000f000 | EESIPR_CNDIP | EESIPR_DLCIP |\n\t\t\t  EESIPR_CDIP | EESIPR_TROIP | EESIPR_RMAFIP |\n\t\t\t  EESIPR_CEEFIP | EESIPR_CELFIP |\n\t\t\t  EESIPR_RRFIP | EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_TC1 | EESR_FTC,\n\t.eesr_err_check\t= EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |\n\t\t\t  EESR_RFE | EESR_RDE | EESR_RFRMER | EESR_TFE |\n\t\t\t  EESR_TDE,\n\t.fdr_value\t= 0x0000072f,\n\n\t.irq_flags\t= IRQF_SHARED,\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.gecmr\t\t= 1,\n\t.bculr\t\t= 1,\n\t.hw_swap\t= 1,\n\t.rpadir\t\t= 1,\n\t.no_trimd\t= 1,\n\t.no_ade\t\t= 1,\n\t.xdfar_rw\t= 1,\n\t.tsu\t\t= 1,\n\t.cexcr\t\t= 1,\n\t.dual_port\t= 1,\n};\n\n \nstatic struct sh_eth_cpu_data sh7734_data = {\n\t.soft_reset\t= sh_eth_soft_reset_gether,\n\n\t.chip_reset\t= sh_eth_chip_reset,\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_gether,\n\n\t.register_type\t= SH_ETH_REG_GIGABIT,\n\n\t.edtrr_trns\t= EDTRR_TRNS_GETHER,\n\t.ecsr_value\t= ECSR_ICD | ECSR_MPD,\n\t.ecsipr_value\t= ECSIPR_LCHNGIP | ECSIPR_ICDIP | ECSIPR_MPDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  EESIPR_DLCIP | EESIPR_CDIP | EESIPR_TROIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_CEEFIP | EESIPR_CELFIP |\n\t\t\t  EESIPR_RRFIP | EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_TC1 | EESR_FTC,\n\t.eesr_err_check\t= EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |\n\t\t\t  EESR_RFE | EESR_RDE | EESR_RFRMER | EESR_TFE |\n\t\t\t  EESR_TDE,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.gecmr\t\t= 1,\n\t.bculr\t\t= 1,\n\t.hw_swap\t= 1,\n\t.no_trimd\t= 1,\n\t.no_ade\t\t= 1,\n\t.xdfar_rw\t= 1,\n\t.tsu\t\t= 1,\n\t.csmr\t\t= 1,\n\t.rx_csum\t= 1,\n\t.select_mii\t= 1,\n\t.magic\t\t= 1,\n\t.cexcr\t\t= 1,\n};\n\n \nstatic struct sh_eth_cpu_data sh7763_data = {\n\t.soft_reset\t= sh_eth_soft_reset_gether,\n\n\t.chip_reset\t= sh_eth_chip_reset,\n\t.set_duplex\t= sh_eth_set_duplex,\n\t.set_rate\t= sh_eth_set_rate_gether,\n\n\t.register_type\t= SH_ETH_REG_GIGABIT,\n\n\t.edtrr_trns\t= EDTRR_TRNS_GETHER,\n\t.ecsr_value\t= ECSR_ICD | ECSR_MPD,\n\t.ecsipr_value\t= ECSIPR_LCHNGIP | ECSIPR_ICDIP | ECSIPR_MPDIP,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  EESIPR_DLCIP | EESIPR_CDIP | EESIPR_TROIP |\n\t\t\t  EESIPR_RMAFIP | EESIPR_CEEFIP | EESIPR_CELFIP |\n\t\t\t  EESIPR_RRFIP | EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.tx_check\t= EESR_TC1 | EESR_FTC,\n\t.eesr_err_check\t= EESR_TWB1 | EESR_TWB | EESR_TABT | EESR_RABT |\n\t\t\t  EESR_RDE | EESR_RFRMER | EESR_TFE | EESR_TDE,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.gecmr\t\t= 1,\n\t.bculr\t\t= 1,\n\t.hw_swap\t= 1,\n\t.no_trimd\t= 1,\n\t.no_ade\t\t= 1,\n\t.xdfar_rw\t= 1,\n\t.tsu\t\t= 1,\n\t.irq_flags\t= IRQF_SHARED,\n\t.magic\t\t= 1,\n\t.cexcr\t\t= 1,\n\t.rx_csum\t= 1,\n\t.dual_port\t= 1,\n};\n\nstatic struct sh_eth_cpu_data sh7619_data = {\n\t.soft_reset\t= sh_eth_soft_reset,\n\n\t.register_type\t= SH_ETH_REG_FAST_SH3_SH2,\n\n\t.edtrr_trns\t= EDTRR_TRNS_ETHER,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  0x0000f000 | EESIPR_CNDIP | EESIPR_DLCIP |\n\t\t\t  EESIPR_CDIP | EESIPR_TROIP | EESIPR_RMAFIP |\n\t\t\t  EESIPR_CEEFIP | EESIPR_CELFIP |\n\t\t\t  EESIPR_RRFIP | EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.apr\t\t= 1,\n\t.mpr\t\t= 1,\n\t.tpauser\t= 1,\n\t.hw_swap\t= 1,\n};\n\nstatic struct sh_eth_cpu_data sh771x_data = {\n\t.soft_reset\t= sh_eth_soft_reset,\n\n\t.register_type\t= SH_ETH_REG_FAST_SH3_SH2,\n\n\t.edtrr_trns\t= EDTRR_TRNS_ETHER,\n\t.eesipr_value\t= EESIPR_RFCOFIP | EESIPR_ECIIP |\n\t\t\t  EESIPR_FTCIP | EESIPR_TDEIP | EESIPR_TFUFIP |\n\t\t\t  EESIPR_FRIP | EESIPR_RDEIP | EESIPR_RFOFIP |\n\t\t\t  0x0000f000 | EESIPR_CNDIP | EESIPR_DLCIP |\n\t\t\t  EESIPR_CDIP | EESIPR_TROIP | EESIPR_RMAFIP |\n\t\t\t  EESIPR_CEEFIP | EESIPR_CELFIP |\n\t\t\t  EESIPR_RRFIP | EESIPR_RTLFIP | EESIPR_RTSFIP |\n\t\t\t  EESIPR_PREIP | EESIPR_CERFIP,\n\n\t.trscer_err_mask = TRSCER_RMAFCE,\n\n\t.tsu\t\t= 1,\n\t.dual_port\t= 1,\n};\n\nstatic void sh_eth_set_default_cpu_data(struct sh_eth_cpu_data *cd)\n{\n\tif (!cd->ecsr_value)\n\t\tcd->ecsr_value = DEFAULT_ECSR_INIT;\n\n\tif (!cd->ecsipr_value)\n\t\tcd->ecsipr_value = DEFAULT_ECSIPR_INIT;\n\n\tif (!cd->fcftr_value)\n\t\tcd->fcftr_value = DEFAULT_FIFO_F_D_RFF |\n\t\t\t\t  DEFAULT_FIFO_F_D_RFD;\n\n\tif (!cd->fdr_value)\n\t\tcd->fdr_value = DEFAULT_FDR_INIT;\n\n\tif (!cd->tx_check)\n\t\tcd->tx_check = DEFAULT_TX_CHECK;\n\n\tif (!cd->eesr_err_check)\n\t\tcd->eesr_err_check = DEFAULT_EESR_ERR_CHECK;\n\n\tif (!cd->trscer_err_mask)\n\t\tcd->trscer_err_mask = DEFAULT_TRSCER_ERR_MASK;\n}\n\nstatic void sh_eth_set_receive_align(struct sk_buff *skb)\n{\n\tuintptr_t reserve = (uintptr_t)skb->data & (SH_ETH_RX_ALIGN - 1);\n\n\tif (reserve)\n\t\tskb_reserve(skb, SH_ETH_RX_ALIGN - reserve);\n}\n\n \nstatic void update_mac_address(struct net_device *ndev)\n{\n\tsh_eth_write(ndev,\n\t\t     (ndev->dev_addr[0] << 24) | (ndev->dev_addr[1] << 16) |\n\t\t     (ndev->dev_addr[2] << 8) | (ndev->dev_addr[3]), MAHR);\n\tsh_eth_write(ndev,\n\t\t     (ndev->dev_addr[4] << 8) | (ndev->dev_addr[5]), MALR);\n}\n\n \nstatic void read_mac_address(struct net_device *ndev, unsigned char *mac)\n{\n\tif (mac[0] || mac[1] || mac[2] || mac[3] || mac[4] || mac[5]) {\n\t\teth_hw_addr_set(ndev, mac);\n\t} else {\n\t\tu32 mahr = sh_eth_read(ndev, MAHR);\n\t\tu32 malr = sh_eth_read(ndev, MALR);\n\t\tu8 addr[ETH_ALEN];\n\n\t\taddr[0] = (mahr >> 24) & 0xFF;\n\t\taddr[1] = (mahr >> 16) & 0xFF;\n\t\taddr[2] = (mahr >>  8) & 0xFF;\n\t\taddr[3] = (mahr >>  0) & 0xFF;\n\t\taddr[4] = (malr >>  8) & 0xFF;\n\t\taddr[5] = (malr >>  0) & 0xFF;\n\t\teth_hw_addr_set(ndev, addr);\n\t}\n}\n\nstruct bb_info {\n\tvoid (*set_gate)(void *addr);\n\tstruct mdiobb_ctrl ctrl;\n\tvoid *addr;\n};\n\nstatic void sh_mdio_ctrl(struct mdiobb_ctrl *ctrl, u32 mask, int set)\n{\n\tstruct bb_info *bitbang = container_of(ctrl, struct bb_info, ctrl);\n\tu32 pir;\n\n\tif (bitbang->set_gate)\n\t\tbitbang->set_gate(bitbang->addr);\n\n\tpir = ioread32(bitbang->addr);\n\tif (set)\n\t\tpir |=  mask;\n\telse\n\t\tpir &= ~mask;\n\tiowrite32(pir, bitbang->addr);\n}\n\n \nstatic void sh_mmd_ctrl(struct mdiobb_ctrl *ctrl, int bit)\n{\n\tsh_mdio_ctrl(ctrl, PIR_MMD, bit);\n}\n\n \nstatic void sh_set_mdio(struct mdiobb_ctrl *ctrl, int bit)\n{\n\tsh_mdio_ctrl(ctrl, PIR_MDO, bit);\n}\n\n \nstatic int sh_get_mdio(struct mdiobb_ctrl *ctrl)\n{\n\tstruct bb_info *bitbang = container_of(ctrl, struct bb_info, ctrl);\n\n\tif (bitbang->set_gate)\n\t\tbitbang->set_gate(bitbang->addr);\n\n\treturn (ioread32(bitbang->addr) & PIR_MDI) != 0;\n}\n\n \nstatic void sh_mdc_ctrl(struct mdiobb_ctrl *ctrl, int bit)\n{\n\tsh_mdio_ctrl(ctrl, PIR_MDC, bit);\n}\n\n \nstatic const struct mdiobb_ops bb_ops = {\n\t.owner = THIS_MODULE,\n\t.set_mdc = sh_mdc_ctrl,\n\t.set_mdio_dir = sh_mmd_ctrl,\n\t.set_mdio_data = sh_set_mdio,\n\t.get_mdio_data = sh_get_mdio,\n};\n\n \nstatic int sh_eth_tx_free(struct net_device *ndev, bool sent_only)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct sh_eth_txdesc *txdesc;\n\tint free_num = 0;\n\tint entry;\n\tbool sent;\n\n\tfor (; mdp->cur_tx - mdp->dirty_tx > 0; mdp->dirty_tx++) {\n\t\tentry = mdp->dirty_tx % mdp->num_tx_ring;\n\t\ttxdesc = &mdp->tx_ring[entry];\n\t\tsent = !(txdesc->status & cpu_to_le32(TD_TACT));\n\t\tif (sent_only && !sent)\n\t\t\tbreak;\n\t\t \n\t\tdma_rmb();\n\t\tnetif_info(mdp, tx_done, ndev,\n\t\t\t   \"tx entry %d status 0x%08x\\n\",\n\t\t\t   entry, le32_to_cpu(txdesc->status));\n\t\t \n\t\tif (mdp->tx_skbuff[entry]) {\n\t\t\tdma_unmap_single(&mdp->pdev->dev,\n\t\t\t\t\t le32_to_cpu(txdesc->addr),\n\t\t\t\t\t le32_to_cpu(txdesc->len) >> 16,\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb_irq(mdp->tx_skbuff[entry]);\n\t\t\tmdp->tx_skbuff[entry] = NULL;\n\t\t\tfree_num++;\n\t\t}\n\t\ttxdesc->status = cpu_to_le32(TD_TFP);\n\t\tif (entry >= mdp->num_tx_ring - 1)\n\t\t\ttxdesc->status |= cpu_to_le32(TD_TDLE);\n\n\t\tif (sent) {\n\t\t\tndev->stats.tx_packets++;\n\t\t\tndev->stats.tx_bytes += le32_to_cpu(txdesc->len) >> 16;\n\t\t}\n\t}\n\treturn free_num;\n}\n\n \nstatic void sh_eth_ring_free(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ringsize, i;\n\n\tif (mdp->rx_ring) {\n\t\tfor (i = 0; i < mdp->num_rx_ring; i++) {\n\t\t\tif (mdp->rx_skbuff[i]) {\n\t\t\t\tstruct sh_eth_rxdesc *rxdesc = &mdp->rx_ring[i];\n\n\t\t\t\tdma_unmap_single(&mdp->pdev->dev,\n\t\t\t\t\t\t le32_to_cpu(rxdesc->addr),\n\t\t\t\t\t\t ALIGN(mdp->rx_buf_sz, 32),\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\t}\n\t\t}\n\t\tringsize = sizeof(struct sh_eth_rxdesc) * mdp->num_rx_ring;\n\t\tdma_free_coherent(&mdp->pdev->dev, ringsize, mdp->rx_ring,\n\t\t\t\t  mdp->rx_desc_dma);\n\t\tmdp->rx_ring = NULL;\n\t}\n\n\t \n\tif (mdp->rx_skbuff) {\n\t\tfor (i = 0; i < mdp->num_rx_ring; i++)\n\t\t\tdev_kfree_skb(mdp->rx_skbuff[i]);\n\t}\n\tkfree(mdp->rx_skbuff);\n\tmdp->rx_skbuff = NULL;\n\n\tif (mdp->tx_ring) {\n\t\tsh_eth_tx_free(ndev, false);\n\n\t\tringsize = sizeof(struct sh_eth_txdesc) * mdp->num_tx_ring;\n\t\tdma_free_coherent(&mdp->pdev->dev, ringsize, mdp->tx_ring,\n\t\t\t\t  mdp->tx_desc_dma);\n\t\tmdp->tx_ring = NULL;\n\t}\n\n\t \n\tkfree(mdp->tx_skbuff);\n\tmdp->tx_skbuff = NULL;\n}\n\n \nstatic void sh_eth_ring_format(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint i;\n\tstruct sk_buff *skb;\n\tstruct sh_eth_rxdesc *rxdesc = NULL;\n\tstruct sh_eth_txdesc *txdesc = NULL;\n\tint rx_ringsize = sizeof(*rxdesc) * mdp->num_rx_ring;\n\tint tx_ringsize = sizeof(*txdesc) * mdp->num_tx_ring;\n\tint skbuff_size = mdp->rx_buf_sz + SH_ETH_RX_ALIGN + 32 - 1;\n\tdma_addr_t dma_addr;\n\tu32 buf_len;\n\n\tmdp->cur_rx = 0;\n\tmdp->cur_tx = 0;\n\tmdp->dirty_rx = 0;\n\tmdp->dirty_tx = 0;\n\n\tmemset(mdp->rx_ring, 0, rx_ringsize);\n\n\t \n\tfor (i = 0; i < mdp->num_rx_ring; i++) {\n\t\t \n\t\tmdp->rx_skbuff[i] = NULL;\n\t\tskb = netdev_alloc_skb(ndev, skbuff_size);\n\t\tif (skb == NULL)\n\t\t\tbreak;\n\t\tsh_eth_set_receive_align(skb);\n\n\t\t \n\t\tbuf_len = ALIGN(mdp->rx_buf_sz, 32);\n\t\tdma_addr = dma_map_single(&mdp->pdev->dev, skb->data, buf_len,\n\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(&mdp->pdev->dev, dma_addr)) {\n\t\t\tkfree_skb(skb);\n\t\t\tbreak;\n\t\t}\n\t\tmdp->rx_skbuff[i] = skb;\n\n\t\t \n\t\trxdesc = &mdp->rx_ring[i];\n\t\trxdesc->len = cpu_to_le32(buf_len << 16);\n\t\trxdesc->addr = cpu_to_le32(dma_addr);\n\t\trxdesc->status = cpu_to_le32(RD_RACT | RD_RFP);\n\n\t\t \n\t\tif (i == 0) {\n\t\t\tsh_eth_write(ndev, mdp->rx_desc_dma, RDLAR);\n\t\t\tif (mdp->cd->xdfar_rw)\n\t\t\t\tsh_eth_write(ndev, mdp->rx_desc_dma, RDFAR);\n\t\t}\n\t}\n\n\tmdp->dirty_rx = (u32) (i - mdp->num_rx_ring);\n\n\t \n\tif (rxdesc)\n\t\trxdesc->status |= cpu_to_le32(RD_RDLE);\n\n\tmemset(mdp->tx_ring, 0, tx_ringsize);\n\n\t \n\tfor (i = 0; i < mdp->num_tx_ring; i++) {\n\t\tmdp->tx_skbuff[i] = NULL;\n\t\ttxdesc = &mdp->tx_ring[i];\n\t\ttxdesc->status = cpu_to_le32(TD_TFP);\n\t\ttxdesc->len = cpu_to_le32(0);\n\t\tif (i == 0) {\n\t\t\t \n\t\t\tsh_eth_write(ndev, mdp->tx_desc_dma, TDLAR);\n\t\t\tif (mdp->cd->xdfar_rw)\n\t\t\t\tsh_eth_write(ndev, mdp->tx_desc_dma, TDFAR);\n\t\t}\n\t}\n\n\ttxdesc->status |= cpu_to_le32(TD_TDLE);\n}\n\n \nstatic int sh_eth_ring_init(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint rx_ringsize, tx_ringsize;\n\n\t \n\tmdp->rx_buf_sz = (ndev->mtu <= 1492 ? PKT_BUF_SZ :\n\t\t\t  (((ndev->mtu + 26 + 7) & ~7) + 2 + 16));\n\tif (mdp->cd->rpadir)\n\t\tmdp->rx_buf_sz += NET_IP_ALIGN;\n\n\t \n\tmdp->rx_skbuff = kcalloc(mdp->num_rx_ring, sizeof(*mdp->rx_skbuff),\n\t\t\t\t GFP_KERNEL);\n\tif (!mdp->rx_skbuff)\n\t\treturn -ENOMEM;\n\n\tmdp->tx_skbuff = kcalloc(mdp->num_tx_ring, sizeof(*mdp->tx_skbuff),\n\t\t\t\t GFP_KERNEL);\n\tif (!mdp->tx_skbuff)\n\t\tgoto ring_free;\n\n\t \n\trx_ringsize = sizeof(struct sh_eth_rxdesc) * mdp->num_rx_ring;\n\tmdp->rx_ring = dma_alloc_coherent(&mdp->pdev->dev, rx_ringsize,\n\t\t\t\t\t  &mdp->rx_desc_dma, GFP_KERNEL);\n\tif (!mdp->rx_ring)\n\t\tgoto ring_free;\n\n\tmdp->dirty_rx = 0;\n\n\t \n\ttx_ringsize = sizeof(struct sh_eth_txdesc) * mdp->num_tx_ring;\n\tmdp->tx_ring = dma_alloc_coherent(&mdp->pdev->dev, tx_ringsize,\n\t\t\t\t\t  &mdp->tx_desc_dma, GFP_KERNEL);\n\tif (!mdp->tx_ring)\n\t\tgoto ring_free;\n\treturn 0;\n\nring_free:\n\t \n\tsh_eth_ring_free(ndev);\n\n\treturn -ENOMEM;\n}\n\nstatic int sh_eth_dev_init(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ret;\n\n\t \n\tret = mdp->cd->soft_reset(ndev);\n\tif (ret)\n\t\treturn ret;\n\n\tif (mdp->cd->rmiimode)\n\t\tsh_eth_write(ndev, 0x1, RMIIMODE);\n\n\t \n\tsh_eth_ring_format(ndev);\n\tif (mdp->cd->rpadir)\n\t\tsh_eth_write(ndev, NET_IP_ALIGN << 16, RPADIR);\n\n\t \n\tsh_eth_write(ndev, 0, EESIPR);\n\n#if defined(__LITTLE_ENDIAN)\n\tif (mdp->cd->hw_swap)\n\t\tsh_eth_write(ndev, EDMR_EL, EDMR);\n\telse\n#endif\n\t\tsh_eth_write(ndev, 0, EDMR);\n\n\t \n\tsh_eth_write(ndev, mdp->cd->fdr_value, FDR);\n\tsh_eth_write(ndev, 0, TFTR);\n\n\t \n\tsh_eth_write(ndev, RMCR_RNC, RMCR);\n\n\tsh_eth_write(ndev, mdp->cd->trscer_err_mask, TRSCER);\n\n\t \n\tif (mdp->cd->nbst)\n\t\tsh_eth_modify(ndev, EDMR, EDMR_NBST, EDMR_NBST);\n\n\t \n\tif (mdp->cd->bculr)\n\t\tsh_eth_write(ndev, 0x800, BCULR);\n\n\tsh_eth_write(ndev, mdp->cd->fcftr_value, FCFTR);\n\n\tif (!mdp->cd->no_trimd)\n\t\tsh_eth_write(ndev, 0, TRIMD);\n\n\t \n\tsh_eth_write(ndev, ndev->mtu + ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN,\n\t\t     RFLR);\n\n\tsh_eth_modify(ndev, EESR, 0, 0);\n\tmdp->irq_enabled = true;\n\tsh_eth_write(ndev, mdp->cd->eesipr_value, EESIPR);\n\n\t \n\tsh_eth_write(ndev, ECMR_ZPF | (mdp->duplex ? ECMR_DM : 0) |\n\t\t     (ndev->features & NETIF_F_RXCSUM ? ECMR_RCSC : 0) |\n\t\t     ECMR_TE | ECMR_RE, ECMR);\n\n\tif (mdp->cd->set_rate)\n\t\tmdp->cd->set_rate(ndev);\n\n\t \n\tsh_eth_write(ndev, mdp->cd->ecsr_value, ECSR);\n\n\t \n\tsh_eth_write(ndev, mdp->cd->ecsipr_value, ECSIPR);\n\n\t \n\tupdate_mac_address(ndev);\n\n\t \n\tif (mdp->cd->apr)\n\t\tsh_eth_write(ndev, 1, APR);\n\tif (mdp->cd->mpr)\n\t\tsh_eth_write(ndev, 1, MPR);\n\tif (mdp->cd->tpauser)\n\t\tsh_eth_write(ndev, TPAUSER_UNLIMITED, TPAUSER);\n\n\t \n\tsh_eth_write(ndev, EDRRR_R, EDRRR);\n\n\treturn ret;\n}\n\nstatic void sh_eth_dev_exit(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint i;\n\n\t \n\tfor (i = 0; i < mdp->num_tx_ring; i++)\n\t\tmdp->tx_ring[i].status &= ~cpu_to_le32(TD_TACT);\n\n\t \n\tsh_eth_rcv_snd_disable(ndev);\n\n\t \n\tsh_eth_write(ndev, 0, EDRRR);\n\n\t \n\tmsleep(2);  \n\tsh_eth_get_stats(ndev);\n\tmdp->cd->soft_reset(ndev);\n\n\t \n\tif (mdp->cd->rmiimode)\n\t\tsh_eth_write(ndev, 0x1, RMIIMODE);\n\n\t \n\tupdate_mac_address(ndev);\n}\n\nstatic void sh_eth_rx_csum(struct sk_buff *skb)\n{\n\tu8 *hw_csum;\n\n\t \n\tif (unlikely(skb->len < sizeof(__sum16)))\n\t\treturn;\n\thw_csum = skb_tail_pointer(skb) - sizeof(__sum16);\n\tskb->csum = csum_unfold((__force __sum16)get_unaligned_le16(hw_csum));\n\tskb->ip_summed = CHECKSUM_COMPLETE;\n\tskb_trim(skb, skb->len - sizeof(__sum16));\n}\n\n \nstatic int sh_eth_rx(struct net_device *ndev, u32 intr_status, int *quota)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct sh_eth_rxdesc *rxdesc;\n\n\tint entry = mdp->cur_rx % mdp->num_rx_ring;\n\tint boguscnt = (mdp->dirty_rx + mdp->num_rx_ring) - mdp->cur_rx;\n\tint limit;\n\tstruct sk_buff *skb;\n\tu32 desc_status;\n\tint skbuff_size = mdp->rx_buf_sz + SH_ETH_RX_ALIGN + 32 - 1;\n\tdma_addr_t dma_addr;\n\tu16 pkt_len;\n\tu32 buf_len;\n\n\tboguscnt = min(boguscnt, *quota);\n\tlimit = boguscnt;\n\trxdesc = &mdp->rx_ring[entry];\n\twhile (!(rxdesc->status & cpu_to_le32(RD_RACT))) {\n\t\t \n\t\tdma_rmb();\n\t\tdesc_status = le32_to_cpu(rxdesc->status);\n\t\tpkt_len = le32_to_cpu(rxdesc->len) & RD_RFL;\n\n\t\tif (--boguscnt < 0)\n\t\t\tbreak;\n\n\t\tnetif_info(mdp, rx_status, ndev,\n\t\t\t   \"rx entry %d status 0x%08x len %d\\n\",\n\t\t\t   entry, desc_status, pkt_len);\n\n\t\tif (!(desc_status & RDFEND))\n\t\t\tndev->stats.rx_length_errors++;\n\n\t\t \n\t\tif (mdp->cd->csmr)\n\t\t\tdesc_status >>= 16;\n\n\t\tskb = mdp->rx_skbuff[entry];\n\t\tif (desc_status & (RD_RFS1 | RD_RFS2 | RD_RFS3 | RD_RFS4 |\n\t\t\t\t   RD_RFS5 | RD_RFS6 | RD_RFS10)) {\n\t\t\tndev->stats.rx_errors++;\n\t\t\tif (desc_status & RD_RFS1)\n\t\t\t\tndev->stats.rx_crc_errors++;\n\t\t\tif (desc_status & RD_RFS2)\n\t\t\t\tndev->stats.rx_frame_errors++;\n\t\t\tif (desc_status & RD_RFS3)\n\t\t\t\tndev->stats.rx_length_errors++;\n\t\t\tif (desc_status & RD_RFS4)\n\t\t\t\tndev->stats.rx_length_errors++;\n\t\t\tif (desc_status & RD_RFS6)\n\t\t\t\tndev->stats.rx_missed_errors++;\n\t\t\tif (desc_status & RD_RFS10)\n\t\t\t\tndev->stats.rx_over_errors++;\n\t\t} else\tif (skb) {\n\t\t\tdma_addr = le32_to_cpu(rxdesc->addr);\n\t\t\tif (!mdp->cd->hw_swap)\n\t\t\t\tsh_eth_soft_swap(\n\t\t\t\t\tphys_to_virt(ALIGN(dma_addr, 4)),\n\t\t\t\t\tpkt_len + 2);\n\t\t\tmdp->rx_skbuff[entry] = NULL;\n\t\t\tif (mdp->cd->rpadir)\n\t\t\t\tskb_reserve(skb, NET_IP_ALIGN);\n\t\t\tdma_unmap_single(&mdp->pdev->dev, dma_addr,\n\t\t\t\t\t ALIGN(mdp->rx_buf_sz, 32),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tskb_put(skb, pkt_len);\n\t\t\tskb->protocol = eth_type_trans(skb, ndev);\n\t\t\tif (ndev->features & NETIF_F_RXCSUM)\n\t\t\t\tsh_eth_rx_csum(skb);\n\t\t\tnetif_receive_skb(skb);\n\t\t\tndev->stats.rx_packets++;\n\t\t\tndev->stats.rx_bytes += pkt_len;\n\t\t\tif (desc_status & RD_RFS8)\n\t\t\t\tndev->stats.multicast++;\n\t\t}\n\t\tentry = (++mdp->cur_rx) % mdp->num_rx_ring;\n\t\trxdesc = &mdp->rx_ring[entry];\n\t}\n\n\t \n\tfor (; mdp->cur_rx - mdp->dirty_rx > 0; mdp->dirty_rx++) {\n\t\tentry = mdp->dirty_rx % mdp->num_rx_ring;\n\t\trxdesc = &mdp->rx_ring[entry];\n\t\t \n\t\tbuf_len = ALIGN(mdp->rx_buf_sz, 32);\n\t\trxdesc->len = cpu_to_le32(buf_len << 16);\n\n\t\tif (mdp->rx_skbuff[entry] == NULL) {\n\t\t\tskb = netdev_alloc_skb(ndev, skbuff_size);\n\t\t\tif (skb == NULL)\n\t\t\t\tbreak;\t \n\t\t\tsh_eth_set_receive_align(skb);\n\t\t\tdma_addr = dma_map_single(&mdp->pdev->dev, skb->data,\n\t\t\t\t\t\t  buf_len, DMA_FROM_DEVICE);\n\t\t\tif (dma_mapping_error(&mdp->pdev->dev, dma_addr)) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tmdp->rx_skbuff[entry] = skb;\n\n\t\t\tskb_checksum_none_assert(skb);\n\t\t\trxdesc->addr = cpu_to_le32(dma_addr);\n\t\t}\n\t\tdma_wmb();  \n\t\tif (entry >= mdp->num_rx_ring - 1)\n\t\t\trxdesc->status |=\n\t\t\t\tcpu_to_le32(RD_RACT | RD_RFP | RD_RDLE);\n\t\telse\n\t\t\trxdesc->status |= cpu_to_le32(RD_RACT | RD_RFP);\n\t}\n\n\t \n\t \n\tif (!(sh_eth_read(ndev, EDRRR) & EDRRR_R)) {\n\t\t \n\t\tif (intr_status & EESR_RDE && !mdp->cd->no_xdfar) {\n\t\t\tu32 count = (sh_eth_read(ndev, RDFAR) -\n\t\t\t\t     sh_eth_read(ndev, RDLAR)) >> 4;\n\n\t\t\tmdp->cur_rx = count;\n\t\t\tmdp->dirty_rx = count;\n\t\t}\n\t\tsh_eth_write(ndev, EDRRR_R, EDRRR);\n\t}\n\n\t*quota -= limit - boguscnt - 1;\n\n\treturn *quota <= 0;\n}\n\nstatic void sh_eth_rcv_snd_disable(struct net_device *ndev)\n{\n\t \n\tsh_eth_modify(ndev, ECMR, ECMR_RE | ECMR_TE, 0);\n}\n\nstatic void sh_eth_rcv_snd_enable(struct net_device *ndev)\n{\n\t \n\tsh_eth_modify(ndev, ECMR, ECMR_RE | ECMR_TE, ECMR_RE | ECMR_TE);\n}\n\n \nstatic void sh_eth_emac_interrupt(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu32 felic_stat;\n\tu32 link_stat;\n\n\tfelic_stat = sh_eth_read(ndev, ECSR) & sh_eth_read(ndev, ECSIPR);\n\tsh_eth_write(ndev, felic_stat, ECSR);\t \n\tif (felic_stat & ECSR_ICD)\n\t\tndev->stats.tx_carrier_errors++;\n\tif (felic_stat & ECSR_MPD)\n\t\tpm_wakeup_event(&mdp->pdev->dev, 0);\n\tif (felic_stat & ECSR_LCHNG) {\n\t\t \n\t\tif (mdp->cd->no_psr || mdp->no_ether_link)\n\t\t\treturn;\n\t\tlink_stat = sh_eth_read(ndev, PSR);\n\t\tif (mdp->ether_link_active_low)\n\t\t\tlink_stat = ~link_stat;\n\t\tif (!(link_stat & PSR_LMON)) {\n\t\t\tsh_eth_rcv_snd_disable(ndev);\n\t\t} else {\n\t\t\t \n\t\t\tsh_eth_modify(ndev, EESIPR, EESIPR_ECIIP, 0);\n\t\t\t \n\t\t\tsh_eth_modify(ndev, ECSR, 0, 0);\n\t\t\tsh_eth_modify(ndev, EESIPR, EESIPR_ECIIP, EESIPR_ECIIP);\n\t\t\t \n\t\t\tsh_eth_rcv_snd_enable(ndev);\n\t\t}\n\t}\n}\n\n \nstatic void sh_eth_error(struct net_device *ndev, u32 intr_status)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu32 mask;\n\n\tif (intr_status & EESR_TWB) {\n\t\t \n\t\tif (intr_status & EESR_TABT) {\t \n\t\t\tndev->stats.tx_aborted_errors++;\n\t\t\tnetif_err(mdp, tx_err, ndev, \"Transmit Abort\\n\");\n\t\t}\n\t}\n\n\tif (intr_status & EESR_RABT) {\n\t\t \n\t\tif (intr_status & EESR_RFRMER) {\n\t\t\t \n\t\t\tndev->stats.rx_frame_errors++;\n\t\t}\n\t}\n\n\tif (intr_status & EESR_TDE) {\n\t\t \n\t\tndev->stats.tx_fifo_errors++;\n\t\tnetif_err(mdp, tx_err, ndev, \"Transmit Descriptor Empty\\n\");\n\t}\n\n\tif (intr_status & EESR_TFE) {\n\t\t \n\t\tndev->stats.tx_fifo_errors++;\n\t\tnetif_err(mdp, tx_err, ndev, \"Transmit FIFO Under flow\\n\");\n\t}\n\n\tif (intr_status & EESR_RDE) {\n\t\t \n\t\tndev->stats.rx_over_errors++;\n\t}\n\n\tif (intr_status & EESR_RFE) {\n\t\t \n\t\tndev->stats.rx_fifo_errors++;\n\t}\n\n\tif (!mdp->cd->no_ade && (intr_status & EESR_ADE)) {\n\t\t \n\t\tndev->stats.tx_fifo_errors++;\n\t\tnetif_err(mdp, tx_err, ndev, \"Address Error\\n\");\n\t}\n\n\tmask = EESR_TWB | EESR_TABT | EESR_ADE | EESR_TDE | EESR_TFE;\n\tif (mdp->cd->no_ade)\n\t\tmask &= ~EESR_ADE;\n\tif (intr_status & mask) {\n\t\t \n\t\tu32 edtrr = sh_eth_read(ndev, EDTRR);\n\n\t\t \n\t\tnetdev_err(ndev, \"TX error. status=%8.8x cur_tx=%8.8x dirty_tx=%8.8x state=%8.8x EDTRR=%8.8x.\\n\",\n\t\t\t   intr_status, mdp->cur_tx, mdp->dirty_tx,\n\t\t\t   (u32)ndev->state, edtrr);\n\t\t \n\t\tsh_eth_tx_free(ndev, true);\n\n\t\t \n\t\tif (edtrr ^ mdp->cd->edtrr_trns) {\n\t\t\t \n\t\t\tsh_eth_write(ndev, mdp->cd->edtrr_trns, EDTRR);\n\t\t}\n\t\t \n\t\tnetif_wake_queue(ndev);\n\t}\n}\n\nstatic irqreturn_t sh_eth_interrupt(int irq, void *netdev)\n{\n\tstruct net_device *ndev = netdev;\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct sh_eth_cpu_data *cd = mdp->cd;\n\tirqreturn_t ret = IRQ_NONE;\n\tu32 intr_status, intr_enable;\n\n\tspin_lock(&mdp->lock);\n\n\t \n\tintr_status = sh_eth_read(ndev, EESR);\n\t \n\tintr_enable = sh_eth_read(ndev, EESIPR);\n\tintr_status &= intr_enable | EESIPR_ECIIP;\n\tif (intr_status & (EESR_RX_CHECK | cd->tx_check | EESR_ECI |\n\t\t\t   cd->eesr_err_check))\n\t\tret = IRQ_HANDLED;\n\telse\n\t\tgoto out;\n\n\tif (unlikely(!mdp->irq_enabled)) {\n\t\tsh_eth_write(ndev, 0, EESIPR);\n\t\tgoto out;\n\t}\n\n\tif (intr_status & EESR_RX_CHECK) {\n\t\tif (napi_schedule_prep(&mdp->napi)) {\n\t\t\t \n\t\t\tsh_eth_write(ndev, intr_enable & ~EESR_RX_CHECK,\n\t\t\t\t     EESIPR);\n\t\t\t__napi_schedule(&mdp->napi);\n\t\t} else {\n\t\t\tnetdev_warn(ndev,\n\t\t\t\t    \"ignoring interrupt, status 0x%08x, mask 0x%08x.\\n\",\n\t\t\t\t    intr_status, intr_enable);\n\t\t}\n\t}\n\n\t \n\tif (intr_status & cd->tx_check) {\n\t\t \n\t\tsh_eth_write(ndev, intr_status & cd->tx_check, EESR);\n\n\t\tsh_eth_tx_free(ndev, true);\n\t\tnetif_wake_queue(ndev);\n\t}\n\n\t \n\tif (intr_status & EESR_ECI)\n\t\tsh_eth_emac_interrupt(ndev);\n\n\tif (intr_status & cd->eesr_err_check) {\n\t\t \n\t\tsh_eth_write(ndev, intr_status & cd->eesr_err_check, EESR);\n\n\t\tsh_eth_error(ndev, intr_status);\n\t}\n\nout:\n\tspin_unlock(&mdp->lock);\n\n\treturn ret;\n}\n\nstatic int sh_eth_poll(struct napi_struct *napi, int budget)\n{\n\tstruct sh_eth_private *mdp = container_of(napi, struct sh_eth_private,\n\t\t\t\t\t\t  napi);\n\tstruct net_device *ndev = napi->dev;\n\tint quota = budget;\n\tu32 intr_status;\n\n\tfor (;;) {\n\t\tintr_status = sh_eth_read(ndev, EESR);\n\t\tif (!(intr_status & EESR_RX_CHECK))\n\t\t\tbreak;\n\t\t \n\t\tsh_eth_write(ndev, intr_status & EESR_RX_CHECK, EESR);\n\n\t\tif (sh_eth_rx(ndev, intr_status, &quota))\n\t\t\tgoto out;\n\t}\n\n\tnapi_complete(napi);\n\n\t \n\tif (mdp->irq_enabled)\n\t\tsh_eth_write(ndev, mdp->cd->eesipr_value, EESIPR);\nout:\n\treturn budget - quota;\n}\n\n \nstatic void sh_eth_adjust_link(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct phy_device *phydev = ndev->phydev;\n\tunsigned long flags;\n\tint new_state = 0;\n\n\tspin_lock_irqsave(&mdp->lock, flags);\n\n\t \n\tif (mdp->cd->no_psr || mdp->no_ether_link)\n\t\tsh_eth_rcv_snd_disable(ndev);\n\n\tif (phydev->link) {\n\t\tif (phydev->duplex != mdp->duplex) {\n\t\t\tnew_state = 1;\n\t\t\tmdp->duplex = phydev->duplex;\n\t\t\tif (mdp->cd->set_duplex)\n\t\t\t\tmdp->cd->set_duplex(ndev);\n\t\t}\n\n\t\tif (phydev->speed != mdp->speed) {\n\t\t\tnew_state = 1;\n\t\t\tmdp->speed = phydev->speed;\n\t\t\tif (mdp->cd->set_rate)\n\t\t\t\tmdp->cd->set_rate(ndev);\n\t\t}\n\t\tif (!mdp->link) {\n\t\t\tsh_eth_modify(ndev, ECMR, ECMR_TXF, 0);\n\t\t\tnew_state = 1;\n\t\t\tmdp->link = phydev->link;\n\t\t}\n\t} else if (mdp->link) {\n\t\tnew_state = 1;\n\t\tmdp->link = 0;\n\t\tmdp->speed = 0;\n\t\tmdp->duplex = -1;\n\t}\n\n\t \n\tif ((mdp->cd->no_psr || mdp->no_ether_link) && phydev->link)\n\t\tsh_eth_rcv_snd_enable(ndev);\n\n\tspin_unlock_irqrestore(&mdp->lock, flags);\n\n\tif (new_state && netif_msg_link(mdp))\n\t\tphy_print_status(phydev);\n}\n\n \nstatic int sh_eth_phy_init(struct net_device *ndev)\n{\n\tstruct device_node *np = ndev->dev.parent->of_node;\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct phy_device *phydev;\n\n\tmdp->link = 0;\n\tmdp->speed = 0;\n\tmdp->duplex = -1;\n\n\t \n\tif (np) {\n\t\tstruct device_node *pn;\n\n\t\tpn = of_parse_phandle(np, \"phy-handle\", 0);\n\t\tphydev = of_phy_connect(ndev, pn,\n\t\t\t\t\tsh_eth_adjust_link, 0,\n\t\t\t\t\tmdp->phy_interface);\n\n\t\tof_node_put(pn);\n\t\tif (!phydev)\n\t\t\tphydev = ERR_PTR(-ENOENT);\n\t} else {\n\t\tchar phy_id[MII_BUS_ID_SIZE + 3];\n\n\t\tsnprintf(phy_id, sizeof(phy_id), PHY_ID_FMT,\n\t\t\t mdp->mii_bus->id, mdp->phy_id);\n\n\t\tphydev = phy_connect(ndev, phy_id, sh_eth_adjust_link,\n\t\t\t\t     mdp->phy_interface);\n\t}\n\n\tif (IS_ERR(phydev)) {\n\t\tnetdev_err(ndev, \"failed to connect PHY\\n\");\n\t\treturn PTR_ERR(phydev);\n\t}\n\n\t \n\tif (mdp->cd->register_type != SH_ETH_REG_GIGABIT)\n\t\tphy_set_max_speed(phydev, SPEED_100);\n\n\tphy_attached_info(phydev);\n\n\treturn 0;\n}\n\n \nstatic int sh_eth_phy_start(struct net_device *ndev)\n{\n\tint ret;\n\n\tret = sh_eth_phy_init(ndev);\n\tif (ret)\n\t\treturn ret;\n\n\tphy_start(ndev->phydev);\n\n\treturn 0;\n}\n\n \n#define SH_ETH_REG_DUMP_VERSION\t\t1\n#define SH_ETH_REG_DUMP_MAX_REGS\t256\n\nstatic size_t __sh_eth_get_regs(struct net_device *ndev, u32 *buf)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct sh_eth_cpu_data *cd = mdp->cd;\n\tu32 *valid_map;\n\tsize_t len;\n\n\tBUILD_BUG_ON(SH_ETH_MAX_REGISTER_OFFSET > SH_ETH_REG_DUMP_MAX_REGS);\n\n\t \n\tlen = DIV_ROUND_UP(SH_ETH_REG_DUMP_MAX_REGS, 32);\n\tif (buf) {\n\t\tvalid_map = buf;\n\t\tbuf += len;\n\t} else {\n\t\tvalid_map = NULL;\n\t}\n\n\t \n#define mark_reg_valid(reg) valid_map[reg / 32] |= 1U << (reg % 32)\n#define add_reg_from(reg, read_expr) do {\t\t\t\t\\\n\t\tif (mdp->reg_offset[reg] != SH_ETH_OFFSET_INVALID) {\t\\\n\t\t\tif (buf) {\t\t\t\t\t\\\n\t\t\t\tmark_reg_valid(reg);\t\t\t\\\n\t\t\t\t*buf++ = read_expr;\t\t\t\\\n\t\t\t}\t\t\t\t\t\t\\\n\t\t\t++len;\t\t\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t} while (0)\n#define add_reg(reg) add_reg_from(reg, sh_eth_read(ndev, reg))\n#define add_tsu_reg(reg) add_reg_from(reg, sh_eth_tsu_read(mdp, reg))\n\n\tadd_reg(EDSR);\n\tadd_reg(EDMR);\n\tadd_reg(EDTRR);\n\tadd_reg(EDRRR);\n\tadd_reg(EESR);\n\tadd_reg(EESIPR);\n\tadd_reg(TDLAR);\n\tif (!cd->no_xdfar)\n\t\tadd_reg(TDFAR);\n\tadd_reg(TDFXR);\n\tadd_reg(TDFFR);\n\tadd_reg(RDLAR);\n\tif (!cd->no_xdfar)\n\t\tadd_reg(RDFAR);\n\tadd_reg(RDFXR);\n\tadd_reg(RDFFR);\n\tadd_reg(TRSCER);\n\tadd_reg(RMFCR);\n\tadd_reg(TFTR);\n\tadd_reg(FDR);\n\tadd_reg(RMCR);\n\tadd_reg(TFUCR);\n\tadd_reg(RFOCR);\n\tif (cd->rmiimode)\n\t\tadd_reg(RMIIMODE);\n\tadd_reg(FCFTR);\n\tif (cd->rpadir)\n\t\tadd_reg(RPADIR);\n\tif (!cd->no_trimd)\n\t\tadd_reg(TRIMD);\n\tadd_reg(ECMR);\n\tadd_reg(ECSR);\n\tadd_reg(ECSIPR);\n\tadd_reg(PIR);\n\tif (!cd->no_psr)\n\t\tadd_reg(PSR);\n\tadd_reg(RDMLR);\n\tadd_reg(RFLR);\n\tadd_reg(IPGR);\n\tif (cd->apr)\n\t\tadd_reg(APR);\n\tif (cd->mpr)\n\t\tadd_reg(MPR);\n\tadd_reg(RFCR);\n\tadd_reg(RFCF);\n\tif (cd->tpauser)\n\t\tadd_reg(TPAUSER);\n\tadd_reg(TPAUSECR);\n\tif (cd->gecmr)\n\t\tadd_reg(GECMR);\n\tif (cd->bculr)\n\t\tadd_reg(BCULR);\n\tadd_reg(MAHR);\n\tadd_reg(MALR);\n\tif (!cd->no_tx_cntrs) {\n\t\tadd_reg(TROCR);\n\t\tadd_reg(CDCR);\n\t\tadd_reg(LCCR);\n\t\tadd_reg(CNDCR);\n\t}\n\tadd_reg(CEFCR);\n\tadd_reg(FRECR);\n\tadd_reg(TSFRCR);\n\tadd_reg(TLFRCR);\n\tif (cd->cexcr) {\n\t\tadd_reg(CERCR);\n\t\tadd_reg(CEECR);\n\t}\n\tadd_reg(MAFCR);\n\tif (cd->rtrate)\n\t\tadd_reg(RTRATE);\n\tif (cd->csmr)\n\t\tadd_reg(CSMR);\n\tif (cd->select_mii)\n\t\tadd_reg(RMII_MII);\n\tif (cd->tsu) {\n\t\tadd_tsu_reg(ARSTR);\n\t\tadd_tsu_reg(TSU_CTRST);\n\t\tif (cd->dual_port) {\n\t\t\tadd_tsu_reg(TSU_FWEN0);\n\t\t\tadd_tsu_reg(TSU_FWEN1);\n\t\t\tadd_tsu_reg(TSU_FCM);\n\t\t\tadd_tsu_reg(TSU_BSYSL0);\n\t\t\tadd_tsu_reg(TSU_BSYSL1);\n\t\t\tadd_tsu_reg(TSU_PRISL0);\n\t\t\tadd_tsu_reg(TSU_PRISL1);\n\t\t\tadd_tsu_reg(TSU_FWSL0);\n\t\t\tadd_tsu_reg(TSU_FWSL1);\n\t\t}\n\t\tadd_tsu_reg(TSU_FWSLC);\n\t\tif (cd->dual_port) {\n\t\t\tadd_tsu_reg(TSU_QTAGM0);\n\t\t\tadd_tsu_reg(TSU_QTAGM1);\n\t\t\tadd_tsu_reg(TSU_FWSR);\n\t\t\tadd_tsu_reg(TSU_FWINMK);\n\t\t\tadd_tsu_reg(TSU_ADQT0);\n\t\t\tadd_tsu_reg(TSU_ADQT1);\n\t\t\tadd_tsu_reg(TSU_VTAG0);\n\t\t\tadd_tsu_reg(TSU_VTAG1);\n\t\t}\n\t\tadd_tsu_reg(TSU_ADSBSY);\n\t\tadd_tsu_reg(TSU_TEN);\n\t\tadd_tsu_reg(TSU_POST1);\n\t\tadd_tsu_reg(TSU_POST2);\n\t\tadd_tsu_reg(TSU_POST3);\n\t\tadd_tsu_reg(TSU_POST4);\n\t\t \n\t\tif (buf) {\n\t\t\tunsigned int i;\n\n\t\t\tmark_reg_valid(TSU_ADRH0);\n\t\t\tfor (i = 0; i < SH_ETH_TSU_CAM_ENTRIES * 2; i++)\n\t\t\t\t*buf++ = ioread32(mdp->tsu_addr +\n\t\t\t\t\t\t  mdp->reg_offset[TSU_ADRH0] +\n\t\t\t\t\t\t  i * 4);\n\t\t}\n\t\tlen += SH_ETH_TSU_CAM_ENTRIES * 2;\n\t}\n\n#undef mark_reg_valid\n#undef add_reg_from\n#undef add_reg\n#undef add_tsu_reg\n\n\treturn len * 4;\n}\n\nstatic int sh_eth_get_regs_len(struct net_device *ndev)\n{\n\treturn __sh_eth_get_regs(ndev, NULL);\n}\n\nstatic void sh_eth_get_regs(struct net_device *ndev, struct ethtool_regs *regs,\n\t\t\t    void *buf)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tregs->version = SH_ETH_REG_DUMP_VERSION;\n\n\tpm_runtime_get_sync(&mdp->pdev->dev);\n\t__sh_eth_get_regs(ndev, buf);\n\tpm_runtime_put_sync(&mdp->pdev->dev);\n}\n\nstatic u32 sh_eth_get_msglevel(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\treturn mdp->msg_enable;\n}\n\nstatic void sh_eth_set_msglevel(struct net_device *ndev, u32 value)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tmdp->msg_enable = value;\n}\n\nstatic const char sh_eth_gstrings_stats[][ETH_GSTRING_LEN] = {\n\t\"rx_current\", \"tx_current\",\n\t\"rx_dirty\", \"tx_dirty\",\n};\n#define SH_ETH_STATS_LEN  ARRAY_SIZE(sh_eth_gstrings_stats)\n\nstatic int sh_eth_get_sset_count(struct net_device *netdev, int sset)\n{\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn SH_ETH_STATS_LEN;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void sh_eth_get_ethtool_stats(struct net_device *ndev,\n\t\t\t\t     struct ethtool_stats *stats, u64 *data)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint i = 0;\n\n\t \n\tdata[i++] = mdp->cur_rx;\n\tdata[i++] = mdp->cur_tx;\n\tdata[i++] = mdp->dirty_rx;\n\tdata[i++] = mdp->dirty_tx;\n}\n\nstatic void sh_eth_get_strings(struct net_device *ndev, u32 stringset, u8 *data)\n{\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tmemcpy(data, sh_eth_gstrings_stats,\n\t\t       sizeof(sh_eth_gstrings_stats));\n\t\tbreak;\n\t}\n}\n\nstatic void sh_eth_get_ringparam(struct net_device *ndev,\n\t\t\t\t struct ethtool_ringparam *ring,\n\t\t\t\t struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tring->rx_max_pending = RX_RING_MAX;\n\tring->tx_max_pending = TX_RING_MAX;\n\tring->rx_pending = mdp->num_rx_ring;\n\tring->tx_pending = mdp->num_tx_ring;\n}\n\nstatic int sh_eth_set_ringparam(struct net_device *ndev,\n\t\t\t\tstruct ethtool_ringparam *ring,\n\t\t\t\tstruct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ret;\n\n\tif (ring->tx_pending > TX_RING_MAX ||\n\t    ring->rx_pending > RX_RING_MAX ||\n\t    ring->tx_pending < TX_RING_MIN ||\n\t    ring->rx_pending < RX_RING_MIN)\n\t\treturn -EINVAL;\n\tif (ring->rx_mini_pending || ring->rx_jumbo_pending)\n\t\treturn -EINVAL;\n\n\tif (netif_running(ndev)) {\n\t\tnetif_device_detach(ndev);\n\t\tnetif_tx_disable(ndev);\n\n\t\t \n\t\tmdp->irq_enabled = false;\n\t\tsynchronize_irq(ndev->irq);\n\t\tnapi_synchronize(&mdp->napi);\n\t\tsh_eth_write(ndev, 0x0000, EESIPR);\n\n\t\tsh_eth_dev_exit(ndev);\n\n\t\t \n\t\tsh_eth_ring_free(ndev);\n\t}\n\n\t \n\tmdp->num_rx_ring = ring->rx_pending;\n\tmdp->num_tx_ring = ring->tx_pending;\n\n\tif (netif_running(ndev)) {\n\t\tret = sh_eth_ring_init(ndev);\n\t\tif (ret < 0) {\n\t\t\tnetdev_err(ndev, \"%s: sh_eth_ring_init failed.\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn ret;\n\t\t}\n\t\tret = sh_eth_dev_init(ndev);\n\t\tif (ret < 0) {\n\t\t\tnetdev_err(ndev, \"%s: sh_eth_dev_init failed.\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn ret;\n\t\t}\n\n\t\tnetif_device_attach(ndev);\n\t}\n\n\treturn 0;\n}\n\nstatic void sh_eth_get_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\twol->supported = 0;\n\twol->wolopts = 0;\n\n\tif (mdp->cd->magic) {\n\t\twol->supported = WAKE_MAGIC;\n\t\twol->wolopts = mdp->wol_enabled ? WAKE_MAGIC : 0;\n\t}\n}\n\nstatic int sh_eth_set_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tif (!mdp->cd->magic || wol->wolopts & ~WAKE_MAGIC)\n\t\treturn -EOPNOTSUPP;\n\n\tmdp->wol_enabled = !!(wol->wolopts & WAKE_MAGIC);\n\n\tdevice_set_wakeup_enable(&mdp->pdev->dev, mdp->wol_enabled);\n\n\treturn 0;\n}\n\nstatic const struct ethtool_ops sh_eth_ethtool_ops = {\n\t.get_regs_len\t= sh_eth_get_regs_len,\n\t.get_regs\t= sh_eth_get_regs,\n\t.nway_reset\t= phy_ethtool_nway_reset,\n\t.get_msglevel\t= sh_eth_get_msglevel,\n\t.set_msglevel\t= sh_eth_set_msglevel,\n\t.get_link\t= ethtool_op_get_link,\n\t.get_strings\t= sh_eth_get_strings,\n\t.get_ethtool_stats  = sh_eth_get_ethtool_stats,\n\t.get_sset_count     = sh_eth_get_sset_count,\n\t.get_ringparam\t= sh_eth_get_ringparam,\n\t.set_ringparam\t= sh_eth_set_ringparam,\n\t.get_link_ksettings = phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings = phy_ethtool_set_link_ksettings,\n\t.get_wol\t= sh_eth_get_wol,\n\t.set_wol\t= sh_eth_set_wol,\n};\n\n \nstatic int sh_eth_open(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ret;\n\n\tpm_runtime_get_sync(&mdp->pdev->dev);\n\n\tnapi_enable(&mdp->napi);\n\n\tret = request_irq(ndev->irq, sh_eth_interrupt,\n\t\t\t  mdp->cd->irq_flags, ndev->name, ndev);\n\tif (ret) {\n\t\tnetdev_err(ndev, \"Can not assign IRQ number\\n\");\n\t\tgoto out_napi_off;\n\t}\n\n\t \n\tret = sh_eth_ring_init(ndev);\n\tif (ret)\n\t\tgoto out_free_irq;\n\n\t \n\tret = sh_eth_dev_init(ndev);\n\tif (ret)\n\t\tgoto out_free_irq;\n\n\t \n\tret = sh_eth_phy_start(ndev);\n\tif (ret)\n\t\tgoto out_free_irq;\n\n\tnetif_start_queue(ndev);\n\n\tmdp->is_opened = 1;\n\n\treturn ret;\n\nout_free_irq:\n\tfree_irq(ndev->irq, ndev);\nout_napi_off:\n\tnapi_disable(&mdp->napi);\n\tpm_runtime_put_sync(&mdp->pdev->dev);\n\treturn ret;\n}\n\n \nstatic void sh_eth_tx_timeout(struct net_device *ndev, unsigned int txqueue)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct sh_eth_rxdesc *rxdesc;\n\tint i;\n\n\tnetif_stop_queue(ndev);\n\n\tnetif_err(mdp, timer, ndev,\n\t\t  \"transmit timed out, status %8.8x, resetting...\\n\",\n\t\t  sh_eth_read(ndev, EESR));\n\n\t \n\tndev->stats.tx_errors++;\n\n\t \n\tfor (i = 0; i < mdp->num_rx_ring; i++) {\n\t\trxdesc = &mdp->rx_ring[i];\n\t\trxdesc->status = cpu_to_le32(0);\n\t\trxdesc->addr = cpu_to_le32(0xBADF00D0);\n\t\tdev_kfree_skb(mdp->rx_skbuff[i]);\n\t\tmdp->rx_skbuff[i] = NULL;\n\t}\n\tfor (i = 0; i < mdp->num_tx_ring; i++) {\n\t\tdev_kfree_skb(mdp->tx_skbuff[i]);\n\t\tmdp->tx_skbuff[i] = NULL;\n\t}\n\n\t \n\tsh_eth_dev_init(ndev);\n\n\tnetif_start_queue(ndev);\n}\n\n \nstatic netdev_tx_t sh_eth_start_xmit(struct sk_buff *skb,\n\t\t\t\t     struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tstruct sh_eth_txdesc *txdesc;\n\tdma_addr_t dma_addr;\n\tu32 entry;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&mdp->lock, flags);\n\tif ((mdp->cur_tx - mdp->dirty_tx) >= (mdp->num_tx_ring - 4)) {\n\t\tif (!sh_eth_tx_free(ndev, true)) {\n\t\t\tnetif_warn(mdp, tx_queued, ndev, \"TxFD exhausted.\\n\");\n\t\t\tnetif_stop_queue(ndev);\n\t\t\tspin_unlock_irqrestore(&mdp->lock, flags);\n\t\t\treturn NETDEV_TX_BUSY;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&mdp->lock, flags);\n\n\tif (skb_put_padto(skb, ETH_ZLEN))\n\t\treturn NETDEV_TX_OK;\n\n\tentry = mdp->cur_tx % mdp->num_tx_ring;\n\tmdp->tx_skbuff[entry] = skb;\n\ttxdesc = &mdp->tx_ring[entry];\n\t \n\tif (!mdp->cd->hw_swap)\n\t\tsh_eth_soft_swap(PTR_ALIGN(skb->data, 4), skb->len + 2);\n\tdma_addr = dma_map_single(&mdp->pdev->dev, skb->data, skb->len,\n\t\t\t\t  DMA_TO_DEVICE);\n\tif (dma_mapping_error(&mdp->pdev->dev, dma_addr)) {\n\t\tkfree_skb(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\ttxdesc->addr = cpu_to_le32(dma_addr);\n\ttxdesc->len  = cpu_to_le32(skb->len << 16);\n\n\tdma_wmb();  \n\tif (entry >= mdp->num_tx_ring - 1)\n\t\ttxdesc->status |= cpu_to_le32(TD_TACT | TD_TDLE);\n\telse\n\t\ttxdesc->status |= cpu_to_le32(TD_TACT);\n\n\twmb();  \n\tmdp->cur_tx++;\n\n\tif (!(sh_eth_read(ndev, EDTRR) & mdp->cd->edtrr_trns))\n\t\tsh_eth_write(ndev, mdp->cd->edtrr_trns, EDTRR);\n\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic void\nsh_eth_update_stat(struct net_device *ndev, unsigned long *stat, int reg)\n{\n\tu32 delta = sh_eth_read(ndev, reg);\n\n\tif (delta) {\n\t\t*stat += delta;\n\t\tsh_eth_write(ndev, 0, reg);\n\t}\n}\n\nstatic struct net_device_stats *sh_eth_get_stats(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tif (mdp->cd->no_tx_cntrs)\n\t\treturn &ndev->stats;\n\n\tif (!mdp->is_opened)\n\t\treturn &ndev->stats;\n\n\tsh_eth_update_stat(ndev, &ndev->stats.tx_dropped, TROCR);\n\tsh_eth_update_stat(ndev, &ndev->stats.collisions, CDCR);\n\tsh_eth_update_stat(ndev, &ndev->stats.tx_carrier_errors, LCCR);\n\n\tif (mdp->cd->cexcr) {\n\t\tsh_eth_update_stat(ndev, &ndev->stats.tx_carrier_errors,\n\t\t\t\t   CERCR);\n\t\tsh_eth_update_stat(ndev, &ndev->stats.tx_carrier_errors,\n\t\t\t\t   CEECR);\n\t} else {\n\t\tsh_eth_update_stat(ndev, &ndev->stats.tx_carrier_errors,\n\t\t\t\t   CNDCR);\n\t}\n\n\treturn &ndev->stats;\n}\n\n \nstatic int sh_eth_close(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tnetif_stop_queue(ndev);\n\n\t \n\tmdp->irq_enabled = false;\n\tsynchronize_irq(ndev->irq);\n\tnapi_disable(&mdp->napi);\n\tsh_eth_write(ndev, 0x0000, EESIPR);\n\n\tsh_eth_dev_exit(ndev);\n\n\t \n\tif (ndev->phydev) {\n\t\tphy_stop(ndev->phydev);\n\t\tphy_disconnect(ndev->phydev);\n\t}\n\n\tfree_irq(ndev->irq, ndev);\n\n\t \n\tsh_eth_ring_free(ndev);\n\n\tmdp->is_opened = 0;\n\n\tpm_runtime_put(&mdp->pdev->dev);\n\n\treturn 0;\n}\n\nstatic int sh_eth_change_mtu(struct net_device *ndev, int new_mtu)\n{\n\tif (netif_running(ndev))\n\t\treturn -EBUSY;\n\n\tndev->mtu = new_mtu;\n\tnetdev_update_features(ndev);\n\n\treturn 0;\n}\n\n \nstatic u32 sh_eth_tsu_get_post_mask(int entry)\n{\n\treturn 0x0f << (28 - ((entry % 8) * 4));\n}\n\nstatic u32 sh_eth_tsu_get_post_bit(struct sh_eth_private *mdp, int entry)\n{\n\treturn (0x08 >> (mdp->port << 1)) << (28 - ((entry % 8) * 4));\n}\n\nstatic void sh_eth_tsu_enable_cam_entry_post(struct net_device *ndev,\n\t\t\t\t\t     int entry)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint reg = TSU_POST1 + entry / 8;\n\tu32 tmp;\n\n\ttmp = sh_eth_tsu_read(mdp, reg);\n\tsh_eth_tsu_write(mdp, tmp | sh_eth_tsu_get_post_bit(mdp, entry), reg);\n}\n\nstatic bool sh_eth_tsu_disable_cam_entry_post(struct net_device *ndev,\n\t\t\t\t\t      int entry)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint reg = TSU_POST1 + entry / 8;\n\tu32 post_mask, ref_mask, tmp;\n\n\tpost_mask = sh_eth_tsu_get_post_mask(entry);\n\tref_mask = sh_eth_tsu_get_post_bit(mdp, entry) & ~post_mask;\n\n\ttmp = sh_eth_tsu_read(mdp, reg);\n\tsh_eth_tsu_write(mdp, tmp & ~post_mask, reg);\n\n\t \n\treturn tmp & ref_mask;\n}\n\nstatic int sh_eth_tsu_busy(struct net_device *ndev)\n{\n\tint timeout = SH_ETH_TSU_TIMEOUT_MS * 100;\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\twhile ((sh_eth_tsu_read(mdp, TSU_ADSBSY) & TSU_ADSBSY_0)) {\n\t\tudelay(10);\n\t\ttimeout--;\n\t\tif (timeout <= 0) {\n\t\t\tnetdev_err(ndev, \"%s: timeout\\n\", __func__);\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int sh_eth_tsu_write_entry(struct net_device *ndev, u16 offset,\n\t\t\t\t  const u8 *addr)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu32 val;\n\n\tval = addr[0] << 24 | addr[1] << 16 | addr[2] << 8 | addr[3];\n\tiowrite32(val, mdp->tsu_addr + offset);\n\tif (sh_eth_tsu_busy(ndev) < 0)\n\t\treturn -EBUSY;\n\n\tval = addr[4] << 8 | addr[5];\n\tiowrite32(val, mdp->tsu_addr + offset + 4);\n\tif (sh_eth_tsu_busy(ndev) < 0)\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\nstatic void sh_eth_tsu_read_entry(struct net_device *ndev, u16 offset, u8 *addr)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu32 val;\n\n\tval = ioread32(mdp->tsu_addr + offset);\n\taddr[0] = (val >> 24) & 0xff;\n\taddr[1] = (val >> 16) & 0xff;\n\taddr[2] = (val >> 8) & 0xff;\n\taddr[3] = val & 0xff;\n\tval = ioread32(mdp->tsu_addr + offset + 4);\n\taddr[4] = (val >> 8) & 0xff;\n\taddr[5] = val & 0xff;\n}\n\n\nstatic int sh_eth_tsu_find_entry(struct net_device *ndev, const u8 *addr)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu16 reg_offset = sh_eth_tsu_get_offset(mdp, TSU_ADRH0);\n\tint i;\n\tu8 c_addr[ETH_ALEN];\n\n\tfor (i = 0; i < SH_ETH_TSU_CAM_ENTRIES; i++, reg_offset += 8) {\n\t\tsh_eth_tsu_read_entry(ndev, reg_offset, c_addr);\n\t\tif (ether_addr_equal(addr, c_addr))\n\t\t\treturn i;\n\t}\n\n\treturn -ENOENT;\n}\n\nstatic int sh_eth_tsu_find_empty(struct net_device *ndev)\n{\n\tu8 blank[ETH_ALEN];\n\tint entry;\n\n\tmemset(blank, 0, sizeof(blank));\n\tentry = sh_eth_tsu_find_entry(ndev, blank);\n\treturn (entry < 0) ? -ENOMEM : entry;\n}\n\nstatic int sh_eth_tsu_disable_cam_entry_table(struct net_device *ndev,\n\t\t\t\t\t      int entry)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu16 reg_offset = sh_eth_tsu_get_offset(mdp, TSU_ADRH0);\n\tint ret;\n\tu8 blank[ETH_ALEN];\n\n\tsh_eth_tsu_write(mdp, sh_eth_tsu_read(mdp, TSU_TEN) &\n\t\t\t ~(1 << (31 - entry)), TSU_TEN);\n\n\tmemset(blank, 0, sizeof(blank));\n\tret = sh_eth_tsu_write_entry(ndev, reg_offset + entry * 8, blank);\n\tif (ret < 0)\n\t\treturn ret;\n\treturn 0;\n}\n\nstatic int sh_eth_tsu_add_entry(struct net_device *ndev, const u8 *addr)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu16 reg_offset = sh_eth_tsu_get_offset(mdp, TSU_ADRH0);\n\tint i, ret;\n\n\tif (!mdp->cd->tsu)\n\t\treturn 0;\n\n\ti = sh_eth_tsu_find_entry(ndev, addr);\n\tif (i < 0) {\n\t\t \n\t\ti = sh_eth_tsu_find_empty(ndev);\n\t\tif (i < 0)\n\t\t\treturn -ENOMEM;\n\t\tret = sh_eth_tsu_write_entry(ndev, reg_offset + i * 8, addr);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\t \n\t\tsh_eth_tsu_write(mdp, sh_eth_tsu_read(mdp, TSU_TEN) |\n\t\t\t\t (1 << (31 - i)), TSU_TEN);\n\t}\n\n\t \n\tsh_eth_tsu_enable_cam_entry_post(ndev, i);\n\n\treturn 0;\n}\n\nstatic int sh_eth_tsu_del_entry(struct net_device *ndev, const u8 *addr)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint i, ret;\n\n\tif (!mdp->cd->tsu)\n\t\treturn 0;\n\n\ti = sh_eth_tsu_find_entry(ndev, addr);\n\tif (i) {\n\t\t \n\t\tif (sh_eth_tsu_disable_cam_entry_post(ndev, i))\n\t\t\tgoto done;\n\n\t\t \n\t\tret = sh_eth_tsu_disable_cam_entry_table(ndev, i);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\ndone:\n\treturn 0;\n}\n\nstatic int sh_eth_tsu_purge_all(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint i, ret;\n\n\tif (!mdp->cd->tsu)\n\t\treturn 0;\n\n\tfor (i = 0; i < SH_ETH_TSU_CAM_ENTRIES; i++) {\n\t\tif (sh_eth_tsu_disable_cam_entry_post(ndev, i))\n\t\t\tcontinue;\n\n\t\t \n\t\tret = sh_eth_tsu_disable_cam_entry_table(ndev, i);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void sh_eth_tsu_purge_mcast(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu16 reg_offset = sh_eth_tsu_get_offset(mdp, TSU_ADRH0);\n\tu8 addr[ETH_ALEN];\n\tint i;\n\n\tif (!mdp->cd->tsu)\n\t\treturn;\n\n\tfor (i = 0; i < SH_ETH_TSU_CAM_ENTRIES; i++, reg_offset += 8) {\n\t\tsh_eth_tsu_read_entry(ndev, reg_offset, addr);\n\t\tif (is_multicast_ether_addr(addr))\n\t\t\tsh_eth_tsu_del_entry(ndev, addr);\n\t}\n}\n\n \nstatic void sh_eth_set_rx_mode(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tu32 ecmr_bits;\n\tint mcast_all = 0;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&mdp->lock, flags);\n\t \n\tecmr_bits = sh_eth_read(ndev, ECMR) & ~ECMR_PRM;\n\tif (mdp->cd->tsu)\n\t\tecmr_bits |= ECMR_MCT;\n\n\tif (!(ndev->flags & IFF_MULTICAST)) {\n\t\tsh_eth_tsu_purge_mcast(ndev);\n\t\tmcast_all = 1;\n\t}\n\tif (ndev->flags & IFF_ALLMULTI) {\n\t\tsh_eth_tsu_purge_mcast(ndev);\n\t\tecmr_bits &= ~ECMR_MCT;\n\t\tmcast_all = 1;\n\t}\n\n\tif (ndev->flags & IFF_PROMISC) {\n\t\tsh_eth_tsu_purge_all(ndev);\n\t\tecmr_bits = (ecmr_bits & ~ECMR_MCT) | ECMR_PRM;\n\t} else if (mdp->cd->tsu) {\n\t\tstruct netdev_hw_addr *ha;\n\t\tnetdev_for_each_mc_addr(ha, ndev) {\n\t\t\tif (mcast_all && is_multicast_ether_addr(ha->addr))\n\t\t\t\tcontinue;\n\n\t\t\tif (sh_eth_tsu_add_entry(ndev, ha->addr) < 0) {\n\t\t\t\tif (!mcast_all) {\n\t\t\t\t\tsh_eth_tsu_purge_mcast(ndev);\n\t\t\t\t\tecmr_bits &= ~ECMR_MCT;\n\t\t\t\t\tmcast_all = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tsh_eth_write(ndev, ecmr_bits, ECMR);\n\n\tspin_unlock_irqrestore(&mdp->lock, flags);\n}\n\nstatic void sh_eth_set_rx_csum(struct net_device *ndev, bool enable)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&mdp->lock, flags);\n\n\t \n\tsh_eth_rcv_snd_disable(ndev);\n\n\t \n\tsh_eth_modify(ndev, ECMR, ECMR_RCSC, enable ? ECMR_RCSC : 0);\n\n\t \n\tsh_eth_rcv_snd_enable(ndev);\n\n\tspin_unlock_irqrestore(&mdp->lock, flags);\n}\n\nstatic int sh_eth_set_features(struct net_device *ndev,\n\t\t\t       netdev_features_t features)\n{\n\tnetdev_features_t changed = ndev->features ^ features;\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tif (changed & NETIF_F_RXCSUM && mdp->cd->rx_csum)\n\t\tsh_eth_set_rx_csum(ndev, features & NETIF_F_RXCSUM);\n\n\tndev->features = features;\n\n\treturn 0;\n}\n\nstatic int sh_eth_get_vtag_index(struct sh_eth_private *mdp)\n{\n\tif (!mdp->port)\n\t\treturn TSU_VTAG0;\n\telse\n\t\treturn TSU_VTAG1;\n}\n\nstatic int sh_eth_vlan_rx_add_vid(struct net_device *ndev,\n\t\t\t\t  __be16 proto, u16 vid)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint vtag_reg_index = sh_eth_get_vtag_index(mdp);\n\n\tif (unlikely(!mdp->cd->tsu))\n\t\treturn -EPERM;\n\n\t \n\tif (!vid)\n\t\treturn 0;\n\n\tmdp->vlan_num_ids++;\n\n\t \n\tif (mdp->vlan_num_ids > 1) {\n\t\t \n\t\tsh_eth_tsu_write(mdp, 0, vtag_reg_index);\n\t\treturn 0;\n\t}\n\n\tsh_eth_tsu_write(mdp, TSU_VTAG_ENABLE | (vid & TSU_VTAG_VID_MASK),\n\t\t\t vtag_reg_index);\n\n\treturn 0;\n}\n\nstatic int sh_eth_vlan_rx_kill_vid(struct net_device *ndev,\n\t\t\t\t   __be16 proto, u16 vid)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint vtag_reg_index = sh_eth_get_vtag_index(mdp);\n\n\tif (unlikely(!mdp->cd->tsu))\n\t\treturn -EPERM;\n\n\t \n\tif (!vid)\n\t\treturn 0;\n\n\tmdp->vlan_num_ids--;\n\tsh_eth_tsu_write(mdp, 0, vtag_reg_index);\n\n\treturn 0;\n}\n\n \nstatic void sh_eth_tsu_init(struct sh_eth_private *mdp)\n{\n\tif (!mdp->cd->dual_port) {\n\t\tsh_eth_tsu_write(mdp, 0, TSU_TEN);  \n\t\tsh_eth_tsu_write(mdp, TSU_FWSLC_POSTENU | TSU_FWSLC_POSTENL,\n\t\t\t\t TSU_FWSLC);\t \n\t\treturn;\n\t}\n\n\tsh_eth_tsu_write(mdp, 0, TSU_FWEN0);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_FWEN1);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_FCM);\t \n\tsh_eth_tsu_write(mdp, 0xc, TSU_BSYSL0);\n\tsh_eth_tsu_write(mdp, 0xc, TSU_BSYSL1);\n\tsh_eth_tsu_write(mdp, 0, TSU_PRISL0);\n\tsh_eth_tsu_write(mdp, 0, TSU_PRISL1);\n\tsh_eth_tsu_write(mdp, 0, TSU_FWSL0);\n\tsh_eth_tsu_write(mdp, 0, TSU_FWSL1);\n\tsh_eth_tsu_write(mdp, TSU_FWSLC_POSTENU | TSU_FWSLC_POSTENL, TSU_FWSLC);\n\tsh_eth_tsu_write(mdp, 0, TSU_QTAGM0);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_QTAGM1);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_FWSR);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_FWINMK);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_TEN);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_POST1);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_POST2);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_POST3);\t \n\tsh_eth_tsu_write(mdp, 0, TSU_POST4);\t \n}\n\n \nstatic int sh_mdio_release(struct sh_eth_private *mdp)\n{\n\t \n\tmdiobus_unregister(mdp->mii_bus);\n\n\t \n\tfree_mdio_bitbang(mdp->mii_bus);\n\n\treturn 0;\n}\n\nstatic int sh_mdiobb_read_c22(struct mii_bus *bus, int phy, int reg)\n{\n\tint res;\n\n\tpm_runtime_get_sync(bus->parent);\n\tres = mdiobb_read_c22(bus, phy, reg);\n\tpm_runtime_put(bus->parent);\n\n\treturn res;\n}\n\nstatic int sh_mdiobb_write_c22(struct mii_bus *bus, int phy, int reg, u16 val)\n{\n\tint res;\n\n\tpm_runtime_get_sync(bus->parent);\n\tres = mdiobb_write_c22(bus, phy, reg, val);\n\tpm_runtime_put(bus->parent);\n\n\treturn res;\n}\n\nstatic int sh_mdiobb_read_c45(struct mii_bus *bus, int phy, int devad, int reg)\n{\n\tint res;\n\n\tpm_runtime_get_sync(bus->parent);\n\tres = mdiobb_read_c45(bus, phy, devad, reg);\n\tpm_runtime_put(bus->parent);\n\n\treturn res;\n}\n\nstatic int sh_mdiobb_write_c45(struct mii_bus *bus, int phy, int devad,\n\t\t\t       int reg, u16 val)\n{\n\tint res;\n\n\tpm_runtime_get_sync(bus->parent);\n\tres = mdiobb_write_c45(bus, phy, devad, reg, val);\n\tpm_runtime_put(bus->parent);\n\n\treturn res;\n}\n\n \nstatic int sh_mdio_init(struct sh_eth_private *mdp,\n\t\t\tstruct sh_eth_plat_data *pd)\n{\n\tint ret;\n\tstruct bb_info *bitbang;\n\tstruct platform_device *pdev = mdp->pdev;\n\tstruct device *dev = &mdp->pdev->dev;\n\tstruct phy_device *phydev;\n\tstruct device_node *pn;\n\n\t \n\tbitbang = devm_kzalloc(dev, sizeof(struct bb_info), GFP_KERNEL);\n\tif (!bitbang)\n\t\treturn -ENOMEM;\n\n\t \n\tbitbang->addr = mdp->addr + mdp->reg_offset[PIR];\n\tbitbang->set_gate = pd->set_mdio_gate;\n\tbitbang->ctrl.ops = &bb_ops;\n\n\t \n\tmdp->mii_bus = alloc_mdio_bitbang(&bitbang->ctrl);\n\tif (!mdp->mii_bus)\n\t\treturn -ENOMEM;\n\n\t \n\tmdp->mii_bus->read = sh_mdiobb_read_c22;\n\tmdp->mii_bus->write = sh_mdiobb_write_c22;\n\tmdp->mii_bus->read_c45 = sh_mdiobb_read_c45;\n\tmdp->mii_bus->write_c45 = sh_mdiobb_write_c45;\n\n\t \n\tmdp->mii_bus->name = \"sh_mii\";\n\tmdp->mii_bus->parent = dev;\n\tsnprintf(mdp->mii_bus->id, MII_BUS_ID_SIZE, \"%s-%x\",\n\t\t pdev->name, pdev->id);\n\n\t \n\tif (pd->phy_irq > 0)\n\t\tmdp->mii_bus->irq[pd->phy] = pd->phy_irq;\n\n\tret = of_mdiobus_register(mdp->mii_bus, dev->of_node);\n\tif (ret)\n\t\tgoto out_free_bus;\n\n\tpn = of_parse_phandle(dev->of_node, \"phy-handle\", 0);\n\tphydev = of_phy_find_device(pn);\n\tif (phydev) {\n\t\tphydev->mac_managed_pm = true;\n\t\tput_device(&phydev->mdio.dev);\n\t}\n\tof_node_put(pn);\n\n\treturn 0;\n\nout_free_bus:\n\tfree_mdio_bitbang(mdp->mii_bus);\n\treturn ret;\n}\n\nstatic const u16 *sh_eth_get_register_offset(int register_type)\n{\n\tconst u16 *reg_offset = NULL;\n\n\tswitch (register_type) {\n\tcase SH_ETH_REG_GIGABIT:\n\t\treg_offset = sh_eth_offset_gigabit;\n\t\tbreak;\n\tcase SH_ETH_REG_FAST_RCAR:\n\t\treg_offset = sh_eth_offset_fast_rcar;\n\t\tbreak;\n\tcase SH_ETH_REG_FAST_SH4:\n\t\treg_offset = sh_eth_offset_fast_sh4;\n\t\tbreak;\n\tcase SH_ETH_REG_FAST_SH3_SH2:\n\t\treg_offset = sh_eth_offset_fast_sh3_sh2;\n\t\tbreak;\n\t}\n\n\treturn reg_offset;\n}\n\nstatic const struct net_device_ops sh_eth_netdev_ops = {\n\t.ndo_open\t\t= sh_eth_open,\n\t.ndo_stop\t\t= sh_eth_close,\n\t.ndo_start_xmit\t\t= sh_eth_start_xmit,\n\t.ndo_get_stats\t\t= sh_eth_get_stats,\n\t.ndo_set_rx_mode\t= sh_eth_set_rx_mode,\n\t.ndo_tx_timeout\t\t= sh_eth_tx_timeout,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl_running,\n\t.ndo_change_mtu\t\t= sh_eth_change_mtu,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n\t.ndo_set_features\t= sh_eth_set_features,\n};\n\nstatic const struct net_device_ops sh_eth_netdev_ops_tsu = {\n\t.ndo_open\t\t= sh_eth_open,\n\t.ndo_stop\t\t= sh_eth_close,\n\t.ndo_start_xmit\t\t= sh_eth_start_xmit,\n\t.ndo_get_stats\t\t= sh_eth_get_stats,\n\t.ndo_set_rx_mode\t= sh_eth_set_rx_mode,\n\t.ndo_vlan_rx_add_vid\t= sh_eth_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= sh_eth_vlan_rx_kill_vid,\n\t.ndo_tx_timeout\t\t= sh_eth_tx_timeout,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl_running,\n\t.ndo_change_mtu\t\t= sh_eth_change_mtu,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n\t.ndo_set_features\t= sh_eth_set_features,\n};\n\n#ifdef CONFIG_OF\nstatic struct sh_eth_plat_data *sh_eth_parse_dt(struct device *dev)\n{\n\tstruct device_node *np = dev->of_node;\n\tstruct sh_eth_plat_data *pdata;\n\tphy_interface_t interface;\n\tint ret;\n\n\tpdata = devm_kzalloc(dev, sizeof(*pdata), GFP_KERNEL);\n\tif (!pdata)\n\t\treturn NULL;\n\n\tret = of_get_phy_mode(np, &interface);\n\tif (ret)\n\t\treturn NULL;\n\tpdata->phy_interface = interface;\n\n\tof_get_mac_address(np, pdata->mac_addr);\n\n\tpdata->no_ether_link =\n\t\tof_property_read_bool(np, \"renesas,no-ether-link\");\n\tpdata->ether_link_active_low =\n\t\tof_property_read_bool(np, \"renesas,ether-link-active-low\");\n\n\treturn pdata;\n}\n\nstatic const struct of_device_id sh_eth_match_table[] = {\n\t{ .compatible = \"renesas,gether-r8a7740\", .data = &r8a7740_data },\n\t{ .compatible = \"renesas,ether-r8a7743\", .data = &rcar_gen2_data },\n\t{ .compatible = \"renesas,ether-r8a7745\", .data = &rcar_gen2_data },\n\t{ .compatible = \"renesas,ether-r8a7778\", .data = &rcar_gen1_data },\n\t{ .compatible = \"renesas,ether-r8a7779\", .data = &rcar_gen1_data },\n\t{ .compatible = \"renesas,ether-r8a7790\", .data = &rcar_gen2_data },\n\t{ .compatible = \"renesas,ether-r8a7791\", .data = &rcar_gen2_data },\n\t{ .compatible = \"renesas,ether-r8a7793\", .data = &rcar_gen2_data },\n\t{ .compatible = \"renesas,ether-r8a7794\", .data = &rcar_gen2_data },\n\t{ .compatible = \"renesas,gether-r8a77980\", .data = &r8a77980_data },\n\t{ .compatible = \"renesas,ether-r7s72100\", .data = &r7s72100_data },\n\t{ .compatible = \"renesas,ether-r7s9210\", .data = &r7s9210_data },\n\t{ .compatible = \"renesas,rcar-gen1-ether\", .data = &rcar_gen1_data },\n\t{ .compatible = \"renesas,rcar-gen2-ether\", .data = &rcar_gen2_data },\n\t{ }\n};\nMODULE_DEVICE_TABLE(of, sh_eth_match_table);\n#else\nstatic inline struct sh_eth_plat_data *sh_eth_parse_dt(struct device *dev)\n{\n\treturn NULL;\n}\n#endif\n\nstatic int sh_eth_drv_probe(struct platform_device *pdev)\n{\n\tstruct resource *res;\n\tstruct sh_eth_plat_data *pd = dev_get_platdata(&pdev->dev);\n\tconst struct platform_device_id *id = platform_get_device_id(pdev);\n\tstruct sh_eth_private *mdp;\n\tstruct net_device *ndev;\n\tint ret;\n\n\tndev = alloc_etherdev(sizeof(struct sh_eth_private));\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tpm_runtime_enable(&pdev->dev);\n\tpm_runtime_get_sync(&pdev->dev);\n\n\tret = platform_get_irq(pdev, 0);\n\tif (ret < 0)\n\t\tgoto out_release;\n\tndev->irq = ret;\n\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\n\tmdp = netdev_priv(ndev);\n\tmdp->num_tx_ring = TX_RING_SIZE;\n\tmdp->num_rx_ring = RX_RING_SIZE;\n\tmdp->addr = devm_platform_get_and_ioremap_resource(pdev, 0, &res);\n\tif (IS_ERR(mdp->addr)) {\n\t\tret = PTR_ERR(mdp->addr);\n\t\tgoto out_release;\n\t}\n\n\tndev->base_addr = res->start;\n\n\tspin_lock_init(&mdp->lock);\n\tmdp->pdev = pdev;\n\n\tif (pdev->dev.of_node)\n\t\tpd = sh_eth_parse_dt(&pdev->dev);\n\tif (!pd) {\n\t\tdev_err(&pdev->dev, \"no platform data\\n\");\n\t\tret = -EINVAL;\n\t\tgoto out_release;\n\t}\n\n\t \n\tmdp->phy_id = pd->phy;\n\tmdp->phy_interface = pd->phy_interface;\n\tmdp->no_ether_link = pd->no_ether_link;\n\tmdp->ether_link_active_low = pd->ether_link_active_low;\n\n\t \n\tif (id)\n\t\tmdp->cd = (struct sh_eth_cpu_data *)id->driver_data;\n\telse\n\t\tmdp->cd = (struct sh_eth_cpu_data *)of_device_get_match_data(&pdev->dev);\n\n\tmdp->reg_offset = sh_eth_get_register_offset(mdp->cd->register_type);\n\tif (!mdp->reg_offset) {\n\t\tdev_err(&pdev->dev, \"Unknown register type (%d)\\n\",\n\t\t\tmdp->cd->register_type);\n\t\tret = -EINVAL;\n\t\tgoto out_release;\n\t}\n\tsh_eth_set_default_cpu_data(mdp->cd);\n\n\t \n\tndev->max_mtu = 2000 - (ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN);\n\tndev->min_mtu = ETH_MIN_MTU;\n\n\tif (mdp->cd->rx_csum) {\n\t\tndev->features = NETIF_F_RXCSUM;\n\t\tndev->hw_features = NETIF_F_RXCSUM;\n\t}\n\n\t \n\tif (mdp->cd->tsu)\n\t\tndev->netdev_ops = &sh_eth_netdev_ops_tsu;\n\telse\n\t\tndev->netdev_ops = &sh_eth_netdev_ops;\n\tndev->ethtool_ops = &sh_eth_ethtool_ops;\n\tndev->watchdog_timeo = TX_TIMEOUT;\n\n\t \n\tmdp->msg_enable = SH_ETH_DEF_MSG_ENABLE;\n\n\t \n\tread_mac_address(ndev, pd->mac_addr);\n\tif (!is_valid_ether_addr(ndev->dev_addr)) {\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"no valid MAC address supplied, using a random one.\\n\");\n\t\teth_hw_addr_random(ndev);\n\t}\n\n\tif (mdp->cd->tsu) {\n\t\tint port = pdev->id < 0 ? 0 : pdev->id % 2;\n\t\tstruct resource *rtsu;\n\n\t\trtsu = platform_get_resource(pdev, IORESOURCE_MEM, 1);\n\t\tif (!rtsu) {\n\t\t\tdev_err(&pdev->dev, \"no TSU resource\\n\");\n\t\t\tret = -ENODEV;\n\t\t\tgoto out_release;\n\t\t}\n\t\t \n\t\tif (port == 0 &&\n\t\t    !devm_request_mem_region(&pdev->dev, rtsu->start,\n\t\t\t\t\t     resource_size(rtsu),\n\t\t\t\t\t     dev_name(&pdev->dev))) {\n\t\t\tdev_err(&pdev->dev, \"can't request TSU resource.\\n\");\n\t\t\tret = -EBUSY;\n\t\t\tgoto out_release;\n\t\t}\n\t\t \n\t\tmdp->tsu_addr = devm_ioremap(&pdev->dev, rtsu->start,\n\t\t\t\t\t     resource_size(rtsu));\n\t\tif (!mdp->tsu_addr) {\n\t\t\tdev_err(&pdev->dev, \"TSU region ioremap() failed.\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_release;\n\t\t}\n\t\tmdp->port = port;\n\t\tndev->features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\n\t\t \n\t\tif (port == 0) {\n\t\t\tif (mdp->cd->chip_reset)\n\t\t\t\tmdp->cd->chip_reset(ndev);\n\n\t\t\t \n\t\t\tsh_eth_tsu_init(mdp);\n\t\t}\n\t}\n\n\tif (mdp->cd->rmiimode)\n\t\tsh_eth_write(ndev, 0x1, RMIIMODE);\n\n\t \n\tret = sh_mdio_init(mdp, pd);\n\tif (ret) {\n\t\tdev_err_probe(&pdev->dev, ret, \"MDIO init failed\\n\");\n\t\tgoto out_release;\n\t}\n\n\tnetif_napi_add(ndev, &mdp->napi, sh_eth_poll);\n\n\t \n\tret = register_netdev(ndev);\n\tif (ret)\n\t\tgoto out_napi_del;\n\n\tif (mdp->cd->magic)\n\t\tdevice_set_wakeup_capable(&pdev->dev, 1);\n\n\t \n\tnetdev_info(ndev, \"Base address at 0x%x, %pM, IRQ %d.\\n\",\n\t\t    (u32)ndev->base_addr, ndev->dev_addr, ndev->irq);\n\n\tpm_runtime_put(&pdev->dev);\n\tplatform_set_drvdata(pdev, ndev);\n\n\treturn ret;\n\nout_napi_del:\n\tnetif_napi_del(&mdp->napi);\n\tsh_mdio_release(mdp);\n\nout_release:\n\t \n\tfree_netdev(ndev);\n\n\tpm_runtime_put(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\treturn ret;\n}\n\nstatic int sh_eth_drv_remove(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\tunregister_netdev(ndev);\n\tnetif_napi_del(&mdp->napi);\n\tsh_mdio_release(mdp);\n\tpm_runtime_disable(&pdev->dev);\n\tfree_netdev(ndev);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM\n#ifdef CONFIG_PM_SLEEP\nstatic int sh_eth_wol_setup(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\n\t \n\tsynchronize_irq(ndev->irq);\n\tnapi_disable(&mdp->napi);\n\tsh_eth_write(ndev, EESIPR_ECIIP, EESIPR);\n\n\t \n\tsh_eth_modify(ndev, ECMR, ECMR_MPDE, ECMR_MPDE);\n\n\treturn enable_irq_wake(ndev->irq);\n}\n\nstatic int sh_eth_wol_restore(struct net_device *ndev)\n{\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ret;\n\n\tnapi_enable(&mdp->napi);\n\n\t \n\tsh_eth_modify(ndev, ECMR, ECMR_MPDE, 0);\n\n\t \n\tsh_eth_close(ndev);\n\tret = sh_eth_open(ndev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn disable_irq_wake(ndev->irq);\n}\n\nstatic int sh_eth_suspend(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ret;\n\n\tif (!netif_running(ndev))\n\t\treturn 0;\n\n\tnetif_device_detach(ndev);\n\n\tif (mdp->wol_enabled)\n\t\tret = sh_eth_wol_setup(ndev);\n\telse\n\t\tret = sh_eth_close(ndev);\n\n\treturn ret;\n}\n\nstatic int sh_eth_resume(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct sh_eth_private *mdp = netdev_priv(ndev);\n\tint ret;\n\n\tif (!netif_running(ndev))\n\t\treturn 0;\n\n\tif (mdp->wol_enabled)\n\t\tret = sh_eth_wol_restore(ndev);\n\telse\n\t\tret = sh_eth_open(ndev);\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\tnetif_device_attach(ndev);\n\n\treturn ret;\n}\n#endif\n\nstatic int sh_eth_runtime_nop(struct device *dev)\n{\n\t \n\treturn 0;\n}\n\nstatic const struct dev_pm_ops sh_eth_dev_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(sh_eth_suspend, sh_eth_resume)\n\tSET_RUNTIME_PM_OPS(sh_eth_runtime_nop, sh_eth_runtime_nop, NULL)\n};\n#define SH_ETH_PM_OPS (&sh_eth_dev_pm_ops)\n#else\n#define SH_ETH_PM_OPS NULL\n#endif\n\nstatic const struct platform_device_id sh_eth_id_table[] = {\n\t{ \"sh7619-ether\", (kernel_ulong_t)&sh7619_data },\n\t{ \"sh771x-ether\", (kernel_ulong_t)&sh771x_data },\n\t{ \"sh7724-ether\", (kernel_ulong_t)&sh7724_data },\n\t{ \"sh7734-gether\", (kernel_ulong_t)&sh7734_data },\n\t{ \"sh7757-ether\", (kernel_ulong_t)&sh7757_data },\n\t{ \"sh7757-gether\", (kernel_ulong_t)&sh7757_data_giga },\n\t{ \"sh7763-gether\", (kernel_ulong_t)&sh7763_data },\n\t{ }\n};\nMODULE_DEVICE_TABLE(platform, sh_eth_id_table);\n\nstatic struct platform_driver sh_eth_driver = {\n\t.probe = sh_eth_drv_probe,\n\t.remove = sh_eth_drv_remove,\n\t.id_table = sh_eth_id_table,\n\t.driver = {\n\t\t   .name = CARDNAME,\n\t\t   .pm = SH_ETH_PM_OPS,\n\t\t   .of_match_table = of_match_ptr(sh_eth_match_table),\n\t},\n};\n\nmodule_platform_driver(sh_eth_driver);\n\nMODULE_AUTHOR(\"Nobuhiro Iwamatsu, Yoshihiro Shimoda\");\nMODULE_DESCRIPTION(\"Renesas SuperH Ethernet driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}