{
  "module_name": "tehuti.c",
  "hash_id": "498590c2cb55ddea87f7fdcf438ac8a829012e5e3f462774d6f0e32e1217fb56",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/tehuti/tehuti.c",
  "human_readable_source": "\n \n\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include \"tehuti.h\"\n\nstatic const struct pci_device_id bdx_pci_tbl[] = {\n\t{ PCI_VDEVICE(TEHUTI, 0x3009), },\n\t{ PCI_VDEVICE(TEHUTI, 0x3010), },\n\t{ PCI_VDEVICE(TEHUTI, 0x3014), },\n\t{ 0 }\n};\n\nMODULE_DEVICE_TABLE(pci, bdx_pci_tbl);\n\n \nstatic void bdx_rx_alloc_skbs(struct bdx_priv *priv, struct rxf_fifo *f);\nstatic void bdx_tx_cleanup(struct bdx_priv *priv);\nstatic int bdx_rx_receive(struct bdx_priv *priv, struct rxd_fifo *f, int budget);\n\n \nstatic void bdx_tx_push_desc_safe(struct bdx_priv *priv, void *data, int size);\n\n \nstatic int bdx_tx_init(struct bdx_priv *priv);\nstatic int bdx_rx_init(struct bdx_priv *priv);\n\n \nstatic void bdx_rx_free(struct bdx_priv *priv);\nstatic void bdx_tx_free(struct bdx_priv *priv);\n\n \nstatic void bdx_set_ethtool_ops(struct net_device *netdev);\n\n \n\nstatic void print_hw_id(struct pci_dev *pdev)\n{\n\tstruct pci_nic *nic = pci_get_drvdata(pdev);\n\tu16 pci_link_status = 0;\n\tu16 pci_ctrl = 0;\n\n\tpci_read_config_word(pdev, PCI_LINK_STATUS_REG, &pci_link_status);\n\tpci_read_config_word(pdev, PCI_DEV_CTRL_REG, &pci_ctrl);\n\n\tpr_info(\"%s%s\\n\", BDX_NIC_NAME,\n\t\tnic->port_num == 1 ? \"\" : \", 2-Port\");\n\tpr_info(\"srom 0x%x fpga %d build %u lane# %d max_pl 0x%x mrrs 0x%x\\n\",\n\t\treadl(nic->regs + SROM_VER), readl(nic->regs + FPGA_VER) & 0xFFF,\n\t\treadl(nic->regs + FPGA_SEED),\n\t\tGET_LINK_STATUS_LANES(pci_link_status),\n\t\tGET_DEV_CTRL_MAXPL(pci_ctrl), GET_DEV_CTRL_MRRS(pci_ctrl));\n}\n\nstatic void print_fw_id(struct pci_nic *nic)\n{\n\tpr_info(\"fw 0x%x\\n\", readl(nic->regs + FW_VER));\n}\n\nstatic void print_eth_id(struct net_device *ndev)\n{\n\tnetdev_info(ndev, \"%s, Port %c\\n\",\n\t\t    BDX_NIC_NAME, (ndev->if_port == 0) ? 'A' : 'B');\n\n}\n\n \n\n#define bdx_enable_interrupts(priv)\t\\\n\tdo { WRITE_REG(priv, regIMR, IR_RUN); } while (0)\n#define bdx_disable_interrupts(priv)\t\\\n\tdo { WRITE_REG(priv, regIMR, 0); } while (0)\n\n \nstatic int\nbdx_fifo_init(struct bdx_priv *priv, struct fifo *f, int fsz_type,\n\t      u16 reg_CFG0, u16 reg_CFG1, u16 reg_RPTR, u16 reg_WPTR)\n{\n\tu16 memsz = FIFO_SIZE * (1 << fsz_type);\n\n\tmemset(f, 0, sizeof(struct fifo));\n\t \n\tf->va = dma_alloc_coherent(&priv->pdev->dev, memsz + FIFO_EXTRA_SPACE,\n\t\t\t\t   &f->da, GFP_ATOMIC);\n\tif (!f->va) {\n\t\tpr_err(\"dma_alloc_coherent failed\\n\");\n\t\tRET(-ENOMEM);\n\t}\n\tf->reg_CFG0 = reg_CFG0;\n\tf->reg_CFG1 = reg_CFG1;\n\tf->reg_RPTR = reg_RPTR;\n\tf->reg_WPTR = reg_WPTR;\n\tf->rptr = 0;\n\tf->wptr = 0;\n\tf->memsz = memsz;\n\tf->size_mask = memsz - 1;\n\tWRITE_REG(priv, reg_CFG0, (u32) ((f->da & TX_RX_CFG0_BASE) | fsz_type));\n\tWRITE_REG(priv, reg_CFG1, H32_64(f->da));\n\n\tRET(0);\n}\n\n \nstatic void bdx_fifo_free(struct bdx_priv *priv, struct fifo *f)\n{\n\tENTER;\n\tif (f->va) {\n\t\tdma_free_coherent(&priv->pdev->dev,\n\t\t\t\t  f->memsz + FIFO_EXTRA_SPACE, f->va, f->da);\n\t\tf->va = NULL;\n\t}\n\tRET();\n}\n\n \nstatic void bdx_link_changed(struct bdx_priv *priv)\n{\n\tu32 link = READ_REG(priv, regMAC_LNK_STAT) & MAC_LINK_STAT;\n\n\tif (!link) {\n\t\tif (netif_carrier_ok(priv->ndev)) {\n\t\t\tnetif_stop_queue(priv->ndev);\n\t\t\tnetif_carrier_off(priv->ndev);\n\t\t\tnetdev_err(priv->ndev, \"Link Down\\n\");\n\t\t}\n\t} else {\n\t\tif (!netif_carrier_ok(priv->ndev)) {\n\t\t\tnetif_wake_queue(priv->ndev);\n\t\t\tnetif_carrier_on(priv->ndev);\n\t\t\tnetdev_err(priv->ndev, \"Link Up\\n\");\n\t\t}\n\t}\n}\n\nstatic void bdx_isr_extra(struct bdx_priv *priv, u32 isr)\n{\n\tif (isr & IR_RX_FREE_0) {\n\t\tbdx_rx_alloc_skbs(priv, &priv->rxf_fifo0);\n\t\tDBG(\"RX_FREE_0\\n\");\n\t}\n\n\tif (isr & IR_LNKCHG0)\n\t\tbdx_link_changed(priv);\n\n\tif (isr & IR_PCIE_LINK)\n\t\tnetdev_err(priv->ndev, \"PCI-E Link Fault\\n\");\n\n\tif (isr & IR_PCIE_TOUT)\n\t\tnetdev_err(priv->ndev, \"PCI-E Time Out\\n\");\n\n}\n\n \n\nstatic irqreturn_t bdx_isr_napi(int irq, void *dev)\n{\n\tstruct net_device *ndev = dev;\n\tstruct bdx_priv *priv = netdev_priv(ndev);\n\tu32 isr;\n\n\tENTER;\n\tisr = (READ_REG(priv, regISR) & IR_RUN);\n\tif (unlikely(!isr)) {\n\t\tbdx_enable_interrupts(priv);\n\t\treturn IRQ_NONE;\t \n\t}\n\n\tif (isr & IR_EXTRA)\n\t\tbdx_isr_extra(priv, isr);\n\n\tif (isr & (IR_RX_DESC_0 | IR_TX_FREE_0)) {\n\t\tif (likely(napi_schedule_prep(&priv->napi))) {\n\t\t\t__napi_schedule(&priv->napi);\n\t\t\tRET(IRQ_HANDLED);\n\t\t} else {\n\t\t\t \n\t\t\tREAD_REG(priv, regTXF_WPTR_0);\n\t\t\tREAD_REG(priv, regRXD_WPTR_0);\n\t\t}\n\t}\n\n\tbdx_enable_interrupts(priv);\n\tRET(IRQ_HANDLED);\n}\n\nstatic int bdx_poll(struct napi_struct *napi, int budget)\n{\n\tstruct bdx_priv *priv = container_of(napi, struct bdx_priv, napi);\n\tint work_done;\n\n\tENTER;\n\tbdx_tx_cleanup(priv);\n\twork_done = bdx_rx_receive(priv, &priv->rxd_fifo0, budget);\n\tif ((work_done < budget) ||\n\t    (priv->napi_stop++ >= 30)) {\n\t\tDBG(\"rx poll is done. backing to isr-driven\\n\");\n\n\t\t \n\t\tpriv->napi_stop = 0;\n\n\t\tnapi_complete_done(napi, work_done);\n\t\tbdx_enable_interrupts(priv);\n\t}\n\treturn work_done;\n}\n\n \n\nstatic int bdx_fw_load(struct bdx_priv *priv)\n{\n\tconst struct firmware *fw = NULL;\n\tint master, i;\n\tint rc;\n\n\tENTER;\n\tmaster = READ_REG(priv, regINIT_SEMAPHORE);\n\tif (!READ_REG(priv, regINIT_STATUS) && master) {\n\t\trc = request_firmware(&fw, \"tehuti/bdx.bin\", &priv->pdev->dev);\n\t\tif (rc)\n\t\t\tgoto out;\n\t\tbdx_tx_push_desc_safe(priv, (char *)fw->data, fw->size);\n\t\tmdelay(100);\n\t}\n\tfor (i = 0; i < 200; i++) {\n\t\tif (READ_REG(priv, regINIT_STATUS)) {\n\t\t\trc = 0;\n\t\t\tgoto out;\n\t\t}\n\t\tmdelay(2);\n\t}\n\trc = -EIO;\nout:\n\tif (master)\n\t\tWRITE_REG(priv, regINIT_SEMAPHORE, 1);\n\n\trelease_firmware(fw);\n\n\tif (rc) {\n\t\tnetdev_err(priv->ndev, \"firmware loading failed\\n\");\n\t\tif (rc == -EIO)\n\t\t\tDBG(\"VPC = 0x%x VIC = 0x%x INIT_STATUS = 0x%x i=%d\\n\",\n\t\t\t    READ_REG(priv, regVPC),\n\t\t\t    READ_REG(priv, regVIC),\n\t\t\t    READ_REG(priv, regINIT_STATUS), i);\n\t\tRET(rc);\n\t} else {\n\t\tDBG(\"%s: firmware loading success\\n\", priv->ndev->name);\n\t\tRET(0);\n\t}\n}\n\nstatic void bdx_restore_mac(struct net_device *ndev, struct bdx_priv *priv)\n{\n\tu32 val;\n\n\tENTER;\n\tDBG(\"mac0=%x mac1=%x mac2=%x\\n\",\n\t    READ_REG(priv, regUNC_MAC0_A),\n\t    READ_REG(priv, regUNC_MAC1_A), READ_REG(priv, regUNC_MAC2_A));\n\n\tval = (ndev->dev_addr[0] << 8) | (ndev->dev_addr[1]);\n\tWRITE_REG(priv, regUNC_MAC2_A, val);\n\tval = (ndev->dev_addr[2] << 8) | (ndev->dev_addr[3]);\n\tWRITE_REG(priv, regUNC_MAC1_A, val);\n\tval = (ndev->dev_addr[4] << 8) | (ndev->dev_addr[5]);\n\tWRITE_REG(priv, regUNC_MAC0_A, val);\n\n\tDBG(\"mac0=%x mac1=%x mac2=%x\\n\",\n\t    READ_REG(priv, regUNC_MAC0_A),\n\t    READ_REG(priv, regUNC_MAC1_A), READ_REG(priv, regUNC_MAC2_A));\n\tRET();\n}\n\n \nstatic int bdx_hw_start(struct bdx_priv *priv)\n{\n\tint rc = -EIO;\n\tstruct net_device *ndev = priv->ndev;\n\n\tENTER;\n\tbdx_link_changed(priv);\n\n\t \n\tWRITE_REG(priv, regFRM_LENGTH, 0X3FE0);\n\tWRITE_REG(priv, regPAUSE_QUANT, 0x96);\n\tWRITE_REG(priv, regRX_FIFO_SECTION, 0x800010);\n\tWRITE_REG(priv, regTX_FIFO_SECTION, 0xE00010);\n\tWRITE_REG(priv, regRX_FULLNESS, 0);\n\tWRITE_REG(priv, regTX_FULLNESS, 0);\n\tWRITE_REG(priv, regCTRLST,\n\t\t  regCTRLST_BASE | regCTRLST_RX_ENA | regCTRLST_TX_ENA);\n\n\tWRITE_REG(priv, regVGLB, 0);\n\tWRITE_REG(priv, regMAX_FRAME_A,\n\t\t  priv->rxf_fifo0.m.pktsz & MAX_FRAME_AB_VAL);\n\n\tDBG(\"RDINTCM=%08x\\n\", priv->rdintcm);\t \n\tWRITE_REG(priv, regRDINTCM0, priv->rdintcm);\n\tWRITE_REG(priv, regRDINTCM2, 0);\t \n\n\tDBG(\"TDINTCM=%08x\\n\", priv->tdintcm);\t \n\tWRITE_REG(priv, regTDINTCM0, priv->tdintcm);\t \n\n\t \n\t \n\tbdx_restore_mac(priv->ndev, priv);\n\n\tWRITE_REG(priv, regGMAC_RXF_A, GMAC_RX_FILTER_OSEN |\n\t\t  GMAC_RX_FILTER_AM | GMAC_RX_FILTER_AB);\n\n#define BDX_IRQ_TYPE\t((priv->nic->irq_type == IRQ_MSI) ? 0 : IRQF_SHARED)\n\n\trc = request_irq(priv->pdev->irq, bdx_isr_napi, BDX_IRQ_TYPE,\n\t\t\t ndev->name, ndev);\n\tif (rc)\n\t\tgoto err_irq;\n\tbdx_enable_interrupts(priv);\n\n\tRET(0);\n\nerr_irq:\n\tRET(rc);\n}\n\nstatic void bdx_hw_stop(struct bdx_priv *priv)\n{\n\tENTER;\n\tbdx_disable_interrupts(priv);\n\tfree_irq(priv->pdev->irq, priv->ndev);\n\n\tnetif_carrier_off(priv->ndev);\n\tnetif_stop_queue(priv->ndev);\n\n\tRET();\n}\n\nstatic int bdx_hw_reset_direct(void __iomem *regs)\n{\n\tu32 val, i;\n\tENTER;\n\n\t \n\tval = readl(regs + regCLKPLL);\n\twritel((val | CLKPLL_SFTRST) + 0x8, regs + regCLKPLL);\n\tudelay(50);\n\tval = readl(regs + regCLKPLL);\n\twritel(val & ~CLKPLL_SFTRST, regs + regCLKPLL);\n\n\t \n\tfor (i = 0; i < 70; i++, mdelay(10))\n\t\tif ((readl(regs + regCLKPLL) & CLKPLL_LKD) == CLKPLL_LKD) {\n\t\t\t \n\t\t\treadl(regs + regRXD_CFG0_0);\n\t\t\treturn 0;\n\t\t}\n\tpr_err(\"HW reset failed\\n\");\n\treturn 1;\t\t \n}\n\nstatic int bdx_hw_reset(struct bdx_priv *priv)\n{\n\tu32 val, i;\n\tENTER;\n\n\tif (priv->port == 0) {\n\t\t \n\t\tval = READ_REG(priv, regCLKPLL);\n\t\tWRITE_REG(priv, regCLKPLL, (val | CLKPLL_SFTRST) + 0x8);\n\t\tudelay(50);\n\t\tval = READ_REG(priv, regCLKPLL);\n\t\tWRITE_REG(priv, regCLKPLL, val & ~CLKPLL_SFTRST);\n\t}\n\t \n\tfor (i = 0; i < 70; i++, mdelay(10))\n\t\tif ((READ_REG(priv, regCLKPLL) & CLKPLL_LKD) == CLKPLL_LKD) {\n\t\t\t \n\t\t\tREAD_REG(priv, regRXD_CFG0_0);\n\t\t\treturn 0;\n\t\t}\n\tpr_err(\"HW reset failed\\n\");\n\treturn 1;\t\t \n}\n\nstatic int bdx_sw_reset(struct bdx_priv *priv)\n{\n\tint i;\n\n\tENTER;\n\t \n\t \n\tWRITE_REG(priv, regGMAC_RXF_A, 0);\n\tmdelay(100);\n\t \n\tWRITE_REG(priv, regDIS_PORT, 1);\n\t \n\tWRITE_REG(priv, regDIS_QU, 1);\n\t \n\tfor (i = 0; i < 50; i++) {\n\t\tif (READ_REG(priv, regRST_PORT) & 1)\n\t\t\tbreak;\n\t\tmdelay(10);\n\t}\n\tif (i == 50)\n\t\tnetdev_err(priv->ndev, \"SW reset timeout. continuing anyway\\n\");\n\n\t \n\tWRITE_REG(priv, regRDINTCM0, 0);\n\tWRITE_REG(priv, regTDINTCM0, 0);\n\tWRITE_REG(priv, regIMR, 0);\n\tREAD_REG(priv, regISR);\n\n\t \n\tWRITE_REG(priv, regRST_QU, 1);\n\t \n\tWRITE_REG(priv, regRST_PORT, 1);\n\t \n\tfor (i = regTXD_WPTR_0; i <= regTXF_RPTR_3; i += 0x10)\n\t\tDBG(\"%x = %x\\n\", i, READ_REG(priv, i) & TXF_WPTR_WR_PTR);\n\tfor (i = regTXD_WPTR_0; i <= regTXF_RPTR_3; i += 0x10)\n\t\tWRITE_REG(priv, i, 0);\n\t \n\tWRITE_REG(priv, regDIS_PORT, 0);\n\t \n\tWRITE_REG(priv, regDIS_QU, 0);\n\t \n\tWRITE_REG(priv, regRST_QU, 0);\n\t \n\tWRITE_REG(priv, regRST_PORT, 0);\n\t \n\t \n\t \n\tfor (i = regTXD_WPTR_0; i <= regTXF_RPTR_3; i += 0x10)\n\t\tDBG(\"%x = %x\\n\", i, READ_REG(priv, i) & TXF_WPTR_WR_PTR);\n\n\tRET(0);\n}\n\n \nstatic int bdx_reset(struct bdx_priv *priv)\n{\n\tENTER;\n\tRET((priv->pdev->device == 0x3009)\n\t    ? bdx_hw_reset(priv)\n\t    : bdx_sw_reset(priv));\n}\n\n \nstatic int bdx_close(struct net_device *ndev)\n{\n\tstruct bdx_priv *priv = NULL;\n\n\tENTER;\n\tpriv = netdev_priv(ndev);\n\n\tnapi_disable(&priv->napi);\n\n\tbdx_reset(priv);\n\tbdx_hw_stop(priv);\n\tbdx_rx_free(priv);\n\tbdx_tx_free(priv);\n\tRET(0);\n}\n\n \nstatic int bdx_open(struct net_device *ndev)\n{\n\tstruct bdx_priv *priv;\n\tint rc;\n\n\tENTER;\n\tpriv = netdev_priv(ndev);\n\tbdx_reset(priv);\n\tif (netif_running(ndev))\n\t\tnetif_stop_queue(priv->ndev);\n\n\tif ((rc = bdx_tx_init(priv)) ||\n\t    (rc = bdx_rx_init(priv)) ||\n\t    (rc = bdx_fw_load(priv)))\n\t\tgoto err;\n\n\tbdx_rx_alloc_skbs(priv, &priv->rxf_fifo0);\n\n\trc = bdx_hw_start(priv);\n\tif (rc)\n\t\tgoto err;\n\n\tnapi_enable(&priv->napi);\n\n\tprint_fw_id(priv->nic);\n\n\tRET(0);\n\nerr:\n\tbdx_close(ndev);\n\tRET(rc);\n}\n\nstatic int bdx_range_check(struct bdx_priv *priv, u32 offset)\n{\n\treturn (offset > (u32) (BDX_REGS_SIZE / priv->nic->port_num)) ?\n\t\t-EINVAL : 0;\n}\n\nstatic int bdx_siocdevprivate(struct net_device *ndev, struct ifreq *ifr,\n\t\t\t      void __user *udata, int cmd)\n{\n\tstruct bdx_priv *priv = netdev_priv(ndev);\n\tu32 data[3];\n\tint error;\n\n\tENTER;\n\n\tDBG(\"jiffies=%ld cmd=%d\\n\", jiffies, cmd);\n\tif (cmd != SIOCDEVPRIVATE) {\n\t\terror = copy_from_user(data, udata, sizeof(data));\n\t\tif (error) {\n\t\t\tpr_err(\"can't copy from user\\n\");\n\t\t\tRET(-EFAULT);\n\t\t}\n\t\tDBG(\"%d 0x%x 0x%x\\n\", data[0], data[1], data[2]);\n\t} else {\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\n\tswitch (data[0]) {\n\n\tcase BDX_OP_READ:\n\t\terror = bdx_range_check(priv, data[1]);\n\t\tif (error < 0)\n\t\t\treturn error;\n\t\tdata[2] = READ_REG(priv, data[1]);\n\t\tDBG(\"read_reg(0x%x)=0x%x (dec %d)\\n\", data[1], data[2],\n\t\t    data[2]);\n\t\terror = copy_to_user(udata, data, sizeof(data));\n\t\tif (error)\n\t\t\tRET(-EFAULT);\n\t\tbreak;\n\n\tcase BDX_OP_WRITE:\n\t\terror = bdx_range_check(priv, data[1]);\n\t\tif (error < 0)\n\t\t\treturn error;\n\t\tWRITE_REG(priv, data[1], data[2]);\n\t\tDBG(\"write_reg(0x%x, 0x%x)\\n\", data[1], data[2]);\n\t\tbreak;\n\n\tdefault:\n\t\tRET(-EOPNOTSUPP);\n\t}\n\treturn 0;\n}\n\n \nstatic void __bdx_vlan_rx_vid(struct net_device *ndev, uint16_t vid, int enable)\n{\n\tstruct bdx_priv *priv = netdev_priv(ndev);\n\tu32 reg, bit, val;\n\n\tENTER;\n\tDBG2(\"vid=%d value=%d\\n\", (int)vid, enable);\n\tif (unlikely(vid >= 4096)) {\n\t\tpr_err(\"invalid VID: %u (> 4096)\\n\", vid);\n\t\tRET();\n\t}\n\treg = regVLAN_0 + (vid / 32) * 4;\n\tbit = 1 << vid % 32;\n\tval = READ_REG(priv, reg);\n\tDBG2(\"reg=%x, val=%x, bit=%d\\n\", reg, val, bit);\n\tif (enable)\n\t\tval |= bit;\n\telse\n\t\tval &= ~bit;\n\tDBG2(\"new val %x\\n\", val);\n\tWRITE_REG(priv, reg, val);\n\tRET();\n}\n\n \nstatic int bdx_vlan_rx_add_vid(struct net_device *ndev, __be16 proto, u16 vid)\n{\n\t__bdx_vlan_rx_vid(ndev, vid, 1);\n\treturn 0;\n}\n\n \nstatic int bdx_vlan_rx_kill_vid(struct net_device *ndev, __be16 proto, u16 vid)\n{\n\t__bdx_vlan_rx_vid(ndev, vid, 0);\n\treturn 0;\n}\n\n \nstatic int bdx_change_mtu(struct net_device *ndev, int new_mtu)\n{\n\tENTER;\n\n\tndev->mtu = new_mtu;\n\tif (netif_running(ndev)) {\n\t\tbdx_close(ndev);\n\t\tbdx_open(ndev);\n\t}\n\tRET(0);\n}\n\nstatic void bdx_setmulti(struct net_device *ndev)\n{\n\tstruct bdx_priv *priv = netdev_priv(ndev);\n\n\tu32 rxf_val =\n\t    GMAC_RX_FILTER_AM | GMAC_RX_FILTER_AB | GMAC_RX_FILTER_OSEN;\n\tint i;\n\n\tENTER;\n\t \n\t \n\n\t \n\tif (ndev->flags & IFF_PROMISC) {\n\t\trxf_val |= GMAC_RX_FILTER_PRM;\n\t} else if (ndev->flags & IFF_ALLMULTI) {\n\t\t \n\t\tfor (i = 0; i < MAC_MCST_HASH_NUM; i++)\n\t\t\tWRITE_REG(priv, regRX_MCST_HASH0 + i * 4, ~0);\n\t} else if (!netdev_mc_empty(ndev)) {\n\t\tu8 hash;\n\t\tstruct netdev_hw_addr *ha;\n\t\tu32 reg, val;\n\n\t\t \n\t\tfor (i = 0; i < MAC_MCST_HASH_NUM; i++)\n\t\t\tWRITE_REG(priv, regRX_MCST_HASH0 + i * 4, 0);\n\t\t \n\t\tfor (i = 0; i < MAC_MCST_NUM; i++) {\n\t\t\tWRITE_REG(priv, regRX_MAC_MCST0 + i * 8, 0);\n\t\t\tWRITE_REG(priv, regRX_MAC_MCST1 + i * 8, 0);\n\t\t}\n\n\t\t \n\t\t \n\t\t \n\t\tnetdev_for_each_mc_addr(ha, ndev) {\n\t\t\thash = 0;\n\t\t\tfor (i = 0; i < ETH_ALEN; i++)\n\t\t\t\thash ^= ha->addr[i];\n\t\t\treg = regRX_MCST_HASH0 + ((hash >> 5) << 2);\n\t\t\tval = READ_REG(priv, reg);\n\t\t\tval |= (1 << (hash % 32));\n\t\t\tWRITE_REG(priv, reg, val);\n\t\t}\n\n\t} else {\n\t\tDBG(\"only own mac %d\\n\", netdev_mc_count(ndev));\n\t\trxf_val |= GMAC_RX_FILTER_AB;\n\t}\n\tWRITE_REG(priv, regGMAC_RXF_A, rxf_val);\n\t \n\t \n\tRET();\n}\n\nstatic int bdx_set_mac(struct net_device *ndev, void *p)\n{\n\tstruct bdx_priv *priv = netdev_priv(ndev);\n\tstruct sockaddr *addr = p;\n\n\tENTER;\n\t \n\teth_hw_addr_set(ndev, addr->sa_data);\n\tbdx_restore_mac(ndev, priv);\n\tRET(0);\n}\n\nstatic int bdx_read_mac(struct bdx_priv *priv)\n{\n\tu16 macAddress[3], i;\n\tu8 addr[ETH_ALEN];\n\tENTER;\n\n\tmacAddress[2] = READ_REG(priv, regUNC_MAC0_A);\n\tmacAddress[2] = READ_REG(priv, regUNC_MAC0_A);\n\tmacAddress[1] = READ_REG(priv, regUNC_MAC1_A);\n\tmacAddress[1] = READ_REG(priv, regUNC_MAC1_A);\n\tmacAddress[0] = READ_REG(priv, regUNC_MAC2_A);\n\tmacAddress[0] = READ_REG(priv, regUNC_MAC2_A);\n\tfor (i = 0; i < 3; i++) {\n\t\taddr[i * 2 + 1] = macAddress[i];\n\t\taddr[i * 2] = macAddress[i] >> 8;\n\t}\n\teth_hw_addr_set(priv->ndev, addr);\n\tRET(0);\n}\n\nstatic u64 bdx_read_l2stat(struct bdx_priv *priv, int reg)\n{\n\tu64 val;\n\n\tval = READ_REG(priv, reg);\n\tval |= ((u64) READ_REG(priv, reg + 8)) << 32;\n\treturn val;\n}\n\n \nstatic void bdx_update_stats(struct bdx_priv *priv)\n{\n\tstruct bdx_stats *stats = &priv->hw_stats;\n\tu64 *stats_vector = (u64 *) stats;\n\tint i;\n\tint addr;\n\n\t \n\taddr = 0x7200;\n\t \n\tfor (i = 0; i < 12; i++) {\n\t\tstats_vector[i] = bdx_read_l2stat(priv, addr);\n\t\taddr += 0x10;\n\t}\n\tBDX_ASSERT(addr != 0x72C0);\n\t \n\taddr = 0x72F0;\n\tfor (; i < 16; i++) {\n\t\tstats_vector[i] = bdx_read_l2stat(priv, addr);\n\t\taddr += 0x10;\n\t}\n\tBDX_ASSERT(addr != 0x7330);\n\t \n\taddr = 0x7370;\n\tfor (; i < 19; i++) {\n\t\tstats_vector[i] = bdx_read_l2stat(priv, addr);\n\t\taddr += 0x10;\n\t}\n\tBDX_ASSERT(addr != 0x73A0);\n\t \n\taddr = 0x73C0;\n\tfor (; i < 23; i++) {\n\t\tstats_vector[i] = bdx_read_l2stat(priv, addr);\n\t\taddr += 0x10;\n\t}\n\tBDX_ASSERT(addr != 0x7400);\n\tBDX_ASSERT((sizeof(struct bdx_stats) / sizeof(u64)) != i);\n}\n\nstatic void print_rxdd(struct rxd_desc *rxdd, u32 rxd_val1, u16 len,\n\t\t       u16 rxd_vlan);\nstatic void print_rxfd(struct rxf_desc *rxfd);\n\n \n\nstatic void bdx_rxdb_destroy(struct rxdb *db)\n{\n\tvfree(db);\n}\n\nstatic struct rxdb *bdx_rxdb_create(int nelem)\n{\n\tstruct rxdb *db;\n\tint i;\n\n\tdb = vmalloc(sizeof(struct rxdb)\n\t\t     + (nelem * sizeof(int))\n\t\t     + (nelem * sizeof(struct rx_map)));\n\tif (likely(db != NULL)) {\n\t\tdb->stack = (int *)(db + 1);\n\t\tdb->elems = (void *)(db->stack + nelem);\n\t\tdb->nelem = nelem;\n\t\tdb->top = nelem;\n\t\tfor (i = 0; i < nelem; i++)\n\t\t\tdb->stack[i] = nelem - i - 1;\t \n\t}\n\n\treturn db;\n}\n\nstatic inline int bdx_rxdb_alloc_elem(struct rxdb *db)\n{\n\tBDX_ASSERT(db->top <= 0);\n\treturn db->stack[--(db->top)];\n}\n\nstatic inline void *bdx_rxdb_addr_elem(struct rxdb *db, int n)\n{\n\tBDX_ASSERT((n < 0) || (n >= db->nelem));\n\treturn db->elems + n;\n}\n\nstatic inline int bdx_rxdb_available(struct rxdb *db)\n{\n\treturn db->top;\n}\n\nstatic inline void bdx_rxdb_free_elem(struct rxdb *db, int n)\n{\n\tBDX_ASSERT((n >= db->nelem) || (n < 0));\n\tdb->stack[(db->top)++] = n;\n}\n\n \n\n \n\n \n\nstatic int bdx_rx_init(struct bdx_priv *priv)\n{\n\tENTER;\n\n\tif (bdx_fifo_init(priv, &priv->rxd_fifo0.m, priv->rxd_size,\n\t\t\t  regRXD_CFG0_0, regRXD_CFG1_0,\n\t\t\t  regRXD_RPTR_0, regRXD_WPTR_0))\n\t\tgoto err_mem;\n\tif (bdx_fifo_init(priv, &priv->rxf_fifo0.m, priv->rxf_size,\n\t\t\t  regRXF_CFG0_0, regRXF_CFG1_0,\n\t\t\t  regRXF_RPTR_0, regRXF_WPTR_0))\n\t\tgoto err_mem;\n\tpriv->rxdb = bdx_rxdb_create(priv->rxf_fifo0.m.memsz /\n\t\t\t\t     sizeof(struct rxf_desc));\n\tif (!priv->rxdb)\n\t\tgoto err_mem;\n\n\tpriv->rxf_fifo0.m.pktsz = priv->ndev->mtu + VLAN_ETH_HLEN;\n\treturn 0;\n\nerr_mem:\n\tnetdev_err(priv->ndev, \"Rx init failed\\n\");\n\treturn -ENOMEM;\n}\n\n \nstatic void bdx_rx_free_skbs(struct bdx_priv *priv, struct rxf_fifo *f)\n{\n\tstruct rx_map *dm;\n\tstruct rxdb *db = priv->rxdb;\n\tu16 i;\n\n\tENTER;\n\tDBG(\"total=%d free=%d busy=%d\\n\", db->nelem, bdx_rxdb_available(db),\n\t    db->nelem - bdx_rxdb_available(db));\n\twhile (bdx_rxdb_available(db) > 0) {\n\t\ti = bdx_rxdb_alloc_elem(db);\n\t\tdm = bdx_rxdb_addr_elem(db, i);\n\t\tdm->dma = 0;\n\t}\n\tfor (i = 0; i < db->nelem; i++) {\n\t\tdm = bdx_rxdb_addr_elem(db, i);\n\t\tif (dm->dma) {\n\t\t\tdma_unmap_single(&priv->pdev->dev, dm->dma,\n\t\t\t\t\t f->m.pktsz, DMA_FROM_DEVICE);\n\t\t\tdev_kfree_skb(dm->skb);\n\t\t}\n\t}\n}\n\n \nstatic void bdx_rx_free(struct bdx_priv *priv)\n{\n\tENTER;\n\tif (priv->rxdb) {\n\t\tbdx_rx_free_skbs(priv, &priv->rxf_fifo0);\n\t\tbdx_rxdb_destroy(priv->rxdb);\n\t\tpriv->rxdb = NULL;\n\t}\n\tbdx_fifo_free(priv, &priv->rxf_fifo0.m);\n\tbdx_fifo_free(priv, &priv->rxd_fifo0.m);\n\n\tRET();\n}\n\n \n\n \n\n \n\nstatic void bdx_rx_alloc_skbs(struct bdx_priv *priv, struct rxf_fifo *f)\n{\n\tstruct sk_buff *skb;\n\tstruct rxf_desc *rxfd;\n\tstruct rx_map *dm;\n\tint dno, delta, idx;\n\tstruct rxdb *db = priv->rxdb;\n\n\tENTER;\n\tdno = bdx_rxdb_available(db) - 1;\n\twhile (dno > 0) {\n\t\tskb = netdev_alloc_skb(priv->ndev, f->m.pktsz + NET_IP_ALIGN);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tskb_reserve(skb, NET_IP_ALIGN);\n\n\t\tidx = bdx_rxdb_alloc_elem(db);\n\t\tdm = bdx_rxdb_addr_elem(db, idx);\n\t\tdm->dma = dma_map_single(&priv->pdev->dev, skb->data,\n\t\t\t\t\t f->m.pktsz, DMA_FROM_DEVICE);\n\t\tdm->skb = skb;\n\t\trxfd = (struct rxf_desc *)(f->m.va + f->m.wptr);\n\t\trxfd->info = CPU_CHIP_SWAP32(0x10003);\t \n\t\trxfd->va_lo = idx;\n\t\trxfd->pa_lo = CPU_CHIP_SWAP32(L32_64(dm->dma));\n\t\trxfd->pa_hi = CPU_CHIP_SWAP32(H32_64(dm->dma));\n\t\trxfd->len = CPU_CHIP_SWAP32(f->m.pktsz);\n\t\tprint_rxfd(rxfd);\n\n\t\tf->m.wptr += sizeof(struct rxf_desc);\n\t\tdelta = f->m.wptr - f->m.memsz;\n\t\tif (unlikely(delta >= 0)) {\n\t\t\tf->m.wptr = delta;\n\t\t\tif (delta > 0) {\n\t\t\t\tmemcpy(f->m.va, f->m.va + f->m.memsz, delta);\n\t\t\t\tDBG(\"wrapped descriptor\\n\");\n\t\t\t}\n\t\t}\n\t\tdno--;\n\t}\n\t \n\tWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\n\tRET();\n}\n\nstatic inline void\nNETIF_RX_MUX(struct bdx_priv *priv, u32 rxd_val1, u16 rxd_vlan,\n\t     struct sk_buff *skb)\n{\n\tENTER;\n\tDBG(\"rxdd->flags.bits.vtag=%d\\n\", GET_RXD_VTAG(rxd_val1));\n\tif (GET_RXD_VTAG(rxd_val1)) {\n\t\tDBG(\"%s: vlan rcv vlan '%x' vtag '%x'\\n\",\n\t\t    priv->ndev->name,\n\t\t    GET_RXD_VLAN_ID(rxd_vlan),\n\t\t    GET_RXD_VTAG(rxd_val1));\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), GET_RXD_VLAN_TCI(rxd_vlan));\n\t}\n\tnetif_receive_skb(skb);\n}\n\nstatic void bdx_recycle_skb(struct bdx_priv *priv, struct rxd_desc *rxdd)\n{\n\tstruct rxf_desc *rxfd;\n\tstruct rx_map *dm;\n\tstruct rxf_fifo *f;\n\tstruct rxdb *db;\n\tint delta;\n\n\tENTER;\n\tDBG(\"priv=%p rxdd=%p\\n\", priv, rxdd);\n\tf = &priv->rxf_fifo0;\n\tdb = priv->rxdb;\n\tDBG(\"db=%p f=%p\\n\", db, f);\n\tdm = bdx_rxdb_addr_elem(db, rxdd->va_lo);\n\tDBG(\"dm=%p\\n\", dm);\n\trxfd = (struct rxf_desc *)(f->m.va + f->m.wptr);\n\trxfd->info = CPU_CHIP_SWAP32(0x10003);\t \n\trxfd->va_lo = rxdd->va_lo;\n\trxfd->pa_lo = CPU_CHIP_SWAP32(L32_64(dm->dma));\n\trxfd->pa_hi = CPU_CHIP_SWAP32(H32_64(dm->dma));\n\trxfd->len = CPU_CHIP_SWAP32(f->m.pktsz);\n\tprint_rxfd(rxfd);\n\n\tf->m.wptr += sizeof(struct rxf_desc);\n\tdelta = f->m.wptr - f->m.memsz;\n\tif (unlikely(delta >= 0)) {\n\t\tf->m.wptr = delta;\n\t\tif (delta > 0) {\n\t\t\tmemcpy(f->m.va, f->m.va + f->m.memsz, delta);\n\t\t\tDBG(\"wrapped descriptor\\n\");\n\t\t}\n\t}\n\tRET();\n}\n\n \n\n \n\nstatic int bdx_rx_receive(struct bdx_priv *priv, struct rxd_fifo *f, int budget)\n{\n\tstruct net_device *ndev = priv->ndev;\n\tstruct sk_buff *skb, *skb2;\n\tstruct rxd_desc *rxdd;\n\tstruct rx_map *dm;\n\tstruct rxf_fifo *rxf_fifo;\n\tint tmp_len, size;\n\tint done = 0;\n\tint max_done = BDX_MAX_RX_DONE;\n\tstruct rxdb *db = NULL;\n\t \n\tu32 rxd_val1;\n\tu16 len;\n\tu16 rxd_vlan;\n\n\tENTER;\n\tmax_done = budget;\n\n\tf->m.wptr = READ_REG(priv, f->m.reg_WPTR) & TXF_WPTR_WR_PTR;\n\n\tsize = f->m.wptr - f->m.rptr;\n\tif (size < 0)\n\t\tsize = f->m.memsz + size;\t \n\n\twhile (size > 0) {\n\n\t\trxdd = (struct rxd_desc *)(f->m.va + f->m.rptr);\n\t\trxd_val1 = CPU_CHIP_SWAP32(rxdd->rxd_val1);\n\n\t\tlen = CPU_CHIP_SWAP16(rxdd->len);\n\n\t\trxd_vlan = CPU_CHIP_SWAP16(rxdd->rxd_vlan);\n\n\t\tprint_rxdd(rxdd, rxd_val1, len, rxd_vlan);\n\n\t\ttmp_len = GET_RXD_BC(rxd_val1) << 3;\n\t\tBDX_ASSERT(tmp_len <= 0);\n\t\tsize -= tmp_len;\n\t\tif (size < 0)\t \n\t\t\tbreak;\n\n\t\tf->m.rptr += tmp_len;\n\n\t\ttmp_len = f->m.rptr - f->m.memsz;\n\t\tif (unlikely(tmp_len >= 0)) {\n\t\t\tf->m.rptr = tmp_len;\n\t\t\tif (tmp_len > 0) {\n\t\t\t\tDBG(\"wrapped desc rptr=%d tmp_len=%d\\n\",\n\t\t\t\t    f->m.rptr, tmp_len);\n\t\t\t\tmemcpy(f->m.va + f->m.memsz, f->m.va, tmp_len);\n\t\t\t}\n\t\t}\n\n\t\tif (unlikely(GET_RXD_ERR(rxd_val1))) {\n\t\t\tDBG(\"rxd_err = 0x%x\\n\", GET_RXD_ERR(rxd_val1));\n\t\t\tndev->stats.rx_errors++;\n\t\t\tbdx_recycle_skb(priv, rxdd);\n\t\t\tcontinue;\n\t\t}\n\n\t\trxf_fifo = &priv->rxf_fifo0;\n\t\tdb = priv->rxdb;\n\t\tdm = bdx_rxdb_addr_elem(db, rxdd->va_lo);\n\t\tskb = dm->skb;\n\n\t\tif (len < BDX_COPYBREAK &&\n\t\t    (skb2 = netdev_alloc_skb(priv->ndev, len + NET_IP_ALIGN))) {\n\t\t\tskb_reserve(skb2, NET_IP_ALIGN);\n\t\t\t \n\t\t\tdma_sync_single_for_cpu(&priv->pdev->dev, dm->dma,\n\t\t\t\t\t\trxf_fifo->m.pktsz,\n\t\t\t\t\t\tDMA_FROM_DEVICE);\n\t\t\tmemcpy(skb2->data, skb->data, len);\n\t\t\tbdx_recycle_skb(priv, rxdd);\n\t\t\tskb = skb2;\n\t\t} else {\n\t\t\tdma_unmap_single(&priv->pdev->dev, dm->dma,\n\t\t\t\t\t rxf_fifo->m.pktsz, DMA_FROM_DEVICE);\n\t\t\tbdx_rxdb_free_elem(db, rxdd->va_lo);\n\t\t}\n\n\t\tndev->stats.rx_bytes += len;\n\n\t\tskb_put(skb, len);\n\t\tskb->protocol = eth_type_trans(skb, ndev);\n\n\t\t \n\t\tif (GET_RXD_PKT_ID(rxd_val1) == 0)\n\t\t\tskb_checksum_none_assert(skb);\n\t\telse\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\n\t\tNETIF_RX_MUX(priv, rxd_val1, rxd_vlan, skb);\n\n\t\tif (++done >= max_done)\n\t\t\tbreak;\n\t}\n\n\tndev->stats.rx_packets += done;\n\n\t \n\tWRITE_REG(priv, f->m.reg_RPTR, f->m.rptr & TXF_WPTR_WR_PTR);\n\n\tbdx_rx_alloc_skbs(priv, &priv->rxf_fifo0);\n\n\tRET(done);\n}\n\n \nstatic void print_rxdd(struct rxd_desc *rxdd, u32 rxd_val1, u16 len,\n\t\t       u16 rxd_vlan)\n{\n\tDBG(\"ERROR: rxdd bc %d rxfq %d to %d type %d err %d rxp %d pkt_id %d vtag %d len %d vlan_id %d cfi %d prio %d va_lo %d va_hi %d\\n\",\n\t    GET_RXD_BC(rxd_val1), GET_RXD_RXFQ(rxd_val1), GET_RXD_TO(rxd_val1),\n\t    GET_RXD_TYPE(rxd_val1), GET_RXD_ERR(rxd_val1),\n\t    GET_RXD_RXP(rxd_val1), GET_RXD_PKT_ID(rxd_val1),\n\t    GET_RXD_VTAG(rxd_val1), len, GET_RXD_VLAN_ID(rxd_vlan),\n\t    GET_RXD_CFI(rxd_vlan), GET_RXD_PRIO(rxd_vlan), rxdd->va_lo,\n\t    rxdd->va_hi);\n}\n\nstatic void print_rxfd(struct rxf_desc *rxfd)\n{\n\tDBG(\"=== RxF desc CHIP ORDER/ENDIANNESS =============\\n\"\n\t    \"info 0x%x va_lo %u pa_lo 0x%x pa_hi 0x%x len 0x%x\\n\",\n\t    rxfd->info, rxfd->va_lo, rxfd->pa_lo, rxfd->pa_hi, rxfd->len);\n}\n\n \n\n \nstatic inline void __bdx_tx_db_ptr_next(struct txdb *db, struct tx_map **pptr)\n{\n\tBDX_ASSERT(db == NULL || pptr == NULL);\t \n\n\tBDX_ASSERT(*pptr != db->rptr &&\t \n\t\t   *pptr != db->wptr);\t \n\n\tBDX_ASSERT(*pptr < db->start ||\t \n\t\t   *pptr >= db->end);\t \n\n\t++*pptr;\n\tif (unlikely(*pptr == db->end))\n\t\t*pptr = db->start;\n}\n\n \nstatic inline void bdx_tx_db_inc_rptr(struct txdb *db)\n{\n\tBDX_ASSERT(db->rptr == db->wptr);\t \n\t__bdx_tx_db_ptr_next(db, &db->rptr);\n}\n\n \nstatic inline void bdx_tx_db_inc_wptr(struct txdb *db)\n{\n\t__bdx_tx_db_ptr_next(db, &db->wptr);\n\tBDX_ASSERT(db->rptr == db->wptr);\t \n}\n\n \nstatic int bdx_tx_db_init(struct txdb *d, int sz_type)\n{\n\tint memsz = FIFO_SIZE * (1 << (sz_type + 1));\n\n\td->start = vmalloc(memsz);\n\tif (!d->start)\n\t\treturn -ENOMEM;\n\n\t \n\td->size = memsz / sizeof(struct tx_map) - 1;\n\td->end = d->start + d->size + 1;\t \n\n\t \n\td->rptr = d->start;\n\td->wptr = d->start;\n\n\treturn 0;\n}\n\n \nstatic void bdx_tx_db_close(struct txdb *d)\n{\n\tBDX_ASSERT(d == NULL);\n\n\tvfree(d->start);\n\td->start = NULL;\n}\n\n \n\n \nstatic struct {\n\tu16 bytes;\n\tu16 qwords;\t\t \n} txd_sizes[MAX_SKB_FRAGS + 1];\n\n \nstatic inline void\nbdx_tx_map_skb(struct bdx_priv *priv, struct sk_buff *skb,\n\t       struct txd_desc *txdd)\n{\n\tstruct txdb *db = &priv->txdb;\n\tstruct pbl *pbl = &txdd->pbl[0];\n\tint nr_frags = skb_shinfo(skb)->nr_frags;\n\tint i;\n\n\tdb->wptr->len = skb_headlen(skb);\n\tdb->wptr->addr.dma = dma_map_single(&priv->pdev->dev, skb->data,\n\t\t\t\t\t    db->wptr->len, DMA_TO_DEVICE);\n\tpbl->len = CPU_CHIP_SWAP32(db->wptr->len);\n\tpbl->pa_lo = CPU_CHIP_SWAP32(L32_64(db->wptr->addr.dma));\n\tpbl->pa_hi = CPU_CHIP_SWAP32(H32_64(db->wptr->addr.dma));\n\tDBG(\"=== pbl   len: 0x%x ================\\n\", pbl->len);\n\tDBG(\"=== pbl pa_lo: 0x%x ================\\n\", pbl->pa_lo);\n\tDBG(\"=== pbl pa_hi: 0x%x ================\\n\", pbl->pa_hi);\n\tbdx_tx_db_inc_wptr(db);\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\tconst skb_frag_t *frag;\n\n\t\tfrag = &skb_shinfo(skb)->frags[i];\n\t\tdb->wptr->len = skb_frag_size(frag);\n\t\tdb->wptr->addr.dma = skb_frag_dma_map(&priv->pdev->dev, frag,\n\t\t\t\t\t\t      0, skb_frag_size(frag),\n\t\t\t\t\t\t      DMA_TO_DEVICE);\n\n\t\tpbl++;\n\t\tpbl->len = CPU_CHIP_SWAP32(db->wptr->len);\n\t\tpbl->pa_lo = CPU_CHIP_SWAP32(L32_64(db->wptr->addr.dma));\n\t\tpbl->pa_hi = CPU_CHIP_SWAP32(H32_64(db->wptr->addr.dma));\n\t\tbdx_tx_db_inc_wptr(db);\n\t}\n\n\t \n\tdb->wptr->len = -txd_sizes[nr_frags].bytes;\n\tdb->wptr->addr.skb = skb;\n\tbdx_tx_db_inc_wptr(db);\n}\n\n \nstatic void __init init_txd_sizes(void)\n{\n\tint i, lwords;\n\n\t \n\tfor (i = 0; i < MAX_SKB_FRAGS + 1; i++) {\n\t\tlwords = 7 + (i * 3);\n\t\tif (lwords & 1)\n\t\t\tlwords++;\t \n\t\ttxd_sizes[i].qwords = lwords >> 1;\n\t\ttxd_sizes[i].bytes = lwords << 2;\n\t}\n}\n\n \nstatic int bdx_tx_init(struct bdx_priv *priv)\n{\n\tif (bdx_fifo_init(priv, &priv->txd_fifo0.m, priv->txd_size,\n\t\t\t  regTXD_CFG0_0,\n\t\t\t  regTXD_CFG1_0, regTXD_RPTR_0, regTXD_WPTR_0))\n\t\tgoto err_mem;\n\tif (bdx_fifo_init(priv, &priv->txf_fifo0.m, priv->txf_size,\n\t\t\t  regTXF_CFG0_0,\n\t\t\t  regTXF_CFG1_0, regTXF_RPTR_0, regTXF_WPTR_0))\n\t\tgoto err_mem;\n\n\t \n\tif (bdx_tx_db_init(&priv->txdb, max(priv->txd_size, priv->txf_size)))\n\t\tgoto err_mem;\n\n\tpriv->tx_level = BDX_MAX_TX_LEVEL;\n#ifdef BDX_DELAY_WPTR\n\tpriv->tx_update_mark = priv->tx_level - 1024;\n#endif\n\treturn 0;\n\nerr_mem:\n\tnetdev_err(priv->ndev, \"Tx init failed\\n\");\n\treturn -ENOMEM;\n}\n\n \nstatic inline int bdx_tx_space(struct bdx_priv *priv)\n{\n\tstruct txd_fifo *f = &priv->txd_fifo0;\n\tint fsize;\n\n\tf->m.rptr = READ_REG(priv, f->m.reg_RPTR) & TXF_WPTR_WR_PTR;\n\tfsize = f->m.rptr - f->m.wptr;\n\tif (fsize <= 0)\n\t\tfsize = f->m.memsz + fsize;\n\treturn fsize;\n}\n\n \nstatic netdev_tx_t bdx_tx_transmit(struct sk_buff *skb,\n\t\t\t\t   struct net_device *ndev)\n{\n\tstruct bdx_priv *priv = netdev_priv(ndev);\n\tstruct txd_fifo *f = &priv->txd_fifo0;\n\tint txd_checksum = 7;\t \n\tint txd_lgsnd = 0;\n\tint txd_vlan_id = 0;\n\tint txd_vtag = 0;\n\tint txd_mss = 0;\n\n\tint nr_frags = skb_shinfo(skb)->nr_frags;\n\tstruct txd_desc *txdd;\n\tint len;\n\tunsigned long flags;\n\n\tENTER;\n\tlocal_irq_save(flags);\n\tspin_lock(&priv->tx_lock);\n\n\t \n\tBDX_ASSERT(f->m.wptr >= f->m.memsz);\t \n\ttxdd = (struct txd_desc *)(f->m.va + f->m.wptr);\n\tif (unlikely(skb->ip_summed != CHECKSUM_PARTIAL))\n\t\ttxd_checksum = 0;\n\n\tif (skb_shinfo(skb)->gso_size) {\n\t\ttxd_mss = skb_shinfo(skb)->gso_size;\n\t\ttxd_lgsnd = 1;\n\t\tDBG(\"skb %p skb len %d gso size = %d\\n\", skb, skb->len,\n\t\t    txd_mss);\n\t}\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\t \n\t\ttxd_vlan_id = skb_vlan_tag_get(skb) & BITS_MASK(12);\n\t\ttxd_vtag = 1;\n\t}\n\n\ttxdd->length = CPU_CHIP_SWAP16(skb->len);\n\ttxdd->mss = CPU_CHIP_SWAP16(txd_mss);\n\ttxdd->txd_val1 =\n\t    CPU_CHIP_SWAP32(TXD_W1_VAL\n\t\t\t    (txd_sizes[nr_frags].qwords, txd_checksum, txd_vtag,\n\t\t\t     txd_lgsnd, txd_vlan_id));\n\tDBG(\"=== TxD desc =====================\\n\");\n\tDBG(\"=== w1: 0x%x ================\\n\", txdd->txd_val1);\n\tDBG(\"=== w2: mss 0x%x len 0x%x\\n\", txdd->mss, txdd->length);\n\n\tbdx_tx_map_skb(priv, skb, txdd);\n\n\t \n\tf->m.wptr += txd_sizes[nr_frags].bytes;\n\tlen = f->m.wptr - f->m.memsz;\n\tif (unlikely(len >= 0)) {\n\t\tf->m.wptr = len;\n\t\tif (len > 0) {\n\t\t\tBDX_ASSERT(len > f->m.memsz);\n\t\t\tmemcpy(f->m.va, f->m.va + f->m.memsz, len);\n\t\t}\n\t}\n\tBDX_ASSERT(f->m.wptr >= f->m.memsz);\t \n\n\tpriv->tx_level -= txd_sizes[nr_frags].bytes;\n\tBDX_ASSERT(priv->tx_level <= 0 || priv->tx_level > BDX_MAX_TX_LEVEL);\n#ifdef BDX_DELAY_WPTR\n\tif (priv->tx_level > priv->tx_update_mark) {\n\t\t \n\t\tWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\n\t} else {\n\t\tif (priv->tx_noupd++ > BDX_NO_UPD_PACKETS) {\n\t\t\tpriv->tx_noupd = 0;\n\t\t\tWRITE_REG(priv, f->m.reg_WPTR,\n\t\t\t\t  f->m.wptr & TXF_WPTR_WR_PTR);\n\t\t}\n\t}\n#else\n\t \n\tWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\n\n#endif\n#ifdef BDX_LLTX\n\tnetif_trans_update(ndev);  \n#endif\n\tndev->stats.tx_packets++;\n\tndev->stats.tx_bytes += skb->len;\n\n\tif (priv->tx_level < BDX_MIN_TX_LEVEL) {\n\t\tDBG(\"%s: %s: TX Q STOP level %d\\n\",\n\t\t    BDX_DRV_NAME, ndev->name, priv->tx_level);\n\t\tnetif_stop_queue(ndev);\n\t}\n\n\tspin_unlock_irqrestore(&priv->tx_lock, flags);\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic void bdx_tx_cleanup(struct bdx_priv *priv)\n{\n\tstruct txf_fifo *f = &priv->txf_fifo0;\n\tstruct txdb *db = &priv->txdb;\n\tint tx_level = 0;\n\n\tENTER;\n\tf->m.wptr = READ_REG(priv, f->m.reg_WPTR) & TXF_WPTR_MASK;\n\tBDX_ASSERT(f->m.rptr >= f->m.memsz);\t \n\n\twhile (f->m.wptr != f->m.rptr) {\n\t\tf->m.rptr += BDX_TXF_DESC_SZ;\n\t\tf->m.rptr &= f->m.size_mask;\n\n\t\t \n\t\t \n\t\tBDX_ASSERT(db->rptr->len == 0);\n\t\tdo {\n\t\t\tBDX_ASSERT(db->rptr->addr.dma == 0);\n\t\t\tdma_unmap_page(&priv->pdev->dev, db->rptr->addr.dma,\n\t\t\t\t       db->rptr->len, DMA_TO_DEVICE);\n\t\t\tbdx_tx_db_inc_rptr(db);\n\t\t} while (db->rptr->len > 0);\n\t\ttx_level -= db->rptr->len;\t \n\n\t\t \n\t\tdev_consume_skb_irq(db->rptr->addr.skb);\n\t\tbdx_tx_db_inc_rptr(db);\n\t}\n\n\t \n\tBDX_ASSERT((f->m.wptr & TXF_WPTR_WR_PTR) >= f->m.memsz);\n\tWRITE_REG(priv, f->m.reg_RPTR, f->m.rptr & TXF_WPTR_WR_PTR);\n\n\t \n\tspin_lock(&priv->tx_lock);\n\tpriv->tx_level += tx_level;\n\tBDX_ASSERT(priv->tx_level <= 0 || priv->tx_level > BDX_MAX_TX_LEVEL);\n#ifdef BDX_DELAY_WPTR\n\tif (priv->tx_noupd) {\n\t\tpriv->tx_noupd = 0;\n\t\tWRITE_REG(priv, priv->txd_fifo0.m.reg_WPTR,\n\t\t\t  priv->txd_fifo0.m.wptr & TXF_WPTR_WR_PTR);\n\t}\n#endif\n\n\tif (unlikely(netif_queue_stopped(priv->ndev) &&\n\t\t     netif_carrier_ok(priv->ndev) &&\n\t\t     (priv->tx_level >= BDX_MIN_TX_LEVEL))) {\n\t\tDBG(\"%s: %s: TX Q WAKE level %d\\n\",\n\t\t    BDX_DRV_NAME, priv->ndev->name, priv->tx_level);\n\t\tnetif_wake_queue(priv->ndev);\n\t}\n\tspin_unlock(&priv->tx_lock);\n}\n\n \nstatic void bdx_tx_free_skbs(struct bdx_priv *priv)\n{\n\tstruct txdb *db = &priv->txdb;\n\n\tENTER;\n\twhile (db->rptr != db->wptr) {\n\t\tif (likely(db->rptr->len))\n\t\t\tdma_unmap_page(&priv->pdev->dev, db->rptr->addr.dma,\n\t\t\t\t       db->rptr->len, DMA_TO_DEVICE);\n\t\telse\n\t\t\tdev_kfree_skb(db->rptr->addr.skb);\n\t\tbdx_tx_db_inc_rptr(db);\n\t}\n\tRET();\n}\n\n \nstatic void bdx_tx_free(struct bdx_priv *priv)\n{\n\tENTER;\n\tbdx_tx_free_skbs(priv);\n\tbdx_fifo_free(priv, &priv->txd_fifo0.m);\n\tbdx_fifo_free(priv, &priv->txf_fifo0.m);\n\tbdx_tx_db_close(&priv->txdb);\n}\n\n \nstatic void bdx_tx_push_desc(struct bdx_priv *priv, void *data, int size)\n{\n\tstruct txd_fifo *f = &priv->txd_fifo0;\n\tint i = f->m.memsz - f->m.wptr;\n\n\tif (size == 0)\n\t\treturn;\n\n\tif (i > size) {\n\t\tmemcpy(f->m.va + f->m.wptr, data, size);\n\t\tf->m.wptr += size;\n\t} else {\n\t\tmemcpy(f->m.va + f->m.wptr, data, i);\n\t\tf->m.wptr = size - i;\n\t\tmemcpy(f->m.va, data + i, f->m.wptr);\n\t}\n\tWRITE_REG(priv, f->m.reg_WPTR, f->m.wptr & TXF_WPTR_WR_PTR);\n}\n\n \nstatic void bdx_tx_push_desc_safe(struct bdx_priv *priv, void *data, int size)\n{\n\tint timer = 0;\n\tENTER;\n\n\twhile (size > 0) {\n\t\t \n\t\tint avail = bdx_tx_space(priv) - 8;\n\t\tif (avail <= 0) {\n\t\t\tif (timer++ > 300) {\t \n\t\t\t\tDBG(\"timeout while writing desc to TxD fifo\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tudelay(50);\t \n\t\t\tcontinue;\n\t\t}\n\t\tavail = min(avail, size);\n\t\tDBG(\"about to push  %d bytes starting %p size %d\\n\", avail,\n\t\t    data, size);\n\t\tbdx_tx_push_desc(priv, data, avail);\n\t\tsize -= avail;\n\t\tdata += avail;\n\t}\n\tRET();\n}\n\nstatic const struct net_device_ops bdx_netdev_ops = {\n\t.ndo_open\t\t= bdx_open,\n\t.ndo_stop\t\t= bdx_close,\n\t.ndo_start_xmit\t\t= bdx_tx_transmit,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_siocdevprivate\t= bdx_siocdevprivate,\n\t.ndo_set_rx_mode\t= bdx_setmulti,\n\t.ndo_change_mtu\t\t= bdx_change_mtu,\n\t.ndo_set_mac_address\t= bdx_set_mac,\n\t.ndo_vlan_rx_add_vid\t= bdx_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= bdx_vlan_rx_kill_vid,\n};\n\n \n\n \nstatic int\nbdx_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct net_device *ndev;\n\tstruct bdx_priv *priv;\n\tunsigned long pciaddr;\n\tu32 regionSize;\n\tstruct pci_nic *nic;\n\tint err, port;\n\n\tENTER;\n\n\tnic = vmalloc(sizeof(*nic));\n\tif (!nic)\n\t\tRET(-ENOMEM);\n\n     \n\terr = pci_enable_device(pdev);\n\tif (err)\t\t\t \n\t\tgoto err_pci;\t\t \n\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\tpr_err(\"No usable DMA configuration, aborting\\n\");\n\t\tgoto err_dma;\n\t}\n\n\terr = pci_request_regions(pdev, BDX_DRV_NAME);\n\tif (err)\n\t\tgoto err_dma;\n\n\tpci_set_master(pdev);\n\n\tpciaddr = pci_resource_start(pdev, 0);\n\tif (!pciaddr) {\n\t\terr = -EIO;\n\t\tpr_err(\"no MMIO resource\\n\");\n\t\tgoto err_out_res;\n\t}\n\tregionSize = pci_resource_len(pdev, 0);\n\tif (regionSize < BDX_REGS_SIZE) {\n\t\terr = -EIO;\n\t\tpr_err(\"MMIO resource (%x) too small\\n\", regionSize);\n\t\tgoto err_out_res;\n\t}\n\n\tnic->regs = ioremap(pciaddr, regionSize);\n\tif (!nic->regs) {\n\t\terr = -EIO;\n\t\tpr_err(\"ioremap failed\\n\");\n\t\tgoto err_out_res;\n\t}\n\n\tif (pdev->irq < 2) {\n\t\terr = -EIO;\n\t\tpr_err(\"invalid irq (%d)\\n\", pdev->irq);\n\t\tgoto err_out_iomap;\n\t}\n\tpci_set_drvdata(pdev, nic);\n\n\tif (pdev->device == 0x3014)\n\t\tnic->port_num = 2;\n\telse\n\t\tnic->port_num = 1;\n\n\tprint_hw_id(pdev);\n\n\tbdx_hw_reset_direct(nic->regs);\n\n\tnic->irq_type = IRQ_INTX;\n#ifdef BDX_MSI\n\tif ((readl(nic->regs + FPGA_VER) & 0xFFF) >= 378) {\n\t\terr = pci_enable_msi(pdev);\n\t\tif (err)\n\t\t\tpr_err(\"Can't enable msi. error is %d\\n\", err);\n\t\telse\n\t\t\tnic->irq_type = IRQ_MSI;\n\t} else\n\t\tDBG(\"HW does not support MSI\\n\");\n#endif\n\n     \n\tfor (port = 0; port < nic->port_num; port++) {\n\t\tndev = alloc_etherdev(sizeof(struct bdx_priv));\n\t\tif (!ndev) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out_iomap;\n\t\t}\n\n\t\tndev->netdev_ops = &bdx_netdev_ops;\n\t\tndev->tx_queue_len = BDX_NDEV_TXQ_LEN;\n\n\t\tbdx_set_ethtool_ops(ndev);\t \n\n\t\t \n\t\tndev->if_port = port;\n\t\tndev->features = NETIF_F_IP_CSUM | NETIF_F_SG | NETIF_F_TSO |\n\t\t    NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX |\n\t\t    NETIF_F_HW_VLAN_CTAG_FILTER | NETIF_F_RXCSUM |\n\t\t    NETIF_F_HIGHDMA;\n\n\t\tndev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG |\n\t\t\tNETIF_F_TSO | NETIF_F_HW_VLAN_CTAG_TX;\n\n\t \n\t\tpriv = nic->priv[port] = netdev_priv(ndev);\n\n\t\tpriv->pBdxRegs = nic->regs + port * 0x8000;\n\t\tpriv->port = port;\n\t\tpriv->pdev = pdev;\n\t\tpriv->ndev = ndev;\n\t\tpriv->nic = nic;\n\t\tpriv->msg_enable = BDX_DEF_MSG_ENABLE;\n\n\t\tnetif_napi_add(ndev, &priv->napi, bdx_poll);\n\n\t\tif ((readl(nic->regs + FPGA_VER) & 0xFFF) == 308) {\n\t\t\tDBG(\"HW statistics not supported\\n\");\n\t\t\tpriv->stats_flag = 0;\n\t\t} else {\n\t\t\tpriv->stats_flag = 1;\n\t\t}\n\n\t\t \n\t\tpriv->txd_size = 2;\n\t\tpriv->txf_size = 2;\n\t\tpriv->rxd_size = 2;\n\t\tpriv->rxf_size = 3;\n\n\t\t \n\t\tpriv->rdintcm = INT_REG_VAL(0x20, 1, 4, 12);\n\t\tpriv->tdintcm = INT_REG_VAL(0x20, 1, 0, 12);\n\n\t\t \n#ifdef BDX_LLTX\n\t\tndev->features |= NETIF_F_LLTX;\n#endif\n\t\t \n\t\tndev->min_mtu = ETH_ZLEN;\n\t\tndev->max_mtu = BDX_MAX_MTU;\n\n\t\tspin_lock_init(&priv->tx_lock);\n\n\t\t \n\t\tif (bdx_read_mac(priv)) {\n\t\t\tpr_err(\"load MAC address failed\\n\");\n\t\t\terr = -EFAULT;\n\t\t\tgoto err_out_iomap;\n\t\t}\n\t\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\t\terr = register_netdev(ndev);\n\t\tif (err) {\n\t\t\tpr_err(\"register_netdev failed\\n\");\n\t\t\tgoto err_out_free;\n\t\t}\n\t\tnetif_carrier_off(ndev);\n\t\tnetif_stop_queue(ndev);\n\n\t\tprint_eth_id(ndev);\n\t}\n\tRET(0);\n\nerr_out_free:\n\tfree_netdev(ndev);\nerr_out_iomap:\n\tiounmap(nic->regs);\nerr_out_res:\n\tpci_release_regions(pdev);\nerr_dma:\n\tpci_disable_device(pdev);\nerr_pci:\n\tvfree(nic);\n\n\tRET(err);\n}\n\n \n \nstatic const char\n bdx_stat_names[][ETH_GSTRING_LEN] = {\n\t\"InUCast\",\t\t \n\t\"InMCast\",\t\t \n\t\"InBCast\",\t\t \n\t\"InPkts\",\t\t \n\t\"InErrors\",\t\t \n\t\"InDropped\",\t\t \n\t\"FrameTooLong\",\t\t \n\t\"FrameSequenceErrors\",\t \n\t\"InVLAN\",\t\t \n\t\"InDroppedDFE\",\t\t \n\t\"InDroppedIntFull\",\t \n\t\"InFrameAlignErrors\",\t \n\n\t \n\n\t\"OutUCast\",\t\t \n\t\"OutMCast\",\t\t \n\t\"OutBCast\",\t\t \n\t\"OutPkts\",\t\t \n\n\t \n\n\t\"OutVLAN\",\t\t \n\t\"InUCastOctects\",\t \n\t\"OutUCastOctects\",\t \n\n\t \n\n\t\"InBCastOctects\",\t \n\t\"OutBCastOctects\",\t \n\t\"InOctects\",\t\t \n\t\"OutOctects\",\t\t \n};\n\n \nstatic int bdx_get_link_ksettings(struct net_device *netdev,\n\t\t\t\t  struct ethtool_link_ksettings *ecmd)\n{\n\tethtool_link_ksettings_zero_link_mode(ecmd, supported);\n\tethtool_link_ksettings_add_link_mode(ecmd, supported,\n\t\t\t\t\t     10000baseT_Full);\n\tethtool_link_ksettings_add_link_mode(ecmd, supported, FIBRE);\n\tethtool_link_ksettings_zero_link_mode(ecmd, advertising);\n\tethtool_link_ksettings_add_link_mode(ecmd, advertising,\n\t\t\t\t\t     10000baseT_Full);\n\tethtool_link_ksettings_add_link_mode(ecmd, advertising, FIBRE);\n\n\tecmd->base.speed = SPEED_10000;\n\tecmd->base.duplex = DUPLEX_FULL;\n\tecmd->base.port = PORT_FIBRE;\n\tecmd->base.autoneg = AUTONEG_DISABLE;\n\n\treturn 0;\n}\n\n \nstatic void\nbdx_get_drvinfo(struct net_device *netdev, struct ethtool_drvinfo *drvinfo)\n{\n\tstruct bdx_priv *priv = netdev_priv(netdev);\n\n\tstrscpy(drvinfo->driver, BDX_DRV_NAME, sizeof(drvinfo->driver));\n\tstrscpy(drvinfo->version, BDX_DRV_VERSION, sizeof(drvinfo->version));\n\tstrscpy(drvinfo->fw_version, \"N/A\", sizeof(drvinfo->fw_version));\n\tstrscpy(drvinfo->bus_info, pci_name(priv->pdev),\n\t\tsizeof(drvinfo->bus_info));\n}\n\n \nstatic int bdx_get_coalesce(struct net_device *netdev,\n\t\t\t    struct ethtool_coalesce *ecoal,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tu32 rdintcm;\n\tu32 tdintcm;\n\tstruct bdx_priv *priv = netdev_priv(netdev);\n\n\trdintcm = priv->rdintcm;\n\ttdintcm = priv->tdintcm;\n\n\t \n\tecoal->rx_coalesce_usecs = GET_INT_COAL(rdintcm) * INT_COAL_MULT;\n\tecoal->rx_max_coalesced_frames =\n\t    ((GET_PCK_TH(rdintcm) * PCK_TH_MULT) / sizeof(struct rxf_desc));\n\n\tecoal->tx_coalesce_usecs = GET_INT_COAL(tdintcm) * INT_COAL_MULT;\n\tecoal->tx_max_coalesced_frames =\n\t    ((GET_PCK_TH(tdintcm) * PCK_TH_MULT) / BDX_TXF_DESC_SZ);\n\n\t \n\treturn 0;\n}\n\n \nstatic int bdx_set_coalesce(struct net_device *netdev,\n\t\t\t    struct ethtool_coalesce *ecoal,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tu32 rdintcm;\n\tu32 tdintcm;\n\tstruct bdx_priv *priv = netdev_priv(netdev);\n\tint rx_coal;\n\tint tx_coal;\n\tint rx_max_coal;\n\tint tx_max_coal;\n\n\t \n\trx_coal = ecoal->rx_coalesce_usecs / INT_COAL_MULT;\n\ttx_coal = ecoal->tx_coalesce_usecs / INT_COAL_MULT;\n\trx_max_coal = ecoal->rx_max_coalesced_frames;\n\ttx_max_coal = ecoal->tx_max_coalesced_frames;\n\n\t \n\trx_max_coal =\n\t    (((rx_max_coal * sizeof(struct rxf_desc)) + PCK_TH_MULT - 1)\n\t     / PCK_TH_MULT);\n\ttx_max_coal =\n\t    (((tx_max_coal * BDX_TXF_DESC_SZ) + PCK_TH_MULT - 1)\n\t     / PCK_TH_MULT);\n\n\tif ((rx_coal > 0x7FFF) || (tx_coal > 0x7FFF) ||\n\t    (rx_max_coal > 0xF) || (tx_max_coal > 0xF))\n\t\treturn -EINVAL;\n\n\trdintcm = INT_REG_VAL(rx_coal, GET_INT_COAL_RC(priv->rdintcm),\n\t\t\t      GET_RXF_TH(priv->rdintcm), rx_max_coal);\n\ttdintcm = INT_REG_VAL(tx_coal, GET_INT_COAL_RC(priv->tdintcm), 0,\n\t\t\t      tx_max_coal);\n\n\tpriv->rdintcm = rdintcm;\n\tpriv->tdintcm = tdintcm;\n\n\tWRITE_REG(priv, regRDINTCM0, rdintcm);\n\tWRITE_REG(priv, regTDINTCM0, tdintcm);\n\n\treturn 0;\n}\n\n \nstatic inline int bdx_rx_fifo_size_to_packets(int rx_size)\n{\n\treturn (FIFO_SIZE * (1 << rx_size)) / sizeof(struct rxf_desc);\n}\n\n \nstatic inline int bdx_tx_fifo_size_to_packets(int tx_size)\n{\n\treturn (FIFO_SIZE * (1 << tx_size)) / BDX_TXF_DESC_SZ;\n}\n\n \nstatic void\nbdx_get_ringparam(struct net_device *netdev, struct ethtool_ringparam *ring,\n\t\t  struct kernel_ethtool_ringparam *kernel_ring,\n\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct bdx_priv *priv = netdev_priv(netdev);\n\n\t \n\tring->rx_max_pending = bdx_rx_fifo_size_to_packets(3);\n\tring->tx_max_pending = bdx_tx_fifo_size_to_packets(3);\n\tring->rx_pending = bdx_rx_fifo_size_to_packets(priv->rxf_size);\n\tring->tx_pending = bdx_tx_fifo_size_to_packets(priv->txd_size);\n}\n\n \nstatic int\nbdx_set_ringparam(struct net_device *netdev, struct ethtool_ringparam *ring,\n\t\t  struct kernel_ethtool_ringparam *kernel_ring,\n\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct bdx_priv *priv = netdev_priv(netdev);\n\tint rx_size = 0;\n\tint tx_size = 0;\n\n\tfor (; rx_size < 4; rx_size++) {\n\t\tif (bdx_rx_fifo_size_to_packets(rx_size) >= ring->rx_pending)\n\t\t\tbreak;\n\t}\n\tif (rx_size == 4)\n\t\trx_size = 3;\n\n\tfor (; tx_size < 4; tx_size++) {\n\t\tif (bdx_tx_fifo_size_to_packets(tx_size) >= ring->tx_pending)\n\t\t\tbreak;\n\t}\n\tif (tx_size == 4)\n\t\ttx_size = 3;\n\n\t \n\tif ((rx_size == priv->rxf_size) &&\n\t    (tx_size == priv->txd_size))\n\t\treturn 0;\n\n\tpriv->rxf_size = rx_size;\n\tif (rx_size > 1)\n\t\tpriv->rxd_size = rx_size - 1;\n\telse\n\t\tpriv->rxd_size = rx_size;\n\n\tpriv->txf_size = priv->txd_size = tx_size;\n\n\tif (netif_running(netdev)) {\n\t\tbdx_close(netdev);\n\t\tbdx_open(netdev);\n\t}\n\treturn 0;\n}\n\n \nstatic void bdx_get_strings(struct net_device *netdev, u32 stringset, u8 *data)\n{\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tmemcpy(data, *bdx_stat_names, sizeof(bdx_stat_names));\n\t\tbreak;\n\t}\n}\n\n \nstatic int bdx_get_sset_count(struct net_device *netdev, int stringset)\n{\n\tstruct bdx_priv *priv = netdev_priv(netdev);\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tBDX_ASSERT(ARRAY_SIZE(bdx_stat_names)\n\t\t\t   != sizeof(struct bdx_stats) / sizeof(u64));\n\t\treturn (priv->stats_flag) ? ARRAY_SIZE(bdx_stat_names)\t: 0;\n\t}\n\n\treturn -EINVAL;\n}\n\n \nstatic void bdx_get_ethtool_stats(struct net_device *netdev,\n\t\t\t\t  struct ethtool_stats *stats, u64 *data)\n{\n\tstruct bdx_priv *priv = netdev_priv(netdev);\n\n\tif (priv->stats_flag) {\n\n\t\t \n\t\tbdx_update_stats(priv);\n\n\t\t \n\t\tmemcpy(data, &priv->hw_stats, sizeof(priv->hw_stats));\n\t}\n}\n\n \nstatic void bdx_set_ethtool_ops(struct net_device *netdev)\n{\n\tstatic const struct ethtool_ops bdx_ethtool_ops = {\n\t\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS |\n\t\t\t\t\t     ETHTOOL_COALESCE_MAX_FRAMES,\n\t\t.get_drvinfo = bdx_get_drvinfo,\n\t\t.get_link = ethtool_op_get_link,\n\t\t.get_coalesce = bdx_get_coalesce,\n\t\t.set_coalesce = bdx_set_coalesce,\n\t\t.get_ringparam = bdx_get_ringparam,\n\t\t.set_ringparam = bdx_set_ringparam,\n\t\t.get_strings = bdx_get_strings,\n\t\t.get_sset_count = bdx_get_sset_count,\n\t\t.get_ethtool_stats = bdx_get_ethtool_stats,\n\t\t.get_link_ksettings = bdx_get_link_ksettings,\n\t};\n\n\tnetdev->ethtool_ops = &bdx_ethtool_ops;\n}\n\n \nstatic void bdx_remove(struct pci_dev *pdev)\n{\n\tstruct pci_nic *nic = pci_get_drvdata(pdev);\n\tstruct net_device *ndev;\n\tint port;\n\n\tfor (port = 0; port < nic->port_num; port++) {\n\t\tndev = nic->priv[port]->ndev;\n\t\tunregister_netdev(ndev);\n\t\tfree_netdev(ndev);\n\t}\n\n\t \n#ifdef BDX_MSI\n\tif (nic->irq_type == IRQ_MSI)\n\t\tpci_disable_msi(pdev);\n#endif\n\n\tiounmap(nic->regs);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\tvfree(nic);\n\n\tRET();\n}\n\nstatic struct pci_driver bdx_pci_driver = {\n\t.name = BDX_DRV_NAME,\n\t.id_table = bdx_pci_tbl,\n\t.probe = bdx_probe,\n\t.remove = bdx_remove,\n};\n\n \nstatic void __init print_driver_id(void)\n{\n\tpr_info(\"%s, %s\\n\", BDX_DRV_DESC, BDX_DRV_VERSION);\n\tpr_info(\"Options: hw_csum %s\\n\", BDX_MSI_STRING);\n}\n\nstatic int __init bdx_module_init(void)\n{\n\tENTER;\n\tinit_txd_sizes();\n\tprint_driver_id();\n\tRET(pci_register_driver(&bdx_pci_driver));\n}\n\nmodule_init(bdx_module_init);\n\nstatic void __exit bdx_module_exit(void)\n{\n\tENTER;\n\tpci_unregister_driver(&bdx_pci_driver);\n\tRET();\n}\n\nmodule_exit(bdx_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(DRIVER_AUTHOR);\nMODULE_DESCRIPTION(BDX_DRV_DESC);\nMODULE_FIRMWARE(\"tehuti/bdx.bin\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}