{
  "module_name": "ena_netdev.h",
  "hash_id": "3f2dde0299b99752a8c2daa2ec84da7e3147fb5784fb2d6c01de5bbafa7b3b5c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/amazon/ena/ena_netdev.h",
  "human_readable_source": " \n \n\n#ifndef ENA_H\n#define ENA_H\n\n#include <linux/bitops.h>\n#include <linux/dim.h>\n#include <linux/etherdevice.h>\n#include <linux/if_vlan.h>\n#include <linux/inetdevice.h>\n#include <linux/interrupt.h>\n#include <linux/netdevice.h>\n#include <linux/skbuff.h>\n#include <net/xdp.h>\n#include <uapi/linux/bpf.h>\n\n#include \"ena_com.h\"\n#include \"ena_eth_com.h\"\n\n#define DRV_MODULE_GEN_MAJOR\t2\n#define DRV_MODULE_GEN_MINOR\t1\n#define DRV_MODULE_GEN_SUBMINOR 0\n\n#define DRV_MODULE_NAME\t\t\"ena\"\n\n#define DEVICE_NAME\t\"Elastic Network Adapter (ENA)\"\n\n \n#define ENA_ADMIN_MSIX_VEC\t\t1\n#define ENA_MAX_MSIX_VEC(io_queues)\t(ENA_ADMIN_MSIX_VEC + (io_queues))\n\n \n#if PAGE_SIZE > SZ_16K\n#define ENA_PAGE_SIZE (_AC(SZ_16K, UL))\n#else\n#define ENA_PAGE_SIZE PAGE_SIZE\n#endif\n\n#define ENA_MIN_MSIX_VEC\t\t2\n\n#define ENA_REG_BAR\t\t\t0\n#define ENA_MEM_BAR\t\t\t2\n#define ENA_BAR_MASK (BIT(ENA_REG_BAR) | BIT(ENA_MEM_BAR))\n\n#define ENA_DEFAULT_RING_SIZE\t(1024)\n#define ENA_MIN_RING_SIZE\t(256)\n\n#define ENA_MIN_RX_BUF_SIZE (2048)\n\n#define ENA_MIN_NUM_IO_QUEUES\t(1)\n\n#define ENA_TX_WAKEUP_THRESH\t\t(MAX_SKB_FRAGS + 2)\n#define ENA_DEFAULT_RX_COPYBREAK\t(256 - NET_IP_ALIGN)\n\n#define ENA_MIN_MTU\t\t128\n\n#define ENA_NAME_MAX_LEN\t20\n#define ENA_IRQNAME_SIZE\t40\n\n#define ENA_PKT_MAX_BUFS\t19\n\n#define ENA_RX_RSS_TABLE_LOG_SIZE  7\n#define ENA_RX_RSS_TABLE_SIZE\t(1 << ENA_RX_RSS_TABLE_LOG_SIZE)\n\n \n#define ENA_TX_POLL_BUDGET_DIVIDER\t4\n\n \n#define ENA_RX_REFILL_THRESH_DIVIDER\t8\n#define ENA_RX_REFILL_THRESH_PACKET\t256\n\n \n#define ENA_MONITORED_TX_QUEUES\t4\n \n#define MAX_NUM_OF_TIMEOUTED_PACKETS 128\n\n#define ENA_TX_RING_IDX_NEXT(idx, ring_size) (((idx) + 1) & ((ring_size) - 1))\n\n#define ENA_RX_RING_IDX_NEXT(idx, ring_size) (((idx) + 1) & ((ring_size) - 1))\n#define ENA_RX_RING_IDX_ADD(idx, n, ring_size) \\\n\t(((idx) + (n)) & ((ring_size) - 1))\n\n#define ENA_IO_TXQ_IDX(q)\t(2 * (q))\n#define ENA_IO_RXQ_IDX(q)\t(2 * (q) + 1)\n#define ENA_IO_TXQ_IDX_TO_COMBINED_IDX(q)\t((q) / 2)\n#define ENA_IO_RXQ_IDX_TO_COMBINED_IDX(q)\t(((q) - 1) / 2)\n\n#define ENA_MGMNT_IRQ_IDX\t\t0\n#define ENA_IO_IRQ_FIRST_IDX\t\t1\n#define ENA_IO_IRQ_IDX(q)\t\t(ENA_IO_IRQ_FIRST_IDX + (q))\n\n#define ENA_ADMIN_POLL_DELAY_US 100\n\n \n#define ENA_DEVICE_KALIVE_TIMEOUT\t(6 * HZ)\n#define ENA_MAX_NO_INTERRUPT_ITERATIONS 3\n\n#define ENA_MMIO_DISABLE_REG_READ\tBIT(0)\n\n \n\n#define ENA_XDP_MAX_MTU (ENA_PAGE_SIZE - ETH_HLEN - ETH_FCS_LEN -\t\\\n\t\t\t VLAN_HLEN - XDP_PACKET_HEADROOM -\t\t\\\n\t\t\t SKB_DATA_ALIGN(sizeof(struct skb_shared_info)))\n\n#define ENA_IS_XDP_INDEX(adapter, index) (((index) >= (adapter)->xdp_first_ring) && \\\n\t((index) < (adapter)->xdp_first_ring + (adapter)->xdp_num_queues))\n\nstruct ena_irq {\n\tirq_handler_t handler;\n\tvoid *data;\n\tint cpu;\n\tu32 vector;\n\tcpumask_t affinity_hint_mask;\n\tchar name[ENA_IRQNAME_SIZE];\n};\n\nstruct ena_napi {\n\tu8 first_interrupt ____cacheline_aligned;\n\tu8 interrupts_masked;\n\tstruct napi_struct napi;\n\tstruct ena_ring *tx_ring;\n\tstruct ena_ring *rx_ring;\n\tstruct ena_ring *xdp_ring;\n\tu32 qid;\n\tstruct dim dim;\n};\n\nstruct ena_tx_buffer {\n\tstruct sk_buff *skb;\n\t \n\tu32 tx_descs;\n\t \n\tu32 num_of_bufs;\n\n\t \n\tstruct xdp_frame *xdpf;\n\n\t \n\tu8 map_linear_data;\n\n\t \n\tu32 print_once;\n\t \n\tunsigned long last_jiffies;\n\tstruct ena_com_buf bufs[ENA_PKT_MAX_BUFS];\n} ____cacheline_aligned;\n\nstruct ena_rx_buffer {\n\tstruct sk_buff *skb;\n\tstruct page *page;\n\tdma_addr_t dma_addr;\n\tu32 page_offset;\n\tu32 buf_offset;\n\tstruct ena_com_buf ena_buf;\n} ____cacheline_aligned;\n\nstruct ena_stats_tx {\n\tu64 cnt;\n\tu64 bytes;\n\tu64 queue_stop;\n\tu64 prepare_ctx_err;\n\tu64 queue_wakeup;\n\tu64 dma_mapping_err;\n\tu64 linearize;\n\tu64 linearize_failed;\n\tu64 napi_comp;\n\tu64 tx_poll;\n\tu64 doorbells;\n\tu64 bad_req_id;\n\tu64 llq_buffer_copy;\n\tu64 missed_tx;\n\tu64 unmask_interrupt;\n\tu64 last_napi_jiffies;\n};\n\nstruct ena_stats_rx {\n\tu64 cnt;\n\tu64 bytes;\n\tu64 rx_copybreak_pkt;\n\tu64 csum_good;\n\tu64 refil_partial;\n\tu64 csum_bad;\n\tu64 page_alloc_fail;\n\tu64 skb_alloc_fail;\n\tu64 dma_mapping_err;\n\tu64 bad_desc_num;\n\tu64 bad_req_id;\n\tu64 empty_rx_ring;\n\tu64 csum_unchecked;\n\tu64 xdp_aborted;\n\tu64 xdp_drop;\n\tu64 xdp_pass;\n\tu64 xdp_tx;\n\tu64 xdp_invalid;\n\tu64 xdp_redirect;\n};\n\nstruct ena_ring {\n\t \n\tu16 *free_ids;\n\n\tunion {\n\t\tstruct ena_tx_buffer *tx_buffer_info;\n\t\tstruct ena_rx_buffer *rx_buffer_info;\n\t};\n\n\t \n\tstruct device *dev;\n\tstruct pci_dev *pdev;\n\tstruct napi_struct *napi;\n\tstruct net_device *netdev;\n\tstruct ena_com_dev *ena_dev;\n\tstruct ena_adapter *adapter;\n\tstruct ena_com_io_cq *ena_com_io_cq;\n\tstruct ena_com_io_sq *ena_com_io_sq;\n\tstruct bpf_prog *xdp_bpf_prog;\n\tstruct xdp_rxq_info xdp_rxq;\n\tspinlock_t xdp_tx_lock;\t \n\t \n\tstruct ena_ring *xdp_ring;\n\n\tu16 next_to_use;\n\tu16 next_to_clean;\n\tu16 rx_copybreak;\n\tu16 rx_headroom;\n\tu16 qid;\n\tu16 mtu;\n\tu16 sgl_size;\n\n\t \n\tu8 tx_max_header_size;\n\n\tbool disable_meta_caching;\n\tu16 no_interrupt_event_cnt;\n\n\t \n\tint cpu;\n\tint numa_node;\n\n\t \n\tint ring_size;\n\n\tenum ena_admin_placement_policy_type tx_mem_queue_type;\n\n\tstruct ena_com_rx_buf_info ena_bufs[ENA_PKT_MAX_BUFS];\n\tu32  smoothed_interval;\n\tu32  per_napi_packets;\n\tu16 non_empty_napi_events;\n\tstruct u64_stats_sync syncp;\n\tunion {\n\t\tstruct ena_stats_tx tx_stats;\n\t\tstruct ena_stats_rx rx_stats;\n\t};\n\n\tu8 *push_buf_intermediate_buf;\n\tint empty_rx_queue;\n} ____cacheline_aligned;\n\nstruct ena_stats_dev {\n\tu64 tx_timeout;\n\tu64 suspend;\n\tu64 resume;\n\tu64 wd_expired;\n\tu64 interface_up;\n\tu64 interface_down;\n\tu64 admin_q_pause;\n\tu64 rx_drops;\n\tu64 tx_drops;\n};\n\nenum ena_flags_t {\n\tENA_FLAG_DEVICE_RUNNING,\n\tENA_FLAG_DEV_UP,\n\tENA_FLAG_LINK_UP,\n\tENA_FLAG_MSIX_ENABLED,\n\tENA_FLAG_TRIGGER_RESET,\n\tENA_FLAG_ONGOING_RESET\n};\n\n \nstruct ena_adapter {\n\tstruct ena_com_dev *ena_dev;\n\t \n\tstruct net_device *netdev;\n\tstruct pci_dev *pdev;\n\n\t \n\tu32 rx_copybreak;\n\tu32 max_mtu;\n\n\tu32 num_io_queues;\n\tu32 max_num_io_queues;\n\n\tint msix_vecs;\n\n\tu32 missing_tx_completion_threshold;\n\n\tu32 requested_tx_ring_size;\n\tu32 requested_rx_ring_size;\n\n\tu32 max_tx_ring_size;\n\tu32 max_rx_ring_size;\n\n\tu32 msg_enable;\n\n\t \n\tbool large_llq_header_enabled;\n\tbool large_llq_header_supported;\n\n\tu16 max_tx_sgl_size;\n\tu16 max_rx_sgl_size;\n\n\tu8 mac_addr[ETH_ALEN];\n\n\tunsigned long keep_alive_timeout;\n\tunsigned long missing_tx_completion_to;\n\n\tchar name[ENA_NAME_MAX_LEN];\n\n\tunsigned long flags;\n\t \n\tstruct ena_ring tx_ring[ENA_MAX_NUM_IO_QUEUES]\n\t\t____cacheline_aligned_in_smp;\n\n\t \n\tstruct ena_ring rx_ring[ENA_MAX_NUM_IO_QUEUES]\n\t\t____cacheline_aligned_in_smp;\n\n\tstruct ena_napi ena_napi[ENA_MAX_NUM_IO_QUEUES];\n\n\tstruct ena_irq irq_tbl[ENA_MAX_MSIX_VEC(ENA_MAX_NUM_IO_QUEUES)];\n\n\t \n\tstruct work_struct reset_task;\n\tstruct timer_list timer_service;\n\n\tbool wd_state;\n\tbool dev_up_before_reset;\n\tbool disable_meta_caching;\n\tunsigned long last_keep_alive_jiffies;\n\n\tstruct u64_stats_sync syncp;\n\tstruct ena_stats_dev dev_stats;\n\tstruct ena_admin_eni_stats eni_stats;\n\n\t \n\tu32 last_monitored_tx_qid;\n\n\tenum ena_regs_reset_reason_types reset_reason;\n\n\tstruct bpf_prog *xdp_bpf_prog;\n\tu32 xdp_first_ring;\n\tu32 xdp_num_queues;\n};\n\nvoid ena_set_ethtool_ops(struct net_device *netdev);\n\nvoid ena_dump_stats_to_dmesg(struct ena_adapter *adapter);\n\nvoid ena_dump_stats_to_buf(struct ena_adapter *adapter, u8 *buf);\n\nint ena_update_hw_stats(struct ena_adapter *adapter);\n\nint ena_update_queue_params(struct ena_adapter *adapter,\n\t\t\t    u32 new_tx_size,\n\t\t\t    u32 new_rx_size,\n\t\t\t    u32 new_llq_header_len);\n\nint ena_update_queue_count(struct ena_adapter *adapter, u32 new_channel_count);\n\nint ena_set_rx_copybreak(struct ena_adapter *adapter, u32 rx_copybreak);\n\nint ena_get_sset_count(struct net_device *netdev, int sset);\n\nstatic inline void ena_reset_device(struct ena_adapter *adapter,\n\t\t\t\t    enum ena_regs_reset_reason_types reset_reason)\n{\n\tadapter->reset_reason = reset_reason;\n\t \n\tsmp_mb__before_atomic();\n\tset_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags);\n}\n\nenum ena_xdp_errors_t {\n\tENA_XDP_ALLOWED = 0,\n\tENA_XDP_CURRENT_MTU_TOO_LARGE,\n\tENA_XDP_NO_ENOUGH_QUEUES,\n};\n\nenum ENA_XDP_ACTIONS {\n\tENA_XDP_PASS\t\t= 0,\n\tENA_XDP_TX\t\t= BIT(0),\n\tENA_XDP_REDIRECT\t= BIT(1),\n\tENA_XDP_DROP\t\t= BIT(2)\n};\n\n#define ENA_XDP_FORWARDED (ENA_XDP_TX | ENA_XDP_REDIRECT)\n\nstatic inline bool ena_xdp_present(struct ena_adapter *adapter)\n{\n\treturn !!adapter->xdp_bpf_prog;\n}\n\nstatic inline bool ena_xdp_present_ring(struct ena_ring *ring)\n{\n\treturn !!ring->xdp_bpf_prog;\n}\n\nstatic inline bool ena_xdp_legal_queue_count(struct ena_adapter *adapter,\n\t\t\t\t\t     u32 queues)\n{\n\treturn 2 * queues <= adapter->max_num_io_queues;\n}\n\nstatic inline enum ena_xdp_errors_t ena_xdp_allowed(struct ena_adapter *adapter)\n{\n\tenum ena_xdp_errors_t rc = ENA_XDP_ALLOWED;\n\n\tif (adapter->netdev->mtu > ENA_XDP_MAX_MTU)\n\t\trc = ENA_XDP_CURRENT_MTU_TOO_LARGE;\n\telse if (!ena_xdp_legal_queue_count(adapter, adapter->num_io_queues))\n\t\trc = ENA_XDP_NO_ENOUGH_QUEUES;\n\n\treturn rc;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}