{
  "module_name": "atl1.c",
  "hash_id": "a958bd6a1d727b224671d0def4623f4b7ce90e9e59f87af7dba03cccd2d60fe6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/atheros/atlx/atl1.c",
  "human_readable_source": "\n \n\n#include <linux/atomic.h>\n#include <asm/byteorder.h>\n\n#include <linux/compiler.h>\n#include <linux/crc32.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/etherdevice.h>\n#include <linux/hardirq.h>\n#include <linux/if_ether.h>\n#include <linux/if_vlan.h>\n#include <linux/in.h>\n#include <linux/interrupt.h>\n#include <linux/ip.h>\n#include <linux/irqflags.h>\n#include <linux/irqreturn.h>\n#include <linux/jiffies.h>\n#include <linux/mii.h>\n#include <linux/module.h>\n#include <linux/net.h>\n#include <linux/netdevice.h>\n#include <linux/pci.h>\n#include <linux/pci_ids.h>\n#include <linux/pm.h>\n#include <linux/skbuff.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include <linux/tcp.h>\n#include <linux/timer.h>\n#include <linux/types.h>\n#include <linux/workqueue.h>\n\n#include <net/checksum.h>\n\n#include \"atl1.h\"\n\nMODULE_AUTHOR(\"Xiong Huang <xiong.huang@atheros.com>, \"\n\t      \"Chris Snook <csnook@redhat.com>, \"\n\t      \"Jay Cliburn <jcliburn@gmail.com>\");\nMODULE_LICENSE(\"GPL\");\n\n \n#include \"atlx.c\"\n\nstatic const struct ethtool_ops atl1_ethtool_ops;\n\n \n#define ATL1_MAX_NIC 4\n\n#define OPTION_UNSET    -1\n#define OPTION_DISABLED 0\n#define OPTION_ENABLED  1\n\n#define ATL1_PARAM_INIT { [0 ... ATL1_MAX_NIC] = OPTION_UNSET }\n\n \nstatic int int_mod_timer[ATL1_MAX_NIC+1] = ATL1_PARAM_INIT;\nstatic unsigned int num_int_mod_timer;\nmodule_param_array_named(int_mod_timer, int_mod_timer, int,\n\t&num_int_mod_timer, 0);\nMODULE_PARM_DESC(int_mod_timer, \"Interrupt moderator timer\");\n\n#define DEFAULT_INT_MOD_CNT\t100\t \n#define MAX_INT_MOD_CNT\t\t65000\n#define MIN_INT_MOD_CNT\t\t50\n\nstruct atl1_option {\n\tenum { enable_option, range_option, list_option } type;\n\tchar *name;\n\tchar *err;\n\tint def;\n\tunion {\n\t\tstruct {\t \n\t\t\tint min;\n\t\t\tint max;\n\t\t} r;\n\t\tstruct {\t \n\t\t\tint nr;\n\t\t\tstruct atl1_opt_list {\n\t\t\t\tint i;\n\t\t\t\tchar *str;\n\t\t\t} *p;\n\t\t} l;\n\t} arg;\n};\n\nstatic int atl1_validate_option(int *value, struct atl1_option *opt,\n\t\t\t\tstruct pci_dev *pdev)\n{\n\tif (*value == OPTION_UNSET) {\n\t\t*value = opt->def;\n\t\treturn 0;\n\t}\n\n\tswitch (opt->type) {\n\tcase enable_option:\n\t\tswitch (*value) {\n\t\tcase OPTION_ENABLED:\n\t\t\tdev_info(&pdev->dev, \"%s enabled\\n\", opt->name);\n\t\t\treturn 0;\n\t\tcase OPTION_DISABLED:\n\t\t\tdev_info(&pdev->dev, \"%s disabled\\n\", opt->name);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tcase range_option:\n\t\tif (*value >= opt->arg.r.min && *value <= opt->arg.r.max) {\n\t\t\tdev_info(&pdev->dev, \"%s set to %i\\n\", opt->name,\n\t\t\t\t*value);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tcase list_option:{\n\t\t\tint i;\n\t\t\tstruct atl1_opt_list *ent;\n\n\t\t\tfor (i = 0; i < opt->arg.l.nr; i++) {\n\t\t\t\tent = &opt->arg.l.p[i];\n\t\t\t\tif (*value == ent->i) {\n\t\t\t\t\tif (ent->str[0] != '\\0')\n\t\t\t\t\t\tdev_info(&pdev->dev, \"%s\\n\",\n\t\t\t\t\t\t\tent->str);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tdev_info(&pdev->dev, \"invalid %s specified (%i) %s\\n\",\n\t\topt->name, *value, opt->err);\n\t*value = opt->def;\n\treturn -1;\n}\n\n \nstatic void atl1_check_options(struct atl1_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tint bd = adapter->bd_number;\n\tif (bd >= ATL1_MAX_NIC) {\n\t\tdev_notice(&pdev->dev, \"no configuration for board#%i\\n\", bd);\n\t\tdev_notice(&pdev->dev, \"using defaults for all values\\n\");\n\t}\n\t{\t\t\t \n\t\tstruct atl1_option opt = {\n\t\t\t.type = range_option,\n\t\t\t.name = \"Interrupt Moderator Timer\",\n\t\t\t.err = \"using default of \"\n\t\t\t\t__MODULE_STRING(DEFAULT_INT_MOD_CNT),\n\t\t\t.def = DEFAULT_INT_MOD_CNT,\n\t\t\t.arg = {.r = {.min = MIN_INT_MOD_CNT,\n\t\t\t\t\t.max = MAX_INT_MOD_CNT} }\n\t\t};\n\t\tint val;\n\t\tif (num_int_mod_timer > bd) {\n\t\t\tval = int_mod_timer[bd];\n\t\t\tatl1_validate_option(&val, &opt, pdev);\n\t\t\tadapter->imt = (u16) val;\n\t\t} else\n\t\t\tadapter->imt = (u16) (opt.def);\n\t}\n}\n\n \nstatic const struct pci_device_id atl1_pci_tbl[] = {\n\t{PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, PCI_DEVICE_ID_ATTANSIC_L1)},\n\t \n\t{0,}\n};\nMODULE_DEVICE_TABLE(pci, atl1_pci_tbl);\n\nstatic const u32 atl1_default_msg = NETIF_MSG_DRV | NETIF_MSG_PROBE |\n\tNETIF_MSG_LINK | NETIF_MSG_TIMER | NETIF_MSG_IFDOWN | NETIF_MSG_IFUP;\n\nstatic int debug = -1;\nmodule_param(debug, int, 0);\nMODULE_PARM_DESC(debug, \"Message level (0=none,...,16=all)\");\n\n \nstatic s32 atl1_reset_hw(struct atl1_hw *hw)\n{\n\tstruct pci_dev *pdev = hw->back->pdev;\n\tstruct atl1_adapter *adapter = hw->back;\n\tu32 icr;\n\tint i;\n\n\t \n\t \n\n\t \n\tiowrite32(MASTER_CTRL_SOFT_RST, hw->hw_addr + REG_MASTER_CTRL);\n\tioread32(hw->hw_addr + REG_MASTER_CTRL);\n\n\tiowrite16(1, hw->hw_addr + REG_PHY_ENABLE);\n\tioread16(hw->hw_addr + REG_PHY_ENABLE);\n\n\t \n\tmsleep(1);\n\n\t \n\tfor (i = 0; i < 10; i++) {\n\t\ticr = ioread32(hw->hw_addr + REG_IDLE_STATUS);\n\t\tif (!icr)\n\t\t\tbreak;\n\t\t \n\t\tmsleep(1);\n\t\t \n\t\tcpu_relax();\n\t}\n\n\tif (icr) {\n\t\tif (netif_msg_hw(adapter))\n\t\t\tdev_dbg(&pdev->dev, \"ICR = 0x%x\\n\", icr);\n\t\treturn icr;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int atl1_check_eeprom_exist(struct atl1_hw *hw)\n{\n\tu32 value;\n\tvalue = ioread32(hw->hw_addr + REG_SPI_FLASH_CTRL);\n\tif (value & SPI_FLASH_CTRL_EN_VPD) {\n\t\tvalue &= ~SPI_FLASH_CTRL_EN_VPD;\n\t\tiowrite32(value, hw->hw_addr + REG_SPI_FLASH_CTRL);\n\t}\n\n\tvalue = ioread16(hw->hw_addr + REG_PCIE_CAP_LIST);\n\treturn ((value & 0xFF00) == 0x6C00) ? 0 : 1;\n}\n\nstatic bool atl1_read_eeprom(struct atl1_hw *hw, u32 offset, u32 *p_value)\n{\n\tint i;\n\tu32 control;\n\n\tif (offset & 3)\n\t\t \n\t\treturn false;\n\n\tiowrite32(0, hw->hw_addr + REG_VPD_DATA);\n\tcontrol = (offset & VPD_CAP_VPD_ADDR_MASK) << VPD_CAP_VPD_ADDR_SHIFT;\n\tiowrite32(control, hw->hw_addr + REG_VPD_CAP);\n\tioread32(hw->hw_addr + REG_VPD_CAP);\n\n\tfor (i = 0; i < 10; i++) {\n\t\tmsleep(2);\n\t\tcontrol = ioread32(hw->hw_addr + REG_VPD_CAP);\n\t\tif (control & VPD_CAP_VPD_FLAG)\n\t\t\tbreak;\n\t}\n\tif (control & VPD_CAP_VPD_FLAG) {\n\t\t*p_value = ioread32(hw->hw_addr + REG_VPD_DATA);\n\t\treturn true;\n\t}\n\t \n\treturn false;\n}\n\n \nstatic s32 atl1_read_phy_reg(struct atl1_hw *hw, u16 reg_addr, u16 *phy_data)\n{\n\tu32 val;\n\tint i;\n\n\tval = ((u32) (reg_addr & MDIO_REG_ADDR_MASK)) << MDIO_REG_ADDR_SHIFT |\n\t\tMDIO_START | MDIO_SUP_PREAMBLE | MDIO_RW | MDIO_CLK_25_4 <<\n\t\tMDIO_CLK_SEL_SHIFT;\n\tiowrite32(val, hw->hw_addr + REG_MDIO_CTRL);\n\tioread32(hw->hw_addr + REG_MDIO_CTRL);\n\n\tfor (i = 0; i < MDIO_WAIT_TIMES; i++) {\n\t\tudelay(2);\n\t\tval = ioread32(hw->hw_addr + REG_MDIO_CTRL);\n\t\tif (!(val & (MDIO_START | MDIO_BUSY)))\n\t\t\tbreak;\n\t}\n\tif (!(val & (MDIO_START | MDIO_BUSY))) {\n\t\t*phy_data = (u16) val;\n\t\treturn 0;\n\t}\n\treturn ATLX_ERR_PHY;\n}\n\n#define CUSTOM_SPI_CS_SETUP\t2\n#define CUSTOM_SPI_CLK_HI\t2\n#define CUSTOM_SPI_CLK_LO\t2\n#define CUSTOM_SPI_CS_HOLD\t2\n#define CUSTOM_SPI_CS_HI\t3\n\nstatic bool atl1_spi_read(struct atl1_hw *hw, u32 addr, u32 *buf)\n{\n\tint i;\n\tu32 value;\n\n\tiowrite32(0, hw->hw_addr + REG_SPI_DATA);\n\tiowrite32(addr, hw->hw_addr + REG_SPI_ADDR);\n\n\tvalue = SPI_FLASH_CTRL_WAIT_READY |\n\t    (CUSTOM_SPI_CS_SETUP & SPI_FLASH_CTRL_CS_SETUP_MASK) <<\n\t    SPI_FLASH_CTRL_CS_SETUP_SHIFT | (CUSTOM_SPI_CLK_HI &\n\t\t\t\t\t     SPI_FLASH_CTRL_CLK_HI_MASK) <<\n\t    SPI_FLASH_CTRL_CLK_HI_SHIFT | (CUSTOM_SPI_CLK_LO &\n\t\t\t\t\t   SPI_FLASH_CTRL_CLK_LO_MASK) <<\n\t    SPI_FLASH_CTRL_CLK_LO_SHIFT | (CUSTOM_SPI_CS_HOLD &\n\t\t\t\t\t   SPI_FLASH_CTRL_CS_HOLD_MASK) <<\n\t    SPI_FLASH_CTRL_CS_HOLD_SHIFT | (CUSTOM_SPI_CS_HI &\n\t\t\t\t\t    SPI_FLASH_CTRL_CS_HI_MASK) <<\n\t    SPI_FLASH_CTRL_CS_HI_SHIFT | (1 & SPI_FLASH_CTRL_INS_MASK) <<\n\t    SPI_FLASH_CTRL_INS_SHIFT;\n\n\tiowrite32(value, hw->hw_addr + REG_SPI_FLASH_CTRL);\n\n\tvalue |= SPI_FLASH_CTRL_START;\n\tiowrite32(value, hw->hw_addr + REG_SPI_FLASH_CTRL);\n\tioread32(hw->hw_addr + REG_SPI_FLASH_CTRL);\n\n\tfor (i = 0; i < 10; i++) {\n\t\tmsleep(1);\n\t\tvalue = ioread32(hw->hw_addr + REG_SPI_FLASH_CTRL);\n\t\tif (!(value & SPI_FLASH_CTRL_START))\n\t\t\tbreak;\n\t}\n\n\tif (value & SPI_FLASH_CTRL_START)\n\t\treturn false;\n\n\t*buf = ioread32(hw->hw_addr + REG_SPI_DATA);\n\n\treturn true;\n}\n\n \nstatic int atl1_get_permanent_address(struct atl1_hw *hw)\n{\n\tu32 addr[2];\n\tu32 i, control;\n\tu16 reg;\n\tu8 eth_addr[ETH_ALEN];\n\tbool key_valid;\n\n\tif (is_valid_ether_addr(hw->perm_mac_addr))\n\t\treturn 0;\n\n\t \n\taddr[0] = addr[1] = 0;\n\n\tif (!atl1_check_eeprom_exist(hw)) {\n\t\treg = 0;\n\t\tkey_valid = false;\n\t\t \n\t\ti = 0;\n\t\twhile (1) {\n\t\t\tif (atl1_read_eeprom(hw, i + 0x100, &control)) {\n\t\t\t\tif (key_valid) {\n\t\t\t\t\tif (reg == REG_MAC_STA_ADDR)\n\t\t\t\t\t\taddr[0] = control;\n\t\t\t\t\telse if (reg == (REG_MAC_STA_ADDR + 4))\n\t\t\t\t\t\taddr[1] = control;\n\t\t\t\t\tkey_valid = false;\n\t\t\t\t} else if ((control & 0xff) == 0x5A) {\n\t\t\t\t\tkey_valid = true;\n\t\t\t\t\treg = (u16) (control >> 16);\n\t\t\t\t} else\n\t\t\t\t\tbreak;\n\t\t\t} else\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t\ti += 4;\n\t\t}\n\n\t\t*(u32 *) &eth_addr[2] = swab32(addr[0]);\n\t\t*(u16 *) &eth_addr[0] = swab16(*(u16 *) &addr[1]);\n\t\tif (is_valid_ether_addr(eth_addr)) {\n\t\t\tmemcpy(hw->perm_mac_addr, eth_addr, ETH_ALEN);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\taddr[0] = addr[1] = 0;\n\treg = 0;\n\tkey_valid = false;\n\ti = 0;\n\twhile (1) {\n\t\tif (atl1_spi_read(hw, i + 0x1f000, &control)) {\n\t\t\tif (key_valid) {\n\t\t\t\tif (reg == REG_MAC_STA_ADDR)\n\t\t\t\t\taddr[0] = control;\n\t\t\t\telse if (reg == (REG_MAC_STA_ADDR + 4))\n\t\t\t\t\taddr[1] = control;\n\t\t\t\tkey_valid = false;\n\t\t\t} else if ((control & 0xff) == 0x5A) {\n\t\t\t\tkey_valid = true;\n\t\t\t\treg = (u16) (control >> 16);\n\t\t\t} else\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t} else\n\t\t\t \n\t\t\tbreak;\n\t\ti += 4;\n\t}\n\n\t*(u32 *) &eth_addr[2] = swab32(addr[0]);\n\t*(u16 *) &eth_addr[0] = swab16(*(u16 *) &addr[1]);\n\tif (is_valid_ether_addr(eth_addr)) {\n\t\tmemcpy(hw->perm_mac_addr, eth_addr, ETH_ALEN);\n\t\treturn 0;\n\t}\n\n\t \n\taddr[0] = ioread32(hw->hw_addr + REG_MAC_STA_ADDR);\n\taddr[1] = ioread16(hw->hw_addr + (REG_MAC_STA_ADDR + 4));\n\t*(u32 *) &eth_addr[2] = swab32(addr[0]);\n\t*(u16 *) &eth_addr[0] = swab16(*(u16 *) &addr[1]);\n\tif (is_valid_ether_addr(eth_addr)) {\n\t\tmemcpy(hw->perm_mac_addr, eth_addr, ETH_ALEN);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\n \nstatic s32 atl1_read_mac_addr(struct atl1_hw *hw)\n{\n\ts32 ret = 0;\n\tu16 i;\n\n\tif (atl1_get_permanent_address(hw)) {\n\t\teth_random_addr(hw->perm_mac_addr);\n\t\tret = 1;\n\t}\n\n\tfor (i = 0; i < ETH_ALEN; i++)\n\t\thw->mac_addr[i] = hw->perm_mac_addr[i];\n\treturn ret;\n}\n\n \nstatic u32 atl1_hash_mc_addr(struct atl1_hw *hw, u8 *mc_addr)\n{\n\tu32 crc32, value = 0;\n\tint i;\n\n\tcrc32 = ether_crc_le(6, mc_addr);\n\tfor (i = 0; i < 32; i++)\n\t\tvalue |= (((crc32 >> i) & 1) << (31 - i));\n\n\treturn value;\n}\n\n \nstatic void atl1_hash_set(struct atl1_hw *hw, u32 hash_value)\n{\n\tu32 hash_bit, hash_reg;\n\tu32 mta;\n\n\t \n\thash_reg = (hash_value >> 31) & 0x1;\n\thash_bit = (hash_value >> 26) & 0x1F;\n\tmta = ioread32((hw->hw_addr + REG_RX_HASH_TABLE) + (hash_reg << 2));\n\tmta |= (1 << hash_bit);\n\tiowrite32(mta, (hw->hw_addr + REG_RX_HASH_TABLE) + (hash_reg << 2));\n}\n\n \nstatic s32 atl1_write_phy_reg(struct atl1_hw *hw, u32 reg_addr, u16 phy_data)\n{\n\tint i;\n\tu32 val;\n\n\tval = ((u32) (phy_data & MDIO_DATA_MASK)) << MDIO_DATA_SHIFT |\n\t    (reg_addr & MDIO_REG_ADDR_MASK) << MDIO_REG_ADDR_SHIFT |\n\t    MDIO_SUP_PREAMBLE |\n\t    MDIO_START | MDIO_CLK_25_4 << MDIO_CLK_SEL_SHIFT;\n\tiowrite32(val, hw->hw_addr + REG_MDIO_CTRL);\n\tioread32(hw->hw_addr + REG_MDIO_CTRL);\n\n\tfor (i = 0; i < MDIO_WAIT_TIMES; i++) {\n\t\tudelay(2);\n\t\tval = ioread32(hw->hw_addr + REG_MDIO_CTRL);\n\t\tif (!(val & (MDIO_START | MDIO_BUSY)))\n\t\t\tbreak;\n\t}\n\n\tif (!(val & (MDIO_START | MDIO_BUSY)))\n\t\treturn 0;\n\n\treturn ATLX_ERR_PHY;\n}\n\n \nstatic s32 atl1_phy_leave_power_saving(struct atl1_hw *hw)\n{\n\ts32 ret;\n\tret = atl1_write_phy_reg(hw, 29, 0x0029);\n\tif (ret)\n\t\treturn ret;\n\treturn atl1_write_phy_reg(hw, 30, 0);\n}\n\n \nstatic s32 atl1_phy_reset(struct atl1_hw *hw)\n{\n\tstruct pci_dev *pdev = hw->back->pdev;\n\tstruct atl1_adapter *adapter = hw->back;\n\ts32 ret_val;\n\tu16 phy_data;\n\n\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\n\t    hw->media_type == MEDIA_TYPE_1000M_FULL)\n\t\tphy_data = MII_CR_RESET | MII_CR_AUTO_NEG_EN;\n\telse {\n\t\tswitch (hw->media_type) {\n\t\tcase MEDIA_TYPE_100M_FULL:\n\t\t\tphy_data =\n\t\t\t    MII_CR_FULL_DUPLEX | MII_CR_SPEED_100 |\n\t\t\t    MII_CR_RESET;\n\t\t\tbreak;\n\t\tcase MEDIA_TYPE_100M_HALF:\n\t\t\tphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\n\t\t\tbreak;\n\t\tcase MEDIA_TYPE_10M_FULL:\n\t\t\tphy_data =\n\t\t\t    MII_CR_FULL_DUPLEX | MII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tret_val = atl1_write_phy_reg(hw, MII_BMCR, phy_data);\n\tif (ret_val) {\n\t\tu32 val;\n\t\tint i;\n\t\t \n\t\tif (netif_msg_hw(adapter))\n\t\t\tdev_dbg(&pdev->dev, \"pcie phy link down\\n\");\n\n\t\tfor (i = 0; i < 25; i++) {\n\t\t\tmsleep(1);\n\t\t\tval = ioread32(hw->hw_addr + REG_MDIO_CTRL);\n\t\t\tif (!(val & (MDIO_START | MDIO_BUSY)))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif ((val & (MDIO_START | MDIO_BUSY)) != 0) {\n\t\t\tif (netif_msg_hw(adapter))\n\t\t\t\tdev_warn(&pdev->dev,\n\t\t\t\t\t\"pcie link down at least 25ms\\n\");\n\t\t\treturn ret_val;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic s32 atl1_phy_setup_autoneg_adv(struct atl1_hw *hw)\n{\n\ts32 ret_val;\n\ts16 mii_autoneg_adv_reg;\n\ts16 mii_1000t_ctrl_reg;\n\n\t \n\tmii_autoneg_adv_reg = MII_AR_DEFAULT_CAP_MASK;\n\n\t \n\tmii_1000t_ctrl_reg = MII_ATLX_CR_1000T_DEFAULT_CAP_MASK;\n\n\t \n\tmii_autoneg_adv_reg &= ~MII_AR_SPEED_MASK;\n\tmii_1000t_ctrl_reg &= ~MII_ATLX_CR_1000T_SPEED_MASK;\n\n\t \n\tswitch (hw->media_type) {\n\tcase MEDIA_TYPE_AUTO_SENSOR:\n\t\tmii_autoneg_adv_reg |= (MII_AR_10T_HD_CAPS |\n\t\t\t\t\tMII_AR_10T_FD_CAPS |\n\t\t\t\t\tMII_AR_100TX_HD_CAPS |\n\t\t\t\t\tMII_AR_100TX_FD_CAPS);\n\t\tmii_1000t_ctrl_reg |= MII_ATLX_CR_1000T_FD_CAPS;\n\t\tbreak;\n\n\tcase MEDIA_TYPE_1000M_FULL:\n\t\tmii_1000t_ctrl_reg |= MII_ATLX_CR_1000T_FD_CAPS;\n\t\tbreak;\n\n\tcase MEDIA_TYPE_100M_FULL:\n\t\tmii_autoneg_adv_reg |= MII_AR_100TX_FD_CAPS;\n\t\tbreak;\n\n\tcase MEDIA_TYPE_100M_HALF:\n\t\tmii_autoneg_adv_reg |= MII_AR_100TX_HD_CAPS;\n\t\tbreak;\n\n\tcase MEDIA_TYPE_10M_FULL:\n\t\tmii_autoneg_adv_reg |= MII_AR_10T_FD_CAPS;\n\t\tbreak;\n\n\tdefault:\n\t\tmii_autoneg_adv_reg |= MII_AR_10T_HD_CAPS;\n\t\tbreak;\n\t}\n\n\t \n\tmii_autoneg_adv_reg |= (MII_AR_ASM_DIR | MII_AR_PAUSE);\n\n\thw->mii_autoneg_adv_reg = mii_autoneg_adv_reg;\n\thw->mii_1000t_ctrl_reg = mii_1000t_ctrl_reg;\n\n\tret_val = atl1_write_phy_reg(hw, MII_ADVERTISE, mii_autoneg_adv_reg);\n\tif (ret_val)\n\t\treturn ret_val;\n\n\tret_val = atl1_write_phy_reg(hw, MII_ATLX_CR, mii_1000t_ctrl_reg);\n\tif (ret_val)\n\t\treturn ret_val;\n\n\treturn 0;\n}\n\n \nstatic s32 atl1_setup_link(struct atl1_hw *hw)\n{\n\tstruct pci_dev *pdev = hw->back->pdev;\n\tstruct atl1_adapter *adapter = hw->back;\n\ts32 ret_val;\n\n\t \n\tret_val = atl1_phy_setup_autoneg_adv(hw);\n\tif (ret_val) {\n\t\tif (netif_msg_link(adapter))\n\t\t\tdev_dbg(&pdev->dev,\n\t\t\t\t\"error setting up autonegotiation\\n\");\n\t\treturn ret_val;\n\t}\n\t \n\tret_val = atl1_phy_reset(hw);\n\tif (ret_val) {\n\t\tif (netif_msg_link(adapter))\n\t\t\tdev_dbg(&pdev->dev, \"error resetting phy\\n\");\n\t\treturn ret_val;\n\t}\n\thw->phy_configured = true;\n\treturn ret_val;\n}\n\nstatic void atl1_init_flash_opcode(struct atl1_hw *hw)\n{\n\tif (hw->flash_vendor >= ARRAY_SIZE(flash_table))\n\t\t \n\t\thw->flash_vendor = 0;\n\n\t \n\tiowrite8(flash_table[hw->flash_vendor].cmd_program,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_PROGRAM);\n\tiowrite8(flash_table[hw->flash_vendor].cmd_sector_erase,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_SC_ERASE);\n\tiowrite8(flash_table[hw->flash_vendor].cmd_chip_erase,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_CHIP_ERASE);\n\tiowrite8(flash_table[hw->flash_vendor].cmd_rdid,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_RDID);\n\tiowrite8(flash_table[hw->flash_vendor].cmd_wren,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_WREN);\n\tiowrite8(flash_table[hw->flash_vendor].cmd_rdsr,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_RDSR);\n\tiowrite8(flash_table[hw->flash_vendor].cmd_wrsr,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_WRSR);\n\tiowrite8(flash_table[hw->flash_vendor].cmd_read,\n\t\thw->hw_addr + REG_SPI_FLASH_OP_READ);\n}\n\n \nstatic s32 atl1_init_hw(struct atl1_hw *hw)\n{\n\tu32 ret_val = 0;\n\n\t \n\tiowrite32(0, hw->hw_addr + REG_RX_HASH_TABLE);\n\t \n\tiowrite32(0, (hw->hw_addr + REG_RX_HASH_TABLE) + (1 << 2));\n\n\tatl1_init_flash_opcode(hw);\n\n\tif (!hw->phy_configured) {\n\t\t \n\t\tret_val = atl1_write_phy_reg(hw, 18, 0xC00);\n\t\tif (ret_val)\n\t\t\treturn ret_val;\n\t\t \n\t\tret_val = atl1_phy_leave_power_saving(hw);\n\t\tif (ret_val)\n\t\t\treturn ret_val;\n\t\t \n\t\tret_val = atl1_setup_link(hw);\n\t}\n\treturn ret_val;\n}\n\n \nstatic s32 atl1_get_speed_and_duplex(struct atl1_hw *hw, u16 *speed, u16 *duplex)\n{\n\tstruct pci_dev *pdev = hw->back->pdev;\n\tstruct atl1_adapter *adapter = hw->back;\n\ts32 ret_val;\n\tu16 phy_data;\n\n\t \n\tret_val = atl1_read_phy_reg(hw, MII_ATLX_PSSR, &phy_data);\n\tif (ret_val)\n\t\treturn ret_val;\n\n\tif (!(phy_data & MII_ATLX_PSSR_SPD_DPLX_RESOLVED))\n\t\treturn ATLX_ERR_PHY_RES;\n\n\tswitch (phy_data & MII_ATLX_PSSR_SPEED) {\n\tcase MII_ATLX_PSSR_1000MBS:\n\t\t*speed = SPEED_1000;\n\t\tbreak;\n\tcase MII_ATLX_PSSR_100MBS:\n\t\t*speed = SPEED_100;\n\t\tbreak;\n\tcase MII_ATLX_PSSR_10MBS:\n\t\t*speed = SPEED_10;\n\t\tbreak;\n\tdefault:\n\t\tif (netif_msg_hw(adapter))\n\t\t\tdev_dbg(&pdev->dev, \"error getting speed\\n\");\n\t\treturn ATLX_ERR_PHY_SPEED;\n\t}\n\tif (phy_data & MII_ATLX_PSSR_DPLX)\n\t\t*duplex = FULL_DUPLEX;\n\telse\n\t\t*duplex = HALF_DUPLEX;\n\n\treturn 0;\n}\n\nstatic void atl1_set_mac_addr(struct atl1_hw *hw)\n{\n\tu32 value;\n\t \n\tvalue = (((u32) hw->mac_addr[2]) << 24) |\n\t    (((u32) hw->mac_addr[3]) << 16) |\n\t    (((u32) hw->mac_addr[4]) << 8) | (((u32) hw->mac_addr[5]));\n\tiowrite32(value, hw->hw_addr + REG_MAC_STA_ADDR);\n\t \n\tvalue = (((u32) hw->mac_addr[0]) << 8) | (((u32) hw->mac_addr[1]));\n\tiowrite32(value, (hw->hw_addr + REG_MAC_STA_ADDR) + (1 << 2));\n}\n\n \nstatic int atl1_sw_init(struct atl1_adapter *adapter)\n{\n\tstruct atl1_hw *hw = &adapter->hw;\n\tstruct net_device *netdev = adapter->netdev;\n\n\thw->max_frame_size = netdev->mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\thw->min_frame_size = ETH_ZLEN + ETH_FCS_LEN;\n\n\tadapter->wol = 0;\n\tdevice_set_wakeup_enable(&adapter->pdev->dev, false);\n\tadapter->rx_buffer_len = (hw->max_frame_size + 7) & ~7;\n\tadapter->ict = 50000;\t\t \n\tadapter->link_speed = SPEED_0;\t \n\tadapter->link_duplex = FULL_DUPLEX;\n\n\thw->phy_configured = false;\n\thw->preamble_len = 7;\n\thw->ipgt = 0x60;\n\thw->min_ifg = 0x50;\n\thw->ipgr1 = 0x40;\n\thw->ipgr2 = 0x60;\n\thw->max_retry = 0xf;\n\thw->lcol = 0x37;\n\thw->jam_ipg = 7;\n\thw->rfd_burst = 8;\n\thw->rrd_burst = 8;\n\thw->rfd_fetch_gap = 1;\n\thw->rx_jumbo_th = adapter->rx_buffer_len / 8;\n\thw->rx_jumbo_lkah = 1;\n\thw->rrd_ret_timer = 16;\n\thw->tpd_burst = 4;\n\thw->tpd_fetch_th = 16;\n\thw->txf_burst = 0x100;\n\thw->tx_jumbo_task_th = (hw->max_frame_size + 7) >> 3;\n\thw->tpd_fetch_gap = 1;\n\thw->rcb_value = atl1_rcb_64;\n\thw->dma_ord = atl1_dma_ord_enh;\n\thw->dmar_block = atl1_dma_req_256;\n\thw->dmaw_block = atl1_dma_req_256;\n\thw->cmb_rrd = 4;\n\thw->cmb_tpd = 4;\n\thw->cmb_rx_timer = 1;\t \n\thw->cmb_tx_timer = 1;\t \n\thw->smb_timer = 100000;\t \n\n\tspin_lock_init(&adapter->lock);\n\tspin_lock_init(&adapter->mb_lock);\n\n\treturn 0;\n}\n\nstatic int mdio_read(struct net_device *netdev, int phy_id, int reg_num)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tu16 result;\n\n\tatl1_read_phy_reg(&adapter->hw, reg_num & 0x1f, &result);\n\n\treturn result;\n}\n\nstatic void mdio_write(struct net_device *netdev, int phy_id, int reg_num,\n\tint val)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\n\tatl1_write_phy_reg(&adapter->hw, reg_num, val);\n}\n\nstatic int atl1_mii_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tunsigned long flags;\n\tint retval;\n\n\tif (!netif_running(netdev))\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&adapter->lock, flags);\n\tretval = generic_mii_ioctl(&adapter->mii, if_mii(ifr), cmd, NULL);\n\tspin_unlock_irqrestore(&adapter->lock, flags);\n\n\treturn retval;\n}\n\n \nstatic s32 atl1_setup_ring_resources(struct atl1_adapter *adapter)\n{\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\n\tstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\n\tstruct atl1_ring_header *ring_header = &adapter->ring_header;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tint size;\n\tu8 offset = 0;\n\n\tsize = sizeof(struct atl1_buffer) * (tpd_ring->count + rfd_ring->count);\n\ttpd_ring->buffer_info = kzalloc(size, GFP_KERNEL);\n\tif (unlikely(!tpd_ring->buffer_info)) {\n\t\tif (netif_msg_drv(adapter))\n\t\t\tdev_err(&pdev->dev, \"kzalloc failed , size = D%d\\n\",\n\t\t\t\tsize);\n\t\tgoto err_nomem;\n\t}\n\trfd_ring->buffer_info =\n\t\t(tpd_ring->buffer_info + tpd_ring->count);\n\n\t \n\tring_header->size =\n\t\tsizeof(struct tx_packet_desc) * tpd_ring->count\n\t\t+ sizeof(struct rx_free_desc) * rfd_ring->count\n\t\t+ sizeof(struct rx_return_desc) * rrd_ring->count\n\t\t+ sizeof(struct coals_msg_block)\n\t\t+ sizeof(struct stats_msg_block)\n\t\t+ 40;\n\n\tring_header->desc = dma_alloc_coherent(&pdev->dev, ring_header->size,\n\t\t\t\t\t       &ring_header->dma, GFP_KERNEL);\n\tif (unlikely(!ring_header->desc)) {\n\t\tif (netif_msg_drv(adapter))\n\t\t\tdev_err(&pdev->dev, \"dma_alloc_coherent failed\\n\");\n\t\tgoto err_nomem;\n\t}\n\n\t \n\ttpd_ring->dma = ring_header->dma;\n\toffset = (tpd_ring->dma & 0x7) ? (8 - (ring_header->dma & 0x7)) : 0;\n\ttpd_ring->dma += offset;\n\ttpd_ring->desc = (u8 *) ring_header->desc + offset;\n\ttpd_ring->size = sizeof(struct tx_packet_desc) * tpd_ring->count;\n\n\t \n\trfd_ring->dma = tpd_ring->dma + tpd_ring->size;\n\toffset = (rfd_ring->dma & 0x7) ? (8 - (rfd_ring->dma & 0x7)) : 0;\n\trfd_ring->dma += offset;\n\trfd_ring->desc = (u8 *) tpd_ring->desc + (tpd_ring->size + offset);\n\trfd_ring->size = sizeof(struct rx_free_desc) * rfd_ring->count;\n\n\n\t \n\trrd_ring->dma = rfd_ring->dma + rfd_ring->size;\n\toffset = (rrd_ring->dma & 0x7) ? (8 - (rrd_ring->dma & 0x7)) : 0;\n\trrd_ring->dma += offset;\n\trrd_ring->desc = (u8 *) rfd_ring->desc + (rfd_ring->size + offset);\n\trrd_ring->size = sizeof(struct rx_return_desc) * rrd_ring->count;\n\n\n\t \n\tadapter->cmb.dma = rrd_ring->dma + rrd_ring->size;\n\toffset = (adapter->cmb.dma & 0x7) ? (8 - (adapter->cmb.dma & 0x7)) : 0;\n\tadapter->cmb.dma += offset;\n\tadapter->cmb.cmb = (struct coals_msg_block *)\n\t\t((u8 *) rrd_ring->desc + (rrd_ring->size + offset));\n\n\t \n\tadapter->smb.dma = adapter->cmb.dma + sizeof(struct coals_msg_block);\n\toffset = (adapter->smb.dma & 0x7) ? (8 - (adapter->smb.dma & 0x7)) : 0;\n\tadapter->smb.dma += offset;\n\tadapter->smb.smb = (struct stats_msg_block *)\n\t\t((u8 *) adapter->cmb.cmb +\n\t\t(sizeof(struct coals_msg_block) + offset));\n\n\treturn 0;\n\nerr_nomem:\n\tkfree(tpd_ring->buffer_info);\n\treturn -ENOMEM;\n}\n\nstatic void atl1_init_ring_ptrs(struct atl1_adapter *adapter)\n{\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\n\tstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\n\n\tatomic_set(&tpd_ring->next_to_use, 0);\n\tatomic_set(&tpd_ring->next_to_clean, 0);\n\n\trfd_ring->next_to_clean = 0;\n\tatomic_set(&rfd_ring->next_to_use, 0);\n\n\trrd_ring->next_to_use = 0;\n\tatomic_set(&rrd_ring->next_to_clean, 0);\n}\n\n \nstatic void atl1_clean_rx_ring(struct atl1_adapter *adapter)\n{\n\tstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\n\tstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\n\tstruct atl1_buffer *buffer_info;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tunsigned long size;\n\tunsigned int i;\n\n\t \n\tfor (i = 0; i < rfd_ring->count; i++) {\n\t\tbuffer_info = &rfd_ring->buffer_info[i];\n\t\tif (buffer_info->dma) {\n\t\t\tdma_unmap_page(&pdev->dev, buffer_info->dma,\n\t\t\t\t       buffer_info->length, DMA_FROM_DEVICE);\n\t\t\tbuffer_info->dma = 0;\n\t\t}\n\t\tif (buffer_info->skb) {\n\t\t\tdev_kfree_skb(buffer_info->skb);\n\t\t\tbuffer_info->skb = NULL;\n\t\t}\n\t}\n\n\tsize = sizeof(struct atl1_buffer) * rfd_ring->count;\n\tmemset(rfd_ring->buffer_info, 0, size);\n\n\t \n\tmemset(rfd_ring->desc, 0, rfd_ring->size);\n\n\trfd_ring->next_to_clean = 0;\n\tatomic_set(&rfd_ring->next_to_use, 0);\n\n\trrd_ring->next_to_use = 0;\n\tatomic_set(&rrd_ring->next_to_clean, 0);\n}\n\n \nstatic void atl1_clean_tx_ring(struct atl1_adapter *adapter)\n{\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tstruct atl1_buffer *buffer_info;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tunsigned long size;\n\tunsigned int i;\n\n\t \n\tfor (i = 0; i < tpd_ring->count; i++) {\n\t\tbuffer_info = &tpd_ring->buffer_info[i];\n\t\tif (buffer_info->dma) {\n\t\t\tdma_unmap_page(&pdev->dev, buffer_info->dma,\n\t\t\t\t       buffer_info->length, DMA_TO_DEVICE);\n\t\t\tbuffer_info->dma = 0;\n\t\t}\n\t}\n\n\tfor (i = 0; i < tpd_ring->count; i++) {\n\t\tbuffer_info = &tpd_ring->buffer_info[i];\n\t\tif (buffer_info->skb) {\n\t\t\tdev_kfree_skb_any(buffer_info->skb);\n\t\t\tbuffer_info->skb = NULL;\n\t\t}\n\t}\n\n\tsize = sizeof(struct atl1_buffer) * tpd_ring->count;\n\tmemset(tpd_ring->buffer_info, 0, size);\n\n\t \n\tmemset(tpd_ring->desc, 0, tpd_ring->size);\n\n\tatomic_set(&tpd_ring->next_to_use, 0);\n\tatomic_set(&tpd_ring->next_to_clean, 0);\n}\n\n \nstatic void atl1_free_ring_resources(struct atl1_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\n\tstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\n\tstruct atl1_ring_header *ring_header = &adapter->ring_header;\n\n\tatl1_clean_tx_ring(adapter);\n\tatl1_clean_rx_ring(adapter);\n\n\tkfree(tpd_ring->buffer_info);\n\tdma_free_coherent(&pdev->dev, ring_header->size, ring_header->desc,\n\t\t\t  ring_header->dma);\n\n\ttpd_ring->buffer_info = NULL;\n\ttpd_ring->desc = NULL;\n\ttpd_ring->dma = 0;\n\n\trfd_ring->buffer_info = NULL;\n\trfd_ring->desc = NULL;\n\trfd_ring->dma = 0;\n\n\trrd_ring->desc = NULL;\n\trrd_ring->dma = 0;\n\n\tadapter->cmb.dma = 0;\n\tadapter->cmb.cmb = NULL;\n\n\tadapter->smb.dma = 0;\n\tadapter->smb.smb = NULL;\n}\n\nstatic void atl1_setup_mac_ctrl(struct atl1_adapter *adapter)\n{\n\tu32 value;\n\tstruct atl1_hw *hw = &adapter->hw;\n\tstruct net_device *netdev = adapter->netdev;\n\t \n\tvalue = MAC_CTRL_TX_EN | MAC_CTRL_RX_EN;\n\t \n\tif (FULL_DUPLEX == adapter->link_duplex)\n\t\tvalue |= MAC_CTRL_DUPLX;\n\t \n\tvalue |= ((u32) ((SPEED_1000 == adapter->link_speed) ?\n\t\t\t MAC_CTRL_SPEED_1000 : MAC_CTRL_SPEED_10_100) <<\n\t\t  MAC_CTRL_SPEED_SHIFT);\n\t \n\tvalue |= (MAC_CTRL_TX_FLOW | MAC_CTRL_RX_FLOW);\n\t \n\tvalue |= (MAC_CTRL_ADD_CRC | MAC_CTRL_PAD);\n\t \n\tvalue |= (((u32) adapter->hw.preamble_len\n\t\t   & MAC_CTRL_PRMLEN_MASK) << MAC_CTRL_PRMLEN_SHIFT);\n\t \n\t__atlx_vlan_mode(netdev->features, &value);\n\t \n\t \n\tvalue |= MAC_CTRL_BC_EN;\n\tif (netdev->flags & IFF_PROMISC)\n\t\tvalue |= MAC_CTRL_PROMIS_EN;\n\telse if (netdev->flags & IFF_ALLMULTI)\n\t\tvalue |= MAC_CTRL_MC_ALL_EN;\n\t \n\tiowrite32(value, hw->hw_addr + REG_MAC_CTRL);\n}\n\nstatic u32 atl1_check_link(struct atl1_adapter *adapter)\n{\n\tstruct atl1_hw *hw = &adapter->hw;\n\tstruct net_device *netdev = adapter->netdev;\n\tu32 ret_val;\n\tu16 speed, duplex, phy_data;\n\tint reconfig = 0;\n\n\t \n\tatl1_read_phy_reg(hw, MII_BMSR, &phy_data);\n\tatl1_read_phy_reg(hw, MII_BMSR, &phy_data);\n\tif (!(phy_data & BMSR_LSTATUS)) {\n\t\t \n\t\tif (netif_carrier_ok(netdev)) {\n\t\t\t \n\t\t\tif (netif_msg_link(adapter))\n\t\t\t\tdev_info(&adapter->pdev->dev, \"link is down\\n\");\n\t\t\tadapter->link_speed = SPEED_0;\n\t\t\tnetif_carrier_off(netdev);\n\t\t}\n\t\treturn 0;\n\t}\n\n\t \n\tret_val = atl1_get_speed_and_duplex(hw, &speed, &duplex);\n\tif (ret_val)\n\t\treturn ret_val;\n\n\tswitch (hw->media_type) {\n\tcase MEDIA_TYPE_1000M_FULL:\n\t\tif (speed != SPEED_1000 || duplex != FULL_DUPLEX)\n\t\t\treconfig = 1;\n\t\tbreak;\n\tcase MEDIA_TYPE_100M_FULL:\n\t\tif (speed != SPEED_100 || duplex != FULL_DUPLEX)\n\t\t\treconfig = 1;\n\t\tbreak;\n\tcase MEDIA_TYPE_100M_HALF:\n\t\tif (speed != SPEED_100 || duplex != HALF_DUPLEX)\n\t\t\treconfig = 1;\n\t\tbreak;\n\tcase MEDIA_TYPE_10M_FULL:\n\t\tif (speed != SPEED_10 || duplex != FULL_DUPLEX)\n\t\t\treconfig = 1;\n\t\tbreak;\n\tcase MEDIA_TYPE_10M_HALF:\n\t\tif (speed != SPEED_10 || duplex != HALF_DUPLEX)\n\t\t\treconfig = 1;\n\t\tbreak;\n\t}\n\n\t \n\tif (!reconfig) {\n\t\tif (adapter->link_speed != speed ||\n\t\t    adapter->link_duplex != duplex) {\n\t\t\tadapter->link_speed = speed;\n\t\t\tadapter->link_duplex = duplex;\n\t\t\tatl1_setup_mac_ctrl(adapter);\n\t\t\tif (netif_msg_link(adapter))\n\t\t\t\tdev_info(&adapter->pdev->dev,\n\t\t\t\t\t\"%s link is up %d Mbps %s\\n\",\n\t\t\t\t\tnetdev->name, adapter->link_speed,\n\t\t\t\t\tadapter->link_duplex == FULL_DUPLEX ?\n\t\t\t\t\t\"full duplex\" : \"half duplex\");\n\t\t}\n\t\tif (!netif_carrier_ok(netdev)) {\n\t\t\t \n\t\t\tnetif_carrier_on(netdev);\n\t\t}\n\t\treturn 0;\n\t}\n\n\t \n\tif (netif_carrier_ok(netdev)) {\n\t\tadapter->link_speed = SPEED_0;\n\t\tnetif_carrier_off(netdev);\n\t\tnetif_stop_queue(netdev);\n\t}\n\n\tif (hw->media_type != MEDIA_TYPE_AUTO_SENSOR &&\n\t    hw->media_type != MEDIA_TYPE_1000M_FULL) {\n\t\tswitch (hw->media_type) {\n\t\tcase MEDIA_TYPE_100M_FULL:\n\t\t\tphy_data = MII_CR_FULL_DUPLEX | MII_CR_SPEED_100 |\n\t\t\t           MII_CR_RESET;\n\t\t\tbreak;\n\t\tcase MEDIA_TYPE_100M_HALF:\n\t\t\tphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\n\t\t\tbreak;\n\t\tcase MEDIA_TYPE_10M_FULL:\n\t\t\tphy_data =\n\t\t\t    MII_CR_FULL_DUPLEX | MII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\tbreak;\n\t\t}\n\t\tatl1_write_phy_reg(hw, MII_BMCR, phy_data);\n\t\treturn 0;\n\t}\n\n\t \n\tif (!adapter->phy_timer_pending) {\n\t\tadapter->phy_timer_pending = true;\n\t\tmod_timer(&adapter->phy_config_timer,\n\t\t\t  round_jiffies(jiffies + 3 * HZ));\n\t}\n\n\treturn 0;\n}\n\nstatic void set_flow_ctrl_old(struct atl1_adapter *adapter)\n{\n\tu32 hi, lo, value;\n\n\t \n\tvalue = adapter->rfd_ring.count;\n\thi = value / 16;\n\tif (hi < 2)\n\t\thi = 2;\n\tlo = value * 7 / 8;\n\n\tvalue = ((hi & RXQ_RXF_PAUSE_TH_HI_MASK) << RXQ_RXF_PAUSE_TH_HI_SHIFT) |\n\t\t((lo & RXQ_RXF_PAUSE_TH_LO_MASK) << RXQ_RXF_PAUSE_TH_LO_SHIFT);\n\tiowrite32(value, adapter->hw.hw_addr + REG_RXQ_RXF_PAUSE_THRESH);\n\n\t \n\tvalue = adapter->rrd_ring.count;\n\tlo = value / 16;\n\thi = value * 7 / 8;\n\tif (lo < 2)\n\t\tlo = 2;\n\tvalue = ((hi & RXQ_RRD_PAUSE_TH_HI_MASK) << RXQ_RRD_PAUSE_TH_HI_SHIFT) |\n\t\t((lo & RXQ_RRD_PAUSE_TH_LO_MASK) << RXQ_RRD_PAUSE_TH_LO_SHIFT);\n\tiowrite32(value, adapter->hw.hw_addr + REG_RXQ_RRD_PAUSE_THRESH);\n}\n\nstatic void set_flow_ctrl_new(struct atl1_hw *hw)\n{\n\tu32 hi, lo, value;\n\n\t \n\tvalue = ioread32(hw->hw_addr + REG_SRAM_RXF_LEN);\n\tlo = value / 16;\n\tif (lo < 192)\n\t\tlo = 192;\n\thi = value * 7 / 8;\n\tif (hi < lo)\n\t\thi = lo + 16;\n\tvalue = ((hi & RXQ_RXF_PAUSE_TH_HI_MASK) << RXQ_RXF_PAUSE_TH_HI_SHIFT) |\n\t\t((lo & RXQ_RXF_PAUSE_TH_LO_MASK) << RXQ_RXF_PAUSE_TH_LO_SHIFT);\n\tiowrite32(value, hw->hw_addr + REG_RXQ_RXF_PAUSE_THRESH);\n\n\t \n\tvalue = ioread32(hw->hw_addr + REG_SRAM_RRD_LEN);\n\tlo = value / 8;\n\thi = value * 7 / 8;\n\tif (lo < 2)\n\t\tlo = 2;\n\tif (hi < lo)\n\t\thi = lo + 3;\n\tvalue = ((hi & RXQ_RRD_PAUSE_TH_HI_MASK) << RXQ_RRD_PAUSE_TH_HI_SHIFT) |\n\t\t((lo & RXQ_RRD_PAUSE_TH_LO_MASK) << RXQ_RRD_PAUSE_TH_LO_SHIFT);\n\tiowrite32(value, hw->hw_addr + REG_RXQ_RRD_PAUSE_THRESH);\n}\n\n \nstatic u32 atl1_configure(struct atl1_adapter *adapter)\n{\n\tstruct atl1_hw *hw = &adapter->hw;\n\tu32 value;\n\n\t \n\tiowrite32(0xffffffff, adapter->hw.hw_addr + REG_ISR);\n\n\t \n\tvalue = (((u32) hw->mac_addr[2]) << 24) |\n\t\t(((u32) hw->mac_addr[3]) << 16) |\n\t\t(((u32) hw->mac_addr[4]) << 8) |\n\t\t(((u32) hw->mac_addr[5]));\n\tiowrite32(value, hw->hw_addr + REG_MAC_STA_ADDR);\n\tvalue = (((u32) hw->mac_addr[0]) << 8) | (((u32) hw->mac_addr[1]));\n\tiowrite32(value, hw->hw_addr + (REG_MAC_STA_ADDR + 4));\n\n\t \n\n\t \n\tiowrite32((u32) ((adapter->tpd_ring.dma & 0xffffffff00000000ULL) >> 32),\n\t\thw->hw_addr + REG_DESC_BASE_ADDR_HI);\n\t \n\tiowrite32((u32) (adapter->rfd_ring.dma & 0x00000000ffffffffULL),\n\t\thw->hw_addr + REG_DESC_RFD_ADDR_LO);\n\tiowrite32((u32) (adapter->rrd_ring.dma & 0x00000000ffffffffULL),\n\t\thw->hw_addr + REG_DESC_RRD_ADDR_LO);\n\tiowrite32((u32) (adapter->tpd_ring.dma & 0x00000000ffffffffULL),\n\t\thw->hw_addr + REG_DESC_TPD_ADDR_LO);\n\tiowrite32((u32) (adapter->cmb.dma & 0x00000000ffffffffULL),\n\t\thw->hw_addr + REG_DESC_CMB_ADDR_LO);\n\tiowrite32((u32) (adapter->smb.dma & 0x00000000ffffffffULL),\n\t\thw->hw_addr + REG_DESC_SMB_ADDR_LO);\n\n\t \n\tvalue = adapter->rrd_ring.count;\n\tvalue <<= 16;\n\tvalue += adapter->rfd_ring.count;\n\tiowrite32(value, hw->hw_addr + REG_DESC_RFD_RRD_RING_SIZE);\n\tiowrite32(adapter->tpd_ring.count, hw->hw_addr +\n\t\tREG_DESC_TPD_RING_SIZE);\n\n\t \n\tiowrite32(1, hw->hw_addr + REG_LOAD_PTR);\n\n\t \n\tvalue = ((atomic_read(&adapter->tpd_ring.next_to_use)\n\t\t  & MB_TPD_PROD_INDX_MASK) << MB_TPD_PROD_INDX_SHIFT) |\n\t\t((atomic_read(&adapter->rrd_ring.next_to_clean)\n\t\t& MB_RRD_CONS_INDX_MASK) << MB_RRD_CONS_INDX_SHIFT) |\n\t\t((atomic_read(&adapter->rfd_ring.next_to_use)\n\t\t& MB_RFD_PROD_INDX_MASK) << MB_RFD_PROD_INDX_SHIFT);\n\tiowrite32(value, hw->hw_addr + REG_MAILBOX);\n\n\t \n\tvalue = (((u32) hw->ipgt & MAC_IPG_IFG_IPGT_MASK)\n\t\t << MAC_IPG_IFG_IPGT_SHIFT) |\n\t\t(((u32) hw->min_ifg & MAC_IPG_IFG_MIFG_MASK)\n\t\t<< MAC_IPG_IFG_MIFG_SHIFT) |\n\t\t(((u32) hw->ipgr1 & MAC_IPG_IFG_IPGR1_MASK)\n\t\t<< MAC_IPG_IFG_IPGR1_SHIFT) |\n\t\t(((u32) hw->ipgr2 & MAC_IPG_IFG_IPGR2_MASK)\n\t\t<< MAC_IPG_IFG_IPGR2_SHIFT);\n\tiowrite32(value, hw->hw_addr + REG_MAC_IPG_IFG);\n\n\t \n\tvalue = ((u32) hw->lcol & MAC_HALF_DUPLX_CTRL_LCOL_MASK) |\n\t\t(((u32) hw->max_retry & MAC_HALF_DUPLX_CTRL_RETRY_MASK)\n\t\t<< MAC_HALF_DUPLX_CTRL_RETRY_SHIFT) |\n\t\tMAC_HALF_DUPLX_CTRL_EXC_DEF_EN |\n\t\t(0xa << MAC_HALF_DUPLX_CTRL_ABEBT_SHIFT) |\n\t\t(((u32) hw->jam_ipg & MAC_HALF_DUPLX_CTRL_JAMIPG_MASK)\n\t\t<< MAC_HALF_DUPLX_CTRL_JAMIPG_SHIFT);\n\tiowrite32(value, hw->hw_addr + REG_MAC_HALF_DUPLX_CTRL);\n\n\t \n\tiowrite16(adapter->imt, hw->hw_addr + REG_IRQ_MODU_TIMER_INIT);\n\tiowrite32(MASTER_CTRL_ITIMER_EN, hw->hw_addr + REG_MASTER_CTRL);\n\n\t \n\tiowrite16(adapter->ict, hw->hw_addr + REG_CMBDISDMA_TIMER);\n\n\t \n\tiowrite32(hw->max_frame_size, hw->hw_addr + REG_MTU);\n\n\t \n\tvalue = (((u32) hw->rx_jumbo_th & RXQ_JMBOSZ_TH_MASK)\n\t\t << RXQ_JMBOSZ_TH_SHIFT) |\n\t\t(((u32) hw->rx_jumbo_lkah & RXQ_JMBO_LKAH_MASK)\n\t\t<< RXQ_JMBO_LKAH_SHIFT) |\n\t\t(((u32) hw->rrd_ret_timer & RXQ_RRD_TIMER_MASK)\n\t\t<< RXQ_RRD_TIMER_SHIFT);\n\tiowrite32(value, hw->hw_addr + REG_RXQ_JMBOSZ_RRDTIM);\n\n\t \n\tswitch (hw->dev_rev) {\n\tcase 0x8001:\n\tcase 0x9001:\n\tcase 0x9002:\n\tcase 0x9003:\n\t\tset_flow_ctrl_old(adapter);\n\t\tbreak;\n\tdefault:\n\t\tset_flow_ctrl_new(hw);\n\t\tbreak;\n\t}\n\n\t \n\tvalue = (((u32) hw->tpd_burst & TXQ_CTRL_TPD_BURST_NUM_MASK)\n\t\t << TXQ_CTRL_TPD_BURST_NUM_SHIFT) |\n\t\t(((u32) hw->txf_burst & TXQ_CTRL_TXF_BURST_NUM_MASK)\n\t\t<< TXQ_CTRL_TXF_BURST_NUM_SHIFT) |\n\t\t(((u32) hw->tpd_fetch_th & TXQ_CTRL_TPD_FETCH_TH_MASK)\n\t\t<< TXQ_CTRL_TPD_FETCH_TH_SHIFT) | TXQ_CTRL_ENH_MODE |\n\t\tTXQ_CTRL_EN;\n\tiowrite32(value, hw->hw_addr + REG_TXQ_CTRL);\n\n\t \n\tvalue = (((u32) hw->tx_jumbo_task_th & TX_JUMBO_TASK_TH_MASK)\n\t\t<< TX_JUMBO_TASK_TH_SHIFT) |\n\t\t(((u32) hw->tpd_fetch_gap & TX_TPD_MIN_IPG_MASK)\n\t\t<< TX_TPD_MIN_IPG_SHIFT);\n\tiowrite32(value, hw->hw_addr + REG_TX_JUMBO_TASK_TH_TPD_IPG);\n\n\t \n\tvalue = (((u32) hw->rfd_burst & RXQ_CTRL_RFD_BURST_NUM_MASK)\n\t\t<< RXQ_CTRL_RFD_BURST_NUM_SHIFT) |\n\t\t(((u32) hw->rrd_burst & RXQ_CTRL_RRD_BURST_THRESH_MASK)\n\t\t<< RXQ_CTRL_RRD_BURST_THRESH_SHIFT) |\n\t\t(((u32) hw->rfd_fetch_gap & RXQ_CTRL_RFD_PREF_MIN_IPG_MASK)\n\t\t<< RXQ_CTRL_RFD_PREF_MIN_IPG_SHIFT) | RXQ_CTRL_CUT_THRU_EN |\n\t\tRXQ_CTRL_EN;\n\tiowrite32(value, hw->hw_addr + REG_RXQ_CTRL);\n\n\t \n\tvalue = ((((u32) hw->dmar_block) & DMA_CTRL_DMAR_BURST_LEN_MASK)\n\t\t<< DMA_CTRL_DMAR_BURST_LEN_SHIFT) |\n\t\t((((u32) hw->dmaw_block) & DMA_CTRL_DMAW_BURST_LEN_MASK)\n\t\t<< DMA_CTRL_DMAW_BURST_LEN_SHIFT) | DMA_CTRL_DMAR_EN |\n\t\tDMA_CTRL_DMAW_EN;\n\tvalue |= (u32) hw->dma_ord;\n\tif (atl1_rcb_128 == hw->rcb_value)\n\t\tvalue |= DMA_CTRL_RCB_VALUE;\n\tiowrite32(value, hw->hw_addr + REG_DMA_CTRL);\n\n\t \n\tvalue = (hw->cmb_tpd > adapter->tpd_ring.count) ?\n\t\thw->cmb_tpd : adapter->tpd_ring.count;\n\tvalue <<= 16;\n\tvalue |= hw->cmb_rrd;\n\tiowrite32(value, hw->hw_addr + REG_CMB_WRITE_TH);\n\tvalue = hw->cmb_rx_timer | ((u32) hw->cmb_tx_timer << 16);\n\tiowrite32(value, hw->hw_addr + REG_CMB_WRITE_TIMER);\n\tiowrite32(hw->smb_timer, hw->hw_addr + REG_SMB_TIMER);\n\n\t \n\tvalue = CSMB_CTRL_CMB_EN | CSMB_CTRL_SMB_EN;\n\tiowrite32(value, hw->hw_addr + REG_CSMB_CTRL);\n\n\tvalue = ioread32(adapter->hw.hw_addr + REG_ISR);\n\tif (unlikely((value & ISR_PHY_LINKDOWN) != 0))\n\t\tvalue = 1;\t \n\telse\n\t\tvalue = 0;\n\n\t \n\tiowrite32(0x3fffffff, adapter->hw.hw_addr + REG_ISR);\n\tiowrite32(0, adapter->hw.hw_addr + REG_ISR);\n\treturn value;\n}\n\n \nstatic void atl1_pcie_patch(struct atl1_adapter *adapter)\n{\n\tu32 value;\n\n\t \n\tvalue = 0x6500;\n\tiowrite32(value, adapter->hw.hw_addr + 0x12FC);\n\t \n\tvalue = ioread32(adapter->hw.hw_addr + 0x1008);\n\tvalue |= 0x8000;\n\tiowrite32(value, adapter->hw.hw_addr + 0x1008);\n}\n\n \nstatic void atl1_via_workaround(struct atl1_adapter *adapter)\n{\n\tunsigned long value;\n\n\tvalue = ioread16(adapter->hw.hw_addr + PCI_COMMAND);\n\tif (value & PCI_COMMAND_INTX_DISABLE)\n\t\tvalue &= ~PCI_COMMAND_INTX_DISABLE;\n\tiowrite32(value, adapter->hw.hw_addr + PCI_COMMAND);\n}\n\nstatic void atl1_inc_smb(struct atl1_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct stats_msg_block *smb = adapter->smb.smb;\n\n\tu64 new_rx_errors = smb->rx_frag +\n\t\t\t    smb->rx_fcs_err +\n\t\t\t    smb->rx_len_err +\n\t\t\t    smb->rx_sz_ov +\n\t\t\t    smb->rx_rxf_ov +\n\t\t\t    smb->rx_rrd_ov +\n\t\t\t    smb->rx_align_err;\n\tu64 new_tx_errors = smb->tx_late_col +\n\t\t\t    smb->tx_abort_col +\n\t\t\t    smb->tx_underrun +\n\t\t\t    smb->tx_trunc;\n\n\t \n\tadapter->soft_stats.rx_packets += smb->rx_ok + new_rx_errors;\n\tadapter->soft_stats.tx_packets += smb->tx_ok + new_tx_errors;\n\tadapter->soft_stats.rx_bytes += smb->rx_byte_cnt;\n\tadapter->soft_stats.tx_bytes += smb->tx_byte_cnt;\n\tadapter->soft_stats.multicast += smb->rx_mcast;\n\tadapter->soft_stats.collisions += smb->tx_1_col +\n\t\t\t\t\t  smb->tx_2_col +\n\t\t\t\t\t  smb->tx_late_col +\n\t\t\t\t\t  smb->tx_abort_col;\n\n\t \n\tadapter->soft_stats.rx_errors += new_rx_errors;\n\tadapter->soft_stats.rx_fifo_errors += smb->rx_rxf_ov;\n\tadapter->soft_stats.rx_length_errors += smb->rx_len_err;\n\tadapter->soft_stats.rx_crc_errors += smb->rx_fcs_err;\n\tadapter->soft_stats.rx_frame_errors += smb->rx_align_err;\n\n\tadapter->soft_stats.rx_pause += smb->rx_pause;\n\tadapter->soft_stats.rx_rrd_ov += smb->rx_rrd_ov;\n\tadapter->soft_stats.rx_trunc += smb->rx_sz_ov;\n\n\t \n\tadapter->soft_stats.tx_errors += new_tx_errors;\n\tadapter->soft_stats.tx_fifo_errors += smb->tx_underrun;\n\tadapter->soft_stats.tx_aborted_errors += smb->tx_abort_col;\n\tadapter->soft_stats.tx_window_errors += smb->tx_late_col;\n\n\tadapter->soft_stats.excecol += smb->tx_abort_col;\n\tadapter->soft_stats.deffer += smb->tx_defer;\n\tadapter->soft_stats.scc += smb->tx_1_col;\n\tadapter->soft_stats.mcc += smb->tx_2_col;\n\tadapter->soft_stats.latecol += smb->tx_late_col;\n\tadapter->soft_stats.tx_underrun += smb->tx_underrun;\n\tadapter->soft_stats.tx_trunc += smb->tx_trunc;\n\tadapter->soft_stats.tx_pause += smb->tx_pause;\n\n\tnetdev->stats.rx_bytes = adapter->soft_stats.rx_bytes;\n\tnetdev->stats.tx_bytes = adapter->soft_stats.tx_bytes;\n\tnetdev->stats.multicast = adapter->soft_stats.multicast;\n\tnetdev->stats.collisions = adapter->soft_stats.collisions;\n\tnetdev->stats.rx_errors = adapter->soft_stats.rx_errors;\n\tnetdev->stats.rx_length_errors =\n\t\tadapter->soft_stats.rx_length_errors;\n\tnetdev->stats.rx_crc_errors = adapter->soft_stats.rx_crc_errors;\n\tnetdev->stats.rx_frame_errors =\n\t\tadapter->soft_stats.rx_frame_errors;\n\tnetdev->stats.rx_fifo_errors = adapter->soft_stats.rx_fifo_errors;\n\tnetdev->stats.rx_dropped = adapter->soft_stats.rx_rrd_ov;\n\tnetdev->stats.tx_errors = adapter->soft_stats.tx_errors;\n\tnetdev->stats.tx_fifo_errors = adapter->soft_stats.tx_fifo_errors;\n\tnetdev->stats.tx_aborted_errors =\n\t\tadapter->soft_stats.tx_aborted_errors;\n\tnetdev->stats.tx_window_errors =\n\t\tadapter->soft_stats.tx_window_errors;\n\tnetdev->stats.tx_carrier_errors =\n\t\tadapter->soft_stats.tx_carrier_errors;\n\n\tnetdev->stats.rx_packets = adapter->soft_stats.rx_packets;\n\tnetdev->stats.tx_packets = adapter->soft_stats.tx_packets;\n}\n\nstatic void atl1_update_mailbox(struct atl1_adapter *adapter)\n{\n\tunsigned long flags;\n\tu32 tpd_next_to_use;\n\tu32 rfd_next_to_use;\n\tu32 rrd_next_to_clean;\n\tu32 value;\n\n\tspin_lock_irqsave(&adapter->mb_lock, flags);\n\n\ttpd_next_to_use = atomic_read(&adapter->tpd_ring.next_to_use);\n\trfd_next_to_use = atomic_read(&adapter->rfd_ring.next_to_use);\n\trrd_next_to_clean = atomic_read(&adapter->rrd_ring.next_to_clean);\n\n\tvalue = ((rfd_next_to_use & MB_RFD_PROD_INDX_MASK) <<\n\t\tMB_RFD_PROD_INDX_SHIFT) |\n\t\t((rrd_next_to_clean & MB_RRD_CONS_INDX_MASK) <<\n\t\tMB_RRD_CONS_INDX_SHIFT) |\n\t\t((tpd_next_to_use & MB_TPD_PROD_INDX_MASK) <<\n\t\tMB_TPD_PROD_INDX_SHIFT);\n\tiowrite32(value, adapter->hw.hw_addr + REG_MAILBOX);\n\n\tspin_unlock_irqrestore(&adapter->mb_lock, flags);\n}\n\nstatic void atl1_clean_alloc_flag(struct atl1_adapter *adapter,\n\tstruct rx_return_desc *rrd, u16 offset)\n{\n\tstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\n\n\twhile (rfd_ring->next_to_clean != (rrd->buf_indx + offset)) {\n\t\trfd_ring->buffer_info[rfd_ring->next_to_clean].alloced = 0;\n\t\tif (++rfd_ring->next_to_clean == rfd_ring->count) {\n\t\t\trfd_ring->next_to_clean = 0;\n\t\t}\n\t}\n}\n\nstatic void atl1_update_rfd_index(struct atl1_adapter *adapter,\n\tstruct rx_return_desc *rrd)\n{\n\tu16 num_buf;\n\n\tnum_buf = (rrd->xsz.xsum_sz.pkt_size + adapter->rx_buffer_len - 1) /\n\t\tadapter->rx_buffer_len;\n\tif (rrd->num_buf == num_buf)\n\t\t \n\t\tatl1_clean_alloc_flag(adapter, rrd, num_buf);\n}\n\nstatic void atl1_rx_checksum(struct atl1_adapter *adapter,\n\tstruct rx_return_desc *rrd, struct sk_buff *skb)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\n\t \n\n\tskb_checksum_none_assert(skb);\n\n\tif (unlikely(rrd->pkt_flg & PACKET_FLAG_ERR)) {\n\t\tif (rrd->err_flg & (ERR_FLAG_CRC | ERR_FLAG_TRUNC |\n\t\t\t\t\tERR_FLAG_CODE | ERR_FLAG_OV)) {\n\t\t\tadapter->hw_csum_err++;\n\t\t\tif (netif_msg_rx_err(adapter))\n\t\t\t\tdev_printk(KERN_DEBUG, &pdev->dev,\n\t\t\t\t\t\"rx checksum error\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tif (!(rrd->pkt_flg & PACKET_FLAG_IPV4))\n\t\t \n\t\treturn;\n\n\t \n\tif (likely(!(rrd->err_flg &\n\t\t(ERR_FLAG_IP_CHKSUM | ERR_FLAG_L4_CHKSUM)))) {\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\tadapter->hw_csum_good++;\n\t\treturn;\n\t}\n}\n\n \nstatic u16 atl1_alloc_rx_buffers(struct atl1_adapter *adapter)\n{\n\tstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct page *page;\n\tunsigned long offset;\n\tstruct atl1_buffer *buffer_info, *next_info;\n\tstruct sk_buff *skb;\n\tu16 num_alloc = 0;\n\tu16 rfd_next_to_use, next_next;\n\tstruct rx_free_desc *rfd_desc;\n\n\tnext_next = rfd_next_to_use = atomic_read(&rfd_ring->next_to_use);\n\tif (++next_next == rfd_ring->count)\n\t\tnext_next = 0;\n\tbuffer_info = &rfd_ring->buffer_info[rfd_next_to_use];\n\tnext_info = &rfd_ring->buffer_info[next_next];\n\n\twhile (!buffer_info->alloced && !next_info->alloced) {\n\t\tif (buffer_info->skb) {\n\t\t\tbuffer_info->alloced = 1;\n\t\t\tgoto next;\n\t\t}\n\n\t\trfd_desc = ATL1_RFD_DESC(rfd_ring, rfd_next_to_use);\n\n\t\tskb = netdev_alloc_skb_ip_align(adapter->netdev,\n\t\t\t\t\t\tadapter->rx_buffer_len);\n\t\tif (unlikely(!skb)) {\n\t\t\t \n\t\t\tadapter->soft_stats.rx_dropped++;\n\t\t\tbreak;\n\t\t}\n\n\t\tbuffer_info->alloced = 1;\n\t\tbuffer_info->skb = skb;\n\t\tbuffer_info->length = (u16) adapter->rx_buffer_len;\n\t\tpage = virt_to_page(skb->data);\n\t\toffset = offset_in_page(skb->data);\n\t\tbuffer_info->dma = dma_map_page(&pdev->dev, page, offset,\n\t\t\t\t\t\tadapter->rx_buffer_len,\n\t\t\t\t\t\tDMA_FROM_DEVICE);\n\t\trfd_desc->buffer_addr = cpu_to_le64(buffer_info->dma);\n\t\trfd_desc->buf_len = cpu_to_le16(adapter->rx_buffer_len);\n\t\trfd_desc->coalese = 0;\n\nnext:\n\t\trfd_next_to_use = next_next;\n\t\tif (unlikely(++next_next == rfd_ring->count))\n\t\t\tnext_next = 0;\n\n\t\tbuffer_info = &rfd_ring->buffer_info[rfd_next_to_use];\n\t\tnext_info = &rfd_ring->buffer_info[next_next];\n\t\tnum_alloc++;\n\t}\n\n\tif (num_alloc) {\n\t\t \n\t\twmb();\n\t\tatomic_set(&rfd_ring->next_to_use, (int)rfd_next_to_use);\n\t}\n\treturn num_alloc;\n}\n\nstatic int atl1_intr_rx(struct atl1_adapter *adapter, int budget)\n{\n\tint i, count;\n\tu16 length;\n\tu16 rrd_next_to_clean;\n\tu32 value;\n\tstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\n\tstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\n\tstruct atl1_buffer *buffer_info;\n\tstruct rx_return_desc *rrd;\n\tstruct sk_buff *skb;\n\n\tcount = 0;\n\n\trrd_next_to_clean = atomic_read(&rrd_ring->next_to_clean);\n\n\twhile (count < budget) {\n\t\trrd = ATL1_RRD_DESC(rrd_ring, rrd_next_to_clean);\n\t\ti = 1;\n\t\tif (likely(rrd->xsz.valid)) {\t \nchk_rrd:\n\t\t\t \n\t\t\tif (likely(rrd->num_buf == 1))\n\t\t\t\tgoto rrd_ok;\n\t\t\telse if (netif_msg_rx_err(adapter)) {\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"unexpected RRD buffer count\\n\");\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"rx_buf_len = %d\\n\",\n\t\t\t\t\tadapter->rx_buffer_len);\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"RRD num_buf = %d\\n\",\n\t\t\t\t\trrd->num_buf);\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"RRD pkt_len = %d\\n\",\n\t\t\t\t\trrd->xsz.xsum_sz.pkt_size);\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"RRD pkt_flg = 0x%08X\\n\",\n\t\t\t\t\trrd->pkt_flg);\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"RRD err_flg = 0x%08X\\n\",\n\t\t\t\t\trrd->err_flg);\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"RRD vlan_tag = 0x%08X\\n\",\n\t\t\t\t\trrd->vlan_tag);\n\t\t\t}\n\n\t\t\t \n\t\t\tif (unlikely(i-- > 0)) {\n\t\t\t\t \n\t\t\t\tudelay(1);\n\t\t\t\tgoto chk_rrd;\n\t\t\t}\n\t\t\t \n\t\t\tif (netif_msg_rx_err(adapter))\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"bad RRD\\n\");\n\t\t\t \n\t\t\tif (rrd->num_buf > 1)\n\t\t\t\tatl1_update_rfd_index(adapter, rrd);\n\n\t\t\t \n\t\t\trrd->xsz.valid = 0;\n\t\t\tif (++rrd_next_to_clean == rrd_ring->count)\n\t\t\t\trrd_next_to_clean = 0;\n\t\t\tcount++;\n\t\t\tcontinue;\n\t\t} else {\t \n\n\t\t\tbreak;\n\t\t}\nrrd_ok:\n\t\t \n\t\tatl1_clean_alloc_flag(adapter, rrd, 0);\n\n\t\tbuffer_info = &rfd_ring->buffer_info[rrd->buf_indx];\n\t\tif (++rfd_ring->next_to_clean == rfd_ring->count)\n\t\t\trfd_ring->next_to_clean = 0;\n\n\t\t \n\t\tif (++rrd_next_to_clean == rrd_ring->count)\n\t\t\trrd_next_to_clean = 0;\n\t\tcount++;\n\n\t\tif (unlikely(rrd->pkt_flg & PACKET_FLAG_ERR)) {\n\t\t\tif (!(rrd->err_flg &\n\t\t\t\t(ERR_FLAG_IP_CHKSUM | ERR_FLAG_L4_CHKSUM\n\t\t\t\t| ERR_FLAG_LEN))) {\n\t\t\t\t \n\t\t\t\tbuffer_info->alloced = 0;\n\t\t\t\trrd->xsz.valid = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tdma_unmap_page(&adapter->pdev->dev, buffer_info->dma,\n\t\t\t       buffer_info->length, DMA_FROM_DEVICE);\n\t\tbuffer_info->dma = 0;\n\t\tskb = buffer_info->skb;\n\t\tlength = le16_to_cpu(rrd->xsz.xsum_sz.pkt_size);\n\n\t\tskb_put(skb, length - ETH_FCS_LEN);\n\n\t\t \n\t\tatl1_rx_checksum(adapter, rrd, skb);\n\t\tskb->protocol = eth_type_trans(skb, adapter->netdev);\n\n\t\tif (rrd->pkt_flg & PACKET_FLAG_VLAN_INS) {\n\t\t\tu16 vlan_tag = (rrd->vlan_tag >> 4) |\n\t\t\t\t\t((rrd->vlan_tag & 7) << 13) |\n\t\t\t\t\t((rrd->vlan_tag & 8) << 9);\n\n\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tag);\n\t\t}\n\t\tnetif_receive_skb(skb);\n\n\t\t \n\t\tbuffer_info->skb = NULL;\n\t\tbuffer_info->alloced = 0;\n\t\trrd->xsz.valid = 0;\n\t}\n\n\tatomic_set(&rrd_ring->next_to_clean, rrd_next_to_clean);\n\n\tatl1_alloc_rx_buffers(adapter);\n\n\t \n\tif (count) {\n\t\tu32 tpd_next_to_use;\n\t\tu32 rfd_next_to_use;\n\n\t\tspin_lock(&adapter->mb_lock);\n\n\t\ttpd_next_to_use = atomic_read(&adapter->tpd_ring.next_to_use);\n\t\trfd_next_to_use =\n\t\t    atomic_read(&adapter->rfd_ring.next_to_use);\n\t\trrd_next_to_clean =\n\t\t    atomic_read(&adapter->rrd_ring.next_to_clean);\n\t\tvalue = ((rfd_next_to_use & MB_RFD_PROD_INDX_MASK) <<\n\t\t\tMB_RFD_PROD_INDX_SHIFT) |\n                        ((rrd_next_to_clean & MB_RRD_CONS_INDX_MASK) <<\n\t\t\tMB_RRD_CONS_INDX_SHIFT) |\n                        ((tpd_next_to_use & MB_TPD_PROD_INDX_MASK) <<\n\t\t\tMB_TPD_PROD_INDX_SHIFT);\n\t\tiowrite32(value, adapter->hw.hw_addr + REG_MAILBOX);\n\t\tspin_unlock(&adapter->mb_lock);\n\t}\n\n\treturn count;\n}\n\nstatic int atl1_intr_tx(struct atl1_adapter *adapter)\n{\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tstruct atl1_buffer *buffer_info;\n\tu16 sw_tpd_next_to_clean;\n\tu16 cmb_tpd_next_to_clean;\n\tint count = 0;\n\n\tsw_tpd_next_to_clean = atomic_read(&tpd_ring->next_to_clean);\n\tcmb_tpd_next_to_clean = le16_to_cpu(adapter->cmb.cmb->tpd_cons_idx);\n\n\twhile (cmb_tpd_next_to_clean != sw_tpd_next_to_clean) {\n\t\tbuffer_info = &tpd_ring->buffer_info[sw_tpd_next_to_clean];\n\t\tif (buffer_info->dma) {\n\t\t\tdma_unmap_page(&adapter->pdev->dev, buffer_info->dma,\n\t\t\t\t       buffer_info->length, DMA_TO_DEVICE);\n\t\t\tbuffer_info->dma = 0;\n\t\t}\n\n\t\tif (buffer_info->skb) {\n\t\t\tdev_consume_skb_irq(buffer_info->skb);\n\t\t\tbuffer_info->skb = NULL;\n\t\t}\n\n\t\tif (++sw_tpd_next_to_clean == tpd_ring->count)\n\t\t\tsw_tpd_next_to_clean = 0;\n\n\t\tcount++;\n\t}\n\tatomic_set(&tpd_ring->next_to_clean, sw_tpd_next_to_clean);\n\n\tif (netif_queue_stopped(adapter->netdev) &&\n\t    netif_carrier_ok(adapter->netdev))\n\t\tnetif_wake_queue(adapter->netdev);\n\n\treturn count;\n}\n\nstatic u16 atl1_tpd_avail(struct atl1_tpd_ring *tpd_ring)\n{\n\tu16 next_to_clean = atomic_read(&tpd_ring->next_to_clean);\n\tu16 next_to_use = atomic_read(&tpd_ring->next_to_use);\n\treturn (next_to_clean > next_to_use) ?\n\t\tnext_to_clean - next_to_use - 1 :\n\t\ttpd_ring->count + next_to_clean - next_to_use - 1;\n}\n\nstatic int atl1_tso(struct atl1_adapter *adapter, struct sk_buff *skb,\n\t\t    struct tx_packet_desc *ptpd)\n{\n\tu8 hdr_len, ip_off;\n\tu32 real_len;\n\n\tif (skb_shinfo(skb)->gso_size) {\n\t\tint err;\n\n\t\terr = skb_cow_head(skb, 0);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\tstruct iphdr *iph = ip_hdr(skb);\n\n\t\t\treal_len = (((unsigned char *)iph - skb->data) +\n\t\t\t\tntohs(iph->tot_len));\n\t\t\tif (real_len < skb->len) {\n\t\t\t\terr = pskb_trim(skb, real_len);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t\thdr_len = skb_tcp_all_headers(skb);\n\t\t\tif (skb->len == hdr_len) {\n\t\t\t\tiph->check = 0;\n\t\t\t\ttcp_hdr(skb)->check =\n\t\t\t\t\t~csum_tcpudp_magic(iph->saddr,\n\t\t\t\t\tiph->daddr, tcp_hdrlen(skb),\n\t\t\t\t\tIPPROTO_TCP, 0);\n\t\t\t\tptpd->word3 |= (iph->ihl & TPD_IPHL_MASK) <<\n\t\t\t\t\tTPD_IPHL_SHIFT;\n\t\t\t\tptpd->word3 |= ((tcp_hdrlen(skb) >> 2) &\n\t\t\t\t\tTPD_TCPHDRLEN_MASK) <<\n\t\t\t\t\tTPD_TCPHDRLEN_SHIFT;\n\t\t\t\tptpd->word3 |= 1 << TPD_IP_CSUM_SHIFT;\n\t\t\t\tptpd->word3 |= 1 << TPD_TCP_CSUM_SHIFT;\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tiph->check = 0;\n\t\t\ttcp_hdr(skb)->check = ~csum_tcpudp_magic(iph->saddr,\n\t\t\t\t\tiph->daddr, 0, IPPROTO_TCP, 0);\n\t\t\tip_off = (unsigned char *)iph -\n\t\t\t\t(unsigned char *) skb_network_header(skb);\n\t\t\tif (ip_off == 8)  \n\t\t\t\tptpd->word3 |= 1 << TPD_ETHTYPE_SHIFT;\n\t\t\telse if (ip_off != 0)\n\t\t\t\treturn -2;\n\n\t\t\tptpd->word3 |= (iph->ihl & TPD_IPHL_MASK) <<\n\t\t\t\tTPD_IPHL_SHIFT;\n\t\t\tptpd->word3 |= ((tcp_hdrlen(skb) >> 2) &\n\t\t\t\tTPD_TCPHDRLEN_MASK) << TPD_TCPHDRLEN_SHIFT;\n\t\t\tptpd->word3 |= (skb_shinfo(skb)->gso_size &\n\t\t\t\tTPD_MSS_MASK) << TPD_MSS_SHIFT;\n\t\t\tptpd->word3 |= 1 << TPD_SEGMENT_EN_SHIFT;\n\t\t\treturn 3;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int atl1_tx_csum(struct atl1_adapter *adapter, struct sk_buff *skb,\n\tstruct tx_packet_desc *ptpd)\n{\n\tu8 css, cso;\n\n\tif (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {\n\t\tcss = skb_checksum_start_offset(skb);\n\t\tcso = css + (u8) skb->csum_offset;\n\t\tif (unlikely(css & 0x1)) {\n\t\t\t \n\t\t\tif (netif_msg_tx_err(adapter))\n\t\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\t\"payload offset not an even number\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\tptpd->word3 |= (css & TPD_PLOADOFFSET_MASK) <<\n\t\t\tTPD_PLOADOFFSET_SHIFT;\n\t\tptpd->word3 |= (cso & TPD_CCSUMOFFSET_MASK) <<\n\t\t\tTPD_CCSUMOFFSET_SHIFT;\n\t\tptpd->word3 |= 1 << TPD_CUST_CSUM_EN_SHIFT;\n\t\treturn true;\n\t}\n\treturn 0;\n}\n\nstatic void atl1_tx_map(struct atl1_adapter *adapter, struct sk_buff *skb,\n\tstruct tx_packet_desc *ptpd)\n{\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tstruct atl1_buffer *buffer_info;\n\tu16 buf_len = skb->len;\n\tstruct page *page;\n\tunsigned long offset;\n\tunsigned int nr_frags;\n\tunsigned int f;\n\tint retval;\n\tu16 next_to_use;\n\tu16 data_len;\n\tu8 hdr_len;\n\n\tbuf_len -= skb->data_len;\n\tnr_frags = skb_shinfo(skb)->nr_frags;\n\tnext_to_use = atomic_read(&tpd_ring->next_to_use);\n\tbuffer_info = &tpd_ring->buffer_info[next_to_use];\n\tBUG_ON(buffer_info->skb);\n\t \n\tbuffer_info->skb = NULL;\n\n\tretval = (ptpd->word3 >> TPD_SEGMENT_EN_SHIFT) & TPD_SEGMENT_EN_MASK;\n\tif (retval) {\n\t\t \n\t\thdr_len = skb_tcp_all_headers(skb);\n\t\tbuffer_info->length = hdr_len;\n\t\tpage = virt_to_page(skb->data);\n\t\toffset = offset_in_page(skb->data);\n\t\tbuffer_info->dma = dma_map_page(&adapter->pdev->dev, page,\n\t\t\t\t\t\toffset, hdr_len,\n\t\t\t\t\t\tDMA_TO_DEVICE);\n\n\t\tif (++next_to_use == tpd_ring->count)\n\t\t\tnext_to_use = 0;\n\n\t\tif (buf_len > hdr_len) {\n\t\t\tint i, nseg;\n\n\t\t\tdata_len = buf_len - hdr_len;\n\t\t\tnseg = (data_len + ATL1_MAX_TX_BUF_LEN - 1) /\n\t\t\t\tATL1_MAX_TX_BUF_LEN;\n\t\t\tfor (i = 0; i < nseg; i++) {\n\t\t\t\tbuffer_info =\n\t\t\t\t    &tpd_ring->buffer_info[next_to_use];\n\t\t\t\tbuffer_info->skb = NULL;\n\t\t\t\tbuffer_info->length =\n\t\t\t\t    (ATL1_MAX_TX_BUF_LEN >=\n\t\t\t\t     data_len) ? ATL1_MAX_TX_BUF_LEN : data_len;\n\t\t\t\tdata_len -= buffer_info->length;\n\t\t\t\tpage = virt_to_page(skb->data +\n\t\t\t\t\t(hdr_len + i * ATL1_MAX_TX_BUF_LEN));\n\t\t\t\toffset = offset_in_page(skb->data +\n\t\t\t\t\t(hdr_len + i * ATL1_MAX_TX_BUF_LEN));\n\t\t\t\tbuffer_info->dma = dma_map_page(&adapter->pdev->dev,\n\t\t\t\t\t\t\t\tpage, offset,\n\t\t\t\t\t\t\t\tbuffer_info->length,\n\t\t\t\t\t\t\t\tDMA_TO_DEVICE);\n\t\t\t\tif (++next_to_use == tpd_ring->count)\n\t\t\t\t\tnext_to_use = 0;\n\t\t\t}\n\t\t}\n\t} else {\n\t\t \n\t\tbuffer_info->length = buf_len;\n\t\tpage = virt_to_page(skb->data);\n\t\toffset = offset_in_page(skb->data);\n\t\tbuffer_info->dma = dma_map_page(&adapter->pdev->dev, page,\n\t\t\t\t\t\toffset, buf_len,\n\t\t\t\t\t\tDMA_TO_DEVICE);\n\t\tif (++next_to_use == tpd_ring->count)\n\t\t\tnext_to_use = 0;\n\t}\n\n\tfor (f = 0; f < nr_frags; f++) {\n\t\tconst skb_frag_t *frag = &skb_shinfo(skb)->frags[f];\n\t\tu16 i, nseg;\n\n\t\tbuf_len = skb_frag_size(frag);\n\n\t\tnseg = (buf_len + ATL1_MAX_TX_BUF_LEN - 1) /\n\t\t\tATL1_MAX_TX_BUF_LEN;\n\t\tfor (i = 0; i < nseg; i++) {\n\t\t\tbuffer_info = &tpd_ring->buffer_info[next_to_use];\n\t\t\tBUG_ON(buffer_info->skb);\n\n\t\t\tbuffer_info->skb = NULL;\n\t\t\tbuffer_info->length = (buf_len > ATL1_MAX_TX_BUF_LEN) ?\n\t\t\t\tATL1_MAX_TX_BUF_LEN : buf_len;\n\t\t\tbuf_len -= buffer_info->length;\n\t\t\tbuffer_info->dma = skb_frag_dma_map(&adapter->pdev->dev,\n\t\t\t\tfrag, i * ATL1_MAX_TX_BUF_LEN,\n\t\t\t\tbuffer_info->length, DMA_TO_DEVICE);\n\n\t\t\tif (++next_to_use == tpd_ring->count)\n\t\t\t\tnext_to_use = 0;\n\t\t}\n\t}\n\n\t \n\tbuffer_info->skb = skb;\n}\n\nstatic void atl1_tx_queue(struct atl1_adapter *adapter, u16 count,\n       struct tx_packet_desc *ptpd)\n{\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tstruct atl1_buffer *buffer_info;\n\tstruct tx_packet_desc *tpd;\n\tu16 j;\n\tu32 val;\n\tu16 next_to_use = (u16) atomic_read(&tpd_ring->next_to_use);\n\n\tfor (j = 0; j < count; j++) {\n\t\tbuffer_info = &tpd_ring->buffer_info[next_to_use];\n\t\ttpd = ATL1_TPD_DESC(&adapter->tpd_ring, next_to_use);\n\t\tif (tpd != ptpd)\n\t\t\tmemcpy(tpd, ptpd, sizeof(struct tx_packet_desc));\n\t\ttpd->buffer_addr = cpu_to_le64(buffer_info->dma);\n\t\ttpd->word2 &= ~(TPD_BUFLEN_MASK << TPD_BUFLEN_SHIFT);\n\t\ttpd->word2 |= (cpu_to_le16(buffer_info->length) &\n\t\t\tTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT;\n\n\t\t \n\t\tval = (tpd->word3 >> TPD_SEGMENT_EN_SHIFT) &\n\t\t\tTPD_SEGMENT_EN_MASK;\n\t\tif (val) {\n\t\t\tif (!j)\n\t\t\t\ttpd->word3 |= 1 << TPD_HDRFLAG_SHIFT;\n\t\t\telse\n\t\t\t\ttpd->word3 &= ~(1 << TPD_HDRFLAG_SHIFT);\n\t\t}\n\n\t\tif (j == (count - 1))\n\t\t\ttpd->word3 |= 1 << TPD_EOP_SHIFT;\n\n\t\tif (++next_to_use == tpd_ring->count)\n\t\t\tnext_to_use = 0;\n\t}\n\t \n\twmb();\n\n\tatomic_set(&tpd_ring->next_to_use, next_to_use);\n}\n\nstatic netdev_tx_t atl1_xmit_frame(struct sk_buff *skb,\n\t\t\t\t\t struct net_device *netdev)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\n\tint len;\n\tint tso;\n\tint count = 1;\n\tint ret_val;\n\tstruct tx_packet_desc *ptpd;\n\tu16 vlan_tag;\n\tunsigned int nr_frags = 0;\n\tunsigned int mss = 0;\n\tunsigned int f;\n\tunsigned int proto_hdr_len;\n\n\tlen = skb_headlen(skb);\n\n\tif (unlikely(skb->len <= 0)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tnr_frags = skb_shinfo(skb)->nr_frags;\n\tfor (f = 0; f < nr_frags; f++) {\n\t\tunsigned int f_size = skb_frag_size(&skb_shinfo(skb)->frags[f]);\n\t\tcount += (f_size + ATL1_MAX_TX_BUF_LEN - 1) /\n\t\t\t ATL1_MAX_TX_BUF_LEN;\n\t}\n\n\tmss = skb_shinfo(skb)->gso_size;\n\tif (mss) {\n\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\tproto_hdr_len = skb_tcp_all_headers(skb);\n\t\t\tif (unlikely(proto_hdr_len > len)) {\n\t\t\t\tdev_kfree_skb_any(skb);\n\t\t\t\treturn NETDEV_TX_OK;\n\t\t\t}\n\t\t\t \n\t\t\tif (proto_hdr_len != len)\n\t\t\t\tcount += (len - proto_hdr_len +\n\t\t\t\t\tATL1_MAX_TX_BUF_LEN - 1) /\n\t\t\t\t\tATL1_MAX_TX_BUF_LEN;\n\t\t}\n\t}\n\n\tif (atl1_tpd_avail(&adapter->tpd_ring) < count) {\n\t\t \n\t\tnetif_stop_queue(netdev);\n\t\tif (netif_msg_tx_queued(adapter))\n\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\"tx busy\\n\");\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tptpd = ATL1_TPD_DESC(tpd_ring,\n\t\t(u16) atomic_read(&tpd_ring->next_to_use));\n\tmemset(ptpd, 0, sizeof(struct tx_packet_desc));\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\tvlan_tag = skb_vlan_tag_get(skb);\n\t\tvlan_tag = (vlan_tag << 4) | (vlan_tag >> 13) |\n\t\t\t((vlan_tag >> 9) & 0x8);\n\t\tptpd->word3 |= 1 << TPD_INS_VL_TAG_SHIFT;\n\t\tptpd->word2 |= (vlan_tag & TPD_VLANTAG_MASK) <<\n\t\t\tTPD_VLANTAG_SHIFT;\n\t}\n\n\ttso = atl1_tso(adapter, skb, ptpd);\n\tif (tso < 0) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tif (!tso) {\n\t\tret_val = atl1_tx_csum(adapter, skb, ptpd);\n\t\tif (ret_val < 0) {\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\treturn NETDEV_TX_OK;\n\t\t}\n\t}\n\n\tatl1_tx_map(adapter, skb, ptpd);\n\tatl1_tx_queue(adapter, count, ptpd);\n\tatl1_update_mailbox(adapter);\n\treturn NETDEV_TX_OK;\n}\n\nstatic int atl1_rings_clean(struct napi_struct *napi, int budget)\n{\n\tstruct atl1_adapter *adapter = container_of(napi, struct atl1_adapter, napi);\n\tint work_done = atl1_intr_rx(adapter, budget);\n\n\tif (atl1_intr_tx(adapter))\n\t\twork_done = budget;\n\n\t \n\tif (work_done >= budget)\n\t\treturn work_done;\n\n\tnapi_complete_done(napi, work_done);\n\t \n\tif (likely(adapter->int_enabled))\n\t\tatlx_imr_set(adapter, IMR_NORMAL_MASK);\n\treturn work_done;\n}\n\nstatic inline int atl1_sched_rings_clean(struct atl1_adapter* adapter)\n{\n\tif (!napi_schedule_prep(&adapter->napi))\n\t\t \n\t\treturn 0;\n\n\t__napi_schedule(&adapter->napi);\n\n\t \n\tif (!adapter->int_enabled)\n\t\treturn 1;\n\n\tatlx_imr_set(adapter, IMR_NORXTX_MASK);\n\treturn 1;\n}\n\n \nstatic irqreturn_t atl1_intr(int irq, void *data)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(data);\n\tu32 status;\n\n\tstatus = adapter->cmb.cmb->int_stats;\n\tif (!status)\n\t\treturn IRQ_NONE;\n\n\t \n\tadapter->cmb.cmb->int_stats = status & (ISR_CMB_TX | ISR_CMB_RX);\n\n\tif (status & ISR_GPHY)\t \n\t\tatlx_clear_phy_int(adapter);\n\n\t \n\tiowrite32(status | ISR_DIS_INT, adapter->hw.hw_addr + REG_ISR);\n\n\t \n\tif (status & ISR_SMB)\n\t\tatl1_inc_smb(adapter);\n\n\t \n\tif (status & ISR_PHY_LINKDOWN) {\n\t\tif (netif_msg_intr(adapter))\n\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\"pcie phy link down %x\\n\", status);\n\t\tif (netif_running(adapter->netdev)) {\t \n\t\t\tatlx_irq_disable(adapter);\n\t\t\tschedule_work(&adapter->reset_dev_task);\n\t\t\treturn IRQ_HANDLED;\n\t\t}\n\t}\n\n\t \n\tif (status & (ISR_DMAR_TO_RST | ISR_DMAW_TO_RST)) {\n\t\tif (netif_msg_intr(adapter))\n\t\t\tdev_printk(KERN_DEBUG, &adapter->pdev->dev,\n\t\t\t\t\"pcie DMA r/w error (status = 0x%x)\\n\",\n\t\t\t\tstatus);\n\t\tatlx_irq_disable(adapter);\n\t\tschedule_work(&adapter->reset_dev_task);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\t \n\tif (status & ISR_GPHY) {\n\t\tadapter->soft_stats.tx_carrier_errors++;\n\t\tatl1_check_for_link(adapter);\n\t}\n\n\t \n\tif (status & (ISR_CMB_TX | ISR_CMB_RX) &&\n\t    atl1_sched_rings_clean(adapter))\n\t\tadapter->cmb.cmb->int_stats = adapter->cmb.cmb->int_stats &\n\t\t\t\t\t      ~(ISR_CMB_TX | ISR_CMB_RX);\n\n\t \n\tif (unlikely(status & (ISR_RXF_OV | ISR_RFD_UNRUN |\n\t\tISR_RRD_OV | ISR_HOST_RFD_UNRUN |\n\t\tISR_HOST_RRD_OV))) {\n\t\tif (netif_msg_intr(adapter))\n\t\t\tdev_printk(KERN_DEBUG,\n\t\t\t\t&adapter->pdev->dev,\n\t\t\t\t\"rx exception, ISR = 0x%x\\n\",\n\t\t\t\tstatus);\n\t\tatl1_sched_rings_clean(adapter);\n\t}\n\n\t \n\tiowrite32(ISR_DIS_SMB | ISR_DIS_DMA, adapter->hw.hw_addr + REG_ISR);\n\treturn IRQ_HANDLED;\n}\n\n\n \nstatic void atl1_phy_config(struct timer_list *t)\n{\n\tstruct atl1_adapter *adapter = from_timer(adapter, t,\n\t\t\t\t\t\t  phy_config_timer);\n\tstruct atl1_hw *hw = &adapter->hw;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&adapter->lock, flags);\n\tadapter->phy_timer_pending = false;\n\tatl1_write_phy_reg(hw, MII_ADVERTISE, hw->mii_autoneg_adv_reg);\n\tatl1_write_phy_reg(hw, MII_ATLX_CR, hw->mii_1000t_ctrl_reg);\n\tatl1_write_phy_reg(hw, MII_BMCR, MII_CR_RESET | MII_CR_AUTO_NEG_EN);\n\tspin_unlock_irqrestore(&adapter->lock, flags);\n}\n\n \n\nstatic int atl1_reset(struct atl1_adapter *adapter)\n{\n\tint ret;\n\tret = atl1_reset_hw(&adapter->hw);\n\tif (ret)\n\t\treturn ret;\n\treturn atl1_init_hw(&adapter->hw);\n}\n\nstatic s32 atl1_up(struct atl1_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint err;\n\tint irq_flags = 0;\n\n\t \n\tatlx_set_multi(netdev);\n\tatl1_init_ring_ptrs(adapter);\n\tatlx_restore_vlan(adapter);\n\terr = atl1_alloc_rx_buffers(adapter);\n\tif (unlikely(!err))\n\t\t \n\t\treturn -ENOMEM;\n\n\tif (unlikely(atl1_configure(adapter))) {\n\t\terr = -EIO;\n\t\tgoto err_up;\n\t}\n\n\terr = pci_enable_msi(adapter->pdev);\n\tif (err) {\n\t\tif (netif_msg_ifup(adapter))\n\t\t\tdev_info(&adapter->pdev->dev,\n\t\t\t\t\"Unable to enable MSI: %d\\n\", err);\n\t\tirq_flags |= IRQF_SHARED;\n\t}\n\n\terr = request_irq(adapter->pdev->irq, atl1_intr, irq_flags,\n\t\t\tnetdev->name, netdev);\n\tif (unlikely(err))\n\t\tgoto err_up;\n\n\tnapi_enable(&adapter->napi);\n\tatlx_irq_enable(adapter);\n\tatl1_check_link(adapter);\n\tnetif_start_queue(netdev);\n\treturn 0;\n\nerr_up:\n\tpci_disable_msi(adapter->pdev);\n\t \n\tatl1_clean_rx_ring(adapter);\n\treturn err;\n}\n\nstatic void atl1_down(struct atl1_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tnapi_disable(&adapter->napi);\n\tnetif_stop_queue(netdev);\n\tdel_timer_sync(&adapter->phy_config_timer);\n\tadapter->phy_timer_pending = false;\n\n\tatlx_irq_disable(adapter);\n\tfree_irq(adapter->pdev->irq, netdev);\n\tpci_disable_msi(adapter->pdev);\n\tatl1_reset_hw(&adapter->hw);\n\tadapter->cmb.cmb->int_stats = 0;\n\n\tadapter->link_speed = SPEED_0;\n\tadapter->link_duplex = -1;\n\tnetif_carrier_off(netdev);\n\n\tatl1_clean_tx_ring(adapter);\n\tatl1_clean_rx_ring(adapter);\n}\n\nstatic void atl1_reset_dev_task(struct work_struct *work)\n{\n\tstruct atl1_adapter *adapter =\n\t\tcontainer_of(work, struct atl1_adapter, reset_dev_task);\n\tstruct net_device *netdev = adapter->netdev;\n\n\tnetif_device_detach(netdev);\n\tatl1_down(adapter);\n\tatl1_up(adapter);\n\tnetif_device_attach(netdev);\n}\n\n \nstatic int atl1_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tint max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\n\tadapter->hw.max_frame_size = max_frame;\n\tadapter->hw.tx_jumbo_task_th = (max_frame + 7) >> 3;\n\tadapter->rx_buffer_len = (max_frame + 7) & ~7;\n\tadapter->hw.rx_jumbo_th = adapter->rx_buffer_len / 8;\n\n\tnetdev->mtu = new_mtu;\n\tif (netif_running(netdev)) {\n\t\tatl1_down(adapter);\n\t\tatl1_up(adapter);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int atl1_open(struct net_device *netdev)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tint err;\n\n\tnetif_carrier_off(netdev);\n\n\t \n\terr = atl1_setup_ring_resources(adapter);\n\tif (err)\n\t\treturn err;\n\n\terr = atl1_up(adapter);\n\tif (err)\n\t\tgoto err_up;\n\n\treturn 0;\n\nerr_up:\n\tatl1_reset(adapter);\n\treturn err;\n}\n\n \nstatic int atl1_close(struct net_device *netdev)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tatl1_down(adapter);\n\tatl1_free_ring_resources(adapter);\n\treturn 0;\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int atl1_suspend(struct device *dev)\n{\n\tstruct net_device *netdev = dev_get_drvdata(dev);\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_hw *hw = &adapter->hw;\n\tu32 ctrl = 0;\n\tu32 wufc = adapter->wol;\n\tu32 val;\n\tu16 speed;\n\tu16 duplex;\n\n\tnetif_device_detach(netdev);\n\tif (netif_running(netdev))\n\t\tatl1_down(adapter);\n\n\tatl1_read_phy_reg(hw, MII_BMSR, (u16 *) & ctrl);\n\tatl1_read_phy_reg(hw, MII_BMSR, (u16 *) & ctrl);\n\tval = ctrl & BMSR_LSTATUS;\n\tif (val)\n\t\twufc &= ~ATLX_WUFC_LNKC;\n\tif (!wufc)\n\t\tgoto disable_wol;\n\n\tif (val) {\n\t\tval = atl1_get_speed_and_duplex(hw, &speed, &duplex);\n\t\tif (val) {\n\t\t\tif (netif_msg_ifdown(adapter))\n\t\t\t\tdev_printk(KERN_DEBUG, dev,\n\t\t\t\t\t\"error getting speed/duplex\\n\");\n\t\t\tgoto disable_wol;\n\t\t}\n\n\t\tctrl = 0;\n\n\t\t \n\t\tif (wufc & ATLX_WUFC_MAG)\n\t\t\tctrl |= (WOL_MAGIC_EN | WOL_MAGIC_PME_EN);\n\t\tiowrite32(ctrl, hw->hw_addr + REG_WOL_CTRL);\n\t\tioread32(hw->hw_addr + REG_WOL_CTRL);\n\n\t\t \n\t\tctrl = MAC_CTRL_RX_EN;\n\t\tctrl |= ((u32)((speed == SPEED_1000) ? MAC_CTRL_SPEED_1000 :\n\t\t\tMAC_CTRL_SPEED_10_100) << MAC_CTRL_SPEED_SHIFT);\n\t\tif (duplex == FULL_DUPLEX)\n\t\t\tctrl |= MAC_CTRL_DUPLX;\n\t\tctrl |= (((u32)adapter->hw.preamble_len &\n\t\t\tMAC_CTRL_PRMLEN_MASK) << MAC_CTRL_PRMLEN_SHIFT);\n\t\t__atlx_vlan_mode(netdev->features, &ctrl);\n\t\tif (wufc & ATLX_WUFC_MAG)\n\t\t\tctrl |= MAC_CTRL_BC_EN;\n\t\tiowrite32(ctrl, hw->hw_addr + REG_MAC_CTRL);\n\t\tioread32(hw->hw_addr + REG_MAC_CTRL);\n\n\t\t \n\t\tctrl = ioread32(hw->hw_addr + REG_PCIE_PHYMISC);\n\t\tctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\n\t\tiowrite32(ctrl, hw->hw_addr + REG_PCIE_PHYMISC);\n\t\tioread32(hw->hw_addr + REG_PCIE_PHYMISC);\n\t} else {\n\t\tctrl |= (WOL_LINK_CHG_EN | WOL_LINK_CHG_PME_EN);\n\t\tiowrite32(ctrl, hw->hw_addr + REG_WOL_CTRL);\n\t\tioread32(hw->hw_addr + REG_WOL_CTRL);\n\t\tiowrite32(0, hw->hw_addr + REG_MAC_CTRL);\n\t\tioread32(hw->hw_addr + REG_MAC_CTRL);\n\t\thw->phy_configured = false;\n\t}\n\n\treturn 0;\n\n disable_wol:\n\tiowrite32(0, hw->hw_addr + REG_WOL_CTRL);\n\tioread32(hw->hw_addr + REG_WOL_CTRL);\n\tctrl = ioread32(hw->hw_addr + REG_PCIE_PHYMISC);\n\tctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\n\tiowrite32(ctrl, hw->hw_addr + REG_PCIE_PHYMISC);\n\tioread32(hw->hw_addr + REG_PCIE_PHYMISC);\n\thw->phy_configured = false;\n\n\treturn 0;\n}\n\nstatic int atl1_resume(struct device *dev)\n{\n\tstruct net_device *netdev = dev_get_drvdata(dev);\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\n\tiowrite32(0, adapter->hw.hw_addr + REG_WOL_CTRL);\n\n\tatl1_reset_hw(&adapter->hw);\n\n\tif (netif_running(netdev)) {\n\t\tadapter->cmb.cmb->int_stats = 0;\n\t\tatl1_up(adapter);\n\t}\n\tnetif_device_attach(netdev);\n\n\treturn 0;\n}\n#endif\n\nstatic SIMPLE_DEV_PM_OPS(atl1_pm_ops, atl1_suspend, atl1_resume);\n\nstatic void atl1_shutdown(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\n#ifdef CONFIG_PM_SLEEP\n\tatl1_suspend(&pdev->dev);\n#endif\n\tpci_wake_from_d3(pdev, adapter->wol);\n\tpci_set_power_state(pdev, PCI_D3hot);\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void atl1_poll_controller(struct net_device *netdev)\n{\n\tdisable_irq(netdev->irq);\n\tatl1_intr(netdev->irq, netdev);\n\tenable_irq(netdev->irq);\n}\n#endif\n\nstatic const struct net_device_ops atl1_netdev_ops = {\n\t.ndo_open\t\t= atl1_open,\n\t.ndo_stop\t\t= atl1_close,\n\t.ndo_start_xmit\t\t= atl1_xmit_frame,\n\t.ndo_set_rx_mode\t= atlx_set_multi,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= atl1_set_mac,\n\t.ndo_change_mtu\t\t= atl1_change_mtu,\n\t.ndo_fix_features\t= atlx_fix_features,\n\t.ndo_set_features\t= atlx_set_features,\n\t.ndo_eth_ioctl\t\t= atlx_ioctl,\n\t.ndo_tx_timeout\t\t= atlx_tx_timeout,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= atl1_poll_controller,\n#endif\n};\n\n \nstatic int atl1_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct net_device *netdev;\n\tstruct atl1_adapter *adapter;\n\tstatic int cards_found = 0;\n\tint err;\n\n\terr = pci_enable_device(pdev);\n\tif (err)\n\t\treturn err;\n\n\t \n\terr = dma_set_mask(&pdev->dev, DMA_BIT_MASK(32));\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"no usable DMA configuration\\n\");\n\t\tgoto err_dma;\n\t}\n\t \n\terr = pci_request_regions(pdev, ATLX_DRIVER_NAME);\n\tif (err)\n\t\tgoto err_request_regions;\n\n\t \n\tpci_set_master(pdev);\n\n\tnetdev = alloc_etherdev(sizeof(struct atl1_adapter));\n\tif (!netdev) {\n\t\terr = -ENOMEM;\n\t\tgoto err_alloc_etherdev;\n\t}\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\n\tpci_set_drvdata(pdev, netdev);\n\tadapter = netdev_priv(netdev);\n\tadapter->netdev = netdev;\n\tadapter->pdev = pdev;\n\tadapter->hw.back = adapter;\n\tadapter->msg_enable = netif_msg_init(debug, atl1_default_msg);\n\n\tadapter->hw.hw_addr = pci_iomap(pdev, 0, 0);\n\tif (!adapter->hw.hw_addr) {\n\t\terr = -EIO;\n\t\tgoto err_pci_iomap;\n\t}\n\t \n\tadapter->hw.dev_rev = ioread16(adapter->hw.hw_addr +\n\t\t(REG_MASTER_CTRL + 2));\n\n\t \n\tadapter->rfd_ring.count = adapter->rrd_ring.count = ATL1_DEFAULT_RFD;\n\tadapter->tpd_ring.count = ATL1_DEFAULT_TPD;\n\n\tadapter->mii.dev = netdev;\n\tadapter->mii.mdio_read = mdio_read;\n\tadapter->mii.mdio_write = mdio_write;\n\tadapter->mii.phy_id_mask = 0x1f;\n\tadapter->mii.reg_num_mask = 0x1f;\n\n\tnetdev->netdev_ops = &atl1_netdev_ops;\n\tnetdev->watchdog_timeo = 5 * HZ;\n\tnetif_napi_add(netdev, &adapter->napi, atl1_rings_clean);\n\n\tnetdev->ethtool_ops = &atl1_ethtool_ops;\n\tadapter->bd_number = cards_found;\n\n\t \n\terr = atl1_sw_init(adapter);\n\tif (err)\n\t\tgoto err_common;\n\n\tnetdev->features = NETIF_F_HW_CSUM;\n\tnetdev->features |= NETIF_F_SG;\n\tnetdev->features |= (NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX);\n\n\tnetdev->hw_features = NETIF_F_HW_CSUM | NETIF_F_SG | NETIF_F_TSO |\n\t\t\t      NETIF_F_HW_VLAN_CTAG_RX;\n\n\t \n\tnetdev->features |= NETIF_F_RXCSUM;\n\n\t \n\tnetdev->min_mtu = ETH_ZLEN - (ETH_HLEN + VLAN_HLEN);\n\tnetdev->max_mtu = MAX_JUMBO_FRAME_SIZE -\n\t\t\t  (ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN);\n\n\t \n\t \n\n\t \n\tiowrite16(0, adapter->hw.hw_addr + REG_PHY_ENABLE);\n\n\t \n\tif (atl1_reset_hw(&adapter->hw)) {\n\t\terr = -EIO;\n\t\tgoto err_common;\n\t}\n\n\t \n\tif (atl1_read_mac_addr(&adapter->hw)) {\n\t\t \n\t\tnetdev->addr_assign_type = NET_ADDR_RANDOM;\n\t}\n\teth_hw_addr_set(netdev, adapter->hw.mac_addr);\n\n\tif (!is_valid_ether_addr(netdev->dev_addr)) {\n\t\terr = -EIO;\n\t\tgoto err_common;\n\t}\n\n\tatl1_check_options(adapter);\n\n\t \n\terr = atl1_init_hw(&adapter->hw);\n\tif (err) {\n\t\terr = -EIO;\n\t\tgoto err_common;\n\t}\n\n\tatl1_pcie_patch(adapter);\n\t \n\tnetif_carrier_off(netdev);\n\n\ttimer_setup(&adapter->phy_config_timer, atl1_phy_config, 0);\n\tadapter->phy_timer_pending = false;\n\n\tINIT_WORK(&adapter->reset_dev_task, atl1_reset_dev_task);\n\n\tINIT_WORK(&adapter->link_chg_task, atlx_link_chg_task);\n\n\terr = register_netdev(netdev);\n\tif (err)\n\t\tgoto err_common;\n\n\tcards_found++;\n\tatl1_via_workaround(adapter);\n\treturn 0;\n\nerr_common:\n\tpci_iounmap(pdev, adapter->hw.hw_addr);\nerr_pci_iomap:\n\tfree_netdev(netdev);\nerr_alloc_etherdev:\n\tpci_release_regions(pdev);\nerr_dma:\nerr_request_regions:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n \nstatic void atl1_remove(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1_adapter *adapter;\n\t \n\tif (!netdev)\n\t\treturn;\n\n\tadapter = netdev_priv(netdev);\n\n\t \n\tif (!ether_addr_equal_unaligned(adapter->hw.mac_addr,\n\t\t\t\t\tadapter->hw.perm_mac_addr)) {\n\t\tmemcpy(adapter->hw.mac_addr, adapter->hw.perm_mac_addr,\n\t\t\tETH_ALEN);\n\t\tatl1_set_mac_addr(&adapter->hw);\n\t}\n\n\tiowrite16(0, adapter->hw.hw_addr + REG_PHY_ENABLE);\n\tunregister_netdev(netdev);\n\tpci_iounmap(pdev, adapter->hw.hw_addr);\n\tpci_release_regions(pdev);\n\tfree_netdev(netdev);\n\tpci_disable_device(pdev);\n}\n\nstatic struct pci_driver atl1_driver = {\n\t.name = ATLX_DRIVER_NAME,\n\t.id_table = atl1_pci_tbl,\n\t.probe = atl1_probe,\n\t.remove = atl1_remove,\n\t.shutdown = atl1_shutdown,\n\t.driver.pm = &atl1_pm_ops,\n};\n\nstruct atl1_stats {\n\tchar stat_string[ETH_GSTRING_LEN];\n\tint sizeof_stat;\n\tint stat_offset;\n};\n\n#define ATL1_STAT(m) \\\n\tsizeof(((struct atl1_adapter *)0)->m), offsetof(struct atl1_adapter, m)\n\nstatic struct atl1_stats atl1_gstrings_stats[] = {\n\t{\"rx_packets\", ATL1_STAT(soft_stats.rx_packets)},\n\t{\"tx_packets\", ATL1_STAT(soft_stats.tx_packets)},\n\t{\"rx_bytes\", ATL1_STAT(soft_stats.rx_bytes)},\n\t{\"tx_bytes\", ATL1_STAT(soft_stats.tx_bytes)},\n\t{\"rx_errors\", ATL1_STAT(soft_stats.rx_errors)},\n\t{\"tx_errors\", ATL1_STAT(soft_stats.tx_errors)},\n\t{\"multicast\", ATL1_STAT(soft_stats.multicast)},\n\t{\"collisions\", ATL1_STAT(soft_stats.collisions)},\n\t{\"rx_length_errors\", ATL1_STAT(soft_stats.rx_length_errors)},\n\t{\"rx_over_errors\", ATL1_STAT(soft_stats.rx_missed_errors)},\n\t{\"rx_crc_errors\", ATL1_STAT(soft_stats.rx_crc_errors)},\n\t{\"rx_frame_errors\", ATL1_STAT(soft_stats.rx_frame_errors)},\n\t{\"rx_fifo_errors\", ATL1_STAT(soft_stats.rx_fifo_errors)},\n\t{\"rx_missed_errors\", ATL1_STAT(soft_stats.rx_missed_errors)},\n\t{\"tx_aborted_errors\", ATL1_STAT(soft_stats.tx_aborted_errors)},\n\t{\"tx_carrier_errors\", ATL1_STAT(soft_stats.tx_carrier_errors)},\n\t{\"tx_fifo_errors\", ATL1_STAT(soft_stats.tx_fifo_errors)},\n\t{\"tx_window_errors\", ATL1_STAT(soft_stats.tx_window_errors)},\n\t{\"tx_abort_exce_coll\", ATL1_STAT(soft_stats.excecol)},\n\t{\"tx_abort_late_coll\", ATL1_STAT(soft_stats.latecol)},\n\t{\"tx_deferred_ok\", ATL1_STAT(soft_stats.deffer)},\n\t{\"tx_single_coll_ok\", ATL1_STAT(soft_stats.scc)},\n\t{\"tx_multi_coll_ok\", ATL1_STAT(soft_stats.mcc)},\n\t{\"tx_underrun\", ATL1_STAT(soft_stats.tx_underrun)},\n\t{\"tx_trunc\", ATL1_STAT(soft_stats.tx_trunc)},\n\t{\"tx_pause\", ATL1_STAT(soft_stats.tx_pause)},\n\t{\"rx_pause\", ATL1_STAT(soft_stats.rx_pause)},\n\t{\"rx_rrd_ov\", ATL1_STAT(soft_stats.rx_rrd_ov)},\n\t{\"rx_trunc\", ATL1_STAT(soft_stats.rx_trunc)}\n};\n\nstatic void atl1_get_ethtool_stats(struct net_device *netdev,\n\tstruct ethtool_stats *stats, u64 *data)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tint i;\n\tchar *p;\n\n\tfor (i = 0; i < ARRAY_SIZE(atl1_gstrings_stats); i++) {\n\t\tp = (char *)adapter+atl1_gstrings_stats[i].stat_offset;\n\t\tdata[i] = (atl1_gstrings_stats[i].sizeof_stat ==\n\t\t\tsizeof(u64)) ? *(u64 *)p : *(u32 *)p;\n\t}\n\n}\n\nstatic int atl1_get_sset_count(struct net_device *netdev, int sset)\n{\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn ARRAY_SIZE(atl1_gstrings_stats);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int atl1_get_link_ksettings(struct net_device *netdev,\n\t\t\t\t   struct ethtool_link_ksettings *cmd)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_hw *hw = &adapter->hw;\n\tu32 supported, advertising;\n\n\tsupported = (SUPPORTED_10baseT_Half |\n\t\t\t   SUPPORTED_10baseT_Full |\n\t\t\t   SUPPORTED_100baseT_Half |\n\t\t\t   SUPPORTED_100baseT_Full |\n\t\t\t   SUPPORTED_1000baseT_Full |\n\t\t\t   SUPPORTED_Autoneg | SUPPORTED_TP);\n\tadvertising = ADVERTISED_TP;\n\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\n\t    hw->media_type == MEDIA_TYPE_1000M_FULL) {\n\t\tadvertising |= ADVERTISED_Autoneg;\n\t\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR) {\n\t\t\tadvertising |= ADVERTISED_Autoneg;\n\t\t\tadvertising |=\n\t\t\t    (ADVERTISED_10baseT_Half |\n\t\t\t     ADVERTISED_10baseT_Full |\n\t\t\t     ADVERTISED_100baseT_Half |\n\t\t\t     ADVERTISED_100baseT_Full |\n\t\t\t     ADVERTISED_1000baseT_Full);\n\t\t} else\n\t\t\tadvertising |= (ADVERTISED_1000baseT_Full);\n\t}\n\tcmd->base.port = PORT_TP;\n\tcmd->base.phy_address = 0;\n\n\tif (netif_carrier_ok(adapter->netdev)) {\n\t\tu16 link_speed, link_duplex;\n\t\tatl1_get_speed_and_duplex(hw, &link_speed, &link_duplex);\n\t\tcmd->base.speed = link_speed;\n\t\tif (link_duplex == FULL_DUPLEX)\n\t\t\tcmd->base.duplex = DUPLEX_FULL;\n\t\telse\n\t\t\tcmd->base.duplex = DUPLEX_HALF;\n\t} else {\n\t\tcmd->base.speed = SPEED_UNKNOWN;\n\t\tcmd->base.duplex = DUPLEX_UNKNOWN;\n\t}\n\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\n\t    hw->media_type == MEDIA_TYPE_1000M_FULL)\n\t\tcmd->base.autoneg = AUTONEG_ENABLE;\n\telse\n\t\tcmd->base.autoneg = AUTONEG_DISABLE;\n\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported,\n\t\t\t\t\t\tsupported);\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.advertising,\n\t\t\t\t\t\tadvertising);\n\n\treturn 0;\n}\n\nstatic int atl1_set_link_ksettings(struct net_device *netdev,\n\t\t\t\t   const struct ethtool_link_ksettings *cmd)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_hw *hw = &adapter->hw;\n\tu16 phy_data;\n\tint ret_val = 0;\n\tu16 old_media_type = hw->media_type;\n\n\tif (netif_running(adapter->netdev)) {\n\t\tif (netif_msg_link(adapter))\n\t\t\tdev_dbg(&adapter->pdev->dev,\n\t\t\t\t\"ethtool shutting down adapter\\n\");\n\t\tatl1_down(adapter);\n\t}\n\n\tif (cmd->base.autoneg == AUTONEG_ENABLE)\n\t\thw->media_type = MEDIA_TYPE_AUTO_SENSOR;\n\telse {\n\t\tu32 speed = cmd->base.speed;\n\t\tif (speed == SPEED_1000) {\n\t\t\tif (cmd->base.duplex != DUPLEX_FULL) {\n\t\t\t\tif (netif_msg_link(adapter))\n\t\t\t\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t\t\t\t\"1000M half is invalid\\n\");\n\t\t\t\tret_val = -EINVAL;\n\t\t\t\tgoto exit_sset;\n\t\t\t}\n\t\t\thw->media_type = MEDIA_TYPE_1000M_FULL;\n\t\t} else if (speed == SPEED_100) {\n\t\t\tif (cmd->base.duplex == DUPLEX_FULL)\n\t\t\t\thw->media_type = MEDIA_TYPE_100M_FULL;\n\t\t\telse\n\t\t\t\thw->media_type = MEDIA_TYPE_100M_HALF;\n\t\t} else {\n\t\t\tif (cmd->base.duplex == DUPLEX_FULL)\n\t\t\t\thw->media_type = MEDIA_TYPE_10M_FULL;\n\t\t\telse\n\t\t\t\thw->media_type = MEDIA_TYPE_10M_HALF;\n\t\t}\n\t}\n\n\tif (atl1_phy_setup_autoneg_adv(hw)) {\n\t\tret_val = -EINVAL;\n\t\tif (netif_msg_link(adapter))\n\t\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t\t\"invalid ethtool speed/duplex setting\\n\");\n\t\tgoto exit_sset;\n\t}\n\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\n\t    hw->media_type == MEDIA_TYPE_1000M_FULL)\n\t\tphy_data = MII_CR_RESET | MII_CR_AUTO_NEG_EN;\n\telse {\n\t\tswitch (hw->media_type) {\n\t\tcase MEDIA_TYPE_100M_FULL:\n\t\t\tphy_data =\n\t\t\t    MII_CR_FULL_DUPLEX | MII_CR_SPEED_100 |\n\t\t\t    MII_CR_RESET;\n\t\t\tbreak;\n\t\tcase MEDIA_TYPE_100M_HALF:\n\t\t\tphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\n\t\t\tbreak;\n\t\tcase MEDIA_TYPE_10M_FULL:\n\t\t\tphy_data =\n\t\t\t    MII_CR_FULL_DUPLEX | MII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\tbreak;\n\t\t}\n\t}\n\tatl1_write_phy_reg(hw, MII_BMCR, phy_data);\nexit_sset:\n\tif (ret_val)\n\t\thw->media_type = old_media_type;\n\n\tif (netif_running(adapter->netdev)) {\n\t\tif (netif_msg_link(adapter))\n\t\t\tdev_dbg(&adapter->pdev->dev,\n\t\t\t\t\"ethtool starting adapter\\n\");\n\t\tatl1_up(adapter);\n\t} else if (!ret_val) {\n\t\tif (netif_msg_link(adapter))\n\t\t\tdev_dbg(&adapter->pdev->dev,\n\t\t\t\t\"ethtool resetting adapter\\n\");\n\t\tatl1_reset(adapter);\n\t}\n\treturn ret_val;\n}\n\nstatic void atl1_get_drvinfo(struct net_device *netdev,\n\tstruct ethtool_drvinfo *drvinfo)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\n\tstrscpy(drvinfo->driver, ATLX_DRIVER_NAME, sizeof(drvinfo->driver));\n\tstrscpy(drvinfo->bus_info, pci_name(adapter->pdev),\n\t\tsizeof(drvinfo->bus_info));\n}\n\nstatic void atl1_get_wol(struct net_device *netdev,\n\tstruct ethtool_wolinfo *wol)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\n\twol->supported = WAKE_MAGIC;\n\twol->wolopts = 0;\n\tif (adapter->wol & ATLX_WUFC_MAG)\n\t\twol->wolopts |= WAKE_MAGIC;\n}\n\nstatic int atl1_set_wol(struct net_device *netdev,\n\tstruct ethtool_wolinfo *wol)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\n\tif (wol->wolopts & (WAKE_PHY | WAKE_UCAST | WAKE_MCAST | WAKE_BCAST |\n\t\tWAKE_ARP | WAKE_MAGICSECURE))\n\t\treturn -EOPNOTSUPP;\n\tadapter->wol = 0;\n\tif (wol->wolopts & WAKE_MAGIC)\n\t\tadapter->wol |= ATLX_WUFC_MAG;\n\n\tdevice_set_wakeup_enable(&adapter->pdev->dev, adapter->wol);\n\n\treturn 0;\n}\n\nstatic u32 atl1_get_msglevel(struct net_device *netdev)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\treturn adapter->msg_enable;\n}\n\nstatic void atl1_set_msglevel(struct net_device *netdev, u32 value)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tadapter->msg_enable = value;\n}\n\nstatic int atl1_get_regs_len(struct net_device *netdev)\n{\n\treturn ATL1_REG_COUNT * sizeof(u32);\n}\n\nstatic void atl1_get_regs(struct net_device *netdev, struct ethtool_regs *regs,\n\tvoid *p)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_hw *hw = &adapter->hw;\n\tunsigned int i;\n\tu32 *regbuf = p;\n\n\tfor (i = 0; i < ATL1_REG_COUNT; i++) {\n\t\t \n\t\tswitch (i) {\n\t\tcase 6 ... 9:\n\t\tcase 14:\n\t\tcase 29 ... 31:\n\t\tcase 34 ... 63:\n\t\tcase 75 ... 127:\n\t\tcase 136 ... 1023:\n\t\tcase 1027 ... 1087:\n\t\tcase 1091 ... 1151:\n\t\tcase 1194 ... 1195:\n\t\tcase 1200 ... 1201:\n\t\tcase 1206 ... 1213:\n\t\tcase 1216 ... 1279:\n\t\tcase 1290 ... 1311:\n\t\tcase 1323 ... 1343:\n\t\tcase 1358 ... 1359:\n\t\tcase 1368 ... 1375:\n\t\tcase 1378 ... 1383:\n\t\tcase 1388 ... 1391:\n\t\tcase 1393 ... 1395:\n\t\tcase 1402 ... 1403:\n\t\tcase 1410 ... 1471:\n\t\tcase 1522 ... 1535:\n\t\t\t \n\t\t\tregbuf[i] = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tregbuf[i] = ioread32(hw->hw_addr + (i * sizeof(u32)));\n\t\t}\n\t}\n}\n\nstatic void atl1_get_ringparam(struct net_device *netdev,\n\t\t\t       struct ethtool_ringparam *ring,\n\t\t\t       struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_tpd_ring *txdr = &adapter->tpd_ring;\n\tstruct atl1_rfd_ring *rxdr = &adapter->rfd_ring;\n\n\tring->rx_max_pending = ATL1_MAX_RFD;\n\tring->tx_max_pending = ATL1_MAX_TPD;\n\tring->rx_pending = rxdr->count;\n\tring->tx_pending = txdr->count;\n}\n\nstatic int atl1_set_ringparam(struct net_device *netdev,\n\t\t\t      struct ethtool_ringparam *ring,\n\t\t\t      struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_tpd_ring *tpdr = &adapter->tpd_ring;\n\tstruct atl1_rrd_ring *rrdr = &adapter->rrd_ring;\n\tstruct atl1_rfd_ring *rfdr = &adapter->rfd_ring;\n\n\tstruct atl1_tpd_ring tpd_old, tpd_new;\n\tstruct atl1_rfd_ring rfd_old, rfd_new;\n\tstruct atl1_rrd_ring rrd_old, rrd_new;\n\tstruct atl1_ring_header rhdr_old, rhdr_new;\n\tstruct atl1_smb smb;\n\tstruct atl1_cmb cmb;\n\tint err;\n\n\ttpd_old = adapter->tpd_ring;\n\trfd_old = adapter->rfd_ring;\n\trrd_old = adapter->rrd_ring;\n\trhdr_old = adapter->ring_header;\n\n\tif (netif_running(adapter->netdev))\n\t\tatl1_down(adapter);\n\n\trfdr->count = (u16) max(ring->rx_pending, (u32) ATL1_MIN_RFD);\n\trfdr->count = rfdr->count > ATL1_MAX_RFD ? ATL1_MAX_RFD :\n\t\t\trfdr->count;\n\trfdr->count = (rfdr->count + 3) & ~3;\n\trrdr->count = rfdr->count;\n\n\ttpdr->count = (u16) max(ring->tx_pending, (u32) ATL1_MIN_TPD);\n\ttpdr->count = tpdr->count > ATL1_MAX_TPD ? ATL1_MAX_TPD :\n\t\t\ttpdr->count;\n\ttpdr->count = (tpdr->count + 3) & ~3;\n\n\tif (netif_running(adapter->netdev)) {\n\t\t \n\t\terr = atl1_setup_ring_resources(adapter);\n\t\tif (err)\n\t\t\tgoto err_setup_ring;\n\n\t\t \n\n\t\trfd_new = adapter->rfd_ring;\n\t\trrd_new = adapter->rrd_ring;\n\t\ttpd_new = adapter->tpd_ring;\n\t\trhdr_new = adapter->ring_header;\n\t\tadapter->rfd_ring = rfd_old;\n\t\tadapter->rrd_ring = rrd_old;\n\t\tadapter->tpd_ring = tpd_old;\n\t\tadapter->ring_header = rhdr_old;\n\t\t \n\t\tsmb = adapter->smb;\n\t\tcmb = adapter->cmb;\n\t\tatl1_free_ring_resources(adapter);\n\t\tadapter->rfd_ring = rfd_new;\n\t\tadapter->rrd_ring = rrd_new;\n\t\tadapter->tpd_ring = tpd_new;\n\t\tadapter->ring_header = rhdr_new;\n\t\tadapter->smb = smb;\n\t\tadapter->cmb = cmb;\n\n\t\terr = atl1_up(adapter);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\treturn 0;\n\nerr_setup_ring:\n\tadapter->rfd_ring = rfd_old;\n\tadapter->rrd_ring = rrd_old;\n\tadapter->tpd_ring = tpd_old;\n\tadapter->ring_header = rhdr_old;\n\tatl1_up(adapter);\n\treturn err;\n}\n\nstatic void atl1_get_pauseparam(struct net_device *netdev,\n\tstruct ethtool_pauseparam *epause)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_hw *hw = &adapter->hw;\n\n\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\n\t    hw->media_type == MEDIA_TYPE_1000M_FULL) {\n\t\tepause->autoneg = AUTONEG_ENABLE;\n\t} else {\n\t\tepause->autoneg = AUTONEG_DISABLE;\n\t}\n\tepause->rx_pause = 1;\n\tepause->tx_pause = 1;\n}\n\nstatic int atl1_set_pauseparam(struct net_device *netdev,\n\tstruct ethtool_pauseparam *epause)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_hw *hw = &adapter->hw;\n\n\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\n\t    hw->media_type == MEDIA_TYPE_1000M_FULL) {\n\t\tepause->autoneg = AUTONEG_ENABLE;\n\t} else {\n\t\tepause->autoneg = AUTONEG_DISABLE;\n\t}\n\n\tepause->rx_pause = 1;\n\tepause->tx_pause = 1;\n\n\treturn 0;\n}\n\nstatic void atl1_get_strings(struct net_device *netdev, u32 stringset,\n\tu8 *data)\n{\n\tu8 *p = data;\n\tint i;\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tfor (i = 0; i < ARRAY_SIZE(atl1_gstrings_stats); i++) {\n\t\t\tmemcpy(p, atl1_gstrings_stats[i].stat_string,\n\t\t\t\tETH_GSTRING_LEN);\n\t\t\tp += ETH_GSTRING_LEN;\n\t\t}\n\t\tbreak;\n\t}\n}\n\nstatic int atl1_nway_reset(struct net_device *netdev)\n{\n\tstruct atl1_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1_hw *hw = &adapter->hw;\n\n\tif (netif_running(netdev)) {\n\t\tu16 phy_data;\n\t\tatl1_down(adapter);\n\n\t\tif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\n\t\t\thw->media_type == MEDIA_TYPE_1000M_FULL) {\n\t\t\tphy_data = MII_CR_RESET | MII_CR_AUTO_NEG_EN;\n\t\t} else {\n\t\t\tswitch (hw->media_type) {\n\t\t\tcase MEDIA_TYPE_100M_FULL:\n\t\t\t\tphy_data = MII_CR_FULL_DUPLEX |\n\t\t\t\t\tMII_CR_SPEED_100 | MII_CR_RESET;\n\t\t\t\tbreak;\n\t\t\tcase MEDIA_TYPE_100M_HALF:\n\t\t\t\tphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\n\t\t\t\tbreak;\n\t\t\tcase MEDIA_TYPE_10M_FULL:\n\t\t\t\tphy_data = MII_CR_FULL_DUPLEX |\n\t\t\t\t\tMII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t \n\t\t\t\tphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\n\t\t\t}\n\t\t}\n\t\tatl1_write_phy_reg(hw, MII_BMCR, phy_data);\n\t\tatl1_up(adapter);\n\t}\n\treturn 0;\n}\n\nstatic const struct ethtool_ops atl1_ethtool_ops = {\n\t.get_drvinfo\t\t= atl1_get_drvinfo,\n\t.get_wol\t\t= atl1_get_wol,\n\t.set_wol\t\t= atl1_set_wol,\n\t.get_msglevel\t\t= atl1_get_msglevel,\n\t.set_msglevel\t\t= atl1_set_msglevel,\n\t.get_regs_len\t\t= atl1_get_regs_len,\n\t.get_regs\t\t= atl1_get_regs,\n\t.get_ringparam\t\t= atl1_get_ringparam,\n\t.set_ringparam\t\t= atl1_set_ringparam,\n\t.get_pauseparam\t\t= atl1_get_pauseparam,\n\t.set_pauseparam\t\t= atl1_set_pauseparam,\n\t.get_link\t\t= ethtool_op_get_link,\n\t.get_strings\t\t= atl1_get_strings,\n\t.nway_reset\t\t= atl1_nway_reset,\n\t.get_ethtool_stats\t= atl1_get_ethtool_stats,\n\t.get_sset_count\t\t= atl1_get_sset_count,\n\t.get_link_ksettings\t= atl1_get_link_ksettings,\n\t.set_link_ksettings\t= atl1_set_link_ksettings,\n};\n\nmodule_pci_driver(atl1_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}