{
  "module_name": "atl1e_main.c",
  "hash_id": "e17f14234f68064add9446aaf9a9d0dcd77a8d66f9f200342e4bb632a0836738",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/atheros/atl1e/atl1e_main.c",
  "human_readable_source": "\n \n\n#include \"atl1e.h\"\n\nchar atl1e_driver_name[] = \"ATL1E\";\n#define PCI_DEVICE_ID_ATTANSIC_L1E      0x1026\n \nstatic const struct pci_device_id atl1e_pci_tbl[] = {\n\t{PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, PCI_DEVICE_ID_ATTANSIC_L1E)},\n\t{PCI_DEVICE(PCI_VENDOR_ID_ATTANSIC, 0x1066)},\n\t \n\t{ 0 }\n};\nMODULE_DEVICE_TABLE(pci, atl1e_pci_tbl);\n\nMODULE_AUTHOR(\"Atheros Corporation, <xiong.huang@atheros.com>, Jie Yang <jie.yang@atheros.com>\");\nMODULE_DESCRIPTION(\"Atheros 1000M Ethernet Network Driver\");\nMODULE_LICENSE(\"GPL\");\n\nstatic void atl1e_setup_mac_ctrl(struct atl1e_adapter *adapter);\n\nstatic const u16\natl1e_rx_page_vld_regs[AT_MAX_RECEIVE_QUEUE][AT_PAGE_NUM_PER_QUEUE] =\n{\n\t{REG_HOST_RXF0_PAGE0_VLD, REG_HOST_RXF0_PAGE1_VLD},\n\t{REG_HOST_RXF1_PAGE0_VLD, REG_HOST_RXF1_PAGE1_VLD},\n\t{REG_HOST_RXF2_PAGE0_VLD, REG_HOST_RXF2_PAGE1_VLD},\n\t{REG_HOST_RXF3_PAGE0_VLD, REG_HOST_RXF3_PAGE1_VLD}\n};\n\nstatic const u16 atl1e_rx_page_hi_addr_regs[AT_MAX_RECEIVE_QUEUE] =\n{\n\tREG_RXF0_BASE_ADDR_HI,\n\tREG_RXF1_BASE_ADDR_HI,\n\tREG_RXF2_BASE_ADDR_HI,\n\tREG_RXF3_BASE_ADDR_HI\n};\n\nstatic const u16\natl1e_rx_page_lo_addr_regs[AT_MAX_RECEIVE_QUEUE][AT_PAGE_NUM_PER_QUEUE] =\n{\n\t{REG_HOST_RXF0_PAGE0_LO, REG_HOST_RXF0_PAGE1_LO},\n\t{REG_HOST_RXF1_PAGE0_LO, REG_HOST_RXF1_PAGE1_LO},\n\t{REG_HOST_RXF2_PAGE0_LO, REG_HOST_RXF2_PAGE1_LO},\n\t{REG_HOST_RXF3_PAGE0_LO, REG_HOST_RXF3_PAGE1_LO}\n};\n\nstatic const u16\natl1e_rx_page_write_offset_regs[AT_MAX_RECEIVE_QUEUE][AT_PAGE_NUM_PER_QUEUE] =\n{\n\t{REG_HOST_RXF0_MB0_LO,  REG_HOST_RXF0_MB1_LO},\n\t{REG_HOST_RXF1_MB0_LO,  REG_HOST_RXF1_MB1_LO},\n\t{REG_HOST_RXF2_MB0_LO,  REG_HOST_RXF2_MB1_LO},\n\t{REG_HOST_RXF3_MB0_LO,  REG_HOST_RXF3_MB1_LO}\n};\n\nstatic const u16 atl1e_pay_load_size[] = {\n\t128, 256, 512, 1024, 2048, 4096,\n};\n\n \nstatic inline void atl1e_irq_enable(struct atl1e_adapter *adapter)\n{\n\tif (likely(atomic_dec_and_test(&adapter->irq_sem))) {\n\t\tAT_WRITE_REG(&adapter->hw, REG_ISR, 0);\n\t\tAT_WRITE_REG(&adapter->hw, REG_IMR, IMR_NORMAL_MASK);\n\t\tAT_WRITE_FLUSH(&adapter->hw);\n\t}\n}\n\n \nstatic inline void atl1e_irq_disable(struct atl1e_adapter *adapter)\n{\n\tatomic_inc(&adapter->irq_sem);\n\tAT_WRITE_REG(&adapter->hw, REG_IMR, 0);\n\tAT_WRITE_FLUSH(&adapter->hw);\n\tsynchronize_irq(adapter->pdev->irq);\n}\n\n \nstatic inline void atl1e_irq_reset(struct atl1e_adapter *adapter)\n{\n\tatomic_set(&adapter->irq_sem, 0);\n\tAT_WRITE_REG(&adapter->hw, REG_ISR, 0);\n\tAT_WRITE_REG(&adapter->hw, REG_IMR, 0);\n\tAT_WRITE_FLUSH(&adapter->hw);\n}\n\n \nstatic void atl1e_phy_config(struct timer_list *t)\n{\n\tstruct atl1e_adapter *adapter = from_timer(adapter, t,\n\t\t\t\t\t\t   phy_config_timer);\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&adapter->mdio_lock, flags);\n\tatl1e_restart_autoneg(hw);\n\tspin_unlock_irqrestore(&adapter->mdio_lock, flags);\n}\n\nvoid atl1e_reinit_locked(struct atl1e_adapter *adapter)\n{\n\twhile (test_and_set_bit(__AT_RESETTING, &adapter->flags))\n\t\tmsleep(1);\n\tatl1e_down(adapter);\n\tatl1e_up(adapter);\n\tclear_bit(__AT_RESETTING, &adapter->flags);\n}\n\nstatic void atl1e_reset_task(struct work_struct *work)\n{\n\tstruct atl1e_adapter *adapter;\n\tadapter = container_of(work, struct atl1e_adapter, reset_task);\n\n\tatl1e_reinit_locked(adapter);\n}\n\nstatic int atl1e_check_link(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tstruct net_device *netdev = adapter->netdev;\n\tint err = 0;\n\tu16 speed, duplex, phy_data;\n\n\t \n\tatl1e_read_phy_reg(hw, MII_BMSR, &phy_data);\n\tatl1e_read_phy_reg(hw, MII_BMSR, &phy_data);\n\tif ((phy_data & BMSR_LSTATUS) == 0) {\n\t\t \n\t\tif (netif_carrier_ok(netdev)) {  \n\t\t\tu32 value;\n\t\t\t \n\t\t\tvalue = AT_READ_REG(hw, REG_MAC_CTRL);\n\t\t\tvalue &= ~MAC_CTRL_RX_EN;\n\t\t\tAT_WRITE_REG(hw, REG_MAC_CTRL, value);\n\t\t\tadapter->link_speed = SPEED_0;\n\t\t\tnetif_carrier_off(netdev);\n\t\t\tnetif_stop_queue(netdev);\n\t\t}\n\t} else {\n\t\t \n\t\terr = atl1e_get_speed_and_duplex(hw, &speed, &duplex);\n\t\tif (unlikely(err))\n\t\t\treturn err;\n\n\t\t \n\t\tif (adapter->link_speed != speed ||\n\t\t    adapter->link_duplex != duplex) {\n\t\t\tadapter->link_speed  = speed;\n\t\t\tadapter->link_duplex = duplex;\n\t\t\tatl1e_setup_mac_ctrl(adapter);\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"NIC Link is Up <%d Mbps %s Duplex>\\n\",\n\t\t\t\t    adapter->link_speed,\n\t\t\t\t    adapter->link_duplex == FULL_DUPLEX ?\n\t\t\t\t    \"Full\" : \"Half\");\n\t\t}\n\n\t\tif (!netif_carrier_ok(netdev)) {\n\t\t\t \n\t\t\tnetif_carrier_on(netdev);\n\t\t\tnetif_wake_queue(netdev);\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic void atl1e_link_chg_task(struct work_struct *work)\n{\n\tstruct atl1e_adapter *adapter;\n\tunsigned long flags;\n\n\tadapter = container_of(work, struct atl1e_adapter, link_chg_task);\n\tspin_lock_irqsave(&adapter->mdio_lock, flags);\n\tatl1e_check_link(adapter);\n\tspin_unlock_irqrestore(&adapter->mdio_lock, flags);\n}\n\nstatic void atl1e_link_chg_event(struct atl1e_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tu16 phy_data = 0;\n\tu16 link_up = 0;\n\n\tspin_lock(&adapter->mdio_lock);\n\tatl1e_read_phy_reg(&adapter->hw, MII_BMSR, &phy_data);\n\tatl1e_read_phy_reg(&adapter->hw, MII_BMSR, &phy_data);\n\tspin_unlock(&adapter->mdio_lock);\n\tlink_up = phy_data & BMSR_LSTATUS;\n\t \n\tif (!link_up) {\n\t\tif (netif_carrier_ok(netdev)) {\n\t\t\t \n\t\t\tnetdev_info(netdev, \"NIC Link is Down\\n\");\n\t\t\tadapter->link_speed = SPEED_0;\n\t\t\tnetif_stop_queue(netdev);\n\t\t}\n\t}\n\tschedule_work(&adapter->link_chg_task);\n}\n\nstatic void atl1e_del_timer(struct atl1e_adapter *adapter)\n{\n\tdel_timer_sync(&adapter->phy_config_timer);\n}\n\nstatic void atl1e_cancel_work(struct atl1e_adapter *adapter)\n{\n\tcancel_work_sync(&adapter->reset_task);\n\tcancel_work_sync(&adapter->link_chg_task);\n}\n\n \nstatic void atl1e_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tschedule_work(&adapter->reset_task);\n}\n\n \nstatic void atl1e_set_multi(struct net_device *netdev)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tstruct netdev_hw_addr *ha;\n\tu32 mac_ctrl_data = 0;\n\tu32 hash_value;\n\n\t \n\tmac_ctrl_data = AT_READ_REG(hw, REG_MAC_CTRL);\n\n\tif (netdev->flags & IFF_PROMISC) {\n\t\tmac_ctrl_data |= MAC_CTRL_PROMIS_EN;\n\t} else if (netdev->flags & IFF_ALLMULTI) {\n\t\tmac_ctrl_data |= MAC_CTRL_MC_ALL_EN;\n\t\tmac_ctrl_data &= ~MAC_CTRL_PROMIS_EN;\n\t} else {\n\t\tmac_ctrl_data &= ~(MAC_CTRL_PROMIS_EN | MAC_CTRL_MC_ALL_EN);\n\t}\n\n\tAT_WRITE_REG(hw, REG_MAC_CTRL, mac_ctrl_data);\n\n\t \n\tAT_WRITE_REG(hw, REG_RX_HASH_TABLE, 0);\n\tAT_WRITE_REG_ARRAY(hw, REG_RX_HASH_TABLE, 1, 0);\n\n\t \n\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\thash_value = atl1e_hash_mc_addr(hw, ha->addr);\n\t\tatl1e_hash_set(hw, hash_value);\n\t}\n}\n\nstatic void __atl1e_rx_mode(netdev_features_t features, u32 *mac_ctrl_data)\n{\n\n\tif (features & NETIF_F_RXALL) {\n\t\t \n\t\t*mac_ctrl_data |= MAC_CTRL_DBG;\n\t} else {\n\t\t \n\t\t*mac_ctrl_data &= ~MAC_CTRL_DBG;\n\t}\n}\n\nstatic void atl1e_rx_mode(struct net_device *netdev,\n\tnetdev_features_t features)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tu32 mac_ctrl_data = 0;\n\n\tnetdev_dbg(adapter->netdev, \"%s\\n\", __func__);\n\n\tatl1e_irq_disable(adapter);\n\tmac_ctrl_data = AT_READ_REG(&adapter->hw, REG_MAC_CTRL);\n\t__atl1e_rx_mode(features, &mac_ctrl_data);\n\tAT_WRITE_REG(&adapter->hw, REG_MAC_CTRL, mac_ctrl_data);\n\tatl1e_irq_enable(adapter);\n}\n\n\nstatic void __atl1e_vlan_mode(netdev_features_t features, u32 *mac_ctrl_data)\n{\n\tif (features & NETIF_F_HW_VLAN_CTAG_RX) {\n\t\t \n\t\t*mac_ctrl_data |= MAC_CTRL_RMV_VLAN;\n\t} else {\n\t\t \n\t\t*mac_ctrl_data &= ~MAC_CTRL_RMV_VLAN;\n\t}\n}\n\nstatic void atl1e_vlan_mode(struct net_device *netdev,\n\tnetdev_features_t features)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tu32 mac_ctrl_data = 0;\n\n\tnetdev_dbg(adapter->netdev, \"%s\\n\", __func__);\n\n\tatl1e_irq_disable(adapter);\n\tmac_ctrl_data = AT_READ_REG(&adapter->hw, REG_MAC_CTRL);\n\t__atl1e_vlan_mode(features, &mac_ctrl_data);\n\tAT_WRITE_REG(&adapter->hw, REG_MAC_CTRL, mac_ctrl_data);\n\tatl1e_irq_enable(adapter);\n}\n\nstatic void atl1e_restore_vlan(struct atl1e_adapter *adapter)\n{\n\tnetdev_dbg(adapter->netdev, \"%s\\n\", __func__);\n\tatl1e_vlan_mode(adapter->netdev, adapter->netdev->features);\n}\n\n \nstatic int atl1e_set_mac_addr(struct net_device *netdev, void *p)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tstruct sockaddr *addr = p;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (netif_running(netdev))\n\t\treturn -EBUSY;\n\n\teth_hw_addr_set(netdev, addr->sa_data);\n\tmemcpy(adapter->hw.mac_addr, addr->sa_data, netdev->addr_len);\n\n\tatl1e_hw_set_mac_addr(&adapter->hw);\n\n\treturn 0;\n}\n\nstatic netdev_features_t atl1e_fix_features(struct net_device *netdev,\n\tnetdev_features_t features)\n{\n\t \n\tif (features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_TX;\n\telse\n\t\tfeatures &= ~NETIF_F_HW_VLAN_CTAG_TX;\n\n\treturn features;\n}\n\nstatic int atl1e_set_features(struct net_device *netdev,\n\tnetdev_features_t features)\n{\n\tnetdev_features_t changed = netdev->features ^ features;\n\n\tif (changed & NETIF_F_HW_VLAN_CTAG_RX)\n\t\tatl1e_vlan_mode(netdev, features);\n\n\tif (changed & NETIF_F_RXALL)\n\t\tatl1e_rx_mode(netdev, features);\n\n\n\treturn 0;\n}\n\n \nstatic int atl1e_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tint max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\n\t \n\tif (netif_running(netdev)) {\n\t\twhile (test_and_set_bit(__AT_RESETTING, &adapter->flags))\n\t\t\tmsleep(1);\n\t\tnetdev->mtu = new_mtu;\n\t\tadapter->hw.max_frame_size = new_mtu;\n\t\tadapter->hw.rx_jumbo_th = (max_frame + 7) >> 3;\n\t\tatl1e_down(adapter);\n\t\tatl1e_up(adapter);\n\t\tclear_bit(__AT_RESETTING, &adapter->flags);\n\t}\n\treturn 0;\n}\n\n \nstatic int atl1e_mdio_read(struct net_device *netdev, int phy_id, int reg_num)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tu16 result;\n\n\tatl1e_read_phy_reg(&adapter->hw, reg_num & MDIO_REG_ADDR_MASK, &result);\n\treturn result;\n}\n\nstatic void atl1e_mdio_write(struct net_device *netdev, int phy_id,\n\t\t\t     int reg_num, int val)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\tif (atl1e_write_phy_reg(&adapter->hw,\n\t\t\t\treg_num & MDIO_REG_ADDR_MASK, val))\n\t\tnetdev_err(netdev, \"write phy register failed\\n\");\n}\n\nstatic int atl1e_mii_ioctl(struct net_device *netdev,\n\t\t\t   struct ifreq *ifr, int cmd)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tstruct mii_ioctl_data *data = if_mii(ifr);\n\tunsigned long flags;\n\tint retval = 0;\n\n\tif (!netif_running(netdev))\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&adapter->mdio_lock, flags);\n\tswitch (cmd) {\n\tcase SIOCGMIIPHY:\n\t\tdata->phy_id = 0;\n\t\tbreak;\n\n\tcase SIOCGMIIREG:\n\t\tif (atl1e_read_phy_reg(&adapter->hw, data->reg_num & 0x1F,\n\t\t\t\t    &data->val_out)) {\n\t\t\tretval = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\n\tcase SIOCSMIIREG:\n\t\tif (data->reg_num & ~(0x1F)) {\n\t\t\tretval = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tnetdev_dbg(adapter->netdev, \"<atl1e_mii_ioctl> write %x %x\\n\",\n\t\t\t   data->reg_num, data->val_in);\n\t\tif (atl1e_write_phy_reg(&adapter->hw,\n\t\t\t\t     data->reg_num, data->val_in)) {\n\t\t\tretval = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tretval = -EOPNOTSUPP;\n\t\tbreak;\n\t}\nout:\n\tspin_unlock_irqrestore(&adapter->mdio_lock, flags);\n\treturn retval;\n\n}\n\nstatic int atl1e_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tswitch (cmd) {\n\tcase SIOCGMIIPHY:\n\tcase SIOCGMIIREG:\n\tcase SIOCSMIIREG:\n\t\treturn atl1e_mii_ioctl(netdev, ifr, cmd);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void atl1e_setup_pcicmd(struct pci_dev *pdev)\n{\n\tu16 cmd;\n\n\tpci_read_config_word(pdev, PCI_COMMAND, &cmd);\n\tcmd &= ~(PCI_COMMAND_INTX_DISABLE | PCI_COMMAND_IO);\n\tcmd |=  (PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER);\n\tpci_write_config_word(pdev, PCI_COMMAND, cmd);\n\n\t \n\tpci_write_config_dword(pdev, REG_PM_CTRLSTAT, 0);\n\tmsleep(1);\n}\n\n \nstatic int atl1e_alloc_queues(struct atl1e_adapter *adapter)\n{\n\treturn 0;\n}\n\n \nstatic int atl1e_sw_init(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_hw *hw   = &adapter->hw;\n\tstruct pci_dev\t*pdev = adapter->pdev;\n\tu32 phy_status_data = 0;\n\n\tadapter->wol = 0;\n\tadapter->link_speed = SPEED_0;    \n\tadapter->link_duplex = FULL_DUPLEX;\n\tadapter->num_rx_queues = 1;\n\n\t \n\thw->vendor_id = pdev->vendor;\n\thw->device_id = pdev->device;\n\thw->subsystem_vendor_id = pdev->subsystem_vendor;\n\thw->subsystem_id = pdev->subsystem_device;\n\thw->revision_id  = pdev->revision;\n\n\tpci_read_config_word(pdev, PCI_COMMAND, &hw->pci_cmd_word);\n\n\tphy_status_data = AT_READ_REG(hw, REG_PHY_STATUS);\n\t \n\tif (hw->revision_id >= 0xF0) {\n\t\thw->nic_type = athr_l2e_revB;\n\t} else {\n\t\tif (phy_status_data & PHY_STATUS_100M)\n\t\t\thw->nic_type = athr_l1e;\n\t\telse\n\t\t\thw->nic_type = athr_l2e_revA;\n\t}\n\n\tphy_status_data = AT_READ_REG(hw, REG_PHY_STATUS);\n\n\tif (phy_status_data & PHY_STATUS_EMI_CA)\n\t\thw->emi_ca = true;\n\telse\n\t\thw->emi_ca = false;\n\n\thw->phy_configured = false;\n\thw->preamble_len = 7;\n\thw->max_frame_size = adapter->netdev->mtu;\n\thw->rx_jumbo_th = (hw->max_frame_size + ETH_HLEN +\n\t\t\t\tVLAN_HLEN + ETH_FCS_LEN + 7) >> 3;\n\n\thw->rrs_type = atl1e_rrs_disable;\n\thw->indirect_tab = 0;\n\thw->base_cpu = 0;\n\n\t \n\n\thw->ict = 50000;                  \n\thw->smb_timer = 200000;           \n\thw->tpd_burst = 5;\n\thw->rrd_thresh = 1;\n\thw->tpd_thresh = adapter->tx_ring.count / 2;\n\thw->rx_count_down = 4;   \n\thw->tx_count_down = hw->imt * 4 / 3;\n\thw->dmar_block = atl1e_dma_req_1024;\n\thw->dmaw_block = atl1e_dma_req_1024;\n\thw->dmar_dly_cnt = 15;\n\thw->dmaw_dly_cnt = 4;\n\n\tif (atl1e_alloc_queues(adapter)) {\n\t\tnetdev_err(adapter->netdev, \"Unable to allocate memory for queues\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tatomic_set(&adapter->irq_sem, 1);\n\tspin_lock_init(&adapter->mdio_lock);\n\n\tset_bit(__AT_DOWN, &adapter->flags);\n\n\treturn 0;\n}\n\n \nstatic void atl1e_clean_tx_ring(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\n\tstruct atl1e_tx_buffer *tx_buffer = NULL;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tu16 index, ring_count;\n\n\tif (tx_ring->desc == NULL || tx_ring->tx_buffer == NULL)\n\t\treturn;\n\n\tring_count = tx_ring->count;\n\t \n\tfor (index = 0; index < ring_count; index++) {\n\t\ttx_buffer = &tx_ring->tx_buffer[index];\n\t\tif (tx_buffer->dma) {\n\t\t\tif (tx_buffer->flags & ATL1E_TX_PCIMAP_SINGLE)\n\t\t\t\tdma_unmap_single(&pdev->dev, tx_buffer->dma,\n\t\t\t\t\t\t tx_buffer->length,\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\telse if (tx_buffer->flags & ATL1E_TX_PCIMAP_PAGE)\n\t\t\t\tdma_unmap_page(&pdev->dev, tx_buffer->dma,\n\t\t\t\t\t       tx_buffer->length,\n\t\t\t\t\t       DMA_TO_DEVICE);\n\t\t\ttx_buffer->dma = 0;\n\t\t}\n\t}\n\t \n\tfor (index = 0; index < ring_count; index++) {\n\t\ttx_buffer = &tx_ring->tx_buffer[index];\n\t\tif (tx_buffer->skb) {\n\t\t\tdev_kfree_skb_any(tx_buffer->skb);\n\t\t\ttx_buffer->skb = NULL;\n\t\t}\n\t}\n\t \n\tmemset(tx_ring->desc, 0, sizeof(struct atl1e_tpd_desc) *\n\t\t\t\tring_count);\n\tmemset(tx_ring->tx_buffer, 0, sizeof(struct atl1e_tx_buffer) *\n\t\t\t\tring_count);\n}\n\n \nstatic void atl1e_clean_rx_ring(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_rx_ring *rx_ring =\n\t\t&adapter->rx_ring;\n\tstruct atl1e_rx_page_desc *rx_page_desc = rx_ring->rx_page_desc;\n\tu16 i, j;\n\n\n\tif (adapter->ring_vir_addr == NULL)\n\t\treturn;\n\t \n\tfor (i = 0; i < adapter->num_rx_queues; i++) {\n\t\tfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\n\t\t\tif (rx_page_desc[i].rx_page[j].addr != NULL) {\n\t\t\t\tmemset(rx_page_desc[i].rx_page[j].addr, 0,\n\t\t\t\t\t\trx_ring->real_page_size);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void atl1e_cal_ring_size(struct atl1e_adapter *adapter, u32 *ring_size)\n{\n\t*ring_size = ((u32)(adapter->tx_ring.count *\n\t\t     sizeof(struct atl1e_tpd_desc) + 7\n\t\t\t \n\t\t     + adapter->rx_ring.real_page_size * AT_PAGE_NUM_PER_QUEUE *\n\t\t\tadapter->num_rx_queues + 31\n\t\t\t \n\t\t     + (1 + AT_PAGE_NUM_PER_QUEUE * adapter->num_rx_queues) *\n\t\t\tsizeof(u32) + 3));\n\t\t\t \n}\n\nstatic void atl1e_init_ring_resources(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_rx_ring *rx_ring = NULL;\n\n\trx_ring = &adapter->rx_ring;\n\n\trx_ring->real_page_size = adapter->rx_ring.page_size\n\t\t\t\t + adapter->hw.max_frame_size\n\t\t\t\t + ETH_HLEN + VLAN_HLEN\n\t\t\t\t + ETH_FCS_LEN;\n\trx_ring->real_page_size = roundup(rx_ring->real_page_size, 32);\n\tatl1e_cal_ring_size(adapter, &adapter->ring_size);\n\n\tadapter->ring_vir_addr = NULL;\n\tadapter->rx_ring.desc = NULL;\n\trwlock_init(&adapter->tx_ring.tx_lock);\n}\n\n \nstatic void atl1e_init_ring_ptrs(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_tx_ring *tx_ring = NULL;\n\tstruct atl1e_rx_ring *rx_ring = NULL;\n\tstruct atl1e_rx_page_desc *rx_page_desc = NULL;\n\tint i, j;\n\n\ttx_ring = &adapter->tx_ring;\n\trx_ring = &adapter->rx_ring;\n\trx_page_desc = rx_ring->rx_page_desc;\n\n\ttx_ring->next_to_use = 0;\n\tatomic_set(&tx_ring->next_to_clean, 0);\n\n\tfor (i = 0; i < adapter->num_rx_queues; i++) {\n\t\trx_page_desc[i].rx_using  = 0;\n\t\trx_page_desc[i].rx_nxseq = 0;\n\t\tfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\n\t\t\t*rx_page_desc[i].rx_page[j].write_offset_addr = 0;\n\t\t\trx_page_desc[i].rx_page[j].read_offset = 0;\n\t\t}\n\t}\n}\n\n \nstatic void atl1e_free_ring_resources(struct atl1e_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\n\tatl1e_clean_tx_ring(adapter);\n\tatl1e_clean_rx_ring(adapter);\n\n\tif (adapter->ring_vir_addr) {\n\t\tdma_free_coherent(&pdev->dev, adapter->ring_size,\n\t\t\t\t  adapter->ring_vir_addr, adapter->ring_dma);\n\t\tadapter->ring_vir_addr = NULL;\n\t}\n\n\tif (adapter->tx_ring.tx_buffer) {\n\t\tkfree(adapter->tx_ring.tx_buffer);\n\t\tadapter->tx_ring.tx_buffer = NULL;\n\t}\n}\n\n \nstatic int atl1e_setup_ring_resources(struct atl1e_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct atl1e_tx_ring *tx_ring;\n\tstruct atl1e_rx_ring *rx_ring;\n\tstruct atl1e_rx_page_desc  *rx_page_desc;\n\tint size, i, j;\n\tu32 offset = 0;\n\tint err = 0;\n\n\tif (adapter->ring_vir_addr != NULL)\n\t\treturn 0;  \n\n\ttx_ring = &adapter->tx_ring;\n\trx_ring = &adapter->rx_ring;\n\n\t \n\n\tsize = adapter->ring_size;\n\tadapter->ring_vir_addr = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t\t    adapter->ring_size,\n\t\t\t\t\t\t    &adapter->ring_dma, GFP_KERNEL);\n\tif (adapter->ring_vir_addr == NULL) {\n\t\tnetdev_err(adapter->netdev,\n\t\t\t   \"dma_alloc_coherent failed, size = D%d\\n\", size);\n\t\treturn -ENOMEM;\n\t}\n\n\trx_page_desc = rx_ring->rx_page_desc;\n\n\t \n\ttx_ring->dma = roundup(adapter->ring_dma, 8);\n\toffset = tx_ring->dma - adapter->ring_dma;\n\ttx_ring->desc = adapter->ring_vir_addr + offset;\n\tsize = sizeof(struct atl1e_tx_buffer) * (tx_ring->count);\n\ttx_ring->tx_buffer = kzalloc(size, GFP_KERNEL);\n\tif (tx_ring->tx_buffer == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto failed;\n\t}\n\n\t \n\toffset += (sizeof(struct atl1e_tpd_desc) * tx_ring->count);\n\toffset = roundup(offset, 32);\n\n\tfor (i = 0; i < adapter->num_rx_queues; i++) {\n\t\tfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\n\t\t\trx_page_desc[i].rx_page[j].dma =\n\t\t\t\tadapter->ring_dma + offset;\n\t\t\trx_page_desc[i].rx_page[j].addr =\n\t\t\t\tadapter->ring_vir_addr + offset;\n\t\t\toffset += rx_ring->real_page_size;\n\t\t}\n\t}\n\n\t \n\ttx_ring->cmb_dma = adapter->ring_dma + offset;\n\ttx_ring->cmb = adapter->ring_vir_addr + offset;\n\toffset += sizeof(u32);\n\n\tfor (i = 0; i < adapter->num_rx_queues; i++) {\n\t\tfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\n\t\t\trx_page_desc[i].rx_page[j].write_offset_dma =\n\t\t\t\tadapter->ring_dma + offset;\n\t\t\trx_page_desc[i].rx_page[j].write_offset_addr =\n\t\t\t\tadapter->ring_vir_addr + offset;\n\t\t\toffset += sizeof(u32);\n\t\t}\n\t}\n\n\tif (unlikely(offset > adapter->ring_size)) {\n\t\tnetdev_err(adapter->netdev, \"offset(%d) > ring size(%d) !!\\n\",\n\t\t\t   offset, adapter->ring_size);\n\t\terr = -1;\n\t\tgoto free_buffer;\n\t}\n\n\treturn 0;\nfree_buffer:\n\tkfree(tx_ring->tx_buffer);\n\ttx_ring->tx_buffer = NULL;\nfailed:\n\tif (adapter->ring_vir_addr != NULL) {\n\t\tdma_free_coherent(&pdev->dev, adapter->ring_size,\n\t\t\t\t  adapter->ring_vir_addr, adapter->ring_dma);\n\t\tadapter->ring_vir_addr = NULL;\n\t}\n\treturn err;\n}\n\nstatic inline void atl1e_configure_des_ring(struct atl1e_adapter *adapter)\n{\n\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tstruct atl1e_rx_ring *rx_ring = &adapter->rx_ring;\n\tstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\n\tstruct atl1e_rx_page_desc *rx_page_desc = NULL;\n\tint i, j;\n\n\tAT_WRITE_REG(hw, REG_DESC_BASE_ADDR_HI,\n\t\t\t(u32)((adapter->ring_dma & AT_DMA_HI_ADDR_MASK) >> 32));\n\tAT_WRITE_REG(hw, REG_TPD_BASE_ADDR_LO,\n\t\t\t(u32)((tx_ring->dma) & AT_DMA_LO_ADDR_MASK));\n\tAT_WRITE_REG(hw, REG_TPD_RING_SIZE, (u16)(tx_ring->count));\n\tAT_WRITE_REG(hw, REG_HOST_TX_CMB_LO,\n\t\t\t(u32)((tx_ring->cmb_dma) & AT_DMA_LO_ADDR_MASK));\n\n\trx_page_desc = rx_ring->rx_page_desc;\n\t \n\tfor (i = 0; i < AT_MAX_RECEIVE_QUEUE; i++) {\n\t\tAT_WRITE_REG(hw, atl1e_rx_page_hi_addr_regs[i],\n\t\t\t\t (u32)((adapter->ring_dma &\n\t\t\t\t AT_DMA_HI_ADDR_MASK) >> 32));\n\t\tfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\n\t\t\tu32 page_phy_addr;\n\t\t\tu32 offset_phy_addr;\n\n\t\t\tpage_phy_addr = rx_page_desc[i].rx_page[j].dma;\n\t\t\toffset_phy_addr =\n\t\t\t\t   rx_page_desc[i].rx_page[j].write_offset_dma;\n\n\t\t\tAT_WRITE_REG(hw, atl1e_rx_page_lo_addr_regs[i][j],\n\t\t\t\t\tpage_phy_addr & AT_DMA_LO_ADDR_MASK);\n\t\t\tAT_WRITE_REG(hw, atl1e_rx_page_write_offset_regs[i][j],\n\t\t\t\t\toffset_phy_addr & AT_DMA_LO_ADDR_MASK);\n\t\t\tAT_WRITE_REGB(hw, atl1e_rx_page_vld_regs[i][j], 1);\n\t\t}\n\t}\n\t \n\tAT_WRITE_REG(hw, REG_HOST_RXFPAGE_SIZE, rx_ring->page_size);\n\t \n\tAT_WRITE_REG(hw, REG_LOAD_PTR, 1);\n}\n\nstatic inline void atl1e_configure_tx(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tu32 dev_ctrl_data = 0;\n\tu32 max_pay_load = 0;\n\tu32 jumbo_thresh = 0;\n\tu32 extra_size = 0;      \n\n\t \n\tif (hw->nic_type != athr_l2e_revB) {\n\t\textra_size = ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN;\n\t\tif (hw->max_frame_size <= 1500) {\n\t\t\tjumbo_thresh = hw->max_frame_size + extra_size;\n\t\t} else if (hw->max_frame_size < 6*1024) {\n\t\t\tjumbo_thresh =\n\t\t\t\t(hw->max_frame_size + extra_size) * 2 / 3;\n\t\t} else {\n\t\t\tjumbo_thresh = (hw->max_frame_size + extra_size) / 2;\n\t\t}\n\t\tAT_WRITE_REG(hw, REG_TX_EARLY_TH, (jumbo_thresh + 7) >> 3);\n\t}\n\n\tdev_ctrl_data = AT_READ_REG(hw, REG_DEVICE_CTRL);\n\n\tmax_pay_load  = ((dev_ctrl_data >> DEVICE_CTRL_MAX_PAYLOAD_SHIFT)) &\n\t\t\tDEVICE_CTRL_MAX_PAYLOAD_MASK;\n\n\thw->dmaw_block = min_t(u32, max_pay_load, hw->dmaw_block);\n\n\tmax_pay_load  = ((dev_ctrl_data >> DEVICE_CTRL_MAX_RREQ_SZ_SHIFT)) &\n\t\t\tDEVICE_CTRL_MAX_RREQ_SZ_MASK;\n\thw->dmar_block = min_t(u32, max_pay_load, hw->dmar_block);\n\n\tif (hw->nic_type != athr_l2e_revB)\n\t\tAT_WRITE_REGW(hw, REG_TXQ_CTRL + 2,\n\t\t\t      atl1e_pay_load_size[hw->dmar_block]);\n\t \n\tAT_WRITE_REGW(hw, REG_TXQ_CTRL,\n\t\t\t(((u16)hw->tpd_burst & TXQ_CTRL_NUM_TPD_BURST_MASK)\n\t\t\t << TXQ_CTRL_NUM_TPD_BURST_SHIFT)\n\t\t\t| TXQ_CTRL_ENH_MODE | TXQ_CTRL_EN);\n}\n\nstatic inline void atl1e_configure_rx(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tu32 rxf_len  = 0;\n\tu32 rxf_low  = 0;\n\tu32 rxf_high = 0;\n\tu32 rxf_thresh_data = 0;\n\tu32 rxq_ctrl_data = 0;\n\n\tif (hw->nic_type != athr_l2e_revB) {\n\t\tAT_WRITE_REGW(hw, REG_RXQ_JMBOSZ_RRDTIM,\n\t\t\t      (u16)((hw->rx_jumbo_th & RXQ_JMBOSZ_TH_MASK) <<\n\t\t\t      RXQ_JMBOSZ_TH_SHIFT |\n\t\t\t      (1 & RXQ_JMBO_LKAH_MASK) <<\n\t\t\t      RXQ_JMBO_LKAH_SHIFT));\n\n\t\trxf_len  = AT_READ_REG(hw, REG_SRAM_RXF_LEN);\n\t\trxf_high = rxf_len * 4 / 5;\n\t\trxf_low  = rxf_len / 5;\n\t\trxf_thresh_data = ((rxf_high  & RXQ_RXF_PAUSE_TH_HI_MASK)\n\t\t\t\t  << RXQ_RXF_PAUSE_TH_HI_SHIFT) |\n\t\t\t\t  ((rxf_low & RXQ_RXF_PAUSE_TH_LO_MASK)\n\t\t\t\t  << RXQ_RXF_PAUSE_TH_LO_SHIFT);\n\n\t\tAT_WRITE_REG(hw, REG_RXQ_RXF_PAUSE_THRESH, rxf_thresh_data);\n\t}\n\n\t \n\tAT_WRITE_REG(hw, REG_IDT_TABLE, hw->indirect_tab);\n\tAT_WRITE_REG(hw, REG_BASE_CPU_NUMBER, hw->base_cpu);\n\n\tif (hw->rrs_type & atl1e_rrs_ipv4)\n\t\trxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV4;\n\n\tif (hw->rrs_type & atl1e_rrs_ipv4_tcp)\n\t\trxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV4_TCP;\n\n\tif (hw->rrs_type & atl1e_rrs_ipv6)\n\t\trxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV6;\n\n\tif (hw->rrs_type & atl1e_rrs_ipv6_tcp)\n\t\trxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV6_TCP;\n\n\tif (hw->rrs_type != atl1e_rrs_disable)\n\t\trxq_ctrl_data |=\n\t\t\t(RXQ_CTRL_HASH_ENABLE | RXQ_CTRL_RSS_MODE_MQUESINT);\n\n\trxq_ctrl_data |= RXQ_CTRL_IPV6_XSUM_VERIFY_EN | RXQ_CTRL_PBA_ALIGN_32 |\n\t\t\t RXQ_CTRL_CUT_THRU_EN | RXQ_CTRL_EN;\n\n\tAT_WRITE_REG(hw, REG_RXQ_CTRL, rxq_ctrl_data);\n}\n\nstatic inline void atl1e_configure_dma(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tu32 dma_ctrl_data = 0;\n\n\tdma_ctrl_data = DMA_CTRL_RXCMB_EN;\n\tdma_ctrl_data |= (((u32)hw->dmar_block) & DMA_CTRL_DMAR_BURST_LEN_MASK)\n\t\t<< DMA_CTRL_DMAR_BURST_LEN_SHIFT;\n\tdma_ctrl_data |= (((u32)hw->dmaw_block) & DMA_CTRL_DMAW_BURST_LEN_MASK)\n\t\t<< DMA_CTRL_DMAW_BURST_LEN_SHIFT;\n\tdma_ctrl_data |= DMA_CTRL_DMAR_REQ_PRI | DMA_CTRL_DMAR_OUT_ORDER;\n\tdma_ctrl_data |= (((u32)hw->dmar_dly_cnt) & DMA_CTRL_DMAR_DLY_CNT_MASK)\n\t\t<< DMA_CTRL_DMAR_DLY_CNT_SHIFT;\n\tdma_ctrl_data |= (((u32)hw->dmaw_dly_cnt) & DMA_CTRL_DMAW_DLY_CNT_MASK)\n\t\t<< DMA_CTRL_DMAW_DLY_CNT_SHIFT;\n\n\tAT_WRITE_REG(hw, REG_DMA_CTRL, dma_ctrl_data);\n}\n\nstatic void atl1e_setup_mac_ctrl(struct atl1e_adapter *adapter)\n{\n\tu32 value;\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tstruct net_device *netdev = adapter->netdev;\n\n\t \n\tvalue = MAC_CTRL_TX_EN |\n\t\tMAC_CTRL_RX_EN ;\n\n\tif (FULL_DUPLEX == adapter->link_duplex)\n\t\tvalue |= MAC_CTRL_DUPLX;\n\n\tvalue |= ((u32)((SPEED_1000 == adapter->link_speed) ?\n\t\t\t  MAC_CTRL_SPEED_1000 : MAC_CTRL_SPEED_10_100) <<\n\t\t\t  MAC_CTRL_SPEED_SHIFT);\n\tvalue |= (MAC_CTRL_TX_FLOW | MAC_CTRL_RX_FLOW);\n\n\tvalue |= (MAC_CTRL_ADD_CRC | MAC_CTRL_PAD);\n\tvalue |= (((u32)adapter->hw.preamble_len &\n\t\t  MAC_CTRL_PRMLEN_MASK) << MAC_CTRL_PRMLEN_SHIFT);\n\n\t__atl1e_vlan_mode(netdev->features, &value);\n\n\tvalue |= MAC_CTRL_BC_EN;\n\tif (netdev->flags & IFF_PROMISC)\n\t\tvalue |= MAC_CTRL_PROMIS_EN;\n\tif (netdev->flags & IFF_ALLMULTI)\n\t\tvalue |= MAC_CTRL_MC_ALL_EN;\n\tif (netdev->features & NETIF_F_RXALL)\n\t\tvalue |= MAC_CTRL_DBG;\n\tAT_WRITE_REG(hw, REG_MAC_CTRL, value);\n}\n\n \nstatic int atl1e_configure(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_hw *hw = &adapter->hw;\n\n\tu32 intr_status_data = 0;\n\n\t \n\tAT_WRITE_REG(hw, REG_ISR, ~0);\n\n\t \n\tatl1e_hw_set_mac_addr(hw);\n\n\t \n\n\t \n\tAT_WRITE_REG(hw, REG_WOL_CTRL, 0);\n\n\t \n\tatl1e_configure_des_ring(adapter);\n\n\t \n\tAT_WRITE_REGW(hw, REG_IRQ_MODU_TIMER_INIT, hw->imt);\n\tAT_WRITE_REGW(hw, REG_IRQ_MODU_TIMER2_INIT, hw->imt);\n\tAT_WRITE_REG(hw, REG_MASTER_CTRL, MASTER_CTRL_LED_MODE |\n\t\t\tMASTER_CTRL_ITIMER_EN | MASTER_CTRL_ITIMER2_EN);\n\n\t \n\tAT_WRITE_REGW(hw, REG_TRIG_RRD_THRESH, hw->rrd_thresh);\n\tAT_WRITE_REGW(hw, REG_TRIG_TPD_THRESH, hw->tpd_thresh);\n\tAT_WRITE_REGW(hw, REG_TRIG_RXTIMER, hw->rx_count_down);\n\tAT_WRITE_REGW(hw, REG_TRIG_TXTIMER, hw->tx_count_down);\n\n\t \n\tAT_WRITE_REGW(hw, REG_CMBDISDMA_TIMER, hw->ict);\n\n\t \n\tAT_WRITE_REG(hw, REG_MTU, hw->max_frame_size + ETH_HLEN +\n\t\t\tVLAN_HLEN + ETH_FCS_LEN);\n\n\t \n\tatl1e_configure_tx(adapter);\n\n\t \n\tatl1e_configure_rx(adapter);\n\n\t \n\tatl1e_configure_dma(adapter);\n\n\t \n\tAT_WRITE_REG(hw, REG_SMB_STAT_TIMER, hw->smb_timer);\n\n\tintr_status_data = AT_READ_REG(hw, REG_ISR);\n\tif (unlikely((intr_status_data & ISR_PHY_LINKDOWN) != 0)) {\n\t\tnetdev_err(adapter->netdev,\n\t\t\t   \"atl1e_configure failed, PCIE phy link down\\n\");\n\t\treturn -1;\n\t}\n\n\tAT_WRITE_REG(hw, REG_ISR, 0x7fffffff);\n\treturn 0;\n}\n\n \nstatic struct net_device_stats *atl1e_get_stats(struct net_device *netdev)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1e_hw_stats  *hw_stats = &adapter->hw_stats;\n\tstruct net_device_stats *net_stats = &netdev->stats;\n\n\tnet_stats->rx_bytes   = hw_stats->rx_byte_cnt;\n\tnet_stats->tx_bytes   = hw_stats->tx_byte_cnt;\n\tnet_stats->multicast  = hw_stats->rx_mcast;\n\tnet_stats->collisions = hw_stats->tx_1_col +\n\t\t\t\thw_stats->tx_2_col +\n\t\t\t\thw_stats->tx_late_col +\n\t\t\t\thw_stats->tx_abort_col;\n\n\tnet_stats->rx_errors  = hw_stats->rx_frag +\n\t\t\t\thw_stats->rx_fcs_err +\n\t\t\t\thw_stats->rx_len_err +\n\t\t\t\thw_stats->rx_sz_ov +\n\t\t\t\thw_stats->rx_rrd_ov +\n\t\t\t\thw_stats->rx_align_err +\n\t\t\t\thw_stats->rx_rxf_ov;\n\n\tnet_stats->rx_fifo_errors   = hw_stats->rx_rxf_ov;\n\tnet_stats->rx_length_errors = hw_stats->rx_len_err;\n\tnet_stats->rx_crc_errors    = hw_stats->rx_fcs_err;\n\tnet_stats->rx_frame_errors  = hw_stats->rx_align_err;\n\tnet_stats->rx_dropped       = hw_stats->rx_rrd_ov;\n\n\tnet_stats->tx_errors = hw_stats->tx_late_col +\n\t\t\t       hw_stats->tx_abort_col +\n\t\t\t       hw_stats->tx_underrun +\n\t\t\t       hw_stats->tx_trunc;\n\n\tnet_stats->tx_fifo_errors    = hw_stats->tx_underrun;\n\tnet_stats->tx_aborted_errors = hw_stats->tx_abort_col;\n\tnet_stats->tx_window_errors  = hw_stats->tx_late_col;\n\n\tnet_stats->rx_packets = hw_stats->rx_ok + net_stats->rx_errors;\n\tnet_stats->tx_packets = hw_stats->tx_ok + net_stats->tx_errors;\n\n\treturn net_stats;\n}\n\nstatic void atl1e_update_hw_stats(struct atl1e_adapter *adapter)\n{\n\tu16 hw_reg_addr = 0;\n\tunsigned long *stats_item = NULL;\n\n\t \n\thw_reg_addr = REG_MAC_RX_STATUS_BIN;\n\tstats_item  = &adapter->hw_stats.rx_ok;\n\twhile (hw_reg_addr <= REG_MAC_RX_STATUS_END) {\n\t\t*stats_item += AT_READ_REG(&adapter->hw, hw_reg_addr);\n\t\tstats_item++;\n\t\thw_reg_addr += 4;\n\t}\n\t \n\thw_reg_addr = REG_MAC_TX_STATUS_BIN;\n\tstats_item  = &adapter->hw_stats.tx_ok;\n\twhile (hw_reg_addr <= REG_MAC_TX_STATUS_END) {\n\t\t*stats_item += AT_READ_REG(&adapter->hw, hw_reg_addr);\n\t\tstats_item++;\n\t\thw_reg_addr += 4;\n\t}\n}\n\nstatic inline void atl1e_clear_phy_int(struct atl1e_adapter *adapter)\n{\n\tu16 phy_data;\n\n\tspin_lock(&adapter->mdio_lock);\n\tatl1e_read_phy_reg(&adapter->hw, MII_INT_STATUS, &phy_data);\n\tspin_unlock(&adapter->mdio_lock);\n}\n\nstatic bool atl1e_clean_tx_irq(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\n\tstruct atl1e_tx_buffer *tx_buffer = NULL;\n\tu16 hw_next_to_clean = AT_READ_REGW(&adapter->hw, REG_TPD_CONS_IDX);\n\tu16 next_to_clean = atomic_read(&tx_ring->next_to_clean);\n\n\twhile (next_to_clean != hw_next_to_clean) {\n\t\ttx_buffer = &tx_ring->tx_buffer[next_to_clean];\n\t\tif (tx_buffer->dma) {\n\t\t\tif (tx_buffer->flags & ATL1E_TX_PCIMAP_SINGLE)\n\t\t\t\tdma_unmap_single(&adapter->pdev->dev,\n\t\t\t\t\t\t tx_buffer->dma,\n\t\t\t\t\t\t tx_buffer->length,\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\telse if (tx_buffer->flags & ATL1E_TX_PCIMAP_PAGE)\n\t\t\t\tdma_unmap_page(&adapter->pdev->dev,\n\t\t\t\t\t       tx_buffer->dma,\n\t\t\t\t\t       tx_buffer->length,\n\t\t\t\t\t       DMA_TO_DEVICE);\n\t\t\ttx_buffer->dma = 0;\n\t\t}\n\n\t\tif (tx_buffer->skb) {\n\t\t\tdev_consume_skb_irq(tx_buffer->skb);\n\t\t\ttx_buffer->skb = NULL;\n\t\t}\n\n\t\tif (++next_to_clean == tx_ring->count)\n\t\t\tnext_to_clean = 0;\n\t}\n\n\tatomic_set(&tx_ring->next_to_clean, next_to_clean);\n\n\tif (netif_queue_stopped(adapter->netdev) &&\n\t\t\tnetif_carrier_ok(adapter->netdev)) {\n\t\tnetif_wake_queue(adapter->netdev);\n\t}\n\n\treturn true;\n}\n\n \nstatic irqreturn_t atl1e_intr(int irq, void *data)\n{\n\tstruct net_device *netdev  = data;\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tint max_ints = AT_MAX_INT_WORK;\n\tint handled = IRQ_NONE;\n\tu32 status;\n\n\tdo {\n\t\tstatus = AT_READ_REG(hw, REG_ISR);\n\t\tif ((status & IMR_NORMAL_MASK) == 0 ||\n\t\t\t\t(status & ISR_DIS_INT) != 0) {\n\t\t\tif (max_ints != AT_MAX_INT_WORK)\n\t\t\t\thandled = IRQ_HANDLED;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif (status & ISR_GPHY)\n\t\t\tatl1e_clear_phy_int(adapter);\n\t\t \n\t\tAT_WRITE_REG(hw, REG_ISR, status | ISR_DIS_INT);\n\n\t\thandled = IRQ_HANDLED;\n\t\t \n\t\tif (status & ISR_PHY_LINKDOWN) {\n\t\t\tnetdev_err(adapter->netdev,\n\t\t\t\t   \"pcie phy linkdown %x\\n\", status);\n\t\t\tif (netif_running(adapter->netdev)) {\n\t\t\t\t \n\t\t\t\tatl1e_irq_reset(adapter);\n\t\t\t\tschedule_work(&adapter->reset_task);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (status & (ISR_DMAR_TO_RST | ISR_DMAW_TO_RST)) {\n\t\t\tnetdev_err(adapter->netdev,\n\t\t\t\t   \"PCIE DMA RW error (status = 0x%x)\\n\",\n\t\t\t\t   status);\n\t\t\tatl1e_irq_reset(adapter);\n\t\t\tschedule_work(&adapter->reset_task);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (status & ISR_SMB)\n\t\t\tatl1e_update_hw_stats(adapter);\n\n\t\t \n\t\tif (status & (ISR_GPHY | ISR_MANUAL)) {\n\t\t\tnetdev->stats.tx_carrier_errors++;\n\t\t\tatl1e_link_chg_event(adapter);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (status & ISR_TX_EVENT)\n\t\t\tatl1e_clean_tx_irq(adapter);\n\n\t\tif (status & ISR_RX_EVENT) {\n\t\t\t \n\t\t\tAT_WRITE_REG(hw, REG_IMR,\n\t\t\t\t     IMR_NORMAL_MASK & ~ISR_RX_EVENT);\n\t\t\tAT_WRITE_FLUSH(hw);\n\t\t\tif (likely(napi_schedule_prep(\n\t\t\t\t   &adapter->napi)))\n\t\t\t\t__napi_schedule(&adapter->napi);\n\t\t}\n\t} while (--max_ints > 0);\n\t \n\tAT_WRITE_REG(&adapter->hw, REG_ISR, 0);\n\n\treturn handled;\n}\n\nstatic inline void atl1e_rx_checksum(struct atl1e_adapter *adapter,\n\t\t  struct sk_buff *skb, struct atl1e_recv_ret_status *prrs)\n{\n\tu8 *packet = (u8 *)(prrs + 1);\n\tstruct iphdr *iph;\n\tu16 head_len = ETH_HLEN;\n\tu16 pkt_flags;\n\tu16 err_flags;\n\n\tskb_checksum_none_assert(skb);\n\tpkt_flags = prrs->pkt_flag;\n\terr_flags = prrs->err_flag;\n\tif (((pkt_flags & RRS_IS_IPV4) || (pkt_flags & RRS_IS_IPV6)) &&\n\t\t((pkt_flags & RRS_IS_TCP) || (pkt_flags & RRS_IS_UDP))) {\n\t\tif (pkt_flags & RRS_IS_IPV4) {\n\t\t\tif (pkt_flags & RRS_IS_802_3)\n\t\t\t\thead_len += 8;\n\t\t\tiph = (struct iphdr *) (packet + head_len);\n\t\t\tif (iph->frag_off != 0 && !(pkt_flags & RRS_IS_IP_DF))\n\t\t\t\tgoto hw_xsum;\n\t\t}\n\t\tif (!(err_flags & (RRS_ERR_IP_CSUM | RRS_ERR_L4_CSUM))) {\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\t\treturn;\n\t\t}\n\t}\n\nhw_xsum :\n\treturn;\n}\n\nstatic struct atl1e_rx_page *atl1e_get_rx_page(struct atl1e_adapter *adapter,\n\t\t\t\t\t       u8 que)\n{\n\tstruct atl1e_rx_page_desc *rx_page_desc =\n\t\t(struct atl1e_rx_page_desc *) adapter->rx_ring.rx_page_desc;\n\tu8 rx_using = rx_page_desc[que].rx_using;\n\n\treturn &(rx_page_desc[que].rx_page[rx_using]);\n}\n\nstatic void atl1e_clean_rx_irq(struct atl1e_adapter *adapter, u8 que,\n\t\t   int *work_done, int work_to_do)\n{\n\tstruct net_device *netdev  = adapter->netdev;\n\tstruct atl1e_rx_ring *rx_ring = &adapter->rx_ring;\n\tstruct atl1e_rx_page_desc *rx_page_desc =\n\t\t(struct atl1e_rx_page_desc *) rx_ring->rx_page_desc;\n\tstruct sk_buff *skb = NULL;\n\tstruct atl1e_rx_page *rx_page = atl1e_get_rx_page(adapter, que);\n\tu32 packet_size, write_offset;\n\tstruct atl1e_recv_ret_status *prrs;\n\n\twrite_offset = *(rx_page->write_offset_addr);\n\tif (likely(rx_page->read_offset < write_offset)) {\n\t\tdo {\n\t\t\tif (*work_done >= work_to_do)\n\t\t\t\tbreak;\n\t\t\t(*work_done)++;\n\t\t\t \n\t\t\tprrs = (struct atl1e_recv_ret_status *) (rx_page->addr +\n\t\t\t\t\t\t rx_page->read_offset);\n\t\t\t \n\t\t\tif (prrs->seq_num != rx_page_desc[que].rx_nxseq) {\n\t\t\t\tnetdev_err(netdev,\n\t\t\t\t\t   \"rx sequence number error (rx=%d) (expect=%d)\\n\",\n\t\t\t\t\t   prrs->seq_num,\n\t\t\t\t\t   rx_page_desc[que].rx_nxseq);\n\t\t\t\trx_page_desc[que].rx_nxseq++;\n\t\t\t\t \n\t\t\t\tAT_WRITE_REG(&adapter->hw, REG_DEBUG_DATA0,\n\t\t\t\t\t     (((u32)prrs->seq_num) << 16) |\n\t\t\t\t\t     rx_page_desc[que].rx_nxseq);\n\t\t\t\tgoto fatal_err;\n\t\t\t}\n\t\t\trx_page_desc[que].rx_nxseq++;\n\n\t\t\t \n\t\t\tif ((prrs->pkt_flag & RRS_IS_ERR_FRAME) &&\n\t\t\t    !(netdev->features & NETIF_F_RXALL)) {\n\t\t\t\tif (prrs->err_flag & (RRS_ERR_BAD_CRC |\n\t\t\t\t\tRRS_ERR_DRIBBLE | RRS_ERR_CODE |\n\t\t\t\t\tRRS_ERR_TRUNC)) {\n\t\t\t\t \n\t\t\t\t\tnetdev_err(netdev,\n\t\t\t\t\t\t   \"rx packet desc error %x\\n\",\n\t\t\t\t\t\t   *((u32 *)prrs + 1));\n\t\t\t\t\tgoto skip_pkt;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tpacket_size = ((prrs->word1 >> RRS_PKT_SIZE_SHIFT) &\n\t\t\t\t\tRRS_PKT_SIZE_MASK);\n\t\t\tif (likely(!(netdev->features & NETIF_F_RXFCS)))\n\t\t\t\tpacket_size -= 4;  \n\n\t\t\tskb = netdev_alloc_skb_ip_align(netdev, packet_size);\n\t\t\tif (skb == NULL)\n\t\t\t\tgoto skip_pkt;\n\n\t\t\tmemcpy(skb->data, (u8 *)(prrs + 1), packet_size);\n\t\t\tskb_put(skb, packet_size);\n\t\t\tskb->protocol = eth_type_trans(skb, netdev);\n\t\t\tatl1e_rx_checksum(adapter, skb, prrs);\n\n\t\t\tif (prrs->pkt_flag & RRS_IS_VLAN_TAG) {\n\t\t\t\tu16 vlan_tag = (prrs->vtag >> 4) |\n\t\t\t\t\t       ((prrs->vtag & 7) << 13) |\n\t\t\t\t\t       ((prrs->vtag & 8) << 9);\n\t\t\t\tnetdev_dbg(netdev,\n\t\t\t\t\t   \"RXD VLAN TAG<RRD>=0x%04x\\n\",\n\t\t\t\t\t   prrs->vtag);\n\t\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tag);\n\t\t\t}\n\t\t\tnapi_gro_receive(&adapter->napi, skb);\n\nskip_pkt:\n\t \n\t\t\trx_page->read_offset +=\n\t\t\t\t(((u32)((prrs->word1 >> RRS_PKT_SIZE_SHIFT) &\n\t\t\t\tRRS_PKT_SIZE_MASK) +\n\t\t\t\tsizeof(struct atl1e_recv_ret_status) + 31) &\n\t\t\t\t\t\t0xFFFFFFE0);\n\n\t\t\tif (rx_page->read_offset >= rx_ring->page_size) {\n\t\t\t\t \n\t\t\t\tu16 reg_addr;\n\t\t\t\tu8  rx_using;\n\n\t\t\t\trx_page->read_offset =\n\t\t\t\t\t*(rx_page->write_offset_addr) = 0;\n\t\t\t\trx_using = rx_page_desc[que].rx_using;\n\t\t\t\treg_addr =\n\t\t\t\t\tatl1e_rx_page_vld_regs[que][rx_using];\n\t\t\t\tAT_WRITE_REGB(&adapter->hw, reg_addr, 1);\n\t\t\t\trx_page_desc[que].rx_using ^= 1;\n\t\t\t\trx_page = atl1e_get_rx_page(adapter, que);\n\t\t\t}\n\t\t\twrite_offset = *(rx_page->write_offset_addr);\n\t\t} while (rx_page->read_offset < write_offset);\n\t}\n\n\treturn;\n\nfatal_err:\n\tif (!test_bit(__AT_DOWN, &adapter->flags))\n\t\tschedule_work(&adapter->reset_task);\n}\n\n \nstatic int atl1e_clean(struct napi_struct *napi, int budget)\n{\n\tstruct atl1e_adapter *adapter =\n\t\t\tcontainer_of(napi, struct atl1e_adapter, napi);\n\tu32 imr_data;\n\tint work_done = 0;\n\n\t \n\tif (!netif_carrier_ok(adapter->netdev))\n\t\tgoto quit_polling;\n\n\tatl1e_clean_rx_irq(adapter, 0, &work_done, budget);\n\n\t \n\tif (work_done < budget) {\nquit_polling:\n\t\tnapi_complete_done(napi, work_done);\n\t\timr_data = AT_READ_REG(&adapter->hw, REG_IMR);\n\t\tAT_WRITE_REG(&adapter->hw, REG_IMR, imr_data | ISR_RX_EVENT);\n\t\t \n\t\tif (test_bit(__AT_DOWN, &adapter->flags)) {\n\t\t\tatomic_dec(&adapter->irq_sem);\n\t\t\tnetdev_err(adapter->netdev,\n\t\t\t\t   \"atl1e_clean is called when AT_DOWN\\n\");\n\t\t}\n\t\t \n\t\t \n\n\t}\n\treturn work_done;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\n \nstatic void atl1e_netpoll(struct net_device *netdev)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\tdisable_irq(adapter->pdev->irq);\n\tatl1e_intr(adapter->pdev->irq, netdev);\n\tenable_irq(adapter->pdev->irq);\n}\n#endif\n\nstatic inline u16 atl1e_tpd_avail(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\n\tu16 next_to_use = 0;\n\tu16 next_to_clean = 0;\n\n\tnext_to_clean = atomic_read(&tx_ring->next_to_clean);\n\tnext_to_use   = tx_ring->next_to_use;\n\n\treturn (u16)(next_to_clean > next_to_use) ?\n\t\t(next_to_clean - next_to_use - 1) :\n\t\t(tx_ring->count + next_to_clean - next_to_use - 1);\n}\n\n \nstatic struct atl1e_tpd_desc *atl1e_get_tpd(struct atl1e_adapter *adapter)\n{\n\tstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\n\tu16 next_to_use = 0;\n\n\tnext_to_use = tx_ring->next_to_use;\n\tif (++tx_ring->next_to_use == tx_ring->count)\n\t\ttx_ring->next_to_use = 0;\n\n\tmemset(&tx_ring->desc[next_to_use], 0, sizeof(struct atl1e_tpd_desc));\n\treturn &tx_ring->desc[next_to_use];\n}\n\nstatic struct atl1e_tx_buffer *\natl1e_get_tx_buffer(struct atl1e_adapter *adapter, struct atl1e_tpd_desc *tpd)\n{\n\tstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\n\n\treturn &tx_ring->tx_buffer[tpd - tx_ring->desc];\n}\n\n \nstatic u16 atl1e_cal_tdp_req(const struct sk_buff *skb)\n{\n\tint i = 0;\n\tu16 tpd_req = 1;\n\tu16 fg_size = 0;\n\tu16 proto_hdr_len = 0;\n\n\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\tfg_size = skb_frag_size(&skb_shinfo(skb)->frags[i]);\n\t\ttpd_req += ((fg_size + MAX_TX_BUF_LEN - 1) >> MAX_TX_BUF_SHIFT);\n\t}\n\n\tif (skb_is_gso(skb)) {\n\t\tif (skb->protocol == htons(ETH_P_IP) ||\n\t\t   (skb_shinfo(skb)->gso_type == SKB_GSO_TCPV6)) {\n\t\t\tproto_hdr_len = skb_tcp_all_headers(skb);\n\t\t\tif (proto_hdr_len < skb_headlen(skb)) {\n\t\t\t\ttpd_req += ((skb_headlen(skb) - proto_hdr_len +\n\t\t\t\t\t   MAX_TX_BUF_LEN - 1) >>\n\t\t\t\t\t   MAX_TX_BUF_SHIFT);\n\t\t\t}\n\t\t}\n\n\t}\n\treturn tpd_req;\n}\n\nstatic int atl1e_tso_csum(struct atl1e_adapter *adapter,\n\t\t       struct sk_buff *skb, struct atl1e_tpd_desc *tpd)\n{\n\tunsigned short offload_type;\n\tu8 hdr_len;\n\tu32 real_len;\n\n\tif (skb_is_gso(skb)) {\n\t\tint err;\n\n\t\terr = skb_cow_head(skb, 0);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\toffload_type = skb_shinfo(skb)->gso_type;\n\n\t\tif (offload_type & SKB_GSO_TCPV4) {\n\t\t\treal_len = (((unsigned char *)ip_hdr(skb) - skb->data)\n\t\t\t\t\t+ ntohs(ip_hdr(skb)->tot_len));\n\n\t\t\tif (real_len < skb->len) {\n\t\t\t\terr = pskb_trim(skb, real_len);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t}\n\n\t\t\thdr_len = skb_tcp_all_headers(skb);\n\t\t\tif (unlikely(skb->len == hdr_len)) {\n\t\t\t\t \n\t\t\t\tnetdev_warn(adapter->netdev,\n\t\t\t\t\t    \"IPV4 tso with zero data??\\n\");\n\t\t\t\tgoto check_sum;\n\t\t\t} else {\n\t\t\t\tip_hdr(skb)->check = 0;\n\t\t\t\tip_hdr(skb)->tot_len = 0;\n\t\t\t\ttcp_hdr(skb)->check = ~csum_tcpudp_magic(\n\t\t\t\t\t\t\tip_hdr(skb)->saddr,\n\t\t\t\t\t\t\tip_hdr(skb)->daddr,\n\t\t\t\t\t\t\t0, IPPROTO_TCP, 0);\n\t\t\t\ttpd->word3 |= (ip_hdr(skb)->ihl &\n\t\t\t\t\tTDP_V4_IPHL_MASK) <<\n\t\t\t\t\tTPD_V4_IPHL_SHIFT;\n\t\t\t\ttpd->word3 |= ((tcp_hdrlen(skb) >> 2) &\n\t\t\t\t\tTPD_TCPHDRLEN_MASK) <<\n\t\t\t\t\tTPD_TCPHDRLEN_SHIFT;\n\t\t\t\ttpd->word3 |= ((skb_shinfo(skb)->gso_size) &\n\t\t\t\t\tTPD_MSS_MASK) << TPD_MSS_SHIFT;\n\t\t\t\ttpd->word3 |= 1 << TPD_SEGMENT_EN_SHIFT;\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t}\n\ncheck_sum:\n\tif (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {\n\t\tu8 css, cso;\n\n\t\tcso = skb_checksum_start_offset(skb);\n\t\tif (unlikely(cso & 0x1)) {\n\t\t\tnetdev_err(adapter->netdev,\n\t\t\t\t   \"payload offset should not ant event number\\n\");\n\t\t\treturn -1;\n\t\t} else {\n\t\t\tcss = cso + skb->csum_offset;\n\t\t\ttpd->word3 |= (cso & TPD_PLOADOFFSET_MASK) <<\n\t\t\t\t\tTPD_PLOADOFFSET_SHIFT;\n\t\t\ttpd->word3 |= (css & TPD_CCSUMOFFSET_MASK) <<\n\t\t\t\t\tTPD_CCSUMOFFSET_SHIFT;\n\t\t\ttpd->word3 |= 1 << TPD_CC_SEGMENT_EN_SHIFT;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int atl1e_tx_map(struct atl1e_adapter *adapter,\n\t\t\tstruct sk_buff *skb, struct atl1e_tpd_desc *tpd)\n{\n\tstruct atl1e_tpd_desc *use_tpd = NULL;\n\tstruct atl1e_tx_buffer *tx_buffer = NULL;\n\tu16 buf_len = skb_headlen(skb);\n\tu16 map_len = 0;\n\tu16 mapped_len = 0;\n\tu16 hdr_len = 0;\n\tu16 nr_frags;\n\tu16 f;\n\tint segment;\n\tint ring_start = adapter->tx_ring.next_to_use;\n\tint ring_end;\n\n\tnr_frags = skb_shinfo(skb)->nr_frags;\n\tsegment = (tpd->word3 >> TPD_SEGMENT_EN_SHIFT) & TPD_SEGMENT_EN_MASK;\n\tif (segment) {\n\t\t \n\t\thdr_len = skb_tcp_all_headers(skb);\n\t\tmap_len = hdr_len;\n\t\tuse_tpd = tpd;\n\n\t\ttx_buffer = atl1e_get_tx_buffer(adapter, use_tpd);\n\t\ttx_buffer->length = map_len;\n\t\ttx_buffer->dma = dma_map_single(&adapter->pdev->dev,\n\t\t\t\t\t\tskb->data, hdr_len,\n\t\t\t\t\t\tDMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&adapter->pdev->dev, tx_buffer->dma))\n\t\t\treturn -ENOSPC;\n\n\t\tATL1E_SET_PCIMAP_TYPE(tx_buffer, ATL1E_TX_PCIMAP_SINGLE);\n\t\tmapped_len += map_len;\n\t\tuse_tpd->buffer_addr = cpu_to_le64(tx_buffer->dma);\n\t\tuse_tpd->word2 = (use_tpd->word2 & (~TPD_BUFLEN_MASK)) |\n\t\t\t((cpu_to_le32(tx_buffer->length) &\n\t\t\tTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT);\n\t}\n\n\twhile (mapped_len < buf_len) {\n\t\t \n\t\tif (mapped_len == 0) {\n\t\t\tuse_tpd = tpd;\n\t\t} else {\n\t\t\tuse_tpd = atl1e_get_tpd(adapter);\n\t\t\tmemcpy(use_tpd, tpd, sizeof(struct atl1e_tpd_desc));\n\t\t}\n\t\ttx_buffer = atl1e_get_tx_buffer(adapter, use_tpd);\n\t\ttx_buffer->skb = NULL;\n\n\t\ttx_buffer->length = map_len =\n\t\t\t((buf_len - mapped_len) >= MAX_TX_BUF_LEN) ?\n\t\t\tMAX_TX_BUF_LEN : (buf_len - mapped_len);\n\t\ttx_buffer->dma =\n\t\t\tdma_map_single(&adapter->pdev->dev,\n\t\t\t\t       skb->data + mapped_len, map_len,\n\t\t\t\t       DMA_TO_DEVICE);\n\n\t\tif (dma_mapping_error(&adapter->pdev->dev, tx_buffer->dma)) {\n\t\t\t \n\t\t\tring_end = adapter->tx_ring.next_to_use;\n\t\t\tadapter->tx_ring.next_to_use = ring_start;\n\t\t\twhile (adapter->tx_ring.next_to_use != ring_end) {\n\t\t\t\ttpd = atl1e_get_tpd(adapter);\n\t\t\t\ttx_buffer = atl1e_get_tx_buffer(adapter, tpd);\n\t\t\t\tdma_unmap_single(&adapter->pdev->dev,\n\t\t\t\t\t\t tx_buffer->dma,\n\t\t\t\t\t\t tx_buffer->length,\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\t}\n\t\t\t \n\t\t\tadapter->tx_ring.next_to_use = ring_start;\n\t\t\treturn -ENOSPC;\n\t\t}\n\n\t\tATL1E_SET_PCIMAP_TYPE(tx_buffer, ATL1E_TX_PCIMAP_SINGLE);\n\t\tmapped_len  += map_len;\n\t\tuse_tpd->buffer_addr = cpu_to_le64(tx_buffer->dma);\n\t\tuse_tpd->word2 = (use_tpd->word2 & (~TPD_BUFLEN_MASK)) |\n\t\t\t((cpu_to_le32(tx_buffer->length) &\n\t\t\tTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT);\n\t}\n\n\tfor (f = 0; f < nr_frags; f++) {\n\t\tconst skb_frag_t *frag = &skb_shinfo(skb)->frags[f];\n\t\tu16 i;\n\t\tu16 seg_num;\n\n\t\tbuf_len = skb_frag_size(frag);\n\n\t\tseg_num = (buf_len + MAX_TX_BUF_LEN - 1) / MAX_TX_BUF_LEN;\n\t\tfor (i = 0; i < seg_num; i++) {\n\t\t\tuse_tpd = atl1e_get_tpd(adapter);\n\t\t\tmemcpy(use_tpd, tpd, sizeof(struct atl1e_tpd_desc));\n\n\t\t\ttx_buffer = atl1e_get_tx_buffer(adapter, use_tpd);\n\t\t\tBUG_ON(tx_buffer->skb);\n\n\t\t\ttx_buffer->skb = NULL;\n\t\t\ttx_buffer->length =\n\t\t\t\t(buf_len > MAX_TX_BUF_LEN) ?\n\t\t\t\tMAX_TX_BUF_LEN : buf_len;\n\t\t\tbuf_len -= tx_buffer->length;\n\n\t\t\ttx_buffer->dma = skb_frag_dma_map(&adapter->pdev->dev,\n\t\t\t\t\t\t\t  frag,\n\t\t\t\t\t\t\t  (i * MAX_TX_BUF_LEN),\n\t\t\t\t\t\t\t  tx_buffer->length,\n\t\t\t\t\t\t\t  DMA_TO_DEVICE);\n\n\t\t\tif (dma_mapping_error(&adapter->pdev->dev, tx_buffer->dma)) {\n\t\t\t\t \n\t\t\t\tring_end = adapter->tx_ring.next_to_use;\n\t\t\t\tadapter->tx_ring.next_to_use = ring_start;\n\t\t\t\twhile (adapter->tx_ring.next_to_use != ring_end) {\n\t\t\t\t\ttpd = atl1e_get_tpd(adapter);\n\t\t\t\t\ttx_buffer = atl1e_get_tx_buffer(adapter, tpd);\n\t\t\t\t\tdma_unmap_page(&adapter->pdev->dev, tx_buffer->dma,\n\t\t\t\t\t\t       tx_buffer->length, DMA_TO_DEVICE);\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tadapter->tx_ring.next_to_use = ring_start;\n\t\t\t\treturn -ENOSPC;\n\t\t\t}\n\n\t\t\tATL1E_SET_PCIMAP_TYPE(tx_buffer, ATL1E_TX_PCIMAP_PAGE);\n\t\t\tuse_tpd->buffer_addr = cpu_to_le64(tx_buffer->dma);\n\t\t\tuse_tpd->word2 = (use_tpd->word2 & (~TPD_BUFLEN_MASK)) |\n\t\t\t\t\t((cpu_to_le32(tx_buffer->length) &\n\t\t\t\t\tTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT);\n\t\t}\n\t}\n\n\tif ((tpd->word3 >> TPD_SEGMENT_EN_SHIFT) & TPD_SEGMENT_EN_MASK)\n\t\t \n\t\ttpd->word3 |= 1 << TPD_HDRFLAG_SHIFT;\n\t \n\n\tuse_tpd->word3 |= 1 << TPD_EOP_SHIFT;\n\t \n\ttx_buffer->skb = skb;\n\treturn 0;\n}\n\nstatic void atl1e_tx_queue(struct atl1e_adapter *adapter, u16 count,\n\t\t\t   struct atl1e_tpd_desc *tpd)\n{\n\tstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\n\t \n\twmb();\n\tAT_WRITE_REG(&adapter->hw, REG_MB_TPD_PROD_IDX, tx_ring->next_to_use);\n}\n\nstatic netdev_tx_t atl1e_xmit_frame(struct sk_buff *skb,\n\t\t\t\t\t  struct net_device *netdev)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tu16 tpd_req = 1;\n\tstruct atl1e_tpd_desc *tpd;\n\n\tif (test_bit(__AT_DOWN, &adapter->flags)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tif (unlikely(skb->len <= 0)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\ttpd_req = atl1e_cal_tdp_req(skb);\n\n\tif (atl1e_tpd_avail(adapter) < tpd_req) {\n\t\t \n\t\tnetif_stop_queue(netdev);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\ttpd = atl1e_get_tpd(adapter);\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\tu16 vlan_tag = skb_vlan_tag_get(skb);\n\t\tu16 atl1e_vlan_tag;\n\n\t\ttpd->word3 |= 1 << TPD_INS_VL_TAG_SHIFT;\n\t\tAT_VLAN_TAG_TO_TPD_TAG(vlan_tag, atl1e_vlan_tag);\n\t\ttpd->word2 |= (atl1e_vlan_tag & TPD_VLANTAG_MASK) <<\n\t\t\t\tTPD_VLAN_SHIFT;\n\t}\n\n\tif (skb->protocol == htons(ETH_P_8021Q))\n\t\ttpd->word3 |= 1 << TPD_VL_TAGGED_SHIFT;\n\n\tif (skb_network_offset(skb) != ETH_HLEN)\n\t\ttpd->word3 |= 1 << TPD_ETHTYPE_SHIFT;  \n\n\t \n\tif (atl1e_tso_csum(adapter, skb, tpd) != 0) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tif (atl1e_tx_map(adapter, skb, tpd)) {\n\t\tdev_kfree_skb_any(skb);\n\t\tgoto out;\n\t}\n\n\tatl1e_tx_queue(adapter, tpd_req, tpd);\nout:\n\treturn NETDEV_TX_OK;\n}\n\nstatic void atl1e_free_irq(struct atl1e_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tfree_irq(adapter->pdev->irq, netdev);\n}\n\nstatic int atl1e_request_irq(struct atl1e_adapter *adapter)\n{\n\tstruct pci_dev    *pdev   = adapter->pdev;\n\tstruct net_device *netdev = adapter->netdev;\n\tint err = 0;\n\n\terr = request_irq(pdev->irq, atl1e_intr, IRQF_SHARED, netdev->name,\n\t\t\t  netdev);\n\tif (err) {\n\t\tnetdev_dbg(adapter->netdev,\n\t\t\t   \"Unable to allocate interrupt Error: %d\\n\", err);\n\t\treturn err;\n\t}\n\tnetdev_dbg(netdev, \"atl1e_request_irq OK\\n\");\n\treturn err;\n}\n\nint atl1e_up(struct atl1e_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint err = 0;\n\tu32 val;\n\n\t \n\terr = atl1e_init_hw(&adapter->hw);\n\tif (err) {\n\t\terr = -EIO;\n\t\treturn err;\n\t}\n\tatl1e_init_ring_ptrs(adapter);\n\tatl1e_set_multi(netdev);\n\tatl1e_restore_vlan(adapter);\n\n\tif (atl1e_configure(adapter)) {\n\t\terr = -EIO;\n\t\tgoto err_up;\n\t}\n\n\tclear_bit(__AT_DOWN, &adapter->flags);\n\tnapi_enable(&adapter->napi);\n\tatl1e_irq_enable(adapter);\n\tval = AT_READ_REG(&adapter->hw, REG_MASTER_CTRL);\n\tAT_WRITE_REG(&adapter->hw, REG_MASTER_CTRL,\n\t\t      val | MASTER_CTRL_MANUAL_INT);\n\nerr_up:\n\treturn err;\n}\n\nvoid atl1e_down(struct atl1e_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\t \n\tset_bit(__AT_DOWN, &adapter->flags);\n\n\tnetif_stop_queue(netdev);\n\n\t \n\tatl1e_reset_hw(&adapter->hw);\n\tmsleep(1);\n\n\tnapi_disable(&adapter->napi);\n\tatl1e_del_timer(adapter);\n\tatl1e_irq_disable(adapter);\n\n\tnetif_carrier_off(netdev);\n\tadapter->link_speed = SPEED_0;\n\tadapter->link_duplex = -1;\n\tatl1e_clean_tx_ring(adapter);\n\tatl1e_clean_rx_ring(adapter);\n}\n\n \nstatic int atl1e_open(struct net_device *netdev)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tint err;\n\n\t \n\tif (test_bit(__AT_TESTING, &adapter->flags))\n\t\treturn -EBUSY;\n\n\t \n\tatl1e_init_ring_resources(adapter);\n\terr = atl1e_setup_ring_resources(adapter);\n\tif (unlikely(err))\n\t\treturn err;\n\n\terr = atl1e_request_irq(adapter);\n\tif (unlikely(err))\n\t\tgoto err_req_irq;\n\n\terr = atl1e_up(adapter);\n\tif (unlikely(err))\n\t\tgoto err_up;\n\n\treturn 0;\n\nerr_up:\n\tatl1e_free_irq(adapter);\nerr_req_irq:\n\tatl1e_free_ring_resources(adapter);\n\tatl1e_reset_hw(&adapter->hw);\n\n\treturn err;\n}\n\n \nstatic int atl1e_close(struct net_device *netdev)\n{\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\tWARN_ON(test_bit(__AT_RESETTING, &adapter->flags));\n\tatl1e_down(adapter);\n\tatl1e_free_irq(adapter);\n\tatl1e_free_ring_resources(adapter);\n\n\treturn 0;\n}\n\nstatic int atl1e_suspend(struct pci_dev *pdev, pm_message_t state)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tstruct atl1e_hw *hw = &adapter->hw;\n\tu32 ctrl = 0;\n\tu32 mac_ctrl_data = 0;\n\tu32 wol_ctrl_data = 0;\n\tu16 mii_advertise_data = 0;\n\tu16 mii_bmsr_data = 0;\n\tu16 mii_intr_status_data = 0;\n\tu32 wufc = adapter->wol;\n\tu32 i;\n#ifdef CONFIG_PM\n\tint retval = 0;\n#endif\n\n\tif (netif_running(netdev)) {\n\t\tWARN_ON(test_bit(__AT_RESETTING, &adapter->flags));\n\t\tatl1e_down(adapter);\n\t}\n\tnetif_device_detach(netdev);\n\n#ifdef CONFIG_PM\n\tretval = pci_save_state(pdev);\n\tif (retval)\n\t\treturn retval;\n#endif\n\n\tif (wufc) {\n\t\t \n\t\tatl1e_read_phy_reg(hw, MII_BMSR, &mii_bmsr_data);\n\t\tatl1e_read_phy_reg(hw, MII_BMSR, &mii_bmsr_data);\n\n\t\tmii_advertise_data = ADVERTISE_10HALF;\n\n\t\tif ((atl1e_write_phy_reg(hw, MII_CTRL1000, 0) != 0) ||\n\t\t    (atl1e_write_phy_reg(hw,\n\t\t\t   MII_ADVERTISE, mii_advertise_data) != 0) ||\n\t\t    (atl1e_phy_commit(hw)) != 0) {\n\t\t\tnetdev_dbg(adapter->netdev, \"set phy register failed\\n\");\n\t\t\tgoto wol_dis;\n\t\t}\n\n\t\thw->phy_configured = false;  \n\n\t\t \n\t\tif (wufc & AT_WUFC_MAG)\n\t\t\twol_ctrl_data |= WOL_MAGIC_EN | WOL_MAGIC_PME_EN;\n\n\t\tif (wufc & AT_WUFC_LNKC) {\n\t\t \n\t\t\tif (mii_bmsr_data & BMSR_LSTATUS) {\n\t\t\t\tfor (i = 0; i < AT_SUSPEND_LINK_TIMEOUT; i++) {\n\t\t\t\t\tmsleep(100);\n\t\t\t\t\tatl1e_read_phy_reg(hw, MII_BMSR,\n\t\t\t\t\t\t\t&mii_bmsr_data);\n\t\t\t\t\tif (mii_bmsr_data & BMSR_LSTATUS)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif ((mii_bmsr_data & BMSR_LSTATUS) == 0)\n\t\t\t\t\tnetdev_dbg(adapter->netdev,\n\t\t\t\t\t\t   \"Link may change when suspend\\n\");\n\t\t\t}\n\t\t\twol_ctrl_data |=  WOL_LINK_CHG_EN | WOL_LINK_CHG_PME_EN;\n\t\t\t \n\t\t\tif (atl1e_write_phy_reg(hw, MII_INT_CTRL, 0x400) != 0) {\n\t\t\t\tnetdev_dbg(adapter->netdev,\n\t\t\t\t\t   \"read write phy register failed\\n\");\n\t\t\t\tgoto wol_dis;\n\t\t\t}\n\t\t}\n\t\t \n\t\tatl1e_read_phy_reg(hw, MII_INT_STATUS, &mii_intr_status_data);\n\t\t \n\t\tmac_ctrl_data = MAC_CTRL_RX_EN;\n\t\t \n\t\tmac_ctrl_data |= MAC_CTRL_SPEED_10_100 << MAC_CTRL_SPEED_SHIFT;\n\t\tmac_ctrl_data |= (((u32)adapter->hw.preamble_len &\n\t\t\t\t MAC_CTRL_PRMLEN_MASK) <<\n\t\t\t\t MAC_CTRL_PRMLEN_SHIFT);\n\n\t\t__atl1e_vlan_mode(netdev->features, &mac_ctrl_data);\n\n\t\t \n\t\tif (wufc & AT_WUFC_MAG)\n\t\t\tmac_ctrl_data |= MAC_CTRL_BC_EN;\n\n\t\tnetdev_dbg(adapter->netdev, \"suspend MAC=0x%x\\n\",\n\t\t\t   mac_ctrl_data);\n\n\t\tAT_WRITE_REG(hw, REG_WOL_CTRL, wol_ctrl_data);\n\t\tAT_WRITE_REG(hw, REG_MAC_CTRL, mac_ctrl_data);\n\t\t \n\t\tctrl = AT_READ_REG(hw, REG_PCIE_PHYMISC);\n\t\tctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\n\t\tAT_WRITE_REG(hw, REG_PCIE_PHYMISC, ctrl);\n\t\tpci_enable_wake(pdev, pci_choose_state(pdev, state), 1);\n\t\tgoto suspend_exit;\n\t}\nwol_dis:\n\n\t \n\tAT_WRITE_REG(hw, REG_WOL_CTRL, 0);\n\n\t \n\tctrl = AT_READ_REG(hw, REG_PCIE_PHYMISC);\n\tctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\n\tAT_WRITE_REG(hw, REG_PCIE_PHYMISC, ctrl);\n\n\tatl1e_force_ps(hw);\n\thw->phy_configured = false;  \n\n\tpci_enable_wake(pdev, pci_choose_state(pdev, state), 0);\n\nsuspend_exit:\n\n\tif (netif_running(netdev))\n\t\tatl1e_free_irq(adapter);\n\n\tpci_disable_device(pdev);\n\n\tpci_set_power_state(pdev, pci_choose_state(pdev, state));\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM\nstatic int atl1e_resume(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\tu32 err;\n\n\tpci_set_power_state(pdev, PCI_D0);\n\tpci_restore_state(pdev);\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tnetdev_err(adapter->netdev,\n\t\t\t   \"Cannot enable PCI device from suspend\\n\");\n\t\treturn err;\n\t}\n\n\tpci_set_master(pdev);\n\n\tAT_READ_REG(&adapter->hw, REG_WOL_CTRL);  \n\n\tpci_enable_wake(pdev, PCI_D3hot, 0);\n\tpci_enable_wake(pdev, PCI_D3cold, 0);\n\n\tAT_WRITE_REG(&adapter->hw, REG_WOL_CTRL, 0);\n\n\tif (netif_running(netdev)) {\n\t\terr = atl1e_request_irq(adapter);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tatl1e_reset_hw(&adapter->hw);\n\n\tif (netif_running(netdev))\n\t\tatl1e_up(adapter);\n\n\tnetif_device_attach(netdev);\n\n\treturn 0;\n}\n#endif\n\nstatic void atl1e_shutdown(struct pci_dev *pdev)\n{\n\tatl1e_suspend(pdev, PMSG_SUSPEND);\n}\n\nstatic const struct net_device_ops atl1e_netdev_ops = {\n\t.ndo_open\t\t= atl1e_open,\n\t.ndo_stop\t\t= atl1e_close,\n\t.ndo_start_xmit\t\t= atl1e_xmit_frame,\n\t.ndo_get_stats\t\t= atl1e_get_stats,\n\t.ndo_set_rx_mode\t= atl1e_set_multi,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= atl1e_set_mac_addr,\n\t.ndo_fix_features\t= atl1e_fix_features,\n\t.ndo_set_features\t= atl1e_set_features,\n\t.ndo_change_mtu\t\t= atl1e_change_mtu,\n\t.ndo_eth_ioctl\t\t= atl1e_ioctl,\n\t.ndo_tx_timeout\t\t= atl1e_tx_timeout,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= atl1e_netpoll,\n#endif\n\n};\n\nstatic int atl1e_init_netdev(struct net_device *netdev, struct pci_dev *pdev)\n{\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\tpci_set_drvdata(pdev, netdev);\n\n\tnetdev->netdev_ops = &atl1e_netdev_ops;\n\n\tnetdev->watchdog_timeo = AT_TX_WATCHDOG;\n\t \n\tnetdev->min_mtu = ETH_ZLEN - (ETH_HLEN + VLAN_HLEN);\n\tnetdev->max_mtu = MAX_JUMBO_FRAME_SIZE -\n\t\t\t  (ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN);\n\tatl1e_set_ethtool_ops(netdev);\n\n\tnetdev->hw_features = NETIF_F_SG | NETIF_F_HW_CSUM | NETIF_F_TSO |\n\t\t\t      NETIF_F_HW_VLAN_CTAG_RX;\n\tnetdev->features = netdev->hw_features | NETIF_F_HW_VLAN_CTAG_TX;\n\t \n\tnetdev->hw_features |= NETIF_F_RXALL | NETIF_F_RXFCS;\n\treturn 0;\n}\n\n \nstatic int atl1e_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct net_device *netdev;\n\tstruct atl1e_adapter *adapter = NULL;\n\tstatic int cards_found;\n\n\tint err = 0;\n\n\terr = pci_enable_device(pdev);\n\tif (err)\n\t\treturn dev_err_probe(&pdev->dev, err, \"cannot enable PCI device\\n\");\n\n\t \n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"No usable DMA configuration,aborting\\n\");\n\t\tgoto err_dma;\n\t}\n\n\terr = pci_request_regions(pdev, atl1e_driver_name);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"cannot obtain PCI resources\\n\");\n\t\tgoto err_pci_reg;\n\t}\n\n\tpci_set_master(pdev);\n\n\tnetdev = alloc_etherdev(sizeof(struct atl1e_adapter));\n\tif (netdev == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto err_alloc_etherdev;\n\t}\n\n\terr = atl1e_init_netdev(netdev, pdev);\n\tif (err) {\n\t\tnetdev_err(netdev, \"init netdevice failed\\n\");\n\t\tgoto err_init_netdev;\n\t}\n\tadapter = netdev_priv(netdev);\n\tadapter->bd_number = cards_found;\n\tadapter->netdev = netdev;\n\tadapter->pdev = pdev;\n\tadapter->hw.adapter = adapter;\n\tadapter->hw.hw_addr = pci_iomap(pdev, BAR_0, 0);\n\tif (!adapter->hw.hw_addr) {\n\t\terr = -EIO;\n\t\tnetdev_err(netdev, \"cannot map device registers\\n\");\n\t\tgoto err_ioremap;\n\t}\n\n\t \n\tadapter->mii.dev = netdev;\n\tadapter->mii.mdio_read  = atl1e_mdio_read;\n\tadapter->mii.mdio_write = atl1e_mdio_write;\n\tadapter->mii.phy_id_mask = 0x1f;\n\tadapter->mii.reg_num_mask = MDIO_REG_ADDR_MASK;\n\n\tnetif_napi_add(netdev, &adapter->napi, atl1e_clean);\n\n\ttimer_setup(&adapter->phy_config_timer, atl1e_phy_config, 0);\n\n\t \n\tatl1e_check_options(adapter);\n\t \n\tatl1e_setup_pcicmd(pdev);\n\t \n\terr = atl1e_sw_init(adapter);\n\tif (err) {\n\t\tnetdev_err(netdev, \"net device private data init failed\\n\");\n\t\tgoto err_sw_init;\n\t}\n\n\t \n\tatl1e_phy_init(&adapter->hw);\n\t \n\terr = atl1e_reset_hw(&adapter->hw);\n\tif (err) {\n\t\terr = -EIO;\n\t\tgoto err_reset;\n\t}\n\n\tif (atl1e_read_mac_addr(&adapter->hw) != 0) {\n\t\terr = -EIO;\n\t\tnetdev_err(netdev, \"get mac address failed\\n\");\n\t\tgoto err_eeprom;\n\t}\n\n\teth_hw_addr_set(netdev, adapter->hw.mac_addr);\n\tnetdev_dbg(netdev, \"mac address : %pM\\n\", adapter->hw.mac_addr);\n\n\tINIT_WORK(&adapter->reset_task, atl1e_reset_task);\n\tINIT_WORK(&adapter->link_chg_task, atl1e_link_chg_task);\n\tnetif_set_tso_max_size(netdev, MAX_TSO_SEG_SIZE);\n\terr = register_netdev(netdev);\n\tif (err) {\n\t\tnetdev_err(netdev, \"register netdevice failed\\n\");\n\t\tgoto err_register;\n\t}\n\n\t \n\tnetif_stop_queue(netdev);\n\tnetif_carrier_off(netdev);\n\n\tcards_found++;\n\n\treturn 0;\n\nerr_reset:\nerr_register:\nerr_sw_init:\nerr_eeprom:\n\tpci_iounmap(pdev, adapter->hw.hw_addr);\nerr_init_netdev:\nerr_ioremap:\n\tfree_netdev(netdev);\nerr_alloc_etherdev:\n\tpci_release_regions(pdev);\nerr_pci_reg:\nerr_dma:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n \nstatic void atl1e_remove(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tset_bit(__AT_DOWN, &adapter->flags);\n\n\tatl1e_del_timer(adapter);\n\tatl1e_cancel_work(adapter);\n\n\tunregister_netdev(netdev);\n\tatl1e_free_ring_resources(adapter);\n\tatl1e_force_ps(&adapter->hw);\n\tpci_iounmap(pdev, adapter->hw.hw_addr);\n\tpci_release_regions(pdev);\n\tfree_netdev(netdev);\n\tpci_disable_device(pdev);\n}\n\n \nstatic pci_ers_result_t\natl1e_io_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\tnetif_device_detach(netdev);\n\n\tif (state == pci_channel_io_perm_failure)\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\n\tif (netif_running(netdev))\n\t\tatl1e_down(adapter);\n\n\tpci_disable_device(pdev);\n\n\t \n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\n \nstatic pci_ers_result_t atl1e_io_slot_reset(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\tif (pci_enable_device(pdev)) {\n\t\tnetdev_err(adapter->netdev,\n\t\t\t   \"Cannot re-enable PCI device after reset\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\tpci_set_master(pdev);\n\n\tpci_enable_wake(pdev, PCI_D3hot, 0);\n\tpci_enable_wake(pdev, PCI_D3cold, 0);\n\n\tatl1e_reset_hw(&adapter->hw);\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n \nstatic void atl1e_io_resume(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct atl1e_adapter *adapter = netdev_priv(netdev);\n\n\tif (netif_running(netdev)) {\n\t\tif (atl1e_up(adapter)) {\n\t\t\tnetdev_err(adapter->netdev,\n\t\t\t\t   \"can't bring device back up after reset\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\tnetif_device_attach(netdev);\n}\n\nstatic const struct pci_error_handlers atl1e_err_handler = {\n\t.error_detected = atl1e_io_error_detected,\n\t.slot_reset = atl1e_io_slot_reset,\n\t.resume = atl1e_io_resume,\n};\n\nstatic struct pci_driver atl1e_driver = {\n\t.name     = atl1e_driver_name,\n\t.id_table = atl1e_pci_tbl,\n\t.probe    = atl1e_probe,\n\t.remove   = atl1e_remove,\n\t \n#ifdef CONFIG_PM\n\t.suspend  = atl1e_suspend,\n\t.resume   = atl1e_resume,\n#endif\n\t.shutdown = atl1e_shutdown,\n\t.err_handler = &atl1e_err_handler\n};\n\nmodule_pci_driver(atl1e_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}