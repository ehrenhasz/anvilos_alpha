{
  "module_name": "nfp_net_xsk.c",
  "hash_id": "b887ba128c6e1075282e9dece7f8d47de2a57229d9238e89908be7500d77a8c5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/netronome/nfp/nfp_net_xsk.c",
  "human_readable_source": "\n \n \n\n#include <linux/dma-direction.h>\n#include <linux/dma-mapping.h>\n#include <linux/slab.h>\n#include <net/xdp_sock_drv.h>\n#include <trace/events/xdp.h>\n\n#include \"nfp_app.h\"\n#include \"nfp_net.h\"\n#include \"nfp_net_dp.h\"\n#include \"nfp_net_xsk.h\"\n\nstatic void\nnfp_net_xsk_rx_bufs_stash(struct nfp_net_rx_ring *rx_ring, unsigned int idx,\n\t\t\t  struct xdp_buff *xdp)\n{\n\tunsigned int headroom;\n\n\theadroom = xsk_pool_get_headroom(rx_ring->r_vec->xsk_pool);\n\n\trx_ring->rxds[idx].fld.reserved = 0;\n\trx_ring->rxds[idx].fld.meta_len_dd = 0;\n\n\trx_ring->xsk_rxbufs[idx].xdp = xdp;\n\trx_ring->xsk_rxbufs[idx].dma_addr =\n\t\txsk_buff_xdp_get_frame_dma(xdp) + headroom;\n}\n\nvoid nfp_net_xsk_rx_unstash(struct nfp_net_xsk_rx_buf *rxbuf)\n{\n\trxbuf->dma_addr = 0;\n\trxbuf->xdp = NULL;\n}\n\nvoid nfp_net_xsk_rx_free(struct nfp_net_xsk_rx_buf *rxbuf)\n{\n\tif (rxbuf->xdp)\n\t\txsk_buff_free(rxbuf->xdp);\n\n\tnfp_net_xsk_rx_unstash(rxbuf);\n}\n\nvoid nfp_net_xsk_rx_bufs_free(struct nfp_net_rx_ring *rx_ring)\n{\n\tunsigned int i;\n\n\tif (!rx_ring->cnt)\n\t\treturn;\n\n\tfor (i = 0; i < rx_ring->cnt - 1; i++)\n\t\tnfp_net_xsk_rx_free(&rx_ring->xsk_rxbufs[i]);\n}\n\nvoid nfp_net_xsk_rx_ring_fill_freelist(struct nfp_net_rx_ring *rx_ring)\n{\n\tstruct nfp_net_r_vector *r_vec = rx_ring->r_vec;\n\tstruct xsk_buff_pool *pool = r_vec->xsk_pool;\n\tunsigned int wr_idx, wr_ptr_add = 0;\n\tstruct xdp_buff *xdp;\n\n\twhile (nfp_net_rx_space(rx_ring)) {\n\t\twr_idx = D_IDX(rx_ring, rx_ring->wr_p);\n\n\t\txdp = xsk_buff_alloc(pool);\n\t\tif (!xdp)\n\t\t\tbreak;\n\n\t\tnfp_net_xsk_rx_bufs_stash(rx_ring, wr_idx, xdp);\n\n\t\t \n\t\tnfp_desc_set_dma_addr_48b(&rx_ring->rxds[wr_idx].fld,\n\t\t\t\t\t  rx_ring->xsk_rxbufs[wr_idx].dma_addr);\n\n\t\trx_ring->wr_p++;\n\t\twr_ptr_add++;\n\t}\n\n\t \n\twmb();\n\tnfp_qcp_wr_ptr_add(rx_ring->qcp_fl, wr_ptr_add);\n}\n\nvoid nfp_net_xsk_rx_drop(struct nfp_net_r_vector *r_vec,\n\t\t\t struct nfp_net_xsk_rx_buf *xrxbuf)\n{\n\tu64_stats_update_begin(&r_vec->rx_sync);\n\tr_vec->rx_drops++;\n\tu64_stats_update_end(&r_vec->rx_sync);\n\n\tnfp_net_xsk_rx_free(xrxbuf);\n}\n\nstatic void nfp_net_xsk_pool_unmap(struct device *dev,\n\t\t\t\t   struct xsk_buff_pool *pool)\n{\n\treturn xsk_pool_dma_unmap(pool, 0);\n}\n\nstatic int nfp_net_xsk_pool_map(struct device *dev, struct xsk_buff_pool *pool)\n{\n\treturn xsk_pool_dma_map(pool, dev, 0);\n}\n\nint nfp_net_xsk_setup_pool(struct net_device *netdev,\n\t\t\t   struct xsk_buff_pool *pool, u16 queue_id)\n{\n\tstruct nfp_net *nn = netdev_priv(netdev);\n\n\tstruct xsk_buff_pool *prev_pool;\n\tstruct nfp_net_dp *dp;\n\tint err;\n\n\t \n\tif (nn->dp.ops->version == NFP_NFD_VER_NFDK)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (nn->dp.rx_offset != NFP_NET_CFG_RX_OFFSET_DYNAMIC)\n\t\treturn -EOPNOTSUPP;\n\tif (!nn->dp.chained_metadata_format)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (pool) {\n\t\terr = nfp_net_xsk_pool_map(nn->dp.dev, pool);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\t \n\tdp = nfp_net_clone_dp(nn);\n\tif (!dp) {\n\t\terr = -ENOMEM;\n\t\tgoto err_unmap;\n\t}\n\n\tprev_pool = dp->xsk_pools[queue_id];\n\tdp->xsk_pools[queue_id] = pool;\n\n\terr = nfp_net_ring_reconfig(nn, dp, NULL);\n\tif (err)\n\t\tgoto err_unmap;\n\n\t \n\tif (prev_pool)\n\t\tnfp_net_xsk_pool_unmap(nn->dp.dev, prev_pool);\n\n\treturn 0;\nerr_unmap:\n\tif (pool)\n\t\tnfp_net_xsk_pool_unmap(nn->dp.dev, pool);\n\n\treturn err;\n}\n\nint nfp_net_xsk_wakeup(struct net_device *netdev, u32 queue_id, u32 flags)\n{\n\tstruct nfp_net *nn = netdev_priv(netdev);\n\n\t \n\tnapi_schedule(&nn->r_vecs[queue_id].napi);\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}