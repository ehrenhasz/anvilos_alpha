{
  "module_name": "action.c",
  "hash_id": "5528f05c88c29e31f1cb7d9461f2b4fb7fb5270698cc36a57121a7394a6745c4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/netronome/nfp/flower/action.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/mpls.h>\n#include <net/pkt_cls.h>\n#include <net/tc_act/tc_csum.h>\n#include <net/tc_act/tc_gact.h>\n#include <net/tc_act/tc_mirred.h>\n#include <net/tc_act/tc_mpls.h>\n#include <net/tc_act/tc_pedit.h>\n#include <net/tc_act/tc_vlan.h>\n#include <net/tc_act/tc_tunnel_key.h>\n\n#include \"cmsg.h\"\n#include \"main.h\"\n#include \"../nfp_net_repr.h\"\n\n \n#define NFP_FL_TUNNEL_CSUM\t\t\tcpu_to_be16(0x01)\n#define NFP_FL_TUNNEL_KEY\t\t\tcpu_to_be16(0x04)\n#define NFP_FL_TUNNEL_GENEVE_OPT\t\tcpu_to_be16(0x0800)\n#define NFP_FL_SUPPORTED_TUNNEL_INFO_FLAGS\t(IP_TUNNEL_INFO_TX | \\\n\t\t\t\t\t\t IP_TUNNEL_INFO_IPV6)\n#define NFP_FL_SUPPORTED_UDP_TUN_FLAGS\t\t(NFP_FL_TUNNEL_CSUM | \\\n\t\t\t\t\t\t NFP_FL_TUNNEL_KEY | \\\n\t\t\t\t\t\t NFP_FL_TUNNEL_GENEVE_OPT)\n\nstatic int\nnfp_fl_push_mpls(struct nfp_fl_push_mpls *push_mpls,\n\t\t const struct flow_action_entry *act,\n\t\t struct netlink_ext_ack *extack)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_push_mpls);\n\tu32 mpls_lse = 0;\n\n\tpush_mpls->head.jump_id = NFP_FL_ACTION_OPCODE_PUSH_MPLS;\n\tpush_mpls->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\n\t \n\tif (act->mpls_push.bos != ACT_MPLS_BOS_NOT_SET) {\n\t\tmpls_lse |= act->mpls_push.bos << MPLS_LS_S_SHIFT;\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: BOS field must explicitly be set for MPLS push\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\t \n\tif (act->mpls_push.tc != ACT_MPLS_TC_NOT_SET)\n\t\tmpls_lse |= act->mpls_push.tc << MPLS_LS_TC_SHIFT;\n\n\t \n\tmpls_lse |= act->mpls_push.label << MPLS_LS_LABEL_SHIFT;\n\tmpls_lse |= act->mpls_push.ttl << MPLS_LS_TTL_SHIFT;\n\tpush_mpls->ethtype = act->mpls_push.proto;\n\tpush_mpls->lse = cpu_to_be32(mpls_lse);\n\n\treturn 0;\n}\n\nstatic void\nnfp_fl_pop_mpls(struct nfp_fl_pop_mpls *pop_mpls,\n\t\tconst struct flow_action_entry *act)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_pop_mpls);\n\n\tpop_mpls->head.jump_id = NFP_FL_ACTION_OPCODE_POP_MPLS;\n\tpop_mpls->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\tpop_mpls->ethtype = act->mpls_pop.proto;\n}\n\nstatic void\nnfp_fl_set_mpls(struct nfp_fl_set_mpls *set_mpls,\n\t\tconst struct flow_action_entry *act)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_set_mpls);\n\tu32 mpls_lse = 0, mpls_mask = 0;\n\n\tset_mpls->head.jump_id = NFP_FL_ACTION_OPCODE_SET_MPLS;\n\tset_mpls->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\n\tif (act->mpls_mangle.label != ACT_MPLS_LABEL_NOT_SET) {\n\t\tmpls_lse |= act->mpls_mangle.label << MPLS_LS_LABEL_SHIFT;\n\t\tmpls_mask |= MPLS_LS_LABEL_MASK;\n\t}\n\tif (act->mpls_mangle.tc != ACT_MPLS_TC_NOT_SET) {\n\t\tmpls_lse |= act->mpls_mangle.tc << MPLS_LS_TC_SHIFT;\n\t\tmpls_mask |= MPLS_LS_TC_MASK;\n\t}\n\tif (act->mpls_mangle.bos != ACT_MPLS_BOS_NOT_SET) {\n\t\tmpls_lse |= act->mpls_mangle.bos << MPLS_LS_S_SHIFT;\n\t\tmpls_mask |= MPLS_LS_S_MASK;\n\t}\n\tif (act->mpls_mangle.ttl) {\n\t\tmpls_lse |= act->mpls_mangle.ttl << MPLS_LS_TTL_SHIFT;\n\t\tmpls_mask |= MPLS_LS_TTL_MASK;\n\t}\n\n\tset_mpls->lse = cpu_to_be32(mpls_lse);\n\tset_mpls->lse_mask = cpu_to_be32(mpls_mask);\n}\n\nstatic void nfp_fl_pop_vlan(struct nfp_fl_pop_vlan *pop_vlan)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_pop_vlan);\n\n\tpop_vlan->head.jump_id = NFP_FL_ACTION_OPCODE_POP_VLAN;\n\tpop_vlan->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\tpop_vlan->reserved = 0;\n}\n\nstatic void\nnfp_fl_push_vlan(struct nfp_fl_push_vlan *push_vlan,\n\t\t const struct flow_action_entry *act)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_push_vlan);\n\tu16 tmp_push_vlan_tci;\n\n\tpush_vlan->head.jump_id = NFP_FL_ACTION_OPCODE_PUSH_VLAN;\n\tpush_vlan->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\tpush_vlan->reserved = 0;\n\tpush_vlan->vlan_tpid = act->vlan.proto;\n\n\ttmp_push_vlan_tci =\n\t\tFIELD_PREP(NFP_FL_PUSH_VLAN_PRIO, act->vlan.prio) |\n\t\tFIELD_PREP(NFP_FL_PUSH_VLAN_VID, act->vlan.vid);\n\tpush_vlan->vlan_tci = cpu_to_be16(tmp_push_vlan_tci);\n}\n\nstatic int\nnfp_fl_pre_lag(struct nfp_app *app, const struct flow_action_entry *act,\n\t       struct nfp_fl_payload *nfp_flow, int act_len,\n\t       struct netlink_ext_ack *extack)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_pre_lag);\n\tstruct nfp_fl_pre_lag *pre_lag;\n\tstruct net_device *out_dev;\n\tint err;\n\n\tout_dev = act->dev;\n\tif (!out_dev || !netif_is_lag_master(out_dev))\n\t\treturn 0;\n\n\tif (act_len + act_size > NFP_FL_MAX_A_SIZ) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at LAG action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\t \n\tif (act_len)\n\t\tmemmove(nfp_flow->action_data + act_size,\n\t\t\tnfp_flow->action_data, act_len);\n\n\tpre_lag = (struct nfp_fl_pre_lag *)nfp_flow->action_data;\n\terr = nfp_flower_lag_populate_pre_action(app, out_dev, pre_lag, extack);\n\tif (err)\n\t\treturn err;\n\n\tpre_lag->head.jump_id = NFP_FL_ACTION_OPCODE_PRE_LAG;\n\tpre_lag->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\n\tnfp_flow->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);\n\n\treturn act_size;\n}\n\nstatic int\nnfp_fl_output(struct nfp_app *app, struct nfp_fl_output *output,\n\t      const struct flow_action_entry *act,\n\t      struct nfp_fl_payload *nfp_flow,\n\t      bool last, struct net_device *in_dev,\n\t      enum nfp_flower_tun_type tun_type, int *tun_out_cnt,\n\t      bool pkt_host, struct netlink_ext_ack *extack)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_output);\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct net_device *out_dev;\n\tu16 tmp_flags;\n\n\toutput->head.jump_id = NFP_FL_ACTION_OPCODE_OUTPUT;\n\toutput->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\n\tout_dev = act->dev;\n\tif (!out_dev) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid egress interface for mirred action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\ttmp_flags = last ? NFP_FL_OUT_FLAGS_LAST : 0;\n\n\tif (tun_type) {\n\t\t \n\t\tif (!nfp_fl_netdev_is_tunnel_type(out_dev, tun_type)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: egress interface does not match the required tunnel type\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (*tun_out_cnt) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: cannot offload more than one tunnel mirred output per filter\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\t(*tun_out_cnt)++;\n\n\t\toutput->flags = cpu_to_be16(tmp_flags |\n\t\t\t\t\t    NFP_FL_OUT_FLAGS_USE_TUN);\n\t\toutput->port = cpu_to_be32(NFP_FL_PORT_TYPE_TUN | tun_type);\n\t} else if (netif_is_lag_master(out_dev) &&\n\t\t   priv->flower_en_feats & NFP_FL_ENABLE_LAG) {\n\t\tint gid;\n\n\t\toutput->flags = cpu_to_be16(tmp_flags);\n\t\tgid = nfp_flower_lag_get_output_id(app, out_dev);\n\t\tif (gid < 0) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"invalid entry: cannot find group id for LAG action\");\n\t\t\treturn gid;\n\t\t}\n\t\toutput->port = cpu_to_be32(NFP_FL_LAG_OUT | gid);\n\t} else if (nfp_flower_internal_port_can_offload(app, out_dev)) {\n\t\tif (!(priv->flower_ext_feats & NFP_FL_FEATS_PRE_TUN_RULES) &&\n\t\t    !(priv->flower_ext_feats & NFP_FL_FEATS_DECAP_V2)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: pre-tunnel rules not supported in loaded firmware\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (nfp_flow->pre_tun_rule.dev || !pkt_host) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: pre-tunnel rules require single egress dev and ptype HOST action\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tnfp_flow->pre_tun_rule.dev = out_dev;\n\n\t\treturn 0;\n\t} else {\n\t\t \n\t\toutput->flags = cpu_to_be16(tmp_flags);\n\n\t\tif (nfp_netdev_is_nfp_repr(in_dev)) {\n\t\t\t \n\t\t\tif (!netdev_port_same_parent_id(in_dev, out_dev)) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: ingress and egress interfaces are on different devices\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t}\n\n\t\tif (!nfp_netdev_is_nfp_repr(out_dev)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: egress interface is not an nfp port\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\toutput->port = cpu_to_be32(nfp_repr_get_port_id(out_dev));\n\t\tif (!output->port) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid port id for egress interface\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\tnfp_flow->meta.shortcut = output->port;\n\n\treturn 0;\n}\n\nstatic bool\nnfp_flower_tun_is_gre(struct flow_rule *rule, int start_idx)\n{\n\tstruct flow_action_entry *act = rule->action.entries;\n\tint num_act = rule->action.num_entries;\n\tint act_idx;\n\n\t \n\tfor (act_idx = start_idx + 1; act_idx < num_act; act_idx++)\n\t\tif (act[act_idx].id == FLOW_ACTION_REDIRECT ||\n\t\t    act[act_idx].id == FLOW_ACTION_MIRRED)\n\t\t\treturn netif_is_gretap(act[act_idx].dev) ||\n\t\t\t       netif_is_ip6gretap(act[act_idx].dev);\n\n\treturn false;\n}\n\nstatic enum nfp_flower_tun_type\nnfp_fl_get_tun_from_act(struct nfp_app *app,\n\t\t\tstruct flow_rule *rule,\n\t\t\tconst struct flow_action_entry *act, int act_idx)\n{\n\tconst struct ip_tunnel_info *tun = act->tunnel;\n\tstruct nfp_flower_priv *priv = app->priv;\n\n\t \n\tif (nfp_flower_tun_is_gre(rule, act_idx))\n\t\treturn NFP_FL_TUNNEL_GRE;\n\n\tswitch (tun->key.tp_dst) {\n\tcase htons(IANA_VXLAN_UDP_PORT):\n\t\treturn NFP_FL_TUNNEL_VXLAN;\n\tcase htons(GENEVE_UDP_PORT):\n\t\tif (priv->flower_ext_feats & NFP_FL_FEATS_GENEVE)\n\t\t\treturn NFP_FL_TUNNEL_GENEVE;\n\t\tfallthrough;\n\tdefault:\n\t\treturn NFP_FL_TUNNEL_NONE;\n\t}\n}\n\nstatic struct nfp_fl_pre_tunnel *nfp_fl_pre_tunnel(char *act_data, int act_len)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_pre_tunnel);\n\tstruct nfp_fl_pre_tunnel *pre_tun_act;\n\n\t \n\tif (act_len)\n\t\tmemmove(act_data + act_size, act_data, act_len);\n\n\tpre_tun_act = (struct nfp_fl_pre_tunnel *)act_data;\n\n\tmemset(pre_tun_act, 0, act_size);\n\n\tpre_tun_act->head.jump_id = NFP_FL_ACTION_OPCODE_PRE_TUNNEL;\n\tpre_tun_act->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\n\treturn pre_tun_act;\n}\n\nstatic int\nnfp_fl_push_geneve_options(struct nfp_fl_payload *nfp_fl, int *list_len,\n\t\t\t   const struct flow_action_entry *act,\n\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct ip_tunnel_info *ip_tun = (struct ip_tunnel_info *)act->tunnel;\n\tint opt_len, opt_cnt, act_start, tot_push_len;\n\tu8 *src = ip_tunnel_info_opts(ip_tun);\n\n\t \n\topt_cnt = 0;\n\ttot_push_len = 0;\n\topt_len = ip_tun->options_len;\n\twhile (opt_len > 0) {\n\t\tstruct geneve_opt *opt = (struct geneve_opt *)src;\n\n\t\topt_cnt++;\n\t\tif (opt_cnt > NFP_FL_MAX_GENEVE_OPT_CNT) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed number of geneve options exceeded\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\ttot_push_len += sizeof(struct nfp_fl_push_geneve) +\n\t\t\t       opt->length * 4;\n\t\tif (tot_push_len > NFP_FL_MAX_GENEVE_OPT_ACT) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at push geneve options\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\topt_len -= sizeof(struct geneve_opt) + opt->length * 4;\n\t\tsrc += sizeof(struct geneve_opt) + opt->length * 4;\n\t}\n\n\tif (*list_len + tot_push_len > NFP_FL_MAX_A_SIZ) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at push geneve options\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tact_start = *list_len;\n\t*list_len += tot_push_len;\n\tsrc = ip_tunnel_info_opts(ip_tun);\n\twhile (opt_cnt) {\n\t\tstruct geneve_opt *opt = (struct geneve_opt *)src;\n\t\tstruct nfp_fl_push_geneve *push;\n\t\tsize_t act_size, len;\n\n\t\topt_cnt--;\n\t\tact_size = sizeof(struct nfp_fl_push_geneve) + opt->length * 4;\n\t\ttot_push_len -= act_size;\n\t\tlen = act_start + tot_push_len;\n\n\t\tpush = (struct nfp_fl_push_geneve *)&nfp_fl->action_data[len];\n\t\tpush->head.jump_id = NFP_FL_ACTION_OPCODE_PUSH_GENEVE;\n\t\tpush->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\t\tpush->reserved = 0;\n\t\tpush->class = opt->opt_class;\n\t\tpush->type = opt->type;\n\t\tpush->length = opt->length;\n\t\tmemcpy(&push->opt_data, opt->opt_data, opt->length * 4);\n\n\t\tsrc += sizeof(struct geneve_opt) + opt->length * 4;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nnfp_fl_set_tun(struct nfp_app *app, struct nfp_fl_set_tun *set_tun,\n\t       const struct flow_action_entry *act,\n\t       struct nfp_fl_pre_tunnel *pre_tun,\n\t       enum nfp_flower_tun_type tun_type,\n\t       struct net_device *netdev, struct netlink_ext_ack *extack)\n{\n\tconst struct ip_tunnel_info *ip_tun = act->tunnel;\n\tbool ipv6 = ip_tunnel_info_af(ip_tun) == AF_INET6;\n\tsize_t act_size = sizeof(struct nfp_fl_set_tun);\n\tstruct nfp_flower_priv *priv = app->priv;\n\tu32 tmp_set_ip_tun_type_index = 0;\n\t \n\tint pretun_idx = 0;\n\n\tif (!IS_ENABLED(CONFIG_IPV6) && ipv6)\n\t\treturn -EOPNOTSUPP;\n\n\tif (ipv6 && !(priv->flower_ext_feats & NFP_FL_FEATS_IPV6_TUN))\n\t\treturn -EOPNOTSUPP;\n\n\tBUILD_BUG_ON(NFP_FL_TUNNEL_CSUM != TUNNEL_CSUM ||\n\t\t     NFP_FL_TUNNEL_KEY\t!= TUNNEL_KEY ||\n\t\t     NFP_FL_TUNNEL_GENEVE_OPT != TUNNEL_GENEVE_OPT);\n\tif (ip_tun->options_len &&\n\t    (tun_type != NFP_FL_TUNNEL_GENEVE ||\n\t    !(priv->flower_ext_feats & NFP_FL_FEATS_GENEVE_OPT))) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: loaded firmware does not support geneve options offload\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (ip_tun->key.tun_flags & ~NFP_FL_SUPPORTED_UDP_TUN_FLAGS) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"unsupported offload: loaded firmware does not support tunnel flag offload\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tset_tun->head.jump_id = NFP_FL_ACTION_OPCODE_SET_TUNNEL;\n\tset_tun->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\n\t \n\ttmp_set_ip_tun_type_index |=\n\t\tFIELD_PREP(NFP_FL_TUNNEL_TYPE, tun_type) |\n\t\tFIELD_PREP(NFP_FL_PRE_TUN_INDEX, pretun_idx);\n\n\tset_tun->tun_type_index = cpu_to_be32(tmp_set_ip_tun_type_index);\n\tif (ip_tun->key.tun_flags & NFP_FL_TUNNEL_KEY)\n\t\tset_tun->tun_id = ip_tun->key.tun_id;\n\n\tif (ip_tun->key.ttl) {\n\t\tset_tun->ttl = ip_tun->key.ttl;\n#ifdef CONFIG_IPV6\n\t} else if (ipv6) {\n\t\tstruct net *net = dev_net(netdev);\n\t\tstruct flowi6 flow = {};\n\t\tstruct dst_entry *dst;\n\n\t\tflow.daddr = ip_tun->key.u.ipv6.dst;\n\t\tflow.flowi4_proto = IPPROTO_UDP;\n\t\tdst = ipv6_stub->ipv6_dst_lookup_flow(net, NULL, &flow, NULL);\n\t\tif (!IS_ERR(dst)) {\n\t\t\tset_tun->ttl = ip6_dst_hoplimit(dst);\n\t\t\tdst_release(dst);\n\t\t} else {\n\t\t\tset_tun->ttl = net->ipv6.devconf_all->hop_limit;\n\t\t}\n#endif\n\t} else {\n\t\tstruct net *net = dev_net(netdev);\n\t\tstruct flowi4 flow = {};\n\t\tstruct rtable *rt;\n\t\tint err;\n\n\t\t \n\t\tflow.daddr = ip_tun->key.u.ipv4.dst;\n\t\tflow.flowi4_proto = IPPROTO_UDP;\n\t\trt = ip_route_output_key(net, &flow);\n\t\terr = PTR_ERR_OR_ZERO(rt);\n\t\tif (!err) {\n\t\t\tset_tun->ttl = ip4_dst_hoplimit(&rt->dst);\n\t\t\tip_rt_put(rt);\n\t\t} else {\n\t\t\tset_tun->ttl = READ_ONCE(net->ipv4.sysctl_ip_default_ttl);\n\t\t}\n\t}\n\n\tset_tun->tos = ip_tun->key.tos;\n\tset_tun->tun_flags = ip_tun->key.tun_flags;\n\n\tif (tun_type == NFP_FL_TUNNEL_GENEVE) {\n\t\tset_tun->tun_proto = htons(ETH_P_TEB);\n\t\tset_tun->tun_len = ip_tun->options_len / 4;\n\t}\n\n\t \n\tif (ipv6) {\n\t\tpre_tun->flags |= cpu_to_be16(NFP_FL_PRE_TUN_IPV6);\n\t\tpre_tun->ipv6_dst = ip_tun->key.u.ipv6.dst;\n\t} else {\n\t\tpre_tun->ipv4_dst = ip_tun->key.u.ipv4.dst;\n\t}\n\n\treturn 0;\n}\n\nstatic void nfp_fl_set_helper32(u32 value, u32 mask, u8 *p_exact, u8 *p_mask)\n{\n\tu32 oldvalue = get_unaligned((u32 *)p_exact);\n\tu32 oldmask = get_unaligned((u32 *)p_mask);\n\n\tvalue &= mask;\n\tvalue |= oldvalue & ~mask;\n\n\tput_unaligned(oldmask | mask, (u32 *)p_mask);\n\tput_unaligned(value, (u32 *)p_exact);\n}\n\nstatic int\nnfp_fl_set_eth(const struct flow_action_entry *act, u32 off,\n\t       struct nfp_fl_set_eth *set_eth, struct netlink_ext_ack *extack)\n{\n\tu32 exact, mask;\n\n\tif (off + 4 > ETH_ALEN * 2) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit ethernet action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmask = ~act->mangle.mask;\n\texact = act->mangle.val;\n\n\tif (exact & ~mask) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit ethernet action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tnfp_fl_set_helper32(exact, mask, &set_eth->eth_addr_val[off],\n\t\t\t    &set_eth->eth_addr_mask[off]);\n\n\tset_eth->reserved = cpu_to_be16(0);\n\tset_eth->head.jump_id = NFP_FL_ACTION_OPCODE_SET_ETHERNET;\n\tset_eth->head.len_lw = sizeof(*set_eth) >> NFP_FL_LW_SIZ;\n\n\treturn 0;\n}\n\nstruct ipv4_ttl_word {\n\t__u8\tttl;\n\t__u8\tprotocol;\n\t__sum16\tcheck;\n};\n\nstatic int\nnfp_fl_set_ip4(const struct flow_action_entry *act, u32 off,\n\t       struct nfp_fl_set_ip4_addrs *set_ip_addr,\n\t       struct nfp_fl_set_ip4_ttl_tos *set_ip_ttl_tos,\n\t       struct netlink_ext_ack *extack)\n{\n\tstruct ipv4_ttl_word *ttl_word_mask;\n\tstruct ipv4_ttl_word *ttl_word;\n\tstruct iphdr *tos_word_mask;\n\tstruct iphdr *tos_word;\n\t__be32 exact, mask;\n\n\t \n\tmask = (__force __be32)~act->mangle.mask;\n\texact = (__force __be32)act->mangle.val;\n\n\tif (exact & ~mask) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit IPv4 action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tswitch (off) {\n\tcase offsetof(struct iphdr, daddr):\n\t\tset_ip_addr->ipv4_dst_mask |= mask;\n\t\tset_ip_addr->ipv4_dst &= ~mask;\n\t\tset_ip_addr->ipv4_dst |= exact & mask;\n\t\tset_ip_addr->head.jump_id = NFP_FL_ACTION_OPCODE_SET_IPV4_ADDRS;\n\t\tset_ip_addr->head.len_lw = sizeof(*set_ip_addr) >>\n\t\t\t\t\t   NFP_FL_LW_SIZ;\n\t\tbreak;\n\tcase offsetof(struct iphdr, saddr):\n\t\tset_ip_addr->ipv4_src_mask |= mask;\n\t\tset_ip_addr->ipv4_src &= ~mask;\n\t\tset_ip_addr->ipv4_src |= exact & mask;\n\t\tset_ip_addr->head.jump_id = NFP_FL_ACTION_OPCODE_SET_IPV4_ADDRS;\n\t\tset_ip_addr->head.len_lw = sizeof(*set_ip_addr) >>\n\t\t\t\t\t   NFP_FL_LW_SIZ;\n\t\tbreak;\n\tcase offsetof(struct iphdr, ttl):\n\t\tttl_word_mask = (struct ipv4_ttl_word *)&mask;\n\t\tttl_word = (struct ipv4_ttl_word *)&exact;\n\n\t\tif (ttl_word_mask->protocol || ttl_word_mask->check) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit IPv4 ttl action\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tset_ip_ttl_tos->ipv4_ttl_mask |= ttl_word_mask->ttl;\n\t\tset_ip_ttl_tos->ipv4_ttl &= ~ttl_word_mask->ttl;\n\t\tset_ip_ttl_tos->ipv4_ttl |= ttl_word->ttl & ttl_word_mask->ttl;\n\t\tset_ip_ttl_tos->head.jump_id =\n\t\t\tNFP_FL_ACTION_OPCODE_SET_IPV4_TTL_TOS;\n\t\tset_ip_ttl_tos->head.len_lw = sizeof(*set_ip_ttl_tos) >>\n\t\t\t\t\t      NFP_FL_LW_SIZ;\n\t\tbreak;\n\tcase round_down(offsetof(struct iphdr, tos), 4):\n\t\ttos_word_mask = (struct iphdr *)&mask;\n\t\ttos_word = (struct iphdr *)&exact;\n\n\t\tif (tos_word_mask->version || tos_word_mask->ihl ||\n\t\t    tos_word_mask->tot_len) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit IPv4 tos action\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tset_ip_ttl_tos->ipv4_tos_mask |= tos_word_mask->tos;\n\t\tset_ip_ttl_tos->ipv4_tos &= ~tos_word_mask->tos;\n\t\tset_ip_ttl_tos->ipv4_tos |= tos_word->tos & tos_word_mask->tos;\n\t\tset_ip_ttl_tos->head.jump_id =\n\t\t\tNFP_FL_ACTION_OPCODE_SET_IPV4_TTL_TOS;\n\t\tset_ip_ttl_tos->head.len_lw = sizeof(*set_ip_ttl_tos) >>\n\t\t\t\t\t      NFP_FL_LW_SIZ;\n\t\tbreak;\n\tdefault:\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: pedit on unsupported section of IPv4 header\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic void\nnfp_fl_set_ip6_helper(int opcode_tag, u8 word, __be32 exact, __be32 mask,\n\t\t      struct nfp_fl_set_ipv6_addr *ip6)\n{\n\tip6->ipv6[word].mask |= mask;\n\tip6->ipv6[word].exact &= ~mask;\n\tip6->ipv6[word].exact |= exact & mask;\n\n\tip6->reserved = cpu_to_be16(0);\n\tip6->head.jump_id = opcode_tag;\n\tip6->head.len_lw = sizeof(*ip6) >> NFP_FL_LW_SIZ;\n}\n\nstruct ipv6_hop_limit_word {\n\t__be16 payload_len;\n\tu8 nexthdr;\n\tu8 hop_limit;\n};\n\nstatic int\nnfp_fl_set_ip6_hop_limit_flow_label(u32 off, __be32 exact, __be32 mask,\n\t\t\t\t    struct nfp_fl_set_ipv6_tc_hl_fl *ip_hl_fl,\n\t\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct ipv6_hop_limit_word *fl_hl_mask;\n\tstruct ipv6_hop_limit_word *fl_hl;\n\n\tswitch (off) {\n\tcase offsetof(struct ipv6hdr, payload_len):\n\t\tfl_hl_mask = (struct ipv6_hop_limit_word *)&mask;\n\t\tfl_hl = (struct ipv6_hop_limit_word *)&exact;\n\n\t\tif (fl_hl_mask->nexthdr || fl_hl_mask->payload_len) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit IPv6 hop limit action\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tip_hl_fl->ipv6_hop_limit_mask |= fl_hl_mask->hop_limit;\n\t\tip_hl_fl->ipv6_hop_limit &= ~fl_hl_mask->hop_limit;\n\t\tip_hl_fl->ipv6_hop_limit |= fl_hl->hop_limit &\n\t\t\t\t\t    fl_hl_mask->hop_limit;\n\t\tbreak;\n\tcase round_down(offsetof(struct ipv6hdr, flow_lbl), 4):\n\t\tif (mask & ~IPV6_FLOWINFO_MASK ||\n\t\t    exact & ~IPV6_FLOWINFO_MASK) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit IPv6 flow info action\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tip_hl_fl->ipv6_label_mask |= mask;\n\t\tip_hl_fl->ipv6_label &= ~mask;\n\t\tip_hl_fl->ipv6_label |= exact & mask;\n\t\tbreak;\n\t}\n\n\tip_hl_fl->head.jump_id = NFP_FL_ACTION_OPCODE_SET_IPV6_TC_HL_FL;\n\tip_hl_fl->head.len_lw = sizeof(*ip_hl_fl) >> NFP_FL_LW_SIZ;\n\n\treturn 0;\n}\n\nstatic int\nnfp_fl_set_ip6(const struct flow_action_entry *act, u32 off,\n\t       struct nfp_fl_set_ipv6_addr *ip_dst,\n\t       struct nfp_fl_set_ipv6_addr *ip_src,\n\t       struct nfp_fl_set_ipv6_tc_hl_fl *ip_hl_fl,\n\t       struct netlink_ext_ack *extack)\n{\n\t__be32 exact, mask;\n\tint err = 0;\n\tu8 word;\n\n\t \n\tmask = (__force __be32)~act->mangle.mask;\n\texact = (__force __be32)act->mangle.val;\n\n\tif (exact & ~mask) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit IPv6 action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (off < offsetof(struct ipv6hdr, saddr)) {\n\t\terr = nfp_fl_set_ip6_hop_limit_flow_label(off, exact, mask,\n\t\t\t\t\t\t\t  ip_hl_fl, extack);\n\t} else if (off < offsetof(struct ipv6hdr, daddr)) {\n\t\tword = (off - offsetof(struct ipv6hdr, saddr)) / sizeof(exact);\n\t\tnfp_fl_set_ip6_helper(NFP_FL_ACTION_OPCODE_SET_IPV6_SRC, word,\n\t\t\t\t      exact, mask, ip_src);\n\t} else if (off < offsetof(struct ipv6hdr, daddr) +\n\t\t       sizeof(struct in6_addr)) {\n\t\tword = (off - offsetof(struct ipv6hdr, daddr)) / sizeof(exact);\n\t\tnfp_fl_set_ip6_helper(NFP_FL_ACTION_OPCODE_SET_IPV6_DST, word,\n\t\t\t\t      exact, mask, ip_dst);\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: pedit on unsupported section of IPv6 header\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn err;\n}\n\nstatic int\nnfp_fl_set_tport(const struct flow_action_entry *act, u32 off,\n\t\t struct nfp_fl_set_tport *set_tport, int opcode,\n\t\t struct netlink_ext_ack *extack)\n{\n\tu32 exact, mask;\n\n\tif (off) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: pedit on unsupported section of L4 header\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmask = ~act->mangle.mask;\n\texact = act->mangle.val;\n\n\tif (exact & ~mask) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: invalid pedit L4 action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tnfp_fl_set_helper32(exact, mask, set_tport->tp_port_val,\n\t\t\t    set_tport->tp_port_mask);\n\n\tset_tport->reserved = cpu_to_be16(0);\n\tset_tport->head.jump_id = opcode;\n\tset_tport->head.len_lw = sizeof(*set_tport) >> NFP_FL_LW_SIZ;\n\n\treturn 0;\n}\n\nstatic u32 nfp_fl_csum_l4_to_flag(u8 ip_proto)\n{\n\tswitch (ip_proto) {\n\tcase 0:\n\t\t \n\t\treturn TCA_CSUM_UPDATE_FLAG_TCP | TCA_CSUM_UPDATE_FLAG_UDP;\n\tcase IPPROTO_TCP:\n\t\treturn TCA_CSUM_UPDATE_FLAG_TCP;\n\tcase IPPROTO_UDP:\n\t\treturn TCA_CSUM_UPDATE_FLAG_UDP;\n\tdefault:\n\t\t \n\t\treturn 0;\n\t}\n}\n\nstruct nfp_flower_pedit_acts {\n\tstruct nfp_fl_set_ipv6_addr set_ip6_dst, set_ip6_src;\n\tstruct nfp_fl_set_ipv6_tc_hl_fl set_ip6_tc_hl_fl;\n\tstruct nfp_fl_set_ip4_ttl_tos set_ip_ttl_tos;\n\tstruct nfp_fl_set_ip4_addrs set_ip_addr;\n\tstruct nfp_fl_set_tport set_tport;\n\tstruct nfp_fl_set_eth set_eth;\n};\n\nstatic int\nnfp_fl_commit_mangle(struct flow_rule *rule, char *nfp_action,\n\t\t     int *a_len, struct nfp_flower_pedit_acts *set_act,\n\t\t     u32 *csum_updated)\n{\n\tsize_t act_size = 0;\n\tu8 ip_proto = 0;\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tip_proto = match.key->ip_proto;\n\t}\n\n\tif (set_act->set_eth.head.len_lw) {\n\t\tact_size = sizeof(set_act->set_eth);\n\t\tmemcpy(nfp_action, &set_act->set_eth, act_size);\n\t\t*a_len += act_size;\n\t}\n\n\tif (set_act->set_ip_ttl_tos.head.len_lw) {\n\t\tnfp_action += act_size;\n\t\tact_size = sizeof(set_act->set_ip_ttl_tos);\n\t\tmemcpy(nfp_action, &set_act->set_ip_ttl_tos, act_size);\n\t\t*a_len += act_size;\n\n\t\t \n\t\t*csum_updated |= TCA_CSUM_UPDATE_FLAG_IPV4HDR |\n\t\t\t\tnfp_fl_csum_l4_to_flag(ip_proto);\n\t}\n\n\tif (set_act->set_ip_addr.head.len_lw) {\n\t\tnfp_action += act_size;\n\t\tact_size = sizeof(set_act->set_ip_addr);\n\t\tmemcpy(nfp_action, &set_act->set_ip_addr, act_size);\n\t\t*a_len += act_size;\n\n\t\t \n\t\t*csum_updated |= TCA_CSUM_UPDATE_FLAG_IPV4HDR |\n\t\t\t\tnfp_fl_csum_l4_to_flag(ip_proto);\n\t}\n\n\tif (set_act->set_ip6_tc_hl_fl.head.len_lw) {\n\t\tnfp_action += act_size;\n\t\tact_size = sizeof(set_act->set_ip6_tc_hl_fl);\n\t\tmemcpy(nfp_action, &set_act->set_ip6_tc_hl_fl, act_size);\n\t\t*a_len += act_size;\n\n\t\t \n\t\t*csum_updated |= nfp_fl_csum_l4_to_flag(ip_proto);\n\t}\n\n\tif (set_act->set_ip6_dst.head.len_lw &&\n\t    set_act->set_ip6_src.head.len_lw) {\n\t\t \n\t\tnfp_action += act_size;\n\t\tact_size = sizeof(set_act->set_ip6_src);\n\t\tmemcpy(nfp_action, &set_act->set_ip6_src, act_size);\n\t\t*a_len += act_size;\n\n\t\tact_size = sizeof(set_act->set_ip6_dst);\n\t\tmemcpy(&nfp_action[sizeof(set_act->set_ip6_src)],\n\t\t       &set_act->set_ip6_dst, act_size);\n\t\t*a_len += act_size;\n\n\t\t \n\t\t*csum_updated |= nfp_fl_csum_l4_to_flag(ip_proto);\n\t} else if (set_act->set_ip6_dst.head.len_lw) {\n\t\tnfp_action += act_size;\n\t\tact_size = sizeof(set_act->set_ip6_dst);\n\t\tmemcpy(nfp_action, &set_act->set_ip6_dst, act_size);\n\t\t*a_len += act_size;\n\n\t\t \n\t\t*csum_updated |= nfp_fl_csum_l4_to_flag(ip_proto);\n\t} else if (set_act->set_ip6_src.head.len_lw) {\n\t\tnfp_action += act_size;\n\t\tact_size = sizeof(set_act->set_ip6_src);\n\t\tmemcpy(nfp_action, &set_act->set_ip6_src, act_size);\n\t\t*a_len += act_size;\n\n\t\t \n\t\t*csum_updated |= nfp_fl_csum_l4_to_flag(ip_proto);\n\t}\n\tif (set_act->set_tport.head.len_lw) {\n\t\tnfp_action += act_size;\n\t\tact_size = sizeof(set_act->set_tport);\n\t\tmemcpy(nfp_action, &set_act->set_tport, act_size);\n\t\t*a_len += act_size;\n\n\t\t \n\t\t*csum_updated |= nfp_fl_csum_l4_to_flag(ip_proto);\n\t}\n\n\treturn 0;\n}\n\nstatic int\nnfp_fl_pedit(const struct flow_action_entry *act,\n\t     char *nfp_action, int *a_len,\n\t     u32 *csum_updated, struct nfp_flower_pedit_acts *set_act,\n\t     struct netlink_ext_ack *extack)\n{\n\tenum flow_action_mangle_base htype;\n\tu32 offset;\n\n\thtype = act->mangle.htype;\n\toffset = act->mangle.offset;\n\n\tswitch (htype) {\n\tcase TCA_PEDIT_KEY_EX_HDR_TYPE_ETH:\n\t\treturn nfp_fl_set_eth(act, offset, &set_act->set_eth, extack);\n\tcase TCA_PEDIT_KEY_EX_HDR_TYPE_IP4:\n\t\treturn nfp_fl_set_ip4(act, offset, &set_act->set_ip_addr,\n\t\t\t\t      &set_act->set_ip_ttl_tos, extack);\n\tcase TCA_PEDIT_KEY_EX_HDR_TYPE_IP6:\n\t\treturn nfp_fl_set_ip6(act, offset, &set_act->set_ip6_dst,\n\t\t\t\t      &set_act->set_ip6_src,\n\t\t\t\t      &set_act->set_ip6_tc_hl_fl, extack);\n\tcase TCA_PEDIT_KEY_EX_HDR_TYPE_TCP:\n\t\treturn nfp_fl_set_tport(act, offset, &set_act->set_tport,\n\t\t\t\t\tNFP_FL_ACTION_OPCODE_SET_TCP, extack);\n\tcase TCA_PEDIT_KEY_EX_HDR_TYPE_UDP:\n\t\treturn nfp_fl_set_tport(act, offset, &set_act->set_tport,\n\t\t\t\t\tNFP_FL_ACTION_OPCODE_SET_UDP, extack);\n\tdefault:\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: pedit on unsupported header\");\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic struct nfp_fl_meter *nfp_fl_meter(char *act_data)\n{\n\tsize_t act_size = sizeof(struct nfp_fl_meter);\n\tstruct nfp_fl_meter *meter_act;\n\n\tmeter_act = (struct nfp_fl_meter *)act_data;\n\n\tmemset(meter_act, 0, act_size);\n\n\tmeter_act->head.jump_id = NFP_FL_ACTION_OPCODE_METER;\n\tmeter_act->head.len_lw = act_size >> NFP_FL_LW_SIZ;\n\n\treturn meter_act;\n}\n\nstatic int\nnfp_flower_meter_action(struct nfp_app *app,\n\t\t\tconst struct flow_action_entry *action,\n\t\t\tstruct nfp_fl_payload *nfp_fl, int *a_len,\n\t\t\tstruct net_device *netdev,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct nfp_fl_meter *fl_meter;\n\tu32 meter_id;\n\n\tif (*a_len + sizeof(struct nfp_fl_meter) > NFP_FL_MAX_A_SIZ) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"unsupported offload:meter action size beyond the allowed maximum\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmeter_id = action->hw_index;\n\tif (!nfp_flower_search_meter_entry(app, meter_id)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"can not offload flow table with unsupported police action.\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tfl_meter = nfp_fl_meter(&nfp_fl->action_data[*a_len]);\n\t*a_len += sizeof(struct nfp_fl_meter);\n\tfl_meter->meter_id = cpu_to_be32(meter_id);\n\n\treturn 0;\n}\n\nstatic int\nnfp_flower_output_action(struct nfp_app *app,\n\t\t\t const struct flow_action_entry *act,\n\t\t\t struct nfp_fl_payload *nfp_fl, int *a_len,\n\t\t\t struct net_device *netdev, bool last,\n\t\t\t enum nfp_flower_tun_type *tun_type, int *tun_out_cnt,\n\t\t\t int *out_cnt, u32 *csum_updated, bool pkt_host,\n\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_fl_output *output;\n\tint err, prelag_size;\n\n\t \n\tif (*csum_updated) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: set actions without updating checksums are not supported\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (*a_len + sizeof(struct nfp_fl_output) > NFP_FL_MAX_A_SIZ) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: mirred output increases action list size beyond the allowed maximum\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\toutput = (struct nfp_fl_output *)&nfp_fl->action_data[*a_len];\n\terr = nfp_fl_output(app, output, act, nfp_fl, last, netdev, *tun_type,\n\t\t\t    tun_out_cnt, pkt_host, extack);\n\tif (err)\n\t\treturn err;\n\n\t*a_len += sizeof(struct nfp_fl_output);\n\n\tif (priv->flower_en_feats & NFP_FL_ENABLE_LAG) {\n\t\t \n\t\tprelag_size = nfp_fl_pre_lag(app, act, nfp_fl, *a_len, extack);\n\t\tif (prelag_size < 0) {\n\t\t\treturn prelag_size;\n\t\t} else if (prelag_size > 0 && (!last || *out_cnt)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: LAG action has to be last action in action list\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\t*a_len += prelag_size;\n\t}\n\t(*out_cnt)++;\n\n\treturn 0;\n}\n\nstatic int\nnfp_flower_loop_action(struct nfp_app *app, const struct flow_action_entry *act,\n\t\t       struct flow_rule *rule,\n\t\t       struct nfp_fl_payload *nfp_fl, int *a_len,\n\t\t       struct net_device *netdev,\n\t\t       enum nfp_flower_tun_type *tun_type, int *tun_out_cnt,\n\t\t       int *out_cnt, u32 *csum_updated,\n\t\t       struct nfp_flower_pedit_acts *set_act, bool *pkt_host,\n\t\t       struct netlink_ext_ack *extack, int act_idx)\n{\n\tstruct nfp_flower_priv *fl_priv = app->priv;\n\tstruct nfp_fl_pre_tunnel *pre_tun;\n\tstruct nfp_fl_set_tun *set_tun;\n\tstruct nfp_fl_push_vlan *psh_v;\n\tstruct nfp_fl_push_mpls *psh_m;\n\tstruct nfp_fl_pop_vlan *pop_v;\n\tstruct nfp_fl_pop_mpls *pop_m;\n\tstruct nfp_fl_set_mpls *set_m;\n\tint err;\n\n\tswitch (act->id) {\n\tcase FLOW_ACTION_DROP:\n\t\tnfp_fl->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_DROP);\n\t\tbreak;\n\tcase FLOW_ACTION_REDIRECT_INGRESS:\n\tcase FLOW_ACTION_REDIRECT:\n\t\terr = nfp_flower_output_action(app, act, nfp_fl, a_len, netdev,\n\t\t\t\t\t       true, tun_type, tun_out_cnt,\n\t\t\t\t\t       out_cnt, csum_updated, *pkt_host,\n\t\t\t\t\t       extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\tbreak;\n\tcase FLOW_ACTION_MIRRED_INGRESS:\n\tcase FLOW_ACTION_MIRRED:\n\t\terr = nfp_flower_output_action(app, act, nfp_fl, a_len, netdev,\n\t\t\t\t\t       false, tun_type, tun_out_cnt,\n\t\t\t\t\t       out_cnt, csum_updated, *pkt_host,\n\t\t\t\t\t       extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\tbreak;\n\tcase FLOW_ACTION_VLAN_POP:\n\t\tif (*a_len +\n\t\t    sizeof(struct nfp_fl_pop_vlan) > NFP_FL_MAX_A_SIZ) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at pop vlan\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tpop_v = (struct nfp_fl_pop_vlan *)&nfp_fl->action_data[*a_len];\n\t\tnfp_fl->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_POPV);\n\n\t\tnfp_fl_pop_vlan(pop_v);\n\t\t*a_len += sizeof(struct nfp_fl_pop_vlan);\n\t\tbreak;\n\tcase FLOW_ACTION_VLAN_PUSH:\n\t\tif (*a_len +\n\t\t    sizeof(struct nfp_fl_push_vlan) > NFP_FL_MAX_A_SIZ) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at push vlan\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tpsh_v = (struct nfp_fl_push_vlan *)&nfp_fl->action_data[*a_len];\n\t\tnfp_fl->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);\n\n\t\tnfp_fl_push_vlan(psh_v, act);\n\t\t*a_len += sizeof(struct nfp_fl_push_vlan);\n\t\tbreak;\n\tcase FLOW_ACTION_TUNNEL_ENCAP: {\n\t\tconst struct ip_tunnel_info *ip_tun = act->tunnel;\n\n\t\t*tun_type = nfp_fl_get_tun_from_act(app, rule, act, act_idx);\n\t\tif (*tun_type == NFP_FL_TUNNEL_NONE) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: unsupported tunnel type in action list\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (ip_tun->mode & ~NFP_FL_SUPPORTED_TUNNEL_INFO_FLAGS) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: unsupported tunnel flags in action list\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\t \n\t\tif (*a_len + sizeof(struct nfp_fl_pre_tunnel) +\n\t\t    sizeof(struct nfp_fl_set_tun) > NFP_FL_MAX_A_SIZ) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at tunnel encap\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tpre_tun = nfp_fl_pre_tunnel(nfp_fl->action_data, *a_len);\n\t\tnfp_fl->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);\n\t\t*a_len += sizeof(struct nfp_fl_pre_tunnel);\n\n\t\terr = nfp_fl_push_geneve_options(nfp_fl, a_len, act, extack);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tset_tun = (void *)&nfp_fl->action_data[*a_len];\n\t\terr = nfp_fl_set_tun(app, set_tun, act, pre_tun, *tun_type,\n\t\t\t\t     netdev, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\t*a_len += sizeof(struct nfp_fl_set_tun);\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACTION_TUNNEL_DECAP:\n\t\t \n\t\treturn 0;\n\tcase FLOW_ACTION_MANGLE:\n\t\tif (nfp_fl_pedit(act, &nfp_fl->action_data[*a_len],\n\t\t\t\t a_len, csum_updated, set_act, extack))\n\t\t\treturn -EOPNOTSUPP;\n\t\tbreak;\n\tcase FLOW_ACTION_CSUM:\n\t\t \n\t\tif (act->csum_flags & ~*csum_updated) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: unsupported csum update action in action list\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\t \n\t\t*csum_updated &= ~act->csum_flags;\n\t\tbreak;\n\tcase FLOW_ACTION_MPLS_PUSH:\n\t\tif (*a_len +\n\t\t    sizeof(struct nfp_fl_push_mpls) > NFP_FL_MAX_A_SIZ) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at push MPLS\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tpsh_m = (struct nfp_fl_push_mpls *)&nfp_fl->action_data[*a_len];\n\t\tnfp_fl->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);\n\n\t\terr = nfp_fl_push_mpls(psh_m, act, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\t*a_len += sizeof(struct nfp_fl_push_mpls);\n\t\tbreak;\n\tcase FLOW_ACTION_MPLS_POP:\n\t\tif (*a_len +\n\t\t    sizeof(struct nfp_fl_pop_mpls) > NFP_FL_MAX_A_SIZ) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at pop MPLS\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tpop_m = (struct nfp_fl_pop_mpls *)&nfp_fl->action_data[*a_len];\n\t\tnfp_fl->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);\n\n\t\tnfp_fl_pop_mpls(pop_m, act);\n\t\t*a_len += sizeof(struct nfp_fl_pop_mpls);\n\t\tbreak;\n\tcase FLOW_ACTION_MPLS_MANGLE:\n\t\tif (*a_len +\n\t\t    sizeof(struct nfp_fl_set_mpls) > NFP_FL_MAX_A_SIZ) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: maximum allowed action list size exceeded at set MPLS\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tset_m = (struct nfp_fl_set_mpls *)&nfp_fl->action_data[*a_len];\n\t\tnfp_fl->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);\n\n\t\tnfp_fl_set_mpls(set_m, act);\n\t\t*a_len += sizeof(struct nfp_fl_set_mpls);\n\t\tbreak;\n\tcase FLOW_ACTION_PTYPE:\n\t\t \n\t\tif (act->ptype != PACKET_HOST)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t*pkt_host = true;\n\t\tbreak;\n\tcase FLOW_ACTION_POLICE:\n\t\tif (!(fl_priv->flower_ext_feats & NFP_FL_FEATS_QOS_METER)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"unsupported offload: unsupported police action in action list\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\terr = nfp_flower_meter_action(app, act, nfp_fl, a_len, netdev,\n\t\t\t\t\t      extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tNL_SET_ERR_MSG_MOD(extack, \"unsupported offload: unsupported action in action list\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic bool nfp_fl_check_mangle_start(struct flow_action *flow_act,\n\t\t\t\t      int current_act_idx)\n{\n\tstruct flow_action_entry current_act;\n\tstruct flow_action_entry prev_act;\n\n\tcurrent_act = flow_act->entries[current_act_idx];\n\tif (current_act.id != FLOW_ACTION_MANGLE)\n\t\treturn false;\n\n\tif (current_act_idx == 0)\n\t\treturn true;\n\n\tprev_act = flow_act->entries[current_act_idx - 1];\n\n\treturn prev_act.id != FLOW_ACTION_MANGLE;\n}\n\nstatic bool nfp_fl_check_mangle_end(struct flow_action *flow_act,\n\t\t\t\t    int current_act_idx)\n{\n\tstruct flow_action_entry current_act;\n\tstruct flow_action_entry next_act;\n\n\tcurrent_act = flow_act->entries[current_act_idx];\n\tif (current_act.id != FLOW_ACTION_MANGLE)\n\t\treturn false;\n\n\tif (current_act_idx == flow_act->num_entries)\n\t\treturn true;\n\n\tnext_act = flow_act->entries[current_act_idx + 1];\n\n\treturn next_act.id != FLOW_ACTION_MANGLE;\n}\n\nint nfp_flower_compile_action(struct nfp_app *app,\n\t\t\t      struct flow_rule *rule,\n\t\t\t      struct net_device *netdev,\n\t\t\t      struct nfp_fl_payload *nfp_flow,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tint act_len, act_cnt, err, tun_out_cnt, out_cnt, i;\n\tstruct nfp_flower_pedit_acts set_act;\n\tenum nfp_flower_tun_type tun_type;\n\tstruct flow_action_entry *act;\n\tbool pkt_host = false;\n\tu32 csum_updated = 0;\n\n\tif (!flow_action_hw_stats_check(&rule->action, extack,\n\t\t\t\t\tFLOW_ACTION_HW_STATS_DELAYED_BIT))\n\t\treturn -EOPNOTSUPP;\n\n\tmemset(nfp_flow->action_data, 0, NFP_FL_MAX_A_SIZ);\n\tnfp_flow->meta.act_len = 0;\n\ttun_type = NFP_FL_TUNNEL_NONE;\n\tact_len = 0;\n\tact_cnt = 0;\n\ttun_out_cnt = 0;\n\tout_cnt = 0;\n\n\tflow_action_for_each(i, act, &rule->action) {\n\t\tif (nfp_fl_check_mangle_start(&rule->action, i))\n\t\t\tmemset(&set_act, 0, sizeof(set_act));\n\t\terr = nfp_flower_loop_action(app, act, rule, nfp_flow, &act_len,\n\t\t\t\t\t     netdev, &tun_type, &tun_out_cnt,\n\t\t\t\t\t     &out_cnt, &csum_updated,\n\t\t\t\t\t     &set_act, &pkt_host, extack, i);\n\t\tif (err)\n\t\t\treturn err;\n\t\tact_cnt++;\n\t\tif (nfp_fl_check_mangle_end(&rule->action, i))\n\t\t\tnfp_fl_commit_mangle(rule,\n\t\t\t\t\t     &nfp_flow->action_data[act_len],\n\t\t\t\t\t     &act_len, &set_act, &csum_updated);\n\t}\n\n\t \n\tif (act_cnt > 1)\n\t\tnfp_flow->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);\n\n\tnfp_flow->meta.act_len = act_len;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}