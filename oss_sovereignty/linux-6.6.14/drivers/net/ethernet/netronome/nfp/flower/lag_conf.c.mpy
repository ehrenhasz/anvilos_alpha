{
  "module_name": "lag_conf.c",
  "hash_id": "a8038b0df6ece7dd15b14ca3bee5d6d0f0adef15650db9ff174f5ffa9e836ebd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/netronome/nfp/flower/lag_conf.c",
  "human_readable_source": "\n \n\n#include \"main.h\"\n\n \n#define NFP_FL_LAG_LAST\t\t\tBIT(1)\n#define NFP_FL_LAG_FIRST\t\tBIT(2)\n#define NFP_FL_LAG_DATA\t\t\tBIT(3)\n#define NFP_FL_LAG_XON\t\t\tBIT(4)\n#define NFP_FL_LAG_SYNC\t\t\tBIT(5)\n#define NFP_FL_LAG_SWITCH\t\tBIT(6)\n#define NFP_FL_LAG_RESET\t\tBIT(7)\n\n \n#define NFP_PORT_LAG_LINK_UP\t\tBIT(0)\n#define NFP_PORT_LAG_TX_ENABLED\t\tBIT(1)\n#define NFP_PORT_LAG_CHANGED\t\tBIT(2)\n\nenum nfp_fl_lag_batch {\n\tNFP_FL_LAG_BATCH_FIRST,\n\tNFP_FL_LAG_BATCH_MEMBER,\n\tNFP_FL_LAG_BATCH_FINISHED\n};\n\n \nstruct nfp_flower_cmsg_lag_config {\n\tu8 ctrl_flags;\n\tu8 reserved[2];\n\tu8 ttl;\n\t__be32 pkt_number;\n\t__be32 batch_ver;\n\t__be32 group_id;\n\t__be32 group_inst;\n\t__be32 members[];\n};\n\n \nstruct nfp_fl_lag_group {\n\tunsigned int group_id;\n\tu8 group_inst;\n\tstruct list_head list;\n\tstruct net_device *master_ndev;\n\tbool dirty;\n\tbool offloaded;\n\tbool to_remove;\n\tbool to_destroy;\n\tunsigned int slave_cnt;\n};\n\n#define NFP_FL_LAG_PKT_NUMBER_MASK\tGENMASK(30, 0)\n#define NFP_FL_LAG_VERSION_MASK\t\tGENMASK(22, 0)\n#define NFP_FL_LAG_HOST_TTL\t\t0xff\n\n \n#define NFP_FL_LAG_SYNC_ID\t\t0\n#define NFP_FL_LAG_GROUP_MIN\t\t1  \n#define NFP_FL_LAG_GROUP_MAX\t\t32  \n\n \n#define NFP_FL_LAG_DELAY\t\t(msecs_to_jiffies(2))\n\n#define NFP_FL_LAG_RETRANS_LIMIT\t100  \n\nstatic unsigned int nfp_fl_get_next_pkt_number(struct nfp_fl_lag *lag)\n{\n\tlag->pkt_num++;\n\tlag->pkt_num &= NFP_FL_LAG_PKT_NUMBER_MASK;\n\n\treturn lag->pkt_num;\n}\n\nstatic void nfp_fl_increment_version(struct nfp_fl_lag *lag)\n{\n\t \n\tlag->batch_ver += 2;\n\tlag->batch_ver &= NFP_FL_LAG_VERSION_MASK;\n\n\t \n\tif (!lag->batch_ver)\n\t\tlag->batch_ver += 2;\n}\n\nstatic struct nfp_fl_lag_group *\nnfp_fl_lag_group_create(struct nfp_fl_lag *lag, struct net_device *master)\n{\n\tstruct nfp_fl_lag_group *group;\n\tstruct nfp_flower_priv *priv;\n\tint id;\n\n\tpriv = container_of(lag, struct nfp_flower_priv, nfp_lag);\n\n\tid = ida_simple_get(&lag->ida_handle, NFP_FL_LAG_GROUP_MIN,\n\t\t\t    NFP_FL_LAG_GROUP_MAX, GFP_KERNEL);\n\tif (id < 0) {\n\t\tnfp_flower_cmsg_warn(priv->app,\n\t\t\t\t     \"No more bonding groups available\\n\");\n\t\treturn ERR_PTR(id);\n\t}\n\n\tgroup = kmalloc(sizeof(*group), GFP_KERNEL);\n\tif (!group) {\n\t\tida_simple_remove(&lag->ida_handle, id);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tgroup->group_id = id;\n\tgroup->master_ndev = master;\n\tgroup->dirty = true;\n\tgroup->offloaded = false;\n\tgroup->to_remove = false;\n\tgroup->to_destroy = false;\n\tgroup->slave_cnt = 0;\n\tgroup->group_inst = ++lag->global_inst;\n\tlist_add_tail(&group->list, &lag->group_list);\n\n\treturn group;\n}\n\nstatic struct nfp_fl_lag_group *\nnfp_fl_lag_find_group_for_master_with_lag(struct nfp_fl_lag *lag,\n\t\t\t\t\t  struct net_device *master)\n{\n\tstruct nfp_fl_lag_group *entry;\n\n\tif (!master)\n\t\treturn NULL;\n\n\tlist_for_each_entry(entry, &lag->group_list, list)\n\t\tif (entry->master_ndev == master)\n\t\t\treturn entry;\n\n\treturn NULL;\n}\n\nstatic int nfp_fl_lag_get_group_info(struct nfp_app *app,\n\t\t\t\t     struct net_device *netdev,\n\t\t\t\t     __be16 *group_id,\n\t\t\t\t     u8 *batch_ver,\n\t\t\t\t     u8 *group_inst)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_fl_lag_group *group = NULL;\n\t__be32 temp_vers;\n\n\tmutex_lock(&priv->nfp_lag.lock);\n\tgroup = nfp_fl_lag_find_group_for_master_with_lag(&priv->nfp_lag,\n\t\t\t\t\t\t\t  netdev);\n\tif (!group) {\n\t\tmutex_unlock(&priv->nfp_lag.lock);\n\t\treturn -ENOENT;\n\t}\n\n\tif (group_id)\n\t\t*group_id = cpu_to_be16(group->group_id);\n\n\tif (batch_ver) {\n\t\ttemp_vers = cpu_to_be32(priv->nfp_lag.batch_ver <<\n\t\t\t\t\tNFP_FL_PRE_LAG_VER_OFF);\n\t\tmemcpy(batch_ver, &temp_vers, 3);\n\t}\n\n\tif (group_inst)\n\t\t*group_inst = group->group_inst;\n\n\tmutex_unlock(&priv->nfp_lag.lock);\n\n\treturn 0;\n}\n\nint nfp_flower_lag_populate_pre_action(struct nfp_app *app,\n\t\t\t\t       struct net_device *master,\n\t\t\t\t       struct nfp_fl_pre_lag *pre_act,\n\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tif (nfp_fl_lag_get_group_info(app, master, &pre_act->group_id,\n\t\t\t\t      pre_act->lag_version,\n\t\t\t\t      &pre_act->instance)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"invalid entry: group does not exist for LAG action\");\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\nvoid nfp_flower_lag_get_info_from_netdev(struct nfp_app *app,\n\t\t\t\t\t struct net_device *netdev,\n\t\t\t\t\t struct nfp_tun_neigh_lag *lag)\n{\n\tnfp_fl_lag_get_group_info(app, netdev, NULL,\n\t\t\t\t  lag->lag_version, &lag->lag_instance);\n}\n\nint nfp_flower_lag_get_output_id(struct nfp_app *app, struct net_device *master)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_fl_lag_group *group = NULL;\n\tint group_id = -ENOENT;\n\n\tmutex_lock(&priv->nfp_lag.lock);\n\tgroup = nfp_fl_lag_find_group_for_master_with_lag(&priv->nfp_lag,\n\t\t\t\t\t\t\t  master);\n\tif (group)\n\t\tgroup_id = group->group_id;\n\tmutex_unlock(&priv->nfp_lag.lock);\n\n\treturn group_id;\n}\n\nstatic int\nnfp_fl_lag_config_group(struct nfp_fl_lag *lag, struct nfp_fl_lag_group *group,\n\t\t\tstruct net_device **active_members,\n\t\t\tunsigned int member_cnt, enum nfp_fl_lag_batch *batch)\n{\n\tstruct nfp_flower_cmsg_lag_config *cmsg_payload;\n\tstruct nfp_flower_priv *priv;\n\tunsigned long int flags;\n\tunsigned int size, i;\n\tstruct sk_buff *skb;\n\n\tpriv = container_of(lag, struct nfp_flower_priv, nfp_lag);\n\tsize = sizeof(*cmsg_payload) + sizeof(__be32) * member_cnt;\n\tskb = nfp_flower_cmsg_alloc(priv->app, size,\n\t\t\t\t    NFP_FLOWER_CMSG_TYPE_LAG_CONFIG,\n\t\t\t\t    GFP_KERNEL);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmsg_payload = nfp_flower_cmsg_get_data(skb);\n\tflags = 0;\n\n\t \n\tif (*batch == NFP_FL_LAG_BATCH_FIRST) {\n\t\tflags |= NFP_FL_LAG_FIRST;\n\t\tnfp_fl_increment_version(lag);\n\t\t*batch = NFP_FL_LAG_BATCH_MEMBER;\n\t}\n\n\t \n\tif (lag->rst_cfg) {\n\t\tflags |= NFP_FL_LAG_RESET;\n\t\t*batch = NFP_FL_LAG_BATCH_FINISHED;\n\t}\n\n\t \n\tif (*batch == NFP_FL_LAG_BATCH_FINISHED) {\n\t\tflags |= NFP_FL_LAG_SWITCH | NFP_FL_LAG_LAST;\n\t\tlag->rst_cfg = false;\n\t\tcmsg_payload->group_id = cpu_to_be32(NFP_FL_LAG_SYNC_ID);\n\t\tcmsg_payload->group_inst = 0;\n\t} else {\n\t\tcmsg_payload->group_id = cpu_to_be32(group->group_id);\n\t\tcmsg_payload->group_inst = cpu_to_be32(group->group_inst);\n\t}\n\n\tcmsg_payload->reserved[0] = 0;\n\tcmsg_payload->reserved[1] = 0;\n\tcmsg_payload->ttl = NFP_FL_LAG_HOST_TTL;\n\tcmsg_payload->ctrl_flags = flags;\n\tcmsg_payload->batch_ver = cpu_to_be32(lag->batch_ver);\n\tcmsg_payload->pkt_number = cpu_to_be32(nfp_fl_get_next_pkt_number(lag));\n\n\tfor (i = 0; i < member_cnt; i++)\n\t\tcmsg_payload->members[i] =\n\t\t\tcpu_to_be32(nfp_repr_get_port_id(active_members[i]));\n\n\tnfp_ctrl_tx(priv->app->ctrl, skb);\n\treturn 0;\n}\n\nstatic void nfp_fl_lag_do_work(struct work_struct *work)\n{\n\tenum nfp_fl_lag_batch batch = NFP_FL_LAG_BATCH_FIRST;\n\tstruct nfp_fl_lag_group *entry, *storage;\n\tstruct delayed_work *delayed_work;\n\tstruct nfp_flower_priv *priv;\n\tstruct nfp_fl_lag *lag;\n\tint err;\n\n\tdelayed_work = to_delayed_work(work);\n\tlag = container_of(delayed_work, struct nfp_fl_lag, work);\n\tpriv = container_of(lag, struct nfp_flower_priv, nfp_lag);\n\n\tmutex_lock(&lag->lock);\n\tlist_for_each_entry_safe(entry, storage, &lag->group_list, list) {\n\t\tstruct net_device *iter_netdev, **acti_netdevs;\n\t\tstruct nfp_flower_repr_priv *repr_priv;\n\t\tint active_count = 0, slaves = 0;\n\t\tstruct nfp_repr *repr;\n\t\tunsigned long *flags;\n\n\t\tif (entry->to_remove) {\n\t\t\t \n\t\t\terr = nfp_fl_lag_config_group(lag, entry, NULL, 0,\n\t\t\t\t\t\t      &batch);\n\t\t\tif (!err) {\n\t\t\t\tentry->to_remove = false;\n\t\t\t\tentry->offloaded = false;\n\t\t\t} else {\n\t\t\t\tnfp_flower_cmsg_warn(priv->app,\n\t\t\t\t\t\t     \"group delete failed\\n\");\n\t\t\t\tschedule_delayed_work(&lag->work,\n\t\t\t\t\t\t      NFP_FL_LAG_DELAY);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (entry->to_destroy) {\n\t\t\t\tida_simple_remove(&lag->ida_handle,\n\t\t\t\t\t\t  entry->group_id);\n\t\t\t\tlist_del(&entry->list);\n\t\t\t\tkfree(entry);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tacti_netdevs = kmalloc_array(entry->slave_cnt,\n\t\t\t\t\t     sizeof(*acti_netdevs), GFP_KERNEL);\n\n\t\t \n\t\trcu_read_lock();\n\t\tfor_each_netdev_in_bond_rcu(entry->master_ndev, iter_netdev) {\n\t\t\tif (!nfp_netdev_is_nfp_repr(iter_netdev)) {\n\t\t\t\tslaves = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\trepr = netdev_priv(iter_netdev);\n\n\t\t\tif (repr->app != priv->app) {\n\t\t\t\tslaves = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tslaves++;\n\t\t\tif (slaves > entry->slave_cnt)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\trepr_priv = repr->app_priv;\n\t\t\tflags = &repr_priv->lag_port_flags;\n\n\t\t\tif (*flags & NFP_PORT_LAG_CHANGED) {\n\t\t\t\t*flags &= ~NFP_PORT_LAG_CHANGED;\n\t\t\t\tentry->dirty = true;\n\t\t\t}\n\n\t\t\tif ((*flags & NFP_PORT_LAG_TX_ENABLED) &&\n\t\t\t    (*flags & NFP_PORT_LAG_LINK_UP))\n\t\t\t\tacti_netdevs[active_count++] = iter_netdev;\n\t\t}\n\t\trcu_read_unlock();\n\n\t\tif (slaves != entry->slave_cnt || !entry->dirty) {\n\t\t\tkfree(acti_netdevs);\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = nfp_fl_lag_config_group(lag, entry, acti_netdevs,\n\t\t\t\t\t      active_count, &batch);\n\t\tif (!err) {\n\t\t\tentry->offloaded = true;\n\t\t\tentry->dirty = false;\n\t\t} else {\n\t\t\tnfp_flower_cmsg_warn(priv->app,\n\t\t\t\t\t     \"group offload failed\\n\");\n\t\t\tschedule_delayed_work(&lag->work, NFP_FL_LAG_DELAY);\n\t\t}\n\n\t\tkfree(acti_netdevs);\n\t}\n\n\t \n\tif (batch == NFP_FL_LAG_BATCH_MEMBER) {\n\t\tbatch = NFP_FL_LAG_BATCH_FINISHED;\n\t\terr = nfp_fl_lag_config_group(lag, NULL, NULL, 0, &batch);\n\t\tif (err)\n\t\t\tnfp_flower_cmsg_warn(priv->app,\n\t\t\t\t\t     \"group batch end cmsg failed\\n\");\n\t}\n\n\tmutex_unlock(&lag->lock);\n}\n\nstatic int\nnfp_fl_lag_put_unprocessed(struct nfp_fl_lag *lag, struct sk_buff *skb)\n{\n\tstruct nfp_flower_cmsg_lag_config *cmsg_payload;\n\n\tcmsg_payload = nfp_flower_cmsg_get_data(skb);\n\tif (be32_to_cpu(cmsg_payload->group_id) >= NFP_FL_LAG_GROUP_MAX)\n\t\treturn -EINVAL;\n\n\t \n\tif (skb_queue_len(&lag->retrans_skbs) >= NFP_FL_LAG_RETRANS_LIMIT)\n\t\treturn -ENOSPC;\n\n\t__skb_queue_tail(&lag->retrans_skbs, skb);\n\n\treturn 0;\n}\n\nstatic void nfp_fl_send_unprocessed(struct nfp_fl_lag *lag)\n{\n\tstruct nfp_flower_priv *priv;\n\tstruct sk_buff *skb;\n\n\tpriv = container_of(lag, struct nfp_flower_priv, nfp_lag);\n\n\twhile ((skb = __skb_dequeue(&lag->retrans_skbs)))\n\t\tnfp_ctrl_tx(priv->app->ctrl, skb);\n}\n\nbool nfp_flower_lag_unprocessed_msg(struct nfp_app *app, struct sk_buff *skb)\n{\n\tstruct nfp_flower_cmsg_lag_config *cmsg_payload;\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_fl_lag_group *group_entry;\n\tunsigned long int flags;\n\tbool store_skb = false;\n\tint err;\n\n\tcmsg_payload = nfp_flower_cmsg_get_data(skb);\n\tflags = cmsg_payload->ctrl_flags;\n\n\t \n\n\t \n\tif (flags & NFP_FL_LAG_DATA)\n\t\tif (!nfp_fl_lag_put_unprocessed(&priv->nfp_lag, skb))\n\t\t\tstore_skb = true;\n\n\t \n\tif (flags & NFP_FL_LAG_XON)\n\t\tnfp_fl_send_unprocessed(&priv->nfp_lag);\n\n\t \n\tif (flags & NFP_FL_LAG_SYNC) {\n\t\t \n\n\t\t__skb_queue_purge(&priv->nfp_lag.retrans_skbs);\n\n\t\tmutex_lock(&priv->nfp_lag.lock);\n\t\tlist_for_each_entry(group_entry, &priv->nfp_lag.group_list,\n\t\t\t\t    list)\n\t\t\tgroup_entry->dirty = true;\n\n\t\terr = nfp_flower_lag_reset(&priv->nfp_lag);\n\t\tif (err)\n\t\t\tnfp_flower_cmsg_warn(priv->app,\n\t\t\t\t\t     \"mem err in group reset msg\\n\");\n\t\tmutex_unlock(&priv->nfp_lag.lock);\n\n\t\tschedule_delayed_work(&priv->nfp_lag.work, 0);\n\t}\n\n\treturn store_skb;\n}\n\nstatic void\nnfp_fl_lag_schedule_group_remove(struct nfp_fl_lag *lag,\n\t\t\t\t struct nfp_fl_lag_group *group)\n{\n\tgroup->to_remove = true;\n\n\tschedule_delayed_work(&lag->work, NFP_FL_LAG_DELAY);\n}\n\nstatic void\nnfp_fl_lag_schedule_group_delete(struct nfp_fl_lag *lag,\n\t\t\t\t struct net_device *master)\n{\n\tstruct nfp_fl_lag_group *group;\n\tstruct nfp_flower_priv *priv;\n\n\tpriv = container_of(lag, struct nfp_flower_priv, nfp_lag);\n\n\tif (!netif_is_bond_master(master))\n\t\treturn;\n\n\tmutex_lock(&lag->lock);\n\tgroup = nfp_fl_lag_find_group_for_master_with_lag(lag, master);\n\tif (!group) {\n\t\tmutex_unlock(&lag->lock);\n\t\tnfp_warn(priv->app->cpp, \"untracked bond got unregistered %s\\n\",\n\t\t\t netdev_name(master));\n\t\treturn;\n\t}\n\n\tgroup->to_remove = true;\n\tgroup->to_destroy = true;\n\tmutex_unlock(&lag->lock);\n\n\tschedule_delayed_work(&lag->work, NFP_FL_LAG_DELAY);\n}\n\nstatic int\nnfp_fl_lag_changeupper_event(struct nfp_fl_lag *lag,\n\t\t\t     struct netdev_notifier_changeupper_info *info)\n{\n\tstruct net_device *upper = info->upper_dev, *iter_netdev;\n\tstruct netdev_lag_upper_info *lag_upper_info;\n\tstruct nfp_fl_lag_group *group;\n\tstruct nfp_flower_priv *priv;\n\tunsigned int slave_count = 0;\n\tbool can_offload = true;\n\tstruct nfp_repr *repr;\n\n\tif (!netif_is_lag_master(upper))\n\t\treturn 0;\n\n\tpriv = container_of(lag, struct nfp_flower_priv, nfp_lag);\n\n\trcu_read_lock();\n\tfor_each_netdev_in_bond_rcu(upper, iter_netdev) {\n\t\tif (!nfp_netdev_is_nfp_repr(iter_netdev)) {\n\t\t\tcan_offload = false;\n\t\t\tbreak;\n\t\t}\n\t\trepr = netdev_priv(iter_netdev);\n\n\t\t \n\t\tif (repr->app != priv->app) {\n\t\t\tcan_offload = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tslave_count++;\n\t}\n\trcu_read_unlock();\n\n\tlag_upper_info = info->upper_info;\n\n\t \n\tif (lag_upper_info &&\n\t    lag_upper_info->tx_type != NETDEV_LAG_TX_TYPE_ACTIVEBACKUP &&\n\t    (lag_upper_info->tx_type != NETDEV_LAG_TX_TYPE_HASH ||\n\t     (lag_upper_info->hash_type != NETDEV_LAG_HASH_L34 &&\n\t      lag_upper_info->hash_type != NETDEV_LAG_HASH_E34 &&\n\t      lag_upper_info->hash_type != NETDEV_LAG_HASH_UNKNOWN))) {\n\t\tcan_offload = false;\n\t\tnfp_flower_cmsg_warn(priv->app,\n\t\t\t\t     \"Unable to offload tx_type %u hash %u\\n\",\n\t\t\t\t     lag_upper_info->tx_type,\n\t\t\t\t     lag_upper_info->hash_type);\n\t}\n\n\tmutex_lock(&lag->lock);\n\tgroup = nfp_fl_lag_find_group_for_master_with_lag(lag, upper);\n\n\tif (slave_count == 0 || !can_offload) {\n\t\t \n\t\tif (group && group->offloaded)\n\t\t\tnfp_fl_lag_schedule_group_remove(lag, group);\n\n\t\tmutex_unlock(&lag->lock);\n\t\treturn 0;\n\t}\n\n\tif (!group) {\n\t\tgroup = nfp_fl_lag_group_create(lag, upper);\n\t\tif (IS_ERR(group)) {\n\t\t\tmutex_unlock(&lag->lock);\n\t\t\treturn PTR_ERR(group);\n\t\t}\n\t}\n\n\tgroup->dirty = true;\n\tgroup->slave_cnt = slave_count;\n\n\t \n\tgroup->to_remove = false;\n\tmutex_unlock(&lag->lock);\n\n\tschedule_delayed_work(&lag->work, NFP_FL_LAG_DELAY);\n\treturn 0;\n}\n\nstatic void\nnfp_fl_lag_changels_event(struct nfp_fl_lag *lag, struct net_device *netdev,\n\t\t\t  struct netdev_notifier_changelowerstate_info *info)\n{\n\tstruct netdev_lag_lower_state_info *lag_lower_info;\n\tstruct nfp_flower_repr_priv *repr_priv;\n\tstruct nfp_flower_priv *priv;\n\tstruct nfp_repr *repr;\n\tunsigned long *flags;\n\n\tif (!netif_is_lag_port(netdev) || !nfp_netdev_is_nfp_repr(netdev))\n\t\treturn;\n\n\tlag_lower_info = info->lower_state_info;\n\tif (!lag_lower_info)\n\t\treturn;\n\n\tpriv = container_of(lag, struct nfp_flower_priv, nfp_lag);\n\trepr = netdev_priv(netdev);\n\n\t \n\tif (repr->app != priv->app)\n\t\treturn;\n\n\trepr_priv = repr->app_priv;\n\tflags = &repr_priv->lag_port_flags;\n\n\tmutex_lock(&lag->lock);\n\tif (lag_lower_info->link_up)\n\t\t*flags |= NFP_PORT_LAG_LINK_UP;\n\telse\n\t\t*flags &= ~NFP_PORT_LAG_LINK_UP;\n\n\tif (lag_lower_info->tx_enabled)\n\t\t*flags |= NFP_PORT_LAG_TX_ENABLED;\n\telse\n\t\t*flags &= ~NFP_PORT_LAG_TX_ENABLED;\n\n\t*flags |= NFP_PORT_LAG_CHANGED;\n\tmutex_unlock(&lag->lock);\n\n\tschedule_delayed_work(&lag->work, NFP_FL_LAG_DELAY);\n}\n\nint nfp_flower_lag_netdev_event(struct nfp_flower_priv *priv,\n\t\t\t\tstruct net_device *netdev,\n\t\t\t\tunsigned long event, void *ptr)\n{\n\tstruct nfp_fl_lag *lag = &priv->nfp_lag;\n\tint err;\n\n\tswitch (event) {\n\tcase NETDEV_CHANGEUPPER:\n\t\terr = nfp_fl_lag_changeupper_event(lag, ptr);\n\t\tif (err)\n\t\t\treturn NOTIFY_BAD;\n\t\treturn NOTIFY_OK;\n\tcase NETDEV_CHANGELOWERSTATE:\n\t\tnfp_fl_lag_changels_event(lag, netdev, ptr);\n\t\treturn NOTIFY_OK;\n\tcase NETDEV_UNREGISTER:\n\t\tnfp_fl_lag_schedule_group_delete(lag, netdev);\n\t\treturn NOTIFY_OK;\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\nint nfp_flower_lag_reset(struct nfp_fl_lag *lag)\n{\n\tenum nfp_fl_lag_batch batch = NFP_FL_LAG_BATCH_FIRST;\n\n\tlag->rst_cfg = true;\n\treturn nfp_fl_lag_config_group(lag, NULL, NULL, 0, &batch);\n}\n\nvoid nfp_flower_lag_init(struct nfp_fl_lag *lag)\n{\n\tINIT_DELAYED_WORK(&lag->work, nfp_fl_lag_do_work);\n\tINIT_LIST_HEAD(&lag->group_list);\n\tmutex_init(&lag->lock);\n\tida_init(&lag->ida_handle);\n\n\t__skb_queue_head_init(&lag->retrans_skbs);\n\n\t \n\tnfp_fl_increment_version(lag);\n}\n\nvoid nfp_flower_lag_cleanup(struct nfp_fl_lag *lag)\n{\n\tstruct nfp_fl_lag_group *entry, *storage;\n\n\tcancel_delayed_work_sync(&lag->work);\n\n\t__skb_queue_purge(&lag->retrans_skbs);\n\n\t \n\tmutex_lock(&lag->lock);\n\tlist_for_each_entry_safe(entry, storage, &lag->group_list, list) {\n\t\tlist_del(&entry->list);\n\t\tkfree(entry);\n\t}\n\tmutex_unlock(&lag->lock);\n\tmutex_destroy(&lag->lock);\n\tida_destroy(&lag->ida_handle);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}