{
  "module_name": "tunnel_conf.c",
  "hash_id": "93d5b0d17abb055172237a9f22b821a0c48600ac5010104bb73a1567669c93cd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/netronome/nfp/flower/tunnel_conf.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <linux/inetdevice.h>\n#include <net/netevent.h>\n#include <linux/idr.h>\n#include <net/dst_metadata.h>\n#include <net/arp.h>\n\n#include \"cmsg.h\"\n#include \"main.h\"\n#include \"../nfp_net_repr.h\"\n#include \"../nfp_net.h\"\n\n#define NFP_FL_MAX_ROUTES               32\n\n#define NFP_TUN_PRE_TUN_RULE_LIMIT\t32\n#define NFP_TUN_PRE_TUN_RULE_DEL\tBIT(0)\n#define NFP_TUN_PRE_TUN_IDX_BIT\t\tBIT(3)\n#define NFP_TUN_PRE_TUN_IPV6_BIT\tBIT(7)\n\n \nstruct nfp_tun_pre_tun_rule {\n\t__be32 flags;\n\t__be16 port_idx;\n\t__be16 vlan_tci;\n\t__be32 host_ctx_id;\n};\n\n \nstruct nfp_tun_active_tuns {\n\t__be32 seq;\n\t__be32 count;\n\t__be32 flags;\n\tstruct route_ip_info {\n\t\t__be32 ipv4;\n\t\t__be32 egress_port;\n\t\t__be32 extra[2];\n\t} tun_info[];\n};\n\n \nstruct nfp_tun_active_tuns_v6 {\n\t__be32 seq;\n\t__be32 count;\n\t__be32 flags;\n\tstruct route_ip_info_v6 {\n\t\tstruct in6_addr ipv6;\n\t\t__be32 egress_port;\n\t\t__be32 extra[2];\n\t} tun_info[];\n};\n\n \nstruct nfp_tun_req_route_ipv4 {\n\t__be32 ingress_port;\n\t__be32 ipv4_addr;\n\t__be32 reserved[2];\n};\n\n \nstruct nfp_tun_req_route_ipv6 {\n\t__be32 ingress_port;\n\tstruct in6_addr ipv6_addr;\n};\n\n \nstruct nfp_offloaded_route {\n\tstruct list_head list;\n\tu8 ip_add[];\n};\n\n#define NFP_FL_IPV4_ADDRS_MAX        32\n\n \nstruct nfp_tun_ipv4_addr {\n\t__be32 count;\n\t__be32 ipv4_addr[NFP_FL_IPV4_ADDRS_MAX];\n};\n\n \nstruct nfp_ipv4_addr_entry {\n\t__be32 ipv4_addr;\n\tint ref_count;\n\tstruct list_head list;\n};\n\n#define NFP_FL_IPV6_ADDRS_MAX        4\n\n \nstruct nfp_tun_ipv6_addr {\n\t__be32 count;\n\tstruct in6_addr ipv6_addr[NFP_FL_IPV6_ADDRS_MAX];\n};\n\n#define NFP_TUN_MAC_OFFLOAD_DEL_FLAG\t0x2\n\n \nstruct nfp_tun_mac_addr_offload {\n\t__be16 flags;\n\t__be16 count;\n\t__be16 index;\n\tu8 addr[ETH_ALEN];\n};\n\n \nstruct nfp_neigh_update_work {\n\tstruct work_struct work;\n\tstruct neighbour *n;\n\tstruct nfp_app *app;\n};\n\nenum nfp_flower_mac_offload_cmd {\n\tNFP_TUNNEL_MAC_OFFLOAD_ADD =\t\t0,\n\tNFP_TUNNEL_MAC_OFFLOAD_DEL =\t\t1,\n\tNFP_TUNNEL_MAC_OFFLOAD_MOD =\t\t2,\n};\n\n#define NFP_MAX_MAC_INDEX       0xff\n\n \nstruct nfp_tun_offloaded_mac {\n\tstruct rhash_head ht_node;\n\tu8 addr[ETH_ALEN];\n\tu16 index;\n\tint ref_count;\n\tstruct list_head repr_list;\n\tint bridge_count;\n};\n\nstatic const struct rhashtable_params offloaded_macs_params = {\n\t.key_offset\t= offsetof(struct nfp_tun_offloaded_mac, addr),\n\t.head_offset\t= offsetof(struct nfp_tun_offloaded_mac, ht_node),\n\t.key_len\t= ETH_ALEN,\n\t.automatic_shrinking\t= true,\n};\n\nvoid nfp_tunnel_keep_alive(struct nfp_app *app, struct sk_buff *skb)\n{\n\tstruct nfp_tun_active_tuns *payload;\n\tstruct net_device *netdev;\n\tint count, i, pay_len;\n\tstruct neighbour *n;\n\t__be32 ipv4_addr;\n\tu32 port;\n\n\tpayload = nfp_flower_cmsg_get_data(skb);\n\tcount = be32_to_cpu(payload->count);\n\tif (count > NFP_FL_MAX_ROUTES) {\n\t\tnfp_flower_cmsg_warn(app, \"Tunnel keep-alive request exceeds max routes.\\n\");\n\t\treturn;\n\t}\n\n\tpay_len = nfp_flower_cmsg_get_data_len(skb);\n\tif (pay_len != struct_size(payload, tun_info, count)) {\n\t\tnfp_flower_cmsg_warn(app, \"Corruption in tunnel keep-alive message.\\n\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tfor (i = 0; i < count; i++) {\n\t\tipv4_addr = payload->tun_info[i].ipv4;\n\t\tport = be32_to_cpu(payload->tun_info[i].egress_port);\n\t\tnetdev = nfp_app_dev_get(app, port, NULL);\n\t\tif (!netdev)\n\t\t\tcontinue;\n\n\t\tn = neigh_lookup(&arp_tbl, &ipv4_addr, netdev);\n\t\tif (!n)\n\t\t\tcontinue;\n\n\t\t \n\t\tneigh_event_send(n, NULL);\n\t\tneigh_release(n);\n\t}\n\trcu_read_unlock();\n}\n\nvoid nfp_tunnel_keep_alive_v6(struct nfp_app *app, struct sk_buff *skb)\n{\n#if IS_ENABLED(CONFIG_IPV6)\n\tstruct nfp_tun_active_tuns_v6 *payload;\n\tstruct net_device *netdev;\n\tint count, i, pay_len;\n\tstruct neighbour *n;\n\tvoid *ipv6_add;\n\tu32 port;\n\n\tpayload = nfp_flower_cmsg_get_data(skb);\n\tcount = be32_to_cpu(payload->count);\n\tif (count > NFP_FL_IPV6_ADDRS_MAX) {\n\t\tnfp_flower_cmsg_warn(app, \"IPv6 tunnel keep-alive request exceeds max routes.\\n\");\n\t\treturn;\n\t}\n\n\tpay_len = nfp_flower_cmsg_get_data_len(skb);\n\tif (pay_len != struct_size(payload, tun_info, count)) {\n\t\tnfp_flower_cmsg_warn(app, \"Corruption in tunnel keep-alive message.\\n\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tfor (i = 0; i < count; i++) {\n\t\tipv6_add = &payload->tun_info[i].ipv6;\n\t\tport = be32_to_cpu(payload->tun_info[i].egress_port);\n\t\tnetdev = nfp_app_dev_get(app, port, NULL);\n\t\tif (!netdev)\n\t\t\tcontinue;\n\n\t\tn = neigh_lookup(&nd_tbl, ipv6_add, netdev);\n\t\tif (!n)\n\t\t\tcontinue;\n\n\t\t \n\t\tneigh_event_send(n, NULL);\n\t\tneigh_release(n);\n\t}\n\trcu_read_unlock();\n#endif\n}\n\nstatic int\nnfp_flower_xmit_tun_conf(struct nfp_app *app, u8 mtype, u16 plen, void *pdata,\n\t\t\t gfp_t flag)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct sk_buff *skb;\n\tunsigned char *msg;\n\n\tif (!(priv->flower_ext_feats & NFP_FL_FEATS_DECAP_V2) &&\n\t    (mtype == NFP_FLOWER_CMSG_TYPE_TUN_NEIGH ||\n\t     mtype == NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6))\n\t\tplen -= sizeof(struct nfp_tun_neigh_ext);\n\n\tif (!(priv->flower_ext_feats & NFP_FL_FEATS_TUNNEL_NEIGH_LAG) &&\n\t    (mtype == NFP_FLOWER_CMSG_TYPE_TUN_NEIGH ||\n\t     mtype == NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6))\n\t\tplen -= sizeof(struct nfp_tun_neigh_lag);\n\n\tskb = nfp_flower_cmsg_alloc(app, plen, mtype, flag);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tmsg = nfp_flower_cmsg_get_data(skb);\n\tmemcpy(msg, pdata, nfp_flower_cmsg_get_data_len(skb));\n\n\tnfp_ctrl_tx(app->ctrl, skb);\n\treturn 0;\n}\n\nstatic void\nnfp_tun_mutual_link(struct nfp_predt_entry *predt,\n\t\t    struct nfp_neigh_entry *neigh)\n{\n\tstruct nfp_fl_payload *flow_pay = predt->flow_pay;\n\tstruct nfp_tun_neigh_ext *ext;\n\tstruct nfp_tun_neigh *common;\n\n\tif (flow_pay->pre_tun_rule.is_ipv6 != neigh->is_ipv6)\n\t\treturn;\n\n\t \n\tif (neigh->flow)\n\t\treturn;\n\n\tcommon = neigh->is_ipv6 ?\n\t\t &((struct nfp_tun_neigh_v6 *)neigh->payload)->common :\n\t\t &((struct nfp_tun_neigh_v4 *)neigh->payload)->common;\n\text = neigh->is_ipv6 ?\n\t\t &((struct nfp_tun_neigh_v6 *)neigh->payload)->ext :\n\t\t &((struct nfp_tun_neigh_v4 *)neigh->payload)->ext;\n\n\tif (memcmp(flow_pay->pre_tun_rule.loc_mac,\n\t\t   common->src_addr, ETH_ALEN) ||\n\t    memcmp(flow_pay->pre_tun_rule.rem_mac,\n\t\t   common->dst_addr, ETH_ALEN))\n\t\treturn;\n\n\tlist_add(&neigh->list_head, &predt->nn_list);\n\tneigh->flow = predt;\n\text->host_ctx = flow_pay->meta.host_ctx_id;\n\text->vlan_tci = flow_pay->pre_tun_rule.vlan_tci;\n\text->vlan_tpid = flow_pay->pre_tun_rule.vlan_tpid;\n}\n\nstatic void\nnfp_tun_link_predt_entries(struct nfp_app *app,\n\t\t\t   struct nfp_neigh_entry *nn_entry)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_predt_entry *predt, *tmp;\n\n\tlist_for_each_entry_safe(predt, tmp, &priv->predt_list, list_head) {\n\t\tnfp_tun_mutual_link(predt, nn_entry);\n\t}\n}\n\nvoid nfp_tun_link_and_update_nn_entries(struct nfp_app *app,\n\t\t\t\t\tstruct nfp_predt_entry *predt)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_neigh_entry *nn_entry;\n\tstruct rhashtable_iter iter;\n\tsize_t neigh_size;\n\tu8 type;\n\n\trhashtable_walk_enter(&priv->neigh_table, &iter);\n\trhashtable_walk_start(&iter);\n\twhile ((nn_entry = rhashtable_walk_next(&iter)) != NULL) {\n\t\tif (IS_ERR(nn_entry))\n\t\t\tcontinue;\n\t\tnfp_tun_mutual_link(predt, nn_entry);\n\t\tneigh_size = nn_entry->is_ipv6 ?\n\t\t\t     sizeof(struct nfp_tun_neigh_v6) :\n\t\t\t     sizeof(struct nfp_tun_neigh_v4);\n\t\ttype = nn_entry->is_ipv6 ? NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6 :\n\t\t\t\t\t   NFP_FLOWER_CMSG_TYPE_TUN_NEIGH;\n\t\tnfp_flower_xmit_tun_conf(app, type, neigh_size,\n\t\t\t\t\t nn_entry->payload,\n\t\t\t\t\t GFP_ATOMIC);\n\t}\n\trhashtable_walk_stop(&iter);\n\trhashtable_walk_exit(&iter);\n}\n\nstatic void nfp_tun_cleanup_nn_entries(struct nfp_app *app)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_neigh_entry *neigh;\n\tstruct nfp_tun_neigh_ext *ext;\n\tstruct rhashtable_iter iter;\n\tsize_t neigh_size;\n\tu8 type;\n\n\trhashtable_walk_enter(&priv->neigh_table, &iter);\n\trhashtable_walk_start(&iter);\n\twhile ((neigh = rhashtable_walk_next(&iter)) != NULL) {\n\t\tif (IS_ERR(neigh))\n\t\t\tcontinue;\n\t\text = neigh->is_ipv6 ?\n\t\t\t &((struct nfp_tun_neigh_v6 *)neigh->payload)->ext :\n\t\t\t &((struct nfp_tun_neigh_v4 *)neigh->payload)->ext;\n\t\text->host_ctx = cpu_to_be32(U32_MAX);\n\t\text->vlan_tpid = cpu_to_be16(U16_MAX);\n\t\text->vlan_tci = cpu_to_be16(U16_MAX);\n\n\t\tneigh_size = neigh->is_ipv6 ?\n\t\t\t     sizeof(struct nfp_tun_neigh_v6) :\n\t\t\t     sizeof(struct nfp_tun_neigh_v4);\n\t\ttype = neigh->is_ipv6 ? NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6 :\n\t\t\t\t\t   NFP_FLOWER_CMSG_TYPE_TUN_NEIGH;\n\t\tnfp_flower_xmit_tun_conf(app, type, neigh_size, neigh->payload,\n\t\t\t\t\t GFP_ATOMIC);\n\n\t\trhashtable_remove_fast(&priv->neigh_table, &neigh->ht_node,\n\t\t\t\t       neigh_table_params);\n\t\tif (neigh->flow)\n\t\t\tlist_del(&neigh->list_head);\n\t\tkfree(neigh);\n\t}\n\trhashtable_walk_stop(&iter);\n\trhashtable_walk_exit(&iter);\n}\n\nvoid nfp_tun_unlink_and_update_nn_entries(struct nfp_app *app,\n\t\t\t\t\t  struct nfp_predt_entry *predt)\n{\n\tstruct nfp_neigh_entry *neigh, *tmp;\n\tstruct nfp_tun_neigh_ext *ext;\n\tsize_t neigh_size;\n\tu8 type;\n\n\tlist_for_each_entry_safe(neigh, tmp, &predt->nn_list, list_head) {\n\t\text = neigh->is_ipv6 ?\n\t\t\t &((struct nfp_tun_neigh_v6 *)neigh->payload)->ext :\n\t\t\t &((struct nfp_tun_neigh_v4 *)neigh->payload)->ext;\n\t\tneigh->flow = NULL;\n\t\text->host_ctx = cpu_to_be32(U32_MAX);\n\t\text->vlan_tpid = cpu_to_be16(U16_MAX);\n\t\text->vlan_tci = cpu_to_be16(U16_MAX);\n\t\tlist_del(&neigh->list_head);\n\t\tneigh_size = neigh->is_ipv6 ?\n\t\t\t     sizeof(struct nfp_tun_neigh_v6) :\n\t\t\t     sizeof(struct nfp_tun_neigh_v4);\n\t\ttype = neigh->is_ipv6 ? NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6 :\n\t\t\t\t\t   NFP_FLOWER_CMSG_TYPE_TUN_NEIGH;\n\t\tnfp_flower_xmit_tun_conf(app, type, neigh_size, neigh->payload,\n\t\t\t\t\t GFP_ATOMIC);\n\t}\n}\n\nstatic void\nnfp_tun_write_neigh(struct net_device *netdev, struct nfp_app *app,\n\t\t    void *flow, struct neighbour *neigh, bool is_ipv6,\n\t\t    bool override)\n{\n\tbool neigh_invalid = !(neigh->nud_state & NUD_VALID) || neigh->dead;\n\tsize_t neigh_size = is_ipv6 ? sizeof(struct nfp_tun_neigh_v6) :\n\t\t\t    sizeof(struct nfp_tun_neigh_v4);\n\tunsigned long cookie = (unsigned long)neigh;\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_tun_neigh_lag lag_info;\n\tstruct nfp_neigh_entry *nn_entry;\n\tu32 port_id;\n\tu8 mtype;\n\n\tport_id = nfp_flower_get_port_id_from_netdev(app, netdev);\n\tif (!port_id)\n\t\treturn;\n\n\tif ((port_id & NFP_FL_LAG_OUT) == NFP_FL_LAG_OUT) {\n\t\tmemset(&lag_info, 0, sizeof(struct nfp_tun_neigh_lag));\n\t\tnfp_flower_lag_get_info_from_netdev(app, netdev, &lag_info);\n\t}\n\n\tspin_lock_bh(&priv->predt_lock);\n\tnn_entry = rhashtable_lookup_fast(&priv->neigh_table, &cookie,\n\t\t\t\t\t  neigh_table_params);\n\tif (!nn_entry && !neigh_invalid) {\n\t\tstruct nfp_tun_neigh_ext *ext;\n\t\tstruct nfp_tun_neigh_lag *lag;\n\t\tstruct nfp_tun_neigh *common;\n\n\t\tnn_entry = kzalloc(sizeof(*nn_entry) + neigh_size,\n\t\t\t\t   GFP_ATOMIC);\n\t\tif (!nn_entry)\n\t\t\tgoto err;\n\n\t\tnn_entry->payload = (char *)&nn_entry[1];\n\t\tnn_entry->neigh_cookie = cookie;\n\t\tnn_entry->is_ipv6 = is_ipv6;\n\t\tnn_entry->flow = NULL;\n\t\tif (is_ipv6) {\n\t\t\tstruct flowi6 *flowi6 = (struct flowi6 *)flow;\n\t\t\tstruct nfp_tun_neigh_v6 *payload;\n\n\t\t\tpayload = (struct nfp_tun_neigh_v6 *)nn_entry->payload;\n\t\t\tpayload->src_ipv6 = flowi6->saddr;\n\t\t\tpayload->dst_ipv6 = flowi6->daddr;\n\t\t\tcommon = &payload->common;\n\t\t\text = &payload->ext;\n\t\t\tlag = &payload->lag;\n\t\t\tmtype = NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6;\n\t\t} else {\n\t\t\tstruct flowi4 *flowi4 = (struct flowi4 *)flow;\n\t\t\tstruct nfp_tun_neigh_v4 *payload;\n\n\t\t\tpayload = (struct nfp_tun_neigh_v4 *)nn_entry->payload;\n\t\t\tpayload->src_ipv4 = flowi4->saddr;\n\t\t\tpayload->dst_ipv4 = flowi4->daddr;\n\t\t\tcommon = &payload->common;\n\t\t\text = &payload->ext;\n\t\t\tlag = &payload->lag;\n\t\t\tmtype = NFP_FLOWER_CMSG_TYPE_TUN_NEIGH;\n\t\t}\n\t\text->host_ctx = cpu_to_be32(U32_MAX);\n\t\text->vlan_tpid = cpu_to_be16(U16_MAX);\n\t\text->vlan_tci = cpu_to_be16(U16_MAX);\n\t\tether_addr_copy(common->src_addr, netdev->dev_addr);\n\t\tneigh_ha_snapshot(common->dst_addr, neigh, netdev);\n\n\t\tif ((port_id & NFP_FL_LAG_OUT) == NFP_FL_LAG_OUT)\n\t\t\tmemcpy(lag, &lag_info, sizeof(struct nfp_tun_neigh_lag));\n\t\tcommon->port_id = cpu_to_be32(port_id);\n\n\t\tif (rhashtable_insert_fast(&priv->neigh_table,\n\t\t\t\t\t   &nn_entry->ht_node,\n\t\t\t\t\t   neigh_table_params))\n\t\t\tgoto err;\n\n\t\tnfp_tun_link_predt_entries(app, nn_entry);\n\t\tnfp_flower_xmit_tun_conf(app, mtype, neigh_size,\n\t\t\t\t\t nn_entry->payload,\n\t\t\t\t\t GFP_ATOMIC);\n\t} else if (nn_entry && neigh_invalid) {\n\t\tif (is_ipv6) {\n\t\t\tstruct flowi6 *flowi6 = (struct flowi6 *)flow;\n\t\t\tstruct nfp_tun_neigh_v6 *payload;\n\n\t\t\tpayload = (struct nfp_tun_neigh_v6 *)nn_entry->payload;\n\t\t\tmemset(payload, 0, sizeof(struct nfp_tun_neigh_v6));\n\t\t\tpayload->dst_ipv6 = flowi6->daddr;\n\t\t\tmtype = NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6;\n\t\t} else {\n\t\t\tstruct flowi4 *flowi4 = (struct flowi4 *)flow;\n\t\t\tstruct nfp_tun_neigh_v4 *payload;\n\n\t\t\tpayload = (struct nfp_tun_neigh_v4 *)nn_entry->payload;\n\t\t\tmemset(payload, 0, sizeof(struct nfp_tun_neigh_v4));\n\t\t\tpayload->dst_ipv4 = flowi4->daddr;\n\t\t\tmtype = NFP_FLOWER_CMSG_TYPE_TUN_NEIGH;\n\t\t}\n\t\t \n\t\tneigh_event_send(neigh, NULL);\n\t\trhashtable_remove_fast(&priv->neigh_table,\n\t\t\t\t       &nn_entry->ht_node,\n\t\t\t\t       neigh_table_params);\n\n\t\tnfp_flower_xmit_tun_conf(app, mtype, neigh_size,\n\t\t\t\t\t nn_entry->payload,\n\t\t\t\t\t GFP_ATOMIC);\n\n\t\tif (nn_entry->flow)\n\t\t\tlist_del(&nn_entry->list_head);\n\t\tkfree(nn_entry);\n\t} else if (nn_entry && !neigh_invalid) {\n\t\tstruct nfp_tun_neigh *common;\n\t\tu8 dst_addr[ETH_ALEN];\n\t\tbool is_mac_change;\n\n\t\tif (is_ipv6) {\n\t\t\tstruct nfp_tun_neigh_v6 *payload;\n\n\t\t\tpayload = (struct nfp_tun_neigh_v6 *)nn_entry->payload;\n\t\t\tcommon = &payload->common;\n\t\t\tmtype = NFP_FLOWER_CMSG_TYPE_TUN_NEIGH_V6;\n\t\t} else {\n\t\t\tstruct nfp_tun_neigh_v4 *payload;\n\n\t\t\tpayload = (struct nfp_tun_neigh_v4 *)nn_entry->payload;\n\t\t\tcommon = &payload->common;\n\t\t\tmtype = NFP_FLOWER_CMSG_TYPE_TUN_NEIGH;\n\t\t}\n\n\t\tether_addr_copy(dst_addr, common->dst_addr);\n\t\tneigh_ha_snapshot(common->dst_addr, neigh, netdev);\n\t\tis_mac_change = !ether_addr_equal(dst_addr, common->dst_addr);\n\t\tif (override || is_mac_change) {\n\t\t\tif (is_mac_change && nn_entry->flow) {\n\t\t\t\tlist_del(&nn_entry->list_head);\n\t\t\t\tnn_entry->flow = NULL;\n\t\t\t}\n\t\t\tnfp_tun_link_predt_entries(app, nn_entry);\n\t\t\tnfp_flower_xmit_tun_conf(app, mtype, neigh_size,\n\t\t\t\t\t\t nn_entry->payload,\n\t\t\t\t\t\t GFP_ATOMIC);\n\t\t}\n\t}\n\n\tspin_unlock_bh(&priv->predt_lock);\n\treturn;\n\nerr:\n\tkfree(nn_entry);\n\tspin_unlock_bh(&priv->predt_lock);\n\tnfp_flower_cmsg_warn(app, \"Neighbour configuration failed.\\n\");\n}\n\nstatic void\nnfp_tun_release_neigh_update_work(struct nfp_neigh_update_work *update_work)\n{\n\tneigh_release(update_work->n);\n\tkfree(update_work);\n}\n\nstatic void nfp_tun_neigh_update(struct work_struct *work)\n{\n\tstruct nfp_neigh_update_work *update_work;\n\tstruct nfp_app *app;\n\tstruct neighbour *n;\n\tbool neigh_invalid;\n\tint err;\n\n\tupdate_work = container_of(work, struct nfp_neigh_update_work, work);\n\tapp = update_work->app;\n\tn = update_work->n;\n\n\tif (!nfp_flower_get_port_id_from_netdev(app, n->dev))\n\t\tgoto out;\n\n#if IS_ENABLED(CONFIG_INET)\n\tneigh_invalid = !(n->nud_state & NUD_VALID) || n->dead;\n\tif (n->tbl->family == AF_INET6) {\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tstruct flowi6 flow6 = {};\n\n\t\tflow6.daddr = *(struct in6_addr *)n->primary_key;\n\t\tif (!neigh_invalid) {\n\t\t\tstruct dst_entry *dst;\n\t\t\t \n\t\t\tdst = ip6_dst_lookup_flow(dev_net(n->dev), NULL,\n\t\t\t\t\t\t  &flow6, NULL);\n\t\t\tif (IS_ERR(dst))\n\t\t\t\tgoto out;\n\n\t\t\tdst_release(dst);\n\t\t}\n\t\tnfp_tun_write_neigh(n->dev, app, &flow6, n, true, false);\n#endif  \n\t} else {\n\t\tstruct flowi4 flow4 = {};\n\n\t\tflow4.daddr = *(__be32 *)n->primary_key;\n\t\tif (!neigh_invalid) {\n\t\t\tstruct rtable *rt;\n\t\t\t \n\t\t\trt = ip_route_output_key(dev_net(n->dev), &flow4);\n\t\t\terr = PTR_ERR_OR_ZERO(rt);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\tip_rt_put(rt);\n\t\t}\n\t\tnfp_tun_write_neigh(n->dev, app, &flow4, n, false, false);\n\t}\n#endif  \nout:\n\tnfp_tun_release_neigh_update_work(update_work);\n}\n\nstatic struct nfp_neigh_update_work *\nnfp_tun_alloc_neigh_update_work(struct nfp_app *app, struct neighbour *n)\n{\n\tstruct nfp_neigh_update_work *update_work;\n\n\tupdate_work = kzalloc(sizeof(*update_work), GFP_ATOMIC);\n\tif (!update_work)\n\t\treturn NULL;\n\n\tINIT_WORK(&update_work->work, nfp_tun_neigh_update);\n\tneigh_hold(n);\n\tupdate_work->n = n;\n\tupdate_work->app = app;\n\n\treturn update_work;\n}\n\nstatic int\nnfp_tun_neigh_event_handler(struct notifier_block *nb, unsigned long event,\n\t\t\t    void *ptr)\n{\n\tstruct nfp_neigh_update_work *update_work;\n\tstruct nfp_flower_priv *app_priv;\n\tstruct netevent_redirect *redir;\n\tstruct neighbour *n;\n\tstruct nfp_app *app;\n\n\tswitch (event) {\n\tcase NETEVENT_REDIRECT:\n\t\tredir = (struct netevent_redirect *)ptr;\n\t\tn = redir->neigh;\n\t\tbreak;\n\tcase NETEVENT_NEIGH_UPDATE:\n\t\tn = (struct neighbour *)ptr;\n\t\tbreak;\n\tdefault:\n\t\treturn NOTIFY_DONE;\n\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\tif (n->tbl != ipv6_stub->nd_tbl && n->tbl != &arp_tbl)\n#else\n\tif (n->tbl != &arp_tbl)\n#endif\n\t\treturn NOTIFY_DONE;\n\n\tapp_priv = container_of(nb, struct nfp_flower_priv, tun.neigh_nb);\n\tapp = app_priv->app;\n\tupdate_work = nfp_tun_alloc_neigh_update_work(app, n);\n\tif (!update_work)\n\t\treturn NOTIFY_DONE;\n\n\tqueue_work(system_highpri_wq, &update_work->work);\n\n\treturn NOTIFY_DONE;\n}\n\nvoid nfp_tunnel_request_route_v4(struct nfp_app *app, struct sk_buff *skb)\n{\n\tstruct nfp_tun_req_route_ipv4 *payload;\n\tstruct net_device *netdev;\n\tstruct flowi4 flow = {};\n\tstruct neighbour *n;\n\tstruct rtable *rt;\n\tint err;\n\n\tpayload = nfp_flower_cmsg_get_data(skb);\n\n\trcu_read_lock();\n\tnetdev = nfp_app_dev_get(app, be32_to_cpu(payload->ingress_port), NULL);\n\tif (!netdev)\n\t\tgoto fail_rcu_unlock;\n\tdev_hold(netdev);\n\n\tflow.daddr = payload->ipv4_addr;\n\tflow.flowi4_proto = IPPROTO_UDP;\n\n#if IS_ENABLED(CONFIG_INET)\n\t \n\trt = ip_route_output_key(dev_net(netdev), &flow);\n\terr = PTR_ERR_OR_ZERO(rt);\n\tif (err)\n\t\tgoto fail_rcu_unlock;\n#else\n\tgoto fail_rcu_unlock;\n#endif\n\n\t \n\tn = dst_neigh_lookup(&rt->dst, &flow.daddr);\n\tip_rt_put(rt);\n\tif (!n)\n\t\tgoto fail_rcu_unlock;\n\trcu_read_unlock();\n\n\tnfp_tun_write_neigh(n->dev, app, &flow, n, false, true);\n\tneigh_release(n);\n\tdev_put(netdev);\n\treturn;\n\nfail_rcu_unlock:\n\trcu_read_unlock();\n\tdev_put(netdev);\n\tnfp_flower_cmsg_warn(app, \"Requested route not found.\\n\");\n}\n\nvoid nfp_tunnel_request_route_v6(struct nfp_app *app, struct sk_buff *skb)\n{\n\tstruct nfp_tun_req_route_ipv6 *payload;\n\tstruct net_device *netdev;\n\tstruct flowi6 flow = {};\n\tstruct dst_entry *dst;\n\tstruct neighbour *n;\n\n\tpayload = nfp_flower_cmsg_get_data(skb);\n\n\trcu_read_lock();\n\tnetdev = nfp_app_dev_get(app, be32_to_cpu(payload->ingress_port), NULL);\n\tif (!netdev)\n\t\tgoto fail_rcu_unlock;\n\tdev_hold(netdev);\n\n\tflow.daddr = payload->ipv6_addr;\n\tflow.flowi6_proto = IPPROTO_UDP;\n\n#if IS_ENABLED(CONFIG_INET) && IS_ENABLED(CONFIG_IPV6)\n\tdst = ipv6_stub->ipv6_dst_lookup_flow(dev_net(netdev), NULL, &flow,\n\t\t\t\t\t      NULL);\n\tif (IS_ERR(dst))\n\t\tgoto fail_rcu_unlock;\n#else\n\tgoto fail_rcu_unlock;\n#endif\n\n\tn = dst_neigh_lookup(dst, &flow.daddr);\n\tdst_release(dst);\n\tif (!n)\n\t\tgoto fail_rcu_unlock;\n\trcu_read_unlock();\n\n\tnfp_tun_write_neigh(n->dev, app, &flow, n, true, true);\n\tneigh_release(n);\n\tdev_put(netdev);\n\treturn;\n\nfail_rcu_unlock:\n\trcu_read_unlock();\n\tdev_put(netdev);\n\tnfp_flower_cmsg_warn(app, \"Requested IPv6 route not found.\\n\");\n}\n\nstatic void nfp_tun_write_ipv4_list(struct nfp_app *app)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_ipv4_addr_entry *entry;\n\tstruct nfp_tun_ipv4_addr payload;\n\tstruct list_head *ptr, *storage;\n\tint count;\n\n\tmemset(&payload, 0, sizeof(struct nfp_tun_ipv4_addr));\n\tmutex_lock(&priv->tun.ipv4_off_lock);\n\tcount = 0;\n\tlist_for_each_safe(ptr, storage, &priv->tun.ipv4_off_list) {\n\t\tif (count >= NFP_FL_IPV4_ADDRS_MAX) {\n\t\t\tmutex_unlock(&priv->tun.ipv4_off_lock);\n\t\t\tnfp_flower_cmsg_warn(app, \"IPv4 offload exceeds limit.\\n\");\n\t\t\treturn;\n\t\t}\n\t\tentry = list_entry(ptr, struct nfp_ipv4_addr_entry, list);\n\t\tpayload.ipv4_addr[count++] = entry->ipv4_addr;\n\t}\n\tpayload.count = cpu_to_be32(count);\n\tmutex_unlock(&priv->tun.ipv4_off_lock);\n\n\tnfp_flower_xmit_tun_conf(app, NFP_FLOWER_CMSG_TYPE_TUN_IPS,\n\t\t\t\t sizeof(struct nfp_tun_ipv4_addr),\n\t\t\t\t &payload, GFP_KERNEL);\n}\n\nvoid nfp_tunnel_add_ipv4_off(struct nfp_app *app, __be32 ipv4)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_ipv4_addr_entry *entry;\n\tstruct list_head *ptr, *storage;\n\n\tmutex_lock(&priv->tun.ipv4_off_lock);\n\tlist_for_each_safe(ptr, storage, &priv->tun.ipv4_off_list) {\n\t\tentry = list_entry(ptr, struct nfp_ipv4_addr_entry, list);\n\t\tif (entry->ipv4_addr == ipv4) {\n\t\t\tentry->ref_count++;\n\t\t\tmutex_unlock(&priv->tun.ipv4_off_lock);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tentry = kmalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry) {\n\t\tmutex_unlock(&priv->tun.ipv4_off_lock);\n\t\tnfp_flower_cmsg_warn(app, \"Mem error when offloading IP address.\\n\");\n\t\treturn;\n\t}\n\tentry->ipv4_addr = ipv4;\n\tentry->ref_count = 1;\n\tlist_add_tail(&entry->list, &priv->tun.ipv4_off_list);\n\tmutex_unlock(&priv->tun.ipv4_off_lock);\n\n\tnfp_tun_write_ipv4_list(app);\n}\n\nvoid nfp_tunnel_del_ipv4_off(struct nfp_app *app, __be32 ipv4)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_ipv4_addr_entry *entry;\n\tstruct list_head *ptr, *storage;\n\n\tmutex_lock(&priv->tun.ipv4_off_lock);\n\tlist_for_each_safe(ptr, storage, &priv->tun.ipv4_off_list) {\n\t\tentry = list_entry(ptr, struct nfp_ipv4_addr_entry, list);\n\t\tif (entry->ipv4_addr == ipv4) {\n\t\t\tentry->ref_count--;\n\t\t\tif (!entry->ref_count) {\n\t\t\t\tlist_del(&entry->list);\n\t\t\t\tkfree(entry);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&priv->tun.ipv4_off_lock);\n\n\tnfp_tun_write_ipv4_list(app);\n}\n\nstatic void nfp_tun_write_ipv6_list(struct nfp_app *app)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_ipv6_addr_entry *entry;\n\tstruct nfp_tun_ipv6_addr payload;\n\tint count = 0;\n\n\tmemset(&payload, 0, sizeof(struct nfp_tun_ipv6_addr));\n\tmutex_lock(&priv->tun.ipv6_off_lock);\n\tlist_for_each_entry(entry, &priv->tun.ipv6_off_list, list) {\n\t\tif (count >= NFP_FL_IPV6_ADDRS_MAX) {\n\t\t\tnfp_flower_cmsg_warn(app, \"Too many IPv6 tunnel endpoint addresses, some cannot be offloaded.\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tpayload.ipv6_addr[count++] = entry->ipv6_addr;\n\t}\n\tmutex_unlock(&priv->tun.ipv6_off_lock);\n\tpayload.count = cpu_to_be32(count);\n\n\tnfp_flower_xmit_tun_conf(app, NFP_FLOWER_CMSG_TYPE_TUN_IPS_V6,\n\t\t\t\t sizeof(struct nfp_tun_ipv6_addr),\n\t\t\t\t &payload, GFP_KERNEL);\n}\n\nstruct nfp_ipv6_addr_entry *\nnfp_tunnel_add_ipv6_off(struct nfp_app *app, struct in6_addr *ipv6)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_ipv6_addr_entry *entry;\n\n\tmutex_lock(&priv->tun.ipv6_off_lock);\n\tlist_for_each_entry(entry, &priv->tun.ipv6_off_list, list)\n\t\tif (!memcmp(&entry->ipv6_addr, ipv6, sizeof(*ipv6))) {\n\t\t\tentry->ref_count++;\n\t\t\tmutex_unlock(&priv->tun.ipv6_off_lock);\n\t\t\treturn entry;\n\t\t}\n\n\tentry = kmalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry) {\n\t\tmutex_unlock(&priv->tun.ipv6_off_lock);\n\t\tnfp_flower_cmsg_warn(app, \"Mem error when offloading IP address.\\n\");\n\t\treturn NULL;\n\t}\n\tentry->ipv6_addr = *ipv6;\n\tentry->ref_count = 1;\n\tlist_add_tail(&entry->list, &priv->tun.ipv6_off_list);\n\tmutex_unlock(&priv->tun.ipv6_off_lock);\n\n\tnfp_tun_write_ipv6_list(app);\n\n\treturn entry;\n}\n\nvoid\nnfp_tunnel_put_ipv6_off(struct nfp_app *app, struct nfp_ipv6_addr_entry *entry)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tbool freed = false;\n\n\tmutex_lock(&priv->tun.ipv6_off_lock);\n\tif (!--entry->ref_count) {\n\t\tlist_del(&entry->list);\n\t\tkfree(entry);\n\t\tfreed = true;\n\t}\n\tmutex_unlock(&priv->tun.ipv6_off_lock);\n\n\tif (freed)\n\t\tnfp_tun_write_ipv6_list(app);\n}\n\nstatic int\n__nfp_tunnel_offload_mac(struct nfp_app *app, const u8 *mac, u16 idx, bool del)\n{\n\tstruct nfp_tun_mac_addr_offload payload;\n\n\tmemset(&payload, 0, sizeof(payload));\n\n\tif (del)\n\t\tpayload.flags = cpu_to_be16(NFP_TUN_MAC_OFFLOAD_DEL_FLAG);\n\n\t \n\tpayload.count = cpu_to_be16(1);\n\tpayload.index = cpu_to_be16(idx);\n\tether_addr_copy(payload.addr, mac);\n\n\treturn nfp_flower_xmit_tun_conf(app, NFP_FLOWER_CMSG_TYPE_TUN_MAC,\n\t\t\t\t\tsizeof(struct nfp_tun_mac_addr_offload),\n\t\t\t\t\t&payload, GFP_KERNEL);\n}\n\nstatic bool nfp_tunnel_port_is_phy_repr(int port)\n{\n\tif (FIELD_GET(NFP_FLOWER_CMSG_PORT_TYPE, port) ==\n\t    NFP_FLOWER_CMSG_PORT_TYPE_PHYS_PORT)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic u16 nfp_tunnel_get_mac_idx_from_phy_port_id(int port)\n{\n\treturn port << 8 | NFP_FLOWER_CMSG_PORT_TYPE_PHYS_PORT;\n}\n\nstatic u16 nfp_tunnel_get_global_mac_idx_from_ida(int id)\n{\n\treturn id << 8 | NFP_FLOWER_CMSG_PORT_TYPE_OTHER_PORT;\n}\n\nstatic int nfp_tunnel_get_ida_from_global_mac_idx(u16 nfp_mac_idx)\n{\n\treturn nfp_mac_idx >> 8;\n}\n\nstatic bool nfp_tunnel_is_mac_idx_global(u16 nfp_mac_idx)\n{\n\treturn (nfp_mac_idx & 0xff) == NFP_FLOWER_CMSG_PORT_TYPE_OTHER_PORT;\n}\n\nstatic struct nfp_tun_offloaded_mac *\nnfp_tunnel_lookup_offloaded_macs(struct nfp_app *app, const u8 *mac)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\n\treturn rhashtable_lookup_fast(&priv->tun.offloaded_macs, mac,\n\t\t\t\t      offloaded_macs_params);\n}\n\nstatic void\nnfp_tunnel_offloaded_macs_inc_ref_and_link(struct nfp_tun_offloaded_mac *entry,\n\t\t\t\t\t   struct net_device *netdev, bool mod)\n{\n\tif (nfp_netdev_is_nfp_repr(netdev)) {\n\t\tstruct nfp_flower_repr_priv *repr_priv;\n\t\tstruct nfp_repr *repr;\n\n\t\trepr = netdev_priv(netdev);\n\t\trepr_priv = repr->app_priv;\n\n\t\t \n\t\tif (mod)\n\t\t\tlist_del(&repr_priv->mac_list);\n\n\t\tlist_add_tail(&repr_priv->mac_list, &entry->repr_list);\n\t} else if (nfp_flower_is_supported_bridge(netdev)) {\n\t\tentry->bridge_count++;\n\t}\n\n\tentry->ref_count++;\n}\n\nstatic int\nnfp_tunnel_add_shared_mac(struct nfp_app *app, struct net_device *netdev,\n\t\t\t  int port, bool mod)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_tun_offloaded_mac *entry;\n\tint ida_idx = -1, err;\n\tu16 nfp_mac_idx = 0;\n\n\tentry = nfp_tunnel_lookup_offloaded_macs(app, netdev->dev_addr);\n\tif (entry && nfp_tunnel_is_mac_idx_global(entry->index)) {\n\t\tif (entry->bridge_count ||\n\t\t    !nfp_flower_is_supported_bridge(netdev)) {\n\t\t\tnfp_tunnel_offloaded_macs_inc_ref_and_link(entry,\n\t\t\t\t\t\t\t\t   netdev, mod);\n\t\t\treturn 0;\n\t\t}\n\n\t\t \n\t\tnfp_mac_idx = entry->index | NFP_TUN_PRE_TUN_IDX_BIT;\n\t}\n\n\tif (!nfp_mac_idx) {\n\t\t \n\t\tif (entry || !port) {\n\t\t\tida_idx = ida_alloc_max(&priv->tun.mac_off_ids,\n\t\t\t\t\t\tNFP_MAX_MAC_INDEX, GFP_KERNEL);\n\t\t\tif (ida_idx < 0)\n\t\t\t\treturn ida_idx;\n\n\t\t\tnfp_mac_idx =\n\t\t\t\tnfp_tunnel_get_global_mac_idx_from_ida(ida_idx);\n\n\t\t\tif (nfp_flower_is_supported_bridge(netdev))\n\t\t\t\tnfp_mac_idx |= NFP_TUN_PRE_TUN_IDX_BIT;\n\n\t\t} else {\n\t\t\tnfp_mac_idx =\n\t\t\t\tnfp_tunnel_get_mac_idx_from_phy_port_id(port);\n\t\t}\n\t}\n\n\tif (!entry) {\n\t\tentry = kzalloc(sizeof(*entry), GFP_KERNEL);\n\t\tif (!entry) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_free_ida;\n\t\t}\n\n\t\tether_addr_copy(entry->addr, netdev->dev_addr);\n\t\tINIT_LIST_HEAD(&entry->repr_list);\n\n\t\tif (rhashtable_insert_fast(&priv->tun.offloaded_macs,\n\t\t\t\t\t   &entry->ht_node,\n\t\t\t\t\t   offloaded_macs_params)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_free_entry;\n\t\t}\n\t}\n\n\terr = __nfp_tunnel_offload_mac(app, netdev->dev_addr,\n\t\t\t\t       nfp_mac_idx, false);\n\tif (err) {\n\t\t \n\t\tif (!entry->ref_count)\n\t\t\tgoto err_remove_hash;\n\t\tgoto err_free_ida;\n\t}\n\n\tentry->index = nfp_mac_idx;\n\tnfp_tunnel_offloaded_macs_inc_ref_and_link(entry, netdev, mod);\n\n\treturn 0;\n\nerr_remove_hash:\n\trhashtable_remove_fast(&priv->tun.offloaded_macs, &entry->ht_node,\n\t\t\t       offloaded_macs_params);\nerr_free_entry:\n\tkfree(entry);\nerr_free_ida:\n\tif (ida_idx != -1)\n\t\tida_free(&priv->tun.mac_off_ids, ida_idx);\n\n\treturn err;\n}\n\nstatic int\nnfp_tunnel_del_shared_mac(struct nfp_app *app, struct net_device *netdev,\n\t\t\t  const u8 *mac, bool mod)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_flower_repr_priv *repr_priv;\n\tstruct nfp_tun_offloaded_mac *entry;\n\tstruct nfp_repr *repr;\n\tu16 nfp_mac_idx;\n\tint ida_idx;\n\n\tentry = nfp_tunnel_lookup_offloaded_macs(app, mac);\n\tif (!entry)\n\t\treturn 0;\n\n\tentry->ref_count--;\n\t \n\tif (nfp_netdev_is_nfp_repr(netdev) && !mod) {\n\t\trepr = netdev_priv(netdev);\n\t\trepr_priv = repr->app_priv;\n\t\tlist_del(&repr_priv->mac_list);\n\t}\n\n\tif (nfp_flower_is_supported_bridge(netdev)) {\n\t\tentry->bridge_count--;\n\n\t\tif (!entry->bridge_count && entry->ref_count) {\n\t\t\tnfp_mac_idx = entry->index & ~NFP_TUN_PRE_TUN_IDX_BIT;\n\t\t\tif (__nfp_tunnel_offload_mac(app, mac, nfp_mac_idx,\n\t\t\t\t\t\t     false)) {\n\t\t\t\tnfp_flower_cmsg_warn(app, \"MAC offload index revert failed on %s.\\n\",\n\t\t\t\t\t\t     netdev_name(netdev));\n\t\t\t\treturn 0;\n\t\t\t}\n\n\t\t\tentry->index = nfp_mac_idx;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\tif (entry->ref_count == 1 && list_is_singular(&entry->repr_list)) {\n\t\tint port, err;\n\n\t\trepr_priv = list_first_entry(&entry->repr_list,\n\t\t\t\t\t     struct nfp_flower_repr_priv,\n\t\t\t\t\t     mac_list);\n\t\trepr = repr_priv->nfp_repr;\n\t\tport = nfp_repr_get_port_id(repr->netdev);\n\t\tnfp_mac_idx = nfp_tunnel_get_mac_idx_from_phy_port_id(port);\n\t\terr = __nfp_tunnel_offload_mac(app, mac, nfp_mac_idx, false);\n\t\tif (err) {\n\t\t\tnfp_flower_cmsg_warn(app, \"MAC offload index revert failed on %s.\\n\",\n\t\t\t\t\t     netdev_name(netdev));\n\t\t\treturn 0;\n\t\t}\n\n\t\tida_idx = nfp_tunnel_get_ida_from_global_mac_idx(entry->index);\n\t\tida_free(&priv->tun.mac_off_ids, ida_idx);\n\t\tentry->index = nfp_mac_idx;\n\t\treturn 0;\n\t}\n\n\tif (entry->ref_count)\n\t\treturn 0;\n\n\tWARN_ON_ONCE(rhashtable_remove_fast(&priv->tun.offloaded_macs,\n\t\t\t\t\t    &entry->ht_node,\n\t\t\t\t\t    offloaded_macs_params));\n\n\tif (nfp_flower_is_supported_bridge(netdev))\n\t\tnfp_mac_idx = entry->index & ~NFP_TUN_PRE_TUN_IDX_BIT;\n\telse\n\t\tnfp_mac_idx = entry->index;\n\n\t \n\tif (nfp_tunnel_is_mac_idx_global(nfp_mac_idx)) {\n\t\tida_idx = nfp_tunnel_get_ida_from_global_mac_idx(entry->index);\n\t\tida_free(&priv->tun.mac_off_ids, ida_idx);\n\t}\n\n\tkfree(entry);\n\n\treturn __nfp_tunnel_offload_mac(app, mac, 0, true);\n}\n\nstatic int\nnfp_tunnel_offload_mac(struct nfp_app *app, struct net_device *netdev,\n\t\t       enum nfp_flower_mac_offload_cmd cmd)\n{\n\tstruct nfp_flower_non_repr_priv *nr_priv = NULL;\n\tbool non_repr = false, *mac_offloaded;\n\tu8 *off_mac = NULL;\n\tint err, port = 0;\n\n\tif (nfp_netdev_is_nfp_repr(netdev)) {\n\t\tstruct nfp_flower_repr_priv *repr_priv;\n\t\tstruct nfp_repr *repr;\n\n\t\trepr = netdev_priv(netdev);\n\t\tif (repr->app != app)\n\t\t\treturn 0;\n\n\t\trepr_priv = repr->app_priv;\n\t\tif (repr_priv->on_bridge)\n\t\t\treturn 0;\n\n\t\tmac_offloaded = &repr_priv->mac_offloaded;\n\t\toff_mac = &repr_priv->offloaded_mac_addr[0];\n\t\tport = nfp_repr_get_port_id(netdev);\n\t\tif (!nfp_tunnel_port_is_phy_repr(port))\n\t\t\treturn 0;\n\t} else if (nfp_fl_is_netdev_to_offload(netdev)) {\n\t\tnr_priv = nfp_flower_non_repr_priv_get(app, netdev);\n\t\tif (!nr_priv)\n\t\t\treturn -ENOMEM;\n\n\t\tmac_offloaded = &nr_priv->mac_offloaded;\n\t\toff_mac = &nr_priv->offloaded_mac_addr[0];\n\t\tnon_repr = true;\n\t} else {\n\t\treturn 0;\n\t}\n\n\tif (!is_valid_ether_addr(netdev->dev_addr)) {\n\t\terr = -EINVAL;\n\t\tgoto err_put_non_repr_priv;\n\t}\n\n\tif (cmd == NFP_TUNNEL_MAC_OFFLOAD_MOD && !*mac_offloaded)\n\t\tcmd = NFP_TUNNEL_MAC_OFFLOAD_ADD;\n\n\tswitch (cmd) {\n\tcase NFP_TUNNEL_MAC_OFFLOAD_ADD:\n\t\terr = nfp_tunnel_add_shared_mac(app, netdev, port, false);\n\t\tif (err)\n\t\t\tgoto err_put_non_repr_priv;\n\n\t\tif (non_repr)\n\t\t\t__nfp_flower_non_repr_priv_get(nr_priv);\n\n\t\t*mac_offloaded = true;\n\t\tether_addr_copy(off_mac, netdev->dev_addr);\n\t\tbreak;\n\tcase NFP_TUNNEL_MAC_OFFLOAD_DEL:\n\t\t \n\t\tif (!*mac_offloaded)\n\t\t\tbreak;\n\n\t\tif (non_repr)\n\t\t\t__nfp_flower_non_repr_priv_put(nr_priv);\n\n\t\t*mac_offloaded = false;\n\n\t\terr = nfp_tunnel_del_shared_mac(app, netdev, netdev->dev_addr,\n\t\t\t\t\t\tfalse);\n\t\tif (err)\n\t\t\tgoto err_put_non_repr_priv;\n\n\t\tbreak;\n\tcase NFP_TUNNEL_MAC_OFFLOAD_MOD:\n\t\t \n\t\tif (ether_addr_equal(netdev->dev_addr, off_mac))\n\t\t\tbreak;\n\n\t\terr = nfp_tunnel_add_shared_mac(app, netdev, port, true);\n\t\tif (err)\n\t\t\tgoto err_put_non_repr_priv;\n\n\t\t \n\t\terr = nfp_tunnel_del_shared_mac(app, netdev, off_mac, true);\n\t\tif (err)\n\t\t\tnfp_flower_cmsg_warn(app, \"Failed to remove offload of replaced MAC addr on %s.\\n\",\n\t\t\t\t\t     netdev_name(netdev));\n\n\t\tether_addr_copy(off_mac, netdev->dev_addr);\n\t\tbreak;\n\tdefault:\n\t\terr = -EINVAL;\n\t\tgoto err_put_non_repr_priv;\n\t}\n\n\tif (non_repr)\n\t\t__nfp_flower_non_repr_priv_put(nr_priv);\n\n\treturn 0;\n\nerr_put_non_repr_priv:\n\tif (non_repr)\n\t\t__nfp_flower_non_repr_priv_put(nr_priv);\n\n\treturn err;\n}\n\nint nfp_tunnel_mac_event_handler(struct nfp_app *app,\n\t\t\t\t struct net_device *netdev,\n\t\t\t\t unsigned long event, void *ptr)\n{\n\tint err;\n\n\tif (event == NETDEV_DOWN) {\n\t\terr = nfp_tunnel_offload_mac(app, netdev,\n\t\t\t\t\t     NFP_TUNNEL_MAC_OFFLOAD_DEL);\n\t\tif (err)\n\t\t\tnfp_flower_cmsg_warn(app, \"Failed to delete offload MAC on %s.\\n\",\n\t\t\t\t\t     netdev_name(netdev));\n\t} else if (event == NETDEV_UP) {\n\t\terr = nfp_tunnel_offload_mac(app, netdev,\n\t\t\t\t\t     NFP_TUNNEL_MAC_OFFLOAD_ADD);\n\t\tif (err)\n\t\t\tnfp_flower_cmsg_warn(app, \"Failed to offload MAC on %s.\\n\",\n\t\t\t\t\t     netdev_name(netdev));\n\t} else if (event == NETDEV_CHANGEADDR) {\n\t\t \n\t\tif (!(netdev->flags & IFF_UP))\n\t\t\treturn NOTIFY_OK;\n\n\t\terr = nfp_tunnel_offload_mac(app, netdev,\n\t\t\t\t\t     NFP_TUNNEL_MAC_OFFLOAD_MOD);\n\t\tif (err)\n\t\t\tnfp_flower_cmsg_warn(app, \"Failed to offload MAC change on %s.\\n\",\n\t\t\t\t\t     netdev_name(netdev));\n\t} else if (event == NETDEV_CHANGEUPPER) {\n\t\t \n\t\tstruct netdev_notifier_changeupper_info *info = ptr;\n\t\tstruct net_device *upper = info->upper_dev;\n\t\tstruct nfp_flower_repr_priv *repr_priv;\n\t\tstruct nfp_repr *repr;\n\n\t\tif (!nfp_netdev_is_nfp_repr(netdev) ||\n\t\t    !nfp_flower_is_supported_bridge(upper))\n\t\t\treturn NOTIFY_OK;\n\n\t\trepr = netdev_priv(netdev);\n\t\tif (repr->app != app)\n\t\t\treturn NOTIFY_OK;\n\n\t\trepr_priv = repr->app_priv;\n\n\t\tif (info->linking) {\n\t\t\tif (nfp_tunnel_offload_mac(app, netdev,\n\t\t\t\t\t\t   NFP_TUNNEL_MAC_OFFLOAD_DEL))\n\t\t\t\tnfp_flower_cmsg_warn(app, \"Failed to delete offloaded MAC on %s.\\n\",\n\t\t\t\t\t\t     netdev_name(netdev));\n\t\t\trepr_priv->on_bridge = true;\n\t\t} else {\n\t\t\trepr_priv->on_bridge = false;\n\n\t\t\tif (!(netdev->flags & IFF_UP))\n\t\t\t\treturn NOTIFY_OK;\n\n\t\t\tif (nfp_tunnel_offload_mac(app, netdev,\n\t\t\t\t\t\t   NFP_TUNNEL_MAC_OFFLOAD_ADD))\n\t\t\t\tnfp_flower_cmsg_warn(app, \"Failed to offload MAC on %s.\\n\",\n\t\t\t\t\t\t     netdev_name(netdev));\n\t\t}\n\t}\n\treturn NOTIFY_OK;\n}\n\nint nfp_flower_xmit_pre_tun_flow(struct nfp_app *app,\n\t\t\t\t struct nfp_fl_payload *flow)\n{\n\tstruct nfp_flower_priv *app_priv = app->priv;\n\tstruct nfp_tun_offloaded_mac *mac_entry;\n\tstruct nfp_flower_meta_tci *key_meta;\n\tstruct nfp_tun_pre_tun_rule payload;\n\tstruct net_device *internal_dev;\n\tint err;\n\n\tif (app_priv->pre_tun_rule_cnt == NFP_TUN_PRE_TUN_RULE_LIMIT)\n\t\treturn -ENOSPC;\n\n\tmemset(&payload, 0, sizeof(struct nfp_tun_pre_tun_rule));\n\n\tinternal_dev = flow->pre_tun_rule.dev;\n\tpayload.vlan_tci = flow->pre_tun_rule.vlan_tci;\n\tpayload.host_ctx_id = flow->meta.host_ctx_id;\n\n\t \n\tmac_entry = nfp_tunnel_lookup_offloaded_macs(app,\n\t\t\t\t\t\t     internal_dev->dev_addr);\n\tif (!mac_entry)\n\t\treturn -ENOENT;\n\n\t \n\tkey_meta = (struct nfp_flower_meta_tci *)flow->unmasked_data;\n\tif (key_meta->nfp_flow_key_layer & NFP_FLOWER_LAYER_IPV6)\n\t\tmac_entry->index |= NFP_TUN_PRE_TUN_IPV6_BIT;\n\telse\n\t\tmac_entry->index &= ~NFP_TUN_PRE_TUN_IPV6_BIT;\n\n\tpayload.port_idx = cpu_to_be16(mac_entry->index);\n\n\t \n\tflow->pre_tun_rule.vlan_tci = payload.vlan_tci;\n\tflow->pre_tun_rule.port_idx = payload.port_idx;\n\n\terr = nfp_flower_xmit_tun_conf(app, NFP_FLOWER_CMSG_TYPE_PRE_TUN_RULE,\n\t\t\t\t       sizeof(struct nfp_tun_pre_tun_rule),\n\t\t\t\t       (unsigned char *)&payload, GFP_KERNEL);\n\tif (err)\n\t\treturn err;\n\n\tapp_priv->pre_tun_rule_cnt++;\n\n\treturn 0;\n}\n\nint nfp_flower_xmit_pre_tun_del_flow(struct nfp_app *app,\n\t\t\t\t     struct nfp_fl_payload *flow)\n{\n\tstruct nfp_flower_priv *app_priv = app->priv;\n\tstruct nfp_tun_pre_tun_rule payload;\n\tu32 tmp_flags = 0;\n\tint err;\n\n\tmemset(&payload, 0, sizeof(struct nfp_tun_pre_tun_rule));\n\n\ttmp_flags |= NFP_TUN_PRE_TUN_RULE_DEL;\n\tpayload.flags = cpu_to_be32(tmp_flags);\n\tpayload.vlan_tci = flow->pre_tun_rule.vlan_tci;\n\tpayload.port_idx = flow->pre_tun_rule.port_idx;\n\n\terr = nfp_flower_xmit_tun_conf(app, NFP_FLOWER_CMSG_TYPE_PRE_TUN_RULE,\n\t\t\t\t       sizeof(struct nfp_tun_pre_tun_rule),\n\t\t\t\t       (unsigned char *)&payload, GFP_KERNEL);\n\tif (err)\n\t\treturn err;\n\n\tapp_priv->pre_tun_rule_cnt--;\n\n\treturn 0;\n}\n\nint nfp_tunnel_config_start(struct nfp_app *app)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tint err;\n\n\t \n\terr = rhashtable_init(&priv->tun.offloaded_macs,\n\t\t\t      &offloaded_macs_params);\n\tif (err)\n\t\treturn err;\n\n\tida_init(&priv->tun.mac_off_ids);\n\n\t \n\tmutex_init(&priv->tun.ipv4_off_lock);\n\tINIT_LIST_HEAD(&priv->tun.ipv4_off_list);\n\tmutex_init(&priv->tun.ipv6_off_lock);\n\tINIT_LIST_HEAD(&priv->tun.ipv6_off_list);\n\n\t \n\tpriv->tun.neigh_nb.notifier_call = nfp_tun_neigh_event_handler;\n\n\terr = register_netevent_notifier(&priv->tun.neigh_nb);\n\tif (err) {\n\t\trhashtable_free_and_destroy(&priv->tun.offloaded_macs,\n\t\t\t\t\t    nfp_check_rhashtable_empty, NULL);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nvoid nfp_tunnel_config_stop(struct nfp_app *app)\n{\n\tstruct nfp_flower_priv *priv = app->priv;\n\tstruct nfp_ipv4_addr_entry *ip_entry;\n\tstruct list_head *ptr, *storage;\n\n\tunregister_netevent_notifier(&priv->tun.neigh_nb);\n\n\tida_destroy(&priv->tun.mac_off_ids);\n\n\t \n\tlist_for_each_safe(ptr, storage, &priv->tun.ipv4_off_list) {\n\t\tip_entry = list_entry(ptr, struct nfp_ipv4_addr_entry, list);\n\t\tlist_del(&ip_entry->list);\n\t\tkfree(ip_entry);\n\t}\n\n\tmutex_destroy(&priv->tun.ipv6_off_lock);\n\n\t \n\trhashtable_free_and_destroy(&priv->tun.offloaded_macs,\n\t\t\t\t    nfp_check_rhashtable_empty, NULL);\n\n\tnfp_tun_cleanup_nn_entries(app);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}