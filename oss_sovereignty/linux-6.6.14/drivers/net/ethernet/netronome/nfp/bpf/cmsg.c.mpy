{
  "module_name": "cmsg.c",
  "hash_id": "9deaf6612cfc16c24d6829f441c9f9f5269e42863cad82c19642f4f935536da8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/netronome/nfp/bpf/cmsg.c",
  "human_readable_source": "\n \n\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n#include <linux/bug.h>\n#include <linux/jiffies.h>\n#include <linux/skbuff.h>\n#include <linux/timekeeping.h>\n\n#include \"../ccm.h\"\n#include \"../nfp_app.h\"\n#include \"../nfp_net.h\"\n#include \"fw.h\"\n#include \"main.h\"\n\nstatic struct sk_buff *\nnfp_bpf_cmsg_alloc(struct nfp_app_bpf *bpf, unsigned int size)\n{\n\tstruct sk_buff *skb;\n\n\tskb = nfp_app_ctrl_msg_alloc(bpf->app, size, GFP_KERNEL);\n\tskb_put(skb, size);\n\n\treturn skb;\n}\n\nstatic unsigned int\nnfp_bpf_cmsg_map_req_size(struct nfp_app_bpf *bpf, unsigned int n)\n{\n\tunsigned int size;\n\n\tsize = sizeof(struct cmsg_req_map_op);\n\tsize += (bpf->cmsg_key_sz + bpf->cmsg_val_sz) * n;\n\n\treturn size;\n}\n\nstatic struct sk_buff *\nnfp_bpf_cmsg_map_req_alloc(struct nfp_app_bpf *bpf, unsigned int n)\n{\n\treturn nfp_bpf_cmsg_alloc(bpf, nfp_bpf_cmsg_map_req_size(bpf, n));\n}\n\nstatic unsigned int\nnfp_bpf_cmsg_map_reply_size(struct nfp_app_bpf *bpf, unsigned int n)\n{\n\tunsigned int size;\n\n\tsize = sizeof(struct cmsg_reply_map_op);\n\tsize += (bpf->cmsg_key_sz + bpf->cmsg_val_sz) * n;\n\n\treturn size;\n}\n\nstatic int\nnfp_bpf_ctrl_rc_to_errno(struct nfp_app_bpf *bpf,\n\t\t\t struct cmsg_reply_map_simple *reply)\n{\n\tstatic const int res_table[] = {\n\t\t[CMSG_RC_SUCCESS]\t= 0,\n\t\t[CMSG_RC_ERR_MAP_FD]\t= -EBADFD,\n\t\t[CMSG_RC_ERR_MAP_NOENT]\t= -ENOENT,\n\t\t[CMSG_RC_ERR_MAP_ERR]\t= -EINVAL,\n\t\t[CMSG_RC_ERR_MAP_PARSE]\t= -EIO,\n\t\t[CMSG_RC_ERR_MAP_EXIST]\t= -EEXIST,\n\t\t[CMSG_RC_ERR_MAP_NOMEM]\t= -ENOMEM,\n\t\t[CMSG_RC_ERR_MAP_E2BIG]\t= -E2BIG,\n\t};\n\tu32 rc;\n\n\trc = be32_to_cpu(reply->rc);\n\tif (rc >= ARRAY_SIZE(res_table)) {\n\t\tcmsg_warn(bpf, \"FW responded with invalid status: %u\\n\", rc);\n\t\treturn -EIO;\n\t}\n\n\treturn res_table[rc];\n}\n\nlong long int\nnfp_bpf_ctrl_alloc_map(struct nfp_app_bpf *bpf, struct bpf_map *map)\n{\n\tstruct cmsg_reply_map_alloc_tbl *reply;\n\tstruct cmsg_req_map_alloc_tbl *req;\n\tstruct sk_buff *skb;\n\tu32 tid;\n\tint err;\n\n\tskb = nfp_bpf_cmsg_alloc(bpf, sizeof(*req));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\treq = (void *)skb->data;\n\treq->key_size = cpu_to_be32(map->key_size);\n\treq->value_size = cpu_to_be32(map->value_size);\n\treq->max_entries = cpu_to_be32(map->max_entries);\n\treq->map_type = cpu_to_be32(map->map_type);\n\treq->map_flags = 0;\n\n\tskb = nfp_ccm_communicate(&bpf->ccm, skb, NFP_CCM_TYPE_BPF_MAP_ALLOC,\n\t\t\t\t  sizeof(*reply));\n\tif (IS_ERR(skb))\n\t\treturn PTR_ERR(skb);\n\n\treply = (void *)skb->data;\n\terr = nfp_bpf_ctrl_rc_to_errno(bpf, &reply->reply_hdr);\n\tif (err)\n\t\tgoto err_free;\n\n\ttid = be32_to_cpu(reply->tid);\n\tdev_consume_skb_any(skb);\n\n\treturn tid;\nerr_free:\n\tdev_kfree_skb_any(skb);\n\treturn err;\n}\n\nvoid nfp_bpf_ctrl_free_map(struct nfp_app_bpf *bpf, struct nfp_bpf_map *nfp_map)\n{\n\tstruct cmsg_reply_map_free_tbl *reply;\n\tstruct cmsg_req_map_free_tbl *req;\n\tstruct sk_buff *skb;\n\tint err;\n\n\tskb = nfp_bpf_cmsg_alloc(bpf, sizeof(*req));\n\tif (!skb) {\n\t\tcmsg_warn(bpf, \"leaking map - failed to allocate msg\\n\");\n\t\treturn;\n\t}\n\n\treq = (void *)skb->data;\n\treq->tid = cpu_to_be32(nfp_map->tid);\n\n\tskb = nfp_ccm_communicate(&bpf->ccm, skb, NFP_CCM_TYPE_BPF_MAP_FREE,\n\t\t\t\t  sizeof(*reply));\n\tif (IS_ERR(skb)) {\n\t\tcmsg_warn(bpf, \"leaking map - I/O error\\n\");\n\t\treturn;\n\t}\n\n\treply = (void *)skb->data;\n\terr = nfp_bpf_ctrl_rc_to_errno(bpf, &reply->reply_hdr);\n\tif (err)\n\t\tcmsg_warn(bpf, \"leaking map - FW responded with: %d\\n\", err);\n\n\tdev_consume_skb_any(skb);\n}\n\nstatic void *\nnfp_bpf_ctrl_req_key(struct nfp_app_bpf *bpf, struct cmsg_req_map_op *req,\n\t\t     unsigned int n)\n{\n\treturn &req->data[bpf->cmsg_key_sz * n + bpf->cmsg_val_sz * n];\n}\n\nstatic void *\nnfp_bpf_ctrl_req_val(struct nfp_app_bpf *bpf, struct cmsg_req_map_op *req,\n\t\t     unsigned int n)\n{\n\treturn &req->data[bpf->cmsg_key_sz * (n + 1) + bpf->cmsg_val_sz * n];\n}\n\nstatic void *\nnfp_bpf_ctrl_reply_key(struct nfp_app_bpf *bpf, struct cmsg_reply_map_op *reply,\n\t\t       unsigned int n)\n{\n\treturn &reply->data[bpf->cmsg_key_sz * n + bpf->cmsg_val_sz * n];\n}\n\nstatic void *\nnfp_bpf_ctrl_reply_val(struct nfp_app_bpf *bpf, struct cmsg_reply_map_op *reply,\n\t\t       unsigned int n)\n{\n\treturn &reply->data[bpf->cmsg_key_sz * (n + 1) + bpf->cmsg_val_sz * n];\n}\n\nstatic bool nfp_bpf_ctrl_op_cache_invalidate(enum nfp_ccm_type op)\n{\n\treturn op == NFP_CCM_TYPE_BPF_MAP_UPDATE ||\n\t       op == NFP_CCM_TYPE_BPF_MAP_DELETE;\n}\n\nstatic bool nfp_bpf_ctrl_op_cache_capable(enum nfp_ccm_type op)\n{\n\treturn op == NFP_CCM_TYPE_BPF_MAP_LOOKUP ||\n\t       op == NFP_CCM_TYPE_BPF_MAP_GETNEXT;\n}\n\nstatic bool nfp_bpf_ctrl_op_cache_fill(enum nfp_ccm_type op)\n{\n\treturn op == NFP_CCM_TYPE_BPF_MAP_GETFIRST ||\n\t       op == NFP_CCM_TYPE_BPF_MAP_GETNEXT;\n}\n\nstatic unsigned int\nnfp_bpf_ctrl_op_cache_get(struct nfp_bpf_map *nfp_map, enum nfp_ccm_type op,\n\t\t\t  const u8 *key, u8 *out_key, u8 *out_value,\n\t\t\t  u32 *cache_gen)\n{\n\tstruct bpf_map *map = &nfp_map->offmap->map;\n\tstruct nfp_app_bpf *bpf = nfp_map->bpf;\n\tunsigned int i, count, n_entries;\n\tstruct cmsg_reply_map_op *reply;\n\n\tn_entries = nfp_bpf_ctrl_op_cache_fill(op) ? bpf->cmsg_cache_cnt : 1;\n\n\tspin_lock(&nfp_map->cache_lock);\n\t*cache_gen = nfp_map->cache_gen;\n\tif (nfp_map->cache_blockers)\n\t\tn_entries = 1;\n\n\tif (nfp_bpf_ctrl_op_cache_invalidate(op))\n\t\tgoto exit_block;\n\tif (!nfp_bpf_ctrl_op_cache_capable(op))\n\t\tgoto exit_unlock;\n\n\tif (!nfp_map->cache)\n\t\tgoto exit_unlock;\n\tif (nfp_map->cache_to < ktime_get_ns())\n\t\tgoto exit_invalidate;\n\n\treply = (void *)nfp_map->cache->data;\n\tcount = be32_to_cpu(reply->count);\n\n\tfor (i = 0; i < count; i++) {\n\t\tvoid *cached_key;\n\n\t\tcached_key = nfp_bpf_ctrl_reply_key(bpf, reply, i);\n\t\tif (memcmp(cached_key, key, map->key_size))\n\t\t\tcontinue;\n\n\t\tif (op == NFP_CCM_TYPE_BPF_MAP_LOOKUP)\n\t\t\tmemcpy(out_value, nfp_bpf_ctrl_reply_val(bpf, reply, i),\n\t\t\t       map->value_size);\n\t\tif (op == NFP_CCM_TYPE_BPF_MAP_GETNEXT) {\n\t\t\tif (i + 1 == count)\n\t\t\t\tbreak;\n\n\t\t\tmemcpy(out_key,\n\t\t\t       nfp_bpf_ctrl_reply_key(bpf, reply, i + 1),\n\t\t\t       map->key_size);\n\t\t}\n\n\t\tn_entries = 0;\n\t\tgoto exit_unlock;\n\t}\n\tgoto exit_unlock;\n\nexit_block:\n\tnfp_map->cache_blockers++;\nexit_invalidate:\n\tdev_consume_skb_any(nfp_map->cache);\n\tnfp_map->cache = NULL;\nexit_unlock:\n\tspin_unlock(&nfp_map->cache_lock);\n\treturn n_entries;\n}\n\nstatic void\nnfp_bpf_ctrl_op_cache_put(struct nfp_bpf_map *nfp_map, enum nfp_ccm_type op,\n\t\t\t  struct sk_buff *skb, u32 cache_gen)\n{\n\tbool blocker, filler;\n\n\tblocker = nfp_bpf_ctrl_op_cache_invalidate(op);\n\tfiller = nfp_bpf_ctrl_op_cache_fill(op);\n\tif (blocker || filler) {\n\t\tu64 to = 0;\n\n\t\tif (filler)\n\t\t\tto = ktime_get_ns() + NFP_BPF_MAP_CACHE_TIME_NS;\n\n\t\tspin_lock(&nfp_map->cache_lock);\n\t\tif (blocker) {\n\t\t\tnfp_map->cache_blockers--;\n\t\t\tnfp_map->cache_gen++;\n\t\t}\n\t\tif (filler && !nfp_map->cache_blockers &&\n\t\t    nfp_map->cache_gen == cache_gen) {\n\t\t\tnfp_map->cache_to = to;\n\t\t\tswap(nfp_map->cache, skb);\n\t\t}\n\t\tspin_unlock(&nfp_map->cache_lock);\n\t}\n\n\tdev_consume_skb_any(skb);\n}\n\nstatic int\nnfp_bpf_ctrl_entry_op(struct bpf_offloaded_map *offmap, enum nfp_ccm_type op,\n\t\t      u8 *key, u8 *value, u64 flags, u8 *out_key, u8 *out_value)\n{\n\tstruct nfp_bpf_map *nfp_map = offmap->dev_priv;\n\tunsigned int n_entries, reply_entries, count;\n\tstruct nfp_app_bpf *bpf = nfp_map->bpf;\n\tstruct bpf_map *map = &offmap->map;\n\tstruct cmsg_reply_map_op *reply;\n\tstruct cmsg_req_map_op *req;\n\tstruct sk_buff *skb;\n\tu32 cache_gen;\n\tint err;\n\n\t \n\tif (flags >> 32)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tn_entries = nfp_bpf_ctrl_op_cache_get(nfp_map, op, key, out_key,\n\t\t\t\t\t      out_value, &cache_gen);\n\tif (!n_entries)\n\t\treturn 0;\n\n\tskb = nfp_bpf_cmsg_map_req_alloc(bpf, 1);\n\tif (!skb) {\n\t\terr = -ENOMEM;\n\t\tgoto err_cache_put;\n\t}\n\n\treq = (void *)skb->data;\n\treq->tid = cpu_to_be32(nfp_map->tid);\n\treq->count = cpu_to_be32(n_entries);\n\treq->flags = cpu_to_be32(flags);\n\n\t \n\tif (key)\n\t\tmemcpy(nfp_bpf_ctrl_req_key(bpf, req, 0), key, map->key_size);\n\tif (value)\n\t\tmemcpy(nfp_bpf_ctrl_req_val(bpf, req, 0), value,\n\t\t       map->value_size);\n\n\tskb = nfp_ccm_communicate(&bpf->ccm, skb, op, 0);\n\tif (IS_ERR(skb)) {\n\t\terr = PTR_ERR(skb);\n\t\tgoto err_cache_put;\n\t}\n\n\tif (skb->len < sizeof(*reply)) {\n\t\tcmsg_warn(bpf, \"cmsg drop - type 0x%02x too short %d!\\n\",\n\t\t\t  op, skb->len);\n\t\terr = -EIO;\n\t\tgoto err_free;\n\t}\n\n\treply = (void *)skb->data;\n\tcount = be32_to_cpu(reply->count);\n\terr = nfp_bpf_ctrl_rc_to_errno(bpf, &reply->reply_hdr);\n\t \n\treply_entries = count + !!err;\n\tif (n_entries > 1 && count)\n\t\terr = 0;\n\tif (err)\n\t\tgoto err_free;\n\n\tif (skb->len != nfp_bpf_cmsg_map_reply_size(bpf, reply_entries)) {\n\t\tcmsg_warn(bpf, \"cmsg drop - type 0x%02x too short %d for %d entries!\\n\",\n\t\t\t  op, skb->len, reply_entries);\n\t\terr = -EIO;\n\t\tgoto err_free;\n\t}\n\n\t \n\tif (out_key)\n\t\tmemcpy(out_key, nfp_bpf_ctrl_reply_key(bpf, reply, 0),\n\t\t       map->key_size);\n\tif (out_value)\n\t\tmemcpy(out_value, nfp_bpf_ctrl_reply_val(bpf, reply, 0),\n\t\t       map->value_size);\n\n\tnfp_bpf_ctrl_op_cache_put(nfp_map, op, skb, cache_gen);\n\n\treturn 0;\nerr_free:\n\tdev_kfree_skb_any(skb);\nerr_cache_put:\n\tnfp_bpf_ctrl_op_cache_put(nfp_map, op, NULL, cache_gen);\n\treturn err;\n}\n\nint nfp_bpf_ctrl_update_entry(struct bpf_offloaded_map *offmap,\n\t\t\t      void *key, void *value, u64 flags)\n{\n\treturn nfp_bpf_ctrl_entry_op(offmap, NFP_CCM_TYPE_BPF_MAP_UPDATE,\n\t\t\t\t     key, value, flags, NULL, NULL);\n}\n\nint nfp_bpf_ctrl_del_entry(struct bpf_offloaded_map *offmap, void *key)\n{\n\treturn nfp_bpf_ctrl_entry_op(offmap, NFP_CCM_TYPE_BPF_MAP_DELETE,\n\t\t\t\t     key, NULL, 0, NULL, NULL);\n}\n\nint nfp_bpf_ctrl_lookup_entry(struct bpf_offloaded_map *offmap,\n\t\t\t      void *key, void *value)\n{\n\treturn nfp_bpf_ctrl_entry_op(offmap, NFP_CCM_TYPE_BPF_MAP_LOOKUP,\n\t\t\t\t     key, NULL, 0, NULL, value);\n}\n\nint nfp_bpf_ctrl_getfirst_entry(struct bpf_offloaded_map *offmap,\n\t\t\t\tvoid *next_key)\n{\n\treturn nfp_bpf_ctrl_entry_op(offmap, NFP_CCM_TYPE_BPF_MAP_GETFIRST,\n\t\t\t\t     NULL, NULL, 0, next_key, NULL);\n}\n\nint nfp_bpf_ctrl_getnext_entry(struct bpf_offloaded_map *offmap,\n\t\t\t       void *key, void *next_key)\n{\n\treturn nfp_bpf_ctrl_entry_op(offmap, NFP_CCM_TYPE_BPF_MAP_GETNEXT,\n\t\t\t\t     key, NULL, 0, next_key, NULL);\n}\n\nunsigned int nfp_bpf_ctrl_cmsg_min_mtu(struct nfp_app_bpf *bpf)\n{\n\treturn max(nfp_bpf_cmsg_map_req_size(bpf, 1),\n\t\t   nfp_bpf_cmsg_map_reply_size(bpf, 1));\n}\n\nunsigned int nfp_bpf_ctrl_cmsg_mtu(struct nfp_app_bpf *bpf)\n{\n\treturn max3(NFP_NET_DEFAULT_MTU,\n\t\t    nfp_bpf_cmsg_map_req_size(bpf, NFP_BPF_MAP_CACHE_CNT),\n\t\t    nfp_bpf_cmsg_map_reply_size(bpf, NFP_BPF_MAP_CACHE_CNT));\n}\n\nunsigned int nfp_bpf_ctrl_cmsg_cache_cnt(struct nfp_app_bpf *bpf)\n{\n\tunsigned int mtu, req_max, reply_max, entry_sz;\n\n\tmtu = bpf->app->ctrl->dp.mtu;\n\tentry_sz = bpf->cmsg_key_sz + bpf->cmsg_val_sz;\n\treq_max = (mtu - sizeof(struct cmsg_req_map_op)) / entry_sz;\n\treply_max = (mtu - sizeof(struct cmsg_reply_map_op)) / entry_sz;\n\n\treturn min3(req_max, reply_max, NFP_BPF_MAP_CACHE_CNT);\n}\n\nvoid nfp_bpf_ctrl_msg_rx(struct nfp_app *app, struct sk_buff *skb)\n{\n\tstruct nfp_app_bpf *bpf = app->priv;\n\n\tif (unlikely(skb->len < sizeof(struct cmsg_reply_map_simple))) {\n\t\tcmsg_warn(bpf, \"cmsg drop - too short %d!\\n\", skb->len);\n\t\tdev_kfree_skb_any(skb);\n\t\treturn;\n\t}\n\n\tif (nfp_ccm_get_type(skb) == NFP_CCM_TYPE_BPF_BPF_EVENT) {\n\t\tif (!nfp_bpf_event_output(bpf, skb->data, skb->len))\n\t\t\tdev_consume_skb_any(skb);\n\t\telse\n\t\t\tdev_kfree_skb_any(skb);\n\t\treturn;\n\t}\n\n\tnfp_ccm_rx(&bpf->ccm, skb);\n}\n\nvoid\nnfp_bpf_ctrl_msg_rx_raw(struct nfp_app *app, const void *data, unsigned int len)\n{\n\tconst struct nfp_ccm_hdr *hdr = data;\n\tstruct nfp_app_bpf *bpf = app->priv;\n\n\tif (unlikely(len < sizeof(struct cmsg_reply_map_simple))) {\n\t\tcmsg_warn(bpf, \"cmsg drop - too short %d!\\n\", len);\n\t\treturn;\n\t}\n\n\tif (hdr->type == NFP_CCM_TYPE_BPF_BPF_EVENT)\n\t\tnfp_bpf_event_output(bpf, data, len);\n\telse\n\t\tcmsg_warn(bpf, \"cmsg drop - msg type %d with raw buffer!\\n\",\n\t\t\t  hdr->type);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}