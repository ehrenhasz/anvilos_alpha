{
  "module_name": "jme.c",
  "hash_id": "15077c9a3871ca768d90fef8048ed987117bf7060c2caa2b3200e652a9b9a473",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/jme.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/mii.h>\n#include <linux/crc32.h>\n#include <linux/delay.h>\n#include <linux/spinlock.h>\n#include <linux/in.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <linux/if_vlan.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <net/ip6_checksum.h>\n#include \"jme.h\"\n\nstatic int force_pseudohp = -1;\nstatic int no_pseudohp = -1;\nstatic int no_extplug = -1;\nmodule_param(force_pseudohp, int, 0);\nMODULE_PARM_DESC(force_pseudohp,\n\t\"Enable pseudo hot-plug feature manually by driver instead of BIOS.\");\nmodule_param(no_pseudohp, int, 0);\nMODULE_PARM_DESC(no_pseudohp, \"Disable pseudo hot-plug feature.\");\nmodule_param(no_extplug, int, 0);\nMODULE_PARM_DESC(no_extplug,\n\t\"Do not use external plug signal for pseudo hot-plug.\");\n\nstatic int\njme_mdio_read(struct net_device *netdev, int phy, int reg)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tint i, val, again = (reg == MII_BMSR) ? 1 : 0;\n\nread_again:\n\tjwrite32(jme, JME_SMI, SMI_OP_REQ |\n\t\t\t\tsmi_phy_addr(phy) |\n\t\t\t\tsmi_reg_addr(reg));\n\n\twmb();\n\tfor (i = JME_PHY_TIMEOUT * 50 ; i > 0 ; --i) {\n\t\tudelay(20);\n\t\tval = jread32(jme, JME_SMI);\n\t\tif ((val & SMI_OP_REQ) == 0)\n\t\t\tbreak;\n\t}\n\n\tif (i == 0) {\n\t\tpr_err(\"phy(%d) read timeout : %d\\n\", phy, reg);\n\t\treturn 0;\n\t}\n\n\tif (again--)\n\t\tgoto read_again;\n\n\treturn (val & SMI_DATA_MASK) >> SMI_DATA_SHIFT;\n}\n\nstatic void\njme_mdio_write(struct net_device *netdev,\n\t\t\t\tint phy, int reg, int val)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tint i;\n\n\tjwrite32(jme, JME_SMI, SMI_OP_WRITE | SMI_OP_REQ |\n\t\t((val << SMI_DATA_SHIFT) & SMI_DATA_MASK) |\n\t\tsmi_phy_addr(phy) | smi_reg_addr(reg));\n\n\twmb();\n\tfor (i = JME_PHY_TIMEOUT * 50 ; i > 0 ; --i) {\n\t\tudelay(20);\n\t\tif ((jread32(jme, JME_SMI) & SMI_OP_REQ) == 0)\n\t\t\tbreak;\n\t}\n\n\tif (i == 0)\n\t\tpr_err(\"phy(%d) write timeout : %d\\n\", phy, reg);\n}\n\nstatic inline void\njme_reset_phy_processor(struct jme_adapter *jme)\n{\n\tu32 val;\n\n\tjme_mdio_write(jme->dev,\n\t\t\tjme->mii_if.phy_id,\n\t\t\tMII_ADVERTISE, ADVERTISE_ALL |\n\t\t\tADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);\n\n\tif (jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC250)\n\t\tjme_mdio_write(jme->dev,\n\t\t\t\tjme->mii_if.phy_id,\n\t\t\t\tMII_CTRL1000,\n\t\t\t\tADVERTISE_1000FULL | ADVERTISE_1000HALF);\n\n\tval = jme_mdio_read(jme->dev,\n\t\t\t\tjme->mii_if.phy_id,\n\t\t\t\tMII_BMCR);\n\n\tjme_mdio_write(jme->dev,\n\t\t\tjme->mii_if.phy_id,\n\t\t\tMII_BMCR, val | BMCR_RESET);\n}\n\nstatic void\njme_setup_wakeup_frame(struct jme_adapter *jme,\n\t\t       const u32 *mask, u32 crc, int fnr)\n{\n\tint i;\n\n\t \n\tjwrite32(jme, JME_WFOI, WFOI_CRC_SEL | (fnr & WFOI_FRAME_SEL));\n\twmb();\n\tjwrite32(jme, JME_WFODP, crc);\n\twmb();\n\n\t \n\tfor (i = 0 ; i < WAKEUP_FRAME_MASK_DWNR ; ++i) {\n\t\tjwrite32(jme, JME_WFOI,\n\t\t\t\t((i << WFOI_MASK_SHIFT) & WFOI_MASK_SEL) |\n\t\t\t\t(fnr & WFOI_FRAME_SEL));\n\t\twmb();\n\t\tjwrite32(jme, JME_WFODP, mask[i]);\n\t\twmb();\n\t}\n}\n\nstatic inline void\njme_mac_rxclk_off(struct jme_adapter *jme)\n{\n\tjme->reg_gpreg1 |= GPREG1_RXCLKOFF;\n\tjwrite32f(jme, JME_GPREG1, jme->reg_gpreg1);\n}\n\nstatic inline void\njme_mac_rxclk_on(struct jme_adapter *jme)\n{\n\tjme->reg_gpreg1 &= ~GPREG1_RXCLKOFF;\n\tjwrite32f(jme, JME_GPREG1, jme->reg_gpreg1);\n}\n\nstatic inline void\njme_mac_txclk_off(struct jme_adapter *jme)\n{\n\tjme->reg_ghc &= ~(GHC_TO_CLK_SRC | GHC_TXMAC_CLK_SRC);\n\tjwrite32f(jme, JME_GHC, jme->reg_ghc);\n}\n\nstatic inline void\njme_mac_txclk_on(struct jme_adapter *jme)\n{\n\tu32 speed = jme->reg_ghc & GHC_SPEED;\n\tif (speed == GHC_SPEED_1000M)\n\t\tjme->reg_ghc |= GHC_TO_CLK_GPHY | GHC_TXMAC_CLK_GPHY;\n\telse\n\t\tjme->reg_ghc |= GHC_TO_CLK_PCIE | GHC_TXMAC_CLK_PCIE;\n\tjwrite32f(jme, JME_GHC, jme->reg_ghc);\n}\n\nstatic inline void\njme_reset_ghc_speed(struct jme_adapter *jme)\n{\n\tjme->reg_ghc &= ~(GHC_SPEED | GHC_DPX);\n\tjwrite32f(jme, JME_GHC, jme->reg_ghc);\n}\n\nstatic inline void\njme_reset_250A2_workaround(struct jme_adapter *jme)\n{\n\tjme->reg_gpreg1 &= ~(GPREG1_HALFMODEPATCH |\n\t\t\t     GPREG1_RSSPATCH);\n\tjwrite32(jme, JME_GPREG1, jme->reg_gpreg1);\n}\n\nstatic inline void\njme_assert_ghc_reset(struct jme_adapter *jme)\n{\n\tjme->reg_ghc |= GHC_SWRST;\n\tjwrite32f(jme, JME_GHC, jme->reg_ghc);\n}\n\nstatic inline void\njme_clear_ghc_reset(struct jme_adapter *jme)\n{\n\tjme->reg_ghc &= ~GHC_SWRST;\n\tjwrite32f(jme, JME_GHC, jme->reg_ghc);\n}\n\nstatic void\njme_reset_mac_processor(struct jme_adapter *jme)\n{\n\tstatic const u32 mask[WAKEUP_FRAME_MASK_DWNR] = {0, 0, 0, 0};\n\tu32 crc = 0xCDCDCDCD;\n\tu32 gpreg0;\n\tint i;\n\n\tjme_reset_ghc_speed(jme);\n\tjme_reset_250A2_workaround(jme);\n\n\tjme_mac_rxclk_on(jme);\n\tjme_mac_txclk_on(jme);\n\tudelay(1);\n\tjme_assert_ghc_reset(jme);\n\tudelay(1);\n\tjme_mac_rxclk_off(jme);\n\tjme_mac_txclk_off(jme);\n\tudelay(1);\n\tjme_clear_ghc_reset(jme);\n\tudelay(1);\n\tjme_mac_rxclk_on(jme);\n\tjme_mac_txclk_on(jme);\n\tudelay(1);\n\tjme_mac_rxclk_off(jme);\n\tjme_mac_txclk_off(jme);\n\n\tjwrite32(jme, JME_RXDBA_LO, 0x00000000);\n\tjwrite32(jme, JME_RXDBA_HI, 0x00000000);\n\tjwrite32(jme, JME_RXQDC, 0x00000000);\n\tjwrite32(jme, JME_RXNDA, 0x00000000);\n\tjwrite32(jme, JME_TXDBA_LO, 0x00000000);\n\tjwrite32(jme, JME_TXDBA_HI, 0x00000000);\n\tjwrite32(jme, JME_TXQDC, 0x00000000);\n\tjwrite32(jme, JME_TXNDA, 0x00000000);\n\n\tjwrite32(jme, JME_RXMCHT_LO, 0x00000000);\n\tjwrite32(jme, JME_RXMCHT_HI, 0x00000000);\n\tfor (i = 0 ; i < WAKEUP_FRAME_NR ; ++i)\n\t\tjme_setup_wakeup_frame(jme, mask, crc, i);\n\tif (jme->fpgaver)\n\t\tgpreg0 = GPREG0_DEFAULT | GPREG0_LNKINTPOLL;\n\telse\n\t\tgpreg0 = GPREG0_DEFAULT;\n\tjwrite32(jme, JME_GPREG0, gpreg0);\n}\n\nstatic inline void\njme_clear_pm_enable_wol(struct jme_adapter *jme)\n{\n\tjwrite32(jme, JME_PMCS, PMCS_STMASK | jme->reg_pmcs);\n}\n\nstatic inline void\njme_clear_pm_disable_wol(struct jme_adapter *jme)\n{\n\tjwrite32(jme, JME_PMCS, PMCS_STMASK);\n}\n\nstatic int\njme_reload_eeprom(struct jme_adapter *jme)\n{\n\tu32 val;\n\tint i;\n\n\tval = jread32(jme, JME_SMBCSR);\n\n\tif (val & SMBCSR_EEPROMD) {\n\t\tval |= SMBCSR_CNACK;\n\t\tjwrite32(jme, JME_SMBCSR, val);\n\t\tval |= SMBCSR_RELOAD;\n\t\tjwrite32(jme, JME_SMBCSR, val);\n\t\tmdelay(12);\n\n\t\tfor (i = JME_EEPROM_RELOAD_TIMEOUT; i > 0; --i) {\n\t\t\tmdelay(1);\n\t\t\tif ((jread32(jme, JME_SMBCSR) & SMBCSR_RELOAD) == 0)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (i == 0) {\n\t\t\tpr_err(\"eeprom reload timeout\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void\njme_load_macaddr(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tunsigned char macaddr[ETH_ALEN];\n\tu32 val;\n\n\tspin_lock_bh(&jme->macaddr_lock);\n\tval = jread32(jme, JME_RXUMA_LO);\n\tmacaddr[0] = (val >>  0) & 0xFF;\n\tmacaddr[1] = (val >>  8) & 0xFF;\n\tmacaddr[2] = (val >> 16) & 0xFF;\n\tmacaddr[3] = (val >> 24) & 0xFF;\n\tval = jread32(jme, JME_RXUMA_HI);\n\tmacaddr[4] = (val >>  0) & 0xFF;\n\tmacaddr[5] = (val >>  8) & 0xFF;\n\teth_hw_addr_set(netdev, macaddr);\n\tspin_unlock_bh(&jme->macaddr_lock);\n}\n\nstatic inline void\njme_set_rx_pcc(struct jme_adapter *jme, int p)\n{\n\tswitch (p) {\n\tcase PCC_OFF:\n\t\tjwrite32(jme, JME_PCCRX0,\n\t\t\t((PCC_OFF_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\n\t\t\t((PCC_OFF_CNT << PCCRX_SHIFT) & PCCRX_MASK));\n\t\tbreak;\n\tcase PCC_P1:\n\t\tjwrite32(jme, JME_PCCRX0,\n\t\t\t((PCC_P1_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\n\t\t\t((PCC_P1_CNT << PCCRX_SHIFT) & PCCRX_MASK));\n\t\tbreak;\n\tcase PCC_P2:\n\t\tjwrite32(jme, JME_PCCRX0,\n\t\t\t((PCC_P2_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\n\t\t\t((PCC_P2_CNT << PCCRX_SHIFT) & PCCRX_MASK));\n\t\tbreak;\n\tcase PCC_P3:\n\t\tjwrite32(jme, JME_PCCRX0,\n\t\t\t((PCC_P3_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\n\t\t\t((PCC_P3_CNT << PCCRX_SHIFT) & PCCRX_MASK));\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\twmb();\n\n\tif (!(test_bit(JME_FLAG_POLL, &jme->flags)))\n\t\tnetif_info(jme, rx_status, jme->dev, \"Switched to PCC_P%d\\n\", p);\n}\n\nstatic void\njme_start_irq(struct jme_adapter *jme)\n{\n\tregister struct dynpcc_info *dpi = &(jme->dpi);\n\n\tjme_set_rx_pcc(jme, PCC_P1);\n\tdpi->cur\t\t= PCC_P1;\n\tdpi->attempt\t\t= PCC_P1;\n\tdpi->cnt\t\t= 0;\n\n\tjwrite32(jme, JME_PCCTX,\n\t\t\t((PCC_TX_TO << PCCTXTO_SHIFT) & PCCTXTO_MASK) |\n\t\t\t((PCC_TX_CNT << PCCTX_SHIFT) & PCCTX_MASK) |\n\t\t\tPCCTXQ0_EN\n\t\t);\n\n\t \n\tjwrite32(jme, JME_IENS, INTR_ENABLE);\n}\n\nstatic inline void\njme_stop_irq(struct jme_adapter *jme)\n{\n\t \n\tjwrite32f(jme, JME_IENC, INTR_ENABLE);\n}\n\nstatic u32\njme_linkstat_from_phy(struct jme_adapter *jme)\n{\n\tu32 phylink, bmsr;\n\n\tphylink = jme_mdio_read(jme->dev, jme->mii_if.phy_id, 17);\n\tbmsr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMSR);\n\tif (bmsr & BMSR_ANCOMP)\n\t\tphylink |= PHY_LINK_AUTONEG_COMPLETE;\n\n\treturn phylink;\n}\n\nstatic inline void\njme_set_phyfifo_5level(struct jme_adapter *jme)\n{\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, 27, 0x0004);\n}\n\nstatic inline void\njme_set_phyfifo_8level(struct jme_adapter *jme)\n{\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, 27, 0x0000);\n}\n\nstatic int\njme_check_link(struct net_device *netdev, int testonly)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 phylink, cnt = JME_SPDRSV_TIMEOUT, bmcr;\n\tchar linkmsg[64];\n\tint rc = 0;\n\n\tlinkmsg[0] = '\\0';\n\n\tif (jme->fpgaver)\n\t\tphylink = jme_linkstat_from_phy(jme);\n\telse\n\t\tphylink = jread32(jme, JME_PHY_LINK);\n\n\tif (phylink & PHY_LINK_UP) {\n\t\tif (!(phylink & PHY_LINK_AUTONEG_COMPLETE)) {\n\t\t\t \n\t\t\tphylink = PHY_LINK_UP;\n\n\t\t\tbmcr = jme_mdio_read(jme->dev,\n\t\t\t\t\t\tjme->mii_if.phy_id,\n\t\t\t\t\t\tMII_BMCR);\n\n\t\t\tphylink |= ((bmcr & BMCR_SPEED1000) &&\n\t\t\t\t\t(bmcr & BMCR_SPEED100) == 0) ?\n\t\t\t\t\tPHY_LINK_SPEED_1000M :\n\t\t\t\t\t(bmcr & BMCR_SPEED100) ?\n\t\t\t\t\tPHY_LINK_SPEED_100M :\n\t\t\t\t\tPHY_LINK_SPEED_10M;\n\n\t\t\tphylink |= (bmcr & BMCR_FULLDPLX) ?\n\t\t\t\t\t PHY_LINK_DUPLEX : 0;\n\n\t\t\tstrcat(linkmsg, \"Forced: \");\n\t\t} else {\n\t\t\t \n\t\t\twhile (!(phylink & PHY_LINK_SPEEDDPU_RESOLVED) &&\n\t\t\t\t--cnt) {\n\n\t\t\t\tudelay(1);\n\n\t\t\t\tif (jme->fpgaver)\n\t\t\t\t\tphylink = jme_linkstat_from_phy(jme);\n\t\t\t\telse\n\t\t\t\t\tphylink = jread32(jme, JME_PHY_LINK);\n\t\t\t}\n\t\t\tif (!cnt)\n\t\t\t\tpr_err(\"Waiting speed resolve timeout\\n\");\n\n\t\t\tstrcat(linkmsg, \"ANed: \");\n\t\t}\n\n\t\tif (jme->phylink == phylink) {\n\t\t\trc = 1;\n\t\t\tgoto out;\n\t\t}\n\t\tif (testonly)\n\t\t\tgoto out;\n\n\t\tjme->phylink = phylink;\n\n\t\t \n\t\tswitch (phylink & PHY_LINK_SPEED_MASK) {\n\t\tcase PHY_LINK_SPEED_10M:\n\t\t\tjme->reg_ghc |= GHC_SPEED_10M;\n\t\t\tstrcat(linkmsg, \"10 Mbps, \");\n\t\t\tbreak;\n\t\tcase PHY_LINK_SPEED_100M:\n\t\t\tjme->reg_ghc |= GHC_SPEED_100M;\n\t\t\tstrcat(linkmsg, \"100 Mbps, \");\n\t\t\tbreak;\n\t\tcase PHY_LINK_SPEED_1000M:\n\t\t\tjme->reg_ghc |= GHC_SPEED_1000M;\n\t\t\tstrcat(linkmsg, \"1000 Mbps, \");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (phylink & PHY_LINK_DUPLEX) {\n\t\t\tjwrite32(jme, JME_TXMCS, TXMCS_DEFAULT);\n\t\t\tjwrite32(jme, JME_TXTRHD, TXTRHD_FULLDUPLEX);\n\t\t\tjme->reg_ghc |= GHC_DPX;\n\t\t} else {\n\t\t\tjwrite32(jme, JME_TXMCS, TXMCS_DEFAULT |\n\t\t\t\t\t\tTXMCS_BACKOFF |\n\t\t\t\t\t\tTXMCS_CARRIERSENSE |\n\t\t\t\t\t\tTXMCS_COLLISION);\n\t\t\tjwrite32(jme, JME_TXTRHD, TXTRHD_HALFDUPLEX);\n\t\t}\n\n\t\tjwrite32(jme, JME_GHC, jme->reg_ghc);\n\n\t\tif (is_buggy250(jme->pdev->device, jme->chiprev)) {\n\t\t\tjme->reg_gpreg1 &= ~(GPREG1_HALFMODEPATCH |\n\t\t\t\t\t     GPREG1_RSSPATCH);\n\t\t\tif (!(phylink & PHY_LINK_DUPLEX))\n\t\t\t\tjme->reg_gpreg1 |= GPREG1_HALFMODEPATCH;\n\t\t\tswitch (phylink & PHY_LINK_SPEED_MASK) {\n\t\t\tcase PHY_LINK_SPEED_10M:\n\t\t\t\tjme_set_phyfifo_8level(jme);\n\t\t\t\tjme->reg_gpreg1 |= GPREG1_RSSPATCH;\n\t\t\t\tbreak;\n\t\t\tcase PHY_LINK_SPEED_100M:\n\t\t\t\tjme_set_phyfifo_5level(jme);\n\t\t\t\tjme->reg_gpreg1 |= GPREG1_RSSPATCH;\n\t\t\t\tbreak;\n\t\t\tcase PHY_LINK_SPEED_1000M:\n\t\t\t\tjme_set_phyfifo_8level(jme);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tjwrite32(jme, JME_GPREG1, jme->reg_gpreg1);\n\n\t\tstrcat(linkmsg, (phylink & PHY_LINK_DUPLEX) ?\n\t\t\t\t\t\"Full-Duplex, \" :\n\t\t\t\t\t\"Half-Duplex, \");\n\t\tstrcat(linkmsg, (phylink & PHY_LINK_MDI_STAT) ?\n\t\t\t\t\t\"MDI-X\" :\n\t\t\t\t\t\"MDI\");\n\t\tnetif_info(jme, link, jme->dev, \"Link is up at %s\\n\", linkmsg);\n\t\tnetif_carrier_on(netdev);\n\t} else {\n\t\tif (testonly)\n\t\t\tgoto out;\n\n\t\tnetif_info(jme, link, jme->dev, \"Link is down\\n\");\n\t\tjme->phylink = 0;\n\t\tnetif_carrier_off(netdev);\n\t}\n\nout:\n\treturn rc;\n}\n\nstatic int\njme_setup_tx_resources(struct jme_adapter *jme)\n{\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\n\ttxring->alloc = dma_alloc_coherent(&(jme->pdev->dev),\n\t\t\t\t   TX_RING_ALLOC_SIZE(jme->tx_ring_size),\n\t\t\t\t   &(txring->dmaalloc),\n\t\t\t\t   GFP_ATOMIC);\n\n\tif (!txring->alloc)\n\t\tgoto err_set_null;\n\n\t \n\ttxring->desc\t\t= (void *)ALIGN((unsigned long)(txring->alloc),\n\t\t\t\t\t\tRING_DESC_ALIGN);\n\ttxring->dma\t\t= ALIGN(txring->dmaalloc, RING_DESC_ALIGN);\n\ttxring->next_to_use\t= 0;\n\tatomic_set(&txring->next_to_clean, 0);\n\tatomic_set(&txring->nr_free, jme->tx_ring_size);\n\n\ttxring->bufinf\t\t= kcalloc(jme->tx_ring_size,\n\t\t\t\t\t\tsizeof(struct jme_buffer_info),\n\t\t\t\t\t\tGFP_ATOMIC);\n\tif (unlikely(!(txring->bufinf)))\n\t\tgoto err_free_txring;\n\n\treturn 0;\n\nerr_free_txring:\n\tdma_free_coherent(&(jme->pdev->dev),\n\t\t\t  TX_RING_ALLOC_SIZE(jme->tx_ring_size),\n\t\t\t  txring->alloc,\n\t\t\t  txring->dmaalloc);\n\nerr_set_null:\n\ttxring->desc = NULL;\n\ttxring->dmaalloc = 0;\n\ttxring->dma = 0;\n\ttxring->bufinf = NULL;\n\n\treturn -ENOMEM;\n}\n\nstatic void\njme_free_tx_resources(struct jme_adapter *jme)\n{\n\tint i;\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\tstruct jme_buffer_info *txbi;\n\n\tif (txring->alloc) {\n\t\tif (txring->bufinf) {\n\t\t\tfor (i = 0 ; i < jme->tx_ring_size ; ++i) {\n\t\t\t\ttxbi = txring->bufinf + i;\n\t\t\t\tif (txbi->skb) {\n\t\t\t\t\tdev_kfree_skb(txbi->skb);\n\t\t\t\t\ttxbi->skb = NULL;\n\t\t\t\t}\n\t\t\t\ttxbi->mapping\t\t= 0;\n\t\t\t\ttxbi->len\t\t= 0;\n\t\t\t\ttxbi->nr_desc\t\t= 0;\n\t\t\t\ttxbi->start_xmit\t= 0;\n\t\t\t}\n\t\t\tkfree(txring->bufinf);\n\t\t}\n\n\t\tdma_free_coherent(&(jme->pdev->dev),\n\t\t\t\t  TX_RING_ALLOC_SIZE(jme->tx_ring_size),\n\t\t\t\t  txring->alloc,\n\t\t\t\t  txring->dmaalloc);\n\n\t\ttxring->alloc\t\t= NULL;\n\t\ttxring->desc\t\t= NULL;\n\t\ttxring->dmaalloc\t= 0;\n\t\ttxring->dma\t\t= 0;\n\t\ttxring->bufinf\t\t= NULL;\n\t}\n\ttxring->next_to_use\t= 0;\n\tatomic_set(&txring->next_to_clean, 0);\n\tatomic_set(&txring->nr_free, 0);\n}\n\nstatic inline void\njme_enable_tx_engine(struct jme_adapter *jme)\n{\n\t \n\tjwrite32(jme, JME_TXCS, TXCS_DEFAULT | TXCS_SELECT_QUEUE0);\n\twmb();\n\n\t \n\tjwrite32(jme, JME_TXDBA_LO, (__u64)jme->txring[0].dma & 0xFFFFFFFFUL);\n\tjwrite32(jme, JME_TXDBA_HI, (__u64)(jme->txring[0].dma) >> 32);\n\tjwrite32(jme, JME_TXNDA, (__u64)jme->txring[0].dma & 0xFFFFFFFFUL);\n\n\t \n\tjwrite32(jme, JME_TXQDC, jme->tx_ring_size);\n\n\t \n\twmb();\n\tjwrite32f(jme, JME_TXCS, jme->reg_txcs |\n\t\t\t\tTXCS_SELECT_QUEUE0 |\n\t\t\t\tTXCS_ENABLE);\n\n\t \n\tjme_mac_txclk_on(jme);\n}\n\nstatic inline void\njme_disable_tx_engine(struct jme_adapter *jme)\n{\n\tint i;\n\tu32 val;\n\n\t \n\tjwrite32(jme, JME_TXCS, jme->reg_txcs | TXCS_SELECT_QUEUE0);\n\twmb();\n\n\tval = jread32(jme, JME_TXCS);\n\tfor (i = JME_TX_DISABLE_TIMEOUT ; (val & TXCS_ENABLE) && i > 0 ; --i) {\n\t\tmdelay(1);\n\t\tval = jread32(jme, JME_TXCS);\n\t\trmb();\n\t}\n\n\tif (!i)\n\t\tpr_err(\"Disable TX engine timeout\\n\");\n\n\t \n\tjme_mac_txclk_off(jme);\n}\n\nstatic void\njme_set_clean_rxdesc(struct jme_adapter *jme, int i)\n{\n\tstruct jme_ring *rxring = &(jme->rxring[0]);\n\tregister struct rxdesc *rxdesc = rxring->desc;\n\tstruct jme_buffer_info *rxbi = rxring->bufinf;\n\trxdesc += i;\n\trxbi += i;\n\n\trxdesc->dw[0] = 0;\n\trxdesc->dw[1] = 0;\n\trxdesc->desc1.bufaddrh\t= cpu_to_le32((__u64)rxbi->mapping >> 32);\n\trxdesc->desc1.bufaddrl\t= cpu_to_le32(\n\t\t\t\t\t(__u64)rxbi->mapping & 0xFFFFFFFFUL);\n\trxdesc->desc1.datalen\t= cpu_to_le16(rxbi->len);\n\tif (jme->dev->features & NETIF_F_HIGHDMA)\n\t\trxdesc->desc1.flags = RXFLAG_64BIT;\n\twmb();\n\trxdesc->desc1.flags\t|= RXFLAG_OWN | RXFLAG_INT;\n}\n\nstatic int\njme_make_new_rx_buf(struct jme_adapter *jme, int i)\n{\n\tstruct jme_ring *rxring = &(jme->rxring[0]);\n\tstruct jme_buffer_info *rxbi = rxring->bufinf + i;\n\tstruct sk_buff *skb;\n\tdma_addr_t mapping;\n\n\tskb = netdev_alloc_skb(jme->dev,\n\t\tjme->dev->mtu + RX_EXTRA_LEN);\n\tif (unlikely(!skb))\n\t\treturn -ENOMEM;\n\n\tmapping = dma_map_page(&jme->pdev->dev, virt_to_page(skb->data),\n\t\t\t       offset_in_page(skb->data), skb_tailroom(skb),\n\t\t\t       DMA_FROM_DEVICE);\n\tif (unlikely(dma_mapping_error(&jme->pdev->dev, mapping))) {\n\t\tdev_kfree_skb(skb);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (likely(rxbi->mapping))\n\t\tdma_unmap_page(&jme->pdev->dev, rxbi->mapping, rxbi->len,\n\t\t\t       DMA_FROM_DEVICE);\n\n\trxbi->skb = skb;\n\trxbi->len = skb_tailroom(skb);\n\trxbi->mapping = mapping;\n\treturn 0;\n}\n\nstatic void\njme_free_rx_buf(struct jme_adapter *jme, int i)\n{\n\tstruct jme_ring *rxring = &(jme->rxring[0]);\n\tstruct jme_buffer_info *rxbi = rxring->bufinf;\n\trxbi += i;\n\n\tif (rxbi->skb) {\n\t\tdma_unmap_page(&jme->pdev->dev, rxbi->mapping, rxbi->len,\n\t\t\t       DMA_FROM_DEVICE);\n\t\tdev_kfree_skb(rxbi->skb);\n\t\trxbi->skb = NULL;\n\t\trxbi->mapping = 0;\n\t\trxbi->len = 0;\n\t}\n}\n\nstatic void\njme_free_rx_resources(struct jme_adapter *jme)\n{\n\tint i;\n\tstruct jme_ring *rxring = &(jme->rxring[0]);\n\n\tif (rxring->alloc) {\n\t\tif (rxring->bufinf) {\n\t\t\tfor (i = 0 ; i < jme->rx_ring_size ; ++i)\n\t\t\t\tjme_free_rx_buf(jme, i);\n\t\t\tkfree(rxring->bufinf);\n\t\t}\n\n\t\tdma_free_coherent(&(jme->pdev->dev),\n\t\t\t\t  RX_RING_ALLOC_SIZE(jme->rx_ring_size),\n\t\t\t\t  rxring->alloc,\n\t\t\t\t  rxring->dmaalloc);\n\t\trxring->alloc    = NULL;\n\t\trxring->desc     = NULL;\n\t\trxring->dmaalloc = 0;\n\t\trxring->dma      = 0;\n\t\trxring->bufinf   = NULL;\n\t}\n\trxring->next_to_use   = 0;\n\tatomic_set(&rxring->next_to_clean, 0);\n}\n\nstatic int\njme_setup_rx_resources(struct jme_adapter *jme)\n{\n\tint i;\n\tstruct jme_ring *rxring = &(jme->rxring[0]);\n\n\trxring->alloc = dma_alloc_coherent(&(jme->pdev->dev),\n\t\t\t\t   RX_RING_ALLOC_SIZE(jme->rx_ring_size),\n\t\t\t\t   &(rxring->dmaalloc),\n\t\t\t\t   GFP_ATOMIC);\n\tif (!rxring->alloc)\n\t\tgoto err_set_null;\n\n\t \n\trxring->desc\t\t= (void *)ALIGN((unsigned long)(rxring->alloc),\n\t\t\t\t\t\tRING_DESC_ALIGN);\n\trxring->dma\t\t= ALIGN(rxring->dmaalloc, RING_DESC_ALIGN);\n\trxring->next_to_use\t= 0;\n\tatomic_set(&rxring->next_to_clean, 0);\n\n\trxring->bufinf\t\t= kcalloc(jme->rx_ring_size,\n\t\t\t\t\t\tsizeof(struct jme_buffer_info),\n\t\t\t\t\t\tGFP_ATOMIC);\n\tif (unlikely(!(rxring->bufinf)))\n\t\tgoto err_free_rxring;\n\n\t \n\tfor (i = 0 ; i < jme->rx_ring_size ; ++i) {\n\t\tif (unlikely(jme_make_new_rx_buf(jme, i))) {\n\t\t\tjme_free_rx_resources(jme);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tjme_set_clean_rxdesc(jme, i);\n\t}\n\n\treturn 0;\n\nerr_free_rxring:\n\tdma_free_coherent(&(jme->pdev->dev),\n\t\t\t  RX_RING_ALLOC_SIZE(jme->rx_ring_size),\n\t\t\t  rxring->alloc,\n\t\t\t  rxring->dmaalloc);\nerr_set_null:\n\trxring->desc = NULL;\n\trxring->dmaalloc = 0;\n\trxring->dma = 0;\n\trxring->bufinf = NULL;\n\n\treturn -ENOMEM;\n}\n\nstatic inline void\njme_enable_rx_engine(struct jme_adapter *jme)\n{\n\t \n\tjwrite32(jme, JME_RXCS, jme->reg_rxcs |\n\t\t\t\tRXCS_QUEUESEL_Q0);\n\twmb();\n\n\t \n\tjwrite32(jme, JME_RXDBA_LO, (__u64)(jme->rxring[0].dma) & 0xFFFFFFFFUL);\n\tjwrite32(jme, JME_RXDBA_HI, (__u64)(jme->rxring[0].dma) >> 32);\n\tjwrite32(jme, JME_RXNDA, (__u64)(jme->rxring[0].dma) & 0xFFFFFFFFUL);\n\n\t \n\tjwrite32(jme, JME_RXQDC, jme->rx_ring_size);\n\n\t \n\tjme_set_unicastaddr(jme->dev);\n\tjme_set_multi(jme->dev);\n\n\t \n\twmb();\n\tjwrite32f(jme, JME_RXCS, jme->reg_rxcs |\n\t\t\t\tRXCS_QUEUESEL_Q0 |\n\t\t\t\tRXCS_ENABLE |\n\t\t\t\tRXCS_QST);\n\n\t \n\tjme_mac_rxclk_on(jme);\n}\n\nstatic inline void\njme_restart_rx_engine(struct jme_adapter *jme)\n{\n\t \n\tjwrite32(jme, JME_RXCS, jme->reg_rxcs |\n\t\t\t\tRXCS_QUEUESEL_Q0 |\n\t\t\t\tRXCS_ENABLE |\n\t\t\t\tRXCS_QST);\n}\n\nstatic inline void\njme_disable_rx_engine(struct jme_adapter *jme)\n{\n\tint i;\n\tu32 val;\n\n\t \n\tjwrite32(jme, JME_RXCS, jme->reg_rxcs);\n\twmb();\n\n\tval = jread32(jme, JME_RXCS);\n\tfor (i = JME_RX_DISABLE_TIMEOUT ; (val & RXCS_ENABLE) && i > 0 ; --i) {\n\t\tmdelay(1);\n\t\tval = jread32(jme, JME_RXCS);\n\t\trmb();\n\t}\n\n\tif (!i)\n\t\tpr_err(\"Disable RX engine timeout\\n\");\n\n\t \n\tjme_mac_rxclk_off(jme);\n}\n\nstatic u16\njme_udpsum(struct sk_buff *skb)\n{\n\tu16 csum = 0xFFFFu;\n\n\tif (skb->len < (ETH_HLEN + sizeof(struct iphdr)))\n\t\treturn csum;\n\tif (skb->protocol != htons(ETH_P_IP))\n\t\treturn csum;\n\tskb_set_network_header(skb, ETH_HLEN);\n\tif ((ip_hdr(skb)->protocol != IPPROTO_UDP) ||\n\t    (skb->len < (ETH_HLEN +\n\t\t\t(ip_hdr(skb)->ihl << 2) +\n\t\t\tsizeof(struct udphdr)))) {\n\t\tskb_reset_network_header(skb);\n\t\treturn csum;\n\t}\n\tskb_set_transport_header(skb,\n\t\t\tETH_HLEN + (ip_hdr(skb)->ihl << 2));\n\tcsum = udp_hdr(skb)->check;\n\tskb_reset_transport_header(skb);\n\tskb_reset_network_header(skb);\n\n\treturn csum;\n}\n\nstatic int\njme_rxsum_ok(struct jme_adapter *jme, u16 flags, struct sk_buff *skb)\n{\n\tif (!(flags & (RXWBFLAG_TCPON | RXWBFLAG_UDPON | RXWBFLAG_IPV4)))\n\t\treturn false;\n\n\tif (unlikely((flags & (RXWBFLAG_MF | RXWBFLAG_TCPON | RXWBFLAG_TCPCS))\n\t\t\t== RXWBFLAG_TCPON)) {\n\t\tif (flags & RXWBFLAG_IPV4)\n\t\t\tnetif_err(jme, rx_err, jme->dev, \"TCP Checksum error\\n\");\n\t\treturn false;\n\t}\n\n\tif (unlikely((flags & (RXWBFLAG_MF | RXWBFLAG_UDPON | RXWBFLAG_UDPCS))\n\t\t\t== RXWBFLAG_UDPON) && jme_udpsum(skb)) {\n\t\tif (flags & RXWBFLAG_IPV4)\n\t\t\tnetif_err(jme, rx_err, jme->dev, \"UDP Checksum error\\n\");\n\t\treturn false;\n\t}\n\n\tif (unlikely((flags & (RXWBFLAG_IPV4 | RXWBFLAG_IPCS))\n\t\t\t== RXWBFLAG_IPV4)) {\n\t\tnetif_err(jme, rx_err, jme->dev, \"IPv4 Checksum error\\n\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void\njme_alloc_and_feed_skb(struct jme_adapter *jme, int idx)\n{\n\tstruct jme_ring *rxring = &(jme->rxring[0]);\n\tstruct rxdesc *rxdesc = rxring->desc;\n\tstruct jme_buffer_info *rxbi = rxring->bufinf;\n\tstruct sk_buff *skb;\n\tint framesize;\n\n\trxdesc += idx;\n\trxbi += idx;\n\n\tskb = rxbi->skb;\n\tdma_sync_single_for_cpu(&jme->pdev->dev, rxbi->mapping, rxbi->len,\n\t\t\t\tDMA_FROM_DEVICE);\n\n\tif (unlikely(jme_make_new_rx_buf(jme, idx))) {\n\t\tdma_sync_single_for_device(&jme->pdev->dev, rxbi->mapping,\n\t\t\t\t\t   rxbi->len, DMA_FROM_DEVICE);\n\n\t\t++(NET_STAT(jme).rx_dropped);\n\t} else {\n\t\tframesize = le16_to_cpu(rxdesc->descwb.framesize)\n\t\t\t\t- RX_PREPAD_SIZE;\n\n\t\tskb_reserve(skb, RX_PREPAD_SIZE);\n\t\tskb_put(skb, framesize);\n\t\tskb->protocol = eth_type_trans(skb, jme->dev);\n\n\t\tif (jme_rxsum_ok(jme, le16_to_cpu(rxdesc->descwb.flags), skb))\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\telse\n\t\t\tskb_checksum_none_assert(skb);\n\n\t\tif (rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_TAGON)) {\n\t\t\tu16 vid = le16_to_cpu(rxdesc->descwb.vlan);\n\n\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\n\t\t\tNET_STAT(jme).rx_bytes += 4;\n\t\t}\n\t\tjme->jme_rx(skb);\n\n\t\tif ((rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_DEST)) ==\n\t\t    cpu_to_le16(RXWBFLAG_DEST_MUL))\n\t\t\t++(NET_STAT(jme).multicast);\n\n\t\tNET_STAT(jme).rx_bytes += framesize;\n\t\t++(NET_STAT(jme).rx_packets);\n\t}\n\n\tjme_set_clean_rxdesc(jme, idx);\n\n}\n\nstatic int\njme_process_receive(struct jme_adapter *jme, int limit)\n{\n\tstruct jme_ring *rxring = &(jme->rxring[0]);\n\tstruct rxdesc *rxdesc;\n\tint i, j, ccnt, desccnt, mask = jme->rx_ring_mask;\n\n\tif (unlikely(!atomic_dec_and_test(&jme->rx_cleaning)))\n\t\tgoto out_inc;\n\n\tif (unlikely(atomic_read(&jme->link_changing) != 1))\n\t\tgoto out_inc;\n\n\tif (unlikely(!netif_carrier_ok(jme->dev)))\n\t\tgoto out_inc;\n\n\ti = atomic_read(&rxring->next_to_clean);\n\twhile (limit > 0) {\n\t\trxdesc = rxring->desc;\n\t\trxdesc += i;\n\n\t\tif ((rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_OWN)) ||\n\t\t!(rxdesc->descwb.desccnt & RXWBDCNT_WBCPL))\n\t\t\tgoto out;\n\t\t--limit;\n\n\t\trmb();\n\t\tdesccnt = rxdesc->descwb.desccnt & RXWBDCNT_DCNT;\n\n\t\tif (unlikely(desccnt > 1 ||\n\t\trxdesc->descwb.errstat & RXWBERR_ALLERR)) {\n\n\t\t\tif (rxdesc->descwb.errstat & RXWBERR_CRCERR)\n\t\t\t\t++(NET_STAT(jme).rx_crc_errors);\n\t\t\telse if (rxdesc->descwb.errstat & RXWBERR_OVERUN)\n\t\t\t\t++(NET_STAT(jme).rx_fifo_errors);\n\t\t\telse\n\t\t\t\t++(NET_STAT(jme).rx_errors);\n\n\t\t\tif (desccnt > 1)\n\t\t\t\tlimit -= desccnt - 1;\n\n\t\t\tfor (j = i, ccnt = desccnt ; ccnt-- ; ) {\n\t\t\t\tjme_set_clean_rxdesc(jme, j);\n\t\t\t\tj = (j + 1) & (mask);\n\t\t\t}\n\n\t\t} else {\n\t\t\tjme_alloc_and_feed_skb(jme, i);\n\t\t}\n\n\t\ti = (i + desccnt) & (mask);\n\t}\n\nout:\n\tatomic_set(&rxring->next_to_clean, i);\n\nout_inc:\n\tatomic_inc(&jme->rx_cleaning);\n\n\treturn limit > 0 ? limit : 0;\n\n}\n\nstatic void\njme_attempt_pcc(struct dynpcc_info *dpi, int atmp)\n{\n\tif (likely(atmp == dpi->cur)) {\n\t\tdpi->cnt = 0;\n\t\treturn;\n\t}\n\n\tif (dpi->attempt == atmp) {\n\t\t++(dpi->cnt);\n\t} else {\n\t\tdpi->attempt = atmp;\n\t\tdpi->cnt = 0;\n\t}\n\n}\n\nstatic void\njme_dynamic_pcc(struct jme_adapter *jme)\n{\n\tregister struct dynpcc_info *dpi = &(jme->dpi);\n\n\tif ((NET_STAT(jme).rx_bytes - dpi->last_bytes) > PCC_P3_THRESHOLD)\n\t\tjme_attempt_pcc(dpi, PCC_P3);\n\telse if ((NET_STAT(jme).rx_packets - dpi->last_pkts) > PCC_P2_THRESHOLD ||\n\t\t dpi->intr_cnt > PCC_INTR_THRESHOLD)\n\t\tjme_attempt_pcc(dpi, PCC_P2);\n\telse\n\t\tjme_attempt_pcc(dpi, PCC_P1);\n\n\tif (unlikely(dpi->attempt != dpi->cur && dpi->cnt > 5)) {\n\t\tif (dpi->attempt < dpi->cur)\n\t\t\ttasklet_schedule(&jme->rxclean_task);\n\t\tjme_set_rx_pcc(jme, dpi->attempt);\n\t\tdpi->cur = dpi->attempt;\n\t\tdpi->cnt = 0;\n\t}\n}\n\nstatic void\njme_start_pcc_timer(struct jme_adapter *jme)\n{\n\tstruct dynpcc_info *dpi = &(jme->dpi);\n\tdpi->last_bytes\t\t= NET_STAT(jme).rx_bytes;\n\tdpi->last_pkts\t\t= NET_STAT(jme).rx_packets;\n\tdpi->intr_cnt\t\t= 0;\n\tjwrite32(jme, JME_TMCSR,\n\t\tTMCSR_EN | ((0xFFFFFF - PCC_INTERVAL_US) & TMCSR_CNT));\n}\n\nstatic inline void\njme_stop_pcc_timer(struct jme_adapter *jme)\n{\n\tjwrite32(jme, JME_TMCSR, 0);\n}\n\nstatic void\njme_shutdown_nic(struct jme_adapter *jme)\n{\n\tu32 phylink;\n\n\tphylink = jme_linkstat_from_phy(jme);\n\n\tif (!(phylink & PHY_LINK_UP)) {\n\t\t \n\t\tjme_stop_irq(jme);\n\t\tjwrite32(jme, JME_TIMER2, TMCSR_EN | 0xFFFFFE);\n\t}\n}\n\nstatic void\njme_pcc_tasklet(struct tasklet_struct *t)\n{\n\tstruct jme_adapter *jme = from_tasklet(jme, t, pcc_task);\n\tstruct net_device *netdev = jme->dev;\n\n\tif (unlikely(test_bit(JME_FLAG_SHUTDOWN, &jme->flags))) {\n\t\tjme_shutdown_nic(jme);\n\t\treturn;\n\t}\n\n\tif (unlikely(!netif_carrier_ok(netdev) ||\n\t\t(atomic_read(&jme->link_changing) != 1)\n\t)) {\n\t\tjme_stop_pcc_timer(jme);\n\t\treturn;\n\t}\n\n\tif (!(test_bit(JME_FLAG_POLL, &jme->flags)))\n\t\tjme_dynamic_pcc(jme);\n\n\tjme_start_pcc_timer(jme);\n}\n\nstatic inline void\njme_polling_mode(struct jme_adapter *jme)\n{\n\tjme_set_rx_pcc(jme, PCC_OFF);\n}\n\nstatic inline void\njme_interrupt_mode(struct jme_adapter *jme)\n{\n\tjme_set_rx_pcc(jme, PCC_P1);\n}\n\nstatic inline int\njme_pseudo_hotplug_enabled(struct jme_adapter *jme)\n{\n\tu32 apmc;\n\tapmc = jread32(jme, JME_APMC);\n\treturn apmc & JME_APMC_PSEUDO_HP_EN;\n}\n\nstatic void\njme_start_shutdown_timer(struct jme_adapter *jme)\n{\n\tu32 apmc;\n\n\tapmc = jread32(jme, JME_APMC) | JME_APMC_PCIE_SD_EN;\n\tapmc &= ~JME_APMC_EPIEN_CTRL;\n\tif (!no_extplug) {\n\t\tjwrite32f(jme, JME_APMC, apmc | JME_APMC_EPIEN_CTRL_EN);\n\t\twmb();\n\t}\n\tjwrite32f(jme, JME_APMC, apmc);\n\n\tjwrite32f(jme, JME_TIMER2, 0);\n\tset_bit(JME_FLAG_SHUTDOWN, &jme->flags);\n\tjwrite32(jme, JME_TMCSR,\n\t\tTMCSR_EN | ((0xFFFFFF - APMC_PHP_SHUTDOWN_DELAY) & TMCSR_CNT));\n}\n\nstatic void\njme_stop_shutdown_timer(struct jme_adapter *jme)\n{\n\tu32 apmc;\n\n\tjwrite32f(jme, JME_TMCSR, 0);\n\tjwrite32f(jme, JME_TIMER2, 0);\n\tclear_bit(JME_FLAG_SHUTDOWN, &jme->flags);\n\n\tapmc = jread32(jme, JME_APMC);\n\tapmc &= ~(JME_APMC_PCIE_SD_EN | JME_APMC_EPIEN_CTRL);\n\tjwrite32f(jme, JME_APMC, apmc | JME_APMC_EPIEN_CTRL_DIS);\n\twmb();\n\tjwrite32f(jme, JME_APMC, apmc);\n}\n\nstatic void jme_link_change_work(struct work_struct *work)\n{\n\tstruct jme_adapter *jme = container_of(work, struct jme_adapter, linkch_task);\n\tstruct net_device *netdev = jme->dev;\n\tint rc;\n\n\twhile (!atomic_dec_and_test(&jme->link_changing)) {\n\t\tatomic_inc(&jme->link_changing);\n\t\tnetif_info(jme, intr, jme->dev, \"Get link change lock failed\\n\");\n\t\twhile (atomic_read(&jme->link_changing) != 1)\n\t\t\tnetif_info(jme, intr, jme->dev, \"Waiting link change lock\\n\");\n\t}\n\n\tif (jme_check_link(netdev, 1) && jme->old_mtu == netdev->mtu)\n\t\tgoto out;\n\n\tjme->old_mtu = netdev->mtu;\n\tnetif_stop_queue(netdev);\n\tif (jme_pseudo_hotplug_enabled(jme))\n\t\tjme_stop_shutdown_timer(jme);\n\n\tjme_stop_pcc_timer(jme);\n\ttasklet_disable(&jme->txclean_task);\n\ttasklet_disable(&jme->rxclean_task);\n\ttasklet_disable(&jme->rxempty_task);\n\n\tif (netif_carrier_ok(netdev)) {\n\t\tjme_disable_rx_engine(jme);\n\t\tjme_disable_tx_engine(jme);\n\t\tjme_reset_mac_processor(jme);\n\t\tjme_free_rx_resources(jme);\n\t\tjme_free_tx_resources(jme);\n\n\t\tif (test_bit(JME_FLAG_POLL, &jme->flags))\n\t\t\tjme_polling_mode(jme);\n\n\t\tnetif_carrier_off(netdev);\n\t}\n\n\tjme_check_link(netdev, 0);\n\tif (netif_carrier_ok(netdev)) {\n\t\trc = jme_setup_rx_resources(jme);\n\t\tif (rc) {\n\t\t\tpr_err(\"Allocating resources for RX error, Device STOPPED!\\n\");\n\t\t\tgoto out_enable_tasklet;\n\t\t}\n\n\t\trc = jme_setup_tx_resources(jme);\n\t\tif (rc) {\n\t\t\tpr_err(\"Allocating resources for TX error, Device STOPPED!\\n\");\n\t\t\tgoto err_out_free_rx_resources;\n\t\t}\n\n\t\tjme_enable_rx_engine(jme);\n\t\tjme_enable_tx_engine(jme);\n\n\t\tnetif_start_queue(netdev);\n\n\t\tif (test_bit(JME_FLAG_POLL, &jme->flags))\n\t\t\tjme_interrupt_mode(jme);\n\n\t\tjme_start_pcc_timer(jme);\n\t} else if (jme_pseudo_hotplug_enabled(jme)) {\n\t\tjme_start_shutdown_timer(jme);\n\t}\n\n\tgoto out_enable_tasklet;\n\nerr_out_free_rx_resources:\n\tjme_free_rx_resources(jme);\nout_enable_tasklet:\n\ttasklet_enable(&jme->txclean_task);\n\ttasklet_enable(&jme->rxclean_task);\n\ttasklet_enable(&jme->rxempty_task);\nout:\n\tatomic_inc(&jme->link_changing);\n}\n\nstatic void\njme_rx_clean_tasklet(struct tasklet_struct *t)\n{\n\tstruct jme_adapter *jme = from_tasklet(jme, t, rxclean_task);\n\tstruct dynpcc_info *dpi = &(jme->dpi);\n\n\tjme_process_receive(jme, jme->rx_ring_size);\n\t++(dpi->intr_cnt);\n\n}\n\nstatic int\njme_poll(JME_NAPI_HOLDER(holder), JME_NAPI_WEIGHT(budget))\n{\n\tstruct jme_adapter *jme = jme_napi_priv(holder);\n\tint rest;\n\n\trest = jme_process_receive(jme, JME_NAPI_WEIGHT_VAL(budget));\n\n\twhile (atomic_read(&jme->rx_empty) > 0) {\n\t\tatomic_dec(&jme->rx_empty);\n\t\t++(NET_STAT(jme).rx_dropped);\n\t\tjme_restart_rx_engine(jme);\n\t}\n\tatomic_inc(&jme->rx_empty);\n\n\tif (rest) {\n\t\tJME_RX_COMPLETE(netdev, holder);\n\t\tjme_interrupt_mode(jme);\n\t}\n\n\tJME_NAPI_WEIGHT_SET(budget, rest);\n\treturn JME_NAPI_WEIGHT_VAL(budget) - rest;\n}\n\nstatic void\njme_rx_empty_tasklet(struct tasklet_struct *t)\n{\n\tstruct jme_adapter *jme = from_tasklet(jme, t, rxempty_task);\n\n\tif (unlikely(atomic_read(&jme->link_changing) != 1))\n\t\treturn;\n\n\tif (unlikely(!netif_carrier_ok(jme->dev)))\n\t\treturn;\n\n\tnetif_info(jme, rx_status, jme->dev, \"RX Queue Full!\\n\");\n\n\tjme_rx_clean_tasklet(&jme->rxclean_task);\n\n\twhile (atomic_read(&jme->rx_empty) > 0) {\n\t\tatomic_dec(&jme->rx_empty);\n\t\t++(NET_STAT(jme).rx_dropped);\n\t\tjme_restart_rx_engine(jme);\n\t}\n\tatomic_inc(&jme->rx_empty);\n}\n\nstatic void\njme_wake_queue_if_stopped(struct jme_adapter *jme)\n{\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\n\tsmp_wmb();\n\tif (unlikely(netif_queue_stopped(jme->dev) &&\n\tatomic_read(&txring->nr_free) >= (jme->tx_wake_threshold))) {\n\t\tnetif_info(jme, tx_done, jme->dev, \"TX Queue Waked\\n\");\n\t\tnetif_wake_queue(jme->dev);\n\t}\n\n}\n\nstatic void jme_tx_clean_tasklet(struct tasklet_struct *t)\n{\n\tstruct jme_adapter *jme = from_tasklet(jme, t, txclean_task);\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\tstruct txdesc *txdesc = txring->desc;\n\tstruct jme_buffer_info *txbi = txring->bufinf, *ctxbi, *ttxbi;\n\tint i, j, cnt = 0, max, err, mask;\n\n\ttx_dbg(jme, \"Into txclean\\n\");\n\n\tif (unlikely(!atomic_dec_and_test(&jme->tx_cleaning)))\n\t\tgoto out;\n\n\tif (unlikely(atomic_read(&jme->link_changing) != 1))\n\t\tgoto out;\n\n\tif (unlikely(!netif_carrier_ok(jme->dev)))\n\t\tgoto out;\n\n\tmax = jme->tx_ring_size - atomic_read(&txring->nr_free);\n\tmask = jme->tx_ring_mask;\n\n\tfor (i = atomic_read(&txring->next_to_clean) ; cnt < max ; ) {\n\n\t\tctxbi = txbi + i;\n\n\t\tif (likely(ctxbi->skb &&\n\t\t!(txdesc[i].descwb.flags & TXWBFLAG_OWN))) {\n\n\t\t\ttx_dbg(jme, \"txclean: %d+%d@%lu\\n\",\n\t\t\t       i, ctxbi->nr_desc, jiffies);\n\n\t\t\terr = txdesc[i].descwb.flags & TXWBFLAG_ALLERR;\n\n\t\t\tfor (j = 1 ; j < ctxbi->nr_desc ; ++j) {\n\t\t\t\tttxbi = txbi + ((i + j) & (mask));\n\t\t\t\ttxdesc[(i + j) & (mask)].dw[0] = 0;\n\n\t\t\t\tdma_unmap_page(&jme->pdev->dev,\n\t\t\t\t\t       ttxbi->mapping, ttxbi->len,\n\t\t\t\t\t       DMA_TO_DEVICE);\n\n\t\t\t\tttxbi->mapping = 0;\n\t\t\t\tttxbi->len = 0;\n\t\t\t}\n\n\t\t\tdev_kfree_skb(ctxbi->skb);\n\n\t\t\tcnt += ctxbi->nr_desc;\n\n\t\t\tif (unlikely(err)) {\n\t\t\t\t++(NET_STAT(jme).tx_carrier_errors);\n\t\t\t} else {\n\t\t\t\t++(NET_STAT(jme).tx_packets);\n\t\t\t\tNET_STAT(jme).tx_bytes += ctxbi->len;\n\t\t\t}\n\n\t\t\tctxbi->skb = NULL;\n\t\t\tctxbi->len = 0;\n\t\t\tctxbi->start_xmit = 0;\n\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\n\t\ti = (i + ctxbi->nr_desc) & mask;\n\n\t\tctxbi->nr_desc = 0;\n\t}\n\n\ttx_dbg(jme, \"txclean: done %d@%lu\\n\", i, jiffies);\n\tatomic_set(&txring->next_to_clean, i);\n\tatomic_add(cnt, &txring->nr_free);\n\n\tjme_wake_queue_if_stopped(jme);\n\nout:\n\tatomic_inc(&jme->tx_cleaning);\n}\n\nstatic void\njme_intr_msi(struct jme_adapter *jme, u32 intrstat)\n{\n\t \n\tjwrite32f(jme, JME_IENC, INTR_ENABLE);\n\n\tif (intrstat & (INTR_LINKCH | INTR_SWINTR)) {\n\t\t \n\t\tjwrite32(jme, JME_IEVE, intrstat);\n\t\tschedule_work(&jme->linkch_task);\n\t\tgoto out_reenable;\n\t}\n\n\tif (intrstat & INTR_TMINTR) {\n\t\tjwrite32(jme, JME_IEVE, INTR_TMINTR);\n\t\ttasklet_schedule(&jme->pcc_task);\n\t}\n\n\tif (intrstat & (INTR_PCCTXTO | INTR_PCCTX)) {\n\t\tjwrite32(jme, JME_IEVE, INTR_PCCTXTO | INTR_PCCTX | INTR_TX0);\n\t\ttasklet_schedule(&jme->txclean_task);\n\t}\n\n\tif ((intrstat & (INTR_PCCRX0TO | INTR_PCCRX0 | INTR_RX0EMP))) {\n\t\tjwrite32(jme, JME_IEVE, (intrstat & (INTR_PCCRX0TO |\n\t\t\t\t\t\t     INTR_PCCRX0 |\n\t\t\t\t\t\t     INTR_RX0EMP)) |\n\t\t\t\t\tINTR_RX0);\n\t}\n\n\tif (test_bit(JME_FLAG_POLL, &jme->flags)) {\n\t\tif (intrstat & INTR_RX0EMP)\n\t\t\tatomic_inc(&jme->rx_empty);\n\n\t\tif ((intrstat & (INTR_PCCRX0TO | INTR_PCCRX0 | INTR_RX0EMP))) {\n\t\t\tif (likely(JME_RX_SCHEDULE_PREP(jme))) {\n\t\t\t\tjme_polling_mode(jme);\n\t\t\t\tJME_RX_SCHEDULE(jme);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (intrstat & INTR_RX0EMP) {\n\t\t\tatomic_inc(&jme->rx_empty);\n\t\t\ttasklet_hi_schedule(&jme->rxempty_task);\n\t\t} else if (intrstat & (INTR_PCCRX0TO | INTR_PCCRX0)) {\n\t\t\ttasklet_hi_schedule(&jme->rxclean_task);\n\t\t}\n\t}\n\nout_reenable:\n\t \n\tjwrite32f(jme, JME_IENS, INTR_ENABLE);\n}\n\nstatic irqreturn_t\njme_intr(int irq, void *dev_id)\n{\n\tstruct net_device *netdev = dev_id;\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 intrstat;\n\n\tintrstat = jread32(jme, JME_IEVE);\n\n\t \n\tif (unlikely((intrstat & INTR_ENABLE) == 0))\n\t\treturn IRQ_NONE;\n\n\t \n\tif (unlikely(intrstat == ~((typeof(intrstat))0)))\n\t\treturn IRQ_NONE;\n\n\tjme_intr_msi(jme, intrstat);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t\njme_msi(int irq, void *dev_id)\n{\n\tstruct net_device *netdev = dev_id;\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 intrstat;\n\n\tintrstat = jread32(jme, JME_IEVE);\n\n\tjme_intr_msi(jme, intrstat);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void\njme_reset_link(struct jme_adapter *jme)\n{\n\tjwrite32(jme, JME_TMCSR, TMCSR_SWIT);\n}\n\nstatic void\njme_restart_an(struct jme_adapter *jme)\n{\n\tu32 bmcr;\n\n\tspin_lock_bh(&jme->phy_lock);\n\tbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\n\tbmcr |= (BMCR_ANENABLE | BMCR_ANRESTART);\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, bmcr);\n\tspin_unlock_bh(&jme->phy_lock);\n}\n\nstatic int\njme_request_irq(struct jme_adapter *jme)\n{\n\tint rc;\n\tstruct net_device *netdev = jme->dev;\n\tirq_handler_t handler = jme_intr;\n\tint irq_flags = IRQF_SHARED;\n\n\tif (!pci_enable_msi(jme->pdev)) {\n\t\tset_bit(JME_FLAG_MSI, &jme->flags);\n\t\thandler = jme_msi;\n\t\tirq_flags = 0;\n\t}\n\n\trc = request_irq(jme->pdev->irq, handler, irq_flags, netdev->name,\n\t\t\t  netdev);\n\tif (rc) {\n\t\tnetdev_err(netdev,\n\t\t\t   \"Unable to request %s interrupt (return: %d)\\n\",\n\t\t\t   test_bit(JME_FLAG_MSI, &jme->flags) ? \"MSI\" : \"INTx\",\n\t\t\t   rc);\n\n\t\tif (test_bit(JME_FLAG_MSI, &jme->flags)) {\n\t\t\tpci_disable_msi(jme->pdev);\n\t\t\tclear_bit(JME_FLAG_MSI, &jme->flags);\n\t\t}\n\t} else {\n\t\tnetdev->irq = jme->pdev->irq;\n\t}\n\n\treturn rc;\n}\n\nstatic void\njme_free_irq(struct jme_adapter *jme)\n{\n\tfree_irq(jme->pdev->irq, jme->dev);\n\tif (test_bit(JME_FLAG_MSI, &jme->flags)) {\n\t\tpci_disable_msi(jme->pdev);\n\t\tclear_bit(JME_FLAG_MSI, &jme->flags);\n\t\tjme->dev->irq = jme->pdev->irq;\n\t}\n}\n\nstatic inline void\njme_new_phy_on(struct jme_adapter *jme)\n{\n\tu32 reg;\n\n\treg = jread32(jme, JME_PHY_PWR);\n\treg &= ~(PHY_PWR_DWN1SEL | PHY_PWR_DWN1SW |\n\t\t PHY_PWR_DWN2 | PHY_PWR_CLKSEL);\n\tjwrite32(jme, JME_PHY_PWR, reg);\n\n\tpci_read_config_dword(jme->pdev, PCI_PRIV_PE1, &reg);\n\treg &= ~PE1_GPREG0_PBG;\n\treg |= PE1_GPREG0_ENBG;\n\tpci_write_config_dword(jme->pdev, PCI_PRIV_PE1, reg);\n}\n\nstatic inline void\njme_new_phy_off(struct jme_adapter *jme)\n{\n\tu32 reg;\n\n\treg = jread32(jme, JME_PHY_PWR);\n\treg |= PHY_PWR_DWN1SEL | PHY_PWR_DWN1SW |\n\t       PHY_PWR_DWN2 | PHY_PWR_CLKSEL;\n\tjwrite32(jme, JME_PHY_PWR, reg);\n\n\tpci_read_config_dword(jme->pdev, PCI_PRIV_PE1, &reg);\n\treg &= ~PE1_GPREG0_PBG;\n\treg |= PE1_GPREG0_PDD3COLD;\n\tpci_write_config_dword(jme->pdev, PCI_PRIV_PE1, reg);\n}\n\nstatic inline void\njme_phy_on(struct jme_adapter *jme)\n{\n\tu32 bmcr;\n\n\tbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\n\tbmcr &= ~BMCR_PDOWN;\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, bmcr);\n\n\tif (new_phy_power_ctrl(jme->chip_main_rev))\n\t\tjme_new_phy_on(jme);\n}\n\nstatic inline void\njme_phy_off(struct jme_adapter *jme)\n{\n\tu32 bmcr;\n\n\tbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\n\tbmcr |= BMCR_PDOWN;\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, bmcr);\n\n\tif (new_phy_power_ctrl(jme->chip_main_rev))\n\t\tjme_new_phy_off(jme);\n}\n\nstatic int\njme_phy_specreg_read(struct jme_adapter *jme, u32 specreg)\n{\n\tu32 phy_addr;\n\n\tphy_addr = JM_PHY_SPEC_REG_READ | specreg;\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, JM_PHY_SPEC_ADDR_REG,\n\t\t\tphy_addr);\n\treturn jme_mdio_read(jme->dev, jme->mii_if.phy_id,\n\t\t\tJM_PHY_SPEC_DATA_REG);\n}\n\nstatic void\njme_phy_specreg_write(struct jme_adapter *jme, u32 ext_reg, u32 phy_data)\n{\n\tu32 phy_addr;\n\n\tphy_addr = JM_PHY_SPEC_REG_WRITE | ext_reg;\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, JM_PHY_SPEC_DATA_REG,\n\t\t\tphy_data);\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, JM_PHY_SPEC_ADDR_REG,\n\t\t\tphy_addr);\n}\n\nstatic int\njme_phy_calibration(struct jme_adapter *jme)\n{\n\tu32 ctrl1000, phy_data;\n\n\tjme_phy_off(jme);\n\tjme_phy_on(jme);\n\t \n\tctrl1000 = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_CTRL1000);\n\tctrl1000 &= ~PHY_GAD_TEST_MODE_MSK;\n\tctrl1000 |= PHY_GAD_TEST_MODE_1;\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_CTRL1000, ctrl1000);\n\n\tphy_data = jme_phy_specreg_read(jme, JM_PHY_EXT_COMM_2_REG);\n\tphy_data &= ~JM_PHY_EXT_COMM_2_CALI_MODE_0;\n\tphy_data |= JM_PHY_EXT_COMM_2_CALI_LATCH |\n\t\t\tJM_PHY_EXT_COMM_2_CALI_ENABLE;\n\tjme_phy_specreg_write(jme, JM_PHY_EXT_COMM_2_REG, phy_data);\n\tmsleep(20);\n\tphy_data = jme_phy_specreg_read(jme, JM_PHY_EXT_COMM_2_REG);\n\tphy_data &= ~(JM_PHY_EXT_COMM_2_CALI_ENABLE |\n\t\t\tJM_PHY_EXT_COMM_2_CALI_MODE_0 |\n\t\t\tJM_PHY_EXT_COMM_2_CALI_LATCH);\n\tjme_phy_specreg_write(jme, JM_PHY_EXT_COMM_2_REG, phy_data);\n\n\t \n\tctrl1000 = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_CTRL1000);\n\tctrl1000 &= ~PHY_GAD_TEST_MODE_MSK;\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_CTRL1000, ctrl1000);\n\treturn 0;\n}\n\nstatic int\njme_phy_setEA(struct jme_adapter *jme)\n{\n\tu32 phy_comm0 = 0, phy_comm1 = 0;\n\tu8 nic_ctrl;\n\n\tpci_read_config_byte(jme->pdev, PCI_PRIV_SHARE_NICCTRL, &nic_ctrl);\n\tif ((nic_ctrl & 0x3) == JME_FLAG_PHYEA_ENABLE)\n\t\treturn 0;\n\n\tswitch (jme->pdev->device) {\n\tcase PCI_DEVICE_ID_JMICRON_JMC250:\n\t\tif (((jme->chip_main_rev == 5) &&\n\t\t\t((jme->chip_sub_rev == 0) || (jme->chip_sub_rev == 1) ||\n\t\t\t(jme->chip_sub_rev == 3))) ||\n\t\t\t(jme->chip_main_rev >= 6)) {\n\t\t\tphy_comm0 = 0x008A;\n\t\t\tphy_comm1 = 0x4109;\n\t\t}\n\t\tif ((jme->chip_main_rev == 3) &&\n\t\t\t((jme->chip_sub_rev == 1) || (jme->chip_sub_rev == 2)))\n\t\t\tphy_comm0 = 0xE088;\n\t\tbreak;\n\tcase PCI_DEVICE_ID_JMICRON_JMC260:\n\t\tif (((jme->chip_main_rev == 5) &&\n\t\t\t((jme->chip_sub_rev == 0) || (jme->chip_sub_rev == 1) ||\n\t\t\t(jme->chip_sub_rev == 3))) ||\n\t\t\t(jme->chip_main_rev >= 6)) {\n\t\t\tphy_comm0 = 0x008A;\n\t\t\tphy_comm1 = 0x4109;\n\t\t}\n\t\tif ((jme->chip_main_rev == 3) &&\n\t\t\t((jme->chip_sub_rev == 1) || (jme->chip_sub_rev == 2)))\n\t\t\tphy_comm0 = 0xE088;\n\t\tif ((jme->chip_main_rev == 2) && (jme->chip_sub_rev == 0))\n\t\t\tphy_comm0 = 0x608A;\n\t\tif ((jme->chip_main_rev == 2) && (jme->chip_sub_rev == 2))\n\t\t\tphy_comm0 = 0x408A;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\tif (phy_comm0)\n\t\tjme_phy_specreg_write(jme, JM_PHY_EXT_COMM_0_REG, phy_comm0);\n\tif (phy_comm1)\n\t\tjme_phy_specreg_write(jme, JM_PHY_EXT_COMM_1_REG, phy_comm1);\n\n\treturn 0;\n}\n\nstatic int\njme_open(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tint rc;\n\n\tjme_clear_pm_disable_wol(jme);\n\tJME_NAPI_ENABLE(jme);\n\n\ttasklet_setup(&jme->txclean_task, jme_tx_clean_tasklet);\n\ttasklet_setup(&jme->rxclean_task, jme_rx_clean_tasklet);\n\ttasklet_setup(&jme->rxempty_task, jme_rx_empty_tasklet);\n\n\trc = jme_request_irq(jme);\n\tif (rc)\n\t\tgoto err_out;\n\n\tjme_start_irq(jme);\n\n\tjme_phy_on(jme);\n\tif (test_bit(JME_FLAG_SSET, &jme->flags))\n\t\tjme_set_link_ksettings(netdev, &jme->old_cmd);\n\telse\n\t\tjme_reset_phy_processor(jme);\n\tjme_phy_calibration(jme);\n\tjme_phy_setEA(jme);\n\tjme_reset_link(jme);\n\n\treturn 0;\n\nerr_out:\n\tnetif_stop_queue(netdev);\n\tnetif_carrier_off(netdev);\n\treturn rc;\n}\n\nstatic void\njme_set_100m_half(struct jme_adapter *jme)\n{\n\tu32 bmcr, tmp;\n\n\tjme_phy_on(jme);\n\tbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\n\ttmp = bmcr & ~(BMCR_ANENABLE | BMCR_SPEED100 |\n\t\t       BMCR_SPEED1000 | BMCR_FULLDPLX);\n\ttmp |= BMCR_SPEED100;\n\n\tif (bmcr != tmp)\n\t\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, tmp);\n\n\tif (jme->fpgaver)\n\t\tjwrite32(jme, JME_GHC, GHC_SPEED_100M | GHC_LINK_POLL);\n\telse\n\t\tjwrite32(jme, JME_GHC, GHC_SPEED_100M);\n}\n\n#define JME_WAIT_LINK_TIME 2000  \nstatic void\njme_wait_link(struct jme_adapter *jme)\n{\n\tu32 phylink, to = JME_WAIT_LINK_TIME;\n\n\tmsleep(1000);\n\tphylink = jme_linkstat_from_phy(jme);\n\twhile (!(phylink & PHY_LINK_UP) && (to -= 10) > 0) {\n\t\tusleep_range(10000, 11000);\n\t\tphylink = jme_linkstat_from_phy(jme);\n\t}\n}\n\nstatic void\njme_powersave_phy(struct jme_adapter *jme)\n{\n\tif (jme->reg_pmcs && device_may_wakeup(&jme->pdev->dev)) {\n\t\tjme_set_100m_half(jme);\n\t\tif (jme->reg_pmcs & (PMCS_LFEN | PMCS_LREN))\n\t\t\tjme_wait_link(jme);\n\t\tjme_clear_pm_enable_wol(jme);\n\t} else {\n\t\tjme_phy_off(jme);\n\t}\n}\n\nstatic int\njme_close(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tnetif_stop_queue(netdev);\n\tnetif_carrier_off(netdev);\n\n\tjme_stop_irq(jme);\n\tjme_free_irq(jme);\n\n\tJME_NAPI_DISABLE(jme);\n\n\tcancel_work_sync(&jme->linkch_task);\n\ttasklet_kill(&jme->txclean_task);\n\ttasklet_kill(&jme->rxclean_task);\n\ttasklet_kill(&jme->rxempty_task);\n\n\tjme_disable_rx_engine(jme);\n\tjme_disable_tx_engine(jme);\n\tjme_reset_mac_processor(jme);\n\tjme_free_rx_resources(jme);\n\tjme_free_tx_resources(jme);\n\tjme->phylink = 0;\n\tjme_phy_off(jme);\n\n\treturn 0;\n}\n\nstatic int\njme_alloc_txdesc(struct jme_adapter *jme,\n\t\t\tstruct sk_buff *skb)\n{\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\tint idx, nr_alloc, mask = jme->tx_ring_mask;\n\n\tidx = txring->next_to_use;\n\tnr_alloc = skb_shinfo(skb)->nr_frags + 2;\n\n\tif (unlikely(atomic_read(&txring->nr_free) < nr_alloc))\n\t\treturn -1;\n\n\tatomic_sub(nr_alloc, &txring->nr_free);\n\n\ttxring->next_to_use = (txring->next_to_use + nr_alloc) & mask;\n\n\treturn idx;\n}\n\nstatic int\njme_fill_tx_map(struct pci_dev *pdev,\n\t\tstruct txdesc *txdesc,\n\t\tstruct jme_buffer_info *txbi,\n\t\tstruct page *page,\n\t\tu32 page_offset,\n\t\tu32 len,\n\t\tbool hidma)\n{\n\tdma_addr_t dmaaddr;\n\n\tdmaaddr = dma_map_page(&pdev->dev, page, page_offset, len,\n\t\t\t       DMA_TO_DEVICE);\n\n\tif (unlikely(dma_mapping_error(&pdev->dev, dmaaddr)))\n\t\treturn -EINVAL;\n\n\tdma_sync_single_for_device(&pdev->dev, dmaaddr, len, DMA_TO_DEVICE);\n\n\ttxdesc->dw[0] = 0;\n\ttxdesc->dw[1] = 0;\n\ttxdesc->desc2.flags\t= TXFLAG_OWN;\n\ttxdesc->desc2.flags\t|= (hidma) ? TXFLAG_64BIT : 0;\n\ttxdesc->desc2.datalen\t= cpu_to_le16(len);\n\ttxdesc->desc2.bufaddrh\t= cpu_to_le32((__u64)dmaaddr >> 32);\n\ttxdesc->desc2.bufaddrl\t= cpu_to_le32(\n\t\t\t\t\t(__u64)dmaaddr & 0xFFFFFFFFUL);\n\n\ttxbi->mapping = dmaaddr;\n\ttxbi->len = len;\n\treturn 0;\n}\n\nstatic void jme_drop_tx_map(struct jme_adapter *jme, int startidx, int count)\n{\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\tstruct jme_buffer_info *txbi = txring->bufinf, *ctxbi;\n\tint mask = jme->tx_ring_mask;\n\tint j;\n\n\tfor (j = 0 ; j < count ; j++) {\n\t\tctxbi = txbi + ((startidx + j + 2) & (mask));\n\t\tdma_unmap_page(&jme->pdev->dev, ctxbi->mapping, ctxbi->len,\n\t\t\t       DMA_TO_DEVICE);\n\n\t\tctxbi->mapping = 0;\n\t\tctxbi->len = 0;\n\t}\n}\n\nstatic int\njme_map_tx_skb(struct jme_adapter *jme, struct sk_buff *skb, int idx)\n{\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\tstruct txdesc *txdesc = txring->desc, *ctxdesc;\n\tstruct jme_buffer_info *txbi = txring->bufinf, *ctxbi;\n\tbool hidma = jme->dev->features & NETIF_F_HIGHDMA;\n\tint i, nr_frags = skb_shinfo(skb)->nr_frags;\n\tint mask = jme->tx_ring_mask;\n\tu32 len;\n\tint ret = 0;\n\n\tfor (i = 0 ; i < nr_frags ; ++i) {\n\t\tconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\n\t\tctxdesc = txdesc + ((idx + i + 2) & (mask));\n\t\tctxbi = txbi + ((idx + i + 2) & (mask));\n\n\t\tret = jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi,\n\t\t\t\t      skb_frag_page(frag), skb_frag_off(frag),\n\t\t\t\t      skb_frag_size(frag), hidma);\n\t\tif (ret) {\n\t\t\tjme_drop_tx_map(jme, idx, i);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tlen = skb_is_nonlinear(skb) ? skb_headlen(skb) : skb->len;\n\tctxdesc = txdesc + ((idx + 1) & (mask));\n\tctxbi = txbi + ((idx + 1) & (mask));\n\tret = jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi, virt_to_page(skb->data),\n\t\t\toffset_in_page(skb->data), len, hidma);\n\tif (ret)\n\t\tjme_drop_tx_map(jme, idx, i);\n\nout:\n\treturn ret;\n\n}\n\n\nstatic int\njme_tx_tso(struct sk_buff *skb, __le16 *mss, u8 *flags)\n{\n\t*mss = cpu_to_le16(skb_shinfo(skb)->gso_size << TXDESC_MSS_SHIFT);\n\tif (*mss) {\n\t\t*flags |= TXFLAG_LSEN;\n\n\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\tstruct iphdr *iph = ip_hdr(skb);\n\n\t\t\tiph->check = 0;\n\t\t\ttcp_hdr(skb)->check = ~csum_tcpudp_magic(iph->saddr,\n\t\t\t\t\t\t\t\tiph->daddr, 0,\n\t\t\t\t\t\t\t\tIPPROTO_TCP,\n\t\t\t\t\t\t\t\t0);\n\t\t} else {\n\t\t\ttcp_v6_gso_csum_prep(skb);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic void\njme_tx_csum(struct jme_adapter *jme, struct sk_buff *skb, u8 *flags)\n{\n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tu8 ip_proto;\n\n\t\tswitch (skb->protocol) {\n\t\tcase htons(ETH_P_IP):\n\t\t\tip_proto = ip_hdr(skb)->protocol;\n\t\t\tbreak;\n\t\tcase htons(ETH_P_IPV6):\n\t\t\tip_proto = ipv6_hdr(skb)->nexthdr;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tip_proto = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (ip_proto) {\n\t\tcase IPPROTO_TCP:\n\t\t\t*flags |= TXFLAG_TCPCS;\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\t\t*flags |= TXFLAG_UDPCS;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetif_err(jme, tx_err, jme->dev, \"Error upper layer protocol\\n\");\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic inline void\njme_tx_vlan(struct sk_buff *skb, __le16 *vlan, u8 *flags)\n{\n\tif (skb_vlan_tag_present(skb)) {\n\t\t*flags |= TXFLAG_TAGON;\n\t\t*vlan = cpu_to_le16(skb_vlan_tag_get(skb));\n\t}\n}\n\nstatic int\njme_fill_tx_desc(struct jme_adapter *jme, struct sk_buff *skb, int idx)\n{\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\tstruct txdesc *txdesc;\n\tstruct jme_buffer_info *txbi;\n\tu8 flags;\n\tint ret = 0;\n\n\ttxdesc = (struct txdesc *)txring->desc + idx;\n\ttxbi = txring->bufinf + idx;\n\n\ttxdesc->dw[0] = 0;\n\ttxdesc->dw[1] = 0;\n\ttxdesc->dw[2] = 0;\n\ttxdesc->dw[3] = 0;\n\ttxdesc->desc1.pktsize = cpu_to_le16(skb->len);\n\t \n\twmb();\n\tflags = TXFLAG_OWN | TXFLAG_INT;\n\t \n\tif (jme_tx_tso(skb, &txdesc->desc1.mss, &flags))\n\t\tjme_tx_csum(jme, skb, &flags);\n\tjme_tx_vlan(skb, &txdesc->desc1.vlan, &flags);\n\tret = jme_map_tx_skb(jme, skb, idx);\n\tif (ret)\n\t\treturn ret;\n\n\ttxdesc->desc1.flags = flags;\n\t \n\twmb();\n\ttxbi->nr_desc = skb_shinfo(skb)->nr_frags + 2;\n\ttxbi->skb = skb;\n\ttxbi->len = skb->len;\n\ttxbi->start_xmit = jiffies;\n\tif (!txbi->start_xmit)\n\t\ttxbi->start_xmit = (0UL-1);\n\n\treturn 0;\n}\n\nstatic void\njme_stop_queue_if_full(struct jme_adapter *jme)\n{\n\tstruct jme_ring *txring = &(jme->txring[0]);\n\tstruct jme_buffer_info *txbi = txring->bufinf;\n\tint idx = atomic_read(&txring->next_to_clean);\n\n\ttxbi += idx;\n\n\tsmp_wmb();\n\tif (unlikely(atomic_read(&txring->nr_free) < (MAX_SKB_FRAGS+2))) {\n\t\tnetif_stop_queue(jme->dev);\n\t\tnetif_info(jme, tx_queued, jme->dev, \"TX Queue Paused\\n\");\n\t\tsmp_wmb();\n\t\tif (atomic_read(&txring->nr_free)\n\t\t\t>= (jme->tx_wake_threshold)) {\n\t\t\tnetif_wake_queue(jme->dev);\n\t\t\tnetif_info(jme, tx_queued, jme->dev, \"TX Queue Fast Waked\\n\");\n\t\t}\n\t}\n\n\tif (unlikely(txbi->start_xmit &&\n\t\t\ttime_is_before_eq_jiffies(txbi->start_xmit + TX_TIMEOUT) &&\n\t\t\ttxbi->skb)) {\n\t\tnetif_stop_queue(jme->dev);\n\t\tnetif_info(jme, tx_queued, jme->dev,\n\t\t\t   \"TX Queue Stopped %d@%lu\\n\", idx, jiffies);\n\t}\n}\n\n \n\nstatic netdev_tx_t\njme_start_xmit(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tint idx;\n\n\tif (unlikely(skb_is_gso(skb) && skb_cow_head(skb, 0))) {\n\t\tdev_kfree_skb_any(skb);\n\t\t++(NET_STAT(jme).tx_dropped);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tidx = jme_alloc_txdesc(jme, skb);\n\n\tif (unlikely(idx < 0)) {\n\t\tnetif_stop_queue(netdev);\n\t\tnetif_err(jme, tx_err, jme->dev,\n\t\t\t  \"BUG! Tx ring full when queue awake!\\n\");\n\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tif (jme_fill_tx_desc(jme, skb, idx))\n\t\treturn NETDEV_TX_OK;\n\n\tjwrite32(jme, JME_TXCS, jme->reg_txcs |\n\t\t\t\tTXCS_SELECT_QUEUE0 |\n\t\t\t\tTXCS_QUEUE0S |\n\t\t\t\tTXCS_ENABLE);\n\n\ttx_dbg(jme, \"xmit: %d+%d@%lu\\n\",\n\t       idx, skb_shinfo(skb)->nr_frags + 2, jiffies);\n\tjme_stop_queue_if_full(jme);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void\njme_set_unicastaddr(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 val;\n\n\tval = (netdev->dev_addr[3] & 0xff) << 24 |\n\t      (netdev->dev_addr[2] & 0xff) << 16 |\n\t      (netdev->dev_addr[1] & 0xff) <<  8 |\n\t      (netdev->dev_addr[0] & 0xff);\n\tjwrite32(jme, JME_RXUMA_LO, val);\n\tval = (netdev->dev_addr[5] & 0xff) << 8 |\n\t      (netdev->dev_addr[4] & 0xff);\n\tjwrite32(jme, JME_RXUMA_HI, val);\n}\n\nstatic int\njme_set_macaddr(struct net_device *netdev, void *p)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tstruct sockaddr *addr = p;\n\n\tif (netif_running(netdev))\n\t\treturn -EBUSY;\n\n\tspin_lock_bh(&jme->macaddr_lock);\n\teth_hw_addr_set(netdev, addr->sa_data);\n\tjme_set_unicastaddr(netdev);\n\tspin_unlock_bh(&jme->macaddr_lock);\n\n\treturn 0;\n}\n\nstatic void\njme_set_multi(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 mc_hash[2] = {};\n\n\tspin_lock_bh(&jme->rxmcs_lock);\n\n\tjme->reg_rxmcs |= RXMCS_BRDFRAME | RXMCS_UNIFRAME;\n\n\tif (netdev->flags & IFF_PROMISC) {\n\t\tjme->reg_rxmcs |= RXMCS_ALLFRAME;\n\t} else if (netdev->flags & IFF_ALLMULTI) {\n\t\tjme->reg_rxmcs |= RXMCS_ALLMULFRAME;\n\t} else if (netdev->flags & IFF_MULTICAST) {\n\t\tstruct netdev_hw_addr *ha;\n\t\tint bit_nr;\n\n\t\tjme->reg_rxmcs |= RXMCS_MULFRAME | RXMCS_MULFILTERED;\n\t\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\t\tbit_nr = ether_crc(ETH_ALEN, ha->addr) & 0x3F;\n\t\t\tmc_hash[bit_nr >> 5] |= 1 << (bit_nr & 0x1F);\n\t\t}\n\n\t\tjwrite32(jme, JME_RXMCHT_LO, mc_hash[0]);\n\t\tjwrite32(jme, JME_RXMCHT_HI, mc_hash[1]);\n\t}\n\n\twmb();\n\tjwrite32(jme, JME_RXMCS, jme->reg_rxmcs);\n\n\tspin_unlock_bh(&jme->rxmcs_lock);\n}\n\nstatic int\njme_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tnetdev->mtu = new_mtu;\n\tnetdev_update_features(netdev);\n\n\tjme_restart_rx_engine(jme);\n\tjme_reset_link(jme);\n\n\treturn 0;\n}\n\nstatic void\njme_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tjme->phylink = 0;\n\tjme_reset_phy_processor(jme);\n\tif (test_bit(JME_FLAG_SSET, &jme->flags))\n\t\tjme_set_link_ksettings(netdev, &jme->old_cmd);\n\n\t \n\tjme_reset_link(jme);\n}\n\nstatic void\njme_get_drvinfo(struct net_device *netdev,\n\t\t     struct ethtool_drvinfo *info)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tstrscpy(info->driver, DRV_NAME, sizeof(info->driver));\n\tstrscpy(info->version, DRV_VERSION, sizeof(info->version));\n\tstrscpy(info->bus_info, pci_name(jme->pdev), sizeof(info->bus_info));\n}\n\nstatic int\njme_get_regs_len(struct net_device *netdev)\n{\n\treturn JME_REG_LEN;\n}\n\nstatic void\nmmapio_memcpy(struct jme_adapter *jme, u32 *p, u32 reg, int len)\n{\n\tint i;\n\n\tfor (i = 0 ; i < len ; i += 4)\n\t\tp[i >> 2] = jread32(jme, reg + i);\n}\n\nstatic void\nmdio_memcpy(struct jme_adapter *jme, u32 *p, int reg_nr)\n{\n\tint i;\n\tu16 *p16 = (u16 *)p;\n\n\tfor (i = 0 ; i < reg_nr ; ++i)\n\t\tp16[i] = jme_mdio_read(jme->dev, jme->mii_if.phy_id, i);\n}\n\nstatic void\njme_get_regs(struct net_device *netdev, struct ethtool_regs *regs, void *p)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 *p32 = (u32 *)p;\n\n\tmemset(p, 0xFF, JME_REG_LEN);\n\n\tregs->version = 1;\n\tmmapio_memcpy(jme, p32, JME_MAC, JME_MAC_LEN);\n\n\tp32 += 0x100 >> 2;\n\tmmapio_memcpy(jme, p32, JME_PHY, JME_PHY_LEN);\n\n\tp32 += 0x100 >> 2;\n\tmmapio_memcpy(jme, p32, JME_MISC, JME_MISC_LEN);\n\n\tp32 += 0x100 >> 2;\n\tmmapio_memcpy(jme, p32, JME_RSS, JME_RSS_LEN);\n\n\tp32 += 0x100 >> 2;\n\tmdio_memcpy(jme, p32, JME_PHY_REG_NR);\n}\n\nstatic int jme_get_coalesce(struct net_device *netdev,\n\t\t\t    struct ethtool_coalesce *ecmd,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tecmd->tx_coalesce_usecs = PCC_TX_TO;\n\tecmd->tx_max_coalesced_frames = PCC_TX_CNT;\n\n\tif (test_bit(JME_FLAG_POLL, &jme->flags)) {\n\t\tecmd->use_adaptive_rx_coalesce = false;\n\t\tecmd->rx_coalesce_usecs = 0;\n\t\tecmd->rx_max_coalesced_frames = 0;\n\t\treturn 0;\n\t}\n\n\tecmd->use_adaptive_rx_coalesce = true;\n\n\tswitch (jme->dpi.cur) {\n\tcase PCC_P1:\n\t\tecmd->rx_coalesce_usecs = PCC_P1_TO;\n\t\tecmd->rx_max_coalesced_frames = PCC_P1_CNT;\n\t\tbreak;\n\tcase PCC_P2:\n\t\tecmd->rx_coalesce_usecs = PCC_P2_TO;\n\t\tecmd->rx_max_coalesced_frames = PCC_P2_CNT;\n\t\tbreak;\n\tcase PCC_P3:\n\t\tecmd->rx_coalesce_usecs = PCC_P3_TO;\n\t\tecmd->rx_max_coalesced_frames = PCC_P3_CNT;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int jme_set_coalesce(struct net_device *netdev,\n\t\t\t    struct ethtool_coalesce *ecmd,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tstruct dynpcc_info *dpi = &(jme->dpi);\n\n\tif (netif_running(netdev))\n\t\treturn -EBUSY;\n\n\tif (ecmd->use_adaptive_rx_coalesce &&\n\t    test_bit(JME_FLAG_POLL, &jme->flags)) {\n\t\tclear_bit(JME_FLAG_POLL, &jme->flags);\n\t\tjme->jme_rx = netif_rx;\n\t\tdpi->cur\t\t= PCC_P1;\n\t\tdpi->attempt\t\t= PCC_P1;\n\t\tdpi->cnt\t\t= 0;\n\t\tjme_set_rx_pcc(jme, PCC_P1);\n\t\tjme_interrupt_mode(jme);\n\t} else if (!(ecmd->use_adaptive_rx_coalesce) &&\n\t\t   !(test_bit(JME_FLAG_POLL, &jme->flags))) {\n\t\tset_bit(JME_FLAG_POLL, &jme->flags);\n\t\tjme->jme_rx = netif_receive_skb;\n\t\tjme_interrupt_mode(jme);\n\t}\n\n\treturn 0;\n}\n\nstatic void\njme_get_pauseparam(struct net_device *netdev,\n\t\t\tstruct ethtool_pauseparam *ecmd)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 val;\n\n\tecmd->tx_pause = (jme->reg_txpfc & TXPFC_PF_EN) != 0;\n\tecmd->rx_pause = (jme->reg_rxmcs & RXMCS_FLOWCTRL) != 0;\n\n\tspin_lock_bh(&jme->phy_lock);\n\tval = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_ADVERTISE);\n\tspin_unlock_bh(&jme->phy_lock);\n\n\tecmd->autoneg =\n\t\t(val & (ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM)) != 0;\n}\n\nstatic int\njme_set_pauseparam(struct net_device *netdev,\n\t\t\tstruct ethtool_pauseparam *ecmd)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 val;\n\n\tif (((jme->reg_txpfc & TXPFC_PF_EN) != 0) ^\n\t\t(ecmd->tx_pause != 0)) {\n\n\t\tif (ecmd->tx_pause)\n\t\t\tjme->reg_txpfc |= TXPFC_PF_EN;\n\t\telse\n\t\t\tjme->reg_txpfc &= ~TXPFC_PF_EN;\n\n\t\tjwrite32(jme, JME_TXPFC, jme->reg_txpfc);\n\t}\n\n\tspin_lock_bh(&jme->rxmcs_lock);\n\tif (((jme->reg_rxmcs & RXMCS_FLOWCTRL) != 0) ^\n\t\t(ecmd->rx_pause != 0)) {\n\n\t\tif (ecmd->rx_pause)\n\t\t\tjme->reg_rxmcs |= RXMCS_FLOWCTRL;\n\t\telse\n\t\t\tjme->reg_rxmcs &= ~RXMCS_FLOWCTRL;\n\n\t\tjwrite32(jme, JME_RXMCS, jme->reg_rxmcs);\n\t}\n\tspin_unlock_bh(&jme->rxmcs_lock);\n\n\tspin_lock_bh(&jme->phy_lock);\n\tval = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_ADVERTISE);\n\tif (((val & (ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM)) != 0) ^\n\t\t(ecmd->autoneg != 0)) {\n\n\t\tif (ecmd->autoneg)\n\t\t\tval |= (ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);\n\t\telse\n\t\t\tval &= ~(ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);\n\n\t\tjme_mdio_write(jme->dev, jme->mii_if.phy_id,\n\t\t\t\tMII_ADVERTISE, val);\n\t}\n\tspin_unlock_bh(&jme->phy_lock);\n\n\treturn 0;\n}\n\nstatic void\njme_get_wol(struct net_device *netdev,\n\t\tstruct ethtool_wolinfo *wol)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\twol->supported = WAKE_MAGIC | WAKE_PHY;\n\n\twol->wolopts = 0;\n\n\tif (jme->reg_pmcs & (PMCS_LFEN | PMCS_LREN))\n\t\twol->wolopts |= WAKE_PHY;\n\n\tif (jme->reg_pmcs & PMCS_MFEN)\n\t\twol->wolopts |= WAKE_MAGIC;\n\n}\n\nstatic int\njme_set_wol(struct net_device *netdev,\n\t\tstruct ethtool_wolinfo *wol)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tif (wol->wolopts & (WAKE_MAGICSECURE |\n\t\t\t\tWAKE_UCAST |\n\t\t\t\tWAKE_MCAST |\n\t\t\t\tWAKE_BCAST |\n\t\t\t\tWAKE_ARP))\n\t\treturn -EOPNOTSUPP;\n\n\tjme->reg_pmcs = 0;\n\n\tif (wol->wolopts & WAKE_PHY)\n\t\tjme->reg_pmcs |= PMCS_LFEN | PMCS_LREN;\n\n\tif (wol->wolopts & WAKE_MAGIC)\n\t\tjme->reg_pmcs |= PMCS_MFEN;\n\n\treturn 0;\n}\n\nstatic int\njme_get_link_ksettings(struct net_device *netdev,\n\t\t       struct ethtool_link_ksettings *cmd)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tspin_lock_bh(&jme->phy_lock);\n\tmii_ethtool_get_link_ksettings(&jme->mii_if, cmd);\n\tspin_unlock_bh(&jme->phy_lock);\n\treturn 0;\n}\n\nstatic int\njme_set_link_ksettings(struct net_device *netdev,\n\t\t       const struct ethtool_link_ksettings *cmd)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tint rc, fdc = 0;\n\n\tif (cmd->base.speed == SPEED_1000 &&\n\t    cmd->base.autoneg != AUTONEG_ENABLE)\n\t\treturn -EINVAL;\n\n\t \n\tif (jme->mii_if.force_media &&\n\t    cmd->base.autoneg != AUTONEG_ENABLE &&\n\t    (jme->mii_if.full_duplex != cmd->base.duplex))\n\t\tfdc = 1;\n\n\tspin_lock_bh(&jme->phy_lock);\n\trc = mii_ethtool_set_link_ksettings(&jme->mii_if, cmd);\n\tspin_unlock_bh(&jme->phy_lock);\n\n\tif (!rc) {\n\t\tif (fdc)\n\t\t\tjme_reset_link(jme);\n\t\tjme->old_cmd = *cmd;\n\t\tset_bit(JME_FLAG_SSET, &jme->flags);\n\t}\n\n\treturn rc;\n}\n\nstatic int\njme_ioctl(struct net_device *netdev, struct ifreq *rq, int cmd)\n{\n\tint rc;\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tstruct mii_ioctl_data *mii_data = if_mii(rq);\n\tunsigned int duplex_chg;\n\n\tif (cmd == SIOCSMIIREG) {\n\t\tu16 val = mii_data->val_in;\n\t\tif (!(val & (BMCR_RESET|BMCR_ANENABLE)) &&\n\t\t    (val & BMCR_SPEED1000))\n\t\t\treturn -EINVAL;\n\t}\n\n\tspin_lock_bh(&jme->phy_lock);\n\trc = generic_mii_ioctl(&jme->mii_if, mii_data, cmd, &duplex_chg);\n\tspin_unlock_bh(&jme->phy_lock);\n\n\tif (!rc && (cmd == SIOCSMIIREG)) {\n\t\tif (duplex_chg)\n\t\t\tjme_reset_link(jme);\n\t\tjme_get_link_ksettings(netdev, &jme->old_cmd);\n\t\tset_bit(JME_FLAG_SSET, &jme->flags);\n\t}\n\n\treturn rc;\n}\n\nstatic u32\njme_get_link(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\treturn jread32(jme, JME_PHY_LINK) & PHY_LINK_UP;\n}\n\nstatic u32\njme_get_msglevel(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\treturn jme->msg_enable;\n}\n\nstatic void\njme_set_msglevel(struct net_device *netdev, u32 value)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tjme->msg_enable = value;\n}\n\nstatic netdev_features_t\njme_fix_features(struct net_device *netdev, netdev_features_t features)\n{\n\tif (netdev->mtu > 1900)\n\t\tfeatures &= ~(NETIF_F_ALL_TSO | NETIF_F_CSUM_MASK);\n\treturn features;\n}\n\nstatic int\njme_set_features(struct net_device *netdev, netdev_features_t features)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tspin_lock_bh(&jme->rxmcs_lock);\n\tif (features & NETIF_F_RXCSUM)\n\t\tjme->reg_rxmcs |= RXMCS_CHECKSUM;\n\telse\n\t\tjme->reg_rxmcs &= ~RXMCS_CHECKSUM;\n\tjwrite32(jme, JME_RXMCS, jme->reg_rxmcs);\n\tspin_unlock_bh(&jme->rxmcs_lock);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void jme_netpoll(struct net_device *dev)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tjme_intr(dev->irq, dev);\n\tlocal_irq_restore(flags);\n}\n#endif\n\nstatic int\njme_nway_reset(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tjme_restart_an(jme);\n\treturn 0;\n}\n\nstatic u8\njme_smb_read(struct jme_adapter *jme, unsigned int addr)\n{\n\tu32 val;\n\tint to;\n\n\tval = jread32(jme, JME_SMBCSR);\n\tto = JME_SMB_BUSY_TIMEOUT;\n\twhile ((val & SMBCSR_BUSY) && --to) {\n\t\tmsleep(1);\n\t\tval = jread32(jme, JME_SMBCSR);\n\t}\n\tif (!to) {\n\t\tnetif_err(jme, hw, jme->dev, \"SMB Bus Busy\\n\");\n\t\treturn 0xFF;\n\t}\n\n\tjwrite32(jme, JME_SMBINTF,\n\t\t((addr << SMBINTF_HWADDR_SHIFT) & SMBINTF_HWADDR) |\n\t\tSMBINTF_HWRWN_READ |\n\t\tSMBINTF_HWCMD);\n\n\tval = jread32(jme, JME_SMBINTF);\n\tto = JME_SMB_BUSY_TIMEOUT;\n\twhile ((val & SMBINTF_HWCMD) && --to) {\n\t\tmsleep(1);\n\t\tval = jread32(jme, JME_SMBINTF);\n\t}\n\tif (!to) {\n\t\tnetif_err(jme, hw, jme->dev, \"SMB Bus Busy\\n\");\n\t\treturn 0xFF;\n\t}\n\n\treturn (val & SMBINTF_HWDATR) >> SMBINTF_HWDATR_SHIFT;\n}\n\nstatic void\njme_smb_write(struct jme_adapter *jme, unsigned int addr, u8 data)\n{\n\tu32 val;\n\tint to;\n\n\tval = jread32(jme, JME_SMBCSR);\n\tto = JME_SMB_BUSY_TIMEOUT;\n\twhile ((val & SMBCSR_BUSY) && --to) {\n\t\tmsleep(1);\n\t\tval = jread32(jme, JME_SMBCSR);\n\t}\n\tif (!to) {\n\t\tnetif_err(jme, hw, jme->dev, \"SMB Bus Busy\\n\");\n\t\treturn;\n\t}\n\n\tjwrite32(jme, JME_SMBINTF,\n\t\t((data << SMBINTF_HWDATW_SHIFT) & SMBINTF_HWDATW) |\n\t\t((addr << SMBINTF_HWADDR_SHIFT) & SMBINTF_HWADDR) |\n\t\tSMBINTF_HWRWN_WRITE |\n\t\tSMBINTF_HWCMD);\n\n\tval = jread32(jme, JME_SMBINTF);\n\tto = JME_SMB_BUSY_TIMEOUT;\n\twhile ((val & SMBINTF_HWCMD) && --to) {\n\t\tmsleep(1);\n\t\tval = jread32(jme, JME_SMBINTF);\n\t}\n\tif (!to) {\n\t\tnetif_err(jme, hw, jme->dev, \"SMB Bus Busy\\n\");\n\t\treturn;\n\t}\n\n\tmdelay(2);\n}\n\nstatic int\njme_get_eeprom_len(struct net_device *netdev)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tu32 val;\n\tval = jread32(jme, JME_SMBCSR);\n\treturn (val & SMBCSR_EEPROMD) ? JME_SMB_LEN : 0;\n}\n\nstatic int\njme_get_eeprom(struct net_device *netdev,\n\t\tstruct ethtool_eeprom *eeprom, u8 *data)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tint i, offset = eeprom->offset, len = eeprom->len;\n\n\t \n\teeprom->magic = JME_EEPROM_MAGIC;\n\tfor (i = 0 ; i < len ; ++i)\n\t\tdata[i] = jme_smb_read(jme, i + offset);\n\n\treturn 0;\n}\n\nstatic int\njme_set_eeprom(struct net_device *netdev,\n\t\tstruct ethtool_eeprom *eeprom, u8 *data)\n{\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\tint i, offset = eeprom->offset, len = eeprom->len;\n\n\tif (eeprom->magic != JME_EEPROM_MAGIC)\n\t\treturn -EINVAL;\n\n\t \n\tfor (i = 0 ; i < len ; ++i)\n\t\tjme_smb_write(jme, i + offset, data[i]);\n\n\treturn 0;\n}\n\nstatic const struct ethtool_ops jme_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS |\n\t\t\t\t     ETHTOOL_COALESCE_MAX_FRAMES |\n\t\t\t\t     ETHTOOL_COALESCE_USE_ADAPTIVE_RX,\n\t.get_drvinfo            = jme_get_drvinfo,\n\t.get_regs_len\t\t= jme_get_regs_len,\n\t.get_regs\t\t= jme_get_regs,\n\t.get_coalesce\t\t= jme_get_coalesce,\n\t.set_coalesce\t\t= jme_set_coalesce,\n\t.get_pauseparam\t\t= jme_get_pauseparam,\n\t.set_pauseparam\t\t= jme_set_pauseparam,\n\t.get_wol\t\t= jme_get_wol,\n\t.set_wol\t\t= jme_set_wol,\n\t.get_link\t\t= jme_get_link,\n\t.get_msglevel           = jme_get_msglevel,\n\t.set_msglevel           = jme_set_msglevel,\n\t.nway_reset             = jme_nway_reset,\n\t.get_eeprom_len\t\t= jme_get_eeprom_len,\n\t.get_eeprom\t\t= jme_get_eeprom,\n\t.set_eeprom\t\t= jme_set_eeprom,\n\t.get_link_ksettings\t= jme_get_link_ksettings,\n\t.set_link_ksettings\t= jme_set_link_ksettings,\n};\n\nstatic int\njme_pci_dma64(struct pci_dev *pdev)\n{\n\tif (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250 &&\n\t    !dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64)))\n\t\treturn 1;\n\n\tif (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250 &&\n\t    !dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(40)))\n\t\treturn 1;\n\n\tif (!dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32)))\n\t\treturn 0;\n\n\treturn -1;\n}\n\nstatic inline void\njme_phy_init(struct jme_adapter *jme)\n{\n\tu16 reg26;\n\n\treg26 = jme_mdio_read(jme->dev, jme->mii_if.phy_id, 26);\n\tjme_mdio_write(jme->dev, jme->mii_if.phy_id, 26, reg26 | 0x1000);\n}\n\nstatic inline void\njme_check_hw_ver(struct jme_adapter *jme)\n{\n\tu32 chipmode;\n\n\tchipmode = jread32(jme, JME_CHIPMODE);\n\n\tjme->fpgaver = (chipmode & CM_FPGAVER_MASK) >> CM_FPGAVER_SHIFT;\n\tjme->chiprev = (chipmode & CM_CHIPREV_MASK) >> CM_CHIPREV_SHIFT;\n\tjme->chip_main_rev = jme->chiprev & 0xF;\n\tjme->chip_sub_rev = (jme->chiprev >> 4) & 0xF;\n}\n\nstatic const struct net_device_ops jme_netdev_ops = {\n\t.ndo_open\t\t= jme_open,\n\t.ndo_stop\t\t= jme_close,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_eth_ioctl\t\t= jme_ioctl,\n\t.ndo_start_xmit\t\t= jme_start_xmit,\n\t.ndo_set_mac_address\t= jme_set_macaddr,\n\t.ndo_set_rx_mode\t= jme_set_multi,\n\t.ndo_change_mtu\t\t= jme_change_mtu,\n\t.ndo_tx_timeout\t\t= jme_tx_timeout,\n\t.ndo_fix_features       = jme_fix_features,\n\t.ndo_set_features       = jme_set_features,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= jme_netpoll,\n#endif\n};\n\nstatic int\njme_init_one(struct pci_dev *pdev,\n\t     const struct pci_device_id *ent)\n{\n\tint rc = 0, using_dac, i;\n\tstruct net_device *netdev;\n\tstruct jme_adapter *jme;\n\tu16 bmcr, bmsr;\n\tu32 apmc;\n\n\t \n\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S | PCIE_LINK_STATE_L1 |\n\t\t\t       PCIE_LINK_STATE_CLKPM);\n\n\trc = pci_enable_device(pdev);\n\tif (rc) {\n\t\tpr_err(\"Cannot enable PCI device\\n\");\n\t\tgoto err_out;\n\t}\n\n\tusing_dac = jme_pci_dma64(pdev);\n\tif (using_dac < 0) {\n\t\tpr_err(\"Cannot set PCI DMA Mask\\n\");\n\t\trc = -EIO;\n\t\tgoto err_out_disable_pdev;\n\t}\n\n\tif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\n\t\tpr_err(\"No PCI resource region found\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err_out_disable_pdev;\n\t}\n\n\trc = pci_request_regions(pdev, DRV_NAME);\n\tif (rc) {\n\t\tpr_err(\"Cannot obtain PCI resource region\\n\");\n\t\tgoto err_out_disable_pdev;\n\t}\n\n\tpci_set_master(pdev);\n\n\t \n\tnetdev = alloc_etherdev(sizeof(*jme));\n\tif (!netdev) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out_release_regions;\n\t}\n\tnetdev->netdev_ops = &jme_netdev_ops;\n\tnetdev->ethtool_ops\t\t= &jme_ethtool_ops;\n\tnetdev->watchdog_timeo\t\t= TX_TIMEOUT;\n\tnetdev->hw_features\t\t=\tNETIF_F_IP_CSUM |\n\t\t\t\t\t\tNETIF_F_IPV6_CSUM |\n\t\t\t\t\t\tNETIF_F_SG |\n\t\t\t\t\t\tNETIF_F_TSO |\n\t\t\t\t\t\tNETIF_F_TSO6 |\n\t\t\t\t\t\tNETIF_F_RXCSUM;\n\tnetdev->features\t\t=\tNETIF_F_IP_CSUM |\n\t\t\t\t\t\tNETIF_F_IPV6_CSUM |\n\t\t\t\t\t\tNETIF_F_SG |\n\t\t\t\t\t\tNETIF_F_TSO |\n\t\t\t\t\t\tNETIF_F_TSO6 |\n\t\t\t\t\t\tNETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\t\t\tNETIF_F_HW_VLAN_CTAG_RX;\n\tif (using_dac)\n\t\tnetdev->features\t|=\tNETIF_F_HIGHDMA;\n\n\t \n\tnetdev->min_mtu = IPV6_MIN_MTU;\n\tnetdev->max_mtu = MAX_ETHERNET_JUMBO_PACKET_SIZE - ETH_HLEN;\n\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\tpci_set_drvdata(pdev, netdev);\n\n\t \n\tjme = netdev_priv(netdev);\n\tjme->pdev = pdev;\n\tjme->dev = netdev;\n\tjme->jme_rx = netif_rx;\n\tjme->old_mtu = netdev->mtu = 1500;\n\tjme->phylink = 0;\n\tjme->tx_ring_size = 1 << 10;\n\tjme->tx_ring_mask = jme->tx_ring_size - 1;\n\tjme->tx_wake_threshold = 1 << 9;\n\tjme->rx_ring_size = 1 << 9;\n\tjme->rx_ring_mask = jme->rx_ring_size - 1;\n\tjme->msg_enable = JME_DEF_MSG_ENABLE;\n\tjme->regs = ioremap(pci_resource_start(pdev, 0),\n\t\t\t     pci_resource_len(pdev, 0));\n\tif (!(jme->regs)) {\n\t\tpr_err(\"Mapping PCI resource region error\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err_out_free_netdev;\n\t}\n\n\tif (no_pseudohp) {\n\t\tapmc = jread32(jme, JME_APMC) & ~JME_APMC_PSEUDO_HP_EN;\n\t\tjwrite32(jme, JME_APMC, apmc);\n\t} else if (force_pseudohp) {\n\t\tapmc = jread32(jme, JME_APMC) | JME_APMC_PSEUDO_HP_EN;\n\t\tjwrite32(jme, JME_APMC, apmc);\n\t}\n\n\tnetif_napi_add(netdev, &jme->napi, jme_poll);\n\n\tspin_lock_init(&jme->phy_lock);\n\tspin_lock_init(&jme->macaddr_lock);\n\tspin_lock_init(&jme->rxmcs_lock);\n\n\tatomic_set(&jme->link_changing, 1);\n\tatomic_set(&jme->rx_cleaning, 1);\n\tatomic_set(&jme->tx_cleaning, 1);\n\tatomic_set(&jme->rx_empty, 1);\n\n\ttasklet_setup(&jme->pcc_task, jme_pcc_tasklet);\n\tINIT_WORK(&jme->linkch_task, jme_link_change_work);\n\tjme->dpi.cur = PCC_P1;\n\n\tjme->reg_ghc = 0;\n\tjme->reg_rxcs = RXCS_DEFAULT;\n\tjme->reg_rxmcs = RXMCS_DEFAULT;\n\tjme->reg_txpfc = 0;\n\tjme->reg_pmcs = PMCS_MFEN;\n\tjme->reg_gpreg1 = GPREG1_DEFAULT;\n\n\tif (jme->reg_rxmcs & RXMCS_CHECKSUM)\n\t\tnetdev->features |= NETIF_F_RXCSUM;\n\n\t \n\tpci_read_config_byte(pdev, PCI_DCSR_MRRS, &jme->mrrs);\n\tjme->mrrs &= PCI_DCSR_MRRS_MASK;\n\tswitch (jme->mrrs) {\n\tcase MRRS_128B:\n\t\tjme->reg_txcs = TXCS_DEFAULT | TXCS_DMASIZE_128B;\n\t\tbreak;\n\tcase MRRS_256B:\n\t\tjme->reg_txcs = TXCS_DEFAULT | TXCS_DMASIZE_256B;\n\t\tbreak;\n\tdefault:\n\t\tjme->reg_txcs = TXCS_DEFAULT | TXCS_DMASIZE_512B;\n\t\tbreak;\n\t}\n\n\t \n\tjme_check_hw_ver(jme);\n\tjme->mii_if.dev = netdev;\n\tif (jme->fpgaver) {\n\t\tjme->mii_if.phy_id = 0;\n\t\tfor (i = 1 ; i < 32 ; ++i) {\n\t\t\tbmcr = jme_mdio_read(netdev, i, MII_BMCR);\n\t\t\tbmsr = jme_mdio_read(netdev, i, MII_BMSR);\n\t\t\tif (bmcr != 0xFFFFU && (bmcr != 0 || bmsr != 0)) {\n\t\t\t\tjme->mii_if.phy_id = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!jme->mii_if.phy_id) {\n\t\t\trc = -EIO;\n\t\t\tpr_err(\"Can not find phy_id\\n\");\n\t\t\tgoto err_out_unmap;\n\t\t}\n\n\t\tjme->reg_ghc |= GHC_LINK_POLL;\n\t} else {\n\t\tjme->mii_if.phy_id = 1;\n\t}\n\tif (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250)\n\t\tjme->mii_if.supports_gmii = true;\n\telse\n\t\tjme->mii_if.supports_gmii = false;\n\tjme->mii_if.phy_id_mask = 0x1F;\n\tjme->mii_if.reg_num_mask = 0x1F;\n\tjme->mii_if.mdio_read = jme_mdio_read;\n\tjme->mii_if.mdio_write = jme_mdio_write;\n\n\tjme_clear_pm_disable_wol(jme);\n\tdevice_init_wakeup(&pdev->dev, true);\n\n\tjme_set_phyfifo_5level(jme);\n\tjme->pcirev = pdev->revision;\n\tif (!jme->fpgaver)\n\t\tjme_phy_init(jme);\n\tjme_phy_off(jme);\n\n\t \n\tjme_reset_mac_processor(jme);\n\trc = jme_reload_eeprom(jme);\n\tif (rc) {\n\t\tpr_err(\"Reload eeprom for reading MAC Address error\\n\");\n\t\tgoto err_out_unmap;\n\t}\n\tjme_load_macaddr(netdev);\n\n\t \n\tnetif_carrier_off(netdev);\n\n\trc = register_netdev(netdev);\n\tif (rc) {\n\t\tpr_err(\"Cannot register net device\\n\");\n\t\tgoto err_out_unmap;\n\t}\n\n\tnetif_info(jme, probe, jme->dev, \"%s%s chiprev:%x pcirev:%x macaddr:%pM\\n\",\n\t\t   (jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC250) ?\n\t\t   \"JMC250 Gigabit Ethernet\" :\n\t\t   (jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC260) ?\n\t\t   \"JMC260 Fast Ethernet\" : \"Unknown\",\n\t\t   (jme->fpgaver != 0) ? \" (FPGA)\" : \"\",\n\t\t   (jme->fpgaver != 0) ? jme->fpgaver : jme->chiprev,\n\t\t   jme->pcirev, netdev->dev_addr);\n\n\treturn 0;\n\nerr_out_unmap:\n\tiounmap(jme->regs);\nerr_out_free_netdev:\n\tfree_netdev(netdev);\nerr_out_release_regions:\n\tpci_release_regions(pdev);\nerr_out_disable_pdev:\n\tpci_disable_device(pdev);\nerr_out:\n\treturn rc;\n}\n\nstatic void\njme_remove_one(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tunregister_netdev(netdev);\n\tiounmap(jme->regs);\n\tfree_netdev(netdev);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\n}\n\nstatic void\njme_shutdown(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tjme_powersave_phy(jme);\n\tpci_pme_active(pdev, true);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int\njme_suspend(struct device *dev)\n{\n\tstruct net_device *netdev = dev_get_drvdata(dev);\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tif (!netif_running(netdev))\n\t\treturn 0;\n\n\tatomic_dec(&jme->link_changing);\n\n\tnetif_device_detach(netdev);\n\tnetif_stop_queue(netdev);\n\tjme_stop_irq(jme);\n\n\ttasklet_disable(&jme->txclean_task);\n\ttasklet_disable(&jme->rxclean_task);\n\ttasklet_disable(&jme->rxempty_task);\n\n\tif (netif_carrier_ok(netdev)) {\n\t\tif (test_bit(JME_FLAG_POLL, &jme->flags))\n\t\t\tjme_polling_mode(jme);\n\n\t\tjme_stop_pcc_timer(jme);\n\t\tjme_disable_rx_engine(jme);\n\t\tjme_disable_tx_engine(jme);\n\t\tjme_reset_mac_processor(jme);\n\t\tjme_free_rx_resources(jme);\n\t\tjme_free_tx_resources(jme);\n\t\tnetif_carrier_off(netdev);\n\t\tjme->phylink = 0;\n\t}\n\n\ttasklet_enable(&jme->txclean_task);\n\ttasklet_enable(&jme->rxclean_task);\n\ttasklet_enable(&jme->rxempty_task);\n\n\tjme_powersave_phy(jme);\n\n\treturn 0;\n}\n\nstatic int\njme_resume(struct device *dev)\n{\n\tstruct net_device *netdev = dev_get_drvdata(dev);\n\tstruct jme_adapter *jme = netdev_priv(netdev);\n\n\tif (!netif_running(netdev))\n\t\treturn 0;\n\n\tjme_clear_pm_disable_wol(jme);\n\tjme_phy_on(jme);\n\tif (test_bit(JME_FLAG_SSET, &jme->flags))\n\t\tjme_set_link_ksettings(netdev, &jme->old_cmd);\n\telse\n\t\tjme_reset_phy_processor(jme);\n\tjme_phy_calibration(jme);\n\tjme_phy_setEA(jme);\n\tnetif_device_attach(netdev);\n\n\tatomic_inc(&jme->link_changing);\n\n\tjme_reset_link(jme);\n\n\tjme_start_irq(jme);\n\n\treturn 0;\n}\n\nstatic SIMPLE_DEV_PM_OPS(jme_pm_ops, jme_suspend, jme_resume);\n#define JME_PM_OPS (&jme_pm_ops)\n\n#else\n\n#define JME_PM_OPS NULL\n#endif\n\nstatic const struct pci_device_id jme_pci_tbl[] = {\n\t{ PCI_VDEVICE(JMICRON, PCI_DEVICE_ID_JMICRON_JMC250) },\n\t{ PCI_VDEVICE(JMICRON, PCI_DEVICE_ID_JMICRON_JMC260) },\n\t{ }\n};\n\nstatic struct pci_driver jme_driver = {\n\t.name           = DRV_NAME,\n\t.id_table       = jme_pci_tbl,\n\t.probe          = jme_init_one,\n\t.remove         = jme_remove_one,\n\t.shutdown       = jme_shutdown,\n\t.driver.pm\t= JME_PM_OPS,\n};\n\nstatic int __init\njme_init_module(void)\n{\n\tpr_info(\"JMicron JMC2XX ethernet driver version %s\\n\", DRV_VERSION);\n\treturn pci_register_driver(&jme_driver);\n}\n\nstatic void __exit\njme_cleanup_module(void)\n{\n\tpci_unregister_driver(&jme_driver);\n}\n\nmodule_init(jme_init_module);\nmodule_exit(jme_cleanup_module);\n\nMODULE_AUTHOR(\"Guo-Fu Tseng <cooldavid@cooldavid.org>\");\nMODULE_DESCRIPTION(\"JMicron JMC2x0 PCI Express Ethernet driver\");\nMODULE_LICENSE(\"GPL\");\nMODULE_VERSION(DRV_VERSION);\nMODULE_DEVICE_TABLE(pci, jme_pci_tbl);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}