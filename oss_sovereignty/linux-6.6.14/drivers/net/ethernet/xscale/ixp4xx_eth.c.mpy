{
  "module_name": "ixp4xx_eth.c",
  "hash_id": "558ded5a6d226f9100ef5eb9f018fa64777330e3f5e3cf9c046daa93e432aeb3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/xscale/ixp4xx_eth.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/etherdevice.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/net_tstamp.h>\n#include <linux/of.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n#include <linux/phy.h>\n#include <linux/platform_device.h>\n#include <linux/ptp_classify.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <linux/soc/ixp4xx/npe.h>\n#include <linux/soc/ixp4xx/qmgr.h>\n#include <linux/soc/ixp4xx/cpu.h>\n#include <linux/types.h>\n\n#define IXP4XX_ETH_NPEA\t\t0x00\n#define IXP4XX_ETH_NPEB\t\t0x10\n#define IXP4XX_ETH_NPEC\t\t0x20\n\n#include \"ixp46x_ts.h\"\n\n#define DEBUG_DESC\t\t0\n#define DEBUG_RX\t\t0\n#define DEBUG_TX\t\t0\n#define DEBUG_PKT_BYTES\t\t0\n#define DEBUG_MDIO\t\t0\n#define DEBUG_CLOSE\t\t0\n\n#define DRV_NAME\t\t\"ixp4xx_eth\"\n\n#define MAX_NPES\t\t3\n\n#define RX_DESCS\t\t64  \n#define TX_DESCS\t\t16  \n#define TXDONE_QUEUE_LEN\t64  \n\n#define POOL_ALLOC_SIZE\t\t(sizeof(struct desc) * (RX_DESCS + TX_DESCS))\n#define REGS_SIZE\t\t0x1000\n#define MAX_MRU\t\t\t1536  \n#define RX_BUFF_SIZE\t\tALIGN((NET_IP_ALIGN) + MAX_MRU, 4)\n\n#define NAPI_WEIGHT\t\t16\n#define MDIO_INTERVAL\t\t(3 * HZ)\n#define MAX_MDIO_RETRIES\t100  \n#define MAX_CLOSE_WAIT\t\t1000  \n\n#define NPE_ID(port_id)\t\t((port_id) >> 4)\n#define PHYSICAL_ID(port_id)\t((NPE_ID(port_id) + 2) % 3)\n#define TX_QUEUE(port_id)\t(NPE_ID(port_id) + 23)\n#define RXFREE_QUEUE(port_id)\t(NPE_ID(port_id) + 26)\n#define TXDONE_QUEUE\t\t31\n\n#define PTP_SLAVE_MODE\t\t1\n#define PTP_MASTER_MODE\t\t2\n#define PORT2CHANNEL(p)\t\tNPE_ID(p->id)\n\n \n#define TX_CNTRL0_TX_EN\t\t0x01\n#define TX_CNTRL0_HALFDUPLEX\t0x02\n#define TX_CNTRL0_RETRY\t\t0x04\n#define TX_CNTRL0_PAD_EN\t0x08\n#define TX_CNTRL0_APPEND_FCS\t0x10\n#define TX_CNTRL0_2DEFER\t0x20\n#define TX_CNTRL0_RMII\t\t0x40  \n#define TX_CNTRL1_RETRIES\t0x0F  \n\n \n#define RX_CNTRL0_RX_EN\t\t0x01\n#define RX_CNTRL0_PADSTRIP_EN\t0x02\n#define RX_CNTRL0_SEND_FCS\t0x04\n#define RX_CNTRL0_PAUSE_EN\t0x08\n#define RX_CNTRL0_LOOP_EN\t0x10\n#define RX_CNTRL0_ADDR_FLTR_EN\t0x20\n#define RX_CNTRL0_RX_RUNT_EN\t0x40\n#define RX_CNTRL0_BCAST_DIS\t0x80\n#define RX_CNTRL1_DEFER_EN\t0x01\n\n \n#define CORE_RESET\t\t0x01\n#define CORE_RX_FIFO_FLUSH\t0x02\n#define CORE_TX_FIFO_FLUSH\t0x04\n#define CORE_SEND_JAM\t\t0x08\n#define CORE_MDC_EN\t\t0x10  \n\n#define DEFAULT_TX_CNTRL0\t(TX_CNTRL0_TX_EN | TX_CNTRL0_RETRY |\t\\\n\t\t\t\t TX_CNTRL0_PAD_EN | TX_CNTRL0_APPEND_FCS | \\\n\t\t\t\t TX_CNTRL0_2DEFER)\n#define DEFAULT_RX_CNTRL0\tRX_CNTRL0_RX_EN\n#define DEFAULT_CORE_CNTRL\tCORE_MDC_EN\n\n\n \n#define NPE_GETSTATUS\t\t\t0x00\n#define NPE_EDB_SETPORTADDRESS\t\t0x01\n#define NPE_EDB_GETMACADDRESSDATABASE\t0x02\n#define NPE_EDB_SETMACADDRESSSDATABASE\t0x03\n#define NPE_GETSTATS\t\t\t0x04\n#define NPE_RESETSTATS\t\t\t0x05\n#define NPE_SETMAXFRAMELENGTHS\t\t0x06\n#define NPE_VLAN_SETRXTAGMODE\t\t0x07\n#define NPE_VLAN_SETDEFAULTRXVID\t0x08\n#define NPE_VLAN_SETPORTVLANTABLEENTRY\t0x09\n#define NPE_VLAN_SETPORTVLANTABLERANGE\t0x0A\n#define NPE_VLAN_SETRXQOSENTRY\t\t0x0B\n#define NPE_VLAN_SETPORTIDEXTRACTIONMODE 0x0C\n#define NPE_STP_SETBLOCKINGSTATE\t0x0D\n#define NPE_FW_SETFIREWALLMODE\t\t0x0E\n#define NPE_PC_SETFRAMECONTROLDURATIONID 0x0F\n#define NPE_PC_SETAPMACTABLE\t\t0x11\n#define NPE_SETLOOPBACK_MODE\t\t0x12\n#define NPE_PC_SETBSSIDTABLE\t\t0x13\n#define NPE_ADDRESS_FILTER_CONFIG\t0x14\n#define NPE_APPENDFCSCONFIG\t\t0x15\n#define NPE_NOTIFY_MAC_RECOVERY_DONE\t0x16\n#define NPE_MAC_RECOVERY_START\t\t0x17\n\n\n#ifdef __ARMEB__\ntypedef struct sk_buff buffer_t;\n#define free_buffer dev_kfree_skb\n#define free_buffer_irq dev_consume_skb_irq\n#else\ntypedef void buffer_t;\n#define free_buffer kfree\n#define free_buffer_irq kfree\n#endif\n\n \nstruct eth_plat_info {\n\tu8 phy;\t\t \n\tu8 rxq;\t\t \n\tu8 txreadyq;\n\tu8 hwaddr[ETH_ALEN];\n\tu8 npe;\t\t \n\tbool has_mdio;\t \n};\n\nstruct eth_regs {\n\tu32 tx_control[2], __res1[2];\t\t \n\tu32 rx_control[2], __res2[2];\t\t \n\tu32 random_seed, __res3[3];\t\t \n\tu32 partial_empty_threshold, __res4;\t \n\tu32 partial_full_threshold, __res5;\t \n\tu32 tx_start_bytes, __res6[3];\t\t \n\tu32 tx_deferral, rx_deferral, __res7[2]; \n\tu32 tx_2part_deferral[2], __res8[2];\t \n\tu32 slot_time, __res9[3];\t\t \n\tu32 mdio_command[4];\t\t\t \n\tu32 mdio_status[4];\t\t\t \n\tu32 mcast_mask[6], __res10[2];\t\t \n\tu32 mcast_addr[6], __res11[2];\t\t \n\tu32 int_clock_threshold, __res12[3];\t \n\tu32 hw_addr[6], __res13[61];\t\t \n\tu32 core_control;\t\t\t \n};\n\nstruct port {\n\tstruct eth_regs __iomem *regs;\n\tstruct ixp46x_ts_regs __iomem *timesync_regs;\n\tint phc_index;\n\tstruct npe *npe;\n\tstruct net_device *netdev;\n\tstruct napi_struct napi;\n\tstruct eth_plat_info *plat;\n\tbuffer_t *rx_buff_tab[RX_DESCS], *tx_buff_tab[TX_DESCS];\n\tstruct desc *desc_tab;\t \n\tdma_addr_t desc_tab_phys;\n\tint id;\t\t\t \n\tint speed, duplex;\n\tu8 firmware[4];\n\tint hwts_tx_en;\n\tint hwts_rx_en;\n};\n\n \nstruct msg {\n#ifdef __ARMEB__\n\tu8 cmd, eth_id, byte2, byte3;\n\tu8 byte4, byte5, byte6, byte7;\n#else\n\tu8 byte3, byte2, eth_id, cmd;\n\tu8 byte7, byte6, byte5, byte4;\n#endif\n};\n\n \nstruct desc {\n\tu32 next;\t\t \n\n#ifdef __ARMEB__\n\tu16 buf_len;\t\t \n\tu16 pkt_len;\t\t \n\tu32 data;\t\t \n\tu8 dest_id;\n\tu8 src_id;\n\tu16 flags;\n\tu8 qos;\n\tu8 padlen;\n\tu16 vlan_tci;\n#else\n\tu16 pkt_len;\t\t \n\tu16 buf_len;\t\t \n\tu32 data;\t\t \n\tu16 flags;\n\tu8 src_id;\n\tu8 dest_id;\n\tu16 vlan_tci;\n\tu8 padlen;\n\tu8 qos;\n#endif\n\n#ifdef __ARMEB__\n\tu8 dst_mac_0, dst_mac_1, dst_mac_2, dst_mac_3;\n\tu8 dst_mac_4, dst_mac_5, src_mac_0, src_mac_1;\n\tu8 src_mac_2, src_mac_3, src_mac_4, src_mac_5;\n#else\n\tu8 dst_mac_3, dst_mac_2, dst_mac_1, dst_mac_0;\n\tu8 src_mac_1, src_mac_0, dst_mac_5, dst_mac_4;\n\tu8 src_mac_5, src_mac_4, src_mac_3, src_mac_2;\n#endif\n};\n\n\n#define rx_desc_phys(port, n)\t((port)->desc_tab_phys +\t\t\\\n\t\t\t\t (n) * sizeof(struct desc))\n#define rx_desc_ptr(port, n)\t(&(port)->desc_tab[n])\n\n#define tx_desc_phys(port, n)\t((port)->desc_tab_phys +\t\t\\\n\t\t\t\t ((n) + RX_DESCS) * sizeof(struct desc))\n#define tx_desc_ptr(port, n)\t(&(port)->desc_tab[(n) + RX_DESCS])\n\n#ifndef __ARMEB__\nstatic inline void memcpy_swab32(u32 *dest, u32 *src, int cnt)\n{\n\tint i;\n\tfor (i = 0; i < cnt; i++)\n\t\tdest[i] = swab32(src[i]);\n}\n#endif\n\nstatic DEFINE_SPINLOCK(mdio_lock);\nstatic struct eth_regs __iomem *mdio_regs;  \nstatic struct mii_bus *mdio_bus;\nstatic struct device_node *mdio_bus_np;\nstatic int ports_open;\nstatic struct port *npe_port_tab[MAX_NPES];\nstatic struct dma_pool *dma_pool;\n\nstatic int ixp_ptp_match(struct sk_buff *skb, u16 uid_hi, u32 uid_lo, u16 seqid)\n{\n\tu8 *data = skb->data;\n\tunsigned int offset;\n\tu16 *hi, *id;\n\tu32 lo;\n\n\tif (ptp_classify_raw(skb) != PTP_CLASS_V1_IPV4)\n\t\treturn 0;\n\n\toffset = ETH_HLEN + IPV4_HLEN(data) + UDP_HLEN;\n\n\tif (skb->len < offset + OFF_PTP_SEQUENCE_ID + sizeof(seqid))\n\t\treturn 0;\n\n\thi = (u16 *)(data + offset + OFF_PTP_SOURCE_UUID);\n\tid = (u16 *)(data + offset + OFF_PTP_SEQUENCE_ID);\n\n\tmemcpy(&lo, &hi[1], sizeof(lo));\n\n\treturn (uid_hi == ntohs(*hi) &&\n\t\tuid_lo == ntohl(lo) &&\n\t\tseqid  == ntohs(*id));\n}\n\nstatic void ixp_rx_timestamp(struct port *port, struct sk_buff *skb)\n{\n\tstruct skb_shared_hwtstamps *shhwtstamps;\n\tstruct ixp46x_ts_regs *regs;\n\tu64 ns;\n\tu32 ch, hi, lo, val;\n\tu16 uid, seq;\n\n\tif (!port->hwts_rx_en)\n\t\treturn;\n\n\tch = PORT2CHANNEL(port);\n\n\tregs = port->timesync_regs;\n\n\tval = __raw_readl(&regs->channel[ch].ch_event);\n\n\tif (!(val & RX_SNAPSHOT_LOCKED))\n\t\treturn;\n\n\tlo = __raw_readl(&regs->channel[ch].src_uuid_lo);\n\thi = __raw_readl(&regs->channel[ch].src_uuid_hi);\n\n\tuid = hi & 0xffff;\n\tseq = (hi >> 16) & 0xffff;\n\n\tif (!ixp_ptp_match(skb, htons(uid), htonl(lo), htons(seq)))\n\t\tgoto out;\n\n\tlo = __raw_readl(&regs->channel[ch].rx_snap_lo);\n\thi = __raw_readl(&regs->channel[ch].rx_snap_hi);\n\tns = ((u64) hi) << 32;\n\tns |= lo;\n\tns <<= TICKS_NS_SHIFT;\n\n\tshhwtstamps = skb_hwtstamps(skb);\n\tmemset(shhwtstamps, 0, sizeof(*shhwtstamps));\n\tshhwtstamps->hwtstamp = ns_to_ktime(ns);\nout:\n\t__raw_writel(RX_SNAPSHOT_LOCKED, &regs->channel[ch].ch_event);\n}\n\nstatic void ixp_tx_timestamp(struct port *port, struct sk_buff *skb)\n{\n\tstruct skb_shared_hwtstamps shhwtstamps;\n\tstruct ixp46x_ts_regs *regs;\n\tstruct skb_shared_info *shtx;\n\tu64 ns;\n\tu32 ch, cnt, hi, lo, val;\n\n\tshtx = skb_shinfo(skb);\n\tif (unlikely(shtx->tx_flags & SKBTX_HW_TSTAMP && port->hwts_tx_en))\n\t\tshtx->tx_flags |= SKBTX_IN_PROGRESS;\n\telse\n\t\treturn;\n\n\tch = PORT2CHANNEL(port);\n\n\tregs = port->timesync_regs;\n\n\t \n\tfor (cnt = 0; cnt < 100; cnt++) {\n\t\tval = __raw_readl(&regs->channel[ch].ch_event);\n\t\tif (val & TX_SNAPSHOT_LOCKED)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n\tif (!(val & TX_SNAPSHOT_LOCKED)) {\n\t\tshtx->tx_flags &= ~SKBTX_IN_PROGRESS;\n\t\treturn;\n\t}\n\n\tlo = __raw_readl(&regs->channel[ch].tx_snap_lo);\n\thi = __raw_readl(&regs->channel[ch].tx_snap_hi);\n\tns = ((u64) hi) << 32;\n\tns |= lo;\n\tns <<= TICKS_NS_SHIFT;\n\n\tmemset(&shhwtstamps, 0, sizeof(shhwtstamps));\n\tshhwtstamps.hwtstamp = ns_to_ktime(ns);\n\tskb_tstamp_tx(skb, &shhwtstamps);\n\n\t__raw_writel(TX_SNAPSHOT_LOCKED, &regs->channel[ch].ch_event);\n}\n\nstatic int hwtstamp_set(struct net_device *netdev, struct ifreq *ifr)\n{\n\tstruct hwtstamp_config cfg;\n\tstruct ixp46x_ts_regs *regs;\n\tstruct port *port = netdev_priv(netdev);\n\tint ret;\n\tint ch;\n\n\tif (copy_from_user(&cfg, ifr->ifr_data, sizeof(cfg)))\n\t\treturn -EFAULT;\n\n\tret = ixp46x_ptp_find(&port->timesync_regs, &port->phc_index);\n\tif (ret)\n\t\treturn ret;\n\n\tch = PORT2CHANNEL(port);\n\tregs = port->timesync_regs;\n\n\tif (cfg.tx_type != HWTSTAMP_TX_OFF && cfg.tx_type != HWTSTAMP_TX_ON)\n\t\treturn -ERANGE;\n\n\tswitch (cfg.rx_filter) {\n\tcase HWTSTAMP_FILTER_NONE:\n\t\tport->hwts_rx_en = 0;\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_SYNC:\n\t\tport->hwts_rx_en = PTP_SLAVE_MODE;\n\t\t__raw_writel(0, &regs->channel[ch].ch_control);\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:\n\t\tport->hwts_rx_en = PTP_MASTER_MODE;\n\t\t__raw_writel(MASTER_MODE, &regs->channel[ch].ch_control);\n\t\tbreak;\n\tdefault:\n\t\treturn -ERANGE;\n\t}\n\n\tport->hwts_tx_en = cfg.tx_type == HWTSTAMP_TX_ON;\n\n\t \n\t__raw_writel(TX_SNAPSHOT_LOCKED | RX_SNAPSHOT_LOCKED,\n\t\t     &regs->channel[ch].ch_event);\n\n\treturn copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;\n}\n\nstatic int hwtstamp_get(struct net_device *netdev, struct ifreq *ifr)\n{\n\tstruct hwtstamp_config cfg;\n\tstruct port *port = netdev_priv(netdev);\n\n\tcfg.flags = 0;\n\tcfg.tx_type = port->hwts_tx_en ? HWTSTAMP_TX_ON : HWTSTAMP_TX_OFF;\n\n\tswitch (port->hwts_rx_en) {\n\tcase 0:\n\t\tcfg.rx_filter = HWTSTAMP_FILTER_NONE;\n\t\tbreak;\n\tcase PTP_SLAVE_MODE:\n\t\tcfg.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_SYNC;\n\t\tbreak;\n\tcase PTP_MASTER_MODE:\n\t\tcfg.rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -ERANGE;\n\t}\n\n\treturn copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;\n}\n\nstatic int ixp4xx_mdio_cmd(struct mii_bus *bus, int phy_id, int location,\n\t\t\t   int write, u16 cmd)\n{\n\tint cycles = 0;\n\n\tif (__raw_readl(&mdio_regs->mdio_command[3]) & 0x80) {\n\t\tprintk(KERN_ERR \"%s: MII not ready to transmit\\n\", bus->name);\n\t\treturn -1;\n\t}\n\n\tif (write) {\n\t\t__raw_writel(cmd & 0xFF, &mdio_regs->mdio_command[0]);\n\t\t__raw_writel(cmd >> 8, &mdio_regs->mdio_command[1]);\n\t}\n\t__raw_writel(((phy_id << 5) | location) & 0xFF,\n\t\t     &mdio_regs->mdio_command[2]);\n\t__raw_writel((phy_id >> 3) | (write << 2) | 0x80  ,\n\t\t     &mdio_regs->mdio_command[3]);\n\n\twhile ((cycles < MAX_MDIO_RETRIES) &&\n\t       (__raw_readl(&mdio_regs->mdio_command[3]) & 0x80)) {\n\t\tudelay(1);\n\t\tcycles++;\n\t}\n\n\tif (cycles == MAX_MDIO_RETRIES) {\n\t\tprintk(KERN_ERR \"%s #%i: MII write failed\\n\", bus->name,\n\t\t       phy_id);\n\t\treturn -1;\n\t}\n\n#if DEBUG_MDIO\n\tprintk(KERN_DEBUG \"%s #%i: mdio_%s() took %i cycles\\n\", bus->name,\n\t       phy_id, write ? \"write\" : \"read\", cycles);\n#endif\n\n\tif (write)\n\t\treturn 0;\n\n\tif (__raw_readl(&mdio_regs->mdio_status[3]) & 0x80) {\n#if DEBUG_MDIO\n\t\tprintk(KERN_DEBUG \"%s #%i: MII read failed\\n\", bus->name,\n\t\t       phy_id);\n#endif\n\t\treturn 0xFFFF;  \n\t}\n\n\treturn (__raw_readl(&mdio_regs->mdio_status[0]) & 0xFF) |\n\t\t((__raw_readl(&mdio_regs->mdio_status[1]) & 0xFF) << 8);\n}\n\nstatic int ixp4xx_mdio_read(struct mii_bus *bus, int phy_id, int location)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&mdio_lock, flags);\n\tret = ixp4xx_mdio_cmd(bus, phy_id, location, 0, 0);\n\tspin_unlock_irqrestore(&mdio_lock, flags);\n#if DEBUG_MDIO\n\tprintk(KERN_DEBUG \"%s #%i: MII read [%i] -> 0x%X\\n\", bus->name,\n\t       phy_id, location, ret);\n#endif\n\treturn ret;\n}\n\nstatic int ixp4xx_mdio_write(struct mii_bus *bus, int phy_id, int location,\n\t\t\t     u16 val)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&mdio_lock, flags);\n\tret = ixp4xx_mdio_cmd(bus, phy_id, location, 1, val);\n\tspin_unlock_irqrestore(&mdio_lock, flags);\n#if DEBUG_MDIO\n\tprintk(KERN_DEBUG \"%s #%i: MII write [%i] <- 0x%X, err = %i\\n\",\n\t       bus->name, phy_id, location, val, ret);\n#endif\n\treturn ret;\n}\n\nstatic int ixp4xx_mdio_register(struct eth_regs __iomem *regs)\n{\n\tint err;\n\n\tif (!(mdio_bus = mdiobus_alloc()))\n\t\treturn -ENOMEM;\n\n\tmdio_regs = regs;\n\t__raw_writel(DEFAULT_CORE_CNTRL, &mdio_regs->core_control);\n\tmdio_bus->name = \"IXP4xx MII Bus\";\n\tmdio_bus->read = &ixp4xx_mdio_read;\n\tmdio_bus->write = &ixp4xx_mdio_write;\n\tsnprintf(mdio_bus->id, MII_BUS_ID_SIZE, \"ixp4xx-eth-0\");\n\n\terr = of_mdiobus_register(mdio_bus, mdio_bus_np);\n\tif (err)\n\t\tmdiobus_free(mdio_bus);\n\treturn err;\n}\n\nstatic void ixp4xx_mdio_remove(void)\n{\n\tmdiobus_unregister(mdio_bus);\n\tmdiobus_free(mdio_bus);\n}\n\n\nstatic void ixp4xx_adjust_link(struct net_device *dev)\n{\n\tstruct port *port = netdev_priv(dev);\n\tstruct phy_device *phydev = dev->phydev;\n\n\tif (!phydev->link) {\n\t\tif (port->speed) {\n\t\t\tport->speed = 0;\n\t\t\tprintk(KERN_INFO \"%s: link down\\n\", dev->name);\n\t\t}\n\t\treturn;\n\t}\n\n\tif (port->speed == phydev->speed && port->duplex == phydev->duplex)\n\t\treturn;\n\n\tport->speed = phydev->speed;\n\tport->duplex = phydev->duplex;\n\n\tif (port->duplex)\n\t\t__raw_writel(DEFAULT_TX_CNTRL0 & ~TX_CNTRL0_HALFDUPLEX,\n\t\t\t     &port->regs->tx_control[0]);\n\telse\n\t\t__raw_writel(DEFAULT_TX_CNTRL0 | TX_CNTRL0_HALFDUPLEX,\n\t\t\t     &port->regs->tx_control[0]);\n\n\tnetdev_info(dev, \"%s: link up, speed %u Mb/s, %s duplex\\n\",\n\t\t    dev->name, port->speed, port->duplex ? \"full\" : \"half\");\n}\n\n\nstatic inline void debug_pkt(struct net_device *dev, const char *func,\n\t\t\t     u8 *data, int len)\n{\n#if DEBUG_PKT_BYTES\n\tint i;\n\n\tnetdev_debug(dev, \"%s(%i) \", func, len);\n\tfor (i = 0; i < len; i++) {\n\t\tif (i >= DEBUG_PKT_BYTES)\n\t\t\tbreak;\n\t\tprintk(\"%s%02X\",\n\t\t       ((i == 6) || (i == 12) || (i >= 14)) ? \" \" : \"\",\n\t\t       data[i]);\n\t}\n\tprintk(\"\\n\");\n#endif\n}\n\n\nstatic inline void debug_desc(u32 phys, struct desc *desc)\n{\n#if DEBUG_DESC\n\tprintk(KERN_DEBUG \"%X: %X %3X %3X %08X %2X < %2X %4X %X\"\n\t       \" %X %X %02X%02X%02X%02X%02X%02X < %02X%02X%02X%02X%02X%02X\\n\",\n\t       phys, desc->next, desc->buf_len, desc->pkt_len,\n\t       desc->data, desc->dest_id, desc->src_id, desc->flags,\n\t       desc->qos, desc->padlen, desc->vlan_tci,\n\t       desc->dst_mac_0, desc->dst_mac_1, desc->dst_mac_2,\n\t       desc->dst_mac_3, desc->dst_mac_4, desc->dst_mac_5,\n\t       desc->src_mac_0, desc->src_mac_1, desc->src_mac_2,\n\t       desc->src_mac_3, desc->src_mac_4, desc->src_mac_5);\n#endif\n}\n\nstatic inline int queue_get_desc(unsigned int queue, struct port *port,\n\t\t\t\t int is_tx)\n{\n\tu32 phys, tab_phys, n_desc;\n\tstruct desc *tab;\n\n\tif (!(phys = qmgr_get_entry(queue)))\n\t\treturn -1;\n\n\tphys &= ~0x1F;  \n\ttab_phys = is_tx ? tx_desc_phys(port, 0) : rx_desc_phys(port, 0);\n\ttab = is_tx ? tx_desc_ptr(port, 0) : rx_desc_ptr(port, 0);\n\tn_desc = (phys - tab_phys) / sizeof(struct desc);\n\tBUG_ON(n_desc >= (is_tx ? TX_DESCS : RX_DESCS));\n\tdebug_desc(phys, &tab[n_desc]);\n\tBUG_ON(tab[n_desc].next);\n\treturn n_desc;\n}\n\nstatic inline void queue_put_desc(unsigned int queue, u32 phys,\n\t\t\t\t  struct desc *desc)\n{\n\tdebug_desc(phys, desc);\n\tBUG_ON(phys & 0x1F);\n\tqmgr_put_entry(queue, phys);\n\t \n}\n\n\nstatic inline void dma_unmap_tx(struct port *port, struct desc *desc)\n{\n#ifdef __ARMEB__\n\tdma_unmap_single(&port->netdev->dev, desc->data,\n\t\t\t desc->buf_len, DMA_TO_DEVICE);\n#else\n\tdma_unmap_single(&port->netdev->dev, desc->data & ~3,\n\t\t\t ALIGN((desc->data & 3) + desc->buf_len, 4),\n\t\t\t DMA_TO_DEVICE);\n#endif\n}\n\n\nstatic void eth_rx_irq(void *pdev)\n{\n\tstruct net_device *dev = pdev;\n\tstruct port *port = netdev_priv(dev);\n\n#if DEBUG_RX\n\tprintk(KERN_DEBUG \"%s: eth_rx_irq\\n\", dev->name);\n#endif\n\tqmgr_disable_irq(port->plat->rxq);\n\tnapi_schedule(&port->napi);\n}\n\nstatic int eth_poll(struct napi_struct *napi, int budget)\n{\n\tstruct port *port = container_of(napi, struct port, napi);\n\tstruct net_device *dev = port->netdev;\n\tunsigned int rxq = port->plat->rxq, rxfreeq = RXFREE_QUEUE(port->id);\n\tint received = 0;\n\n#if DEBUG_RX\n\tnetdev_debug(dev, \"eth_poll\\n\");\n#endif\n\n\twhile (received < budget) {\n\t\tstruct sk_buff *skb;\n\t\tstruct desc *desc;\n\t\tint n;\n#ifdef __ARMEB__\n\t\tstruct sk_buff *temp;\n\t\tu32 phys;\n#endif\n\n\t\tif ((n = queue_get_desc(rxq, port, 0)) < 0) {\n#if DEBUG_RX\n\t\t\tnetdev_debug(dev, \"eth_poll napi_complete\\n\");\n#endif\n\t\t\tnapi_complete(napi);\n\t\t\tqmgr_enable_irq(rxq);\n\t\t\tif (!qmgr_stat_below_low_watermark(rxq) &&\n\t\t\t    napi_reschedule(napi)) {  \n#if DEBUG_RX\n\t\t\t\tnetdev_debug(dev, \"eth_poll napi_reschedule succeeded\\n\");\n#endif\n\t\t\t\tqmgr_disable_irq(rxq);\n\t\t\t\tcontinue;\n\t\t\t}\n#if DEBUG_RX\n\t\t\tnetdev_debug(dev, \"eth_poll all done\\n\");\n#endif\n\t\t\treturn received;  \n\t\t}\n\n\t\tdesc = rx_desc_ptr(port, n);\n\n#ifdef __ARMEB__\n\t\tif ((skb = netdev_alloc_skb(dev, RX_BUFF_SIZE))) {\n\t\t\tphys = dma_map_single(&dev->dev, skb->data,\n\t\t\t\t\t      RX_BUFF_SIZE, DMA_FROM_DEVICE);\n\t\t\tif (dma_mapping_error(&dev->dev, phys)) {\n\t\t\t\tdev_kfree_skb(skb);\n\t\t\t\tskb = NULL;\n\t\t\t}\n\t\t}\n#else\n\t\tskb = netdev_alloc_skb(dev,\n\t\t\t\t       ALIGN(NET_IP_ALIGN + desc->pkt_len, 4));\n#endif\n\n\t\tif (!skb) {\n\t\t\tdev->stats.rx_dropped++;\n\t\t\t \n\t\t\tdesc->buf_len = MAX_MRU;\n\t\t\tdesc->pkt_len = 0;\n\t\t\tqueue_put_desc(rxfreeq, rx_desc_phys(port, n), desc);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n#ifdef __ARMEB__\n\t\ttemp = skb;\n\t\tskb = port->rx_buff_tab[n];\n\t\tdma_unmap_single(&dev->dev, desc->data - NET_IP_ALIGN,\n\t\t\t\t RX_BUFF_SIZE, DMA_FROM_DEVICE);\n#else\n\t\tdma_sync_single_for_cpu(&dev->dev, desc->data - NET_IP_ALIGN,\n\t\t\t\t\tRX_BUFF_SIZE, DMA_FROM_DEVICE);\n\t\tmemcpy_swab32((u32 *)skb->data, (u32 *)port->rx_buff_tab[n],\n\t\t\t      ALIGN(NET_IP_ALIGN + desc->pkt_len, 4) / 4);\n#endif\n\t\tskb_reserve(skb, NET_IP_ALIGN);\n\t\tskb_put(skb, desc->pkt_len);\n\n\t\tdebug_pkt(dev, \"eth_poll\", skb->data, skb->len);\n\n\t\tixp_rx_timestamp(port, skb);\n\t\tskb->protocol = eth_type_trans(skb, dev);\n\t\tdev->stats.rx_packets++;\n\t\tdev->stats.rx_bytes += skb->len;\n\t\tnetif_receive_skb(skb);\n\n\t\t \n#ifdef __ARMEB__\n\t\tport->rx_buff_tab[n] = temp;\n\t\tdesc->data = phys + NET_IP_ALIGN;\n#endif\n\t\tdesc->buf_len = MAX_MRU;\n\t\tdesc->pkt_len = 0;\n\t\tqueue_put_desc(rxfreeq, rx_desc_phys(port, n), desc);\n\t\treceived++;\n\t}\n\n#if DEBUG_RX\n\tnetdev_debug(dev, \"eth_poll(): end, not all work done\\n\");\n#endif\n\treturn received;\t\t \n}\n\n\nstatic void eth_txdone_irq(void *unused)\n{\n\tu32 phys;\n\n#if DEBUG_TX\n\tprintk(KERN_DEBUG DRV_NAME \": eth_txdone_irq\\n\");\n#endif\n\twhile ((phys = qmgr_get_entry(TXDONE_QUEUE)) != 0) {\n\t\tu32 npe_id, n_desc;\n\t\tstruct port *port;\n\t\tstruct desc *desc;\n\t\tint start;\n\n\t\tnpe_id = phys & 3;\n\t\tBUG_ON(npe_id >= MAX_NPES);\n\t\tport = npe_port_tab[npe_id];\n\t\tBUG_ON(!port);\n\t\tphys &= ~0x1F;  \n\t\tn_desc = (phys - tx_desc_phys(port, 0)) / sizeof(struct desc);\n\t\tBUG_ON(n_desc >= TX_DESCS);\n\t\tdesc = tx_desc_ptr(port, n_desc);\n\t\tdebug_desc(phys, desc);\n\n\t\tif (port->tx_buff_tab[n_desc]) {  \n\t\t\tport->netdev->stats.tx_packets++;\n\t\t\tport->netdev->stats.tx_bytes += desc->pkt_len;\n\n\t\t\tdma_unmap_tx(port, desc);\n#if DEBUG_TX\n\t\t\tprintk(KERN_DEBUG \"%s: eth_txdone_irq free %p\\n\",\n\t\t\t       port->netdev->name, port->tx_buff_tab[n_desc]);\n#endif\n\t\t\tfree_buffer_irq(port->tx_buff_tab[n_desc]);\n\t\t\tport->tx_buff_tab[n_desc] = NULL;\n\t\t}\n\n\t\tstart = qmgr_stat_below_low_watermark(port->plat->txreadyq);\n\t\tqueue_put_desc(port->plat->txreadyq, phys, desc);\n\t\tif (start) {  \n#if DEBUG_TX\n\t\t\tprintk(KERN_DEBUG \"%s: eth_txdone_irq xmit ready\\n\",\n\t\t\t       port->netdev->name);\n#endif\n\t\t\tnetif_wake_queue(port->netdev);\n\t\t}\n\t}\n}\n\nstatic netdev_tx_t eth_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct port *port = netdev_priv(dev);\n\tunsigned int txreadyq = port->plat->txreadyq;\n\tint len, offset, bytes, n;\n\tvoid *mem;\n\tu32 phys;\n\tstruct desc *desc;\n\n#if DEBUG_TX\n\tnetdev_debug(dev, \"eth_xmit\\n\");\n#endif\n\n\tif (unlikely(skb->len > MAX_MRU)) {\n\t\tdev_kfree_skb(skb);\n\t\tdev->stats.tx_errors++;\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tdebug_pkt(dev, \"eth_xmit\", skb->data, skb->len);\n\n\tlen = skb->len;\n#ifdef __ARMEB__\n\toffset = 0;  \n\tbytes = len;\n\tmem = skb->data;\n#else\n\toffset = (uintptr_t)skb->data & 3;  \n\tbytes = ALIGN(offset + len, 4);\n\tif (!(mem = kmalloc(bytes, GFP_ATOMIC))) {\n\t\tdev_kfree_skb(skb);\n\t\tdev->stats.tx_dropped++;\n\t\treturn NETDEV_TX_OK;\n\t}\n\tmemcpy_swab32(mem, (u32 *)((uintptr_t)skb->data & ~3), bytes / 4);\n#endif\n\n\tphys = dma_map_single(&dev->dev, mem, bytes, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&dev->dev, phys)) {\n\t\tdev_kfree_skb(skb);\n#ifndef __ARMEB__\n\t\tkfree(mem);\n#endif\n\t\tdev->stats.tx_dropped++;\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tn = queue_get_desc(txreadyq, port, 1);\n\tBUG_ON(n < 0);\n\tdesc = tx_desc_ptr(port, n);\n\n#ifdef __ARMEB__\n\tport->tx_buff_tab[n] = skb;\n#else\n\tport->tx_buff_tab[n] = mem;\n#endif\n\tdesc->data = phys + offset;\n\tdesc->buf_len = desc->pkt_len = len;\n\n\t \n\twmb();\n\tqueue_put_desc(TX_QUEUE(port->id), tx_desc_phys(port, n), desc);\n\n\tif (qmgr_stat_below_low_watermark(txreadyq)) {  \n#if DEBUG_TX\n\t\tnetdev_debug(dev, \"eth_xmit queue full\\n\");\n#endif\n\t\tnetif_stop_queue(dev);\n\t\t \n\t\t \n\t\tif (!qmgr_stat_below_low_watermark(txreadyq)) {\n#if DEBUG_TX\n\t\t\tnetdev_debug(dev, \"eth_xmit ready again\\n\");\n#endif\n\t\t\tnetif_wake_queue(dev);\n\t\t}\n\t}\n\n#if DEBUG_TX\n\tnetdev_debug(dev, \"eth_xmit end\\n\");\n#endif\n\n\tixp_tx_timestamp(port, skb);\n\tskb_tx_timestamp(skb);\n\n#ifndef __ARMEB__\n\tdev_kfree_skb(skb);\n#endif\n\treturn NETDEV_TX_OK;\n}\n\n\nstatic void eth_set_mcast_list(struct net_device *dev)\n{\n\tstruct port *port = netdev_priv(dev);\n\tstruct netdev_hw_addr *ha;\n\tu8 diffs[ETH_ALEN], *addr;\n\tint i;\n\tstatic const u8 allmulti[] = { 0x01, 0x00, 0x00, 0x00, 0x00, 0x00 };\n\n\tif ((dev->flags & IFF_ALLMULTI) && !(dev->flags & IFF_PROMISC)) {\n\t\tfor (i = 0; i < ETH_ALEN; i++) {\n\t\t\t__raw_writel(allmulti[i], &port->regs->mcast_addr[i]);\n\t\t\t__raw_writel(allmulti[i], &port->regs->mcast_mask[i]);\n\t\t}\n\t\t__raw_writel(DEFAULT_RX_CNTRL0 | RX_CNTRL0_ADDR_FLTR_EN,\n\t\t\t&port->regs->rx_control[0]);\n\t\treturn;\n\t}\n\n\tif ((dev->flags & IFF_PROMISC) || netdev_mc_empty(dev)) {\n\t\t__raw_writel(DEFAULT_RX_CNTRL0 & ~RX_CNTRL0_ADDR_FLTR_EN,\n\t\t\t     &port->regs->rx_control[0]);\n\t\treturn;\n\t}\n\n\teth_zero_addr(diffs);\n\n\taddr = NULL;\n\tnetdev_for_each_mc_addr(ha, dev) {\n\t\tif (!addr)\n\t\t\taddr = ha->addr;  \n\t\tfor (i = 0; i < ETH_ALEN; i++)\n\t\t\tdiffs[i] |= addr[i] ^ ha->addr[i];\n\t}\n\n\tfor (i = 0; i < ETH_ALEN; i++) {\n\t\t__raw_writel(addr[i], &port->regs->mcast_addr[i]);\n\t\t__raw_writel(~diffs[i], &port->regs->mcast_mask[i]);\n\t}\n\n\t__raw_writel(DEFAULT_RX_CNTRL0 | RX_CNTRL0_ADDR_FLTR_EN,\n\t\t     &port->regs->rx_control[0]);\n}\n\n\nstatic int eth_ioctl(struct net_device *dev, struct ifreq *req, int cmd)\n{\n\tif (!netif_running(dev))\n\t\treturn -EINVAL;\n\n\tif (cpu_is_ixp46x()) {\n\t\tif (cmd == SIOCSHWTSTAMP)\n\t\t\treturn hwtstamp_set(dev, req);\n\t\tif (cmd == SIOCGHWTSTAMP)\n\t\t\treturn hwtstamp_get(dev, req);\n\t}\n\n\treturn phy_mii_ioctl(dev->phydev, req, cmd);\n}\n\n \n\nstatic void ixp4xx_get_drvinfo(struct net_device *dev,\n\t\t\t       struct ethtool_drvinfo *info)\n{\n\tstruct port *port = netdev_priv(dev);\n\n\tstrscpy(info->driver, DRV_NAME, sizeof(info->driver));\n\tsnprintf(info->fw_version, sizeof(info->fw_version), \"%u:%u:%u:%u\",\n\t\t port->firmware[0], port->firmware[1],\n\t\t port->firmware[2], port->firmware[3]);\n\tstrscpy(info->bus_info, \"internal\", sizeof(info->bus_info));\n}\n\nstatic int ixp4xx_get_ts_info(struct net_device *dev,\n\t\t\t      struct ethtool_ts_info *info)\n{\n\tstruct port *port = netdev_priv(dev);\n\n\tif (port->phc_index < 0)\n\t\tixp46x_ptp_find(&port->timesync_regs, &port->phc_index);\n\n\tinfo->phc_index = port->phc_index;\n\n\tif (info->phc_index < 0) {\n\t\tinfo->so_timestamping =\n\t\t\tSOF_TIMESTAMPING_TX_SOFTWARE |\n\t\t\tSOF_TIMESTAMPING_RX_SOFTWARE |\n\t\t\tSOF_TIMESTAMPING_SOFTWARE;\n\t\treturn 0;\n\t}\n\tinfo->so_timestamping =\n\t\tSOF_TIMESTAMPING_TX_HARDWARE |\n\t\tSOF_TIMESTAMPING_RX_HARDWARE |\n\t\tSOF_TIMESTAMPING_RAW_HARDWARE;\n\tinfo->tx_types =\n\t\t(1 << HWTSTAMP_TX_OFF) |\n\t\t(1 << HWTSTAMP_TX_ON);\n\tinfo->rx_filters =\n\t\t(1 << HWTSTAMP_FILTER_NONE) |\n\t\t(1 << HWTSTAMP_FILTER_PTP_V1_L4_SYNC) |\n\t\t(1 << HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ);\n\treturn 0;\n}\n\nstatic const struct ethtool_ops ixp4xx_ethtool_ops = {\n\t.get_drvinfo = ixp4xx_get_drvinfo,\n\t.nway_reset = phy_ethtool_nway_reset,\n\t.get_link = ethtool_op_get_link,\n\t.get_ts_info = ixp4xx_get_ts_info,\n\t.get_link_ksettings = phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings = phy_ethtool_set_link_ksettings,\n};\n\n\nstatic int request_queues(struct port *port)\n{\n\tint err;\n\n\terr = qmgr_request_queue(RXFREE_QUEUE(port->id), RX_DESCS, 0, 0,\n\t\t\t\t \"%s:RX-free\", port->netdev->name);\n\tif (err)\n\t\treturn err;\n\n\terr = qmgr_request_queue(port->plat->rxq, RX_DESCS, 0, 0,\n\t\t\t\t \"%s:RX\", port->netdev->name);\n\tif (err)\n\t\tgoto rel_rxfree;\n\n\terr = qmgr_request_queue(TX_QUEUE(port->id), TX_DESCS, 0, 0,\n\t\t\t\t \"%s:TX\", port->netdev->name);\n\tif (err)\n\t\tgoto rel_rx;\n\n\terr = qmgr_request_queue(port->plat->txreadyq, TX_DESCS, 0, 0,\n\t\t\t\t \"%s:TX-ready\", port->netdev->name);\n\tif (err)\n\t\tgoto rel_tx;\n\n\t \n\tif (!ports_open) {\n\t\terr = qmgr_request_queue(TXDONE_QUEUE, TXDONE_QUEUE_LEN, 0, 0,\n\t\t\t\t\t \"%s:TX-done\", DRV_NAME);\n\t\tif (err)\n\t\t\tgoto rel_txready;\n\t}\n\treturn 0;\n\nrel_txready:\n\tqmgr_release_queue(port->plat->txreadyq);\nrel_tx:\n\tqmgr_release_queue(TX_QUEUE(port->id));\nrel_rx:\n\tqmgr_release_queue(port->plat->rxq);\nrel_rxfree:\n\tqmgr_release_queue(RXFREE_QUEUE(port->id));\n\tprintk(KERN_DEBUG \"%s: unable to request hardware queues\\n\",\n\t       port->netdev->name);\n\treturn err;\n}\n\nstatic void release_queues(struct port *port)\n{\n\tqmgr_release_queue(RXFREE_QUEUE(port->id));\n\tqmgr_release_queue(port->plat->rxq);\n\tqmgr_release_queue(TX_QUEUE(port->id));\n\tqmgr_release_queue(port->plat->txreadyq);\n\n\tif (!ports_open)\n\t\tqmgr_release_queue(TXDONE_QUEUE);\n}\n\nstatic int init_queues(struct port *port)\n{\n\tint i;\n\n\tif (!ports_open) {\n\t\tdma_pool = dma_pool_create(DRV_NAME, &port->netdev->dev,\n\t\t\t\t\t   POOL_ALLOC_SIZE, 32, 0);\n\t\tif (!dma_pool)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tport->desc_tab = dma_pool_zalloc(dma_pool, GFP_KERNEL, &port->desc_tab_phys);\n\tif (!port->desc_tab)\n\t\treturn -ENOMEM;\n\tmemset(port->rx_buff_tab, 0, sizeof(port->rx_buff_tab));  \n\tmemset(port->tx_buff_tab, 0, sizeof(port->tx_buff_tab));\n\n\t \n\tfor (i = 0; i < RX_DESCS; i++) {\n\t\tstruct desc *desc = rx_desc_ptr(port, i);\n\t\tbuffer_t *buff;  \n\t\tvoid *data;\n#ifdef __ARMEB__\n\t\tif (!(buff = netdev_alloc_skb(port->netdev, RX_BUFF_SIZE)))\n\t\t\treturn -ENOMEM;\n\t\tdata = buff->data;\n#else\n\t\tif (!(buff = kmalloc(RX_BUFF_SIZE, GFP_KERNEL)))\n\t\t\treturn -ENOMEM;\n\t\tdata = buff;\n#endif\n\t\tdesc->buf_len = MAX_MRU;\n\t\tdesc->data = dma_map_single(&port->netdev->dev, data,\n\t\t\t\t\t    RX_BUFF_SIZE, DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(&port->netdev->dev, desc->data)) {\n\t\t\tfree_buffer(buff);\n\t\t\treturn -EIO;\n\t\t}\n\t\tdesc->data += NET_IP_ALIGN;\n\t\tport->rx_buff_tab[i] = buff;\n\t}\n\n\treturn 0;\n}\n\nstatic void destroy_queues(struct port *port)\n{\n\tint i;\n\n\tif (port->desc_tab) {\n\t\tfor (i = 0; i < RX_DESCS; i++) {\n\t\t\tstruct desc *desc = rx_desc_ptr(port, i);\n\t\t\tbuffer_t *buff = port->rx_buff_tab[i];\n\t\t\tif (buff) {\n\t\t\t\tdma_unmap_single(&port->netdev->dev,\n\t\t\t\t\t\t desc->data - NET_IP_ALIGN,\n\t\t\t\t\t\t RX_BUFF_SIZE, DMA_FROM_DEVICE);\n\t\t\t\tfree_buffer(buff);\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < TX_DESCS; i++) {\n\t\t\tstruct desc *desc = tx_desc_ptr(port, i);\n\t\t\tbuffer_t *buff = port->tx_buff_tab[i];\n\t\t\tif (buff) {\n\t\t\t\tdma_unmap_tx(port, desc);\n\t\t\t\tfree_buffer(buff);\n\t\t\t}\n\t\t}\n\t\tdma_pool_free(dma_pool, port->desc_tab, port->desc_tab_phys);\n\t\tport->desc_tab = NULL;\n\t}\n\n\tif (!ports_open && dma_pool) {\n\t\tdma_pool_destroy(dma_pool);\n\t\tdma_pool = NULL;\n\t}\n}\n\nstatic int eth_open(struct net_device *dev)\n{\n\tstruct port *port = netdev_priv(dev);\n\tstruct npe *npe = port->npe;\n\tstruct msg msg;\n\tint i, err;\n\n\tif (!npe_running(npe)) {\n\t\terr = npe_load_firmware(npe, npe_name(npe), &dev->dev);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (npe_recv_message(npe, &msg, \"ETH_GET_STATUS\")) {\n\t\t\tnetdev_err(dev, \"%s not responding\\n\", npe_name(npe));\n\t\t\treturn -EIO;\n\t\t}\n\t\tport->firmware[0] = msg.byte4;\n\t\tport->firmware[1] = msg.byte5;\n\t\tport->firmware[2] = msg.byte6;\n\t\tport->firmware[3] = msg.byte7;\n\t}\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = NPE_VLAN_SETRXQOSENTRY;\n\tmsg.eth_id = port->id;\n\tmsg.byte5 = port->plat->rxq | 0x80;\n\tmsg.byte7 = port->plat->rxq << 4;\n\tfor (i = 0; i < 8; i++) {\n\t\tmsg.byte3 = i;\n\t\tif (npe_send_recv_message(port->npe, &msg, \"ETH_SET_RXQ\"))\n\t\t\treturn -EIO;\n\t}\n\n\tmsg.cmd = NPE_EDB_SETPORTADDRESS;\n\tmsg.eth_id = PHYSICAL_ID(port->id);\n\tmsg.byte2 = dev->dev_addr[0];\n\tmsg.byte3 = dev->dev_addr[1];\n\tmsg.byte4 = dev->dev_addr[2];\n\tmsg.byte5 = dev->dev_addr[3];\n\tmsg.byte6 = dev->dev_addr[4];\n\tmsg.byte7 = dev->dev_addr[5];\n\tif (npe_send_recv_message(port->npe, &msg, \"ETH_SET_MAC\"))\n\t\treturn -EIO;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = NPE_FW_SETFIREWALLMODE;\n\tmsg.eth_id = port->id;\n\tif (npe_send_recv_message(port->npe, &msg, \"ETH_SET_FIREWALL_MODE\"))\n\t\treturn -EIO;\n\n\tif ((err = request_queues(port)) != 0)\n\t\treturn err;\n\n\tif ((err = init_queues(port)) != 0) {\n\t\tdestroy_queues(port);\n\t\trelease_queues(port);\n\t\treturn err;\n\t}\n\n\tport->speed = 0;\t \n\tphy_start(dev->phydev);\n\n\tfor (i = 0; i < ETH_ALEN; i++)\n\t\t__raw_writel(dev->dev_addr[i], &port->regs->hw_addr[i]);\n\t__raw_writel(0x08, &port->regs->random_seed);\n\t__raw_writel(0x12, &port->regs->partial_empty_threshold);\n\t__raw_writel(0x30, &port->regs->partial_full_threshold);\n\t__raw_writel(0x08, &port->regs->tx_start_bytes);\n\t__raw_writel(0x15, &port->regs->tx_deferral);\n\t__raw_writel(0x08, &port->regs->tx_2part_deferral[0]);\n\t__raw_writel(0x07, &port->regs->tx_2part_deferral[1]);\n\t__raw_writel(0x80, &port->regs->slot_time);\n\t__raw_writel(0x01, &port->regs->int_clock_threshold);\n\n\t \n\tfor (i = 0; i < TX_DESCS; i++)\n\t\tqueue_put_desc(port->plat->txreadyq,\n\t\t\t       tx_desc_phys(port, i), tx_desc_ptr(port, i));\n\n\tfor (i = 0; i < RX_DESCS; i++)\n\t\tqueue_put_desc(RXFREE_QUEUE(port->id),\n\t\t\t       rx_desc_phys(port, i), rx_desc_ptr(port, i));\n\n\t__raw_writel(TX_CNTRL1_RETRIES, &port->regs->tx_control[1]);\n\t__raw_writel(DEFAULT_TX_CNTRL0, &port->regs->tx_control[0]);\n\t__raw_writel(0, &port->regs->rx_control[1]);\n\t__raw_writel(DEFAULT_RX_CNTRL0, &port->regs->rx_control[0]);\n\n\tnapi_enable(&port->napi);\n\teth_set_mcast_list(dev);\n\tnetif_start_queue(dev);\n\n\tqmgr_set_irq(port->plat->rxq, QUEUE_IRQ_SRC_NOT_EMPTY,\n\t\t     eth_rx_irq, dev);\n\tif (!ports_open) {\n\t\tqmgr_set_irq(TXDONE_QUEUE, QUEUE_IRQ_SRC_NOT_EMPTY,\n\t\t\t     eth_txdone_irq, NULL);\n\t\tqmgr_enable_irq(TXDONE_QUEUE);\n\t}\n\tports_open++;\n\t \n\tnapi_schedule(&port->napi);\n\treturn 0;\n}\n\nstatic int eth_close(struct net_device *dev)\n{\n\tstruct port *port = netdev_priv(dev);\n\tstruct msg msg;\n\tint buffs = RX_DESCS;  \n\tint i;\n\n\tports_open--;\n\tqmgr_disable_irq(port->plat->rxq);\n\tnapi_disable(&port->napi);\n\tnetif_stop_queue(dev);\n\n\twhile (queue_get_desc(RXFREE_QUEUE(port->id), port, 0) >= 0)\n\t\tbuffs--;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = NPE_SETLOOPBACK_MODE;\n\tmsg.eth_id = port->id;\n\tmsg.byte3 = 1;\n\tif (npe_send_recv_message(port->npe, &msg, \"ETH_ENABLE_LOOPBACK\"))\n\t\tnetdev_crit(dev, \"unable to enable loopback\\n\");\n\n\ti = 0;\n\tdo {\t\t\t \n\t\twhile (queue_get_desc(port->plat->rxq, port, 0) >= 0)\n\t\t\tbuffs--;\n\t\tif (!buffs)\n\t\t\tbreak;\n\t\tif (qmgr_stat_empty(TX_QUEUE(port->id))) {\n\t\t\t \n\t\t\tstruct desc *desc;\n\t\t\tu32 phys;\n\t\t\tint n = queue_get_desc(port->plat->txreadyq, port, 1);\n\t\t\tBUG_ON(n < 0);\n\t\t\tdesc = tx_desc_ptr(port, n);\n\t\t\tphys = tx_desc_phys(port, n);\n\t\t\tdesc->buf_len = desc->pkt_len = 1;\n\t\t\twmb();\n\t\t\tqueue_put_desc(TX_QUEUE(port->id), phys, desc);\n\t\t}\n\t\tudelay(1);\n\t} while (++i < MAX_CLOSE_WAIT);\n\n\tif (buffs)\n\t\tnetdev_crit(dev, \"unable to drain RX queue, %i buffer(s)\"\n\t\t\t    \" left in NPE\\n\", buffs);\n#if DEBUG_CLOSE\n\tif (!buffs)\n\t\tnetdev_debug(dev, \"draining RX queue took %i cycles\\n\", i);\n#endif\n\n\tbuffs = TX_DESCS;\n\twhile (queue_get_desc(TX_QUEUE(port->id), port, 1) >= 0)\n\t\tbuffs--;  \n\n\ti = 0;\n\tdo {\n\t\twhile (queue_get_desc(port->plat->txreadyq, port, 1) >= 0)\n\t\t\tbuffs--;\n\t\tif (!buffs)\n\t\t\tbreak;\n\t} while (++i < MAX_CLOSE_WAIT);\n\n\tif (buffs)\n\t\tnetdev_crit(dev, \"unable to drain TX queue, %i buffer(s) \"\n\t\t\t    \"left in NPE\\n\", buffs);\n#if DEBUG_CLOSE\n\tif (!buffs)\n\t\tnetdev_debug(dev, \"draining TX queues took %i cycles\\n\", i);\n#endif\n\n\tmsg.byte3 = 0;\n\tif (npe_send_recv_message(port->npe, &msg, \"ETH_DISABLE_LOOPBACK\"))\n\t\tnetdev_crit(dev, \"unable to disable loopback\\n\");\n\n\tphy_stop(dev->phydev);\n\n\tif (!ports_open)\n\t\tqmgr_disable_irq(TXDONE_QUEUE);\n\tdestroy_queues(port);\n\trelease_queues(port);\n\treturn 0;\n}\n\nstatic const struct net_device_ops ixp4xx_netdev_ops = {\n\t.ndo_open = eth_open,\n\t.ndo_stop = eth_close,\n\t.ndo_start_xmit = eth_xmit,\n\t.ndo_set_rx_mode = eth_set_mcast_list,\n\t.ndo_eth_ioctl = eth_ioctl,\n\t.ndo_set_mac_address = eth_mac_addr,\n\t.ndo_validate_addr = eth_validate_addr,\n};\n\nstatic struct eth_plat_info *ixp4xx_of_get_platdata(struct device *dev)\n{\n\tstruct device_node *np = dev->of_node;\n\tstruct of_phandle_args queue_spec;\n\tstruct of_phandle_args npe_spec;\n\tstruct device_node *mdio_np;\n\tstruct eth_plat_info *plat;\n\tu8 mac[ETH_ALEN];\n\tint ret;\n\n\tplat = devm_kzalloc(dev, sizeof(*plat), GFP_KERNEL);\n\tif (!plat)\n\t\treturn NULL;\n\n\tret = of_parse_phandle_with_fixed_args(np, \"intel,npe-handle\", 1, 0,\n\t\t\t\t\t       &npe_spec);\n\tif (ret) {\n\t\tdev_err(dev, \"no NPE engine specified\\n\");\n\t\treturn NULL;\n\t}\n\t \n\tplat->npe = (npe_spec.args[0] << 4);\n\n\t \n\tmdio_np = of_get_child_by_name(np, \"mdio\");\n\tif (mdio_np) {\n\t\tplat->has_mdio = true;\n\t\tmdio_bus_np = mdio_np;\n\t\t \n\t}\n\n\t \n\tret = of_parse_phandle_with_fixed_args(np, \"queue-rx\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (ret) {\n\t\tdev_err(dev, \"no rx queue phandle\\n\");\n\t\treturn NULL;\n\t}\n\tplat->rxq = queue_spec.args[0];\n\n\t \n\tret = of_parse_phandle_with_fixed_args(np, \"queue-txready\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (ret) {\n\t\tdev_err(dev, \"no txready queue phandle\\n\");\n\t\treturn NULL;\n\t}\n\tplat->txreadyq = queue_spec.args[0];\n\n\tret = of_get_mac_address(np, mac);\n\tif (!ret) {\n\t\tdev_info(dev, \"Setting macaddr from DT %pM\\n\", mac);\n\t\tmemcpy(plat->hwaddr, mac, ETH_ALEN);\n\t}\n\n\treturn plat;\n}\n\nstatic int ixp4xx_eth_probe(struct platform_device *pdev)\n{\n\tstruct phy_device *phydev = NULL;\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *np = dev->of_node;\n\tstruct eth_plat_info *plat;\n\tstruct net_device *ndev;\n\tstruct port *port;\n\tint err;\n\n\tplat = ixp4xx_of_get_platdata(dev);\n\tif (!plat)\n\t\treturn -ENODEV;\n\n\tif (!(ndev = devm_alloc_etherdev(dev, sizeof(struct port))))\n\t\treturn -ENOMEM;\n\n\tSET_NETDEV_DEV(ndev, dev);\n\tport = netdev_priv(ndev);\n\tport->netdev = ndev;\n\tport->id = plat->npe;\n\tport->phc_index = -1;\n\n\t \n\tport->regs = devm_platform_get_and_ioremap_resource(pdev, 0, NULL);\n\tif (IS_ERR(port->regs))\n\t\treturn PTR_ERR(port->regs);\n\n\t \n\tif (plat->has_mdio) {\n\t\terr = ixp4xx_mdio_register(port->regs);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"failed to register MDIO bus\\n\");\n\t\t\treturn err;\n\t\t}\n\t}\n\t \n\tif (!mdio_bus)\n\t\treturn -EPROBE_DEFER;\n\n\tndev->netdev_ops = &ixp4xx_netdev_ops;\n\tndev->ethtool_ops = &ixp4xx_ethtool_ops;\n\tndev->tx_queue_len = 100;\n\t \n\tndev->dev.dma_mask = dev->dma_mask;\n\tndev->dev.coherent_dma_mask = dev->coherent_dma_mask;\n\n\tnetif_napi_add_weight(ndev, &port->napi, eth_poll, NAPI_WEIGHT);\n\n\tif (!(port->npe = npe_request(NPE_ID(port->id))))\n\t\treturn -EIO;\n\n\tport->plat = plat;\n\tnpe_port_tab[NPE_ID(port->id)] = port;\n\tif (is_valid_ether_addr(plat->hwaddr))\n\t\teth_hw_addr_set(ndev, plat->hwaddr);\n\telse\n\t\teth_hw_addr_random(ndev);\n\n\tplatform_set_drvdata(pdev, ndev);\n\n\t__raw_writel(DEFAULT_CORE_CNTRL | CORE_RESET,\n\t\t     &port->regs->core_control);\n\tudelay(50);\n\t__raw_writel(DEFAULT_CORE_CNTRL, &port->regs->core_control);\n\tudelay(50);\n\n\tphydev = of_phy_get_and_connect(ndev, np, ixp4xx_adjust_link);\n\tif (!phydev) {\n\t\terr = -ENODEV;\n\t\tdev_err(dev, \"no phydev\\n\");\n\t\tgoto err_free_mem;\n\t}\n\n\tphydev->irq = PHY_POLL;\n\n\tif ((err = register_netdev(ndev)))\n\t\tgoto err_phy_dis;\n\n\tnetdev_info(ndev, \"%s: MII PHY %i on %s\\n\", ndev->name, plat->phy,\n\t\t    npe_name(port->npe));\n\n\treturn 0;\n\nerr_phy_dis:\n\tphy_disconnect(phydev);\nerr_free_mem:\n\tnpe_port_tab[NPE_ID(port->id)] = NULL;\n\tnpe_release(port->npe);\n\treturn err;\n}\n\nstatic int ixp4xx_eth_remove(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct phy_device *phydev = ndev->phydev;\n\tstruct port *port = netdev_priv(ndev);\n\n\tunregister_netdev(ndev);\n\tphy_disconnect(phydev);\n\tixp4xx_mdio_remove();\n\tnpe_port_tab[NPE_ID(port->id)] = NULL;\n\tnpe_release(port->npe);\n\treturn 0;\n}\n\nstatic const struct of_device_id ixp4xx_eth_of_match[] = {\n\t{\n\t\t.compatible = \"intel,ixp4xx-ethernet\",\n\t},\n\t{ },\n};\n\nstatic struct platform_driver ixp4xx_eth_driver = {\n\t.driver = {\n\t\t.name = DRV_NAME,\n\t\t.of_match_table = of_match_ptr(ixp4xx_eth_of_match),\n\t},\n\t.probe\t\t= ixp4xx_eth_probe,\n\t.remove\t\t= ixp4xx_eth_remove,\n};\nmodule_platform_driver(ixp4xx_eth_driver);\n\nMODULE_AUTHOR(\"Krzysztof Halasa\");\nMODULE_DESCRIPTION(\"Intel IXP4xx Ethernet driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS(\"platform:ixp4xx_eth\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}