{
  "module_name": "rmnet_map_data.c",
  "hash_id": "90f9d863cec0d7fdb6e0effe0380bf15cfa44cec5682beb0880541b77e69d35a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qualcomm/rmnet/rmnet_map_data.c",
  "human_readable_source": "\n \n\n#include <linux/netdevice.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <net/ip6_checksum.h>\n#include <linux/bitfield.h>\n#include \"rmnet_config.h\"\n#include \"rmnet_map.h\"\n#include \"rmnet_private.h\"\n#include \"rmnet_vnd.h\"\n\n#define RMNET_MAP_DEAGGR_SPACING  64\n#define RMNET_MAP_DEAGGR_HEADROOM (RMNET_MAP_DEAGGR_SPACING / 2)\n\nstatic __sum16 *rmnet_map_get_csum_field(unsigned char protocol,\n\t\t\t\t\t const void *txporthdr)\n{\n\tif (protocol == IPPROTO_TCP)\n\t\treturn &((struct tcphdr *)txporthdr)->check;\n\n\tif (protocol == IPPROTO_UDP)\n\t\treturn &((struct udphdr *)txporthdr)->check;\n\n\treturn NULL;\n}\n\nstatic int\nrmnet_map_ipv4_dl_csum_trailer(struct sk_buff *skb,\n\t\t\t       struct rmnet_map_dl_csum_trailer *csum_trailer,\n\t\t\t       struct rmnet_priv *priv)\n{\n\tstruct iphdr *ip4h = (struct iphdr *)skb->data;\n\tvoid *txporthdr = skb->data + ip4h->ihl * 4;\n\t__sum16 *csum_field, pseudo_csum;\n\t__sum16 ip_payload_csum;\n\n\t \n\tif (ip_fast_csum(ip4h, ip4h->ihl)) {\n\t\tpriv->stats.csum_ip4_header_bad++;\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (ip_is_fragment(ip4h)) {\n\t\tpriv->stats.csum_fragmented_pkt++;\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\t \n\tcsum_field = rmnet_map_get_csum_field(ip4h->protocol, txporthdr);\n\tif (!csum_field) {\n\t\tpriv->stats.csum_err_invalid_transport++;\n\t\treturn -EPROTONOSUPPORT;\n\t}\n\n\t \n\tif (!*csum_field && ip4h->protocol == IPPROTO_UDP) {\n\t\tpriv->stats.csum_skipped++;\n\t\treturn 0;\n\t}\n\n\t \n\tip_payload_csum = csum_trailer->csum_value;\n\n\tpseudo_csum = csum_tcpudp_magic(ip4h->saddr, ip4h->daddr,\n\t\t\t\t\tntohs(ip4h->tot_len) - ip4h->ihl * 4,\n\t\t\t\t\tip4h->protocol, 0);\n\n\t \n\tif (ip_payload_csum != (__sum16)~pseudo_csum) {\n\t\tpriv->stats.csum_validation_failed++;\n\t\treturn -EINVAL;\n\t}\n\n\tpriv->stats.csum_ok++;\n\treturn 0;\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic int\nrmnet_map_ipv6_dl_csum_trailer(struct sk_buff *skb,\n\t\t\t       struct rmnet_map_dl_csum_trailer *csum_trailer,\n\t\t\t       struct rmnet_priv *priv)\n{\n\tstruct ipv6hdr *ip6h = (struct ipv6hdr *)skb->data;\n\tvoid *txporthdr = skb->data + sizeof(*ip6h);\n\t__sum16 *csum_field, pseudo_csum;\n\t__sum16 ip6_payload_csum;\n\t__be16 ip_header_csum;\n\n\t \n\tcsum_field = rmnet_map_get_csum_field(ip6h->nexthdr, txporthdr);\n\tif (!csum_field) {\n\t\tpriv->stats.csum_err_invalid_transport++;\n\t\treturn -EPROTONOSUPPORT;\n\t}\n\n\t \n\tip_header_csum = (__force __be16)ip_fast_csum(ip6h, sizeof(*ip6h) / 4);\n\tip6_payload_csum = csum16_sub(csum_trailer->csum_value, ip_header_csum);\n\n\tpseudo_csum = csum_ipv6_magic(&ip6h->saddr, &ip6h->daddr,\n\t\t\t\t      ntohs(ip6h->payload_len),\n\t\t\t\t      ip6h->nexthdr, 0);\n\n\t \n\tif (ip6_payload_csum != (__sum16)~pseudo_csum) {\n\t\tpriv->stats.csum_validation_failed++;\n\t\treturn -EINVAL;\n\t}\n\n\tpriv->stats.csum_ok++;\n\treturn 0;\n}\n#else\nstatic int\nrmnet_map_ipv6_dl_csum_trailer(struct sk_buff *skb,\n\t\t\t       struct rmnet_map_dl_csum_trailer *csum_trailer,\n\t\t\t       struct rmnet_priv *priv)\n{\n\treturn 0;\n}\n#endif\n\nstatic void rmnet_map_complement_ipv4_txporthdr_csum_field(struct iphdr *ip4h)\n{\n\tvoid *txphdr;\n\tu16 *csum;\n\n\ttxphdr = (void *)ip4h + ip4h->ihl * 4;\n\n\tif (ip4h->protocol == IPPROTO_TCP || ip4h->protocol == IPPROTO_UDP) {\n\t\tcsum = (u16 *)rmnet_map_get_csum_field(ip4h->protocol, txphdr);\n\t\t*csum = ~(*csum);\n\t}\n}\n\nstatic void\nrmnet_map_ipv4_ul_csum_header(struct iphdr *iphdr,\n\t\t\t      struct rmnet_map_ul_csum_header *ul_header,\n\t\t\t      struct sk_buff *skb)\n{\n\tu16 val;\n\n\tval = MAP_CSUM_UL_ENABLED_FLAG;\n\tif (iphdr->protocol == IPPROTO_UDP)\n\t\tval |= MAP_CSUM_UL_UDP_FLAG;\n\tval |= skb->csum_offset & MAP_CSUM_UL_OFFSET_MASK;\n\n\tul_header->csum_start_offset = htons(skb_network_header_len(skb));\n\tul_header->csum_info = htons(val);\n\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\trmnet_map_complement_ipv4_txporthdr_csum_field(iphdr);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic void\nrmnet_map_complement_ipv6_txporthdr_csum_field(struct ipv6hdr *ip6h)\n{\n\tvoid *txphdr;\n\tu16 *csum;\n\n\ttxphdr = ip6h + 1;\n\n\tif (ip6h->nexthdr == IPPROTO_TCP || ip6h->nexthdr == IPPROTO_UDP) {\n\t\tcsum = (u16 *)rmnet_map_get_csum_field(ip6h->nexthdr, txphdr);\n\t\t*csum = ~(*csum);\n\t}\n}\n\nstatic void\nrmnet_map_ipv6_ul_csum_header(struct ipv6hdr *ipv6hdr,\n\t\t\t      struct rmnet_map_ul_csum_header *ul_header,\n\t\t\t      struct sk_buff *skb)\n{\n\tu16 val;\n\n\tval = MAP_CSUM_UL_ENABLED_FLAG;\n\tif (ipv6hdr->nexthdr == IPPROTO_UDP)\n\t\tval |= MAP_CSUM_UL_UDP_FLAG;\n\tval |= skb->csum_offset & MAP_CSUM_UL_OFFSET_MASK;\n\n\tul_header->csum_start_offset = htons(skb_network_header_len(skb));\n\tul_header->csum_info = htons(val);\n\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\trmnet_map_complement_ipv6_txporthdr_csum_field(ipv6hdr);\n}\n#else\nstatic void\nrmnet_map_ipv6_ul_csum_header(void *ip6hdr,\n\t\t\t      struct rmnet_map_ul_csum_header *ul_header,\n\t\t\t      struct sk_buff *skb)\n{\n}\n#endif\n\nstatic void rmnet_map_v5_checksum_uplink_packet(struct sk_buff *skb,\n\t\t\t\t\t\tstruct rmnet_port *port,\n\t\t\t\t\t\tstruct net_device *orig_dev)\n{\n\tstruct rmnet_priv *priv = netdev_priv(orig_dev);\n\tstruct rmnet_map_v5_csum_header *ul_header;\n\n\tul_header = skb_push(skb, sizeof(*ul_header));\n\tmemset(ul_header, 0, sizeof(*ul_header));\n\tul_header->header_info = u8_encode_bits(RMNET_MAP_HEADER_TYPE_CSUM_OFFLOAD,\n\t\t\t\t\t\tMAPV5_HDRINFO_HDR_TYPE_FMASK);\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tvoid *iph = ip_hdr(skb);\n\t\t__sum16 *check;\n\t\tvoid *trans;\n\t\tu8 proto;\n\n\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\tu16 ip_len = ((struct iphdr *)iph)->ihl * 4;\n\n\t\t\tproto = ((struct iphdr *)iph)->protocol;\n\t\t\ttrans = iph + ip_len;\n\t\t} else if (IS_ENABLED(CONFIG_IPV6) &&\n\t\t\t   skb->protocol == htons(ETH_P_IPV6)) {\n\t\t\tu16 ip_len = sizeof(struct ipv6hdr);\n\n\t\t\tproto = ((struct ipv6hdr *)iph)->nexthdr;\n\t\t\ttrans = iph + ip_len;\n\t\t} else {\n\t\t\tpriv->stats.csum_err_invalid_ip_version++;\n\t\t\tgoto sw_csum;\n\t\t}\n\n\t\tcheck = rmnet_map_get_csum_field(proto, trans);\n\t\tif (check) {\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t\t \n\t\t\tul_header->csum_info |= MAPV5_CSUMINFO_VALID_FLAG;\n\t\t\tpriv->stats.csum_hw++;\n\t\t\treturn;\n\t\t}\n\t}\n\nsw_csum:\n\tpriv->stats.csum_sw++;\n}\n\n \nstruct rmnet_map_header *rmnet_map_add_map_header(struct sk_buff *skb,\n\t\t\t\t\t\t  int hdrlen,\n\t\t\t\t\t\t  struct rmnet_port *port,\n\t\t\t\t\t\t  int pad)\n{\n\tstruct rmnet_map_header *map_header;\n\tu32 padding, map_datalen;\n\n\tmap_datalen = skb->len - hdrlen;\n\tmap_header = (struct rmnet_map_header *)\n\t\t\tskb_push(skb, sizeof(struct rmnet_map_header));\n\tmemset(map_header, 0, sizeof(struct rmnet_map_header));\n\n\t \n\tif (port->data_format & RMNET_FLAGS_EGRESS_MAP_CKSUMV5)\n\t\tmap_header->flags |= MAP_NEXT_HEADER_FLAG;\n\n\tif (pad == RMNET_MAP_NO_PAD_BYTES) {\n\t\tmap_header->pkt_len = htons(map_datalen);\n\t\treturn map_header;\n\t}\n\n\tBUILD_BUG_ON(MAP_PAD_LEN_MASK < 3);\n\tpadding = ALIGN(map_datalen, 4) - map_datalen;\n\n\tif (padding == 0)\n\t\tgoto done;\n\n\tif (skb_tailroom(skb) < padding)\n\t\treturn NULL;\n\n\tskb_put_zero(skb, padding);\n\ndone:\n\tmap_header->pkt_len = htons(map_datalen + padding);\n\t \n\tmap_header->flags = padding & MAP_PAD_LEN_MASK;\n\n\treturn map_header;\n}\n\n \nstruct sk_buff *rmnet_map_deaggregate(struct sk_buff *skb,\n\t\t\t\t      struct rmnet_port *port)\n{\n\tstruct rmnet_map_v5_csum_header *next_hdr = NULL;\n\tstruct rmnet_map_header *maph;\n\tvoid *data = skb->data;\n\tstruct sk_buff *skbn;\n\tu8 nexthdr_type;\n\tu32 packet_len;\n\n\tif (skb->len == 0)\n\t\treturn NULL;\n\n\tmaph = (struct rmnet_map_header *)skb->data;\n\tpacket_len = ntohs(maph->pkt_len) + sizeof(*maph);\n\n\tif (port->data_format & RMNET_FLAGS_INGRESS_MAP_CKSUMV4) {\n\t\tpacket_len += sizeof(struct rmnet_map_dl_csum_trailer);\n\t} else if (port->data_format & RMNET_FLAGS_INGRESS_MAP_CKSUMV5) {\n\t\tif (!(maph->flags & MAP_CMD_FLAG)) {\n\t\t\tpacket_len += sizeof(*next_hdr);\n\t\t\tif (maph->flags & MAP_NEXT_HEADER_FLAG)\n\t\t\t\tnext_hdr = data + sizeof(*maph);\n\t\t\telse\n\t\t\t\t \n\t\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tif (((int)skb->len - (int)packet_len) < 0)\n\t\treturn NULL;\n\n\t \n\tif (!maph->pkt_len)\n\t\treturn NULL;\n\n\tif (next_hdr) {\n\t\tnexthdr_type = u8_get_bits(next_hdr->header_info,\n\t\t\t\t\t   MAPV5_HDRINFO_HDR_TYPE_FMASK);\n\t\tif (nexthdr_type != RMNET_MAP_HEADER_TYPE_CSUM_OFFLOAD)\n\t\t\treturn NULL;\n\t}\n\n\tskbn = alloc_skb(packet_len + RMNET_MAP_DEAGGR_SPACING, GFP_ATOMIC);\n\tif (!skbn)\n\t\treturn NULL;\n\n\tskb_reserve(skbn, RMNET_MAP_DEAGGR_HEADROOM);\n\tskb_put(skbn, packet_len);\n\tmemcpy(skbn->data, skb->data, packet_len);\n\tskb_pull(skb, packet_len);\n\n\treturn skbn;\n}\n\n \nint rmnet_map_checksum_downlink_packet(struct sk_buff *skb, u16 len)\n{\n\tstruct rmnet_priv *priv = netdev_priv(skb->dev);\n\tstruct rmnet_map_dl_csum_trailer *csum_trailer;\n\n\tif (unlikely(!(skb->dev->features & NETIF_F_RXCSUM))) {\n\t\tpriv->stats.csum_sw++;\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tcsum_trailer = (struct rmnet_map_dl_csum_trailer *)(skb->data + len);\n\n\tif (!(csum_trailer->flags & MAP_CSUM_DL_VALID_FLAG)) {\n\t\tpriv->stats.csum_valid_unset++;\n\t\treturn -EINVAL;\n\t}\n\n\tif (skb->protocol == htons(ETH_P_IP))\n\t\treturn rmnet_map_ipv4_dl_csum_trailer(skb, csum_trailer, priv);\n\n\tif (IS_ENABLED(CONFIG_IPV6) && skb->protocol == htons(ETH_P_IPV6))\n\t\treturn rmnet_map_ipv6_dl_csum_trailer(skb, csum_trailer, priv);\n\n\tpriv->stats.csum_err_invalid_ip_version++;\n\n\treturn -EPROTONOSUPPORT;\n}\n\nstatic void rmnet_map_v4_checksum_uplink_packet(struct sk_buff *skb,\n\t\t\t\t\t\tstruct net_device *orig_dev)\n{\n\tstruct rmnet_priv *priv = netdev_priv(orig_dev);\n\tstruct rmnet_map_ul_csum_header *ul_header;\n\tvoid *iphdr;\n\n\tul_header = (struct rmnet_map_ul_csum_header *)\n\t\t    skb_push(skb, sizeof(struct rmnet_map_ul_csum_header));\n\n\tif (unlikely(!(orig_dev->features &\n\t\t     (NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM))))\n\t\tgoto sw_csum;\n\n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\tgoto sw_csum;\n\n\tiphdr = (char *)ul_header +\n\t\tsizeof(struct rmnet_map_ul_csum_header);\n\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\trmnet_map_ipv4_ul_csum_header(iphdr, ul_header, skb);\n\t\tpriv->stats.csum_hw++;\n\t\treturn;\n\t}\n\n\tif (IS_ENABLED(CONFIG_IPV6) && skb->protocol == htons(ETH_P_IPV6)) {\n\t\trmnet_map_ipv6_ul_csum_header(iphdr, ul_header, skb);\n\t\tpriv->stats.csum_hw++;\n\t\treturn;\n\t}\n\n\tpriv->stats.csum_err_invalid_ip_version++;\n\nsw_csum:\n\tmemset(ul_header, 0, sizeof(*ul_header));\n\n\tpriv->stats.csum_sw++;\n}\n\n \nvoid rmnet_map_checksum_uplink_packet(struct sk_buff *skb,\n\t\t\t\t      struct rmnet_port *port,\n\t\t\t\t      struct net_device *orig_dev,\n\t\t\t\t      int csum_type)\n{\n\tswitch (csum_type) {\n\tcase RMNET_FLAGS_EGRESS_MAP_CKSUMV4:\n\t\trmnet_map_v4_checksum_uplink_packet(skb, orig_dev);\n\t\tbreak;\n\tcase RMNET_FLAGS_EGRESS_MAP_CKSUMV5:\n\t\trmnet_map_v5_checksum_uplink_packet(skb, port, orig_dev);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nint rmnet_map_process_next_hdr_packet(struct sk_buff *skb,\n\t\t\t\t      u16 len)\n{\n\tstruct rmnet_priv *priv = netdev_priv(skb->dev);\n\tstruct rmnet_map_v5_csum_header *next_hdr;\n\tu8 nexthdr_type;\n\n\tnext_hdr = (struct rmnet_map_v5_csum_header *)(skb->data +\n\t\t\tsizeof(struct rmnet_map_header));\n\n\tnexthdr_type = u8_get_bits(next_hdr->header_info,\n\t\t\t\t   MAPV5_HDRINFO_HDR_TYPE_FMASK);\n\n\tif (nexthdr_type != RMNET_MAP_HEADER_TYPE_CSUM_OFFLOAD)\n\t\treturn -EINVAL;\n\n\tif (unlikely(!(skb->dev->features & NETIF_F_RXCSUM))) {\n\t\tpriv->stats.csum_sw++;\n\t} else if (next_hdr->csum_info & MAPV5_CSUMINFO_VALID_FLAG) {\n\t\tpriv->stats.csum_ok++;\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t} else {\n\t\tpriv->stats.csum_valid_unset++;\n\t}\n\n\t \n\tskb_pull(skb, sizeof(*next_hdr));\n\n\treturn 0;\n}\n\n#define RMNET_AGG_BYPASS_TIME_NSEC 10000000L\n\nstatic void reset_aggr_params(struct rmnet_port *port)\n{\n\tport->skbagg_head = NULL;\n\tport->agg_count = 0;\n\tport->agg_state = 0;\n\tmemset(&port->agg_time, 0, sizeof(struct timespec64));\n}\n\nstatic void rmnet_send_skb(struct rmnet_port *port, struct sk_buff *skb)\n{\n\tif (skb_needs_linearize(skb, port->dev->features)) {\n\t\tif (unlikely(__skb_linearize(skb))) {\n\t\t\tstruct rmnet_priv *priv;\n\n\t\t\tpriv = netdev_priv(port->rmnet_dev);\n\t\t\tthis_cpu_inc(priv->pcpu_stats->stats.tx_drops);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tdev_queue_xmit(skb);\n}\n\nstatic void rmnet_map_flush_tx_packet_work(struct work_struct *work)\n{\n\tstruct sk_buff *skb = NULL;\n\tstruct rmnet_port *port;\n\n\tport = container_of(work, struct rmnet_port, agg_wq);\n\n\tspin_lock_bh(&port->agg_lock);\n\tif (likely(port->agg_state == -EINPROGRESS)) {\n\t\t \n\t\tif (likely(port->skbagg_head)) {\n\t\t\tskb = port->skbagg_head;\n\t\t\treset_aggr_params(port);\n\t\t}\n\t\tport->agg_state = 0;\n\t}\n\n\tspin_unlock_bh(&port->agg_lock);\n\tif (skb)\n\t\trmnet_send_skb(port, skb);\n}\n\nstatic enum hrtimer_restart rmnet_map_flush_tx_packet_queue(struct hrtimer *t)\n{\n\tstruct rmnet_port *port;\n\n\tport = container_of(t, struct rmnet_port, hrtimer);\n\n\tschedule_work(&port->agg_wq);\n\n\treturn HRTIMER_NORESTART;\n}\n\nunsigned int rmnet_map_tx_aggregate(struct sk_buff *skb, struct rmnet_port *port,\n\t\t\t\t    struct net_device *orig_dev)\n{\n\tstruct timespec64 diff, last;\n\tunsigned int len = skb->len;\n\tstruct sk_buff *agg_skb;\n\tint size;\n\n\tspin_lock_bh(&port->agg_lock);\n\tmemcpy(&last, &port->agg_last, sizeof(struct timespec64));\n\tktime_get_real_ts64(&port->agg_last);\n\n\tif (!port->skbagg_head) {\n\t\t \nnew_packet:\n\t\tdiff = timespec64_sub(port->agg_last, last);\n\t\tsize = port->egress_agg_params.bytes - skb->len;\n\n\t\tif (size < 0) {\n\t\t\t \n\t\t\tspin_unlock_bh(&port->agg_lock);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (diff.tv_sec > 0 || diff.tv_nsec > RMNET_AGG_BYPASS_TIME_NSEC ||\n\t\t    size == 0)\n\t\t\tgoto no_aggr;\n\n\t\tport->skbagg_head = skb_copy_expand(skb, 0, size, GFP_ATOMIC);\n\t\tif (!port->skbagg_head)\n\t\t\tgoto no_aggr;\n\n\t\tdev_kfree_skb_any(skb);\n\t\tport->skbagg_head->protocol = htons(ETH_P_MAP);\n\t\tport->agg_count = 1;\n\t\tktime_get_real_ts64(&port->agg_time);\n\t\tskb_frag_list_init(port->skbagg_head);\n\t\tgoto schedule;\n\t}\n\tdiff = timespec64_sub(port->agg_last, port->agg_time);\n\tsize = port->egress_agg_params.bytes - port->skbagg_head->len;\n\n\tif (skb->len > size) {\n\t\tagg_skb = port->skbagg_head;\n\t\treset_aggr_params(port);\n\t\tspin_unlock_bh(&port->agg_lock);\n\t\thrtimer_cancel(&port->hrtimer);\n\t\trmnet_send_skb(port, agg_skb);\n\t\tspin_lock_bh(&port->agg_lock);\n\t\tgoto new_packet;\n\t}\n\n\tif (skb_has_frag_list(port->skbagg_head))\n\t\tport->skbagg_tail->next = skb;\n\telse\n\t\tskb_shinfo(port->skbagg_head)->frag_list = skb;\n\n\tport->skbagg_head->len += skb->len;\n\tport->skbagg_head->data_len += skb->len;\n\tport->skbagg_head->truesize += skb->truesize;\n\tport->skbagg_tail = skb;\n\tport->agg_count++;\n\n\tif (diff.tv_sec > 0 || diff.tv_nsec > port->egress_agg_params.time_nsec ||\n\t    port->agg_count >= port->egress_agg_params.count ||\n\t    port->skbagg_head->len == port->egress_agg_params.bytes) {\n\t\tagg_skb = port->skbagg_head;\n\t\treset_aggr_params(port);\n\t\tspin_unlock_bh(&port->agg_lock);\n\t\thrtimer_cancel(&port->hrtimer);\n\t\trmnet_send_skb(port, agg_skb);\n\t\treturn len;\n\t}\n\nschedule:\n\tif (!hrtimer_active(&port->hrtimer) && port->agg_state != -EINPROGRESS) {\n\t\tport->agg_state = -EINPROGRESS;\n\t\thrtimer_start(&port->hrtimer,\n\t\t\t      ns_to_ktime(port->egress_agg_params.time_nsec),\n\t\t\t      HRTIMER_MODE_REL);\n\t}\n\tspin_unlock_bh(&port->agg_lock);\n\n\treturn len;\n\nno_aggr:\n\tspin_unlock_bh(&port->agg_lock);\n\tskb->protocol = htons(ETH_P_MAP);\n\tdev_queue_xmit(skb);\n\n\treturn len;\n}\n\nvoid rmnet_map_update_ul_agg_config(struct rmnet_port *port, u32 size,\n\t\t\t\t    u32 count, u32 time)\n{\n\tspin_lock_bh(&port->agg_lock);\n\tport->egress_agg_params.bytes = size;\n\tWRITE_ONCE(port->egress_agg_params.count, count);\n\tport->egress_agg_params.time_nsec = time * NSEC_PER_USEC;\n\tspin_unlock_bh(&port->agg_lock);\n}\n\nvoid rmnet_map_tx_aggregate_init(struct rmnet_port *port)\n{\n\thrtimer_init(&port->hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tport->hrtimer.function = rmnet_map_flush_tx_packet_queue;\n\tspin_lock_init(&port->agg_lock);\n\trmnet_map_update_ul_agg_config(port, 4096, 1, 800);\n\tINIT_WORK(&port->agg_wq, rmnet_map_flush_tx_packet_work);\n}\n\nvoid rmnet_map_tx_aggregate_exit(struct rmnet_port *port)\n{\n\thrtimer_cancel(&port->hrtimer);\n\tcancel_work_sync(&port->agg_wq);\n\n\tspin_lock_bh(&port->agg_lock);\n\tif (port->agg_state == -EINPROGRESS) {\n\t\tif (port->skbagg_head) {\n\t\t\tdev_kfree_skb_any(port->skbagg_head);\n\t\t\treset_aggr_params(port);\n\t\t}\n\n\t\tport->agg_state = 0;\n\t}\n\tspin_unlock_bh(&port->agg_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}