{
  "module_name": "emac-mac.c",
  "hash_id": "377705d7e1420e414dcbfa53c6926389182049bb0f17353ca40bbbae8a589f0b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qualcomm/emac/emac-mac.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/tcp.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/crc32.h>\n#include <linux/if_vlan.h>\n#include <linux/jiffies.h>\n#include <linux/phy.h>\n#include <linux/of.h>\n#include <net/ip6_checksum.h>\n#include \"emac.h\"\n#include \"emac-sgmii.h\"\n\n \n#define SINGLE_PAUSE_MODE       \t0x10000000\n#define DEBUG_MODE                      0x08000000\n#define BROAD_EN                        0x04000000\n#define MULTI_ALL                       0x02000000\n#define RX_CHKSUM_EN                    0x01000000\n#define HUGE                            0x00800000\n#define SPEED(x)\t\t\t(((x) & 0x3) << 20)\n#define SPEED_MASK\t\t\tSPEED(0x3)\n#define SIMR                            0x00080000\n#define TPAUSE                          0x00010000\n#define PROM_MODE                       0x00008000\n#define VLAN_STRIP                      0x00004000\n#define PRLEN_BMSK                      0x00003c00\n#define PRLEN_SHFT                      10\n#define HUGEN                           0x00000200\n#define FLCHK                           0x00000100\n#define PCRCE                           0x00000080\n#define CRCE                            0x00000040\n#define FULLD                           0x00000020\n#define MAC_LP_EN                       0x00000010\n#define RXFC                            0x00000008\n#define TXFC                            0x00000004\n#define RXEN                            0x00000002\n#define TXEN                            0x00000001\n\n \n#define RFD_RING_SIZE_BMSK                                       0xfff\n\n \n#define RX_BUFFER_SIZE_BMSK                                     0xffff\n\n \n#define RRD_RING_SIZE_BMSK                                       0xfff\n\n \n#define TPD_RING_SIZE_BMSK                                      0xffff\n\n \n#define NUM_TXF_BURST_PREF_BMSK                             0xffff0000\n#define NUM_TXF_BURST_PREF_SHFT                                     16\n#define LS_8023_SP                                                0x80\n#define TXQ_MODE                                                  0x40\n#define TXQ_EN                                                    0x20\n#define IP_OP_SP                                                  0x10\n#define NUM_TPD_BURST_PREF_BMSK                                    0xf\n#define NUM_TPD_BURST_PREF_SHFT                                      0\n\n \n#define JUMBO_TASK_OFFLOAD_THRESHOLD_BMSK                        0x7ff\n\n \n#define TXF_HWM_BMSK                                         0xfff0000\n#define TXF_LWM_BMSK                                             0xfff\n\n \n#define RXQ_EN                                                 BIT(31)\n#define CUT_THRU_EN                                            BIT(30)\n#define RSS_HASH_EN                                            BIT(29)\n#define NUM_RFD_BURST_PREF_BMSK                              0x3f00000\n#define NUM_RFD_BURST_PREF_SHFT                                     20\n#define IDT_TABLE_SIZE_BMSK                                    0x1ff00\n#define IDT_TABLE_SIZE_SHFT                                          8\n#define SP_IPV6                                                   0x80\n\n \n#define JUMBO_1KAH_BMSK                                         0xf000\n#define JUMBO_1KAH_SHFT                                             12\n#define RFD_PREF_LOW_TH                                           0x10\n#define RFD_PREF_LOW_THRESHOLD_BMSK                              0xfc0\n#define RFD_PREF_LOW_THRESHOLD_SHFT                                  6\n#define RFD_PREF_UP_TH                                            0x10\n#define RFD_PREF_UP_THRESHOLD_BMSK                                0x3f\n#define RFD_PREF_UP_THRESHOLD_SHFT                                   0\n\n \n#define RXF_DOF_THRESFHOLD                                       0x1a0\n#define RXF_DOF_THRESHOLD_BMSK                               0xfff0000\n#define RXF_DOF_THRESHOLD_SHFT                                      16\n#define RXF_UOF_THRESFHOLD                                        0xbe\n#define RXF_UOF_THRESHOLD_BMSK                                   0xfff\n#define RXF_UOF_THRESHOLD_SHFT                                       0\n\n \n#define RXD_TIMER_BMSK                                      0xffff0000\n#define RXD_THRESHOLD_BMSK                                       0xfff\n#define RXD_THRESHOLD_SHFT                                           0\n\n \n#define DMAW_DLY_CNT_BMSK                                      0xf0000\n#define DMAW_DLY_CNT_SHFT                                           16\n#define DMAR_DLY_CNT_BMSK                                       0xf800\n#define DMAR_DLY_CNT_SHFT                                           11\n#define DMAR_REQ_PRI                                             0x400\n#define REGWRBLEN_BMSK                                           0x380\n#define REGWRBLEN_SHFT                                               7\n#define REGRDBLEN_BMSK                                            0x70\n#define REGRDBLEN_SHFT                                               4\n#define OUT_ORDER_MODE                                             0x4\n#define ENH_ORDER_MODE                                             0x2\n#define IN_ORDER_MODE                                              0x1\n\n \n#define RFD3_PROC_IDX_BMSK                                   0xfff0000\n#define RFD3_PROC_IDX_SHFT                                          16\n#define RFD3_PROD_IDX_BMSK                                       0xfff\n#define RFD3_PROD_IDX_SHFT                                           0\n\n \n#define NTPD_CONS_IDX_BMSK                                  0xffff0000\n#define NTPD_CONS_IDX_SHFT                                          16\n\n \n#define RFD0_CONS_IDX_BMSK                                       0xfff\n#define RFD0_CONS_IDX_SHFT                                           0\n\n \n#define H3TPD_PROD_IDX_BMSK                                 0xffff0000\n#define H3TPD_PROD_IDX_SHFT                                         16\n\n \n#define DATA_BYTE_SWAP                                             0x8\n#define MAX_BOUND                                                  0x2\n#define MAX_BTYPE                                                  0x1\n\n \n#define H3TPD_CONS_IDX_BMSK                                 0xffff0000\n#define H3TPD_CONS_IDX_SHFT                                         16\n\n \n#define H2TPD_PROD_IDX_BMSK                                     0xffff\n#define H2TPD_PROD_IDX_SHFT                                          0\n\n \n#define H1TPD_CONS_IDX_BMSK                                 0xffff0000\n#define H1TPD_CONS_IDX_SHFT                                         16\n#define H2TPD_CONS_IDX_BMSK                                     0xffff\n#define H2TPD_CONS_IDX_SHFT                                          0\n\n \n#define HEADER_CNT_EN                                              0x2\n#define HEADER_ENABLE                                              0x1\n\n \n#define RFD0_PROC_IDX_BMSK                                   0xfff0000\n#define RFD0_PROC_IDX_SHFT                                          16\n#define RFD0_PROD_IDX_BMSK                                       0xfff\n#define RFD0_PROD_IDX_SHFT                                           0\n\n \n#define RFD1_PROC_IDX_BMSK                                   0xfff0000\n#define RFD1_PROC_IDX_SHFT                                          16\n#define RFD1_PROD_IDX_BMSK                                       0xfff\n#define RFD1_PROD_IDX_SHFT                                           0\n\n \n#define RX_UNCPL_INT_EN                                            0x1\n\n \n#define RFD2_CONS_IDX_BMSK                                   0xfff0000\n#define RFD2_CONS_IDX_SHFT                                          16\n#define RFD1_CONS_IDX_BMSK                                       0xfff\n#define RFD1_CONS_IDX_SHFT                                           0\n\n \n#define RFD3_CONS_IDX_BMSK                                       0xfff\n#define RFD3_CONS_IDX_SHFT                                           0\n\n \n#define NTPD_PROD_IDX_BMSK                                      0xffff\n#define NTPD_PROD_IDX_SHFT                                           0\n\n \n#define H1TPD_PROD_IDX_BMSK                                     0xffff\n#define H1TPD_PROD_IDX_SHFT                                          0\n\n#define RXQ0_RSS_HSTYP_IPV6_TCP_EN                                0x20\n#define RXQ0_RSS_HSTYP_IPV6_EN                                    0x10\n#define RXQ0_RSS_HSTYP_IPV4_TCP_EN                                 0x8\n#define RXQ0_RSS_HSTYP_IPV4_EN                                     0x4\n\n \n#define EMAC_WRAPPER_TX_TS_EMPTY                               BIT(31)\n#define EMAC_WRAPPER_TX_TS_INX_BMSK                             0xffff\n\nstruct emac_skb_cb {\n\tu32           tpd_idx;\n\tunsigned long jiffies;\n};\n\n#define EMAC_SKB_CB(skb)\t((struct emac_skb_cb *)(skb)->cb)\n#define EMAC_RSS_IDT_SIZE\t256\n#define JUMBO_1KAH\t\t0x4\n#define RXD_TH\t\t\t0x100\n#define EMAC_TPD_LAST_FRAGMENT\t0x80000000\n#define EMAC_TPD_TSTAMP_SAVE\t0x80000000\n\n \n#define EMAC_RRD_L4F\t\tBIT(14)\n#define EMAC_RRD_IPF\t\tBIT(15)\n#define EMAC_RRD_CRC\t\tBIT(21)\n#define EMAC_RRD_FAE\t\tBIT(22)\n#define EMAC_RRD_TRN\t\tBIT(23)\n#define EMAC_RRD_RNT\t\tBIT(24)\n#define EMAC_RRD_INC\t\tBIT(25)\n#define EMAC_RRD_FOV\t\tBIT(29)\n#define EMAC_RRD_LEN\t\tBIT(30)\n\n \n#define EMAC_RRD_ERROR (EMAC_RRD_IPF | EMAC_RRD_CRC | EMAC_RRD_FAE | \\\n\t\t\tEMAC_RRD_TRN | EMAC_RRD_RNT | EMAC_RRD_INC | \\\n\t\t\tEMAC_RRD_FOV | EMAC_RRD_LEN)\n#define EMAC_RRD_STATS_DW_IDX 3\n\n#define EMAC_RRD(RXQ, SIZE, IDX)\t((RXQ)->rrd.v_addr + (SIZE * (IDX)))\n#define EMAC_RFD(RXQ, SIZE, IDX)\t((RXQ)->rfd.v_addr + (SIZE * (IDX)))\n#define EMAC_TPD(TXQ, SIZE, IDX)\t((TXQ)->tpd.v_addr + (SIZE * (IDX)))\n\n#define GET_RFD_BUFFER(RXQ, IDX)\t(&((RXQ)->rfd.rfbuff[(IDX)]))\n#define GET_TPD_BUFFER(RTQ, IDX)\t(&((RTQ)->tpd.tpbuff[(IDX)]))\n\n#define EMAC_TX_POLL_HWTXTSTAMP_THRESHOLD\t8\n\n#define ISR_RX_PKT      (\\\n\tRX_PKT_INT0     |\\\n\tRX_PKT_INT1     |\\\n\tRX_PKT_INT2     |\\\n\tRX_PKT_INT3)\n\nvoid emac_mac_multicast_addr_set(struct emac_adapter *adpt, u8 *addr)\n{\n\tu32 crc32, bit, reg, mta;\n\n\t \n\tcrc32 = ether_crc(ETH_ALEN, addr);\n\n\t \n\treg = (crc32 >> 31) & 0x1;\n\tbit = (crc32 >> 26) & 0x1F;\n\n\tmta = readl(adpt->base + EMAC_HASH_TAB_REG0 + (reg << 2));\n\tmta |= BIT(bit);\n\twritel(mta, adpt->base + EMAC_HASH_TAB_REG0 + (reg << 2));\n}\n\nvoid emac_mac_multicast_addr_clear(struct emac_adapter *adpt)\n{\n\twritel(0, adpt->base + EMAC_HASH_TAB_REG0);\n\twritel(0, adpt->base + EMAC_HASH_TAB_REG1);\n}\n\n \n#define EMAC_RSS_KEY(_i, _type) \\\n\t\t(EMAC_RSS_KEY0 + ((_i) * sizeof(_type)))\n#define EMAC_RSS_TBL(_i, _type) \\\n\t\t(EMAC_IDT_TABLE0 + ((_i) * sizeof(_type)))\n\n \nvoid emac_mac_mode_config(struct emac_adapter *adpt)\n{\n\tstruct net_device *netdev = adpt->netdev;\n\tu32 mac;\n\n\tmac = readl(adpt->base + EMAC_MAC_CTRL);\n\tmac &= ~(VLAN_STRIP | PROM_MODE | MULTI_ALL | MAC_LP_EN);\n\n\tif (netdev->features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\tmac |= VLAN_STRIP;\n\n\tif (netdev->flags & IFF_PROMISC)\n\t\tmac |= PROM_MODE;\n\n\tif (netdev->flags & IFF_ALLMULTI)\n\t\tmac |= MULTI_ALL;\n\n\twritel(mac, adpt->base + EMAC_MAC_CTRL);\n}\n\n \nstatic void emac_mac_dma_rings_config(struct emac_adapter *adpt)\n{\n\t \n\twritel(upper_32_bits(adpt->tx_q.tpd.dma_addr),\n\t       adpt->base + EMAC_DESC_CTRL_1);\n\n\twritel(lower_32_bits(adpt->tx_q.tpd.dma_addr),\n\t       adpt->base + EMAC_DESC_CTRL_8);\n\n\twritel(adpt->tx_q.tpd.count & TPD_RING_SIZE_BMSK,\n\t       adpt->base + EMAC_DESC_CTRL_9);\n\n\t \n\twritel(upper_32_bits(adpt->rx_q.rfd.dma_addr),\n\t       adpt->base + EMAC_DESC_CTRL_0);\n\n\twritel(lower_32_bits(adpt->rx_q.rfd.dma_addr),\n\t       adpt->base + EMAC_DESC_CTRL_2);\n\twritel(lower_32_bits(adpt->rx_q.rrd.dma_addr),\n\t       adpt->base + EMAC_DESC_CTRL_5);\n\n\twritel(adpt->rx_q.rfd.count & RFD_RING_SIZE_BMSK,\n\t       adpt->base + EMAC_DESC_CTRL_3);\n\twritel(adpt->rx_q.rrd.count & RRD_RING_SIZE_BMSK,\n\t       adpt->base + EMAC_DESC_CTRL_6);\n\n\twritel(adpt->rxbuf_size & RX_BUFFER_SIZE_BMSK,\n\t       adpt->base + EMAC_DESC_CTRL_4);\n\n\twritel(0, adpt->base + EMAC_DESC_CTRL_11);\n\n\t \n\twritel(1, adpt->base + EMAC_INTER_SRAM_PART9);\n}\n\n \nstatic void emac_mac_tx_config(struct emac_adapter *adpt)\n{\n\tu32 val;\n\n\twritel((EMAC_MAX_TX_OFFLOAD_THRESH >> 3) &\n\t       JUMBO_TASK_OFFLOAD_THRESHOLD_BMSK, adpt->base + EMAC_TXQ_CTRL_1);\n\n\tval = (adpt->tpd_burst << NUM_TPD_BURST_PREF_SHFT) &\n\t       NUM_TPD_BURST_PREF_BMSK;\n\n\tval |= TXQ_MODE | LS_8023_SP;\n\tval |= (0x0100 << NUM_TXF_BURST_PREF_SHFT) &\n\t\tNUM_TXF_BURST_PREF_BMSK;\n\n\twritel(val, adpt->base + EMAC_TXQ_CTRL_0);\n\temac_reg_update32(adpt->base + EMAC_TXQ_CTRL_2,\n\t\t\t  (TXF_HWM_BMSK | TXF_LWM_BMSK), 0);\n}\n\n \nstatic void emac_mac_rx_config(struct emac_adapter *adpt)\n{\n\tu32 val;\n\n\tval = (adpt->rfd_burst << NUM_RFD_BURST_PREF_SHFT) &\n\t       NUM_RFD_BURST_PREF_BMSK;\n\tval |= (SP_IPV6 | CUT_THRU_EN);\n\n\twritel(val, adpt->base + EMAC_RXQ_CTRL_0);\n\n\tval = readl(adpt->base + EMAC_RXQ_CTRL_1);\n\tval &= ~(JUMBO_1KAH_BMSK | RFD_PREF_LOW_THRESHOLD_BMSK |\n\t\t RFD_PREF_UP_THRESHOLD_BMSK);\n\tval |= (JUMBO_1KAH << JUMBO_1KAH_SHFT) |\n\t\t(RFD_PREF_LOW_TH << RFD_PREF_LOW_THRESHOLD_SHFT) |\n\t\t(RFD_PREF_UP_TH  << RFD_PREF_UP_THRESHOLD_SHFT);\n\twritel(val, adpt->base + EMAC_RXQ_CTRL_1);\n\n\tval = readl(adpt->base + EMAC_RXQ_CTRL_2);\n\tval &= ~(RXF_DOF_THRESHOLD_BMSK | RXF_UOF_THRESHOLD_BMSK);\n\tval |= (RXF_DOF_THRESFHOLD  << RXF_DOF_THRESHOLD_SHFT) |\n\t\t(RXF_UOF_THRESFHOLD << RXF_UOF_THRESHOLD_SHFT);\n\twritel(val, adpt->base + EMAC_RXQ_CTRL_2);\n\n\tval = readl(adpt->base + EMAC_RXQ_CTRL_3);\n\tval &= ~(RXD_TIMER_BMSK | RXD_THRESHOLD_BMSK);\n\tval |= RXD_TH << RXD_THRESHOLD_SHFT;\n\twritel(val, adpt->base + EMAC_RXQ_CTRL_3);\n}\n\n \nstatic void emac_mac_dma_config(struct emac_adapter *adpt)\n{\n\tu32 dma_ctrl = DMAR_REQ_PRI;\n\n\tswitch (adpt->dma_order) {\n\tcase emac_dma_ord_in:\n\t\tdma_ctrl |= IN_ORDER_MODE;\n\t\tbreak;\n\tcase emac_dma_ord_enh:\n\t\tdma_ctrl |= ENH_ORDER_MODE;\n\t\tbreak;\n\tcase emac_dma_ord_out:\n\t\tdma_ctrl |= OUT_ORDER_MODE;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tdma_ctrl |= (((u32)adpt->dmar_block) << REGRDBLEN_SHFT) &\n\t\t\t\t\t\tREGRDBLEN_BMSK;\n\tdma_ctrl |= (((u32)adpt->dmaw_block) << REGWRBLEN_SHFT) &\n\t\t\t\t\t\tREGWRBLEN_BMSK;\n\tdma_ctrl |= (((u32)adpt->dmar_dly_cnt) << DMAR_DLY_CNT_SHFT) &\n\t\t\t\t\t\tDMAR_DLY_CNT_BMSK;\n\tdma_ctrl |= (((u32)adpt->dmaw_dly_cnt) << DMAW_DLY_CNT_SHFT) &\n\t\t\t\t\t\tDMAW_DLY_CNT_BMSK;\n\n\t \n\twritel(dma_ctrl, adpt->base + EMAC_DMA_CTRL);\n}\n\n \nstatic void emac_set_mac_address(struct emac_adapter *adpt, const u8 *addr)\n{\n\tu32 sta;\n\n\t \n\n\t \n\tsta = (((u32)addr[2]) << 24) | (((u32)addr[3]) << 16) |\n\t      (((u32)addr[4]) << 8)  | (((u32)addr[5]));\n\twritel(sta, adpt->base + EMAC_MAC_STA_ADDR0);\n\n\t \n\tsta = (((u32)addr[0]) << 8) | (u32)addr[1];\n\twritel(sta, adpt->base + EMAC_MAC_STA_ADDR1);\n}\n\nstatic void emac_mac_config(struct emac_adapter *adpt)\n{\n\tstruct net_device *netdev = adpt->netdev;\n\tunsigned int max_frame;\n\tu32 val;\n\n\temac_set_mac_address(adpt, netdev->dev_addr);\n\n\tmax_frame = netdev->mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\tadpt->rxbuf_size = netdev->mtu > EMAC_DEF_RX_BUF_SIZE ?\n\t\tALIGN(max_frame, 8) : EMAC_DEF_RX_BUF_SIZE;\n\n\temac_mac_dma_rings_config(adpt);\n\n\twritel(netdev->mtu + ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN,\n\t       adpt->base + EMAC_MAX_FRAM_LEN_CTRL);\n\n\temac_mac_tx_config(adpt);\n\temac_mac_rx_config(adpt);\n\temac_mac_dma_config(adpt);\n\n\tval = readl(adpt->base + EMAC_AXI_MAST_CTRL);\n\tval &= ~(DATA_BYTE_SWAP | MAX_BOUND);\n\tval |= MAX_BTYPE;\n\twritel(val, adpt->base + EMAC_AXI_MAST_CTRL);\n\twritel(0, adpt->base + EMAC_CLK_GATE_CTRL);\n\twritel(RX_UNCPL_INT_EN, adpt->base + EMAC_MISC_CTRL);\n}\n\nvoid emac_mac_reset(struct emac_adapter *adpt)\n{\n\temac_mac_stop(adpt);\n\n\temac_reg_update32(adpt->base + EMAC_DMA_MAS_CTRL, 0, SOFT_RST);\n\tusleep_range(100, 150);  \n\n\t \n\temac_reg_update32(adpt->base + EMAC_DMA_MAS_CTRL, 0, INT_RD_CLR_EN);\n}\n\nstatic void emac_mac_start(struct emac_adapter *adpt)\n{\n\tstruct phy_device *phydev = adpt->phydev;\n\tu32 mac, csr1;\n\n\t \n\temac_reg_update32(adpt->base + EMAC_TXQ_CTRL_0, 0, TXQ_EN);\n\n\t \n\temac_reg_update32(adpt->base + EMAC_RXQ_CTRL_0, 0, RXQ_EN);\n\n\t \n\tmac = readl(adpt->base + EMAC_MAC_CTRL);\n\tcsr1 = readl(adpt->csr + EMAC_EMAC_WRAPPER_CSR1);\n\n\tmac |= TXEN | RXEN;      \n\n\t \n\tmac &= ~(RXFC | TXFC);\n\n\tif (adpt->automatic) {\n\t\t \n\t\tadpt->rx_flow_control = phydev->pause;\n\t\tadpt->tx_flow_control = phydev->pause != phydev->asym_pause;\n\t}\n\tmac |= adpt->rx_flow_control ? RXFC : 0;\n\tmac |= adpt->tx_flow_control ? TXFC : 0;\n\n\t \n\tmac &= ~SPEED_MASK;\n\tif (phydev->speed == SPEED_1000) {\n\t\tmac |= SPEED(2);\n\t\tcsr1 |= FREQ_MODE;\n\t} else {\n\t\tmac |= SPEED(1);\n\t\tcsr1 &= ~FREQ_MODE;\n\t}\n\n\tif (phydev->duplex == DUPLEX_FULL)\n\t\tmac |= FULLD;\n\telse\n\t\tmac &= ~FULLD;\n\n\t \n\tmac |= (CRCE | PCRCE);\n\tmac |= ((adpt->preamble << PRLEN_SHFT) & PRLEN_BMSK);\n\tmac |= BROAD_EN;\n\tmac |= FLCHK;\n\tmac &= ~RX_CHKSUM_EN;\n\tmac &= ~(HUGEN | VLAN_STRIP | TPAUSE | SIMR | HUGE | MULTI_ALL |\n\t\t DEBUG_MODE | SINGLE_PAUSE_MODE);\n\n\t \n\tmac |= adpt->single_pause_mode ? SINGLE_PAUSE_MODE : 0;\n\n\twritel_relaxed(csr1, adpt->csr + EMAC_EMAC_WRAPPER_CSR1);\n\n\twritel_relaxed(mac, adpt->base + EMAC_MAC_CTRL);\n\n\t \n\n\twritel_relaxed(adpt->irq_mod, adpt->base + EMAC_IRQ_MOD_TIM_INIT);\n\twritel_relaxed(INT_RD_CLR_EN | LPW_MODE | IRQ_MODERATOR_EN |\n\t\t\tIRQ_MODERATOR2_EN, adpt->base + EMAC_DMA_MAS_CTRL);\n\n\temac_mac_mode_config(adpt);\n\n\temac_reg_update32(adpt->base + EMAC_ATHR_HEADER_CTRL,\n\t\t\t  (HEADER_ENABLE | HEADER_CNT_EN), 0);\n}\n\nvoid emac_mac_stop(struct emac_adapter *adpt)\n{\n\temac_reg_update32(adpt->base + EMAC_RXQ_CTRL_0, RXQ_EN, 0);\n\temac_reg_update32(adpt->base + EMAC_TXQ_CTRL_0, TXQ_EN, 0);\n\temac_reg_update32(adpt->base + EMAC_MAC_CTRL, TXEN | RXEN, 0);\n\tusleep_range(1000, 1050);  \n}\n\n \nstatic void emac_tx_q_descs_free(struct emac_adapter *adpt)\n{\n\tstruct emac_tx_queue *tx_q = &adpt->tx_q;\n\tunsigned int i;\n\tsize_t size;\n\n\t \n\tif (!tx_q->tpd.tpbuff)\n\t\treturn;\n\n\tfor (i = 0; i < tx_q->tpd.count; i++) {\n\t\tstruct emac_buffer *tpbuf = GET_TPD_BUFFER(tx_q, i);\n\n\t\tif (tpbuf->dma_addr) {\n\t\t\tdma_unmap_single(adpt->netdev->dev.parent,\n\t\t\t\t\t tpbuf->dma_addr, tpbuf->length,\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\ttpbuf->dma_addr = 0;\n\t\t}\n\t\tif (tpbuf->skb) {\n\t\t\tdev_kfree_skb_any(tpbuf->skb);\n\t\t\ttpbuf->skb = NULL;\n\t\t}\n\t}\n\n\tsize = sizeof(struct emac_buffer) * tx_q->tpd.count;\n\tmemset(tx_q->tpd.tpbuff, 0, size);\n\n\t \n\tmemset(tx_q->tpd.v_addr, 0, tx_q->tpd.size);\n\n\ttx_q->tpd.consume_idx = 0;\n\ttx_q->tpd.produce_idx = 0;\n}\n\n \nstatic void emac_rx_q_free_descs(struct emac_adapter *adpt)\n{\n\tstruct device *dev = adpt->netdev->dev.parent;\n\tstruct emac_rx_queue *rx_q = &adpt->rx_q;\n\tunsigned int i;\n\tsize_t size;\n\n\t \n\tif (!rx_q->rfd.rfbuff)\n\t\treturn;\n\n\tfor (i = 0; i < rx_q->rfd.count; i++) {\n\t\tstruct emac_buffer *rfbuf = GET_RFD_BUFFER(rx_q, i);\n\n\t\tif (rfbuf->dma_addr) {\n\t\t\tdma_unmap_single(dev, rfbuf->dma_addr, rfbuf->length,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\trfbuf->dma_addr = 0;\n\t\t}\n\t\tif (rfbuf->skb) {\n\t\t\tdev_kfree_skb(rfbuf->skb);\n\t\t\trfbuf->skb = NULL;\n\t\t}\n\t}\n\n\tsize =  sizeof(struct emac_buffer) * rx_q->rfd.count;\n\tmemset(rx_q->rfd.rfbuff, 0, size);\n\n\t \n\tmemset(rx_q->rrd.v_addr, 0, rx_q->rrd.size);\n\trx_q->rrd.produce_idx = 0;\n\trx_q->rrd.consume_idx = 0;\n\n\tmemset(rx_q->rfd.v_addr, 0, rx_q->rfd.size);\n\trx_q->rfd.produce_idx = 0;\n\trx_q->rfd.consume_idx = 0;\n}\n\n \nstatic void emac_tx_q_bufs_free(struct emac_adapter *adpt)\n{\n\tstruct emac_tx_queue *tx_q = &adpt->tx_q;\n\n\temac_tx_q_descs_free(adpt);\n\n\tkfree(tx_q->tpd.tpbuff);\n\ttx_q->tpd.tpbuff = NULL;\n\ttx_q->tpd.v_addr = NULL;\n\ttx_q->tpd.dma_addr = 0;\n\ttx_q->tpd.size = 0;\n}\n\n \nstatic int emac_tx_q_desc_alloc(struct emac_adapter *adpt,\n\t\t\t\tstruct emac_tx_queue *tx_q)\n{\n\tstruct emac_ring_header *ring_header = &adpt->ring_header;\n\tint node = dev_to_node(adpt->netdev->dev.parent);\n\tsize_t size;\n\n\tsize = sizeof(struct emac_buffer) * tx_q->tpd.count;\n\ttx_q->tpd.tpbuff = kzalloc_node(size, GFP_KERNEL, node);\n\tif (!tx_q->tpd.tpbuff)\n\t\treturn -ENOMEM;\n\n\ttx_q->tpd.size = tx_q->tpd.count * (adpt->tpd_size * 4);\n\ttx_q->tpd.dma_addr = ring_header->dma_addr + ring_header->used;\n\ttx_q->tpd.v_addr = ring_header->v_addr + ring_header->used;\n\tring_header->used += ALIGN(tx_q->tpd.size, 8);\n\ttx_q->tpd.produce_idx = 0;\n\ttx_q->tpd.consume_idx = 0;\n\n\treturn 0;\n}\n\n \nstatic void emac_rx_q_bufs_free(struct emac_adapter *adpt)\n{\n\tstruct emac_rx_queue *rx_q = &adpt->rx_q;\n\n\temac_rx_q_free_descs(adpt);\n\n\tkfree(rx_q->rfd.rfbuff);\n\trx_q->rfd.rfbuff   = NULL;\n\n\trx_q->rfd.v_addr   = NULL;\n\trx_q->rfd.dma_addr = 0;\n\trx_q->rfd.size     = 0;\n\n\trx_q->rrd.v_addr   = NULL;\n\trx_q->rrd.dma_addr = 0;\n\trx_q->rrd.size     = 0;\n}\n\n \nstatic int emac_rx_descs_alloc(struct emac_adapter *adpt)\n{\n\tstruct emac_ring_header *ring_header = &adpt->ring_header;\n\tint node = dev_to_node(adpt->netdev->dev.parent);\n\tstruct emac_rx_queue *rx_q = &adpt->rx_q;\n\tsize_t size;\n\n\tsize = sizeof(struct emac_buffer) * rx_q->rfd.count;\n\trx_q->rfd.rfbuff = kzalloc_node(size, GFP_KERNEL, node);\n\tif (!rx_q->rfd.rfbuff)\n\t\treturn -ENOMEM;\n\n\trx_q->rrd.size = rx_q->rrd.count * (adpt->rrd_size * 4);\n\trx_q->rfd.size = rx_q->rfd.count * (adpt->rfd_size * 4);\n\n\trx_q->rrd.dma_addr = ring_header->dma_addr + ring_header->used;\n\trx_q->rrd.v_addr   = ring_header->v_addr + ring_header->used;\n\tring_header->used += ALIGN(rx_q->rrd.size, 8);\n\n\trx_q->rfd.dma_addr = ring_header->dma_addr + ring_header->used;\n\trx_q->rfd.v_addr   = ring_header->v_addr + ring_header->used;\n\tring_header->used += ALIGN(rx_q->rfd.size, 8);\n\n\trx_q->rrd.produce_idx = 0;\n\trx_q->rrd.consume_idx = 0;\n\n\trx_q->rfd.produce_idx = 0;\n\trx_q->rfd.consume_idx = 0;\n\n\treturn 0;\n}\n\n \nint emac_mac_rx_tx_rings_alloc_all(struct emac_adapter *adpt)\n{\n\tstruct emac_ring_header *ring_header = &adpt->ring_header;\n\tstruct device *dev = adpt->netdev->dev.parent;\n\tunsigned int num_tx_descs = adpt->tx_desc_cnt;\n\tunsigned int num_rx_descs = adpt->rx_desc_cnt;\n\tint ret;\n\n\tadpt->tx_q.tpd.count = adpt->tx_desc_cnt;\n\n\tadpt->rx_q.rrd.count = adpt->rx_desc_cnt;\n\tadpt->rx_q.rfd.count = adpt->rx_desc_cnt;\n\n\t \n\tring_header->size = num_tx_descs * (adpt->tpd_size * 4) +\n\t\t\t    num_rx_descs * (adpt->rfd_size * 4) +\n\t\t\t    num_rx_descs * (adpt->rrd_size * 4) +\n\t\t\t    8 + 2 * 8;  \n\n\tring_header->used = 0;\n\tring_header->v_addr = dma_alloc_coherent(dev, ring_header->size,\n\t\t\t\t\t\t &ring_header->dma_addr,\n\t\t\t\t\t\t GFP_KERNEL);\n\tif (!ring_header->v_addr)\n\t\treturn -ENOMEM;\n\n\tring_header->used = ALIGN(ring_header->dma_addr, 8) -\n\t\t\t\t\t\t\tring_header->dma_addr;\n\n\tret = emac_tx_q_desc_alloc(adpt, &adpt->tx_q);\n\tif (ret) {\n\t\tnetdev_err(adpt->netdev, \"error: Tx Queue alloc failed\\n\");\n\t\tgoto err_alloc_tx;\n\t}\n\n\tret = emac_rx_descs_alloc(adpt);\n\tif (ret) {\n\t\tnetdev_err(adpt->netdev, \"error: Rx Queue alloc failed\\n\");\n\t\tgoto err_alloc_rx;\n\t}\n\n\treturn 0;\n\nerr_alloc_rx:\n\temac_tx_q_bufs_free(adpt);\nerr_alloc_tx:\n\tdma_free_coherent(dev, ring_header->size,\n\t\t\t  ring_header->v_addr, ring_header->dma_addr);\n\n\tring_header->v_addr   = NULL;\n\tring_header->dma_addr = 0;\n\tring_header->size     = 0;\n\tring_header->used     = 0;\n\n\treturn ret;\n}\n\n \nvoid emac_mac_rx_tx_rings_free_all(struct emac_adapter *adpt)\n{\n\tstruct emac_ring_header *ring_header = &adpt->ring_header;\n\tstruct device *dev = adpt->netdev->dev.parent;\n\n\temac_tx_q_bufs_free(adpt);\n\temac_rx_q_bufs_free(adpt);\n\n\tdma_free_coherent(dev, ring_header->size,\n\t\t\t  ring_header->v_addr, ring_header->dma_addr);\n\n\tring_header->v_addr   = NULL;\n\tring_header->dma_addr = 0;\n\tring_header->size     = 0;\n\tring_header->used     = 0;\n}\n\n \nstatic void emac_mac_rx_tx_ring_reset_all(struct emac_adapter *adpt)\n{\n\tunsigned int i;\n\n\tadpt->tx_q.tpd.produce_idx = 0;\n\tadpt->tx_q.tpd.consume_idx = 0;\n\tfor (i = 0; i < adpt->tx_q.tpd.count; i++)\n\t\tadpt->tx_q.tpd.tpbuff[i].dma_addr = 0;\n\n\tadpt->rx_q.rrd.produce_idx = 0;\n\tadpt->rx_q.rrd.consume_idx = 0;\n\tadpt->rx_q.rfd.produce_idx = 0;\n\tadpt->rx_q.rfd.consume_idx = 0;\n\tfor (i = 0; i < adpt->rx_q.rfd.count; i++)\n\t\tadpt->rx_q.rfd.rfbuff[i].dma_addr = 0;\n}\n\n \nstatic void emac_mac_rx_rfd_create(struct emac_adapter *adpt,\n\t\t\t\t   struct emac_rx_queue *rx_q,\n\t\t\t\t   dma_addr_t addr)\n{\n\tu32 *hw_rfd = EMAC_RFD(rx_q, adpt->rfd_size, rx_q->rfd.produce_idx);\n\n\t*(hw_rfd++) = lower_32_bits(addr);\n\t*hw_rfd = upper_32_bits(addr);\n\n\tif (++rx_q->rfd.produce_idx == rx_q->rfd.count)\n\t\trx_q->rfd.produce_idx = 0;\n}\n\n \nstatic void emac_mac_rx_descs_refill(struct emac_adapter *adpt,\n\t\t\t\t    struct emac_rx_queue *rx_q)\n{\n\tstruct emac_buffer *curr_rxbuf;\n\tstruct emac_buffer *next_rxbuf;\n\tunsigned int count = 0;\n\tu32 next_produce_idx;\n\n\tnext_produce_idx = rx_q->rfd.produce_idx + 1;\n\tif (next_produce_idx == rx_q->rfd.count)\n\t\tnext_produce_idx = 0;\n\n\tcurr_rxbuf = GET_RFD_BUFFER(rx_q, rx_q->rfd.produce_idx);\n\tnext_rxbuf = GET_RFD_BUFFER(rx_q, next_produce_idx);\n\n\t \n\twhile (!next_rxbuf->dma_addr) {\n\t\tstruct sk_buff *skb;\n\t\tint ret;\n\n\t\tskb = netdev_alloc_skb_ip_align(adpt->netdev, adpt->rxbuf_size);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tcurr_rxbuf->dma_addr =\n\t\t\tdma_map_single(adpt->netdev->dev.parent, skb->data,\n\t\t\t\t       adpt->rxbuf_size, DMA_FROM_DEVICE);\n\n\t\tret = dma_mapping_error(adpt->netdev->dev.parent,\n\t\t\t\t\tcurr_rxbuf->dma_addr);\n\t\tif (ret) {\n\t\t\tdev_kfree_skb(skb);\n\t\t\tbreak;\n\t\t}\n\t\tcurr_rxbuf->skb = skb;\n\t\tcurr_rxbuf->length = adpt->rxbuf_size;\n\n\t\temac_mac_rx_rfd_create(adpt, rx_q, curr_rxbuf->dma_addr);\n\t\tnext_produce_idx = rx_q->rfd.produce_idx + 1;\n\t\tif (next_produce_idx == rx_q->rfd.count)\n\t\t\tnext_produce_idx = 0;\n\n\t\tcurr_rxbuf = GET_RFD_BUFFER(rx_q, rx_q->rfd.produce_idx);\n\t\tnext_rxbuf = GET_RFD_BUFFER(rx_q, next_produce_idx);\n\t\tcount++;\n\t}\n\n\tif (count) {\n\t\tu32 prod_idx = (rx_q->rfd.produce_idx << rx_q->produce_shift) &\n\t\t\t\trx_q->produce_mask;\n\t\temac_reg_update32(adpt->base + rx_q->produce_reg,\n\t\t\t\t  rx_q->produce_mask, prod_idx);\n\t}\n}\n\nstatic void emac_adjust_link(struct net_device *netdev)\n{\n\tstruct emac_adapter *adpt = netdev_priv(netdev);\n\tstruct phy_device *phydev = netdev->phydev;\n\n\tif (phydev->link) {\n\t\temac_mac_start(adpt);\n\t\temac_sgmii_link_change(adpt, true);\n\t} else {\n\t\temac_sgmii_link_change(adpt, false);\n\t\temac_mac_stop(adpt);\n\t}\n\n\tphy_print_status(phydev);\n}\n\n \nint emac_mac_up(struct emac_adapter *adpt)\n{\n\tstruct net_device *netdev = adpt->netdev;\n\tint ret;\n\n\temac_mac_rx_tx_ring_reset_all(adpt);\n\temac_mac_config(adpt);\n\temac_mac_rx_descs_refill(adpt, &adpt->rx_q);\n\n\tadpt->phydev->irq = PHY_POLL;\n\tret = phy_connect_direct(netdev, adpt->phydev, emac_adjust_link,\n\t\t\t\t PHY_INTERFACE_MODE_SGMII);\n\tif (ret) {\n\t\tnetdev_err(adpt->netdev, \"could not connect phy\\n\");\n\t\treturn ret;\n\t}\n\n\tphy_attached_print(adpt->phydev, NULL);\n\n\t \n\twritel((u32)~DIS_INT, adpt->base + EMAC_INT_STATUS);\n\twritel(adpt->irq.mask, adpt->base + EMAC_INT_MASK);\n\n\tphy_start(adpt->phydev);\n\n\tnapi_enable(&adpt->rx_q.napi);\n\tnetif_start_queue(netdev);\n\n\treturn 0;\n}\n\n \nvoid emac_mac_down(struct emac_adapter *adpt)\n{\n\tstruct net_device *netdev = adpt->netdev;\n\n\tnetif_stop_queue(netdev);\n\tnapi_disable(&adpt->rx_q.napi);\n\n\tphy_stop(adpt->phydev);\n\n\t \n\twritel(DIS_INT, adpt->base + EMAC_INT_STATUS);\n\twritel(0, adpt->base + EMAC_INT_MASK);\n\tsynchronize_irq(adpt->irq.irq);\n\n\tphy_disconnect(adpt->phydev);\n\n\temac_mac_reset(adpt);\n\n\temac_tx_q_descs_free(adpt);\n\tnetdev_reset_queue(adpt->netdev);\n\temac_rx_q_free_descs(adpt);\n}\n\n \nstatic bool emac_rx_process_rrd(struct emac_adapter *adpt,\n\t\t\t\tstruct emac_rx_queue *rx_q,\n\t\t\t\tstruct emac_rrd *rrd)\n{\n\tu32 *hw_rrd = EMAC_RRD(rx_q, adpt->rrd_size, rx_q->rrd.consume_idx);\n\n\trrd->word[3] = *(hw_rrd + 3);\n\n\tif (!RRD_UPDT(rrd))\n\t\treturn false;\n\n\trrd->word[4] = 0;\n\trrd->word[5] = 0;\n\n\trrd->word[0] = *(hw_rrd++);\n\trrd->word[1] = *(hw_rrd++);\n\trrd->word[2] = *(hw_rrd++);\n\n\tif (unlikely(RRD_NOR(rrd) != 1)) {\n\t\tnetdev_err(adpt->netdev,\n\t\t\t   \"error: multi-RFD not support yet! nor:%lu\\n\",\n\t\t\t   RRD_NOR(rrd));\n\t}\n\n\t \n\tRRD_UPDT_SET(rrd, 0);\n\t*hw_rrd = rrd->word[3];\n\n\tif (++rx_q->rrd.consume_idx == rx_q->rrd.count)\n\t\trx_q->rrd.consume_idx = 0;\n\n\treturn true;\n}\n\n \nstatic void emac_tx_tpd_create(struct emac_adapter *adpt,\n\t\t\t       struct emac_tx_queue *tx_q, struct emac_tpd *tpd)\n{\n\tu32 *hw_tpd;\n\n\ttx_q->tpd.last_produce_idx = tx_q->tpd.produce_idx;\n\thw_tpd = EMAC_TPD(tx_q, adpt->tpd_size, tx_q->tpd.produce_idx);\n\n\tif (++tx_q->tpd.produce_idx == tx_q->tpd.count)\n\t\ttx_q->tpd.produce_idx = 0;\n\n\t*(hw_tpd++) = tpd->word[0];\n\t*(hw_tpd++) = tpd->word[1];\n\t*(hw_tpd++) = tpd->word[2];\n\t*hw_tpd = tpd->word[3];\n}\n\n \nstatic void emac_tx_tpd_mark_last(struct emac_adapter *adpt,\n\t\t\t\t  struct emac_tx_queue *tx_q)\n{\n\tu32 *hw_tpd =\n\t\tEMAC_TPD(tx_q, adpt->tpd_size, tx_q->tpd.last_produce_idx);\n\tu32 tmp_tpd;\n\n\ttmp_tpd = *(hw_tpd + 1);\n\ttmp_tpd |= EMAC_TPD_LAST_FRAGMENT;\n\t*(hw_tpd + 1) = tmp_tpd;\n}\n\nstatic void emac_rx_rfd_clean(struct emac_rx_queue *rx_q, struct emac_rrd *rrd)\n{\n\tstruct emac_buffer *rfbuf = rx_q->rfd.rfbuff;\n\tu32 consume_idx = RRD_SI(rrd);\n\tunsigned int i;\n\n\tfor (i = 0; i < RRD_NOR(rrd); i++) {\n\t\trfbuf[consume_idx].skb = NULL;\n\t\tif (++consume_idx == rx_q->rfd.count)\n\t\t\tconsume_idx = 0;\n\t}\n\n\trx_q->rfd.consume_idx = consume_idx;\n\trx_q->rfd.process_idx = consume_idx;\n}\n\n \nstatic void emac_receive_skb(struct emac_rx_queue *rx_q,\n\t\t\t     struct sk_buff *skb,\n\t\t\t     u16 vlan_tag, bool vlan_flag)\n{\n\tif (vlan_flag) {\n\t\tu16 vlan;\n\n\t\tEMAC_TAG_TO_VLAN(vlan_tag, vlan);\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan);\n\t}\n\n\tnapi_gro_receive(&rx_q->napi, skb);\n}\n\n \nvoid emac_mac_rx_process(struct emac_adapter *adpt, struct emac_rx_queue *rx_q,\n\t\t\t int *num_pkts, int max_pkts)\n{\n\tu32 proc_idx, hw_consume_idx, num_consume_pkts;\n\tstruct net_device *netdev  = adpt->netdev;\n\tstruct emac_buffer *rfbuf;\n\tunsigned int count = 0;\n\tstruct emac_rrd rrd;\n\tstruct sk_buff *skb;\n\tu32 reg;\n\n\treg = readl_relaxed(adpt->base + rx_q->consume_reg);\n\n\thw_consume_idx = (reg & rx_q->consume_mask) >> rx_q->consume_shift;\n\tnum_consume_pkts = (hw_consume_idx >= rx_q->rrd.consume_idx) ?\n\t\t(hw_consume_idx -  rx_q->rrd.consume_idx) :\n\t\t(hw_consume_idx + rx_q->rrd.count - rx_q->rrd.consume_idx);\n\n\tdo {\n\t\tif (!num_consume_pkts)\n\t\t\tbreak;\n\n\t\tif (!emac_rx_process_rrd(adpt, rx_q, &rrd))\n\t\t\tbreak;\n\n\t\tif (likely(RRD_NOR(&rrd) == 1)) {\n\t\t\t \n\t\t\trfbuf = GET_RFD_BUFFER(rx_q, RRD_SI(&rrd));\n\t\t\tdma_unmap_single(adpt->netdev->dev.parent,\n\t\t\t\t\t rfbuf->dma_addr, rfbuf->length,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\trfbuf->dma_addr = 0;\n\t\t\tskb = rfbuf->skb;\n\t\t} else {\n\t\t\tnetdev_err(adpt->netdev,\n\t\t\t\t   \"error: multi-RFD not support yet!\\n\");\n\t\t\tbreak;\n\t\t}\n\t\temac_rx_rfd_clean(rx_q, &rrd);\n\t\tnum_consume_pkts--;\n\t\tcount++;\n\n\t\t \n\t\tif (rrd.word[EMAC_RRD_STATS_DW_IDX] & EMAC_RRD_ERROR) {\n\t\t\tnetif_dbg(adpt, rx_status, adpt->netdev,\n\t\t\t\t  \"Drop error packet[RRD: 0x%x:0x%x:0x%x:0x%x]\\n\",\n\t\t\t\t  rrd.word[0], rrd.word[1],\n\t\t\t\t  rrd.word[2], rrd.word[3]);\n\n\t\t\tdev_kfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tskb_put(skb, RRD_PKT_SIZE(&rrd) - ETH_FCS_LEN);\n\t\tskb->dev = netdev;\n\t\tskb->protocol = eth_type_trans(skb, skb->dev);\n\t\tif (netdev->features & NETIF_F_RXCSUM)\n\t\t\tskb->ip_summed = RRD_L4F(&rrd) ?\n\t\t\t\t\t  CHECKSUM_NONE : CHECKSUM_UNNECESSARY;\n\t\telse\n\t\t\tskb_checksum_none_assert(skb);\n\n\t\temac_receive_skb(rx_q, skb, (u16)RRD_CVALN_TAG(&rrd),\n\t\t\t\t (bool)RRD_CVTAG(&rrd));\n\n\t\t(*num_pkts)++;\n\t} while (*num_pkts < max_pkts);\n\n\tif (count) {\n\t\tproc_idx = (rx_q->rfd.process_idx << rx_q->process_shft) &\n\t\t\t\trx_q->process_mask;\n\t\temac_reg_update32(adpt->base + rx_q->process_reg,\n\t\t\t\t  rx_q->process_mask, proc_idx);\n\t\temac_mac_rx_descs_refill(adpt, rx_q);\n\t}\n}\n\n \nstatic unsigned int emac_tpd_num_free_descs(struct emac_tx_queue *tx_q)\n{\n\tu32 produce_idx = tx_q->tpd.produce_idx;\n\tu32 consume_idx = tx_q->tpd.consume_idx;\n\n\treturn (consume_idx > produce_idx) ?\n\t\t(consume_idx - produce_idx - 1) :\n\t\t(tx_q->tpd.count + consume_idx - produce_idx - 1);\n}\n\n \nvoid emac_mac_tx_process(struct emac_adapter *adpt, struct emac_tx_queue *tx_q)\n{\n\tu32 reg = readl_relaxed(adpt->base + tx_q->consume_reg);\n\tu32 hw_consume_idx, pkts_compl = 0, bytes_compl = 0;\n\tstruct emac_buffer *tpbuf;\n\n\thw_consume_idx = (reg & tx_q->consume_mask) >> tx_q->consume_shift;\n\n\twhile (tx_q->tpd.consume_idx != hw_consume_idx) {\n\t\ttpbuf = GET_TPD_BUFFER(tx_q, tx_q->tpd.consume_idx);\n\t\tif (tpbuf->dma_addr) {\n\t\t\tdma_unmap_page(adpt->netdev->dev.parent,\n\t\t\t\t       tpbuf->dma_addr, tpbuf->length,\n\t\t\t\t       DMA_TO_DEVICE);\n\t\t\ttpbuf->dma_addr = 0;\n\t\t}\n\n\t\tif (tpbuf->skb) {\n\t\t\tpkts_compl++;\n\t\t\tbytes_compl += tpbuf->skb->len;\n\t\t\tdev_consume_skb_irq(tpbuf->skb);\n\t\t\ttpbuf->skb = NULL;\n\t\t}\n\n\t\tif (++tx_q->tpd.consume_idx == tx_q->tpd.count)\n\t\t\ttx_q->tpd.consume_idx = 0;\n\t}\n\n\tnetdev_completed_queue(adpt->netdev, pkts_compl, bytes_compl);\n\n\tif (netif_queue_stopped(adpt->netdev))\n\t\tif (emac_tpd_num_free_descs(tx_q) > (MAX_SKB_FRAGS + 1))\n\t\t\tnetif_wake_queue(adpt->netdev);\n}\n\n \nvoid emac_mac_rx_tx_ring_init_all(struct platform_device *pdev,\n\t\t\t\t  struct emac_adapter *adpt)\n{\n\tadpt->rx_q.netdev = adpt->netdev;\n\n\tadpt->rx_q.produce_reg  = EMAC_MAILBOX_0;\n\tadpt->rx_q.produce_mask = RFD0_PROD_IDX_BMSK;\n\tadpt->rx_q.produce_shift = RFD0_PROD_IDX_SHFT;\n\n\tadpt->rx_q.process_reg  = EMAC_MAILBOX_0;\n\tadpt->rx_q.process_mask = RFD0_PROC_IDX_BMSK;\n\tadpt->rx_q.process_shft = RFD0_PROC_IDX_SHFT;\n\n\tadpt->rx_q.consume_reg  = EMAC_MAILBOX_3;\n\tadpt->rx_q.consume_mask = RFD0_CONS_IDX_BMSK;\n\tadpt->rx_q.consume_shift = RFD0_CONS_IDX_SHFT;\n\n\tadpt->rx_q.irq          = &adpt->irq;\n\tadpt->rx_q.intr         = adpt->irq.mask & ISR_RX_PKT;\n\n\tadpt->tx_q.produce_reg  = EMAC_MAILBOX_15;\n\tadpt->tx_q.produce_mask = NTPD_PROD_IDX_BMSK;\n\tadpt->tx_q.produce_shift = NTPD_PROD_IDX_SHFT;\n\n\tadpt->tx_q.consume_reg  = EMAC_MAILBOX_2;\n\tadpt->tx_q.consume_mask = NTPD_CONS_IDX_BMSK;\n\tadpt->tx_q.consume_shift = NTPD_CONS_IDX_SHFT;\n}\n\n \nstatic int emac_tso_csum(struct emac_adapter *adpt,\n\t\t\t struct emac_tx_queue *tx_q,\n\t\t\t struct sk_buff *skb,\n\t\t\t struct emac_tpd *tpd)\n{\n\tunsigned int hdr_len;\n\tint ret;\n\n\tif (skb_is_gso(skb)) {\n\t\tif (skb_header_cloned(skb)) {\n\t\t\tret = pskb_expand_head(skb, 0, 0, GFP_ATOMIC);\n\t\t\tif (unlikely(ret))\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\tu32 pkt_len = ((unsigned char *)ip_hdr(skb) - skb->data)\n\t\t\t\t       + ntohs(ip_hdr(skb)->tot_len);\n\t\t\tif (skb->len > pkt_len) {\n\t\t\t\tret = pskb_trim(skb, pkt_len);\n\t\t\t\tif (unlikely(ret))\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\thdr_len = skb_tcp_all_headers(skb);\n\t\tif (unlikely(skb->len == hdr_len)) {\n\t\t\t \n\t\t\tnetif_warn(adpt, tx_err, adpt->netdev,\n\t\t\t\t   \"tso not needed for packet with 0 data\\n\");\n\t\t\tgoto do_csum;\n\t\t}\n\n\t\tif (skb_shinfo(skb)->gso_type & SKB_GSO_TCPV4) {\n\t\t\tip_hdr(skb)->check = 0;\n\t\t\ttcp_hdr(skb)->check =\n\t\t\t\t~csum_tcpudp_magic(ip_hdr(skb)->saddr,\n\t\t\t\t\t\t   ip_hdr(skb)->daddr,\n\t\t\t\t\t\t   0, IPPROTO_TCP, 0);\n\t\t\tTPD_IPV4_SET(tpd, 1);\n\t\t}\n\n\t\tif (skb_shinfo(skb)->gso_type & SKB_GSO_TCPV6) {\n\t\t\t \n\t\t\tstruct emac_tpd extra_tpd;\n\n\t\t\tmemset(tpd, 0, sizeof(*tpd));\n\t\t\tmemset(&extra_tpd, 0, sizeof(extra_tpd));\n\n\t\t\ttcp_v6_gso_csum_prep(skb);\n\n\t\t\tTPD_PKT_LEN_SET(&extra_tpd, skb->len);\n\t\t\tTPD_LSO_SET(&extra_tpd, 1);\n\t\t\tTPD_LSOV_SET(&extra_tpd, 1);\n\t\t\temac_tx_tpd_create(adpt, tx_q, &extra_tpd);\n\t\t\tTPD_LSOV_SET(tpd, 1);\n\t\t}\n\n\t\tTPD_LSO_SET(tpd, 1);\n\t\tTPD_TCPHDR_OFFSET_SET(tpd, skb_transport_offset(skb));\n\t\tTPD_MSS_SET(tpd, skb_shinfo(skb)->gso_size);\n\t\treturn 0;\n\t}\n\ndo_csum:\n\tif (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {\n\t\tunsigned int css, cso;\n\n\t\tcso = skb_transport_offset(skb);\n\t\tif (unlikely(cso & 0x1)) {\n\t\t\tnetdev_err(adpt->netdev,\n\t\t\t\t   \"error: payload offset should be even\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tcss = cso + skb->csum_offset;\n\n\t\tTPD_PAYLOAD_OFFSET_SET(tpd, cso >> 1);\n\t\tTPD_CXSUM_OFFSET_SET(tpd, css >> 1);\n\t\tTPD_CSX_SET(tpd, 1);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void emac_tx_fill_tpd(struct emac_adapter *adpt,\n\t\t\t     struct emac_tx_queue *tx_q, struct sk_buff *skb,\n\t\t\t     struct emac_tpd *tpd)\n{\n\tunsigned int nr_frags = skb_shinfo(skb)->nr_frags;\n\tunsigned int first = tx_q->tpd.produce_idx;\n\tunsigned int len = skb_headlen(skb);\n\tstruct emac_buffer *tpbuf = NULL;\n\tunsigned int mapped_len = 0;\n\tunsigned int i;\n\tint count = 0;\n\tint ret;\n\n\t \n\tif (TPD_LSO(tpd)) {\n\t\tmapped_len = skb_tcp_all_headers(skb);\n\n\t\ttpbuf = GET_TPD_BUFFER(tx_q, tx_q->tpd.produce_idx);\n\t\ttpbuf->length = mapped_len;\n\t\ttpbuf->dma_addr = dma_map_page(adpt->netdev->dev.parent,\n\t\t\t\t\t       virt_to_page(skb->data),\n\t\t\t\t\t       offset_in_page(skb->data),\n\t\t\t\t\t       tpbuf->length,\n\t\t\t\t\t       DMA_TO_DEVICE);\n\t\tret = dma_mapping_error(adpt->netdev->dev.parent,\n\t\t\t\t\ttpbuf->dma_addr);\n\t\tif (ret)\n\t\t\tgoto error;\n\n\t\tTPD_BUFFER_ADDR_L_SET(tpd, lower_32_bits(tpbuf->dma_addr));\n\t\tTPD_BUFFER_ADDR_H_SET(tpd, upper_32_bits(tpbuf->dma_addr));\n\t\tTPD_BUF_LEN_SET(tpd, tpbuf->length);\n\t\temac_tx_tpd_create(adpt, tx_q, tpd);\n\t\tcount++;\n\t}\n\n\tif (mapped_len < len) {\n\t\ttpbuf = GET_TPD_BUFFER(tx_q, tx_q->tpd.produce_idx);\n\t\ttpbuf->length = len - mapped_len;\n\t\ttpbuf->dma_addr = dma_map_page(adpt->netdev->dev.parent,\n\t\t\t\t\t       virt_to_page(skb->data +\n\t\t\t\t\t\t\t    mapped_len),\n\t\t\t\t\t       offset_in_page(skb->data +\n\t\t\t\t\t\t\t      mapped_len),\n\t\t\t\t\t       tpbuf->length, DMA_TO_DEVICE);\n\t\tret = dma_mapping_error(adpt->netdev->dev.parent,\n\t\t\t\t\ttpbuf->dma_addr);\n\t\tif (ret)\n\t\t\tgoto error;\n\n\t\tTPD_BUFFER_ADDR_L_SET(tpd, lower_32_bits(tpbuf->dma_addr));\n\t\tTPD_BUFFER_ADDR_H_SET(tpd, upper_32_bits(tpbuf->dma_addr));\n\t\tTPD_BUF_LEN_SET(tpd, tpbuf->length);\n\t\temac_tx_tpd_create(adpt, tx_q, tpd);\n\t\tcount++;\n\t}\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\n\t\ttpbuf = GET_TPD_BUFFER(tx_q, tx_q->tpd.produce_idx);\n\t\ttpbuf->length = skb_frag_size(frag);\n\t\ttpbuf->dma_addr = skb_frag_dma_map(adpt->netdev->dev.parent,\n\t\t\t\t\t\t   frag, 0, tpbuf->length,\n\t\t\t\t\t\t   DMA_TO_DEVICE);\n\t\tret = dma_mapping_error(adpt->netdev->dev.parent,\n\t\t\t\t\ttpbuf->dma_addr);\n\t\tif (ret)\n\t\t\tgoto error;\n\n\t\tTPD_BUFFER_ADDR_L_SET(tpd, lower_32_bits(tpbuf->dma_addr));\n\t\tTPD_BUFFER_ADDR_H_SET(tpd, upper_32_bits(tpbuf->dma_addr));\n\t\tTPD_BUF_LEN_SET(tpd, tpbuf->length);\n\t\temac_tx_tpd_create(adpt, tx_q, tpd);\n\t\tcount++;\n\t}\n\n\t \n\twmb();\n\temac_tx_tpd_mark_last(adpt, tx_q);\n\n\t \n\ttpbuf->skb = skb;\n\n\treturn;\n\nerror:\n\t \n\ttx_q->tpd.produce_idx = first;\n\n\twhile (count--) {\n\t\ttpbuf = GET_TPD_BUFFER(tx_q, first);\n\t\tdma_unmap_page(adpt->netdev->dev.parent, tpbuf->dma_addr,\n\t\t\t       tpbuf->length, DMA_TO_DEVICE);\n\t\ttpbuf->dma_addr = 0;\n\t\ttpbuf->length = 0;\n\n\t\tif (++first == tx_q->tpd.count)\n\t\t\tfirst = 0;\n\t}\n\n\tdev_kfree_skb(skb);\n}\n\n \nnetdev_tx_t emac_mac_tx_buf_send(struct emac_adapter *adpt,\n\t\t\t\t struct emac_tx_queue *tx_q,\n\t\t\t\t struct sk_buff *skb)\n{\n\tstruct emac_tpd tpd;\n\tu32 prod_idx;\n\tint len;\n\n\tmemset(&tpd, 0, sizeof(tpd));\n\n\tif (emac_tso_csum(adpt, tx_q, skb, &tpd) != 0) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\tu16 tag;\n\n\t\tEMAC_VLAN_TO_TAG(skb_vlan_tag_get(skb), tag);\n\t\tTPD_CVLAN_TAG_SET(&tpd, tag);\n\t\tTPD_INSTC_SET(&tpd, 1);\n\t}\n\n\tif (skb_network_offset(skb) != ETH_HLEN)\n\t\tTPD_TYP_SET(&tpd, 1);\n\n\tlen = skb->len;\n\temac_tx_fill_tpd(adpt, tx_q, skb, &tpd);\n\n\tnetdev_sent_queue(adpt->netdev, len);\n\n\t \n\tif (emac_tpd_num_free_descs(tx_q) < (MAX_SKB_FRAGS + 3))\n\t\tnetif_stop_queue(adpt->netdev);\n\n\t \n\tprod_idx = (tx_q->tpd.produce_idx << tx_q->produce_shift) &\n\t\t    tx_q->produce_mask;\n\temac_reg_update32(adpt->base + tx_q->produce_reg,\n\t\t\t  tx_q->produce_mask, prod_idx);\n\n\treturn NETDEV_TX_OK;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}