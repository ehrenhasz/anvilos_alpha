{
  "module_name": "sparx5_qos.c",
  "hash_id": "3c3c305b3ca7116452ac97aab6fa897af47fc4cd2b1cf02a48da8f63c004242f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/microchip/sparx5/sparx5_qos.c",
  "human_readable_source": "\n \n\n#include <net/pkt_cls.h>\n\n#include \"sparx5_main.h\"\n#include \"sparx5_qos.h\"\n\n \nvoid sparx5_new_base_time(struct sparx5 *sparx5, const u32 cycle_time,\n\t\t\t  const ktime_t org_base_time, ktime_t *new_base_time)\n{\n\tktime_t current_time, threshold_time, new_time;\n\tstruct timespec64 ts;\n\tu64 nr_of_cycles_p2;\n\tu64 nr_of_cycles;\n\tu64 diff_time;\n\n\tnew_time = org_base_time;\n\n\tsparx5_ptp_gettime64(&sparx5->phc[SPARX5_PHC_PORT].info, &ts);\n\tcurrent_time = timespec64_to_ktime(ts);\n\tthreshold_time = current_time + (2 * cycle_time);\n\tdiff_time = threshold_time - new_time;\n\tnr_of_cycles = div_u64(diff_time, cycle_time);\n\tnr_of_cycles_p2 = 1;  \n\n\tif (new_time >= threshold_time) {\n\t\t*new_base_time = new_time;\n\t\treturn;\n\t}\n\n\t \n\twhile (nr_of_cycles_p2 < nr_of_cycles)\n\t\tnr_of_cycles_p2 <<= 1;  \n\n\t \n\twhile (nr_of_cycles_p2) {\n\t\tif (new_time < threshold_time) {\n\t\t\tnew_time += cycle_time * nr_of_cycles_p2;\n\t\t\twhile (new_time < threshold_time)\n\t\t\t\tnew_time += cycle_time * nr_of_cycles_p2;\n\t\t\tnew_time -= cycle_time * nr_of_cycles_p2;\n\t\t}\n\t\tnr_of_cycles_p2 >>= 1;  \n\t}\n\tnew_time += cycle_time;\n\t*new_base_time = new_time;\n}\n\n \nstatic const u32 spx5_hsch_max_group_rate[SPX5_HSCH_LEAK_GRP_CNT] = {\n\t1048568,  \n\t2621420,  \n\t10485680,  \n\t26214200  \n};\n\nstatic struct sparx5_layer layers[SPX5_HSCH_LAYER_CNT];\n\nstatic u32 sparx5_lg_get_leak_time(struct sparx5 *sparx5, u32 layer, u32 group)\n{\n\tu32 value;\n\n\tvalue = spx5_rd(sparx5, HSCH_HSCH_TIMER_CFG(layer, group));\n\treturn HSCH_HSCH_TIMER_CFG_LEAK_TIME_GET(value);\n}\n\nstatic void sparx5_lg_set_leak_time(struct sparx5 *sparx5, u32 layer, u32 group,\n\t\t\t\t    u32 leak_time)\n{\n\tspx5_wr(HSCH_HSCH_TIMER_CFG_LEAK_TIME_SET(leak_time), sparx5,\n\t\tHSCH_HSCH_TIMER_CFG(layer, group));\n}\n\nstatic u32 sparx5_lg_get_first(struct sparx5 *sparx5, u32 layer, u32 group)\n{\n\tu32 value;\n\n\tvalue = spx5_rd(sparx5, HSCH_HSCH_LEAK_CFG(layer, group));\n\treturn HSCH_HSCH_LEAK_CFG_LEAK_FIRST_GET(value);\n}\n\nstatic u32 sparx5_lg_get_next(struct sparx5 *sparx5, u32 layer, u32 group,\n\t\t\t      u32 idx)\n\n{\n\tu32 value;\n\n\tvalue = spx5_rd(sparx5, HSCH_SE_CONNECT(idx));\n\treturn HSCH_SE_CONNECT_SE_LEAK_LINK_GET(value);\n}\n\nstatic u32 sparx5_lg_get_last(struct sparx5 *sparx5, u32 layer, u32 group)\n{\n\tu32 itr, next;\n\n\titr = sparx5_lg_get_first(sparx5, layer, group);\n\n\tfor (;;) {\n\t\tnext = sparx5_lg_get_next(sparx5, layer, group, itr);\n\t\tif (itr == next)\n\t\t\treturn itr;\n\n\t\titr = next;\n\t}\n}\n\nstatic bool sparx5_lg_is_last(struct sparx5 *sparx5, u32 layer, u32 group,\n\t\t\t      u32 idx)\n{\n\treturn idx == sparx5_lg_get_next(sparx5, layer, group, idx);\n}\n\nstatic bool sparx5_lg_is_first(struct sparx5 *sparx5, u32 layer, u32 group,\n\t\t\t       u32 idx)\n{\n\treturn idx == sparx5_lg_get_first(sparx5, layer, group);\n}\n\nstatic bool sparx5_lg_is_empty(struct sparx5 *sparx5, u32 layer, u32 group)\n{\n\treturn sparx5_lg_get_leak_time(sparx5, layer, group) == 0;\n}\n\nstatic bool sparx5_lg_is_singular(struct sparx5 *sparx5, u32 layer, u32 group)\n{\n\tif (sparx5_lg_is_empty(sparx5, layer, group))\n\t\treturn false;\n\n\treturn sparx5_lg_get_first(sparx5, layer, group) ==\n\t       sparx5_lg_get_last(sparx5, layer, group);\n}\n\nstatic void sparx5_lg_enable(struct sparx5 *sparx5, u32 layer, u32 group,\n\t\t\t     u32 leak_time)\n{\n\tsparx5_lg_set_leak_time(sparx5, layer, group, leak_time);\n}\n\nstatic void sparx5_lg_disable(struct sparx5 *sparx5, u32 layer, u32 group)\n{\n\tsparx5_lg_set_leak_time(sparx5, layer, group, 0);\n}\n\nstatic int sparx5_lg_get_group_by_index(struct sparx5 *sparx5, u32 layer,\n\t\t\t\t\tu32 idx, u32 *group)\n{\n\tu32 itr, next;\n\tint i;\n\n\tfor (i = 0; i < SPX5_HSCH_LEAK_GRP_CNT; i++) {\n\t\tif (sparx5_lg_is_empty(sparx5, layer, i))\n\t\t\tcontinue;\n\n\t\titr = sparx5_lg_get_first(sparx5, layer, i);\n\n\t\tfor (;;) {\n\t\t\tnext = sparx5_lg_get_next(sparx5, layer, i, itr);\n\n\t\t\tif (itr == idx) {\n\t\t\t\t*group = i;\n\t\t\t\treturn 0;  \n\t\t\t}\n\t\t\tif (itr == next)\n\t\t\t\tbreak;  \n\n\t\t\titr = next;\n\t\t}\n\t}\n\n\treturn -1;\n}\n\nstatic int sparx5_lg_get_group_by_rate(u32 layer, u32 rate, u32 *group)\n{\n\tstruct sparx5_layer *l = &layers[layer];\n\tstruct sparx5_lg *lg;\n\tu32 i;\n\n\tfor (i = 0; i < SPX5_HSCH_LEAK_GRP_CNT; i++) {\n\t\tlg = &l->leak_groups[i];\n\t\tif (rate <= lg->max_rate) {\n\t\t\t*group = i;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -1;\n}\n\nstatic int sparx5_lg_get_adjacent(struct sparx5 *sparx5, u32 layer, u32 group,\n\t\t\t\t  u32 idx, u32 *prev, u32 *next, u32 *first)\n{\n\tu32 itr;\n\n\t*first = sparx5_lg_get_first(sparx5, layer, group);\n\t*prev = *first;\n\t*next = *first;\n\titr = *first;\n\n\tfor (;;) {\n\t\t*next = sparx5_lg_get_next(sparx5, layer, group, itr);\n\n\t\tif (itr == idx)\n\t\t\treturn 0;  \n\n\t\tif (itr == *next)\n\t\t\treturn -1;  \n\n\t\t*prev = itr;\n\t\titr = *next;\n\t}\n\n\treturn -1;\n}\n\nstatic int sparx5_lg_conf_set(struct sparx5 *sparx5, u32 layer, u32 group,\n\t\t\t      u32 se_first, u32 idx, u32 idx_next, bool empty)\n{\n\tu32 leak_time = layers[layer].leak_groups[group].leak_time;\n\n\t \n\tsparx5_lg_disable(sparx5, layer, group);\n\n\tif (empty)\n\t\treturn 0;\n\n\t \n\tspx5_rmw(HSCH_HSCH_CFG_CFG_HSCH_LAYER_SET(layer),\n\t\t HSCH_HSCH_CFG_CFG_HSCH_LAYER, sparx5, HSCH_HSCH_CFG_CFG);\n\n\t \n\tspx5_wr(HSCH_SE_CONNECT_SE_LEAK_LINK_SET(idx_next), sparx5,\n\t\tHSCH_SE_CONNECT(idx));\n\n\t \n\tspx5_rmw(HSCH_HSCH_LEAK_CFG_LEAK_FIRST_SET(se_first),\n\t\t HSCH_HSCH_LEAK_CFG_LEAK_FIRST, sparx5,\n\t\t HSCH_HSCH_LEAK_CFG(layer, group));\n\n\t \n\tsparx5_lg_enable(sparx5, layer, group, leak_time);\n\n\treturn 0;\n}\n\nstatic int sparx5_lg_del(struct sparx5 *sparx5, u32 layer, u32 group, u32 idx)\n{\n\tu32 first, next, prev;\n\tbool empty = false;\n\n\t \n\tWARN_ON(sparx5_lg_get_adjacent(sparx5, layer, group, idx, &prev, &next,\n\t\t\t\t       &first) < 0);\n\n\tif (sparx5_lg_is_singular(sparx5, layer, group)) {\n\t\tempty = true;\n\t} else if (sparx5_lg_is_last(sparx5, layer, group, idx)) {\n\t\t \n\t\tidx = prev;\n\t\tnext = prev;\n\t} else if (sparx5_lg_is_first(sparx5, layer, group, idx)) {\n\t\t \n\t\tfirst = next;\n\t\tnext = idx;\n\t} else {\n\t\t \n\t\tidx = prev;\n\t}\n\n\treturn sparx5_lg_conf_set(sparx5, layer, group, first, idx, next,\n\t\t\t\t  empty);\n}\n\nstatic int sparx5_lg_add(struct sparx5 *sparx5, u32 layer, u32 new_group,\n\t\t\t u32 idx)\n{\n\tu32 first, next, old_group;\n\n\tpr_debug(\"ADD: layer: %d, new_group: %d, idx: %d\", layer, new_group,\n\t\t idx);\n\n\t \n\tif (sparx5_lg_get_group_by_index(sparx5, layer, idx, &old_group) >= 0) {\n\t\tif (old_group != new_group) {\n\t\t\t \n\t\t\tsparx5_lg_del(sparx5, layer, old_group, idx);\n\t\t} else {\n\t\t\t \n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\tfirst = idx;\n\n\tif (sparx5_lg_is_empty(sparx5, layer, new_group))\n\t\tnext = idx;\n\telse\n\t\tnext = sparx5_lg_get_first(sparx5, layer, new_group);\n\n\treturn sparx5_lg_conf_set(sparx5, layer, new_group, first, idx, next,\n\t\t\t\t  false);\n}\n\nstatic int sparx5_shaper_conf_set(struct sparx5_port *port,\n\t\t\t\t  const struct sparx5_shaper *sh, u32 layer,\n\t\t\t\t  u32 idx, u32 group)\n{\n\tint (*sparx5_lg_action)(struct sparx5 *, u32, u32, u32);\n\tstruct sparx5 *sparx5 = port->sparx5;\n\n\tif (!sh->rate && !sh->burst)\n\t\tsparx5_lg_action = &sparx5_lg_del;\n\telse\n\t\tsparx5_lg_action = &sparx5_lg_add;\n\n\t \n\tspx5_rmw(HSCH_HSCH_CFG_CFG_HSCH_LAYER_SET(layer),\n\t\t HSCH_HSCH_CFG_CFG_HSCH_LAYER, sparx5, HSCH_HSCH_CFG_CFG);\n\n\t \n\tspx5_rmw(HSCH_SE_CFG_SE_FRM_MODE_SET(sh->mode), HSCH_SE_CFG_SE_FRM_MODE,\n\t\t sparx5, HSCH_SE_CFG(idx));\n\n\t \n\tspx5_wr(HSCH_CIR_CFG_CIR_RATE_SET(sh->rate) |\n\t\t\tHSCH_CIR_CFG_CIR_BURST_SET(sh->burst),\n\t\tsparx5, HSCH_CIR_CFG(idx));\n\n\t \n\tsparx5_lg_action(sparx5, layer, group, idx);\n\n\treturn 0;\n}\n\nstatic u32 sparx5_weight_to_hw_cost(u32 weight_min, u32 weight)\n{\n\treturn ((((SPX5_DWRR_COST_MAX << 4) * weight_min / weight) + 8) >> 4) -\n\t       1;\n}\n\nstatic int sparx5_dwrr_conf_set(struct sparx5_port *port,\n\t\t\t\tstruct sparx5_dwrr *dwrr)\n{\n\tint i;\n\n\tspx5_rmw(HSCH_HSCH_CFG_CFG_HSCH_LAYER_SET(2) |\n\t\t HSCH_HSCH_CFG_CFG_CFG_SE_IDX_SET(port->portno),\n\t\t HSCH_HSCH_CFG_CFG_HSCH_LAYER | HSCH_HSCH_CFG_CFG_CFG_SE_IDX,\n\t\t port->sparx5, HSCH_HSCH_CFG_CFG);\n\n\t \n\tspx5_rmw(HSCH_SE_CFG_SE_DWRR_CNT_SET(dwrr->count),\n\t\t HSCH_SE_CFG_SE_DWRR_CNT, port->sparx5,\n\t\t HSCH_SE_CFG(port->portno));\n\n\tfor (i = 0; i < dwrr->count; i++) {\n\t\tspx5_rmw(HSCH_DWRR_ENTRY_DWRR_COST_SET(dwrr->cost[i]),\n\t\t\t HSCH_DWRR_ENTRY_DWRR_COST, port->sparx5,\n\t\t\t HSCH_DWRR_ENTRY(i));\n\t}\n\n\treturn 0;\n}\n\nstatic int sparx5_leak_groups_init(struct sparx5 *sparx5)\n{\n\tstruct sparx5_layer *layer;\n\tu32 sys_clk_per_100ps;\n\tstruct sparx5_lg *lg;\n\tu32 leak_time_us;\n\tint i, ii;\n\n\tsys_clk_per_100ps = spx5_rd(sparx5, HSCH_SYS_CLK_PER);\n\n\tfor (i = 0; i < SPX5_HSCH_LAYER_CNT; i++) {\n\t\tlayer = &layers[i];\n\t\tfor (ii = 0; ii < SPX5_HSCH_LEAK_GRP_CNT; ii++) {\n\t\t\tlg = &layer->leak_groups[ii];\n\t\t\tlg->max_rate = spx5_hsch_max_group_rate[ii];\n\n\t\t\t \n\t\t\tleak_time_us = (SPX5_SE_RATE_MAX * 1000) / lg->max_rate;\n\n\t\t\t \n\t\t\tlg->leak_time = 1000 * leak_time_us;\n\n\t\t\t \n\t\t\tlg->resolution = 1000 / leak_time_us;\n\n\t\t\t \n\t\t\tlg->max_ses = (1000 * leak_time_us) / sys_clk_per_100ps;\n\n\t\t\t \n\n\t\t\t \n\t\t\tsparx5_lg_disable(sparx5, i, ii);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint sparx5_qos_init(struct sparx5 *sparx5)\n{\n\tint ret;\n\n\tret = sparx5_leak_groups_init(sparx5);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = sparx5_dcb_init(sparx5);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tsparx5_psfp_init(sparx5);\n\n\treturn 0;\n}\n\nint sparx5_tc_mqprio_add(struct net_device *ndev, u8 num_tc)\n{\n\tint i;\n\n\tif (num_tc != SPX5_PRIOS) {\n\t\tnetdev_err(ndev, \"Only %d traffic classes supported\\n\",\n\t\t\t   SPX5_PRIOS);\n\t\treturn -EINVAL;\n\t}\n\n\tnetdev_set_num_tc(ndev, num_tc);\n\n\tfor (i = 0; i < num_tc; i++)\n\t\tnetdev_set_tc_queue(ndev, i, 1, i);\n\n\tnetdev_dbg(ndev, \"dev->num_tc %u dev->real_num_tx_queues %u\\n\",\n\t\t   ndev->num_tc, ndev->real_num_tx_queues);\n\n\treturn 0;\n}\n\nint sparx5_tc_mqprio_del(struct net_device *ndev)\n{\n\tnetdev_reset_tc(ndev);\n\n\tnetdev_dbg(ndev, \"dev->num_tc %u dev->real_num_tx_queues %u\\n\",\n\t\t   ndev->num_tc, ndev->real_num_tx_queues);\n\n\treturn 0;\n}\n\nint sparx5_tc_tbf_add(struct sparx5_port *port,\n\t\t      struct tc_tbf_qopt_offload_replace_params *params,\n\t\t      u32 layer, u32 idx)\n{\n\tstruct sparx5_shaper sh = {\n\t\t.mode = SPX5_SE_MODE_DATARATE,\n\t\t.rate = div_u64(params->rate.rate_bytes_ps, 1000) * 8,\n\t\t.burst = params->max_size,\n\t};\n\tstruct sparx5_lg *lg;\n\tu32 group;\n\n\t \n\tif (sparx5_lg_get_group_by_rate(layer, sh.rate, &group) < 0) {\n\t\tpr_debug(\"Could not find leak group for se with rate: %d\",\n\t\t\t sh.rate);\n\t\treturn -EINVAL;\n\t}\n\n\tlg = &layers[layer].leak_groups[group];\n\n\tpr_debug(\"Found matching group (speed: %d)\\n\", lg->max_rate);\n\n\tif (sh.rate < SPX5_SE_RATE_MIN || sh.burst < SPX5_SE_BURST_MIN)\n\t\treturn -EINVAL;\n\n\t \n\tsh.rate = DIV_ROUND_UP(sh.rate, lg->resolution);\n\tsh.burst = DIV_ROUND_UP(sh.burst, SPX5_SE_BURST_UNIT);\n\n\tif (sh.rate > SPX5_SE_RATE_MAX || sh.burst > SPX5_SE_BURST_MAX)\n\t\treturn -EINVAL;\n\n\treturn sparx5_shaper_conf_set(port, &sh, layer, idx, group);\n}\n\nint sparx5_tc_tbf_del(struct sparx5_port *port, u32 layer, u32 idx)\n{\n\tstruct sparx5_shaper sh = {0};\n\tu32 group;\n\n\tsparx5_lg_get_group_by_index(port->sparx5, layer, idx, &group);\n\n\treturn sparx5_shaper_conf_set(port, &sh, layer, idx, group);\n}\n\nint sparx5_tc_ets_add(struct sparx5_port *port,\n\t\t      struct tc_ets_qopt_offload_replace_params *params)\n{\n\tstruct sparx5_dwrr dwrr = {0};\n\t \n\tunsigned int w_min = 100;\n\tint i;\n\n\t \n\tfor (i = 0; i < SPX5_PRIOS; i++) {\n\t\tif (params->quanta[i] == 0)\n\t\t\tcontinue;\n\t\tw_min = min(w_min, params->weights[i]);\n\t}\n\n\tfor (i = 0; i < SPX5_PRIOS; i++) {\n\t\t \n\t\tif (params->quanta[i] == 0)\n\t\t\tcontinue;\n\n\t\tdwrr.count++;\n\n\t\t \n\t\tdwrr.cost[SPX5_PRIOS - i - 1] =\n\t\t\tsparx5_weight_to_hw_cost(w_min, params->weights[i]);\n\t}\n\n\treturn sparx5_dwrr_conf_set(port, &dwrr);\n}\n\nint sparx5_tc_ets_del(struct sparx5_port *port)\n{\n\tstruct sparx5_dwrr dwrr = {0};\n\n\treturn sparx5_dwrr_conf_set(port, &dwrr);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}