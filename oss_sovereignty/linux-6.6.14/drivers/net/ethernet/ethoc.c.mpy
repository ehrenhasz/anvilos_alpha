{
  "module_name": "ethoc.c",
  "hash_id": "2f229f960143688a8ff558bc35f35fc9f2f49d0fcf49516e0fd5e01c2d7c1460",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ethoc.c",
  "human_readable_source": "\n \n\n#include <linux/dma-mapping.h>\n#include <linux/etherdevice.h>\n#include <linux/clk.h>\n#include <linux/crc32.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/mii.h>\n#include <linux/phy.h>\n#include <linux/platform_device.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/of.h>\n#include <linux/of_net.h>\n#include <linux/module.h>\n#include <net/ethoc.h>\n\nstatic int buffer_size = 0x8000;  \nmodule_param(buffer_size, int, 0);\nMODULE_PARM_DESC(buffer_size, \"DMA buffer allocation size\");\n\n \n#define\tMODER\t\t0x00\n#define\tINT_SOURCE\t0x04\n#define\tINT_MASK\t0x08\n#define\tIPGT\t\t0x0c\n#define\tIPGR1\t\t0x10\n#define\tIPGR2\t\t0x14\n#define\tPACKETLEN\t0x18\n#define\tCOLLCONF\t0x1c\n#define\tTX_BD_NUM\t0x20\n#define\tCTRLMODER\t0x24\n#define\tMIIMODER\t0x28\n#define\tMIICOMMAND\t0x2c\n#define\tMIIADDRESS\t0x30\n#define\tMIITX_DATA\t0x34\n#define\tMIIRX_DATA\t0x38\n#define\tMIISTATUS\t0x3c\n#define\tMAC_ADDR0\t0x40\n#define\tMAC_ADDR1\t0x44\n#define\tETH_HASH0\t0x48\n#define\tETH_HASH1\t0x4c\n#define\tETH_TXCTRL\t0x50\n#define\tETH_END\t\t0x54\n\n \n#define\tMODER_RXEN\t(1 <<  0)  \n#define\tMODER_TXEN\t(1 <<  1)  \n#define\tMODER_NOPRE\t(1 <<  2)  \n#define\tMODER_BRO\t(1 <<  3)  \n#define\tMODER_IAM\t(1 <<  4)  \n#define\tMODER_PRO\t(1 <<  5)  \n#define\tMODER_IFG\t(1 <<  6)  \n#define\tMODER_LOOP\t(1 <<  7)  \n#define\tMODER_NBO\t(1 <<  8)  \n#define\tMODER_EDE\t(1 <<  9)  \n#define\tMODER_FULLD\t(1 << 10)  \n#define\tMODER_RESET\t(1 << 11)  \n#define\tMODER_DCRC\t(1 << 12)  \n#define\tMODER_CRC\t(1 << 13)  \n#define\tMODER_HUGE\t(1 << 14)  \n#define\tMODER_PAD\t(1 << 15)  \n#define\tMODER_RSM\t(1 << 16)  \n\n \n#define\tINT_MASK_TXF\t(1 << 0)  \n#define\tINT_MASK_TXE\t(1 << 1)  \n#define\tINT_MASK_RXF\t(1 << 2)  \n#define\tINT_MASK_RXE\t(1 << 3)  \n#define\tINT_MASK_BUSY\t(1 << 4)\n#define\tINT_MASK_TXC\t(1 << 5)  \n#define\tINT_MASK_RXC\t(1 << 6)  \n\n#define\tINT_MASK_TX\t(INT_MASK_TXF | INT_MASK_TXE)\n#define\tINT_MASK_RX\t(INT_MASK_RXF | INT_MASK_RXE)\n\n#define\tINT_MASK_ALL ( \\\n\t\tINT_MASK_TXF | INT_MASK_TXE | \\\n\t\tINT_MASK_RXF | INT_MASK_RXE | \\\n\t\tINT_MASK_TXC | INT_MASK_RXC | \\\n\t\tINT_MASK_BUSY \\\n\t)\n\n \n#define\tPACKETLEN_MIN(min)\t\t(((min) & 0xffff) << 16)\n#define\tPACKETLEN_MAX(max)\t\t(((max) & 0xffff) <<  0)\n#define\tPACKETLEN_MIN_MAX(min, max)\t(PACKETLEN_MIN(min) | \\\n\t\t\t\t\tPACKETLEN_MAX(max))\n\n \n#define\tTX_BD_NUM_VAL(x)\t(((x) <= 0x80) ? (x) : 0x80)\n\n \n#define\tCTRLMODER_PASSALL\t(1 << 0)  \n#define\tCTRLMODER_RXFLOW\t(1 << 1)  \n#define\tCTRLMODER_TXFLOW\t(1 << 2)  \n\n \n#define\tMIIMODER_CLKDIV(x)\t((x) & 0xfe)  \n#define\tMIIMODER_NOPRE\t\t(1 << 8)  \n\n \n#define\tMIICOMMAND_SCAN\t\t(1 << 0)  \n#define\tMIICOMMAND_READ\t\t(1 << 1)  \n#define\tMIICOMMAND_WRITE\t(1 << 2)  \n\n \n#define\tMIIADDRESS_FIAD(x)\t\t(((x) & 0x1f) << 0)\n#define\tMIIADDRESS_RGAD(x)\t\t(((x) & 0x1f) << 8)\n#define\tMIIADDRESS_ADDR(phy, reg)\t(MIIADDRESS_FIAD(phy) | \\\n\t\t\t\t\tMIIADDRESS_RGAD(reg))\n\n \n#define\tMIITX_DATA_VAL(x)\t((x) & 0xffff)\n\n \n#define\tMIIRX_DATA_VAL(x)\t((x) & 0xffff)\n\n \n#define\tMIISTATUS_LINKFAIL\t(1 << 0)\n#define\tMIISTATUS_BUSY\t\t(1 << 1)\n#define\tMIISTATUS_INVALID\t(1 << 2)\n\n \n#define\tTX_BD_CS\t\t(1 <<  0)  \n#define\tTX_BD_DF\t\t(1 <<  1)  \n#define\tTX_BD_LC\t\t(1 <<  2)  \n#define\tTX_BD_RL\t\t(1 <<  3)  \n#define\tTX_BD_RETRY_MASK\t(0x00f0)\n#define\tTX_BD_RETRY(x)\t\t(((x) & 0x00f0) >>  4)\n#define\tTX_BD_UR\t\t(1 <<  8)  \n#define\tTX_BD_CRC\t\t(1 << 11)  \n#define\tTX_BD_PAD\t\t(1 << 12)  \n#define\tTX_BD_WRAP\t\t(1 << 13)\n#define\tTX_BD_IRQ\t\t(1 << 14)  \n#define\tTX_BD_READY\t\t(1 << 15)  \n#define\tTX_BD_LEN(x)\t\t(((x) & 0xffff) << 16)\n#define\tTX_BD_LEN_MASK\t\t(0xffff << 16)\n\n#define\tTX_BD_STATS\t\t(TX_BD_CS | TX_BD_DF | TX_BD_LC | \\\n\t\t\t\tTX_BD_RL | TX_BD_RETRY_MASK | TX_BD_UR)\n\n \n#define\tRX_BD_LC\t(1 <<  0)  \n#define\tRX_BD_CRC\t(1 <<  1)  \n#define\tRX_BD_SF\t(1 <<  2)  \n#define\tRX_BD_TL\t(1 <<  3)  \n#define\tRX_BD_DN\t(1 <<  4)  \n#define\tRX_BD_IS\t(1 <<  5)  \n#define\tRX_BD_OR\t(1 <<  6)  \n#define\tRX_BD_MISS\t(1 <<  7)\n#define\tRX_BD_CF\t(1 <<  8)  \n#define\tRX_BD_WRAP\t(1 << 13)\n#define\tRX_BD_IRQ\t(1 << 14)  \n#define\tRX_BD_EMPTY\t(1 << 15)\n#define\tRX_BD_LEN(x)\t(((x) & 0xffff) << 16)\n\n#define\tRX_BD_STATS\t(RX_BD_LC | RX_BD_CRC | RX_BD_SF | RX_BD_TL | \\\n\t\t\tRX_BD_DN | RX_BD_IS | RX_BD_OR | RX_BD_MISS)\n\n#define\tETHOC_BUFSIZ\t\t1536\n#define\tETHOC_ZLEN\t\t64\n#define\tETHOC_BD_BASE\t\t0x400\n#define\tETHOC_TIMEOUT\t\t(HZ / 2)\n#define\tETHOC_MII_TIMEOUT\t(1 + (HZ / 5))\n\n \nstruct ethoc {\n\tvoid __iomem *iobase;\n\tvoid __iomem *membase;\n\tbool big_endian;\n\n\tunsigned int num_bd;\n\tunsigned int num_tx;\n\tunsigned int cur_tx;\n\tunsigned int dty_tx;\n\n\tunsigned int num_rx;\n\tunsigned int cur_rx;\n\n\tvoid **vma;\n\n\tstruct net_device *netdev;\n\tstruct napi_struct napi;\n\tu32 msg_enable;\n\n\tspinlock_t lock;\n\n\tstruct mii_bus *mdio;\n\tstruct clk *clk;\n\ts8 phy_id;\n\n\tint old_link;\n\tint old_duplex;\n};\n\n \nstruct ethoc_bd {\n\tu32 stat;\n\tu32 addr;\n};\n\nstatic inline u32 ethoc_read(struct ethoc *dev, loff_t offset)\n{\n\tif (dev->big_endian)\n\t\treturn ioread32be(dev->iobase + offset);\n\telse\n\t\treturn ioread32(dev->iobase + offset);\n}\n\nstatic inline void ethoc_write(struct ethoc *dev, loff_t offset, u32 data)\n{\n\tif (dev->big_endian)\n\t\tiowrite32be(data, dev->iobase + offset);\n\telse\n\t\tiowrite32(data, dev->iobase + offset);\n}\n\nstatic inline void ethoc_read_bd(struct ethoc *dev, int index,\n\t\tstruct ethoc_bd *bd)\n{\n\tloff_t offset = ETHOC_BD_BASE + (index * sizeof(struct ethoc_bd));\n\tbd->stat = ethoc_read(dev, offset + 0);\n\tbd->addr = ethoc_read(dev, offset + 4);\n}\n\nstatic inline void ethoc_write_bd(struct ethoc *dev, int index,\n\t\tconst struct ethoc_bd *bd)\n{\n\tloff_t offset = ETHOC_BD_BASE + (index * sizeof(struct ethoc_bd));\n\tethoc_write(dev, offset + 0, bd->stat);\n\tethoc_write(dev, offset + 4, bd->addr);\n}\n\nstatic inline void ethoc_enable_irq(struct ethoc *dev, u32 mask)\n{\n\tu32 imask = ethoc_read(dev, INT_MASK);\n\timask |= mask;\n\tethoc_write(dev, INT_MASK, imask);\n}\n\nstatic inline void ethoc_disable_irq(struct ethoc *dev, u32 mask)\n{\n\tu32 imask = ethoc_read(dev, INT_MASK);\n\timask &= ~mask;\n\tethoc_write(dev, INT_MASK, imask);\n}\n\nstatic inline void ethoc_ack_irq(struct ethoc *dev, u32 mask)\n{\n\tethoc_write(dev, INT_SOURCE, mask);\n}\n\nstatic inline void ethoc_enable_rx_and_tx(struct ethoc *dev)\n{\n\tu32 mode = ethoc_read(dev, MODER);\n\tmode |= MODER_RXEN | MODER_TXEN;\n\tethoc_write(dev, MODER, mode);\n}\n\nstatic inline void ethoc_disable_rx_and_tx(struct ethoc *dev)\n{\n\tu32 mode = ethoc_read(dev, MODER);\n\tmode &= ~(MODER_RXEN | MODER_TXEN);\n\tethoc_write(dev, MODER, mode);\n}\n\nstatic int ethoc_init_ring(struct ethoc *dev, unsigned long mem_start)\n{\n\tstruct ethoc_bd bd;\n\tint i;\n\tvoid *vma;\n\n\tdev->cur_tx = 0;\n\tdev->dty_tx = 0;\n\tdev->cur_rx = 0;\n\n\tethoc_write(dev, TX_BD_NUM, dev->num_tx);\n\n\t \n\tbd.addr = mem_start;\n\tbd.stat = TX_BD_IRQ | TX_BD_CRC;\n\tvma = dev->membase;\n\n\tfor (i = 0; i < dev->num_tx; i++) {\n\t\tif (i == dev->num_tx - 1)\n\t\t\tbd.stat |= TX_BD_WRAP;\n\n\t\tethoc_write_bd(dev, i, &bd);\n\t\tbd.addr += ETHOC_BUFSIZ;\n\n\t\tdev->vma[i] = vma;\n\t\tvma += ETHOC_BUFSIZ;\n\t}\n\n\tbd.stat = RX_BD_EMPTY | RX_BD_IRQ;\n\n\tfor (i = 0; i < dev->num_rx; i++) {\n\t\tif (i == dev->num_rx - 1)\n\t\t\tbd.stat |= RX_BD_WRAP;\n\n\t\tethoc_write_bd(dev, dev->num_tx + i, &bd);\n\t\tbd.addr += ETHOC_BUFSIZ;\n\n\t\tdev->vma[dev->num_tx + i] = vma;\n\t\tvma += ETHOC_BUFSIZ;\n\t}\n\n\treturn 0;\n}\n\nstatic int ethoc_reset(struct ethoc *dev)\n{\n\tu32 mode;\n\n\t \n\n\tethoc_disable_rx_and_tx(dev);\n\n\t \n\n\t \n\tmode = ethoc_read(dev, MODER);\n\tmode |= MODER_CRC | MODER_PAD;\n\tethoc_write(dev, MODER, mode);\n\n\t \n\tmode = ethoc_read(dev, MODER);\n\tmode |= MODER_FULLD;\n\tethoc_write(dev, MODER, mode);\n\tethoc_write(dev, IPGT, 0x15);\n\n\tethoc_ack_irq(dev, INT_MASK_ALL);\n\tethoc_enable_irq(dev, INT_MASK_ALL);\n\tethoc_enable_rx_and_tx(dev);\n\treturn 0;\n}\n\nstatic unsigned int ethoc_update_rx_stats(struct ethoc *dev,\n\t\tstruct ethoc_bd *bd)\n{\n\tstruct net_device *netdev = dev->netdev;\n\tunsigned int ret = 0;\n\n\tif (bd->stat & RX_BD_TL) {\n\t\tdev_err(&netdev->dev, \"RX: frame too long\\n\");\n\t\tnetdev->stats.rx_length_errors++;\n\t\tret++;\n\t}\n\n\tif (bd->stat & RX_BD_SF) {\n\t\tdev_err(&netdev->dev, \"RX: frame too short\\n\");\n\t\tnetdev->stats.rx_length_errors++;\n\t\tret++;\n\t}\n\n\tif (bd->stat & RX_BD_DN) {\n\t\tdev_err(&netdev->dev, \"RX: dribble nibble\\n\");\n\t\tnetdev->stats.rx_frame_errors++;\n\t}\n\n\tif (bd->stat & RX_BD_CRC) {\n\t\tdev_err(&netdev->dev, \"RX: wrong CRC\\n\");\n\t\tnetdev->stats.rx_crc_errors++;\n\t\tret++;\n\t}\n\n\tif (bd->stat & RX_BD_OR) {\n\t\tdev_err(&netdev->dev, \"RX: overrun\\n\");\n\t\tnetdev->stats.rx_over_errors++;\n\t\tret++;\n\t}\n\n\tif (bd->stat & RX_BD_MISS)\n\t\tnetdev->stats.rx_missed_errors++;\n\n\tif (bd->stat & RX_BD_LC) {\n\t\tdev_err(&netdev->dev, \"RX: late collision\\n\");\n\t\tnetdev->stats.collisions++;\n\t\tret++;\n\t}\n\n\treturn ret;\n}\n\nstatic int ethoc_rx(struct net_device *dev, int limit)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tint count;\n\n\tfor (count = 0; count < limit; ++count) {\n\t\tunsigned int entry;\n\t\tstruct ethoc_bd bd;\n\n\t\tentry = priv->num_tx + priv->cur_rx;\n\t\tethoc_read_bd(priv, entry, &bd);\n\t\tif (bd.stat & RX_BD_EMPTY) {\n\t\t\tethoc_ack_irq(priv, INT_MASK_RX);\n\t\t\t \n\t\t\tethoc_read_bd(priv, entry, &bd);\n\t\t\tif (bd.stat & RX_BD_EMPTY)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (ethoc_update_rx_stats(priv, &bd) == 0) {\n\t\t\tint size = bd.stat >> 16;\n\t\t\tstruct sk_buff *skb;\n\n\t\t\tsize -= 4;  \n\t\t\tskb = netdev_alloc_skb_ip_align(dev, size);\n\n\t\t\tif (likely(skb)) {\n\t\t\t\tvoid *src = priv->vma[entry];\n\t\t\t\tmemcpy_fromio(skb_put(skb, size), src, size);\n\t\t\t\tskb->protocol = eth_type_trans(skb, dev);\n\t\t\t\tdev->stats.rx_packets++;\n\t\t\t\tdev->stats.rx_bytes += size;\n\t\t\t\tnetif_receive_skb(skb);\n\t\t\t} else {\n\t\t\t\tif (net_ratelimit())\n\t\t\t\t\tdev_warn(&dev->dev,\n\t\t\t\t\t    \"low on memory - packet dropped\\n\");\n\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tbd.stat &= ~RX_BD_STATS;\n\t\tbd.stat |=  RX_BD_EMPTY;\n\t\tethoc_write_bd(priv, entry, &bd);\n\t\tif (++priv->cur_rx == priv->num_rx)\n\t\t\tpriv->cur_rx = 0;\n\t}\n\n\treturn count;\n}\n\nstatic void ethoc_update_tx_stats(struct ethoc *dev, struct ethoc_bd *bd)\n{\n\tstruct net_device *netdev = dev->netdev;\n\n\tif (bd->stat & TX_BD_LC) {\n\t\tdev_err(&netdev->dev, \"TX: late collision\\n\");\n\t\tnetdev->stats.tx_window_errors++;\n\t}\n\n\tif (bd->stat & TX_BD_RL) {\n\t\tdev_err(&netdev->dev, \"TX: retransmit limit\\n\");\n\t\tnetdev->stats.tx_aborted_errors++;\n\t}\n\n\tif (bd->stat & TX_BD_UR) {\n\t\tdev_err(&netdev->dev, \"TX: underrun\\n\");\n\t\tnetdev->stats.tx_fifo_errors++;\n\t}\n\n\tif (bd->stat & TX_BD_CS) {\n\t\tdev_err(&netdev->dev, \"TX: carrier sense lost\\n\");\n\t\tnetdev->stats.tx_carrier_errors++;\n\t}\n\n\tif (bd->stat & TX_BD_STATS)\n\t\tnetdev->stats.tx_errors++;\n\n\tnetdev->stats.collisions += (bd->stat >> 4) & 0xf;\n\tnetdev->stats.tx_bytes += bd->stat >> 16;\n\tnetdev->stats.tx_packets++;\n}\n\nstatic int ethoc_tx(struct net_device *dev, int limit)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tint count;\n\tstruct ethoc_bd bd;\n\n\tfor (count = 0; count < limit; ++count) {\n\t\tunsigned int entry;\n\n\t\tentry = priv->dty_tx & (priv->num_tx-1);\n\n\t\tethoc_read_bd(priv, entry, &bd);\n\n\t\tif (bd.stat & TX_BD_READY || (priv->dty_tx == priv->cur_tx)) {\n\t\t\tethoc_ack_irq(priv, INT_MASK_TX);\n\t\t\t \n\t\t\tethoc_read_bd(priv, entry, &bd);\n\t\t\tif (bd.stat & TX_BD_READY ||\n\t\t\t    (priv->dty_tx == priv->cur_tx))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tethoc_update_tx_stats(priv, &bd);\n\t\tpriv->dty_tx++;\n\t}\n\n\tif ((priv->cur_tx - priv->dty_tx) <= (priv->num_tx / 2))\n\t\tnetif_wake_queue(dev);\n\n\treturn count;\n}\n\nstatic irqreturn_t ethoc_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *dev = dev_id;\n\tstruct ethoc *priv = netdev_priv(dev);\n\tu32 pending;\n\tu32 mask;\n\n\t \n\tmask = ethoc_read(priv, INT_MASK);\n\tpending = ethoc_read(priv, INT_SOURCE);\n\tpending &= mask;\n\n\tif (unlikely(pending == 0))\n\t\treturn IRQ_NONE;\n\n\tethoc_ack_irq(priv, pending);\n\n\t \n\tif (pending & INT_MASK_BUSY) {\n\t\tdev_dbg(&dev->dev, \"packet dropped\\n\");\n\t\tdev->stats.rx_dropped++;\n\t}\n\n\t \n\tif (pending & (INT_MASK_TX | INT_MASK_RX)) {\n\t\tethoc_disable_irq(priv, INT_MASK_TX | INT_MASK_RX);\n\t\tnapi_schedule(&priv->napi);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int ethoc_get_mac_address(struct net_device *dev, void *addr)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tu8 *mac = (u8 *)addr;\n\tu32 reg;\n\n\treg = ethoc_read(priv, MAC_ADDR0);\n\tmac[2] = (reg >> 24) & 0xff;\n\tmac[3] = (reg >> 16) & 0xff;\n\tmac[4] = (reg >>  8) & 0xff;\n\tmac[5] = (reg >>  0) & 0xff;\n\n\treg = ethoc_read(priv, MAC_ADDR1);\n\tmac[0] = (reg >>  8) & 0xff;\n\tmac[1] = (reg >>  0) & 0xff;\n\n\treturn 0;\n}\n\nstatic int ethoc_poll(struct napi_struct *napi, int budget)\n{\n\tstruct ethoc *priv = container_of(napi, struct ethoc, napi);\n\tint rx_work_done = 0;\n\tint tx_work_done = 0;\n\n\trx_work_done = ethoc_rx(priv->netdev, budget);\n\ttx_work_done = ethoc_tx(priv->netdev, budget);\n\n\tif (rx_work_done < budget && tx_work_done < budget) {\n\t\tnapi_complete_done(napi, rx_work_done);\n\t\tethoc_enable_irq(priv, INT_MASK_TX | INT_MASK_RX);\n\t}\n\n\treturn rx_work_done;\n}\n\nstatic int ethoc_mdio_read(struct mii_bus *bus, int phy, int reg)\n{\n\tstruct ethoc *priv = bus->priv;\n\tint i;\n\n\tethoc_write(priv, MIIADDRESS, MIIADDRESS_ADDR(phy, reg));\n\tethoc_write(priv, MIICOMMAND, MIICOMMAND_READ);\n\n\tfor (i = 0; i < 5; i++) {\n\t\tu32 status = ethoc_read(priv, MIISTATUS);\n\t\tif (!(status & MIISTATUS_BUSY)) {\n\t\t\tu32 data = ethoc_read(priv, MIIRX_DATA);\n\t\t\t \n\t\t\tethoc_write(priv, MIICOMMAND, 0);\n\t\t\treturn data;\n\t\t}\n\t\tusleep_range(100, 200);\n\t}\n\n\treturn -EBUSY;\n}\n\nstatic int ethoc_mdio_write(struct mii_bus *bus, int phy, int reg, u16 val)\n{\n\tstruct ethoc *priv = bus->priv;\n\tint i;\n\n\tethoc_write(priv, MIIADDRESS, MIIADDRESS_ADDR(phy, reg));\n\tethoc_write(priv, MIITX_DATA, val);\n\tethoc_write(priv, MIICOMMAND, MIICOMMAND_WRITE);\n\n\tfor (i = 0; i < 5; i++) {\n\t\tu32 stat = ethoc_read(priv, MIISTATUS);\n\t\tif (!(stat & MIISTATUS_BUSY)) {\n\t\t\t \n\t\t\tethoc_write(priv, MIICOMMAND, 0);\n\t\t\treturn 0;\n\t\t}\n\t\tusleep_range(100, 200);\n\t}\n\n\treturn -EBUSY;\n}\n\nstatic void ethoc_mdio_poll(struct net_device *dev)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tstruct phy_device *phydev = dev->phydev;\n\tbool changed = false;\n\tu32 mode;\n\n\tif (priv->old_link != phydev->link) {\n\t\tchanged = true;\n\t\tpriv->old_link = phydev->link;\n\t}\n\n\tif (priv->old_duplex != phydev->duplex) {\n\t\tchanged = true;\n\t\tpriv->old_duplex = phydev->duplex;\n\t}\n\n\tif (!changed)\n\t\treturn;\n\n\tmode = ethoc_read(priv, MODER);\n\tif (phydev->duplex == DUPLEX_FULL)\n\t\tmode |= MODER_FULLD;\n\telse\n\t\tmode &= ~MODER_FULLD;\n\tethoc_write(priv, MODER, mode);\n\n\tphy_print_status(phydev);\n}\n\nstatic int ethoc_mdio_probe(struct net_device *dev)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tstruct phy_device *phy;\n\tint err;\n\n\tif (priv->phy_id != -1)\n\t\tphy = mdiobus_get_phy(priv->mdio, priv->phy_id);\n\telse\n\t\tphy = phy_find_first(priv->mdio);\n\n\tif (!phy)\n\t\treturn dev_err_probe(&dev->dev, -ENXIO, \"no PHY found\\n\");\n\n\tpriv->old_duplex = -1;\n\tpriv->old_link = -1;\n\n\terr = phy_connect_direct(dev, phy, ethoc_mdio_poll,\n\t\t\t\t PHY_INTERFACE_MODE_GMII);\n\tif (err)\n\t\treturn dev_err_probe(&dev->dev, err, \"could not attach to PHY\\n\");\n\n\tphy_set_max_speed(phy, SPEED_100);\n\n\treturn 0;\n}\n\nstatic int ethoc_open(struct net_device *dev)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tint ret;\n\n\tret = request_irq(dev->irq, ethoc_interrupt, IRQF_SHARED,\n\t\t\tdev->name, dev);\n\tif (ret)\n\t\treturn ret;\n\n\tnapi_enable(&priv->napi);\n\n\tethoc_init_ring(priv, dev->mem_start);\n\tethoc_reset(priv);\n\n\tif (netif_queue_stopped(dev)) {\n\t\tdev_dbg(&dev->dev, \" resuming queue\\n\");\n\t\tnetif_wake_queue(dev);\n\t} else {\n\t\tdev_dbg(&dev->dev, \" starting queue\\n\");\n\t\tnetif_start_queue(dev);\n\t}\n\n\tpriv->old_link = -1;\n\tpriv->old_duplex = -1;\n\n\tphy_start(dev->phydev);\n\n\tif (netif_msg_ifup(priv)) {\n\t\tdev_info(&dev->dev, \"I/O: %08lx Memory: %08lx-%08lx\\n\",\n\t\t\t\tdev->base_addr, dev->mem_start, dev->mem_end);\n\t}\n\n\treturn 0;\n}\n\nstatic int ethoc_stop(struct net_device *dev)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\n\tnapi_disable(&priv->napi);\n\n\tif (dev->phydev)\n\t\tphy_stop(dev->phydev);\n\n\tethoc_disable_rx_and_tx(priv);\n\tfree_irq(dev->irq, dev);\n\n\tif (!netif_queue_stopped(dev))\n\t\tnetif_stop_queue(dev);\n\n\treturn 0;\n}\n\nstatic int ethoc_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tstruct mii_ioctl_data *mdio = if_mii(ifr);\n\tstruct phy_device *phy = NULL;\n\n\tif (!netif_running(dev))\n\t\treturn -EINVAL;\n\n\tif (cmd != SIOCGMIIPHY) {\n\t\tif (mdio->phy_id >= PHY_MAX_ADDR)\n\t\t\treturn -ERANGE;\n\n\t\tphy = mdiobus_get_phy(priv->mdio, mdio->phy_id);\n\t\tif (!phy)\n\t\t\treturn -ENODEV;\n\t} else {\n\t\tphy = dev->phydev;\n\t}\n\n\treturn phy_mii_ioctl(phy, ifr, cmd);\n}\n\nstatic void ethoc_do_set_mac_address(struct net_device *dev)\n{\n\tconst unsigned char *mac = dev->dev_addr;\n\tstruct ethoc *priv = netdev_priv(dev);\n\n\tethoc_write(priv, MAC_ADDR0, (mac[2] << 24) | (mac[3] << 16) |\n\t\t\t\t     (mac[4] <<  8) | (mac[5] <<  0));\n\tethoc_write(priv, MAC_ADDR1, (mac[0] <<  8) | (mac[1] <<  0));\n}\n\nstatic int ethoc_set_mac_address(struct net_device *dev, void *p)\n{\n\tconst struct sockaddr *addr = p;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\teth_hw_addr_set(dev, addr->sa_data);\n\tethoc_do_set_mac_address(dev);\n\treturn 0;\n}\n\nstatic void ethoc_set_multicast_list(struct net_device *dev)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tu32 mode = ethoc_read(priv, MODER);\n\tstruct netdev_hw_addr *ha;\n\tu32 hash[2] = { 0, 0 };\n\n\t \n\tif (dev->flags & IFF_LOOPBACK)\n\t\tmode |=  MODER_LOOP;\n\telse\n\t\tmode &= ~MODER_LOOP;\n\n\t \n\tif (dev->flags & IFF_BROADCAST)\n\t\tmode &= ~MODER_BRO;\n\telse\n\t\tmode |=  MODER_BRO;\n\n\t \n\tif (dev->flags & IFF_PROMISC)\n\t\tmode |=  MODER_PRO;\n\telse\n\t\tmode &= ~MODER_PRO;\n\n\tethoc_write(priv, MODER, mode);\n\n\t \n\tif (dev->flags & IFF_ALLMULTI) {\n\t\thash[0] = 0xffffffff;\n\t\thash[1] = 0xffffffff;\n\t} else {\n\t\tnetdev_for_each_mc_addr(ha, dev) {\n\t\t\tu32 crc = ether_crc(ETH_ALEN, ha->addr);\n\t\t\tint bit = (crc >> 26) & 0x3f;\n\t\t\thash[bit >> 5] |= 1 << (bit & 0x1f);\n\t\t}\n\t}\n\n\tethoc_write(priv, ETH_HASH0, hash[0]);\n\tethoc_write(priv, ETH_HASH1, hash[1]);\n}\n\nstatic int ethoc_change_mtu(struct net_device *dev, int new_mtu)\n{\n\treturn -ENOSYS;\n}\n\nstatic void ethoc_tx_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tu32 pending = ethoc_read(priv, INT_SOURCE);\n\tif (likely(pending))\n\t\tethoc_interrupt(dev->irq, dev);\n}\n\nstatic netdev_tx_t ethoc_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tstruct ethoc_bd bd;\n\tunsigned int entry;\n\tvoid *dest;\n\n\tif (skb_put_padto(skb, ETHOC_ZLEN)) {\n\t\tdev->stats.tx_errors++;\n\t\tgoto out_no_free;\n\t}\n\n\tif (unlikely(skb->len > ETHOC_BUFSIZ)) {\n\t\tdev->stats.tx_errors++;\n\t\tgoto out;\n\t}\n\n\tentry = priv->cur_tx % priv->num_tx;\n\tspin_lock_irq(&priv->lock);\n\tpriv->cur_tx++;\n\n\tethoc_read_bd(priv, entry, &bd);\n\tif (unlikely(skb->len < ETHOC_ZLEN))\n\t\tbd.stat |=  TX_BD_PAD;\n\telse\n\t\tbd.stat &= ~TX_BD_PAD;\n\n\tdest = priv->vma[entry];\n\tmemcpy_toio(dest, skb->data, skb->len);\n\n\tbd.stat &= ~(TX_BD_STATS | TX_BD_LEN_MASK);\n\tbd.stat |= TX_BD_LEN(skb->len);\n\tethoc_write_bd(priv, entry, &bd);\n\n\tbd.stat |= TX_BD_READY;\n\tethoc_write_bd(priv, entry, &bd);\n\n\tif (priv->cur_tx == (priv->dty_tx + priv->num_tx)) {\n\t\tdev_dbg(&dev->dev, \"stopping queue\\n\");\n\t\tnetif_stop_queue(dev);\n\t}\n\n\tspin_unlock_irq(&priv->lock);\n\tskb_tx_timestamp(skb);\nout:\n\tdev_kfree_skb(skb);\nout_no_free:\n\treturn NETDEV_TX_OK;\n}\n\nstatic int ethoc_get_regs_len(struct net_device *netdev)\n{\n\treturn ETH_END;\n}\n\nstatic void ethoc_get_regs(struct net_device *dev, struct ethtool_regs *regs,\n\t\t\t   void *p)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\tu32 *regs_buff = p;\n\tunsigned i;\n\n\tregs->version = 0;\n\tfor (i = 0; i < ETH_END / sizeof(u32); ++i)\n\t\tregs_buff[i] = ethoc_read(priv, i * sizeof(u32));\n}\n\nstatic void ethoc_get_ringparam(struct net_device *dev,\n\t\t\t\tstruct ethtool_ringparam *ring,\n\t\t\t\tstruct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\n\tring->rx_max_pending = priv->num_bd - 1;\n\tring->rx_mini_max_pending = 0;\n\tring->rx_jumbo_max_pending = 0;\n\tring->tx_max_pending = priv->num_bd - 1;\n\n\tring->rx_pending = priv->num_rx;\n\tring->rx_mini_pending = 0;\n\tring->rx_jumbo_pending = 0;\n\tring->tx_pending = priv->num_tx;\n}\n\nstatic int ethoc_set_ringparam(struct net_device *dev,\n\t\t\t       struct ethtool_ringparam *ring,\n\t\t\t       struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct ethoc *priv = netdev_priv(dev);\n\n\tif (ring->tx_pending < 1 || ring->rx_pending < 1 ||\n\t    ring->tx_pending + ring->rx_pending > priv->num_bd)\n\t\treturn -EINVAL;\n\tif (ring->rx_mini_pending || ring->rx_jumbo_pending)\n\t\treturn -EINVAL;\n\n\tif (netif_running(dev)) {\n\t\tnetif_tx_disable(dev);\n\t\tethoc_disable_rx_and_tx(priv);\n\t\tethoc_disable_irq(priv, INT_MASK_TX | INT_MASK_RX);\n\t\tsynchronize_irq(dev->irq);\n\t}\n\n\tpriv->num_tx = rounddown_pow_of_two(ring->tx_pending);\n\tpriv->num_rx = ring->rx_pending;\n\tethoc_init_ring(priv, dev->mem_start);\n\n\tif (netif_running(dev)) {\n\t\tethoc_enable_irq(priv, INT_MASK_TX | INT_MASK_RX);\n\t\tethoc_enable_rx_and_tx(priv);\n\t\tnetif_wake_queue(dev);\n\t}\n\treturn 0;\n}\n\nstatic const struct ethtool_ops ethoc_ethtool_ops = {\n\t.get_regs_len = ethoc_get_regs_len,\n\t.get_regs = ethoc_get_regs,\n\t.nway_reset = phy_ethtool_nway_reset,\n\t.get_link = ethtool_op_get_link,\n\t.get_ringparam = ethoc_get_ringparam,\n\t.set_ringparam = ethoc_set_ringparam,\n\t.get_ts_info = ethtool_op_get_ts_info,\n\t.get_link_ksettings = phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings = phy_ethtool_set_link_ksettings,\n};\n\nstatic const struct net_device_ops ethoc_netdev_ops = {\n\t.ndo_open = ethoc_open,\n\t.ndo_stop = ethoc_stop,\n\t.ndo_eth_ioctl = ethoc_ioctl,\n\t.ndo_set_mac_address = ethoc_set_mac_address,\n\t.ndo_set_rx_mode = ethoc_set_multicast_list,\n\t.ndo_change_mtu = ethoc_change_mtu,\n\t.ndo_tx_timeout = ethoc_tx_timeout,\n\t.ndo_start_xmit = ethoc_start_xmit,\n};\n\n \nstatic int ethoc_probe(struct platform_device *pdev)\n{\n\tstruct net_device *netdev = NULL;\n\tstruct resource *res = NULL;\n\tstruct resource *mmio = NULL;\n\tstruct resource *mem = NULL;\n\tstruct ethoc *priv = NULL;\n\tint num_bd;\n\tint ret = 0;\n\tstruct ethoc_platform_data *pdata = dev_get_platdata(&pdev->dev);\n\tu32 eth_clkfreq = pdata ? pdata->eth_clkfreq : 0;\n\n\t \n\tnetdev = alloc_etherdev(sizeof(struct ethoc));\n\tif (!netdev) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\tplatform_set_drvdata(pdev, netdev);\n\n\t \n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res) {\n\t\tdev_err(&pdev->dev, \"cannot obtain I/O memory space\\n\");\n\t\tret = -ENXIO;\n\t\tgoto free;\n\t}\n\n\tmmio = devm_request_mem_region(&pdev->dev, res->start,\n\t\t\tresource_size(res), res->name);\n\tif (!mmio) {\n\t\tdev_err(&pdev->dev, \"cannot request I/O memory space\\n\");\n\t\tret = -ENXIO;\n\t\tgoto free;\n\t}\n\n\tnetdev->base_addr = mmio->start;\n\n\t \n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 1);\n\tif (res) {\n\t\tmem = devm_request_mem_region(&pdev->dev, res->start,\n\t\t\tresource_size(res), res->name);\n\t\tif (!mem) {\n\t\t\tdev_err(&pdev->dev, \"cannot request memory space\\n\");\n\t\t\tret = -ENXIO;\n\t\t\tgoto free;\n\t\t}\n\n\t\tnetdev->mem_start = mem->start;\n\t\tnetdev->mem_end   = mem->end;\n\t}\n\n\n\t \n\tret = platform_get_irq(pdev, 0);\n\tif (ret < 0)\n\t\tgoto free;\n\n\tnetdev->irq = ret;\n\n\t \n\tpriv = netdev_priv(netdev);\n\tpriv->netdev = netdev;\n\n\tpriv->iobase = devm_ioremap(&pdev->dev, netdev->base_addr,\n\t\t\tresource_size(mmio));\n\tif (!priv->iobase) {\n\t\tdev_err(&pdev->dev, \"cannot remap I/O memory space\\n\");\n\t\tret = -ENXIO;\n\t\tgoto free;\n\t}\n\n\tif (netdev->mem_end) {\n\t\tpriv->membase = devm_ioremap(&pdev->dev,\n\t\t\tnetdev->mem_start, resource_size(mem));\n\t\tif (!priv->membase) {\n\t\t\tdev_err(&pdev->dev, \"cannot remap memory space\\n\");\n\t\t\tret = -ENXIO;\n\t\t\tgoto free;\n\t\t}\n\t} else {\n\t\t \n\t\tpriv->membase = dmam_alloc_coherent(&pdev->dev,\n\t\t\tbuffer_size, (void *)&netdev->mem_start,\n\t\t\tGFP_KERNEL);\n\t\tif (!priv->membase) {\n\t\t\tdev_err(&pdev->dev, \"cannot allocate %dB buffer\\n\",\n\t\t\t\tbuffer_size);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto free;\n\t\t}\n\t\tnetdev->mem_end = netdev->mem_start + buffer_size;\n\t}\n\n\tpriv->big_endian = pdata ? pdata->big_endian :\n\t\tof_device_is_big_endian(pdev->dev.of_node);\n\n\t \n\tnum_bd = min_t(unsigned int,\n\t\t128, (netdev->mem_end - netdev->mem_start + 1) / ETHOC_BUFSIZ);\n\tif (num_bd < 4) {\n\t\tret = -ENODEV;\n\t\tgoto free;\n\t}\n\tpriv->num_bd = num_bd;\n\t \n\tpriv->num_tx = rounddown_pow_of_two(num_bd >> 1);\n\tpriv->num_rx = num_bd - priv->num_tx;\n\n\tdev_dbg(&pdev->dev, \"ethoc: num_tx: %d num_rx: %d\\n\",\n\t\tpriv->num_tx, priv->num_rx);\n\n\tpriv->vma = devm_kcalloc(&pdev->dev, num_bd, sizeof(void *),\n\t\t\t\t GFP_KERNEL);\n\tif (!priv->vma) {\n\t\tret = -ENOMEM;\n\t\tgoto free;\n\t}\n\n\t \n\tif (pdata) {\n\t\teth_hw_addr_set(netdev, pdata->hwaddr);\n\t\tpriv->phy_id = pdata->phy_id;\n\t} else {\n\t\tof_get_ethdev_address(pdev->dev.of_node, netdev);\n\t\tpriv->phy_id = -1;\n\t}\n\n\t \n\tif (!is_valid_ether_addr(netdev->dev_addr)) {\n\t\tu8 addr[ETH_ALEN];\n\n\t\tethoc_get_mac_address(netdev, addr);\n\t\teth_hw_addr_set(netdev, addr);\n\t}\n\n\t \n\tif (!is_valid_ether_addr(netdev->dev_addr))\n\t\teth_hw_addr_random(netdev);\n\n\tethoc_do_set_mac_address(netdev);\n\n\t \n\tif (!eth_clkfreq) {\n\t\tstruct clk *clk = devm_clk_get(&pdev->dev, NULL);\n\n\t\tif (!IS_ERR(clk)) {\n\t\t\tpriv->clk = clk;\n\t\t\tclk_prepare_enable(clk);\n\t\t\teth_clkfreq = clk_get_rate(clk);\n\t\t}\n\t}\n\tif (eth_clkfreq) {\n\t\tu32 clkdiv = MIIMODER_CLKDIV(eth_clkfreq / 2500000 + 1);\n\n\t\tif (!clkdiv)\n\t\t\tclkdiv = 2;\n\t\tdev_dbg(&pdev->dev, \"setting MII clkdiv to %u\\n\", clkdiv);\n\t\tethoc_write(priv, MIIMODER,\n\t\t\t    (ethoc_read(priv, MIIMODER) & MIIMODER_NOPRE) |\n\t\t\t    clkdiv);\n\t}\n\n\t \n\tpriv->mdio = mdiobus_alloc();\n\tif (!priv->mdio) {\n\t\tret = -ENOMEM;\n\t\tgoto free2;\n\t}\n\n\tpriv->mdio->name = \"ethoc-mdio\";\n\tsnprintf(priv->mdio->id, MII_BUS_ID_SIZE, \"%s-%d\",\n\t\t\tpriv->mdio->name, pdev->id);\n\tpriv->mdio->read = ethoc_mdio_read;\n\tpriv->mdio->write = ethoc_mdio_write;\n\tpriv->mdio->priv = priv;\n\n\tret = mdiobus_register(priv->mdio);\n\tif (ret) {\n\t\tdev_err(&netdev->dev, \"failed to register MDIO bus\\n\");\n\t\tgoto free3;\n\t}\n\n\tret = ethoc_mdio_probe(netdev);\n\tif (ret) {\n\t\tdev_err(&netdev->dev, \"failed to probe MDIO bus\\n\");\n\t\tgoto error;\n\t}\n\n\t \n\tnetdev->netdev_ops = &ethoc_netdev_ops;\n\tnetdev->watchdog_timeo = ETHOC_TIMEOUT;\n\tnetdev->features |= 0;\n\tnetdev->ethtool_ops = &ethoc_ethtool_ops;\n\n\t \n\tnetif_napi_add(netdev, &priv->napi, ethoc_poll);\n\n\tspin_lock_init(&priv->lock);\n\n\tret = register_netdev(netdev);\n\tif (ret < 0) {\n\t\tdev_err(&netdev->dev, \"failed to register interface\\n\");\n\t\tgoto error2;\n\t}\n\n\tgoto out;\n\nerror2:\n\tnetif_napi_del(&priv->napi);\nerror:\n\tmdiobus_unregister(priv->mdio);\nfree3:\n\tmdiobus_free(priv->mdio);\nfree2:\n\tclk_disable_unprepare(priv->clk);\nfree:\n\tfree_netdev(netdev);\nout:\n\treturn ret;\n}\n\n \nstatic int ethoc_remove(struct platform_device *pdev)\n{\n\tstruct net_device *netdev = platform_get_drvdata(pdev);\n\tstruct ethoc *priv = netdev_priv(netdev);\n\n\tif (netdev) {\n\t\tnetif_napi_del(&priv->napi);\n\t\tphy_disconnect(netdev->phydev);\n\n\t\tif (priv->mdio) {\n\t\t\tmdiobus_unregister(priv->mdio);\n\t\t\tmdiobus_free(priv->mdio);\n\t\t}\n\t\tclk_disable_unprepare(priv->clk);\n\t\tunregister_netdev(netdev);\n\t\tfree_netdev(netdev);\n\t}\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM\nstatic int ethoc_suspend(struct platform_device *pdev, pm_message_t state)\n{\n\treturn -ENOSYS;\n}\n\nstatic int ethoc_resume(struct platform_device *pdev)\n{\n\treturn -ENOSYS;\n}\n#else\n# define ethoc_suspend NULL\n# define ethoc_resume  NULL\n#endif\n\nstatic const struct of_device_id ethoc_match[] = {\n\t{ .compatible = \"opencores,ethoc\", },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, ethoc_match);\n\nstatic struct platform_driver ethoc_driver = {\n\t.probe   = ethoc_probe,\n\t.remove  = ethoc_remove,\n\t.suspend = ethoc_suspend,\n\t.resume  = ethoc_resume,\n\t.driver  = {\n\t\t.name = \"ethoc\",\n\t\t.of_match_table = ethoc_match,\n\t},\n};\n\nmodule_platform_driver(ethoc_driver);\n\nMODULE_AUTHOR(\"Thierry Reding <thierry.reding@avionic-design.de>\");\nMODULE_DESCRIPTION(\"OpenCores Ethernet MAC driver\");\nMODULE_LICENSE(\"GPL v2\");\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}