{
  "module_name": "acenic.c",
  "hash_id": "0b7d4a6ace23e8b284de3e661084633666d883c75e3e5f1dd3f938052c48fcc7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/alteon/acenic.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <linux/ioport.h>\n#include <linux/pci.h>\n#include <linux/dma-mapping.h>\n#include <linux/kernel.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/delay.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/sockios.h>\n#include <linux/firmware.h>\n#include <linux/slab.h>\n#include <linux/prefetch.h>\n#include <linux/if_vlan.h>\n\n#ifdef SIOCETHTOOL\n#include <linux/ethtool.h>\n#endif\n\n#include <net/sock.h>\n#include <net/ip.h>\n\n#include <asm/io.h>\n#include <asm/irq.h>\n#include <asm/byteorder.h>\n#include <linux/uaccess.h>\n\n\n#define DRV_NAME \"acenic\"\n\n#undef INDEX_DEBUG\n\n#ifdef CONFIG_ACENIC_OMIT_TIGON_I\n#define ACE_IS_TIGON_I(ap)\t0\n#define ACE_TX_RING_ENTRIES(ap)\tMAX_TX_RING_ENTRIES\n#else\n#define ACE_IS_TIGON_I(ap)\t(ap->version == 1)\n#define ACE_TX_RING_ENTRIES(ap)\tap->tx_ring_entries\n#endif\n\n#ifndef PCI_VENDOR_ID_ALTEON\n#define PCI_VENDOR_ID_ALTEON\t\t0x12ae\n#endif\n#ifndef PCI_DEVICE_ID_ALTEON_ACENIC_FIBRE\n#define PCI_DEVICE_ID_ALTEON_ACENIC_FIBRE  0x0001\n#define PCI_DEVICE_ID_ALTEON_ACENIC_COPPER 0x0002\n#endif\n#ifndef PCI_DEVICE_ID_3COM_3C985\n#define PCI_DEVICE_ID_3COM_3C985\t0x0001\n#endif\n#ifndef PCI_VENDOR_ID_NETGEAR\n#define PCI_VENDOR_ID_NETGEAR\t\t0x1385\n#define PCI_DEVICE_ID_NETGEAR_GA620\t0x620a\n#endif\n#ifndef PCI_DEVICE_ID_NETGEAR_GA620T\n#define PCI_DEVICE_ID_NETGEAR_GA620T\t0x630a\n#endif\n\n\n \n#ifndef PCI_DEVICE_ID_FARALLON_PN9000SX\n#define PCI_DEVICE_ID_FARALLON_PN9000SX\t0x1a\n#endif\n#ifndef PCI_DEVICE_ID_FARALLON_PN9100T\n#define PCI_DEVICE_ID_FARALLON_PN9100T  0xfa\n#endif\n#ifndef PCI_VENDOR_ID_SGI\n#define PCI_VENDOR_ID_SGI\t\t0x10a9\n#endif\n#ifndef PCI_DEVICE_ID_SGI_ACENIC\n#define PCI_DEVICE_ID_SGI_ACENIC\t0x0009\n#endif\n\nstatic const struct pci_device_id acenic_pci_tbl[] = {\n\t{ PCI_VENDOR_ID_ALTEON, PCI_DEVICE_ID_ALTEON_ACENIC_FIBRE,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t{ PCI_VENDOR_ID_ALTEON, PCI_DEVICE_ID_ALTEON_ACENIC_COPPER,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t{ PCI_VENDOR_ID_3COM, PCI_DEVICE_ID_3COM_3C985,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t{ PCI_VENDOR_ID_NETGEAR, PCI_DEVICE_ID_NETGEAR_GA620,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t{ PCI_VENDOR_ID_NETGEAR, PCI_DEVICE_ID_NETGEAR_GA620T,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t \n\t{ PCI_VENDOR_ID_DEC, PCI_DEVICE_ID_FARALLON_PN9000SX,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t{ PCI_VENDOR_ID_ALTEON, PCI_DEVICE_ID_FARALLON_PN9100T,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t{ PCI_VENDOR_ID_SGI, PCI_DEVICE_ID_SGI_ACENIC,\n\t  PCI_ANY_ID, PCI_ANY_ID, PCI_CLASS_NETWORK_ETHERNET << 8, 0xffff00, },\n\t{ }\n};\nMODULE_DEVICE_TABLE(pci, acenic_pci_tbl);\n\n#define ace_sync_irq(irq)\tsynchronize_irq(irq)\n\n#ifndef offset_in_page\n#define offset_in_page(ptr)\t((unsigned long)(ptr) & ~PAGE_MASK)\n#endif\n\n#define ACE_MAX_MOD_PARMS\t8\n#define BOARD_IDX_STATIC\t0\n#define BOARD_IDX_OVERFLOW\t-1\n\n#include \"acenic.h\"\n\n \n#define MAX_TEXT_LEN\t96*1024\n#define MAX_RODATA_LEN\t8*1024\n#define MAX_DATA_LEN\t2*1024\n\n#ifndef tigon2FwReleaseLocal\n#define tigon2FwReleaseLocal 0\n#endif\n\n \n\n \n#define RX_RING_SIZE\t\t72\n#define RX_MINI_SIZE\t\t64\n#define RX_JUMBO_SIZE\t\t48\n\n#define RX_PANIC_STD_THRES\t16\n#define RX_PANIC_STD_REFILL\t(3*RX_PANIC_STD_THRES)/2\n#define RX_LOW_STD_THRES\t(3*RX_RING_SIZE)/4\n#define RX_PANIC_MINI_THRES\t12\n#define RX_PANIC_MINI_REFILL\t(3*RX_PANIC_MINI_THRES)/2\n#define RX_LOW_MINI_THRES\t(3*RX_MINI_SIZE)/4\n#define RX_PANIC_JUMBO_THRES\t6\n#define RX_PANIC_JUMBO_REFILL\t(3*RX_PANIC_JUMBO_THRES)/2\n#define RX_LOW_JUMBO_THRES\t(3*RX_JUMBO_SIZE)/4\n\n\n \n#define ACE_MINI_SIZE\t\t100\n\n#define ACE_MINI_BUFSIZE\tACE_MINI_SIZE\n#define ACE_STD_BUFSIZE\t\t(ACE_STD_MTU + ETH_HLEN + 4)\n#define ACE_JUMBO_BUFSIZE\t(ACE_JUMBO_MTU + ETH_HLEN + 4)\n\n \n#define DEF_TX_COAL\t\t400  \n#define DEF_TX_MAX_DESC\t\t60   \n#define DEF_RX_COAL\t\t120  \n#define DEF_RX_MAX_DESC\t\t25\n#define DEF_TX_RATIO\t\t21  \n\n#define DEF_JUMBO_TX_COAL\t20\n#define DEF_JUMBO_TX_MAX_DESC\t60\n#define DEF_JUMBO_RX_COAL\t30\n#define DEF_JUMBO_RX_MAX_DESC\t6\n#define DEF_JUMBO_TX_RATIO\t21\n\n#if tigon2FwReleaseLocal < 20001118\n \n#define TX_COAL_INTS_ONLY\t1\t \n#else\n \n#define TX_COAL_INTS_ONLY\t1\n#endif\n\n#define DEF_TRACE\t\t0\n#define DEF_STAT\t\t(2 * TICKS_PER_SEC)\n\n\nstatic int link_state[ACE_MAX_MOD_PARMS];\nstatic int trace[ACE_MAX_MOD_PARMS];\nstatic int tx_coal_tick[ACE_MAX_MOD_PARMS];\nstatic int rx_coal_tick[ACE_MAX_MOD_PARMS];\nstatic int max_tx_desc[ACE_MAX_MOD_PARMS];\nstatic int max_rx_desc[ACE_MAX_MOD_PARMS];\nstatic int tx_ratio[ACE_MAX_MOD_PARMS];\nstatic int dis_pci_mem_inval[ACE_MAX_MOD_PARMS] = {1, 1, 1, 1, 1, 1, 1, 1};\n\nMODULE_AUTHOR(\"Jes Sorensen <jes@trained-monkey.org>\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"AceNIC/3C985/GA620 Gigabit Ethernet driver\");\n#ifndef CONFIG_ACENIC_OMIT_TIGON_I\nMODULE_FIRMWARE(\"acenic/tg1.bin\");\n#endif\nMODULE_FIRMWARE(\"acenic/tg2.bin\");\n\nmodule_param_array_named(link, link_state, int, NULL, 0);\nmodule_param_array(trace, int, NULL, 0);\nmodule_param_array(tx_coal_tick, int, NULL, 0);\nmodule_param_array(max_tx_desc, int, NULL, 0);\nmodule_param_array(rx_coal_tick, int, NULL, 0);\nmodule_param_array(max_rx_desc, int, NULL, 0);\nmodule_param_array(tx_ratio, int, NULL, 0);\nMODULE_PARM_DESC(link, \"AceNIC/3C985/NetGear link state\");\nMODULE_PARM_DESC(trace, \"AceNIC/3C985/NetGear firmware trace level\");\nMODULE_PARM_DESC(tx_coal_tick, \"AceNIC/3C985/GA620 max clock ticks to wait from first tx descriptor arrives\");\nMODULE_PARM_DESC(max_tx_desc, \"AceNIC/3C985/GA620 max number of transmit descriptors to wait\");\nMODULE_PARM_DESC(rx_coal_tick, \"AceNIC/3C985/GA620 max clock ticks to wait from first rx descriptor arrives\");\nMODULE_PARM_DESC(max_rx_desc, \"AceNIC/3C985/GA620 max number of receive descriptors to wait\");\nMODULE_PARM_DESC(tx_ratio, \"AceNIC/3C985/GA620 ratio of NIC memory used for TX/RX descriptors (range 0-63)\");\n\n\nstatic const char version[] =\n  \"acenic.c: v0.92 08/05/2002  Jes Sorensen, linux-acenic@SunSITE.dk\\n\"\n  \"                            http://home.cern.ch/~jes/gige/acenic.html\\n\";\n\nstatic int ace_get_link_ksettings(struct net_device *,\n\t\t\t\t  struct ethtool_link_ksettings *);\nstatic int ace_set_link_ksettings(struct net_device *,\n\t\t\t\t  const struct ethtool_link_ksettings *);\nstatic void ace_get_drvinfo(struct net_device *, struct ethtool_drvinfo *);\n\nstatic const struct ethtool_ops ace_ethtool_ops = {\n\t.get_drvinfo = ace_get_drvinfo,\n\t.get_link_ksettings = ace_get_link_ksettings,\n\t.set_link_ksettings = ace_set_link_ksettings,\n};\n\nstatic void ace_watchdog(struct net_device *dev, unsigned int txqueue);\n\nstatic const struct net_device_ops ace_netdev_ops = {\n\t.ndo_open\t\t= ace_open,\n\t.ndo_stop\t\t= ace_close,\n\t.ndo_tx_timeout\t\t= ace_watchdog,\n\t.ndo_get_stats\t\t= ace_get_stats,\n\t.ndo_start_xmit\t\t= ace_start_xmit,\n\t.ndo_set_rx_mode\t= ace_set_multicast_list,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= ace_set_mac_addr,\n\t.ndo_change_mtu\t\t= ace_change_mtu,\n};\n\nstatic int acenic_probe_one(struct pci_dev *pdev,\n\t\t\t    const struct pci_device_id *id)\n{\n\tstruct net_device *dev;\n\tstruct ace_private *ap;\n\tstatic int boards_found;\n\n\tdev = alloc_etherdev(sizeof(struct ace_private));\n\tif (dev == NULL)\n\t\treturn -ENOMEM;\n\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\tap = netdev_priv(dev);\n\tap->ndev = dev;\n\tap->pdev = pdev;\n\tap->name = pci_name(pdev);\n\n\tdev->features |= NETIF_F_SG | NETIF_F_IP_CSUM;\n\tdev->features |= NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX;\n\n\tdev->watchdog_timeo = 5*HZ;\n\tdev->min_mtu = 0;\n\tdev->max_mtu = ACE_JUMBO_MTU;\n\n\tdev->netdev_ops = &ace_netdev_ops;\n\tdev->ethtool_ops = &ace_ethtool_ops;\n\n\t \n\tif (!boards_found)\n\t\tprintk(version);\n\n\tif (pci_enable_device(pdev))\n\t\tgoto fail_free_netdev;\n\n\t \n\tpci_set_master(pdev);\n\n\tpci_read_config_word(pdev, PCI_COMMAND, &ap->pci_command);\n\n\t \n\tif (!(ap->pci_command & PCI_COMMAND_MEMORY)) {\n\t\tprintk(KERN_INFO \"%s: Enabling PCI Memory Mapped \"\n\t\t       \"access - was not enabled by BIOS/Firmware\\n\",\n\t\t       ap->name);\n\t\tap->pci_command = ap->pci_command | PCI_COMMAND_MEMORY;\n\t\tpci_write_config_word(ap->pdev, PCI_COMMAND,\n\t\t\t\t      ap->pci_command);\n\t\twmb();\n\t}\n\n\tpci_read_config_byte(pdev, PCI_LATENCY_TIMER, &ap->pci_latency);\n\tif (ap->pci_latency <= 0x40) {\n\t\tap->pci_latency = 0x40;\n\t\tpci_write_config_byte(pdev, PCI_LATENCY_TIMER, ap->pci_latency);\n\t}\n\n\t \n\tdev->base_addr = pci_resource_start(pdev, 0);\n\tap->regs = ioremap(dev->base_addr, 0x4000);\n\tif (!ap->regs) {\n\t\tprintk(KERN_ERR \"%s:  Unable to map I/O register, \"\n\t\t       \"AceNIC %i will be disabled.\\n\",\n\t\t       ap->name, boards_found);\n\t\tgoto fail_free_netdev;\n\t}\n\n\tswitch(pdev->vendor) {\n\tcase PCI_VENDOR_ID_ALTEON:\n\t\tif (pdev->device == PCI_DEVICE_ID_FARALLON_PN9100T) {\n\t\t\tprintk(KERN_INFO \"%s: Farallon PN9100-T \",\n\t\t\t       ap->name);\n\t\t} else {\n\t\t\tprintk(KERN_INFO \"%s: Alteon AceNIC \",\n\t\t\t       ap->name);\n\t\t}\n\t\tbreak;\n\tcase PCI_VENDOR_ID_3COM:\n\t\tprintk(KERN_INFO \"%s: 3Com 3C985 \", ap->name);\n\t\tbreak;\n\tcase PCI_VENDOR_ID_NETGEAR:\n\t\tprintk(KERN_INFO \"%s: NetGear GA620 \", ap->name);\n\t\tbreak;\n\tcase PCI_VENDOR_ID_DEC:\n\t\tif (pdev->device == PCI_DEVICE_ID_FARALLON_PN9000SX) {\n\t\t\tprintk(KERN_INFO \"%s: Farallon PN9000-SX \",\n\t\t\t       ap->name);\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\n\tcase PCI_VENDOR_ID_SGI:\n\t\tprintk(KERN_INFO \"%s: SGI AceNIC \", ap->name);\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_INFO \"%s: Unknown AceNIC \", ap->name);\n\t\tbreak;\n\t}\n\n\tprintk(\"Gigabit Ethernet at 0x%08lx, \", dev->base_addr);\n\tprintk(\"irq %d\\n\", pdev->irq);\n\n#ifdef CONFIG_ACENIC_OMIT_TIGON_I\n\tif ((readl(&ap->regs->HostCtrl) >> 28) == 4) {\n\t\tprintk(KERN_ERR \"%s: Driver compiled without Tigon I\"\n\t\t       \" support - NIC disabled\\n\", dev->name);\n\t\tgoto fail_uninit;\n\t}\n#endif\n\n\tif (ace_allocate_descriptors(dev))\n\t\tgoto fail_free_netdev;\n\n#ifdef MODULE\n\tif (boards_found >= ACE_MAX_MOD_PARMS)\n\t\tap->board_idx = BOARD_IDX_OVERFLOW;\n\telse\n\t\tap->board_idx = boards_found;\n#else\n\tap->board_idx = BOARD_IDX_STATIC;\n#endif\n\n\tif (ace_init(dev))\n\t\tgoto fail_free_netdev;\n\n\tif (register_netdev(dev)) {\n\t\tprintk(KERN_ERR \"acenic: device registration failed\\n\");\n\t\tgoto fail_uninit;\n\t}\n\tap->name = dev->name;\n\n\tdev->features |= NETIF_F_HIGHDMA;\n\n\tpci_set_drvdata(pdev, dev);\n\n\tboards_found++;\n\treturn 0;\n\n fail_uninit:\n\tace_init_cleanup(dev);\n fail_free_netdev:\n\tfree_netdev(dev);\n\treturn -ENODEV;\n}\n\nstatic void acenic_remove_one(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tshort i;\n\n\tunregister_netdev(dev);\n\n\twritel(readl(&regs->CpuCtrl) | CPU_HALT, &regs->CpuCtrl);\n\tif (ap->version >= 2)\n\t\twritel(readl(&regs->CpuBCtrl) | CPU_HALT, &regs->CpuBCtrl);\n\n\t \n\twritel(1, &regs->Mb0Lo);\n\treadl(&regs->CpuCtrl);\t \n\n\t \n\tace_sync_irq(dev->irq);\n\n\tfor (i = 0; i < RX_STD_RING_ENTRIES; i++) {\n\t\tstruct sk_buff *skb = ap->skb->rx_std_skbuff[i].skb;\n\n\t\tif (skb) {\n\t\t\tstruct ring_info *ringp;\n\t\t\tdma_addr_t mapping;\n\n\t\t\tringp = &ap->skb->rx_std_skbuff[i];\n\t\t\tmapping = dma_unmap_addr(ringp, mapping);\n\t\t\tdma_unmap_page(&ap->pdev->dev, mapping,\n\t\t\t\t       ACE_STD_BUFSIZE, DMA_FROM_DEVICE);\n\n\t\t\tap->rx_std_ring[i].size = 0;\n\t\t\tap->skb->rx_std_skbuff[i].skb = NULL;\n\t\t\tdev_kfree_skb(skb);\n\t\t}\n\t}\n\n\tif (ap->version >= 2) {\n\t\tfor (i = 0; i < RX_MINI_RING_ENTRIES; i++) {\n\t\t\tstruct sk_buff *skb = ap->skb->rx_mini_skbuff[i].skb;\n\n\t\t\tif (skb) {\n\t\t\t\tstruct ring_info *ringp;\n\t\t\t\tdma_addr_t mapping;\n\n\t\t\t\tringp = &ap->skb->rx_mini_skbuff[i];\n\t\t\t\tmapping = dma_unmap_addr(ringp,mapping);\n\t\t\t\tdma_unmap_page(&ap->pdev->dev, mapping,\n\t\t\t\t\t       ACE_MINI_BUFSIZE,\n\t\t\t\t\t       DMA_FROM_DEVICE);\n\n\t\t\t\tap->rx_mini_ring[i].size = 0;\n\t\t\t\tap->skb->rx_mini_skbuff[i].skb = NULL;\n\t\t\t\tdev_kfree_skb(skb);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = 0; i < RX_JUMBO_RING_ENTRIES; i++) {\n\t\tstruct sk_buff *skb = ap->skb->rx_jumbo_skbuff[i].skb;\n\t\tif (skb) {\n\t\t\tstruct ring_info *ringp;\n\t\t\tdma_addr_t mapping;\n\n\t\t\tringp = &ap->skb->rx_jumbo_skbuff[i];\n\t\t\tmapping = dma_unmap_addr(ringp, mapping);\n\t\t\tdma_unmap_page(&ap->pdev->dev, mapping,\n\t\t\t\t       ACE_JUMBO_BUFSIZE, DMA_FROM_DEVICE);\n\n\t\t\tap->rx_jumbo_ring[i].size = 0;\n\t\t\tap->skb->rx_jumbo_skbuff[i].skb = NULL;\n\t\t\tdev_kfree_skb(skb);\n\t\t}\n\t}\n\n\tace_init_cleanup(dev);\n\tfree_netdev(dev);\n}\n\nstatic struct pci_driver acenic_pci_driver = {\n\t.name\t\t= \"acenic\",\n\t.id_table\t= acenic_pci_tbl,\n\t.probe\t\t= acenic_probe_one,\n\t.remove\t\t= acenic_remove_one,\n};\n\nstatic void ace_free_descriptors(struct net_device *dev)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tint size;\n\n\tif (ap->rx_std_ring != NULL) {\n\t\tsize = (sizeof(struct rx_desc) *\n\t\t\t(RX_STD_RING_ENTRIES +\n\t\t\t RX_JUMBO_RING_ENTRIES +\n\t\t\t RX_MINI_RING_ENTRIES +\n\t\t\t RX_RETURN_RING_ENTRIES));\n\t\tdma_free_coherent(&ap->pdev->dev, size, ap->rx_std_ring,\n\t\t\t\t  ap->rx_ring_base_dma);\n\t\tap->rx_std_ring = NULL;\n\t\tap->rx_jumbo_ring = NULL;\n\t\tap->rx_mini_ring = NULL;\n\t\tap->rx_return_ring = NULL;\n\t}\n\tif (ap->evt_ring != NULL) {\n\t\tsize = (sizeof(struct event) * EVT_RING_ENTRIES);\n\t\tdma_free_coherent(&ap->pdev->dev, size, ap->evt_ring,\n\t\t\t\t  ap->evt_ring_dma);\n\t\tap->evt_ring = NULL;\n\t}\n\tif (ap->tx_ring != NULL && !ACE_IS_TIGON_I(ap)) {\n\t\tsize = (sizeof(struct tx_desc) * MAX_TX_RING_ENTRIES);\n\t\tdma_free_coherent(&ap->pdev->dev, size, ap->tx_ring,\n\t\t\t\t  ap->tx_ring_dma);\n\t}\n\tap->tx_ring = NULL;\n\n\tif (ap->evt_prd != NULL) {\n\t\tdma_free_coherent(&ap->pdev->dev, sizeof(u32),\n\t\t\t\t  (void *)ap->evt_prd, ap->evt_prd_dma);\n\t\tap->evt_prd = NULL;\n\t}\n\tif (ap->rx_ret_prd != NULL) {\n\t\tdma_free_coherent(&ap->pdev->dev, sizeof(u32),\n\t\t\t\t  (void *)ap->rx_ret_prd, ap->rx_ret_prd_dma);\n\t\tap->rx_ret_prd = NULL;\n\t}\n\tif (ap->tx_csm != NULL) {\n\t\tdma_free_coherent(&ap->pdev->dev, sizeof(u32),\n\t\t\t\t  (void *)ap->tx_csm, ap->tx_csm_dma);\n\t\tap->tx_csm = NULL;\n\t}\n}\n\n\nstatic int ace_allocate_descriptors(struct net_device *dev)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tint size;\n\n\tsize = (sizeof(struct rx_desc) *\n\t\t(RX_STD_RING_ENTRIES +\n\t\t RX_JUMBO_RING_ENTRIES +\n\t\t RX_MINI_RING_ENTRIES +\n\t\t RX_RETURN_RING_ENTRIES));\n\n\tap->rx_std_ring = dma_alloc_coherent(&ap->pdev->dev, size,\n\t\t\t\t\t     &ap->rx_ring_base_dma, GFP_KERNEL);\n\tif (ap->rx_std_ring == NULL)\n\t\tgoto fail;\n\n\tap->rx_jumbo_ring = ap->rx_std_ring + RX_STD_RING_ENTRIES;\n\tap->rx_mini_ring = ap->rx_jumbo_ring + RX_JUMBO_RING_ENTRIES;\n\tap->rx_return_ring = ap->rx_mini_ring + RX_MINI_RING_ENTRIES;\n\n\tsize = (sizeof(struct event) * EVT_RING_ENTRIES);\n\n\tap->evt_ring = dma_alloc_coherent(&ap->pdev->dev, size,\n\t\t\t\t\t  &ap->evt_ring_dma, GFP_KERNEL);\n\n\tif (ap->evt_ring == NULL)\n\t\tgoto fail;\n\n\t \n\tif (!ACE_IS_TIGON_I(ap)) {\n\t\tsize = (sizeof(struct tx_desc) * MAX_TX_RING_ENTRIES);\n\n\t\tap->tx_ring = dma_alloc_coherent(&ap->pdev->dev, size,\n\t\t\t\t\t\t &ap->tx_ring_dma, GFP_KERNEL);\n\n\t\tif (ap->tx_ring == NULL)\n\t\t\tgoto fail;\n\t}\n\n\tap->evt_prd = dma_alloc_coherent(&ap->pdev->dev, sizeof(u32),\n\t\t\t\t\t &ap->evt_prd_dma, GFP_KERNEL);\n\tif (ap->evt_prd == NULL)\n\t\tgoto fail;\n\n\tap->rx_ret_prd = dma_alloc_coherent(&ap->pdev->dev, sizeof(u32),\n\t\t\t\t\t    &ap->rx_ret_prd_dma, GFP_KERNEL);\n\tif (ap->rx_ret_prd == NULL)\n\t\tgoto fail;\n\n\tap->tx_csm = dma_alloc_coherent(&ap->pdev->dev, sizeof(u32),\n\t\t\t\t\t&ap->tx_csm_dma, GFP_KERNEL);\n\tif (ap->tx_csm == NULL)\n\t\tgoto fail;\n\n\treturn 0;\n\nfail:\n\t \n\tace_init_cleanup(dev);\n\treturn 1;\n}\n\n\n \nstatic void ace_init_cleanup(struct net_device *dev)\n{\n\tstruct ace_private *ap;\n\n\tap = netdev_priv(dev);\n\n\tace_free_descriptors(dev);\n\n\tif (ap->info)\n\t\tdma_free_coherent(&ap->pdev->dev, sizeof(struct ace_info),\n\t\t\t\t  ap->info, ap->info_dma);\n\tkfree(ap->skb);\n\tkfree(ap->trace_buf);\n\n\tif (dev->irq)\n\t\tfree_irq(dev->irq, dev);\n\n\tiounmap(ap->regs);\n}\n\n\n \nstatic inline void ace_issue_cmd(struct ace_regs __iomem *regs, struct cmd *cmd)\n{\n\tu32 idx;\n\n\tidx = readl(&regs->CmdPrd);\n\n\twritel(*(u32 *)(cmd), &regs->CmdRng[idx]);\n\tidx = (idx + 1) % CMD_RING_ENTRIES;\n\n\twritel(idx, &regs->CmdPrd);\n}\n\n\nstatic int ace_init(struct net_device *dev)\n{\n\tstruct ace_private *ap;\n\tstruct ace_regs __iomem *regs;\n\tstruct ace_info *info = NULL;\n\tstruct pci_dev *pdev;\n\tunsigned long myjif;\n\tu64 tmp_ptr;\n\tu32 tig_ver, mac1, mac2, tmp, pci_state;\n\tint board_idx, ecode = 0;\n\tshort i;\n\tunsigned char cache_size;\n\tu8 addr[ETH_ALEN];\n\n\tap = netdev_priv(dev);\n\tregs = ap->regs;\n\n\tboard_idx = ap->board_idx;\n\n\t \n\twritel(HW_RESET | (HW_RESET << 24), &regs->HostCtrl);\n\treadl(&regs->HostCtrl);\t\t \n\tudelay(5);\n\n\t \n#ifdef __BIG_ENDIAN\n\t \n\twritel((WORD_SWAP | CLR_INT | ((WORD_SWAP | CLR_INT) << 24)),\n\t       &regs->HostCtrl);\n#else\n\twritel((CLR_INT | WORD_SWAP | ((CLR_INT | WORD_SWAP) << 24)),\n\t       &regs->HostCtrl);\n#endif\n\treadl(&regs->HostCtrl);\t\t \n\n\t \n\twritel(readl(&regs->CpuCtrl) | CPU_HALT, &regs->CpuCtrl);\n\treadl(&regs->CpuCtrl);\t\t \n\twritel(0, &regs->Mb0Lo);\n\n\ttig_ver = readl(&regs->HostCtrl) >> 28;\n\n\tswitch(tig_ver){\n#ifndef CONFIG_ACENIC_OMIT_TIGON_I\n\tcase 4:\n\tcase 5:\n\t\tprintk(KERN_INFO \"  Tigon I  (Rev. %i), Firmware: %i.%i.%i, \",\n\t\t       tig_ver, ap->firmware_major, ap->firmware_minor,\n\t\t       ap->firmware_fix);\n\t\twritel(0, &regs->LocalCtrl);\n\t\tap->version = 1;\n\t\tap->tx_ring_entries = TIGON_I_TX_RING_ENTRIES;\n\t\tbreak;\n#endif\n\tcase 6:\n\t\tprintk(KERN_INFO \"  Tigon II (Rev. %i), Firmware: %i.%i.%i, \",\n\t\t       tig_ver, ap->firmware_major, ap->firmware_minor,\n\t\t       ap->firmware_fix);\n\t\twritel(readl(&regs->CpuBCtrl) | CPU_HALT, &regs->CpuBCtrl);\n\t\treadl(&regs->CpuBCtrl);\t\t \n\t\t \n\t\twritel(SRAM_BANK_512K, &regs->LocalCtrl);\n\t\twritel(SYNC_SRAM_TIMING, &regs->MiscCfg);\n\t\tap->version = 2;\n\t\tap->tx_ring_entries = MAX_TX_RING_ENTRIES;\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_WARNING \"  Unsupported Tigon version detected \"\n\t\t       \"(%i)\\n\", tig_ver);\n\t\tecode = -ENODEV;\n\t\tgoto init_error;\n\t}\n\n\t \n#ifdef __BIG_ENDIAN\n\twritel(ACE_BYTE_SWAP_DMA | ACE_WARN | ACE_FATAL | ACE_BYTE_SWAP_BD |\n\t       ACE_WORD_SWAP_BD | ACE_NO_JUMBO_FRAG, &regs->ModeStat);\n#else\n\twritel(ACE_BYTE_SWAP_DMA | ACE_WARN | ACE_FATAL |\n\t       ACE_WORD_SWAP_BD | ACE_NO_JUMBO_FRAG, &regs->ModeStat);\n#endif\n\treadl(&regs->ModeStat);\t\t \n\n\tmac1 = 0;\n\tfor(i = 0; i < 4; i++) {\n\t\tint t;\n\n\t\tmac1 = mac1 << 8;\n\t\tt = read_eeprom_byte(dev, 0x8c+i);\n\t\tif (t < 0) {\n\t\t\tecode = -EIO;\n\t\t\tgoto init_error;\n\t\t} else\n\t\t\tmac1 |= (t & 0xff);\n\t}\n\tmac2 = 0;\n\tfor(i = 4; i < 8; i++) {\n\t\tint t;\n\n\t\tmac2 = mac2 << 8;\n\t\tt = read_eeprom_byte(dev, 0x8c+i);\n\t\tif (t < 0) {\n\t\t\tecode = -EIO;\n\t\t\tgoto init_error;\n\t\t} else\n\t\t\tmac2 |= (t & 0xff);\n\t}\n\n\twritel(mac1, &regs->MacAddrHi);\n\twritel(mac2, &regs->MacAddrLo);\n\n\taddr[0] = (mac1 >> 8) & 0xff;\n\taddr[1] = mac1 & 0xff;\n\taddr[2] = (mac2 >> 24) & 0xff;\n\taddr[3] = (mac2 >> 16) & 0xff;\n\taddr[4] = (mac2 >> 8) & 0xff;\n\taddr[5] = mac2 & 0xff;\n\teth_hw_addr_set(dev, addr);\n\n\tprintk(\"MAC: %pM\\n\", dev->dev_addr);\n\n\t \n\tpdev = ap->pdev;\n\tpci_read_config_byte(pdev, PCI_CACHE_LINE_SIZE, &cache_size);\n\tcache_size <<= 2;\n\tif (cache_size != SMP_CACHE_BYTES) {\n\t\tprintk(KERN_INFO \"  PCI cache line size set incorrectly \"\n\t\t       \"(%i bytes) by BIOS/FW, \", cache_size);\n\t\tif (cache_size > SMP_CACHE_BYTES)\n\t\t\tprintk(\"expecting %i\\n\", SMP_CACHE_BYTES);\n\t\telse {\n\t\t\tprintk(\"correcting to %i\\n\", SMP_CACHE_BYTES);\n\t\t\tpci_write_config_byte(pdev, PCI_CACHE_LINE_SIZE,\n\t\t\t\t\t      SMP_CACHE_BYTES >> 2);\n\t\t}\n\t}\n\n\tpci_state = readl(&regs->PciState);\n\tprintk(KERN_INFO \"  PCI bus width: %i bits, speed: %iMHz, \"\n\t       \"latency: %i clks\\n\",\n\t       \t(pci_state & PCI_32BIT) ? 32 : 64,\n\t\t(pci_state & PCI_66MHZ) ? 66 : 33,\n\t\tap->pci_latency);\n\n\t \n\ttmp = READ_CMD_MEM | WRITE_CMD_MEM;\n\tif (ap->version >= 2) {\n\t\ttmp |= (MEM_READ_MULTIPLE | (pci_state & PCI_66MHZ));\n\t\t \n\t\tif (board_idx == BOARD_IDX_OVERFLOW ||\n\t\t    dis_pci_mem_inval[board_idx]) {\n\t\t\tif (ap->pci_command & PCI_COMMAND_INVALIDATE) {\n\t\t\t\tap->pci_command &= ~PCI_COMMAND_INVALIDATE;\n\t\t\t\tpci_write_config_word(pdev, PCI_COMMAND,\n\t\t\t\t\t\t      ap->pci_command);\n\t\t\t\tprintk(KERN_INFO \"  Disabling PCI memory \"\n\t\t\t\t       \"write and invalidate\\n\");\n\t\t\t}\n\t\t} else if (ap->pci_command & PCI_COMMAND_INVALIDATE) {\n\t\t\tprintk(KERN_INFO \"  PCI memory write & invalidate \"\n\t\t\t       \"enabled by BIOS, enabling counter measures\\n\");\n\n\t\t\tswitch(SMP_CACHE_BYTES) {\n\t\t\tcase 16:\n\t\t\t\ttmp |= DMA_WRITE_MAX_16;\n\t\t\t\tbreak;\n\t\t\tcase 32:\n\t\t\t\ttmp |= DMA_WRITE_MAX_32;\n\t\t\t\tbreak;\n\t\t\tcase 64:\n\t\t\t\ttmp |= DMA_WRITE_MAX_64;\n\t\t\t\tbreak;\n\t\t\tcase 128:\n\t\t\t\ttmp |= DMA_WRITE_MAX_128;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tprintk(KERN_INFO \"  Cache line size %i not \"\n\t\t\t\t       \"supported, PCI write and invalidate \"\n\t\t\t\t       \"disabled\\n\", SMP_CACHE_BYTES);\n\t\t\t\tap->pci_command &= ~PCI_COMMAND_INVALIDATE;\n\t\t\t\tpci_write_config_word(pdev, PCI_COMMAND,\n\t\t\t\t\t\t      ap->pci_command);\n\t\t\t}\n\t\t}\n\t}\n\n#ifdef __sparc__\n\t \n\ttmp &= ~DMA_READ_WRITE_MASK;\n\ttmp |= DMA_READ_MAX_64;\n\ttmp |= DMA_WRITE_MAX_64;\n#endif\n#ifdef __alpha__\n\ttmp &= ~DMA_READ_WRITE_MASK;\n\ttmp |= DMA_READ_MAX_128;\n\t \n\ttmp |= DMA_WRITE_MAX_128;\n#endif\n\twritel(tmp, &regs->PciState);\n\n#if 0\n\t \n\t \n\tif (!(ap->pci_command & PCI_COMMAND_FAST_BACK)) {\n\t\tprintk(KERN_INFO \"  Enabling PCI Fast Back to Back\\n\");\n\t\tap->pci_command |= PCI_COMMAND_FAST_BACK;\n\t\tpci_write_config_word(pdev, PCI_COMMAND, ap->pci_command);\n\t}\n#endif\n\n\t \n\tif (dma_set_mask(&pdev->dev, DMA_BIT_MASK(64))) {\n\t\tecode = -ENODEV;\n\t\tgoto init_error;\n\t}\n\n\t \n\tif (!(info = dma_alloc_coherent(&ap->pdev->dev, sizeof(struct ace_info),\n\t\t\t\t\t&ap->info_dma, GFP_KERNEL))) {\n\t\tecode = -EAGAIN;\n\t\tgoto init_error;\n\t}\n\tap->info = info;\n\n\t \n\tif (!(ap->skb = kzalloc(sizeof(struct ace_skb), GFP_KERNEL))) {\n\t\tecode = -EAGAIN;\n\t\tgoto init_error;\n\t}\n\n\tecode = request_irq(pdev->irq, ace_interrupt, IRQF_SHARED,\n\t\t\t    DRV_NAME, dev);\n\tif (ecode) {\n\t\tprintk(KERN_WARNING \"%s: Requested IRQ %d is busy\\n\",\n\t\t       DRV_NAME, pdev->irq);\n\t\tgoto init_error;\n\t} else\n\t\tdev->irq = pdev->irq;\n\n#ifdef INDEX_DEBUG\n\tspin_lock_init(&ap->debug_lock);\n\tap->last_tx = ACE_TX_RING_ENTRIES(ap) - 1;\n\tap->last_std_rx = 0;\n\tap->last_mini_rx = 0;\n#endif\n\n\tecode = ace_load_firmware(dev);\n\tif (ecode)\n\t\tgoto init_error;\n\n\tap->fw_running = 0;\n\n\ttmp_ptr = ap->info_dma;\n\twritel(tmp_ptr >> 32, &regs->InfoPtrHi);\n\twritel(tmp_ptr & 0xffffffff, &regs->InfoPtrLo);\n\n\tmemset(ap->evt_ring, 0, EVT_RING_ENTRIES * sizeof(struct event));\n\n\tset_aceaddr(&info->evt_ctrl.rngptr, ap->evt_ring_dma);\n\tinfo->evt_ctrl.flags = 0;\n\n\t*(ap->evt_prd) = 0;\n\twmb();\n\tset_aceaddr(&info->evt_prd_ptr, ap->evt_prd_dma);\n\twritel(0, &regs->EvtCsm);\n\n\tset_aceaddr(&info->cmd_ctrl.rngptr, 0x100);\n\tinfo->cmd_ctrl.flags = 0;\n\tinfo->cmd_ctrl.max_len = 0;\n\n\tfor (i = 0; i < CMD_RING_ENTRIES; i++)\n\t\twritel(0, &regs->CmdRng[i]);\n\n\twritel(0, &regs->CmdPrd);\n\twritel(0, &regs->CmdCsm);\n\n\ttmp_ptr = ap->info_dma;\n\ttmp_ptr += (unsigned long) &(((struct ace_info *)0)->s.stats);\n\tset_aceaddr(&info->stats2_ptr, (dma_addr_t) tmp_ptr);\n\n\tset_aceaddr(&info->rx_std_ctrl.rngptr, ap->rx_ring_base_dma);\n\tinfo->rx_std_ctrl.max_len = ACE_STD_BUFSIZE;\n\tinfo->rx_std_ctrl.flags =\n\t  RCB_FLG_TCP_UDP_SUM | RCB_FLG_NO_PSEUDO_HDR | RCB_FLG_VLAN_ASSIST;\n\n\tmemset(ap->rx_std_ring, 0,\n\t       RX_STD_RING_ENTRIES * sizeof(struct rx_desc));\n\n\tfor (i = 0; i < RX_STD_RING_ENTRIES; i++)\n\t\tap->rx_std_ring[i].flags = BD_FLG_TCP_UDP_SUM;\n\n\tap->rx_std_skbprd = 0;\n\tatomic_set(&ap->cur_rx_bufs, 0);\n\n\tset_aceaddr(&info->rx_jumbo_ctrl.rngptr,\n\t\t    (ap->rx_ring_base_dma +\n\t\t     (sizeof(struct rx_desc) * RX_STD_RING_ENTRIES)));\n\tinfo->rx_jumbo_ctrl.max_len = 0;\n\tinfo->rx_jumbo_ctrl.flags =\n\t  RCB_FLG_TCP_UDP_SUM | RCB_FLG_NO_PSEUDO_HDR | RCB_FLG_VLAN_ASSIST;\n\n\tmemset(ap->rx_jumbo_ring, 0,\n\t       RX_JUMBO_RING_ENTRIES * sizeof(struct rx_desc));\n\n\tfor (i = 0; i < RX_JUMBO_RING_ENTRIES; i++)\n\t\tap->rx_jumbo_ring[i].flags = BD_FLG_TCP_UDP_SUM | BD_FLG_JUMBO;\n\n\tap->rx_jumbo_skbprd = 0;\n\tatomic_set(&ap->cur_jumbo_bufs, 0);\n\n\tmemset(ap->rx_mini_ring, 0,\n\t       RX_MINI_RING_ENTRIES * sizeof(struct rx_desc));\n\n\tif (ap->version >= 2) {\n\t\tset_aceaddr(&info->rx_mini_ctrl.rngptr,\n\t\t\t    (ap->rx_ring_base_dma +\n\t\t\t     (sizeof(struct rx_desc) *\n\t\t\t      (RX_STD_RING_ENTRIES +\n\t\t\t       RX_JUMBO_RING_ENTRIES))));\n\t\tinfo->rx_mini_ctrl.max_len = ACE_MINI_SIZE;\n\t\tinfo->rx_mini_ctrl.flags =\n\t\t  RCB_FLG_TCP_UDP_SUM|RCB_FLG_NO_PSEUDO_HDR|RCB_FLG_VLAN_ASSIST;\n\n\t\tfor (i = 0; i < RX_MINI_RING_ENTRIES; i++)\n\t\t\tap->rx_mini_ring[i].flags =\n\t\t\t\tBD_FLG_TCP_UDP_SUM | BD_FLG_MINI;\n\t} else {\n\t\tset_aceaddr(&info->rx_mini_ctrl.rngptr, 0);\n\t\tinfo->rx_mini_ctrl.flags = RCB_FLG_RNG_DISABLE;\n\t\tinfo->rx_mini_ctrl.max_len = 0;\n\t}\n\n\tap->rx_mini_skbprd = 0;\n\tatomic_set(&ap->cur_mini_bufs, 0);\n\n\tset_aceaddr(&info->rx_return_ctrl.rngptr,\n\t\t    (ap->rx_ring_base_dma +\n\t\t     (sizeof(struct rx_desc) *\n\t\t      (RX_STD_RING_ENTRIES +\n\t\t       RX_JUMBO_RING_ENTRIES +\n\t\t       RX_MINI_RING_ENTRIES))));\n\tinfo->rx_return_ctrl.flags = 0;\n\tinfo->rx_return_ctrl.max_len = RX_RETURN_RING_ENTRIES;\n\n\tmemset(ap->rx_return_ring, 0,\n\t       RX_RETURN_RING_ENTRIES * sizeof(struct rx_desc));\n\n\tset_aceaddr(&info->rx_ret_prd_ptr, ap->rx_ret_prd_dma);\n\t*(ap->rx_ret_prd) = 0;\n\n\twritel(TX_RING_BASE, &regs->WinBase);\n\n\tif (ACE_IS_TIGON_I(ap)) {\n\t\tap->tx_ring = (__force struct tx_desc *) regs->Window;\n\t\tfor (i = 0; i < (TIGON_I_TX_RING_ENTRIES\n\t\t\t\t * sizeof(struct tx_desc)) / sizeof(u32); i++)\n\t\t\twritel(0, (__force void __iomem *)ap->tx_ring  + i * 4);\n\n\t\tset_aceaddr(&info->tx_ctrl.rngptr, TX_RING_BASE);\n\t} else {\n\t\tmemset(ap->tx_ring, 0,\n\t\t       MAX_TX_RING_ENTRIES * sizeof(struct tx_desc));\n\n\t\tset_aceaddr(&info->tx_ctrl.rngptr, ap->tx_ring_dma);\n\t}\n\n\tinfo->tx_ctrl.max_len = ACE_TX_RING_ENTRIES(ap);\n\ttmp = RCB_FLG_TCP_UDP_SUM | RCB_FLG_NO_PSEUDO_HDR | RCB_FLG_VLAN_ASSIST;\n\n\t \n\tif (!ACE_IS_TIGON_I(ap))\n\t\ttmp |= RCB_FLG_TX_HOST_RING;\n#if TX_COAL_INTS_ONLY\n\ttmp |= RCB_FLG_COAL_INT_ONLY;\n#endif\n\tinfo->tx_ctrl.flags = tmp;\n\n\tset_aceaddr(&info->tx_csm_ptr, ap->tx_csm_dma);\n\n\t \n#if 0  \n\twritel(DMA_THRESH_16W, &regs->DmaReadCfg);\n\twritel(DMA_THRESH_16W, &regs->DmaWriteCfg);\n#else\n\twritel(DMA_THRESH_8W, &regs->DmaReadCfg);\n\twritel(DMA_THRESH_8W, &regs->DmaWriteCfg);\n#endif\n\n\twritel(0, &regs->MaskInt);\n\twritel(1, &regs->IfIdx);\n#if 0\n\t \n\twritel(1, &regs->AssistState);\n#endif\n\n\twritel(DEF_STAT, &regs->TuneStatTicks);\n\twritel(DEF_TRACE, &regs->TuneTrace);\n\n\tace_set_rxtx_parms(dev, 0);\n\n\tif (board_idx == BOARD_IDX_OVERFLOW) {\n\t\tprintk(KERN_WARNING \"%s: more than %i NICs detected, \"\n\t\t       \"ignoring module parameters!\\n\",\n\t\t       ap->name, ACE_MAX_MOD_PARMS);\n\t} else if (board_idx >= 0) {\n\t\tif (tx_coal_tick[board_idx])\n\t\t\twritel(tx_coal_tick[board_idx],\n\t\t\t       &regs->TuneTxCoalTicks);\n\t\tif (max_tx_desc[board_idx])\n\t\t\twritel(max_tx_desc[board_idx], &regs->TuneMaxTxDesc);\n\n\t\tif (rx_coal_tick[board_idx])\n\t\t\twritel(rx_coal_tick[board_idx],\n\t\t\t       &regs->TuneRxCoalTicks);\n\t\tif (max_rx_desc[board_idx])\n\t\t\twritel(max_rx_desc[board_idx], &regs->TuneMaxRxDesc);\n\n\t\tif (trace[board_idx])\n\t\t\twritel(trace[board_idx], &regs->TuneTrace);\n\n\t\tif ((tx_ratio[board_idx] > 0) && (tx_ratio[board_idx] < 64))\n\t\t\twritel(tx_ratio[board_idx], &regs->TxBufRat);\n\t}\n\n\t \n\ttmp = LNK_ENABLE | LNK_FULL_DUPLEX | LNK_1000MB | LNK_100MB |\n\t\tLNK_10MB | LNK_RX_FLOW_CTL_Y | LNK_NEG_FCTL | LNK_NEGOTIATE;\n\tif(ap->version >= 2)\n\t\ttmp |= LNK_TX_FLOW_CTL_Y;\n\n\t \n\tif ((board_idx >= 0) && link_state[board_idx]) {\n\t\tint option = link_state[board_idx];\n\n\t\ttmp = LNK_ENABLE;\n\n\t\tif (option & 0x01) {\n\t\t\tprintk(KERN_INFO \"%s: Setting half duplex link\\n\",\n\t\t\t       ap->name);\n\t\t\ttmp &= ~LNK_FULL_DUPLEX;\n\t\t}\n\t\tif (option & 0x02)\n\t\t\ttmp &= ~LNK_NEGOTIATE;\n\t\tif (option & 0x10)\n\t\t\ttmp |= LNK_10MB;\n\t\tif (option & 0x20)\n\t\t\ttmp |= LNK_100MB;\n\t\tif (option & 0x40)\n\t\t\ttmp |= LNK_1000MB;\n\t\tif ((option & 0x70) == 0) {\n\t\t\tprintk(KERN_WARNING \"%s: No media speed specified, \"\n\t\t\t       \"forcing auto negotiation\\n\", ap->name);\n\t\t\ttmp |= LNK_NEGOTIATE | LNK_1000MB |\n\t\t\t\tLNK_100MB | LNK_10MB;\n\t\t}\n\t\tif ((option & 0x100) == 0)\n\t\t\ttmp |= LNK_NEG_FCTL;\n\t\telse\n\t\t\tprintk(KERN_INFO \"%s: Disabling flow control \"\n\t\t\t       \"negotiation\\n\", ap->name);\n\t\tif (option & 0x200)\n\t\t\ttmp |= LNK_RX_FLOW_CTL_Y;\n\t\tif ((option & 0x400) && (ap->version >= 2)) {\n\t\t\tprintk(KERN_INFO \"%s: Enabling TX flow control\\n\",\n\t\t\t       ap->name);\n\t\t\ttmp |= LNK_TX_FLOW_CTL_Y;\n\t\t}\n\t}\n\n\tap->link = tmp;\n\twritel(tmp, &regs->TuneLink);\n\tif (ap->version >= 2)\n\t\twritel(tmp, &regs->TuneFastLink);\n\n\twritel(ap->firmware_start, &regs->Pc);\n\n\twritel(0, &regs->Mb0Lo);\n\n\t \n\tap->cur_rx = 0;\n\tap->tx_prd = *(ap->tx_csm) = ap->tx_ret_csm = 0;\n\n\twmb();\n\tace_set_txprd(regs, ap, 0);\n\twritel(0, &regs->RxRetCsm);\n\n\t \n\twritel(1, &regs->AssistState);   \n\n\t \n\twritel(readl(&regs->CpuCtrl) & ~(CPU_HALT|CPU_TRACE), &regs->CpuCtrl);\n\treadl(&regs->CpuCtrl);\n\n\t \n\tmyjif = jiffies + 3 * HZ;\n\twhile (time_before(jiffies, myjif) && !ap->fw_running)\n\t\tcpu_relax();\n\n\tif (!ap->fw_running) {\n\t\tprintk(KERN_ERR \"%s: Firmware NOT running!\\n\", ap->name);\n\n\t\tace_dump_trace(ap);\n\t\twritel(readl(&regs->CpuCtrl) | CPU_HALT, &regs->CpuCtrl);\n\t\treadl(&regs->CpuCtrl);\n\n\t\t \n\t\tif (ap->version >= 2)\n\t\t\twritel(readl(&regs->CpuBCtrl) | CPU_HALT,\n\t\t\t       &regs->CpuBCtrl);\n\t\twritel(0, &regs->Mb0Lo);\n\t\treadl(&regs->Mb0Lo);\n\n\t\tecode = -EBUSY;\n\t\tgoto init_error;\n\t}\n\n\t \n\tif (!test_and_set_bit(0, &ap->std_refill_busy))\n\t\tace_load_std_rx_ring(dev, RX_RING_SIZE);\n\telse\n\t\tprintk(KERN_ERR \"%s: Someone is busy refilling the RX ring\\n\",\n\t\t       ap->name);\n\tif (ap->version >= 2) {\n\t\tif (!test_and_set_bit(0, &ap->mini_refill_busy))\n\t\t\tace_load_mini_rx_ring(dev, RX_MINI_SIZE);\n\t\telse\n\t\t\tprintk(KERN_ERR \"%s: Someone is busy refilling \"\n\t\t\t       \"the RX mini ring\\n\", ap->name);\n\t}\n\treturn 0;\n\n init_error:\n\tace_init_cleanup(dev);\n\treturn ecode;\n}\n\n\nstatic void ace_set_rxtx_parms(struct net_device *dev, int jumbo)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tint board_idx = ap->board_idx;\n\n\tif (board_idx >= 0) {\n\t\tif (!jumbo) {\n\t\t\tif (!tx_coal_tick[board_idx])\n\t\t\t\twritel(DEF_TX_COAL, &regs->TuneTxCoalTicks);\n\t\t\tif (!max_tx_desc[board_idx])\n\t\t\t\twritel(DEF_TX_MAX_DESC, &regs->TuneMaxTxDesc);\n\t\t\tif (!rx_coal_tick[board_idx])\n\t\t\t\twritel(DEF_RX_COAL, &regs->TuneRxCoalTicks);\n\t\t\tif (!max_rx_desc[board_idx])\n\t\t\t\twritel(DEF_RX_MAX_DESC, &regs->TuneMaxRxDesc);\n\t\t\tif (!tx_ratio[board_idx])\n\t\t\t\twritel(DEF_TX_RATIO, &regs->TxBufRat);\n\t\t} else {\n\t\t\tif (!tx_coal_tick[board_idx])\n\t\t\t\twritel(DEF_JUMBO_TX_COAL,\n\t\t\t\t       &regs->TuneTxCoalTicks);\n\t\t\tif (!max_tx_desc[board_idx])\n\t\t\t\twritel(DEF_JUMBO_TX_MAX_DESC,\n\t\t\t\t       &regs->TuneMaxTxDesc);\n\t\t\tif (!rx_coal_tick[board_idx])\n\t\t\t\twritel(DEF_JUMBO_RX_COAL,\n\t\t\t\t       &regs->TuneRxCoalTicks);\n\t\t\tif (!max_rx_desc[board_idx])\n\t\t\t\twritel(DEF_JUMBO_RX_MAX_DESC,\n\t\t\t\t       &regs->TuneMaxRxDesc);\n\t\t\tif (!tx_ratio[board_idx])\n\t\t\t\twritel(DEF_JUMBO_TX_RATIO, &regs->TxBufRat);\n\t\t}\n\t}\n}\n\n\nstatic void ace_watchdog(struct net_device *data, unsigned int txqueue)\n{\n\tstruct net_device *dev = data;\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\n\t \n\tif (*ap->tx_csm != ap->tx_ret_csm) {\n\t\tprintk(KERN_WARNING \"%s: Transmitter is stuck, %08x\\n\",\n\t\t       dev->name, (unsigned int)readl(&regs->HostCtrl));\n\t\t \n\t} else {\n\t\tprintk(KERN_DEBUG \"%s: BUG... transmitter died. Kicking it.\\n\",\n\t\t       dev->name);\n#if 0\n\t\tnetif_wake_queue(dev);\n#endif\n\t}\n}\n\n\nstatic void ace_tasklet(struct tasklet_struct *t)\n{\n\tstruct ace_private *ap = from_tasklet(ap, t, ace_tasklet);\n\tstruct net_device *dev = ap->ndev;\n\tint cur_size;\n\n\tcur_size = atomic_read(&ap->cur_rx_bufs);\n\tif ((cur_size < RX_LOW_STD_THRES) &&\n\t    !test_and_set_bit(0, &ap->std_refill_busy)) {\n#ifdef DEBUG\n\t\tprintk(\"refilling buffers (current %i)\\n\", cur_size);\n#endif\n\t\tace_load_std_rx_ring(dev, RX_RING_SIZE - cur_size);\n\t}\n\n\tif (ap->version >= 2) {\n\t\tcur_size = atomic_read(&ap->cur_mini_bufs);\n\t\tif ((cur_size < RX_LOW_MINI_THRES) &&\n\t\t    !test_and_set_bit(0, &ap->mini_refill_busy)) {\n#ifdef DEBUG\n\t\t\tprintk(\"refilling mini buffers (current %i)\\n\",\n\t\t\t       cur_size);\n#endif\n\t\t\tace_load_mini_rx_ring(dev, RX_MINI_SIZE - cur_size);\n\t\t}\n\t}\n\n\tcur_size = atomic_read(&ap->cur_jumbo_bufs);\n\tif (ap->jumbo && (cur_size < RX_LOW_JUMBO_THRES) &&\n\t    !test_and_set_bit(0, &ap->jumbo_refill_busy)) {\n#ifdef DEBUG\n\t\tprintk(\"refilling jumbo buffers (current %i)\\n\", cur_size);\n#endif\n\t\tace_load_jumbo_rx_ring(dev, RX_JUMBO_SIZE - cur_size);\n\t}\n\tap->tasklet_pending = 0;\n}\n\n\n \nstatic void ace_dump_trace(struct ace_private *ap)\n{\n#if 0\n\tif (!ap->trace_buf)\n\t\tif (!(ap->trace_buf = kmalloc(ACE_TRACE_SIZE, GFP_KERNEL)))\n\t\t    return;\n#endif\n}\n\n\n \nstatic void ace_load_std_rx_ring(struct net_device *dev, int nr_bufs)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tshort i, idx;\n\n\n\tprefetchw(&ap->cur_rx_bufs);\n\n\tidx = ap->rx_std_skbprd;\n\n\tfor (i = 0; i < nr_bufs; i++) {\n\t\tstruct sk_buff *skb;\n\t\tstruct rx_desc *rd;\n\t\tdma_addr_t mapping;\n\n\t\tskb = netdev_alloc_skb_ip_align(dev, ACE_STD_BUFSIZE);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tmapping = dma_map_page(&ap->pdev->dev,\n\t\t\t\t       virt_to_page(skb->data),\n\t\t\t\t       offset_in_page(skb->data),\n\t\t\t\t       ACE_STD_BUFSIZE, DMA_FROM_DEVICE);\n\t\tap->skb->rx_std_skbuff[idx].skb = skb;\n\t\tdma_unmap_addr_set(&ap->skb->rx_std_skbuff[idx],\n\t\t\t\t   mapping, mapping);\n\n\t\trd = &ap->rx_std_ring[idx];\n\t\tset_aceaddr(&rd->addr, mapping);\n\t\trd->size = ACE_STD_BUFSIZE;\n\t\trd->idx = idx;\n\t\tidx = (idx + 1) % RX_STD_RING_ENTRIES;\n\t}\n\n\tif (!i)\n\t\tgoto error_out;\n\n\tatomic_add(i, &ap->cur_rx_bufs);\n\tap->rx_std_skbprd = idx;\n\n\tif (ACE_IS_TIGON_I(ap)) {\n\t\tstruct cmd cmd;\n\t\tcmd.evt = C_SET_RX_PRD_IDX;\n\t\tcmd.code = 0;\n\t\tcmd.idx = ap->rx_std_skbprd;\n\t\tace_issue_cmd(regs, &cmd);\n\t} else {\n\t\twritel(idx, &regs->RxStdPrd);\n\t\twmb();\n\t}\n\n out:\n\tclear_bit(0, &ap->std_refill_busy);\n\treturn;\n\n error_out:\n\tprintk(KERN_INFO \"Out of memory when allocating \"\n\t       \"standard receive buffers\\n\");\n\tgoto out;\n}\n\n\nstatic void ace_load_mini_rx_ring(struct net_device *dev, int nr_bufs)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tshort i, idx;\n\n\tprefetchw(&ap->cur_mini_bufs);\n\n\tidx = ap->rx_mini_skbprd;\n\tfor (i = 0; i < nr_bufs; i++) {\n\t\tstruct sk_buff *skb;\n\t\tstruct rx_desc *rd;\n\t\tdma_addr_t mapping;\n\n\t\tskb = netdev_alloc_skb_ip_align(dev, ACE_MINI_BUFSIZE);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tmapping = dma_map_page(&ap->pdev->dev,\n\t\t\t\t       virt_to_page(skb->data),\n\t\t\t\t       offset_in_page(skb->data),\n\t\t\t\t       ACE_MINI_BUFSIZE, DMA_FROM_DEVICE);\n\t\tap->skb->rx_mini_skbuff[idx].skb = skb;\n\t\tdma_unmap_addr_set(&ap->skb->rx_mini_skbuff[idx],\n\t\t\t\t   mapping, mapping);\n\n\t\trd = &ap->rx_mini_ring[idx];\n\t\tset_aceaddr(&rd->addr, mapping);\n\t\trd->size = ACE_MINI_BUFSIZE;\n\t\trd->idx = idx;\n\t\tidx = (idx + 1) % RX_MINI_RING_ENTRIES;\n\t}\n\n\tif (!i)\n\t\tgoto error_out;\n\n\tatomic_add(i, &ap->cur_mini_bufs);\n\n\tap->rx_mini_skbprd = idx;\n\n\twritel(idx, &regs->RxMiniPrd);\n\twmb();\n\n out:\n\tclear_bit(0, &ap->mini_refill_busy);\n\treturn;\n error_out:\n\tprintk(KERN_INFO \"Out of memory when allocating \"\n\t       \"mini receive buffers\\n\");\n\tgoto out;\n}\n\n\n \nstatic void ace_load_jumbo_rx_ring(struct net_device *dev, int nr_bufs)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tshort i, idx;\n\n\tidx = ap->rx_jumbo_skbprd;\n\n\tfor (i = 0; i < nr_bufs; i++) {\n\t\tstruct sk_buff *skb;\n\t\tstruct rx_desc *rd;\n\t\tdma_addr_t mapping;\n\n\t\tskb = netdev_alloc_skb_ip_align(dev, ACE_JUMBO_BUFSIZE);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tmapping = dma_map_page(&ap->pdev->dev,\n\t\t\t\t       virt_to_page(skb->data),\n\t\t\t\t       offset_in_page(skb->data),\n\t\t\t\t       ACE_JUMBO_BUFSIZE, DMA_FROM_DEVICE);\n\t\tap->skb->rx_jumbo_skbuff[idx].skb = skb;\n\t\tdma_unmap_addr_set(&ap->skb->rx_jumbo_skbuff[idx],\n\t\t\t\t   mapping, mapping);\n\n\t\trd = &ap->rx_jumbo_ring[idx];\n\t\tset_aceaddr(&rd->addr, mapping);\n\t\trd->size = ACE_JUMBO_BUFSIZE;\n\t\trd->idx = idx;\n\t\tidx = (idx + 1) % RX_JUMBO_RING_ENTRIES;\n\t}\n\n\tif (!i)\n\t\tgoto error_out;\n\n\tatomic_add(i, &ap->cur_jumbo_bufs);\n\tap->rx_jumbo_skbprd = idx;\n\n\tif (ACE_IS_TIGON_I(ap)) {\n\t\tstruct cmd cmd;\n\t\tcmd.evt = C_SET_RX_JUMBO_PRD_IDX;\n\t\tcmd.code = 0;\n\t\tcmd.idx = ap->rx_jumbo_skbprd;\n\t\tace_issue_cmd(regs, &cmd);\n\t} else {\n\t\twritel(idx, &regs->RxJumboPrd);\n\t\twmb();\n\t}\n\n out:\n\tclear_bit(0, &ap->jumbo_refill_busy);\n\treturn;\n error_out:\n\tif (net_ratelimit())\n\t\tprintk(KERN_INFO \"Out of memory when allocating \"\n\t\t       \"jumbo receive buffers\\n\");\n\tgoto out;\n}\n\n\n \nstatic u32 ace_handle_event(struct net_device *dev, u32 evtcsm, u32 evtprd)\n{\n\tstruct ace_private *ap;\n\n\tap = netdev_priv(dev);\n\n\twhile (evtcsm != evtprd) {\n\t\tswitch (ap->evt_ring[evtcsm].evt) {\n\t\tcase E_FW_RUNNING:\n\t\t\tprintk(KERN_INFO \"%s: Firmware up and running\\n\",\n\t\t\t       ap->name);\n\t\t\tap->fw_running = 1;\n\t\t\twmb();\n\t\t\tbreak;\n\t\tcase E_STATS_UPDATED:\n\t\t\tbreak;\n\t\tcase E_LNK_STATE:\n\t\t{\n\t\t\tu16 code = ap->evt_ring[evtcsm].code;\n\t\t\tswitch (code) {\n\t\t\tcase E_C_LINK_UP:\n\t\t\t{\n\t\t\t\tu32 state = readl(&ap->regs->GigLnkState);\n\t\t\t\tprintk(KERN_WARNING \"%s: Optical link UP \"\n\t\t\t\t       \"(%s Duplex, Flow Control: %s%s)\\n\",\n\t\t\t\t       ap->name,\n\t\t\t\t       state & LNK_FULL_DUPLEX ? \"Full\":\"Half\",\n\t\t\t\t       state & LNK_TX_FLOW_CTL_Y ? \"TX \" : \"\",\n\t\t\t\t       state & LNK_RX_FLOW_CTL_Y ? \"RX\" : \"\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase E_C_LINK_DOWN:\n\t\t\t\tprintk(KERN_WARNING \"%s: Optical link DOWN\\n\",\n\t\t\t\t       ap->name);\n\t\t\t\tbreak;\n\t\t\tcase E_C_LINK_10_100:\n\t\t\t\tprintk(KERN_WARNING \"%s: 10/100BaseT link \"\n\t\t\t\t       \"UP\\n\", ap->name);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tprintk(KERN_ERR \"%s: Unknown optical link \"\n\t\t\t\t       \"state %02x\\n\", ap->name, code);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase E_ERROR:\n\t\t\tswitch(ap->evt_ring[evtcsm].code) {\n\t\t\tcase E_C_ERR_INVAL_CMD:\n\t\t\t\tprintk(KERN_ERR \"%s: invalid command error\\n\",\n\t\t\t\t       ap->name);\n\t\t\t\tbreak;\n\t\t\tcase E_C_ERR_UNIMP_CMD:\n\t\t\t\tprintk(KERN_ERR \"%s: unimplemented command \"\n\t\t\t\t       \"error\\n\", ap->name);\n\t\t\t\tbreak;\n\t\t\tcase E_C_ERR_BAD_CFG:\n\t\t\t\tprintk(KERN_ERR \"%s: bad config error\\n\",\n\t\t\t\t       ap->name);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tprintk(KERN_ERR \"%s: unknown error %02x\\n\",\n\t\t\t\t       ap->name, ap->evt_ring[evtcsm].code);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase E_RESET_JUMBO_RNG:\n\t\t{\n\t\t\tint i;\n\t\t\tfor (i = 0; i < RX_JUMBO_RING_ENTRIES; i++) {\n\t\t\t\tif (ap->skb->rx_jumbo_skbuff[i].skb) {\n\t\t\t\t\tap->rx_jumbo_ring[i].size = 0;\n\t\t\t\t\tset_aceaddr(&ap->rx_jumbo_ring[i].addr, 0);\n\t\t\t\t\tdev_kfree_skb(ap->skb->rx_jumbo_skbuff[i].skb);\n\t\t\t\t\tap->skb->rx_jumbo_skbuff[i].skb = NULL;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (ACE_IS_TIGON_I(ap)) {\n\t\t\t\tstruct cmd cmd;\n\t\t\t\tcmd.evt = C_SET_RX_JUMBO_PRD_IDX;\n\t\t\t\tcmd.code = 0;\n\t\t\t\tcmd.idx = 0;\n\t\t\t\tace_issue_cmd(ap->regs, &cmd);\n\t\t\t} else {\n\t\t\t\twritel(0, &((ap->regs)->RxJumboPrd));\n\t\t\t\twmb();\n\t\t\t}\n\n\t\t\tap->jumbo = 0;\n\t\t\tap->rx_jumbo_skbprd = 0;\n\t\t\tprintk(KERN_INFO \"%s: Jumbo ring flushed\\n\",\n\t\t\t       ap->name);\n\t\t\tclear_bit(0, &ap->jumbo_refill_busy);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tprintk(KERN_ERR \"%s: Unhandled event 0x%02x\\n\",\n\t\t\t       ap->name, ap->evt_ring[evtcsm].evt);\n\t\t}\n\t\tevtcsm = (evtcsm + 1) % EVT_RING_ENTRIES;\n\t}\n\n\treturn evtcsm;\n}\n\n\nstatic void ace_rx_int(struct net_device *dev, u32 rxretprd, u32 rxretcsm)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tu32 idx;\n\tint mini_count = 0, std_count = 0;\n\n\tidx = rxretcsm;\n\n\tprefetchw(&ap->cur_rx_bufs);\n\tprefetchw(&ap->cur_mini_bufs);\n\n\twhile (idx != rxretprd) {\n\t\tstruct ring_info *rip;\n\t\tstruct sk_buff *skb;\n\t\tstruct rx_desc *retdesc;\n\t\tu32 skbidx;\n\t\tint bd_flags, desc_type, mapsize;\n\t\tu16 csum;\n\n\n\t\t \n\t\tif (idx == rxretcsm)\n\t\t\trmb();\n\n\t\tretdesc = &ap->rx_return_ring[idx];\n\t\tskbidx = retdesc->idx;\n\t\tbd_flags = retdesc->flags;\n\t\tdesc_type = bd_flags & (BD_FLG_JUMBO | BD_FLG_MINI);\n\n\t\tswitch(desc_type) {\n\t\t\t \n\t\tcase 0:\n\t\t\trip = &ap->skb->rx_std_skbuff[skbidx];\n\t\t\tmapsize = ACE_STD_BUFSIZE;\n\t\t\tstd_count++;\n\t\t\tbreak;\n\t\tcase BD_FLG_JUMBO:\n\t\t\trip = &ap->skb->rx_jumbo_skbuff[skbidx];\n\t\t\tmapsize = ACE_JUMBO_BUFSIZE;\n\t\t\tatomic_dec(&ap->cur_jumbo_bufs);\n\t\t\tbreak;\n\t\tcase BD_FLG_MINI:\n\t\t\trip = &ap->skb->rx_mini_skbuff[skbidx];\n\t\t\tmapsize = ACE_MINI_BUFSIZE;\n\t\t\tmini_count++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tprintk(KERN_INFO \"%s: unknown frame type (0x%02x) \"\n\t\t\t       \"returned by NIC\\n\", dev->name,\n\t\t\t       retdesc->flags);\n\t\t\tgoto error;\n\t\t}\n\n\t\tskb = rip->skb;\n\t\trip->skb = NULL;\n\t\tdma_unmap_page(&ap->pdev->dev, dma_unmap_addr(rip, mapping),\n\t\t\t       mapsize, DMA_FROM_DEVICE);\n\t\tskb_put(skb, retdesc->size);\n\n\t\t \n\t\tcsum = retdesc->tcp_udp_csum;\n\n\t\tskb->protocol = eth_type_trans(skb, dev);\n\n\t\t \n\t\tif (bd_flags & BD_FLG_TCP_UDP_SUM) {\n\t\t\tskb->csum = htons(csum);\n\t\t\tskb->ip_summed = CHECKSUM_COMPLETE;\n\t\t} else {\n\t\t\tskb_checksum_none_assert(skb);\n\t\t}\n\n\t\t \n\t\tif ((bd_flags & BD_FLG_VLAN_TAG))\n\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), retdesc->vlan);\n\t\tnetif_rx(skb);\n\n\t\tdev->stats.rx_packets++;\n\t\tdev->stats.rx_bytes += retdesc->size;\n\n\t\tidx = (idx + 1) % RX_RETURN_RING_ENTRIES;\n\t}\n\n\tatomic_sub(std_count, &ap->cur_rx_bufs);\n\tif (!ACE_IS_TIGON_I(ap))\n\t\tatomic_sub(mini_count, &ap->cur_mini_bufs);\n\n out:\n\t \n\tif (ACE_IS_TIGON_I(ap)) {\n\t\twritel(idx, &ap->regs->RxRetCsm);\n\t}\n\tap->cur_rx = idx;\n\n\treturn;\n error:\n\tidx = rxretprd;\n\tgoto out;\n}\n\n\nstatic inline void ace_tx_int(struct net_device *dev,\n\t\t\t      u32 txcsm, u32 idx)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\n\tdo {\n\t\tstruct sk_buff *skb;\n\t\tstruct tx_ring_info *info;\n\n\t\tinfo = ap->skb->tx_skbuff + idx;\n\t\tskb = info->skb;\n\n\t\tif (dma_unmap_len(info, maplen)) {\n\t\t\tdma_unmap_page(&ap->pdev->dev,\n\t\t\t\t       dma_unmap_addr(info, mapping),\n\t\t\t\t       dma_unmap_len(info, maplen),\n\t\t\t\t       DMA_TO_DEVICE);\n\t\t\tdma_unmap_len_set(info, maplen, 0);\n\t\t}\n\n\t\tif (skb) {\n\t\t\tdev->stats.tx_packets++;\n\t\t\tdev->stats.tx_bytes += skb->len;\n\t\t\tdev_consume_skb_irq(skb);\n\t\t\tinfo->skb = NULL;\n\t\t}\n\n\t\tidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\n\t} while (idx != txcsm);\n\n\tif (netif_queue_stopped(dev))\n\t\tnetif_wake_queue(dev);\n\n\twmb();\n\tap->tx_ret_csm = txcsm;\n\n\t \n}\n\n\nstatic irqreturn_t ace_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *dev = (struct net_device *)dev_id;\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tu32 idx;\n\tu32 txcsm, rxretcsm, rxretprd;\n\tu32 evtcsm, evtprd;\n\n\t \n\tif (!(readl(&regs->HostCtrl) & IN_INT))\n\t\treturn IRQ_NONE;\n\n\t \n\twritel(0, &regs->Mb0Lo);\n\treadl(&regs->Mb0Lo);\n\n\t \n\trxretprd = *ap->rx_ret_prd;\n\trxretcsm = ap->cur_rx;\n\n\tif (rxretprd != rxretcsm)\n\t\tace_rx_int(dev, rxretprd, rxretcsm);\n\n\ttxcsm = *ap->tx_csm;\n\tidx = ap->tx_ret_csm;\n\n\tif (txcsm != idx) {\n\t\t \n\t\tif (!tx_ring_full(ap, txcsm, ap->tx_prd))\n\t\t\tace_tx_int(dev, txcsm, idx);\n\t}\n\n\tevtcsm = readl(&regs->EvtCsm);\n\tevtprd = *ap->evt_prd;\n\n\tif (evtcsm != evtprd) {\n\t\tevtcsm = ace_handle_event(dev, evtcsm, evtprd);\n\t\twritel(evtcsm, &regs->EvtCsm);\n\t}\n\n\t \n\tif (netif_running(dev)) {\n\t\tint cur_size;\n\t\tint run_tasklet = 0;\n\n\t\tcur_size = atomic_read(&ap->cur_rx_bufs);\n\t\tif (cur_size < RX_LOW_STD_THRES) {\n\t\t\tif ((cur_size < RX_PANIC_STD_THRES) &&\n\t\t\t    !test_and_set_bit(0, &ap->std_refill_busy)) {\n#ifdef DEBUG\n\t\t\t\tprintk(\"low on std buffers %i\\n\", cur_size);\n#endif\n\t\t\t\tace_load_std_rx_ring(dev,\n\t\t\t\t\t\t     RX_RING_SIZE - cur_size);\n\t\t\t} else\n\t\t\t\trun_tasklet = 1;\n\t\t}\n\n\t\tif (!ACE_IS_TIGON_I(ap)) {\n\t\t\tcur_size = atomic_read(&ap->cur_mini_bufs);\n\t\t\tif (cur_size < RX_LOW_MINI_THRES) {\n\t\t\t\tif ((cur_size < RX_PANIC_MINI_THRES) &&\n\t\t\t\t    !test_and_set_bit(0,\n\t\t\t\t\t\t      &ap->mini_refill_busy)) {\n#ifdef DEBUG\n\t\t\t\t\tprintk(\"low on mini buffers %i\\n\",\n\t\t\t\t\t       cur_size);\n#endif\n\t\t\t\t\tace_load_mini_rx_ring(dev,\n\t\t\t\t\t\t\t      RX_MINI_SIZE - cur_size);\n\t\t\t\t} else\n\t\t\t\t\trun_tasklet = 1;\n\t\t\t}\n\t\t}\n\n\t\tif (ap->jumbo) {\n\t\t\tcur_size = atomic_read(&ap->cur_jumbo_bufs);\n\t\t\tif (cur_size < RX_LOW_JUMBO_THRES) {\n\t\t\t\tif ((cur_size < RX_PANIC_JUMBO_THRES) &&\n\t\t\t\t    !test_and_set_bit(0,\n\t\t\t\t\t\t      &ap->jumbo_refill_busy)){\n#ifdef DEBUG\n\t\t\t\t\tprintk(\"low on jumbo buffers %i\\n\",\n\t\t\t\t\t       cur_size);\n#endif\n\t\t\t\t\tace_load_jumbo_rx_ring(dev,\n\t\t\t\t\t\t\t       RX_JUMBO_SIZE - cur_size);\n\t\t\t\t} else\n\t\t\t\t\trun_tasklet = 1;\n\t\t\t}\n\t\t}\n\t\tif (run_tasklet && !ap->tasklet_pending) {\n\t\t\tap->tasklet_pending = 1;\n\t\t\ttasklet_schedule(&ap->ace_tasklet);\n\t\t}\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int ace_open(struct net_device *dev)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tstruct cmd cmd;\n\n\tif (!(ap->fw_running)) {\n\t\tprintk(KERN_WARNING \"%s: Firmware not running!\\n\", dev->name);\n\t\treturn -EBUSY;\n\t}\n\n\twritel(dev->mtu + ETH_HLEN + 4, &regs->IfMtu);\n\n\tcmd.evt = C_CLEAR_STATS;\n\tcmd.code = 0;\n\tcmd.idx = 0;\n\tace_issue_cmd(regs, &cmd);\n\n\tcmd.evt = C_HOST_STATE;\n\tcmd.code = C_C_STACK_UP;\n\tcmd.idx = 0;\n\tace_issue_cmd(regs, &cmd);\n\n\tif (ap->jumbo &&\n\t    !test_and_set_bit(0, &ap->jumbo_refill_busy))\n\t\tace_load_jumbo_rx_ring(dev, RX_JUMBO_SIZE);\n\n\tif (dev->flags & IFF_PROMISC) {\n\t\tcmd.evt = C_SET_PROMISC_MODE;\n\t\tcmd.code = C_C_PROMISC_ENABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\n\t\tap->promisc = 1;\n\t}else\n\t\tap->promisc = 0;\n\tap->mcast_all = 0;\n\n#if 0\n\tcmd.evt = C_LNK_NEGOTIATION;\n\tcmd.code = 0;\n\tcmd.idx = 0;\n\tace_issue_cmd(regs, &cmd);\n#endif\n\n\tnetif_start_queue(dev);\n\n\t \n\ttasklet_setup(&ap->ace_tasklet, ace_tasklet);\n\treturn 0;\n}\n\n\nstatic int ace_close(struct net_device *dev)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tstruct cmd cmd;\n\tunsigned long flags;\n\tshort i;\n\n\t \n\tnetif_stop_queue(dev);\n\n\n\tif (ap->promisc) {\n\t\tcmd.evt = C_SET_PROMISC_MODE;\n\t\tcmd.code = C_C_PROMISC_DISABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t\tap->promisc = 0;\n\t}\n\n\tcmd.evt = C_HOST_STATE;\n\tcmd.code = C_C_STACK_DOWN;\n\tcmd.idx = 0;\n\tace_issue_cmd(regs, &cmd);\n\n\ttasklet_kill(&ap->ace_tasklet);\n\n\t \n\n\tlocal_irq_save(flags);\n\tace_mask_irq(dev);\n\n\tfor (i = 0; i < ACE_TX_RING_ENTRIES(ap); i++) {\n\t\tstruct sk_buff *skb;\n\t\tstruct tx_ring_info *info;\n\n\t\tinfo = ap->skb->tx_skbuff + i;\n\t\tskb = info->skb;\n\n\t\tif (dma_unmap_len(info, maplen)) {\n\t\t\tif (ACE_IS_TIGON_I(ap)) {\n\t\t\t\t \n\t\t\t\tstruct tx_desc __iomem *tx;\n\t\t\t\ttx = (__force struct tx_desc __iomem *) &ap->tx_ring[i];\n\t\t\t\twritel(0, &tx->addr.addrhi);\n\t\t\t\twritel(0, &tx->addr.addrlo);\n\t\t\t\twritel(0, &tx->flagsize);\n\t\t\t} else\n\t\t\t\tmemset(ap->tx_ring + i, 0,\n\t\t\t\t       sizeof(struct tx_desc));\n\t\t\tdma_unmap_page(&ap->pdev->dev,\n\t\t\t\t       dma_unmap_addr(info, mapping),\n\t\t\t\t       dma_unmap_len(info, maplen),\n\t\t\t\t       DMA_TO_DEVICE);\n\t\t\tdma_unmap_len_set(info, maplen, 0);\n\t\t}\n\t\tif (skb) {\n\t\t\tdev_kfree_skb(skb);\n\t\t\tinfo->skb = NULL;\n\t\t}\n\t}\n\n\tif (ap->jumbo) {\n\t\tcmd.evt = C_RESET_JUMBO_RNG;\n\t\tcmd.code = 0;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t}\n\n\tace_unmask_irq(dev);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}\n\n\nstatic inline dma_addr_t\nace_map_tx_skb(struct ace_private *ap, struct sk_buff *skb,\n\t       struct sk_buff *tail, u32 idx)\n{\n\tdma_addr_t mapping;\n\tstruct tx_ring_info *info;\n\n\tmapping = dma_map_page(&ap->pdev->dev, virt_to_page(skb->data),\n\t\t\t       offset_in_page(skb->data), skb->len,\n\t\t\t       DMA_TO_DEVICE);\n\n\tinfo = ap->skb->tx_skbuff + idx;\n\tinfo->skb = tail;\n\tdma_unmap_addr_set(info, mapping, mapping);\n\tdma_unmap_len_set(info, maplen, skb->len);\n\treturn mapping;\n}\n\n\nstatic inline void\nace_load_tx_bd(struct ace_private *ap, struct tx_desc *desc, u64 addr,\n\t       u32 flagsize, u32 vlan_tag)\n{\n#if !USE_TX_COAL_NOW\n\tflagsize &= ~BD_FLG_COAL_NOW;\n#endif\n\n\tif (ACE_IS_TIGON_I(ap)) {\n\t\tstruct tx_desc __iomem *io = (__force struct tx_desc __iomem *) desc;\n\t\twritel(addr >> 32, &io->addr.addrhi);\n\t\twritel(addr & 0xffffffff, &io->addr.addrlo);\n\t\twritel(flagsize, &io->flagsize);\n\t\twritel(vlan_tag, &io->vlanres);\n\t} else {\n\t\tdesc->addr.addrhi = addr >> 32;\n\t\tdesc->addr.addrlo = addr;\n\t\tdesc->flagsize = flagsize;\n\t\tdesc->vlanres = vlan_tag;\n\t}\n}\n\n\nstatic netdev_tx_t ace_start_xmit(struct sk_buff *skb,\n\t\t\t\t  struct net_device *dev)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tstruct tx_desc *desc;\n\tu32 idx, flagsize;\n\tunsigned long maxjiff = jiffies + 3*HZ;\n\nrestart:\n\tidx = ap->tx_prd;\n\n\tif (tx_ring_full(ap, ap->tx_ret_csm, idx))\n\t\tgoto overflow;\n\n\tif (!skb_shinfo(skb)->nr_frags)\t{\n\t\tdma_addr_t mapping;\n\t\tu32 vlan_tag = 0;\n\n\t\tmapping = ace_map_tx_skb(ap, skb, skb, idx);\n\t\tflagsize = (skb->len << 16) | (BD_FLG_END);\n\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\tflagsize |= BD_FLG_TCP_UDP_SUM;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\tflagsize |= BD_FLG_VLAN_TAG;\n\t\t\tvlan_tag = skb_vlan_tag_get(skb);\n\t\t}\n\t\tdesc = ap->tx_ring + idx;\n\t\tidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\n\n\t\t \n\t\tif (tx_ring_full(ap, ap->tx_ret_csm, idx))\n\t\t\tflagsize |= BD_FLG_COAL_NOW;\n\n\t\tace_load_tx_bd(ap, desc, mapping, flagsize, vlan_tag);\n\t} else {\n\t\tdma_addr_t mapping;\n\t\tu32 vlan_tag = 0;\n\t\tint i;\n\n\t\tmapping = ace_map_tx_skb(ap, skb, NULL, idx);\n\t\tflagsize = (skb_headlen(skb) << 16);\n\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\tflagsize |= BD_FLG_TCP_UDP_SUM;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\tflagsize |= BD_FLG_VLAN_TAG;\n\t\t\tvlan_tag = skb_vlan_tag_get(skb);\n\t\t}\n\n\t\tace_load_tx_bd(ap, ap->tx_ring + idx, mapping, flagsize, vlan_tag);\n\n\t\tidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\n\n\t\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\t\tconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\t\t\tstruct tx_ring_info *info;\n\n\t\t\tinfo = ap->skb->tx_skbuff + idx;\n\t\t\tdesc = ap->tx_ring + idx;\n\n\t\t\tmapping = skb_frag_dma_map(&ap->pdev->dev, frag, 0,\n\t\t\t\t\t\t   skb_frag_size(frag),\n\t\t\t\t\t\t   DMA_TO_DEVICE);\n\n\t\t\tflagsize = skb_frag_size(frag) << 16;\n\t\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\t\tflagsize |= BD_FLG_TCP_UDP_SUM;\n\t\t\tidx = (idx + 1) % ACE_TX_RING_ENTRIES(ap);\n\n\t\t\tif (i == skb_shinfo(skb)->nr_frags - 1) {\n\t\t\t\tflagsize |= BD_FLG_END;\n\t\t\t\tif (tx_ring_full(ap, ap->tx_ret_csm, idx))\n\t\t\t\t\tflagsize |= BD_FLG_COAL_NOW;\n\n\t\t\t\t \n\t\t\t\tinfo->skb = skb;\n\t\t\t} else {\n\t\t\t\tinfo->skb = NULL;\n\t\t\t}\n\t\t\tdma_unmap_addr_set(info, mapping, mapping);\n\t\t\tdma_unmap_len_set(info, maplen, skb_frag_size(frag));\n\t\t\tace_load_tx_bd(ap, desc, mapping, flagsize, vlan_tag);\n\t\t}\n\t}\n\n\twmb();\n\tap->tx_prd = idx;\n\tace_set_txprd(regs, ap, idx);\n\n\tif (flagsize & BD_FLG_COAL_NOW) {\n\t\tnetif_stop_queue(dev);\n\n\t\t \n\t\tif (!tx_ring_full(ap, ap->tx_ret_csm, idx))\n\t\t\tnetif_wake_queue(dev);\n\t}\n\n\treturn NETDEV_TX_OK;\n\noverflow:\n\t \n\tif (time_before(jiffies, maxjiff)) {\n\t\tbarrier();\n\t\tcpu_relax();\n\t\tgoto restart;\n\t}\n\n\t \n\tprintk(KERN_WARNING \"%s: Transmit ring stuck full\\n\", dev->name);\n\treturn NETDEV_TX_BUSY;\n}\n\n\nstatic int ace_change_mtu(struct net_device *dev, int new_mtu)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\n\twritel(new_mtu + ETH_HLEN + 4, &regs->IfMtu);\n\tdev->mtu = new_mtu;\n\n\tif (new_mtu > ACE_STD_MTU) {\n\t\tif (!(ap->jumbo)) {\n\t\t\tprintk(KERN_INFO \"%s: Enabling Jumbo frame \"\n\t\t\t       \"support\\n\", dev->name);\n\t\t\tap->jumbo = 1;\n\t\t\tif (!test_and_set_bit(0, &ap->jumbo_refill_busy))\n\t\t\t\tace_load_jumbo_rx_ring(dev, RX_JUMBO_SIZE);\n\t\t\tace_set_rxtx_parms(dev, 1);\n\t\t}\n\t} else {\n\t\twhile (test_and_set_bit(0, &ap->jumbo_refill_busy));\n\t\tace_sync_irq(dev->irq);\n\t\tace_set_rxtx_parms(dev, 0);\n\t\tif (ap->jumbo) {\n\t\t\tstruct cmd cmd;\n\n\t\t\tcmd.evt = C_RESET_JUMBO_RNG;\n\t\t\tcmd.code = 0;\n\t\t\tcmd.idx = 0;\n\t\t\tace_issue_cmd(regs, &cmd);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int ace_get_link_ksettings(struct net_device *dev,\n\t\t\t\t  struct ethtool_link_ksettings *cmd)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tu32 link;\n\tu32 supported;\n\n\tmemset(cmd, 0, sizeof(struct ethtool_link_ksettings));\n\n\tsupported = (SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full |\n\t\t     SUPPORTED_100baseT_Half | SUPPORTED_100baseT_Full |\n\t\t     SUPPORTED_1000baseT_Half | SUPPORTED_1000baseT_Full |\n\t\t     SUPPORTED_Autoneg | SUPPORTED_FIBRE);\n\n\tcmd->base.port = PORT_FIBRE;\n\n\tlink = readl(&regs->GigLnkState);\n\tif (link & LNK_1000MB) {\n\t\tcmd->base.speed = SPEED_1000;\n\t} else {\n\t\tlink = readl(&regs->FastLnkState);\n\t\tif (link & LNK_100MB)\n\t\t\tcmd->base.speed = SPEED_100;\n\t\telse if (link & LNK_10MB)\n\t\t\tcmd->base.speed = SPEED_10;\n\t\telse\n\t\t\tcmd->base.speed = 0;\n\t}\n\tif (link & LNK_FULL_DUPLEX)\n\t\tcmd->base.duplex = DUPLEX_FULL;\n\telse\n\t\tcmd->base.duplex = DUPLEX_HALF;\n\n\tif (link & LNK_NEGOTIATE)\n\t\tcmd->base.autoneg = AUTONEG_ENABLE;\n\telse\n\t\tcmd->base.autoneg = AUTONEG_DISABLE;\n\n#if 0\n\t \n\tecmd->trace = readl(&regs->TuneTrace);\n\n\tecmd->txcoal = readl(&regs->TuneTxCoalTicks);\n\tecmd->rxcoal = readl(&regs->TuneRxCoalTicks);\n#endif\n\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported,\n\t\t\t\t\t\tsupported);\n\n\treturn 0;\n}\n\nstatic int ace_set_link_ksettings(struct net_device *dev,\n\t\t\t\t  const struct ethtool_link_ksettings *cmd)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tu32 link, speed;\n\n\tlink = readl(&regs->GigLnkState);\n\tif (link & LNK_1000MB)\n\t\tspeed = SPEED_1000;\n\telse {\n\t\tlink = readl(&regs->FastLnkState);\n\t\tif (link & LNK_100MB)\n\t\t\tspeed = SPEED_100;\n\t\telse if (link & LNK_10MB)\n\t\t\tspeed = SPEED_10;\n\t\telse\n\t\t\tspeed = SPEED_100;\n\t}\n\n\tlink = LNK_ENABLE | LNK_1000MB | LNK_100MB | LNK_10MB |\n\t\tLNK_RX_FLOW_CTL_Y | LNK_NEG_FCTL;\n\tif (!ACE_IS_TIGON_I(ap))\n\t\tlink |= LNK_TX_FLOW_CTL_Y;\n\tif (cmd->base.autoneg == AUTONEG_ENABLE)\n\t\tlink |= LNK_NEGOTIATE;\n\tif (cmd->base.speed != speed) {\n\t\tlink &= ~(LNK_1000MB | LNK_100MB | LNK_10MB);\n\t\tswitch (cmd->base.speed) {\n\t\tcase SPEED_1000:\n\t\t\tlink |= LNK_1000MB;\n\t\t\tbreak;\n\t\tcase SPEED_100:\n\t\t\tlink |= LNK_100MB;\n\t\t\tbreak;\n\t\tcase SPEED_10:\n\t\t\tlink |= LNK_10MB;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (cmd->base.duplex == DUPLEX_FULL)\n\t\tlink |= LNK_FULL_DUPLEX;\n\n\tif (link != ap->link) {\n\t\tstruct cmd cmd;\n\t\tprintk(KERN_INFO \"%s: Renegotiating link state\\n\",\n\t\t       dev->name);\n\n\t\tap->link = link;\n\t\twritel(link, &regs->TuneLink);\n\t\tif (!ACE_IS_TIGON_I(ap))\n\t\t\twritel(link, &regs->TuneFastLink);\n\t\twmb();\n\n\t\tcmd.evt = C_LNK_NEGOTIATION;\n\t\tcmd.code = 0;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t}\n\treturn 0;\n}\n\nstatic void ace_get_drvinfo(struct net_device *dev,\n\t\t\t    struct ethtool_drvinfo *info)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\n\tstrscpy(info->driver, \"acenic\", sizeof(info->driver));\n\tsnprintf(info->fw_version, sizeof(info->version), \"%i.%i.%i\",\n\t\t ap->firmware_major, ap->firmware_minor, ap->firmware_fix);\n\n\tif (ap->pdev)\n\t\tstrscpy(info->bus_info, pci_name(ap->pdev),\n\t\t\tsizeof(info->bus_info));\n\n}\n\n \nstatic int ace_set_mac_addr(struct net_device *dev, void *p)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tstruct sockaddr *addr=p;\n\tconst u8 *da;\n\tstruct cmd cmd;\n\n\tif(netif_running(dev))\n\t\treturn -EBUSY;\n\n\teth_hw_addr_set(dev, addr->sa_data);\n\n\tda = (const u8 *)dev->dev_addr;\n\n\twritel(da[0] << 8 | da[1], &regs->MacAddrHi);\n\twritel((da[2] << 24) | (da[3] << 16) | (da[4] << 8) | da[5],\n\t       &regs->MacAddrLo);\n\n\tcmd.evt = C_SET_MAC_ADDR;\n\tcmd.code = 0;\n\tcmd.idx = 0;\n\tace_issue_cmd(regs, &cmd);\n\n\treturn 0;\n}\n\n\nstatic void ace_set_multicast_list(struct net_device *dev)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tstruct cmd cmd;\n\n\tif ((dev->flags & IFF_ALLMULTI) && !(ap->mcast_all)) {\n\t\tcmd.evt = C_SET_MULTICAST_MODE;\n\t\tcmd.code = C_C_MCAST_ENABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t\tap->mcast_all = 1;\n\t} else if (ap->mcast_all) {\n\t\tcmd.evt = C_SET_MULTICAST_MODE;\n\t\tcmd.code = C_C_MCAST_DISABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t\tap->mcast_all = 0;\n\t}\n\n\tif ((dev->flags & IFF_PROMISC) && !(ap->promisc)) {\n\t\tcmd.evt = C_SET_PROMISC_MODE;\n\t\tcmd.code = C_C_PROMISC_ENABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t\tap->promisc = 1;\n\t}else if (!(dev->flags & IFF_PROMISC) && (ap->promisc)) {\n\t\tcmd.evt = C_SET_PROMISC_MODE;\n\t\tcmd.code = C_C_PROMISC_DISABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t\tap->promisc = 0;\n\t}\n\n\t \n\tif (!netdev_mc_empty(dev) && !ap->mcast_all) {\n\t\tcmd.evt = C_SET_MULTICAST_MODE;\n\t\tcmd.code = C_C_MCAST_ENABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t}else if (!ap->mcast_all) {\n\t\tcmd.evt = C_SET_MULTICAST_MODE;\n\t\tcmd.code = C_C_MCAST_DISABLE;\n\t\tcmd.idx = 0;\n\t\tace_issue_cmd(regs, &cmd);\n\t}\n}\n\n\nstatic struct net_device_stats *ace_get_stats(struct net_device *dev)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_mac_stats __iomem *mac_stats =\n\t\t(struct ace_mac_stats __iomem *)ap->regs->Stats;\n\n\tdev->stats.rx_missed_errors = readl(&mac_stats->drop_space);\n\tdev->stats.multicast = readl(&mac_stats->kept_mc);\n\tdev->stats.collisions = readl(&mac_stats->coll);\n\n\treturn &dev->stats;\n}\n\n\nstatic void ace_copy(struct ace_regs __iomem *regs, const __be32 *src,\n\t\t     u32 dest, int size)\n{\n\tvoid __iomem *tdest;\n\tshort tsize, i;\n\n\tif (size <= 0)\n\t\treturn;\n\n\twhile (size > 0) {\n\t\ttsize = min_t(u32, ((~dest & (ACE_WINDOW_SIZE - 1)) + 1),\n\t\t\t    min_t(u32, size, ACE_WINDOW_SIZE));\n\t\ttdest = (void __iomem *) &regs->Window +\n\t\t\t(dest & (ACE_WINDOW_SIZE - 1));\n\t\twritel(dest & ~(ACE_WINDOW_SIZE - 1), &regs->WinBase);\n\t\tfor (i = 0; i < (tsize / 4); i++) {\n\t\t\t \n\t\t\twritel(be32_to_cpup(src), tdest);\n\t\t\tsrc++;\n\t\t\ttdest += 4;\n\t\t\tdest += 4;\n\t\t\tsize -= 4;\n\t\t}\n\t}\n}\n\n\nstatic void ace_clear(struct ace_regs __iomem *regs, u32 dest, int size)\n{\n\tvoid __iomem *tdest;\n\tshort tsize = 0, i;\n\n\tif (size <= 0)\n\t\treturn;\n\n\twhile (size > 0) {\n\t\ttsize = min_t(u32, ((~dest & (ACE_WINDOW_SIZE - 1)) + 1),\n\t\t\t\tmin_t(u32, size, ACE_WINDOW_SIZE));\n\t\ttdest = (void __iomem *) &regs->Window +\n\t\t\t(dest & (ACE_WINDOW_SIZE - 1));\n\t\twritel(dest & ~(ACE_WINDOW_SIZE - 1), &regs->WinBase);\n\n\t\tfor (i = 0; i < (tsize / 4); i++) {\n\t\t\twritel(0, tdest + i*4);\n\t\t}\n\n\t\tdest += tsize;\n\t\tsize -= tsize;\n\t}\n}\n\n\n \nstatic int ace_load_firmware(struct net_device *dev)\n{\n\tconst struct firmware *fw;\n\tconst char *fw_name = \"acenic/tg2.bin\";\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tconst __be32 *fw_data;\n\tu32 load_addr;\n\tint ret;\n\n\tif (!(readl(&regs->CpuCtrl) & CPU_HALTED)) {\n\t\tprintk(KERN_ERR \"%s: trying to download firmware while the \"\n\t\t       \"CPU is running!\\n\", ap->name);\n\t\treturn -EFAULT;\n\t}\n\n\tif (ACE_IS_TIGON_I(ap))\n\t\tfw_name = \"acenic/tg1.bin\";\n\n\tret = request_firmware(&fw, fw_name, &ap->pdev->dev);\n\tif (ret) {\n\t\tprintk(KERN_ERR \"%s: Failed to load firmware \\\"%s\\\"\\n\",\n\t\t       ap->name, fw_name);\n\t\treturn ret;\n\t}\n\n\tfw_data = (void *)fw->data;\n\n\t \n\tap->firmware_major = fw->data[0];\n\tap->firmware_minor = fw->data[1];\n\tap->firmware_fix = fw->data[2];\n\n\tap->firmware_start = be32_to_cpu(fw_data[1]);\n\tif (ap->firmware_start < 0x4000 || ap->firmware_start >= 0x80000) {\n\t\tprintk(KERN_ERR \"%s: bogus load address %08x in \\\"%s\\\"\\n\",\n\t\t       ap->name, ap->firmware_start, fw_name);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tload_addr = be32_to_cpu(fw_data[2]);\n\tif (load_addr < 0x4000 || load_addr >= 0x80000) {\n\t\tprintk(KERN_ERR \"%s: bogus load address %08x in \\\"%s\\\"\\n\",\n\t\t       ap->name, load_addr, fw_name);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t \n\tace_clear(regs, 0x2000, 0x80000-0x2000);\n\tace_copy(regs, &fw_data[3], load_addr, fw->size-12);\n out:\n\trelease_firmware(fw);\n\treturn ret;\n}\n\n\n \nstatic void eeprom_start(struct ace_regs __iomem *regs)\n{\n\tu32 local;\n\n\treadl(&regs->LocalCtrl);\n\tudelay(ACE_SHORT_DELAY);\n\tlocal = readl(&regs->LocalCtrl);\n\tlocal |= EEPROM_DATA_OUT | EEPROM_WRITE_ENABLE;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\tlocal |= EEPROM_CLK_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\tlocal &= ~EEPROM_DATA_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\tlocal &= ~EEPROM_CLK_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n}\n\n\nstatic void eeprom_prep(struct ace_regs __iomem *regs, u8 magic)\n{\n\tshort i;\n\tu32 local;\n\n\tudelay(ACE_SHORT_DELAY);\n\tlocal = readl(&regs->LocalCtrl);\n\tlocal &= ~EEPROM_DATA_OUT;\n\tlocal |= EEPROM_WRITE_ENABLE;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\n\tfor (i = 0; i < 8; i++, magic <<= 1) {\n\t\tudelay(ACE_SHORT_DELAY);\n\t\tif (magic & 0x80)\n\t\t\tlocal |= EEPROM_DATA_OUT;\n\t\telse\n\t\t\tlocal &= ~EEPROM_DATA_OUT;\n\t\twritel(local, &regs->LocalCtrl);\n\t\treadl(&regs->LocalCtrl);\n\t\tmb();\n\n\t\tudelay(ACE_SHORT_DELAY);\n\t\tlocal |= EEPROM_CLK_OUT;\n\t\twritel(local, &regs->LocalCtrl);\n\t\treadl(&regs->LocalCtrl);\n\t\tmb();\n\t\tudelay(ACE_SHORT_DELAY);\n\t\tlocal &= ~(EEPROM_CLK_OUT | EEPROM_DATA_OUT);\n\t\twritel(local, &regs->LocalCtrl);\n\t\treadl(&regs->LocalCtrl);\n\t\tmb();\n\t}\n}\n\n\nstatic int eeprom_check_ack(struct ace_regs __iomem *regs)\n{\n\tint state;\n\tu32 local;\n\n\tlocal = readl(&regs->LocalCtrl);\n\tlocal &= ~EEPROM_WRITE_ENABLE;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_LONG_DELAY);\n\tlocal |= EEPROM_CLK_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\t \n\tstate = (readl(&regs->LocalCtrl) & EEPROM_DATA_IN) != 0;\n\tudelay(ACE_SHORT_DELAY);\n\tmb();\n\twritel(readl(&regs->LocalCtrl) & ~EEPROM_CLK_OUT, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\n\treturn state;\n}\n\n\nstatic void eeprom_stop(struct ace_regs __iomem *regs)\n{\n\tu32 local;\n\n\tudelay(ACE_SHORT_DELAY);\n\tlocal = readl(&regs->LocalCtrl);\n\tlocal |= EEPROM_WRITE_ENABLE;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\tlocal &= ~EEPROM_DATA_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\tlocal |= EEPROM_CLK_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\tlocal |= EEPROM_DATA_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_LONG_DELAY);\n\tlocal &= ~EEPROM_CLK_OUT;\n\twritel(local, &regs->LocalCtrl);\n\tmb();\n}\n\n\n \nstatic int read_eeprom_byte(struct net_device *dev, unsigned long offset)\n{\n\tstruct ace_private *ap = netdev_priv(dev);\n\tstruct ace_regs __iomem *regs = ap->regs;\n\tunsigned long flags;\n\tu32 local;\n\tint result = 0;\n\tshort i;\n\n\t \n\tlocal_irq_save(flags);\n\n\teeprom_start(regs);\n\n\teeprom_prep(regs, EEPROM_WRITE_SELECT);\n\tif (eeprom_check_ack(regs)) {\n\t\tlocal_irq_restore(flags);\n\t\tprintk(KERN_ERR \"%s: Unable to sync eeprom\\n\", ap->name);\n\t\tresult = -EIO;\n\t\tgoto eeprom_read_error;\n\t}\n\n\teeprom_prep(regs, (offset >> 8) & 0xff);\n\tif (eeprom_check_ack(regs)) {\n\t\tlocal_irq_restore(flags);\n\t\tprintk(KERN_ERR \"%s: Unable to set address byte 0\\n\",\n\t\t       ap->name);\n\t\tresult = -EIO;\n\t\tgoto eeprom_read_error;\n\t}\n\n\teeprom_prep(regs, offset & 0xff);\n\tif (eeprom_check_ack(regs)) {\n\t\tlocal_irq_restore(flags);\n\t\tprintk(KERN_ERR \"%s: Unable to set address byte 1\\n\",\n\t\t       ap->name);\n\t\tresult = -EIO;\n\t\tgoto eeprom_read_error;\n\t}\n\n\teeprom_start(regs);\n\teeprom_prep(regs, EEPROM_READ_SELECT);\n\tif (eeprom_check_ack(regs)) {\n\t\tlocal_irq_restore(flags);\n\t\tprintk(KERN_ERR \"%s: Unable to set READ_SELECT\\n\",\n\t\t       ap->name);\n\t\tresult = -EIO;\n\t\tgoto eeprom_read_error;\n\t}\n\n\tfor (i = 0; i < 8; i++) {\n\t\tlocal = readl(&regs->LocalCtrl);\n\t\tlocal &= ~EEPROM_WRITE_ENABLE;\n\t\twritel(local, &regs->LocalCtrl);\n\t\treadl(&regs->LocalCtrl);\n\t\tudelay(ACE_LONG_DELAY);\n\t\tmb();\n\t\tlocal |= EEPROM_CLK_OUT;\n\t\twritel(local, &regs->LocalCtrl);\n\t\treadl(&regs->LocalCtrl);\n\t\tmb();\n\t\tudelay(ACE_SHORT_DELAY);\n\t\t \n\t\tresult = (result << 1) |\n\t\t\t((readl(&regs->LocalCtrl) & EEPROM_DATA_IN) != 0);\n\t\tudelay(ACE_SHORT_DELAY);\n\t\tmb();\n\t\tlocal = readl(&regs->LocalCtrl);\n\t\tlocal &= ~EEPROM_CLK_OUT;\n\t\twritel(local, &regs->LocalCtrl);\n\t\treadl(&regs->LocalCtrl);\n\t\tudelay(ACE_SHORT_DELAY);\n\t\tmb();\n\t\tif (i == 7) {\n\t\t\tlocal |= EEPROM_WRITE_ENABLE;\n\t\t\twritel(local, &regs->LocalCtrl);\n\t\t\treadl(&regs->LocalCtrl);\n\t\t\tmb();\n\t\t\tudelay(ACE_SHORT_DELAY);\n\t\t}\n\t}\n\n\tlocal |= EEPROM_DATA_OUT;\n\twritel(local, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\twritel(readl(&regs->LocalCtrl) | EEPROM_CLK_OUT, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tudelay(ACE_LONG_DELAY);\n\twritel(readl(&regs->LocalCtrl) & ~EEPROM_CLK_OUT, &regs->LocalCtrl);\n\treadl(&regs->LocalCtrl);\n\tmb();\n\tudelay(ACE_SHORT_DELAY);\n\teeprom_stop(regs);\n\n\tlocal_irq_restore(flags);\n out:\n\treturn result;\n\n eeprom_read_error:\n\tprintk(KERN_ERR \"%s: Unable to read eeprom byte 0x%02lx\\n\",\n\t       ap->name, offset);\n\tgoto out;\n}\n\nmodule_pci_driver(acenic_pci_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}