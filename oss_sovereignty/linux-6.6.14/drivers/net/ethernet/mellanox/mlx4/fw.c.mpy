{
  "module_name": "fw.c",
  "hash_id": "a18efcf89ca8ef5143ffdbba7b6fb6c6d94b0085e007d91855f1a1d732cc8cae",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx4/fw.c",
  "human_readable_source": " \n\n#include <linux/etherdevice.h>\n#include <linux/mlx4/cmd.h>\n#include <linux/module.h>\n#include <linux/cache.h>\n#include <linux/kernel.h>\n#include <uapi/rdma/mlx4-abi.h>\n\n#include \"fw.h\"\n#include \"icm.h\"\n\nenum {\n\tMLX4_COMMAND_INTERFACE_MIN_REV\t\t= 2,\n\tMLX4_COMMAND_INTERFACE_MAX_REV\t\t= 3,\n\tMLX4_COMMAND_INTERFACE_NEW_PORT_CMDS\t= 3,\n};\n\nextern void __buggy_use_of_MLX4_GET(void);\nextern void __buggy_use_of_MLX4_PUT(void);\n\nstatic bool enable_qos;\nmodule_param(enable_qos, bool, 0444);\nMODULE_PARM_DESC(enable_qos, \"Enable Enhanced QoS support (default: off)\");\n\n#define MLX4_GET(dest, source, offset)\t\t\t\t      \\\n\tdo {\t\t\t\t\t\t\t      \\\n\t\tvoid *__p = (char *) (source) + (offset);\t      \\\n\t\t__be64 val;                                           \\\n\t\tswitch (sizeof(dest)) {\t\t\t\t      \\\n\t\tcase 1: (dest) = *(u8 *) __p;\t    break;\t      \\\n\t\tcase 2: (dest) = be16_to_cpup(__p); break;\t      \\\n\t\tcase 4: (dest) = be32_to_cpup(__p); break;\t      \\\n\t\tcase 8: val = get_unaligned((__be64 *)__p);           \\\n\t\t\t(dest) = be64_to_cpu(val);  break;            \\\n\t\tdefault: __buggy_use_of_MLX4_GET();\t\t      \\\n\t\t}\t\t\t\t\t\t      \\\n\t} while (0)\n\n#define MLX4_PUT(dest, source, offset)\t\t\t\t      \\\n\tdo {\t\t\t\t\t\t\t      \\\n\t\tvoid *__d = ((char *) (dest) + (offset));\t      \\\n\t\tswitch (sizeof(source)) {\t\t\t      \\\n\t\tcase 1: *(u8 *) __d = (source);\t\t       break; \\\n\t\tcase 2:\t*(__be16 *) __d = cpu_to_be16(source); break; \\\n\t\tcase 4:\t*(__be32 *) __d = cpu_to_be32(source); break; \\\n\t\tcase 8:\t*(__be64 *) __d = cpu_to_be64(source); break; \\\n\t\tdefault: __buggy_use_of_MLX4_PUT();\t\t      \\\n\t\t}\t\t\t\t\t\t      \\\n\t} while (0)\n\nstatic void dump_dev_cap_flags(struct mlx4_dev *dev, u64 flags)\n{\n\tstatic const char *fname[] = {\n\t\t[ 0] = \"RC transport\",\n\t\t[ 1] = \"UC transport\",\n\t\t[ 2] = \"UD transport\",\n\t\t[ 3] = \"XRC transport\",\n\t\t[ 6] = \"SRQ support\",\n\t\t[ 7] = \"IPoIB checksum offload\",\n\t\t[ 8] = \"P_Key violation counter\",\n\t\t[ 9] = \"Q_Key violation counter\",\n\t\t[12] = \"Dual Port Different Protocol (DPDP) support\",\n\t\t[15] = \"Big LSO headers\",\n\t\t[16] = \"MW support\",\n\t\t[17] = \"APM support\",\n\t\t[18] = \"Atomic ops support\",\n\t\t[19] = \"Raw multicast support\",\n\t\t[20] = \"Address vector port checking support\",\n\t\t[21] = \"UD multicast support\",\n\t\t[30] = \"IBoE support\",\n\t\t[32] = \"Unicast loopback support\",\n\t\t[34] = \"FCS header control\",\n\t\t[37] = \"Wake On LAN (port1) support\",\n\t\t[38] = \"Wake On LAN (port2) support\",\n\t\t[40] = \"UDP RSS support\",\n\t\t[41] = \"Unicast VEP steering support\",\n\t\t[42] = \"Multicast VEP steering support\",\n\t\t[48] = \"Counters support\",\n\t\t[52] = \"RSS IP fragments support\",\n\t\t[53] = \"Port ETS Scheduler support\",\n\t\t[55] = \"Port link type sensing support\",\n\t\t[59] = \"Port management change event support\",\n\t\t[61] = \"64 byte EQE support\",\n\t\t[62] = \"64 byte CQE support\",\n\t};\n\tint i;\n\n\tmlx4_dbg(dev, \"DEV_CAP flags:\\n\");\n\tfor (i = 0; i < ARRAY_SIZE(fname); ++i)\n\t\tif (fname[i] && (flags & (1LL << i)))\n\t\t\tmlx4_dbg(dev, \"    %s\\n\", fname[i]);\n}\n\nstatic void dump_dev_cap_flags2(struct mlx4_dev *dev, u64 flags)\n{\n\tstatic const char * const fname[] = {\n\t\t[0] = \"RSS support\",\n\t\t[1] = \"RSS Toeplitz Hash Function support\",\n\t\t[2] = \"RSS XOR Hash Function support\",\n\t\t[3] = \"Device managed flow steering support\",\n\t\t[4] = \"Automatic MAC reassignment support\",\n\t\t[5] = \"Time stamping support\",\n\t\t[6] = \"VST (control vlan insertion/stripping) support\",\n\t\t[7] = \"FSM (MAC anti-spoofing) support\",\n\t\t[8] = \"Dynamic QP updates support\",\n\t\t[9] = \"Device managed flow steering IPoIB support\",\n\t\t[10] = \"TCP/IP offloads/flow-steering for VXLAN support\",\n\t\t[11] = \"MAD DEMUX (Secure-Host) support\",\n\t\t[12] = \"Large cache line (>64B) CQE stride support\",\n\t\t[13] = \"Large cache line (>64B) EQE stride support\",\n\t\t[14] = \"Ethernet protocol control support\",\n\t\t[15] = \"Ethernet Backplane autoneg support\",\n\t\t[16] = \"CONFIG DEV support\",\n\t\t[17] = \"Asymmetric EQs support\",\n\t\t[18] = \"More than 80 VFs support\",\n\t\t[19] = \"Performance optimized for limited rule configuration flow steering support\",\n\t\t[20] = \"Recoverable error events support\",\n\t\t[21] = \"Port Remap support\",\n\t\t[22] = \"QCN support\",\n\t\t[23] = \"QP rate limiting support\",\n\t\t[24] = \"Ethernet Flow control statistics support\",\n\t\t[25] = \"Granular QoS per VF support\",\n\t\t[26] = \"Port ETS Scheduler support\",\n\t\t[27] = \"Port beacon support\",\n\t\t[28] = \"RX-ALL support\",\n\t\t[29] = \"802.1ad offload support\",\n\t\t[31] = \"Modifying loopback source checks using UPDATE_QP support\",\n\t\t[32] = \"Loopback source checks support\",\n\t\t[33] = \"RoCEv2 support\",\n\t\t[34] = \"DMFS Sniffer support (UC & MC)\",\n\t\t[35] = \"Diag counters per port\",\n\t\t[36] = \"QinQ VST mode support\",\n\t\t[37] = \"sl to vl mapping table change event support\",\n\t\t[38] = \"user MAC support\",\n\t\t[39] = \"Report driver version to FW support\",\n\t\t[40] = \"SW CQ initialization support\",\n\t};\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(fname); ++i)\n\t\tif (fname[i] && (flags & (1LL << i)))\n\t\t\tmlx4_dbg(dev, \"    %s\\n\", fname[i]);\n}\n\nint mlx4_MOD_STAT_CFG(struct mlx4_dev *dev, struct mlx4_mod_stat_cfg *cfg)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *inbox;\n\tint err = 0;\n\n#define MOD_STAT_CFG_IN_SIZE\t\t0x100\n\n#define MOD_STAT_CFG_PG_SZ_M_OFFSET\t0x002\n#define MOD_STAT_CFG_PG_SZ_OFFSET\t0x003\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\tinbox = mailbox->buf;\n\n\tMLX4_PUT(inbox, cfg->log_pg_sz, MOD_STAT_CFG_PG_SZ_OFFSET);\n\tMLX4_PUT(inbox, cfg->log_pg_sz_m, MOD_STAT_CFG_PG_SZ_M_OFFSET);\n\n\terr = mlx4_cmd(dev, mailbox->dma, 0, 0, MLX4_CMD_MOD_STAT_CFG,\n\t\t\tMLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nint mlx4_QUERY_FUNC(struct mlx4_dev *dev, struct mlx4_func *func, int slave)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *outbox;\n\tu8 in_modifier;\n\tu8 field;\n\tu16 field16;\n\tint err;\n\n#define QUERY_FUNC_BUS_OFFSET\t\t\t0x00\n#define QUERY_FUNC_DEVICE_OFFSET\t\t0x01\n#define QUERY_FUNC_FUNCTION_OFFSET\t\t0x01\n#define QUERY_FUNC_PHYSICAL_FUNCTION_OFFSET\t0x03\n#define QUERY_FUNC_RSVD_EQS_OFFSET\t\t0x04\n#define QUERY_FUNC_MAX_EQ_OFFSET\t\t0x06\n#define QUERY_FUNC_RSVD_UARS_OFFSET\t\t0x0b\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\toutbox = mailbox->buf;\n\n\tin_modifier = slave;\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, in_modifier, 0,\n\t\t\t   MLX4_CMD_QUERY_FUNC,\n\t\t\t   MLX4_CMD_TIME_CLASS_A,\n\t\t\t   MLX4_CMD_NATIVE);\n\tif (err)\n\t\tgoto out;\n\n\tMLX4_GET(field, outbox, QUERY_FUNC_BUS_OFFSET);\n\tfunc->bus = field & 0xf;\n\tMLX4_GET(field, outbox, QUERY_FUNC_DEVICE_OFFSET);\n\tfunc->device = field & 0xf1;\n\tMLX4_GET(field, outbox, QUERY_FUNC_FUNCTION_OFFSET);\n\tfunc->function = field & 0x7;\n\tMLX4_GET(field, outbox, QUERY_FUNC_PHYSICAL_FUNCTION_OFFSET);\n\tfunc->physical_function = field & 0xf;\n\tMLX4_GET(field16, outbox, QUERY_FUNC_RSVD_EQS_OFFSET);\n\tfunc->rsvd_eqs = field16 & 0xffff;\n\tMLX4_GET(field16, outbox, QUERY_FUNC_MAX_EQ_OFFSET);\n\tfunc->max_eq = field16 & 0xffff;\n\tMLX4_GET(field, outbox, QUERY_FUNC_RSVD_UARS_OFFSET);\n\tfunc->rsvd_uars = field & 0x0f;\n\n\tmlx4_dbg(dev, \"Bus: %d, Device: %d, Function: %d, Physical function: %d, Max EQs: %d, Reserved EQs: %d, Reserved UARs: %d\\n\",\n\t\t func->bus, func->device, func->function, func->physical_function,\n\t\t func->max_eq, func->rsvd_eqs, func->rsvd_uars);\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nstatic int mlx4_activate_vst_qinq(struct mlx4_priv *priv, int slave, int port)\n{\n\tstruct mlx4_vport_oper_state *vp_oper;\n\tstruct mlx4_vport_state *vp_admin;\n\tint err;\n\n\tvp_oper = &priv->mfunc.master.vf_oper[slave].vport[port];\n\tvp_admin = &priv->mfunc.master.vf_admin[slave].vport[port];\n\n\tif (vp_admin->default_vlan != vp_oper->state.default_vlan) {\n\t\terr = __mlx4_register_vlan(&priv->dev, port,\n\t\t\t\t\t   vp_admin->default_vlan,\n\t\t\t\t\t   &vp_oper->vlan_idx);\n\t\tif (err) {\n\t\t\tvp_oper->vlan_idx = NO_INDX;\n\t\t\tmlx4_warn(&priv->dev,\n\t\t\t\t  \"No vlan resources slave %d, port %d\\n\",\n\t\t\t\t  slave, port);\n\t\t\treturn err;\n\t\t}\n\t\tmlx4_dbg(&priv->dev, \"alloc vlan %d idx  %d slave %d port %d\\n\",\n\t\t\t (int)(vp_oper->state.default_vlan),\n\t\t\t vp_oper->vlan_idx, slave, port);\n\t}\n\tvp_oper->state.vlan_proto   = vp_admin->vlan_proto;\n\tvp_oper->state.default_vlan = vp_admin->default_vlan;\n\tvp_oper->state.default_qos  = vp_admin->default_qos;\n\n\treturn 0;\n}\n\nstatic int mlx4_handle_vst_qinq(struct mlx4_priv *priv, int slave, int port)\n{\n\tstruct mlx4_vport_oper_state *vp_oper;\n\tstruct mlx4_slave_state *slave_state;\n\tstruct mlx4_vport_state *vp_admin;\n\tint err;\n\n\tvp_oper = &priv->mfunc.master.vf_oper[slave].vport[port];\n\tvp_admin = &priv->mfunc.master.vf_admin[slave].vport[port];\n\tslave_state = &priv->mfunc.master.slave_state[slave];\n\n\tif ((vp_admin->vlan_proto != htons(ETH_P_8021AD)) ||\n\t    (!slave_state->active))\n\t\treturn 0;\n\n\tif (vp_oper->state.vlan_proto == vp_admin->vlan_proto &&\n\t    vp_oper->state.default_vlan == vp_admin->default_vlan &&\n\t    vp_oper->state.default_qos == vp_admin->default_qos)\n\t\treturn 0;\n\n\tif (!slave_state->vst_qinq_supported) {\n\t\t \n\t\tvp_admin->vlan_proto   = vp_oper->state.vlan_proto;\n\t\tvp_admin->default_vlan = vp_oper->state.default_vlan;\n\t\tvp_admin->default_qos  = vp_oper->state.default_qos;\n\n\t\tmlx4_warn(&priv->dev,\n\t\t\t  \"Slave %d does not support VST QinQ mode\\n\", slave);\n\t\treturn 0;\n\t}\n\n\terr = mlx4_activate_vst_qinq(priv, slave, port);\n\treturn err;\n}\n\nint mlx4_QUERY_FUNC_CAP_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t\tstruct mlx4_vhcr *vhcr,\n\t\t\t\tstruct mlx4_cmd_mailbox *inbox,\n\t\t\t\tstruct mlx4_cmd_mailbox *outbox,\n\t\t\t\tstruct mlx4_cmd_info *cmd)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tu8\tfield, port;\n\tu32\tsize, proxy_qp, qkey;\n\tint\terr = 0;\n\tstruct mlx4_func func;\n\n#define QUERY_FUNC_CAP_FLAGS_OFFSET\t\t0x0\n#define QUERY_FUNC_CAP_NUM_PORTS_OFFSET\t\t0x1\n#define QUERY_FUNC_CAP_PF_BHVR_OFFSET\t\t0x4\n#define QUERY_FUNC_CAP_FMR_OFFSET\t\t0x8\n#define QUERY_FUNC_CAP_QP_QUOTA_OFFSET_DEP\t0x10\n#define QUERY_FUNC_CAP_CQ_QUOTA_OFFSET_DEP\t0x14\n#define QUERY_FUNC_CAP_SRQ_QUOTA_OFFSET_DEP\t0x18\n#define QUERY_FUNC_CAP_MPT_QUOTA_OFFSET_DEP\t0x20\n#define QUERY_FUNC_CAP_MTT_QUOTA_OFFSET_DEP\t0x24\n#define QUERY_FUNC_CAP_MCG_QUOTA_OFFSET_DEP\t0x28\n#define QUERY_FUNC_CAP_MAX_EQ_OFFSET\t\t0x2c\n#define QUERY_FUNC_CAP_RESERVED_EQ_OFFSET\t0x30\n#define QUERY_FUNC_CAP_QP_RESD_LKEY_OFFSET\t0x48\n\n#define QUERY_FUNC_CAP_QP_QUOTA_OFFSET\t\t0x50\n#define QUERY_FUNC_CAP_CQ_QUOTA_OFFSET\t\t0x54\n#define QUERY_FUNC_CAP_SRQ_QUOTA_OFFSET\t\t0x58\n#define QUERY_FUNC_CAP_MPT_QUOTA_OFFSET\t\t0x60\n#define QUERY_FUNC_CAP_MTT_QUOTA_OFFSET\t\t0x64\n#define QUERY_FUNC_CAP_MCG_QUOTA_OFFSET\t\t0x68\n\n#define QUERY_FUNC_CAP_EXTRA_FLAGS_OFFSET\t0x6c\n\n#define QUERY_FUNC_CAP_FMR_FLAG\t\t\t0x80\n#define QUERY_FUNC_CAP_FLAG_RDMA\t\t0x40\n#define QUERY_FUNC_CAP_FLAG_ETH\t\t\t0x80\n#define QUERY_FUNC_CAP_FLAG_QUOTAS\t\t0x10\n#define QUERY_FUNC_CAP_FLAG_RESD_LKEY\t\t0x08\n#define QUERY_FUNC_CAP_FLAG_VALID_MAILBOX\t0x04\n\n#define QUERY_FUNC_CAP_EXTRA_FLAGS_BF_QP_ALLOC_FLAG\t(1UL << 31)\n#define QUERY_FUNC_CAP_EXTRA_FLAGS_A0_QP_ALLOC_FLAG\t(1UL << 30)\n\n \n#define QUERY_FUNC_CAP_PHYS_PORT_OFFSET\t\t0x3\n#define QUERY_FUNC_CAP_PRIV_VF_QKEY_OFFSET\t0x4\n#define QUERY_FUNC_CAP_FLAGS0_OFFSET\t\t0x8\n#define QUERY_FUNC_CAP_FLAGS1_OFFSET\t\t0xc\n\n#define QUERY_FUNC_CAP_QP0_TUNNEL\t\t0x10\n#define QUERY_FUNC_CAP_QP0_PROXY\t\t0x14\n#define QUERY_FUNC_CAP_QP1_TUNNEL\t\t0x18\n#define QUERY_FUNC_CAP_QP1_PROXY\t\t0x1c\n#define QUERY_FUNC_CAP_PHYS_PORT_ID\t\t0x28\n\n#define QUERY_FUNC_CAP_FLAGS1_FORCE_MAC\t\t0x40\n#define QUERY_FUNC_CAP_FLAGS1_FORCE_VLAN\t0x80\n#define QUERY_FUNC_CAP_FLAGS1_NIC_INFO\t\t\t0x10\n#define QUERY_FUNC_CAP_VF_ENABLE_QP0\t\t0x08\n\n#define QUERY_FUNC_CAP_FLAGS0_FORCE_PHY_WQE_GID 0x80\n#define QUERY_FUNC_CAP_PHV_BIT\t\t\t0x40\n#define QUERY_FUNC_CAP_VLAN_OFFLOAD_DISABLE\t0x20\n\n#define QUERY_FUNC_CAP_SUPPORTS_VST_QINQ\tBIT(30)\n#define QUERY_FUNC_CAP_SUPPORTS_NON_POWER_OF_2_NUM_EQS BIT(31)\n\n\tif (vhcr->op_modifier == 1) {\n\t\tstruct mlx4_active_ports actv_ports =\n\t\t\tmlx4_get_active_ports(dev, slave);\n\t\tint converted_port = mlx4_slave_convert_port(\n\t\t\t\tdev, slave, vhcr->in_modifier);\n\t\tstruct mlx4_vport_oper_state *vp_oper;\n\n\t\tif (converted_port < 0)\n\t\t\treturn -EINVAL;\n\n\t\tvhcr->in_modifier = converted_port;\n\t\t \n\t\tfield = vhcr->in_modifier -\n\t\t\tfind_first_bit(actv_ports.ports, dev->caps.num_ports);\n\t\tMLX4_PUT(outbox->buf, field, QUERY_FUNC_CAP_PHYS_PORT_OFFSET);\n\n\t\tport = vhcr->in_modifier;\n\t\tproxy_qp = dev->phys_caps.base_proxy_sqpn + 8 * slave + port - 1;\n\n\t\t \n\t\tfield  = QUERY_FUNC_CAP_FLAGS1_NIC_INFO;\n\n\t\tif (mlx4_vf_smi_enabled(dev, slave, port) &&\n\t\t    !mlx4_get_parav_qkey(dev, proxy_qp, &qkey)) {\n\t\t\tfield |= QUERY_FUNC_CAP_VF_ENABLE_QP0;\n\t\t\tMLX4_PUT(outbox->buf, qkey,\n\t\t\t\t QUERY_FUNC_CAP_PRIV_VF_QKEY_OFFSET);\n\t\t}\n\t\tMLX4_PUT(outbox->buf, field, QUERY_FUNC_CAP_FLAGS1_OFFSET);\n\n\t\t \n\t\tsize = dev->phys_caps.base_tunnel_sqpn + 8 * slave + port - 1;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_QP0_TUNNEL);\n\n\t\tsize += 2;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_QP1_TUNNEL);\n\n\t\tMLX4_PUT(outbox->buf, proxy_qp, QUERY_FUNC_CAP_QP0_PROXY);\n\t\tproxy_qp += 2;\n\t\tMLX4_PUT(outbox->buf, proxy_qp, QUERY_FUNC_CAP_QP1_PROXY);\n\n\t\tMLX4_PUT(outbox->buf, dev->caps.phys_port_id[vhcr->in_modifier],\n\t\t\t QUERY_FUNC_CAP_PHYS_PORT_ID);\n\n\t\tvp_oper = &priv->mfunc.master.vf_oper[slave].vport[port];\n\t\terr = mlx4_handle_vst_qinq(priv, slave, port);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tfield = 0;\n\t\tif (dev->caps.phv_bit[port])\n\t\t\tfield |= QUERY_FUNC_CAP_PHV_BIT;\n\t\tif (vp_oper->state.vlan_proto == htons(ETH_P_8021AD))\n\t\t\tfield |= QUERY_FUNC_CAP_VLAN_OFFLOAD_DISABLE;\n\t\tMLX4_PUT(outbox->buf, field, QUERY_FUNC_CAP_FLAGS0_OFFSET);\n\n\t} else if (vhcr->op_modifier == 0) {\n\t\tstruct mlx4_active_ports actv_ports =\n\t\t\tmlx4_get_active_ports(dev, slave);\n\t\tstruct mlx4_slave_state *slave_state =\n\t\t\t&priv->mfunc.master.slave_state[slave];\n\n\t\t \n\t\tfield = (QUERY_FUNC_CAP_FLAG_ETH | QUERY_FUNC_CAP_FLAG_RDMA |\n\t\t\t QUERY_FUNC_CAP_FLAG_QUOTAS | QUERY_FUNC_CAP_FLAG_VALID_MAILBOX |\n\t\t\t QUERY_FUNC_CAP_FLAG_RESD_LKEY);\n\t\tMLX4_PUT(outbox->buf, field, QUERY_FUNC_CAP_FLAGS_OFFSET);\n\n\t\tfield = min(\n\t\t\tbitmap_weight(actv_ports.ports, dev->caps.num_ports),\n\t\t\t(unsigned int) dev->caps.num_ports);\n\t\tMLX4_PUT(outbox->buf, field, QUERY_FUNC_CAP_NUM_PORTS_OFFSET);\n\n\t\tsize = dev->caps.function_caps;  \n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_PF_BHVR_OFFSET);\n\n\t\tfield = 0;  \n\t\tMLX4_PUT(outbox->buf, field, QUERY_FUNC_CAP_FMR_OFFSET);\n\n\t\tsize = priv->mfunc.master.res_tracker.res_alloc[RES_QP].quota[slave];\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_QP_QUOTA_OFFSET);\n\t\tsize = dev->caps.num_qps;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_QP_QUOTA_OFFSET_DEP);\n\n\t\tsize = priv->mfunc.master.res_tracker.res_alloc[RES_SRQ].quota[slave];\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_SRQ_QUOTA_OFFSET);\n\t\tsize = dev->caps.num_srqs;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_SRQ_QUOTA_OFFSET_DEP);\n\n\t\tsize = priv->mfunc.master.res_tracker.res_alloc[RES_CQ].quota[slave];\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_CQ_QUOTA_OFFSET);\n\t\tsize = dev->caps.num_cqs;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_CQ_QUOTA_OFFSET_DEP);\n\n\t\tif (!(dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_SYS_EQS) ||\n\t\t    mlx4_QUERY_FUNC(dev, &func, slave)) {\n\t\t\tsize = vhcr->in_modifier &\n\t\t\t\tQUERY_FUNC_CAP_SUPPORTS_NON_POWER_OF_2_NUM_EQS ?\n\t\t\t\tdev->caps.num_eqs :\n\t\t\t\trounddown_pow_of_two(dev->caps.num_eqs);\n\t\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MAX_EQ_OFFSET);\n\t\t\tsize = dev->caps.reserved_eqs;\n\t\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_RESERVED_EQ_OFFSET);\n\t\t} else {\n\t\t\tsize = vhcr->in_modifier &\n\t\t\t\tQUERY_FUNC_CAP_SUPPORTS_NON_POWER_OF_2_NUM_EQS ?\n\t\t\t\tfunc.max_eq :\n\t\t\t\trounddown_pow_of_two(func.max_eq);\n\t\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MAX_EQ_OFFSET);\n\t\t\tsize = func.rsvd_eqs;\n\t\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_RESERVED_EQ_OFFSET);\n\t\t}\n\n\t\tsize = priv->mfunc.master.res_tracker.res_alloc[RES_MPT].quota[slave];\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MPT_QUOTA_OFFSET);\n\t\tsize = dev->caps.num_mpts;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MPT_QUOTA_OFFSET_DEP);\n\n\t\tsize = priv->mfunc.master.res_tracker.res_alloc[RES_MTT].quota[slave];\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MTT_QUOTA_OFFSET);\n\t\tsize = dev->caps.num_mtts;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MTT_QUOTA_OFFSET_DEP);\n\n\t\tsize = dev->caps.num_mgms + dev->caps.num_amgms;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MCG_QUOTA_OFFSET);\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_MCG_QUOTA_OFFSET_DEP);\n\n\t\tsize = QUERY_FUNC_CAP_EXTRA_FLAGS_BF_QP_ALLOC_FLAG |\n\t\t\tQUERY_FUNC_CAP_EXTRA_FLAGS_A0_QP_ALLOC_FLAG;\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_EXTRA_FLAGS_OFFSET);\n\n\t\tsize = dev->caps.reserved_lkey + ((slave << 8) & 0xFF00);\n\t\tMLX4_PUT(outbox->buf, size, QUERY_FUNC_CAP_QP_RESD_LKEY_OFFSET);\n\n\t\tif (vhcr->in_modifier & QUERY_FUNC_CAP_SUPPORTS_VST_QINQ)\n\t\t\tslave_state->vst_qinq_supported = true;\n\n\t} else\n\t\terr = -EINVAL;\n\n\treturn err;\n}\n\nint mlx4_QUERY_FUNC_CAP(struct mlx4_dev *dev, u8 gen_or_port,\n\t\t\tstruct mlx4_func_cap *func_cap)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32\t\t\t*outbox;\n\tu8\t\t\tfield, op_modifier;\n\tu32\t\t\tsize, qkey;\n\tint\t\t\terr = 0, quotas = 0;\n\tu32                     in_modifier;\n\tu32\t\t\tslave_caps;\n\n\top_modifier = !!gen_or_port;  \n\tslave_caps = QUERY_FUNC_CAP_SUPPORTS_VST_QINQ |\n\t\tQUERY_FUNC_CAP_SUPPORTS_NON_POWER_OF_2_NUM_EQS;\n\tin_modifier = op_modifier ? gen_or_port : slave_caps;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, in_modifier, op_modifier,\n\t\t\t   MLX4_CMD_QUERY_FUNC_CAP,\n\t\t\t   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED);\n\tif (err)\n\t\tgoto out;\n\n\toutbox = mailbox->buf;\n\n\tif (!op_modifier) {\n\t\tMLX4_GET(field, outbox, QUERY_FUNC_CAP_FLAGS_OFFSET);\n\t\tif (!(field & (QUERY_FUNC_CAP_FLAG_ETH | QUERY_FUNC_CAP_FLAG_RDMA))) {\n\t\t\tmlx4_err(dev, \"The host supports neither eth nor rdma interfaces\\n\");\n\t\t\terr = -EPROTONOSUPPORT;\n\t\t\tgoto out;\n\t\t}\n\t\tfunc_cap->flags = field;\n\t\tquotas = !!(func_cap->flags & QUERY_FUNC_CAP_FLAG_QUOTAS);\n\n\t\tMLX4_GET(field, outbox, QUERY_FUNC_CAP_NUM_PORTS_OFFSET);\n\t\tfunc_cap->num_ports = field;\n\n\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_PF_BHVR_OFFSET);\n\t\tfunc_cap->pf_context_behaviour = size;\n\n\t\tif (quotas) {\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_QP_QUOTA_OFFSET);\n\t\t\tfunc_cap->qp_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_SRQ_QUOTA_OFFSET);\n\t\t\tfunc_cap->srq_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_CQ_QUOTA_OFFSET);\n\t\t\tfunc_cap->cq_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_MPT_QUOTA_OFFSET);\n\t\t\tfunc_cap->mpt_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_MTT_QUOTA_OFFSET);\n\t\t\tfunc_cap->mtt_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_MCG_QUOTA_OFFSET);\n\t\t\tfunc_cap->mcg_quota = size & 0xFFFFFF;\n\n\t\t} else {\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_QP_QUOTA_OFFSET_DEP);\n\t\t\tfunc_cap->qp_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_SRQ_QUOTA_OFFSET_DEP);\n\t\t\tfunc_cap->srq_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_CQ_QUOTA_OFFSET_DEP);\n\t\t\tfunc_cap->cq_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_MPT_QUOTA_OFFSET_DEP);\n\t\t\tfunc_cap->mpt_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_MTT_QUOTA_OFFSET_DEP);\n\t\t\tfunc_cap->mtt_quota = size & 0xFFFFFF;\n\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_MCG_QUOTA_OFFSET_DEP);\n\t\t\tfunc_cap->mcg_quota = size & 0xFFFFFF;\n\t\t}\n\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_MAX_EQ_OFFSET);\n\t\tfunc_cap->max_eq = size & 0xFFFFFF;\n\n\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_RESERVED_EQ_OFFSET);\n\t\tfunc_cap->reserved_eq = size & 0xFFFFFF;\n\n\t\tif (func_cap->flags & QUERY_FUNC_CAP_FLAG_RESD_LKEY) {\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_QP_RESD_LKEY_OFFSET);\n\t\t\tfunc_cap->reserved_lkey = size;\n\t\t} else {\n\t\t\tfunc_cap->reserved_lkey = 0;\n\t\t}\n\n\t\tfunc_cap->extra_flags = 0;\n\n\t\t \n\t\tif (func_cap->flags & QUERY_FUNC_CAP_FLAG_VALID_MAILBOX) {\n\t\t\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_EXTRA_FLAGS_OFFSET);\n\t\t\tif (size & QUERY_FUNC_CAP_EXTRA_FLAGS_BF_QP_ALLOC_FLAG)\n\t\t\t\tfunc_cap->extra_flags |= MLX4_QUERY_FUNC_FLAGS_BF_RES_QP;\n\t\t\tif (size & QUERY_FUNC_CAP_EXTRA_FLAGS_A0_QP_ALLOC_FLAG)\n\t\t\t\tfunc_cap->extra_flags |= MLX4_QUERY_FUNC_FLAGS_A0_RES_QP;\n\t\t}\n\n\t\tgoto out;\n\t}\n\n\t \n\tif (gen_or_port > dev->caps.num_ports) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tMLX4_GET(func_cap->flags1, outbox, QUERY_FUNC_CAP_FLAGS1_OFFSET);\n\tif (dev->caps.port_type[gen_or_port] == MLX4_PORT_TYPE_ETH) {\n\t\tif (func_cap->flags1 & QUERY_FUNC_CAP_FLAGS1_FORCE_VLAN) {\n\t\t\tmlx4_err(dev, \"VLAN is enforced on this port\\n\");\n\t\t\terr = -EPROTONOSUPPORT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (func_cap->flags1 & QUERY_FUNC_CAP_FLAGS1_FORCE_MAC) {\n\t\t\tmlx4_err(dev, \"Force mac is enabled on this port\\n\");\n\t\t\terr = -EPROTONOSUPPORT;\n\t\t\tgoto out;\n\t\t}\n\t} else if (dev->caps.port_type[gen_or_port] == MLX4_PORT_TYPE_IB) {\n\t\tMLX4_GET(field, outbox, QUERY_FUNC_CAP_FLAGS0_OFFSET);\n\t\tif (field & QUERY_FUNC_CAP_FLAGS0_FORCE_PHY_WQE_GID) {\n\t\t\tmlx4_err(dev, \"phy_wqe_gid is enforced on this ib port\\n\");\n\t\t\terr = -EPROTONOSUPPORT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tMLX4_GET(field, outbox, QUERY_FUNC_CAP_PHYS_PORT_OFFSET);\n\tfunc_cap->physical_port = field;\n\tif (func_cap->physical_port != gen_or_port) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (func_cap->flags1 & QUERY_FUNC_CAP_VF_ENABLE_QP0) {\n\t\tMLX4_GET(qkey, outbox, QUERY_FUNC_CAP_PRIV_VF_QKEY_OFFSET);\n\t\tfunc_cap->spec_qps.qp0_qkey = qkey;\n\t} else {\n\t\tfunc_cap->spec_qps.qp0_qkey = 0;\n\t}\n\n\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_QP0_TUNNEL);\n\tfunc_cap->spec_qps.qp0_tunnel = size & 0xFFFFFF;\n\n\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_QP0_PROXY);\n\tfunc_cap->spec_qps.qp0_proxy = size & 0xFFFFFF;\n\n\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_QP1_TUNNEL);\n\tfunc_cap->spec_qps.qp1_tunnel = size & 0xFFFFFF;\n\n\tMLX4_GET(size, outbox, QUERY_FUNC_CAP_QP1_PROXY);\n\tfunc_cap->spec_qps.qp1_proxy = size & 0xFFFFFF;\n\n\tif (func_cap->flags1 & QUERY_FUNC_CAP_FLAGS1_NIC_INFO)\n\t\tMLX4_GET(func_cap->phys_port_id, outbox,\n\t\t\t QUERY_FUNC_CAP_PHYS_PORT_ID);\n\n\tMLX4_GET(func_cap->flags0, outbox, QUERY_FUNC_CAP_FLAGS0_OFFSET);\n\n\t \n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\n\treturn err;\n}\n\nstatic void disable_unsupported_roce_caps(void *buf);\n\nint mlx4_QUERY_DEV_CAP(struct mlx4_dev *dev, struct mlx4_dev_cap *dev_cap)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *outbox;\n\tu8 field;\n\tu32 field32, flags, ext_flags;\n\tu16 size;\n\tu16 stat_rate;\n\tint err;\n\tint i;\n\n#define QUERY_DEV_CAP_OUT_SIZE\t\t       0x100\n#define QUERY_DEV_CAP_MAX_SRQ_SZ_OFFSET\t\t0x10\n#define QUERY_DEV_CAP_MAX_QP_SZ_OFFSET\t\t0x11\n#define QUERY_DEV_CAP_RSVD_QP_OFFSET\t\t0x12\n#define QUERY_DEV_CAP_MAX_QP_OFFSET\t\t0x13\n#define QUERY_DEV_CAP_RSVD_SRQ_OFFSET\t\t0x14\n#define QUERY_DEV_CAP_MAX_SRQ_OFFSET\t\t0x15\n#define QUERY_DEV_CAP_RSVD_EEC_OFFSET\t\t0x16\n#define QUERY_DEV_CAP_MAX_EEC_OFFSET\t\t0x17\n#define QUERY_DEV_CAP_MAX_CQ_SZ_OFFSET\t\t0x19\n#define QUERY_DEV_CAP_RSVD_CQ_OFFSET\t\t0x1a\n#define QUERY_DEV_CAP_MAX_CQ_OFFSET\t\t0x1b\n#define QUERY_DEV_CAP_MAX_MPT_OFFSET\t\t0x1d\n#define QUERY_DEV_CAP_RSVD_EQ_OFFSET\t\t0x1e\n#define QUERY_DEV_CAP_MAX_EQ_OFFSET\t\t0x1f\n#define QUERY_DEV_CAP_RSVD_MTT_OFFSET\t\t0x20\n#define QUERY_DEV_CAP_MAX_MRW_SZ_OFFSET\t\t0x21\n#define QUERY_DEV_CAP_RSVD_MRW_OFFSET\t\t0x22\n#define QUERY_DEV_CAP_MAX_MTT_SEG_OFFSET\t0x23\n#define QUERY_DEV_CAP_NUM_SYS_EQ_OFFSET\t\t0x26\n#define QUERY_DEV_CAP_MAX_AV_OFFSET\t\t0x27\n#define QUERY_DEV_CAP_MAX_REQ_QP_OFFSET\t\t0x29\n#define QUERY_DEV_CAP_MAX_RES_QP_OFFSET\t\t0x2b\n#define QUERY_DEV_CAP_MAX_GSO_OFFSET\t\t0x2d\n#define QUERY_DEV_CAP_RSS_OFFSET\t\t0x2e\n#define QUERY_DEV_CAP_MAX_RDMA_OFFSET\t\t0x2f\n#define QUERY_DEV_CAP_RSZ_SRQ_OFFSET\t\t0x33\n#define QUERY_DEV_CAP_PORT_BEACON_OFFSET\t0x34\n#define QUERY_DEV_CAP_ACK_DELAY_OFFSET\t\t0x35\n#define QUERY_DEV_CAP_MTU_WIDTH_OFFSET\t\t0x36\n#define QUERY_DEV_CAP_VL_PORT_OFFSET\t\t0x37\n#define QUERY_DEV_CAP_MAX_MSG_SZ_OFFSET\t\t0x38\n#define QUERY_DEV_CAP_MAX_GID_OFFSET\t\t0x3b\n#define QUERY_DEV_CAP_RATE_SUPPORT_OFFSET\t0x3c\n#define QUERY_DEV_CAP_CQ_TS_SUPPORT_OFFSET\t0x3e\n#define QUERY_DEV_CAP_MAX_PKEY_OFFSET\t\t0x3f\n#define QUERY_DEV_CAP_EXT_FLAGS_OFFSET\t\t0x40\n#define QUERY_DEV_CAP_WOL_OFFSET\t\t0x43\n#define QUERY_DEV_CAP_FLAGS_OFFSET\t\t0x44\n#define QUERY_DEV_CAP_RSVD_UAR_OFFSET\t\t0x48\n#define QUERY_DEV_CAP_UAR_SZ_OFFSET\t\t0x49\n#define QUERY_DEV_CAP_PAGE_SZ_OFFSET\t\t0x4b\n#define QUERY_DEV_CAP_BF_OFFSET\t\t\t0x4c\n#define QUERY_DEV_CAP_LOG_BF_REG_SZ_OFFSET\t0x4d\n#define QUERY_DEV_CAP_LOG_MAX_BF_REGS_PER_PAGE_OFFSET\t0x4e\n#define QUERY_DEV_CAP_LOG_MAX_BF_PAGES_OFFSET\t0x4f\n#define QUERY_DEV_CAP_MAX_SG_SQ_OFFSET\t\t0x51\n#define QUERY_DEV_CAP_MAX_DESC_SZ_SQ_OFFSET\t0x52\n#define QUERY_DEV_CAP_MAX_SG_RQ_OFFSET\t\t0x55\n#define QUERY_DEV_CAP_MAX_DESC_SZ_RQ_OFFSET\t0x56\n#define QUERY_DEV_CAP_USER_MAC_EN_OFFSET\t0x5C\n#define QUERY_DEV_CAP_SVLAN_BY_QP_OFFSET\t0x5D\n#define QUERY_DEV_CAP_MAX_QP_MCG_OFFSET\t\t0x61\n#define QUERY_DEV_CAP_RSVD_MCG_OFFSET\t\t0x62\n#define QUERY_DEV_CAP_MAX_MCG_OFFSET\t\t0x63\n#define QUERY_DEV_CAP_RSVD_PD_OFFSET\t\t0x64\n#define QUERY_DEV_CAP_MAX_PD_OFFSET\t\t0x65\n#define QUERY_DEV_CAP_RSVD_XRC_OFFSET\t\t0x66\n#define QUERY_DEV_CAP_MAX_XRC_OFFSET\t\t0x67\n#define QUERY_DEV_CAP_MAX_COUNTERS_OFFSET\t0x68\n#define QUERY_DEV_CAP_PORT_FLOWSTATS_COUNTERS_OFFSET\t0x70\n#define QUERY_DEV_CAP_EXT_2_FLAGS_OFFSET\t0x70\n#define QUERY_DEV_CAP_FLOW_STEERING_IPOIB_OFFSET\t0x74\n#define QUERY_DEV_CAP_FLOW_STEERING_RANGE_EN_OFFSET\t0x76\n#define QUERY_DEV_CAP_FLOW_STEERING_MAX_QP_OFFSET\t0x77\n#define QUERY_DEV_CAP_SL2VL_EVENT_OFFSET\t0x78\n#define QUERY_DEV_CAP_CQ_EQ_CACHE_LINE_STRIDE\t0x7a\n#define QUERY_DEV_CAP_ECN_QCN_VER_OFFSET\t0x7b\n#define QUERY_DEV_CAP_RDMARC_ENTRY_SZ_OFFSET\t0x80\n#define QUERY_DEV_CAP_QPC_ENTRY_SZ_OFFSET\t0x82\n#define QUERY_DEV_CAP_AUX_ENTRY_SZ_OFFSET\t0x84\n#define QUERY_DEV_CAP_ALTC_ENTRY_SZ_OFFSET\t0x86\n#define QUERY_DEV_CAP_EQC_ENTRY_SZ_OFFSET\t0x88\n#define QUERY_DEV_CAP_CQC_ENTRY_SZ_OFFSET\t0x8a\n#define QUERY_DEV_CAP_SRQ_ENTRY_SZ_OFFSET\t0x8c\n#define QUERY_DEV_CAP_C_MPT_ENTRY_SZ_OFFSET\t0x8e\n#define QUERY_DEV_CAP_MTT_ENTRY_SZ_OFFSET\t0x90\n#define QUERY_DEV_CAP_D_MPT_ENTRY_SZ_OFFSET\t0x92\n#define QUERY_DEV_CAP_BMME_FLAGS_OFFSET\t\t0x94\n#define QUERY_DEV_CAP_CONFIG_DEV_OFFSET\t\t0x94\n#define QUERY_DEV_CAP_PHV_EN_OFFSET\t\t0x96\n#define QUERY_DEV_CAP_RSVD_LKEY_OFFSET\t\t0x98\n#define QUERY_DEV_CAP_MAX_ICM_SZ_OFFSET\t\t0xa0\n#define QUERY_DEV_CAP_ETH_BACKPL_OFFSET\t\t0x9c\n#define QUERY_DEV_CAP_DIAG_RPRT_PER_PORT\t0x9c\n#define QUERY_DEV_CAP_FW_REASSIGN_MAC\t\t0x9d\n#define QUERY_DEV_CAP_VXLAN\t\t\t0x9e\n#define QUERY_DEV_CAP_MAD_DEMUX_OFFSET\t\t0xb0\n#define QUERY_DEV_CAP_DMFS_HIGH_RATE_QPN_BASE_OFFSET\t0xa8\n#define QUERY_DEV_CAP_DMFS_HIGH_RATE_QPN_RANGE_OFFSET\t0xac\n#define QUERY_DEV_CAP_MAP_CLOCK_TO_USER 0xc1\n#define QUERY_DEV_CAP_QP_RATE_LIMIT_NUM_OFFSET\t0xcc\n#define QUERY_DEV_CAP_QP_RATE_LIMIT_MAX_OFFSET\t0xd0\n#define QUERY_DEV_CAP_QP_RATE_LIMIT_MIN_OFFSET\t0xd2\n#define QUERY_DEV_CAP_HEALTH_BUFFER_ADDRESS_OFFSET\t0xe4\n\n\tdev_cap->flags2 = 0;\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\toutbox = mailbox->buf;\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 0, MLX4_CMD_QUERY_DEV_CAP,\n\t\t\t   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\tif (err)\n\t\tgoto out;\n\n\tif (mlx4_is_mfunc(dev))\n\t\tdisable_unsupported_roce_caps(outbox);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAP_CLOCK_TO_USER);\n\tdev_cap->map_clock_to_user = field & 0x80;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_QP_OFFSET);\n\tdev_cap->reserved_qps = 1 << (field & 0xf);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_QP_OFFSET);\n\tdev_cap->max_qps = 1 << (field & 0x1f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_SRQ_OFFSET);\n\tdev_cap->reserved_srqs = 1 << (field >> 4);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_SRQ_OFFSET);\n\tdev_cap->max_srqs = 1 << (field & 0x1f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_CQ_SZ_OFFSET);\n\tdev_cap->max_cq_sz = 1 << field;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_CQ_OFFSET);\n\tdev_cap->reserved_cqs = 1 << (field & 0xf);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_CQ_OFFSET);\n\tdev_cap->max_cqs = 1 << (field & 0x1f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_MPT_OFFSET);\n\tdev_cap->max_mpts = 1 << (field & 0x3f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_EQ_OFFSET);\n\tdev_cap->reserved_eqs = 1 << (field & 0xf);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_EQ_OFFSET);\n\tdev_cap->max_eqs = 1 << (field & 0xf);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_MTT_OFFSET);\n\tdev_cap->reserved_mtts = 1 << (field >> 4);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_MRW_OFFSET);\n\tdev_cap->reserved_mrws = 1 << (field & 0xf);\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_NUM_SYS_EQ_OFFSET);\n\tdev_cap->num_sys_eqs = size & 0xfff;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_REQ_QP_OFFSET);\n\tdev_cap->max_requester_per_qp = 1 << (field & 0x3f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_RES_QP_OFFSET);\n\tdev_cap->max_responder_per_qp = 1 << (field & 0x3f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_GSO_OFFSET);\n\tfield &= 0x1f;\n\tif (!field)\n\t\tdev_cap->max_gso_sz = 0;\n\telse\n\t\tdev_cap->max_gso_sz = 1 << field;\n\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSS_OFFSET);\n\tif (field & 0x20)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_RSS_XOR;\n\tif (field & 0x10)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_RSS_TOP;\n\tfield &= 0xf;\n\tif (field) {\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_RSS;\n\t\tdev_cap->max_rss_tbl_sz = 1 << field;\n\t} else\n\t\tdev_cap->max_rss_tbl_sz = 0;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_RDMA_OFFSET);\n\tdev_cap->max_rdma_global = 1 << (field & 0x3f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_ACK_DELAY_OFFSET);\n\tdev_cap->local_ca_ack_delay = field & 0x1f;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_VL_PORT_OFFSET);\n\tdev_cap->num_ports = field & 0xf;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_MSG_SZ_OFFSET);\n\tdev_cap->max_msg_sz = 1 << (field & 0x1f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_PORT_FLOWSTATS_COUNTERS_OFFSET);\n\tif (field & 0x10)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_FLOWSTATS_EN;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_FLOW_STEERING_RANGE_EN_OFFSET);\n\tif (field & 0x80)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_FS_EN;\n\tdev_cap->fs_log_max_ucast_qp_range_size = field & 0x1f;\n\tif (field & 0x20)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_DMFS_UC_MC_SNIFFER;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_PORT_BEACON_OFFSET);\n\tif (field & 0x80)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_PORT_BEACON;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_FLOW_STEERING_IPOIB_OFFSET);\n\tif (field & 0x80)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_DMFS_IPOIB;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_FLOW_STEERING_MAX_QP_OFFSET);\n\tdev_cap->fs_max_num_qp_per_entry = field;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_SL2VL_EVENT_OFFSET);\n\tif (field & (1 << 5))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_SL_TO_VL_CHANGE_EVENT;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_ECN_QCN_VER_OFFSET);\n\tif (field & 0x1)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_QCN;\n\tMLX4_GET(stat_rate, outbox, QUERY_DEV_CAP_RATE_SUPPORT_OFFSET);\n\tdev_cap->stat_rate_support = stat_rate;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_CQ_TS_SUPPORT_OFFSET);\n\tif (field & 0x80)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_TS;\n\tMLX4_GET(ext_flags, outbox, QUERY_DEV_CAP_EXT_FLAGS_OFFSET);\n\tMLX4_GET(flags, outbox, QUERY_DEV_CAP_FLAGS_OFFSET);\n\tdev_cap->flags = flags | (u64)ext_flags << 32;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_WOL_OFFSET);\n\tdev_cap->wol_port[1] = !!(field & 0x20);\n\tdev_cap->wol_port[2] = !!(field & 0x40);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_UAR_OFFSET);\n\tdev_cap->reserved_uars = field >> 4;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_UAR_SZ_OFFSET);\n\tdev_cap->uar_size = 1 << ((field & 0x3f) + 20);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_PAGE_SZ_OFFSET);\n\tdev_cap->min_page_sz = 1 << field;\n\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_BF_OFFSET);\n\tif (field & 0x80) {\n\t\tMLX4_GET(field, outbox, QUERY_DEV_CAP_LOG_BF_REG_SZ_OFFSET);\n\t\tdev_cap->bf_reg_size = 1 << (field & 0x1f);\n\t\tMLX4_GET(field, outbox, QUERY_DEV_CAP_LOG_MAX_BF_REGS_PER_PAGE_OFFSET);\n\t\tif ((1 << (field & 0x3f)) > (PAGE_SIZE / dev_cap->bf_reg_size))\n\t\t\tfield = 3;\n\t\tdev_cap->bf_regs_per_page = 1 << (field & 0x3f);\n\t} else {\n\t\tdev_cap->bf_reg_size = 0;\n\t}\n\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_SG_SQ_OFFSET);\n\tdev_cap->max_sq_sg = field;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_MAX_DESC_SZ_SQ_OFFSET);\n\tdev_cap->max_sq_desc_sz = size;\n\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_USER_MAC_EN_OFFSET);\n\tif (field & (1 << 2))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_USER_MAC_EN;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_SVLAN_BY_QP_OFFSET);\n\tif (field & 0x1)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_SVLAN_BY_QP;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_QP_MCG_OFFSET);\n\tdev_cap->max_qp_per_mcg = 1 << field;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_MCG_OFFSET);\n\tdev_cap->reserved_mgms = field & 0xf;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_MCG_OFFSET);\n\tdev_cap->max_mcgs = 1 << field;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_PD_OFFSET);\n\tdev_cap->reserved_pds = field >> 4;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_PD_OFFSET);\n\tdev_cap->max_pds = 1 << (field & 0x3f);\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSVD_XRC_OFFSET);\n\tdev_cap->reserved_xrcds = field >> 4;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_XRC_OFFSET);\n\tdev_cap->max_xrcds = 1 << (field & 0x1f);\n\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_RDMARC_ENTRY_SZ_OFFSET);\n\tdev_cap->rdmarc_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_QPC_ENTRY_SZ_OFFSET);\n\tdev_cap->qpc_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_AUX_ENTRY_SZ_OFFSET);\n\tdev_cap->aux_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_ALTC_ENTRY_SZ_OFFSET);\n\tdev_cap->altc_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_EQC_ENTRY_SZ_OFFSET);\n\tdev_cap->eqc_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_CQC_ENTRY_SZ_OFFSET);\n\tdev_cap->cqc_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_SRQ_ENTRY_SZ_OFFSET);\n\tdev_cap->srq_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_C_MPT_ENTRY_SZ_OFFSET);\n\tdev_cap->cmpt_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_MTT_ENTRY_SZ_OFFSET);\n\tdev_cap->mtt_entry_sz = size;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_D_MPT_ENTRY_SZ_OFFSET);\n\tdev_cap->dmpt_entry_sz = size;\n\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_SRQ_SZ_OFFSET);\n\tdev_cap->max_srq_sz = 1 << field;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_QP_SZ_OFFSET);\n\tdev_cap->max_qp_sz = 1 << field;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_RSZ_SRQ_OFFSET);\n\tdev_cap->resize_srq = field & 1;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_SG_RQ_OFFSET);\n\tdev_cap->max_rq_sg = field;\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_MAX_DESC_SZ_RQ_OFFSET);\n\tdev_cap->max_rq_desc_sz = size;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_CQ_EQ_CACHE_LINE_STRIDE);\n\tif (field & (1 << 4))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_QOS_VPP;\n\tif (field & (1 << 5))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_ETH_PROT_CTRL;\n\tif (field & (1 << 6))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_CQE_STRIDE;\n\tif (field & (1 << 7))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_EQE_STRIDE;\n\tMLX4_GET(dev_cap->bmme_flags, outbox,\n\t\t QUERY_DEV_CAP_BMME_FLAGS_OFFSET);\n\tif (dev_cap->bmme_flags & MLX4_FLAG_ROCE_V1_V2)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_ROCE_V1_V2;\n\tif (dev_cap->bmme_flags & MLX4_FLAG_PORT_REMAP)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_PORT_REMAP;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_CONFIG_DEV_OFFSET);\n\tif (field & 0x20)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_CONFIG_DEV;\n\tif (field & (1 << 2))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_IGNORE_FCS;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_PHV_EN_OFFSET);\n\tif (field & 0x80)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_PHV_EN;\n\tif (field & 0x40)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_SKIP_OUTER_VLAN;\n\n\tMLX4_GET(dev_cap->reserved_lkey, outbox,\n\t\t QUERY_DEV_CAP_RSVD_LKEY_OFFSET);\n\tMLX4_GET(field32, outbox, QUERY_DEV_CAP_ETH_BACKPL_OFFSET);\n\tif (field32 & (1 << 0))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_ETH_BACKPL_AN_REP;\n\tif (field32 & (1 << 7))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_RECOVERABLE_ERROR_EVENT;\n\tif (field32 & (1 << 8))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_DRIVER_VERSION_TO_FW;\n\tMLX4_GET(field32, outbox, QUERY_DEV_CAP_DIAG_RPRT_PER_PORT);\n\tif (field32 & (1 << 17))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_DIAG_PER_PORT;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_FW_REASSIGN_MAC);\n\tif (field & 1<<6)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_REASSIGN_MAC_EN;\n\tMLX4_GET(field, outbox, QUERY_DEV_CAP_VXLAN);\n\tif (field & 1<<3)\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_VXLAN_OFFLOADS;\n\tif (field & (1 << 5))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_ETS_CFG;\n\tMLX4_GET(dev_cap->max_icm_sz, outbox,\n\t\t QUERY_DEV_CAP_MAX_ICM_SZ_OFFSET);\n\tif (dev_cap->flags & MLX4_DEV_CAP_FLAG_COUNTERS)\n\t\tMLX4_GET(dev_cap->max_counters, outbox,\n\t\t\t QUERY_DEV_CAP_MAX_COUNTERS_OFFSET);\n\n\tMLX4_GET(field32, outbox,\n\t\t QUERY_DEV_CAP_MAD_DEMUX_OFFSET);\n\tif (field32 & (1 << 0))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_MAD_DEMUX;\n\n\tMLX4_GET(dev_cap->dmfs_high_rate_qpn_base, outbox,\n\t\t QUERY_DEV_CAP_DMFS_HIGH_RATE_QPN_BASE_OFFSET);\n\tdev_cap->dmfs_high_rate_qpn_base &= MGM_QPN_MASK;\n\tMLX4_GET(dev_cap->dmfs_high_rate_qpn_range, outbox,\n\t\t QUERY_DEV_CAP_DMFS_HIGH_RATE_QPN_RANGE_OFFSET);\n\tdev_cap->dmfs_high_rate_qpn_range &= MGM_QPN_MASK;\n\n\tMLX4_GET(size, outbox, QUERY_DEV_CAP_QP_RATE_LIMIT_NUM_OFFSET);\n\tdev_cap->rl_caps.num_rates = size;\n\tif (dev_cap->rl_caps.num_rates) {\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_QP_RATE_LIMIT;\n\t\tMLX4_GET(size, outbox, QUERY_DEV_CAP_QP_RATE_LIMIT_MAX_OFFSET);\n\t\tdev_cap->rl_caps.max_val  = size & 0xfff;\n\t\tdev_cap->rl_caps.max_unit = size >> 14;\n\t\tMLX4_GET(size, outbox, QUERY_DEV_CAP_QP_RATE_LIMIT_MIN_OFFSET);\n\t\tdev_cap->rl_caps.min_val  = size & 0xfff;\n\t\tdev_cap->rl_caps.min_unit = size >> 14;\n\t}\n\n\tMLX4_GET(dev_cap->health_buffer_addrs, outbox,\n\t\t QUERY_DEV_CAP_HEALTH_BUFFER_ADDRESS_OFFSET);\n\n\tMLX4_GET(field32, outbox, QUERY_DEV_CAP_EXT_2_FLAGS_OFFSET);\n\tif (field32 & (1 << 16))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_UPDATE_QP;\n\tif (field32 & (1 << 18))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_UPDATE_QP_SRC_CHECK_LB;\n\tif (field32 & (1 << 19))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_LB_SRC_CHK;\n\tif (field32 & (1 << 26))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_VLAN_CONTROL;\n\tif (field32 & (1 << 20))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_FSM;\n\tif (field32 & (1 << 21))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_80_VFS;\n\tif (field32 & (1 << 23))\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_SW_CQ_INIT;\n\n\tfor (i = 1; i <= dev_cap->num_ports; i++) {\n\t\terr = mlx4_QUERY_PORT(dev, i, dev_cap->port_cap + i);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\t \n\tif (dev_cap->num_sys_eqs == 0)\n\t\tdev_cap->reserved_eqs = max(dev_cap->reserved_uars * 4,\n\t\t\t\t\t    dev_cap->reserved_eqs);\n\telse\n\t\tdev_cap->flags2 |= MLX4_DEV_CAP_FLAG2_SYS_EQS;\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nvoid mlx4_dev_cap_dump(struct mlx4_dev *dev, struct mlx4_dev_cap *dev_cap)\n{\n\tif (dev_cap->bf_reg_size > 0)\n\t\tmlx4_dbg(dev, \"BlueFlame available (reg size %d, regs/page %d)\\n\",\n\t\t\t dev_cap->bf_reg_size, dev_cap->bf_regs_per_page);\n\telse\n\t\tmlx4_dbg(dev, \"BlueFlame not available\\n\");\n\n\tmlx4_dbg(dev, \"Base MM extensions: flags %08x, rsvd L_Key %08x\\n\",\n\t\t dev_cap->bmme_flags, dev_cap->reserved_lkey);\n\tmlx4_dbg(dev, \"Max ICM size %lld MB\\n\",\n\t\t (unsigned long long) dev_cap->max_icm_sz >> 20);\n\tmlx4_dbg(dev, \"Max QPs: %d, reserved QPs: %d, entry size: %d\\n\",\n\t\t dev_cap->max_qps, dev_cap->reserved_qps, dev_cap->qpc_entry_sz);\n\tmlx4_dbg(dev, \"Max SRQs: %d, reserved SRQs: %d, entry size: %d\\n\",\n\t\t dev_cap->max_srqs, dev_cap->reserved_srqs, dev_cap->srq_entry_sz);\n\tmlx4_dbg(dev, \"Max CQs: %d, reserved CQs: %d, entry size: %d\\n\",\n\t\t dev_cap->max_cqs, dev_cap->reserved_cqs, dev_cap->cqc_entry_sz);\n\tmlx4_dbg(dev, \"Num sys EQs: %d, max EQs: %d, reserved EQs: %d, entry size: %d\\n\",\n\t\t dev_cap->num_sys_eqs, dev_cap->max_eqs, dev_cap->reserved_eqs,\n\t\t dev_cap->eqc_entry_sz);\n\tmlx4_dbg(dev, \"reserved MPTs: %d, reserved MTTs: %d\\n\",\n\t\t dev_cap->reserved_mrws, dev_cap->reserved_mtts);\n\tmlx4_dbg(dev, \"Max PDs: %d, reserved PDs: %d, reserved UARs: %d\\n\",\n\t\t dev_cap->max_pds, dev_cap->reserved_pds, dev_cap->reserved_uars);\n\tmlx4_dbg(dev, \"Max QP/MCG: %d, reserved MGMs: %d\\n\",\n\t\t dev_cap->max_pds, dev_cap->reserved_mgms);\n\tmlx4_dbg(dev, \"Max CQEs: %d, max WQEs: %d, max SRQ WQEs: %d\\n\",\n\t\t dev_cap->max_cq_sz, dev_cap->max_qp_sz, dev_cap->max_srq_sz);\n\tmlx4_dbg(dev, \"Local CA ACK delay: %d, max MTU: %d, port width cap: %d\\n\",\n\t\t dev_cap->local_ca_ack_delay, 128 << dev_cap->port_cap[1].ib_mtu,\n\t\t dev_cap->port_cap[1].max_port_width);\n\tmlx4_dbg(dev, \"Max SQ desc size: %d, max SQ S/G: %d\\n\",\n\t\t dev_cap->max_sq_desc_sz, dev_cap->max_sq_sg);\n\tmlx4_dbg(dev, \"Max RQ desc size: %d, max RQ S/G: %d\\n\",\n\t\t dev_cap->max_rq_desc_sz, dev_cap->max_rq_sg);\n\tmlx4_dbg(dev, \"Max GSO size: %d\\n\", dev_cap->max_gso_sz);\n\tmlx4_dbg(dev, \"Max counters: %d\\n\", dev_cap->max_counters);\n\tmlx4_dbg(dev, \"Max RSS Table size: %d\\n\", dev_cap->max_rss_tbl_sz);\n\tmlx4_dbg(dev, \"DMFS high rate steer QPn base: %d\\n\",\n\t\t dev_cap->dmfs_high_rate_qpn_base);\n\tmlx4_dbg(dev, \"DMFS high rate steer QPn range: %d\\n\",\n\t\t dev_cap->dmfs_high_rate_qpn_range);\n\n\tif (dev_cap->flags2 & MLX4_DEV_CAP_FLAG2_QP_RATE_LIMIT) {\n\t\tstruct mlx4_rate_limit_caps *rl_caps = &dev_cap->rl_caps;\n\n\t\tmlx4_dbg(dev, \"QP Rate-Limit: #rates %d, unit/val max %d/%d, min %d/%d\\n\",\n\t\t\t rl_caps->num_rates, rl_caps->max_unit, rl_caps->max_val,\n\t\t\t rl_caps->min_unit, rl_caps->min_val);\n\t}\n\n\tdump_dev_cap_flags(dev, dev_cap->flags);\n\tdump_dev_cap_flags2(dev, dev_cap->flags2);\n}\n\nint mlx4_QUERY_PORT(struct mlx4_dev *dev, int port, struct mlx4_port_cap *port_cap)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *outbox;\n\tu8 field;\n\tu32 field32;\n\tint err;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\toutbox = mailbox->buf;\n\n\tif (dev->flags & MLX4_FLAG_OLD_PORT_CMDS) {\n\t\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 0, MLX4_CMD_QUERY_DEV_CAP,\n\t\t\t\t   MLX4_CMD_TIME_CLASS_A,\n\t\t\t\t   MLX4_CMD_NATIVE);\n\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tMLX4_GET(field, outbox, QUERY_DEV_CAP_VL_PORT_OFFSET);\n\t\tport_cap->max_vl\t   = field >> 4;\n\t\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MTU_WIDTH_OFFSET);\n\t\tport_cap->ib_mtu\t   = field >> 4;\n\t\tport_cap->max_port_width = field & 0xf;\n\t\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_GID_OFFSET);\n\t\tport_cap->max_gids\t   = 1 << (field & 0xf);\n\t\tMLX4_GET(field, outbox, QUERY_DEV_CAP_MAX_PKEY_OFFSET);\n\t\tport_cap->max_pkeys\t   = 1 << (field & 0xf);\n\t} else {\n#define QUERY_PORT_SUPPORTED_TYPE_OFFSET\t0x00\n#define QUERY_PORT_MTU_OFFSET\t\t\t0x01\n#define QUERY_PORT_ETH_MTU_OFFSET\t\t0x02\n#define QUERY_PORT_WIDTH_OFFSET\t\t\t0x06\n#define QUERY_PORT_MAX_GID_PKEY_OFFSET\t\t0x07\n#define QUERY_PORT_MAX_MACVLAN_OFFSET\t\t0x0a\n#define QUERY_PORT_MAX_VL_OFFSET\t\t0x0b\n#define QUERY_PORT_MAC_OFFSET\t\t\t0x10\n#define QUERY_PORT_TRANS_VENDOR_OFFSET\t\t0x18\n#define QUERY_PORT_WAVELENGTH_OFFSET\t\t0x1c\n#define QUERY_PORT_TRANS_CODE_OFFSET\t\t0x20\n\n\t\terr = mlx4_cmd_box(dev, 0, mailbox->dma, port, 0, MLX4_CMD_QUERY_PORT,\n\t\t\t\t   MLX4_CMD_TIME_CLASS_B, MLX4_CMD_NATIVE);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tMLX4_GET(field, outbox, QUERY_PORT_SUPPORTED_TYPE_OFFSET);\n\t\tport_cap->link_state = (field & 0x80) >> 7;\n\t\tport_cap->supported_port_types = field & 3;\n\t\tport_cap->suggested_type = (field >> 3) & 1;\n\t\tport_cap->default_sense = (field >> 4) & 1;\n\t\tport_cap->dmfs_optimized_state = (field >> 5) & 1;\n\t\tMLX4_GET(field, outbox, QUERY_PORT_MTU_OFFSET);\n\t\tport_cap->ib_mtu\t   = field & 0xf;\n\t\tMLX4_GET(field, outbox, QUERY_PORT_WIDTH_OFFSET);\n\t\tport_cap->max_port_width = field & 0xf;\n\t\tMLX4_GET(field, outbox, QUERY_PORT_MAX_GID_PKEY_OFFSET);\n\t\tport_cap->max_gids\t   = 1 << (field >> 4);\n\t\tport_cap->max_pkeys\t   = 1 << (field & 0xf);\n\t\tMLX4_GET(field, outbox, QUERY_PORT_MAX_VL_OFFSET);\n\t\tport_cap->max_vl\t   = field & 0xf;\n\t\tport_cap->max_tc_eth\t   = field >> 4;\n\t\tMLX4_GET(field, outbox, QUERY_PORT_MAX_MACVLAN_OFFSET);\n\t\tport_cap->log_max_macs  = field & 0xf;\n\t\tport_cap->log_max_vlans = field >> 4;\n\t\tMLX4_GET(port_cap->eth_mtu, outbox, QUERY_PORT_ETH_MTU_OFFSET);\n\t\tMLX4_GET(port_cap->def_mac, outbox, QUERY_PORT_MAC_OFFSET);\n\t\tMLX4_GET(field32, outbox, QUERY_PORT_TRANS_VENDOR_OFFSET);\n\t\tport_cap->trans_type = field32 >> 24;\n\t\tport_cap->vendor_oui = field32 & 0xffffff;\n\t\tMLX4_GET(port_cap->wavelength, outbox, QUERY_PORT_WAVELENGTH_OFFSET);\n\t\tMLX4_GET(port_cap->trans_code, outbox, QUERY_PORT_TRANS_CODE_OFFSET);\n\t}\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\n#define DEV_CAP_EXT_2_FLAG_PFC_COUNTERS\t(1 << 28)\n#define DEV_CAP_EXT_2_FLAG_VLAN_CONTROL (1 << 26)\n#define DEV_CAP_EXT_2_FLAG_80_VFS\t(1 << 21)\n#define DEV_CAP_EXT_2_FLAG_FSM\t\t(1 << 20)\n\nint mlx4_QUERY_DEV_CAP_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t       struct mlx4_vhcr *vhcr,\n\t\t\t       struct mlx4_cmd_mailbox *inbox,\n\t\t\t       struct mlx4_cmd_mailbox *outbox,\n\t\t\t       struct mlx4_cmd_info *cmd)\n{\n\tu64\tflags;\n\tint\terr = 0;\n\tu8\tfield;\n\tu16\tfield16;\n\tu32\tbmme_flags, field32;\n\tint\treal_port;\n\tint\tslave_port;\n\tint\tfirst_port;\n\tstruct mlx4_active_ports actv_ports;\n\n\terr = mlx4_cmd_box(dev, 0, outbox->dma, 0, 0, MLX4_CMD_QUERY_DEV_CAP,\n\t\t\t   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\tif (err)\n\t\treturn err;\n\n\tdisable_unsupported_roce_caps(outbox->buf);\n\t \n\tMLX4_GET(flags, outbox->buf, QUERY_DEV_CAP_EXT_FLAGS_OFFSET);\n\tflags |= MLX4_DEV_CAP_FLAG_PORT_MNG_CHG_EV;\n\tflags &= ~MLX4_DEV_CAP_FLAG_MEM_WINDOW;\n\tactv_ports = mlx4_get_active_ports(dev, slave);\n\tfirst_port = find_first_bit(actv_ports.ports, dev->caps.num_ports);\n\tfor (slave_port = 0, real_port = first_port;\n\t     real_port < first_port +\n\t     bitmap_weight(actv_ports.ports, dev->caps.num_ports);\n\t     ++real_port, ++slave_port) {\n\t\tif (flags & (MLX4_DEV_CAP_FLAG_WOL_PORT1 << real_port))\n\t\t\tflags |= MLX4_DEV_CAP_FLAG_WOL_PORT1 << slave_port;\n\t\telse\n\t\t\tflags &= ~(MLX4_DEV_CAP_FLAG_WOL_PORT1 << slave_port);\n\t}\n\tfor (; slave_port < dev->caps.num_ports; ++slave_port)\n\t\tflags &= ~(MLX4_DEV_CAP_FLAG_WOL_PORT1 << slave_port);\n\n\t \n\tflags &= ~MLX4_DEV_CAP_FLAG_RSS_IP_FRAG;\n\tMLX4_PUT(outbox->buf, flags, QUERY_DEV_CAP_EXT_FLAGS_OFFSET);\n\n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_VL_PORT_OFFSET);\n\tfield &= ~0x0F;\n\tfield |= bitmap_weight(actv_ports.ports, dev->caps.num_ports) & 0x0F;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_VL_PORT_OFFSET);\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_CQ_TS_SUPPORT_OFFSET);\n\tfield &= 0x7f;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_CQ_TS_SUPPORT_OFFSET);\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_VXLAN);\n\tfield &= 0xd7;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_VXLAN);\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_PORT_BEACON_OFFSET);\n\tfield &= 0x7f;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_PORT_BEACON_OFFSET);\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_BF_OFFSET);\n\tfield &= 0x7f;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_BF_OFFSET);\n\n\t \n\tMLX4_GET(bmme_flags, outbox->buf, QUERY_DEV_CAP_BMME_FLAGS_OFFSET);\n\tbmme_flags &= ~MLX4_BMME_FLAG_TYPE_2_WIN;\n\tbmme_flags &= ~MLX4_FLAG_PORT_REMAP;\n\tMLX4_PUT(outbox->buf, bmme_flags, QUERY_DEV_CAP_BMME_FLAGS_OFFSET);\n\n\t \n\tif (dev->caps.steering_mode != MLX4_STEERING_MODE_DEVICE_MANAGED) {\n\t\tMLX4_GET(field, outbox->buf,\n\t\t\t QUERY_DEV_CAP_FLOW_STEERING_RANGE_EN_OFFSET);\n\t\tfield &= 0x7f;\n\t\tMLX4_PUT(outbox->buf, field,\n\t\t\t QUERY_DEV_CAP_FLOW_STEERING_RANGE_EN_OFFSET);\n\t}\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_FLOW_STEERING_IPOIB_OFFSET);\n\tfield &= ~0x80;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_FLOW_STEERING_IPOIB_OFFSET);\n\n\t \n\tMLX4_GET(field32, outbox->buf, QUERY_DEV_CAP_EXT_2_FLAGS_OFFSET);\n\tfield32 &= ~(DEV_CAP_EXT_2_FLAG_VLAN_CONTROL | DEV_CAP_EXT_2_FLAG_80_VFS |\n\t\t     DEV_CAP_EXT_2_FLAG_FSM | DEV_CAP_EXT_2_FLAG_PFC_COUNTERS);\n\tMLX4_PUT(outbox->buf, field32, QUERY_DEV_CAP_EXT_2_FLAGS_OFFSET);\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_ECN_QCN_VER_OFFSET);\n\tfield &= 0xfe;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_ECN_QCN_VER_OFFSET);\n\n\t \n\tfield16 = 0;\n\tMLX4_PUT(outbox->buf, field16, QUERY_DEV_CAP_QP_RATE_LIMIT_NUM_OFFSET);\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_CQ_EQ_CACHE_LINE_STRIDE);\n\tfield &= 0xef;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_CQ_EQ_CACHE_LINE_STRIDE);\n\n\t \n\tMLX4_GET(field, outbox->buf, QUERY_DEV_CAP_CONFIG_DEV_OFFSET);\n\tfield &= 0xfb;\n\tMLX4_PUT(outbox->buf, field, QUERY_DEV_CAP_CONFIG_DEV_OFFSET);\n\n\treturn 0;\n}\n\nstatic void disable_unsupported_roce_caps(void *buf)\n{\n\tu32 flags;\n\n\tMLX4_GET(flags, buf, QUERY_DEV_CAP_EXT_FLAGS_OFFSET);\n\tflags &= ~(1UL << 31);\n\tMLX4_PUT(buf, flags, QUERY_DEV_CAP_EXT_FLAGS_OFFSET);\n\tMLX4_GET(flags, buf, QUERY_DEV_CAP_EXT_2_FLAGS_OFFSET);\n\tflags &= ~(1UL << 24);\n\tMLX4_PUT(buf, flags, QUERY_DEV_CAP_EXT_2_FLAGS_OFFSET);\n\tMLX4_GET(flags, buf, QUERY_DEV_CAP_BMME_FLAGS_OFFSET);\n\tflags &= ~(MLX4_FLAG_ROCE_V1_V2);\n\tMLX4_PUT(buf, flags, QUERY_DEV_CAP_BMME_FLAGS_OFFSET);\n}\n\nint mlx4_QUERY_PORT_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t    struct mlx4_vhcr *vhcr,\n\t\t\t    struct mlx4_cmd_mailbox *inbox,\n\t\t\t    struct mlx4_cmd_mailbox *outbox,\n\t\t\t    struct mlx4_cmd_info *cmd)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tu64 def_mac;\n\tu8 port_type;\n\tu16 short_field;\n\tint err;\n\tint admin_link_state;\n\tint port = mlx4_slave_convert_port(dev, slave,\n\t\t\t\t\t   vhcr->in_modifier & 0xFF);\n\n#define MLX4_VF_PORT_NO_LINK_SENSE_MASK\t0xE0\n#define MLX4_PORT_LINK_UP_MASK\t\t0x80\n#define QUERY_PORT_CUR_MAX_PKEY_OFFSET\t0x0c\n#define QUERY_PORT_CUR_MAX_GID_OFFSET\t0x0e\n\n\tif (port < 0)\n\t\treturn -EINVAL;\n\n\t \n\tif (vhcr->op_modifier || vhcr->in_modifier & ~0xFF)\n\t\treturn -EINVAL;\n\n\tvhcr->in_modifier = port;\n\n\terr = mlx4_cmd_box(dev, 0, outbox->dma, vhcr->in_modifier, 0,\n\t\t\t   MLX4_CMD_QUERY_PORT, MLX4_CMD_TIME_CLASS_B,\n\t\t\t   MLX4_CMD_NATIVE);\n\n\tif (!err && dev->caps.function != slave) {\n\t\tdef_mac = priv->mfunc.master.vf_oper[slave].vport[vhcr->in_modifier].state.mac;\n\t\tMLX4_PUT(outbox->buf, def_mac, QUERY_PORT_MAC_OFFSET);\n\n\t\t \n\t\tMLX4_GET(port_type, outbox->buf,\n\t\t\t QUERY_PORT_SUPPORTED_TYPE_OFFSET);\n\n\t\t \n\t\tport_type &= MLX4_VF_PORT_NO_LINK_SENSE_MASK;\n\t\t \n\t\tport_type |= (dev->caps.port_type[vhcr->in_modifier] & 0x3);\n\n\t\tadmin_link_state = priv->mfunc.master.vf_oper[slave].vport[vhcr->in_modifier].state.link_state;\n\t\tif (IFLA_VF_LINK_STATE_ENABLE == admin_link_state)\n\t\t\tport_type |= MLX4_PORT_LINK_UP_MASK;\n\t\telse if (IFLA_VF_LINK_STATE_DISABLE == admin_link_state)\n\t\t\tport_type &= ~MLX4_PORT_LINK_UP_MASK;\n\t\telse if (IFLA_VF_LINK_STATE_AUTO == admin_link_state && mlx4_is_bonded(dev)) {\n\t\t\tint other_port = (port == 1) ? 2 : 1;\n\t\t\tstruct mlx4_port_cap port_cap;\n\n\t\t\terr = mlx4_QUERY_PORT(dev, other_port, &port_cap);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t\tport_type |= (port_cap.link_state << 7);\n\t\t}\n\n\t\tMLX4_PUT(outbox->buf, port_type,\n\t\t\t QUERY_PORT_SUPPORTED_TYPE_OFFSET);\n\n\t\tif (dev->caps.port_type[vhcr->in_modifier] == MLX4_PORT_TYPE_ETH)\n\t\t\tshort_field = mlx4_get_slave_num_gids(dev, slave, port);\n\t\telse\n\t\t\tshort_field = 1;  \n\t\tMLX4_PUT(outbox->buf, short_field,\n\t\t\t QUERY_PORT_CUR_MAX_GID_OFFSET);\n\n\t\tshort_field = dev->caps.pkey_table_len[vhcr->in_modifier];\n\t\tMLX4_PUT(outbox->buf, short_field,\n\t\t\t QUERY_PORT_CUR_MAX_PKEY_OFFSET);\n\t}\nout:\n\treturn err;\n}\n\nint mlx4_get_slave_pkey_gid_tbl_len(struct mlx4_dev *dev, u8 port,\n\t\t\t\t    int *gid_tbl_len, int *pkey_tbl_len)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32\t\t\t*outbox;\n\tu16\t\t\tfield;\n\tint\t\t\terr;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\terr =  mlx4_cmd_box(dev, 0, mailbox->dma, port, 0,\n\t\t\t    MLX4_CMD_QUERY_PORT, MLX4_CMD_TIME_CLASS_B,\n\t\t\t    MLX4_CMD_WRAPPED);\n\tif (err)\n\t\tgoto out;\n\n\toutbox = mailbox->buf;\n\n\tMLX4_GET(field, outbox, QUERY_PORT_CUR_MAX_GID_OFFSET);\n\t*gid_tbl_len = field;\n\n\tMLX4_GET(field, outbox, QUERY_PORT_CUR_MAX_PKEY_OFFSET);\n\t*pkey_tbl_len = field;\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\nEXPORT_SYMBOL(mlx4_get_slave_pkey_gid_tbl_len);\n\nint mlx4_map_cmd(struct mlx4_dev *dev, u16 op, struct mlx4_icm *icm, u64 virt)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_icm_iter iter;\n\t__be64 *pages;\n\tint lg;\n\tint nent = 0;\n\tint i;\n\tint err = 0;\n\tint ts = 0, tc = 0;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\tpages = mailbox->buf;\n\n\tfor (mlx4_icm_first(icm, &iter);\n\t     !mlx4_icm_last(&iter);\n\t     mlx4_icm_next(&iter)) {\n\t\t \n\t\tlg = ffs(mlx4_icm_addr(&iter) | mlx4_icm_size(&iter)) - 1;\n\t\tif (lg < MLX4_ICM_PAGE_SHIFT) {\n\t\t\tmlx4_warn(dev, \"Got FW area not aligned to %d (%llx/%lx)\\n\",\n\t\t\t\t  MLX4_ICM_PAGE_SIZE,\n\t\t\t\t  (unsigned long long) mlx4_icm_addr(&iter),\n\t\t\t\t  mlx4_icm_size(&iter));\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tfor (i = 0; i < mlx4_icm_size(&iter) >> lg; ++i) {\n\t\t\tif (virt != -1) {\n\t\t\t\tpages[nent * 2] = cpu_to_be64(virt);\n\t\t\t\tvirt += 1ULL << lg;\n\t\t\t}\n\n\t\t\tpages[nent * 2 + 1] =\n\t\t\t\tcpu_to_be64((mlx4_icm_addr(&iter) + (i << lg)) |\n\t\t\t\t\t    (lg - MLX4_ICM_PAGE_SHIFT));\n\t\t\tts += 1 << (lg - 10);\n\t\t\t++tc;\n\n\t\t\tif (++nent == MLX4_MAILBOX_SIZE / 16) {\n\t\t\t\terr = mlx4_cmd(dev, mailbox->dma, nent, 0, op,\n\t\t\t\t\t\tMLX4_CMD_TIME_CLASS_B,\n\t\t\t\t\t\tMLX4_CMD_NATIVE);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto out;\n\t\t\t\tnent = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nent)\n\t\terr = mlx4_cmd(dev, mailbox->dma, nent, 0, op,\n\t\t\t       MLX4_CMD_TIME_CLASS_B, MLX4_CMD_NATIVE);\n\tif (err)\n\t\tgoto out;\n\n\tswitch (op) {\n\tcase MLX4_CMD_MAP_FA:\n\t\tmlx4_dbg(dev, \"Mapped %d chunks/%d KB for FW\\n\", tc, ts);\n\t\tbreak;\n\tcase MLX4_CMD_MAP_ICM_AUX:\n\t\tmlx4_dbg(dev, \"Mapped %d chunks/%d KB for ICM aux\\n\", tc, ts);\n\t\tbreak;\n\tcase MLX4_CMD_MAP_ICM:\n\t\tmlx4_dbg(dev, \"Mapped %d chunks/%d KB at %llx for ICM\\n\",\n\t\t\t tc, ts, (unsigned long long) virt - (ts << 10));\n\t\tbreak;\n\t}\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nint mlx4_MAP_FA(struct mlx4_dev *dev, struct mlx4_icm *icm)\n{\n\treturn mlx4_map_cmd(dev, MLX4_CMD_MAP_FA, icm, -1);\n}\n\nint mlx4_UNMAP_FA(struct mlx4_dev *dev)\n{\n\treturn mlx4_cmd(dev, 0, 0, 0, MLX4_CMD_UNMAP_FA,\n\t\t\tMLX4_CMD_TIME_CLASS_B, MLX4_CMD_NATIVE);\n}\n\n\nint mlx4_RUN_FW(struct mlx4_dev *dev)\n{\n\treturn mlx4_cmd(dev, 0, 0, 0, MLX4_CMD_RUN_FW,\n\t\t\tMLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n}\n\nint mlx4_QUERY_FW(struct mlx4_dev *dev)\n{\n\tstruct mlx4_fw  *fw  = &mlx4_priv(dev)->fw;\n\tstruct mlx4_cmd *cmd = &mlx4_priv(dev)->cmd;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *outbox;\n\tint err = 0;\n\tu64 fw_ver;\n\tu16 cmd_if_rev;\n\tu8 lg;\n\n#define QUERY_FW_OUT_SIZE             0x100\n#define QUERY_FW_VER_OFFSET            0x00\n#define QUERY_FW_PPF_ID\t\t       0x09\n#define QUERY_FW_CMD_IF_REV_OFFSET     0x0a\n#define QUERY_FW_MAX_CMD_OFFSET        0x0f\n#define QUERY_FW_ERR_START_OFFSET      0x30\n#define QUERY_FW_ERR_SIZE_OFFSET       0x38\n#define QUERY_FW_ERR_BAR_OFFSET        0x3c\n\n#define QUERY_FW_SIZE_OFFSET           0x00\n#define QUERY_FW_CLR_INT_BASE_OFFSET   0x20\n#define QUERY_FW_CLR_INT_BAR_OFFSET    0x28\n\n#define QUERY_FW_COMM_BASE_OFFSET      0x40\n#define QUERY_FW_COMM_BAR_OFFSET       0x48\n\n#define QUERY_FW_CLOCK_OFFSET\t       0x50\n#define QUERY_FW_CLOCK_BAR\t       0x58\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\toutbox = mailbox->buf;\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 0, MLX4_CMD_QUERY_FW,\n\t\t\t    MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\tif (err)\n\t\tgoto out;\n\n\tMLX4_GET(fw_ver, outbox, QUERY_FW_VER_OFFSET);\n\t \n\tdev->caps.fw_ver = (fw_ver & 0xffff00000000ull) |\n\t\t((fw_ver & 0xffff0000ull) >> 16) |\n\t\t((fw_ver & 0x0000ffffull) << 16);\n\n\tMLX4_GET(lg, outbox, QUERY_FW_PPF_ID);\n\tdev->caps.function = lg;\n\n\tif (mlx4_is_slave(dev))\n\t\tgoto out;\n\n\n\tMLX4_GET(cmd_if_rev, outbox, QUERY_FW_CMD_IF_REV_OFFSET);\n\tif (cmd_if_rev < MLX4_COMMAND_INTERFACE_MIN_REV ||\n\t    cmd_if_rev > MLX4_COMMAND_INTERFACE_MAX_REV) {\n\t\tmlx4_err(dev, \"Installed FW has unsupported command interface revision %d\\n\",\n\t\t\t cmd_if_rev);\n\t\tmlx4_err(dev, \"(Installed FW version is %d.%d.%03d)\\n\",\n\t\t\t (int) (dev->caps.fw_ver >> 32),\n\t\t\t (int) (dev->caps.fw_ver >> 16) & 0xffff,\n\t\t\t (int) dev->caps.fw_ver & 0xffff);\n\t\tmlx4_err(dev, \"This driver version supports only revisions %d to %d\\n\",\n\t\t\t MLX4_COMMAND_INTERFACE_MIN_REV, MLX4_COMMAND_INTERFACE_MAX_REV);\n\t\terr = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tif (cmd_if_rev < MLX4_COMMAND_INTERFACE_NEW_PORT_CMDS)\n\t\tdev->flags |= MLX4_FLAG_OLD_PORT_CMDS;\n\n\tMLX4_GET(lg, outbox, QUERY_FW_MAX_CMD_OFFSET);\n\tcmd->max_cmds = 1 << lg;\n\n\tmlx4_dbg(dev, \"FW version %d.%d.%03d (cmd intf rev %d), max commands %d\\n\",\n\t\t (int) (dev->caps.fw_ver >> 32),\n\t\t (int) (dev->caps.fw_ver >> 16) & 0xffff,\n\t\t (int) dev->caps.fw_ver & 0xffff,\n\t\t cmd_if_rev, cmd->max_cmds);\n\n\tMLX4_GET(fw->catas_offset, outbox, QUERY_FW_ERR_START_OFFSET);\n\tMLX4_GET(fw->catas_size,   outbox, QUERY_FW_ERR_SIZE_OFFSET);\n\tMLX4_GET(fw->catas_bar,    outbox, QUERY_FW_ERR_BAR_OFFSET);\n\tfw->catas_bar = (fw->catas_bar >> 6) * 2;\n\n\tmlx4_dbg(dev, \"Catastrophic error buffer at 0x%llx, size 0x%x, BAR %d\\n\",\n\t\t (unsigned long long) fw->catas_offset, fw->catas_size, fw->catas_bar);\n\n\tMLX4_GET(fw->fw_pages,     outbox, QUERY_FW_SIZE_OFFSET);\n\tMLX4_GET(fw->clr_int_base, outbox, QUERY_FW_CLR_INT_BASE_OFFSET);\n\tMLX4_GET(fw->clr_int_bar,  outbox, QUERY_FW_CLR_INT_BAR_OFFSET);\n\tfw->clr_int_bar = (fw->clr_int_bar >> 6) * 2;\n\n\tMLX4_GET(fw->comm_base, outbox, QUERY_FW_COMM_BASE_OFFSET);\n\tMLX4_GET(fw->comm_bar,  outbox, QUERY_FW_COMM_BAR_OFFSET);\n\tfw->comm_bar = (fw->comm_bar >> 6) * 2;\n\tmlx4_dbg(dev, \"Communication vector bar:%d offset:0x%llx\\n\",\n\t\t fw->comm_bar, fw->comm_base);\n\tmlx4_dbg(dev, \"FW size %d KB\\n\", fw->fw_pages >> 2);\n\n\tMLX4_GET(fw->clock_offset, outbox, QUERY_FW_CLOCK_OFFSET);\n\tMLX4_GET(fw->clock_bar,    outbox, QUERY_FW_CLOCK_BAR);\n\tfw->clock_bar = (fw->clock_bar >> 6) * 2;\n\tmlx4_dbg(dev, \"Internal clock bar:%d offset:0x%llx\\n\",\n\t\t fw->clock_bar, fw->clock_offset);\n\n\t \n\tfw->fw_pages =\n\t\tALIGN(fw->fw_pages, PAGE_SIZE / MLX4_ICM_PAGE_SIZE) >>\n\t\t(PAGE_SHIFT - MLX4_ICM_PAGE_SHIFT);\n\n\tmlx4_dbg(dev, \"Clear int @ %llx, BAR %d\\n\",\n\t\t (unsigned long long) fw->clr_int_base, fw->clr_int_bar);\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nint mlx4_QUERY_FW_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t  struct mlx4_vhcr *vhcr,\n\t\t\t  struct mlx4_cmd_mailbox *inbox,\n\t\t\t  struct mlx4_cmd_mailbox *outbox,\n\t\t\t  struct mlx4_cmd_info *cmd)\n{\n\tu8 *outbuf;\n\tint err;\n\n\toutbuf = outbox->buf;\n\terr = mlx4_cmd_box(dev, 0, outbox->dma, 0, 0, MLX4_CMD_QUERY_FW,\n\t\t\t    MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\tif (err)\n\t\treturn err;\n\n\t \n\toutbuf[0] = outbuf[1] = 0;\n\tmemset(&outbuf[8], 0, QUERY_FW_OUT_SIZE - 8);\n\toutbuf[QUERY_FW_PPF_ID] = MLX4_INVALID_SLAVE_ID;\n\n\treturn 0;\n}\n\nstatic void get_board_id(void *vsd, char *board_id)\n{\n\tint i;\n\n#define VSD_OFFSET_SIG1\t\t0x00\n#define VSD_OFFSET_SIG2\t\t0xde\n#define VSD_OFFSET_MLX_BOARD_ID\t0xd0\n#define VSD_OFFSET_TS_BOARD_ID\t0x20\n\n#define VSD_SIGNATURE_TOPSPIN\t0x5ad\n\n\tmemset(board_id, 0, MLX4_BOARD_ID_LEN);\n\n\tif (be16_to_cpup(vsd + VSD_OFFSET_SIG1) == VSD_SIGNATURE_TOPSPIN &&\n\t    be16_to_cpup(vsd + VSD_OFFSET_SIG2) == VSD_SIGNATURE_TOPSPIN) {\n\t\tstrscpy(board_id, vsd + VSD_OFFSET_TS_BOARD_ID, MLX4_BOARD_ID_LEN);\n\t} else {\n\t\t \n\t\tu32 *bid_u32 = (u32 *)board_id;\n\n\t\tfor (i = 0; i < 4; ++i) {\n\t\t\tu32 *addr;\n\t\t\tu32 val;\n\n\t\t\taddr = (u32 *) (vsd + VSD_OFFSET_MLX_BOARD_ID + i * 4);\n\t\t\tval = get_unaligned(addr);\n\t\t\tval = swab32(val);\n\t\t\tput_unaligned(val, &bid_u32[i]);\n\t\t}\n\t}\n}\n\nint mlx4_QUERY_ADAPTER(struct mlx4_dev *dev, struct mlx4_adapter *adapter)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *outbox;\n\tint err;\n\n#define QUERY_ADAPTER_OUT_SIZE             0x100\n#define QUERY_ADAPTER_INTA_PIN_OFFSET      0x10\n#define QUERY_ADAPTER_VSD_OFFSET           0x20\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\toutbox = mailbox->buf;\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 0, MLX4_CMD_QUERY_ADAPTER,\n\t\t\t   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\tif (err)\n\t\tgoto out;\n\n\tMLX4_GET(adapter->inta_pin, outbox,    QUERY_ADAPTER_INTA_PIN_OFFSET);\n\n\tget_board_id(outbox + QUERY_ADAPTER_VSD_OFFSET / 4,\n\t\t     adapter->board_id);\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nint mlx4_INIT_HCA(struct mlx4_dev *dev, struct mlx4_init_hca_param *param)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\t__be32 *inbox;\n\tint err;\n\tstatic const u8 a0_dmfs_hw_steering[] =  {\n\t\t[MLX4_STEERING_DMFS_A0_DEFAULT]\t\t= 0,\n\t\t[MLX4_STEERING_DMFS_A0_DYNAMIC]\t\t= 1,\n\t\t[MLX4_STEERING_DMFS_A0_STATIC]\t\t= 2,\n\t\t[MLX4_STEERING_DMFS_A0_DISABLE]\t\t= 3\n\t};\n\n#define INIT_HCA_IN_SIZE\t\t 0x200\n#define INIT_HCA_VERSION_OFFSET\t\t 0x000\n#define\t INIT_HCA_VERSION\t\t 2\n#define INIT_HCA_VXLAN_OFFSET\t\t 0x0c\n#define INIT_HCA_CACHELINE_SZ_OFFSET\t 0x0e\n#define INIT_HCA_FLAGS_OFFSET\t\t 0x014\n#define INIT_HCA_RECOVERABLE_ERROR_EVENT_OFFSET 0x018\n#define INIT_HCA_QPC_OFFSET\t\t 0x020\n#define\t INIT_HCA_QPC_BASE_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x10)\n#define\t INIT_HCA_LOG_QP_OFFSET\t\t (INIT_HCA_QPC_OFFSET + 0x17)\n#define\t INIT_HCA_SRQC_BASE_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x28)\n#define\t INIT_HCA_LOG_SRQ_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x2f)\n#define\t INIT_HCA_CQC_BASE_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x30)\n#define\t INIT_HCA_LOG_CQ_OFFSET\t\t (INIT_HCA_QPC_OFFSET + 0x37)\n#define\t INIT_HCA_EQE_CQE_OFFSETS\t (INIT_HCA_QPC_OFFSET + 0x38)\n#define\t INIT_HCA_EQE_CQE_STRIDE_OFFSET  (INIT_HCA_QPC_OFFSET + 0x3b)\n#define\t INIT_HCA_ALTC_BASE_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x40)\n#define\t INIT_HCA_AUXC_BASE_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x50)\n#define\t INIT_HCA_EQC_BASE_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x60)\n#define\t INIT_HCA_LOG_EQ_OFFSET\t\t (INIT_HCA_QPC_OFFSET + 0x67)\n#define\tINIT_HCA_NUM_SYS_EQS_OFFSET\t(INIT_HCA_QPC_OFFSET + 0x6a)\n#define\t INIT_HCA_RDMARC_BASE_OFFSET\t (INIT_HCA_QPC_OFFSET + 0x70)\n#define\t INIT_HCA_LOG_RD_OFFSET\t\t (INIT_HCA_QPC_OFFSET + 0x77)\n#define INIT_HCA_MCAST_OFFSET\t\t 0x0c0\n#define\t INIT_HCA_MC_BASE_OFFSET\t (INIT_HCA_MCAST_OFFSET + 0x00)\n#define\t INIT_HCA_LOG_MC_ENTRY_SZ_OFFSET (INIT_HCA_MCAST_OFFSET + 0x13)\n#define\t INIT_HCA_LOG_MC_HASH_SZ_OFFSET\t (INIT_HCA_MCAST_OFFSET + 0x17)\n#define  INIT_HCA_UC_STEERING_OFFSET\t (INIT_HCA_MCAST_OFFSET + 0x18)\n#define\t INIT_HCA_LOG_MC_TABLE_SZ_OFFSET (INIT_HCA_MCAST_OFFSET + 0x1b)\n#define  INIT_HCA_DEVICE_MANAGED_FLOW_STEERING_EN\t0x6\n#define  INIT_HCA_DRIVER_VERSION_OFFSET   0x140\n#define  INIT_HCA_DRIVER_VERSION_SZ       0x40\n#define  INIT_HCA_FS_PARAM_OFFSET         0x1d0\n#define  INIT_HCA_FS_BASE_OFFSET          (INIT_HCA_FS_PARAM_OFFSET + 0x00)\n#define  INIT_HCA_FS_LOG_ENTRY_SZ_OFFSET  (INIT_HCA_FS_PARAM_OFFSET + 0x13)\n#define  INIT_HCA_FS_A0_OFFSET\t\t  (INIT_HCA_FS_PARAM_OFFSET + 0x18)\n#define  INIT_HCA_FS_LOG_TABLE_SZ_OFFSET  (INIT_HCA_FS_PARAM_OFFSET + 0x1b)\n#define  INIT_HCA_FS_ETH_BITS_OFFSET      (INIT_HCA_FS_PARAM_OFFSET + 0x21)\n#define  INIT_HCA_FS_ETH_NUM_ADDRS_OFFSET (INIT_HCA_FS_PARAM_OFFSET + 0x22)\n#define  INIT_HCA_FS_IB_BITS_OFFSET       (INIT_HCA_FS_PARAM_OFFSET + 0x25)\n#define  INIT_HCA_FS_IB_NUM_ADDRS_OFFSET  (INIT_HCA_FS_PARAM_OFFSET + 0x26)\n#define INIT_HCA_TPT_OFFSET\t\t 0x0f0\n#define\t INIT_HCA_DMPT_BASE_OFFSET\t (INIT_HCA_TPT_OFFSET + 0x00)\n#define  INIT_HCA_TPT_MW_OFFSET\t\t (INIT_HCA_TPT_OFFSET + 0x08)\n#define\t INIT_HCA_LOG_MPT_SZ_OFFSET\t (INIT_HCA_TPT_OFFSET + 0x0b)\n#define\t INIT_HCA_MTT_BASE_OFFSET\t (INIT_HCA_TPT_OFFSET + 0x10)\n#define\t INIT_HCA_CMPT_BASE_OFFSET\t (INIT_HCA_TPT_OFFSET + 0x18)\n#define INIT_HCA_UAR_OFFSET\t\t 0x120\n#define\t INIT_HCA_LOG_UAR_SZ_OFFSET\t (INIT_HCA_UAR_OFFSET + 0x0a)\n#define  INIT_HCA_UAR_PAGE_SZ_OFFSET     (INIT_HCA_UAR_OFFSET + 0x0b)\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\tinbox = mailbox->buf;\n\n\t*((u8 *) mailbox->buf + INIT_HCA_VERSION_OFFSET) = INIT_HCA_VERSION;\n\n\t*((u8 *) mailbox->buf + INIT_HCA_CACHELINE_SZ_OFFSET) =\n\t\t((ilog2(cache_line_size()) - 4) << 5) | (1 << 4);\n\n#if defined(__LITTLE_ENDIAN)\n\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) &= ~cpu_to_be32(1 << 1);\n#elif defined(__BIG_ENDIAN)\n\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) |= cpu_to_be32(1 << 1);\n#else\n#error Host endianness not defined\n#endif\n\t \n\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) |= cpu_to_be32(1);\n\n\t \n\tif (dev->caps.flags & MLX4_DEV_CAP_FLAG_IPOIB_CSUM)\n\t\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) |= cpu_to_be32(1 << 3);\n\n\t \n\tif (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_ETS_CFG && enable_qos)\n\t\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) |= cpu_to_be32(1 << 2);\n\n\t \n\tif (dev->caps.flags & MLX4_DEV_CAP_FLAG_COUNTERS)\n\t\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) |= cpu_to_be32(1 << 4);\n\n\t \n\tif (dev->caps.flags & MLX4_DEV_CAP_FLAG_RSS_IP_FRAG)\n\t\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) |= cpu_to_be32(1 << 13);\n\n\t \n\tif (dev->caps.flags & MLX4_DEV_CAP_FLAG_64B_EQE) {\n\t\t*(inbox + INIT_HCA_EQE_CQE_OFFSETS / 4) |= cpu_to_be32(1 << 29);\n\t\tdev->caps.eqe_size   = 64;\n\t\tdev->caps.eqe_factor = 1;\n\t} else {\n\t\tdev->caps.eqe_size   = 32;\n\t\tdev->caps.eqe_factor = 0;\n\t}\n\n\tif (dev->caps.flags & MLX4_DEV_CAP_FLAG_64B_CQE) {\n\t\t*(inbox + INIT_HCA_EQE_CQE_OFFSETS / 4) |= cpu_to_be32(1 << 30);\n\t\tdev->caps.cqe_size   = 64;\n\t\tdev->caps.userspace_caps |= MLX4_USER_DEV_CAP_LARGE_CQE;\n\t} else {\n\t\tdev->caps.cqe_size   = 32;\n\t}\n\n\t \n\tif ((dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_EQE_STRIDE) &&\n\t    (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_CQE_STRIDE)) {\n\t\tdev->caps.eqe_size = cache_line_size();\n\t\tdev->caps.cqe_size = cache_line_size();\n\t\tdev->caps.eqe_factor = 0;\n\t\tMLX4_PUT(inbox, (u8)((ilog2(dev->caps.eqe_size) - 5) << 4 |\n\t\t\t\t      (ilog2(dev->caps.eqe_size) - 5)),\n\t\t\t INIT_HCA_EQE_CQE_STRIDE_OFFSET);\n\n\t\t \n\t\tdev->caps.userspace_caps |= MLX4_USER_DEV_CAP_LARGE_CQE;\n\t}\n\n\tif (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_RECOVERABLE_ERROR_EVENT)\n\t\t*(inbox + INIT_HCA_RECOVERABLE_ERROR_EVENT_OFFSET / 4) |= cpu_to_be32(1 << 31);\n\n\tif (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_DRIVER_VERSION_TO_FW) {\n\t\tu8 *dst = (u8 *)(inbox + INIT_HCA_DRIVER_VERSION_OFFSET / 4);\n\n\t\tstrncpy(dst, DRV_NAME_FOR_FW, INIT_HCA_DRIVER_VERSION_SZ - 1);\n\t\tmlx4_dbg(dev, \"Reporting Driver Version to FW: %s\\n\", dst);\n\t}\n\n\t \n\n\tMLX4_PUT(inbox, param->qpc_base,      INIT_HCA_QPC_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->log_num_qps,   INIT_HCA_LOG_QP_OFFSET);\n\tMLX4_PUT(inbox, param->srqc_base,     INIT_HCA_SRQC_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->log_num_srqs,  INIT_HCA_LOG_SRQ_OFFSET);\n\tMLX4_PUT(inbox, param->cqc_base,      INIT_HCA_CQC_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->log_num_cqs,   INIT_HCA_LOG_CQ_OFFSET);\n\tMLX4_PUT(inbox, param->altc_base,     INIT_HCA_ALTC_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->auxc_base,     INIT_HCA_AUXC_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->eqc_base,      INIT_HCA_EQC_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->log_num_eqs,   INIT_HCA_LOG_EQ_OFFSET);\n\tMLX4_PUT(inbox, param->num_sys_eqs,   INIT_HCA_NUM_SYS_EQS_OFFSET);\n\tMLX4_PUT(inbox, param->rdmarc_base,   INIT_HCA_RDMARC_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->log_rd_per_qp, INIT_HCA_LOG_RD_OFFSET);\n\n\t \n\tif (dev->caps.steering_mode ==\n\t    MLX4_STEERING_MODE_DEVICE_MANAGED) {\n\t\t*(inbox + INIT_HCA_FLAGS_OFFSET / 4) |=\n\t\t\tcpu_to_be32(1 <<\n\t\t\t\t    INIT_HCA_DEVICE_MANAGED_FLOW_STEERING_EN);\n\n\t\tMLX4_PUT(inbox, param->mc_base, INIT_HCA_FS_BASE_OFFSET);\n\t\tMLX4_PUT(inbox, param->log_mc_entry_sz,\n\t\t\t INIT_HCA_FS_LOG_ENTRY_SZ_OFFSET);\n\t\tMLX4_PUT(inbox, param->log_mc_table_sz,\n\t\t\t INIT_HCA_FS_LOG_TABLE_SZ_OFFSET);\n\t\t \n\t\tif (dev->caps.dmfs_high_steer_mode !=\n\t\t    MLX4_STEERING_DMFS_A0_STATIC)\n\t\t\tMLX4_PUT(inbox,\n\t\t\t\t (u8)(MLX4_FS_UDP_UC_EN | MLX4_FS_TCP_UC_EN),\n\t\t\t\t INIT_HCA_FS_ETH_BITS_OFFSET);\n\t\tMLX4_PUT(inbox, (u16) MLX4_FS_NUM_OF_L2_ADDR,\n\t\t\t INIT_HCA_FS_ETH_NUM_ADDRS_OFFSET);\n\t\t \n\t\tMLX4_PUT(inbox, (u8) (MLX4_FS_UDP_UC_EN | MLX4_FS_TCP_UC_EN),\n\t\t\t INIT_HCA_FS_IB_BITS_OFFSET);\n\t\tMLX4_PUT(inbox, (u16) MLX4_FS_NUM_OF_L2_ADDR,\n\t\t\t INIT_HCA_FS_IB_NUM_ADDRS_OFFSET);\n\n\t\tif (dev->caps.dmfs_high_steer_mode !=\n\t\t    MLX4_STEERING_DMFS_A0_NOT_SUPPORTED)\n\t\t\tMLX4_PUT(inbox,\n\t\t\t\t ((u8)(a0_dmfs_hw_steering[dev->caps.dmfs_high_steer_mode]\n\t\t\t\t       << 6)),\n\t\t\t\t INIT_HCA_FS_A0_OFFSET);\n\t} else {\n\t\tMLX4_PUT(inbox, param->mc_base,\tINIT_HCA_MC_BASE_OFFSET);\n\t\tMLX4_PUT(inbox, param->log_mc_entry_sz,\n\t\t\t INIT_HCA_LOG_MC_ENTRY_SZ_OFFSET);\n\t\tMLX4_PUT(inbox, param->log_mc_hash_sz,\n\t\t\t INIT_HCA_LOG_MC_HASH_SZ_OFFSET);\n\t\tMLX4_PUT(inbox, param->log_mc_table_sz,\n\t\t\t INIT_HCA_LOG_MC_TABLE_SZ_OFFSET);\n\t\tif (dev->caps.steering_mode == MLX4_STEERING_MODE_B0)\n\t\t\tMLX4_PUT(inbox, (u8) (1 << 3),\n\t\t\t\t INIT_HCA_UC_STEERING_OFFSET);\n\t}\n\n\t \n\n\tMLX4_PUT(inbox, param->dmpt_base,  INIT_HCA_DMPT_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->mw_enabled, INIT_HCA_TPT_MW_OFFSET);\n\tMLX4_PUT(inbox, param->log_mpt_sz, INIT_HCA_LOG_MPT_SZ_OFFSET);\n\tMLX4_PUT(inbox, param->mtt_base,   INIT_HCA_MTT_BASE_OFFSET);\n\tMLX4_PUT(inbox, param->cmpt_base,  INIT_HCA_CMPT_BASE_OFFSET);\n\n\t \n\n\tMLX4_PUT(inbox, param->uar_page_sz,\tINIT_HCA_UAR_PAGE_SZ_OFFSET);\n\tMLX4_PUT(inbox, param->log_uar_sz,      INIT_HCA_LOG_UAR_SZ_OFFSET);\n\n\t \n\tif (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_VXLAN_OFFLOADS) {\n\t\tu8 parser_params = 0;\n\t\tMLX4_PUT(inbox, parser_params,\tINIT_HCA_VXLAN_OFFSET);\n\t}\n\n\terr = mlx4_cmd(dev, mailbox->dma, 0, 0, MLX4_CMD_INIT_HCA,\n\t\t       MLX4_CMD_TIME_CLASS_C, MLX4_CMD_NATIVE);\n\n\tif (err)\n\t\tmlx4_err(dev, \"INIT_HCA returns %d\\n\", err);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nint mlx4_QUERY_HCA(struct mlx4_dev *dev,\n\t\t   struct mlx4_init_hca_param *param)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\t__be32 *outbox;\n\tu64 qword_field;\n\tu32 dword_field;\n\tu16 word_field;\n\tu8 byte_field;\n\tint err;\n\tstatic const u8 a0_dmfs_query_hw_steering[] =  {\n\t\t[0] = MLX4_STEERING_DMFS_A0_DEFAULT,\n\t\t[1] = MLX4_STEERING_DMFS_A0_DYNAMIC,\n\t\t[2] = MLX4_STEERING_DMFS_A0_STATIC,\n\t\t[3] = MLX4_STEERING_DMFS_A0_DISABLE\n\t};\n\n#define QUERY_HCA_GLOBAL_CAPS_OFFSET\t0x04\n#define QUERY_HCA_CORE_CLOCK_OFFSET\t0x0c\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\toutbox = mailbox->buf;\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 0,\n\t\t\t   MLX4_CMD_QUERY_HCA,\n\t\t\t   MLX4_CMD_TIME_CLASS_B,\n\t\t\t   !mlx4_is_slave(dev));\n\tif (err)\n\t\tgoto out;\n\n\tMLX4_GET(param->global_caps, outbox, QUERY_HCA_GLOBAL_CAPS_OFFSET);\n\tMLX4_GET(param->hca_core_clock, outbox, QUERY_HCA_CORE_CLOCK_OFFSET);\n\n\t \n\n\tMLX4_GET(qword_field, outbox, INIT_HCA_QPC_BASE_OFFSET);\n\tparam->qpc_base = qword_field & ~((u64)0x1f);\n\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_QP_OFFSET);\n\tparam->log_num_qps = byte_field & 0x1f;\n\tMLX4_GET(qword_field, outbox, INIT_HCA_SRQC_BASE_OFFSET);\n\tparam->srqc_base = qword_field & ~((u64)0x1f);\n\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_SRQ_OFFSET);\n\tparam->log_num_srqs = byte_field & 0x1f;\n\tMLX4_GET(qword_field, outbox, INIT_HCA_CQC_BASE_OFFSET);\n\tparam->cqc_base = qword_field & ~((u64)0x1f);\n\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_CQ_OFFSET);\n\tparam->log_num_cqs = byte_field & 0x1f;\n\tMLX4_GET(qword_field, outbox, INIT_HCA_ALTC_BASE_OFFSET);\n\tparam->altc_base = qword_field;\n\tMLX4_GET(qword_field, outbox, INIT_HCA_AUXC_BASE_OFFSET);\n\tparam->auxc_base = qword_field;\n\tMLX4_GET(qword_field, outbox, INIT_HCA_EQC_BASE_OFFSET);\n\tparam->eqc_base = qword_field & ~((u64)0x1f);\n\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_EQ_OFFSET);\n\tparam->log_num_eqs = byte_field & 0x1f;\n\tMLX4_GET(word_field, outbox, INIT_HCA_NUM_SYS_EQS_OFFSET);\n\tparam->num_sys_eqs = word_field & 0xfff;\n\tMLX4_GET(qword_field, outbox, INIT_HCA_RDMARC_BASE_OFFSET);\n\tparam->rdmarc_base = qword_field & ~((u64)0x1f);\n\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_RD_OFFSET);\n\tparam->log_rd_per_qp = byte_field & 0x7;\n\n\tMLX4_GET(dword_field, outbox, INIT_HCA_FLAGS_OFFSET);\n\tif (dword_field & (1 << INIT_HCA_DEVICE_MANAGED_FLOW_STEERING_EN)) {\n\t\tparam->steering_mode = MLX4_STEERING_MODE_DEVICE_MANAGED;\n\t} else {\n\t\tMLX4_GET(byte_field, outbox, INIT_HCA_UC_STEERING_OFFSET);\n\t\tif (byte_field & 0x8)\n\t\t\tparam->steering_mode = MLX4_STEERING_MODE_B0;\n\t\telse\n\t\t\tparam->steering_mode = MLX4_STEERING_MODE_A0;\n\t}\n\n\tif (dword_field & (1 << 13))\n\t\tparam->rss_ip_frags = 1;\n\n\t \n\tif (param->steering_mode == MLX4_STEERING_MODE_DEVICE_MANAGED) {\n\t\tMLX4_GET(param->mc_base, outbox, INIT_HCA_FS_BASE_OFFSET);\n\t\tMLX4_GET(byte_field, outbox, INIT_HCA_FS_LOG_ENTRY_SZ_OFFSET);\n\t\tparam->log_mc_entry_sz = byte_field & 0x1f;\n\t\tMLX4_GET(byte_field, outbox, INIT_HCA_FS_LOG_TABLE_SZ_OFFSET);\n\t\tparam->log_mc_table_sz = byte_field & 0x1f;\n\t\tMLX4_GET(byte_field, outbox, INIT_HCA_FS_A0_OFFSET);\n\t\tparam->dmfs_high_steer_mode =\n\t\t\ta0_dmfs_query_hw_steering[(byte_field >> 6) & 3];\n\t} else {\n\t\tMLX4_GET(param->mc_base, outbox, INIT_HCA_MC_BASE_OFFSET);\n\t\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_MC_ENTRY_SZ_OFFSET);\n\t\tparam->log_mc_entry_sz = byte_field & 0x1f;\n\t\tMLX4_GET(byte_field,  outbox, INIT_HCA_LOG_MC_HASH_SZ_OFFSET);\n\t\tparam->log_mc_hash_sz = byte_field & 0x1f;\n\t\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_MC_TABLE_SZ_OFFSET);\n\t\tparam->log_mc_table_sz = byte_field & 0x1f;\n\t}\n\n\t \n\tMLX4_GET(byte_field, outbox, INIT_HCA_EQE_CQE_OFFSETS);\n\tif (byte_field & 0x20)  \n\t\tparam->dev_cap_enabled |= MLX4_DEV_CAP_64B_EQE_ENABLED;\n\tif (byte_field & 0x40)  \n\t\tparam->dev_cap_enabled |= MLX4_DEV_CAP_64B_CQE_ENABLED;\n\n\t \n\tMLX4_GET(byte_field, outbox, INIT_HCA_EQE_CQE_STRIDE_OFFSET);\n\tif (byte_field) {\n\t\tparam->dev_cap_enabled |= MLX4_DEV_CAP_EQE_STRIDE_ENABLED;\n\t\tparam->dev_cap_enabled |= MLX4_DEV_CAP_CQE_STRIDE_ENABLED;\n\t\tparam->cqe_size = 1 << ((byte_field &\n\t\t\t\t\t MLX4_CQE_SIZE_MASK_STRIDE) + 5);\n\t\tparam->eqe_size = 1 << (((byte_field &\n\t\t\t\t\t  MLX4_EQE_SIZE_MASK_STRIDE) >> 4) + 5);\n\t}\n\n\t \n\n\tMLX4_GET(param->dmpt_base,  outbox, INIT_HCA_DMPT_BASE_OFFSET);\n\tMLX4_GET(byte_field, outbox, INIT_HCA_TPT_MW_OFFSET);\n\tparam->mw_enabled = byte_field >> 7;\n\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_MPT_SZ_OFFSET);\n\tparam->log_mpt_sz = byte_field & 0x3f;\n\tMLX4_GET(param->mtt_base,   outbox, INIT_HCA_MTT_BASE_OFFSET);\n\tMLX4_GET(param->cmpt_base,  outbox, INIT_HCA_CMPT_BASE_OFFSET);\n\n\t \n\n\tMLX4_GET(param->uar_page_sz, outbox, INIT_HCA_UAR_PAGE_SZ_OFFSET);\n\tMLX4_GET(byte_field, outbox, INIT_HCA_LOG_UAR_SZ_OFFSET);\n\tparam->log_uar_sz = byte_field & 0xf;\n\n\t \n\tMLX4_GET(byte_field, outbox, INIT_HCA_CACHELINE_SZ_OFFSET);\n\tif (byte_field & 0x2)\n\t\tparam->phv_check_en = 1;\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\n\treturn err;\n}\n\nstatic int mlx4_hca_core_clock_update(struct mlx4_dev *dev)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\t__be32 *outbox;\n\tint err;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\tmlx4_warn(dev, \"hca_core_clock mailbox allocation failed\\n\");\n\t\treturn PTR_ERR(mailbox);\n\t}\n\toutbox = mailbox->buf;\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 0,\n\t\t\t   MLX4_CMD_QUERY_HCA,\n\t\t\t   MLX4_CMD_TIME_CLASS_B,\n\t\t\t   !mlx4_is_slave(dev));\n\tif (err) {\n\t\tmlx4_warn(dev, \"hca_core_clock update failed\\n\");\n\t\tgoto out;\n\t}\n\n\tMLX4_GET(dev->caps.hca_core_clock, outbox, QUERY_HCA_CORE_CLOCK_OFFSET);\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\n\treturn err;\n}\n\n \nstatic int check_qp0_state(struct mlx4_dev *dev, int function, int port)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\t \n\tif (priv->mfunc.master.qp0_state[port].proxy_qp0_active &&\n\t    priv->mfunc.master.qp0_state[port].qp0_active)\n\t\treturn 1;\n\treturn 0;\n}\n\nint mlx4_INIT_PORT_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t   struct mlx4_vhcr *vhcr,\n\t\t\t   struct mlx4_cmd_mailbox *inbox,\n\t\t\t   struct mlx4_cmd_mailbox *outbox,\n\t\t\t   struct mlx4_cmd_info *cmd)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tint port = mlx4_slave_convert_port(dev, slave, vhcr->in_modifier);\n\tint err;\n\n\tif (port < 0)\n\t\treturn -EINVAL;\n\n\tif (priv->mfunc.master.slave_state[slave].init_port_mask & (1 << port))\n\t\treturn 0;\n\n\tif (dev->caps.port_mask[port] != MLX4_PORT_TYPE_IB) {\n\t\t \n\t\tif (!priv->mfunc.master.init_port_ref[port]) {\n\t\t\terr = mlx4_cmd(dev, 0, port, 0, MLX4_CMD_INIT_PORT,\n\t\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\tpriv->mfunc.master.slave_state[slave].init_port_mask |= (1 << port);\n\t} else {\n\t\tif (slave == mlx4_master_func_num(dev)) {\n\t\t\tif (check_qp0_state(dev, slave, port) &&\n\t\t\t    !priv->mfunc.master.qp0_state[port].port_active) {\n\t\t\t\terr = mlx4_cmd(dev, 0, port, 0, MLX4_CMD_INIT_PORT,\n\t\t\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t\tpriv->mfunc.master.qp0_state[port].port_active = 1;\n\t\t\t\tpriv->mfunc.master.slave_state[slave].init_port_mask |= (1 << port);\n\t\t\t}\n\t\t} else\n\t\t\tpriv->mfunc.master.slave_state[slave].init_port_mask |= (1 << port);\n\t}\n\t++priv->mfunc.master.init_port_ref[port];\n\treturn 0;\n}\n\nint mlx4_INIT_PORT(struct mlx4_dev *dev, int port)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *inbox;\n\tint err;\n\tu32 flags;\n\tu16 field;\n\n\tif (dev->flags & MLX4_FLAG_OLD_PORT_CMDS) {\n#define INIT_PORT_IN_SIZE          256\n#define INIT_PORT_FLAGS_OFFSET     0x00\n#define INIT_PORT_FLAG_SIG         (1 << 18)\n#define INIT_PORT_FLAG_NG          (1 << 17)\n#define INIT_PORT_FLAG_G0          (1 << 16)\n#define INIT_PORT_VL_SHIFT         4\n#define INIT_PORT_PORT_WIDTH_SHIFT 8\n#define INIT_PORT_MTU_OFFSET       0x04\n#define INIT_PORT_MAX_GID_OFFSET   0x06\n#define INIT_PORT_MAX_PKEY_OFFSET  0x0a\n#define INIT_PORT_GUID0_OFFSET     0x10\n#define INIT_PORT_NODE_GUID_OFFSET 0x18\n#define INIT_PORT_SI_GUID_OFFSET   0x20\n\n\t\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\t\tif (IS_ERR(mailbox))\n\t\t\treturn PTR_ERR(mailbox);\n\t\tinbox = mailbox->buf;\n\n\t\tflags = 0;\n\t\tflags |= (dev->caps.vl_cap[port] & 0xf) << INIT_PORT_VL_SHIFT;\n\t\tflags |= (dev->caps.port_width_cap[port] & 0xf) << INIT_PORT_PORT_WIDTH_SHIFT;\n\t\tMLX4_PUT(inbox, flags,\t\t  INIT_PORT_FLAGS_OFFSET);\n\n\t\tfield = 128 << dev->caps.ib_mtu_cap[port];\n\t\tMLX4_PUT(inbox, field, INIT_PORT_MTU_OFFSET);\n\t\tfield = dev->caps.gid_table_len[port];\n\t\tMLX4_PUT(inbox, field, INIT_PORT_MAX_GID_OFFSET);\n\t\tfield = dev->caps.pkey_table_len[port];\n\t\tMLX4_PUT(inbox, field, INIT_PORT_MAX_PKEY_OFFSET);\n\n\t\terr = mlx4_cmd(dev, mailbox->dma, port, 0, MLX4_CMD_INIT_PORT,\n\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\n\t\tmlx4_free_cmd_mailbox(dev, mailbox);\n\t} else\n\t\terr = mlx4_cmd(dev, 0, port, 0, MLX4_CMD_INIT_PORT,\n\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED);\n\n\tif (!err)\n\t\tmlx4_hca_core_clock_update(dev);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_INIT_PORT);\n\nint mlx4_CLOSE_PORT_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t    struct mlx4_vhcr *vhcr,\n\t\t\t    struct mlx4_cmd_mailbox *inbox,\n\t\t\t    struct mlx4_cmd_mailbox *outbox,\n\t\t\t    struct mlx4_cmd_info *cmd)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tint port = mlx4_slave_convert_port(dev, slave, vhcr->in_modifier);\n\tint err;\n\n\tif (port < 0)\n\t\treturn -EINVAL;\n\n\tif (!(priv->mfunc.master.slave_state[slave].init_port_mask &\n\t    (1 << port)))\n\t\treturn 0;\n\n\tif (dev->caps.port_mask[port] != MLX4_PORT_TYPE_IB) {\n\t\tif (priv->mfunc.master.init_port_ref[port] == 1) {\n\t\t\terr = mlx4_cmd(dev, 0, port, 0, MLX4_CMD_CLOSE_PORT,\n\t\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\tpriv->mfunc.master.slave_state[slave].init_port_mask &= ~(1 << port);\n\t} else {\n\t\t \n\t\tif (slave == mlx4_master_func_num(dev)) {\n\t\t\tif (!priv->mfunc.master.qp0_state[port].qp0_active &&\n\t\t\t    priv->mfunc.master.qp0_state[port].port_active) {\n\t\t\t\terr = mlx4_cmd(dev, 0, port, 0, MLX4_CMD_CLOSE_PORT,\n\t\t\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t\tpriv->mfunc.master.slave_state[slave].init_port_mask &= ~(1 << port);\n\t\t\t\tpriv->mfunc.master.qp0_state[port].port_active = 0;\n\t\t\t}\n\t\t} else\n\t\t\tpriv->mfunc.master.slave_state[slave].init_port_mask &= ~(1 << port);\n\t}\n\t--priv->mfunc.master.init_port_ref[port];\n\treturn 0;\n}\n\nint mlx4_CLOSE_PORT(struct mlx4_dev *dev, int port)\n{\n\treturn mlx4_cmd(dev, 0, port, 0, MLX4_CMD_CLOSE_PORT,\n\t\t\tMLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED);\n}\nEXPORT_SYMBOL_GPL(mlx4_CLOSE_PORT);\n\nint mlx4_CLOSE_HCA(struct mlx4_dev *dev, int panic)\n{\n\treturn mlx4_cmd(dev, 0, 0, panic, MLX4_CMD_CLOSE_HCA,\n\t\t\tMLX4_CMD_TIME_CLASS_C, MLX4_CMD_NATIVE);\n}\n\nstruct mlx4_config_dev {\n\t__be32\tupdate_flags;\n\t__be32\trsvd1[3];\n\t__be16\tvxlan_udp_dport;\n\t__be16\trsvd2;\n\t__be16  roce_v2_entropy;\n\t__be16  roce_v2_udp_dport;\n\t__be32\troce_flags;\n\t__be32\trsvd4[25];\n\t__be16\trsvd5;\n\tu8\trsvd6;\n\tu8\trx_checksum_val;\n};\n\n#define MLX4_VXLAN_UDP_DPORT (1 << 0)\n#define MLX4_ROCE_V2_UDP_DPORT BIT(3)\n#define MLX4_DISABLE_RX_PORT BIT(18)\n\nstatic int mlx4_CONFIG_DEV_set(struct mlx4_dev *dev, struct mlx4_config_dev *config_dev)\n{\n\tint err;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\tmemcpy(mailbox->buf, config_dev, sizeof(*config_dev));\n\n\terr = mlx4_cmd(dev, mailbox->dma, 0, 0, MLX4_CMD_CONFIG_DEV,\n\t\t       MLX4_CMD_TIME_CLASS_B, MLX4_CMD_NATIVE);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nstatic int mlx4_CONFIG_DEV_get(struct mlx4_dev *dev, struct mlx4_config_dev *config_dev)\n{\n\tint err;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 1, MLX4_CMD_CONFIG_DEV,\n\t\t\t   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\n\tif (!err)\n\t\tmemcpy(config_dev, mailbox->buf, sizeof(*config_dev));\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\n \nstatic const u8 config_dev_csum_flags[] = {\n\t[0] =\t0,\n\t[1] =\tMLX4_RX_CSUM_MODE_VAL_NON_TCP_UDP,\n\t[2] =\tMLX4_RX_CSUM_MODE_VAL_NON_TCP_UDP\t|\n\t\tMLX4_RX_CSUM_MODE_L4,\n\t[3] =\tMLX4_RX_CSUM_MODE_L4\t\t\t|\n\t\tMLX4_RX_CSUM_MODE_IP_OK_IP_NON_TCP_UDP\t|\n\t\tMLX4_RX_CSUM_MODE_MULTI_VLAN\n};\n\nint mlx4_config_dev_retrieval(struct mlx4_dev *dev,\n\t\t\t      struct mlx4_config_dev_params *params)\n{\n\tstruct mlx4_config_dev config_dev = {0};\n\tint err;\n\tu8 csum_mask;\n\n#define CONFIG_DEV_RX_CSUM_MODE_MASK\t\t\t0x7\n#define CONFIG_DEV_RX_CSUM_MODE_PORT1_BIT_OFFSET\t0\n#define CONFIG_DEV_RX_CSUM_MODE_PORT2_BIT_OFFSET\t4\n\n\tif (!(dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_CONFIG_DEV))\n\t\treturn -EOPNOTSUPP;\n\n\terr = mlx4_CONFIG_DEV_get(dev, &config_dev);\n\tif (err)\n\t\treturn err;\n\n\tcsum_mask = (config_dev.rx_checksum_val >> CONFIG_DEV_RX_CSUM_MODE_PORT1_BIT_OFFSET) &\n\t\t\tCONFIG_DEV_RX_CSUM_MODE_MASK;\n\n\tif (csum_mask >= ARRAY_SIZE(config_dev_csum_flags))\n\t\treturn -EINVAL;\n\tparams->rx_csum_flags_port_1 = config_dev_csum_flags[csum_mask];\n\n\tcsum_mask = (config_dev.rx_checksum_val >> CONFIG_DEV_RX_CSUM_MODE_PORT2_BIT_OFFSET) &\n\t\t\tCONFIG_DEV_RX_CSUM_MODE_MASK;\n\n\tif (csum_mask >= ARRAY_SIZE(config_dev_csum_flags))\n\t\treturn -EINVAL;\n\tparams->rx_csum_flags_port_2 = config_dev_csum_flags[csum_mask];\n\n\tparams->vxlan_udp_dport = be16_to_cpu(config_dev.vxlan_udp_dport);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mlx4_config_dev_retrieval);\n\nint mlx4_config_vxlan_port(struct mlx4_dev *dev, __be16 udp_port)\n{\n\tstruct mlx4_config_dev config_dev;\n\n\tmemset(&config_dev, 0, sizeof(config_dev));\n\tconfig_dev.update_flags    = cpu_to_be32(MLX4_VXLAN_UDP_DPORT);\n\tconfig_dev.vxlan_udp_dport = udp_port;\n\n\treturn mlx4_CONFIG_DEV_set(dev, &config_dev);\n}\nEXPORT_SYMBOL_GPL(mlx4_config_vxlan_port);\n\n#define CONFIG_DISABLE_RX_PORT BIT(15)\nint mlx4_disable_rx_port_check(struct mlx4_dev *dev, bool dis)\n{\n\tstruct mlx4_config_dev config_dev;\n\n\tmemset(&config_dev, 0, sizeof(config_dev));\n\tconfig_dev.update_flags = cpu_to_be32(MLX4_DISABLE_RX_PORT);\n\tif (dis)\n\t\tconfig_dev.roce_flags =\n\t\t\tcpu_to_be32(CONFIG_DISABLE_RX_PORT);\n\n\treturn mlx4_CONFIG_DEV_set(dev, &config_dev);\n}\n\nint mlx4_config_roce_v2_port(struct mlx4_dev *dev, u16 udp_port)\n{\n\tstruct mlx4_config_dev config_dev;\n\n\tmemset(&config_dev, 0, sizeof(config_dev));\n\tconfig_dev.update_flags    = cpu_to_be32(MLX4_ROCE_V2_UDP_DPORT);\n\tconfig_dev.roce_v2_udp_dport = cpu_to_be16(udp_port);\n\n\treturn mlx4_CONFIG_DEV_set(dev, &config_dev);\n}\nEXPORT_SYMBOL_GPL(mlx4_config_roce_v2_port);\n\nint mlx4_virt2phy_port_map(struct mlx4_dev *dev, u32 port1, u32 port2)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct {\n\t\t__be32 v_port1;\n\t\t__be32 v_port2;\n\t} *v2p;\n\tint err;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn -ENOMEM;\n\n\tv2p = mailbox->buf;\n\tv2p->v_port1 = cpu_to_be32(port1);\n\tv2p->v_port2 = cpu_to_be32(port2);\n\n\terr = mlx4_cmd(dev, mailbox->dma, 0,\n\t\t       MLX4_SET_PORT_VIRT2PHY, MLX4_CMD_VIRT_PORT_MAP,\n\t\t       MLX4_CMD_TIME_CLASS_B, MLX4_CMD_NATIVE);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\n\nint mlx4_SET_ICM_SIZE(struct mlx4_dev *dev, u64 icm_size, u64 *aux_pages)\n{\n\tint ret = mlx4_cmd_imm(dev, icm_size, aux_pages, 0, 0,\n\t\t\t       MLX4_CMD_SET_ICM_SIZE,\n\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\t*aux_pages = ALIGN(*aux_pages, PAGE_SIZE / MLX4_ICM_PAGE_SIZE) >>\n\t\t(PAGE_SHIFT - MLX4_ICM_PAGE_SHIFT);\n\n\treturn 0;\n}\n\nint mlx4_NOP(struct mlx4_dev *dev)\n{\n\t \n\treturn mlx4_cmd(dev, 0, 0x1f, 0, MLX4_CMD_NOP, MLX4_CMD_TIME_CLASS_A,\n\t\t\tMLX4_CMD_NATIVE);\n}\n\nint mlx4_query_diag_counters(struct mlx4_dev *dev, u8 op_modifier,\n\t\t\t     const u32 offset[],\n\t\t\t     u32 value[], size_t array_len, u8 port)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 *outbox;\n\tsize_t i;\n\tint ret;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\toutbox = mailbox->buf;\n\n\tret = mlx4_cmd_box(dev, 0, mailbox->dma, port, op_modifier,\n\t\t\t   MLX4_CMD_DIAG_RPRT, MLX4_CMD_TIME_CLASS_A,\n\t\t\t   MLX4_CMD_NATIVE);\n\tif (ret)\n\t\tgoto out;\n\n\tfor (i = 0; i < array_len; i++) {\n\t\tif (offset[i] > MLX4_MAILBOX_SIZE) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tMLX4_GET(value[i], outbox, offset[i]);\n\t}\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn ret;\n}\nEXPORT_SYMBOL(mlx4_query_diag_counters);\n\nint mlx4_get_phys_port_id(struct mlx4_dev *dev)\n{\n\tu8 port;\n\tu32 *outbox;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tu32 in_mod;\n\tu32 guid_hi, guid_lo;\n\tint err, ret = 0;\n#define MOD_STAT_CFG_PORT_OFFSET 8\n#define MOD_STAT_CFG_GUID_H\t 0X14\n#define MOD_STAT_CFG_GUID_L\t 0X1c\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\toutbox = mailbox->buf;\n\n\tfor (port = 1; port <= dev->caps.num_ports; port++) {\n\t\tin_mod = port << MOD_STAT_CFG_PORT_OFFSET;\n\t\terr = mlx4_cmd_box(dev, 0, mailbox->dma, in_mod, 0x2,\n\t\t\t\t   MLX4_CMD_MOD_STAT_CFG, MLX4_CMD_TIME_CLASS_A,\n\t\t\t\t   MLX4_CMD_NATIVE);\n\t\tif (err) {\n\t\t\tmlx4_err(dev, \"Fail to get port %d uplink guid\\n\",\n\t\t\t\t port);\n\t\t\tret = err;\n\t\t} else {\n\t\t\tMLX4_GET(guid_hi, outbox, MOD_STAT_CFG_GUID_H);\n\t\t\tMLX4_GET(guid_lo, outbox, MOD_STAT_CFG_GUID_L);\n\t\t\tdev->caps.phys_port_id[port] = (u64)guid_lo |\n\t\t\t\t\t\t       (u64)guid_hi << 32;\n\t\t}\n\t}\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn ret;\n}\n\n#define MLX4_WOL_SETUP_MODE (5 << 28)\nint mlx4_wol_read(struct mlx4_dev *dev, u64 *config, int port)\n{\n\tu32 in_mod = MLX4_WOL_SETUP_MODE | port << 8;\n\n\treturn mlx4_cmd_imm(dev, 0, config, in_mod, 0x3,\n\t\t\t    MLX4_CMD_MOD_STAT_CFG, MLX4_CMD_TIME_CLASS_A,\n\t\t\t    MLX4_CMD_NATIVE);\n}\nEXPORT_SYMBOL_GPL(mlx4_wol_read);\n\nint mlx4_wol_write(struct mlx4_dev *dev, u64 config, int port)\n{\n\tu32 in_mod = MLX4_WOL_SETUP_MODE | port << 8;\n\n\treturn mlx4_cmd(dev, config, in_mod, 0x1, MLX4_CMD_MOD_STAT_CFG,\n\t\t\tMLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n}\nEXPORT_SYMBOL_GPL(mlx4_wol_write);\n\nenum {\n\tADD_TO_MCG = 0x26,\n};\n\n\nvoid mlx4_opreq_action(struct work_struct *work)\n{\n\tstruct mlx4_priv *priv = container_of(work, struct mlx4_priv,\n\t\t\t\t\t      opreq_task);\n\tstruct mlx4_dev *dev = &priv->dev;\n\tint num_tasks = atomic_read(&priv->opreq_count);\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm;\n\tu32 *outbox;\n\tu32 modifier;\n\tu16 token;\n\tu16 type;\n\tint err;\n\tu32 num_qps;\n\tstruct mlx4_qp qp;\n\tint i;\n\tu8 rem_mcg;\n\tu8 prot;\n\n#define GET_OP_REQ_MODIFIER_OFFSET\t0x08\n#define GET_OP_REQ_TOKEN_OFFSET\t\t0x14\n#define GET_OP_REQ_TYPE_OFFSET\t\t0x1a\n#define GET_OP_REQ_DATA_OFFSET\t\t0x20\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\tmlx4_err(dev, \"Failed to allocate mailbox for GET_OP_REQ\\n\");\n\t\treturn;\n\t}\n\toutbox = mailbox->buf;\n\n\twhile (num_tasks) {\n\t\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0, 0,\n\t\t\t\t   MLX4_CMD_GET_OP_REQ, MLX4_CMD_TIME_CLASS_A,\n\t\t\t\t   MLX4_CMD_NATIVE);\n\t\tif (err) {\n\t\t\tmlx4_err(dev, \"Failed to retrieve required operation: %d\\n\",\n\t\t\t\t err);\n\t\t\tgoto out;\n\t\t}\n\t\tMLX4_GET(modifier, outbox, GET_OP_REQ_MODIFIER_OFFSET);\n\t\tMLX4_GET(token, outbox, GET_OP_REQ_TOKEN_OFFSET);\n\t\tMLX4_GET(type, outbox, GET_OP_REQ_TYPE_OFFSET);\n\t\ttype &= 0xfff;\n\n\t\tswitch (type) {\n\t\tcase ADD_TO_MCG:\n\t\t\tif (dev->caps.steering_mode ==\n\t\t\t    MLX4_STEERING_MODE_DEVICE_MANAGED) {\n\t\t\t\tmlx4_warn(dev, \"ADD MCG operation is not supported in DEVICE_MANAGED steering mode\\n\");\n\t\t\t\terr = EPERM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tmgm = (struct mlx4_mgm *)((u8 *)(outbox) +\n\t\t\t\t\t\t  GET_OP_REQ_DATA_OFFSET);\n\t\t\tnum_qps = be32_to_cpu(mgm->members_count) &\n\t\t\t\t  MGM_QPN_MASK;\n\t\t\trem_mcg = ((u8 *)(&mgm->members_count))[0] & 1;\n\t\t\tprot = ((u8 *)(&mgm->members_count))[0] >> 6;\n\n\t\t\tfor (i = 0; i < num_qps; i++) {\n\t\t\t\tqp.qpn = be32_to_cpu(mgm->qp[i]);\n\t\t\t\tif (rem_mcg)\n\t\t\t\t\terr = mlx4_multicast_detach(dev, &qp,\n\t\t\t\t\t\t\t\t    mgm->gid,\n\t\t\t\t\t\t\t\t    prot, 0);\n\t\t\t\telse\n\t\t\t\t\terr = mlx4_multicast_attach(dev, &qp,\n\t\t\t\t\t\t\t\t    mgm->gid,\n\t\t\t\t\t\t\t\t    mgm->gid[5]\n\t\t\t\t\t\t\t\t    , 0, prot,\n\t\t\t\t\t\t\t\t    NULL);\n\t\t\t\tif (err)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tmlx4_warn(dev, \"Bad type for required operation\\n\");\n\t\t\terr = EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\terr = mlx4_cmd(dev, 0, ((u32) err |\n\t\t\t\t\t(__force u32)cpu_to_be32(token) << 16),\n\t\t\t       1, MLX4_CMD_GET_OP_REQ, MLX4_CMD_TIME_CLASS_A,\n\t\t\t       MLX4_CMD_NATIVE);\n\t\tif (err) {\n\t\t\tmlx4_err(dev, \"Failed to acknowledge required request: %d\\n\",\n\t\t\t\t err);\n\t\t\tgoto out;\n\t\t}\n\t\tmemset(outbox, 0, 0xffc);\n\t\tnum_tasks = atomic_dec_return(&priv->opreq_count);\n\t}\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n}\n\nstatic int mlx4_check_smp_firewall_active(struct mlx4_dev *dev,\n\t\t\t\t\t  struct mlx4_cmd_mailbox *mailbox)\n{\n#define MLX4_CMD_MAD_DEMUX_SET_ATTR_OFFSET\t\t0x10\n#define MLX4_CMD_MAD_DEMUX_GETRESP_ATTR_OFFSET\t\t0x20\n#define MLX4_CMD_MAD_DEMUX_TRAP_ATTR_OFFSET\t\t0x40\n#define MLX4_CMD_MAD_DEMUX_TRAP_REPRESS_ATTR_OFFSET\t0x70\n\n\tu32 set_attr_mask, getresp_attr_mask;\n\tu32 trap_attr_mask, traprepress_attr_mask;\n\n\tMLX4_GET(set_attr_mask, mailbox->buf,\n\t\t MLX4_CMD_MAD_DEMUX_SET_ATTR_OFFSET);\n\tmlx4_dbg(dev, \"SMP firewall set_attribute_mask = 0x%x\\n\",\n\t\t set_attr_mask);\n\n\tMLX4_GET(getresp_attr_mask, mailbox->buf,\n\t\t MLX4_CMD_MAD_DEMUX_GETRESP_ATTR_OFFSET);\n\tmlx4_dbg(dev, \"SMP firewall getresp_attribute_mask = 0x%x\\n\",\n\t\t getresp_attr_mask);\n\n\tMLX4_GET(trap_attr_mask, mailbox->buf,\n\t\t MLX4_CMD_MAD_DEMUX_TRAP_ATTR_OFFSET);\n\tmlx4_dbg(dev, \"SMP firewall trap_attribute_mask = 0x%x\\n\",\n\t\t trap_attr_mask);\n\n\tMLX4_GET(traprepress_attr_mask, mailbox->buf,\n\t\t MLX4_CMD_MAD_DEMUX_TRAP_REPRESS_ATTR_OFFSET);\n\tmlx4_dbg(dev, \"SMP firewall traprepress_attribute_mask = 0x%x\\n\",\n\t\t traprepress_attr_mask);\n\n\tif (set_attr_mask && getresp_attr_mask && trap_attr_mask &&\n\t    traprepress_attr_mask)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nint mlx4_config_mad_demux(struct mlx4_dev *dev)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tint err;\n\n\t \n\tif (!(dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_MAD_DEMUX))\n\t\treturn 0;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\tmlx4_warn(dev, \"Failed to allocate mailbox for cmd MAD_DEMUX\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\terr = mlx4_cmd_box(dev, 0, mailbox->dma, 0x01  ,\n\t\t\t   MLX4_CMD_MAD_DEMUX_QUERY_RESTR, MLX4_CMD_MAD_DEMUX,\n\t\t\t   MLX4_CMD_TIME_CLASS_B, MLX4_CMD_NATIVE);\n\tif (err) {\n\t\tmlx4_warn(dev, \"MLX4_CMD_MAD_DEMUX: query restrictions failed (%d)\\n\",\n\t\t\t  err);\n\t\tgoto out;\n\t}\n\n\tif (mlx4_check_smp_firewall_active(dev, mailbox))\n\t\tdev->flags |= MLX4_FLAG_SECURE_HOST;\n\n\t \n\terr = mlx4_cmd(dev, mailbox->dma, 0x01  ,\n\t\t       MLX4_CMD_MAD_DEMUX_CONFIG, MLX4_CMD_MAD_DEMUX,\n\t\t       MLX4_CMD_TIME_CLASS_B, MLX4_CMD_NATIVE);\n\tif (err) {\n\t\tmlx4_warn(dev, \"MLX4_CMD_MAD_DEMUX: configure failed (%d)\\n\", err);\n\t\tgoto out;\n\t}\n\n\tif (dev->flags & MLX4_FLAG_SECURE_HOST)\n\t\tmlx4_warn(dev, \"HCA operating in secure-host mode. SMP firewall activated.\\n\");\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\n \nenum mlx4_access_reg_masks {\n\tMLX4_ACCESS_REG_STATUS_MASK = 0x7f,\n\tMLX4_ACCESS_REG_METHOD_MASK = 0x7f,\n\tMLX4_ACCESS_REG_LEN_MASK = 0x7ff\n};\n\nstruct mlx4_access_reg {\n\t__be16 constant1;\n\tu8 status;\n\tu8 resrvd1;\n\t__be16 reg_id;\n\tu8 method;\n\tu8 constant2;\n\t__be32 resrvd2[2];\n\t__be16 len_const;\n\t__be16 resrvd3;\n#define MLX4_ACCESS_REG_HEADER_SIZE (20)\n\tu8 reg_data[MLX4_MAILBOX_SIZE-MLX4_ACCESS_REG_HEADER_SIZE];\n} __attribute__((__packed__));\n\n \nstatic int mlx4_ACCESS_REG(struct mlx4_dev *dev, u16 reg_id,\n\t\t\t   enum mlx4_access_reg_method method,\n\t\t\t   u16 reg_len, void *reg_data)\n{\n\tstruct mlx4_cmd_mailbox *inbox, *outbox;\n\tstruct mlx4_access_reg *inbuf, *outbuf;\n\tint err;\n\n\tinbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(inbox))\n\t\treturn PTR_ERR(inbox);\n\n\toutbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(outbox)) {\n\t\tmlx4_free_cmd_mailbox(dev, inbox);\n\t\treturn PTR_ERR(outbox);\n\t}\n\n\tinbuf = inbox->buf;\n\toutbuf = outbox->buf;\n\n\tinbuf->constant1 = cpu_to_be16(0x1<<11 | 0x4);\n\tinbuf->constant2 = 0x1;\n\tinbuf->reg_id = cpu_to_be16(reg_id);\n\tinbuf->method = method & MLX4_ACCESS_REG_METHOD_MASK;\n\n\treg_len = min(reg_len, (u16)(sizeof(inbuf->reg_data)));\n\tinbuf->len_const =\n\t\tcpu_to_be16(((reg_len/4 + 1) & MLX4_ACCESS_REG_LEN_MASK) |\n\t\t\t    ((0x3) << 12));\n\n\tmemcpy(inbuf->reg_data, reg_data, reg_len);\n\terr = mlx4_cmd_box(dev, inbox->dma, outbox->dma, 0, 0,\n\t\t\t   MLX4_CMD_ACCESS_REG, MLX4_CMD_TIME_CLASS_C,\n\t\t\t   MLX4_CMD_WRAPPED);\n\tif (err)\n\t\tgoto out;\n\n\tif (outbuf->status & MLX4_ACCESS_REG_STATUS_MASK) {\n\t\terr = outbuf->status & MLX4_ACCESS_REG_STATUS_MASK;\n\t\tmlx4_err(dev,\n\t\t\t \"MLX4_CMD_ACCESS_REG(%x) returned REG status (%x)\\n\",\n\t\t\t reg_id, err);\n\t\tgoto out;\n\t}\n\n\tmemcpy(reg_data, outbuf->reg_data, reg_len);\nout:\n\tmlx4_free_cmd_mailbox(dev, inbox);\n\tmlx4_free_cmd_mailbox(dev, outbox);\n\treturn err;\n}\n\n \nenum mlx4_reg_id {\n\tMLX4_REG_ID_PTYS = 0x5004,\n};\n\n \nint mlx4_ACCESS_PTYS_REG(struct mlx4_dev *dev,\n\t\t\t enum mlx4_access_reg_method method,\n\t\t\t struct mlx4_ptys_reg *ptys_reg)\n{\n\treturn mlx4_ACCESS_REG(dev, MLX4_REG_ID_PTYS,\n\t\t\t       method, sizeof(*ptys_reg), ptys_reg);\n}\nEXPORT_SYMBOL_GPL(mlx4_ACCESS_PTYS_REG);\n\nint mlx4_ACCESS_REG_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t    struct mlx4_vhcr *vhcr,\n\t\t\t    struct mlx4_cmd_mailbox *inbox,\n\t\t\t    struct mlx4_cmd_mailbox *outbox,\n\t\t\t    struct mlx4_cmd_info *cmd)\n{\n\tstruct mlx4_access_reg *inbuf = inbox->buf;\n\tu8 method = inbuf->method & MLX4_ACCESS_REG_METHOD_MASK;\n\tu16 reg_id = be16_to_cpu(inbuf->reg_id);\n\n\tif (slave != mlx4_master_func_num(dev) &&\n\t    method == MLX4_ACCESS_REG_WRITE)\n\t\treturn -EPERM;\n\n\tif (reg_id == MLX4_REG_ID_PTYS) {\n\t\tstruct mlx4_ptys_reg *ptys_reg =\n\t\t\t(struct mlx4_ptys_reg *)inbuf->reg_data;\n\n\t\tptys_reg->local_port =\n\t\t\tmlx4_slave_convert_port(dev, slave,\n\t\t\t\t\t\tptys_reg->local_port);\n\t}\n\n\treturn mlx4_cmd_box(dev, inbox->dma, outbox->dma, vhcr->in_modifier,\n\t\t\t    0, MLX4_CMD_ACCESS_REG, MLX4_CMD_TIME_CLASS_C,\n\t\t\t    MLX4_CMD_NATIVE);\n}\n\nstatic int mlx4_SET_PORT_phv_bit(struct mlx4_dev *dev, u8 port, u8 phv_bit)\n{\n#define SET_PORT_GEN_PHV_VALID\t0x10\n#define SET_PORT_GEN_PHV_EN\t0x80\n\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_set_port_general_context *context;\n\tu32 in_mod;\n\tint err;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\tcontext = mailbox->buf;\n\n\tcontext->flags2 |=  SET_PORT_GEN_PHV_VALID;\n\tif (phv_bit)\n\t\tcontext->phv_en |=  SET_PORT_GEN_PHV_EN;\n\n\tin_mod = MLX4_SET_PORT_GENERAL << 8 | port;\n\terr = mlx4_cmd(dev, mailbox->dma, in_mod, MLX4_SET_PORT_ETH_OPCODE,\n\t\t       MLX4_CMD_SET_PORT, MLX4_CMD_TIME_CLASS_B,\n\t\t       MLX4_CMD_NATIVE);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nint get_phv_bit(struct mlx4_dev *dev, u8 port, int *phv)\n{\n\tint err;\n\tstruct mlx4_func_cap func_cap;\n\n\tmemset(&func_cap, 0, sizeof(func_cap));\n\terr = mlx4_QUERY_FUNC_CAP(dev, port, &func_cap);\n\tif (!err)\n\t\t*phv = func_cap.flags0 & QUERY_FUNC_CAP_PHV_BIT;\n\treturn err;\n}\nEXPORT_SYMBOL(get_phv_bit);\n\nint set_phv_bit(struct mlx4_dev *dev, u8 port, int new_val)\n{\n\tint ret;\n\n\tif (mlx4_is_slave(dev))\n\t\treturn -EPERM;\n\n\tif (dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_PHV_EN &&\n\t    !(dev->caps.flags2 & MLX4_DEV_CAP_FLAG2_SKIP_OUTER_VLAN)) {\n\t\tret = mlx4_SET_PORT_phv_bit(dev, port, new_val);\n\t\tif (!ret)\n\t\t\tdev->caps.phv_bit[port] = new_val;\n\t\treturn ret;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\nEXPORT_SYMBOL(set_phv_bit);\n\nint mlx4_get_is_vlan_offload_disabled(struct mlx4_dev *dev, u8 port,\n\t\t\t\t      bool *vlan_offload_disabled)\n{\n\tstruct mlx4_func_cap func_cap;\n\tint err;\n\n\tmemset(&func_cap, 0, sizeof(func_cap));\n\terr = mlx4_QUERY_FUNC_CAP(dev, port, &func_cap);\n\tif (!err)\n\t\t*vlan_offload_disabled =\n\t\t\t!!(func_cap.flags0 &\n\t\t\t   QUERY_FUNC_CAP_VLAN_OFFLOAD_DISABLE);\n\treturn err;\n}\nEXPORT_SYMBOL(mlx4_get_is_vlan_offload_disabled);\n\nvoid mlx4_replace_zero_macs(struct mlx4_dev *dev)\n{\n\tint i;\n\tu8 mac_addr[ETH_ALEN];\n\n\tdev->port_random_macs = 0;\n\tfor (i = 1; i <= dev->caps.num_ports; ++i)\n\t\tif (!dev->caps.def_mac[i] &&\n\t\t    dev->caps.port_type[i] == MLX4_PORT_TYPE_ETH) {\n\t\t\teth_random_addr(mac_addr);\n\t\t\tdev->port_random_macs |= 1 << i;\n\t\t\tdev->caps.def_mac[i] = ether_addr_to_u64(mac_addr);\n\t\t}\n}\nEXPORT_SYMBOL_GPL(mlx4_replace_zero_macs);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}