{
  "module_name": "srq.c",
  "hash_id": "ee2f981e3cb958674ca4c35d352c886e6a6f4d65832cf572a5c01a025a9e649f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx4/srq.c",
  "human_readable_source": " \n\n\n#include <linux/mlx4/cmd.h>\n#include <linux/mlx4/srq.h>\n#include <linux/export.h>\n#include <linux/gfp.h>\n\n#include \"mlx4.h\"\n#include \"icm.h\"\n\nvoid mlx4_srq_event(struct mlx4_dev *dev, u32 srqn, int event_type)\n{\n\tstruct mlx4_srq_table *srq_table = &mlx4_priv(dev)->srq_table;\n\tstruct mlx4_srq *srq;\n\n\trcu_read_lock();\n\tsrq = radix_tree_lookup(&srq_table->tree, srqn & (dev->caps.num_srqs - 1));\n\trcu_read_unlock();\n\tif (srq)\n\t\trefcount_inc(&srq->refcount);\n\telse {\n\t\tmlx4_warn(dev, \"Async event for bogus SRQ %08x\\n\", srqn);\n\t\treturn;\n\t}\n\n\tsrq->event(srq, event_type);\n\n\tif (refcount_dec_and_test(&srq->refcount))\n\t\tcomplete(&srq->free);\n}\n\nstatic int mlx4_SW2HW_SRQ(struct mlx4_dev *dev, struct mlx4_cmd_mailbox *mailbox,\n\t\t\t  int srq_num)\n{\n\treturn mlx4_cmd(dev, mailbox->dma, srq_num, 0,\n\t\t\tMLX4_CMD_SW2HW_SRQ, MLX4_CMD_TIME_CLASS_A,\n\t\t\tMLX4_CMD_WRAPPED);\n}\n\nstatic int mlx4_HW2SW_SRQ(struct mlx4_dev *dev, struct mlx4_cmd_mailbox *mailbox,\n\t\t\t  int srq_num)\n{\n\treturn mlx4_cmd_box(dev, 0, mailbox ? mailbox->dma : 0, srq_num,\n\t\t\t    mailbox ? 0 : 1, MLX4_CMD_HW2SW_SRQ,\n\t\t\t    MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED);\n}\n\nstatic int mlx4_ARM_SRQ(struct mlx4_dev *dev, int srq_num, int limit_watermark)\n{\n\treturn mlx4_cmd(dev, limit_watermark, srq_num, 0, MLX4_CMD_ARM_SRQ,\n\t\t\tMLX4_CMD_TIME_CLASS_B, MLX4_CMD_WRAPPED);\n}\n\nstatic int mlx4_QUERY_SRQ(struct mlx4_dev *dev, struct mlx4_cmd_mailbox *mailbox,\n\t\t\t  int srq_num)\n{\n\treturn mlx4_cmd_box(dev, 0, mailbox->dma, srq_num, 0, MLX4_CMD_QUERY_SRQ,\n\t\t\t    MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED);\n}\n\nint __mlx4_srq_alloc_icm(struct mlx4_dev *dev, int *srqn)\n{\n\tstruct mlx4_srq_table *srq_table = &mlx4_priv(dev)->srq_table;\n\tint err;\n\n\n\t*srqn = mlx4_bitmap_alloc(&srq_table->bitmap);\n\tif (*srqn == -1)\n\t\treturn -ENOMEM;\n\n\terr = mlx4_table_get(dev, &srq_table->table, *srqn);\n\tif (err)\n\t\tgoto err_out;\n\n\terr = mlx4_table_get(dev, &srq_table->cmpt_table, *srqn);\n\tif (err)\n\t\tgoto err_put;\n\treturn 0;\n\nerr_put:\n\tmlx4_table_put(dev, &srq_table->table, *srqn);\n\nerr_out:\n\tmlx4_bitmap_free(&srq_table->bitmap, *srqn, MLX4_NO_RR);\n\treturn err;\n}\n\nstatic int mlx4_srq_alloc_icm(struct mlx4_dev *dev, int *srqn)\n{\n\tu64 out_param;\n\tint err;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\terr = mlx4_cmd_imm(dev, 0, &out_param, RES_SRQ,\n\t\t\t\t   RES_OP_RESERVE_AND_MAP,\n\t\t\t\t   MLX4_CMD_ALLOC_RES,\n\t\t\t\t   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED);\n\t\tif (!err)\n\t\t\t*srqn = get_param_l(&out_param);\n\n\t\treturn err;\n\t}\n\treturn __mlx4_srq_alloc_icm(dev, srqn);\n}\n\nvoid __mlx4_srq_free_icm(struct mlx4_dev *dev, int srqn)\n{\n\tstruct mlx4_srq_table *srq_table = &mlx4_priv(dev)->srq_table;\n\n\tmlx4_table_put(dev, &srq_table->cmpt_table, srqn);\n\tmlx4_table_put(dev, &srq_table->table, srqn);\n\tmlx4_bitmap_free(&srq_table->bitmap, srqn, MLX4_NO_RR);\n}\n\nstatic void mlx4_srq_free_icm(struct mlx4_dev *dev, int srqn)\n{\n\tu64 in_param = 0;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tset_param_l(&in_param, srqn);\n\t\tif (mlx4_cmd(dev, in_param, RES_SRQ, RES_OP_RESERVE_AND_MAP,\n\t\t\t     MLX4_CMD_FREE_RES,\n\t\t\t     MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED))\n\t\t\tmlx4_warn(dev, \"Failed freeing cq:%d\\n\", srqn);\n\t\treturn;\n\t}\n\t__mlx4_srq_free_icm(dev, srqn);\n}\n\nint mlx4_srq_alloc(struct mlx4_dev *dev, u32 pdn, u32 cqn, u16 xrcd,\n\t\t   struct mlx4_mtt *mtt, u64 db_rec, struct mlx4_srq *srq)\n{\n\tstruct mlx4_srq_table *srq_table = &mlx4_priv(dev)->srq_table;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_srq_context *srq_context;\n\tu64 mtt_addr;\n\tint err;\n\n\terr = mlx4_srq_alloc_icm(dev, &srq->srqn);\n\tif (err)\n\t\treturn err;\n\n\tspin_lock_irq(&srq_table->lock);\n\terr = radix_tree_insert(&srq_table->tree, srq->srqn, srq);\n\tspin_unlock_irq(&srq_table->lock);\n\tif (err)\n\t\tgoto err_icm;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\terr = PTR_ERR(mailbox);\n\t\tgoto err_radix;\n\t}\n\n\tsrq_context = mailbox->buf;\n\tsrq_context->state_logsize_srqn = cpu_to_be32((ilog2(srq->max) << 24) |\n\t\t\t\t\t\t      srq->srqn);\n\tsrq_context->logstride          = srq->wqe_shift - 4;\n\tsrq_context->xrcd\t\t= cpu_to_be16(xrcd);\n\tsrq_context->pg_offset_cqn\t= cpu_to_be32(cqn & 0xffffff);\n\tsrq_context->log_page_size      = mtt->page_shift - MLX4_ICM_PAGE_SHIFT;\n\n\tmtt_addr = mlx4_mtt_addr(dev, mtt);\n\tsrq_context->mtt_base_addr_h    = mtt_addr >> 32;\n\tsrq_context->mtt_base_addr_l    = cpu_to_be32(mtt_addr & 0xffffffff);\n\tsrq_context->pd\t\t\t= cpu_to_be32(pdn);\n\tsrq_context->db_rec_addr        = cpu_to_be64(db_rec);\n\n\terr = mlx4_SW2HW_SRQ(dev, mailbox, srq->srqn);\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\tif (err)\n\t\tgoto err_radix;\n\n\trefcount_set(&srq->refcount, 1);\n\tinit_completion(&srq->free);\n\n\treturn 0;\n\nerr_radix:\n\tspin_lock_irq(&srq_table->lock);\n\tradix_tree_delete(&srq_table->tree, srq->srqn);\n\tspin_unlock_irq(&srq_table->lock);\n\nerr_icm:\n\tmlx4_srq_free_icm(dev, srq->srqn);\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_srq_alloc);\n\nvoid mlx4_srq_free(struct mlx4_dev *dev, struct mlx4_srq *srq)\n{\n\tstruct mlx4_srq_table *srq_table = &mlx4_priv(dev)->srq_table;\n\tint err;\n\n\terr = mlx4_HW2SW_SRQ(dev, NULL, srq->srqn);\n\tif (err)\n\t\tmlx4_warn(dev, \"HW2SW_SRQ failed (%d) for SRQN %06x\\n\", err, srq->srqn);\n\n\tspin_lock_irq(&srq_table->lock);\n\tradix_tree_delete(&srq_table->tree, srq->srqn);\n\tspin_unlock_irq(&srq_table->lock);\n\n\tif (refcount_dec_and_test(&srq->refcount))\n\t\tcomplete(&srq->free);\n\twait_for_completion(&srq->free);\n\n\tmlx4_srq_free_icm(dev, srq->srqn);\n}\nEXPORT_SYMBOL_GPL(mlx4_srq_free);\n\nint mlx4_srq_arm(struct mlx4_dev *dev, struct mlx4_srq *srq, int limit_watermark)\n{\n\treturn mlx4_ARM_SRQ(dev, srq->srqn, limit_watermark);\n}\nEXPORT_SYMBOL_GPL(mlx4_srq_arm);\n\nint mlx4_srq_query(struct mlx4_dev *dev, struct mlx4_srq *srq, int *limit_watermark)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_srq_context *srq_context;\n\tint err;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\tsrq_context = mailbox->buf;\n\n\terr = mlx4_QUERY_SRQ(dev, mailbox, srq->srqn);\n\tif (err)\n\t\tgoto err_out;\n\t*limit_watermark = be16_to_cpu(srq_context->limit_watermark);\n\nerr_out:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_srq_query);\n\nint mlx4_init_srq_table(struct mlx4_dev *dev)\n{\n\tstruct mlx4_srq_table *srq_table = &mlx4_priv(dev)->srq_table;\n\n\tspin_lock_init(&srq_table->lock);\n\tINIT_RADIX_TREE(&srq_table->tree, GFP_ATOMIC);\n\tif (mlx4_is_slave(dev))\n\t\treturn 0;\n\n\treturn mlx4_bitmap_init(&srq_table->bitmap, dev->caps.num_srqs,\n\t\t\t\tdev->caps.num_srqs - 1, dev->caps.reserved_srqs, 0);\n}\n\nvoid mlx4_cleanup_srq_table(struct mlx4_dev *dev)\n{\n\tif (mlx4_is_slave(dev))\n\t\treturn;\n\tmlx4_bitmap_cleanup(&mlx4_priv(dev)->srq_table.bitmap);\n}\n\nstruct mlx4_srq *mlx4_srq_lookup(struct mlx4_dev *dev, u32 srqn)\n{\n\tstruct mlx4_srq_table *srq_table = &mlx4_priv(dev)->srq_table;\n\tstruct mlx4_srq *srq;\n\n\trcu_read_lock();\n\tsrq = radix_tree_lookup(&srq_table->tree,\n\t\t\t\tsrqn & (dev->caps.num_srqs - 1));\n\trcu_read_unlock();\n\n\treturn srq;\n}\nEXPORT_SYMBOL_GPL(mlx4_srq_lookup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}