{
  "module_name": "mcg.c",
  "hash_id": "ea626e6b45f4cc1a85bbd8d8f75f72c0ac7af1b489ccf46ad4338033080d2ec7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx4/mcg.c",
  "human_readable_source": " \n\n#include <linux/string.h>\n#include <linux/etherdevice.h>\n\n#include <linux/mlx4/cmd.h>\n#include <linux/mlx4/qp.h>\n#include <linux/export.h>\n\n#include \"mlx4.h\"\n\nint mlx4_get_mgm_entry_size(struct mlx4_dev *dev)\n{\n\treturn 1 << dev->oper_log_mgm_entry_size;\n}\n\nint mlx4_get_qp_per_mgm(struct mlx4_dev *dev)\n{\n\treturn 4 * (mlx4_get_mgm_entry_size(dev) / 16 - 2);\n}\n\nstatic int mlx4_QP_FLOW_STEERING_ATTACH(struct mlx4_dev *dev,\n\t\t\t\t\tstruct mlx4_cmd_mailbox *mailbox,\n\t\t\t\t\tu32 size,\n\t\t\t\t\tu64 *reg_id)\n{\n\tu64 imm;\n\tint err = 0;\n\n\terr = mlx4_cmd_imm(dev, mailbox->dma, &imm, size, 0,\n\t\t\t   MLX4_QP_FLOW_STEERING_ATTACH, MLX4_CMD_TIME_CLASS_A,\n\t\t\t   MLX4_CMD_NATIVE);\n\tif (err)\n\t\treturn err;\n\t*reg_id = imm;\n\n\treturn err;\n}\n\nstatic int mlx4_QP_FLOW_STEERING_DETACH(struct mlx4_dev *dev, u64 regid)\n{\n\tint err = 0;\n\n\terr = mlx4_cmd(dev, regid, 0, 0,\n\t\t       MLX4_QP_FLOW_STEERING_DETACH, MLX4_CMD_TIME_CLASS_A,\n\t\t       MLX4_CMD_NATIVE);\n\n\treturn err;\n}\n\nstatic int mlx4_READ_ENTRY(struct mlx4_dev *dev, int index,\n\t\t\t   struct mlx4_cmd_mailbox *mailbox)\n{\n\treturn mlx4_cmd_box(dev, 0, mailbox->dma, index, 0, MLX4_CMD_READ_MCG,\n\t\t\t    MLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n}\n\nstatic int mlx4_WRITE_ENTRY(struct mlx4_dev *dev, int index,\n\t\t\t    struct mlx4_cmd_mailbox *mailbox)\n{\n\treturn mlx4_cmd(dev, mailbox->dma, index, 0, MLX4_CMD_WRITE_MCG,\n\t\t\tMLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n}\n\nstatic int mlx4_WRITE_PROMISC(struct mlx4_dev *dev, u8 port, u8 steer,\n\t\t\t      struct mlx4_cmd_mailbox *mailbox)\n{\n\tu32 in_mod;\n\n\tin_mod = (u32) port << 16 | steer << 1;\n\treturn mlx4_cmd(dev, mailbox->dma, in_mod, 0x1,\n\t\t\tMLX4_CMD_WRITE_MCG, MLX4_CMD_TIME_CLASS_A,\n\t\t\tMLX4_CMD_NATIVE);\n}\n\nstatic int mlx4_GID_HASH(struct mlx4_dev *dev, struct mlx4_cmd_mailbox *mailbox,\n\t\t\t u16 *hash, u8 op_mod)\n{\n\tu64 imm;\n\tint err;\n\n\terr = mlx4_cmd_imm(dev, mailbox->dma, &imm, 0, op_mod,\n\t\t\t   MLX4_CMD_MGID_HASH, MLX4_CMD_TIME_CLASS_A,\n\t\t\t   MLX4_CMD_NATIVE);\n\n\tif (!err)\n\t\t*hash = imm;\n\n\treturn err;\n}\n\nstatic struct mlx4_promisc_qp *get_promisc_qp(struct mlx4_dev *dev, u8 port,\n\t\t\t\t\t      enum mlx4_steer_type steer,\n\t\t\t\t\t      u32 qpn)\n{\n\tstruct mlx4_steer *s_steer;\n\tstruct mlx4_promisc_qp *pqp;\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn NULL;\n\n\ts_steer = &mlx4_priv(dev)->steer[port - 1];\n\n\tlist_for_each_entry(pqp, &s_steer->promisc_qps[steer], list) {\n\t\tif (pqp->qpn == qpn)\n\t\t\treturn pqp;\n\t}\n\t \n\treturn NULL;\n}\n\n \nstatic int new_steering_entry(struct mlx4_dev *dev, u8 port,\n\t\t\t      enum mlx4_steer_type steer,\n\t\t\t      unsigned int index, u32 qpn)\n{\n\tstruct mlx4_steer *s_steer;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm;\n\tu32 members_count;\n\tstruct mlx4_steer_index *new_entry;\n\tstruct mlx4_promisc_qp *pqp;\n\tstruct mlx4_promisc_qp *dqp = NULL;\n\tu32 prot;\n\tint err;\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn -EINVAL;\n\n\ts_steer = &mlx4_priv(dev)->steer[port - 1];\n\tnew_entry = kzalloc(sizeof(*new_entry), GFP_KERNEL);\n\tif (!new_entry)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&new_entry->duplicates);\n\tnew_entry->index = index;\n\tlist_add_tail(&new_entry->list, &s_steer->steer_entries[steer]);\n\n\t \n\tpqp = get_promisc_qp(dev, port, steer, qpn);\n\tif (pqp) {\n\t\tdqp = kmalloc(sizeof(*dqp), GFP_KERNEL);\n\t\tif (!dqp) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_alloc;\n\t\t}\n\t\tdqp->qpn = qpn;\n\t\tlist_add_tail(&dqp->list, &new_entry->duplicates);\n\t}\n\n\t \n\tif (list_empty(&s_steer->promisc_qps[steer]))\n\t\treturn 0;\n\n\t \n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\terr = -ENOMEM;\n\t\tgoto out_alloc;\n\t}\n\tmgm = mailbox->buf;\n\n\terr = mlx4_READ_ENTRY(dev, index, mailbox);\n\tif (err)\n\t\tgoto out_mailbox;\n\n\tmembers_count = be32_to_cpu(mgm->members_count) & 0xffffff;\n\tprot = be32_to_cpu(mgm->members_count) >> 30;\n\tlist_for_each_entry(pqp, &s_steer->promisc_qps[steer], list) {\n\t\t \n\t\tif (pqp->qpn == qpn)\n\t\t\tcontinue;\n\t\tif (members_count == dev->caps.num_qp_per_mgm) {\n\t\t\t \n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_mailbox;\n\t\t}\n\n\t\t \n\t\tmgm->qp[members_count++] = cpu_to_be32(pqp->qpn & MGM_QPN_MASK);\n\t}\n\t \n\tmgm->members_count = cpu_to_be32(members_count | (prot << 30));\n\terr = mlx4_WRITE_ENTRY(dev, index, mailbox);\n\nout_mailbox:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\tif (!err)\n\t\treturn 0;\nout_alloc:\n\tif (dqp) {\n\t\tlist_del(&dqp->list);\n\t\tkfree(dqp);\n\t}\n\tlist_del(&new_entry->list);\n\tkfree(new_entry);\n\treturn err;\n}\n\n \nstatic int existing_steering_entry(struct mlx4_dev *dev, u8 port,\n\t\t\t\t   enum mlx4_steer_type steer,\n\t\t\t\t   unsigned int index, u32 qpn)\n{\n\tstruct mlx4_steer *s_steer;\n\tstruct mlx4_steer_index *tmp_entry, *entry = NULL;\n\tstruct mlx4_promisc_qp *pqp;\n\tstruct mlx4_promisc_qp *dqp;\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn -EINVAL;\n\n\ts_steer = &mlx4_priv(dev)->steer[port - 1];\n\n\tpqp = get_promisc_qp(dev, port, steer, qpn);\n\tif (!pqp)\n\t\treturn 0;  \n\n\tlist_for_each_entry(tmp_entry, &s_steer->steer_entries[steer], list) {\n\t\tif (tmp_entry->index == index) {\n\t\t\tentry = tmp_entry;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (unlikely(!entry)) {\n\t\tmlx4_warn(dev, \"Steering entry at index %x is not registered\\n\", index);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tlist_for_each_entry(dqp, &entry->duplicates, list) {\n\t\tif (qpn == dqp->qpn)\n\t\t\treturn 0;  \n\t}\n\n\t \n\tdqp = kmalloc(sizeof(*dqp), GFP_KERNEL);\n\tif (!dqp)\n\t\treturn -ENOMEM;\n\tdqp->qpn = qpn;\n\tlist_add_tail(&dqp->list, &entry->duplicates);\n\n\treturn 0;\n}\n\n \nstatic bool check_duplicate_entry(struct mlx4_dev *dev, u8 port,\n\t\t\t\t  enum mlx4_steer_type steer,\n\t\t\t\t  unsigned int index, u32 qpn)\n{\n\tstruct mlx4_steer *s_steer;\n\tstruct mlx4_steer_index *tmp_entry, *entry = NULL;\n\tstruct mlx4_promisc_qp *dqp, *tmp_dqp;\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn false;\n\n\ts_steer = &mlx4_priv(dev)->steer[port - 1];\n\n\t \n\tif (!get_promisc_qp(dev, port, steer, qpn))\n\t\treturn false;\n\n\t \n\tlist_for_each_entry(tmp_entry, &s_steer->steer_entries[steer], list) {\n\t\tif (tmp_entry->index == index) {\n\t\t\tentry = tmp_entry;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (unlikely(!entry)) {\n\t\tmlx4_warn(dev, \"Steering entry for index %x is not registered\\n\", index);\n\t\treturn false;\n\t}\n\tlist_for_each_entry_safe(dqp, tmp_dqp, &entry->duplicates, list) {\n\t\tif (dqp->qpn == qpn) {\n\t\t\tlist_del(&dqp->list);\n\t\t\tkfree(dqp);\n\t\t}\n\t}\n\treturn true;\n}\n\n \nstatic bool promisc_steering_entry(struct mlx4_dev *dev, u8 port,\n\t\t\t\t   enum mlx4_steer_type steer,\n\t\t\t\t   unsigned int index, u32 tqpn,\n\t\t\t\t   u32 *members_count)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm;\n\tu32 m_count;\n\tbool ret = false;\n\tint i;\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn false;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn false;\n\tmgm = mailbox->buf;\n\n\tif (mlx4_READ_ENTRY(dev, index, mailbox))\n\t\tgoto out;\n\tm_count = be32_to_cpu(mgm->members_count) & 0xffffff;\n\tif (members_count)\n\t\t*members_count = m_count;\n\n\tfor (i = 0;  i < m_count; i++) {\n\t\tu32 qpn = be32_to_cpu(mgm->qp[i]) & MGM_QPN_MASK;\n\t\tif (!get_promisc_qp(dev, port, steer, qpn) && qpn != tqpn) {\n\t\t\t \n\t\t\tgoto out;\n\t\t}\n\t}\n\tret = true;\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn ret;\n}\n\n \nstatic bool can_remove_steering_entry(struct mlx4_dev *dev, u8 port,\n\t\t\t\t      enum mlx4_steer_type steer,\n\t\t\t\t      unsigned int index, u32 tqpn)\n{\n\tstruct mlx4_steer *s_steer;\n\tstruct mlx4_steer_index *entry = NULL, *tmp_entry;\n\tu32 members_count;\n\tbool ret = false;\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn false;\n\n\ts_steer = &mlx4_priv(dev)->steer[port - 1];\n\n\tif (!promisc_steering_entry(dev, port, steer, index,\n\t\t\t\t    tqpn, &members_count))\n\t\tgoto out;\n\n\t \n\tret = true;\n\tlist_for_each_entry_safe(entry, tmp_entry, &s_steer->steer_entries[steer], list) {\n\t\tif (entry->index == index) {\n\t\t\tif (list_empty(&entry->duplicates) ||\n\t\t\t    members_count == 1) {\n\t\t\t\tstruct mlx4_promisc_qp *pqp, *tmp_pqp;\n\t\t\t\t \n\t\t\t\tlist_del(&entry->list);\n\t\t\t\tlist_for_each_entry_safe(pqp, tmp_pqp,\n\t\t\t\t\t\t\t &entry->duplicates,\n\t\t\t\t\t\t\t list) {\n\t\t\t\t\tlist_del(&pqp->list);\n\t\t\t\t\tkfree(pqp);\n\t\t\t\t}\n\t\t\t\tkfree(entry);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tret = false;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}\n\nstatic int add_promisc_qp(struct mlx4_dev *dev, u8 port,\n\t\t\t  enum mlx4_steer_type steer, u32 qpn)\n{\n\tstruct mlx4_steer *s_steer;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm;\n\tstruct mlx4_steer_index *entry;\n\tstruct mlx4_promisc_qp *pqp;\n\tstruct mlx4_promisc_qp *dqp;\n\tu32 members_count;\n\tu32 prot;\n\tint i;\n\tbool found;\n\tint err;\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn -EINVAL;\n\n\ts_steer = &mlx4_priv(dev)->steer[port - 1];\n\n\tmutex_lock(&priv->mcg_table.mutex);\n\n\tif (get_promisc_qp(dev, port, steer, qpn)) {\n\t\terr = 0;   \n\t\tgoto out_mutex;\n\t}\n\n\tpqp = kmalloc(sizeof(*pqp), GFP_KERNEL);\n\tif (!pqp) {\n\t\terr = -ENOMEM;\n\t\tgoto out_mutex;\n\t}\n\tpqp->qpn = qpn;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\terr = -ENOMEM;\n\t\tgoto out_alloc;\n\t}\n\tmgm = mailbox->buf;\n\n\tif (!(mlx4_is_mfunc(dev) && steer == MLX4_UC_STEER)) {\n\t\t \n\t\tlist_for_each_entry(entry,\n\t\t\t\t    &s_steer->steer_entries[steer],\n\t\t\t\t    list) {\n\t\t\terr = mlx4_READ_ENTRY(dev, entry->index, mailbox);\n\t\t\tif (err)\n\t\t\t\tgoto out_mailbox;\n\n\t\t\tmembers_count = be32_to_cpu(mgm->members_count) &\n\t\t\t\t\t0xffffff;\n\t\t\tprot = be32_to_cpu(mgm->members_count) >> 30;\n\t\t\tfound = false;\n\t\t\tfor (i = 0; i < members_count; i++) {\n\t\t\t\tif ((be32_to_cpu(mgm->qp[i]) &\n\t\t\t\t     MGM_QPN_MASK) == qpn) {\n\t\t\t\t\t \n\t\t\t\t\tdqp = kmalloc(sizeof(*dqp), GFP_KERNEL);\n\t\t\t\t\tif (!dqp) {\n\t\t\t\t\t\terr = -ENOMEM;\n\t\t\t\t\t\tgoto out_mailbox;\n\t\t\t\t\t}\n\t\t\t\t\tdqp->qpn = qpn;\n\t\t\t\t\tlist_add_tail(&dqp->list,\n\t\t\t\t\t\t      &entry->duplicates);\n\t\t\t\t\tfound = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!found) {\n\t\t\t\t \n\t\t\t\tif (members_count ==\n\t\t\t\t    dev->caps.num_qp_per_mgm) {\n\t\t\t\t\t \n\t\t\t\t\terr = -ENOMEM;\n\t\t\t\t\tgoto out_mailbox;\n\t\t\t\t}\n\t\t\t\tmgm->qp[members_count++] =\n\t\t\t\t\tcpu_to_be32(qpn & MGM_QPN_MASK);\n\t\t\t\tmgm->members_count =\n\t\t\t\t\tcpu_to_be32(members_count |\n\t\t\t\t\t\t    (prot << 30));\n\t\t\t\terr = mlx4_WRITE_ENTRY(dev, entry->index,\n\t\t\t\t\t\t       mailbox);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto out_mailbox;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tlist_add_tail(&pqp->list, &s_steer->promisc_qps[steer]);\n\t \n\tmemset(mgm, 0, sizeof(*mgm));\n\tmembers_count = 0;\n\tlist_for_each_entry(dqp, &s_steer->promisc_qps[steer], list) {\n\t\tif (members_count == dev->caps.num_qp_per_mgm) {\n\t\t\t \n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_list;\n\t\t}\n\t\tmgm->qp[members_count++] = cpu_to_be32(dqp->qpn & MGM_QPN_MASK);\n\t}\n\tmgm->members_count = cpu_to_be32(members_count | MLX4_PROT_ETH << 30);\n\n\terr = mlx4_WRITE_PROMISC(dev, port, steer, mailbox);\n\tif (err)\n\t\tgoto out_list;\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\tmutex_unlock(&priv->mcg_table.mutex);\n\treturn 0;\n\nout_list:\n\tlist_del(&pqp->list);\nout_mailbox:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\nout_alloc:\n\tkfree(pqp);\nout_mutex:\n\tmutex_unlock(&priv->mcg_table.mutex);\n\treturn err;\n}\n\nstatic int remove_promisc_qp(struct mlx4_dev *dev, u8 port,\n\t\t\t     enum mlx4_steer_type steer, u32 qpn)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tstruct mlx4_steer *s_steer;\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm;\n\tstruct mlx4_steer_index *entry, *tmp_entry;\n\tstruct mlx4_promisc_qp *pqp;\n\tstruct mlx4_promisc_qp *dqp;\n\tu32 members_count;\n\tbool found;\n\tbool back_to_list = false;\n\tint i;\n\tint err;\n\n\tif (port < 1 || port > dev->caps.num_ports)\n\t\treturn -EINVAL;\n\n\ts_steer = &mlx4_priv(dev)->steer[port - 1];\n\tmutex_lock(&priv->mcg_table.mutex);\n\n\tpqp = get_promisc_qp(dev, port, steer, qpn);\n\tif (unlikely(!pqp)) {\n\t\tmlx4_warn(dev, \"QP %x is not promiscuous QP\\n\", qpn);\n\t\t \n\t\terr = 0;\n\t\tgoto out_mutex;\n\t}\n\n\t \n\tlist_del(&pqp->list);\n\n\t \n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\terr = -ENOMEM;\n\t\tback_to_list = true;\n\t\tgoto out_list;\n\t}\n\tmgm = mailbox->buf;\n\tmembers_count = 0;\n\tlist_for_each_entry(dqp, &s_steer->promisc_qps[steer], list)\n\t\tmgm->qp[members_count++] = cpu_to_be32(dqp->qpn & MGM_QPN_MASK);\n\tmgm->members_count = cpu_to_be32(members_count | MLX4_PROT_ETH << 30);\n\n\terr = mlx4_WRITE_PROMISC(dev, port, steer, mailbox);\n\tif (err)\n\t\tgoto out_mailbox;\n\n\tif (!(mlx4_is_mfunc(dev) && steer == MLX4_UC_STEER)) {\n\t\t \n\t\tlist_for_each_entry_safe(entry, tmp_entry,\n\t\t\t\t\t &s_steer->steer_entries[steer],\n\t\t\t\t\t list) {\n\t\t\tfound = false;\n\t\t\tlist_for_each_entry(dqp, &entry->duplicates, list) {\n\t\t\t\tif (dqp->qpn == qpn) {\n\t\t\t\t\tfound = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (found) {\n\t\t\t\t \n\t\t\t\tlist_del(&dqp->list);\n\t\t\t\tkfree(dqp);\n\t\t\t} else {\n\t\t\t\tint loc = -1;\n\n\t\t\t\terr = mlx4_READ_ENTRY(dev,\n\t\t\t\t\t\t      entry->index,\n\t\t\t\t\t\t      mailbox);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto out_mailbox;\n\t\t\t\tmembers_count =\n\t\t\t\t\tbe32_to_cpu(mgm->members_count) &\n\t\t\t\t\t0xffffff;\n\t\t\t\tif (!members_count) {\n\t\t\t\t\tmlx4_warn(dev, \"QP %06x wasn't found in entry %x mcount=0. deleting entry...\\n\",\n\t\t\t\t\t\t  qpn, entry->index);\n\t\t\t\t\tlist_del(&entry->list);\n\t\t\t\t\tkfree(entry);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tfor (i = 0; i < members_count; ++i)\n\t\t\t\t\tif ((be32_to_cpu(mgm->qp[i]) &\n\t\t\t\t\t     MGM_QPN_MASK) == qpn) {\n\t\t\t\t\t\tloc = i;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\n\t\t\t\tif (loc < 0) {\n\t\t\t\t\tmlx4_err(dev, \"QP %06x wasn't found in entry %d\\n\",\n\t\t\t\t\t\t qpn, entry->index);\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out_mailbox;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tmgm->qp[loc] = mgm->qp[members_count - 1];\n\t\t\t\tmgm->qp[members_count - 1] = 0;\n\t\t\t\tmgm->members_count =\n\t\t\t\t\tcpu_to_be32(--members_count |\n\t\t\t\t\t\t    (MLX4_PROT_ETH << 30));\n\n\t\t\t\terr = mlx4_WRITE_ENTRY(dev,\n\t\t\t\t\t\t       entry->index,\n\t\t\t\t\t\t       mailbox);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto out_mailbox;\n\t\t\t}\n\t\t}\n\t}\n\nout_mailbox:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\nout_list:\n\tif (back_to_list)\n\t\tlist_add_tail(&pqp->list, &s_steer->promisc_qps[steer]);\n\telse\n\t\tkfree(pqp);\nout_mutex:\n\tmutex_unlock(&priv->mcg_table.mutex);\n\treturn err;\n}\n\n \nstatic int find_entry(struct mlx4_dev *dev, u8 port,\n\t\t      u8 *gid, enum mlx4_protocol prot,\n\t\t      struct mlx4_cmd_mailbox *mgm_mailbox,\n\t\t      int *prev, int *index)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm = mgm_mailbox->buf;\n\tu8 *mgid;\n\tint err;\n\tu16 hash;\n\tu8 op_mod = (prot == MLX4_PROT_ETH) ?\n\t\t!!(dev->caps.flags & MLX4_DEV_CAP_FLAG_VEP_MC_STEER) : 0;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn -ENOMEM;\n\tmgid = mailbox->buf;\n\n\tmemcpy(mgid, gid, 16);\n\n\terr = mlx4_GID_HASH(dev, mailbox, &hash, op_mod);\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\tif (err)\n\t\treturn err;\n\n\tif (0)\n\t\tmlx4_dbg(dev, \"Hash for %pI6 is %04x\\n\", gid, hash);\n\n\t*index = hash;\n\t*prev  = -1;\n\n\tdo {\n\t\terr = mlx4_READ_ENTRY(dev, *index, mgm_mailbox);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (!(be32_to_cpu(mgm->members_count) & 0xffffff)) {\n\t\t\tif (*index != hash) {\n\t\t\t\tmlx4_err(dev, \"Found zero MGID in AMGM\\n\");\n\t\t\t\terr = -EINVAL;\n\t\t\t}\n\t\t\treturn err;\n\t\t}\n\n\t\tif (!memcmp(mgm->gid, gid, 16) &&\n\t\t    be32_to_cpu(mgm->members_count) >> 30 == prot)\n\t\t\treturn err;\n\n\t\t*prev = *index;\n\t\t*index = be32_to_cpu(mgm->next_gid_index) >> 6;\n\t} while (*index);\n\n\t*index = -1;\n\treturn err;\n}\n\nstatic const u8 __promisc_mode[] = {\n\t[MLX4_FS_REGULAR]   = 0x0,\n\t[MLX4_FS_ALL_DEFAULT] = 0x1,\n\t[MLX4_FS_MC_DEFAULT] = 0x3,\n\t[MLX4_FS_MIRROR_RX_PORT] = 0x4,\n\t[MLX4_FS_MIRROR_SX_PORT] = 0x5,\n\t[MLX4_FS_UC_SNIFFER] = 0x6,\n\t[MLX4_FS_MC_SNIFFER] = 0x7,\n};\n\nint mlx4_map_sw_to_hw_steering_mode(struct mlx4_dev *dev,\n\t\t\t\t    enum mlx4_net_trans_promisc_mode flow_type)\n{\n\tif (flow_type >= MLX4_FS_MODE_NUM) {\n\t\tmlx4_err(dev, \"Invalid flow type. type = %d\\n\", flow_type);\n\t\treturn -EINVAL;\n\t}\n\treturn __promisc_mode[flow_type];\n}\nEXPORT_SYMBOL_GPL(mlx4_map_sw_to_hw_steering_mode);\n\nstatic void trans_rule_ctrl_to_hw(struct mlx4_net_trans_rule *ctrl,\n\t\t\t\t  struct mlx4_net_trans_rule_hw_ctrl *hw)\n{\n\tu8 flags = 0;\n\n\tflags = ctrl->queue_mode == MLX4_NET_TRANS_Q_LIFO ? 1 : 0;\n\tflags |= ctrl->exclusive ? (1 << 2) : 0;\n\tflags |= ctrl->allow_loopback ? (1 << 3) : 0;\n\n\thw->flags = flags;\n\thw->type = __promisc_mode[ctrl->promisc_mode];\n\thw->prio = cpu_to_be16(ctrl->priority);\n\thw->port = ctrl->port;\n\thw->qpn = cpu_to_be32(ctrl->qpn);\n}\n\nconst u16 __sw_id_hw[] = {\n\t[MLX4_NET_TRANS_RULE_ID_ETH]     = 0xE001,\n\t[MLX4_NET_TRANS_RULE_ID_IB]      = 0xE005,\n\t[MLX4_NET_TRANS_RULE_ID_IPV6]    = 0xE003,\n\t[MLX4_NET_TRANS_RULE_ID_IPV4]    = 0xE002,\n\t[MLX4_NET_TRANS_RULE_ID_TCP]     = 0xE004,\n\t[MLX4_NET_TRANS_RULE_ID_UDP]     = 0xE006,\n\t[MLX4_NET_TRANS_RULE_ID_VXLAN]\t = 0xE008\n};\n\nint mlx4_map_sw_to_hw_steering_id(struct mlx4_dev *dev,\n\t\t\t\t  enum mlx4_net_trans_rule_id id)\n{\n\tif (id >= MLX4_NET_TRANS_RULE_NUM) {\n\t\tmlx4_err(dev, \"Invalid network rule id. id = %d\\n\", id);\n\t\treturn -EINVAL;\n\t}\n\treturn __sw_id_hw[id];\n}\nEXPORT_SYMBOL_GPL(mlx4_map_sw_to_hw_steering_id);\n\nstatic const int __rule_hw_sz[] = {\n\t[MLX4_NET_TRANS_RULE_ID_ETH] =\n\t\tsizeof(struct mlx4_net_trans_rule_hw_eth),\n\t[MLX4_NET_TRANS_RULE_ID_IB] =\n\t\tsizeof(struct mlx4_net_trans_rule_hw_ib),\n\t[MLX4_NET_TRANS_RULE_ID_IPV6] = 0,\n\t[MLX4_NET_TRANS_RULE_ID_IPV4] =\n\t\tsizeof(struct mlx4_net_trans_rule_hw_ipv4),\n\t[MLX4_NET_TRANS_RULE_ID_TCP] =\n\t\tsizeof(struct mlx4_net_trans_rule_hw_tcp_udp),\n\t[MLX4_NET_TRANS_RULE_ID_UDP] =\n\t\tsizeof(struct mlx4_net_trans_rule_hw_tcp_udp),\n\t[MLX4_NET_TRANS_RULE_ID_VXLAN] =\n\t\tsizeof(struct mlx4_net_trans_rule_hw_vxlan)\n};\n\nint mlx4_hw_rule_sz(struct mlx4_dev *dev,\n\t       enum mlx4_net_trans_rule_id id)\n{\n\tif (id >= MLX4_NET_TRANS_RULE_NUM) {\n\t\tmlx4_err(dev, \"Invalid network rule id. id = %d\\n\", id);\n\t\treturn -EINVAL;\n\t}\n\n\treturn __rule_hw_sz[id];\n}\nEXPORT_SYMBOL_GPL(mlx4_hw_rule_sz);\n\nstatic int parse_trans_rule(struct mlx4_dev *dev, struct mlx4_spec_list *spec,\n\t\t\t    struct _rule_hw *rule_hw)\n{\n\tif (mlx4_hw_rule_sz(dev, spec->id) < 0)\n\t\treturn -EINVAL;\n\tmemset(rule_hw, 0, mlx4_hw_rule_sz(dev, spec->id));\n\trule_hw->id = cpu_to_be16(__sw_id_hw[spec->id]);\n\trule_hw->size = mlx4_hw_rule_sz(dev, spec->id) >> 2;\n\n\tswitch (spec->id) {\n\tcase MLX4_NET_TRANS_RULE_ID_ETH:\n\t\tmemcpy(rule_hw->eth.dst_mac, spec->eth.dst_mac, ETH_ALEN);\n\t\tmemcpy(rule_hw->eth.dst_mac_msk, spec->eth.dst_mac_msk,\n\t\t       ETH_ALEN);\n\t\tmemcpy(rule_hw->eth.src_mac, spec->eth.src_mac, ETH_ALEN);\n\t\tmemcpy(rule_hw->eth.src_mac_msk, spec->eth.src_mac_msk,\n\t\t       ETH_ALEN);\n\t\tif (spec->eth.ether_type_enable) {\n\t\t\trule_hw->eth.ether_type_enable = 1;\n\t\t\trule_hw->eth.ether_type = spec->eth.ether_type;\n\t\t}\n\t\trule_hw->eth.vlan_tag = spec->eth.vlan_id;\n\t\trule_hw->eth.vlan_tag_msk = spec->eth.vlan_id_msk;\n\t\tbreak;\n\n\tcase MLX4_NET_TRANS_RULE_ID_IB:\n\t\trule_hw->ib.l3_qpn = spec->ib.l3_qpn;\n\t\trule_hw->ib.qpn_mask = spec->ib.qpn_msk;\n\t\tmemcpy(&rule_hw->ib.dst_gid, &spec->ib.dst_gid, 16);\n\t\tmemcpy(&rule_hw->ib.dst_gid_msk, &spec->ib.dst_gid_msk, 16);\n\t\tbreak;\n\n\tcase MLX4_NET_TRANS_RULE_ID_IPV6:\n\t\treturn -EOPNOTSUPP;\n\n\tcase MLX4_NET_TRANS_RULE_ID_IPV4:\n\t\trule_hw->ipv4.src_ip = spec->ipv4.src_ip;\n\t\trule_hw->ipv4.src_ip_msk = spec->ipv4.src_ip_msk;\n\t\trule_hw->ipv4.dst_ip = spec->ipv4.dst_ip;\n\t\trule_hw->ipv4.dst_ip_msk = spec->ipv4.dst_ip_msk;\n\t\tbreak;\n\n\tcase MLX4_NET_TRANS_RULE_ID_TCP:\n\tcase MLX4_NET_TRANS_RULE_ID_UDP:\n\t\trule_hw->tcp_udp.dst_port = spec->tcp_udp.dst_port;\n\t\trule_hw->tcp_udp.dst_port_msk = spec->tcp_udp.dst_port_msk;\n\t\trule_hw->tcp_udp.src_port = spec->tcp_udp.src_port;\n\t\trule_hw->tcp_udp.src_port_msk = spec->tcp_udp.src_port_msk;\n\t\tbreak;\n\n\tcase MLX4_NET_TRANS_RULE_ID_VXLAN:\n\t\trule_hw->vxlan.vni =\n\t\t\tcpu_to_be32(be32_to_cpu(spec->vxlan.vni) << 8);\n\t\trule_hw->vxlan.vni_mask =\n\t\t\tcpu_to_be32(be32_to_cpu(spec->vxlan.vni_mask) << 8);\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn __rule_hw_sz[spec->id];\n}\n\nstatic void mlx4_err_rule(struct mlx4_dev *dev, char *str,\n\t\t\t  struct mlx4_net_trans_rule *rule)\n{\n#define BUF_SIZE 256\n\tstruct mlx4_spec_list *cur;\n\tchar buf[BUF_SIZE];\n\tint len = 0;\n\n\tmlx4_err(dev, \"%s\", str);\n\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t \"port = %d prio = 0x%x qp = 0x%x \",\n\t\t\t rule->port, rule->priority, rule->qpn);\n\n\tlist_for_each_entry(cur, &rule->list, list) {\n\t\tswitch (cur->id) {\n\t\tcase MLX4_NET_TRANS_RULE_ID_ETH:\n\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t \"dmac = %pM \", &cur->eth.dst_mac);\n\t\t\tif (cur->eth.ether_type)\n\t\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t\t \"ethertype = 0x%x \",\n\t\t\t\t\t\t be16_to_cpu(cur->eth.ether_type));\n\t\t\tif (cur->eth.vlan_id)\n\t\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t\t \"vlan-id = %d \",\n\t\t\t\t\t\t be16_to_cpu(cur->eth.vlan_id));\n\t\t\tbreak;\n\n\t\tcase MLX4_NET_TRANS_RULE_ID_IPV4:\n\t\t\tif (cur->ipv4.src_ip)\n\t\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t\t \"src-ip = %pI4 \",\n\t\t\t\t\t\t &cur->ipv4.src_ip);\n\t\t\tif (cur->ipv4.dst_ip)\n\t\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t\t \"dst-ip = %pI4 \",\n\t\t\t\t\t\t &cur->ipv4.dst_ip);\n\t\t\tbreak;\n\n\t\tcase MLX4_NET_TRANS_RULE_ID_TCP:\n\t\tcase MLX4_NET_TRANS_RULE_ID_UDP:\n\t\t\tif (cur->tcp_udp.src_port)\n\t\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t\t \"src-port = %d \",\n\t\t\t\t\t\t be16_to_cpu(cur->tcp_udp.src_port));\n\t\t\tif (cur->tcp_udp.dst_port)\n\t\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t\t \"dst-port = %d \",\n\t\t\t\t\t\t be16_to_cpu(cur->tcp_udp.dst_port));\n\t\t\tbreak;\n\n\t\tcase MLX4_NET_TRANS_RULE_ID_IB:\n\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t \"dst-gid = %pI6\\n\", cur->ib.dst_gid);\n\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t \"dst-gid-mask = %pI6\\n\",\n\t\t\t\t\t cur->ib.dst_gid_msk);\n\t\t\tbreak;\n\n\t\tcase MLX4_NET_TRANS_RULE_ID_VXLAN:\n\t\t\tlen += scnprintf(buf + len, BUF_SIZE - len,\n\t\t\t\t\t \"VNID = %d \", be32_to_cpu(cur->vxlan.vni));\n\t\t\tbreak;\n\t\tcase MLX4_NET_TRANS_RULE_ID_IPV6:\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tlen += scnprintf(buf + len, BUF_SIZE - len, \"\\n\");\n\tmlx4_err(dev, \"%s\", buf);\n\n\tif (len >= BUF_SIZE)\n\t\tmlx4_err(dev, \"Network rule error message was truncated, print buffer is too small\\n\");\n}\n\nint mlx4_flow_attach(struct mlx4_dev *dev,\n\t\t     struct mlx4_net_trans_rule *rule, u64 *reg_id)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_spec_list *cur;\n\tu32 size = 0;\n\tint ret;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\tif (!mlx4_qp_lookup(dev, rule->qpn)) {\n\t\tmlx4_err_rule(dev, \"QP doesn't exist\\n\", rule);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\ttrans_rule_ctrl_to_hw(rule, mailbox->buf);\n\n\tsize += sizeof(struct mlx4_net_trans_rule_hw_ctrl);\n\n\tlist_for_each_entry(cur, &rule->list, list) {\n\t\tret = parse_trans_rule(dev, cur, mailbox->buf + size);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tsize += ret;\n\t}\n\n\tret = mlx4_QP_FLOW_STEERING_ATTACH(dev, mailbox, size >> 2, reg_id);\n\tif (ret == -ENOMEM) {\n\t\tmlx4_err_rule(dev,\n\t\t\t      \"mcg table is full. Fail to register network rule\\n\",\n\t\t\t      rule);\n\t} else if (ret) {\n\t\tif (ret == -ENXIO) {\n\t\t\tif (dev->caps.steering_mode != MLX4_STEERING_MODE_DEVICE_MANAGED)\n\t\t\t\tmlx4_err_rule(dev,\n\t\t\t\t\t      \"DMFS is not enabled, \"\n\t\t\t\t\t      \"failed to register network rule.\\n\",\n\t\t\t\t\t      rule);\n\t\t\telse\n\t\t\t\tmlx4_err_rule(dev,\n\t\t\t\t\t      \"Rule exceeds the dmfs_high_rate_mode limitations, \"\n\t\t\t\t\t      \"failed to register network rule.\\n\",\n\t\t\t\t\t      rule);\n\n\t\t} else {\n\t\t\tmlx4_err_rule(dev, \"Fail to register network rule.\\n\", rule);\n\t\t}\n\t}\n\nout:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mlx4_flow_attach);\n\nint mlx4_flow_detach(struct mlx4_dev *dev, u64 reg_id)\n{\n\tint err;\n\n\terr = mlx4_QP_FLOW_STEERING_DETACH(dev, reg_id);\n\tif (err)\n\t\tmlx4_err(dev, \"Fail to detach network rule. registration id = 0x%llx\\n\",\n\t\t\t reg_id);\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_flow_detach);\n\nint mlx4_tunnel_steer_add(struct mlx4_dev *dev, const unsigned char *addr,\n\t\t\t  int port, int qpn, u16 prio, u64 *reg_id)\n{\n\tint err;\n\tstruct mlx4_spec_list spec_eth_outer = { {NULL} };\n\tstruct mlx4_spec_list spec_vxlan     = { {NULL} };\n\tstruct mlx4_spec_list spec_eth_inner = { {NULL} };\n\n\tstruct mlx4_net_trans_rule rule = {\n\t\t.queue_mode = MLX4_NET_TRANS_Q_FIFO,\n\t\t.exclusive = 0,\n\t\t.allow_loopback = 1,\n\t\t.promisc_mode = MLX4_FS_REGULAR,\n\t};\n\n\t__be64 mac_mask = cpu_to_be64(MLX4_MAC_MASK << 16);\n\n\trule.port = port;\n\trule.qpn = qpn;\n\trule.priority = prio;\n\tINIT_LIST_HEAD(&rule.list);\n\n\tspec_eth_outer.id = MLX4_NET_TRANS_RULE_ID_ETH;\n\tmemcpy(spec_eth_outer.eth.dst_mac, addr, ETH_ALEN);\n\tmemcpy(spec_eth_outer.eth.dst_mac_msk, &mac_mask, ETH_ALEN);\n\n\tspec_vxlan.id = MLX4_NET_TRANS_RULE_ID_VXLAN;     \n\tspec_eth_inner.id = MLX4_NET_TRANS_RULE_ID_ETH;\t  \n\n\tlist_add_tail(&spec_eth_outer.list, &rule.list);\n\tlist_add_tail(&spec_vxlan.list,     &rule.list);\n\tlist_add_tail(&spec_eth_inner.list, &rule.list);\n\n\terr = mlx4_flow_attach(dev, &rule, reg_id);\n\treturn err;\n}\nEXPORT_SYMBOL(mlx4_tunnel_steer_add);\n\nint mlx4_FLOW_STEERING_IB_UC_QP_RANGE(struct mlx4_dev *dev, u32 min_range_qpn,\n\t\t\t\t      u32 max_range_qpn)\n{\n\tint err;\n\tu64 in_param;\n\n\tin_param = ((u64) min_range_qpn) << 32;\n\tin_param |= ((u64) max_range_qpn) & 0xFFFFFFFF;\n\n\terr = mlx4_cmd(dev, in_param, 0, 0,\n\t\t\tMLX4_FLOW_STEERING_IB_UC_QP_RANGE,\n\t\t\tMLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_FLOW_STEERING_IB_UC_QP_RANGE);\n\nint mlx4_qp_attach_common(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],\n\t\t\t  int block_mcast_loopback, enum mlx4_protocol prot,\n\t\t\t  enum mlx4_steer_type steer)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm;\n\tu32 members_count;\n\tint index = -1, prev;\n\tint link = 0;\n\tint i;\n\tint err;\n\tu8 port = gid[5];\n\tu8 new_entry = 0;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\tmgm = mailbox->buf;\n\n\tmutex_lock(&priv->mcg_table.mutex);\n\terr = find_entry(dev, port, gid, prot,\n\t\t\t mailbox, &prev, &index);\n\tif (err)\n\t\tgoto out;\n\n\tif (index != -1) {\n\t\tif (!(be32_to_cpu(mgm->members_count) & 0xffffff)) {\n\t\t\tnew_entry = 1;\n\t\t\tmemcpy(mgm->gid, gid, 16);\n\t\t}\n\t} else {\n\t\tlink = 1;\n\n\t\tindex = mlx4_bitmap_alloc(&priv->mcg_table.bitmap);\n\t\tif (index == -1) {\n\t\t\tmlx4_err(dev, \"No AMGM entries left\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tindex += dev->caps.num_mgms;\n\n\t\tnew_entry = 1;\n\t\tmemset(mgm, 0, sizeof(*mgm));\n\t\tmemcpy(mgm->gid, gid, 16);\n\t}\n\n\tmembers_count = be32_to_cpu(mgm->members_count) & 0xffffff;\n\tif (members_count == dev->caps.num_qp_per_mgm) {\n\t\tmlx4_err(dev, \"MGM at index %x is full\\n\", index);\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < members_count; ++i)\n\t\tif ((be32_to_cpu(mgm->qp[i]) & MGM_QPN_MASK) == qp->qpn) {\n\t\t\tmlx4_dbg(dev, \"QP %06x already a member of MGM\\n\", qp->qpn);\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\n\tif (block_mcast_loopback)\n\t\tmgm->qp[members_count++] = cpu_to_be32((qp->qpn & MGM_QPN_MASK) |\n\t\t\t\t\t\t       (1U << MGM_BLCK_LB_BIT));\n\telse\n\t\tmgm->qp[members_count++] = cpu_to_be32(qp->qpn & MGM_QPN_MASK);\n\n\tmgm->members_count = cpu_to_be32(members_count | (u32) prot << 30);\n\n\terr = mlx4_WRITE_ENTRY(dev, index, mailbox);\n\tif (err)\n\t\tgoto out;\n\n\tif (!link)\n\t\tgoto out;\n\n\terr = mlx4_READ_ENTRY(dev, prev, mailbox);\n\tif (err)\n\t\tgoto out;\n\n\tmgm->next_gid_index = cpu_to_be32(index << 6);\n\n\terr = mlx4_WRITE_ENTRY(dev, prev, mailbox);\n\tif (err)\n\t\tgoto out;\n\nout:\n\tif (prot == MLX4_PROT_ETH && index != -1) {\n\t\t \n\t\tif (new_entry)\n\t\t\terr = new_steering_entry(dev, port, steer,\n\t\t\t\t\t\t index, qp->qpn);\n\t\telse\n\t\t\terr = existing_steering_entry(dev, port, steer,\n\t\t\t\t\t\t      index, qp->qpn);\n\t}\n\tif (err && link && index != -1) {\n\t\tif (index < dev->caps.num_mgms)\n\t\t\tmlx4_warn(dev, \"Got AMGM index %d < %d\\n\",\n\t\t\t\t  index, dev->caps.num_mgms);\n\t\telse\n\t\t\tmlx4_bitmap_free(&priv->mcg_table.bitmap,\n\t\t\t\t\t index - dev->caps.num_mgms, MLX4_USE_RR);\n\t}\n\tmutex_unlock(&priv->mcg_table.mutex);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\n\nint mlx4_qp_detach_common(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],\n\t\t\t  enum mlx4_protocol prot, enum mlx4_steer_type steer)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mgm *mgm;\n\tu32 members_count;\n\tint prev, index;\n\tint i, loc = -1;\n\tint err;\n\tu8 port = gid[5];\n\tbool removed_entry = false;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\tmgm = mailbox->buf;\n\n\tmutex_lock(&priv->mcg_table.mutex);\n\n\terr = find_entry(dev, port, gid, prot,\n\t\t\t mailbox, &prev, &index);\n\tif (err)\n\t\tgoto out;\n\n\tif (index == -1) {\n\t\tmlx4_err(dev, \"MGID %pI6 not found\\n\", gid);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t \n\tif (prot == MLX4_PROT_ETH &&\n\t    check_duplicate_entry(dev, port, steer, index, qp->qpn) &&\n\t    !promisc_steering_entry(dev, port, steer, index, qp->qpn, NULL))\n\t\t\tgoto out;\n\n\tmembers_count = be32_to_cpu(mgm->members_count) & 0xffffff;\n\tfor (i = 0; i < members_count; ++i)\n\t\tif ((be32_to_cpu(mgm->qp[i]) & MGM_QPN_MASK) == qp->qpn) {\n\t\t\tloc = i;\n\t\t\tbreak;\n\t\t}\n\n\tif (loc == -1) {\n\t\tmlx4_err(dev, \"QP %06x not found in MGM\\n\", qp->qpn);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t \n\tmgm->qp[loc] = mgm->qp[members_count - 1];\n\tmgm->qp[members_count - 1] = 0;\n\tmgm->members_count = cpu_to_be32(--members_count | (u32) prot << 30);\n\n\tif (prot == MLX4_PROT_ETH)\n\t\tremoved_entry = can_remove_steering_entry(dev, port, steer,\n\t\t\t\t\t\t\t\tindex, qp->qpn);\n\tif (members_count && (prot != MLX4_PROT_ETH || !removed_entry)) {\n\t\terr = mlx4_WRITE_ENTRY(dev, index, mailbox);\n\t\tgoto out;\n\t}\n\n\t \n\tmgm->members_count = cpu_to_be32((u32) prot << 30);\n\n\tif (prev == -1) {\n\t\t \n\t\tint amgm_index = be32_to_cpu(mgm->next_gid_index) >> 6;\n\t\tif (amgm_index) {\n\t\t\terr = mlx4_READ_ENTRY(dev, amgm_index, mailbox);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t} else\n\t\t\tmemset(mgm->gid, 0, 16);\n\n\t\terr = mlx4_WRITE_ENTRY(dev, index, mailbox);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tif (amgm_index) {\n\t\t\tif (amgm_index < dev->caps.num_mgms)\n\t\t\t\tmlx4_warn(dev, \"MGM entry %d had AMGM index %d < %d\\n\",\n\t\t\t\t\t  index, amgm_index, dev->caps.num_mgms);\n\t\t\telse\n\t\t\t\tmlx4_bitmap_free(&priv->mcg_table.bitmap,\n\t\t\t\t\t\t amgm_index - dev->caps.num_mgms, MLX4_USE_RR);\n\t\t}\n\t} else {\n\t\t \n\t\tint cur_next_index = be32_to_cpu(mgm->next_gid_index) >> 6;\n\t\terr = mlx4_READ_ENTRY(dev, prev, mailbox);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tmgm->next_gid_index = cpu_to_be32(cur_next_index << 6);\n\n\t\terr = mlx4_WRITE_ENTRY(dev, prev, mailbox);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tif (index < dev->caps.num_mgms)\n\t\t\tmlx4_warn(dev, \"entry %d had next AMGM index %d < %d\\n\",\n\t\t\t\t  prev, index, dev->caps.num_mgms);\n\t\telse\n\t\t\tmlx4_bitmap_free(&priv->mcg_table.bitmap,\n\t\t\t\t\t index - dev->caps.num_mgms, MLX4_USE_RR);\n\t}\n\nout:\n\tmutex_unlock(&priv->mcg_table.mutex);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\tif (err && dev->persist->state & MLX4_DEVICE_STATE_INTERNAL_ERROR)\n\t\t \n\t\terr = 0;\n\treturn err;\n}\n\nstatic int mlx4_QP_ATTACH(struct mlx4_dev *dev, struct mlx4_qp *qp,\n\t\t\t  u8 gid[16], u8 attach, u8 block_loopback,\n\t\t\t  enum mlx4_protocol prot)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tint err = 0;\n\tint qpn;\n\n\tif (!mlx4_is_mfunc(dev))\n\t\treturn -EBADF;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox))\n\t\treturn PTR_ERR(mailbox);\n\n\tmemcpy(mailbox->buf, gid, 16);\n\tqpn = qp->qpn;\n\tqpn |= (prot << 28);\n\tif (attach && block_loopback)\n\t\tqpn |= (1 << 31);\n\n\terr = mlx4_cmd(dev, mailbox->dma, qpn, attach,\n\t\t       MLX4_CMD_QP_ATTACH, MLX4_CMD_TIME_CLASS_A,\n\t\t       MLX4_CMD_WRAPPED);\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\tif (err && !attach &&\n\t    dev->persist->state & MLX4_DEVICE_STATE_INTERNAL_ERROR)\n\t\terr = 0;\n\treturn err;\n}\n\nint mlx4_trans_to_dmfs_attach(struct mlx4_dev *dev, struct mlx4_qp *qp,\n\t\t\t      u8 gid[16], u8 port,\n\t\t\t      int block_mcast_loopback,\n\t\t\t      enum mlx4_protocol prot, u64 *reg_id)\n{\n\t\tstruct mlx4_spec_list spec = { {NULL} };\n\t\t__be64 mac_mask = cpu_to_be64(MLX4_MAC_MASK << 16);\n\n\t\tstruct mlx4_net_trans_rule rule = {\n\t\t\t.queue_mode = MLX4_NET_TRANS_Q_FIFO,\n\t\t\t.exclusive = 0,\n\t\t\t.promisc_mode = MLX4_FS_REGULAR,\n\t\t\t.priority = MLX4_DOMAIN_NIC,\n\t\t};\n\n\t\trule.allow_loopback = !block_mcast_loopback;\n\t\trule.port = port;\n\t\trule.qpn = qp->qpn;\n\t\tINIT_LIST_HEAD(&rule.list);\n\n\t\tswitch (prot) {\n\t\tcase MLX4_PROT_ETH:\n\t\t\tspec.id = MLX4_NET_TRANS_RULE_ID_ETH;\n\t\t\tmemcpy(spec.eth.dst_mac, &gid[10], ETH_ALEN);\n\t\t\tmemcpy(spec.eth.dst_mac_msk, &mac_mask, ETH_ALEN);\n\t\t\tbreak;\n\n\t\tcase MLX4_PROT_IB_IPV6:\n\t\t\tspec.id = MLX4_NET_TRANS_RULE_ID_IB;\n\t\t\tmemcpy(spec.ib.dst_gid, gid, 16);\n\t\t\tmemset(&spec.ib.dst_gid_msk, 0xff, 16);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tlist_add_tail(&spec.list, &rule.list);\n\n\t\treturn mlx4_flow_attach(dev, &rule, reg_id);\n}\n\nint mlx4_multicast_attach(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],\n\t\t\t  u8 port, int block_mcast_loopback,\n\t\t\t  enum mlx4_protocol prot, u64 *reg_id)\n{\n\tswitch (dev->caps.steering_mode) {\n\tcase MLX4_STEERING_MODE_A0:\n\t\tif (prot == MLX4_PROT_ETH)\n\t\t\treturn 0;\n\t\tfallthrough;\n\n\tcase MLX4_STEERING_MODE_B0:\n\t\tif (prot == MLX4_PROT_ETH)\n\t\t\tgid[7] |= (MLX4_MC_STEER << 1);\n\n\t\tif (mlx4_is_mfunc(dev))\n\t\t\treturn mlx4_QP_ATTACH(dev, qp, gid, 1,\n\t\t\t\t\t      block_mcast_loopback, prot);\n\t\treturn mlx4_qp_attach_common(dev, qp, gid,\n\t\t\t\t\t     block_mcast_loopback, prot,\n\t\t\t\t\t     MLX4_MC_STEER);\n\n\tcase MLX4_STEERING_MODE_DEVICE_MANAGED:\n\t\treturn mlx4_trans_to_dmfs_attach(dev, qp, gid, port,\n\t\t\t\t\t\t block_mcast_loopback,\n\t\t\t\t\t\t prot, reg_id);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\nEXPORT_SYMBOL_GPL(mlx4_multicast_attach);\n\nint mlx4_multicast_detach(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],\n\t\t\t  enum mlx4_protocol prot, u64 reg_id)\n{\n\tswitch (dev->caps.steering_mode) {\n\tcase MLX4_STEERING_MODE_A0:\n\t\tif (prot == MLX4_PROT_ETH)\n\t\t\treturn 0;\n\t\tfallthrough;\n\n\tcase MLX4_STEERING_MODE_B0:\n\t\tif (prot == MLX4_PROT_ETH)\n\t\t\tgid[7] |= (MLX4_MC_STEER << 1);\n\n\t\tif (mlx4_is_mfunc(dev))\n\t\t\treturn mlx4_QP_ATTACH(dev, qp, gid, 0, 0, prot);\n\n\t\treturn mlx4_qp_detach_common(dev, qp, gid, prot,\n\t\t\t\t\t     MLX4_MC_STEER);\n\n\tcase MLX4_STEERING_MODE_DEVICE_MANAGED:\n\t\treturn mlx4_flow_detach(dev, reg_id);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\nEXPORT_SYMBOL_GPL(mlx4_multicast_detach);\n\nint mlx4_flow_steer_promisc_add(struct mlx4_dev *dev, u8 port,\n\t\t\t\tu32 qpn, enum mlx4_net_trans_promisc_mode mode)\n{\n\tstruct mlx4_net_trans_rule rule = {\n\t\t.queue_mode = MLX4_NET_TRANS_Q_FIFO,\n\t\t.exclusive = 0,\n\t\t.allow_loopback = 1,\n\t};\n\n\tu64 *regid_p;\n\n\tswitch (mode) {\n\tcase MLX4_FS_ALL_DEFAULT:\n\t\tregid_p = &dev->regid_promisc_array[port];\n\t\tbreak;\n\tcase MLX4_FS_MC_DEFAULT:\n\t\tregid_p = &dev->regid_allmulti_array[port];\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\tif (*regid_p != 0)\n\t\treturn -1;\n\n\trule.promisc_mode = mode;\n\trule.port = port;\n\trule.qpn = qpn;\n\tINIT_LIST_HEAD(&rule.list);\n\tmlx4_info(dev, \"going promisc on %x\\n\", port);\n\n\treturn  mlx4_flow_attach(dev, &rule, regid_p);\n}\nEXPORT_SYMBOL_GPL(mlx4_flow_steer_promisc_add);\n\nint mlx4_flow_steer_promisc_remove(struct mlx4_dev *dev, u8 port,\n\t\t\t\t   enum mlx4_net_trans_promisc_mode mode)\n{\n\tint ret;\n\tu64 *regid_p;\n\n\tswitch (mode) {\n\tcase MLX4_FS_ALL_DEFAULT:\n\t\tregid_p = &dev->regid_promisc_array[port];\n\t\tbreak;\n\tcase MLX4_FS_MC_DEFAULT:\n\t\tregid_p = &dev->regid_allmulti_array[port];\n\t\tbreak;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\tif (*regid_p == 0)\n\t\treturn -1;\n\n\tret =  mlx4_flow_detach(dev, *regid_p);\n\tif (ret == 0)\n\t\t*regid_p = 0;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mlx4_flow_steer_promisc_remove);\n\nint mlx4_unicast_attach(struct mlx4_dev *dev,\n\t\t\tstruct mlx4_qp *qp, u8 gid[16],\n\t\t\tint block_mcast_loopback, enum mlx4_protocol prot)\n{\n\tif (prot == MLX4_PROT_ETH)\n\t\tgid[7] |= (MLX4_UC_STEER << 1);\n\n\tif (mlx4_is_mfunc(dev))\n\t\treturn mlx4_QP_ATTACH(dev, qp, gid, 1,\n\t\t\t\t\tblock_mcast_loopback, prot);\n\n\treturn mlx4_qp_attach_common(dev, qp, gid, block_mcast_loopback,\n\t\t\t\t\tprot, MLX4_UC_STEER);\n}\nEXPORT_SYMBOL_GPL(mlx4_unicast_attach);\n\nint mlx4_unicast_detach(struct mlx4_dev *dev, struct mlx4_qp *qp,\n\t\t\t       u8 gid[16], enum mlx4_protocol prot)\n{\n\tif (prot == MLX4_PROT_ETH)\n\t\tgid[7] |= (MLX4_UC_STEER << 1);\n\n\tif (mlx4_is_mfunc(dev))\n\t\treturn mlx4_QP_ATTACH(dev, qp, gid, 0, 0, prot);\n\n\treturn mlx4_qp_detach_common(dev, qp, gid, prot, MLX4_UC_STEER);\n}\nEXPORT_SYMBOL_GPL(mlx4_unicast_detach);\n\nint mlx4_PROMISC_wrapper(struct mlx4_dev *dev, int slave,\n\t\t\t struct mlx4_vhcr *vhcr,\n\t\t\t struct mlx4_cmd_mailbox *inbox,\n\t\t\t struct mlx4_cmd_mailbox *outbox,\n\t\t\t struct mlx4_cmd_info *cmd)\n{\n\tu32 qpn = (u32) vhcr->in_param & 0xffffffff;\n\tint port = mlx4_slave_convert_port(dev, slave, vhcr->in_param >> 62);\n\tenum mlx4_steer_type steer = vhcr->in_modifier;\n\n\tif (port < 0)\n\t\treturn -EINVAL;\n\n\t \n\tif (mlx4_is_mfunc(dev) && steer == MLX4_UC_STEER)\n\t\treturn 0;\n\n\tif (vhcr->op_modifier)\n\t\treturn add_promisc_qp(dev, port, steer, qpn);\n\telse\n\t\treturn remove_promisc_qp(dev, port, steer, qpn);\n}\n\nstatic int mlx4_PROMISC(struct mlx4_dev *dev, u32 qpn,\n\t\t\tenum mlx4_steer_type steer, u8 add, u8 port)\n{\n\treturn mlx4_cmd(dev, (u64) qpn | (u64) port << 62, (u32) steer, add,\n\t\t\tMLX4_CMD_PROMISC, MLX4_CMD_TIME_CLASS_A,\n\t\t\tMLX4_CMD_WRAPPED);\n}\n\nint mlx4_multicast_promisc_add(struct mlx4_dev *dev, u32 qpn, u8 port)\n{\n\tif (mlx4_is_mfunc(dev))\n\t\treturn mlx4_PROMISC(dev, qpn, MLX4_MC_STEER, 1, port);\n\n\treturn add_promisc_qp(dev, port, MLX4_MC_STEER, qpn);\n}\nEXPORT_SYMBOL_GPL(mlx4_multicast_promisc_add);\n\nint mlx4_multicast_promisc_remove(struct mlx4_dev *dev, u32 qpn, u8 port)\n{\n\tif (mlx4_is_mfunc(dev))\n\t\treturn mlx4_PROMISC(dev, qpn, MLX4_MC_STEER, 0, port);\n\n\treturn remove_promisc_qp(dev, port, MLX4_MC_STEER, qpn);\n}\nEXPORT_SYMBOL_GPL(mlx4_multicast_promisc_remove);\n\nint mlx4_unicast_promisc_add(struct mlx4_dev *dev, u32 qpn, u8 port)\n{\n\tif (mlx4_is_mfunc(dev))\n\t\treturn mlx4_PROMISC(dev, qpn, MLX4_UC_STEER, 1, port);\n\n\treturn add_promisc_qp(dev, port, MLX4_UC_STEER, qpn);\n}\nEXPORT_SYMBOL_GPL(mlx4_unicast_promisc_add);\n\nint mlx4_unicast_promisc_remove(struct mlx4_dev *dev, u32 qpn, u8 port)\n{\n\tif (mlx4_is_mfunc(dev))\n\t\treturn mlx4_PROMISC(dev, qpn, MLX4_UC_STEER, 0, port);\n\n\treturn remove_promisc_qp(dev, port, MLX4_UC_STEER, qpn);\n}\nEXPORT_SYMBOL_GPL(mlx4_unicast_promisc_remove);\n\nint mlx4_init_mcg_table(struct mlx4_dev *dev)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tint err;\n\n\t \n\tif (dev->caps.steering_mode ==\n\t    MLX4_STEERING_MODE_DEVICE_MANAGED)\n\t\treturn 0;\n\terr = mlx4_bitmap_init(&priv->mcg_table.bitmap, dev->caps.num_amgms,\n\t\t\t       dev->caps.num_amgms - 1, 0, 0);\n\tif (err)\n\t\treturn err;\n\n\tmutex_init(&priv->mcg_table.mutex);\n\n\treturn 0;\n}\n\nvoid mlx4_cleanup_mcg_table(struct mlx4_dev *dev)\n{\n\tif (dev->caps.steering_mode !=\n\t    MLX4_STEERING_MODE_DEVICE_MANAGED)\n\t\tmlx4_bitmap_cleanup(&mlx4_priv(dev)->mcg_table.bitmap);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}