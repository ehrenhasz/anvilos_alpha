{
  "module_name": "mr.c",
  "hash_id": "1146e265bf1ce614337a4ad802126ff3f55cc23cc01ecc496a0ca44c81a15d29",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx4/mr.c",
  "human_readable_source": " \n\n#include <linux/errno.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/vmalloc.h>\n\n#include <linux/mlx4/cmd.h>\n\n#include \"mlx4.h\"\n#include \"icm.h\"\n\nstatic u32 mlx4_buddy_alloc(struct mlx4_buddy *buddy, int order)\n{\n\tint o;\n\tint m;\n\tu32 seg;\n\n\tspin_lock(&buddy->lock);\n\n\tfor (o = order; o <= buddy->max_order; ++o)\n\t\tif (buddy->num_free[o]) {\n\t\t\tm = 1 << (buddy->max_order - o);\n\t\t\tseg = find_first_bit(buddy->bits[o], m);\n\t\t\tif (seg < m)\n\t\t\t\tgoto found;\n\t\t}\n\n\tspin_unlock(&buddy->lock);\n\treturn -1;\n\n found:\n\tclear_bit(seg, buddy->bits[o]);\n\t--buddy->num_free[o];\n\n\twhile (o > order) {\n\t\t--o;\n\t\tseg <<= 1;\n\t\tset_bit(seg ^ 1, buddy->bits[o]);\n\t\t++buddy->num_free[o];\n\t}\n\n\tspin_unlock(&buddy->lock);\n\n\tseg <<= order;\n\n\treturn seg;\n}\n\nstatic void mlx4_buddy_free(struct mlx4_buddy *buddy, u32 seg, int order)\n{\n\tseg >>= order;\n\n\tspin_lock(&buddy->lock);\n\n\twhile (test_bit(seg ^ 1, buddy->bits[order])) {\n\t\tclear_bit(seg ^ 1, buddy->bits[order]);\n\t\t--buddy->num_free[order];\n\t\tseg >>= 1;\n\t\t++order;\n\t}\n\n\tset_bit(seg, buddy->bits[order]);\n\t++buddy->num_free[order];\n\n\tspin_unlock(&buddy->lock);\n}\n\nstatic int mlx4_buddy_init(struct mlx4_buddy *buddy, int max_order)\n{\n\tint i, s;\n\n\tbuddy->max_order = max_order;\n\tspin_lock_init(&buddy->lock);\n\n\tbuddy->bits = kcalloc(buddy->max_order + 1, sizeof(long *),\n\t\t\t      GFP_KERNEL);\n\tbuddy->num_free = kcalloc(buddy->max_order + 1, sizeof(*buddy->num_free),\n\t\t\t\t  GFP_KERNEL);\n\tif (!buddy->bits || !buddy->num_free)\n\t\tgoto err_out;\n\n\tfor (i = 0; i <= buddy->max_order; ++i) {\n\t\ts = BITS_TO_LONGS(1UL << (buddy->max_order - i));\n\t\tbuddy->bits[i] = kvmalloc_array(s, sizeof(long), GFP_KERNEL | __GFP_ZERO);\n\t\tif (!buddy->bits[i])\n\t\t\tgoto err_out_free;\n\t}\n\n\tset_bit(0, buddy->bits[buddy->max_order]);\n\tbuddy->num_free[buddy->max_order] = 1;\n\n\treturn 0;\n\nerr_out_free:\n\tfor (i = 0; i <= buddy->max_order; ++i)\n\t\tkvfree(buddy->bits[i]);\n\nerr_out:\n\tkfree(buddy->bits);\n\tkfree(buddy->num_free);\n\n\treturn -ENOMEM;\n}\n\nstatic void mlx4_buddy_cleanup(struct mlx4_buddy *buddy)\n{\n\tint i;\n\n\tfor (i = 0; i <= buddy->max_order; ++i)\n\t\tkvfree(buddy->bits[i]);\n\n\tkfree(buddy->bits);\n\tkfree(buddy->num_free);\n}\n\nu32 __mlx4_alloc_mtt_range(struct mlx4_dev *dev, int order)\n{\n\tstruct mlx4_mr_table *mr_table = &mlx4_priv(dev)->mr_table;\n\tu32 seg;\n\tint seg_order;\n\tu32 offset;\n\n\tseg_order = max_t(int, order - log_mtts_per_seg, 0);\n\n\tseg = mlx4_buddy_alloc(&mr_table->mtt_buddy, seg_order);\n\tif (seg == -1)\n\t\treturn -1;\n\n\toffset = seg * (1 << log_mtts_per_seg);\n\n\tif (mlx4_table_get_range(dev, &mr_table->mtt_table, offset,\n\t\t\t\t offset + (1 << order) - 1)) {\n\t\tmlx4_buddy_free(&mr_table->mtt_buddy, seg, seg_order);\n\t\treturn -1;\n\t}\n\n\treturn offset;\n}\n\nstatic u32 mlx4_alloc_mtt_range(struct mlx4_dev *dev, int order)\n{\n\tu64 in_param = 0;\n\tu64 out_param;\n\tint err;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tset_param_l(&in_param, order);\n\t\terr = mlx4_cmd_imm(dev, in_param, &out_param, RES_MTT,\n\t\t\t\t\t\t       RES_OP_RESERVE_AND_MAP,\n\t\t\t\t\t\t       MLX4_CMD_ALLOC_RES,\n\t\t\t\t\t\t       MLX4_CMD_TIME_CLASS_A,\n\t\t\t\t\t\t       MLX4_CMD_WRAPPED);\n\t\tif (err)\n\t\t\treturn -1;\n\t\treturn get_param_l(&out_param);\n\t}\n\treturn __mlx4_alloc_mtt_range(dev, order);\n}\n\nint mlx4_mtt_init(struct mlx4_dev *dev, int npages, int page_shift,\n\t\t  struct mlx4_mtt *mtt)\n{\n\tint i;\n\n\tif (!npages) {\n\t\tmtt->order      = -1;\n\t\tmtt->page_shift = MLX4_ICM_PAGE_SHIFT;\n\t\treturn 0;\n\t} else\n\t\tmtt->page_shift = page_shift;\n\n\tfor (mtt->order = 0, i = 1; i < npages; i <<= 1)\n\t\t++mtt->order;\n\n\tmtt->offset = mlx4_alloc_mtt_range(dev, mtt->order);\n\tif (mtt->offset == -1)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mlx4_mtt_init);\n\nvoid __mlx4_free_mtt_range(struct mlx4_dev *dev, u32 offset, int order)\n{\n\tu32 first_seg;\n\tint seg_order;\n\tstruct mlx4_mr_table *mr_table = &mlx4_priv(dev)->mr_table;\n\n\tseg_order = max_t(int, order - log_mtts_per_seg, 0);\n\tfirst_seg = offset / (1 << log_mtts_per_seg);\n\n\tmlx4_buddy_free(&mr_table->mtt_buddy, first_seg, seg_order);\n\tmlx4_table_put_range(dev, &mr_table->mtt_table, offset,\n\t\t\t     offset + (1 << order) - 1);\n}\n\nstatic void mlx4_free_mtt_range(struct mlx4_dev *dev, u32 offset, int order)\n{\n\tu64 in_param = 0;\n\tint err;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tset_param_l(&in_param, offset);\n\t\tset_param_h(&in_param, order);\n\t\terr = mlx4_cmd(dev, in_param, RES_MTT, RES_OP_RESERVE_AND_MAP,\n\t\t\t\t\t\t       MLX4_CMD_FREE_RES,\n\t\t\t\t\t\t       MLX4_CMD_TIME_CLASS_A,\n\t\t\t\t\t\t       MLX4_CMD_WRAPPED);\n\t\tif (err)\n\t\t\tmlx4_warn(dev, \"Failed to free mtt range at:%d order:%d\\n\",\n\t\t\t\t  offset, order);\n\t\treturn;\n\t}\n\t__mlx4_free_mtt_range(dev, offset, order);\n}\n\nvoid mlx4_mtt_cleanup(struct mlx4_dev *dev, struct mlx4_mtt *mtt)\n{\n\tif (mtt->order < 0)\n\t\treturn;\n\n\tmlx4_free_mtt_range(dev, mtt->offset, mtt->order);\n}\nEXPORT_SYMBOL_GPL(mlx4_mtt_cleanup);\n\nu64 mlx4_mtt_addr(struct mlx4_dev *dev, struct mlx4_mtt *mtt)\n{\n\treturn (u64) mtt->offset * dev->caps.mtt_entry_sz;\n}\nEXPORT_SYMBOL_GPL(mlx4_mtt_addr);\n\nstatic u32 hw_index_to_key(u32 ind)\n{\n\treturn (ind >> 24) | (ind << 8);\n}\n\nstatic u32 key_to_hw_index(u32 key)\n{\n\treturn (key << 24) | (key >> 8);\n}\n\nstatic int mlx4_SW2HW_MPT(struct mlx4_dev *dev, struct mlx4_cmd_mailbox *mailbox,\n\t\t\t  int mpt_index)\n{\n\treturn mlx4_cmd(dev, mailbox->dma, mpt_index,\n\t\t\t0, MLX4_CMD_SW2HW_MPT, MLX4_CMD_TIME_CLASS_B,\n\t\t\tMLX4_CMD_WRAPPED);\n}\n\nstatic int mlx4_HW2SW_MPT(struct mlx4_dev *dev, struct mlx4_cmd_mailbox *mailbox,\n\t\t\t  int mpt_index)\n{\n\treturn mlx4_cmd_box(dev, 0, mailbox ? mailbox->dma : 0, mpt_index,\n\t\t\t    !mailbox, MLX4_CMD_HW2SW_MPT,\n\t\t\t    MLX4_CMD_TIME_CLASS_B, MLX4_CMD_WRAPPED);\n}\n\n \nint mlx4_mr_hw_get_mpt(struct mlx4_dev *dev, struct mlx4_mr *mmr,\n\t\t       struct mlx4_mpt_entry ***mpt_entry)\n{\n\tint err;\n\tint key = key_to_hw_index(mmr->key) & (dev->caps.num_mpts - 1);\n\tstruct mlx4_cmd_mailbox *mailbox = NULL;\n\n\tif (mmr->enabled != MLX4_MPT_EN_HW)\n\t\treturn -EINVAL;\n\n\terr = mlx4_HW2SW_MPT(dev, NULL, key);\n\tif (err) {\n\t\tmlx4_warn(dev, \"HW2SW_MPT failed (%d).\", err);\n\t\tmlx4_warn(dev, \"Most likely the MR has MWs bound to it.\\n\");\n\t\treturn err;\n\t}\n\n\tmmr->enabled = MLX4_MPT_EN_SW;\n\n\tif (!mlx4_is_mfunc(dev)) {\n\t\t**mpt_entry = mlx4_table_find(\n\t\t\t\t&mlx4_priv(dev)->mr_table.dmpt_table,\n\t\t\t\tkey, NULL);\n\t} else {\n\t\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\t\tif (IS_ERR(mailbox))\n\t\t\treturn PTR_ERR(mailbox);\n\n\t\terr = mlx4_cmd_box(dev, 0, mailbox->dma, key,\n\t\t\t\t   0, MLX4_CMD_QUERY_MPT,\n\t\t\t\t   MLX4_CMD_TIME_CLASS_B,\n\t\t\t\t   MLX4_CMD_WRAPPED);\n\t\tif (err)\n\t\t\tgoto free_mailbox;\n\n\t\t*mpt_entry = (struct mlx4_mpt_entry **)&mailbox->buf;\n\t}\n\n\tif (!(*mpt_entry) || !(**mpt_entry)) {\n\t\terr = -ENOMEM;\n\t\tgoto free_mailbox;\n\t}\n\n\treturn 0;\n\nfree_mailbox:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_hw_get_mpt);\n\nint mlx4_mr_hw_write_mpt(struct mlx4_dev *dev, struct mlx4_mr *mmr,\n\t\t\t struct mlx4_mpt_entry **mpt_entry)\n{\n\tint err;\n\n\tif (!mlx4_is_mfunc(dev)) {\n\t\t \n\t\twmb();\n\n\t\t*(u8 *)(*mpt_entry) = MLX4_MPT_STATUS_HW;\n\n\t\t \n\t\twmb();\n\n\t\terr = mlx4_SYNC_TPT(dev);\n\t} else {\n\t\tint key = key_to_hw_index(mmr->key) & (dev->caps.num_mpts - 1);\n\n\t\tstruct mlx4_cmd_mailbox *mailbox =\n\t\t\tcontainer_of((void *)mpt_entry, struct mlx4_cmd_mailbox,\n\t\t\t\t     buf);\n\n\t\t(*mpt_entry)->lkey = 0;\n\t\terr = mlx4_SW2HW_MPT(dev, mailbox, key);\n\t}\n\n\tif (!err) {\n\t\tmmr->pd = be32_to_cpu((*mpt_entry)->pd_flags) & MLX4_MPT_PD_MASK;\n\t\tmmr->enabled = MLX4_MPT_EN_HW;\n\t}\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_hw_write_mpt);\n\nvoid mlx4_mr_hw_put_mpt(struct mlx4_dev *dev,\n\t\t\tstruct mlx4_mpt_entry **mpt_entry)\n{\n\tif (mlx4_is_mfunc(dev)) {\n\t\tstruct mlx4_cmd_mailbox *mailbox =\n\t\t\tcontainer_of((void *)mpt_entry, struct mlx4_cmd_mailbox,\n\t\t\t\t     buf);\n\t\tmlx4_free_cmd_mailbox(dev, mailbox);\n\t}\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_hw_put_mpt);\n\nint mlx4_mr_hw_change_pd(struct mlx4_dev *dev, struct mlx4_mpt_entry *mpt_entry,\n\t\t\t u32 pdn)\n{\n\tu32 pd_flags = be32_to_cpu(mpt_entry->pd_flags) & ~MLX4_MPT_PD_MASK;\n\t \n\tif (mlx4_is_mfunc(dev))\n\t\tpd_flags &= ~MLX4_MPT_PD_VF_MASK;\n\n\tmpt_entry->pd_flags = cpu_to_be32(pd_flags |\n\t\t\t\t\t  (pdn & MLX4_MPT_PD_MASK)\n\t\t\t\t\t  | MLX4_MPT_PD_FLAG_EN_INV);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_hw_change_pd);\n\nint mlx4_mr_hw_change_access(struct mlx4_dev *dev,\n\t\t\t     struct mlx4_mpt_entry *mpt_entry,\n\t\t\t     u32 access)\n{\n\tu32 flags = (be32_to_cpu(mpt_entry->flags) & ~MLX4_PERM_MASK) |\n\t\t    (access & MLX4_PERM_MASK);\n\n\tmpt_entry->flags = cpu_to_be32(flags);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_hw_change_access);\n\nstatic int mlx4_mr_alloc_reserved(struct mlx4_dev *dev, u32 mridx, u32 pd,\n\t\t\t   u64 iova, u64 size, u32 access, int npages,\n\t\t\t   int page_shift, struct mlx4_mr *mr)\n{\n\tmr->iova       = iova;\n\tmr->size       = size;\n\tmr->pd\t       = pd;\n\tmr->access     = access;\n\tmr->enabled    = MLX4_MPT_DISABLED;\n\tmr->key\t       = hw_index_to_key(mridx);\n\n\treturn mlx4_mtt_init(dev, npages, page_shift, &mr->mtt);\n}\n\nstatic int mlx4_WRITE_MTT(struct mlx4_dev *dev,\n\t\t\t  struct mlx4_cmd_mailbox *mailbox,\n\t\t\t  int num_entries)\n{\n\treturn mlx4_cmd(dev, mailbox->dma, num_entries, 0, MLX4_CMD_WRITE_MTT,\n\t\t\tMLX4_CMD_TIME_CLASS_A,  MLX4_CMD_WRAPPED);\n}\n\nint __mlx4_mpt_reserve(struct mlx4_dev *dev)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\n\treturn mlx4_bitmap_alloc(&priv->mr_table.mpt_bitmap);\n}\n\nstatic int mlx4_mpt_reserve(struct mlx4_dev *dev)\n{\n\tu64 out_param;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tif (mlx4_cmd_imm(dev, 0, &out_param, RES_MPT, RES_OP_RESERVE,\n\t\t\t\t   MLX4_CMD_ALLOC_RES,\n\t\t\t\t   MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED))\n\t\t\treturn -1;\n\t\treturn get_param_l(&out_param);\n\t}\n\treturn  __mlx4_mpt_reserve(dev);\n}\n\nvoid __mlx4_mpt_release(struct mlx4_dev *dev, u32 index)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\n\tmlx4_bitmap_free(&priv->mr_table.mpt_bitmap, index, MLX4_NO_RR);\n}\n\nstatic void mlx4_mpt_release(struct mlx4_dev *dev, u32 index)\n{\n\tu64 in_param = 0;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tset_param_l(&in_param, index);\n\t\tif (mlx4_cmd(dev, in_param, RES_MPT, RES_OP_RESERVE,\n\t\t\t       MLX4_CMD_FREE_RES,\n\t\t\t       MLX4_CMD_TIME_CLASS_A, MLX4_CMD_WRAPPED))\n\t\t\tmlx4_warn(dev, \"Failed to release mr index:%d\\n\",\n\t\t\t\t  index);\n\t\treturn;\n\t}\n\t__mlx4_mpt_release(dev, index);\n}\n\nint __mlx4_mpt_alloc_icm(struct mlx4_dev *dev, u32 index)\n{\n\tstruct mlx4_mr_table *mr_table = &mlx4_priv(dev)->mr_table;\n\n\treturn mlx4_table_get(dev, &mr_table->dmpt_table, index);\n}\n\nstatic int mlx4_mpt_alloc_icm(struct mlx4_dev *dev, u32 index)\n{\n\tu64 param = 0;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tset_param_l(&param, index);\n\t\treturn mlx4_cmd_imm(dev, param, &param, RES_MPT, RES_OP_MAP_ICM,\n\t\t\t\t\t\t\tMLX4_CMD_ALLOC_RES,\n\t\t\t\t\t\t\tMLX4_CMD_TIME_CLASS_A,\n\t\t\t\t\t\t\tMLX4_CMD_WRAPPED);\n\t}\n\treturn __mlx4_mpt_alloc_icm(dev, index);\n}\n\nvoid __mlx4_mpt_free_icm(struct mlx4_dev *dev, u32 index)\n{\n\tstruct mlx4_mr_table *mr_table = &mlx4_priv(dev)->mr_table;\n\n\tmlx4_table_put(dev, &mr_table->dmpt_table, index);\n}\n\nstatic void mlx4_mpt_free_icm(struct mlx4_dev *dev, u32 index)\n{\n\tu64 in_param = 0;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tset_param_l(&in_param, index);\n\t\tif (mlx4_cmd(dev, in_param, RES_MPT, RES_OP_MAP_ICM,\n\t\t\t     MLX4_CMD_FREE_RES, MLX4_CMD_TIME_CLASS_A,\n\t\t\t     MLX4_CMD_WRAPPED))\n\t\t\tmlx4_warn(dev, \"Failed to free icm of mr index:%d\\n\",\n\t\t\t\t  index);\n\t\treturn;\n\t}\n\treturn __mlx4_mpt_free_icm(dev, index);\n}\n\nint mlx4_mr_alloc(struct mlx4_dev *dev, u32 pd, u64 iova, u64 size, u32 access,\n\t\t  int npages, int page_shift, struct mlx4_mr *mr)\n{\n\tu32 index;\n\tint err;\n\n\tindex = mlx4_mpt_reserve(dev);\n\tif (index == -1)\n\t\treturn -ENOMEM;\n\n\terr = mlx4_mr_alloc_reserved(dev, index, pd, iova, size,\n\t\t\t\t     access, npages, page_shift, mr);\n\tif (err)\n\t\tmlx4_mpt_release(dev, index);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_alloc);\n\nstatic int mlx4_mr_free_reserved(struct mlx4_dev *dev, struct mlx4_mr *mr)\n{\n\tint err;\n\n\tif (mr->enabled == MLX4_MPT_EN_HW) {\n\t\terr = mlx4_HW2SW_MPT(dev, NULL,\n\t\t\t\t     key_to_hw_index(mr->key) &\n\t\t\t\t     (dev->caps.num_mpts - 1));\n\t\tif (err) {\n\t\t\tmlx4_warn(dev, \"HW2SW_MPT failed (%d), MR has MWs bound to it\\n\",\n\t\t\t\t  err);\n\t\t\treturn err;\n\t\t}\n\n\t\tmr->enabled = MLX4_MPT_EN_SW;\n\t}\n\tmlx4_mtt_cleanup(dev, &mr->mtt);\n\n\treturn 0;\n}\n\nint mlx4_mr_free(struct mlx4_dev *dev, struct mlx4_mr *mr)\n{\n\tint ret;\n\n\tret = mlx4_mr_free_reserved(dev, mr);\n\tif (ret)\n\t\treturn ret;\n\tif (mr->enabled)\n\t\tmlx4_mpt_free_icm(dev, key_to_hw_index(mr->key));\n\tmlx4_mpt_release(dev, key_to_hw_index(mr->key));\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_free);\n\nvoid mlx4_mr_rereg_mem_cleanup(struct mlx4_dev *dev, struct mlx4_mr *mr)\n{\n\tmlx4_mtt_cleanup(dev, &mr->mtt);\n\tmr->mtt.order = -1;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_rereg_mem_cleanup);\n\nint mlx4_mr_rereg_mem_write(struct mlx4_dev *dev, struct mlx4_mr *mr,\n\t\t\t    u64 iova, u64 size, int npages,\n\t\t\t    int page_shift, struct mlx4_mpt_entry *mpt_entry)\n{\n\tint err;\n\n\terr = mlx4_mtt_init(dev, npages, page_shift, &mr->mtt);\n\tif (err)\n\t\treturn err;\n\n\tmpt_entry->start       = cpu_to_be64(iova);\n\tmpt_entry->length      = cpu_to_be64(size);\n\tmpt_entry->entity_size = cpu_to_be32(page_shift);\n\tmpt_entry->flags    &= ~(cpu_to_be32(MLX4_MPT_FLAG_FREE |\n\t\t\t\t\t   MLX4_MPT_FLAG_SW_OWNS));\n\tif (mr->mtt.order < 0) {\n\t\tmpt_entry->flags |= cpu_to_be32(MLX4_MPT_FLAG_PHYSICAL);\n\t\tmpt_entry->mtt_addr = 0;\n\t} else {\n\t\tmpt_entry->mtt_addr = cpu_to_be64(mlx4_mtt_addr(dev,\n\t\t\t\t\t\t  &mr->mtt));\n\t\tif (mr->mtt.page_shift == 0)\n\t\t\tmpt_entry->mtt_sz    = cpu_to_be32(1 << mr->mtt.order);\n\t}\n\tif (mr->mtt.order >= 0 && mr->mtt.page_shift == 0) {\n\t\t \n\t\tmpt_entry->flags    |= cpu_to_be32(MLX4_MPT_FLAG_FREE);\n\t\tmpt_entry->pd_flags |= cpu_to_be32(MLX4_MPT_PD_FLAG_FAST_REG |\n\t\t\t\t\t\t   MLX4_MPT_PD_FLAG_RAE);\n\t} else {\n\t\tmpt_entry->flags    |= cpu_to_be32(MLX4_MPT_FLAG_SW_OWNS);\n\t}\n\tmr->enabled = MLX4_MPT_EN_SW;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_rereg_mem_write);\n\nint mlx4_mr_enable(struct mlx4_dev *dev, struct mlx4_mr *mr)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mpt_entry *mpt_entry;\n\tint err;\n\n\terr = mlx4_mpt_alloc_icm(dev, key_to_hw_index(mr->key));\n\tif (err)\n\t\treturn err;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\terr = PTR_ERR(mailbox);\n\t\tgoto err_table;\n\t}\n\tmpt_entry = mailbox->buf;\n\tmpt_entry->flags = cpu_to_be32(MLX4_MPT_FLAG_MIO\t |\n\t\t\t\t       MLX4_MPT_FLAG_REGION\t |\n\t\t\t\t       mr->access);\n\n\tmpt_entry->key\t       = cpu_to_be32(key_to_hw_index(mr->key));\n\tmpt_entry->pd_flags    = cpu_to_be32(mr->pd | MLX4_MPT_PD_FLAG_EN_INV);\n\tmpt_entry->start       = cpu_to_be64(mr->iova);\n\tmpt_entry->length      = cpu_to_be64(mr->size);\n\tmpt_entry->entity_size = cpu_to_be32(mr->mtt.page_shift);\n\n\tif (mr->mtt.order < 0) {\n\t\tmpt_entry->flags |= cpu_to_be32(MLX4_MPT_FLAG_PHYSICAL);\n\t\tmpt_entry->mtt_addr = 0;\n\t} else {\n\t\tmpt_entry->mtt_addr = cpu_to_be64(mlx4_mtt_addr(dev,\n\t\t\t\t\t\t  &mr->mtt));\n\t}\n\n\tif (mr->mtt.order >= 0 && mr->mtt.page_shift == 0) {\n\t\t \n\t\tmpt_entry->flags    |= cpu_to_be32(MLX4_MPT_FLAG_FREE);\n\t\tmpt_entry->pd_flags |= cpu_to_be32(MLX4_MPT_PD_FLAG_FAST_REG |\n\t\t\t\t\t\t   MLX4_MPT_PD_FLAG_RAE);\n\t\tmpt_entry->mtt_sz    = cpu_to_be32(1 << mr->mtt.order);\n\t} else {\n\t\tmpt_entry->flags    |= cpu_to_be32(MLX4_MPT_FLAG_SW_OWNS);\n\t}\n\n\terr = mlx4_SW2HW_MPT(dev, mailbox,\n\t\t\t     key_to_hw_index(mr->key) & (dev->caps.num_mpts - 1));\n\tif (err) {\n\t\tmlx4_warn(dev, \"SW2HW_MPT failed (%d)\\n\", err);\n\t\tgoto err_cmd;\n\t}\n\tmr->enabled = MLX4_MPT_EN_HW;\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\n\treturn 0;\n\nerr_cmd:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\nerr_table:\n\tmlx4_mpt_free_icm(dev, key_to_hw_index(mr->key));\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_mr_enable);\n\nstatic int mlx4_write_mtt_chunk(struct mlx4_dev *dev, struct mlx4_mtt *mtt,\n\t\t\t\tint start_index, int npages, u64 *page_list)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\t__be64 *mtts;\n\tdma_addr_t dma_handle;\n\tint i;\n\n\tmtts = mlx4_table_find(&priv->mr_table.mtt_table, mtt->offset +\n\t\t\t       start_index, &dma_handle);\n\n\tif (!mtts)\n\t\treturn -ENOMEM;\n\n\tdma_sync_single_for_cpu(&dev->persist->pdev->dev, dma_handle,\n\t\t\t\tnpages * sizeof(u64), DMA_TO_DEVICE);\n\n\tfor (i = 0; i < npages; ++i)\n\t\tmtts[i] = cpu_to_be64(page_list[i] | MLX4_MTT_FLAG_PRESENT);\n\n\tdma_sync_single_for_device(&dev->persist->pdev->dev, dma_handle,\n\t\t\t\t   npages * sizeof(u64), DMA_TO_DEVICE);\n\n\treturn 0;\n}\n\nint __mlx4_write_mtt(struct mlx4_dev *dev, struct mlx4_mtt *mtt,\n\t\t     int start_index, int npages, u64 *page_list)\n{\n\tint err = 0;\n\tint chunk;\n\tint mtts_per_page;\n\tint max_mtts_first_page;\n\n\t \n\tmtts_per_page = PAGE_SIZE / sizeof(u64);\n\tmax_mtts_first_page = mtts_per_page - (mtt->offset + start_index)\n\t\t\t      % mtts_per_page;\n\n\tchunk = min_t(int, max_mtts_first_page, npages);\n\n\twhile (npages > 0) {\n\t\terr = mlx4_write_mtt_chunk(dev, mtt, start_index, chunk, page_list);\n\t\tif (err)\n\t\t\treturn err;\n\t\tnpages      -= chunk;\n\t\tstart_index += chunk;\n\t\tpage_list   += chunk;\n\n\t\tchunk = min_t(int, mtts_per_page, npages);\n\t}\n\treturn err;\n}\n\nint mlx4_write_mtt(struct mlx4_dev *dev, struct mlx4_mtt *mtt,\n\t\t   int start_index, int npages, u64 *page_list)\n{\n\tstruct mlx4_cmd_mailbox *mailbox = NULL;\n\t__be64 *inbox = NULL;\n\tint chunk;\n\tint err = 0;\n\tint i;\n\n\tif (mtt->order < 0)\n\t\treturn -EINVAL;\n\n\tif (mlx4_is_mfunc(dev)) {\n\t\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\t\tif (IS_ERR(mailbox))\n\t\t\treturn PTR_ERR(mailbox);\n\t\tinbox = mailbox->buf;\n\n\t\twhile (npages > 0) {\n\t\t\tchunk = min_t(int, MLX4_MAILBOX_SIZE / sizeof(u64) - 2,\n\t\t\t\t      npages);\n\t\t\tinbox[0] = cpu_to_be64(mtt->offset + start_index);\n\t\t\tinbox[1] = 0;\n\t\t\tfor (i = 0; i < chunk; ++i)\n\t\t\t\tinbox[i + 2] = cpu_to_be64(page_list[i] |\n\t\t\t\t\t       MLX4_MTT_FLAG_PRESENT);\n\t\t\terr = mlx4_WRITE_MTT(dev, mailbox, chunk);\n\t\t\tif (err) {\n\t\t\t\tmlx4_free_cmd_mailbox(dev, mailbox);\n\t\t\t\treturn err;\n\t\t\t}\n\n\t\t\tnpages      -= chunk;\n\t\t\tstart_index += chunk;\n\t\t\tpage_list   += chunk;\n\t\t}\n\t\tmlx4_free_cmd_mailbox(dev, mailbox);\n\t\treturn err;\n\t}\n\n\treturn __mlx4_write_mtt(dev, mtt, start_index, npages, page_list);\n}\nEXPORT_SYMBOL_GPL(mlx4_write_mtt);\n\nint mlx4_buf_write_mtt(struct mlx4_dev *dev, struct mlx4_mtt *mtt,\n\t\t       struct mlx4_buf *buf)\n{\n\tu64 *page_list;\n\tint err;\n\tint i;\n\n\tpage_list = kcalloc(buf->npages, sizeof(*page_list), GFP_KERNEL);\n\tif (!page_list)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < buf->npages; ++i)\n\t\tif (buf->nbufs == 1)\n\t\t\tpage_list[i] = buf->direct.map + (i << buf->page_shift);\n\t\telse\n\t\t\tpage_list[i] = buf->page_list[i].map;\n\n\terr = mlx4_write_mtt(dev, mtt, 0, buf->npages, page_list);\n\n\tkfree(page_list);\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_buf_write_mtt);\n\nint mlx4_mw_alloc(struct mlx4_dev *dev, u32 pd, enum mlx4_mw_type type,\n\t\t  struct mlx4_mw *mw)\n{\n\tu32 index;\n\n\tif ((type == MLX4_MW_TYPE_1 &&\n\t     !(dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW)) ||\n\t     (type == MLX4_MW_TYPE_2 &&\n\t     !(dev->caps.bmme_flags & MLX4_BMME_FLAG_TYPE_2_WIN)))\n\t\treturn -EOPNOTSUPP;\n\n\tindex = mlx4_mpt_reserve(dev);\n\tif (index == -1)\n\t\treturn -ENOMEM;\n\n\tmw->key\t    = hw_index_to_key(index);\n\tmw->pd      = pd;\n\tmw->type    = type;\n\tmw->enabled = MLX4_MPT_DISABLED;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mlx4_mw_alloc);\n\nint mlx4_mw_enable(struct mlx4_dev *dev, struct mlx4_mw *mw)\n{\n\tstruct mlx4_cmd_mailbox *mailbox;\n\tstruct mlx4_mpt_entry *mpt_entry;\n\tint err;\n\n\terr = mlx4_mpt_alloc_icm(dev, key_to_hw_index(mw->key));\n\tif (err)\n\t\treturn err;\n\n\tmailbox = mlx4_alloc_cmd_mailbox(dev);\n\tif (IS_ERR(mailbox)) {\n\t\terr = PTR_ERR(mailbox);\n\t\tgoto err_table;\n\t}\n\tmpt_entry = mailbox->buf;\n\n\t \n\tmpt_entry->key\t       = cpu_to_be32(key_to_hw_index(mw->key));\n\tmpt_entry->pd_flags    = cpu_to_be32(mw->pd);\n\tif (mw->type == MLX4_MW_TYPE_2) {\n\t\tmpt_entry->flags    |= cpu_to_be32(MLX4_MPT_FLAG_FREE);\n\t\tmpt_entry->qpn       = cpu_to_be32(MLX4_MPT_QP_FLAG_BOUND_QP);\n\t\tmpt_entry->pd_flags |= cpu_to_be32(MLX4_MPT_PD_FLAG_EN_INV);\n\t}\n\n\terr = mlx4_SW2HW_MPT(dev, mailbox,\n\t\t\t     key_to_hw_index(mw->key) &\n\t\t\t     (dev->caps.num_mpts - 1));\n\tif (err) {\n\t\tmlx4_warn(dev, \"SW2HW_MPT failed (%d)\\n\", err);\n\t\tgoto err_cmd;\n\t}\n\tmw->enabled = MLX4_MPT_EN_HW;\n\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\n\treturn 0;\n\nerr_cmd:\n\tmlx4_free_cmd_mailbox(dev, mailbox);\n\nerr_table:\n\tmlx4_mpt_free_icm(dev, key_to_hw_index(mw->key));\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mlx4_mw_enable);\n\nvoid mlx4_mw_free(struct mlx4_dev *dev, struct mlx4_mw *mw)\n{\n\tint err;\n\n\tif (mw->enabled == MLX4_MPT_EN_HW) {\n\t\terr = mlx4_HW2SW_MPT(dev, NULL,\n\t\t\t\t     key_to_hw_index(mw->key) &\n\t\t\t\t     (dev->caps.num_mpts - 1));\n\t\tif (err)\n\t\t\tmlx4_warn(dev, \"xxx HW2SW_MPT failed (%d)\\n\", err);\n\n\t\tmw->enabled = MLX4_MPT_EN_SW;\n\t}\n\tif (mw->enabled)\n\t\tmlx4_mpt_free_icm(dev, key_to_hw_index(mw->key));\n\tmlx4_mpt_release(dev, key_to_hw_index(mw->key));\n}\nEXPORT_SYMBOL_GPL(mlx4_mw_free);\n\nint mlx4_init_mr_table(struct mlx4_dev *dev)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tstruct mlx4_mr_table *mr_table = &priv->mr_table;\n\tint err;\n\n\t \n\tif (mlx4_is_slave(dev))\n\t\treturn 0;\n\n\tif (!is_power_of_2(dev->caps.num_mpts))\n\t\treturn -EINVAL;\n\n\terr = mlx4_bitmap_init(&mr_table->mpt_bitmap, dev->caps.num_mpts,\n\t\t\t       ~0, dev->caps.reserved_mrws, 0);\n\tif (err)\n\t\treturn err;\n\n\terr = mlx4_buddy_init(&mr_table->mtt_buddy,\n\t\t\t      ilog2((u32)dev->caps.num_mtts /\n\t\t\t      (1 << log_mtts_per_seg)));\n\tif (err)\n\t\tgoto err_buddy;\n\n\tif (dev->caps.reserved_mtts) {\n\t\tpriv->reserved_mtts =\n\t\t\tmlx4_alloc_mtt_range(dev,\n\t\t\t\t\t     fls(dev->caps.reserved_mtts - 1));\n\t\tif (priv->reserved_mtts < 0) {\n\t\t\tmlx4_warn(dev, \"MTT table of order %u is too small\\n\",\n\t\t\t\t  mr_table->mtt_buddy.max_order);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_reserve_mtts;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_reserve_mtts:\n\tmlx4_buddy_cleanup(&mr_table->mtt_buddy);\n\nerr_buddy:\n\tmlx4_bitmap_cleanup(&mr_table->mpt_bitmap);\n\n\treturn err;\n}\n\nvoid mlx4_cleanup_mr_table(struct mlx4_dev *dev)\n{\n\tstruct mlx4_priv *priv = mlx4_priv(dev);\n\tstruct mlx4_mr_table *mr_table = &priv->mr_table;\n\n\tif (mlx4_is_slave(dev))\n\t\treturn;\n\tif (priv->reserved_mtts >= 0)\n\t\tmlx4_free_mtt_range(dev, priv->reserved_mtts,\n\t\t\t\t    fls(dev->caps.reserved_mtts - 1));\n\tmlx4_buddy_cleanup(&mr_table->mtt_buddy);\n\tmlx4_bitmap_cleanup(&mr_table->mpt_bitmap);\n}\n\nint mlx4_SYNC_TPT(struct mlx4_dev *dev)\n{\n\treturn mlx4_cmd(dev, 0, 0, 0, MLX4_CMD_SYNC_TPT,\n\t\t\tMLX4_CMD_TIME_CLASS_A, MLX4_CMD_NATIVE);\n}\nEXPORT_SYMBOL_GPL(mlx4_SYNC_TPT);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}