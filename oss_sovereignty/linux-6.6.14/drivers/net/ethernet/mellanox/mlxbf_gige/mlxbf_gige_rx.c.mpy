{
  "module_name": "mlxbf_gige_rx.c",
  "hash_id": "b557f3f33c56ad4aa224e0dc5ed4ddd10613b6f64a0dfdf8f1bcd6ecd0a3d60b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlxbf_gige/mlxbf_gige_rx.c",
  "human_readable_source": "\n\n \n\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n\n#include \"mlxbf_gige.h\"\n#include \"mlxbf_gige_regs.h\"\n\nvoid mlxbf_gige_set_mac_rx_filter(struct mlxbf_gige *priv,\n\t\t\t\t  unsigned int index, u64 dmac)\n{\n\tvoid __iomem *base = priv->base;\n\tu64 control;\n\n\t \n\twriteq(dmac, base + MLXBF_GIGE_RX_MAC_FILTER +\n\t       (index * MLXBF_GIGE_RX_MAC_FILTER_STRIDE));\n\n\t \n\tcontrol = readq(base + MLXBF_GIGE_CONTROL);\n\tcontrol |= (MLXBF_GIGE_CONTROL_EN_SPECIFIC_MAC << index);\n\twriteq(control, base + MLXBF_GIGE_CONTROL);\n}\n\nvoid mlxbf_gige_get_mac_rx_filter(struct mlxbf_gige *priv,\n\t\t\t\t  unsigned int index, u64 *dmac)\n{\n\tvoid __iomem *base = priv->base;\n\n\t \n\t*dmac = readq(base + MLXBF_GIGE_RX_MAC_FILTER +\n\t\t      (index * MLXBF_GIGE_RX_MAC_FILTER_STRIDE));\n}\n\nvoid mlxbf_gige_enable_promisc(struct mlxbf_gige *priv)\n{\n\tvoid __iomem *base = priv->base;\n\tu64 control;\n\tu64 end_mac;\n\n\t \n\tcontrol = readq(base + MLXBF_GIGE_CONTROL);\n\tcontrol |= MLXBF_GIGE_CONTROL_MAC_ID_RANGE_EN;\n\twriteq(control, base + MLXBF_GIGE_CONTROL);\n\n\t \n\twriteq(0, base + MLXBF_GIGE_RX_MAC_FILTER_DMAC_RANGE_START);\n\n\t \n\tend_mac = BCAST_MAC_ADDR;\n\twriteq(end_mac, base + MLXBF_GIGE_RX_MAC_FILTER_DMAC_RANGE_END);\n}\n\nvoid mlxbf_gige_disable_promisc(struct mlxbf_gige *priv)\n{\n\tvoid __iomem *base = priv->base;\n\tu64 control;\n\n\t \n\tcontrol = readq(base + MLXBF_GIGE_CONTROL);\n\tcontrol &= ~MLXBF_GIGE_CONTROL_MAC_ID_RANGE_EN;\n\twriteq(control, base + MLXBF_GIGE_CONTROL);\n\n\t \n}\n\n \nint mlxbf_gige_rx_init(struct mlxbf_gige *priv)\n{\n\tsize_t wq_size, cq_size;\n\tdma_addr_t *rx_wqe_ptr;\n\tdma_addr_t rx_buf_dma;\n\tu64 data;\n\tint i, j;\n\n\t \n\tmlxbf_gige_set_mac_rx_filter(priv, MLXBF_GIGE_BCAST_MAC_FILTER_IDX,\n\t\t\t\t     BCAST_MAC_ADDR);\n\n\twq_size = MLXBF_GIGE_RX_WQE_SZ * priv->rx_q_entries;\n\tpriv->rx_wqe_base = dma_alloc_coherent(priv->dev, wq_size,\n\t\t\t\t\t       &priv->rx_wqe_base_dma,\n\t\t\t\t\t       GFP_KERNEL);\n\tif (!priv->rx_wqe_base)\n\t\treturn -ENOMEM;\n\n\t \n\trx_wqe_ptr = priv->rx_wqe_base;\n\n\tfor (i = 0; i < priv->rx_q_entries; i++) {\n\t\tpriv->rx_skb[i] = mlxbf_gige_alloc_skb(priv, MLXBF_GIGE_DEFAULT_BUF_SZ,\n\t\t\t\t\t\t       &rx_buf_dma, DMA_FROM_DEVICE);\n\t\tif (!priv->rx_skb[i])\n\t\t\tgoto free_wqe_and_skb;\n\t\t*rx_wqe_ptr++ = rx_buf_dma;\n\t}\n\n\t \n\twriteq(priv->rx_wqe_base_dma, priv->base + MLXBF_GIGE_RX_WQ_BASE);\n\n\tcq_size = MLXBF_GIGE_RX_CQE_SZ * priv->rx_q_entries;\n\tpriv->rx_cqe_base = dma_alloc_coherent(priv->dev, cq_size,\n\t\t\t\t\t       &priv->rx_cqe_base_dma,\n\t\t\t\t\t       GFP_KERNEL);\n\tif (!priv->rx_cqe_base)\n\t\tgoto free_wqe_and_skb;\n\n\tfor (i = 0; i < priv->rx_q_entries; i++)\n\t\tpriv->rx_cqe_base[i] |= MLXBF_GIGE_RX_CQE_VALID_MASK;\n\n\t \n\twriteq(priv->rx_cqe_base_dma, priv->base + MLXBF_GIGE_RX_CQ_BASE);\n\n\t \n\twriteq(priv->rx_q_entries, priv->base + MLXBF_GIGE_RX_WQE_PI);\n\n\t \n\tdata = readq(priv->base + MLXBF_GIGE_RX);\n\tdata |= MLXBF_GIGE_RX_STRIP_CRC_EN;\n\twriteq(data, priv->base + MLXBF_GIGE_RX);\n\n\t \n\twriteq(MLXBF_GIGE_RX_MAC_FILTER_COUNT_DISC_EN,\n\t       priv->base + MLXBF_GIGE_RX_MAC_FILTER_COUNT_DISC);\n\twriteq(MLXBF_GIGE_RX_MAC_FILTER_COUNT_PASS_EN,\n\t       priv->base + MLXBF_GIGE_RX_MAC_FILTER_COUNT_PASS);\n\n\twriteq(ilog2(priv->rx_q_entries),\n\t       priv->base + MLXBF_GIGE_RX_WQE_SIZE_LOG2);\n\n\t \n\tdata = readq(priv->base + MLXBF_GIGE_INT_MASK);\n\tdata &= ~MLXBF_GIGE_INT_MASK_RX_RECEIVE_PACKET;\n\twriteq(data, priv->base + MLXBF_GIGE_INT_MASK);\n\n\t \n\tdata = readq(priv->base + MLXBF_GIGE_RX_DMA);\n\tdata |= MLXBF_GIGE_RX_DMA_EN;\n\twriteq(data, priv->base + MLXBF_GIGE_RX_DMA);\n\n\treturn 0;\n\nfree_wqe_and_skb:\n\trx_wqe_ptr = priv->rx_wqe_base;\n\tfor (j = 0; j < i; j++) {\n\t\tdma_unmap_single(priv->dev, *rx_wqe_ptr,\n\t\t\t\t MLXBF_GIGE_DEFAULT_BUF_SZ, DMA_FROM_DEVICE);\n\t\tdev_kfree_skb(priv->rx_skb[j]);\n\t\trx_wqe_ptr++;\n\t}\n\tdma_free_coherent(priv->dev, wq_size,\n\t\t\t  priv->rx_wqe_base, priv->rx_wqe_base_dma);\n\treturn -ENOMEM;\n}\n\n \nvoid mlxbf_gige_rx_deinit(struct mlxbf_gige *priv)\n{\n\tdma_addr_t *rx_wqe_ptr;\n\tsize_t size;\n\tu64 data;\n\tint i;\n\n\t \n\tdata = readq(priv->base + MLXBF_GIGE_RX_DMA);\n\tdata &= ~MLXBF_GIGE_RX_DMA_EN;\n\twriteq(data, priv->base + MLXBF_GIGE_RX_DMA);\n\n\trx_wqe_ptr = priv->rx_wqe_base;\n\n\tfor (i = 0; i < priv->rx_q_entries; i++) {\n\t\tdma_unmap_single(priv->dev, *rx_wqe_ptr, MLXBF_GIGE_DEFAULT_BUF_SZ,\n\t\t\t\t DMA_FROM_DEVICE);\n\t\tdev_kfree_skb(priv->rx_skb[i]);\n\t\trx_wqe_ptr++;\n\t}\n\n\tsize = MLXBF_GIGE_RX_WQE_SZ * priv->rx_q_entries;\n\tdma_free_coherent(priv->dev, size,\n\t\t\t  priv->rx_wqe_base, priv->rx_wqe_base_dma);\n\n\tsize = MLXBF_GIGE_RX_CQE_SZ * priv->rx_q_entries;\n\tdma_free_coherent(priv->dev, size,\n\t\t\t  priv->rx_cqe_base, priv->rx_cqe_base_dma);\n\n\tpriv->rx_wqe_base = NULL;\n\tpriv->rx_wqe_base_dma = 0;\n\tpriv->rx_cqe_base = NULL;\n\tpriv->rx_cqe_base_dma = 0;\n\twriteq(0, priv->base + MLXBF_GIGE_RX_WQ_BASE);\n\twriteq(0, priv->base + MLXBF_GIGE_RX_CQ_BASE);\n}\n\nstatic bool mlxbf_gige_rx_packet(struct mlxbf_gige *priv, int *rx_pkts)\n{\n\tstruct net_device *netdev = priv->netdev;\n\tstruct sk_buff *skb = NULL, *rx_skb;\n\tu16 rx_pi_rem, rx_ci_rem;\n\tdma_addr_t *rx_wqe_addr;\n\tdma_addr_t rx_buf_dma;\n\tu64 *rx_cqe_addr;\n\tu64 datalen;\n\tu64 rx_cqe;\n\tu16 rx_ci;\n\tu16 rx_pi;\n\n\t \n\trx_pi = readq(priv->base + MLXBF_GIGE_RX_WQE_PI);\n\trx_pi_rem = rx_pi % priv->rx_q_entries;\n\n\trx_wqe_addr = priv->rx_wqe_base + rx_pi_rem;\n\trx_cqe_addr = priv->rx_cqe_base + rx_pi_rem;\n\trx_cqe = *rx_cqe_addr;\n\n\tif ((!!(rx_cqe & MLXBF_GIGE_RX_CQE_VALID_MASK)) != priv->valid_polarity)\n\t\treturn false;\n\n\tif ((rx_cqe & MLXBF_GIGE_RX_CQE_PKT_STATUS_MASK) == 0) {\n\t\t \n\t\tdatalen = rx_cqe & MLXBF_GIGE_RX_CQE_PKT_LEN_MASK;\n\t\tnetdev->stats.rx_packets++;\n\t\tnetdev->stats.rx_bytes += datalen;\n\n\t\tskb = priv->rx_skb[rx_pi_rem];\n\n\t\t \n\t\trx_skb = mlxbf_gige_alloc_skb(priv, MLXBF_GIGE_DEFAULT_BUF_SZ,\n\t\t\t\t\t      &rx_buf_dma, DMA_FROM_DEVICE);\n\t\tif (!rx_skb)\n\t\t\treturn false;\n\t\tpriv->rx_skb[rx_pi_rem] = rx_skb;\n\t\tdma_unmap_single(priv->dev, *rx_wqe_addr,\n\t\t\t\t MLXBF_GIGE_DEFAULT_BUF_SZ, DMA_FROM_DEVICE);\n\n\t\tskb_put(skb, datalen);\n\n\t\tskb->ip_summed = CHECKSUM_NONE;  \n\n\t\tskb->protocol = eth_type_trans(skb, netdev);\n\n\t\t*rx_wqe_addr = rx_buf_dma;\n\t} else if (rx_cqe & MLXBF_GIGE_RX_CQE_PKT_STATUS_MAC_ERR) {\n\t\tpriv->stats.rx_mac_errors++;\n\t} else if (rx_cqe & MLXBF_GIGE_RX_CQE_PKT_STATUS_TRUNCATED) {\n\t\tpriv->stats.rx_truncate_errors++;\n\t}\n\n\t \n\trx_ci = readq(priv->base + MLXBF_GIGE_RX_CQE_PACKET_CI);\n\trx_ci_rem = rx_ci % priv->rx_q_entries;\n\n\t \n\trx_pi++;\n\n\t \n\twmb();\n\twriteq(rx_pi, priv->base + MLXBF_GIGE_RX_WQE_PI);\n\n\t(*rx_pkts)++;\n\n\trx_pi_rem = rx_pi % priv->rx_q_entries;\n\tif (rx_pi_rem == 0)\n\t\tpriv->valid_polarity ^= 1;\n\n\tif (skb)\n\t\tnetif_receive_skb(skb);\n\n\treturn rx_pi_rem != rx_ci_rem;\n}\n\n \nint mlxbf_gige_poll(struct napi_struct *napi, int budget)\n{\n\tstruct mlxbf_gige *priv;\n\tbool remaining_pkts;\n\tint work_done = 0;\n\tu64 data;\n\n\tpriv = container_of(napi, struct mlxbf_gige, napi);\n\n\tmlxbf_gige_handle_tx_complete(priv);\n\n\tdo {\n\t\tremaining_pkts = mlxbf_gige_rx_packet(priv, &work_done);\n\t} while (remaining_pkts && work_done < budget);\n\n\t \n\tif (work_done < budget && napi_complete_done(napi, work_done)) {\n\t\t \n\t\tdata = readq(priv->base + MLXBF_GIGE_INT_MASK);\n\t\tdata &= ~MLXBF_GIGE_INT_MASK_RX_RECEIVE_PACKET;\n\t\twriteq(data, priv->base + MLXBF_GIGE_INT_MASK);\n\t}\n\n\treturn work_done;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}