{
  "module_name": "spectrum_flower.c",
  "hash_id": "a815611b53c727f21db4519ac1265d7013f0488101902407bed90bc0751a744a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/errno.h>\n#include <linux/netdevice.h>\n#include <linux/log2.h>\n#include <net/net_namespace.h>\n#include <net/flow_dissector.h>\n#include <net/pkt_cls.h>\n#include <net/tc_act/tc_gact.h>\n#include <net/tc_act/tc_mirred.h>\n#include <net/tc_act/tc_vlan.h>\n\n#include \"spectrum.h\"\n#include \"core_acl_flex_keys.h\"\n\nstatic int mlxsw_sp_policer_validate(const struct flow_action *action,\n\t\t\t\t     const struct flow_action_entry *act,\n\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tif (act->police.exceed.act_id != FLOW_ACTION_DROP) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when exceed action is not drop\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id != FLOW_ACTION_PIPE &&\n\t    act->police.notexceed.act_id != FLOW_ACTION_ACCEPT) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is not pipe or ok\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id == FLOW_ACTION_ACCEPT &&\n\t    !flow_action_is_last_entry(action, act)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is ok, but action is not last\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.peakrate_bytes_ps ||\n\t    act->police.avrate || act->police.overhead) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when peakrate/avrate/overhead is configured\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.rate_pkt_ps) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"QoS offload not support packets per second\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int mlxsw_sp_flower_parse_actions(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t struct mlxsw_sp_flow_block *block,\n\t\t\t\t\t struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t\t struct flow_action *flow_action,\n\t\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tconst struct flow_action_entry *act;\n\tint mirror_act_count = 0;\n\tint police_act_count = 0;\n\tint sample_act_count = 0;\n\tint err, i;\n\n\tif (!flow_action_has_entries(flow_action))\n\t\treturn 0;\n\tif (!flow_action_mixed_hw_stats_check(flow_action, extack))\n\t\treturn -EOPNOTSUPP;\n\n\tact = flow_action_first_entry_get(flow_action);\n\tif (act->hw_stats & FLOW_ACTION_HW_STATS_DISABLED) {\n\t\t \n\t} else if (act->hw_stats & FLOW_ACTION_HW_STATS_IMMEDIATE) {\n\t\t \n\t\terr = mlxsw_sp_acl_rulei_act_count(mlxsw_sp, rulei, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported action HW stats type\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tflow_action_for_each(i, act, flow_action) {\n\t\tswitch (act->id) {\n\t\tcase FLOW_ACTION_ACCEPT:\n\t\t\terr = mlxsw_sp_acl_rulei_act_terminate(rulei);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot append terminate action\");\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_DROP: {\n\t\t\tbool ingress;\n\n\t\t\tif (mlxsw_sp_flow_block_is_mixed_bound(block)) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Drop action is not supported when block is bound to ingress and egress\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t\tingress = mlxsw_sp_flow_block_is_ingress_bound(block);\n\t\t\terr = mlxsw_sp_acl_rulei_act_drop(rulei, ingress,\n\t\t\t\t\t\t\t  act->user_cookie, extack);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot append drop action\");\n\t\t\t\treturn err;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (ingress)\n\t\t\t\trulei->egress_bind_blocker = 1;\n\t\t\telse\n\t\t\t\trulei->ingress_bind_blocker = 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_TRAP:\n\t\t\terr = mlxsw_sp_acl_rulei_act_trap(rulei);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot append trap action\");\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_GOTO: {\n\t\t\tu32 chain_index = act->chain_index;\n\t\t\tstruct mlxsw_sp_acl_ruleset *ruleset;\n\t\t\tu16 group_id;\n\n\t\t\truleset = mlxsw_sp_acl_ruleset_lookup(mlxsw_sp, block,\n\t\t\t\t\t\t\t      chain_index,\n\t\t\t\t\t\t\t      MLXSW_SP_ACL_PROFILE_FLOWER);\n\t\t\tif (IS_ERR(ruleset))\n\t\t\t\treturn PTR_ERR(ruleset);\n\n\t\t\tgroup_id = mlxsw_sp_acl_ruleset_group_id(ruleset);\n\t\t\terr = mlxsw_sp_acl_rulei_act_jump(rulei, group_id);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot append jump action\");\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_REDIRECT: {\n\t\t\tstruct net_device *out_dev;\n\t\t\tstruct mlxsw_sp_fid *fid;\n\t\t\tu16 fid_index;\n\n\t\t\tif (mlxsw_sp_flow_block_is_egress_bound(block)) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Redirect action is not supported on egress\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\t \n\t\t\trulei->egress_bind_blocker = 1;\n\n\t\t\t \n\t\t\terr = mlxsw_sp_acl_rulei_act_ignore(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t    true, true);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot append ignore action\");\n\t\t\t\treturn err;\n\t\t\t}\n\n\t\t\tfid = mlxsw_sp_acl_dummy_fid(mlxsw_sp);\n\t\t\tfid_index = mlxsw_sp_fid_index(fid);\n\t\t\terr = mlxsw_sp_acl_rulei_act_fid_set(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t     fid_index, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\tout_dev = act->dev;\n\t\t\terr = mlxsw_sp_acl_rulei_act_fwd(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t out_dev, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_MIRRED: {\n\t\t\tstruct net_device *out_dev = act->dev;\n\n\t\t\tif (mirror_act_count++) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Multiple mirror actions per rule are not supported\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\terr = mlxsw_sp_acl_rulei_act_mirror(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t    block, out_dev,\n\t\t\t\t\t\t\t    extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_VLAN_MANGLE: {\n\t\t\tu16 proto = be16_to_cpu(act->vlan.proto);\n\t\t\tu8 prio = act->vlan.prio;\n\t\t\tu16 vid = act->vlan.vid;\n\n\t\t\terr = mlxsw_sp_acl_rulei_act_vlan(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t  act->id, vid,\n\t\t\t\t\t\t\t  proto, prio, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\tbreak;\n\t\t\t}\n\t\tcase FLOW_ACTION_PRIORITY:\n\t\t\terr = mlxsw_sp_acl_rulei_act_priority(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t      act->priority,\n\t\t\t\t\t\t\t      extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_MANGLE: {\n\t\t\tenum flow_action_mangle_base htype = act->mangle.htype;\n\t\t\t__be32 be_mask = (__force __be32) act->mangle.mask;\n\t\t\t__be32 be_val = (__force __be32) act->mangle.val;\n\t\t\tu32 offset = act->mangle.offset;\n\t\t\tu32 mask = be32_to_cpu(be_mask);\n\t\t\tu32 val = be32_to_cpu(be_val);\n\n\t\t\terr = mlxsw_sp_acl_rulei_act_mangle(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t    htype, offset,\n\t\t\t\t\t\t\t    mask, val, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\tbreak;\n\t\t\t}\n\t\tcase FLOW_ACTION_POLICE: {\n\t\t\tu32 burst;\n\n\t\t\tif (police_act_count++) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Multiple police actions per rule are not supported\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\terr = mlxsw_sp_policer_validate(flow_action, act, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\t \n\t\t\tburst = roundup_pow_of_two(act->police.burst);\n\t\t\terr = mlxsw_sp_acl_rulei_act_police(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t    act->hw_index,\n\t\t\t\t\t\t\t    act->police.rate_bytes_ps,\n\t\t\t\t\t\t\t    burst, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\tbreak;\n\t\t\t}\n\t\tcase FLOW_ACTION_SAMPLE: {\n\t\t\tif (sample_act_count++) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Multiple sample actions per rule are not supported\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\terr = mlxsw_sp_acl_rulei_act_sample(mlxsw_sp, rulei,\n\t\t\t\t\t\t\t    block,\n\t\t\t\t\t\t\t    act->sample.psample_group,\n\t\t\t\t\t\t\t    act->sample.rate,\n\t\t\t\t\t\t\t    act->sample.trunc_size,\n\t\t\t\t\t\t\t    act->sample.truncate,\n\t\t\t\t\t\t\t    extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\tbreak;\n\t\t\t}\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported action\");\n\t\t\tdev_err(mlxsw_sp->bus_info->dev, \"Unsupported action\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\n\tif (rulei->ipv6_valid) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported mangle field\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_flower_parse_meta_iif(struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t       const struct mlxsw_sp_flow_block *block,\n\t\t\t       const struct flow_match_meta *match,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct mlxsw_sp_port *mlxsw_sp_port;\n\tstruct net_device *ingress_dev;\n\n\tif (!match->mask->ingress_ifindex)\n\t\treturn 0;\n\n\tif (match->mask->ingress_ifindex != 0xFFFFFFFF) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported ingress ifindex mask\");\n\t\treturn -EINVAL;\n\t}\n\n\tingress_dev = __dev_get_by_index(block->net,\n\t\t\t\t\t match->key->ingress_ifindex);\n\tif (!ingress_dev) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't find specified ingress port to match on\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!mlxsw_sp_port_dev_check(ingress_dev)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't match on non-mlxsw ingress port\");\n\t\treturn -EINVAL;\n\t}\n\n\tmlxsw_sp_port = netdev_priv(ingress_dev);\n\tif (mlxsw_sp_port->mlxsw_sp != block->mlxsw_sp) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't match on a port from different device\");\n\t\treturn -EINVAL;\n\t}\n\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei,\n\t\t\t\t       MLXSW_AFK_ELEMENT_SRC_SYS_PORT,\n\t\t\t\t       mlxsw_sp_port->local_port,\n\t\t\t\t       0xFFFFFFFF);\n\n\treturn 0;\n}\n\nstatic int mlxsw_sp_flower_parse_meta(struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t      struct flow_cls_offload *f,\n\t\t\t\t      struct mlxsw_sp_flow_block *block)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_match_meta match;\n\n\tif (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_META))\n\t\treturn 0;\n\n\tflow_rule_match_meta(rule, &match);\n\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_FDB_MISS,\n\t\t\t\t       match.key->l2_miss, match.mask->l2_miss);\n\n\treturn mlxsw_sp_flower_parse_meta_iif(rulei, block, &match,\n\t\t\t\t\t      f->common.extack);\n}\n\nstatic void mlxsw_sp_flower_parse_ipv4(struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t       struct flow_cls_offload *f)\n{\n\tstruct flow_match_ipv4_addrs match;\n\n\tflow_rule_match_ipv4_addrs(f->rule, &match);\n\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_SRC_IP_0_31,\n\t\t\t\t       (char *) &match.key->src,\n\t\t\t\t       (char *) &match.mask->src, 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_DST_IP_0_31,\n\t\t\t\t       (char *) &match.key->dst,\n\t\t\t\t       (char *) &match.mask->dst, 4);\n}\n\nstatic void mlxsw_sp_flower_parse_ipv6(struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t       struct flow_cls_offload *f)\n{\n\tstruct flow_match_ipv6_addrs match;\n\n\tflow_rule_match_ipv6_addrs(f->rule, &match);\n\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_SRC_IP_96_127,\n\t\t\t\t       &match.key->src.s6_addr[0x0],\n\t\t\t\t       &match.mask->src.s6_addr[0x0], 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_SRC_IP_64_95,\n\t\t\t\t       &match.key->src.s6_addr[0x4],\n\t\t\t\t       &match.mask->src.s6_addr[0x4], 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_SRC_IP_32_63,\n\t\t\t\t       &match.key->src.s6_addr[0x8],\n\t\t\t\t       &match.mask->src.s6_addr[0x8], 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_SRC_IP_0_31,\n\t\t\t\t       &match.key->src.s6_addr[0xC],\n\t\t\t\t       &match.mask->src.s6_addr[0xC], 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_DST_IP_96_127,\n\t\t\t\t       &match.key->dst.s6_addr[0x0],\n\t\t\t\t       &match.mask->dst.s6_addr[0x0], 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_DST_IP_64_95,\n\t\t\t\t       &match.key->dst.s6_addr[0x4],\n\t\t\t\t       &match.mask->dst.s6_addr[0x4], 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_DST_IP_32_63,\n\t\t\t\t       &match.key->dst.s6_addr[0x8],\n\t\t\t\t       &match.mask->dst.s6_addr[0x8], 4);\n\tmlxsw_sp_acl_rulei_keymask_buf(rulei, MLXSW_AFK_ELEMENT_DST_IP_0_31,\n\t\t\t\t       &match.key->dst.s6_addr[0xC],\n\t\t\t\t       &match.mask->dst.s6_addr[0xC], 4);\n}\n\nstatic int mlxsw_sp_flower_parse_ports(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t       struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t       struct flow_cls_offload *f,\n\t\t\t\t       u8 ip_proto)\n{\n\tconst struct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_match_ports match;\n\n\tif (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS))\n\t\treturn 0;\n\n\tif (ip_proto != IPPROTO_TCP && ip_proto != IPPROTO_UDP) {\n\t\tNL_SET_ERR_MSG_MOD(f->common.extack, \"Only UDP and TCP keys are supported\");\n\t\tdev_err(mlxsw_sp->bus_info->dev, \"Only UDP and TCP keys are supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tflow_rule_match_ports(rule, &match);\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_DST_L4_PORT,\n\t\t\t\t       ntohs(match.key->dst),\n\t\t\t\t       ntohs(match.mask->dst));\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_SRC_L4_PORT,\n\t\t\t\t       ntohs(match.key->src),\n\t\t\t\t       ntohs(match.mask->src));\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_flower_parse_ports_range(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t  struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t  struct flow_cls_offload *f, u8 ip_proto)\n{\n\tconst struct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_match_ports_range match;\n\tu32 key_mask_value = 0;\n\n\tif (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS_RANGE))\n\t\treturn 0;\n\n\tif (ip_proto != IPPROTO_TCP && ip_proto != IPPROTO_UDP) {\n\t\tNL_SET_ERR_MSG_MOD(f->common.extack, \"Only UDP and TCP keys are supported\");\n\t\treturn -EINVAL;\n\t}\n\n\tflow_rule_match_ports_range(rule, &match);\n\n\tif (match.mask->tp_min.src) {\n\t\tstruct mlxsw_sp_port_range range = {\n\t\t\t.min = ntohs(match.key->tp_min.src),\n\t\t\t.max = ntohs(match.key->tp_max.src),\n\t\t\t.source = true,\n\t\t};\n\t\tu8 prr_index;\n\t\tint err;\n\n\t\terr = mlxsw_sp_port_range_reg_get(mlxsw_sp, &range,\n\t\t\t\t\t\t  f->common.extack, &prr_index);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\trulei->src_port_range_reg_index = prr_index;\n\t\trulei->src_port_range_reg_valid = true;\n\t\tkey_mask_value |= BIT(prr_index);\n\t}\n\n\tif (match.mask->tp_min.dst) {\n\t\tstruct mlxsw_sp_port_range range = {\n\t\t\t.min = ntohs(match.key->tp_min.dst),\n\t\t\t.max = ntohs(match.key->tp_max.dst),\n\t\t};\n\t\tu8 prr_index;\n\t\tint err;\n\n\t\terr = mlxsw_sp_port_range_reg_get(mlxsw_sp, &range,\n\t\t\t\t\t\t  f->common.extack, &prr_index);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\trulei->dst_port_range_reg_index = prr_index;\n\t\trulei->dst_port_range_reg_valid = true;\n\t\tkey_mask_value |= BIT(prr_index);\n\t}\n\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_L4_PORT_RANGE,\n\t\t\t\t       key_mask_value, key_mask_value);\n\n\treturn 0;\n}\n\nstatic int mlxsw_sp_flower_parse_tcp(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t     struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t     struct flow_cls_offload *f,\n\t\t\t\t     u8 ip_proto)\n{\n\tconst struct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_match_tcp match;\n\n\tif (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_TCP))\n\t\treturn 0;\n\n\tif (ip_proto != IPPROTO_TCP) {\n\t\tNL_SET_ERR_MSG_MOD(f->common.extack, \"TCP keys supported only for TCP\");\n\t\tdev_err(mlxsw_sp->bus_info->dev, \"TCP keys supported only for TCP\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tflow_rule_match_tcp(rule, &match);\n\n\tif (match.mask->flags & htons(0x0E00)) {\n\t\tNL_SET_ERR_MSG_MOD(f->common.extack, \"TCP flags match not supported on reserved bits\");\n\t\tdev_err(mlxsw_sp->bus_info->dev, \"TCP flags match not supported on reserved bits\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_TCP_FLAGS,\n\t\t\t\t       ntohs(match.key->flags),\n\t\t\t\t       ntohs(match.mask->flags));\n\treturn 0;\n}\n\nstatic int mlxsw_sp_flower_parse_ip(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t    struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t    struct flow_cls_offload *f,\n\t\t\t\t    u16 n_proto)\n{\n\tconst struct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_match_ip match;\n\n\tif (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IP))\n\t\treturn 0;\n\n\tif (n_proto != ETH_P_IP && n_proto != ETH_P_IPV6) {\n\t\tNL_SET_ERR_MSG_MOD(f->common.extack, \"IP keys supported only for IPv4/6\");\n\t\tdev_err(mlxsw_sp->bus_info->dev, \"IP keys supported only for IPv4/6\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tflow_rule_match_ip(rule, &match);\n\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_IP_TTL_,\n\t\t\t\t       match.key->ttl, match.mask->ttl);\n\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_IP_ECN,\n\t\t\t\t       match.key->tos & 0x3,\n\t\t\t\t       match.mask->tos & 0x3);\n\n\tmlxsw_sp_acl_rulei_keymask_u32(rulei, MLXSW_AFK_ELEMENT_IP_DSCP,\n\t\t\t\t       match.key->tos >> 2,\n\t\t\t\t       match.mask->tos >> 2);\n\n\treturn 0;\n}\n\nstatic int mlxsw_sp_flower_parse(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t struct mlxsw_sp_flow_block *block,\n\t\t\t\t struct mlxsw_sp_acl_rule_info *rulei,\n\t\t\t\t struct flow_cls_offload *f)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tu16 n_proto_mask = 0;\n\tu16 n_proto_key = 0;\n\tu16 addr_type = 0;\n\tu8 ip_proto = 0;\n\tint err;\n\n\tif (dissector->used_keys &\n\t    ~(BIT_ULL(FLOW_DISSECTOR_KEY_META) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ETH_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_PORTS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_PORTS_RANGE) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_TCP) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IP) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_VLAN))) {\n\t\tdev_err(mlxsw_sp->bus_info->dev, \"Unsupported key\\n\");\n\t\tNL_SET_ERR_MSG_MOD(f->common.extack, \"Unsupported key\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmlxsw_sp_acl_rulei_priority(rulei, f->common.prio);\n\n\terr = mlxsw_sp_flower_parse_meta(rulei, f, block);\n\tif (err)\n\t\treturn err;\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {\n\t\tstruct flow_match_control match;\n\n\t\tflow_rule_match_control(rule, &match);\n\t\taddr_type = match.key->addr_type;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tn_proto_key = ntohs(match.key->n_proto);\n\t\tn_proto_mask = ntohs(match.mask->n_proto);\n\n\t\tif (n_proto_key == ETH_P_ALL) {\n\t\t\tn_proto_key = 0;\n\t\t\tn_proto_mask = 0;\n\t\t}\n\t\tmlxsw_sp_acl_rulei_keymask_u32(rulei,\n\t\t\t\t\t       MLXSW_AFK_ELEMENT_ETHERTYPE,\n\t\t\t\t\t       n_proto_key, n_proto_mask);\n\n\t\tip_proto = match.key->ip_proto;\n\t\tmlxsw_sp_acl_rulei_keymask_u32(rulei,\n\t\t\t\t\t       MLXSW_AFK_ELEMENT_IP_PROTO,\n\t\t\t\t\t       match.key->ip_proto,\n\t\t\t\t\t       match.mask->ip_proto);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct flow_match_eth_addrs match;\n\n\t\tflow_rule_match_eth_addrs(rule, &match);\n\t\tmlxsw_sp_acl_rulei_keymask_buf(rulei,\n\t\t\t\t\t       MLXSW_AFK_ELEMENT_DMAC_32_47,\n\t\t\t\t\t       match.key->dst,\n\t\t\t\t\t       match.mask->dst, 2);\n\t\tmlxsw_sp_acl_rulei_keymask_buf(rulei,\n\t\t\t\t\t       MLXSW_AFK_ELEMENT_DMAC_0_31,\n\t\t\t\t\t       match.key->dst + 2,\n\t\t\t\t\t       match.mask->dst + 2, 4);\n\t\tmlxsw_sp_acl_rulei_keymask_buf(rulei,\n\t\t\t\t\t       MLXSW_AFK_ELEMENT_SMAC_32_47,\n\t\t\t\t\t       match.key->src,\n\t\t\t\t\t       match.mask->src, 2);\n\t\tmlxsw_sp_acl_rulei_keymask_buf(rulei,\n\t\t\t\t\t       MLXSW_AFK_ELEMENT_SMAC_0_31,\n\t\t\t\t\t       match.key->src + 2,\n\t\t\t\t\t       match.mask->src + 2, 4);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {\n\t\tstruct flow_match_vlan match;\n\n\t\tflow_rule_match_vlan(rule, &match);\n\t\tif (mlxsw_sp_flow_block_is_egress_bound(block) &&\n\t\t    match.mask->vlan_id) {\n\t\t\tNL_SET_ERR_MSG_MOD(f->common.extack, \"vlan_id key is not supported on egress\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\t \n\t\trulei->egress_bind_blocker = 1;\n\n\t\tif (match.mask->vlan_id != 0)\n\t\t\tmlxsw_sp_acl_rulei_keymask_u32(rulei,\n\t\t\t\t\t\t       MLXSW_AFK_ELEMENT_VID,\n\t\t\t\t\t\t       match.key->vlan_id,\n\t\t\t\t\t\t       match.mask->vlan_id);\n\t\tif (match.mask->vlan_priority != 0)\n\t\t\tmlxsw_sp_acl_rulei_keymask_u32(rulei,\n\t\t\t\t\t\t       MLXSW_AFK_ELEMENT_PCP,\n\t\t\t\t\t\t       match.key->vlan_priority,\n\t\t\t\t\t\t       match.mask->vlan_priority);\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS)\n\t\tmlxsw_sp_flower_parse_ipv4(rulei, f);\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS)\n\t\tmlxsw_sp_flower_parse_ipv6(rulei, f);\n\n\terr = mlxsw_sp_flower_parse_ports(mlxsw_sp, rulei, f, ip_proto);\n\tif (err)\n\t\treturn err;\n\n\terr = mlxsw_sp_flower_parse_ports_range(mlxsw_sp, rulei, f, ip_proto);\n\tif (err)\n\t\treturn err;\n\n\terr = mlxsw_sp_flower_parse_tcp(mlxsw_sp, rulei, f, ip_proto);\n\tif (err)\n\t\treturn err;\n\n\terr = mlxsw_sp_flower_parse_ip(mlxsw_sp, rulei, f, n_proto_key & n_proto_mask);\n\tif (err)\n\t\treturn err;\n\n\treturn mlxsw_sp_flower_parse_actions(mlxsw_sp, block, rulei,\n\t\t\t\t\t     &f->rule->action,\n\t\t\t\t\t     f->common.extack);\n}\n\nstatic int mlxsw_sp_flower_mall_prio_check(struct mlxsw_sp_flow_block *block,\n\t\t\t\t\t   struct flow_cls_offload *f)\n{\n\tbool ingress = mlxsw_sp_flow_block_is_ingress_bound(block);\n\tunsigned int mall_min_prio;\n\tunsigned int mall_max_prio;\n\tint err;\n\n\terr = mlxsw_sp_mall_prio_get(block, f->common.chain_index,\n\t\t\t\t     &mall_min_prio, &mall_max_prio);\n\tif (err) {\n\t\tif (err == -ENOENT)\n\t\t\t \n\t\t\treturn 0;\n\t\tNL_SET_ERR_MSG(f->common.extack, \"Failed to get matchall priorities\");\n\t\treturn err;\n\t}\n\tif (ingress && f->common.prio <= mall_min_prio) {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"Failed to add in front of existing matchall rules\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\tif (!ingress && f->common.prio >= mall_max_prio) {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"Failed to add behind of existing matchall rules\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\treturn 0;\n}\n\nint mlxsw_sp_flower_replace(struct mlxsw_sp *mlxsw_sp,\n\t\t\t    struct mlxsw_sp_flow_block *block,\n\t\t\t    struct flow_cls_offload *f)\n{\n\tstruct mlxsw_sp_acl_rule_info *rulei;\n\tstruct mlxsw_sp_acl_ruleset *ruleset;\n\tstruct mlxsw_sp_acl_rule *rule;\n\tint err;\n\n\terr = mlxsw_sp_flower_mall_prio_check(block, f);\n\tif (err)\n\t\treturn err;\n\n\truleset = mlxsw_sp_acl_ruleset_get(mlxsw_sp, block,\n\t\t\t\t\t   f->common.chain_index,\n\t\t\t\t\t   MLXSW_SP_ACL_PROFILE_FLOWER, NULL);\n\tif (IS_ERR(ruleset))\n\t\treturn PTR_ERR(ruleset);\n\n\trule = mlxsw_sp_acl_rule_create(mlxsw_sp, ruleset, f->cookie, NULL,\n\t\t\t\t\tf->common.extack);\n\tif (IS_ERR(rule)) {\n\t\terr = PTR_ERR(rule);\n\t\tgoto err_rule_create;\n\t}\n\n\trulei = mlxsw_sp_acl_rule_rulei(rule);\n\terr = mlxsw_sp_flower_parse(mlxsw_sp, block, rulei, f);\n\tif (err)\n\t\tgoto err_flower_parse;\n\n\terr = mlxsw_sp_acl_rulei_commit(rulei);\n\tif (err)\n\t\tgoto err_rulei_commit;\n\n\terr = mlxsw_sp_acl_rule_add(mlxsw_sp, rule);\n\tif (err)\n\t\tgoto err_rule_add;\n\n\tmlxsw_sp_acl_ruleset_put(mlxsw_sp, ruleset);\n\treturn 0;\n\nerr_rule_add:\nerr_rulei_commit:\nerr_flower_parse:\n\tmlxsw_sp_acl_rule_destroy(mlxsw_sp, rule);\nerr_rule_create:\n\tmlxsw_sp_acl_ruleset_put(mlxsw_sp, ruleset);\n\treturn err;\n}\n\nvoid mlxsw_sp_flower_destroy(struct mlxsw_sp *mlxsw_sp,\n\t\t\t     struct mlxsw_sp_flow_block *block,\n\t\t\t     struct flow_cls_offload *f)\n{\n\tstruct mlxsw_sp_acl_ruleset *ruleset;\n\tstruct mlxsw_sp_acl_rule *rule;\n\n\truleset = mlxsw_sp_acl_ruleset_get(mlxsw_sp, block,\n\t\t\t\t\t   f->common.chain_index,\n\t\t\t\t\t   MLXSW_SP_ACL_PROFILE_FLOWER, NULL);\n\tif (IS_ERR(ruleset))\n\t\treturn;\n\n\trule = mlxsw_sp_acl_rule_lookup(mlxsw_sp, ruleset, f->cookie);\n\tif (rule) {\n\t\tmlxsw_sp_acl_rule_del(mlxsw_sp, rule);\n\t\tmlxsw_sp_acl_rule_destroy(mlxsw_sp, rule);\n\t}\n\n\tmlxsw_sp_acl_ruleset_put(mlxsw_sp, ruleset);\n}\n\nint mlxsw_sp_flower_stats(struct mlxsw_sp *mlxsw_sp,\n\t\t\t  struct mlxsw_sp_flow_block *block,\n\t\t\t  struct flow_cls_offload *f)\n{\n\tenum flow_action_hw_stats used_hw_stats = FLOW_ACTION_HW_STATS_DISABLED;\n\tstruct mlxsw_sp_acl_ruleset *ruleset;\n\tstruct mlxsw_sp_acl_rule *rule;\n\tu64 packets;\n\tu64 lastuse;\n\tu64 bytes;\n\tu64 drops;\n\tint err;\n\n\truleset = mlxsw_sp_acl_ruleset_get(mlxsw_sp, block,\n\t\t\t\t\t   f->common.chain_index,\n\t\t\t\t\t   MLXSW_SP_ACL_PROFILE_FLOWER, NULL);\n\tif (WARN_ON(IS_ERR(ruleset)))\n\t\treturn -EINVAL;\n\n\trule = mlxsw_sp_acl_rule_lookup(mlxsw_sp, ruleset, f->cookie);\n\tif (!rule)\n\t\treturn -EINVAL;\n\n\terr = mlxsw_sp_acl_rule_get_stats(mlxsw_sp, rule, &packets, &bytes,\n\t\t\t\t\t  &drops, &lastuse, &used_hw_stats);\n\tif (err)\n\t\tgoto err_rule_get_stats;\n\n\tflow_stats_update(&f->stats, bytes, packets, drops, lastuse,\n\t\t\t  used_hw_stats);\n\n\tmlxsw_sp_acl_ruleset_put(mlxsw_sp, ruleset);\n\treturn 0;\n\nerr_rule_get_stats:\n\tmlxsw_sp_acl_ruleset_put(mlxsw_sp, ruleset);\n\treturn err;\n}\n\nint mlxsw_sp_flower_tmplt_create(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t struct mlxsw_sp_flow_block *block,\n\t\t\t\t struct flow_cls_offload *f)\n{\n\tstruct mlxsw_sp_acl_ruleset *ruleset;\n\tstruct mlxsw_sp_acl_rule_info rulei;\n\tint err;\n\n\tmemset(&rulei, 0, sizeof(rulei));\n\terr = mlxsw_sp_flower_parse(mlxsw_sp, block, &rulei, f);\n\tif (err)\n\t\treturn err;\n\truleset = mlxsw_sp_acl_ruleset_get(mlxsw_sp, block,\n\t\t\t\t\t   f->common.chain_index,\n\t\t\t\t\t   MLXSW_SP_ACL_PROFILE_FLOWER,\n\t\t\t\t\t   &rulei.values.elusage);\n\n\t \n\treturn PTR_ERR_OR_ZERO(ruleset);\n}\n\nvoid mlxsw_sp_flower_tmplt_destroy(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t   struct mlxsw_sp_flow_block *block,\n\t\t\t\t   struct flow_cls_offload *f)\n{\n\tstruct mlxsw_sp_acl_ruleset *ruleset;\n\n\truleset = mlxsw_sp_acl_ruleset_get(mlxsw_sp, block,\n\t\t\t\t\t   f->common.chain_index,\n\t\t\t\t\t   MLXSW_SP_ACL_PROFILE_FLOWER, NULL);\n\tif (IS_ERR(ruleset))\n\t\treturn;\n\t \n\tmlxsw_sp_acl_ruleset_put(mlxsw_sp, ruleset);\n\tmlxsw_sp_acl_ruleset_put(mlxsw_sp, ruleset);\n}\n\nint mlxsw_sp_flower_prio_get(struct mlxsw_sp *mlxsw_sp,\n\t\t\t     struct mlxsw_sp_flow_block *block,\n\t\t\t     u32 chain_index, unsigned int *p_min_prio,\n\t\t\t     unsigned int *p_max_prio)\n{\n\tstruct mlxsw_sp_acl_ruleset *ruleset;\n\n\truleset = mlxsw_sp_acl_ruleset_lookup(mlxsw_sp, block,\n\t\t\t\t\t      chain_index,\n\t\t\t\t\t      MLXSW_SP_ACL_PROFILE_FLOWER);\n\tif (IS_ERR(ruleset))\n\t\t \n\t\treturn PTR_ERR(ruleset);\n\tmlxsw_sp_acl_ruleset_prio_get(ruleset, p_min_prio, p_max_prio);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}