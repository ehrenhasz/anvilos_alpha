{
  "module_name": "spectrum_qdisc.c",
  "hash_id": "134f7d64de72fe26b20dbe21d2492065d02dae2c007aa81a66b6f122d1729218",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlxsw/spectrum_qdisc.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/errno.h>\n#include <linux/netdevice.h>\n#include <net/pkt_cls.h>\n#include <net/red.h>\n\n#include \"spectrum.h\"\n#include \"spectrum_span.h\"\n#include \"reg.h\"\n\n#define MLXSW_SP_PRIO_BAND_TO_TCLASS(band) (IEEE_8021QAZ_MAX_TCS - band - 1)\n#define MLXSW_SP_PRIO_CHILD_TO_TCLASS(child) \\\n\tMLXSW_SP_PRIO_BAND_TO_TCLASS((child - 1))\n\nenum mlxsw_sp_qdisc_type {\n\tMLXSW_SP_QDISC_NO_QDISC,\n\tMLXSW_SP_QDISC_RED,\n\tMLXSW_SP_QDISC_PRIO,\n\tMLXSW_SP_QDISC_ETS,\n\tMLXSW_SP_QDISC_TBF,\n\tMLXSW_SP_QDISC_FIFO,\n};\n\nstruct mlxsw_sp_qdisc;\n\nstruct mlxsw_sp_qdisc_ops {\n\tenum mlxsw_sp_qdisc_type type;\n\tint (*check_params)(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t    void *params);\n\tint (*replace)(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t       struct mlxsw_sp_qdisc *mlxsw_sp_qdisc, void *params);\n\tint (*destroy)(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t       struct mlxsw_sp_qdisc *mlxsw_sp_qdisc);\n\tint (*get_stats)(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t struct tc_qopt_offload_stats *stats_ptr);\n\tint (*get_xstats)(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t  struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t  void *xstats_ptr);\n\tvoid (*clean_stats)(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t    struct mlxsw_sp_qdisc *mlxsw_sp_qdisc);\n\t \n\tvoid (*unoffload)(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t  struct mlxsw_sp_qdisc *mlxsw_sp_qdisc, void *params);\n\tstruct mlxsw_sp_qdisc *(*find_class)(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\t\t     u32 parent);\n\tunsigned int num_classes;\n\n\tu8 (*get_prio_bitmap)(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t      struct mlxsw_sp_qdisc *child);\n\tint (*get_tclass_num)(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t      struct mlxsw_sp_qdisc *child);\n};\n\nstruct mlxsw_sp_qdisc_ets_band {\n\tu8 prio_bitmap;\n\tint tclass_num;\n};\n\nstruct mlxsw_sp_qdisc_ets_data {\n\tstruct mlxsw_sp_qdisc_ets_band bands[IEEE_8021QAZ_MAX_TCS];\n};\n\nstruct mlxsw_sp_qdisc {\n\tu32 handle;\n\tunion {\n\t\tstruct red_stats red;\n\t} xstats_base;\n\tstruct mlxsw_sp_qdisc_stats {\n\t\tu64 tx_bytes;\n\t\tu64 tx_packets;\n\t\tu64 drops;\n\t\tu64 overlimits;\n\t\tu64 backlog;\n\t} stats_base;\n\n\tunion {\n\t\tstruct mlxsw_sp_qdisc_ets_data *ets_data;\n\t};\n\n\tstruct mlxsw_sp_qdisc_ops *ops;\n\tstruct mlxsw_sp_qdisc *parent;\n\tstruct mlxsw_sp_qdisc *qdiscs;\n\tunsigned int num_classes;\n};\n\nstruct mlxsw_sp_qdisc_state {\n\tstruct mlxsw_sp_qdisc root_qdisc;\n\n\t \n\tu32 future_handle;\n\tbool future_fifos[IEEE_8021QAZ_MAX_TCS];\n\tstruct mutex lock;  \n};\n\nstatic bool\nmlxsw_sp_qdisc_compare(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc, u32 handle)\n{\n\treturn mlxsw_sp_qdisc->ops && mlxsw_sp_qdisc->handle == handle;\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_walk(struct mlxsw_sp_qdisc *qdisc,\n\t\t    struct mlxsw_sp_qdisc *(*pre)(struct mlxsw_sp_qdisc *,\n\t\t\t\t\t\t  void *),\n\t\t    void *data)\n{\n\tstruct mlxsw_sp_qdisc *tmp;\n\tunsigned int i;\n\n\tif (pre) {\n\t\ttmp = pre(qdisc, data);\n\t\tif (tmp)\n\t\t\treturn tmp;\n\t}\n\n\tif (qdisc->ops) {\n\t\tfor (i = 0; i < qdisc->num_classes; i++) {\n\t\t\ttmp = &qdisc->qdiscs[i];\n\t\t\tif (qdisc->ops) {\n\t\t\t\ttmp = mlxsw_sp_qdisc_walk(tmp, pre, data);\n\t\t\t\tif (tmp)\n\t\t\t\t\treturn tmp;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_walk_cb_find(struct mlxsw_sp_qdisc *qdisc, void *data)\n{\n\tu32 parent = *(u32 *)data;\n\n\tif (qdisc->ops && TC_H_MAJ(qdisc->handle) == TC_H_MAJ(parent)) {\n\t\tif (qdisc->ops->find_class)\n\t\t\treturn qdisc->ops->find_class(qdisc, parent);\n\t}\n\n\treturn NULL;\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_find(struct mlxsw_sp_port *mlxsw_sp_port, u32 parent)\n{\n\tstruct mlxsw_sp_qdisc_state *qdisc_state = mlxsw_sp_port->qdisc;\n\n\tif (!qdisc_state)\n\t\treturn NULL;\n\tif (parent == TC_H_ROOT)\n\t\treturn &qdisc_state->root_qdisc;\n\treturn mlxsw_sp_qdisc_walk(&qdisc_state->root_qdisc,\n\t\t\t\t   mlxsw_sp_qdisc_walk_cb_find, &parent);\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_walk_cb_find_by_handle(struct mlxsw_sp_qdisc *qdisc, void *data)\n{\n\tu32 handle = *(u32 *)data;\n\n\tif (qdisc->ops && qdisc->handle == handle)\n\t\treturn qdisc;\n\treturn NULL;\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_find_by_handle(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle)\n{\n\tstruct mlxsw_sp_qdisc_state *qdisc_state = mlxsw_sp_port->qdisc;\n\n\tif (!qdisc_state)\n\t\treturn NULL;\n\treturn mlxsw_sp_qdisc_walk(&qdisc_state->root_qdisc,\n\t\t\t\t   mlxsw_sp_qdisc_walk_cb_find_by_handle,\n\t\t\t\t   &handle);\n}\n\nstatic void\nmlxsw_sp_qdisc_reduce_parent_backlog(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tstruct mlxsw_sp_qdisc *tmp;\n\n\tfor (tmp = mlxsw_sp_qdisc->parent; tmp; tmp = tmp->parent)\n\t\ttmp->stats_base.backlog -= mlxsw_sp_qdisc->stats_base.backlog;\n}\n\nstatic u8 mlxsw_sp_qdisc_get_prio_bitmap(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\t struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tstruct mlxsw_sp_qdisc *parent = mlxsw_sp_qdisc->parent;\n\n\tif (!parent)\n\t\treturn 0xff;\n\tif (!parent->ops->get_prio_bitmap)\n\t\treturn mlxsw_sp_qdisc_get_prio_bitmap(mlxsw_sp_port, parent);\n\treturn parent->ops->get_prio_bitmap(parent, mlxsw_sp_qdisc);\n}\n\n#define MLXSW_SP_PORT_DEFAULT_TCLASS 0\n\nstatic int mlxsw_sp_qdisc_get_tclass_num(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\t struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tstruct mlxsw_sp_qdisc *parent = mlxsw_sp_qdisc->parent;\n\n\tif (!parent)\n\t\treturn MLXSW_SP_PORT_DEFAULT_TCLASS;\n\tif (!parent->ops->get_tclass_num)\n\t\treturn mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port, parent);\n\treturn parent->ops->get_tclass_num(parent, mlxsw_sp_qdisc);\n}\n\nstatic int\nmlxsw_sp_qdisc_destroy(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t       struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tstruct mlxsw_sp_qdisc *root_qdisc = &mlxsw_sp_port->qdisc->root_qdisc;\n\tint err_hdroom = 0;\n\tint err = 0;\n\tint i;\n\n\tif (!mlxsw_sp_qdisc)\n\t\treturn 0;\n\n\tif (root_qdisc == mlxsw_sp_qdisc) {\n\t\tstruct mlxsw_sp_hdroom hdroom = *mlxsw_sp_port->hdroom;\n\n\t\thdroom.mode = MLXSW_SP_HDROOM_MODE_DCB;\n\t\tmlxsw_sp_hdroom_prios_reset_buf_idx(&hdroom);\n\t\tmlxsw_sp_hdroom_bufs_reset_lossiness(&hdroom);\n\t\tmlxsw_sp_hdroom_bufs_reset_sizes(mlxsw_sp_port, &hdroom);\n\t\terr_hdroom = mlxsw_sp_hdroom_configure(mlxsw_sp_port, &hdroom);\n\t}\n\n\tif (!mlxsw_sp_qdisc->ops)\n\t\treturn 0;\n\n\tfor (i = 0; i < mlxsw_sp_qdisc->num_classes; i++)\n\t\tmlxsw_sp_qdisc_destroy(mlxsw_sp_port,\n\t\t\t\t       &mlxsw_sp_qdisc->qdiscs[i]);\n\tmlxsw_sp_qdisc_reduce_parent_backlog(mlxsw_sp_qdisc);\n\tif (mlxsw_sp_qdisc->ops->destroy)\n\t\terr = mlxsw_sp_qdisc->ops->destroy(mlxsw_sp_port,\n\t\t\t\t\t\t   mlxsw_sp_qdisc);\n\tif (mlxsw_sp_qdisc->ops->clean_stats)\n\t\tmlxsw_sp_qdisc->ops->clean_stats(mlxsw_sp_port, mlxsw_sp_qdisc);\n\n\tmlxsw_sp_qdisc->handle = TC_H_UNSPEC;\n\tmlxsw_sp_qdisc->ops = NULL;\n\tmlxsw_sp_qdisc->num_classes = 0;\n\tkfree(mlxsw_sp_qdisc->qdiscs);\n\tmlxsw_sp_qdisc->qdiscs = NULL;\n\treturn err_hdroom ?: err;\n}\n\nstruct mlxsw_sp_qdisc_tree_validate {\n\tbool forbid_ets;\n\tbool forbid_root_tbf;\n\tbool forbid_tbf;\n\tbool forbid_red;\n};\n\nstatic int\n__mlxsw_sp_qdisc_tree_validate(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t       struct mlxsw_sp_qdisc_tree_validate validate);\n\nstatic int\nmlxsw_sp_qdisc_tree_validate_children(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\t      struct mlxsw_sp_qdisc_tree_validate validate)\n{\n\tunsigned int i;\n\tint err;\n\n\tfor (i = 0; i < mlxsw_sp_qdisc->num_classes; i++) {\n\t\terr = __mlxsw_sp_qdisc_tree_validate(&mlxsw_sp_qdisc->qdiscs[i],\n\t\t\t\t\t\t     validate);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int\n__mlxsw_sp_qdisc_tree_validate(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t       struct mlxsw_sp_qdisc_tree_validate validate)\n{\n\tif (!mlxsw_sp_qdisc->ops)\n\t\treturn 0;\n\n\tswitch (mlxsw_sp_qdisc->ops->type) {\n\tcase MLXSW_SP_QDISC_FIFO:\n\t\tbreak;\n\tcase MLXSW_SP_QDISC_RED:\n\t\tif (validate.forbid_red)\n\t\t\treturn -EINVAL;\n\t\tvalidate.forbid_red = true;\n\t\tvalidate.forbid_root_tbf = true;\n\t\tvalidate.forbid_ets = true;\n\t\tbreak;\n\tcase MLXSW_SP_QDISC_TBF:\n\t\tif (validate.forbid_root_tbf) {\n\t\t\tif (validate.forbid_tbf)\n\t\t\t\treturn -EINVAL;\n\t\t\t \n\t\t\tvalidate.forbid_tbf = true;\n\t\t\tvalidate.forbid_ets = true;\n\t\t} else {\n\t\t\t \n\t\t\tvalidate.forbid_root_tbf = true;\n\t\t}\n\t\tbreak;\n\tcase MLXSW_SP_QDISC_PRIO:\n\tcase MLXSW_SP_QDISC_ETS:\n\t\tif (validate.forbid_ets)\n\t\t\treturn -EINVAL;\n\t\tvalidate.forbid_root_tbf = true;\n\t\tvalidate.forbid_ets = true;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -EINVAL;\n\t}\n\n\treturn mlxsw_sp_qdisc_tree_validate_children(mlxsw_sp_qdisc, validate);\n}\n\nstatic int mlxsw_sp_qdisc_tree_validate(struct mlxsw_sp_port *mlxsw_sp_port)\n{\n\tstruct mlxsw_sp_qdisc_tree_validate validate = {};\n\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc;\n\n\tmlxsw_sp_qdisc = &mlxsw_sp_port->qdisc->root_qdisc;\n\treturn __mlxsw_sp_qdisc_tree_validate(mlxsw_sp_qdisc, validate);\n}\n\nstatic int mlxsw_sp_qdisc_create(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t u32 handle,\n\t\t\t\t struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\t struct mlxsw_sp_qdisc_ops *ops, void *params)\n{\n\tstruct mlxsw_sp_qdisc *root_qdisc = &mlxsw_sp_port->qdisc->root_qdisc;\n\tstruct mlxsw_sp_hdroom orig_hdroom;\n\tunsigned int i;\n\tint err;\n\n\terr = ops->check_params(mlxsw_sp_port, params);\n\tif (err)\n\t\treturn err;\n\n\tif (ops->num_classes) {\n\t\tmlxsw_sp_qdisc->qdiscs = kcalloc(ops->num_classes,\n\t\t\t\t\t\t sizeof(*mlxsw_sp_qdisc->qdiscs),\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (!mlxsw_sp_qdisc->qdiscs)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < ops->num_classes; i++)\n\t\t\tmlxsw_sp_qdisc->qdiscs[i].parent = mlxsw_sp_qdisc;\n\t}\n\n\torig_hdroom = *mlxsw_sp_port->hdroom;\n\tif (root_qdisc == mlxsw_sp_qdisc) {\n\t\tstruct mlxsw_sp_hdroom hdroom = orig_hdroom;\n\n\t\thdroom.mode = MLXSW_SP_HDROOM_MODE_TC;\n\t\tmlxsw_sp_hdroom_prios_reset_buf_idx(&hdroom);\n\t\tmlxsw_sp_hdroom_bufs_reset_lossiness(&hdroom);\n\t\tmlxsw_sp_hdroom_bufs_reset_sizes(mlxsw_sp_port, &hdroom);\n\n\t\terr = mlxsw_sp_hdroom_configure(mlxsw_sp_port, &hdroom);\n\t\tif (err)\n\t\t\tgoto err_hdroom_configure;\n\t}\n\n\tmlxsw_sp_qdisc->num_classes = ops->num_classes;\n\tmlxsw_sp_qdisc->ops = ops;\n\tmlxsw_sp_qdisc->handle = handle;\n\terr = mlxsw_sp_qdisc_tree_validate(mlxsw_sp_port);\n\tif (err)\n\t\tgoto err_replace;\n\n\terr = ops->replace(mlxsw_sp_port, handle, mlxsw_sp_qdisc, params);\n\tif (err)\n\t\tgoto err_replace;\n\n\treturn 0;\n\nerr_replace:\n\tmlxsw_sp_qdisc->handle = TC_H_UNSPEC;\n\tmlxsw_sp_qdisc->ops = NULL;\n\tmlxsw_sp_qdisc->num_classes = 0;\n\tmlxsw_sp_hdroom_configure(mlxsw_sp_port, &orig_hdroom);\nerr_hdroom_configure:\n\tkfree(mlxsw_sp_qdisc->qdiscs);\n\tmlxsw_sp_qdisc->qdiscs = NULL;\n\treturn err;\n}\n\nstatic int\nmlxsw_sp_qdisc_change(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t      struct mlxsw_sp_qdisc *mlxsw_sp_qdisc, void *params)\n{\n\tstruct mlxsw_sp_qdisc_ops *ops = mlxsw_sp_qdisc->ops;\n\tint err;\n\n\terr = ops->check_params(mlxsw_sp_port, params);\n\tif (err)\n\t\tgoto unoffload;\n\n\terr = ops->replace(mlxsw_sp_port, handle, mlxsw_sp_qdisc, params);\n\tif (err)\n\t\tgoto unoffload;\n\n\t \n\tif (mlxsw_sp_qdisc->handle != handle) {\n\t\tif (ops->clean_stats)\n\t\t\tops->clean_stats(mlxsw_sp_port, mlxsw_sp_qdisc);\n\t}\n\n\tmlxsw_sp_qdisc->handle = handle;\n\treturn 0;\n\nunoffload:\n\tif (ops->unoffload)\n\t\tops->unoffload(mlxsw_sp_port, mlxsw_sp_qdisc, params);\n\n\tmlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\treturn err;\n}\n\nstatic int\nmlxsw_sp_qdisc_replace(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t       struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t       struct mlxsw_sp_qdisc_ops *ops, void *params)\n{\n\tif (mlxsw_sp_qdisc->ops && mlxsw_sp_qdisc->ops->type != ops->type)\n\t\t \n\t\tmlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\n\tif (!mlxsw_sp_qdisc->ops)\n\t\treturn mlxsw_sp_qdisc_create(mlxsw_sp_port, handle,\n\t\t\t\t\t     mlxsw_sp_qdisc, ops, params);\n\telse\n\t\treturn mlxsw_sp_qdisc_change(mlxsw_sp_port, handle,\n\t\t\t\t\t     mlxsw_sp_qdisc, params);\n}\n\nstatic int\nmlxsw_sp_qdisc_get_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t struct tc_qopt_offload_stats *stats_ptr)\n{\n\tif (mlxsw_sp_qdisc && mlxsw_sp_qdisc->ops &&\n\t    mlxsw_sp_qdisc->ops->get_stats)\n\t\treturn mlxsw_sp_qdisc->ops->get_stats(mlxsw_sp_port,\n\t\t\t\t\t\t      mlxsw_sp_qdisc,\n\t\t\t\t\t\t      stats_ptr);\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int\nmlxsw_sp_qdisc_get_xstats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t  struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t  void *xstats_ptr)\n{\n\tif (mlxsw_sp_qdisc && mlxsw_sp_qdisc->ops &&\n\t    mlxsw_sp_qdisc->ops->get_xstats)\n\t\treturn mlxsw_sp_qdisc->ops->get_xstats(mlxsw_sp_port,\n\t\t\t\t\t\t      mlxsw_sp_qdisc,\n\t\t\t\t\t\t      xstats_ptr);\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic u64\nmlxsw_sp_xstats_backlog(struct mlxsw_sp_port_xstats *xstats, int tclass_num)\n{\n\treturn xstats->backlog[tclass_num] +\n\t       xstats->backlog[tclass_num + 8];\n}\n\nstatic u64\nmlxsw_sp_xstats_tail_drop(struct mlxsw_sp_port_xstats *xstats, int tclass_num)\n{\n\treturn xstats->tail_drop[tclass_num] +\n\t       xstats->tail_drop[tclass_num + 8];\n}\n\nstatic void\nmlxsw_sp_qdisc_bstats_per_priority_get(struct mlxsw_sp_port_xstats *xstats,\n\t\t\t\t       u8 prio_bitmap, u64 *tx_packets,\n\t\t\t\t       u64 *tx_bytes)\n{\n\tint i;\n\n\t*tx_packets = 0;\n\t*tx_bytes = 0;\n\tfor (i = 0; i < IEEE_8021QAZ_MAX_TCS; i++) {\n\t\tif (prio_bitmap & BIT(i)) {\n\t\t\t*tx_packets += xstats->tx_packets[i];\n\t\t\t*tx_bytes += xstats->tx_bytes[i];\n\t\t}\n\t}\n}\n\nstatic void\nmlxsw_sp_qdisc_collect_tc_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\tu64 *p_tx_bytes, u64 *p_tx_packets,\n\t\t\t\tu64 *p_drops, u64 *p_backlog)\n{\n\tstruct mlxsw_sp_port_xstats *xstats;\n\tu64 tx_bytes, tx_packets;\n\tu8 prio_bitmap;\n\tint tclass_num;\n\n\tprio_bitmap = mlxsw_sp_qdisc_get_prio_bitmap(mlxsw_sp_port,\n\t\t\t\t\t\t     mlxsw_sp_qdisc);\n\ttclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t   mlxsw_sp_qdisc);\n\txstats = &mlxsw_sp_port->periodic_hw_stats.xstats;\n\tmlxsw_sp_qdisc_bstats_per_priority_get(xstats, prio_bitmap,\n\t\t\t\t\t       &tx_packets, &tx_bytes);\n\n\t*p_tx_packets += tx_packets;\n\t*p_tx_bytes += tx_bytes;\n\t*p_drops += xstats->wred_drop[tclass_num] +\n\t\t    mlxsw_sp_xstats_tail_drop(xstats, tclass_num);\n\t*p_backlog += mlxsw_sp_xstats_backlog(xstats, tclass_num);\n}\n\nstatic void\nmlxsw_sp_qdisc_update_stats(struct mlxsw_sp *mlxsw_sp,\n\t\t\t    struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t    u64 tx_bytes, u64 tx_packets,\n\t\t\t    u64 drops, u64 backlog,\n\t\t\t    struct tc_qopt_offload_stats *stats_ptr)\n{\n\tstruct mlxsw_sp_qdisc_stats *stats_base = &mlxsw_sp_qdisc->stats_base;\n\n\ttx_bytes -= stats_base->tx_bytes;\n\ttx_packets -= stats_base->tx_packets;\n\tdrops -= stats_base->drops;\n\tbacklog -= stats_base->backlog;\n\n\t_bstats_update(stats_ptr->bstats, tx_bytes, tx_packets);\n\tstats_ptr->qstats->drops += drops;\n\tstats_ptr->qstats->backlog += mlxsw_sp_cells_bytes(mlxsw_sp, backlog);\n\n\tstats_base->backlog += backlog;\n\tstats_base->drops += drops;\n\tstats_base->tx_bytes += tx_bytes;\n\tstats_base->tx_packets += tx_packets;\n}\n\nstatic void\nmlxsw_sp_qdisc_get_tc_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t    struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t    struct tc_qopt_offload_stats *stats_ptr)\n{\n\tu64 tx_packets = 0;\n\tu64 tx_bytes = 0;\n\tu64 backlog = 0;\n\tu64 drops = 0;\n\n\tmlxsw_sp_qdisc_collect_tc_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t&tx_bytes, &tx_packets,\n\t\t\t\t\t&drops, &backlog);\n\tmlxsw_sp_qdisc_update_stats(mlxsw_sp_port->mlxsw_sp, mlxsw_sp_qdisc,\n\t\t\t\t    tx_bytes, tx_packets, drops, backlog,\n\t\t\t\t    stats_ptr);\n}\n\nstatic int\nmlxsw_sp_tclass_congestion_enable(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t  int tclass_num, u32 min, u32 max,\n\t\t\t\t  u32 probability, bool is_wred, bool is_ecn)\n{\n\tchar cwtpm_cmd[MLXSW_REG_CWTPM_LEN];\n\tchar cwtp_cmd[MLXSW_REG_CWTP_LEN];\n\tstruct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;\n\tint err;\n\n\tmlxsw_reg_cwtp_pack(cwtp_cmd, mlxsw_sp_port->local_port, tclass_num);\n\tmlxsw_reg_cwtp_profile_pack(cwtp_cmd, MLXSW_REG_CWTP_DEFAULT_PROFILE,\n\t\t\t\t    roundup(min, MLXSW_REG_CWTP_MIN_VALUE),\n\t\t\t\t    roundup(max, MLXSW_REG_CWTP_MIN_VALUE),\n\t\t\t\t    probability);\n\n\terr = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(cwtp), cwtp_cmd);\n\tif (err)\n\t\treturn err;\n\n\tmlxsw_reg_cwtpm_pack(cwtpm_cmd, mlxsw_sp_port->local_port, tclass_num,\n\t\t\t     MLXSW_REG_CWTP_DEFAULT_PROFILE, is_wred, is_ecn);\n\n\treturn mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(cwtpm), cwtpm_cmd);\n}\n\nstatic int\nmlxsw_sp_tclass_congestion_disable(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t   int tclass_num)\n{\n\tstruct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;\n\tchar cwtpm_cmd[MLXSW_REG_CWTPM_LEN];\n\n\tmlxsw_reg_cwtpm_pack(cwtpm_cmd, mlxsw_sp_port->local_port, tclass_num,\n\t\t\t     MLXSW_REG_CWTPM_RESET_PROFILE, false, false);\n\treturn mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(cwtpm), cwtpm_cmd);\n}\n\nstatic void\nmlxsw_sp_setup_tc_qdisc_red_clean_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tstruct mlxsw_sp_qdisc_stats *stats_base;\n\tstruct mlxsw_sp_port_xstats *xstats;\n\tstruct red_stats *red_base;\n\tu8 prio_bitmap;\n\tint tclass_num;\n\n\tprio_bitmap = mlxsw_sp_qdisc_get_prio_bitmap(mlxsw_sp_port,\n\t\t\t\t\t\t     mlxsw_sp_qdisc);\n\ttclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t   mlxsw_sp_qdisc);\n\txstats = &mlxsw_sp_port->periodic_hw_stats.xstats;\n\tstats_base = &mlxsw_sp_qdisc->stats_base;\n\tred_base = &mlxsw_sp_qdisc->xstats_base.red;\n\n\tmlxsw_sp_qdisc_bstats_per_priority_get(xstats, prio_bitmap,\n\t\t\t\t\t       &stats_base->tx_packets,\n\t\t\t\t\t       &stats_base->tx_bytes);\n\tred_base->prob_mark = xstats->tc_ecn[tclass_num];\n\tred_base->prob_drop = xstats->wred_drop[tclass_num];\n\tred_base->pdrop = mlxsw_sp_xstats_tail_drop(xstats, tclass_num);\n\n\tstats_base->overlimits = red_base->prob_drop + red_base->prob_mark;\n\tstats_base->drops = red_base->prob_drop + red_base->pdrop;\n\n\tstats_base->backlog = 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_red_destroy(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t   struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tint tclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t       mlxsw_sp_qdisc);\n\n\treturn mlxsw_sp_tclass_congestion_disable(mlxsw_sp_port, tclass_num);\n}\n\nstatic int\nmlxsw_sp_qdisc_red_check_params(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\tvoid *params)\n{\n\tstruct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;\n\tstruct tc_red_qopt_offload_params *p = params;\n\n\tif (p->min > p->max) {\n\t\tdev_err(mlxsw_sp->bus_info->dev,\n\t\t\t\"spectrum: RED: min %u is bigger then max %u\\n\", p->min,\n\t\t\tp->max);\n\t\treturn -EINVAL;\n\t}\n\tif (p->max > MLXSW_CORE_RES_GET(mlxsw_sp->core,\n\t\t\t\t\tGUARANTEED_SHARED_BUFFER)) {\n\t\tdev_err(mlxsw_sp->bus_info->dev,\n\t\t\t\"spectrum: RED: max value %u is too big\\n\", p->max);\n\t\treturn -EINVAL;\n\t}\n\tif (p->min == 0 || p->max == 0) {\n\t\tdev_err(mlxsw_sp->bus_info->dev,\n\t\t\t\"spectrum: RED: 0 value is illegal for min and max\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_future_fifo_replace(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t   u32 handle, unsigned int band,\n\t\t\t\t   struct mlxsw_sp_qdisc *child_qdisc);\nstatic void\nmlxsw_sp_qdisc_future_fifos_init(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t u32 handle);\n\nstatic int\nmlxsw_sp_qdisc_red_replace(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t\t   struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t   void *params)\n{\n\tstruct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;\n\tstruct tc_red_qopt_offload_params *p = params;\n\tint tclass_num;\n\tu32 min, max;\n\tu64 prob;\n\tint err;\n\n\terr = mlxsw_sp_qdisc_future_fifo_replace(mlxsw_sp_port, handle, 0,\n\t\t\t\t\t\t &mlxsw_sp_qdisc->qdiscs[0]);\n\tif (err)\n\t\treturn err;\n\tmlxsw_sp_qdisc_future_fifos_init(mlxsw_sp_port, TC_H_UNSPEC);\n\n\ttclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t   mlxsw_sp_qdisc);\n\n\t \n\tprob = p->probability;\n\tprob *= 100;\n\tprob = DIV_ROUND_UP(prob, 1 << 16);\n\tprob = DIV_ROUND_UP(prob, 1 << 16);\n\tmin = mlxsw_sp_bytes_cells(mlxsw_sp, p->min);\n\tmax = mlxsw_sp_bytes_cells(mlxsw_sp, p->max);\n\treturn mlxsw_sp_tclass_congestion_enable(mlxsw_sp_port, tclass_num,\n\t\t\t\t\t\t min, max, prob,\n\t\t\t\t\t\t !p->is_nodrop, p->is_ecn);\n}\n\nstatic void\nmlxsw_sp_qdisc_leaf_unoffload(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t      struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t      struct gnet_stats_queue *qstats)\n{\n\tu64 backlog;\n\n\tbacklog = mlxsw_sp_cells_bytes(mlxsw_sp_port->mlxsw_sp,\n\t\t\t\t       mlxsw_sp_qdisc->stats_base.backlog);\n\tqstats->backlog -= backlog;\n\tmlxsw_sp_qdisc->stats_base.backlog = 0;\n}\n\nstatic void\nmlxsw_sp_qdisc_red_unoffload(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t     struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t     void *params)\n{\n\tstruct tc_red_qopt_offload_params *p = params;\n\n\tmlxsw_sp_qdisc_leaf_unoffload(mlxsw_sp_port, mlxsw_sp_qdisc, p->qstats);\n}\n\nstatic int\nmlxsw_sp_qdisc_get_red_xstats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t      struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t      void *xstats_ptr)\n{\n\tstruct red_stats *xstats_base = &mlxsw_sp_qdisc->xstats_base.red;\n\tstruct mlxsw_sp_port_xstats *xstats;\n\tstruct red_stats *res = xstats_ptr;\n\tint early_drops, marks, pdrops;\n\tint tclass_num;\n\n\ttclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t   mlxsw_sp_qdisc);\n\txstats = &mlxsw_sp_port->periodic_hw_stats.xstats;\n\n\tearly_drops = xstats->wred_drop[tclass_num] - xstats_base->prob_drop;\n\tmarks = xstats->tc_ecn[tclass_num] - xstats_base->prob_mark;\n\tpdrops = mlxsw_sp_xstats_tail_drop(xstats, tclass_num) -\n\t\t xstats_base->pdrop;\n\n\tres->pdrop += pdrops;\n\tres->prob_drop += early_drops;\n\tres->prob_mark += marks;\n\n\txstats_base->pdrop += pdrops;\n\txstats_base->prob_drop += early_drops;\n\txstats_base->prob_mark += marks;\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_get_red_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t     struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t     struct tc_qopt_offload_stats *stats_ptr)\n{\n\tstruct mlxsw_sp_qdisc_stats *stats_base;\n\tstruct mlxsw_sp_port_xstats *xstats;\n\tu64 overlimits;\n\tint tclass_num;\n\n\ttclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t   mlxsw_sp_qdisc);\n\txstats = &mlxsw_sp_port->periodic_hw_stats.xstats;\n\tstats_base = &mlxsw_sp_qdisc->stats_base;\n\n\tmlxsw_sp_qdisc_get_tc_stats(mlxsw_sp_port, mlxsw_sp_qdisc, stats_ptr);\n\toverlimits = xstats->wred_drop[tclass_num] +\n\t\t     xstats->tc_ecn[tclass_num] - stats_base->overlimits;\n\n\tstats_ptr->qstats->overlimits += overlimits;\n\tstats_base->overlimits += overlimits;\n\n\treturn 0;\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_leaf_find_class(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t       u32 parent)\n{\n\t \n\treturn &mlxsw_sp_qdisc->qdiscs[0];\n}\n\nstatic struct mlxsw_sp_qdisc_ops mlxsw_sp_qdisc_ops_red = {\n\t.type = MLXSW_SP_QDISC_RED,\n\t.check_params = mlxsw_sp_qdisc_red_check_params,\n\t.replace = mlxsw_sp_qdisc_red_replace,\n\t.unoffload = mlxsw_sp_qdisc_red_unoffload,\n\t.destroy = mlxsw_sp_qdisc_red_destroy,\n\t.get_stats = mlxsw_sp_qdisc_get_red_stats,\n\t.get_xstats = mlxsw_sp_qdisc_get_red_xstats,\n\t.clean_stats = mlxsw_sp_setup_tc_qdisc_red_clean_stats,\n\t.find_class = mlxsw_sp_qdisc_leaf_find_class,\n\t.num_classes = 1,\n};\n\nstatic int mlxsw_sp_qdisc_graft(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\tu8 band, u32 child_handle);\n\nstatic int __mlxsw_sp_setup_tc_red(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t   struct tc_red_qopt_offload *p)\n{\n\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc;\n\n\tmlxsw_sp_qdisc = mlxsw_sp_qdisc_find(mlxsw_sp_port, p->parent);\n\tif (!mlxsw_sp_qdisc)\n\t\treturn -EOPNOTSUPP;\n\n\tif (p->command == TC_RED_REPLACE)\n\t\treturn mlxsw_sp_qdisc_replace(mlxsw_sp_port, p->handle,\n\t\t\t\t\t      mlxsw_sp_qdisc,\n\t\t\t\t\t      &mlxsw_sp_qdisc_ops_red,\n\t\t\t\t\t      &p->set);\n\n\tif (!mlxsw_sp_qdisc_compare(mlxsw_sp_qdisc, p->handle))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (p->command) {\n\tcase TC_RED_DESTROY:\n\t\treturn mlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\tcase TC_RED_XSTATS:\n\t\treturn mlxsw_sp_qdisc_get_xstats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t\t p->xstats);\n\tcase TC_RED_STATS:\n\t\treturn mlxsw_sp_qdisc_get_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t\t&p->stats);\n\tcase TC_RED_GRAFT:\n\t\treturn mlxsw_sp_qdisc_graft(mlxsw_sp_port, mlxsw_sp_qdisc, 0,\n\t\t\t\t\t    p->child_handle);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nint mlxsw_sp_setup_tc_red(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t  struct tc_red_qopt_offload *p)\n{\n\tint err;\n\n\tmutex_lock(&mlxsw_sp_port->qdisc->lock);\n\terr = __mlxsw_sp_setup_tc_red(mlxsw_sp_port, p);\n\tmutex_unlock(&mlxsw_sp_port->qdisc->lock);\n\n\treturn err;\n}\n\nstatic void\nmlxsw_sp_setup_tc_qdisc_leaf_clean_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\t struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tu64 backlog_cells = 0;\n\tu64 tx_packets = 0;\n\tu64 tx_bytes = 0;\n\tu64 drops = 0;\n\n\tmlxsw_sp_qdisc_collect_tc_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t&tx_bytes, &tx_packets,\n\t\t\t\t\t&drops, &backlog_cells);\n\n\tmlxsw_sp_qdisc->stats_base.tx_packets = tx_packets;\n\tmlxsw_sp_qdisc->stats_base.tx_bytes = tx_bytes;\n\tmlxsw_sp_qdisc->stats_base.drops = drops;\n\tmlxsw_sp_qdisc->stats_base.backlog = 0;\n}\n\nstatic enum mlxsw_reg_qeec_hr\nmlxsw_sp_qdisc_tbf_hr(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t      struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tif (mlxsw_sp_qdisc == &mlxsw_sp_port->qdisc->root_qdisc)\n\t\treturn MLXSW_REG_QEEC_HR_PORT;\n\n\t \n\treturn MLXSW_REG_QEEC_HR_SUBGROUP;\n}\n\nstatic int\nmlxsw_sp_qdisc_tbf_destroy(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t   struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tenum mlxsw_reg_qeec_hr hr = mlxsw_sp_qdisc_tbf_hr(mlxsw_sp_port,\n\t\t\t\t\t\t\t  mlxsw_sp_qdisc);\n\tint tclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t       mlxsw_sp_qdisc);\n\n\treturn mlxsw_sp_port_ets_maxrate_set(mlxsw_sp_port, hr, tclass_num, 0,\n\t\t\t\t\t     MLXSW_REG_QEEC_MAS_DIS, 0);\n}\n\nstatic int\nmlxsw_sp_qdisc_tbf_bs(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t      u32 max_size, u8 *p_burst_size)\n{\n\t \n\tu32 bs512 = max_size / 64;\n\tu8 bs = fls(bs512);\n\n\tif (!bs)\n\t\treturn -EINVAL;\n\t--bs;\n\n\t \n\tif ((1 << bs) != bs512)\n\t\treturn -EINVAL;\n\n\tif (bs < mlxsw_sp_port->mlxsw_sp->lowest_shaper_bs ||\n\t    bs > MLXSW_REG_QEEC_HIGHEST_SHAPER_BS)\n\t\treturn -EINVAL;\n\n\t*p_burst_size = bs;\n\treturn 0;\n}\n\nstatic u32\nmlxsw_sp_qdisc_tbf_max_size(u8 bs)\n{\n\treturn (1U << bs) * 64;\n}\n\nstatic u64\nmlxsw_sp_qdisc_tbf_rate_kbps(struct tc_tbf_qopt_offload_replace_params *p)\n{\n\t \n\treturn div_u64(p->rate.rate_bytes_ps, 1000) * 8;\n}\n\nstatic int\nmlxsw_sp_qdisc_tbf_check_params(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\tvoid *params)\n{\n\tstruct tc_tbf_qopt_offload_replace_params *p = params;\n\tstruct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;\n\tu64 rate_kbps = mlxsw_sp_qdisc_tbf_rate_kbps(p);\n\tu8 burst_size;\n\tint err;\n\n\tif (rate_kbps >= MLXSW_REG_QEEC_MAS_DIS) {\n\t\tdev_err(mlxsw_sp_port->mlxsw_sp->bus_info->dev,\n\t\t\t\"spectrum: TBF: rate of %lluKbps must be below %u\\n\",\n\t\t\trate_kbps, MLXSW_REG_QEEC_MAS_DIS);\n\t\treturn -EINVAL;\n\t}\n\n\terr = mlxsw_sp_qdisc_tbf_bs(mlxsw_sp_port, p->max_size, &burst_size);\n\tif (err) {\n\t\tu8 highest_shaper_bs = MLXSW_REG_QEEC_HIGHEST_SHAPER_BS;\n\n\t\tdev_err(mlxsw_sp->bus_info->dev,\n\t\t\t\"spectrum: TBF: invalid burst size of %u, must be a power of two between %u and %u\",\n\t\t\tp->max_size,\n\t\t\tmlxsw_sp_qdisc_tbf_max_size(mlxsw_sp->lowest_shaper_bs),\n\t\t\tmlxsw_sp_qdisc_tbf_max_size(highest_shaper_bs));\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_tbf_replace(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t\t   struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t   void *params)\n{\n\tenum mlxsw_reg_qeec_hr hr = mlxsw_sp_qdisc_tbf_hr(mlxsw_sp_port,\n\t\t\t\t\t\t\t  mlxsw_sp_qdisc);\n\tstruct tc_tbf_qopt_offload_replace_params *p = params;\n\tu64 rate_kbps = mlxsw_sp_qdisc_tbf_rate_kbps(p);\n\tint tclass_num;\n\tu8 burst_size;\n\tint err;\n\n\terr = mlxsw_sp_qdisc_future_fifo_replace(mlxsw_sp_port, handle, 0,\n\t\t\t\t\t\t &mlxsw_sp_qdisc->qdiscs[0]);\n\tif (err)\n\t\treturn err;\n\tmlxsw_sp_qdisc_future_fifos_init(mlxsw_sp_port, TC_H_UNSPEC);\n\n\ttclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port,\n\t\t\t\t\t\t   mlxsw_sp_qdisc);\n\n\terr = mlxsw_sp_qdisc_tbf_bs(mlxsw_sp_port, p->max_size, &burst_size);\n\tif (WARN_ON_ONCE(err))\n\t\t \n\t\treturn -EINVAL;\n\n\treturn mlxsw_sp_port_ets_maxrate_set(mlxsw_sp_port, hr, tclass_num, 0,\n\t\t\t\t\t     rate_kbps, burst_size);\n}\n\nstatic void\nmlxsw_sp_qdisc_tbf_unoffload(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t     struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t     void *params)\n{\n\tstruct tc_tbf_qopt_offload_replace_params *p = params;\n\n\tmlxsw_sp_qdisc_leaf_unoffload(mlxsw_sp_port, mlxsw_sp_qdisc, p->qstats);\n}\n\nstatic int\nmlxsw_sp_qdisc_get_tbf_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t     struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t     struct tc_qopt_offload_stats *stats_ptr)\n{\n\tmlxsw_sp_qdisc_get_tc_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t    stats_ptr);\n\treturn 0;\n}\n\nstatic struct mlxsw_sp_qdisc_ops mlxsw_sp_qdisc_ops_tbf = {\n\t.type = MLXSW_SP_QDISC_TBF,\n\t.check_params = mlxsw_sp_qdisc_tbf_check_params,\n\t.replace = mlxsw_sp_qdisc_tbf_replace,\n\t.unoffload = mlxsw_sp_qdisc_tbf_unoffload,\n\t.destroy = mlxsw_sp_qdisc_tbf_destroy,\n\t.get_stats = mlxsw_sp_qdisc_get_tbf_stats,\n\t.clean_stats = mlxsw_sp_setup_tc_qdisc_leaf_clean_stats,\n\t.find_class = mlxsw_sp_qdisc_leaf_find_class,\n\t.num_classes = 1,\n};\n\nstatic int __mlxsw_sp_setup_tc_tbf(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t   struct tc_tbf_qopt_offload *p)\n{\n\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc;\n\n\tmlxsw_sp_qdisc = mlxsw_sp_qdisc_find(mlxsw_sp_port, p->parent);\n\tif (!mlxsw_sp_qdisc)\n\t\treturn -EOPNOTSUPP;\n\n\tif (p->command == TC_TBF_REPLACE)\n\t\treturn mlxsw_sp_qdisc_replace(mlxsw_sp_port, p->handle,\n\t\t\t\t\t      mlxsw_sp_qdisc,\n\t\t\t\t\t      &mlxsw_sp_qdisc_ops_tbf,\n\t\t\t\t\t      &p->replace_params);\n\n\tif (!mlxsw_sp_qdisc_compare(mlxsw_sp_qdisc, p->handle))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (p->command) {\n\tcase TC_TBF_DESTROY:\n\t\treturn mlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\tcase TC_TBF_STATS:\n\t\treturn mlxsw_sp_qdisc_get_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t\t&p->stats);\n\tcase TC_TBF_GRAFT:\n\t\treturn mlxsw_sp_qdisc_graft(mlxsw_sp_port, mlxsw_sp_qdisc, 0,\n\t\t\t\t\t    p->child_handle);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nint mlxsw_sp_setup_tc_tbf(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t  struct tc_tbf_qopt_offload *p)\n{\n\tint err;\n\n\tmutex_lock(&mlxsw_sp_port->qdisc->lock);\n\terr = __mlxsw_sp_setup_tc_tbf(mlxsw_sp_port, p);\n\tmutex_unlock(&mlxsw_sp_port->qdisc->lock);\n\n\treturn err;\n}\n\nstatic int\nmlxsw_sp_qdisc_fifo_check_params(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t void *params)\n{\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_fifo_replace(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t\t    struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t    void *params)\n{\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_get_fifo_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t      struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t      struct tc_qopt_offload_stats *stats_ptr)\n{\n\tmlxsw_sp_qdisc_get_tc_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t    stats_ptr);\n\treturn 0;\n}\n\nstatic struct mlxsw_sp_qdisc_ops mlxsw_sp_qdisc_ops_fifo = {\n\t.type = MLXSW_SP_QDISC_FIFO,\n\t.check_params = mlxsw_sp_qdisc_fifo_check_params,\n\t.replace = mlxsw_sp_qdisc_fifo_replace,\n\t.get_stats = mlxsw_sp_qdisc_get_fifo_stats,\n\t.clean_stats = mlxsw_sp_setup_tc_qdisc_leaf_clean_stats,\n};\n\nstatic int\nmlxsw_sp_qdisc_future_fifo_replace(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t   u32 handle, unsigned int band,\n\t\t\t\t   struct mlxsw_sp_qdisc *child_qdisc)\n{\n\tstruct mlxsw_sp_qdisc_state *qdisc_state = mlxsw_sp_port->qdisc;\n\n\tif (handle == qdisc_state->future_handle &&\n\t    qdisc_state->future_fifos[band])\n\t\treturn mlxsw_sp_qdisc_replace(mlxsw_sp_port, TC_H_UNSPEC,\n\t\t\t\t\t      child_qdisc,\n\t\t\t\t\t      &mlxsw_sp_qdisc_ops_fifo,\n\t\t\t\t\t      NULL);\n\treturn 0;\n}\n\nstatic void\nmlxsw_sp_qdisc_future_fifos_init(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t u32 handle)\n{\n\tstruct mlxsw_sp_qdisc_state *qdisc_state = mlxsw_sp_port->qdisc;\n\n\tqdisc_state->future_handle = handle;\n\tmemset(qdisc_state->future_fifos, 0, sizeof(qdisc_state->future_fifos));\n}\n\nstatic int __mlxsw_sp_setup_tc_fifo(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t    struct tc_fifo_qopt_offload *p)\n{\n\tstruct mlxsw_sp_qdisc_state *qdisc_state = mlxsw_sp_port->qdisc;\n\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc;\n\tunsigned int band;\n\tu32 parent_handle;\n\n\tmlxsw_sp_qdisc = mlxsw_sp_qdisc_find(mlxsw_sp_port, p->parent);\n\tif (!mlxsw_sp_qdisc && p->handle == TC_H_UNSPEC) {\n\t\tparent_handle = TC_H_MAJ(p->parent);\n\t\tif (parent_handle != qdisc_state->future_handle) {\n\t\t\t \n\t\t\tmlxsw_sp_qdisc_future_fifos_init(mlxsw_sp_port,\n\t\t\t\t\t\t\t parent_handle);\n\t\t}\n\n\t\tband = TC_H_MIN(p->parent) - 1;\n\t\tif (band < IEEE_8021QAZ_MAX_TCS) {\n\t\t\tif (p->command == TC_FIFO_REPLACE)\n\t\t\t\tqdisc_state->future_fifos[band] = true;\n\t\t\telse if (p->command == TC_FIFO_DESTROY)\n\t\t\t\tqdisc_state->future_fifos[band] = false;\n\t\t}\n\t}\n\tif (!mlxsw_sp_qdisc)\n\t\treturn -EOPNOTSUPP;\n\n\tif (p->command == TC_FIFO_REPLACE) {\n\t\treturn mlxsw_sp_qdisc_replace(mlxsw_sp_port, p->handle,\n\t\t\t\t\t      mlxsw_sp_qdisc,\n\t\t\t\t\t      &mlxsw_sp_qdisc_ops_fifo, NULL);\n\t}\n\n\tif (!mlxsw_sp_qdisc_compare(mlxsw_sp_qdisc, p->handle))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (p->command) {\n\tcase TC_FIFO_DESTROY:\n\t\treturn mlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\tcase TC_FIFO_STATS:\n\t\treturn mlxsw_sp_qdisc_get_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t\t&p->stats);\n\tcase TC_FIFO_REPLACE:  \n\t\tbreak;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nint mlxsw_sp_setup_tc_fifo(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t   struct tc_fifo_qopt_offload *p)\n{\n\tint err;\n\n\tmutex_lock(&mlxsw_sp_port->qdisc->lock);\n\terr = __mlxsw_sp_setup_tc_fifo(mlxsw_sp_port, p);\n\tmutex_unlock(&mlxsw_sp_port->qdisc->lock);\n\n\treturn err;\n}\n\nstatic int __mlxsw_sp_qdisc_ets_destroy(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tint i;\n\n\tfor (i = 0; i < mlxsw_sp_qdisc->num_classes; i++) {\n\t\tmlxsw_sp_port_prio_tc_set(mlxsw_sp_port, i,\n\t\t\t\t\t  MLXSW_SP_PORT_DEFAULT_TCLASS);\n\t\tmlxsw_sp_port_ets_set(mlxsw_sp_port,\n\t\t\t\t      MLXSW_REG_QEEC_HR_SUBGROUP,\n\t\t\t\t      i, 0, false, 0);\n\t}\n\n\tkfree(mlxsw_sp_qdisc->ets_data);\n\tmlxsw_sp_qdisc->ets_data = NULL;\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_prio_destroy(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t    struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\treturn __mlxsw_sp_qdisc_ets_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n}\n\nstatic int\n__mlxsw_sp_qdisc_ets_check_params(unsigned int nbands)\n{\n\tif (nbands > IEEE_8021QAZ_MAX_TCS)\n\t\treturn -EOPNOTSUPP;\n\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_prio_check_params(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t void *params)\n{\n\tstruct tc_prio_qopt_offload_params *p = params;\n\n\treturn __mlxsw_sp_qdisc_ets_check_params(p->bands);\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_walk_cb_clean_stats(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\t   void *mlxsw_sp_port)\n{\n\tu64 backlog;\n\n\tif (mlxsw_sp_qdisc->ops) {\n\t\tbacklog = mlxsw_sp_qdisc->stats_base.backlog;\n\t\tif (mlxsw_sp_qdisc->ops->clean_stats)\n\t\t\tmlxsw_sp_qdisc->ops->clean_stats(mlxsw_sp_port,\n\t\t\t\t\t\t\t mlxsw_sp_qdisc);\n\t\tmlxsw_sp_qdisc->stats_base.backlog = backlog;\n\t}\n\n\treturn NULL;\n}\n\nstatic void\nmlxsw_sp_qdisc_tree_clean_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tmlxsw_sp_qdisc_walk(mlxsw_sp_qdisc, mlxsw_sp_qdisc_walk_cb_clean_stats,\n\t\t\t    mlxsw_sp_port);\n}\n\nstatic int\n__mlxsw_sp_qdisc_ets_replace(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t     struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t     u32 handle, unsigned int nbands,\n\t\t\t     const unsigned int *quanta,\n\t\t\t     const unsigned int *weights,\n\t\t\t     const u8 *priomap)\n{\n\tstruct mlxsw_sp_qdisc_ets_data *ets_data = mlxsw_sp_qdisc->ets_data;\n\tstruct mlxsw_sp_qdisc_ets_band *ets_band;\n\tstruct mlxsw_sp_qdisc *child_qdisc;\n\tu8 old_priomap, new_priomap;\n\tint i, band;\n\tint err;\n\n\tif (!ets_data) {\n\t\tets_data = kzalloc(sizeof(*ets_data), GFP_KERNEL);\n\t\tif (!ets_data)\n\t\t\treturn -ENOMEM;\n\t\tmlxsw_sp_qdisc->ets_data = ets_data;\n\n\t\tfor (band = 0; band < mlxsw_sp_qdisc->num_classes; band++) {\n\t\t\tint tclass_num = MLXSW_SP_PRIO_BAND_TO_TCLASS(band);\n\n\t\t\tets_band = &ets_data->bands[band];\n\t\t\tets_band->tclass_num = tclass_num;\n\t\t}\n\t}\n\n\tfor (band = 0; band < nbands; band++) {\n\t\tint tclass_num;\n\n\t\tchild_qdisc = &mlxsw_sp_qdisc->qdiscs[band];\n\t\tets_band = &ets_data->bands[band];\n\n\t\ttclass_num = ets_band->tclass_num;\n\t\told_priomap = ets_band->prio_bitmap;\n\t\tnew_priomap = 0;\n\n\t\terr = mlxsw_sp_port_ets_set(mlxsw_sp_port,\n\t\t\t\t\t    MLXSW_REG_QEEC_HR_SUBGROUP,\n\t\t\t\t\t    tclass_num, 0, !!quanta[band],\n\t\t\t\t\t    weights[band]);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tfor (i = 0; i < IEEE_8021QAZ_MAX_TCS; i++) {\n\t\t\tif (priomap[i] == band) {\n\t\t\t\tnew_priomap |= BIT(i);\n\t\t\t\tif (BIT(i) & old_priomap)\n\t\t\t\t\tcontinue;\n\t\t\t\terr = mlxsw_sp_port_prio_tc_set(mlxsw_sp_port,\n\t\t\t\t\t\t\t\ti, tclass_num);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\n\t\tets_band->prio_bitmap = new_priomap;\n\n\t\tif (old_priomap != new_priomap)\n\t\t\tmlxsw_sp_qdisc_tree_clean_stats(mlxsw_sp_port,\n\t\t\t\t\t\t\tchild_qdisc);\n\n\t\terr = mlxsw_sp_qdisc_future_fifo_replace(mlxsw_sp_port, handle,\n\t\t\t\t\t\t\t band, child_qdisc);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\tfor (; band < IEEE_8021QAZ_MAX_TCS; band++) {\n\t\tets_band = &ets_data->bands[band];\n\t\tets_band->prio_bitmap = 0;\n\n\t\tchild_qdisc = &mlxsw_sp_qdisc->qdiscs[band];\n\t\tmlxsw_sp_qdisc_destroy(mlxsw_sp_port, child_qdisc);\n\n\t\tmlxsw_sp_port_ets_set(mlxsw_sp_port,\n\t\t\t\t      MLXSW_REG_QEEC_HR_SUBGROUP,\n\t\t\t\t      ets_band->tclass_num, 0, false, 0);\n\t}\n\n\tmlxsw_sp_qdisc_future_fifos_init(mlxsw_sp_port, TC_H_UNSPEC);\n\treturn 0;\n}\n\nstatic int\nmlxsw_sp_qdisc_prio_replace(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t\t    struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t    void *params)\n{\n\tstruct tc_prio_qopt_offload_params *p = params;\n\tunsigned int zeroes[TCQ_ETS_MAX_BANDS] = {0};\n\n\treturn __mlxsw_sp_qdisc_ets_replace(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t    handle, p->bands, zeroes,\n\t\t\t\t\t    zeroes, p->priomap);\n}\n\nstatic void\n__mlxsw_sp_qdisc_ets_unoffload(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t       struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t       struct gnet_stats_queue *qstats)\n{\n\tu64 backlog;\n\n\tbacklog = mlxsw_sp_cells_bytes(mlxsw_sp_port->mlxsw_sp,\n\t\t\t\t       mlxsw_sp_qdisc->stats_base.backlog);\n\tqstats->backlog -= backlog;\n}\n\nstatic void\nmlxsw_sp_qdisc_prio_unoffload(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t      struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t      void *params)\n{\n\tstruct tc_prio_qopt_offload_params *p = params;\n\n\t__mlxsw_sp_qdisc_ets_unoffload(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t       p->qstats);\n}\n\nstatic int\nmlxsw_sp_qdisc_get_prio_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t      struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t      struct tc_qopt_offload_stats *stats_ptr)\n{\n\tstruct mlxsw_sp_qdisc *tc_qdisc;\n\tu64 tx_packets = 0;\n\tu64 tx_bytes = 0;\n\tu64 backlog = 0;\n\tu64 drops = 0;\n\tint i;\n\n\tfor (i = 0; i < mlxsw_sp_qdisc->num_classes; i++) {\n\t\ttc_qdisc = &mlxsw_sp_qdisc->qdiscs[i];\n\t\tmlxsw_sp_qdisc_collect_tc_stats(mlxsw_sp_port, tc_qdisc,\n\t\t\t\t\t\t&tx_bytes, &tx_packets,\n\t\t\t\t\t\t&drops, &backlog);\n\t}\n\n\tmlxsw_sp_qdisc_update_stats(mlxsw_sp_port->mlxsw_sp, mlxsw_sp_qdisc,\n\t\t\t\t    tx_bytes, tx_packets, drops, backlog,\n\t\t\t\t    stats_ptr);\n\treturn 0;\n}\n\nstatic void\nmlxsw_sp_setup_tc_qdisc_prio_clean_stats(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\t struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\tstruct mlxsw_sp_qdisc_stats *stats_base;\n\tstruct mlxsw_sp_port_xstats *xstats;\n\tstruct rtnl_link_stats64 *stats;\n\tint i;\n\n\txstats = &mlxsw_sp_port->periodic_hw_stats.xstats;\n\tstats = &mlxsw_sp_port->periodic_hw_stats.stats;\n\tstats_base = &mlxsw_sp_qdisc->stats_base;\n\n\tstats_base->tx_packets = stats->tx_packets;\n\tstats_base->tx_bytes = stats->tx_bytes;\n\n\tstats_base->drops = 0;\n\tfor (i = 0; i < IEEE_8021QAZ_MAX_TCS; i++) {\n\t\tstats_base->drops += mlxsw_sp_xstats_tail_drop(xstats, i);\n\t\tstats_base->drops += xstats->wred_drop[i];\n\t}\n\n\tmlxsw_sp_qdisc->stats_base.backlog = 0;\n}\n\nstatic struct mlxsw_sp_qdisc *\nmlxsw_sp_qdisc_prio_find_class(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t       u32 parent)\n{\n\tint child_index = TC_H_MIN(parent);\n\tint band = child_index - 1;\n\n\tif (band < 0 || band >= mlxsw_sp_qdisc->num_classes)\n\t\treturn NULL;\n\treturn &mlxsw_sp_qdisc->qdiscs[band];\n}\n\nstatic struct mlxsw_sp_qdisc_ets_band *\nmlxsw_sp_qdisc_ets_get_band(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t    struct mlxsw_sp_qdisc *child)\n{\n\tunsigned int band = child - mlxsw_sp_qdisc->qdiscs;\n\n\tif (WARN_ON(band >= IEEE_8021QAZ_MAX_TCS))\n\t\tband = 0;\n\treturn &mlxsw_sp_qdisc->ets_data->bands[band];\n}\n\nstatic u8\nmlxsw_sp_qdisc_ets_get_prio_bitmap(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\t   struct mlxsw_sp_qdisc *child)\n{\n\treturn mlxsw_sp_qdisc_ets_get_band(mlxsw_sp_qdisc, child)->prio_bitmap;\n}\n\nstatic int\nmlxsw_sp_qdisc_ets_get_tclass_num(struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\t  struct mlxsw_sp_qdisc *child)\n{\n\treturn mlxsw_sp_qdisc_ets_get_band(mlxsw_sp_qdisc, child)->tclass_num;\n}\n\nstatic struct mlxsw_sp_qdisc_ops mlxsw_sp_qdisc_ops_prio = {\n\t.type = MLXSW_SP_QDISC_PRIO,\n\t.check_params = mlxsw_sp_qdisc_prio_check_params,\n\t.replace = mlxsw_sp_qdisc_prio_replace,\n\t.unoffload = mlxsw_sp_qdisc_prio_unoffload,\n\t.destroy = mlxsw_sp_qdisc_prio_destroy,\n\t.get_stats = mlxsw_sp_qdisc_get_prio_stats,\n\t.clean_stats = mlxsw_sp_setup_tc_qdisc_prio_clean_stats,\n\t.find_class = mlxsw_sp_qdisc_prio_find_class,\n\t.num_classes = IEEE_8021QAZ_MAX_TCS,\n\t.get_prio_bitmap = mlxsw_sp_qdisc_ets_get_prio_bitmap,\n\t.get_tclass_num = mlxsw_sp_qdisc_ets_get_tclass_num,\n};\n\nstatic int\nmlxsw_sp_qdisc_ets_check_params(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\tvoid *params)\n{\n\tstruct tc_ets_qopt_offload_replace_params *p = params;\n\n\treturn __mlxsw_sp_qdisc_ets_check_params(p->bands);\n}\n\nstatic int\nmlxsw_sp_qdisc_ets_replace(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle,\n\t\t\t   struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t   void *params)\n{\n\tstruct tc_ets_qopt_offload_replace_params *p = params;\n\n\treturn __mlxsw_sp_qdisc_ets_replace(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t    handle, p->bands, p->quanta,\n\t\t\t\t\t    p->weights, p->priomap);\n}\n\nstatic void\nmlxsw_sp_qdisc_ets_unoffload(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t     struct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t     void *params)\n{\n\tstruct tc_ets_qopt_offload_replace_params *p = params;\n\n\t__mlxsw_sp_qdisc_ets_unoffload(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t       p->qstats);\n}\n\nstatic int\nmlxsw_sp_qdisc_ets_destroy(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t   struct mlxsw_sp_qdisc *mlxsw_sp_qdisc)\n{\n\treturn __mlxsw_sp_qdisc_ets_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n}\n\nstatic struct mlxsw_sp_qdisc_ops mlxsw_sp_qdisc_ops_ets = {\n\t.type = MLXSW_SP_QDISC_ETS,\n\t.check_params = mlxsw_sp_qdisc_ets_check_params,\n\t.replace = mlxsw_sp_qdisc_ets_replace,\n\t.unoffload = mlxsw_sp_qdisc_ets_unoffload,\n\t.destroy = mlxsw_sp_qdisc_ets_destroy,\n\t.get_stats = mlxsw_sp_qdisc_get_prio_stats,\n\t.clean_stats = mlxsw_sp_setup_tc_qdisc_prio_clean_stats,\n\t.find_class = mlxsw_sp_qdisc_prio_find_class,\n\t.num_classes = IEEE_8021QAZ_MAX_TCS,\n\t.get_prio_bitmap = mlxsw_sp_qdisc_ets_get_prio_bitmap,\n\t.get_tclass_num = mlxsw_sp_qdisc_ets_get_tclass_num,\n};\n\n \nstatic int mlxsw_sp_qdisc_graft(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc,\n\t\t\t\tu8 band, u32 child_handle)\n{\n\tstruct mlxsw_sp_qdisc *old_qdisc;\n\tu32 parent;\n\n\tif (band < mlxsw_sp_qdisc->num_classes &&\n\t    mlxsw_sp_qdisc->qdiscs[band].handle == child_handle)\n\t\treturn 0;\n\n\tif (!child_handle) {\n\t\t \n\t\treturn 0;\n\t}\n\n\t \n\told_qdisc = mlxsw_sp_qdisc_find_by_handle(mlxsw_sp_port,\n\t\t\t\t\t\t  child_handle);\n\tif (old_qdisc)\n\t\tmlxsw_sp_qdisc_destroy(mlxsw_sp_port, old_qdisc);\n\n\tparent = TC_H_MAKE(mlxsw_sp_qdisc->handle, band + 1);\n\tmlxsw_sp_qdisc = mlxsw_sp_qdisc->ops->find_class(mlxsw_sp_qdisc,\n\t\t\t\t\t\t\t parent);\n\tif (!WARN_ON(!mlxsw_sp_qdisc))\n\t\tmlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int __mlxsw_sp_setup_tc_prio(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t    struct tc_prio_qopt_offload *p)\n{\n\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc;\n\n\tmlxsw_sp_qdisc = mlxsw_sp_qdisc_find(mlxsw_sp_port, p->parent);\n\tif (!mlxsw_sp_qdisc)\n\t\treturn -EOPNOTSUPP;\n\n\tif (p->command == TC_PRIO_REPLACE)\n\t\treturn mlxsw_sp_qdisc_replace(mlxsw_sp_port, p->handle,\n\t\t\t\t\t      mlxsw_sp_qdisc,\n\t\t\t\t\t      &mlxsw_sp_qdisc_ops_prio,\n\t\t\t\t\t      &p->replace_params);\n\n\tif (!mlxsw_sp_qdisc_compare(mlxsw_sp_qdisc, p->handle))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (p->command) {\n\tcase TC_PRIO_DESTROY:\n\t\treturn mlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\tcase TC_PRIO_STATS:\n\t\treturn mlxsw_sp_qdisc_get_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t\t&p->stats);\n\tcase TC_PRIO_GRAFT:\n\t\treturn mlxsw_sp_qdisc_graft(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t    p->graft_params.band,\n\t\t\t\t\t    p->graft_params.child_handle);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nint mlxsw_sp_setup_tc_prio(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t   struct tc_prio_qopt_offload *p)\n{\n\tint err;\n\n\tmutex_lock(&mlxsw_sp_port->qdisc->lock);\n\terr = __mlxsw_sp_setup_tc_prio(mlxsw_sp_port, p);\n\tmutex_unlock(&mlxsw_sp_port->qdisc->lock);\n\n\treturn err;\n}\n\nstatic int __mlxsw_sp_setup_tc_ets(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t   struct tc_ets_qopt_offload *p)\n{\n\tstruct mlxsw_sp_qdisc *mlxsw_sp_qdisc;\n\n\tmlxsw_sp_qdisc = mlxsw_sp_qdisc_find(mlxsw_sp_port, p->parent);\n\tif (!mlxsw_sp_qdisc)\n\t\treturn -EOPNOTSUPP;\n\n\tif (p->command == TC_ETS_REPLACE)\n\t\treturn mlxsw_sp_qdisc_replace(mlxsw_sp_port, p->handle,\n\t\t\t\t\t      mlxsw_sp_qdisc,\n\t\t\t\t\t      &mlxsw_sp_qdisc_ops_ets,\n\t\t\t\t\t      &p->replace_params);\n\n\tif (!mlxsw_sp_qdisc_compare(mlxsw_sp_qdisc, p->handle))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (p->command) {\n\tcase TC_ETS_DESTROY:\n\t\treturn mlxsw_sp_qdisc_destroy(mlxsw_sp_port, mlxsw_sp_qdisc);\n\tcase TC_ETS_STATS:\n\t\treturn mlxsw_sp_qdisc_get_stats(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t\t&p->stats);\n\tcase TC_ETS_GRAFT:\n\t\treturn mlxsw_sp_qdisc_graft(mlxsw_sp_port, mlxsw_sp_qdisc,\n\t\t\t\t\t    p->graft_params.band,\n\t\t\t\t\t    p->graft_params.child_handle);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nint mlxsw_sp_setup_tc_ets(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t  struct tc_ets_qopt_offload *p)\n{\n\tint err;\n\n\tmutex_lock(&mlxsw_sp_port->qdisc->lock);\n\terr = __mlxsw_sp_setup_tc_ets(mlxsw_sp_port, p);\n\tmutex_unlock(&mlxsw_sp_port->qdisc->lock);\n\n\treturn err;\n}\n\nstruct mlxsw_sp_qevent_block {\n\tstruct list_head binding_list;\n\tstruct list_head mall_entry_list;\n\tstruct mlxsw_sp *mlxsw_sp;\n};\n\nstruct mlxsw_sp_qevent_binding {\n\tstruct list_head list;\n\tstruct mlxsw_sp_port *mlxsw_sp_port;\n\tu32 handle;\n\tint tclass_num;\n\tenum mlxsw_sp_span_trigger span_trigger;\n\tunsigned int action_mask;\n};\n\nstatic LIST_HEAD(mlxsw_sp_qevent_block_cb_list);\n\nstatic int mlxsw_sp_qevent_span_configure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t  struct mlxsw_sp_mall_entry *mall_entry,\n\t\t\t\t\t  struct mlxsw_sp_qevent_binding *qevent_binding,\n\t\t\t\t\t  const struct mlxsw_sp_span_agent_parms *agent_parms,\n\t\t\t\t\t  int *p_span_id)\n{\n\tenum mlxsw_sp_span_trigger span_trigger = qevent_binding->span_trigger;\n\tstruct mlxsw_sp_port *mlxsw_sp_port = qevent_binding->mlxsw_sp_port;\n\tstruct mlxsw_sp_span_trigger_parms trigger_parms = {};\n\tbool ingress;\n\tint span_id;\n\tint err;\n\n\terr = mlxsw_sp_span_agent_get(mlxsw_sp, &span_id, agent_parms);\n\tif (err)\n\t\treturn err;\n\n\tingress = mlxsw_sp_span_trigger_is_ingress(span_trigger);\n\terr = mlxsw_sp_span_analyzed_port_get(mlxsw_sp_port, ingress);\n\tif (err)\n\t\tgoto err_analyzed_port_get;\n\n\ttrigger_parms.span_id = span_id;\n\ttrigger_parms.probability_rate = 1;\n\terr = mlxsw_sp_span_agent_bind(mlxsw_sp, span_trigger, mlxsw_sp_port,\n\t\t\t\t       &trigger_parms);\n\tif (err)\n\t\tgoto err_agent_bind;\n\n\terr = mlxsw_sp_span_trigger_enable(mlxsw_sp_port, span_trigger,\n\t\t\t\t\t   qevent_binding->tclass_num);\n\tif (err)\n\t\tgoto err_trigger_enable;\n\n\t*p_span_id = span_id;\n\treturn 0;\n\nerr_trigger_enable:\n\tmlxsw_sp_span_agent_unbind(mlxsw_sp, span_trigger, mlxsw_sp_port,\n\t\t\t\t   &trigger_parms);\nerr_agent_bind:\n\tmlxsw_sp_span_analyzed_port_put(mlxsw_sp_port, ingress);\nerr_analyzed_port_get:\n\tmlxsw_sp_span_agent_put(mlxsw_sp, span_id);\n\treturn err;\n}\n\nstatic void mlxsw_sp_qevent_span_deconfigure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t     struct mlxsw_sp_qevent_binding *qevent_binding,\n\t\t\t\t\t     int span_id)\n{\n\tenum mlxsw_sp_span_trigger span_trigger = qevent_binding->span_trigger;\n\tstruct mlxsw_sp_port *mlxsw_sp_port = qevent_binding->mlxsw_sp_port;\n\tstruct mlxsw_sp_span_trigger_parms trigger_parms = {\n\t\t.span_id = span_id,\n\t};\n\tbool ingress;\n\n\tingress = mlxsw_sp_span_trigger_is_ingress(span_trigger);\n\n\tmlxsw_sp_span_trigger_disable(mlxsw_sp_port, span_trigger,\n\t\t\t\t      qevent_binding->tclass_num);\n\tmlxsw_sp_span_agent_unbind(mlxsw_sp, span_trigger, mlxsw_sp_port,\n\t\t\t\t   &trigger_parms);\n\tmlxsw_sp_span_analyzed_port_put(mlxsw_sp_port, ingress);\n\tmlxsw_sp_span_agent_put(mlxsw_sp, span_id);\n}\n\nstatic int mlxsw_sp_qevent_mirror_configure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t    struct mlxsw_sp_mall_entry *mall_entry,\n\t\t\t\t\t    struct mlxsw_sp_qevent_binding *qevent_binding)\n{\n\tstruct mlxsw_sp_span_agent_parms agent_parms = {\n\t\t.to_dev = mall_entry->mirror.to_dev,\n\t};\n\n\treturn mlxsw_sp_qevent_span_configure(mlxsw_sp, mall_entry, qevent_binding,\n\t\t\t\t\t      &agent_parms, &mall_entry->mirror.span_id);\n}\n\nstatic void mlxsw_sp_qevent_mirror_deconfigure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t       struct mlxsw_sp_mall_entry *mall_entry,\n\t\t\t\t\t       struct mlxsw_sp_qevent_binding *qevent_binding)\n{\n\tmlxsw_sp_qevent_span_deconfigure(mlxsw_sp, qevent_binding, mall_entry->mirror.span_id);\n}\n\nstatic int mlxsw_sp_qevent_trap_configure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t  struct mlxsw_sp_mall_entry *mall_entry,\n\t\t\t\t\t  struct mlxsw_sp_qevent_binding *qevent_binding)\n{\n\tstruct mlxsw_sp_span_agent_parms agent_parms = {\n\t\t.session_id = MLXSW_SP_SPAN_SESSION_ID_BUFFER,\n\t};\n\tint err;\n\n\terr = mlxsw_sp_trap_group_policer_hw_id_get(mlxsw_sp,\n\t\t\t\t\t\t    DEVLINK_TRAP_GROUP_GENERIC_ID_BUFFER_DROPS,\n\t\t\t\t\t\t    &agent_parms.policer_enable,\n\t\t\t\t\t\t    &agent_parms.policer_id);\n\tif (err)\n\t\treturn err;\n\n\treturn mlxsw_sp_qevent_span_configure(mlxsw_sp, mall_entry, qevent_binding,\n\t\t\t\t\t      &agent_parms, &mall_entry->trap.span_id);\n}\n\nstatic void mlxsw_sp_qevent_trap_deconfigure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t     struct mlxsw_sp_mall_entry *mall_entry,\n\t\t\t\t\t     struct mlxsw_sp_qevent_binding *qevent_binding)\n{\n\tmlxsw_sp_qevent_span_deconfigure(mlxsw_sp, qevent_binding, mall_entry->trap.span_id);\n}\n\nstatic int\nmlxsw_sp_qevent_entry_configure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\tstruct mlxsw_sp_mall_entry *mall_entry,\n\t\t\t\tstruct mlxsw_sp_qevent_binding *qevent_binding,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tif (!(BIT(mall_entry->type) & qevent_binding->action_mask)) {\n\t\tNL_SET_ERR_MSG(extack, \"Action not supported at this qevent\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tswitch (mall_entry->type) {\n\tcase MLXSW_SP_MALL_ACTION_TYPE_MIRROR:\n\t\treturn mlxsw_sp_qevent_mirror_configure(mlxsw_sp, mall_entry, qevent_binding);\n\tcase MLXSW_SP_MALL_ACTION_TYPE_TRAP:\n\t\treturn mlxsw_sp_qevent_trap_configure(mlxsw_sp, mall_entry, qevent_binding);\n\tdefault:\n\t\t \n\t\tWARN_ON(1);\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void mlxsw_sp_qevent_entry_deconfigure(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t      struct mlxsw_sp_mall_entry *mall_entry,\n\t\t\t\t\t      struct mlxsw_sp_qevent_binding *qevent_binding)\n{\n\tswitch (mall_entry->type) {\n\tcase MLXSW_SP_MALL_ACTION_TYPE_MIRROR:\n\t\treturn mlxsw_sp_qevent_mirror_deconfigure(mlxsw_sp, mall_entry, qevent_binding);\n\tcase MLXSW_SP_MALL_ACTION_TYPE_TRAP:\n\t\treturn mlxsw_sp_qevent_trap_deconfigure(mlxsw_sp, mall_entry, qevent_binding);\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n}\n\nstatic int\nmlxsw_sp_qevent_binding_configure(struct mlxsw_sp_qevent_block *qevent_block,\n\t\t\t\t  struct mlxsw_sp_qevent_binding *qevent_binding,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct mlxsw_sp_mall_entry *mall_entry;\n\tint err;\n\n\tlist_for_each_entry(mall_entry, &qevent_block->mall_entry_list, list) {\n\t\terr = mlxsw_sp_qevent_entry_configure(qevent_block->mlxsw_sp, mall_entry,\n\t\t\t\t\t\t      qevent_binding, extack);\n\t\tif (err)\n\t\t\tgoto err_entry_configure;\n\t}\n\n\treturn 0;\n\nerr_entry_configure:\n\tlist_for_each_entry_continue_reverse(mall_entry, &qevent_block->mall_entry_list, list)\n\t\tmlxsw_sp_qevent_entry_deconfigure(qevent_block->mlxsw_sp, mall_entry,\n\t\t\t\t\t\t  qevent_binding);\n\treturn err;\n}\n\nstatic void mlxsw_sp_qevent_binding_deconfigure(struct mlxsw_sp_qevent_block *qevent_block,\n\t\t\t\t\t\tstruct mlxsw_sp_qevent_binding *qevent_binding)\n{\n\tstruct mlxsw_sp_mall_entry *mall_entry;\n\n\tlist_for_each_entry(mall_entry, &qevent_block->mall_entry_list, list)\n\t\tmlxsw_sp_qevent_entry_deconfigure(qevent_block->mlxsw_sp, mall_entry,\n\t\t\t\t\t\t  qevent_binding);\n}\n\nstatic int\nmlxsw_sp_qevent_block_configure(struct mlxsw_sp_qevent_block *qevent_block,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct mlxsw_sp_qevent_binding *qevent_binding;\n\tint err;\n\n\tlist_for_each_entry(qevent_binding, &qevent_block->binding_list, list) {\n\t\terr = mlxsw_sp_qevent_binding_configure(qevent_block,\n\t\t\t\t\t\t\tqevent_binding,\n\t\t\t\t\t\t\textack);\n\t\tif (err)\n\t\t\tgoto err_binding_configure;\n\t}\n\n\treturn 0;\n\nerr_binding_configure:\n\tlist_for_each_entry_continue_reverse(qevent_binding, &qevent_block->binding_list, list)\n\t\tmlxsw_sp_qevent_binding_deconfigure(qevent_block, qevent_binding);\n\treturn err;\n}\n\nstatic void mlxsw_sp_qevent_block_deconfigure(struct mlxsw_sp_qevent_block *qevent_block)\n{\n\tstruct mlxsw_sp_qevent_binding *qevent_binding;\n\n\tlist_for_each_entry(qevent_binding, &qevent_block->binding_list, list)\n\t\tmlxsw_sp_qevent_binding_deconfigure(qevent_block, qevent_binding);\n}\n\nstatic struct mlxsw_sp_mall_entry *\nmlxsw_sp_qevent_mall_entry_find(struct mlxsw_sp_qevent_block *block, unsigned long cookie)\n{\n\tstruct mlxsw_sp_mall_entry *mall_entry;\n\n\tlist_for_each_entry(mall_entry, &block->mall_entry_list, list)\n\t\tif (mall_entry->cookie == cookie)\n\t\t\treturn mall_entry;\n\n\treturn NULL;\n}\n\nstatic int mlxsw_sp_qevent_mall_replace(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\tstruct mlxsw_sp_qevent_block *qevent_block,\n\t\t\t\t\tstruct tc_cls_matchall_offload *f)\n{\n\tstruct mlxsw_sp_mall_entry *mall_entry;\n\tstruct flow_action_entry *act;\n\tint err;\n\n\t \n\tif (!list_empty(&qevent_block->mall_entry_list)) {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"At most one filter supported\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\tif (f->rule->action.num_entries != 1) {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"Only singular actions supported\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\tif (f->common.chain_index) {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"Only chain 0 is supported\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\tif (f->common.protocol != htons(ETH_P_ALL)) {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"Protocol matching not supported\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tact = &f->rule->action.entries[0];\n\tif (!(act->hw_stats & FLOW_ACTION_HW_STATS_DISABLED)) {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"HW counters not supported on qevents\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmall_entry = kzalloc(sizeof(*mall_entry), GFP_KERNEL);\n\tif (!mall_entry)\n\t\treturn -ENOMEM;\n\tmall_entry->cookie = f->cookie;\n\n\tif (act->id == FLOW_ACTION_MIRRED) {\n\t\tmall_entry->type = MLXSW_SP_MALL_ACTION_TYPE_MIRROR;\n\t\tmall_entry->mirror.to_dev = act->dev;\n\t} else if (act->id == FLOW_ACTION_TRAP) {\n\t\tmall_entry->type = MLXSW_SP_MALL_ACTION_TYPE_TRAP;\n\t} else {\n\t\tNL_SET_ERR_MSG(f->common.extack, \"Unsupported action\");\n\t\terr = -EOPNOTSUPP;\n\t\tgoto err_unsupported_action;\n\t}\n\n\tlist_add_tail(&mall_entry->list, &qevent_block->mall_entry_list);\n\n\terr = mlxsw_sp_qevent_block_configure(qevent_block, f->common.extack);\n\tif (err)\n\t\tgoto err_block_configure;\n\n\treturn 0;\n\nerr_block_configure:\n\tlist_del(&mall_entry->list);\nerr_unsupported_action:\n\tkfree(mall_entry);\n\treturn err;\n}\n\nstatic void mlxsw_sp_qevent_mall_destroy(struct mlxsw_sp_qevent_block *qevent_block,\n\t\t\t\t\t struct tc_cls_matchall_offload *f)\n{\n\tstruct mlxsw_sp_mall_entry *mall_entry;\n\n\tmall_entry = mlxsw_sp_qevent_mall_entry_find(qevent_block, f->cookie);\n\tif (!mall_entry)\n\t\treturn;\n\n\tmlxsw_sp_qevent_block_deconfigure(qevent_block);\n\n\tlist_del(&mall_entry->list);\n\tkfree(mall_entry);\n}\n\nstatic int mlxsw_sp_qevent_block_mall_cb(struct mlxsw_sp_qevent_block *qevent_block,\n\t\t\t\t\t struct tc_cls_matchall_offload *f)\n{\n\tstruct mlxsw_sp *mlxsw_sp = qevent_block->mlxsw_sp;\n\n\tswitch (f->command) {\n\tcase TC_CLSMATCHALL_REPLACE:\n\t\treturn mlxsw_sp_qevent_mall_replace(mlxsw_sp, qevent_block, f);\n\tcase TC_CLSMATCHALL_DESTROY:\n\t\tmlxsw_sp_qevent_mall_destroy(qevent_block, f);\n\t\treturn 0;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int mlxsw_sp_qevent_block_cb(enum tc_setup_type type, void *type_data, void *cb_priv)\n{\n\tstruct mlxsw_sp_qevent_block *qevent_block = cb_priv;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSMATCHALL:\n\t\treturn mlxsw_sp_qevent_block_mall_cb(qevent_block, type_data);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic struct mlxsw_sp_qevent_block *mlxsw_sp_qevent_block_create(struct mlxsw_sp *mlxsw_sp,\n\t\t\t\t\t\t\t\t  struct net *net)\n{\n\tstruct mlxsw_sp_qevent_block *qevent_block;\n\n\tqevent_block = kzalloc(sizeof(*qevent_block), GFP_KERNEL);\n\tif (!qevent_block)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&qevent_block->binding_list);\n\tINIT_LIST_HEAD(&qevent_block->mall_entry_list);\n\tqevent_block->mlxsw_sp = mlxsw_sp;\n\treturn qevent_block;\n}\n\nstatic void\nmlxsw_sp_qevent_block_destroy(struct mlxsw_sp_qevent_block *qevent_block)\n{\n\tWARN_ON(!list_empty(&qevent_block->binding_list));\n\tWARN_ON(!list_empty(&qevent_block->mall_entry_list));\n\tkfree(qevent_block);\n}\n\nstatic void mlxsw_sp_qevent_block_release(void *cb_priv)\n{\n\tstruct mlxsw_sp_qevent_block *qevent_block = cb_priv;\n\n\tmlxsw_sp_qevent_block_destroy(qevent_block);\n}\n\nstatic struct mlxsw_sp_qevent_binding *\nmlxsw_sp_qevent_binding_create(struct mlxsw_sp_port *mlxsw_sp_port, u32 handle, int tclass_num,\n\t\t\t       enum mlxsw_sp_span_trigger span_trigger,\n\t\t\t       unsigned int action_mask)\n{\n\tstruct mlxsw_sp_qevent_binding *binding;\n\n\tbinding = kzalloc(sizeof(*binding), GFP_KERNEL);\n\tif (!binding)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbinding->mlxsw_sp_port = mlxsw_sp_port;\n\tbinding->handle = handle;\n\tbinding->tclass_num = tclass_num;\n\tbinding->span_trigger = span_trigger;\n\tbinding->action_mask = action_mask;\n\treturn binding;\n}\n\nstatic void\nmlxsw_sp_qevent_binding_destroy(struct mlxsw_sp_qevent_binding *binding)\n{\n\tkfree(binding);\n}\n\nstatic struct mlxsw_sp_qevent_binding *\nmlxsw_sp_qevent_binding_lookup(struct mlxsw_sp_qevent_block *block,\n\t\t\t       struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t       u32 handle,\n\t\t\t       enum mlxsw_sp_span_trigger span_trigger)\n{\n\tstruct mlxsw_sp_qevent_binding *qevent_binding;\n\n\tlist_for_each_entry(qevent_binding, &block->binding_list, list)\n\t\tif (qevent_binding->mlxsw_sp_port == mlxsw_sp_port &&\n\t\t    qevent_binding->handle == handle &&\n\t\t    qevent_binding->span_trigger == span_trigger)\n\t\t\treturn qevent_binding;\n\treturn NULL;\n}\n\nstatic int\nmlxsw_sp_setup_tc_block_qevent_bind(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t    struct flow_block_offload *f,\n\t\t\t\t    enum mlxsw_sp_span_trigger span_trigger,\n\t\t\t\t    unsigned int action_mask)\n{\n\tstruct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;\n\tstruct mlxsw_sp_qevent_binding *qevent_binding;\n\tstruct mlxsw_sp_qevent_block *qevent_block;\n\tstruct flow_block_cb *block_cb;\n\tstruct mlxsw_sp_qdisc *qdisc;\n\tbool register_block = false;\n\tint tclass_num;\n\tint err;\n\n\tblock_cb = flow_block_cb_lookup(f->block, mlxsw_sp_qevent_block_cb, mlxsw_sp);\n\tif (!block_cb) {\n\t\tqevent_block = mlxsw_sp_qevent_block_create(mlxsw_sp, f->net);\n\t\tif (!qevent_block)\n\t\t\treturn -ENOMEM;\n\t\tblock_cb = flow_block_cb_alloc(mlxsw_sp_qevent_block_cb, mlxsw_sp, qevent_block,\n\t\t\t\t\t       mlxsw_sp_qevent_block_release);\n\t\tif (IS_ERR(block_cb)) {\n\t\t\tmlxsw_sp_qevent_block_destroy(qevent_block);\n\t\t\treturn PTR_ERR(block_cb);\n\t\t}\n\t\tregister_block = true;\n\t} else {\n\t\tqevent_block = flow_block_cb_priv(block_cb);\n\t}\n\tflow_block_cb_incref(block_cb);\n\n\tqdisc = mlxsw_sp_qdisc_find_by_handle(mlxsw_sp_port, f->sch->handle);\n\tif (!qdisc) {\n\t\tNL_SET_ERR_MSG(f->extack, \"Qdisc not offloaded\");\n\t\terr = -ENOENT;\n\t\tgoto err_find_qdisc;\n\t}\n\n\tif (WARN_ON(mlxsw_sp_qevent_binding_lookup(qevent_block, mlxsw_sp_port, f->sch->handle,\n\t\t\t\t\t\t   span_trigger))) {\n\t\terr = -EEXIST;\n\t\tgoto err_binding_exists;\n\t}\n\n\ttclass_num = mlxsw_sp_qdisc_get_tclass_num(mlxsw_sp_port, qdisc);\n\tqevent_binding = mlxsw_sp_qevent_binding_create(mlxsw_sp_port,\n\t\t\t\t\t\t\tf->sch->handle,\n\t\t\t\t\t\t\ttclass_num,\n\t\t\t\t\t\t\tspan_trigger,\n\t\t\t\t\t\t\taction_mask);\n\tif (IS_ERR(qevent_binding)) {\n\t\terr = PTR_ERR(qevent_binding);\n\t\tgoto err_binding_create;\n\t}\n\n\terr = mlxsw_sp_qevent_binding_configure(qevent_block, qevent_binding,\n\t\t\t\t\t\tf->extack);\n\tif (err)\n\t\tgoto err_binding_configure;\n\n\tlist_add(&qevent_binding->list, &qevent_block->binding_list);\n\n\tif (register_block) {\n\t\tflow_block_cb_add(block_cb, f);\n\t\tlist_add_tail(&block_cb->driver_list, &mlxsw_sp_qevent_block_cb_list);\n\t}\n\n\treturn 0;\n\nerr_binding_configure:\n\tmlxsw_sp_qevent_binding_destroy(qevent_binding);\nerr_binding_create:\nerr_binding_exists:\nerr_find_qdisc:\n\tif (!flow_block_cb_decref(block_cb))\n\t\tflow_block_cb_free(block_cb);\n\treturn err;\n}\n\nstatic void mlxsw_sp_setup_tc_block_qevent_unbind(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\t\t  struct flow_block_offload *f,\n\t\t\t\t\t\t  enum mlxsw_sp_span_trigger span_trigger)\n{\n\tstruct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;\n\tstruct mlxsw_sp_qevent_binding *qevent_binding;\n\tstruct mlxsw_sp_qevent_block *qevent_block;\n\tstruct flow_block_cb *block_cb;\n\n\tblock_cb = flow_block_cb_lookup(f->block, mlxsw_sp_qevent_block_cb, mlxsw_sp);\n\tif (!block_cb)\n\t\treturn;\n\tqevent_block = flow_block_cb_priv(block_cb);\n\n\tqevent_binding = mlxsw_sp_qevent_binding_lookup(qevent_block, mlxsw_sp_port, f->sch->handle,\n\t\t\t\t\t\t\tspan_trigger);\n\tif (!qevent_binding)\n\t\treturn;\n\n\tlist_del(&qevent_binding->list);\n\tmlxsw_sp_qevent_binding_deconfigure(qevent_block, qevent_binding);\n\tmlxsw_sp_qevent_binding_destroy(qevent_binding);\n\n\tif (!flow_block_cb_decref(block_cb)) {\n\t\tflow_block_cb_remove(block_cb, f);\n\t\tlist_del(&block_cb->driver_list);\n\t}\n}\n\nstatic int\nmlxsw_sp_setup_tc_block_qevent(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t       struct flow_block_offload *f,\n\t\t\t       enum mlxsw_sp_span_trigger span_trigger,\n\t\t\t       unsigned int action_mask)\n{\n\tf->driver_block_list = &mlxsw_sp_qevent_block_cb_list;\n\n\tswitch (f->command) {\n\tcase FLOW_BLOCK_BIND:\n\t\treturn mlxsw_sp_setup_tc_block_qevent_bind(mlxsw_sp_port, f,\n\t\t\t\t\t\t\t   span_trigger,\n\t\t\t\t\t\t\t   action_mask);\n\tcase FLOW_BLOCK_UNBIND:\n\t\tmlxsw_sp_setup_tc_block_qevent_unbind(mlxsw_sp_port, f, span_trigger);\n\t\treturn 0;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nint mlxsw_sp_setup_tc_block_qevent_early_drop(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\t      struct flow_block_offload *f)\n{\n\tunsigned int action_mask = BIT(MLXSW_SP_MALL_ACTION_TYPE_MIRROR) |\n\t\t\t\t   BIT(MLXSW_SP_MALL_ACTION_TYPE_TRAP);\n\n\treturn mlxsw_sp_setup_tc_block_qevent(mlxsw_sp_port, f,\n\t\t\t\t\t      MLXSW_SP_SPAN_TRIGGER_EARLY_DROP,\n\t\t\t\t\t      action_mask);\n}\n\nint mlxsw_sp_setup_tc_block_qevent_mark(struct mlxsw_sp_port *mlxsw_sp_port,\n\t\t\t\t\tstruct flow_block_offload *f)\n{\n\tunsigned int action_mask = BIT(MLXSW_SP_MALL_ACTION_TYPE_MIRROR);\n\n\treturn mlxsw_sp_setup_tc_block_qevent(mlxsw_sp_port, f,\n\t\t\t\t\t      MLXSW_SP_SPAN_TRIGGER_ECN,\n\t\t\t\t\t      action_mask);\n}\n\nint mlxsw_sp_tc_qdisc_init(struct mlxsw_sp_port *mlxsw_sp_port)\n{\n\tstruct mlxsw_sp_qdisc_state *qdisc_state;\n\n\tqdisc_state = kzalloc(sizeof(*qdisc_state), GFP_KERNEL);\n\tif (!qdisc_state)\n\t\treturn -ENOMEM;\n\n\tmutex_init(&qdisc_state->lock);\n\tmlxsw_sp_port->qdisc = qdisc_state;\n\treturn 0;\n}\n\nvoid mlxsw_sp_tc_qdisc_fini(struct mlxsw_sp_port *mlxsw_sp_port)\n{\n\tmutex_destroy(&mlxsw_sp_port->qdisc->lock);\n\tkfree(mlxsw_sp_port->qdisc);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}