{
  "module_name": "ipsec_rxtx.c",
  "hash_id": "880f595cb8fcdb6961677ab9a1f69f5461f295d914c341e6785c697dae9529f1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_rxtx.c",
  "human_readable_source": " \n\n#include <crypto/aead.h>\n#include <net/xfrm.h>\n#include <net/esp.h>\n#include \"ipsec.h\"\n#include \"ipsec_rxtx.h\"\n#include \"en.h\"\n#include \"esw/ipsec_fs.h\"\n\nenum {\n\tMLX5E_IPSEC_TX_SYNDROME_OFFLOAD = 0x8,\n\tMLX5E_IPSEC_TX_SYNDROME_OFFLOAD_WITH_LSO_TCP = 0x9,\n};\n\nstatic int mlx5e_ipsec_remove_trailer(struct sk_buff *skb, struct xfrm_state *x)\n{\n\tunsigned int alen = crypto_aead_authsize(x->data);\n\tstruct ipv6hdr *ipv6hdr = ipv6_hdr(skb);\n\tstruct iphdr *ipv4hdr = ip_hdr(skb);\n\tunsigned int trailer_len;\n\tu8 plen;\n\tint ret;\n\n\tret = skb_copy_bits(skb, skb->len - alen - 2, &plen, 1);\n\tif (unlikely(ret))\n\t\treturn ret;\n\n\ttrailer_len = alen + plen + 2;\n\n\tret = pskb_trim(skb, skb->len - trailer_len);\n\tif (unlikely(ret))\n\t\treturn ret;\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\tipv4hdr->tot_len = htons(ntohs(ipv4hdr->tot_len) - trailer_len);\n\t\tip_send_check(ipv4hdr);\n\t} else {\n\t\tipv6hdr->payload_len = htons(ntohs(ipv6hdr->payload_len) -\n\t\t\t\t\t     trailer_len);\n\t}\n\treturn 0;\n}\n\nstatic void mlx5e_ipsec_set_swp(struct sk_buff *skb,\n\t\t\t\tstruct mlx5_wqe_eth_seg *eseg, u8 mode,\n\t\t\t\tstruct xfrm_offload *xo)\n{\n\t \n\n\t \n\teseg->swp_outer_l3_offset = skb_network_offset(skb) / 2;\n\tif (skb->protocol == htons(ETH_P_IPV6))\n\t\teseg->swp_flags |= MLX5_ETH_WQE_SWP_OUTER_L3_IPV6;\n\n\t \n\tif (mode == XFRM_MODE_TUNNEL) {\n\t\teseg->swp_inner_l3_offset = skb_inner_network_offset(skb) / 2;\n\t\tif (xo->proto == IPPROTO_IPV6)\n\t\t\teseg->swp_flags |= MLX5_ETH_WQE_SWP_INNER_L3_IPV6;\n\n\t\tswitch (xo->inner_ipproto) {\n\t\tcase IPPROTO_UDP:\n\t\t\teseg->swp_flags |= MLX5_ETH_WQE_SWP_INNER_L4_UDP;\n\t\t\tfallthrough;\n\t\tcase IPPROTO_TCP:\n\t\t\t \n\t\t\teseg->swp_inner_l4_offset = skb_inner_transport_offset(skb) / 2;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\n\t \n\tif (mode != XFRM_MODE_TRANSPORT)\n\t\treturn;\n\n\tif (!xo->inner_ipproto) {\n\t\tswitch (xo->proto) {\n\t\tcase IPPROTO_UDP:\n\t\t\teseg->swp_flags |= MLX5_ETH_WQE_SWP_OUTER_L4_UDP;\n\t\t\tfallthrough;\n\t\tcase IPPROTO_TCP:\n\t\t\t \n\t\t\teseg->swp_outer_l4_offset = skb_inner_transport_offset(skb) / 2;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\t \n\t\tswitch (xo->inner_ipproto) {\n\t\tcase IPPROTO_UDP:\n\t\t\teseg->swp_flags |= MLX5_ETH_WQE_SWP_INNER_L4_UDP;\n\t\t\tfallthrough;\n\t\tcase IPPROTO_TCP:\n\t\t\teseg->swp_inner_l3_offset = skb_inner_network_offset(skb) / 2;\n\t\t\teseg->swp_inner_l4_offset =\n\t\t\t\t(skb->csum_start + skb->head - skb->data) / 2;\n\t\t\tif (inner_ip_hdr(skb)->version == 6)\n\t\t\t\teseg->swp_flags |= MLX5_ETH_WQE_SWP_INNER_L3_IPV6;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n}\n\nvoid mlx5e_ipsec_set_iv_esn(struct sk_buff *skb, struct xfrm_state *x,\n\t\t\t    struct xfrm_offload *xo)\n{\n\tstruct xfrm_replay_state_esn *replay_esn = x->replay_esn;\n\t__u32 oseq = replay_esn->oseq;\n\tint iv_offset;\n\t__be64 seqno;\n\tu32 seq_hi;\n\n\tif (unlikely(skb_is_gso(skb) && oseq < MLX5E_IPSEC_ESN_SCOPE_MID &&\n\t\t     MLX5E_IPSEC_ESN_SCOPE_MID < (oseq - skb_shinfo(skb)->gso_segs))) {\n\t\tseq_hi = xo->seq.hi - 1;\n\t} else {\n\t\tseq_hi = xo->seq.hi;\n\t}\n\n\t \n\tseqno = cpu_to_be64(xo->seq.low + ((u64)seq_hi << 32));\n\tiv_offset = skb_transport_offset(skb) + sizeof(struct ip_esp_hdr);\n\tskb_store_bits(skb, iv_offset, &seqno, 8);\n}\n\nvoid mlx5e_ipsec_set_iv(struct sk_buff *skb, struct xfrm_state *x,\n\t\t\tstruct xfrm_offload *xo)\n{\n\tint iv_offset;\n\t__be64 seqno;\n\n\t \n\tseqno = cpu_to_be64(xo->seq.low + ((u64)xo->seq.hi << 32));\n\tiv_offset = skb_transport_offset(skb) + sizeof(struct ip_esp_hdr);\n\tskb_store_bits(skb, iv_offset, &seqno, 8);\n}\n\nvoid mlx5e_ipsec_handle_tx_wqe(struct mlx5e_tx_wqe *wqe,\n\t\t\t       struct mlx5e_accel_tx_ipsec_state *ipsec_st,\n\t\t\t       struct mlx5_wqe_inline_seg *inlseg)\n{\n\tinlseg->byte_count = cpu_to_be32(ipsec_st->tailen | MLX5_INLINE_SEG);\n\tesp_output_fill_trailer((u8 *)inlseg->data, 0, ipsec_st->plen, ipsec_st->xo->proto);\n}\n\nstatic int mlx5e_ipsec_set_state(struct mlx5e_priv *priv,\n\t\t\t\t struct sk_buff *skb,\n\t\t\t\t struct xfrm_state *x,\n\t\t\t\t struct xfrm_offload *xo,\n\t\t\t\t struct mlx5e_accel_tx_ipsec_state *ipsec_st)\n{\n\tunsigned int blksize, clen, alen, plen;\n\tstruct crypto_aead *aead;\n\tunsigned int tailen;\n\n\tipsec_st->x = x;\n\tipsec_st->xo = xo;\n\taead = x->data;\n\talen = crypto_aead_authsize(aead);\n\tblksize = ALIGN(crypto_aead_blocksize(aead), 4);\n\tclen = ALIGN(skb->len + 2, blksize);\n\tplen = max_t(u32, clen - skb->len, 4);\n\ttailen = plen + alen;\n\tipsec_st->plen = plen;\n\tipsec_st->tailen = tailen;\n\n\treturn 0;\n}\n\nvoid mlx5e_ipsec_tx_build_eseg(struct mlx5e_priv *priv, struct sk_buff *skb,\n\t\t\t       struct mlx5_wqe_eth_seg *eseg)\n{\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\tstruct xfrm_encap_tmpl  *encap;\n\tstruct xfrm_state *x;\n\tstruct sec_path *sp;\n\tu8 l3_proto;\n\n\tsp = skb_sec_path(skb);\n\tif (unlikely(sp->len != 1))\n\t\treturn;\n\n\tx = xfrm_input_state(skb);\n\tif (unlikely(!x))\n\t\treturn;\n\n\tif (unlikely(!x->xso.offload_handle ||\n\t\t     (skb->protocol != htons(ETH_P_IP) &&\n\t\t      skb->protocol != htons(ETH_P_IPV6))))\n\t\treturn;\n\n\tmlx5e_ipsec_set_swp(skb, eseg, x->props.mode, xo);\n\n\tl3_proto = (x->props.family == AF_INET) ?\n\t\t   ((struct iphdr *)skb_network_header(skb))->protocol :\n\t\t   ((struct ipv6hdr *)skb_network_header(skb))->nexthdr;\n\n\teseg->flow_table_metadata |= cpu_to_be32(MLX5_ETH_WQE_FT_META_IPSEC);\n\teseg->trailer |= cpu_to_be32(MLX5_ETH_WQE_INSERT_TRAILER);\n\tencap = x->encap;\n\tif (!encap) {\n\t\teseg->trailer |= (l3_proto == IPPROTO_ESP) ?\n\t\t\tcpu_to_be32(MLX5_ETH_WQE_TRAILER_HDR_OUTER_IP_ASSOC) :\n\t\t\tcpu_to_be32(MLX5_ETH_WQE_TRAILER_HDR_OUTER_L4_ASSOC);\n\t} else if (encap->encap_type == UDP_ENCAP_ESPINUDP) {\n\t\teseg->trailer |= (l3_proto == IPPROTO_ESP) ?\n\t\t\tcpu_to_be32(MLX5_ETH_WQE_TRAILER_HDR_INNER_IP_ASSOC) :\n\t\t\tcpu_to_be32(MLX5_ETH_WQE_TRAILER_HDR_INNER_L4_ASSOC);\n\t}\n}\n\nbool mlx5e_ipsec_handle_tx_skb(struct net_device *netdev,\n\t\t\t       struct sk_buff *skb,\n\t\t\t       struct mlx5e_accel_tx_ipsec_state *ipsec_st)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\tstruct xfrm_offload *xo = xfrm_offload(skb);\n\tstruct mlx5e_ipsec_sa_entry *sa_entry;\n\tstruct xfrm_state *x;\n\tstruct sec_path *sp;\n\n\tsp = skb_sec_path(skb);\n\tif (unlikely(sp->len != 1)) {\n\t\tatomic64_inc(&priv->ipsec->sw_stats.ipsec_tx_drop_bundle);\n\t\tgoto drop;\n\t}\n\n\tx = xfrm_input_state(skb);\n\tif (unlikely(!x)) {\n\t\tatomic64_inc(&priv->ipsec->sw_stats.ipsec_tx_drop_no_state);\n\t\tgoto drop;\n\t}\n\n\tif (unlikely(!x->xso.offload_handle ||\n\t\t     (skb->protocol != htons(ETH_P_IP) &&\n\t\t      skb->protocol != htons(ETH_P_IPV6)))) {\n\t\tatomic64_inc(&priv->ipsec->sw_stats.ipsec_tx_drop_not_ip);\n\t\tgoto drop;\n\t}\n\n\tif (!skb_is_gso(skb))\n\t\tif (unlikely(mlx5e_ipsec_remove_trailer(skb, x))) {\n\t\t\tatomic64_inc(&priv->ipsec->sw_stats.ipsec_tx_drop_trailer);\n\t\t\tgoto drop;\n\t\t}\n\n\tsa_entry = (struct mlx5e_ipsec_sa_entry *)x->xso.offload_handle;\n\tsa_entry->set_iv_op(skb, x, xo);\n\tmlx5e_ipsec_set_state(priv, skb, x, xo, ipsec_st);\n\n\treturn true;\n\ndrop:\n\tkfree_skb(skb);\n\treturn false;\n}\n\nenum {\n\tMLX5E_IPSEC_OFFLOAD_RX_SYNDROME_DECRYPTED,\n\tMLX5E_IPSEC_OFFLOAD_RX_SYNDROME_AUTH_FAILED,\n\tMLX5E_IPSEC_OFFLOAD_RX_SYNDROME_BAD_TRAILER,\n};\n\nvoid mlx5e_ipsec_offload_handle_rx_skb(struct net_device *netdev,\n\t\t\t\t       struct sk_buff *skb,\n\t\t\t\t       u32 ipsec_meta_data)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\tstruct mlx5e_ipsec *ipsec = priv->ipsec;\n\tstruct mlx5e_ipsec_sa_entry *sa_entry;\n\tstruct xfrm_offload *xo;\n\tstruct sec_path *sp;\n\tu32  sa_handle;\n\n\tsa_handle = MLX5_IPSEC_METADATA_HANDLE(ipsec_meta_data);\n\tsp = secpath_set(skb);\n\tif (unlikely(!sp)) {\n\t\tatomic64_inc(&ipsec->sw_stats.ipsec_rx_drop_sp_alloc);\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tsa_entry = xa_load(&ipsec->sadb, sa_handle);\n\tif (unlikely(!sa_entry)) {\n\t\trcu_read_unlock();\n\t\tatomic64_inc(&ipsec->sw_stats.ipsec_rx_drop_sadb_miss);\n\t\treturn;\n\t}\n\txfrm_state_hold(sa_entry->x);\n\trcu_read_unlock();\n\n\tsp->xvec[sp->len++] = sa_entry->x;\n\tsp->olen++;\n\n\txo = xfrm_offload(skb);\n\txo->flags = CRYPTO_DONE;\n\n\tswitch (MLX5_IPSEC_METADATA_SYNDROM(ipsec_meta_data)) {\n\tcase MLX5E_IPSEC_OFFLOAD_RX_SYNDROME_DECRYPTED:\n\t\txo->status = CRYPTO_SUCCESS;\n\t\tbreak;\n\tcase MLX5E_IPSEC_OFFLOAD_RX_SYNDROME_AUTH_FAILED:\n\t\txo->status = CRYPTO_TUNNEL_ESP_AUTH_FAILED;\n\t\tbreak;\n\tcase MLX5E_IPSEC_OFFLOAD_RX_SYNDROME_BAD_TRAILER:\n\t\txo->status = CRYPTO_INVALID_PACKET_SYNTAX;\n\t\tbreak;\n\tdefault:\n\t\tatomic64_inc(&ipsec->sw_stats.ipsec_rx_drop_syndrome);\n\t}\n}\n\nint mlx5_esw_ipsec_rx_make_metadata(struct mlx5e_priv *priv, u32 id, u32 *metadata)\n{\n\tstruct mlx5e_ipsec *ipsec = priv->ipsec;\n\tu32 ipsec_obj_id;\n\tint err;\n\n\tif (!ipsec || !ipsec->is_uplink_rep)\n\t\treturn -EINVAL;\n\n\terr = mlx5_esw_ipsec_rx_ipsec_obj_id_search(priv, id, &ipsec_obj_id);\n\tif (err) {\n\t\tatomic64_inc(&ipsec->sw_stats.ipsec_rx_drop_sadb_miss);\n\t\treturn err;\n\t}\n\n\t*metadata = MLX5_IPSEC_METADATA_CREATE(ipsec_obj_id,\n\t\t\t\t\t       MLX5E_IPSEC_OFFLOAD_RX_SYNDROME_DECRYPTED);\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}