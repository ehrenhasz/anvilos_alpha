{
  "module_name": "xdp.c",
  "hash_id": "e793d96b85e54ba429255c5df427be367697141b70da2c129dc0aa3d5cab1318",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c",
  "human_readable_source": " \n\n#include <linux/bpf_trace.h>\n#include <net/xdp_sock_drv.h>\n#include \"en/xdp.h\"\n#include \"en/params.h\"\n#include <linux/bitfield.h>\n#include <net/page_pool/helpers.h>\n\nint mlx5e_xdp_max_mtu(struct mlx5e_params *params, struct mlx5e_xsk_param *xsk)\n{\n\tint hr = mlx5e_get_linear_rq_headroom(params, xsk);\n\n\t \n\n\treturn MLX5E_HW2SW_MTU(params, SKB_MAX_HEAD(hr));\n}\n\nstatic inline bool\nmlx5e_xmit_xdp_buff(struct mlx5e_xdpsq *sq, struct mlx5e_rq *rq,\n\t\t    struct xdp_buff *xdp)\n{\n\tstruct page *page = virt_to_page(xdp->data);\n\tstruct mlx5e_xmit_data_frags xdptxdf = {};\n\tstruct mlx5e_xmit_data *xdptxd;\n\tstruct xdp_frame *xdpf;\n\tdma_addr_t dma_addr;\n\tint i;\n\n\txdpf = xdp_convert_buff_to_frame(xdp);\n\tif (unlikely(!xdpf))\n\t\treturn false;\n\n\txdptxd = &xdptxdf.xd;\n\txdptxd->data = xdpf->data;\n\txdptxd->len  = xdpf->len;\n\txdptxd->has_frags = xdp_frame_has_frags(xdpf);\n\n\tif (xdp->rxq->mem.type == MEM_TYPE_XSK_BUFF_POOL) {\n\t\t \n\n\t\t \n\t\t__set_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags);  \n\n\t\tif (unlikely(xdptxd->has_frags))\n\t\t\treturn false;\n\n\t\tdma_addr = dma_map_single(sq->pdev, xdptxd->data, xdptxd->len,\n\t\t\t\t\t  DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(sq->pdev, dma_addr)) {\n\t\t\txdp_return_frame(xdpf);\n\t\t\treturn false;\n\t\t}\n\n\t\txdptxd->dma_addr = dma_addr;\n\n\t\tif (unlikely(!INDIRECT_CALL_2(sq->xmit_xdp_frame, mlx5e_xmit_xdp_frame_mpwqe,\n\t\t\t\t\t      mlx5e_xmit_xdp_frame, sq, xdptxd, 0)))\n\t\t\treturn false;\n\n\t\t \n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .mode = MLX5E_XDP_XMIT_MODE_FRAME });\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .frame.xdpf = xdpf });\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .frame.dma_addr = dma_addr });\n\t\treturn true;\n\t}\n\n\t \n\n\tdma_addr = page_pool_get_dma_addr(page) + (xdpf->data - (void *)xdpf);\n\tdma_sync_single_for_device(sq->pdev, dma_addr, xdptxd->len, DMA_BIDIRECTIONAL);\n\n\tif (xdptxd->has_frags) {\n\t\txdptxdf.sinfo = xdp_get_shared_info_from_frame(xdpf);\n\t\txdptxdf.dma_arr = NULL;\n\n\t\tfor (i = 0; i < xdptxdf.sinfo->nr_frags; i++) {\n\t\t\tskb_frag_t *frag = &xdptxdf.sinfo->frags[i];\n\t\t\tdma_addr_t addr;\n\t\t\tu32 len;\n\n\t\t\taddr = page_pool_get_dma_addr(skb_frag_page(frag)) +\n\t\t\t\tskb_frag_off(frag);\n\t\t\tlen = skb_frag_size(frag);\n\t\t\tdma_sync_single_for_device(sq->pdev, addr, len,\n\t\t\t\t\t\t   DMA_BIDIRECTIONAL);\n\t\t}\n\t}\n\n\txdptxd->dma_addr = dma_addr;\n\n\tif (unlikely(!INDIRECT_CALL_2(sq->xmit_xdp_frame, mlx5e_xmit_xdp_frame_mpwqe,\n\t\t\t\t      mlx5e_xmit_xdp_frame, sq, xdptxd, 0)))\n\t\treturn false;\n\n\t \n\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t     (union mlx5e_xdp_info) { .mode = MLX5E_XDP_XMIT_MODE_PAGE });\n\n\tif (xdptxd->has_frags) {\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info)\n\t\t\t\t     { .page.num = 1 + xdptxdf.sinfo->nr_frags });\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .page.page = page });\n\t\tfor (i = 0; i < xdptxdf.sinfo->nr_frags; i++) {\n\t\t\tskb_frag_t *frag = &xdptxdf.sinfo->frags[i];\n\n\t\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t\t     (union mlx5e_xdp_info)\n\t\t\t\t\t     { .page.page = skb_frag_page(frag) });\n\t\t}\n\t} else {\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .page.num = 1 });\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .page.page = page });\n\t}\n\n\treturn true;\n}\n\nstatic int mlx5e_xdp_rx_timestamp(const struct xdp_md *ctx, u64 *timestamp)\n{\n\tconst struct mlx5e_xdp_buff *_ctx = (void *)ctx;\n\n\tif (unlikely(!mlx5e_rx_hw_stamp(_ctx->rq->tstamp)))\n\t\treturn -ENODATA;\n\n\t*timestamp =  mlx5e_cqe_ts_to_ns(_ctx->rq->ptp_cyc2time,\n\t\t\t\t\t _ctx->rq->clock, get_cqe_ts(_ctx->cqe));\n\treturn 0;\n}\n\n \n#define RSS_TYPE_MAX_TABLE\t16  \n#define RSS_L4\t\tGENMASK(1, 0)\n#define RSS_L3\t\tGENMASK(3, 2)  \n\n \nenum mlx5_rss_hash_type {\n\tRSS_TYPE_NO_HASH\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IP_NONE) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_NONE)),\n\tRSS_TYPE_L3_IPV4\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV4) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_NONE)),\n\tRSS_TYPE_L4_IPV4_TCP\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV4) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_TCP)),\n\tRSS_TYPE_L4_IPV4_UDP\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV4) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_UDP)),\n\tRSS_TYPE_L4_IPV4_IPSEC\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV4) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_IPSEC)),\n\tRSS_TYPE_L3_IPV6\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV6) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_NONE)),\n\tRSS_TYPE_L4_IPV6_TCP\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV6) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_TCP)),\n\tRSS_TYPE_L4_IPV6_UDP\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV6) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_UDP)),\n\tRSS_TYPE_L4_IPV6_IPSEC\t= (FIELD_PREP_CONST(RSS_L3, CQE_RSS_IPV6) |\n\t\t\t\t   FIELD_PREP_CONST(RSS_L4, CQE_RSS_L4_IPSEC)),\n};\n\n \nstatic const enum xdp_rss_hash_type mlx5_xdp_rss_type[RSS_TYPE_MAX_TABLE] = {\n\t[RSS_TYPE_NO_HASH]\t = XDP_RSS_TYPE_NONE,\n\t[1]\t\t\t = XDP_RSS_TYPE_NONE,  \n\t[2]\t\t\t = XDP_RSS_TYPE_NONE,  \n\t[3]\t\t\t = XDP_RSS_TYPE_NONE,  \n\t[RSS_TYPE_L3_IPV4]\t = XDP_RSS_TYPE_L3_IPV4,\n\t[RSS_TYPE_L4_IPV4_TCP]\t = XDP_RSS_TYPE_L4_IPV4_TCP,\n\t[RSS_TYPE_L4_IPV4_UDP]\t = XDP_RSS_TYPE_L4_IPV4_UDP,\n\t[RSS_TYPE_L4_IPV4_IPSEC] = XDP_RSS_TYPE_L4_IPV4_IPSEC,\n\t[RSS_TYPE_L3_IPV6]\t = XDP_RSS_TYPE_L3_IPV6,\n\t[RSS_TYPE_L4_IPV6_TCP]\t = XDP_RSS_TYPE_L4_IPV6_TCP,\n\t[RSS_TYPE_L4_IPV6_UDP]   = XDP_RSS_TYPE_L4_IPV6_UDP,\n\t[RSS_TYPE_L4_IPV6_IPSEC] = XDP_RSS_TYPE_L4_IPV6_IPSEC,\n\t[12]\t\t\t = XDP_RSS_TYPE_NONE,  \n\t[13]\t\t\t = XDP_RSS_TYPE_NONE,  \n\t[14]\t\t\t = XDP_RSS_TYPE_NONE,  \n\t[15]\t\t\t = XDP_RSS_TYPE_NONE,  \n};\n\nstatic int mlx5e_xdp_rx_hash(const struct xdp_md *ctx, u32 *hash,\n\t\t\t     enum xdp_rss_hash_type *rss_type)\n{\n\tconst struct mlx5e_xdp_buff *_ctx = (void *)ctx;\n\tconst struct mlx5_cqe64 *cqe = _ctx->cqe;\n\tu32 hash_type, l4_type, ip_type, lookup;\n\n\tif (unlikely(!(_ctx->xdp.rxq->dev->features & NETIF_F_RXHASH)))\n\t\treturn -ENODATA;\n\n\t*hash = be32_to_cpu(cqe->rss_hash_result);\n\n\thash_type = cqe->rss_hash_type;\n\tBUILD_BUG_ON(CQE_RSS_HTYPE_IP != RSS_L3);  \n\tip_type = hash_type & CQE_RSS_HTYPE_IP;\n\tl4_type = FIELD_GET(CQE_RSS_HTYPE_L4, hash_type);\n\tlookup = ip_type | l4_type;\n\t*rss_type = mlx5_xdp_rss_type[lookup];\n\n\treturn 0;\n}\n\nconst struct xdp_metadata_ops mlx5e_xdp_metadata_ops = {\n\t.xmo_rx_timestamp\t\t= mlx5e_xdp_rx_timestamp,\n\t.xmo_rx_hash\t\t\t= mlx5e_xdp_rx_hash,\n};\n\n \nbool mlx5e_xdp_handle(struct mlx5e_rq *rq,\n\t\t      struct bpf_prog *prog, struct mlx5e_xdp_buff *mxbuf)\n{\n\tstruct xdp_buff *xdp = &mxbuf->xdp;\n\tu32 act;\n\tint err;\n\n\tact = bpf_prog_run_xdp(prog, xdp);\n\tswitch (act) {\n\tcase XDP_PASS:\n\t\treturn false;\n\tcase XDP_TX:\n\t\tif (unlikely(!mlx5e_xmit_xdp_buff(rq->xdpsq, rq, xdp)))\n\t\t\tgoto xdp_abort;\n\t\t__set_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags);  \n\t\treturn true;\n\tcase XDP_REDIRECT:\n\t\t \n\t\terr = xdp_do_redirect(rq->netdev, xdp, prog);\n\t\tif (unlikely(err))\n\t\t\tgoto xdp_abort;\n\t\t__set_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags);\n\t\t__set_bit(MLX5E_RQ_FLAG_XDP_REDIRECT, rq->flags);\n\t\trq->stats->xdp_redirect++;\n\t\treturn true;\n\tdefault:\n\t\tbpf_warn_invalid_xdp_action(rq->netdev, prog, act);\n\t\tfallthrough;\n\tcase XDP_ABORTED:\nxdp_abort:\n\t\ttrace_xdp_exception(rq->netdev, prog, act);\n\t\tfallthrough;\n\tcase XDP_DROP:\n\t\trq->stats->xdp_drop++;\n\t\treturn true;\n\t}\n}\n\nstatic u16 mlx5e_xdpsq_get_next_pi(struct mlx5e_xdpsq *sq, u16 size)\n{\n\tstruct mlx5_wq_cyc *wq = &sq->wq;\n\tu16 pi, contig_wqebbs;\n\n\tpi = mlx5_wq_cyc_ctr2ix(wq, sq->pc);\n\tcontig_wqebbs = mlx5_wq_cyc_get_contig_wqebbs(wq, pi);\n\tif (unlikely(contig_wqebbs < size)) {\n\t\tstruct mlx5e_xdp_wqe_info *wi, *edge_wi;\n\n\t\twi = &sq->db.wqe_info[pi];\n\t\tedge_wi = wi + contig_wqebbs;\n\n\t\t \n\t\tfor (; wi < edge_wi; wi++) {\n\t\t\t*wi = (struct mlx5e_xdp_wqe_info) {\n\t\t\t\t.num_wqebbs = 1,\n\t\t\t\t.num_pkts = 0,\n\t\t\t};\n\t\t\tmlx5e_post_nop(wq, sq->sqn, &sq->pc);\n\t\t}\n\t\tsq->stats->nops += contig_wqebbs;\n\n\t\tpi = mlx5_wq_cyc_ctr2ix(wq, sq->pc);\n\t}\n\n\treturn pi;\n}\n\nstatic void mlx5e_xdp_mpwqe_session_start(struct mlx5e_xdpsq *sq)\n{\n\tstruct mlx5e_tx_mpwqe *session = &sq->mpwqe;\n\tstruct mlx5e_xdpsq_stats *stats = sq->stats;\n\tstruct mlx5e_tx_wqe *wqe;\n\tu16 pi;\n\n\tpi = mlx5e_xdpsq_get_next_pi(sq, sq->max_sq_mpw_wqebbs);\n\twqe = MLX5E_TX_FETCH_WQE(sq, pi);\n\tnet_prefetchw(wqe->data);\n\n\t*session = (struct mlx5e_tx_mpwqe) {\n\t\t.wqe = wqe,\n\t\t.bytes_count = 0,\n\t\t.ds_count = MLX5E_TX_WQE_EMPTY_DS_COUNT,\n\t\t.pkt_count = 0,\n\t\t.inline_on = mlx5e_xdp_get_inline_state(sq, session->inline_on),\n\t};\n\n\tstats->mpwqe++;\n}\n\nvoid mlx5e_xdp_mpwqe_complete(struct mlx5e_xdpsq *sq)\n{\n\tstruct mlx5_wq_cyc       *wq    = &sq->wq;\n\tstruct mlx5e_tx_mpwqe *session = &sq->mpwqe;\n\tstruct mlx5_wqe_ctrl_seg *cseg = &session->wqe->ctrl;\n\tu16 ds_count = session->ds_count;\n\tu16 pi = mlx5_wq_cyc_ctr2ix(wq, sq->pc);\n\tstruct mlx5e_xdp_wqe_info *wi = &sq->db.wqe_info[pi];\n\n\tcseg->opmod_idx_opcode =\n\t\tcpu_to_be32((sq->pc << 8) | MLX5_OPCODE_ENHANCED_MPSW);\n\tcseg->qpn_ds = cpu_to_be32((sq->sqn << 8) | ds_count);\n\n\twi->num_wqebbs = DIV_ROUND_UP(ds_count, MLX5_SEND_WQEBB_NUM_DS);\n\twi->num_pkts   = session->pkt_count;\n\n\tsq->pc += wi->num_wqebbs;\n\n\tsq->doorbell_cseg = cseg;\n\n\tsession->wqe = NULL;  \n}\n\nenum {\n\tMLX5E_XDP_CHECK_OK = 1,\n\tMLX5E_XDP_CHECK_START_MPWQE = 2,\n};\n\nINDIRECT_CALLABLE_SCOPE int mlx5e_xmit_xdp_frame_check_mpwqe(struct mlx5e_xdpsq *sq)\n{\n\tif (unlikely(!sq->mpwqe.wqe)) {\n\t\tif (unlikely(!mlx5e_wqc_has_room_for(&sq->wq, sq->cc, sq->pc,\n\t\t\t\t\t\t     sq->stop_room))) {\n\t\t\t \n\t\t\tmlx5e_xmit_xdp_doorbell(sq);\n\t\t\tsq->stats->full++;\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\treturn MLX5E_XDP_CHECK_START_MPWQE;\n\t}\n\n\treturn MLX5E_XDP_CHECK_OK;\n}\n\nINDIRECT_CALLABLE_SCOPE bool\nmlx5e_xmit_xdp_frame(struct mlx5e_xdpsq *sq, struct mlx5e_xmit_data *xdptxd,\n\t\t     int check_result);\n\nINDIRECT_CALLABLE_SCOPE bool\nmlx5e_xmit_xdp_frame_mpwqe(struct mlx5e_xdpsq *sq, struct mlx5e_xmit_data *xdptxd,\n\t\t\t   int check_result)\n{\n\tstruct mlx5e_tx_mpwqe *session = &sq->mpwqe;\n\tstruct mlx5e_xdpsq_stats *stats = sq->stats;\n\tstruct mlx5e_xmit_data *p = xdptxd;\n\tstruct mlx5e_xmit_data tmp;\n\n\tif (xdptxd->has_frags) {\n\t\tstruct mlx5e_xmit_data_frags *xdptxdf =\n\t\t\tcontainer_of(xdptxd, struct mlx5e_xmit_data_frags, xd);\n\n\t\tif (!!xdptxd->len + xdptxdf->sinfo->nr_frags > 1) {\n\t\t\t \n\t\t\tif (unlikely(sq->mpwqe.wqe))\n\t\t\t\tmlx5e_xdp_mpwqe_complete(sq);\n\t\t\treturn mlx5e_xmit_xdp_frame(sq, xdptxd, 0);\n\t\t}\n\t\tif (!xdptxd->len) {\n\t\t\tskb_frag_t *frag = &xdptxdf->sinfo->frags[0];\n\n\t\t\ttmp.data = skb_frag_address(frag);\n\t\t\ttmp.len = skb_frag_size(frag);\n\t\t\ttmp.dma_addr = xdptxdf->dma_arr ? xdptxdf->dma_arr[0] :\n\t\t\t\tpage_pool_get_dma_addr(skb_frag_page(frag)) +\n\t\t\t\tskb_frag_off(frag);\n\t\t\tp = &tmp;\n\t\t}\n\t}\n\n\tif (unlikely(p->len > sq->hw_mtu)) {\n\t\tstats->err++;\n\t\treturn false;\n\t}\n\n\tif (!check_result)\n\t\tcheck_result = mlx5e_xmit_xdp_frame_check_mpwqe(sq);\n\tif (unlikely(check_result < 0))\n\t\treturn false;\n\n\tif (check_result == MLX5E_XDP_CHECK_START_MPWQE) {\n\t\t \n\t\tmlx5e_xdp_mpwqe_session_start(sq);\n\t}\n\n\tmlx5e_xdp_mpwqe_add_dseg(sq, p, stats);\n\n\tif (unlikely(mlx5e_xdp_mpwqe_is_full(session, sq->max_sq_mpw_wqebbs)))\n\t\tmlx5e_xdp_mpwqe_complete(sq);\n\n\tstats->xmit++;\n\treturn true;\n}\n\nstatic int mlx5e_xmit_xdp_frame_check_stop_room(struct mlx5e_xdpsq *sq, int stop_room)\n{\n\tif (unlikely(!mlx5e_wqc_has_room_for(&sq->wq, sq->cc, sq->pc, stop_room))) {\n\t\t \n\t\tmlx5e_xmit_xdp_doorbell(sq);\n\t\tsq->stats->full++;\n\t\treturn -EBUSY;\n\t}\n\n\treturn MLX5E_XDP_CHECK_OK;\n}\n\nINDIRECT_CALLABLE_SCOPE int mlx5e_xmit_xdp_frame_check(struct mlx5e_xdpsq *sq)\n{\n\treturn mlx5e_xmit_xdp_frame_check_stop_room(sq, 1);\n}\n\nINDIRECT_CALLABLE_SCOPE bool\nmlx5e_xmit_xdp_frame(struct mlx5e_xdpsq *sq, struct mlx5e_xmit_data *xdptxd,\n\t\t     int check_result)\n{\n\tstruct mlx5e_xmit_data_frags *xdptxdf =\n\t\tcontainer_of(xdptxd, struct mlx5e_xmit_data_frags, xd);\n\tstruct mlx5_wq_cyc       *wq   = &sq->wq;\n\tstruct mlx5_wqe_ctrl_seg *cseg;\n\tstruct mlx5_wqe_data_seg *dseg;\n\tstruct mlx5_wqe_eth_seg *eseg;\n\tstruct mlx5e_tx_wqe *wqe;\n\n\tdma_addr_t dma_addr = xdptxd->dma_addr;\n\tu32 dma_len = xdptxd->len;\n\tu16 ds_cnt, inline_hdr_sz;\n\tunsigned int frags_size;\n\tu8 num_wqebbs = 1;\n\tint num_frags = 0;\n\tbool inline_ok;\n\tbool linear;\n\tu16 pi;\n\n\tstruct mlx5e_xdpsq_stats *stats = sq->stats;\n\n\tinline_ok = sq->min_inline_mode == MLX5_INLINE_MODE_NONE ||\n\t\tdma_len >= MLX5E_XDP_MIN_INLINE;\n\tfrags_size = xdptxd->has_frags ? xdptxdf->sinfo->xdp_frags_size : 0;\n\n\tif (unlikely(!inline_ok || sq->hw_mtu < dma_len + frags_size)) {\n\t\tstats->err++;\n\t\treturn false;\n\t}\n\n\tinline_hdr_sz = 0;\n\tif (sq->min_inline_mode != MLX5_INLINE_MODE_NONE)\n\t\tinline_hdr_sz = MLX5E_XDP_MIN_INLINE;\n\n\tlinear = !!(dma_len - inline_hdr_sz);\n\tds_cnt = MLX5E_TX_WQE_EMPTY_DS_COUNT + linear + !!inline_hdr_sz;\n\n\t \n\tif (!check_result) {\n\t\tint stop_room = 1;\n\n\t\tif (xdptxd->has_frags) {\n\t\t\tds_cnt += xdptxdf->sinfo->nr_frags;\n\t\t\tnum_frags = xdptxdf->sinfo->nr_frags;\n\t\t\tnum_wqebbs = DIV_ROUND_UP(ds_cnt, MLX5_SEND_WQEBB_NUM_DS);\n\t\t\t \n\t\t\tstop_room = MLX5E_STOP_ROOM(num_wqebbs);\n\t\t}\n\n\t\tcheck_result = mlx5e_xmit_xdp_frame_check_stop_room(sq, stop_room);\n\t}\n\tif (unlikely(check_result < 0))\n\t\treturn false;\n\n\tpi = mlx5e_xdpsq_get_next_pi(sq, num_wqebbs);\n\twqe = mlx5_wq_cyc_get_wqe(wq, pi);\n\tnet_prefetchw(wqe);\n\n\tcseg = &wqe->ctrl;\n\teseg = &wqe->eth;\n\tdseg = wqe->data;\n\n\t \n\tif (inline_hdr_sz) {\n\t\tmemcpy(eseg->inline_hdr.start, xdptxd->data, sizeof(eseg->inline_hdr.start));\n\t\tmemcpy(dseg, xdptxd->data + sizeof(eseg->inline_hdr.start),\n\t\t       inline_hdr_sz - sizeof(eseg->inline_hdr.start));\n\t\tdma_len  -= inline_hdr_sz;\n\t\tdma_addr += inline_hdr_sz;\n\t\tdseg++;\n\t}\n\n\t \n\tif (linear) {\n\t\tdseg->addr       = cpu_to_be64(dma_addr);\n\t\tdseg->byte_count = cpu_to_be32(dma_len);\n\t\tdseg->lkey       = sq->mkey_be;\n\t\tdseg++;\n\t}\n\n\tcseg->opmod_idx_opcode = cpu_to_be32((sq->pc << 8) | MLX5_OPCODE_SEND);\n\n\tif (test_bit(MLX5E_SQ_STATE_XDP_MULTIBUF, &sq->state)) {\n\t\tint i;\n\n\t\tmemset(&cseg->trailer, 0, sizeof(cseg->trailer));\n\t\tmemset(eseg, 0, sizeof(*eseg) - sizeof(eseg->trailer));\n\n\t\teseg->inline_hdr.sz = cpu_to_be16(inline_hdr_sz);\n\n\t\tfor (i = 0; i < num_frags; i++) {\n\t\t\tskb_frag_t *frag = &xdptxdf->sinfo->frags[i];\n\t\t\tdma_addr_t addr;\n\n\t\t\taddr = xdptxdf->dma_arr ? xdptxdf->dma_arr[i] :\n\t\t\t\tpage_pool_get_dma_addr(skb_frag_page(frag)) +\n\t\t\t\tskb_frag_off(frag);\n\n\t\t\tdseg->addr = cpu_to_be64(addr);\n\t\t\tdseg->byte_count = cpu_to_be32(skb_frag_size(frag));\n\t\t\tdseg->lkey = sq->mkey_be;\n\t\t\tdseg++;\n\t\t}\n\n\t\tcseg->qpn_ds = cpu_to_be32((sq->sqn << 8) | ds_cnt);\n\n\t\tsq->db.wqe_info[pi] = (struct mlx5e_xdp_wqe_info) {\n\t\t\t.num_wqebbs = num_wqebbs,\n\t\t\t.num_pkts = 1,\n\t\t};\n\n\t\tsq->pc += num_wqebbs;\n\t} else {\n\t\tcseg->fm_ce_se = 0;\n\n\t\tsq->pc++;\n\t}\n\n\tsq->doorbell_cseg = cseg;\n\n\tstats->xmit++;\n\treturn true;\n}\n\nstatic void mlx5e_free_xdpsq_desc(struct mlx5e_xdpsq *sq,\n\t\t\t\t  struct mlx5e_xdp_wqe_info *wi,\n\t\t\t\t  u32 *xsk_frames,\n\t\t\t\t  struct xdp_frame_bulk *bq)\n{\n\tstruct mlx5e_xdp_info_fifo *xdpi_fifo = &sq->db.xdpi_fifo;\n\tu16 i;\n\n\tfor (i = 0; i < wi->num_pkts; i++) {\n\t\tunion mlx5e_xdp_info xdpi = mlx5e_xdpi_fifo_pop(xdpi_fifo);\n\n\t\tswitch (xdpi.mode) {\n\t\tcase MLX5E_XDP_XMIT_MODE_FRAME: {\n\t\t\t \n\t\t\tstruct xdp_frame *xdpf;\n\t\t\tdma_addr_t dma_addr;\n\n\t\t\txdpi = mlx5e_xdpi_fifo_pop(xdpi_fifo);\n\t\t\txdpf = xdpi.frame.xdpf;\n\t\t\txdpi = mlx5e_xdpi_fifo_pop(xdpi_fifo);\n\t\t\tdma_addr = xdpi.frame.dma_addr;\n\n\t\t\tdma_unmap_single(sq->pdev, dma_addr,\n\t\t\t\t\t xdpf->len, DMA_TO_DEVICE);\n\t\t\tif (xdp_frame_has_frags(xdpf)) {\n\t\t\t\tstruct skb_shared_info *sinfo;\n\t\t\t\tint j;\n\n\t\t\t\tsinfo = xdp_get_shared_info_from_frame(xdpf);\n\t\t\t\tfor (j = 0; j < sinfo->nr_frags; j++) {\n\t\t\t\t\tskb_frag_t *frag = &sinfo->frags[j];\n\n\t\t\t\t\txdpi = mlx5e_xdpi_fifo_pop(xdpi_fifo);\n\t\t\t\t\tdma_addr = xdpi.frame.dma_addr;\n\n\t\t\t\t\tdma_unmap_single(sq->pdev, dma_addr,\n\t\t\t\t\t\t\t skb_frag_size(frag), DMA_TO_DEVICE);\n\t\t\t\t}\n\t\t\t}\n\t\t\txdp_return_frame_bulk(xdpf, bq);\n\t\t\tbreak;\n\t\t}\n\t\tcase MLX5E_XDP_XMIT_MODE_PAGE: {\n\t\t\t \n\t\t\tu8 num, n = 0;\n\n\t\t\txdpi = mlx5e_xdpi_fifo_pop(xdpi_fifo);\n\t\t\tnum = xdpi.page.num;\n\n\t\t\tdo {\n\t\t\t\tstruct page *page;\n\n\t\t\t\txdpi = mlx5e_xdpi_fifo_pop(xdpi_fifo);\n\t\t\t\tpage = xdpi.page.page;\n\n\t\t\t\t \n\t\t\t\tpage_pool_recycle_direct(page->pp, page);\n\t\t\t} while (++n < num);\n\n\t\t\tbreak;\n\t\t}\n\t\tcase MLX5E_XDP_XMIT_MODE_XSK:\n\t\t\t \n\t\t\t(*xsk_frames)++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tWARN_ON_ONCE(true);\n\t\t}\n\t}\n}\n\nbool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)\n{\n\tstruct xdp_frame_bulk bq;\n\tstruct mlx5e_xdpsq *sq;\n\tstruct mlx5_cqe64 *cqe;\n\tu32 xsk_frames = 0;\n\tu16 sqcc;\n\tint i;\n\n\txdp_frame_bulk_init(&bq);\n\n\tsq = container_of(cq, struct mlx5e_xdpsq, cq);\n\n\tif (unlikely(!test_bit(MLX5E_SQ_STATE_ENABLED, &sq->state)))\n\t\treturn false;\n\n\tcqe = mlx5_cqwq_get_cqe(&cq->wq);\n\tif (!cqe)\n\t\treturn false;\n\n\t \n\tsqcc = sq->cc;\n\n\ti = 0;\n\tdo {\n\t\tstruct mlx5e_xdp_wqe_info *wi;\n\t\tu16 wqe_counter, ci;\n\t\tbool last_wqe;\n\n\t\tmlx5_cqwq_pop(&cq->wq);\n\n\t\twqe_counter = be16_to_cpu(cqe->wqe_counter);\n\n\t\tdo {\n\t\t\tlast_wqe = (sqcc == wqe_counter);\n\t\t\tci = mlx5_wq_cyc_ctr2ix(&sq->wq, sqcc);\n\t\t\twi = &sq->db.wqe_info[ci];\n\n\t\t\tsqcc += wi->num_wqebbs;\n\n\t\t\tmlx5e_free_xdpsq_desc(sq, wi, &xsk_frames, &bq);\n\t\t} while (!last_wqe);\n\n\t\tif (unlikely(get_cqe_opcode(cqe) != MLX5_CQE_REQ)) {\n\t\t\tnetdev_WARN_ONCE(sq->channel->netdev,\n\t\t\t\t\t \"Bad OP in XDPSQ CQE: 0x%x\\n\",\n\t\t\t\t\t get_cqe_opcode(cqe));\n\t\t\tmlx5e_dump_error_cqe(&sq->cq, sq->sqn,\n\t\t\t\t\t     (struct mlx5_err_cqe *)cqe);\n\t\t\tmlx5_wq_cyc_wqe_dump(&sq->wq, ci, wi->num_wqebbs);\n\t\t}\n\t} while ((++i < MLX5E_TX_CQ_POLL_BUDGET) && (cqe = mlx5_cqwq_get_cqe(&cq->wq)));\n\n\txdp_flush_frame_bulk(&bq);\n\n\tif (xsk_frames)\n\t\txsk_tx_completed(sq->xsk_pool, xsk_frames);\n\n\tsq->stats->cqes += i;\n\n\tmlx5_cqwq_update_db_record(&cq->wq);\n\n\t \n\twmb();\n\n\tsq->cc = sqcc;\n\treturn (i == MLX5E_TX_CQ_POLL_BUDGET);\n}\n\nvoid mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq)\n{\n\tstruct xdp_frame_bulk bq;\n\tu32 xsk_frames = 0;\n\n\txdp_frame_bulk_init(&bq);\n\n\trcu_read_lock();  \n\n\twhile (sq->cc != sq->pc) {\n\t\tstruct mlx5e_xdp_wqe_info *wi;\n\t\tu16 ci;\n\n\t\tci = mlx5_wq_cyc_ctr2ix(&sq->wq, sq->cc);\n\t\twi = &sq->db.wqe_info[ci];\n\n\t\tsq->cc += wi->num_wqebbs;\n\n\t\tmlx5e_free_xdpsq_desc(sq, wi, &xsk_frames, &bq);\n\t}\n\n\txdp_flush_frame_bulk(&bq);\n\trcu_read_unlock();\n\n\tif (xsk_frames)\n\t\txsk_tx_completed(sq->xsk_pool, xsk_frames);\n}\n\nint mlx5e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,\n\t\t   u32 flags)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\tstruct mlx5e_xdpsq *sq;\n\tint nxmit = 0;\n\tint sq_num;\n\tint i;\n\n\t \n\tif (unlikely(!mlx5e_xdp_tx_is_enabled(priv)))\n\t\treturn -ENETDOWN;\n\n\tif (unlikely(flags & ~XDP_XMIT_FLAGS_MASK))\n\t\treturn -EINVAL;\n\n\tsq_num = smp_processor_id();\n\n\tif (unlikely(sq_num >= priv->channels.num))\n\t\treturn -ENXIO;\n\n\tsq = &priv->channels.c[sq_num]->xdpsq;\n\n\tfor (i = 0; i < n; i++) {\n\t\tstruct mlx5e_xmit_data_frags xdptxdf = {};\n\t\tstruct xdp_frame *xdpf = frames[i];\n\t\tdma_addr_t dma_arr[MAX_SKB_FRAGS];\n\t\tstruct mlx5e_xmit_data *xdptxd;\n\t\tbool ret;\n\n\t\txdptxd = &xdptxdf.xd;\n\t\txdptxd->data = xdpf->data;\n\t\txdptxd->len = xdpf->len;\n\t\txdptxd->has_frags = xdp_frame_has_frags(xdpf);\n\t\txdptxd->dma_addr = dma_map_single(sq->pdev, xdptxd->data,\n\t\t\t\t\t\t  xdptxd->len, DMA_TO_DEVICE);\n\n\t\tif (unlikely(dma_mapping_error(sq->pdev, xdptxd->dma_addr)))\n\t\t\tbreak;\n\n\t\tif (xdptxd->has_frags) {\n\t\t\tint j;\n\n\t\t\txdptxdf.sinfo = xdp_get_shared_info_from_frame(xdpf);\n\t\t\txdptxdf.dma_arr = dma_arr;\n\t\t\tfor (j = 0; j < xdptxdf.sinfo->nr_frags; j++) {\n\t\t\t\tskb_frag_t *frag = &xdptxdf.sinfo->frags[j];\n\n\t\t\t\tdma_arr[j] = dma_map_single(sq->pdev, skb_frag_address(frag),\n\t\t\t\t\t\t\t    skb_frag_size(frag), DMA_TO_DEVICE);\n\n\t\t\t\tif (!dma_mapping_error(sq->pdev, dma_arr[j]))\n\t\t\t\t\tcontinue;\n\t\t\t\t \n\t\t\t\twhile (--j >= 0)\n\t\t\t\t\tdma_unmap_single(sq->pdev, dma_arr[j],\n\t\t\t\t\t\t\t skb_frag_size(&xdptxdf.sinfo->frags[j]),\n\t\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tret = INDIRECT_CALL_2(sq->xmit_xdp_frame, mlx5e_xmit_xdp_frame_mpwqe,\n\t\t\t\t      mlx5e_xmit_xdp_frame, sq, xdptxd, 0);\n\t\tif (unlikely(!ret)) {\n\t\t\tint j;\n\n\t\t\tdma_unmap_single(sq->pdev, xdptxd->dma_addr,\n\t\t\t\t\t xdptxd->len, DMA_TO_DEVICE);\n\t\t\tif (!xdptxd->has_frags)\n\t\t\t\tbreak;\n\t\t\tfor (j = 0; j < xdptxdf.sinfo->nr_frags; j++)\n\t\t\t\tdma_unmap_single(sq->pdev, dma_arr[j],\n\t\t\t\t\t\t skb_frag_size(&xdptxdf.sinfo->frags[j]),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .mode = MLX5E_XDP_XMIT_MODE_FRAME });\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .frame.xdpf = xdpf });\n\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t     (union mlx5e_xdp_info) { .frame.dma_addr = xdptxd->dma_addr });\n\t\tif (xdptxd->has_frags) {\n\t\t\tint j;\n\n\t\t\tfor (j = 0; j < xdptxdf.sinfo->nr_frags; j++)\n\t\t\t\tmlx5e_xdpi_fifo_push(&sq->db.xdpi_fifo,\n\t\t\t\t\t\t     (union mlx5e_xdp_info)\n\t\t\t\t\t\t     { .frame.dma_addr = dma_arr[j] });\n\t\t}\n\t\tnxmit++;\n\t}\n\nout:\n\tif (sq->mpwqe.wqe)\n\t\tmlx5e_xdp_mpwqe_complete(sq);\n\n\tif (flags & XDP_XMIT_FLUSH)\n\t\tmlx5e_xmit_xdp_doorbell(sq);\n\n\treturn nxmit;\n}\n\nvoid mlx5e_xdp_rx_poll_complete(struct mlx5e_rq *rq)\n{\n\tstruct mlx5e_xdpsq *xdpsq = rq->xdpsq;\n\n\tif (xdpsq->mpwqe.wqe)\n\t\tmlx5e_xdp_mpwqe_complete(xdpsq);\n\n\tmlx5e_xmit_xdp_doorbell(xdpsq);\n\n\tif (test_bit(MLX5E_RQ_FLAG_XDP_REDIRECT, rq->flags)) {\n\t\txdp_do_flush_map();\n\t\t__clear_bit(MLX5E_RQ_FLAG_XDP_REDIRECT, rq->flags);\n\t}\n}\n\nvoid mlx5e_set_xmit_fp(struct mlx5e_xdpsq *sq, bool is_mpw)\n{\n\tsq->xmit_xdp_frame_check = is_mpw ?\n\t\tmlx5e_xmit_xdp_frame_check_mpwqe : mlx5e_xmit_xdp_frame_check;\n\tsq->xmit_xdp_frame = is_mpw ?\n\t\tmlx5e_xmit_xdp_frame_mpwqe : mlx5e_xmit_xdp_frame;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}