{
  "module_name": "dr_domain.c",
  "hash_id": "f7a796fa73c72a30ccd7605c6a488f525990c3e85f9b07662cb746458bcf79a0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_domain.c",
  "human_readable_source": "\n \n\n#include <linux/mlx5/eswitch.h>\n#include <linux/err.h>\n#include \"dr_types.h\"\n\n#define DR_DOMAIN_SW_STEERING_SUPPORTED(dmn, dmn_type)\t\\\n\t((dmn)->info.caps.dmn_type##_sw_owner ||\t\\\n\t ((dmn)->info.caps.dmn_type##_sw_owner_v2 &&\t\\\n\t  (dmn)->info.caps.sw_format_ver <= MLX5_STEERING_FORMAT_CONNECTX_7))\n\nbool mlx5dr_domain_is_support_ptrn_arg(struct mlx5dr_domain *dmn)\n{\n\treturn dmn->info.caps.sw_format_ver >= MLX5_STEERING_FORMAT_CONNECTX_6DX &&\n\t       dmn->info.caps.support_modify_argument;\n}\n\nstatic int dr_domain_init_modify_header_resources(struct mlx5dr_domain *dmn)\n{\n\tif (!mlx5dr_domain_is_support_ptrn_arg(dmn))\n\t\treturn 0;\n\n\tdmn->ptrn_mgr = mlx5dr_ptrn_mgr_create(dmn);\n\tif (!dmn->ptrn_mgr) {\n\t\tmlx5dr_err(dmn, \"Couldn't create ptrn_mgr\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tdmn->arg_mgr = mlx5dr_arg_mgr_create(dmn);\n\tif (!dmn->arg_mgr) {\n\t\tmlx5dr_err(dmn, \"Couldn't create arg_mgr\\n\");\n\t\tgoto free_modify_header_pattern;\n\t}\n\n\treturn 0;\n\nfree_modify_header_pattern:\n\tmlx5dr_ptrn_mgr_destroy(dmn->ptrn_mgr);\n\treturn -ENOMEM;\n}\n\nstatic void dr_domain_destroy_modify_header_resources(struct mlx5dr_domain *dmn)\n{\n\tif (!mlx5dr_domain_is_support_ptrn_arg(dmn))\n\t\treturn;\n\n\tmlx5dr_arg_mgr_destroy(dmn->arg_mgr);\n\tmlx5dr_ptrn_mgr_destroy(dmn->ptrn_mgr);\n}\n\nstatic void dr_domain_init_csum_recalc_fts(struct mlx5dr_domain *dmn)\n{\n\t \n\txa_init(&dmn->csum_fts_xa);\n}\n\nstatic void dr_domain_uninit_csum_recalc_fts(struct mlx5dr_domain *dmn)\n{\n\tstruct mlx5dr_fw_recalc_cs_ft *recalc_cs_ft;\n\tunsigned long i;\n\n\txa_for_each(&dmn->csum_fts_xa, i, recalc_cs_ft) {\n\t\tif (recalc_cs_ft)\n\t\t\tmlx5dr_fw_destroy_recalc_cs_ft(dmn, recalc_cs_ft);\n\t}\n\n\txa_destroy(&dmn->csum_fts_xa);\n}\n\nint mlx5dr_domain_get_recalc_cs_ft_addr(struct mlx5dr_domain *dmn,\n\t\t\t\t\tu16 vport_num,\n\t\t\t\t\tu64 *rx_icm_addr)\n{\n\tstruct mlx5dr_fw_recalc_cs_ft *recalc_cs_ft;\n\tint ret;\n\n\trecalc_cs_ft = xa_load(&dmn->csum_fts_xa, vport_num);\n\tif (!recalc_cs_ft) {\n\t\t \n\t\trecalc_cs_ft = mlx5dr_fw_create_recalc_cs_ft(dmn, vport_num);\n\t\tif (!recalc_cs_ft)\n\t\t\treturn -EINVAL;\n\n\t\tret = xa_err(xa_store(&dmn->csum_fts_xa, vport_num,\n\t\t\t\t      recalc_cs_ft, GFP_KERNEL));\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t*rx_icm_addr = recalc_cs_ft->rx_icm_addr;\n\n\treturn 0;\n}\n\nstatic int dr_domain_init_mem_resources(struct mlx5dr_domain *dmn)\n{\n\tint ret;\n\n\tdmn->chunks_kmem_cache = kmem_cache_create(\"mlx5_dr_chunks\",\n\t\t\t\t\t\t   sizeof(struct mlx5dr_icm_chunk), 0,\n\t\t\t\t\t\t   SLAB_HWCACHE_ALIGN, NULL);\n\tif (!dmn->chunks_kmem_cache) {\n\t\tmlx5dr_err(dmn, \"Couldn't create chunks kmem_cache\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tdmn->htbls_kmem_cache = kmem_cache_create(\"mlx5_dr_htbls\",\n\t\t\t\t\t\t  sizeof(struct mlx5dr_ste_htbl), 0,\n\t\t\t\t\t\t  SLAB_HWCACHE_ALIGN, NULL);\n\tif (!dmn->htbls_kmem_cache) {\n\t\tmlx5dr_err(dmn, \"Couldn't create hash tables kmem_cache\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_chunks_kmem_cache;\n\t}\n\n\tdmn->ste_icm_pool = mlx5dr_icm_pool_create(dmn, DR_ICM_TYPE_STE);\n\tif (!dmn->ste_icm_pool) {\n\t\tmlx5dr_err(dmn, \"Couldn't get icm memory\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_htbls_kmem_cache;\n\t}\n\n\tdmn->action_icm_pool = mlx5dr_icm_pool_create(dmn, DR_ICM_TYPE_MODIFY_ACTION);\n\tif (!dmn->action_icm_pool) {\n\t\tmlx5dr_err(dmn, \"Couldn't get action icm memory\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_ste_icm_pool;\n\t}\n\n\tret = mlx5dr_send_info_pool_create(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't create send info pool\\n\");\n\t\tgoto free_action_icm_pool;\n\t}\n\n\treturn 0;\n\nfree_action_icm_pool:\n\tmlx5dr_icm_pool_destroy(dmn->action_icm_pool);\nfree_ste_icm_pool:\n\tmlx5dr_icm_pool_destroy(dmn->ste_icm_pool);\nfree_htbls_kmem_cache:\n\tkmem_cache_destroy(dmn->htbls_kmem_cache);\nfree_chunks_kmem_cache:\n\tkmem_cache_destroy(dmn->chunks_kmem_cache);\n\n\treturn ret;\n}\n\nstatic void dr_domain_uninit_mem_resources(struct mlx5dr_domain *dmn)\n{\n\tmlx5dr_send_info_pool_destroy(dmn);\n\tmlx5dr_icm_pool_destroy(dmn->action_icm_pool);\n\tmlx5dr_icm_pool_destroy(dmn->ste_icm_pool);\n\tkmem_cache_destroy(dmn->htbls_kmem_cache);\n\tkmem_cache_destroy(dmn->chunks_kmem_cache);\n}\n\nstatic int dr_domain_init_resources(struct mlx5dr_domain *dmn)\n{\n\tint ret;\n\n\tdmn->ste_ctx = mlx5dr_ste_get_ctx(dmn->info.caps.sw_format_ver);\n\tif (!dmn->ste_ctx) {\n\t\tmlx5dr_err(dmn, \"SW Steering on this device is unsupported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tret = mlx5_core_alloc_pd(dmn->mdev, &dmn->pdn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't allocate PD, ret: %d\", ret);\n\t\treturn ret;\n\t}\n\n\tdmn->uar = mlx5_get_uars_page(dmn->mdev);\n\tif (IS_ERR(dmn->uar)) {\n\t\tmlx5dr_err(dmn, \"Couldn't allocate UAR\\n\");\n\t\tret = PTR_ERR(dmn->uar);\n\t\tgoto clean_pd;\n\t}\n\n\tret = dr_domain_init_mem_resources(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't create domain memory resources\\n\");\n\t\tgoto clean_uar;\n\t}\n\n\tret = dr_domain_init_modify_header_resources(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't create modify-header-resources\\n\");\n\t\tgoto clean_mem_resources;\n\t}\n\n\tret = mlx5dr_send_ring_alloc(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't create send-ring\\n\");\n\t\tgoto clean_modify_hdr;\n\t}\n\n\treturn 0;\n\nclean_modify_hdr:\n\tdr_domain_destroy_modify_header_resources(dmn);\nclean_mem_resources:\n\tdr_domain_uninit_mem_resources(dmn);\nclean_uar:\n\tmlx5_put_uars_page(dmn->mdev, dmn->uar);\nclean_pd:\n\tmlx5_core_dealloc_pd(dmn->mdev, dmn->pdn);\n\n\treturn ret;\n}\n\nstatic void dr_domain_uninit_resources(struct mlx5dr_domain *dmn)\n{\n\tmlx5dr_send_ring_free(dmn, dmn->send_ring);\n\tdr_domain_destroy_modify_header_resources(dmn);\n\tdr_domain_uninit_mem_resources(dmn);\n\tmlx5_put_uars_page(dmn->mdev, dmn->uar);\n\tmlx5_core_dealloc_pd(dmn->mdev, dmn->pdn);\n}\n\nstatic void dr_domain_fill_uplink_caps(struct mlx5dr_domain *dmn,\n\t\t\t\t       struct mlx5dr_cmd_vport_cap *uplink_vport)\n{\n\tstruct mlx5dr_esw_caps *esw_caps = &dmn->info.caps.esw_caps;\n\n\tuplink_vport->num = MLX5_VPORT_UPLINK;\n\tuplink_vport->icm_address_rx = esw_caps->uplink_icm_address_rx;\n\tuplink_vport->icm_address_tx = esw_caps->uplink_icm_address_tx;\n\tuplink_vport->vport_gvmi = 0;\n\tuplink_vport->vhca_gvmi = dmn->info.caps.gvmi;\n}\n\nstatic int dr_domain_query_vport(struct mlx5dr_domain *dmn,\n\t\t\t\t u16 vport_number,\n\t\t\t\t bool other_vport,\n\t\t\t\t struct mlx5dr_cmd_vport_cap *vport_caps)\n{\n\tint ret;\n\n\tret = mlx5dr_cmd_query_esw_vport_context(dmn->mdev,\n\t\t\t\t\t\t other_vport,\n\t\t\t\t\t\t vport_number,\n\t\t\t\t\t\t &vport_caps->icm_address_rx,\n\t\t\t\t\t\t &vport_caps->icm_address_tx);\n\tif (ret)\n\t\treturn ret;\n\n\tret = mlx5dr_cmd_query_gvmi(dmn->mdev,\n\t\t\t\t    other_vport,\n\t\t\t\t    vport_number,\n\t\t\t\t    &vport_caps->vport_gvmi);\n\tif (ret)\n\t\treturn ret;\n\n\tvport_caps->num = vport_number;\n\tvport_caps->vhca_gvmi = dmn->info.caps.gvmi;\n\n\treturn 0;\n}\n\nstatic int dr_domain_query_esw_mgr(struct mlx5dr_domain *dmn)\n{\n\treturn dr_domain_query_vport(dmn, 0, false,\n\t\t\t\t     &dmn->info.caps.vports.esw_manager_caps);\n}\n\nstatic void dr_domain_query_uplink(struct mlx5dr_domain *dmn)\n{\n\tdr_domain_fill_uplink_caps(dmn, &dmn->info.caps.vports.uplink_caps);\n}\n\nstatic struct mlx5dr_cmd_vport_cap *\ndr_domain_add_vport_cap(struct mlx5dr_domain *dmn, u16 vport)\n{\n\tstruct mlx5dr_cmd_caps *caps = &dmn->info.caps;\n\tstruct mlx5dr_cmd_vport_cap *vport_caps;\n\tint ret;\n\n\tvport_caps = kvzalloc(sizeof(*vport_caps), GFP_KERNEL);\n\tif (!vport_caps)\n\t\treturn NULL;\n\n\tret = dr_domain_query_vport(dmn, vport, true, vport_caps);\n\tif (ret) {\n\t\tkvfree(vport_caps);\n\t\treturn NULL;\n\t}\n\n\tret = xa_insert(&caps->vports.vports_caps_xa, vport,\n\t\t\tvport_caps, GFP_KERNEL);\n\tif (ret) {\n\t\tmlx5dr_dbg(dmn, \"Couldn't insert new vport into xarray (%d)\\n\", ret);\n\t\tkvfree(vport_caps);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn vport_caps;\n}\n\nstatic bool dr_domain_is_esw_mgr_vport(struct mlx5dr_domain *dmn, u16 vport)\n{\n\tstruct mlx5dr_cmd_caps *caps = &dmn->info.caps;\n\n\treturn (caps->is_ecpf && vport == MLX5_VPORT_ECPF) ||\n\t       (!caps->is_ecpf && vport == 0);\n}\n\nstruct mlx5dr_cmd_vport_cap *\nmlx5dr_domain_get_vport_cap(struct mlx5dr_domain *dmn, u16 vport)\n{\n\tstruct mlx5dr_cmd_caps *caps = &dmn->info.caps;\n\tstruct mlx5dr_cmd_vport_cap *vport_caps;\n\n\tif (dr_domain_is_esw_mgr_vport(dmn, vport))\n\t\treturn &caps->vports.esw_manager_caps;\n\n\tif (vport == MLX5_VPORT_UPLINK)\n\t\treturn &caps->vports.uplink_caps;\n\nvport_load:\n\tvport_caps = xa_load(&caps->vports.vports_caps_xa, vport);\n\tif (vport_caps)\n\t\treturn vport_caps;\n\n\tvport_caps = dr_domain_add_vport_cap(dmn, vport);\n\tif (PTR_ERR(vport_caps) == -EBUSY)\n\t\t \n\t\tgoto vport_load;\n\n\treturn vport_caps;\n}\n\nstatic void dr_domain_clear_vports(struct mlx5dr_domain *dmn)\n{\n\tstruct mlx5dr_cmd_vport_cap *vport_caps;\n\tunsigned long i;\n\n\txa_for_each(&dmn->info.caps.vports.vports_caps_xa, i, vport_caps) {\n\t\tvport_caps = xa_erase(&dmn->info.caps.vports.vports_caps_xa, i);\n\t\tkvfree(vport_caps);\n\t}\n}\n\nstatic int dr_domain_query_fdb_caps(struct mlx5_core_dev *mdev,\n\t\t\t\t    struct mlx5dr_domain *dmn)\n{\n\tint ret;\n\n\tif (!dmn->info.caps.eswitch_manager)\n\t\treturn -EOPNOTSUPP;\n\n\tret = mlx5dr_cmd_query_esw_caps(mdev, &dmn->info.caps.esw_caps);\n\tif (ret)\n\t\treturn ret;\n\n\tdmn->info.caps.fdb_sw_owner = dmn->info.caps.esw_caps.sw_owner;\n\tdmn->info.caps.fdb_sw_owner_v2 = dmn->info.caps.esw_caps.sw_owner_v2;\n\tdmn->info.caps.esw_rx_drop_address = dmn->info.caps.esw_caps.drop_icm_address_rx;\n\tdmn->info.caps.esw_tx_drop_address = dmn->info.caps.esw_caps.drop_icm_address_tx;\n\n\txa_init(&dmn->info.caps.vports.vports_caps_xa);\n\n\t \n\n\tret = dr_domain_query_esw_mgr(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Failed to query eswitch manager vport caps (err: %d)\", ret);\n\t\tgoto free_vports_caps_xa;\n\t}\n\n\tdr_domain_query_uplink(dmn);\n\n\treturn 0;\n\nfree_vports_caps_xa:\n\txa_destroy(&dmn->info.caps.vports.vports_caps_xa);\n\n\treturn ret;\n}\n\nstatic int dr_domain_caps_init(struct mlx5_core_dev *mdev,\n\t\t\t       struct mlx5dr_domain *dmn)\n{\n\tstruct mlx5dr_cmd_vport_cap *vport_cap;\n\tint ret;\n\n\tif (MLX5_CAP_GEN(mdev, port_type) != MLX5_CAP_PORT_TYPE_ETH) {\n\t\tmlx5dr_err(dmn, \"Failed to allocate domain, bad link type\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tret = mlx5dr_cmd_query_device(mdev, &dmn->info.caps);\n\tif (ret)\n\t\treturn ret;\n\n\tret = dr_domain_query_fdb_caps(mdev, dmn);\n\tif (ret)\n\t\treturn ret;\n\n\tswitch (dmn->type) {\n\tcase MLX5DR_DOMAIN_TYPE_NIC_RX:\n\t\tif (!DR_DOMAIN_SW_STEERING_SUPPORTED(dmn, rx))\n\t\t\treturn -ENOTSUPP;\n\n\t\tdmn->info.supp_sw_steering = true;\n\t\tdmn->info.rx.type = DR_DOMAIN_NIC_TYPE_RX;\n\t\tdmn->info.rx.default_icm_addr = dmn->info.caps.nic_rx_drop_address;\n\t\tdmn->info.rx.drop_icm_addr = dmn->info.caps.nic_rx_drop_address;\n\t\tbreak;\n\tcase MLX5DR_DOMAIN_TYPE_NIC_TX:\n\t\tif (!DR_DOMAIN_SW_STEERING_SUPPORTED(dmn, tx))\n\t\t\treturn -ENOTSUPP;\n\n\t\tdmn->info.supp_sw_steering = true;\n\t\tdmn->info.tx.type = DR_DOMAIN_NIC_TYPE_TX;\n\t\tdmn->info.tx.default_icm_addr = dmn->info.caps.nic_tx_allow_address;\n\t\tdmn->info.tx.drop_icm_addr = dmn->info.caps.nic_tx_drop_address;\n\t\tbreak;\n\tcase MLX5DR_DOMAIN_TYPE_FDB:\n\t\tif (!dmn->info.caps.eswitch_manager)\n\t\t\treturn -ENOTSUPP;\n\n\t\tif (!DR_DOMAIN_SW_STEERING_SUPPORTED(dmn, fdb))\n\t\t\treturn -ENOTSUPP;\n\n\t\tdmn->info.rx.type = DR_DOMAIN_NIC_TYPE_RX;\n\t\tdmn->info.tx.type = DR_DOMAIN_NIC_TYPE_TX;\n\t\tvport_cap = &dmn->info.caps.vports.esw_manager_caps;\n\n\t\tdmn->info.supp_sw_steering = true;\n\t\tdmn->info.tx.default_icm_addr = vport_cap->icm_address_tx;\n\t\tdmn->info.rx.default_icm_addr = vport_cap->icm_address_rx;\n\t\tdmn->info.rx.drop_icm_addr = dmn->info.caps.esw_rx_drop_address;\n\t\tdmn->info.tx.drop_icm_addr = dmn->info.caps.esw_tx_drop_address;\n\t\tbreak;\n\tdefault:\n\t\tmlx5dr_err(dmn, \"Invalid domain\\n\");\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic void dr_domain_caps_uninit(struct mlx5dr_domain *dmn)\n{\n\tdr_domain_clear_vports(dmn);\n\txa_destroy(&dmn->info.caps.vports.vports_caps_xa);\n}\n\nstruct mlx5dr_domain *\nmlx5dr_domain_create(struct mlx5_core_dev *mdev, enum mlx5dr_domain_type type)\n{\n\tstruct mlx5dr_domain *dmn;\n\tint ret;\n\n\tif (type > MLX5DR_DOMAIN_TYPE_FDB)\n\t\treturn NULL;\n\n\tdmn = kzalloc(sizeof(*dmn), GFP_KERNEL);\n\tif (!dmn)\n\t\treturn NULL;\n\n\tdmn->mdev = mdev;\n\tdmn->type = type;\n\trefcount_set(&dmn->refcount, 1);\n\tmutex_init(&dmn->info.rx.mutex);\n\tmutex_init(&dmn->info.tx.mutex);\n\txa_init(&dmn->definers_xa);\n\txa_init(&dmn->peer_dmn_xa);\n\n\tif (dr_domain_caps_init(mdev, dmn)) {\n\t\tmlx5dr_err(dmn, \"Failed init domain, no caps\\n\");\n\t\tgoto def_xa_destroy;\n\t}\n\n\tdmn->info.max_log_action_icm_sz = DR_CHUNK_SIZE_4K;\n\tdmn->info.max_log_sw_icm_sz = min_t(u32, DR_CHUNK_SIZE_1024K,\n\t\t\t\t\t    dmn->info.caps.log_icm_size);\n\tdmn->info.max_log_modify_hdr_pattern_icm_sz =\n\t\tmin_t(u32, DR_CHUNK_SIZE_4K,\n\t\t      dmn->info.caps.log_modify_pattern_icm_size);\n\n\tif (!dmn->info.supp_sw_steering) {\n\t\tmlx5dr_err(dmn, \"SW steering is not supported\\n\");\n\t\tgoto uninit_caps;\n\t}\n\n\t \n\tret = dr_domain_init_resources(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Failed init domain resources\\n\");\n\t\tgoto uninit_caps;\n\t}\n\n\tdr_domain_init_csum_recalc_fts(dmn);\n\tmlx5dr_dbg_init_dump(dmn);\n\treturn dmn;\n\nuninit_caps:\n\tdr_domain_caps_uninit(dmn);\ndef_xa_destroy:\n\txa_destroy(&dmn->peer_dmn_xa);\n\txa_destroy(&dmn->definers_xa);\n\tkfree(dmn);\n\treturn NULL;\n}\n\n \nint mlx5dr_domain_sync(struct mlx5dr_domain *dmn, u32 flags)\n{\n\tint ret = 0;\n\n\tif (flags & MLX5DR_DOMAIN_SYNC_FLAGS_SW) {\n\t\tmlx5dr_domain_lock(dmn);\n\t\tret = mlx5dr_send_ring_force_drain(dmn);\n\t\tmlx5dr_domain_unlock(dmn);\n\t\tif (ret) {\n\t\t\tmlx5dr_err(dmn, \"Force drain failed flags: %d, ret: %d\\n\",\n\t\t\t\t   flags, ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (flags & MLX5DR_DOMAIN_SYNC_FLAGS_HW)\n\t\tret = mlx5dr_cmd_sync_steering(dmn->mdev);\n\n\treturn ret;\n}\n\nint mlx5dr_domain_destroy(struct mlx5dr_domain *dmn)\n{\n\tif (WARN_ON_ONCE(refcount_read(&dmn->refcount) > 1))\n\t\treturn -EBUSY;\n\n\t \n\tmlx5dr_cmd_sync_steering(dmn->mdev);\n\tmlx5dr_dbg_uninit_dump(dmn);\n\tdr_domain_uninit_csum_recalc_fts(dmn);\n\tdr_domain_uninit_resources(dmn);\n\tdr_domain_caps_uninit(dmn);\n\txa_destroy(&dmn->peer_dmn_xa);\n\txa_destroy(&dmn->definers_xa);\n\tmutex_destroy(&dmn->info.tx.mutex);\n\tmutex_destroy(&dmn->info.rx.mutex);\n\tkfree(dmn);\n\treturn 0;\n}\n\nvoid mlx5dr_domain_set_peer(struct mlx5dr_domain *dmn,\n\t\t\t    struct mlx5dr_domain *peer_dmn,\n\t\t\t    u16 peer_vhca_id)\n{\n\tstruct mlx5dr_domain *peer;\n\n\tmlx5dr_domain_lock(dmn);\n\n\tpeer = xa_load(&dmn->peer_dmn_xa, peer_vhca_id);\n\tif (peer)\n\t\trefcount_dec(&peer->refcount);\n\n\tWARN_ON(xa_err(xa_store(&dmn->peer_dmn_xa, peer_vhca_id, peer_dmn, GFP_KERNEL)));\n\n\tpeer = xa_load(&dmn->peer_dmn_xa, peer_vhca_id);\n\tif (peer)\n\t\trefcount_inc(&peer->refcount);\n\n\tmlx5dr_domain_unlock(dmn);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}