{
  "module_name": "cmd.c",
  "hash_id": "a42bcf94f455b963ba733711e3e4742ec53c5e4fe252d2a209913fc3b52030e1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/cmd.c",
  "human_readable_source": " \n\n#include <linux/highmem.h>\n#include <linux/errno.h>\n#include <linux/pci.h>\n#include <linux/dma-mapping.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/random.h>\n#include <linux/mlx5/driver.h>\n#include <linux/mlx5/eq.h>\n#include <linux/debugfs.h>\n\n#include \"mlx5_core.h\"\n#include \"lib/eq.h\"\n#include \"lib/tout.h\"\n#define CREATE_TRACE_POINTS\n#include \"diag/cmd_tracepoint.h\"\n\nstruct mlx5_ifc_mbox_out_bits {\n\tu8         status[0x8];\n\tu8         reserved_at_8[0x18];\n\n\tu8         syndrome[0x20];\n\n\tu8         reserved_at_40[0x40];\n};\n\nstruct mlx5_ifc_mbox_in_bits {\n\tu8         opcode[0x10];\n\tu8         uid[0x10];\n\n\tu8         reserved_at_20[0x10];\n\tu8         op_mod[0x10];\n\n\tu8         reserved_at_40[0x40];\n};\n\nenum {\n\tCMD_IF_REV = 5,\n};\n\nenum {\n\tCMD_MODE_POLLING,\n\tCMD_MODE_EVENTS\n};\n\nenum {\n\tMLX5_CMD_DELIVERY_STAT_OK\t\t\t= 0x0,\n\tMLX5_CMD_DELIVERY_STAT_SIGNAT_ERR\t\t= 0x1,\n\tMLX5_CMD_DELIVERY_STAT_TOK_ERR\t\t\t= 0x2,\n\tMLX5_CMD_DELIVERY_STAT_BAD_BLK_NUM_ERR\t\t= 0x3,\n\tMLX5_CMD_DELIVERY_STAT_OUT_PTR_ALIGN_ERR\t= 0x4,\n\tMLX5_CMD_DELIVERY_STAT_IN_PTR_ALIGN_ERR\t\t= 0x5,\n\tMLX5_CMD_DELIVERY_STAT_FW_ERR\t\t\t= 0x6,\n\tMLX5_CMD_DELIVERY_STAT_IN_LENGTH_ERR\t\t= 0x7,\n\tMLX5_CMD_DELIVERY_STAT_OUT_LENGTH_ERR\t\t= 0x8,\n\tMLX5_CMD_DELIVERY_STAT_RES_FLD_NOT_CLR_ERR\t= 0x9,\n\tMLX5_CMD_DELIVERY_STAT_CMD_DESCR_ERR\t\t= 0x10,\n};\n\nstatic u16 in_to_opcode(void *in)\n{\n\treturn MLX5_GET(mbox_in, in, opcode);\n}\n\n \nstatic bool mlx5_cmd_is_throttle_opcode(u16 op)\n{\n\tswitch (op) {\n\tcase MLX5_CMD_OP_CREATE_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_DESTROY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_MODIFY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_QUERY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_SYNC_CRYPTO:\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic struct mlx5_cmd_work_ent *\ncmd_alloc_ent(struct mlx5_cmd *cmd, struct mlx5_cmd_msg *in,\n\t      struct mlx5_cmd_msg *out, void *uout, int uout_size,\n\t      mlx5_cmd_cbk_t cbk, void *context, int page_queue)\n{\n\tgfp_t alloc_flags = cbk ? GFP_ATOMIC : GFP_KERNEL;\n\tstruct mlx5_cmd_work_ent *ent;\n\n\tent = kzalloc(sizeof(*ent), alloc_flags);\n\tif (!ent)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tent->idx\t= -EINVAL;\n\tent->in\t\t= in;\n\tent->out\t= out;\n\tent->uout\t= uout;\n\tent->uout_size\t= uout_size;\n\tent->callback\t= cbk;\n\tent->context\t= context;\n\tent->cmd\t= cmd;\n\tent->page_queue = page_queue;\n\tent->op         = in_to_opcode(in->first.data);\n\trefcount_set(&ent->refcnt, 1);\n\n\treturn ent;\n}\n\nstatic void cmd_free_ent(struct mlx5_cmd_work_ent *ent)\n{\n\tkfree(ent);\n}\n\nstatic u8 alloc_token(struct mlx5_cmd *cmd)\n{\n\tu8 token;\n\n\tspin_lock(&cmd->token_lock);\n\tcmd->token++;\n\tif (cmd->token == 0)\n\t\tcmd->token++;\n\ttoken = cmd->token;\n\tspin_unlock(&cmd->token_lock);\n\n\treturn token;\n}\n\nstatic int cmd_alloc_index(struct mlx5_cmd *cmd, struct mlx5_cmd_work_ent *ent)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&cmd->alloc_lock, flags);\n\tret = find_first_bit(&cmd->vars.bitmask, cmd->vars.max_reg_cmds);\n\tif (ret < cmd->vars.max_reg_cmds) {\n\t\tclear_bit(ret, &cmd->vars.bitmask);\n\t\tent->idx = ret;\n\t\tcmd->ent_arr[ent->idx] = ent;\n\t}\n\tspin_unlock_irqrestore(&cmd->alloc_lock, flags);\n\n\treturn ret < cmd->vars.max_reg_cmds ? ret : -ENOMEM;\n}\n\nstatic void cmd_free_index(struct mlx5_cmd *cmd, int idx)\n{\n\tlockdep_assert_held(&cmd->alloc_lock);\n\tset_bit(idx, &cmd->vars.bitmask);\n}\n\nstatic void cmd_ent_get(struct mlx5_cmd_work_ent *ent)\n{\n\trefcount_inc(&ent->refcnt);\n}\n\nstatic void cmd_ent_put(struct mlx5_cmd_work_ent *ent)\n{\n\tstruct mlx5_cmd *cmd = ent->cmd;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cmd->alloc_lock, flags);\n\tif (!refcount_dec_and_test(&ent->refcnt))\n\t\tgoto out;\n\n\tif (ent->idx >= 0) {\n\t\tcmd_free_index(cmd, ent->idx);\n\t\tup(ent->page_queue ? &cmd->vars.pages_sem : &cmd->vars.sem);\n\t}\n\n\tcmd_free_ent(ent);\nout:\n\tspin_unlock_irqrestore(&cmd->alloc_lock, flags);\n}\n\nstatic struct mlx5_cmd_layout *get_inst(struct mlx5_cmd *cmd, int idx)\n{\n\treturn cmd->cmd_buf + (idx << cmd->vars.log_stride);\n}\n\nstatic int mlx5_calc_cmd_blocks(struct mlx5_cmd_msg *msg)\n{\n\tint size = msg->len;\n\tint blen = size - min_t(int, sizeof(msg->first.data), size);\n\n\treturn DIV_ROUND_UP(blen, MLX5_CMD_DATA_BLOCK_SIZE);\n}\n\nstatic u8 xor8_buf(void *buf, size_t offset, int len)\n{\n\tu8 *ptr = buf;\n\tu8 sum = 0;\n\tint i;\n\tint end = len + offset;\n\n\tfor (i = offset; i < end; i++)\n\t\tsum ^= ptr[i];\n\n\treturn sum;\n}\n\nstatic int verify_block_sig(struct mlx5_cmd_prot_block *block)\n{\n\tsize_t rsvd0_off = offsetof(struct mlx5_cmd_prot_block, rsvd0);\n\tint xor_len = sizeof(*block) - sizeof(block->data) - 1;\n\n\tif (xor8_buf(block, rsvd0_off, xor_len) != 0xff)\n\t\treturn -EHWPOISON;\n\n\tif (xor8_buf(block, 0, sizeof(*block)) != 0xff)\n\t\treturn -EHWPOISON;\n\n\treturn 0;\n}\n\nstatic void calc_block_sig(struct mlx5_cmd_prot_block *block)\n{\n\tint ctrl_xor_len = sizeof(*block) - sizeof(block->data) - 2;\n\tsize_t rsvd0_off = offsetof(struct mlx5_cmd_prot_block, rsvd0);\n\n\tblock->ctrl_sig = ~xor8_buf(block, rsvd0_off, ctrl_xor_len);\n\tblock->sig = ~xor8_buf(block, 0, sizeof(*block) - 1);\n}\n\nstatic void calc_chain_sig(struct mlx5_cmd_msg *msg)\n{\n\tstruct mlx5_cmd_mailbox *next = msg->next;\n\tint n = mlx5_calc_cmd_blocks(msg);\n\tint i = 0;\n\n\tfor (i = 0; i < n && next; i++)  {\n\t\tcalc_block_sig(next->buf);\n\t\tnext = next->next;\n\t}\n}\n\nstatic void set_signature(struct mlx5_cmd_work_ent *ent, int csum)\n{\n\tent->lay->sig = ~xor8_buf(ent->lay, 0,  sizeof(*ent->lay));\n\tif (csum) {\n\t\tcalc_chain_sig(ent->in);\n\t\tcalc_chain_sig(ent->out);\n\t}\n}\n\nstatic void poll_timeout(struct mlx5_cmd_work_ent *ent)\n{\n\tstruct mlx5_core_dev *dev = container_of(ent->cmd, struct mlx5_core_dev, cmd);\n\tu64 cmd_to_ms = mlx5_tout_ms(dev, CMD);\n\tunsigned long poll_end;\n\tu8 own;\n\n\tpoll_end = jiffies + msecs_to_jiffies(cmd_to_ms + 1000);\n\n\tdo {\n\t\town = READ_ONCE(ent->lay->status_own);\n\t\tif (!(own & CMD_OWNER_HW)) {\n\t\t\tent->ret = 0;\n\t\t\treturn;\n\t\t}\n\t\tcond_resched();\n\t} while (time_before(jiffies, poll_end));\n\n\tent->ret = -ETIMEDOUT;\n}\n\nstatic int verify_signature(struct mlx5_cmd_work_ent *ent)\n{\n\tstruct mlx5_cmd_mailbox *next = ent->out->next;\n\tint n = mlx5_calc_cmd_blocks(ent->out);\n\tint err;\n\tu8 sig;\n\tint i = 0;\n\n\tsig = xor8_buf(ent->lay, 0, sizeof(*ent->lay));\n\tif (sig != 0xff)\n\t\treturn -EHWPOISON;\n\n\tfor (i = 0; i < n && next; i++) {\n\t\terr = verify_block_sig(next->buf);\n\t\tif (err)\n\t\t\treturn -EHWPOISON;\n\n\t\tnext = next->next;\n\t}\n\n\treturn 0;\n}\n\nstatic void dump_buf(void *buf, int size, int data_only, int offset, int idx)\n{\n\t__be32 *p = buf;\n\tint i;\n\n\tfor (i = 0; i < size; i += 16) {\n\t\tpr_debug(\"cmd[%d]: %03x: %08x %08x %08x %08x\\n\", idx, offset,\n\t\t\t be32_to_cpu(p[0]), be32_to_cpu(p[1]),\n\t\t\t be32_to_cpu(p[2]), be32_to_cpu(p[3]));\n\t\tp += 4;\n\t\toffset += 16;\n\t}\n\tif (!data_only)\n\t\tpr_debug(\"\\n\");\n}\n\nstatic int mlx5_internal_err_ret_value(struct mlx5_core_dev *dev, u16 op,\n\t\t\t\t       u32 *synd, u8 *status)\n{\n\t*synd = 0;\n\t*status = 0;\n\n\tswitch (op) {\n\tcase MLX5_CMD_OP_TEARDOWN_HCA:\n\tcase MLX5_CMD_OP_DISABLE_HCA:\n\tcase MLX5_CMD_OP_MANAGE_PAGES:\n\tcase MLX5_CMD_OP_DESTROY_MKEY:\n\tcase MLX5_CMD_OP_DESTROY_EQ:\n\tcase MLX5_CMD_OP_DESTROY_CQ:\n\tcase MLX5_CMD_OP_DESTROY_QP:\n\tcase MLX5_CMD_OP_DESTROY_PSV:\n\tcase MLX5_CMD_OP_DESTROY_SRQ:\n\tcase MLX5_CMD_OP_DESTROY_XRC_SRQ:\n\tcase MLX5_CMD_OP_DESTROY_XRQ:\n\tcase MLX5_CMD_OP_DESTROY_DCT:\n\tcase MLX5_CMD_OP_DEALLOC_Q_COUNTER:\n\tcase MLX5_CMD_OP_DESTROY_SCHEDULING_ELEMENT:\n\tcase MLX5_CMD_OP_DESTROY_QOS_PARA_VPORT:\n\tcase MLX5_CMD_OP_DEALLOC_PD:\n\tcase MLX5_CMD_OP_DEALLOC_UAR:\n\tcase MLX5_CMD_OP_DETACH_FROM_MCG:\n\tcase MLX5_CMD_OP_DEALLOC_XRCD:\n\tcase MLX5_CMD_OP_DEALLOC_TRANSPORT_DOMAIN:\n\tcase MLX5_CMD_OP_DELETE_VXLAN_UDP_DPORT:\n\tcase MLX5_CMD_OP_DELETE_L2_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_DESTROY_LAG:\n\tcase MLX5_CMD_OP_DESTROY_VPORT_LAG:\n\tcase MLX5_CMD_OP_DESTROY_TIR:\n\tcase MLX5_CMD_OP_DESTROY_SQ:\n\tcase MLX5_CMD_OP_DESTROY_RQ:\n\tcase MLX5_CMD_OP_DESTROY_RMP:\n\tcase MLX5_CMD_OP_DESTROY_TIS:\n\tcase MLX5_CMD_OP_DESTROY_RQT:\n\tcase MLX5_CMD_OP_DESTROY_FLOW_TABLE:\n\tcase MLX5_CMD_OP_DESTROY_FLOW_GROUP:\n\tcase MLX5_CMD_OP_DELETE_FLOW_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_DEALLOC_FLOW_COUNTER:\n\tcase MLX5_CMD_OP_2ERR_QP:\n\tcase MLX5_CMD_OP_2RST_QP:\n\tcase MLX5_CMD_OP_MODIFY_NIC_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_MODIFY_FLOW_TABLE:\n\tcase MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_SET_FLOW_TABLE_ROOT:\n\tcase MLX5_CMD_OP_DEALLOC_PACKET_REFORMAT_CONTEXT:\n\tcase MLX5_CMD_OP_DEALLOC_MODIFY_HEADER_CONTEXT:\n\tcase MLX5_CMD_OP_FPGA_DESTROY_QP:\n\tcase MLX5_CMD_OP_DESTROY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_DEALLOC_MEMIC:\n\tcase MLX5_CMD_OP_PAGE_FAULT_RESUME:\n\tcase MLX5_CMD_OP_QUERY_ESW_FUNCTIONS:\n\tcase MLX5_CMD_OP_DEALLOC_SF:\n\tcase MLX5_CMD_OP_DESTROY_UCTX:\n\tcase MLX5_CMD_OP_DESTROY_UMEM:\n\tcase MLX5_CMD_OP_MODIFY_RQT:\n\t\treturn MLX5_CMD_STAT_OK;\n\n\tcase MLX5_CMD_OP_QUERY_HCA_CAP:\n\tcase MLX5_CMD_OP_QUERY_ADAPTER:\n\tcase MLX5_CMD_OP_INIT_HCA:\n\tcase MLX5_CMD_OP_ENABLE_HCA:\n\tcase MLX5_CMD_OP_QUERY_PAGES:\n\tcase MLX5_CMD_OP_SET_HCA_CAP:\n\tcase MLX5_CMD_OP_QUERY_ISSI:\n\tcase MLX5_CMD_OP_SET_ISSI:\n\tcase MLX5_CMD_OP_CREATE_MKEY:\n\tcase MLX5_CMD_OP_QUERY_MKEY:\n\tcase MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS:\n\tcase MLX5_CMD_OP_CREATE_EQ:\n\tcase MLX5_CMD_OP_QUERY_EQ:\n\tcase MLX5_CMD_OP_GEN_EQE:\n\tcase MLX5_CMD_OP_CREATE_CQ:\n\tcase MLX5_CMD_OP_QUERY_CQ:\n\tcase MLX5_CMD_OP_MODIFY_CQ:\n\tcase MLX5_CMD_OP_CREATE_QP:\n\tcase MLX5_CMD_OP_RST2INIT_QP:\n\tcase MLX5_CMD_OP_INIT2RTR_QP:\n\tcase MLX5_CMD_OP_RTR2RTS_QP:\n\tcase MLX5_CMD_OP_RTS2RTS_QP:\n\tcase MLX5_CMD_OP_SQERR2RTS_QP:\n\tcase MLX5_CMD_OP_QUERY_QP:\n\tcase MLX5_CMD_OP_SQD_RTS_QP:\n\tcase MLX5_CMD_OP_INIT2INIT_QP:\n\tcase MLX5_CMD_OP_CREATE_PSV:\n\tcase MLX5_CMD_OP_CREATE_SRQ:\n\tcase MLX5_CMD_OP_QUERY_SRQ:\n\tcase MLX5_CMD_OP_ARM_RQ:\n\tcase MLX5_CMD_OP_CREATE_XRC_SRQ:\n\tcase MLX5_CMD_OP_QUERY_XRC_SRQ:\n\tcase MLX5_CMD_OP_ARM_XRC_SRQ:\n\tcase MLX5_CMD_OP_CREATE_XRQ:\n\tcase MLX5_CMD_OP_QUERY_XRQ:\n\tcase MLX5_CMD_OP_ARM_XRQ:\n\tcase MLX5_CMD_OP_CREATE_DCT:\n\tcase MLX5_CMD_OP_DRAIN_DCT:\n\tcase MLX5_CMD_OP_QUERY_DCT:\n\tcase MLX5_CMD_OP_ARM_DCT_FOR_KEY_VIOLATION:\n\tcase MLX5_CMD_OP_QUERY_VPORT_STATE:\n\tcase MLX5_CMD_OP_MODIFY_VPORT_STATE:\n\tcase MLX5_CMD_OP_QUERY_ESW_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_MODIFY_ESW_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_ROCE_ADDRESS:\n\tcase MLX5_CMD_OP_SET_ROCE_ADDRESS:\n\tcase MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_MODIFY_HCA_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_HCA_VPORT_GID:\n\tcase MLX5_CMD_OP_QUERY_HCA_VPORT_PKEY:\n\tcase MLX5_CMD_OP_QUERY_VNIC_ENV:\n\tcase MLX5_CMD_OP_QUERY_VPORT_COUNTER:\n\tcase MLX5_CMD_OP_ALLOC_Q_COUNTER:\n\tcase MLX5_CMD_OP_QUERY_Q_COUNTER:\n\tcase MLX5_CMD_OP_SET_MONITOR_COUNTER:\n\tcase MLX5_CMD_OP_ARM_MONITOR_COUNTER:\n\tcase MLX5_CMD_OP_SET_PP_RATE_LIMIT:\n\tcase MLX5_CMD_OP_QUERY_RATE_LIMIT:\n\tcase MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT:\n\tcase MLX5_CMD_OP_QUERY_SCHEDULING_ELEMENT:\n\tcase MLX5_CMD_OP_MODIFY_SCHEDULING_ELEMENT:\n\tcase MLX5_CMD_OP_CREATE_QOS_PARA_VPORT:\n\tcase MLX5_CMD_OP_ALLOC_PD:\n\tcase MLX5_CMD_OP_ALLOC_UAR:\n\tcase MLX5_CMD_OP_CONFIG_INT_MODERATION:\n\tcase MLX5_CMD_OP_ACCESS_REG:\n\tcase MLX5_CMD_OP_ATTACH_TO_MCG:\n\tcase MLX5_CMD_OP_GET_DROPPED_PACKET_LOG:\n\tcase MLX5_CMD_OP_MAD_IFC:\n\tcase MLX5_CMD_OP_QUERY_MAD_DEMUX:\n\tcase MLX5_CMD_OP_SET_MAD_DEMUX:\n\tcase MLX5_CMD_OP_NOP:\n\tcase MLX5_CMD_OP_ALLOC_XRCD:\n\tcase MLX5_CMD_OP_ALLOC_TRANSPORT_DOMAIN:\n\tcase MLX5_CMD_OP_QUERY_CONG_STATUS:\n\tcase MLX5_CMD_OP_MODIFY_CONG_STATUS:\n\tcase MLX5_CMD_OP_QUERY_CONG_PARAMS:\n\tcase MLX5_CMD_OP_MODIFY_CONG_PARAMS:\n\tcase MLX5_CMD_OP_QUERY_CONG_STATISTICS:\n\tcase MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT:\n\tcase MLX5_CMD_OP_SET_L2_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_QUERY_L2_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_CREATE_LAG:\n\tcase MLX5_CMD_OP_MODIFY_LAG:\n\tcase MLX5_CMD_OP_QUERY_LAG:\n\tcase MLX5_CMD_OP_CREATE_VPORT_LAG:\n\tcase MLX5_CMD_OP_CREATE_TIR:\n\tcase MLX5_CMD_OP_MODIFY_TIR:\n\tcase MLX5_CMD_OP_QUERY_TIR:\n\tcase MLX5_CMD_OP_CREATE_SQ:\n\tcase MLX5_CMD_OP_MODIFY_SQ:\n\tcase MLX5_CMD_OP_QUERY_SQ:\n\tcase MLX5_CMD_OP_CREATE_RQ:\n\tcase MLX5_CMD_OP_MODIFY_RQ:\n\tcase MLX5_CMD_OP_QUERY_RQ:\n\tcase MLX5_CMD_OP_CREATE_RMP:\n\tcase MLX5_CMD_OP_MODIFY_RMP:\n\tcase MLX5_CMD_OP_QUERY_RMP:\n\tcase MLX5_CMD_OP_CREATE_TIS:\n\tcase MLX5_CMD_OP_MODIFY_TIS:\n\tcase MLX5_CMD_OP_QUERY_TIS:\n\tcase MLX5_CMD_OP_CREATE_RQT:\n\tcase MLX5_CMD_OP_QUERY_RQT:\n\n\tcase MLX5_CMD_OP_CREATE_FLOW_TABLE:\n\tcase MLX5_CMD_OP_QUERY_FLOW_TABLE:\n\tcase MLX5_CMD_OP_CREATE_FLOW_GROUP:\n\tcase MLX5_CMD_OP_QUERY_FLOW_GROUP:\n\tcase MLX5_CMD_OP_QUERY_FLOW_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_ALLOC_FLOW_COUNTER:\n\tcase MLX5_CMD_OP_QUERY_FLOW_COUNTER:\n\tcase MLX5_CMD_OP_ALLOC_PACKET_REFORMAT_CONTEXT:\n\tcase MLX5_CMD_OP_ALLOC_MODIFY_HEADER_CONTEXT:\n\tcase MLX5_CMD_OP_FPGA_CREATE_QP:\n\tcase MLX5_CMD_OP_FPGA_MODIFY_QP:\n\tcase MLX5_CMD_OP_FPGA_QUERY_QP:\n\tcase MLX5_CMD_OP_FPGA_QUERY_QP_COUNTERS:\n\tcase MLX5_CMD_OP_CREATE_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_MODIFY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_QUERY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_CREATE_UCTX:\n\tcase MLX5_CMD_OP_CREATE_UMEM:\n\tcase MLX5_CMD_OP_ALLOC_MEMIC:\n\tcase MLX5_CMD_OP_MODIFY_XRQ:\n\tcase MLX5_CMD_OP_RELEASE_XRQ_ERROR:\n\tcase MLX5_CMD_OP_QUERY_VHCA_STATE:\n\tcase MLX5_CMD_OP_MODIFY_VHCA_STATE:\n\tcase MLX5_CMD_OP_ALLOC_SF:\n\tcase MLX5_CMD_OP_SUSPEND_VHCA:\n\tcase MLX5_CMD_OP_RESUME_VHCA:\n\tcase MLX5_CMD_OP_QUERY_VHCA_MIGRATION_STATE:\n\tcase MLX5_CMD_OP_SAVE_VHCA_STATE:\n\tcase MLX5_CMD_OP_LOAD_VHCA_STATE:\n\tcase MLX5_CMD_OP_SYNC_CRYPTO:\n\t\t*status = MLX5_DRIVER_STATUS_ABORTED;\n\t\t*synd = MLX5_DRIVER_SYND;\n\t\treturn -ENOLINK;\n\tdefault:\n\t\tmlx5_core_err(dev, \"Unknown FW command (%d)\\n\", op);\n\t\treturn -EINVAL;\n\t}\n}\n\nconst char *mlx5_command_str(int command)\n{\n#define MLX5_COMMAND_STR_CASE(__cmd) case MLX5_CMD_OP_ ## __cmd: return #__cmd\n\n\tswitch (command) {\n\tMLX5_COMMAND_STR_CASE(QUERY_HCA_CAP);\n\tMLX5_COMMAND_STR_CASE(QUERY_ADAPTER);\n\tMLX5_COMMAND_STR_CASE(INIT_HCA);\n\tMLX5_COMMAND_STR_CASE(TEARDOWN_HCA);\n\tMLX5_COMMAND_STR_CASE(ENABLE_HCA);\n\tMLX5_COMMAND_STR_CASE(DISABLE_HCA);\n\tMLX5_COMMAND_STR_CASE(QUERY_PAGES);\n\tMLX5_COMMAND_STR_CASE(MANAGE_PAGES);\n\tMLX5_COMMAND_STR_CASE(SET_HCA_CAP);\n\tMLX5_COMMAND_STR_CASE(QUERY_ISSI);\n\tMLX5_COMMAND_STR_CASE(SET_ISSI);\n\tMLX5_COMMAND_STR_CASE(SET_DRIVER_VERSION);\n\tMLX5_COMMAND_STR_CASE(CREATE_MKEY);\n\tMLX5_COMMAND_STR_CASE(QUERY_MKEY);\n\tMLX5_COMMAND_STR_CASE(DESTROY_MKEY);\n\tMLX5_COMMAND_STR_CASE(QUERY_SPECIAL_CONTEXTS);\n\tMLX5_COMMAND_STR_CASE(PAGE_FAULT_RESUME);\n\tMLX5_COMMAND_STR_CASE(CREATE_EQ);\n\tMLX5_COMMAND_STR_CASE(DESTROY_EQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_EQ);\n\tMLX5_COMMAND_STR_CASE(GEN_EQE);\n\tMLX5_COMMAND_STR_CASE(CREATE_CQ);\n\tMLX5_COMMAND_STR_CASE(DESTROY_CQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_CQ);\n\tMLX5_COMMAND_STR_CASE(MODIFY_CQ);\n\tMLX5_COMMAND_STR_CASE(CREATE_QP);\n\tMLX5_COMMAND_STR_CASE(DESTROY_QP);\n\tMLX5_COMMAND_STR_CASE(RST2INIT_QP);\n\tMLX5_COMMAND_STR_CASE(INIT2RTR_QP);\n\tMLX5_COMMAND_STR_CASE(RTR2RTS_QP);\n\tMLX5_COMMAND_STR_CASE(RTS2RTS_QP);\n\tMLX5_COMMAND_STR_CASE(SQERR2RTS_QP);\n\tMLX5_COMMAND_STR_CASE(2ERR_QP);\n\tMLX5_COMMAND_STR_CASE(2RST_QP);\n\tMLX5_COMMAND_STR_CASE(QUERY_QP);\n\tMLX5_COMMAND_STR_CASE(SQD_RTS_QP);\n\tMLX5_COMMAND_STR_CASE(INIT2INIT_QP);\n\tMLX5_COMMAND_STR_CASE(CREATE_PSV);\n\tMLX5_COMMAND_STR_CASE(DESTROY_PSV);\n\tMLX5_COMMAND_STR_CASE(CREATE_SRQ);\n\tMLX5_COMMAND_STR_CASE(DESTROY_SRQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_SRQ);\n\tMLX5_COMMAND_STR_CASE(ARM_RQ);\n\tMLX5_COMMAND_STR_CASE(CREATE_XRC_SRQ);\n\tMLX5_COMMAND_STR_CASE(DESTROY_XRC_SRQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_XRC_SRQ);\n\tMLX5_COMMAND_STR_CASE(ARM_XRC_SRQ);\n\tMLX5_COMMAND_STR_CASE(CREATE_DCT);\n\tMLX5_COMMAND_STR_CASE(DESTROY_DCT);\n\tMLX5_COMMAND_STR_CASE(DRAIN_DCT);\n\tMLX5_COMMAND_STR_CASE(QUERY_DCT);\n\tMLX5_COMMAND_STR_CASE(ARM_DCT_FOR_KEY_VIOLATION);\n\tMLX5_COMMAND_STR_CASE(QUERY_VPORT_STATE);\n\tMLX5_COMMAND_STR_CASE(MODIFY_VPORT_STATE);\n\tMLX5_COMMAND_STR_CASE(QUERY_ESW_VPORT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(MODIFY_ESW_VPORT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(QUERY_NIC_VPORT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(MODIFY_NIC_VPORT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(QUERY_ROCE_ADDRESS);\n\tMLX5_COMMAND_STR_CASE(SET_ROCE_ADDRESS);\n\tMLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(MODIFY_HCA_VPORT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_GID);\n\tMLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_PKEY);\n\tMLX5_COMMAND_STR_CASE(QUERY_VNIC_ENV);\n\tMLX5_COMMAND_STR_CASE(QUERY_VPORT_COUNTER);\n\tMLX5_COMMAND_STR_CASE(ALLOC_Q_COUNTER);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_Q_COUNTER);\n\tMLX5_COMMAND_STR_CASE(QUERY_Q_COUNTER);\n\tMLX5_COMMAND_STR_CASE(SET_MONITOR_COUNTER);\n\tMLX5_COMMAND_STR_CASE(ARM_MONITOR_COUNTER);\n\tMLX5_COMMAND_STR_CASE(SET_PP_RATE_LIMIT);\n\tMLX5_COMMAND_STR_CASE(QUERY_RATE_LIMIT);\n\tMLX5_COMMAND_STR_CASE(CREATE_SCHEDULING_ELEMENT);\n\tMLX5_COMMAND_STR_CASE(DESTROY_SCHEDULING_ELEMENT);\n\tMLX5_COMMAND_STR_CASE(QUERY_SCHEDULING_ELEMENT);\n\tMLX5_COMMAND_STR_CASE(MODIFY_SCHEDULING_ELEMENT);\n\tMLX5_COMMAND_STR_CASE(CREATE_QOS_PARA_VPORT);\n\tMLX5_COMMAND_STR_CASE(DESTROY_QOS_PARA_VPORT);\n\tMLX5_COMMAND_STR_CASE(ALLOC_PD);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_PD);\n\tMLX5_COMMAND_STR_CASE(ALLOC_UAR);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_UAR);\n\tMLX5_COMMAND_STR_CASE(CONFIG_INT_MODERATION);\n\tMLX5_COMMAND_STR_CASE(ACCESS_REG);\n\tMLX5_COMMAND_STR_CASE(ATTACH_TO_MCG);\n\tMLX5_COMMAND_STR_CASE(DETACH_FROM_MCG);\n\tMLX5_COMMAND_STR_CASE(GET_DROPPED_PACKET_LOG);\n\tMLX5_COMMAND_STR_CASE(MAD_IFC);\n\tMLX5_COMMAND_STR_CASE(QUERY_MAD_DEMUX);\n\tMLX5_COMMAND_STR_CASE(SET_MAD_DEMUX);\n\tMLX5_COMMAND_STR_CASE(NOP);\n\tMLX5_COMMAND_STR_CASE(ALLOC_XRCD);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_XRCD);\n\tMLX5_COMMAND_STR_CASE(ALLOC_TRANSPORT_DOMAIN);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_TRANSPORT_DOMAIN);\n\tMLX5_COMMAND_STR_CASE(QUERY_CONG_STATUS);\n\tMLX5_COMMAND_STR_CASE(MODIFY_CONG_STATUS);\n\tMLX5_COMMAND_STR_CASE(QUERY_CONG_PARAMS);\n\tMLX5_COMMAND_STR_CASE(MODIFY_CONG_PARAMS);\n\tMLX5_COMMAND_STR_CASE(QUERY_CONG_STATISTICS);\n\tMLX5_COMMAND_STR_CASE(ADD_VXLAN_UDP_DPORT);\n\tMLX5_COMMAND_STR_CASE(DELETE_VXLAN_UDP_DPORT);\n\tMLX5_COMMAND_STR_CASE(SET_L2_TABLE_ENTRY);\n\tMLX5_COMMAND_STR_CASE(QUERY_L2_TABLE_ENTRY);\n\tMLX5_COMMAND_STR_CASE(DELETE_L2_TABLE_ENTRY);\n\tMLX5_COMMAND_STR_CASE(SET_WOL_ROL);\n\tMLX5_COMMAND_STR_CASE(QUERY_WOL_ROL);\n\tMLX5_COMMAND_STR_CASE(CREATE_LAG);\n\tMLX5_COMMAND_STR_CASE(MODIFY_LAG);\n\tMLX5_COMMAND_STR_CASE(QUERY_LAG);\n\tMLX5_COMMAND_STR_CASE(DESTROY_LAG);\n\tMLX5_COMMAND_STR_CASE(CREATE_VPORT_LAG);\n\tMLX5_COMMAND_STR_CASE(DESTROY_VPORT_LAG);\n\tMLX5_COMMAND_STR_CASE(CREATE_TIR);\n\tMLX5_COMMAND_STR_CASE(MODIFY_TIR);\n\tMLX5_COMMAND_STR_CASE(DESTROY_TIR);\n\tMLX5_COMMAND_STR_CASE(QUERY_TIR);\n\tMLX5_COMMAND_STR_CASE(CREATE_SQ);\n\tMLX5_COMMAND_STR_CASE(MODIFY_SQ);\n\tMLX5_COMMAND_STR_CASE(DESTROY_SQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_SQ);\n\tMLX5_COMMAND_STR_CASE(CREATE_RQ);\n\tMLX5_COMMAND_STR_CASE(MODIFY_RQ);\n\tMLX5_COMMAND_STR_CASE(DESTROY_RQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_RQ);\n\tMLX5_COMMAND_STR_CASE(CREATE_RMP);\n\tMLX5_COMMAND_STR_CASE(MODIFY_RMP);\n\tMLX5_COMMAND_STR_CASE(DESTROY_RMP);\n\tMLX5_COMMAND_STR_CASE(QUERY_RMP);\n\tMLX5_COMMAND_STR_CASE(CREATE_TIS);\n\tMLX5_COMMAND_STR_CASE(MODIFY_TIS);\n\tMLX5_COMMAND_STR_CASE(DESTROY_TIS);\n\tMLX5_COMMAND_STR_CASE(QUERY_TIS);\n\tMLX5_COMMAND_STR_CASE(CREATE_RQT);\n\tMLX5_COMMAND_STR_CASE(MODIFY_RQT);\n\tMLX5_COMMAND_STR_CASE(DESTROY_RQT);\n\tMLX5_COMMAND_STR_CASE(QUERY_RQT);\n\tMLX5_COMMAND_STR_CASE(SET_FLOW_TABLE_ROOT);\n\tMLX5_COMMAND_STR_CASE(CREATE_FLOW_TABLE);\n\tMLX5_COMMAND_STR_CASE(DESTROY_FLOW_TABLE);\n\tMLX5_COMMAND_STR_CASE(QUERY_FLOW_TABLE);\n\tMLX5_COMMAND_STR_CASE(CREATE_FLOW_GROUP);\n\tMLX5_COMMAND_STR_CASE(DESTROY_FLOW_GROUP);\n\tMLX5_COMMAND_STR_CASE(QUERY_FLOW_GROUP);\n\tMLX5_COMMAND_STR_CASE(SET_FLOW_TABLE_ENTRY);\n\tMLX5_COMMAND_STR_CASE(QUERY_FLOW_TABLE_ENTRY);\n\tMLX5_COMMAND_STR_CASE(DELETE_FLOW_TABLE_ENTRY);\n\tMLX5_COMMAND_STR_CASE(ALLOC_FLOW_COUNTER);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_FLOW_COUNTER);\n\tMLX5_COMMAND_STR_CASE(QUERY_FLOW_COUNTER);\n\tMLX5_COMMAND_STR_CASE(MODIFY_FLOW_TABLE);\n\tMLX5_COMMAND_STR_CASE(ALLOC_PACKET_REFORMAT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_PACKET_REFORMAT_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(ALLOC_MODIFY_HEADER_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_MODIFY_HEADER_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(FPGA_CREATE_QP);\n\tMLX5_COMMAND_STR_CASE(FPGA_MODIFY_QP);\n\tMLX5_COMMAND_STR_CASE(FPGA_QUERY_QP);\n\tMLX5_COMMAND_STR_CASE(FPGA_QUERY_QP_COUNTERS);\n\tMLX5_COMMAND_STR_CASE(FPGA_DESTROY_QP);\n\tMLX5_COMMAND_STR_CASE(CREATE_XRQ);\n\tMLX5_COMMAND_STR_CASE(DESTROY_XRQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_XRQ);\n\tMLX5_COMMAND_STR_CASE(ARM_XRQ);\n\tMLX5_COMMAND_STR_CASE(CREATE_GENERAL_OBJECT);\n\tMLX5_COMMAND_STR_CASE(DESTROY_GENERAL_OBJECT);\n\tMLX5_COMMAND_STR_CASE(MODIFY_GENERAL_OBJECT);\n\tMLX5_COMMAND_STR_CASE(QUERY_GENERAL_OBJECT);\n\tMLX5_COMMAND_STR_CASE(QUERY_MODIFY_HEADER_CONTEXT);\n\tMLX5_COMMAND_STR_CASE(ALLOC_MEMIC);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_MEMIC);\n\tMLX5_COMMAND_STR_CASE(QUERY_ESW_FUNCTIONS);\n\tMLX5_COMMAND_STR_CASE(CREATE_UCTX);\n\tMLX5_COMMAND_STR_CASE(DESTROY_UCTX);\n\tMLX5_COMMAND_STR_CASE(CREATE_UMEM);\n\tMLX5_COMMAND_STR_CASE(DESTROY_UMEM);\n\tMLX5_COMMAND_STR_CASE(RELEASE_XRQ_ERROR);\n\tMLX5_COMMAND_STR_CASE(MODIFY_XRQ);\n\tMLX5_COMMAND_STR_CASE(QUERY_VHCA_STATE);\n\tMLX5_COMMAND_STR_CASE(MODIFY_VHCA_STATE);\n\tMLX5_COMMAND_STR_CASE(ALLOC_SF);\n\tMLX5_COMMAND_STR_CASE(DEALLOC_SF);\n\tMLX5_COMMAND_STR_CASE(SUSPEND_VHCA);\n\tMLX5_COMMAND_STR_CASE(RESUME_VHCA);\n\tMLX5_COMMAND_STR_CASE(QUERY_VHCA_MIGRATION_STATE);\n\tMLX5_COMMAND_STR_CASE(SAVE_VHCA_STATE);\n\tMLX5_COMMAND_STR_CASE(LOAD_VHCA_STATE);\n\tMLX5_COMMAND_STR_CASE(SYNC_CRYPTO);\n\tdefault: return \"unknown command opcode\";\n\t}\n}\n\nstatic const char *cmd_status_str(u8 status)\n{\n\tswitch (status) {\n\tcase MLX5_CMD_STAT_OK:\n\t\treturn \"OK\";\n\tcase MLX5_CMD_STAT_INT_ERR:\n\t\treturn \"internal error\";\n\tcase MLX5_CMD_STAT_BAD_OP_ERR:\n\t\treturn \"bad operation\";\n\tcase MLX5_CMD_STAT_BAD_PARAM_ERR:\n\t\treturn \"bad parameter\";\n\tcase MLX5_CMD_STAT_BAD_SYS_STATE_ERR:\n\t\treturn \"bad system state\";\n\tcase MLX5_CMD_STAT_BAD_RES_ERR:\n\t\treturn \"bad resource\";\n\tcase MLX5_CMD_STAT_RES_BUSY:\n\t\treturn \"resource busy\";\n\tcase MLX5_CMD_STAT_LIM_ERR:\n\t\treturn \"limits exceeded\";\n\tcase MLX5_CMD_STAT_BAD_RES_STATE_ERR:\n\t\treturn \"bad resource state\";\n\tcase MLX5_CMD_STAT_IX_ERR:\n\t\treturn \"bad index\";\n\tcase MLX5_CMD_STAT_NO_RES_ERR:\n\t\treturn \"no resources\";\n\tcase MLX5_CMD_STAT_BAD_INP_LEN_ERR:\n\t\treturn \"bad input length\";\n\tcase MLX5_CMD_STAT_BAD_OUTP_LEN_ERR:\n\t\treturn \"bad output length\";\n\tcase MLX5_CMD_STAT_BAD_QP_STATE_ERR:\n\t\treturn \"bad QP state\";\n\tcase MLX5_CMD_STAT_BAD_PKT_ERR:\n\t\treturn \"bad packet (discarded)\";\n\tcase MLX5_CMD_STAT_BAD_SIZE_OUTS_CQES_ERR:\n\t\treturn \"bad size too many outstanding CQEs\";\n\tdefault:\n\t\treturn \"unknown status\";\n\t}\n}\n\nstatic int cmd_status_to_err(u8 status)\n{\n\tswitch (status) {\n\tcase MLX5_CMD_STAT_OK:\t\t\t\treturn 0;\n\tcase MLX5_CMD_STAT_INT_ERR:\t\t\treturn -EIO;\n\tcase MLX5_CMD_STAT_BAD_OP_ERR:\t\t\treturn -EINVAL;\n\tcase MLX5_CMD_STAT_BAD_PARAM_ERR:\t\treturn -EINVAL;\n\tcase MLX5_CMD_STAT_BAD_SYS_STATE_ERR:\t\treturn -EIO;\n\tcase MLX5_CMD_STAT_BAD_RES_ERR:\t\t\treturn -EINVAL;\n\tcase MLX5_CMD_STAT_RES_BUSY:\t\t\treturn -EBUSY;\n\tcase MLX5_CMD_STAT_LIM_ERR:\t\t\treturn -ENOMEM;\n\tcase MLX5_CMD_STAT_BAD_RES_STATE_ERR:\t\treturn -EINVAL;\n\tcase MLX5_CMD_STAT_IX_ERR:\t\t\treturn -EINVAL;\n\tcase MLX5_CMD_STAT_NO_RES_ERR:\t\t\treturn -EAGAIN;\n\tcase MLX5_CMD_STAT_BAD_INP_LEN_ERR:\t\treturn -EIO;\n\tcase MLX5_CMD_STAT_BAD_OUTP_LEN_ERR:\t\treturn -EIO;\n\tcase MLX5_CMD_STAT_BAD_QP_STATE_ERR:\t\treturn -EINVAL;\n\tcase MLX5_CMD_STAT_BAD_PKT_ERR:\t\t\treturn -EINVAL;\n\tcase MLX5_CMD_STAT_BAD_SIZE_OUTS_CQES_ERR:\treturn -EINVAL;\n\tdefault:\t\t\t\t\treturn -EIO;\n\t}\n}\n\nvoid mlx5_cmd_out_err(struct mlx5_core_dev *dev, u16 opcode, u16 op_mod, void *out)\n{\n\tu32 syndrome = MLX5_GET(mbox_out, out, syndrome);\n\tu8 status = MLX5_GET(mbox_out, out, status);\n\n\tmlx5_core_err_rl(dev,\n\t\t\t \"%s(0x%x) op_mod(0x%x) failed, status %s(0x%x), syndrome (0x%x), err(%d)\\n\",\n\t\t\t mlx5_command_str(opcode), opcode, op_mod,\n\t\t\t cmd_status_str(status), status, syndrome, cmd_status_to_err(status));\n}\nEXPORT_SYMBOL(mlx5_cmd_out_err);\n\nstatic void cmd_status_print(struct mlx5_core_dev *dev, void *in, void *out)\n{\n\tu16 opcode, op_mod;\n\tu16 uid;\n\n\topcode = in_to_opcode(in);\n\top_mod = MLX5_GET(mbox_in, in, op_mod);\n\tuid    = MLX5_GET(mbox_in, in, uid);\n\n\tif (!uid && opcode != MLX5_CMD_OP_DESTROY_MKEY &&\n\t    opcode != MLX5_CMD_OP_CREATE_UCTX)\n\t\tmlx5_cmd_out_err(dev, opcode, op_mod, out);\n}\n\nint mlx5_cmd_check(struct mlx5_core_dev *dev, int err, void *in, void *out)\n{\n\t \n\tif (err == -ENXIO) {\n\t\tu16 opcode = in_to_opcode(in);\n\t\tu32 syndrome;\n\t\tu8 status;\n\n\t\t \n\t\terr = mlx5_internal_err_ret_value(dev, opcode, &syndrome, &status);\n\t\tMLX5_SET(mbox_out, out, status, status);\n\t\tMLX5_SET(mbox_out, out, syndrome, syndrome);\n\t\tif (!err)\n\t\t\treturn 0;\n\t}\n\n\t \n\tif (err != -EREMOTEIO && err)\n\t\treturn err;\n\n\t \n\terr = cmd_status_to_err(MLX5_GET(mbox_out, out, status));\n\tif (err)\n\t\tcmd_status_print(dev, in, out);\n\n\treturn err;\n}\nEXPORT_SYMBOL(mlx5_cmd_check);\n\nstatic void dump_command(struct mlx5_core_dev *dev,\n\t\t\t struct mlx5_cmd_work_ent *ent, int input)\n{\n\tstruct mlx5_cmd_msg *msg = input ? ent->in : ent->out;\n\tstruct mlx5_cmd_mailbox *next = msg->next;\n\tint n = mlx5_calc_cmd_blocks(msg);\n\tu16 op = ent->op;\n\tint data_only;\n\tu32 offset = 0;\n\tint dump_len;\n\tint i;\n\n\tmlx5_core_dbg(dev, \"cmd[%d]: start dump\\n\", ent->idx);\n\tdata_only = !!(mlx5_core_debug_mask & (1 << MLX5_CMD_DATA));\n\n\tif (data_only)\n\t\tmlx5_core_dbg_mask(dev, 1 << MLX5_CMD_DATA,\n\t\t\t\t   \"cmd[%d]: dump command data %s(0x%x) %s\\n\",\n\t\t\t\t   ent->idx, mlx5_command_str(op), op,\n\t\t\t\t   input ? \"INPUT\" : \"OUTPUT\");\n\telse\n\t\tmlx5_core_dbg(dev, \"cmd[%d]: dump command %s(0x%x) %s\\n\",\n\t\t\t      ent->idx, mlx5_command_str(op), op,\n\t\t\t      input ? \"INPUT\" : \"OUTPUT\");\n\n\tif (data_only) {\n\t\tif (input) {\n\t\t\tdump_buf(ent->lay->in, sizeof(ent->lay->in), 1, offset, ent->idx);\n\t\t\toffset += sizeof(ent->lay->in);\n\t\t} else {\n\t\t\tdump_buf(ent->lay->out, sizeof(ent->lay->out), 1, offset, ent->idx);\n\t\t\toffset += sizeof(ent->lay->out);\n\t\t}\n\t} else {\n\t\tdump_buf(ent->lay, sizeof(*ent->lay), 0, offset, ent->idx);\n\t\toffset += sizeof(*ent->lay);\n\t}\n\n\tfor (i = 0; i < n && next; i++)  {\n\t\tif (data_only) {\n\t\t\tdump_len = min_t(int, MLX5_CMD_DATA_BLOCK_SIZE, msg->len - offset);\n\t\t\tdump_buf(next->buf, dump_len, 1, offset, ent->idx);\n\t\t\toffset += MLX5_CMD_DATA_BLOCK_SIZE;\n\t\t} else {\n\t\t\tmlx5_core_dbg(dev, \"cmd[%d]: command block:\\n\", ent->idx);\n\t\t\tdump_buf(next->buf, sizeof(struct mlx5_cmd_prot_block), 0, offset,\n\t\t\t\t ent->idx);\n\t\t\toffset += sizeof(struct mlx5_cmd_prot_block);\n\t\t}\n\t\tnext = next->next;\n\t}\n\n\tif (data_only)\n\t\tpr_debug(\"\\n\");\n\n\tmlx5_core_dbg(dev, \"cmd[%d]: end dump\\n\", ent->idx);\n}\n\nstatic void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced);\n\nstatic void cb_timeout_handler(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = container_of(work, struct delayed_work,\n\t\t\t\t\t\t  work);\n\tstruct mlx5_cmd_work_ent *ent = container_of(dwork,\n\t\t\t\t\t\t     struct mlx5_cmd_work_ent,\n\t\t\t\t\t\t     cb_timeout_work);\n\tstruct mlx5_core_dev *dev = container_of(ent->cmd, struct mlx5_core_dev,\n\t\t\t\t\t\t cmd);\n\n\tmlx5_cmd_eq_recover(dev);\n\n\t \n\tif (!test_bit(MLX5_CMD_ENT_STATE_PENDING_COMP, &ent->state)) {\n\t\tmlx5_core_warn(dev, \"cmd[%d]: %s(0x%x) Async, recovered after timeout\\n\", ent->idx,\n\t\t\t       mlx5_command_str(ent->op), ent->op);\n\t\tgoto out;  \n\t}\n\n\tent->ret = -ETIMEDOUT;\n\tmlx5_core_warn(dev, \"cmd[%d]: %s(0x%x) Async, timeout. Will cause a leak of a command resource\\n\",\n\t\t       ent->idx, mlx5_command_str(ent->op), ent->op);\n\tmlx5_cmd_comp_handler(dev, 1ULL << ent->idx, true);\n\nout:\n\tcmd_ent_put(ent);  \n}\n\nstatic void free_msg(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *msg);\nstatic void mlx5_free_cmd_msg(struct mlx5_core_dev *dev,\n\t\t\t      struct mlx5_cmd_msg *msg);\n\nstatic bool opcode_allowed(struct mlx5_cmd *cmd, u16 opcode)\n{\n\tif (cmd->allowed_opcode == CMD_ALLOWED_OPCODE_ALL)\n\t\treturn true;\n\n\treturn cmd->allowed_opcode == opcode;\n}\n\nbool mlx5_cmd_is_down(struct mlx5_core_dev *dev)\n{\n\treturn pci_channel_offline(dev->pdev) ||\n\t       dev->cmd.state != MLX5_CMDIF_STATE_UP ||\n\t       dev->state == MLX5_DEVICE_STATE_INTERNAL_ERROR;\n}\n\nstatic void cmd_work_handler(struct work_struct *work)\n{\n\tstruct mlx5_cmd_work_ent *ent = container_of(work, struct mlx5_cmd_work_ent, work);\n\tstruct mlx5_cmd *cmd = ent->cmd;\n\tbool poll_cmd = ent->polling;\n\tstruct mlx5_cmd_layout *lay;\n\tstruct mlx5_core_dev *dev;\n\tunsigned long cb_timeout;\n\tstruct semaphore *sem;\n\tunsigned long flags;\n\tint alloc_ret;\n\tint cmd_mode;\n\n\tdev = container_of(cmd, struct mlx5_core_dev, cmd);\n\tcb_timeout = msecs_to_jiffies(mlx5_tout_ms(dev, CMD));\n\n\tcomplete(&ent->handling);\n\tsem = ent->page_queue ? &cmd->vars.pages_sem : &cmd->vars.sem;\n\tdown(sem);\n\tif (!ent->page_queue) {\n\t\talloc_ret = cmd_alloc_index(cmd, ent);\n\t\tif (alloc_ret < 0) {\n\t\t\tmlx5_core_err_rl(dev, \"failed to allocate command entry\\n\");\n\t\t\tif (ent->callback) {\n\t\t\t\tent->callback(-EAGAIN, ent->context);\n\t\t\t\tmlx5_free_cmd_msg(dev, ent->out);\n\t\t\t\tfree_msg(dev, ent->in);\n\t\t\t\tcmd_ent_put(ent);\n\t\t\t} else {\n\t\t\t\tent->ret = -EAGAIN;\n\t\t\t\tcomplete(&ent->done);\n\t\t\t}\n\t\t\tup(sem);\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\tent->idx = cmd->vars.max_reg_cmds;\n\t\tspin_lock_irqsave(&cmd->alloc_lock, flags);\n\t\tclear_bit(ent->idx, &cmd->vars.bitmask);\n\t\tcmd->ent_arr[ent->idx] = ent;\n\t\tspin_unlock_irqrestore(&cmd->alloc_lock, flags);\n\t}\n\n\tlay = get_inst(cmd, ent->idx);\n\tent->lay = lay;\n\tmemset(lay, 0, sizeof(*lay));\n\tmemcpy(lay->in, ent->in->first.data, sizeof(lay->in));\n\tif (ent->in->next)\n\t\tlay->in_ptr = cpu_to_be64(ent->in->next->dma);\n\tlay->inlen = cpu_to_be32(ent->in->len);\n\tif (ent->out->next)\n\t\tlay->out_ptr = cpu_to_be64(ent->out->next->dma);\n\tlay->outlen = cpu_to_be32(ent->out->len);\n\tlay->type = MLX5_PCI_CMD_XPORT;\n\tlay->token = ent->token;\n\tlay->status_own = CMD_OWNER_HW;\n\tset_signature(ent, !cmd->checksum_disabled);\n\tdump_command(dev, ent, 1);\n\tent->ts1 = ktime_get_ns();\n\tcmd_mode = cmd->mode;\n\n\tif (ent->callback && schedule_delayed_work(&ent->cb_timeout_work, cb_timeout))\n\t\tcmd_ent_get(ent);\n\tset_bit(MLX5_CMD_ENT_STATE_PENDING_COMP, &ent->state);\n\n\tcmd_ent_get(ent);  \n\t \n\tif (mlx5_cmd_is_down(dev) || !opcode_allowed(&dev->cmd, ent->op)) {\n\t\tent->ret = -ENXIO;\n\t\tmlx5_cmd_comp_handler(dev, 1ULL << ent->idx, true);\n\t\treturn;\n\t}\n\n\t \n\tmlx5_core_dbg(dev, \"writing 0x%x to command doorbell\\n\", 1 << ent->idx);\n\twmb();\n\tiowrite32be(1 << ent->idx, &dev->iseg->cmd_dbell);\n\t \n\tif (cmd_mode == CMD_MODE_POLLING || poll_cmd) {\n\t\tpoll_timeout(ent);\n\t\t \n\t\trmb();\n\t\tmlx5_cmd_comp_handler(dev, 1ULL << ent->idx, (ent->ret == -ETIMEDOUT));\n\t}\n}\n\nstatic int deliv_status_to_err(u8 status)\n{\n\tswitch (status) {\n\tcase MLX5_CMD_DELIVERY_STAT_OK:\n\tcase MLX5_DRIVER_STATUS_ABORTED:\n\t\treturn 0;\n\tcase MLX5_CMD_DELIVERY_STAT_SIGNAT_ERR:\n\tcase MLX5_CMD_DELIVERY_STAT_TOK_ERR:\n\t\treturn -EBADR;\n\tcase MLX5_CMD_DELIVERY_STAT_BAD_BLK_NUM_ERR:\n\tcase MLX5_CMD_DELIVERY_STAT_OUT_PTR_ALIGN_ERR:\n\tcase MLX5_CMD_DELIVERY_STAT_IN_PTR_ALIGN_ERR:\n\t\treturn -EFAULT;  \n\tcase MLX5_CMD_DELIVERY_STAT_IN_LENGTH_ERR:\n\tcase MLX5_CMD_DELIVERY_STAT_OUT_LENGTH_ERR:\n\tcase MLX5_CMD_DELIVERY_STAT_CMD_DESCR_ERR:\n\tcase MLX5_CMD_DELIVERY_STAT_RES_FLD_NOT_CLR_ERR:\n\t\treturn -ENOMSG;\n\tcase MLX5_CMD_DELIVERY_STAT_FW_ERR:\n\t\treturn -EIO;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic const char *deliv_status_to_str(u8 status)\n{\n\tswitch (status) {\n\tcase MLX5_CMD_DELIVERY_STAT_OK:\n\t\treturn \"no errors\";\n\tcase MLX5_CMD_DELIVERY_STAT_SIGNAT_ERR:\n\t\treturn \"signature error\";\n\tcase MLX5_CMD_DELIVERY_STAT_TOK_ERR:\n\t\treturn \"token error\";\n\tcase MLX5_CMD_DELIVERY_STAT_BAD_BLK_NUM_ERR:\n\t\treturn \"bad block number\";\n\tcase MLX5_CMD_DELIVERY_STAT_OUT_PTR_ALIGN_ERR:\n\t\treturn \"output pointer not aligned to block size\";\n\tcase MLX5_CMD_DELIVERY_STAT_IN_PTR_ALIGN_ERR:\n\t\treturn \"input pointer not aligned to block size\";\n\tcase MLX5_CMD_DELIVERY_STAT_FW_ERR:\n\t\treturn \"firmware internal error\";\n\tcase MLX5_CMD_DELIVERY_STAT_IN_LENGTH_ERR:\n\t\treturn \"command input length error\";\n\tcase MLX5_CMD_DELIVERY_STAT_OUT_LENGTH_ERR:\n\t\treturn \"command output length error\";\n\tcase MLX5_CMD_DELIVERY_STAT_RES_FLD_NOT_CLR_ERR:\n\t\treturn \"reserved fields not cleared\";\n\tcase MLX5_CMD_DELIVERY_STAT_CMD_DESCR_ERR:\n\t\treturn \"bad command descriptor type\";\n\tdefault:\n\t\treturn \"unknown status code\";\n\t}\n}\n\nenum {\n\tMLX5_CMD_TIMEOUT_RECOVER_MSEC   = 5 * 1000,\n};\n\nstatic void wait_func_handle_exec_timeout(struct mlx5_core_dev *dev,\n\t\t\t\t\t  struct mlx5_cmd_work_ent *ent)\n{\n\tunsigned long timeout = msecs_to_jiffies(MLX5_CMD_TIMEOUT_RECOVER_MSEC);\n\n\tmlx5_cmd_eq_recover(dev);\n\n\t \n\tif (wait_for_completion_timeout(&ent->done, timeout)) {\n\t\tmlx5_core_warn(dev, \"cmd[%d]: %s(0x%x) recovered after timeout\\n\", ent->idx,\n\t\t\t       mlx5_command_str(ent->op), ent->op);\n\t\treturn;\n\t}\n\n\tmlx5_core_warn(dev, \"cmd[%d]: %s(0x%x) No done completion\\n\", ent->idx,\n\t\t       mlx5_command_str(ent->op), ent->op);\n\n\tent->ret = -ETIMEDOUT;\n\tmlx5_cmd_comp_handler(dev, 1ULL << ent->idx, true);\n}\n\nstatic int wait_func(struct mlx5_core_dev *dev, struct mlx5_cmd_work_ent *ent)\n{\n\tunsigned long timeout = msecs_to_jiffies(mlx5_tout_ms(dev, CMD));\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tint err;\n\n\tif (!wait_for_completion_timeout(&ent->handling, timeout) &&\n\t    cancel_work_sync(&ent->work)) {\n\t\tent->ret = -ECANCELED;\n\t\tgoto out_err;\n\t}\n\tif (cmd->mode == CMD_MODE_POLLING || ent->polling)\n\t\twait_for_completion(&ent->done);\n\telse if (!wait_for_completion_timeout(&ent->done, timeout))\n\t\twait_func_handle_exec_timeout(dev, ent);\n\nout_err:\n\terr = ent->ret;\n\n\tif (err == -ETIMEDOUT) {\n\t\tmlx5_core_warn(dev, \"%s(0x%x) timeout. Will cause a leak of a command resource\\n\",\n\t\t\t       mlx5_command_str(ent->op), ent->op);\n\t} else if (err == -ECANCELED) {\n\t\tmlx5_core_warn(dev, \"%s(0x%x) canceled on out of queue timeout.\\n\",\n\t\t\t       mlx5_command_str(ent->op), ent->op);\n\t}\n\tmlx5_core_dbg(dev, \"err %d, delivery status %s(%d)\\n\",\n\t\t      err, deliv_status_to_str(ent->status), ent->status);\n\n\treturn err;\n}\n\n \nstatic int mlx5_cmd_invoke(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *in,\n\t\t\t   struct mlx5_cmd_msg *out, void *uout, int uout_size,\n\t\t\t   mlx5_cmd_cbk_t callback,\n\t\t\t   void *context, int page_queue,\n\t\t\t   u8 token, bool force_polling)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tstruct mlx5_cmd_work_ent *ent;\n\tstruct mlx5_cmd_stats *stats;\n\tu8 status = 0;\n\tint err = 0;\n\ts64 ds;\n\n\tif (callback && page_queue)\n\t\treturn -EINVAL;\n\n\tent = cmd_alloc_ent(cmd, in, out, uout, uout_size,\n\t\t\t    callback, context, page_queue);\n\tif (IS_ERR(ent))\n\t\treturn PTR_ERR(ent);\n\n\t \n\n\tent->token = token;\n\tent->polling = force_polling;\n\n\tinit_completion(&ent->handling);\n\tif (!callback)\n\t\tinit_completion(&ent->done);\n\n\tINIT_DELAYED_WORK(&ent->cb_timeout_work, cb_timeout_handler);\n\tINIT_WORK(&ent->work, cmd_work_handler);\n\tif (page_queue) {\n\t\tcmd_work_handler(&ent->work);\n\t} else if (!queue_work(cmd->wq, &ent->work)) {\n\t\tmlx5_core_warn(dev, \"failed to queue work\\n\");\n\t\terr = -EALREADY;\n\t\tgoto out_free;\n\t}\n\n\tif (callback)\n\t\treturn 0;  \n\n\terr = wait_func(dev, ent);\n\tif (err == -ETIMEDOUT || err == -ECANCELED)\n\t\tgoto out_free;\n\n\tds = ent->ts2 - ent->ts1;\n\tstats = xa_load(&cmd->stats, ent->op);\n\tif (stats) {\n\t\tspin_lock_irq(&stats->lock);\n\t\tstats->sum += ds;\n\t\t++stats->n;\n\t\tspin_unlock_irq(&stats->lock);\n\t}\n\tmlx5_core_dbg_mask(dev, 1 << MLX5_CMD_TIME,\n\t\t\t   \"fw exec time for %s is %lld nsec\\n\",\n\t\t\t   mlx5_command_str(ent->op), ds);\n\nout_free:\n\tstatus = ent->status;\n\tcmd_ent_put(ent);\n\treturn err ? : status;\n}\n\nstatic ssize_t dbg_write(struct file *filp, const char __user *buf,\n\t\t\t size_t count, loff_t *pos)\n{\n\tstruct mlx5_core_dev *dev = filp->private_data;\n\tstruct mlx5_cmd_debug *dbg = &dev->cmd.dbg;\n\tchar lbuf[3];\n\tint err;\n\n\tif (!dbg->in_msg || !dbg->out_msg)\n\t\treturn -ENOMEM;\n\n\tif (count < sizeof(lbuf) - 1)\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(lbuf, buf, sizeof(lbuf) - 1))\n\t\treturn -EFAULT;\n\n\tlbuf[sizeof(lbuf) - 1] = 0;\n\n\tif (strcmp(lbuf, \"go\"))\n\t\treturn -EINVAL;\n\n\terr = mlx5_cmd_exec(dev, dbg->in_msg, dbg->inlen, dbg->out_msg, dbg->outlen);\n\n\treturn err ? err : count;\n}\n\nstatic const struct file_operations fops = {\n\t.owner\t= THIS_MODULE,\n\t.open\t= simple_open,\n\t.write\t= dbg_write,\n};\n\nstatic int mlx5_copy_to_msg(struct mlx5_cmd_msg *to, void *from, int size,\n\t\t\t    u8 token)\n{\n\tstruct mlx5_cmd_prot_block *block;\n\tstruct mlx5_cmd_mailbox *next;\n\tint copy;\n\n\tif (!to || !from)\n\t\treturn -ENOMEM;\n\n\tcopy = min_t(int, size, sizeof(to->first.data));\n\tmemcpy(to->first.data, from, copy);\n\tsize -= copy;\n\tfrom += copy;\n\n\tnext = to->next;\n\twhile (size) {\n\t\tif (!next) {\n\t\t\t \n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tcopy = min_t(int, size, MLX5_CMD_DATA_BLOCK_SIZE);\n\t\tblock = next->buf;\n\t\tmemcpy(block->data, from, copy);\n\t\tfrom += copy;\n\t\tsize -= copy;\n\t\tblock->token = token;\n\t\tnext = next->next;\n\t}\n\n\treturn 0;\n}\n\nstatic int mlx5_copy_from_msg(void *to, struct mlx5_cmd_msg *from, int size)\n{\n\tstruct mlx5_cmd_prot_block *block;\n\tstruct mlx5_cmd_mailbox *next;\n\tint copy;\n\n\tif (!to || !from)\n\t\treturn -ENOMEM;\n\n\tcopy = min_t(int, size, sizeof(from->first.data));\n\tmemcpy(to, from->first.data, copy);\n\tsize -= copy;\n\tto += copy;\n\n\tnext = from->next;\n\twhile (size) {\n\t\tif (!next) {\n\t\t\t \n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tcopy = min_t(int, size, MLX5_CMD_DATA_BLOCK_SIZE);\n\t\tblock = next->buf;\n\n\t\tmemcpy(to, block->data, copy);\n\t\tto += copy;\n\t\tsize -= copy;\n\t\tnext = next->next;\n\t}\n\n\treturn 0;\n}\n\nstatic struct mlx5_cmd_mailbox *alloc_cmd_box(struct mlx5_core_dev *dev,\n\t\t\t\t\t      gfp_t flags)\n{\n\tstruct mlx5_cmd_mailbox *mailbox;\n\n\tmailbox = kmalloc(sizeof(*mailbox), flags);\n\tif (!mailbox)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmailbox->buf = dma_pool_zalloc(dev->cmd.pool, flags,\n\t\t\t\t       &mailbox->dma);\n\tif (!mailbox->buf) {\n\t\tmlx5_core_dbg(dev, \"failed allocation\\n\");\n\t\tkfree(mailbox);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tmailbox->next = NULL;\n\n\treturn mailbox;\n}\n\nstatic void free_cmd_box(struct mlx5_core_dev *dev,\n\t\t\t struct mlx5_cmd_mailbox *mailbox)\n{\n\tdma_pool_free(dev->cmd.pool, mailbox->buf, mailbox->dma);\n\tkfree(mailbox);\n}\n\nstatic struct mlx5_cmd_msg *mlx5_alloc_cmd_msg(struct mlx5_core_dev *dev,\n\t\t\t\t\t       gfp_t flags, int size,\n\t\t\t\t\t       u8 token)\n{\n\tstruct mlx5_cmd_mailbox *tmp, *head = NULL;\n\tstruct mlx5_cmd_prot_block *block;\n\tstruct mlx5_cmd_msg *msg;\n\tint err;\n\tint n;\n\tint i;\n\n\tmsg = kzalloc(sizeof(*msg), flags);\n\tif (!msg)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmsg->len = size;\n\tn = mlx5_calc_cmd_blocks(msg);\n\n\tfor (i = 0; i < n; i++) {\n\t\ttmp = alloc_cmd_box(dev, flags);\n\t\tif (IS_ERR(tmp)) {\n\t\t\tmlx5_core_warn(dev, \"failed allocating block\\n\");\n\t\t\terr = PTR_ERR(tmp);\n\t\t\tgoto err_alloc;\n\t\t}\n\n\t\tblock = tmp->buf;\n\t\ttmp->next = head;\n\t\tblock->next = cpu_to_be64(tmp->next ? tmp->next->dma : 0);\n\t\tblock->block_num = cpu_to_be32(n - i - 1);\n\t\tblock->token = token;\n\t\thead = tmp;\n\t}\n\tmsg->next = head;\n\treturn msg;\n\nerr_alloc:\n\twhile (head) {\n\t\ttmp = head->next;\n\t\tfree_cmd_box(dev, head);\n\t\thead = tmp;\n\t}\n\tkfree(msg);\n\n\treturn ERR_PTR(err);\n}\n\nstatic void mlx5_free_cmd_msg(struct mlx5_core_dev *dev,\n\t\t\t      struct mlx5_cmd_msg *msg)\n{\n\tstruct mlx5_cmd_mailbox *head = msg->next;\n\tstruct mlx5_cmd_mailbox *next;\n\n\twhile (head) {\n\t\tnext = head->next;\n\t\tfree_cmd_box(dev, head);\n\t\thead = next;\n\t}\n\tkfree(msg);\n}\n\nstatic ssize_t data_write(struct file *filp, const char __user *buf,\n\t\t\t  size_t count, loff_t *pos)\n{\n\tstruct mlx5_core_dev *dev = filp->private_data;\n\tstruct mlx5_cmd_debug *dbg = &dev->cmd.dbg;\n\tvoid *ptr;\n\n\tif (*pos != 0)\n\t\treturn -EINVAL;\n\n\tkfree(dbg->in_msg);\n\tdbg->in_msg = NULL;\n\tdbg->inlen = 0;\n\tptr = memdup_user(buf, count);\n\tif (IS_ERR(ptr))\n\t\treturn PTR_ERR(ptr);\n\tdbg->in_msg = ptr;\n\tdbg->inlen = count;\n\n\t*pos = count;\n\n\treturn count;\n}\n\nstatic ssize_t data_read(struct file *filp, char __user *buf, size_t count,\n\t\t\t loff_t *pos)\n{\n\tstruct mlx5_core_dev *dev = filp->private_data;\n\tstruct mlx5_cmd_debug *dbg = &dev->cmd.dbg;\n\n\tif (!dbg->out_msg)\n\t\treturn -ENOMEM;\n\n\treturn simple_read_from_buffer(buf, count, pos, dbg->out_msg,\n\t\t\t\t       dbg->outlen);\n}\n\nstatic const struct file_operations dfops = {\n\t.owner\t= THIS_MODULE,\n\t.open\t= simple_open,\n\t.write\t= data_write,\n\t.read\t= data_read,\n};\n\nstatic ssize_t outlen_read(struct file *filp, char __user *buf, size_t count,\n\t\t\t   loff_t *pos)\n{\n\tstruct mlx5_core_dev *dev = filp->private_data;\n\tstruct mlx5_cmd_debug *dbg = &dev->cmd.dbg;\n\tchar outlen[8];\n\tint err;\n\n\terr = snprintf(outlen, sizeof(outlen), \"%d\", dbg->outlen);\n\tif (err < 0)\n\t\treturn err;\n\n\treturn simple_read_from_buffer(buf, count, pos, outlen, err);\n}\n\nstatic ssize_t outlen_write(struct file *filp, const char __user *buf,\n\t\t\t    size_t count, loff_t *pos)\n{\n\tstruct mlx5_core_dev *dev = filp->private_data;\n\tstruct mlx5_cmd_debug *dbg = &dev->cmd.dbg;\n\tchar outlen_str[8] = {0};\n\tint outlen;\n\tvoid *ptr;\n\tint err;\n\n\tif (*pos != 0 || count > 6)\n\t\treturn -EINVAL;\n\n\tkfree(dbg->out_msg);\n\tdbg->out_msg = NULL;\n\tdbg->outlen = 0;\n\n\tif (copy_from_user(outlen_str, buf, count))\n\t\treturn -EFAULT;\n\n\terr = sscanf(outlen_str, \"%d\", &outlen);\n\tif (err != 1)\n\t\treturn -EINVAL;\n\n\tptr = kzalloc(outlen, GFP_KERNEL);\n\tif (!ptr)\n\t\treturn -ENOMEM;\n\n\tdbg->out_msg = ptr;\n\tdbg->outlen = outlen;\n\n\t*pos = count;\n\n\treturn count;\n}\n\nstatic const struct file_operations olfops = {\n\t.owner\t= THIS_MODULE,\n\t.open\t= simple_open,\n\t.write\t= outlen_write,\n\t.read\t= outlen_read,\n};\n\nstatic void set_wqname(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\n\tsnprintf(cmd->wq_name, sizeof(cmd->wq_name), \"mlx5_cmd_%s\",\n\t\t dev_name(dev->device));\n}\n\nstatic void clean_debug_files(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd_debug *dbg = &dev->cmd.dbg;\n\n\tif (!mlx5_debugfs_root)\n\t\treturn;\n\n\tdebugfs_remove_recursive(dbg->dbg_root);\n}\n\nstatic void create_debugfs_files(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd_debug *dbg = &dev->cmd.dbg;\n\n\tdbg->dbg_root = debugfs_create_dir(\"cmd\", mlx5_debugfs_get_dev_root(dev));\n\n\tdebugfs_create_file(\"in\", 0400, dbg->dbg_root, dev, &dfops);\n\tdebugfs_create_file(\"out\", 0200, dbg->dbg_root, dev, &dfops);\n\tdebugfs_create_file(\"out_len\", 0600, dbg->dbg_root, dev, &olfops);\n\tdebugfs_create_u8(\"status\", 0600, dbg->dbg_root, &dbg->status);\n\tdebugfs_create_file(\"run\", 0200, dbg->dbg_root, dev, &fops);\n}\n\nvoid mlx5_cmd_allowed_opcode(struct mlx5_core_dev *dev, u16 opcode)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tint i;\n\n\tfor (i = 0; i < cmd->vars.max_reg_cmds; i++)\n\t\tdown(&cmd->vars.sem);\n\tdown(&cmd->vars.pages_sem);\n\n\tcmd->allowed_opcode = opcode;\n\n\tup(&cmd->vars.pages_sem);\n\tfor (i = 0; i < cmd->vars.max_reg_cmds; i++)\n\t\tup(&cmd->vars.sem);\n}\n\nstatic void mlx5_cmd_change_mod(struct mlx5_core_dev *dev, int mode)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tint i;\n\n\tfor (i = 0; i < cmd->vars.max_reg_cmds; i++)\n\t\tdown(&cmd->vars.sem);\n\tdown(&cmd->vars.pages_sem);\n\n\tcmd->mode = mode;\n\n\tup(&cmd->vars.pages_sem);\n\tfor (i = 0; i < cmd->vars.max_reg_cmds; i++)\n\t\tup(&cmd->vars.sem);\n}\n\nstatic int cmd_comp_notifier(struct notifier_block *nb,\n\t\t\t     unsigned long type, void *data)\n{\n\tstruct mlx5_core_dev *dev;\n\tstruct mlx5_cmd *cmd;\n\tstruct mlx5_eqe *eqe;\n\n\tcmd = mlx5_nb_cof(nb, struct mlx5_cmd, nb);\n\tdev = container_of(cmd, struct mlx5_core_dev, cmd);\n\teqe = data;\n\n\tmlx5_cmd_comp_handler(dev, be32_to_cpu(eqe->data.cmd.vector), false);\n\n\treturn NOTIFY_OK;\n}\nvoid mlx5_cmd_use_events(struct mlx5_core_dev *dev)\n{\n\tMLX5_NB_INIT(&dev->cmd.nb, cmd_comp_notifier, CMD);\n\tmlx5_eq_notifier_register(dev, &dev->cmd.nb);\n\tmlx5_cmd_change_mod(dev, CMD_MODE_EVENTS);\n}\n\nvoid mlx5_cmd_use_polling(struct mlx5_core_dev *dev)\n{\n\tmlx5_cmd_change_mod(dev, CMD_MODE_POLLING);\n\tmlx5_eq_notifier_unregister(dev, &dev->cmd.nb);\n}\n\nstatic void free_msg(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *msg)\n{\n\tunsigned long flags;\n\n\tif (msg->parent) {\n\t\tspin_lock_irqsave(&msg->parent->lock, flags);\n\t\tlist_add_tail(&msg->list, &msg->parent->head);\n\t\tspin_unlock_irqrestore(&msg->parent->lock, flags);\n\t} else {\n\t\tmlx5_free_cmd_msg(dev, msg);\n\t}\n}\n\nstatic void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tstruct mlx5_cmd_work_ent *ent;\n\tmlx5_cmd_cbk_t callback;\n\tvoid *context;\n\tint err;\n\tint i;\n\ts64 ds;\n\tstruct mlx5_cmd_stats *stats;\n\tunsigned long flags;\n\tunsigned long vector;\n\n\t \n\tvector = vec & 0xffffffff;\n\tfor (i = 0; i < (1 << cmd->vars.log_sz); i++) {\n\t\tif (test_bit(i, &vector)) {\n\t\t\tent = cmd->ent_arr[i];\n\n\t\t\t \n\t\t\tif (!test_and_clear_bit(MLX5_CMD_ENT_STATE_PENDING_COMP,\n\t\t\t\t\t\t&ent->state)) {\n\t\t\t\t \n\t\t\t\tif (!forced) {\n\t\t\t\t\tmlx5_core_err(dev, \"Command completion arrived after timeout (entry idx = %d).\\n\",\n\t\t\t\t\t\t      ent->idx);\n\t\t\t\t\tcmd_ent_put(ent);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (ent->callback && cancel_delayed_work(&ent->cb_timeout_work))\n\t\t\t\tcmd_ent_put(ent);  \n\n\t\t\tif (!forced ||  \n\t\t\t     mlx5_cmd_is_down(dev) ||  \n\t\t\t     !opcode_allowed(cmd, ent->op))\n\t\t\t\tcmd_ent_put(ent);\n\n\t\t\tent->ts2 = ktime_get_ns();\n\t\t\tmemcpy(ent->out->first.data, ent->lay->out, sizeof(ent->lay->out));\n\t\t\tdump_command(dev, ent, 0);\n\n\t\t\tif (vec & MLX5_TRIGGERED_CMD_COMP)\n\t\t\t\tent->ret = -ENXIO;\n\n\t\t\tif (!ent->ret) {  \n\t\t\t\tif (!cmd->checksum_disabled)\n\t\t\t\t\tent->ret = verify_signature(ent);\n\n\t\t\t\tent->status = ent->lay->status_own >> 1;\n\n\t\t\t\tmlx5_core_dbg(dev, \"command completed. ret 0x%x, delivery status %s(0x%x)\\n\",\n\t\t\t\t\t      ent->ret, deliv_status_to_str(ent->status), ent->status);\n\t\t\t}\n\n\t\t\tif (ent->callback) {\n\t\t\t\tds = ent->ts2 - ent->ts1;\n\t\t\t\tstats = xa_load(&cmd->stats, ent->op);\n\t\t\t\tif (stats) {\n\t\t\t\t\tspin_lock_irqsave(&stats->lock, flags);\n\t\t\t\t\tstats->sum += ds;\n\t\t\t\t\t++stats->n;\n\t\t\t\t\tspin_unlock_irqrestore(&stats->lock, flags);\n\t\t\t\t}\n\n\t\t\t\tcallback = ent->callback;\n\t\t\t\tcontext = ent->context;\n\t\t\t\terr = ent->ret ? : ent->status;\n\t\t\t\tif (err > 0)  \n\t\t\t\t\terr = deliv_status_to_err(err);\n\n\t\t\t\tif (!err)\n\t\t\t\t\terr = mlx5_copy_from_msg(ent->uout,\n\t\t\t\t\t\t\t\t ent->out,\n\t\t\t\t\t\t\t\t ent->uout_size);\n\n\t\t\t\tmlx5_free_cmd_msg(dev, ent->out);\n\t\t\t\tfree_msg(dev, ent->in);\n\n\t\t\t\t \n\t\t\t\tcmd_ent_put(ent);\n\t\t\t\tcallback(err, context);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tcomplete(&ent->done);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void mlx5_cmd_trigger_completions(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tunsigned long bitmask;\n\tunsigned long flags;\n\tu64 vector;\n\tint i;\n\n\t \n\tmlx5_eq_synchronize_cmd_irq(dev);\n\tspin_lock_irqsave(&dev->cmd.alloc_lock, flags);\n\tvector = ~dev->cmd.vars.bitmask & ((1ul << (1 << dev->cmd.vars.log_sz)) - 1);\n\tif (!vector)\n\t\tgoto no_trig;\n\n\tbitmask = vector;\n\t \n\tfor_each_set_bit(i, &bitmask, (1 << cmd->vars.log_sz))\n\t\tcmd_ent_get(cmd->ent_arr[i]);\n\tvector |= MLX5_TRIGGERED_CMD_COMP;\n\tspin_unlock_irqrestore(&dev->cmd.alloc_lock, flags);\n\n\tmlx5_core_dbg(dev, \"vector 0x%llx\\n\", vector);\n\tmlx5_cmd_comp_handler(dev, vector, true);\n\tfor_each_set_bit(i, &bitmask, (1 << cmd->vars.log_sz))\n\t\tcmd_ent_put(cmd->ent_arr[i]);\n\treturn;\n\nno_trig:\n\tspin_unlock_irqrestore(&dev->cmd.alloc_lock, flags);\n}\n\nvoid mlx5_cmd_flush(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tint i;\n\n\tfor (i = 0; i < cmd->vars.max_reg_cmds; i++) {\n\t\twhile (down_trylock(&cmd->vars.sem)) {\n\t\t\tmlx5_cmd_trigger_completions(dev);\n\t\t\tcond_resched();\n\t\t}\n\t}\n\n\twhile (down_trylock(&cmd->vars.pages_sem)) {\n\t\tmlx5_cmd_trigger_completions(dev);\n\t\tcond_resched();\n\t}\n\n\t \n\tup(&cmd->vars.pages_sem);\n\tfor (i = 0; i < cmd->vars.max_reg_cmds; i++)\n\t\tup(&cmd->vars.sem);\n}\n\nstatic struct mlx5_cmd_msg *alloc_msg(struct mlx5_core_dev *dev, int in_size,\n\t\t\t\t      gfp_t gfp)\n{\n\tstruct mlx5_cmd_msg *msg = ERR_PTR(-ENOMEM);\n\tstruct cmd_msg_cache *ch = NULL;\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tint i;\n\n\tif (in_size <= 16)\n\t\tgoto cache_miss;\n\n\tfor (i = 0; i < dev->profile.num_cmd_caches; i++) {\n\t\tch = &cmd->cache[i];\n\t\tif (in_size > ch->max_inbox_size)\n\t\t\tcontinue;\n\t\tspin_lock_irq(&ch->lock);\n\t\tif (list_empty(&ch->head)) {\n\t\t\tspin_unlock_irq(&ch->lock);\n\t\t\tcontinue;\n\t\t}\n\t\tmsg = list_entry(ch->head.next, typeof(*msg), list);\n\t\t \n\t\tmsg->len = in_size;\n\t\tlist_del(&msg->list);\n\t\tspin_unlock_irq(&ch->lock);\n\t\tbreak;\n\t}\n\n\tif (!IS_ERR(msg))\n\t\treturn msg;\n\ncache_miss:\n\tmsg = mlx5_alloc_cmd_msg(dev, gfp, in_size, 0);\n\treturn msg;\n}\n\nstatic int is_manage_pages(void *in)\n{\n\treturn in_to_opcode(in) == MLX5_CMD_OP_MANAGE_PAGES;\n}\n\n \nstatic int cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,\n\t\t    int out_size, mlx5_cmd_cbk_t callback, void *context,\n\t\t    bool force_polling)\n{\n\tstruct mlx5_cmd_msg *inb, *outb;\n\tu16 opcode = in_to_opcode(in);\n\tbool throttle_op;\n\tint pages_queue;\n\tgfp_t gfp;\n\tu8 token;\n\tint err;\n\n\tif (mlx5_cmd_is_down(dev) || !opcode_allowed(&dev->cmd, opcode))\n\t\treturn -ENXIO;\n\n\tthrottle_op = mlx5_cmd_is_throttle_opcode(opcode);\n\tif (throttle_op) {\n\t\t \n\t\tif (callback)\n\t\t\treturn -EINVAL;\n\t\tdown(&dev->cmd.vars.throttle_sem);\n\t}\n\n\tpages_queue = is_manage_pages(in);\n\tgfp = callback ? GFP_ATOMIC : GFP_KERNEL;\n\n\tinb = alloc_msg(dev, in_size, gfp);\n\tif (IS_ERR(inb)) {\n\t\terr = PTR_ERR(inb);\n\t\tgoto out_up;\n\t}\n\n\ttoken = alloc_token(&dev->cmd);\n\n\terr = mlx5_copy_to_msg(inb, in, in_size, token);\n\tif (err) {\n\t\tmlx5_core_warn(dev, \"err %d\\n\", err);\n\t\tgoto out_in;\n\t}\n\n\toutb = mlx5_alloc_cmd_msg(dev, gfp, out_size, token);\n\tif (IS_ERR(outb)) {\n\t\terr = PTR_ERR(outb);\n\t\tgoto out_in;\n\t}\n\n\terr = mlx5_cmd_invoke(dev, inb, outb, out, out_size, callback, context,\n\t\t\t      pages_queue, token, force_polling);\n\tif (callback)\n\t\treturn err;\n\n\tif (err > 0)  \n\t\terr = deliv_status_to_err(err);\n\n\tif (err)\n\t\tgoto out_out;\n\n\t \n\terr = mlx5_copy_from_msg(out, outb, out_size);\nout_out:\n\tmlx5_free_cmd_msg(dev, outb);\nout_in:\n\tfree_msg(dev, inb);\nout_up:\n\tif (throttle_op)\n\t\tup(&dev->cmd.vars.throttle_sem);\n\treturn err;\n}\n\nstatic void mlx5_cmd_err_trace(struct mlx5_core_dev *dev, u16 opcode, u16 op_mod, void *out)\n{\n\tu32 syndrome = MLX5_GET(mbox_out, out, syndrome);\n\tu8 status = MLX5_GET(mbox_out, out, status);\n\n\ttrace_mlx5_cmd(mlx5_command_str(opcode), opcode, op_mod,\n\t\t       cmd_status_str(status), status, syndrome,\n\t\t       cmd_status_to_err(status));\n}\n\nstatic void cmd_status_log(struct mlx5_core_dev *dev, u16 opcode, u8 status,\n\t\t\t   u32 syndrome, int err)\n{\n\tconst char *namep = mlx5_command_str(opcode);\n\tstruct mlx5_cmd_stats *stats;\n\n\tif (!err || !(strcmp(namep, \"unknown command opcode\")))\n\t\treturn;\n\n\tstats = xa_load(&dev->cmd.stats, opcode);\n\tif (!stats)\n\t\treturn;\n\tspin_lock_irq(&stats->lock);\n\tstats->failed++;\n\tif (err < 0)\n\t\tstats->last_failed_errno = -err;\n\tif (err == -EREMOTEIO) {\n\t\tstats->failed_mbox_status++;\n\t\tstats->last_failed_mbox_status = status;\n\t\tstats->last_failed_syndrome = syndrome;\n\t}\n\tspin_unlock_irq(&stats->lock);\n}\n\n \nstatic int cmd_status_err(struct mlx5_core_dev *dev, int err, u16 opcode, u16 op_mod, void *out)\n{\n\tu32 syndrome = MLX5_GET(mbox_out, out, syndrome);\n\tu8 status = MLX5_GET(mbox_out, out, status);\n\n\tif (err == -EREMOTEIO)  \n\t\terr = -EIO;\n\n\tif (!err && status != MLX5_CMD_STAT_OK) {\n\t\terr = -EREMOTEIO;\n\t\tmlx5_cmd_err_trace(dev, opcode, op_mod, out);\n\t}\n\n\tcmd_status_log(dev, opcode, status, syndrome, err);\n\treturn err;\n}\n\n \nint mlx5_cmd_do(struct mlx5_core_dev *dev, void *in, int in_size, void *out, int out_size)\n{\n\tint err = cmd_exec(dev, in, in_size, out, out_size, NULL, NULL, false);\n\tu16 op_mod = MLX5_GET(mbox_in, in, op_mod);\n\tu16 opcode = in_to_opcode(in);\n\n\treturn cmd_status_err(dev, err, opcode, op_mod, out);\n}\nEXPORT_SYMBOL(mlx5_cmd_do);\n\n \nint mlx5_cmd_exec(struct mlx5_core_dev *dev, void *in, int in_size, void *out,\n\t\t  int out_size)\n{\n\tint err = mlx5_cmd_do(dev, in, in_size, out, out_size);\n\n\treturn mlx5_cmd_check(dev, err, in, out);\n}\nEXPORT_SYMBOL(mlx5_cmd_exec);\n\n \nint mlx5_cmd_exec_polling(struct mlx5_core_dev *dev, void *in, int in_size,\n\t\t\t  void *out, int out_size)\n{\n\tint err = cmd_exec(dev, in, in_size, out, out_size, NULL, NULL, true);\n\tu16 op_mod = MLX5_GET(mbox_in, in, op_mod);\n\tu16 opcode = in_to_opcode(in);\n\n\terr = cmd_status_err(dev, err, opcode, op_mod, out);\n\treturn mlx5_cmd_check(dev, err, in, out);\n}\nEXPORT_SYMBOL(mlx5_cmd_exec_polling);\n\nvoid mlx5_cmd_init_async_ctx(struct mlx5_core_dev *dev,\n\t\t\t     struct mlx5_async_ctx *ctx)\n{\n\tctx->dev = dev;\n\t \n\tatomic_set(&ctx->num_inflight, 1);\n\tinit_completion(&ctx->inflight_done);\n}\nEXPORT_SYMBOL(mlx5_cmd_init_async_ctx);\n\n \nvoid mlx5_cmd_cleanup_async_ctx(struct mlx5_async_ctx *ctx)\n{\n\tif (!atomic_dec_and_test(&ctx->num_inflight))\n\t\twait_for_completion(&ctx->inflight_done);\n}\nEXPORT_SYMBOL(mlx5_cmd_cleanup_async_ctx);\n\nstatic void mlx5_cmd_exec_cb_handler(int status, void *_work)\n{\n\tstruct mlx5_async_work *work = _work;\n\tstruct mlx5_async_ctx *ctx;\n\n\tctx = work->ctx;\n\tstatus = cmd_status_err(ctx->dev, status, work->opcode, work->op_mod, work->out);\n\twork->user_callback(status, work);\n\tif (atomic_dec_and_test(&ctx->num_inflight))\n\t\tcomplete(&ctx->inflight_done);\n}\n\nint mlx5_cmd_exec_cb(struct mlx5_async_ctx *ctx, void *in, int in_size,\n\t\t     void *out, int out_size, mlx5_async_cbk_t callback,\n\t\t     struct mlx5_async_work *work)\n{\n\tint ret;\n\n\twork->ctx = ctx;\n\twork->user_callback = callback;\n\twork->opcode = in_to_opcode(in);\n\twork->op_mod = MLX5_GET(mbox_in, in, op_mod);\n\twork->out = out;\n\tif (WARN_ON(!atomic_inc_not_zero(&ctx->num_inflight)))\n\t\treturn -EIO;\n\tret = cmd_exec(ctx->dev, in, in_size, out, out_size,\n\t\t       mlx5_cmd_exec_cb_handler, work, false);\n\tif (ret && atomic_dec_and_test(&ctx->num_inflight))\n\t\tcomplete(&ctx->inflight_done);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(mlx5_cmd_exec_cb);\n\nstatic void destroy_msg_cache(struct mlx5_core_dev *dev)\n{\n\tstruct cmd_msg_cache *ch;\n\tstruct mlx5_cmd_msg *msg;\n\tstruct mlx5_cmd_msg *n;\n\tint i;\n\n\tfor (i = 0; i < dev->profile.num_cmd_caches; i++) {\n\t\tch = &dev->cmd.cache[i];\n\t\tlist_for_each_entry_safe(msg, n, &ch->head, list) {\n\t\t\tlist_del(&msg->list);\n\t\t\tmlx5_free_cmd_msg(dev, msg);\n\t\t}\n\t}\n}\n\nstatic unsigned cmd_cache_num_ent[MLX5_NUM_COMMAND_CACHES] = {\n\t512, 32, 16, 8, 2\n};\n\nstatic unsigned cmd_cache_ent_size[MLX5_NUM_COMMAND_CACHES] = {\n\t16 + MLX5_CMD_DATA_BLOCK_SIZE,\n\t16 + MLX5_CMD_DATA_BLOCK_SIZE * 2,\n\t16 + MLX5_CMD_DATA_BLOCK_SIZE * 16,\n\t16 + MLX5_CMD_DATA_BLOCK_SIZE * 256,\n\t16 + MLX5_CMD_DATA_BLOCK_SIZE * 512,\n};\n\nstatic void create_msg_cache(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tstruct cmd_msg_cache *ch;\n\tstruct mlx5_cmd_msg *msg;\n\tint i;\n\tint k;\n\n\t \n\tfor (k = 0; k < dev->profile.num_cmd_caches; k++) {\n\t\tch = &cmd->cache[k];\n\t\tspin_lock_init(&ch->lock);\n\t\tINIT_LIST_HEAD(&ch->head);\n\t\tch->num_ent = cmd_cache_num_ent[k];\n\t\tch->max_inbox_size = cmd_cache_ent_size[k];\n\t\tfor (i = 0; i < ch->num_ent; i++) {\n\t\t\tmsg = mlx5_alloc_cmd_msg(dev, GFP_KERNEL | __GFP_NOWARN,\n\t\t\t\t\t\t ch->max_inbox_size, 0);\n\t\t\tif (IS_ERR(msg))\n\t\t\t\tbreak;\n\t\t\tmsg->parent = ch;\n\t\t\tlist_add_tail(&msg->list, &ch->head);\n\t\t}\n\t}\n}\n\nstatic int alloc_cmd_page(struct mlx5_core_dev *dev, struct mlx5_cmd *cmd)\n{\n\tcmd->cmd_alloc_buf = dma_alloc_coherent(mlx5_core_dma_dev(dev), MLX5_ADAPTER_PAGE_SIZE,\n\t\t\t\t\t\t&cmd->alloc_dma, GFP_KERNEL);\n\tif (!cmd->cmd_alloc_buf)\n\t\treturn -ENOMEM;\n\n\t \n\tif (!((uintptr_t)cmd->cmd_alloc_buf & (MLX5_ADAPTER_PAGE_SIZE - 1))) {\n\t\tcmd->cmd_buf = cmd->cmd_alloc_buf;\n\t\tcmd->dma = cmd->alloc_dma;\n\t\tcmd->alloc_size = MLX5_ADAPTER_PAGE_SIZE;\n\t\treturn 0;\n\t}\n\n\tdma_free_coherent(mlx5_core_dma_dev(dev), MLX5_ADAPTER_PAGE_SIZE, cmd->cmd_alloc_buf,\n\t\t\t  cmd->alloc_dma);\n\tcmd->cmd_alloc_buf = dma_alloc_coherent(mlx5_core_dma_dev(dev),\n\t\t\t\t\t\t2 * MLX5_ADAPTER_PAGE_SIZE - 1,\n\t\t\t\t\t\t&cmd->alloc_dma, GFP_KERNEL);\n\tif (!cmd->cmd_alloc_buf)\n\t\treturn -ENOMEM;\n\n\tcmd->cmd_buf = PTR_ALIGN(cmd->cmd_alloc_buf, MLX5_ADAPTER_PAGE_SIZE);\n\tcmd->dma = ALIGN(cmd->alloc_dma, MLX5_ADAPTER_PAGE_SIZE);\n\tcmd->alloc_size = 2 * MLX5_ADAPTER_PAGE_SIZE - 1;\n\treturn 0;\n}\n\nstatic void free_cmd_page(struct mlx5_core_dev *dev, struct mlx5_cmd *cmd)\n{\n\tdma_free_coherent(mlx5_core_dma_dev(dev), cmd->alloc_size, cmd->cmd_alloc_buf,\n\t\t\t  cmd->alloc_dma);\n}\n\nstatic u16 cmdif_rev(struct mlx5_core_dev *dev)\n{\n\treturn ioread32be(&dev->iseg->cmdif_rev_fw_sub) >> 16;\n}\n\nint mlx5_cmd_init(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\n\tcmd->checksum_disabled = 1;\n\n\tspin_lock_init(&cmd->alloc_lock);\n\tspin_lock_init(&cmd->token_lock);\n\n\tset_wqname(dev);\n\tcmd->wq = create_singlethread_workqueue(cmd->wq_name);\n\tif (!cmd->wq) {\n\t\tmlx5_core_err(dev, \"failed to create command workqueue\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmlx5_cmdif_debugfs_init(dev);\n\n\treturn 0;\n}\n\nvoid mlx5_cmd_cleanup(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\n\tmlx5_cmdif_debugfs_cleanup(dev);\n\tdestroy_workqueue(cmd->wq);\n}\n\nint mlx5_cmd_enable(struct mlx5_core_dev *dev)\n{\n\tint size = sizeof(struct mlx5_cmd_prot_block);\n\tint align = roundup_pow_of_two(size);\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\tu32 cmd_h, cmd_l;\n\tint err;\n\n\tmemset(&cmd->vars, 0, sizeof(cmd->vars));\n\tcmd->vars.cmdif_rev = cmdif_rev(dev);\n\tif (cmd->vars.cmdif_rev != CMD_IF_REV) {\n\t\tmlx5_core_err(dev,\n\t\t\t      \"Driver cmdif rev(%d) differs from firmware's(%d)\\n\",\n\t\t\t      CMD_IF_REV, cmd->vars.cmdif_rev);\n\t\treturn -EINVAL;\n\t}\n\n\tcmd_l = ioread32be(&dev->iseg->cmdq_addr_l_sz) & 0xff;\n\tcmd->vars.log_sz = cmd_l >> 4 & 0xf;\n\tcmd->vars.log_stride = cmd_l & 0xf;\n\tif (1 << cmd->vars.log_sz > MLX5_MAX_COMMANDS) {\n\t\tmlx5_core_err(dev, \"firmware reports too many outstanding commands %d\\n\",\n\t\t\t      1 << cmd->vars.log_sz);\n\t\treturn -EINVAL;\n\t}\n\n\tif (cmd->vars.log_sz + cmd->vars.log_stride > MLX5_ADAPTER_PAGE_SHIFT) {\n\t\tmlx5_core_err(dev, \"command queue size overflow\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tcmd->state = MLX5_CMDIF_STATE_DOWN;\n\tcmd->vars.max_reg_cmds = (1 << cmd->vars.log_sz) - 1;\n\tcmd->vars.bitmask = (1UL << cmd->vars.max_reg_cmds) - 1;\n\n\tsema_init(&cmd->vars.sem, cmd->vars.max_reg_cmds);\n\tsema_init(&cmd->vars.pages_sem, 1);\n\tsema_init(&cmd->vars.throttle_sem, DIV_ROUND_UP(cmd->vars.max_reg_cmds, 2));\n\n\tcmd->pool = dma_pool_create(\"mlx5_cmd\", mlx5_core_dma_dev(dev), size, align, 0);\n\tif (!cmd->pool)\n\t\treturn -ENOMEM;\n\n\terr = alloc_cmd_page(dev, cmd);\n\tif (err)\n\t\tgoto err_free_pool;\n\n\tcmd_h = (u32)((u64)(cmd->dma) >> 32);\n\tcmd_l = (u32)(cmd->dma);\n\tif (cmd_l & 0xfff) {\n\t\tmlx5_core_err(dev, \"invalid command queue address\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_cmd_page;\n\t}\n\n\tiowrite32be(cmd_h, &dev->iseg->cmdq_addr_h);\n\tiowrite32be(cmd_l, &dev->iseg->cmdq_addr_l_sz);\n\n\t \n\twmb();\n\n\tmlx5_core_dbg(dev, \"descriptor at dma 0x%llx\\n\", (unsigned long long)(cmd->dma));\n\n\tcmd->mode = CMD_MODE_POLLING;\n\tcmd->allowed_opcode = CMD_ALLOWED_OPCODE_ALL;\n\n\tcreate_msg_cache(dev);\n\tcreate_debugfs_files(dev);\n\n\treturn 0;\n\nerr_cmd_page:\n\tfree_cmd_page(dev, cmd);\nerr_free_pool:\n\tdma_pool_destroy(cmd->pool);\n\treturn err;\n}\n\nvoid mlx5_cmd_disable(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_cmd *cmd = &dev->cmd;\n\n\tflush_workqueue(cmd->wq);\n\tclean_debug_files(dev);\n\tdestroy_msg_cache(dev);\n\tfree_cmd_page(dev, cmd);\n\tdma_pool_destroy(cmd->pool);\n}\n\nvoid mlx5_cmd_set_state(struct mlx5_core_dev *dev,\n\t\t\tenum mlx5_cmdif_state cmdif_state)\n{\n\tdev->cmd.state = cmdif_state;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}