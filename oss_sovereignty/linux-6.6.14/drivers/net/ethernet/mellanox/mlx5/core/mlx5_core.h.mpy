{
  "module_name": "mlx5_core.h",
  "hash_id": "ed56aa01967a392fe50533d9cc865fd0775649f4f6be1f310e3fd083966dfce8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h",
  "human_readable_source": " \n\n#ifndef __MLX5_CORE_H__\n#define __MLX5_CORE_H__\n\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <linux/if_link.h>\n#include <linux/firmware.h>\n#include <linux/mlx5/cq.h>\n#include <linux/mlx5/fs.h>\n#include <linux/mlx5/driver.h>\n\nextern uint mlx5_core_debug_mask;\n\n#define mlx5_core_dbg(__dev, format, ...)\t\t\t\t\\\n\tdev_dbg((__dev)->device, \"%s:%d:(pid %d): \" format,\t\t\\\n\t\t __func__, __LINE__, current->pid,\t\t\t\\\n\t\t ##__VA_ARGS__)\n\n#define mlx5_core_dbg_once(__dev, format, ...)\t\t\\\n\tdev_dbg_once((__dev)->device,\t\t\\\n\t\t     \"%s:%d:(pid %d): \" format,\t\t\\\n\t\t     __func__, __LINE__, current->pid,\t\\\n\t\t     ##__VA_ARGS__)\n\n#define mlx5_core_dbg_mask(__dev, mask, format, ...)\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\tif ((mask) & mlx5_core_debug_mask)\t\t\t\\\n\t\tmlx5_core_dbg(__dev, format, ##__VA_ARGS__);\t\\\n} while (0)\n\n#define mlx5_core_err(__dev, format, ...)\t\t\t\\\n\tdev_err((__dev)->device, \"%s:%d:(pid %d): \" format,\t\\\n\t\t__func__, __LINE__, current->pid,\t\t\\\n\t       ##__VA_ARGS__)\n\n#define mlx5_core_err_rl(__dev, format, ...)\t\t\t\\\n\tdev_err_ratelimited((__dev)->device,\t\t\t\\\n\t\t\t    \"%s:%d:(pid %d): \" format,\t\t\\\n\t\t\t    __func__, __LINE__, current->pid,\t\\\n\t\t\t    ##__VA_ARGS__)\n\n#define mlx5_core_warn(__dev, format, ...)\t\t\t\\\n\tdev_warn((__dev)->device, \"%s:%d:(pid %d): \" format,\t\\\n\t\t __func__, __LINE__, current->pid,\t\t\\\n\t\t ##__VA_ARGS__)\n\n#define mlx5_core_warn_once(__dev, format, ...)\t\t\t\t\\\n\tdev_warn_once((__dev)->device, \"%s:%d:(pid %d): \" format,\t\\\n\t\t      __func__, __LINE__, current->pid,\t\t\t\\\n\t\t      ##__VA_ARGS__)\n\n#define mlx5_core_warn_rl(__dev, format, ...)\t\t\t\\\n\tdev_warn_ratelimited((__dev)->device,\t\t\t\\\n\t\t\t     \"%s:%d:(pid %d): \" format,\t\t\\\n\t\t\t     __func__, __LINE__, current->pid,\t\\\n\t\t\t     ##__VA_ARGS__)\n\n#define mlx5_core_info(__dev, format, ...)\t\t\\\n\tdev_info((__dev)->device, format, ##__VA_ARGS__)\n\n#define mlx5_core_info_rl(__dev, format, ...)\t\t\t\\\n\tdev_info_ratelimited((__dev)->device,\t\t\t\\\n\t\t\t     \"%s:%d:(pid %d): \" format,\t\t\\\n\t\t\t     __func__, __LINE__, current->pid,\t\\\n\t\t\t     ##__VA_ARGS__)\n\nstatic inline void mlx5_printk(struct mlx5_core_dev *dev, int level, const char *format, ...)\n{\n\tstruct device *device = dev->device;\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (WARN_ONCE(level < LOGLEVEL_EMERG || level > LOGLEVEL_DEBUG,\n\t\t      \"Level %d is out of range, set to default level\\n\", level))\n\t\tlevel = LOGLEVEL_DEFAULT;\n\n\tva_start(args, format);\n\tvaf.fmt = format;\n\tvaf.va = &args;\n\n\tdev_printk_emit(level, device, \"%s %s: %pV\", dev_driver_string(device), dev_name(device),\n\t\t\t&vaf);\n\tva_end(args);\n}\n\n#define mlx5_log(__dev, level, format, ...)\t\t\t\\\n\tmlx5_printk(__dev, level, \"%s:%d:(pid %d): \" format,\t\\\n\t\t    __func__, __LINE__, current->pid,\t\t\\\n\t\t    ##__VA_ARGS__)\n\nstatic inline struct device *mlx5_core_dma_dev(struct mlx5_core_dev *dev)\n{\n\treturn &dev->pdev->dev;\n}\n\nenum {\n\tMLX5_CMD_DATA,  \n\tMLX5_CMD_TIME,  \n};\n\nenum {\n\tMLX5_DRIVER_STATUS_ABORTED = 0xfe,\n\tMLX5_DRIVER_SYND = 0xbadd00de,\n};\n\nenum mlx5_semaphore_space_address {\n\tMLX5_SEMAPHORE_SPACE_DOMAIN     = 0xA,\n\tMLX5_SEMAPHORE_SW_RESET         = 0x20,\n};\n\n#define MLX5_DEFAULT_PROF       2\n#define MLX5_SF_PROF\t\t3\n\nstatic inline int mlx5_flexible_inlen(struct mlx5_core_dev *dev, size_t fixed,\n\t\t\t\t      size_t item_size, size_t num_items,\n\t\t\t\t      const char *func, int line)\n{\n\tint inlen;\n\n\tif (fixed > INT_MAX || item_size > INT_MAX || num_items > INT_MAX) {\n\t\tmlx5_core_err(dev, \"%s: %s:%d: input values too big: %zu + %zu * %zu\\n\",\n\t\t\t      __func__, func, line, fixed, item_size, num_items);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (check_mul_overflow((int)item_size, (int)num_items, &inlen)) {\n\t\tmlx5_core_err(dev, \"%s: %s:%d: multiplication overflow: %zu + %zu * %zu\\n\",\n\t\t\t      __func__, func, line, fixed, item_size, num_items);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (check_add_overflow((int)fixed, inlen, &inlen)) {\n\t\tmlx5_core_err(dev, \"%s: %s:%d: addition overflow: %zu + %zu * %zu\\n\",\n\t\t\t      __func__, func, line, fixed, item_size, num_items);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn inlen;\n}\n\n#define MLX5_FLEXIBLE_INLEN(dev, fixed, item_size, num_items) \\\n\tmlx5_flexible_inlen(dev, fixed, item_size, num_items, __func__, __LINE__)\n\nint mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type);\nint mlx5_core_get_caps_mode(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type,\n\t\t\t    enum mlx5_cap_mode cap_mode);\nint mlx5_query_hca_caps(struct mlx5_core_dev *dev);\nint mlx5_query_board_id(struct mlx5_core_dev *dev);\nint mlx5_query_module_num(struct mlx5_core_dev *dev, int *module_num);\nint mlx5_cmd_init(struct mlx5_core_dev *dev);\nvoid mlx5_cmd_cleanup(struct mlx5_core_dev *dev);\nint mlx5_cmd_enable(struct mlx5_core_dev *dev);\nvoid mlx5_cmd_disable(struct mlx5_core_dev *dev);\nvoid mlx5_cmd_set_state(struct mlx5_core_dev *dev,\n\t\t\tenum mlx5_cmdif_state cmdif_state);\nint mlx5_cmd_init_hca(struct mlx5_core_dev *dev, uint32_t *sw_owner_id);\nint mlx5_cmd_teardown_hca(struct mlx5_core_dev *dev);\nint mlx5_cmd_force_teardown_hca(struct mlx5_core_dev *dev);\nint mlx5_cmd_fast_teardown_hca(struct mlx5_core_dev *dev);\nvoid mlx5_enter_error_state(struct mlx5_core_dev *dev, bool force);\nvoid mlx5_error_sw_reset(struct mlx5_core_dev *dev);\nu32 mlx5_health_check_fatal_sensors(struct mlx5_core_dev *dev);\nint mlx5_health_wait_pci_up(struct mlx5_core_dev *dev);\nvoid mlx5_disable_device(struct mlx5_core_dev *dev);\nint mlx5_recover_device(struct mlx5_core_dev *dev);\nint mlx5_sriov_init(struct mlx5_core_dev *dev);\nvoid mlx5_sriov_cleanup(struct mlx5_core_dev *dev);\nint mlx5_sriov_attach(struct mlx5_core_dev *dev);\nvoid mlx5_sriov_detach(struct mlx5_core_dev *dev);\nint mlx5_core_sriov_configure(struct pci_dev *dev, int num_vfs);\nvoid mlx5_sriov_disable(struct pci_dev *pdev, bool num_vf_change);\nint mlx5_core_sriov_set_msix_vec_count(struct pci_dev *vf, int msix_vec_count);\nint mlx5_core_enable_hca(struct mlx5_core_dev *dev, u16 func_id);\nint mlx5_core_disable_hca(struct mlx5_core_dev *dev, u16 func_id);\nint mlx5_create_scheduling_element_cmd(struct mlx5_core_dev *dev, u8 hierarchy,\n\t\t\t\t       void *context, u32 *element_id);\nint mlx5_modify_scheduling_element_cmd(struct mlx5_core_dev *dev, u8 hierarchy,\n\t\t\t\t       void *context, u32 element_id,\n\t\t\t\t       u32 modify_bitmask);\nint mlx5_destroy_scheduling_element_cmd(struct mlx5_core_dev *dev, u8 hierarchy,\n\t\t\t\t\tu32 element_id);\nint mlx5_wait_for_pages(struct mlx5_core_dev *dev, int *pages);\n\nvoid mlx5_cmd_flush(struct mlx5_core_dev *dev);\nvoid mlx5_cq_debugfs_init(struct mlx5_core_dev *dev);\nvoid mlx5_cq_debugfs_cleanup(struct mlx5_core_dev *dev);\n\nint mlx5_query_pcam_reg(struct mlx5_core_dev *dev, u32 *pcam, u8 feature_group,\n\t\t\tu8 access_reg_group);\nint mlx5_query_mcam_reg(struct mlx5_core_dev *dev, u32 *mcap, u8 feature_group,\n\t\t\tu8 access_reg_group);\nint mlx5_query_qcam_reg(struct mlx5_core_dev *mdev, u32 *qcam,\n\t\t\tu8 feature_group, u8 access_reg_group);\n\nvoid mlx5_lag_add_netdev(struct mlx5_core_dev *dev, struct net_device *netdev);\nvoid mlx5_lag_remove_netdev(struct mlx5_core_dev *dev, struct net_device *netdev);\nvoid mlx5_lag_add_mdev(struct mlx5_core_dev *dev);\nvoid mlx5_lag_remove_mdev(struct mlx5_core_dev *dev);\nvoid mlx5_lag_disable_change(struct mlx5_core_dev *dev);\nvoid mlx5_lag_enable_change(struct mlx5_core_dev *dev);\n\nint mlx5_events_init(struct mlx5_core_dev *dev);\nvoid mlx5_events_cleanup(struct mlx5_core_dev *dev);\nvoid mlx5_events_start(struct mlx5_core_dev *dev);\nvoid mlx5_events_stop(struct mlx5_core_dev *dev);\n\nint mlx5_adev_idx_alloc(void);\nvoid mlx5_adev_idx_free(int idx);\nvoid mlx5_adev_cleanup(struct mlx5_core_dev *dev);\nint mlx5_adev_init(struct mlx5_core_dev *dev);\n\nint mlx5_attach_device(struct mlx5_core_dev *dev);\nvoid mlx5_detach_device(struct mlx5_core_dev *dev, bool suspend);\nint mlx5_register_device(struct mlx5_core_dev *dev);\nvoid mlx5_unregister_device(struct mlx5_core_dev *dev);\nvoid mlx5_dev_set_lightweight(struct mlx5_core_dev *dev);\nbool mlx5_dev_is_lightweight(struct mlx5_core_dev *dev);\nstruct mlx5_core_dev *mlx5_get_next_phys_dev_lag(struct mlx5_core_dev *dev);\nvoid mlx5_dev_list_lock(void);\nvoid mlx5_dev_list_unlock(void);\nint mlx5_dev_list_trylock(void);\n\nvoid mlx5_fw_reporters_create(struct mlx5_core_dev *dev);\nint mlx5_query_mtpps(struct mlx5_core_dev *dev, u32 *mtpps, u32 mtpps_size);\nint mlx5_set_mtpps(struct mlx5_core_dev *mdev, u32 *mtpps, u32 mtpps_size);\nint mlx5_query_mtppse(struct mlx5_core_dev *mdev, u8 pin, u8 *arm, u8 *mode);\nint mlx5_set_mtppse(struct mlx5_core_dev *mdev, u8 pin, u8 arm, u8 mode);\n\nstruct mlx5_dm *mlx5_dm_create(struct mlx5_core_dev *dev);\nvoid mlx5_dm_cleanup(struct mlx5_core_dev *dev);\n\n#define MLX5_PPS_CAP(mdev) (MLX5_CAP_GEN((mdev), pps) &&\t\t\\\n\t\t\t    MLX5_CAP_GEN((mdev), pps_modify) &&\t\t\\\n\t\t\t    MLX5_CAP_MCAM_FEATURE((mdev), mtpps_fs) &&\t\\\n\t\t\t    MLX5_CAP_MCAM_FEATURE((mdev), mtpps_enh_out_per_adj))\n\nint mlx5_firmware_flash(struct mlx5_core_dev *dev, const struct firmware *fw,\n\t\t\tstruct netlink_ext_ack *extack);\nint mlx5_fw_version_query(struct mlx5_core_dev *dev,\n\t\t\t  u32 *running_ver, u32 *stored_ver);\n\n#ifdef CONFIG_MLX5_CORE_EN\nint mlx5e_init(void);\nvoid mlx5e_cleanup(void);\n#else\nstatic inline int mlx5e_init(void){ return 0; }\nstatic inline void mlx5e_cleanup(void){}\n#endif\n\nstatic inline bool mlx5_sriov_is_enabled(struct mlx5_core_dev *dev)\n{\n\treturn pci_num_vf(dev->pdev) ? true : false;\n}\n\nint mlx5_rescan_drivers_locked(struct mlx5_core_dev *dev);\nstatic inline int mlx5_rescan_drivers(struct mlx5_core_dev *dev)\n{\n\tint ret;\n\n\tmlx5_dev_list_lock();\n\tret = mlx5_rescan_drivers_locked(dev);\n\tmlx5_dev_list_unlock();\n\treturn ret;\n}\n\nvoid mlx5_lag_update(struct mlx5_core_dev *dev);\n\nenum {\n\tMLX5_NIC_IFC_FULL\t\t= 0,\n\tMLX5_NIC_IFC_DISABLED\t\t= 1,\n\tMLX5_NIC_IFC_NO_DRAM_NIC\t= 2,\n\tMLX5_NIC_IFC_SW_RESET\t\t= 7\n};\n\nu8 mlx5_get_nic_state(struct mlx5_core_dev *dev);\nvoid mlx5_set_nic_state(struct mlx5_core_dev *dev, u8 state);\n\nstatic inline bool mlx5_core_is_sf(const struct mlx5_core_dev *dev)\n{\n\treturn dev->coredev_type == MLX5_COREDEV_SF;\n}\n\nint mlx5_mdev_init(struct mlx5_core_dev *dev, int profile_idx);\nvoid mlx5_mdev_uninit(struct mlx5_core_dev *dev);\nint mlx5_init_one(struct mlx5_core_dev *dev);\nint mlx5_init_one_devl_locked(struct mlx5_core_dev *dev);\nvoid mlx5_uninit_one(struct mlx5_core_dev *dev);\nvoid mlx5_unload_one(struct mlx5_core_dev *dev, bool suspend);\nvoid mlx5_unload_one_devl_locked(struct mlx5_core_dev *dev, bool suspend);\nint mlx5_load_one(struct mlx5_core_dev *dev, bool recovery);\nint mlx5_load_one_devl_locked(struct mlx5_core_dev *dev, bool recovery);\nint mlx5_init_one_light(struct mlx5_core_dev *dev);\nvoid mlx5_uninit_one_light(struct mlx5_core_dev *dev);\nvoid mlx5_unload_one_light(struct mlx5_core_dev *dev);\n\nint mlx5_vport_set_other_func_cap(struct mlx5_core_dev *dev, const void *hca_cap, u16 vport,\n\t\t\t\t  u16 opmod);\n#define mlx5_vport_get_other_func_general_cap(dev, vport, out)\t\t\\\n\tmlx5_vport_get_other_func_cap(dev, vport, out, MLX5_CAP_GENERAL)\n\nvoid mlx5_events_work_enqueue(struct mlx5_core_dev *dev, struct work_struct *work);\nstatic inline u32 mlx5_sriov_get_vf_total_msix(struct pci_dev *pdev)\n{\n\tstruct mlx5_core_dev *dev = pci_get_drvdata(pdev);\n\n\treturn MLX5_CAP_GEN_MAX(dev, num_total_dynamic_vf_msix);\n}\n\nbool mlx5_eth_supported(struct mlx5_core_dev *dev);\nbool mlx5_rdma_supported(struct mlx5_core_dev *dev);\nbool mlx5_vnet_supported(struct mlx5_core_dev *dev);\nbool mlx5_same_hw_devs(struct mlx5_core_dev *dev, struct mlx5_core_dev *peer_dev);\n\nstatic inline u16 mlx5_core_ec_vf_vport_base(const struct mlx5_core_dev *dev)\n{\n\treturn MLX5_CAP_GEN_2(dev, ec_vf_vport_base);\n}\n\nstatic inline u16 mlx5_core_ec_sriov_enabled(const struct mlx5_core_dev *dev)\n{\n\treturn mlx5_core_is_ecpf(dev) && mlx5_core_ec_vf_vport_base(dev);\n}\n\nstatic inline bool mlx5_core_is_ec_vf_vport(const struct mlx5_core_dev *dev, u16 vport_num)\n{\n\tint base_vport = mlx5_core_ec_vf_vport_base(dev);\n\tint max_vport = base_vport + mlx5_core_max_ec_vfs(dev);\n\n\tif (!mlx5_core_ec_sriov_enabled(dev))\n\t\treturn false;\n\n\treturn (vport_num >= base_vport && vport_num < max_vport);\n}\n\nstatic inline int mlx5_vport_to_func_id(const struct mlx5_core_dev *dev, u16 vport, bool ec_vf_func)\n{\n\treturn ec_vf_func ? vport - mlx5_core_ec_vf_vport_base(dev) + 1\n\t\t\t  : vport;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}