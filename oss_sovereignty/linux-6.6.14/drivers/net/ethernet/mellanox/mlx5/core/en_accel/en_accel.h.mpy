{
  "module_name": "en_accel.h",
  "hash_id": "1aea3d82054d6eed5cdd848c5dcae2734f2d30c8a1da70715f376f42769d4e02",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en_accel/en_accel.h",
  "human_readable_source": " \n\n#ifndef __MLX5E_EN_ACCEL_H__\n#define __MLX5E_EN_ACCEL_H__\n\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include \"en_accel/ipsec_rxtx.h\"\n#include \"en_accel/ktls.h\"\n#include \"en_accel/ktls_txrx.h\"\n#include <en_accel/macsec.h>\n#include \"en.h\"\n#include \"en/txrx.h\"\n\n#if IS_ENABLED(CONFIG_GENEVE)\n#include <net/geneve.h>\n\nstatic inline bool mlx5_geneve_tx_allowed(struct mlx5_core_dev *mdev)\n{\n\treturn mlx5_tx_swp_supported(mdev);\n}\n\nstatic inline void\nmlx5e_tx_tunnel_accel(struct sk_buff *skb, struct mlx5_wqe_eth_seg *eseg, u16 ihs)\n{\n\tstruct mlx5e_swp_spec swp_spec = {};\n\tunsigned int offset = 0;\n\t__be16 l3_proto;\n\tu8 l4_proto;\n\n\tl3_proto = vlan_get_protocol(skb);\n\tswitch (l3_proto) {\n\tcase htons(ETH_P_IP):\n\t\tl4_proto = ip_hdr(skb)->protocol;\n\t\tbreak;\n\tcase htons(ETH_P_IPV6):\n\t\tl4_proto = ipv6_find_hdr(skb, &offset, -1, NULL, NULL);\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\tif (l4_proto != IPPROTO_UDP ||\n\t    udp_hdr(skb)->dest != cpu_to_be16(GENEVE_UDP_PORT))\n\t\treturn;\n\tswp_spec.l3_proto = l3_proto;\n\tswp_spec.l4_proto = l4_proto;\n\tswp_spec.is_tun = true;\n\tif (inner_ip_hdr(skb)->version == 6) {\n\t\tswp_spec.tun_l3_proto = htons(ETH_P_IPV6);\n\t\tswp_spec.tun_l4_proto = inner_ipv6_hdr(skb)->nexthdr;\n\t} else {\n\t\tswp_spec.tun_l3_proto = htons(ETH_P_IP);\n\t\tswp_spec.tun_l4_proto = inner_ip_hdr(skb)->protocol;\n\t}\n\n\tmlx5e_set_eseg_swp(skb, eseg, &swp_spec);\n\tif (skb_vlan_tag_present(skb) && ihs)\n\t\tmlx5e_eseg_swp_offsets_add_vlan(eseg);\n}\n\n#else\nstatic inline bool mlx5_geneve_tx_allowed(struct mlx5_core_dev *mdev)\n{\n\treturn false;\n}\n\n#endif  \n\nstatic inline void\nmlx5e_udp_gso_handle_tx_skb(struct sk_buff *skb)\n{\n\tint payload_len = skb_shinfo(skb)->gso_size + sizeof(struct udphdr);\n\n\tudp_hdr(skb)->len = htons(payload_len);\n}\n\nstruct mlx5e_accel_tx_state {\n#ifdef CONFIG_MLX5_EN_TLS\n\tstruct mlx5e_accel_tx_tls_state tls;\n#endif\n#ifdef CONFIG_MLX5_EN_IPSEC\n\tstruct mlx5e_accel_tx_ipsec_state ipsec;\n#endif\n};\n\nstatic inline bool mlx5e_accel_tx_begin(struct net_device *dev,\n\t\t\t\t\tstruct mlx5e_txqsq *sq,\n\t\t\t\t\tstruct sk_buff *skb,\n\t\t\t\t\tstruct mlx5e_accel_tx_state *state)\n{\n\tif (skb_is_gso(skb) && skb_shinfo(skb)->gso_type & SKB_GSO_UDP_L4)\n\t\tmlx5e_udp_gso_handle_tx_skb(skb);\n\n#ifdef CONFIG_MLX5_EN_TLS\n\t \n\tif (tls_is_skb_tx_device_offloaded(skb))\n\t\tif (unlikely(!mlx5e_ktls_handle_tx_skb(dev, sq, skb,\n\t\t\t\t\t\t       &state->tls)))\n\t\t\treturn false;\n#endif\n\n#ifdef CONFIG_MLX5_EN_IPSEC\n\tif (test_bit(MLX5E_SQ_STATE_IPSEC, &sq->state) && xfrm_offload(skb)) {\n\t\tif (unlikely(!mlx5e_ipsec_handle_tx_skb(dev, skb, &state->ipsec)))\n\t\t\treturn false;\n\t}\n#endif\n\n#ifdef CONFIG_MLX5_MACSEC\n\tif (unlikely(mlx5e_macsec_skb_is_offload(skb))) {\n\t\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\t\tif (unlikely(!mlx5e_macsec_handle_tx_skb(priv->macsec, skb)))\n\t\t\treturn false;\n\t}\n#endif\n\n\treturn true;\n}\n\nstatic inline unsigned int mlx5e_accel_tx_ids_len(struct mlx5e_txqsq *sq,\n\t\t\t\t\t\t  struct mlx5e_accel_tx_state *state)\n{\n#ifdef CONFIG_MLX5_EN_IPSEC\n\tif (test_bit(MLX5E_SQ_STATE_IPSEC, &sq->state))\n\t\treturn mlx5e_ipsec_tx_ids_len(&state->ipsec);\n#endif\n\n\treturn 0;\n}\n\n \n#define MLX5E_ACCEL_ESEG_LEN offsetof(struct mlx5_wqe_eth_seg, mss)\n\nstatic inline void mlx5e_accel_tx_eseg(struct mlx5e_priv *priv,\n\t\t\t\t       struct sk_buff *skb,\n\t\t\t\t       struct mlx5_wqe_eth_seg *eseg, u16 ihs)\n{\n#ifdef CONFIG_MLX5_EN_IPSEC\n\tif (xfrm_offload(skb))\n\t\tmlx5e_ipsec_tx_build_eseg(priv, skb, eseg);\n#endif\n\n#ifdef CONFIG_MLX5_MACSEC\n\tif (unlikely(mlx5e_macsec_skb_is_offload(skb)))\n\t\tmlx5e_macsec_tx_build_eseg(priv->macsec, skb, eseg);\n#endif\n\n#if IS_ENABLED(CONFIG_GENEVE)\n\tif (skb->encapsulation && skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tmlx5e_tx_tunnel_accel(skb, eseg, ihs);\n#endif\n}\n\nstatic inline void mlx5e_accel_tx_finish(struct mlx5e_txqsq *sq,\n\t\t\t\t\t struct mlx5e_tx_wqe *wqe,\n\t\t\t\t\t struct mlx5e_accel_tx_state *state,\n\t\t\t\t\t struct mlx5_wqe_inline_seg *inlseg)\n{\n#ifdef CONFIG_MLX5_EN_TLS\n\tmlx5e_ktls_handle_tx_wqe(&wqe->ctrl, &state->tls);\n#endif\n\n#ifdef CONFIG_MLX5_EN_IPSEC\n\tif (test_bit(MLX5E_SQ_STATE_IPSEC, &sq->state) &&\n\t    state->ipsec.xo && state->ipsec.tailen)\n\t\tmlx5e_ipsec_handle_tx_wqe(wqe, &state->ipsec, inlseg);\n#endif\n}\n\nstatic inline int mlx5e_accel_init_rx(struct mlx5e_priv *priv)\n{\n\treturn mlx5e_ktls_init_rx(priv);\n}\n\nstatic inline void mlx5e_accel_cleanup_rx(struct mlx5e_priv *priv)\n{\n\tmlx5e_ktls_cleanup_rx(priv);\n}\n\nstatic inline int mlx5e_accel_init_tx(struct mlx5e_priv *priv)\n{\n\treturn mlx5e_ktls_init_tx(priv);\n}\n\nstatic inline void mlx5e_accel_cleanup_tx(struct mlx5e_priv *priv)\n{\n\tmlx5e_ktls_cleanup_tx(priv);\n}\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}