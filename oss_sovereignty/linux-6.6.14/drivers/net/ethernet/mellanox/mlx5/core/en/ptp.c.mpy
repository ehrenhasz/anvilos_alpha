{
  "module_name": "ptp.c",
  "hash_id": "20b366259f3c65a6c99d4b7522e2eb68992ea4717c2f2bd20abfeeaec0e45463",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en/ptp.c",
  "human_readable_source": "\n\n\n#include \"en/ptp.h\"\n#include \"en/health.h\"\n#include \"en/txrx.h\"\n#include \"en/params.h\"\n#include \"en/fs_tt_redirect.h\"\n#include <linux/list.h>\n#include <linux/spinlock.h>\n\nstruct mlx5e_ptp_fs {\n\tstruct mlx5_flow_handle *l2_rule;\n\tstruct mlx5_flow_handle *udp_v4_rule;\n\tstruct mlx5_flow_handle *udp_v6_rule;\n\tbool valid;\n};\n\nstruct mlx5e_ptp_params {\n\tstruct mlx5e_params params;\n\tstruct mlx5e_sq_param txq_sq_param;\n\tstruct mlx5e_rq_param rq_param;\n};\n\nstruct mlx5e_ptp_port_ts_cqe_tracker {\n\tu8 metadata_id;\n\tbool inuse : 1;\n\tstruct list_head entry;\n};\n\nstruct mlx5e_ptp_port_ts_cqe_list {\n\tstruct mlx5e_ptp_port_ts_cqe_tracker *nodes;\n\tstruct list_head tracker_list_head;\n\t \n\tspinlock_t tracker_list_lock;\n};\n\nstatic inline void\nmlx5e_ptp_port_ts_cqe_list_add(struct mlx5e_ptp_port_ts_cqe_list *list, u8 metadata)\n{\n\tstruct mlx5e_ptp_port_ts_cqe_tracker *tracker = &list->nodes[metadata];\n\n\tWARN_ON_ONCE(tracker->inuse);\n\ttracker->inuse = true;\n\tspin_lock(&list->tracker_list_lock);\n\tlist_add_tail(&tracker->entry, &list->tracker_list_head);\n\tspin_unlock(&list->tracker_list_lock);\n}\n\nstatic void\nmlx5e_ptp_port_ts_cqe_list_remove(struct mlx5e_ptp_port_ts_cqe_list *list, u8 metadata)\n{\n\tstruct mlx5e_ptp_port_ts_cqe_tracker *tracker = &list->nodes[metadata];\n\n\tWARN_ON_ONCE(!tracker->inuse);\n\ttracker->inuse = false;\n\tspin_lock(&list->tracker_list_lock);\n\tlist_del(&tracker->entry);\n\tspin_unlock(&list->tracker_list_lock);\n}\n\nvoid mlx5e_ptpsq_track_metadata(struct mlx5e_ptpsq *ptpsq, u8 metadata)\n{\n\tmlx5e_ptp_port_ts_cqe_list_add(ptpsq->ts_cqe_pending_list, metadata);\n}\n\nstruct mlx5e_skb_cb_hwtstamp {\n\tktime_t cqe_hwtstamp;\n\tktime_t port_hwtstamp;\n};\n\nvoid mlx5e_skb_cb_hwtstamp_init(struct sk_buff *skb)\n{\n\tmemset(skb->cb, 0, sizeof(struct mlx5e_skb_cb_hwtstamp));\n}\n\nstatic struct mlx5e_skb_cb_hwtstamp *mlx5e_skb_cb_get_hwts(struct sk_buff *skb)\n{\n\tBUILD_BUG_ON(sizeof(struct mlx5e_skb_cb_hwtstamp) > sizeof(skb->cb));\n\treturn (struct mlx5e_skb_cb_hwtstamp *)skb->cb;\n}\n\nstatic void mlx5e_skb_cb_hwtstamp_tx(struct sk_buff *skb,\n\t\t\t\t     struct mlx5e_ptp_cq_stats *cq_stats)\n{\n\tstruct skb_shared_hwtstamps hwts = {};\n\tktime_t diff;\n\n\tdiff = abs(mlx5e_skb_cb_get_hwts(skb)->port_hwtstamp -\n\t\t   mlx5e_skb_cb_get_hwts(skb)->cqe_hwtstamp);\n\n\t \n\tif (diff > (NSEC_PER_SEC >> 7)) {\n\t\tcq_stats->abort++;\n\t\tcq_stats->abort_abs_diff_ns += diff;\n\t\treturn;\n\t}\n\n\thwts.hwtstamp = mlx5e_skb_cb_get_hwts(skb)->port_hwtstamp;\n\tskb_tstamp_tx(skb, &hwts);\n}\n\nvoid mlx5e_skb_cb_hwtstamp_handler(struct sk_buff *skb, int hwtstamp_type,\n\t\t\t\t   ktime_t hwtstamp,\n\t\t\t\t   struct mlx5e_ptp_cq_stats *cq_stats)\n{\n\tswitch (hwtstamp_type) {\n\tcase (MLX5E_SKB_CB_CQE_HWTSTAMP):\n\t\tmlx5e_skb_cb_get_hwts(skb)->cqe_hwtstamp = hwtstamp;\n\t\tbreak;\n\tcase (MLX5E_SKB_CB_PORT_HWTSTAMP):\n\t\tmlx5e_skb_cb_get_hwts(skb)->port_hwtstamp = hwtstamp;\n\t\tbreak;\n\t}\n\n\t \n\tif (!mlx5e_skb_cb_get_hwts(skb)->cqe_hwtstamp ||\n\t    !mlx5e_skb_cb_get_hwts(skb)->port_hwtstamp)\n\t\treturn;\n\n\tmlx5e_skb_cb_hwtstamp_tx(skb, cq_stats);\n\tmemset(skb->cb, 0, sizeof(struct mlx5e_skb_cb_hwtstamp));\n}\n\nstatic struct sk_buff *\nmlx5e_ptp_metadata_map_lookup(struct mlx5e_ptp_metadata_map *map, u16 metadata)\n{\n\treturn map->data[metadata];\n}\n\nstatic struct sk_buff *\nmlx5e_ptp_metadata_map_remove(struct mlx5e_ptp_metadata_map *map, u16 metadata)\n{\n\tstruct sk_buff *skb;\n\n\tskb = map->data[metadata];\n\tmap->data[metadata] = NULL;\n\n\treturn skb;\n}\n\nstatic bool mlx5e_ptp_metadata_map_unhealthy(struct mlx5e_ptp_metadata_map *map)\n{\n\t \n\treturn map->undelivered_counter > (map->capacity >> 4) * 15;\n}\n\nstatic void mlx5e_ptpsq_mark_ts_cqes_undelivered(struct mlx5e_ptpsq *ptpsq,\n\t\t\t\t\t\t ktime_t port_tstamp)\n{\n\tstruct mlx5e_ptp_port_ts_cqe_list *cqe_list = ptpsq->ts_cqe_pending_list;\n\tktime_t timeout = ns_to_ktime(MLX5E_PTP_TS_CQE_UNDELIVERED_TIMEOUT);\n\tstruct mlx5e_ptp_metadata_map *metadata_map = &ptpsq->metadata_map;\n\tstruct mlx5e_ptp_port_ts_cqe_tracker *pos, *n;\n\n\tspin_lock(&cqe_list->tracker_list_lock);\n\tlist_for_each_entry_safe(pos, n, &cqe_list->tracker_list_head, entry) {\n\t\tstruct sk_buff *skb =\n\t\t\tmlx5e_ptp_metadata_map_lookup(metadata_map, pos->metadata_id);\n\t\tktime_t dma_tstamp = mlx5e_skb_cb_get_hwts(skb)->cqe_hwtstamp;\n\n\t\tif (!dma_tstamp ||\n\t\t    ktime_after(ktime_add(dma_tstamp, timeout), port_tstamp))\n\t\t\tbreak;\n\n\t\tmetadata_map->undelivered_counter++;\n\t\tWARN_ON_ONCE(!pos->inuse);\n\t\tpos->inuse = false;\n\t\tlist_del(&pos->entry);\n\t}\n\tspin_unlock(&cqe_list->tracker_list_lock);\n}\n\n#define PTP_WQE_CTR2IDX(val) ((val) & ptpsq->ts_cqe_ctr_mask)\n\nstatic void mlx5e_ptp_handle_ts_cqe(struct mlx5e_ptpsq *ptpsq,\n\t\t\t\t    struct mlx5_cqe64 *cqe,\n\t\t\t\t    u8 *md_buff,\n\t\t\t\t    u8 *md_buff_sz,\n\t\t\t\t    int budget)\n{\n\tstruct mlx5e_ptp_port_ts_cqe_list *pending_cqe_list = ptpsq->ts_cqe_pending_list;\n\tu8 metadata_id = PTP_WQE_CTR2IDX(be16_to_cpu(cqe->wqe_counter));\n\tbool is_err_cqe = !!MLX5E_RX_ERR_CQE(cqe);\n\tstruct mlx5e_txqsq *sq = &ptpsq->txqsq;\n\tstruct sk_buff *skb;\n\tktime_t hwtstamp;\n\n\tif (likely(pending_cqe_list->nodes[metadata_id].inuse)) {\n\t\tmlx5e_ptp_port_ts_cqe_list_remove(pending_cqe_list, metadata_id);\n\t} else {\n\t\t \n\t\tptpsq->metadata_map.undelivered_counter--;\n\t\tptpsq->cq_stats->late_cqe++;\n\t}\n\n\tskb = mlx5e_ptp_metadata_map_remove(&ptpsq->metadata_map, metadata_id);\n\n\tif (unlikely(is_err_cqe)) {\n\t\tptpsq->cq_stats->err_cqe++;\n\t\tgoto out;\n\t}\n\n\thwtstamp = mlx5e_cqe_ts_to_ns(sq->ptp_cyc2time, sq->clock, get_cqe_ts(cqe));\n\tmlx5e_skb_cb_hwtstamp_handler(skb, MLX5E_SKB_CB_PORT_HWTSTAMP,\n\t\t\t\t      hwtstamp, ptpsq->cq_stats);\n\tptpsq->cq_stats->cqe++;\n\n\tmlx5e_ptpsq_mark_ts_cqes_undelivered(ptpsq, hwtstamp);\nout:\n\tnapi_consume_skb(skb, budget);\n\tmd_buff[*md_buff_sz++] = metadata_id;\n\tif (unlikely(mlx5e_ptp_metadata_map_unhealthy(&ptpsq->metadata_map)) &&\n\t    !test_and_set_bit(MLX5E_SQ_STATE_RECOVERING, &sq->state))\n\t\tqueue_work(ptpsq->txqsq.priv->wq, &ptpsq->report_unhealthy_work);\n}\n\nstatic bool mlx5e_ptp_poll_ts_cq(struct mlx5e_cq *cq, int napi_budget)\n{\n\tstruct mlx5e_ptpsq *ptpsq = container_of(cq, struct mlx5e_ptpsq, ts_cq);\n\tint budget = min(napi_budget, MLX5E_TX_CQ_POLL_BUDGET);\n\tu8 metadata_buff[MLX5E_TX_CQ_POLL_BUDGET];\n\tu8 metadata_buff_sz = 0;\n\tstruct mlx5_cqwq *cqwq;\n\tstruct mlx5_cqe64 *cqe;\n\tint work_done = 0;\n\n\tcqwq = &cq->wq;\n\n\tif (unlikely(!test_bit(MLX5E_SQ_STATE_ENABLED, &ptpsq->txqsq.state)))\n\t\treturn false;\n\n\tcqe = mlx5_cqwq_get_cqe(cqwq);\n\tif (!cqe)\n\t\treturn false;\n\n\tdo {\n\t\tmlx5_cqwq_pop(cqwq);\n\n\t\tmlx5e_ptp_handle_ts_cqe(ptpsq, cqe,\n\t\t\t\t\tmetadata_buff, &metadata_buff_sz, napi_budget);\n\t} while ((++work_done < budget) && (cqe = mlx5_cqwq_get_cqe(cqwq)));\n\n\tmlx5_cqwq_update_db_record(cqwq);\n\n\t \n\twmb();\n\n\twhile (metadata_buff_sz > 0)\n\t\tmlx5e_ptp_metadata_fifo_push(&ptpsq->metadata_freelist,\n\t\t\t\t\t     metadata_buff[--metadata_buff_sz]);\n\n\tmlx5e_txqsq_wake(&ptpsq->txqsq);\n\n\treturn work_done == budget;\n}\n\nstatic int mlx5e_ptp_napi_poll(struct napi_struct *napi, int budget)\n{\n\tstruct mlx5e_ptp *c = container_of(napi, struct mlx5e_ptp, napi);\n\tstruct mlx5e_ch_stats *ch_stats = c->stats;\n\tstruct mlx5e_rq *rq = &c->rq;\n\tbool busy = false;\n\tint work_done = 0;\n\tint i;\n\n\trcu_read_lock();\n\n\tch_stats->poll++;\n\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state)) {\n\t\tfor (i = 0; i < c->num_tc; i++) {\n\t\t\tbusy |= mlx5e_poll_tx_cq(&c->ptpsq[i].txqsq.cq, budget);\n\t\t\tbusy |= mlx5e_ptp_poll_ts_cq(&c->ptpsq[i].ts_cq, budget);\n\t\t}\n\t}\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state) && likely(budget)) {\n\t\twork_done = mlx5e_poll_rx_cq(&rq->cq, budget);\n\t\tbusy |= work_done == budget;\n\t\tbusy |= INDIRECT_CALL_2(rq->post_wqes,\n\t\t\t\t\tmlx5e_post_rx_mpwqes,\n\t\t\t\t\tmlx5e_post_rx_wqes,\n\t\t\t\t\trq);\n\t}\n\n\tif (busy) {\n\t\twork_done = budget;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(!napi_complete_done(napi, work_done)))\n\t\tgoto out;\n\n\tch_stats->arm++;\n\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state)) {\n\t\tfor (i = 0; i < c->num_tc; i++) {\n\t\t\tmlx5e_cq_arm(&c->ptpsq[i].txqsq.cq);\n\t\t\tmlx5e_cq_arm(&c->ptpsq[i].ts_cq);\n\t\t}\n\t}\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state))\n\t\tmlx5e_cq_arm(&rq->cq);\n\nout:\n\trcu_read_unlock();\n\n\treturn work_done;\n}\n\nstatic int mlx5e_ptp_alloc_txqsq(struct mlx5e_ptp *c, int txq_ix,\n\t\t\t\t struct mlx5e_params *params,\n\t\t\t\t struct mlx5e_sq_param *param,\n\t\t\t\t struct mlx5e_txqsq *sq, int tc,\n\t\t\t\t struct mlx5e_ptpsq *ptpsq)\n{\n\tvoid *sqc_wq               = MLX5_ADDR_OF(sqc, param->sqc, wq);\n\tstruct mlx5_core_dev *mdev = c->mdev;\n\tstruct mlx5_wq_cyc *wq = &sq->wq;\n\tint err;\n\tint node;\n\n\tsq->pdev      = c->pdev;\n\tsq->clock     = &mdev->clock;\n\tsq->mkey_be   = c->mkey_be;\n\tsq->netdev    = c->netdev;\n\tsq->priv      = c->priv;\n\tsq->mdev      = mdev;\n\tsq->ch_ix     = MLX5E_PTP_CHANNEL_IX;\n\tsq->txq_ix    = txq_ix;\n\tsq->uar_map   = mdev->mlx5e_res.hw_objs.bfreg.map;\n\tsq->min_inline_mode = params->tx_min_inline_mode;\n\tsq->hw_mtu    = MLX5E_SW2HW_MTU(params, params->sw_mtu);\n\tsq->stats     = &c->priv->ptp_stats.sq[tc];\n\tsq->ptpsq     = ptpsq;\n\tINIT_WORK(&sq->recover_work, mlx5e_tx_err_cqe_work);\n\tif (!MLX5_CAP_ETH(mdev, wqe_vlan_insert))\n\t\tset_bit(MLX5E_SQ_STATE_VLAN_NEED_L2_INLINE, &sq->state);\n\tsq->stop_room = param->stop_room;\n\tsq->ptp_cyc2time = mlx5_sq_ts_translator(mdev);\n\n\tnode = dev_to_node(mlx5_core_dma_dev(mdev));\n\n\tparam->wq.db_numa_node = node;\n\terr = mlx5_wq_cyc_create(mdev, &param->wq, sqc_wq, wq, &sq->wq_ctrl);\n\tif (err)\n\t\treturn err;\n\twq->db    = &wq->db[MLX5_SND_DBR];\n\n\terr = mlx5e_alloc_txqsq_db(sq, node);\n\tif (err)\n\t\tgoto err_sq_wq_destroy;\n\n\treturn 0;\n\nerr_sq_wq_destroy:\n\tmlx5_wq_destroy(&sq->wq_ctrl);\n\n\treturn err;\n}\n\nstatic void mlx5e_ptp_destroy_sq(struct mlx5_core_dev *mdev, u32 sqn)\n{\n\tmlx5_core_destroy_sq(mdev, sqn);\n}\n\nstatic int mlx5e_ptp_alloc_traffic_db(struct mlx5e_ptpsq *ptpsq, int numa)\n{\n\tstruct mlx5e_ptp_metadata_fifo *metadata_freelist = &ptpsq->metadata_freelist;\n\tstruct mlx5e_ptp_metadata_map *metadata_map = &ptpsq->metadata_map;\n\tstruct mlx5e_ptp_port_ts_cqe_list *cqe_list;\n\tint db_sz;\n\tint md;\n\n\tcqe_list = kvzalloc_node(sizeof(*ptpsq->ts_cqe_pending_list), GFP_KERNEL, numa);\n\tif (!cqe_list)\n\t\treturn -ENOMEM;\n\tptpsq->ts_cqe_pending_list = cqe_list;\n\n\tdb_sz = min_t(u32, mlx5_wq_cyc_get_size(&ptpsq->txqsq.wq),\n\t\t      1 << MLX5_CAP_GEN_2(ptpsq->txqsq.mdev,\n\t\t\t\t\t  ts_cqe_metadata_size2wqe_counter));\n\tptpsq->ts_cqe_ctr_mask = db_sz - 1;\n\n\tcqe_list->nodes = kvzalloc_node(array_size(db_sz, sizeof(*cqe_list->nodes)),\n\t\t\t\t\tGFP_KERNEL, numa);\n\tif (!cqe_list->nodes)\n\t\tgoto free_cqe_list;\n\tINIT_LIST_HEAD(&cqe_list->tracker_list_head);\n\tspin_lock_init(&cqe_list->tracker_list_lock);\n\n\tmetadata_freelist->data =\n\t\tkvzalloc_node(array_size(db_sz, sizeof(*metadata_freelist->data)),\n\t\t\t      GFP_KERNEL, numa);\n\tif (!metadata_freelist->data)\n\t\tgoto free_cqe_list_nodes;\n\tmetadata_freelist->mask = ptpsq->ts_cqe_ctr_mask;\n\n\tfor (md = 0; md < db_sz; ++md) {\n\t\tcqe_list->nodes[md].metadata_id = md;\n\t\tmetadata_freelist->data[md] = md;\n\t}\n\tmetadata_freelist->pc = db_sz;\n\n\tmetadata_map->data =\n\t\tkvzalloc_node(array_size(db_sz, sizeof(*metadata_map->data)),\n\t\t\t      GFP_KERNEL, numa);\n\tif (!metadata_map->data)\n\t\tgoto free_metadata_freelist;\n\tmetadata_map->capacity = db_sz;\n\n\treturn 0;\n\nfree_metadata_freelist:\n\tkvfree(metadata_freelist->data);\nfree_cqe_list_nodes:\n\tkvfree(cqe_list->nodes);\nfree_cqe_list:\n\tkvfree(cqe_list);\n\treturn -ENOMEM;\n}\n\nstatic void mlx5e_ptp_drain_metadata_map(struct mlx5e_ptp_metadata_map *map)\n{\n\tint idx;\n\n\tfor (idx = 0; idx < map->capacity; ++idx) {\n\t\tstruct sk_buff *skb = map->data[idx];\n\n\t\tdev_kfree_skb_any(skb);\n\t}\n}\n\nstatic void mlx5e_ptp_free_traffic_db(struct mlx5e_ptpsq *ptpsq)\n{\n\tmlx5e_ptp_drain_metadata_map(&ptpsq->metadata_map);\n\tkvfree(ptpsq->metadata_map.data);\n\tkvfree(ptpsq->metadata_freelist.data);\n\tkvfree(ptpsq->ts_cqe_pending_list->nodes);\n\tkvfree(ptpsq->ts_cqe_pending_list);\n}\n\nstatic void mlx5e_ptpsq_unhealthy_work(struct work_struct *work)\n{\n\tstruct mlx5e_ptpsq *ptpsq =\n\t\tcontainer_of(work, struct mlx5e_ptpsq, report_unhealthy_work);\n\n\tmlx5e_reporter_tx_ptpsq_unhealthy(ptpsq);\n}\n\nstatic int mlx5e_ptp_open_txqsq(struct mlx5e_ptp *c, u32 tisn,\n\t\t\t\tint txq_ix, struct mlx5e_ptp_params *cparams,\n\t\t\t\tint tc, struct mlx5e_ptpsq *ptpsq)\n{\n\tstruct mlx5e_sq_param *sqp = &cparams->txq_sq_param;\n\tstruct mlx5e_txqsq *txqsq = &ptpsq->txqsq;\n\tstruct mlx5e_create_sq_param csp = {};\n\tint err;\n\n\terr = mlx5e_ptp_alloc_txqsq(c, txq_ix, &cparams->params, sqp,\n\t\t\t\t    txqsq, tc, ptpsq);\n\tif (err)\n\t\treturn err;\n\n\tcsp.tisn            = tisn;\n\tcsp.tis_lst_sz      = 1;\n\tcsp.cqn             = txqsq->cq.mcq.cqn;\n\tcsp.wq_ctrl         = &txqsq->wq_ctrl;\n\tcsp.min_inline_mode = txqsq->min_inline_mode;\n\tcsp.ts_cqe_to_dest_cqn = ptpsq->ts_cq.mcq.cqn;\n\n\terr = mlx5e_create_sq_rdy(c->mdev, sqp, &csp, 0, &txqsq->sqn);\n\tif (err)\n\t\tgoto err_free_txqsq;\n\n\terr = mlx5e_ptp_alloc_traffic_db(ptpsq, dev_to_node(mlx5_core_dma_dev(c->mdev)));\n\tif (err)\n\t\tgoto err_free_txqsq;\n\n\tINIT_WORK(&ptpsq->report_unhealthy_work, mlx5e_ptpsq_unhealthy_work);\n\n\treturn 0;\n\nerr_free_txqsq:\n\tmlx5e_free_txqsq(txqsq);\n\n\treturn err;\n}\n\nstatic void mlx5e_ptp_close_txqsq(struct mlx5e_ptpsq *ptpsq)\n{\n\tstruct mlx5e_txqsq *sq = &ptpsq->txqsq;\n\tstruct mlx5_core_dev *mdev = sq->mdev;\n\n\tif (current_work() != &ptpsq->report_unhealthy_work)\n\t\tcancel_work_sync(&ptpsq->report_unhealthy_work);\n\tmlx5e_ptp_free_traffic_db(ptpsq);\n\tcancel_work_sync(&sq->recover_work);\n\tmlx5e_ptp_destroy_sq(mdev, sq->sqn);\n\tmlx5e_free_txqsq_descs(sq);\n\tmlx5e_free_txqsq(sq);\n}\n\nstatic int mlx5e_ptp_open_txqsqs(struct mlx5e_ptp *c,\n\t\t\t\t struct mlx5e_ptp_params *cparams)\n{\n\tstruct mlx5e_params *params = &cparams->params;\n\tu8 num_tc = mlx5e_get_dcb_num_tc(params);\n\tint ix_base;\n\tint err;\n\tint tc;\n\n\tix_base = num_tc * params->num_channels;\n\n\tfor (tc = 0; tc < num_tc; tc++) {\n\t\tint txq_ix = ix_base + tc;\n\n\t\terr = mlx5e_ptp_open_txqsq(c, c->priv->tisn[c->lag_port][tc], txq_ix,\n\t\t\t\t\t   cparams, tc, &c->ptpsq[tc]);\n\t\tif (err)\n\t\t\tgoto close_txqsq;\n\t}\n\n\treturn 0;\n\nclose_txqsq:\n\tfor (--tc; tc >= 0; tc--)\n\t\tmlx5e_ptp_close_txqsq(&c->ptpsq[tc]);\n\n\treturn err;\n}\n\nstatic void mlx5e_ptp_close_txqsqs(struct mlx5e_ptp *c)\n{\n\tint tc;\n\n\tfor (tc = 0; tc < c->num_tc; tc++)\n\t\tmlx5e_ptp_close_txqsq(&c->ptpsq[tc]);\n}\n\nstatic int mlx5e_ptp_open_tx_cqs(struct mlx5e_ptp *c,\n\t\t\t\t struct mlx5e_ptp_params *cparams)\n{\n\tstruct mlx5e_params *params = &cparams->params;\n\tstruct mlx5e_create_cq_param ccp = {};\n\tstruct dim_cq_moder ptp_moder = {};\n\tstruct mlx5e_cq_param *cq_param;\n\tu8 num_tc;\n\tint err;\n\tint tc;\n\n\tnum_tc = mlx5e_get_dcb_num_tc(params);\n\n\tccp.node     = dev_to_node(mlx5_core_dma_dev(c->mdev));\n\tccp.ch_stats = c->stats;\n\tccp.napi     = &c->napi;\n\tccp.ix       = MLX5E_PTP_CHANNEL_IX;\n\n\tcq_param = &cparams->txq_sq_param.cqp;\n\n\tfor (tc = 0; tc < num_tc; tc++) {\n\t\tstruct mlx5e_cq *cq = &c->ptpsq[tc].txqsq.cq;\n\n\t\terr = mlx5e_open_cq(c->priv, ptp_moder, cq_param, &ccp, cq);\n\t\tif (err)\n\t\t\tgoto out_err_txqsq_cq;\n\t}\n\n\tfor (tc = 0; tc < num_tc; tc++) {\n\t\tstruct mlx5e_cq *cq = &c->ptpsq[tc].ts_cq;\n\t\tstruct mlx5e_ptpsq *ptpsq = &c->ptpsq[tc];\n\n\t\terr = mlx5e_open_cq(c->priv, ptp_moder, cq_param, &ccp, cq);\n\t\tif (err)\n\t\t\tgoto out_err_ts_cq;\n\n\t\tptpsq->cq_stats = &c->priv->ptp_stats.cq[tc];\n\t}\n\n\treturn 0;\n\nout_err_ts_cq:\n\tfor (--tc; tc >= 0; tc--)\n\t\tmlx5e_close_cq(&c->ptpsq[tc].ts_cq);\n\ttc = num_tc;\nout_err_txqsq_cq:\n\tfor (--tc; tc >= 0; tc--)\n\t\tmlx5e_close_cq(&c->ptpsq[tc].txqsq.cq);\n\n\treturn err;\n}\n\nstatic int mlx5e_ptp_open_rx_cq(struct mlx5e_ptp *c,\n\t\t\t\tstruct mlx5e_ptp_params *cparams)\n{\n\tstruct mlx5e_create_cq_param ccp = {};\n\tstruct dim_cq_moder ptp_moder = {};\n\tstruct mlx5e_cq_param *cq_param;\n\tstruct mlx5e_cq *cq = &c->rq.cq;\n\n\tccp.node     = dev_to_node(mlx5_core_dma_dev(c->mdev));\n\tccp.ch_stats = c->stats;\n\tccp.napi     = &c->napi;\n\tccp.ix       = MLX5E_PTP_CHANNEL_IX;\n\n\tcq_param = &cparams->rq_param.cqp;\n\n\treturn mlx5e_open_cq(c->priv, ptp_moder, cq_param, &ccp, cq);\n}\n\nstatic void mlx5e_ptp_close_tx_cqs(struct mlx5e_ptp *c)\n{\n\tint tc;\n\n\tfor (tc = 0; tc < c->num_tc; tc++)\n\t\tmlx5e_close_cq(&c->ptpsq[tc].ts_cq);\n\n\tfor (tc = 0; tc < c->num_tc; tc++)\n\t\tmlx5e_close_cq(&c->ptpsq[tc].txqsq.cq);\n}\n\nstatic void mlx5e_ptp_build_sq_param(struct mlx5_core_dev *mdev,\n\t\t\t\t     struct mlx5e_params *params,\n\t\t\t\t     struct mlx5e_sq_param *param)\n{\n\tvoid *sqc = param->sqc;\n\tvoid *wq;\n\n\tmlx5e_build_sq_param_common(mdev, param);\n\n\twq = MLX5_ADDR_OF(sqc, sqc, wq);\n\tMLX5_SET(wq, wq, log_wq_sz, params->log_sq_size);\n\tparam->stop_room = mlx5e_stop_room_for_max_wqe(mdev);\n\tmlx5e_build_tx_cq_param(mdev, params, &param->cqp);\n}\n\nstatic void mlx5e_ptp_build_rq_param(struct mlx5_core_dev *mdev,\n\t\t\t\t     struct net_device *netdev,\n\t\t\t\t     u16 q_counter,\n\t\t\t\t     struct mlx5e_ptp_params *ptp_params)\n{\n\tstruct mlx5e_rq_param *rq_params = &ptp_params->rq_param;\n\tstruct mlx5e_params *params = &ptp_params->params;\n\n\tparams->rq_wq_type = MLX5_WQ_TYPE_CYCLIC;\n\tmlx5e_init_rq_type_params(mdev, params);\n\tparams->sw_mtu = netdev->max_mtu;\n\tmlx5e_build_rq_param(mdev, params, NULL, q_counter, rq_params);\n}\n\nstatic void mlx5e_ptp_build_params(struct mlx5e_ptp *c,\n\t\t\t\t   struct mlx5e_ptp_params *cparams,\n\t\t\t\t   struct mlx5e_params *orig)\n{\n\tstruct mlx5e_params *params = &cparams->params;\n\n\tparams->tx_min_inline_mode = orig->tx_min_inline_mode;\n\tparams->num_channels = orig->num_channels;\n\tparams->hard_mtu = orig->hard_mtu;\n\tparams->sw_mtu = orig->sw_mtu;\n\tparams->mqprio = orig->mqprio;\n\n\t \n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state)) {\n\t\tparams->log_sq_size =\n\t\t\tmin(MLX5_CAP_GEN_2(c->mdev, ts_cqe_metadata_size2wqe_counter),\n\t\t\t    MLX5E_PTP_MAX_LOG_SQ_SIZE);\n\t\tparams->log_sq_size = min(params->log_sq_size, orig->log_sq_size);\n\t\tmlx5e_ptp_build_sq_param(c->mdev, params, &cparams->txq_sq_param);\n\t}\n\t \n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state)) {\n\t\tparams->vlan_strip_disable = orig->vlan_strip_disable;\n\t\tmlx5e_ptp_build_rq_param(c->mdev, c->netdev, c->priv->q_counter, cparams);\n\t}\n}\n\nstatic int mlx5e_init_ptp_rq(struct mlx5e_ptp *c, struct mlx5e_params *params,\n\t\t\t     struct mlx5e_rq *rq)\n{\n\tstruct mlx5_core_dev *mdev = c->mdev;\n\tstruct mlx5e_priv *priv = c->priv;\n\tint err;\n\n\trq->wq_type      = params->rq_wq_type;\n\trq->pdev         = c->pdev;\n\trq->netdev       = priv->netdev;\n\trq->priv         = priv;\n\trq->clock        = &mdev->clock;\n\trq->tstamp       = &priv->tstamp;\n\trq->mdev         = mdev;\n\trq->hw_mtu       = MLX5E_SW2HW_MTU(params, params->sw_mtu);\n\trq->stats        = &c->priv->ptp_stats.rq;\n\trq->ix           = MLX5E_PTP_CHANNEL_IX;\n\trq->ptp_cyc2time = mlx5_rq_ts_translator(mdev);\n\terr = mlx5e_rq_set_handlers(rq, params, false);\n\tif (err)\n\t\treturn err;\n\n\treturn xdp_rxq_info_reg(&rq->xdp_rxq, rq->netdev, rq->ix, 0);\n}\n\nstatic int mlx5e_ptp_open_rq(struct mlx5e_ptp *c, struct mlx5e_params *params,\n\t\t\t     struct mlx5e_rq_param *rq_param)\n{\n\tint node = dev_to_node(c->mdev->device);\n\tint err;\n\n\terr = mlx5e_init_ptp_rq(c, params, &c->rq);\n\tif (err)\n\t\treturn err;\n\n\treturn mlx5e_open_rq(params, rq_param, NULL, node, &c->rq);\n}\n\nstatic int mlx5e_ptp_open_queues(struct mlx5e_ptp *c,\n\t\t\t\t struct mlx5e_ptp_params *cparams)\n{\n\tint err;\n\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state)) {\n\t\terr = mlx5e_ptp_open_tx_cqs(c, cparams);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = mlx5e_ptp_open_txqsqs(c, cparams);\n\t\tif (err)\n\t\t\tgoto close_tx_cqs;\n\t}\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state)) {\n\t\terr = mlx5e_ptp_open_rx_cq(c, cparams);\n\t\tif (err)\n\t\t\tgoto close_txqsq;\n\n\t\terr = mlx5e_ptp_open_rq(c, &cparams->params, &cparams->rq_param);\n\t\tif (err)\n\t\t\tgoto close_rx_cq;\n\t}\n\treturn 0;\n\nclose_rx_cq:\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state))\n\t\tmlx5e_close_cq(&c->rq.cq);\nclose_txqsq:\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state))\n\t\tmlx5e_ptp_close_txqsqs(c);\nclose_tx_cqs:\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state))\n\t\tmlx5e_ptp_close_tx_cqs(c);\n\n\treturn err;\n}\n\nstatic void mlx5e_ptp_close_queues(struct mlx5e_ptp *c)\n{\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state)) {\n\t\tmlx5e_close_rq(&c->rq);\n\t\tmlx5e_close_cq(&c->rq.cq);\n\t}\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state)) {\n\t\tmlx5e_ptp_close_txqsqs(c);\n\t\tmlx5e_ptp_close_tx_cqs(c);\n\t}\n}\n\nstatic int mlx5e_ptp_set_state(struct mlx5e_ptp *c, struct mlx5e_params *params)\n{\n\tif (MLX5E_GET_PFLAG(params, MLX5E_PFLAG_TX_PORT_TS))\n\t\t__set_bit(MLX5E_PTP_STATE_TX, c->state);\n\n\tif (params->ptp_rx)\n\t\t__set_bit(MLX5E_PTP_STATE_RX, c->state);\n\n\treturn bitmap_empty(c->state, MLX5E_PTP_STATE_NUM_STATES) ? -EINVAL : 0;\n}\n\nstatic void mlx5e_ptp_rx_unset_fs(struct mlx5e_flow_steering *fs)\n{\n\tstruct mlx5e_ptp_fs *ptp_fs = mlx5e_fs_get_ptp(fs);\n\n\tif (!ptp_fs->valid)\n\t\treturn;\n\n\tmlx5e_fs_tt_redirect_del_rule(ptp_fs->l2_rule);\n\tmlx5e_fs_tt_redirect_any_destroy(fs);\n\n\tmlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v6_rule);\n\tmlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v4_rule);\n\tmlx5e_fs_tt_redirect_udp_destroy(fs);\n\tptp_fs->valid = false;\n}\n\nstatic int mlx5e_ptp_rx_set_fs(struct mlx5e_priv *priv)\n{\n\tu32 tirn = mlx5e_rx_res_get_tirn_ptp(priv->rx_res);\n\tstruct mlx5e_flow_steering *fs = priv->fs;\n\tstruct mlx5_flow_handle *rule;\n\tstruct mlx5e_ptp_fs *ptp_fs;\n\tint err;\n\n\tptp_fs = mlx5e_fs_get_ptp(fs);\n\tif (ptp_fs->valid)\n\t\treturn 0;\n\n\terr = mlx5e_fs_tt_redirect_udp_create(fs);\n\tif (err)\n\t\tgoto out_free;\n\n\trule = mlx5e_fs_tt_redirect_udp_add_rule(fs, MLX5_TT_IPV4_UDP,\n\t\t\t\t\t\t tirn, PTP_EV_PORT);\n\tif (IS_ERR(rule)) {\n\t\terr = PTR_ERR(rule);\n\t\tgoto out_destroy_fs_udp;\n\t}\n\tptp_fs->udp_v4_rule = rule;\n\n\trule = mlx5e_fs_tt_redirect_udp_add_rule(fs, MLX5_TT_IPV6_UDP,\n\t\t\t\t\t\t tirn, PTP_EV_PORT);\n\tif (IS_ERR(rule)) {\n\t\terr = PTR_ERR(rule);\n\t\tgoto out_destroy_udp_v4_rule;\n\t}\n\tptp_fs->udp_v6_rule = rule;\n\n\terr = mlx5e_fs_tt_redirect_any_create(fs);\n\tif (err)\n\t\tgoto out_destroy_udp_v6_rule;\n\n\trule = mlx5e_fs_tt_redirect_any_add_rule(fs, tirn, ETH_P_1588);\n\tif (IS_ERR(rule)) {\n\t\terr = PTR_ERR(rule);\n\t\tgoto out_destroy_fs_any;\n\t}\n\tptp_fs->l2_rule = rule;\n\tptp_fs->valid = true;\n\n\treturn 0;\n\nout_destroy_fs_any:\n\tmlx5e_fs_tt_redirect_any_destroy(fs);\nout_destroy_udp_v6_rule:\n\tmlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v6_rule);\nout_destroy_udp_v4_rule:\n\tmlx5e_fs_tt_redirect_del_rule(ptp_fs->udp_v4_rule);\nout_destroy_fs_udp:\n\tmlx5e_fs_tt_redirect_udp_destroy(fs);\nout_free:\n\treturn err;\n}\n\nint mlx5e_ptp_open(struct mlx5e_priv *priv, struct mlx5e_params *params,\n\t\t   u8 lag_port, struct mlx5e_ptp **cp)\n{\n\tstruct net_device *netdev = priv->netdev;\n\tstruct mlx5_core_dev *mdev = priv->mdev;\n\tstruct mlx5e_ptp_params *cparams;\n\tstruct mlx5e_ptp *c;\n\tint err;\n\n\n\tc = kvzalloc_node(sizeof(*c), GFP_KERNEL, dev_to_node(mlx5_core_dma_dev(mdev)));\n\tcparams = kvzalloc(sizeof(*cparams), GFP_KERNEL);\n\tif (!c || !cparams) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free;\n\t}\n\n\tc->priv     = priv;\n\tc->mdev     = priv->mdev;\n\tc->tstamp   = &priv->tstamp;\n\tc->pdev     = mlx5_core_dma_dev(priv->mdev);\n\tc->netdev   = priv->netdev;\n\tc->mkey_be  = cpu_to_be32(priv->mdev->mlx5e_res.hw_objs.mkey);\n\tc->num_tc   = mlx5e_get_dcb_num_tc(params);\n\tc->stats    = &priv->ptp_stats.ch;\n\tc->lag_port = lag_port;\n\n\terr = mlx5e_ptp_set_state(c, params);\n\tif (err)\n\t\tgoto err_free;\n\n\tnetif_napi_add(netdev, &c->napi, mlx5e_ptp_napi_poll);\n\n\tmlx5e_ptp_build_params(c, cparams, params);\n\n\terr = mlx5e_ptp_open_queues(c, cparams);\n\tif (unlikely(err))\n\t\tgoto err_napi_del;\n\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state))\n\t\tpriv->rx_ptp_opened = true;\n\n\t*cp = c;\n\n\tkvfree(cparams);\n\n\treturn 0;\n\nerr_napi_del:\n\tnetif_napi_del(&c->napi);\nerr_free:\n\tkvfree(cparams);\n\tkvfree(c);\n\treturn err;\n}\n\nvoid mlx5e_ptp_close(struct mlx5e_ptp *c)\n{\n\tmlx5e_ptp_close_queues(c);\n\tnetif_napi_del(&c->napi);\n\n\tkvfree(c);\n}\n\nvoid mlx5e_ptp_activate_channel(struct mlx5e_ptp *c)\n{\n\tint tc;\n\n\tnapi_enable(&c->napi);\n\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state)) {\n\t\tfor (tc = 0; tc < c->num_tc; tc++)\n\t\t\tmlx5e_activate_txqsq(&c->ptpsq[tc].txqsq);\n\t}\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state)) {\n\t\tmlx5e_ptp_rx_set_fs(c->priv);\n\t\tmlx5e_activate_rq(&c->rq);\n\t}\n\tmlx5e_trigger_napi_sched(&c->napi);\n}\n\nvoid mlx5e_ptp_deactivate_channel(struct mlx5e_ptp *c)\n{\n\tint tc;\n\n\tif (test_bit(MLX5E_PTP_STATE_RX, c->state))\n\t\tmlx5e_deactivate_rq(&c->rq);\n\n\tif (test_bit(MLX5E_PTP_STATE_TX, c->state)) {\n\t\tfor (tc = 0; tc < c->num_tc; tc++)\n\t\t\tmlx5e_deactivate_txqsq(&c->ptpsq[tc].txqsq);\n\t}\n\n\tnapi_disable(&c->napi);\n}\n\nint mlx5e_ptp_get_rqn(struct mlx5e_ptp *c, u32 *rqn)\n{\n\tif (!c || !test_bit(MLX5E_PTP_STATE_RX, c->state))\n\t\treturn -EINVAL;\n\n\t*rqn = c->rq.rqn;\n\treturn 0;\n}\n\nint mlx5e_ptp_alloc_rx_fs(struct mlx5e_flow_steering *fs,\n\t\t\t  const struct mlx5e_profile *profile)\n{\n\tstruct mlx5e_ptp_fs *ptp_fs;\n\n\tif (!mlx5e_profile_feature_cap(profile, PTP_RX))\n\t\treturn 0;\n\n\tptp_fs = kzalloc(sizeof(*ptp_fs), GFP_KERNEL);\n\tif (!ptp_fs)\n\t\treturn -ENOMEM;\n\tmlx5e_fs_set_ptp(fs, ptp_fs);\n\n\treturn 0;\n}\n\nvoid mlx5e_ptp_free_rx_fs(struct mlx5e_flow_steering *fs,\n\t\t\t  const struct mlx5e_profile *profile)\n{\n\tstruct mlx5e_ptp_fs *ptp_fs = mlx5e_fs_get_ptp(fs);\n\n\tif (!mlx5e_profile_feature_cap(profile, PTP_RX))\n\t\treturn;\n\n\tmlx5e_ptp_rx_unset_fs(fs);\n\tkfree(ptp_fs);\n}\n\nint mlx5e_ptp_rx_manage_fs(struct mlx5e_priv *priv, bool set)\n{\n\tstruct mlx5e_ptp *c = priv->channels.ptp;\n\n\tif (!mlx5e_profile_feature_cap(priv->profile, PTP_RX))\n\t\treturn 0;\n\n\tif (!test_bit(MLX5E_STATE_OPENED, &priv->state))\n\t\treturn 0;\n\n\tif (set) {\n\t\tif (!c || !test_bit(MLX5E_PTP_STATE_RX, c->state)) {\n\t\t\tnetdev_WARN_ONCE(priv->netdev, \"Don't try to add PTP RX-FS rules\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn mlx5e_ptp_rx_set_fs(priv);\n\t}\n\t \n\tif (c && test_bit(MLX5E_PTP_STATE_RX, c->state)) {\n\t\tnetdev_WARN_ONCE(priv->netdev, \"Don't try to remove PTP RX-FS rules\");\n\t\treturn -EINVAL;\n\t}\n\tmlx5e_ptp_rx_unset_fs(priv->fs);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}