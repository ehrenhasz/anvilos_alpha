{
  "module_name": "en_fs.c",
  "hash_id": "68d8dd156626652354aa37bdc908937df30ad48c57704a48268680ad11083c58",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en_fs.c",
  "human_readable_source": " \n\n#include <linux/debugfs.h>\n#include <linux/list.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/tcp.h>\n#include <linux/mlx5/fs.h>\n#include <linux/mlx5/mpfs.h>\n#include \"en_tc.h\"\n#include \"lib/mpfs.h\"\n#include \"en/ptp.h\"\n#include \"en/fs_ethtool.h\"\n\nstruct mlx5e_flow_steering {\n\tstruct work_struct\t\tset_rx_mode_work;\n\tbool\t\t\t\tstate_destroy;\n\tbool\t\t\t\tvlan_strip_disable;\n\tstruct mlx5_core_dev\t\t*mdev;\n\tstruct net_device\t\t*netdev;\n\tstruct mlx5_flow_namespace      *ns;\n\tstruct mlx5_flow_namespace      *egress_ns;\n#ifdef CONFIG_MLX5_EN_RXNFC\n\tstruct mlx5e_ethtool_steering   *ethtool;\n#endif\n\tstruct mlx5e_tc_table           *tc;\n\tstruct mlx5e_promisc_table      promisc;\n\tstruct mlx5e_vlan_table         *vlan;\n\tstruct mlx5e_l2_table           l2;\n\tstruct mlx5_ttc_table           *ttc;\n\tstruct mlx5_ttc_table           *inner_ttc;\n#ifdef CONFIG_MLX5_EN_ARFS\n\tstruct mlx5e_arfs_tables       *arfs;\n#endif\n#ifdef CONFIG_MLX5_EN_TLS\n\tstruct mlx5e_accel_fs_tcp      *accel_tcp;\n#endif\n\tstruct mlx5e_fs_udp            *udp;\n\tstruct mlx5e_fs_any            *any;\n\tstruct mlx5e_ptp_fs            *ptp_fs;\n\tstruct dentry                  *dfs_root;\n};\n\nstatic int mlx5e_add_l2_flow_rule(struct mlx5e_flow_steering *fs,\n\t\t\t\t  struct mlx5e_l2_rule *ai, int type);\nstatic void mlx5e_del_l2_flow_rule(struct mlx5e_flow_steering *fs,\n\t\t\t\t   struct mlx5e_l2_rule *ai);\n\nenum {\n\tMLX5E_FULLMATCH = 0,\n\tMLX5E_ALLMULTI  = 1,\n};\n\nenum {\n\tMLX5E_UC        = 0,\n\tMLX5E_MC_IPV4   = 1,\n\tMLX5E_MC_IPV6   = 2,\n\tMLX5E_MC_OTHER  = 3,\n};\n\nenum {\n\tMLX5E_ACTION_NONE = 0,\n\tMLX5E_ACTION_ADD  = 1,\n\tMLX5E_ACTION_DEL  = 2,\n};\n\nstruct mlx5e_l2_hash_node {\n\tstruct hlist_node          hlist;\n\tu8                         action;\n\tstruct mlx5e_l2_rule ai;\n\tbool   mpfs;\n};\n\nstatic inline int mlx5e_hash_l2(const u8 *addr)\n{\n\treturn addr[5];\n}\n\nstruct dentry *mlx5e_fs_get_debugfs_root(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->dfs_root;\n}\n\nstatic void mlx5e_add_l2_to_hash(struct hlist_head *hash, const u8 *addr)\n{\n\tstruct mlx5e_l2_hash_node *hn;\n\tint ix = mlx5e_hash_l2(addr);\n\tint found = 0;\n\n\thlist_for_each_entry(hn, &hash[ix], hlist)\n\t\tif (ether_addr_equal_64bits(hn->ai.addr, addr)) {\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\t}\n\n\tif (found) {\n\t\thn->action = MLX5E_ACTION_NONE;\n\t\treturn;\n\t}\n\n\thn = kzalloc(sizeof(*hn), GFP_ATOMIC);\n\tif (!hn)\n\t\treturn;\n\n\tether_addr_copy(hn->ai.addr, addr);\n\thn->action = MLX5E_ACTION_ADD;\n\n\thlist_add_head(&hn->hlist, &hash[ix]);\n}\n\nstatic void mlx5e_del_l2_from_hash(struct mlx5e_l2_hash_node *hn)\n{\n\thlist_del(&hn->hlist);\n\tkfree(hn);\n}\n\nstruct mlx5e_vlan_table {\n\tstruct mlx5e_flow_table\t\tft;\n\tDECLARE_BITMAP(active_cvlans, VLAN_N_VID);\n\tDECLARE_BITMAP(active_svlans, VLAN_N_VID);\n\tstruct mlx5_flow_handle\t*active_cvlans_rule[VLAN_N_VID];\n\tstruct mlx5_flow_handle\t*active_svlans_rule[VLAN_N_VID];\n\tstruct mlx5_flow_handle\t*untagged_rule;\n\tstruct mlx5_flow_handle\t*any_cvlan_rule;\n\tstruct mlx5_flow_handle\t*any_svlan_rule;\n\tstruct mlx5_flow_handle\t*trap_rule;\n\tbool\t\t\tcvlan_filter_disabled;\n};\n\nunsigned long *mlx5e_vlan_get_active_svlans(struct mlx5e_vlan_table *vlan)\n{\n\treturn vlan->active_svlans;\n}\n\nstruct mlx5_flow_table *mlx5e_vlan_get_flowtable(struct mlx5e_vlan_table *vlan)\n{\n\treturn vlan->ft.t;\n}\n\nstatic int mlx5e_vport_context_update_vlans(struct mlx5e_flow_steering *fs)\n{\n\tint max_list_size;\n\tint list_size;\n\tu16 *vlans;\n\tint vlan;\n\tint err;\n\tint i;\n\n\tlist_size = 0;\n\tfor_each_set_bit(vlan, fs->vlan->active_cvlans, VLAN_N_VID)\n\t\tlist_size++;\n\n\tmax_list_size = 1 << MLX5_CAP_GEN(fs->mdev, log_max_vlan_list);\n\n\tif (list_size > max_list_size) {\n\t\tfs_warn(fs, \"netdev vlans list size (%d) > (%d) max vport list size, some vlans will be dropped\\n\",\n\t\t\tlist_size, max_list_size);\n\t\tlist_size = max_list_size;\n\t}\n\n\tvlans = kvcalloc(list_size, sizeof(*vlans), GFP_KERNEL);\n\tif (!vlans)\n\t\treturn -ENOMEM;\n\n\ti = 0;\n\tfor_each_set_bit(vlan, fs->vlan->active_cvlans, VLAN_N_VID) {\n\t\tif (i >= list_size)\n\t\t\tbreak;\n\t\tvlans[i++] = vlan;\n\t}\n\n\terr = mlx5_modify_nic_vport_vlans(fs->mdev, vlans, list_size);\n\tif (err)\n\t\tfs_err(fs, \"Failed to modify vport vlans list err(%d)\\n\",\n\t\t       err);\n\n\tkvfree(vlans);\n\treturn err;\n}\n\nenum mlx5e_vlan_rule_type {\n\tMLX5E_VLAN_RULE_TYPE_UNTAGGED,\n\tMLX5E_VLAN_RULE_TYPE_ANY_CTAG_VID,\n\tMLX5E_VLAN_RULE_TYPE_ANY_STAG_VID,\n\tMLX5E_VLAN_RULE_TYPE_MATCH_CTAG_VID,\n\tMLX5E_VLAN_RULE_TYPE_MATCH_STAG_VID,\n};\n\nstatic int __mlx5e_add_vlan_rule(struct mlx5e_flow_steering *fs,\n\t\t\t\t enum mlx5e_vlan_rule_type rule_type,\n\t\t\t\t u16 vid, struct mlx5_flow_spec *spec)\n{\n\tstruct mlx5_flow_table *ft = fs->vlan->ft.t;\n\tstruct mlx5_flow_destination dest = {};\n\tstruct mlx5_flow_handle **rule_p;\n\tMLX5_DECLARE_FLOW_ACT(flow_act);\n\tint err = 0;\n\n\tdest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\n\tdest.ft = fs->l2.ft.t;\n\n\tspec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;\n\n\tswitch (rule_type) {\n\tcase MLX5E_VLAN_RULE_TYPE_UNTAGGED:\n\t\t \n\t\trule_p = &fs->vlan->untagged_rule;\n\t\tMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\n\t\t\t\t outer_headers.cvlan_tag);\n\t\tbreak;\n\tcase MLX5E_VLAN_RULE_TYPE_ANY_CTAG_VID:\n\t\trule_p = &fs->vlan->any_cvlan_rule;\n\t\tMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\n\t\t\t\t outer_headers.cvlan_tag);\n\t\tMLX5_SET(fte_match_param, spec->match_value, outer_headers.cvlan_tag, 1);\n\t\tbreak;\n\tcase MLX5E_VLAN_RULE_TYPE_ANY_STAG_VID:\n\t\trule_p = &fs->vlan->any_svlan_rule;\n\t\tMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\n\t\t\t\t outer_headers.svlan_tag);\n\t\tMLX5_SET(fte_match_param, spec->match_value, outer_headers.svlan_tag, 1);\n\t\tbreak;\n\tcase MLX5E_VLAN_RULE_TYPE_MATCH_STAG_VID:\n\t\trule_p = &fs->vlan->active_svlans_rule[vid];\n\t\tMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\n\t\t\t\t outer_headers.svlan_tag);\n\t\tMLX5_SET(fte_match_param, spec->match_value, outer_headers.svlan_tag, 1);\n\t\tMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\n\t\t\t\t outer_headers.first_vid);\n\t\tMLX5_SET(fte_match_param, spec->match_value, outer_headers.first_vid,\n\t\t\t vid);\n\t\tbreak;\n\tdefault:  \n\t\trule_p = &fs->vlan->active_cvlans_rule[vid];\n\t\tMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\n\t\t\t\t outer_headers.cvlan_tag);\n\t\tMLX5_SET(fte_match_param, spec->match_value, outer_headers.cvlan_tag, 1);\n\t\tMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\n\t\t\t\t outer_headers.first_vid);\n\t\tMLX5_SET(fte_match_param, spec->match_value, outer_headers.first_vid,\n\t\t\t vid);\n\t\tbreak;\n\t}\n\n\tif (WARN_ONCE(*rule_p, \"VLAN rule already exists type %d\", rule_type))\n\t\treturn 0;\n\n\t*rule_p = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1);\n\n\tif (IS_ERR(*rule_p)) {\n\t\terr = PTR_ERR(*rule_p);\n\t\t*rule_p = NULL;\n\t\tfs_err(fs, \"add rule failed\\n\");\n\t}\n\n\treturn err;\n}\n\nstatic int mlx5e_add_vlan_rule(struct mlx5e_flow_steering *fs,\n\t\t\t       enum mlx5e_vlan_rule_type rule_type, u16 vid)\n{\n\tstruct mlx5_flow_spec *spec;\n\tint err = 0;\n\n\tspec = kvzalloc(sizeof(*spec), GFP_KERNEL);\n\tif (!spec)\n\t\treturn -ENOMEM;\n\n\tif (rule_type == MLX5E_VLAN_RULE_TYPE_MATCH_CTAG_VID)\n\t\tmlx5e_vport_context_update_vlans(fs);\n\n\terr = __mlx5e_add_vlan_rule(fs, rule_type, vid, spec);\n\n\tkvfree(spec);\n\n\treturn err;\n}\n\nstatic void mlx5e_fs_del_vlan_rule(struct mlx5e_flow_steering *fs,\n\t\t\t\t   enum mlx5e_vlan_rule_type rule_type, u16 vid)\n{\n\tswitch (rule_type) {\n\tcase MLX5E_VLAN_RULE_TYPE_UNTAGGED:\n\t\tif (fs->vlan->untagged_rule) {\n\t\t\tmlx5_del_flow_rules(fs->vlan->untagged_rule);\n\t\t\tfs->vlan->untagged_rule = NULL;\n\t\t}\n\t\tbreak;\n\tcase MLX5E_VLAN_RULE_TYPE_ANY_CTAG_VID:\n\t\tif (fs->vlan->any_cvlan_rule) {\n\t\t\tmlx5_del_flow_rules(fs->vlan->any_cvlan_rule);\n\t\t\tfs->vlan->any_cvlan_rule = NULL;\n\t\t}\n\t\tbreak;\n\tcase MLX5E_VLAN_RULE_TYPE_ANY_STAG_VID:\n\t\tif (fs->vlan->any_svlan_rule) {\n\t\t\tmlx5_del_flow_rules(fs->vlan->any_svlan_rule);\n\t\t\tfs->vlan->any_svlan_rule = NULL;\n\t\t}\n\t\tbreak;\n\tcase MLX5E_VLAN_RULE_TYPE_MATCH_STAG_VID:\n\t\tif (fs->vlan->active_svlans_rule[vid]) {\n\t\t\tmlx5_del_flow_rules(fs->vlan->active_svlans_rule[vid]);\n\t\t\tfs->vlan->active_svlans_rule[vid] = NULL;\n\t\t}\n\t\tbreak;\n\tcase MLX5E_VLAN_RULE_TYPE_MATCH_CTAG_VID:\n\t\tif (fs->vlan->active_cvlans_rule[vid]) {\n\t\t\tmlx5_del_flow_rules(fs->vlan->active_cvlans_rule[vid]);\n\t\t\tfs->vlan->active_cvlans_rule[vid] = NULL;\n\t\t}\n\t\tmlx5e_vport_context_update_vlans(fs);\n\t\tbreak;\n\t}\n}\n\nstatic void mlx5e_fs_del_any_vid_rules(struct mlx5e_flow_steering *fs)\n{\n\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_ANY_CTAG_VID, 0);\n\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_ANY_STAG_VID, 0);\n}\n\nstatic int mlx5e_fs_add_any_vid_rules(struct mlx5e_flow_steering *fs)\n{\n\tint err;\n\n\terr = mlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_ANY_CTAG_VID, 0);\n\tif (err)\n\t\treturn err;\n\n\treturn mlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_ANY_STAG_VID, 0);\n}\n\nstatic struct mlx5_flow_handle *\nmlx5e_add_trap_rule(struct mlx5_flow_table *ft, int trap_id, int tir_num)\n{\n\tstruct mlx5_flow_destination dest = {};\n\tMLX5_DECLARE_FLOW_ACT(flow_act);\n\tstruct mlx5_flow_handle *rule;\n\tstruct mlx5_flow_spec *spec;\n\n\tspec = kvzalloc(sizeof(*spec), GFP_KERNEL);\n\tif (!spec)\n\t\treturn ERR_PTR(-ENOMEM);\n\tspec->flow_context.flags |= FLOW_CONTEXT_HAS_TAG;\n\tspec->flow_context.flow_tag = trap_id;\n\tdest.type = MLX5_FLOW_DESTINATION_TYPE_TIR;\n\tdest.tir_num = tir_num;\n\n\trule = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1);\n\tkvfree(spec);\n\treturn rule;\n}\n\nint mlx5e_add_vlan_trap(struct mlx5e_flow_steering *fs, int trap_id, int tir_num)\n{\n\tstruct mlx5_flow_table *ft = fs->vlan->ft.t;\n\tstruct mlx5_flow_handle *rule;\n\tint err;\n\n\trule = mlx5e_add_trap_rule(ft, trap_id, tir_num);\n\tif (IS_ERR(rule)) {\n\t\terr = PTR_ERR(rule);\n\t\tfs->vlan->trap_rule = NULL;\n\t\tfs_err(fs, \"add VLAN trap rule failed, err %d\\n\", err);\n\t\treturn err;\n\t}\n\tfs->vlan->trap_rule = rule;\n\treturn 0;\n}\n\nvoid mlx5e_remove_vlan_trap(struct mlx5e_flow_steering *fs)\n{\n\tif (fs->vlan->trap_rule) {\n\t\tmlx5_del_flow_rules(fs->vlan->trap_rule);\n\t\tfs->vlan->trap_rule = NULL;\n\t}\n}\n\nint mlx5e_add_mac_trap(struct mlx5e_flow_steering *fs, int trap_id, int tir_num)\n{\n\tstruct mlx5_flow_table *ft = fs->l2.ft.t;\n\tstruct mlx5_flow_handle *rule;\n\tint err;\n\n\trule = mlx5e_add_trap_rule(ft, trap_id, tir_num);\n\tif (IS_ERR(rule)) {\n\t\terr = PTR_ERR(rule);\n\t\tfs->l2.trap_rule = NULL;\n\t\tfs_err(fs, \"add MAC trap rule failed, err %d\\n\", err);\n\t\treturn err;\n\t}\n\tfs->l2.trap_rule = rule;\n\treturn 0;\n}\n\nvoid mlx5e_remove_mac_trap(struct mlx5e_flow_steering *fs)\n{\n\tif (fs->l2.trap_rule) {\n\t\tmlx5_del_flow_rules(fs->l2.trap_rule);\n\t\tfs->l2.trap_rule = NULL;\n\t}\n}\n\nvoid mlx5e_enable_cvlan_filter(struct mlx5e_flow_steering *fs, bool promisc)\n{\n\tif (!fs->vlan->cvlan_filter_disabled)\n\t\treturn;\n\n\tfs->vlan->cvlan_filter_disabled = false;\n\tif (promisc)\n\t\treturn;\n\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_ANY_CTAG_VID, 0);\n}\n\nvoid mlx5e_disable_cvlan_filter(struct mlx5e_flow_steering *fs, bool promisc)\n{\n\tif (!fs->vlan || fs->vlan->cvlan_filter_disabled)\n\t\treturn;\n\n\tfs->vlan->cvlan_filter_disabled = true;\n\tif (promisc)\n\t\treturn;\n\tmlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_ANY_CTAG_VID, 0);\n}\n\nstatic int mlx5e_vlan_rx_add_cvid(struct mlx5e_flow_steering *fs, u16 vid)\n{\n\tint err;\n\n\tset_bit(vid, fs->vlan->active_cvlans);\n\n\terr = mlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_CTAG_VID, vid);\n\tif (err)\n\t\tclear_bit(vid, fs->vlan->active_cvlans);\n\n\treturn err;\n}\n\nstatic int mlx5e_vlan_rx_add_svid(struct mlx5e_flow_steering *fs,\n\t\t\t\t  struct net_device *netdev, u16 vid)\n{\n\tint err;\n\n\tset_bit(vid, fs->vlan->active_svlans);\n\n\terr = mlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_STAG_VID, vid);\n\tif (err) {\n\t\tclear_bit(vid, fs->vlan->active_svlans);\n\t\treturn err;\n\t}\n\n\t \n\tnetdev_update_features(netdev);\n\treturn err;\n}\n\nint mlx5e_fs_vlan_rx_add_vid(struct mlx5e_flow_steering *fs,\n\t\t\t     struct net_device *netdev,\n\t\t\t     __be16 proto, u16 vid)\n{\n\n\tif (!fs->vlan) {\n\t\tfs_err(fs, \"Vlan doesn't exist\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (be16_to_cpu(proto) == ETH_P_8021Q)\n\t\treturn mlx5e_vlan_rx_add_cvid(fs, vid);\n\telse if (be16_to_cpu(proto) == ETH_P_8021AD)\n\t\treturn mlx5e_vlan_rx_add_svid(fs, netdev, vid);\n\n\treturn -EOPNOTSUPP;\n}\n\nint mlx5e_fs_vlan_rx_kill_vid(struct mlx5e_flow_steering *fs,\n\t\t\t      struct net_device *netdev,\n\t\t\t      __be16 proto, u16 vid)\n{\n\tif (!fs->vlan) {\n\t\tfs_err(fs, \"Vlan doesn't exist\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (be16_to_cpu(proto) == ETH_P_8021Q) {\n\t\tclear_bit(vid, fs->vlan->active_cvlans);\n\t\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_CTAG_VID, vid);\n\t} else if (be16_to_cpu(proto) == ETH_P_8021AD) {\n\t\tclear_bit(vid, fs->vlan->active_svlans);\n\t\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_STAG_VID, vid);\n\t\tnetdev_update_features(netdev);\n\t}\n\n\treturn 0;\n}\n\nstatic void mlx5e_fs_add_vlan_rules(struct mlx5e_flow_steering *fs)\n{\n\tint i;\n\n\tmlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_UNTAGGED, 0);\n\n\tfor_each_set_bit(i, fs->vlan->active_cvlans, VLAN_N_VID) {\n\t\tmlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_CTAG_VID, i);\n\t}\n\n\tfor_each_set_bit(i, fs->vlan->active_svlans, VLAN_N_VID)\n\t\tmlx5e_add_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_STAG_VID, i);\n\n\tif (fs->vlan->cvlan_filter_disabled)\n\t\tmlx5e_fs_add_any_vid_rules(fs);\n}\n\nstatic void mlx5e_del_vlan_rules(struct mlx5e_flow_steering *fs)\n{\n\tint i;\n\n\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_UNTAGGED, 0);\n\n\tfor_each_set_bit(i, fs->vlan->active_cvlans, VLAN_N_VID) {\n\t\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_CTAG_VID, i);\n\t}\n\n\tfor_each_set_bit(i, fs->vlan->active_svlans, VLAN_N_VID)\n\t\tmlx5e_fs_del_vlan_rule(fs, MLX5E_VLAN_RULE_TYPE_MATCH_STAG_VID, i);\n\n\tWARN_ON_ONCE(fs->state_destroy);\n\n\tmlx5e_remove_vlan_trap(fs);\n\n\t \n\tif (fs->vlan->cvlan_filter_disabled)\n\t\tmlx5e_fs_del_any_vid_rules(fs);\n}\n\n#define mlx5e_for_each_hash_node(hn, tmp, hash, i) \\\n\tfor (i = 0; i < MLX5E_L2_ADDR_HASH_SIZE; i++) \\\n\t\thlist_for_each_entry_safe(hn, tmp, &hash[i], hlist)\n\nstatic void mlx5e_execute_l2_action(struct mlx5e_flow_steering *fs,\n\t\t\t\t    struct mlx5e_l2_hash_node *hn)\n{\n\tu8 action = hn->action;\n\tu8 mac_addr[ETH_ALEN];\n\tint l2_err = 0;\n\n\tether_addr_copy(mac_addr, hn->ai.addr);\n\n\tswitch (action) {\n\tcase MLX5E_ACTION_ADD:\n\t\tmlx5e_add_l2_flow_rule(fs, &hn->ai, MLX5E_FULLMATCH);\n\t\tif (!is_multicast_ether_addr(mac_addr)) {\n\t\t\tl2_err = mlx5_mpfs_add_mac(fs->mdev, mac_addr);\n\t\t\thn->mpfs = !l2_err;\n\t\t}\n\t\thn->action = MLX5E_ACTION_NONE;\n\t\tbreak;\n\n\tcase MLX5E_ACTION_DEL:\n\t\tif (!is_multicast_ether_addr(mac_addr) && hn->mpfs)\n\t\t\tl2_err = mlx5_mpfs_del_mac(fs->mdev, mac_addr);\n\t\tmlx5e_del_l2_flow_rule(fs, &hn->ai);\n\t\tmlx5e_del_l2_from_hash(hn);\n\t\tbreak;\n\t}\n\n\tif (l2_err)\n\t\tfs_warn(fs, \"MPFS, failed to %s mac %pM, err(%d)\\n\",\n\t\t\taction == MLX5E_ACTION_ADD ? \"add\" : \"del\",\n\t\t\tmac_addr, l2_err);\n}\n\nstatic void mlx5e_sync_netdev_addr(struct mlx5e_flow_steering *fs,\n\t\t\t\t   struct net_device *netdev)\n{\n\tstruct netdev_hw_addr *ha;\n\n\tnetif_addr_lock_bh(netdev);\n\n\tmlx5e_add_l2_to_hash(fs->l2.netdev_uc, netdev->dev_addr);\n\tnetdev_for_each_uc_addr(ha, netdev)\n\t\tmlx5e_add_l2_to_hash(fs->l2.netdev_uc, ha->addr);\n\n\tnetdev_for_each_mc_addr(ha, netdev)\n\t\tmlx5e_add_l2_to_hash(fs->l2.netdev_mc, ha->addr);\n\n\tnetif_addr_unlock_bh(netdev);\n}\n\nstatic void mlx5e_fill_addr_array(struct mlx5e_flow_steering *fs, int list_type,\n\t\t\t\t  struct net_device *ndev,\n\t\t\t\t  u8 addr_array[][ETH_ALEN], int size)\n{\n\tbool is_uc = (list_type == MLX5_NVPRT_LIST_TYPE_UC);\n\tstruct mlx5e_l2_hash_node *hn;\n\tstruct hlist_head *addr_list;\n\tstruct hlist_node *tmp;\n\tint i = 0;\n\tint hi;\n\n\taddr_list = is_uc ? fs->l2.netdev_uc : fs->l2.netdev_mc;\n\n\tif (is_uc)  \n\t\tether_addr_copy(addr_array[i++], ndev->dev_addr);\n\telse if (fs->l2.broadcast_enabled)\n\t\tether_addr_copy(addr_array[i++], ndev->broadcast);\n\n\tmlx5e_for_each_hash_node(hn, tmp, addr_list, hi) {\n\t\tif (ether_addr_equal(ndev->dev_addr, hn->ai.addr))\n\t\t\tcontinue;\n\t\tif (i >= size)\n\t\t\tbreak;\n\t\tether_addr_copy(addr_array[i++], hn->ai.addr);\n\t}\n}\n\nstatic void mlx5e_vport_context_update_addr_list(struct mlx5e_flow_steering *fs,\n\t\t\t\t\t\t struct net_device *netdev,\n\t\t\t\t\t\t int list_type)\n{\n\tbool is_uc = (list_type == MLX5_NVPRT_LIST_TYPE_UC);\n\tstruct mlx5e_l2_hash_node *hn;\n\tu8 (*addr_array)[ETH_ALEN] = NULL;\n\tstruct hlist_head *addr_list;\n\tstruct hlist_node *tmp;\n\tint max_size;\n\tint size;\n\tint err;\n\tint hi;\n\n\tsize = is_uc ? 0 : (fs->l2.broadcast_enabled ? 1 : 0);\n\tmax_size = is_uc ?\n\t\t1 << MLX5_CAP_GEN(fs->mdev, log_max_current_uc_list) :\n\t\t1 << MLX5_CAP_GEN(fs->mdev, log_max_current_mc_list);\n\n\taddr_list = is_uc ? fs->l2.netdev_uc : fs->l2.netdev_mc;\n\tmlx5e_for_each_hash_node(hn, tmp, addr_list, hi)\n\t\tsize++;\n\n\tif (size > max_size) {\n\t\tfs_warn(fs, \"mdev %s list size (%d) > (%d) max vport list size, some addresses will be dropped\\n\",\n\t\t\tis_uc ? \"UC\" : \"MC\", size, max_size);\n\t\tsize = max_size;\n\t}\n\n\tif (size) {\n\t\taddr_array = kcalloc(size, ETH_ALEN, GFP_KERNEL);\n\t\tif (!addr_array) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tmlx5e_fill_addr_array(fs, list_type, netdev, addr_array, size);\n\t}\n\n\terr = mlx5_modify_nic_vport_mac_list(fs->mdev, list_type, addr_array, size);\nout:\n\tif (err)\n\t\tfs_err(fs, \"Failed to modify vport %s list err(%d)\\n\",\n\t\t       is_uc ? \"UC\" : \"MC\", err);\n\tkfree(addr_array);\n}\n\nstatic void mlx5e_vport_context_update(struct mlx5e_flow_steering *fs,\n\t\t\t\t       struct net_device *netdev)\n{\n\tstruct mlx5e_l2_table *ea = &fs->l2;\n\n\tmlx5e_vport_context_update_addr_list(fs, netdev, MLX5_NVPRT_LIST_TYPE_UC);\n\tmlx5e_vport_context_update_addr_list(fs, netdev, MLX5_NVPRT_LIST_TYPE_MC);\n\tmlx5_modify_nic_vport_promisc(fs->mdev, 0,\n\t\t\t\t      ea->allmulti_enabled,\n\t\t\t\t      ea->promisc_enabled);\n}\n\nstatic void mlx5e_apply_netdev_addr(struct mlx5e_flow_steering *fs)\n{\n\tstruct mlx5e_l2_hash_node *hn;\n\tstruct hlist_node *tmp;\n\tint i;\n\n\tmlx5e_for_each_hash_node(hn, tmp, fs->l2.netdev_uc, i)\n\t\tmlx5e_execute_l2_action(fs, hn);\n\n\tmlx5e_for_each_hash_node(hn, tmp, fs->l2.netdev_mc, i)\n\t\tmlx5e_execute_l2_action(fs, hn);\n}\n\nstatic void mlx5e_handle_netdev_addr(struct mlx5e_flow_steering *fs,\n\t\t\t\t     struct net_device *netdev)\n{\n\tstruct mlx5e_l2_hash_node *hn;\n\tstruct hlist_node *tmp;\n\tint i;\n\n\tmlx5e_for_each_hash_node(hn, tmp, fs->l2.netdev_uc, i)\n\t\thn->action = MLX5E_ACTION_DEL;\n\tmlx5e_for_each_hash_node(hn, tmp, fs->l2.netdev_mc, i)\n\t\thn->action = MLX5E_ACTION_DEL;\n\n\tif (fs->state_destroy)\n\t\tmlx5e_sync_netdev_addr(fs, netdev);\n\n\tmlx5e_apply_netdev_addr(fs);\n}\n\n#define MLX5E_PROMISC_GROUP0_SIZE BIT(0)\n#define MLX5E_PROMISC_TABLE_SIZE MLX5E_PROMISC_GROUP0_SIZE\n\nstatic int mlx5e_add_promisc_rule(struct mlx5e_flow_steering *fs)\n{\n\tstruct mlx5_flow_table *ft = fs->promisc.ft.t;\n\tstruct mlx5_flow_destination dest = {};\n\tstruct mlx5_flow_handle **rule_p;\n\tMLX5_DECLARE_FLOW_ACT(flow_act);\n\tstruct mlx5_flow_spec *spec;\n\tint err = 0;\n\n\tspec = kvzalloc(sizeof(*spec), GFP_KERNEL);\n\tif (!spec)\n\t\treturn -ENOMEM;\n\tdest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\n\tdest.ft = mlx5_get_ttc_flow_table(fs->ttc);\n\n\trule_p = &fs->promisc.rule;\n\t*rule_p = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1);\n\tif (IS_ERR(*rule_p)) {\n\t\terr = PTR_ERR(*rule_p);\n\t\t*rule_p = NULL;\n\t\tfs_err(fs, \"add promiscuous rule failed\\n\");\n\t}\n\tkvfree(spec);\n\treturn err;\n}\n\nstatic int mlx5e_create_promisc_table(struct mlx5e_flow_steering *fs)\n{\n\tstruct mlx5e_flow_table *ft = &fs->promisc.ft;\n\tstruct mlx5_flow_table_attr ft_attr = {};\n\tint err;\n\n\tft_attr.max_fte = MLX5E_PROMISC_TABLE_SIZE;\n\tft_attr.autogroup.max_num_groups = 1;\n\tft_attr.level = MLX5E_PROMISC_FT_LEVEL;\n\tft_attr.prio = MLX5E_NIC_PRIO;\n\n\tft->t = mlx5_create_auto_grouped_flow_table(fs->ns, &ft_attr);\n\tif (IS_ERR(ft->t)) {\n\t\terr = PTR_ERR(ft->t);\n\t\tft->t = NULL;\n\t\tfs_err(fs, \"fail to create promisc table err=%d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = mlx5e_add_promisc_rule(fs);\n\tif (err)\n\t\tgoto err_destroy_promisc_table;\n\n\treturn 0;\n\nerr_destroy_promisc_table:\n\tmlx5_destroy_flow_table(ft->t);\n\tft->t = NULL;\n\n\treturn err;\n}\n\nstatic void mlx5e_del_promisc_rule(struct mlx5e_flow_steering *fs)\n{\n\tif (WARN(!fs->promisc.rule, \"Trying to remove non-existing promiscuous rule\"))\n\t\treturn;\n\tmlx5_del_flow_rules(fs->promisc.rule);\n\tfs->promisc.rule = NULL;\n}\n\nstatic void mlx5e_destroy_promisc_table(struct mlx5e_flow_steering *fs)\n{\n\tif (!fs->promisc.ft.t)\n\t\treturn;\n\tmlx5e_del_promisc_rule(fs);\n\tmlx5_destroy_flow_table(fs->promisc.ft.t);\n\tfs->promisc.ft.t = NULL;\n}\n\nvoid mlx5e_fs_set_rx_mode_work(struct mlx5e_flow_steering *fs,\n\t\t\t       struct net_device *netdev)\n{\n\tstruct mlx5e_l2_table *ea = &fs->l2;\n\n\tbool rx_mode_enable  = fs->state_destroy;\n\tbool promisc_enabled   = rx_mode_enable && (netdev->flags & IFF_PROMISC);\n\tbool allmulti_enabled  = rx_mode_enable && (netdev->flags & IFF_ALLMULTI);\n\tbool broadcast_enabled = rx_mode_enable;\n\n\tbool enable_promisc    = !ea->promisc_enabled   &&  promisc_enabled;\n\tbool disable_promisc   =  ea->promisc_enabled   && !promisc_enabled;\n\tbool enable_allmulti   = !ea->allmulti_enabled  &&  allmulti_enabled;\n\tbool disable_allmulti  =  ea->allmulti_enabled  && !allmulti_enabled;\n\tbool enable_broadcast  = !ea->broadcast_enabled &&  broadcast_enabled;\n\tbool disable_broadcast =  ea->broadcast_enabled && !broadcast_enabled;\n\tint err;\n\n\tif (enable_promisc) {\n\t\terr = mlx5e_create_promisc_table(fs);\n\t\tif (err)\n\t\t\tenable_promisc = false;\n\t\tif (!fs->vlan_strip_disable && !err)\n\t\t\tfs_warn_once(fs,\n\t\t\t\t     \"S-tagged traffic will be dropped while C-tag vlan stripping is enabled\\n\");\n\t}\n\tif (enable_allmulti)\n\t\tmlx5e_add_l2_flow_rule(fs, &ea->allmulti, MLX5E_ALLMULTI);\n\tif (enable_broadcast)\n\t\tmlx5e_add_l2_flow_rule(fs, &ea->broadcast, MLX5E_FULLMATCH);\n\n\tmlx5e_handle_netdev_addr(fs, netdev);\n\n\tif (disable_broadcast)\n\t\tmlx5e_del_l2_flow_rule(fs, &ea->broadcast);\n\tif (disable_allmulti)\n\t\tmlx5e_del_l2_flow_rule(fs, &ea->allmulti);\n\tif (disable_promisc)\n\t\tmlx5e_destroy_promisc_table(fs);\n\n\tea->promisc_enabled   = promisc_enabled;\n\tea->allmulti_enabled  = allmulti_enabled;\n\tea->broadcast_enabled = broadcast_enabled;\n\n\tmlx5e_vport_context_update(fs, netdev);\n}\n\nstatic void mlx5e_destroy_groups(struct mlx5e_flow_table *ft)\n{\n\tint i;\n\n\tfor (i = ft->num_groups - 1; i >= 0; i--) {\n\t\tif (!IS_ERR_OR_NULL(ft->g[i]))\n\t\t\tmlx5_destroy_flow_group(ft->g[i]);\n\t\tft->g[i] = NULL;\n\t}\n\tft->num_groups = 0;\n}\n\nvoid mlx5e_fs_init_l2_addr(struct mlx5e_flow_steering *fs, struct net_device *netdev)\n{\n\tether_addr_copy(fs->l2.broadcast.addr, netdev->broadcast);\n}\n\nvoid mlx5e_destroy_flow_table(struct mlx5e_flow_table *ft)\n{\n\tmlx5e_destroy_groups(ft);\n\tkfree(ft->g);\n\tmlx5_destroy_flow_table(ft->t);\n\tft->t = NULL;\n}\n\nstatic void mlx5e_set_inner_ttc_params(struct mlx5e_flow_steering *fs,\n\t\t\t\t       struct mlx5e_rx_res *rx_res,\n\t\t\t\t       struct ttc_params *ttc_params)\n{\n\tstruct mlx5_flow_table_attr *ft_attr = &ttc_params->ft_attr;\n\tint tt;\n\n\tmemset(ttc_params, 0, sizeof(*ttc_params));\n\tttc_params->ns = mlx5_get_flow_namespace(fs->mdev,\n\t\t\t\t\t\t MLX5_FLOW_NAMESPACE_KERNEL);\n\tft_attr->level = MLX5E_INNER_TTC_FT_LEVEL;\n\tft_attr->prio = MLX5E_NIC_PRIO;\n\n\tfor (tt = 0; tt < MLX5_NUM_TT; tt++) {\n\t\tttc_params->dests[tt].type = MLX5_FLOW_DESTINATION_TYPE_TIR;\n\t\tttc_params->dests[tt].tir_num =\n\t\t\ttt == MLX5_TT_ANY ?\n\t\t\t\tmlx5e_rx_res_get_tirn_direct(rx_res, 0) :\n\t\t\t\tmlx5e_rx_res_get_tirn_rss_inner(rx_res,\n\t\t\t\t\t\t\t\ttt);\n\t}\n}\n\nvoid mlx5e_set_ttc_params(struct mlx5e_flow_steering *fs,\n\t\t\t  struct mlx5e_rx_res *rx_res,\n\t\t\t  struct ttc_params *ttc_params, bool tunnel)\n\n{\n\tstruct mlx5_flow_table_attr *ft_attr = &ttc_params->ft_attr;\n\tint tt;\n\n\tmemset(ttc_params, 0, sizeof(*ttc_params));\n\tttc_params->ns = mlx5_get_flow_namespace(fs->mdev,\n\t\t\t\t\t\t MLX5_FLOW_NAMESPACE_KERNEL);\n\tft_attr->level = MLX5E_TTC_FT_LEVEL;\n\tft_attr->prio = MLX5E_NIC_PRIO;\n\n\tfor (tt = 0; tt < MLX5_NUM_TT; tt++) {\n\t\tttc_params->dests[tt].type = MLX5_FLOW_DESTINATION_TYPE_TIR;\n\t\tttc_params->dests[tt].tir_num =\n\t\t\ttt == MLX5_TT_ANY ?\n\t\t\t\tmlx5e_rx_res_get_tirn_direct(rx_res, 0) :\n\t\t\t\tmlx5e_rx_res_get_tirn_rss(rx_res, tt);\n\t}\n\n\tttc_params->inner_ttc = tunnel;\n\tif (!tunnel || !mlx5_tunnel_inner_ft_supported(fs->mdev))\n\t\treturn;\n\n\tfor (tt = 0; tt < MLX5_NUM_TUNNEL_TT; tt++) {\n\t\tttc_params->tunnel_dests[tt].type =\n\t\t\tMLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\n\t\tttc_params->tunnel_dests[tt].ft =\n\t\t\tmlx5_get_ttc_flow_table(fs->inner_ttc);\n\t}\n}\n\nstatic void mlx5e_del_l2_flow_rule(struct mlx5e_flow_steering *fs,\n\t\t\t\t   struct mlx5e_l2_rule *ai)\n{\n\tif (!IS_ERR_OR_NULL(ai->rule)) {\n\t\tmlx5_del_flow_rules(ai->rule);\n\t\tai->rule = NULL;\n\t}\n}\n\nstatic int mlx5e_add_l2_flow_rule(struct mlx5e_flow_steering *fs,\n\t\t\t\t  struct mlx5e_l2_rule *ai, int type)\n{\n\tstruct mlx5_flow_table *ft = fs->l2.ft.t;\n\tstruct mlx5_flow_destination dest = {};\n\tMLX5_DECLARE_FLOW_ACT(flow_act);\n\tstruct mlx5_flow_spec *spec;\n\tint err = 0;\n\tu8 *mc_dmac;\n\tu8 *mv_dmac;\n\n\tspec = kvzalloc(sizeof(*spec), GFP_KERNEL);\n\tif (!spec)\n\t\treturn -ENOMEM;\n\n\tmc_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,\n\t\t\t       outer_headers.dmac_47_16);\n\tmv_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_value,\n\t\t\t       outer_headers.dmac_47_16);\n\n\tdest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\n\tdest.ft = mlx5_get_ttc_flow_table(fs->ttc);\n\n\tswitch (type) {\n\tcase MLX5E_FULLMATCH:\n\t\tspec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;\n\t\teth_broadcast_addr(mc_dmac);\n\t\tether_addr_copy(mv_dmac, ai->addr);\n\t\tbreak;\n\n\tcase MLX5E_ALLMULTI:\n\t\tspec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;\n\t\tmc_dmac[0] = 0x01;\n\t\tmv_dmac[0] = 0x01;\n\t\tbreak;\n\t}\n\n\tai->rule = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1);\n\tif (IS_ERR(ai->rule)) {\n\t\tfs_err(fs, \"add l2 rule(mac:%pM) failed\\n\", mv_dmac);\n\t\terr = PTR_ERR(ai->rule);\n\t\tai->rule = NULL;\n\t}\n\n\tkvfree(spec);\n\n\treturn err;\n}\n\n#define MLX5E_NUM_L2_GROUPS\t   3\n#define MLX5E_L2_GROUP1_SIZE\t   BIT(15)\n#define MLX5E_L2_GROUP2_SIZE\t   BIT(0)\n#define MLX5E_L2_GROUP_TRAP_SIZE   BIT(0)  \n#define MLX5E_L2_TABLE_SIZE\t   (MLX5E_L2_GROUP1_SIZE +\\\n\t\t\t\t    MLX5E_L2_GROUP2_SIZE +\\\n\t\t\t\t    MLX5E_L2_GROUP_TRAP_SIZE)\nstatic int mlx5e_create_l2_table_groups(struct mlx5e_l2_table *l2_table)\n{\n\tint inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);\n\tstruct mlx5e_flow_table *ft = &l2_table->ft;\n\tint ix = 0;\n\tu8 *mc_dmac;\n\tu32 *in;\n\tint err;\n\tu8 *mc;\n\n\tft->g = kcalloc(MLX5E_NUM_L2_GROUPS, sizeof(*ft->g), GFP_KERNEL);\n\tif (!ft->g)\n\t\treturn -ENOMEM;\n\tin = kvzalloc(inlen, GFP_KERNEL);\n\tif (!in) {\n\t\tkfree(ft->g);\n\t\treturn -ENOMEM;\n\t}\n\n\tmc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);\n\tmc_dmac = MLX5_ADDR_OF(fte_match_param, mc,\n\t\t\t       outer_headers.dmac_47_16);\n\t \n\teth_broadcast_addr(mc_dmac);\n\tMLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_L2_GROUP1_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\t \n\teth_zero_addr(mc_dmac);\n\tmc_dmac[0] = 0x01;\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_L2_GROUP2_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\t \n\tmemset(in, 0, inlen);\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_L2_GROUP_TRAP_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\tkvfree(in);\n\treturn 0;\n\nerr_destroy_groups:\n\terr = PTR_ERR(ft->g[ft->num_groups]);\n\tft->g[ft->num_groups] = NULL;\n\tmlx5e_destroy_groups(ft);\n\tkvfree(in);\n\tkfree(ft->g);\n\n\treturn err;\n}\n\nstatic void mlx5e_destroy_l2_table(struct mlx5e_flow_steering *fs)\n{\n\tmlx5e_destroy_flow_table(&fs->l2.ft);\n}\n\nstatic int mlx5e_create_l2_table(struct mlx5e_flow_steering *fs)\n{\n\tstruct mlx5e_l2_table *l2_table = &fs->l2;\n\tstruct mlx5e_flow_table *ft = &l2_table->ft;\n\tstruct mlx5_flow_table_attr ft_attr = {};\n\tint err;\n\n\tft->num_groups = 0;\n\n\tft_attr.max_fte = MLX5E_L2_TABLE_SIZE;\n\tft_attr.level = MLX5E_L2_FT_LEVEL;\n\tft_attr.prio = MLX5E_NIC_PRIO;\n\n\tft->t = mlx5_create_flow_table(fs->ns, &ft_attr);\n\tif (IS_ERR(ft->t)) {\n\t\terr = PTR_ERR(ft->t);\n\t\tft->t = NULL;\n\t\treturn err;\n\t}\n\n\terr = mlx5e_create_l2_table_groups(l2_table);\n\tif (err)\n\t\tgoto err_destroy_flow_table;\n\n\treturn 0;\n\nerr_destroy_flow_table:\n\tmlx5_destroy_flow_table(ft->t);\n\tft->t = NULL;\n\n\treturn err;\n}\n\n#define MLX5E_NUM_VLAN_GROUPS\t5\n#define MLX5E_VLAN_GROUP0_SIZE\tBIT(12)\n#define MLX5E_VLAN_GROUP1_SIZE\tBIT(12)\n#define MLX5E_VLAN_GROUP2_SIZE\tBIT(1)\n#define MLX5E_VLAN_GROUP3_SIZE\tBIT(0)\n#define MLX5E_VLAN_GROUP_TRAP_SIZE BIT(0)  \n#define MLX5E_VLAN_TABLE_SIZE\t(MLX5E_VLAN_GROUP0_SIZE +\\\n\t\t\t\t MLX5E_VLAN_GROUP1_SIZE +\\\n\t\t\t\t MLX5E_VLAN_GROUP2_SIZE +\\\n\t\t\t\t MLX5E_VLAN_GROUP3_SIZE +\\\n\t\t\t\t MLX5E_VLAN_GROUP_TRAP_SIZE)\n\nstatic int __mlx5e_create_vlan_table_groups(struct mlx5e_flow_table *ft, u32 *in,\n\t\t\t\t\t    int inlen)\n{\n\tint err;\n\tint ix = 0;\n\tu8 *mc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);\n\n\tmemset(in, 0, inlen);\n\tMLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);\n\tMLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.cvlan_tag);\n\tMLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.first_vid);\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_VLAN_GROUP0_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\tmemset(in, 0, inlen);\n\tMLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);\n\tMLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.svlan_tag);\n\tMLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.first_vid);\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_VLAN_GROUP1_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\tmemset(in, 0, inlen);\n\tMLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);\n\tMLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.cvlan_tag);\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_VLAN_GROUP2_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\tmemset(in, 0, inlen);\n\tMLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);\n\tMLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.svlan_tag);\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_VLAN_GROUP3_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\tmemset(in, 0, inlen);\n\tMLX5_SET_CFG(in, start_flow_index, ix);\n\tix += MLX5E_VLAN_GROUP_TRAP_SIZE;\n\tMLX5_SET_CFG(in, end_flow_index, ix - 1);\n\tft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\n\tif (IS_ERR(ft->g[ft->num_groups]))\n\t\tgoto err_destroy_groups;\n\tft->num_groups++;\n\n\treturn 0;\n\nerr_destroy_groups:\n\terr = PTR_ERR(ft->g[ft->num_groups]);\n\tft->g[ft->num_groups] = NULL;\n\tmlx5e_destroy_groups(ft);\n\n\treturn err;\n}\n\nstatic int mlx5e_create_vlan_table_groups(struct mlx5e_flow_table *ft)\n{\n\tu32 *in;\n\tint inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);\n\tint err;\n\n\tin = kvzalloc(inlen, GFP_KERNEL);\n\tif (!in)\n\t\treturn -ENOMEM;\n\n\terr = __mlx5e_create_vlan_table_groups(ft, in, inlen);\n\n\tkvfree(in);\n\treturn err;\n}\n\nstatic int mlx5e_fs_create_vlan_table(struct mlx5e_flow_steering *fs)\n{\n\tstruct mlx5_flow_table_attr ft_attr = {};\n\tstruct mlx5e_flow_table *ft;\n\tint err;\n\n\tft = &fs->vlan->ft;\n\tft->num_groups = 0;\n\n\tft_attr.max_fte = MLX5E_VLAN_TABLE_SIZE;\n\tft_attr.level = MLX5E_VLAN_FT_LEVEL;\n\tft_attr.prio = MLX5E_NIC_PRIO;\n\n\tft->t = mlx5_create_flow_table(fs->ns, &ft_attr);\n\tif (IS_ERR(ft->t))\n\t\treturn PTR_ERR(ft->t);\n\n\tft->g = kcalloc(MLX5E_NUM_VLAN_GROUPS, sizeof(*ft->g), GFP_KERNEL);\n\tif (!ft->g) {\n\t\terr = -ENOMEM;\n\t\tgoto err_destroy_vlan_table;\n\t}\n\n\terr = mlx5e_create_vlan_table_groups(ft);\n\tif (err)\n\t\tgoto err_free_g;\n\n\tmlx5e_fs_add_vlan_rules(fs);\n\n\treturn 0;\n\nerr_free_g:\n\tkfree(ft->g);\nerr_destroy_vlan_table:\n\tmlx5_destroy_flow_table(ft->t);\n\n\treturn err;\n}\n\nstatic void mlx5e_destroy_vlan_table(struct mlx5e_flow_steering *fs)\n{\n\tmlx5e_del_vlan_rules(fs);\n\tmlx5e_destroy_flow_table(&fs->vlan->ft);\n}\n\nstatic void mlx5e_destroy_inner_ttc_table(struct mlx5e_flow_steering *fs)\n{\n\tif (!mlx5_tunnel_inner_ft_supported(fs->mdev))\n\t\treturn;\n\tmlx5_destroy_ttc_table(fs->inner_ttc);\n}\n\nvoid mlx5e_destroy_ttc_table(struct mlx5e_flow_steering *fs)\n{\n\tmlx5_destroy_ttc_table(fs->ttc);\n}\n\nstatic int mlx5e_create_inner_ttc_table(struct mlx5e_flow_steering *fs,\n\t\t\t\t\tstruct mlx5e_rx_res *rx_res)\n{\n\tstruct ttc_params ttc_params = {};\n\n\tif (!mlx5_tunnel_inner_ft_supported(fs->mdev))\n\t\treturn 0;\n\n\tmlx5e_set_inner_ttc_params(fs, rx_res, &ttc_params);\n\tfs->inner_ttc = mlx5_create_inner_ttc_table(fs->mdev,\n\t\t\t\t\t\t    &ttc_params);\n\tif (IS_ERR(fs->inner_ttc))\n\t\treturn PTR_ERR(fs->inner_ttc);\n\treturn 0;\n}\n\nint mlx5e_create_ttc_table(struct mlx5e_flow_steering *fs,\n\t\t\t   struct mlx5e_rx_res *rx_res)\n{\n\tstruct ttc_params ttc_params = {};\n\n\tmlx5e_set_ttc_params(fs, rx_res, &ttc_params, true);\n\tfs->ttc = mlx5_create_ttc_table(fs->mdev, &ttc_params);\n\tif (IS_ERR(fs->ttc))\n\t\treturn PTR_ERR(fs->ttc);\n\treturn 0;\n}\n\nint mlx5e_create_flow_steering(struct mlx5e_flow_steering *fs,\n\t\t\t       struct mlx5e_rx_res *rx_res,\n\t\t\t       const struct mlx5e_profile *profile,\n\t\t\t       struct net_device *netdev)\n{\n\tstruct mlx5_flow_namespace *ns = mlx5_get_flow_namespace(fs->mdev,\n\t\t\t\t\t\t\t\t MLX5_FLOW_NAMESPACE_KERNEL);\n\tint err;\n\n\tif (!ns)\n\t\treturn -EOPNOTSUPP;\n\n\tmlx5e_fs_set_ns(fs, ns, false);\n\terr = mlx5e_arfs_create_tables(fs, rx_res,\n\t\t\t\t       !!(netdev->hw_features & NETIF_F_NTUPLE));\n\tif (err) {\n\t\tfs_err(fs, \"Failed to create arfs tables, err=%d\\n\", err);\n\t\tnetdev->hw_features &= ~NETIF_F_NTUPLE;\n\t}\n\n\terr = mlx5e_create_inner_ttc_table(fs, rx_res);\n\tif (err) {\n\t\tfs_err(fs, \"Failed to create inner ttc table, err=%d\\n\", err);\n\t\tgoto err_destroy_arfs_tables;\n\t}\n\n\terr = mlx5e_create_ttc_table(fs, rx_res);\n\tif (err) {\n\t\tfs_err(fs, \"Failed to create ttc table, err=%d\\n\", err);\n\t\tgoto err_destroy_inner_ttc_table;\n\t}\n\n\terr = mlx5e_create_l2_table(fs);\n\tif (err) {\n\t\tfs_err(fs, \"Failed to create l2 table, err=%d\\n\", err);\n\t\tgoto err_destroy_ttc_table;\n\t}\n\n\terr = mlx5e_fs_create_vlan_table(fs);\n\tif (err) {\n\t\tfs_err(fs, \"Failed to create vlan table, err=%d\\n\", err);\n\t\tgoto err_destroy_l2_table;\n\t}\n\n\terr = mlx5e_ptp_alloc_rx_fs(fs, profile);\n\tif (err)\n\t\tgoto err_destory_vlan_table;\n\n\tmlx5e_ethtool_init_steering(fs);\n\n\treturn 0;\n\nerr_destory_vlan_table:\n\tmlx5e_destroy_vlan_table(fs);\nerr_destroy_l2_table:\n\tmlx5e_destroy_l2_table(fs);\nerr_destroy_ttc_table:\n\tmlx5e_destroy_ttc_table(fs);\nerr_destroy_inner_ttc_table:\n\tmlx5e_destroy_inner_ttc_table(fs);\nerr_destroy_arfs_tables:\n\tmlx5e_arfs_destroy_tables(fs, !!(netdev->hw_features & NETIF_F_NTUPLE));\n\n\treturn err;\n}\n\nvoid mlx5e_destroy_flow_steering(struct mlx5e_flow_steering *fs, bool ntuple,\n\t\t\t\t const struct mlx5e_profile *profile)\n{\n\tmlx5e_ptp_free_rx_fs(fs, profile);\n\tmlx5e_destroy_vlan_table(fs);\n\tmlx5e_destroy_l2_table(fs);\n\tmlx5e_destroy_ttc_table(fs);\n\tmlx5e_destroy_inner_ttc_table(fs);\n\tmlx5e_arfs_destroy_tables(fs, ntuple);\n\tmlx5e_ethtool_cleanup_steering(fs);\n}\n\nstatic int mlx5e_fs_vlan_alloc(struct mlx5e_flow_steering *fs)\n{\n\tfs->vlan = kvzalloc(sizeof(*fs->vlan), GFP_KERNEL);\n\tif (!fs->vlan)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void mlx5e_fs_vlan_free(struct mlx5e_flow_steering *fs)\n{\n\tkvfree(fs->vlan);\n}\n\nstruct mlx5e_vlan_table *mlx5e_fs_get_vlan(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->vlan;\n}\n\nstatic int mlx5e_fs_tc_alloc(struct mlx5e_flow_steering *fs)\n{\n\tfs->tc = mlx5e_tc_table_alloc();\n\tif (IS_ERR(fs->tc))\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void mlx5e_fs_tc_free(struct mlx5e_flow_steering *fs)\n{\n\tmlx5e_tc_table_free(fs->tc);\n}\n\nstruct mlx5e_tc_table *mlx5e_fs_get_tc(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->tc;\n}\n\n#ifdef CONFIG_MLX5_EN_RXNFC\nstatic int mlx5e_fs_ethtool_alloc(struct mlx5e_flow_steering *fs)\n{\n\treturn mlx5e_ethtool_alloc(&fs->ethtool);\n}\n\nstatic void mlx5e_fs_ethtool_free(struct mlx5e_flow_steering *fs)\n{\n\tmlx5e_ethtool_free(fs->ethtool);\n}\n\nstruct mlx5e_ethtool_steering *mlx5e_fs_get_ethtool(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->ethtool;\n}\n#else\nstatic int mlx5e_fs_ethtool_alloc(struct mlx5e_flow_steering *fs)\n{ return 0; }\nstatic void mlx5e_fs_ethtool_free(struct mlx5e_flow_steering *fs) { }\n#endif\n\nstatic void mlx5e_fs_debugfs_init(struct mlx5e_flow_steering *fs,\n\t\t\t\t  struct dentry *dfs_root)\n{\n\tif (IS_ERR_OR_NULL(dfs_root))\n\t\treturn;\n\n\tfs->dfs_root = debugfs_create_dir(\"fs\", dfs_root);\n}\n\nstruct mlx5e_flow_steering *mlx5e_fs_init(const struct mlx5e_profile *profile,\n\t\t\t\t\t  struct mlx5_core_dev *mdev,\n\t\t\t\t\t  bool state_destroy,\n\t\t\t\t\t  struct dentry *dfs_root)\n{\n\tstruct mlx5e_flow_steering *fs;\n\tint err;\n\n\tfs = kvzalloc(sizeof(*fs), GFP_KERNEL);\n\tif (!fs)\n\t\tgoto err;\n\n\tfs->mdev = mdev;\n\tfs->state_destroy = state_destroy;\n\tif (mlx5e_profile_feature_cap(profile, FS_VLAN)) {\n\t\terr = mlx5e_fs_vlan_alloc(fs);\n\t\tif (err)\n\t\t\tgoto err_free_fs;\n\t}\n\n\tif (mlx5e_profile_feature_cap(profile, FS_TC)) {\n\t\terr = mlx5e_fs_tc_alloc(fs);\n\t\tif (err)\n\t\t\tgoto err_free_vlan;\n\t}\n\n\terr = mlx5e_fs_ethtool_alloc(fs);\n\tif (err)\n\t\tgoto err_free_tc;\n\n\tmlx5e_fs_debugfs_init(fs, dfs_root);\n\n\treturn fs;\nerr_free_tc:\n\tmlx5e_fs_tc_free(fs);\nerr_free_vlan:\n\tmlx5e_fs_vlan_free(fs);\nerr_free_fs:\n\tkvfree(fs);\nerr:\n\treturn NULL;\n}\n\nvoid mlx5e_fs_cleanup(struct mlx5e_flow_steering *fs)\n{\n\tif (!fs)\n\t\treturn;\n\tdebugfs_remove_recursive(fs->dfs_root);\n\tmlx5e_fs_ethtool_free(fs);\n\tmlx5e_fs_tc_free(fs);\n\tmlx5e_fs_vlan_free(fs);\n\tkvfree(fs);\n}\n\nstruct mlx5e_l2_table *mlx5e_fs_get_l2(struct mlx5e_flow_steering *fs)\n{\n\treturn &fs->l2;\n}\n\nstruct mlx5_flow_namespace *mlx5e_fs_get_ns(struct mlx5e_flow_steering *fs, bool egress)\n{\n\treturn  egress ? fs->egress_ns : fs->ns;\n}\n\nvoid mlx5e_fs_set_ns(struct mlx5e_flow_steering *fs, struct mlx5_flow_namespace *ns, bool egress)\n{\n\tif (!egress)\n\t\tfs->ns = ns;\n\telse\n\t\tfs->egress_ns = ns;\n}\n\nstruct mlx5_ttc_table *mlx5e_fs_get_ttc(struct mlx5e_flow_steering *fs, bool inner)\n{\n\treturn inner ? fs->inner_ttc : fs->ttc;\n}\n\nvoid mlx5e_fs_set_ttc(struct mlx5e_flow_steering *fs, struct mlx5_ttc_table *ttc, bool inner)\n{\n\tif (!inner)\n\t\tfs->ttc = ttc;\n\telse\n\t\tfs->inner_ttc = ttc;\n}\n\n#ifdef CONFIG_MLX5_EN_ARFS\nstruct mlx5e_arfs_tables *mlx5e_fs_get_arfs(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->arfs;\n}\n\nvoid mlx5e_fs_set_arfs(struct mlx5e_flow_steering *fs, struct mlx5e_arfs_tables *arfs)\n{\n\tfs->arfs = arfs;\n}\n#endif\n\nstruct mlx5e_ptp_fs *mlx5e_fs_get_ptp(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->ptp_fs;\n}\n\nvoid mlx5e_fs_set_ptp(struct mlx5e_flow_steering *fs, struct mlx5e_ptp_fs *ptp_fs)\n{\n\tfs->ptp_fs = ptp_fs;\n}\n\nstruct mlx5e_fs_any *mlx5e_fs_get_any(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->any;\n}\n\nvoid mlx5e_fs_set_any(struct mlx5e_flow_steering *fs, struct mlx5e_fs_any *any)\n{\n\tfs->any = any;\n}\n\n#ifdef CONFIG_MLX5_EN_TLS\nstruct mlx5e_accel_fs_tcp *mlx5e_fs_get_accel_tcp(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->accel_tcp;\n}\n\nvoid mlx5e_fs_set_accel_tcp(struct mlx5e_flow_steering *fs, struct mlx5e_accel_fs_tcp *accel_tcp)\n{\n\tfs->accel_tcp = accel_tcp;\n}\n#endif\n\nvoid mlx5e_fs_set_state_destroy(struct mlx5e_flow_steering *fs, bool state_destroy)\n{\n\tfs->state_destroy = state_destroy;\n}\n\nvoid mlx5e_fs_set_vlan_strip_disable(struct mlx5e_flow_steering *fs,\n\t\t\t\t     bool vlan_strip_disable)\n{\n\tfs->vlan_strip_disable = vlan_strip_disable;\n}\n\nstruct mlx5e_fs_udp *mlx5e_fs_get_udp(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->udp;\n}\n\nvoid mlx5e_fs_set_udp(struct mlx5e_flow_steering *fs, struct mlx5e_fs_udp *udp)\n{\n\tfs->udp = udp;\n}\n\nstruct mlx5_core_dev *mlx5e_fs_get_mdev(struct mlx5e_flow_steering *fs)\n{\n\treturn fs->mdev;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}