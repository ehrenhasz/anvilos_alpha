{
  "module_name": "en_rep.c",
  "hash_id": "fb117bd3ceddf9f0819423400246b24b169ab9ed51a8f848a61f8743f939d965",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c",
  "human_readable_source": " \n\n#include <linux/debugfs.h>\n#include <linux/mlx5/fs.h>\n#include <net/switchdev.h>\n#include <net/pkt_cls.h>\n#include <net/act_api.h>\n#include <net/devlink.h>\n#include <net/ipv6_stubs.h>\n\n#include \"eswitch.h\"\n#include \"en.h\"\n#include \"en_rep.h\"\n#include \"en/params.h\"\n#include \"en/txrx.h\"\n#include \"en_tc.h\"\n#include \"en/rep/tc.h\"\n#include \"en/rep/neigh.h\"\n#include \"en/rep/bridge.h\"\n#include \"en/devlink.h\"\n#include \"fs_core.h\"\n#include \"lib/mlx5.h\"\n#include \"lib/devcom.h\"\n#include \"lib/vxlan.h\"\n#define CREATE_TRACE_POINTS\n#include \"diag/en_rep_tracepoint.h\"\n#include \"diag/reporter_vnic.h\"\n#include \"en_accel/ipsec.h\"\n#include \"en/tc/int_port.h\"\n#include \"en/ptp.h\"\n#include \"en/fs_ethtool.h\"\n\n#define MLX5E_REP_PARAMS_DEF_LOG_SQ_SIZE \\\n\tmax(0x7, MLX5E_PARAMS_MINIMUM_LOG_SQ_SIZE)\n#define MLX5E_REP_PARAMS_DEF_NUM_CHANNELS 1\n\nstatic const char mlx5e_rep_driver_name[] = \"mlx5e_rep\";\n\nstatic void mlx5e_rep_get_drvinfo(struct net_device *dev,\n\t\t\t\t  struct ethtool_drvinfo *drvinfo)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\tstruct mlx5_core_dev *mdev = priv->mdev;\n\tint count;\n\n\tstrscpy(drvinfo->driver, mlx5e_rep_driver_name,\n\t\tsizeof(drvinfo->driver));\n\tcount = snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),\n\t\t\t \"%d.%d.%04d (%.16s)\", fw_rev_maj(mdev),\n\t\t\t fw_rev_min(mdev), fw_rev_sub(mdev), mdev->board_id);\n\tif (count >= sizeof(drvinfo->fw_version))\n\t\tsnprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),\n\t\t\t \"%d.%d.%04d\", fw_rev_maj(mdev),\n\t\t\t fw_rev_min(mdev), fw_rev_sub(mdev));\n}\n\nstatic const struct counter_desc sw_rep_stats_desc[] = {\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_bytes) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_bytes) },\n};\n\nstatic const struct counter_desc vport_rep_stats_desc[] = {\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats, vport_rx_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats, vport_rx_bytes) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats, vport_tx_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats, vport_tx_bytes) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats,\n\t\t\t     rx_vport_rdma_unicast_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats, rx_vport_rdma_unicast_bytes) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats,\n\t\t\t     tx_vport_rdma_unicast_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats, tx_vport_rdma_unicast_bytes) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats,\n\t\t\t     rx_vport_rdma_multicast_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats,\n\t\t\t     rx_vport_rdma_multicast_bytes) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats,\n\t\t\t     tx_vport_rdma_multicast_packets) },\n\t{ MLX5E_DECLARE_STAT(struct mlx5e_rep_stats,\n\t\t\t     tx_vport_rdma_multicast_bytes) },\n};\n\n#define NUM_VPORT_REP_SW_COUNTERS ARRAY_SIZE(sw_rep_stats_desc)\n#define NUM_VPORT_REP_HW_COUNTERS ARRAY_SIZE(vport_rep_stats_desc)\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_NUM_STATS(sw_rep)\n{\n\treturn NUM_VPORT_REP_SW_COUNTERS;\n}\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_FILL_STRS(sw_rep)\n{\n\tint i;\n\n\tfor (i = 0; i < NUM_VPORT_REP_SW_COUNTERS; i++)\n\t\tstrcpy(data + (idx++) * ETH_GSTRING_LEN,\n\t\t       sw_rep_stats_desc[i].format);\n\treturn idx;\n}\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_FILL_STATS(sw_rep)\n{\n\tint i;\n\n\tfor (i = 0; i < NUM_VPORT_REP_SW_COUNTERS; i++)\n\t\tdata[idx++] = MLX5E_READ_CTR64_CPU(&priv->stats.sw,\n\t\t\t\t\t\t   sw_rep_stats_desc, i);\n\treturn idx;\n}\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_UPDATE_STATS(sw_rep)\n{\n\tstruct mlx5e_sw_stats *s = &priv->stats.sw;\n\tstruct rtnl_link_stats64 stats64 = {};\n\n\tmemset(s, 0, sizeof(*s));\n\tmlx5e_fold_sw_stats64(priv, &stats64);\n\n\ts->rx_packets = stats64.rx_packets;\n\ts->rx_bytes   = stats64.rx_bytes;\n\ts->tx_packets = stats64.tx_packets;\n\ts->tx_bytes   = stats64.tx_bytes;\n\ts->tx_queue_dropped = stats64.tx_dropped;\n}\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_NUM_STATS(vport_rep)\n{\n\treturn NUM_VPORT_REP_HW_COUNTERS;\n}\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_FILL_STRS(vport_rep)\n{\n\tint i;\n\n\tfor (i = 0; i < NUM_VPORT_REP_HW_COUNTERS; i++)\n\t\tstrcpy(data + (idx++) * ETH_GSTRING_LEN, vport_rep_stats_desc[i].format);\n\treturn idx;\n}\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_FILL_STATS(vport_rep)\n{\n\tint i;\n\n\tfor (i = 0; i < NUM_VPORT_REP_HW_COUNTERS; i++)\n\t\tdata[idx++] = MLX5E_READ_CTR64_CPU(&priv->stats.rep_stats,\n\t\t\t\t\t\t   vport_rep_stats_desc, i);\n\treturn idx;\n}\n\nstatic MLX5E_DECLARE_STATS_GRP_OP_UPDATE_STATS(vport_rep)\n{\n\tstruct mlx5e_rep_stats *rep_stats = &priv->stats.rep_stats;\n\tint outlen = MLX5_ST_SZ_BYTES(query_vport_counter_out);\n\tstruct mlx5_eswitch *esw = priv->mdev->priv.eswitch;\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tu32 *out;\n\tint err;\n\n\tout = kvzalloc(outlen, GFP_KERNEL);\n\tif (!out)\n\t\treturn;\n\n\terr = mlx5_core_query_vport_counter(esw->dev, 1, rep->vport - 1, 0, out);\n\tif (err) {\n\t\tnetdev_warn(priv->netdev, \"vport %d error %d reading stats\\n\",\n\t\t\t    rep->vport, err);\n\t\tgoto out;\n\t}\n\n\t#define MLX5_GET_CTR(p, x) \\\n\t\tMLX5_GET64(query_vport_counter_out, p, x)\n\t \n\trep_stats->vport_rx_packets =\n\t\tMLX5_GET_CTR(out, transmitted_ib_unicast.packets) +\n\t\tMLX5_GET_CTR(out, transmitted_eth_unicast.packets) +\n\t\tMLX5_GET_CTR(out, transmitted_ib_multicast.packets) +\n\t\tMLX5_GET_CTR(out, transmitted_eth_multicast.packets) +\n\t\tMLX5_GET_CTR(out, transmitted_eth_broadcast.packets);\n\n\trep_stats->vport_tx_packets =\n\t\tMLX5_GET_CTR(out, received_ib_unicast.packets) +\n\t\tMLX5_GET_CTR(out, received_eth_unicast.packets) +\n\t\tMLX5_GET_CTR(out, received_ib_multicast.packets) +\n\t\tMLX5_GET_CTR(out, received_eth_multicast.packets) +\n\t\tMLX5_GET_CTR(out, received_eth_broadcast.packets);\n\n\trep_stats->vport_rx_bytes =\n\t\tMLX5_GET_CTR(out, transmitted_ib_unicast.octets) +\n\t\tMLX5_GET_CTR(out, transmitted_eth_unicast.octets) +\n\t\tMLX5_GET_CTR(out, transmitted_ib_multicast.octets) +\n\t\tMLX5_GET_CTR(out, transmitted_eth_broadcast.octets);\n\n\trep_stats->vport_tx_bytes =\n\t\tMLX5_GET_CTR(out, received_ib_unicast.octets) +\n\t\tMLX5_GET_CTR(out, received_eth_unicast.octets) +\n\t\tMLX5_GET_CTR(out, received_ib_multicast.octets) +\n\t\tMLX5_GET_CTR(out, received_eth_multicast.octets) +\n\t\tMLX5_GET_CTR(out, received_eth_broadcast.octets);\n\n\trep_stats->rx_vport_rdma_unicast_packets =\n\t\tMLX5_GET_CTR(out, transmitted_ib_unicast.packets);\n\trep_stats->tx_vport_rdma_unicast_packets =\n\t\tMLX5_GET_CTR(out, received_ib_unicast.packets);\n\trep_stats->rx_vport_rdma_unicast_bytes =\n\t\tMLX5_GET_CTR(out, transmitted_ib_unicast.octets);\n\trep_stats->tx_vport_rdma_unicast_bytes =\n\t\tMLX5_GET_CTR(out, received_ib_unicast.octets);\n\trep_stats->rx_vport_rdma_multicast_packets =\n\t\tMLX5_GET_CTR(out, transmitted_ib_multicast.packets);\n\trep_stats->tx_vport_rdma_multicast_packets =\n\t\tMLX5_GET_CTR(out, received_ib_multicast.packets);\n\trep_stats->rx_vport_rdma_multicast_bytes =\n\t\tMLX5_GET_CTR(out, transmitted_ib_multicast.octets);\n\trep_stats->tx_vport_rdma_multicast_bytes =\n\t\tMLX5_GET_CTR(out, received_ib_multicast.octets);\n\nout:\n\tkvfree(out);\n}\n\nstatic void mlx5e_rep_get_strings(struct net_device *dev,\n\t\t\t\t  u32 stringset, uint8_t *data)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tmlx5e_stats_fill_strings(priv, data);\n\t\tbreak;\n\t}\n}\n\nstatic void mlx5e_rep_get_ethtool_stats(struct net_device *dev,\n\t\t\t\t\tstruct ethtool_stats *stats, u64 *data)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\tmlx5e_ethtool_get_ethtool_stats(priv, stats, data);\n}\n\nstatic int mlx5e_rep_get_sset_count(struct net_device *dev, int sset)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn mlx5e_stats_total_num(priv);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void\nmlx5e_rep_get_ringparam(struct net_device *dev,\n\t\t\tstruct ethtool_ringparam *param,\n\t\t\tstruct kernel_ethtool_ringparam *kernel_param,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\tmlx5e_ethtool_get_ringparam(priv, param, kernel_param);\n}\n\nstatic int\nmlx5e_rep_set_ringparam(struct net_device *dev,\n\t\t\tstruct ethtool_ringparam *param,\n\t\t\tstruct kernel_ethtool_ringparam *kernel_param,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\treturn mlx5e_ethtool_set_ringparam(priv, param);\n}\n\nstatic void mlx5e_rep_get_channels(struct net_device *dev,\n\t\t\t\t   struct ethtool_channels *ch)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\tmlx5e_ethtool_get_channels(priv, ch);\n}\n\nstatic int mlx5e_rep_set_channels(struct net_device *dev,\n\t\t\t\t  struct ethtool_channels *ch)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\treturn mlx5e_ethtool_set_channels(priv, ch);\n}\n\nstatic int mlx5e_rep_get_coalesce(struct net_device *netdev,\n\t\t\t\t  struct ethtool_coalesce *coal,\n\t\t\t\t  struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\n\treturn mlx5e_ethtool_get_coalesce(priv, coal, kernel_coal);\n}\n\nstatic int mlx5e_rep_set_coalesce(struct net_device *netdev,\n\t\t\t\t  struct ethtool_coalesce *coal,\n\t\t\t\t  struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\n\treturn mlx5e_ethtool_set_coalesce(priv, coal, kernel_coal, extack);\n}\n\nstatic u32 mlx5e_rep_get_rxfh_key_size(struct net_device *netdev)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\n\treturn mlx5e_ethtool_get_rxfh_key_size(priv);\n}\n\nstatic u32 mlx5e_rep_get_rxfh_indir_size(struct net_device *netdev)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\n\treturn mlx5e_ethtool_get_rxfh_indir_size(priv);\n}\n\nstatic const struct ethtool_ops mlx5e_rep_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS |\n\t\t\t\t     ETHTOOL_COALESCE_MAX_FRAMES |\n\t\t\t\t     ETHTOOL_COALESCE_USE_ADAPTIVE,\n\t.get_drvinfo\t   = mlx5e_rep_get_drvinfo,\n\t.get_link\t   = ethtool_op_get_link,\n\t.get_strings       = mlx5e_rep_get_strings,\n\t.get_sset_count    = mlx5e_rep_get_sset_count,\n\t.get_ethtool_stats = mlx5e_rep_get_ethtool_stats,\n\t.get_ringparam     = mlx5e_rep_get_ringparam,\n\t.set_ringparam     = mlx5e_rep_set_ringparam,\n\t.get_channels      = mlx5e_rep_get_channels,\n\t.set_channels      = mlx5e_rep_set_channels,\n\t.get_coalesce      = mlx5e_rep_get_coalesce,\n\t.set_coalesce      = mlx5e_rep_set_coalesce,\n\t.get_rxfh_key_size   = mlx5e_rep_get_rxfh_key_size,\n\t.get_rxfh_indir_size = mlx5e_rep_get_rxfh_indir_size,\n};\n\nstatic void mlx5e_sqs2vport_stop(struct mlx5_eswitch *esw,\n\t\t\t\t struct mlx5_eswitch_rep *rep)\n{\n\tstruct mlx5e_rep_sq *rep_sq, *tmp;\n\tstruct mlx5e_rep_sq_peer *sq_peer;\n\tstruct mlx5e_rep_priv *rpriv;\n\tunsigned long i;\n\n\tif (esw->mode != MLX5_ESWITCH_OFFLOADS)\n\t\treturn;\n\n\trpriv = mlx5e_rep_to_rep_priv(rep);\n\tlist_for_each_entry_safe(rep_sq, tmp, &rpriv->vport_sqs_list, list) {\n\t\tmlx5_eswitch_del_send_to_vport_rule(rep_sq->send_to_vport_rule);\n\t\txa_for_each(&rep_sq->sq_peer, i, sq_peer) {\n\t\t\tif (sq_peer->rule)\n\t\t\t\tmlx5_eswitch_del_send_to_vport_rule(sq_peer->rule);\n\n\t\t\txa_erase(&rep_sq->sq_peer, i);\n\t\t\tkfree(sq_peer);\n\t\t}\n\n\t\txa_destroy(&rep_sq->sq_peer);\n\t\tlist_del(&rep_sq->list);\n\t\tkfree(rep_sq);\n\t}\n}\n\nstatic int mlx5e_sqs2vport_add_peers_rules(struct mlx5_eswitch *esw, struct mlx5_eswitch_rep *rep,\n\t\t\t\t\t   struct mlx5e_rep_sq *rep_sq, int i)\n{\n\tstruct mlx5_flow_handle *flow_rule;\n\tstruct mlx5_devcom_comp_dev *tmp;\n\tstruct mlx5_eswitch *peer_esw;\n\n\tmlx5_devcom_for_each_peer_entry(esw->devcom, peer_esw, tmp) {\n\t\tu16 peer_rule_idx = MLX5_CAP_GEN(peer_esw->dev, vhca_id);\n\t\tstruct mlx5e_rep_sq_peer *sq_peer;\n\t\tint err;\n\n\t\tsq_peer = kzalloc(sizeof(*sq_peer), GFP_KERNEL);\n\t\tif (!sq_peer)\n\t\t\treturn -ENOMEM;\n\n\t\tflow_rule = mlx5_eswitch_add_send_to_vport_rule(peer_esw, esw,\n\t\t\t\t\t\t\t\trep, rep_sq->sqn);\n\t\tif (IS_ERR(flow_rule)) {\n\t\t\tkfree(sq_peer);\n\t\t\treturn PTR_ERR(flow_rule);\n\t\t}\n\n\t\tsq_peer->rule = flow_rule;\n\t\tsq_peer->peer = peer_esw;\n\t\terr = xa_insert(&rep_sq->sq_peer, peer_rule_idx, sq_peer, GFP_KERNEL);\n\t\tif (err) {\n\t\t\tkfree(sq_peer);\n\t\t\tmlx5_eswitch_del_send_to_vport_rule(flow_rule);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int mlx5e_sqs2vport_start(struct mlx5_eswitch *esw,\n\t\t\t\t struct mlx5_eswitch_rep *rep,\n\t\t\t\t u32 *sqns_array, int sqns_num)\n{\n\tstruct mlx5_flow_handle *flow_rule;\n\tstruct mlx5e_rep_priv *rpriv;\n\tstruct mlx5e_rep_sq *rep_sq;\n\tbool devcom_locked = false;\n\tint err;\n\tint i;\n\n\tif (esw->mode != MLX5_ESWITCH_OFFLOADS)\n\t\treturn 0;\n\n\trpriv = mlx5e_rep_to_rep_priv(rep);\n\n\tif (mlx5_devcom_comp_is_ready(esw->devcom) &&\n\t    mlx5_devcom_for_each_peer_begin(esw->devcom))\n\t\tdevcom_locked = true;\n\n\tfor (i = 0; i < sqns_num; i++) {\n\t\trep_sq = kzalloc(sizeof(*rep_sq), GFP_KERNEL);\n\t\tif (!rep_sq) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\t \n\t\tflow_rule = mlx5_eswitch_add_send_to_vport_rule(esw, esw, rep,\n\t\t\t\t\t\t\t\tsqns_array[i]);\n\t\tif (IS_ERR(flow_rule)) {\n\t\t\terr = PTR_ERR(flow_rule);\n\t\t\tkfree(rep_sq);\n\t\t\tgoto out_err;\n\t\t}\n\t\trep_sq->send_to_vport_rule = flow_rule;\n\t\trep_sq->sqn = sqns_array[i];\n\n\t\txa_init(&rep_sq->sq_peer);\n\t\tif (devcom_locked) {\n\t\t\terr = mlx5e_sqs2vport_add_peers_rules(esw, rep, rep_sq, i);\n\t\t\tif (err) {\n\t\t\t\tmlx5_eswitch_del_send_to_vport_rule(rep_sq->send_to_vport_rule);\n\t\t\t\txa_destroy(&rep_sq->sq_peer);\n\t\t\t\tkfree(rep_sq);\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tlist_add(&rep_sq->list, &rpriv->vport_sqs_list);\n\t}\n\n\tif (devcom_locked)\n\t\tmlx5_devcom_for_each_peer_end(esw->devcom);\n\n\treturn 0;\n\nout_err:\n\tmlx5e_sqs2vport_stop(esw, rep);\n\n\tif (devcom_locked)\n\t\tmlx5_devcom_for_each_peer_end(esw->devcom);\n\n\treturn err;\n}\n\nstatic int\nmlx5e_add_sqs_fwd_rules(struct mlx5e_priv *priv)\n{\n\tint sqs_per_channel = mlx5e_get_dcb_num_tc(&priv->channels.params);\n\tstruct mlx5_eswitch *esw = priv->mdev->priv.eswitch;\n\tbool is_uplink_rep = mlx5e_is_uplink_rep(priv);\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tint n, tc, nch, num_sqs = 0;\n\tstruct mlx5e_channel *c;\n\tint err = -ENOMEM;\n\tbool ptp_sq;\n\tu32 *sqs;\n\n\tptp_sq = !!(priv->channels.ptp &&\n\t\t    MLX5E_GET_PFLAG(&priv->channels.params, MLX5E_PFLAG_TX_PORT_TS));\n\tnch = priv->channels.num + ptp_sq;\n\t \n\tif (is_uplink_rep)\n\t\tsqs_per_channel += 2;\n\n\tsqs = kvcalloc(nch * sqs_per_channel, sizeof(*sqs), GFP_KERNEL);\n\tif (!sqs)\n\t\tgoto out;\n\n\tfor (n = 0; n < priv->channels.num; n++) {\n\t\tc = priv->channels.c[n];\n\t\tfor (tc = 0; tc < c->num_tc; tc++)\n\t\t\tsqs[num_sqs++] = c->sq[tc].sqn;\n\n\t\tif (is_uplink_rep) {\n\t\t\tif (c->xdp)\n\t\t\t\tsqs[num_sqs++] = c->rq_xdpsq.sqn;\n\n\t\t\tsqs[num_sqs++] = c->xdpsq.sqn;\n\t\t}\n\t}\n\tif (ptp_sq) {\n\t\tstruct mlx5e_ptp *ptp_ch = priv->channels.ptp;\n\n\t\tfor (tc = 0; tc < ptp_ch->num_tc; tc++)\n\t\t\tsqs[num_sqs++] = ptp_ch->ptpsq[tc].txqsq.sqn;\n\t}\n\n\terr = mlx5e_sqs2vport_start(esw, rep, sqs, num_sqs);\n\tkvfree(sqs);\n\nout:\n\tif (err)\n\t\tnetdev_warn(priv->netdev, \"Failed to add SQs FWD rules %d\\n\", err);\n\treturn err;\n}\n\nstatic void\nmlx5e_remove_sqs_fwd_rules(struct mlx5e_priv *priv)\n{\n\tstruct mlx5_eswitch *esw = priv->mdev->priv.eswitch;\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\n\tmlx5e_sqs2vport_stop(esw, rep);\n}\n\nstatic int\nmlx5e_rep_add_meta_tunnel_rule(struct mlx5e_priv *priv)\n{\n\tstruct mlx5_eswitch *esw = priv->mdev->priv.eswitch;\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tstruct mlx5_flow_handle *flow_rule;\n\tstruct mlx5_flow_group *g;\n\n\tg = esw->fdb_table.offloads.send_to_vport_meta_grp;\n\tif (!g)\n\t\treturn 0;\n\n\tflow_rule = mlx5_eswitch_add_send_to_vport_meta_rule(esw, rep->vport);\n\tif (IS_ERR(flow_rule))\n\t\treturn PTR_ERR(flow_rule);\n\n\trpriv->send_to_vport_meta_rule = flow_rule;\n\n\treturn 0;\n}\n\nstatic void\nmlx5e_rep_del_meta_tunnel_rule(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\n\tif (rpriv->send_to_vport_meta_rule)\n\t\tmlx5_eswitch_del_send_to_vport_meta_rule(rpriv->send_to_vport_meta_rule);\n}\n\nvoid mlx5e_rep_activate_channels(struct mlx5e_priv *priv)\n{\n\tmlx5e_add_sqs_fwd_rules(priv);\n\tmlx5e_rep_add_meta_tunnel_rule(priv);\n}\n\nvoid mlx5e_rep_deactivate_channels(struct mlx5e_priv *priv)\n{\n\tmlx5e_rep_del_meta_tunnel_rule(priv);\n\tmlx5e_remove_sqs_fwd_rules(priv);\n}\n\nstatic int mlx5e_rep_open(struct net_device *dev)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tint err;\n\n\tmutex_lock(&priv->state_lock);\n\terr = mlx5e_open_locked(dev);\n\tif (err)\n\t\tgoto unlock;\n\n\tif (!mlx5_modify_vport_admin_state(priv->mdev,\n\t\t\t\t\t   MLX5_VPORT_STATE_OP_MOD_ESW_VPORT,\n\t\t\t\t\t   rep->vport, 1,\n\t\t\t\t\t   MLX5_VPORT_ADMIN_STATE_UP))\n\t\tnetif_carrier_on(dev);\n\nunlock:\n\tmutex_unlock(&priv->state_lock);\n\treturn err;\n}\n\nstatic int mlx5e_rep_close(struct net_device *dev)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tint ret;\n\n\tmutex_lock(&priv->state_lock);\n\tmlx5_modify_vport_admin_state(priv->mdev,\n\t\t\t\t      MLX5_VPORT_STATE_OP_MOD_ESW_VPORT,\n\t\t\t\t      rep->vport, 1,\n\t\t\t\t      MLX5_VPORT_ADMIN_STATE_DOWN);\n\tret = mlx5e_close_locked(dev);\n\tmutex_unlock(&priv->state_lock);\n\treturn ret;\n}\n\nbool mlx5e_is_uplink_rep(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep;\n\n\tif (!MLX5_ESWITCH_MANAGER(priv->mdev))\n\t\treturn false;\n\n\tif (!rpriv)  \n\t\treturn false;\n\n\trep = rpriv->rep;\n\treturn (rep->vport == MLX5_VPORT_UPLINK);\n}\n\nbool mlx5e_rep_has_offload_stats(const struct net_device *dev, int attr_id)\n{\n\tswitch (attr_id) {\n\tcase IFLA_OFFLOAD_XSTATS_CPU_HIT:\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int\nmlx5e_get_sw_stats64(const struct net_device *dev,\n\t\t     struct rtnl_link_stats64 *stats)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\tmlx5e_fold_sw_stats64(priv, stats);\n\treturn 0;\n}\n\nint mlx5e_rep_get_offload_stats(int attr_id, const struct net_device *dev,\n\t\t\t\tvoid *sp)\n{\n\tswitch (attr_id) {\n\tcase IFLA_OFFLOAD_XSTATS_CPU_HIT:\n\t\treturn mlx5e_get_sw_stats64(dev, sp);\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic void\nmlx5e_rep_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\n\t \n\tmlx5e_queue_update_stats(priv);\n\tmlx5e_stats_copy_rep_stats(stats, &priv->stats.rep_stats);\n}\n\nstatic int mlx5e_rep_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\treturn mlx5e_change_mtu(netdev, new_mtu, NULL);\n}\n\nstatic int mlx5e_rep_change_carrier(struct net_device *dev, bool new_carrier)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(dev);\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tint err;\n\n\tif (new_carrier) {\n\t\terr = mlx5_modify_vport_admin_state(priv->mdev, MLX5_VPORT_STATE_OP_MOD_ESW_VPORT,\n\t\t\t\t\t\t    rep->vport, 1, MLX5_VPORT_ADMIN_STATE_UP);\n\t\tif (err)\n\t\t\treturn err;\n\t\tnetif_carrier_on(dev);\n\t} else {\n\t\terr = mlx5_modify_vport_admin_state(priv->mdev, MLX5_VPORT_STATE_OP_MOD_ESW_VPORT,\n\t\t\t\t\t\t    rep->vport, 1, MLX5_VPORT_ADMIN_STATE_DOWN);\n\t\tif (err)\n\t\t\treturn err;\n\t\tnetif_carrier_off(dev);\n\t}\n\treturn 0;\n}\n\nstatic const struct net_device_ops mlx5e_netdev_ops_rep = {\n\t.ndo_open                = mlx5e_rep_open,\n\t.ndo_stop                = mlx5e_rep_close,\n\t.ndo_start_xmit          = mlx5e_xmit,\n\t.ndo_setup_tc            = mlx5e_rep_setup_tc,\n\t.ndo_get_stats64         = mlx5e_rep_get_stats,\n\t.ndo_has_offload_stats\t = mlx5e_rep_has_offload_stats,\n\t.ndo_get_offload_stats\t = mlx5e_rep_get_offload_stats,\n\t.ndo_change_mtu          = mlx5e_rep_change_mtu,\n\t.ndo_change_carrier      = mlx5e_rep_change_carrier,\n};\n\nbool mlx5e_eswitch_uplink_rep(const struct net_device *netdev)\n{\n\treturn netdev->netdev_ops == &mlx5e_netdev_ops &&\n\t       mlx5e_is_uplink_rep(netdev_priv(netdev));\n}\n\nbool mlx5e_eswitch_vf_rep(const struct net_device *netdev)\n{\n\treturn netdev->netdev_ops == &mlx5e_netdev_ops_rep;\n}\n\n \n#define REP_NUM_INDIR_TIRS MLX5E_NUM_INDIR_TIRS\n\nstatic int mlx5e_rep_max_nch_limit(struct mlx5_core_dev *mdev)\n{\n\tint max_tir_num = 1 << MLX5_CAP_GEN(mdev, log_max_tir);\n\tint num_vports = mlx5_eswitch_get_total_vports(mdev);\n\n\treturn (max_tir_num - mlx5e_get_pf_num_tirs(mdev)\n\t\t- (num_vports * REP_NUM_INDIR_TIRS)) / num_vports;\n}\n\nstatic void mlx5e_build_rep_params(struct net_device *netdev)\n{\n\tconst bool take_rtnl = netdev->reg_state == NETREG_REGISTERED;\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tstruct mlx5_core_dev *mdev = priv->mdev;\n\tstruct mlx5e_params *params;\n\n\tu8 cq_period_mode = MLX5_CAP_GEN(mdev, cq_period_start_from_cqe) ?\n\t\t\t\t\t MLX5_CQ_PERIOD_MODE_START_FROM_CQE :\n\t\t\t\t\t MLX5_CQ_PERIOD_MODE_START_FROM_EQE;\n\n\tparams = &priv->channels.params;\n\n\tparams->num_channels = MLX5E_REP_PARAMS_DEF_NUM_CHANNELS;\n\tparams->hard_mtu    = MLX5E_ETH_HARD_MTU;\n\tparams->sw_mtu      = netdev->mtu;\n\n\t \n\tif (rep->vport == MLX5_VPORT_UPLINK)\n\t\tparams->log_sq_size = MLX5E_PARAMS_DEFAULT_LOG_SQ_SIZE;\n\telse\n\t\tparams->log_sq_size = MLX5E_REP_PARAMS_DEF_LOG_SQ_SIZE;\n\n\t \n\tmlx5e_build_rq_params(mdev, params);\n\n\t \n\tif (take_rtnl)\n\t\trtnl_lock();\n\t \n\tmlx5e_set_xdp_feature(netdev);\n\tif (take_rtnl)\n\t\trtnl_unlock();\n\n\t \n\tparams->rx_dim_enabled = MLX5_CAP_GEN(mdev, cq_moderation);\n\tmlx5e_set_rx_cq_mode_params(params, cq_period_mode);\n\n\tparams->mqprio.num_tc       = 1;\n\tif (rep->vport != MLX5_VPORT_UPLINK)\n\t\tparams->vlan_strip_disable = true;\n\n\tmlx5_query_min_inline(mdev, &params->tx_min_inline_mode);\n}\n\nstatic void mlx5e_build_rep_netdev(struct net_device *netdev,\n\t\t\t\t   struct mlx5_core_dev *mdev)\n{\n\tSET_NETDEV_DEV(netdev, mdev->device);\n\tnetdev->netdev_ops = &mlx5e_netdev_ops_rep;\n\teth_hw_addr_random(netdev);\n\tnetdev->ethtool_ops = &mlx5e_rep_ethtool_ops;\n\n\tnetdev->watchdog_timeo    = 15 * HZ;\n\n#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)\n\tnetdev->hw_features    |= NETIF_F_HW_TC;\n#endif\n\tnetdev->hw_features    |= NETIF_F_SG;\n\tnetdev->hw_features    |= NETIF_F_IP_CSUM;\n\tnetdev->hw_features    |= NETIF_F_IPV6_CSUM;\n\tnetdev->hw_features    |= NETIF_F_GRO;\n\tnetdev->hw_features    |= NETIF_F_TSO;\n\tnetdev->hw_features    |= NETIF_F_TSO6;\n\tnetdev->hw_features    |= NETIF_F_RXCSUM;\n\n\tnetdev->features |= netdev->hw_features;\n\tnetdev->features |= NETIF_F_NETNS_LOCAL;\n}\n\nstatic int mlx5e_init_rep(struct mlx5_core_dev *mdev,\n\t\t\t  struct net_device *netdev)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\n\tpriv->fs =\n\t\tmlx5e_fs_init(priv->profile, mdev,\n\t\t\t      !test_bit(MLX5E_STATE_DESTROYING, &priv->state),\n\t\t\t      priv->dfs_root);\n\tif (!priv->fs) {\n\t\tnetdev_err(priv->netdev, \"FS allocation failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmlx5e_build_rep_params(netdev);\n\tmlx5e_timestamp_init(priv);\n\n\treturn 0;\n}\n\nstatic int mlx5e_init_ul_rep(struct mlx5_core_dev *mdev,\n\t\t\t     struct net_device *netdev)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\n\tpriv->dfs_root = debugfs_create_dir(\"nic\",\n\t\t\t\t\t    mlx5_debugfs_get_dev_root(mdev));\n\n\tpriv->fs = mlx5e_fs_init(priv->profile, mdev,\n\t\t\t\t !test_bit(MLX5E_STATE_DESTROYING, &priv->state),\n\t\t\t\t priv->dfs_root);\n\tif (!priv->fs) {\n\t\tnetdev_err(priv->netdev, \"FS allocation failed\\n\");\n\t\tdebugfs_remove_recursive(priv->dfs_root);\n\t\treturn -ENOMEM;\n\t}\n\n\tmlx5e_vxlan_set_netdev_info(priv);\n\tmlx5e_build_rep_params(netdev);\n\tmlx5e_timestamp_init(priv);\n\treturn 0;\n}\n\nstatic void mlx5e_cleanup_rep(struct mlx5e_priv *priv)\n{\n\tmlx5e_fs_cleanup(priv->fs);\n\tdebugfs_remove_recursive(priv->dfs_root);\n\tpriv->fs = NULL;\n}\n\nstatic int mlx5e_create_rep_ttc_table(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tstruct ttc_params ttc_params = {};\n\tint err;\n\n\tmlx5e_fs_set_ns(priv->fs,\n\t\t\tmlx5_get_flow_namespace(priv->mdev,\n\t\t\t\t\t\tMLX5_FLOW_NAMESPACE_KERNEL), false);\n\n\t \n\tmlx5e_set_ttc_params(priv->fs, priv->rx_res, &ttc_params, false);\n\n\tif (rep->vport != MLX5_VPORT_UPLINK)\n\t\t \n\t\tttc_params.ft_attr.level = MLX5E_TTC_FT_LEVEL + 1;\n\n\tmlx5e_fs_set_ttc(priv->fs, mlx5_create_ttc_table(priv->mdev, &ttc_params), false);\n\tif (IS_ERR(mlx5e_fs_get_ttc(priv->fs, false))) {\n\t\terr = PTR_ERR(mlx5e_fs_get_ttc(priv->fs, false));\n\t\tnetdev_err(priv->netdev, \"Failed to create rep ttc table, err=%d\\n\",\n\t\t\t   err);\n\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic int mlx5e_create_rep_root_ft(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tstruct mlx5_flow_table_attr ft_attr = {};\n\tstruct mlx5_flow_namespace *ns;\n\tint err = 0;\n\n\tif (rep->vport != MLX5_VPORT_UPLINK) {\n\t\t \n\t\trpriv->root_ft = mlx5_get_ttc_flow_table(mlx5e_fs_get_ttc(priv->fs, false));\n\t\treturn 0;\n\t}\n\n\t \n\tns = mlx5_get_flow_namespace(priv->mdev, MLX5_FLOW_NAMESPACE_OFFLOADS);\n\tif (!ns) {\n\t\tnetdev_err(priv->netdev, \"Failed to get reps offloads namespace\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tft_attr.max_fte = 0;  \n\tft_attr.prio = 1;\n\tft_attr.level = 1;\n\n\trpriv->root_ft = mlx5_create_flow_table(ns, &ft_attr);\n\tif (IS_ERR(rpriv->root_ft)) {\n\t\terr = PTR_ERR(rpriv->root_ft);\n\t\trpriv->root_ft = NULL;\n\t}\n\n\treturn err;\n}\n\nstatic void mlx5e_destroy_rep_root_ft(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\n\tif (rep->vport != MLX5_VPORT_UPLINK)\n\t\treturn;\n\tmlx5_destroy_flow_table(rpriv->root_ft);\n}\n\nstatic int mlx5e_create_rep_vport_rx_rule(struct mlx5e_priv *priv)\n{\n\tstruct mlx5_eswitch *esw = priv->mdev->priv.eswitch;\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\tstruct mlx5_flow_handle *flow_rule;\n\tstruct mlx5_flow_destination dest;\n\n\tdest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\n\tdest.ft = rpriv->root_ft;\n\n\tflow_rule = mlx5_eswitch_create_vport_rx_rule(esw, rep->vport, &dest);\n\tif (IS_ERR(flow_rule))\n\t\treturn PTR_ERR(flow_rule);\n\trpriv->vport_rx_rule = flow_rule;\n\treturn 0;\n}\n\nstatic void rep_vport_rx_rule_destroy(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\n\tif (!rpriv->vport_rx_rule)\n\t\treturn;\n\n\tmlx5_del_flow_rules(rpriv->vport_rx_rule);\n\trpriv->vport_rx_rule = NULL;\n}\n\nint mlx5e_rep_bond_update(struct mlx5e_priv *priv, bool cleanup)\n{\n\trep_vport_rx_rule_destroy(priv);\n\n\treturn cleanup ? 0 : mlx5e_create_rep_vport_rx_rule(priv);\n}\n\nstatic int mlx5e_init_rep_rx(struct mlx5e_priv *priv)\n{\n\tstruct mlx5_core_dev *mdev = priv->mdev;\n\tint err;\n\n\tpriv->rx_res = mlx5e_rx_res_alloc();\n\tif (!priv->rx_res) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_fs;\n\t}\n\n\tmlx5e_fs_init_l2_addr(priv->fs, priv->netdev);\n\n\terr = mlx5e_open_drop_rq(priv, &priv->drop_rq);\n\tif (err) {\n\t\tmlx5_core_err(mdev, \"open drop rq failed, %d\\n\", err);\n\t\tgoto err_rx_res_free;\n\t}\n\n\terr = mlx5e_rx_res_init(priv->rx_res, priv->mdev, 0,\n\t\t\t\tpriv->max_nch, priv->drop_rq.rqn,\n\t\t\t\t&priv->channels.params.packet_merge,\n\t\t\t\tpriv->channels.params.num_channels);\n\tif (err)\n\t\tgoto err_close_drop_rq;\n\n\terr = mlx5e_create_rep_ttc_table(priv);\n\tif (err)\n\t\tgoto err_destroy_rx_res;\n\n\terr = mlx5e_create_rep_root_ft(priv);\n\tif (err)\n\t\tgoto err_destroy_ttc_table;\n\n\terr = mlx5e_create_rep_vport_rx_rule(priv);\n\tif (err)\n\t\tgoto err_destroy_root_ft;\n\n\tmlx5e_ethtool_init_steering(priv->fs);\n\n\treturn 0;\n\nerr_destroy_root_ft:\n\tmlx5e_destroy_rep_root_ft(priv);\nerr_destroy_ttc_table:\n\tmlx5_destroy_ttc_table(mlx5e_fs_get_ttc(priv->fs, false));\nerr_destroy_rx_res:\n\tmlx5e_rx_res_destroy(priv->rx_res);\nerr_close_drop_rq:\n\tmlx5e_close_drop_rq(&priv->drop_rq);\nerr_rx_res_free:\n\tmlx5e_rx_res_free(priv->rx_res);\n\tpriv->rx_res = NULL;\nerr_free_fs:\n\tmlx5e_fs_cleanup(priv->fs);\n\tpriv->fs = NULL;\n\treturn err;\n}\n\nstatic void mlx5e_cleanup_rep_rx(struct mlx5e_priv *priv)\n{\n\tmlx5e_ethtool_cleanup_steering(priv->fs);\n\trep_vport_rx_rule_destroy(priv);\n\tmlx5e_destroy_rep_root_ft(priv);\n\tmlx5_destroy_ttc_table(mlx5e_fs_get_ttc(priv->fs, false));\n\tmlx5e_rx_res_destroy(priv->rx_res);\n\tmlx5e_close_drop_rq(&priv->drop_rq);\n\tmlx5e_rx_res_free(priv->rx_res);\n\tpriv->rx_res = NULL;\n}\n\nstatic void mlx5e_rep_mpesw_work(struct work_struct *work)\n{\n\tstruct mlx5_rep_uplink_priv *uplink_priv =\n\t\tcontainer_of(work, struct mlx5_rep_uplink_priv,\n\t\t\t     mpesw_work);\n\tstruct mlx5e_rep_priv *rpriv =\n\t\tcontainer_of(uplink_priv, struct mlx5e_rep_priv,\n\t\t\t     uplink_priv);\n\tstruct mlx5e_priv *priv = netdev_priv(rpriv->netdev);\n\n\trep_vport_rx_rule_destroy(priv);\n\tmlx5e_create_rep_vport_rx_rule(priv);\n}\n\nstatic int mlx5e_init_ul_rep_rx(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tint err;\n\n\tmlx5e_create_q_counters(priv);\n\terr = mlx5e_init_rep_rx(priv);\n\tif (err)\n\t\tgoto out;\n\n\tmlx5e_tc_int_port_init_rep_rx(priv);\n\n\tINIT_WORK(&rpriv->uplink_priv.mpesw_work, mlx5e_rep_mpesw_work);\n\nout:\n\treturn err;\n}\n\nstatic void mlx5e_cleanup_ul_rep_rx(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\n\tcancel_work_sync(&rpriv->uplink_priv.mpesw_work);\n\tmlx5e_tc_int_port_cleanup_rep_rx(priv);\n\tmlx5e_cleanup_rep_rx(priv);\n\tmlx5e_destroy_q_counters(priv);\n}\n\nstatic int mlx5e_init_uplink_rep_tx(struct mlx5e_rep_priv *rpriv)\n{\n\tstruct mlx5_rep_uplink_priv *uplink_priv;\n\tstruct net_device *netdev;\n\tstruct mlx5e_priv *priv;\n\tint err;\n\n\tnetdev = rpriv->netdev;\n\tpriv = netdev_priv(netdev);\n\tuplink_priv = &rpriv->uplink_priv;\n\n\terr = mlx5e_rep_tc_init(rpriv);\n\tif (err)\n\t\treturn err;\n\n\tmlx5_init_port_tun_entropy(&uplink_priv->tun_entropy, priv->mdev);\n\n\tmlx5e_rep_bond_init(rpriv);\n\terr = mlx5e_rep_tc_netdevice_event_register(rpriv);\n\tif (err) {\n\t\tmlx5_core_err(priv->mdev, \"Failed to register netdev notifier, err: %d\\n\",\n\t\t\t      err);\n\t\tgoto err_event_reg;\n\t}\n\n\treturn 0;\n\nerr_event_reg:\n\tmlx5e_rep_bond_cleanup(rpriv);\n\tmlx5e_rep_tc_cleanup(rpriv);\n\treturn err;\n}\n\nstatic void mlx5e_cleanup_uplink_rep_tx(struct mlx5e_rep_priv *rpriv)\n{\n\tmlx5e_rep_tc_netdevice_event_unregister(rpriv);\n\tmlx5e_rep_bond_cleanup(rpriv);\n\tmlx5e_rep_tc_cleanup(rpriv);\n}\n\nstatic int mlx5e_init_rep_tx(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tint err;\n\n\terr = mlx5e_create_tises(priv);\n\tif (err) {\n\t\tmlx5_core_warn(priv->mdev, \"create tises failed, %d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = mlx5e_rep_neigh_init(rpriv);\n\tif (err)\n\t\tgoto err_neigh_init;\n\n\tif (rpriv->rep->vport == MLX5_VPORT_UPLINK) {\n\t\terr = mlx5e_init_uplink_rep_tx(rpriv);\n\t\tif (err)\n\t\t\tgoto err_init_tx;\n\t}\n\n\terr = mlx5e_tc_ht_init(&rpriv->tc_ht);\n\tif (err)\n\t\tgoto err_ht_init;\n\n\treturn 0;\n\nerr_ht_init:\n\tif (rpriv->rep->vport == MLX5_VPORT_UPLINK)\n\t\tmlx5e_cleanup_uplink_rep_tx(rpriv);\nerr_init_tx:\n\tmlx5e_rep_neigh_cleanup(rpriv);\nerr_neigh_init:\n\tmlx5e_destroy_tises(priv);\n\treturn err;\n}\n\nstatic void mlx5e_cleanup_rep_tx(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\n\tmlx5e_tc_ht_cleanup(&rpriv->tc_ht);\n\n\tif (rpriv->rep->vport == MLX5_VPORT_UPLINK)\n\t\tmlx5e_cleanup_uplink_rep_tx(rpriv);\n\n\tmlx5e_rep_neigh_cleanup(rpriv);\n\tmlx5e_destroy_tises(priv);\n}\n\nstatic void mlx5e_rep_enable(struct mlx5e_priv *priv)\n{\n\tmlx5e_set_netdev_mtu_boundaries(priv);\n}\n\nstatic void mlx5e_rep_disable(struct mlx5e_priv *priv)\n{\n}\n\nstatic int mlx5e_update_rep_rx(struct mlx5e_priv *priv)\n{\n\treturn 0;\n}\n\nstatic int mlx5e_rep_event_mpesw(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\n\tif (rep->vport != MLX5_VPORT_UPLINK)\n\t\treturn NOTIFY_DONE;\n\n\tqueue_work(priv->wq, &rpriv->uplink_priv.mpesw_work);\n\n\treturn NOTIFY_OK;\n}\n\nstatic int uplink_rep_async_event(struct notifier_block *nb, unsigned long event, void *data)\n{\n\tstruct mlx5e_priv *priv = container_of(nb, struct mlx5e_priv, events_nb);\n\n\tif (event == MLX5_EVENT_TYPE_PORT_CHANGE) {\n\t\tstruct mlx5_eqe *eqe = data;\n\n\t\tswitch (eqe->sub_type) {\n\t\tcase MLX5_PORT_CHANGE_SUBTYPE_DOWN:\n\t\tcase MLX5_PORT_CHANGE_SUBTYPE_ACTIVE:\n\t\t\tqueue_work(priv->wq, &priv->update_carrier_work);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn NOTIFY_DONE;\n\t\t}\n\n\t\treturn NOTIFY_OK;\n\t}\n\n\tif (event == MLX5_DEV_EVENT_PORT_AFFINITY)\n\t\treturn mlx5e_rep_tc_event_port_affinity(priv);\n\telse if (event == MLX5_DEV_EVENT_MULTIPORT_ESW)\n\t\treturn mlx5e_rep_event_mpesw(priv);\n\n\treturn NOTIFY_DONE;\n}\n\nstatic void mlx5e_uplink_rep_enable(struct mlx5e_priv *priv)\n{\n\tstruct net_device *netdev = priv->netdev;\n\tstruct mlx5_core_dev *mdev = priv->mdev;\n\tu16 max_mtu;\n\n\tmlx5e_ipsec_init(priv);\n\n\tnetdev->min_mtu = ETH_MIN_MTU;\n\tmlx5_query_port_max_mtu(priv->mdev, &max_mtu, 1);\n\tnetdev->max_mtu = MLX5E_HW2SW_MTU(&priv->channels.params, max_mtu);\n\tmlx5e_set_dev_port_mtu(priv);\n\n\tmlx5e_rep_tc_enable(priv);\n\n\tif (MLX5_CAP_GEN(mdev, uplink_follow))\n\t\tmlx5_modify_vport_admin_state(mdev, MLX5_VPORT_STATE_OP_MOD_UPLINK,\n\t\t\t\t\t      0, 0, MLX5_VPORT_ADMIN_STATE_AUTO);\n\tmlx5_lag_add_netdev(mdev, netdev);\n\tpriv->events_nb.notifier_call = uplink_rep_async_event;\n\tmlx5_notifier_register(mdev, &priv->events_nb);\n\tmlx5e_dcbnl_initialize(priv);\n\tmlx5e_dcbnl_init_app(priv);\n\tmlx5e_rep_bridge_init(priv);\n\n\tnetdev->wanted_features |= NETIF_F_HW_TC;\n\n\trtnl_lock();\n\tif (netif_running(netdev))\n\t\tmlx5e_open(netdev);\n\tudp_tunnel_nic_reset_ntf(priv->netdev);\n\tnetif_device_attach(netdev);\n\trtnl_unlock();\n}\n\nstatic void mlx5e_uplink_rep_disable(struct mlx5e_priv *priv)\n{\n\tstruct mlx5_core_dev *mdev = priv->mdev;\n\n\trtnl_lock();\n\tif (netif_running(priv->netdev))\n\t\tmlx5e_close(priv->netdev);\n\tnetif_device_detach(priv->netdev);\n\trtnl_unlock();\n\n\tmlx5e_rep_bridge_cleanup(priv);\n\tmlx5e_dcbnl_delete_app(priv);\n\tmlx5_notifier_unregister(mdev, &priv->events_nb);\n\tmlx5e_rep_tc_disable(priv);\n\tmlx5_lag_remove_netdev(mdev, priv->netdev);\n\tmlx5_vxlan_reset_to_default(mdev->vxlan);\n\n\tmlx5e_ipsec_cleanup(priv);\n}\n\nstatic MLX5E_DEFINE_STATS_GRP(sw_rep, 0);\nstatic MLX5E_DEFINE_STATS_GRP(vport_rep, MLX5E_NDO_UPDATE_STATS);\n\n \nstatic mlx5e_stats_grp_t mlx5e_rep_stats_grps[] = {\n\t&MLX5E_STATS_GRP(sw_rep),\n\t&MLX5E_STATS_GRP(vport_rep),\n};\n\nstatic unsigned int mlx5e_rep_stats_grps_num(struct mlx5e_priv *priv)\n{\n\treturn ARRAY_SIZE(mlx5e_rep_stats_grps);\n}\n\n \nstatic mlx5e_stats_grp_t mlx5e_ul_rep_stats_grps[] = {\n\t&MLX5E_STATS_GRP(sw),\n\t&MLX5E_STATS_GRP(qcnt),\n\t&MLX5E_STATS_GRP(vnic_env),\n\t&MLX5E_STATS_GRP(vport),\n\t&MLX5E_STATS_GRP(802_3),\n\t&MLX5E_STATS_GRP(2863),\n\t&MLX5E_STATS_GRP(2819),\n\t&MLX5E_STATS_GRP(phy),\n\t&MLX5E_STATS_GRP(eth_ext),\n\t&MLX5E_STATS_GRP(pcie),\n\t&MLX5E_STATS_GRP(per_prio),\n\t&MLX5E_STATS_GRP(pme),\n\t&MLX5E_STATS_GRP(channels),\n\t&MLX5E_STATS_GRP(per_port_buff_congest),\n#ifdef CONFIG_MLX5_EN_IPSEC\n\t&MLX5E_STATS_GRP(ipsec_hw),\n\t&MLX5E_STATS_GRP(ipsec_sw),\n#endif\n\t&MLX5E_STATS_GRP(ptp),\n};\n\nstatic unsigned int mlx5e_ul_rep_stats_grps_num(struct mlx5e_priv *priv)\n{\n\treturn ARRAY_SIZE(mlx5e_ul_rep_stats_grps);\n}\n\nstatic int\nmlx5e_rep_vnic_reporter_diagnose(struct devlink_health_reporter *reporter,\n\t\t\t\t struct devlink_fmsg *fmsg,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct mlx5e_rep_priv *rpriv = devlink_health_reporter_priv(reporter);\n\tstruct mlx5_eswitch_rep *rep = rpriv->rep;\n\n\treturn mlx5_reporter_vnic_diagnose_counters(rep->esw->dev, fmsg,\n\t\t\t\t\t\t    rep->vport, true);\n}\n\nstatic const struct devlink_health_reporter_ops mlx5_rep_vnic_reporter_ops = {\n\t.name = \"vnic\",\n\t.diagnose = mlx5e_rep_vnic_reporter_diagnose,\n};\n\nstatic void mlx5e_rep_vnic_reporter_create(struct mlx5e_priv *priv,\n\t\t\t\t\t   struct devlink_port *dl_port)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\tstruct devlink_health_reporter *reporter;\n\n\treporter = devl_port_health_reporter_create(dl_port,\n\t\t\t\t\t\t    &mlx5_rep_vnic_reporter_ops,\n\t\t\t\t\t\t    0, rpriv);\n\tif (IS_ERR(reporter)) {\n\t\tmlx5_core_err(priv->mdev,\n\t\t\t      \"Failed to create representor vnic reporter, err = %ld\\n\",\n\t\t\t      PTR_ERR(reporter));\n\t\treturn;\n\t}\n\n\trpriv->rep_vnic_reporter = reporter;\n}\n\nstatic void mlx5e_rep_vnic_reporter_destroy(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_rep_priv *rpriv = priv->ppriv;\n\n\tif (!IS_ERR_OR_NULL(rpriv->rep_vnic_reporter))\n\t\tdevl_health_reporter_destroy(rpriv->rep_vnic_reporter);\n}\n\nstatic const struct mlx5e_profile mlx5e_rep_profile = {\n\t.init\t\t\t= mlx5e_init_rep,\n\t.cleanup\t\t= mlx5e_cleanup_rep,\n\t.init_rx\t\t= mlx5e_init_rep_rx,\n\t.cleanup_rx\t\t= mlx5e_cleanup_rep_rx,\n\t.init_tx\t\t= mlx5e_init_rep_tx,\n\t.cleanup_tx\t\t= mlx5e_cleanup_rep_tx,\n\t.enable\t\t        = mlx5e_rep_enable,\n\t.disable\t        = mlx5e_rep_disable,\n\t.update_rx\t\t= mlx5e_update_rep_rx,\n\t.update_stats           = mlx5e_stats_update_ndo_stats,\n\t.rx_handlers            = &mlx5e_rx_handlers_rep,\n\t.max_tc\t\t\t= 1,\n\t.stats_grps\t\t= mlx5e_rep_stats_grps,\n\t.stats_grps_num\t\t= mlx5e_rep_stats_grps_num,\n\t.max_nch_limit\t\t= mlx5e_rep_max_nch_limit,\n};\n\nstatic const struct mlx5e_profile mlx5e_uplink_rep_profile = {\n\t.init\t\t\t= mlx5e_init_ul_rep,\n\t.cleanup\t\t= mlx5e_cleanup_rep,\n\t.init_rx\t\t= mlx5e_init_ul_rep_rx,\n\t.cleanup_rx\t\t= mlx5e_cleanup_ul_rep_rx,\n\t.init_tx\t\t= mlx5e_init_rep_tx,\n\t.cleanup_tx\t\t= mlx5e_cleanup_rep_tx,\n\t.enable\t\t        = mlx5e_uplink_rep_enable,\n\t.disable\t        = mlx5e_uplink_rep_disable,\n\t.update_rx\t\t= mlx5e_update_rep_rx,\n\t.update_stats           = mlx5e_stats_update_ndo_stats,\n\t.update_carrier\t        = mlx5e_update_carrier,\n\t.rx_handlers            = &mlx5e_rx_handlers_rep,\n\t.max_tc\t\t\t= MLX5E_MAX_NUM_TC,\n\t.stats_grps\t\t= mlx5e_ul_rep_stats_grps,\n\t.stats_grps_num\t\t= mlx5e_ul_rep_stats_grps_num,\n};\n\n \nstatic int\nmlx5e_vport_uplink_rep_load(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep)\n{\n\tstruct mlx5e_priv *priv = netdev_priv(mlx5_uplink_netdev_get(dev));\n\tstruct mlx5e_rep_priv *rpriv = mlx5e_rep_to_rep_priv(rep);\n\n\trpriv->netdev = priv->netdev;\n\treturn mlx5e_netdev_change_profile(priv, &mlx5e_uplink_rep_profile,\n\t\t\t\t\t   rpriv);\n}\n\nstatic void\nmlx5e_vport_uplink_rep_unload(struct mlx5e_rep_priv *rpriv)\n{\n\tstruct net_device *netdev = rpriv->netdev;\n\tstruct mlx5e_priv *priv;\n\n\tpriv = netdev_priv(netdev);\n\n\tmlx5e_netdev_attach_nic_profile(priv);\n}\n\nstatic int\nmlx5e_vport_vf_rep_load(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep)\n{\n\tstruct mlx5e_rep_priv *rpriv = mlx5e_rep_to_rep_priv(rep);\n\tconst struct mlx5e_profile *profile;\n\tstruct devlink_port *dl_port;\n\tstruct net_device *netdev;\n\tstruct mlx5e_priv *priv;\n\tint err;\n\n\tprofile = &mlx5e_rep_profile;\n\tnetdev = mlx5e_create_netdev(dev, profile);\n\tif (!netdev) {\n\t\tmlx5_core_warn(dev,\n\t\t\t       \"Failed to create representor netdev for vport %d\\n\",\n\t\t\t       rep->vport);\n\t\treturn -EINVAL;\n\t}\n\n\tmlx5e_build_rep_netdev(netdev, dev);\n\trpriv->netdev = netdev;\n\n\tpriv = netdev_priv(netdev);\n\tpriv->profile = profile;\n\tpriv->ppriv = rpriv;\n\terr = profile->init(dev, netdev);\n\tif (err) {\n\t\tnetdev_warn(netdev, \"rep profile init failed, %d\\n\", err);\n\t\tgoto err_destroy_netdev;\n\t}\n\n\terr = mlx5e_attach_netdev(netdev_priv(netdev));\n\tif (err) {\n\t\tnetdev_warn(netdev,\n\t\t\t    \"Failed to attach representor netdev for vport %d\\n\",\n\t\t\t    rep->vport);\n\t\tgoto err_cleanup_profile;\n\t}\n\n\tdl_port = mlx5_esw_offloads_devlink_port(dev->priv.eswitch,\n\t\t\t\t\t\t rpriv->rep->vport);\n\tif (!IS_ERR(dl_port)) {\n\t\tSET_NETDEV_DEVLINK_PORT(netdev, dl_port);\n\t\tmlx5e_rep_vnic_reporter_create(priv, dl_port);\n\t}\n\n\terr = register_netdev(netdev);\n\tif (err) {\n\t\tnetdev_warn(netdev,\n\t\t\t    \"Failed to register representor netdev for vport %d\\n\",\n\t\t\t    rep->vport);\n\t\tgoto err_detach_netdev;\n\t}\n\n\treturn 0;\n\nerr_detach_netdev:\n\tmlx5e_rep_vnic_reporter_destroy(priv);\n\tmlx5e_detach_netdev(netdev_priv(netdev));\nerr_cleanup_profile:\n\tpriv->profile->cleanup(priv);\n\nerr_destroy_netdev:\n\tmlx5e_destroy_netdev(netdev_priv(netdev));\n\treturn err;\n}\n\nstatic int\nmlx5e_vport_rep_load(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep)\n{\n\tstruct mlx5e_rep_priv *rpriv;\n\tint err;\n\n\trpriv = kvzalloc(sizeof(*rpriv), GFP_KERNEL);\n\tif (!rpriv)\n\t\treturn -ENOMEM;\n\n\t \n\trpriv->rep = rep;\n\trep->rep_data[REP_ETH].priv = rpriv;\n\tINIT_LIST_HEAD(&rpriv->vport_sqs_list);\n\n\tif (rep->vport == MLX5_VPORT_UPLINK)\n\t\terr = mlx5e_vport_uplink_rep_load(dev, rep);\n\telse\n\t\terr = mlx5e_vport_vf_rep_load(dev, rep);\n\n\tif (err)\n\t\tkvfree(rpriv);\n\n\treturn err;\n}\n\nstatic void\nmlx5e_vport_rep_unload(struct mlx5_eswitch_rep *rep)\n{\n\tstruct mlx5e_rep_priv *rpriv = mlx5e_rep_to_rep_priv(rep);\n\tstruct net_device *netdev = rpriv->netdev;\n\tstruct mlx5e_priv *priv = netdev_priv(netdev);\n\tvoid *ppriv = priv->ppriv;\n\n\tif (rep->vport == MLX5_VPORT_UPLINK) {\n\t\tmlx5e_vport_uplink_rep_unload(rpriv);\n\t\tgoto free_ppriv;\n\t}\n\n\tunregister_netdev(netdev);\n\tmlx5e_rep_vnic_reporter_destroy(priv);\n\tmlx5e_detach_netdev(priv);\n\tpriv->profile->cleanup(priv);\n\tmlx5e_destroy_netdev(priv);\nfree_ppriv:\n\tkvfree(ppriv);  \n}\n\nstatic void *mlx5e_vport_rep_get_proto_dev(struct mlx5_eswitch_rep *rep)\n{\n\tstruct mlx5e_rep_priv *rpriv;\n\n\trpriv = mlx5e_rep_to_rep_priv(rep);\n\n\treturn rpriv->netdev;\n}\n\nstatic void mlx5e_vport_rep_event_unpair(struct mlx5_eswitch_rep *rep,\n\t\t\t\t\t struct mlx5_eswitch *peer_esw)\n{\n\tu16 i = MLX5_CAP_GEN(peer_esw->dev, vhca_id);\n\tstruct mlx5e_rep_priv *rpriv;\n\tstruct mlx5e_rep_sq *rep_sq;\n\n\tWARN_ON_ONCE(!peer_esw);\n\trpriv = mlx5e_rep_to_rep_priv(rep);\n\tlist_for_each_entry(rep_sq, &rpriv->vport_sqs_list, list) {\n\t\tstruct mlx5e_rep_sq_peer *sq_peer = xa_load(&rep_sq->sq_peer, i);\n\n\t\tif (!sq_peer || sq_peer->peer != peer_esw)\n\t\t\tcontinue;\n\n\t\tmlx5_eswitch_del_send_to_vport_rule(sq_peer->rule);\n\t\txa_erase(&rep_sq->sq_peer, i);\n\t\tkfree(sq_peer);\n\t}\n}\n\nstatic int mlx5e_vport_rep_event_pair(struct mlx5_eswitch *esw,\n\t\t\t\t      struct mlx5_eswitch_rep *rep,\n\t\t\t\t      struct mlx5_eswitch *peer_esw)\n{\n\tu16 i = MLX5_CAP_GEN(peer_esw->dev, vhca_id);\n\tstruct mlx5_flow_handle *flow_rule;\n\tstruct mlx5e_rep_sq_peer *sq_peer;\n\tstruct mlx5e_rep_priv *rpriv;\n\tstruct mlx5e_rep_sq *rep_sq;\n\tint err;\n\n\trpriv = mlx5e_rep_to_rep_priv(rep);\n\tlist_for_each_entry(rep_sq, &rpriv->vport_sqs_list, list) {\n\t\tsq_peer = xa_load(&rep_sq->sq_peer, i);\n\n\t\tif (sq_peer && sq_peer->peer)\n\t\t\tcontinue;\n\n\t\tflow_rule = mlx5_eswitch_add_send_to_vport_rule(peer_esw, esw, rep,\n\t\t\t\t\t\t\t\trep_sq->sqn);\n\t\tif (IS_ERR(flow_rule)) {\n\t\t\terr = PTR_ERR(flow_rule);\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (sq_peer) {\n\t\t\tsq_peer->rule = flow_rule;\n\t\t\tsq_peer->peer = peer_esw;\n\t\t\tcontinue;\n\t\t}\n\t\tsq_peer = kzalloc(sizeof(*sq_peer), GFP_KERNEL);\n\t\tif (!sq_peer) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_sq_alloc;\n\t\t}\n\t\terr = xa_insert(&rep_sq->sq_peer, i, sq_peer, GFP_KERNEL);\n\t\tif (err)\n\t\t\tgoto err_xa;\n\t\tsq_peer->rule = flow_rule;\n\t\tsq_peer->peer = peer_esw;\n\t}\n\n\treturn 0;\nerr_xa:\n\tkfree(sq_peer);\nerr_sq_alloc:\n\tmlx5_eswitch_del_send_to_vport_rule(flow_rule);\nerr_out:\n\tmlx5e_vport_rep_event_unpair(rep, peer_esw);\n\treturn err;\n}\n\nstatic int mlx5e_vport_rep_event(struct mlx5_eswitch *esw,\n\t\t\t\t struct mlx5_eswitch_rep *rep,\n\t\t\t\t enum mlx5_switchdev_event event,\n\t\t\t\t void *data)\n{\n\tint err = 0;\n\n\tif (event == MLX5_SWITCHDEV_EVENT_PAIR)\n\t\terr = mlx5e_vport_rep_event_pair(esw, rep, data);\n\telse if (event == MLX5_SWITCHDEV_EVENT_UNPAIR)\n\t\tmlx5e_vport_rep_event_unpair(rep, data);\n\n\treturn err;\n}\n\nstatic const struct mlx5_eswitch_rep_ops rep_ops = {\n\t.load = mlx5e_vport_rep_load,\n\t.unload = mlx5e_vport_rep_unload,\n\t.get_proto_dev = mlx5e_vport_rep_get_proto_dev,\n\t.event = mlx5e_vport_rep_event,\n};\n\nstatic int mlx5e_rep_probe(struct auxiliary_device *adev,\n\t\t\t   const struct auxiliary_device_id *id)\n{\n\tstruct mlx5_adev *edev = container_of(adev, struct mlx5_adev, adev);\n\tstruct mlx5_core_dev *mdev = edev->mdev;\n\tstruct mlx5_eswitch *esw;\n\n\tesw = mdev->priv.eswitch;\n\tmlx5_eswitch_register_vport_reps(esw, &rep_ops, REP_ETH);\n\treturn 0;\n}\n\nstatic void mlx5e_rep_remove(struct auxiliary_device *adev)\n{\n\tstruct mlx5_adev *vdev = container_of(adev, struct mlx5_adev, adev);\n\tstruct mlx5_core_dev *mdev = vdev->mdev;\n\tstruct mlx5_eswitch *esw;\n\n\tesw = mdev->priv.eswitch;\n\tmlx5_eswitch_unregister_vport_reps(esw, REP_ETH);\n}\n\nstatic const struct auxiliary_device_id mlx5e_rep_id_table[] = {\n\t{ .name = MLX5_ADEV_NAME \".eth-rep\", },\n\t{},\n};\n\nMODULE_DEVICE_TABLE(auxiliary, mlx5e_rep_id_table);\n\nstatic struct auxiliary_driver mlx5e_rep_driver = {\n\t.name = \"eth-rep\",\n\t.probe = mlx5e_rep_probe,\n\t.remove = mlx5e_rep_remove,\n\t.id_table = mlx5e_rep_id_table,\n};\n\nint mlx5e_rep_init(void)\n{\n\treturn auxiliary_driver_register(&mlx5e_rep_driver);\n}\n\nvoid mlx5e_rep_cleanup(void)\n{\n\tauxiliary_driver_unregister(&mlx5e_rep_driver);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}