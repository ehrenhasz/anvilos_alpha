{
  "module_name": "rl.c",
  "hash_id": "c28aa73bf3fc5689fe2228e7d92ac5beaddc9925638d14a7e65947b23be4d026",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/rl.c",
  "human_readable_source": " \n\n#include <linux/kernel.h>\n#include <linux/mlx5/driver.h>\n#include \"mlx5_core.h\"\n\n \nint mlx5_create_scheduling_element_cmd(struct mlx5_core_dev *dev, u8 hierarchy,\n\t\t\t\t       void *ctx, u32 *element_id)\n{\n\tu32 out[MLX5_ST_SZ_DW(create_scheduling_element_in)] = {};\n\tu32 in[MLX5_ST_SZ_DW(create_scheduling_element_in)] = {};\n\tvoid *schedc;\n\tint err;\n\n\tschedc = MLX5_ADDR_OF(create_scheduling_element_in, in,\n\t\t\t      scheduling_context);\n\tMLX5_SET(create_scheduling_element_in, in, opcode,\n\t\t MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT);\n\tMLX5_SET(create_scheduling_element_in, in, scheduling_hierarchy,\n\t\t hierarchy);\n\tmemcpy(schedc, ctx, MLX5_ST_SZ_BYTES(scheduling_context));\n\n\terr = mlx5_cmd_exec_inout(dev, create_scheduling_element, in, out);\n\tif (err)\n\t\treturn err;\n\n\t*element_id = MLX5_GET(create_scheduling_element_out, out,\n\t\t\t       scheduling_element_id);\n\treturn 0;\n}\n\nint mlx5_modify_scheduling_element_cmd(struct mlx5_core_dev *dev, u8 hierarchy,\n\t\t\t\t       void *ctx, u32 element_id,\n\t\t\t\t       u32 modify_bitmask)\n{\n\tu32 in[MLX5_ST_SZ_DW(modify_scheduling_element_in)] = {};\n\tvoid *schedc;\n\n\tschedc = MLX5_ADDR_OF(modify_scheduling_element_in, in,\n\t\t\t      scheduling_context);\n\tMLX5_SET(modify_scheduling_element_in, in, opcode,\n\t\t MLX5_CMD_OP_MODIFY_SCHEDULING_ELEMENT);\n\tMLX5_SET(modify_scheduling_element_in, in, scheduling_element_id,\n\t\t element_id);\n\tMLX5_SET(modify_scheduling_element_in, in, modify_bitmask,\n\t\t modify_bitmask);\n\tMLX5_SET(modify_scheduling_element_in, in, scheduling_hierarchy,\n\t\t hierarchy);\n\tmemcpy(schedc, ctx, MLX5_ST_SZ_BYTES(scheduling_context));\n\n\treturn mlx5_cmd_exec_in(dev, modify_scheduling_element, in);\n}\n\nint mlx5_destroy_scheduling_element_cmd(struct mlx5_core_dev *dev, u8 hierarchy,\n\t\t\t\t\tu32 element_id)\n{\n\tu32 in[MLX5_ST_SZ_DW(destroy_scheduling_element_in)] = {};\n\n\tMLX5_SET(destroy_scheduling_element_in, in, opcode,\n\t\t MLX5_CMD_OP_DESTROY_SCHEDULING_ELEMENT);\n\tMLX5_SET(destroy_scheduling_element_in, in, scheduling_element_id,\n\t\t element_id);\n\tMLX5_SET(destroy_scheduling_element_in, in, scheduling_hierarchy,\n\t\t hierarchy);\n\n\treturn mlx5_cmd_exec_in(dev, destroy_scheduling_element, in);\n}\n\nstatic bool mlx5_rl_are_equal_raw(struct mlx5_rl_entry *entry, void *rl_in,\n\t\t\t\t  u16 uid)\n{\n\treturn (!memcmp(entry->rl_raw, rl_in, sizeof(entry->rl_raw)) &&\n\t\tentry->uid == uid);\n}\n\n \nstatic struct mlx5_rl_entry *find_rl_entry(struct mlx5_rl_table *table,\n\t\t\t\t\t   void *rl_in, u16 uid, bool dedicated)\n{\n\tstruct mlx5_rl_entry *ret_entry = NULL;\n\tbool empty_found = false;\n\tint i;\n\n\tlockdep_assert_held(&table->rl_lock);\n\tWARN_ON(!table->rl_entry);\n\n\tfor (i = 0; i < table->max_size; i++) {\n\t\tif (dedicated) {\n\t\t\tif (!table->rl_entry[i].refcount)\n\t\t\t\treturn &table->rl_entry[i];\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (table->rl_entry[i].refcount) {\n\t\t\tif (table->rl_entry[i].dedicated)\n\t\t\t\tcontinue;\n\t\t\tif (mlx5_rl_are_equal_raw(&table->rl_entry[i], rl_in,\n\t\t\t\t\t\t  uid))\n\t\t\t\treturn &table->rl_entry[i];\n\t\t} else if (!empty_found) {\n\t\t\tempty_found = true;\n\t\t\tret_entry = &table->rl_entry[i];\n\t\t}\n\t}\n\n\treturn ret_entry;\n}\n\nstatic int mlx5_set_pp_rate_limit_cmd(struct mlx5_core_dev *dev,\n\t\t\t\t      struct mlx5_rl_entry *entry, bool set)\n{\n\tu32 in[MLX5_ST_SZ_DW(set_pp_rate_limit_in)] = {};\n\tvoid *pp_context;\n\n\tpp_context = MLX5_ADDR_OF(set_pp_rate_limit_in, in, ctx);\n\tMLX5_SET(set_pp_rate_limit_in, in, opcode,\n\t\t MLX5_CMD_OP_SET_PP_RATE_LIMIT);\n\tMLX5_SET(set_pp_rate_limit_in, in, uid, entry->uid);\n\tMLX5_SET(set_pp_rate_limit_in, in, rate_limit_index, entry->index);\n\tif (set)\n\t\tmemcpy(pp_context, entry->rl_raw, sizeof(entry->rl_raw));\n\treturn mlx5_cmd_exec_in(dev, set_pp_rate_limit, in);\n}\n\nbool mlx5_rl_is_in_range(struct mlx5_core_dev *dev, u32 rate)\n{\n\tstruct mlx5_rl_table *table = &dev->priv.rl_table;\n\n\treturn (rate <= table->max_rate && rate >= table->min_rate);\n}\nEXPORT_SYMBOL(mlx5_rl_is_in_range);\n\nbool mlx5_rl_are_equal(struct mlx5_rate_limit *rl_0,\n\t\t       struct mlx5_rate_limit *rl_1)\n{\n\treturn ((rl_0->rate == rl_1->rate) &&\n\t\t(rl_0->max_burst_sz == rl_1->max_burst_sz) &&\n\t\t(rl_0->typical_pkt_sz == rl_1->typical_pkt_sz));\n}\nEXPORT_SYMBOL(mlx5_rl_are_equal);\n\nstatic int mlx5_rl_table_get(struct mlx5_rl_table *table)\n{\n\tint i;\n\n\tlockdep_assert_held(&table->rl_lock);\n\n\tif (table->rl_entry) {\n\t\ttable->refcount++;\n\t\treturn 0;\n\t}\n\n\ttable->rl_entry = kcalloc(table->max_size, sizeof(struct mlx5_rl_entry),\n\t\t\t\t  GFP_KERNEL);\n\tif (!table->rl_entry)\n\t\treturn -ENOMEM;\n\n\t \n\tfor (i = 0; i < table->max_size; i++)\n\t\ttable->rl_entry[i].index = i + 1;\n\n\ttable->refcount++;\n\treturn 0;\n}\n\nstatic void mlx5_rl_table_put(struct mlx5_rl_table *table)\n{\n\tlockdep_assert_held(&table->rl_lock);\n\tif (--table->refcount)\n\t\treturn;\n\n\tkfree(table->rl_entry);\n\ttable->rl_entry = NULL;\n}\n\nstatic void mlx5_rl_table_free(struct mlx5_core_dev *dev, struct mlx5_rl_table *table)\n{\n\tint i;\n\n\tif (!table->rl_entry)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < table->max_size; i++)\n\t\tif (table->rl_entry[i].refcount)\n\t\t\tmlx5_set_pp_rate_limit_cmd(dev, &table->rl_entry[i], false);\n\tkfree(table->rl_entry);\n}\n\nstatic void mlx5_rl_entry_get(struct mlx5_rl_entry *entry)\n{\n\tentry->refcount++;\n}\n\nstatic void\nmlx5_rl_entry_put(struct mlx5_core_dev *dev, struct mlx5_rl_entry *entry)\n{\n\tentry->refcount--;\n\tif (!entry->refcount)\n\t\tmlx5_set_pp_rate_limit_cmd(dev, entry, false);\n}\n\nint mlx5_rl_add_rate_raw(struct mlx5_core_dev *dev, void *rl_in, u16 uid,\n\t\t\t bool dedicated_entry, u16 *index)\n{\n\tstruct mlx5_rl_table *table = &dev->priv.rl_table;\n\tstruct mlx5_rl_entry *entry;\n\tu32 rate;\n\tint err;\n\n\tif (!table->max_size)\n\t\treturn -EOPNOTSUPP;\n\n\trate = MLX5_GET(set_pp_rate_limit_context, rl_in, rate_limit);\n\tif (!rate || !mlx5_rl_is_in_range(dev, rate)) {\n\t\tmlx5_core_err(dev, \"Invalid rate: %u, should be %u to %u\\n\",\n\t\t\t      rate, table->min_rate, table->max_rate);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_lock(&table->rl_lock);\n\terr = mlx5_rl_table_get(table);\n\tif (err)\n\t\tgoto out;\n\n\tentry = find_rl_entry(table, rl_in, uid, dedicated_entry);\n\tif (!entry) {\n\t\tmlx5_core_err(dev, \"Max number of %u rates reached\\n\",\n\t\t\t      table->max_size);\n\t\terr = -ENOSPC;\n\t\tgoto rl_err;\n\t}\n\tif (!entry->refcount) {\n\t\t \n\t\tmemcpy(entry->rl_raw, rl_in, sizeof(entry->rl_raw));\n\t\tentry->uid = uid;\n\t\terr = mlx5_set_pp_rate_limit_cmd(dev, entry, true);\n\t\tif (err) {\n\t\t\tmlx5_core_err(\n\t\t\t\tdev,\n\t\t\t\t\"Failed configuring rate limit(err %d): rate %u, max_burst_sz %u, typical_pkt_sz %u\\n\",\n\t\t\t\terr, rate,\n\t\t\t\tMLX5_GET(set_pp_rate_limit_context, rl_in,\n\t\t\t\t\t burst_upper_bound),\n\t\t\t\tMLX5_GET(set_pp_rate_limit_context, rl_in,\n\t\t\t\t\t typical_packet_size));\n\t\t\tgoto rl_err;\n\t\t}\n\n\t\tentry->dedicated = dedicated_entry;\n\t}\n\tmlx5_rl_entry_get(entry);\n\t*index = entry->index;\n\tmutex_unlock(&table->rl_lock);\n\treturn 0;\n\nrl_err:\n\tmlx5_rl_table_put(table);\nout:\n\tmutex_unlock(&table->rl_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(mlx5_rl_add_rate_raw);\n\nvoid mlx5_rl_remove_rate_raw(struct mlx5_core_dev *dev, u16 index)\n{\n\tstruct mlx5_rl_table *table = &dev->priv.rl_table;\n\tstruct mlx5_rl_entry *entry;\n\n\tmutex_lock(&table->rl_lock);\n\tentry = &table->rl_entry[index - 1];\n\tmlx5_rl_entry_put(dev, entry);\n\tmlx5_rl_table_put(table);\n\tmutex_unlock(&table->rl_lock);\n}\nEXPORT_SYMBOL(mlx5_rl_remove_rate_raw);\n\nint mlx5_rl_add_rate(struct mlx5_core_dev *dev, u16 *index,\n\t\t     struct mlx5_rate_limit *rl)\n{\n\tu8 rl_raw[MLX5_ST_SZ_BYTES(set_pp_rate_limit_context)] = {};\n\n\tMLX5_SET(set_pp_rate_limit_context, rl_raw, rate_limit, rl->rate);\n\tMLX5_SET(set_pp_rate_limit_context, rl_raw, burst_upper_bound,\n\t\t rl->max_burst_sz);\n\tMLX5_SET(set_pp_rate_limit_context, rl_raw, typical_packet_size,\n\t\t rl->typical_pkt_sz);\n\n\treturn mlx5_rl_add_rate_raw(dev, rl_raw,\n\t\t\t\t    MLX5_CAP_QOS(dev, packet_pacing_uid) ?\n\t\t\t\t\tMLX5_SHARED_RESOURCE_UID : 0,\n\t\t\t\t    false, index);\n}\nEXPORT_SYMBOL(mlx5_rl_add_rate);\n\nvoid mlx5_rl_remove_rate(struct mlx5_core_dev *dev, struct mlx5_rate_limit *rl)\n{\n\tu8 rl_raw[MLX5_ST_SZ_BYTES(set_pp_rate_limit_context)] = {};\n\tstruct mlx5_rl_table *table = &dev->priv.rl_table;\n\tstruct mlx5_rl_entry *entry = NULL;\n\n\t \n\tif (rl->rate == 0)\n\t\treturn;\n\n\tMLX5_SET(set_pp_rate_limit_context, rl_raw, rate_limit, rl->rate);\n\tMLX5_SET(set_pp_rate_limit_context, rl_raw, burst_upper_bound,\n\t\t rl->max_burst_sz);\n\tMLX5_SET(set_pp_rate_limit_context, rl_raw, typical_packet_size,\n\t\t rl->typical_pkt_sz);\n\n\tmutex_lock(&table->rl_lock);\n\tentry = find_rl_entry(table, rl_raw,\n\t\t\t      MLX5_CAP_QOS(dev, packet_pacing_uid) ?\n\t\t\t\tMLX5_SHARED_RESOURCE_UID : 0, false);\n\tif (!entry || !entry->refcount) {\n\t\tmlx5_core_warn(dev, \"Rate %u, max_burst_sz %u typical_pkt_sz %u are not configured\\n\",\n\t\t\t       rl->rate, rl->max_burst_sz, rl->typical_pkt_sz);\n\t\tgoto out;\n\t}\n\tmlx5_rl_entry_put(dev, entry);\n\tmlx5_rl_table_put(table);\nout:\n\tmutex_unlock(&table->rl_lock);\n}\nEXPORT_SYMBOL(mlx5_rl_remove_rate);\n\nint mlx5_init_rl_table(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_rl_table *table = &dev->priv.rl_table;\n\n\tif (!MLX5_CAP_GEN(dev, qos) || !MLX5_CAP_QOS(dev, packet_pacing)) {\n\t\ttable->max_size = 0;\n\t\treturn 0;\n\t}\n\n\tmutex_init(&table->rl_lock);\n\n\t \n\ttable->max_size = MLX5_CAP_QOS(dev, packet_pacing_rate_table_size) - 1;\n\ttable->max_rate = MLX5_CAP_QOS(dev, packet_pacing_max_rate);\n\ttable->min_rate = MLX5_CAP_QOS(dev, packet_pacing_min_rate);\n\n\tmlx5_core_info(dev, \"Rate limit: %u rates are supported, range: %uMbps to %uMbps\\n\",\n\t\t       table->max_size,\n\t\t       table->min_rate >> 10,\n\t\t       table->max_rate >> 10);\n\n\treturn 0;\n}\n\nvoid mlx5_cleanup_rl_table(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_rl_table *table = &dev->priv.rl_table;\n\n\tif (!MLX5_CAP_GEN(dev, qos) || !MLX5_CAP_QOS(dev, packet_pacing))\n\t\treturn;\n\n\tmlx5_rl_table_free(dev, table);\n\tmutex_destroy(&table->rl_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}