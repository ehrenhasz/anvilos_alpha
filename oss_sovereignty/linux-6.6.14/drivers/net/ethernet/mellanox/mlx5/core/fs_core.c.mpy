{
  "module_name": "fs_core.c",
  "hash_id": "6e16d3d6d1100b14a4bd93b956b5b3685f3ba74f3c08d71035f50e498731c468",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c",
  "human_readable_source": " \n\n#include <linux/mutex.h>\n#include <linux/mlx5/driver.h>\n#include <linux/mlx5/vport.h>\n#include <linux/mlx5/eswitch.h>\n#include <net/devlink.h>\n\n#include \"mlx5_core.h\"\n#include \"fs_core.h\"\n#include \"fs_cmd.h\"\n#include \"fs_ft_pool.h\"\n#include \"diag/fs_tracepoint.h\"\n#include \"devlink.h\"\n\n#define INIT_TREE_NODE_ARRAY_SIZE(...)\t(sizeof((struct init_tree_node[]){__VA_ARGS__}) /\\\n\t\t\t\t\t sizeof(struct init_tree_node))\n\n#define ADD_PRIO(num_prios_val, min_level_val, num_levels_val, caps_val,\\\n\t\t ...) {.type = FS_TYPE_PRIO,\\\n\t.min_ft_level = min_level_val,\\\n\t.num_levels = num_levels_val,\\\n\t.num_leaf_prios = num_prios_val,\\\n\t.caps = caps_val,\\\n\t.children = (struct init_tree_node[]) {__VA_ARGS__},\\\n\t.ar_size = INIT_TREE_NODE_ARRAY_SIZE(__VA_ARGS__) \\\n}\n\n#define ADD_MULTIPLE_PRIO(num_prios_val, num_levels_val, ...)\\\n\tADD_PRIO(num_prios_val, 0, num_levels_val, {},\\\n\t\t __VA_ARGS__)\\\n\n#define ADD_NS(def_miss_act, ...) {.type = FS_TYPE_NAMESPACE,\t\\\n\t.def_miss_action = def_miss_act,\\\n\t.children = (struct init_tree_node[]) {__VA_ARGS__},\\\n\t.ar_size = INIT_TREE_NODE_ARRAY_SIZE(__VA_ARGS__) \\\n}\n\n#define INIT_CAPS_ARRAY_SIZE(...) (sizeof((long[]){__VA_ARGS__}) /\\\n\t\t\t\t   sizeof(long))\n\n#define FS_CAP(cap) (__mlx5_bit_off(flow_table_nic_cap, cap))\n\n#define FS_REQUIRED_CAPS(...) {.arr_sz = INIT_CAPS_ARRAY_SIZE(__VA_ARGS__), \\\n\t\t\t       .caps = (long[]) {__VA_ARGS__} }\n\n#define FS_CHAINING_CAPS  FS_REQUIRED_CAPS(FS_CAP(flow_table_properties_nic_receive.flow_modify_en), \\\n\t\t\t\t\t   FS_CAP(flow_table_properties_nic_receive.modify_root), \\\n\t\t\t\t\t   FS_CAP(flow_table_properties_nic_receive.identified_miss_table_mode), \\\n\t\t\t\t\t   FS_CAP(flow_table_properties_nic_receive.flow_table_modify))\n\n#define FS_CHAINING_CAPS_EGRESS                                                \\\n\tFS_REQUIRED_CAPS(                                                      \\\n\t\tFS_CAP(flow_table_properties_nic_transmit.flow_modify_en),     \\\n\t\tFS_CAP(flow_table_properties_nic_transmit.modify_root),        \\\n\t\tFS_CAP(flow_table_properties_nic_transmit                      \\\n\t\t\t       .identified_miss_table_mode),                   \\\n\t\tFS_CAP(flow_table_properties_nic_transmit.flow_table_modify))\n\n#define FS_CHAINING_CAPS_RDMA_TX                                                \\\n\tFS_REQUIRED_CAPS(                                                       \\\n\t\tFS_CAP(flow_table_properties_nic_transmit_rdma.flow_modify_en), \\\n\t\tFS_CAP(flow_table_properties_nic_transmit_rdma.modify_root),    \\\n\t\tFS_CAP(flow_table_properties_nic_transmit_rdma                  \\\n\t\t\t       .identified_miss_table_mode),                    \\\n\t\tFS_CAP(flow_table_properties_nic_transmit_rdma                  \\\n\t\t\t       .flow_table_modify))\n\n#define LEFTOVERS_NUM_LEVELS 1\n#define LEFTOVERS_NUM_PRIOS 1\n\n#define RDMA_RX_COUNTERS_PRIO_NUM_LEVELS 1\n#define RDMA_TX_COUNTERS_PRIO_NUM_LEVELS 1\n\n#define BY_PASS_PRIO_NUM_LEVELS 1\n#define BY_PASS_MIN_LEVEL (ETHTOOL_MIN_LEVEL + MLX5_BY_PASS_NUM_PRIOS +\\\n\t\t\t   LEFTOVERS_NUM_PRIOS)\n\n#define KERNEL_RX_MACSEC_NUM_PRIOS  1\n#define KERNEL_RX_MACSEC_NUM_LEVELS 3\n#define KERNEL_RX_MACSEC_MIN_LEVEL (BY_PASS_MIN_LEVEL + KERNEL_RX_MACSEC_NUM_PRIOS)\n\n#define ETHTOOL_PRIO_NUM_LEVELS 1\n#define ETHTOOL_NUM_PRIOS 11\n#define ETHTOOL_MIN_LEVEL (KERNEL_MIN_LEVEL + ETHTOOL_NUM_PRIOS)\n \n#define KERNEL_NIC_PRIO_NUM_LEVELS 9\n#define KERNEL_NIC_NUM_PRIOS 1\n \n#define KERNEL_MIN_LEVEL (KERNEL_NIC_PRIO_NUM_LEVELS + 1)\n\n#define KERNEL_NIC_TC_NUM_PRIOS  1\n#define KERNEL_NIC_TC_NUM_LEVELS 3\n\n#define ANCHOR_NUM_LEVELS 1\n#define ANCHOR_NUM_PRIOS 1\n#define ANCHOR_MIN_LEVEL (BY_PASS_MIN_LEVEL + 1)\n\n#define OFFLOADS_MAX_FT 2\n#define OFFLOADS_NUM_PRIOS 2\n#define OFFLOADS_MIN_LEVEL (ANCHOR_MIN_LEVEL + OFFLOADS_NUM_PRIOS)\n\n#define LAG_PRIO_NUM_LEVELS 1\n#define LAG_NUM_PRIOS 1\n#define LAG_MIN_LEVEL (OFFLOADS_MIN_LEVEL + KERNEL_RX_MACSEC_MIN_LEVEL + 1)\n\n#define KERNEL_TX_IPSEC_NUM_PRIOS  1\n#define KERNEL_TX_IPSEC_NUM_LEVELS 3\n#define KERNEL_TX_IPSEC_MIN_LEVEL        (KERNEL_TX_IPSEC_NUM_LEVELS)\n\n#define KERNEL_TX_MACSEC_NUM_PRIOS  1\n#define KERNEL_TX_MACSEC_NUM_LEVELS 2\n#define KERNEL_TX_MACSEC_MIN_LEVEL       (KERNEL_TX_IPSEC_MIN_LEVEL + KERNEL_TX_MACSEC_NUM_PRIOS)\n\nstruct node_caps {\n\tsize_t\tarr_sz;\n\tlong\t*caps;\n};\n\nstatic struct init_tree_node {\n\tenum fs_node_type\ttype;\n\tstruct init_tree_node *children;\n\tint ar_size;\n\tstruct node_caps caps;\n\tint min_ft_level;\n\tint num_leaf_prios;\n\tint prio;\n\tint num_levels;\n\tenum mlx5_flow_table_miss_action def_miss_action;\n} root_fs = {\n\t.type = FS_TYPE_NAMESPACE,\n\t.ar_size = 8,\n\t  .children = (struct init_tree_node[]){\n\t\t  ADD_PRIO(0, BY_PASS_MIN_LEVEL, 0, FS_CHAINING_CAPS,\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(MLX5_BY_PASS_NUM_PRIOS,\n\t\t\t\t\t\t    BY_PASS_PRIO_NUM_LEVELS))),\n\t\t  ADD_PRIO(0, KERNEL_RX_MACSEC_MIN_LEVEL, 0, FS_CHAINING_CAPS,\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(KERNEL_RX_MACSEC_NUM_PRIOS,\n\t\t\t\t\t\t    KERNEL_RX_MACSEC_NUM_LEVELS))),\n\t\t  ADD_PRIO(0, LAG_MIN_LEVEL, 0, FS_CHAINING_CAPS,\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(LAG_NUM_PRIOS,\n\t\t\t\t\t\t    LAG_PRIO_NUM_LEVELS))),\n\t\t  ADD_PRIO(0, OFFLOADS_MIN_LEVEL, 0, FS_CHAINING_CAPS,\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(OFFLOADS_NUM_PRIOS,\n\t\t\t\t\t\t    OFFLOADS_MAX_FT))),\n\t\t  ADD_PRIO(0, ETHTOOL_MIN_LEVEL, 0, FS_CHAINING_CAPS,\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(ETHTOOL_NUM_PRIOS,\n\t\t\t\t\t\t    ETHTOOL_PRIO_NUM_LEVELS))),\n\t\t  ADD_PRIO(0, KERNEL_MIN_LEVEL, 0, {},\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(KERNEL_NIC_TC_NUM_PRIOS,\n\t\t\t\t\t\t    KERNEL_NIC_TC_NUM_LEVELS),\n\t\t\t\t  ADD_MULTIPLE_PRIO(KERNEL_NIC_NUM_PRIOS,\n\t\t\t\t\t\t    KERNEL_NIC_PRIO_NUM_LEVELS))),\n\t\t  ADD_PRIO(0, BY_PASS_MIN_LEVEL, 0, FS_CHAINING_CAPS,\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(LEFTOVERS_NUM_PRIOS,\n\t\t\t\t\t\t    LEFTOVERS_NUM_LEVELS))),\n\t\t  ADD_PRIO(0, ANCHOR_MIN_LEVEL, 0, {},\n\t\t\t   ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\t  ADD_MULTIPLE_PRIO(ANCHOR_NUM_PRIOS,\n\t\t\t\t\t\t    ANCHOR_NUM_LEVELS))),\n\t}\n};\n\nstatic struct init_tree_node egress_root_fs = {\n\t.type = FS_TYPE_NAMESPACE,\n\t.ar_size = 3,\n\t.children = (struct init_tree_node[]) {\n\t\tADD_PRIO(0, MLX5_BY_PASS_NUM_PRIOS, 0,\n\t\t\t FS_CHAINING_CAPS_EGRESS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(MLX5_BY_PASS_NUM_PRIOS,\n\t\t\t\t\t\t  BY_PASS_PRIO_NUM_LEVELS))),\n\t\tADD_PRIO(0, KERNEL_TX_IPSEC_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS_EGRESS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(KERNEL_TX_IPSEC_NUM_PRIOS,\n\t\t\t\t\t\t  KERNEL_TX_IPSEC_NUM_LEVELS))),\n\t\tADD_PRIO(0, KERNEL_TX_MACSEC_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS_EGRESS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(KERNEL_TX_MACSEC_NUM_PRIOS,\n\t\t\t\t\t\t  KERNEL_TX_MACSEC_NUM_LEVELS))),\n\t}\n};\n\nenum {\n\tRDMA_RX_IPSEC_PRIO,\n\tRDMA_RX_MACSEC_PRIO,\n\tRDMA_RX_COUNTERS_PRIO,\n\tRDMA_RX_BYPASS_PRIO,\n\tRDMA_RX_KERNEL_PRIO,\n};\n\n#define RDMA_RX_IPSEC_NUM_PRIOS 1\n#define RDMA_RX_IPSEC_NUM_LEVELS 2\n#define RDMA_RX_IPSEC_MIN_LEVEL  (RDMA_RX_IPSEC_NUM_LEVELS)\n\n#define RDMA_RX_BYPASS_MIN_LEVEL MLX5_BY_PASS_NUM_REGULAR_PRIOS\n#define RDMA_RX_KERNEL_MIN_LEVEL (RDMA_RX_BYPASS_MIN_LEVEL + 1)\n#define RDMA_RX_COUNTERS_MIN_LEVEL (RDMA_RX_KERNEL_MIN_LEVEL + 2)\n\n#define RDMA_RX_MACSEC_NUM_PRIOS 1\n#define RDMA_RX_MACSEC_PRIO_NUM_LEVELS 2\n#define RDMA_RX_MACSEC_MIN_LEVEL  (RDMA_RX_COUNTERS_MIN_LEVEL + RDMA_RX_MACSEC_NUM_PRIOS)\n\nstatic struct init_tree_node rdma_rx_root_fs = {\n\t.type = FS_TYPE_NAMESPACE,\n\t.ar_size = 5,\n\t.children = (struct init_tree_node[]) {\n\t\t[RDMA_RX_IPSEC_PRIO] =\n\t\tADD_PRIO(0, RDMA_RX_IPSEC_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(RDMA_RX_IPSEC_NUM_PRIOS,\n\t\t\t\t\t\t  RDMA_RX_IPSEC_NUM_LEVELS))),\n\t\t[RDMA_RX_MACSEC_PRIO] =\n\t\tADD_PRIO(0, RDMA_RX_MACSEC_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(RDMA_RX_MACSEC_NUM_PRIOS,\n\t\t\t\t\t\t  RDMA_RX_MACSEC_PRIO_NUM_LEVELS))),\n\t\t[RDMA_RX_COUNTERS_PRIO] =\n\t\tADD_PRIO(0, RDMA_RX_COUNTERS_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(MLX5_RDMA_RX_NUM_COUNTERS_PRIOS,\n\t\t\t\t\t\t  RDMA_RX_COUNTERS_PRIO_NUM_LEVELS))),\n\t\t[RDMA_RX_BYPASS_PRIO] =\n\t\tADD_PRIO(0, RDMA_RX_BYPASS_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(MLX5_BY_PASS_NUM_REGULAR_PRIOS,\n\t\t\t\t\t\t  BY_PASS_PRIO_NUM_LEVELS))),\n\t\t[RDMA_RX_KERNEL_PRIO] =\n\t\tADD_PRIO(0, RDMA_RX_KERNEL_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_SWITCH_DOMAIN,\n\t\t\t\tADD_MULTIPLE_PRIO(1, 1))),\n\t}\n};\n\nenum {\n\tRDMA_TX_COUNTERS_PRIO,\n\tRDMA_TX_IPSEC_PRIO,\n\tRDMA_TX_MACSEC_PRIO,\n\tRDMA_TX_BYPASS_PRIO,\n};\n\n#define RDMA_TX_BYPASS_MIN_LEVEL MLX5_BY_PASS_NUM_PRIOS\n#define RDMA_TX_COUNTERS_MIN_LEVEL (RDMA_TX_BYPASS_MIN_LEVEL + 1)\n\n#define RDMA_TX_IPSEC_NUM_PRIOS 1\n#define RDMA_TX_IPSEC_PRIO_NUM_LEVELS 1\n#define RDMA_TX_IPSEC_MIN_LEVEL  (RDMA_TX_COUNTERS_MIN_LEVEL + RDMA_TX_IPSEC_NUM_PRIOS)\n\n#define RDMA_TX_MACSEC_NUM_PRIOS 1\n#define RDMA_TX_MACESC_PRIO_NUM_LEVELS 1\n#define RDMA_TX_MACSEC_MIN_LEVEL  (RDMA_TX_COUNTERS_MIN_LEVEL + RDMA_TX_MACSEC_NUM_PRIOS)\n\nstatic struct init_tree_node rdma_tx_root_fs = {\n\t.type = FS_TYPE_NAMESPACE,\n\t.ar_size = 4,\n\t.children = (struct init_tree_node[]) {\n\t\t[RDMA_TX_COUNTERS_PRIO] =\n\t\tADD_PRIO(0, RDMA_TX_COUNTERS_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(MLX5_RDMA_TX_NUM_COUNTERS_PRIOS,\n\t\t\t\t\t\t  RDMA_TX_COUNTERS_PRIO_NUM_LEVELS))),\n\t\t[RDMA_TX_IPSEC_PRIO] =\n\t\tADD_PRIO(0, RDMA_TX_IPSEC_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(RDMA_TX_IPSEC_NUM_PRIOS,\n\t\t\t\t\t\t  RDMA_TX_IPSEC_PRIO_NUM_LEVELS))),\n\t\t[RDMA_TX_MACSEC_PRIO] =\n\t\tADD_PRIO(0, RDMA_TX_MACSEC_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(RDMA_TX_MACSEC_NUM_PRIOS,\n\t\t\t\t\t\t  RDMA_TX_MACESC_PRIO_NUM_LEVELS))),\n\t\t[RDMA_TX_BYPASS_PRIO] =\n\t\tADD_PRIO(0, RDMA_TX_BYPASS_MIN_LEVEL, 0,\n\t\t\t FS_CHAINING_CAPS_RDMA_TX,\n\t\t\t ADD_NS(MLX5_FLOW_TABLE_MISS_ACTION_DEF,\n\t\t\t\tADD_MULTIPLE_PRIO(RDMA_TX_BYPASS_MIN_LEVEL,\n\t\t\t\t\t\t  BY_PASS_PRIO_NUM_LEVELS))),\n\t}\n};\n\nenum fs_i_lock_class {\n\tFS_LOCK_GRANDPARENT,\n\tFS_LOCK_PARENT,\n\tFS_LOCK_CHILD\n};\n\nstatic const struct rhashtable_params rhash_fte = {\n\t.key_len = sizeof_field(struct fs_fte, val),\n\t.key_offset = offsetof(struct fs_fte, val),\n\t.head_offset = offsetof(struct fs_fte, hash),\n\t.automatic_shrinking = true,\n\t.min_size = 1,\n};\n\nstatic const struct rhashtable_params rhash_fg = {\n\t.key_len = sizeof_field(struct mlx5_flow_group, mask),\n\t.key_offset = offsetof(struct mlx5_flow_group, mask),\n\t.head_offset = offsetof(struct mlx5_flow_group, hash),\n\t.automatic_shrinking = true,\n\t.min_size = 1,\n\n};\n\nstatic void del_hw_flow_table(struct fs_node *node);\nstatic void del_hw_flow_group(struct fs_node *node);\nstatic void del_hw_fte(struct fs_node *node);\nstatic void del_sw_flow_table(struct fs_node *node);\nstatic void del_sw_flow_group(struct fs_node *node);\nstatic void del_sw_fte(struct fs_node *node);\nstatic void del_sw_prio(struct fs_node *node);\nstatic void del_sw_ns(struct fs_node *node);\n \nstatic void del_sw_hw_rule(struct fs_node *node);\nstatic bool mlx5_flow_dests_cmp(struct mlx5_flow_destination *d1,\n\t\t\t\tstruct mlx5_flow_destination *d2);\nstatic void cleanup_root_ns(struct mlx5_flow_root_namespace *root_ns);\nstatic struct mlx5_flow_rule *\nfind_flow_rule(struct fs_fte *fte,\n\t       struct mlx5_flow_destination *dest);\n\nstatic void tree_init_node(struct fs_node *node,\n\t\t\t   void (*del_hw_func)(struct fs_node *),\n\t\t\t   void (*del_sw_func)(struct fs_node *))\n{\n\trefcount_set(&node->refcount, 1);\n\tINIT_LIST_HEAD(&node->list);\n\tINIT_LIST_HEAD(&node->children);\n\tinit_rwsem(&node->lock);\n\tnode->del_hw_func = del_hw_func;\n\tnode->del_sw_func = del_sw_func;\n\tnode->active = false;\n}\n\nstatic void tree_add_node(struct fs_node *node, struct fs_node *parent)\n{\n\tif (parent)\n\t\trefcount_inc(&parent->refcount);\n\tnode->parent = parent;\n\n\t \n\tif (!parent)\n\t\tnode->root = node;\n\telse\n\t\tnode->root = parent->root;\n}\n\nstatic int tree_get_node(struct fs_node *node)\n{\n\treturn refcount_inc_not_zero(&node->refcount);\n}\n\nstatic void nested_down_read_ref_node(struct fs_node *node,\n\t\t\t\t      enum fs_i_lock_class class)\n{\n\tif (node) {\n\t\tdown_read_nested(&node->lock, class);\n\t\trefcount_inc(&node->refcount);\n\t}\n}\n\nstatic void nested_down_write_ref_node(struct fs_node *node,\n\t\t\t\t       enum fs_i_lock_class class)\n{\n\tif (node) {\n\t\tdown_write_nested(&node->lock, class);\n\t\trefcount_inc(&node->refcount);\n\t}\n}\n\nstatic void down_write_ref_node(struct fs_node *node, bool locked)\n{\n\tif (node) {\n\t\tif (!locked)\n\t\t\tdown_write(&node->lock);\n\t\trefcount_inc(&node->refcount);\n\t}\n}\n\nstatic void up_read_ref_node(struct fs_node *node)\n{\n\trefcount_dec(&node->refcount);\n\tup_read(&node->lock);\n}\n\nstatic void up_write_ref_node(struct fs_node *node, bool locked)\n{\n\trefcount_dec(&node->refcount);\n\tif (!locked)\n\t\tup_write(&node->lock);\n}\n\nstatic void tree_put_node(struct fs_node *node, bool locked)\n{\n\tstruct fs_node *parent_node = node->parent;\n\n\tif (refcount_dec_and_test(&node->refcount)) {\n\t\tif (node->del_hw_func)\n\t\t\tnode->del_hw_func(node);\n\t\tif (parent_node) {\n\t\t\tdown_write_ref_node(parent_node, locked);\n\t\t\tlist_del_init(&node->list);\n\t\t}\n\t\tnode->del_sw_func(node);\n\t\tif (parent_node)\n\t\t\tup_write_ref_node(parent_node, locked);\n\t\tnode = NULL;\n\t}\n\tif (!node && parent_node)\n\t\ttree_put_node(parent_node, locked);\n}\n\nstatic int tree_remove_node(struct fs_node *node, bool locked)\n{\n\tif (refcount_read(&node->refcount) > 1) {\n\t\trefcount_dec(&node->refcount);\n\t\treturn -EEXIST;\n\t}\n\ttree_put_node(node, locked);\n\treturn 0;\n}\n\nstatic struct fs_prio *find_prio(struct mlx5_flow_namespace *ns,\n\t\t\t\t unsigned int prio)\n{\n\tstruct fs_prio *iter_prio;\n\n\tfs_for_each_prio(iter_prio, ns) {\n\t\tif (iter_prio->prio == prio)\n\t\t\treturn iter_prio;\n\t}\n\n\treturn NULL;\n}\n\nstatic bool is_fwd_next_action(u32 action)\n{\n\treturn action & (MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO |\n\t\t\t MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_NS);\n}\n\nstatic bool is_fwd_dest_type(enum mlx5_flow_destination_type type)\n{\n\treturn type == MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE_NUM ||\n\t\ttype == MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE ||\n\t\ttype == MLX5_FLOW_DESTINATION_TYPE_UPLINK ||\n\t\ttype == MLX5_FLOW_DESTINATION_TYPE_VPORT ||\n\t\ttype == MLX5_FLOW_DESTINATION_TYPE_FLOW_SAMPLER ||\n\t\ttype == MLX5_FLOW_DESTINATION_TYPE_TIR ||\n\t\ttype == MLX5_FLOW_DESTINATION_TYPE_RANGE ||\n\t\ttype == MLX5_FLOW_DESTINATION_TYPE_TABLE_TYPE;\n}\n\nstatic bool check_valid_spec(const struct mlx5_flow_spec *spec)\n{\n\tint i;\n\n\tfor (i = 0; i < MLX5_ST_SZ_DW_MATCH_PARAM; i++)\n\t\tif (spec->match_value[i] & ~spec->match_criteria[i]) {\n\t\t\tpr_warn(\"mlx5_core: match_value differs from match_criteria\\n\");\n\t\t\treturn false;\n\t\t}\n\n\treturn true;\n}\n\nstruct mlx5_flow_root_namespace *find_root(struct fs_node *node)\n{\n\tstruct fs_node *root;\n\tstruct mlx5_flow_namespace *ns;\n\n\troot = node->root;\n\n\tif (WARN_ON(root->type != FS_TYPE_NAMESPACE)) {\n\t\tpr_warn(\"mlx5: flow steering node is not in tree or garbaged\\n\");\n\t\treturn NULL;\n\t}\n\n\tns = container_of(root, struct mlx5_flow_namespace, node);\n\treturn container_of(ns, struct mlx5_flow_root_namespace, ns);\n}\n\nstatic inline struct mlx5_flow_steering *get_steering(struct fs_node *node)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(node);\n\n\tif (root)\n\t\treturn root->dev->priv.steering;\n\treturn NULL;\n}\n\nstatic inline struct mlx5_core_dev *get_dev(struct fs_node *node)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(node);\n\n\tif (root)\n\t\treturn root->dev;\n\treturn NULL;\n}\n\nstatic void del_sw_ns(struct fs_node *node)\n{\n\tkfree(node);\n}\n\nstatic void del_sw_prio(struct fs_node *node)\n{\n\tkfree(node);\n}\n\nstatic void del_hw_flow_table(struct fs_node *node)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_table *ft;\n\tstruct mlx5_core_dev *dev;\n\tint err;\n\n\tfs_get_obj(ft, node);\n\tdev = get_dev(&ft->node);\n\troot = find_root(&ft->node);\n\ttrace_mlx5_fs_del_ft(ft);\n\n\tif (node->active) {\n\t\terr = root->cmds->destroy_flow_table(root, ft);\n\t\tif (err)\n\t\t\tmlx5_core_warn(dev, \"flow steering can't destroy ft\\n\");\n\t}\n}\n\nstatic void del_sw_flow_table(struct fs_node *node)\n{\n\tstruct mlx5_flow_table *ft;\n\tstruct fs_prio *prio;\n\n\tfs_get_obj(ft, node);\n\n\trhltable_destroy(&ft->fgs_hash);\n\tif (ft->node.parent) {\n\t\tfs_get_obj(prio, ft->node.parent);\n\t\tprio->num_ft--;\n\t}\n\tkfree(ft);\n}\n\nstatic void modify_fte(struct fs_fte *fte)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_table *ft;\n\tstruct mlx5_flow_group *fg;\n\tstruct mlx5_core_dev *dev;\n\tint err;\n\n\tfs_get_obj(fg, fte->node.parent);\n\tfs_get_obj(ft, fg->node.parent);\n\tdev = get_dev(&fte->node);\n\n\troot = find_root(&ft->node);\n\terr = root->cmds->update_fte(root, ft, fg, fte->modify_mask, fte);\n\tif (err)\n\t\tmlx5_core_warn(dev,\n\t\t\t       \"%s can't del rule fg id=%d fte_index=%d\\n\",\n\t\t\t       __func__, fg->id, fte->index);\n\tfte->modify_mask = 0;\n}\n\nstatic void del_sw_hw_rule(struct fs_node *node)\n{\n\tstruct mlx5_flow_rule *rule;\n\tstruct fs_fte *fte;\n\n\tfs_get_obj(rule, node);\n\tfs_get_obj(fte, rule->node.parent);\n\ttrace_mlx5_fs_del_rule(rule);\n\tif (is_fwd_next_action(rule->sw_action)) {\n\t\tmutex_lock(&rule->dest_attr.ft->lock);\n\t\tlist_del(&rule->next_ft);\n\t\tmutex_unlock(&rule->dest_attr.ft->lock);\n\t}\n\n\tif (rule->dest_attr.type == MLX5_FLOW_DESTINATION_TYPE_COUNTER) {\n\t\t--fte->dests_size;\n\t\tfte->modify_mask |=\n\t\t\tBIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_ACTION) |\n\t\t\tBIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_FLOW_COUNTERS);\n\t\tfte->action.action &= ~MLX5_FLOW_CONTEXT_ACTION_COUNT;\n\t\tgoto out;\n\t}\n\n\tif (rule->dest_attr.type == MLX5_FLOW_DESTINATION_TYPE_PORT) {\n\t\t--fte->dests_size;\n\t\tfte->modify_mask |= BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_ACTION);\n\t\tfte->action.action &= ~MLX5_FLOW_CONTEXT_ACTION_ALLOW;\n\t\tgoto out;\n\t}\n\n\tif (is_fwd_dest_type(rule->dest_attr.type)) {\n\t\t--fte->dests_size;\n\t\t--fte->fwd_dests;\n\n\t\tif (!fte->fwd_dests)\n\t\t\tfte->action.action &=\n\t\t\t\t~MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;\n\t\tfte->modify_mask |=\n\t\t\tBIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_DESTINATION_LIST);\n\t\tgoto out;\n\t}\nout:\n\tkfree(rule);\n}\n\nstatic void del_hw_fte(struct fs_node *node)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_table *ft;\n\tstruct mlx5_flow_group *fg;\n\tstruct mlx5_core_dev *dev;\n\tstruct fs_fte *fte;\n\tint err;\n\n\tfs_get_obj(fte, node);\n\tfs_get_obj(fg, fte->node.parent);\n\tfs_get_obj(ft, fg->node.parent);\n\n\ttrace_mlx5_fs_del_fte(fte);\n\tWARN_ON(fte->dests_size);\n\tdev = get_dev(&ft->node);\n\troot = find_root(&ft->node);\n\tif (node->active) {\n\t\terr = root->cmds->delete_fte(root, ft, fte);\n\t\tif (err)\n\t\t\tmlx5_core_warn(dev,\n\t\t\t\t       \"flow steering can't delete fte in index %d of flow group id %d\\n\",\n\t\t\t\t       fte->index, fg->id);\n\t\tnode->active = false;\n\t}\n}\n\nstatic void del_sw_fte(struct fs_node *node)\n{\n\tstruct mlx5_flow_steering *steering = get_steering(node);\n\tstruct mlx5_flow_group *fg;\n\tstruct fs_fte *fte;\n\tint err;\n\n\tfs_get_obj(fte, node);\n\tfs_get_obj(fg, fte->node.parent);\n\n\terr = rhashtable_remove_fast(&fg->ftes_hash,\n\t\t\t\t     &fte->hash,\n\t\t\t\t     rhash_fte);\n\tWARN_ON(err);\n\tida_free(&fg->fte_allocator, fte->index - fg->start_index);\n\tkmem_cache_free(steering->ftes_cache, fte);\n}\n\nstatic void del_hw_flow_group(struct fs_node *node)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_group *fg;\n\tstruct mlx5_flow_table *ft;\n\tstruct mlx5_core_dev *dev;\n\n\tfs_get_obj(fg, node);\n\tfs_get_obj(ft, fg->node.parent);\n\tdev = get_dev(&ft->node);\n\ttrace_mlx5_fs_del_fg(fg);\n\n\troot = find_root(&ft->node);\n\tif (fg->node.active && root->cmds->destroy_flow_group(root, ft, fg))\n\t\tmlx5_core_warn(dev, \"flow steering can't destroy fg %d of ft %d\\n\",\n\t\t\t       fg->id, ft->id);\n}\n\nstatic void del_sw_flow_group(struct fs_node *node)\n{\n\tstruct mlx5_flow_steering *steering = get_steering(node);\n\tstruct mlx5_flow_group *fg;\n\tstruct mlx5_flow_table *ft;\n\tint err;\n\n\tfs_get_obj(fg, node);\n\tfs_get_obj(ft, fg->node.parent);\n\n\trhashtable_destroy(&fg->ftes_hash);\n\tida_destroy(&fg->fte_allocator);\n\tif (ft->autogroup.active &&\n\t    fg->max_ftes == ft->autogroup.group_size &&\n\t    fg->start_index < ft->autogroup.max_fte)\n\t\tft->autogroup.num_groups--;\n\terr = rhltable_remove(&ft->fgs_hash,\n\t\t\t      &fg->hash,\n\t\t\t      rhash_fg);\n\tWARN_ON(err);\n\tkmem_cache_free(steering->fgs_cache, fg);\n}\n\nstatic int insert_fte(struct mlx5_flow_group *fg, struct fs_fte *fte)\n{\n\tint index;\n\tint ret;\n\n\tindex = ida_alloc_max(&fg->fte_allocator, fg->max_ftes - 1, GFP_KERNEL);\n\tif (index < 0)\n\t\treturn index;\n\n\tfte->index = index + fg->start_index;\n\tret = rhashtable_insert_fast(&fg->ftes_hash,\n\t\t\t\t     &fte->hash,\n\t\t\t\t     rhash_fte);\n\tif (ret)\n\t\tgoto err_ida_remove;\n\n\ttree_add_node(&fte->node, &fg->node);\n\tlist_add_tail(&fte->node.list, &fg->node.children);\n\treturn 0;\n\nerr_ida_remove:\n\tida_free(&fg->fte_allocator, index);\n\treturn ret;\n}\n\nstatic struct fs_fte *alloc_fte(struct mlx5_flow_table *ft,\n\t\t\t\tconst struct mlx5_flow_spec *spec,\n\t\t\t\tstruct mlx5_flow_act *flow_act)\n{\n\tstruct mlx5_flow_steering *steering = get_steering(&ft->node);\n\tstruct fs_fte *fte;\n\n\tfte = kmem_cache_zalloc(steering->ftes_cache, GFP_KERNEL);\n\tif (!fte)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmemcpy(fte->val, &spec->match_value, sizeof(fte->val));\n\tfte->node.type =  FS_TYPE_FLOW_ENTRY;\n\tfte->action = *flow_act;\n\tfte->flow_context = spec->flow_context;\n\n\ttree_init_node(&fte->node, del_hw_fte, del_sw_fte);\n\n\treturn fte;\n}\n\nstatic void dealloc_flow_group(struct mlx5_flow_steering *steering,\n\t\t\t       struct mlx5_flow_group *fg)\n{\n\trhashtable_destroy(&fg->ftes_hash);\n\tkmem_cache_free(steering->fgs_cache, fg);\n}\n\nstatic struct mlx5_flow_group *alloc_flow_group(struct mlx5_flow_steering *steering,\n\t\t\t\t\t\tu8 match_criteria_enable,\n\t\t\t\t\t\tconst void *match_criteria,\n\t\t\t\t\t\tint start_index,\n\t\t\t\t\t\tint end_index)\n{\n\tstruct mlx5_flow_group *fg;\n\tint ret;\n\n\tfg = kmem_cache_zalloc(steering->fgs_cache, GFP_KERNEL);\n\tif (!fg)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = rhashtable_init(&fg->ftes_hash, &rhash_fte);\n\tif (ret) {\n\t\tkmem_cache_free(steering->fgs_cache, fg);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tida_init(&fg->fte_allocator);\n\tfg->mask.match_criteria_enable = match_criteria_enable;\n\tmemcpy(&fg->mask.match_criteria, match_criteria,\n\t       sizeof(fg->mask.match_criteria));\n\tfg->node.type =  FS_TYPE_FLOW_GROUP;\n\tfg->start_index = start_index;\n\tfg->max_ftes = end_index - start_index + 1;\n\n\treturn fg;\n}\n\nstatic struct mlx5_flow_group *alloc_insert_flow_group(struct mlx5_flow_table *ft,\n\t\t\t\t\t\t       u8 match_criteria_enable,\n\t\t\t\t\t\t       const void *match_criteria,\n\t\t\t\t\t\t       int start_index,\n\t\t\t\t\t\t       int end_index,\n\t\t\t\t\t\t       struct list_head *prev)\n{\n\tstruct mlx5_flow_steering *steering = get_steering(&ft->node);\n\tstruct mlx5_flow_group *fg;\n\tint ret;\n\n\tfg = alloc_flow_group(steering, match_criteria_enable, match_criteria,\n\t\t\t      start_index, end_index);\n\tif (IS_ERR(fg))\n\t\treturn fg;\n\n\t \n\tret = rhltable_insert(&ft->fgs_hash,\n\t\t\t      &fg->hash,\n\t\t\t      rhash_fg);\n\tif (ret) {\n\t\tdealloc_flow_group(steering, fg);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\ttree_init_node(&fg->node, del_hw_flow_group, del_sw_flow_group);\n\ttree_add_node(&fg->node, &ft->node);\n\t \n\tlist_add(&fg->node.list, prev);\n\tatomic_inc(&ft->node.version);\n\n\treturn fg;\n}\n\nstatic struct mlx5_flow_table *alloc_flow_table(int level, u16 vport,\n\t\t\t\t\t\tenum fs_flow_table_type table_type,\n\t\t\t\t\t\tenum fs_flow_table_op_mod op_mod,\n\t\t\t\t\t\tu32 flags)\n{\n\tstruct mlx5_flow_table *ft;\n\tint ret;\n\n\tft  = kzalloc(sizeof(*ft), GFP_KERNEL);\n\tif (!ft)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = rhltable_init(&ft->fgs_hash, &rhash_fg);\n\tif (ret) {\n\t\tkfree(ft);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tft->level = level;\n\tft->node.type = FS_TYPE_FLOW_TABLE;\n\tft->op_mod = op_mod;\n\tft->type = table_type;\n\tft->vport = vport;\n\tft->flags = flags;\n\tINIT_LIST_HEAD(&ft->fwd_rules);\n\tmutex_init(&ft->lock);\n\n\treturn ft;\n}\n\n \nstatic struct mlx5_flow_table *find_closest_ft_recursive(struct fs_node  *root,\n\t\t\t\t\t\t\t struct list_head *start,\n\t\t\t\t\t\t\t bool reverse)\n{\n#define list_advance_entry(pos, reverse)\t\t\\\n\t((reverse) ? list_prev_entry(pos, list) : list_next_entry(pos, list))\n\n#define list_for_each_advance_continue(pos, head, reverse)\t\\\n\tfor (pos = list_advance_entry(pos, reverse);\t\t\\\n\t     &pos->list != (head);\t\t\t\t\\\n\t     pos = list_advance_entry(pos, reverse))\n\n\tstruct fs_node *iter = list_entry(start, struct fs_node, list);\n\tstruct mlx5_flow_table *ft = NULL;\n\n\tif (!root)\n\t\treturn NULL;\n\n\tlist_for_each_advance_continue(iter, &root->children, reverse) {\n\t\tif (iter->type == FS_TYPE_FLOW_TABLE) {\n\t\t\tfs_get_obj(ft, iter);\n\t\t\treturn ft;\n\t\t}\n\t\tft = find_closest_ft_recursive(iter, &iter->children, reverse);\n\t\tif (ft)\n\t\t\treturn ft;\n\t}\n\n\treturn ft;\n}\n\nstatic struct fs_node *find_prio_chains_parent(struct fs_node *parent,\n\t\t\t\t\t       struct fs_node **child)\n{\n\tstruct fs_node *node = NULL;\n\n\twhile (parent && parent->type != FS_TYPE_PRIO_CHAINS) {\n\t\tnode = parent;\n\t\tparent = parent->parent;\n\t}\n\n\tif (child)\n\t\t*child = node;\n\n\treturn parent;\n}\n\n \nstatic struct mlx5_flow_table *find_closest_ft(struct fs_node *node, bool reverse,\n\t\t\t\t\t       bool skip)\n{\n\tstruct fs_node *prio_chains_parent = NULL;\n\tstruct mlx5_flow_table *ft = NULL;\n\tstruct fs_node *curr_node;\n\tstruct fs_node *parent;\n\n\tif (skip)\n\t\tprio_chains_parent = find_prio_chains_parent(node, NULL);\n\tparent = node->parent;\n\tcurr_node = node;\n\twhile (!ft && parent) {\n\t\tif (parent != prio_chains_parent)\n\t\t\tft = find_closest_ft_recursive(parent, &curr_node->list,\n\t\t\t\t\t\t       reverse);\n\t\tcurr_node = parent;\n\t\tparent = curr_node->parent;\n\t}\n\treturn ft;\n}\n\n \nstatic struct mlx5_flow_table *find_next_chained_ft(struct fs_node *node)\n{\n\treturn find_closest_ft(node, false, true);\n}\n\n \nstatic struct mlx5_flow_table *find_prev_chained_ft(struct fs_node *node)\n{\n\treturn find_closest_ft(node, true, true);\n}\n\nstatic struct mlx5_flow_table *find_next_fwd_ft(struct mlx5_flow_table *ft,\n\t\t\t\t\t\tstruct mlx5_flow_act *flow_act)\n{\n\tstruct fs_prio *prio;\n\tbool next_ns;\n\n\tnext_ns = flow_act->action & MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_NS;\n\tfs_get_obj(prio, next_ns ? ft->ns->node.parent : ft->node.parent);\n\n\treturn find_next_chained_ft(&prio->node);\n}\n\nstatic int connect_fts_in_prio(struct mlx5_core_dev *dev,\n\t\t\t       struct fs_prio *prio,\n\t\t\t       struct mlx5_flow_table *ft)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&prio->node);\n\tstruct mlx5_flow_table *iter;\n\tint err;\n\n\tfs_for_each_ft(iter, prio) {\n\t\terr = root->cmds->modify_flow_table(root, iter, ft);\n\t\tif (err) {\n\t\t\tmlx5_core_err(dev,\n\t\t\t\t      \"Failed to modify flow table id %d, type %d, err %d\\n\",\n\t\t\t\t      iter->id, iter->type, err);\n\t\t\t \n\t\t\treturn err;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic struct mlx5_flow_table *find_closet_ft_prio_chains(struct fs_node *node,\n\t\t\t\t\t\t\t  struct fs_node *parent,\n\t\t\t\t\t\t\t  struct fs_node **child,\n\t\t\t\t\t\t\t  bool reverse)\n{\n\tstruct mlx5_flow_table *ft;\n\n\tft = find_closest_ft(node, reverse, false);\n\n\tif (ft && parent == find_prio_chains_parent(&ft->node, child))\n\t\treturn ft;\n\n\treturn NULL;\n}\n\n \nstatic int connect_prev_fts(struct mlx5_core_dev *dev,\n\t\t\t    struct mlx5_flow_table *ft,\n\t\t\t    struct fs_prio *prio)\n{\n\tstruct fs_node *prio_parent, *parent = NULL, *child, *node;\n\tstruct mlx5_flow_table *prev_ft;\n\tint err = 0;\n\n\tprio_parent = find_prio_chains_parent(&prio->node, &child);\n\n\t \n\tif (prio_parent && !list_is_first(&child->list, &prio_parent->children))\n\t\treturn 0;\n\n\tprev_ft = find_prev_chained_ft(&prio->node);\n\twhile (prev_ft) {\n\t\tstruct fs_prio *prev_prio;\n\n\t\tfs_get_obj(prev_prio, prev_ft->node.parent);\n\t\terr = connect_fts_in_prio(dev, prev_prio, ft);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\tif (!parent) {\n\t\t\tparent = find_prio_chains_parent(&prev_prio->node, &child);\n\t\t\tif (!parent)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tnode = child;\n\t\tprev_ft = find_closet_ft_prio_chains(node, parent, &child, true);\n\t}\n\treturn err;\n}\n\nstatic int update_root_ft_create(struct mlx5_flow_table *ft, struct fs_prio\n\t\t\t\t *prio)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&prio->node);\n\tstruct mlx5_ft_underlay_qp *uqp;\n\tint min_level = INT_MAX;\n\tint err = 0;\n\tu32 qpn;\n\n\tif (root->root_ft)\n\t\tmin_level = root->root_ft->level;\n\n\tif (ft->level >= min_level)\n\t\treturn 0;\n\n\tif (list_empty(&root->underlay_qpns)) {\n\t\t \n\t\tqpn = 0;\n\t\terr = root->cmds->update_root_ft(root, ft, qpn, false);\n\t} else {\n\t\tlist_for_each_entry(uqp, &root->underlay_qpns, list) {\n\t\t\tqpn = uqp->qpn;\n\t\t\terr = root->cmds->update_root_ft(root, ft,\n\t\t\t\t\t\t\t qpn, false);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (err)\n\t\tmlx5_core_warn(root->dev,\n\t\t\t       \"Update root flow table of id(%u) qpn(%d) failed\\n\",\n\t\t\t       ft->id, qpn);\n\telse\n\t\troot->root_ft = ft;\n\n\treturn err;\n}\n\nstatic int _mlx5_modify_rule_destination(struct mlx5_flow_rule *rule,\n\t\t\t\t\t struct mlx5_flow_destination *dest)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_table *ft;\n\tstruct mlx5_flow_group *fg;\n\tstruct fs_fte *fte;\n\tint modify_mask = BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_DESTINATION_LIST);\n\tint err = 0;\n\n\tfs_get_obj(fte, rule->node.parent);\n\tif (!(fte->action.action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST))\n\t\treturn -EINVAL;\n\tdown_write_ref_node(&fte->node, false);\n\tfs_get_obj(fg, fte->node.parent);\n\tfs_get_obj(ft, fg->node.parent);\n\n\tmemcpy(&rule->dest_attr, dest, sizeof(*dest));\n\troot = find_root(&ft->node);\n\terr = root->cmds->update_fte(root, ft, fg,\n\t\t\t\t     modify_mask, fte);\n\tup_write_ref_node(&fte->node, false);\n\n\treturn err;\n}\n\nint mlx5_modify_rule_destination(struct mlx5_flow_handle *handle,\n\t\t\t\t struct mlx5_flow_destination *new_dest,\n\t\t\t\t struct mlx5_flow_destination *old_dest)\n{\n\tint i;\n\n\tif (!old_dest) {\n\t\tif (handle->num_rules != 1)\n\t\t\treturn -EINVAL;\n\t\treturn _mlx5_modify_rule_destination(handle->rule[0],\n\t\t\t\t\t\t     new_dest);\n\t}\n\n\tfor (i = 0; i < handle->num_rules; i++) {\n\t\tif (mlx5_flow_dests_cmp(old_dest, &handle->rule[i]->dest_attr))\n\t\t\treturn _mlx5_modify_rule_destination(handle->rule[i],\n\t\t\t\t\t\t\t     new_dest);\n\t}\n\n\treturn -EINVAL;\n}\n\n \nstatic int connect_fwd_rules(struct mlx5_core_dev *dev,\n\t\t\t     struct mlx5_flow_table *new_next_ft,\n\t\t\t     struct mlx5_flow_table *old_next_ft)\n{\n\tstruct mlx5_flow_destination dest = {};\n\tstruct mlx5_flow_rule *iter;\n\tint err = 0;\n\n\t \n\tif (!new_next_ft || !old_next_ft)\n\t\treturn 0;\n\n\tdest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\n\tdest.ft = new_next_ft;\n\n\tmutex_lock(&old_next_ft->lock);\n\tlist_splice_init(&old_next_ft->fwd_rules, &new_next_ft->fwd_rules);\n\tmutex_unlock(&old_next_ft->lock);\n\tlist_for_each_entry(iter, &new_next_ft->fwd_rules, next_ft) {\n\t\tif ((iter->sw_action & MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_NS) &&\n\t\t    iter->ft->ns == new_next_ft->ns)\n\t\t\tcontinue;\n\n\t\terr = _mlx5_modify_rule_destination(iter, &dest);\n\t\tif (err)\n\t\t\tpr_err(\"mlx5_core: failed to modify rule to point on flow table %d\\n\",\n\t\t\t       new_next_ft->id);\n\t}\n\treturn 0;\n}\n\nstatic int connect_flow_table(struct mlx5_core_dev *dev, struct mlx5_flow_table *ft,\n\t\t\t      struct fs_prio *prio)\n{\n\tstruct mlx5_flow_table *next_ft, *first_ft;\n\tint err = 0;\n\n\t \n\n\tfirst_ft = list_first_entry_or_null(&prio->node.children,\n\t\t\t\t\t    struct mlx5_flow_table, node.list);\n\tif (!first_ft || first_ft->level > ft->level) {\n\t\terr = connect_prev_fts(dev, ft, prio);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tnext_ft = first_ft ? first_ft : find_next_chained_ft(&prio->node);\n\t\terr = connect_fwd_rules(dev, ft, next_ft);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE(dev,\n\t\t\t       flow_table_properties_nic_receive.modify_root))\n\t\terr = update_root_ft_create(ft, prio);\n\treturn err;\n}\n\nstatic void list_add_flow_table(struct mlx5_flow_table *ft,\n\t\t\t\tstruct fs_prio *prio)\n{\n\tstruct list_head *prev = &prio->node.children;\n\tstruct mlx5_flow_table *iter;\n\n\tfs_for_each_ft(iter, prio) {\n\t\tif (iter->level > ft->level)\n\t\t\tbreak;\n\t\tprev = &iter->node.list;\n\t}\n\tlist_add(&ft->node.list, prev);\n}\n\nstatic struct mlx5_flow_table *__mlx5_create_flow_table(struct mlx5_flow_namespace *ns,\n\t\t\t\t\t\t\tstruct mlx5_flow_table_attr *ft_attr,\n\t\t\t\t\t\t\tenum fs_flow_table_op_mod op_mod,\n\t\t\t\t\t\t\tu16 vport)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&ns->node);\n\tbool unmanaged = ft_attr->flags & MLX5_FLOW_TABLE_UNMANAGED;\n\tstruct mlx5_flow_table *next_ft;\n\tstruct fs_prio *fs_prio = NULL;\n\tstruct mlx5_flow_table *ft;\n\tint err;\n\n\tif (!root) {\n\t\tpr_err(\"mlx5: flow steering failed to find root of namespace\\n\");\n\t\treturn ERR_PTR(-ENODEV);\n\t}\n\n\tmutex_lock(&root->chain_lock);\n\tfs_prio = find_prio(ns, ft_attr->prio);\n\tif (!fs_prio) {\n\t\terr = -EINVAL;\n\t\tgoto unlock_root;\n\t}\n\tif (!unmanaged) {\n\t\t \n\t\tif (ft_attr->level >= fs_prio->num_levels) {\n\t\t\terr = -ENOSPC;\n\t\t\tgoto unlock_root;\n\t\t}\n\n\t\tft_attr->level += fs_prio->start_level;\n\t}\n\n\t \n\tft = alloc_flow_table(ft_attr->level,\n\t\t\t      vport,\n\t\t\t      root->table_type,\n\t\t\t      op_mod, ft_attr->flags);\n\tif (IS_ERR(ft)) {\n\t\terr = PTR_ERR(ft);\n\t\tgoto unlock_root;\n\t}\n\n\ttree_init_node(&ft->node, del_hw_flow_table, del_sw_flow_table);\n\tnext_ft = unmanaged ? ft_attr->next_ft :\n\t\t\t      find_next_chained_ft(&fs_prio->node);\n\tft->def_miss_action = ns->def_miss_action;\n\tft->ns = ns;\n\terr = root->cmds->create_flow_table(root, ft, ft_attr, next_ft);\n\tif (err)\n\t\tgoto free_ft;\n\n\tif (!unmanaged) {\n\t\terr = connect_flow_table(root->dev, ft, fs_prio);\n\t\tif (err)\n\t\t\tgoto destroy_ft;\n\t}\n\n\tft->node.active = true;\n\tdown_write_ref_node(&fs_prio->node, false);\n\tif (!unmanaged) {\n\t\ttree_add_node(&ft->node, &fs_prio->node);\n\t\tlist_add_flow_table(ft, fs_prio);\n\t} else {\n\t\tft->node.root = fs_prio->node.root;\n\t}\n\tfs_prio->num_ft++;\n\tup_write_ref_node(&fs_prio->node, false);\n\tmutex_unlock(&root->chain_lock);\n\ttrace_mlx5_fs_add_ft(ft);\n\treturn ft;\ndestroy_ft:\n\troot->cmds->destroy_flow_table(root, ft);\nfree_ft:\n\trhltable_destroy(&ft->fgs_hash);\n\tkfree(ft);\nunlock_root:\n\tmutex_unlock(&root->chain_lock);\n\treturn ERR_PTR(err);\n}\n\nstruct mlx5_flow_table *mlx5_create_flow_table(struct mlx5_flow_namespace *ns,\n\t\t\t\t\t       struct mlx5_flow_table_attr *ft_attr)\n{\n\treturn __mlx5_create_flow_table(ns, ft_attr, FS_FT_OP_MOD_NORMAL, 0);\n}\nEXPORT_SYMBOL(mlx5_create_flow_table);\n\nu32 mlx5_flow_table_id(struct mlx5_flow_table *ft)\n{\n\treturn ft->id;\n}\nEXPORT_SYMBOL(mlx5_flow_table_id);\n\nstruct mlx5_flow_table *\nmlx5_create_vport_flow_table(struct mlx5_flow_namespace *ns,\n\t\t\t     struct mlx5_flow_table_attr *ft_attr, u16 vport)\n{\n\treturn __mlx5_create_flow_table(ns, ft_attr, FS_FT_OP_MOD_NORMAL, vport);\n}\n\nstruct mlx5_flow_table*\nmlx5_create_lag_demux_flow_table(struct mlx5_flow_namespace *ns,\n\t\t\t\t int prio, u32 level)\n{\n\tstruct mlx5_flow_table_attr ft_attr = {};\n\n\tft_attr.level = level;\n\tft_attr.prio  = prio;\n\tft_attr.max_fte = 1;\n\n\treturn __mlx5_create_flow_table(ns, &ft_attr, FS_FT_OP_MOD_LAG_DEMUX, 0);\n}\nEXPORT_SYMBOL(mlx5_create_lag_demux_flow_table);\n\n#define MAX_FLOW_GROUP_SIZE BIT(24)\nstruct mlx5_flow_table*\nmlx5_create_auto_grouped_flow_table(struct mlx5_flow_namespace *ns,\n\t\t\t\t    struct mlx5_flow_table_attr *ft_attr)\n{\n\tint num_reserved_entries = ft_attr->autogroup.num_reserved_entries;\n\tint max_num_groups = ft_attr->autogroup.max_num_groups;\n\tstruct mlx5_flow_table *ft;\n\tint autogroups_max_fte;\n\n\tft = mlx5_create_flow_table(ns, ft_attr);\n\tif (IS_ERR(ft))\n\t\treturn ft;\n\n\tautogroups_max_fte = ft->max_fte - num_reserved_entries;\n\tif (max_num_groups > autogroups_max_fte)\n\t\tgoto err_validate;\n\tif (num_reserved_entries > ft->max_fte)\n\t\tgoto err_validate;\n\n\t \n\tif (autogroups_max_fte / (max_num_groups + 1) > MAX_FLOW_GROUP_SIZE)\n\t\tmax_num_groups = (autogroups_max_fte / MAX_FLOW_GROUP_SIZE) - 1;\n\n\tft->autogroup.active = true;\n\tft->autogroup.required_groups = max_num_groups;\n\tft->autogroup.max_fte = autogroups_max_fte;\n\t \n\tft->autogroup.group_size = autogroups_max_fte / (max_num_groups + 1);\n\n\treturn ft;\n\nerr_validate:\n\tmlx5_destroy_flow_table(ft);\n\treturn ERR_PTR(-ENOSPC);\n}\nEXPORT_SYMBOL(mlx5_create_auto_grouped_flow_table);\n\nstruct mlx5_flow_group *mlx5_create_flow_group(struct mlx5_flow_table *ft,\n\t\t\t\t\t       u32 *fg_in)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&ft->node);\n\tvoid *match_criteria = MLX5_ADDR_OF(create_flow_group_in,\n\t\t\t\t\t    fg_in, match_criteria);\n\tu8 match_criteria_enable = MLX5_GET(create_flow_group_in,\n\t\t\t\t\t    fg_in,\n\t\t\t\t\t    match_criteria_enable);\n\tint start_index = MLX5_GET(create_flow_group_in, fg_in,\n\t\t\t\t   start_flow_index);\n\tint end_index = MLX5_GET(create_flow_group_in, fg_in,\n\t\t\t\t end_flow_index);\n\tstruct mlx5_flow_group *fg;\n\tint err;\n\n\tif (ft->autogroup.active && start_index < ft->autogroup.max_fte)\n\t\treturn ERR_PTR(-EPERM);\n\n\tdown_write_ref_node(&ft->node, false);\n\tfg = alloc_insert_flow_group(ft, match_criteria_enable, match_criteria,\n\t\t\t\t     start_index, end_index,\n\t\t\t\t     ft->node.children.prev);\n\tup_write_ref_node(&ft->node, false);\n\tif (IS_ERR(fg))\n\t\treturn fg;\n\n\terr = root->cmds->create_flow_group(root, ft, fg_in, fg);\n\tif (err) {\n\t\ttree_put_node(&fg->node, false);\n\t\treturn ERR_PTR(err);\n\t}\n\ttrace_mlx5_fs_add_fg(fg);\n\tfg->node.active = true;\n\n\treturn fg;\n}\nEXPORT_SYMBOL(mlx5_create_flow_group);\n\nstatic struct mlx5_flow_rule *alloc_rule(struct mlx5_flow_destination *dest)\n{\n\tstruct mlx5_flow_rule *rule;\n\n\trule = kzalloc(sizeof(*rule), GFP_KERNEL);\n\tif (!rule)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&rule->next_ft);\n\trule->node.type = FS_TYPE_FLOW_DEST;\n\tif (dest)\n\t\tmemcpy(&rule->dest_attr, dest, sizeof(*dest));\n\telse\n\t\trule->dest_attr.type = MLX5_FLOW_DESTINATION_TYPE_NONE;\n\n\treturn rule;\n}\n\nstatic struct mlx5_flow_handle *alloc_handle(int num_rules)\n{\n\tstruct mlx5_flow_handle *handle;\n\n\thandle = kzalloc(struct_size(handle, rule, num_rules), GFP_KERNEL);\n\tif (!handle)\n\t\treturn NULL;\n\n\thandle->num_rules = num_rules;\n\n\treturn handle;\n}\n\nstatic void destroy_flow_handle(struct fs_fte *fte,\n\t\t\t\tstruct mlx5_flow_handle *handle,\n\t\t\t\tstruct mlx5_flow_destination *dest,\n\t\t\t\tint i)\n{\n\tfor (; --i >= 0;) {\n\t\tif (refcount_dec_and_test(&handle->rule[i]->node.refcount)) {\n\t\t\tfte->dests_size--;\n\t\t\tlist_del(&handle->rule[i]->node.list);\n\t\t\tkfree(handle->rule[i]);\n\t\t}\n\t}\n\tkfree(handle);\n}\n\nstatic struct mlx5_flow_handle *\ncreate_flow_handle(struct fs_fte *fte,\n\t\t   struct mlx5_flow_destination *dest,\n\t\t   int dest_num,\n\t\t   int *modify_mask,\n\t\t   bool *new_rule)\n{\n\tstruct mlx5_flow_handle *handle;\n\tstruct mlx5_flow_rule *rule = NULL;\n\tstatic int count = BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_FLOW_COUNTERS);\n\tstatic int dst = BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_DESTINATION_LIST);\n\tint type;\n\tint i = 0;\n\n\thandle = alloc_handle((dest_num) ? dest_num : 1);\n\tif (!handle)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdo {\n\t\tif (dest) {\n\t\t\trule = find_flow_rule(fte, dest + i);\n\t\t\tif (rule) {\n\t\t\t\trefcount_inc(&rule->node.refcount);\n\t\t\t\tgoto rule_found;\n\t\t\t}\n\t\t}\n\n\t\t*new_rule = true;\n\t\trule = alloc_rule(dest + i);\n\t\tif (!rule)\n\t\t\tgoto free_rules;\n\n\t\t \n\t\ttree_init_node(&rule->node, NULL, del_sw_hw_rule);\n\t\tif (dest &&\n\t\t    dest[i].type != MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE)\n\t\t\tlist_add(&rule->node.list, &fte->node.children);\n\t\telse\n\t\t\tlist_add_tail(&rule->node.list, &fte->node.children);\n\t\tif (dest) {\n\t\t\tfte->dests_size++;\n\n\t\t\tif (is_fwd_dest_type(dest[i].type))\n\t\t\t\tfte->fwd_dests++;\n\n\t\t\ttype = dest[i].type ==\n\t\t\t\tMLX5_FLOW_DESTINATION_TYPE_COUNTER;\n\t\t\t*modify_mask |= type ? count : dst;\n\t\t}\nrule_found:\n\t\thandle->rule[i] = rule;\n\t} while (++i < dest_num);\n\n\treturn handle;\n\nfree_rules:\n\tdestroy_flow_handle(fte, handle, dest, i);\n\treturn ERR_PTR(-ENOMEM);\n}\n\n \nstatic struct mlx5_flow_handle *\nadd_rule_fte(struct fs_fte *fte,\n\t     struct mlx5_flow_group *fg,\n\t     struct mlx5_flow_destination *dest,\n\t     int dest_num,\n\t     bool update_action)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_handle *handle;\n\tstruct mlx5_flow_table *ft;\n\tint modify_mask = 0;\n\tint err;\n\tbool new_rule = false;\n\n\thandle = create_flow_handle(fte, dest, dest_num, &modify_mask,\n\t\t\t\t    &new_rule);\n\tif (IS_ERR(handle) || !new_rule)\n\t\tgoto out;\n\n\tif (update_action)\n\t\tmodify_mask |= BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_ACTION);\n\n\tfs_get_obj(ft, fg->node.parent);\n\troot = find_root(&fg->node);\n\tif (!(fte->status & FS_FTE_STATUS_EXISTING))\n\t\terr = root->cmds->create_fte(root, ft, fg, fte);\n\telse\n\t\terr = root->cmds->update_fte(root, ft, fg, modify_mask, fte);\n\tif (err)\n\t\tgoto free_handle;\n\n\tfte->node.active = true;\n\tfte->status |= FS_FTE_STATUS_EXISTING;\n\tatomic_inc(&fg->node.version);\n\nout:\n\treturn handle;\n\nfree_handle:\n\tdestroy_flow_handle(fte, handle, dest, handle->num_rules);\n\treturn ERR_PTR(err);\n}\n\nstatic struct mlx5_flow_group *alloc_auto_flow_group(struct mlx5_flow_table  *ft,\n\t\t\t\t\t\t     const struct mlx5_flow_spec *spec)\n{\n\tstruct list_head *prev = &ft->node.children;\n\tu32 max_fte = ft->autogroup.max_fte;\n\tunsigned int candidate_index = 0;\n\tunsigned int group_size = 0;\n\tstruct mlx5_flow_group *fg;\n\n\tif (!ft->autogroup.active)\n\t\treturn ERR_PTR(-ENOENT);\n\n\tif (ft->autogroup.num_groups < ft->autogroup.required_groups)\n\t\tgroup_size = ft->autogroup.group_size;\n\n\t \n\tif (group_size == 0)\n\t\tgroup_size = 1;\n\n\t \n\tfs_for_each_fg(fg, ft) {\n\t\tif (candidate_index + group_size > fg->start_index)\n\t\t\tcandidate_index = fg->start_index + fg->max_ftes;\n\t\telse\n\t\t\tbreak;\n\t\tprev = &fg->node.list;\n\t}\n\n\tif (candidate_index + group_size > max_fte)\n\t\treturn ERR_PTR(-ENOSPC);\n\n\tfg = alloc_insert_flow_group(ft,\n\t\t\t\t     spec->match_criteria_enable,\n\t\t\t\t     spec->match_criteria,\n\t\t\t\t     candidate_index,\n\t\t\t\t     candidate_index + group_size - 1,\n\t\t\t\t     prev);\n\tif (IS_ERR(fg))\n\t\tgoto out;\n\n\tif (group_size == ft->autogroup.group_size)\n\t\tft->autogroup.num_groups++;\n\nout:\n\treturn fg;\n}\n\nstatic int create_auto_flow_group(struct mlx5_flow_table *ft,\n\t\t\t\t  struct mlx5_flow_group *fg)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&ft->node);\n\tint inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);\n\tvoid *match_criteria_addr;\n\tu8 src_esw_owner_mask_on;\n\tvoid *misc;\n\tint err;\n\tu32 *in;\n\n\tin = kvzalloc(inlen, GFP_KERNEL);\n\tif (!in)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(create_flow_group_in, in, match_criteria_enable,\n\t\t fg->mask.match_criteria_enable);\n\tMLX5_SET(create_flow_group_in, in, start_flow_index, fg->start_index);\n\tMLX5_SET(create_flow_group_in, in, end_flow_index,   fg->start_index +\n\t\t fg->max_ftes - 1);\n\n\tmisc = MLX5_ADDR_OF(fte_match_param, fg->mask.match_criteria,\n\t\t\t    misc_parameters);\n\tsrc_esw_owner_mask_on = !!MLX5_GET(fte_match_set_misc, misc,\n\t\t\t\t\t source_eswitch_owner_vhca_id);\n\tMLX5_SET(create_flow_group_in, in,\n\t\t source_eswitch_owner_vhca_id_valid, src_esw_owner_mask_on);\n\n\tmatch_criteria_addr = MLX5_ADDR_OF(create_flow_group_in,\n\t\t\t\t\t   in, match_criteria);\n\tmemcpy(match_criteria_addr, fg->mask.match_criteria,\n\t       sizeof(fg->mask.match_criteria));\n\n\terr = root->cmds->create_flow_group(root, ft, in, fg);\n\tif (!err) {\n\t\tfg->node.active = true;\n\t\ttrace_mlx5_fs_add_fg(fg);\n\t}\n\n\tkvfree(in);\n\treturn err;\n}\n\nstatic bool mlx5_flow_dests_cmp(struct mlx5_flow_destination *d1,\n\t\t\t\tstruct mlx5_flow_destination *d2)\n{\n\tif (d1->type == d2->type) {\n\t\tif (((d1->type == MLX5_FLOW_DESTINATION_TYPE_VPORT ||\n\t\t      d1->type == MLX5_FLOW_DESTINATION_TYPE_UPLINK) &&\n\t\t     d1->vport.num == d2->vport.num &&\n\t\t     d1->vport.flags == d2->vport.flags &&\n\t\t     ((d1->vport.flags & MLX5_FLOW_DEST_VPORT_VHCA_ID) ?\n\t\t      (d1->vport.vhca_id == d2->vport.vhca_id) : true) &&\n\t\t     ((d1->vport.flags & MLX5_FLOW_DEST_VPORT_REFORMAT_ID) ?\n\t\t      (d1->vport.pkt_reformat->id ==\n\t\t       d2->vport.pkt_reformat->id) : true)) ||\n\t\t    (d1->type == MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE &&\n\t\t     d1->ft == d2->ft) ||\n\t\t    (d1->type == MLX5_FLOW_DESTINATION_TYPE_TIR &&\n\t\t     d1->tir_num == d2->tir_num) ||\n\t\t    (d1->type == MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE_NUM &&\n\t\t     d1->ft_num == d2->ft_num) ||\n\t\t    (d1->type == MLX5_FLOW_DESTINATION_TYPE_FLOW_SAMPLER &&\n\t\t     d1->sampler_id == d2->sampler_id) ||\n\t\t    (d1->type == MLX5_FLOW_DESTINATION_TYPE_RANGE &&\n\t\t     d1->range.field == d2->range.field &&\n\t\t     d1->range.hit_ft == d2->range.hit_ft &&\n\t\t     d1->range.miss_ft == d2->range.miss_ft &&\n\t\t     d1->range.min == d2->range.min &&\n\t\t     d1->range.max == d2->range.max))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic struct mlx5_flow_rule *find_flow_rule(struct fs_fte *fte,\n\t\t\t\t\t     struct mlx5_flow_destination *dest)\n{\n\tstruct mlx5_flow_rule *rule;\n\n\tlist_for_each_entry(rule, &fte->node.children, node.list) {\n\t\tif (mlx5_flow_dests_cmp(&rule->dest_attr, dest))\n\t\t\treturn rule;\n\t}\n\treturn NULL;\n}\n\nstatic bool check_conflicting_actions_vlan(const struct mlx5_fs_vlan *vlan0,\n\t\t\t\t\t   const struct mlx5_fs_vlan *vlan1)\n{\n\treturn vlan0->ethtype != vlan1->ethtype ||\n\t       vlan0->vid != vlan1->vid ||\n\t       vlan0->prio != vlan1->prio;\n}\n\nstatic bool check_conflicting_actions(const struct mlx5_flow_act *act1,\n\t\t\t\t      const struct mlx5_flow_act *act2)\n{\n\tu32 action1 = act1->action;\n\tu32 action2 = act2->action;\n\tu32 xored_actions;\n\n\txored_actions = action1 ^ action2;\n\n\t \n\tif (action1 == MLX5_FLOW_CONTEXT_ACTION_COUNT ||\n\t    action2 == MLX5_FLOW_CONTEXT_ACTION_COUNT)\n\t\treturn false;\n\n\tif (xored_actions & (MLX5_FLOW_CONTEXT_ACTION_DROP  |\n\t\t\t     MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT |\n\t\t\t     MLX5_FLOW_CONTEXT_ACTION_DECAP |\n\t\t\t     MLX5_FLOW_CONTEXT_ACTION_MOD_HDR  |\n\t\t\t     MLX5_FLOW_CONTEXT_ACTION_VLAN_POP |\n\t\t\t     MLX5_FLOW_CONTEXT_ACTION_VLAN_PUSH |\n\t\t\t     MLX5_FLOW_CONTEXT_ACTION_VLAN_POP_2 |\n\t\t\t     MLX5_FLOW_CONTEXT_ACTION_VLAN_PUSH_2))\n\t\treturn true;\n\n\tif (action1 & MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT &&\n\t    act1->pkt_reformat != act2->pkt_reformat)\n\t\treturn true;\n\n\tif (action1 & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR &&\n\t    act1->modify_hdr != act2->modify_hdr)\n\t\treturn true;\n\n\tif (action1 & MLX5_FLOW_CONTEXT_ACTION_VLAN_PUSH &&\n\t    check_conflicting_actions_vlan(&act1->vlan[0], &act2->vlan[0]))\n\t\treturn true;\n\n\tif (action1 & MLX5_FLOW_CONTEXT_ACTION_VLAN_PUSH_2 &&\n\t    check_conflicting_actions_vlan(&act1->vlan[1], &act2->vlan[1]))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int check_conflicting_ftes(struct fs_fte *fte,\n\t\t\t\t  const struct mlx5_flow_context *flow_context,\n\t\t\t\t  const struct mlx5_flow_act *flow_act)\n{\n\tif (check_conflicting_actions(flow_act, &fte->action)) {\n\t\tmlx5_core_warn(get_dev(&fte->node),\n\t\t\t       \"Found two FTEs with conflicting actions\\n\");\n\t\treturn -EEXIST;\n\t}\n\n\tif ((flow_context->flags & FLOW_CONTEXT_HAS_TAG) &&\n\t    fte->flow_context.flow_tag != flow_context->flow_tag) {\n\t\tmlx5_core_warn(get_dev(&fte->node),\n\t\t\t       \"FTE flow tag %u already exists with different flow tag %u\\n\",\n\t\t\t       fte->flow_context.flow_tag,\n\t\t\t       flow_context->flow_tag);\n\t\treturn -EEXIST;\n\t}\n\n\treturn 0;\n}\n\nstatic struct mlx5_flow_handle *add_rule_fg(struct mlx5_flow_group *fg,\n\t\t\t\t\t    const struct mlx5_flow_spec *spec,\n\t\t\t\t\t    struct mlx5_flow_act *flow_act,\n\t\t\t\t\t    struct mlx5_flow_destination *dest,\n\t\t\t\t\t    int dest_num,\n\t\t\t\t\t    struct fs_fte *fte)\n{\n\tstruct mlx5_flow_handle *handle;\n\tint old_action;\n\tint i;\n\tint ret;\n\n\tret = check_conflicting_ftes(fte, &spec->flow_context, flow_act);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\told_action = fte->action.action;\n\tfte->action.action |= flow_act->action;\n\thandle = add_rule_fte(fte, fg, dest, dest_num,\n\t\t\t      old_action != flow_act->action);\n\tif (IS_ERR(handle)) {\n\t\tfte->action.action = old_action;\n\t\treturn handle;\n\t}\n\ttrace_mlx5_fs_set_fte(fte, false);\n\n\tfor (i = 0; i < handle->num_rules; i++) {\n\t\tif (refcount_read(&handle->rule[i]->node.refcount) == 1) {\n\t\t\ttree_add_node(&handle->rule[i]->node, &fte->node);\n\t\t\ttrace_mlx5_fs_add_rule(handle->rule[i]);\n\t\t}\n\t}\n\treturn handle;\n}\n\nstatic bool counter_is_valid(u32 action)\n{\n\treturn (action & (MLX5_FLOW_CONTEXT_ACTION_DROP |\n\t\t\t  MLX5_FLOW_CONTEXT_ACTION_ALLOW |\n\t\t\t  MLX5_FLOW_CONTEXT_ACTION_FWD_DEST));\n}\n\nstatic bool dest_is_valid(struct mlx5_flow_destination *dest,\n\t\t\t  struct mlx5_flow_act *flow_act,\n\t\t\t  struct mlx5_flow_table *ft)\n{\n\tbool ignore_level = flow_act->flags & FLOW_ACT_IGNORE_FLOW_LEVEL;\n\tu32 action = flow_act->action;\n\n\tif (dest && (dest->type == MLX5_FLOW_DESTINATION_TYPE_COUNTER))\n\t\treturn counter_is_valid(action);\n\n\tif (!(action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST))\n\t\treturn true;\n\n\tif (ignore_level) {\n\t\tif (ft->type != FS_FT_FDB &&\n\t\t    ft->type != FS_FT_NIC_RX &&\n\t\t    ft->type != FS_FT_NIC_TX)\n\t\t\treturn false;\n\n\t\tif (dest->type == MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE &&\n\t\t    ft->type != dest->ft->type)\n\t\t\treturn false;\n\t}\n\n\tif (!dest || ((dest->type ==\n\t    MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE) &&\n\t    (dest->ft->level <= ft->level && !ignore_level)))\n\t\treturn false;\n\treturn true;\n}\n\nstruct match_list {\n\tstruct list_head\tlist;\n\tstruct mlx5_flow_group *g;\n};\n\nstatic void free_match_list(struct match_list *head, bool ft_locked)\n{\n\tstruct match_list *iter, *match_tmp;\n\n\tlist_for_each_entry_safe(iter, match_tmp, &head->list,\n\t\t\t\t list) {\n\t\ttree_put_node(&iter->g->node, ft_locked);\n\t\tlist_del(&iter->list);\n\t\tkfree(iter);\n\t}\n}\n\nstatic int build_match_list(struct match_list *match_head,\n\t\t\t    struct mlx5_flow_table *ft,\n\t\t\t    const struct mlx5_flow_spec *spec,\n\t\t\t    struct mlx5_flow_group *fg,\n\t\t\t    bool ft_locked)\n{\n\tstruct rhlist_head *tmp, *list;\n\tstruct mlx5_flow_group *g;\n\n\trcu_read_lock();\n\tINIT_LIST_HEAD(&match_head->list);\n\t \n\tlist = rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);\n\t \n\trhl_for_each_entry_rcu(g, tmp, list, hash) {\n\t\tstruct match_list *curr_match;\n\n\t\tif (fg && fg != g)\n\t\t\tcontinue;\n\n\t\tif (unlikely(!tree_get_node(&g->node)))\n\t\t\tcontinue;\n\n\t\tcurr_match = kmalloc(sizeof(*curr_match), GFP_ATOMIC);\n\t\tif (!curr_match) {\n\t\t\trcu_read_unlock();\n\t\t\tfree_match_list(match_head, ft_locked);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tcurr_match->g = g;\n\t\tlist_add_tail(&curr_match->list, &match_head->list);\n\t}\n\trcu_read_unlock();\n\treturn 0;\n}\n\nstatic u64 matched_fgs_get_version(struct list_head *match_head)\n{\n\tstruct match_list *iter;\n\tu64 version = 0;\n\n\tlist_for_each_entry(iter, match_head, list)\n\t\tversion += (u64)atomic_read(&iter->g->node.version);\n\treturn version;\n}\n\nstatic struct fs_fte *\nlookup_fte_locked(struct mlx5_flow_group *g,\n\t\t  const u32 *match_value,\n\t\t  bool take_write)\n{\n\tstruct fs_fte *fte_tmp;\n\n\tif (take_write)\n\t\tnested_down_write_ref_node(&g->node, FS_LOCK_PARENT);\n\telse\n\t\tnested_down_read_ref_node(&g->node, FS_LOCK_PARENT);\n\tfte_tmp = rhashtable_lookup_fast(&g->ftes_hash, match_value,\n\t\t\t\t\t rhash_fte);\n\tif (!fte_tmp || !tree_get_node(&fte_tmp->node)) {\n\t\tfte_tmp = NULL;\n\t\tgoto out;\n\t}\n\tif (!fte_tmp->node.active) {\n\t\ttree_put_node(&fte_tmp->node, false);\n\t\tfte_tmp = NULL;\n\t\tgoto out;\n\t}\n\n\tnested_down_write_ref_node(&fte_tmp->node, FS_LOCK_CHILD);\nout:\n\tif (take_write)\n\t\tup_write_ref_node(&g->node, false);\n\telse\n\t\tup_read_ref_node(&g->node);\n\treturn fte_tmp;\n}\n\nstatic struct mlx5_flow_handle *\ntry_add_to_existing_fg(struct mlx5_flow_table *ft,\n\t\t       struct list_head *match_head,\n\t\t       const struct mlx5_flow_spec *spec,\n\t\t       struct mlx5_flow_act *flow_act,\n\t\t       struct mlx5_flow_destination *dest,\n\t\t       int dest_num,\n\t\t       int ft_version)\n{\n\tstruct mlx5_flow_steering *steering = get_steering(&ft->node);\n\tstruct mlx5_flow_group *g;\n\tstruct mlx5_flow_handle *rule;\n\tstruct match_list *iter;\n\tbool take_write = false;\n\tstruct fs_fte *fte;\n\tu64  version = 0;\n\tint err;\n\n\tfte = alloc_fte(ft, spec, flow_act);\n\tif (IS_ERR(fte))\n\t\treturn  ERR_PTR(-ENOMEM);\n\nsearch_again_locked:\n\tif (flow_act->flags & FLOW_ACT_NO_APPEND)\n\t\tgoto skip_search;\n\tversion = matched_fgs_get_version(match_head);\n\t \n\tlist_for_each_entry(iter, match_head, list) {\n\t\tstruct fs_fte *fte_tmp;\n\n\t\tg = iter->g;\n\t\tfte_tmp = lookup_fte_locked(g, spec->match_value, take_write);\n\t\tif (!fte_tmp)\n\t\t\tcontinue;\n\t\trule = add_rule_fg(g, spec, flow_act, dest, dest_num, fte_tmp);\n\t\t \n\t\tup_write_ref_node(&fte_tmp->node, false);\n\t\ttree_put_node(&fte_tmp->node, false);\n\t\tkmem_cache_free(steering->ftes_cache, fte);\n\t\treturn rule;\n\t}\n\nskip_search:\n\t \n\n\t \n\tif (atomic_read(&ft->node.version) != ft_version) {\n\t\trule = ERR_PTR(-EAGAIN);\n\t\tgoto out;\n\t}\n\n\t \n\tif (!(flow_act->flags & FLOW_ACT_NO_APPEND) &&\n\t    version != matched_fgs_get_version(match_head)) {\n\t\ttake_write = true;\n\t\tgoto search_again_locked;\n\t}\n\n\tlist_for_each_entry(iter, match_head, list) {\n\t\tg = iter->g;\n\n\t\tnested_down_write_ref_node(&g->node, FS_LOCK_PARENT);\n\n\t\tif (!g->node.active) {\n\t\t\tup_write_ref_node(&g->node, false);\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = insert_fte(g, fte);\n\t\tif (err) {\n\t\t\tup_write_ref_node(&g->node, false);\n\t\t\tif (err == -ENOSPC)\n\t\t\t\tcontinue;\n\t\t\tkmem_cache_free(steering->ftes_cache, fte);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\n\t\tnested_down_write_ref_node(&fte->node, FS_LOCK_CHILD);\n\t\tup_write_ref_node(&g->node, false);\n\t\trule = add_rule_fg(g, spec, flow_act, dest, dest_num, fte);\n\t\tup_write_ref_node(&fte->node, false);\n\t\tif (IS_ERR(rule))\n\t\t\ttree_put_node(&fte->node, false);\n\t\treturn rule;\n\t}\n\trule = ERR_PTR(-ENOENT);\nout:\n\tkmem_cache_free(steering->ftes_cache, fte);\n\treturn rule;\n}\n\nstatic struct mlx5_flow_handle *\n_mlx5_add_flow_rules(struct mlx5_flow_table *ft,\n\t\t     const struct mlx5_flow_spec *spec,\n\t\t     struct mlx5_flow_act *flow_act,\n\t\t     struct mlx5_flow_destination *dest,\n\t\t     int dest_num)\n\n{\n\tstruct mlx5_flow_steering *steering = get_steering(&ft->node);\n\tstruct mlx5_flow_handle *rule;\n\tstruct match_list match_head;\n\tstruct mlx5_flow_group *g;\n\tbool take_write = false;\n\tstruct fs_fte *fte;\n\tint version;\n\tint err;\n\tint i;\n\n\tif (!check_valid_spec(spec))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (flow_act->fg && ft->autogroup.active)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (dest && dest_num <= 0)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tfor (i = 0; i < dest_num; i++) {\n\t\tif (!dest_is_valid(&dest[i], flow_act, ft))\n\t\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tnested_down_read_ref_node(&ft->node, FS_LOCK_GRANDPARENT);\nsearch_again_locked:\n\tversion = atomic_read(&ft->node.version);\n\n\t \n\terr = build_match_list(&match_head, ft, spec, flow_act->fg, take_write);\n\tif (err) {\n\t\tif (take_write)\n\t\t\tup_write_ref_node(&ft->node, false);\n\t\telse\n\t\t\tup_read_ref_node(&ft->node);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tif (!take_write)\n\t\tup_read_ref_node(&ft->node);\n\n\trule = try_add_to_existing_fg(ft, &match_head.list, spec, flow_act, dest,\n\t\t\t\t      dest_num, version);\n\tfree_match_list(&match_head, take_write);\n\tif (!IS_ERR(rule) ||\n\t    (PTR_ERR(rule) != -ENOENT && PTR_ERR(rule) != -EAGAIN)) {\n\t\tif (take_write)\n\t\t\tup_write_ref_node(&ft->node, false);\n\t\treturn rule;\n\t}\n\n\tif (!take_write) {\n\t\tnested_down_write_ref_node(&ft->node, FS_LOCK_GRANDPARENT);\n\t\ttake_write = true;\n\t}\n\n\tif (PTR_ERR(rule) == -EAGAIN ||\n\t    version != atomic_read(&ft->node.version))\n\t\tgoto search_again_locked;\n\n\tg = alloc_auto_flow_group(ft, spec);\n\tif (IS_ERR(g)) {\n\t\trule = ERR_CAST(g);\n\t\tup_write_ref_node(&ft->node, false);\n\t\treturn rule;\n\t}\n\n\tfte = alloc_fte(ft, spec, flow_act);\n\tif (IS_ERR(fte)) {\n\t\tup_write_ref_node(&ft->node, false);\n\t\terr = PTR_ERR(fte);\n\t\tgoto err_alloc_fte;\n\t}\n\n\tnested_down_write_ref_node(&g->node, FS_LOCK_PARENT);\n\tup_write_ref_node(&ft->node, false);\n\n\terr = create_auto_flow_group(ft, g);\n\tif (err)\n\t\tgoto err_release_fg;\n\n\terr = insert_fte(g, fte);\n\tif (err)\n\t\tgoto err_release_fg;\n\n\tnested_down_write_ref_node(&fte->node, FS_LOCK_CHILD);\n\tup_write_ref_node(&g->node, false);\n\trule = add_rule_fg(g, spec, flow_act, dest, dest_num, fte);\n\tup_write_ref_node(&fte->node, false);\n\tif (IS_ERR(rule))\n\t\ttree_put_node(&fte->node, false);\n\ttree_put_node(&g->node, false);\n\treturn rule;\n\nerr_release_fg:\n\tup_write_ref_node(&g->node, false);\n\tkmem_cache_free(steering->ftes_cache, fte);\nerr_alloc_fte:\n\ttree_put_node(&g->node, false);\n\treturn ERR_PTR(err);\n}\n\nstatic bool fwd_next_prio_supported(struct mlx5_flow_table *ft)\n{\n\treturn ((ft->type == FS_FT_NIC_RX) &&\n\t\t(MLX5_CAP_FLOWTABLE(get_dev(&ft->node), nic_rx_multi_path_tirs)));\n}\n\nstruct mlx5_flow_handle *\nmlx5_add_flow_rules(struct mlx5_flow_table *ft,\n\t\t    const struct mlx5_flow_spec *spec,\n\t\t    struct mlx5_flow_act *flow_act,\n\t\t    struct mlx5_flow_destination *dest,\n\t\t    int num_dest)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&ft->node);\n\tstatic const struct mlx5_flow_spec zero_spec = {};\n\tstruct mlx5_flow_destination *gen_dest = NULL;\n\tstruct mlx5_flow_table *next_ft = NULL;\n\tstruct mlx5_flow_handle *handle = NULL;\n\tu32 sw_action = flow_act->action;\n\tint i;\n\n\tif (!spec)\n\t\tspec = &zero_spec;\n\n\tif (!is_fwd_next_action(sw_action))\n\t\treturn _mlx5_add_flow_rules(ft, spec, flow_act, dest, num_dest);\n\n\tif (!fwd_next_prio_supported(ft))\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\tmutex_lock(&root->chain_lock);\n\tnext_ft = find_next_fwd_ft(ft, flow_act);\n\tif (!next_ft) {\n\t\thandle = ERR_PTR(-EOPNOTSUPP);\n\t\tgoto unlock;\n\t}\n\n\tgen_dest = kcalloc(num_dest + 1, sizeof(*dest),\n\t\t\t   GFP_KERNEL);\n\tif (!gen_dest) {\n\t\thandle = ERR_PTR(-ENOMEM);\n\t\tgoto unlock;\n\t}\n\tfor (i = 0; i < num_dest; i++)\n\t\tgen_dest[i] = dest[i];\n\tgen_dest[i].type =\n\t\tMLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\n\tgen_dest[i].ft = next_ft;\n\tdest = gen_dest;\n\tnum_dest++;\n\tflow_act->action &= ~(MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO |\n\t\t\t      MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_NS);\n\tflow_act->action |= MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;\n\thandle = _mlx5_add_flow_rules(ft, spec, flow_act, dest, num_dest);\n\tif (IS_ERR(handle))\n\t\tgoto unlock;\n\n\tif (list_empty(&handle->rule[num_dest - 1]->next_ft)) {\n\t\tmutex_lock(&next_ft->lock);\n\t\tlist_add(&handle->rule[num_dest - 1]->next_ft,\n\t\t\t &next_ft->fwd_rules);\n\t\tmutex_unlock(&next_ft->lock);\n\t\thandle->rule[num_dest - 1]->sw_action = sw_action;\n\t\thandle->rule[num_dest - 1]->ft = ft;\n\t}\nunlock:\n\tmutex_unlock(&root->chain_lock);\n\tkfree(gen_dest);\n\treturn handle;\n}\nEXPORT_SYMBOL(mlx5_add_flow_rules);\n\nvoid mlx5_del_flow_rules(struct mlx5_flow_handle *handle)\n{\n\tstruct fs_fte *fte;\n\tint i;\n\n\t \n\tfs_get_obj(fte, handle->rule[0]->node.parent);\n\tdown_write_ref_node(&fte->node, false);\n\tfor (i = handle->num_rules - 1; i >= 0; i--)\n\t\ttree_remove_node(&handle->rule[i]->node, true);\n\tif (list_empty(&fte->node.children)) {\n\t\tfte->node.del_hw_func(&fte->node);\n\t\t \n\t\tfte->node.del_hw_func = NULL;\n\t\tup_write_ref_node(&fte->node, false);\n\t\ttree_put_node(&fte->node, false);\n\t} else if (fte->dests_size) {\n\t\tif (fte->modify_mask)\n\t\t\tmodify_fte(fte);\n\t\tup_write_ref_node(&fte->node, false);\n\t} else {\n\t\tup_write_ref_node(&fte->node, false);\n\t}\n\tkfree(handle);\n}\nEXPORT_SYMBOL(mlx5_del_flow_rules);\n\n \nstatic struct mlx5_flow_table *find_next_ft(struct mlx5_flow_table *ft)\n{\n\tstruct fs_node *prio_parent, *child;\n\tstruct fs_prio *prio;\n\n\tfs_get_obj(prio, ft->node.parent);\n\n\tif (!list_is_last(&ft->node.list, &prio->node.children))\n\t\treturn list_next_entry(ft, node.list);\n\n\tprio_parent = find_prio_chains_parent(&prio->node, &child);\n\n\tif (prio_parent && list_is_first(&child->list, &prio_parent->children))\n\t\treturn find_closest_ft(&prio->node, false, false);\n\n\treturn find_next_chained_ft(&prio->node);\n}\n\nstatic int update_root_ft_destroy(struct mlx5_flow_table *ft)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&ft->node);\n\tstruct mlx5_ft_underlay_qp *uqp;\n\tstruct mlx5_flow_table *new_root_ft = NULL;\n\tint err = 0;\n\tu32 qpn;\n\n\tif (root->root_ft != ft)\n\t\treturn 0;\n\n\tnew_root_ft = find_next_ft(ft);\n\tif (!new_root_ft) {\n\t\troot->root_ft = NULL;\n\t\treturn 0;\n\t}\n\n\tif (list_empty(&root->underlay_qpns)) {\n\t\t \n\t\tqpn = 0;\n\t\terr = root->cmds->update_root_ft(root, new_root_ft,\n\t\t\t\t\t\t qpn, false);\n\t} else {\n\t\tlist_for_each_entry(uqp, &root->underlay_qpns, list) {\n\t\t\tqpn = uqp->qpn;\n\t\t\terr = root->cmds->update_root_ft(root,\n\t\t\t\t\t\t\t new_root_ft, qpn,\n\t\t\t\t\t\t\t false);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (err)\n\t\tmlx5_core_warn(root->dev,\n\t\t\t       \"Update root flow table of id(%u) qpn(%d) failed\\n\",\n\t\t\t       ft->id, qpn);\n\telse\n\t\troot->root_ft = new_root_ft;\n\n\treturn 0;\n}\n\n \nstatic int disconnect_flow_table(struct mlx5_flow_table *ft)\n{\n\tstruct mlx5_core_dev *dev = get_dev(&ft->node);\n\tstruct mlx5_flow_table *next_ft;\n\tstruct fs_prio *prio;\n\tint err = 0;\n\n\terr = update_root_ft_destroy(ft);\n\tif (err)\n\t\treturn err;\n\n\tfs_get_obj(prio, ft->node.parent);\n\tif  (!(list_first_entry(&prio->node.children,\n\t\t\t\tstruct mlx5_flow_table,\n\t\t\t\tnode.list) == ft))\n\t\treturn 0;\n\n\tnext_ft = find_next_ft(ft);\n\terr = connect_fwd_rules(dev, next_ft, ft);\n\tif (err)\n\t\treturn err;\n\n\terr = connect_prev_fts(dev, next_ft, prio);\n\tif (err)\n\t\tmlx5_core_warn(dev, \"Failed to disconnect flow table %d\\n\",\n\t\t\t       ft->id);\n\treturn err;\n}\n\nint mlx5_destroy_flow_table(struct mlx5_flow_table *ft)\n{\n\tstruct mlx5_flow_root_namespace *root = find_root(&ft->node);\n\tint err = 0;\n\n\tmutex_lock(&root->chain_lock);\n\tif (!(ft->flags & MLX5_FLOW_TABLE_UNMANAGED))\n\t\terr = disconnect_flow_table(ft);\n\tif (err) {\n\t\tmutex_unlock(&root->chain_lock);\n\t\treturn err;\n\t}\n\tif (tree_remove_node(&ft->node, false))\n\t\tmlx5_core_warn(get_dev(&ft->node), \"Flow table %d wasn't destroyed, refcount > 1\\n\",\n\t\t\t       ft->id);\n\tmutex_unlock(&root->chain_lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL(mlx5_destroy_flow_table);\n\nvoid mlx5_destroy_flow_group(struct mlx5_flow_group *fg)\n{\n\tif (tree_remove_node(&fg->node, false))\n\t\tmlx5_core_warn(get_dev(&fg->node), \"Flow group %d wasn't destroyed, refcount > 1\\n\",\n\t\t\t       fg->id);\n}\nEXPORT_SYMBOL(mlx5_destroy_flow_group);\n\nstruct mlx5_flow_namespace *mlx5_get_fdb_sub_ns(struct mlx5_core_dev *dev,\n\t\t\t\t\t\tint n)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\n\tif (!steering || !steering->fdb_sub_ns)\n\t\treturn NULL;\n\n\treturn steering->fdb_sub_ns[n];\n}\nEXPORT_SYMBOL(mlx5_get_fdb_sub_ns);\n\nstatic bool is_nic_rx_ns(enum mlx5_flow_namespace_type type)\n{\n\tswitch (type) {\n\tcase MLX5_FLOW_NAMESPACE_BYPASS:\n\tcase MLX5_FLOW_NAMESPACE_KERNEL_RX_MACSEC:\n\tcase MLX5_FLOW_NAMESPACE_LAG:\n\tcase MLX5_FLOW_NAMESPACE_OFFLOADS:\n\tcase MLX5_FLOW_NAMESPACE_ETHTOOL:\n\tcase MLX5_FLOW_NAMESPACE_KERNEL:\n\tcase MLX5_FLOW_NAMESPACE_LEFTOVERS:\n\tcase MLX5_FLOW_NAMESPACE_ANCHOR:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstruct mlx5_flow_namespace *mlx5_get_flow_namespace(struct mlx5_core_dev *dev,\n\t\t\t\t\t\t    enum mlx5_flow_namespace_type type)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\tstruct mlx5_flow_root_namespace *root_ns;\n\tint prio = 0;\n\tstruct fs_prio *fs_prio;\n\tstruct mlx5_flow_namespace *ns;\n\n\tif (!steering)\n\t\treturn NULL;\n\n\tswitch (type) {\n\tcase MLX5_FLOW_NAMESPACE_FDB:\n\t\tif (steering->fdb_root_ns)\n\t\t\treturn &steering->fdb_root_ns->ns;\n\t\treturn NULL;\n\tcase MLX5_FLOW_NAMESPACE_PORT_SEL:\n\t\tif (steering->port_sel_root_ns)\n\t\t\treturn &steering->port_sel_root_ns->ns;\n\t\treturn NULL;\n\tcase MLX5_FLOW_NAMESPACE_SNIFFER_RX:\n\t\tif (steering->sniffer_rx_root_ns)\n\t\t\treturn &steering->sniffer_rx_root_ns->ns;\n\t\treturn NULL;\n\tcase MLX5_FLOW_NAMESPACE_SNIFFER_TX:\n\t\tif (steering->sniffer_tx_root_ns)\n\t\t\treturn &steering->sniffer_tx_root_ns->ns;\n\t\treturn NULL;\n\tcase MLX5_FLOW_NAMESPACE_FDB_BYPASS:\n\t\troot_ns = steering->fdb_root_ns;\n\t\tprio =  FDB_BYPASS_PATH;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_EGRESS:\n\tcase MLX5_FLOW_NAMESPACE_EGRESS_IPSEC:\n\tcase MLX5_FLOW_NAMESPACE_EGRESS_MACSEC:\n\t\troot_ns = steering->egress_root_ns;\n\t\tprio = type - MLX5_FLOW_NAMESPACE_EGRESS;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_RX:\n\t\troot_ns = steering->rdma_rx_root_ns;\n\t\tprio = RDMA_RX_BYPASS_PRIO;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_RX_KERNEL:\n\t\troot_ns = steering->rdma_rx_root_ns;\n\t\tprio = RDMA_RX_KERNEL_PRIO;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_TX:\n\t\troot_ns = steering->rdma_tx_root_ns;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_RX_COUNTERS:\n\t\troot_ns = steering->rdma_rx_root_ns;\n\t\tprio = RDMA_RX_COUNTERS_PRIO;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_TX_COUNTERS:\n\t\troot_ns = steering->rdma_tx_root_ns;\n\t\tprio = RDMA_TX_COUNTERS_PRIO;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_RX_IPSEC:\n\t\troot_ns = steering->rdma_rx_root_ns;\n\t\tprio = RDMA_RX_IPSEC_PRIO;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_TX_IPSEC:\n\t\troot_ns = steering->rdma_tx_root_ns;\n\t\tprio = RDMA_TX_IPSEC_PRIO;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_RX_MACSEC:\n\t\troot_ns = steering->rdma_rx_root_ns;\n\t\tprio = RDMA_RX_MACSEC_PRIO;\n\t\tbreak;\n\tcase MLX5_FLOW_NAMESPACE_RDMA_TX_MACSEC:\n\t\troot_ns = steering->rdma_tx_root_ns;\n\t\tprio = RDMA_TX_MACSEC_PRIO;\n\t\tbreak;\n\tdefault:  \n\t\tWARN_ON(!is_nic_rx_ns(type));\n\t\troot_ns = steering->root_ns;\n\t\tprio = type;\n\t\tbreak;\n\t}\n\n\tif (!root_ns)\n\t\treturn NULL;\n\n\tfs_prio = find_prio(&root_ns->ns, prio);\n\tif (!fs_prio)\n\t\treturn NULL;\n\n\tns = list_first_entry(&fs_prio->node.children,\n\t\t\t      typeof(*ns),\n\t\t\t      node.list);\n\n\treturn ns;\n}\nEXPORT_SYMBOL(mlx5_get_flow_namespace);\n\nstruct mlx5_flow_namespace *mlx5_get_flow_vport_acl_namespace(struct mlx5_core_dev *dev,\n\t\t\t\t\t\t\t      enum mlx5_flow_namespace_type type,\n\t\t\t\t\t\t\t      int vport)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\n\tif (!steering)\n\t\treturn NULL;\n\n\tswitch (type) {\n\tcase MLX5_FLOW_NAMESPACE_ESW_EGRESS:\n\t\tif (vport >= steering->esw_egress_acl_vports)\n\t\t\treturn NULL;\n\t\tif (steering->esw_egress_root_ns &&\n\t\t    steering->esw_egress_root_ns[vport])\n\t\t\treturn &steering->esw_egress_root_ns[vport]->ns;\n\t\telse\n\t\t\treturn NULL;\n\tcase MLX5_FLOW_NAMESPACE_ESW_INGRESS:\n\t\tif (vport >= steering->esw_ingress_acl_vports)\n\t\t\treturn NULL;\n\t\tif (steering->esw_ingress_root_ns &&\n\t\t    steering->esw_ingress_root_ns[vport])\n\t\t\treturn &steering->esw_ingress_root_ns[vport]->ns;\n\t\telse\n\t\t\treturn NULL;\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic struct fs_prio *_fs_create_prio(struct mlx5_flow_namespace *ns,\n\t\t\t\t       unsigned int prio,\n\t\t\t\t       int num_levels,\n\t\t\t\t       enum fs_node_type type)\n{\n\tstruct fs_prio *fs_prio;\n\n\tfs_prio = kzalloc(sizeof(*fs_prio), GFP_KERNEL);\n\tif (!fs_prio)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfs_prio->node.type = type;\n\ttree_init_node(&fs_prio->node, NULL, del_sw_prio);\n\ttree_add_node(&fs_prio->node, &ns->node);\n\tfs_prio->num_levels = num_levels;\n\tfs_prio->prio = prio;\n\tlist_add_tail(&fs_prio->node.list, &ns->node.children);\n\n\treturn fs_prio;\n}\n\nstatic struct fs_prio *fs_create_prio_chained(struct mlx5_flow_namespace *ns,\n\t\t\t\t\t      unsigned int prio,\n\t\t\t\t\t      int num_levels)\n{\n\treturn _fs_create_prio(ns, prio, num_levels, FS_TYPE_PRIO_CHAINS);\n}\n\nstatic struct fs_prio *fs_create_prio(struct mlx5_flow_namespace *ns,\n\t\t\t\t      unsigned int prio, int num_levels)\n{\n\treturn _fs_create_prio(ns, prio, num_levels, FS_TYPE_PRIO);\n}\n\nstatic struct mlx5_flow_namespace *fs_init_namespace(struct mlx5_flow_namespace\n\t\t\t\t\t\t     *ns)\n{\n\tns->node.type = FS_TYPE_NAMESPACE;\n\n\treturn ns;\n}\n\nstatic struct mlx5_flow_namespace *fs_create_namespace(struct fs_prio *prio,\n\t\t\t\t\t\t       int def_miss_act)\n{\n\tstruct mlx5_flow_namespace\t*ns;\n\n\tns = kzalloc(sizeof(*ns), GFP_KERNEL);\n\tif (!ns)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfs_init_namespace(ns);\n\tns->def_miss_action = def_miss_act;\n\ttree_init_node(&ns->node, NULL, del_sw_ns);\n\ttree_add_node(&ns->node, &prio->node);\n\tlist_add_tail(&ns->node.list, &prio->node.children);\n\n\treturn ns;\n}\n\nstatic int create_leaf_prios(struct mlx5_flow_namespace *ns, int prio,\n\t\t\t     struct init_tree_node *prio_metadata)\n{\n\tstruct fs_prio *fs_prio;\n\tint i;\n\n\tfor (i = 0; i < prio_metadata->num_leaf_prios; i++) {\n\t\tfs_prio = fs_create_prio(ns, prio++, prio_metadata->num_levels);\n\t\tif (IS_ERR(fs_prio))\n\t\t\treturn PTR_ERR(fs_prio);\n\t}\n\treturn 0;\n}\n\n#define FLOW_TABLE_BIT_SZ 1\n#define GET_FLOW_TABLE_CAP(dev, offset) \\\n\t((be32_to_cpu(*((__be32 *)(dev->caps.hca[MLX5_CAP_FLOW_TABLE]->cur) +\t\\\n\t\t\toffset / 32)) >>\t\t\t\t\t\\\n\t  (32 - FLOW_TABLE_BIT_SZ - (offset & 0x1f))) & FLOW_TABLE_BIT_SZ)\nstatic bool has_required_caps(struct mlx5_core_dev *dev, struct node_caps *caps)\n{\n\tint i;\n\n\tfor (i = 0; i < caps->arr_sz; i++) {\n\t\tif (!GET_FLOW_TABLE_CAP(dev, caps->caps[i]))\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic int init_root_tree_recursive(struct mlx5_flow_steering *steering,\n\t\t\t\t    struct init_tree_node *init_node,\n\t\t\t\t    struct fs_node *fs_parent_node,\n\t\t\t\t    struct init_tree_node *init_parent_node,\n\t\t\t\t    int prio)\n{\n\tint max_ft_level = MLX5_CAP_FLOWTABLE(steering->dev,\n\t\t\t\t\t      flow_table_properties_nic_receive.\n\t\t\t\t\t      max_ft_level);\n\tstruct mlx5_flow_namespace *fs_ns;\n\tstruct fs_prio *fs_prio;\n\tstruct fs_node *base;\n\tint i;\n\tint err;\n\n\tif (init_node->type == FS_TYPE_PRIO) {\n\t\tif ((init_node->min_ft_level > max_ft_level) ||\n\t\t    !has_required_caps(steering->dev, &init_node->caps))\n\t\t\treturn 0;\n\n\t\tfs_get_obj(fs_ns, fs_parent_node);\n\t\tif (init_node->num_leaf_prios)\n\t\t\treturn create_leaf_prios(fs_ns, prio, init_node);\n\t\tfs_prio = fs_create_prio(fs_ns, prio, init_node->num_levels);\n\t\tif (IS_ERR(fs_prio))\n\t\t\treturn PTR_ERR(fs_prio);\n\t\tbase = &fs_prio->node;\n\t} else if (init_node->type == FS_TYPE_NAMESPACE) {\n\t\tfs_get_obj(fs_prio, fs_parent_node);\n\t\tfs_ns = fs_create_namespace(fs_prio, init_node->def_miss_action);\n\t\tif (IS_ERR(fs_ns))\n\t\t\treturn PTR_ERR(fs_ns);\n\t\tbase = &fs_ns->node;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\tprio = 0;\n\tfor (i = 0; i < init_node->ar_size; i++) {\n\t\terr = init_root_tree_recursive(steering, &init_node->children[i],\n\t\t\t\t\t       base, init_node, prio);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (init_node->children[i].type == FS_TYPE_PRIO &&\n\t\t    init_node->children[i].num_leaf_prios) {\n\t\t\tprio += init_node->children[i].num_leaf_prios;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int init_root_tree(struct mlx5_flow_steering *steering,\n\t\t\t  struct init_tree_node *init_node,\n\t\t\t  struct fs_node *fs_parent_node)\n{\n\tint err;\n\tint i;\n\n\tfor (i = 0; i < init_node->ar_size; i++) {\n\t\terr = init_root_tree_recursive(steering, &init_node->children[i],\n\t\t\t\t\t       fs_parent_node,\n\t\t\t\t\t       init_node, i);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic void del_sw_root_ns(struct fs_node *node)\n{\n\tstruct mlx5_flow_root_namespace *root_ns;\n\tstruct mlx5_flow_namespace *ns;\n\n\tfs_get_obj(ns, node);\n\troot_ns = container_of(ns, struct mlx5_flow_root_namespace, ns);\n\tmutex_destroy(&root_ns->chain_lock);\n\tkfree(node);\n}\n\nstatic struct mlx5_flow_root_namespace\n*create_root_ns(struct mlx5_flow_steering *steering,\n\t\tenum fs_flow_table_type table_type)\n{\n\tconst struct mlx5_flow_cmds *cmds = mlx5_fs_cmd_get_default(table_type);\n\tstruct mlx5_flow_root_namespace *root_ns;\n\tstruct mlx5_flow_namespace *ns;\n\n\t \n\troot_ns = kzalloc(sizeof(*root_ns), GFP_KERNEL);\n\tif (!root_ns)\n\t\treturn NULL;\n\n\troot_ns->dev = steering->dev;\n\troot_ns->table_type = table_type;\n\troot_ns->cmds = cmds;\n\n\tINIT_LIST_HEAD(&root_ns->underlay_qpns);\n\n\tns = &root_ns->ns;\n\tfs_init_namespace(ns);\n\tmutex_init(&root_ns->chain_lock);\n\ttree_init_node(&ns->node, NULL, del_sw_root_ns);\n\ttree_add_node(&ns->node, NULL);\n\n\treturn root_ns;\n}\n\nstatic void set_prio_attrs_in_prio(struct fs_prio *prio, int acc_level);\n\nstatic int set_prio_attrs_in_ns(struct mlx5_flow_namespace *ns, int acc_level)\n{\n\tstruct fs_prio *prio;\n\n\tfs_for_each_prio(prio, ns) {\n\t\t  \n\t\tset_prio_attrs_in_prio(prio, acc_level);\n\t\tacc_level += prio->num_levels;\n\t}\n\treturn acc_level;\n}\n\nstatic void set_prio_attrs_in_prio(struct fs_prio *prio, int acc_level)\n{\n\tstruct mlx5_flow_namespace *ns;\n\tint acc_level_ns = acc_level;\n\n\tprio->start_level = acc_level;\n\tfs_for_each_ns(ns, prio) {\n\t\t \n\t\tacc_level_ns = set_prio_attrs_in_ns(ns, acc_level);\n\n\t\t \n\t\tif (prio->node.type == FS_TYPE_PRIO_CHAINS)\n\t\t\tacc_level = acc_level_ns;\n\t}\n\n\tif (!prio->num_levels)\n\t\tprio->num_levels = acc_level_ns - prio->start_level;\n\tWARN_ON(prio->num_levels < acc_level_ns - prio->start_level);\n}\n\nstatic void set_prio_attrs(struct mlx5_flow_root_namespace *root_ns)\n{\n\tstruct mlx5_flow_namespace *ns = &root_ns->ns;\n\tstruct fs_prio *prio;\n\tint start_level = 0;\n\n\tfs_for_each_prio(prio, ns) {\n\t\tset_prio_attrs_in_prio(prio, start_level);\n\t\tstart_level += prio->num_levels;\n\t}\n}\n\n#define ANCHOR_PRIO 0\n#define ANCHOR_SIZE 1\n#define ANCHOR_LEVEL 0\nstatic int create_anchor_flow_table(struct mlx5_flow_steering *steering)\n{\n\tstruct mlx5_flow_namespace *ns = NULL;\n\tstruct mlx5_flow_table_attr ft_attr = {};\n\tstruct mlx5_flow_table *ft;\n\n\tns = mlx5_get_flow_namespace(steering->dev, MLX5_FLOW_NAMESPACE_ANCHOR);\n\tif (WARN_ON(!ns))\n\t\treturn -EINVAL;\n\n\tft_attr.max_fte = ANCHOR_SIZE;\n\tft_attr.level   = ANCHOR_LEVEL;\n\tft_attr.prio    = ANCHOR_PRIO;\n\n\tft = mlx5_create_flow_table(ns, &ft_attr);\n\tif (IS_ERR(ft)) {\n\t\tmlx5_core_err(steering->dev, \"Failed to create last anchor flow table\");\n\t\treturn PTR_ERR(ft);\n\t}\n\treturn 0;\n}\n\nstatic int init_root_ns(struct mlx5_flow_steering *steering)\n{\n\tint err;\n\n\tsteering->root_ns = create_root_ns(steering, FS_FT_NIC_RX);\n\tif (!steering->root_ns)\n\t\treturn -ENOMEM;\n\n\terr = init_root_tree(steering, &root_fs, &steering->root_ns->ns.node);\n\tif (err)\n\t\tgoto out_err;\n\n\tset_prio_attrs(steering->root_ns);\n\terr = create_anchor_flow_table(steering);\n\tif (err)\n\t\tgoto out_err;\n\n\treturn 0;\n\nout_err:\n\tcleanup_root_ns(steering->root_ns);\n\tsteering->root_ns = NULL;\n\treturn err;\n}\n\nstatic void clean_tree(struct fs_node *node)\n{\n\tif (node) {\n\t\tstruct fs_node *iter;\n\t\tstruct fs_node *temp;\n\n\t\ttree_get_node(node);\n\t\tlist_for_each_entry_safe(iter, temp, &node->children, list)\n\t\t\tclean_tree(iter);\n\t\ttree_put_node(node, false);\n\t\ttree_remove_node(node, false);\n\t}\n}\n\nstatic void cleanup_root_ns(struct mlx5_flow_root_namespace *root_ns)\n{\n\tif (!root_ns)\n\t\treturn;\n\n\tclean_tree(&root_ns->ns.node);\n}\n\nstatic int init_sniffer_tx_root_ns(struct mlx5_flow_steering *steering)\n{\n\tstruct fs_prio *prio;\n\n\tsteering->sniffer_tx_root_ns = create_root_ns(steering, FS_FT_SNIFFER_TX);\n\tif (!steering->sniffer_tx_root_ns)\n\t\treturn -ENOMEM;\n\n\t \n\tprio = fs_create_prio(&steering->sniffer_tx_root_ns->ns, 0, 1);\n\treturn PTR_ERR_OR_ZERO(prio);\n}\n\nstatic int init_sniffer_rx_root_ns(struct mlx5_flow_steering *steering)\n{\n\tstruct fs_prio *prio;\n\n\tsteering->sniffer_rx_root_ns = create_root_ns(steering, FS_FT_SNIFFER_RX);\n\tif (!steering->sniffer_rx_root_ns)\n\t\treturn -ENOMEM;\n\n\t \n\tprio = fs_create_prio(&steering->sniffer_rx_root_ns->ns, 0, 1);\n\treturn PTR_ERR_OR_ZERO(prio);\n}\n\n#define PORT_SEL_NUM_LEVELS 3\nstatic int init_port_sel_root_ns(struct mlx5_flow_steering *steering)\n{\n\tstruct fs_prio *prio;\n\n\tsteering->port_sel_root_ns = create_root_ns(steering, FS_FT_PORT_SEL);\n\tif (!steering->port_sel_root_ns)\n\t\treturn -ENOMEM;\n\n\t \n\tprio = fs_create_prio(&steering->port_sel_root_ns->ns, 0,\n\t\t\t      PORT_SEL_NUM_LEVELS);\n\treturn PTR_ERR_OR_ZERO(prio);\n}\n\nstatic int init_rdma_rx_root_ns(struct mlx5_flow_steering *steering)\n{\n\tint err;\n\n\tsteering->rdma_rx_root_ns = create_root_ns(steering, FS_FT_RDMA_RX);\n\tif (!steering->rdma_rx_root_ns)\n\t\treturn -ENOMEM;\n\n\terr = init_root_tree(steering, &rdma_rx_root_fs,\n\t\t\t     &steering->rdma_rx_root_ns->ns.node);\n\tif (err)\n\t\tgoto out_err;\n\n\tset_prio_attrs(steering->rdma_rx_root_ns);\n\n\treturn 0;\n\nout_err:\n\tcleanup_root_ns(steering->rdma_rx_root_ns);\n\tsteering->rdma_rx_root_ns = NULL;\n\treturn err;\n}\n\nstatic int init_rdma_tx_root_ns(struct mlx5_flow_steering *steering)\n{\n\tint err;\n\n\tsteering->rdma_tx_root_ns = create_root_ns(steering, FS_FT_RDMA_TX);\n\tif (!steering->rdma_tx_root_ns)\n\t\treturn -ENOMEM;\n\n\terr = init_root_tree(steering, &rdma_tx_root_fs,\n\t\t\t     &steering->rdma_tx_root_ns->ns.node);\n\tif (err)\n\t\tgoto out_err;\n\n\tset_prio_attrs(steering->rdma_tx_root_ns);\n\n\treturn 0;\n\nout_err:\n\tcleanup_root_ns(steering->rdma_tx_root_ns);\n\tsteering->rdma_tx_root_ns = NULL;\n\treturn err;\n}\n\n \nstatic void store_fdb_sub_ns_prio_chain(struct mlx5_flow_steering *steering,\n\t\t\t\t\tstruct mlx5_flow_namespace *ns)\n{\n\tint chain = 0;\n\n\twhile (steering->fdb_sub_ns[chain])\n\t\t++chain;\n\n\tsteering->fdb_sub_ns[chain] = ns;\n}\n\nstatic int create_fdb_sub_ns_prio_chain(struct mlx5_flow_steering *steering,\n\t\t\t\t\tstruct fs_prio *maj_prio)\n{\n\tstruct mlx5_flow_namespace *ns;\n\tstruct fs_prio *min_prio;\n\tint prio;\n\n\tns = fs_create_namespace(maj_prio, MLX5_FLOW_TABLE_MISS_ACTION_DEF);\n\tif (IS_ERR(ns))\n\t\treturn PTR_ERR(ns);\n\n\tfor (prio = 0; prio < FDB_TC_MAX_PRIO; prio++) {\n\t\tmin_prio = fs_create_prio(ns, prio, FDB_TC_LEVELS_PER_PRIO);\n\t\tif (IS_ERR(min_prio))\n\t\t\treturn PTR_ERR(min_prio);\n\t}\n\n\tstore_fdb_sub_ns_prio_chain(steering, ns);\n\n\treturn 0;\n}\n\nstatic int create_fdb_chains(struct mlx5_flow_steering *steering,\n\t\t\t     int fs_prio,\n\t\t\t     int chains)\n{\n\tstruct fs_prio *maj_prio;\n\tint levels;\n\tint chain;\n\tint err;\n\n\tlevels = FDB_TC_LEVELS_PER_PRIO * FDB_TC_MAX_PRIO * chains;\n\tmaj_prio = fs_create_prio_chained(&steering->fdb_root_ns->ns,\n\t\t\t\t\t  fs_prio,\n\t\t\t\t\t  levels);\n\tif (IS_ERR(maj_prio))\n\t\treturn PTR_ERR(maj_prio);\n\n\tfor (chain = 0; chain < chains; chain++) {\n\t\terr = create_fdb_sub_ns_prio_chain(steering, maj_prio);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int create_fdb_fast_path(struct mlx5_flow_steering *steering)\n{\n\tint err;\n\n\tsteering->fdb_sub_ns = kcalloc(FDB_NUM_CHAINS,\n\t\t\t\t       sizeof(*steering->fdb_sub_ns),\n\t\t\t\t       GFP_KERNEL);\n\tif (!steering->fdb_sub_ns)\n\t\treturn -ENOMEM;\n\n\terr = create_fdb_chains(steering, FDB_TC_OFFLOAD, FDB_TC_MAX_CHAIN + 1);\n\tif (err)\n\t\treturn err;\n\n\terr = create_fdb_chains(steering, FDB_FT_OFFLOAD, 1);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nstatic int create_fdb_bypass(struct mlx5_flow_steering *steering)\n{\n\tstruct mlx5_flow_namespace *ns;\n\tstruct fs_prio *prio;\n\tint i;\n\n\tprio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_BYPASS_PATH, 0);\n\tif (IS_ERR(prio))\n\t\treturn PTR_ERR(prio);\n\n\tns = fs_create_namespace(prio, MLX5_FLOW_TABLE_MISS_ACTION_DEF);\n\tif (IS_ERR(ns))\n\t\treturn PTR_ERR(ns);\n\n\tfor (i = 0; i < MLX5_BY_PASS_NUM_REGULAR_PRIOS; i++) {\n\t\tprio = fs_create_prio(ns, i, 1);\n\t\tif (IS_ERR(prio))\n\t\t\treturn PTR_ERR(prio);\n\t}\n\treturn 0;\n}\n\nstatic void cleanup_fdb_root_ns(struct mlx5_flow_steering *steering)\n{\n\tcleanup_root_ns(steering->fdb_root_ns);\n\tsteering->fdb_root_ns = NULL;\n\tkfree(steering->fdb_sub_ns);\n\tsteering->fdb_sub_ns = NULL;\n}\n\nstatic int init_fdb_root_ns(struct mlx5_flow_steering *steering)\n{\n\tstruct fs_prio *maj_prio;\n\tint err;\n\n\tsteering->fdb_root_ns = create_root_ns(steering, FS_FT_FDB);\n\tif (!steering->fdb_root_ns)\n\t\treturn -ENOMEM;\n\n\terr = create_fdb_bypass(steering);\n\tif (err)\n\t\tgoto out_err;\n\n\tmaj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_CRYPTO_INGRESS, 3);\n\tif (IS_ERR(maj_prio)) {\n\t\terr = PTR_ERR(maj_prio);\n\t\tgoto out_err;\n\t}\n\n\terr = create_fdb_fast_path(steering);\n\tif (err)\n\t\tgoto out_err;\n\n\tmaj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_TC_MISS, 1);\n\tif (IS_ERR(maj_prio)) {\n\t\terr = PTR_ERR(maj_prio);\n\t\tgoto out_err;\n\t}\n\n\tmaj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_BR_OFFLOAD, 4);\n\tif (IS_ERR(maj_prio)) {\n\t\terr = PTR_ERR(maj_prio);\n\t\tgoto out_err;\n\t}\n\n\tmaj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_SLOW_PATH, 1);\n\tif (IS_ERR(maj_prio)) {\n\t\terr = PTR_ERR(maj_prio);\n\t\tgoto out_err;\n\t}\n\n\tmaj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_CRYPTO_EGRESS, 3);\n\tif (IS_ERR(maj_prio)) {\n\t\terr = PTR_ERR(maj_prio);\n\t\tgoto out_err;\n\t}\n\n\t \n\tmaj_prio = fs_create_prio(&steering->fdb_root_ns->ns, FDB_PER_VPORT, 1);\n\tif (IS_ERR(maj_prio)) {\n\t\terr = PTR_ERR(maj_prio);\n\t\tgoto out_err;\n\t}\n\n\tset_prio_attrs(steering->fdb_root_ns);\n\treturn 0;\n\nout_err:\n\tcleanup_fdb_root_ns(steering);\n\treturn err;\n}\n\nstatic int init_egress_acl_root_ns(struct mlx5_flow_steering *steering, int vport)\n{\n\tstruct fs_prio *prio;\n\n\tsteering->esw_egress_root_ns[vport] = create_root_ns(steering, FS_FT_ESW_EGRESS_ACL);\n\tif (!steering->esw_egress_root_ns[vport])\n\t\treturn -ENOMEM;\n\n\t \n\tprio = fs_create_prio(&steering->esw_egress_root_ns[vport]->ns, 0, 1);\n\treturn PTR_ERR_OR_ZERO(prio);\n}\n\nstatic int init_ingress_acl_root_ns(struct mlx5_flow_steering *steering, int vport)\n{\n\tstruct fs_prio *prio;\n\n\tsteering->esw_ingress_root_ns[vport] = create_root_ns(steering, FS_FT_ESW_INGRESS_ACL);\n\tif (!steering->esw_ingress_root_ns[vport])\n\t\treturn -ENOMEM;\n\n\t \n\tprio = fs_create_prio(&steering->esw_ingress_root_ns[vport]->ns, 0, 1);\n\treturn PTR_ERR_OR_ZERO(prio);\n}\n\nint mlx5_fs_egress_acls_init(struct mlx5_core_dev *dev, int total_vports)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\tint err;\n\tint i;\n\n\tsteering->esw_egress_root_ns =\n\t\t\tkcalloc(total_vports,\n\t\t\t\tsizeof(*steering->esw_egress_root_ns),\n\t\t\t\tGFP_KERNEL);\n\tif (!steering->esw_egress_root_ns)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < total_vports; i++) {\n\t\terr = init_egress_acl_root_ns(steering, i);\n\t\tif (err)\n\t\t\tgoto cleanup_root_ns;\n\t}\n\tsteering->esw_egress_acl_vports = total_vports;\n\treturn 0;\n\ncleanup_root_ns:\n\tfor (i--; i >= 0; i--)\n\t\tcleanup_root_ns(steering->esw_egress_root_ns[i]);\n\tkfree(steering->esw_egress_root_ns);\n\tsteering->esw_egress_root_ns = NULL;\n\treturn err;\n}\n\nvoid mlx5_fs_egress_acls_cleanup(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\tint i;\n\n\tif (!steering->esw_egress_root_ns)\n\t\treturn;\n\n\tfor (i = 0; i < steering->esw_egress_acl_vports; i++)\n\t\tcleanup_root_ns(steering->esw_egress_root_ns[i]);\n\n\tkfree(steering->esw_egress_root_ns);\n\tsteering->esw_egress_root_ns = NULL;\n}\n\nint mlx5_fs_ingress_acls_init(struct mlx5_core_dev *dev, int total_vports)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\tint err;\n\tint i;\n\n\tsteering->esw_ingress_root_ns =\n\t\t\tkcalloc(total_vports,\n\t\t\t\tsizeof(*steering->esw_ingress_root_ns),\n\t\t\t\tGFP_KERNEL);\n\tif (!steering->esw_ingress_root_ns)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < total_vports; i++) {\n\t\terr = init_ingress_acl_root_ns(steering, i);\n\t\tif (err)\n\t\t\tgoto cleanup_root_ns;\n\t}\n\tsteering->esw_ingress_acl_vports = total_vports;\n\treturn 0;\n\ncleanup_root_ns:\n\tfor (i--; i >= 0; i--)\n\t\tcleanup_root_ns(steering->esw_ingress_root_ns[i]);\n\tkfree(steering->esw_ingress_root_ns);\n\tsteering->esw_ingress_root_ns = NULL;\n\treturn err;\n}\n\nvoid mlx5_fs_ingress_acls_cleanup(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\tint i;\n\n\tif (!steering->esw_ingress_root_ns)\n\t\treturn;\n\n\tfor (i = 0; i < steering->esw_ingress_acl_vports; i++)\n\t\tcleanup_root_ns(steering->esw_ingress_root_ns[i]);\n\n\tkfree(steering->esw_ingress_root_ns);\n\tsteering->esw_ingress_root_ns = NULL;\n}\n\nu32 mlx5_fs_get_capabilities(struct mlx5_core_dev *dev, enum mlx5_flow_namespace_type type)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_namespace *ns;\n\n\tns = mlx5_get_flow_namespace(dev, type);\n\tif (!ns)\n\t\treturn 0;\n\n\troot = find_root(&ns->node);\n\tif (!root)\n\t\treturn 0;\n\n\treturn root->cmds->get_capabilities(root, root->table_type);\n}\n\nstatic int init_egress_root_ns(struct mlx5_flow_steering *steering)\n{\n\tint err;\n\n\tsteering->egress_root_ns = create_root_ns(steering,\n\t\t\t\t\t\t  FS_FT_NIC_TX);\n\tif (!steering->egress_root_ns)\n\t\treturn -ENOMEM;\n\n\terr = init_root_tree(steering, &egress_root_fs,\n\t\t\t     &steering->egress_root_ns->ns.node);\n\tif (err)\n\t\tgoto cleanup;\n\tset_prio_attrs(steering->egress_root_ns);\n\treturn 0;\ncleanup:\n\tcleanup_root_ns(steering->egress_root_ns);\n\tsteering->egress_root_ns = NULL;\n\treturn err;\n}\n\nstatic int mlx5_fs_mode_validate(struct devlink *devlink, u32 id,\n\t\t\t\t union devlink_param_value val,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_core_dev *dev = devlink_priv(devlink);\n\tchar *value = val.vstr;\n\tint err = 0;\n\n\tif (!strcmp(value, \"dmfs\")) {\n\t\treturn 0;\n\t} else if (!strcmp(value, \"smfs\")) {\n\t\tu8 eswitch_mode;\n\t\tbool smfs_cap;\n\n\t\teswitch_mode = mlx5_eswitch_mode(dev);\n\t\tsmfs_cap = mlx5_fs_dr_is_supported(dev);\n\n\t\tif (!smfs_cap) {\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Software managed steering is not supported by current device\");\n\t\t}\n\n\t\telse if (eswitch_mode == MLX5_ESWITCH_OFFLOADS) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Software managed steering is not supported when eswitch offloads enabled.\");\n\t\t\terr = -EOPNOTSUPP;\n\t\t}\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Bad parameter: supported values are [\\\"dmfs\\\", \\\"smfs\\\"]\");\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}\n\nstatic int mlx5_fs_mode_set(struct devlink *devlink, u32 id,\n\t\t\t    struct devlink_param_gset_ctx *ctx)\n{\n\tstruct mlx5_core_dev *dev = devlink_priv(devlink);\n\tenum mlx5_flow_steering_mode mode;\n\n\tif (!strcmp(ctx->val.vstr, \"smfs\"))\n\t\tmode = MLX5_FLOW_STEERING_MODE_SMFS;\n\telse\n\t\tmode = MLX5_FLOW_STEERING_MODE_DMFS;\n\tdev->priv.steering->mode = mode;\n\n\treturn 0;\n}\n\nstatic int mlx5_fs_mode_get(struct devlink *devlink, u32 id,\n\t\t\t    struct devlink_param_gset_ctx *ctx)\n{\n\tstruct mlx5_core_dev *dev = devlink_priv(devlink);\n\n\tif (dev->priv.steering->mode == MLX5_FLOW_STEERING_MODE_SMFS)\n\t\tstrcpy(ctx->val.vstr, \"smfs\");\n\telse\n\t\tstrcpy(ctx->val.vstr, \"dmfs\");\n\treturn 0;\n}\n\nstatic const struct devlink_param mlx5_fs_params[] = {\n\tDEVLINK_PARAM_DRIVER(MLX5_DEVLINK_PARAM_ID_FLOW_STEERING_MODE,\n\t\t\t     \"flow_steering_mode\", DEVLINK_PARAM_TYPE_STRING,\n\t\t\t     BIT(DEVLINK_PARAM_CMODE_RUNTIME),\n\t\t\t     mlx5_fs_mode_get, mlx5_fs_mode_set,\n\t\t\t     mlx5_fs_mode_validate),\n};\n\nvoid mlx5_fs_core_cleanup(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\n\tcleanup_root_ns(steering->root_ns);\n\tcleanup_fdb_root_ns(steering);\n\tcleanup_root_ns(steering->port_sel_root_ns);\n\tcleanup_root_ns(steering->sniffer_rx_root_ns);\n\tcleanup_root_ns(steering->sniffer_tx_root_ns);\n\tcleanup_root_ns(steering->rdma_rx_root_ns);\n\tcleanup_root_ns(steering->rdma_tx_root_ns);\n\tcleanup_root_ns(steering->egress_root_ns);\n\n\tdevl_params_unregister(priv_to_devlink(dev), mlx5_fs_params,\n\t\t\t       ARRAY_SIZE(mlx5_fs_params));\n}\n\nint mlx5_fs_core_init(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\tint err;\n\n\terr = devl_params_register(priv_to_devlink(dev), mlx5_fs_params,\n\t\t\t\t   ARRAY_SIZE(mlx5_fs_params));\n\tif (err)\n\t\treturn err;\n\n\tif ((((MLX5_CAP_GEN(dev, port_type) == MLX5_CAP_PORT_TYPE_ETH) &&\n\t      (MLX5_CAP_GEN(dev, nic_flow_table))) ||\n\t     ((MLX5_CAP_GEN(dev, port_type) == MLX5_CAP_PORT_TYPE_IB) &&\n\t      MLX5_CAP_GEN(dev, ipoib_enhanced_offloads))) &&\n\t    MLX5_CAP_FLOWTABLE_NIC_RX(dev, ft_support)) {\n\t\terr = init_root_ns(steering);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tif (MLX5_ESWITCH_MANAGER(dev)) {\n\t\tif (MLX5_CAP_ESW_FLOWTABLE_FDB(dev, ft_support)) {\n\t\t\terr = init_fdb_root_ns(steering);\n\t\t\tif (err)\n\t\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE_SNIFFER_RX(dev, ft_support)) {\n\t\terr = init_sniffer_rx_root_ns(steering);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE_SNIFFER_TX(dev, ft_support)) {\n\t\terr = init_sniffer_tx_root_ns(steering);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE_PORT_SELECTION(dev, ft_support)) {\n\t\terr = init_port_sel_root_ns(steering);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE_RDMA_RX(dev, ft_support) &&\n\t    MLX5_CAP_FLOWTABLE_RDMA_RX(dev, table_miss_action_domain)) {\n\t\terr = init_rdma_rx_root_ns(steering);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE_RDMA_TX(dev, ft_support)) {\n\t\terr = init_rdma_tx_root_ns(steering);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE_NIC_TX(dev, ft_support)) {\n\t\terr = init_egress_root_ns(steering);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tmlx5_fs_core_cleanup(dev);\n\treturn err;\n}\n\nvoid mlx5_fs_core_free(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_flow_steering *steering = dev->priv.steering;\n\n\tkmem_cache_destroy(steering->ftes_cache);\n\tkmem_cache_destroy(steering->fgs_cache);\n\tkfree(steering);\n\tmlx5_ft_pool_destroy(dev);\n\tmlx5_cleanup_fc_stats(dev);\n}\n\nint mlx5_fs_core_alloc(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_flow_steering *steering;\n\tint err = 0;\n\n\terr = mlx5_init_fc_stats(dev);\n\tif (err)\n\t\treturn err;\n\n\terr = mlx5_ft_pool_init(dev);\n\tif (err)\n\t\tgoto err;\n\n\tsteering = kzalloc(sizeof(*steering), GFP_KERNEL);\n\tif (!steering) {\n\t\terr = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tsteering->dev = dev;\n\tdev->priv.steering = steering;\n\n\tif (mlx5_fs_dr_is_supported(dev))\n\t\tsteering->mode = MLX5_FLOW_STEERING_MODE_SMFS;\n\telse\n\t\tsteering->mode = MLX5_FLOW_STEERING_MODE_DMFS;\n\n\tsteering->fgs_cache = kmem_cache_create(\"mlx5_fs_fgs\",\n\t\t\t\t\t\tsizeof(struct mlx5_flow_group), 0,\n\t\t\t\t\t\t0, NULL);\n\tsteering->ftes_cache = kmem_cache_create(\"mlx5_fs_ftes\", sizeof(struct fs_fte), 0,\n\t\t\t\t\t\t 0, NULL);\n\tif (!steering->ftes_cache || !steering->fgs_cache) {\n\t\terr = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tmlx5_fs_core_free(dev);\n\treturn err;\n}\n\nint mlx5_fs_add_rx_underlay_qpn(struct mlx5_core_dev *dev, u32 underlay_qpn)\n{\n\tstruct mlx5_flow_root_namespace *root = dev->priv.steering->root_ns;\n\tstruct mlx5_ft_underlay_qp *new_uqp;\n\tint err = 0;\n\n\tnew_uqp = kzalloc(sizeof(*new_uqp), GFP_KERNEL);\n\tif (!new_uqp)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&root->chain_lock);\n\n\tif (!root->root_ft) {\n\t\terr = -EINVAL;\n\t\tgoto update_ft_fail;\n\t}\n\n\terr = root->cmds->update_root_ft(root, root->root_ft, underlay_qpn,\n\t\t\t\t\t false);\n\tif (err) {\n\t\tmlx5_core_warn(dev, \"Failed adding underlay QPN (%u) to root FT err(%d)\\n\",\n\t\t\t       underlay_qpn, err);\n\t\tgoto update_ft_fail;\n\t}\n\n\tnew_uqp->qpn = underlay_qpn;\n\tlist_add_tail(&new_uqp->list, &root->underlay_qpns);\n\n\tmutex_unlock(&root->chain_lock);\n\n\treturn 0;\n\nupdate_ft_fail:\n\tmutex_unlock(&root->chain_lock);\n\tkfree(new_uqp);\n\treturn err;\n}\nEXPORT_SYMBOL(mlx5_fs_add_rx_underlay_qpn);\n\nint mlx5_fs_remove_rx_underlay_qpn(struct mlx5_core_dev *dev, u32 underlay_qpn)\n{\n\tstruct mlx5_flow_root_namespace *root = dev->priv.steering->root_ns;\n\tstruct mlx5_ft_underlay_qp *uqp;\n\tbool found = false;\n\tint err = 0;\n\n\tmutex_lock(&root->chain_lock);\n\tlist_for_each_entry(uqp, &root->underlay_qpns, list) {\n\t\tif (uqp->qpn == underlay_qpn) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tmlx5_core_warn(dev, \"Failed finding underlay qp (%u) in qpn list\\n\",\n\t\t\t       underlay_qpn);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\terr = root->cmds->update_root_ft(root, root->root_ft, underlay_qpn,\n\t\t\t\t\t true);\n\tif (err)\n\t\tmlx5_core_warn(dev, \"Failed removing underlay QPN (%u) from root FT err(%d)\\n\",\n\t\t\t       underlay_qpn, err);\n\n\tlist_del(&uqp->list);\n\tmutex_unlock(&root->chain_lock);\n\tkfree(uqp);\n\n\treturn 0;\n\nout:\n\tmutex_unlock(&root->chain_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(mlx5_fs_remove_rx_underlay_qpn);\n\nstatic struct mlx5_flow_root_namespace\n*get_root_namespace(struct mlx5_core_dev *dev, enum mlx5_flow_namespace_type ns_type)\n{\n\tstruct mlx5_flow_namespace *ns;\n\n\tif (ns_type == MLX5_FLOW_NAMESPACE_ESW_EGRESS ||\n\t    ns_type == MLX5_FLOW_NAMESPACE_ESW_INGRESS)\n\t\tns = mlx5_get_flow_vport_acl_namespace(dev, ns_type, 0);\n\telse\n\t\tns = mlx5_get_flow_namespace(dev, ns_type);\n\tif (!ns)\n\t\treturn NULL;\n\n\treturn find_root(&ns->node);\n}\n\nstruct mlx5_modify_hdr *mlx5_modify_header_alloc(struct mlx5_core_dev *dev,\n\t\t\t\t\t\t u8 ns_type, u8 num_actions,\n\t\t\t\t\t\t void *modify_actions)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_modify_hdr *modify_hdr;\n\tint err;\n\n\troot = get_root_namespace(dev, ns_type);\n\tif (!root)\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\tmodify_hdr = kzalloc(sizeof(*modify_hdr), GFP_KERNEL);\n\tif (!modify_hdr)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmodify_hdr->ns_type = ns_type;\n\terr = root->cmds->modify_header_alloc(root, ns_type, num_actions,\n\t\t\t\t\t      modify_actions, modify_hdr);\n\tif (err) {\n\t\tkfree(modify_hdr);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn modify_hdr;\n}\nEXPORT_SYMBOL(mlx5_modify_header_alloc);\n\nvoid mlx5_modify_header_dealloc(struct mlx5_core_dev *dev,\n\t\t\t\tstruct mlx5_modify_hdr *modify_hdr)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\n\troot = get_root_namespace(dev, modify_hdr->ns_type);\n\tif (WARN_ON(!root))\n\t\treturn;\n\troot->cmds->modify_header_dealloc(root, modify_hdr);\n\tkfree(modify_hdr);\n}\nEXPORT_SYMBOL(mlx5_modify_header_dealloc);\n\nstruct mlx5_pkt_reformat *mlx5_packet_reformat_alloc(struct mlx5_core_dev *dev,\n\t\t\t\t\t\t     struct mlx5_pkt_reformat_params *params,\n\t\t\t\t\t\t     enum mlx5_flow_namespace_type ns_type)\n{\n\tstruct mlx5_pkt_reformat *pkt_reformat;\n\tstruct mlx5_flow_root_namespace *root;\n\tint err;\n\n\troot = get_root_namespace(dev, ns_type);\n\tif (!root)\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\tpkt_reformat = kzalloc(sizeof(*pkt_reformat), GFP_KERNEL);\n\tif (!pkt_reformat)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpkt_reformat->ns_type = ns_type;\n\tpkt_reformat->reformat_type = params->type;\n\terr = root->cmds->packet_reformat_alloc(root, params, ns_type,\n\t\t\t\t\t\tpkt_reformat);\n\tif (err) {\n\t\tkfree(pkt_reformat);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn pkt_reformat;\n}\nEXPORT_SYMBOL(mlx5_packet_reformat_alloc);\n\nvoid mlx5_packet_reformat_dealloc(struct mlx5_core_dev *dev,\n\t\t\t\t  struct mlx5_pkt_reformat *pkt_reformat)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\n\troot = get_root_namespace(dev, pkt_reformat->ns_type);\n\tif (WARN_ON(!root))\n\t\treturn;\n\troot->cmds->packet_reformat_dealloc(root, pkt_reformat);\n\tkfree(pkt_reformat);\n}\nEXPORT_SYMBOL(mlx5_packet_reformat_dealloc);\n\nint mlx5_get_match_definer_id(struct mlx5_flow_definer *definer)\n{\n\treturn definer->id;\n}\n\nstruct mlx5_flow_definer *\nmlx5_create_match_definer(struct mlx5_core_dev *dev,\n\t\t\t  enum mlx5_flow_namespace_type ns_type, u16 format_id,\n\t\t\t  u32 *match_mask)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tstruct mlx5_flow_definer *definer;\n\tint id;\n\n\troot = get_root_namespace(dev, ns_type);\n\tif (!root)\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\tdefiner = kzalloc(sizeof(*definer), GFP_KERNEL);\n\tif (!definer)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdefiner->ns_type = ns_type;\n\tid = root->cmds->create_match_definer(root, format_id, match_mask);\n\tif (id < 0) {\n\t\tmlx5_core_warn(root->dev, \"Failed to create match definer (%d)\\n\", id);\n\t\tkfree(definer);\n\t\treturn ERR_PTR(id);\n\t}\n\tdefiner->id = id;\n\treturn definer;\n}\n\nvoid mlx5_destroy_match_definer(struct mlx5_core_dev *dev,\n\t\t\t\tstruct mlx5_flow_definer *definer)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\n\troot = get_root_namespace(dev, definer->ns_type);\n\tif (WARN_ON(!root))\n\t\treturn;\n\n\troot->cmds->destroy_match_definer(root, definer->id);\n\tkfree(definer);\n}\n\nint mlx5_flow_namespace_set_peer(struct mlx5_flow_root_namespace *ns,\n\t\t\t\t struct mlx5_flow_root_namespace *peer_ns,\n\t\t\t\t u16 peer_vhca_id)\n{\n\tif (peer_ns && ns->mode != peer_ns->mode) {\n\t\tmlx5_core_err(ns->dev,\n\t\t\t      \"Can't peer namespace of different steering mode\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn ns->cmds->set_peer(ns, peer_ns, peer_vhca_id);\n}\n\n \nint mlx5_flow_namespace_set_mode(struct mlx5_flow_namespace *ns,\n\t\t\t\t enum mlx5_flow_steering_mode mode)\n{\n\tstruct mlx5_flow_root_namespace *root;\n\tconst struct mlx5_flow_cmds *cmds;\n\tint err;\n\n\troot = find_root(&ns->node);\n\tif (&root->ns != ns)\n\t \n\t\treturn -EINVAL;\n\n\tif (root->table_type != FS_FT_FDB)\n\t\treturn -EOPNOTSUPP;\n\n\tif (root->mode == mode)\n\t\treturn 0;\n\n\tif (mode == MLX5_FLOW_STEERING_MODE_SMFS)\n\t\tcmds = mlx5_fs_cmd_get_dr_cmds();\n\telse\n\t\tcmds = mlx5_fs_cmd_get_fw_cmds();\n\tif (!cmds)\n\t\treturn -EOPNOTSUPP;\n\n\terr = cmds->create_ns(root);\n\tif (err) {\n\t\tmlx5_core_err(root->dev, \"Failed to create flow namespace (%d)\\n\",\n\t\t\t      err);\n\t\treturn err;\n\t}\n\n\troot->cmds->destroy_ns(root);\n\troot->cmds = cmds;\n\troot->mode = mode;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}