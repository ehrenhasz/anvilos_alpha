{
  "module_name": "dr_ste.c",
  "hash_id": "c28b1befe1753630648de71c304566487e951c82e7db1a0f5cdd05c9538e1841",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/steering/dr_ste.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <linux/crc32.h>\n#include \"dr_ste.h\"\n\nstruct dr_hw_ste_format {\n\tu8 ctrl[DR_STE_SIZE_CTRL];\n\tu8 tag[DR_STE_SIZE_TAG];\n\tu8 mask[DR_STE_SIZE_MASK];\n};\n\nstatic u32 dr_ste_crc32_calc(const void *input_data, size_t length)\n{\n\tu32 crc = crc32(0, input_data, length);\n\n\treturn (__force u32)((crc >> 24) & 0xff) | ((crc << 8) & 0xff0000) |\n\t\t\t    ((crc >> 8) & 0xff00) | ((crc << 24) & 0xff000000);\n}\n\nbool mlx5dr_ste_supp_ttl_cs_recalc(struct mlx5dr_cmd_caps *caps)\n{\n\treturn caps->sw_format_ver > MLX5_STEERING_FORMAT_CONNECTX_5;\n}\n\nu32 mlx5dr_ste_calc_hash_index(u8 *hw_ste_p, struct mlx5dr_ste_htbl *htbl)\n{\n\tu32 num_entries = mlx5dr_icm_pool_get_chunk_num_of_entries(htbl->chunk);\n\tstruct dr_hw_ste_format *hw_ste = (struct dr_hw_ste_format *)hw_ste_p;\n\tu8 masked[DR_STE_SIZE_TAG] = {};\n\tu32 crc32, index;\n\tu16 bit;\n\tint i;\n\n\t \n\tif (num_entries == 1 || htbl->byte_mask == 0)\n\t\treturn 0;\n\n\t \n\tbit = 1 << (DR_STE_SIZE_TAG - 1);\n\tfor (i = 0; i < DR_STE_SIZE_TAG; i++) {\n\t\tif (htbl->byte_mask & bit)\n\t\t\tmasked[i] = hw_ste->tag[i];\n\n\t\tbit = bit >> 1;\n\t}\n\n\tcrc32 = dr_ste_crc32_calc(masked, DR_STE_SIZE_TAG);\n\tindex = crc32 & (num_entries - 1);\n\n\treturn index;\n}\n\nu16 mlx5dr_ste_conv_bit_to_byte_mask(u8 *bit_mask)\n{\n\tu16 byte_mask = 0;\n\tint i;\n\n\tfor (i = 0; i < DR_STE_SIZE_MASK; i++) {\n\t\tbyte_mask = byte_mask << 1;\n\t\tif (bit_mask[i] == 0xff)\n\t\t\tbyte_mask |= 1;\n\t}\n\treturn byte_mask;\n}\n\nstatic u8 *dr_ste_get_tag(u8 *hw_ste_p)\n{\n\tstruct dr_hw_ste_format *hw_ste = (struct dr_hw_ste_format *)hw_ste_p;\n\n\treturn hw_ste->tag;\n}\n\nvoid mlx5dr_ste_set_bit_mask(u8 *hw_ste_p, u8 *bit_mask)\n{\n\tstruct dr_hw_ste_format *hw_ste = (struct dr_hw_ste_format *)hw_ste_p;\n\n\tmemcpy(hw_ste->mask, bit_mask, DR_STE_SIZE_MASK);\n}\n\nstatic void dr_ste_set_always_hit(struct dr_hw_ste_format *hw_ste)\n{\n\tmemset(&hw_ste->tag, 0, sizeof(hw_ste->tag));\n\tmemset(&hw_ste->mask, 0, sizeof(hw_ste->mask));\n}\n\nstatic void dr_ste_set_always_miss(struct dr_hw_ste_format *hw_ste)\n{\n\thw_ste->tag[0] = 0xdc;\n\thw_ste->mask[0] = 0;\n}\n\nbool mlx5dr_ste_is_miss_addr_set(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t u8 *hw_ste_p)\n{\n\tif (!ste_ctx->is_miss_addr_set)\n\t\treturn false;\n\n\t \n\treturn ste_ctx->is_miss_addr_set(hw_ste_p);\n}\n\nvoid mlx5dr_ste_set_miss_addr(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t      u8 *hw_ste_p, u64 miss_addr)\n{\n\tste_ctx->set_miss_addr(hw_ste_p, miss_addr);\n}\n\nstatic void dr_ste_always_miss_addr(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t    u8 *hw_ste, u64 miss_addr)\n{\n\tste_ctx->set_next_lu_type(hw_ste, MLX5DR_STE_LU_TYPE_DONT_CARE);\n\tste_ctx->set_miss_addr(hw_ste, miss_addr);\n\tdr_ste_set_always_miss((struct dr_hw_ste_format *)hw_ste);\n}\n\nvoid mlx5dr_ste_set_hit_addr(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t     u8 *hw_ste, u64 icm_addr, u32 ht_size)\n{\n\tste_ctx->set_hit_addr(hw_ste, icm_addr, ht_size);\n}\n\nu64 mlx5dr_ste_get_icm_addr(struct mlx5dr_ste *ste)\n{\n\tu64 base_icm_addr = mlx5dr_icm_pool_get_chunk_icm_addr(ste->htbl->chunk);\n\tu32 index = ste - ste->htbl->chunk->ste_arr;\n\n\treturn base_icm_addr + DR_STE_SIZE * index;\n}\n\nu64 mlx5dr_ste_get_mr_addr(struct mlx5dr_ste *ste)\n{\n\tu32 index = ste - ste->htbl->chunk->ste_arr;\n\n\treturn mlx5dr_icm_pool_get_chunk_mr_addr(ste->htbl->chunk) + DR_STE_SIZE * index;\n}\n\nu8 *mlx5dr_ste_get_hw_ste(struct mlx5dr_ste *ste)\n{\n\tu64 index = ste - ste->htbl->chunk->ste_arr;\n\n\treturn ste->htbl->chunk->hw_ste_arr + DR_STE_SIZE_REDUCED * index;\n}\n\nstruct list_head *mlx5dr_ste_get_miss_list(struct mlx5dr_ste *ste)\n{\n\tu32 index = ste - ste->htbl->chunk->ste_arr;\n\n\treturn &ste->htbl->chunk->miss_list[index];\n}\n\nstatic void dr_ste_always_hit_htbl(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t   u8 *hw_ste,\n\t\t\t\t   struct mlx5dr_ste_htbl *next_htbl)\n{\n\tstruct mlx5dr_icm_chunk *chunk = next_htbl->chunk;\n\n\tste_ctx->set_byte_mask(hw_ste, next_htbl->byte_mask);\n\tste_ctx->set_next_lu_type(hw_ste, next_htbl->lu_type);\n\tste_ctx->set_hit_addr(hw_ste, mlx5dr_icm_pool_get_chunk_icm_addr(chunk),\n\t\t\t      mlx5dr_icm_pool_get_chunk_num_of_entries(chunk));\n\n\tdr_ste_set_always_hit((struct dr_hw_ste_format *)hw_ste);\n}\n\nbool mlx5dr_ste_is_last_in_rule(struct mlx5dr_matcher_rx_tx *nic_matcher,\n\t\t\t\tu8 ste_location)\n{\n\treturn ste_location == nic_matcher->num_of_builders;\n}\n\n \nstatic void dr_ste_replace(struct mlx5dr_ste *dst, struct mlx5dr_ste *src)\n{\n\tmemcpy(mlx5dr_ste_get_hw_ste(dst), mlx5dr_ste_get_hw_ste(src),\n\t       DR_STE_SIZE_REDUCED);\n\tdst->next_htbl = src->next_htbl;\n\tif (dst->next_htbl)\n\t\tdst->next_htbl->pointing_ste = dst;\n\n\tdst->refcount = src->refcount;\n}\n\n \nstatic void\ndr_ste_remove_head_ste(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t       struct mlx5dr_ste *ste,\n\t\t       struct mlx5dr_matcher_rx_tx *nic_matcher,\n\t\t       struct mlx5dr_ste_send_info *ste_info_head,\n\t\t       struct list_head *send_ste_list,\n\t\t       struct mlx5dr_ste_htbl *stats_tbl)\n{\n\tu8 tmp_data_ste[DR_STE_SIZE] = {};\n\tu64 miss_addr;\n\n\tmiss_addr = mlx5dr_icm_pool_get_chunk_icm_addr(nic_matcher->e_anchor->chunk);\n\n\t \n\tmemcpy(tmp_data_ste, mlx5dr_ste_get_hw_ste(ste), DR_STE_SIZE_REDUCED);\n\tdr_ste_always_miss_addr(ste_ctx, tmp_data_ste, miss_addr);\n\tmemcpy(mlx5dr_ste_get_hw_ste(ste), tmp_data_ste, DR_STE_SIZE_REDUCED);\n\n\tlist_del_init(&ste->miss_list_node);\n\n\t \n\tmlx5dr_send_fill_and_append_ste_send_info(ste, DR_STE_SIZE,\n\t\t\t\t\t\t  0, tmp_data_ste,\n\t\t\t\t\t\t  ste_info_head,\n\t\t\t\t\t\t  send_ste_list,\n\t\t\t\t\t\t  true  );\n\n\tstats_tbl->ctrl.num_of_valid_entries--;\n}\n\n \nstatic void\ndr_ste_replace_head_ste(struct mlx5dr_matcher_rx_tx *nic_matcher,\n\t\t\tstruct mlx5dr_ste *ste,\n\t\t\tstruct mlx5dr_ste *next_ste,\n\t\t\tstruct mlx5dr_ste_send_info *ste_info_head,\n\t\t\tstruct list_head *send_ste_list,\n\t\t\tstruct mlx5dr_ste_htbl *stats_tbl)\n\n{\n\tstruct mlx5dr_ste_htbl *next_miss_htbl;\n\tu8 hw_ste[DR_STE_SIZE] = {};\n\tint sb_idx;\n\n\tnext_miss_htbl = next_ste->htbl;\n\n\t \n\tlist_del_init(&next_ste->miss_list_node);\n\n\t \n\tdr_ste_replace(ste, next_ste);\n\n\t \n\tmlx5dr_rule_set_last_member(next_ste->rule_rx_tx, ste, false);\n\n\t \n\tmemcpy(hw_ste, mlx5dr_ste_get_hw_ste(ste), DR_STE_SIZE_REDUCED);\n\tsb_idx = ste->ste_chain_location - 1;\n\tmlx5dr_ste_set_bit_mask(hw_ste,\n\t\t\t\tnic_matcher->ste_builder[sb_idx].bit_mask);\n\n\t \n\tmlx5dr_htbl_put(next_miss_htbl);\n\n\tmlx5dr_send_fill_and_append_ste_send_info(ste, DR_STE_SIZE,\n\t\t\t\t\t\t  0, hw_ste,\n\t\t\t\t\t\t  ste_info_head,\n\t\t\t\t\t\t  send_ste_list,\n\t\t\t\t\t\t  true  );\n\n\tstats_tbl->ctrl.num_of_collisions--;\n\tstats_tbl->ctrl.num_of_valid_entries--;\n}\n\n \nstatic void dr_ste_remove_middle_ste(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t     struct mlx5dr_ste *ste,\n\t\t\t\t     struct mlx5dr_ste_send_info *ste_info,\n\t\t\t\t     struct list_head *send_ste_list,\n\t\t\t\t     struct mlx5dr_ste_htbl *stats_tbl)\n{\n\tstruct mlx5dr_ste *prev_ste;\n\tu64 miss_addr;\n\n\tprev_ste = list_prev_entry(ste, miss_list_node);\n\tif (WARN_ON(!prev_ste))\n\t\treturn;\n\n\tmiss_addr = ste_ctx->get_miss_addr(mlx5dr_ste_get_hw_ste(ste));\n\tste_ctx->set_miss_addr(mlx5dr_ste_get_hw_ste(prev_ste), miss_addr);\n\n\tmlx5dr_send_fill_and_append_ste_send_info(prev_ste, DR_STE_SIZE_CTRL, 0,\n\t\t\t\t\t\t  mlx5dr_ste_get_hw_ste(prev_ste),\n\t\t\t\t\t\t  ste_info, send_ste_list,\n\t\t\t\t\t\t  true  );\n\n\tlist_del_init(&ste->miss_list_node);\n\n\tstats_tbl->ctrl.num_of_valid_entries--;\n\tstats_tbl->ctrl.num_of_collisions--;\n}\n\nvoid mlx5dr_ste_free(struct mlx5dr_ste *ste,\n\t\t     struct mlx5dr_matcher *matcher,\n\t\t     struct mlx5dr_matcher_rx_tx *nic_matcher)\n{\n\tstruct mlx5dr_ste_send_info *cur_ste_info, *tmp_ste_info;\n\tstruct mlx5dr_domain *dmn = matcher->tbl->dmn;\n\tstruct mlx5dr_ste_ctx *ste_ctx = dmn->ste_ctx;\n\tstruct mlx5dr_ste_send_info ste_info_head;\n\tstruct mlx5dr_ste *next_ste, *first_ste;\n\tbool put_on_origin_table = true;\n\tstruct mlx5dr_ste_htbl *stats_tbl;\n\tLIST_HEAD(send_ste_list);\n\n\tfirst_ste = list_first_entry(mlx5dr_ste_get_miss_list(ste),\n\t\t\t\t     struct mlx5dr_ste, miss_list_node);\n\tstats_tbl = first_ste->htbl;\n\n\t \n\tif (first_ste == ste) {  \n\t\tstruct mlx5dr_ste *last_ste;\n\n\t\tlast_ste = list_last_entry(mlx5dr_ste_get_miss_list(ste),\n\t\t\t\t\t   struct mlx5dr_ste, miss_list_node);\n\t\tif (last_ste == first_ste)\n\t\t\tnext_ste = NULL;\n\t\telse\n\t\t\tnext_ste = list_next_entry(ste, miss_list_node);\n\n\t\tif (!next_ste) {\n\t\t\t \n\t\t\tdr_ste_remove_head_ste(ste_ctx, ste,\n\t\t\t\t\t       nic_matcher,\n\t\t\t\t\t       &ste_info_head,\n\t\t\t\t\t       &send_ste_list,\n\t\t\t\t\t       stats_tbl);\n\t\t} else {\n\t\t\t \n\t\t\tdr_ste_replace_head_ste(nic_matcher, ste,\n\t\t\t\t\t\tnext_ste, &ste_info_head,\n\t\t\t\t\t\t&send_ste_list, stats_tbl);\n\t\t\tput_on_origin_table = false;\n\t\t}\n\t} else {  \n\t\tdr_ste_remove_middle_ste(ste_ctx, ste,\n\t\t\t\t\t &ste_info_head, &send_ste_list,\n\t\t\t\t\t stats_tbl);\n\t}\n\n\t \n\tlist_for_each_entry_safe(cur_ste_info, tmp_ste_info,\n\t\t\t\t &send_ste_list, send_list) {\n\t\tlist_del(&cur_ste_info->send_list);\n\t\tmlx5dr_send_postsend_ste(dmn, cur_ste_info->ste,\n\t\t\t\t\t cur_ste_info->data, cur_ste_info->size,\n\t\t\t\t\t cur_ste_info->offset);\n\t}\n\n\tif (put_on_origin_table)\n\t\tmlx5dr_htbl_put(ste->htbl);\n}\n\nbool mlx5dr_ste_equal_tag(void *src, void *dst)\n{\n\tstruct dr_hw_ste_format *s_hw_ste = (struct dr_hw_ste_format *)src;\n\tstruct dr_hw_ste_format *d_hw_ste = (struct dr_hw_ste_format *)dst;\n\n\treturn !memcmp(s_hw_ste->tag, d_hw_ste->tag, DR_STE_SIZE_TAG);\n}\n\nvoid mlx5dr_ste_set_hit_addr_by_next_htbl(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\t  u8 *hw_ste,\n\t\t\t\t\t  struct mlx5dr_ste_htbl *next_htbl)\n{\n\tu64 icm_addr = mlx5dr_icm_pool_get_chunk_icm_addr(next_htbl->chunk);\n\tu32 num_entries =\n\t\tmlx5dr_icm_pool_get_chunk_num_of_entries(next_htbl->chunk);\n\n\tste_ctx->set_hit_addr(hw_ste, icm_addr, num_entries);\n}\n\nvoid mlx5dr_ste_prepare_for_postsend(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t     u8 *hw_ste_p, u32 ste_size)\n{\n\tif (ste_ctx->prepare_for_postsend)\n\t\tste_ctx->prepare_for_postsend(hw_ste_p, ste_size);\n}\n\n \nvoid mlx5dr_ste_set_formatted_ste(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t  u16 gvmi,\n\t\t\t\t  enum mlx5dr_domain_nic_type nic_type,\n\t\t\t\t  struct mlx5dr_ste_htbl *htbl,\n\t\t\t\t  u8 *formatted_ste,\n\t\t\t\t  struct mlx5dr_htbl_connect_info *connect_info)\n{\n\tbool is_rx = nic_type == DR_DOMAIN_NIC_TYPE_RX;\n\tu8 tmp_hw_ste[DR_STE_SIZE] = {0};\n\n\tste_ctx->ste_init(formatted_ste, htbl->lu_type, is_rx, gvmi);\n\n\t \n\tmemcpy(tmp_hw_ste, formatted_ste, DR_STE_SIZE_REDUCED);\n\tif (connect_info->type == CONNECT_HIT)\n\t\tdr_ste_always_hit_htbl(ste_ctx, tmp_hw_ste,\n\t\t\t\t       connect_info->hit_next_htbl);\n\telse\n\t\tdr_ste_always_miss_addr(ste_ctx, tmp_hw_ste,\n\t\t\t\t\tconnect_info->miss_icm_addr);\n\tmemcpy(formatted_ste, tmp_hw_ste, DR_STE_SIZE_REDUCED);\n}\n\nint mlx5dr_ste_htbl_init_and_postsend(struct mlx5dr_domain *dmn,\n\t\t\t\t      struct mlx5dr_domain_rx_tx *nic_dmn,\n\t\t\t\t      struct mlx5dr_ste_htbl *htbl,\n\t\t\t\t      struct mlx5dr_htbl_connect_info *connect_info,\n\t\t\t\t      bool update_hw_ste)\n{\n\tu8 formatted_ste[DR_STE_SIZE] = {};\n\n\tmlx5dr_ste_set_formatted_ste(dmn->ste_ctx,\n\t\t\t\t     dmn->info.caps.gvmi,\n\t\t\t\t     nic_dmn->type,\n\t\t\t\t     htbl,\n\t\t\t\t     formatted_ste,\n\t\t\t\t     connect_info);\n\n\treturn mlx5dr_send_postsend_formatted_htbl(dmn, htbl, formatted_ste, update_hw_ste);\n}\n\nint mlx5dr_ste_create_next_htbl(struct mlx5dr_matcher *matcher,\n\t\t\t\tstruct mlx5dr_matcher_rx_tx *nic_matcher,\n\t\t\t\tstruct mlx5dr_ste *ste,\n\t\t\t\tu8 *cur_hw_ste,\n\t\t\t\tenum mlx5dr_icm_chunk_size log_table_size)\n{\n\tstruct mlx5dr_domain_rx_tx *nic_dmn = nic_matcher->nic_tbl->nic_dmn;\n\tstruct mlx5dr_domain *dmn = matcher->tbl->dmn;\n\tstruct mlx5dr_ste_ctx *ste_ctx = dmn->ste_ctx;\n\tstruct mlx5dr_htbl_connect_info info;\n\tstruct mlx5dr_ste_htbl *next_htbl;\n\n\tif (!mlx5dr_ste_is_last_in_rule(nic_matcher, ste->ste_chain_location)) {\n\t\tu16 next_lu_type;\n\t\tu16 byte_mask;\n\n\t\tnext_lu_type = ste_ctx->get_next_lu_type(cur_hw_ste);\n\t\tbyte_mask = ste_ctx->get_byte_mask(cur_hw_ste);\n\n\t\tnext_htbl = mlx5dr_ste_htbl_alloc(dmn->ste_icm_pool,\n\t\t\t\t\t\t  log_table_size,\n\t\t\t\t\t\t  next_lu_type,\n\t\t\t\t\t\t  byte_mask);\n\t\tif (!next_htbl) {\n\t\t\tmlx5dr_dbg(dmn, \"Failed allocating table\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tinfo.type = CONNECT_MISS;\n\t\tinfo.miss_icm_addr =\n\t\t\tmlx5dr_icm_pool_get_chunk_icm_addr(nic_matcher->e_anchor->chunk);\n\t\tif (mlx5dr_ste_htbl_init_and_postsend(dmn, nic_dmn, next_htbl,\n\t\t\t\t\t\t      &info, false)) {\n\t\t\tmlx5dr_info(dmn, \"Failed writing table to HW\\n\");\n\t\t\tgoto free_table;\n\t\t}\n\n\t\tmlx5dr_ste_set_hit_addr_by_next_htbl(ste_ctx,\n\t\t\t\t\t\t     cur_hw_ste, next_htbl);\n\t\tste->next_htbl = next_htbl;\n\t\tnext_htbl->pointing_ste = ste;\n\t}\n\n\treturn 0;\n\nfree_table:\n\tmlx5dr_ste_htbl_free(next_htbl);\n\treturn -ENOENT;\n}\n\nstruct mlx5dr_ste_htbl *mlx5dr_ste_htbl_alloc(struct mlx5dr_icm_pool *pool,\n\t\t\t\t\t      enum mlx5dr_icm_chunk_size chunk_size,\n\t\t\t\t\t      u16 lu_type, u16 byte_mask)\n{\n\tstruct mlx5dr_icm_chunk *chunk;\n\tstruct mlx5dr_ste_htbl *htbl;\n\tu32 num_entries;\n\tint i;\n\n\thtbl = mlx5dr_icm_pool_alloc_htbl(pool);\n\tif (!htbl)\n\t\treturn NULL;\n\n\tchunk = mlx5dr_icm_alloc_chunk(pool, chunk_size);\n\tif (!chunk)\n\t\tgoto out_free_htbl;\n\n\thtbl->chunk = chunk;\n\thtbl->lu_type = lu_type;\n\thtbl->byte_mask = byte_mask;\n\thtbl->refcount = 0;\n\thtbl->pointing_ste = NULL;\n\thtbl->ctrl.num_of_valid_entries = 0;\n\thtbl->ctrl.num_of_collisions = 0;\n\tnum_entries = mlx5dr_icm_pool_get_chunk_num_of_entries(chunk);\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tstruct mlx5dr_ste *ste = &chunk->ste_arr[i];\n\n\t\tste->htbl = htbl;\n\t\tste->refcount = 0;\n\t\tINIT_LIST_HEAD(&ste->miss_list_node);\n\t\tINIT_LIST_HEAD(&chunk->miss_list[i]);\n\t}\n\n\treturn htbl;\n\nout_free_htbl:\n\tmlx5dr_icm_pool_free_htbl(pool, htbl);\n\treturn NULL;\n}\n\nint mlx5dr_ste_htbl_free(struct mlx5dr_ste_htbl *htbl)\n{\n\tstruct mlx5dr_icm_pool *pool = htbl->chunk->buddy_mem->pool;\n\n\tif (htbl->refcount)\n\t\treturn -EBUSY;\n\n\tmlx5dr_icm_free_chunk(htbl->chunk);\n\tmlx5dr_icm_pool_free_htbl(pool, htbl);\n\n\treturn 0;\n}\n\nvoid mlx5dr_ste_set_actions_tx(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t       struct mlx5dr_domain *dmn,\n\t\t\t       u8 *action_type_set,\n\t\t\t       u8 *hw_ste_arr,\n\t\t\t       struct mlx5dr_ste_actions_attr *attr,\n\t\t\t       u32 *added_stes)\n{\n\tste_ctx->set_actions_tx(dmn, action_type_set, ste_ctx->actions_caps,\n\t\t\t\thw_ste_arr, attr, added_stes);\n}\n\nvoid mlx5dr_ste_set_actions_rx(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t       struct mlx5dr_domain *dmn,\n\t\t\t       u8 *action_type_set,\n\t\t\t       u8 *hw_ste_arr,\n\t\t\t       struct mlx5dr_ste_actions_attr *attr,\n\t\t\t       u32 *added_stes)\n{\n\tste_ctx->set_actions_rx(dmn, action_type_set, ste_ctx->actions_caps,\n\t\t\t\thw_ste_arr, attr, added_stes);\n}\n\nconst struct mlx5dr_ste_action_modify_field *\nmlx5dr_ste_conv_modify_hdr_sw_field(struct mlx5dr_ste_ctx *ste_ctx, u16 sw_field)\n{\n\tconst struct mlx5dr_ste_action_modify_field *hw_field;\n\n\tif (sw_field >= ste_ctx->modify_field_arr_sz)\n\t\treturn NULL;\n\n\thw_field = &ste_ctx->modify_field_arr[sw_field];\n\tif (!hw_field->end && !hw_field->start)\n\t\treturn NULL;\n\n\treturn hw_field;\n}\n\nvoid mlx5dr_ste_set_action_set(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t       __be64 *hw_action,\n\t\t\t       u8 hw_field,\n\t\t\t       u8 shifter,\n\t\t\t       u8 length,\n\t\t\t       u32 data)\n{\n\tste_ctx->set_action_set((u8 *)hw_action,\n\t\t\t\thw_field, shifter, length, data);\n}\n\nvoid mlx5dr_ste_set_action_add(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t       __be64 *hw_action,\n\t\t\t       u8 hw_field,\n\t\t\t       u8 shifter,\n\t\t\t       u8 length,\n\t\t\t       u32 data)\n{\n\tste_ctx->set_action_add((u8 *)hw_action,\n\t\t\t\thw_field, shifter, length, data);\n}\n\nvoid mlx5dr_ste_set_action_copy(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t__be64 *hw_action,\n\t\t\t\tu8 dst_hw_field,\n\t\t\t\tu8 dst_shifter,\n\t\t\t\tu8 dst_len,\n\t\t\t\tu8 src_hw_field,\n\t\t\t\tu8 src_shifter)\n{\n\tste_ctx->set_action_copy((u8 *)hw_action,\n\t\t\t\t dst_hw_field, dst_shifter, dst_len,\n\t\t\t\t src_hw_field, src_shifter);\n}\n\nint mlx5dr_ste_set_action_decap_l3_list(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\tvoid *data, u32 data_sz,\n\t\t\t\t\tu8 *hw_action, u32 hw_action_sz,\n\t\t\t\t\tu16 *used_hw_action_num)\n{\n\t \n\tif (data_sz != HDR_LEN_L2 && data_sz != HDR_LEN_L2_W_VLAN)\n\t\treturn -EINVAL;\n\n\treturn ste_ctx->set_action_decap_l3_list(data, data_sz,\n\t\t\t\t\t\t hw_action, hw_action_sz,\n\t\t\t\t\t\t used_hw_action_num);\n}\n\nstatic int\ndr_ste_alloc_modify_hdr_chunk(struct mlx5dr_action *action)\n{\n\tstruct mlx5dr_domain *dmn = action->rewrite->dmn;\n\tu32 chunk_size;\n\tint ret;\n\n\tchunk_size = ilog2(roundup_pow_of_two(action->rewrite->num_of_actions));\n\n\t \n\tchunk_size = max_t(u32, chunk_size, DR_CHUNK_SIZE_8);\n\n\taction->rewrite->chunk = mlx5dr_icm_alloc_chunk(dmn->action_icm_pool,\n\t\t\t\t\t\t\tchunk_size);\n\tif (!action->rewrite->chunk)\n\t\treturn -ENOMEM;\n\n\taction->rewrite->index = (mlx5dr_icm_pool_get_chunk_icm_addr(action->rewrite->chunk) -\n\t\t\t\t  dmn->info.caps.hdr_modify_icm_addr) /\n\t\t\t\t DR_ACTION_CACHE_LINE_SIZE;\n\n\tret = mlx5dr_send_postsend_action(action->rewrite->dmn, action);\n\tif (ret)\n\t\tgoto free_chunk;\n\n\treturn 0;\n\nfree_chunk:\n\tmlx5dr_icm_free_chunk(action->rewrite->chunk);\n\treturn -ENOMEM;\n}\n\nstatic void dr_ste_free_modify_hdr_chunk(struct mlx5dr_action *action)\n{\n\tmlx5dr_icm_free_chunk(action->rewrite->chunk);\n}\n\nint mlx5dr_ste_alloc_modify_hdr(struct mlx5dr_action *action)\n{\n\tstruct mlx5dr_domain *dmn = action->rewrite->dmn;\n\n\tif (mlx5dr_domain_is_support_ptrn_arg(dmn))\n\t\treturn dmn->ste_ctx->alloc_modify_hdr_chunk(action);\n\n\treturn dr_ste_alloc_modify_hdr_chunk(action);\n}\n\nvoid mlx5dr_ste_free_modify_hdr(struct mlx5dr_action *action)\n{\n\tstruct mlx5dr_domain *dmn = action->rewrite->dmn;\n\n\tif (mlx5dr_domain_is_support_ptrn_arg(dmn))\n\t\treturn dmn->ste_ctx->dealloc_modify_hdr_chunk(action);\n\n\treturn dr_ste_free_modify_hdr_chunk(action);\n}\n\nstatic int dr_ste_build_pre_check_spec(struct mlx5dr_domain *dmn,\n\t\t\t\t       struct mlx5dr_match_spec *spec)\n{\n\tif (spec->ip_version) {\n\t\tif (spec->ip_version != 0xf) {\n\t\t\tmlx5dr_err(dmn,\n\t\t\t\t   \"Partial ip_version mask with src/dst IP is not supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (spec->ethertype != 0xffff &&\n\t\t   (DR_MASK_IS_SRC_IP_SET(spec) || DR_MASK_IS_DST_IP_SET(spec))) {\n\t\tmlx5dr_err(dmn,\n\t\t\t   \"Partial/no ethertype mask with src/dst IP is not supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nint mlx5dr_ste_build_pre_check(struct mlx5dr_domain *dmn,\n\t\t\t       u8 match_criteria,\n\t\t\t       struct mlx5dr_match_param *mask,\n\t\t\t       struct mlx5dr_match_param *value)\n{\n\tif (value)\n\t\treturn 0;\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_MISC) {\n\t\tif (mask->misc.source_port && mask->misc.source_port != 0xffff) {\n\t\t\tmlx5dr_err(dmn,\n\t\t\t\t   \"Partial mask source_port is not supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (mask->misc.source_eswitch_owner_vhca_id &&\n\t\t    mask->misc.source_eswitch_owner_vhca_id != 0xffff) {\n\t\t\tmlx5dr_err(dmn,\n\t\t\t\t   \"Partial mask source_eswitch_owner_vhca_id is not supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif ((match_criteria & DR_MATCHER_CRITERIA_OUTER) &&\n\t    dr_ste_build_pre_check_spec(dmn, &mask->outer))\n\t\treturn -EINVAL;\n\n\tif ((match_criteria & DR_MATCHER_CRITERIA_INNER) &&\n\t    dr_ste_build_pre_check_spec(dmn, &mask->inner))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nint mlx5dr_ste_build_ste_arr(struct mlx5dr_matcher *matcher,\n\t\t\t     struct mlx5dr_matcher_rx_tx *nic_matcher,\n\t\t\t     struct mlx5dr_match_param *value,\n\t\t\t     u8 *ste_arr)\n{\n\tstruct mlx5dr_domain_rx_tx *nic_dmn = nic_matcher->nic_tbl->nic_dmn;\n\tbool is_rx = nic_dmn->type == DR_DOMAIN_NIC_TYPE_RX;\n\tstruct mlx5dr_domain *dmn = matcher->tbl->dmn;\n\tstruct mlx5dr_ste_ctx *ste_ctx = dmn->ste_ctx;\n\tstruct mlx5dr_ste_build *sb;\n\tint ret, i;\n\n\tret = mlx5dr_ste_build_pre_check(dmn, matcher->match_criteria,\n\t\t\t\t\t &matcher->mask, value);\n\tif (ret)\n\t\treturn ret;\n\n\tsb = nic_matcher->ste_builder;\n\tfor (i = 0; i < nic_matcher->num_of_builders; i++) {\n\t\tste_ctx->ste_init(ste_arr,\n\t\t\t\t  sb->lu_type,\n\t\t\t\t  is_rx,\n\t\t\t\t  dmn->info.caps.gvmi);\n\n\t\tmlx5dr_ste_set_bit_mask(ste_arr, sb->bit_mask);\n\n\t\tret = sb->ste_build_tag_func(value, sb, dr_ste_get_tag(ste_arr));\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\tif (i < (nic_matcher->num_of_builders - 1)) {\n\t\t\t \n\t\t\tsb++;\n\t\t\tste_ctx->set_next_lu_type(ste_arr, sb->lu_type);\n\t\t\tste_ctx->set_byte_mask(ste_arr, sb->byte_mask);\n\t\t}\n\t\tste_arr += DR_STE_SIZE;\n\t}\n\treturn 0;\n}\n\n#define IFC_GET_CLR(typ, p, fld, clear) ({ \\\n\tvoid *__p = (p); \\\n\tu32 __t = MLX5_GET(typ, __p, fld); \\\n\tif (clear) \\\n\t\tMLX5_SET(typ, __p, fld, 0); \\\n\t__t; \\\n})\n\n#define memcpy_and_clear(to, from, len, clear) ({ \\\n\tvoid *__to = (to), *__from = (from); \\\n\tsize_t __len = (len); \\\n\tmemcpy(__to, __from, __len); \\\n\tif (clear) \\\n\t\tmemset(__from, 0, __len); \\\n})\n\nstatic void dr_ste_copy_mask_misc(char *mask, struct mlx5dr_match_misc *spec, bool clr)\n{\n\tspec->gre_c_present = IFC_GET_CLR(fte_match_set_misc, mask, gre_c_present, clr);\n\tspec->gre_k_present = IFC_GET_CLR(fte_match_set_misc, mask, gre_k_present, clr);\n\tspec->gre_s_present = IFC_GET_CLR(fte_match_set_misc, mask, gre_s_present, clr);\n\tspec->source_vhca_port = IFC_GET_CLR(fte_match_set_misc, mask, source_vhca_port, clr);\n\tspec->source_sqn = IFC_GET_CLR(fte_match_set_misc, mask, source_sqn, clr);\n\n\tspec->source_port = IFC_GET_CLR(fte_match_set_misc, mask, source_port, clr);\n\tspec->source_eswitch_owner_vhca_id =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, source_eswitch_owner_vhca_id, clr);\n\n\tspec->outer_second_prio = IFC_GET_CLR(fte_match_set_misc, mask, outer_second_prio, clr);\n\tspec->outer_second_cfi = IFC_GET_CLR(fte_match_set_misc, mask, outer_second_cfi, clr);\n\tspec->outer_second_vid = IFC_GET_CLR(fte_match_set_misc, mask, outer_second_vid, clr);\n\tspec->inner_second_prio = IFC_GET_CLR(fte_match_set_misc, mask, inner_second_prio, clr);\n\tspec->inner_second_cfi = IFC_GET_CLR(fte_match_set_misc, mask, inner_second_cfi, clr);\n\tspec->inner_second_vid = IFC_GET_CLR(fte_match_set_misc, mask, inner_second_vid, clr);\n\n\tspec->outer_second_cvlan_tag =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, outer_second_cvlan_tag, clr);\n\tspec->inner_second_cvlan_tag =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, inner_second_cvlan_tag, clr);\n\tspec->outer_second_svlan_tag =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, outer_second_svlan_tag, clr);\n\tspec->inner_second_svlan_tag =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, inner_second_svlan_tag, clr);\n\tspec->gre_protocol = IFC_GET_CLR(fte_match_set_misc, mask, gre_protocol, clr);\n\n\tspec->gre_key_h = IFC_GET_CLR(fte_match_set_misc, mask, gre_key.nvgre.hi, clr);\n\tspec->gre_key_l = IFC_GET_CLR(fte_match_set_misc, mask, gre_key.nvgre.lo, clr);\n\n\tspec->vxlan_vni = IFC_GET_CLR(fte_match_set_misc, mask, vxlan_vni, clr);\n\n\tspec->geneve_vni = IFC_GET_CLR(fte_match_set_misc, mask, geneve_vni, clr);\n\tspec->geneve_tlv_option_0_exist =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, geneve_tlv_option_0_exist, clr);\n\tspec->geneve_oam = IFC_GET_CLR(fte_match_set_misc, mask, geneve_oam, clr);\n\n\tspec->outer_ipv6_flow_label =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, outer_ipv6_flow_label, clr);\n\n\tspec->inner_ipv6_flow_label =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, inner_ipv6_flow_label, clr);\n\n\tspec->geneve_opt_len = IFC_GET_CLR(fte_match_set_misc, mask, geneve_opt_len, clr);\n\tspec->geneve_protocol_type =\n\t\tIFC_GET_CLR(fte_match_set_misc, mask, geneve_protocol_type, clr);\n\n\tspec->bth_dst_qp = IFC_GET_CLR(fte_match_set_misc, mask, bth_dst_qp, clr);\n}\n\nstatic void dr_ste_copy_mask_spec(char *mask, struct mlx5dr_match_spec *spec, bool clr)\n{\n\t__be32 raw_ip[4];\n\n\tspec->smac_47_16 = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, smac_47_16, clr);\n\n\tspec->smac_15_0 = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, smac_15_0, clr);\n\tspec->ethertype = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, ethertype, clr);\n\n\tspec->dmac_47_16 = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, dmac_47_16, clr);\n\n\tspec->dmac_15_0 = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, dmac_15_0, clr);\n\tspec->first_prio = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, first_prio, clr);\n\tspec->first_cfi = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, first_cfi, clr);\n\tspec->first_vid = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, first_vid, clr);\n\n\tspec->ip_protocol = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, ip_protocol, clr);\n\tspec->ip_dscp = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, ip_dscp, clr);\n\tspec->ip_ecn = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, ip_ecn, clr);\n\tspec->cvlan_tag = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, cvlan_tag, clr);\n\tspec->svlan_tag = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, svlan_tag, clr);\n\tspec->frag = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, frag, clr);\n\tspec->ip_version = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, ip_version, clr);\n\tspec->tcp_flags = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, tcp_flags, clr);\n\tspec->tcp_sport = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, tcp_sport, clr);\n\tspec->tcp_dport = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, tcp_dport, clr);\n\n\tspec->ipv4_ihl = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, ipv4_ihl, clr);\n\tspec->ttl_hoplimit = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, ttl_hoplimit, clr);\n\n\tspec->udp_sport = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, udp_sport, clr);\n\tspec->udp_dport = IFC_GET_CLR(fte_match_set_lyr_2_4, mask, udp_dport, clr);\n\n\tmemcpy_and_clear(raw_ip, MLX5_ADDR_OF(fte_match_set_lyr_2_4, mask,\n\t\t\t\t\t      src_ipv4_src_ipv6.ipv6_layout.ipv6),\n\t\t\t sizeof(raw_ip), clr);\n\n\tspec->src_ip_127_96 = be32_to_cpu(raw_ip[0]);\n\tspec->src_ip_95_64 = be32_to_cpu(raw_ip[1]);\n\tspec->src_ip_63_32 = be32_to_cpu(raw_ip[2]);\n\tspec->src_ip_31_0 = be32_to_cpu(raw_ip[3]);\n\n\tmemcpy_and_clear(raw_ip, MLX5_ADDR_OF(fte_match_set_lyr_2_4, mask,\n\t\t\t\t\t      dst_ipv4_dst_ipv6.ipv6_layout.ipv6),\n\t\t\t sizeof(raw_ip), clr);\n\n\tspec->dst_ip_127_96 = be32_to_cpu(raw_ip[0]);\n\tspec->dst_ip_95_64 = be32_to_cpu(raw_ip[1]);\n\tspec->dst_ip_63_32 = be32_to_cpu(raw_ip[2]);\n\tspec->dst_ip_31_0 = be32_to_cpu(raw_ip[3]);\n}\n\nstatic void dr_ste_copy_mask_misc2(char *mask, struct mlx5dr_match_misc2 *spec, bool clr)\n{\n\tspec->outer_first_mpls_label =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls.mpls_label, clr);\n\tspec->outer_first_mpls_exp =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls.mpls_exp, clr);\n\tspec->outer_first_mpls_s_bos =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls.mpls_s_bos, clr);\n\tspec->outer_first_mpls_ttl =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls.mpls_ttl, clr);\n\tspec->inner_first_mpls_label =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, inner_first_mpls.mpls_label, clr);\n\tspec->inner_first_mpls_exp =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, inner_first_mpls.mpls_exp, clr);\n\tspec->inner_first_mpls_s_bos =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, inner_first_mpls.mpls_s_bos, clr);\n\tspec->inner_first_mpls_ttl =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, inner_first_mpls.mpls_ttl, clr);\n\tspec->outer_first_mpls_over_gre_label =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_gre.mpls_label, clr);\n\tspec->outer_first_mpls_over_gre_exp =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_gre.mpls_exp, clr);\n\tspec->outer_first_mpls_over_gre_s_bos =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_gre.mpls_s_bos, clr);\n\tspec->outer_first_mpls_over_gre_ttl =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_gre.mpls_ttl, clr);\n\tspec->outer_first_mpls_over_udp_label =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_udp.mpls_label, clr);\n\tspec->outer_first_mpls_over_udp_exp =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_udp.mpls_exp, clr);\n\tspec->outer_first_mpls_over_udp_s_bos =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_udp.mpls_s_bos, clr);\n\tspec->outer_first_mpls_over_udp_ttl =\n\t\tIFC_GET_CLR(fte_match_set_misc2, mask, outer_first_mpls_over_udp.mpls_ttl, clr);\n\tspec->metadata_reg_c_7 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_7, clr);\n\tspec->metadata_reg_c_6 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_6, clr);\n\tspec->metadata_reg_c_5 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_5, clr);\n\tspec->metadata_reg_c_4 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_4, clr);\n\tspec->metadata_reg_c_3 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_3, clr);\n\tspec->metadata_reg_c_2 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_2, clr);\n\tspec->metadata_reg_c_1 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_1, clr);\n\tspec->metadata_reg_c_0 = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_c_0, clr);\n\tspec->metadata_reg_a = IFC_GET_CLR(fte_match_set_misc2, mask, metadata_reg_a, clr);\n}\n\nstatic void dr_ste_copy_mask_misc3(char *mask, struct mlx5dr_match_misc3 *spec, bool clr)\n{\n\tspec->inner_tcp_seq_num = IFC_GET_CLR(fte_match_set_misc3, mask, inner_tcp_seq_num, clr);\n\tspec->outer_tcp_seq_num = IFC_GET_CLR(fte_match_set_misc3, mask, outer_tcp_seq_num, clr);\n\tspec->inner_tcp_ack_num = IFC_GET_CLR(fte_match_set_misc3, mask, inner_tcp_ack_num, clr);\n\tspec->outer_tcp_ack_num = IFC_GET_CLR(fte_match_set_misc3, mask, outer_tcp_ack_num, clr);\n\tspec->outer_vxlan_gpe_vni =\n\t\tIFC_GET_CLR(fte_match_set_misc3, mask, outer_vxlan_gpe_vni, clr);\n\tspec->outer_vxlan_gpe_next_protocol =\n\t\tIFC_GET_CLR(fte_match_set_misc3, mask, outer_vxlan_gpe_next_protocol, clr);\n\tspec->outer_vxlan_gpe_flags =\n\t\tIFC_GET_CLR(fte_match_set_misc3, mask, outer_vxlan_gpe_flags, clr);\n\tspec->icmpv4_header_data = IFC_GET_CLR(fte_match_set_misc3, mask, icmp_header_data, clr);\n\tspec->icmpv6_header_data =\n\t\tIFC_GET_CLR(fte_match_set_misc3, mask, icmpv6_header_data, clr);\n\tspec->icmpv4_type = IFC_GET_CLR(fte_match_set_misc3, mask, icmp_type, clr);\n\tspec->icmpv4_code = IFC_GET_CLR(fte_match_set_misc3, mask, icmp_code, clr);\n\tspec->icmpv6_type = IFC_GET_CLR(fte_match_set_misc3, mask, icmpv6_type, clr);\n\tspec->icmpv6_code = IFC_GET_CLR(fte_match_set_misc3, mask, icmpv6_code, clr);\n\tspec->geneve_tlv_option_0_data =\n\t\tIFC_GET_CLR(fte_match_set_misc3, mask, geneve_tlv_option_0_data, clr);\n\tspec->gtpu_teid = IFC_GET_CLR(fte_match_set_misc3, mask, gtpu_teid, clr);\n\tspec->gtpu_msg_flags = IFC_GET_CLR(fte_match_set_misc3, mask, gtpu_msg_flags, clr);\n\tspec->gtpu_msg_type = IFC_GET_CLR(fte_match_set_misc3, mask, gtpu_msg_type, clr);\n\tspec->gtpu_dw_0 = IFC_GET_CLR(fte_match_set_misc3, mask, gtpu_dw_0, clr);\n\tspec->gtpu_dw_2 = IFC_GET_CLR(fte_match_set_misc3, mask, gtpu_dw_2, clr);\n\tspec->gtpu_first_ext_dw_0 =\n\t\tIFC_GET_CLR(fte_match_set_misc3, mask, gtpu_first_ext_dw_0, clr);\n}\n\nstatic void dr_ste_copy_mask_misc4(char *mask, struct mlx5dr_match_misc4 *spec, bool clr)\n{\n\tspec->prog_sample_field_id_0 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_id_0, clr);\n\tspec->prog_sample_field_value_0 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_value_0, clr);\n\tspec->prog_sample_field_id_1 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_id_1, clr);\n\tspec->prog_sample_field_value_1 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_value_1, clr);\n\tspec->prog_sample_field_id_2 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_id_2, clr);\n\tspec->prog_sample_field_value_2 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_value_2, clr);\n\tspec->prog_sample_field_id_3 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_id_3, clr);\n\tspec->prog_sample_field_value_3 =\n\t\tIFC_GET_CLR(fte_match_set_misc4, mask, prog_sample_field_value_3, clr);\n}\n\nstatic void dr_ste_copy_mask_misc5(char *mask, struct mlx5dr_match_misc5 *spec, bool clr)\n{\n\tspec->macsec_tag_0 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, macsec_tag_0, clr);\n\tspec->macsec_tag_1 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, macsec_tag_1, clr);\n\tspec->macsec_tag_2 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, macsec_tag_2, clr);\n\tspec->macsec_tag_3 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, macsec_tag_3, clr);\n\tspec->tunnel_header_0 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, tunnel_header_0, clr);\n\tspec->tunnel_header_1 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, tunnel_header_1, clr);\n\tspec->tunnel_header_2 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, tunnel_header_2, clr);\n\tspec->tunnel_header_3 =\n\t\tIFC_GET_CLR(fte_match_set_misc5, mask, tunnel_header_3, clr);\n}\n\nvoid mlx5dr_ste_copy_param(u8 match_criteria,\n\t\t\t   struct mlx5dr_match_param *set_param,\n\t\t\t   struct mlx5dr_match_parameters *mask,\n\t\t\t   bool clr)\n{\n\tu8 tail_param[MLX5_ST_SZ_BYTES(fte_match_set_lyr_2_4)] = {};\n\tu8 *data = (u8 *)mask->match_buf;\n\tsize_t param_location;\n\tvoid *buff;\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_OUTER) {\n\t\tif (mask->match_sz < sizeof(struct mlx5dr_match_spec)) {\n\t\t\tmemcpy(tail_param, data, mask->match_sz);\n\t\t\tbuff = tail_param;\n\t\t} else {\n\t\t\tbuff = mask->match_buf;\n\t\t}\n\t\tdr_ste_copy_mask_spec(buff, &set_param->outer, clr);\n\t}\n\tparam_location = sizeof(struct mlx5dr_match_spec);\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_MISC) {\n\t\tif (mask->match_sz < param_location +\n\t\t    sizeof(struct mlx5dr_match_misc)) {\n\t\t\tmemcpy(tail_param, data + param_location,\n\t\t\t       mask->match_sz - param_location);\n\t\t\tbuff = tail_param;\n\t\t} else {\n\t\t\tbuff = data + param_location;\n\t\t}\n\t\tdr_ste_copy_mask_misc(buff, &set_param->misc, clr);\n\t}\n\tparam_location += sizeof(struct mlx5dr_match_misc);\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_INNER) {\n\t\tif (mask->match_sz < param_location +\n\t\t    sizeof(struct mlx5dr_match_spec)) {\n\t\t\tmemcpy(tail_param, data + param_location,\n\t\t\t       mask->match_sz - param_location);\n\t\t\tbuff = tail_param;\n\t\t} else {\n\t\t\tbuff = data + param_location;\n\t\t}\n\t\tdr_ste_copy_mask_spec(buff, &set_param->inner, clr);\n\t}\n\tparam_location += sizeof(struct mlx5dr_match_spec);\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_MISC2) {\n\t\tif (mask->match_sz < param_location +\n\t\t    sizeof(struct mlx5dr_match_misc2)) {\n\t\t\tmemcpy(tail_param, data + param_location,\n\t\t\t       mask->match_sz - param_location);\n\t\t\tbuff = tail_param;\n\t\t} else {\n\t\t\tbuff = data + param_location;\n\t\t}\n\t\tdr_ste_copy_mask_misc2(buff, &set_param->misc2, clr);\n\t}\n\n\tparam_location += sizeof(struct mlx5dr_match_misc2);\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_MISC3) {\n\t\tif (mask->match_sz < param_location +\n\t\t    sizeof(struct mlx5dr_match_misc3)) {\n\t\t\tmemcpy(tail_param, data + param_location,\n\t\t\t       mask->match_sz - param_location);\n\t\t\tbuff = tail_param;\n\t\t} else {\n\t\t\tbuff = data + param_location;\n\t\t}\n\t\tdr_ste_copy_mask_misc3(buff, &set_param->misc3, clr);\n\t}\n\n\tparam_location += sizeof(struct mlx5dr_match_misc3);\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_MISC4) {\n\t\tif (mask->match_sz < param_location +\n\t\t    sizeof(struct mlx5dr_match_misc4)) {\n\t\t\tmemcpy(tail_param, data + param_location,\n\t\t\t       mask->match_sz - param_location);\n\t\t\tbuff = tail_param;\n\t\t} else {\n\t\t\tbuff = data + param_location;\n\t\t}\n\t\tdr_ste_copy_mask_misc4(buff, &set_param->misc4, clr);\n\t}\n\n\tparam_location += sizeof(struct mlx5dr_match_misc4);\n\n\tif (match_criteria & DR_MATCHER_CRITERIA_MISC5) {\n\t\tif (mask->match_sz < param_location +\n\t\t    sizeof(struct mlx5dr_match_misc5)) {\n\t\t\tmemcpy(tail_param, data + param_location,\n\t\t\t       mask->match_sz - param_location);\n\t\t\tbuff = tail_param;\n\t\t} else {\n\t\t\tbuff = data + param_location;\n\t\t}\n\t\tdr_ste_copy_mask_misc5(buff, &set_param->misc5, clr);\n\t}\n}\n\nvoid mlx5dr_ste_build_eth_l2_src_dst(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t     struct mlx5dr_ste_build *sb,\n\t\t\t\t     struct mlx5dr_match_param *mask,\n\t\t\t\t     bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l2_src_dst_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l3_ipv6_dst(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t      struct mlx5dr_ste_build *sb,\n\t\t\t\t      struct mlx5dr_match_param *mask,\n\t\t\t\t      bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l3_ipv6_dst_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l3_ipv6_src(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t      struct mlx5dr_ste_build *sb,\n\t\t\t\t      struct mlx5dr_match_param *mask,\n\t\t\t\t      bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l3_ipv6_src_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l3_ipv4_5_tuple(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\t  struct mlx5dr_ste_build *sb,\n\t\t\t\t\t  struct mlx5dr_match_param *mask,\n\t\t\t\t\t  bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l3_ipv4_5_tuple_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l2_src(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t struct mlx5dr_ste_build *sb,\n\t\t\t\t struct mlx5dr_match_param *mask,\n\t\t\t\t bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l2_src_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l2_dst(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t struct mlx5dr_ste_build *sb,\n\t\t\t\t struct mlx5dr_match_param *mask,\n\t\t\t\t bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l2_dst_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l2_tnl(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t struct mlx5dr_ste_build *sb,\n\t\t\t\t struct mlx5dr_match_param *mask, bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l2_tnl_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l3_ipv4_misc(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t       struct mlx5dr_ste_build *sb,\n\t\t\t\t       struct mlx5dr_match_param *mask,\n\t\t\t\t       bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l3_ipv4_misc_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_ipv6_l3_l4(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t     struct mlx5dr_ste_build *sb,\n\t\t\t\t     struct mlx5dr_match_param *mask,\n\t\t\t\t     bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_ipv6_l3_l4_init(sb, mask);\n}\n\nstatic int dr_ste_build_empty_always_hit_tag(struct mlx5dr_match_param *value,\n\t\t\t\t\t     struct mlx5dr_ste_build *sb,\n\t\t\t\t\t     u8 *tag)\n{\n\treturn 0;\n}\n\nvoid mlx5dr_ste_build_empty_always_hit(struct mlx5dr_ste_build *sb, bool rx)\n{\n\tsb->rx = rx;\n\tsb->lu_type = MLX5DR_STE_LU_TYPE_DONT_CARE;\n\tsb->byte_mask = 0;\n\tsb->ste_build_tag_func = &dr_ste_build_empty_always_hit_tag;\n}\n\nvoid mlx5dr_ste_build_mpls(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t   struct mlx5dr_ste_build *sb,\n\t\t\t   struct mlx5dr_match_param *mask,\n\t\t\t   bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_mpls_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_gre(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t      struct mlx5dr_ste_build *sb,\n\t\t\t      struct mlx5dr_match_param *mask,\n\t\t\t      bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_gre_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_mpls_over_gre(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\tstruct mlx5dr_ste_build *sb,\n\t\t\t\t\tstruct mlx5dr_match_param *mask,\n\t\t\t\t\tstruct mlx5dr_cmd_caps *caps,\n\t\t\t\t\tbool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tsb->caps = caps;\n\treturn ste_ctx->build_tnl_mpls_over_gre_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_mpls_over_udp(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\tstruct mlx5dr_ste_build *sb,\n\t\t\t\t\tstruct mlx5dr_match_param *mask,\n\t\t\t\t\tstruct mlx5dr_cmd_caps *caps,\n\t\t\t\t\tbool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tsb->caps = caps;\n\treturn ste_ctx->build_tnl_mpls_over_udp_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_icmp(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t   struct mlx5dr_ste_build *sb,\n\t\t\t   struct mlx5dr_match_param *mask,\n\t\t\t   struct mlx5dr_cmd_caps *caps,\n\t\t\t   bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tsb->caps = caps;\n\tste_ctx->build_icmp_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_general_purpose(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t      struct mlx5dr_ste_build *sb,\n\t\t\t\t      struct mlx5dr_match_param *mask,\n\t\t\t\t      bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_general_purpose_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_eth_l4_misc(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t  struct mlx5dr_ste_build *sb,\n\t\t\t\t  struct mlx5dr_match_param *mask,\n\t\t\t\t  bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_eth_l4_misc_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_vxlan_gpe(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t    struct mlx5dr_ste_build *sb,\n\t\t\t\t    struct mlx5dr_match_param *mask,\n\t\t\t\t    bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_vxlan_gpe_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_geneve(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t struct mlx5dr_ste_build *sb,\n\t\t\t\t struct mlx5dr_match_param *mask,\n\t\t\t\t bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_geneve_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_geneve_tlv_opt(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\t struct mlx5dr_ste_build *sb,\n\t\t\t\t\t struct mlx5dr_match_param *mask,\n\t\t\t\t\t struct mlx5dr_cmd_caps *caps,\n\t\t\t\t\t bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->caps = caps;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_geneve_tlv_opt_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_geneve_tlv_opt_exist(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\t       struct mlx5dr_ste_build *sb,\n\t\t\t\t\t       struct mlx5dr_match_param *mask,\n\t\t\t\t\t       struct mlx5dr_cmd_caps *caps,\n\t\t\t\t\t       bool inner, bool rx)\n{\n\tif (!ste_ctx->build_tnl_geneve_tlv_opt_exist_init)\n\t\treturn;\n\n\tsb->rx = rx;\n\tsb->caps = caps;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_geneve_tlv_opt_exist_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_gtpu(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t       struct mlx5dr_ste_build *sb,\n\t\t\t       struct mlx5dr_match_param *mask,\n\t\t\t       bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_gtpu_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_gtpu_flex_parser_0(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\t     struct mlx5dr_ste_build *sb,\n\t\t\t\t\t     struct mlx5dr_match_param *mask,\n\t\t\t\t\t     struct mlx5dr_cmd_caps *caps,\n\t\t\t\t\t     bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->caps = caps;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_gtpu_flex_parser_0_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_gtpu_flex_parser_1(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t\t     struct mlx5dr_ste_build *sb,\n\t\t\t\t\t     struct mlx5dr_match_param *mask,\n\t\t\t\t\t     struct mlx5dr_cmd_caps *caps,\n\t\t\t\t\t     bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->caps = caps;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_gtpu_flex_parser_1_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_register_0(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t struct mlx5dr_ste_build *sb,\n\t\t\t\t struct mlx5dr_match_param *mask,\n\t\t\t\t bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_register_0_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_register_1(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t struct mlx5dr_ste_build *sb,\n\t\t\t\t struct mlx5dr_match_param *mask,\n\t\t\t\t bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_register_1_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_src_gvmi_qpn(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t   struct mlx5dr_ste_build *sb,\n\t\t\t\t   struct mlx5dr_match_param *mask,\n\t\t\t\t   struct mlx5dr_domain *dmn,\n\t\t\t\t   bool inner, bool rx)\n{\n\t \n\tsb->vhca_id_valid = mask->misc.source_eswitch_owner_vhca_id;\n\n\tsb->rx = rx;\n\tsb->dmn = dmn;\n\tsb->inner = inner;\n\tste_ctx->build_src_gvmi_qpn_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_flex_parser_0(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t    struct mlx5dr_ste_build *sb,\n\t\t\t\t    struct mlx5dr_match_param *mask,\n\t\t\t\t    bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_flex_parser_0_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_flex_parser_1(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t    struct mlx5dr_ste_build *sb,\n\t\t\t\t    struct mlx5dr_match_param *mask,\n\t\t\t\t    bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_flex_parser_1_init(sb, mask);\n}\n\nvoid mlx5dr_ste_build_tnl_header_0_1(struct mlx5dr_ste_ctx *ste_ctx,\n\t\t\t\t     struct mlx5dr_ste_build *sb,\n\t\t\t\t     struct mlx5dr_match_param *mask,\n\t\t\t\t     bool inner, bool rx)\n{\n\tsb->rx = rx;\n\tsb->inner = inner;\n\tste_ctx->build_tnl_header_0_1_init(sb, mask);\n}\n\nstruct mlx5dr_ste_ctx *mlx5dr_ste_get_ctx(u8 version)\n{\n\tif (version == MLX5_STEERING_FORMAT_CONNECTX_5)\n\t\treturn mlx5dr_ste_get_ctx_v0();\n\telse if (version == MLX5_STEERING_FORMAT_CONNECTX_6DX)\n\t\treturn mlx5dr_ste_get_ctx_v1();\n\telse if (version == MLX5_STEERING_FORMAT_CONNECTX_7)\n\t\treturn mlx5dr_ste_get_ctx_v2();\n\n\treturn NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}