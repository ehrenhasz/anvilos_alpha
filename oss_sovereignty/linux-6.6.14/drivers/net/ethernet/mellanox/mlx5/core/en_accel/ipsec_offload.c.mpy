{
  "module_name": "ipsec_offload.c",
  "hash_id": "dd5e36a680205d3d19682879b0044acb2c4d463c7c5241a9168c79fca9116699",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_offload.c",
  "human_readable_source": "\n \n\n#include \"mlx5_core.h\"\n#include \"en.h\"\n#include \"ipsec.h\"\n#include \"lib/crypto.h\"\n#include \"fs_core.h\"\n#include \"eswitch.h\"\n\nenum {\n\tMLX5_IPSEC_ASO_REMOVE_FLOW_PKT_CNT_OFFSET,\n\tMLX5_IPSEC_ASO_REMOVE_FLOW_SOFT_LFT_OFFSET,\n};\n\nu32 mlx5_ipsec_device_caps(struct mlx5_core_dev *mdev)\n{\n\tu32 caps = 0;\n\n\tif (!MLX5_CAP_GEN(mdev, ipsec_offload))\n\t\treturn 0;\n\n\tif (!MLX5_CAP_GEN(mdev, log_max_dek))\n\t\treturn 0;\n\n\tif (!(MLX5_CAP_GEN_64(mdev, general_obj_types) &\n\t    MLX5_HCA_CAP_GENERAL_OBJECT_TYPES_IPSEC))\n\t\treturn 0;\n\n\tif (!MLX5_CAP_FLOWTABLE_NIC_TX(mdev, ipsec_encrypt) ||\n\t    !MLX5_CAP_FLOWTABLE_NIC_RX(mdev, ipsec_decrypt))\n\t\treturn 0;\n\n\tif (!MLX5_CAP_IPSEC(mdev, ipsec_crypto_esp_aes_gcm_128_encrypt) ||\n\t    !MLX5_CAP_IPSEC(mdev, ipsec_crypto_esp_aes_gcm_128_decrypt))\n\t\treturn 0;\n\n\tif (MLX5_CAP_IPSEC(mdev, ipsec_crypto_offload) &&\n\t    MLX5_CAP_ETH(mdev, insert_trailer) && MLX5_CAP_ETH(mdev, swp))\n\t\tcaps |= MLX5_IPSEC_CAP_CRYPTO;\n\n\tif (MLX5_CAP_IPSEC(mdev, ipsec_full_offload) &&\n\t    (mdev->priv.steering->mode == MLX5_FLOW_STEERING_MODE_DMFS ||\n\t     (mdev->priv.steering->mode == MLX5_FLOW_STEERING_MODE_SMFS &&\n\t     is_mdev_legacy_mode(mdev)))) {\n\t\tif (MLX5_CAP_FLOWTABLE_NIC_TX(mdev,\n\t\t\t\t\t      reformat_add_esp_trasport) &&\n\t\t    MLX5_CAP_FLOWTABLE_NIC_RX(mdev,\n\t\t\t\t\t      reformat_del_esp_trasport) &&\n\t\t    MLX5_CAP_FLOWTABLE_NIC_RX(mdev, decap))\n\t\t\tcaps |= MLX5_IPSEC_CAP_PACKET_OFFLOAD;\n\n\t\tif ((MLX5_CAP_FLOWTABLE_NIC_TX(mdev, ignore_flow_level) &&\n\t\t     MLX5_CAP_FLOWTABLE_NIC_RX(mdev, ignore_flow_level)) ||\n\t\t    MLX5_CAP_ESW_FLOWTABLE_FDB(mdev, ignore_flow_level))\n\t\t\tcaps |= MLX5_IPSEC_CAP_PRIO;\n\n\t\tif (MLX5_CAP_FLOWTABLE_NIC_TX(mdev,\n\t\t\t\t\t      reformat_l2_to_l3_esp_tunnel) &&\n\t\t    MLX5_CAP_FLOWTABLE_NIC_RX(mdev,\n\t\t\t\t\t      reformat_l3_esp_tunnel_to_l2))\n\t\t\tcaps |= MLX5_IPSEC_CAP_TUNNEL;\n\n\t\tif (MLX5_CAP_FLOWTABLE_NIC_TX(mdev,\n\t\t\t\t\t      reformat_add_esp_transport_over_udp) &&\n\t\t    MLX5_CAP_FLOWTABLE_NIC_RX(mdev,\n\t\t\t\t\t      reformat_del_esp_transport_over_udp))\n\t\t\tcaps |= MLX5_IPSEC_CAP_ESPINUDP;\n\t}\n\n\tif (mlx5_get_roce_state(mdev) &&\n\t    MLX5_CAP_GEN_2(mdev, flow_table_type_2_type) & MLX5_FT_NIC_RX_2_NIC_RX_RDMA &&\n\t    MLX5_CAP_GEN_2(mdev, flow_table_type_2_type) & MLX5_FT_NIC_TX_RDMA_2_NIC_TX)\n\t\tcaps |= MLX5_IPSEC_CAP_ROCE;\n\n\tif (!caps)\n\t\treturn 0;\n\n\tif (MLX5_CAP_IPSEC(mdev, ipsec_esn))\n\t\tcaps |= MLX5_IPSEC_CAP_ESN;\n\n\t \n\tWARN_ON_ONCE(MLX5_CAP_IPSEC(mdev, log_max_ipsec_offload) > 24);\n\treturn caps;\n}\nEXPORT_SYMBOL_GPL(mlx5_ipsec_device_caps);\n\nstatic void mlx5e_ipsec_packet_setup(void *obj, u32 pdn,\n\t\t\t\t     struct mlx5_accel_esp_xfrm_attrs *attrs)\n{\n\tvoid *aso_ctx;\n\n\taso_ctx = MLX5_ADDR_OF(ipsec_obj, obj, ipsec_aso);\n\tif (attrs->replay_esn.trigger) {\n\t\tMLX5_SET(ipsec_aso, aso_ctx, esn_event_arm, 1);\n\n\t\tif (attrs->dir == XFRM_DEV_OFFLOAD_IN) {\n\t\t\tMLX5_SET(ipsec_aso, aso_ctx, window_sz,\n\t\t\t\t attrs->replay_esn.replay_window);\n\t\t\tMLX5_SET(ipsec_aso, aso_ctx, mode,\n\t\t\t\t MLX5_IPSEC_ASO_REPLAY_PROTECTION);\n\t\t}\n\t\tMLX5_SET(ipsec_aso, aso_ctx, mode_parameter,\n\t\t\t attrs->replay_esn.esn);\n\t}\n\n\t \n\tMLX5_SET(ipsec_obj, obj, ipsec_aso_access_pd, pdn);\n\tMLX5_SET(ipsec_obj, obj, full_offload, 1);\n\tMLX5_SET(ipsec_aso, aso_ctx, valid, 1);\n\t \n\tMLX5_SET(ipsec_obj, obj, aso_return_reg, MLX5_IPSEC_ASO_REG_C_4_5);\n\tif (attrs->dir == XFRM_DEV_OFFLOAD_OUT)\n\t\tMLX5_SET(ipsec_aso, aso_ctx, mode, MLX5_IPSEC_ASO_INC_SN);\n\n\tif (attrs->lft.hard_packet_limit != XFRM_INF) {\n\t\tMLX5_SET(ipsec_aso, aso_ctx, remove_flow_pkt_cnt,\n\t\t\t attrs->lft.hard_packet_limit);\n\t\tMLX5_SET(ipsec_aso, aso_ctx, hard_lft_arm, 1);\n\t}\n\n\tif (attrs->lft.soft_packet_limit != XFRM_INF) {\n\t\tMLX5_SET(ipsec_aso, aso_ctx, remove_flow_soft_lft,\n\t\t\t attrs->lft.soft_packet_limit);\n\n\t\tMLX5_SET(ipsec_aso, aso_ctx, soft_lft_arm, 1);\n\t}\n}\n\nstatic int mlx5_create_ipsec_obj(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct mlx5_accel_esp_xfrm_attrs *attrs = &sa_entry->attrs;\n\tstruct mlx5_core_dev *mdev = mlx5e_ipsec_sa2dev(sa_entry);\n\tstruct aes_gcm_keymat *aes_gcm = &attrs->aes_gcm;\n\tu32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)];\n\tu32 in[MLX5_ST_SZ_DW(create_ipsec_obj_in)] = {};\n\tvoid *obj, *salt_p, *salt_iv_p;\n\tstruct mlx5e_hw_objs *res;\n\tint err;\n\n\tobj = MLX5_ADDR_OF(create_ipsec_obj_in, in, ipsec_object);\n\n\t \n\tsalt_p = MLX5_ADDR_OF(ipsec_obj, obj, salt);\n\tmemcpy(salt_p, &aes_gcm->salt, sizeof(aes_gcm->salt));\n\n\tMLX5_SET(ipsec_obj, obj, icv_length, MLX5_IPSEC_OBJECT_ICV_LEN_16B);\n\tsalt_iv_p = MLX5_ADDR_OF(ipsec_obj, obj, implicit_iv);\n\tmemcpy(salt_iv_p, &aes_gcm->seq_iv, sizeof(aes_gcm->seq_iv));\n\t \n\tif (attrs->replay_esn.trigger) {\n\t\tMLX5_SET(ipsec_obj, obj, esn_en, 1);\n\t\tMLX5_SET(ipsec_obj, obj, esn_msb, attrs->replay_esn.esn_msb);\n\t\tMLX5_SET(ipsec_obj, obj, esn_overlap, attrs->replay_esn.overlap);\n\t}\n\n\tMLX5_SET(ipsec_obj, obj, dekn, sa_entry->enc_key_id);\n\n\t \n\tMLX5_SET(general_obj_in_cmd_hdr, in, opcode,\n\t\t MLX5_CMD_OP_CREATE_GENERAL_OBJECT);\n\tMLX5_SET(general_obj_in_cmd_hdr, in, obj_type,\n\t\t MLX5_GENERAL_OBJECT_TYPES_IPSEC);\n\n\tres = &mdev->mlx5e_res.hw_objs;\n\tif (attrs->type == XFRM_DEV_OFFLOAD_PACKET)\n\t\tmlx5e_ipsec_packet_setup(obj, res->pdn, attrs);\n\n\terr = mlx5_cmd_exec(mdev, in, sizeof(in), out, sizeof(out));\n\tif (!err)\n\t\tsa_entry->ipsec_obj_id =\n\t\t\tMLX5_GET(general_obj_out_cmd_hdr, out, obj_id);\n\n\treturn err;\n}\n\nstatic void mlx5_destroy_ipsec_obj(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct mlx5_core_dev *mdev = mlx5e_ipsec_sa2dev(sa_entry);\n\tu32 in[MLX5_ST_SZ_DW(general_obj_in_cmd_hdr)] = {};\n\tu32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)];\n\n\tMLX5_SET(general_obj_in_cmd_hdr, in, opcode,\n\t\t MLX5_CMD_OP_DESTROY_GENERAL_OBJECT);\n\tMLX5_SET(general_obj_in_cmd_hdr, in, obj_type,\n\t\t MLX5_GENERAL_OBJECT_TYPES_IPSEC);\n\tMLX5_SET(general_obj_in_cmd_hdr, in, obj_id, sa_entry->ipsec_obj_id);\n\n\tmlx5_cmd_exec(mdev, in, sizeof(in), out, sizeof(out));\n}\n\nint mlx5_ipsec_create_sa_ctx(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct aes_gcm_keymat *aes_gcm = &sa_entry->attrs.aes_gcm;\n\tstruct mlx5_core_dev *mdev = mlx5e_ipsec_sa2dev(sa_entry);\n\tint err;\n\n\t \n\terr = mlx5_create_encryption_key(mdev, aes_gcm->aes_key,\n\t\t\t\t\t aes_gcm->key_len / BITS_PER_BYTE,\n\t\t\t\t\t MLX5_ACCEL_OBJ_IPSEC_KEY,\n\t\t\t\t\t &sa_entry->enc_key_id);\n\tif (err) {\n\t\tmlx5_core_dbg(mdev, \"Failed to create encryption key (err = %d)\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = mlx5_create_ipsec_obj(sa_entry);\n\tif (err) {\n\t\tmlx5_core_dbg(mdev, \"Failed to create IPsec object (err = %d)\\n\", err);\n\t\tgoto err_enc_key;\n\t}\n\n\treturn 0;\n\nerr_enc_key:\n\tmlx5_destroy_encryption_key(mdev, sa_entry->enc_key_id);\n\treturn err;\n}\n\nvoid mlx5_ipsec_free_sa_ctx(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct mlx5_core_dev *mdev = mlx5e_ipsec_sa2dev(sa_entry);\n\n\tmlx5_destroy_ipsec_obj(sa_entry);\n\tmlx5_destroy_encryption_key(mdev, sa_entry->enc_key_id);\n}\n\nstatic int mlx5_modify_ipsec_obj(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\t const struct mlx5_accel_esp_xfrm_attrs *attrs)\n{\n\tstruct mlx5_core_dev *mdev = mlx5e_ipsec_sa2dev(sa_entry);\n\tu32 in[MLX5_ST_SZ_DW(modify_ipsec_obj_in)] = {};\n\tu32 out[MLX5_ST_SZ_DW(query_ipsec_obj_out)];\n\tu64 modify_field_select = 0;\n\tu64 general_obj_types;\n\tvoid *obj;\n\tint err;\n\n\tgeneral_obj_types = MLX5_CAP_GEN_64(mdev, general_obj_types);\n\tif (!(general_obj_types & MLX5_HCA_CAP_GENERAL_OBJECT_TYPES_IPSEC))\n\t\treturn -EINVAL;\n\n\t \n\tMLX5_SET(general_obj_in_cmd_hdr, in, opcode, MLX5_CMD_OP_QUERY_GENERAL_OBJECT);\n\tMLX5_SET(general_obj_in_cmd_hdr, in, obj_type, MLX5_GENERAL_OBJECT_TYPES_IPSEC);\n\tMLX5_SET(general_obj_in_cmd_hdr, in, obj_id, sa_entry->ipsec_obj_id);\n\terr = mlx5_cmd_exec(mdev, in, sizeof(in), out, sizeof(out));\n\tif (err) {\n\t\tmlx5_core_err(mdev, \"Query IPsec object failed (Object id %d), err = %d\\n\",\n\t\t\t      sa_entry->ipsec_obj_id, err);\n\t\treturn err;\n\t}\n\n\tobj = MLX5_ADDR_OF(query_ipsec_obj_out, out, ipsec_object);\n\tmodify_field_select = MLX5_GET64(ipsec_obj, obj, modify_field_select);\n\n\t \n\tif (!(modify_field_select & MLX5_MODIFY_IPSEC_BITMASK_ESN_OVERLAP) ||\n\t    !(modify_field_select & MLX5_MODIFY_IPSEC_BITMASK_ESN_MSB))\n\t\treturn -EOPNOTSUPP;\n\n\tobj = MLX5_ADDR_OF(modify_ipsec_obj_in, in, ipsec_object);\n\tMLX5_SET64(ipsec_obj, obj, modify_field_select,\n\t\t   MLX5_MODIFY_IPSEC_BITMASK_ESN_OVERLAP |\n\t\t\t   MLX5_MODIFY_IPSEC_BITMASK_ESN_MSB);\n\tMLX5_SET(ipsec_obj, obj, esn_msb, attrs->replay_esn.esn_msb);\n\tMLX5_SET(ipsec_obj, obj, esn_overlap, attrs->replay_esn.overlap);\n\n\t \n\tMLX5_SET(general_obj_in_cmd_hdr, in, opcode, MLX5_CMD_OP_MODIFY_GENERAL_OBJECT);\n\n\treturn mlx5_cmd_exec(mdev, in, sizeof(in), out, sizeof(out));\n}\n\nvoid mlx5_accel_esp_modify_xfrm(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\tconst struct mlx5_accel_esp_xfrm_attrs *attrs)\n{\n\tint err;\n\n\terr = mlx5_modify_ipsec_obj(sa_entry, attrs);\n\tif (err)\n\t\treturn;\n\n\tmemcpy(&sa_entry->attrs, attrs, sizeof(sa_entry->attrs));\n}\n\nstatic void mlx5e_ipsec_aso_update(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\t   struct mlx5_wqe_aso_ctrl_seg *data)\n{\n\tdata->data_mask_mode = MLX5_ASO_DATA_MASK_MODE_BITWISE_64BIT << 6;\n\tdata->condition_1_0_operand = MLX5_ASO_ALWAYS_TRUE |\n\t\t\t\t      MLX5_ASO_ALWAYS_TRUE << 4;\n\n\tmlx5e_ipsec_aso_query(sa_entry, data);\n}\n\nstatic void mlx5e_ipsec_update_esn_state(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\t\t u32 mode_param)\n{\n\tstruct mlx5_accel_esp_xfrm_attrs attrs = {};\n\tstruct mlx5_wqe_aso_ctrl_seg data = {};\n\n\tif (mode_param < MLX5E_IPSEC_ESN_SCOPE_MID) {\n\t\tsa_entry->esn_state.esn_msb++;\n\t\tsa_entry->esn_state.overlap = 0;\n\t} else {\n\t\tsa_entry->esn_state.overlap = 1;\n\t}\n\n\tmlx5e_ipsec_build_accel_xfrm_attrs(sa_entry, &attrs);\n\n\t \n\tspin_unlock_bh(&sa_entry->x->lock);\n\tmlx5_accel_esp_modify_xfrm(sa_entry, &attrs);\n\tspin_lock_bh(&sa_entry->x->lock);\n\n\tdata.data_offset_condition_operand =\n\t\tMLX5_IPSEC_ASO_REMOVE_FLOW_PKT_CNT_OFFSET;\n\tdata.bitwise_data = cpu_to_be64(BIT_ULL(54));\n\tdata.data_mask = data.bitwise_data;\n\n\tmlx5e_ipsec_aso_update(sa_entry, &data);\n}\n\nstatic void mlx5e_ipsec_aso_update_hard(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct mlx5_wqe_aso_ctrl_seg data = {};\n\n\tdata.data_offset_condition_operand =\n\t\tMLX5_IPSEC_ASO_REMOVE_FLOW_PKT_CNT_OFFSET;\n\tdata.bitwise_data = cpu_to_be64(BIT_ULL(57) + BIT_ULL(31));\n\tdata.data_mask = data.bitwise_data;\n\tmlx5e_ipsec_aso_update(sa_entry, &data);\n}\n\nstatic void mlx5e_ipsec_aso_update_soft(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\t\tu32 val)\n{\n\tstruct mlx5_wqe_aso_ctrl_seg data = {};\n\n\tdata.data_offset_condition_operand =\n\t\tMLX5_IPSEC_ASO_REMOVE_FLOW_SOFT_LFT_OFFSET;\n\tdata.bitwise_data = cpu_to_be64(val);\n\tdata.data_mask = cpu_to_be64(U32_MAX);\n\tmlx5e_ipsec_aso_update(sa_entry, &data);\n}\n\nstatic void mlx5e_ipsec_handle_limits(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct mlx5_accel_esp_xfrm_attrs *attrs = &sa_entry->attrs;\n\tstruct mlx5e_ipsec *ipsec = sa_entry->ipsec;\n\tstruct mlx5e_ipsec_aso *aso = ipsec->aso;\n\tbool soft_arm, hard_arm;\n\tu64 hard_cnt;\n\n\tlockdep_assert_held(&sa_entry->x->lock);\n\n\tsoft_arm = !MLX5_GET(ipsec_aso, aso->ctx, soft_lft_arm);\n\thard_arm = !MLX5_GET(ipsec_aso, aso->ctx, hard_lft_arm);\n\tif (!soft_arm && !hard_arm)\n\t\t \n\t\treturn;\n\n\thard_cnt = MLX5_GET(ipsec_aso, aso->ctx, remove_flow_pkt_cnt);\n\tif (!hard_cnt || hard_arm) {\n\t\t \n\t\tWARN_ON_ONCE(hard_arm && hard_cnt);\n\n\t\t \n\t\txfrm_state_check_expire(sa_entry->x);\n\t\treturn;\n\t}\n\n\t \n\tif (!sa_entry->limits.soft_limit_hit &&\n\t    sa_entry->limits.round == attrs->lft.numb_rounds_soft) {\n\t\tsa_entry->limits.soft_limit_hit = true;\n\t\t \n\t\txfrm_state_check_expire(sa_entry->x);\n\n\t\tif (sa_entry->limits.round == attrs->lft.numb_rounds_hard)\n\t\t\tgoto hard;\n\n\t\tif (attrs->lft.soft_packet_limit > BIT_ULL(31)) {\n\t\t\t \n\t\t\tmlx5e_ipsec_aso_update_soft(sa_entry,\n\t\t\t\t\t\t    BIT_ULL(31) - BIT_ULL(30));\n\t\t\tsa_entry->limits.fix_limit = true;\n\t\t\treturn;\n\t\t}\n\n\t\tsa_entry->limits.fix_limit = true;\n\t}\n\nhard:\n\tif (sa_entry->limits.round == attrs->lft.numb_rounds_hard) {\n\t\tmlx5e_ipsec_aso_update_soft(sa_entry, 0);\n\t\tattrs->lft.soft_packet_limit = XFRM_INF;\n\t\treturn;\n\t}\n\n\tmlx5e_ipsec_aso_update_hard(sa_entry);\n\tsa_entry->limits.round++;\n\tif (sa_entry->limits.round == attrs->lft.numb_rounds_soft)\n\t\tmlx5e_ipsec_aso_update_soft(sa_entry,\n\t\t\t\t\t    attrs->lft.soft_packet_limit);\n\tif (sa_entry->limits.fix_limit) {\n\t\tsa_entry->limits.fix_limit = false;\n\t\tmlx5e_ipsec_aso_update_soft(sa_entry, BIT_ULL(31) - 1);\n\t}\n}\n\nstatic void mlx5e_ipsec_handle_event(struct work_struct *_work)\n{\n\tstruct mlx5e_ipsec_work *work =\n\t\tcontainer_of(_work, struct mlx5e_ipsec_work, work);\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = work->data;\n\tstruct mlx5_accel_esp_xfrm_attrs *attrs;\n\tstruct mlx5e_ipsec_aso *aso;\n\tint ret;\n\n\taso = sa_entry->ipsec->aso;\n\tattrs = &sa_entry->attrs;\n\n\tspin_lock_bh(&sa_entry->x->lock);\n\tret = mlx5e_ipsec_aso_query(sa_entry, NULL);\n\tif (ret)\n\t\tgoto unlock;\n\n\tif (attrs->replay_esn.trigger &&\n\t    !MLX5_GET(ipsec_aso, aso->ctx, esn_event_arm)) {\n\t\tu32 mode_param = MLX5_GET(ipsec_aso, aso->ctx, mode_parameter);\n\n\t\tmlx5e_ipsec_update_esn_state(sa_entry, mode_param);\n\t}\n\n\tif (attrs->lft.soft_packet_limit != XFRM_INF)\n\t\tmlx5e_ipsec_handle_limits(sa_entry);\n\nunlock:\n\tspin_unlock_bh(&sa_entry->x->lock);\n\tkfree(work);\n}\n\nstatic int mlx5e_ipsec_event(struct notifier_block *nb, unsigned long event,\n\t\t\t     void *data)\n{\n\tstruct mlx5e_ipsec *ipsec = container_of(nb, struct mlx5e_ipsec, nb);\n\tstruct mlx5e_ipsec_sa_entry *sa_entry;\n\tstruct mlx5_eqe_obj_change *object;\n\tstruct mlx5e_ipsec_work *work;\n\tstruct mlx5_eqe *eqe = data;\n\tu16 type;\n\n\tif (event != MLX5_EVENT_TYPE_OBJECT_CHANGE)\n\t\treturn NOTIFY_DONE;\n\n\tobject = &eqe->data.obj_change;\n\ttype = be16_to_cpu(object->obj_type);\n\n\tif (type != MLX5_GENERAL_OBJECT_TYPES_IPSEC)\n\t\treturn NOTIFY_DONE;\n\n\tsa_entry = xa_load(&ipsec->sadb, be32_to_cpu(object->obj_id));\n\tif (!sa_entry)\n\t\treturn NOTIFY_DONE;\n\n\twork = kmalloc(sizeof(*work), GFP_ATOMIC);\n\tif (!work)\n\t\treturn NOTIFY_DONE;\n\n\tINIT_WORK(&work->work, mlx5e_ipsec_handle_event);\n\twork->data = sa_entry;\n\n\tqueue_work(ipsec->wq, &work->work);\n\treturn NOTIFY_OK;\n}\n\nint mlx5e_ipsec_aso_init(struct mlx5e_ipsec *ipsec)\n{\n\tstruct mlx5_core_dev *mdev = ipsec->mdev;\n\tstruct mlx5e_ipsec_aso *aso;\n\tstruct mlx5e_hw_objs *res;\n\tstruct device *pdev;\n\tint err;\n\n\taso = kzalloc(sizeof(*ipsec->aso), GFP_KERNEL);\n\tif (!aso)\n\t\treturn -ENOMEM;\n\n\tres = &mdev->mlx5e_res.hw_objs;\n\n\tpdev = mlx5_core_dma_dev(mdev);\n\taso->dma_addr = dma_map_single(pdev, aso->ctx, sizeof(aso->ctx),\n\t\t\t\t       DMA_BIDIRECTIONAL);\n\terr = dma_mapping_error(pdev, aso->dma_addr);\n\tif (err)\n\t\tgoto err_dma;\n\n\taso->aso = mlx5_aso_create(mdev, res->pdn);\n\tif (IS_ERR(aso->aso)) {\n\t\terr = PTR_ERR(aso->aso);\n\t\tgoto err_aso_create;\n\t}\n\n\tspin_lock_init(&aso->lock);\n\tipsec->nb.notifier_call = mlx5e_ipsec_event;\n\tmlx5_notifier_register(mdev, &ipsec->nb);\n\n\tipsec->aso = aso;\n\treturn 0;\n\nerr_aso_create:\n\tdma_unmap_single(pdev, aso->dma_addr, sizeof(aso->ctx),\n\t\t\t DMA_BIDIRECTIONAL);\nerr_dma:\n\tkfree(aso);\n\treturn err;\n}\n\nvoid mlx5e_ipsec_aso_cleanup(struct mlx5e_ipsec *ipsec)\n{\n\tstruct mlx5_core_dev *mdev = ipsec->mdev;\n\tstruct mlx5e_ipsec_aso *aso;\n\tstruct device *pdev;\n\n\taso = ipsec->aso;\n\tpdev = mlx5_core_dma_dev(mdev);\n\n\tmlx5_notifier_unregister(mdev, &ipsec->nb);\n\tmlx5_aso_destroy(aso->aso);\n\tdma_unmap_single(pdev, aso->dma_addr, sizeof(aso->ctx),\n\t\t\t DMA_BIDIRECTIONAL);\n\tkfree(aso);\n\tipsec->aso = NULL;\n}\n\nstatic void mlx5e_ipsec_aso_copy(struct mlx5_wqe_aso_ctrl_seg *ctrl,\n\t\t\t\t struct mlx5_wqe_aso_ctrl_seg *data)\n{\n\tif (!data)\n\t\treturn;\n\n\tctrl->data_mask_mode = data->data_mask_mode;\n\tctrl->condition_1_0_operand = data->condition_1_0_operand;\n\tctrl->condition_1_0_offset = data->condition_1_0_offset;\n\tctrl->data_offset_condition_operand = data->data_offset_condition_operand;\n\tctrl->condition_0_data = data->condition_0_data;\n\tctrl->condition_0_mask = data->condition_0_mask;\n\tctrl->condition_1_data = data->condition_1_data;\n\tctrl->condition_1_mask = data->condition_1_mask;\n\tctrl->bitwise_data = data->bitwise_data;\n\tctrl->data_mask = data->data_mask;\n}\n\nint mlx5e_ipsec_aso_query(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t  struct mlx5_wqe_aso_ctrl_seg *data)\n{\n\tstruct mlx5e_ipsec *ipsec = sa_entry->ipsec;\n\tstruct mlx5e_ipsec_aso *aso = ipsec->aso;\n\tstruct mlx5_core_dev *mdev = ipsec->mdev;\n\tstruct mlx5_wqe_aso_ctrl_seg *ctrl;\n\tstruct mlx5e_hw_objs *res;\n\tstruct mlx5_aso_wqe *wqe;\n\tunsigned long expires;\n\tu8 ds_cnt;\n\tint ret;\n\n\tlockdep_assert_held(&sa_entry->x->lock);\n\tres = &mdev->mlx5e_res.hw_objs;\n\n\tspin_lock_bh(&aso->lock);\n\tmemset(aso->ctx, 0, sizeof(aso->ctx));\n\twqe = mlx5_aso_get_wqe(aso->aso);\n\tds_cnt = DIV_ROUND_UP(sizeof(*wqe), MLX5_SEND_WQE_DS);\n\tmlx5_aso_build_wqe(aso->aso, ds_cnt, wqe, sa_entry->ipsec_obj_id,\n\t\t\t   MLX5_ACCESS_ASO_OPC_MOD_IPSEC);\n\n\tctrl = &wqe->aso_ctrl;\n\tctrl->va_l =\n\t\tcpu_to_be32(lower_32_bits(aso->dma_addr) | ASO_CTRL_READ_EN);\n\tctrl->va_h = cpu_to_be32(upper_32_bits(aso->dma_addr));\n\tctrl->l_key = cpu_to_be32(res->mkey);\n\tmlx5e_ipsec_aso_copy(ctrl, data);\n\n\tmlx5_aso_post_wqe(aso->aso, false, &wqe->ctrl);\n\texpires = jiffies + msecs_to_jiffies(10);\n\tdo {\n\t\tret = mlx5_aso_poll_cq(aso->aso, false);\n\t\tif (ret)\n\t\t\t \n\t\t\tudelay(10);\n\t} while (ret && time_is_after_jiffies(expires));\n\tspin_unlock_bh(&aso->lock);\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}