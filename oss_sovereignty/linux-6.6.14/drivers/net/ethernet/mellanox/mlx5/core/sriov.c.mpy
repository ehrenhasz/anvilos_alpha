{
  "module_name": "sriov.c",
  "hash_id": "0d41923eb3a6070afd027e2b488e16b03287334b1387e9d484126c253daa8c75",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/sriov.c",
  "human_readable_source": " \n\n#include <linux/pci.h>\n#include <linux/mlx5/driver.h>\n#include <linux/mlx5/vport.h>\n#include \"mlx5_core.h\"\n#include \"mlx5_irq.h\"\n#include \"eswitch.h\"\n\nstatic int sriov_restore_guids(struct mlx5_core_dev *dev, int vf, u16 func_id)\n{\n\tstruct mlx5_core_sriov *sriov = &dev->priv.sriov;\n\tstruct mlx5_hca_vport_context *in;\n\tint err = 0;\n\n\t \n\tif (sriov->vfs_ctx[vf].node_guid ||\n\t    sriov->vfs_ctx[vf].port_guid ||\n\t    sriov->vfs_ctx[vf].policy != MLX5_POLICY_INVALID) {\n\t\tin = kzalloc(sizeof(*in), GFP_KERNEL);\n\t\tif (!in)\n\t\t\treturn -ENOMEM;\n\n\t\tin->node_guid = sriov->vfs_ctx[vf].node_guid;\n\t\tin->port_guid = sriov->vfs_ctx[vf].port_guid;\n\t\tin->policy = sriov->vfs_ctx[vf].policy;\n\t\tin->field_select =\n\t\t\t!!(in->port_guid) * MLX5_HCA_VPORT_SEL_PORT_GUID |\n\t\t\t!!(in->node_guid) * MLX5_HCA_VPORT_SEL_NODE_GUID |\n\t\t\t!!(in->policy) * MLX5_HCA_VPORT_SEL_STATE_POLICY;\n\n\t\terr = mlx5_core_modify_hca_vport_context(dev, 1, 1, func_id, in);\n\t\tif (err)\n\t\t\tmlx5_core_warn(dev, \"modify vport context failed, unable to restore VF %d settings\\n\", vf);\n\n\t\tkfree(in);\n\t}\n\n\treturn err;\n}\n\nstatic int mlx5_device_enable_sriov(struct mlx5_core_dev *dev, int num_vfs)\n{\n\tstruct mlx5_core_sriov *sriov = &dev->priv.sriov;\n\tint err, vf, num_msix_count;\n\tint vport_num;\n\n\terr = mlx5_eswitch_enable(dev->priv.eswitch, num_vfs);\n\tif (err) {\n\t\tmlx5_core_warn(dev,\n\t\t\t       \"failed to enable eswitch SRIOV (%d)\\n\", err);\n\t\treturn err;\n\t}\n\n\tnum_msix_count = mlx5_get_default_msix_vec_count(dev, num_vfs);\n\tfor (vf = 0; vf < num_vfs; vf++) {\n\t\t \n\t\tblocking_notifier_call_chain(&sriov->vfs_ctx[vf].notifier,\n\t\t\t\t\t     MLX5_PF_NOTIFY_ENABLE_VF, dev);\n\t\terr = mlx5_core_enable_hca(dev, vf + 1);\n\t\tif (err) {\n\t\t\tmlx5_core_warn(dev, \"failed to enable VF %d (%d)\\n\", vf, err);\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = mlx5_set_msix_vec_count(dev, vf + 1, num_msix_count);\n\t\tif (err) {\n\t\t\tmlx5_core_warn(dev,\n\t\t\t\t       \"failed to set MSI-X vector counts VF %d, err %d\\n\",\n\t\t\t\t       vf, err);\n\t\t\tcontinue;\n\t\t}\n\n\t\tsriov->vfs_ctx[vf].enabled = 1;\n\t\tif (MLX5_CAP_GEN(dev, port_type) == MLX5_CAP_PORT_TYPE_IB) {\n\t\t\tvport_num = mlx5_core_ec_sriov_enabled(dev) ?\n\t\t\t\t\tmlx5_core_ec_vf_vport_base(dev) + vf\n\t\t\t\t\t: vf + 1;\n\t\t\terr = sriov_restore_guids(dev, vf, vport_num);\n\t\t\tif (err) {\n\t\t\t\tmlx5_core_warn(dev,\n\t\t\t\t\t       \"failed to restore VF %d settings, err %d\\n\",\n\t\t\t\t\t       vf, err);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tmlx5_core_dbg(dev, \"successfully enabled VF* %d\\n\", vf);\n\t}\n\n\treturn 0;\n}\n\nstatic void\nmlx5_device_disable_sriov(struct mlx5_core_dev *dev, int num_vfs, bool clear_vf, bool num_vf_change)\n{\n\tstruct mlx5_core_sriov *sriov = &dev->priv.sriov;\n\tbool wait_for_ec_vf_pages = true;\n\tbool wait_for_vf_pages = true;\n\tint err;\n\tint vf;\n\n\tfor (vf = num_vfs - 1; vf >= 0; vf--) {\n\t\tif (!sriov->vfs_ctx[vf].enabled)\n\t\t\tcontinue;\n\t\t \n\t\tblocking_notifier_call_chain(&sriov->vfs_ctx[vf].notifier,\n\t\t\t\t\t     MLX5_PF_NOTIFY_DISABLE_VF, dev);\n\t\terr = mlx5_core_disable_hca(dev, vf + 1);\n\t\tif (err) {\n\t\t\tmlx5_core_warn(dev, \"failed to disable VF %d\\n\", vf);\n\t\t\tcontinue;\n\t\t}\n\t\tsriov->vfs_ctx[vf].enabled = 0;\n\t}\n\n\tmlx5_eswitch_disable_sriov(dev->priv.eswitch, clear_vf);\n\n\t \n\tif (num_vf_change) {\n\t\tif (mlx5_core_ec_sriov_enabled(dev))\n\t\t\twait_for_vf_pages = false;\n\t\telse\n\t\t\twait_for_ec_vf_pages = false;\n\t}\n\n\tif (wait_for_ec_vf_pages && mlx5_wait_for_pages(dev, &dev->priv.page_counters[MLX5_EC_VF]))\n\t\tmlx5_core_warn(dev, \"timeout reclaiming EC VFs pages\\n\");\n\n\t \n\tif (mlx5_core_is_ecpf(dev))\n\t\treturn;\n\n\tif (wait_for_vf_pages && mlx5_wait_for_pages(dev, &dev->priv.page_counters[MLX5_VF]))\n\t\tmlx5_core_warn(dev, \"timeout reclaiming VFs pages\\n\");\n}\n\nstatic int mlx5_sriov_enable(struct pci_dev *pdev, int num_vfs)\n{\n\tstruct mlx5_core_dev *dev  = pci_get_drvdata(pdev);\n\tstruct devlink *devlink = priv_to_devlink(dev);\n\tint err;\n\n\tdevl_lock(devlink);\n\terr = mlx5_device_enable_sriov(dev, num_vfs);\n\tdevl_unlock(devlink);\n\tif (err) {\n\t\tmlx5_core_warn(dev, \"mlx5_device_enable_sriov failed : %d\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = pci_enable_sriov(pdev, num_vfs);\n\tif (err) {\n\t\tmlx5_core_warn(dev, \"pci_enable_sriov failed : %d\\n\", err);\n\t\tmlx5_device_disable_sriov(dev, num_vfs, true, true);\n\t}\n\treturn err;\n}\n\nvoid mlx5_sriov_disable(struct pci_dev *pdev, bool num_vf_change)\n{\n\tstruct mlx5_core_dev *dev  = pci_get_drvdata(pdev);\n\tstruct devlink *devlink = priv_to_devlink(dev);\n\tint num_vfs = pci_num_vf(dev->pdev);\n\n\tpci_disable_sriov(pdev);\n\tdevl_lock(devlink);\n\tmlx5_device_disable_sriov(dev, num_vfs, true, num_vf_change);\n\tdevl_unlock(devlink);\n}\n\nint mlx5_core_sriov_configure(struct pci_dev *pdev, int num_vfs)\n{\n\tstruct mlx5_core_dev *dev  = pci_get_drvdata(pdev);\n\tstruct mlx5_core_sriov *sriov = &dev->priv.sriov;\n\tint err = 0;\n\n\tmlx5_core_dbg(dev, \"requested num_vfs %d\\n\", num_vfs);\n\n\tif (num_vfs)\n\t\terr = mlx5_sriov_enable(pdev, num_vfs);\n\telse\n\t\tmlx5_sriov_disable(pdev, true);\n\n\tif (!err)\n\t\tsriov->num_vfs = num_vfs;\n\treturn err ? err : num_vfs;\n}\n\nint mlx5_core_sriov_set_msix_vec_count(struct pci_dev *vf, int msix_vec_count)\n{\n\tstruct pci_dev *pf = pci_physfn(vf);\n\tstruct mlx5_core_sriov *sriov;\n\tstruct mlx5_core_dev *dev;\n\tint num_vf_msix, id;\n\n\tdev = pci_get_drvdata(pf);\n\tnum_vf_msix = MLX5_CAP_GEN_MAX(dev, num_total_dynamic_vf_msix);\n\tif (!num_vf_msix)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!msix_vec_count)\n\t\tmsix_vec_count =\n\t\t\tmlx5_get_default_msix_vec_count(dev, pci_num_vf(pf));\n\n\tsriov = &dev->priv.sriov;\n\tid = pci_iov_vf_id(vf);\n\tif (id < 0 || !sriov->vfs_ctx[id].enabled)\n\t\treturn -EINVAL;\n\n\treturn mlx5_set_msix_vec_count(dev, id + 1, msix_vec_count);\n}\n\nint mlx5_sriov_attach(struct mlx5_core_dev *dev)\n{\n\tif (!mlx5_core_is_pf(dev) || !pci_num_vf(dev->pdev))\n\t\treturn 0;\n\n\t \n\treturn mlx5_device_enable_sriov(dev, pci_num_vf(dev->pdev));\n}\n\nvoid mlx5_sriov_detach(struct mlx5_core_dev *dev)\n{\n\tif (!mlx5_core_is_pf(dev))\n\t\treturn;\n\n\tmlx5_device_disable_sriov(dev, pci_num_vf(dev->pdev), false, false);\n}\n\nstatic u16 mlx5_get_max_vfs(struct mlx5_core_dev *dev)\n{\n\tu16 host_total_vfs;\n\tconst u32 *out;\n\n\tif (mlx5_core_is_ecpf_esw_manager(dev)) {\n\t\tout = mlx5_esw_query_functions(dev);\n\n\t\t \n\t\tif (IS_ERR(out))\n\t\t\tgoto done;\n\t\thost_total_vfs = MLX5_GET(query_esw_functions_out, out,\n\t\t\t\t\t  host_params_context.host_total_vfs);\n\t\tkvfree(out);\n\t\treturn host_total_vfs;\n\t}\n\ndone:\n\treturn pci_sriov_get_totalvfs(dev->pdev);\n}\n\nint mlx5_sriov_init(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_core_sriov *sriov = &dev->priv.sriov;\n\tstruct pci_dev *pdev = dev->pdev;\n\tint total_vfs, i;\n\n\tif (!mlx5_core_is_pf(dev))\n\t\treturn 0;\n\n\ttotal_vfs = pci_sriov_get_totalvfs(pdev);\n\tsriov->max_vfs = mlx5_get_max_vfs(dev);\n\tsriov->num_vfs = pci_num_vf(pdev);\n\tsriov->max_ec_vfs = mlx5_core_ec_sriov_enabled(dev) ? pci_sriov_get_totalvfs(dev->pdev) : 0;\n\tsriov->vfs_ctx = kcalloc(total_vfs, sizeof(*sriov->vfs_ctx), GFP_KERNEL);\n\tif (!sriov->vfs_ctx)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < total_vfs; i++)\n\t\tBLOCKING_INIT_NOTIFIER_HEAD(&sriov->vfs_ctx[i].notifier);\n\n\treturn 0;\n}\n\nvoid mlx5_sriov_cleanup(struct mlx5_core_dev *dev)\n{\n\tstruct mlx5_core_sriov *sriov = &dev->priv.sriov;\n\n\tif (!mlx5_core_is_pf(dev))\n\t\treturn;\n\n\tkfree(sriov->vfs_ctx);\n}\n\n \nvoid mlx5_sriov_blocking_notifier_unregister(struct mlx5_core_dev *mdev,\n\t\t\t\t\t     int vf_id,\n\t\t\t\t\t     struct notifier_block *nb)\n{\n\tstruct mlx5_vf_context *vfs_ctx;\n\tstruct mlx5_core_sriov *sriov;\n\n\tsriov = &mdev->priv.sriov;\n\tif (WARN_ON(vf_id < 0 || vf_id >= sriov->num_vfs))\n\t\treturn;\n\n\tvfs_ctx = &sriov->vfs_ctx[vf_id];\n\tblocking_notifier_chain_unregister(&vfs_ctx->notifier, nb);\n}\nEXPORT_SYMBOL(mlx5_sriov_blocking_notifier_unregister);\n\n \nint mlx5_sriov_blocking_notifier_register(struct mlx5_core_dev *mdev,\n\t\t\t\t\t  int vf_id,\n\t\t\t\t\t  struct notifier_block *nb)\n{\n\tstruct mlx5_vf_context *vfs_ctx;\n\tstruct mlx5_core_sriov *sriov;\n\n\tsriov = &mdev->priv.sriov;\n\tif (vf_id < 0 || vf_id >= sriov->num_vfs)\n\t\treturn -EINVAL;\n\n\tvfs_ctx = &sriov->vfs_ctx[vf_id];\n\treturn blocking_notifier_chain_register(&vfs_ctx->notifier, nb);\n}\nEXPORT_SYMBOL(mlx5_sriov_blocking_notifier_register);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}