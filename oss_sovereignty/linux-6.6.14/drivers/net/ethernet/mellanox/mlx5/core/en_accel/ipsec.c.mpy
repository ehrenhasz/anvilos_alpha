{
  "module_name": "ipsec.c",
  "hash_id": "f4d4c9f5a0c4d08122857a34fe2a7d08216d680839fe83b545dd7e7894c83abd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec.c",
  "human_readable_source": " \n\n#include <crypto/internal/geniv.h>\n#include <crypto/aead.h>\n#include <linux/inetdevice.h>\n#include <linux/netdevice.h>\n#include <net/netevent.h>\n\n#include \"en.h\"\n#include \"eswitch.h\"\n#include \"ipsec.h\"\n#include \"ipsec_rxtx.h\"\n#include \"en_rep.h\"\n\n#define MLX5_IPSEC_RESCHED msecs_to_jiffies(1000)\n#define MLX5E_IPSEC_TUNNEL_SA XA_MARK_1\n\nstatic struct mlx5e_ipsec_sa_entry *to_ipsec_sa_entry(struct xfrm_state *x)\n{\n\treturn (struct mlx5e_ipsec_sa_entry *)x->xso.offload_handle;\n}\n\nstatic struct mlx5e_ipsec_pol_entry *to_ipsec_pol_entry(struct xfrm_policy *x)\n{\n\treturn (struct mlx5e_ipsec_pol_entry *)x->xdo.offload_handle;\n}\n\nstatic void mlx5e_ipsec_handle_tx_limit(struct work_struct *_work)\n{\n\tstruct mlx5e_ipsec_dwork *dwork =\n\t\tcontainer_of(_work, struct mlx5e_ipsec_dwork, dwork.work);\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = dwork->sa_entry;\n\tstruct xfrm_state *x = sa_entry->x;\n\n\tif (sa_entry->attrs.drop)\n\t\treturn;\n\n\tspin_lock_bh(&x->lock);\n\txfrm_state_check_expire(x);\n\tif (x->km.state == XFRM_STATE_EXPIRED) {\n\t\tsa_entry->attrs.drop = true;\n\t\tspin_unlock_bh(&x->lock);\n\n\t\tmlx5e_accel_ipsec_fs_modify(sa_entry);\n\t\treturn;\n\t}\n\tspin_unlock_bh(&x->lock);\n\n\tqueue_delayed_work(sa_entry->ipsec->wq, &dwork->dwork,\n\t\t\t   MLX5_IPSEC_RESCHED);\n}\n\nstatic bool mlx5e_ipsec_update_esn_state(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct xfrm_state *x = sa_entry->x;\n\tu32 seq_bottom = 0;\n\tu32 esn, esn_msb;\n\tu8 overlap;\n\n\tswitch (x->xso.type) {\n\tcase XFRM_DEV_OFFLOAD_PACKET:\n\t\tswitch (x->xso.dir) {\n\t\tcase XFRM_DEV_OFFLOAD_IN:\n\t\t\tesn = x->replay_esn->seq;\n\t\t\tesn_msb = x->replay_esn->seq_hi;\n\t\t\tbreak;\n\t\tcase XFRM_DEV_OFFLOAD_OUT:\n\t\t\tesn = x->replay_esn->oseq;\n\t\t\tesn_msb = x->replay_esn->oseq_hi;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tWARN_ON(true);\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase XFRM_DEV_OFFLOAD_CRYPTO:\n\t\t \n\t\tesn = x->replay_esn->seq;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(true);\n\t\treturn false;\n\t}\n\n\toverlap = sa_entry->esn_state.overlap;\n\n\tif (esn >= x->replay_esn->replay_window)\n\t\tseq_bottom = esn - x->replay_esn->replay_window + 1;\n\n\tif (x->xso.type == XFRM_DEV_OFFLOAD_CRYPTO)\n\t\tesn_msb = xfrm_replay_seqhi(x, htonl(seq_bottom));\n\n\tif (sa_entry->esn_state.esn_msb)\n\t\tsa_entry->esn_state.esn = esn;\n\telse\n\t\t \n\t\tsa_entry->esn_state.esn = max_t(u32, esn, 1);\n\tsa_entry->esn_state.esn_msb = esn_msb;\n\n\tif (unlikely(overlap && seq_bottom < MLX5E_IPSEC_ESN_SCOPE_MID)) {\n\t\tsa_entry->esn_state.overlap = 0;\n\t\treturn true;\n\t} else if (unlikely(!overlap &&\n\t\t\t    (seq_bottom >= MLX5E_IPSEC_ESN_SCOPE_MID))) {\n\t\tsa_entry->esn_state.overlap = 1;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void mlx5e_ipsec_init_limits(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\t    struct mlx5_accel_esp_xfrm_attrs *attrs)\n{\n\tstruct xfrm_state *x = sa_entry->x;\n\ts64 start_value, n;\n\n\tattrs->lft.hard_packet_limit = x->lft.hard_packet_limit;\n\tattrs->lft.soft_packet_limit = x->lft.soft_packet_limit;\n\tif (x->lft.soft_packet_limit == XFRM_INF)\n\t\treturn;\n\n\t \n\n\t \n\tn = attrs->lft.hard_packet_limit / BIT_ULL(31);\n\tstart_value = attrs->lft.hard_packet_limit - n * BIT_ULL(31);\n\n\t \n\tif (n >= 1)\n\t\tn -= 1;\n\n\t \n\tstart_value = attrs->lft.hard_packet_limit - n * BIT_ULL(31);\n\n\t \n\tattrs->lft.hard_packet_limit = lower_32_bits(start_value);\n\tattrs->lft.numb_rounds_hard = (u64)n;\n\n\t \n\n\t \n\tn = (x->lft.soft_packet_limit - attrs->lft.hard_packet_limit) / BIT_ULL(31);\n\tstart_value = attrs->lft.hard_packet_limit + n * BIT_ULL(31) -\n\t\t      x->lft.soft_packet_limit;\n\n\t \n\tif (n < 0)\n\t\tn = 0;\n\telse if (start_value >= BIT_ULL(32))\n\t\tn -= 1;\n\telse if (start_value < 0)\n\t\tn += 1;\n\n\t \n\tstart_value = attrs->lft.hard_packet_limit + n * BIT_ULL(31) - start_value;\n\tif (n != attrs->lft.numb_rounds_hard && start_value < BIT_ULL(30))\n\t\tn += 1;\n\n\t \n\n\t \n\tstart_value = attrs->lft.hard_packet_limit + n * BIT_ULL(31) - start_value;\n\n\t \n\tattrs->lft.soft_packet_limit = lower_32_bits(start_value);\n\tattrs->lft.numb_rounds_soft = (u64)n;\n}\n\nstatic void mlx5e_ipsec_init_macs(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\t  struct mlx5_accel_esp_xfrm_attrs *attrs)\n{\n\tstruct mlx5_core_dev *mdev = mlx5e_ipsec_sa2dev(sa_entry);\n\tstruct xfrm_state *x = sa_entry->x;\n\tstruct net_device *netdev;\n\tstruct neighbour *n;\n\tu8 addr[ETH_ALEN];\n\tconst void *pkey;\n\tu8 *dst, *src;\n\n\tif (attrs->mode != XFRM_MODE_TUNNEL ||\n\t    attrs->type != XFRM_DEV_OFFLOAD_PACKET)\n\t\treturn;\n\n\tnetdev = x->xso.real_dev;\n\n\tmlx5_query_mac_address(mdev, addr);\n\tswitch (attrs->dir) {\n\tcase XFRM_DEV_OFFLOAD_IN:\n\t\tsrc = attrs->dmac;\n\t\tdst = attrs->smac;\n\t\tpkey = &attrs->saddr.a4;\n\t\tbreak;\n\tcase XFRM_DEV_OFFLOAD_OUT:\n\t\tsrc = attrs->smac;\n\t\tdst = attrs->dmac;\n\t\tpkey = &attrs->daddr.a4;\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\tether_addr_copy(src, addr);\n\tn = neigh_lookup(&arp_tbl, pkey, netdev);\n\tif (!n) {\n\t\tn = neigh_create(&arp_tbl, pkey, netdev);\n\t\tif (IS_ERR(n))\n\t\t\treturn;\n\t\tneigh_event_send(n, NULL);\n\t\tattrs->drop = true;\n\t} else {\n\t\tneigh_ha_snapshot(addr, n, netdev);\n\t\tether_addr_copy(dst, addr);\n\t}\n\tneigh_release(n);\n}\n\nvoid mlx5e_ipsec_build_accel_xfrm_attrs(struct mlx5e_ipsec_sa_entry *sa_entry,\n\t\t\t\t\tstruct mlx5_accel_esp_xfrm_attrs *attrs)\n{\n\tstruct xfrm_state *x = sa_entry->x;\n\tstruct aes_gcm_keymat *aes_gcm = &attrs->aes_gcm;\n\tstruct aead_geniv_ctx *geniv_ctx;\n\tstruct crypto_aead *aead;\n\tunsigned int crypto_data_len, key_len;\n\tint ivsize;\n\n\tmemset(attrs, 0, sizeof(*attrs));\n\n\t \n\tcrypto_data_len = (x->aead->alg_key_len + 7) / 8;\n\tkey_len = crypto_data_len - 4;  \n\n\tmemcpy(aes_gcm->aes_key, x->aead->alg_key, key_len);\n\taes_gcm->key_len = key_len * 8;\n\n\t \n\taead = x->data;\n\tgeniv_ctx = crypto_aead_ctx(aead);\n\tivsize = crypto_aead_ivsize(aead);\n\tmemcpy(&aes_gcm->seq_iv, &geniv_ctx->salt, ivsize);\n\tmemcpy(&aes_gcm->salt, x->aead->alg_key + key_len,\n\t       sizeof(aes_gcm->salt));\n\n\tattrs->authsize = crypto_aead_authsize(aead) / 4;  \n\n\t \n\taes_gcm->icv_len = x->aead->alg_icv_len;\n\n\t \n\tif (x->props.flags & XFRM_STATE_ESN) {\n\t\tattrs->replay_esn.trigger = true;\n\t\tattrs->replay_esn.esn = sa_entry->esn_state.esn;\n\t\tattrs->replay_esn.esn_msb = sa_entry->esn_state.esn_msb;\n\t\tattrs->replay_esn.overlap = sa_entry->esn_state.overlap;\n\t\tswitch (x->replay_esn->replay_window) {\n\t\tcase 32:\n\t\t\tattrs->replay_esn.replay_window =\n\t\t\t\tMLX5_IPSEC_ASO_REPLAY_WIN_32BIT;\n\t\t\tbreak;\n\t\tcase 64:\n\t\t\tattrs->replay_esn.replay_window =\n\t\t\t\tMLX5_IPSEC_ASO_REPLAY_WIN_64BIT;\n\t\t\tbreak;\n\t\tcase 128:\n\t\t\tattrs->replay_esn.replay_window =\n\t\t\t\tMLX5_IPSEC_ASO_REPLAY_WIN_128BIT;\n\t\t\tbreak;\n\t\tcase 256:\n\t\t\tattrs->replay_esn.replay_window =\n\t\t\t\tMLX5_IPSEC_ASO_REPLAY_WIN_256BIT;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tWARN_ON(true);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tattrs->dir = x->xso.dir;\n\t \n\tattrs->spi = be32_to_cpu(x->id.spi);\n\n\t \n\tmemcpy(&attrs->saddr, x->props.saddr.a6, sizeof(attrs->saddr));\n\tmemcpy(&attrs->daddr, x->id.daddr.a6, sizeof(attrs->daddr));\n\tattrs->family = x->props.family;\n\tattrs->type = x->xso.type;\n\tattrs->reqid = x->props.reqid;\n\tattrs->upspec.dport = ntohs(x->sel.dport);\n\tattrs->upspec.dport_mask = ntohs(x->sel.dport_mask);\n\tattrs->upspec.sport = ntohs(x->sel.sport);\n\tattrs->upspec.sport_mask = ntohs(x->sel.sport_mask);\n\tattrs->upspec.proto = x->sel.proto;\n\tattrs->mode = x->props.mode;\n\n\tmlx5e_ipsec_init_limits(sa_entry, attrs);\n\tmlx5e_ipsec_init_macs(sa_entry, attrs);\n\n\tif (x->encap) {\n\t\tattrs->encap = true;\n\t\tattrs->sport = x->encap->encap_sport;\n\t\tattrs->dport = x->encap->encap_dport;\n\t}\n}\n\nstatic int mlx5e_xfrm_validate_state(struct mlx5_core_dev *mdev,\n\t\t\t\t     struct xfrm_state *x,\n\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tif (x->props.aalgo != SADB_AALG_NONE) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload authenticated xfrm states\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->props.ealgo != SADB_X_EALG_AES_GCM_ICV16) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Only AES-GCM-ICV16 xfrm state may be offloaded\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->props.calgo != SADB_X_CALG_NONE) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload compressed xfrm states\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->props.flags & XFRM_STATE_ESN &&\n\t    !(mlx5_ipsec_device_caps(mdev) & MLX5_IPSEC_CAP_ESN)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload ESN xfrm states\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->props.family != AF_INET &&\n\t    x->props.family != AF_INET6) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Only IPv4/6 xfrm states may be offloaded\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->id.proto != IPPROTO_ESP) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Only ESP xfrm state may be offloaded\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->encap) {\n\t\tif (!(mlx5_ipsec_device_caps(mdev) & MLX5_IPSEC_CAP_ESPINUDP)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Encapsulation is not supported\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->encap->encap_type != UDP_ENCAP_ESPINUDP) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Encapsulation other than UDP is not supported\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->xso.type != XFRM_DEV_OFFLOAD_PACKET) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Encapsulation is supported in packet offload mode only\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->props.mode != XFRM_MODE_TRANSPORT) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Encapsulation is supported in transport mode only\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tif (!x->aead) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload xfrm states without aead\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->aead->alg_icv_len != 128) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload xfrm states with AEAD ICV length other than 128bit\");\n\t\treturn -EINVAL;\n\t}\n\tif ((x->aead->alg_key_len != 128 + 32) &&\n\t    (x->aead->alg_key_len != 256 + 32)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload xfrm states with AEAD key length other than 128/256 bit\");\n\t\treturn -EINVAL;\n\t}\n\tif (x->tfcpad) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload xfrm states with tfc padding\");\n\t\treturn -EINVAL;\n\t}\n\tif (!x->geniv) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload xfrm states without geniv\");\n\t\treturn -EINVAL;\n\t}\n\tif (strcmp(x->geniv, \"seqiv\")) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload xfrm states with geniv other than seqiv\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (x->sel.proto != IPPROTO_IP && x->sel.proto != IPPROTO_UDP &&\n\t    x->sel.proto != IPPROTO_TCP) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Device does not support upper protocol other than TCP/UDP\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (x->props.mode != XFRM_MODE_TRANSPORT && x->props.mode != XFRM_MODE_TUNNEL) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Only transport and tunnel xfrm states may be offloaded\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (x->xso.type) {\n\tcase XFRM_DEV_OFFLOAD_CRYPTO:\n\t\tif (!(mlx5_ipsec_device_caps(mdev) & MLX5_IPSEC_CAP_CRYPTO)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Crypto offload is not supported\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tbreak;\n\tcase XFRM_DEV_OFFLOAD_PACKET:\n\t\tif (!(mlx5_ipsec_device_caps(mdev) &\n\t\t      MLX5_IPSEC_CAP_PACKET_OFFLOAD)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Packet offload is not supported\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->props.mode == XFRM_MODE_TUNNEL &&\n\t\t    !(mlx5_ipsec_device_caps(mdev) & MLX5_IPSEC_CAP_TUNNEL)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Packet offload is not supported for tunnel mode\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->replay_esn && x->replay_esn->replay_window != 32 &&\n\t\t    x->replay_esn->replay_window != 64 &&\n\t\t    x->replay_esn->replay_window != 128 &&\n\t\t    x->replay_esn->replay_window != 256) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported replay window size\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!x->props.reqid) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload without reqid\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->lft.hard_byte_limit != XFRM_INF ||\n\t\t    x->lft.soft_byte_limit != XFRM_INF) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Device doesn't support limits in bytes\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->lft.soft_packet_limit >= x->lft.hard_packet_limit &&\n\t\t    x->lft.hard_packet_limit != XFRM_INF) {\n\t\t\t \n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Hard packet limit must be greater than soft one\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!x->lft.soft_packet_limit || !x->lft.hard_packet_limit) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Soft/hard packet limits can't be 0\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported xfrm offload type\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic void mlx5e_ipsec_modify_state(struct work_struct *_work)\n{\n\tstruct mlx5e_ipsec_work *work =\n\t\tcontainer_of(_work, struct mlx5e_ipsec_work, work);\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = work->sa_entry;\n\tstruct mlx5_accel_esp_xfrm_attrs *attrs;\n\n\tattrs = &((struct mlx5e_ipsec_sa_entry *)work->data)->attrs;\n\n\tmlx5_accel_esp_modify_xfrm(sa_entry, attrs);\n}\n\nstatic void mlx5e_ipsec_set_esn_ops(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct xfrm_state *x = sa_entry->x;\n\n\tif (x->xso.type != XFRM_DEV_OFFLOAD_CRYPTO ||\n\t    x->xso.dir != XFRM_DEV_OFFLOAD_OUT)\n\t\treturn;\n\n\tif (x->props.flags & XFRM_STATE_ESN) {\n\t\tsa_entry->set_iv_op = mlx5e_ipsec_set_iv_esn;\n\t\treturn;\n\t}\n\n\tsa_entry->set_iv_op = mlx5e_ipsec_set_iv;\n}\n\nstatic void mlx5e_ipsec_handle_netdev_event(struct work_struct *_work)\n{\n\tstruct mlx5e_ipsec_work *work =\n\t\tcontainer_of(_work, struct mlx5e_ipsec_work, work);\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = work->sa_entry;\n\tstruct mlx5e_ipsec_netevent_data *data = work->data;\n\tstruct mlx5_accel_esp_xfrm_attrs *attrs;\n\n\tattrs = &sa_entry->attrs;\n\n\tswitch (attrs->dir) {\n\tcase XFRM_DEV_OFFLOAD_IN:\n\t\tether_addr_copy(attrs->smac, data->addr);\n\t\tbreak;\n\tcase XFRM_DEV_OFFLOAD_OUT:\n\t\tether_addr_copy(attrs->dmac, data->addr);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON_ONCE(true);\n\t}\n\tattrs->drop = false;\n\tmlx5e_accel_ipsec_fs_modify(sa_entry);\n}\n\nstatic int mlx5_ipsec_create_work(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct xfrm_state *x = sa_entry->x;\n\tstruct mlx5e_ipsec_work *work;\n\tvoid *data = NULL;\n\n\tswitch (x->xso.type) {\n\tcase XFRM_DEV_OFFLOAD_CRYPTO:\n\t\tif (!(x->props.flags & XFRM_STATE_ESN))\n\t\t\treturn 0;\n\t\tbreak;\n\tcase XFRM_DEV_OFFLOAD_PACKET:\n\t\tif (x->props.mode != XFRM_MODE_TUNNEL)\n\t\t\treturn 0;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\twork = kzalloc(sizeof(*work), GFP_KERNEL);\n\tif (!work)\n\t\treturn -ENOMEM;\n\n\tswitch (x->xso.type) {\n\tcase XFRM_DEV_OFFLOAD_CRYPTO:\n\t\tdata = kzalloc(sizeof(*sa_entry), GFP_KERNEL);\n\t\tif (!data)\n\t\t\tgoto free_work;\n\n\t\tINIT_WORK(&work->work, mlx5e_ipsec_modify_state);\n\t\tbreak;\n\tcase XFRM_DEV_OFFLOAD_PACKET:\n\t\tdata = kzalloc(sizeof(struct mlx5e_ipsec_netevent_data),\n\t\t\t       GFP_KERNEL);\n\t\tif (!data)\n\t\t\tgoto free_work;\n\n\t\tINIT_WORK(&work->work, mlx5e_ipsec_handle_netdev_event);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\twork->data = data;\n\twork->sa_entry = sa_entry;\n\tsa_entry->work = work;\n\treturn 0;\n\nfree_work:\n\tkfree(work);\n\treturn -ENOMEM;\n}\n\nstatic int mlx5e_ipsec_create_dwork(struct mlx5e_ipsec_sa_entry *sa_entry)\n{\n\tstruct xfrm_state *x = sa_entry->x;\n\tstruct mlx5e_ipsec_dwork *dwork;\n\n\tif (x->xso.type != XFRM_DEV_OFFLOAD_PACKET)\n\t\treturn 0;\n\n\tif (x->xso.dir != XFRM_DEV_OFFLOAD_OUT)\n\t\treturn 0;\n\n\tif (x->lft.soft_packet_limit == XFRM_INF &&\n\t    x->lft.hard_packet_limit == XFRM_INF)\n\t\treturn 0;\n\n\tdwork = kzalloc(sizeof(*dwork), GFP_KERNEL);\n\tif (!dwork)\n\t\treturn -ENOMEM;\n\n\tdwork->sa_entry = sa_entry;\n\tINIT_DELAYED_WORK(&dwork->dwork, mlx5e_ipsec_handle_tx_limit);\n\tsa_entry->dwork = dwork;\n\treturn 0;\n}\n\nstatic int mlx5e_xfrm_add_state(struct xfrm_state *x,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = NULL;\n\tstruct net_device *netdev = x->xso.real_dev;\n\tstruct mlx5e_ipsec *ipsec;\n\tstruct mlx5e_priv *priv;\n\tgfp_t gfp;\n\tint err;\n\n\tpriv = netdev_priv(netdev);\n\tif (!priv->ipsec)\n\t\treturn -EOPNOTSUPP;\n\n\tipsec = priv->ipsec;\n\tgfp = (x->xso.flags & XFRM_DEV_OFFLOAD_FLAG_ACQ) ? GFP_ATOMIC : GFP_KERNEL;\n\tsa_entry = kzalloc(sizeof(*sa_entry), gfp);\n\tif (!sa_entry)\n\t\treturn -ENOMEM;\n\n\tsa_entry->x = x;\n\tsa_entry->ipsec = ipsec;\n\t \n\tif (x->xso.flags & XFRM_DEV_OFFLOAD_FLAG_ACQ)\n\t\tgoto out;\n\n\terr = mlx5e_xfrm_validate_state(priv->mdev, x, extack);\n\tif (err)\n\t\tgoto err_xfrm;\n\n\tif (!mlx5_eswitch_block_ipsec(priv->mdev)) {\n\t\terr = -EBUSY;\n\t\tgoto err_xfrm;\n\t}\n\n\t \n\tif (x->props.flags & XFRM_STATE_ESN)\n\t\tmlx5e_ipsec_update_esn_state(sa_entry);\n\n\tmlx5e_ipsec_build_accel_xfrm_attrs(sa_entry, &sa_entry->attrs);\n\n\terr = mlx5_ipsec_create_work(sa_entry);\n\tif (err)\n\t\tgoto unblock_ipsec;\n\n\terr = mlx5e_ipsec_create_dwork(sa_entry);\n\tif (err)\n\t\tgoto release_work;\n\n\t \n\terr = mlx5_ipsec_create_sa_ctx(sa_entry);\n\tif (err)\n\t\tgoto release_dwork;\n\n\terr = mlx5e_accel_ipsec_fs_add_rule(sa_entry);\n\tif (err)\n\t\tgoto err_hw_ctx;\n\n\tif (x->props.mode == XFRM_MODE_TUNNEL &&\n\t    x->xso.type == XFRM_DEV_OFFLOAD_PACKET &&\n\t    !mlx5e_ipsec_fs_tunnel_enabled(sa_entry)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Packet offload tunnel mode is disabled due to encap settings\");\n\t\terr = -EINVAL;\n\t\tgoto err_add_rule;\n\t}\n\n\t \n\terr = xa_insert_bh(&ipsec->sadb, sa_entry->ipsec_obj_id, sa_entry,\n\t\t\t   GFP_KERNEL);\n\tif (err)\n\t\tgoto err_add_rule;\n\n\tmlx5e_ipsec_set_esn_ops(sa_entry);\n\n\tif (sa_entry->dwork)\n\t\tqueue_delayed_work(ipsec->wq, &sa_entry->dwork->dwork,\n\t\t\t\t   MLX5_IPSEC_RESCHED);\n\n\tif (x->xso.type == XFRM_DEV_OFFLOAD_PACKET &&\n\t    x->props.mode == XFRM_MODE_TUNNEL)\n\t\txa_set_mark(&ipsec->sadb, sa_entry->ipsec_obj_id,\n\t\t\t    MLX5E_IPSEC_TUNNEL_SA);\n\nout:\n\tx->xso.offload_handle = (unsigned long)sa_entry;\n\treturn 0;\n\nerr_add_rule:\n\tmlx5e_accel_ipsec_fs_del_rule(sa_entry);\nerr_hw_ctx:\n\tmlx5_ipsec_free_sa_ctx(sa_entry);\nrelease_dwork:\n\tkfree(sa_entry->dwork);\nrelease_work:\n\tif (sa_entry->work)\n\t\tkfree(sa_entry->work->data);\n\tkfree(sa_entry->work);\nunblock_ipsec:\n\tmlx5_eswitch_unblock_ipsec(priv->mdev);\nerr_xfrm:\n\tkfree(sa_entry);\n\tNL_SET_ERR_MSG_WEAK_MOD(extack, \"Device failed to offload this state\");\n\treturn err;\n}\n\nstatic void mlx5e_xfrm_del_state(struct xfrm_state *x)\n{\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = to_ipsec_sa_entry(x);\n\tstruct mlx5_accel_esp_xfrm_attrs *attrs = &sa_entry->attrs;\n\tstruct mlx5e_ipsec *ipsec = sa_entry->ipsec;\n\tstruct mlx5e_ipsec_sa_entry *old;\n\n\tif (x->xso.flags & XFRM_DEV_OFFLOAD_FLAG_ACQ)\n\t\treturn;\n\n\told = xa_erase_bh(&ipsec->sadb, sa_entry->ipsec_obj_id);\n\tWARN_ON(old != sa_entry);\n\n\tif (attrs->mode == XFRM_MODE_TUNNEL &&\n\t    attrs->type == XFRM_DEV_OFFLOAD_PACKET)\n\t\t \n\t\tflush_workqueue(ipsec->wq);\n\n}\n\nstatic void mlx5e_xfrm_free_state(struct xfrm_state *x)\n{\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = to_ipsec_sa_entry(x);\n\tstruct mlx5e_ipsec *ipsec = sa_entry->ipsec;\n\n\tif (x->xso.flags & XFRM_DEV_OFFLOAD_FLAG_ACQ)\n\t\tgoto sa_entry_free;\n\n\tif (sa_entry->work)\n\t\tcancel_work_sync(&sa_entry->work->work);\n\n\tif (sa_entry->dwork)\n\t\tcancel_delayed_work_sync(&sa_entry->dwork->dwork);\n\n\tmlx5e_accel_ipsec_fs_del_rule(sa_entry);\n\tmlx5_ipsec_free_sa_ctx(sa_entry);\n\tkfree(sa_entry->dwork);\n\tif (sa_entry->work)\n\t\tkfree(sa_entry->work->data);\n\tkfree(sa_entry->work);\n\tmlx5_eswitch_unblock_ipsec(ipsec->mdev);\nsa_entry_free:\n\tkfree(sa_entry);\n}\n\nstatic int mlx5e_ipsec_netevent_event(struct notifier_block *nb,\n\t\t\t\t      unsigned long event, void *ptr)\n{\n\tstruct mlx5_accel_esp_xfrm_attrs *attrs;\n\tstruct mlx5e_ipsec_netevent_data *data;\n\tstruct mlx5e_ipsec_sa_entry *sa_entry;\n\tstruct mlx5e_ipsec *ipsec;\n\tstruct neighbour *n = ptr;\n\tstruct net_device *netdev;\n\tstruct xfrm_state *x;\n\tunsigned long idx;\n\n\tif (event != NETEVENT_NEIGH_UPDATE || !(n->nud_state & NUD_VALID))\n\t\treturn NOTIFY_DONE;\n\n\tipsec = container_of(nb, struct mlx5e_ipsec, netevent_nb);\n\txa_for_each_marked(&ipsec->sadb, idx, sa_entry, MLX5E_IPSEC_TUNNEL_SA) {\n\t\tattrs = &sa_entry->attrs;\n\n\t\tif (attrs->family == AF_INET) {\n\t\t\tif (!neigh_key_eq32(n, &attrs->saddr.a4) &&\n\t\t\t    !neigh_key_eq32(n, &attrs->daddr.a4))\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tif (!neigh_key_eq128(n, &attrs->saddr.a4) &&\n\t\t\t    !neigh_key_eq128(n, &attrs->daddr.a4))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tx = sa_entry->x;\n\t\tnetdev = x->xso.real_dev;\n\t\tdata = sa_entry->work->data;\n\n\t\tneigh_ha_snapshot(data->addr, n, netdev);\n\t\tqueue_work(ipsec->wq, &sa_entry->work->work);\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\nvoid mlx5e_ipsec_init(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_ipsec *ipsec;\n\tint ret = -ENOMEM;\n\n\tif (!mlx5_ipsec_device_caps(priv->mdev)) {\n\t\tnetdev_dbg(priv->netdev, \"Not an IPSec offload device\\n\");\n\t\treturn;\n\t}\n\n\tipsec = kzalloc(sizeof(*ipsec), GFP_KERNEL);\n\tif (!ipsec)\n\t\treturn;\n\n\txa_init_flags(&ipsec->sadb, XA_FLAGS_ALLOC);\n\tipsec->mdev = priv->mdev;\n\tipsec->wq = alloc_workqueue(\"mlx5e_ipsec: %s\", WQ_UNBOUND, 0,\n\t\t\t\t    priv->netdev->name);\n\tif (!ipsec->wq)\n\t\tgoto err_wq;\n\n\tif (mlx5_ipsec_device_caps(priv->mdev) &\n\t    MLX5_IPSEC_CAP_PACKET_OFFLOAD) {\n\t\tret = mlx5e_ipsec_aso_init(ipsec);\n\t\tif (ret)\n\t\t\tgoto err_aso;\n\t}\n\n\tif (mlx5_ipsec_device_caps(priv->mdev) & MLX5_IPSEC_CAP_TUNNEL) {\n\t\tipsec->netevent_nb.notifier_call = mlx5e_ipsec_netevent_event;\n\t\tret = register_netevent_notifier(&ipsec->netevent_nb);\n\t\tif (ret)\n\t\t\tgoto clear_aso;\n\t}\n\n\tipsec->is_uplink_rep = mlx5e_is_uplink_rep(priv);\n\tret = mlx5e_accel_ipsec_fs_init(ipsec);\n\tif (ret)\n\t\tgoto err_fs_init;\n\n\tipsec->fs = priv->fs;\n\tpriv->ipsec = ipsec;\n\tnetdev_dbg(priv->netdev, \"IPSec attached to netdevice\\n\");\n\treturn;\n\nerr_fs_init:\n\tif (mlx5_ipsec_device_caps(priv->mdev) & MLX5_IPSEC_CAP_TUNNEL)\n\t\tunregister_netevent_notifier(&ipsec->netevent_nb);\nclear_aso:\n\tif (mlx5_ipsec_device_caps(priv->mdev) & MLX5_IPSEC_CAP_PACKET_OFFLOAD)\n\t\tmlx5e_ipsec_aso_cleanup(ipsec);\nerr_aso:\n\tdestroy_workqueue(ipsec->wq);\nerr_wq:\n\tkfree(ipsec);\n\tmlx5_core_err(priv->mdev, \"IPSec initialization failed, %d\\n\", ret);\n\treturn;\n}\n\nvoid mlx5e_ipsec_cleanup(struct mlx5e_priv *priv)\n{\n\tstruct mlx5e_ipsec *ipsec = priv->ipsec;\n\n\tif (!ipsec)\n\t\treturn;\n\n\tmlx5e_accel_ipsec_fs_cleanup(ipsec);\n\tif (ipsec->netevent_nb.notifier_call) {\n\t\tunregister_netevent_notifier(&ipsec->netevent_nb);\n\t\tipsec->netevent_nb.notifier_call = NULL;\n\t}\n\tif (ipsec->aso)\n\t\tmlx5e_ipsec_aso_cleanup(ipsec);\n\tdestroy_workqueue(ipsec->wq);\n\tkfree(ipsec);\n\tpriv->ipsec = NULL;\n}\n\nstatic bool mlx5e_ipsec_offload_ok(struct sk_buff *skb, struct xfrm_state *x)\n{\n\tif (x->props.family == AF_INET) {\n\t\t \n\t\tif (ip_hdr(skb)->ihl > 5)\n\t\t\treturn false;\n\t} else {\n\t\t \n\t\tif (ipv6_ext_hdr(ipv6_hdr(skb)->nexthdr))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void mlx5e_xfrm_advance_esn_state(struct xfrm_state *x)\n{\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = to_ipsec_sa_entry(x);\n\tstruct mlx5e_ipsec_work *work = sa_entry->work;\n\tstruct mlx5e_ipsec_sa_entry *sa_entry_shadow;\n\tbool need_update;\n\n\tneed_update = mlx5e_ipsec_update_esn_state(sa_entry);\n\tif (!need_update)\n\t\treturn;\n\n\tsa_entry_shadow = work->data;\n\tmemset(sa_entry_shadow, 0x00, sizeof(*sa_entry_shadow));\n\tmlx5e_ipsec_build_accel_xfrm_attrs(sa_entry, &sa_entry_shadow->attrs);\n\tqueue_work(sa_entry->ipsec->wq, &work->work);\n}\n\nstatic void mlx5e_xfrm_update_curlft(struct xfrm_state *x)\n{\n\tstruct mlx5e_ipsec_sa_entry *sa_entry = to_ipsec_sa_entry(x);\n\tstruct mlx5e_ipsec_rule *ipsec_rule = &sa_entry->ipsec_rule;\n\tu64 packets, bytes, lastuse;\n\n\tlockdep_assert(lockdep_is_held(&x->lock) ||\n\t\t       lockdep_is_held(&dev_net(x->xso.real_dev)->xfrm.xfrm_cfg_mutex));\n\n\tif (x->xso.flags & XFRM_DEV_OFFLOAD_FLAG_ACQ)\n\t\treturn;\n\n\tmlx5_fc_query_cached(ipsec_rule->fc, &bytes, &packets, &lastuse);\n\tx->curlft.packets += packets;\n\tx->curlft.bytes += bytes;\n}\n\nstatic int mlx5e_xfrm_validate_policy(struct mlx5_core_dev *mdev,\n\t\t\t\t      struct xfrm_policy *x,\n\t\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct xfrm_selector *sel = &x->selector;\n\n\tif (x->type != XFRM_POLICY_TYPE_MAIN) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload non-main policy types\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (x->xfrm_nr > 1) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload more than one template\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (x->xdo.dir != XFRM_DEV_OFFLOAD_IN &&\n\t    x->xdo.dir != XFRM_DEV_OFFLOAD_OUT) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot offload forward policy\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!x->xfrm_vec[0].reqid && sel->proto == IPPROTO_IP &&\n\t    addr6_all_zero(sel->saddr.a6) && addr6_all_zero(sel->daddr.a6)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported policy with reqid 0 without at least one of upper protocol or ip addr(s) different than 0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (x->xdo.type != XFRM_DEV_OFFLOAD_PACKET) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported xfrm offload type\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (x->selector.proto != IPPROTO_IP &&\n\t    x->selector.proto != IPPROTO_UDP &&\n\t    x->selector.proto != IPPROTO_TCP) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Device does not support upper protocol other than TCP/UDP\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (x->priority) {\n\t\tif (!(mlx5_ipsec_device_caps(mdev) & MLX5_IPSEC_CAP_PRIO)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Device does not support policy priority\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (x->priority == U32_MAX) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Device does not support requested policy priority\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (x->xdo.type == XFRM_DEV_OFFLOAD_PACKET &&\n\t    !(mlx5_ipsec_device_caps(mdev) & MLX5_IPSEC_CAP_PACKET_OFFLOAD)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Packet offload is not supported\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void\nmlx5e_ipsec_build_accel_pol_attrs(struct mlx5e_ipsec_pol_entry *pol_entry,\n\t\t\t\t  struct mlx5_accel_pol_xfrm_attrs *attrs)\n{\n\tstruct xfrm_policy *x = pol_entry->x;\n\tstruct xfrm_selector *sel;\n\n\tsel = &x->selector;\n\tmemset(attrs, 0, sizeof(*attrs));\n\n\tmemcpy(&attrs->saddr, sel->saddr.a6, sizeof(attrs->saddr));\n\tmemcpy(&attrs->daddr, sel->daddr.a6, sizeof(attrs->daddr));\n\tattrs->family = sel->family;\n\tattrs->dir = x->xdo.dir;\n\tattrs->action = x->action;\n\tattrs->type = XFRM_DEV_OFFLOAD_PACKET;\n\tattrs->reqid = x->xfrm_vec[0].reqid;\n\tattrs->upspec.dport = ntohs(sel->dport);\n\tattrs->upspec.dport_mask = ntohs(sel->dport_mask);\n\tattrs->upspec.sport = ntohs(sel->sport);\n\tattrs->upspec.sport_mask = ntohs(sel->sport_mask);\n\tattrs->upspec.proto = sel->proto;\n\tattrs->prio = x->priority;\n}\n\nstatic int mlx5e_xfrm_add_policy(struct xfrm_policy *x,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct net_device *netdev = x->xdo.real_dev;\n\tstruct mlx5e_ipsec_pol_entry *pol_entry;\n\tstruct mlx5e_priv *priv;\n\tint err;\n\n\tpriv = netdev_priv(netdev);\n\tif (!priv->ipsec) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Device doesn't support IPsec packet offload\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\terr = mlx5e_xfrm_validate_policy(priv->mdev, x, extack);\n\tif (err)\n\t\treturn err;\n\n\tpol_entry = kzalloc(sizeof(*pol_entry), GFP_KERNEL);\n\tif (!pol_entry)\n\t\treturn -ENOMEM;\n\n\tpol_entry->x = x;\n\tpol_entry->ipsec = priv->ipsec;\n\n\tif (!mlx5_eswitch_block_ipsec(priv->mdev)) {\n\t\terr = -EBUSY;\n\t\tgoto ipsec_busy;\n\t}\n\n\tmlx5e_ipsec_build_accel_pol_attrs(pol_entry, &pol_entry->attrs);\n\terr = mlx5e_accel_ipsec_fs_add_pol(pol_entry);\n\tif (err)\n\t\tgoto err_fs;\n\n\tx->xdo.offload_handle = (unsigned long)pol_entry;\n\treturn 0;\n\nerr_fs:\n\tmlx5_eswitch_unblock_ipsec(priv->mdev);\nipsec_busy:\n\tkfree(pol_entry);\n\tNL_SET_ERR_MSG_MOD(extack, \"Device failed to offload this policy\");\n\treturn err;\n}\n\nstatic void mlx5e_xfrm_del_policy(struct xfrm_policy *x)\n{\n\tstruct mlx5e_ipsec_pol_entry *pol_entry = to_ipsec_pol_entry(x);\n\n\tmlx5e_accel_ipsec_fs_del_pol(pol_entry);\n\tmlx5_eswitch_unblock_ipsec(pol_entry->ipsec->mdev);\n}\n\nstatic void mlx5e_xfrm_free_policy(struct xfrm_policy *x)\n{\n\tstruct mlx5e_ipsec_pol_entry *pol_entry = to_ipsec_pol_entry(x);\n\n\tkfree(pol_entry);\n}\n\nstatic const struct xfrmdev_ops mlx5e_ipsec_xfrmdev_ops = {\n\t.xdo_dev_state_add\t= mlx5e_xfrm_add_state,\n\t.xdo_dev_state_delete\t= mlx5e_xfrm_del_state,\n\t.xdo_dev_state_free\t= mlx5e_xfrm_free_state,\n\t.xdo_dev_offload_ok\t= mlx5e_ipsec_offload_ok,\n\t.xdo_dev_state_advance_esn = mlx5e_xfrm_advance_esn_state,\n\n\t.xdo_dev_state_update_curlft = mlx5e_xfrm_update_curlft,\n\t.xdo_dev_policy_add = mlx5e_xfrm_add_policy,\n\t.xdo_dev_policy_delete = mlx5e_xfrm_del_policy,\n\t.xdo_dev_policy_free = mlx5e_xfrm_free_policy,\n};\n\nvoid mlx5e_ipsec_build_netdev(struct mlx5e_priv *priv)\n{\n\tstruct mlx5_core_dev *mdev = priv->mdev;\n\tstruct net_device *netdev = priv->netdev;\n\n\tif (!mlx5_ipsec_device_caps(mdev))\n\t\treturn;\n\n\tmlx5_core_info(mdev, \"mlx5e: IPSec ESP acceleration enabled\\n\");\n\n\tnetdev->xfrmdev_ops = &mlx5e_ipsec_xfrmdev_ops;\n\tnetdev->features |= NETIF_F_HW_ESP;\n\tnetdev->hw_enc_features |= NETIF_F_HW_ESP;\n\n\tif (!MLX5_CAP_ETH(mdev, swp_csum)) {\n\t\tmlx5_core_dbg(mdev, \"mlx5e: SWP checksum not supported\\n\");\n\t\treturn;\n\t}\n\n\tnetdev->features |= NETIF_F_HW_ESP_TX_CSUM;\n\tnetdev->hw_enc_features |= NETIF_F_HW_ESP_TX_CSUM;\n\n\tif (!MLX5_CAP_ETH(mdev, swp_lso)) {\n\t\tmlx5_core_dbg(mdev, \"mlx5e: ESP LSO not supported\\n\");\n\t\treturn;\n\t}\n\n\tnetdev->gso_partial_features |= NETIF_F_GSO_ESP;\n\tmlx5_core_dbg(mdev, \"mlx5e: ESP GSO capability turned on\\n\");\n\tnetdev->features |= NETIF_F_GSO_ESP;\n\tnetdev->hw_features |= NETIF_F_GSO_ESP;\n\tnetdev->hw_enc_features |= NETIF_F_GSO_ESP;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}