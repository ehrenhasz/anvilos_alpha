{
  "module_name": "uar.c",
  "hash_id": "169884820274f919de3e2d0c55f0d939a885f047912a90cf0ef8756f067808f4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/uar.c",
  "human_readable_source": " \n\n#include <linux/kernel.h>\n#include <linux/mlx5/driver.h>\n#include \"mlx5_core.h\"\n\nstatic int mlx5_cmd_alloc_uar(struct mlx5_core_dev *dev, u32 *uarn)\n{\n\tu32 out[MLX5_ST_SZ_DW(alloc_uar_out)] = {};\n\tu32 in[MLX5_ST_SZ_DW(alloc_uar_in)] = {};\n\tint err;\n\n\tMLX5_SET(alloc_uar_in, in, opcode, MLX5_CMD_OP_ALLOC_UAR);\n\terr = mlx5_cmd_exec_inout(dev, alloc_uar, in, out);\n\tif (err)\n\t\treturn err;\n\n\t*uarn = MLX5_GET(alloc_uar_out, out, uar);\n\treturn 0;\n}\n\nstatic int mlx5_cmd_free_uar(struct mlx5_core_dev *dev, u32 uarn)\n{\n\tu32 in[MLX5_ST_SZ_DW(dealloc_uar_in)] = {};\n\n\tMLX5_SET(dealloc_uar_in, in, opcode, MLX5_CMD_OP_DEALLOC_UAR);\n\tMLX5_SET(dealloc_uar_in, in, uar, uarn);\n\treturn mlx5_cmd_exec_in(dev, dealloc_uar, in);\n}\n\nstatic int uars_per_sys_page(struct mlx5_core_dev *mdev)\n{\n\tif (MLX5_CAP_GEN(mdev, uar_4k))\n\t\treturn MLX5_CAP_GEN(mdev, num_of_uars_per_page);\n\n\treturn 1;\n}\n\nstatic u64 uar2pfn(struct mlx5_core_dev *mdev, u32 index)\n{\n\tu32 system_page_index;\n\n\tif (MLX5_CAP_GEN(mdev, uar_4k))\n\t\tsystem_page_index = index >> (PAGE_SHIFT - MLX5_ADAPTER_PAGE_SHIFT);\n\telse\n\t\tsystem_page_index = index;\n\n\treturn (mdev->bar_addr >> PAGE_SHIFT) + system_page_index;\n}\n\nstatic void up_rel_func(struct kref *kref)\n{\n\tstruct mlx5_uars_page *up = container_of(kref, struct mlx5_uars_page, ref_count);\n\n\tlist_del(&up->list);\n\tiounmap(up->map);\n\tif (mlx5_cmd_free_uar(up->mdev, up->index))\n\t\tmlx5_core_warn(up->mdev, \"failed to free uar index %d\\n\", up->index);\n\tbitmap_free(up->reg_bitmap);\n\tbitmap_free(up->fp_bitmap);\n\tkfree(up);\n}\n\nstatic struct mlx5_uars_page *alloc_uars_page(struct mlx5_core_dev *mdev,\n\t\t\t\t\t      bool map_wc)\n{\n\tstruct mlx5_uars_page *up;\n\tint err = -ENOMEM;\n\tphys_addr_t pfn;\n\tint bfregs;\n\tint node;\n\tint i;\n\n\tbfregs = uars_per_sys_page(mdev) * MLX5_BFREGS_PER_UAR;\n\tnode = mdev->priv.numa_node;\n\tup = kzalloc_node(sizeof(*up), GFP_KERNEL, node);\n\tif (!up)\n\t\treturn ERR_PTR(err);\n\n\tup->mdev = mdev;\n\tup->reg_bitmap = bitmap_zalloc_node(bfregs, GFP_KERNEL, node);\n\tif (!up->reg_bitmap)\n\t\tgoto error1;\n\n\tup->fp_bitmap = bitmap_zalloc_node(bfregs, GFP_KERNEL, node);\n\tif (!up->fp_bitmap)\n\t\tgoto error1;\n\n\tfor (i = 0; i < bfregs; i++)\n\t\tif ((i % MLX5_BFREGS_PER_UAR) < MLX5_NON_FP_BFREGS_PER_UAR)\n\t\t\tset_bit(i, up->reg_bitmap);\n\t\telse\n\t\t\tset_bit(i, up->fp_bitmap);\n\n\tup->bfregs = bfregs;\n\tup->fp_avail = bfregs * MLX5_FP_BFREGS_PER_UAR / MLX5_BFREGS_PER_UAR;\n\tup->reg_avail = bfregs * MLX5_NON_FP_BFREGS_PER_UAR / MLX5_BFREGS_PER_UAR;\n\n\terr = mlx5_cmd_alloc_uar(mdev, &up->index);\n\tif (err) {\n\t\tmlx5_core_warn(mdev, \"mlx5_cmd_alloc_uar() failed, %d\\n\", err);\n\t\tgoto error1;\n\t}\n\n\tpfn = uar2pfn(mdev, up->index);\n\tif (map_wc) {\n\t\tup->map = ioremap_wc(pfn << PAGE_SHIFT, PAGE_SIZE);\n\t\tif (!up->map) {\n\t\t\terr = -EAGAIN;\n\t\t\tgoto error2;\n\t\t}\n\t} else {\n\t\tup->map = ioremap(pfn << PAGE_SHIFT, PAGE_SIZE);\n\t\tif (!up->map) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto error2;\n\t\t}\n\t}\n\tkref_init(&up->ref_count);\n\tmlx5_core_dbg(mdev, \"allocated UAR page: index %d, total bfregs %d\\n\",\n\t\t      up->index, up->bfregs);\n\treturn up;\n\nerror2:\n\tif (mlx5_cmd_free_uar(mdev, up->index))\n\t\tmlx5_core_warn(mdev, \"failed to free uar index %d\\n\", up->index);\nerror1:\n\tbitmap_free(up->fp_bitmap);\n\tbitmap_free(up->reg_bitmap);\n\tkfree(up);\n\treturn ERR_PTR(err);\n}\n\nstruct mlx5_uars_page *mlx5_get_uars_page(struct mlx5_core_dev *mdev)\n{\n\tstruct mlx5_uars_page *ret;\n\n\tmutex_lock(&mdev->priv.bfregs.reg_head.lock);\n\tif (!list_empty(&mdev->priv.bfregs.reg_head.list)) {\n\t\tret = list_first_entry(&mdev->priv.bfregs.reg_head.list,\n\t\t\t\t       struct mlx5_uars_page, list);\n\t\tkref_get(&ret->ref_count);\n\t\tgoto out;\n\t}\n\tret = alloc_uars_page(mdev, false);\n\tif (IS_ERR(ret))\n\t\tgoto out;\n\tlist_add(&ret->list, &mdev->priv.bfregs.reg_head.list);\nout:\n\tmutex_unlock(&mdev->priv.bfregs.reg_head.lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(mlx5_get_uars_page);\n\nvoid mlx5_put_uars_page(struct mlx5_core_dev *mdev, struct mlx5_uars_page *up)\n{\n\tmutex_lock(&mdev->priv.bfregs.reg_head.lock);\n\tkref_put(&up->ref_count, up_rel_func);\n\tmutex_unlock(&mdev->priv.bfregs.reg_head.lock);\n}\nEXPORT_SYMBOL(mlx5_put_uars_page);\n\nstatic unsigned long map_offset(struct mlx5_core_dev *mdev, int dbi)\n{\n\t \n\treturn dbi / MLX5_BFREGS_PER_UAR * MLX5_ADAPTER_PAGE_SIZE +\n\t       (dbi % MLX5_BFREGS_PER_UAR) *\n\t       (1 << MLX5_CAP_GEN(mdev, log_bf_reg_size)) + MLX5_BF_OFFSET;\n}\n\nstatic int alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,\n\t\t       bool map_wc, bool fast_path)\n{\n\tstruct mlx5_bfreg_data *bfregs;\n\tstruct mlx5_uars_page *up;\n\tstruct list_head *head;\n\tunsigned long *bitmap;\n\tunsigned int *avail;\n\tstruct mutex *lock;   \n\tint dbi;\n\n\tbfregs = &mdev->priv.bfregs;\n\tif (map_wc) {\n\t\thead = &bfregs->wc_head.list;\n\t\tlock = &bfregs->wc_head.lock;\n\t} else {\n\t\thead = &bfregs->reg_head.list;\n\t\tlock = &bfregs->reg_head.lock;\n\t}\n\tmutex_lock(lock);\n\tif (list_empty(head)) {\n\t\tup = alloc_uars_page(mdev, map_wc);\n\t\tif (IS_ERR(up)) {\n\t\t\tmutex_unlock(lock);\n\t\t\treturn PTR_ERR(up);\n\t\t}\n\t\tlist_add(&up->list, head);\n\t} else {\n\t\tup = list_entry(head->next, struct mlx5_uars_page, list);\n\t\tkref_get(&up->ref_count);\n\t}\n\tif (fast_path) {\n\t\tbitmap = up->fp_bitmap;\n\t\tavail = &up->fp_avail;\n\t} else {\n\t\tbitmap = up->reg_bitmap;\n\t\tavail = &up->reg_avail;\n\t}\n\tdbi = find_first_bit(bitmap, up->bfregs);\n\tclear_bit(dbi, bitmap);\n\t(*avail)--;\n\tif (!(*avail))\n\t\tlist_del(&up->list);\n\n\tbfreg->map = up->map + map_offset(mdev, dbi);\n\tbfreg->up = up;\n\tbfreg->wc = map_wc;\n\tbfreg->index = up->index + dbi / MLX5_BFREGS_PER_UAR;\n\tmutex_unlock(lock);\n\n\treturn 0;\n}\n\nint mlx5_alloc_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg,\n\t\t     bool map_wc, bool fast_path)\n{\n\tint err;\n\n\terr = alloc_bfreg(mdev, bfreg, map_wc, fast_path);\n\tif (!err)\n\t\treturn 0;\n\n\tif (err == -EAGAIN && map_wc)\n\t\treturn alloc_bfreg(mdev, bfreg, false, fast_path);\n\n\treturn err;\n}\nEXPORT_SYMBOL(mlx5_alloc_bfreg);\n\nstatic unsigned int addr_to_dbi_in_syspage(struct mlx5_core_dev *dev,\n\t\t\t\t\t   struct mlx5_uars_page *up,\n\t\t\t\t\t   struct mlx5_sq_bfreg *bfreg)\n{\n\tunsigned int uar_idx;\n\tunsigned int bfreg_idx;\n\tunsigned int bf_reg_size;\n\n\tbf_reg_size = 1 << MLX5_CAP_GEN(dev, log_bf_reg_size);\n\n\tuar_idx = (bfreg->map - up->map) >> MLX5_ADAPTER_PAGE_SHIFT;\n\tbfreg_idx = (((uintptr_t)bfreg->map % MLX5_ADAPTER_PAGE_SIZE) - MLX5_BF_OFFSET) / bf_reg_size;\n\n\treturn uar_idx * MLX5_BFREGS_PER_UAR + bfreg_idx;\n}\n\nvoid mlx5_free_bfreg(struct mlx5_core_dev *mdev, struct mlx5_sq_bfreg *bfreg)\n{\n\tstruct mlx5_bfreg_data *bfregs;\n\tstruct mlx5_uars_page *up;\n\tstruct mutex *lock;  \n\tunsigned int dbi;\n\tbool fp;\n\tunsigned int *avail;\n\tunsigned long *bitmap;\n\tstruct list_head *head;\n\n\tbfregs = &mdev->priv.bfregs;\n\tif (bfreg->wc) {\n\t\thead = &bfregs->wc_head.list;\n\t\tlock = &bfregs->wc_head.lock;\n\t} else {\n\t\thead = &bfregs->reg_head.list;\n\t\tlock = &bfregs->reg_head.lock;\n\t}\n\tup = bfreg->up;\n\tdbi = addr_to_dbi_in_syspage(mdev, up, bfreg);\n\tfp = (dbi % MLX5_BFREGS_PER_UAR) >= MLX5_NON_FP_BFREGS_PER_UAR;\n\tif (fp) {\n\t\tavail = &up->fp_avail;\n\t\tbitmap = up->fp_bitmap;\n\t} else {\n\t\tavail = &up->reg_avail;\n\t\tbitmap = up->reg_bitmap;\n\t}\n\tmutex_lock(lock);\n\t(*avail)++;\n\tset_bit(dbi, bitmap);\n\tif (*avail == 1)\n\t\tlist_add_tail(&up->list, head);\n\n\tkref_put(&up->ref_count, up_rel_func);\n\tmutex_unlock(lock);\n}\nEXPORT_SYMBOL(mlx5_free_bfreg);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}