{
  "module_name": "qos.c",
  "hash_id": "4e65c31949a5de5d57f8d578f504a64c5fce1b7578c86906231a1d5e62997101",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/esw/qos.c",
  "human_readable_source": "\n \n\n#include \"eswitch.h\"\n#include \"esw/qos.h\"\n#include \"en/port.h\"\n#define CREATE_TRACE_POINTS\n#include \"diag/qos_tracepoint.h\"\n\n \n#define MLX5_MIN_BW_SHARE 1\n\n#define MLX5_RATE_TO_BW_SHARE(rate, divider, limit) \\\n\tmin_t(u32, max_t(u32, DIV_ROUND_UP(rate, divider), MLX5_MIN_BW_SHARE), limit)\n\nstruct mlx5_esw_rate_group {\n\tu32 tsar_ix;\n\tu32 max_rate;\n\tu32 min_rate;\n\tu32 bw_share;\n\tstruct list_head list;\n};\n\nstatic int esw_qos_tsar_config(struct mlx5_core_dev *dev, u32 *sched_ctx,\n\t\t\t       u32 tsar_ix, u32 max_rate, u32 bw_share)\n{\n\tu32 bitmask = 0;\n\n\tif (!MLX5_CAP_GEN(dev, qos) || !MLX5_CAP_QOS(dev, esw_scheduling))\n\t\treturn -EOPNOTSUPP;\n\n\tMLX5_SET(scheduling_context, sched_ctx, max_average_bw, max_rate);\n\tMLX5_SET(scheduling_context, sched_ctx, bw_share, bw_share);\n\tbitmask |= MODIFY_SCHEDULING_ELEMENT_IN_MODIFY_BITMASK_MAX_AVERAGE_BW;\n\tbitmask |= MODIFY_SCHEDULING_ELEMENT_IN_MODIFY_BITMASK_BW_SHARE;\n\n\treturn mlx5_modify_scheduling_element_cmd(dev,\n\t\t\t\t\t\t  SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t  sched_ctx,\n\t\t\t\t\t\t  tsar_ix,\n\t\t\t\t\t\t  bitmask);\n}\n\nstatic int esw_qos_group_config(struct mlx5_eswitch *esw, struct mlx5_esw_rate_group *group,\n\t\t\t\tu32 max_rate, u32 bw_share, struct netlink_ext_ack *extack)\n{\n\tu32 sched_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {};\n\tstruct mlx5_core_dev *dev = esw->dev;\n\tint err;\n\n\terr = esw_qos_tsar_config(dev, sched_ctx,\n\t\t\t\t  group->tsar_ix,\n\t\t\t\t  max_rate, bw_share);\n\tif (err)\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch modify group TSAR element failed\");\n\n\ttrace_mlx5_esw_group_qos_config(dev, group, group->tsar_ix, bw_share, max_rate);\n\n\treturn err;\n}\n\nstatic int esw_qos_vport_config(struct mlx5_eswitch *esw,\n\t\t\t\tstruct mlx5_vport *vport,\n\t\t\t\tu32 max_rate, u32 bw_share,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tu32 sched_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {};\n\tstruct mlx5_core_dev *dev = esw->dev;\n\tint err;\n\n\tif (!vport->qos.enabled)\n\t\treturn -EIO;\n\n\terr = esw_qos_tsar_config(dev, sched_ctx, vport->qos.esw_tsar_ix,\n\t\t\t\t  max_rate, bw_share);\n\tif (err) {\n\t\tesw_warn(esw->dev,\n\t\t\t \"E-Switch modify TSAR vport element failed (vport=%d,err=%d)\\n\",\n\t\t\t vport->vport, err);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch modify TSAR vport element failed\");\n\t\treturn err;\n\t}\n\n\ttrace_mlx5_esw_vport_qos_config(vport, bw_share, max_rate);\n\n\treturn 0;\n}\n\nstatic u32 esw_qos_calculate_min_rate_divider(struct mlx5_eswitch *esw,\n\t\t\t\t\t      struct mlx5_esw_rate_group *group,\n\t\t\t\t\t      bool group_level)\n{\n\tu32 fw_max_bw_share = MLX5_CAP_QOS(esw->dev, max_tsar_bw_share);\n\tstruct mlx5_vport *evport;\n\tu32 max_guarantee = 0;\n\tunsigned long i;\n\n\tif (group_level) {\n\t\tstruct mlx5_esw_rate_group *group;\n\n\t\tlist_for_each_entry(group, &esw->qos.groups, list) {\n\t\t\tif (group->min_rate < max_guarantee)\n\t\t\t\tcontinue;\n\t\t\tmax_guarantee = group->min_rate;\n\t\t}\n\t} else {\n\t\tmlx5_esw_for_each_vport(esw, i, evport) {\n\t\t\tif (!evport->enabled || !evport->qos.enabled ||\n\t\t\t    evport->qos.group != group || evport->qos.min_rate < max_guarantee)\n\t\t\t\tcontinue;\n\t\t\tmax_guarantee = evport->qos.min_rate;\n\t\t}\n\t}\n\n\tif (max_guarantee)\n\t\treturn max_t(u32, max_guarantee / fw_max_bw_share, 1);\n\n\t \n\tif (!group_level && !max_guarantee && group && group->bw_share)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic u32 esw_qos_calc_bw_share(u32 min_rate, u32 divider, u32 fw_max)\n{\n\tif (divider)\n\t\treturn MLX5_RATE_TO_BW_SHARE(min_rate, divider, fw_max);\n\n\treturn 0;\n}\n\nstatic int esw_qos_normalize_vports_min_rate(struct mlx5_eswitch *esw,\n\t\t\t\t\t     struct mlx5_esw_rate_group *group,\n\t\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tu32 fw_max_bw_share = MLX5_CAP_QOS(esw->dev, max_tsar_bw_share);\n\tu32 divider = esw_qos_calculate_min_rate_divider(esw, group, false);\n\tstruct mlx5_vport *evport;\n\tunsigned long i;\n\tu32 bw_share;\n\tint err;\n\n\tmlx5_esw_for_each_vport(esw, i, evport) {\n\t\tif (!evport->enabled || !evport->qos.enabled || evport->qos.group != group)\n\t\t\tcontinue;\n\t\tbw_share = esw_qos_calc_bw_share(evport->qos.min_rate, divider, fw_max_bw_share);\n\n\t\tif (bw_share == evport->qos.bw_share)\n\t\t\tcontinue;\n\n\t\terr = esw_qos_vport_config(esw, evport, evport->qos.max_rate, bw_share, extack);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tevport->qos.bw_share = bw_share;\n\t}\n\n\treturn 0;\n}\n\nstatic int esw_qos_normalize_groups_min_rate(struct mlx5_eswitch *esw, u32 divider,\n\t\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tu32 fw_max_bw_share = MLX5_CAP_QOS(esw->dev, max_tsar_bw_share);\n\tstruct mlx5_esw_rate_group *group;\n\tu32 bw_share;\n\tint err;\n\n\tlist_for_each_entry(group, &esw->qos.groups, list) {\n\t\tbw_share = esw_qos_calc_bw_share(group->min_rate, divider, fw_max_bw_share);\n\n\t\tif (bw_share == group->bw_share)\n\t\t\tcontinue;\n\n\t\terr = esw_qos_group_config(esw, group, group->max_rate, bw_share, extack);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tgroup->bw_share = bw_share;\n\n\t\t \n\t\terr = esw_qos_normalize_vports_min_rate(esw, group, extack);\n\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int esw_qos_set_vport_min_rate(struct mlx5_eswitch *esw, struct mlx5_vport *evport,\n\t\t\t\t      u32 min_rate, struct netlink_ext_ack *extack)\n{\n\tu32 fw_max_bw_share, previous_min_rate;\n\tbool min_rate_supported;\n\tint err;\n\n\tlockdep_assert_held(&esw->state_lock);\n\tfw_max_bw_share = MLX5_CAP_QOS(esw->dev, max_tsar_bw_share);\n\tmin_rate_supported = MLX5_CAP_QOS(esw->dev, esw_bw_share) &&\n\t\t\t\tfw_max_bw_share >= MLX5_MIN_BW_SHARE;\n\tif (min_rate && !min_rate_supported)\n\t\treturn -EOPNOTSUPP;\n\tif (min_rate == evport->qos.min_rate)\n\t\treturn 0;\n\n\tprevious_min_rate = evport->qos.min_rate;\n\tevport->qos.min_rate = min_rate;\n\terr = esw_qos_normalize_vports_min_rate(esw, evport->qos.group, extack);\n\tif (err)\n\t\tevport->qos.min_rate = previous_min_rate;\n\n\treturn err;\n}\n\nstatic int esw_qos_set_vport_max_rate(struct mlx5_eswitch *esw, struct mlx5_vport *evport,\n\t\t\t\t      u32 max_rate, struct netlink_ext_ack *extack)\n{\n\tu32 act_max_rate = max_rate;\n\tbool max_rate_supported;\n\tint err;\n\n\tlockdep_assert_held(&esw->state_lock);\n\tmax_rate_supported = MLX5_CAP_QOS(esw->dev, esw_rate_limit);\n\n\tif (max_rate && !max_rate_supported)\n\t\treturn -EOPNOTSUPP;\n\tif (max_rate == evport->qos.max_rate)\n\t\treturn 0;\n\n\t \n\tif (evport->qos.group && !max_rate)\n\t\tact_max_rate = evport->qos.group->max_rate;\n\n\terr = esw_qos_vport_config(esw, evport, act_max_rate, evport->qos.bw_share, extack);\n\n\tif (!err)\n\t\tevport->qos.max_rate = max_rate;\n\n\treturn err;\n}\n\nstatic int esw_qos_set_group_min_rate(struct mlx5_eswitch *esw, struct mlx5_esw_rate_group *group,\n\t\t\t\t      u32 min_rate, struct netlink_ext_ack *extack)\n{\n\tu32 fw_max_bw_share = MLX5_CAP_QOS(esw->dev, max_tsar_bw_share);\n\tstruct mlx5_core_dev *dev = esw->dev;\n\tu32 previous_min_rate, divider;\n\tint err;\n\n\tif (!(MLX5_CAP_QOS(dev, esw_bw_share) && fw_max_bw_share >= MLX5_MIN_BW_SHARE))\n\t\treturn -EOPNOTSUPP;\n\n\tif (min_rate == group->min_rate)\n\t\treturn 0;\n\n\tprevious_min_rate = group->min_rate;\n\tgroup->min_rate = min_rate;\n\tdivider = esw_qos_calculate_min_rate_divider(esw, group, true);\n\terr = esw_qos_normalize_groups_min_rate(esw, divider, extack);\n\tif (err) {\n\t\tgroup->min_rate = previous_min_rate;\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch group min rate setting failed\");\n\n\t\t \n\t\tdivider = esw_qos_calculate_min_rate_divider(esw, group, true);\n\t\tif (esw_qos_normalize_groups_min_rate(esw, divider, extack))\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch BW share restore failed\");\n\t}\n\n\treturn err;\n}\n\nstatic int esw_qos_set_group_max_rate(struct mlx5_eswitch *esw,\n\t\t\t\t      struct mlx5_esw_rate_group *group,\n\t\t\t\t      u32 max_rate, struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_vport *vport;\n\tunsigned long i;\n\tint err;\n\n\tif (group->max_rate == max_rate)\n\t\treturn 0;\n\n\terr = esw_qos_group_config(esw, group, max_rate, group->bw_share, extack);\n\tif (err)\n\t\treturn err;\n\n\tgroup->max_rate = max_rate;\n\n\t \n\tmlx5_esw_for_each_vport(esw, i, vport) {\n\t\tif (!vport->enabled || !vport->qos.enabled ||\n\t\t    vport->qos.group != group || vport->qos.max_rate)\n\t\t\tcontinue;\n\n\t\terr = esw_qos_vport_config(esw, vport, max_rate, vport->qos.bw_share, extack);\n\t\tif (err)\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"E-Switch vport implicit rate limit setting failed\");\n\t}\n\n\treturn err;\n}\n\nstatic int esw_qos_vport_create_sched_element(struct mlx5_eswitch *esw,\n\t\t\t\t\t      struct mlx5_vport *vport,\n\t\t\t\t\t      u32 max_rate, u32 bw_share)\n{\n\tu32 sched_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {};\n\tstruct mlx5_esw_rate_group *group = vport->qos.group;\n\tstruct mlx5_core_dev *dev = esw->dev;\n\tu32 parent_tsar_ix;\n\tvoid *vport_elem;\n\tint err;\n\n\tparent_tsar_ix = group ? group->tsar_ix : esw->qos.root_tsar_ix;\n\tMLX5_SET(scheduling_context, sched_ctx, element_type,\n\t\t SCHEDULING_CONTEXT_ELEMENT_TYPE_VPORT);\n\tvport_elem = MLX5_ADDR_OF(scheduling_context, sched_ctx, element_attributes);\n\tMLX5_SET(vport_element, vport_elem, vport_number, vport->vport);\n\tMLX5_SET(scheduling_context, sched_ctx, parent_element_id, parent_tsar_ix);\n\tMLX5_SET(scheduling_context, sched_ctx, max_average_bw, max_rate);\n\tMLX5_SET(scheduling_context, sched_ctx, bw_share, bw_share);\n\n\terr = mlx5_create_scheduling_element_cmd(dev,\n\t\t\t\t\t\t SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t sched_ctx,\n\t\t\t\t\t\t &vport->qos.esw_tsar_ix);\n\tif (err) {\n\t\tesw_warn(esw->dev, \"E-Switch create TSAR vport element failed (vport=%d,err=%d)\\n\",\n\t\t\t vport->vport, err);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int esw_qos_update_group_scheduling_element(struct mlx5_eswitch *esw,\n\t\t\t\t\t\t   struct mlx5_vport *vport,\n\t\t\t\t\t\t   struct mlx5_esw_rate_group *curr_group,\n\t\t\t\t\t\t   struct mlx5_esw_rate_group *new_group,\n\t\t\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tu32 max_rate;\n\tint err;\n\n\terr = mlx5_destroy_scheduling_element_cmd(esw->dev,\n\t\t\t\t\t\t  SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t  vport->qos.esw_tsar_ix);\n\tif (err) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch destroy TSAR vport element failed\");\n\t\treturn err;\n\t}\n\n\tvport->qos.group = new_group;\n\tmax_rate = vport->qos.max_rate ? vport->qos.max_rate : new_group->max_rate;\n\n\t \n\terr = esw_qos_vport_create_sched_element(esw, vport, max_rate, vport->qos.bw_share);\n\tif (err) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch vport group set failed.\");\n\t\tgoto err_sched;\n\t}\n\n\treturn 0;\n\nerr_sched:\n\tvport->qos.group = curr_group;\n\tmax_rate = vport->qos.max_rate ? vport->qos.max_rate : curr_group->max_rate;\n\tif (esw_qos_vport_create_sched_element(esw, vport, max_rate, vport->qos.bw_share))\n\t\tesw_warn(esw->dev, \"E-Switch vport group restore failed (vport=%d)\\n\",\n\t\t\t vport->vport);\n\n\treturn err;\n}\n\nstatic int esw_qos_vport_update_group(struct mlx5_eswitch *esw,\n\t\t\t\t      struct mlx5_vport *vport,\n\t\t\t\t      struct mlx5_esw_rate_group *group,\n\t\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_esw_rate_group *new_group, *curr_group;\n\tint err;\n\n\tif (!vport->enabled)\n\t\treturn -EINVAL;\n\n\tcurr_group = vport->qos.group;\n\tnew_group = group ?: esw->qos.group0;\n\tif (curr_group == new_group)\n\t\treturn 0;\n\n\terr = esw_qos_update_group_scheduling_element(esw, vport, curr_group, new_group, extack);\n\tif (err)\n\t\treturn err;\n\n\t \n\tif (vport->qos.bw_share || new_group->bw_share) {\n\t\tesw_qos_normalize_vports_min_rate(esw, curr_group, extack);\n\t\tesw_qos_normalize_vports_min_rate(esw, new_group, extack);\n\t}\n\n\treturn 0;\n}\n\nstatic struct mlx5_esw_rate_group *\n__esw_qos_create_rate_group(struct mlx5_eswitch *esw, struct netlink_ext_ack *extack)\n{\n\tu32 tsar_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {};\n\tstruct mlx5_esw_rate_group *group;\n\tu32 divider;\n\tint err;\n\n\tgroup = kzalloc(sizeof(*group), GFP_KERNEL);\n\tif (!group)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tMLX5_SET(scheduling_context, tsar_ctx, parent_element_id,\n\t\t esw->qos.root_tsar_ix);\n\terr = mlx5_create_scheduling_element_cmd(esw->dev,\n\t\t\t\t\t\t SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t tsar_ctx,\n\t\t\t\t\t\t &group->tsar_ix);\n\tif (err) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch create TSAR for group failed\");\n\t\tgoto err_sched_elem;\n\t}\n\n\tlist_add_tail(&group->list, &esw->qos.groups);\n\n\tdivider = esw_qos_calculate_min_rate_divider(esw, group, true);\n\tif (divider) {\n\t\terr = esw_qos_normalize_groups_min_rate(esw, divider, extack);\n\t\tif (err) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch groups normalization failed\");\n\t\t\tgoto err_min_rate;\n\t\t}\n\t}\n\ttrace_mlx5_esw_group_qos_create(esw->dev, group, group->tsar_ix);\n\n\treturn group;\n\nerr_min_rate:\n\tlist_del(&group->list);\n\tif (mlx5_destroy_scheduling_element_cmd(esw->dev,\n\t\t\t\t\t\tSCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\tgroup->tsar_ix))\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch destroy TSAR for group failed\");\nerr_sched_elem:\n\tkfree(group);\n\treturn ERR_PTR(err);\n}\n\nstatic int esw_qos_get(struct mlx5_eswitch *esw, struct netlink_ext_ack *extack);\nstatic void esw_qos_put(struct mlx5_eswitch *esw);\n\nstatic struct mlx5_esw_rate_group *\nesw_qos_create_rate_group(struct mlx5_eswitch *esw, struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_esw_rate_group *group;\n\tint err;\n\n\tif (!MLX5_CAP_QOS(esw->dev, log_esw_max_sched_depth))\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\terr = esw_qos_get(esw, extack);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tgroup = __esw_qos_create_rate_group(esw, extack);\n\tif (IS_ERR(group))\n\t\tesw_qos_put(esw);\n\n\treturn group;\n}\n\nstatic int __esw_qos_destroy_rate_group(struct mlx5_eswitch *esw,\n\t\t\t\t\tstruct mlx5_esw_rate_group *group,\n\t\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tu32 divider;\n\tint err;\n\n\tlist_del(&group->list);\n\n\tdivider = esw_qos_calculate_min_rate_divider(esw, NULL, true);\n\terr = esw_qos_normalize_groups_min_rate(esw, divider, extack);\n\tif (err)\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch groups' normalization failed\");\n\n\terr = mlx5_destroy_scheduling_element_cmd(esw->dev,\n\t\t\t\t\t\t  SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t  group->tsar_ix);\n\tif (err)\n\t\tNL_SET_ERR_MSG_MOD(extack, \"E-Switch destroy TSAR_ID failed\");\n\n\ttrace_mlx5_esw_group_qos_destroy(esw->dev, group, group->tsar_ix);\n\n\tkfree(group);\n\n\treturn err;\n}\n\nstatic int esw_qos_destroy_rate_group(struct mlx5_eswitch *esw,\n\t\t\t\t      struct mlx5_esw_rate_group *group,\n\t\t\t\t      struct netlink_ext_ack *extack)\n{\n\tint err;\n\n\terr = __esw_qos_destroy_rate_group(esw, group, extack);\n\tesw_qos_put(esw);\n\n\treturn err;\n}\n\nstatic bool esw_qos_element_type_supported(struct mlx5_core_dev *dev, int type)\n{\n\tswitch (type) {\n\tcase SCHEDULING_CONTEXT_ELEMENT_TYPE_TSAR:\n\t\treturn MLX5_CAP_QOS(dev, esw_element_type) &\n\t\t       ELEMENT_TYPE_CAP_MASK_TASR;\n\tcase SCHEDULING_CONTEXT_ELEMENT_TYPE_VPORT:\n\t\treturn MLX5_CAP_QOS(dev, esw_element_type) &\n\t\t       ELEMENT_TYPE_CAP_MASK_VPORT;\n\tcase SCHEDULING_CONTEXT_ELEMENT_TYPE_VPORT_TC:\n\t\treturn MLX5_CAP_QOS(dev, esw_element_type) &\n\t\t       ELEMENT_TYPE_CAP_MASK_VPORT_TC;\n\tcase SCHEDULING_CONTEXT_ELEMENT_TYPE_PARA_VPORT_TC:\n\t\treturn MLX5_CAP_QOS(dev, esw_element_type) &\n\t\t       ELEMENT_TYPE_CAP_MASK_PARA_VPORT_TC;\n\t}\n\treturn false;\n}\n\nstatic int esw_qos_create(struct mlx5_eswitch *esw, struct netlink_ext_ack *extack)\n{\n\tu32 tsar_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {};\n\tstruct mlx5_core_dev *dev = esw->dev;\n\t__be32 *attr;\n\tint err;\n\n\tif (!MLX5_CAP_GEN(dev, qos) || !MLX5_CAP_QOS(dev, esw_scheduling))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!esw_qos_element_type_supported(dev, SCHEDULING_CONTEXT_ELEMENT_TYPE_TSAR))\n\t\treturn -EOPNOTSUPP;\n\n\tMLX5_SET(scheduling_context, tsar_ctx, element_type,\n\t\t SCHEDULING_CONTEXT_ELEMENT_TYPE_TSAR);\n\n\tattr = MLX5_ADDR_OF(scheduling_context, tsar_ctx, element_attributes);\n\t*attr = cpu_to_be32(TSAR_ELEMENT_TSAR_TYPE_DWRR << 16);\n\n\terr = mlx5_create_scheduling_element_cmd(dev,\n\t\t\t\t\t\t SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t tsar_ctx,\n\t\t\t\t\t\t &esw->qos.root_tsar_ix);\n\tif (err) {\n\t\tesw_warn(dev, \"E-Switch create root TSAR failed (%d)\\n\", err);\n\t\treturn err;\n\t}\n\n\tINIT_LIST_HEAD(&esw->qos.groups);\n\tif (MLX5_CAP_QOS(dev, log_esw_max_sched_depth)) {\n\t\tesw->qos.group0 = __esw_qos_create_rate_group(esw, extack);\n\t\tif (IS_ERR(esw->qos.group0)) {\n\t\t\tesw_warn(dev, \"E-Switch create rate group 0 failed (%ld)\\n\",\n\t\t\t\t PTR_ERR(esw->qos.group0));\n\t\t\terr = PTR_ERR(esw->qos.group0);\n\t\t\tgoto err_group0;\n\t\t}\n\t}\n\trefcount_set(&esw->qos.refcnt, 1);\n\n\treturn 0;\n\nerr_group0:\n\tif (mlx5_destroy_scheduling_element_cmd(esw->dev, SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\tesw->qos.root_tsar_ix))\n\t\tesw_warn(esw->dev, \"E-Switch destroy root TSAR failed.\\n\");\n\n\treturn err;\n}\n\nstatic void esw_qos_destroy(struct mlx5_eswitch *esw)\n{\n\tint err;\n\n\tif (esw->qos.group0)\n\t\t__esw_qos_destroy_rate_group(esw, esw->qos.group0, NULL);\n\n\terr = mlx5_destroy_scheduling_element_cmd(esw->dev,\n\t\t\t\t\t\t  SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t  esw->qos.root_tsar_ix);\n\tif (err)\n\t\tesw_warn(esw->dev, \"E-Switch destroy root TSAR failed (%d)\\n\", err);\n}\n\nstatic int esw_qos_get(struct mlx5_eswitch *esw, struct netlink_ext_ack *extack)\n{\n\tint err = 0;\n\n\tlockdep_assert_held(&esw->state_lock);\n\n\tif (!refcount_inc_not_zero(&esw->qos.refcnt)) {\n\t\t \n\t\terr = esw_qos_create(esw, extack);\n\t}\n\n\treturn err;\n}\n\nstatic void esw_qos_put(struct mlx5_eswitch *esw)\n{\n\tlockdep_assert_held(&esw->state_lock);\n\tif (refcount_dec_and_test(&esw->qos.refcnt))\n\t\tesw_qos_destroy(esw);\n}\n\nstatic int esw_qos_vport_enable(struct mlx5_eswitch *esw, struct mlx5_vport *vport,\n\t\t\t\tu32 max_rate, u32 bw_share, struct netlink_ext_ack *extack)\n{\n\tint err;\n\n\tlockdep_assert_held(&esw->state_lock);\n\tif (vport->qos.enabled)\n\t\treturn 0;\n\n\terr = esw_qos_get(esw, extack);\n\tif (err)\n\t\treturn err;\n\n\tvport->qos.group = esw->qos.group0;\n\n\terr = esw_qos_vport_create_sched_element(esw, vport, max_rate, bw_share);\n\tif (err)\n\t\tgoto err_out;\n\n\tvport->qos.enabled = true;\n\ttrace_mlx5_esw_vport_qos_create(vport, bw_share, max_rate);\n\n\treturn 0;\n\nerr_out:\n\tesw_qos_put(esw);\n\n\treturn err;\n}\n\nvoid mlx5_esw_qos_vport_disable(struct mlx5_eswitch *esw, struct mlx5_vport *vport)\n{\n\tint err;\n\n\tlockdep_assert_held(&esw->state_lock);\n\tif (!vport->qos.enabled)\n\t\treturn;\n\tWARN(vport->qos.group && vport->qos.group != esw->qos.group0,\n\t     \"Disabling QoS on port before detaching it from group\");\n\n\terr = mlx5_destroy_scheduling_element_cmd(esw->dev,\n\t\t\t\t\t\t  SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t  vport->qos.esw_tsar_ix);\n\tif (err)\n\t\tesw_warn(esw->dev, \"E-Switch destroy TSAR vport element failed (vport=%d,err=%d)\\n\",\n\t\t\t vport->vport, err);\n\n\tmemset(&vport->qos, 0, sizeof(vport->qos));\n\ttrace_mlx5_esw_vport_qos_destroy(vport);\n\n\tesw_qos_put(esw);\n}\n\nint mlx5_esw_qos_set_vport_rate(struct mlx5_eswitch *esw, struct mlx5_vport *vport,\n\t\t\t\tu32 max_rate, u32 min_rate)\n{\n\tint err;\n\n\tlockdep_assert_held(&esw->state_lock);\n\terr = esw_qos_vport_enable(esw, vport, 0, 0, NULL);\n\tif (err)\n\t\treturn err;\n\n\terr = esw_qos_set_vport_min_rate(esw, vport, min_rate, NULL);\n\tif (!err)\n\t\terr = esw_qos_set_vport_max_rate(esw, vport, max_rate, NULL);\n\n\treturn err;\n}\n\nint mlx5_esw_qos_modify_vport_rate(struct mlx5_eswitch *esw, u16 vport_num, u32 rate_mbps)\n{\n\tu32 ctx[MLX5_ST_SZ_DW(scheduling_context)] = {};\n\tstruct mlx5_vport *vport;\n\tu32 bitmask;\n\tint err;\n\n\tvport = mlx5_eswitch_get_vport(esw, vport_num);\n\tif (IS_ERR(vport))\n\t\treturn PTR_ERR(vport);\n\n\tmutex_lock(&esw->state_lock);\n\tif (!vport->qos.enabled) {\n\t\t \n\t\terr = esw_qos_vport_enable(esw, vport, rate_mbps, vport->qos.bw_share, NULL);\n\t} else {\n\t\tMLX5_SET(scheduling_context, ctx, max_average_bw, rate_mbps);\n\n\t\tbitmask = MODIFY_SCHEDULING_ELEMENT_IN_MODIFY_BITMASK_MAX_AVERAGE_BW;\n\t\terr = mlx5_modify_scheduling_element_cmd(esw->dev,\n\t\t\t\t\t\t\t SCHEDULING_HIERARCHY_E_SWITCH,\n\t\t\t\t\t\t\t ctx,\n\t\t\t\t\t\t\t vport->qos.esw_tsar_ix,\n\t\t\t\t\t\t\t bitmask);\n\t}\n\tmutex_unlock(&esw->state_lock);\n\n\treturn err;\n}\n\n#define MLX5_LINKSPEED_UNIT 125000  \n\n \nstatic int esw_qos_devlink_rate_to_mbps(struct mlx5_core_dev *mdev, const char *name,\n\t\t\t\t\tu64 *rate, struct netlink_ext_ack *extack)\n{\n\tu32 link_speed_max, remainder;\n\tu64 value;\n\tint err;\n\n\terr = mlx5_port_max_linkspeed(mdev, &link_speed_max);\n\tif (err) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to get link maximum speed\");\n\t\treturn err;\n\t}\n\n\tvalue = div_u64_rem(*rate, MLX5_LINKSPEED_UNIT, &remainder);\n\tif (remainder) {\n\t\tpr_err(\"%s rate value %lluBps not in link speed units of 1Mbps.\\n\",\n\t\t       name, *rate);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"TX rate value not in link speed units of 1Mbps\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (value > link_speed_max) {\n\t\tpr_err(\"%s rate value %lluMbps exceed link maximum speed %u.\\n\",\n\t\t       name, value, link_speed_max);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"TX rate value exceed link maximum speed\");\n\t\treturn -EINVAL;\n\t}\n\n\t*rate = value;\n\treturn 0;\n}\n\n \n\nint mlx5_esw_devlink_rate_leaf_tx_share_set(struct devlink_rate *rate_leaf, void *priv,\n\t\t\t\t\t    u64 tx_share, struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_vport *vport = priv;\n\tstruct mlx5_eswitch *esw;\n\tint err;\n\n\tesw = vport->dev->priv.eswitch;\n\tif (!mlx5_esw_allowed(esw))\n\t\treturn -EPERM;\n\n\terr = esw_qos_devlink_rate_to_mbps(vport->dev, \"tx_share\", &tx_share, extack);\n\tif (err)\n\t\treturn err;\n\n\tmutex_lock(&esw->state_lock);\n\terr = esw_qos_vport_enable(esw, vport, 0, 0, extack);\n\tif (err)\n\t\tgoto unlock;\n\n\terr = esw_qos_set_vport_min_rate(esw, vport, tx_share, extack);\nunlock:\n\tmutex_unlock(&esw->state_lock);\n\treturn err;\n}\n\nint mlx5_esw_devlink_rate_leaf_tx_max_set(struct devlink_rate *rate_leaf, void *priv,\n\t\t\t\t\t  u64 tx_max, struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_vport *vport = priv;\n\tstruct mlx5_eswitch *esw;\n\tint err;\n\n\tesw = vport->dev->priv.eswitch;\n\tif (!mlx5_esw_allowed(esw))\n\t\treturn -EPERM;\n\n\terr = esw_qos_devlink_rate_to_mbps(vport->dev, \"tx_max\", &tx_max, extack);\n\tif (err)\n\t\treturn err;\n\n\tmutex_lock(&esw->state_lock);\n\terr = esw_qos_vport_enable(esw, vport, 0, 0, extack);\n\tif (err)\n\t\tgoto unlock;\n\n\terr = esw_qos_set_vport_max_rate(esw, vport, tx_max, extack);\nunlock:\n\tmutex_unlock(&esw->state_lock);\n\treturn err;\n}\n\nint mlx5_esw_devlink_rate_node_tx_share_set(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t\t    u64 tx_share, struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_core_dev *dev = devlink_priv(rate_node->devlink);\n\tstruct mlx5_eswitch *esw = dev->priv.eswitch;\n\tstruct mlx5_esw_rate_group *group = priv;\n\tint err;\n\n\terr = esw_qos_devlink_rate_to_mbps(dev, \"tx_share\", &tx_share, extack);\n\tif (err)\n\t\treturn err;\n\n\tmutex_lock(&esw->state_lock);\n\terr = esw_qos_set_group_min_rate(esw, group, tx_share, extack);\n\tmutex_unlock(&esw->state_lock);\n\treturn err;\n}\n\nint mlx5_esw_devlink_rate_node_tx_max_set(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t\t  u64 tx_max, struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_core_dev *dev = devlink_priv(rate_node->devlink);\n\tstruct mlx5_eswitch *esw = dev->priv.eswitch;\n\tstruct mlx5_esw_rate_group *group = priv;\n\tint err;\n\n\terr = esw_qos_devlink_rate_to_mbps(dev, \"tx_max\", &tx_max, extack);\n\tif (err)\n\t\treturn err;\n\n\tmutex_lock(&esw->state_lock);\n\terr = esw_qos_set_group_max_rate(esw, group, tx_max, extack);\n\tmutex_unlock(&esw->state_lock);\n\treturn err;\n}\n\nint mlx5_esw_devlink_rate_node_new(struct devlink_rate *rate_node, void **priv,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_esw_rate_group *group;\n\tstruct mlx5_eswitch *esw;\n\tint err = 0;\n\n\tesw = mlx5_devlink_eswitch_get(rate_node->devlink);\n\tif (IS_ERR(esw))\n\t\treturn PTR_ERR(esw);\n\n\tmutex_lock(&esw->state_lock);\n\tif (esw->mode != MLX5_ESWITCH_OFFLOADS) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Rate node creation supported only in switchdev mode\");\n\t\terr = -EOPNOTSUPP;\n\t\tgoto unlock;\n\t}\n\n\tgroup = esw_qos_create_rate_group(esw, extack);\n\tif (IS_ERR(group)) {\n\t\terr = PTR_ERR(group);\n\t\tgoto unlock;\n\t}\n\n\t*priv = group;\nunlock:\n\tmutex_unlock(&esw->state_lock);\n\treturn err;\n}\n\nint mlx5_esw_devlink_rate_node_del(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_esw_rate_group *group = priv;\n\tstruct mlx5_eswitch *esw;\n\tint err;\n\n\tesw = mlx5_devlink_eswitch_get(rate_node->devlink);\n\tif (IS_ERR(esw))\n\t\treturn PTR_ERR(esw);\n\n\tmutex_lock(&esw->state_lock);\n\terr = esw_qos_destroy_rate_group(esw, group, extack);\n\tmutex_unlock(&esw->state_lock);\n\treturn err;\n}\n\nint mlx5_esw_qos_vport_update_group(struct mlx5_eswitch *esw,\n\t\t\t\t    struct mlx5_vport *vport,\n\t\t\t\t    struct mlx5_esw_rate_group *group,\n\t\t\t\t    struct netlink_ext_ack *extack)\n{\n\tint err = 0;\n\n\tmutex_lock(&esw->state_lock);\n\tif (!vport->qos.enabled && !group)\n\t\tgoto unlock;\n\n\terr = esw_qos_vport_enable(esw, vport, 0, 0, extack);\n\tif (!err)\n\t\terr = esw_qos_vport_update_group(esw, vport, group, extack);\nunlock:\n\tmutex_unlock(&esw->state_lock);\n\treturn err;\n}\n\nint mlx5_esw_devlink_rate_parent_set(struct devlink_rate *devlink_rate,\n\t\t\t\t     struct devlink_rate *parent,\n\t\t\t\t     void *priv, void *parent_priv,\n\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct mlx5_esw_rate_group *group;\n\tstruct mlx5_vport *vport = priv;\n\n\tif (!parent)\n\t\treturn mlx5_esw_qos_vport_update_group(vport->dev->priv.eswitch,\n\t\t\t\t\t\t       vport, NULL, extack);\n\n\tgroup = parent_priv;\n\treturn mlx5_esw_qos_vport_update_group(vport->dev->priv.eswitch, vport, group, extack);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}