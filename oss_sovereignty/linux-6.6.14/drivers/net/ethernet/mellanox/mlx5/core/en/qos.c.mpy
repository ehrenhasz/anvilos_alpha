{
  "module_name": "qos.c",
  "hash_id": "4105d389eacb907153a1d4b22e63add740c05acf7c81ef4d0d6fa2d9773bba91",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en/qos.c",
  "human_readable_source": "\n \n#include <net/sch_generic.h>\n\n#include <net/pkt_cls.h>\n#include \"en.h\"\n#include \"params.h\"\n#include \"../qos.h\"\n#include \"en/htb.h\"\n\nstruct qos_sq_callback_params {\n\tstruct mlx5e_priv *priv;\n\tstruct mlx5e_channels *chs;\n};\n\nint mlx5e_qos_bytes_rate_check(struct mlx5_core_dev *mdev, u64 nbytes)\n{\n\tif (nbytes < BYTES_IN_MBIT) {\n\t\tqos_warn(mdev, \"Input rate (%llu Bytes/sec) below minimum supported (%u Bytes/sec)\\n\",\n\t\t\t nbytes, BYTES_IN_MBIT);\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic u32 mlx5e_qos_bytes2mbits(struct mlx5_core_dev *mdev, u64 nbytes)\n{\n\treturn div_u64(nbytes, BYTES_IN_MBIT);\n}\n\nint mlx5e_qos_max_leaf_nodes(struct mlx5_core_dev *mdev)\n{\n\treturn min(MLX5E_QOS_MAX_LEAF_NODES, mlx5_qos_max_leaf_nodes(mdev));\n}\n\n \n\nu16 mlx5e_qid_from_qos(struct mlx5e_channels *chs, u16 qid)\n{\n\t \n\tbool is_ptp = MLX5E_GET_PFLAG(&chs->params, MLX5E_PFLAG_TX_PORT_TS);\n\n\treturn (chs->params.num_channels + is_ptp) * mlx5e_get_dcb_num_tc(&chs->params) + qid;\n}\n\n \n\nstatic struct mlx5e_txqsq *mlx5e_get_qos_sq(struct mlx5e_priv *priv, int qid)\n{\n\tstruct mlx5e_params *params = &priv->channels.params;\n\tstruct mlx5e_txqsq __rcu **qos_sqs;\n\tstruct mlx5e_channel *c;\n\tint ix;\n\n\tix = qid % params->num_channels;\n\tqid /= params->num_channels;\n\tc = priv->channels.c[ix];\n\n\tqos_sqs = mlx5e_state_dereference(priv, c->qos_sqs);\n\treturn mlx5e_state_dereference(priv, qos_sqs[qid]);\n}\n\nint mlx5e_open_qos_sq(struct mlx5e_priv *priv, struct mlx5e_channels *chs,\n\t\t      u16 node_qid, u32 hw_id)\n{\n\tstruct mlx5e_create_cq_param ccp = {};\n\tstruct mlx5e_txqsq __rcu **qos_sqs;\n\tstruct mlx5e_sq_param param_sq;\n\tstruct mlx5e_cq_param param_cq;\n\tint txq_ix, ix, qid, err = 0;\n\tstruct mlx5e_params *params;\n\tstruct mlx5e_channel *c;\n\tstruct mlx5e_txqsq *sq;\n\n\tparams = &chs->params;\n\n\ttxq_ix = mlx5e_qid_from_qos(chs, node_qid);\n\n\tWARN_ON(node_qid > priv->htb_max_qos_sqs);\n\tif (node_qid == priv->htb_max_qos_sqs) {\n\t\tstruct mlx5e_sq_stats *stats, **stats_list = NULL;\n\n\t\tif (priv->htb_max_qos_sqs == 0) {\n\t\t\tstats_list = kvcalloc(mlx5e_qos_max_leaf_nodes(priv->mdev),\n\t\t\t\t\t      sizeof(*stats_list),\n\t\t\t\t\t      GFP_KERNEL);\n\t\t\tif (!stats_list)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\t\tstats = kzalloc(sizeof(*stats), GFP_KERNEL);\n\t\tif (!stats) {\n\t\t\tkvfree(stats_list);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tif (stats_list)\n\t\t\tWRITE_ONCE(priv->htb_qos_sq_stats, stats_list);\n\t\tWRITE_ONCE(priv->htb_qos_sq_stats[node_qid], stats);\n\t\t \n\t\tsmp_store_release(&priv->htb_max_qos_sqs, priv->htb_max_qos_sqs + 1);\n\t}\n\n\tix = node_qid % params->num_channels;\n\tqid = node_qid / params->num_channels;\n\tc = chs->c[ix];\n\n\tqos_sqs = mlx5e_state_dereference(priv, c->qos_sqs);\n\tsq = kzalloc(sizeof(*sq), GFP_KERNEL);\n\n\tif (!sq)\n\t\treturn -ENOMEM;\n\n\tmlx5e_build_create_cq_param(&ccp, c);\n\n\tmemset(&param_sq, 0, sizeof(param_sq));\n\tmemset(&param_cq, 0, sizeof(param_cq));\n\tmlx5e_build_sq_param(priv->mdev, params, &param_sq);\n\tmlx5e_build_tx_cq_param(priv->mdev, params, &param_cq);\n\terr = mlx5e_open_cq(priv, params->tx_cq_moderation, &param_cq, &ccp, &sq->cq);\n\tif (err)\n\t\tgoto err_free_sq;\n\terr = mlx5e_open_txqsq(c, priv->tisn[c->lag_port][0], txq_ix, params,\n\t\t\t       &param_sq, sq, 0, hw_id,\n\t\t\t       priv->htb_qos_sq_stats[node_qid]);\n\tif (err)\n\t\tgoto err_close_cq;\n\n\trcu_assign_pointer(qos_sqs[qid], sq);\n\n\treturn 0;\n\nerr_close_cq:\n\tmlx5e_close_cq(&sq->cq);\nerr_free_sq:\n\tkfree(sq);\n\treturn err;\n}\n\nstatic int mlx5e_open_qos_sq_cb_wrapper(void *data, u16 node_qid, u32 hw_id)\n{\n\tstruct qos_sq_callback_params *cb_params = data;\n\n\treturn mlx5e_open_qos_sq(cb_params->priv, cb_params->chs, node_qid, hw_id);\n}\n\nint mlx5e_activate_qos_sq(void *data, u16 node_qid, u32 hw_id)\n{\n\tstruct mlx5e_priv *priv = data;\n\tstruct mlx5e_txqsq *sq;\n\tu16 qid;\n\n\tsq = mlx5e_get_qos_sq(priv, node_qid);\n\n\tqid = mlx5e_qid_from_qos(&priv->channels, node_qid);\n\n\t \n\tmlx5e_tx_disable_queue(netdev_get_tx_queue(priv->netdev, qid));\n\n\tpriv->txq2sq[qid] = sq;\n\n\t \n\tsmp_wmb();\n\n\tqos_dbg(priv->mdev, \"Activate QoS SQ qid %u\\n\", node_qid);\n\tmlx5e_activate_txqsq(sq);\n\n\treturn 0;\n}\n\nvoid mlx5e_deactivate_qos_sq(struct mlx5e_priv *priv, u16 qid)\n{\n\tstruct mlx5e_txqsq *sq;\n\n\tsq = mlx5e_get_qos_sq(priv, qid);\n\tif (!sq)  \n\t\treturn;\n\n\tqos_dbg(priv->mdev, \"Deactivate QoS SQ qid %u\\n\", qid);\n\tmlx5e_deactivate_txqsq(sq);\n\n\tpriv->txq2sq[mlx5e_qid_from_qos(&priv->channels, qid)] = NULL;\n\n\t \n\tsmp_wmb();\n}\n\nvoid mlx5e_close_qos_sq(struct mlx5e_priv *priv, u16 qid)\n{\n\tstruct mlx5e_txqsq __rcu **qos_sqs;\n\tstruct mlx5e_params *params;\n\tstruct mlx5e_channel *c;\n\tstruct mlx5e_txqsq *sq;\n\tint ix;\n\n\tparams = &priv->channels.params;\n\n\tix = qid % params->num_channels;\n\tqid /= params->num_channels;\n\tc = priv->channels.c[ix];\n\tqos_sqs = mlx5e_state_dereference(priv, c->qos_sqs);\n\tsq = rcu_replace_pointer(qos_sqs[qid], NULL, lockdep_is_held(&priv->state_lock));\n\tif (!sq)  \n\t\treturn;\n\n\tsynchronize_rcu();  \n\n\tmlx5e_close_txqsq(sq);\n\tmlx5e_close_cq(&sq->cq);\n\tkfree(sq);\n}\n\nvoid mlx5e_qos_close_queues(struct mlx5e_channel *c)\n{\n\tstruct mlx5e_txqsq __rcu **qos_sqs;\n\tint i;\n\n\tqos_sqs = rcu_replace_pointer(c->qos_sqs, NULL, lockdep_is_held(&c->priv->state_lock));\n\tif (!qos_sqs)\n\t\treturn;\n\tsynchronize_rcu();  \n\n\tfor (i = 0; i < c->qos_sqs_size; i++) {\n\t\tstruct mlx5e_txqsq *sq;\n\n\t\tsq = mlx5e_state_dereference(c->priv, qos_sqs[i]);\n\t\tif (!sq)  \n\t\t\tcontinue;\n\n\t\tmlx5e_close_txqsq(sq);\n\t\tmlx5e_close_cq(&sq->cq);\n\t\tkfree(sq);\n\t}\n\n\tkvfree(qos_sqs);\n}\n\nvoid mlx5e_qos_close_all_queues(struct mlx5e_channels *chs)\n{\n\tint i;\n\n\tfor (i = 0; i < chs->num; i++)\n\t\tmlx5e_qos_close_queues(chs->c[i]);\n}\n\nint mlx5e_qos_alloc_queues(struct mlx5e_priv *priv, struct mlx5e_channels *chs)\n{\n\tu16 qos_sqs_size;\n\tint i;\n\n\tqos_sqs_size = DIV_ROUND_UP(mlx5e_qos_max_leaf_nodes(priv->mdev), chs->num);\n\n\tfor (i = 0; i < chs->num; i++) {\n\t\tstruct mlx5e_txqsq **sqs;\n\n\t\tsqs = kvcalloc(qos_sqs_size, sizeof(struct mlx5e_txqsq *), GFP_KERNEL);\n\t\tif (!sqs)\n\t\t\tgoto err_free;\n\n\t\tWRITE_ONCE(chs->c[i]->qos_sqs_size, qos_sqs_size);\n\t\tsmp_wmb();  \n\t\trcu_assign_pointer(chs->c[i]->qos_sqs, sqs);\n\t}\n\n\treturn 0;\n\nerr_free:\n\twhile (--i >= 0) {\n\t\tstruct mlx5e_txqsq **sqs;\n\n\t\tsqs = rcu_replace_pointer(chs->c[i]->qos_sqs, NULL,\n\t\t\t\t\t  lockdep_is_held(&priv->state_lock));\n\n\t\tsynchronize_rcu();  \n\t\tkvfree(sqs);\n\t}\n\treturn -ENOMEM;\n}\n\nint mlx5e_qos_open_queues(struct mlx5e_priv *priv, struct mlx5e_channels *chs)\n{\n\tstruct qos_sq_callback_params callback_params;\n\tint err;\n\n\terr = mlx5e_qos_alloc_queues(priv, chs);\n\tif (err)\n\t\treturn err;\n\n\tcallback_params.priv = priv;\n\tcallback_params.chs = chs;\n\n\terr = mlx5e_htb_enumerate_leaves(priv->htb, mlx5e_open_qos_sq_cb_wrapper, &callback_params);\n\tif (err) {\n\t\tmlx5e_qos_close_all_queues(chs);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nvoid mlx5e_qos_activate_queues(struct mlx5e_priv *priv)\n{\n\tmlx5e_htb_enumerate_leaves(priv->htb, mlx5e_activate_qos_sq, priv);\n}\n\nvoid mlx5e_qos_deactivate_queues(struct mlx5e_channel *c)\n{\n\tstruct mlx5e_params *params = &c->priv->channels.params;\n\tstruct mlx5e_txqsq __rcu **qos_sqs;\n\tint i;\n\n\tqos_sqs = mlx5e_state_dereference(c->priv, c->qos_sqs);\n\tif (!qos_sqs)\n\t\treturn;\n\n\tfor (i = 0; i < c->qos_sqs_size; i++) {\n\t\tu16 qid = params->num_channels * i + c->ix;\n\t\tstruct mlx5e_txqsq *sq;\n\n\t\tsq = mlx5e_state_dereference(c->priv, qos_sqs[i]);\n\t\tif (!sq)  \n\t\t\tcontinue;\n\n\t\tqos_dbg(c->mdev, \"Deactivate QoS SQ qid %u\\n\", qid);\n\t\tmlx5e_deactivate_txqsq(sq);\n\n\t\t \n\t\tc->priv->txq2sq[mlx5e_qid_from_qos(&c->priv->channels, qid)] = NULL;\n\t}\n}\n\nvoid mlx5e_qos_deactivate_all_queues(struct mlx5e_channels *chs)\n{\n\tint i;\n\n\tfor (i = 0; i < chs->num; i++)\n\t\tmlx5e_qos_deactivate_queues(chs->c[i]);\n}\n\nvoid mlx5e_reactivate_qos_sq(struct mlx5e_priv *priv, u16 qid, struct netdev_queue *txq)\n{\n\tqos_dbg(priv->mdev, \"Reactivate QoS SQ qid %u\\n\", qid);\n\tnetdev_tx_reset_queue(txq);\n\tnetif_tx_start_queue(txq);\n}\n\nvoid mlx5e_reset_qdisc(struct net_device *dev, u16 qid)\n{\n\tstruct netdev_queue *dev_queue = netdev_get_tx_queue(dev, qid);\n\tstruct Qdisc *qdisc = dev_queue->qdisc_sleeping;\n\n\tif (!qdisc)\n\t\treturn;\n\n\tspin_lock_bh(qdisc_lock(qdisc));\n\tqdisc_reset(qdisc);\n\tspin_unlock_bh(qdisc_lock(qdisc));\n}\n\nint mlx5e_htb_setup_tc(struct mlx5e_priv *priv, struct tc_htb_qopt_offload *htb_qopt)\n{\n\tstruct mlx5e_htb *htb = priv->htb;\n\tint res;\n\n\tif (!htb && htb_qopt->command != TC_HTB_CREATE)\n\t\treturn -EINVAL;\n\n\tif (htb_qopt->prio || htb_qopt->quantum) {\n\t\tNL_SET_ERR_MSG_MOD(htb_qopt->extack,\n\t\t\t\t   \"prio and quantum parameters are not supported by device with HTB offload enabled.\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tswitch (htb_qopt->command) {\n\tcase TC_HTB_CREATE:\n\t\tif (!mlx5_qos_is_supported(priv->mdev)) {\n\t\t\tNL_SET_ERR_MSG_MOD(htb_qopt->extack,\n\t\t\t\t\t   \"Missing QoS capabilities. Try disabling SRIOV or use a supported device.\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tpriv->htb = mlx5e_htb_alloc();\n\t\thtb = priv->htb;\n\t\tif (!htb)\n\t\t\treturn -ENOMEM;\n\t\tres = mlx5e_htb_init(htb, htb_qopt, priv->netdev, priv->mdev, &priv->selq, priv);\n\t\tif (res) {\n\t\t\tmlx5e_htb_free(htb);\n\t\t\tpriv->htb = NULL;\n\t\t}\n\t\treturn res;\n\tcase TC_HTB_DESTROY:\n\t\tmlx5e_htb_cleanup(htb);\n\t\tmlx5e_htb_free(htb);\n\t\tpriv->htb = NULL;\n\t\treturn 0;\n\tcase TC_HTB_LEAF_ALLOC_QUEUE:\n\t\tres = mlx5e_htb_leaf_alloc_queue(htb, htb_qopt->classid, htb_qopt->parent_classid,\n\t\t\t\t\t\t htb_qopt->rate, htb_qopt->ceil, htb_qopt->extack);\n\t\tif (res < 0)\n\t\t\treturn res;\n\t\thtb_qopt->qid = res;\n\t\treturn 0;\n\tcase TC_HTB_LEAF_TO_INNER:\n\t\treturn mlx5e_htb_leaf_to_inner(htb, htb_qopt->parent_classid, htb_qopt->classid,\n\t\t\t\t\t       htb_qopt->rate, htb_qopt->ceil, htb_qopt->extack);\n\tcase TC_HTB_LEAF_DEL:\n\t\treturn mlx5e_htb_leaf_del(htb, &htb_qopt->classid, htb_qopt->extack);\n\tcase TC_HTB_LEAF_DEL_LAST:\n\tcase TC_HTB_LEAF_DEL_LAST_FORCE:\n\t\treturn mlx5e_htb_leaf_del_last(htb, htb_qopt->classid,\n\t\t\t\t\t       htb_qopt->command == TC_HTB_LEAF_DEL_LAST_FORCE,\n\t\t\t\t\t       htb_qopt->extack);\n\tcase TC_HTB_NODE_MODIFY:\n\t\treturn mlx5e_htb_node_modify(htb, htb_qopt->classid, htb_qopt->rate, htb_qopt->ceil,\n\t\t\t\t\t     htb_qopt->extack);\n\tcase TC_HTB_LEAF_QUERY_QUEUE:\n\t\tres = mlx5e_htb_get_txq_by_classid(htb, htb_qopt->classid);\n\t\tif (res < 0)\n\t\t\treturn res;\n\t\thtb_qopt->qid = res;\n\t\treturn 0;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstruct mlx5e_mqprio_rl {\n\tstruct mlx5_core_dev *mdev;\n\tu32 root_id;\n\tu32 *leaves_id;\n\tu8 num_tc;\n};\n\nstruct mlx5e_mqprio_rl *mlx5e_mqprio_rl_alloc(void)\n{\n\treturn kvzalloc(sizeof(struct mlx5e_mqprio_rl), GFP_KERNEL);\n}\n\nvoid mlx5e_mqprio_rl_free(struct mlx5e_mqprio_rl *rl)\n{\n\tkvfree(rl);\n}\n\nint mlx5e_mqprio_rl_init(struct mlx5e_mqprio_rl *rl, struct mlx5_core_dev *mdev, u8 num_tc,\n\t\t\t u64 max_rate[])\n{\n\tint err;\n\tint tc;\n\n\tif (!mlx5_qos_is_supported(mdev)) {\n\t\tqos_warn(mdev, \"Missing QoS capabilities. Try disabling SRIOV or use a supported device.\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\tif (num_tc > mlx5e_qos_max_leaf_nodes(mdev))\n\t\treturn -EINVAL;\n\n\trl->mdev = mdev;\n\trl->num_tc = num_tc;\n\trl->leaves_id = kvcalloc(num_tc, sizeof(*rl->leaves_id), GFP_KERNEL);\n\tif (!rl->leaves_id)\n\t\treturn -ENOMEM;\n\n\terr = mlx5_qos_create_root_node(mdev, &rl->root_id);\n\tif (err)\n\t\tgoto err_free_leaves;\n\n\tqos_dbg(mdev, \"Root created, id %#x\\n\", rl->root_id);\n\n\tfor (tc = 0; tc < num_tc; tc++) {\n\t\tu32 max_average_bw;\n\n\t\tmax_average_bw = mlx5e_qos_bytes2mbits(mdev, max_rate[tc]);\n\t\terr = mlx5_qos_create_leaf_node(mdev, rl->root_id, 0, max_average_bw,\n\t\t\t\t\t\t&rl->leaves_id[tc]);\n\t\tif (err)\n\t\t\tgoto err_destroy_leaves;\n\n\t\tqos_dbg(mdev, \"Leaf[%d] created, id %#x, max average bw %u Mbits/sec\\n\",\n\t\t\ttc, rl->leaves_id[tc], max_average_bw);\n\t}\n\treturn 0;\n\nerr_destroy_leaves:\n\twhile (--tc >= 0)\n\t\tmlx5_qos_destroy_node(mdev, rl->leaves_id[tc]);\n\tmlx5_qos_destroy_node(mdev, rl->root_id);\nerr_free_leaves:\n\tkvfree(rl->leaves_id);\n\treturn err;\n}\n\nvoid mlx5e_mqprio_rl_cleanup(struct mlx5e_mqprio_rl *rl)\n{\n\tint tc;\n\n\tfor (tc = 0; tc < rl->num_tc; tc++)\n\t\tmlx5_qos_destroy_node(rl->mdev, rl->leaves_id[tc]);\n\tmlx5_qos_destroy_node(rl->mdev, rl->root_id);\n\tkvfree(rl->leaves_id);\n}\n\nint mlx5e_mqprio_rl_get_node_hw_id(struct mlx5e_mqprio_rl *rl, int tc, u32 *hw_id)\n{\n\tif (tc >= rl->num_tc)\n\t\treturn -EINVAL;\n\n\t*hw_id = rl->leaves_id[tc];\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}