{
  "module_name": "en.h",
  "hash_id": "1236d50db28aea8014d5788025000acb84423ab2b77cb602fbc5300025d09f1a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/mellanox/mlx5/core/en.h",
  "human_readable_source": " \n#ifndef __MLX5_EN_H__\n#define __MLX5_EN_H__\n\n#include <linux/if_vlan.h>\n#include <linux/etherdevice.h>\n#include <linux/timecounter.h>\n#include <linux/net_tstamp.h>\n#include <linux/crash_dump.h>\n#include <linux/mlx5/driver.h>\n#include <linux/mlx5/qp.h>\n#include <linux/mlx5/cq.h>\n#include <linux/mlx5/port.h>\n#include <linux/mlx5/vport.h>\n#include <linux/mlx5/transobj.h>\n#include <linux/mlx5/fs.h>\n#include <linux/rhashtable.h>\n#include <net/udp_tunnel.h>\n#include <net/switchdev.h>\n#include <net/xdp.h>\n#include <linux/dim.h>\n#include <linux/bits.h>\n#include \"wq.h\"\n#include \"mlx5_core.h\"\n#include \"en_stats.h\"\n#include \"en/dcbnl.h\"\n#include \"en/fs.h\"\n#include \"en/qos.h\"\n#include \"lib/hv_vhca.h\"\n#include \"lib/clock.h\"\n#include \"en/rx_res.h\"\n#include \"en/selq.h\"\n\nextern const struct net_device_ops mlx5e_netdev_ops;\nstruct page_pool;\n\n#define MLX5E_METADATA_ETHER_TYPE (0x8CE4)\n#define MLX5E_METADATA_ETHER_LEN 8\n\n#define MLX5E_ETH_HARD_MTU (ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN)\n\n#define MLX5E_HW2SW_MTU(params, hwmtu) ((hwmtu) - ((params)->hard_mtu))\n#define MLX5E_SW2HW_MTU(params, swmtu) ((swmtu) + ((params)->hard_mtu))\n\n#define MLX5E_MAX_NUM_TC\t8\n#define MLX5E_MAX_NUM_MQPRIO_CH_TC TC_QOPT_MAX_QUEUE\n\n#define MLX5_RX_HEADROOM NET_SKB_PAD\n#define MLX5_SKB_FRAG_SZ(len)\t(SKB_DATA_ALIGN(len) +\t\\\n\t\t\t\t SKB_DATA_ALIGN(sizeof(struct skb_shared_info)))\n\n#define MLX5E_RX_MAX_HEAD (256)\n#define MLX5E_SHAMPO_LOG_MAX_HEADER_ENTRY_SIZE (9)\n#define MLX5E_SHAMPO_WQ_HEADER_PER_PAGE (PAGE_SIZE >> MLX5E_SHAMPO_LOG_MAX_HEADER_ENTRY_SIZE)\n#define MLX5E_SHAMPO_WQ_BASE_HEAD_ENTRY_SIZE (64)\n#define MLX5E_SHAMPO_WQ_RESRV_SIZE (64 * 1024)\n#define MLX5E_SHAMPO_WQ_BASE_RESRV_SIZE (4096)\n\n#define MLX5_MPWRQ_MIN_LOG_STRIDE_SZ(mdev) \\\n\t(6 + MLX5_CAP_GEN(mdev, cache_line_128byte))  \n#define MLX5_MPWRQ_LOG_STRIDE_SZ(mdev, req) \\\n\tmax_t(u32, MLX5_MPWRQ_MIN_LOG_STRIDE_SZ(mdev), req)\n#define MLX5_MPWRQ_DEF_LOG_STRIDE_SZ(mdev) \\\n\tMLX5_MPWRQ_LOG_STRIDE_SZ(mdev, order_base_2(MLX5E_RX_MAX_HEAD))\n\n#define MLX5_MPWRQ_MAX_LOG_WQE_SZ 18\n\n \n#define MLX5_UMR_MAX_FLEX_SPACE \\\n\t(ALIGN_DOWN(MLX5_SEND_WQE_MAX_SIZE - sizeof(struct mlx5e_umr_wqe), \\\n\t\t    MLX5_UMR_FLEX_ALIGNMENT))\n#define MLX5_MPWRQ_MAX_PAGES_PER_WQE \\\n\trounddown_pow_of_two(MLX5_UMR_MAX_FLEX_SPACE / sizeof(struct mlx5_mtt))\n\n#define MLX5E_MAX_RQ_NUM_MTTS\t\\\n\t(ALIGN_DOWN(U16_MAX, 4) * 2)  \n#define MLX5E_MAX_RQ_NUM_KSMS (U16_MAX - 1)  \n#define MLX5E_ORDER2_MAX_PACKET_MTU (order_base_2(10 * 1024))\n\n#define MLX5E_MIN_SKB_FRAG_SZ\t\t(MLX5_SKB_FRAG_SZ(MLX5_RX_HEADROOM))\n#define MLX5E_LOG_MAX_RX_WQE_BULK\t\\\n\t(ilog2(PAGE_SIZE / roundup_pow_of_two(MLX5E_MIN_SKB_FRAG_SZ)))\n\n#define MLX5E_PARAMS_MINIMUM_LOG_SQ_SIZE                0x6\n#define MLX5E_PARAMS_DEFAULT_LOG_SQ_SIZE                0xa\n#define MLX5E_PARAMS_MAXIMUM_LOG_SQ_SIZE                0xd\n\n#define MLX5E_PARAMS_MINIMUM_LOG_RQ_SIZE (1 + MLX5E_LOG_MAX_RX_WQE_BULK)\n#define MLX5E_PARAMS_DEFAULT_LOG_RQ_SIZE                0xa\n#define MLX5E_PARAMS_MAXIMUM_LOG_RQ_SIZE\t\t0xd\n\n#define MLX5E_PARAMS_MINIMUM_LOG_RQ_SIZE_MPW            0x2\n\n#define MLX5E_DEFAULT_LRO_TIMEOUT                       32\n#define MLX5E_LRO_TIMEOUT_ARR_SIZE                      4\n\n#define MLX5E_PARAMS_DEFAULT_RX_CQ_MODERATION_USEC      0x10\n#define MLX5E_PARAMS_DEFAULT_RX_CQ_MODERATION_USEC_FROM_CQE 0x3\n#define MLX5E_PARAMS_DEFAULT_RX_CQ_MODERATION_PKTS      0x20\n#define MLX5E_PARAMS_DEFAULT_TX_CQ_MODERATION_USEC      0x10\n#define MLX5E_PARAMS_DEFAULT_TX_CQ_MODERATION_USEC_FROM_CQE 0x10\n#define MLX5E_PARAMS_DEFAULT_TX_CQ_MODERATION_PKTS      0x20\n#define MLX5E_PARAMS_DEFAULT_MIN_RX_WQES                0x80\n#define MLX5E_PARAMS_DEFAULT_MIN_RX_WQES_MPW            0x2\n\n#define MLX5E_MIN_NUM_CHANNELS         0x1\n#define MLX5E_MAX_NUM_CHANNELS         (MLX5E_INDIR_RQT_SIZE / 2)\n#define MLX5E_TX_CQ_POLL_BUDGET        128\n#define MLX5E_TX_XSK_POLL_BUDGET       64\n#define MLX5E_SQ_RECOVER_MIN_INTERVAL  500  \n\n#define MLX5E_KLM_UMR_WQE_SZ(sgl_len)\\\n\t(sizeof(struct mlx5e_umr_wqe) +\\\n\t(sizeof(struct mlx5_klm) * (sgl_len)))\n\n#define MLX5E_KLM_UMR_WQEBBS(klm_entries) \\\n\t(DIV_ROUND_UP(MLX5E_KLM_UMR_WQE_SZ(klm_entries), MLX5_SEND_WQE_BB))\n\n#define MLX5E_KLM_UMR_DS_CNT(klm_entries)\\\n\t(DIV_ROUND_UP(MLX5E_KLM_UMR_WQE_SZ(klm_entries), MLX5_SEND_WQE_DS))\n\n#define MLX5E_KLM_MAX_ENTRIES_PER_WQE(wqe_size)\\\n\t(((wqe_size) - sizeof(struct mlx5e_umr_wqe)) / sizeof(struct mlx5_klm))\n\n#define MLX5E_KLM_ENTRIES_PER_WQE(wqe_size)\\\n\tALIGN_DOWN(MLX5E_KLM_MAX_ENTRIES_PER_WQE(wqe_size), MLX5_UMR_KLM_NUM_ENTRIES_ALIGNMENT)\n\n#define MLX5E_MAX_KLM_PER_WQE(mdev) \\\n\tMLX5E_KLM_ENTRIES_PER_WQE(MLX5_SEND_WQE_BB * mlx5e_get_max_sq_aligned_wqebbs(mdev))\n\n#define mlx5e_state_dereference(priv, p) \\\n\trcu_dereference_protected((p), lockdep_is_held(&(priv)->state_lock))\n\nstatic inline u8 mlx5e_get_num_lag_ports(struct mlx5_core_dev *mdev)\n{\n\tif (mlx5_lag_is_lacp_owner(mdev))\n\t\treturn 1;\n\n\treturn clamp_t(u8, MLX5_CAP_GEN(mdev, num_lag_ports), 1, MLX5_MAX_PORTS);\n}\n\nstatic inline u16 mlx5_min_rx_wqes(int wq_type, u32 wq_size)\n{\n\tswitch (wq_type) {\n\tcase MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ:\n\t\treturn min_t(u16, MLX5E_PARAMS_DEFAULT_MIN_RX_WQES_MPW,\n\t\t\t     wq_size / 2);\n\tdefault:\n\t\treturn min_t(u16, MLX5E_PARAMS_DEFAULT_MIN_RX_WQES,\n\t\t\t     wq_size / 2);\n\t}\n}\n\n \nstatic inline int mlx5e_get_max_num_channels(struct mlx5_core_dev *mdev)\n{\n\treturn is_kdump_kernel() ?\n\t\tMLX5E_MIN_NUM_CHANNELS :\n\t\tmin_t(int, mlx5_comp_vectors_max(mdev), MLX5E_MAX_NUM_CHANNELS);\n}\n\n \nstatic inline u8 mlx5e_get_max_sq_wqebbs(struct mlx5_core_dev *mdev)\n{\n\tBUILD_BUG_ON(MLX5_SEND_WQE_MAX_WQEBBS > U8_MAX);\n\n\treturn (u8)min_t(u16, MLX5_SEND_WQE_MAX_WQEBBS,\n\t\t\t MLX5_CAP_GEN(mdev, max_wqe_sz_sq) / MLX5_SEND_WQE_BB);\n}\n\nstatic inline u8 mlx5e_get_max_sq_aligned_wqebbs(struct mlx5_core_dev *mdev)\n{\n \n\tu8 wqebbs = mlx5e_get_max_sq_wqebbs(mdev);\n\n\twqebbs = min_t(u8, wqebbs, MLX5_SEND_WQE_MAX_WQEBBS - 1);\n#if L1_CACHE_BYTES >= 128\n\twqebbs = ALIGN_DOWN(wqebbs, 2);\n#endif\n\treturn wqebbs;\n}\n\nstruct mlx5e_tx_wqe {\n\tstruct mlx5_wqe_ctrl_seg ctrl;\n\tstruct mlx5_wqe_eth_seg  eth;\n\tstruct mlx5_wqe_data_seg data[];\n};\n\nstruct mlx5e_rx_wqe_ll {\n\tstruct mlx5_wqe_srq_next_seg  next;\n\tstruct mlx5_wqe_data_seg      data[];\n};\n\nstruct mlx5e_rx_wqe_cyc {\n\tDECLARE_FLEX_ARRAY(struct mlx5_wqe_data_seg, data);\n};\n\nstruct mlx5e_umr_wqe {\n\tstruct mlx5_wqe_ctrl_seg       ctrl;\n\tstruct mlx5_wqe_umr_ctrl_seg   uctrl;\n\tstruct mlx5_mkey_seg           mkc;\n\tunion {\n\t\tDECLARE_FLEX_ARRAY(struct mlx5_mtt, inline_mtts);\n\t\tDECLARE_FLEX_ARRAY(struct mlx5_klm, inline_klms);\n\t\tDECLARE_FLEX_ARRAY(struct mlx5_ksm, inline_ksms);\n\t};\n};\n\nenum mlx5e_priv_flag {\n\tMLX5E_PFLAG_RX_CQE_BASED_MODER,\n\tMLX5E_PFLAG_TX_CQE_BASED_MODER,\n\tMLX5E_PFLAG_RX_CQE_COMPRESS,\n\tMLX5E_PFLAG_RX_STRIDING_RQ,\n\tMLX5E_PFLAG_RX_NO_CSUM_COMPLETE,\n\tMLX5E_PFLAG_XDP_TX_MPWQE,\n\tMLX5E_PFLAG_SKB_TX_MPWQE,\n\tMLX5E_PFLAG_TX_PORT_TS,\n\tMLX5E_NUM_PFLAGS,  \n};\n\n#define MLX5E_SET_PFLAG(params, pflag, enable)\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tif (enable)\t\t\t\t\t\\\n\t\t\t(params)->pflags |= BIT(pflag);\t\t\\\n\t\telse\t\t\t\t\t\t\\\n\t\t\t(params)->pflags &= ~(BIT(pflag));\t\\\n\t} while (0)\n\n#define MLX5E_GET_PFLAG(params, pflag) (!!((params)->pflags & (BIT(pflag))))\n\nenum packet_merge {\n\tMLX5E_PACKET_MERGE_NONE,\n\tMLX5E_PACKET_MERGE_LRO,\n\tMLX5E_PACKET_MERGE_SHAMPO,\n};\n\nstruct mlx5e_packet_merge_param {\n\tenum packet_merge type;\n\tu32 timeout;\n\tstruct {\n\t\tu8 match_criteria_type;\n\t\tu8 alignment_granularity;\n\t} shampo;\n};\n\nstruct mlx5e_params {\n\tu8  log_sq_size;\n\tu8  rq_wq_type;\n\tu8  log_rq_mtu_frames;\n\tu16 num_channels;\n\tstruct {\n\t\tu16 mode;\n\t\tu8 num_tc;\n\t\tstruct netdev_tc_txq tc_to_txq[TC_MAX_QUEUE];\n\t\tstruct {\n\t\t\tu64 max_rate[TC_MAX_QUEUE];\n\t\t\tu32 hw_id[TC_MAX_QUEUE];\n\t\t} channel;\n\t} mqprio;\n\tbool rx_cqe_compress_def;\n\tstruct dim_cq_moder rx_cq_moderation;\n\tstruct dim_cq_moder tx_cq_moderation;\n\tstruct mlx5e_packet_merge_param packet_merge;\n\tu8  tx_min_inline_mode;\n\tbool vlan_strip_disable;\n\tbool scatter_fcs_en;\n\tbool rx_dim_enabled;\n\tbool tx_dim_enabled;\n\tu32 pflags;\n\tstruct bpf_prog *xdp_prog;\n\tstruct mlx5e_xsk *xsk;\n\tunsigned int sw_mtu;\n\tint hard_mtu;\n\tbool ptp_rx;\n\t__be32 terminate_lkey_be;\n};\n\nstatic inline u8 mlx5e_get_dcb_num_tc(struct mlx5e_params *params)\n{\n\treturn params->mqprio.mode == TC_MQPRIO_MODE_DCB ?\n\t\tparams->mqprio.num_tc : 1;\n}\n\n \nenum {\n\tMLX5E_RQ_STATE_ENABLED = 0,\n\tMLX5E_RQ_STATE_RECOVERING,\n\tMLX5E_RQ_STATE_DIM,\n\tMLX5E_RQ_STATE_NO_CSUM_COMPLETE,\n\tMLX5E_RQ_STATE_CSUM_FULL,  \n\tMLX5E_RQ_STATE_MINI_CQE_HW_STRIDX,  \n\tMLX5E_RQ_STATE_SHAMPO,  \n\tMLX5E_RQ_STATE_MINI_CQE_ENHANCED,   \n\tMLX5E_RQ_STATE_XSK,  \n\tMLX5E_NUM_RQ_STATES,  \n};\n\nstruct mlx5e_cq {\n\t \n\tstruct mlx5_cqwq           wq;\n\n\t \n\tu16                        event_ctr;\n\tstruct napi_struct        *napi;\n\tstruct mlx5_core_cq        mcq;\n\tstruct mlx5e_ch_stats     *ch_stats;\n\n\t \n\tstruct net_device         *netdev;\n\tstruct mlx5_core_dev      *mdev;\n\tstruct mlx5e_priv         *priv;\n\tstruct mlx5_wq_ctrl        wq_ctrl;\n} ____cacheline_aligned_in_smp;\n\nstruct mlx5e_cq_decomp {\n\t \n\tstruct mlx5_cqe64          title;\n\tstruct mlx5_mini_cqe8      mini_arr[MLX5_MINI_CQE_ARRAY_SIZE];\n\tu8                         mini_arr_idx;\n\tu16                        left;\n\tu16                        wqe_counter;\n\tbool                       last_cqe_title;\n} ____cacheline_aligned_in_smp;\n\nenum mlx5e_dma_map_type {\n\tMLX5E_DMA_MAP_SINGLE,\n\tMLX5E_DMA_MAP_PAGE\n};\n\nstruct mlx5e_sq_dma {\n\tdma_addr_t              addr;\n\tu32                     size;\n\tenum mlx5e_dma_map_type type;\n};\n\n \nenum {\n\tMLX5E_SQ_STATE_ENABLED = 0,\n\tMLX5E_SQ_STATE_MPWQE,\n\tMLX5E_SQ_STATE_RECOVERING,\n\tMLX5E_SQ_STATE_IPSEC,\n\tMLX5E_SQ_STATE_DIM,\n\tMLX5E_SQ_STATE_VLAN_NEED_L2_INLINE,\n\tMLX5E_SQ_STATE_PENDING_XSK_TX,\n\tMLX5E_SQ_STATE_PENDING_TLS_RX_RESYNC,\n\tMLX5E_SQ_STATE_XDP_MULTIBUF,\n\tMLX5E_NUM_SQ_STATES,  \n};\n\nstruct mlx5e_tx_mpwqe {\n\t \n\tstruct mlx5e_tx_wqe *wqe;\n\tu32 bytes_count;\n\tu8 ds_count;\n\tu8 pkt_count;\n\tu8 inline_on;\n};\n\nstruct mlx5e_skb_fifo {\n\tstruct sk_buff **fifo;\n\tu16 *pc;\n\tu16 *cc;\n\tu16 mask;\n};\n\nstruct mlx5e_ptpsq;\n\nstruct mlx5e_txqsq {\n\t \n\n\t \n\tu16                        cc;\n\tu16                        skb_fifo_cc;\n\tu32                        dma_fifo_cc;\n\tstruct dim                 dim;  \n\n\t \n\tu16                        pc ____cacheline_aligned_in_smp;\n\tu16                        skb_fifo_pc;\n\tu32                        dma_fifo_pc;\n\tstruct mlx5e_tx_mpwqe      mpwqe;\n\n\tstruct mlx5e_cq            cq;\n\n\t \n\tstruct mlx5_wq_cyc         wq;\n\tu32                        dma_fifo_mask;\n\tstruct mlx5e_sq_stats     *stats;\n\tstruct {\n\t\tstruct mlx5e_sq_dma       *dma_fifo;\n\t\tstruct mlx5e_skb_fifo      skb_fifo;\n\t\tstruct mlx5e_tx_wqe_info  *wqe_info;\n\t} db;\n\tvoid __iomem              *uar_map;\n\tstruct netdev_queue       *txq;\n\tu32                        sqn;\n\tu16                        stop_room;\n\tu8                         max_sq_mpw_wqebbs;\n\tu8                         min_inline_mode;\n\tstruct device             *pdev;\n\t__be32                     mkey_be;\n\tunsigned long              state;\n\tunsigned int               hw_mtu;\n\tstruct mlx5_clock         *clock;\n\tstruct net_device         *netdev;\n\tstruct mlx5_core_dev      *mdev;\n\tstruct mlx5e_channel      *channel;\n\tstruct mlx5e_priv         *priv;\n\n\t \n\tstruct mlx5_wq_ctrl        wq_ctrl;\n\tint                        ch_ix;\n\tint                        txq_ix;\n\tu32                        rate_limit;\n\tstruct work_struct         recover_work;\n\tstruct mlx5e_ptpsq        *ptpsq;\n\tcqe_ts_to_ns               ptp_cyc2time;\n} ____cacheline_aligned_in_smp;\n\nstruct mlx5e_xdp_info_fifo {\n\tunion mlx5e_xdp_info *xi;\n\tu32 *cc;\n\tu32 *pc;\n\tu32 mask;\n};\n\nstruct mlx5e_xdpsq;\nstruct mlx5e_xmit_data;\ntypedef int (*mlx5e_fp_xmit_xdp_frame_check)(struct mlx5e_xdpsq *);\ntypedef bool (*mlx5e_fp_xmit_xdp_frame)(struct mlx5e_xdpsq *,\n\t\t\t\t\tstruct mlx5e_xmit_data *,\n\t\t\t\t\tint);\n\nstruct mlx5e_xdpsq {\n\t \n\n\t \n\tu32                        xdpi_fifo_cc;\n\tu16                        cc;\n\n\t \n\tu32                        xdpi_fifo_pc ____cacheline_aligned_in_smp;\n\tu16                        pc;\n\tstruct mlx5_wqe_ctrl_seg   *doorbell_cseg;\n\tstruct mlx5e_tx_mpwqe      mpwqe;\n\n\tstruct mlx5e_cq            cq;\n\n\t \n\tstruct xsk_buff_pool      *xsk_pool;\n\tstruct mlx5_wq_cyc         wq;\n\tstruct mlx5e_xdpsq_stats  *stats;\n\tmlx5e_fp_xmit_xdp_frame_check xmit_xdp_frame_check;\n\tmlx5e_fp_xmit_xdp_frame    xmit_xdp_frame;\n\tstruct {\n\t\tstruct mlx5e_xdp_wqe_info *wqe_info;\n\t\tstruct mlx5e_xdp_info_fifo xdpi_fifo;\n\t} db;\n\tvoid __iomem              *uar_map;\n\tu32                        sqn;\n\tstruct device             *pdev;\n\t__be32                     mkey_be;\n\tu16                        stop_room;\n\tu8                         max_sq_mpw_wqebbs;\n\tu8                         min_inline_mode;\n\tunsigned long              state;\n\tunsigned int               hw_mtu;\n\n\t \n\tstruct mlx5_wq_ctrl        wq_ctrl;\n\tstruct mlx5e_channel      *channel;\n} ____cacheline_aligned_in_smp;\n\nstruct mlx5e_ktls_resync_resp;\n\nstruct mlx5e_icosq {\n\t \n\tu16                        cc;\n\tu16                        pc;\n\n\tstruct mlx5_wqe_ctrl_seg  *doorbell_cseg;\n\tstruct mlx5e_cq            cq;\n\n\t \n\tstruct {\n\t\tstruct mlx5e_icosq_wqe_info *wqe_info;\n\t} db;\n\n\t \n\tstruct mlx5_wq_cyc         wq;\n\tvoid __iomem              *uar_map;\n\tu32                        sqn;\n\tu16                        reserved_room;\n\tunsigned long              state;\n\tstruct mlx5e_ktls_resync_resp *ktls_resync;\n\n\t \n\tstruct mlx5_wq_ctrl        wq_ctrl;\n\tstruct mlx5e_channel      *channel;\n\n\tstruct work_struct         recover_work;\n} ____cacheline_aligned_in_smp;\n\nstruct mlx5e_frag_page {\n\tstruct page *page;\n\tu16 frags;\n};\n\nenum mlx5e_wqe_frag_flag {\n\tMLX5E_WQE_FRAG_LAST_IN_PAGE,\n\tMLX5E_WQE_FRAG_SKIP_RELEASE,\n};\n\nstruct mlx5e_wqe_frag_info {\n\tunion {\n\t\tstruct mlx5e_frag_page *frag_page;\n\t\tstruct xdp_buff **xskp;\n\t};\n\tu32 offset;\n\tu8 flags;\n};\n\nunion mlx5e_alloc_units {\n\tDECLARE_FLEX_ARRAY(struct mlx5e_frag_page, frag_pages);\n\tDECLARE_FLEX_ARRAY(struct page *, pages);\n\tDECLARE_FLEX_ARRAY(struct xdp_buff *, xsk_buffs);\n};\n\nstruct mlx5e_mpw_info {\n\tu16 consumed_strides;\n\tDECLARE_BITMAP(skip_release_bitmap, MLX5_MPWRQ_MAX_PAGES_PER_WQE);\n\tstruct mlx5e_frag_page linear_page;\n\tunion mlx5e_alloc_units alloc_units;\n};\n\n#define MLX5E_MAX_RX_FRAGS 4\n\nstruct mlx5e_rq;\ntypedef void (*mlx5e_fp_handle_rx_cqe)(struct mlx5e_rq*, struct mlx5_cqe64*);\ntypedef struct sk_buff *\n(*mlx5e_fp_skb_from_cqe_mpwrq)(struct mlx5e_rq *rq, struct mlx5e_mpw_info *wi,\n\t\t\t       struct mlx5_cqe64 *cqe, u16 cqe_bcnt,\n\t\t\t       u32 head_offset, u32 page_idx);\ntypedef struct sk_buff *\n(*mlx5e_fp_skb_from_cqe)(struct mlx5e_rq *rq, struct mlx5e_wqe_frag_info *wi,\n\t\t\t struct mlx5_cqe64 *cqe, u32 cqe_bcnt);\ntypedef bool (*mlx5e_fp_post_rx_wqes)(struct mlx5e_rq *rq);\ntypedef void (*mlx5e_fp_dealloc_wqe)(struct mlx5e_rq*, u16);\ntypedef void (*mlx5e_fp_shampo_dealloc_hd)(struct mlx5e_rq*, u16, u16, bool);\n\nint mlx5e_rq_set_handlers(struct mlx5e_rq *rq, struct mlx5e_params *params, bool xsk);\nvoid mlx5e_rq_set_trap_handlers(struct mlx5e_rq *rq, struct mlx5e_params *params);\n\nenum mlx5e_rq_flag {\n\tMLX5E_RQ_FLAG_XDP_XMIT,\n\tMLX5E_RQ_FLAG_XDP_REDIRECT,\n};\n\nstruct mlx5e_rq_frag_info {\n\tint frag_size;\n\tint frag_stride;\n};\n\nstruct mlx5e_rq_frags_info {\n\tstruct mlx5e_rq_frag_info arr[MLX5E_MAX_RX_FRAGS];\n\tu8 num_frags;\n\tu8 log_num_frags;\n\tu16 wqe_bulk;\n\tu16 refill_unit;\n\tu8 wqe_index_mask;\n};\n\nstruct mlx5e_dma_info {\n\tdma_addr_t addr;\n\tunion {\n\t\tstruct mlx5e_frag_page *frag_page;\n\t\tstruct page *page;\n\t};\n};\n\nstruct mlx5e_shampo_hd {\n\tu32 mkey;\n\tstruct mlx5e_dma_info *info;\n\tstruct mlx5e_frag_page *pages;\n\tu16 curr_page_index;\n\tu16 hd_per_wq;\n\tu16 hd_per_wqe;\n\tunsigned long *bitmap;\n\tu16 pi;\n\tu16 ci;\n\t__be32 key;\n\tu64 last_addr;\n};\n\nstruct mlx5e_hw_gro_data {\n\tstruct sk_buff *skb;\n\tstruct flow_keys fk;\n\tint second_ip_id;\n};\n\nenum mlx5e_mpwrq_umr_mode {\n\tMLX5E_MPWRQ_UMR_MODE_ALIGNED,\n\tMLX5E_MPWRQ_UMR_MODE_UNALIGNED,\n\tMLX5E_MPWRQ_UMR_MODE_OVERSIZED,\n\tMLX5E_MPWRQ_UMR_MODE_TRIPLE,\n};\n\nstruct mlx5e_rq {\n\t \n\tunion {\n\t\tstruct {\n\t\t\tstruct mlx5_wq_cyc          wq;\n\t\t\tstruct mlx5e_wqe_frag_info *frags;\n\t\t\tunion mlx5e_alloc_units    *alloc_units;\n\t\t\tstruct mlx5e_rq_frags_info  info;\n\t\t\tmlx5e_fp_skb_from_cqe       skb_from_cqe;\n\t\t} wqe;\n\t\tstruct {\n\t\t\tstruct mlx5_wq_ll      wq;\n\t\t\tstruct mlx5e_umr_wqe   umr_wqe;\n\t\t\tstruct mlx5e_mpw_info *info;\n\t\t\tmlx5e_fp_skb_from_cqe_mpwrq skb_from_cqe_mpwrq;\n\t\t\t__be32                 umr_mkey_be;\n\t\t\tu16                    num_strides;\n\t\t\tu16                    actual_wq_head;\n\t\t\tu8                     log_stride_sz;\n\t\t\tu8                     umr_in_progress;\n\t\t\tu8                     umr_last_bulk;\n\t\t\tu8                     umr_completed;\n\t\t\tu8                     min_wqe_bulk;\n\t\t\tu8                     page_shift;\n\t\t\tu8                     pages_per_wqe;\n\t\t\tu8                     umr_wqebbs;\n\t\t\tu8                     mtts_per_wqe;\n\t\t\tu8                     umr_mode;\n\t\t\tstruct mlx5e_shampo_hd *shampo;\n\t\t} mpwqe;\n\t};\n\tstruct {\n\t\tu16            headroom;\n\t\tu32            frame0_sz;\n\t\tu8             map_dir;    \n\t} buff;\n\n\tstruct device         *pdev;\n\tstruct net_device     *netdev;\n\tstruct mlx5e_rq_stats *stats;\n\tstruct mlx5e_cq        cq;\n\tstruct mlx5e_cq_decomp cqd;\n\tstruct hwtstamp_config *tstamp;\n\tstruct mlx5_clock      *clock;\n\tstruct mlx5e_icosq    *icosq;\n\tstruct mlx5e_priv     *priv;\n\n\tstruct mlx5e_hw_gro_data *hw_gro_data;\n\n\tmlx5e_fp_handle_rx_cqe handle_rx_cqe;\n\tmlx5e_fp_post_rx_wqes  post_wqes;\n\tmlx5e_fp_dealloc_wqe   dealloc_wqe;\n\n\tunsigned long          state;\n\tint                    ix;\n\tunsigned int           hw_mtu;\n\n\tstruct dim         dim;  \n\n\t \n\tstruct bpf_prog __rcu *xdp_prog;\n\tstruct mlx5e_xdpsq    *xdpsq;\n\tDECLARE_BITMAP(flags, 8);\n\tstruct page_pool      *page_pool;\n\n\t \n\tstruct xsk_buff_pool  *xsk_pool;\n\n\tstruct work_struct     recover_work;\n\n\t \n\tstruct mlx5_wq_ctrl    wq_ctrl;\n\t__be32                 mkey_be;\n\tu8                     wq_type;\n\tu32                    rqn;\n\tstruct mlx5_core_dev  *mdev;\n\tstruct mlx5e_channel  *channel;\n\tstruct mlx5e_dma_info  wqe_overflow;\n\n\t \n\tstruct xdp_rxq_info    xdp_rxq;\n\tcqe_ts_to_ns           ptp_cyc2time;\n} ____cacheline_aligned_in_smp;\n\nenum mlx5e_channel_state {\n\tMLX5E_CHANNEL_STATE_XSK,\n\tMLX5E_CHANNEL_NUM_STATES\n};\n\nstruct mlx5e_channel {\n\t \n\tstruct mlx5e_rq            rq;\n\tstruct mlx5e_xdpsq         rq_xdpsq;\n\tstruct mlx5e_txqsq         sq[MLX5E_MAX_NUM_TC];\n\tstruct mlx5e_icosq         icosq;    \n\tstruct mlx5e_txqsq __rcu * __rcu *qos_sqs;\n\tbool                       xdp;\n\tstruct napi_struct         napi;\n\tstruct device             *pdev;\n\tstruct net_device         *netdev;\n\t__be32                     mkey_be;\n\tu16                        qos_sqs_size;\n\tu8                         num_tc;\n\tu8                         lag_port;\n\n\t \n\tstruct mlx5e_xdpsq         xdpsq;\n\n\t \n\tstruct mlx5e_rq            xskrq;\n\tstruct mlx5e_xdpsq         xsksq;\n\n\t \n\tstruct mlx5e_icosq         async_icosq;\n\t \n\tspinlock_t                 async_icosq_lock;\n\n\t \n\tconst struct cpumask\t  *aff_mask;\n\tstruct mlx5e_ch_stats     *stats;\n\n\t \n\tstruct mlx5e_priv         *priv;\n\tstruct mlx5_core_dev      *mdev;\n\tstruct hwtstamp_config    *tstamp;\n\tDECLARE_BITMAP(state, MLX5E_CHANNEL_NUM_STATES);\n\tint                        ix;\n\tint                        cpu;\n\t \n\tstruct mutex               icosq_recovery_lock;\n};\n\nstruct mlx5e_ptp;\n\nstruct mlx5e_channels {\n\tstruct mlx5e_channel **c;\n\tstruct mlx5e_ptp      *ptp;\n\tunsigned int           num;\n\tstruct mlx5e_params    params;\n};\n\nstruct mlx5e_channel_stats {\n\tstruct mlx5e_ch_stats ch;\n\tstruct mlx5e_sq_stats sq[MLX5E_MAX_NUM_TC];\n\tstruct mlx5e_rq_stats rq;\n\tstruct mlx5e_rq_stats xskrq;\n\tstruct mlx5e_xdpsq_stats rq_xdpsq;\n\tstruct mlx5e_xdpsq_stats xdpsq;\n\tstruct mlx5e_xdpsq_stats xsksq;\n} ____cacheline_aligned_in_smp;\n\nstruct mlx5e_ptp_stats {\n\tstruct mlx5e_ch_stats ch;\n\tstruct mlx5e_sq_stats sq[MLX5E_MAX_NUM_TC];\n\tstruct mlx5e_ptp_cq_stats cq[MLX5E_MAX_NUM_TC];\n\tstruct mlx5e_rq_stats rq;\n} ____cacheline_aligned_in_smp;\n\nenum {\n\tMLX5E_STATE_OPENED,\n\tMLX5E_STATE_DESTROYING,\n\tMLX5E_STATE_XDP_TX_ENABLED,\n\tMLX5E_STATE_XDP_ACTIVE,\n\tMLX5E_STATE_CHANNELS_ACTIVE,\n};\n\nstruct mlx5e_modify_sq_param {\n\tint curr_state;\n\tint next_state;\n\tint rl_update;\n\tint rl_index;\n\tbool qos_update;\n\tu16 qos_queue_group_id;\n};\n\n#if IS_ENABLED(CONFIG_PCI_HYPERV_INTERFACE)\nstruct mlx5e_hv_vhca_stats_agent {\n\tstruct mlx5_hv_vhca_agent *agent;\n\tstruct delayed_work        work;\n\tu16                        delay;\n\tvoid                      *buf;\n};\n#endif\n\nstruct mlx5e_xsk {\n\t \n\tstruct xsk_buff_pool **pools;\n\tu16 refcnt;\n\tbool ever_used;\n};\n\n \nstruct mlx5e_scratchpad {\n\tcpumask_var_t cpumask;\n};\n\nstruct mlx5e_trap;\nstruct mlx5e_htb;\n\nstruct mlx5e_priv {\n\t \n\tstruct mlx5e_selq selq;\n\tstruct mlx5e_txqsq **txq2sq;\n#ifdef CONFIG_MLX5_CORE_EN_DCB\n\tstruct mlx5e_dcbx_dp       dcbx_dp;\n#endif\n\t \n\n\tunsigned long              state;\n\tstruct mutex               state_lock;  \n\tstruct mlx5e_rq            drop_rq;\n\n\tstruct mlx5e_channels      channels;\n\tu32                        tisn[MLX5_MAX_PORTS][MLX5E_MAX_NUM_TC];\n\tstruct mlx5e_rx_res       *rx_res;\n\tu32                       *tx_rates;\n\n\tstruct mlx5e_flow_steering *fs;\n\n\tstruct workqueue_struct    *wq;\n\tstruct work_struct         update_carrier_work;\n\tstruct work_struct         set_rx_mode_work;\n\tstruct work_struct         tx_timeout_work;\n\tstruct work_struct         update_stats_work;\n\tstruct work_struct         monitor_counters_work;\n\tstruct mlx5_nb             monitor_counters_nb;\n\n\tstruct mlx5_core_dev      *mdev;\n\tstruct net_device         *netdev;\n\tstruct mlx5e_trap         *en_trap;\n\tstruct mlx5e_stats         stats;\n\tstruct mlx5e_channel_stats **channel_stats;\n\tstruct mlx5e_channel_stats trap_stats;\n\tstruct mlx5e_ptp_stats     ptp_stats;\n\tstruct mlx5e_sq_stats      **htb_qos_sq_stats;\n\tu16                        htb_max_qos_sqs;\n\tu16                        stats_nch;\n\tu16                        max_nch;\n\tu8                         max_opened_tc;\n\tbool                       tx_ptp_opened;\n\tbool                       rx_ptp_opened;\n\tstruct hwtstamp_config     tstamp;\n\tu16                        q_counter;\n\tu16                        drop_rq_q_counter;\n\tstruct notifier_block      events_nb;\n\tstruct notifier_block      blocking_events_nb;\n\n\tstruct udp_tunnel_nic_info nic_info;\n#ifdef CONFIG_MLX5_CORE_EN_DCB\n\tstruct mlx5e_dcbx          dcbx;\n#endif\n\n\tconst struct mlx5e_profile *profile;\n\tvoid                      *ppriv;\n#ifdef CONFIG_MLX5_MACSEC\n\tstruct mlx5e_macsec       *macsec;\n#endif\n#ifdef CONFIG_MLX5_EN_IPSEC\n\tstruct mlx5e_ipsec        *ipsec;\n#endif\n#ifdef CONFIG_MLX5_EN_TLS\n\tstruct mlx5e_tls          *tls;\n#endif\n\tstruct devlink_health_reporter *tx_reporter;\n\tstruct devlink_health_reporter *rx_reporter;\n\tstruct mlx5e_xsk           xsk;\n#if IS_ENABLED(CONFIG_PCI_HYPERV_INTERFACE)\n\tstruct mlx5e_hv_vhca_stats_agent stats_agent;\n#endif\n\tstruct mlx5e_scratchpad    scratchpad;\n\tstruct mlx5e_htb          *htb;\n\tstruct mlx5e_mqprio_rl    *mqprio_rl;\n\tstruct dentry             *dfs_root;\n};\n\nstruct mlx5e_dev {\n\tstruct mlx5e_priv *priv;\n\tstruct devlink_port dl_port;\n};\n\nstruct mlx5e_rx_handlers {\n\tmlx5e_fp_handle_rx_cqe handle_rx_cqe;\n\tmlx5e_fp_handle_rx_cqe handle_rx_cqe_mpwqe;\n\tmlx5e_fp_handle_rx_cqe handle_rx_cqe_mpwqe_shampo;\n};\n\nextern const struct mlx5e_rx_handlers mlx5e_rx_handlers_nic;\n\nenum mlx5e_profile_feature {\n\tMLX5E_PROFILE_FEATURE_PTP_RX,\n\tMLX5E_PROFILE_FEATURE_PTP_TX,\n\tMLX5E_PROFILE_FEATURE_QOS_HTB,\n\tMLX5E_PROFILE_FEATURE_FS_VLAN,\n\tMLX5E_PROFILE_FEATURE_FS_TC,\n};\n\nstruct mlx5e_profile {\n\tint\t(*init)(struct mlx5_core_dev *mdev,\n\t\t\tstruct net_device *netdev);\n\tvoid\t(*cleanup)(struct mlx5e_priv *priv);\n\tint\t(*init_rx)(struct mlx5e_priv *priv);\n\tvoid\t(*cleanup_rx)(struct mlx5e_priv *priv);\n\tint\t(*init_tx)(struct mlx5e_priv *priv);\n\tvoid\t(*cleanup_tx)(struct mlx5e_priv *priv);\n\tvoid\t(*enable)(struct mlx5e_priv *priv);\n\tvoid\t(*disable)(struct mlx5e_priv *priv);\n\tint\t(*update_rx)(struct mlx5e_priv *priv);\n\tvoid\t(*update_stats)(struct mlx5e_priv *priv);\n\tvoid\t(*update_carrier)(struct mlx5e_priv *priv);\n\tint\t(*max_nch_limit)(struct mlx5_core_dev *mdev);\n\tunsigned int (*stats_grps_num)(struct mlx5e_priv *priv);\n\tmlx5e_stats_grp_t *stats_grps;\n\tconst struct mlx5e_rx_handlers *rx_handlers;\n\tint\tmax_tc;\n\tu32     features;\n};\n\n#define mlx5e_profile_feature_cap(profile, feature)\t\\\n\t((profile)->features & BIT(MLX5E_PROFILE_FEATURE_##feature))\n\nvoid mlx5e_build_ptys2ethtool_map(void);\n\nbool mlx5e_check_fragmented_striding_rq_cap(struct mlx5_core_dev *mdev, u8 page_shift,\n\t\t\t\t\t    enum mlx5e_mpwrq_umr_mode umr_mode);\n\nvoid mlx5e_shampo_dealloc_hd(struct mlx5e_rq *rq, u16 len, u16 start, bool close);\nvoid mlx5e_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats);\nvoid mlx5e_fold_sw_stats64(struct mlx5e_priv *priv, struct rtnl_link_stats64 *s);\n\nint mlx5e_self_test_num(struct mlx5e_priv *priv);\nint mlx5e_self_test_fill_strings(struct mlx5e_priv *priv, u8 *data);\nvoid mlx5e_self_test(struct net_device *ndev, struct ethtool_test *etest,\n\t\t     u64 *buf);\nvoid mlx5e_set_rx_mode_work(struct work_struct *work);\n\nint mlx5e_hwstamp_set(struct mlx5e_priv *priv, struct ifreq *ifr);\nint mlx5e_hwstamp_get(struct mlx5e_priv *priv, struct ifreq *ifr);\nint mlx5e_modify_rx_cqe_compression_locked(struct mlx5e_priv *priv, bool val, bool rx_filter);\n\nint mlx5e_vlan_rx_add_vid(struct net_device *dev, __always_unused __be16 proto,\n\t\t\t  u16 vid);\nint mlx5e_vlan_rx_kill_vid(struct net_device *dev, __always_unused __be16 proto,\n\t\t\t   u16 vid);\nvoid mlx5e_timestamp_init(struct mlx5e_priv *priv);\n\nstruct mlx5e_xsk_param;\n\nstruct mlx5e_rq_param;\nint mlx5e_open_rq(struct mlx5e_params *params, struct mlx5e_rq_param *param,\n\t\t  struct mlx5e_xsk_param *xsk, int node,\n\t\t  struct mlx5e_rq *rq);\n#define MLX5E_RQ_WQES_TIMEOUT 20000  \nint mlx5e_wait_for_min_rx_wqes(struct mlx5e_rq *rq, int wait_time);\nvoid mlx5e_close_rq(struct mlx5e_rq *rq);\nint mlx5e_create_rq(struct mlx5e_rq *rq, struct mlx5e_rq_param *param);\nvoid mlx5e_destroy_rq(struct mlx5e_rq *rq);\n\nstruct mlx5e_sq_param;\nint mlx5e_open_xdpsq(struct mlx5e_channel *c, struct mlx5e_params *params,\n\t\t     struct mlx5e_sq_param *param, struct xsk_buff_pool *xsk_pool,\n\t\t     struct mlx5e_xdpsq *sq, bool is_redirect);\nvoid mlx5e_close_xdpsq(struct mlx5e_xdpsq *sq);\n\nstruct mlx5e_create_cq_param {\n\tstruct napi_struct *napi;\n\tstruct mlx5e_ch_stats *ch_stats;\n\tint node;\n\tint ix;\n};\n\nstruct mlx5e_cq_param;\nint mlx5e_open_cq(struct mlx5e_priv *priv, struct dim_cq_moder moder,\n\t\t  struct mlx5e_cq_param *param, struct mlx5e_create_cq_param *ccp,\n\t\t  struct mlx5e_cq *cq);\nvoid mlx5e_close_cq(struct mlx5e_cq *cq);\n\nint mlx5e_open_locked(struct net_device *netdev);\nint mlx5e_close_locked(struct net_device *netdev);\n\nvoid mlx5e_trigger_napi_icosq(struct mlx5e_channel *c);\nvoid mlx5e_trigger_napi_sched(struct napi_struct *napi);\n\nint mlx5e_open_channels(struct mlx5e_priv *priv,\n\t\t\tstruct mlx5e_channels *chs);\nvoid mlx5e_close_channels(struct mlx5e_channels *chs);\n\n \ntypedef int (*mlx5e_fp_preactivate)(struct mlx5e_priv *priv, void *context);\n#define MLX5E_DEFINE_PREACTIVATE_WRAPPER_CTX(fn) \\\nint fn##_ctx(struct mlx5e_priv *priv, void *context) \\\n{ \\\n\treturn fn(priv); \\\n}\nint mlx5e_safe_reopen_channels(struct mlx5e_priv *priv);\nint mlx5e_safe_switch_params(struct mlx5e_priv *priv,\n\t\t\t     struct mlx5e_params *new_params,\n\t\t\t     mlx5e_fp_preactivate preactivate,\n\t\t\t     void *context, bool reset);\nint mlx5e_update_tx_netdev_queues(struct mlx5e_priv *priv);\nint mlx5e_num_channels_changed_ctx(struct mlx5e_priv *priv, void *context);\nvoid mlx5e_activate_priv_channels(struct mlx5e_priv *priv);\nvoid mlx5e_deactivate_priv_channels(struct mlx5e_priv *priv);\nint mlx5e_ptp_rx_manage_fs_ctx(struct mlx5e_priv *priv, void *ctx);\n\nint mlx5e_flush_rq(struct mlx5e_rq *rq, int curr_state);\nvoid mlx5e_activate_rq(struct mlx5e_rq *rq);\nvoid mlx5e_deactivate_rq(struct mlx5e_rq *rq);\nvoid mlx5e_activate_icosq(struct mlx5e_icosq *icosq);\nvoid mlx5e_deactivate_icosq(struct mlx5e_icosq *icosq);\n\nint mlx5e_modify_sq(struct mlx5_core_dev *mdev, u32 sqn,\n\t\t    struct mlx5e_modify_sq_param *p);\nint mlx5e_open_txqsq(struct mlx5e_channel *c, u32 tisn, int txq_ix,\n\t\t     struct mlx5e_params *params, struct mlx5e_sq_param *param,\n\t\t     struct mlx5e_txqsq *sq, int tc, u16 qos_queue_group_id,\n\t\t     struct mlx5e_sq_stats *sq_stats);\nvoid mlx5e_activate_txqsq(struct mlx5e_txqsq *sq);\nvoid mlx5e_deactivate_txqsq(struct mlx5e_txqsq *sq);\nvoid mlx5e_free_txqsq(struct mlx5e_txqsq *sq);\nvoid mlx5e_tx_disable_queue(struct netdev_queue *txq);\nint mlx5e_alloc_txqsq_db(struct mlx5e_txqsq *sq, int numa);\nvoid mlx5e_free_txqsq_db(struct mlx5e_txqsq *sq);\nstruct mlx5e_create_sq_param;\nint mlx5e_create_sq_rdy(struct mlx5_core_dev *mdev,\n\t\t\tstruct mlx5e_sq_param *param,\n\t\t\tstruct mlx5e_create_sq_param *csp,\n\t\t\tu16 qos_queue_group_id,\n\t\t\tu32 *sqn);\nvoid mlx5e_tx_err_cqe_work(struct work_struct *recover_work);\nvoid mlx5e_close_txqsq(struct mlx5e_txqsq *sq);\n\nstatic inline bool mlx5_tx_swp_supported(struct mlx5_core_dev *mdev)\n{\n\treturn MLX5_CAP_ETH(mdev, swp) &&\n\t\tMLX5_CAP_ETH(mdev, swp_csum) && MLX5_CAP_ETH(mdev, swp_lso);\n}\n\nextern const struct ethtool_ops mlx5e_ethtool_ops;\n\nint mlx5e_create_mkey(struct mlx5_core_dev *mdev, u32 pdn, u32 *mkey);\nint mlx5e_create_mdev_resources(struct mlx5_core_dev *mdev);\nvoid mlx5e_destroy_mdev_resources(struct mlx5_core_dev *mdev);\nint mlx5e_refresh_tirs(struct mlx5e_priv *priv, bool enable_uc_lb,\n\t\t       bool enable_mc_lb);\nvoid mlx5e_mkey_set_relaxed_ordering(struct mlx5_core_dev *mdev, void *mkc);\n\n \nvoid mlx5e_create_q_counters(struct mlx5e_priv *priv);\nvoid mlx5e_destroy_q_counters(struct mlx5e_priv *priv);\nint mlx5e_open_drop_rq(struct mlx5e_priv *priv,\n\t\t       struct mlx5e_rq *drop_rq);\nvoid mlx5e_close_drop_rq(struct mlx5e_rq *drop_rq);\n\nint mlx5e_create_tis(struct mlx5_core_dev *mdev, void *in, u32 *tisn);\nvoid mlx5e_destroy_tis(struct mlx5_core_dev *mdev, u32 tisn);\n\nint mlx5e_create_tises(struct mlx5e_priv *priv);\nvoid mlx5e_destroy_tises(struct mlx5e_priv *priv);\nint mlx5e_update_nic_rx(struct mlx5e_priv *priv);\nvoid mlx5e_update_carrier(struct mlx5e_priv *priv);\nint mlx5e_close(struct net_device *netdev);\nint mlx5e_open(struct net_device *netdev);\n\nvoid mlx5e_queue_update_stats(struct mlx5e_priv *priv);\n\nint mlx5e_set_dev_port_mtu(struct mlx5e_priv *priv);\nint mlx5e_set_dev_port_mtu_ctx(struct mlx5e_priv *priv, void *context);\nint mlx5e_change_mtu(struct net_device *netdev, int new_mtu,\n\t\t     mlx5e_fp_preactivate preactivate);\nvoid mlx5e_vxlan_set_netdev_info(struct mlx5e_priv *priv);\n\n \nvoid mlx5e_ethtool_get_drvinfo(struct mlx5e_priv *priv,\n\t\t\t       struct ethtool_drvinfo *drvinfo);\nvoid mlx5e_ethtool_get_strings(struct mlx5e_priv *priv,\n\t\t\t       uint32_t stringset, uint8_t *data);\nint mlx5e_ethtool_get_sset_count(struct mlx5e_priv *priv, int sset);\nvoid mlx5e_ethtool_get_ethtool_stats(struct mlx5e_priv *priv,\n\t\t\t\t     struct ethtool_stats *stats, u64 *data);\nvoid mlx5e_ethtool_get_ringparam(struct mlx5e_priv *priv,\n\t\t\t\t struct ethtool_ringparam *param,\n\t\t\t\t struct kernel_ethtool_ringparam *kernel_param);\nint mlx5e_ethtool_set_ringparam(struct mlx5e_priv *priv,\n\t\t\t\tstruct ethtool_ringparam *param);\nvoid mlx5e_ethtool_get_channels(struct mlx5e_priv *priv,\n\t\t\t\tstruct ethtool_channels *ch);\nint mlx5e_ethtool_set_channels(struct mlx5e_priv *priv,\n\t\t\t       struct ethtool_channels *ch);\nint mlx5e_ethtool_get_coalesce(struct mlx5e_priv *priv,\n\t\t\t       struct ethtool_coalesce *coal,\n\t\t\t       struct kernel_ethtool_coalesce *kernel_coal);\nint mlx5e_ethtool_set_coalesce(struct mlx5e_priv *priv,\n\t\t\t       struct ethtool_coalesce *coal,\n\t\t\t       struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t       struct netlink_ext_ack *extack);\nint mlx5e_ethtool_get_link_ksettings(struct mlx5e_priv *priv,\n\t\t\t\t     struct ethtool_link_ksettings *link_ksettings);\nint mlx5e_ethtool_set_link_ksettings(struct mlx5e_priv *priv,\n\t\t\t\t     const struct ethtool_link_ksettings *link_ksettings);\nint mlx5e_get_rxfh(struct net_device *netdev, u32 *indir, u8 *key, u8 *hfunc);\nint mlx5e_set_rxfh(struct net_device *dev, const u32 *indir, const u8 *key,\n\t\t   const u8 hfunc);\nu32 mlx5e_ethtool_get_rxfh_key_size(struct mlx5e_priv *priv);\nu32 mlx5e_ethtool_get_rxfh_indir_size(struct mlx5e_priv *priv);\nint mlx5e_ethtool_get_ts_info(struct mlx5e_priv *priv,\n\t\t\t      struct ethtool_ts_info *info);\nint mlx5e_ethtool_flash_device(struct mlx5e_priv *priv,\n\t\t\t       struct ethtool_flash *flash);\nvoid mlx5e_ethtool_get_pauseparam(struct mlx5e_priv *priv,\n\t\t\t\t  struct ethtool_pauseparam *pauseparam);\nint mlx5e_ethtool_set_pauseparam(struct mlx5e_priv *priv,\n\t\t\t\t struct ethtool_pauseparam *pauseparam);\n\n \nstatic inline bool\nmlx5e_tx_mpwqe_supported(struct mlx5_core_dev *mdev)\n{\n\treturn !is_kdump_kernel() &&\n\t\tMLX5_CAP_ETH(mdev, enhanced_multi_pkt_send_wqe);\n}\n\nint mlx5e_get_pf_num_tirs(struct mlx5_core_dev *mdev);\nint mlx5e_priv_init(struct mlx5e_priv *priv,\n\t\t    const struct mlx5e_profile *profile,\n\t\t    struct net_device *netdev,\n\t\t    struct mlx5_core_dev *mdev);\nvoid mlx5e_priv_cleanup(struct mlx5e_priv *priv);\nstruct net_device *\nmlx5e_create_netdev(struct mlx5_core_dev *mdev, const struct mlx5e_profile *profile);\nint mlx5e_attach_netdev(struct mlx5e_priv *priv);\nvoid mlx5e_detach_netdev(struct mlx5e_priv *priv);\nvoid mlx5e_destroy_netdev(struct mlx5e_priv *priv);\nint mlx5e_netdev_change_profile(struct mlx5e_priv *priv,\n\t\t\t\tconst struct mlx5e_profile *new_profile, void *new_ppriv);\nvoid mlx5e_netdev_attach_nic_profile(struct mlx5e_priv *priv);\nvoid mlx5e_set_netdev_mtu_boundaries(struct mlx5e_priv *priv);\nvoid mlx5e_build_nic_params(struct mlx5e_priv *priv, struct mlx5e_xsk *xsk, u16 mtu);\nvoid mlx5e_rx_dim_work(struct work_struct *work);\nvoid mlx5e_tx_dim_work(struct work_struct *work);\n\nvoid mlx5e_set_xdp_feature(struct net_device *netdev);\nnetdev_features_t mlx5e_features_check(struct sk_buff *skb,\n\t\t\t\t       struct net_device *netdev,\n\t\t\t\t       netdev_features_t features);\nint mlx5e_set_features(struct net_device *netdev, netdev_features_t features);\n#ifdef CONFIG_MLX5_ESWITCH\nint mlx5e_set_vf_mac(struct net_device *dev, int vf, u8 *mac);\nint mlx5e_set_vf_rate(struct net_device *dev, int vf, int min_tx_rate, int max_tx_rate);\nint mlx5e_get_vf_config(struct net_device *dev, int vf, struct ifla_vf_info *ivi);\nint mlx5e_get_vf_stats(struct net_device *dev, int vf, struct ifla_vf_stats *vf_stats);\n#endif\nint mlx5e_create_mkey(struct mlx5_core_dev *mdev, u32 pdn, u32 *mkey);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}