{
  "module_name": "netsec.c",
  "hash_id": "46dc9c0ef91a5f57be9881dd4642126491265338788a396263422e7753633304",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/socionext/netsec.c",
  "human_readable_source": "\n\n#include <linux/types.h>\n#include <linux/clk.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/acpi.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n#include <linux/etherdevice.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/netlink.h>\n#include <linux/bpf.h>\n#include <linux/bpf_trace.h>\n\n#include <net/tcp.h>\n#include <net/page_pool/helpers.h>\n#include <net/ip6_checksum.h>\n\n#define NETSEC_REG_SOFT_RST\t\t\t0x104\n#define NETSEC_REG_COM_INIT\t\t\t0x120\n\n#define NETSEC_REG_TOP_STATUS\t\t\t0x200\n#define NETSEC_IRQ_RX\t\t\t\tBIT(1)\n#define NETSEC_IRQ_TX\t\t\t\tBIT(0)\n\n#define NETSEC_REG_TOP_INTEN\t\t\t0x204\n#define NETSEC_REG_INTEN_SET\t\t\t0x234\n#define NETSEC_REG_INTEN_CLR\t\t\t0x238\n\n#define NETSEC_REG_NRM_TX_STATUS\t\t0x400\n#define NETSEC_REG_NRM_TX_INTEN\t\t\t0x404\n#define NETSEC_REG_NRM_TX_INTEN_SET\t\t0x428\n#define NETSEC_REG_NRM_TX_INTEN_CLR\t\t0x42c\n#define NRM_TX_ST_NTOWNR\tBIT(17)\n#define NRM_TX_ST_TR_ERR\tBIT(16)\n#define NRM_TX_ST_TXDONE\tBIT(15)\n#define NRM_TX_ST_TMREXP\tBIT(14)\n\n#define NETSEC_REG_NRM_RX_STATUS\t\t0x440\n#define NETSEC_REG_NRM_RX_INTEN\t\t\t0x444\n#define NETSEC_REG_NRM_RX_INTEN_SET\t\t0x468\n#define NETSEC_REG_NRM_RX_INTEN_CLR\t\t0x46c\n#define NRM_RX_ST_RC_ERR\tBIT(16)\n#define NRM_RX_ST_PKTCNT\tBIT(15)\n#define NRM_RX_ST_TMREXP\tBIT(14)\n\n#define NETSEC_REG_PKT_CMD_BUF\t\t\t0xd0\n\n#define NETSEC_REG_CLK_EN\t\t\t0x100\n\n#define NETSEC_REG_PKT_CTRL\t\t\t0x140\n\n#define NETSEC_REG_DMA_TMR_CTRL\t\t\t0x20c\n#define NETSEC_REG_F_TAIKI_MC_VER\t\t0x22c\n#define NETSEC_REG_F_TAIKI_VER\t\t\t0x230\n#define NETSEC_REG_DMA_HM_CTRL\t\t\t0x214\n#define NETSEC_REG_DMA_MH_CTRL\t\t\t0x220\n#define NETSEC_REG_ADDR_DIS_CORE\t\t0x218\n#define NETSEC_REG_DMAC_HM_CMD_BUF\t\t0x210\n#define NETSEC_REG_DMAC_MH_CMD_BUF\t\t0x21c\n\n#define NETSEC_REG_NRM_TX_PKTCNT\t\t0x410\n\n#define NETSEC_REG_NRM_TX_DONE_PKTCNT\t\t0x414\n#define NETSEC_REG_NRM_TX_DONE_TXINT_PKTCNT\t0x418\n\n#define NETSEC_REG_NRM_TX_TMR\t\t\t0x41c\n\n#define NETSEC_REG_NRM_RX_PKTCNT\t\t0x454\n#define NETSEC_REG_NRM_RX_RXINT_PKTCNT\t\t0x458\n#define NETSEC_REG_NRM_TX_TXINT_TMR\t\t0x420\n#define NETSEC_REG_NRM_RX_RXINT_TMR\t\t0x460\n\n#define NETSEC_REG_NRM_RX_TMR\t\t\t0x45c\n\n#define NETSEC_REG_NRM_TX_DESC_START_UP\t\t0x434\n#define NETSEC_REG_NRM_TX_DESC_START_LW\t\t0x408\n#define NETSEC_REG_NRM_RX_DESC_START_UP\t\t0x474\n#define NETSEC_REG_NRM_RX_DESC_START_LW\t\t0x448\n\n#define NETSEC_REG_NRM_TX_CONFIG\t\t0x430\n#define NETSEC_REG_NRM_RX_CONFIG\t\t0x470\n\n#define MAC_REG_STATUS\t\t\t\t0x1024\n#define MAC_REG_DATA\t\t\t\t0x11c0\n#define MAC_REG_CMD\t\t\t\t0x11c4\n#define MAC_REG_FLOW_TH\t\t\t\t0x11cc\n#define MAC_REG_INTF_SEL\t\t\t0x11d4\n#define MAC_REG_DESC_INIT\t\t\t0x11fc\n#define MAC_REG_DESC_SOFT_RST\t\t\t0x1204\n#define NETSEC_REG_MODE_TRANS_COMP_STATUS\t0x500\n\n#define GMAC_REG_MCR\t\t\t\t0x0000\n#define GMAC_REG_MFFR\t\t\t\t0x0004\n#define GMAC_REG_GAR\t\t\t\t0x0010\n#define GMAC_REG_GDR\t\t\t\t0x0014\n#define GMAC_REG_FCR\t\t\t\t0x0018\n#define GMAC_REG_BMR\t\t\t\t0x1000\n#define GMAC_REG_RDLAR\t\t\t\t0x100c\n#define GMAC_REG_TDLAR\t\t\t\t0x1010\n#define GMAC_REG_OMR\t\t\t\t0x1018\n\n#define MHZ(n)\t\t((n) * 1000 * 1000)\n\n#define NETSEC_TX_SHIFT_OWN_FIELD\t\t31\n#define NETSEC_TX_SHIFT_LD_FIELD\t\t30\n#define NETSEC_TX_SHIFT_DRID_FIELD\t\t24\n#define NETSEC_TX_SHIFT_PT_FIELD\t\t21\n#define NETSEC_TX_SHIFT_TDRID_FIELD\t\t16\n#define NETSEC_TX_SHIFT_CC_FIELD\t\t15\n#define NETSEC_TX_SHIFT_FS_FIELD\t\t9\n#define NETSEC_TX_LAST\t\t\t\t8\n#define NETSEC_TX_SHIFT_CO\t\t\t7\n#define NETSEC_TX_SHIFT_SO\t\t\t6\n#define NETSEC_TX_SHIFT_TRS_FIELD\t\t4\n\n#define NETSEC_RX_PKT_OWN_FIELD\t\t\t31\n#define NETSEC_RX_PKT_LD_FIELD\t\t\t30\n#define NETSEC_RX_PKT_SDRID_FIELD\t\t24\n#define NETSEC_RX_PKT_FR_FIELD\t\t\t23\n#define NETSEC_RX_PKT_ER_FIELD\t\t\t21\n#define NETSEC_RX_PKT_ERR_FIELD\t\t\t16\n#define NETSEC_RX_PKT_TDRID_FIELD\t\t12\n#define NETSEC_RX_PKT_FS_FIELD\t\t\t9\n#define NETSEC_RX_PKT_LS_FIELD\t\t\t8\n#define NETSEC_RX_PKT_CO_FIELD\t\t\t6\n\n#define NETSEC_RX_PKT_ERR_MASK\t\t\t3\n\n#define NETSEC_MAX_TX_PKT_LEN\t\t\t1518\n#define NETSEC_MAX_TX_JUMBO_PKT_LEN\t\t9018\n\n#define NETSEC_RING_GMAC\t\t\t15\n#define NETSEC_RING_MAX\t\t\t\t2\n\n#define NETSEC_TCP_SEG_LEN_MAX\t\t\t1460\n#define NETSEC_TCP_JUMBO_SEG_LEN_MAX\t\t8960\n\n#define NETSEC_RX_CKSUM_NOTAVAIL\t\t0\n#define NETSEC_RX_CKSUM_OK\t\t\t1\n#define NETSEC_RX_CKSUM_NG\t\t\t2\n\n#define NETSEC_TOP_IRQ_REG_CODE_LOAD_END\tBIT(20)\n#define NETSEC_IRQ_TRANSITION_COMPLETE\t\tBIT(4)\n\n#define NETSEC_MODE_TRANS_COMP_IRQ_N2T\t\tBIT(20)\n#define NETSEC_MODE_TRANS_COMP_IRQ_T2N\t\tBIT(19)\n\n#define NETSEC_INT_PKTCNT_MAX\t\t\t2047\n\n#define NETSEC_FLOW_START_TH_MAX\t\t95\n#define NETSEC_FLOW_STOP_TH_MAX\t\t\t95\n#define NETSEC_FLOW_PAUSE_TIME_MIN\t\t5\n\n#define NETSEC_CLK_EN_REG_DOM_ALL\t\t0x3f\n\n#define NETSEC_PKT_CTRL_REG_MODE_NRM\t\tBIT(28)\n#define NETSEC_PKT_CTRL_REG_EN_JUMBO\t\tBIT(27)\n#define NETSEC_PKT_CTRL_REG_LOG_CHKSUM_ER\tBIT(3)\n#define NETSEC_PKT_CTRL_REG_LOG_HD_INCOMPLETE\tBIT(2)\n#define NETSEC_PKT_CTRL_REG_LOG_HD_ER\t\tBIT(1)\n#define NETSEC_PKT_CTRL_REG_DRP_NO_MATCH\tBIT(0)\n\n#define NETSEC_CLK_EN_REG_DOM_G\t\t\tBIT(5)\n#define NETSEC_CLK_EN_REG_DOM_C\t\t\tBIT(1)\n#define NETSEC_CLK_EN_REG_DOM_D\t\t\tBIT(0)\n\n#define NETSEC_COM_INIT_REG_DB\t\t\tBIT(2)\n#define NETSEC_COM_INIT_REG_CLS\t\t\tBIT(1)\n#define NETSEC_COM_INIT_REG_ALL\t\t\t(NETSEC_COM_INIT_REG_CLS | \\\n\t\t\t\t\t\t NETSEC_COM_INIT_REG_DB)\n\n#define NETSEC_SOFT_RST_REG_RESET\t\t0\n#define NETSEC_SOFT_RST_REG_RUN\t\t\tBIT(31)\n\n#define NETSEC_DMA_CTRL_REG_STOP\t\t1\n#define MH_CTRL__MODE_TRANS\t\t\tBIT(20)\n\n#define NETSEC_GMAC_CMD_ST_READ\t\t\t0\n#define NETSEC_GMAC_CMD_ST_WRITE\t\tBIT(28)\n#define NETSEC_GMAC_CMD_ST_BUSY\t\t\tBIT(31)\n\n#define NETSEC_GMAC_BMR_REG_COMMON\t\t0x00412080\n#define NETSEC_GMAC_BMR_REG_RESET\t\t0x00020181\n#define NETSEC_GMAC_BMR_REG_SWR\t\t\t0x00000001\n\n#define NETSEC_GMAC_OMR_REG_ST\t\t\tBIT(13)\n#define NETSEC_GMAC_OMR_REG_SR\t\t\tBIT(1)\n\n#define NETSEC_GMAC_MCR_REG_IBN\t\t\tBIT(30)\n#define NETSEC_GMAC_MCR_REG_CST\t\t\tBIT(25)\n#define NETSEC_GMAC_MCR_REG_JE\t\t\tBIT(20)\n#define NETSEC_MCR_PS\t\t\t\tBIT(15)\n#define NETSEC_GMAC_MCR_REG_FES\t\t\tBIT(14)\n#define NETSEC_GMAC_MCR_REG_FULL_DUPLEX_COMMON\t0x0000280c\n#define NETSEC_GMAC_MCR_REG_HALF_DUPLEX_COMMON\t0x0001a00c\n\n#define NETSEC_FCR_RFE\t\t\t\tBIT(2)\n#define NETSEC_FCR_TFE\t\t\t\tBIT(1)\n\n#define NETSEC_GMAC_GAR_REG_GW\t\t\tBIT(1)\n#define NETSEC_GMAC_GAR_REG_GB\t\t\tBIT(0)\n\n#define NETSEC_GMAC_GAR_REG_SHIFT_PA\t\t11\n#define NETSEC_GMAC_GAR_REG_SHIFT_GR\t\t6\n#define GMAC_REG_SHIFT_CR_GAR\t\t\t2\n\n#define NETSEC_GMAC_GAR_REG_CR_25_35_MHZ\t2\n#define NETSEC_GMAC_GAR_REG_CR_35_60_MHZ\t3\n#define NETSEC_GMAC_GAR_REG_CR_60_100_MHZ\t0\n#define NETSEC_GMAC_GAR_REG_CR_100_150_MHZ\t1\n#define NETSEC_GMAC_GAR_REG_CR_150_250_MHZ\t4\n#define NETSEC_GMAC_GAR_REG_CR_250_300_MHZ\t5\n\n#define NETSEC_GMAC_RDLAR_REG_COMMON\t\t0x18000\n#define NETSEC_GMAC_TDLAR_REG_COMMON\t\t0x1c000\n\n#define NETSEC_REG_NETSEC_VER_F_TAIKI\t\t0x50000\n\n#define NETSEC_REG_DESC_RING_CONFIG_CFG_UP\tBIT(31)\n#define NETSEC_REG_DESC_RING_CONFIG_CH_RST\tBIT(30)\n#define NETSEC_REG_DESC_TMR_MODE\t\t4\n#define NETSEC_REG_DESC_ENDIAN\t\t\t0\n\n#define NETSEC_MAC_DESC_SOFT_RST_SOFT_RST\t1\n#define NETSEC_MAC_DESC_INIT_REG_INIT\t\t1\n\n#define NETSEC_EEPROM_MAC_ADDRESS\t\t0x00\n#define NETSEC_EEPROM_HM_ME_ADDRESS_H\t\t0x08\n#define NETSEC_EEPROM_HM_ME_ADDRESS_L\t\t0x0C\n#define NETSEC_EEPROM_HM_ME_SIZE\t\t0x10\n#define NETSEC_EEPROM_MH_ME_ADDRESS_H\t\t0x14\n#define NETSEC_EEPROM_MH_ME_ADDRESS_L\t\t0x18\n#define NETSEC_EEPROM_MH_ME_SIZE\t\t0x1C\n#define NETSEC_EEPROM_PKT_ME_ADDRESS\t\t0x20\n#define NETSEC_EEPROM_PKT_ME_SIZE\t\t0x24\n\n#define DESC_NUM\t256\n\n#define NETSEC_SKB_PAD (NET_SKB_PAD + NET_IP_ALIGN)\n#define NETSEC_RXBUF_HEADROOM (max(XDP_PACKET_HEADROOM, NET_SKB_PAD) + \\\n\t\t\t       NET_IP_ALIGN)\n#define NETSEC_RX_BUF_NON_DATA (NETSEC_RXBUF_HEADROOM + \\\n\t\t\t\tSKB_DATA_ALIGN(sizeof(struct skb_shared_info)))\n#define NETSEC_RX_BUF_SIZE\t(PAGE_SIZE - NETSEC_RX_BUF_NON_DATA)\n\n#define DESC_SZ\tsizeof(struct netsec_de)\n\n#define NETSEC_F_NETSEC_VER_MAJOR_NUM(x)\t((x) & 0xffff0000)\n\n#define NETSEC_XDP_PASS          0\n#define NETSEC_XDP_CONSUMED      BIT(0)\n#define NETSEC_XDP_TX            BIT(1)\n#define NETSEC_XDP_REDIR         BIT(2)\n\nenum ring_id {\n\tNETSEC_RING_TX = 0,\n\tNETSEC_RING_RX\n};\n\nenum buf_type {\n\tTYPE_NETSEC_SKB = 0,\n\tTYPE_NETSEC_XDP_TX,\n\tTYPE_NETSEC_XDP_NDO,\n};\n\nstruct netsec_desc {\n\tunion {\n\t\tstruct sk_buff *skb;\n\t\tstruct xdp_frame *xdpf;\n\t};\n\tdma_addr_t dma_addr;\n\tvoid *addr;\n\tu16 len;\n\tu8 buf_type;\n};\n\nstruct netsec_desc_ring {\n\tdma_addr_t desc_dma;\n\tstruct netsec_desc *desc;\n\tvoid *vaddr;\n\tu16 head, tail;\n\tu16 xdp_xmit;  \n\tstruct page_pool *page_pool;\n\tstruct xdp_rxq_info xdp_rxq;\n\tspinlock_t lock;  \n};\n\nstruct netsec_priv {\n\tstruct netsec_desc_ring desc_ring[NETSEC_RING_MAX];\n\tstruct ethtool_coalesce et_coalesce;\n\tstruct bpf_prog *xdp_prog;\n\tspinlock_t reglock;  \n\tstruct napi_struct napi;\n\tphy_interface_t phy_interface;\n\tstruct net_device *ndev;\n\tstruct device_node *phy_np;\n\tstruct phy_device *phydev;\n\tstruct mii_bus *mii_bus;\n\tvoid __iomem *ioaddr;\n\tvoid __iomem *eeprom_base;\n\tstruct device *dev;\n\tstruct clk *clk;\n\tu32 msg_enable;\n\tu32 freq;\n\tu32 phy_addr;\n\tbool rx_cksum_offload_flag;\n};\n\nstruct netsec_de {  \n\tu32 attr;\n\tu32 data_buf_addr_up;\n\tu32 data_buf_addr_lw;\n\tu32 buf_len_info;\n};\n\nstruct netsec_tx_pkt_ctrl {\n\tu16 tcp_seg_len;\n\tbool tcp_seg_offload_flag;\n\tbool cksum_offload_flag;\n};\n\nstruct netsec_rx_pkt_info {\n\tint rx_cksum_result;\n\tint err_code;\n\tbool err_flag;\n};\n\nstatic void netsec_write(struct netsec_priv *priv, u32 reg_addr, u32 val)\n{\n\twritel(val, priv->ioaddr + reg_addr);\n}\n\nstatic u32 netsec_read(struct netsec_priv *priv, u32 reg_addr)\n{\n\treturn readl(priv->ioaddr + reg_addr);\n}\n\n \n\n#define TIMEOUT_SPINS_MAC\t\t1000\n#define TIMEOUT_SECONDARY_MS_MAC\t100\n\nstatic u32 netsec_clk_type(u32 freq)\n{\n\tif (freq < MHZ(35))\n\t\treturn NETSEC_GMAC_GAR_REG_CR_25_35_MHZ;\n\tif (freq < MHZ(60))\n\t\treturn NETSEC_GMAC_GAR_REG_CR_35_60_MHZ;\n\tif (freq < MHZ(100))\n\t\treturn NETSEC_GMAC_GAR_REG_CR_60_100_MHZ;\n\tif (freq < MHZ(150))\n\t\treturn NETSEC_GMAC_GAR_REG_CR_100_150_MHZ;\n\tif (freq < MHZ(250))\n\t\treturn NETSEC_GMAC_GAR_REG_CR_150_250_MHZ;\n\n\treturn NETSEC_GMAC_GAR_REG_CR_250_300_MHZ;\n}\n\nstatic int netsec_wait_while_busy(struct netsec_priv *priv, u32 addr, u32 mask)\n{\n\tu32 timeout = TIMEOUT_SPINS_MAC;\n\n\twhile (--timeout && netsec_read(priv, addr) & mask)\n\t\tcpu_relax();\n\tif (timeout)\n\t\treturn 0;\n\n\ttimeout = TIMEOUT_SECONDARY_MS_MAC;\n\twhile (--timeout && netsec_read(priv, addr) & mask)\n\t\tusleep_range(1000, 2000);\n\n\tif (timeout)\n\t\treturn 0;\n\n\tnetdev_WARN(priv->ndev, \"%s: timeout\\n\", __func__);\n\n\treturn -ETIMEDOUT;\n}\n\nstatic int netsec_mac_write(struct netsec_priv *priv, u32 addr, u32 value)\n{\n\tnetsec_write(priv, MAC_REG_DATA, value);\n\tnetsec_write(priv, MAC_REG_CMD, addr | NETSEC_GMAC_CMD_ST_WRITE);\n\treturn netsec_wait_while_busy(priv,\n\t\t\t\t      MAC_REG_CMD, NETSEC_GMAC_CMD_ST_BUSY);\n}\n\nstatic int netsec_mac_read(struct netsec_priv *priv, u32 addr, u32 *read)\n{\n\tint ret;\n\n\tnetsec_write(priv, MAC_REG_CMD, addr | NETSEC_GMAC_CMD_ST_READ);\n\tret = netsec_wait_while_busy(priv,\n\t\t\t\t     MAC_REG_CMD, NETSEC_GMAC_CMD_ST_BUSY);\n\tif (ret)\n\t\treturn ret;\n\n\t*read = netsec_read(priv, MAC_REG_DATA);\n\n\treturn 0;\n}\n\nstatic int netsec_mac_wait_while_busy(struct netsec_priv *priv,\n\t\t\t\t      u32 addr, u32 mask)\n{\n\tu32 timeout = TIMEOUT_SPINS_MAC;\n\tint ret, data;\n\n\tdo {\n\t\tret = netsec_mac_read(priv, addr, &data);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tcpu_relax();\n\t} while (--timeout && (data & mask));\n\n\tif (timeout)\n\t\treturn 0;\n\n\ttimeout = TIMEOUT_SECONDARY_MS_MAC;\n\tdo {\n\t\tusleep_range(1000, 2000);\n\n\t\tret = netsec_mac_read(priv, addr, &data);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tcpu_relax();\n\t} while (--timeout && (data & mask));\n\n\tif (timeout && !ret)\n\t\treturn 0;\n\n\tnetdev_WARN(priv->ndev, \"%s: timeout\\n\", __func__);\n\n\treturn -ETIMEDOUT;\n}\n\nstatic int netsec_mac_update_to_phy_state(struct netsec_priv *priv)\n{\n\tstruct phy_device *phydev = priv->ndev->phydev;\n\tu32 value = 0;\n\n\tvalue = phydev->duplex ? NETSEC_GMAC_MCR_REG_FULL_DUPLEX_COMMON :\n\t\t\t\t NETSEC_GMAC_MCR_REG_HALF_DUPLEX_COMMON;\n\n\tif (phydev->speed != SPEED_1000)\n\t\tvalue |= NETSEC_MCR_PS;\n\n\tif (priv->phy_interface != PHY_INTERFACE_MODE_GMII &&\n\t    phydev->speed == SPEED_100)\n\t\tvalue |= NETSEC_GMAC_MCR_REG_FES;\n\n\tvalue |= NETSEC_GMAC_MCR_REG_CST | NETSEC_GMAC_MCR_REG_JE;\n\n\tif (phy_interface_mode_is_rgmii(priv->phy_interface))\n\t\tvalue |= NETSEC_GMAC_MCR_REG_IBN;\n\n\tif (netsec_mac_write(priv, GMAC_REG_MCR, value))\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nstatic int netsec_phy_read(struct mii_bus *bus, int phy_addr, int reg_addr);\n\nstatic int netsec_phy_write(struct mii_bus *bus,\n\t\t\t    int phy_addr, int reg, u16 val)\n{\n\tint status;\n\tstruct netsec_priv *priv = bus->priv;\n\n\tif (netsec_mac_write(priv, GMAC_REG_GDR, val))\n\t\treturn -ETIMEDOUT;\n\tif (netsec_mac_write(priv, GMAC_REG_GAR,\n\t\t\t     phy_addr << NETSEC_GMAC_GAR_REG_SHIFT_PA |\n\t\t\t     reg << NETSEC_GMAC_GAR_REG_SHIFT_GR |\n\t\t\t     NETSEC_GMAC_GAR_REG_GW | NETSEC_GMAC_GAR_REG_GB |\n\t\t\t     (netsec_clk_type(priv->freq) <<\n\t\t\t      GMAC_REG_SHIFT_CR_GAR)))\n\t\treturn -ETIMEDOUT;\n\n\tstatus = netsec_mac_wait_while_busy(priv, GMAC_REG_GAR,\n\t\t\t\t\t    NETSEC_GMAC_GAR_REG_GB);\n\n\t \n\tnetsec_phy_read(bus, phy_addr, MII_PHYSID1);\n\n\treturn status;\n}\n\nstatic int netsec_phy_read(struct mii_bus *bus, int phy_addr, int reg_addr)\n{\n\tstruct netsec_priv *priv = bus->priv;\n\tu32 data;\n\tint ret;\n\n\tif (netsec_mac_write(priv, GMAC_REG_GAR, NETSEC_GMAC_GAR_REG_GB |\n\t\t\t     phy_addr << NETSEC_GMAC_GAR_REG_SHIFT_PA |\n\t\t\t     reg_addr << NETSEC_GMAC_GAR_REG_SHIFT_GR |\n\t\t\t     (netsec_clk_type(priv->freq) <<\n\t\t\t      GMAC_REG_SHIFT_CR_GAR)))\n\t\treturn -ETIMEDOUT;\n\n\tret = netsec_mac_wait_while_busy(priv, GMAC_REG_GAR,\n\t\t\t\t\t NETSEC_GMAC_GAR_REG_GB);\n\tif (ret)\n\t\treturn ret;\n\n\tret = netsec_mac_read(priv, GMAC_REG_GDR, &data);\n\tif (ret)\n\t\treturn ret;\n\n\treturn data;\n}\n\n \n\nstatic void netsec_et_get_drvinfo(struct net_device *net_device,\n\t\t\t\t  struct ethtool_drvinfo *info)\n{\n\tstrscpy(info->driver, \"netsec\", sizeof(info->driver));\n\tstrscpy(info->bus_info, dev_name(net_device->dev.parent),\n\t\tsizeof(info->bus_info));\n}\n\nstatic int netsec_et_get_coalesce(struct net_device *net_device,\n\t\t\t\t  struct ethtool_coalesce *et_coalesce,\n\t\t\t\t  struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct netsec_priv *priv = netdev_priv(net_device);\n\n\t*et_coalesce = priv->et_coalesce;\n\n\treturn 0;\n}\n\nstatic int netsec_et_set_coalesce(struct net_device *net_device,\n\t\t\t\t  struct ethtool_coalesce *et_coalesce,\n\t\t\t\t  struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct netsec_priv *priv = netdev_priv(net_device);\n\n\tpriv->et_coalesce = *et_coalesce;\n\n\tif (priv->et_coalesce.tx_coalesce_usecs < 50)\n\t\tpriv->et_coalesce.tx_coalesce_usecs = 50;\n\tif (priv->et_coalesce.tx_max_coalesced_frames < 1)\n\t\tpriv->et_coalesce.tx_max_coalesced_frames = 1;\n\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_DONE_TXINT_PKTCNT,\n\t\t     priv->et_coalesce.tx_max_coalesced_frames);\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_TXINT_TMR,\n\t\t     priv->et_coalesce.tx_coalesce_usecs);\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_INTEN_SET, NRM_TX_ST_TXDONE);\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_INTEN_SET, NRM_TX_ST_TMREXP);\n\n\tif (priv->et_coalesce.rx_coalesce_usecs < 50)\n\t\tpriv->et_coalesce.rx_coalesce_usecs = 50;\n\tif (priv->et_coalesce.rx_max_coalesced_frames < 1)\n\t\tpriv->et_coalesce.rx_max_coalesced_frames = 1;\n\n\tnetsec_write(priv, NETSEC_REG_NRM_RX_RXINT_PKTCNT,\n\t\t     priv->et_coalesce.rx_max_coalesced_frames);\n\tnetsec_write(priv, NETSEC_REG_NRM_RX_RXINT_TMR,\n\t\t     priv->et_coalesce.rx_coalesce_usecs);\n\tnetsec_write(priv, NETSEC_REG_NRM_RX_INTEN_SET, NRM_RX_ST_PKTCNT);\n\tnetsec_write(priv, NETSEC_REG_NRM_RX_INTEN_SET, NRM_RX_ST_TMREXP);\n\n\treturn 0;\n}\n\nstatic u32 netsec_et_get_msglevel(struct net_device *dev)\n{\n\tstruct netsec_priv *priv = netdev_priv(dev);\n\n\treturn priv->msg_enable;\n}\n\nstatic void netsec_et_set_msglevel(struct net_device *dev, u32 datum)\n{\n\tstruct netsec_priv *priv = netdev_priv(dev);\n\n\tpriv->msg_enable = datum;\n}\n\nstatic const struct ethtool_ops netsec_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS |\n\t\t\t\t     ETHTOOL_COALESCE_MAX_FRAMES,\n\t.get_drvinfo\t\t= netsec_et_get_drvinfo,\n\t.get_link_ksettings\t= phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings\t= phy_ethtool_set_link_ksettings,\n\t.get_link\t\t= ethtool_op_get_link,\n\t.get_coalesce\t\t= netsec_et_get_coalesce,\n\t.set_coalesce\t\t= netsec_et_set_coalesce,\n\t.get_msglevel\t\t= netsec_et_get_msglevel,\n\t.set_msglevel\t\t= netsec_et_set_msglevel,\n};\n\n \n\n\nstatic void netsec_set_rx_de(struct netsec_priv *priv,\n\t\t\t     struct netsec_desc_ring *dring, u16 idx,\n\t\t\t     const struct netsec_desc *desc)\n{\n\tstruct netsec_de *de = dring->vaddr + DESC_SZ * idx;\n\tu32 attr = (1 << NETSEC_RX_PKT_OWN_FIELD) |\n\t\t   (1 << NETSEC_RX_PKT_FS_FIELD) |\n\t\t   (1 << NETSEC_RX_PKT_LS_FIELD);\n\n\tif (idx == DESC_NUM - 1)\n\t\tattr |= (1 << NETSEC_RX_PKT_LD_FIELD);\n\n\tde->data_buf_addr_up = upper_32_bits(desc->dma_addr);\n\tde->data_buf_addr_lw = lower_32_bits(desc->dma_addr);\n\tde->buf_len_info = desc->len;\n\tde->attr = attr;\n\tdma_wmb();\n\n\tdring->desc[idx].dma_addr = desc->dma_addr;\n\tdring->desc[idx].addr = desc->addr;\n\tdring->desc[idx].len = desc->len;\n}\n\nstatic bool netsec_clean_tx_dring(struct netsec_priv *priv)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_TX];\n\tstruct xdp_frame_bulk bq;\n\tstruct netsec_de *entry;\n\tint tail = dring->tail;\n\tunsigned int bytes;\n\tint cnt = 0;\n\n\tspin_lock(&dring->lock);\n\n\tbytes = 0;\n\txdp_frame_bulk_init(&bq);\n\tentry = dring->vaddr + DESC_SZ * tail;\n\n\trcu_read_lock();  \n\n\twhile (!(entry->attr & (1U << NETSEC_TX_SHIFT_OWN_FIELD)) &&\n\t       cnt < DESC_NUM) {\n\t\tstruct netsec_desc *desc;\n\t\tint eop;\n\n\t\tdesc = &dring->desc[tail];\n\t\teop = (entry->attr >> NETSEC_TX_LAST) & 1;\n\t\tdma_rmb();\n\n\t\t \n\t\tif (desc->buf_type != TYPE_NETSEC_XDP_TX)\n\t\t\tdma_unmap_single(priv->dev, desc->dma_addr, desc->len,\n\t\t\t\t\t DMA_TO_DEVICE);\n\n\t\tif (!eop)\n\t\t\tgoto next;\n\n\t\tif (desc->buf_type == TYPE_NETSEC_SKB) {\n\t\t\tbytes += desc->skb->len;\n\t\t\tdev_kfree_skb(desc->skb);\n\t\t} else {\n\t\t\tbytes += desc->xdpf->len;\n\t\t\tif (desc->buf_type == TYPE_NETSEC_XDP_TX)\n\t\t\t\txdp_return_frame_rx_napi(desc->xdpf);\n\t\t\telse\n\t\t\t\txdp_return_frame_bulk(desc->xdpf, &bq);\n\t\t}\nnext:\n\t\t \n\t\t*desc = (struct netsec_desc){};\n\n\t\t \n\t\tentry->attr = 1U << NETSEC_TX_SHIFT_OWN_FIELD;\n\t\t \n\t\tdring->tail = (tail + 1) % DESC_NUM;\n\n\t\ttail = dring->tail;\n\t\tentry = dring->vaddr + DESC_SZ * tail;\n\t\tcnt++;\n\t}\n\txdp_flush_frame_bulk(&bq);\n\n\trcu_read_unlock();\n\n\tspin_unlock(&dring->lock);\n\n\tif (!cnt)\n\t\treturn false;\n\n\t \n\tnetsec_read(priv, NETSEC_REG_NRM_TX_DONE_PKTCNT);\n\n\tpriv->ndev->stats.tx_packets += cnt;\n\tpriv->ndev->stats.tx_bytes += bytes;\n\n\tnetdev_completed_queue(priv->ndev, cnt, bytes);\n\n\treturn true;\n}\n\nstatic void netsec_process_tx(struct netsec_priv *priv)\n{\n\tstruct net_device *ndev = priv->ndev;\n\tbool cleaned;\n\n\tcleaned = netsec_clean_tx_dring(priv);\n\n\tif (cleaned && netif_queue_stopped(ndev)) {\n\t\t \n\t\tsmp_wmb();\n\t\tnetif_wake_queue(ndev);\n\t}\n}\n\nstatic void *netsec_alloc_rx_data(struct netsec_priv *priv,\n\t\t\t\t  dma_addr_t *dma_handle, u16 *desc_len)\n\n{\n\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_RX];\n\tstruct page *page;\n\n\tpage = page_pool_dev_alloc_pages(dring->page_pool);\n\tif (!page)\n\t\treturn NULL;\n\n\t \n\t*dma_handle = page_pool_get_dma_addr(page) + NETSEC_RXBUF_HEADROOM;\n\t \n\t*desc_len = NETSEC_RX_BUF_SIZE;\n\n\treturn page_address(page);\n}\n\nstatic void netsec_rx_fill(struct netsec_priv *priv, u16 from, u16 num)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_RX];\n\tu16 idx = from;\n\n\twhile (num) {\n\t\tnetsec_set_rx_de(priv, dring, idx, &dring->desc[idx]);\n\t\tidx++;\n\t\tif (idx >= DESC_NUM)\n\t\t\tidx = 0;\n\t\tnum--;\n\t}\n}\n\nstatic void netsec_xdp_ring_tx_db(struct netsec_priv *priv, u16 pkts)\n{\n\tif (likely(pkts))\n\t\tnetsec_write(priv, NETSEC_REG_NRM_TX_PKTCNT, pkts);\n}\n\nstatic void netsec_finalize_xdp_rx(struct netsec_priv *priv, u32 xdp_res,\n\t\t\t\t   u16 pkts)\n{\n\tif (xdp_res & NETSEC_XDP_REDIR)\n\t\txdp_do_flush_map();\n\n\tif (xdp_res & NETSEC_XDP_TX)\n\t\tnetsec_xdp_ring_tx_db(priv, pkts);\n}\n\nstatic void netsec_set_tx_de(struct netsec_priv *priv,\n\t\t\t     struct netsec_desc_ring *dring,\n\t\t\t     const struct netsec_tx_pkt_ctrl *tx_ctrl,\n\t\t\t     const struct netsec_desc *desc, void *buf)\n{\n\tint idx = dring->head;\n\tstruct netsec_de *de;\n\tu32 attr;\n\n\tde = dring->vaddr + (DESC_SZ * idx);\n\n\tattr = (1 << NETSEC_TX_SHIFT_OWN_FIELD) |\n\t       (1 << NETSEC_TX_SHIFT_PT_FIELD) |\n\t       (NETSEC_RING_GMAC << NETSEC_TX_SHIFT_TDRID_FIELD) |\n\t       (1 << NETSEC_TX_SHIFT_FS_FIELD) |\n\t       (1 << NETSEC_TX_LAST) |\n\t       (tx_ctrl->cksum_offload_flag << NETSEC_TX_SHIFT_CO) |\n\t       (tx_ctrl->tcp_seg_offload_flag << NETSEC_TX_SHIFT_SO) |\n\t       (1 << NETSEC_TX_SHIFT_TRS_FIELD);\n\tif (idx == DESC_NUM - 1)\n\t\tattr |= (1 << NETSEC_TX_SHIFT_LD_FIELD);\n\n\tde->data_buf_addr_up = upper_32_bits(desc->dma_addr);\n\tde->data_buf_addr_lw = lower_32_bits(desc->dma_addr);\n\tde->buf_len_info = (tx_ctrl->tcp_seg_len << 16) | desc->len;\n\tde->attr = attr;\n\n\tdring->desc[idx] = *desc;\n\tif (desc->buf_type == TYPE_NETSEC_SKB)\n\t\tdring->desc[idx].skb = buf;\n\telse if (desc->buf_type == TYPE_NETSEC_XDP_TX ||\n\t\t desc->buf_type == TYPE_NETSEC_XDP_NDO)\n\t\tdring->desc[idx].xdpf = buf;\n\n\t \n\tdring->head = (dring->head + 1) % DESC_NUM;\n}\n\n \nstatic u32 netsec_xdp_queue_one(struct netsec_priv *priv,\n\t\t\t\tstruct xdp_frame *xdpf, bool is_ndo)\n\n{\n\tstruct netsec_desc_ring *tx_ring = &priv->desc_ring[NETSEC_RING_TX];\n\tstruct page *page = virt_to_page(xdpf->data);\n\tstruct netsec_tx_pkt_ctrl tx_ctrl = {};\n\tstruct netsec_desc tx_desc;\n\tdma_addr_t dma_handle;\n\tu16 filled;\n\n\tif (tx_ring->head >= tx_ring->tail)\n\t\tfilled = tx_ring->head - tx_ring->tail;\n\telse\n\t\tfilled = tx_ring->head + DESC_NUM - tx_ring->tail;\n\n\tif (DESC_NUM - filled <= 1)\n\t\treturn NETSEC_XDP_CONSUMED;\n\n\tif (is_ndo) {\n\t\t \n\t\tdma_handle = dma_map_single(priv->dev, xdpf->data, xdpf->len,\n\t\t\t\t\t    DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(priv->dev, dma_handle))\n\t\t\treturn NETSEC_XDP_CONSUMED;\n\t\ttx_desc.buf_type = TYPE_NETSEC_XDP_NDO;\n\t} else {\n\t\t \n\t\tstruct netsec_desc_ring *rx_ring =\n\t\t\t&priv->desc_ring[NETSEC_RING_RX];\n\t\tenum dma_data_direction dma_dir =\n\t\t\tpage_pool_get_dma_dir(rx_ring->page_pool);\n\n\t\tdma_handle = page_pool_get_dma_addr(page) + xdpf->headroom +\n\t\t\tsizeof(*xdpf);\n\t\tdma_sync_single_for_device(priv->dev, dma_handle, xdpf->len,\n\t\t\t\t\t   dma_dir);\n\t\ttx_desc.buf_type = TYPE_NETSEC_XDP_TX;\n\t}\n\n\ttx_desc.dma_addr = dma_handle;\n\ttx_desc.addr = xdpf->data;\n\ttx_desc.len = xdpf->len;\n\n\tnetdev_sent_queue(priv->ndev, xdpf->len);\n\tnetsec_set_tx_de(priv, tx_ring, &tx_ctrl, &tx_desc, xdpf);\n\n\treturn NETSEC_XDP_TX;\n}\n\nstatic u32 netsec_xdp_xmit_back(struct netsec_priv *priv, struct xdp_buff *xdp)\n{\n\tstruct netsec_desc_ring *tx_ring = &priv->desc_ring[NETSEC_RING_TX];\n\tstruct xdp_frame *xdpf = xdp_convert_buff_to_frame(xdp);\n\tu32 ret;\n\n\tif (unlikely(!xdpf))\n\t\treturn NETSEC_XDP_CONSUMED;\n\n\tspin_lock(&tx_ring->lock);\n\tret = netsec_xdp_queue_one(priv, xdpf, false);\n\tspin_unlock(&tx_ring->lock);\n\n\treturn ret;\n}\n\nstatic u32 netsec_run_xdp(struct netsec_priv *priv, struct bpf_prog *prog,\n\t\t\t  struct xdp_buff *xdp)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_RX];\n\tunsigned int sync, len = xdp->data_end - xdp->data;\n\tu32 ret = NETSEC_XDP_PASS;\n\tstruct page *page;\n\tint err;\n\tu32 act;\n\n\tact = bpf_prog_run_xdp(prog, xdp);\n\n\t \n\tsync = xdp->data_end - xdp->data_hard_start - NETSEC_RXBUF_HEADROOM;\n\tsync = max(sync, len);\n\n\tswitch (act) {\n\tcase XDP_PASS:\n\t\tret = NETSEC_XDP_PASS;\n\t\tbreak;\n\tcase XDP_TX:\n\t\tret = netsec_xdp_xmit_back(priv, xdp);\n\t\tif (ret != NETSEC_XDP_TX) {\n\t\t\tpage = virt_to_head_page(xdp->data);\n\t\t\tpage_pool_put_page(dring->page_pool, page, sync, true);\n\t\t}\n\t\tbreak;\n\tcase XDP_REDIRECT:\n\t\terr = xdp_do_redirect(priv->ndev, xdp, prog);\n\t\tif (!err) {\n\t\t\tret = NETSEC_XDP_REDIR;\n\t\t} else {\n\t\t\tret = NETSEC_XDP_CONSUMED;\n\t\t\tpage = virt_to_head_page(xdp->data);\n\t\t\tpage_pool_put_page(dring->page_pool, page, sync, true);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbpf_warn_invalid_xdp_action(priv->ndev, prog, act);\n\t\tfallthrough;\n\tcase XDP_ABORTED:\n\t\ttrace_xdp_exception(priv->ndev, prog, act);\n\t\tfallthrough;\t \n\tcase XDP_DROP:\n\t\tret = NETSEC_XDP_CONSUMED;\n\t\tpage = virt_to_head_page(xdp->data);\n\t\tpage_pool_put_page(dring->page_pool, page, sync, true);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int netsec_process_rx(struct netsec_priv *priv, int budget)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_RX];\n\tstruct net_device *ndev = priv->ndev;\n\tstruct netsec_rx_pkt_info rx_info;\n\tenum dma_data_direction dma_dir;\n\tstruct bpf_prog *xdp_prog;\n\tstruct xdp_buff xdp;\n\tu16 xdp_xmit = 0;\n\tu32 xdp_act = 0;\n\tint done = 0;\n\n\txdp_init_buff(&xdp, PAGE_SIZE, &dring->xdp_rxq);\n\n\txdp_prog = READ_ONCE(priv->xdp_prog);\n\tdma_dir = page_pool_get_dma_dir(dring->page_pool);\n\n\twhile (done < budget) {\n\t\tu16 idx = dring->tail;\n\t\tstruct netsec_de *de = dring->vaddr + (DESC_SZ * idx);\n\t\tstruct netsec_desc *desc = &dring->desc[idx];\n\t\tstruct page *page = virt_to_page(desc->addr);\n\t\tu32 xdp_result = NETSEC_XDP_PASS;\n\t\tstruct sk_buff *skb = NULL;\n\t\tu16 pkt_len, desc_len;\n\t\tdma_addr_t dma_handle;\n\t\tvoid *buf_addr;\n\n\t\tif (de->attr & (1U << NETSEC_RX_PKT_OWN_FIELD)) {\n\t\t\t \n\t\t\tnetsec_read(priv, NETSEC_REG_NRM_RX_PKTCNT);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tdma_rmb();\n\t\tdone++;\n\n\t\tpkt_len = de->buf_len_info >> 16;\n\t\trx_info.err_code = (de->attr >> NETSEC_RX_PKT_ERR_FIELD) &\n\t\t\tNETSEC_RX_PKT_ERR_MASK;\n\t\trx_info.err_flag = (de->attr >> NETSEC_RX_PKT_ER_FIELD) & 1;\n\t\tif (rx_info.err_flag) {\n\t\t\tnetif_err(priv, drv, priv->ndev,\n\t\t\t\t  \"%s: rx fail err(%d)\\n\", __func__,\n\t\t\t\t  rx_info.err_code);\n\t\t\tndev->stats.rx_dropped++;\n\t\t\tdring->tail = (dring->tail + 1) % DESC_NUM;\n\t\t\t \n\t\t\tnetsec_rx_fill(priv, idx, 1);\n\t\t\tcontinue;\n\t\t}\n\t\trx_info.rx_cksum_result =\n\t\t\t(de->attr >> NETSEC_RX_PKT_CO_FIELD) & 3;\n\n\t\t \n\t\tbuf_addr = netsec_alloc_rx_data(priv, &dma_handle, &desc_len);\n\n\t\tif (unlikely(!buf_addr))\n\t\t\tbreak;\n\n\t\tdma_sync_single_for_cpu(priv->dev, desc->dma_addr, pkt_len,\n\t\t\t\t\tdma_dir);\n\t\tprefetch(desc->addr);\n\n\t\txdp_prepare_buff(&xdp, desc->addr, NETSEC_RXBUF_HEADROOM,\n\t\t\t\t pkt_len, false);\n\n\t\tif (xdp_prog) {\n\t\t\txdp_result = netsec_run_xdp(priv, xdp_prog, &xdp);\n\t\t\tif (xdp_result != NETSEC_XDP_PASS) {\n\t\t\t\txdp_act |= xdp_result;\n\t\t\t\tif (xdp_result == NETSEC_XDP_TX)\n\t\t\t\t\txdp_xmit++;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t}\n\t\tskb = build_skb(desc->addr, desc->len + NETSEC_RX_BUF_NON_DATA);\n\n\t\tif (unlikely(!skb)) {\n\t\t\t \n\t\t\tpage_pool_put_page(dring->page_pool, page, pkt_len,\n\t\t\t\t\t   true);\n\t\t\tnetif_err(priv, drv, priv->ndev,\n\t\t\t\t  \"rx failed to build skb\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tskb_mark_for_recycle(skb);\n\n\t\tskb_reserve(skb, xdp.data - xdp.data_hard_start);\n\t\tskb_put(skb, xdp.data_end - xdp.data);\n\t\tskb->protocol = eth_type_trans(skb, priv->ndev);\n\n\t\tif (priv->rx_cksum_offload_flag &&\n\t\t    rx_info.rx_cksum_result == NETSEC_RX_CKSUM_OK)\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\nnext:\n\t\tif (skb)\n\t\t\tnapi_gro_receive(&priv->napi, skb);\n\t\tif (skb || xdp_result) {\n\t\t\tndev->stats.rx_packets++;\n\t\t\tndev->stats.rx_bytes += xdp.data_end - xdp.data;\n\t\t}\n\n\t\t \n\t\tdesc->len = desc_len;\n\t\tdesc->dma_addr = dma_handle;\n\t\tdesc->addr = buf_addr;\n\n\t\tnetsec_rx_fill(priv, idx, 1);\n\t\tdring->tail = (dring->tail + 1) % DESC_NUM;\n\t}\n\tnetsec_finalize_xdp_rx(priv, xdp_act, xdp_xmit);\n\n\treturn done;\n}\n\nstatic int netsec_napi_poll(struct napi_struct *napi, int budget)\n{\n\tstruct netsec_priv *priv;\n\tint done;\n\n\tpriv = container_of(napi, struct netsec_priv, napi);\n\n\tnetsec_process_tx(priv);\n\tdone = netsec_process_rx(priv, budget);\n\n\tif (done < budget && napi_complete_done(napi, done)) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&priv->reglock, flags);\n\t\tnetsec_write(priv, NETSEC_REG_INTEN_SET,\n\t\t\t     NETSEC_IRQ_RX | NETSEC_IRQ_TX);\n\t\tspin_unlock_irqrestore(&priv->reglock, flags);\n\t}\n\n\treturn done;\n}\n\n\nstatic int netsec_desc_used(struct netsec_desc_ring *dring)\n{\n\tint used;\n\n\tif (dring->head >= dring->tail)\n\t\tused = dring->head - dring->tail;\n\telse\n\t\tused = dring->head + DESC_NUM - dring->tail;\n\n\treturn used;\n}\n\nstatic int netsec_check_stop_tx(struct netsec_priv *priv, int used)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_TX];\n\n\t \n\tif (DESC_NUM - used < 2) {\n\t\tnetif_stop_queue(priv->ndev);\n\n\t\t \n\t\tsmp_rmb();\n\n\t\tused = netsec_desc_used(dring);\n\t\tif (DESC_NUM - used < 2)\n\t\t\treturn NETDEV_TX_BUSY;\n\n\t\tnetif_wake_queue(priv->ndev);\n\t}\n\n\treturn 0;\n}\n\nstatic netdev_tx_t netsec_netdev_start_xmit(struct sk_buff *skb,\n\t\t\t\t\t    struct net_device *ndev)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_TX];\n\tstruct netsec_tx_pkt_ctrl tx_ctrl = {};\n\tstruct netsec_desc tx_desc;\n\tu16 tso_seg_len = 0;\n\tint filled;\n\n\tspin_lock_bh(&dring->lock);\n\tfilled = netsec_desc_used(dring);\n\tif (netsec_check_stop_tx(priv, filled)) {\n\t\tspin_unlock_bh(&dring->lock);\n\t\tnet_warn_ratelimited(\"%s %s Tx queue full\\n\",\n\t\t\t\t     dev_name(priv->dev), ndev->name);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\ttx_ctrl.cksum_offload_flag = true;\n\n\tif (skb_is_gso(skb))\n\t\ttso_seg_len = skb_shinfo(skb)->gso_size;\n\n\tif (tso_seg_len > 0) {\n\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\tip_hdr(skb)->tot_len = 0;\n\t\t\ttcp_hdr(skb)->check =\n\t\t\t\t~tcp_v4_check(0, ip_hdr(skb)->saddr,\n\t\t\t\t\t      ip_hdr(skb)->daddr, 0);\n\t\t} else {\n\t\t\ttcp_v6_gso_csum_prep(skb);\n\t\t}\n\n\t\ttx_ctrl.tcp_seg_offload_flag = true;\n\t\ttx_ctrl.tcp_seg_len = tso_seg_len;\n\t}\n\n\ttx_desc.dma_addr = dma_map_single(priv->dev, skb->data,\n\t\t\t\t\t  skb_headlen(skb), DMA_TO_DEVICE);\n\tif (dma_mapping_error(priv->dev, tx_desc.dma_addr)) {\n\t\tspin_unlock_bh(&dring->lock);\n\t\tnetif_err(priv, drv, priv->ndev,\n\t\t\t  \"%s: DMA mapping failed\\n\", __func__);\n\t\tndev->stats.tx_dropped++;\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\ttx_desc.addr = skb->data;\n\ttx_desc.len = skb_headlen(skb);\n\ttx_desc.buf_type = TYPE_NETSEC_SKB;\n\n\tskb_tx_timestamp(skb);\n\tnetdev_sent_queue(priv->ndev, skb->len);\n\n\tnetsec_set_tx_de(priv, dring, &tx_ctrl, &tx_desc, skb);\n\tspin_unlock_bh(&dring->lock);\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_PKTCNT, 1);  \n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void netsec_uninit_pkt_dring(struct netsec_priv *priv, int id)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[id];\n\tstruct netsec_desc *desc;\n\tu16 idx;\n\n\tif (!dring->vaddr || !dring->desc)\n\t\treturn;\n\tfor (idx = 0; idx < DESC_NUM; idx++) {\n\t\tdesc = &dring->desc[idx];\n\t\tif (!desc->addr)\n\t\t\tcontinue;\n\n\t\tif (id == NETSEC_RING_RX) {\n\t\t\tstruct page *page = virt_to_page(desc->addr);\n\n\t\t\tpage_pool_put_full_page(dring->page_pool, page, false);\n\t\t} else if (id == NETSEC_RING_TX) {\n\t\t\tdma_unmap_single(priv->dev, desc->dma_addr, desc->len,\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb(desc->skb);\n\t\t}\n\t}\n\n\t \n\tif (id == NETSEC_RING_RX) {\n\t\tif (xdp_rxq_info_is_reg(&dring->xdp_rxq))\n\t\t\txdp_rxq_info_unreg(&dring->xdp_rxq);\n\t\tpage_pool_destroy(dring->page_pool);\n\t}\n\n\tmemset(dring->desc, 0, sizeof(struct netsec_desc) * DESC_NUM);\n\tmemset(dring->vaddr, 0, DESC_SZ * DESC_NUM);\n\n\tdring->head = 0;\n\tdring->tail = 0;\n\n\tif (id == NETSEC_RING_TX)\n\t\tnetdev_reset_queue(priv->ndev);\n}\n\nstatic void netsec_free_dring(struct netsec_priv *priv, int id)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[id];\n\n\tif (dring->vaddr) {\n\t\tdma_free_coherent(priv->dev, DESC_SZ * DESC_NUM,\n\t\t\t\t  dring->vaddr, dring->desc_dma);\n\t\tdring->vaddr = NULL;\n\t}\n\n\tkfree(dring->desc);\n\tdring->desc = NULL;\n}\n\nstatic int netsec_alloc_dring(struct netsec_priv *priv, enum ring_id id)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[id];\n\n\tdring->vaddr = dma_alloc_coherent(priv->dev, DESC_SZ * DESC_NUM,\n\t\t\t\t\t  &dring->desc_dma, GFP_KERNEL);\n\tif (!dring->vaddr)\n\t\tgoto err;\n\n\tdring->desc = kcalloc(DESC_NUM, sizeof(*dring->desc), GFP_KERNEL);\n\tif (!dring->desc)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tnetsec_free_dring(priv, id);\n\n\treturn -ENOMEM;\n}\n\nstatic void netsec_setup_tx_dring(struct netsec_priv *priv)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_TX];\n\tint i;\n\n\tfor (i = 0; i < DESC_NUM; i++) {\n\t\tstruct netsec_de *de;\n\n\t\tde = dring->vaddr + (DESC_SZ * i);\n\t\t \n\t\tde->attr = 1U << NETSEC_TX_SHIFT_OWN_FIELD;\n\t}\n}\n\nstatic int netsec_setup_rx_dring(struct netsec_priv *priv)\n{\n\tstruct netsec_desc_ring *dring = &priv->desc_ring[NETSEC_RING_RX];\n\tstruct bpf_prog *xdp_prog = READ_ONCE(priv->xdp_prog);\n\tstruct page_pool_params pp_params = {\n\t\t.order = 0,\n\t\t \n\t\t.flags = PP_FLAG_DMA_MAP | PP_FLAG_DMA_SYNC_DEV,\n\t\t.pool_size = DESC_NUM,\n\t\t.nid = NUMA_NO_NODE,\n\t\t.dev = priv->dev,\n\t\t.dma_dir = xdp_prog ? DMA_BIDIRECTIONAL : DMA_FROM_DEVICE,\n\t\t.offset = NETSEC_RXBUF_HEADROOM,\n\t\t.max_len = NETSEC_RX_BUF_SIZE,\n\t};\n\tint i, err;\n\n\tdring->page_pool = page_pool_create(&pp_params);\n\tif (IS_ERR(dring->page_pool)) {\n\t\terr = PTR_ERR(dring->page_pool);\n\t\tdring->page_pool = NULL;\n\t\tgoto err_out;\n\t}\n\n\terr = xdp_rxq_info_reg(&dring->xdp_rxq, priv->ndev, 0, priv->napi.napi_id);\n\tif (err)\n\t\tgoto err_out;\n\n\terr = xdp_rxq_info_reg_mem_model(&dring->xdp_rxq, MEM_TYPE_PAGE_POOL,\n\t\t\t\t\t dring->page_pool);\n\tif (err)\n\t\tgoto err_out;\n\n\tfor (i = 0; i < DESC_NUM; i++) {\n\t\tstruct netsec_desc *desc = &dring->desc[i];\n\t\tdma_addr_t dma_handle;\n\t\tvoid *buf;\n\t\tu16 len;\n\n\t\tbuf = netsec_alloc_rx_data(priv, &dma_handle, &len);\n\n\t\tif (!buf) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out;\n\t\t}\n\t\tdesc->dma_addr = dma_handle;\n\t\tdesc->addr = buf;\n\t\tdesc->len = len;\n\t}\n\n\tnetsec_rx_fill(priv, 0, DESC_NUM);\n\n\treturn 0;\n\nerr_out:\n\tnetsec_uninit_pkt_dring(priv, NETSEC_RING_RX);\n\treturn err;\n}\n\nstatic int netsec_netdev_load_ucode_region(struct netsec_priv *priv, u32 reg,\n\t\t\t\t\t   u32 addr_h, u32 addr_l, u32 size)\n{\n\tu64 base = (u64)addr_h << 32 | addr_l;\n\tvoid __iomem *ucode;\n\tu32 i;\n\n\tucode = ioremap(base, size * sizeof(u32));\n\tif (!ucode)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < size; i++)\n\t\tnetsec_write(priv, reg, readl(ucode + i * 4));\n\n\tiounmap(ucode);\n\treturn 0;\n}\n\nstatic int netsec_netdev_load_microcode(struct netsec_priv *priv)\n{\n\tu32 addr_h, addr_l, size;\n\tint err;\n\n\taddr_h = readl(priv->eeprom_base + NETSEC_EEPROM_HM_ME_ADDRESS_H);\n\taddr_l = readl(priv->eeprom_base + NETSEC_EEPROM_HM_ME_ADDRESS_L);\n\tsize = readl(priv->eeprom_base + NETSEC_EEPROM_HM_ME_SIZE);\n\terr = netsec_netdev_load_ucode_region(priv, NETSEC_REG_DMAC_HM_CMD_BUF,\n\t\t\t\t\t      addr_h, addr_l, size);\n\tif (err)\n\t\treturn err;\n\n\taddr_h = readl(priv->eeprom_base + NETSEC_EEPROM_MH_ME_ADDRESS_H);\n\taddr_l = readl(priv->eeprom_base + NETSEC_EEPROM_MH_ME_ADDRESS_L);\n\tsize = readl(priv->eeprom_base + NETSEC_EEPROM_MH_ME_SIZE);\n\terr = netsec_netdev_load_ucode_region(priv, NETSEC_REG_DMAC_MH_CMD_BUF,\n\t\t\t\t\t      addr_h, addr_l, size);\n\tif (err)\n\t\treturn err;\n\n\taddr_h = 0;\n\taddr_l = readl(priv->eeprom_base + NETSEC_EEPROM_PKT_ME_ADDRESS);\n\tsize = readl(priv->eeprom_base + NETSEC_EEPROM_PKT_ME_SIZE);\n\terr = netsec_netdev_load_ucode_region(priv, NETSEC_REG_PKT_CMD_BUF,\n\t\t\t\t\t      addr_h, addr_l, size);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nstatic int netsec_reset_hardware(struct netsec_priv *priv,\n\t\t\t\t bool load_ucode)\n{\n\tu32 value;\n\tint err;\n\n\t \n\tif (!netsec_read(priv, NETSEC_REG_ADDR_DIS_CORE)) {\n\t\tnetsec_write(priv, NETSEC_REG_DMA_HM_CTRL,\n\t\t\t     NETSEC_DMA_CTRL_REG_STOP);\n\t\tnetsec_write(priv, NETSEC_REG_DMA_MH_CTRL,\n\t\t\t     NETSEC_DMA_CTRL_REG_STOP);\n\n\t\twhile (netsec_read(priv, NETSEC_REG_DMA_HM_CTRL) &\n\t\t       NETSEC_DMA_CTRL_REG_STOP)\n\t\t\tcpu_relax();\n\n\t\twhile (netsec_read(priv, NETSEC_REG_DMA_MH_CTRL) &\n\t\t       NETSEC_DMA_CTRL_REG_STOP)\n\t\t\tcpu_relax();\n\t}\n\n\tnetsec_write(priv, NETSEC_REG_SOFT_RST, NETSEC_SOFT_RST_REG_RESET);\n\tnetsec_write(priv, NETSEC_REG_SOFT_RST, NETSEC_SOFT_RST_REG_RUN);\n\tnetsec_write(priv, NETSEC_REG_COM_INIT, NETSEC_COM_INIT_REG_ALL);\n\n\twhile (netsec_read(priv, NETSEC_REG_COM_INIT) != 0)\n\t\tcpu_relax();\n\n\t \n\tnetsec_write(priv, NETSEC_REG_NRM_RX_DESC_START_UP,\n\t\t     upper_32_bits(priv->desc_ring[NETSEC_RING_RX].desc_dma));\n\tnetsec_write(priv, NETSEC_REG_NRM_RX_DESC_START_LW,\n\t\t     lower_32_bits(priv->desc_ring[NETSEC_RING_RX].desc_dma));\n\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_DESC_START_UP,\n\t\t     upper_32_bits(priv->desc_ring[NETSEC_RING_TX].desc_dma));\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_DESC_START_LW,\n\t\t     lower_32_bits(priv->desc_ring[NETSEC_RING_TX].desc_dma));\n\n\t \n\tnetsec_write(priv, NETSEC_REG_NRM_TX_CONFIG,\n\t\t     1 << NETSEC_REG_DESC_ENDIAN);\n\tnetsec_write(priv, NETSEC_REG_NRM_RX_CONFIG,\n\t\t     1 << NETSEC_REG_DESC_ENDIAN);\n\n\tif (load_ucode) {\n\t\terr = netsec_netdev_load_microcode(priv);\n\t\tif (err) {\n\t\t\tnetif_err(priv, probe, priv->ndev,\n\t\t\t\t  \"%s: failed to load microcode (%d)\\n\",\n\t\t\t\t  __func__, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\t \n\tnetsec_write(priv, NETSEC_REG_DMA_TMR_CTRL, priv->freq / 1000000 - 1);\n\tnetsec_write(priv, NETSEC_REG_ADDR_DIS_CORE, 0);\n\n\tusleep_range(1000, 2000);\n\n\tif (!(netsec_read(priv, NETSEC_REG_TOP_STATUS) &\n\t      NETSEC_TOP_IRQ_REG_CODE_LOAD_END)) {\n\t\tnetif_err(priv, probe, priv->ndev,\n\t\t\t  \"microengine start failed\\n\");\n\t\treturn -ENXIO;\n\t}\n\tnetsec_write(priv, NETSEC_REG_TOP_STATUS,\n\t\t     NETSEC_TOP_IRQ_REG_CODE_LOAD_END);\n\n\tvalue = NETSEC_PKT_CTRL_REG_MODE_NRM;\n\tif (priv->ndev->mtu > ETH_DATA_LEN)\n\t\tvalue |= NETSEC_PKT_CTRL_REG_EN_JUMBO;\n\n\t \n\tnetsec_write(priv, NETSEC_REG_DMA_MH_CTRL, MH_CTRL__MODE_TRANS);\n\tnetsec_write(priv, NETSEC_REG_PKT_CTRL, value);\n\n\twhile ((netsec_read(priv, NETSEC_REG_MODE_TRANS_COMP_STATUS) &\n\t\tNETSEC_MODE_TRANS_COMP_IRQ_T2N) == 0)\n\t\tcpu_relax();\n\n\t \n\tnetsec_write(priv, NETSEC_REG_NRM_TX_STATUS, ~0);\n\n\t \n\tnetsec_write(priv, NETSEC_REG_INTEN_CLR, ~0);\n\n\treturn 0;\n}\n\nstatic int netsec_start_gmac(struct netsec_priv *priv)\n{\n\tstruct phy_device *phydev = priv->ndev->phydev;\n\tu32 value = 0;\n\tint ret;\n\n\tif (phydev->speed != SPEED_1000)\n\t\tvalue = (NETSEC_GMAC_MCR_REG_CST |\n\t\t\t NETSEC_GMAC_MCR_REG_HALF_DUPLEX_COMMON);\n\n\tif (netsec_mac_write(priv, GMAC_REG_MCR, value))\n\t\treturn -ETIMEDOUT;\n\tif (netsec_mac_write(priv, GMAC_REG_BMR,\n\t\t\t     NETSEC_GMAC_BMR_REG_RESET))\n\t\treturn -ETIMEDOUT;\n\n\t \n\tusleep_range(1000, 5000);\n\n\tret = netsec_mac_read(priv, GMAC_REG_BMR, &value);\n\tif (ret)\n\t\treturn ret;\n\tif (value & NETSEC_GMAC_BMR_REG_SWR)\n\t\treturn -EAGAIN;\n\n\tnetsec_write(priv, MAC_REG_DESC_SOFT_RST, 1);\n\tif (netsec_wait_while_busy(priv, MAC_REG_DESC_SOFT_RST, 1))\n\t\treturn -ETIMEDOUT;\n\n\tnetsec_write(priv, MAC_REG_DESC_INIT, 1);\n\tif (netsec_wait_while_busy(priv, MAC_REG_DESC_INIT, 1))\n\t\treturn -ETIMEDOUT;\n\n\tif (netsec_mac_write(priv, GMAC_REG_BMR,\n\t\t\t     NETSEC_GMAC_BMR_REG_COMMON))\n\t\treturn -ETIMEDOUT;\n\tif (netsec_mac_write(priv, GMAC_REG_RDLAR,\n\t\t\t     NETSEC_GMAC_RDLAR_REG_COMMON))\n\t\treturn -ETIMEDOUT;\n\tif (netsec_mac_write(priv, GMAC_REG_TDLAR,\n\t\t\t     NETSEC_GMAC_TDLAR_REG_COMMON))\n\t\treturn -ETIMEDOUT;\n\tif (netsec_mac_write(priv, GMAC_REG_MFFR, 0x80000001))\n\t\treturn -ETIMEDOUT;\n\n\tret = netsec_mac_update_to_phy_state(priv);\n\tif (ret)\n\t\treturn ret;\n\n\tret = netsec_mac_read(priv, GMAC_REG_OMR, &value);\n\tif (ret)\n\t\treturn ret;\n\n\tvalue |= NETSEC_GMAC_OMR_REG_SR;\n\tvalue |= NETSEC_GMAC_OMR_REG_ST;\n\n\tnetsec_write(priv, NETSEC_REG_NRM_RX_INTEN_CLR, ~0);\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_INTEN_CLR, ~0);\n\n\tnetsec_et_set_coalesce(priv->ndev, &priv->et_coalesce, NULL, NULL);\n\n\tif (netsec_mac_write(priv, GMAC_REG_OMR, value))\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nstatic int netsec_stop_gmac(struct netsec_priv *priv)\n{\n\tu32 value;\n\tint ret;\n\n\tret = netsec_mac_read(priv, GMAC_REG_OMR, &value);\n\tif (ret)\n\t\treturn ret;\n\tvalue &= ~NETSEC_GMAC_OMR_REG_SR;\n\tvalue &= ~NETSEC_GMAC_OMR_REG_ST;\n\n\t \n\tnetsec_write(priv, NETSEC_REG_NRM_RX_INTEN_CLR, ~0);\n\tnetsec_write(priv, NETSEC_REG_NRM_TX_INTEN_CLR, ~0);\n\n\treturn netsec_mac_write(priv, GMAC_REG_OMR, value);\n}\n\nstatic void netsec_phy_adjust_link(struct net_device *ndev)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\n\tif (ndev->phydev->link)\n\t\tnetsec_start_gmac(priv);\n\telse\n\t\tnetsec_stop_gmac(priv);\n\n\tphy_print_status(ndev->phydev);\n}\n\nstatic irqreturn_t netsec_irq_handler(int irq, void *dev_id)\n{\n\tstruct netsec_priv *priv = dev_id;\n\tu32 val, status = netsec_read(priv, NETSEC_REG_TOP_STATUS);\n\tunsigned long flags;\n\n\t \n\tif (status & NETSEC_IRQ_TX) {\n\t\tval = netsec_read(priv, NETSEC_REG_NRM_TX_STATUS);\n\t\tnetsec_write(priv, NETSEC_REG_NRM_TX_STATUS, val);\n\t}\n\tif (status & NETSEC_IRQ_RX) {\n\t\tval = netsec_read(priv, NETSEC_REG_NRM_RX_STATUS);\n\t\tnetsec_write(priv, NETSEC_REG_NRM_RX_STATUS, val);\n\t}\n\n\tspin_lock_irqsave(&priv->reglock, flags);\n\tnetsec_write(priv, NETSEC_REG_INTEN_CLR, NETSEC_IRQ_RX | NETSEC_IRQ_TX);\n\tspin_unlock_irqrestore(&priv->reglock, flags);\n\n\tnapi_schedule(&priv->napi);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int netsec_netdev_open(struct net_device *ndev)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\tint ret;\n\n\tpm_runtime_get_sync(priv->dev);\n\n\tnetsec_setup_tx_dring(priv);\n\tret = netsec_setup_rx_dring(priv);\n\tif (ret) {\n\t\tnetif_err(priv, probe, priv->ndev,\n\t\t\t  \"%s: fail setup ring\\n\", __func__);\n\t\tgoto err1;\n\t}\n\n\tret = request_irq(priv->ndev->irq, netsec_irq_handler,\n\t\t\t  IRQF_SHARED, \"netsec\", priv);\n\tif (ret) {\n\t\tnetif_err(priv, drv, priv->ndev, \"request_irq failed\\n\");\n\t\tgoto err2;\n\t}\n\n\tif (dev_of_node(priv->dev)) {\n\t\tif (!of_phy_connect(priv->ndev, priv->phy_np,\n\t\t\t\t    netsec_phy_adjust_link, 0,\n\t\t\t\t    priv->phy_interface)) {\n\t\t\tnetif_err(priv, link, priv->ndev, \"missing PHY\\n\");\n\t\t\tret = -ENODEV;\n\t\t\tgoto err3;\n\t\t}\n\t} else {\n\t\tret = phy_connect_direct(priv->ndev, priv->phydev,\n\t\t\t\t\t netsec_phy_adjust_link,\n\t\t\t\t\t priv->phy_interface);\n\t\tif (ret) {\n\t\t\tnetif_err(priv, link, priv->ndev,\n\t\t\t\t  \"phy_connect_direct() failed (%d)\\n\", ret);\n\t\t\tgoto err3;\n\t\t}\n\t}\n\n\tphy_start(ndev->phydev);\n\n\tnetsec_start_gmac(priv);\n\tnapi_enable(&priv->napi);\n\tnetif_start_queue(ndev);\n\n\t \n\tnetsec_write(priv, NETSEC_REG_INTEN_SET, NETSEC_IRQ_RX | NETSEC_IRQ_TX);\n\n\treturn 0;\nerr3:\n\tfree_irq(priv->ndev->irq, priv);\nerr2:\n\tnetsec_uninit_pkt_dring(priv, NETSEC_RING_RX);\nerr1:\n\tpm_runtime_put_sync(priv->dev);\n\treturn ret;\n}\n\nstatic int netsec_netdev_stop(struct net_device *ndev)\n{\n\tint ret;\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\n\tnetif_stop_queue(priv->ndev);\n\tdma_wmb();\n\n\tnapi_disable(&priv->napi);\n\n\tnetsec_write(priv, NETSEC_REG_INTEN_CLR, ~0);\n\tnetsec_stop_gmac(priv);\n\n\tfree_irq(priv->ndev->irq, priv);\n\n\tnetsec_uninit_pkt_dring(priv, NETSEC_RING_TX);\n\tnetsec_uninit_pkt_dring(priv, NETSEC_RING_RX);\n\n\tphy_stop(ndev->phydev);\n\tphy_disconnect(ndev->phydev);\n\n\tret = netsec_reset_hardware(priv, false);\n\n\tpm_runtime_put_sync(priv->dev);\n\n\treturn ret;\n}\n\nstatic int netsec_netdev_init(struct net_device *ndev)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\tint ret;\n\tu16 data;\n\n\tBUILD_BUG_ON_NOT_POWER_OF_2(DESC_NUM);\n\n\tret = netsec_alloc_dring(priv, NETSEC_RING_TX);\n\tif (ret)\n\t\treturn ret;\n\n\tret = netsec_alloc_dring(priv, NETSEC_RING_RX);\n\tif (ret)\n\t\tgoto err1;\n\n\t \n\tdata = netsec_phy_read(priv->mii_bus, priv->phy_addr, MII_BMCR);\n\tnetsec_phy_write(priv->mii_bus, priv->phy_addr, MII_BMCR,\n\t\t\t data | BMCR_PDOWN);\n\n\tret = netsec_reset_hardware(priv, true);\n\tif (ret)\n\t\tgoto err2;\n\n\t \n\tnetsec_phy_write(priv->mii_bus, priv->phy_addr, MII_BMCR, data);\n\n\tspin_lock_init(&priv->desc_ring[NETSEC_RING_TX].lock);\n\tspin_lock_init(&priv->desc_ring[NETSEC_RING_RX].lock);\n\n\treturn 0;\nerr2:\n\tnetsec_free_dring(priv, NETSEC_RING_RX);\nerr1:\n\tnetsec_free_dring(priv, NETSEC_RING_TX);\n\treturn ret;\n}\n\nstatic void netsec_netdev_uninit(struct net_device *ndev)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\n\tnetsec_free_dring(priv, NETSEC_RING_RX);\n\tnetsec_free_dring(priv, NETSEC_RING_TX);\n}\n\nstatic int netsec_netdev_set_features(struct net_device *ndev,\n\t\t\t\t      netdev_features_t features)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\n\tpriv->rx_cksum_offload_flag = !!(features & NETIF_F_RXCSUM);\n\n\treturn 0;\n}\n\nstatic int netsec_xdp_xmit(struct net_device *ndev, int n,\n\t\t\t   struct xdp_frame **frames, u32 flags)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\tstruct netsec_desc_ring *tx_ring = &priv->desc_ring[NETSEC_RING_TX];\n\tint i, nxmit = 0;\n\n\tif (unlikely(flags & ~XDP_XMIT_FLAGS_MASK))\n\t\treturn -EINVAL;\n\n\tspin_lock(&tx_ring->lock);\n\tfor (i = 0; i < n; i++) {\n\t\tstruct xdp_frame *xdpf = frames[i];\n\t\tint err;\n\n\t\terr = netsec_xdp_queue_one(priv, xdpf, true);\n\t\tif (err != NETSEC_XDP_TX)\n\t\t\tbreak;\n\n\t\ttx_ring->xdp_xmit++;\n\t\tnxmit++;\n\t}\n\tspin_unlock(&tx_ring->lock);\n\n\tif (unlikely(flags & XDP_XMIT_FLUSH)) {\n\t\tnetsec_xdp_ring_tx_db(priv, tx_ring->xdp_xmit);\n\t\ttx_ring->xdp_xmit = 0;\n\t}\n\n\treturn nxmit;\n}\n\nstatic int netsec_xdp_setup(struct netsec_priv *priv, struct bpf_prog *prog,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct net_device *dev = priv->ndev;\n\tstruct bpf_prog *old_prog;\n\n\t \n\tif (prog && dev->mtu > 1500) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Jumbo frames not supported on XDP\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (netif_running(dev))\n\t\tnetsec_netdev_stop(dev);\n\n\t \n\told_prog = xchg(&priv->xdp_prog, prog);\n\tif (old_prog)\n\t\tbpf_prog_put(old_prog);\n\n\tif (netif_running(dev))\n\t\tnetsec_netdev_open(dev);\n\n\treturn 0;\n}\n\nstatic int netsec_xdp(struct net_device *ndev, struct netdev_bpf *xdp)\n{\n\tstruct netsec_priv *priv = netdev_priv(ndev);\n\n\tswitch (xdp->command) {\n\tcase XDP_SETUP_PROG:\n\t\treturn netsec_xdp_setup(priv, xdp->prog, xdp->extack);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic const struct net_device_ops netsec_netdev_ops = {\n\t.ndo_init\t\t= netsec_netdev_init,\n\t.ndo_uninit\t\t= netsec_netdev_uninit,\n\t.ndo_open\t\t= netsec_netdev_open,\n\t.ndo_stop\t\t= netsec_netdev_stop,\n\t.ndo_start_xmit\t\t= netsec_netdev_start_xmit,\n\t.ndo_set_features\t= netsec_netdev_set_features,\n\t.ndo_set_mac_address    = eth_mac_addr,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl,\n\t.ndo_xdp_xmit\t\t= netsec_xdp_xmit,\n\t.ndo_bpf\t\t= netsec_xdp,\n};\n\nstatic int netsec_of_probe(struct platform_device *pdev,\n\t\t\t   struct netsec_priv *priv, u32 *phy_addr)\n{\n\tint err;\n\n\terr = of_get_phy_mode(pdev->dev.of_node, &priv->phy_interface);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"missing required property 'phy-mode'\\n\");\n\t\treturn err;\n\t}\n\n\t \n\tif (of_machine_is_compatible(\"socionext,developer-box\") &&\n\t    priv->phy_interface != PHY_INTERFACE_MODE_RGMII_ID) {\n\t\tdev_warn(&pdev->dev, \"Outdated firmware reports incorrect PHY mode, overriding\\n\");\n\t\tpriv->phy_interface = PHY_INTERFACE_MODE_RGMII_ID;\n\t}\n\n\tpriv->phy_np = of_parse_phandle(pdev->dev.of_node, \"phy-handle\", 0);\n\tif (!priv->phy_np) {\n\t\tdev_err(&pdev->dev, \"missing required property 'phy-handle'\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t*phy_addr = of_mdio_parse_addr(&pdev->dev, priv->phy_np);\n\n\tpriv->clk = devm_clk_get(&pdev->dev, NULL);  \n\tif (IS_ERR(priv->clk))\n\t\treturn dev_err_probe(&pdev->dev, PTR_ERR(priv->clk),\n\t\t\t\t     \"phy_ref_clk not found\\n\");\n\tpriv->freq = clk_get_rate(priv->clk);\n\n\treturn 0;\n}\n\nstatic int netsec_acpi_probe(struct platform_device *pdev,\n\t\t\t     struct netsec_priv *priv, u32 *phy_addr)\n{\n\tint ret;\n\n\tif (!IS_ENABLED(CONFIG_ACPI))\n\t\treturn -ENODEV;\n\n\t \n\tpriv->phy_interface = PHY_INTERFACE_MODE_NA;\n\n\tret = device_property_read_u32(&pdev->dev, \"phy-channel\", phy_addr);\n\tif (ret)\n\t\treturn dev_err_probe(&pdev->dev, ret,\n\t\t\t\t     \"missing required property 'phy-channel'\\n\");\n\n\tret = device_property_read_u32(&pdev->dev,\n\t\t\t\t       \"socionext,phy-clock-frequency\",\n\t\t\t\t       &priv->freq);\n\tif (ret)\n\t\treturn dev_err_probe(&pdev->dev, ret,\n\t\t\t\t     \"missing required property 'socionext,phy-clock-frequency'\\n\");\n\treturn 0;\n}\n\nstatic void netsec_unregister_mdio(struct netsec_priv *priv)\n{\n\tstruct phy_device *phydev = priv->phydev;\n\n\tif (!dev_of_node(priv->dev) && phydev) {\n\t\tphy_device_remove(phydev);\n\t\tphy_device_free(phydev);\n\t}\n\n\tmdiobus_unregister(priv->mii_bus);\n}\n\nstatic int netsec_register_mdio(struct netsec_priv *priv, u32 phy_addr)\n{\n\tstruct mii_bus *bus;\n\tint ret;\n\n\tbus = devm_mdiobus_alloc(priv->dev);\n\tif (!bus)\n\t\treturn -ENOMEM;\n\n\tsnprintf(bus->id, MII_BUS_ID_SIZE, \"%s\", dev_name(priv->dev));\n\tbus->priv = priv;\n\tbus->name = \"SNI NETSEC MDIO\";\n\tbus->read = netsec_phy_read;\n\tbus->write = netsec_phy_write;\n\tbus->parent = priv->dev;\n\tpriv->mii_bus = bus;\n\n\tif (dev_of_node(priv->dev)) {\n\t\tstruct device_node *mdio_node, *parent = dev_of_node(priv->dev);\n\n\t\tmdio_node = of_get_child_by_name(parent, \"mdio\");\n\t\tif (mdio_node) {\n\t\t\tparent = mdio_node;\n\t\t} else {\n\t\t\t \n\t\t\tdev_info(priv->dev, \"Upgrade f/w for mdio subnode!\\n\");\n\t\t}\n\n\t\tret = of_mdiobus_register(bus, parent);\n\t\tof_node_put(mdio_node);\n\n\t\tif (ret) {\n\t\t\tdev_err(priv->dev, \"mdiobus register err(%d)\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\t \n\t\tbus->phy_mask = ~0;\n\t\tret = mdiobus_register(bus);\n\t\tif (ret) {\n\t\t\tdev_err(priv->dev, \"mdiobus register err(%d)\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tpriv->phydev = get_phy_device(bus, phy_addr, false);\n\t\tif (IS_ERR(priv->phydev)) {\n\t\t\tret = PTR_ERR(priv->phydev);\n\t\t\tdev_err(priv->dev, \"get_phy_device err(%d)\\n\", ret);\n\t\t\tpriv->phydev = NULL;\n\t\t\tmdiobus_unregister(bus);\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tret = phy_device_register(priv->phydev);\n\t\tif (ret) {\n\t\t\tphy_device_free(priv->phydev);\n\t\t\tmdiobus_unregister(bus);\n\t\t\tdev_err(priv->dev,\n\t\t\t\t\"phy_device_register err(%d)\\n\", ret);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int netsec_probe(struct platform_device *pdev)\n{\n\tstruct resource *mmio_res, *eeprom_res;\n\tstruct netsec_priv *priv;\n\tu32 hw_ver, phy_addr = 0;\n\tstruct net_device *ndev;\n\tint ret;\n\tint irq;\n\n\tmmio_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!mmio_res) {\n\t\tdev_err(&pdev->dev, \"No MMIO resource found.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\teeprom_res = platform_get_resource(pdev, IORESOURCE_MEM, 1);\n\tif (!eeprom_res) {\n\t\tdev_info(&pdev->dev, \"No EEPROM resource found.\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tndev = alloc_etherdev(sizeof(*priv));\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tpriv = netdev_priv(ndev);\n\n\tspin_lock_init(&priv->reglock);\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\tplatform_set_drvdata(pdev, priv);\n\tndev->irq = irq;\n\tpriv->dev = &pdev->dev;\n\tpriv->ndev = ndev;\n\n\tpriv->msg_enable = NETIF_MSG_TX_ERR | NETIF_MSG_HW | NETIF_MSG_DRV |\n\t\t\t   NETIF_MSG_LINK | NETIF_MSG_PROBE;\n\n\tpriv->ioaddr = devm_ioremap(&pdev->dev, mmio_res->start,\n\t\t\t\t    resource_size(mmio_res));\n\tif (!priv->ioaddr) {\n\t\tdev_err(&pdev->dev, \"devm_ioremap() failed\\n\");\n\t\tret = -ENXIO;\n\t\tgoto free_ndev;\n\t}\n\n\tpriv->eeprom_base = devm_ioremap(&pdev->dev, eeprom_res->start,\n\t\t\t\t\t resource_size(eeprom_res));\n\tif (!priv->eeprom_base) {\n\t\tdev_err(&pdev->dev, \"devm_ioremap() failed for EEPROM\\n\");\n\t\tret = -ENXIO;\n\t\tgoto free_ndev;\n\t}\n\n\tret = device_get_ethdev_address(&pdev->dev, ndev);\n\tif (ret && priv->eeprom_base) {\n\t\tvoid __iomem *macp = priv->eeprom_base +\n\t\t\t\t\tNETSEC_EEPROM_MAC_ADDRESS;\n\t\tu8 addr[ETH_ALEN];\n\n\t\taddr[0] = readb(macp + 3);\n\t\taddr[1] = readb(macp + 2);\n\t\taddr[2] = readb(macp + 1);\n\t\taddr[3] = readb(macp + 0);\n\t\taddr[4] = readb(macp + 7);\n\t\taddr[5] = readb(macp + 6);\n\t\teth_hw_addr_set(ndev, addr);\n\t}\n\n\tif (!is_valid_ether_addr(ndev->dev_addr)) {\n\t\tdev_warn(&pdev->dev, \"No MAC address found, using random\\n\");\n\t\teth_hw_addr_random(ndev);\n\t}\n\n\tif (dev_of_node(&pdev->dev))\n\t\tret = netsec_of_probe(pdev, priv, &phy_addr);\n\telse\n\t\tret = netsec_acpi_probe(pdev, priv, &phy_addr);\n\tif (ret)\n\t\tgoto free_ndev;\n\n\tpriv->phy_addr = phy_addr;\n\n\tif (!priv->freq) {\n\t\tdev_err(&pdev->dev, \"missing PHY reference clock frequency\\n\");\n\t\tret = -ENODEV;\n\t\tgoto free_ndev;\n\t}\n\n\t \n\tpriv->et_coalesce.rx_coalesce_usecs = 500;\n\tpriv->et_coalesce.rx_max_coalesced_frames = 8;\n\tpriv->et_coalesce.tx_coalesce_usecs = 500;\n\tpriv->et_coalesce.tx_max_coalesced_frames = 8;\n\n\tret = device_property_read_u32(&pdev->dev, \"max-frame-size\",\n\t\t\t\t       &ndev->max_mtu);\n\tif (ret < 0)\n\t\tndev->max_mtu = ETH_DATA_LEN;\n\n\t \n\tpm_runtime_enable(&pdev->dev);\n\tpm_runtime_get_sync(&pdev->dev);\n\n\thw_ver = netsec_read(priv, NETSEC_REG_F_TAIKI_VER);\n\t \n\tif (NETSEC_F_NETSEC_VER_MAJOR_NUM(hw_ver) !=\n\t    NETSEC_F_NETSEC_VER_MAJOR_NUM(NETSEC_REG_NETSEC_VER_F_TAIKI)) {\n\t\tret = -ENODEV;\n\t\tgoto pm_disable;\n\t}\n\n\tdev_info(&pdev->dev, \"hardware revision %d.%d\\n\",\n\t\t hw_ver >> 16, hw_ver & 0xffff);\n\n\tnetif_napi_add(ndev, &priv->napi, netsec_napi_poll);\n\n\tndev->netdev_ops = &netsec_netdev_ops;\n\tndev->ethtool_ops = &netsec_ethtool_ops;\n\n\tndev->features |= NETIF_F_HIGHDMA | NETIF_F_RXCSUM | NETIF_F_GSO |\n\t\t\t\tNETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM;\n\tndev->hw_features = ndev->features;\n\n\tndev->xdp_features = NETDEV_XDP_ACT_BASIC | NETDEV_XDP_ACT_REDIRECT |\n\t\t\t     NETDEV_XDP_ACT_NDO_XMIT;\n\n\tpriv->rx_cksum_offload_flag = true;\n\n\tret = netsec_register_mdio(priv, phy_addr);\n\tif (ret)\n\t\tgoto unreg_napi;\n\n\tif (dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(40)))\n\t\tdev_warn(&pdev->dev, \"Failed to set DMA mask\\n\");\n\n\tret = register_netdev(ndev);\n\tif (ret) {\n\t\tnetif_err(priv, probe, ndev, \"register_netdev() failed\\n\");\n\t\tgoto unreg_mii;\n\t}\n\n\tpm_runtime_put_sync(&pdev->dev);\n\treturn 0;\n\nunreg_mii:\n\tnetsec_unregister_mdio(priv);\nunreg_napi:\n\tnetif_napi_del(&priv->napi);\npm_disable:\n\tpm_runtime_put_sync(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\nfree_ndev:\n\tfree_netdev(ndev);\n\tdev_err(&pdev->dev, \"init failed\\n\");\n\n\treturn ret;\n}\n\nstatic int netsec_remove(struct platform_device *pdev)\n{\n\tstruct netsec_priv *priv = platform_get_drvdata(pdev);\n\n\tunregister_netdev(priv->ndev);\n\n\tnetsec_unregister_mdio(priv);\n\n\tnetif_napi_del(&priv->napi);\n\n\tpm_runtime_disable(&pdev->dev);\n\tfree_netdev(priv->ndev);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM\nstatic int netsec_runtime_suspend(struct device *dev)\n{\n\tstruct netsec_priv *priv = dev_get_drvdata(dev);\n\n\tnetsec_write(priv, NETSEC_REG_CLK_EN, 0);\n\n\tclk_disable_unprepare(priv->clk);\n\n\treturn 0;\n}\n\nstatic int netsec_runtime_resume(struct device *dev)\n{\n\tstruct netsec_priv *priv = dev_get_drvdata(dev);\n\n\tclk_prepare_enable(priv->clk);\n\n\tnetsec_write(priv, NETSEC_REG_CLK_EN, NETSEC_CLK_EN_REG_DOM_D |\n\t\t\t\t\t       NETSEC_CLK_EN_REG_DOM_C |\n\t\t\t\t\t       NETSEC_CLK_EN_REG_DOM_G);\n\treturn 0;\n}\n#endif\n\nstatic const struct dev_pm_ops netsec_pm_ops = {\n\tSET_RUNTIME_PM_OPS(netsec_runtime_suspend, netsec_runtime_resume, NULL)\n};\n\nstatic const struct of_device_id netsec_dt_ids[] = {\n\t{ .compatible = \"socionext,synquacer-netsec\" },\n\t{ }\n};\nMODULE_DEVICE_TABLE(of, netsec_dt_ids);\n\n#ifdef CONFIG_ACPI\nstatic const struct acpi_device_id netsec_acpi_ids[] = {\n\t{ \"SCX0001\" },\n\t{ }\n};\nMODULE_DEVICE_TABLE(acpi, netsec_acpi_ids);\n#endif\n\nstatic struct platform_driver netsec_driver = {\n\t.probe\t= netsec_probe,\n\t.remove\t= netsec_remove,\n\t.driver = {\n\t\t.name = \"netsec\",\n\t\t.pm = &netsec_pm_ops,\n\t\t.of_match_table = netsec_dt_ids,\n\t\t.acpi_match_table = ACPI_PTR(netsec_acpi_ids),\n\t},\n};\nmodule_platform_driver(netsec_driver);\n\nMODULE_AUTHOR(\"Jassi Brar <jaswinder.singh@linaro.org>\");\nMODULE_AUTHOR(\"Ard Biesheuvel <ard.biesheuvel@linaro.org>\");\nMODULE_DESCRIPTION(\"NETSEC Ethernet driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}