{
  "module_name": "nixge.c",
  "hash_id": "78f7900b4d3121da64eb336ec26f2f1ab1efb41569e91cb4154b49252429b53a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ni/nixge.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/of.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n#include <linux/platform_device.h>\n#include <linux/skbuff.h>\n#include <linux/phy.h>\n#include <linux/mii.h>\n#include <linux/nvmem-consumer.h>\n#include <linux/ethtool.h>\n#include <linux/iopoll.h>\n\n#define TX_BD_NUM\t\t64\n#define RX_BD_NUM\t\t128\n\n \n#define XAXIDMA_TX_CR_OFFSET\t0x00  \n#define XAXIDMA_TX_SR_OFFSET\t0x04  \n#define XAXIDMA_TX_CDESC_OFFSET\t0x08  \n#define XAXIDMA_TX_TDESC_OFFSET\t0x10  \n\n#define XAXIDMA_RX_CR_OFFSET\t0x30  \n#define XAXIDMA_RX_SR_OFFSET\t0x34  \n#define XAXIDMA_RX_CDESC_OFFSET\t0x38  \n#define XAXIDMA_RX_TDESC_OFFSET\t0x40  \n\n#define XAXIDMA_CR_RUNSTOP_MASK\t0x1  \n#define XAXIDMA_CR_RESET_MASK\t0x4  \n\n#define XAXIDMA_BD_CTRL_LENGTH_MASK\t0x007FFFFF  \n#define XAXIDMA_BD_CTRL_TXSOF_MASK\t0x08000000  \n#define XAXIDMA_BD_CTRL_TXEOF_MASK\t0x04000000  \n#define XAXIDMA_BD_CTRL_ALL_MASK\t0x0C000000  \n\n#define XAXIDMA_DELAY_MASK\t\t0xFF000000  \n#define XAXIDMA_COALESCE_MASK\t\t0x00FF0000  \n\n#define XAXIDMA_DELAY_SHIFT\t\t24\n#define XAXIDMA_COALESCE_SHIFT\t\t16\n\n#define XAXIDMA_IRQ_IOC_MASK\t\t0x00001000  \n#define XAXIDMA_IRQ_DELAY_MASK\t\t0x00002000  \n#define XAXIDMA_IRQ_ERROR_MASK\t\t0x00004000  \n#define XAXIDMA_IRQ_ALL_MASK\t\t0x00007000  \n\n \n#define XAXIDMA_DFT_TX_THRESHOLD\t24\n#define XAXIDMA_DFT_TX_WAITBOUND\t254\n#define XAXIDMA_DFT_RX_THRESHOLD\t24\n#define XAXIDMA_DFT_RX_WAITBOUND\t254\n\n#define XAXIDMA_BD_STS_ACTUAL_LEN_MASK\t0x007FFFFF  \n#define XAXIDMA_BD_STS_COMPLETE_MASK\t0x80000000  \n#define XAXIDMA_BD_STS_DEC_ERR_MASK\t0x40000000  \n#define XAXIDMA_BD_STS_SLV_ERR_MASK\t0x20000000  \n#define XAXIDMA_BD_STS_INT_ERR_MASK\t0x10000000  \n#define XAXIDMA_BD_STS_ALL_ERR_MASK\t0x70000000  \n#define XAXIDMA_BD_STS_RXSOF_MASK\t0x08000000  \n#define XAXIDMA_BD_STS_RXEOF_MASK\t0x04000000  \n#define XAXIDMA_BD_STS_ALL_MASK\t\t0xFC000000  \n\n#define NIXGE_REG_CTRL_OFFSET\t0x4000\n#define NIXGE_REG_INFO\t\t0x00\n#define NIXGE_REG_MAC_CTL\t0x04\n#define NIXGE_REG_PHY_CTL\t0x08\n#define NIXGE_REG_LED_CTL\t0x0c\n#define NIXGE_REG_MDIO_DATA\t0x10\n#define NIXGE_REG_MDIO_ADDR\t0x14\n#define NIXGE_REG_MDIO_OP\t0x18\n#define NIXGE_REG_MDIO_CTRL\t0x1c\n\n#define NIXGE_ID_LED_CTL_EN\tBIT(0)\n#define NIXGE_ID_LED_CTL_VAL\tBIT(1)\n\n#define NIXGE_MDIO_CLAUSE45\tBIT(12)\n#define NIXGE_MDIO_CLAUSE22\t0\n#define NIXGE_MDIO_OP(n)     (((n) & 0x3) << 10)\n#define NIXGE_MDIO_OP_ADDRESS\t0\n#define NIXGE_MDIO_C45_WRITE\tBIT(0)\n#define NIXGE_MDIO_C45_READ\t(BIT(1) | BIT(0))\n#define NIXGE_MDIO_C22_WRITE\tBIT(0)\n#define NIXGE_MDIO_C22_READ\tBIT(1)\n#define NIXGE_MDIO_ADDR(n)   (((n) & 0x1f) << 5)\n#define NIXGE_MDIO_MMD(n)    (((n) & 0x1f) << 0)\n\n#define NIXGE_REG_MAC_LSB\t0x1000\n#define NIXGE_REG_MAC_MSB\t0x1004\n\n \n#define NIXGE_HDR_SIZE\t\t14  \n#define NIXGE_TRL_SIZE\t\t4  \n#define NIXGE_MTU\t\t1500  \n#define NIXGE_JUMBO_MTU\t\t9000  \n\n#define NIXGE_MAX_FRAME_SIZE\t (NIXGE_MTU + NIXGE_HDR_SIZE + NIXGE_TRL_SIZE)\n#define NIXGE_MAX_JUMBO_FRAME_SIZE \\\n\t(NIXGE_JUMBO_MTU + NIXGE_HDR_SIZE + NIXGE_TRL_SIZE)\n\nenum nixge_version {\n\tNIXGE_V2,\n\tNIXGE_V3,\n\tNIXGE_VERSION_COUNT\n};\n\nstruct nixge_hw_dma_bd {\n\tu32 next_lo;\n\tu32 next_hi;\n\tu32 phys_lo;\n\tu32 phys_hi;\n\tu32 reserved3;\n\tu32 reserved4;\n\tu32 cntrl;\n\tu32 status;\n\tu32 app0;\n\tu32 app1;\n\tu32 app2;\n\tu32 app3;\n\tu32 app4;\n\tu32 sw_id_offset_lo;\n\tu32 sw_id_offset_hi;\n\tu32 reserved6;\n};\n\n#ifdef CONFIG_PHYS_ADDR_T_64BIT\n#define nixge_hw_dma_bd_set_addr(bd, field, addr) \\\n\tdo { \\\n\t\t(bd)->field##_lo = lower_32_bits((addr)); \\\n\t\t(bd)->field##_hi = upper_32_bits((addr)); \\\n\t} while (0)\n#else\n#define nixge_hw_dma_bd_set_addr(bd, field, addr) \\\n\t((bd)->field##_lo = lower_32_bits((addr)))\n#endif\n\n#define nixge_hw_dma_bd_set_phys(bd, addr) \\\n\tnixge_hw_dma_bd_set_addr((bd), phys, (addr))\n\n#define nixge_hw_dma_bd_set_next(bd, addr) \\\n\tnixge_hw_dma_bd_set_addr((bd), next, (addr))\n\n#define nixge_hw_dma_bd_set_offset(bd, addr) \\\n\tnixge_hw_dma_bd_set_addr((bd), sw_id_offset, (addr))\n\n#ifdef CONFIG_PHYS_ADDR_T_64BIT\n#define nixge_hw_dma_bd_get_addr(bd, field) \\\n\t(dma_addr_t)((((u64)(bd)->field##_hi) << 32) | ((bd)->field##_lo))\n#else\n#define nixge_hw_dma_bd_get_addr(bd, field) \\\n\t(dma_addr_t)((bd)->field##_lo)\n#endif\n\nstruct nixge_tx_skb {\n\tstruct sk_buff *skb;\n\tdma_addr_t mapping;\n\tsize_t size;\n\tbool mapped_as_page;\n};\n\nstruct nixge_priv {\n\tstruct net_device *ndev;\n\tstruct napi_struct napi;\n\tstruct device *dev;\n\n\t \n\tstruct device_node *phy_node;\n\tphy_interface_t\t\tphy_mode;\n\n\tint link;\n\tunsigned int speed;\n\tunsigned int duplex;\n\n\t \n\tstruct mii_bus *mii_bus;\t \n\n\t \n\tvoid __iomem *ctrl_regs;\n\tvoid __iomem *dma_regs;\n\n\tstruct tasklet_struct dma_err_tasklet;\n\n\tint tx_irq;\n\tint rx_irq;\n\n\t \n\tstruct nixge_hw_dma_bd *tx_bd_v;\n\tstruct nixge_tx_skb *tx_skb;\n\tdma_addr_t tx_bd_p;\n\n\tstruct nixge_hw_dma_bd *rx_bd_v;\n\tdma_addr_t rx_bd_p;\n\tu32 tx_bd_ci;\n\tu32 tx_bd_tail;\n\tu32 rx_bd_ci;\n\n\tu32 coalesce_count_rx;\n\tu32 coalesce_count_tx;\n};\n\nstatic void nixge_dma_write_reg(struct nixge_priv *priv, off_t offset, u32 val)\n{\n\twritel(val, priv->dma_regs + offset);\n}\n\nstatic void nixge_dma_write_desc_reg(struct nixge_priv *priv, off_t offset,\n\t\t\t\t     dma_addr_t addr)\n{\n\twritel(lower_32_bits(addr), priv->dma_regs + offset);\n#ifdef CONFIG_PHYS_ADDR_T_64BIT\n\twritel(upper_32_bits(addr), priv->dma_regs + offset + 4);\n#endif\n}\n\nstatic u32 nixge_dma_read_reg(const struct nixge_priv *priv, off_t offset)\n{\n\treturn readl(priv->dma_regs + offset);\n}\n\nstatic void nixge_ctrl_write_reg(struct nixge_priv *priv, off_t offset, u32 val)\n{\n\twritel(val, priv->ctrl_regs + offset);\n}\n\nstatic u32 nixge_ctrl_read_reg(struct nixge_priv *priv, off_t offset)\n{\n\treturn readl(priv->ctrl_regs + offset);\n}\n\n#define nixge_ctrl_poll_timeout(priv, addr, val, cond, sleep_us, timeout_us) \\\n\treadl_poll_timeout((priv)->ctrl_regs + (addr), (val), (cond), \\\n\t\t\t   (sleep_us), (timeout_us))\n\n#define nixge_dma_poll_timeout(priv, addr, val, cond, sleep_us, timeout_us) \\\n\treadl_poll_timeout((priv)->dma_regs + (addr), (val), (cond), \\\n\t\t\t   (sleep_us), (timeout_us))\n\nstatic void nixge_hw_dma_bd_release(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tdma_addr_t phys_addr;\n\tstruct sk_buff *skb;\n\tint i;\n\n\tif (priv->rx_bd_v) {\n\t\tfor (i = 0; i < RX_BD_NUM; i++) {\n\t\t\tphys_addr = nixge_hw_dma_bd_get_addr(&priv->rx_bd_v[i],\n\t\t\t\t\t\t\t     phys);\n\n\t\t\tdma_unmap_single(ndev->dev.parent, phys_addr,\n\t\t\t\t\t NIXGE_MAX_JUMBO_FRAME_SIZE,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\n\t\t\tskb = (struct sk_buff *)(uintptr_t)\n\t\t\t\tnixge_hw_dma_bd_get_addr(&priv->rx_bd_v[i],\n\t\t\t\t\t\t\t sw_id_offset);\n\t\t\tdev_kfree_skb(skb);\n\t\t}\n\n\t\tdma_free_coherent(ndev->dev.parent,\n\t\t\t\t  sizeof(*priv->rx_bd_v) * RX_BD_NUM,\n\t\t\t\t  priv->rx_bd_v,\n\t\t\t\t  priv->rx_bd_p);\n\t}\n\n\tif (priv->tx_skb)\n\t\tdevm_kfree(ndev->dev.parent, priv->tx_skb);\n\n\tif (priv->tx_bd_v)\n\t\tdma_free_coherent(ndev->dev.parent,\n\t\t\t\t  sizeof(*priv->tx_bd_v) * TX_BD_NUM,\n\t\t\t\t  priv->tx_bd_v,\n\t\t\t\t  priv->tx_bd_p);\n}\n\nstatic int nixge_hw_dma_bd_init(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tstruct sk_buff *skb;\n\tdma_addr_t phys;\n\tu32 cr;\n\tint i;\n\n\t \n\tpriv->tx_bd_ci = 0;\n\tpriv->tx_bd_tail = 0;\n\tpriv->rx_bd_ci = 0;\n\n\t \n\tpriv->tx_bd_v = dma_alloc_coherent(ndev->dev.parent,\n\t\t\t\t\t   sizeof(*priv->tx_bd_v) * TX_BD_NUM,\n\t\t\t\t\t   &priv->tx_bd_p, GFP_KERNEL);\n\tif (!priv->tx_bd_v)\n\t\tgoto out;\n\n\tpriv->tx_skb = devm_kcalloc(ndev->dev.parent,\n\t\t\t\t    TX_BD_NUM, sizeof(*priv->tx_skb),\n\t\t\t\t    GFP_KERNEL);\n\tif (!priv->tx_skb)\n\t\tgoto out;\n\n\tpriv->rx_bd_v = dma_alloc_coherent(ndev->dev.parent,\n\t\t\t\t\t   sizeof(*priv->rx_bd_v) * RX_BD_NUM,\n\t\t\t\t\t   &priv->rx_bd_p, GFP_KERNEL);\n\tif (!priv->rx_bd_v)\n\t\tgoto out;\n\n\tfor (i = 0; i < TX_BD_NUM; i++) {\n\t\tnixge_hw_dma_bd_set_next(&priv->tx_bd_v[i],\n\t\t\t\t\t priv->tx_bd_p +\n\t\t\t\t\t sizeof(*priv->tx_bd_v) *\n\t\t\t\t\t ((i + 1) % TX_BD_NUM));\n\t}\n\n\tfor (i = 0; i < RX_BD_NUM; i++) {\n\t\tnixge_hw_dma_bd_set_next(&priv->rx_bd_v[i],\n\t\t\t\t\t priv->rx_bd_p\n\t\t\t\t\t + sizeof(*priv->rx_bd_v) *\n\t\t\t\t\t ((i + 1) % RX_BD_NUM));\n\n\t\tskb = __netdev_alloc_skb_ip_align(ndev,\n\t\t\t\t\t\t  NIXGE_MAX_JUMBO_FRAME_SIZE,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!skb)\n\t\t\tgoto out;\n\n\t\tnixge_hw_dma_bd_set_offset(&priv->rx_bd_v[i], (uintptr_t)skb);\n\t\tphys = dma_map_single(ndev->dev.parent, skb->data,\n\t\t\t\t      NIXGE_MAX_JUMBO_FRAME_SIZE,\n\t\t\t\t      DMA_FROM_DEVICE);\n\n\t\tnixge_hw_dma_bd_set_phys(&priv->rx_bd_v[i], phys);\n\n\t\tpriv->rx_bd_v[i].cntrl = NIXGE_MAX_JUMBO_FRAME_SIZE;\n\t}\n\n\t \n\tcr = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\t \n\tcr = ((cr & ~XAXIDMA_COALESCE_MASK) |\n\t      ((priv->coalesce_count_rx) << XAXIDMA_COALESCE_SHIFT));\n\t \n\tcr = ((cr & ~XAXIDMA_DELAY_MASK) |\n\t      (XAXIDMA_DFT_RX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\n\t \n\tcr |= XAXIDMA_IRQ_ALL_MASK;\n\t \n\tnixge_dma_write_reg(priv, XAXIDMA_RX_CR_OFFSET, cr);\n\n\t \n\tcr = nixge_dma_read_reg(priv, XAXIDMA_TX_CR_OFFSET);\n\t \n\tcr = (((cr & ~XAXIDMA_COALESCE_MASK)) |\n\t      ((priv->coalesce_count_tx) << XAXIDMA_COALESCE_SHIFT));\n\t \n\tcr = (((cr & ~XAXIDMA_DELAY_MASK)) |\n\t      (XAXIDMA_DFT_TX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\n\t \n\tcr |= XAXIDMA_IRQ_ALL_MASK;\n\t \n\tnixge_dma_write_reg(priv, XAXIDMA_TX_CR_OFFSET, cr);\n\n\t \n\tnixge_dma_write_desc_reg(priv, XAXIDMA_RX_CDESC_OFFSET, priv->rx_bd_p);\n\tcr = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\tnixge_dma_write_reg(priv, XAXIDMA_RX_CR_OFFSET,\n\t\t\t    cr | XAXIDMA_CR_RUNSTOP_MASK);\n\tnixge_dma_write_desc_reg(priv, XAXIDMA_RX_TDESC_OFFSET, priv->rx_bd_p +\n\t\t\t    (sizeof(*priv->rx_bd_v) * (RX_BD_NUM - 1)));\n\n\t \n\tnixge_dma_write_desc_reg(priv, XAXIDMA_TX_CDESC_OFFSET, priv->tx_bd_p);\n\tcr = nixge_dma_read_reg(priv, XAXIDMA_TX_CR_OFFSET);\n\tnixge_dma_write_reg(priv, XAXIDMA_TX_CR_OFFSET,\n\t\t\t    cr | XAXIDMA_CR_RUNSTOP_MASK);\n\n\treturn 0;\nout:\n\tnixge_hw_dma_bd_release(ndev);\n\treturn -ENOMEM;\n}\n\nstatic void __nixge_device_reset(struct nixge_priv *priv, off_t offset)\n{\n\tu32 status;\n\tint err;\n\n\t \n\tnixge_dma_write_reg(priv, offset, XAXIDMA_CR_RESET_MASK);\n\terr = nixge_dma_poll_timeout(priv, offset, status,\n\t\t\t\t     !(status & XAXIDMA_CR_RESET_MASK), 10,\n\t\t\t\t     1000);\n\tif (err)\n\t\tnetdev_err(priv->ndev, \"%s: DMA reset timeout!\\n\", __func__);\n}\n\nstatic void nixge_device_reset(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\n\t__nixge_device_reset(priv, XAXIDMA_TX_CR_OFFSET);\n\t__nixge_device_reset(priv, XAXIDMA_RX_CR_OFFSET);\n\n\tif (nixge_hw_dma_bd_init(ndev))\n\t\tnetdev_err(ndev, \"%s: descriptor allocation failed\\n\",\n\t\t\t   __func__);\n\n\tnetif_trans_update(ndev);\n}\n\nstatic void nixge_handle_link_change(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tstruct phy_device *phydev = ndev->phydev;\n\n\tif (phydev->link != priv->link || phydev->speed != priv->speed ||\n\t    phydev->duplex != priv->duplex) {\n\t\tpriv->link = phydev->link;\n\t\tpriv->speed = phydev->speed;\n\t\tpriv->duplex = phydev->duplex;\n\t\tphy_print_status(phydev);\n\t}\n}\n\nstatic void nixge_tx_skb_unmap(struct nixge_priv *priv,\n\t\t\t       struct nixge_tx_skb *tx_skb)\n{\n\tif (tx_skb->mapping) {\n\t\tif (tx_skb->mapped_as_page)\n\t\t\tdma_unmap_page(priv->ndev->dev.parent, tx_skb->mapping,\n\t\t\t\t       tx_skb->size, DMA_TO_DEVICE);\n\t\telse\n\t\t\tdma_unmap_single(priv->ndev->dev.parent,\n\t\t\t\t\t tx_skb->mapping,\n\t\t\t\t\t tx_skb->size, DMA_TO_DEVICE);\n\t\ttx_skb->mapping = 0;\n\t}\n\n\tif (tx_skb->skb) {\n\t\tdev_kfree_skb_any(tx_skb->skb);\n\t\ttx_skb->skb = NULL;\n\t}\n}\n\nstatic void nixge_start_xmit_done(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tstruct nixge_hw_dma_bd *cur_p;\n\tstruct nixge_tx_skb *tx_skb;\n\tunsigned int status = 0;\n\tu32 packets = 0;\n\tu32 size = 0;\n\n\tcur_p = &priv->tx_bd_v[priv->tx_bd_ci];\n\ttx_skb = &priv->tx_skb[priv->tx_bd_ci];\n\n\tstatus = cur_p->status;\n\n\twhile (status & XAXIDMA_BD_STS_COMPLETE_MASK) {\n\t\tnixge_tx_skb_unmap(priv, tx_skb);\n\t\tcur_p->status = 0;\n\n\t\tsize += status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;\n\t\tpackets++;\n\n\t\t++priv->tx_bd_ci;\n\t\tpriv->tx_bd_ci %= TX_BD_NUM;\n\t\tcur_p = &priv->tx_bd_v[priv->tx_bd_ci];\n\t\ttx_skb = &priv->tx_skb[priv->tx_bd_ci];\n\t\tstatus = cur_p->status;\n\t}\n\n\tndev->stats.tx_packets += packets;\n\tndev->stats.tx_bytes += size;\n\n\tif (packets)\n\t\tnetif_wake_queue(ndev);\n}\n\nstatic int nixge_check_tx_bd_space(struct nixge_priv *priv,\n\t\t\t\t   int num_frag)\n{\n\tstruct nixge_hw_dma_bd *cur_p;\n\n\tcur_p = &priv->tx_bd_v[(priv->tx_bd_tail + num_frag) % TX_BD_NUM];\n\tif (cur_p->status & XAXIDMA_BD_STS_ALL_MASK)\n\t\treturn NETDEV_TX_BUSY;\n\treturn 0;\n}\n\nstatic netdev_tx_t nixge_start_xmit(struct sk_buff *skb,\n\t\t\t\t    struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tstruct nixge_hw_dma_bd *cur_p;\n\tstruct nixge_tx_skb *tx_skb;\n\tdma_addr_t tail_p, cur_phys;\n\tskb_frag_t *frag;\n\tu32 num_frag;\n\tu32 ii;\n\n\tnum_frag = skb_shinfo(skb)->nr_frags;\n\tcur_p = &priv->tx_bd_v[priv->tx_bd_tail];\n\ttx_skb = &priv->tx_skb[priv->tx_bd_tail];\n\n\tif (nixge_check_tx_bd_space(priv, num_frag)) {\n\t\tif (!netif_queue_stopped(ndev))\n\t\t\tnetif_stop_queue(ndev);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tcur_phys = dma_map_single(ndev->dev.parent, skb->data,\n\t\t\t\t  skb_headlen(skb), DMA_TO_DEVICE);\n\tif (dma_mapping_error(ndev->dev.parent, cur_phys))\n\t\tgoto drop;\n\tnixge_hw_dma_bd_set_phys(cur_p, cur_phys);\n\n\tcur_p->cntrl = skb_headlen(skb) | XAXIDMA_BD_CTRL_TXSOF_MASK;\n\n\ttx_skb->skb = NULL;\n\ttx_skb->mapping = cur_phys;\n\ttx_skb->size = skb_headlen(skb);\n\ttx_skb->mapped_as_page = false;\n\n\tfor (ii = 0; ii < num_frag; ii++) {\n\t\t++priv->tx_bd_tail;\n\t\tpriv->tx_bd_tail %= TX_BD_NUM;\n\t\tcur_p = &priv->tx_bd_v[priv->tx_bd_tail];\n\t\ttx_skb = &priv->tx_skb[priv->tx_bd_tail];\n\t\tfrag = &skb_shinfo(skb)->frags[ii];\n\n\t\tcur_phys = skb_frag_dma_map(ndev->dev.parent, frag, 0,\n\t\t\t\t\t    skb_frag_size(frag),\n\t\t\t\t\t    DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ndev->dev.parent, cur_phys))\n\t\t\tgoto frag_err;\n\t\tnixge_hw_dma_bd_set_phys(cur_p, cur_phys);\n\n\t\tcur_p->cntrl = skb_frag_size(frag);\n\n\t\ttx_skb->skb = NULL;\n\t\ttx_skb->mapping = cur_phys;\n\t\ttx_skb->size = skb_frag_size(frag);\n\t\ttx_skb->mapped_as_page = true;\n\t}\n\n\t \n\ttx_skb->skb = skb;\n\n\tcur_p->cntrl |= XAXIDMA_BD_CTRL_TXEOF_MASK;\n\n\ttail_p = priv->tx_bd_p + sizeof(*priv->tx_bd_v) * priv->tx_bd_tail;\n\t \n\tnixge_dma_write_desc_reg(priv, XAXIDMA_TX_TDESC_OFFSET, tail_p);\n\t++priv->tx_bd_tail;\n\tpriv->tx_bd_tail %= TX_BD_NUM;\n\n\treturn NETDEV_TX_OK;\nfrag_err:\n\tfor (; ii > 0; ii--) {\n\t\tif (priv->tx_bd_tail)\n\t\t\tpriv->tx_bd_tail--;\n\t\telse\n\t\t\tpriv->tx_bd_tail = TX_BD_NUM - 1;\n\n\t\ttx_skb = &priv->tx_skb[priv->tx_bd_tail];\n\t\tnixge_tx_skb_unmap(priv, tx_skb);\n\n\t\tcur_p = &priv->tx_bd_v[priv->tx_bd_tail];\n\t\tcur_p->status = 0;\n\t}\n\tdma_unmap_single(priv->ndev->dev.parent,\n\t\t\t tx_skb->mapping,\n\t\t\t tx_skb->size, DMA_TO_DEVICE);\ndrop:\n\tndev->stats.tx_dropped++;\n\treturn NETDEV_TX_OK;\n}\n\nstatic int nixge_recv(struct net_device *ndev, int budget)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tstruct sk_buff *skb, *new_skb;\n\tstruct nixge_hw_dma_bd *cur_p;\n\tdma_addr_t tail_p = 0, cur_phys = 0;\n\tu32 packets = 0;\n\tu32 length = 0;\n\tu32 size = 0;\n\n\tcur_p = &priv->rx_bd_v[priv->rx_bd_ci];\n\n\twhile ((cur_p->status & XAXIDMA_BD_STS_COMPLETE_MASK &&\n\t\tbudget > packets)) {\n\t\ttail_p = priv->rx_bd_p + sizeof(*priv->rx_bd_v) *\n\t\t\t priv->rx_bd_ci;\n\n\t\tskb = (struct sk_buff *)(uintptr_t)\n\t\t\tnixge_hw_dma_bd_get_addr(cur_p, sw_id_offset);\n\n\t\tlength = cur_p->status & XAXIDMA_BD_STS_ACTUAL_LEN_MASK;\n\t\tif (length > NIXGE_MAX_JUMBO_FRAME_SIZE)\n\t\t\tlength = NIXGE_MAX_JUMBO_FRAME_SIZE;\n\n\t\tdma_unmap_single(ndev->dev.parent,\n\t\t\t\t nixge_hw_dma_bd_get_addr(cur_p, phys),\n\t\t\t\t NIXGE_MAX_JUMBO_FRAME_SIZE,\n\t\t\t\t DMA_FROM_DEVICE);\n\n\t\tskb_put(skb, length);\n\n\t\tskb->protocol = eth_type_trans(skb, ndev);\n\t\tskb_checksum_none_assert(skb);\n\n\t\t \n\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\tnapi_gro_receive(&priv->napi, skb);\n\n\t\tsize += length;\n\t\tpackets++;\n\n\t\tnew_skb = netdev_alloc_skb_ip_align(ndev,\n\t\t\t\t\t\t    NIXGE_MAX_JUMBO_FRAME_SIZE);\n\t\tif (!new_skb)\n\t\t\treturn packets;\n\n\t\tcur_phys = dma_map_single(ndev->dev.parent, new_skb->data,\n\t\t\t\t\t  NIXGE_MAX_JUMBO_FRAME_SIZE,\n\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(ndev->dev.parent, cur_phys)) {\n\t\t\t \n\t\t\tnetdev_err(ndev, \"Failed to map ...\\n\");\n\t\t}\n\t\tnixge_hw_dma_bd_set_phys(cur_p, cur_phys);\n\t\tcur_p->cntrl = NIXGE_MAX_JUMBO_FRAME_SIZE;\n\t\tcur_p->status = 0;\n\t\tnixge_hw_dma_bd_set_offset(cur_p, (uintptr_t)new_skb);\n\n\t\t++priv->rx_bd_ci;\n\t\tpriv->rx_bd_ci %= RX_BD_NUM;\n\t\tcur_p = &priv->rx_bd_v[priv->rx_bd_ci];\n\t}\n\n\tndev->stats.rx_packets += packets;\n\tndev->stats.rx_bytes += size;\n\n\tif (tail_p)\n\t\tnixge_dma_write_desc_reg(priv, XAXIDMA_RX_TDESC_OFFSET, tail_p);\n\n\treturn packets;\n}\n\nstatic int nixge_poll(struct napi_struct *napi, int budget)\n{\n\tstruct nixge_priv *priv = container_of(napi, struct nixge_priv, napi);\n\tint work_done;\n\tu32 status, cr;\n\n\twork_done = 0;\n\n\twork_done = nixge_recv(priv->ndev, budget);\n\tif (work_done < budget) {\n\t\tnapi_complete_done(napi, work_done);\n\t\tstatus = nixge_dma_read_reg(priv, XAXIDMA_RX_SR_OFFSET);\n\n\t\tif (status & (XAXIDMA_IRQ_IOC_MASK | XAXIDMA_IRQ_DELAY_MASK)) {\n\t\t\t \n\t\t\tnixge_dma_write_reg(priv, XAXIDMA_RX_SR_OFFSET, status);\n\t\t\tnapi_reschedule(napi);\n\t\t} else {\n\t\t\t \n\t\t\tcr = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\t\t\tcr |= (XAXIDMA_IRQ_IOC_MASK | XAXIDMA_IRQ_DELAY_MASK);\n\t\t\tnixge_dma_write_reg(priv, XAXIDMA_RX_CR_OFFSET, cr);\n\t\t}\n\t}\n\n\treturn work_done;\n}\n\nstatic irqreturn_t nixge_tx_irq(int irq, void *_ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(_ndev);\n\tstruct net_device *ndev = _ndev;\n\tunsigned int status;\n\tdma_addr_t phys;\n\tu32 cr;\n\n\tstatus = nixge_dma_read_reg(priv, XAXIDMA_TX_SR_OFFSET);\n\tif (status & (XAXIDMA_IRQ_IOC_MASK | XAXIDMA_IRQ_DELAY_MASK)) {\n\t\tnixge_dma_write_reg(priv, XAXIDMA_TX_SR_OFFSET, status);\n\t\tnixge_start_xmit_done(priv->ndev);\n\t\tgoto out;\n\t}\n\tif (!(status & XAXIDMA_IRQ_ALL_MASK)) {\n\t\tnetdev_err(ndev, \"No interrupts asserted in Tx path\\n\");\n\t\treturn IRQ_NONE;\n\t}\n\tif (status & XAXIDMA_IRQ_ERROR_MASK) {\n\t\tphys = nixge_hw_dma_bd_get_addr(&priv->tx_bd_v[priv->tx_bd_ci],\n\t\t\t\t\t\tphys);\n\n\t\tnetdev_err(ndev, \"DMA Tx error 0x%x\\n\", status);\n\t\tnetdev_err(ndev, \"Current BD is at: 0x%llx\\n\", (u64)phys);\n\n\t\tcr = nixge_dma_read_reg(priv, XAXIDMA_TX_CR_OFFSET);\n\t\t \n\t\tcr &= (~XAXIDMA_IRQ_ALL_MASK);\n\t\t \n\t\tnixge_dma_write_reg(priv, XAXIDMA_TX_CR_OFFSET, cr);\n\n\t\tcr = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\t\t \n\t\tcr &= (~XAXIDMA_IRQ_ALL_MASK);\n\t\t \n\t\tnixge_dma_write_reg(priv, XAXIDMA_RX_CR_OFFSET, cr);\n\n\t\ttasklet_schedule(&priv->dma_err_tasklet);\n\t\tnixge_dma_write_reg(priv, XAXIDMA_TX_SR_OFFSET, status);\n\t}\nout:\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t nixge_rx_irq(int irq, void *_ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(_ndev);\n\tstruct net_device *ndev = _ndev;\n\tunsigned int status;\n\tdma_addr_t phys;\n\tu32 cr;\n\n\tstatus = nixge_dma_read_reg(priv, XAXIDMA_RX_SR_OFFSET);\n\tif (status & (XAXIDMA_IRQ_IOC_MASK | XAXIDMA_IRQ_DELAY_MASK)) {\n\t\t \n\t\tnixge_dma_write_reg(priv, XAXIDMA_RX_SR_OFFSET, status);\n\t\tcr = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\t\tcr &= ~(XAXIDMA_IRQ_IOC_MASK | XAXIDMA_IRQ_DELAY_MASK);\n\t\tnixge_dma_write_reg(priv, XAXIDMA_RX_CR_OFFSET, cr);\n\n\t\tif (napi_schedule_prep(&priv->napi))\n\t\t\t__napi_schedule(&priv->napi);\n\t\tgoto out;\n\t}\n\tif (!(status & XAXIDMA_IRQ_ALL_MASK)) {\n\t\tnetdev_err(ndev, \"No interrupts asserted in Rx path\\n\");\n\t\treturn IRQ_NONE;\n\t}\n\tif (status & XAXIDMA_IRQ_ERROR_MASK) {\n\t\tphys = nixge_hw_dma_bd_get_addr(&priv->rx_bd_v[priv->rx_bd_ci],\n\t\t\t\t\t\tphys);\n\t\tnetdev_err(ndev, \"DMA Rx error 0x%x\\n\", status);\n\t\tnetdev_err(ndev, \"Current BD is at: 0x%llx\\n\", (u64)phys);\n\n\t\tcr = nixge_dma_read_reg(priv, XAXIDMA_TX_CR_OFFSET);\n\t\t \n\t\tcr &= (~XAXIDMA_IRQ_ALL_MASK);\n\t\t \n\t\tnixge_dma_write_reg(priv, XAXIDMA_TX_CR_OFFSET, cr);\n\n\t\tcr = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\t\t \n\t\tcr &= (~XAXIDMA_IRQ_ALL_MASK);\n\t\t \n\t\tnixge_dma_write_reg(priv, XAXIDMA_RX_CR_OFFSET, cr);\n\n\t\ttasklet_schedule(&priv->dma_err_tasklet);\n\t\tnixge_dma_write_reg(priv, XAXIDMA_RX_SR_OFFSET, status);\n\t}\nout:\n\treturn IRQ_HANDLED;\n}\n\nstatic void nixge_dma_err_handler(struct tasklet_struct *t)\n{\n\tstruct nixge_priv *lp = from_tasklet(lp, t, dma_err_tasklet);\n\tstruct nixge_hw_dma_bd *cur_p;\n\tstruct nixge_tx_skb *tx_skb;\n\tu32 cr, i;\n\n\t__nixge_device_reset(lp, XAXIDMA_TX_CR_OFFSET);\n\t__nixge_device_reset(lp, XAXIDMA_RX_CR_OFFSET);\n\n\tfor (i = 0; i < TX_BD_NUM; i++) {\n\t\tcur_p = &lp->tx_bd_v[i];\n\t\ttx_skb = &lp->tx_skb[i];\n\t\tnixge_tx_skb_unmap(lp, tx_skb);\n\n\t\tnixge_hw_dma_bd_set_phys(cur_p, 0);\n\t\tcur_p->cntrl = 0;\n\t\tcur_p->status = 0;\n\t\tnixge_hw_dma_bd_set_offset(cur_p, 0);\n\t}\n\n\tfor (i = 0; i < RX_BD_NUM; i++) {\n\t\tcur_p = &lp->rx_bd_v[i];\n\t\tcur_p->status = 0;\n\t}\n\n\tlp->tx_bd_ci = 0;\n\tlp->tx_bd_tail = 0;\n\tlp->rx_bd_ci = 0;\n\n\t \n\tcr = nixge_dma_read_reg(lp, XAXIDMA_RX_CR_OFFSET);\n\t \n\tcr = ((cr & ~XAXIDMA_COALESCE_MASK) |\n\t      (XAXIDMA_DFT_RX_THRESHOLD << XAXIDMA_COALESCE_SHIFT));\n\t \n\tcr = ((cr & ~XAXIDMA_DELAY_MASK) |\n\t      (XAXIDMA_DFT_RX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\n\t \n\tcr |= XAXIDMA_IRQ_ALL_MASK;\n\t \n\tnixge_dma_write_reg(lp, XAXIDMA_RX_CR_OFFSET, cr);\n\n\t \n\tcr = nixge_dma_read_reg(lp, XAXIDMA_TX_CR_OFFSET);\n\t \n\tcr = (((cr & ~XAXIDMA_COALESCE_MASK)) |\n\t      (XAXIDMA_DFT_TX_THRESHOLD << XAXIDMA_COALESCE_SHIFT));\n\t \n\tcr = (((cr & ~XAXIDMA_DELAY_MASK)) |\n\t      (XAXIDMA_DFT_TX_WAITBOUND << XAXIDMA_DELAY_SHIFT));\n\t \n\tcr |= XAXIDMA_IRQ_ALL_MASK;\n\t \n\tnixge_dma_write_reg(lp, XAXIDMA_TX_CR_OFFSET, cr);\n\n\t \n\tnixge_dma_write_desc_reg(lp, XAXIDMA_RX_CDESC_OFFSET, lp->rx_bd_p);\n\tcr = nixge_dma_read_reg(lp, XAXIDMA_RX_CR_OFFSET);\n\tnixge_dma_write_reg(lp, XAXIDMA_RX_CR_OFFSET,\n\t\t\t    cr | XAXIDMA_CR_RUNSTOP_MASK);\n\tnixge_dma_write_desc_reg(lp, XAXIDMA_RX_TDESC_OFFSET, lp->rx_bd_p +\n\t\t\t    (sizeof(*lp->rx_bd_v) * (RX_BD_NUM - 1)));\n\n\t \n\tnixge_dma_write_desc_reg(lp, XAXIDMA_TX_CDESC_OFFSET, lp->tx_bd_p);\n\tcr = nixge_dma_read_reg(lp, XAXIDMA_TX_CR_OFFSET);\n\tnixge_dma_write_reg(lp, XAXIDMA_TX_CR_OFFSET,\n\t\t\t    cr | XAXIDMA_CR_RUNSTOP_MASK);\n}\n\nstatic int nixge_open(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tstruct phy_device *phy;\n\tint ret;\n\n\tnixge_device_reset(ndev);\n\n\tphy = of_phy_connect(ndev, priv->phy_node,\n\t\t\t     &nixge_handle_link_change, 0, priv->phy_mode);\n\tif (!phy)\n\t\treturn -ENODEV;\n\n\tphy_start(phy);\n\n\t \n\ttasklet_setup(&priv->dma_err_tasklet, nixge_dma_err_handler);\n\n\tnapi_enable(&priv->napi);\n\n\t \n\tret = request_irq(priv->tx_irq, nixge_tx_irq, 0, ndev->name, ndev);\n\tif (ret)\n\t\tgoto err_tx_irq;\n\t \n\tret = request_irq(priv->rx_irq, nixge_rx_irq, 0, ndev->name, ndev);\n\tif (ret)\n\t\tgoto err_rx_irq;\n\n\tnetif_start_queue(ndev);\n\n\treturn 0;\n\nerr_rx_irq:\n\tfree_irq(priv->tx_irq, ndev);\nerr_tx_irq:\n\tnapi_disable(&priv->napi);\n\tphy_stop(phy);\n\tphy_disconnect(phy);\n\ttasklet_kill(&priv->dma_err_tasklet);\n\tnetdev_err(ndev, \"request_irq() failed\\n\");\n\treturn ret;\n}\n\nstatic int nixge_stop(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tu32 cr;\n\n\tnetif_stop_queue(ndev);\n\tnapi_disable(&priv->napi);\n\n\tif (ndev->phydev) {\n\t\tphy_stop(ndev->phydev);\n\t\tphy_disconnect(ndev->phydev);\n\t}\n\n\tcr = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\tnixge_dma_write_reg(priv, XAXIDMA_RX_CR_OFFSET,\n\t\t\t    cr & (~XAXIDMA_CR_RUNSTOP_MASK));\n\tcr = nixge_dma_read_reg(priv, XAXIDMA_TX_CR_OFFSET);\n\tnixge_dma_write_reg(priv, XAXIDMA_TX_CR_OFFSET,\n\t\t\t    cr & (~XAXIDMA_CR_RUNSTOP_MASK));\n\n\ttasklet_kill(&priv->dma_err_tasklet);\n\n\tfree_irq(priv->tx_irq, ndev);\n\tfree_irq(priv->rx_irq, ndev);\n\n\tnixge_hw_dma_bd_release(ndev);\n\n\treturn 0;\n}\n\nstatic int nixge_change_mtu(struct net_device *ndev, int new_mtu)\n{\n\tif (netif_running(ndev))\n\t\treturn -EBUSY;\n\n\tif ((new_mtu + NIXGE_HDR_SIZE + NIXGE_TRL_SIZE) >\n\t     NIXGE_MAX_JUMBO_FRAME_SIZE)\n\t\treturn -EINVAL;\n\n\tndev->mtu = new_mtu;\n\n\treturn 0;\n}\n\nstatic s32 __nixge_hw_set_mac_address(struct net_device *ndev)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MAC_LSB,\n\t\t\t     (ndev->dev_addr[2]) << 24 |\n\t\t\t     (ndev->dev_addr[3] << 16) |\n\t\t\t     (ndev->dev_addr[4] << 8) |\n\t\t\t     (ndev->dev_addr[5] << 0));\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MAC_MSB,\n\t\t\t     (ndev->dev_addr[1] | (ndev->dev_addr[0] << 8)));\n\n\treturn 0;\n}\n\nstatic int nixge_net_set_mac_address(struct net_device *ndev, void *p)\n{\n\tint err;\n\n\terr = eth_mac_addr(ndev, p);\n\tif (!err)\n\t\t__nixge_hw_set_mac_address(ndev);\n\n\treturn err;\n}\n\nstatic const struct net_device_ops nixge_netdev_ops = {\n\t.ndo_open = nixge_open,\n\t.ndo_stop = nixge_stop,\n\t.ndo_start_xmit = nixge_start_xmit,\n\t.ndo_change_mtu\t= nixge_change_mtu,\n\t.ndo_set_mac_address = nixge_net_set_mac_address,\n\t.ndo_validate_addr = eth_validate_addr,\n};\n\nstatic void nixge_ethtools_get_drvinfo(struct net_device *ndev,\n\t\t\t\t       struct ethtool_drvinfo *ed)\n{\n\tstrscpy(ed->driver, \"nixge\", sizeof(ed->driver));\n\tstrscpy(ed->bus_info, \"platform\", sizeof(ed->bus_info));\n}\n\nstatic int\nnixge_ethtools_get_coalesce(struct net_device *ndev,\n\t\t\t    struct ethtool_coalesce *ecoalesce,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tu32 regval = 0;\n\n\tregval = nixge_dma_read_reg(priv, XAXIDMA_RX_CR_OFFSET);\n\tecoalesce->rx_max_coalesced_frames = (regval & XAXIDMA_COALESCE_MASK)\n\t\t\t\t\t     >> XAXIDMA_COALESCE_SHIFT;\n\tregval = nixge_dma_read_reg(priv, XAXIDMA_TX_CR_OFFSET);\n\tecoalesce->tx_max_coalesced_frames = (regval & XAXIDMA_COALESCE_MASK)\n\t\t\t\t\t     >> XAXIDMA_COALESCE_SHIFT;\n\treturn 0;\n}\n\nstatic int\nnixge_ethtools_set_coalesce(struct net_device *ndev,\n\t\t\t    struct ethtool_coalesce *ecoalesce,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\n\tif (netif_running(ndev)) {\n\t\tnetdev_err(ndev,\n\t\t\t   \"Please stop netif before applying configuration\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\tif (ecoalesce->rx_max_coalesced_frames)\n\t\tpriv->coalesce_count_rx = ecoalesce->rx_max_coalesced_frames;\n\tif (ecoalesce->tx_max_coalesced_frames)\n\t\tpriv->coalesce_count_tx = ecoalesce->tx_max_coalesced_frames;\n\n\treturn 0;\n}\n\nstatic int nixge_ethtools_set_phys_id(struct net_device *ndev,\n\t\t\t\t      enum ethtool_phys_id_state state)\n{\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\tu32 ctrl;\n\n\tctrl = nixge_ctrl_read_reg(priv, NIXGE_REG_LED_CTL);\n\tswitch (state) {\n\tcase ETHTOOL_ID_ACTIVE:\n\t\tctrl |= NIXGE_ID_LED_CTL_EN;\n\t\t \n\t\tnixge_ctrl_write_reg(priv, NIXGE_REG_LED_CTL, ctrl);\n\t\treturn 2;\n\n\tcase ETHTOOL_ID_ON:\n\t\tctrl |= NIXGE_ID_LED_CTL_VAL;\n\t\tnixge_ctrl_write_reg(priv, NIXGE_REG_LED_CTL, ctrl);\n\t\tbreak;\n\n\tcase ETHTOOL_ID_OFF:\n\t\tctrl &= ~NIXGE_ID_LED_CTL_VAL;\n\t\tnixge_ctrl_write_reg(priv, NIXGE_REG_LED_CTL, ctrl);\n\t\tbreak;\n\n\tcase ETHTOOL_ID_INACTIVE:\n\t\t \n\t\tctrl &= ~NIXGE_ID_LED_CTL_EN;\n\t\tnixge_ctrl_write_reg(priv, NIXGE_REG_LED_CTL, ctrl);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct ethtool_ops nixge_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_MAX_FRAMES,\n\t.get_drvinfo    = nixge_ethtools_get_drvinfo,\n\t.get_coalesce   = nixge_ethtools_get_coalesce,\n\t.set_coalesce   = nixge_ethtools_set_coalesce,\n\t.set_phys_id    = nixge_ethtools_set_phys_id,\n\t.get_link_ksettings     = phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings     = phy_ethtool_set_link_ksettings,\n\t.get_link\t\t= ethtool_op_get_link,\n};\n\nstatic int nixge_mdio_read_c22(struct mii_bus *bus, int phy_id, int reg)\n{\n\tstruct nixge_priv *priv = bus->priv;\n\tu32 status, tmp;\n\tint err;\n\tu16 device;\n\n\tdevice = reg & 0x1f;\n\n\ttmp = NIXGE_MDIO_CLAUSE22 | NIXGE_MDIO_OP(NIXGE_MDIO_C22_READ) |\n\t      NIXGE_MDIO_ADDR(phy_id) | NIXGE_MDIO_MMD(device);\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_OP, tmp);\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_CTRL, 1);\n\n\terr = nixge_ctrl_poll_timeout(priv, NIXGE_REG_MDIO_CTRL, status,\n\t\t\t\t      !status, 10, 1000);\n\tif (err) {\n\t\tdev_err(priv->dev, \"timeout setting read command\");\n\t\treturn err;\n\t}\n\n\tstatus = nixge_ctrl_read_reg(priv, NIXGE_REG_MDIO_DATA);\n\n\treturn status;\n}\n\nstatic int nixge_mdio_read_c45(struct mii_bus *bus, int phy_id, int device,\n\t\t\t       int reg)\n{\n\tstruct nixge_priv *priv = bus->priv;\n\tu32 status, tmp;\n\tint err;\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_ADDR, reg & 0xffff);\n\n\ttmp = NIXGE_MDIO_CLAUSE45 |\n\t      NIXGE_MDIO_OP(NIXGE_MDIO_OP_ADDRESS) |\n\t      NIXGE_MDIO_ADDR(phy_id) | NIXGE_MDIO_MMD(device);\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_OP, tmp);\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_CTRL, 1);\n\n\terr = nixge_ctrl_poll_timeout(priv, NIXGE_REG_MDIO_CTRL, status,\n\t\t\t\t      !status, 10, 1000);\n\tif (err) {\n\t\tdev_err(priv->dev, \"timeout setting address\");\n\t\treturn err;\n\t}\n\n\ttmp = NIXGE_MDIO_CLAUSE45 | NIXGE_MDIO_OP(NIXGE_MDIO_C45_READ) |\n\t      NIXGE_MDIO_ADDR(phy_id) | NIXGE_MDIO_MMD(device);\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_OP, tmp);\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_CTRL, 1);\n\n\terr = nixge_ctrl_poll_timeout(priv, NIXGE_REG_MDIO_CTRL, status,\n\t\t\t\t      !status, 10, 1000);\n\tif (err) {\n\t\tdev_err(priv->dev, \"timeout setting read command\");\n\t\treturn err;\n\t}\n\n\tstatus = nixge_ctrl_read_reg(priv, NIXGE_REG_MDIO_DATA);\n\n\treturn status;\n}\n\nstatic int nixge_mdio_write_c22(struct mii_bus *bus, int phy_id, int reg,\n\t\t\t\tu16 val)\n{\n\tstruct nixge_priv *priv = bus->priv;\n\tu32 status, tmp;\n\tu16 device;\n\tint err;\n\n\tdevice = reg & 0x1f;\n\n\ttmp = NIXGE_MDIO_CLAUSE22 | NIXGE_MDIO_OP(NIXGE_MDIO_C22_WRITE) |\n\t      NIXGE_MDIO_ADDR(phy_id) | NIXGE_MDIO_MMD(device);\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_DATA, val);\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_OP, tmp);\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_CTRL, 1);\n\n\terr = nixge_ctrl_poll_timeout(priv, NIXGE_REG_MDIO_CTRL, status,\n\t\t\t\t      !status, 10, 1000);\n\tif (err)\n\t\tdev_err(priv->dev, \"timeout setting write command\");\n\n\treturn err;\n}\n\nstatic int nixge_mdio_write_c45(struct mii_bus *bus, int phy_id,\n\t\t\t\tint device, int reg, u16 val)\n{\n\tstruct nixge_priv *priv = bus->priv;\n\tu32 status, tmp;\n\tint err;\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_ADDR, reg & 0xffff);\n\n\ttmp = NIXGE_MDIO_CLAUSE45 |\n\t      NIXGE_MDIO_OP(NIXGE_MDIO_OP_ADDRESS) |\n\t      NIXGE_MDIO_ADDR(phy_id) | NIXGE_MDIO_MMD(device);\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_OP, tmp);\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_CTRL, 1);\n\n\terr = nixge_ctrl_poll_timeout(priv, NIXGE_REG_MDIO_CTRL, status,\n\t\t\t\t      !status, 10, 1000);\n\tif (err) {\n\t\tdev_err(priv->dev, \"timeout setting address\");\n\t\treturn err;\n\t}\n\n\ttmp = NIXGE_MDIO_CLAUSE45 | NIXGE_MDIO_OP(NIXGE_MDIO_C45_WRITE) |\n\t      NIXGE_MDIO_ADDR(phy_id) | NIXGE_MDIO_MMD(device);\n\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_DATA, val);\n\tnixge_ctrl_write_reg(priv, NIXGE_REG_MDIO_OP, tmp);\n\n\terr = nixge_ctrl_poll_timeout(priv, NIXGE_REG_MDIO_CTRL, status,\n\t\t\t\t      !status, 10, 1000);\n\tif (err)\n\t\tdev_err(priv->dev, \"timeout setting write command\");\n\n\treturn err;\n}\n\nstatic int nixge_mdio_setup(struct nixge_priv *priv, struct device_node *np)\n{\n\tstruct mii_bus *bus;\n\n\tbus = devm_mdiobus_alloc(priv->dev);\n\tif (!bus)\n\t\treturn -ENOMEM;\n\n\tsnprintf(bus->id, MII_BUS_ID_SIZE, \"%s-mii\", dev_name(priv->dev));\n\tbus->priv = priv;\n\tbus->name = \"nixge_mii_bus\";\n\tbus->read = nixge_mdio_read_c22;\n\tbus->write = nixge_mdio_write_c22;\n\tbus->read_c45 = nixge_mdio_read_c45;\n\tbus->write_c45 = nixge_mdio_write_c45;\n\tbus->parent = priv->dev;\n\n\tpriv->mii_bus = bus;\n\n\treturn of_mdiobus_register(bus, np);\n}\n\nstatic void *nixge_get_nvmem_address(struct device *dev)\n{\n\tstruct nvmem_cell *cell;\n\tsize_t cell_size;\n\tchar *mac;\n\n\tcell = nvmem_cell_get(dev, \"address\");\n\tif (IS_ERR(cell))\n\t\treturn cell;\n\n\tmac = nvmem_cell_read(cell, &cell_size);\n\tnvmem_cell_put(cell);\n\n\treturn mac;\n}\n\n \nstatic const struct of_device_id nixge_dt_ids[] = {\n\t{ .compatible = \"ni,xge-enet-2.00\", .data = (void *)NIXGE_V2 },\n\t{ .compatible = \"ni,xge-enet-3.00\", .data = (void *)NIXGE_V3 },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, nixge_dt_ids);\n\nstatic int nixge_of_get_resources(struct platform_device *pdev)\n{\n\tconst struct of_device_id *of_id;\n\tenum nixge_version version;\n\tstruct net_device *ndev;\n\tstruct nixge_priv *priv;\n\n\tndev = platform_get_drvdata(pdev);\n\tpriv = netdev_priv(ndev);\n\tof_id = of_match_node(nixge_dt_ids, pdev->dev.of_node);\n\tif (!of_id)\n\t\treturn -ENODEV;\n\n\tversion = (enum nixge_version)of_id->data;\n\tif (version <= NIXGE_V2)\n\t\tpriv->dma_regs = devm_platform_get_and_ioremap_resource(pdev, 0, NULL);\n\telse\n\t\tpriv->dma_regs = devm_platform_ioremap_resource_byname(pdev, \"dma\");\n\tif (IS_ERR(priv->dma_regs)) {\n\t\tnetdev_err(ndev, \"failed to map dma regs\\n\");\n\t\treturn PTR_ERR(priv->dma_regs);\n\t}\n\tif (version <= NIXGE_V2)\n\t\tpriv->ctrl_regs = priv->dma_regs + NIXGE_REG_CTRL_OFFSET;\n\telse\n\t\tpriv->ctrl_regs = devm_platform_ioremap_resource_byname(pdev, \"ctrl\");\n\tif (IS_ERR(priv->ctrl_regs)) {\n\t\tnetdev_err(ndev, \"failed to map ctrl regs\\n\");\n\t\treturn PTR_ERR(priv->ctrl_regs);\n\t}\n\treturn 0;\n}\n\nstatic int nixge_probe(struct platform_device *pdev)\n{\n\tstruct device_node *mn, *phy_node;\n\tstruct nixge_priv *priv;\n\tstruct net_device *ndev;\n\tconst u8 *mac_addr;\n\tint err;\n\n\tndev = alloc_etherdev(sizeof(*priv));\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, ndev);\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\n\tndev->features = NETIF_F_SG;\n\tndev->netdev_ops = &nixge_netdev_ops;\n\tndev->ethtool_ops = &nixge_ethtool_ops;\n\n\t \n\tndev->min_mtu = 64;\n\tndev->max_mtu = NIXGE_JUMBO_MTU;\n\n\tmac_addr = nixge_get_nvmem_address(&pdev->dev);\n\tif (!IS_ERR(mac_addr) && is_valid_ether_addr(mac_addr)) {\n\t\teth_hw_addr_set(ndev, mac_addr);\n\t\tkfree(mac_addr);\n\t} else {\n\t\teth_hw_addr_random(ndev);\n\t}\n\n\tpriv = netdev_priv(ndev);\n\tpriv->ndev = ndev;\n\tpriv->dev = &pdev->dev;\n\n\tnetif_napi_add(ndev, &priv->napi, nixge_poll);\n\terr = nixge_of_get_resources(pdev);\n\tif (err)\n\t\tgoto free_netdev;\n\t__nixge_hw_set_mac_address(ndev);\n\n\tpriv->tx_irq = platform_get_irq_byname(pdev, \"tx\");\n\tif (priv->tx_irq < 0) {\n\t\tnetdev_err(ndev, \"could not find 'tx' irq\");\n\t\terr = priv->tx_irq;\n\t\tgoto free_netdev;\n\t}\n\n\tpriv->rx_irq = platform_get_irq_byname(pdev, \"rx\");\n\tif (priv->rx_irq < 0) {\n\t\tnetdev_err(ndev, \"could not find 'rx' irq\");\n\t\terr = priv->rx_irq;\n\t\tgoto free_netdev;\n\t}\n\n\tpriv->coalesce_count_rx = XAXIDMA_DFT_RX_THRESHOLD;\n\tpriv->coalesce_count_tx = XAXIDMA_DFT_TX_THRESHOLD;\n\n\tmn = of_get_child_by_name(pdev->dev.of_node, \"mdio\");\n\tif (mn) {\n\t\terr = nixge_mdio_setup(priv, mn);\n\t\tof_node_put(mn);\n\t\tif (err) {\n\t\t\tnetdev_err(ndev, \"error registering mdio bus\");\n\t\t\tgoto free_netdev;\n\t\t}\n\t}\n\n\terr = of_get_phy_mode(pdev->dev.of_node, &priv->phy_mode);\n\tif (err) {\n\t\tnetdev_err(ndev, \"not find \\\"phy-mode\\\" property\\n\");\n\t\tgoto unregister_mdio;\n\t}\n\n\tphy_node = of_parse_phandle(pdev->dev.of_node, \"phy-handle\", 0);\n\tif (!phy_node && of_phy_is_fixed_link(pdev->dev.of_node)) {\n\t\terr = of_phy_register_fixed_link(pdev->dev.of_node);\n\t\tif (err < 0) {\n\t\t\tnetdev_err(ndev, \"broken fixed-link specification\\n\");\n\t\t\tgoto unregister_mdio;\n\t\t}\n\t\tphy_node = of_node_get(pdev->dev.of_node);\n\t}\n\tpriv->phy_node = phy_node;\n\n\terr = register_netdev(priv->ndev);\n\tif (err) {\n\t\tnetdev_err(ndev, \"register_netdev() error (%i)\\n\", err);\n\t\tgoto free_phy;\n\t}\n\n\treturn 0;\n\nfree_phy:\n\tif (of_phy_is_fixed_link(pdev->dev.of_node))\n\t\tof_phy_deregister_fixed_link(pdev->dev.of_node);\n\tof_node_put(phy_node);\n\nunregister_mdio:\n\tif (priv->mii_bus)\n\t\tmdiobus_unregister(priv->mii_bus);\n\nfree_netdev:\n\tfree_netdev(ndev);\n\n\treturn err;\n}\n\nstatic int nixge_remove(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct nixge_priv *priv = netdev_priv(ndev);\n\n\tunregister_netdev(ndev);\n\n\tif (of_phy_is_fixed_link(pdev->dev.of_node))\n\t\tof_phy_deregister_fixed_link(pdev->dev.of_node);\n\tof_node_put(priv->phy_node);\n\n\tif (priv->mii_bus)\n\t\tmdiobus_unregister(priv->mii_bus);\n\n\tfree_netdev(ndev);\n\n\treturn 0;\n}\n\nstatic struct platform_driver nixge_driver = {\n\t.probe\t\t= nixge_probe,\n\t.remove\t\t= nixge_remove,\n\t.driver\t\t= {\n\t\t.name\t\t= \"nixge\",\n\t\t.of_match_table\t= nixge_dt_ids,\n\t},\n};\nmodule_platform_driver(nixge_driver);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"National Instruments XGE Management MAC\");\nMODULE_AUTHOR(\"Moritz Fischer <mdf@kernel.org>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}