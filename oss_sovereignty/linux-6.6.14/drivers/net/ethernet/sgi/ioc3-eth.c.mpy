{
  "module_name": "ioc3-eth.c",
  "hash_id": "2240440c92460b34c873482ad6c65ecaa43599ae17ef915554dcc578864d98f7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sgi/ioc3-eth.c",
  "human_readable_source": "\n \n\n#define IOC3_NAME\t\"ioc3-eth\"\n#define IOC3_VERSION\t\"2.6.3-4\"\n\n#include <linux/delay.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/errno.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/crc16.h>\n#include <linux/crc32.h>\n#include <linux/mii.h>\n#include <linux/in.h>\n#include <linux/io.h>\n#include <linux/ip.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <linux/gfp.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/skbuff.h>\n#include <linux/dma-mapping.h>\n#include <linux/platform_device.h>\n#include <linux/nvmem-consumer.h>\n\n#include <net/ip.h>\n\n#include <asm/sn/ioc3.h>\n#include <asm/pci/bridge.h>\n\n#define CRC16_INIT\t0\n#define CRC16_VALID\t0xb001\n\n \n#define RX_BUFFS\t\t64\n#define RX_RING_ENTRIES\t\t512\t\t \n#define RX_RING_MASK\t\t(RX_RING_ENTRIES - 1)\n#define RX_RING_SIZE\t\t(RX_RING_ENTRIES * sizeof(u64))\n\n \n#define TX_RING_ENTRIES\t\t128\n#define TX_RING_MASK\t\t(TX_RING_ENTRIES - 1)\n#define TX_RING_SIZE\t\t(TX_RING_ENTRIES * sizeof(struct ioc3_etxd))\n\n \n#define IOC3_DMA_XFER_LEN\t128UL\n\n \n#define RX_OFFSET\t\t(sizeof(struct ioc3_erxbuf) + NET_IP_ALIGN)\n#define RX_BUF_SIZE\t\t(13 * IOC3_DMA_XFER_LEN)\n\n#define ETCSR_FD   ((21 << ETCSR_IPGR2_SHIFT) | (21 << ETCSR_IPGR1_SHIFT) | 21)\n#define ETCSR_HD   ((17 << ETCSR_IPGR2_SHIFT) | (11 << ETCSR_IPGR1_SHIFT) | 21)\n\n \nstruct ioc3_private {\n\tstruct ioc3_ethregs *regs;\n\tstruct device *dma_dev;\n\tu32 *ssram;\n\tunsigned long *rxr;\t\t \n\tvoid *tx_ring;\n\tstruct ioc3_etxd *txr;\n\tdma_addr_t rxr_dma;\n\tdma_addr_t txr_dma;\n\tstruct sk_buff *rx_skbs[RX_RING_ENTRIES];\n\tstruct sk_buff *tx_skbs[TX_RING_ENTRIES];\n\tint rx_ci;\t\t\t \n\tint rx_pi;\t\t\t \n\tint tx_ci;\t\t\t \n\tint tx_pi;\t\t\t \n\tint txqlen;\n\tu32 emcr, ehar_h, ehar_l;\n\tspinlock_t ioc3_lock;\n\tstruct mii_if_info mii;\n\n\t \n\tstruct timer_list ioc3_timer;\n};\n\nstatic int ioc3_ioctl(struct net_device *dev, struct ifreq *rq, int cmd);\nstatic void ioc3_set_multicast_list(struct net_device *dev);\nstatic netdev_tx_t ioc3_start_xmit(struct sk_buff *skb, struct net_device *dev);\nstatic void ioc3_timeout(struct net_device *dev, unsigned int txqueue);\nstatic inline unsigned int ioc3_hash(const unsigned char *addr);\nstatic void ioc3_start(struct ioc3_private *ip);\nstatic inline void ioc3_stop(struct ioc3_private *ip);\nstatic void ioc3_init(struct net_device *dev);\nstatic int ioc3_alloc_rx_bufs(struct net_device *dev);\nstatic void ioc3_free_rx_bufs(struct ioc3_private *ip);\nstatic inline void ioc3_clean_tx_ring(struct ioc3_private *ip);\n\nstatic const struct ethtool_ops ioc3_ethtool_ops;\n\nstatic inline unsigned long aligned_rx_skb_addr(unsigned long addr)\n{\n\treturn (~addr + 1) & (IOC3_DMA_XFER_LEN - 1UL);\n}\n\nstatic inline int ioc3_alloc_skb(struct ioc3_private *ip, struct sk_buff **skb,\n\t\t\t\t struct ioc3_erxbuf **rxb, dma_addr_t *rxb_dma)\n{\n\tstruct sk_buff *new_skb;\n\tdma_addr_t d;\n\tint offset;\n\n\tnew_skb = alloc_skb(RX_BUF_SIZE + IOC3_DMA_XFER_LEN - 1, GFP_ATOMIC);\n\tif (!new_skb)\n\t\treturn -ENOMEM;\n\n\t \n\toffset = aligned_rx_skb_addr((unsigned long)new_skb->data);\n\tif (offset)\n\t\tskb_reserve(new_skb, offset);\n\n\td = dma_map_single(ip->dma_dev, new_skb->data,\n\t\t\t   RX_BUF_SIZE, DMA_FROM_DEVICE);\n\n\tif (dma_mapping_error(ip->dma_dev, d)) {\n\t\tdev_kfree_skb_any(new_skb);\n\t\treturn -ENOMEM;\n\t}\n\t*rxb_dma = d;\n\t*rxb = (struct ioc3_erxbuf *)new_skb->data;\n\tskb_reserve(new_skb, RX_OFFSET);\n\t*skb = new_skb;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PCI_XTALK_BRIDGE\nstatic inline unsigned long ioc3_map(dma_addr_t addr, unsigned long attr)\n{\n\treturn (addr & ~PCI64_ATTR_BAR) | attr;\n}\n\n#define ERBAR_VAL\t(ERBAR_BARRIER_BIT << ERBAR_RXBARR_SHIFT)\n#else\nstatic inline unsigned long ioc3_map(dma_addr_t addr, unsigned long attr)\n{\n\treturn addr;\n}\n\n#define ERBAR_VAL\t0\n#endif\n\nstatic int ioc3eth_nvmem_match(struct device *dev, const void *data)\n{\n\tconst char *name = dev_name(dev);\n\tconst char *prefix = data;\n\tint prefix_len;\n\n\tprefix_len = strlen(prefix);\n\tif (strlen(name) < (prefix_len + 3))\n\t\treturn 0;\n\n\tif (memcmp(prefix, name, prefix_len) != 0)\n\t\treturn 0;\n\n\t \n\tif (memcmp(name + prefix_len, \"09-\", 3) == 0)\n\t\treturn 1;\n\tif (memcmp(name + prefix_len, \"89-\", 3) == 0)\n\t\treturn 1;\n\tif (memcmp(name + prefix_len, \"91-\", 3) == 0)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic int ioc3eth_get_mac_addr(struct resource *res, u8 mac_addr[6])\n{\n\tstruct nvmem_device *nvmem;\n\tchar prefix[24];\n\tu8 prom[16];\n\tint ret;\n\tint i;\n\n\tsnprintf(prefix, sizeof(prefix), \"ioc3-%012llx-\",\n\t\t res->start & ~0xffff);\n\n\tnvmem = nvmem_device_find(prefix, ioc3eth_nvmem_match);\n\tif (IS_ERR(nvmem))\n\t\treturn PTR_ERR(nvmem);\n\n\tret = nvmem_device_read(nvmem, 0, 16, prom);\n\tnvmem_device_put(nvmem);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tif (prom[0] != 0x0a ||\n\t    crc16(CRC16_INIT, prom, 13) != CRC16_VALID)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < 6; i++)\n\t\tmac_addr[i] = prom[10 - i];\n\n\treturn 0;\n}\n\nstatic void __ioc3_set_mac_address(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\n\twritel((dev->dev_addr[5] <<  8) |\n\t       dev->dev_addr[4],\n\t       &ip->regs->emar_h);\n\twritel((dev->dev_addr[3] << 24) |\n\t       (dev->dev_addr[2] << 16) |\n\t       (dev->dev_addr[1] <<  8) |\n\t       dev->dev_addr[0],\n\t       &ip->regs->emar_l);\n}\n\nstatic int ioc3_set_mac_address(struct net_device *dev, void *addr)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct sockaddr *sa = addr;\n\n\teth_hw_addr_set(dev, sa->sa_data);\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\t__ioc3_set_mac_address(dev);\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn 0;\n}\n\n \nstatic int ioc3_mdio_read(struct net_device *dev, int phy, int reg)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_ethregs *regs = ip->regs;\n\n\twhile (readl(&regs->micr) & MICR_BUSY)\n\t\t;\n\twritel((phy << MICR_PHYADDR_SHIFT) | reg | MICR_READTRIG,\n\t       &regs->micr);\n\twhile (readl(&regs->micr) & MICR_BUSY)\n\t\t;\n\n\treturn readl(&regs->midr_r) & MIDR_DATA_MASK;\n}\n\nstatic void ioc3_mdio_write(struct net_device *dev, int phy, int reg, int data)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_ethregs *regs = ip->regs;\n\n\twhile (readl(&regs->micr) & MICR_BUSY)\n\t\t;\n\twritel(data, &regs->midr_w);\n\twritel((phy << MICR_PHYADDR_SHIFT) | reg, &regs->micr);\n\twhile (readl(&regs->micr) & MICR_BUSY)\n\t\t;\n}\n\nstatic int ioc3_mii_init(struct ioc3_private *ip);\n\nstatic struct net_device_stats *ioc3_get_stats(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_ethregs *regs = ip->regs;\n\n\tdev->stats.collisions += readl(&regs->etcdc) & ETCDC_COLLCNT_MASK;\n\treturn &dev->stats;\n}\n\nstatic void ioc3_tcpudp_checksum(struct sk_buff *skb, u32 hwsum, int len)\n{\n\tstruct ethhdr *eh = eth_hdr(skb);\n\tunsigned int proto;\n\tunsigned char *cp;\n\tstruct iphdr *ih;\n\tu32 csum, ehsum;\n\tu16 *ew;\n\n\t \n\tif (eh->h_proto != htons(ETH_P_IP))\n\t\treturn;\n\n\tih = (struct iphdr *)((char *)eh + ETH_HLEN);\n\tif (ip_is_fragment(ih))\n\t\treturn;\n\n\tproto = ih->protocol;\n\tif (proto != IPPROTO_TCP && proto != IPPROTO_UDP)\n\t\treturn;\n\n\t \n\tcsum = hwsum +\n\t       (ih->tot_len - (ih->ihl << 2)) +\n\t       htons((u16)ih->protocol) +\n\t       (ih->saddr >> 16) + (ih->saddr & 0xffff) +\n\t       (ih->daddr >> 16) + (ih->daddr & 0xffff);\n\n\t \n\tew = (u16 *)eh;\n\tehsum = ew[0] + ew[1] + ew[2] + ew[3] + ew[4] + ew[5] + ew[6];\n\n\tehsum = (ehsum & 0xffff) + (ehsum >> 16);\n\tehsum = (ehsum & 0xffff) + (ehsum >> 16);\n\n\tcsum += 0xffff ^ ehsum;\n\n\t \n\tcp = (char *)eh + len;\t \n\tif (len & 1) {\n\t\tcsum += 0xffff ^ (u16)((cp[1] << 8) | cp[0]);\n\t\tcsum += 0xffff ^ (u16)((cp[3] << 8) | cp[2]);\n\t} else {\n\t\tcsum += 0xffff ^ (u16)((cp[0] << 8) | cp[1]);\n\t\tcsum += 0xffff ^ (u16)((cp[2] << 8) | cp[3]);\n\t}\n\n\tcsum = (csum & 0xffff) + (csum >> 16);\n\tcsum = (csum & 0xffff) + (csum >> 16);\n\n\tif (csum == 0xffff)\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n}\n\nstatic inline void ioc3_rx(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct sk_buff *skb, *new_skb;\n\tint rx_entry, n_entry, len;\n\tstruct ioc3_erxbuf *rxb;\n\tunsigned long *rxr;\n\tdma_addr_t d;\n\tu32 w0, err;\n\n\trxr = ip->rxr;\t\t \n\trx_entry = ip->rx_ci;\t\t\t\t \n\tn_entry = ip->rx_pi;\n\n\tskb = ip->rx_skbs[rx_entry];\n\trxb = (struct ioc3_erxbuf *)(skb->data - RX_OFFSET);\n\tw0 = be32_to_cpu(rxb->w0);\n\n\twhile (w0 & ERXBUF_V) {\n\t\terr = be32_to_cpu(rxb->err);\t\t \n\t\tif (err & ERXBUF_GOODPKT) {\n\t\t\tlen = ((w0 >> ERXBUF_BYTECNT_SHIFT) & 0x7ff) - 4;\n\t\t\tskb_put(skb, len);\n\t\t\tskb->protocol = eth_type_trans(skb, dev);\n\n\t\t\tif (ioc3_alloc_skb(ip, &new_skb, &rxb, &d)) {\n\t\t\t\t \n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\tnew_skb = skb;\n\t\t\t\td = rxr[rx_entry];\n\t\t\t\tgoto next;\n\t\t\t}\n\n\t\t\tif (likely(dev->features & NETIF_F_RXCSUM))\n\t\t\t\tioc3_tcpudp_checksum(skb,\n\t\t\t\t\t\t     w0 & ERXBUF_IPCKSUM_MASK,\n\t\t\t\t\t\t     len);\n\n\t\t\tdma_unmap_single(ip->dma_dev, rxr[rx_entry],\n\t\t\t\t\t RX_BUF_SIZE, DMA_FROM_DEVICE);\n\n\t\t\tnetif_rx(skb);\n\n\t\t\tip->rx_skbs[rx_entry] = NULL;\t \n\n\t\t\tdev->stats.rx_packets++;\t\t \n\t\t\tdev->stats.rx_bytes += len;\n\t\t} else {\n\t\t\t \n\t\t\tnew_skb = skb;\n\t\t\td = rxr[rx_entry];\n\t\t\tdev->stats.rx_errors++;\n\t\t}\n\t\tif (err & ERXBUF_CRCERR)\t \n\t\t\tdev->stats.rx_crc_errors++;\n\t\tif (err & ERXBUF_FRAMERR)\n\t\t\tdev->stats.rx_frame_errors++;\n\nnext:\n\t\tip->rx_skbs[n_entry] = new_skb;\n\t\trxr[n_entry] = cpu_to_be64(ioc3_map(d, PCI64_ATTR_BAR));\n\t\trxb->w0 = 0;\t\t\t\t \n\t\tn_entry = (n_entry + 1) & RX_RING_MASK;\t \n\n\t\t \n\t\trx_entry = (rx_entry + 1) & RX_RING_MASK;\n\t\tskb = ip->rx_skbs[rx_entry];\n\t\trxb = (struct ioc3_erxbuf *)(skb->data - RX_OFFSET);\n\t\tw0 = be32_to_cpu(rxb->w0);\n\t}\n\twritel((n_entry << 3) | ERPIR_ARM, &ip->regs->erpir);\n\tip->rx_pi = n_entry;\n\tip->rx_ci = rx_entry;\n}\n\nstatic inline void ioc3_tx(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_ethregs *regs = ip->regs;\n\tunsigned long packets, bytes;\n\tint tx_entry, o_entry;\n\tstruct sk_buff *skb;\n\tu32 etcir;\n\n\tspin_lock(&ip->ioc3_lock);\n\tetcir = readl(&regs->etcir);\n\n\ttx_entry = (etcir >> 7) & TX_RING_MASK;\n\to_entry = ip->tx_ci;\n\tpackets = 0;\n\tbytes = 0;\n\n\twhile (o_entry != tx_entry) {\n\t\tpackets++;\n\t\tskb = ip->tx_skbs[o_entry];\n\t\tbytes += skb->len;\n\t\tdev_consume_skb_irq(skb);\n\t\tip->tx_skbs[o_entry] = NULL;\n\n\t\to_entry = (o_entry + 1) & TX_RING_MASK;\t \n\n\t\tetcir = readl(&regs->etcir);\t\t \n\t\ttx_entry = (etcir >> 7) & TX_RING_MASK;\n\t}\n\n\tdev->stats.tx_packets += packets;\n\tdev->stats.tx_bytes += bytes;\n\tip->txqlen -= packets;\n\n\tif (netif_queue_stopped(dev) && ip->txqlen < TX_RING_ENTRIES)\n\t\tnetif_wake_queue(dev);\n\n\tip->tx_ci = o_entry;\n\tspin_unlock(&ip->ioc3_lock);\n}\n\n \nstatic void ioc3_error(struct net_device *dev, u32 eisr)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\n\tspin_lock(&ip->ioc3_lock);\n\n\tif (eisr & EISR_RXOFLO)\n\t\tnet_err_ratelimited(\"%s: RX overflow.\\n\", dev->name);\n\tif (eisr & EISR_RXBUFOFLO)\n\t\tnet_err_ratelimited(\"%s: RX buffer overflow.\\n\", dev->name);\n\tif (eisr & EISR_RXMEMERR)\n\t\tnet_err_ratelimited(\"%s: RX PCI error.\\n\", dev->name);\n\tif (eisr & EISR_RXPARERR)\n\t\tnet_err_ratelimited(\"%s: RX SSRAM parity error.\\n\", dev->name);\n\tif (eisr & EISR_TXBUFUFLO)\n\t\tnet_err_ratelimited(\"%s: TX buffer underflow.\\n\", dev->name);\n\tif (eisr & EISR_TXMEMERR)\n\t\tnet_err_ratelimited(\"%s: TX PCI error.\\n\", dev->name);\n\n\tioc3_stop(ip);\n\tioc3_free_rx_bufs(ip);\n\tioc3_clean_tx_ring(ip);\n\n\tioc3_init(dev);\n\tif (ioc3_alloc_rx_bufs(dev)) {\n\t\tnetdev_err(dev, \"%s: rx buffer allocation failed\\n\", __func__);\n\t\tspin_unlock(&ip->ioc3_lock);\n\t\treturn;\n\t}\n\tioc3_start(ip);\n\tioc3_mii_init(ip);\n\n\tnetif_wake_queue(dev);\n\n\tspin_unlock(&ip->ioc3_lock);\n}\n\n \nstatic irqreturn_t ioc3_interrupt(int irq, void *dev_id)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev_id);\n\tstruct ioc3_ethregs *regs = ip->regs;\n\tu32 eisr;\n\n\teisr = readl(&regs->eisr);\n\twritel(eisr, &regs->eisr);\n\treadl(&regs->eisr);\t\t\t\t \n\n\tif (eisr & (EISR_RXOFLO | EISR_RXBUFOFLO | EISR_RXMEMERR |\n\t\t    EISR_RXPARERR | EISR_TXBUFUFLO | EISR_TXMEMERR))\n\t\tioc3_error(dev_id, eisr);\n\tif (eisr & EISR_RXTIMERINT)\n\t\tioc3_rx(dev_id);\n\tif (eisr & EISR_TXEXPLICIT)\n\t\tioc3_tx(dev_id);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic inline void ioc3_setup_duplex(struct ioc3_private *ip)\n{\n\tstruct ioc3_ethregs *regs = ip->regs;\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\n\tif (ip->mii.full_duplex) {\n\t\twritel(ETCSR_FD, &regs->etcsr);\n\t\tip->emcr |= EMCR_DUPLEX;\n\t} else {\n\t\twritel(ETCSR_HD, &regs->etcsr);\n\t\tip->emcr &= ~EMCR_DUPLEX;\n\t}\n\twritel(ip->emcr, &regs->emcr);\n\n\tspin_unlock_irq(&ip->ioc3_lock);\n}\n\nstatic void ioc3_timer(struct timer_list *t)\n{\n\tstruct ioc3_private *ip = from_timer(ip, t, ioc3_timer);\n\n\t \n\tmii_check_media(&ip->mii, 1, 0);\n\tioc3_setup_duplex(ip);\n\n\tip->ioc3_timer.expires = jiffies + ((12 * HZ) / 10);  \n\tadd_timer(&ip->ioc3_timer);\n}\n\n \nstatic int ioc3_mii_init(struct ioc3_private *ip)\n{\n\tu16 word;\n\tint i;\n\n\tfor (i = 0; i < 32; i++) {\n\t\tword = ioc3_mdio_read(ip->mii.dev, i, MII_PHYSID1);\n\n\t\tif (word != 0xffff && word != 0x0000) {\n\t\t\tip->mii.phy_id = i;\n\t\t\treturn 0;\n\t\t}\n\t}\n\tip->mii.phy_id = -1;\n\treturn -ENODEV;\n}\n\nstatic void ioc3_mii_start(struct ioc3_private *ip)\n{\n\tip->ioc3_timer.expires = jiffies + (12 * HZ) / 10;   \n\tadd_timer(&ip->ioc3_timer);\n}\n\nstatic inline void ioc3_tx_unmap(struct ioc3_private *ip, int entry)\n{\n\tstruct ioc3_etxd *desc;\n\tu32 cmd, bufcnt, len;\n\n\tdesc = &ip->txr[entry];\n\tcmd = be32_to_cpu(desc->cmd);\n\tbufcnt = be32_to_cpu(desc->bufcnt);\n\tif (cmd & ETXD_B1V) {\n\t\tlen = (bufcnt & ETXD_B1CNT_MASK) >> ETXD_B1CNT_SHIFT;\n\t\tdma_unmap_single(ip->dma_dev, be64_to_cpu(desc->p1),\n\t\t\t\t len, DMA_TO_DEVICE);\n\t}\n\tif (cmd & ETXD_B2V) {\n\t\tlen = (bufcnt & ETXD_B2CNT_MASK) >> ETXD_B2CNT_SHIFT;\n\t\tdma_unmap_single(ip->dma_dev, be64_to_cpu(desc->p2),\n\t\t\t\t len, DMA_TO_DEVICE);\n\t}\n}\n\nstatic inline void ioc3_clean_tx_ring(struct ioc3_private *ip)\n{\n\tstruct sk_buff *skb;\n\tint i;\n\n\tfor (i = 0; i < TX_RING_ENTRIES; i++) {\n\t\tskb = ip->tx_skbs[i];\n\t\tif (skb) {\n\t\t\tioc3_tx_unmap(ip, i);\n\t\t\tip->tx_skbs[i] = NULL;\n\t\t\tdev_kfree_skb_any(skb);\n\t\t}\n\t\tip->txr[i].cmd = 0;\n\t}\n\tip->tx_pi = 0;\n\tip->tx_ci = 0;\n}\n\nstatic void ioc3_free_rx_bufs(struct ioc3_private *ip)\n{\n\tint rx_entry, n_entry;\n\tstruct sk_buff *skb;\n\n\tn_entry = ip->rx_ci;\n\trx_entry = ip->rx_pi;\n\n\twhile (n_entry != rx_entry) {\n\t\tskb = ip->rx_skbs[n_entry];\n\t\tif (skb) {\n\t\t\tdma_unmap_single(ip->dma_dev,\n\t\t\t\t\t be64_to_cpu(ip->rxr[n_entry]),\n\t\t\t\t\t RX_BUF_SIZE, DMA_FROM_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t}\n\t\tn_entry = (n_entry + 1) & RX_RING_MASK;\n\t}\n}\n\nstatic int ioc3_alloc_rx_bufs(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_erxbuf *rxb;\n\tdma_addr_t d;\n\tint i;\n\n\t \n\tfor (i = 0; i < RX_BUFFS; i++) {\n\t\tif (ioc3_alloc_skb(ip, &ip->rx_skbs[i], &rxb, &d))\n\t\t\treturn -ENOMEM;\n\n\t\trxb->w0 = 0;\t \n\t\tip->rxr[i] = cpu_to_be64(ioc3_map(d, PCI64_ATTR_BAR));\n\t}\n\tip->rx_ci = 0;\n\tip->rx_pi = RX_BUFFS;\n\n\treturn 0;\n}\n\nstatic inline void ioc3_ssram_disc(struct ioc3_private *ip)\n{\n\tstruct ioc3_ethregs *regs = ip->regs;\n\tu32 *ssram0 = &ip->ssram[0x0000];\n\tu32 *ssram1 = &ip->ssram[0x4000];\n\tu32 pattern = 0x5555;\n\n\t \n\twritel(readl(&regs->emcr) | (EMCR_BUFSIZ | EMCR_RAMPAR), &regs->emcr);\n\treadl(&regs->emcr);  \n\n\twritel(pattern, ssram0);\n\twritel(~pattern & IOC3_SSRAM_DM, ssram1);\n\n\tif ((readl(ssram0) & IOC3_SSRAM_DM) != pattern ||\n\t    (readl(ssram1) & IOC3_SSRAM_DM) != (~pattern & IOC3_SSRAM_DM)) {\n\t\t \n\t\tip->emcr |= EMCR_RAMPAR;\n\t\twritel(readl(&regs->emcr) & ~EMCR_BUFSIZ, &regs->emcr);\n\t} else {\n\t\tip->emcr |= EMCR_BUFSIZ | EMCR_RAMPAR;\n\t}\n}\n\nstatic void ioc3_init(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_ethregs *regs = ip->regs;\n\n\tdel_timer_sync(&ip->ioc3_timer);\t \n\n\twritel(EMCR_RST, &regs->emcr);\t\t \n\treadl(&regs->emcr);\t\t\t \n\tudelay(4);\t\t\t\t \n\twritel(0, &regs->emcr);\n\treadl(&regs->emcr);\n\n\t \n\twritel(ERBAR_VAL, &regs->erbar);\n\treadl(&regs->etcdc);\t\t\t \n\twritel(15, &regs->ercsr);\t\t \n\twritel(0, &regs->ertr);\t\t\t \n\t__ioc3_set_mac_address(dev);\n\twritel(ip->ehar_h, &regs->ehar_h);\n\twritel(ip->ehar_l, &regs->ehar_l);\n\twritel(42, &regs->ersr);\t\t \n}\n\nstatic void ioc3_start(struct ioc3_private *ip)\n{\n\tstruct ioc3_ethregs *regs = ip->regs;\n\tunsigned long ring;\n\n\t \n\tring = ioc3_map(ip->rxr_dma, PCI64_ATTR_PREC);\n\twritel(ring >> 32, &regs->erbr_h);\n\twritel(ring & 0xffffffff, &regs->erbr_l);\n\twritel(ip->rx_ci << 3, &regs->ercir);\n\twritel((ip->rx_pi << 3) | ERPIR_ARM, &regs->erpir);\n\n\tring = ioc3_map(ip->txr_dma, PCI64_ATTR_PREC);\n\n\tip->txqlen = 0;\t\t\t\t\t \n\n\t \n\twritel(ring >> 32, &regs->etbr_h);\n\twritel(ring & 0xffffffff, &regs->etbr_l);\n\twritel(ip->tx_pi << 7, &regs->etpir);\n\twritel(ip->tx_ci << 7, &regs->etcir);\n\treadl(&regs->etcir);\t\t\t\t \n\n\tip->emcr |= ((RX_OFFSET / 2) << EMCR_RXOFF_SHIFT) | EMCR_TXDMAEN |\n\t\t    EMCR_TXEN | EMCR_RXDMAEN | EMCR_RXEN | EMCR_PADEN;\n\twritel(ip->emcr, &regs->emcr);\n\twritel(EISR_RXTIMERINT | EISR_RXOFLO | EISR_RXBUFOFLO |\n\t       EISR_RXMEMERR | EISR_RXPARERR | EISR_TXBUFUFLO |\n\t       EISR_TXEXPLICIT | EISR_TXMEMERR, &regs->eier);\n\treadl(&regs->eier);\n}\n\nstatic inline void ioc3_stop(struct ioc3_private *ip)\n{\n\tstruct ioc3_ethregs *regs = ip->regs;\n\n\twritel(0, &regs->emcr);\t\t\t \n\twritel(0, &regs->eier);\t\t\t \n\treadl(&regs->eier);\t\t\t \n}\n\nstatic int ioc3_open(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\n\tip->ehar_h = 0;\n\tip->ehar_l = 0;\n\n\tioc3_init(dev);\n\tif (ioc3_alloc_rx_bufs(dev)) {\n\t\tnetdev_err(dev, \"%s: rx buffer allocation failed\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\tioc3_start(ip);\n\tioc3_mii_start(ip);\n\n\tnetif_start_queue(dev);\n\treturn 0;\n}\n\nstatic int ioc3_close(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\n\tdel_timer_sync(&ip->ioc3_timer);\n\n\tnetif_stop_queue(dev);\n\n\tioc3_stop(ip);\n\n\tioc3_free_rx_bufs(ip);\n\tioc3_clean_tx_ring(ip);\n\n\treturn 0;\n}\n\nstatic const struct net_device_ops ioc3_netdev_ops = {\n\t.ndo_open\t\t= ioc3_open,\n\t.ndo_stop\t\t= ioc3_close,\n\t.ndo_start_xmit\t\t= ioc3_start_xmit,\n\t.ndo_tx_timeout\t\t= ioc3_timeout,\n\t.ndo_get_stats\t\t= ioc3_get_stats,\n\t.ndo_set_rx_mode\t= ioc3_set_multicast_list,\n\t.ndo_eth_ioctl\t\t= ioc3_ioctl,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= ioc3_set_mac_address,\n};\n\nstatic int ioc3eth_probe(struct platform_device *pdev)\n{\n\tu32 sw_physid1, sw_physid2, vendor, model, rev;\n\tstruct ioc3_private *ip;\n\tstruct net_device *dev;\n\tstruct resource *regs;\n\tu8 mac_addr[6];\n\tint err;\n\n\tregs = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!regs) {\n\t\tdev_err(&pdev->dev, \"Invalid resource\\n\");\n\t\treturn -EINVAL;\n\t}\n\t \n\tif (ioc3eth_get_mac_addr(regs, mac_addr))\n\t\treturn -EPROBE_DEFER;  \n\n\tdev = alloc_etherdev(sizeof(struct ioc3_private));\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\tip = netdev_priv(dev);\n\tip->dma_dev = pdev->dev.parent;\n\tip->regs = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(ip->regs)) {\n\t\terr = PTR_ERR(ip->regs);\n\t\tgoto out_free;\n\t}\n\n\tip->ssram = devm_platform_ioremap_resource(pdev, 1);\n\tif (IS_ERR(ip->ssram)) {\n\t\terr = PTR_ERR(ip->ssram);\n\t\tgoto out_free;\n\t}\n\n\tdev->irq = platform_get_irq(pdev, 0);\n\tif (dev->irq < 0) {\n\t\terr = dev->irq;\n\t\tgoto out_free;\n\t}\n\n\tif (devm_request_irq(&pdev->dev, dev->irq, ioc3_interrupt,\n\t\t\t     IRQF_SHARED, \"ioc3-eth\", dev)) {\n\t\tdev_err(&pdev->dev, \"Can't get irq %d\\n\", dev->irq);\n\t\terr = -ENODEV;\n\t\tgoto out_free;\n\t}\n\n\tspin_lock_init(&ip->ioc3_lock);\n\ttimer_setup(&ip->ioc3_timer, ioc3_timer, 0);\n\n\tioc3_stop(ip);\n\n\t \n\tip->rxr = dma_alloc_coherent(ip->dma_dev, RX_RING_SIZE, &ip->rxr_dma,\n\t\t\t\t     GFP_KERNEL);\n\tif (!ip->rxr) {\n\t\tpr_err(\"ioc3-eth: rx ring allocation failed\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto out_stop;\n\t}\n\n\t \n\tip->tx_ring = dma_alloc_coherent(ip->dma_dev, TX_RING_SIZE + SZ_16K - 1,\n\t\t\t\t\t &ip->txr_dma, GFP_KERNEL);\n\tif (!ip->tx_ring) {\n\t\tpr_err(\"ioc3-eth: tx ring allocation failed\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto out_stop;\n\t}\n\t \n\tip->txr = PTR_ALIGN(ip->tx_ring, SZ_16K);\n\tip->txr_dma = ALIGN(ip->txr_dma, SZ_16K);\n\n\tioc3_init(dev);\n\n\tip->mii.phy_id_mask = 0x1f;\n\tip->mii.reg_num_mask = 0x1f;\n\tip->mii.dev = dev;\n\tip->mii.mdio_read = ioc3_mdio_read;\n\tip->mii.mdio_write = ioc3_mdio_write;\n\n\tioc3_mii_init(ip);\n\n\tif (ip->mii.phy_id == -1) {\n\t\tnetdev_err(dev, \"Didn't find a PHY, goodbye.\\n\");\n\t\terr = -ENODEV;\n\t\tgoto out_stop;\n\t}\n\n\tioc3_mii_start(ip);\n\tioc3_ssram_disc(ip);\n\teth_hw_addr_set(dev, mac_addr);\n\n\t \n\tdev->watchdog_timeo\t= 5 * HZ;\n\tdev->netdev_ops\t\t= &ioc3_netdev_ops;\n\tdev->ethtool_ops\t= &ioc3_ethtool_ops;\n\tdev->hw_features\t= NETIF_F_IP_CSUM | NETIF_F_RXCSUM;\n\tdev->features\t\t= NETIF_F_IP_CSUM | NETIF_F_HIGHDMA;\n\n\tsw_physid1 = ioc3_mdio_read(dev, ip->mii.phy_id, MII_PHYSID1);\n\tsw_physid2 = ioc3_mdio_read(dev, ip->mii.phy_id, MII_PHYSID2);\n\n\terr = register_netdev(dev);\n\tif (err)\n\t\tgoto out_stop;\n\n\tmii_check_media(&ip->mii, 1, 1);\n\tioc3_setup_duplex(ip);\n\n\tvendor = (sw_physid1 << 12) | (sw_physid2 >> 4);\n\tmodel  = (sw_physid2 >> 4) & 0x3f;\n\trev    = sw_physid2 & 0xf;\n\tnetdev_info(dev, \"Using PHY %d, vendor 0x%x, model %d, rev %d.\\n\",\n\t\t    ip->mii.phy_id, vendor, model, rev);\n\tnetdev_info(dev, \"IOC3 SSRAM has %d kbyte.\\n\",\n\t\t    ip->emcr & EMCR_BUFSIZ ? 128 : 64);\n\n\treturn 0;\n\nout_stop:\n\tdel_timer_sync(&ip->ioc3_timer);\n\tif (ip->rxr)\n\t\tdma_free_coherent(ip->dma_dev, RX_RING_SIZE, ip->rxr,\n\t\t\t\t  ip->rxr_dma);\n\tif (ip->tx_ring)\n\t\tdma_free_coherent(ip->dma_dev, TX_RING_SIZE + SZ_16K - 1, ip->tx_ring,\n\t\t\t\t  ip->txr_dma);\nout_free:\n\tfree_netdev(dev);\n\treturn err;\n}\n\nstatic int ioc3eth_remove(struct platform_device *pdev)\n{\n\tstruct net_device *dev = platform_get_drvdata(pdev);\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\n\tdma_free_coherent(ip->dma_dev, RX_RING_SIZE, ip->rxr, ip->rxr_dma);\n\tdma_free_coherent(ip->dma_dev, TX_RING_SIZE + SZ_16K - 1, ip->tx_ring, ip->txr_dma);\n\n\tunregister_netdev(dev);\n\tdel_timer_sync(&ip->ioc3_timer);\n\tfree_netdev(dev);\n\n\treturn 0;\n}\n\n\nstatic netdev_tx_t ioc3_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_etxd *desc;\n\tunsigned long data;\n\tunsigned int len;\n\tint produce;\n\tu32 w0 = 0;\n\n\t \n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tconst struct iphdr *ih = ip_hdr(skb);\n\t\tconst int proto = ntohs(ih->protocol);\n\t\tunsigned int csoff;\n\t\tu32 csum, ehsum;\n\t\tu16 *eh;\n\n\t\t \n\t\teh = (u16 *)skb->data;\n\n\t\t \n\t\tehsum = eh[0] + eh[1] + eh[2] + eh[3] + eh[4] + eh[5] + eh[6];\n\n\t\t \n\t\tcsum = csum_tcpudp_nofold(ih->saddr, ih->daddr,\n\t\t\t\t\t  ih->tot_len - (ih->ihl << 2),\n\t\t\t\t\t  proto, csum_fold(ehsum));\n\n\t\tcsum = (csum & 0xffff) + (csum >> 16);\t \n\t\tcsum = (csum & 0xffff) + (csum >> 16);\n\n\t\tcsoff = ETH_HLEN + (ih->ihl << 2);\n\t\tif (proto == IPPROTO_UDP) {\n\t\t\tcsoff += offsetof(struct udphdr, check);\n\t\t\tudp_hdr(skb)->check = csum;\n\t\t}\n\t\tif (proto == IPPROTO_TCP) {\n\t\t\tcsoff += offsetof(struct tcphdr, check);\n\t\t\ttcp_hdr(skb)->check = csum;\n\t\t}\n\n\t\tw0 = ETXD_DOCHECKSUM | (csoff << ETXD_CHKOFF_SHIFT);\n\t}\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\n\tdata = (unsigned long)skb->data;\n\tlen = skb->len;\n\n\tproduce = ip->tx_pi;\n\tdesc = &ip->txr[produce];\n\n\tif (len <= 104) {\n\t\t \n\t\tskb_copy_from_linear_data(skb, desc->data, skb->len);\n\t\tif (len < ETH_ZLEN) {\n\t\t\t \n\t\t\tmemset(desc->data + len, 0, ETH_ZLEN - len);\n\t\t\tlen = ETH_ZLEN;\n\t\t}\n\t\tdesc->cmd = cpu_to_be32(len | ETXD_INTWHENDONE | ETXD_D0V | w0);\n\t\tdesc->bufcnt = cpu_to_be32(len);\n\t} else if ((data ^ (data + len - 1)) & 0x4000) {\n\t\tunsigned long b2 = (data | 0x3fffUL) + 1UL;\n\t\tunsigned long s1 = b2 - data;\n\t\tunsigned long s2 = data + len - b2;\n\t\tdma_addr_t d1, d2;\n\n\t\tdesc->cmd    = cpu_to_be32(len | ETXD_INTWHENDONE |\n\t\t\t\t\t   ETXD_B1V | ETXD_B2V | w0);\n\t\tdesc->bufcnt = cpu_to_be32((s1 << ETXD_B1CNT_SHIFT) |\n\t\t\t\t\t   (s2 << ETXD_B2CNT_SHIFT));\n\t\td1 = dma_map_single(ip->dma_dev, skb->data, s1, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ip->dma_dev, d1))\n\t\t\tgoto drop_packet;\n\t\td2 = dma_map_single(ip->dma_dev, (void *)b2, s1, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ip->dma_dev, d2)) {\n\t\t\tdma_unmap_single(ip->dma_dev, d1, len, DMA_TO_DEVICE);\n\t\t\tgoto drop_packet;\n\t\t}\n\t\tdesc->p1     = cpu_to_be64(ioc3_map(d1, PCI64_ATTR_PREF));\n\t\tdesc->p2     = cpu_to_be64(ioc3_map(d2, PCI64_ATTR_PREF));\n\t} else {\n\t\tdma_addr_t d;\n\n\t\t \n\t\tdesc->cmd = cpu_to_be32(len | ETXD_INTWHENDONE | ETXD_B1V | w0);\n\t\tdesc->bufcnt = cpu_to_be32(len << ETXD_B1CNT_SHIFT);\n\t\td = dma_map_single(ip->dma_dev, skb->data, len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ip->dma_dev, d))\n\t\t\tgoto drop_packet;\n\t\tdesc->p1     = cpu_to_be64(ioc3_map(d, PCI64_ATTR_PREF));\n\t}\n\n\tmb();  \n\n\tip->tx_skbs[produce] = skb;\t\t\t \n\tproduce = (produce + 1) & TX_RING_MASK;\n\tip->tx_pi = produce;\n\twritel(produce << 7, &ip->regs->etpir);\t\t \n\n\tip->txqlen++;\n\n\tif (ip->txqlen >= (TX_RING_ENTRIES - 1))\n\t\tnetif_stop_queue(dev);\n\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn NETDEV_TX_OK;\n\ndrop_packet:\n\tdev_kfree_skb_any(skb);\n\tdev->stats.tx_dropped++;\n\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void ioc3_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\n\tnetdev_err(dev, \"transmit timed out, resetting\\n\");\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\n\tioc3_stop(ip);\n\tioc3_free_rx_bufs(ip);\n\tioc3_clean_tx_ring(ip);\n\n\tioc3_init(dev);\n\tif (ioc3_alloc_rx_bufs(dev)) {\n\t\tnetdev_err(dev, \"%s: rx buffer allocation failed\\n\", __func__);\n\t\tspin_unlock_irq(&ip->ioc3_lock);\n\t\treturn;\n\t}\n\tioc3_start(ip);\n\tioc3_mii_init(ip);\n\tioc3_mii_start(ip);\n\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\tnetif_wake_queue(dev);\n}\n\n \nstatic inline unsigned int ioc3_hash(const unsigned char *addr)\n{\n\tunsigned int temp = 0;\n\tint bits;\n\tu32 crc;\n\n\tcrc = ether_crc_le(ETH_ALEN, addr);\n\n\tcrc &= 0x3f;     \n\tfor (bits = 6; --bits >= 0; ) {\n\t\ttemp <<= 1;\n\t\ttemp |= (crc & 0x1);\n\t\tcrc >>= 1;\n\t}\n\n\treturn temp;\n}\n\nstatic void ioc3_get_drvinfo(struct net_device *dev,\n\t\t\t     struct ethtool_drvinfo *info)\n{\n\tstrscpy(info->driver, IOC3_NAME, sizeof(info->driver));\n\tstrscpy(info->version, IOC3_VERSION, sizeof(info->version));\n\tstrscpy(info->bus_info, pci_name(to_pci_dev(dev->dev.parent)),\n\t\tsizeof(info->bus_info));\n}\n\nstatic int ioc3_get_link_ksettings(struct net_device *dev,\n\t\t\t\t   struct ethtool_link_ksettings *cmd)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\tmii_ethtool_get_link_ksettings(&ip->mii, cmd);\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn 0;\n}\n\nstatic int ioc3_set_link_ksettings(struct net_device *dev,\n\t\t\t\t   const struct ethtool_link_ksettings *cmd)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tint rc;\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\trc = mii_ethtool_set_link_ksettings(&ip->mii, cmd);\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn rc;\n}\n\nstatic int ioc3_nway_reset(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tint rc;\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\trc = mii_nway_restart(&ip->mii);\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn rc;\n}\n\nstatic u32 ioc3_get_link(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tint rc;\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\trc = mii_link_ok(&ip->mii);\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn rc;\n}\n\nstatic const struct ethtool_ops ioc3_ethtool_ops = {\n\t.get_drvinfo\t\t= ioc3_get_drvinfo,\n\t.nway_reset\t\t= ioc3_nway_reset,\n\t.get_link\t\t= ioc3_get_link,\n\t.get_link_ksettings\t= ioc3_get_link_ksettings,\n\t.set_link_ksettings\t= ioc3_set_link_ksettings,\n};\n\nstatic int ioc3_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tint rc;\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\trc = generic_mii_ioctl(&ip->mii, if_mii(rq), cmd, NULL);\n\tspin_unlock_irq(&ip->ioc3_lock);\n\n\treturn rc;\n}\n\nstatic void ioc3_set_multicast_list(struct net_device *dev)\n{\n\tstruct ioc3_private *ip = netdev_priv(dev);\n\tstruct ioc3_ethregs *regs = ip->regs;\n\tstruct netdev_hw_addr *ha;\n\tu64 ehar = 0;\n\n\tspin_lock_irq(&ip->ioc3_lock);\n\n\tif (dev->flags & IFF_PROMISC) {\t\t\t \n\t\tip->emcr |= EMCR_PROMISC;\n\t\twritel(ip->emcr, &regs->emcr);\n\t\treadl(&regs->emcr);\n\t} else {\n\t\tip->emcr &= ~EMCR_PROMISC;\n\t\twritel(ip->emcr, &regs->emcr);\t\t \n\t\treadl(&regs->emcr);\n\n\t\tif ((dev->flags & IFF_ALLMULTI) ||\n\t\t    (netdev_mc_count(dev) > 64)) {\n\t\t\t \n\t\t\tip->ehar_h = 0xffffffff;\n\t\t\tip->ehar_l = 0xffffffff;\n\t\t} else {\n\t\t\tnetdev_for_each_mc_addr(ha, dev) {\n\t\t\t\tehar |= (1UL << ioc3_hash(ha->addr));\n\t\t\t}\n\t\t\tip->ehar_h = ehar >> 32;\n\t\t\tip->ehar_l = ehar & 0xffffffff;\n\t\t}\n\t\twritel(ip->ehar_h, &regs->ehar_h);\n\t\twritel(ip->ehar_l, &regs->ehar_l);\n\t}\n\n\tspin_unlock_irq(&ip->ioc3_lock);\n}\n\nstatic struct platform_driver ioc3eth_driver = {\n\t.probe  = ioc3eth_probe,\n\t.remove = ioc3eth_remove,\n\t.driver = {\n\t\t.name = \"ioc3-eth\",\n\t}\n};\n\nmodule_platform_driver(ioc3eth_driver);\n\nMODULE_AUTHOR(\"Ralf Baechle <ralf@linux-mips.org>\");\nMODULE_DESCRIPTION(\"SGI IOC3 Ethernet driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}