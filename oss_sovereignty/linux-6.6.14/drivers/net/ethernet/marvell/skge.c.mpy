{
  "module_name": "skge.c",
  "hash_id": "3b382b5243ac1e55560d497feda5fba264cbb2c4525d2b21b3f52c3cb588300f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/skge.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/in.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/pci.h>\n#include <linux/if_vlan.h>\n#include <linux/ip.h>\n#include <linux/delay.h>\n#include <linux/crc32.h>\n#include <linux/dma-mapping.h>\n#include <linux/debugfs.h>\n#include <linux/sched.h>\n#include <linux/seq_file.h>\n#include <linux/mii.h>\n#include <linux/slab.h>\n#include <linux/dmi.h>\n#include <linux/prefetch.h>\n#include <asm/irq.h>\n\n#include \"skge.h\"\n\n#define DRV_NAME\t\t\"skge\"\n#define DRV_VERSION\t\t\"1.14\"\n\n#define DEFAULT_TX_RING_SIZE\t128\n#define DEFAULT_RX_RING_SIZE\t512\n#define MAX_TX_RING_SIZE\t1024\n#define TX_LOW_WATER\t\t(MAX_SKB_FRAGS + 1)\n#define MAX_RX_RING_SIZE\t4096\n#define RX_COPY_THRESHOLD\t128\n#define RX_BUF_SIZE\t\t1536\n#define PHY_RETRIES\t        1000\n#define ETH_JUMBO_MTU\t\t9000\n#define TX_WATCHDOG\t\t(5 * HZ)\n#define BLINK_MS\t\t250\n#define LINK_HZ\t\t\tHZ\n\n#define SKGE_EEPROM_MAGIC\t0x9933aabb\n\n\nMODULE_DESCRIPTION(\"SysKonnect Gigabit Ethernet driver\");\nMODULE_AUTHOR(\"Stephen Hemminger <shemminger@linux-foundation.org>\");\nMODULE_LICENSE(\"GPL\");\nMODULE_VERSION(DRV_VERSION);\n\nstatic const u32 default_msg = (NETIF_MSG_DRV | NETIF_MSG_PROBE |\n\t\t\t\tNETIF_MSG_LINK | NETIF_MSG_IFUP |\n\t\t\t\tNETIF_MSG_IFDOWN);\n\nstatic int debug = -1;\t \nmodule_param(debug, int, 0);\nMODULE_PARM_DESC(debug, \"Debug level (0=none,...,16=all)\");\n\nstatic const struct pci_device_id skge_id_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_3COM, 0x1700) },\t   \n\t{ PCI_DEVICE(PCI_VENDOR_ID_3COM, 0x80EB) },\t   \n#ifdef CONFIG_SKGE_GENESIS\n\t{ PCI_DEVICE(PCI_VENDOR_ID_SYSKONNECT, 0x4300) },  \n#endif\n\t{ PCI_DEVICE(PCI_VENDOR_ID_SYSKONNECT, 0x4320) },  \n\t{ PCI_DEVICE(PCI_VENDOR_ID_DLINK, 0x4b01) },\t   \n\t{ PCI_DEVICE(PCI_VENDOR_ID_DLINK, 0x4c00) },\t   \n\t{ PCI_DEVICE(PCI_VENDOR_ID_DLINK, 0x4302) },\t   \n\t{ PCI_DEVICE(PCI_VENDOR_ID_MARVELL, 0x4320) },\t   \n\t{ PCI_DEVICE(PCI_VENDOR_ID_MARVELL, 0x5005) },\t   \n\t{ PCI_DEVICE(PCI_VENDOR_ID_CNET, 0x434E) }, \t   \n\t{ PCI_DEVICE(PCI_VENDOR_ID_LINKSYS, 0x1064) },\t   \n\t{ PCI_VENDOR_ID_LINKSYS, 0x1032, PCI_ANY_ID, 0x0015 },  \n\t{ 0 }\n};\nMODULE_DEVICE_TABLE(pci, skge_id_table);\n\nstatic int skge_up(struct net_device *dev);\nstatic int skge_down(struct net_device *dev);\nstatic void skge_phy_reset(struct skge_port *skge);\nstatic void skge_tx_clean(struct net_device *dev);\nstatic int xm_phy_write(struct skge_hw *hw, int port, u16 reg, u16 val);\nstatic int gm_phy_write(struct skge_hw *hw, int port, u16 reg, u16 val);\nstatic void genesis_get_stats(struct skge_port *skge, u64 *data);\nstatic void yukon_get_stats(struct skge_port *skge, u64 *data);\nstatic void yukon_init(struct skge_hw *hw, int port);\nstatic void genesis_mac_init(struct skge_hw *hw, int port);\nstatic void genesis_link_up(struct skge_port *skge);\nstatic void skge_set_multicast(struct net_device *dev);\nstatic irqreturn_t skge_intr(int irq, void *dev_id);\n\n \nstatic const int txqaddr[] = { Q_XA1, Q_XA2 };\nstatic const int rxqaddr[] = { Q_R1, Q_R2 };\nstatic const u32 rxirqmask[] = { IS_R1_F, IS_R2_F };\nstatic const u32 txirqmask[] = { IS_XA1_F, IS_XA2_F };\nstatic const u32 napimask[] = { IS_R1_F|IS_XA1_F, IS_R2_F|IS_XA2_F };\nstatic const u32 portmask[] = { IS_PORT_1, IS_PORT_2 };\n\nstatic inline bool is_genesis(const struct skge_hw *hw)\n{\n#ifdef CONFIG_SKGE_GENESIS\n\treturn hw->chip_id == CHIP_ID_GENESIS;\n#else\n\treturn false;\n#endif\n}\n\nstatic int skge_get_regs_len(struct net_device *dev)\n{\n\treturn 0x4000;\n}\n\n \nstatic void skge_get_regs(struct net_device *dev, struct ethtool_regs *regs,\n\t\t\t  void *p)\n{\n\tconst struct skge_port *skge = netdev_priv(dev);\n\tconst void __iomem *io = skge->hw->regs;\n\n\tregs->version = 1;\n\tmemset(p, 0, regs->len);\n\tmemcpy_fromio(p, io, B3_RAM_ADDR);\n\n\tif (regs->len > B3_RI_WTO_R1) {\n\t\tmemcpy_fromio(p + B3_RI_WTO_R1, io + B3_RI_WTO_R1,\n\t\t\t      regs->len - B3_RI_WTO_R1);\n\t}\n}\n\n \nstatic u32 wol_supported(const struct skge_hw *hw)\n{\n\tif (is_genesis(hw))\n\t\treturn 0;\n\n\tif (hw->chip_id == CHIP_ID_YUKON && hw->chip_rev == 0)\n\t\treturn 0;\n\n\treturn WAKE_MAGIC | WAKE_PHY;\n}\n\nstatic void skge_wol_init(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu16 ctrl;\n\n\tskge_write16(hw, B0_CTST, CS_RST_CLR);\n\tskge_write16(hw, SK_REG(port, GMAC_LINK_CTRL), GMLC_RST_CLR);\n\n\t \n\tskge_write8(hw, B0_POWER_CTRL,\n\t\t    PC_VAUX_ENA | PC_VCC_ENA | PC_VAUX_ON | PC_VCC_OFF);\n\n\t \n\tif (hw->chip_id == CHIP_ID_YUKON_LITE &&\n\t    hw->chip_rev >= CHIP_REV_YU_LITE_A3) {\n\t\tu32 reg = skge_read32(hw, B2_GP_IO);\n\t\treg |= GP_DIR_9;\n\t\treg &= ~GP_IO_9;\n\t\tskge_write32(hw, B2_GP_IO, reg);\n\t}\n\n\tskge_write32(hw, SK_REG(port, GPHY_CTRL),\n\t\t     GPC_DIS_SLEEP |\n\t\t     GPC_HWCFG_M_3 | GPC_HWCFG_M_2 | GPC_HWCFG_M_1 | GPC_HWCFG_M_0 |\n\t\t     GPC_ANEG_1 | GPC_RST_SET);\n\n\tskge_write32(hw, SK_REG(port, GPHY_CTRL),\n\t\t     GPC_DIS_SLEEP |\n\t\t     GPC_HWCFG_M_3 | GPC_HWCFG_M_2 | GPC_HWCFG_M_1 | GPC_HWCFG_M_0 |\n\t\t     GPC_ANEG_1 | GPC_RST_CLR);\n\n\tskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_RST_CLR);\n\n\t \n\tgm_phy_write(hw, port, PHY_MARV_AUNE_ADV,\n\t\t     (PHY_AN_100FULL | PHY_AN_100HALF |\n\t\t      PHY_AN_10FULL | PHY_AN_10HALF | PHY_AN_CSMA));\n\t \n\tgm_phy_write(hw, port, PHY_MARV_1000T_CTRL, 0);\n\tgm_phy_write(hw, port, PHY_MARV_CTRL,\n\t\t     PHY_CT_RESET | PHY_CT_SPS_LSB | PHY_CT_ANE |\n\t\t     PHY_CT_RE_CFG | PHY_CT_DUP_MD);\n\n\n\t \n\tgma_write16(hw, port, GM_GP_CTRL,\n\t\t    GM_GPCR_FC_TX_DIS|GM_GPCR_TX_ENA|GM_GPCR_RX_ENA|\n\t\t    GM_GPCR_DUP_FULL|GM_GPCR_FC_RX_DIS|GM_GPCR_AU_FCT_DIS);\n\n\t \n\tmemcpy_toio(hw->regs + WOL_REGS(port, WOL_MAC_ADDR),\n\t\t    skge->netdev->dev_addr, ETH_ALEN);\n\n\t \n\tskge_write16(hw, WOL_REGS(port, WOL_CTRL_STAT), WOL_CTL_CLEAR_RESULT);\n\tctrl = 0;\n\tif (skge->wol & WAKE_PHY)\n\t\tctrl |= WOL_CTL_ENA_PME_ON_LINK_CHG|WOL_CTL_ENA_LINK_CHG_UNIT;\n\telse\n\t\tctrl |= WOL_CTL_DIS_PME_ON_LINK_CHG|WOL_CTL_DIS_LINK_CHG_UNIT;\n\n\tif (skge->wol & WAKE_MAGIC)\n\t\tctrl |= WOL_CTL_ENA_PME_ON_MAGIC_PKT|WOL_CTL_ENA_MAGIC_PKT_UNIT;\n\telse\n\t\tctrl |= WOL_CTL_DIS_PME_ON_MAGIC_PKT|WOL_CTL_DIS_MAGIC_PKT_UNIT;\n\n\tctrl |= WOL_CTL_DIS_PME_ON_PATTERN|WOL_CTL_DIS_PATTERN_UNIT;\n\tskge_write16(hw, WOL_REGS(port, WOL_CTRL_STAT), ctrl);\n\n\t \n\tskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_RST_SET);\n}\n\nstatic void skge_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\twol->supported = wol_supported(skge->hw);\n\twol->wolopts = skge->wol;\n}\n\nstatic int skge_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\n\tif ((wol->wolopts & ~wol_supported(hw)) ||\n\t    !device_can_wakeup(&hw->pdev->dev))\n\t\treturn -EOPNOTSUPP;\n\n\tskge->wol = wol->wolopts;\n\n\tdevice_set_wakeup_enable(&hw->pdev->dev, skge->wol);\n\n\treturn 0;\n}\n\n \nstatic u32 skge_supported_modes(const struct skge_hw *hw)\n{\n\tu32 supported;\n\n\tif (hw->copper) {\n\t\tsupported = (SUPPORTED_10baseT_Half |\n\t\t\t     SUPPORTED_10baseT_Full |\n\t\t\t     SUPPORTED_100baseT_Half |\n\t\t\t     SUPPORTED_100baseT_Full |\n\t\t\t     SUPPORTED_1000baseT_Half |\n\t\t\t     SUPPORTED_1000baseT_Full |\n\t\t\t     SUPPORTED_Autoneg |\n\t\t\t     SUPPORTED_TP);\n\n\t\tif (is_genesis(hw))\n\t\t\tsupported &= ~(SUPPORTED_10baseT_Half |\n\t\t\t\t       SUPPORTED_10baseT_Full |\n\t\t\t\t       SUPPORTED_100baseT_Half |\n\t\t\t\t       SUPPORTED_100baseT_Full);\n\n\t\telse if (hw->chip_id == CHIP_ID_YUKON)\n\t\t\tsupported &= ~SUPPORTED_1000baseT_Half;\n\t} else\n\t\tsupported = (SUPPORTED_1000baseT_Full |\n\t\t\t     SUPPORTED_1000baseT_Half |\n\t\t\t     SUPPORTED_FIBRE |\n\t\t\t     SUPPORTED_Autoneg);\n\n\treturn supported;\n}\n\nstatic int skge_get_link_ksettings(struct net_device *dev,\n\t\t\t\t   struct ethtool_link_ksettings *cmd)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tu32 supported, advertising;\n\n\tsupported = skge_supported_modes(hw);\n\n\tif (hw->copper) {\n\t\tcmd->base.port = PORT_TP;\n\t\tcmd->base.phy_address = hw->phy_addr;\n\t} else\n\t\tcmd->base.port = PORT_FIBRE;\n\n\tadvertising = skge->advertising;\n\tcmd->base.autoneg = skge->autoneg;\n\tcmd->base.speed = skge->speed;\n\tcmd->base.duplex = skge->duplex;\n\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported,\n\t\t\t\t\t\tsupported);\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.advertising,\n\t\t\t\t\t\tadvertising);\n\n\treturn 0;\n}\n\nstatic int skge_set_link_ksettings(struct net_device *dev,\n\t\t\t\t   const struct ethtool_link_ksettings *cmd)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tconst struct skge_hw *hw = skge->hw;\n\tu32 supported = skge_supported_modes(hw);\n\tint err = 0;\n\tu32 advertising;\n\n\tethtool_convert_link_mode_to_legacy_u32(&advertising,\n\t\t\t\t\t\tcmd->link_modes.advertising);\n\n\tif (cmd->base.autoneg == AUTONEG_ENABLE) {\n\t\tadvertising = supported;\n\t\tskge->duplex = -1;\n\t\tskge->speed = -1;\n\t} else {\n\t\tu32 setting;\n\t\tu32 speed = cmd->base.speed;\n\n\t\tswitch (speed) {\n\t\tcase SPEED_1000:\n\t\t\tif (cmd->base.duplex == DUPLEX_FULL)\n\t\t\t\tsetting = SUPPORTED_1000baseT_Full;\n\t\t\telse if (cmd->base.duplex == DUPLEX_HALF)\n\t\t\t\tsetting = SUPPORTED_1000baseT_Half;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase SPEED_100:\n\t\t\tif (cmd->base.duplex == DUPLEX_FULL)\n\t\t\t\tsetting = SUPPORTED_100baseT_Full;\n\t\t\telse if (cmd->base.duplex == DUPLEX_HALF)\n\t\t\t\tsetting = SUPPORTED_100baseT_Half;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\n\t\tcase SPEED_10:\n\t\t\tif (cmd->base.duplex == DUPLEX_FULL)\n\t\t\t\tsetting = SUPPORTED_10baseT_Full;\n\t\t\telse if (cmd->base.duplex == DUPLEX_HALF)\n\t\t\t\tsetting = SUPPORTED_10baseT_Half;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif ((setting & supported) == 0)\n\t\t\treturn -EINVAL;\n\n\t\tskge->speed = speed;\n\t\tskge->duplex = cmd->base.duplex;\n\t}\n\n\tskge->autoneg = cmd->base.autoneg;\n\tskge->advertising = advertising;\n\n\tif (netif_running(dev)) {\n\t\tskge_down(dev);\n\t\terr = skge_up(dev);\n\t\tif (err) {\n\t\t\tdev_close(dev);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void skge_get_drvinfo(struct net_device *dev,\n\t\t\t     struct ethtool_drvinfo *info)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tstrscpy(info->driver, DRV_NAME, sizeof(info->driver));\n\tstrscpy(info->version, DRV_VERSION, sizeof(info->version));\n\tstrscpy(info->bus_info, pci_name(skge->hw->pdev),\n\t\tsizeof(info->bus_info));\n}\n\nstatic const struct skge_stat {\n\tchar \t   name[ETH_GSTRING_LEN];\n\tu16\t   xmac_offset;\n\tu16\t   gma_offset;\n} skge_stats[] = {\n\t{ \"tx_bytes\",\t\tXM_TXO_OK_HI,  GM_TXO_OK_HI },\n\t{ \"rx_bytes\",\t\tXM_RXO_OK_HI,  GM_RXO_OK_HI },\n\n\t{ \"tx_broadcast\",\tXM_TXF_BC_OK,  GM_TXF_BC_OK },\n\t{ \"rx_broadcast\",\tXM_RXF_BC_OK,  GM_RXF_BC_OK },\n\t{ \"tx_multicast\",\tXM_TXF_MC_OK,  GM_TXF_MC_OK },\n\t{ \"rx_multicast\",\tXM_RXF_MC_OK,  GM_RXF_MC_OK },\n\t{ \"tx_unicast\",\t\tXM_TXF_UC_OK,  GM_TXF_UC_OK },\n\t{ \"rx_unicast\",\t\tXM_RXF_UC_OK,  GM_RXF_UC_OK },\n\t{ \"tx_mac_pause\",\tXM_TXF_MPAUSE, GM_TXF_MPAUSE },\n\t{ \"rx_mac_pause\",\tXM_RXF_MPAUSE, GM_RXF_MPAUSE },\n\n\t{ \"collisions\",\t\tXM_TXF_SNG_COL, GM_TXF_SNG_COL },\n\t{ \"multi_collisions\",\tXM_TXF_MUL_COL, GM_TXF_MUL_COL },\n\t{ \"aborted\",\t\tXM_TXF_ABO_COL, GM_TXF_ABO_COL },\n\t{ \"late_collision\",\tXM_TXF_LAT_COL, GM_TXF_LAT_COL },\n\t{ \"fifo_underrun\",\tXM_TXE_FIFO_UR, GM_TXE_FIFO_UR },\n\t{ \"fifo_overflow\",\tXM_RXE_FIFO_OV, GM_RXE_FIFO_OV },\n\n\t{ \"rx_toolong\",\t\tXM_RXF_LNG_ERR, GM_RXF_LNG_ERR },\n\t{ \"rx_jabber\",\t\tXM_RXF_JAB_PKT, GM_RXF_JAB_PKT },\n\t{ \"rx_runt\",\t\tXM_RXE_RUNT, \tGM_RXE_FRAG },\n\t{ \"rx_too_long\",\tXM_RXF_LNG_ERR, GM_RXF_LNG_ERR },\n\t{ \"rx_fcs_error\",\tXM_RXF_FCS_ERR, GM_RXF_FCS_ERR },\n};\n\nstatic int skge_get_sset_count(struct net_device *dev, int sset)\n{\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn ARRAY_SIZE(skge_stats);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void skge_get_ethtool_stats(struct net_device *dev,\n\t\t\t\t   struct ethtool_stats *stats, u64 *data)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tif (is_genesis(skge->hw))\n\t\tgenesis_get_stats(skge, data);\n\telse\n\t\tyukon_get_stats(skge, data);\n}\n\n \nstatic struct net_device_stats *skge_get_stats(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tu64 data[ARRAY_SIZE(skge_stats)];\n\n\tif (is_genesis(skge->hw))\n\t\tgenesis_get_stats(skge, data);\n\telse\n\t\tyukon_get_stats(skge, data);\n\n\tdev->stats.tx_bytes = data[0];\n\tdev->stats.rx_bytes = data[1];\n\tdev->stats.tx_packets = data[2] + data[4] + data[6];\n\tdev->stats.rx_packets = data[3] + data[5] + data[7];\n\tdev->stats.multicast = data[3] + data[5];\n\tdev->stats.collisions = data[10];\n\tdev->stats.tx_aborted_errors = data[12];\n\n\treturn &dev->stats;\n}\n\nstatic void skge_get_strings(struct net_device *dev, u32 stringset, u8 *data)\n{\n\tint i;\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tfor (i = 0; i < ARRAY_SIZE(skge_stats); i++)\n\t\t\tmemcpy(data + i * ETH_GSTRING_LEN,\n\t\t\t       skge_stats[i].name, ETH_GSTRING_LEN);\n\t\tbreak;\n\t}\n}\n\nstatic void skge_get_ring_param(struct net_device *dev,\n\t\t\t\tstruct ethtool_ringparam *p,\n\t\t\t\tstruct kernel_ethtool_ringparam *kernel_p,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tp->rx_max_pending = MAX_RX_RING_SIZE;\n\tp->tx_max_pending = MAX_TX_RING_SIZE;\n\n\tp->rx_pending = skge->rx_ring.count;\n\tp->tx_pending = skge->tx_ring.count;\n}\n\nstatic int skge_set_ring_param(struct net_device *dev,\n\t\t\t       struct ethtool_ringparam *p,\n\t\t\t       struct kernel_ethtool_ringparam *kernel_p,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tint err = 0;\n\n\tif (p->rx_pending == 0 || p->rx_pending > MAX_RX_RING_SIZE ||\n\t    p->tx_pending < TX_LOW_WATER || p->tx_pending > MAX_TX_RING_SIZE)\n\t\treturn -EINVAL;\n\n\tskge->rx_ring.count = p->rx_pending;\n\tskge->tx_ring.count = p->tx_pending;\n\n\tif (netif_running(dev)) {\n\t\tskge_down(dev);\n\t\terr = skge_up(dev);\n\t\tif (err)\n\t\t\tdev_close(dev);\n\t}\n\n\treturn err;\n}\n\nstatic u32 skge_get_msglevel(struct net_device *netdev)\n{\n\tstruct skge_port *skge = netdev_priv(netdev);\n\treturn skge->msg_enable;\n}\n\nstatic void skge_set_msglevel(struct net_device *netdev, u32 value)\n{\n\tstruct skge_port *skge = netdev_priv(netdev);\n\tskge->msg_enable = value;\n}\n\nstatic int skge_nway_reset(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tif (skge->autoneg != AUTONEG_ENABLE || !netif_running(dev))\n\t\treturn -EINVAL;\n\n\tskge_phy_reset(skge);\n\treturn 0;\n}\n\nstatic void skge_get_pauseparam(struct net_device *dev,\n\t\t\t\tstruct ethtool_pauseparam *ecmd)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tecmd->rx_pause = ((skge->flow_control == FLOW_MODE_SYMMETRIC) ||\n\t\t\t  (skge->flow_control == FLOW_MODE_SYM_OR_REM));\n\tecmd->tx_pause = (ecmd->rx_pause ||\n\t\t\t  (skge->flow_control == FLOW_MODE_LOC_SEND));\n\n\tecmd->autoneg = ecmd->rx_pause || ecmd->tx_pause;\n}\n\nstatic int skge_set_pauseparam(struct net_device *dev,\n\t\t\t       struct ethtool_pauseparam *ecmd)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct ethtool_pauseparam old;\n\tint err = 0;\n\n\tskge_get_pauseparam(dev, &old);\n\n\tif (ecmd->autoneg != old.autoneg)\n\t\tskge->flow_control = ecmd->autoneg ? FLOW_MODE_NONE : FLOW_MODE_SYMMETRIC;\n\telse {\n\t\tif (ecmd->rx_pause && ecmd->tx_pause)\n\t\t\tskge->flow_control = FLOW_MODE_SYMMETRIC;\n\t\telse if (ecmd->rx_pause && !ecmd->tx_pause)\n\t\t\tskge->flow_control = FLOW_MODE_SYM_OR_REM;\n\t\telse if (!ecmd->rx_pause && ecmd->tx_pause)\n\t\t\tskge->flow_control = FLOW_MODE_LOC_SEND;\n\t\telse\n\t\t\tskge->flow_control = FLOW_MODE_NONE;\n\t}\n\n\tif (netif_running(dev)) {\n\t\tskge_down(dev);\n\t\terr = skge_up(dev);\n\t\tif (err) {\n\t\t\tdev_close(dev);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic inline u32 hwkhz(const struct skge_hw *hw)\n{\n\treturn is_genesis(hw) ? 53125 : 78125;\n}\n\n \nstatic inline u32 skge_clk2usec(const struct skge_hw *hw, u32 ticks)\n{\n\treturn (ticks * 1000) / hwkhz(hw);\n}\n\n \nstatic inline u32 skge_usecs2clk(const struct skge_hw *hw, u32 usec)\n{\n\treturn hwkhz(hw) * usec / 1000;\n}\n\nstatic int skge_get_coalesce(struct net_device *dev,\n\t\t\t     struct ethtool_coalesce *ecmd,\n\t\t\t     struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\n\tecmd->rx_coalesce_usecs = 0;\n\tecmd->tx_coalesce_usecs = 0;\n\n\tif (skge_read32(hw, B2_IRQM_CTRL) & TIM_START) {\n\t\tu32 delay = skge_clk2usec(hw, skge_read32(hw, B2_IRQM_INI));\n\t\tu32 msk = skge_read32(hw, B2_IRQM_MSK);\n\n\t\tif (msk & rxirqmask[port])\n\t\t\tecmd->rx_coalesce_usecs = delay;\n\t\tif (msk & txirqmask[port])\n\t\t\tecmd->tx_coalesce_usecs = delay;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int skge_set_coalesce(struct net_device *dev,\n\t\t\t     struct ethtool_coalesce *ecmd,\n\t\t\t     struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu32 msk = skge_read32(hw, B2_IRQM_MSK);\n\tu32 delay = 25;\n\n\tif (ecmd->rx_coalesce_usecs == 0)\n\t\tmsk &= ~rxirqmask[port];\n\telse if (ecmd->rx_coalesce_usecs < 25 ||\n\t\t ecmd->rx_coalesce_usecs > 33333)\n\t\treturn -EINVAL;\n\telse {\n\t\tmsk |= rxirqmask[port];\n\t\tdelay = ecmd->rx_coalesce_usecs;\n\t}\n\n\tif (ecmd->tx_coalesce_usecs == 0)\n\t\tmsk &= ~txirqmask[port];\n\telse if (ecmd->tx_coalesce_usecs < 25 ||\n\t\t ecmd->tx_coalesce_usecs > 33333)\n\t\treturn -EINVAL;\n\telse {\n\t\tmsk |= txirqmask[port];\n\t\tdelay = min(delay, ecmd->rx_coalesce_usecs);\n\t}\n\n\tskge_write32(hw, B2_IRQM_MSK, msk);\n\tif (msk == 0)\n\t\tskge_write32(hw, B2_IRQM_CTRL, TIM_STOP);\n\telse {\n\t\tskge_write32(hw, B2_IRQM_INI, skge_usecs2clk(hw, delay));\n\t\tskge_write32(hw, B2_IRQM_CTRL, TIM_START);\n\t}\n\treturn 0;\n}\n\nenum led_mode { LED_MODE_OFF, LED_MODE_ON, LED_MODE_TST };\nstatic void skge_led(struct skge_port *skge, enum led_mode mode)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\n\tspin_lock_bh(&hw->phy_lock);\n\tif (is_genesis(hw)) {\n\t\tswitch (mode) {\n\t\tcase LED_MODE_OFF:\n\t\t\tif (hw->phy_type == SK_PHY_BCOM)\n\t\t\t\txm_phy_write(hw, port, PHY_BCOM_P_EXT_CTRL, PHY_B_PEC_LED_OFF);\n\t\t\telse {\n\t\t\t\tskge_write32(hw, SK_REG(port, TX_LED_VAL), 0);\n\t\t\t\tskge_write8(hw, SK_REG(port, TX_LED_CTRL), LED_T_OFF);\n\t\t\t}\n\t\t\tskge_write8(hw, SK_REG(port, LNK_LED_REG), LINKLED_OFF);\n\t\t\tskge_write32(hw, SK_REG(port, RX_LED_VAL), 0);\n\t\t\tskge_write8(hw, SK_REG(port, RX_LED_CTRL), LED_T_OFF);\n\t\t\tbreak;\n\n\t\tcase LED_MODE_ON:\n\t\t\tskge_write8(hw, SK_REG(port, LNK_LED_REG), LINKLED_ON);\n\t\t\tskge_write8(hw, SK_REG(port, LNK_LED_REG), LINKLED_LINKSYNC_ON);\n\n\t\t\tskge_write8(hw, SK_REG(port, RX_LED_CTRL), LED_START);\n\t\t\tskge_write8(hw, SK_REG(port, TX_LED_CTRL), LED_START);\n\n\t\t\tbreak;\n\n\t\tcase LED_MODE_TST:\n\t\t\tskge_write8(hw, SK_REG(port, RX_LED_TST), LED_T_ON);\n\t\t\tskge_write32(hw, SK_REG(port, RX_LED_VAL), 100);\n\t\t\tskge_write8(hw, SK_REG(port, RX_LED_CTRL), LED_START);\n\n\t\t\tif (hw->phy_type == SK_PHY_BCOM)\n\t\t\t\txm_phy_write(hw, port, PHY_BCOM_P_EXT_CTRL, PHY_B_PEC_LED_ON);\n\t\t\telse {\n\t\t\t\tskge_write8(hw, SK_REG(port, TX_LED_TST), LED_T_ON);\n\t\t\t\tskge_write32(hw, SK_REG(port, TX_LED_VAL), 100);\n\t\t\t\tskge_write8(hw, SK_REG(port, TX_LED_CTRL), LED_START);\n\t\t\t}\n\n\t\t}\n\t} else {\n\t\tswitch (mode) {\n\t\tcase LED_MODE_OFF:\n\t\t\tgm_phy_write(hw, port, PHY_MARV_LED_CTRL, 0);\n\t\t\tgm_phy_write(hw, port, PHY_MARV_LED_OVER,\n\t\t\t\t     PHY_M_LED_MO_DUP(MO_LED_OFF)  |\n\t\t\t\t     PHY_M_LED_MO_10(MO_LED_OFF)   |\n\t\t\t\t     PHY_M_LED_MO_100(MO_LED_OFF)  |\n\t\t\t\t     PHY_M_LED_MO_1000(MO_LED_OFF) |\n\t\t\t\t     PHY_M_LED_MO_RX(MO_LED_OFF));\n\t\t\tbreak;\n\t\tcase LED_MODE_ON:\n\t\t\tgm_phy_write(hw, port, PHY_MARV_LED_CTRL,\n\t\t\t\t     PHY_M_LED_PULS_DUR(PULS_170MS) |\n\t\t\t\t     PHY_M_LED_BLINK_RT(BLINK_84MS) |\n\t\t\t\t     PHY_M_LEDC_TX_CTRL |\n\t\t\t\t     PHY_M_LEDC_DP_CTRL);\n\n\t\t\tgm_phy_write(hw, port, PHY_MARV_LED_OVER,\n\t\t\t\t     PHY_M_LED_MO_RX(MO_LED_OFF) |\n\t\t\t\t     (skge->speed == SPEED_100 ?\n\t\t\t\t      PHY_M_LED_MO_100(MO_LED_ON) : 0));\n\t\t\tbreak;\n\t\tcase LED_MODE_TST:\n\t\t\tgm_phy_write(hw, port, PHY_MARV_LED_CTRL, 0);\n\t\t\tgm_phy_write(hw, port, PHY_MARV_LED_OVER,\n\t\t\t\t     PHY_M_LED_MO_DUP(MO_LED_ON)  |\n\t\t\t\t     PHY_M_LED_MO_10(MO_LED_ON)   |\n\t\t\t\t     PHY_M_LED_MO_100(MO_LED_ON)  |\n\t\t\t\t     PHY_M_LED_MO_1000(MO_LED_ON) |\n\t\t\t\t     PHY_M_LED_MO_RX(MO_LED_ON));\n\t\t}\n\t}\n\tspin_unlock_bh(&hw->phy_lock);\n}\n\n \nstatic int skge_set_phys_id(struct net_device *dev,\n\t\t\t    enum ethtool_phys_id_state state)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tswitch (state) {\n\tcase ETHTOOL_ID_ACTIVE:\n\t\treturn 2;\t \n\n\tcase ETHTOOL_ID_ON:\n\t\tskge_led(skge, LED_MODE_TST);\n\t\tbreak;\n\n\tcase ETHTOOL_ID_OFF:\n\t\tskge_led(skge, LED_MODE_OFF);\n\t\tbreak;\n\n\tcase ETHTOOL_ID_INACTIVE:\n\t\t \n\t\tskge_led(skge, netif_running(dev) ? LED_MODE_ON : LED_MODE_OFF);\n\t}\n\n\treturn 0;\n}\n\nstatic int skge_get_eeprom_len(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tu32 reg2;\n\n\tpci_read_config_dword(skge->hw->pdev, PCI_DEV_REG2, &reg2);\n\treturn 1 << (((reg2 & PCI_VPD_ROM_SZ) >> 14) + 8);\n}\n\nstatic u32 skge_vpd_read(struct pci_dev *pdev, int cap, u16 offset)\n{\n\tu32 val;\n\n\tpci_write_config_word(pdev, cap + PCI_VPD_ADDR, offset);\n\n\tdo {\n\t\tpci_read_config_word(pdev, cap + PCI_VPD_ADDR, &offset);\n\t} while (!(offset & PCI_VPD_ADDR_F));\n\n\tpci_read_config_dword(pdev, cap + PCI_VPD_DATA, &val);\n\treturn val;\n}\n\nstatic void skge_vpd_write(struct pci_dev *pdev, int cap, u16 offset, u32 val)\n{\n\tpci_write_config_dword(pdev, cap + PCI_VPD_DATA, val);\n\tpci_write_config_word(pdev, cap + PCI_VPD_ADDR,\n\t\t\t      offset | PCI_VPD_ADDR_F);\n\n\tdo {\n\t\tpci_read_config_word(pdev, cap + PCI_VPD_ADDR, &offset);\n\t} while (offset & PCI_VPD_ADDR_F);\n}\n\nstatic int skge_get_eeprom(struct net_device *dev, struct ethtool_eeprom *eeprom,\n\t\t\t   u8 *data)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct pci_dev *pdev = skge->hw->pdev;\n\tint cap = pci_find_capability(pdev, PCI_CAP_ID_VPD);\n\tint length = eeprom->len;\n\tu16 offset = eeprom->offset;\n\n\tif (!cap)\n\t\treturn -EINVAL;\n\n\teeprom->magic = SKGE_EEPROM_MAGIC;\n\n\twhile (length > 0) {\n\t\tu32 val = skge_vpd_read(pdev, cap, offset);\n\t\tint n = min_t(int, length, sizeof(val));\n\n\t\tmemcpy(data, &val, n);\n\t\tlength -= n;\n\t\tdata += n;\n\t\toffset += n;\n\t}\n\treturn 0;\n}\n\nstatic int skge_set_eeprom(struct net_device *dev, struct ethtool_eeprom *eeprom,\n\t\t\t   u8 *data)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct pci_dev *pdev = skge->hw->pdev;\n\tint cap = pci_find_capability(pdev, PCI_CAP_ID_VPD);\n\tint length = eeprom->len;\n\tu16 offset = eeprom->offset;\n\n\tif (!cap)\n\t\treturn -EINVAL;\n\n\tif (eeprom->magic != SKGE_EEPROM_MAGIC)\n\t\treturn -EINVAL;\n\n\twhile (length > 0) {\n\t\tu32 val;\n\t\tint n = min_t(int, length, sizeof(val));\n\n\t\tif (n < sizeof(val))\n\t\t\tval = skge_vpd_read(pdev, cap, offset);\n\t\tmemcpy(&val, data, n);\n\n\t\tskge_vpd_write(pdev, cap, offset, val);\n\n\t\tlength -= n;\n\t\tdata += n;\n\t\toffset += n;\n\t}\n\treturn 0;\n}\n\nstatic const struct ethtool_ops skge_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS,\n\t.get_drvinfo\t= skge_get_drvinfo,\n\t.get_regs_len\t= skge_get_regs_len,\n\t.get_regs\t= skge_get_regs,\n\t.get_wol\t= skge_get_wol,\n\t.set_wol\t= skge_set_wol,\n\t.get_msglevel\t= skge_get_msglevel,\n\t.set_msglevel\t= skge_set_msglevel,\n\t.nway_reset\t= skge_nway_reset,\n\t.get_link\t= ethtool_op_get_link,\n\t.get_eeprom_len\t= skge_get_eeprom_len,\n\t.get_eeprom\t= skge_get_eeprom,\n\t.set_eeprom\t= skge_set_eeprom,\n\t.get_ringparam\t= skge_get_ring_param,\n\t.set_ringparam\t= skge_set_ring_param,\n\t.get_pauseparam = skge_get_pauseparam,\n\t.set_pauseparam = skge_set_pauseparam,\n\t.get_coalesce\t= skge_get_coalesce,\n\t.set_coalesce\t= skge_set_coalesce,\n\t.get_strings\t= skge_get_strings,\n\t.set_phys_id\t= skge_set_phys_id,\n\t.get_sset_count = skge_get_sset_count,\n\t.get_ethtool_stats = skge_get_ethtool_stats,\n\t.get_link_ksettings = skge_get_link_ksettings,\n\t.set_link_ksettings = skge_set_link_ksettings,\n};\n\n \nstatic int skge_ring_alloc(struct skge_ring *ring, void *vaddr, u32 base)\n{\n\tstruct skge_tx_desc *d;\n\tstruct skge_element *e;\n\tint i;\n\n\tring->start = kcalloc(ring->count, sizeof(*e), GFP_KERNEL);\n\tif (!ring->start)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0, e = ring->start, d = vaddr; i < ring->count; i++, e++, d++) {\n\t\te->desc = d;\n\t\tif (i == ring->count - 1) {\n\t\t\te->next = ring->start;\n\t\t\td->next_offset = base;\n\t\t} else {\n\t\t\te->next = e + 1;\n\t\t\td->next_offset = base + (i+1) * sizeof(*d);\n\t\t}\n\t}\n\tring->to_use = ring->to_clean = ring->start;\n\n\treturn 0;\n}\n\n \nstatic int skge_rx_setup(struct skge_port *skge, struct skge_element *e,\n\t\t\t struct sk_buff *skb, unsigned int bufsize)\n{\n\tstruct skge_rx_desc *rd = e->desc;\n\tdma_addr_t map;\n\n\tmap = dma_map_single(&skge->hw->pdev->dev, skb->data, bufsize,\n\t\t\t     DMA_FROM_DEVICE);\n\n\tif (dma_mapping_error(&skge->hw->pdev->dev, map))\n\t\treturn -1;\n\n\trd->dma_lo = lower_32_bits(map);\n\trd->dma_hi = upper_32_bits(map);\n\te->skb = skb;\n\trd->csum1_start = ETH_HLEN;\n\trd->csum2_start = ETH_HLEN;\n\trd->csum1 = 0;\n\trd->csum2 = 0;\n\n\twmb();\n\n\trd->control = BMU_OWN | BMU_STF | BMU_IRQ_EOF | BMU_TCP_CHECK | bufsize;\n\tdma_unmap_addr_set(e, mapaddr, map);\n\tdma_unmap_len_set(e, maplen, bufsize);\n\treturn 0;\n}\n\n \nstatic inline void skge_rx_reuse(struct skge_element *e, unsigned int size)\n{\n\tstruct skge_rx_desc *rd = e->desc;\n\n\trd->csum2 = 0;\n\trd->csum2_start = ETH_HLEN;\n\n\twmb();\n\n\trd->control = BMU_OWN | BMU_STF | BMU_IRQ_EOF | BMU_TCP_CHECK | size;\n}\n\n\n \nstatic void skge_rx_clean(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tstruct skge_ring *ring = &skge->rx_ring;\n\tstruct skge_element *e;\n\n\te = ring->start;\n\tdo {\n\t\tstruct skge_rx_desc *rd = e->desc;\n\t\trd->control = 0;\n\t\tif (e->skb) {\n\t\t\tdma_unmap_single(&hw->pdev->dev,\n\t\t\t\t\t dma_unmap_addr(e, mapaddr),\n\t\t\t\t\t dma_unmap_len(e, maplen),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tdev_kfree_skb(e->skb);\n\t\t\te->skb = NULL;\n\t\t}\n\t} while ((e = e->next) != ring->start);\n}\n\n\n \nstatic int skge_rx_fill(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_ring *ring = &skge->rx_ring;\n\tstruct skge_element *e;\n\n\te = ring->start;\n\tdo {\n\t\tstruct sk_buff *skb;\n\n\t\tskb = __netdev_alloc_skb(dev, skge->rx_buf_size + NET_IP_ALIGN,\n\t\t\t\t\t GFP_KERNEL);\n\t\tif (!skb)\n\t\t\treturn -ENOMEM;\n\n\t\tskb_reserve(skb, NET_IP_ALIGN);\n\t\tif (skge_rx_setup(skge, e, skb, skge->rx_buf_size) < 0) {\n\t\t\tdev_kfree_skb(skb);\n\t\t\treturn -EIO;\n\t\t}\n\t} while ((e = e->next) != ring->start);\n\n\tring->to_clean = ring->start;\n\treturn 0;\n}\n\nstatic const char *skge_pause(enum pause_status status)\n{\n\tswitch (status) {\n\tcase FLOW_STAT_NONE:\n\t\treturn \"none\";\n\tcase FLOW_STAT_REM_SEND:\n\t\treturn \"rx only\";\n\tcase FLOW_STAT_LOC_SEND:\n\t\treturn \"tx_only\";\n\tcase FLOW_STAT_SYMMETRIC:\t\t \n\t\treturn \"both\";\n\tdefault:\n\t\treturn \"indeterminated\";\n\t}\n}\n\n\nstatic void skge_link_up(struct skge_port *skge)\n{\n\tskge_write8(skge->hw, SK_REG(skge->port, LNK_LED_REG),\n\t\t    LED_BLK_OFF|LED_SYNC_OFF|LED_REG_ON);\n\n\tnetif_carrier_on(skge->netdev);\n\tnetif_wake_queue(skge->netdev);\n\n\tnetif_info(skge, link, skge->netdev,\n\t\t   \"Link is up at %d Mbps, %s duplex, flow control %s\\n\",\n\t\t   skge->speed,\n\t\t   skge->duplex == DUPLEX_FULL ? \"full\" : \"half\",\n\t\t   skge_pause(skge->flow_status));\n}\n\nstatic void skge_link_down(struct skge_port *skge)\n{\n\tskge_write8(skge->hw, SK_REG(skge->port, LNK_LED_REG), LED_REG_OFF);\n\tnetif_carrier_off(skge->netdev);\n\tnetif_stop_queue(skge->netdev);\n\n\tnetif_info(skge, link, skge->netdev, \"Link is down\\n\");\n}\n\nstatic void xm_link_down(struct skge_hw *hw, int port)\n{\n\tstruct net_device *dev = hw->dev[port];\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\txm_write16(hw, port, XM_IMSK, XM_IMSK_DISABLE);\n\n\tif (netif_carrier_ok(dev))\n\t\tskge_link_down(skge);\n}\n\nstatic int __xm_phy_read(struct skge_hw *hw, int port, u16 reg, u16 *val)\n{\n\tint i;\n\n\txm_write16(hw, port, XM_PHY_ADDR, reg | hw->phy_addr);\n\t*val = xm_read16(hw, port, XM_PHY_DATA);\n\n\tif (hw->phy_type == SK_PHY_XMAC)\n\t\tgoto ready;\n\n\tfor (i = 0; i < PHY_RETRIES; i++) {\n\t\tif (xm_read16(hw, port, XM_MMU_CMD) & XM_MMU_PHY_RDY)\n\t\t\tgoto ready;\n\t\tudelay(1);\n\t}\n\n\treturn -ETIMEDOUT;\n ready:\n\t*val = xm_read16(hw, port, XM_PHY_DATA);\n\n\treturn 0;\n}\n\nstatic u16 xm_phy_read(struct skge_hw *hw, int port, u16 reg)\n{\n\tu16 v = 0;\n\tif (__xm_phy_read(hw, port, reg, &v))\n\t\tpr_warn(\"%s: phy read timed out\\n\", hw->dev[port]->name);\n\treturn v;\n}\n\nstatic int xm_phy_write(struct skge_hw *hw, int port, u16 reg, u16 val)\n{\n\tint i;\n\n\txm_write16(hw, port, XM_PHY_ADDR, reg | hw->phy_addr);\n\tfor (i = 0; i < PHY_RETRIES; i++) {\n\t\tif (!(xm_read16(hw, port, XM_MMU_CMD) & XM_MMU_PHY_BUSY))\n\t\t\tgoto ready;\n\t\tudelay(1);\n\t}\n\treturn -EIO;\n\n ready:\n\txm_write16(hw, port, XM_PHY_DATA, val);\n\tfor (i = 0; i < PHY_RETRIES; i++) {\n\t\tif (!(xm_read16(hw, port, XM_MMU_CMD) & XM_MMU_PHY_BUSY))\n\t\t\treturn 0;\n\t\tudelay(1);\n\t}\n\treturn -ETIMEDOUT;\n}\n\nstatic void genesis_init(struct skge_hw *hw)\n{\n\t \n\tskge_write32(hw, B2_BSC_INI, (SK_BLK_DUR * SK_FACT_53) / 100);\n\tskge_write8(hw, B2_BSC_CTRL, BSC_START);\n\n\t \n\tskge_write16(hw, B3_MA_TO_CTRL, MA_RST_CLR);\n\n\t \n\tskge_write8(hw, B3_MA_TOINI_RX1, SK_MAC_TO_53);\n\tskge_write8(hw, B3_MA_TOINI_RX2, SK_MAC_TO_53);\n\tskge_write8(hw, B3_MA_TOINI_TX1, SK_MAC_TO_53);\n\tskge_write8(hw, B3_MA_TOINI_TX2, SK_MAC_TO_53);\n\n\tskge_write8(hw, B3_MA_RCINI_RX1, 0);\n\tskge_write8(hw, B3_MA_RCINI_RX2, 0);\n\tskge_write8(hw, B3_MA_RCINI_TX1, 0);\n\tskge_write8(hw, B3_MA_RCINI_TX2, 0);\n\n\t \n\tskge_write16(hw, B3_PA_CTRL, PA_RST_CLR);\n\tskge_write16(hw, B3_PA_TOINI_RX1, SK_PKT_TO_MAX);\n\tskge_write16(hw, B3_PA_TOINI_TX1, SK_PKT_TO_MAX);\n\tskge_write16(hw, B3_PA_TOINI_RX2, SK_PKT_TO_MAX);\n\tskge_write16(hw, B3_PA_TOINI_TX2, SK_PKT_TO_MAX);\n}\n\nstatic void genesis_reset(struct skge_hw *hw, int port)\n{\n\tstatic const u8 zero[8]  = { 0 };\n\tu32 reg;\n\n\tskge_write8(hw, SK_REG(port, GMAC_IRQ_MSK), 0);\n\n\t \n\txm_write32(hw, port, XM_GP_PORT, XM_GP_RES_STAT);\n\txm_write16(hw, port, XM_IMSK, XM_IMSK_DISABLE);\n\txm_write32(hw, port, XM_MODE, 0);\t\t \n\txm_write16(hw, port, XM_TX_CMD, 0);\t \n\txm_write16(hw, port, XM_RX_CMD, 0);\t \n\n\t \n\tif (hw->phy_type == SK_PHY_BCOM)\n\t\txm_write16(hw, port, PHY_BCOM_INT_MASK, 0xffff);\n\n\txm_outhash(hw, port, XM_HSM, zero);\n\n\t \n\treg = xm_read32(hw, port, XM_MODE);\n\txm_write32(hw, port, XM_MODE, reg | XM_MD_FTF);\n\txm_write32(hw, port, XM_MODE, reg | XM_MD_FRF);\n}\n\n \nstatic const u16 phy_pause_map[] = {\n\t[FLOW_MODE_NONE] =\t0,\n\t[FLOW_MODE_LOC_SEND] =\tPHY_AN_PAUSE_ASYM,\n\t[FLOW_MODE_SYMMETRIC] = PHY_AN_PAUSE_CAP,\n\t[FLOW_MODE_SYM_OR_REM]  = PHY_AN_PAUSE_CAP | PHY_AN_PAUSE_ASYM,\n};\n\n \nstatic const u16 fiber_pause_map[] = {\n\t[FLOW_MODE_NONE]\t= PHY_X_P_NO_PAUSE,\n\t[FLOW_MODE_LOC_SEND]\t= PHY_X_P_ASYM_MD,\n\t[FLOW_MODE_SYMMETRIC]\t= PHY_X_P_SYM_MD,\n\t[FLOW_MODE_SYM_OR_REM]\t= PHY_X_P_BOTH_MD,\n};\n\n\n \nstatic void bcom_check_link(struct skge_hw *hw, int port)\n{\n\tstruct net_device *dev = hw->dev[port];\n\tstruct skge_port *skge = netdev_priv(dev);\n\tu16 status;\n\n\t \n\txm_phy_read(hw, port, PHY_BCOM_STAT);\n\tstatus = xm_phy_read(hw, port, PHY_BCOM_STAT);\n\n\tif ((status & PHY_ST_LSYNC) == 0) {\n\t\txm_link_down(hw, port);\n\t\treturn;\n\t}\n\n\tif (skge->autoneg == AUTONEG_ENABLE) {\n\t\tu16 lpa, aux;\n\n\t\tif (!(status & PHY_ST_AN_OVER))\n\t\t\treturn;\n\n\t\tlpa = xm_phy_read(hw, port, PHY_XMAC_AUNE_LP);\n\t\tif (lpa & PHY_B_AN_RF) {\n\t\t\tnetdev_notice(dev, \"remote fault\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\taux = xm_phy_read(hw, port, PHY_BCOM_AUX_STAT);\n\n\t\t \n\t\tswitch (aux & PHY_B_AS_AN_RES_MSK) {\n\t\tcase PHY_B_RES_1000FD:\n\t\t\tskge->duplex = DUPLEX_FULL;\n\t\t\tbreak;\n\t\tcase PHY_B_RES_1000HD:\n\t\t\tskge->duplex = DUPLEX_HALF;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_notice(dev, \"duplex mismatch\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tswitch (aux & PHY_B_AS_PAUSE_MSK) {\n\t\tcase PHY_B_AS_PAUSE_MSK:\n\t\t\tskge->flow_status = FLOW_STAT_SYMMETRIC;\n\t\t\tbreak;\n\t\tcase PHY_B_AS_PRR:\n\t\t\tskge->flow_status = FLOW_STAT_REM_SEND;\n\t\t\tbreak;\n\t\tcase PHY_B_AS_PRT:\n\t\t\tskge->flow_status = FLOW_STAT_LOC_SEND;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tskge->flow_status = FLOW_STAT_NONE;\n\t\t}\n\t\tskge->speed = SPEED_1000;\n\t}\n\n\tif (!netif_carrier_ok(dev))\n\t\tgenesis_link_up(skge);\n}\n\n \nstatic void bcom_phy_init(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tint i;\n\tu16 id1, r, ext, ctl;\n\n\t \n\tstatic const struct {\n\t\tu16 reg;\n\t\tu16 val;\n\t} A1hack[] = {\n\t\t{ 0x18, 0x0c20 }, { 0x17, 0x0012 }, { 0x15, 0x1104 },\n\t\t{ 0x17, 0x0013 }, { 0x15, 0x0404 }, { 0x17, 0x8006 },\n\t\t{ 0x15, 0x0132 }, { 0x17, 0x8006 }, { 0x15, 0x0232 },\n\t\t{ 0x17, 0x800D }, { 0x15, 0x000F }, { 0x18, 0x0420 },\n\t}, C0hack[] = {\n\t\t{ 0x18, 0x0c20 }, { 0x17, 0x0012 }, { 0x15, 0x1204 },\n\t\t{ 0x17, 0x0013 }, { 0x15, 0x0A04 }, { 0x18, 0x0420 },\n\t};\n\n\t \n\tid1 = xm_phy_read(hw, port, PHY_XMAC_ID1);\n\n\t \n\tr = xm_read16(hw, port, XM_MMU_CMD);\n\tr |=  XM_MMU_NO_PRE;\n\txm_write16(hw, port, XM_MMU_CMD, r);\n\n\tswitch (id1) {\n\tcase PHY_BCOM_ID1_C0:\n\t\t \n\t\tfor (i = 0; i < ARRAY_SIZE(C0hack); i++)\n\t\t\txm_phy_write(hw, port,\n\t\t\t\t     C0hack[i].reg, C0hack[i].val);\n\n\t\tbreak;\n\tcase PHY_BCOM_ID1_A1:\n\t\t \n\t\tfor (i = 0; i < ARRAY_SIZE(A1hack); i++)\n\t\t\txm_phy_write(hw, port,\n\t\t\t\t     A1hack[i].reg, A1hack[i].val);\n\t\tbreak;\n\t}\n\n\t \n\tr = xm_phy_read(hw, port, PHY_BCOM_AUX_CTRL);\n\tr |= PHY_B_AC_DIS_PM;\n\txm_phy_write(hw, port, PHY_BCOM_AUX_CTRL, r);\n\n\t \n\txm_read16(hw, port, XM_ISRC);\n\n\text = PHY_B_PEC_EN_LTR;  \n\tctl = PHY_CT_SP1000;\t \n\n\tif (skge->autoneg == AUTONEG_ENABLE) {\n\t\t \n\t\tu16 adv = PHY_B_1000C_RD;\n\t\tif (skge->advertising & ADVERTISED_1000baseT_Half)\n\t\t\tadv |= PHY_B_1000C_AHD;\n\t\tif (skge->advertising & ADVERTISED_1000baseT_Full)\n\t\t\tadv |= PHY_B_1000C_AFD;\n\t\txm_phy_write(hw, port, PHY_BCOM_1000T_CTRL, adv);\n\n\t\tctl |= PHY_CT_ANE | PHY_CT_RE_CFG;\n\t} else {\n\t\tif (skge->duplex == DUPLEX_FULL)\n\t\t\tctl |= PHY_CT_DUP_MD;\n\t\t \n\t\txm_phy_write(hw, port, PHY_BCOM_1000T_CTRL, PHY_B_1000C_MSE);\n\t}\n\n\t \n\txm_phy_write(hw, port, PHY_BCOM_AUNE_ADV,\n\t\t     phy_pause_map[skge->flow_control] | PHY_AN_CSMA);\n\n\t \n\tif (hw->dev[port]->mtu > ETH_DATA_LEN) {\n\t\txm_phy_write(hw, port, PHY_BCOM_AUX_CTRL,\n\t\t\t     PHY_B_AC_TX_TST | PHY_B_AC_LONG_PACK);\n\n\t\text |= PHY_B_PEC_HIGH_LA;\n\n\t}\n\n\txm_phy_write(hw, port, PHY_BCOM_P_EXT_CTRL, ext);\n\txm_phy_write(hw, port, PHY_BCOM_CTRL, ctl);\n\n\t \n\txm_phy_write(hw, port, PHY_BCOM_INT_MASK, PHY_B_DEF_MSK);\n}\n\nstatic void xm_phy_init(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu16 ctrl = 0;\n\n\tif (skge->autoneg == AUTONEG_ENABLE) {\n\t\tif (skge->advertising & ADVERTISED_1000baseT_Half)\n\t\t\tctrl |= PHY_X_AN_HD;\n\t\tif (skge->advertising & ADVERTISED_1000baseT_Full)\n\t\t\tctrl |= PHY_X_AN_FD;\n\n\t\tctrl |= fiber_pause_map[skge->flow_control];\n\n\t\txm_phy_write(hw, port, PHY_XMAC_AUNE_ADV, ctrl);\n\n\t\t \n\t\tctrl = PHY_CT_ANE | PHY_CT_RE_CFG;\n\t} else {\n\t\t \n\t\tif (skge->duplex == DUPLEX_FULL)\n\t\t\tctrl |= PHY_CT_DUP_MD;\n\t\t \n\t}\n\n\txm_phy_write(hw, port, PHY_XMAC_CTRL, ctrl);\n\n\t \n\tmod_timer(&skge->link_timer, jiffies + LINK_HZ);\n}\n\nstatic int xm_check_link(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu16 status;\n\n\t \n\txm_phy_read(hw, port, PHY_XMAC_STAT);\n\tstatus = xm_phy_read(hw, port, PHY_XMAC_STAT);\n\n\tif ((status & PHY_ST_LSYNC) == 0) {\n\t\txm_link_down(hw, port);\n\t\treturn 0;\n\t}\n\n\tif (skge->autoneg == AUTONEG_ENABLE) {\n\t\tu16 lpa, res;\n\n\t\tif (!(status & PHY_ST_AN_OVER))\n\t\t\treturn 0;\n\n\t\tlpa = xm_phy_read(hw, port, PHY_XMAC_AUNE_LP);\n\t\tif (lpa & PHY_B_AN_RF) {\n\t\t\tnetdev_notice(dev, \"remote fault\\n\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tres = xm_phy_read(hw, port, PHY_XMAC_RES_ABI);\n\n\t\t \n\t\tswitch (res & (PHY_X_RS_HD | PHY_X_RS_FD)) {\n\t\tcase PHY_X_RS_FD:\n\t\t\tskge->duplex = DUPLEX_FULL;\n\t\t\tbreak;\n\t\tcase PHY_X_RS_HD:\n\t\t\tskge->duplex = DUPLEX_HALF;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_notice(dev, \"duplex mismatch\\n\");\n\t\t\treturn 0;\n\t\t}\n\n\t\t \n\t\tif ((skge->flow_control == FLOW_MODE_SYMMETRIC ||\n\t\t     skge->flow_control == FLOW_MODE_SYM_OR_REM) &&\n\t\t    (lpa & PHY_X_P_SYM_MD))\n\t\t\tskge->flow_status = FLOW_STAT_SYMMETRIC;\n\t\telse if (skge->flow_control == FLOW_MODE_SYM_OR_REM &&\n\t\t\t (lpa & PHY_X_RS_PAUSE) == PHY_X_P_ASYM_MD)\n\t\t\t \n\t\t\tskge->flow_status  = FLOW_STAT_REM_SEND;\n\t\telse if (skge->flow_control == FLOW_MODE_LOC_SEND &&\n\t\t\t (lpa & PHY_X_RS_PAUSE) == PHY_X_P_BOTH_MD)\n\t\t\t \n\t\t\tskge->flow_status = FLOW_STAT_LOC_SEND;\n\t\telse\n\t\t\tskge->flow_status = FLOW_STAT_NONE;\n\n\t\tskge->speed = SPEED_1000;\n\t}\n\n\tif (!netif_carrier_ok(dev))\n\t\tgenesis_link_up(skge);\n\treturn 1;\n}\n\n \nstatic void xm_link_timer(struct timer_list *t)\n{\n\tstruct skge_port *skge = from_timer(skge, t, link_timer);\n\tstruct net_device *dev = skge->netdev;\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tint i;\n\tunsigned long flags;\n\n\tif (!netif_running(dev))\n\t\treturn;\n\n\tspin_lock_irqsave(&hw->phy_lock, flags);\n\n\t \n\tfor (i = 0; i < 3; i++) {\n\t\tif (xm_read16(hw, port, XM_GP_PORT) & XM_GP_INP_ASS)\n\t\t\tgoto link_down;\n\t}\n\n\t \n\tif (xm_check_link(dev)) {\n\t\tu16 msk = xm_read16(hw, port, XM_IMSK);\n\t\tmsk &= ~XM_IS_INP_ASS;\n\t\txm_write16(hw, port, XM_IMSK, msk);\n\t\txm_read16(hw, port, XM_ISRC);\n\t} else {\nlink_down:\n\t\tmod_timer(&skge->link_timer,\n\t\t\t  round_jiffies(jiffies + LINK_HZ));\n\t}\n\tspin_unlock_irqrestore(&hw->phy_lock, flags);\n}\n\nstatic void genesis_mac_init(struct skge_hw *hw, int port)\n{\n\tstruct net_device *dev = hw->dev[port];\n\tstruct skge_port *skge = netdev_priv(dev);\n\tint jumbo = hw->dev[port]->mtu > ETH_DATA_LEN;\n\tint i;\n\tu32 r;\n\tstatic const u8 zero[6]  = { 0 };\n\n\tfor (i = 0; i < 10; i++) {\n\t\tskge_write16(hw, SK_REG(port, TX_MFF_CTRL1),\n\t\t\t     MFF_SET_MAC_RST);\n\t\tif (skge_read16(hw, SK_REG(port, TX_MFF_CTRL1)) & MFF_SET_MAC_RST)\n\t\t\tgoto reset_ok;\n\t\tudelay(1);\n\t}\n\n\tnetdev_warn(dev, \"genesis reset failed\\n\");\n\n reset_ok:\n\t \n\tskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_CLR_MAC_RST);\n\n\t \n\tif (hw->phy_type != SK_PHY_XMAC) {\n\t\t \n\t\tr = skge_read32(hw, B2_GP_IO);\n\t\tif (port == 0)\n\t\t\tr |= GP_DIR_0|GP_IO_0;\n\t\telse\n\t\t\tr |= GP_DIR_2|GP_IO_2;\n\n\t\tskge_write32(hw, B2_GP_IO, r);\n\n\t\t \n\t\txm_write16(hw, port, XM_HW_CFG, XM_HW_GMII_MD);\n\t}\n\n\n\tswitch (hw->phy_type) {\n\tcase SK_PHY_XMAC:\n\t\txm_phy_init(skge);\n\t\tbreak;\n\tcase SK_PHY_BCOM:\n\t\tbcom_phy_init(skge);\n\t\tbcom_check_link(hw, port);\n\t}\n\n\t \n\txm_outaddr(hw, port, XM_SA, dev->dev_addr);\n\n\t \n\tfor (i = 1; i < 16; i++)\n\t\txm_outaddr(hw, port, XM_EXM(i), zero);\n\n\t \n\txm_write16(hw, port, XM_STAT_CMD,\n\t\t\tXM_SC_CLR_RXC | XM_SC_CLR_TXC);\n\t \n\txm_write16(hw, port, XM_STAT_CMD,\n\t\t\tXM_SC_CLR_RXC | XM_SC_CLR_TXC);\n\n\t \n\txm_write16(hw, port, XM_RX_HI_WM, 1450);\n\n\t \n\tr = XM_RX_LENERR_OK | XM_RX_STRIP_FCS;\n\tif (jumbo)\n\t\tr |= XM_RX_BIG_PK_OK;\n\n\tif (skge->duplex == DUPLEX_HALF) {\n\t\t \n\t\tr |= XM_RX_DIS_CEXT;\n\t}\n\txm_write16(hw, port, XM_RX_CMD, r);\n\n\t \n\txm_write16(hw, port, XM_TX_CMD, XM_TX_AUTO_PAD);\n\n\t \n\tif (hw->ports > 1 && jumbo)\n\t\txm_write16(hw, port, XM_TX_THR, 1020);\n\telse\n\t\txm_write16(hw, port, XM_TX_THR, 512);\n\n\t \n\txm_write32(hw, port, XM_MODE, XM_DEF_MODE);\n\n\n\t \n\txm_write32(hw, port, XM_RX_EV_MSK, XMR_DEF_MSK);\n\n\t \n\txm_write32(hw, port, XM_TX_EV_MSK, XMT_DEF_MSK);\n\n\t \n\tskge_write16(hw, B3_MA_TO_CTRL, MA_RST_CLR);\n\n\t \n\tskge_write8(hw, B3_MA_TOINI_RX1, 72);\n\tskge_write8(hw, B3_MA_TOINI_RX2, 72);\n\tskge_write8(hw, B3_MA_TOINI_TX1, 72);\n\tskge_write8(hw, B3_MA_TOINI_TX2, 72);\n\n\tskge_write8(hw, B3_MA_RCINI_RX1, 0);\n\tskge_write8(hw, B3_MA_RCINI_RX2, 0);\n\tskge_write8(hw, B3_MA_RCINI_TX1, 0);\n\tskge_write8(hw, B3_MA_RCINI_TX2, 0);\n\n\t \n\tskge_write8(hw, SK_REG(port, RX_MFF_CTRL2), MFF_RST_CLR);\n\tskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_ENA_TIM_PAT);\n\tskge_write8(hw, SK_REG(port, RX_MFF_CTRL2), MFF_ENA_OP_MD);\n\n\t \n\tskge_write8(hw, SK_REG(port, TX_MFF_CTRL2), MFF_RST_CLR);\n\tskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_TX_CTRL_DEF);\n\tskge_write8(hw, SK_REG(port, TX_MFF_CTRL2), MFF_ENA_OP_MD);\n\n\tif (jumbo) {\n\t\t \n\t\tskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_ENA_FLUSH);\n\t} else {\n\t\t \n\t\tskge_write16(hw, B3_PA_CTRL,\n\t\t\t     (port == 0) ? PA_ENA_TO_TX1 : PA_ENA_TO_TX2);\n\t}\n}\n\nstatic void genesis_stop(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tunsigned retries = 1000;\n\tu16 cmd;\n\n\t \n\tcmd = xm_read16(hw, port, XM_MMU_CMD);\n\tcmd &= ~(XM_MMU_ENA_RX | XM_MMU_ENA_TX);\n\txm_write16(hw, port, XM_MMU_CMD, cmd);\n\n\tgenesis_reset(hw, port);\n\n\t \n\tskge_write16(hw, B3_PA_CTRL,\n\t\t     port == 0 ? PA_CLR_TO_TX1 : PA_CLR_TO_TX2);\n\n\t \n\tskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_CLR_MAC_RST);\n\tdo {\n\t\tskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_SET_MAC_RST);\n\t\tif (!(skge_read16(hw, SK_REG(port, TX_MFF_CTRL1)) & MFF_SET_MAC_RST))\n\t\t\tbreak;\n\t} while (--retries > 0);\n\n\t \n\tif (hw->phy_type != SK_PHY_XMAC) {\n\t\tu32 reg = skge_read32(hw, B2_GP_IO);\n\t\tif (port == 0) {\n\t\t\treg |= GP_DIR_0;\n\t\t\treg &= ~GP_IO_0;\n\t\t} else {\n\t\t\treg |= GP_DIR_2;\n\t\t\treg &= ~GP_IO_2;\n\t\t}\n\t\tskge_write32(hw, B2_GP_IO, reg);\n\t\tskge_read32(hw, B2_GP_IO);\n\t}\n\n\txm_write16(hw, port, XM_MMU_CMD,\n\t\t\txm_read16(hw, port, XM_MMU_CMD)\n\t\t\t& ~(XM_MMU_ENA_RX | XM_MMU_ENA_TX));\n\n\txm_read16(hw, port, XM_MMU_CMD);\n}\n\n\nstatic void genesis_get_stats(struct skge_port *skge, u64 *data)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tint i;\n\tunsigned long timeout = jiffies + HZ;\n\n\txm_write16(hw, port,\n\t\t\tXM_STAT_CMD, XM_SC_SNP_TXC | XM_SC_SNP_RXC);\n\n\t \n\twhile (xm_read16(hw, port, XM_STAT_CMD)\n\t       & (XM_SC_SNP_TXC | XM_SC_SNP_RXC)) {\n\t\tif (time_after(jiffies, timeout))\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\n\t \n\tdata[0] = (u64) xm_read32(hw, port, XM_TXO_OK_HI) << 32\n\t\t| xm_read32(hw, port, XM_TXO_OK_LO);\n\tdata[1] = (u64) xm_read32(hw, port, XM_RXO_OK_HI) << 32\n\t\t| xm_read32(hw, port, XM_RXO_OK_LO);\n\n\tfor (i = 2; i < ARRAY_SIZE(skge_stats); i++)\n\t\tdata[i] = xm_read32(hw, port, skge_stats[i].xmac_offset);\n}\n\nstatic void genesis_mac_intr(struct skge_hw *hw, int port)\n{\n\tstruct net_device *dev = hw->dev[port];\n\tstruct skge_port *skge = netdev_priv(dev);\n\tu16 status = xm_read16(hw, port, XM_ISRC);\n\n\tnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\n\t\t     \"mac interrupt status 0x%x\\n\", status);\n\n\tif (hw->phy_type == SK_PHY_XMAC && (status & XM_IS_INP_ASS)) {\n\t\txm_link_down(hw, port);\n\t\tmod_timer(&skge->link_timer, jiffies + 1);\n\t}\n\n\tif (status & XM_IS_TXF_UR) {\n\t\txm_write32(hw, port, XM_MODE, XM_MD_FTF);\n\t\t++dev->stats.tx_fifo_errors;\n\t}\n}\n\nstatic void genesis_link_up(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu16 cmd, msk;\n\tu32 mode;\n\n\tcmd = xm_read16(hw, port, XM_MMU_CMD);\n\n\t \n\tif (skge->flow_status == FLOW_STAT_NONE ||\n\t    skge->flow_status == FLOW_STAT_LOC_SEND)\n\t\t \n\t\tcmd |= XM_MMU_IGN_PF;\n\telse\n\t\t \n\t\tcmd &= ~XM_MMU_IGN_PF;\n\n\txm_write16(hw, port, XM_MMU_CMD, cmd);\n\n\tmode = xm_read32(hw, port, XM_MODE);\n\tif (skge->flow_status == FLOW_STAT_SYMMETRIC ||\n\t    skge->flow_status == FLOW_STAT_LOC_SEND) {\n\t\t \n\t\t \n\t\t \n\t\t \n\t\txm_write16(hw, port, XM_MAC_PTIME, 0xffff);\n\n\t\tmode |= XM_PAUSE_MODE;\n\t\tskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_ENA_PAUSE);\n\t} else {\n\t\t \n\t\t \n\t\tmode &= ~XM_PAUSE_MODE;\n\n\t\tskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_DIS_PAUSE);\n\t}\n\n\txm_write32(hw, port, XM_MODE, mode);\n\n\t \n\tmsk = xm_read16(hw, port, XM_IMSK);\n\tmsk &= ~XM_IS_TXF_UR;\n\txm_write16(hw, port, XM_IMSK, msk);\n\n\txm_read16(hw, port, XM_ISRC);\n\n\t \n\tcmd = xm_read16(hw, port, XM_MMU_CMD);\n\tif (hw->phy_type != SK_PHY_XMAC && skge->duplex == DUPLEX_FULL)\n\t\tcmd |= XM_MMU_GMII_FD;\n\n\t \n\tif (hw->phy_type == SK_PHY_BCOM) {\n\t\txm_phy_write(hw, port, PHY_BCOM_AUX_CTRL,\n\t\t\t     xm_phy_read(hw, port, PHY_BCOM_AUX_CTRL)\n\t\t\t     & ~PHY_B_AC_DIS_PM);\n\t\txm_phy_write(hw, port, PHY_BCOM_INT_MASK, PHY_B_DEF_MSK);\n\t}\n\n\t \n\txm_write16(hw, port, XM_MMU_CMD,\n\t\t\tcmd | XM_MMU_ENA_RX | XM_MMU_ENA_TX);\n\tskge_link_up(skge);\n}\n\n\nstatic inline void bcom_phy_intr(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu16 isrc;\n\n\tisrc = xm_phy_read(hw, port, PHY_BCOM_INT_STAT);\n\tnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\n\t\t     \"phy interrupt status 0x%x\\n\", isrc);\n\n\tif (isrc & PHY_B_IS_PSE)\n\t\tpr_err(\"%s: uncorrectable pair swap error\\n\",\n\t\t       hw->dev[port]->name);\n\n\t \n\tif (isrc & PHY_B_IS_NO_HDCL) {\n\t\tu16 ctrl = xm_phy_read(hw, port, PHY_BCOM_CTRL);\n\t\txm_phy_write(hw, port, PHY_BCOM_CTRL,\n\t\t\t\t  ctrl | PHY_CT_LOOP);\n\t\txm_phy_write(hw, port, PHY_BCOM_CTRL,\n\t\t\t\t  ctrl & ~PHY_CT_LOOP);\n\t}\n\n\tif (isrc & (PHY_B_IS_AN_PR | PHY_B_IS_LST_CHANGE))\n\t\tbcom_check_link(hw, port);\n\n}\n\nstatic int gm_phy_write(struct skge_hw *hw, int port, u16 reg, u16 val)\n{\n\tint i;\n\n\tgma_write16(hw, port, GM_SMI_DATA, val);\n\tgma_write16(hw, port, GM_SMI_CTRL,\n\t\t\t GM_SMI_CT_PHY_AD(hw->phy_addr) | GM_SMI_CT_REG_AD(reg));\n\tfor (i = 0; i < PHY_RETRIES; i++) {\n\t\tudelay(1);\n\n\t\tif (!(gma_read16(hw, port, GM_SMI_CTRL) & GM_SMI_CT_BUSY))\n\t\t\treturn 0;\n\t}\n\n\tpr_warn(\"%s: phy write timeout\\n\", hw->dev[port]->name);\n\treturn -EIO;\n}\n\nstatic int __gm_phy_read(struct skge_hw *hw, int port, u16 reg, u16 *val)\n{\n\tint i;\n\n\tgma_write16(hw, port, GM_SMI_CTRL,\n\t\t\t GM_SMI_CT_PHY_AD(hw->phy_addr)\n\t\t\t | GM_SMI_CT_REG_AD(reg) | GM_SMI_CT_OP_RD);\n\n\tfor (i = 0; i < PHY_RETRIES; i++) {\n\t\tudelay(1);\n\t\tif (gma_read16(hw, port, GM_SMI_CTRL) & GM_SMI_CT_RD_VAL)\n\t\t\tgoto ready;\n\t}\n\n\treturn -ETIMEDOUT;\n ready:\n\t*val = gma_read16(hw, port, GM_SMI_DATA);\n\treturn 0;\n}\n\nstatic u16 gm_phy_read(struct skge_hw *hw, int port, u16 reg)\n{\n\tu16 v = 0;\n\tif (__gm_phy_read(hw, port, reg, &v))\n\t\tpr_warn(\"%s: phy read timeout\\n\", hw->dev[port]->name);\n\treturn v;\n}\n\n \nstatic void yukon_init(struct skge_hw *hw, int port)\n{\n\tstruct skge_port *skge = netdev_priv(hw->dev[port]);\n\tu16 ctrl, ct1000, adv;\n\n\tif (skge->autoneg == AUTONEG_ENABLE) {\n\t\tu16 ectrl = gm_phy_read(hw, port, PHY_MARV_EXT_CTRL);\n\n\t\tectrl &= ~(PHY_M_EC_M_DSC_MSK | PHY_M_EC_S_DSC_MSK |\n\t\t\t  PHY_M_EC_MAC_S_MSK);\n\t\tectrl |= PHY_M_EC_MAC_S(MAC_TX_CLK_25_MHZ);\n\n\t\tectrl |= PHY_M_EC_M_DSC(0) | PHY_M_EC_S_DSC(1);\n\n\t\tgm_phy_write(hw, port, PHY_MARV_EXT_CTRL, ectrl);\n\t}\n\n\tctrl = gm_phy_read(hw, port, PHY_MARV_CTRL);\n\tif (skge->autoneg == AUTONEG_DISABLE)\n\t\tctrl &= ~PHY_CT_ANE;\n\n\tctrl |= PHY_CT_RESET;\n\tgm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\n\n\tctrl = 0;\n\tct1000 = 0;\n\tadv = PHY_AN_CSMA;\n\n\tif (skge->autoneg == AUTONEG_ENABLE) {\n\t\tif (hw->copper) {\n\t\t\tif (skge->advertising & ADVERTISED_1000baseT_Full)\n\t\t\t\tct1000 |= PHY_M_1000C_AFD;\n\t\t\tif (skge->advertising & ADVERTISED_1000baseT_Half)\n\t\t\t\tct1000 |= PHY_M_1000C_AHD;\n\t\t\tif (skge->advertising & ADVERTISED_100baseT_Full)\n\t\t\t\tadv |= PHY_M_AN_100_FD;\n\t\t\tif (skge->advertising & ADVERTISED_100baseT_Half)\n\t\t\t\tadv |= PHY_M_AN_100_HD;\n\t\t\tif (skge->advertising & ADVERTISED_10baseT_Full)\n\t\t\t\tadv |= PHY_M_AN_10_FD;\n\t\t\tif (skge->advertising & ADVERTISED_10baseT_Half)\n\t\t\t\tadv |= PHY_M_AN_10_HD;\n\n\t\t\t \n\t\t\tadv |= phy_pause_map[skge->flow_control];\n\t\t} else {\n\t\t\tif (skge->advertising & ADVERTISED_1000baseT_Full)\n\t\t\t\tadv |= PHY_M_AN_1000X_AFD;\n\t\t\tif (skge->advertising & ADVERTISED_1000baseT_Half)\n\t\t\t\tadv |= PHY_M_AN_1000X_AHD;\n\n\t\t\tadv |= fiber_pause_map[skge->flow_control];\n\t\t}\n\n\t\t \n\t\tctrl |= PHY_CT_ANE | PHY_CT_RE_CFG;\n\t} else {\n\t\t \n\t\tct1000 = PHY_M_1000C_MSE;\n\n\t\tif (skge->duplex == DUPLEX_FULL)\n\t\t\tctrl |= PHY_CT_DUP_MD;\n\n\t\tswitch (skge->speed) {\n\t\tcase SPEED_1000:\n\t\t\tctrl |= PHY_CT_SP1000;\n\t\t\tbreak;\n\t\tcase SPEED_100:\n\t\t\tctrl |= PHY_CT_SP100;\n\t\t\tbreak;\n\t\t}\n\n\t\tctrl |= PHY_CT_RESET;\n\t}\n\n\tgm_phy_write(hw, port, PHY_MARV_1000T_CTRL, ct1000);\n\n\tgm_phy_write(hw, port, PHY_MARV_AUNE_ADV, adv);\n\tgm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\n\n\t \n\tif (skge->autoneg == AUTONEG_ENABLE)\n\t\tgm_phy_write(hw, port, PHY_MARV_INT_MASK, PHY_M_IS_AN_MSK);\n\telse\n\t\tgm_phy_write(hw, port, PHY_MARV_INT_MASK, PHY_M_IS_DEF_MSK);\n}\n\nstatic void yukon_reset(struct skge_hw *hw, int port)\n{\n\tgm_phy_write(hw, port, PHY_MARV_INT_MASK, 0); \n\tgma_write16(hw, port, GM_MC_ADDR_H1, 0);\t \n\tgma_write16(hw, port, GM_MC_ADDR_H2, 0);\n\tgma_write16(hw, port, GM_MC_ADDR_H3, 0);\n\tgma_write16(hw, port, GM_MC_ADDR_H4, 0);\n\n\tgma_write16(hw, port, GM_RX_CTRL,\n\t\t\t gma_read16(hw, port, GM_RX_CTRL)\n\t\t\t | GM_RXCR_UCF_ENA | GM_RXCR_MCF_ENA);\n}\n\n \nstatic int is_yukon_lite_a0(struct skge_hw *hw)\n{\n\tu32 reg;\n\tint ret;\n\n\tif (hw->chip_id != CHIP_ID_YUKON)\n\t\treturn 0;\n\n\treg = skge_read32(hw, B2_FAR);\n\tskge_write8(hw, B2_FAR + 3, 0xff);\n\tret = (skge_read8(hw, B2_FAR + 3) != 0);\n\tskge_write32(hw, B2_FAR, reg);\n\treturn ret;\n}\n\nstatic void yukon_mac_init(struct skge_hw *hw, int port)\n{\n\tstruct skge_port *skge = netdev_priv(hw->dev[port]);\n\tint i;\n\tu32 reg;\n\tconst u8 *addr = hw->dev[port]->dev_addr;\n\n\t \n\tif (hw->chip_id == CHIP_ID_YUKON_LITE &&\n\t    hw->chip_rev >= CHIP_REV_YU_LITE_A3) {\n\t\treg = skge_read32(hw, B2_GP_IO);\n\t\treg |= GP_DIR_9 | GP_IO_9;\n\t\tskge_write32(hw, B2_GP_IO, reg);\n\t}\n\n\t \n\tskge_write32(hw, SK_REG(port, GPHY_CTRL), GPC_RST_SET);\n\tskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_RST_SET);\n\n\t \n\tif (hw->chip_id == CHIP_ID_YUKON_LITE &&\n\t    hw->chip_rev >= CHIP_REV_YU_LITE_A3) {\n\t\treg = skge_read32(hw, B2_GP_IO);\n\t\treg |= GP_DIR_9;\n\t\treg &= ~GP_IO_9;\n\t\tskge_write32(hw, B2_GP_IO, reg);\n\t}\n\n\t \n\treg = GPC_INT_POL_HI | GPC_DIS_FC | GPC_DIS_SLEEP |\n\t\tGPC_ENA_XC | GPC_ANEG_ADV_ALL_M | GPC_ENA_PAUSE;\n\treg |= hw->copper ? GPC_HWCFG_GMII_COP : GPC_HWCFG_GMII_FIB;\n\n\t \n\tskge_write32(hw, SK_REG(port, GPHY_CTRL), reg | GPC_RST_SET);\n\tskge_write32(hw, SK_REG(port, GPHY_CTRL), reg | GPC_RST_CLR);\n\tskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_ON | GMC_RST_CLR);\n\n\tif (skge->autoneg == AUTONEG_DISABLE) {\n\t\treg = GM_GPCR_AU_ALL_DIS;\n\t\tgma_write16(hw, port, GM_GP_CTRL,\n\t\t\t\t gma_read16(hw, port, GM_GP_CTRL) | reg);\n\n\t\tswitch (skge->speed) {\n\t\tcase SPEED_1000:\n\t\t\treg &= ~GM_GPCR_SPEED_100;\n\t\t\treg |= GM_GPCR_SPEED_1000;\n\t\t\tbreak;\n\t\tcase SPEED_100:\n\t\t\treg &= ~GM_GPCR_SPEED_1000;\n\t\t\treg |= GM_GPCR_SPEED_100;\n\t\t\tbreak;\n\t\tcase SPEED_10:\n\t\t\treg &= ~(GM_GPCR_SPEED_1000 | GM_GPCR_SPEED_100);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (skge->duplex == DUPLEX_FULL)\n\t\t\treg |= GM_GPCR_DUP_FULL;\n\t} else\n\t\treg = GM_GPCR_SPEED_1000 | GM_GPCR_SPEED_100 | GM_GPCR_DUP_FULL;\n\n\tswitch (skge->flow_control) {\n\tcase FLOW_MODE_NONE:\n\t\tskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_OFF);\n\t\treg |= GM_GPCR_FC_TX_DIS | GM_GPCR_FC_RX_DIS | GM_GPCR_AU_FCT_DIS;\n\t\tbreak;\n\tcase FLOW_MODE_LOC_SEND:\n\t\t \n\t\treg |= GM_GPCR_FC_RX_DIS | GM_GPCR_AU_FCT_DIS;\n\t\tbreak;\n\tcase FLOW_MODE_SYMMETRIC:\n\tcase FLOW_MODE_SYM_OR_REM:\n\t\t \n\t\tbreak;\n\t}\n\n\tgma_write16(hw, port, GM_GP_CTRL, reg);\n\tskge_read16(hw, SK_REG(port, GMAC_IRQ_SRC));\n\n\tyukon_init(hw, port);\n\n\t \n\treg = gma_read16(hw, port, GM_PHY_ADDR);\n\tgma_write16(hw, port, GM_PHY_ADDR, reg | GM_PAR_MIB_CLR);\n\n\tfor (i = 0; i < GM_MIB_CNT_SIZE; i++)\n\t\tgma_read16(hw, port, GM_MIB_CNT_BASE + 8*i);\n\tgma_write16(hw, port, GM_PHY_ADDR, reg);\n\n\t \n\tgma_write16(hw, port, GM_TX_CTRL, TX_COL_THR(TX_COL_DEF));\n\n\t \n\tgma_write16(hw, port, GM_RX_CTRL,\n\t\t\t GM_RXCR_UCF_ENA | GM_RXCR_CRC_DIS | GM_RXCR_MCF_ENA);\n\n\t \n\tgma_write16(hw, port, GM_TX_FLOW_CTRL, 0xffff);\n\n\t \n\tgma_write16(hw, port, GM_TX_PARAM,\n\t\t\t TX_JAM_LEN_VAL(TX_JAM_LEN_DEF) |\n\t\t\t TX_JAM_IPG_VAL(TX_JAM_IPG_DEF) |\n\t\t\t TX_IPG_JAM_DATA(TX_IPG_JAM_DEF));\n\n\t \n\treg = DATA_BLIND_VAL(DATA_BLIND_DEF)\n\t\t| GM_SMOD_VLAN_ENA\n\t\t| IPG_DATA_VAL(IPG_DATA_DEF);\n\n\tif (hw->dev[port]->mtu > ETH_DATA_LEN)\n\t\treg |= GM_SMOD_JUMBO_ENA;\n\n\tgma_write16(hw, port, GM_SERIAL_MODE, reg);\n\n\t \n\tgma_set_addr(hw, port, GM_SRC_ADDR_1L, addr);\n\t \n\tgma_set_addr(hw, port, GM_SRC_ADDR_2L, addr);\n\n\t \n\tgma_write16(hw, port, GM_TX_IRQ_MSK, 0);\n\tgma_write16(hw, port, GM_RX_IRQ_MSK, 0);\n\tgma_write16(hw, port, GM_TR_IRQ_MSK, 0);\n\n\t \n\n\t \n\tskge_write16(hw, SK_REG(port, RX_GMF_FL_MSK), RX_FF_FL_DEF_MSK);\n\treg = GMF_OPER_ON | GMF_RX_F_FL_ON;\n\n\t \n\tif (is_yukon_lite_a0(hw))\n\t\treg &= ~GMF_RX_F_FL_ON;\n\n\tskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_RST_CLR);\n\tskge_write16(hw, SK_REG(port, RX_GMF_CTRL_T), reg);\n\t \n\tskge_write16(hw, SK_REG(port, RX_GMF_FL_THR), RX_GMF_FL_THR_DEF+1);\n\n\t \n\tskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_RST_CLR);\n\tskge_write16(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_OPER_ON);\n}\n\n \nstatic void yukon_suspend(struct skge_hw *hw, int port)\n{\n\tu16 ctrl;\n\n\tctrl = gm_phy_read(hw, port, PHY_MARV_PHY_CTRL);\n\tctrl |= PHY_M_PC_POL_R_DIS;\n\tgm_phy_write(hw, port, PHY_MARV_PHY_CTRL, ctrl);\n\n\tctrl = gm_phy_read(hw, port, PHY_MARV_CTRL);\n\tctrl |= PHY_CT_RESET;\n\tgm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\n\n\t \n\tctrl = gm_phy_read(hw, port, PHY_MARV_CTRL);\n\tctrl |= PHY_CT_PDOWN;\n\tgm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\n}\n\nstatic void yukon_stop(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\n\tskge_write8(hw, SK_REG(port, GMAC_IRQ_MSK), 0);\n\tyukon_reset(hw, port);\n\n\tgma_write16(hw, port, GM_GP_CTRL,\n\t\t\t gma_read16(hw, port, GM_GP_CTRL)\n\t\t\t & ~(GM_GPCR_TX_ENA|GM_GPCR_RX_ENA));\n\tgma_read16(hw, port, GM_GP_CTRL);\n\n\tyukon_suspend(hw, port);\n\n\t \n\tskge_write8(hw, SK_REG(port, GPHY_CTRL), GPC_RST_SET);\n\tskge_write8(hw, SK_REG(port, GMAC_CTRL), GMC_RST_SET);\n}\n\nstatic void yukon_get_stats(struct skge_port *skge, u64 *data)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tint i;\n\n\tdata[0] = (u64) gma_read32(hw, port, GM_TXO_OK_HI) << 32\n\t\t| gma_read32(hw, port, GM_TXO_OK_LO);\n\tdata[1] = (u64) gma_read32(hw, port, GM_RXO_OK_HI) << 32\n\t\t| gma_read32(hw, port, GM_RXO_OK_LO);\n\n\tfor (i = 2; i < ARRAY_SIZE(skge_stats); i++)\n\t\tdata[i] = gma_read32(hw, port,\n\t\t\t\t\t  skge_stats[i].gma_offset);\n}\n\nstatic void yukon_mac_intr(struct skge_hw *hw, int port)\n{\n\tstruct net_device *dev = hw->dev[port];\n\tstruct skge_port *skge = netdev_priv(dev);\n\tu8 status = skge_read8(hw, SK_REG(port, GMAC_IRQ_SRC));\n\n\tnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\n\t\t     \"mac interrupt status 0x%x\\n\", status);\n\n\tif (status & GM_IS_RX_FF_OR) {\n\t\t++dev->stats.rx_fifo_errors;\n\t\tskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_CLI_RX_FO);\n\t}\n\n\tif (status & GM_IS_TX_FF_UR) {\n\t\t++dev->stats.tx_fifo_errors;\n\t\tskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_CLI_TX_FU);\n\t}\n\n}\n\nstatic u16 yukon_speed(const struct skge_hw *hw, u16 aux)\n{\n\tswitch (aux & PHY_M_PS_SPEED_MSK) {\n\tcase PHY_M_PS_SPEED_1000:\n\t\treturn SPEED_1000;\n\tcase PHY_M_PS_SPEED_100:\n\t\treturn SPEED_100;\n\tdefault:\n\t\treturn SPEED_10;\n\t}\n}\n\nstatic void yukon_link_up(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu16 reg;\n\n\t \n\tskge_write8(hw, SK_REG(port, GMAC_IRQ_MSK), GMAC_DEF_MSK);\n\n\treg = gma_read16(hw, port, GM_GP_CTRL);\n\tif (skge->duplex == DUPLEX_FULL || skge->autoneg == AUTONEG_ENABLE)\n\t\treg |= GM_GPCR_DUP_FULL;\n\n\t \n\treg |= GM_GPCR_RX_ENA | GM_GPCR_TX_ENA;\n\tgma_write16(hw, port, GM_GP_CTRL, reg);\n\n\tgm_phy_write(hw, port, PHY_MARV_INT_MASK, PHY_M_IS_DEF_MSK);\n\tskge_link_up(skge);\n}\n\nstatic void yukon_link_down(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu16 ctrl;\n\n\tctrl = gma_read16(hw, port, GM_GP_CTRL);\n\tctrl &= ~(GM_GPCR_RX_ENA | GM_GPCR_TX_ENA);\n\tgma_write16(hw, port, GM_GP_CTRL, ctrl);\n\n\tif (skge->flow_status == FLOW_STAT_REM_SEND) {\n\t\tctrl = gm_phy_read(hw, port, PHY_MARV_AUNE_ADV);\n\t\tctrl |= PHY_M_AN_ASP;\n\t\t \n\t\tgm_phy_write(hw, port, PHY_MARV_AUNE_ADV, ctrl);\n\t}\n\n\tskge_link_down(skge);\n\n\tyukon_init(hw, port);\n}\n\nstatic void yukon_phy_intr(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tconst char *reason = NULL;\n\tu16 istatus, phystat;\n\n\tistatus = gm_phy_read(hw, port, PHY_MARV_INT_STAT);\n\tphystat = gm_phy_read(hw, port, PHY_MARV_PHY_STAT);\n\n\tnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\n\t\t     \"phy interrupt status 0x%x 0x%x\\n\", istatus, phystat);\n\n\tif (istatus & PHY_M_IS_AN_COMPL) {\n\t\tif (gm_phy_read(hw, port, PHY_MARV_AUNE_LP)\n\t\t    & PHY_M_AN_RF) {\n\t\t\treason = \"remote fault\";\n\t\t\tgoto failed;\n\t\t}\n\n\t\tif (gm_phy_read(hw, port, PHY_MARV_1000T_STAT) & PHY_B_1000S_MSF) {\n\t\t\treason = \"master/slave fault\";\n\t\t\tgoto failed;\n\t\t}\n\n\t\tif (!(phystat & PHY_M_PS_SPDUP_RES)) {\n\t\t\treason = \"speed/duplex\";\n\t\t\tgoto failed;\n\t\t}\n\n\t\tskge->duplex = (phystat & PHY_M_PS_FULL_DUP)\n\t\t\t? DUPLEX_FULL : DUPLEX_HALF;\n\t\tskge->speed = yukon_speed(hw, phystat);\n\n\t\t \n\t\tswitch (phystat & PHY_M_PS_PAUSE_MSK) {\n\t\tcase PHY_M_PS_PAUSE_MSK:\n\t\t\tskge->flow_status = FLOW_STAT_SYMMETRIC;\n\t\t\tbreak;\n\t\tcase PHY_M_PS_RX_P_EN:\n\t\t\tskge->flow_status = FLOW_STAT_REM_SEND;\n\t\t\tbreak;\n\t\tcase PHY_M_PS_TX_P_EN:\n\t\t\tskge->flow_status = FLOW_STAT_LOC_SEND;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tskge->flow_status = FLOW_STAT_NONE;\n\t\t}\n\n\t\tif (skge->flow_status == FLOW_STAT_NONE ||\n\t\t    (skge->speed < SPEED_1000 && skge->duplex == DUPLEX_HALF))\n\t\t\tskge_write8(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_OFF);\n\t\telse\n\t\t\tskge_write8(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_ON);\n\t\tyukon_link_up(skge);\n\t\treturn;\n\t}\n\n\tif (istatus & PHY_M_IS_LSP_CHANGE)\n\t\tskge->speed = yukon_speed(hw, phystat);\n\n\tif (istatus & PHY_M_IS_DUP_CHANGE)\n\t\tskge->duplex = (phystat & PHY_M_PS_FULL_DUP) ? DUPLEX_FULL : DUPLEX_HALF;\n\tif (istatus & PHY_M_IS_LST_CHANGE) {\n\t\tif (phystat & PHY_M_PS_LINK_UP)\n\t\t\tyukon_link_up(skge);\n\t\telse\n\t\t\tyukon_link_down(skge);\n\t}\n\treturn;\n failed:\n\tpr_err(\"%s: autonegotiation failed (%s)\\n\", skge->netdev->name, reason);\n\n\t \n}\n\nstatic void skge_phy_reset(struct skge_port *skge)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tstruct net_device *dev = hw->dev[port];\n\n\tnetif_stop_queue(skge->netdev);\n\tnetif_carrier_off(skge->netdev);\n\n\tspin_lock_bh(&hw->phy_lock);\n\tif (is_genesis(hw)) {\n\t\tgenesis_reset(hw, port);\n\t\tgenesis_mac_init(hw, port);\n\t} else {\n\t\tyukon_reset(hw, port);\n\t\tyukon_init(hw, port);\n\t}\n\tspin_unlock_bh(&hw->phy_lock);\n\n\tskge_set_multicast(dev);\n}\n\n \nstatic int skge_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct mii_ioctl_data *data = if_mii(ifr);\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint err = -EOPNOTSUPP;\n\n\tif (!netif_running(dev))\n\t\treturn -ENODEV;\t \n\n\tswitch (cmd) {\n\tcase SIOCGMIIPHY:\n\t\tdata->phy_id = hw->phy_addr;\n\n\t\tfallthrough;\n\tcase SIOCGMIIREG: {\n\t\tu16 val = 0;\n\t\tspin_lock_bh(&hw->phy_lock);\n\n\t\tif (is_genesis(hw))\n\t\t\terr = __xm_phy_read(hw, skge->port, data->reg_num & 0x1f, &val);\n\t\telse\n\t\t\terr = __gm_phy_read(hw, skge->port, data->reg_num & 0x1f, &val);\n\t\tspin_unlock_bh(&hw->phy_lock);\n\t\tdata->val_out = val;\n\t\tbreak;\n\t}\n\n\tcase SIOCSMIIREG:\n\t\tspin_lock_bh(&hw->phy_lock);\n\t\tif (is_genesis(hw))\n\t\t\terr = xm_phy_write(hw, skge->port, data->reg_num & 0x1f,\n\t\t\t\t   data->val_in);\n\t\telse\n\t\t\terr = gm_phy_write(hw, skge->port, data->reg_num & 0x1f,\n\t\t\t\t   data->val_in);\n\t\tspin_unlock_bh(&hw->phy_lock);\n\t\tbreak;\n\t}\n\treturn err;\n}\n\nstatic void skge_ramset(struct skge_hw *hw, u16 q, u32 start, size_t len)\n{\n\tu32 end;\n\n\tstart /= 8;\n\tlen /= 8;\n\tend = start + len - 1;\n\n\tskge_write8(hw, RB_ADDR(q, RB_CTRL), RB_RST_CLR);\n\tskge_write32(hw, RB_ADDR(q, RB_START), start);\n\tskge_write32(hw, RB_ADDR(q, RB_WP), start);\n\tskge_write32(hw, RB_ADDR(q, RB_RP), start);\n\tskge_write32(hw, RB_ADDR(q, RB_END), end);\n\n\tif (q == Q_R1 || q == Q_R2) {\n\t\t \n\t\tskge_write32(hw, RB_ADDR(q, RB_RX_UTPP),\n\t\t\t     start + (2*len)/3);\n\t\tskge_write32(hw, RB_ADDR(q, RB_RX_LTPP),\n\t\t\t     start + (len/3));\n\t} else {\n\t\t \n\t\tskge_write8(hw, RB_ADDR(q, RB_CTRL), RB_ENA_STFWD);\n\t}\n\n\tskge_write8(hw, RB_ADDR(q, RB_CTRL), RB_ENA_OP_MD);\n}\n\n \nstatic void skge_qset(struct skge_port *skge, u16 q,\n\t\t      const struct skge_element *e)\n{\n\tstruct skge_hw *hw = skge->hw;\n\tu32 watermark = 0x600;\n\tu64 base = skge->dma + (e->desc - skge->mem);\n\n\t \n\tif ((skge_read16(hw, B0_CTST) & (CS_BUS_CLOCK | CS_BUS_SLOT_SZ)) == 0)\n\t\twatermark /= 2;\n\n\tskge_write32(hw, Q_ADDR(q, Q_CSR), CSR_CLR_RESET);\n\tskge_write32(hw, Q_ADDR(q, Q_F), watermark);\n\tskge_write32(hw, Q_ADDR(q, Q_DA_H), (u32)(base >> 32));\n\tskge_write32(hw, Q_ADDR(q, Q_DA_L), (u32)base);\n}\n\nstatic int skge_up(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tu32 chunk, ram_addr;\n\tsize_t rx_size, tx_size;\n\tint err;\n\n\tif (!is_valid_ether_addr(dev->dev_addr))\n\t\treturn -EINVAL;\n\n\tnetif_info(skge, ifup, skge->netdev, \"enabling interface\\n\");\n\n\tif (dev->mtu > RX_BUF_SIZE)\n\t\tskge->rx_buf_size = dev->mtu + ETH_HLEN;\n\telse\n\t\tskge->rx_buf_size = RX_BUF_SIZE;\n\n\n\trx_size = skge->rx_ring.count * sizeof(struct skge_rx_desc);\n\ttx_size = skge->tx_ring.count * sizeof(struct skge_tx_desc);\n\tskge->mem_size = tx_size + rx_size;\n\tskge->mem = dma_alloc_coherent(&hw->pdev->dev, skge->mem_size,\n\t\t\t\t       &skge->dma, GFP_KERNEL);\n\tif (!skge->mem)\n\t\treturn -ENOMEM;\n\n\tBUG_ON(skge->dma & 7);\n\n\tif (upper_32_bits(skge->dma) != upper_32_bits(skge->dma + skge->mem_size)) {\n\t\tdev_err(&hw->pdev->dev, \"dma_alloc_coherent region crosses 4G boundary\\n\");\n\t\terr = -EINVAL;\n\t\tgoto free_pci_mem;\n\t}\n\n\terr = skge_ring_alloc(&skge->rx_ring, skge->mem, skge->dma);\n\tif (err)\n\t\tgoto free_pci_mem;\n\n\terr = skge_rx_fill(dev);\n\tif (err)\n\t\tgoto free_rx_ring;\n\n\terr = skge_ring_alloc(&skge->tx_ring, skge->mem + rx_size,\n\t\t\t      skge->dma + rx_size);\n\tif (err)\n\t\tgoto free_rx_ring;\n\n\tif (hw->ports == 1) {\n\t\terr = request_irq(hw->pdev->irq, skge_intr, IRQF_SHARED,\n\t\t\t\t  dev->name, hw);\n\t\tif (err) {\n\t\t\tnetdev_err(dev, \"Unable to allocate interrupt %d error: %d\\n\",\n\t\t\t\t   hw->pdev->irq, err);\n\t\t\tgoto free_tx_ring;\n\t\t}\n\t}\n\n\t \n\tnetif_carrier_off(dev);\n\tspin_lock_bh(&hw->phy_lock);\n\tif (is_genesis(hw))\n\t\tgenesis_mac_init(hw, port);\n\telse\n\t\tyukon_mac_init(hw, port);\n\tspin_unlock_bh(&hw->phy_lock);\n\n\t \n\tchunk = (hw->ram_size  - hw->ram_offset) / (hw->ports * 2);\n\tram_addr = hw->ram_offset + 2 * chunk * port;\n\n\tskge_ramset(hw, rxqaddr[port], ram_addr, chunk);\n\tskge_qset(skge, rxqaddr[port], skge->rx_ring.to_clean);\n\n\tBUG_ON(skge->tx_ring.to_use != skge->tx_ring.to_clean);\n\tskge_ramset(hw, txqaddr[port], ram_addr+chunk, chunk);\n\tskge_qset(skge, txqaddr[port], skge->tx_ring.to_use);\n\n\t \n\twmb();\n\tskge_write8(hw, Q_ADDR(rxqaddr[port], Q_CSR), CSR_START | CSR_IRQ_CL_F);\n\tskge_led(skge, LED_MODE_ON);\n\n\tspin_lock_irq(&hw->hw_lock);\n\thw->intr_mask |= portmask[port];\n\tskge_write32(hw, B0_IMSK, hw->intr_mask);\n\tskge_read32(hw, B0_IMSK);\n\tspin_unlock_irq(&hw->hw_lock);\n\n\tnapi_enable(&skge->napi);\n\n\tskge_set_multicast(dev);\n\n\treturn 0;\n\n free_tx_ring:\n\tkfree(skge->tx_ring.start);\n free_rx_ring:\n\tskge_rx_clean(skge);\n\tkfree(skge->rx_ring.start);\n free_pci_mem:\n\tdma_free_coherent(&hw->pdev->dev, skge->mem_size, skge->mem,\n\t\t\t  skge->dma);\n\tskge->mem = NULL;\n\n\treturn err;\n}\n\n \nstatic void skge_rx_stop(struct skge_hw *hw, int port)\n{\n\tskge_write8(hw, Q_ADDR(rxqaddr[port], Q_CSR), CSR_STOP);\n\tskge_write32(hw, RB_ADDR(port ? Q_R2 : Q_R1, RB_CTRL),\n\t\t     RB_RST_SET|RB_DIS_OP_MD);\n\tskge_write32(hw, Q_ADDR(rxqaddr[port], Q_CSR), CSR_SET_RESET);\n}\n\nstatic int skge_down(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\n\tif (!skge->mem)\n\t\treturn 0;\n\n\tnetif_info(skge, ifdown, skge->netdev, \"disabling interface\\n\");\n\n\tnetif_tx_disable(dev);\n\n\tif (is_genesis(hw) && hw->phy_type == SK_PHY_XMAC)\n\t\tdel_timer_sync(&skge->link_timer);\n\n\tnapi_disable(&skge->napi);\n\tnetif_carrier_off(dev);\n\n\tspin_lock_irq(&hw->hw_lock);\n\thw->intr_mask &= ~portmask[port];\n\tskge_write32(hw, B0_IMSK, (hw->ports == 1) ? 0 : hw->intr_mask);\n\tskge_read32(hw, B0_IMSK);\n\tspin_unlock_irq(&hw->hw_lock);\n\n\tif (hw->ports == 1)\n\t\tfree_irq(hw->pdev->irq, hw);\n\n\tskge_write8(skge->hw, SK_REG(skge->port, LNK_LED_REG), LED_REG_OFF);\n\tif (is_genesis(hw))\n\t\tgenesis_stop(skge);\n\telse\n\t\tyukon_stop(skge);\n\n\t \n\tskge_write8(hw, Q_ADDR(txqaddr[port], Q_CSR), CSR_STOP);\n\tskge_write32(hw, RB_ADDR(txqaddr[port], RB_CTRL),\n\t\t     RB_RST_SET|RB_DIS_OP_MD);\n\n\n\t \n\tskge_write8(hw, SK_REG(port, TXA_CTRL),\n\t\t    TXA_DIS_FSYNC | TXA_DIS_ALLOC | TXA_STOP_RC);\n\n\t \n\tskge_write32(hw, SK_REG(port, TXA_ITI_INI), 0L);\n\tskge_write32(hw, SK_REG(port, TXA_LIM_INI), 0L);\n\n\t \n\tskge_write32(hw, Q_ADDR(txqaddr[port], Q_CSR), CSR_SET_RESET);\n\tskge_write32(hw, RB_ADDR(txqaddr[port], RB_CTRL), RB_RST_SET);\n\n\t \n\tskge_write8(hw, RB_ADDR(port == 0 ? Q_XA1 : Q_XA2, RB_CTRL), RB_RST_SET);\n\n\tskge_rx_stop(hw, port);\n\n\tif (is_genesis(hw)) {\n\t\tskge_write8(hw, SK_REG(port, TX_MFF_CTRL2), MFF_RST_SET);\n\t\tskge_write8(hw, SK_REG(port, RX_MFF_CTRL2), MFF_RST_SET);\n\t} else {\n\t\tskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_RST_SET);\n\t\tskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_RST_SET);\n\t}\n\n\tskge_led(skge, LED_MODE_OFF);\n\n\tnetif_tx_lock_bh(dev);\n\tskge_tx_clean(dev);\n\tnetif_tx_unlock_bh(dev);\n\n\tskge_rx_clean(skge);\n\n\tkfree(skge->rx_ring.start);\n\tkfree(skge->tx_ring.start);\n\tdma_free_coherent(&hw->pdev->dev, skge->mem_size, skge->mem,\n\t\t\t  skge->dma);\n\tskge->mem = NULL;\n\treturn 0;\n}\n\nstatic inline int skge_avail(const struct skge_ring *ring)\n{\n\tsmp_mb();\n\treturn ((ring->to_clean > ring->to_use) ? 0 : ring->count)\n\t\t+ (ring->to_clean - ring->to_use) - 1;\n}\n\nstatic netdev_tx_t skge_xmit_frame(struct sk_buff *skb,\n\t\t\t\t   struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tstruct skge_element *e;\n\tstruct skge_tx_desc *td;\n\tint i;\n\tu32 control, len;\n\tdma_addr_t map;\n\n\tif (skb_padto(skb, ETH_ZLEN))\n\t\treturn NETDEV_TX_OK;\n\n\tif (unlikely(skge_avail(&skge->tx_ring) < skb_shinfo(skb)->nr_frags + 1))\n\t\treturn NETDEV_TX_BUSY;\n\n\te = skge->tx_ring.to_use;\n\ttd = e->desc;\n\tBUG_ON(td->control & BMU_OWN);\n\te->skb = skb;\n\tlen = skb_headlen(skb);\n\tmap = dma_map_single(&hw->pdev->dev, skb->data, len, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&hw->pdev->dev, map))\n\t\tgoto mapping_error;\n\n\tdma_unmap_addr_set(e, mapaddr, map);\n\tdma_unmap_len_set(e, maplen, len);\n\n\ttd->dma_lo = lower_32_bits(map);\n\ttd->dma_hi = upper_32_bits(map);\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tconst int offset = skb_checksum_start_offset(skb);\n\n\t\t \n\t\tif (ipip_hdr(skb)->protocol == IPPROTO_UDP &&\n\t\t    hw->chip_rev == 0 && hw->chip_id == CHIP_ID_YUKON)\n\t\t\tcontrol = BMU_TCP_CHECK;\n\t\telse\n\t\t\tcontrol = BMU_UDP_CHECK;\n\n\t\ttd->csum_offs = 0;\n\t\ttd->csum_start = offset;\n\t\ttd->csum_write = offset + skb->csum_offset;\n\t} else\n\t\tcontrol = BMU_CHECK;\n\n\tif (!skb_shinfo(skb)->nr_frags)  \n\t\tcontrol |= BMU_EOF | BMU_IRQ_EOF;\n\telse {\n\t\tstruct skge_tx_desc *tf = td;\n\n\t\tcontrol |= BMU_STFWD;\n\t\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\t\tconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\n\t\t\tmap = skb_frag_dma_map(&hw->pdev->dev, frag, 0,\n\t\t\t\t\t       skb_frag_size(frag), DMA_TO_DEVICE);\n\t\t\tif (dma_mapping_error(&hw->pdev->dev, map))\n\t\t\t\tgoto mapping_unwind;\n\n\t\t\te = e->next;\n\t\t\te->skb = skb;\n\t\t\ttf = e->desc;\n\t\t\tBUG_ON(tf->control & BMU_OWN);\n\n\t\t\ttf->dma_lo = lower_32_bits(map);\n\t\t\ttf->dma_hi = upper_32_bits(map);\n\t\t\tdma_unmap_addr_set(e, mapaddr, map);\n\t\t\tdma_unmap_len_set(e, maplen, skb_frag_size(frag));\n\n\t\t\ttf->control = BMU_OWN | BMU_SW | control | skb_frag_size(frag);\n\t\t}\n\t\ttf->control |= BMU_EOF | BMU_IRQ_EOF;\n\t}\n\t \n\twmb();\n\ttd->control = BMU_OWN | BMU_SW | BMU_STF | control | len;\n\twmb();\n\n\tnetdev_sent_queue(dev, skb->len);\n\n\tskge_write8(hw, Q_ADDR(txqaddr[skge->port], Q_CSR), CSR_START);\n\n\tnetif_printk(skge, tx_queued, KERN_DEBUG, skge->netdev,\n\t\t     \"tx queued, slot %td, len %d\\n\",\n\t\t     e - skge->tx_ring.start, skb->len);\n\n\tskge->tx_ring.to_use = e->next;\n\tsmp_wmb();\n\n\tif (skge_avail(&skge->tx_ring) <= TX_LOW_WATER) {\n\t\tnetdev_dbg(dev, \"transmit queue full\\n\");\n\t\tnetif_stop_queue(dev);\n\t}\n\n\treturn NETDEV_TX_OK;\n\nmapping_unwind:\n\te = skge->tx_ring.to_use;\n\tdma_unmap_single(&hw->pdev->dev, dma_unmap_addr(e, mapaddr),\n\t\t\t dma_unmap_len(e, maplen), DMA_TO_DEVICE);\n\twhile (i-- > 0) {\n\t\te = e->next;\n\t\tdma_unmap_page(&hw->pdev->dev, dma_unmap_addr(e, mapaddr),\n\t\t\t       dma_unmap_len(e, maplen), DMA_TO_DEVICE);\n\t}\n\nmapping_error:\n\tif (net_ratelimit())\n\t\tdev_warn(&hw->pdev->dev, \"%s: tx mapping error\\n\", dev->name);\n\tdev_kfree_skb_any(skb);\n\treturn NETDEV_TX_OK;\n}\n\n\n \nstatic inline void skge_tx_unmap(struct pci_dev *pdev, struct skge_element *e,\n\t\t\t\t u32 control)\n{\n\t \n\tif (control & BMU_STF)\n\t\tdma_unmap_single(&pdev->dev, dma_unmap_addr(e, mapaddr),\n\t\t\t\t dma_unmap_len(e, maplen), DMA_TO_DEVICE);\n\telse\n\t\tdma_unmap_page(&pdev->dev, dma_unmap_addr(e, mapaddr),\n\t\t\t       dma_unmap_len(e, maplen), DMA_TO_DEVICE);\n}\n\n \nstatic void skge_tx_clean(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_element *e;\n\n\tfor (e = skge->tx_ring.to_clean; e != skge->tx_ring.to_use; e = e->next) {\n\t\tstruct skge_tx_desc *td = e->desc;\n\n\t\tskge_tx_unmap(skge->hw->pdev, e, td->control);\n\n\t\tif (td->control & BMU_EOF)\n\t\t\tdev_kfree_skb(e->skb);\n\t\ttd->control = 0;\n\t}\n\n\tnetdev_reset_queue(dev);\n\tskge->tx_ring.to_clean = e;\n}\n\nstatic void skge_tx_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tnetif_printk(skge, timer, KERN_DEBUG, skge->netdev, \"tx timeout\\n\");\n\n\tskge_write8(skge->hw, Q_ADDR(txqaddr[skge->port], Q_CSR), CSR_STOP);\n\tskge_tx_clean(dev);\n\tnetif_wake_queue(dev);\n}\n\nstatic int skge_change_mtu(struct net_device *dev, int new_mtu)\n{\n\tint err;\n\n\tif (!netif_running(dev)) {\n\t\tdev->mtu = new_mtu;\n\t\treturn 0;\n\t}\n\n\tskge_down(dev);\n\n\tdev->mtu = new_mtu;\n\n\terr = skge_up(dev);\n\tif (err)\n\t\tdev_close(dev);\n\n\treturn err;\n}\n\nstatic const u8 pause_mc_addr[ETH_ALEN] = { 0x1, 0x80, 0xc2, 0x0, 0x0, 0x1 };\n\nstatic void genesis_add_filter(u8 filter[8], const u8 *addr)\n{\n\tu32 crc, bit;\n\n\tcrc = ether_crc_le(ETH_ALEN, addr);\n\tbit = ~crc & 0x3f;\n\tfilter[bit/8] |= 1 << (bit%8);\n}\n\nstatic void genesis_set_multicast(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tstruct netdev_hw_addr *ha;\n\tu32 mode;\n\tu8 filter[8];\n\n\tmode = xm_read32(hw, port, XM_MODE);\n\tmode |= XM_MD_ENA_HASH;\n\tif (dev->flags & IFF_PROMISC)\n\t\tmode |= XM_MD_ENA_PROM;\n\telse\n\t\tmode &= ~XM_MD_ENA_PROM;\n\n\tif (dev->flags & IFF_ALLMULTI)\n\t\tmemset(filter, 0xff, sizeof(filter));\n\telse {\n\t\tmemset(filter, 0, sizeof(filter));\n\n\t\tif (skge->flow_status == FLOW_STAT_REM_SEND ||\n\t\t    skge->flow_status == FLOW_STAT_SYMMETRIC)\n\t\t\tgenesis_add_filter(filter, pause_mc_addr);\n\n\t\tnetdev_for_each_mc_addr(ha, dev)\n\t\t\tgenesis_add_filter(filter, ha->addr);\n\t}\n\n\txm_write32(hw, port, XM_MODE, mode);\n\txm_outhash(hw, port, XM_HSM, filter);\n}\n\nstatic void yukon_add_filter(u8 filter[8], const u8 *addr)\n{\n\tu32 bit = ether_crc(ETH_ALEN, addr) & 0x3f;\n\n\tfilter[bit / 8] |= 1 << (bit % 8);\n}\n\nstatic void yukon_set_multicast(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tint port = skge->port;\n\tstruct netdev_hw_addr *ha;\n\tint rx_pause = (skge->flow_status == FLOW_STAT_REM_SEND ||\n\t\t\tskge->flow_status == FLOW_STAT_SYMMETRIC);\n\tu16 reg;\n\tu8 filter[8];\n\n\tmemset(filter, 0, sizeof(filter));\n\n\treg = gma_read16(hw, port, GM_RX_CTRL);\n\treg |= GM_RXCR_UCF_ENA;\n\n\tif (dev->flags & IFF_PROMISC) \t\t \n\t\treg &= ~(GM_RXCR_UCF_ENA | GM_RXCR_MCF_ENA);\n\telse if (dev->flags & IFF_ALLMULTI)\t \n\t\tmemset(filter, 0xff, sizeof(filter));\n\telse if (netdev_mc_empty(dev) && !rx_pause) \n\t\treg &= ~GM_RXCR_MCF_ENA;\n\telse {\n\t\treg |= GM_RXCR_MCF_ENA;\n\n\t\tif (rx_pause)\n\t\t\tyukon_add_filter(filter, pause_mc_addr);\n\n\t\tnetdev_for_each_mc_addr(ha, dev)\n\t\t\tyukon_add_filter(filter, ha->addr);\n\t}\n\n\n\tgma_write16(hw, port, GM_MC_ADDR_H1,\n\t\t\t (u16)filter[0] | ((u16)filter[1] << 8));\n\tgma_write16(hw, port, GM_MC_ADDR_H2,\n\t\t\t (u16)filter[2] | ((u16)filter[3] << 8));\n\tgma_write16(hw, port, GM_MC_ADDR_H3,\n\t\t\t (u16)filter[4] | ((u16)filter[5] << 8));\n\tgma_write16(hw, port, GM_MC_ADDR_H4,\n\t\t\t (u16)filter[6] | ((u16)filter[7] << 8));\n\n\tgma_write16(hw, port, GM_RX_CTRL, reg);\n}\n\nstatic inline u16 phy_length(const struct skge_hw *hw, u32 status)\n{\n\tif (is_genesis(hw))\n\t\treturn status >> XMR_FS_LEN_SHIFT;\n\telse\n\t\treturn status >> GMR_FS_LEN_SHIFT;\n}\n\nstatic inline int bad_phy_status(const struct skge_hw *hw, u32 status)\n{\n\tif (is_genesis(hw))\n\t\treturn (status & (XMR_FS_ERR | XMR_FS_2L_VLAN)) != 0;\n\telse\n\t\treturn (status & GMR_FS_ANY_ERR) ||\n\t\t\t(status & GMR_FS_RX_OK) == 0;\n}\n\nstatic void skge_set_multicast(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tif (is_genesis(skge->hw))\n\t\tgenesis_set_multicast(dev);\n\telse\n\t\tyukon_set_multicast(dev);\n\n}\n\n\n \nstatic struct sk_buff *skge_rx_get(struct net_device *dev,\n\t\t\t\t   struct skge_element *e,\n\t\t\t\t   u32 control, u32 status, u16 csum)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct sk_buff *skb;\n\tu16 len = control & BMU_BBC;\n\n\tnetif_printk(skge, rx_status, KERN_DEBUG, skge->netdev,\n\t\t     \"rx slot %td status 0x%x len %d\\n\",\n\t\t     e - skge->rx_ring.start, status, len);\n\n\tif (len > skge->rx_buf_size)\n\t\tgoto error;\n\n\tif ((control & (BMU_EOF|BMU_STF)) != (BMU_STF|BMU_EOF))\n\t\tgoto error;\n\n\tif (bad_phy_status(skge->hw, status))\n\t\tgoto error;\n\n\tif (phy_length(skge->hw, status) != len)\n\t\tgoto error;\n\n\tif (len < RX_COPY_THRESHOLD) {\n\t\tskb = netdev_alloc_skb_ip_align(dev, len);\n\t\tif (!skb)\n\t\t\tgoto resubmit;\n\n\t\tdma_sync_single_for_cpu(&skge->hw->pdev->dev,\n\t\t\t\t\tdma_unmap_addr(e, mapaddr),\n\t\t\t\t\tdma_unmap_len(e, maplen),\n\t\t\t\t\tDMA_FROM_DEVICE);\n\t\tskb_copy_from_linear_data(e->skb, skb->data, len);\n\t\tdma_sync_single_for_device(&skge->hw->pdev->dev,\n\t\t\t\t\t   dma_unmap_addr(e, mapaddr),\n\t\t\t\t\t   dma_unmap_len(e, maplen),\n\t\t\t\t\t   DMA_FROM_DEVICE);\n\t\tskge_rx_reuse(e, skge->rx_buf_size);\n\t} else {\n\t\tstruct skge_element ee;\n\t\tstruct sk_buff *nskb;\n\n\t\tnskb = netdev_alloc_skb_ip_align(dev, skge->rx_buf_size);\n\t\tif (!nskb)\n\t\t\tgoto resubmit;\n\n\t\tee = *e;\n\n\t\tskb = ee.skb;\n\t\tprefetch(skb->data);\n\n\t\tif (skge_rx_setup(skge, e, nskb, skge->rx_buf_size) < 0) {\n\t\t\tdev_kfree_skb(nskb);\n\t\t\tgoto resubmit;\n\t\t}\n\n\t\tdma_unmap_single(&skge->hw->pdev->dev,\n\t\t\t\t dma_unmap_addr(&ee, mapaddr),\n\t\t\t\t dma_unmap_len(&ee, maplen), DMA_FROM_DEVICE);\n\t}\n\n\tskb_put(skb, len);\n\n\tif (dev->features & NETIF_F_RXCSUM) {\n\t\tskb->csum = le16_to_cpu(csum);\n\t\tskb->ip_summed = CHECKSUM_COMPLETE;\n\t}\n\n\tskb->protocol = eth_type_trans(skb, dev);\n\n\treturn skb;\nerror:\n\n\tnetif_printk(skge, rx_err, KERN_DEBUG, skge->netdev,\n\t\t     \"rx err, slot %td control 0x%x status 0x%x\\n\",\n\t\t     e - skge->rx_ring.start, control, status);\n\n\tif (is_genesis(skge->hw)) {\n\t\tif (status & (XMR_FS_RUNT|XMR_FS_LNG_ERR))\n\t\t\tdev->stats.rx_length_errors++;\n\t\tif (status & XMR_FS_FRA_ERR)\n\t\t\tdev->stats.rx_frame_errors++;\n\t\tif (status & XMR_FS_FCS_ERR)\n\t\t\tdev->stats.rx_crc_errors++;\n\t} else {\n\t\tif (status & (GMR_FS_LONG_ERR|GMR_FS_UN_SIZE))\n\t\t\tdev->stats.rx_length_errors++;\n\t\tif (status & GMR_FS_FRAGMENT)\n\t\t\tdev->stats.rx_frame_errors++;\n\t\tif (status & GMR_FS_CRC_ERR)\n\t\t\tdev->stats.rx_crc_errors++;\n\t}\n\nresubmit:\n\tskge_rx_reuse(e, skge->rx_buf_size);\n\treturn NULL;\n}\n\n \nstatic void skge_tx_done(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_ring *ring = &skge->tx_ring;\n\tstruct skge_element *e;\n\tunsigned int bytes_compl = 0, pkts_compl = 0;\n\n\tskge_write8(skge->hw, Q_ADDR(txqaddr[skge->port], Q_CSR), CSR_IRQ_CL_F);\n\n\tfor (e = ring->to_clean; e != ring->to_use; e = e->next) {\n\t\tu32 control = ((const struct skge_tx_desc *) e->desc)->control;\n\n\t\tif (control & BMU_OWN)\n\t\t\tbreak;\n\n\t\tskge_tx_unmap(skge->hw->pdev, e, control);\n\n\t\tif (control & BMU_EOF) {\n\t\t\tnetif_printk(skge, tx_done, KERN_DEBUG, skge->netdev,\n\t\t\t\t     \"tx done slot %td\\n\",\n\t\t\t\t     e - skge->tx_ring.start);\n\n\t\t\tpkts_compl++;\n\t\t\tbytes_compl += e->skb->len;\n\n\t\t\tdev_consume_skb_any(e->skb);\n\t\t}\n\t}\n\tnetdev_completed_queue(dev, pkts_compl, bytes_compl);\n\tskge->tx_ring.to_clean = e;\n\n\t \n\tsmp_mb();\n\n\tif (unlikely(netif_queue_stopped(dev) &&\n\t\t     skge_avail(&skge->tx_ring) > TX_LOW_WATER)) {\n\t\tnetif_tx_lock(dev);\n\t\tif (unlikely(netif_queue_stopped(dev) &&\n\t\t\t     skge_avail(&skge->tx_ring) > TX_LOW_WATER)) {\n\t\t\tnetif_wake_queue(dev);\n\n\t\t}\n\t\tnetif_tx_unlock(dev);\n\t}\n}\n\nstatic int skge_poll(struct napi_struct *napi, int budget)\n{\n\tstruct skge_port *skge = container_of(napi, struct skge_port, napi);\n\tstruct net_device *dev = skge->netdev;\n\tstruct skge_hw *hw = skge->hw;\n\tstruct skge_ring *ring = &skge->rx_ring;\n\tstruct skge_element *e;\n\tint work_done = 0;\n\n\tskge_tx_done(dev);\n\n\tskge_write8(hw, Q_ADDR(rxqaddr[skge->port], Q_CSR), CSR_IRQ_CL_F);\n\n\tfor (e = ring->to_clean; prefetch(e->next), work_done < budget; e = e->next) {\n\t\tstruct skge_rx_desc *rd = e->desc;\n\t\tstruct sk_buff *skb;\n\t\tu32 control;\n\n\t\trmb();\n\t\tcontrol = rd->control;\n\t\tif (control & BMU_OWN)\n\t\t\tbreak;\n\n\t\tskb = skge_rx_get(dev, e, control, rd->status, rd->csum2);\n\t\tif (likely(skb)) {\n\t\t\tnapi_gro_receive(napi, skb);\n\t\t\t++work_done;\n\t\t}\n\t}\n\tring->to_clean = e;\n\n\t \n\twmb();\n\tskge_write8(hw, Q_ADDR(rxqaddr[skge->port], Q_CSR), CSR_START);\n\n\tif (work_done < budget && napi_complete_done(napi, work_done)) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&hw->hw_lock, flags);\n\t\thw->intr_mask |= napimask[skge->port];\n\t\tskge_write32(hw, B0_IMSK, hw->intr_mask);\n\t\tskge_read32(hw, B0_IMSK);\n\t\tspin_unlock_irqrestore(&hw->hw_lock, flags);\n\t}\n\n\treturn work_done;\n}\n\n \nstatic void skge_mac_parity(struct skge_hw *hw, int port)\n{\n\tstruct net_device *dev = hw->dev[port];\n\n\t++dev->stats.tx_heartbeat_errors;\n\n\tif (is_genesis(hw))\n\t\tskge_write16(hw, SK_REG(port, TX_MFF_CTRL1),\n\t\t\t     MFF_CLR_PERR);\n\telse\n\t\t \n\t\tskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T),\n\t\t\t    (hw->chip_id == CHIP_ID_YUKON && hw->chip_rev == 0)\n\t\t\t    ? GMF_CLI_TX_FC : GMF_CLI_TX_PE);\n}\n\nstatic void skge_mac_intr(struct skge_hw *hw, int port)\n{\n\tif (is_genesis(hw))\n\t\tgenesis_mac_intr(hw, port);\n\telse\n\t\tyukon_mac_intr(hw, port);\n}\n\n \nstatic void skge_error_irq(struct skge_hw *hw)\n{\n\tstruct pci_dev *pdev = hw->pdev;\n\tu32 hwstatus = skge_read32(hw, B0_HWE_ISRC);\n\n\tif (is_genesis(hw)) {\n\t\t \n\t\tif (hwstatus & (IS_NO_STAT_M1|IS_NO_TIST_M1))\n\t\t\tskge_write16(hw, RX_MFF_CTRL1, MFF_CLR_INSTAT);\n\t\tif (hwstatus & (IS_NO_STAT_M2|IS_NO_TIST_M2))\n\t\t\tskge_write16(hw, RX_MFF_CTRL2, MFF_CLR_INSTAT);\n\t} else {\n\t\t \n\t\tif (hwstatus & IS_IRQ_TIST_OV)\n\t\t\tskge_write8(hw, GMAC_TI_ST_CTRL, GMT_ST_CLR_IRQ);\n\t}\n\n\tif (hwstatus & IS_RAM_RD_PAR) {\n\t\tdev_err(&pdev->dev, \"Ram read data parity error\\n\");\n\t\tskge_write16(hw, B3_RI_CTRL, RI_CLR_RD_PERR);\n\t}\n\n\tif (hwstatus & IS_RAM_WR_PAR) {\n\t\tdev_err(&pdev->dev, \"Ram write data parity error\\n\");\n\t\tskge_write16(hw, B3_RI_CTRL, RI_CLR_WR_PERR);\n\t}\n\n\tif (hwstatus & IS_M1_PAR_ERR)\n\t\tskge_mac_parity(hw, 0);\n\n\tif (hwstatus & IS_M2_PAR_ERR)\n\t\tskge_mac_parity(hw, 1);\n\n\tif (hwstatus & IS_R1_PAR_ERR) {\n\t\tdev_err(&pdev->dev, \"%s: receive queue parity error\\n\",\n\t\t\thw->dev[0]->name);\n\t\tskge_write32(hw, B0_R1_CSR, CSR_IRQ_CL_P);\n\t}\n\n\tif (hwstatus & IS_R2_PAR_ERR) {\n\t\tdev_err(&pdev->dev, \"%s: receive queue parity error\\n\",\n\t\t\thw->dev[1]->name);\n\t\tskge_write32(hw, B0_R2_CSR, CSR_IRQ_CL_P);\n\t}\n\n\tif (hwstatus & (IS_IRQ_MST_ERR|IS_IRQ_STAT)) {\n\t\tu16 pci_status, pci_cmd;\n\n\t\tpci_read_config_word(pdev, PCI_COMMAND, &pci_cmd);\n\t\tpci_read_config_word(pdev, PCI_STATUS, &pci_status);\n\n\t\tdev_err(&pdev->dev, \"PCI error cmd=%#x status=%#x\\n\",\n\t\t\tpci_cmd, pci_status);\n\n\t\t \n\t\tpci_status &= PCI_STATUS_ERROR_BITS;\n\t\tskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_ON);\n\t\tpci_write_config_word(pdev, PCI_COMMAND,\n\t\t\t\t      pci_cmd | PCI_COMMAND_SERR | PCI_COMMAND_PARITY);\n\t\tpci_write_config_word(pdev, PCI_STATUS, pci_status);\n\t\tskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_OFF);\n\n\t\t \n\t\thwstatus = skge_read32(hw, B0_HWE_ISRC);\n\t\tif (hwstatus & IS_IRQ_STAT) {\n\t\t\tdev_warn(&hw->pdev->dev, \"unable to clear error (so ignoring them)\\n\");\n\t\t\thw->intr_mask &= ~IS_HW_ERR;\n\t\t}\n\t}\n}\n\n \nstatic void skge_extirq(struct tasklet_struct *t)\n{\n\tstruct skge_hw *hw = from_tasklet(hw, t, phy_task);\n\tint port;\n\n\tfor (port = 0; port < hw->ports; port++) {\n\t\tstruct net_device *dev = hw->dev[port];\n\n\t\tif (netif_running(dev)) {\n\t\t\tstruct skge_port *skge = netdev_priv(dev);\n\n\t\t\tspin_lock(&hw->phy_lock);\n\t\t\tif (!is_genesis(hw))\n\t\t\t\tyukon_phy_intr(skge);\n\t\t\telse if (hw->phy_type == SK_PHY_BCOM)\n\t\t\t\tbcom_phy_intr(skge);\n\t\t\tspin_unlock(&hw->phy_lock);\n\t\t}\n\t}\n\n\tspin_lock_irq(&hw->hw_lock);\n\thw->intr_mask |= IS_EXT_REG;\n\tskge_write32(hw, B0_IMSK, hw->intr_mask);\n\tskge_read32(hw, B0_IMSK);\n\tspin_unlock_irq(&hw->hw_lock);\n}\n\nstatic irqreturn_t skge_intr(int irq, void *dev_id)\n{\n\tstruct skge_hw *hw = dev_id;\n\tu32 status;\n\tint handled = 0;\n\n\tspin_lock(&hw->hw_lock);\n\t \n\tstatus = skge_read32(hw, B0_SP_ISRC);\n\tif (status == 0 || status == ~0)\n\t\tgoto out;\n\n\thandled = 1;\n\tstatus &= hw->intr_mask;\n\tif (status & IS_EXT_REG) {\n\t\thw->intr_mask &= ~IS_EXT_REG;\n\t\ttasklet_schedule(&hw->phy_task);\n\t}\n\n\tif (status & (IS_XA1_F|IS_R1_F)) {\n\t\tstruct skge_port *skge = netdev_priv(hw->dev[0]);\n\t\thw->intr_mask &= ~(IS_XA1_F|IS_R1_F);\n\t\tnapi_schedule(&skge->napi);\n\t}\n\n\tif (status & IS_PA_TO_TX1)\n\t\tskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_TX1);\n\n\tif (status & IS_PA_TO_RX1) {\n\t\t++hw->dev[0]->stats.rx_over_errors;\n\t\tskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_RX1);\n\t}\n\n\n\tif (status & IS_MAC1)\n\t\tskge_mac_intr(hw, 0);\n\n\tif (hw->dev[1]) {\n\t\tstruct skge_port *skge = netdev_priv(hw->dev[1]);\n\n\t\tif (status & (IS_XA2_F|IS_R2_F)) {\n\t\t\thw->intr_mask &= ~(IS_XA2_F|IS_R2_F);\n\t\t\tnapi_schedule(&skge->napi);\n\t\t}\n\n\t\tif (status & IS_PA_TO_RX2) {\n\t\t\t++hw->dev[1]->stats.rx_over_errors;\n\t\t\tskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_RX2);\n\t\t}\n\n\t\tif (status & IS_PA_TO_TX2)\n\t\t\tskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_TX2);\n\n\t\tif (status & IS_MAC2)\n\t\t\tskge_mac_intr(hw, 1);\n\t}\n\n\tif (status & IS_HW_ERR)\n\t\tskge_error_irq(hw);\nout:\n\tskge_write32(hw, B0_IMSK, hw->intr_mask);\n\tskge_read32(hw, B0_IMSK);\n\tspin_unlock(&hw->hw_lock);\n\n\treturn IRQ_RETVAL(handled);\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void skge_netpoll(struct net_device *dev)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\n\tdisable_irq(dev->irq);\n\tskge_intr(dev->irq, skge->hw);\n\tenable_irq(dev->irq);\n}\n#endif\n\nstatic int skge_set_mac_address(struct net_device *dev, void *p)\n{\n\tstruct skge_port *skge = netdev_priv(dev);\n\tstruct skge_hw *hw = skge->hw;\n\tunsigned port = skge->port;\n\tconst struct sockaddr *addr = p;\n\tu16 ctrl;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(dev, addr->sa_data);\n\n\tif (!netif_running(dev)) {\n\t\tmemcpy_toio(hw->regs + B2_MAC_1 + port*8, dev->dev_addr, ETH_ALEN);\n\t\tmemcpy_toio(hw->regs + B2_MAC_2 + port*8, dev->dev_addr, ETH_ALEN);\n\t} else {\n\t\t \n\t\tspin_lock_bh(&hw->phy_lock);\n\t\tctrl = gma_read16(hw, port, GM_GP_CTRL);\n\t\tgma_write16(hw, port, GM_GP_CTRL, ctrl & ~GM_GPCR_RX_ENA);\n\n\t\tmemcpy_toio(hw->regs + B2_MAC_1 + port*8, dev->dev_addr, ETH_ALEN);\n\t\tmemcpy_toio(hw->regs + B2_MAC_2 + port*8, dev->dev_addr, ETH_ALEN);\n\n\t\tif (is_genesis(hw))\n\t\t\txm_outaddr(hw, port, XM_SA, dev->dev_addr);\n\t\telse {\n\t\t\tgma_set_addr(hw, port, GM_SRC_ADDR_1L, dev->dev_addr);\n\t\t\tgma_set_addr(hw, port, GM_SRC_ADDR_2L, dev->dev_addr);\n\t\t}\n\n\t\tgma_write16(hw, port, GM_GP_CTRL, ctrl);\n\t\tspin_unlock_bh(&hw->phy_lock);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct {\n\tu8 id;\n\tconst char *name;\n} skge_chips[] = {\n\t{ CHIP_ID_GENESIS,\t\"Genesis\" },\n\t{ CHIP_ID_YUKON,\t \"Yukon\" },\n\t{ CHIP_ID_YUKON_LITE,\t \"Yukon-Lite\"},\n\t{ CHIP_ID_YUKON_LP,\t \"Yukon-LP\"},\n};\n\nstatic const char *skge_board_name(const struct skge_hw *hw)\n{\n\tint i;\n\tstatic char buf[16];\n\n\tfor (i = 0; i < ARRAY_SIZE(skge_chips); i++)\n\t\tif (skge_chips[i].id == hw->chip_id)\n\t\t\treturn skge_chips[i].name;\n\n\tsnprintf(buf, sizeof(buf), \"chipid 0x%x\", hw->chip_id);\n\treturn buf;\n}\n\n\n \nstatic int skge_reset(struct skge_hw *hw)\n{\n\tu32 reg;\n\tu16 ctst, pci_status;\n\tu8 t8, mac_cfg, pmd_type;\n\tint i;\n\n\tctst = skge_read16(hw, B0_CTST);\n\n\t \n\tskge_write8(hw, B0_CTST, CS_RST_SET);\n\tskge_write8(hw, B0_CTST, CS_RST_CLR);\n\n\t \n\tskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_ON);\n\tskge_write8(hw, B2_TST_CTRL2, 0);\n\n\tpci_read_config_word(hw->pdev, PCI_STATUS, &pci_status);\n\tpci_write_config_word(hw->pdev, PCI_STATUS,\n\t\t\t      pci_status | PCI_STATUS_ERROR_BITS);\n\tskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_OFF);\n\tskge_write8(hw, B0_CTST, CS_MRST_CLR);\n\n\t \n\tskge_write16(hw, B0_CTST,\n\t\t     ctst & (CS_CLK_RUN_HOT|CS_CLK_RUN_RST|CS_CLK_RUN_ENA));\n\n\thw->chip_id = skge_read8(hw, B2_CHIP_ID);\n\thw->phy_type = skge_read8(hw, B2_E_1) & 0xf;\n\tpmd_type = skge_read8(hw, B2_PMD_TYP);\n\thw->copper = (pmd_type == 'T' || pmd_type == '1');\n\n\tswitch (hw->chip_id) {\n\tcase CHIP_ID_GENESIS:\n#ifdef CONFIG_SKGE_GENESIS\n\t\tswitch (hw->phy_type) {\n\t\tcase SK_PHY_XMAC:\n\t\t\thw->phy_addr = PHY_ADDR_XMAC;\n\t\t\tbreak;\n\t\tcase SK_PHY_BCOM:\n\t\t\thw->phy_addr = PHY_ADDR_BCOM;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&hw->pdev->dev, \"unsupported phy type 0x%x\\n\",\n\t\t\t       hw->phy_type);\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tbreak;\n#else\n\t\tdev_err(&hw->pdev->dev, \"Genesis chip detected but not configured\\n\");\n\t\treturn -EOPNOTSUPP;\n#endif\n\n\tcase CHIP_ID_YUKON:\n\tcase CHIP_ID_YUKON_LITE:\n\tcase CHIP_ID_YUKON_LP:\n\t\tif (hw->phy_type < SK_PHY_MARV_COPPER && pmd_type != 'S')\n\t\t\thw->copper = 1;\n\n\t\thw->phy_addr = PHY_ADDR_MARV;\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(&hw->pdev->dev, \"unsupported chip type 0x%x\\n\",\n\t\t       hw->chip_id);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmac_cfg = skge_read8(hw, B2_MAC_CFG);\n\thw->ports = (mac_cfg & CFG_SNG_MAC) ? 1 : 2;\n\thw->chip_rev = (mac_cfg & CFG_CHIP_R_MSK) >> 4;\n\n\t \n\tt8 = skge_read8(hw, B2_E_0);\n\tif (is_genesis(hw)) {\n\t\tif (t8 == 3) {\n\t\t\t \n\t\t\thw->ram_size = 0x100000;\n\t\t\thw->ram_offset = 0x80000;\n\t\t} else\n\t\t\thw->ram_size = t8 * 512;\n\t} else if (t8 == 0)\n\t\thw->ram_size = 0x20000;\n\telse\n\t\thw->ram_size = t8 * 4096;\n\n\thw->intr_mask = IS_HW_ERR;\n\n\t \n\tif (!(is_genesis(hw) && hw->phy_type == SK_PHY_XMAC))\n\t\thw->intr_mask |= IS_EXT_REG;\n\n\tif (is_genesis(hw))\n\t\tgenesis_init(hw);\n\telse {\n\t\t \n\t\tskge_write8(hw, B0_POWER_CTRL,\n\t\t\t    PC_VAUX_ENA | PC_VCC_ENA | PC_VAUX_OFF | PC_VCC_ON);\n\n\t\t \n\t\tif ((skge_read32(hw, B0_ISRC) & IS_HW_ERR) &&\n\t\t    (skge_read32(hw, B0_HWE_ISRC) & IS_IRQ_SENSOR)) {\n\t\t\tdev_warn(&hw->pdev->dev, \"stuck hardware sensor bit\\n\");\n\t\t\thw->intr_mask &= ~IS_HW_ERR;\n\t\t}\n\n\t\t \n\t\tskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_ON);\n\t\tpci_read_config_dword(hw->pdev, PCI_DEV_REG1, &reg);\n\t\treg &= ~PCI_PHY_COMA;\n\t\tpci_write_config_dword(hw->pdev, PCI_DEV_REG1, reg);\n\t\tskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_OFF);\n\n\n\t\tfor (i = 0; i < hw->ports; i++) {\n\t\t\tskge_write16(hw, SK_REG(i, GMAC_LINK_CTRL), GMLC_RST_SET);\n\t\t\tskge_write16(hw, SK_REG(i, GMAC_LINK_CTRL), GMLC_RST_CLR);\n\t\t}\n\t}\n\n\t \n\tskge_write8(hw, B2_TI_CTRL, TIM_STOP);\n\tskge_write8(hw, B2_TI_CTRL, TIM_CLR_IRQ);\n\tskge_write8(hw, B0_LED, LED_STAT_ON);\n\n\t \n\tfor (i = 0; i < hw->ports; i++)\n\t\tskge_write8(hw, SK_REG(i, TXA_CTRL), TXA_ENA_ARB);\n\n\t \n\tskge_write16(hw, B3_RI_CTRL, RI_RST_CLR);\n\n\tskge_write8(hw, B3_RI_WTO_R1, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_WTO_XA1, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_WTO_XS1, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_RTO_R1, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_RTO_XA1, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_RTO_XS1, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_WTO_R2, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_WTO_XA2, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_WTO_XS2, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_RTO_R2, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_RTO_XA2, SK_RI_TO_53);\n\tskge_write8(hw, B3_RI_RTO_XS2, SK_RI_TO_53);\n\n\tskge_write32(hw, B0_HWE_IMSK, IS_ERR_MSK);\n\n\t \n\tskge_write32(hw, B2_IRQM_MSK, IS_XA1_F|IS_XA2_F);\n\tskge_write32(hw, B2_IRQM_INI, skge_usecs2clk(hw, 100));\n\tskge_write32(hw, B2_IRQM_CTRL, TIM_START);\n\n\t \n\tskge_write32(hw, B0_IMSK, 0);\n\n\tfor (i = 0; i < hw->ports; i++) {\n\t\tif (is_genesis(hw))\n\t\t\tgenesis_reset(hw, i);\n\t\telse\n\t\t\tyukon_reset(hw, i);\n\t}\n\n\treturn 0;\n}\n\n\n#ifdef CONFIG_SKGE_DEBUG\n\nstatic struct dentry *skge_debug;\n\nstatic int skge_debug_show(struct seq_file *seq, void *v)\n{\n\tstruct net_device *dev = seq->private;\n\tconst struct skge_port *skge = netdev_priv(dev);\n\tconst struct skge_hw *hw = skge->hw;\n\tconst struct skge_element *e;\n\n\tif (!netif_running(dev))\n\t\treturn -ENETDOWN;\n\n\tseq_printf(seq, \"IRQ src=%x mask=%x\\n\", skge_read32(hw, B0_ISRC),\n\t\t   skge_read32(hw, B0_IMSK));\n\n\tseq_printf(seq, \"Tx Ring: (%d)\\n\", skge_avail(&skge->tx_ring));\n\tfor (e = skge->tx_ring.to_clean; e != skge->tx_ring.to_use; e = e->next) {\n\t\tconst struct skge_tx_desc *t = e->desc;\n\t\tseq_printf(seq, \"%#x dma=%#x%08x %#x csum=%#x/%x/%x\\n\",\n\t\t\t   t->control, t->dma_hi, t->dma_lo, t->status,\n\t\t\t   t->csum_offs, t->csum_write, t->csum_start);\n\t}\n\n\tseq_puts(seq, \"\\nRx Ring:\\n\");\n\tfor (e = skge->rx_ring.to_clean; ; e = e->next) {\n\t\tconst struct skge_rx_desc *r = e->desc;\n\n\t\tif (r->control & BMU_OWN)\n\t\t\tbreak;\n\n\t\tseq_printf(seq, \"%#x dma=%#x%08x %#x %#x csum=%#x/%x\\n\",\n\t\t\t   r->control, r->dma_hi, r->dma_lo, r->status,\n\t\t\t   r->timestamp, r->csum1, r->csum1_start);\n\t}\n\n\treturn 0;\n}\nDEFINE_SHOW_ATTRIBUTE(skge_debug);\n\n \nstatic int skge_device_event(struct notifier_block *unused,\n\t\t\t     unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct skge_port *skge;\n\n\tif (dev->netdev_ops->ndo_open != &skge_up || !skge_debug)\n\t\tgoto done;\n\n\tskge = netdev_priv(dev);\n\tswitch (event) {\n\tcase NETDEV_CHANGENAME:\n\t\tif (skge->debugfs)\n\t\t\tskge->debugfs = debugfs_rename(skge_debug,\n\t\t\t\t\t\t       skge->debugfs,\n\t\t\t\t\t\t       skge_debug, dev->name);\n\t\tbreak;\n\n\tcase NETDEV_GOING_DOWN:\n\t\tdebugfs_remove(skge->debugfs);\n\t\tskge->debugfs = NULL;\n\t\tbreak;\n\n\tcase NETDEV_UP:\n\t\tskge->debugfs = debugfs_create_file(dev->name, 0444, skge_debug,\n\t\t\t\t\t\t    dev, &skge_debug_fops);\n\t\tbreak;\n\t}\n\ndone:\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block skge_notifier = {\n\t.notifier_call = skge_device_event,\n};\n\n\nstatic __init void skge_debug_init(void)\n{\n\tskge_debug = debugfs_create_dir(\"skge\", NULL);\n\n\tregister_netdevice_notifier(&skge_notifier);\n}\n\nstatic __exit void skge_debug_cleanup(void)\n{\n\tif (skge_debug) {\n\t\tunregister_netdevice_notifier(&skge_notifier);\n\t\tdebugfs_remove(skge_debug);\n\t\tskge_debug = NULL;\n\t}\n}\n\n#else\n#define skge_debug_init()\n#define skge_debug_cleanup()\n#endif\n\nstatic const struct net_device_ops skge_netdev_ops = {\n\t.ndo_open\t\t= skge_up,\n\t.ndo_stop\t\t= skge_down,\n\t.ndo_start_xmit\t\t= skge_xmit_frame,\n\t.ndo_eth_ioctl\t\t= skge_ioctl,\n\t.ndo_get_stats\t\t= skge_get_stats,\n\t.ndo_tx_timeout\t\t= skge_tx_timeout,\n\t.ndo_change_mtu\t\t= skge_change_mtu,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_rx_mode\t= skge_set_multicast,\n\t.ndo_set_mac_address\t= skge_set_mac_address,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= skge_netpoll,\n#endif\n};\n\n\n \nstatic struct net_device *skge_devinit(struct skge_hw *hw, int port,\n\t\t\t\t       int highmem)\n{\n\tstruct skge_port *skge;\n\tstruct net_device *dev = alloc_etherdev(sizeof(*skge));\n\tu8 addr[ETH_ALEN];\n\n\tif (!dev)\n\t\treturn NULL;\n\n\tSET_NETDEV_DEV(dev, &hw->pdev->dev);\n\tdev->netdev_ops = &skge_netdev_ops;\n\tdev->ethtool_ops = &skge_ethtool_ops;\n\tdev->watchdog_timeo = TX_WATCHDOG;\n\tdev->irq = hw->pdev->irq;\n\n\t \n\tdev->min_mtu = ETH_ZLEN;\n\tdev->max_mtu = ETH_JUMBO_MTU;\n\n\tif (highmem)\n\t\tdev->features |= NETIF_F_HIGHDMA;\n\n\tskge = netdev_priv(dev);\n\tnetif_napi_add(dev, &skge->napi, skge_poll);\n\tskge->netdev = dev;\n\tskge->hw = hw;\n\tskge->msg_enable = netif_msg_init(debug, default_msg);\n\n\tskge->tx_ring.count = DEFAULT_TX_RING_SIZE;\n\tskge->rx_ring.count = DEFAULT_RX_RING_SIZE;\n\n\t \n\tskge->autoneg = AUTONEG_ENABLE;\n\tskge->flow_control = FLOW_MODE_SYM_OR_REM;\n\tskge->duplex = -1;\n\tskge->speed = -1;\n\tskge->advertising = skge_supported_modes(hw);\n\n\tif (device_can_wakeup(&hw->pdev->dev)) {\n\t\tskge->wol = wol_supported(hw) & WAKE_MAGIC;\n\t\tdevice_set_wakeup_enable(&hw->pdev->dev, skge->wol);\n\t}\n\n\thw->dev[port] = dev;\n\n\tskge->port = port;\n\n\t \n\tif (is_genesis(hw))\n\t\ttimer_setup(&skge->link_timer, xm_link_timer, 0);\n\telse {\n\t\tdev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG |\n\t\t                   NETIF_F_RXCSUM;\n\t\tdev->features |= dev->hw_features;\n\t}\n\n\t \n\tmemcpy_fromio(addr, hw->regs + B2_MAC_1 + port*8, ETH_ALEN);\n\teth_hw_addr_set(dev, addr);\n\n\treturn dev;\n}\n\nstatic void skge_show_addr(struct net_device *dev)\n{\n\tconst struct skge_port *skge = netdev_priv(dev);\n\n\tnetif_info(skge, probe, skge->netdev, \"addr %pM\\n\", dev->dev_addr);\n}\n\nstatic int only_32bit_dma;\n\nstatic int skge_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct net_device *dev, *dev1;\n\tstruct skge_hw *hw;\n\tint err, using_dac = 0;\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"cannot enable PCI device\\n\");\n\t\tgoto err_out;\n\t}\n\n\terr = pci_request_regions(pdev, DRV_NAME);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"cannot obtain PCI resources\\n\");\n\t\tgoto err_out_disable_pdev;\n\t}\n\n\tpci_set_master(pdev);\n\n\tif (!only_32bit_dma && !dma_set_mask(&pdev->dev, DMA_BIT_MASK(64))) {\n\t\tusing_dac = 1;\n\t\terr = dma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(64));\n\t} else if (!(err = dma_set_mask(&pdev->dev, DMA_BIT_MASK(32)))) {\n\t\tusing_dac = 0;\n\t\terr = dma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(32));\n\t}\n\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"no usable DMA configuration\\n\");\n\t\tgoto err_out_free_regions;\n\t}\n\n#ifdef __BIG_ENDIAN\n\t \n\t{\n\t\tu32 reg;\n\n\t\tpci_read_config_dword(pdev, PCI_DEV_REG2, &reg);\n\t\treg |= PCI_REV_DESC;\n\t\tpci_write_config_dword(pdev, PCI_DEV_REG2, reg);\n\t}\n#endif\n\n\terr = -ENOMEM;\n\t \n\thw = kzalloc(sizeof(*hw) + strlen(DRV_NAME \"@pci:\")\n\t\t     + strlen(pci_name(pdev)) + 1, GFP_KERNEL);\n\tif (!hw)\n\t\tgoto err_out_free_regions;\n\n\tsprintf(hw->irq_name, DRV_NAME \"@pci:%s\", pci_name(pdev));\n\n\thw->pdev = pdev;\n\tspin_lock_init(&hw->hw_lock);\n\tspin_lock_init(&hw->phy_lock);\n\ttasklet_setup(&hw->phy_task, skge_extirq);\n\n\thw->regs = ioremap(pci_resource_start(pdev, 0), 0x4000);\n\tif (!hw->regs) {\n\t\tdev_err(&pdev->dev, \"cannot map device registers\\n\");\n\t\tgoto err_out_free_hw;\n\t}\n\n\terr = skge_reset(hw);\n\tif (err)\n\t\tgoto err_out_iounmap;\n\n\tpr_info(\"%s addr 0x%llx irq %d chip %s rev %d\\n\",\n\t\tDRV_VERSION,\n\t\t(unsigned long long)pci_resource_start(pdev, 0), pdev->irq,\n\t\tskge_board_name(hw), hw->chip_rev);\n\n\tdev = skge_devinit(hw, 0, using_dac);\n\tif (!dev) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out_led_off;\n\t}\n\n\t \n\tif (!is_valid_ether_addr(dev->dev_addr))\n\t\tdev_warn(&pdev->dev, \"bad (zero?) ethernet address in rom\\n\");\n\n\terr = register_netdev(dev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"cannot register net device\\n\");\n\t\tgoto err_out_free_netdev;\n\t}\n\n\tskge_show_addr(dev);\n\n\tif (hw->ports > 1) {\n\t\tdev1 = skge_devinit(hw, 1, using_dac);\n\t\tif (!dev1) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out_unregister;\n\t\t}\n\n\t\terr = register_netdev(dev1);\n\t\tif (err) {\n\t\t\tdev_err(&pdev->dev, \"cannot register second net device\\n\");\n\t\t\tgoto err_out_free_dev1;\n\t\t}\n\n\t\terr = request_irq(pdev->irq, skge_intr, IRQF_SHARED,\n\t\t\t\t  hw->irq_name, hw);\n\t\tif (err) {\n\t\t\tdev_err(&pdev->dev, \"cannot assign irq %d\\n\",\n\t\t\t\tpdev->irq);\n\t\t\tgoto err_out_unregister_dev1;\n\t\t}\n\n\t\tskge_show_addr(dev1);\n\t}\n\tpci_set_drvdata(pdev, hw);\n\n\treturn 0;\n\nerr_out_unregister_dev1:\n\tunregister_netdev(dev1);\nerr_out_free_dev1:\n\tfree_netdev(dev1);\nerr_out_unregister:\n\tunregister_netdev(dev);\nerr_out_free_netdev:\n\tfree_netdev(dev);\nerr_out_led_off:\n\tskge_write16(hw, B0_LED, LED_STAT_OFF);\nerr_out_iounmap:\n\tiounmap(hw->regs);\nerr_out_free_hw:\n\tkfree(hw);\nerr_out_free_regions:\n\tpci_release_regions(pdev);\nerr_out_disable_pdev:\n\tpci_disable_device(pdev);\nerr_out:\n\treturn err;\n}\n\nstatic void skge_remove(struct pci_dev *pdev)\n{\n\tstruct skge_hw *hw  = pci_get_drvdata(pdev);\n\tstruct net_device *dev0, *dev1;\n\n\tif (!hw)\n\t\treturn;\n\n\tdev1 = hw->dev[1];\n\tif (dev1)\n\t\tunregister_netdev(dev1);\n\tdev0 = hw->dev[0];\n\tunregister_netdev(dev0);\n\n\ttasklet_kill(&hw->phy_task);\n\n\tspin_lock_irq(&hw->hw_lock);\n\thw->intr_mask = 0;\n\n\tif (hw->ports > 1) {\n\t\tskge_write32(hw, B0_IMSK, 0);\n\t\tskge_read32(hw, B0_IMSK);\n\t}\n\tspin_unlock_irq(&hw->hw_lock);\n\n\tskge_write16(hw, B0_LED, LED_STAT_OFF);\n\tskge_write8(hw, B0_CTST, CS_RST_SET);\n\n\tif (hw->ports > 1)\n\t\tfree_irq(pdev->irq, hw);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\tif (dev1)\n\t\tfree_netdev(dev1);\n\tfree_netdev(dev0);\n\n\tiounmap(hw->regs);\n\tkfree(hw);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int skge_suspend(struct device *dev)\n{\n\tstruct skge_hw *hw  = dev_get_drvdata(dev);\n\tint i;\n\n\tif (!hw)\n\t\treturn 0;\n\n\tfor (i = 0; i < hw->ports; i++) {\n\t\tstruct net_device *dev = hw->dev[i];\n\t\tstruct skge_port *skge = netdev_priv(dev);\n\n\t\tif (netif_running(dev))\n\t\t\tskge_down(dev);\n\n\t\tif (skge->wol)\n\t\t\tskge_wol_init(skge);\n\t}\n\n\tskge_write32(hw, B0_IMSK, 0);\n\n\treturn 0;\n}\n\nstatic int skge_resume(struct device *dev)\n{\n\tstruct skge_hw *hw  = dev_get_drvdata(dev);\n\tint i, err;\n\n\tif (!hw)\n\t\treturn 0;\n\n\terr = skge_reset(hw);\n\tif (err)\n\t\tgoto out;\n\n\tfor (i = 0; i < hw->ports; i++) {\n\t\tstruct net_device *dev = hw->dev[i];\n\n\t\tif (netif_running(dev)) {\n\t\t\terr = skge_up(dev);\n\n\t\t\tif (err) {\n\t\t\t\tnetdev_err(dev, \"could not up: %d\\n\", err);\n\t\t\t\tdev_close(dev);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\nout:\n\treturn err;\n}\n\nstatic SIMPLE_DEV_PM_OPS(skge_pm_ops, skge_suspend, skge_resume);\n#define SKGE_PM_OPS (&skge_pm_ops)\n\n#else\n\n#define SKGE_PM_OPS NULL\n#endif  \n\nstatic void skge_shutdown(struct pci_dev *pdev)\n{\n\tstruct skge_hw *hw  = pci_get_drvdata(pdev);\n\tint i;\n\n\tif (!hw)\n\t\treturn;\n\n\tfor (i = 0; i < hw->ports; i++) {\n\t\tstruct net_device *dev = hw->dev[i];\n\t\tstruct skge_port *skge = netdev_priv(dev);\n\n\t\tif (skge->wol)\n\t\t\tskge_wol_init(skge);\n\t}\n\n\tpci_wake_from_d3(pdev, device_may_wakeup(&pdev->dev));\n\tpci_set_power_state(pdev, PCI_D3hot);\n}\n\nstatic struct pci_driver skge_driver = {\n\t.name =         DRV_NAME,\n\t.id_table =     skge_id_table,\n\t.probe =        skge_probe,\n\t.remove =       skge_remove,\n\t.shutdown =\tskge_shutdown,\n\t.driver.pm =\tSKGE_PM_OPS,\n};\n\nstatic const struct dmi_system_id skge_32bit_dma_boards[] = {\n\t{\n\t\t.ident = \"Gigabyte nForce boards\",\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_BOARD_VENDOR, \"Gigabyte Technology Co\"),\n\t\t\tDMI_MATCH(DMI_BOARD_NAME, \"nForce\"),\n\t\t},\n\t},\n\t{\n\t\t.ident = \"ASUS P5NSLI\",\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_BOARD_VENDOR, \"ASUSTeK Computer INC.\"),\n\t\t\tDMI_MATCH(DMI_BOARD_NAME, \"P5NSLI\")\n\t\t},\n\t},\n\t{\n\t\t.ident = \"FUJITSU SIEMENS A8NE-FM\",\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_BOARD_VENDOR, \"ASUSTek Computer INC.\"),\n\t\t\tDMI_MATCH(DMI_BOARD_NAME, \"A8NE-FM\")\n\t\t},\n\t},\n\t{}\n};\n\nstatic int __init skge_init_module(void)\n{\n\tif (dmi_check_system(skge_32bit_dma_boards))\n\t\tonly_32bit_dma = 1;\n\tskge_debug_init();\n\treturn pci_register_driver(&skge_driver);\n}\n\nstatic void __exit skge_cleanup_module(void)\n{\n\tpci_unregister_driver(&skge_driver);\n\tskge_debug_cleanup();\n}\n\nmodule_init(skge_init_module);\nmodule_exit(skge_cleanup_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}