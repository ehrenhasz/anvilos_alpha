{
  "module_name": "prestera_rxtx.c",
  "hash_id": "75d2c76243c564e31eb2a4f5df5d25fa44a5a683017d825012f5af870620e87a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/dmapool.h>\n#include <linux/etherdevice.h>\n#include <linux/if_vlan.h>\n#include <linux/platform_device.h>\n\n#include \"prestera_dsa.h\"\n#include \"prestera.h\"\n#include \"prestera_hw.h\"\n#include \"prestera_rxtx.h\"\n#include \"prestera_devlink.h\"\n\n#define PRESTERA_SDMA_WAIT_MUL\t\t10\n\nstruct prestera_sdma_desc {\n\t__le32 word1;\n\t__le32 word2;\n\t__le32 buff;\n\t__le32 next;\n} __packed __aligned(16);\n\n#define PRESTERA_SDMA_BUFF_SIZE_MAX\t1544\n\n#define PRESTERA_SDMA_RX_DESC_PKT_LEN(desc) \\\n\t((le32_to_cpu((desc)->word2) >> 16) & GENMASK(13, 0))\n\n#define PRESTERA_SDMA_RX_DESC_OWNER(desc) \\\n\t((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)\n\n#define PRESTERA_SDMA_RX_DESC_IS_RCVD(desc) \\\n\t(PRESTERA_SDMA_RX_DESC_OWNER(desc) == PRESTERA_SDMA_RX_DESC_CPU_OWN)\n\n#define PRESTERA_SDMA_RX_DESC_CPU_OWN\t0\n#define PRESTERA_SDMA_RX_DESC_DMA_OWN\t1\n\n#define PRESTERA_SDMA_RX_QUEUE_NUM\t8\n\n#define PRESTERA_SDMA_RX_DESC_PER_Q\t1000\n\n#define PRESTERA_SDMA_TX_DESC_PER_Q\t1000\n#define PRESTERA_SDMA_TX_MAX_BURST\t64\n\n#define PRESTERA_SDMA_TX_DESC_OWNER(desc) \\\n\t((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)\n\n#define PRESTERA_SDMA_TX_DESC_CPU_OWN\t0\n#define PRESTERA_SDMA_TX_DESC_DMA_OWN\t1U\n\n#define PRESTERA_SDMA_TX_DESC_IS_SENT(desc) \\\n\t(PRESTERA_SDMA_TX_DESC_OWNER(desc) == PRESTERA_SDMA_TX_DESC_CPU_OWN)\n\n#define PRESTERA_SDMA_TX_DESC_LAST\tBIT(20)\n#define PRESTERA_SDMA_TX_DESC_FIRST\tBIT(21)\n#define PRESTERA_SDMA_TX_DESC_CALC_CRC\tBIT(12)\n\n#define PRESTERA_SDMA_TX_DESC_SINGLE\t\\\n\t(PRESTERA_SDMA_TX_DESC_FIRST | PRESTERA_SDMA_TX_DESC_LAST)\n\n#define PRESTERA_SDMA_TX_DESC_INIT\t\\\n\t(PRESTERA_SDMA_TX_DESC_SINGLE | PRESTERA_SDMA_TX_DESC_CALC_CRC)\n\n#define PRESTERA_SDMA_RX_INTR_MASK_REG\t\t0x2814\n#define PRESTERA_SDMA_RX_QUEUE_STATUS_REG\t0x2680\n#define PRESTERA_SDMA_RX_QUEUE_DESC_REG(n)\t(0x260C + (n) * 16)\n\n#define PRESTERA_SDMA_TX_QUEUE_DESC_REG\t\t0x26C0\n#define PRESTERA_SDMA_TX_QUEUE_START_REG\t0x2868\n\nstruct prestera_sdma_buf {\n\tstruct prestera_sdma_desc *desc;\n\tdma_addr_t desc_dma;\n\tstruct sk_buff *skb;\n\tdma_addr_t buf_dma;\n\tbool is_used;\n};\n\nstruct prestera_rx_ring {\n\tstruct prestera_sdma_buf *bufs;\n\tint next_rx;\n};\n\nstruct prestera_tx_ring {\n\tstruct prestera_sdma_buf *bufs;\n\tint next_tx;\n\tint max_burst;\n\tint burst;\n};\n\nstruct prestera_sdma {\n\tstruct prestera_rx_ring rx_ring[PRESTERA_SDMA_RX_QUEUE_NUM];\n\tstruct prestera_tx_ring tx_ring;\n\tstruct prestera_switch *sw;\n\tstruct dma_pool *desc_pool;\n\tstruct work_struct tx_work;\n\tstruct napi_struct rx_napi;\n\tstruct net_device napi_dev;\n\tu32 map_addr;\n\tu64 dma_mask;\n\t \n\tspinlock_t tx_lock;\n};\n\nstruct prestera_rxtx {\n\tstruct prestera_sdma sdma;\n};\n\nstatic int prestera_sdma_buf_init(struct prestera_sdma *sdma,\n\t\t\t\t  struct prestera_sdma_buf *buf)\n{\n\tstruct prestera_sdma_desc *desc;\n\tdma_addr_t dma;\n\n\tdesc = dma_pool_alloc(sdma->desc_pool, GFP_DMA | GFP_KERNEL, &dma);\n\tif (!desc)\n\t\treturn -ENOMEM;\n\n\tbuf->buf_dma = DMA_MAPPING_ERROR;\n\tbuf->desc_dma = dma;\n\tbuf->desc = desc;\n\tbuf->skb = NULL;\n\n\treturn 0;\n}\n\nstatic u32 prestera_sdma_map(struct prestera_sdma *sdma, dma_addr_t pa)\n{\n\treturn sdma->map_addr + pa;\n}\n\nstatic void prestera_sdma_rx_desc_init(struct prestera_sdma *sdma,\n\t\t\t\t       struct prestera_sdma_desc *desc,\n\t\t\t\t       dma_addr_t buf)\n{\n\tu32 word = le32_to_cpu(desc->word2);\n\n\tu32p_replace_bits(&word, PRESTERA_SDMA_BUFF_SIZE_MAX, GENMASK(15, 0));\n\tdesc->word2 = cpu_to_le32(word);\n\n\tdesc->buff = cpu_to_le32(prestera_sdma_map(sdma, buf));\n\n\t \n\twmb();\n\n\tdesc->word1 = cpu_to_le32(0xA0000000);\n}\n\nstatic void prestera_sdma_rx_desc_set_next(struct prestera_sdma *sdma,\n\t\t\t\t\t   struct prestera_sdma_desc *desc,\n\t\t\t\t\t   dma_addr_t next)\n{\n\tdesc->next = cpu_to_le32(prestera_sdma_map(sdma, next));\n}\n\nstatic int prestera_sdma_rx_skb_alloc(struct prestera_sdma *sdma,\n\t\t\t\t      struct prestera_sdma_buf *buf)\n{\n\tstruct device *dev = sdma->sw->dev->dev;\n\tstruct sk_buff *skb;\n\tdma_addr_t dma;\n\n\tskb = alloc_skb(PRESTERA_SDMA_BUFF_SIZE_MAX, GFP_DMA | GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tdma = dma_map_single(dev, skb->data, skb->len, DMA_FROM_DEVICE);\n\tif (dma_mapping_error(dev, dma))\n\t\tgoto err_dma_map;\n\n\tif (buf->skb)\n\t\tdma_unmap_single(dev, buf->buf_dma, buf->skb->len,\n\t\t\t\t DMA_FROM_DEVICE);\n\n\tbuf->buf_dma = dma;\n\tbuf->skb = skb;\n\n\treturn 0;\n\nerr_dma_map:\n\tkfree_skb(skb);\n\n\treturn -ENOMEM;\n}\n\nstatic struct sk_buff *prestera_sdma_rx_skb_get(struct prestera_sdma *sdma,\n\t\t\t\t\t\tstruct prestera_sdma_buf *buf)\n{\n\tdma_addr_t buf_dma = buf->buf_dma;\n\tstruct sk_buff *skb = buf->skb;\n\tu32 len = skb->len;\n\tint err;\n\n\terr = prestera_sdma_rx_skb_alloc(sdma, buf);\n\tif (err) {\n\t\tbuf->buf_dma = buf_dma;\n\t\tbuf->skb = skb;\n\n\t\tskb = alloc_skb(skb->len, GFP_ATOMIC);\n\t\tif (skb) {\n\t\t\tskb_put(skb, len);\n\t\t\tskb_copy_from_linear_data(buf->skb, skb->data, len);\n\t\t}\n\t}\n\n\tprestera_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);\n\n\treturn skb;\n}\n\nstatic int prestera_rxtx_process_skb(struct prestera_sdma *sdma,\n\t\t\t\t     struct sk_buff *skb)\n{\n\tstruct prestera_port *port;\n\tstruct prestera_dsa dsa;\n\tu32 hw_port, dev_id;\n\tu8 cpu_code;\n\tint err;\n\n\tskb_pull(skb, ETH_HLEN);\n\n\t \n\terr = prestera_dsa_parse(&dsa, skb->data - ETH_TLEN);\n\tif (err)\n\t\treturn err;\n\n\tdev_id = dsa.hw_dev_num;\n\thw_port = dsa.port_num;\n\n\tport = prestera_port_find_by_hwid(sdma->sw, dev_id, hw_port);\n\tif (unlikely(!port)) {\n\t\tdev_warn_ratelimited(prestera_dev(sdma->sw), \"received pkt for non-existent port(%u, %u)\\n\",\n\t\t\t\t     dev_id, hw_port);\n\t\treturn -ENOENT;\n\t}\n\n\tif (unlikely(!pskb_may_pull(skb, PRESTERA_DSA_HLEN)))\n\t\treturn -EINVAL;\n\n\t \n\tskb_pull_rcsum(skb, PRESTERA_DSA_HLEN);\n\n\tmemmove(skb->data - ETH_HLEN, skb->data - ETH_HLEN - PRESTERA_DSA_HLEN,\n\t\tETH_ALEN * 2);\n\n\tskb_push(skb, ETH_HLEN);\n\n\tskb->protocol = eth_type_trans(skb, port->dev);\n\n\tif (dsa.vlan.is_tagged) {\n\t\tu16 tci = dsa.vlan.vid & VLAN_VID_MASK;\n\n\t\ttci |= dsa.vlan.vpt << VLAN_PRIO_SHIFT;\n\t\tif (dsa.vlan.cfi_bit)\n\t\t\ttci |= VLAN_CFI_MASK;\n\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), tci);\n\t}\n\n\tcpu_code = dsa.cpu_code;\n\tprestera_devlink_trap_report(port, skb, cpu_code);\n\n\treturn 0;\n}\n\nstatic int prestera_sdma_next_rx_buf_idx(int buf_idx)\n{\n\treturn (buf_idx + 1) % PRESTERA_SDMA_RX_DESC_PER_Q;\n}\n\nstatic int prestera_sdma_rx_poll(struct napi_struct *napi, int budget)\n{\n\tint qnum = PRESTERA_SDMA_RX_QUEUE_NUM;\n\tunsigned int rxq_done_map = 0;\n\tstruct prestera_sdma *sdma;\n\tstruct list_head rx_list;\n\tunsigned int qmask;\n\tint pkts_done = 0;\n\tint q;\n\n\tqnum = PRESTERA_SDMA_RX_QUEUE_NUM;\n\tqmask = GENMASK(qnum - 1, 0);\n\n\tINIT_LIST_HEAD(&rx_list);\n\n\tsdma = container_of(napi, struct prestera_sdma, rx_napi);\n\n\twhile (pkts_done < budget && rxq_done_map != qmask) {\n\t\tfor (q = 0; q < qnum && pkts_done < budget; q++) {\n\t\t\tstruct prestera_rx_ring *ring = &sdma->rx_ring[q];\n\t\t\tstruct prestera_sdma_desc *desc;\n\t\t\tstruct prestera_sdma_buf *buf;\n\t\t\tint buf_idx = ring->next_rx;\n\t\t\tstruct sk_buff *skb;\n\n\t\t\tbuf = &ring->bufs[buf_idx];\n\t\t\tdesc = buf->desc;\n\n\t\t\tif (PRESTERA_SDMA_RX_DESC_IS_RCVD(desc)) {\n\t\t\t\trxq_done_map &= ~BIT(q);\n\t\t\t} else {\n\t\t\t\trxq_done_map |= BIT(q);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tpkts_done++;\n\n\t\t\t__skb_trim(buf->skb, PRESTERA_SDMA_RX_DESC_PKT_LEN(desc));\n\n\t\t\tskb = prestera_sdma_rx_skb_get(sdma, buf);\n\t\t\tif (!skb)\n\t\t\t\tgoto rx_next_buf;\n\n\t\t\tif (unlikely(prestera_rxtx_process_skb(sdma, skb)))\n\t\t\t\tgoto rx_next_buf;\n\n\t\t\tlist_add_tail(&skb->list, &rx_list);\nrx_next_buf:\n\t\t\tring->next_rx = prestera_sdma_next_rx_buf_idx(buf_idx);\n\t\t}\n\t}\n\n\tif (pkts_done < budget && napi_complete_done(napi, pkts_done))\n\t\tprestera_write(sdma->sw, PRESTERA_SDMA_RX_INTR_MASK_REG,\n\t\t\t       GENMASK(9, 2));\n\n\tnetif_receive_skb_list(&rx_list);\n\n\treturn pkts_done;\n}\n\nstatic void prestera_sdma_rx_fini(struct prestera_sdma *sdma)\n{\n\tint qnum = PRESTERA_SDMA_RX_QUEUE_NUM;\n\tint q, b;\n\n\t \n\tprestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_STATUS_REG,\n\t\t       GENMASK(15, 8));\n\n\tfor (q = 0; q < qnum; q++) {\n\t\tstruct prestera_rx_ring *ring = &sdma->rx_ring[q];\n\n\t\tif (!ring->bufs)\n\t\t\tbreak;\n\n\t\tfor (b = 0; b < PRESTERA_SDMA_RX_DESC_PER_Q; b++) {\n\t\t\tstruct prestera_sdma_buf *buf = &ring->bufs[b];\n\n\t\t\tif (buf->desc_dma)\n\t\t\t\tdma_pool_free(sdma->desc_pool, buf->desc,\n\t\t\t\t\t      buf->desc_dma);\n\n\t\t\tif (!buf->skb)\n\t\t\t\tcontinue;\n\n\t\t\tif (buf->buf_dma != DMA_MAPPING_ERROR)\n\t\t\t\tdma_unmap_single(sdma->sw->dev->dev,\n\t\t\t\t\t\t buf->buf_dma, buf->skb->len,\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tkfree_skb(buf->skb);\n\t\t}\n\t}\n}\n\nstatic int prestera_sdma_rx_init(struct prestera_sdma *sdma)\n{\n\tint bnum = PRESTERA_SDMA_RX_DESC_PER_Q;\n\tint qnum = PRESTERA_SDMA_RX_QUEUE_NUM;\n\tint err;\n\tint q;\n\n\t \n\tprestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_STATUS_REG,\n\t\t       GENMASK(15, 8));\n\n\tfor (q = 0; q < qnum; q++) {\n\t\tstruct prestera_sdma_buf *head, *tail, *next, *prev;\n\t\tstruct prestera_rx_ring *ring = &sdma->rx_ring[q];\n\n\t\tring->bufs = kmalloc_array(bnum, sizeof(*head), GFP_KERNEL);\n\t\tif (!ring->bufs)\n\t\t\treturn -ENOMEM;\n\n\t\tring->next_rx = 0;\n\n\t\ttail = &ring->bufs[bnum - 1];\n\t\thead = &ring->bufs[0];\n\t\tnext = head;\n\t\tprev = next;\n\n\t\tdo {\n\t\t\terr = prestera_sdma_buf_init(sdma, next);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\terr = prestera_sdma_rx_skb_alloc(sdma, next);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\tprestera_sdma_rx_desc_init(sdma, next->desc,\n\t\t\t\t\t\t   next->buf_dma);\n\n\t\t\tprestera_sdma_rx_desc_set_next(sdma, prev->desc,\n\t\t\t\t\t\t       next->desc_dma);\n\n\t\t\tprev = next;\n\t\t\tnext++;\n\t\t} while (prev != tail);\n\n\t\t \n\t\tprestera_sdma_rx_desc_set_next(sdma, tail->desc, head->desc_dma);\n\n\t\tprestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_DESC_REG(q),\n\t\t\t       prestera_sdma_map(sdma, head->desc_dma));\n\t}\n\n\t \n\twmb();\n\n\tprestera_write(sdma->sw, PRESTERA_SDMA_RX_QUEUE_STATUS_REG,\n\t\t       GENMASK(7, 0));\n\n\treturn 0;\n}\n\nstatic void prestera_sdma_tx_desc_init(struct prestera_sdma *sdma,\n\t\t\t\t       struct prestera_sdma_desc *desc)\n{\n\tdesc->word1 = cpu_to_le32(PRESTERA_SDMA_TX_DESC_INIT);\n\tdesc->word2 = 0;\n}\n\nstatic void prestera_sdma_tx_desc_set_next(struct prestera_sdma *sdma,\n\t\t\t\t\t   struct prestera_sdma_desc *desc,\n\t\t\t\t\t   dma_addr_t next)\n{\n\tdesc->next = cpu_to_le32(prestera_sdma_map(sdma, next));\n}\n\nstatic void prestera_sdma_tx_desc_set_buf(struct prestera_sdma *sdma,\n\t\t\t\t\t  struct prestera_sdma_desc *desc,\n\t\t\t\t\t  dma_addr_t buf, size_t len)\n{\n\tu32 word = le32_to_cpu(desc->word2);\n\n\tu32p_replace_bits(&word, len + ETH_FCS_LEN, GENMASK(30, 16));\n\n\tdesc->buff = cpu_to_le32(prestera_sdma_map(sdma, buf));\n\tdesc->word2 = cpu_to_le32(word);\n}\n\nstatic void prestera_sdma_tx_desc_xmit(struct prestera_sdma_desc *desc)\n{\n\tu32 word = le32_to_cpu(desc->word1);\n\n\tword |= PRESTERA_SDMA_TX_DESC_DMA_OWN << 31;\n\n\t \n\twmb();\n\n\tdesc->word1 = cpu_to_le32(word);\n}\n\nstatic int prestera_sdma_tx_buf_map(struct prestera_sdma *sdma,\n\t\t\t\t    struct prestera_sdma_buf *buf,\n\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct device *dma_dev = sdma->sw->dev->dev;\n\tdma_addr_t dma;\n\n\tdma = dma_map_single(dma_dev, skb->data, skb->len, DMA_TO_DEVICE);\n\tif (dma_mapping_error(dma_dev, dma))\n\t\treturn -ENOMEM;\n\n\tbuf->buf_dma = dma;\n\tbuf->skb = skb;\n\n\treturn 0;\n}\n\nstatic void prestera_sdma_tx_buf_unmap(struct prestera_sdma *sdma,\n\t\t\t\t       struct prestera_sdma_buf *buf)\n{\n\tstruct device *dma_dev = sdma->sw->dev->dev;\n\n\tdma_unmap_single(dma_dev, buf->buf_dma, buf->skb->len, DMA_TO_DEVICE);\n}\n\nstatic void prestera_sdma_tx_recycle_work_fn(struct work_struct *work)\n{\n\tint bnum = PRESTERA_SDMA_TX_DESC_PER_Q;\n\tstruct prestera_tx_ring *tx_ring;\n\tstruct prestera_sdma *sdma;\n\tint b;\n\n\tsdma = container_of(work, struct prestera_sdma, tx_work);\n\n\ttx_ring = &sdma->tx_ring;\n\n\tfor (b = 0; b < bnum; b++) {\n\t\tstruct prestera_sdma_buf *buf = &tx_ring->bufs[b];\n\n\t\tif (!buf->is_used)\n\t\t\tcontinue;\n\n\t\tif (!PRESTERA_SDMA_TX_DESC_IS_SENT(buf->desc))\n\t\t\tcontinue;\n\n\t\tprestera_sdma_tx_buf_unmap(sdma, buf);\n\t\tdev_consume_skb_any(buf->skb);\n\t\tbuf->skb = NULL;\n\n\t\t \n\t\twmb();\n\n\t\tbuf->is_used = false;\n\t}\n}\n\nstatic int prestera_sdma_tx_init(struct prestera_sdma *sdma)\n{\n\tstruct prestera_sdma_buf *head, *tail, *next, *prev;\n\tstruct prestera_tx_ring *tx_ring = &sdma->tx_ring;\n\tint bnum = PRESTERA_SDMA_TX_DESC_PER_Q;\n\tint err;\n\n\tINIT_WORK(&sdma->tx_work, prestera_sdma_tx_recycle_work_fn);\n\tspin_lock_init(&sdma->tx_lock);\n\n\ttx_ring->bufs = kmalloc_array(bnum, sizeof(*head), GFP_KERNEL);\n\tif (!tx_ring->bufs)\n\t\treturn -ENOMEM;\n\n\ttail = &tx_ring->bufs[bnum - 1];\n\thead = &tx_ring->bufs[0];\n\tnext = head;\n\tprev = next;\n\n\ttx_ring->max_burst = PRESTERA_SDMA_TX_MAX_BURST;\n\ttx_ring->burst = tx_ring->max_burst;\n\ttx_ring->next_tx = 0;\n\n\tdo {\n\t\terr = prestera_sdma_buf_init(sdma, next);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tnext->is_used = false;\n\n\t\tprestera_sdma_tx_desc_init(sdma, next->desc);\n\n\t\tprestera_sdma_tx_desc_set_next(sdma, prev->desc,\n\t\t\t\t\t       next->desc_dma);\n\n\t\tprev = next;\n\t\tnext++;\n\t} while (prev != tail);\n\n\t \n\tprestera_sdma_tx_desc_set_next(sdma, tail->desc, head->desc_dma);\n\n\t \n\twmb();\n\n\tprestera_write(sdma->sw, PRESTERA_SDMA_TX_QUEUE_DESC_REG,\n\t\t       prestera_sdma_map(sdma, head->desc_dma));\n\n\treturn 0;\n}\n\nstatic void prestera_sdma_tx_fini(struct prestera_sdma *sdma)\n{\n\tstruct prestera_tx_ring *ring = &sdma->tx_ring;\n\tint bnum = PRESTERA_SDMA_TX_DESC_PER_Q;\n\tint b;\n\n\tcancel_work_sync(&sdma->tx_work);\n\n\tif (!ring->bufs)\n\t\treturn;\n\n\tfor (b = 0; b < bnum; b++) {\n\t\tstruct prestera_sdma_buf *buf = &ring->bufs[b];\n\n\t\tif (buf->desc)\n\t\t\tdma_pool_free(sdma->desc_pool, buf->desc,\n\t\t\t\t      buf->desc_dma);\n\n\t\tif (!buf->skb)\n\t\t\tcontinue;\n\n\t\tdma_unmap_single(sdma->sw->dev->dev, buf->buf_dma,\n\t\t\t\t buf->skb->len, DMA_TO_DEVICE);\n\n\t\tdev_consume_skb_any(buf->skb);\n\t}\n}\n\nstatic void prestera_rxtx_handle_event(struct prestera_switch *sw,\n\t\t\t\t       struct prestera_event *evt,\n\t\t\t\t       void *arg)\n{\n\tstruct prestera_sdma *sdma = arg;\n\n\tif (evt->id != PRESTERA_RXTX_EVENT_RCV_PKT)\n\t\treturn;\n\n\tprestera_write(sdma->sw, PRESTERA_SDMA_RX_INTR_MASK_REG, 0);\n\tnapi_schedule(&sdma->rx_napi);\n}\n\nstatic int prestera_sdma_switch_init(struct prestera_switch *sw)\n{\n\tstruct prestera_sdma *sdma = &sw->rxtx->sdma;\n\tstruct device *dev = sw->dev->dev;\n\tstruct prestera_rxtx_params p;\n\tint err;\n\n\tp.use_sdma = true;\n\n\terr = prestera_hw_rxtx_init(sw, &p);\n\tif (err) {\n\t\tdev_err(dev, \"failed to init rxtx by hw\\n\");\n\t\treturn err;\n\t}\n\n\tsdma->dma_mask = dma_get_mask(dev);\n\tsdma->map_addr = p.map_addr;\n\tsdma->sw = sw;\n\n\tsdma->desc_pool = dma_pool_create(\"desc_pool\", dev,\n\t\t\t\t\t  sizeof(struct prestera_sdma_desc),\n\t\t\t\t\t  16, 0);\n\tif (!sdma->desc_pool)\n\t\treturn -ENOMEM;\n\n\terr = prestera_sdma_rx_init(sdma);\n\tif (err) {\n\t\tdev_err(dev, \"failed to init rx ring\\n\");\n\t\tgoto err_rx_init;\n\t}\n\n\terr = prestera_sdma_tx_init(sdma);\n\tif (err) {\n\t\tdev_err(dev, \"failed to init tx ring\\n\");\n\t\tgoto err_tx_init;\n\t}\n\n\terr = prestera_hw_event_handler_register(sw, PRESTERA_EVENT_TYPE_RXTX,\n\t\t\t\t\t\t prestera_rxtx_handle_event,\n\t\t\t\t\t\t sdma);\n\tif (err)\n\t\tgoto err_evt_register;\n\n\tinit_dummy_netdev(&sdma->napi_dev);\n\n\tnetif_napi_add(&sdma->napi_dev, &sdma->rx_napi, prestera_sdma_rx_poll);\n\tnapi_enable(&sdma->rx_napi);\n\n\treturn 0;\n\nerr_evt_register:\nerr_tx_init:\n\tprestera_sdma_tx_fini(sdma);\nerr_rx_init:\n\tprestera_sdma_rx_fini(sdma);\n\n\tdma_pool_destroy(sdma->desc_pool);\n\treturn err;\n}\n\nstatic void prestera_sdma_switch_fini(struct prestera_switch *sw)\n{\n\tstruct prestera_sdma *sdma = &sw->rxtx->sdma;\n\n\tnapi_disable(&sdma->rx_napi);\n\tnetif_napi_del(&sdma->rx_napi);\n\tprestera_hw_event_handler_unregister(sw, PRESTERA_EVENT_TYPE_RXTX,\n\t\t\t\t\t     prestera_rxtx_handle_event);\n\tprestera_sdma_tx_fini(sdma);\n\tprestera_sdma_rx_fini(sdma);\n\tdma_pool_destroy(sdma->desc_pool);\n}\n\nstatic bool prestera_sdma_is_ready(struct prestera_sdma *sdma)\n{\n\treturn !(prestera_read(sdma->sw, PRESTERA_SDMA_TX_QUEUE_START_REG) & 1);\n}\n\nstatic int prestera_sdma_tx_wait(struct prestera_sdma *sdma,\n\t\t\t\t struct prestera_tx_ring *tx_ring)\n{\n\tint tx_wait_num = PRESTERA_SDMA_WAIT_MUL * tx_ring->max_burst;\n\n\tdo {\n\t\tif (prestera_sdma_is_ready(sdma))\n\t\t\treturn 0;\n\n\t\tudelay(1);\n\t} while (--tx_wait_num);\n\n\treturn -EBUSY;\n}\n\nstatic void prestera_sdma_tx_start(struct prestera_sdma *sdma)\n{\n\tprestera_write(sdma->sw, PRESTERA_SDMA_TX_QUEUE_START_REG, 1);\n\tschedule_work(&sdma->tx_work);\n}\n\nstatic netdev_tx_t prestera_sdma_xmit(struct prestera_sdma *sdma,\n\t\t\t\t      struct sk_buff *skb)\n{\n\tstruct device *dma_dev = sdma->sw->dev->dev;\n\tstruct net_device *dev = skb->dev;\n\tstruct prestera_tx_ring *tx_ring;\n\tstruct prestera_sdma_buf *buf;\n\tint err;\n\n\tspin_lock(&sdma->tx_lock);\n\n\ttx_ring = &sdma->tx_ring;\n\n\tbuf = &tx_ring->bufs[tx_ring->next_tx];\n\tif (buf->is_used) {\n\t\tschedule_work(&sdma->tx_work);\n\t\tgoto drop_skb;\n\t}\n\n\tif (unlikely(eth_skb_pad(skb)))\n\t\tgoto drop_skb_nofree;\n\n\terr = prestera_sdma_tx_buf_map(sdma, buf, skb);\n\tif (err)\n\t\tgoto drop_skb;\n\n\tprestera_sdma_tx_desc_set_buf(sdma, buf->desc, buf->buf_dma, skb->len);\n\n\tdma_sync_single_for_device(dma_dev, buf->buf_dma, skb->len,\n\t\t\t\t   DMA_TO_DEVICE);\n\n\tif (tx_ring->burst) {\n\t\ttx_ring->burst--;\n\t} else {\n\t\ttx_ring->burst = tx_ring->max_burst;\n\n\t\terr = prestera_sdma_tx_wait(sdma, tx_ring);\n\t\tif (err)\n\t\t\tgoto drop_skb_unmap;\n\t}\n\n\ttx_ring->next_tx = (tx_ring->next_tx + 1) % PRESTERA_SDMA_TX_DESC_PER_Q;\n\tprestera_sdma_tx_desc_xmit(buf->desc);\n\tbuf->is_used = true;\n\n\tprestera_sdma_tx_start(sdma);\n\n\tgoto tx_done;\n\ndrop_skb_unmap:\n\tprestera_sdma_tx_buf_unmap(sdma, buf);\ndrop_skb:\n\tdev_consume_skb_any(skb);\ndrop_skb_nofree:\n\tdev->stats.tx_dropped++;\ntx_done:\n\tspin_unlock(&sdma->tx_lock);\n\treturn NETDEV_TX_OK;\n}\n\nint prestera_rxtx_switch_init(struct prestera_switch *sw)\n{\n\tstruct prestera_rxtx *rxtx;\n\tint err;\n\n\trxtx = kzalloc(sizeof(*rxtx), GFP_KERNEL);\n\tif (!rxtx)\n\t\treturn -ENOMEM;\n\n\tsw->rxtx = rxtx;\n\n\terr = prestera_sdma_switch_init(sw);\n\tif (err)\n\t\tkfree(rxtx);\n\n\treturn err;\n}\n\nvoid prestera_rxtx_switch_fini(struct prestera_switch *sw)\n{\n\tprestera_sdma_switch_fini(sw);\n\tkfree(sw->rxtx);\n}\n\nint prestera_rxtx_port_init(struct prestera_port *port)\n{\n\tport->dev->needed_headroom = PRESTERA_DSA_HLEN;\n\treturn 0;\n}\n\nnetdev_tx_t prestera_rxtx_xmit(struct prestera_port *port, struct sk_buff *skb)\n{\n\tstruct prestera_dsa dsa;\n\n\tdsa.hw_dev_num = port->dev_id;\n\tdsa.port_num = port->hw_id;\n\n\tif (skb_cow_head(skb, PRESTERA_DSA_HLEN) < 0)\n\t\treturn NET_XMIT_DROP;\n\n\tskb_push(skb, PRESTERA_DSA_HLEN);\n\tmemmove(skb->data, skb->data + PRESTERA_DSA_HLEN, 2 * ETH_ALEN);\n\n\tif (prestera_dsa_build(&dsa, skb->data + 2 * ETH_ALEN) != 0)\n\t\treturn NET_XMIT_DROP;\n\n\treturn prestera_sdma_xmit(&port->sw->rxtx->sdma, skb);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}