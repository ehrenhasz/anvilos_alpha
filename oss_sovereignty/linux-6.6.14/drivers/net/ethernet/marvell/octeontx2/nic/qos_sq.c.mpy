{
  "module_name": "qos_sq.c",
  "hash_id": "1140b50d03525d7e3bdaf30e7526eb3cbe914fc243d34db026ed66520c3dd1f5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/nic/qos_sq.c",
  "human_readable_source": "\n \n\n#include <linux/netdevice.h>\n#include <net/tso.h>\n\n#include \"cn10k.h\"\n#include \"otx2_reg.h\"\n#include \"otx2_common.h\"\n#include \"otx2_txrx.h\"\n#include \"otx2_struct.h\"\n\n#define OTX2_QOS_MAX_LEAF_NODES 16\n\nstatic void otx2_qos_aura_pool_free(struct otx2_nic *pfvf, int pool_id)\n{\n\tstruct otx2_pool *pool;\n\n\tif (!pfvf->qset.pool)\n\t\treturn;\n\n\tpool = &pfvf->qset.pool[pool_id];\n\tqmem_free(pfvf->dev, pool->stack);\n\tqmem_free(pfvf->dev, pool->fc_addr);\n\tpool->stack = NULL;\n\tpool->fc_addr = NULL;\n}\n\nstatic int otx2_qos_sq_aura_pool_init(struct otx2_nic *pfvf, int qidx)\n{\n\tstruct otx2_qset *qset = &pfvf->qset;\n\tint pool_id, stack_pages, num_sqbs;\n\tstruct otx2_hw *hw = &pfvf->hw;\n\tstruct otx2_snd_queue *sq;\n\tstruct otx2_pool *pool;\n\tdma_addr_t bufptr;\n\tint err, ptr;\n\tu64 iova, pa;\n\n\t \n\tnum_sqbs = (hw->sqb_size / 128) - 1;\n\tnum_sqbs = (qset->sqe_cnt + num_sqbs) / num_sqbs;\n\n\t \n\tstack_pages =\n\t\t(num_sqbs + hw->stack_pg_ptrs - 1) / hw->stack_pg_ptrs;\n\n\tpool_id = otx2_get_pool_idx(pfvf, AURA_NIX_SQ, qidx);\n\tpool = &pfvf->qset.pool[pool_id];\n\n\t \n\terr = otx2_aura_init(pfvf, pool_id, pool_id, num_sqbs);\n\tif (err)\n\t\treturn err;\n\n\t \n\terr = otx2_pool_init(pfvf, pool_id, stack_pages,\n\t\t\t     num_sqbs, hw->sqb_size, AURA_NIX_SQ);\n\tif (err)\n\t\tgoto aura_free;\n\n\t \n\terr = otx2_sync_mbox_msg(&pfvf->mbox);\n\tif (err)\n\t\tgoto pool_free;\n\n\t \n\tsq = &qset->sq[qidx];\n\tsq->sqb_count = 0;\n\tsq->sqb_ptrs = kcalloc(num_sqbs, sizeof(*sq->sqb_ptrs), GFP_KERNEL);\n\tif (!sq->sqb_ptrs) {\n\t\terr = -ENOMEM;\n\t\tgoto pool_free;\n\t}\n\n\tfor (ptr = 0; ptr < num_sqbs; ptr++) {\n\t\terr = otx2_alloc_rbuf(pfvf, pool, &bufptr);\n\t\tif (err)\n\t\t\tgoto sqb_free;\n\t\tpfvf->hw_ops->aura_freeptr(pfvf, pool_id, bufptr);\n\t\tsq->sqb_ptrs[sq->sqb_count++] = (u64)bufptr;\n\t}\n\n\treturn 0;\n\nsqb_free:\n\twhile (ptr--) {\n\t\tif (!sq->sqb_ptrs[ptr])\n\t\t\tcontinue;\n\t\tiova = sq->sqb_ptrs[ptr];\n\t\tpa = otx2_iova_to_phys(pfvf->iommu_domain, iova);\n\t\tdma_unmap_page_attrs(pfvf->dev, iova, hw->sqb_size,\n\t\t\t\t     DMA_FROM_DEVICE,\n\t\t\t\t     DMA_ATTR_SKIP_CPU_SYNC);\n\t\tput_page(virt_to_page(phys_to_virt(pa)));\n\t\totx2_aura_allocptr(pfvf, pool_id);\n\t}\n\tsq->sqb_count = 0;\n\tkfree(sq->sqb_ptrs);\npool_free:\n\tqmem_free(pfvf->dev, pool->stack);\naura_free:\n\tqmem_free(pfvf->dev, pool->fc_addr);\n\totx2_mbox_reset(&pfvf->mbox.mbox, 0);\n\treturn err;\n}\n\nstatic void otx2_qos_sq_free_sqbs(struct otx2_nic *pfvf, int qidx)\n{\n\tstruct otx2_qset *qset = &pfvf->qset;\n\tstruct otx2_hw *hw = &pfvf->hw;\n\tstruct otx2_snd_queue *sq;\n\tu64 iova, pa;\n\tint sqb;\n\n\tsq = &qset->sq[qidx];\n\tif (!sq->sqb_ptrs)\n\t\treturn;\n\tfor (sqb = 0; sqb < sq->sqb_count; sqb++) {\n\t\tif (!sq->sqb_ptrs[sqb])\n\t\t\tcontinue;\n\t\tiova = sq->sqb_ptrs[sqb];\n\t\tpa = otx2_iova_to_phys(pfvf->iommu_domain, iova);\n\t\tdma_unmap_page_attrs(pfvf->dev, iova, hw->sqb_size,\n\t\t\t\t     DMA_FROM_DEVICE,\n\t\t\t\t     DMA_ATTR_SKIP_CPU_SYNC);\n\t\tput_page(virt_to_page(phys_to_virt(pa)));\n\t}\n\n\tsq->sqb_count = 0;\n\n\tsq = &qset->sq[qidx];\n\tqmem_free(pfvf->dev, sq->sqe);\n\tqmem_free(pfvf->dev, sq->tso_hdrs);\n\tkfree(sq->sg);\n\tkfree(sq->sqb_ptrs);\n\tqmem_free(pfvf->dev, sq->timestamps);\n\n\tmemset((void *)sq, 0, sizeof(*sq));\n}\n\n \nstatic void otx2_qos_sqb_flush(struct otx2_nic *pfvf, int qidx)\n{\n\tint sqe_tail, sqe_head;\n\tu64 incr, *ptr, val;\n\n\tptr = (__force u64 *)otx2_get_regaddr(pfvf, NIX_LF_SQ_OP_STATUS);\n\tincr = (u64)qidx << 32;\n\tval = otx2_atomic64_add(incr, ptr);\n\tsqe_head = (val >> 20) & 0x3F;\n\tsqe_tail = (val >> 28) & 0x3F;\n\tif (sqe_head != sqe_tail)\n\t\tusleep_range(50, 60);\n}\n\nstatic int otx2_qos_ctx_disable(struct otx2_nic *pfvf, u16 qidx, int aura_id)\n{\n\tstruct nix_cn10k_aq_enq_req *cn10k_sq_aq;\n\tstruct npa_aq_enq_req *aura_aq;\n\tstruct npa_aq_enq_req *pool_aq;\n\tstruct nix_aq_enq_req *sq_aq;\n\n\tif (test_bit(CN10K_LMTST, &pfvf->hw.cap_flag)) {\n\t\tcn10k_sq_aq = otx2_mbox_alloc_msg_nix_cn10k_aq_enq(&pfvf->mbox);\n\t\tif (!cn10k_sq_aq)\n\t\t\treturn -ENOMEM;\n\t\tcn10k_sq_aq->qidx = qidx;\n\t\tcn10k_sq_aq->sq.ena = 0;\n\t\tcn10k_sq_aq->sq_mask.ena = 1;\n\t\tcn10k_sq_aq->ctype = NIX_AQ_CTYPE_SQ;\n\t\tcn10k_sq_aq->op = NIX_AQ_INSTOP_WRITE;\n\t} else {\n\t\tsq_aq = otx2_mbox_alloc_msg_nix_aq_enq(&pfvf->mbox);\n\t\tif (!sq_aq)\n\t\t\treturn -ENOMEM;\n\t\tsq_aq->qidx = qidx;\n\t\tsq_aq->sq.ena = 0;\n\t\tsq_aq->sq_mask.ena = 1;\n\t\tsq_aq->ctype = NIX_AQ_CTYPE_SQ;\n\t\tsq_aq->op = NIX_AQ_INSTOP_WRITE;\n\t}\n\n\taura_aq = otx2_mbox_alloc_msg_npa_aq_enq(&pfvf->mbox);\n\tif (!aura_aq) {\n\t\totx2_mbox_reset(&pfvf->mbox.mbox, 0);\n\t\treturn -ENOMEM;\n\t}\n\n\taura_aq->aura_id = aura_id;\n\taura_aq->aura.ena = 0;\n\taura_aq->aura_mask.ena = 1;\n\taura_aq->ctype = NPA_AQ_CTYPE_AURA;\n\taura_aq->op = NPA_AQ_INSTOP_WRITE;\n\n\tpool_aq = otx2_mbox_alloc_msg_npa_aq_enq(&pfvf->mbox);\n\tif (!pool_aq) {\n\t\totx2_mbox_reset(&pfvf->mbox.mbox, 0);\n\t\treturn -ENOMEM;\n\t}\n\n\tpool_aq->aura_id = aura_id;\n\tpool_aq->pool.ena = 0;\n\tpool_aq->pool_mask.ena = 1;\n\n\tpool_aq->ctype = NPA_AQ_CTYPE_POOL;\n\tpool_aq->op = NPA_AQ_INSTOP_WRITE;\n\n\treturn otx2_sync_mbox_msg(&pfvf->mbox);\n}\n\nint otx2_qos_get_qid(struct otx2_nic *pfvf)\n{\n\tint qidx;\n\n\tqidx = find_first_zero_bit(pfvf->qos.qos_sq_bmap,\n\t\t\t\t   pfvf->hw.tc_tx_queues);\n\n\treturn qidx == pfvf->hw.tc_tx_queues ? -ENOSPC : qidx;\n}\n\nvoid otx2_qos_free_qid(struct otx2_nic *pfvf, int qidx)\n{\n\tclear_bit(qidx, pfvf->qos.qos_sq_bmap);\n}\n\nint otx2_qos_enable_sq(struct otx2_nic *pfvf, int qidx)\n{\n\tstruct otx2_hw *hw = &pfvf->hw;\n\tint pool_id, sq_idx, err;\n\n\tif (pfvf->flags & OTX2_FLAG_INTF_DOWN)\n\t\treturn -EPERM;\n\n\tsq_idx = hw->non_qos_queues + qidx;\n\n\tmutex_lock(&pfvf->mbox.lock);\n\terr = otx2_qos_sq_aura_pool_init(pfvf, sq_idx);\n\tif (err)\n\t\tgoto out;\n\n\tpool_id = otx2_get_pool_idx(pfvf, AURA_NIX_SQ, sq_idx);\n\terr = otx2_sq_init(pfvf, sq_idx, pool_id);\n\tif (err)\n\t\tgoto out;\nout:\n\tmutex_unlock(&pfvf->mbox.lock);\n\treturn err;\n}\n\nvoid otx2_qos_disable_sq(struct otx2_nic *pfvf, int qidx)\n{\n\tstruct otx2_qset *qset = &pfvf->qset;\n\tstruct otx2_hw *hw = &pfvf->hw;\n\tstruct otx2_snd_queue *sq;\n\tstruct otx2_cq_queue *cq;\n\tint pool_id, sq_idx;\n\n\tsq_idx = hw->non_qos_queues + qidx;\n\n\t \n\tif (pfvf->flags & OTX2_FLAG_INTF_DOWN)\n\t\treturn;\n\n\tsq = &pfvf->qset.sq[sq_idx];\n\tif (!sq->sqb_ptrs)\n\t\treturn;\n\n\tif (sq_idx < hw->non_qos_queues ||\n\t    sq_idx >= otx2_get_total_tx_queues(pfvf)) {\n\t\tnetdev_err(pfvf->netdev, \"Send Queue is not a QoS queue\\n\");\n\t\treturn;\n\t}\n\n\tcq = &qset->cq[pfvf->hw.rx_queues + sq_idx];\n\tpool_id = otx2_get_pool_idx(pfvf, AURA_NIX_SQ, sq_idx);\n\n\totx2_qos_sqb_flush(pfvf, sq_idx);\n\totx2_smq_flush(pfvf, otx2_get_smq_idx(pfvf, sq_idx));\n\totx2_cleanup_tx_cqes(pfvf, cq);\n\n\tmutex_lock(&pfvf->mbox.lock);\n\totx2_qos_ctx_disable(pfvf, sq_idx, pool_id);\n\tmutex_unlock(&pfvf->mbox.lock);\n\n\totx2_qos_sq_free_sqbs(pfvf, sq_idx);\n\totx2_qos_aura_pool_free(pfvf, pool_id);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}