{
  "module_name": "otx2_tc.c",
  "hash_id": "9455c723494cfcac70e64c2ea6edaebd5d00c504687c6009dd9ae711317fe33a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/nic/otx2_tc.c",
  "human_readable_source": "\n \n\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/inetdevice.h>\n#include <linux/rhashtable.h>\n#include <linux/bitfield.h>\n#include <net/flow_dissector.h>\n#include <net/pkt_cls.h>\n#include <net/tc_act/tc_gact.h>\n#include <net/tc_act/tc_mirred.h>\n#include <net/tc_act/tc_vlan.h>\n#include <net/ipv6.h>\n\n#include \"cn10k.h\"\n#include \"otx2_common.h\"\n#include \"qos.h\"\n\n#define CN10K_MAX_BURST_MANTISSA\t0x7FFFULL\n#define CN10K_MAX_BURST_SIZE\t\t8453888ULL\n\n#define CN10K_TLX_BURST_MANTISSA\tGENMASK_ULL(43, 29)\n#define CN10K_TLX_BURST_EXPONENT\tGENMASK_ULL(47, 44)\n\nstruct otx2_tc_flow_stats {\n\tu64 bytes;\n\tu64 pkts;\n\tu64 used;\n};\n\nstruct otx2_tc_flow {\n\tstruct list_head\t\tlist;\n\tunsigned long\t\t\tcookie;\n\tstruct rcu_head\t\t\trcu;\n\tstruct otx2_tc_flow_stats\tstats;\n\tspinlock_t\t\t\tlock;  \n\tu16\t\t\t\trq;\n\tu16\t\t\t\tentry;\n\tu16\t\t\t\tleaf_profile;\n\tbool\t\t\t\tis_act_police;\n\tu32\t\t\t\tprio;\n\tstruct npc_install_flow_req\treq;\n\tu64\t\t\t\trate;\n\tu32\t\t\t\tburst;\n\tbool\t\t\t\tis_pps;\n};\n\nstatic void otx2_get_egress_burst_cfg(struct otx2_nic *nic, u32 burst,\n\t\t\t\t      u32 *burst_exp, u32 *burst_mantissa)\n{\n\tint max_burst, max_mantissa;\n\tunsigned int tmp;\n\n\tif (is_dev_otx2(nic->pdev)) {\n\t\tmax_burst = MAX_BURST_SIZE;\n\t\tmax_mantissa = MAX_BURST_MANTISSA;\n\t} else {\n\t\tmax_burst = CN10K_MAX_BURST_SIZE;\n\t\tmax_mantissa = CN10K_MAX_BURST_MANTISSA;\n\t}\n\n\t \n\tburst = min_t(u32, burst, max_burst);\n\tif (burst) {\n\t\t*burst_exp = ilog2(burst) ? ilog2(burst) - 1 : 0;\n\t\ttmp = burst - rounddown_pow_of_two(burst);\n\t\tif (burst < max_mantissa)\n\t\t\t*burst_mantissa = tmp * 2;\n\t\telse\n\t\t\t*burst_mantissa = tmp / (1ULL << (*burst_exp - 7));\n\t} else {\n\t\t*burst_exp = MAX_BURST_EXPONENT;\n\t\t*burst_mantissa = max_mantissa;\n\t}\n}\n\nstatic void otx2_get_egress_rate_cfg(u64 maxrate, u32 *exp,\n\t\t\t\t     u32 *mantissa, u32 *div_exp)\n{\n\tu64 tmp;\n\n\t \n\n\t \n\t*div_exp = 0;\n\n\tif (maxrate) {\n\t\t*exp = ilog2(maxrate) ? ilog2(maxrate) - 1 : 0;\n\t\ttmp = maxrate - rounddown_pow_of_two(maxrate);\n\t\tif (maxrate < MAX_RATE_MANTISSA)\n\t\t\t*mantissa = tmp * 2;\n\t\telse\n\t\t\t*mantissa = tmp / (1ULL << (*exp - 7));\n\t} else {\n\t\t \n\t\t*exp = MAX_RATE_EXPONENT;\n\t\t*mantissa = MAX_RATE_MANTISSA;\n\t}\n}\n\nu64 otx2_get_txschq_rate_regval(struct otx2_nic *nic,\n\t\t\t\tu64 maxrate, u32 burst)\n{\n\tu32 burst_exp, burst_mantissa;\n\tu32 exp, mantissa, div_exp;\n\tu64 regval = 0;\n\n\t \n\totx2_get_egress_burst_cfg(nic, burst, &burst_exp, &burst_mantissa);\n\totx2_get_egress_rate_cfg(maxrate, &exp, &mantissa, &div_exp);\n\n\tif (is_dev_otx2(nic->pdev)) {\n\t\tregval = FIELD_PREP(TLX_BURST_EXPONENT, (u64)burst_exp) |\n\t\t\t\tFIELD_PREP(TLX_BURST_MANTISSA, (u64)burst_mantissa) |\n\t\t\t\tFIELD_PREP(TLX_RATE_DIVIDER_EXPONENT, div_exp) |\n\t\t\t\tFIELD_PREP(TLX_RATE_EXPONENT, exp) |\n\t\t\t\tFIELD_PREP(TLX_RATE_MANTISSA, mantissa) | BIT_ULL(0);\n\t} else {\n\t\tregval = FIELD_PREP(CN10K_TLX_BURST_EXPONENT, (u64)burst_exp) |\n\t\t\t\tFIELD_PREP(CN10K_TLX_BURST_MANTISSA, (u64)burst_mantissa) |\n\t\t\t\tFIELD_PREP(TLX_RATE_DIVIDER_EXPONENT, div_exp) |\n\t\t\t\tFIELD_PREP(TLX_RATE_EXPONENT, exp) |\n\t\t\t\tFIELD_PREP(TLX_RATE_MANTISSA, mantissa) | BIT_ULL(0);\n\t}\n\n\treturn regval;\n}\n\nstatic int otx2_set_matchall_egress_rate(struct otx2_nic *nic,\n\t\t\t\t\t u32 burst, u64 maxrate)\n{\n\tstruct otx2_hw *hw = &nic->hw;\n\tstruct nix_txschq_config *req;\n\tint txschq, err;\n\n\t \n\ttxschq = hw->txschq_list[NIX_TXSCH_LVL_TL4][0];\n\n\tmutex_lock(&nic->mbox.lock);\n\treq = otx2_mbox_alloc_msg_nix_txschq_cfg(&nic->mbox);\n\tif (!req) {\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn -ENOMEM;\n\t}\n\n\treq->lvl = NIX_TXSCH_LVL_TL4;\n\treq->num_regs = 1;\n\treq->reg[0] = NIX_AF_TL4X_PIR(txschq);\n\treq->regval[0] = otx2_get_txschq_rate_regval(nic, maxrate, burst);\n\n\terr = otx2_sync_mbox_msg(&nic->mbox);\n\tmutex_unlock(&nic->mbox.lock);\n\treturn err;\n}\n\nstatic int otx2_tc_validate_flow(struct otx2_nic *nic,\n\t\t\t\t struct flow_action *actions,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tif (nic->flags & OTX2_FLAG_INTF_DOWN) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Interface not initialized\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!flow_action_has_entries(actions)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"MATCHALL offload called with no action\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!flow_offload_has_one_action(actions)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Egress MATCHALL offload supports only 1 policing action\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int otx2_policer_validate(const struct flow_action *action,\n\t\t\t\t const struct flow_action_entry *act,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tif (act->police.exceed.act_id != FLOW_ACTION_DROP) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when exceed action is not drop\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id != FLOW_ACTION_PIPE &&\n\t    act->police.notexceed.act_id != FLOW_ACTION_ACCEPT) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is not pipe or ok\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id == FLOW_ACTION_ACCEPT &&\n\t    !flow_action_is_last_entry(action, act)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is ok, but action is not last\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.peakrate_bytes_ps ||\n\t    act->police.avrate || act->police.overhead) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when peakrate/avrate/overhead is configured\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2_tc_egress_matchall_install(struct otx2_nic *nic,\n\t\t\t\t\t   struct tc_cls_matchall_offload *cls)\n{\n\tstruct netlink_ext_ack *extack = cls->common.extack;\n\tstruct flow_action *actions = &cls->rule->action;\n\tstruct flow_action_entry *entry;\n\tint err;\n\n\terr = otx2_tc_validate_flow(nic, actions, extack);\n\tif (err)\n\t\treturn err;\n\n\tif (nic->flags & OTX2_FLAG_TC_MATCHALL_EGRESS_ENABLED) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Only one Egress MATCHALL ratelimiter can be offloaded\");\n\t\treturn -ENOMEM;\n\t}\n\n\tentry = &cls->rule->action.entries[0];\n\tswitch (entry->id) {\n\tcase FLOW_ACTION_POLICE:\n\t\terr = otx2_policer_validate(&cls->rule->action, entry, extack);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (entry->police.rate_pkt_ps) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"QoS offload not support packets per second\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\terr = otx2_set_matchall_egress_rate(nic, entry->police.burst,\n\t\t\t\t\t\t    otx2_convert_rate(entry->police.rate_bytes_ps));\n\t\tif (err)\n\t\t\treturn err;\n\t\tnic->flags |= OTX2_FLAG_TC_MATCHALL_EGRESS_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Only police action is supported with Egress MATCHALL offload\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2_tc_egress_matchall_delete(struct otx2_nic *nic,\n\t\t\t\t\t  struct tc_cls_matchall_offload *cls)\n{\n\tstruct netlink_ext_ack *extack = cls->common.extack;\n\tint err;\n\n\tif (nic->flags & OTX2_FLAG_INTF_DOWN) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Interface not initialized\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = otx2_set_matchall_egress_rate(nic, 0, 0);\n\tnic->flags &= ~OTX2_FLAG_TC_MATCHALL_EGRESS_ENABLED;\n\treturn err;\n}\n\nstatic int otx2_tc_act_set_hw_police(struct otx2_nic *nic,\n\t\t\t\t     struct otx2_tc_flow *node)\n{\n\tint rc;\n\n\tmutex_lock(&nic->mbox.lock);\n\n\trc = cn10k_alloc_leaf_profile(nic, &node->leaf_profile);\n\tif (rc) {\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn rc;\n\t}\n\n\trc = cn10k_set_ipolicer_rate(nic, node->leaf_profile,\n\t\t\t\t     node->burst, node->rate, node->is_pps);\n\tif (rc)\n\t\tgoto free_leaf;\n\n\trc = cn10k_map_unmap_rq_policer(nic, node->rq, node->leaf_profile, true);\n\tif (rc)\n\t\tgoto free_leaf;\n\n\tmutex_unlock(&nic->mbox.lock);\n\n\treturn 0;\n\nfree_leaf:\n\tif (cn10k_free_leaf_profile(nic, node->leaf_profile))\n\t\tnetdev_err(nic->netdev,\n\t\t\t   \"Unable to free leaf bandwidth profile(%d)\\n\",\n\t\t\t   node->leaf_profile);\n\tmutex_unlock(&nic->mbox.lock);\n\treturn rc;\n}\n\nstatic int otx2_tc_act_set_police(struct otx2_nic *nic,\n\t\t\t\t  struct otx2_tc_flow *node,\n\t\t\t\t  struct flow_cls_offload *f,\n\t\t\t\t  u64 rate, u32 burst, u32 mark,\n\t\t\t\t  struct npc_install_flow_req *req, bool pps)\n{\n\tstruct netlink_ext_ack *extack = f->common.extack;\n\tstruct otx2_hw *hw = &nic->hw;\n\tint rq_idx, rc;\n\n\trq_idx = find_first_zero_bit(&nic->rq_bmap, hw->rx_queues);\n\tif (rq_idx >= hw->rx_queues) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Police action rules exceeded\");\n\t\treturn -EINVAL;\n\t}\n\n\treq->match_id = mark & 0xFFFFULL;\n\treq->index = rq_idx;\n\treq->op = NIX_RX_ACTIONOP_UCAST;\n\n\tnode->is_act_police = true;\n\tnode->rq = rq_idx;\n\tnode->burst = burst;\n\tnode->rate = rate;\n\tnode->is_pps = pps;\n\n\trc = otx2_tc_act_set_hw_police(nic, node);\n\tif (!rc)\n\t\tset_bit(rq_idx, &nic->rq_bmap);\n\n\treturn rc;\n}\n\nstatic int otx2_tc_parse_actions(struct otx2_nic *nic,\n\t\t\t\t struct flow_action *flow_action,\n\t\t\t\t struct npc_install_flow_req *req,\n\t\t\t\t struct flow_cls_offload *f,\n\t\t\t\t struct otx2_tc_flow *node)\n{\n\tstruct netlink_ext_ack *extack = f->common.extack;\n\tstruct flow_action_entry *act;\n\tstruct net_device *target;\n\tstruct otx2_nic *priv;\n\tu32 burst, mark = 0;\n\tu8 nr_police = 0;\n\tbool pps = false;\n\tu64 rate;\n\tint err;\n\tint i;\n\n\tif (!flow_action_has_entries(flow_action)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"no tc actions specified\");\n\t\treturn -EINVAL;\n\t}\n\n\tflow_action_for_each(i, act, flow_action) {\n\t\tswitch (act->id) {\n\t\tcase FLOW_ACTION_DROP:\n\t\t\treq->op = NIX_RX_ACTIONOP_DROP;\n\t\t\treturn 0;\n\t\tcase FLOW_ACTION_ACCEPT:\n\t\t\treq->op = NIX_RX_ACTION_DEFAULT;\n\t\t\treturn 0;\n\t\tcase FLOW_ACTION_REDIRECT_INGRESS:\n\t\t\ttarget = act->dev;\n\t\t\tpriv = netdev_priv(target);\n\t\t\t \n\t\t\tif (rvu_get_pf(nic->pcifunc) != rvu_get_pf(priv->pcifunc)) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t\t   \"can't redirect to other pf/vf\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t\treq->vf = priv->pcifunc & RVU_PFVF_FUNC_MASK;\n\n\t\t\t \n\t\t\tif (!req->op)\n\t\t\t\treq->op = NIX_RX_ACTION_DEFAULT;\n\t\t\tbreak;\n\n\t\tcase FLOW_ACTION_VLAN_POP:\n\t\t\treq->vtag0_valid = true;\n\t\t\t \n\t\t\treq->vtag0_type = NIX_AF_LFX_RX_VTAG_TYPE7;\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_POLICE:\n\t\t\t \n\t\t\tif (is_dev_otx2(nic->pdev)) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t\"Ingress policing not supported on this platform\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\terr = otx2_policer_validate(flow_action, act, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\tif (act->police.rate_bytes_ps > 0) {\n\t\t\t\trate = act->police.rate_bytes_ps * 8;\n\t\t\t\tburst = act->police.burst;\n\t\t\t} else if (act->police.rate_pkt_ps > 0) {\n\t\t\t\t \n\t\t\t\trate = act->police.rate_pkt_ps * 8;\n\t\t\t\tburst = act->police.burst_pkt;\n\t\t\t\tpps = true;\n\t\t\t}\n\t\t\tnr_police++;\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_MARK:\n\t\t\tmark = act->mark;\n\t\t\tbreak;\n\n\t\tcase FLOW_ACTION_RX_QUEUE_MAPPING:\n\t\t\treq->op = NIX_RX_ACTIONOP_UCAST;\n\t\t\treq->index = act->rx_queue;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\n\tif (nr_police > 1) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"rate limit police offload requires a single action\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (nr_police)\n\t\treturn otx2_tc_act_set_police(nic, node, f, rate, burst,\n\t\t\t\t\t      mark, req, pps);\n\n\treturn 0;\n}\n\nstatic int otx2_tc_process_vlan(struct otx2_nic *nic, struct flow_msg *flow_spec,\n\t\t\t\tstruct flow_msg *flow_mask, struct flow_rule *rule,\n\t\t\t\tstruct npc_install_flow_req *req, bool is_inner)\n{\n\tstruct flow_match_vlan match;\n\tu16 vlan_tci, vlan_tci_mask;\n\n\tif (is_inner)\n\t\tflow_rule_match_cvlan(rule, &match);\n\telse\n\t\tflow_rule_match_vlan(rule, &match);\n\n\tif (!eth_type_vlan(match.key->vlan_tpid)) {\n\t\tnetdev_err(nic->netdev, \"vlan tpid 0x%x not supported\\n\",\n\t\t\t   ntohs(match.key->vlan_tpid));\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!match.mask->vlan_id) {\n\t\tstruct flow_action_entry *act;\n\t\tint i;\n\n\t\tflow_action_for_each(i, act, &rule->action) {\n\t\t\tif (act->id == FLOW_ACTION_DROP) {\n\t\t\t\tnetdev_err(nic->netdev,\n\t\t\t\t\t   \"vlan tpid 0x%x with vlan_id %d is not supported for DROP rule.\\n\",\n\t\t\t\t\t   ntohs(match.key->vlan_tpid), match.key->vlan_id);\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (match.mask->vlan_id ||\n\t    match.mask->vlan_dei ||\n\t    match.mask->vlan_priority) {\n\t\tvlan_tci = match.key->vlan_id |\n\t\t\t   match.key->vlan_dei << 12 |\n\t\t\t   match.key->vlan_priority << 13;\n\n\t\tvlan_tci_mask = match.mask->vlan_id |\n\t\t\t\tmatch.mask->vlan_dei << 12 |\n\t\t\t\tmatch.mask->vlan_priority << 13;\n\t\tif (is_inner) {\n\t\t\tflow_spec->vlan_itci = htons(vlan_tci);\n\t\t\tflow_mask->vlan_itci = htons(vlan_tci_mask);\n\t\t\treq->features |= BIT_ULL(NPC_INNER_VID);\n\t\t} else {\n\t\t\tflow_spec->vlan_tci = htons(vlan_tci);\n\t\t\tflow_mask->vlan_tci = htons(vlan_tci_mask);\n\t\t\treq->features |= BIT_ULL(NPC_OUTER_VID);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2_tc_prepare_flow(struct otx2_nic *nic, struct otx2_tc_flow *node,\n\t\t\t\tstruct flow_cls_offload *f,\n\t\t\t\tstruct npc_install_flow_req *req)\n{\n\tstruct netlink_ext_ack *extack = f->common.extack;\n\tstruct flow_msg *flow_spec = &req->packet;\n\tstruct flow_msg *flow_mask = &req->mask;\n\tstruct flow_dissector *dissector;\n\tstruct flow_rule *rule;\n\tu8 ip_proto = 0;\n\n\trule = flow_cls_offload_flow_rule(f);\n\tdissector = rule->match.dissector;\n\n\tif ((dissector->used_keys &\n\t    ~(BIT_ULL(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ETH_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_VLAN) |\n\t      BIT(FLOW_DISSECTOR_KEY_CVLAN) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_PORTS) |\n\t      BIT(FLOW_DISSECTOR_KEY_IPSEC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IP))))  {\n\t\tnetdev_info(nic->netdev, \"unsupported flow used key 0x%llx\",\n\t\t\t    dissector->used_keys);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\n\t\t \n\t\tflow_spec->etype = match.key->n_proto;\n\t\tflow_mask->etype = match.mask->n_proto;\n\t\treq->features |= BIT_ULL(NPC_ETYPE);\n\n\t\tif (match.mask->ip_proto &&\n\t\t    (match.key->ip_proto != IPPROTO_TCP &&\n\t\t     match.key->ip_proto != IPPROTO_UDP &&\n\t\t     match.key->ip_proto != IPPROTO_SCTP &&\n\t\t     match.key->ip_proto != IPPROTO_ICMP &&\n\t\t     match.key->ip_proto != IPPROTO_ESP &&\n\t\t     match.key->ip_proto != IPPROTO_AH &&\n\t\t     match.key->ip_proto != IPPROTO_ICMPV6)) {\n\t\t\tnetdev_info(nic->netdev,\n\t\t\t\t    \"ip_proto=0x%x not supported\\n\",\n\t\t\t\t    match.key->ip_proto);\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (match.mask->ip_proto)\n\t\t\tip_proto = match.key->ip_proto;\n\n\t\tif (ip_proto == IPPROTO_UDP)\n\t\t\treq->features |= BIT_ULL(NPC_IPPROTO_UDP);\n\t\telse if (ip_proto == IPPROTO_TCP)\n\t\t\treq->features |= BIT_ULL(NPC_IPPROTO_TCP);\n\t\telse if (ip_proto == IPPROTO_SCTP)\n\t\t\treq->features |= BIT_ULL(NPC_IPPROTO_SCTP);\n\t\telse if (ip_proto == IPPROTO_ICMP)\n\t\t\treq->features |= BIT_ULL(NPC_IPPROTO_ICMP);\n\t\telse if (ip_proto == IPPROTO_ICMPV6)\n\t\t\treq->features |= BIT_ULL(NPC_IPPROTO_ICMP6);\n\t\telse if (ip_proto == IPPROTO_ESP)\n\t\t\treq->features |= BIT_ULL(NPC_IPPROTO_ESP);\n\t\telse if (ip_proto == IPPROTO_AH)\n\t\t\treq->features |= BIT_ULL(NPC_IPPROTO_AH);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {\n\t\tstruct flow_match_control match;\n\n\t\tflow_rule_match_control(rule, &match);\n\t\tif (match.mask->flags & FLOW_DIS_FIRST_FRAG) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"HW doesn't support frag first/later\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (match.mask->flags & FLOW_DIS_IS_FRAGMENT) {\n\t\t\tif (ntohs(flow_spec->etype) == ETH_P_IP) {\n\t\t\t\tflow_spec->ip_flag = IPV4_FLAG_MORE;\n\t\t\t\tflow_mask->ip_flag = IPV4_FLAG_MORE;\n\t\t\t\treq->features |= BIT_ULL(NPC_IPFRAG_IPV4);\n\t\t\t} else if (ntohs(flow_spec->etype) == ETH_P_IPV6) {\n\t\t\t\tflow_spec->next_header = IPPROTO_FRAGMENT;\n\t\t\t\tflow_mask->next_header = 0xff;\n\t\t\t\treq->features |= BIT_ULL(NPC_IPFRAG_IPV6);\n\t\t\t} else {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"flow-type should be either IPv4 and IPv6\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct flow_match_eth_addrs match;\n\n\t\tflow_rule_match_eth_addrs(rule, &match);\n\t\tif (!is_zero_ether_addr(match.mask->src)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"src mac match not supported\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (!is_zero_ether_addr(match.mask->dst)) {\n\t\t\tether_addr_copy(flow_spec->dmac, (u8 *)&match.key->dst);\n\t\t\tether_addr_copy(flow_mask->dmac,\n\t\t\t\t\t(u8 *)&match.mask->dst);\n\t\t\treq->features |= BIT_ULL(NPC_DMAC);\n\t\t}\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IPSEC)) {\n\t\tstruct flow_match_ipsec match;\n\n\t\tflow_rule_match_ipsec(rule, &match);\n\t\tif (!match.mask->spi) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"spi index not specified\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (ip_proto != IPPROTO_ESP &&\n\t\t    ip_proto != IPPROTO_AH) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"SPI index is valid only for ESP/AH proto\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tflow_spec->spi = match.key->spi;\n\t\tflow_mask->spi = match.mask->spi;\n\t\treq->features |= BIT_ULL(NPC_IPSEC_SPI);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IP)) {\n\t\tstruct flow_match_ip match;\n\n\t\tflow_rule_match_ip(rule, &match);\n\t\tif ((ntohs(flow_spec->etype) != ETH_P_IP) &&\n\t\t    match.mask->tos) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"tos not supported\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (match.mask->ttl) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"ttl not supported\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tflow_spec->tos = match.key->tos;\n\t\tflow_mask->tos = match.mask->tos;\n\t\treq->features |= BIT_ULL(NPC_TOS);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {\n\t\tint ret;\n\n\t\tret = otx2_tc_process_vlan(nic, flow_spec, flow_mask, rule, req, false);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CVLAN)) {\n\t\tint ret;\n\n\t\tret = otx2_tc_process_vlan(nic, flow_spec, flow_mask, rule, req, true);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IPV4_ADDRS)) {\n\t\tstruct flow_match_ipv4_addrs match;\n\n\t\tflow_rule_match_ipv4_addrs(rule, &match);\n\n\t\tflow_spec->ip4dst = match.key->dst;\n\t\tflow_mask->ip4dst = match.mask->dst;\n\t\treq->features |= BIT_ULL(NPC_DIP_IPV4);\n\n\t\tflow_spec->ip4src = match.key->src;\n\t\tflow_mask->ip4src = match.mask->src;\n\t\treq->features |= BIT_ULL(NPC_SIP_IPV4);\n\t} else if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IPV6_ADDRS)) {\n\t\tstruct flow_match_ipv6_addrs match;\n\n\t\tflow_rule_match_ipv6_addrs(rule, &match);\n\n\t\tif (ipv6_addr_loopback(&match.key->dst) ||\n\t\t    ipv6_addr_loopback(&match.key->src)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Flow matching IPv6 loopback addr not supported\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (!ipv6_addr_any(&match.mask->dst)) {\n\t\t\tmemcpy(&flow_spec->ip6dst,\n\t\t\t       (struct in6_addr *)&match.key->dst,\n\t\t\t       sizeof(flow_spec->ip6dst));\n\t\t\tmemcpy(&flow_mask->ip6dst,\n\t\t\t       (struct in6_addr *)&match.mask->dst,\n\t\t\t       sizeof(flow_spec->ip6dst));\n\t\t\treq->features |= BIT_ULL(NPC_DIP_IPV6);\n\t\t}\n\n\t\tif (!ipv6_addr_any(&match.mask->src)) {\n\t\t\tmemcpy(&flow_spec->ip6src,\n\t\t\t       (struct in6_addr *)&match.key->src,\n\t\t\t       sizeof(flow_spec->ip6src));\n\t\t\tmemcpy(&flow_mask->ip6src,\n\t\t\t       (struct in6_addr *)&match.mask->src,\n\t\t\t       sizeof(flow_spec->ip6src));\n\t\t\treq->features |= BIT_ULL(NPC_SIP_IPV6);\n\t\t}\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS)) {\n\t\tstruct flow_match_ports match;\n\n\t\tflow_rule_match_ports(rule, &match);\n\n\t\tflow_spec->dport = match.key->dst;\n\t\tflow_mask->dport = match.mask->dst;\n\n\t\tif (flow_mask->dport) {\n\t\t\tif (ip_proto == IPPROTO_UDP)\n\t\t\t\treq->features |= BIT_ULL(NPC_DPORT_UDP);\n\t\t\telse if (ip_proto == IPPROTO_TCP)\n\t\t\t\treq->features |= BIT_ULL(NPC_DPORT_TCP);\n\t\t\telse if (ip_proto == IPPROTO_SCTP)\n\t\t\t\treq->features |= BIT_ULL(NPC_DPORT_SCTP);\n\t\t}\n\n\t\tflow_spec->sport = match.key->src;\n\t\tflow_mask->sport = match.mask->src;\n\n\t\tif (flow_mask->sport) {\n\t\t\tif (ip_proto == IPPROTO_UDP)\n\t\t\t\treq->features |= BIT_ULL(NPC_SPORT_UDP);\n\t\t\telse if (ip_proto == IPPROTO_TCP)\n\t\t\t\treq->features |= BIT_ULL(NPC_SPORT_TCP);\n\t\t\telse if (ip_proto == IPPROTO_SCTP)\n\t\t\t\treq->features |= BIT_ULL(NPC_SPORT_SCTP);\n\t\t}\n\t}\n\n\treturn otx2_tc_parse_actions(nic, &rule->action, req, f, node);\n}\n\nstatic void otx2_destroy_tc_flow_list(struct otx2_nic *pfvf)\n{\n\tstruct otx2_flow_config *flow_cfg = pfvf->flow_cfg;\n\tstruct otx2_tc_flow *iter, *tmp;\n\n\tif (!(pfvf->flags & OTX2_FLAG_MCAM_ENTRIES_ALLOC))\n\t\treturn;\n\n\tlist_for_each_entry_safe(iter, tmp, &flow_cfg->flow_list_tc, list) {\n\t\tlist_del(&iter->list);\n\t\tkfree(iter);\n\t\tflow_cfg->nr_flows--;\n\t}\n}\n\nstatic struct otx2_tc_flow *otx2_tc_get_entry_by_cookie(struct otx2_flow_config *flow_cfg,\n\t\t\t\t\t\t\tunsigned long cookie)\n{\n\tstruct otx2_tc_flow *tmp;\n\n\tlist_for_each_entry(tmp, &flow_cfg->flow_list_tc, list) {\n\t\tif (tmp->cookie == cookie)\n\t\t\treturn tmp;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct otx2_tc_flow *otx2_tc_get_entry_by_index(struct otx2_flow_config *flow_cfg,\n\t\t\t\t\t\t       int index)\n{\n\tstruct otx2_tc_flow *tmp;\n\tint i = 0;\n\n\tlist_for_each_entry(tmp, &flow_cfg->flow_list_tc, list) {\n\t\tif (i == index)\n\t\t\treturn tmp;\n\t\ti++;\n\t}\n\n\treturn NULL;\n}\n\nstatic void otx2_tc_del_from_flow_list(struct otx2_flow_config *flow_cfg,\n\t\t\t\t       struct otx2_tc_flow *node)\n{\n\tstruct list_head *pos, *n;\n\tstruct otx2_tc_flow *tmp;\n\n\tlist_for_each_safe(pos, n, &flow_cfg->flow_list_tc) {\n\t\ttmp = list_entry(pos, struct otx2_tc_flow, list);\n\t\tif (node == tmp) {\n\t\t\tlist_del(&node->list);\n\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic int otx2_tc_add_to_flow_list(struct otx2_flow_config *flow_cfg,\n\t\t\t\t    struct otx2_tc_flow *node)\n{\n\tstruct list_head *pos, *n;\n\tstruct otx2_tc_flow *tmp;\n\tint index = 0;\n\n\t \n\tif (list_empty(&flow_cfg->flow_list_tc)) {\n\t\tlist_add(&node->list, &flow_cfg->flow_list_tc);\n\t\treturn index;\n\t}\n\n\tlist_for_each_safe(pos, n, &flow_cfg->flow_list_tc) {\n\t\ttmp = list_entry(pos, struct otx2_tc_flow, list);\n\t\tif (node->prio < tmp->prio)\n\t\t\tbreak;\n\t\tindex++;\n\t}\n\n\tlist_add(&node->list, pos->prev);\n\treturn index;\n}\n\nstatic int otx2_add_mcam_flow_entry(struct otx2_nic *nic, struct npc_install_flow_req *req)\n{\n\tstruct npc_install_flow_req *tmp_req;\n\tint err;\n\n\tmutex_lock(&nic->mbox.lock);\n\ttmp_req = otx2_mbox_alloc_msg_npc_install_flow(&nic->mbox);\n\tif (!tmp_req) {\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn -ENOMEM;\n\t}\n\n\tmemcpy(tmp_req, req, sizeof(struct npc_install_flow_req));\n\t \n\terr = otx2_sync_mbox_msg(&nic->mbox);\n\tif (err) {\n\t\tnetdev_err(nic->netdev, \"Failed to install MCAM flow entry %d\\n\",\n\t\t\t   req->entry);\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn -EFAULT;\n\t}\n\n\tmutex_unlock(&nic->mbox.lock);\n\treturn 0;\n}\n\nstatic int otx2_del_mcam_flow_entry(struct otx2_nic *nic, u16 entry, u16 *cntr_val)\n{\n\tstruct npc_delete_flow_rsp *rsp;\n\tstruct npc_delete_flow_req *req;\n\tint err;\n\n\tmutex_lock(&nic->mbox.lock);\n\treq = otx2_mbox_alloc_msg_npc_delete_flow(&nic->mbox);\n\tif (!req) {\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn -ENOMEM;\n\t}\n\n\treq->entry = entry;\n\n\t \n\terr = otx2_sync_mbox_msg(&nic->mbox);\n\tif (err) {\n\t\tnetdev_err(nic->netdev, \"Failed to delete MCAM flow entry %d\\n\",\n\t\t\t   entry);\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn -EFAULT;\n\t}\n\n\tif (cntr_val) {\n\t\trsp = (struct npc_delete_flow_rsp *)otx2_mbox_get_rsp(&nic->mbox.mbox,\n\t\t\t\t\t\t\t\t      0, &req->hdr);\n\t\tif (IS_ERR(rsp)) {\n\t\t\tnetdev_err(nic->netdev, \"Failed to get MCAM delete response for entry %d\\n\",\n\t\t\t\t   entry);\n\t\t\tmutex_unlock(&nic->mbox.lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\t*cntr_val = rsp->cntr_val;\n\t}\n\n\tmutex_unlock(&nic->mbox.lock);\n\treturn 0;\n}\n\nstatic int otx2_tc_update_mcam_table_del_req(struct otx2_nic *nic,\n\t\t\t\t\t     struct otx2_flow_config *flow_cfg,\n\t\t\t\t\t     struct otx2_tc_flow *node)\n{\n\tstruct list_head *pos, *n;\n\tstruct otx2_tc_flow *tmp;\n\tint i = 0, index = 0;\n\tu16 cntr_val = 0;\n\n\t \n\tlist_for_each_safe(pos, n, &flow_cfg->flow_list_tc) {\n\t\ttmp = list_entry(pos, struct otx2_tc_flow, list);\n\t\tif (node == tmp) {\n\t\t\tlist_del(&tmp->list);\n\t\t\tbreak;\n\t\t}\n\n\t\totx2_del_mcam_flow_entry(nic, tmp->entry, &cntr_val);\n\t\ttmp->entry++;\n\t\ttmp->req.entry = tmp->entry;\n\t\ttmp->req.cntr_val = cntr_val;\n\t\tindex++;\n\t}\n\n\tlist_for_each_safe(pos, n, &flow_cfg->flow_list_tc) {\n\t\tif (i == index)\n\t\t\tbreak;\n\n\t\ttmp = list_entry(pos, struct otx2_tc_flow, list);\n\t\totx2_add_mcam_flow_entry(nic, &tmp->req);\n\t\ti++;\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2_tc_update_mcam_table_add_req(struct otx2_nic *nic,\n\t\t\t\t\t     struct otx2_flow_config *flow_cfg,\n\t\t\t\t\t     struct otx2_tc_flow *node)\n{\n\tint mcam_idx = flow_cfg->max_flows - flow_cfg->nr_flows - 1;\n\tstruct otx2_tc_flow *tmp;\n\tint list_idx, i;\n\tu16 cntr_val = 0;\n\n\t \n\tlist_idx = otx2_tc_add_to_flow_list(flow_cfg, node);\n\tfor (i = 0; i < list_idx; i++) {\n\t\ttmp = otx2_tc_get_entry_by_index(flow_cfg, i);\n\t\tif (!tmp)\n\t\t\treturn -ENOMEM;\n\n\t\totx2_del_mcam_flow_entry(nic, tmp->entry, &cntr_val);\n\t\ttmp->entry = flow_cfg->flow_ent[mcam_idx];\n\t\ttmp->req.entry = tmp->entry;\n\t\ttmp->req.cntr_val = cntr_val;\n\t\totx2_add_mcam_flow_entry(nic, &tmp->req);\n\t\tmcam_idx++;\n\t}\n\n\treturn mcam_idx;\n}\n\nstatic int otx2_tc_update_mcam_table(struct otx2_nic *nic,\n\t\t\t\t     struct otx2_flow_config *flow_cfg,\n\t\t\t\t     struct otx2_tc_flow *node,\n\t\t\t\t     bool add_req)\n{\n\tif (add_req)\n\t\treturn otx2_tc_update_mcam_table_add_req(nic, flow_cfg, node);\n\n\treturn otx2_tc_update_mcam_table_del_req(nic, flow_cfg, node);\n}\n\nstatic int otx2_tc_del_flow(struct otx2_nic *nic,\n\t\t\t    struct flow_cls_offload *tc_flow_cmd)\n{\n\tstruct otx2_flow_config *flow_cfg = nic->flow_cfg;\n\tstruct otx2_tc_flow *flow_node;\n\tint err;\n\n\tflow_node = otx2_tc_get_entry_by_cookie(flow_cfg, tc_flow_cmd->cookie);\n\tif (!flow_node) {\n\t\tnetdev_err(nic->netdev, \"tc flow not found for cookie 0x%lx\\n\",\n\t\t\t   tc_flow_cmd->cookie);\n\t\treturn -EINVAL;\n\t}\n\n\tif (flow_node->is_act_police) {\n\t\t__clear_bit(flow_node->rq, &nic->rq_bmap);\n\n\t\tif (nic->flags & OTX2_FLAG_INTF_DOWN)\n\t\t\tgoto free_mcam_flow;\n\n\t\tmutex_lock(&nic->mbox.lock);\n\n\t\terr = cn10k_map_unmap_rq_policer(nic, flow_node->rq,\n\t\t\t\t\t\t flow_node->leaf_profile, false);\n\t\tif (err)\n\t\t\tnetdev_err(nic->netdev,\n\t\t\t\t   \"Unmapping RQ %d & profile %d failed\\n\",\n\t\t\t\t   flow_node->rq, flow_node->leaf_profile);\n\n\t\terr = cn10k_free_leaf_profile(nic, flow_node->leaf_profile);\n\t\tif (err)\n\t\t\tnetdev_err(nic->netdev,\n\t\t\t\t   \"Unable to free leaf bandwidth profile(%d)\\n\",\n\t\t\t\t   flow_node->leaf_profile);\n\n\t\tmutex_unlock(&nic->mbox.lock);\n\t}\n\nfree_mcam_flow:\n\totx2_del_mcam_flow_entry(nic, flow_node->entry, NULL);\n\totx2_tc_update_mcam_table(nic, flow_cfg, flow_node, false);\n\tkfree_rcu(flow_node, rcu);\n\tflow_cfg->nr_flows--;\n\treturn 0;\n}\n\nstatic int otx2_tc_add_flow(struct otx2_nic *nic,\n\t\t\t    struct flow_cls_offload *tc_flow_cmd)\n{\n\tstruct netlink_ext_ack *extack = tc_flow_cmd->common.extack;\n\tstruct otx2_flow_config *flow_cfg = nic->flow_cfg;\n\tstruct otx2_tc_flow *new_node, *old_node;\n\tstruct npc_install_flow_req *req, dummy;\n\tint rc, err, mcam_idx;\n\n\tif (!(nic->flags & OTX2_FLAG_TC_FLOWER_SUPPORT))\n\t\treturn -ENOMEM;\n\n\tif (nic->flags & OTX2_FLAG_INTF_DOWN) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Interface not initialized\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (flow_cfg->nr_flows == flow_cfg->max_flows) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Free MCAM entry not available to add the flow\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tnew_node = kzalloc(sizeof(*new_node), GFP_KERNEL);\n\tif (!new_node)\n\t\treturn -ENOMEM;\n\tspin_lock_init(&new_node->lock);\n\tnew_node->cookie = tc_flow_cmd->cookie;\n\tnew_node->prio = tc_flow_cmd->common.prio;\n\n\tmemset(&dummy, 0, sizeof(struct npc_install_flow_req));\n\n\trc = otx2_tc_prepare_flow(nic, new_node, tc_flow_cmd, &dummy);\n\tif (rc) {\n\t\tkfree_rcu(new_node, rcu);\n\t\treturn rc;\n\t}\n\n\t \n\told_node = otx2_tc_get_entry_by_cookie(flow_cfg, tc_flow_cmd->cookie);\n\tif (old_node)\n\t\totx2_tc_del_flow(nic, tc_flow_cmd);\n\n\tmcam_idx = otx2_tc_update_mcam_table(nic, flow_cfg, new_node, true);\n\tmutex_lock(&nic->mbox.lock);\n\treq = otx2_mbox_alloc_msg_npc_install_flow(&nic->mbox);\n\tif (!req) {\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\trc = -ENOMEM;\n\t\tgoto free_leaf;\n\t}\n\n\tmemcpy(&dummy.hdr, &req->hdr, sizeof(struct mbox_msghdr));\n\tmemcpy(req, &dummy, sizeof(struct npc_install_flow_req));\n\treq->channel = nic->hw.rx_chan_base;\n\treq->entry = flow_cfg->flow_ent[mcam_idx];\n\treq->intf = NIX_INTF_RX;\n\treq->set_cntr = 1;\n\tnew_node->entry = req->entry;\n\n\t \n\trc = otx2_sync_mbox_msg(&nic->mbox);\n\tif (rc) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to install MCAM flow entry\");\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\tgoto free_leaf;\n\t}\n\n\tmutex_unlock(&nic->mbox.lock);\n\tmemcpy(&new_node->req, req, sizeof(struct npc_install_flow_req));\n\n\tflow_cfg->nr_flows++;\n\treturn 0;\n\nfree_leaf:\n\totx2_tc_del_from_flow_list(flow_cfg, new_node);\n\tkfree_rcu(new_node, rcu);\n\tif (new_node->is_act_police) {\n\t\tmutex_lock(&nic->mbox.lock);\n\n\t\terr = cn10k_map_unmap_rq_policer(nic, new_node->rq,\n\t\t\t\t\t\t new_node->leaf_profile, false);\n\t\tif (err)\n\t\t\tnetdev_err(nic->netdev,\n\t\t\t\t   \"Unmapping RQ %d & profile %d failed\\n\",\n\t\t\t\t   new_node->rq, new_node->leaf_profile);\n\t\terr = cn10k_free_leaf_profile(nic, new_node->leaf_profile);\n\t\tif (err)\n\t\t\tnetdev_err(nic->netdev,\n\t\t\t\t   \"Unable to free leaf bandwidth profile(%d)\\n\",\n\t\t\t\t   new_node->leaf_profile);\n\n\t\t__clear_bit(new_node->rq, &nic->rq_bmap);\n\n\t\tmutex_unlock(&nic->mbox.lock);\n\t}\n\n\treturn rc;\n}\n\nstatic int otx2_tc_get_flow_stats(struct otx2_nic *nic,\n\t\t\t\t  struct flow_cls_offload *tc_flow_cmd)\n{\n\tstruct npc_mcam_get_stats_req *req;\n\tstruct npc_mcam_get_stats_rsp *rsp;\n\tstruct otx2_tc_flow_stats *stats;\n\tstruct otx2_tc_flow *flow_node;\n\tint err;\n\n\tflow_node = otx2_tc_get_entry_by_cookie(nic->flow_cfg, tc_flow_cmd->cookie);\n\tif (!flow_node) {\n\t\tnetdev_info(nic->netdev, \"tc flow not found for cookie %lx\",\n\t\t\t    tc_flow_cmd->cookie);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_lock(&nic->mbox.lock);\n\n\treq = otx2_mbox_alloc_msg_npc_mcam_entry_stats(&nic->mbox);\n\tif (!req) {\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn -ENOMEM;\n\t}\n\n\treq->entry = flow_node->entry;\n\n\terr = otx2_sync_mbox_msg(&nic->mbox);\n\tif (err) {\n\t\tnetdev_err(nic->netdev, \"Failed to get stats for MCAM flow entry %d\\n\",\n\t\t\t   req->entry);\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn -EFAULT;\n\t}\n\n\trsp = (struct npc_mcam_get_stats_rsp *)otx2_mbox_get_rsp\n\t\t(&nic->mbox.mbox, 0, &req->hdr);\n\tif (IS_ERR(rsp)) {\n\t\tmutex_unlock(&nic->mbox.lock);\n\t\treturn PTR_ERR(rsp);\n\t}\n\n\tmutex_unlock(&nic->mbox.lock);\n\n\tif (!rsp->stat_ena)\n\t\treturn -EINVAL;\n\n\tstats = &flow_node->stats;\n\n\tspin_lock(&flow_node->lock);\n\tflow_stats_update(&tc_flow_cmd->stats, 0x0, rsp->stat - stats->pkts, 0x0, 0x0,\n\t\t\t  FLOW_ACTION_HW_STATS_IMMEDIATE);\n\tstats->pkts = rsp->stat;\n\tspin_unlock(&flow_node->lock);\n\n\treturn 0;\n}\n\nstatic int otx2_setup_tc_cls_flower(struct otx2_nic *nic,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tswitch (cls_flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn otx2_tc_add_flow(nic, cls_flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn otx2_tc_del_flow(nic, cls_flower);\n\tcase FLOW_CLS_STATS:\n\t\treturn otx2_tc_get_flow_stats(nic, cls_flower);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int otx2_tc_ingress_matchall_install(struct otx2_nic *nic,\n\t\t\t\t\t    struct tc_cls_matchall_offload *cls)\n{\n\tstruct netlink_ext_ack *extack = cls->common.extack;\n\tstruct flow_action *actions = &cls->rule->action;\n\tstruct flow_action_entry *entry;\n\tu64 rate;\n\tint err;\n\n\terr = otx2_tc_validate_flow(nic, actions, extack);\n\tif (err)\n\t\treturn err;\n\n\tif (nic->flags & OTX2_FLAG_TC_MATCHALL_INGRESS_ENABLED) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Only one ingress MATCHALL ratelimitter can be offloaded\");\n\t\treturn -ENOMEM;\n\t}\n\n\tentry = &cls->rule->action.entries[0];\n\tswitch (entry->id) {\n\tcase FLOW_ACTION_POLICE:\n\t\t \n\t\tif (is_dev_otx2(nic->pdev)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Ingress policing not supported on this platform\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\terr = cn10k_alloc_matchall_ipolicer(nic);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t \n\t\trate = entry->police.rate_bytes_ps * 8;\n\t\terr = cn10k_set_matchall_ipolicer_rate(nic, entry->police.burst, rate);\n\t\tif (err)\n\t\t\treturn err;\n\t\tnic->flags |= OTX2_FLAG_TC_MATCHALL_INGRESS_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Only police action supported with Ingress MATCHALL offload\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2_tc_ingress_matchall_delete(struct otx2_nic *nic,\n\t\t\t\t\t   struct tc_cls_matchall_offload *cls)\n{\n\tstruct netlink_ext_ack *extack = cls->common.extack;\n\tint err;\n\n\tif (nic->flags & OTX2_FLAG_INTF_DOWN) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Interface not initialized\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = cn10k_free_matchall_ipolicer(nic);\n\tnic->flags &= ~OTX2_FLAG_TC_MATCHALL_INGRESS_ENABLED;\n\treturn err;\n}\n\nstatic int otx2_setup_tc_ingress_matchall(struct otx2_nic *nic,\n\t\t\t\t\t  struct tc_cls_matchall_offload *cls_matchall)\n{\n\tswitch (cls_matchall->command) {\n\tcase TC_CLSMATCHALL_REPLACE:\n\t\treturn otx2_tc_ingress_matchall_install(nic, cls_matchall);\n\tcase TC_CLSMATCHALL_DESTROY:\n\t\treturn otx2_tc_ingress_matchall_delete(nic, cls_matchall);\n\tcase TC_CLSMATCHALL_STATS:\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int otx2_setup_tc_block_ingress_cb(enum tc_setup_type type,\n\t\t\t\t\t  void *type_data, void *cb_priv)\n{\n\tstruct otx2_nic *nic = cb_priv;\n\tbool ntuple;\n\n\tif (!tc_cls_can_offload_and_chain0(nic->netdev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tntuple = nic->netdev->features & NETIF_F_NTUPLE;\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\tif (ntuple) {\n\t\t\tnetdev_warn(nic->netdev,\n\t\t\t\t    \"Can't install TC flower offload rule when NTUPLE is active\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\treturn otx2_setup_tc_cls_flower(nic, type_data);\n\tcase TC_SETUP_CLSMATCHALL:\n\t\treturn otx2_setup_tc_ingress_matchall(nic, type_data);\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int otx2_setup_tc_egress_matchall(struct otx2_nic *nic,\n\t\t\t\t\t struct tc_cls_matchall_offload *cls_matchall)\n{\n\tswitch (cls_matchall->command) {\n\tcase TC_CLSMATCHALL_REPLACE:\n\t\treturn otx2_tc_egress_matchall_install(nic, cls_matchall);\n\tcase TC_CLSMATCHALL_DESTROY:\n\t\treturn otx2_tc_egress_matchall_delete(nic, cls_matchall);\n\tcase TC_CLSMATCHALL_STATS:\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int otx2_setup_tc_block_egress_cb(enum tc_setup_type type,\n\t\t\t\t\t void *type_data, void *cb_priv)\n{\n\tstruct otx2_nic *nic = cb_priv;\n\n\tif (!tc_cls_can_offload_and_chain0(nic->netdev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSMATCHALL:\n\t\treturn otx2_setup_tc_egress_matchall(nic, type_data);\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic LIST_HEAD(otx2_block_cb_list);\n\nstatic int otx2_setup_tc_block(struct net_device *netdev,\n\t\t\t       struct flow_block_offload *f)\n{\n\tstruct otx2_nic *nic = netdev_priv(netdev);\n\tflow_setup_cb_t *cb;\n\tbool ingress;\n\n\tif (f->block_shared)\n\t\treturn -EOPNOTSUPP;\n\n\tif (f->binder_type == FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS) {\n\t\tcb = otx2_setup_tc_block_ingress_cb;\n\t\tingress = true;\n\t} else if (f->binder_type == FLOW_BLOCK_BINDER_TYPE_CLSACT_EGRESS) {\n\t\tcb = otx2_setup_tc_block_egress_cb;\n\t\tingress = false;\n\t} else {\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn flow_block_cb_setup_simple(f, &otx2_block_cb_list, cb,\n\t\t\t\t\t  nic, nic, ingress);\n}\n\nint otx2_setup_tc(struct net_device *netdev, enum tc_setup_type type,\n\t\t  void *type_data)\n{\n\tswitch (type) {\n\tcase TC_SETUP_BLOCK:\n\t\treturn otx2_setup_tc_block(netdev, type_data);\n\tcase TC_SETUP_QDISC_HTB:\n\t\treturn otx2_setup_tc_htb(netdev, type_data);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\nEXPORT_SYMBOL(otx2_setup_tc);\n\nint otx2_init_tc(struct otx2_nic *nic)\n{\n\t \n\tset_bit(0, &nic->rq_bmap);\n\n\tif (!nic->flow_cfg) {\n\t\tnetdev_err(nic->netdev,\n\t\t\t   \"Can't init TC, nic->flow_cfg is not setup\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(otx2_init_tc);\n\nvoid otx2_shutdown_tc(struct otx2_nic *nic)\n{\n\totx2_destroy_tc_flow_list(nic);\n}\nEXPORT_SYMBOL(otx2_shutdown_tc);\n\nstatic void otx2_tc_config_ingress_rule(struct otx2_nic *nic,\n\t\t\t\t\tstruct otx2_tc_flow *node)\n{\n\tstruct npc_install_flow_req *req;\n\n\tif (otx2_tc_act_set_hw_police(nic, node))\n\t\treturn;\n\n\tmutex_lock(&nic->mbox.lock);\n\n\treq = otx2_mbox_alloc_msg_npc_install_flow(&nic->mbox);\n\tif (!req)\n\t\tgoto err;\n\n\tmemcpy(req, &node->req, sizeof(struct npc_install_flow_req));\n\n\tif (otx2_sync_mbox_msg(&nic->mbox))\n\t\tnetdev_err(nic->netdev,\n\t\t\t   \"Failed to install MCAM flow entry for ingress rule\");\nerr:\n\tmutex_unlock(&nic->mbox.lock);\n}\n\nvoid otx2_tc_apply_ingress_police_rules(struct otx2_nic *nic)\n{\n\tstruct otx2_flow_config *flow_cfg = nic->flow_cfg;\n\tstruct otx2_tc_flow *node;\n\n\t \n\tlist_for_each_entry(node, &flow_cfg->flow_list_tc, list) {\n\t\tif (node->is_act_police)\n\t\t\totx2_tc_config_ingress_rule(nic, node);\n\t}\n}\nEXPORT_SYMBOL(otx2_tc_apply_ingress_police_rules);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}