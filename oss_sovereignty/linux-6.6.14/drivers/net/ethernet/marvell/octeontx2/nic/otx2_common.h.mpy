{
  "module_name": "otx2_common.h",
  "hash_id": "a678f6c0a97150b1e7a3dfc4a38d5e13ea4636892759850fa9fb7ab8ad86b408",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h",
  "human_readable_source": " \n \n\n#ifndef OTX2_COMMON_H\n#define OTX2_COMMON_H\n\n#include <linux/ethtool.h>\n#include <linux/pci.h>\n#include <linux/iommu.h>\n#include <linux/net_tstamp.h>\n#include <linux/ptp_clock_kernel.h>\n#include <linux/timecounter.h>\n#include <linux/soc/marvell/octeontx2/asm.h>\n#include <net/macsec.h>\n#include <net/pkt_cls.h>\n#include <net/devlink.h>\n#include <linux/time64.h>\n#include <linux/dim.h>\n#include <uapi/linux/if_macsec.h>\n\n#include <mbox.h>\n#include <npc.h>\n#include \"otx2_reg.h\"\n#include \"otx2_txrx.h\"\n#include \"otx2_devlink.h\"\n#include <rvu_trace.h>\n#include \"qos.h\"\n\n \n#define IPV4_FLAG_MORE\t\t\t\t0x20\n\n \n#define PCI_DEVID_OCTEONTX2_RVU_PF              0xA063\n#define PCI_DEVID_OCTEONTX2_RVU_VF\t\t0xA064\n#define PCI_DEVID_OCTEONTX2_RVU_AFVF\t\t0xA0F8\n\n#define PCI_SUBSYS_DEVID_96XX_RVU_PFVF\t\t0xB200\n#define PCI_SUBSYS_DEVID_CN10K_B_RVU_PFVF\t0xBD00\n\n \n#define PCI_CFG_REG_BAR_NUM                     2\n#define PCI_MBOX_BAR_NUM                        4\n\n#define NAME_SIZE                               32\n\n#ifdef CONFIG_DCB\n \n#define NIX_PF_PFC_PRIO_MAX\t\t\t8\n#endif\n\nenum arua_mapped_qtypes {\n\tAURA_NIX_RQ,\n\tAURA_NIX_SQ,\n};\n\n \n#define NIX_LF_QINT_VEC_START\t\t\t0x00\n#define NIX_LF_CINT_VEC_START\t\t\t0x40\n#define NIX_LF_GINT_VEC\t\t\t\t0x80\n#define NIX_LF_ERR_VEC\t\t\t\t0x81\n#define NIX_LF_POISON_VEC\t\t\t0x82\n\n \n#define SEND_CQ_SKID\t2000\n\n#define OTX2_GET_RX_STATS(reg) \\\n\totx2_read64(pfvf, NIX_LF_RX_STATX(reg))\n#define OTX2_GET_TX_STATS(reg) \\\n\totx2_read64(pfvf, NIX_LF_TX_STATX(reg))\n\nstruct otx2_lmt_info {\n\tu64 lmt_addr;\n\tu16 lmt_id;\n};\n \nstruct otx2_rss_ctx {\n\tu8  ind_tbl[MAX_RSS_INDIR_TBL_SIZE];\n};\n\nstruct otx2_rss_info {\n\tu8 enable;\n\tu32 flowkey_cfg;\n\tu16 rss_size;\n#define RSS_HASH_KEY_SIZE\t44    \n\tu8  key[RSS_HASH_KEY_SIZE];\n\tstruct otx2_rss_ctx\t*rss_ctx[MAX_RSS_GROUPS];\n};\n\n \nenum otx2_errlvl {\n\tNPC_ERRLVL_RE,\n\tNPC_ERRLVL_LID_LA,\n\tNPC_ERRLVL_LID_LB,\n\tNPC_ERRLVL_LID_LC,\n\tNPC_ERRLVL_LID_LD,\n\tNPC_ERRLVL_LID_LE,\n\tNPC_ERRLVL_LID_LF,\n\tNPC_ERRLVL_LID_LG,\n\tNPC_ERRLVL_LID_LH,\n\tNPC_ERRLVL_NIX = 0x0F,\n};\n\nenum otx2_errcodes_re {\n\t \n\tERRCODE_FCS = 0x7,\n\tERRCODE_FCS_RCV = 0x8,\n\tERRCODE_UNDERSIZE = 0x10,\n\tERRCODE_OVERSIZE = 0x11,\n\tERRCODE_OL2_LEN_MISMATCH = 0x12,\n\t \n\tERRCODE_OL3_LEN = 0x10,\n\tERRCODE_OL4_LEN = 0x11,\n\tERRCODE_OL4_CSUM = 0x12,\n\tERRCODE_IL3_LEN = 0x20,\n\tERRCODE_IL4_LEN = 0x21,\n\tERRCODE_IL4_CSUM = 0x22,\n};\n\n \nenum nix_stat_lf_tx {\n\tTX_UCAST\t= 0x0,\n\tTX_BCAST\t= 0x1,\n\tTX_MCAST\t= 0x2,\n\tTX_DROP\t\t= 0x3,\n\tTX_OCTS\t\t= 0x4,\n\tTX_STATS_ENUM_LAST,\n};\n\n \nenum nix_stat_lf_rx {\n\tRX_OCTS\t\t= 0x0,\n\tRX_UCAST\t= 0x1,\n\tRX_BCAST\t= 0x2,\n\tRX_MCAST\t= 0x3,\n\tRX_DROP\t\t= 0x4,\n\tRX_DROP_OCTS\t= 0x5,\n\tRX_FCS\t\t= 0x6,\n\tRX_ERR\t\t= 0x7,\n\tRX_DRP_BCAST\t= 0x8,\n\tRX_DRP_MCAST\t= 0x9,\n\tRX_DRP_L3BCAST\t= 0xa,\n\tRX_DRP_L3MCAST\t= 0xb,\n\tRX_STATS_ENUM_LAST,\n};\n\nstruct otx2_dev_stats {\n\tu64 rx_bytes;\n\tu64 rx_frames;\n\tu64 rx_ucast_frames;\n\tu64 rx_bcast_frames;\n\tu64 rx_mcast_frames;\n\tu64 rx_drops;\n\n\tu64 tx_bytes;\n\tu64 tx_frames;\n\tu64 tx_ucast_frames;\n\tu64 tx_bcast_frames;\n\tu64 tx_mcast_frames;\n\tu64 tx_drops;\n};\n\n \nstruct otx2_drv_stats {\n\tatomic_t rx_fcs_errs;\n\tatomic_t rx_oversize_errs;\n\tatomic_t rx_undersize_errs;\n\tatomic_t rx_csum_errs;\n\tatomic_t rx_len_errs;\n\tatomic_t rx_other_errs;\n};\n\nstruct mbox {\n\tstruct otx2_mbox\tmbox;\n\tstruct work_struct\tmbox_wrk;\n\tstruct otx2_mbox\tmbox_up;\n\tstruct work_struct\tmbox_up_wrk;\n\tstruct otx2_nic\t\t*pfvf;\n\tvoid\t\t\t*bbuf_base;  \n\tstruct mutex\t\tlock;\t \n\tint\t\t\tnum_msgs;  \n\tint\t\t\tup_num_msgs;  \n};\n\n \n#define MAX_BURST_EXPONENT\t\t0x0FULL\n#define MAX_BURST_MANTISSA\t\t0xFFULL\n#define MAX_BURST_SIZE\t\t\t130816ULL\n#define MAX_RATE_DIVIDER_EXPONENT\t12ULL\n#define MAX_RATE_EXPONENT\t\t0x0FULL\n#define MAX_RATE_MANTISSA\t\t0xFFULL\n\n \n#define TLX_RATE_MANTISSA\t\tGENMASK_ULL(8, 1)\n#define TLX_RATE_EXPONENT\t\tGENMASK_ULL(12, 9)\n#define TLX_RATE_DIVIDER_EXPONENT\tGENMASK_ULL(16, 13)\n#define TLX_BURST_MANTISSA\t\tGENMASK_ULL(36, 29)\n#define TLX_BURST_EXPONENT\t\tGENMASK_ULL(40, 37)\n\nstruct otx2_hw {\n\tstruct pci_dev\t\t*pdev;\n\tstruct otx2_rss_info\trss_info;\n\tu16                     rx_queues;\n\tu16                     tx_queues;\n\tu16                     xdp_queues;\n\tu16\t\t\ttc_tx_queues;\n\tu16                     non_qos_queues;  \n\tu16\t\t\tmax_queues;\n\tu16\t\t\tpool_cnt;\n\tu16\t\t\trqpool_cnt;\n\tu16\t\t\tsqpool_cnt;\n\n#define OTX2_DEFAULT_RBUF_LEN\t2048\n\tu16\t\t\trbuf_len;\n\tu32\t\t\txqe_size;\n\n\t \n\tu32\t\t\tstack_pg_ptrs;   \n\tu32\t\t\tstack_pg_bytes;  \n\tu16\t\t\tsqb_size;\n\n\t \n\tu8\t\t\ttxschq_link_cfg_lvl;\n\tu8\t\t\ttxschq_aggr_lvl_rr_prio;\n\tu16\t\t\ttxschq_list[NIX_TXSCH_LVL_CNT][MAX_TXSCHQ_PER_FUNC];\n\tu16\t\t\tmatchall_ipolicer;\n\tu32\t\t\tdwrr_mtu;\n\tu8\t\t\tsmq_link_type;\n\n\t \n\tu16\t\t\trx_chan_base;\n\tu16\t\t\ttx_chan_base;\n\tu16\t\t\tcq_qcount_wait;\n\tu16\t\t\tcq_ecount_wait;\n\tu16\t\t\trq_skid;\n\tu8\t\t\tcq_time_wait;\n\n\t \n\tu8\t\t\tlso_tsov4_idx;\n\tu8\t\t\tlso_tsov6_idx;\n\tu8\t\t\tlso_udpv4_idx;\n\tu8\t\t\tlso_udpv6_idx;\n\n\t \n\tu8\t\t\tflowkey_alg_idx;\n\n\t \n\tu8\t\t\tcint_cnt;  \n\tu16\t\t\tnpa_msixoff;  \n\tu16\t\t\tnix_msixoff;  \n\tchar\t\t\t*irq_name;\n\tcpumask_var_t           *affinity_mask;\n\n\t \n\tstruct otx2_dev_stats\tdev_stats;\n\tstruct otx2_drv_stats\tdrv_stats;\n\tu64\t\t\tcgx_rx_stats[CGX_RX_STATS_COUNT];\n\tu64\t\t\tcgx_tx_stats[CGX_TX_STATS_COUNT];\n\tu64\t\t\tcgx_fec_corr_blks;\n\tu64\t\t\tcgx_fec_uncorr_blks;\n\tu8\t\t\tcgx_links;   \n\tu8\t\t\tlbk_links;   \n\tu8\t\t\ttx_link;     \n#define HW_TSO\t\t\t0\n#define CN10K_MBOX\t\t1\n#define CN10K_LMTST\t\t2\n#define CN10K_RPM\t\t3\n#define CN10K_PTP_ONESTEP\t4\n#define CN10K_HW_MACSEC\t\t5\n#define QOS_CIR_PIR_SUPPORT\t6\n\tunsigned long\t\tcap_flag;\n\n#define LMT_LINE_SIZE\t\t128\n#define LMT_BURST_SIZE\t\t32  \n\tu64\t\t\t*lmt_base;\n\tstruct otx2_lmt_info\t__percpu *lmt_info;\n};\n\nenum vfperm {\n\tOTX2_RESET_VF_PERM,\n\tOTX2_TRUSTED_VF,\n};\n\nstruct otx2_vf_config {\n\tstruct otx2_nic *pf;\n\tstruct delayed_work link_event_work;\n\tbool intf_down;  \n\tu8 mac[ETH_ALEN];\n\tu16 vlan;\n\tint tx_vtag_idx;\n\tbool trusted;\n};\n\nstruct flr_work {\n\tstruct work_struct work;\n\tstruct otx2_nic *pf;\n};\n\nstruct refill_work {\n\tstruct delayed_work pool_refill_work;\n\tstruct otx2_nic *pf;\n\tstruct napi_struct *napi;\n};\n\n \nstruct ptpv2_tstamp {\n\t__be16 seconds_msb;  \n\t__be32 seconds_lsb;  \n\t__be32 nanoseconds;\n} __packed;\n\nstruct otx2_ptp {\n\tstruct ptp_clock_info ptp_info;\n\tstruct ptp_clock *ptp_clock;\n\tstruct otx2_nic *nic;\n\n\tstruct cyclecounter cycle_counter;\n\tstruct timecounter time_counter;\n\n\tstruct delayed_work extts_work;\n\tu64 last_extts;\n\tu64 thresh;\n\n\tstruct ptp_pin_desc extts_config;\n\tu64 (*convert_rx_ptp_tstmp)(u64 timestamp);\n\tu64 (*convert_tx_ptp_tstmp)(u64 timestamp);\n\tu64 (*ptp_tstamp2nsec)(const struct timecounter *time_counter, u64 timestamp);\n\tstruct delayed_work synctstamp_work;\n\tu64 tstamp;\n\tu32 base_ns;\n};\n\n#define OTX2_HW_TIMESTAMP_LEN\t8\n\nstruct otx2_mac_table {\n\tu8 addr[ETH_ALEN];\n\tu16 mcam_entry;\n\tbool inuse;\n};\n\nstruct otx2_flow_config {\n\tu16\t\t\t*flow_ent;\n\tu16\t\t\t*def_ent;\n\tu16\t\t\tnr_flows;\n#define OTX2_DEFAULT_FLOWCOUNT\t\t16\n#define OTX2_MAX_UNICAST_FLOWS\t\t8\n#define OTX2_MAX_VLAN_FLOWS\t\t1\n#define OTX2_MAX_TC_FLOWS\tOTX2_DEFAULT_FLOWCOUNT\n#define OTX2_MCAM_COUNT\t\t(OTX2_DEFAULT_FLOWCOUNT + \\\n\t\t\t\t OTX2_MAX_UNICAST_FLOWS + \\\n\t\t\t\t OTX2_MAX_VLAN_FLOWS)\n\tu16\t\t\tunicast_offset;\n\tu16\t\t\trx_vlan_offset;\n\tu16\t\t\tvf_vlan_offset;\n#define OTX2_PER_VF_VLAN_FLOWS\t2  \n#define OTX2_VF_VLAN_RX_INDEX\t0\n#define OTX2_VF_VLAN_TX_INDEX\t1\n\tu32\t\t\t*bmap_to_dmacindex;\n\tunsigned long\t\t*dmacflt_bmap;\n\tstruct list_head\tflow_list;\n\tu32\t\t\tdmacflt_max_flows;\n\tu16                     max_flows;\n\tstruct list_head\tflow_list_tc;\n\tbool\t\t\tntuple;\n};\n\nstruct dev_hw_ops {\n\tint\t(*sq_aq_init)(void *dev, u16 qidx, u16 sqb_aura);\n\tvoid\t(*sqe_flush)(void *dev, struct otx2_snd_queue *sq,\n\t\t\t     int size, int qidx);\n\tint\t(*refill_pool_ptrs)(void *dev, struct otx2_cq_queue *cq);\n\tvoid\t(*aura_freeptr)(void *dev, int aura, u64 buf);\n};\n\n#define CN10K_MCS_SA_PER_SC\t4\n\n \nstruct cn10k_txsc_stats {\n\tu64 InPktsUntagged;\n\tu64 InPktsNoTag;\n\tu64 InPktsBadTag;\n\tu64 InPktsUnknownSCI;\n\tu64 InPktsNoSCI;\n\tu64 InPktsOverrun;\n};\n\nstruct cn10k_rxsc_stats {\n\tu64 InOctetsValidated;\n\tu64 InOctetsDecrypted;\n\tu64 InPktsUnchecked;\n\tu64 InPktsDelayed;\n\tu64 InPktsOK;\n\tu64 InPktsInvalid;\n\tu64 InPktsLate;\n\tu64 InPktsNotValid;\n\tu64 InPktsNotUsingSA;\n\tu64 InPktsUnusedSA;\n};\n\nstruct cn10k_mcs_txsc {\n\tstruct macsec_secy *sw_secy;\n\tstruct cn10k_txsc_stats stats;\n\tstruct list_head entry;\n\tenum macsec_validation_type last_validate_frames;\n\tbool last_replay_protect;\n\tu16 hw_secy_id_tx;\n\tu16 hw_secy_id_rx;\n\tu16 hw_flow_id;\n\tu16 hw_sc_id;\n\tu16 hw_sa_id[CN10K_MCS_SA_PER_SC];\n\tu8 sa_bmap;\n\tu8 sa_key[CN10K_MCS_SA_PER_SC][MACSEC_MAX_KEY_LEN];\n\tu8 encoding_sa;\n\tu8 salt[CN10K_MCS_SA_PER_SC][MACSEC_SALT_LEN];\n\tssci_t ssci[CN10K_MCS_SA_PER_SC];\n\tbool vlan_dev;  \n};\n\nstruct cn10k_mcs_rxsc {\n\tstruct macsec_secy *sw_secy;\n\tstruct macsec_rx_sc *sw_rxsc;\n\tstruct cn10k_rxsc_stats stats;\n\tstruct list_head entry;\n\tu16 hw_flow_id;\n\tu16 hw_sc_id;\n\tu16 hw_sa_id[CN10K_MCS_SA_PER_SC];\n\tu8 sa_bmap;\n\tu8 sa_key[CN10K_MCS_SA_PER_SC][MACSEC_MAX_KEY_LEN];\n\tu8 salt[CN10K_MCS_SA_PER_SC][MACSEC_SALT_LEN];\n\tssci_t ssci[CN10K_MCS_SA_PER_SC];\n};\n\nstruct cn10k_mcs_cfg {\n\tstruct list_head txsc_list;\n\tstruct list_head rxsc_list;\n};\n\nstruct otx2_nic {\n\tvoid __iomem\t\t*reg_base;\n\tstruct net_device\t*netdev;\n\tstruct dev_hw_ops\t*hw_ops;\n\tvoid\t\t\t*iommu_domain;\n\tu16\t\t\ttx_max_pktlen;\n\tu16\t\t\trbsize;  \n\n#define OTX2_FLAG_RX_TSTAMP_ENABLED\t\tBIT_ULL(0)\n#define OTX2_FLAG_TX_TSTAMP_ENABLED\t\tBIT_ULL(1)\n#define OTX2_FLAG_INTF_DOWN\t\t\tBIT_ULL(2)\n#define OTX2_FLAG_MCAM_ENTRIES_ALLOC\t\tBIT_ULL(3)\n#define OTX2_FLAG_NTUPLE_SUPPORT\t\tBIT_ULL(4)\n#define OTX2_FLAG_UCAST_FLTR_SUPPORT\t\tBIT_ULL(5)\n#define OTX2_FLAG_RX_VLAN_SUPPORT\t\tBIT_ULL(6)\n#define OTX2_FLAG_VF_VLAN_SUPPORT\t\tBIT_ULL(7)\n#define OTX2_FLAG_PF_SHUTDOWN\t\t\tBIT_ULL(8)\n#define OTX2_FLAG_RX_PAUSE_ENABLED\t\tBIT_ULL(9)\n#define OTX2_FLAG_TX_PAUSE_ENABLED\t\tBIT_ULL(10)\n#define OTX2_FLAG_TC_FLOWER_SUPPORT\t\tBIT_ULL(11)\n#define OTX2_FLAG_TC_MATCHALL_EGRESS_ENABLED\tBIT_ULL(12)\n#define OTX2_FLAG_TC_MATCHALL_INGRESS_ENABLED\tBIT_ULL(13)\n#define OTX2_FLAG_DMACFLTR_SUPPORT\t\tBIT_ULL(14)\n#define OTX2_FLAG_PTP_ONESTEP_SYNC\t\tBIT_ULL(15)\n#define OTX2_FLAG_ADPTV_INT_COAL_ENABLED BIT_ULL(16)\n\tu64\t\t\tflags;\n\tu64\t\t\t*cq_op_addr;\n\n\tstruct bpf_prog\t\t*xdp_prog;\n\tstruct otx2_qset\tqset;\n\tstruct otx2_hw\t\thw;\n\tstruct pci_dev\t\t*pdev;\n\tstruct device\t\t*dev;\n\n\t \n\tstruct mbox\t\tmbox;\n\tstruct mbox\t\t*mbox_pfvf;\n\tstruct workqueue_struct *mbox_wq;\n\tstruct workqueue_struct *mbox_pfvf_wq;\n\n\tu8\t\t\ttotal_vfs;\n\tu16\t\t\tpcifunc;  \n\tu16\t\t\tbpid[NIX_MAX_BPID_CHAN];\n\tstruct otx2_vf_config\t*vf_configs;\n\tstruct cgx_link_user_info linfo;\n\n\t \n\tstruct otx2_flow_config\t*flow_cfg;\n\tstruct otx2_mac_table\t*mac_table;\n\n\tu64\t\t\treset_count;\n\tstruct work_struct\treset_task;\n\tstruct workqueue_struct\t*flr_wq;\n\tstruct flr_work\t\t*flr_wrk;\n\tstruct refill_work\t*refill_wrk;\n\tstruct workqueue_struct\t*otx2_wq;\n\tstruct work_struct\trx_mode_work;\n\n\t \n\tu32\t\t\tmsg_enable;\n\n\t \n\tint\t\t\tnix_blkaddr;\n\t \n\tstruct qmem\t\t*dync_lmt;\n\tu16\t\t\ttot_lmt_lines;\n\tu16\t\t\tnpa_lmt_lines;\n\tu32\t\t\tnix_lmt_size;\n\n\tstruct otx2_ptp\t\t*ptp;\n\tstruct hwtstamp_config\ttstamp;\n\n\tunsigned long\t\trq_bmap;\n\n\t \n\tstruct otx2_devlink\t*dl;\n#ifdef CONFIG_DCB\n\t \n\tu8\t\t\tpfc_en;\n\tu8\t\t\t*queue_to_pfc_map;\n\tu16\t\t\tpfc_schq_list[NIX_TXSCH_LVL_CNT][MAX_TXSCHQ_PER_FUNC];\n\tbool\t\t\tpfc_alloc_status[NIX_PF_PFC_PRIO_MAX];\n#endif\n\t \n\tstruct otx2_qos\t\tqos;\n\n\t \n\tu32 napi_events;\n\n#if IS_ENABLED(CONFIG_MACSEC)\n\tstruct cn10k_mcs_cfg\t*macsec_cfg;\n#endif\n};\n\nstatic inline bool is_otx2_lbkvf(struct pci_dev *pdev)\n{\n\treturn pdev->device == PCI_DEVID_OCTEONTX2_RVU_AFVF;\n}\n\nstatic inline bool is_96xx_A0(struct pci_dev *pdev)\n{\n\treturn (pdev->revision == 0x00) &&\n\t\t(pdev->subsystem_device == PCI_SUBSYS_DEVID_96XX_RVU_PFVF);\n}\n\nstatic inline bool is_96xx_B0(struct pci_dev *pdev)\n{\n\treturn (pdev->revision == 0x01) &&\n\t\t(pdev->subsystem_device == PCI_SUBSYS_DEVID_96XX_RVU_PFVF);\n}\n\n \n#define PCI_REVISION_ID_96XX\t\t0x00\n#define PCI_REVISION_ID_95XX\t\t0x10\n#define PCI_REVISION_ID_95XXN\t\t0x20\n#define PCI_REVISION_ID_98XX\t\t0x30\n#define PCI_REVISION_ID_95XXMM\t\t0x40\n#define PCI_REVISION_ID_95XXO\t\t0xE0\n\nstatic inline bool is_dev_otx2(struct pci_dev *pdev)\n{\n\tu8 midr = pdev->revision & 0xF0;\n\n\treturn (midr == PCI_REVISION_ID_96XX || midr == PCI_REVISION_ID_95XX ||\n\t\tmidr == PCI_REVISION_ID_95XXN || midr == PCI_REVISION_ID_98XX ||\n\t\tmidr == PCI_REVISION_ID_95XXMM || midr == PCI_REVISION_ID_95XXO);\n}\n\nstatic inline bool is_dev_cn10kb(struct pci_dev *pdev)\n{\n\treturn pdev->subsystem_device == PCI_SUBSYS_DEVID_CN10K_B_RVU_PFVF;\n}\n\nstatic inline void otx2_setup_dev_hw_settings(struct otx2_nic *pfvf)\n{\n\tstruct otx2_hw *hw = &pfvf->hw;\n\n\tpfvf->hw.cq_time_wait = CQ_TIMER_THRESH_DEFAULT;\n\tpfvf->hw.cq_ecount_wait = CQ_CQE_THRESH_DEFAULT;\n\tpfvf->hw.cq_qcount_wait = CQ_QCOUNT_DEFAULT;\n\n\t__set_bit(HW_TSO, &hw->cap_flag);\n\n\tif (is_96xx_A0(pfvf->pdev)) {\n\t\t__clear_bit(HW_TSO, &hw->cap_flag);\n\n\t\t \n\t\tpfvf->hw.cq_qcount_wait = 0x0;\n\n\t\t \n\t\tpfvf->hw.rq_skid = 600;\n\t\tpfvf->qset.rqe_cnt = Q_COUNT(Q_SIZE_1K);\n\t}\n\tif (is_96xx_B0(pfvf->pdev))\n\t\t__clear_bit(HW_TSO, &hw->cap_flag);\n\n\tif (!is_dev_otx2(pfvf->pdev)) {\n\t\t__set_bit(CN10K_MBOX, &hw->cap_flag);\n\t\t__set_bit(CN10K_LMTST, &hw->cap_flag);\n\t\t__set_bit(CN10K_RPM, &hw->cap_flag);\n\t\t__set_bit(CN10K_PTP_ONESTEP, &hw->cap_flag);\n\t\t__set_bit(QOS_CIR_PIR_SUPPORT, &hw->cap_flag);\n\t}\n\n\tif (is_dev_cn10kb(pfvf->pdev))\n\t\t__set_bit(CN10K_HW_MACSEC, &hw->cap_flag);\n}\n\n \nstatic inline void __iomem *otx2_get_regaddr(struct otx2_nic *nic, u64 offset)\n{\n\tu64 blkaddr;\n\n\tswitch ((offset >> RVU_FUNC_BLKADDR_SHIFT) & RVU_FUNC_BLKADDR_MASK) {\n\tcase BLKTYPE_NIX:\n\t\tblkaddr = nic->nix_blkaddr;\n\t\tbreak;\n\tcase BLKTYPE_NPA:\n\t\tblkaddr = BLKADDR_NPA;\n\t\tbreak;\n\tdefault:\n\t\tblkaddr = BLKADDR_RVUM;\n\t\tbreak;\n\t}\n\n\toffset &= ~(RVU_FUNC_BLKADDR_MASK << RVU_FUNC_BLKADDR_SHIFT);\n\toffset |= (blkaddr << RVU_FUNC_BLKADDR_SHIFT);\n\n\treturn nic->reg_base + offset;\n}\n\nstatic inline void otx2_write64(struct otx2_nic *nic, u64 offset, u64 val)\n{\n\tvoid __iomem *addr = otx2_get_regaddr(nic, offset);\n\n\twriteq(val, addr);\n}\n\nstatic inline u64 otx2_read64(struct otx2_nic *nic, u64 offset)\n{\n\tvoid __iomem *addr = otx2_get_regaddr(nic, offset);\n\n\treturn readq(addr);\n}\n\n \nstatic inline int otx2_mbox_bbuf_init(struct mbox *mbox, struct pci_dev *pdev)\n{\n\tstruct otx2_mbox *otx2_mbox;\n\tstruct otx2_mbox_dev *mdev;\n\n\tmbox->bbuf_base = devm_kmalloc(&pdev->dev, MBOX_SIZE, GFP_KERNEL);\n\tif (!mbox->bbuf_base)\n\t\treturn -ENOMEM;\n\n\t \n\totx2_mbox = &mbox->mbox;\n\tmdev = &otx2_mbox->dev[0];\n\tmdev->mbase = mbox->bbuf_base;\n\n\totx2_mbox = &mbox->mbox_up;\n\tmdev = &otx2_mbox->dev[0];\n\tmdev->mbase = mbox->bbuf_base;\n\treturn 0;\n}\n\nstatic inline void otx2_sync_mbox_bbuf(struct otx2_mbox *mbox, int devid)\n{\n\tu16 msgs_offset = ALIGN(sizeof(struct mbox_hdr), MBOX_MSG_ALIGN);\n\tvoid *hw_mbase = mbox->hwbase + (devid * MBOX_SIZE);\n\tstruct otx2_mbox_dev *mdev = &mbox->dev[devid];\n\tstruct mbox_hdr *hdr;\n\tu64 msg_size;\n\n\tif (mdev->mbase == hw_mbase)\n\t\treturn;\n\n\thdr = hw_mbase + mbox->rx_start;\n\tmsg_size = hdr->msg_size;\n\n\tif (msg_size > mbox->rx_size - msgs_offset)\n\t\tmsg_size = mbox->rx_size - msgs_offset;\n\n\t \n\tmemcpy(mdev->mbase + mbox->rx_start,\n\t       hw_mbase + mbox->rx_start, msg_size + msgs_offset);\n}\n\n \n#if defined(CONFIG_ARM64)\nstatic inline void otx2_write128(u64 lo, u64 hi, void __iomem *addr)\n{\n\t__asm__ volatile(\"stp %x[x0], %x[x1], [%x[p1],#0]!\"\n\t\t\t ::[x0]\"r\"(lo), [x1]\"r\"(hi), [p1]\"r\"(addr));\n}\n\nstatic inline u64 otx2_atomic64_add(u64 incr, u64 *ptr)\n{\n\tu64 result;\n\n\t__asm__ volatile(\".cpu   generic+lse\\n\"\n\t\t\t \"ldadd %x[i], %x[r], [%[b]]\"\n\t\t\t : [r]\"=r\"(result), \"+m\"(*ptr)\n\t\t\t : [i]\"r\"(incr), [b]\"r\"(ptr)\n\t\t\t : \"memory\");\n\treturn result;\n}\n\n#else\n#define otx2_write128(lo, hi, addr)\t\twriteq((hi) | (lo), addr)\n#define otx2_atomic64_add(incr, ptr)\t\t({ *ptr += incr; })\n#endif\n\nstatic inline void __cn10k_aura_freeptr(struct otx2_nic *pfvf, u64 aura,\n\t\t\t\t\tu64 *ptrs, u64 num_ptrs)\n{\n\tstruct otx2_lmt_info *lmt_info;\n\tu64 size = 0, count_eot = 0;\n\tu64 tar_addr, val = 0;\n\n\tlmt_info = per_cpu_ptr(pfvf->hw.lmt_info, smp_processor_id());\n\ttar_addr = (__force u64)otx2_get_regaddr(pfvf, NPA_LF_AURA_BATCH_FREE0);\n\t \n\tval = (lmt_info->lmt_id & 0x7FF) | BIT_ULL(63);\n\t \n\tcount_eot = (num_ptrs % 2) ? 0ULL : 1ULL;\n\t \n\tptrs[0] = (count_eot << 32) | (aura & 0xFFFFF);\n\t \n\tif (num_ptrs > 2) {\n\t\tsize = (sizeof(u64) * num_ptrs) / 16;\n\t\tif (!count_eot)\n\t\t\tsize++;\n\t\ttar_addr |=  ((size - 1) & 0x7) << 4;\n\t}\n\tdma_wmb();\n\tmemcpy((u64 *)lmt_info->lmt_addr, ptrs, sizeof(u64) * num_ptrs);\n\t \n\tcn10k_lmt_flush(val, tar_addr);\n}\n\nstatic inline void cn10k_aura_freeptr(void *dev, int aura, u64 buf)\n{\n\tstruct otx2_nic *pfvf = dev;\n\tu64 ptrs[2];\n\n\tptrs[1] = buf;\n\tget_cpu();\n\t \n\t__cn10k_aura_freeptr(pfvf, aura, ptrs, 2);\n\tput_cpu();\n}\n\n \nstatic inline u64 otx2_aura_allocptr(struct otx2_nic *pfvf, int aura)\n{\n\tu64 *ptr = (__force u64 *)otx2_get_regaddr(pfvf, NPA_LF_AURA_OP_ALLOCX(0));\n\tu64 incr = (u64)aura | BIT_ULL(63);\n\n\treturn otx2_atomic64_add(incr, ptr);\n}\n\n \nstatic inline void otx2_aura_freeptr(void *dev, int aura, u64 buf)\n{\n\tstruct otx2_nic *pfvf = dev;\n\tvoid __iomem *addr = otx2_get_regaddr(pfvf, NPA_LF_AURA_OP_FREE0);\n\n\totx2_write128(buf, (u64)aura | BIT_ULL(63), addr);\n}\n\nstatic inline int otx2_get_pool_idx(struct otx2_nic *pfvf, int type, int idx)\n{\n\tif (type == AURA_NIX_SQ)\n\t\treturn pfvf->hw.rqpool_cnt + idx;\n\n\t  \n\treturn idx;\n}\n\n \nstatic inline int otx2_sync_mbox_msg(struct mbox *mbox)\n{\n\tint err;\n\n\tif (!otx2_mbox_nonempty(&mbox->mbox, 0))\n\t\treturn 0;\n\totx2_mbox_msg_send(&mbox->mbox, 0);\n\terr = otx2_mbox_wait_for_rsp(&mbox->mbox, 0);\n\tif (err)\n\t\treturn err;\n\n\treturn otx2_mbox_check_rsp_msgs(&mbox->mbox, 0);\n}\n\nstatic inline int otx2_sync_mbox_up_msg(struct mbox *mbox, int devid)\n{\n\tint err;\n\n\tif (!otx2_mbox_nonempty(&mbox->mbox_up, devid))\n\t\treturn 0;\n\totx2_mbox_msg_send(&mbox->mbox_up, devid);\n\terr = otx2_mbox_wait_for_rsp(&mbox->mbox_up, devid);\n\tif (err)\n\t\treturn err;\n\n\treturn otx2_mbox_check_rsp_msgs(&mbox->mbox_up, devid);\n}\n\n \nstatic inline int otx2_sync_mbox_msg_busy_poll(struct mbox *mbox)\n{\n\tint err;\n\n\tif (!otx2_mbox_nonempty(&mbox->mbox, 0))\n\t\treturn 0;\n\totx2_mbox_msg_send(&mbox->mbox, 0);\n\terr = otx2_mbox_busy_poll_for_rsp(&mbox->mbox, 0);\n\tif (err)\n\t\treturn err;\n\n\treturn otx2_mbox_check_rsp_msgs(&mbox->mbox, 0);\n}\n\n#define M(_name, _id, _fn_name, _req_type, _rsp_type)                   \\\nstatic struct _req_type __maybe_unused\t\t\t\t\t\\\n*otx2_mbox_alloc_msg_ ## _fn_name(struct mbox *mbox)                    \\\n{\t\t\t\t\t\t\t\t\t\\\n\tstruct _req_type *req;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\treq = (struct _req_type *)otx2_mbox_alloc_msg_rsp(\t\t\\\n\t\t&mbox->mbox, 0, sizeof(struct _req_type),\t\t\\\n\t\tsizeof(struct _rsp_type));\t\t\t\t\\\n\tif (!req)\t\t\t\t\t\t\t\\\n\t\treturn NULL;\t\t\t\t\t\t\\\n\treq->hdr.sig = OTX2_MBOX_REQ_SIG;\t\t\t\t\\\n\treq->hdr.id = _id;\t\t\t\t\t\t\\\n\ttrace_otx2_msg_alloc(mbox->mbox.pdev, _id, sizeof(*req));\t\\\n\treturn req;\t\t\t\t\t\t\t\\\n}\n\nMBOX_MESSAGES\n#undef M\n\n#define M(_name, _id, _fn_name, _req_type, _rsp_type)\t\t\t\\\nint\t\t\t\t\t\t\t\t\t\\\notx2_mbox_up_handler_ ## _fn_name(struct otx2_nic *pfvf,\t\t\\\n\t\t\t\tstruct _req_type *req,\t\t\t\\\n\t\t\t\tstruct _rsp_type *rsp);\t\t\t\\\n\nMBOX_UP_CGX_MESSAGES\nMBOX_UP_MCS_MESSAGES\n#undef M\n\n \n#define OTX2_TX_TIMEOUT\t\t(100 * HZ)\n\n#define\tRVU_PFVF_PF_SHIFT\t10\n#define\tRVU_PFVF_PF_MASK\t0x3F\n#define\tRVU_PFVF_FUNC_SHIFT\t0\n#define\tRVU_PFVF_FUNC_MASK\t0x3FF\n\nstatic inline bool is_otx2_vf(u16 pcifunc)\n{\n\treturn !!(pcifunc & RVU_PFVF_FUNC_MASK);\n}\n\nstatic inline int rvu_get_pf(u16 pcifunc)\n{\n\treturn (pcifunc >> RVU_PFVF_PF_SHIFT) & RVU_PFVF_PF_MASK;\n}\n\nstatic inline dma_addr_t otx2_dma_map_page(struct otx2_nic *pfvf,\n\t\t\t\t\t   struct page *page,\n\t\t\t\t\t   size_t offset, size_t size,\n\t\t\t\t\t   enum dma_data_direction dir)\n{\n\tdma_addr_t iova;\n\n\tiova = dma_map_page_attrs(pfvf->dev, page,\n\t\t\t\t  offset, size, dir, DMA_ATTR_SKIP_CPU_SYNC);\n\tif (unlikely(dma_mapping_error(pfvf->dev, iova)))\n\t\treturn (dma_addr_t)NULL;\n\treturn iova;\n}\n\nstatic inline void otx2_dma_unmap_page(struct otx2_nic *pfvf,\n\t\t\t\t       dma_addr_t addr, size_t size,\n\t\t\t\t       enum dma_data_direction dir)\n{\n\tdma_unmap_page_attrs(pfvf->dev, addr, size,\n\t\t\t     dir, DMA_ATTR_SKIP_CPU_SYNC);\n}\n\nstatic inline u16 otx2_get_smq_idx(struct otx2_nic *pfvf, u16 qidx)\n{\n\tu16 smq;\n#ifdef CONFIG_DCB\n\tif (qidx < NIX_PF_PFC_PRIO_MAX && pfvf->pfc_alloc_status[qidx])\n\t\treturn pfvf->pfc_schq_list[NIX_TXSCH_LVL_SMQ][qidx];\n#endif\n\t \n\tif (qidx >= pfvf->hw.non_qos_queues)\n\t\tsmq = pfvf->qos.qid_to_sqmap[qidx - pfvf->hw.non_qos_queues];\n\telse\n\t\tsmq = pfvf->hw.txschq_list[NIX_TXSCH_LVL_SMQ][0];\n\n\treturn smq;\n}\n\nstatic inline u16 otx2_get_total_tx_queues(struct otx2_nic *pfvf)\n{\n\treturn pfvf->hw.non_qos_queues + pfvf->hw.tc_tx_queues;\n}\n\nstatic inline u64 otx2_convert_rate(u64 rate)\n{\n\tu64 converted_rate;\n\n\t \n\tconverted_rate = rate * 8;\n\tconverted_rate = max_t(u64, converted_rate / 1000000, 1);\n\n\treturn converted_rate;\n}\n\nstatic inline int otx2_tc_flower_rule_cnt(struct otx2_nic *pfvf)\n{\n\t \n\tif (!pfvf->flow_cfg)\n\t\treturn 0;\n\n\treturn pfvf->flow_cfg->nr_flows;\n}\n\n \nvoid otx2_free_cints(struct otx2_nic *pfvf, int n);\nvoid otx2_set_cints_affinity(struct otx2_nic *pfvf);\nint otx2_set_mac_address(struct net_device *netdev, void *p);\nint otx2_hw_set_mtu(struct otx2_nic *pfvf, int mtu);\nvoid otx2_tx_timeout(struct net_device *netdev, unsigned int txq);\nvoid otx2_get_mac_from_af(struct net_device *netdev);\nvoid otx2_config_irq_coalescing(struct otx2_nic *pfvf, int qidx);\nint otx2_config_pause_frm(struct otx2_nic *pfvf);\nvoid otx2_setup_segmentation(struct otx2_nic *pfvf);\n\n \nint otx2_attach_npa_nix(struct otx2_nic *pfvf);\nint otx2_detach_resources(struct mbox *mbox);\nint otx2_config_npa(struct otx2_nic *pfvf);\nint otx2_sq_aura_pool_init(struct otx2_nic *pfvf);\nint otx2_rq_aura_pool_init(struct otx2_nic *pfvf);\nvoid otx2_aura_pool_free(struct otx2_nic *pfvf);\nvoid otx2_free_aura_ptr(struct otx2_nic *pfvf, int type);\nvoid otx2_sq_free_sqbs(struct otx2_nic *pfvf);\nint otx2_config_nix(struct otx2_nic *pfvf);\nint otx2_config_nix_queues(struct otx2_nic *pfvf);\nint otx2_txschq_config(struct otx2_nic *pfvf, int lvl, int prio, bool pfc_en);\nint otx2_txsch_alloc(struct otx2_nic *pfvf);\nvoid otx2_txschq_stop(struct otx2_nic *pfvf);\nvoid otx2_txschq_free_one(struct otx2_nic *pfvf, u16 lvl, u16 schq);\nvoid otx2_free_pending_sqe(struct otx2_nic *pfvf);\nvoid otx2_sqb_flush(struct otx2_nic *pfvf);\nint otx2_alloc_rbuf(struct otx2_nic *pfvf, struct otx2_pool *pool,\n\t\t    dma_addr_t *dma);\nint otx2_rxtx_enable(struct otx2_nic *pfvf, bool enable);\nvoid otx2_ctx_disable(struct mbox *mbox, int type, bool npa);\nint otx2_nix_config_bp(struct otx2_nic *pfvf, bool enable);\nvoid otx2_cleanup_rx_cqes(struct otx2_nic *pfvf, struct otx2_cq_queue *cq, int qidx);\nvoid otx2_cleanup_tx_cqes(struct otx2_nic *pfvf, struct otx2_cq_queue *cq);\nint otx2_sq_init(struct otx2_nic *pfvf, u16 qidx, u16 sqb_aura);\nint otx2_sq_aq_init(void *dev, u16 qidx, u16 sqb_aura);\nint cn10k_sq_aq_init(void *dev, u16 qidx, u16 sqb_aura);\nint otx2_alloc_buffer(struct otx2_nic *pfvf, struct otx2_cq_queue *cq,\n\t\t      dma_addr_t *dma);\nint otx2_pool_init(struct otx2_nic *pfvf, u16 pool_id,\n\t\t   int stack_pages, int numptrs, int buf_size, int type);\nint otx2_aura_init(struct otx2_nic *pfvf, int aura_id,\n\t\t   int pool_id, int numptrs);\n\n \nint otx2_rss_init(struct otx2_nic *pfvf);\nint otx2_set_flowkey_cfg(struct otx2_nic *pfvf);\nvoid otx2_set_rss_key(struct otx2_nic *pfvf);\nint otx2_set_rss_table(struct otx2_nic *pfvf, int ctx_id);\n\n \nvoid mbox_handler_msix_offset(struct otx2_nic *pfvf,\n\t\t\t      struct msix_offset_rsp *rsp);\nvoid mbox_handler_npa_lf_alloc(struct otx2_nic *pfvf,\n\t\t\t       struct npa_lf_alloc_rsp *rsp);\nvoid mbox_handler_nix_lf_alloc(struct otx2_nic *pfvf,\n\t\t\t       struct nix_lf_alloc_rsp *rsp);\nvoid mbox_handler_nix_txsch_alloc(struct otx2_nic *pf,\n\t\t\t\t  struct nix_txsch_alloc_rsp *rsp);\nvoid mbox_handler_cgx_stats(struct otx2_nic *pfvf,\n\t\t\t    struct cgx_stats_rsp *rsp);\nvoid mbox_handler_cgx_fec_stats(struct otx2_nic *pfvf,\n\t\t\t\tstruct cgx_fec_stats_rsp *rsp);\nvoid otx2_set_fec_stats_count(struct otx2_nic *pfvf);\nvoid mbox_handler_nix_bp_enable(struct otx2_nic *pfvf,\n\t\t\t\tstruct nix_bp_cfg_rsp *rsp);\n\n \nvoid otx2_get_dev_stats(struct otx2_nic *pfvf);\nvoid otx2_get_stats64(struct net_device *netdev,\n\t\t      struct rtnl_link_stats64 *stats);\nvoid otx2_update_lmac_stats(struct otx2_nic *pfvf);\nvoid otx2_update_lmac_fec_stats(struct otx2_nic *pfvf);\nint otx2_update_rq_stats(struct otx2_nic *pfvf, int qidx);\nint otx2_update_sq_stats(struct otx2_nic *pfvf, int qidx);\nvoid otx2_set_ethtool_ops(struct net_device *netdev);\nvoid otx2vf_set_ethtool_ops(struct net_device *netdev);\n\nint otx2_open(struct net_device *netdev);\nint otx2_stop(struct net_device *netdev);\nint otx2_set_real_num_queues(struct net_device *netdev,\n\t\t\t     int tx_queues, int rx_queues);\nint otx2_ioctl(struct net_device *netdev, struct ifreq *req, int cmd);\nint otx2_config_hwtstamp(struct net_device *netdev, struct ifreq *ifr);\n\n \nint otx2_mcam_flow_init(struct otx2_nic *pf);\nint otx2vf_mcam_flow_init(struct otx2_nic *pfvf);\nint otx2_alloc_mcam_entries(struct otx2_nic *pfvf, u16 count);\nvoid otx2_mcam_flow_del(struct otx2_nic *pf);\nint otx2_destroy_ntuple_flows(struct otx2_nic *pf);\nint otx2_destroy_mcam_flows(struct otx2_nic *pfvf);\nint otx2_get_flow(struct otx2_nic *pfvf,\n\t\t  struct ethtool_rxnfc *nfc, u32 location);\nint otx2_get_all_flows(struct otx2_nic *pfvf,\n\t\t       struct ethtool_rxnfc *nfc, u32 *rule_locs);\nint otx2_add_flow(struct otx2_nic *pfvf,\n\t\t  struct ethtool_rxnfc *nfc);\nint otx2_remove_flow(struct otx2_nic *pfvf, u32 location);\nint otx2_get_maxflows(struct otx2_flow_config *flow_cfg);\nvoid otx2_rss_ctx_flow_del(struct otx2_nic *pfvf, int ctx_id);\nint otx2_del_macfilter(struct net_device *netdev, const u8 *mac);\nint otx2_add_macfilter(struct net_device *netdev, const u8 *mac);\nint otx2_enable_rxvlan(struct otx2_nic *pf, bool enable);\nint otx2_install_rxvlan_offload_flow(struct otx2_nic *pfvf);\nbool otx2_xdp_sq_append_pkt(struct otx2_nic *pfvf, u64 iova, int len, u16 qidx);\nu16 otx2_get_max_mtu(struct otx2_nic *pfvf);\nint otx2_handle_ntuple_tc_features(struct net_device *netdev,\n\t\t\t\t   netdev_features_t features);\nint otx2_smq_flush(struct otx2_nic *pfvf, int smq);\nvoid otx2_free_bufs(struct otx2_nic *pfvf, struct otx2_pool *pool,\n\t\t    u64 iova, int size);\n\n \nint otx2_init_tc(struct otx2_nic *nic);\nvoid otx2_shutdown_tc(struct otx2_nic *nic);\nint otx2_setup_tc(struct net_device *netdev, enum tc_setup_type type,\n\t\t  void *type_data);\nvoid otx2_tc_apply_ingress_police_rules(struct otx2_nic *nic);\n\n \nint otx2_dmacflt_get_max_cnt(struct otx2_nic *pf);\nint otx2_dmacflt_add(struct otx2_nic *pf, const u8 *mac, u32 bit_pos);\nint otx2_dmacflt_remove(struct otx2_nic *pf, const u8 *mac, u32 bit_pos);\nint otx2_dmacflt_update(struct otx2_nic *pf, u8 *mac, u32 bit_pos);\nvoid otx2_dmacflt_reinstall_flows(struct otx2_nic *pf);\nvoid otx2_dmacflt_update_pfmac_flow(struct otx2_nic *pfvf);\n\n#ifdef CONFIG_DCB\n \nvoid otx2_update_bpid_in_rqctx(struct otx2_nic *pfvf, int vlan_prio, int qidx, bool pfc_enable);\nint otx2_config_priority_flow_ctrl(struct otx2_nic *pfvf);\nint otx2_dcbnl_set_ops(struct net_device *dev);\n \nint otx2_pfc_txschq_config(struct otx2_nic *pfvf);\nint otx2_pfc_txschq_alloc(struct otx2_nic *pfvf);\nint otx2_pfc_txschq_update(struct otx2_nic *pfvf);\nint otx2_pfc_txschq_stop(struct otx2_nic *pfvf);\n#endif\n\n#if IS_ENABLED(CONFIG_MACSEC)\n \nint cn10k_mcs_init(struct otx2_nic *pfvf);\nvoid cn10k_mcs_free(struct otx2_nic *pfvf);\nvoid cn10k_handle_mcs_event(struct otx2_nic *pfvf, struct mcs_intr_info *event);\n#else\nstatic inline int cn10k_mcs_init(struct otx2_nic *pfvf) { return 0; }\nstatic inline void cn10k_mcs_free(struct otx2_nic *pfvf) {}\nstatic inline void cn10k_handle_mcs_event(struct otx2_nic *pfvf,\n\t\t\t\t\t  struct mcs_intr_info *event)\n{}\n#endif  \n\n \nstatic inline void otx2_qos_init(struct otx2_nic *pfvf, int qos_txqs)\n{\n\tstruct otx2_hw *hw = &pfvf->hw;\n\n\thw->tc_tx_queues = qos_txqs;\n\tINIT_LIST_HEAD(&pfvf->qos.qos_tree);\n\tmutex_init(&pfvf->qos.qos_lock);\n}\n\nstatic inline void otx2_shutdown_qos(struct otx2_nic *pfvf)\n{\n\tmutex_destroy(&pfvf->qos.qos_lock);\n}\n\nu16 otx2_select_queue(struct net_device *netdev, struct sk_buff *skb,\n\t\t      struct net_device *sb_dev);\nint otx2_get_txq_by_classid(struct otx2_nic *pfvf, u16 classid);\nvoid otx2_qos_config_txschq(struct otx2_nic *pfvf);\nvoid otx2_clean_qos_queues(struct otx2_nic *pfvf);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}