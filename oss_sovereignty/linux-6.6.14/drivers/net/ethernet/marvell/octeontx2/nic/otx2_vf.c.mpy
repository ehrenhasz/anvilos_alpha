{
  "module_name": "otx2_vf.c",
  "hash_id": "4e5c81545cd0821cb30b5d5dc60a7aeb6308b84c2db1e6a6a7a2618f54186486",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/nic/otx2_vf.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/net_tstamp.h>\n\n#include \"otx2_common.h\"\n#include \"otx2_reg.h\"\n#include \"otx2_ptp.h\"\n#include \"cn10k.h\"\n\n#define DRV_NAME\t\"rvu_nicvf\"\n#define DRV_STRING\t\"Marvell RVU NIC Virtual Function Driver\"\n\nstatic const struct pci_device_id otx2_vf_id_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_OCTEONTX2_RVU_AFVF) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_OCTEONTX2_RVU_VF) },\n\t{ }\n};\n\nMODULE_AUTHOR(\"Sunil Goutham <sgoutham@marvell.com>\");\nMODULE_DESCRIPTION(DRV_STRING);\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DEVICE_TABLE(pci, otx2_vf_id_table);\n\n \nenum {\n\tRVU_VF_INT_VEC_MBOX = 0x0,\n};\n\nstatic void otx2vf_process_vfaf_mbox_msg(struct otx2_nic *vf,\n\t\t\t\t\t struct mbox_msghdr *msg)\n{\n\tif (msg->id >= MBOX_MSG_MAX) {\n\t\tdev_err(vf->dev,\n\t\t\t\"Mbox msg with unknown ID %d\\n\", msg->id);\n\t\treturn;\n\t}\n\n\tif (msg->sig != OTX2_MBOX_RSP_SIG) {\n\t\tdev_err(vf->dev,\n\t\t\t\"Mbox msg with wrong signature %x, ID %d\\n\",\n\t\t\tmsg->sig, msg->id);\n\t\treturn;\n\t}\n\n\tif (msg->rc == MBOX_MSG_INVALID) {\n\t\tdev_err(vf->dev,\n\t\t\t\"PF/AF says the sent msg(s) %d were invalid\\n\",\n\t\t\tmsg->id);\n\t\treturn;\n\t}\n\n\tswitch (msg->id) {\n\tcase MBOX_MSG_READY:\n\t\tvf->pcifunc = msg->pcifunc;\n\t\tbreak;\n\tcase MBOX_MSG_MSIX_OFFSET:\n\t\tmbox_handler_msix_offset(vf, (struct msix_offset_rsp *)msg);\n\t\tbreak;\n\tcase MBOX_MSG_NPA_LF_ALLOC:\n\t\tmbox_handler_npa_lf_alloc(vf, (struct npa_lf_alloc_rsp *)msg);\n\t\tbreak;\n\tcase MBOX_MSG_NIX_LF_ALLOC:\n\t\tmbox_handler_nix_lf_alloc(vf, (struct nix_lf_alloc_rsp *)msg);\n\t\tbreak;\n\tcase MBOX_MSG_NIX_BP_ENABLE:\n\t\tmbox_handler_nix_bp_enable(vf, (struct nix_bp_cfg_rsp *)msg);\n\t\tbreak;\n\tdefault:\n\t\tif (msg->rc)\n\t\t\tdev_err(vf->dev,\n\t\t\t\t\"Mbox msg response has err %d, ID %d\\n\",\n\t\t\t\tmsg->rc, msg->id);\n\t}\n}\n\nstatic void otx2vf_vfaf_mbox_handler(struct work_struct *work)\n{\n\tstruct otx2_mbox_dev *mdev;\n\tstruct mbox_hdr *rsp_hdr;\n\tstruct mbox_msghdr *msg;\n\tstruct otx2_mbox *mbox;\n\tstruct mbox *af_mbox;\n\tint offset, id;\n\n\taf_mbox = container_of(work, struct mbox, mbox_wrk);\n\tmbox = &af_mbox->mbox;\n\tmdev = &mbox->dev[0];\n\trsp_hdr = (struct mbox_hdr *)(mdev->mbase + mbox->rx_start);\n\tif (af_mbox->num_msgs == 0)\n\t\treturn;\n\toffset = mbox->rx_start + ALIGN(sizeof(*rsp_hdr), MBOX_MSG_ALIGN);\n\n\tfor (id = 0; id < af_mbox->num_msgs; id++) {\n\t\tmsg = (struct mbox_msghdr *)(mdev->mbase + offset);\n\t\totx2vf_process_vfaf_mbox_msg(af_mbox->pfvf, msg);\n\t\toffset = mbox->rx_start + msg->next_msgoff;\n\t\tif (mdev->msgs_acked == (af_mbox->num_msgs - 1))\n\t\t\t__otx2_mbox_reset(mbox, 0);\n\t\tmdev->msgs_acked++;\n\t}\n}\n\nstatic int otx2vf_process_mbox_msg_up(struct otx2_nic *vf,\n\t\t\t\t      struct mbox_msghdr *req)\n{\n\tstruct msg_rsp *rsp;\n\tint err;\n\n\t \n\tif (req->sig != OTX2_MBOX_REQ_SIG) {\n\t\totx2_reply_invalid_msg(&vf->mbox.mbox_up, 0, 0, req->id);\n\t\treturn -ENODEV;\n\t}\n\n\tswitch (req->id) {\n\tcase MBOX_MSG_CGX_LINK_EVENT:\n\t\trsp = (struct msg_rsp *)otx2_mbox_alloc_msg(\n\t\t\t\t\t\t&vf->mbox.mbox_up, 0,\n\t\t\t\t\t\tsizeof(struct msg_rsp));\n\t\tif (!rsp)\n\t\t\treturn -ENOMEM;\n\n\t\trsp->hdr.id = MBOX_MSG_CGX_LINK_EVENT;\n\t\trsp->hdr.sig = OTX2_MBOX_RSP_SIG;\n\t\trsp->hdr.pcifunc = 0;\n\t\trsp->hdr.rc = 0;\n\t\terr = otx2_mbox_up_handler_cgx_link_event(\n\t\t\t\tvf, (struct cgx_link_info_msg *)req, rsp);\n\t\treturn err;\n\tdefault:\n\t\totx2_reply_invalid_msg(&vf->mbox.mbox_up, 0, 0, req->id);\n\t\treturn -ENODEV;\n\t}\n\treturn 0;\n}\n\nstatic void otx2vf_vfaf_mbox_up_handler(struct work_struct *work)\n{\n\tstruct otx2_mbox_dev *mdev;\n\tstruct mbox_hdr *rsp_hdr;\n\tstruct mbox_msghdr *msg;\n\tstruct otx2_mbox *mbox;\n\tstruct mbox *vf_mbox;\n\tstruct otx2_nic *vf;\n\tint offset, id;\n\n\tvf_mbox = container_of(work, struct mbox, mbox_up_wrk);\n\tvf = vf_mbox->pfvf;\n\tmbox = &vf_mbox->mbox_up;\n\tmdev = &mbox->dev[0];\n\n\trsp_hdr = (struct mbox_hdr *)(mdev->mbase + mbox->rx_start);\n\tif (vf_mbox->up_num_msgs == 0)\n\t\treturn;\n\n\toffset = mbox->rx_start + ALIGN(sizeof(*rsp_hdr), MBOX_MSG_ALIGN);\n\n\tfor (id = 0; id < vf_mbox->up_num_msgs; id++) {\n\t\tmsg = (struct mbox_msghdr *)(mdev->mbase + offset);\n\t\totx2vf_process_mbox_msg_up(vf, msg);\n\t\toffset = mbox->rx_start + msg->next_msgoff;\n\t}\n\n\totx2_mbox_msg_send(mbox, 0);\n}\n\nstatic irqreturn_t otx2vf_vfaf_mbox_intr_handler(int irq, void *vf_irq)\n{\n\tstruct otx2_nic *vf = (struct otx2_nic *)vf_irq;\n\tstruct otx2_mbox_dev *mdev;\n\tstruct otx2_mbox *mbox;\n\tstruct mbox_hdr *hdr;\n\n\t \n\totx2_write64(vf, RVU_VF_INT, BIT_ULL(0));\n\n\t \n\tsmp_rmb();\n\n\t \n\tmbox = &vf->mbox.mbox;\n\tmdev = &mbox->dev[0];\n\totx2_sync_mbox_bbuf(mbox, 0);\n\n\ttrace_otx2_msg_interrupt(mbox->pdev, \"PF to VF\", BIT_ULL(0));\n\n\thdr = (struct mbox_hdr *)(mdev->mbase + mbox->rx_start);\n\tif (hdr->num_msgs) {\n\t\tvf->mbox.num_msgs = hdr->num_msgs;\n\t\thdr->num_msgs = 0;\n\t\tmemset(mbox->hwbase + mbox->rx_start, 0,\n\t\t       ALIGN(sizeof(struct mbox_hdr), sizeof(u64)));\n\t\tqueue_work(vf->mbox_wq, &vf->mbox.mbox_wrk);\n\t}\n\t \n\tmbox = &vf->mbox.mbox_up;\n\tmdev = &mbox->dev[0];\n\totx2_sync_mbox_bbuf(mbox, 0);\n\n\thdr = (struct mbox_hdr *)(mdev->mbase + mbox->rx_start);\n\tif (hdr->num_msgs) {\n\t\tvf->mbox.up_num_msgs = hdr->num_msgs;\n\t\thdr->num_msgs = 0;\n\t\tmemset(mbox->hwbase + mbox->rx_start, 0,\n\t\t       ALIGN(sizeof(struct mbox_hdr), sizeof(u64)));\n\t\tqueue_work(vf->mbox_wq, &vf->mbox.mbox_up_wrk);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void otx2vf_disable_mbox_intr(struct otx2_nic *vf)\n{\n\tint vector = pci_irq_vector(vf->pdev, RVU_VF_INT_VEC_MBOX);\n\n\t \n\totx2_write64(vf, RVU_VF_INT_ENA_W1C, BIT_ULL(0));\n\tfree_irq(vector, vf);\n}\n\nstatic int otx2vf_register_mbox_intr(struct otx2_nic *vf, bool probe_pf)\n{\n\tstruct otx2_hw *hw = &vf->hw;\n\tstruct msg_req *req;\n\tchar *irq_name;\n\tint err;\n\n\t \n\tirq_name = &hw->irq_name[RVU_VF_INT_VEC_MBOX * NAME_SIZE];\n\tsnprintf(irq_name, NAME_SIZE, \"RVUVFAF Mbox\");\n\terr = request_irq(pci_irq_vector(vf->pdev, RVU_VF_INT_VEC_MBOX),\n\t\t\t  otx2vf_vfaf_mbox_intr_handler, 0, irq_name, vf);\n\tif (err) {\n\t\tdev_err(vf->dev,\n\t\t\t\"RVUPF: IRQ registration failed for VFAF mbox irq\\n\");\n\t\treturn err;\n\t}\n\n\t \n\totx2_write64(vf, RVU_VF_INT, BIT_ULL(0));\n\totx2_write64(vf, RVU_VF_INT_ENA_W1S, BIT_ULL(0));\n\n\tif (!probe_pf)\n\t\treturn 0;\n\n\t \n\treq = otx2_mbox_alloc_msg_ready(&vf->mbox);\n\tif (!req) {\n\t\totx2vf_disable_mbox_intr(vf);\n\t\treturn -ENOMEM;\n\t}\n\n\terr = otx2_sync_mbox_msg(&vf->mbox);\n\tif (err) {\n\t\tdev_warn(vf->dev,\n\t\t\t \"AF not responding to mailbox, deferring probe\\n\");\n\t\totx2vf_disable_mbox_intr(vf);\n\t\treturn -EPROBE_DEFER;\n\t}\n\treturn 0;\n}\n\nstatic void otx2vf_vfaf_mbox_destroy(struct otx2_nic *vf)\n{\n\tstruct mbox *mbox = &vf->mbox;\n\n\tif (vf->mbox_wq) {\n\t\tdestroy_workqueue(vf->mbox_wq);\n\t\tvf->mbox_wq = NULL;\n\t}\n\n\tif (mbox->mbox.hwbase && !test_bit(CN10K_MBOX, &vf->hw.cap_flag))\n\t\tiounmap((void __iomem *)mbox->mbox.hwbase);\n\n\totx2_mbox_destroy(&mbox->mbox);\n\totx2_mbox_destroy(&mbox->mbox_up);\n}\n\nstatic int otx2vf_vfaf_mbox_init(struct otx2_nic *vf)\n{\n\tstruct mbox *mbox = &vf->mbox;\n\tvoid __iomem *hwbase;\n\tint err;\n\n\tmbox->pfvf = vf;\n\tvf->mbox_wq = alloc_ordered_workqueue(\"otx2_vfaf_mailbox\",\n\t\t\t\t\t      WQ_HIGHPRI | WQ_MEM_RECLAIM);\n\tif (!vf->mbox_wq)\n\t\treturn -ENOMEM;\n\n\tif (test_bit(CN10K_MBOX, &vf->hw.cap_flag)) {\n\t\t \n\t\thwbase = vf->reg_base + RVU_VF_MBOX_REGION;\n\t} else {\n\t\t \n\t\thwbase = ioremap_wc(pci_resource_start(vf->pdev,\n\t\t\t\t\t\t       PCI_MBOX_BAR_NUM),\n\t\t\t\t    pci_resource_len(vf->pdev,\n\t\t\t\t\t\t     PCI_MBOX_BAR_NUM));\n\t\tif (!hwbase) {\n\t\t\tdev_err(vf->dev, \"Unable to map VFAF mailbox region\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\terr = otx2_mbox_init(&mbox->mbox, hwbase, vf->pdev, vf->reg_base,\n\t\t\t     MBOX_DIR_VFPF, 1);\n\tif (err)\n\t\tgoto exit;\n\n\terr = otx2_mbox_init(&mbox->mbox_up, hwbase, vf->pdev, vf->reg_base,\n\t\t\t     MBOX_DIR_VFPF_UP, 1);\n\tif (err)\n\t\tgoto exit;\n\n\terr = otx2_mbox_bbuf_init(mbox, vf->pdev);\n\tif (err)\n\t\tgoto exit;\n\n\tINIT_WORK(&mbox->mbox_wrk, otx2vf_vfaf_mbox_handler);\n\tINIT_WORK(&mbox->mbox_up_wrk, otx2vf_vfaf_mbox_up_handler);\n\tmutex_init(&mbox->lock);\n\n\treturn 0;\nexit:\n\tif (hwbase && !test_bit(CN10K_MBOX, &vf->hw.cap_flag))\n\t\tiounmap(hwbase);\n\tdestroy_workqueue(vf->mbox_wq);\n\treturn err;\n}\n\nstatic int otx2vf_open(struct net_device *netdev)\n{\n\tstruct otx2_nic *vf;\n\tint err;\n\n\terr = otx2_open(netdev);\n\tif (err)\n\t\treturn err;\n\n\t \n\tvf = netdev_priv(netdev);\n\tif (is_otx2_lbkvf(vf->pdev)) {\n\t\tpr_info(\"%s NIC Link is UP\\n\", netdev->name);\n\t\tnetif_carrier_on(netdev);\n\t\tnetif_tx_start_all_queues(netdev);\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2vf_stop(struct net_device *netdev)\n{\n\treturn otx2_stop(netdev);\n}\n\nstatic netdev_tx_t otx2vf_xmit(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct otx2_nic *vf = netdev_priv(netdev);\n\tint qidx = skb_get_queue_mapping(skb);\n\tstruct otx2_snd_queue *sq;\n\tstruct netdev_queue *txq;\n\n\tsq = &vf->qset.sq[qidx];\n\ttxq = netdev_get_tx_queue(netdev, qidx);\n\n\tif (!otx2_sq_append_skb(netdev, sq, skb, qidx)) {\n\t\tnetif_tx_stop_queue(txq);\n\n\t\t \n\t\tsmp_mb();\n\t\tif (((sq->num_sqbs - *sq->aura_fc_addr) * sq->sqe_per_sqb)\n\t\t\t\t\t\t\t> sq->sqe_thresh)\n\t\t\tnetif_tx_wake_queue(txq);\n\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void otx2vf_set_rx_mode(struct net_device *netdev)\n{\n\tstruct otx2_nic *vf = netdev_priv(netdev);\n\n\tqueue_work(vf->otx2_wq, &vf->rx_mode_work);\n}\n\nstatic void otx2vf_do_set_rx_mode(struct work_struct *work)\n{\n\tstruct otx2_nic *vf = container_of(work, struct otx2_nic, rx_mode_work);\n\tstruct net_device *netdev = vf->netdev;\n\tunsigned int flags = netdev->flags;\n\tstruct nix_rx_mode *req;\n\n\tmutex_lock(&vf->mbox.lock);\n\n\treq = otx2_mbox_alloc_msg_nix_set_rx_mode(&vf->mbox);\n\tif (!req) {\n\t\tmutex_unlock(&vf->mbox.lock);\n\t\treturn;\n\t}\n\n\treq->mode = NIX_RX_MODE_UCAST;\n\n\tif (flags & IFF_PROMISC)\n\t\treq->mode |= NIX_RX_MODE_PROMISC;\n\tif (flags & (IFF_ALLMULTI | IFF_MULTICAST))\n\t\treq->mode |= NIX_RX_MODE_ALLMULTI;\n\n\treq->mode |= NIX_RX_MODE_USE_MCE;\n\n\totx2_sync_mbox_msg(&vf->mbox);\n\n\tmutex_unlock(&vf->mbox.lock);\n}\n\nstatic int otx2vf_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tbool if_up = netif_running(netdev);\n\tint err = 0;\n\n\tif (if_up)\n\t\totx2vf_stop(netdev);\n\n\tnetdev_info(netdev, \"Changing MTU from %d to %d\\n\",\n\t\t    netdev->mtu, new_mtu);\n\tnetdev->mtu = new_mtu;\n\n\tif (if_up)\n\t\terr = otx2vf_open(netdev);\n\n\treturn err;\n}\n\nstatic void otx2vf_reset_task(struct work_struct *work)\n{\n\tstruct otx2_nic *vf = container_of(work, struct otx2_nic, reset_task);\n\n\trtnl_lock();\n\n\tif (netif_running(vf->netdev)) {\n\t\totx2vf_stop(vf->netdev);\n\t\tvf->reset_count++;\n\t\totx2vf_open(vf->netdev);\n\t}\n\n\trtnl_unlock();\n}\n\nstatic int otx2vf_set_features(struct net_device *netdev,\n\t\t\t       netdev_features_t features)\n{\n\treturn otx2_handle_ntuple_tc_features(netdev, features);\n}\n\nstatic const struct net_device_ops otx2vf_netdev_ops = {\n\t.ndo_open = otx2vf_open,\n\t.ndo_stop = otx2vf_stop,\n\t.ndo_start_xmit = otx2vf_xmit,\n\t.ndo_select_queue = otx2_select_queue,\n\t.ndo_set_rx_mode = otx2vf_set_rx_mode,\n\t.ndo_set_mac_address = otx2_set_mac_address,\n\t.ndo_change_mtu = otx2vf_change_mtu,\n\t.ndo_set_features = otx2vf_set_features,\n\t.ndo_get_stats64 = otx2_get_stats64,\n\t.ndo_tx_timeout = otx2_tx_timeout,\n\t.ndo_eth_ioctl\t= otx2_ioctl,\n\t.ndo_setup_tc = otx2_setup_tc,\n};\n\nstatic int otx2_wq_init(struct otx2_nic *vf)\n{\n\tvf->otx2_wq = create_singlethread_workqueue(\"otx2vf_wq\");\n\tif (!vf->otx2_wq)\n\t\treturn -ENOMEM;\n\n\tINIT_WORK(&vf->rx_mode_work, otx2vf_do_set_rx_mode);\n\tINIT_WORK(&vf->reset_task, otx2vf_reset_task);\n\treturn 0;\n}\n\nstatic int otx2vf_realloc_msix_vectors(struct otx2_nic *vf)\n{\n\tstruct otx2_hw *hw = &vf->hw;\n\tint num_vec, err;\n\n\tnum_vec = hw->nix_msixoff;\n\tnum_vec += NIX_LF_CINT_VEC_START + hw->max_queues;\n\n\totx2vf_disable_mbox_intr(vf);\n\tpci_free_irq_vectors(hw->pdev);\n\terr = pci_alloc_irq_vectors(hw->pdev, num_vec, num_vec, PCI_IRQ_MSIX);\n\tif (err < 0) {\n\t\tdev_err(vf->dev, \"%s: Failed to realloc %d IRQ vectors\\n\",\n\t\t\t__func__, num_vec);\n\t\treturn err;\n\t}\n\n\treturn otx2vf_register_mbox_intr(vf, false);\n}\n\nstatic int otx2vf_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tint num_vec = pci_msix_vec_count(pdev);\n\tstruct device *dev = &pdev->dev;\n\tint err, qcount, qos_txqs;\n\tstruct net_device *netdev;\n\tstruct otx2_nic *vf;\n\tstruct otx2_hw *hw;\n\n\terr = pcim_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to enable PCI device\\n\");\n\t\treturn err;\n\t}\n\n\terr = pci_request_regions(pdev, DRV_NAME);\n\tif (err) {\n\t\tdev_err(dev, \"PCI request regions failed 0x%x\\n\", err);\n\t\treturn err;\n\t}\n\n\terr = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(48));\n\tif (err) {\n\t\tdev_err(dev, \"DMA mask config failed, abort\\n\");\n\t\tgoto err_release_regions;\n\t}\n\n\tpci_set_master(pdev);\n\n\tqcount = num_online_cpus();\n\tqos_txqs = min_t(int, qcount, OTX2_QOS_MAX_LEAF_NODES);\n\tnetdev = alloc_etherdev_mqs(sizeof(*vf), qcount + qos_txqs, qcount);\n\tif (!netdev) {\n\t\terr = -ENOMEM;\n\t\tgoto err_release_regions;\n\t}\n\n\tpci_set_drvdata(pdev, netdev);\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\tvf = netdev_priv(netdev);\n\tvf->netdev = netdev;\n\tvf->pdev = pdev;\n\tvf->dev = dev;\n\tvf->iommu_domain = iommu_get_domain_for_dev(dev);\n\n\tvf->flags |= OTX2_FLAG_INTF_DOWN;\n\thw = &vf->hw;\n\thw->pdev = vf->pdev;\n\thw->rx_queues = qcount;\n\thw->tx_queues = qcount;\n\thw->max_queues = qcount;\n\thw->non_qos_queues = qcount;\n\thw->rbuf_len = OTX2_DEFAULT_RBUF_LEN;\n\t \n\thw->xqe_size = 128;\n\n\thw->irq_name = devm_kmalloc_array(&hw->pdev->dev, num_vec, NAME_SIZE,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!hw->irq_name) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_netdev;\n\t}\n\n\thw->affinity_mask = devm_kcalloc(&hw->pdev->dev, num_vec,\n\t\t\t\t\t sizeof(cpumask_var_t), GFP_KERNEL);\n\tif (!hw->affinity_mask) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_netdev;\n\t}\n\n\terr = pci_alloc_irq_vectors(hw->pdev, num_vec, num_vec, PCI_IRQ_MSIX);\n\tif (err < 0) {\n\t\tdev_err(dev, \"%s: Failed to alloc %d IRQ vectors\\n\",\n\t\t\t__func__, num_vec);\n\t\tgoto err_free_netdev;\n\t}\n\n\tvf->reg_base = pcim_iomap(pdev, PCI_CFG_REG_BAR_NUM, 0);\n\tif (!vf->reg_base) {\n\t\tdev_err(dev, \"Unable to map physical function CSRs, aborting\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_free_irq_vectors;\n\t}\n\n\totx2_setup_dev_hw_settings(vf);\n\t \n\terr = otx2vf_vfaf_mbox_init(vf);\n\tif (err)\n\t\tgoto err_free_irq_vectors;\n\n\t \n\terr = otx2vf_register_mbox_intr(vf, true);\n\tif (err)\n\t\tgoto err_mbox_destroy;\n\n\t \n\terr = otx2_attach_npa_nix(vf);\n\tif (err)\n\t\tgoto err_disable_mbox_intr;\n\n\terr = otx2vf_realloc_msix_vectors(vf);\n\tif (err)\n\t\tgoto err_detach_rsrc;\n\n\terr = otx2_set_real_num_queues(netdev, qcount, qcount);\n\tif (err)\n\t\tgoto err_detach_rsrc;\n\n\terr = cn10k_lmtst_init(vf);\n\tif (err)\n\t\tgoto err_detach_rsrc;\n\n\t \n\totx2_ptp_init(vf);\n\n\t \n\totx2_get_mac_from_af(netdev);\n\n\tnetdev->hw_features = NETIF_F_RXCSUM | NETIF_F_IP_CSUM |\n\t\t\t      NETIF_F_IPV6_CSUM | NETIF_F_RXHASH |\n\t\t\t      NETIF_F_SG | NETIF_F_TSO | NETIF_F_TSO6 |\n\t\t\t      NETIF_F_GSO_UDP_L4;\n\tnetdev->features = netdev->hw_features;\n\t \n\tnetdev->vlan_features |= netdev->features;\n\tnetdev->hw_features  |= NETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\tNETIF_F_HW_VLAN_STAG_TX;\n\tnetdev->features |= netdev->hw_features;\n\n\tnetdev->hw_features |= NETIF_F_NTUPLE;\n\tnetdev->hw_features |= NETIF_F_RXALL;\n\tnetdev->hw_features |= NETIF_F_HW_TC;\n\n\tnetif_set_tso_max_segs(netdev, OTX2_MAX_GSO_SEGS);\n\tnetdev->watchdog_timeo = OTX2_TX_TIMEOUT;\n\n\tnetdev->netdev_ops = &otx2vf_netdev_ops;\n\n\tnetdev->min_mtu = OTX2_MIN_MTU;\n\tnetdev->max_mtu = otx2_get_max_mtu(vf);\n\n\t \n\tif (is_otx2_lbkvf(vf->pdev)) {\n\t\tint n;\n\n\t\tn = (vf->pcifunc >> RVU_PFVF_FUNC_SHIFT) & RVU_PFVF_FUNC_MASK;\n\t\t \n\t\tn -= 1;\n\t\tsnprintf(netdev->name, sizeof(netdev->name), \"lbk%d\", n);\n\t}\n\n\terr = register_netdev(netdev);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to register netdevice\\n\");\n\t\tgoto err_ptp_destroy;\n\t}\n\n\terr = otx2_wq_init(vf);\n\tif (err)\n\t\tgoto err_unreg_netdev;\n\n\totx2vf_set_ethtool_ops(netdev);\n\n\terr = otx2vf_mcam_flow_init(vf);\n\tif (err)\n\t\tgoto err_unreg_netdev;\n\n\terr = otx2_init_tc(vf);\n\tif (err)\n\t\tgoto err_unreg_netdev;\n\n\terr = otx2_register_dl(vf);\n\tif (err)\n\t\tgoto err_shutdown_tc;\n\n#ifdef CONFIG_DCB\n\terr = otx2_dcbnl_set_ops(netdev);\n\tif (err)\n\t\tgoto err_shutdown_tc;\n#endif\n\totx2_qos_init(vf, qos_txqs);\n\n\treturn 0;\n\nerr_shutdown_tc:\n\totx2_shutdown_tc(vf);\nerr_unreg_netdev:\n\tunregister_netdev(netdev);\nerr_ptp_destroy:\n\totx2_ptp_destroy(vf);\nerr_detach_rsrc:\n\tfree_percpu(vf->hw.lmt_info);\n\tif (test_bit(CN10K_LMTST, &vf->hw.cap_flag))\n\t\tqmem_free(vf->dev, vf->dync_lmt);\n\totx2_detach_resources(&vf->mbox);\nerr_disable_mbox_intr:\n\totx2vf_disable_mbox_intr(vf);\nerr_mbox_destroy:\n\totx2vf_vfaf_mbox_destroy(vf);\nerr_free_irq_vectors:\n\tpci_free_irq_vectors(hw->pdev);\nerr_free_netdev:\n\tpci_set_drvdata(pdev, NULL);\n\tfree_netdev(netdev);\nerr_release_regions:\n\tpci_release_regions(pdev);\n\treturn err;\n}\n\nstatic void otx2vf_remove(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct otx2_nic *vf;\n\n\tif (!netdev)\n\t\treturn;\n\n\tvf = netdev_priv(netdev);\n\n\t \n\tif (vf->flags & OTX2_FLAG_RX_PAUSE_ENABLED ||\n\t    (vf->flags & OTX2_FLAG_TX_PAUSE_ENABLED)) {\n\t\tvf->flags &= ~OTX2_FLAG_RX_PAUSE_ENABLED;\n\t\tvf->flags &= ~OTX2_FLAG_TX_PAUSE_ENABLED;\n\t\totx2_config_pause_frm(vf);\n\t}\n\n#ifdef CONFIG_DCB\n\t \n\tif (vf->pfc_en) {\n\t\tvf->pfc_en = 0;\n\t\totx2_config_priority_flow_ctrl(vf);\n\t}\n#endif\n\n\tcancel_work_sync(&vf->reset_task);\n\totx2_unregister_dl(vf);\n\tunregister_netdev(netdev);\n\tif (vf->otx2_wq)\n\t\tdestroy_workqueue(vf->otx2_wq);\n\totx2_ptp_destroy(vf);\n\totx2_mcam_flow_del(vf);\n\totx2_shutdown_tc(vf);\n\totx2_shutdown_qos(vf);\n\totx2vf_disable_mbox_intr(vf);\n\totx2_detach_resources(&vf->mbox);\n\tfree_percpu(vf->hw.lmt_info);\n\tif (test_bit(CN10K_LMTST, &vf->hw.cap_flag))\n\t\tqmem_free(vf->dev, vf->dync_lmt);\n\totx2vf_vfaf_mbox_destroy(vf);\n\tpci_free_irq_vectors(vf->pdev);\n\tpci_set_drvdata(pdev, NULL);\n\tfree_netdev(netdev);\n\n\tpci_release_regions(pdev);\n}\n\nstatic struct pci_driver otx2vf_driver = {\n\t.name = DRV_NAME,\n\t.id_table = otx2_vf_id_table,\n\t.probe = otx2vf_probe,\n\t.remove = otx2vf_remove,\n\t.shutdown = otx2vf_remove,\n};\n\nstatic int __init otx2vf_init_module(void)\n{\n\tpr_info(\"%s: %s\\n\", DRV_NAME, DRV_STRING);\n\n\treturn pci_register_driver(&otx2vf_driver);\n}\n\nstatic void __exit otx2vf_cleanup_module(void)\n{\n\tpci_unregister_driver(&otx2vf_driver);\n}\n\nmodule_init(otx2vf_init_module);\nmodule_exit(otx2vf_cleanup_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}