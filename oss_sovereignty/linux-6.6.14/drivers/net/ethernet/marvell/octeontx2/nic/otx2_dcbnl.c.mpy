{
  "module_name": "otx2_dcbnl.c",
  "hash_id": "f99725866795efadbd1927444922b8de8c2e2424b8d73f4c009cdcaa90f43671",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/nic/otx2_dcbnl.c",
  "human_readable_source": "\n \n\n#include \"otx2_common.h\"\n\nstatic int otx2_check_pfc_config(struct otx2_nic *pfvf)\n{\n\tu8 tx_queues = pfvf->hw.tx_queues, prio;\n\tu8 pfc_en = pfvf->pfc_en;\n\n\tfor (prio = 0; prio < NIX_PF_PFC_PRIO_MAX; prio++) {\n\t\tif ((pfc_en & (1 << prio)) &&\n\t\t    prio > tx_queues - 1) {\n\t\t\tdev_warn(pfvf->dev,\n\t\t\t\t \"Increase number of tx queues from %d to %d to support PFC.\\n\",\n\t\t\t\t tx_queues, prio + 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint otx2_pfc_txschq_config(struct otx2_nic *pfvf)\n{\n\tu8 pfc_en, pfc_bit_set;\n\tint prio, lvl, err;\n\n\tpfc_en = pfvf->pfc_en;\n\tfor (prio = 0; prio < NIX_PF_PFC_PRIO_MAX; prio++) {\n\t\tpfc_bit_set = pfc_en & (1 << prio);\n\n\t\t \n\t\tif (!pfc_bit_set || !pfvf->pfc_alloc_status[prio])\n\t\t\tcontinue;\n\n\t\t \n\t\tfor (lvl = 0; lvl < NIX_TXSCH_LVL_CNT; lvl++) {\n\t\t\terr = otx2_txschq_config(pfvf, lvl, prio, true);\n\t\t\tif (err) {\n\t\t\t\tdev_err(pfvf->dev,\n\t\t\t\t\t\"%s configure PFC tx schq for lvl:%d, prio:%d failed!\\n\",\n\t\t\t\t\t__func__, lvl, prio);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2_pfc_txschq_alloc_one(struct otx2_nic *pfvf, u8 prio)\n{\n\tstruct nix_txsch_alloc_req *req;\n\tstruct nix_txsch_alloc_rsp *rsp;\n\tint lvl, rc;\n\n\t \n\treq = otx2_mbox_alloc_msg_nix_txsch_alloc(&pfvf->mbox);\n\tif (!req)\n\t\treturn -ENOMEM;\n\n\t \n\tfor (lvl = 0; lvl <= pfvf->hw.txschq_link_cfg_lvl; lvl++)\n\t\treq->schq[lvl] = 1;\n\n\trc = otx2_sync_mbox_msg(&pfvf->mbox);\n\tif (rc)\n\t\treturn rc;\n\n\trsp = (struct nix_txsch_alloc_rsp *)\n\t      otx2_mbox_get_rsp(&pfvf->mbox.mbox, 0, &req->hdr);\n\tif (IS_ERR(rsp))\n\t\treturn PTR_ERR(rsp);\n\n\t \n\tfor (lvl = 0; lvl <= pfvf->hw.txschq_link_cfg_lvl; lvl++) {\n\t\tif (!rsp->schq[lvl])\n\t\t\treturn -ENOSPC;\n\n\t\tpfvf->pfc_schq_list[lvl][prio] = rsp->schq_list[lvl][0];\n\t}\n\n\t \n\tfor (; lvl < NIX_TXSCH_LVL_CNT; lvl++)\n\t\tpfvf->pfc_schq_list[lvl][prio] = pfvf->hw.txschq_list[lvl][0];\n\n\tpfvf->pfc_alloc_status[prio] = true;\n\treturn 0;\n}\n\nint otx2_pfc_txschq_alloc(struct otx2_nic *pfvf)\n{\n\tu8 pfc_en = pfvf->pfc_en;\n\tu8 pfc_bit_set;\n\tint err, prio;\n\n\tfor (prio = 0; prio < NIX_PF_PFC_PRIO_MAX; prio++) {\n\t\tpfc_bit_set = pfc_en & (1 << prio);\n\n\t\tif (!pfc_bit_set || pfvf->pfc_alloc_status[prio])\n\t\t\tcontinue;\n\n\t\t \n\t\terr = otx2_pfc_txschq_alloc_one(pfvf, prio);\n\t\tif (err) {\n\t\t\tdev_err(pfvf->dev, \"%s failed to allocate PFC TX schedulers\\n\", __func__);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int otx2_pfc_txschq_stop_one(struct otx2_nic *pfvf, u8 prio)\n{\n\tint lvl;\n\n\t \n\tfor (lvl = 0; lvl <= pfvf->hw.txschq_link_cfg_lvl; lvl++)\n\t\totx2_txschq_free_one(pfvf, lvl,\n\t\t\t\t     pfvf->pfc_schq_list[lvl][prio]);\n\n\tpfvf->pfc_alloc_status[prio] = false;\n\treturn 0;\n}\n\nstatic int otx2_pfc_update_sq_smq_mapping(struct otx2_nic *pfvf, int prio)\n{\n\tstruct nix_cn10k_aq_enq_req *cn10k_sq_aq;\n\tstruct net_device *dev = pfvf->netdev;\n\tbool if_up = netif_running(dev);\n\tstruct nix_aq_enq_req *sq_aq;\n\n\tif (if_up) {\n\t\tif (pfvf->pfc_alloc_status[prio])\n\t\t\tnetif_tx_stop_all_queues(pfvf->netdev);\n\t\telse\n\t\t\tnetif_tx_stop_queue(netdev_get_tx_queue(dev, prio));\n\t}\n\n\tif (test_bit(CN10K_LMTST, &pfvf->hw.cap_flag)) {\n\t\tcn10k_sq_aq = otx2_mbox_alloc_msg_nix_cn10k_aq_enq(&pfvf->mbox);\n\t\tif (!cn10k_sq_aq)\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\tcn10k_sq_aq->qidx = prio;\n\t\tcn10k_sq_aq->ctype = NIX_AQ_CTYPE_SQ;\n\t\tcn10k_sq_aq->op = NIX_AQ_INSTOP_WRITE;\n\n\t\t \n\t\tcn10k_sq_aq->sq.ena = 1;\n\t\tcn10k_sq_aq->sq_mask.ena = 1;\n\t\tcn10k_sq_aq->sq_mask.smq = GENMASK(9, 0);\n\t\tcn10k_sq_aq->sq.smq = otx2_get_smq_idx(pfvf, prio);\n\t} else {\n\t\tsq_aq = otx2_mbox_alloc_msg_nix_aq_enq(&pfvf->mbox);\n\t\tif (!sq_aq)\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\tsq_aq->qidx = prio;\n\t\tsq_aq->ctype = NIX_AQ_CTYPE_SQ;\n\t\tsq_aq->op = NIX_AQ_INSTOP_WRITE;\n\n\t\t \n\t\tsq_aq->sq.ena = 1;\n\t\tsq_aq->sq_mask.ena = 1;\n\t\tsq_aq->sq_mask.smq = GENMASK(8, 0);\n\t\tsq_aq->sq.smq = otx2_get_smq_idx(pfvf, prio);\n\t}\n\n\totx2_sync_mbox_msg(&pfvf->mbox);\n\n\tif (if_up) {\n\t\tif (pfvf->pfc_alloc_status[prio])\n\t\t\tnetif_tx_start_all_queues(pfvf->netdev);\n\t\telse\n\t\t\tnetif_tx_start_queue(netdev_get_tx_queue(dev, prio));\n\t}\n\n\treturn 0;\n}\n\nint otx2_pfc_txschq_update(struct otx2_nic *pfvf)\n{\n\tbool if_up = netif_running(pfvf->netdev);\n\tu8 pfc_en = pfvf->pfc_en, pfc_bit_set;\n\tstruct mbox *mbox = &pfvf->mbox;\n\tint err, prio;\n\n\tmutex_lock(&mbox->lock);\n\tfor (prio = 0; prio < NIX_PF_PFC_PRIO_MAX; prio++) {\n\t\tpfc_bit_set = pfc_en & (1 << prio);\n\n\t\t \n\t\tif (!pfc_bit_set && pfvf->pfc_alloc_status[prio]) {\n\t\t\tmutex_unlock(&mbox->lock);\n\t\t\tif (if_up)\n\t\t\t\tnetif_tx_stop_all_queues(pfvf->netdev);\n\n\t\t\totx2_smq_flush(pfvf, pfvf->pfc_schq_list[NIX_TXSCH_LVL_SMQ][prio]);\n\t\t\tif (if_up)\n\t\t\t\tnetif_tx_start_all_queues(pfvf->netdev);\n\n\t\t\t \n\t\t\terr = otx2_pfc_txschq_stop_one(pfvf, prio);\n\t\t\tif (err) {\n\t\t\t\tdev_err(pfvf->dev,\n\t\t\t\t\t\"%s failed to stop PFC tx schedulers for priority: %d\\n\",\n\t\t\t\t\t__func__, prio);\n\t\t\t\treturn err;\n\t\t\t}\n\n\t\t\tmutex_lock(&mbox->lock);\n\t\t\tgoto update_sq_smq_map;\n\t\t}\n\n\t\t \n\t\tif (!pfc_bit_set || pfvf->pfc_alloc_status[prio])\n\t\t\tcontinue;\n\n\t\t \n\t\terr = otx2_pfc_txschq_alloc_one(pfvf, prio);\n\t\tif (err) {\n\t\t\tmutex_unlock(&mbox->lock);\n\t\t\tdev_err(pfvf->dev,\n\t\t\t\t\"%s failed to allocate PFC tx schedulers for priority: %d\\n\",\n\t\t\t\t__func__, prio);\n\t\t\treturn err;\n\t\t}\n\nupdate_sq_smq_map:\n\t\terr = otx2_pfc_update_sq_smq_mapping(pfvf, prio);\n\t\tif (err) {\n\t\t\tmutex_unlock(&mbox->lock);\n\t\t\tdev_err(pfvf->dev, \"%s failed PFC Tx schq sq:%d mapping\", __func__, prio);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\terr = otx2_pfc_txschq_config(pfvf);\n\tmutex_unlock(&mbox->lock);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nint otx2_pfc_txschq_stop(struct otx2_nic *pfvf)\n{\n\tu8 pfc_en, pfc_bit_set;\n\tint prio, err;\n\n\tpfc_en = pfvf->pfc_en;\n\tfor (prio = 0; prio < NIX_PF_PFC_PRIO_MAX; prio++) {\n\t\tpfc_bit_set = pfc_en & (1 << prio);\n\t\tif (!pfc_bit_set || !pfvf->pfc_alloc_status[prio])\n\t\t\tcontinue;\n\n\t\t \n\t\terr = otx2_pfc_txschq_stop_one(pfvf, prio);\n\t\tif (err) {\n\t\t\tdev_err(pfvf->dev, \"%s failed to stop PFC TX schedulers\\n\", __func__);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint otx2_config_priority_flow_ctrl(struct otx2_nic *pfvf)\n{\n\tstruct cgx_pfc_cfg *req;\n\tstruct cgx_pfc_rsp *rsp;\n\tint err = 0;\n\n\tif (is_otx2_lbkvf(pfvf->pdev))\n\t\treturn 0;\n\n\tmutex_lock(&pfvf->mbox.lock);\n\treq = otx2_mbox_alloc_msg_cgx_prio_flow_ctrl_cfg(&pfvf->mbox);\n\tif (!req) {\n\t\terr = -ENOMEM;\n\t\tgoto unlock;\n\t}\n\n\tif (pfvf->pfc_en) {\n\t\treq->rx_pause = true;\n\t\treq->tx_pause = true;\n\t} else {\n\t\treq->rx_pause = false;\n\t\treq->tx_pause = false;\n\t}\n\treq->pfc_en = pfvf->pfc_en;\n\n\tif (!otx2_sync_mbox_msg(&pfvf->mbox)) {\n\t\trsp = (struct cgx_pfc_rsp *)\n\t\t       otx2_mbox_get_rsp(&pfvf->mbox.mbox, 0, &req->hdr);\n\t\tif (req->rx_pause != rsp->rx_pause || req->tx_pause != rsp->tx_pause) {\n\t\t\tdev_warn(pfvf->dev,\n\t\t\t\t \"Failed to config PFC\\n\");\n\t\t\terr = -EPERM;\n\t\t}\n\t}\nunlock:\n\tmutex_unlock(&pfvf->mbox.lock);\n\treturn err;\n}\n\nvoid otx2_update_bpid_in_rqctx(struct otx2_nic *pfvf, int vlan_prio, int qidx,\n\t\t\t       bool pfc_enable)\n{\n\tbool if_up = netif_running(pfvf->netdev);\n\tstruct npa_aq_enq_req *npa_aq;\n\tstruct nix_aq_enq_req *aq;\n\tint err = 0;\n\n\tif (pfvf->queue_to_pfc_map[qidx] && pfc_enable) {\n\t\tdev_warn(pfvf->dev,\n\t\t\t \"PFC enable not permitted as Priority %d already mapped to Queue %d\\n\",\n\t\t\t pfvf->queue_to_pfc_map[qidx], qidx);\n\t\treturn;\n\t}\n\n\tif (if_up) {\n\t\tnetif_tx_stop_all_queues(pfvf->netdev);\n\t\tnetif_carrier_off(pfvf->netdev);\n\t}\n\n\tpfvf->queue_to_pfc_map[qidx] = vlan_prio;\n\n\taq = otx2_mbox_alloc_msg_nix_aq_enq(&pfvf->mbox);\n\tif (!aq) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\taq->cq.bpid = pfvf->bpid[vlan_prio];\n\taq->cq_mask.bpid = GENMASK(8, 0);\n\n\t \n\taq->qidx = qidx;\n\taq->ctype = NIX_AQ_CTYPE_CQ;\n\taq->op = NIX_AQ_INSTOP_WRITE;\n\n\totx2_sync_mbox_msg(&pfvf->mbox);\n\n\tnpa_aq = otx2_mbox_alloc_msg_npa_aq_enq(&pfvf->mbox);\n\tif (!npa_aq) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\tnpa_aq->aura.nix0_bpid = pfvf->bpid[vlan_prio];\n\tnpa_aq->aura_mask.nix0_bpid = GENMASK(8, 0);\n\n\t \n\tnpa_aq->aura_id = qidx;\n\tnpa_aq->ctype = NPA_AQ_CTYPE_AURA;\n\tnpa_aq->op = NPA_AQ_INSTOP_WRITE;\n\totx2_sync_mbox_msg(&pfvf->mbox);\n\nout:\n\tif (if_up) {\n\t\tnetif_carrier_on(pfvf->netdev);\n\t\tnetif_tx_start_all_queues(pfvf->netdev);\n\t}\n\n\tif (err)\n\t\tdev_warn(pfvf->dev,\n\t\t\t \"Updating BPIDs in CQ and Aura contexts of RQ%d failed with err %d\\n\",\n\t\t\t qidx, err);\n}\n\nstatic int otx2_dcbnl_ieee_getpfc(struct net_device *dev, struct ieee_pfc *pfc)\n{\n\tstruct otx2_nic *pfvf = netdev_priv(dev);\n\n\tpfc->pfc_cap = IEEE_8021QAZ_MAX_TCS;\n\tpfc->pfc_en = pfvf->pfc_en;\n\n\treturn 0;\n}\n\nstatic int otx2_dcbnl_ieee_setpfc(struct net_device *dev, struct ieee_pfc *pfc)\n{\n\tstruct otx2_nic *pfvf = netdev_priv(dev);\n\tu8 old_pfc_en;\n\tint err;\n\n\told_pfc_en = pfvf->pfc_en;\n\tpfvf->pfc_en = pfc->pfc_en;\n\n\tif (pfvf->hw.tx_queues >= NIX_PF_PFC_PRIO_MAX)\n\t\tgoto process_pfc;\n\n\t \n\terr = otx2_check_pfc_config(pfvf);\n\tif (err) {\n\t\tpfvf->pfc_en = old_pfc_en;\n\t\treturn err;\n\t}\n\nprocess_pfc:\n\terr = otx2_config_priority_flow_ctrl(pfvf);\n\tif (err) {\n\t\tpfvf->pfc_en = old_pfc_en;\n\t\treturn err;\n\t}\n\n\t \n\tif (pfc->pfc_en)\n\t\totx2_nix_config_bp(pfvf, true);\n\n\terr = otx2_pfc_txschq_update(pfvf);\n\tif (err) {\n\t\tif (pfc->pfc_en)\n\t\t\totx2_nix_config_bp(pfvf, false);\n\n\t\totx2_pfc_txschq_stop(pfvf);\n\t\tpfvf->pfc_en = old_pfc_en;\n\t\totx2_config_priority_flow_ctrl(pfvf);\n\t\tdev_err(pfvf->dev, \"%s failed to update TX schedulers\\n\", __func__);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic u8 otx2_dcbnl_getdcbx(struct net_device __always_unused *dev)\n{\n\treturn DCB_CAP_DCBX_HOST | DCB_CAP_DCBX_VER_IEEE;\n}\n\nstatic u8 otx2_dcbnl_setdcbx(struct net_device __always_unused *dev, u8 mode)\n{\n\treturn (mode != (DCB_CAP_DCBX_HOST | DCB_CAP_DCBX_VER_IEEE)) ? 1 : 0;\n}\n\nstatic const struct dcbnl_rtnl_ops otx2_dcbnl_ops = {\n\t.ieee_getpfc\t= otx2_dcbnl_ieee_getpfc,\n\t.ieee_setpfc\t= otx2_dcbnl_ieee_setpfc,\n\t.getdcbx\t= otx2_dcbnl_getdcbx,\n\t.setdcbx\t= otx2_dcbnl_setdcbx,\n};\n\nint otx2_dcbnl_set_ops(struct net_device *dev)\n{\n\tstruct otx2_nic *pfvf = netdev_priv(dev);\n\n\tpfvf->queue_to_pfc_map = devm_kzalloc(pfvf->dev, pfvf->hw.rx_queues,\n\t\t\t\t\t      GFP_KERNEL);\n\tif (!pfvf->queue_to_pfc_map)\n\t\treturn -ENOMEM;\n\tdev->dcbnl_ops = &otx2_dcbnl_ops;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}