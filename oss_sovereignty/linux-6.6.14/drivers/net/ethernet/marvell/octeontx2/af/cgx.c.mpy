{
  "module_name": "cgx.c",
  "hash_id": "f519f3b1bfb65f505790007dd06ea89424031a4a9ac4f4cce511d4a4f3579609",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/af/cgx.c",
  "human_readable_source": "\n \n\n#include <linux/acpi.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/phy.h>\n#include <linux/of.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n\n#include \"cgx.h\"\n#include \"rvu.h\"\n#include \"lmac_common.h\"\n\n#define DRV_NAME\t\"Marvell-CGX/RPM\"\n#define DRV_STRING      \"Marvell CGX/RPM Driver\"\n\nstatic LIST_HEAD(cgx_list);\n\n \nstatic const u32 cgx_speed_mbps[CGX_LINK_SPEED_MAX] = {\n\t[CGX_LINK_NONE] = 0,\n\t[CGX_LINK_10M] = 10,\n\t[CGX_LINK_100M] = 100,\n\t[CGX_LINK_1G] = 1000,\n\t[CGX_LINK_2HG] = 2500,\n\t[CGX_LINK_5G] = 5000,\n\t[CGX_LINK_10G] = 10000,\n\t[CGX_LINK_20G] = 20000,\n\t[CGX_LINK_25G] = 25000,\n\t[CGX_LINK_40G] = 40000,\n\t[CGX_LINK_50G] = 50000,\n\t[CGX_LINK_80G] = 80000,\n\t[CGX_LINK_100G] = 100000,\n};\n\n \nstatic const char *cgx_lmactype_string[LMAC_MODE_MAX] = {\n\t[LMAC_MODE_SGMII] = \"SGMII\",\n\t[LMAC_MODE_XAUI] = \"XAUI\",\n\t[LMAC_MODE_RXAUI] = \"RXAUI\",\n\t[LMAC_MODE_10G_R] = \"10G_R\",\n\t[LMAC_MODE_40G_R] = \"40G_R\",\n\t[LMAC_MODE_QSGMII] = \"QSGMII\",\n\t[LMAC_MODE_25G_R] = \"25G_R\",\n\t[LMAC_MODE_50G_R] = \"50G_R\",\n\t[LMAC_MODE_100G_R] = \"100G_R\",\n\t[LMAC_MODE_USXGMII] = \"USXGMII\",\n\t[LMAC_MODE_USGMII] = \"USGMII\",\n};\n\n \nstatic int cgx_fwi_link_change(struct cgx *cgx, int lmac_id, bool en);\n\n \nstatic const struct pci_device_id cgx_id_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_OCTEONTX2_CGX) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CN10K_RPM) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CN10KB_RPM) },\n\t{ 0, }   \n};\n\nMODULE_DEVICE_TABLE(pci, cgx_id_table);\n\nstatic bool is_dev_rpm(void *cgxd)\n{\n\tstruct cgx *cgx = cgxd;\n\n\treturn (cgx->pdev->device == PCI_DEVID_CN10K_RPM) ||\n\t       (cgx->pdev->device == PCI_DEVID_CN10KB_RPM);\n}\n\nbool is_lmac_valid(struct cgx *cgx, int lmac_id)\n{\n\tif (!cgx || lmac_id < 0 || lmac_id >= cgx->max_lmac_per_mac)\n\t\treturn false;\n\treturn test_bit(lmac_id, &cgx->lmac_bmap);\n}\n\n \nstatic int get_sequence_id_of_lmac(struct cgx *cgx, int lmac_id)\n{\n\tint tmp, id = 0;\n\n\tfor_each_set_bit(tmp, &cgx->lmac_bmap, cgx->max_lmac_per_mac) {\n\t\tif (tmp == lmac_id)\n\t\t\tbreak;\n\t\tid++;\n\t}\n\n\treturn id;\n}\n\nstruct mac_ops *get_mac_ops(void *cgxd)\n{\n\tif (!cgxd)\n\t\treturn cgxd;\n\n\treturn ((struct cgx *)cgxd)->mac_ops;\n}\n\nvoid cgx_write(struct cgx *cgx, u64 lmac, u64 offset, u64 val)\n{\n\twriteq(val, cgx->reg_base + (lmac << cgx->mac_ops->lmac_offset) +\n\t       offset);\n}\n\nu64 cgx_read(struct cgx *cgx, u64 lmac, u64 offset)\n{\n\treturn readq(cgx->reg_base + (lmac << cgx->mac_ops->lmac_offset) +\n\t\t     offset);\n}\n\nstruct lmac *lmac_pdata(u8 lmac_id, struct cgx *cgx)\n{\n\tif (!cgx || lmac_id >= cgx->max_lmac_per_mac)\n\t\treturn NULL;\n\n\treturn cgx->lmac_idmap[lmac_id];\n}\n\nint cgx_get_cgxcnt_max(void)\n{\n\tstruct cgx *cgx_dev;\n\tint idmax = -ENODEV;\n\n\tlist_for_each_entry(cgx_dev, &cgx_list, cgx_list)\n\t\tif (cgx_dev->cgx_id > idmax)\n\t\t\tidmax = cgx_dev->cgx_id;\n\n\tif (idmax < 0)\n\t\treturn 0;\n\n\treturn idmax + 1;\n}\n\nint cgx_get_lmac_cnt(void *cgxd)\n{\n\tstruct cgx *cgx = cgxd;\n\n\tif (!cgx)\n\t\treturn -ENODEV;\n\n\treturn cgx->lmac_count;\n}\n\nvoid *cgx_get_pdata(int cgx_id)\n{\n\tstruct cgx *cgx_dev;\n\n\tlist_for_each_entry(cgx_dev, &cgx_list, cgx_list) {\n\t\tif (cgx_dev->cgx_id == cgx_id)\n\t\t\treturn cgx_dev;\n\t}\n\treturn NULL;\n}\n\nvoid cgx_lmac_write(int cgx_id, int lmac_id, u64 offset, u64 val)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\n\t \n\tif (!is_lmac_valid(cgx_dev, lmac_id))\n\t\treturn;\n\tcgx_write(cgx_dev, lmac_id, offset, val);\n}\n\nu64 cgx_lmac_read(int cgx_id, int lmac_id, u64 offset)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\n\t \n\tif (!is_lmac_valid(cgx_dev, lmac_id))\n\t\treturn 0;\n\n\treturn cgx_read(cgx_dev, lmac_id, offset);\n}\n\nint cgx_get_cgxid(void *cgxd)\n{\n\tstruct cgx *cgx = cgxd;\n\n\tif (!cgx)\n\t\treturn -EINVAL;\n\n\treturn cgx->cgx_id;\n}\n\nu8 cgx_lmac_get_p2x(int cgx_id, int lmac_id)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tu64 cfg;\n\n\tcfg = cgx_read(cgx_dev, lmac_id, CGXX_CMRX_CFG);\n\n\treturn (cfg & CMR_P2X_SEL_MASK) >> CMR_P2X_SEL_SHIFT;\n}\n\n \nint cgx_get_link_info(void *cgxd, int lmac_id,\n\t\t      struct cgx_link_user_info *linfo)\n{\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgxd);\n\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\t*linfo = lmac->link_info;\n\treturn 0;\n}\n\nint cgx_lmac_addr_set(u8 cgx_id, u8 lmac_id, u8 *mac_addr)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgx_dev);\n\tstruct mac_ops *mac_ops;\n\tint index, id;\n\tu64 cfg;\n\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\t \n\tmac_ops = cgx_dev->mac_ops;\n\n\t \n\t \n\n\tcfg = ether_addr_to_u64(mac_addr);\n\n\tid = get_sequence_id_of_lmac(cgx_dev, lmac_id);\n\n\tindex = id * lmac->mac_to_index_bmap.max;\n\n\tcgx_write(cgx_dev, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 0x8)),\n\t\t  cfg | CGX_DMAC_CAM_ADDR_ENABLE | ((u64)lmac_id << 49));\n\n\tcfg = cgx_read(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0);\n\tcfg |= (CGX_DMAC_CTL0_CAM_ENABLE | CGX_DMAC_BCAST_MODE |\n\t\tCGX_DMAC_MCAST_MODE);\n\tcgx_write(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0, cfg);\n\n\treturn 0;\n}\n\nu64 cgx_read_dmac_ctrl(void *cgxd, int lmac_id)\n{\n\tstruct mac_ops *mac_ops;\n\tstruct cgx *cgx = cgxd;\n\n\tif (!cgxd || !is_lmac_valid(cgxd, lmac_id))\n\t\treturn 0;\n\n\tcgx = cgxd;\n\t \n\tmac_ops = cgx->mac_ops;\n\n\treturn cgx_read(cgxd, lmac_id, CGXX_CMRX_RX_DMAC_CTL0);\n}\n\nu64 cgx_read_dmac_entry(void *cgxd, int index)\n{\n\tstruct mac_ops *mac_ops;\n\tstruct cgx *cgx;\n\n\tif (!cgxd)\n\t\treturn 0;\n\n\tcgx = cgxd;\n\tmac_ops = cgx->mac_ops;\n\treturn cgx_read(cgx, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 8)));\n}\n\nint cgx_lmac_addr_add(u8 cgx_id, u8 lmac_id, u8 *mac_addr)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgx_dev);\n\tstruct mac_ops *mac_ops;\n\tint index, idx;\n\tu64 cfg = 0;\n\tint id;\n\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\tmac_ops = cgx_dev->mac_ops;\n\t \n\tidx = rvu_alloc_rsrc(&lmac->mac_to_index_bmap);\n\tif (idx < 0)\n\t\treturn idx;\n\n\tid = get_sequence_id_of_lmac(cgx_dev, lmac_id);\n\n\tindex = id * lmac->mac_to_index_bmap.max + idx;\n\n\tcfg = ether_addr_to_u64(mac_addr);\n\tcfg |= CGX_DMAC_CAM_ADDR_ENABLE;\n\tcfg |= ((u64)lmac_id << 49);\n\tcgx_write(cgx_dev, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 0x8)), cfg);\n\n\tcfg = cgx_read(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0);\n\tcfg |= (CGX_DMAC_BCAST_MODE | CGX_DMAC_CAM_ACCEPT);\n\n\tif (is_multicast_ether_addr(mac_addr)) {\n\t\tcfg &= ~GENMASK_ULL(2, 1);\n\t\tcfg |= CGX_DMAC_MCAST_MODE_CAM;\n\t\tlmac->mcast_filters_count++;\n\t} else if (!lmac->mcast_filters_count) {\n\t\tcfg |= CGX_DMAC_MCAST_MODE;\n\t}\n\n\tcgx_write(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0, cfg);\n\n\treturn idx;\n}\n\nint cgx_lmac_addr_reset(u8 cgx_id, u8 lmac_id)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgx_dev);\n\tstruct mac_ops *mac_ops;\n\tu8 index = 0, id;\n\tu64 cfg;\n\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\tmac_ops = cgx_dev->mac_ops;\n\t \n\tset_bit(0, lmac->mac_to_index_bmap.bmap);\n\n\tid = get_sequence_id_of_lmac(cgx_dev, lmac_id);\n\n\tindex = id * lmac->mac_to_index_bmap.max + index;\n\tcgx_write(cgx_dev, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 0x8)), 0);\n\n\t \n\tcfg = cgx_read(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0);\n\tcfg &= ~CGX_DMAC_CAM_ACCEPT;\n\tcfg |= (CGX_DMAC_BCAST_MODE | CGX_DMAC_MCAST_MODE);\n\tcgx_write(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0, cfg);\n\n\treturn 0;\n}\n\n \nint cgx_lmac_addr_update(u8 cgx_id, u8 lmac_id, u8 *mac_addr, u8 index)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tstruct mac_ops *mac_ops;\n\tstruct lmac *lmac;\n\tu64 cfg;\n\tint id;\n\n\tlmac = lmac_pdata(lmac_id, cgx_dev);\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\tmac_ops = cgx_dev->mac_ops;\n\t \n\tif (index >= lmac->mac_to_index_bmap.max)\n\t\treturn -EINVAL;\n\n\t \n\tif (!test_bit(index, lmac->mac_to_index_bmap.bmap))\n\t\treturn -EINVAL;\n\n\tid = get_sequence_id_of_lmac(cgx_dev, lmac_id);\n\n\tindex = id * lmac->mac_to_index_bmap.max + index;\n\n\tcfg = cgx_read(cgx_dev, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 0x8)));\n\tcfg &= ~CGX_RX_DMAC_ADR_MASK;\n\tcfg |= ether_addr_to_u64(mac_addr);\n\n\tcgx_write(cgx_dev, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 0x8)), cfg);\n\treturn 0;\n}\n\nint cgx_lmac_addr_del(u8 cgx_id, u8 lmac_id, u8 index)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgx_dev);\n\tstruct mac_ops *mac_ops;\n\tu8 mac[ETH_ALEN];\n\tu64 cfg;\n\tint id;\n\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\tmac_ops = cgx_dev->mac_ops;\n\t \n\tif (index >= lmac->mac_to_index_bmap.max)\n\t\treturn -EINVAL;\n\n\t \n\tif (index == 0)\n\t\treturn 0;\n\n\trvu_free_rsrc(&lmac->mac_to_index_bmap, index);\n\n\tid = get_sequence_id_of_lmac(cgx_dev, lmac_id);\n\n\tindex = id * lmac->mac_to_index_bmap.max + index;\n\n\t \n\tcfg = cgx_read(cgx_dev, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 0x8)));\n\n\tu64_to_ether_addr(cfg, mac);\n\tif (is_multicast_ether_addr(mac))\n\t\tlmac->mcast_filters_count--;\n\n\tif (!lmac->mcast_filters_count) {\n\t\tcfg = cgx_read(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0);\n\t\tcfg &= ~GENMASK_ULL(2, 1);\n\t\tcfg |= CGX_DMAC_MCAST_MODE;\n\t\tcgx_write(cgx_dev, lmac_id, CGXX_CMRX_RX_DMAC_CTL0, cfg);\n\t}\n\n\tcgx_write(cgx_dev, 0, (CGXX_CMRX_RX_DMAC_CAM0 + (index * 0x8)), 0);\n\n\treturn 0;\n}\n\nint cgx_lmac_addr_max_entries_get(u8 cgx_id, u8 lmac_id)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgx_dev);\n\n\tif (lmac)\n\t\treturn lmac->mac_to_index_bmap.max;\n\n\treturn 0;\n}\n\nu64 cgx_lmac_addr_get(u8 cgx_id, u8 lmac_id)\n{\n\tstruct cgx *cgx_dev = cgx_get_pdata(cgx_id);\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgx_dev);\n\tstruct mac_ops *mac_ops;\n\tint index;\n\tu64 cfg;\n\tint id;\n\n\tmac_ops = cgx_dev->mac_ops;\n\n\tid = get_sequence_id_of_lmac(cgx_dev, lmac_id);\n\n\tindex = id * lmac->mac_to_index_bmap.max;\n\n\tcfg = cgx_read(cgx_dev, 0, CGXX_CMRX_RX_DMAC_CAM0 + index * 0x8);\n\treturn cfg & CGX_RX_DMAC_ADR_MASK;\n}\n\nint cgx_set_pkind(void *cgxd, u8 lmac_id, int pkind)\n{\n\tstruct cgx *cgx = cgxd;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tcgx_write(cgx, lmac_id, cgx->mac_ops->rxid_map_offset, (pkind & 0x3F));\n\treturn 0;\n}\n\nstatic u8 cgx_get_lmac_type(void *cgxd, int lmac_id)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_CMRX_CFG);\n\treturn (cfg >> CGX_LMAC_TYPE_SHIFT) & CGX_LMAC_TYPE_MASK;\n}\n\nstatic u32 cgx_get_lmac_fifo_len(void *cgxd, int lmac_id)\n{\n\tstruct cgx *cgx = cgxd;\n\tu8 num_lmacs;\n\tu32 fifo_len;\n\n\tfifo_len = cgx->mac_ops->fifo_len;\n\tnum_lmacs = cgx->mac_ops->get_nr_lmacs(cgx);\n\n\tswitch (num_lmacs) {\n\tcase 1:\n\t\treturn fifo_len;\n\tcase 2:\n\t\treturn fifo_len / 2;\n\tcase 3:\n\t\t \n\t\tif (lmac_id == 0)\n\t\t\treturn fifo_len / 2;\n\t\treturn fifo_len / 4;\n\tcase 4:\n\tdefault:\n\t\treturn fifo_len / 4;\n\t}\n\treturn 0;\n}\n\n \nint cgx_lmac_internal_loopback(void *cgxd, int lmac_id, bool enable)\n{\n\tstruct cgx *cgx = cgxd;\n\tstruct lmac *lmac;\n\tu64 cfg;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tlmac = lmac_pdata(lmac_id, cgx);\n\tif (lmac->lmac_type == LMAC_MODE_SGMII ||\n\t    lmac->lmac_type == LMAC_MODE_QSGMII) {\n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_GMP_PCS_MRX_CTL);\n\t\tif (enable)\n\t\t\tcfg |= CGXX_GMP_PCS_MRX_CTL_LBK;\n\t\telse\n\t\t\tcfg &= ~CGXX_GMP_PCS_MRX_CTL_LBK;\n\t\tcgx_write(cgx, lmac_id, CGXX_GMP_PCS_MRX_CTL, cfg);\n\t} else {\n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SPUX_CONTROL1);\n\t\tif (enable)\n\t\t\tcfg |= CGXX_SPUX_CONTROL1_LBK;\n\t\telse\n\t\t\tcfg &= ~CGXX_SPUX_CONTROL1_LBK;\n\t\tcgx_write(cgx, lmac_id, CGXX_SPUX_CONTROL1, cfg);\n\t}\n\treturn 0;\n}\n\nvoid cgx_lmac_promisc_config(int cgx_id, int lmac_id, bool enable)\n{\n\tstruct cgx *cgx = cgx_get_pdata(cgx_id);\n\tstruct lmac *lmac = lmac_pdata(lmac_id, cgx);\n\tstruct mac_ops *mac_ops;\n\tu16 max_dmac;\n\tint index, i;\n\tu64 cfg = 0;\n\tint id;\n\n\tif (!cgx || !lmac)\n\t\treturn;\n\n\tmax_dmac = lmac->mac_to_index_bmap.max;\n\tid = get_sequence_id_of_lmac(cgx, lmac_id);\n\n\tmac_ops = cgx->mac_ops;\n\tif (enable) {\n\t\t \n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_CMRX_RX_DMAC_CTL0);\n\t\tcfg &= ~CGX_DMAC_CAM_ACCEPT;\n\t\tcfg |= (CGX_DMAC_BCAST_MODE | CGX_DMAC_MCAST_MODE);\n\t\tcgx_write(cgx, lmac_id, CGXX_CMRX_RX_DMAC_CTL0, cfg);\n\n\t\tfor (i = 0; i < max_dmac; i++) {\n\t\t\tindex = id * max_dmac + i;\n\t\t\tcfg = cgx_read(cgx, 0,\n\t\t\t\t       (CGXX_CMRX_RX_DMAC_CAM0 + index * 0x8));\n\t\t\tcfg &= ~CGX_DMAC_CAM_ADDR_ENABLE;\n\t\t\tcgx_write(cgx, 0,\n\t\t\t\t  (CGXX_CMRX_RX_DMAC_CAM0 + index * 0x8), cfg);\n\t\t}\n\t} else {\n\t\t \n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_CMRX_RX_DMAC_CTL0);\n\t\tcfg |= CGX_DMAC_CAM_ACCEPT | CGX_DMAC_MCAST_MODE;\n\t\tcgx_write(cgx, lmac_id, CGXX_CMRX_RX_DMAC_CTL0, cfg);\n\t\tfor (i = 0; i < max_dmac; i++) {\n\t\t\tindex = id * max_dmac + i;\n\t\t\tcfg = cgx_read(cgx, 0,\n\t\t\t\t       (CGXX_CMRX_RX_DMAC_CAM0 + index * 0x8));\n\t\t\tif ((cfg & CGX_RX_DMAC_ADR_MASK) != 0) {\n\t\t\t\tcfg |= CGX_DMAC_CAM_ADDR_ENABLE;\n\t\t\t\tcgx_write(cgx, 0,\n\t\t\t\t\t  (CGXX_CMRX_RX_DMAC_CAM0 +\n\t\t\t\t\t   index * 0x8),\n\t\t\t\t\t  cfg);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic int cgx_lmac_get_pause_frm_status(void *cgxd, int lmac_id,\n\t\t\t\t\t u8 *tx_pause, u8 *rx_pause)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (is_dev_rpm(cgx))\n\t\treturn 0;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL);\n\t*rx_pause = !!(cfg & CGX_SMUX_RX_FRM_CTL_CTL_BCK);\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_TX_CTL);\n\t*tx_pause = !!(cfg & CGX_SMUX_TX_CTL_L2P_BP_CONV);\n\treturn 0;\n}\n\n \nvoid cgx_lmac_enadis_rx_pause_fwding(void *cgxd, int lmac_id, bool enable)\n{\n\tstruct cgx *cgx = cgxd;\n\tu8 rx_pause, tx_pause;\n\tbool is_pfc_enabled;\n\tstruct lmac *lmac;\n\tu64 cfg;\n\n\tif (!cgx)\n\t\treturn;\n\n\tlmac = lmac_pdata(lmac_id, cgx);\n\tif (!lmac)\n\t\treturn;\n\n\t \n\tif (!bitmap_weight(lmac->rx_fc_pfvf_bmap.bmap, lmac->rx_fc_pfvf_bmap.max))\n\t\treturn;\n\n\tcgx_lmac_get_pause_frm_status(cgx, lmac_id, &rx_pause, &tx_pause);\n\tis_pfc_enabled = rx_pause ? false : true;\n\n\tif (enable) {\n\t\tif (!is_pfc_enabled) {\n\t\t\tcfg = cgx_read(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL);\n\t\t\tcfg |= CGX_GMP_GMI_RXX_FRM_CTL_CTL_BCK;\n\t\t\tcgx_write(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL, cfg);\n\n\t\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL);\n\t\t\tcfg |= CGX_SMUX_RX_FRM_CTL_CTL_BCK;\n\t\t\tcgx_write(cgx, lmac_id,\tCGXX_SMUX_RX_FRM_CTL, cfg);\n\t\t} else {\n\t\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_CBFC_CTL);\n\t\t\tcfg |= CGXX_SMUX_CBFC_CTL_BCK_EN;\n\t\t\tcgx_write(cgx, lmac_id, CGXX_SMUX_CBFC_CTL, cfg);\n\t\t}\n\t} else {\n\n\t\tif (!is_pfc_enabled) {\n\t\t\tcfg = cgx_read(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL);\n\t\t\tcfg &= ~CGX_GMP_GMI_RXX_FRM_CTL_CTL_BCK;\n\t\t\tcgx_write(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL, cfg);\n\n\t\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL);\n\t\t\tcfg &= ~CGX_SMUX_RX_FRM_CTL_CTL_BCK;\n\t\t\tcgx_write(cgx, lmac_id,\tCGXX_SMUX_RX_FRM_CTL, cfg);\n\t\t} else {\n\t\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_CBFC_CTL);\n\t\t\tcfg &= ~CGXX_SMUX_CBFC_CTL_BCK_EN;\n\t\t\tcgx_write(cgx, lmac_id, CGXX_SMUX_CBFC_CTL, cfg);\n\t\t}\n\t}\n}\n\nint cgx_get_rx_stats(void *cgxd, int lmac_id, int idx, u64 *rx_stat)\n{\n\tstruct cgx *cgx = cgxd;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\t*rx_stat =  cgx_read(cgx, lmac_id, CGXX_CMRX_RX_STAT0 + (idx * 8));\n\treturn 0;\n}\n\nint cgx_get_tx_stats(void *cgxd, int lmac_id, int idx, u64 *tx_stat)\n{\n\tstruct cgx *cgx = cgxd;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\t*tx_stat = cgx_read(cgx, lmac_id, CGXX_CMRX_TX_STAT0 + (idx * 8));\n\treturn 0;\n}\n\nu64 cgx_features_get(void *cgxd)\n{\n\treturn ((struct cgx *)cgxd)->hw_features;\n}\n\nstatic int cgx_set_fec_stats_count(struct cgx_link_user_info *linfo)\n{\n\tif (!linfo->fec)\n\t\treturn 0;\n\n\tswitch (linfo->lmac_type_id) {\n\tcase LMAC_MODE_SGMII:\n\tcase LMAC_MODE_XAUI:\n\tcase LMAC_MODE_RXAUI:\n\tcase LMAC_MODE_QSGMII:\n\t\treturn 0;\n\tcase LMAC_MODE_10G_R:\n\tcase LMAC_MODE_25G_R:\n\tcase LMAC_MODE_100G_R:\n\tcase LMAC_MODE_USXGMII:\n\t\treturn 1;\n\tcase LMAC_MODE_40G_R:\n\t\treturn 4;\n\tcase LMAC_MODE_50G_R:\n\t\tif (linfo->fec == OTX2_FEC_BASER)\n\t\t\treturn 2;\n\t\telse\n\t\t\treturn 1;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nint cgx_get_fec_stats(void *cgxd, int lmac_id, struct cgx_fec_stats_rsp *rsp)\n{\n\tint stats, fec_stats_count = 0;\n\tint corr_reg, uncorr_reg;\n\tstruct cgx *cgx = cgxd;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tif (cgx->lmac_idmap[lmac_id]->link_info.fec == OTX2_FEC_NONE)\n\t\treturn 0;\n\n\tfec_stats_count =\n\t\tcgx_set_fec_stats_count(&cgx->lmac_idmap[lmac_id]->link_info);\n\tif (cgx->lmac_idmap[lmac_id]->link_info.fec == OTX2_FEC_BASER) {\n\t\tcorr_reg = CGXX_SPUX_LNX_FEC_CORR_BLOCKS;\n\t\tuncorr_reg = CGXX_SPUX_LNX_FEC_UNCORR_BLOCKS;\n\t} else {\n\t\tcorr_reg = CGXX_SPUX_RSFEC_CORR;\n\t\tuncorr_reg = CGXX_SPUX_RSFEC_UNCORR;\n\t}\n\tfor (stats = 0; stats < fec_stats_count; stats++) {\n\t\trsp->fec_corr_blks +=\n\t\t\tcgx_read(cgx, lmac_id, corr_reg + (stats * 8));\n\t\trsp->fec_uncorr_blks +=\n\t\t\tcgx_read(cgx, lmac_id, uncorr_reg + (stats * 8));\n\t}\n\treturn 0;\n}\n\nint cgx_lmac_rx_tx_enable(void *cgxd, int lmac_id, bool enable)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_CMRX_CFG);\n\tif (enable)\n\t\tcfg |= DATA_PKT_RX_EN | DATA_PKT_TX_EN;\n\telse\n\t\tcfg &= ~(DATA_PKT_RX_EN | DATA_PKT_TX_EN);\n\tcgx_write(cgx, lmac_id, CGXX_CMRX_CFG, cfg);\n\treturn 0;\n}\n\nint cgx_lmac_tx_enable(void *cgxd, int lmac_id, bool enable)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg, last;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_CMRX_CFG);\n\tlast = cfg;\n\tif (enable)\n\t\tcfg |= DATA_PKT_TX_EN;\n\telse\n\t\tcfg &= ~DATA_PKT_TX_EN;\n\n\tif (cfg != last)\n\t\tcgx_write(cgx, lmac_id, CGXX_CMRX_CFG, cfg);\n\treturn !!(last & DATA_PKT_TX_EN);\n}\n\nstatic int cgx_lmac_enadis_pause_frm(void *cgxd, int lmac_id,\n\t\t\t\t     u8 tx_pause, u8 rx_pause)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (is_dev_rpm(cgx))\n\t\treturn 0;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL);\n\tcfg &= ~CGX_SMUX_RX_FRM_CTL_CTL_BCK;\n\tcfg |= rx_pause ? CGX_SMUX_RX_FRM_CTL_CTL_BCK : 0x0;\n\tcgx_write(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL, cfg);\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_TX_CTL);\n\tcfg &= ~CGX_SMUX_TX_CTL_L2P_BP_CONV;\n\tcfg |= tx_pause ? CGX_SMUX_TX_CTL_L2P_BP_CONV : 0x0;\n\tcgx_write(cgx, lmac_id, CGXX_SMUX_TX_CTL, cfg);\n\n\tcfg = cgx_read(cgx, 0, CGXX_CMR_RX_OVR_BP);\n\tif (tx_pause) {\n\t\tcfg &= ~CGX_CMR_RX_OVR_BP_EN(lmac_id);\n\t} else {\n\t\tcfg |= CGX_CMR_RX_OVR_BP_EN(lmac_id);\n\t\tcfg &= ~CGX_CMR_RX_OVR_BP_BP(lmac_id);\n\t}\n\tcgx_write(cgx, 0, CGXX_CMR_RX_OVR_BP, cfg);\n\treturn 0;\n}\n\nstatic void cgx_lmac_pause_frm_config(void *cgxd, int lmac_id, bool enable)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn;\n\n\tif (enable) {\n\t\t \n\t\tcgx_write(cgx, lmac_id, CGXX_SMUX_TX_PAUSE_PKT_TIME,\n\t\t\t  DEFAULT_PAUSE_TIME);\n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_TX_PAUSE_PKT_INTERVAL);\n\t\tcfg &= ~0xFFFFULL;\n\t\tcgx_write(cgx, lmac_id, CGXX_SMUX_TX_PAUSE_PKT_INTERVAL,\n\t\t\t  cfg | (DEFAULT_PAUSE_TIME / 2));\n\n\t\tcgx_write(cgx, lmac_id, CGXX_GMP_GMI_TX_PAUSE_PKT_TIME,\n\t\t\t  DEFAULT_PAUSE_TIME);\n\n\t\tcfg = cgx_read(cgx, lmac_id,\n\t\t\t       CGXX_GMP_GMI_TX_PAUSE_PKT_INTERVAL);\n\t\tcfg &= ~0xFFFFULL;\n\t\tcgx_write(cgx, lmac_id, CGXX_GMP_GMI_TX_PAUSE_PKT_INTERVAL,\n\t\t\t  cfg | (DEFAULT_PAUSE_TIME / 2));\n\t}\n\n\t \n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL);\n\tcfg &= ~CGX_SMUX_RX_FRM_CTL_CTL_BCK;\n\tcgx_write(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL, cfg);\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL);\n\tcfg &= ~CGX_GMP_GMI_RXX_FRM_CTL_CTL_BCK;\n\tcgx_write(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL, cfg);\n\n\t \n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_TX_CTL);\n\tcfg &= ~CGX_SMUX_TX_CTL_L2P_BP_CONV;\n\tcgx_write(cgx, lmac_id, CGXX_SMUX_TX_CTL, cfg);\n\n\tcfg = cgx_read(cgx, 0, CGXX_CMR_RX_OVR_BP);\n\tcfg |= CGX_CMR_RX_OVR_BP_EN(lmac_id);\n\tcfg &= ~CGX_CMR_RX_OVR_BP_BP(lmac_id);\n\tcgx_write(cgx, 0, CGXX_CMR_RX_OVR_BP, cfg);\n\n\t \n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_CBFC_CTL);\n\tcfg = FIELD_SET(CGX_PFC_CLASS_MASK, 0, cfg);\n\tcgx_write(cgx, lmac_id, CGXX_SMUX_CBFC_CTL, cfg);\n}\n\nint verify_lmac_fc_cfg(void *cgxd, int lmac_id, u8 tx_pause, u8 rx_pause,\n\t\t       int pfvf_idx)\n{\n\tstruct cgx *cgx = cgxd;\n\tstruct lmac *lmac;\n\n\tlmac = lmac_pdata(lmac_id, cgx);\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\tif (!rx_pause)\n\t\tclear_bit(pfvf_idx, lmac->rx_fc_pfvf_bmap.bmap);\n\telse\n\t\tset_bit(pfvf_idx, lmac->rx_fc_pfvf_bmap.bmap);\n\n\tif (!tx_pause)\n\t\tclear_bit(pfvf_idx, lmac->tx_fc_pfvf_bmap.bmap);\n\telse\n\t\tset_bit(pfvf_idx, lmac->tx_fc_pfvf_bmap.bmap);\n\n\t \n\tif (!rx_pause && bitmap_weight(lmac->rx_fc_pfvf_bmap.bmap, lmac->rx_fc_pfvf_bmap.max)) {\n\t\tdev_warn(&cgx->pdev->dev,\n\t\t\t \"Receive Flow control disable not permitted as its used by other PFVFs\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tif (!tx_pause && bitmap_weight(lmac->tx_fc_pfvf_bmap.bmap, lmac->tx_fc_pfvf_bmap.max)) {\n\t\tdev_warn(&cgx->pdev->dev,\n\t\t\t \"Transmit Flow control disable not permitted as its used by other PFVFs\\n\");\n\t\treturn -EPERM;\n\t}\n\n\treturn 0;\n}\n\nint cgx_lmac_pfc_config(void *cgxd, int lmac_id, u8 tx_pause,\n\t\t\tu8 rx_pause, u16 pfc_en)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\t \n\tif (tx_pause && !pfc_en)\n\t\treturn 0;\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_CBFC_CTL);\n\tpfc_en |= FIELD_GET(CGX_PFC_CLASS_MASK, cfg);\n\n\tif (rx_pause) {\n\t\tcfg |= (CGXX_SMUX_CBFC_CTL_RX_EN |\n\t\t\tCGXX_SMUX_CBFC_CTL_BCK_EN |\n\t\t\tCGXX_SMUX_CBFC_CTL_DRP_EN);\n\t} else {\n\t\tcfg &= ~(CGXX_SMUX_CBFC_CTL_RX_EN |\n\t\t\tCGXX_SMUX_CBFC_CTL_BCK_EN |\n\t\t\tCGXX_SMUX_CBFC_CTL_DRP_EN);\n\t}\n\n\tif (tx_pause) {\n\t\tcfg |= CGXX_SMUX_CBFC_CTL_TX_EN;\n\t\tcfg = FIELD_SET(CGX_PFC_CLASS_MASK, pfc_en, cfg);\n\t} else {\n\t\tcfg &= ~CGXX_SMUX_CBFC_CTL_TX_EN;\n\t\tcfg = FIELD_SET(CGX_PFC_CLASS_MASK, 0, cfg);\n\t}\n\n\tcgx_write(cgx, lmac_id, CGXX_SMUX_CBFC_CTL, cfg);\n\n\t \n\tcfg = cgx_lmac_addr_get(cgx->cgx_id, lmac_id);\n\tcgx_write(cgx, lmac_id, CGXX_SMUX_SMAC, cfg);\n\n\treturn 0;\n}\n\nint cgx_lmac_get_pfc_frm_cfg(void *cgxd, int lmac_id, u8 *tx_pause,\n\t\t\t     u8 *rx_pause)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_CBFC_CTL);\n\n\t*rx_pause = !!(cfg & CGXX_SMUX_CBFC_CTL_RX_EN);\n\t*tx_pause = !!(cfg & CGXX_SMUX_CBFC_CTL_TX_EN);\n\n\treturn 0;\n}\n\nvoid cgx_lmac_ptp_config(void *cgxd, int lmac_id, bool enable)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (!cgx)\n\t\treturn;\n\n\tif (enable) {\n\t\t \n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL);\n\t\tcfg |= CGX_GMP_GMI_RXX_FRM_CTL_PTP_MODE;\n\t\tcgx_write(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL, cfg);\n\n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL);\n\t\tcfg |= CGX_SMUX_RX_FRM_CTL_PTP_MODE;\n\t\tcgx_write(cgx, lmac_id,\tCGXX_SMUX_RX_FRM_CTL, cfg);\n\t} else {\n\t\t \n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL);\n\t\tcfg &= ~CGX_GMP_GMI_RXX_FRM_CTL_PTP_MODE;\n\t\tcgx_write(cgx, lmac_id, CGXX_GMP_GMI_RXX_FRM_CTL, cfg);\n\n\t\tcfg = cgx_read(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL);\n\t\tcfg &= ~CGX_SMUX_RX_FRM_CTL_PTP_MODE;\n\t\tcgx_write(cgx, lmac_id, CGXX_SMUX_RX_FRM_CTL, cfg);\n\t}\n}\n\n \nint cgx_fwi_cmd_send(u64 req, u64 *resp, struct lmac *lmac)\n{\n\tstruct cgx *cgx = lmac->cgx;\n\tstruct device *dev;\n\tint err = 0;\n\tu64 cmd;\n\n\t \n\terr = mutex_lock_interruptible(&lmac->cmd_lock);\n\tif (err)\n\t\treturn err;\n\n\t \n\tcmd = cgx_read(cgx, lmac->lmac_id,  CGX_COMMAND_REG);\n\tif (FIELD_GET(CMDREG_OWN, cmd) != CGX_CMD_OWN_NS) {\n\t\terr = -EBUSY;\n\t\tgoto unlock;\n\t}\n\n\t \n\treq = FIELD_SET(CMDREG_OWN, CGX_CMD_OWN_FIRMWARE, req);\n\n\t \n\tlmac->cmd_pend = true;\n\n\t \n\tcgx_write(cgx, lmac->lmac_id, CGX_COMMAND_REG, req);\n\n\t \n\tif (!wait_event_timeout(lmac->wq_cmd_cmplt, !lmac->cmd_pend,\n\t\t\t\tmsecs_to_jiffies(CGX_CMD_TIMEOUT))) {\n\t\tdev = &cgx->pdev->dev;\n\t\tdev_err(dev, \"cgx port %d:%d cmd %lld timeout\\n\",\n\t\t\tcgx->cgx_id, lmac->lmac_id, FIELD_GET(CMDREG_ID, req));\n\t\terr = LMAC_AF_ERR_CMD_TIMEOUT;\n\t\tgoto unlock;\n\t}\n\n\t \n\tsmp_rmb();  \n\t*resp = lmac->resp;\n\nunlock:\n\tmutex_unlock(&lmac->cmd_lock);\n\n\treturn err;\n}\n\nint cgx_fwi_cmd_generic(u64 req, u64 *resp, struct cgx *cgx, int lmac_id)\n{\n\tstruct lmac *lmac;\n\tint err;\n\n\tlmac = lmac_pdata(lmac_id, cgx);\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\terr = cgx_fwi_cmd_send(req, resp, lmac);\n\n\t \n\tif (!err) {\n\t\tif (FIELD_GET(EVTREG_STAT, *resp) == CGX_STAT_FAIL)\n\t\t\treturn -EIO;\n\t\telse\n\t\t\treturn 0;\n\t}\n\n\treturn err;\n}\n\nstatic int cgx_link_usertable_index_map(int speed)\n{\n\tswitch (speed) {\n\tcase SPEED_10:\n\t\treturn CGX_LINK_10M;\n\tcase SPEED_100:\n\t\treturn CGX_LINK_100M;\n\tcase SPEED_1000:\n\t\treturn CGX_LINK_1G;\n\tcase SPEED_2500:\n\t\treturn CGX_LINK_2HG;\n\tcase SPEED_5000:\n\t\treturn CGX_LINK_5G;\n\tcase SPEED_10000:\n\t\treturn CGX_LINK_10G;\n\tcase SPEED_20000:\n\t\treturn CGX_LINK_20G;\n\tcase SPEED_25000:\n\t\treturn CGX_LINK_25G;\n\tcase SPEED_40000:\n\t\treturn CGX_LINK_40G;\n\tcase SPEED_50000:\n\t\treturn CGX_LINK_50G;\n\tcase 80000:\n\t\treturn CGX_LINK_80G;\n\tcase SPEED_100000:\n\t\treturn CGX_LINK_100G;\n\tcase SPEED_UNKNOWN:\n\t\treturn CGX_LINK_NONE;\n\t}\n\treturn CGX_LINK_NONE;\n}\n\nstatic void set_mod_args(struct cgx_set_link_mode_args *args,\n\t\t\t u32 speed, u8 duplex, u8 autoneg, u64 mode)\n{\n\t \n\tif (args->duplex == DUPLEX_UNKNOWN)\n\t\targs->duplex = duplex;\n\tif (args->speed == SPEED_UNKNOWN)\n\t\targs->speed = speed;\n\tif (args->an == AUTONEG_UNKNOWN)\n\t\targs->an = autoneg;\n\targs->mode = mode;\n\targs->ports = 0;\n}\n\nstatic void otx2_map_ethtool_link_modes(u64 bitmask,\n\t\t\t\t\tstruct cgx_set_link_mode_args *args)\n{\n\tswitch (bitmask) {\n\tcase ETHTOOL_LINK_MODE_10baseT_Half_BIT:\n\t\tset_mod_args(args, 10, 1, 1, BIT_ULL(CGX_MODE_SGMII));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_10baseT_Full_BIT:\n\t\tset_mod_args(args, 10, 0, 1, BIT_ULL(CGX_MODE_SGMII));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_100baseT_Half_BIT:\n\t\tset_mod_args(args, 100, 1, 1, BIT_ULL(CGX_MODE_SGMII));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_100baseT_Full_BIT:\n\t\tset_mod_args(args, 100, 0, 1, BIT_ULL(CGX_MODE_SGMII));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_1000baseT_Half_BIT:\n\t\tset_mod_args(args, 1000, 1, 1, BIT_ULL(CGX_MODE_SGMII));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_1000baseT_Full_BIT:\n\t\tset_mod_args(args, 1000, 0, 1, BIT_ULL(CGX_MODE_SGMII));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_1000baseX_Full_BIT:\n\t\tset_mod_args(args, 1000, 0, 0, BIT_ULL(CGX_MODE_1000_BASEX));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_10000baseT_Full_BIT:\n\t\tset_mod_args(args, 1000, 0, 1, BIT_ULL(CGX_MODE_QSGMII));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_10000baseSR_Full_BIT:\n\t\tset_mod_args(args, 10000, 0, 0, BIT_ULL(CGX_MODE_10G_C2C));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_10000baseLR_Full_BIT:\n\t\tset_mod_args(args, 10000, 0, 0, BIT_ULL(CGX_MODE_10G_C2M));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_10000baseKR_Full_BIT:\n\t\tset_mod_args(args, 10000, 0, 1, BIT_ULL(CGX_MODE_10G_KR));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_25000baseSR_Full_BIT:\n\t\tset_mod_args(args, 25000, 0, 0, BIT_ULL(CGX_MODE_25G_C2C));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_25000baseCR_Full_BIT:\n\t\tset_mod_args(args, 25000, 0, 1, BIT_ULL(CGX_MODE_25G_CR));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_25000baseKR_Full_BIT:\n\t\tset_mod_args(args, 25000, 0, 1, BIT_ULL(CGX_MODE_25G_KR));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_40000baseSR4_Full_BIT:\n\t\tset_mod_args(args, 40000, 0, 0, BIT_ULL(CGX_MODE_40G_C2C));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_40000baseLR4_Full_BIT:\n\t\tset_mod_args(args, 40000, 0, 0, BIT_ULL(CGX_MODE_40G_C2M));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_40000baseCR4_Full_BIT:\n\t\tset_mod_args(args, 40000, 0, 1, BIT_ULL(CGX_MODE_40G_CR4));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_40000baseKR4_Full_BIT:\n\t\tset_mod_args(args, 40000, 0, 1, BIT_ULL(CGX_MODE_40G_KR4));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_50000baseSR_Full_BIT:\n\t\tset_mod_args(args, 50000, 0, 0, BIT_ULL(CGX_MODE_50G_C2C));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_50000baseLR_ER_FR_Full_BIT:\n\t\tset_mod_args(args, 50000, 0, 0, BIT_ULL(CGX_MODE_50G_C2M));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_50000baseCR_Full_BIT:\n\t\tset_mod_args(args, 50000, 0, 1, BIT_ULL(CGX_MODE_50G_CR));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_50000baseKR_Full_BIT:\n\t\tset_mod_args(args, 50000, 0, 1, BIT_ULL(CGX_MODE_50G_KR));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_100000baseSR4_Full_BIT:\n\t\tset_mod_args(args, 100000, 0, 0, BIT_ULL(CGX_MODE_100G_C2C));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_100000baseLR4_ER4_Full_BIT:\n\t\tset_mod_args(args, 100000, 0, 0, BIT_ULL(CGX_MODE_100G_C2M));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_100000baseCR4_Full_BIT:\n\t\tset_mod_args(args, 100000, 0, 1, BIT_ULL(CGX_MODE_100G_CR4));\n\t\tbreak;\n\tcase  ETHTOOL_LINK_MODE_100000baseKR4_Full_BIT:\n\t\tset_mod_args(args, 100000, 0, 1, BIT_ULL(CGX_MODE_100G_KR4));\n\t\tbreak;\n\tdefault:\n\t\tset_mod_args(args, 0, 1, 0, BIT_ULL(CGX_MODE_MAX));\n\t\tbreak;\n\t}\n}\n\nstatic inline void link_status_user_format(u64 lstat,\n\t\t\t\t\t   struct cgx_link_user_info *linfo,\n\t\t\t\t\t   struct cgx *cgx, u8 lmac_id)\n{\n\tconst char *lmac_string;\n\n\tlinfo->link_up = FIELD_GET(RESP_LINKSTAT_UP, lstat);\n\tlinfo->full_duplex = FIELD_GET(RESP_LINKSTAT_FDUPLEX, lstat);\n\tlinfo->speed = cgx_speed_mbps[FIELD_GET(RESP_LINKSTAT_SPEED, lstat)];\n\tlinfo->an = FIELD_GET(RESP_LINKSTAT_AN, lstat);\n\tlinfo->fec = FIELD_GET(RESP_LINKSTAT_FEC, lstat);\n\tlinfo->lmac_type_id = FIELD_GET(RESP_LINKSTAT_LMAC_TYPE, lstat);\n\n\tif (linfo->lmac_type_id >= LMAC_MODE_MAX) {\n\t\tdev_err(&cgx->pdev->dev, \"Unknown lmac_type_id %d reported by firmware on cgx port%d:%d\",\n\t\t\tlinfo->lmac_type_id, cgx->cgx_id, lmac_id);\n\t\tstrncpy(linfo->lmac_type, \"Unknown\", LMACTYPE_STR_LEN - 1);\n\t\treturn;\n\t}\n\n\tlmac_string = cgx_lmactype_string[linfo->lmac_type_id];\n\tstrncpy(linfo->lmac_type, lmac_string, LMACTYPE_STR_LEN - 1);\n}\n\n \nstatic inline void cgx_link_change_handler(u64 lstat,\n\t\t\t\t\t   struct lmac *lmac)\n{\n\tstruct cgx_link_user_info *linfo;\n\tstruct cgx *cgx = lmac->cgx;\n\tstruct cgx_link_event event;\n\tstruct device *dev;\n\tint err_type;\n\n\tdev = &cgx->pdev->dev;\n\n\tlink_status_user_format(lstat, &event.link_uinfo, cgx, lmac->lmac_id);\n\terr_type = FIELD_GET(RESP_LINKSTAT_ERRTYPE, lstat);\n\n\tevent.cgx_id = cgx->cgx_id;\n\tevent.lmac_id = lmac->lmac_id;\n\n\t \n\tlmac->link_info = event.link_uinfo;\n\tlinfo = &lmac->link_info;\n\n\tif (err_type == CGX_ERR_SPEED_CHANGE_INVALID)\n\t\treturn;\n\n\t \n\tspin_lock(&lmac->event_cb_lock);\n\n\tif (!lmac->event_cb.notify_link_chg) {\n\t\tdev_dbg(dev, \"cgx port %d:%d Link change handler null\",\n\t\t\tcgx->cgx_id, lmac->lmac_id);\n\t\tif (err_type != CGX_ERR_NONE) {\n\t\t\tdev_err(dev, \"cgx port %d:%d Link error %d\\n\",\n\t\t\t\tcgx->cgx_id, lmac->lmac_id, err_type);\n\t\t}\n\t\tdev_info(dev, \"cgx port %d:%d Link is %s %d Mbps\\n\",\n\t\t\t cgx->cgx_id, lmac->lmac_id,\n\t\t\t linfo->link_up ? \"UP\" : \"DOWN\", linfo->speed);\n\t\tgoto err;\n\t}\n\n\tif (lmac->event_cb.notify_link_chg(&event, lmac->event_cb.data))\n\t\tdev_err(dev, \"event notification failure\\n\");\nerr:\n\tspin_unlock(&lmac->event_cb_lock);\n}\n\nstatic inline bool cgx_cmdresp_is_linkevent(u64 event)\n{\n\tu8 id;\n\n\tid = FIELD_GET(EVTREG_ID, event);\n\tif (id == CGX_CMD_LINK_BRING_UP ||\n\t    id == CGX_CMD_LINK_BRING_DOWN ||\n\t    id == CGX_CMD_MODE_CHANGE)\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nstatic inline bool cgx_event_is_linkevent(u64 event)\n{\n\tif (FIELD_GET(EVTREG_ID, event) == CGX_EVT_LINK_CHANGE)\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nstatic irqreturn_t cgx_fwi_event_handler(int irq, void *data)\n{\n\tu64 event, offset, clear_bit;\n\tstruct lmac *lmac = data;\n\tstruct cgx *cgx;\n\n\tcgx = lmac->cgx;\n\n\t \n\toffset     = cgx->mac_ops->int_register;\n\tclear_bit  = cgx->mac_ops->int_ena_bit;\n\n\tevent = cgx_read(cgx, lmac->lmac_id, CGX_EVENT_REG);\n\n\tif (!FIELD_GET(EVTREG_ACK, event))\n\t\treturn IRQ_NONE;\n\n\tswitch (FIELD_GET(EVTREG_EVT_TYPE, event)) {\n\tcase CGX_EVT_CMD_RESP:\n\t\t \n\t\tlmac->resp = event;\n\t\t \n\t\tsmp_wmb();\n\n\t\t \n\t\tif (cgx_cmdresp_is_linkevent(event))\n\t\t\tcgx_link_change_handler(event, lmac);\n\n\t\t \n\t\tlmac->cmd_pend = false;\n\t\twake_up_interruptible(&lmac->wq_cmd_cmplt);\n\t\tbreak;\n\tcase CGX_EVT_ASYNC:\n\t\tif (cgx_event_is_linkevent(event))\n\t\t\tcgx_link_change_handler(event, lmac);\n\t\tbreak;\n\t}\n\n\t \n\tcgx_write(lmac->cgx, lmac->lmac_id, CGX_EVENT_REG, 0);\n\tcgx_write(lmac->cgx, lmac->lmac_id, offset, clear_bit);\n\n\treturn IRQ_HANDLED;\n}\n\n \n\n \nint cgx_lmac_evh_register(struct cgx_event_cb *cb, void *cgxd, int lmac_id)\n{\n\tstruct cgx *cgx = cgxd;\n\tstruct lmac *lmac;\n\n\tlmac = lmac_pdata(lmac_id, cgx);\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\tlmac->event_cb = *cb;\n\n\treturn 0;\n}\n\nint cgx_lmac_evh_unregister(void *cgxd, int lmac_id)\n{\n\tstruct lmac *lmac;\n\tunsigned long flags;\n\tstruct cgx *cgx = cgxd;\n\n\tlmac = lmac_pdata(lmac_id, cgx);\n\tif (!lmac)\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&lmac->event_cb_lock, flags);\n\tlmac->event_cb.notify_link_chg = NULL;\n\tlmac->event_cb.data = NULL;\n\tspin_unlock_irqrestore(&lmac->event_cb_lock, flags);\n\n\treturn 0;\n}\n\nint cgx_get_fwdata_base(u64 *base)\n{\n\tu64 req = 0, resp;\n\tstruct cgx *cgx;\n\tint first_lmac;\n\tint err;\n\n\tcgx = list_first_entry_or_null(&cgx_list, struct cgx, cgx_list);\n\tif (!cgx)\n\t\treturn -ENXIO;\n\n\tfirst_lmac = find_first_bit(&cgx->lmac_bmap, cgx->max_lmac_per_mac);\n\treq = FIELD_SET(CMDREG_ID, CGX_CMD_GET_FWD_BASE, req);\n\terr = cgx_fwi_cmd_generic(req, &resp, cgx, first_lmac);\n\tif (!err)\n\t\t*base = FIELD_GET(RESP_FWD_BASE, resp);\n\n\treturn err;\n}\n\nint cgx_set_link_mode(void *cgxd, struct cgx_set_link_mode_args args,\n\t\t      int cgx_id, int lmac_id)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 req = 0, resp;\n\n\tif (!cgx)\n\t\treturn -ENODEV;\n\n\tif (args.mode)\n\t\totx2_map_ethtool_link_modes(args.mode, &args);\n\tif (!args.speed && args.duplex && !args.an)\n\t\treturn -EINVAL;\n\n\treq = FIELD_SET(CMDREG_ID, CGX_CMD_MODE_CHANGE, req);\n\treq = FIELD_SET(CMDMODECHANGE_SPEED,\n\t\t\tcgx_link_usertable_index_map(args.speed), req);\n\treq = FIELD_SET(CMDMODECHANGE_DUPLEX, args.duplex, req);\n\treq = FIELD_SET(CMDMODECHANGE_AN, args.an, req);\n\treq = FIELD_SET(CMDMODECHANGE_PORT, args.ports, req);\n\treq = FIELD_SET(CMDMODECHANGE_FLAGS, args.mode, req);\n\n\treturn cgx_fwi_cmd_generic(req, &resp, cgx, lmac_id);\n}\nint cgx_set_fec(u64 fec, int cgx_id, int lmac_id)\n{\n\tu64 req = 0, resp;\n\tstruct cgx *cgx;\n\tint err = 0;\n\n\tcgx = cgx_get_pdata(cgx_id);\n\tif (!cgx)\n\t\treturn -ENXIO;\n\n\treq = FIELD_SET(CMDREG_ID, CGX_CMD_SET_FEC, req);\n\treq = FIELD_SET(CMDSETFEC, fec, req);\n\terr = cgx_fwi_cmd_generic(req, &resp, cgx, lmac_id);\n\tif (err)\n\t\treturn err;\n\n\tcgx->lmac_idmap[lmac_id]->link_info.fec =\n\t\t\tFIELD_GET(RESP_LINKSTAT_FEC, resp);\n\treturn cgx->lmac_idmap[lmac_id]->link_info.fec;\n}\n\nint cgx_get_phy_fec_stats(void *cgxd, int lmac_id)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 req = 0, resp;\n\n\tif (!cgx)\n\t\treturn -ENODEV;\n\n\treq = FIELD_SET(CMDREG_ID, CGX_CMD_GET_PHY_FEC_STATS, req);\n\treturn cgx_fwi_cmd_generic(req, &resp, cgx, lmac_id);\n}\n\nstatic int cgx_fwi_link_change(struct cgx *cgx, int lmac_id, bool enable)\n{\n\tu64 req = 0;\n\tu64 resp;\n\n\tif (enable) {\n\t\treq = FIELD_SET(CMDREG_ID, CGX_CMD_LINK_BRING_UP, req);\n\t\t \n\t\tif (!is_dev_rpm(cgx))\n\t\t\treq = FIELD_SET(LINKCFG_TIMEOUT, 1000, req);\n\n\t} else {\n\t\treq = FIELD_SET(CMDREG_ID, CGX_CMD_LINK_BRING_DOWN, req);\n\t}\n\treturn cgx_fwi_cmd_generic(req, &resp, cgx, lmac_id);\n}\n\nstatic inline int cgx_fwi_read_version(u64 *resp, struct cgx *cgx)\n{\n\tint first_lmac = find_first_bit(&cgx->lmac_bmap, cgx->max_lmac_per_mac);\n\tu64 req = 0;\n\n\treq = FIELD_SET(CMDREG_ID, CGX_CMD_GET_FW_VER, req);\n\treturn cgx_fwi_cmd_generic(req, resp, cgx, first_lmac);\n}\n\nstatic int cgx_lmac_verify_fwi_version(struct cgx *cgx)\n{\n\tstruct device *dev = &cgx->pdev->dev;\n\tint major_ver, minor_ver;\n\tu64 resp;\n\tint err;\n\n\tif (!cgx->lmac_count)\n\t\treturn 0;\n\n\terr = cgx_fwi_read_version(&resp, cgx);\n\tif (err)\n\t\treturn err;\n\n\tmajor_ver = FIELD_GET(RESP_MAJOR_VER, resp);\n\tminor_ver = FIELD_GET(RESP_MINOR_VER, resp);\n\tdev_dbg(dev, \"Firmware command interface version = %d.%d\\n\",\n\t\tmajor_ver, minor_ver);\n\tif (major_ver != CGX_FIRMWARE_MAJOR_VER)\n\t\treturn -EIO;\n\telse\n\t\treturn 0;\n}\n\nstatic void cgx_lmac_linkup_work(struct work_struct *work)\n{\n\tstruct cgx *cgx = container_of(work, struct cgx, cgx_cmd_work);\n\tstruct device *dev = &cgx->pdev->dev;\n\tint i, err;\n\n\t \n\tfor_each_set_bit(i, &cgx->lmac_bmap, cgx->max_lmac_per_mac) {\n\t\terr = cgx_fwi_link_change(cgx, i, true);\n\t\tif (err)\n\t\t\tdev_info(dev, \"cgx port %d:%d Link up command failed\\n\",\n\t\t\t\t cgx->cgx_id, i);\n\t}\n}\n\nint cgx_lmac_linkup_start(void *cgxd)\n{\n\tstruct cgx *cgx = cgxd;\n\n\tif (!cgx)\n\t\treturn -ENODEV;\n\n\tqueue_work(cgx->cgx_cmd_workq, &cgx->cgx_cmd_work);\n\n\treturn 0;\n}\n\nint cgx_lmac_reset(void *cgxd, int lmac_id, u8 pf_req_flr)\n{\n\tstruct cgx *cgx = cgxd;\n\tu64 cfg;\n\n\tif (!is_lmac_valid(cgx, lmac_id))\n\t\treturn -ENODEV;\n\n\t \n\tcfg = 0xff;\n\tcgx_write(cgxd, lmac_id, CGXX_CMRX_RX_LOGL_XON, cfg);\n\n\tif (pf_req_flr)\n\t\tcgx_lmac_internal_loopback(cgxd, lmac_id, false);\n\treturn 0;\n}\n\nstatic int cgx_configure_interrupt(struct cgx *cgx, struct lmac *lmac,\n\t\t\t\t   int cnt, bool req_free)\n{\n\tstruct mac_ops *mac_ops = cgx->mac_ops;\n\tu64 offset, ena_bit;\n\tunsigned int irq;\n\tint err;\n\n\tirq      = pci_irq_vector(cgx->pdev, mac_ops->lmac_fwi +\n\t\t\t\t  cnt * mac_ops->irq_offset);\n\toffset   = mac_ops->int_set_reg;\n\tena_bit  = mac_ops->int_ena_bit;\n\n\tif (req_free) {\n\t\tfree_irq(irq, lmac);\n\t\treturn 0;\n\t}\n\n\terr = request_irq(irq, cgx_fwi_event_handler, 0, lmac->name, lmac);\n\tif (err)\n\t\treturn err;\n\n\t \n\tcgx_write(cgx, lmac->lmac_id, offset, ena_bit);\n\treturn 0;\n}\n\nint cgx_get_nr_lmacs(void *cgxd)\n{\n\tstruct cgx *cgx = cgxd;\n\n\treturn cgx_read(cgx, 0, CGXX_CMRX_RX_LMACS) & 0x7ULL;\n}\n\nu8 cgx_get_lmacid(void *cgxd, u8 lmac_index)\n{\n\tstruct cgx *cgx = cgxd;\n\n\treturn cgx->lmac_idmap[lmac_index]->lmac_id;\n}\n\nunsigned long cgx_get_lmac_bmap(void *cgxd)\n{\n\tstruct cgx *cgx = cgxd;\n\n\treturn cgx->lmac_bmap;\n}\n\nstatic int cgx_lmac_init(struct cgx *cgx)\n{\n\tstruct lmac *lmac;\n\tu64 lmac_list;\n\tint i, err;\n\n\t \n\tif (cgx->mac_ops->non_contiguous_serdes_lane) {\n\t\tif (is_dev_rpm2(cgx))\n\t\t\tlmac_list =\n\t\t\t\tcgx_read(cgx, 0, RPM2_CMRX_RX_LMACS) & 0xFFULL;\n\t\telse\n\t\t\tlmac_list =\n\t\t\t\tcgx_read(cgx, 0, CGXX_CMRX_RX_LMACS) & 0xFULL;\n\t}\n\n\tif (cgx->lmac_count > cgx->max_lmac_per_mac)\n\t\tcgx->lmac_count = cgx->max_lmac_per_mac;\n\n\tfor (i = 0; i < cgx->lmac_count; i++) {\n\t\tlmac = kzalloc(sizeof(struct lmac), GFP_KERNEL);\n\t\tif (!lmac)\n\t\t\treturn -ENOMEM;\n\t\tlmac->name = kcalloc(1, sizeof(\"cgx_fwi_xxx_yyy\"), GFP_KERNEL);\n\t\tif (!lmac->name) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_lmac_free;\n\t\t}\n\t\tsprintf(lmac->name, \"cgx_fwi_%d_%d\", cgx->cgx_id, i);\n\t\tif (cgx->mac_ops->non_contiguous_serdes_lane) {\n\t\t\tlmac->lmac_id = __ffs64(lmac_list);\n\t\t\tlmac_list   &= ~BIT_ULL(lmac->lmac_id);\n\t\t} else {\n\t\t\tlmac->lmac_id = i;\n\t\t}\n\n\t\tlmac->cgx = cgx;\n\t\tlmac->mac_to_index_bmap.max =\n\t\t\t\tcgx->mac_ops->dmac_filter_count /\n\t\t\t\tcgx->lmac_count;\n\n\t\terr = rvu_alloc_bitmap(&lmac->mac_to_index_bmap);\n\t\tif (err)\n\t\t\tgoto err_name_free;\n\n\t\t \n\t\tset_bit(0, lmac->mac_to_index_bmap.bmap);\n\n\t\tlmac->rx_fc_pfvf_bmap.max = 128;\n\t\terr = rvu_alloc_bitmap(&lmac->rx_fc_pfvf_bmap);\n\t\tif (err)\n\t\t\tgoto err_dmac_bmap_free;\n\n\t\tlmac->tx_fc_pfvf_bmap.max = 128;\n\t\terr = rvu_alloc_bitmap(&lmac->tx_fc_pfvf_bmap);\n\t\tif (err)\n\t\t\tgoto err_rx_fc_bmap_free;\n\n\t\tinit_waitqueue_head(&lmac->wq_cmd_cmplt);\n\t\tmutex_init(&lmac->cmd_lock);\n\t\tspin_lock_init(&lmac->event_cb_lock);\n\t\terr = cgx_configure_interrupt(cgx, lmac, lmac->lmac_id, false);\n\t\tif (err)\n\t\t\tgoto err_bitmap_free;\n\n\t\t \n\t\tcgx->lmac_idmap[lmac->lmac_id] = lmac;\n\t\tset_bit(lmac->lmac_id, &cgx->lmac_bmap);\n\t\tcgx->mac_ops->mac_pause_frm_config(cgx, lmac->lmac_id, true);\n\t\tlmac->lmac_type = cgx->mac_ops->get_lmac_type(cgx, lmac->lmac_id);\n\t}\n\n\treturn cgx_lmac_verify_fwi_version(cgx);\n\nerr_bitmap_free:\n\trvu_free_bitmap(&lmac->tx_fc_pfvf_bmap);\nerr_rx_fc_bmap_free:\n\trvu_free_bitmap(&lmac->rx_fc_pfvf_bmap);\nerr_dmac_bmap_free:\n\trvu_free_bitmap(&lmac->mac_to_index_bmap);\nerr_name_free:\n\tkfree(lmac->name);\nerr_lmac_free:\n\tkfree(lmac);\n\treturn err;\n}\n\nstatic int cgx_lmac_exit(struct cgx *cgx)\n{\n\tstruct lmac *lmac;\n\tint i;\n\n\tif (cgx->cgx_cmd_workq) {\n\t\tdestroy_workqueue(cgx->cgx_cmd_workq);\n\t\tcgx->cgx_cmd_workq = NULL;\n\t}\n\n\t \n\tfor_each_set_bit(i, &cgx->lmac_bmap, cgx->max_lmac_per_mac) {\n\t\tlmac = cgx->lmac_idmap[i];\n\t\tif (!lmac)\n\t\t\tcontinue;\n\t\tcgx->mac_ops->mac_pause_frm_config(cgx, lmac->lmac_id, false);\n\t\tcgx_configure_interrupt(cgx, lmac, lmac->lmac_id, true);\n\t\tkfree(lmac->mac_to_index_bmap.bmap);\n\t\tkfree(lmac->name);\n\t\tkfree(lmac);\n\t}\n\n\treturn 0;\n}\n\nstatic void cgx_populate_features(struct cgx *cgx)\n{\n\tu64 cfg;\n\n\tcfg = cgx_read(cgx, 0, CGX_CONST);\n\tcgx->mac_ops->fifo_len = FIELD_GET(CGX_CONST_RXFIFO_SIZE, cfg);\n\tcgx->max_lmac_per_mac = FIELD_GET(CGX_CONST_MAX_LMACS, cfg);\n\n\tif (is_dev_rpm(cgx))\n\t\tcgx->hw_features = (RVU_LMAC_FEAT_DMACF | RVU_MAC_RPM |\n\t\t\t\t    RVU_LMAC_FEAT_FC | RVU_LMAC_FEAT_PTP);\n\telse\n\t\tcgx->hw_features = (RVU_LMAC_FEAT_FC  | RVU_LMAC_FEAT_HIGIG2 |\n\t\t\t\t    RVU_LMAC_FEAT_PTP | RVU_LMAC_FEAT_DMACF);\n}\n\nstatic u8 cgx_get_rxid_mapoffset(struct cgx *cgx)\n{\n\tif (cgx->pdev->subsystem_device == PCI_SUBSYS_DEVID_CNF10KB_RPM ||\n\t    is_dev_rpm2(cgx))\n\t\treturn 0x80;\n\telse\n\t\treturn 0x60;\n}\n\nstatic struct mac_ops\tcgx_mac_ops    = {\n\t.name\t\t=       \"cgx\",\n\t.csr_offset\t=       0,\n\t.lmac_offset    =       18,\n\t.int_register\t=       CGXX_CMRX_INT,\n\t.int_set_reg\t=       CGXX_CMRX_INT_ENA_W1S,\n\t.irq_offset\t=       9,\n\t.int_ena_bit    =       FW_CGX_INT,\n\t.lmac_fwi\t=\tCGX_LMAC_FWI,\n\t.non_contiguous_serdes_lane = false,\n\t.rx_stats_cnt   =       9,\n\t.tx_stats_cnt   =       18,\n\t.dmac_filter_count =    32,\n\t.get_nr_lmacs\t=\tcgx_get_nr_lmacs,\n\t.get_lmac_type  =       cgx_get_lmac_type,\n\t.lmac_fifo_len\t=\tcgx_get_lmac_fifo_len,\n\t.mac_lmac_intl_lbk =    cgx_lmac_internal_loopback,\n\t.mac_get_rx_stats  =\tcgx_get_rx_stats,\n\t.mac_get_tx_stats  =\tcgx_get_tx_stats,\n\t.get_fec_stats\t   =\tcgx_get_fec_stats,\n\t.mac_enadis_rx_pause_fwding =\tcgx_lmac_enadis_rx_pause_fwding,\n\t.mac_get_pause_frm_status =\tcgx_lmac_get_pause_frm_status,\n\t.mac_enadis_pause_frm =\t\tcgx_lmac_enadis_pause_frm,\n\t.mac_pause_frm_config =\t\tcgx_lmac_pause_frm_config,\n\t.mac_enadis_ptp_config =\tcgx_lmac_ptp_config,\n\t.mac_rx_tx_enable =\t\tcgx_lmac_rx_tx_enable,\n\t.mac_tx_enable =\t\tcgx_lmac_tx_enable,\n\t.pfc_config =                   cgx_lmac_pfc_config,\n\t.mac_get_pfc_frm_cfg   =        cgx_lmac_get_pfc_frm_cfg,\n\t.mac_reset   =\t\t\tcgx_lmac_reset,\n};\n\nstatic int cgx_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct cgx *cgx;\n\tint err, nvec;\n\n\tcgx = devm_kzalloc(dev, sizeof(*cgx), GFP_KERNEL);\n\tif (!cgx)\n\t\treturn -ENOMEM;\n\tcgx->pdev = pdev;\n\n\tpci_set_drvdata(pdev, cgx);\n\n\t \n\tif (is_dev_rpm(cgx))\n\t\tcgx->mac_ops = rpm_get_mac_ops(cgx);\n\telse\n\t\tcgx->mac_ops = &cgx_mac_ops;\n\n\tcgx->mac_ops->rxid_map_offset = cgx_get_rxid_mapoffset(cgx);\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to enable PCI device\\n\");\n\t\tpci_set_drvdata(pdev, NULL);\n\t\treturn err;\n\t}\n\n\terr = pci_request_regions(pdev, DRV_NAME);\n\tif (err) {\n\t\tdev_err(dev, \"PCI request regions failed 0x%x\\n\", err);\n\t\tgoto err_disable_device;\n\t}\n\n\t \n\tcgx->reg_base = pcim_iomap(pdev, PCI_CFG_REG_BAR_NUM, 0);\n\tif (!cgx->reg_base) {\n\t\tdev_err(dev, \"CGX: Cannot map CSR memory space, aborting\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_release_regions;\n\t}\n\n\tcgx->lmac_count = cgx->mac_ops->get_nr_lmacs(cgx);\n\tif (!cgx->lmac_count) {\n\t\tdev_notice(dev, \"CGX %d LMAC count is zero, skipping probe\\n\", cgx->cgx_id);\n\t\terr = -EOPNOTSUPP;\n\t\tgoto err_release_regions;\n\t}\n\n\tnvec = pci_msix_vec_count(cgx->pdev);\n\terr = pci_alloc_irq_vectors(pdev, nvec, nvec, PCI_IRQ_MSIX);\n\tif (err < 0 || err != nvec) {\n\t\tdev_err(dev, \"Request for %d msix vectors failed, err %d\\n\",\n\t\t\tnvec, err);\n\t\tgoto err_release_regions;\n\t}\n\n\tcgx->cgx_id = (pci_resource_start(pdev, PCI_CFG_REG_BAR_NUM) >> 24)\n\t\t& CGX_ID_MASK;\n\n\t \n\tINIT_WORK(&cgx->cgx_cmd_work, cgx_lmac_linkup_work);\n\tcgx->cgx_cmd_workq = alloc_workqueue(\"cgx_cmd_workq\", 0, 0);\n\tif (!cgx->cgx_cmd_workq) {\n\t\tdev_err(dev, \"alloc workqueue failed for cgx cmd\");\n\t\terr = -ENOMEM;\n\t\tgoto err_free_irq_vectors;\n\t}\n\n\tlist_add(&cgx->cgx_list, &cgx_list);\n\n\n\tcgx_populate_features(cgx);\n\n\tmutex_init(&cgx->lock);\n\n\terr = cgx_lmac_init(cgx);\n\tif (err)\n\t\tgoto err_release_lmac;\n\n\treturn 0;\n\nerr_release_lmac:\n\tcgx_lmac_exit(cgx);\n\tlist_del(&cgx->cgx_list);\nerr_free_irq_vectors:\n\tpci_free_irq_vectors(pdev);\nerr_release_regions:\n\tpci_release_regions(pdev);\nerr_disable_device:\n\tpci_disable_device(pdev);\n\tpci_set_drvdata(pdev, NULL);\n\treturn err;\n}\n\nstatic void cgx_remove(struct pci_dev *pdev)\n{\n\tstruct cgx *cgx = pci_get_drvdata(pdev);\n\n\tif (cgx) {\n\t\tcgx_lmac_exit(cgx);\n\t\tlist_del(&cgx->cgx_list);\n\t}\n\tpci_free_irq_vectors(pdev);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\tpci_set_drvdata(pdev, NULL);\n}\n\nstruct pci_driver cgx_driver = {\n\t.name = DRV_NAME,\n\t.id_table = cgx_id_table,\n\t.probe = cgx_probe,\n\t.remove = cgx_remove,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}