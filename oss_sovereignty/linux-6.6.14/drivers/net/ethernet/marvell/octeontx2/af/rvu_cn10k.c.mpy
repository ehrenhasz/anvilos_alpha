{
  "module_name": "rvu_cn10k.c",
  "hash_id": "039fb853f6f8cb5a77157905df4d4ab9cefb7dfdac67f82db5cd521cd57d6681",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/af/rvu_cn10k.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/pci.h>\n#include \"rvu.h\"\n#include \"cgx.h\"\n#include \"rvu_reg.h\"\n\n \n#define LMT_TBL_OP_READ\t\t0\n#define LMT_TBL_OP_WRITE\t1\n#define LMT_MAP_TABLE_SIZE\t(128 * 1024)\n#define LMT_MAPTBL_ENTRY_SIZE\t16\n\n \nstatic int lmtst_map_table_ops(struct rvu *rvu, u32 index, u64 *val,\n\t\t\t       int lmt_tbl_op)\n{\n\tvoid __iomem *lmt_map_base;\n\tu64 tbl_base;\n\n\ttbl_base = rvu_read64(rvu, BLKADDR_APR, APR_AF_LMT_MAP_BASE);\n\n\tlmt_map_base = ioremap_wc(tbl_base, LMT_MAP_TABLE_SIZE);\n\tif (!lmt_map_base) {\n\t\tdev_err(rvu->dev, \"Failed to setup lmt map table mapping!!\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (lmt_tbl_op == LMT_TBL_OP_READ) {\n\t\t*val = readq(lmt_map_base + index);\n\t} else {\n\t\twriteq((*val), (lmt_map_base + index));\n\t\t \n\t\trvu_write64(rvu, BLKADDR_APR, APR_AF_LMT_CTL, BIT_ULL(0));\n\t\trvu_read64(rvu, BLKADDR_APR, APR_AF_LMT_CTL);\n\t\trvu_write64(rvu, BLKADDR_APR, APR_AF_LMT_CTL, 0x00);\n\t}\n\n\tiounmap(lmt_map_base);\n\treturn 0;\n}\n\n#define LMT_MAP_TBL_W1_OFF  8\nstatic u32 rvu_get_lmtst_tbl_index(struct rvu *rvu, u16 pcifunc)\n{\n\treturn ((rvu_get_pf(pcifunc) * rvu->hw->total_vfs) +\n\t\t(pcifunc & RVU_PFVF_FUNC_MASK)) * LMT_MAPTBL_ENTRY_SIZE;\n}\n\nstatic int rvu_get_lmtaddr(struct rvu *rvu, u16 pcifunc,\n\t\t\t   u64 iova, u64 *lmt_addr)\n{\n\tu64 pa, val, pf;\n\tint err = 0;\n\n\tif (!iova) {\n\t\tdev_err(rvu->dev, \"%s Requested Null address for transulation\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_lock(&rvu->rsrc_lock);\n\trvu_write64(rvu, BLKADDR_RVUM, RVU_AF_SMMU_ADDR_REQ, iova);\n\tpf = rvu_get_pf(pcifunc) & 0x1F;\n\tval = BIT_ULL(63) | BIT_ULL(14) | BIT_ULL(13) | pf << 8 |\n\t      ((pcifunc & RVU_PFVF_FUNC_MASK) & 0xFF);\n\trvu_write64(rvu, BLKADDR_RVUM, RVU_AF_SMMU_TXN_REQ, val);\n\n\terr = rvu_poll_reg(rvu, BLKADDR_RVUM, RVU_AF_SMMU_ADDR_RSP_STS, BIT_ULL(0), false);\n\tif (err) {\n\t\tdev_err(rvu->dev, \"%s LMTLINE iova transulation failed\\n\", __func__);\n\t\tgoto exit;\n\t}\n\tval = rvu_read64(rvu, BLKADDR_RVUM, RVU_AF_SMMU_ADDR_RSP_STS);\n\tif (val & ~0x1ULL) {\n\t\tdev_err(rvu->dev, \"%s LMTLINE iova transulation failed err:%llx\\n\", __func__, val);\n\t\terr = -EIO;\n\t\tgoto exit;\n\t}\n\t \n\tpa = rvu_read64(rvu, BLKADDR_RVUM, RVU_AF_SMMU_TLN_FLIT0) >> 18;\n\tpa &= GENMASK_ULL(39, 0);\n\t*lmt_addr = (pa << 12) | (iova  & 0xFFF);\nexit:\n\tmutex_unlock(&rvu->rsrc_lock);\n\treturn err;\n}\n\nstatic int rvu_update_lmtaddr(struct rvu *rvu, u16 pcifunc, u64 lmt_addr)\n{\n\tstruct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, pcifunc);\n\tu32 tbl_idx;\n\tint err = 0;\n\tu64 val;\n\n\t \n\ttbl_idx = rvu_get_lmtst_tbl_index(rvu, pcifunc);\n\terr = lmtst_map_table_ops(rvu, tbl_idx, &val, LMT_TBL_OP_READ);\n\tif (err) {\n\t\tdev_err(rvu->dev,\n\t\t\t\"Failed to read LMT map table: index 0x%x err %d\\n\",\n\t\t\ttbl_idx, err);\n\t\treturn err;\n\t}\n\n\t \n\tif (!pfvf->lmt_base_addr)\n\t\tpfvf->lmt_base_addr = val;\n\n\t \n\terr = lmtst_map_table_ops(rvu, tbl_idx, &lmt_addr, LMT_TBL_OP_WRITE);\n\tif (err) {\n\t\tdev_err(rvu->dev,\n\t\t\t\"Failed to update LMT map table: index 0x%x err %d\\n\",\n\t\t\ttbl_idx, err);\n\t\treturn err;\n\t}\n\treturn 0;\n}\n\nint rvu_mbox_handler_lmtst_tbl_setup(struct rvu *rvu,\n\t\t\t\t     struct lmtst_tbl_setup_req *req,\n\t\t\t\t     struct msg_rsp *rsp)\n{\n\tstruct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);\n\tu32 pri_tbl_idx, tbl_idx;\n\tu64 lmt_addr;\n\tint err = 0;\n\tu64 val;\n\n\t \n\tif (req->use_local_lmt_region) {\n\t\terr = rvu_get_lmtaddr(rvu, req->hdr.pcifunc,\n\t\t\t\t      req->lmt_iova, &lmt_addr);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\t \n\t\terr = rvu_update_lmtaddr(rvu, req->hdr.pcifunc, lmt_addr);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\t \n\tif (req->base_pcifunc) {\n\t\t \n\t\tpri_tbl_idx = rvu_get_lmtst_tbl_index(rvu, req->base_pcifunc);\n\n\t\t \n\t\terr = lmtst_map_table_ops(rvu, pri_tbl_idx, &val,\n\t\t\t\t\t  LMT_TBL_OP_READ);\n\t\tif (err) {\n\t\t\tdev_err(rvu->dev,\n\t\t\t\t\"Failed to read LMT map table: index 0x%x err %d\\n\",\n\t\t\t\tpri_tbl_idx, err);\n\t\t\tgoto error;\n\t\t}\n\n\t\t \n\t\terr = rvu_update_lmtaddr(rvu, req->hdr.pcifunc, val);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\t \n\tif (req->sch_ena || req->dis_sched_early_comp || req->dis_line_pref) {\n\t\ttbl_idx = rvu_get_lmtst_tbl_index(rvu, req->hdr.pcifunc);\n\t\terr = lmtst_map_table_ops(rvu, tbl_idx + LMT_MAP_TBL_W1_OFF,\n\t\t\t\t\t  &val, LMT_TBL_OP_READ);\n\t\tif (err) {\n\t\t\tdev_err(rvu->dev,\n\t\t\t\t\"Failed to read LMT map table: index 0x%x err %d\\n\",\n\t\t\t\ttbl_idx + LMT_MAP_TBL_W1_OFF, err);\n\t\t\tgoto error;\n\t\t}\n\n\t\t \n\t\tif (!pfvf->lmt_map_ent_w1)\n\t\t\tpfvf->lmt_map_ent_w1 = val;\n\n\t\t \n\t\tif (req->dis_sched_early_comp)\n\t\t\tval |= (req->dis_sched_early_comp <<\n\t\t\t\tAPR_LMT_MAP_ENT_DIS_SCH_CMP_SHIFT);\n\t\t \n\t\tif (req->sch_ena)\n\t\t\tval |= (req->sch_ena << APR_LMT_MAP_ENT_SCH_ENA_SHIFT) |\n\t\t\t\treq->ssow_pf_func;\n\t\t \n\t\tif (req->dis_line_pref)\n\t\t\tval |= (req->dis_line_pref <<\n\t\t\t\tAPR_LMT_MAP_ENT_DIS_LINE_PREF_SHIFT);\n\n\t\terr = lmtst_map_table_ops(rvu, tbl_idx + LMT_MAP_TBL_W1_OFF,\n\t\t\t\t\t  &val, LMT_TBL_OP_WRITE);\n\t\tif (err) {\n\t\t\tdev_err(rvu->dev,\n\t\t\t\t\"Failed to update LMT map table: index 0x%x err %d\\n\",\n\t\t\t\ttbl_idx + LMT_MAP_TBL_W1_OFF, err);\n\t\t\tgoto error;\n\t\t}\n\t}\n\nerror:\n\treturn err;\n}\n\n \nvoid rvu_reset_lmt_map_tbl(struct rvu *rvu, u16 pcifunc)\n{\n\tstruct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, pcifunc);\n\tu32 tbl_idx;\n\tint err;\n\n\tif (is_rvu_otx2(rvu))\n\t\treturn;\n\n\tif (pfvf->lmt_base_addr || pfvf->lmt_map_ent_w1) {\n\t\t \n\t\ttbl_idx = rvu_get_lmtst_tbl_index(rvu, pcifunc);\n\t\t \n\t\tif (pfvf->lmt_base_addr) {\n\t\t\terr = lmtst_map_table_ops(rvu, tbl_idx,\n\t\t\t\t\t\t  &pfvf->lmt_base_addr,\n\t\t\t\t\t\t  LMT_TBL_OP_WRITE);\n\t\t\tif (err)\n\t\t\t\tdev_err(rvu->dev,\n\t\t\t\t\t\"Failed to update LMT map table: index 0x%x err %d\\n\",\n\t\t\t\t\ttbl_idx, err);\n\t\t\tpfvf->lmt_base_addr = 0;\n\t\t}\n\t\t \n\t\tif (pfvf->lmt_map_ent_w1) {\n\t\t\terr = lmtst_map_table_ops(rvu,\n\t\t\t\t\t\t  tbl_idx + LMT_MAP_TBL_W1_OFF,\n\t\t\t\t\t\t  &pfvf->lmt_map_ent_w1,\n\t\t\t\t\t\t  LMT_TBL_OP_WRITE);\n\t\t\tif (err)\n\t\t\t\tdev_err(rvu->dev,\n\t\t\t\t\t\"Failed to update LMT map table: index 0x%x err %d\\n\",\n\t\t\t\t\ttbl_idx + LMT_MAP_TBL_W1_OFF, err);\n\t\t\tpfvf->lmt_map_ent_w1 = 0;\n\t\t}\n\t}\n}\n\nint rvu_set_channels_base(struct rvu *rvu)\n{\n\tu16 nr_lbk_chans, nr_sdp_chans, nr_cgx_chans, nr_cpt_chans;\n\tu16 sdp_chan_base, cgx_chan_base, cpt_chan_base;\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tu64 nix_const, nix_const1;\n\tint blkaddr;\n\n\tblkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, 0);\n\tif (blkaddr < 0)\n\t\treturn blkaddr;\n\n\tnix_const = rvu_read64(rvu, blkaddr, NIX_AF_CONST);\n\tnix_const1 = rvu_read64(rvu, blkaddr, NIX_AF_CONST1);\n\n\thw->cgx = (nix_const >> 12) & 0xFULL;\n\thw->lmac_per_cgx = (nix_const >> 8) & 0xFULL;\n\thw->cgx_links = hw->cgx * hw->lmac_per_cgx;\n\thw->lbk_links = (nix_const >> 24) & 0xFULL;\n\thw->cpt_links = (nix_const >> 44) & 0xFULL;\n\thw->sdp_links = 1;\n\n\thw->cgx_chan_base = NIX_CHAN_CGX_LMAC_CHX(0, 0, 0);\n\thw->lbk_chan_base = NIX_CHAN_LBK_CHX(0, 0);\n\thw->sdp_chan_base = NIX_CHAN_SDP_CH_START;\n\n\t \n\tif (!(nix_const & BIT_ULL(60)))\n\t\treturn 0;\n\n\thw->cap.programmable_chans = true;\n\n\t \n\tnr_lbk_chans = (nix_const >> 16) & 0xFFULL;\n\tnr_sdp_chans = nix_const1 & 0xFFFULL;\n\tnr_cgx_chans = nix_const & 0xFFULL;\n\tnr_cpt_chans = (nix_const >> 32) & 0xFFFULL;\n\n\tsdp_chan_base = hw->lbk_chan_base + hw->lbk_links * nr_lbk_chans;\n\t \n\thw->sdp_chan_base = ALIGN(sdp_chan_base, nr_sdp_chans);\n\n\tcgx_chan_base = hw->sdp_chan_base + hw->sdp_links * nr_sdp_chans;\n\thw->cgx_chan_base = ALIGN(cgx_chan_base, nr_cgx_chans);\n\n\tcpt_chan_base = hw->cgx_chan_base + hw->cgx_links * nr_cgx_chans;\n\thw->cpt_chan_base = ALIGN(cpt_chan_base, nr_cpt_chans);\n\n\t \n\tif (cpt_chan_base <= NIX_CHAN_CPT_CH_START) {\n\t\thw->cpt_chan_base = NIX_CHAN_CPT_CH_START;\n\t} else {\n\t\tdev_err(rvu->dev,\n\t\t\t\"CPT channels could not fit in the range 2048-4095\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n#define LBK_CONNECT_NIXX(a)\t\t(0x0 + (a))\n\nstatic void __rvu_lbk_set_chans(struct rvu *rvu, void __iomem *base,\n\t\t\t\tu64 offset, int lbkid, u16 chans)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tu64 cfg;\n\n\tcfg = readq(base + offset);\n\tcfg &= ~(LBK_LINK_CFG_RANGE_MASK |\n\t\t LBK_LINK_CFG_ID_MASK | LBK_LINK_CFG_BASE_MASK);\n\tcfg |=\tFIELD_PREP(LBK_LINK_CFG_RANGE_MASK, ilog2(chans));\n\tcfg |=\tFIELD_PREP(LBK_LINK_CFG_ID_MASK, lbkid);\n\tcfg |=\tFIELD_PREP(LBK_LINK_CFG_BASE_MASK, hw->lbk_chan_base);\n\n\twriteq(cfg, base + offset);\n}\n\nstatic void rvu_lbk_set_channels(struct rvu *rvu)\n{\n\tstruct pci_dev *pdev = NULL;\n\tvoid __iomem *base;\n\tu64 lbk_const;\n\tu8 src, dst;\n\tu16 chans;\n\n\t \n\twhile (true) {\n\t\tpdev = pci_get_device(PCI_VENDOR_ID_CAVIUM,\n\t\t\t\t      PCI_DEVID_OCTEONTX2_LBK, pdev);\n\t\tif (!pdev)\n\t\t\treturn;\n\n\t\tbase = pci_ioremap_bar(pdev, 0);\n\t\tif (!base)\n\t\t\tgoto err_put;\n\n\t\tlbk_const = readq(base + LBK_CONST);\n\t\tchans = FIELD_GET(LBK_CONST_CHANS, lbk_const);\n\t\tdst = FIELD_GET(LBK_CONST_DST, lbk_const);\n\t\tsrc = FIELD_GET(LBK_CONST_SRC, lbk_const);\n\n\t\tif (src == dst) {\n\t\t\tif (src == LBK_CONNECT_NIXX(0)) {  \n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_X2P,\n\t\t\t\t\t\t    0, chans);\n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_P2X,\n\t\t\t\t\t\t    0, chans);\n\t\t\t} else if (src == LBK_CONNECT_NIXX(1)) {  \n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_X2P,\n\t\t\t\t\t\t    1, chans);\n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_P2X,\n\t\t\t\t\t\t    1, chans);\n\t\t\t}\n\t\t} else {\n\t\t\tif (src == LBK_CONNECT_NIXX(0)) {  \n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_X2P,\n\t\t\t\t\t\t    0, chans);\n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_P2X,\n\t\t\t\t\t\t    1, chans);\n\t\t\t} else if (src == LBK_CONNECT_NIXX(1)) {  \n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_X2P,\n\t\t\t\t\t\t    1, chans);\n\t\t\t\t__rvu_lbk_set_chans(rvu, base, LBK_LINK_CFG_P2X,\n\t\t\t\t\t\t    0, chans);\n\t\t\t}\n\t\t}\n\t\tiounmap(base);\n\t}\nerr_put:\n\tpci_dev_put(pdev);\n}\n\nstatic void __rvu_nix_set_channels(struct rvu *rvu, int blkaddr)\n{\n\tu64 nix_const1 = rvu_read64(rvu, blkaddr, NIX_AF_CONST1);\n\tu64 nix_const = rvu_read64(rvu, blkaddr, NIX_AF_CONST);\n\tu16 cgx_chans, lbk_chans, sdp_chans, cpt_chans;\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tint link, nix_link = 0;\n\tu16 start;\n\tu64 cfg;\n\n\tcgx_chans = nix_const & 0xFFULL;\n\tlbk_chans = (nix_const >> 16) & 0xFFULL;\n\tsdp_chans = nix_const1 & 0xFFFULL;\n\tcpt_chans = (nix_const >> 32) & 0xFFFULL;\n\n\tstart = hw->cgx_chan_base;\n\tfor (link = 0; link < hw->cgx_links; link++, nix_link++) {\n\t\tcfg = rvu_read64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link));\n\t\tcfg &= ~(NIX_AF_LINKX_BASE_MASK | NIX_AF_LINKX_RANGE_MASK);\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_RANGE_MASK, ilog2(cgx_chans));\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_BASE_MASK, start);\n\t\trvu_write64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link), cfg);\n\t\tstart += cgx_chans;\n\t}\n\n\tstart = hw->lbk_chan_base;\n\tfor (link = 0; link < hw->lbk_links; link++, nix_link++) {\n\t\tcfg = rvu_read64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link));\n\t\tcfg &= ~(NIX_AF_LINKX_BASE_MASK | NIX_AF_LINKX_RANGE_MASK);\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_RANGE_MASK, ilog2(lbk_chans));\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_BASE_MASK, start);\n\t\trvu_write64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link), cfg);\n\t\tstart += lbk_chans;\n\t}\n\n\tstart = hw->sdp_chan_base;\n\tfor (link = 0; link < hw->sdp_links; link++, nix_link++) {\n\t\tcfg = rvu_read64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link));\n\t\tcfg &= ~(NIX_AF_LINKX_BASE_MASK | NIX_AF_LINKX_RANGE_MASK);\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_RANGE_MASK, ilog2(sdp_chans));\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_BASE_MASK, start);\n\t\trvu_write64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link), cfg);\n\t\tstart += sdp_chans;\n\t}\n\n\tstart = hw->cpt_chan_base;\n\tfor (link = 0; link < hw->cpt_links; link++, nix_link++) {\n\t\tcfg = rvu_read64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link));\n\t\tcfg &= ~(NIX_AF_LINKX_BASE_MASK | NIX_AF_LINKX_RANGE_MASK);\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_RANGE_MASK, ilog2(cpt_chans));\n\t\tcfg |=\tFIELD_PREP(NIX_AF_LINKX_BASE_MASK, start);\n\t\trvu_write64(rvu, blkaddr, NIX_AF_LINKX_CFG(nix_link), cfg);\n\t\tstart += cpt_chans;\n\t}\n}\n\nstatic void rvu_nix_set_channels(struct rvu *rvu)\n{\n\tint blkaddr = 0;\n\n\tblkaddr = rvu_get_next_nix_blkaddr(rvu, blkaddr);\n\twhile (blkaddr) {\n\t\t__rvu_nix_set_channels(rvu, blkaddr);\n\t\tblkaddr = rvu_get_next_nix_blkaddr(rvu, blkaddr);\n\t}\n}\n\nstatic void __rvu_rpm_set_channels(int cgxid, int lmacid, u16 base)\n{\n\tu64 cfg;\n\n\tcfg = cgx_lmac_read(cgxid, lmacid, RPMX_CMRX_LINK_CFG);\n\tcfg &= ~(RPMX_CMRX_LINK_BASE_MASK | RPMX_CMRX_LINK_RANGE_MASK);\n\n\t \n\tcfg |=\tFIELD_PREP(RPMX_CMRX_LINK_RANGE_MASK, ilog2(16));\n\tcfg |=\tFIELD_PREP(RPMX_CMRX_LINK_BASE_MASK, base);\n\tcgx_lmac_write(cgxid, lmacid, RPMX_CMRX_LINK_CFG, cfg);\n}\n\nstatic void rvu_rpm_set_channels(struct rvu *rvu)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tu16 base = hw->cgx_chan_base;\n\tint cgx, lmac;\n\n\tfor (cgx = 0; cgx < rvu->cgx_cnt_max; cgx++) {\n\t\tfor (lmac = 0; lmac < hw->lmac_per_cgx; lmac++) {\n\t\t\t__rvu_rpm_set_channels(cgx, lmac, base);\n\t\t\tbase += 16;\n\t\t}\n\t}\n}\n\nvoid rvu_program_channels(struct rvu *rvu)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\n\tif (!hw->cap.programmable_chans)\n\t\treturn;\n\n\trvu_nix_set_channels(rvu);\n\trvu_lbk_set_channels(rvu);\n\trvu_rpm_set_channels(rvu);\n}\n\nvoid rvu_nix_block_cn10k_init(struct rvu *rvu, struct nix_hw *nix_hw)\n{\n\tint blkaddr = nix_hw->blkaddr;\n\tu64 cfg;\n\n\t \n\trvu_write64(rvu, blkaddr, NIX_AF_VWQE_TIMER, 0x3FULL);\n\n\t \n\tcfg = rvu_read64(rvu, blkaddr, NIX_AF_CFG);\n\tcfg |= BIT_ULL(1) | BIT_ULL(2);\n\trvu_write64(rvu, blkaddr, NIX_AF_CFG, cfg);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}