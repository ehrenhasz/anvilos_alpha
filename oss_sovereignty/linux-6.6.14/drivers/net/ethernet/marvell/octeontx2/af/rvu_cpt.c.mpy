{
  "module_name": "rvu_cpt.c",
  "hash_id": "59c0694ba90cd4cacd58fc1594139a65f14b80e04bec1d0225245931150be2ee",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/pci.h>\n#include \"rvu_struct.h\"\n#include \"rvu_reg.h\"\n#include \"mbox.h\"\n#include \"rvu.h\"\n\n \n#define\tPCI_DEVID_OTX2_CPT_PF\t0xA0FD\n#define\tPCI_DEVID_OTX2_CPT10K_PF 0xA0F2\n\n \n#define CPT_CTX_ILEN    1ULL\n\n#define cpt_get_eng_sts(e_min, e_max, rsp, etype)                   \\\n({                                                                  \\\n\tu64 free_sts = 0, busy_sts = 0;                             \\\n\ttypeof(rsp) _rsp = rsp;                                     \\\n\tu32 e, i;                                                   \\\n\t\t\t\t\t\t\t\t    \\\n\tfor (e = (e_min), i = 0; e < (e_max); e++, i++) {           \\\n\t\treg = rvu_read64(rvu, blkaddr, CPT_AF_EXEX_STS(e)); \\\n\t\tif (reg & 0x1)                                      \\\n\t\t\tbusy_sts |= 1ULL << i;                      \\\n\t\t\t\t\t\t\t\t    \\\n\t\tif (reg & 0x2)                                      \\\n\t\t\tfree_sts |= 1ULL << i;                      \\\n\t}                                                           \\\n\t(_rsp)->busy_sts_##etype = busy_sts;                        \\\n\t(_rsp)->free_sts_##etype = free_sts;                        \\\n})\n\nstatic irqreturn_t cpt_af_flt_intr_handler(int vec, void *ptr)\n{\n\tstruct rvu_block *block = ptr;\n\tstruct rvu *rvu = block->rvu;\n\tint blkaddr = block->addr;\n\tu64 reg, val;\n\tint i, eng;\n\tu8 grp;\n\n\treg = rvu_read64(rvu, blkaddr, CPT_AF_FLTX_INT(vec));\n\tdev_err_ratelimited(rvu->dev, \"Received CPTAF FLT%d irq : 0x%llx\", vec, reg);\n\n\ti = -1;\n\twhile ((i = find_next_bit((unsigned long *)&reg, 64, i + 1)) < 64) {\n\t\tswitch (vec) {\n\t\tcase 0:\n\t\t\teng = i;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\teng = i + 64;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\teng = i + 128;\n\t\t\tbreak;\n\t\t}\n\t\tgrp = rvu_read64(rvu, blkaddr, CPT_AF_EXEX_CTL2(eng)) & 0xFF;\n\t\t \n\t\trvu_write64(rvu, blkaddr, CPT_AF_EXEX_CTL2(eng), 0x0);\n\t\tval = rvu_read64(rvu, blkaddr, CPT_AF_EXEX_CTL(eng));\n\t\trvu_write64(rvu, blkaddr, CPT_AF_EXEX_CTL(eng), val & ~1ULL);\n\n\t\trvu_write64(rvu, blkaddr, CPT_AF_EXEX_CTL2(eng), grp);\n\t\trvu_write64(rvu, blkaddr, CPT_AF_EXEX_CTL(eng), val | 1ULL);\n\n\t\tspin_lock(&rvu->cpt_intr_lock);\n\t\tblock->cpt_flt_eng_map[vec] |= BIT_ULL(i);\n\t\tval = rvu_read64(rvu, blkaddr, CPT_AF_EXEX_STS(eng));\n\t\tval = val & 0x3;\n\t\tif (val == 0x1 || val == 0x2)\n\t\t\tblock->cpt_rcvrd_eng_map[vec] |= BIT_ULL(i);\n\t\tspin_unlock(&rvu->cpt_intr_lock);\n\t}\n\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT(vec), reg);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t rvu_cpt_af_flt0_intr_handler(int irq, void *ptr)\n{\n\treturn cpt_af_flt_intr_handler(CPT_AF_INT_VEC_FLT0, ptr);\n}\n\nstatic irqreturn_t rvu_cpt_af_flt1_intr_handler(int irq, void *ptr)\n{\n\treturn cpt_af_flt_intr_handler(CPT_AF_INT_VEC_FLT1, ptr);\n}\n\nstatic irqreturn_t rvu_cpt_af_flt2_intr_handler(int irq, void *ptr)\n{\n\treturn cpt_af_flt_intr_handler(CPT_10K_AF_INT_VEC_FLT2, ptr);\n}\n\nstatic irqreturn_t rvu_cpt_af_rvu_intr_handler(int irq, void *ptr)\n{\n\tstruct rvu_block *block = ptr;\n\tstruct rvu *rvu = block->rvu;\n\tint blkaddr = block->addr;\n\tu64 reg;\n\n\treg = rvu_read64(rvu, blkaddr, CPT_AF_RVU_INT);\n\tdev_err_ratelimited(rvu->dev, \"Received CPTAF RVU irq : 0x%llx\", reg);\n\n\trvu_write64(rvu, blkaddr, CPT_AF_RVU_INT, reg);\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t rvu_cpt_af_ras_intr_handler(int irq, void *ptr)\n{\n\tstruct rvu_block *block = ptr;\n\tstruct rvu *rvu = block->rvu;\n\tint blkaddr = block->addr;\n\tu64 reg;\n\n\treg = rvu_read64(rvu, blkaddr, CPT_AF_RAS_INT);\n\tdev_err_ratelimited(rvu->dev, \"Received CPTAF RAS irq : 0x%llx\", reg);\n\n\trvu_write64(rvu, blkaddr, CPT_AF_RAS_INT, reg);\n\treturn IRQ_HANDLED;\n}\n\nstatic int rvu_cpt_do_register_interrupt(struct rvu_block *block, int irq_offs,\n\t\t\t\t\t irq_handler_t handler,\n\t\t\t\t\t const char *name)\n{\n\tstruct rvu *rvu = block->rvu;\n\tint ret;\n\n\tret = request_irq(pci_irq_vector(rvu->pdev, irq_offs), handler, 0,\n\t\t\t  name, block);\n\tif (ret) {\n\t\tdev_err(rvu->dev, \"RVUAF: %s irq registration failed\", name);\n\t\treturn ret;\n\t}\n\n\tWARN_ON(rvu->irq_allocated[irq_offs]);\n\trvu->irq_allocated[irq_offs] = true;\n\treturn 0;\n}\n\nstatic void cpt_10k_unregister_interrupts(struct rvu_block *block, int off)\n{\n\tstruct rvu *rvu = block->rvu;\n\tint blkaddr = block->addr;\n\tint i;\n\n\t \n\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT_ENA_W1C(0), ~0ULL);\n\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT_ENA_W1C(1), ~0ULL);\n\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT_ENA_W1C(2), 0xFFFF);\n\n\trvu_write64(rvu, blkaddr, CPT_AF_RVU_INT_ENA_W1C, 0x1);\n\trvu_write64(rvu, blkaddr, CPT_AF_RAS_INT_ENA_W1C, 0x1);\n\n\tfor (i = 0; i < CPT_10K_AF_INT_VEC_CNT; i++)\n\t\tif (rvu->irq_allocated[off + i]) {\n\t\t\tfree_irq(pci_irq_vector(rvu->pdev, off + i), block);\n\t\t\trvu->irq_allocated[off + i] = false;\n\t\t}\n}\n\nstatic void cpt_unregister_interrupts(struct rvu *rvu, int blkaddr)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tstruct rvu_block *block;\n\tint i, offs;\n\n\tif (!is_block_implemented(rvu->hw, blkaddr))\n\t\treturn;\n\toffs = rvu_read64(rvu, blkaddr, CPT_PRIV_AF_INT_CFG) & 0x7FF;\n\tif (!offs) {\n\t\tdev_warn(rvu->dev,\n\t\t\t \"Failed to get CPT_AF_INT vector offsets\\n\");\n\t\treturn;\n\t}\n\tblock = &hw->block[blkaddr];\n\tif (!is_rvu_otx2(rvu))\n\t\treturn cpt_10k_unregister_interrupts(block, offs);\n\n\t \n\tfor (i = 0; i < CPT_AF_INT_VEC_RVU; i++)\n\t\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT_ENA_W1C(i), ~0ULL);\n\trvu_write64(rvu, blkaddr, CPT_AF_RVU_INT_ENA_W1C, 0x1);\n\trvu_write64(rvu, blkaddr, CPT_AF_RAS_INT_ENA_W1C, 0x1);\n\n\tfor (i = 0; i < CPT_AF_INT_VEC_CNT; i++)\n\t\tif (rvu->irq_allocated[offs + i]) {\n\t\t\tfree_irq(pci_irq_vector(rvu->pdev, offs + i), block);\n\t\t\trvu->irq_allocated[offs + i] = false;\n\t\t}\n}\n\nvoid rvu_cpt_unregister_interrupts(struct rvu *rvu)\n{\n\tcpt_unregister_interrupts(rvu, BLKADDR_CPT0);\n\tcpt_unregister_interrupts(rvu, BLKADDR_CPT1);\n}\n\nstatic int cpt_10k_register_interrupts(struct rvu_block *block, int off)\n{\n\tstruct rvu *rvu = block->rvu;\n\tint blkaddr = block->addr;\n\tirq_handler_t flt_fn;\n\tint i, ret;\n\n\tfor (i = CPT_10K_AF_INT_VEC_FLT0; i < CPT_10K_AF_INT_VEC_RVU; i++) {\n\t\tsprintf(&rvu->irq_name[(off + i) * NAME_SIZE], \"CPTAF FLT%d\", i);\n\n\t\tswitch (i) {\n\t\tcase CPT_10K_AF_INT_VEC_FLT0:\n\t\t\tflt_fn = rvu_cpt_af_flt0_intr_handler;\n\t\t\tbreak;\n\t\tcase CPT_10K_AF_INT_VEC_FLT1:\n\t\t\tflt_fn = rvu_cpt_af_flt1_intr_handler;\n\t\t\tbreak;\n\t\tcase CPT_10K_AF_INT_VEC_FLT2:\n\t\t\tflt_fn = rvu_cpt_af_flt2_intr_handler;\n\t\t\tbreak;\n\t\t}\n\t\tret = rvu_cpt_do_register_interrupt(block, off + i,\n\t\t\t\t\t\t    flt_fn, &rvu->irq_name[(off + i) * NAME_SIZE]);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tif (i == CPT_10K_AF_INT_VEC_FLT2)\n\t\t\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT_ENA_W1S(i), 0xFFFF);\n\t\telse\n\t\t\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT_ENA_W1S(i), ~0ULL);\n\t}\n\n\tret = rvu_cpt_do_register_interrupt(block, off + CPT_10K_AF_INT_VEC_RVU,\n\t\t\t\t\t    rvu_cpt_af_rvu_intr_handler,\n\t\t\t\t\t    \"CPTAF RVU\");\n\tif (ret)\n\t\tgoto err;\n\trvu_write64(rvu, blkaddr, CPT_AF_RVU_INT_ENA_W1S, 0x1);\n\n\tret = rvu_cpt_do_register_interrupt(block, off + CPT_10K_AF_INT_VEC_RAS,\n\t\t\t\t\t    rvu_cpt_af_ras_intr_handler,\n\t\t\t\t\t    \"CPTAF RAS\");\n\tif (ret)\n\t\tgoto err;\n\trvu_write64(rvu, blkaddr, CPT_AF_RAS_INT_ENA_W1S, 0x1);\n\n\treturn 0;\nerr:\n\trvu_cpt_unregister_interrupts(rvu);\n\treturn ret;\n}\n\nstatic int cpt_register_interrupts(struct rvu *rvu, int blkaddr)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tstruct rvu_block *block;\n\tirq_handler_t flt_fn;\n\tint i, offs, ret = 0;\n\n\tif (!is_block_implemented(rvu->hw, blkaddr))\n\t\treturn 0;\n\n\tblock = &hw->block[blkaddr];\n\toffs = rvu_read64(rvu, blkaddr, CPT_PRIV_AF_INT_CFG) & 0x7FF;\n\tif (!offs) {\n\t\tdev_warn(rvu->dev,\n\t\t\t \"Failed to get CPT_AF_INT vector offsets\\n\");\n\t\treturn 0;\n\t}\n\n\tif (!is_rvu_otx2(rvu))\n\t\treturn cpt_10k_register_interrupts(block, offs);\n\n\tfor (i = CPT_AF_INT_VEC_FLT0; i < CPT_AF_INT_VEC_RVU; i++) {\n\t\tsprintf(&rvu->irq_name[(offs + i) * NAME_SIZE], \"CPTAF FLT%d\", i);\n\t\tswitch (i) {\n\t\tcase CPT_AF_INT_VEC_FLT0:\n\t\t\tflt_fn = rvu_cpt_af_flt0_intr_handler;\n\t\t\tbreak;\n\t\tcase CPT_AF_INT_VEC_FLT1:\n\t\t\tflt_fn = rvu_cpt_af_flt1_intr_handler;\n\t\t\tbreak;\n\t\t}\n\t\tret = rvu_cpt_do_register_interrupt(block, offs + i,\n\t\t\t\t\t\t    flt_fn, &rvu->irq_name[(offs + i) * NAME_SIZE]);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\trvu_write64(rvu, blkaddr, CPT_AF_FLTX_INT_ENA_W1S(i), ~0ULL);\n\t}\n\n\tret = rvu_cpt_do_register_interrupt(block, offs + CPT_AF_INT_VEC_RVU,\n\t\t\t\t\t    rvu_cpt_af_rvu_intr_handler,\n\t\t\t\t\t    \"CPTAF RVU\");\n\tif (ret)\n\t\tgoto err;\n\trvu_write64(rvu, blkaddr, CPT_AF_RVU_INT_ENA_W1S, 0x1);\n\n\tret = rvu_cpt_do_register_interrupt(block, offs + CPT_AF_INT_VEC_RAS,\n\t\t\t\t\t    rvu_cpt_af_ras_intr_handler,\n\t\t\t\t\t    \"CPTAF RAS\");\n\tif (ret)\n\t\tgoto err;\n\trvu_write64(rvu, blkaddr, CPT_AF_RAS_INT_ENA_W1S, 0x1);\n\n\treturn 0;\nerr:\n\trvu_cpt_unregister_interrupts(rvu);\n\treturn ret;\n}\n\nint rvu_cpt_register_interrupts(struct rvu *rvu)\n{\n\tint ret;\n\n\tret = cpt_register_interrupts(rvu, BLKADDR_CPT0);\n\tif (ret)\n\t\treturn ret;\n\n\treturn cpt_register_interrupts(rvu, BLKADDR_CPT1);\n}\n\nstatic int get_cpt_pf_num(struct rvu *rvu)\n{\n\tint i, domain_nr, cpt_pf_num = -1;\n\tstruct pci_dev *pdev;\n\n\tdomain_nr = pci_domain_nr(rvu->pdev->bus);\n\tfor (i = 0; i < rvu->hw->total_pfs; i++) {\n\t\tpdev = pci_get_domain_bus_and_slot(domain_nr, i + 1, 0);\n\t\tif (!pdev)\n\t\t\tcontinue;\n\n\t\tif (pdev->device == PCI_DEVID_OTX2_CPT_PF ||\n\t\t    pdev->device == PCI_DEVID_OTX2_CPT10K_PF) {\n\t\t\tcpt_pf_num = i;\n\t\t\tput_device(&pdev->dev);\n\t\t\tbreak;\n\t\t}\n\t\tput_device(&pdev->dev);\n\t}\n\treturn cpt_pf_num;\n}\n\nstatic bool is_cpt_pf(struct rvu *rvu, u16 pcifunc)\n{\n\tint cpt_pf_num = rvu->cpt_pf_num;\n\n\tif (rvu_get_pf(pcifunc) != cpt_pf_num)\n\t\treturn false;\n\tif (pcifunc & RVU_PFVF_FUNC_MASK)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool is_cpt_vf(struct rvu *rvu, u16 pcifunc)\n{\n\tint cpt_pf_num = rvu->cpt_pf_num;\n\n\tif (rvu_get_pf(pcifunc) != cpt_pf_num)\n\t\treturn false;\n\tif (!(pcifunc & RVU_PFVF_FUNC_MASK))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int validate_and_get_cpt_blkaddr(int req_blkaddr)\n{\n\tint blkaddr;\n\n\tblkaddr = req_blkaddr ? req_blkaddr : BLKADDR_CPT0;\n\tif (blkaddr != BLKADDR_CPT0 && blkaddr != BLKADDR_CPT1)\n\t\treturn -EINVAL;\n\n\treturn blkaddr;\n}\n\nint rvu_mbox_handler_cpt_lf_alloc(struct rvu *rvu,\n\t\t\t\t  struct cpt_lf_alloc_req_msg *req,\n\t\t\t\t  struct msg_rsp *rsp)\n{\n\tu16 pcifunc = req->hdr.pcifunc;\n\tstruct rvu_block *block;\n\tint cptlf, blkaddr;\n\tint num_lfs, slot;\n\tu64 val;\n\n\tblkaddr = validate_and_get_cpt_blkaddr(req->blkaddr);\n\tif (blkaddr < 0)\n\t\treturn blkaddr;\n\n\tif (req->eng_grpmsk == 0x0)\n\t\treturn CPT_AF_ERR_GRP_INVALID;\n\n\tblock = &rvu->hw->block[blkaddr];\n\tnum_lfs = rvu_get_rsrc_mapcount(rvu_get_pfvf(rvu, pcifunc),\n\t\t\t\t\tblock->addr);\n\tif (!num_lfs)\n\t\treturn CPT_AF_ERR_LF_INVALID;\n\n\t \n\tif (req->nix_pf_func) {\n\t\t \n\t\tif (req->nix_pf_func == RVU_DEFAULT_PF_FUNC)\n\t\t\treq->nix_pf_func = pcifunc;\n\t\tif (!is_pffunc_map_valid(rvu, req->nix_pf_func, BLKTYPE_NIX))\n\t\t\treturn CPT_AF_ERR_NIX_PF_FUNC_INVALID;\n\t}\n\n\t \n\tif (req->sso_pf_func) {\n\t\t \n\t\tif (req->sso_pf_func == RVU_DEFAULT_PF_FUNC)\n\t\t\treq->sso_pf_func = pcifunc;\n\t\tif (!is_pffunc_map_valid(rvu, req->sso_pf_func, BLKTYPE_SSO))\n\t\t\treturn CPT_AF_ERR_SSO_PF_FUNC_INVALID;\n\t}\n\n\tfor (slot = 0; slot < num_lfs; slot++) {\n\t\tcptlf = rvu_get_lf(rvu, block, pcifunc, slot);\n\t\tif (cptlf < 0)\n\t\t\treturn CPT_AF_ERR_LF_INVALID;\n\n\t\t \n\t\tval = (u64)req->eng_grpmsk << 48 | 1;\n\t\tif (!is_rvu_otx2(rvu)) {\n\t\t\tif (req->ctx_ilen_valid)\n\t\t\t\tval |= (req->ctx_ilen << 17);\n\t\t\telse\n\t\t\t\tval |= (CPT_CTX_ILEN << 17);\n\t\t}\n\n\t\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf), val);\n\n\t\t \n\t\tval = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf));\n\t\tval &= ~(GENMASK_ULL(63, 48) | GENMASK_ULL(47, 32));\n\t\tval |= ((u64)req->nix_pf_func << 48 |\n\t\t\t(u64)req->sso_pf_func << 32);\n\t\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf), val);\n\t}\n\n\treturn 0;\n}\n\nstatic int cpt_lf_free(struct rvu *rvu, struct msg_req *req, int blkaddr)\n{\n\tu16 pcifunc = req->hdr.pcifunc;\n\tint num_lfs, cptlf, slot, err;\n\tstruct rvu_block *block;\n\n\tblock = &rvu->hw->block[blkaddr];\n\tnum_lfs = rvu_get_rsrc_mapcount(rvu_get_pfvf(rvu, pcifunc),\n\t\t\t\t\tblock->addr);\n\tif (!num_lfs)\n\t\treturn 0;\n\n\tfor (slot = 0; slot < num_lfs; slot++) {\n\t\tcptlf = rvu_get_lf(rvu, block, pcifunc, slot);\n\t\tif (cptlf < 0)\n\t\t\treturn CPT_AF_ERR_LF_INVALID;\n\n\t\t \n\t\trvu_cpt_lf_teardown(rvu, pcifunc, blkaddr, cptlf, slot);\n\n\t\t \n\t\terr = rvu_lf_reset(rvu, block, cptlf);\n\t\tif (err) {\n\t\t\tdev_err(rvu->dev, \"Failed to reset blkaddr %d LF%d\\n\",\n\t\t\t\tblock->addr, cptlf);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint rvu_mbox_handler_cpt_lf_free(struct rvu *rvu, struct msg_req *req,\n\t\t\t\t struct msg_rsp *rsp)\n{\n\tint ret;\n\n\tret = cpt_lf_free(rvu, req, BLKADDR_CPT0);\n\tif (ret)\n\t\treturn ret;\n\n\tif (is_block_implemented(rvu->hw, BLKADDR_CPT1))\n\t\tret = cpt_lf_free(rvu, req, BLKADDR_CPT1);\n\n\treturn ret;\n}\n\nstatic int cpt_inline_ipsec_cfg_inbound(struct rvu *rvu, int blkaddr, u8 cptlf,\n\t\t\t\t\tstruct cpt_inline_ipsec_cfg_msg *req)\n{\n\tu16 sso_pf_func = req->sso_pf_func;\n\tu8 nix_sel;\n\tu64 val;\n\n\tval = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf));\n\tif (req->enable && (val & BIT_ULL(16))) {\n\t\t \n\t\treturn CPT_AF_ERR_INLINE_IPSEC_INB_ENA;\n\t}\n\t \n\tif (sso_pf_func && !is_pffunc_map_valid(rvu, sso_pf_func, BLKTYPE_SSO))\n\t\treturn CPT_AF_ERR_SSO_PF_FUNC_INVALID;\n\n\tnix_sel = (blkaddr == BLKADDR_CPT1) ? 1 : 0;\n\t \n\tif (req->enable)\n\t\tval |= BIT_ULL(9);\n\telse\n\t\tval &= ~BIT_ULL(9);\n\n\tval |= (u64)nix_sel << 8;\n\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf), val);\n\n\tif (sso_pf_func) {\n\t\t \n\t\tval = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf));\n\t\tval |= (u64)sso_pf_func << 32;\n\t\tval |= (u64)req->nix_pf_func << 48;\n\t\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf), val);\n\t}\n\tif (req->sso_pf_func_ovrd)\n\t\t \n\t\trvu_write64(rvu, blkaddr, CPT_AF_ECO, 0x1);\n\n\t \n\tif (!is_rvu_otx2(rvu)) {\n\t\tval = (ilog2(NIX_CHAN_CPT_X2P_MASK + 1) << 16);\n\t\tval |= (u64)rvu->hw->cpt_chan_base;\n\n\t\trvu_write64(rvu, blkaddr, CPT_AF_X2PX_LINK_CFG(0), val);\n\t\trvu_write64(rvu, blkaddr, CPT_AF_X2PX_LINK_CFG(1), val);\n\t}\n\n\treturn 0;\n}\n\nstatic int cpt_inline_ipsec_cfg_outbound(struct rvu *rvu, int blkaddr, u8 cptlf,\n\t\t\t\t\t struct cpt_inline_ipsec_cfg_msg *req)\n{\n\tu16 nix_pf_func = req->nix_pf_func;\n\tint nix_blkaddr;\n\tu8 nix_sel;\n\tu64 val;\n\n\tval = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf));\n\tif (req->enable && (val & BIT_ULL(9))) {\n\t\t \n\t\treturn CPT_AF_ERR_INLINE_IPSEC_OUT_ENA;\n\t}\n\n\t \n\tif (nix_pf_func && !is_pffunc_map_valid(rvu, nix_pf_func, BLKTYPE_NIX))\n\t\treturn CPT_AF_ERR_NIX_PF_FUNC_INVALID;\n\n\t \n\tif (req->enable)\n\t\tval |= BIT_ULL(16);\n\telse\n\t\tval &= ~BIT_ULL(16);\n\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf), val);\n\n\tif (nix_pf_func) {\n\t\t \n\t\tval = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf));\n\t\tval |= (u64)nix_pf_func << 48;\n\t\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf), val);\n\n\t\tnix_blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, nix_pf_func);\n\t\tnix_sel = (nix_blkaddr == BLKADDR_NIX0) ? 0 : 1;\n\n\t\tval = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf));\n\t\tval |= (u64)nix_sel << 8;\n\t\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf), val);\n\t}\n\n\treturn 0;\n}\n\nint rvu_mbox_handler_cpt_inline_ipsec_cfg(struct rvu *rvu,\n\t\t\t\t\t  struct cpt_inline_ipsec_cfg_msg *req,\n\t\t\t\t\t  struct msg_rsp *rsp)\n{\n\tu16 pcifunc = req->hdr.pcifunc;\n\tstruct rvu_block *block;\n\tint cptlf, blkaddr, ret;\n\tu16 actual_slot;\n\n\tblkaddr = rvu_get_blkaddr_from_slot(rvu, BLKTYPE_CPT, pcifunc,\n\t\t\t\t\t    req->slot, &actual_slot);\n\tif (blkaddr < 0)\n\t\treturn CPT_AF_ERR_LF_INVALID;\n\n\tblock = &rvu->hw->block[blkaddr];\n\n\tcptlf = rvu_get_lf(rvu, block, pcifunc, actual_slot);\n\tif (cptlf < 0)\n\t\treturn CPT_AF_ERR_LF_INVALID;\n\n\tswitch (req->dir) {\n\tcase CPT_INLINE_INBOUND:\n\t\tret = cpt_inline_ipsec_cfg_inbound(rvu, blkaddr, cptlf, req);\n\t\tbreak;\n\n\tcase CPT_INLINE_OUTBOUND:\n\t\tret = cpt_inline_ipsec_cfg_outbound(rvu, blkaddr, cptlf, req);\n\t\tbreak;\n\n\tdefault:\n\t\treturn CPT_AF_ERR_PARAM;\n\t}\n\n\treturn ret;\n}\n\nstatic bool is_valid_offset(struct rvu *rvu, struct cpt_rd_wr_reg_msg *req)\n{\n\tu64 offset = req->reg_offset;\n\tint blkaddr, num_lfs, lf;\n\tstruct rvu_block *block;\n\tstruct rvu_pfvf *pfvf;\n\n\tblkaddr = validate_and_get_cpt_blkaddr(req->blkaddr);\n\tif (blkaddr < 0)\n\t\treturn false;\n\n\t \n\tif ((offset & 0xFF000) ==  CPT_AF_LFX_CTL(0) ||\n\t    (offset & 0xFF000) ==  CPT_AF_LFX_CTL2(0)) {\n\t\tif (offset & 7)\n\t\t\treturn false;\n\n\t\tlf = (offset & 0xFFF) >> 3;\n\t\tblock = &rvu->hw->block[blkaddr];\n\t\tpfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);\n\t\tnum_lfs = rvu_get_rsrc_mapcount(pfvf, block->addr);\n\t\tif (lf >= num_lfs)\n\t\t\t \n\t\t\treturn false;\n\n\t\t \n\t\tlf = rvu_get_lf(rvu, &rvu->hw->block[blkaddr],\n\t\t\t\treq->hdr.pcifunc, lf);\n\t\tif (lf < 0)\n\t\t\treturn false;\n\n\t\treturn true;\n\t} else if (!(req->hdr.pcifunc & RVU_PFVF_FUNC_MASK)) {\n\t\t \n\t\tswitch (offset) {\n\t\tcase CPT_AF_DIAG:\n\t\tcase CPT_AF_CTL:\n\t\tcase CPT_AF_PF_FUNC:\n\t\tcase CPT_AF_BLK_RST:\n\t\tcase CPT_AF_CONSTANTS1:\n\t\tcase CPT_AF_CTX_FLUSH_TIMER:\n\t\t\treturn true;\n\t\t}\n\n\t\tswitch (offset & 0xFF000) {\n\t\tcase CPT_AF_EXEX_STS(0):\n\t\tcase CPT_AF_EXEX_CTL(0):\n\t\tcase CPT_AF_EXEX_CTL2(0):\n\t\tcase CPT_AF_EXEX_UCODE_BASE(0):\n\t\t\tif (offset & 7)\n\t\t\t\treturn false;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nint rvu_mbox_handler_cpt_rd_wr_register(struct rvu *rvu,\n\t\t\t\t\tstruct cpt_rd_wr_reg_msg *req,\n\t\t\t\t\tstruct cpt_rd_wr_reg_msg *rsp)\n{\n\tint blkaddr;\n\n\tblkaddr = validate_and_get_cpt_blkaddr(req->blkaddr);\n\tif (blkaddr < 0)\n\t\treturn blkaddr;\n\n\t \n\tif (!is_cpt_pf(rvu, req->hdr.pcifunc) &&\n\t    !is_cpt_vf(rvu, req->hdr.pcifunc))\n\t\treturn CPT_AF_ERR_ACCESS_DENIED;\n\n\trsp->reg_offset = req->reg_offset;\n\trsp->ret_val = req->ret_val;\n\trsp->is_write = req->is_write;\n\n\tif (!is_valid_offset(rvu, req))\n\t\treturn CPT_AF_ERR_ACCESS_DENIED;\n\n\tif (req->is_write)\n\t\trvu_write64(rvu, blkaddr, req->reg_offset, req->val);\n\telse\n\t\trsp->val = rvu_read64(rvu, blkaddr, req->reg_offset);\n\n\treturn 0;\n}\n\nstatic void get_ctx_pc(struct rvu *rvu, struct cpt_sts_rsp *rsp, int blkaddr)\n{\n\tif (is_rvu_otx2(rvu))\n\t\treturn;\n\n\trsp->ctx_mis_pc = rvu_read64(rvu, blkaddr, CPT_AF_CTX_MIS_PC);\n\trsp->ctx_hit_pc = rvu_read64(rvu, blkaddr, CPT_AF_CTX_HIT_PC);\n\trsp->ctx_aop_pc = rvu_read64(rvu, blkaddr, CPT_AF_CTX_AOP_PC);\n\trsp->ctx_aop_lat_pc = rvu_read64(rvu, blkaddr,\n\t\t\t\t\t CPT_AF_CTX_AOP_LATENCY_PC);\n\trsp->ctx_ifetch_pc = rvu_read64(rvu, blkaddr, CPT_AF_CTX_IFETCH_PC);\n\trsp->ctx_ifetch_lat_pc = rvu_read64(rvu, blkaddr,\n\t\t\t\t\t    CPT_AF_CTX_IFETCH_LATENCY_PC);\n\trsp->ctx_ffetch_pc = rvu_read64(rvu, blkaddr, CPT_AF_CTX_FFETCH_PC);\n\trsp->ctx_ffetch_lat_pc = rvu_read64(rvu, blkaddr,\n\t\t\t\t\t    CPT_AF_CTX_FFETCH_LATENCY_PC);\n\trsp->ctx_wback_pc = rvu_read64(rvu, blkaddr, CPT_AF_CTX_FFETCH_PC);\n\trsp->ctx_wback_lat_pc = rvu_read64(rvu, blkaddr,\n\t\t\t\t\t   CPT_AF_CTX_FFETCH_LATENCY_PC);\n\trsp->ctx_psh_pc = rvu_read64(rvu, blkaddr, CPT_AF_CTX_FFETCH_PC);\n\trsp->ctx_psh_lat_pc = rvu_read64(rvu, blkaddr,\n\t\t\t\t\t CPT_AF_CTX_FFETCH_LATENCY_PC);\n\trsp->ctx_err = rvu_read64(rvu, blkaddr, CPT_AF_CTX_ERR);\n\trsp->ctx_enc_id = rvu_read64(rvu, blkaddr, CPT_AF_CTX_ENC_ID);\n\trsp->ctx_flush_timer = rvu_read64(rvu, blkaddr, CPT_AF_CTX_FLUSH_TIMER);\n\n\trsp->rxc_time = rvu_read64(rvu, blkaddr, CPT_AF_RXC_TIME);\n\trsp->rxc_time_cfg = rvu_read64(rvu, blkaddr, CPT_AF_RXC_TIME_CFG);\n\trsp->rxc_active_sts = rvu_read64(rvu, blkaddr, CPT_AF_RXC_ACTIVE_STS);\n\trsp->rxc_zombie_sts = rvu_read64(rvu, blkaddr, CPT_AF_RXC_ZOMBIE_STS);\n\trsp->rxc_dfrg = rvu_read64(rvu, blkaddr, CPT_AF_RXC_DFRG);\n\trsp->x2p_link_cfg0 = rvu_read64(rvu, blkaddr, CPT_AF_X2PX_LINK_CFG(0));\n\trsp->x2p_link_cfg1 = rvu_read64(rvu, blkaddr, CPT_AF_X2PX_LINK_CFG(1));\n}\n\nstatic void get_eng_sts(struct rvu *rvu, struct cpt_sts_rsp *rsp, int blkaddr)\n{\n\tu16 max_ses, max_ies, max_aes;\n\tu32 e_min = 0, e_max = 0;\n\tu64 reg;\n\n\treg = rvu_read64(rvu, blkaddr, CPT_AF_CONSTANTS1);\n\tmax_ses = reg & 0xffff;\n\tmax_ies = (reg >> 16) & 0xffff;\n\tmax_aes = (reg >> 32) & 0xffff;\n\n\t \n\te_min = max_ses + max_ies;\n\te_max = max_ses + max_ies + max_aes;\n\tcpt_get_eng_sts(e_min, e_max, rsp, ae);\n\t \n\te_min = 0;\n\te_max = max_ses;\n\tcpt_get_eng_sts(e_min, e_max, rsp, se);\n\t \n\te_min = max_ses;\n\te_max = max_ses + max_ies;\n\tcpt_get_eng_sts(e_min, e_max, rsp, ie);\n}\n\nint rvu_mbox_handler_cpt_sts(struct rvu *rvu, struct cpt_sts_req *req,\n\t\t\t     struct cpt_sts_rsp *rsp)\n{\n\tint blkaddr;\n\n\tblkaddr = validate_and_get_cpt_blkaddr(req->blkaddr);\n\tif (blkaddr < 0)\n\t\treturn blkaddr;\n\n\t \n\tif (!is_cpt_pf(rvu, req->hdr.pcifunc) &&\n\t    !is_cpt_vf(rvu, req->hdr.pcifunc))\n\t\treturn CPT_AF_ERR_ACCESS_DENIED;\n\n\tget_ctx_pc(rvu, rsp, blkaddr);\n\n\t \n\tget_eng_sts(rvu, rsp, blkaddr);\n\n\t \n\trsp->inst_req_pc = rvu_read64(rvu, blkaddr, CPT_AF_INST_REQ_PC);\n\trsp->inst_lat_pc = rvu_read64(rvu, blkaddr, CPT_AF_INST_LATENCY_PC);\n\trsp->rd_req_pc = rvu_read64(rvu, blkaddr, CPT_AF_RD_REQ_PC);\n\trsp->rd_lat_pc = rvu_read64(rvu, blkaddr, CPT_AF_RD_LATENCY_PC);\n\trsp->rd_uc_pc = rvu_read64(rvu, blkaddr, CPT_AF_RD_UC_PC);\n\trsp->active_cycles_pc = rvu_read64(rvu, blkaddr,\n\t\t\t\t\t   CPT_AF_ACTIVE_CYCLES_PC);\n\trsp->exe_err_info = rvu_read64(rvu, blkaddr, CPT_AF_EXE_ERR_INFO);\n\trsp->cptclk_cnt = rvu_read64(rvu, blkaddr, CPT_AF_CPTCLK_CNT);\n\trsp->diag = rvu_read64(rvu, blkaddr, CPT_AF_DIAG);\n\n\treturn 0;\n}\n\n#define RXC_ZOMBIE_THRES  GENMASK_ULL(59, 48)\n#define RXC_ZOMBIE_LIMIT  GENMASK_ULL(43, 32)\n#define RXC_ACTIVE_THRES  GENMASK_ULL(27, 16)\n#define RXC_ACTIVE_LIMIT  GENMASK_ULL(11, 0)\n#define RXC_ACTIVE_COUNT  GENMASK_ULL(60, 48)\n#define RXC_ZOMBIE_COUNT  GENMASK_ULL(60, 48)\n\nstatic void cpt_rxc_time_cfg(struct rvu *rvu, struct cpt_rxc_time_cfg_req *req,\n\t\t\t     int blkaddr, struct cpt_rxc_time_cfg_req *save)\n{\n\tu64 dfrg_reg;\n\n\tif (save) {\n\t\t \n\t\tdfrg_reg = rvu_read64(rvu, blkaddr, CPT_AF_RXC_DFRG);\n\t\tsave->zombie_thres = FIELD_GET(RXC_ZOMBIE_THRES, dfrg_reg);\n\t\tsave->zombie_limit = FIELD_GET(RXC_ZOMBIE_LIMIT, dfrg_reg);\n\t\tsave->active_thres = FIELD_GET(RXC_ACTIVE_THRES, dfrg_reg);\n\t\tsave->active_limit = FIELD_GET(RXC_ACTIVE_LIMIT, dfrg_reg);\n\n\t\tsave->step = rvu_read64(rvu, blkaddr, CPT_AF_RXC_TIME_CFG);\n\t}\n\n\tdfrg_reg = FIELD_PREP(RXC_ZOMBIE_THRES, req->zombie_thres);\n\tdfrg_reg |= FIELD_PREP(RXC_ZOMBIE_LIMIT, req->zombie_limit);\n\tdfrg_reg |= FIELD_PREP(RXC_ACTIVE_THRES, req->active_thres);\n\tdfrg_reg |= FIELD_PREP(RXC_ACTIVE_LIMIT, req->active_limit);\n\n\trvu_write64(rvu, blkaddr, CPT_AF_RXC_TIME_CFG, req->step);\n\trvu_write64(rvu, blkaddr, CPT_AF_RXC_DFRG, dfrg_reg);\n}\n\nint rvu_mbox_handler_cpt_rxc_time_cfg(struct rvu *rvu,\n\t\t\t\t      struct cpt_rxc_time_cfg_req *req,\n\t\t\t\t      struct msg_rsp *rsp)\n{\n\tint blkaddr;\n\n\tblkaddr = validate_and_get_cpt_blkaddr(req->blkaddr);\n\tif (blkaddr < 0)\n\t\treturn blkaddr;\n\n\t \n\tif (!is_cpt_pf(rvu, req->hdr.pcifunc) &&\n\t    !is_cpt_vf(rvu, req->hdr.pcifunc))\n\t\treturn CPT_AF_ERR_ACCESS_DENIED;\n\n\tcpt_rxc_time_cfg(rvu, req, blkaddr, NULL);\n\n\treturn 0;\n}\n\nint rvu_mbox_handler_cpt_ctx_cache_sync(struct rvu *rvu, struct msg_req *req,\n\t\t\t\t\tstruct msg_rsp *rsp)\n{\n\treturn rvu_cpt_ctx_flush(rvu, req->hdr.pcifunc);\n}\n\nint rvu_mbox_handler_cpt_lf_reset(struct rvu *rvu, struct cpt_lf_rst_req *req,\n\t\t\t\t  struct msg_rsp *rsp)\n{\n\tu16 pcifunc = req->hdr.pcifunc;\n\tstruct rvu_block *block;\n\tint cptlf, blkaddr, ret;\n\tu16 actual_slot;\n\tu64 ctl, ctl2;\n\n\tblkaddr = rvu_get_blkaddr_from_slot(rvu, BLKTYPE_CPT, pcifunc,\n\t\t\t\t\t    req->slot, &actual_slot);\n\tif (blkaddr < 0)\n\t\treturn CPT_AF_ERR_LF_INVALID;\n\n\tblock = &rvu->hw->block[blkaddr];\n\n\tcptlf = rvu_get_lf(rvu, block, pcifunc, actual_slot);\n\tif (cptlf < 0)\n\t\treturn CPT_AF_ERR_LF_INVALID;\n\tctl = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf));\n\tctl2 = rvu_read64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf));\n\n\tret = rvu_lf_reset(rvu, block, cptlf);\n\tif (ret)\n\t\tdev_err(rvu->dev, \"Failed to reset blkaddr %d LF%d\\n\",\n\t\t\tblock->addr, cptlf);\n\n\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL(cptlf), ctl);\n\trvu_write64(rvu, blkaddr, CPT_AF_LFX_CTL2(cptlf), ctl2);\n\n\treturn 0;\n}\n\nint rvu_mbox_handler_cpt_flt_eng_info(struct rvu *rvu, struct cpt_flt_eng_info_req *req,\n\t\t\t\t      struct cpt_flt_eng_info_rsp *rsp)\n{\n\tstruct rvu_block *block;\n\tunsigned long flags;\n\tint blkaddr, vec;\n\n\tblkaddr = validate_and_get_cpt_blkaddr(req->blkaddr);\n\tif (blkaddr < 0)\n\t\treturn blkaddr;\n\n\tblock = &rvu->hw->block[blkaddr];\n\tfor (vec = 0; vec < CPT_10K_AF_INT_VEC_RVU; vec++) {\n\t\tspin_lock_irqsave(&rvu->cpt_intr_lock, flags);\n\t\trsp->flt_eng_map[vec] = block->cpt_flt_eng_map[vec];\n\t\trsp->rcvrd_eng_map[vec] = block->cpt_rcvrd_eng_map[vec];\n\t\tif (req->reset) {\n\t\t\tblock->cpt_flt_eng_map[vec] = 0x0;\n\t\t\tblock->cpt_rcvrd_eng_map[vec] = 0x0;\n\t\t}\n\t\tspin_unlock_irqrestore(&rvu->cpt_intr_lock, flags);\n\t}\n\treturn 0;\n}\n\nstatic void cpt_rxc_teardown(struct rvu *rvu, int blkaddr)\n{\n\tstruct cpt_rxc_time_cfg_req req, prev;\n\tint timeout = 2000;\n\tu64 reg;\n\n\tif (is_rvu_otx2(rvu))\n\t\treturn;\n\n\t \n\treq.step = 1;\n\treq.zombie_thres = 1;\n\treq.zombie_limit = 1;\n\treq.active_thres = 1;\n\treq.active_limit = 1;\n\n\tcpt_rxc_time_cfg(rvu, &req, blkaddr, &prev);\n\n\tdo {\n\t\treg = rvu_read64(rvu, blkaddr, CPT_AF_RXC_ACTIVE_STS);\n\t\tudelay(1);\n\t\tif (FIELD_GET(RXC_ACTIVE_COUNT, reg))\n\t\t\ttimeout--;\n\t\telse\n\t\t\tbreak;\n\t} while (timeout);\n\n\tif (timeout == 0)\n\t\tdev_warn(rvu->dev, \"Poll for RXC active count hits hard loop counter\\n\");\n\n\ttimeout = 2000;\n\tdo {\n\t\treg = rvu_read64(rvu, blkaddr, CPT_AF_RXC_ZOMBIE_STS);\n\t\tudelay(1);\n\t\tif (FIELD_GET(RXC_ZOMBIE_COUNT, reg))\n\t\t\ttimeout--;\n\t\telse\n\t\t\tbreak;\n\t} while (timeout);\n\n\tif (timeout == 0)\n\t\tdev_warn(rvu->dev, \"Poll for RXC zombie count hits hard loop counter\\n\");\n\n\t \n\tcpt_rxc_time_cfg(rvu, &prev, blkaddr, NULL);\n}\n\n#define INFLIGHT   GENMASK_ULL(8, 0)\n#define GRB_CNT    GENMASK_ULL(39, 32)\n#define GWB_CNT    GENMASK_ULL(47, 40)\n#define XQ_XOR     GENMASK_ULL(63, 63)\n#define DQPTR      GENMASK_ULL(19, 0)\n#define NQPTR      GENMASK_ULL(51, 32)\n\nstatic void cpt_lf_disable_iqueue(struct rvu *rvu, int blkaddr, int slot)\n{\n\tint timeout = 1000000;\n\tu64 inprog, inst_ptr;\n\tu64 qsize, pending;\n\tint i = 0;\n\n\t \n\trvu_write64(rvu, blkaddr, CPT_AF_BAR2_ALIASX(slot, CPT_LF_CTL), 0x0);\n\n\tinprog = rvu_read64(rvu, blkaddr,\n\t\t\t    CPT_AF_BAR2_ALIASX(slot, CPT_LF_INPROG));\n\tinprog |= BIT_ULL(16);\n\trvu_write64(rvu, blkaddr,\n\t\t    CPT_AF_BAR2_ALIASX(slot, CPT_LF_INPROG), inprog);\n\n\tqsize = rvu_read64(rvu, blkaddr,\n\t\t\t   CPT_AF_BAR2_ALIASX(slot, CPT_LF_Q_SIZE)) & 0x7FFF;\n\tdo {\n\t\tinst_ptr = rvu_read64(rvu, blkaddr,\n\t\t\t\t      CPT_AF_BAR2_ALIASX(slot, CPT_LF_Q_INST_PTR));\n\t\tpending = (FIELD_GET(XQ_XOR, inst_ptr) * qsize * 40) +\n\t\t\t  FIELD_GET(NQPTR, inst_ptr) -\n\t\t\t  FIELD_GET(DQPTR, inst_ptr);\n\t\tudelay(1);\n\t\ttimeout--;\n\t} while ((pending != 0) && (timeout != 0));\n\n\tif (timeout == 0)\n\t\tdev_warn(rvu->dev, \"TIMEOUT: CPT poll on pending instructions\\n\");\n\n\ttimeout = 1000000;\n\t \n\tdo {\n\t\tinprog = rvu_read64(rvu, blkaddr,\n\t\t\t\t    CPT_AF_BAR2_ALIASX(slot, CPT_LF_INPROG));\n\n\t\tif ((FIELD_GET(INFLIGHT, inprog) == 0) &&\n\t\t    (FIELD_GET(GRB_CNT, inprog) == 0)) {\n\t\t\ti++;\n\t\t} else {\n\t\t\ti = 0;\n\t\t\ttimeout--;\n\t\t}\n\t} while ((timeout != 0) && (i < 10));\n\n\tif (timeout == 0)\n\t\tdev_warn(rvu->dev, \"TIMEOUT: CPT poll on inflight count\\n\");\n\t \n\tudelay(2);\n}\n\nint rvu_cpt_lf_teardown(struct rvu *rvu, u16 pcifunc, int blkaddr, int lf, int slot)\n{\n\tu64 reg;\n\n\tif (is_cpt_pf(rvu, pcifunc) || is_cpt_vf(rvu, pcifunc))\n\t\tcpt_rxc_teardown(rvu, blkaddr);\n\n\tmutex_lock(&rvu->alias_lock);\n\t \n\treg = BIT_ULL(16) | pcifunc;\n\trvu_bar2_sel_write64(rvu, blkaddr, CPT_AF_BAR2_SEL, reg);\n\n\tcpt_lf_disable_iqueue(rvu, blkaddr, slot);\n\n\trvu_bar2_sel_write64(rvu, blkaddr, CPT_AF_BAR2_SEL, 0);\n\tmutex_unlock(&rvu->alias_lock);\n\n\treturn 0;\n}\n\n#define CPT_RES_LEN    16\n#define CPT_SE_IE_EGRP 1ULL\n\nstatic int cpt_inline_inb_lf_cmd_send(struct rvu *rvu, int blkaddr,\n\t\t\t\t      int nix_blkaddr)\n{\n\tint cpt_pf_num = rvu->cpt_pf_num;\n\tstruct cpt_inst_lmtst_req *req;\n\tdma_addr_t res_daddr;\n\tint timeout = 3000;\n\tu8 cpt_idx;\n\tu64 *inst;\n\tu16 *res;\n\tint rc;\n\n\tres = kzalloc(CPT_RES_LEN, GFP_KERNEL);\n\tif (!res)\n\t\treturn -ENOMEM;\n\n\tres_daddr = dma_map_single(rvu->dev, res, CPT_RES_LEN,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(rvu->dev, res_daddr)) {\n\t\tdev_err(rvu->dev, \"DMA mapping failed for CPT result\\n\");\n\t\trc = -EFAULT;\n\t\tgoto res_free;\n\t}\n\t*res = 0xFFFF;\n\n\t \n\treq = (struct cpt_inst_lmtst_req *)\n\t       otx2_mbox_alloc_msg_rsp(&rvu->afpf_wq_info.mbox_up,\n\t\t\t\t       cpt_pf_num, sizeof(*req),\n\t\t\t\t       sizeof(struct msg_rsp));\n\tif (!req) {\n\t\trc = -ENOMEM;\n\t\tgoto res_daddr_unmap;\n\t}\n\treq->hdr.sig = OTX2_MBOX_REQ_SIG;\n\treq->hdr.id = MBOX_MSG_CPT_INST_LMTST;\n\n\tinst = req->inst;\n\t \n\tinst[0] = 0;\n\tinst[1] = res_daddr;\n\t \n\tinst[2] = 0;\n\t \n\tinst[3] = 1;\n\tinst[4] = 0;\n\tinst[5] = 0;\n\tinst[6] = 0;\n\t \n\tinst[7] = CPT_SE_IE_EGRP << 61;\n\n\t \n\tcpt_idx = (blkaddr == BLKADDR_CPT0) ? 0 : 1;\n\trvu_write64(rvu, nix_blkaddr, NIX_AF_RX_CPTX_CREDIT(cpt_idx),\n\t\t    BIT_ULL(22) - 1);\n\n\totx2_mbox_msg_send(&rvu->afpf_wq_info.mbox_up, cpt_pf_num);\n\trc = otx2_mbox_wait_for_rsp(&rvu->afpf_wq_info.mbox_up, cpt_pf_num);\n\tif (rc)\n\t\tdev_warn(rvu->dev, \"notification to pf %d failed\\n\",\n\t\t\t cpt_pf_num);\n\t \n\tdo {\n\t\tmdelay(1);\n\t\tif (*res == 0xFFFF)\n\t\t\ttimeout--;\n\t\telse\n\t\t\tbreak;\n\t} while (timeout);\n\n\tif (timeout == 0)\n\t\tdev_warn(rvu->dev, \"Poll for result hits hard loop counter\\n\");\n\nres_daddr_unmap:\n\tdma_unmap_single(rvu->dev, res_daddr, CPT_RES_LEN, DMA_BIDIRECTIONAL);\nres_free:\n\tkfree(res);\n\n\treturn 0;\n}\n\n#define CTX_CAM_PF_FUNC   GENMASK_ULL(61, 46)\n#define CTX_CAM_CPTR      GENMASK_ULL(45, 0)\n\nint rvu_cpt_ctx_flush(struct rvu *rvu, u16 pcifunc)\n{\n\tint nix_blkaddr, blkaddr;\n\tu16 max_ctx_entries, i;\n\tint slot = 0, num_lfs;\n\tu64 reg, cam_data;\n\tint rc;\n\n\tnix_blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, pcifunc);\n\tif (nix_blkaddr < 0)\n\t\treturn -EINVAL;\n\n\tif (is_rvu_otx2(rvu))\n\t\treturn 0;\n\n\tblkaddr = (nix_blkaddr == BLKADDR_NIX1) ? BLKADDR_CPT1 : BLKADDR_CPT0;\n\n\t \n\trc = cpt_inline_inb_lf_cmd_send(rvu, blkaddr, nix_blkaddr);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tcpt_rxc_teardown(rvu, blkaddr);\n\n\treg = rvu_read64(rvu, blkaddr, CPT_AF_CONSTANTS0);\n\tmax_ctx_entries = (reg >> 48) & 0xFFF;\n\n\tmutex_lock(&rvu->rsrc_lock);\n\n\tnum_lfs = rvu_get_rsrc_mapcount(rvu_get_pfvf(rvu, pcifunc),\n\t\t\t\t\tblkaddr);\n\tif (num_lfs == 0) {\n\t\tdev_warn(rvu->dev, \"CPT LF is not configured\\n\");\n\t\tgoto unlock;\n\t}\n\n\t \n\treg = BIT_ULL(16) | pcifunc;\n\trvu_bar2_sel_write64(rvu, blkaddr, CPT_AF_BAR2_SEL, reg);\n\n\tfor (i = 0; i < max_ctx_entries; i++) {\n\t\tcam_data = rvu_read64(rvu, blkaddr, CPT_AF_CTX_CAM_DATA(i));\n\n\t\tif ((FIELD_GET(CTX_CAM_PF_FUNC, cam_data) == pcifunc) &&\n\t\t    FIELD_GET(CTX_CAM_CPTR, cam_data)) {\n\t\t\treg = BIT_ULL(46) | FIELD_GET(CTX_CAM_CPTR, cam_data);\n\t\t\trvu_write64(rvu, blkaddr,\n\t\t\t\t    CPT_AF_BAR2_ALIASX(slot, CPT_LF_CTX_FLUSH),\n\t\t\t\t    reg);\n\t\t}\n\t}\n\trvu_bar2_sel_write64(rvu, blkaddr, CPT_AF_BAR2_SEL, 0);\n\nunlock:\n\tmutex_unlock(&rvu->rsrc_lock);\n\n\treturn 0;\n}\n\nint rvu_cpt_init(struct rvu *rvu)\n{\n\t \n\trvu->cpt_pf_num = get_cpt_pf_num(rvu);\n\tspin_lock_init(&rvu->cpt_intr_lock);\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}