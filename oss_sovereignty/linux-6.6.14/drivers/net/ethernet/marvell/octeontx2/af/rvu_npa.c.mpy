{
  "module_name": "rvu_npa.c",
  "hash_id": "f365b8cfc7a6ed3a00c397b97607982dbc893309fe420dcacf871ee09c70f5e7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c",
  "human_readable_source": "\n \n#include <linux/bitfield.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n\n#include \"rvu_struct.h\"\n#include \"rvu_reg.h\"\n#include \"rvu.h\"\n\nstatic int npa_aq_enqueue_wait(struct rvu *rvu, struct rvu_block *block,\n\t\t\t       struct npa_aq_inst_s *inst)\n{\n\tstruct admin_queue *aq = block->aq;\n\tstruct npa_aq_res_s *result;\n\tint timeout = 1000;\n\tu64 reg, head;\n\n\tresult = (struct npa_aq_res_s *)aq->res->base;\n\n\t \n\treg = rvu_read64(rvu, block->addr, NPA_AF_AQ_STATUS);\n\thead = (reg >> 4) & AQ_PTR_MASK;\n\n\tmemcpy((void *)(aq->inst->base + (head * aq->inst->entry_sz)),\n\t       (void *)inst, aq->inst->entry_sz);\n\tmemset(result, 0, sizeof(*result));\n\t \n\twmb();\n\n\t \n\trvu_write64(rvu, block->addr, NPA_AF_AQ_DOOR, 1);\n\twhile (result->compcode == NPA_AQ_COMP_NOTDONE) {\n\t\tcpu_relax();\n\t\tudelay(1);\n\t\ttimeout--;\n\t\tif (!timeout)\n\t\t\treturn -EBUSY;\n\t}\n\n\tif (result->compcode != NPA_AQ_COMP_GOOD) {\n\t\t \n\t\tif (result->compcode == NPA_AQ_COMP_CTX_FAULT ||\n\t\t    result->compcode == NPA_AQ_COMP_LOCKERR ||\n\t\t    result->compcode == NPA_AQ_COMP_CTX_POISON) {\n\t\t\tif (rvu_ndc_fix_locked_cacheline(rvu, BLKADDR_NDC_NPA0))\n\t\t\t\tdev_err(rvu->dev,\n\t\t\t\t\t\"%s: Not able to unlock cachelines\\n\", __func__);\n\t\t}\n\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\nint rvu_npa_aq_enq_inst(struct rvu *rvu, struct npa_aq_enq_req *req,\n\t\t\tstruct npa_aq_enq_rsp *rsp)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tu16 pcifunc = req->hdr.pcifunc;\n\tint blkaddr, npalf, rc = 0;\n\tstruct npa_aq_inst_s inst;\n\tstruct rvu_block *block;\n\tstruct admin_queue *aq;\n\tstruct rvu_pfvf *pfvf;\n\tvoid *ctx, *mask;\n\tbool ena;\n\n\tpfvf = rvu_get_pfvf(rvu, pcifunc);\n\tif (!pfvf->aura_ctx || req->aura_id >= pfvf->aura_ctx->qsize)\n\t\treturn NPA_AF_ERR_AQ_ENQUEUE;\n\n\tblkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NPA, pcifunc);\n\tif (!pfvf->npalf || blkaddr < 0)\n\t\treturn NPA_AF_ERR_AF_LF_INVALID;\n\n\tblock = &hw->block[blkaddr];\n\taq = block->aq;\n\tif (!aq) {\n\t\tdev_warn(rvu->dev, \"%s: NPA AQ not initialized\\n\", __func__);\n\t\treturn NPA_AF_ERR_AQ_ENQUEUE;\n\t}\n\n\tnpalf = rvu_get_lf(rvu, block, pcifunc, 0);\n\tif (npalf < 0)\n\t\treturn NPA_AF_ERR_AF_LF_INVALID;\n\n\tmemset(&inst, 0, sizeof(struct npa_aq_inst_s));\n\tinst.cindex = req->aura_id;\n\tinst.lf = npalf;\n\tinst.ctype = req->ctype;\n\tinst.op = req->op;\n\t \n\tinst.res_addr = (u64)aq->res->iova;\n\n\t \n\tspin_lock(&aq->lock);\n\n\t \n\tmemset(aq->res->base, 0, aq->res->entry_sz);\n\t \n\tctx = aq->res->base + 128;\n\t \n\tmask = aq->res->base + 256;\n\n\tswitch (req->op) {\n\tcase NPA_AQ_INSTOP_WRITE:\n\t\t \n\t\tif (req->ctype == NPA_AQ_CTYPE_AURA) {\n\t\t\tmemcpy(mask, &req->aura_mask,\n\t\t\t       sizeof(struct npa_aura_s));\n\t\t\tmemcpy(ctx, &req->aura, sizeof(struct npa_aura_s));\n\t\t} else {\n\t\t\tmemcpy(mask, &req->pool_mask,\n\t\t\t       sizeof(struct npa_pool_s));\n\t\t\tmemcpy(ctx, &req->pool, sizeof(struct npa_pool_s));\n\t\t}\n\t\tbreak;\n\tcase NPA_AQ_INSTOP_INIT:\n\t\tif (req->ctype == NPA_AQ_CTYPE_AURA) {\n\t\t\tif (req->aura.pool_addr >= pfvf->pool_ctx->qsize) {\n\t\t\t\trc = NPA_AF_ERR_AQ_FULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t \n\t\t\treq->aura.pool_addr = pfvf->pool_ctx->iova +\n\t\t\t(req->aura.pool_addr * pfvf->pool_ctx->entry_sz);\n\t\t\tmemcpy(ctx, &req->aura, sizeof(struct npa_aura_s));\n\t\t} else {  \n\t\t\tmemcpy(ctx, &req->pool, sizeof(struct npa_pool_s));\n\t\t}\n\t\tbreak;\n\tcase NPA_AQ_INSTOP_NOP:\n\tcase NPA_AQ_INSTOP_READ:\n\tcase NPA_AQ_INSTOP_LOCK:\n\tcase NPA_AQ_INSTOP_UNLOCK:\n\t\tbreak;\n\tdefault:\n\t\trc = NPA_AF_ERR_AQ_FULL;\n\t\tbreak;\n\t}\n\n\tif (rc) {\n\t\tspin_unlock(&aq->lock);\n\t\treturn rc;\n\t}\n\n\t \n\trc = npa_aq_enqueue_wait(rvu, block, &inst);\n\tif (rc) {\n\t\tspin_unlock(&aq->lock);\n\t\treturn rc;\n\t}\n\n\t \n\tif (req->ctype == NPA_AQ_CTYPE_AURA) {\n\t\tif (req->op == NPA_AQ_INSTOP_INIT && req->aura.ena)\n\t\t\t__set_bit(req->aura_id, pfvf->aura_bmap);\n\t\tif (req->op == NPA_AQ_INSTOP_WRITE) {\n\t\t\tena = (req->aura.ena & req->aura_mask.ena) |\n\t\t\t\t(test_bit(req->aura_id, pfvf->aura_bmap) &\n\t\t\t\t~req->aura_mask.ena);\n\t\t\tif (ena)\n\t\t\t\t__set_bit(req->aura_id, pfvf->aura_bmap);\n\t\t\telse\n\t\t\t\t__clear_bit(req->aura_id, pfvf->aura_bmap);\n\t\t}\n\t}\n\n\t \n\tif (req->ctype == NPA_AQ_CTYPE_POOL) {\n\t\tif (req->op == NPA_AQ_INSTOP_INIT && req->pool.ena)\n\t\t\t__set_bit(req->aura_id, pfvf->pool_bmap);\n\t\tif (req->op == NPA_AQ_INSTOP_WRITE) {\n\t\t\tena = (req->pool.ena & req->pool_mask.ena) |\n\t\t\t\t(test_bit(req->aura_id, pfvf->pool_bmap) &\n\t\t\t\t~req->pool_mask.ena);\n\t\t\tif (ena)\n\t\t\t\t__set_bit(req->aura_id, pfvf->pool_bmap);\n\t\t\telse\n\t\t\t\t__clear_bit(req->aura_id, pfvf->pool_bmap);\n\t\t}\n\t}\n\tspin_unlock(&aq->lock);\n\n\tif (rsp) {\n\t\t \n\t\tif (req->op == NPA_AQ_INSTOP_READ) {\n\t\t\tif (req->ctype == NPA_AQ_CTYPE_AURA)\n\t\t\t\tmemcpy(&rsp->aura, ctx,\n\t\t\t\t       sizeof(struct npa_aura_s));\n\t\t\telse\n\t\t\t\tmemcpy(&rsp->pool, ctx,\n\t\t\t\t       sizeof(struct npa_pool_s));\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int npa_lf_hwctx_disable(struct rvu *rvu, struct hwctx_disable_req *req)\n{\n\tstruct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);\n\tstruct npa_aq_enq_req aq_req;\n\tunsigned long *bmap;\n\tint id, cnt = 0;\n\tint err = 0, rc;\n\n\tif (!pfvf->pool_ctx || !pfvf->aura_ctx)\n\t\treturn NPA_AF_ERR_AQ_ENQUEUE;\n\n\tmemset(&aq_req, 0, sizeof(struct npa_aq_enq_req));\n\taq_req.hdr.pcifunc = req->hdr.pcifunc;\n\n\tif (req->ctype == NPA_AQ_CTYPE_POOL) {\n\t\taq_req.pool.ena = 0;\n\t\taq_req.pool_mask.ena = 1;\n\t\tcnt = pfvf->pool_ctx->qsize;\n\t\tbmap = pfvf->pool_bmap;\n\t} else if (req->ctype == NPA_AQ_CTYPE_AURA) {\n\t\taq_req.aura.ena = 0;\n\t\taq_req.aura_mask.ena = 1;\n\t\taq_req.aura.bp_ena = 0;\n\t\taq_req.aura_mask.bp_ena = 1;\n\t\tcnt = pfvf->aura_ctx->qsize;\n\t\tbmap = pfvf->aura_bmap;\n\t}\n\n\taq_req.ctype = req->ctype;\n\taq_req.op = NPA_AQ_INSTOP_WRITE;\n\n\tfor (id = 0; id < cnt; id++) {\n\t\tif (!test_bit(id, bmap))\n\t\t\tcontinue;\n\t\taq_req.aura_id = id;\n\t\trc = rvu_npa_aq_enq_inst(rvu, &aq_req, NULL);\n\t\tif (rc) {\n\t\t\terr = rc;\n\t\t\tdev_err(rvu->dev, \"Failed to disable %s:%d context\\n\",\n\t\t\t\t(req->ctype == NPA_AQ_CTYPE_AURA) ?\n\t\t\t\t\"Aura\" : \"Pool\", id);\n\t\t}\n\t}\n\n\treturn err;\n}\n\n#ifdef CONFIG_NDC_DIS_DYNAMIC_CACHING\nstatic int npa_lf_hwctx_lockdown(struct rvu *rvu, struct npa_aq_enq_req *req)\n{\n\tstruct npa_aq_enq_req lock_ctx_req;\n\tint err;\n\n\tif (req->op != NPA_AQ_INSTOP_INIT)\n\t\treturn 0;\n\n\tmemset(&lock_ctx_req, 0, sizeof(struct npa_aq_enq_req));\n\tlock_ctx_req.hdr.pcifunc = req->hdr.pcifunc;\n\tlock_ctx_req.ctype = req->ctype;\n\tlock_ctx_req.op = NPA_AQ_INSTOP_LOCK;\n\tlock_ctx_req.aura_id = req->aura_id;\n\terr = rvu_npa_aq_enq_inst(rvu, &lock_ctx_req, NULL);\n\tif (err)\n\t\tdev_err(rvu->dev,\n\t\t\t\"PFUNC 0x%x: Failed to lock NPA context %s:%d\\n\",\n\t\t\treq->hdr.pcifunc,\n\t\t\t(req->ctype == NPA_AQ_CTYPE_AURA) ?\n\t\t\t\"Aura\" : \"Pool\", req->aura_id);\n\treturn err;\n}\n\nint rvu_mbox_handler_npa_aq_enq(struct rvu *rvu,\n\t\t\t\tstruct npa_aq_enq_req *req,\n\t\t\t\tstruct npa_aq_enq_rsp *rsp)\n{\n\tint err;\n\n\terr = rvu_npa_aq_enq_inst(rvu, req, rsp);\n\tif (!err)\n\t\terr = npa_lf_hwctx_lockdown(rvu, req);\n\treturn err;\n}\n#else\n\nint rvu_mbox_handler_npa_aq_enq(struct rvu *rvu,\n\t\t\t\tstruct npa_aq_enq_req *req,\n\t\t\t\tstruct npa_aq_enq_rsp *rsp)\n{\n\treturn rvu_npa_aq_enq_inst(rvu, req, rsp);\n}\n#endif\n\nint rvu_mbox_handler_npa_hwctx_disable(struct rvu *rvu,\n\t\t\t\t       struct hwctx_disable_req *req,\n\t\t\t\t       struct msg_rsp *rsp)\n{\n\treturn npa_lf_hwctx_disable(rvu, req);\n}\n\nstatic void npa_ctx_free(struct rvu *rvu, struct rvu_pfvf *pfvf)\n{\n\tkfree(pfvf->aura_bmap);\n\tpfvf->aura_bmap = NULL;\n\n\tqmem_free(rvu->dev, pfvf->aura_ctx);\n\tpfvf->aura_ctx = NULL;\n\n\tkfree(pfvf->pool_bmap);\n\tpfvf->pool_bmap = NULL;\n\n\tqmem_free(rvu->dev, pfvf->pool_ctx);\n\tpfvf->pool_ctx = NULL;\n\n\tqmem_free(rvu->dev, pfvf->npa_qints_ctx);\n\tpfvf->npa_qints_ctx = NULL;\n}\n\nint rvu_mbox_handler_npa_lf_alloc(struct rvu *rvu,\n\t\t\t\t  struct npa_lf_alloc_req *req,\n\t\t\t\t  struct npa_lf_alloc_rsp *rsp)\n{\n\tint npalf, qints, hwctx_size, err, rc = 0;\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tu16 pcifunc = req->hdr.pcifunc;\n\tstruct rvu_block *block;\n\tstruct rvu_pfvf *pfvf;\n\tu64 cfg, ctx_cfg;\n\tint blkaddr;\n\n\tif (req->aura_sz > NPA_AURA_SZ_MAX ||\n\t    req->aura_sz == NPA_AURA_SZ_0 || !req->nr_pools)\n\t\treturn NPA_AF_ERR_PARAM;\n\n\tif (req->way_mask)\n\t\treq->way_mask &= 0xFFFF;\n\n\tpfvf = rvu_get_pfvf(rvu, pcifunc);\n\tblkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NPA, pcifunc);\n\tif (!pfvf->npalf || blkaddr < 0)\n\t\treturn NPA_AF_ERR_AF_LF_INVALID;\n\n\tblock = &hw->block[blkaddr];\n\tnpalf = rvu_get_lf(rvu, block, pcifunc, 0);\n\tif (npalf < 0)\n\t\treturn NPA_AF_ERR_AF_LF_INVALID;\n\n\t \n\terr = rvu_lf_reset(rvu, block, npalf);\n\tif (err) {\n\t\tdev_err(rvu->dev, \"Failed to reset NPALF%d\\n\", npalf);\n\t\treturn NPA_AF_ERR_LF_RESET;\n\t}\n\n\tctx_cfg = rvu_read64(rvu, blkaddr, NPA_AF_CONST1);\n\n\t \n\thwctx_size = 1UL << (ctx_cfg & 0xF);\n\terr = qmem_alloc(rvu->dev, &pfvf->aura_ctx,\n\t\t\t NPA_AURA_COUNT(req->aura_sz), hwctx_size);\n\tif (err)\n\t\tgoto free_mem;\n\n\tpfvf->aura_bmap = kcalloc(NPA_AURA_COUNT(req->aura_sz), sizeof(long),\n\t\t\t\t  GFP_KERNEL);\n\tif (!pfvf->aura_bmap)\n\t\tgoto free_mem;\n\n\t \n\thwctx_size = 1UL << ((ctx_cfg >> 4) & 0xF);\n\terr = qmem_alloc(rvu->dev, &pfvf->pool_ctx, req->nr_pools, hwctx_size);\n\tif (err)\n\t\tgoto free_mem;\n\n\tpfvf->pool_bmap = kcalloc(NPA_AURA_COUNT(req->aura_sz), sizeof(long),\n\t\t\t\t  GFP_KERNEL);\n\tif (!pfvf->pool_bmap)\n\t\tgoto free_mem;\n\n\t \n\tcfg = rvu_read64(rvu, blkaddr, NPA_AF_CONST);\n\tqints = (cfg >> 28) & 0xFFF;\n\n\t \n\thwctx_size = 1UL << ((ctx_cfg >> 8) & 0xF);\n\terr = qmem_alloc(rvu->dev, &pfvf->npa_qints_ctx, qints, hwctx_size);\n\tif (err)\n\t\tgoto free_mem;\n\n\tcfg = rvu_read64(rvu, blkaddr, NPA_AF_LFX_AURAS_CFG(npalf));\n\t \n\tcfg &= ~(BIT_ULL(34) - 1);\n\t \n\tcfg |= (req->aura_sz << 16) | BIT_ULL(34) | req->way_mask;\n\n\trvu_write64(rvu, blkaddr, NPA_AF_LFX_AURAS_CFG(npalf), cfg);\n\n\t \n\trvu_write64(rvu, blkaddr, NPA_AF_LFX_LOC_AURAS_BASE(npalf),\n\t\t    (u64)pfvf->aura_ctx->iova);\n\n\t \n\trvu_write64(rvu, blkaddr, NPA_AF_LFX_QINTS_CFG(npalf),\n\t\t    BIT_ULL(36) | req->way_mask << 20);\n\trvu_write64(rvu, blkaddr, NPA_AF_LFX_QINTS_BASE(npalf),\n\t\t    (u64)pfvf->npa_qints_ctx->iova);\n\n\tgoto exit;\n\nfree_mem:\n\tnpa_ctx_free(rvu, pfvf);\n\trc = -ENOMEM;\n\nexit:\n\t \n\tcfg = rvu_read64(rvu, blkaddr, NPA_AF_CONST);\n\trsp->stack_pg_ptrs = (cfg >> 8) & 0xFF;\n\trsp->stack_pg_bytes = cfg & 0xFF;\n\trsp->qints = (cfg >> 28) & 0xFFF;\n\tif (!is_rvu_otx2(rvu)) {\n\t\tcfg = rvu_read64(rvu, block->addr, NPA_AF_BATCH_CTL);\n\t\trsp->cache_lines = (cfg >> 1) & 0x3F;\n\t}\n\treturn rc;\n}\n\nint rvu_mbox_handler_npa_lf_free(struct rvu *rvu, struct msg_req *req,\n\t\t\t\t struct msg_rsp *rsp)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tu16 pcifunc = req->hdr.pcifunc;\n\tstruct rvu_block *block;\n\tstruct rvu_pfvf *pfvf;\n\tint npalf, err;\n\tint blkaddr;\n\n\tpfvf = rvu_get_pfvf(rvu, pcifunc);\n\tblkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NPA, pcifunc);\n\tif (!pfvf->npalf || blkaddr < 0)\n\t\treturn NPA_AF_ERR_AF_LF_INVALID;\n\n\tblock = &hw->block[blkaddr];\n\tnpalf = rvu_get_lf(rvu, block, pcifunc, 0);\n\tif (npalf < 0)\n\t\treturn NPA_AF_ERR_AF_LF_INVALID;\n\n\t \n\terr = rvu_lf_reset(rvu, block, npalf);\n\tif (err) {\n\t\tdev_err(rvu->dev, \"Failed to reset NPALF%d\\n\", npalf);\n\t\treturn NPA_AF_ERR_LF_RESET;\n\t}\n\n\tnpa_ctx_free(rvu, pfvf);\n\n\treturn 0;\n}\n\nstatic int npa_aq_init(struct rvu *rvu, struct rvu_block *block)\n{\n\tu64 cfg;\n\tint err;\n\n\t \n\tcfg = rvu_read64(rvu, block->addr, NPA_AF_GEN_CFG);\n#ifdef __BIG_ENDIAN\n\tcfg |= BIT_ULL(1);\n\trvu_write64(rvu, block->addr, NPA_AF_GEN_CFG, cfg);\n#else\n\tcfg &= ~BIT_ULL(1);\n\trvu_write64(rvu, block->addr, NPA_AF_GEN_CFG, cfg);\n#endif\n\n\t \n\tcfg = rvu_read64(rvu, block->addr, NPA_AF_NDC_CFG);\n\tcfg &= ~0x03DULL;\n#ifdef CONFIG_NDC_DIS_DYNAMIC_CACHING\n\t \n\tcfg |= 0x10ULL;\n#endif\n\trvu_write64(rvu, block->addr, NPA_AF_NDC_CFG, cfg);\n\n\t \n\tif (!is_rvu_otx2(rvu)) {\n\t\tcfg = rvu_read64(rvu, block->addr, NPA_AF_BATCH_CTL);\n\t\tcfg &= ~0x7EULL;\n\t\tcfg |= BIT_ULL(6) | BIT_ULL(2) | BIT_ULL(1);\n\t\trvu_write64(rvu, block->addr, NPA_AF_BATCH_CTL, cfg);\n\t}\n\t \n\terr = rvu_aq_alloc(rvu, &block->aq,\n\t\t\t   Q_COUNT(AQ_SIZE), sizeof(struct npa_aq_inst_s),\n\t\t\t   ALIGN(sizeof(struct npa_aq_res_s), 128) + 256);\n\tif (err)\n\t\treturn err;\n\n\trvu_write64(rvu, block->addr, NPA_AF_AQ_CFG, AQ_SIZE);\n\trvu_write64(rvu, block->addr,\n\t\t    NPA_AF_AQ_BASE, (u64)block->aq->inst->iova);\n\treturn 0;\n}\n\nint rvu_npa_init(struct rvu *rvu)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tint blkaddr;\n\n\tblkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NPA, 0);\n\tif (blkaddr < 0)\n\t\treturn 0;\n\n\t \n\treturn npa_aq_init(rvu, &hw->block[blkaddr]);\n}\n\nvoid rvu_npa_freemem(struct rvu *rvu)\n{\n\tstruct rvu_hwinfo *hw = rvu->hw;\n\tstruct rvu_block *block;\n\tint blkaddr;\n\n\tblkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NPA, 0);\n\tif (blkaddr < 0)\n\t\treturn;\n\n\tblock = &hw->block[blkaddr];\n\trvu_aq_free(rvu, block->aq);\n}\n\nvoid rvu_npa_lf_teardown(struct rvu *rvu, u16 pcifunc, int npalf)\n{\n\tstruct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, pcifunc);\n\tstruct hwctx_disable_req ctx_req;\n\n\t \n\tctx_req.hdr.pcifunc = pcifunc;\n\tctx_req.ctype = NPA_AQ_CTYPE_POOL;\n\tnpa_lf_hwctx_disable(rvu, &ctx_req);\n\n\t \n\tctx_req.ctype = NPA_AQ_CTYPE_AURA;\n\tnpa_lf_hwctx_disable(rvu, &ctx_req);\n\n\tnpa_ctx_free(rvu, pfvf);\n}\n\n \nint rvu_ndc_fix_locked_cacheline(struct rvu *rvu, int blkaddr)\n{\n\tint bank, max_bank, line, max_line, err;\n\tu64 reg, ndc_af_const;\n\n\t \n\treg = rvu_read64(rvu, blkaddr, NDC_AF_CAMS_RD_INTERVAL);\n\trvu_write64(rvu, blkaddr, NDC_AF_CAMS_RD_INTERVAL, reg & GENMASK_ULL(62, 0));\n\n\t \n\terr = rvu_poll_reg(rvu, blkaddr, NDC_AF_CAMS_RD_INTERVAL, GENMASK_ULL(47, 32), true);\n\tif (err) {\n\t\tdev_err(rvu->dev, \"Timed out while polling for NDC CAM busy bits.\\n\");\n\t\treturn err;\n\t}\n\n\tndc_af_const = rvu_read64(rvu, blkaddr, NDC_AF_CONST);\n\tmax_bank = FIELD_GET(NDC_AF_BANK_MASK, ndc_af_const);\n\tmax_line = FIELD_GET(NDC_AF_BANK_LINE_MASK, ndc_af_const);\n\tfor (bank = 0; bank < max_bank; bank++) {\n\t\tfor (line = 0; line < max_line; line++) {\n\t\t\t \n\t\t\treg = rvu_read64(rvu, blkaddr,\n\t\t\t\t\t NDC_AF_BANKX_LINEX_METADATA(bank, line));\n\t\t\tif (!(reg & BIT_ULL(63)) && (reg & BIT_ULL(60))) {\n\t\t\t\trvu_write64(rvu, blkaddr,\n\t\t\t\t\t    NDC_AF_BANKX_LINEX_METADATA(bank, line),\n\t\t\t\t\t    reg & ~BIT_ULL(60));\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}