{
  "module_name": "octep_tx.c",
  "hash_id": "4dac66135c5764404e984e105cb86207e1bda55988ff06f190178a36a818eca3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeon_ep/octep_tx.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n#include <linux/etherdevice.h>\n#include <linux/vmalloc.h>\n\n#include \"octep_config.h\"\n#include \"octep_main.h\"\n\n \nstatic void octep_iq_reset_indices(struct octep_iq *iq)\n{\n\tiq->fill_cnt = 0;\n\tiq->host_write_index = 0;\n\tiq->octep_read_index = 0;\n\tiq->flush_index = 0;\n\tiq->pkts_processed = 0;\n\tiq->pkt_in_done = 0;\n\tatomic_set(&iq->instr_pending, 0);\n}\n\n \nint octep_iq_process_completions(struct octep_iq *iq, u16 budget)\n{\n\tu32 compl_pkts, compl_bytes, compl_sg;\n\tstruct octep_device *oct = iq->octep_dev;\n\tstruct octep_tx_buffer *tx_buffer;\n\tstruct skb_shared_info *shinfo;\n\tu32 fi = iq->flush_index;\n\tstruct sk_buff *skb;\n\tu8 frags, i;\n\n\tcompl_pkts = 0;\n\tcompl_sg = 0;\n\tcompl_bytes = 0;\n\tiq->octep_read_index = oct->hw_ops.update_iq_read_idx(iq);\n\n\twhile (likely(budget && (fi != iq->octep_read_index))) {\n\t\ttx_buffer = iq->buff_info + fi;\n\t\tskb = tx_buffer->skb;\n\n\t\tfi++;\n\t\tif (unlikely(fi == iq->max_count))\n\t\t\tfi = 0;\n\t\tcompl_bytes += skb->len;\n\t\tcompl_pkts++;\n\t\tbudget--;\n\n\t\tif (!tx_buffer->gather) {\n\t\t\tdma_unmap_single(iq->dev, tx_buffer->dma,\n\t\t\t\t\t tx_buffer->skb->len, DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tshinfo = skb_shinfo(skb);\n\t\tfrags = shinfo->nr_frags;\n\t\tcompl_sg++;\n\n\t\tdma_unmap_single(iq->dev, tx_buffer->sglist[0].dma_ptr[0],\n\t\t\t\t tx_buffer->sglist[0].len[3], DMA_TO_DEVICE);\n\n\t\ti = 1;  \n\t\twhile (frags--) {\n\t\t\tdma_unmap_page(iq->dev, tx_buffer->sglist[i >> 2].dma_ptr[i & 3],\n\t\t\t\t       tx_buffer->sglist[i >> 2].len[3 - (i & 3)], DMA_TO_DEVICE);\n\t\t\ti++;\n\t\t}\n\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\tiq->pkts_processed += compl_pkts;\n\tatomic_sub(compl_pkts, &iq->instr_pending);\n\tiq->stats.instr_completed += compl_pkts;\n\tiq->stats.bytes_sent += compl_bytes;\n\tiq->stats.sgentry_sent += compl_sg;\n\tiq->flush_index = fi;\n\n\tnetdev_tx_completed_queue(iq->netdev_q, compl_pkts, compl_bytes);\n\n\tif (unlikely(__netif_subqueue_stopped(iq->netdev, iq->q_no)) &&\n\t    ((iq->max_count - atomic_read(&iq->instr_pending)) >\n\t     OCTEP_WAKE_QUEUE_THRESHOLD))\n\t\tnetif_wake_subqueue(iq->netdev, iq->q_no);\n\treturn !budget;\n}\n\n \nstatic void octep_iq_free_pending(struct octep_iq *iq)\n{\n\tstruct octep_tx_buffer *tx_buffer;\n\tstruct skb_shared_info *shinfo;\n\tu32 fi = iq->flush_index;\n\tstruct sk_buff *skb;\n\tu8 frags, i;\n\n\twhile (fi != iq->host_write_index) {\n\t\ttx_buffer = iq->buff_info + fi;\n\t\tskb = tx_buffer->skb;\n\n\t\tfi++;\n\t\tif (unlikely(fi == iq->max_count))\n\t\t\tfi = 0;\n\n\t\tif (!tx_buffer->gather) {\n\t\t\tdma_unmap_single(iq->dev, tx_buffer->dma,\n\t\t\t\t\t tx_buffer->skb->len, DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tshinfo = skb_shinfo(skb);\n\t\tfrags = shinfo->nr_frags;\n\n\t\tdma_unmap_single(iq->dev,\n\t\t\t\t tx_buffer->sglist[0].dma_ptr[0],\n\t\t\t\t tx_buffer->sglist[0].len[3],\n\t\t\t\t DMA_TO_DEVICE);\n\n\t\ti = 1;  \n\t\twhile (frags--) {\n\t\t\tdma_unmap_page(iq->dev, tx_buffer->sglist[i >> 2].dma_ptr[i & 3],\n\t\t\t\t       tx_buffer->sglist[i >> 2].len[3 - (i & 3)], DMA_TO_DEVICE);\n\t\t\ti++;\n\t\t}\n\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\tatomic_set(&iq->instr_pending, 0);\n\tiq->flush_index = fi;\n\tnetdev_tx_reset_queue(netdev_get_tx_queue(iq->netdev, iq->q_no));\n}\n\n \nvoid octep_clean_iqs(struct octep_device *oct)\n{\n\tint i;\n\n\tfor (i = 0; i < oct->num_iqs; i++) {\n\t\toctep_iq_free_pending(oct->iq[i]);\n\t\toctep_iq_reset_indices(oct->iq[i]);\n\t}\n}\n\n \nstatic int octep_setup_iq(struct octep_device *oct, int q_no)\n{\n\tu32 desc_ring_size, buff_info_size, sglist_size;\n\tstruct octep_iq *iq;\n\tint i;\n\n\tiq = vzalloc(sizeof(*iq));\n\tif (!iq)\n\t\tgoto iq_alloc_err;\n\toct->iq[q_no] = iq;\n\n\tiq->octep_dev = oct;\n\tiq->netdev = oct->netdev;\n\tiq->dev = &oct->pdev->dev;\n\tiq->q_no = q_no;\n\tiq->max_count = CFG_GET_IQ_NUM_DESC(oct->conf);\n\tiq->ring_size_mask = iq->max_count - 1;\n\tiq->fill_threshold = CFG_GET_IQ_DB_MIN(oct->conf);\n\tiq->netdev_q = netdev_get_tx_queue(iq->netdev, q_no);\n\n\t \n\tdesc_ring_size = OCTEP_IQ_DESC_SIZE * CFG_GET_IQ_NUM_DESC(oct->conf);\n\tiq->desc_ring = dma_alloc_coherent(iq->dev, desc_ring_size,\n\t\t\t\t\t   &iq->desc_ring_dma, GFP_KERNEL);\n\tif (unlikely(!iq->desc_ring)) {\n\t\tdev_err(iq->dev,\n\t\t\t\"Failed to allocate DMA memory for IQ-%d\\n\", q_no);\n\t\tgoto desc_dma_alloc_err;\n\t}\n\n\t \n\tsglist_size = OCTEP_SGLIST_SIZE_PER_PKT *\n\t\t      CFG_GET_IQ_NUM_DESC(oct->conf);\n\tiq->sglist = dma_alloc_coherent(iq->dev, sglist_size,\n\t\t\t\t\t&iq->sglist_dma, GFP_KERNEL);\n\tif (unlikely(!iq->sglist)) {\n\t\tdev_err(iq->dev,\n\t\t\t\"Failed to allocate DMA memory for IQ-%d SGLIST\\n\",\n\t\t\tq_no);\n\t\tgoto sglist_alloc_err;\n\t}\n\n\t \n\tbuff_info_size = OCTEP_IQ_TXBUFF_INFO_SIZE * iq->max_count;\n\tiq->buff_info = vzalloc(buff_info_size);\n\tif (!iq->buff_info) {\n\t\tdev_err(iq->dev,\n\t\t\t\"Failed to allocate buff info for IQ-%d\\n\", q_no);\n\t\tgoto buff_info_err;\n\t}\n\n\t \n\tfor (i = 0; i < CFG_GET_IQ_NUM_DESC(oct->conf); i++) {\n\t\tstruct octep_tx_buffer *tx_buffer;\n\n\t\ttx_buffer = &iq->buff_info[i];\n\t\ttx_buffer->sglist =\n\t\t\t&iq->sglist[i * OCTEP_SGLIST_ENTRIES_PER_PKT];\n\t\ttx_buffer->sglist_dma =\n\t\t\tiq->sglist_dma + (i * OCTEP_SGLIST_SIZE_PER_PKT);\n\t}\n\n\toctep_iq_reset_indices(iq);\n\toct->hw_ops.setup_iq_regs(oct, q_no);\n\n\toct->num_iqs++;\n\treturn 0;\n\nbuff_info_err:\n\tdma_free_coherent(iq->dev, sglist_size, iq->sglist, iq->sglist_dma);\nsglist_alloc_err:\n\tdma_free_coherent(iq->dev, desc_ring_size,\n\t\t\t  iq->desc_ring, iq->desc_ring_dma);\ndesc_dma_alloc_err:\n\tvfree(iq);\n\toct->iq[q_no] = NULL;\niq_alloc_err:\n\treturn -1;\n}\n\n \nstatic void octep_free_iq(struct octep_iq *iq)\n{\n\tstruct octep_device *oct = iq->octep_dev;\n\tu64 desc_ring_size, sglist_size;\n\tint q_no = iq->q_no;\n\n\tdesc_ring_size = OCTEP_IQ_DESC_SIZE * CFG_GET_IQ_NUM_DESC(oct->conf);\n\n\tvfree(iq->buff_info);\n\n\tif (iq->desc_ring)\n\t\tdma_free_coherent(iq->dev, desc_ring_size,\n\t\t\t\t  iq->desc_ring, iq->desc_ring_dma);\n\n\tsglist_size = OCTEP_SGLIST_SIZE_PER_PKT *\n\t\t      CFG_GET_IQ_NUM_DESC(oct->conf);\n\tif (iq->sglist)\n\t\tdma_free_coherent(iq->dev, sglist_size,\n\t\t\t\t  iq->sglist, iq->sglist_dma);\n\n\tvfree(iq);\n\toct->iq[q_no] = NULL;\n\toct->num_iqs--;\n}\n\n \nint octep_setup_iqs(struct octep_device *oct)\n{\n\tint i;\n\n\toct->num_iqs = 0;\n\tfor (i = 0; i < CFG_GET_PORTS_ACTIVE_IO_RINGS(oct->conf); i++) {\n\t\tif (octep_setup_iq(oct, i)) {\n\t\t\tdev_err(&oct->pdev->dev,\n\t\t\t\t\"Failed to setup IQ(TxQ)-%d.\\n\", i);\n\t\t\tgoto iq_setup_err;\n\t\t}\n\t\tdev_dbg(&oct->pdev->dev, \"Successfully setup IQ(TxQ)-%d.\\n\", i);\n\t}\n\n\treturn 0;\n\niq_setup_err:\n\twhile (i) {\n\t\ti--;\n\t\toctep_free_iq(oct->iq[i]);\n\t}\n\treturn -1;\n}\n\n \nvoid octep_free_iqs(struct octep_device *oct)\n{\n\tint i;\n\n\tfor (i = 0; i < CFG_GET_PORTS_ACTIVE_IO_RINGS(oct->conf); i++) {\n\t\toctep_free_iq(oct->iq[i]);\n\t\tdev_dbg(&oct->pdev->dev,\n\t\t\t\"Successfully destroyed IQ(TxQ)-%d.\\n\", i);\n\t}\n\toct->num_iqs = 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}