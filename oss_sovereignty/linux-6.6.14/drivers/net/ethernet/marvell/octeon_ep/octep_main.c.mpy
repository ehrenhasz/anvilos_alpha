{
  "module_name": "octep_main.c",
  "hash_id": "833d2a5087b64eade2de2401cdf3295a8fac1022cf3f07013c3573de834af4b5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/marvell/octeon_ep/octep_main.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/rtnetlink.h>\n#include <linux/vmalloc.h>\n\n#include \"octep_config.h\"\n#include \"octep_main.h\"\n#include \"octep_ctrl_net.h\"\n\n#define OCTEP_INTR_POLL_TIME_MSECS    100\nstruct workqueue_struct *octep_wq;\n\n \nstatic const struct pci_device_id octep_pci_id_tbl[] = {\n\t{PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, OCTEP_PCI_DEVICE_ID_CN93_PF)},\n\t{PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, OCTEP_PCI_DEVICE_ID_CNF95N_PF)},\n\t{0, },\n};\nMODULE_DEVICE_TABLE(pci, octep_pci_id_tbl);\n\nMODULE_AUTHOR(\"Veerasenareddy Burru <vburru@marvell.com>\");\nMODULE_DESCRIPTION(OCTEP_DRV_STRING);\nMODULE_LICENSE(\"GPL\");\n\n \nstatic int octep_alloc_ioq_vectors(struct octep_device *oct)\n{\n\tint i;\n\tstruct octep_ioq_vector *ioq_vector;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\toct->ioq_vector[i] = vzalloc(sizeof(*oct->ioq_vector[i]));\n\t\tif (!oct->ioq_vector[i])\n\t\t\tgoto free_ioq_vector;\n\n\t\tioq_vector = oct->ioq_vector[i];\n\t\tioq_vector->iq = oct->iq[i];\n\t\tioq_vector->oq = oct->oq[i];\n\t\tioq_vector->octep_dev = oct;\n\t}\n\n\tdev_info(&oct->pdev->dev, \"Allocated %d IOQ vectors\\n\", oct->num_oqs);\n\treturn 0;\n\nfree_ioq_vector:\n\twhile (i) {\n\t\ti--;\n\t\tvfree(oct->ioq_vector[i]);\n\t\toct->ioq_vector[i] = NULL;\n\t}\n\treturn -1;\n}\n\n \nstatic void octep_free_ioq_vectors(struct octep_device *oct)\n{\n\tint i;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\tif (oct->ioq_vector[i]) {\n\t\t\tvfree(oct->ioq_vector[i]);\n\t\t\toct->ioq_vector[i] = NULL;\n\t\t}\n\t}\n\tnetdev_info(oct->netdev, \"Freed IOQ Vectors\\n\");\n}\n\n \nstatic int octep_enable_msix_range(struct octep_device *oct)\n{\n\tint num_msix, msix_allocated;\n\tint i;\n\n\t \n\tnum_msix = oct->num_oqs + CFG_GET_NON_IOQ_MSIX(oct->conf);\n\toct->msix_entries = kcalloc(num_msix,\n\t\t\t\t    sizeof(struct msix_entry), GFP_KERNEL);\n\tif (!oct->msix_entries)\n\t\tgoto msix_alloc_err;\n\n\tfor (i = 0; i < num_msix; i++)\n\t\toct->msix_entries[i].entry = i;\n\n\tmsix_allocated = pci_enable_msix_range(oct->pdev, oct->msix_entries,\n\t\t\t\t\t       num_msix, num_msix);\n\tif (msix_allocated != num_msix) {\n\t\tdev_err(&oct->pdev->dev,\n\t\t\t\"Failed to enable %d msix irqs; got only %d\\n\",\n\t\t\tnum_msix, msix_allocated);\n\t\tgoto enable_msix_err;\n\t}\n\toct->num_irqs = msix_allocated;\n\tdev_info(&oct->pdev->dev, \"MSI-X enabled successfully\\n\");\n\n\treturn 0;\n\nenable_msix_err:\n\tif (msix_allocated > 0)\n\t\tpci_disable_msix(oct->pdev);\n\tkfree(oct->msix_entries);\n\toct->msix_entries = NULL;\nmsix_alloc_err:\n\treturn -1;\n}\n\n \nstatic void octep_disable_msix(struct octep_device *oct)\n{\n\tpci_disable_msix(oct->pdev);\n\tkfree(oct->msix_entries);\n\toct->msix_entries = NULL;\n\tdev_info(&oct->pdev->dev, \"Disabled MSI-X\\n\");\n}\n\n \nstatic irqreturn_t octep_non_ioq_intr_handler(int irq, void *data)\n{\n\tstruct octep_device *oct = data;\n\n\treturn oct->hw_ops.non_ioq_intr_handler(oct);\n}\n\n \nstatic irqreturn_t octep_ioq_intr_handler(int irq, void *data)\n{\n\tstruct octep_ioq_vector *ioq_vector = data;\n\tstruct octep_device *oct = ioq_vector->octep_dev;\n\n\treturn oct->hw_ops.ioq_intr_handler(ioq_vector);\n}\n\n \nstatic int octep_request_irqs(struct octep_device *oct)\n{\n\tstruct net_device *netdev = oct->netdev;\n\tstruct octep_ioq_vector *ioq_vector;\n\tstruct msix_entry *msix_entry;\n\tchar **non_ioq_msix_names;\n\tint num_non_ioq_msix;\n\tint ret, i, j;\n\n\tnum_non_ioq_msix = CFG_GET_NON_IOQ_MSIX(oct->conf);\n\tnon_ioq_msix_names = CFG_GET_NON_IOQ_MSIX_NAMES(oct->conf);\n\n\toct->non_ioq_irq_names = kcalloc(num_non_ioq_msix,\n\t\t\t\t\t OCTEP_MSIX_NAME_SIZE, GFP_KERNEL);\n\tif (!oct->non_ioq_irq_names)\n\t\tgoto alloc_err;\n\n\t \n\tfor (i = 0; i < num_non_ioq_msix; i++) {\n\t\tchar *irq_name;\n\n\t\tirq_name = &oct->non_ioq_irq_names[i * OCTEP_MSIX_NAME_SIZE];\n\t\tmsix_entry = &oct->msix_entries[i];\n\n\t\tsnprintf(irq_name, OCTEP_MSIX_NAME_SIZE,\n\t\t\t \"%s-%s\", netdev->name, non_ioq_msix_names[i]);\n\t\tret = request_irq(msix_entry->vector,\n\t\t\t\t  octep_non_ioq_intr_handler, 0,\n\t\t\t\t  irq_name, oct);\n\t\tif (ret) {\n\t\t\tnetdev_err(netdev,\n\t\t\t\t   \"request_irq failed for %s; err=%d\",\n\t\t\t\t   irq_name, ret);\n\t\t\tgoto non_ioq_irq_err;\n\t\t}\n\t}\n\n\t \n\tfor (j = 0; j < oct->num_oqs; j++) {\n\t\tioq_vector = oct->ioq_vector[j];\n\t\tmsix_entry = &oct->msix_entries[j + num_non_ioq_msix];\n\n\t\tsnprintf(ioq_vector->name, sizeof(ioq_vector->name),\n\t\t\t \"%s-q%d\", netdev->name, j);\n\t\tret = request_irq(msix_entry->vector,\n\t\t\t\t  octep_ioq_intr_handler, 0,\n\t\t\t\t  ioq_vector->name, ioq_vector);\n\t\tif (ret) {\n\t\t\tnetdev_err(netdev,\n\t\t\t\t   \"request_irq failed for Q-%d; err=%d\",\n\t\t\t\t   j, ret);\n\t\t\tgoto ioq_irq_err;\n\t\t}\n\n\t\tcpumask_set_cpu(j % num_online_cpus(),\n\t\t\t\t&ioq_vector->affinity_mask);\n\t\tirq_set_affinity_hint(msix_entry->vector,\n\t\t\t\t      &ioq_vector->affinity_mask);\n\t}\n\n\treturn 0;\nioq_irq_err:\n\twhile (j) {\n\t\t--j;\n\t\tioq_vector = oct->ioq_vector[j];\n\t\tmsix_entry = &oct->msix_entries[j + num_non_ioq_msix];\n\n\t\tirq_set_affinity_hint(msix_entry->vector, NULL);\n\t\tfree_irq(msix_entry->vector, ioq_vector);\n\t}\nnon_ioq_irq_err:\n\twhile (i) {\n\t\t--i;\n\t\tfree_irq(oct->msix_entries[i].vector, oct);\n\t}\n\tkfree(oct->non_ioq_irq_names);\n\toct->non_ioq_irq_names = NULL;\nalloc_err:\n\treturn -1;\n}\n\n \nstatic void octep_free_irqs(struct octep_device *oct)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < CFG_GET_NON_IOQ_MSIX(oct->conf); i++)\n\t\tfree_irq(oct->msix_entries[i].vector, oct);\n\tkfree(oct->non_ioq_irq_names);\n\n\t \n\tfor (i = CFG_GET_NON_IOQ_MSIX(oct->conf); i < oct->num_irqs; i++) {\n\t\tirq_set_affinity_hint(oct->msix_entries[i].vector, NULL);\n\t\tfree_irq(oct->msix_entries[i].vector,\n\t\t\t oct->ioq_vector[i - CFG_GET_NON_IOQ_MSIX(oct->conf)]);\n\t}\n\tnetdev_info(oct->netdev, \"IRQs freed\\n\");\n}\n\n \nstatic int octep_setup_irqs(struct octep_device *oct)\n{\n\tif (octep_alloc_ioq_vectors(oct))\n\t\tgoto ioq_vector_err;\n\n\tif (octep_enable_msix_range(oct))\n\t\tgoto enable_msix_err;\n\n\tif (octep_request_irqs(oct))\n\t\tgoto request_irq_err;\n\n\treturn 0;\n\nrequest_irq_err:\n\toctep_disable_msix(oct);\nenable_msix_err:\n\toctep_free_ioq_vectors(oct);\nioq_vector_err:\n\treturn -1;\n}\n\n \nstatic void octep_clean_irqs(struct octep_device *oct)\n{\n\toctep_free_irqs(oct);\n\toctep_disable_msix(oct);\n\toctep_free_ioq_vectors(oct);\n}\n\n \nstatic void octep_enable_ioq_irq(struct octep_iq *iq, struct octep_oq *oq)\n{\n\tu32 pkts_pend = oq->pkts_pending;\n\n\tnetdev_dbg(iq->netdev, \"enabling intr for Q-%u\\n\", iq->q_no);\n\tif (iq->pkts_processed) {\n\t\twritel(iq->pkts_processed, iq->inst_cnt_reg);\n\t\tiq->pkt_in_done -= iq->pkts_processed;\n\t\tiq->pkts_processed = 0;\n\t}\n\tif (oq->last_pkt_count - pkts_pend) {\n\t\twritel(oq->last_pkt_count - pkts_pend, oq->pkts_sent_reg);\n\t\toq->last_pkt_count = pkts_pend;\n\t}\n\n\t \n\twmb();\n\twriteq(1UL << OCTEP_OQ_INTR_RESEND_BIT, oq->pkts_sent_reg);\n\twriteq(1UL << OCTEP_IQ_INTR_RESEND_BIT, iq->inst_cnt_reg);\n}\n\n \nstatic int octep_napi_poll(struct napi_struct *napi, int budget)\n{\n\tstruct octep_ioq_vector *ioq_vector =\n\t\tcontainer_of(napi, struct octep_ioq_vector, napi);\n\tu32 tx_pending, rx_done;\n\n\ttx_pending = octep_iq_process_completions(ioq_vector->iq, budget);\n\trx_done = octep_oq_process_rx(ioq_vector->oq, budget);\n\n\t \n\tif (tx_pending || rx_done >= budget)\n\t\treturn budget;\n\n\tnapi_complete(napi);\n\toctep_enable_ioq_irq(ioq_vector->iq, ioq_vector->oq);\n\treturn rx_done;\n}\n\n \nstatic void octep_napi_add(struct octep_device *oct)\n{\n\tint i;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\tnetdev_dbg(oct->netdev, \"Adding NAPI on Q-%d\\n\", i);\n\t\tnetif_napi_add(oct->netdev, &oct->ioq_vector[i]->napi,\n\t\t\t       octep_napi_poll);\n\t\toct->oq[i]->napi = &oct->ioq_vector[i]->napi;\n\t}\n}\n\n \nstatic void octep_napi_delete(struct octep_device *oct)\n{\n\tint i;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\tnetdev_dbg(oct->netdev, \"Deleting NAPI on Q-%d\\n\", i);\n\t\tnetif_napi_del(&oct->ioq_vector[i]->napi);\n\t\toct->oq[i]->napi = NULL;\n\t}\n}\n\n \nstatic void octep_napi_enable(struct octep_device *oct)\n{\n\tint i;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\tnetdev_dbg(oct->netdev, \"Enabling NAPI on Q-%d\\n\", i);\n\t\tnapi_enable(&oct->ioq_vector[i]->napi);\n\t}\n}\n\n \nstatic void octep_napi_disable(struct octep_device *oct)\n{\n\tint i;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\tnetdev_dbg(oct->netdev, \"Disabling NAPI on Q-%d\\n\", i);\n\t\tnapi_disable(&oct->ioq_vector[i]->napi);\n\t}\n}\n\nstatic void octep_link_up(struct net_device *netdev)\n{\n\tnetif_carrier_on(netdev);\n\tnetif_tx_start_all_queues(netdev);\n}\n\n \nstatic int octep_open(struct net_device *netdev)\n{\n\tstruct octep_device *oct = netdev_priv(netdev);\n\tint err, ret;\n\n\tnetdev_info(netdev, \"Starting netdev ...\\n\");\n\tnetif_carrier_off(netdev);\n\n\toct->hw_ops.reset_io_queues(oct);\n\n\tif (octep_setup_iqs(oct))\n\t\tgoto setup_iq_err;\n\tif (octep_setup_oqs(oct))\n\t\tgoto setup_oq_err;\n\tif (octep_setup_irqs(oct))\n\t\tgoto setup_irq_err;\n\n\terr = netif_set_real_num_tx_queues(netdev, oct->num_oqs);\n\tif (err)\n\t\tgoto set_queues_err;\n\terr = netif_set_real_num_rx_queues(netdev, oct->num_iqs);\n\tif (err)\n\t\tgoto set_queues_err;\n\n\toctep_napi_add(oct);\n\toctep_napi_enable(oct);\n\n\toct->link_info.admin_up = 1;\n\toctep_ctrl_net_set_rx_state(oct, OCTEP_CTRL_NET_INVALID_VFID, true,\n\t\t\t\t    false);\n\toctep_ctrl_net_set_link_status(oct, OCTEP_CTRL_NET_INVALID_VFID, true,\n\t\t\t\t       false);\n\toct->poll_non_ioq_intr = false;\n\n\t \n\toct->hw_ops.enable_io_queues(oct);\n\n\t \n\toct->hw_ops.enable_interrupts(oct);\n\n\toctep_oq_dbell_init(oct);\n\n\tret = octep_ctrl_net_get_link_status(oct, OCTEP_CTRL_NET_INVALID_VFID);\n\tif (ret > 0)\n\t\toctep_link_up(netdev);\n\n\treturn 0;\n\nset_queues_err:\n\toctep_clean_irqs(oct);\nsetup_irq_err:\n\toctep_free_oqs(oct);\nsetup_oq_err:\n\toctep_free_iqs(oct);\nsetup_iq_err:\n\treturn -1;\n}\n\n \nstatic int octep_stop(struct net_device *netdev)\n{\n\tstruct octep_device *oct = netdev_priv(netdev);\n\n\tnetdev_info(netdev, \"Stopping the device ...\\n\");\n\n\toctep_ctrl_net_set_link_status(oct, OCTEP_CTRL_NET_INVALID_VFID, false,\n\t\t\t\t       false);\n\toctep_ctrl_net_set_rx_state(oct, OCTEP_CTRL_NET_INVALID_VFID, false,\n\t\t\t\t    false);\n\n\t \n\tnetif_tx_stop_all_queues(netdev);\n\tnetif_carrier_off(netdev);\n\tnetif_tx_disable(netdev);\n\n\toct->link_info.admin_up = 0;\n\toct->link_info.oper_up = 0;\n\n\toct->hw_ops.disable_interrupts(oct);\n\toctep_napi_disable(oct);\n\toctep_napi_delete(oct);\n\n\toctep_clean_irqs(oct);\n\toctep_clean_iqs(oct);\n\n\toct->hw_ops.disable_io_queues(oct);\n\toct->hw_ops.reset_io_queues(oct);\n\toctep_free_oqs(oct);\n\toctep_free_iqs(oct);\n\n\toct->poll_non_ioq_intr = true;\n\tqueue_delayed_work(octep_wq, &oct->intr_poll_task,\n\t\t\t   msecs_to_jiffies(OCTEP_INTR_POLL_TIME_MSECS));\n\n\tnetdev_info(netdev, \"Device stopped !!\\n\");\n\treturn 0;\n}\n\n \nstatic inline int octep_iq_full_check(struct octep_iq *iq)\n{\n\tif (likely((iq->max_count - atomic_read(&iq->instr_pending)) >=\n\t\t   OCTEP_WAKE_QUEUE_THRESHOLD))\n\t\treturn 0;\n\n\t \n\tnetif_stop_subqueue(iq->netdev, iq->q_no);\n\n\t \n\tif (unlikely((iq->max_count - atomic_read(&iq->instr_pending)) >=\n\t\t     OCTEP_WAKE_QUEUE_THRESHOLD)) {\n\t\tnetif_start_subqueue(iq->netdev, iq->q_no);\n\t\tiq->stats.restart_cnt++;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\n \nstatic netdev_tx_t octep_start_xmit(struct sk_buff *skb,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct octep_device *oct = netdev_priv(netdev);\n\tstruct octep_tx_sglist_desc *sglist;\n\tstruct octep_tx_buffer *tx_buffer;\n\tstruct octep_tx_desc_hw *hw_desc;\n\tstruct skb_shared_info *shinfo;\n\tstruct octep_instr_hdr *ih;\n\tstruct octep_iq *iq;\n\tskb_frag_t *frag;\n\tu16 nr_frags, si;\n\tu16 q_no, wi;\n\n\tq_no = skb_get_queue_mapping(skb);\n\tif (q_no >= oct->num_iqs) {\n\t\tnetdev_err(netdev, \"Invalid Tx skb->queue_mapping=%d\\n\", q_no);\n\t\tq_no = q_no % oct->num_iqs;\n\t}\n\n\tiq = oct->iq[q_no];\n\tif (octep_iq_full_check(iq)) {\n\t\tiq->stats.tx_busy++;\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tshinfo = skb_shinfo(skb);\n\tnr_frags = shinfo->nr_frags;\n\n\twi = iq->host_write_index;\n\thw_desc = &iq->desc_ring[wi];\n\thw_desc->ih64 = 0;\n\n\ttx_buffer = iq->buff_info + wi;\n\ttx_buffer->skb = skb;\n\n\tih = &hw_desc->ih;\n\tih->tlen = skb->len;\n\tih->pkind = oct->pkind;\n\n\tif (!nr_frags) {\n\t\ttx_buffer->gather = 0;\n\t\ttx_buffer->dma = dma_map_single(iq->dev, skb->data,\n\t\t\t\t\t\tskb->len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(iq->dev, tx_buffer->dma))\n\t\t\tgoto dma_map_err;\n\t\thw_desc->dptr = tx_buffer->dma;\n\t} else {\n\t\t \n\t\tdma_addr_t dma;\n\t\tu16 len;\n\n\t\tsglist = tx_buffer->sglist;\n\n\t\tih->gsz = nr_frags + 1;\n\t\tih->gather = 1;\n\t\ttx_buffer->gather = 1;\n\n\t\tlen = skb_headlen(skb);\n\t\tdma = dma_map_single(iq->dev, skb->data, len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(iq->dev, dma))\n\t\t\tgoto dma_map_err;\n\n\t\tdma_sync_single_for_cpu(iq->dev, tx_buffer->sglist_dma,\n\t\t\t\t\tOCTEP_SGLIST_SIZE_PER_PKT,\n\t\t\t\t\tDMA_TO_DEVICE);\n\t\tmemset(sglist, 0, OCTEP_SGLIST_SIZE_PER_PKT);\n\t\tsglist[0].len[3] = len;\n\t\tsglist[0].dma_ptr[0] = dma;\n\n\t\tsi = 1;  \n\t\tfrag = &shinfo->frags[0];\n\t\twhile (nr_frags--) {\n\t\t\tlen = skb_frag_size(frag);\n\t\t\tdma = skb_frag_dma_map(iq->dev, frag, 0,\n\t\t\t\t\t       len, DMA_TO_DEVICE);\n\t\t\tif (dma_mapping_error(iq->dev, dma))\n\t\t\t\tgoto dma_map_sg_err;\n\n\t\t\tsglist[si >> 2].len[3 - (si & 3)] = len;\n\t\t\tsglist[si >> 2].dma_ptr[si & 3] = dma;\n\n\t\t\tfrag++;\n\t\t\tsi++;\n\t\t}\n\t\tdma_sync_single_for_device(iq->dev, tx_buffer->sglist_dma,\n\t\t\t\t\t   OCTEP_SGLIST_SIZE_PER_PKT,\n\t\t\t\t\t   DMA_TO_DEVICE);\n\n\t\thw_desc->dptr = tx_buffer->sglist_dma;\n\t}\n\n\tnetdev_tx_sent_queue(iq->netdev_q, skb->len);\n\tskb_tx_timestamp(skb);\n\tatomic_inc(&iq->instr_pending);\n\twi++;\n\tif (wi == iq->max_count)\n\t\twi = 0;\n\tiq->host_write_index = wi;\n\t \n\twmb();\n\n\t \n\twritel(1, iq->doorbell_reg);\n\tiq->stats.instr_posted++;\n\treturn NETDEV_TX_OK;\n\ndma_map_sg_err:\n\tif (si > 0) {\n\t\tdma_unmap_single(iq->dev, sglist[0].dma_ptr[0],\n\t\t\t\t sglist[0].len[3], DMA_TO_DEVICE);\n\t\tsglist[0].len[3] = 0;\n\t}\n\twhile (si > 1) {\n\t\tdma_unmap_page(iq->dev, sglist[si >> 2].dma_ptr[si & 3],\n\t\t\t       sglist[si >> 2].len[3 - (si & 3)], DMA_TO_DEVICE);\n\t\tsglist[si >> 2].len[3 - (si & 3)] = 0;\n\t\tsi--;\n\t}\n\ttx_buffer->gather = 0;\ndma_map_err:\n\tdev_kfree_skb_any(skb);\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic void octep_get_stats64(struct net_device *netdev,\n\t\t\t      struct rtnl_link_stats64 *stats)\n{\n\tu64 tx_packets, tx_bytes, rx_packets, rx_bytes;\n\tstruct octep_device *oct = netdev_priv(netdev);\n\tint q;\n\n\tif (netif_running(netdev))\n\t\toctep_ctrl_net_get_if_stats(oct,\n\t\t\t\t\t    OCTEP_CTRL_NET_INVALID_VFID,\n\t\t\t\t\t    &oct->iface_rx_stats,\n\t\t\t\t\t    &oct->iface_tx_stats);\n\n\ttx_packets = 0;\n\ttx_bytes = 0;\n\trx_packets = 0;\n\trx_bytes = 0;\n\tfor (q = 0; q < oct->num_oqs; q++) {\n\t\tstruct octep_iq *iq = oct->iq[q];\n\t\tstruct octep_oq *oq = oct->oq[q];\n\n\t\ttx_packets += iq->stats.instr_completed;\n\t\ttx_bytes += iq->stats.bytes_sent;\n\t\trx_packets += oq->stats.packets;\n\t\trx_bytes += oq->stats.bytes;\n\t}\n\tstats->tx_packets = tx_packets;\n\tstats->tx_bytes = tx_bytes;\n\tstats->rx_packets = rx_packets;\n\tstats->rx_bytes = rx_bytes;\n\tstats->multicast = oct->iface_rx_stats.mcast_pkts;\n\tstats->rx_errors = oct->iface_rx_stats.err_pkts;\n\tstats->collisions = oct->iface_tx_stats.xscol;\n\tstats->tx_fifo_errors = oct->iface_tx_stats.undflw;\n}\n\n \nstatic void octep_tx_timeout_task(struct work_struct *work)\n{\n\tstruct octep_device *oct = container_of(work, struct octep_device,\n\t\t\t\t\t\ttx_timeout_task);\n\tstruct net_device *netdev = oct->netdev;\n\n\trtnl_lock();\n\tif (netif_running(netdev)) {\n\t\toctep_stop(netdev);\n\t\toctep_open(netdev);\n\t}\n\trtnl_unlock();\n}\n\n \nstatic void octep_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct octep_device *oct = netdev_priv(netdev);\n\n\tqueue_work(octep_wq, &oct->tx_timeout_task);\n}\n\nstatic int octep_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct octep_device *oct = netdev_priv(netdev);\n\tstruct sockaddr *addr = (struct sockaddr *)p;\n\tint err;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\terr = octep_ctrl_net_set_mac_addr(oct, OCTEP_CTRL_NET_INVALID_VFID,\n\t\t\t\t\t  addr->sa_data, true);\n\tif (err)\n\t\treturn err;\n\n\tmemcpy(oct->mac_addr, addr->sa_data, ETH_ALEN);\n\teth_hw_addr_set(netdev, addr->sa_data);\n\n\treturn 0;\n}\n\nstatic int octep_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct octep_device *oct = netdev_priv(netdev);\n\tstruct octep_iface_link_info *link_info;\n\tint err = 0;\n\n\tlink_info = &oct->link_info;\n\tif (link_info->mtu == new_mtu)\n\t\treturn 0;\n\n\terr = octep_ctrl_net_set_mtu(oct, OCTEP_CTRL_NET_INVALID_VFID, new_mtu,\n\t\t\t\t     true);\n\tif (!err) {\n\t\toct->link_info.mtu = new_mtu;\n\t\tnetdev->mtu = new_mtu;\n\t}\n\n\treturn err;\n}\n\nstatic const struct net_device_ops octep_netdev_ops = {\n\t.ndo_open                = octep_open,\n\t.ndo_stop                = octep_stop,\n\t.ndo_start_xmit          = octep_start_xmit,\n\t.ndo_get_stats64         = octep_get_stats64,\n\t.ndo_tx_timeout          = octep_tx_timeout,\n\t.ndo_set_mac_address     = octep_set_mac,\n\t.ndo_change_mtu          = octep_change_mtu,\n};\n\n \nstatic void octep_intr_poll_task(struct work_struct *work)\n{\n\tstruct octep_device *oct = container_of(work, struct octep_device,\n\t\t\t\t\t\tintr_poll_task.work);\n\n\tif (!oct->poll_non_ioq_intr) {\n\t\tdev_info(&oct->pdev->dev, \"Interrupt poll task stopped.\\n\");\n\t\treturn;\n\t}\n\n\toct->hw_ops.poll_non_ioq_interrupts(oct);\n\tqueue_delayed_work(octep_wq, &oct->intr_poll_task,\n\t\t\t   msecs_to_jiffies(OCTEP_INTR_POLL_TIME_MSECS));\n}\n\n \nstatic void octep_hb_timeout_task(struct work_struct *work)\n{\n\tstruct octep_device *oct = container_of(work, struct octep_device,\n\t\t\t\t\t\thb_task.work);\n\n\tint miss_cnt;\n\n\tmiss_cnt = atomic_inc_return(&oct->hb_miss_cnt);\n\tif (miss_cnt < oct->conf->max_hb_miss_cnt) {\n\t\tqueue_delayed_work(octep_wq, &oct->hb_task,\n\t\t\t\t   msecs_to_jiffies(oct->conf->hb_interval * 1000));\n\t\treturn;\n\t}\n\n\tdev_err(&oct->pdev->dev, \"Missed %u heartbeats. Uninitializing\\n\",\n\t\tmiss_cnt);\n\trtnl_lock();\n\tif (netif_running(oct->netdev))\n\t\toctep_stop(oct->netdev);\n\trtnl_unlock();\n}\n\n \nstatic void octep_ctrl_mbox_task(struct work_struct *work)\n{\n\tstruct octep_device *oct = container_of(work, struct octep_device,\n\t\t\t\t\t\tctrl_mbox_task);\n\n\toctep_ctrl_net_recv_fw_messages(oct);\n}\n\nstatic const char *octep_devid_to_str(struct octep_device *oct)\n{\n\tswitch (oct->chip_id) {\n\tcase OCTEP_PCI_DEVICE_ID_CN93_PF:\n\t\treturn \"CN93XX\";\n\tcase OCTEP_PCI_DEVICE_ID_CNF95N_PF:\n\t\treturn \"CNF95N\";\n\tdefault:\n\t\treturn \"Unsupported\";\n\t}\n}\n\n \nint octep_device_setup(struct octep_device *oct)\n{\n\tstruct pci_dev *pdev = oct->pdev;\n\tint i, ret;\n\n\t \n\toct->conf = kzalloc(sizeof(*oct->conf), GFP_KERNEL);\n\tif (!oct->conf)\n\t\treturn -ENOMEM;\n\n\t \n\tfor (i = 0; i < OCTEP_MMIO_REGIONS; i++) {\n\t\toct->mmio[i].hw_addr =\n\t\t\tioremap(pci_resource_start(oct->pdev, i * 2),\n\t\t\t\tpci_resource_len(oct->pdev, i * 2));\n\t\tif (!oct->mmio[i].hw_addr)\n\t\t\tgoto unmap_prev;\n\n\t\toct->mmio[i].mapped = 1;\n\t}\n\n\toct->chip_id = pdev->device;\n\toct->rev_id = pdev->revision;\n\tdev_info(&pdev->dev, \"chip_id = 0x%x\\n\", pdev->device);\n\n\tswitch (oct->chip_id) {\n\tcase OCTEP_PCI_DEVICE_ID_CN93_PF:\n\tcase OCTEP_PCI_DEVICE_ID_CNF95N_PF:\n\t\tdev_info(&pdev->dev, \"Setting up OCTEON %s PF PASS%d.%d\\n\",\n\t\t\t octep_devid_to_str(oct), OCTEP_MAJOR_REV(oct),\n\t\t\t OCTEP_MINOR_REV(oct));\n\t\toctep_device_setup_cn93_pf(oct);\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&pdev->dev,\n\t\t\t\"%s: unsupported device\\n\", __func__);\n\t\tgoto unsupported_dev;\n\t}\n\n\toct->pkind = CFG_GET_IQ_PKIND(oct->conf);\n\n\tret = octep_ctrl_net_init(oct);\n\tif (ret)\n\t\treturn ret;\n\n\tatomic_set(&oct->hb_miss_cnt, 0);\n\tINIT_DELAYED_WORK(&oct->hb_task, octep_hb_timeout_task);\n\tqueue_delayed_work(octep_wq, &oct->hb_task,\n\t\t\t   msecs_to_jiffies(oct->conf->hb_interval * 1000));\n\treturn 0;\n\nunsupported_dev:\n\ti = OCTEP_MMIO_REGIONS;\nunmap_prev:\n\twhile (i--)\n\t\tiounmap(oct->mmio[i].hw_addr);\n\n\tkfree(oct->conf);\n\treturn -1;\n}\n\n \nstatic void octep_device_cleanup(struct octep_device *oct)\n{\n\tint i;\n\n\toct->poll_non_ioq_intr = false;\n\tcancel_delayed_work_sync(&oct->intr_poll_task);\n\tcancel_work_sync(&oct->ctrl_mbox_task);\n\n\tdev_info(&oct->pdev->dev, \"Cleaning up Octeon Device ...\\n\");\n\n\tfor (i = 0; i < OCTEP_MAX_VF; i++) {\n\t\tvfree(oct->mbox[i]);\n\t\toct->mbox[i] = NULL;\n\t}\n\n\toctep_ctrl_net_uninit(oct);\n\tcancel_delayed_work_sync(&oct->hb_task);\n\n\toct->hw_ops.soft_reset(oct);\n\tfor (i = 0; i < OCTEP_MMIO_REGIONS; i++) {\n\t\tif (oct->mmio[i].mapped)\n\t\t\tiounmap(oct->mmio[i].hw_addr);\n\t}\n\n\tkfree(oct->conf);\n\toct->conf = NULL;\n}\n\nstatic bool get_fw_ready_status(struct pci_dev *pdev)\n{\n\tu32 pos = 0;\n\tu16 vsec_id;\n\tu8 status;\n\n\twhile ((pos = pci_find_next_ext_capability(pdev, pos,\n\t\t\t\t\t\t   PCI_EXT_CAP_ID_VNDR))) {\n\t\tpci_read_config_word(pdev, pos + 4, &vsec_id);\n#define FW_STATUS_VSEC_ID  0xA3\n\t\tif (vsec_id != FW_STATUS_VSEC_ID)\n\t\t\tcontinue;\n\n\t\tpci_read_config_byte(pdev, (pos + 8), &status);\n\t\tdev_info(&pdev->dev, \"Firmware ready status = %u\\n\", status);\n#define FW_STATUS_READY 1ULL\n\t\treturn status == FW_STATUS_READY;\n\t}\n\treturn false;\n}\n\n \nstatic int octep_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct octep_device *octep_dev = NULL;\n\tstruct net_device *netdev;\n\tint err;\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to enable PCI device\\n\");\n\t\treturn  err;\n\t}\n\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to set DMA mask !!\\n\");\n\t\tgoto err_dma_mask;\n\t}\n\n\terr = pci_request_mem_regions(pdev, OCTEP_DRV_NAME);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to map PCI memory regions\\n\");\n\t\tgoto err_pci_regions;\n\t}\n\n\tpci_set_master(pdev);\n\n\tif (!get_fw_ready_status(pdev)) {\n\t\tdev_notice(&pdev->dev, \"Firmware not ready; defer probe.\\n\");\n\t\terr = -EPROBE_DEFER;\n\t\tgoto err_alloc_netdev;\n\t}\n\n\tnetdev = alloc_etherdev_mq(sizeof(struct octep_device),\n\t\t\t\t   OCTEP_MAX_QUEUES);\n\tif (!netdev) {\n\t\tdev_err(&pdev->dev, \"Failed to allocate netdev\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_alloc_netdev;\n\t}\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\n\toctep_dev = netdev_priv(netdev);\n\toctep_dev->netdev = netdev;\n\toctep_dev->pdev = pdev;\n\toctep_dev->dev = &pdev->dev;\n\tpci_set_drvdata(pdev, octep_dev);\n\n\terr = octep_device_setup(octep_dev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Device setup failed\\n\");\n\t\tgoto err_octep_config;\n\t}\n\tINIT_WORK(&octep_dev->tx_timeout_task, octep_tx_timeout_task);\n\tINIT_WORK(&octep_dev->ctrl_mbox_task, octep_ctrl_mbox_task);\n\tINIT_DELAYED_WORK(&octep_dev->intr_poll_task, octep_intr_poll_task);\n\toctep_dev->poll_non_ioq_intr = true;\n\tqueue_delayed_work(octep_wq, &octep_dev->intr_poll_task,\n\t\t\t   msecs_to_jiffies(OCTEP_INTR_POLL_TIME_MSECS));\n\n\tnetdev->netdev_ops = &octep_netdev_ops;\n\toctep_set_ethtool_ops(netdev);\n\tnetif_carrier_off(netdev);\n\n\tnetdev->hw_features = NETIF_F_SG;\n\tnetdev->features |= netdev->hw_features;\n\tnetdev->min_mtu = OCTEP_MIN_MTU;\n\tnetdev->max_mtu = OCTEP_MAX_MTU;\n\tnetdev->mtu = OCTEP_DEFAULT_MTU;\n\n\terr = octep_ctrl_net_get_mac_addr(octep_dev, OCTEP_CTRL_NET_INVALID_VFID,\n\t\t\t\t\t  octep_dev->mac_addr);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to get mac address\\n\");\n\t\tgoto register_dev_err;\n\t}\n\teth_hw_addr_set(netdev, octep_dev->mac_addr);\n\n\terr = register_netdev(netdev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to register netdev\\n\");\n\t\tgoto register_dev_err;\n\t}\n\tdev_info(&pdev->dev, \"Device probe successful\\n\");\n\treturn 0;\n\nregister_dev_err:\n\toctep_device_cleanup(octep_dev);\nerr_octep_config:\n\tfree_netdev(netdev);\nerr_alloc_netdev:\n\tpci_release_mem_regions(pdev);\nerr_pci_regions:\nerr_dma_mask:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n \nstatic void octep_remove(struct pci_dev *pdev)\n{\n\tstruct octep_device *oct = pci_get_drvdata(pdev);\n\tstruct net_device *netdev;\n\n\tif (!oct)\n\t\treturn;\n\n\tnetdev = oct->netdev;\n\tif (netdev->reg_state == NETREG_REGISTERED)\n\t\tunregister_netdev(netdev);\n\n\tcancel_work_sync(&oct->tx_timeout_task);\n\toctep_device_cleanup(oct);\n\tpci_release_mem_regions(pdev);\n\tfree_netdev(netdev);\n\tpci_disable_device(pdev);\n}\n\nstatic struct pci_driver octep_driver = {\n\t.name = OCTEP_DRV_NAME,\n\t.id_table = octep_pci_id_tbl,\n\t.probe = octep_probe,\n\t.remove = octep_remove,\n};\n\n \nstatic int __init octep_init_module(void)\n{\n\tint ret;\n\n\tpr_info(\"%s: Loading %s ...\\n\", OCTEP_DRV_NAME, OCTEP_DRV_STRING);\n\n\t \n\toctep_wq = create_singlethread_workqueue(OCTEP_DRV_NAME);\n\tif (!octep_wq) {\n\t\tpr_err(\"%s: Failed to create common workqueue\\n\",\n\t\t       OCTEP_DRV_NAME);\n\t\treturn -ENOMEM;\n\t}\n\n\tret = pci_register_driver(&octep_driver);\n\tif (ret < 0) {\n\t\tpr_err(\"%s: Failed to register PCI driver; err=%d\\n\",\n\t\t       OCTEP_DRV_NAME, ret);\n\t\tdestroy_workqueue(octep_wq);\n\t\treturn ret;\n\t}\n\n\tpr_info(\"%s: Loaded successfully !\\n\", OCTEP_DRV_NAME);\n\n\treturn ret;\n}\n\n \nstatic void __exit octep_exit_module(void)\n{\n\tpr_info(\"%s: Unloading ...\\n\", OCTEP_DRV_NAME);\n\n\tpci_unregister_driver(&octep_driver);\n\tdestroy_workqueue(octep_wq);\n\n\tpr_info(\"%s: Unloading complete\\n\", OCTEP_DRV_NAME);\n}\n\nmodule_init(octep_init_module);\nmodule_exit(octep_exit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}