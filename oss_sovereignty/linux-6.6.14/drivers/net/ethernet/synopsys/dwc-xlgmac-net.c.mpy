{
  "module_name": "dwc-xlgmac-net.c",
  "hash_id": "7c3397a81a7ed2d6e91c8b736e334ab9ba082ef230fc4b6153ff1e51a56452c8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/synopsys/dwc-xlgmac-net.c",
  "human_readable_source": " \n\n#include <linux/netdevice.h>\n#include <linux/tcp.h>\n#include <linux/interrupt.h>\n\n#include \"dwc-xlgmac.h\"\n#include \"dwc-xlgmac-reg.h\"\n\nstatic int xlgmac_one_poll(struct napi_struct *, int);\nstatic int xlgmac_all_poll(struct napi_struct *, int);\n\nstatic inline unsigned int xlgmac_tx_avail_desc(struct xlgmac_ring *ring)\n{\n\treturn (ring->dma_desc_count - (ring->cur - ring->dirty));\n}\n\nstatic inline unsigned int xlgmac_rx_dirty_desc(struct xlgmac_ring *ring)\n{\n\treturn (ring->cur - ring->dirty);\n}\n\nstatic int xlgmac_maybe_stop_tx_queue(\n\t\t\tstruct xlgmac_channel *channel,\n\t\t\tstruct xlgmac_ring *ring,\n\t\t\tunsigned int count)\n{\n\tstruct xlgmac_pdata *pdata = channel->pdata;\n\n\tif (count > xlgmac_tx_avail_desc(ring)) {\n\t\tnetif_info(pdata, drv, pdata->netdev,\n\t\t\t   \"Tx queue stopped, not enough descriptors available\\n\");\n\t\tnetif_stop_subqueue(pdata->netdev, channel->queue_index);\n\t\tring->tx.queue_stopped = 1;\n\n\t\t \n\t\tif (ring->tx.xmit_more)\n\t\t\tpdata->hw_ops.tx_start_xmit(channel, ring);\n\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\treturn 0;\n}\n\nstatic void xlgmac_prep_vlan(struct sk_buff *skb,\n\t\t\t     struct xlgmac_pkt_info *pkt_info)\n{\n\tif (skb_vlan_tag_present(skb))\n\t\tpkt_info->vlan_ctag = skb_vlan_tag_get(skb);\n}\n\nstatic int xlgmac_prep_tso(struct sk_buff *skb,\n\t\t\t   struct xlgmac_pkt_info *pkt_info)\n{\n\tint ret;\n\n\tif (!XLGMAC_GET_REG_BITS(pkt_info->attributes,\n\t\t\t\t TX_PACKET_ATTRIBUTES_TSO_ENABLE_POS,\n\t\t\t\t TX_PACKET_ATTRIBUTES_TSO_ENABLE_LEN))\n\t\treturn 0;\n\n\tret = skb_cow_head(skb, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tpkt_info->header_len = skb_tcp_all_headers(skb);\n\tpkt_info->tcp_header_len = tcp_hdrlen(skb);\n\tpkt_info->tcp_payload_len = skb->len - pkt_info->header_len;\n\tpkt_info->mss = skb_shinfo(skb)->gso_size;\n\n\tXLGMAC_PR(\"header_len=%u\\n\", pkt_info->header_len);\n\tXLGMAC_PR(\"tcp_header_len=%u, tcp_payload_len=%u\\n\",\n\t\t  pkt_info->tcp_header_len, pkt_info->tcp_payload_len);\n\tXLGMAC_PR(\"mss=%u\\n\", pkt_info->mss);\n\n\t \n\tpkt_info->tx_packets = skb_shinfo(skb)->gso_segs;\n\tpkt_info->tx_bytes += (pkt_info->tx_packets - 1) * pkt_info->header_len;\n\n\treturn 0;\n}\n\nstatic int xlgmac_is_tso(struct sk_buff *skb)\n{\n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn 0;\n\n\tif (!skb_is_gso(skb))\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic void xlgmac_prep_tx_pkt(struct xlgmac_pdata *pdata,\n\t\t\t       struct xlgmac_ring *ring,\n\t\t\t       struct sk_buff *skb,\n\t\t\t       struct xlgmac_pkt_info *pkt_info)\n{\n\tskb_frag_t *frag;\n\tunsigned int context_desc;\n\tunsigned int len;\n\tunsigned int i;\n\n\tpkt_info->skb = skb;\n\n\tcontext_desc = 0;\n\tpkt_info->desc_count = 0;\n\n\tpkt_info->tx_packets = 1;\n\tpkt_info->tx_bytes = skb->len;\n\n\tif (xlgmac_is_tso(skb)) {\n\t\t \n\t\tif (skb_shinfo(skb)->gso_size != ring->tx.cur_mss) {\n\t\t\tcontext_desc = 1;\n\t\t\tpkt_info->desc_count++;\n\t\t}\n\n\t\t \n\t\tpkt_info->desc_count++;\n\n\t\tpkt_info->attributes = XLGMAC_SET_REG_BITS(\n\t\t\t\t\tpkt_info->attributes,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_TSO_ENABLE_POS,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_TSO_ENABLE_LEN,\n\t\t\t\t\t1);\n\t\tpkt_info->attributes = XLGMAC_SET_REG_BITS(\n\t\t\t\t\tpkt_info->attributes,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_CSUM_ENABLE_POS,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_CSUM_ENABLE_LEN,\n\t\t\t\t\t1);\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tpkt_info->attributes = XLGMAC_SET_REG_BITS(\n\t\t\t\t\tpkt_info->attributes,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_CSUM_ENABLE_POS,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_CSUM_ENABLE_LEN,\n\t\t\t\t\t1);\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\t \n\t\tif (skb_vlan_tag_get(skb) != ring->tx.cur_vlan_ctag)\n\t\t\t \n\t\t\tif (!context_desc) {\n\t\t\t\tcontext_desc = 1;\n\t\t\t\tpkt_info->desc_count++;\n\t\t\t}\n\n\t\tpkt_info->attributes = XLGMAC_SET_REG_BITS(\n\t\t\t\t\tpkt_info->attributes,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_VLAN_CTAG_POS,\n\t\t\t\t\tTX_PACKET_ATTRIBUTES_VLAN_CTAG_LEN,\n\t\t\t\t\t1);\n\t}\n\n\tfor (len = skb_headlen(skb); len;) {\n\t\tpkt_info->desc_count++;\n\t\tlen -= min_t(unsigned int, len, XLGMAC_TX_MAX_BUF_SIZE);\n\t}\n\n\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\tfrag = &skb_shinfo(skb)->frags[i];\n\t\tfor (len = skb_frag_size(frag); len; ) {\n\t\t\tpkt_info->desc_count++;\n\t\t\tlen -= min_t(unsigned int, len, XLGMAC_TX_MAX_BUF_SIZE);\n\t\t}\n\t}\n}\n\nstatic int xlgmac_calc_rx_buf_size(struct net_device *netdev, unsigned int mtu)\n{\n\tunsigned int rx_buf_size;\n\n\tif (mtu > XLGMAC_JUMBO_PACKET_MTU) {\n\t\tnetdev_alert(netdev, \"MTU exceeds maximum supported value\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\trx_buf_size = mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\trx_buf_size = clamp_val(rx_buf_size, XLGMAC_RX_MIN_BUF_SIZE, PAGE_SIZE);\n\n\trx_buf_size = (rx_buf_size + XLGMAC_RX_BUF_ALIGN - 1) &\n\t\t      ~(XLGMAC_RX_BUF_ALIGN - 1);\n\n\treturn rx_buf_size;\n}\n\nstatic void xlgmac_enable_rx_tx_ints(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\tstruct xlgmac_channel *channel;\n\tenum xlgmac_int int_id;\n\tunsigned int i;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tif (channel->tx_ring && channel->rx_ring)\n\t\t\tint_id = XLGMAC_INT_DMA_CH_SR_TI_RI;\n\t\telse if (channel->tx_ring)\n\t\t\tint_id = XLGMAC_INT_DMA_CH_SR_TI;\n\t\telse if (channel->rx_ring)\n\t\t\tint_id = XLGMAC_INT_DMA_CH_SR_RI;\n\t\telse\n\t\t\tcontinue;\n\n\t\thw_ops->enable_int(channel, int_id);\n\t}\n}\n\nstatic void xlgmac_disable_rx_tx_ints(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\tstruct xlgmac_channel *channel;\n\tenum xlgmac_int int_id;\n\tunsigned int i;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tif (channel->tx_ring && channel->rx_ring)\n\t\t\tint_id = XLGMAC_INT_DMA_CH_SR_TI_RI;\n\t\telse if (channel->tx_ring)\n\t\t\tint_id = XLGMAC_INT_DMA_CH_SR_TI;\n\t\telse if (channel->rx_ring)\n\t\t\tint_id = XLGMAC_INT_DMA_CH_SR_RI;\n\t\telse\n\t\t\tcontinue;\n\n\t\thw_ops->disable_int(channel, int_id);\n\t}\n}\n\nstatic irqreturn_t xlgmac_isr(int irq, void *data)\n{\n\tunsigned int dma_isr, dma_ch_isr, mac_isr;\n\tstruct xlgmac_pdata *pdata = data;\n\tstruct xlgmac_channel *channel;\n\tstruct xlgmac_hw_ops *hw_ops;\n\tunsigned int i, ti, ri;\n\n\thw_ops = &pdata->hw_ops;\n\n\t \n\tdma_isr = readl(pdata->mac_regs + DMA_ISR);\n\tif (!dma_isr)\n\t\treturn IRQ_HANDLED;\n\n\tnetif_dbg(pdata, intr, pdata->netdev, \"DMA_ISR=%#010x\\n\", dma_isr);\n\n\tfor (i = 0; i < pdata->channel_count; i++) {\n\t\tif (!(dma_isr & (1 << i)))\n\t\t\tcontinue;\n\n\t\tchannel = pdata->channel_head + i;\n\n\t\tdma_ch_isr = readl(XLGMAC_DMA_REG(channel, DMA_CH_SR));\n\t\tnetif_dbg(pdata, intr, pdata->netdev, \"DMA_CH%u_ISR=%#010x\\n\",\n\t\t\t  i, dma_ch_isr);\n\n\t\t \n\t\tti = XLGMAC_GET_REG_BITS(dma_ch_isr, DMA_CH_SR_TI_POS,\n\t\t\t\t\t DMA_CH_SR_TI_LEN);\n\t\tri = XLGMAC_GET_REG_BITS(dma_ch_isr, DMA_CH_SR_RI_POS,\n\t\t\t\t\t DMA_CH_SR_RI_LEN);\n\t\tif (!pdata->per_channel_irq && (ti || ri)) {\n\t\t\tif (napi_schedule_prep(&pdata->napi)) {\n\t\t\t\t \n\t\t\t\txlgmac_disable_rx_tx_ints(pdata);\n\n\t\t\t\tpdata->stats.napi_poll_isr++;\n\t\t\t\t \n\t\t\t\t__napi_schedule_irqoff(&pdata->napi);\n\t\t\t}\n\t\t}\n\n\t\tif (XLGMAC_GET_REG_BITS(dma_ch_isr, DMA_CH_SR_TPS_POS,\n\t\t\t\t\tDMA_CH_SR_TPS_LEN))\n\t\t\tpdata->stats.tx_process_stopped++;\n\n\t\tif (XLGMAC_GET_REG_BITS(dma_ch_isr, DMA_CH_SR_RPS_POS,\n\t\t\t\t\tDMA_CH_SR_RPS_LEN))\n\t\t\tpdata->stats.rx_process_stopped++;\n\n\t\tif (XLGMAC_GET_REG_BITS(dma_ch_isr, DMA_CH_SR_TBU_POS,\n\t\t\t\t\tDMA_CH_SR_TBU_LEN))\n\t\t\tpdata->stats.tx_buffer_unavailable++;\n\n\t\tif (XLGMAC_GET_REG_BITS(dma_ch_isr, DMA_CH_SR_RBU_POS,\n\t\t\t\t\tDMA_CH_SR_RBU_LEN))\n\t\t\tpdata->stats.rx_buffer_unavailable++;\n\n\t\t \n\t\tif (XLGMAC_GET_REG_BITS(dma_ch_isr, DMA_CH_SR_FBE_POS,\n\t\t\t\t\tDMA_CH_SR_FBE_LEN)) {\n\t\t\tpdata->stats.fatal_bus_error++;\n\t\t\tschedule_work(&pdata->restart_work);\n\t\t}\n\n\t\t \n\t\twritel(dma_ch_isr, XLGMAC_DMA_REG(channel, DMA_CH_SR));\n\t}\n\n\tif (XLGMAC_GET_REG_BITS(dma_isr, DMA_ISR_MACIS_POS,\n\t\t\t\tDMA_ISR_MACIS_LEN)) {\n\t\tmac_isr = readl(pdata->mac_regs + MAC_ISR);\n\n\t\tif (XLGMAC_GET_REG_BITS(mac_isr, MAC_ISR_MMCTXIS_POS,\n\t\t\t\t\tMAC_ISR_MMCTXIS_LEN))\n\t\t\thw_ops->tx_mmc_int(pdata);\n\n\t\tif (XLGMAC_GET_REG_BITS(mac_isr, MAC_ISR_MMCRXIS_POS,\n\t\t\t\t\tMAC_ISR_MMCRXIS_LEN))\n\t\t\thw_ops->rx_mmc_int(pdata);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t xlgmac_dma_isr(int irq, void *data)\n{\n\tstruct xlgmac_channel *channel = data;\n\n\t \n\tif (napi_schedule_prep(&channel->napi)) {\n\t\t \n\t\tdisable_irq_nosync(channel->dma_irq);\n\n\t\t \n\t\t__napi_schedule_irqoff(&channel->napi);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void xlgmac_tx_timer(struct timer_list *t)\n{\n\tstruct xlgmac_channel *channel = from_timer(channel, t, tx_timer);\n\tstruct xlgmac_pdata *pdata = channel->pdata;\n\tstruct napi_struct *napi;\n\n\tnapi = (pdata->per_channel_irq) ? &channel->napi : &pdata->napi;\n\n\tif (napi_schedule_prep(napi)) {\n\t\t \n\t\tif (pdata->per_channel_irq)\n\t\t\tdisable_irq_nosync(channel->dma_irq);\n\t\telse\n\t\t\txlgmac_disable_rx_tx_ints(pdata);\n\n\t\tpdata->stats.napi_poll_txtimer++;\n\t\t \n\t\t__napi_schedule(napi);\n\t}\n\n\tchannel->tx_timer_active = 0;\n}\n\nstatic void xlgmac_init_timers(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_channel *channel;\n\tunsigned int i;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tif (!channel->tx_ring)\n\t\t\tbreak;\n\n\t\ttimer_setup(&channel->tx_timer, xlgmac_tx_timer, 0);\n\t}\n}\n\nstatic void xlgmac_stop_timers(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_channel *channel;\n\tunsigned int i;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tif (!channel->tx_ring)\n\t\t\tbreak;\n\n\t\tdel_timer_sync(&channel->tx_timer);\n\t}\n}\n\nstatic void xlgmac_napi_enable(struct xlgmac_pdata *pdata, unsigned int add)\n{\n\tstruct xlgmac_channel *channel;\n\tunsigned int i;\n\n\tif (pdata->per_channel_irq) {\n\t\tchannel = pdata->channel_head;\n\t\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\t\tif (add)\n\t\t\t\tnetif_napi_add(pdata->netdev, &channel->napi,\n\t\t\t\t\t       xlgmac_one_poll);\n\n\t\t\tnapi_enable(&channel->napi);\n\t\t}\n\t} else {\n\t\tif (add)\n\t\t\tnetif_napi_add(pdata->netdev, &pdata->napi,\n\t\t\t\t       xlgmac_all_poll);\n\n\t\tnapi_enable(&pdata->napi);\n\t}\n}\n\nstatic void xlgmac_napi_disable(struct xlgmac_pdata *pdata, unsigned int del)\n{\n\tstruct xlgmac_channel *channel;\n\tunsigned int i;\n\n\tif (pdata->per_channel_irq) {\n\t\tchannel = pdata->channel_head;\n\t\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\t\tnapi_disable(&channel->napi);\n\n\t\t\tif (del)\n\t\t\t\tnetif_napi_del(&channel->napi);\n\t\t}\n\t} else {\n\t\tnapi_disable(&pdata->napi);\n\n\t\tif (del)\n\t\t\tnetif_napi_del(&pdata->napi);\n\t}\n}\n\nstatic int xlgmac_request_irqs(struct xlgmac_pdata *pdata)\n{\n\tstruct net_device *netdev = pdata->netdev;\n\tstruct xlgmac_channel *channel;\n\tunsigned int i;\n\tint ret;\n\n\tret = devm_request_irq(pdata->dev, pdata->dev_irq, xlgmac_isr,\n\t\t\t       IRQF_SHARED, netdev->name, pdata);\n\tif (ret) {\n\t\tnetdev_alert(netdev, \"error requesting irq %d\\n\",\n\t\t\t     pdata->dev_irq);\n\t\treturn ret;\n\t}\n\n\tif (!pdata->per_channel_irq)\n\t\treturn 0;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tsnprintf(channel->dma_irq_name,\n\t\t\t sizeof(channel->dma_irq_name) - 1,\n\t\t\t \"%s-TxRx-%u\", netdev_name(netdev),\n\t\t\t channel->queue_index);\n\n\t\tret = devm_request_irq(pdata->dev, channel->dma_irq,\n\t\t\t\t       xlgmac_dma_isr, 0,\n\t\t\t\t       channel->dma_irq_name, channel);\n\t\tif (ret) {\n\t\t\tnetdev_alert(netdev, \"error requesting irq %d\\n\",\n\t\t\t\t     channel->dma_irq);\n\t\t\tgoto err_irq;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_irq:\n\t \n\tfor (i--, channel--; i < pdata->channel_count; i--, channel--)\n\t\tdevm_free_irq(pdata->dev, channel->dma_irq, channel);\n\n\tdevm_free_irq(pdata->dev, pdata->dev_irq, pdata);\n\n\treturn ret;\n}\n\nstatic void xlgmac_free_irqs(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_channel *channel;\n\tunsigned int i;\n\n\tdevm_free_irq(pdata->dev, pdata->dev_irq, pdata);\n\n\tif (!pdata->per_channel_irq)\n\t\treturn;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++)\n\t\tdevm_free_irq(pdata->dev, channel->dma_irq, channel);\n}\n\nstatic void xlgmac_free_tx_data(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_desc_ops *desc_ops = &pdata->desc_ops;\n\tstruct xlgmac_desc_data *desc_data;\n\tstruct xlgmac_channel *channel;\n\tstruct xlgmac_ring *ring;\n\tunsigned int i, j;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tring = channel->tx_ring;\n\t\tif (!ring)\n\t\t\tbreak;\n\n\t\tfor (j = 0; j < ring->dma_desc_count; j++) {\n\t\t\tdesc_data = XLGMAC_GET_DESC_DATA(ring, j);\n\t\t\tdesc_ops->unmap_desc_data(pdata, desc_data);\n\t\t}\n\t}\n}\n\nstatic void xlgmac_free_rx_data(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_desc_ops *desc_ops = &pdata->desc_ops;\n\tstruct xlgmac_desc_data *desc_data;\n\tstruct xlgmac_channel *channel;\n\tstruct xlgmac_ring *ring;\n\tunsigned int i, j;\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tring = channel->rx_ring;\n\t\tif (!ring)\n\t\t\tbreak;\n\n\t\tfor (j = 0; j < ring->dma_desc_count; j++) {\n\t\t\tdesc_data = XLGMAC_GET_DESC_DATA(ring, j);\n\t\t\tdesc_ops->unmap_desc_data(pdata, desc_data);\n\t\t}\n\t}\n}\n\nstatic int xlgmac_start(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\tstruct net_device *netdev = pdata->netdev;\n\tint ret;\n\n\thw_ops->init(pdata);\n\txlgmac_napi_enable(pdata, 1);\n\n\tret = xlgmac_request_irqs(pdata);\n\tif (ret)\n\t\tgoto err_napi;\n\n\thw_ops->enable_tx(pdata);\n\thw_ops->enable_rx(pdata);\n\tnetif_tx_start_all_queues(netdev);\n\n\treturn 0;\n\nerr_napi:\n\txlgmac_napi_disable(pdata, 1);\n\thw_ops->exit(pdata);\n\n\treturn ret;\n}\n\nstatic void xlgmac_stop(struct xlgmac_pdata *pdata)\n{\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\tstruct net_device *netdev = pdata->netdev;\n\tstruct xlgmac_channel *channel;\n\tstruct netdev_queue *txq;\n\tunsigned int i;\n\n\tnetif_tx_stop_all_queues(netdev);\n\txlgmac_stop_timers(pdata);\n\thw_ops->disable_tx(pdata);\n\thw_ops->disable_rx(pdata);\n\txlgmac_free_irqs(pdata);\n\txlgmac_napi_disable(pdata, 1);\n\thw_ops->exit(pdata);\n\n\tchannel = pdata->channel_head;\n\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\tif (!channel->tx_ring)\n\t\t\tcontinue;\n\n\t\ttxq = netdev_get_tx_queue(netdev, channel->queue_index);\n\t\tnetdev_tx_reset_queue(txq);\n\t}\n}\n\nstatic void xlgmac_restart_dev(struct xlgmac_pdata *pdata)\n{\n\t \n\tif (!netif_running(pdata->netdev))\n\t\treturn;\n\n\txlgmac_stop(pdata);\n\n\txlgmac_free_tx_data(pdata);\n\txlgmac_free_rx_data(pdata);\n\n\txlgmac_start(pdata);\n}\n\nstatic void xlgmac_restart(struct work_struct *work)\n{\n\tstruct xlgmac_pdata *pdata = container_of(work,\n\t\t\t\t\t\t   struct xlgmac_pdata,\n\t\t\t\t\t\t   restart_work);\n\n\trtnl_lock();\n\n\txlgmac_restart_dev(pdata);\n\n\trtnl_unlock();\n}\n\nstatic int xlgmac_open(struct net_device *netdev)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_desc_ops *desc_ops;\n\tint ret;\n\n\tdesc_ops = &pdata->desc_ops;\n\n\t \n\n\t \n\tret = xlgmac_calc_rx_buf_size(netdev, netdev->mtu);\n\tif (ret < 0)\n\t\treturn ret;\n\tpdata->rx_buf_size = ret;\n\n\t \n\tret = desc_ops->alloc_channels_and_rings(pdata);\n\tif (ret)\n\t\treturn ret;\n\n\tINIT_WORK(&pdata->restart_work, xlgmac_restart);\n\txlgmac_init_timers(pdata);\n\n\tret = xlgmac_start(pdata);\n\tif (ret)\n\t\tgoto err_channels_and_rings;\n\n\treturn 0;\n\nerr_channels_and_rings:\n\tdesc_ops->free_channels_and_rings(pdata);\n\n\treturn ret;\n}\n\nstatic int xlgmac_close(struct net_device *netdev)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_desc_ops *desc_ops;\n\n\tdesc_ops = &pdata->desc_ops;\n\n\t \n\txlgmac_stop(pdata);\n\n\t \n\tdesc_ops->free_channels_and_rings(pdata);\n\n\treturn 0;\n}\n\nstatic void xlgmac_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\n\tnetdev_warn(netdev, \"tx timeout, device restarting\\n\");\n\tschedule_work(&pdata->restart_work);\n}\n\nstatic netdev_tx_t xlgmac_xmit(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_pkt_info *tx_pkt_info;\n\tstruct xlgmac_desc_ops *desc_ops;\n\tstruct xlgmac_channel *channel;\n\tstruct xlgmac_hw_ops *hw_ops;\n\tstruct netdev_queue *txq;\n\tstruct xlgmac_ring *ring;\n\tint ret;\n\n\tdesc_ops = &pdata->desc_ops;\n\thw_ops = &pdata->hw_ops;\n\n\tXLGMAC_PR(\"skb->len = %d\\n\", skb->len);\n\n\tchannel = pdata->channel_head + skb->queue_mapping;\n\ttxq = netdev_get_tx_queue(netdev, channel->queue_index);\n\tring = channel->tx_ring;\n\ttx_pkt_info = &ring->pkt_info;\n\n\tif (skb->len == 0) {\n\t\tnetif_err(pdata, tx_err, netdev,\n\t\t\t  \"empty skb received from stack\\n\");\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\t \n\tmemset(tx_pkt_info, 0, sizeof(*tx_pkt_info));\n\txlgmac_prep_tx_pkt(pdata, ring, skb, tx_pkt_info);\n\n\t \n\tret = xlgmac_maybe_stop_tx_queue(channel, ring,\n\t\t\t\t\t tx_pkt_info->desc_count);\n\tif (ret)\n\t\treturn ret;\n\n\tret = xlgmac_prep_tso(skb, tx_pkt_info);\n\tif (ret) {\n\t\tnetif_err(pdata, tx_err, netdev,\n\t\t\t  \"error processing TSO packet\\n\");\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\txlgmac_prep_vlan(skb, tx_pkt_info);\n\n\tif (!desc_ops->map_tx_skb(channel, skb)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\t \n\tnetdev_tx_sent_queue(txq, tx_pkt_info->tx_bytes);\n\n\t \n\thw_ops->dev_xmit(channel);\n\n\tif (netif_msg_pktdata(pdata))\n\t\txlgmac_print_pkt(netdev, skb, true);\n\n\t \n\txlgmac_maybe_stop_tx_queue(channel, ring, XLGMAC_TX_MAX_DESC_NR);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void xlgmac_get_stats64(struct net_device *netdev,\n\t\t\t       struct rtnl_link_stats64 *s)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_stats *pstats = &pdata->stats;\n\n\tpdata->hw_ops.read_mmc_stats(pdata);\n\n\ts->rx_packets = pstats->rxframecount_gb;\n\ts->rx_bytes = pstats->rxoctetcount_gb;\n\ts->rx_errors = pstats->rxframecount_gb -\n\t\t       pstats->rxbroadcastframes_g -\n\t\t       pstats->rxmulticastframes_g -\n\t\t       pstats->rxunicastframes_g;\n\ts->multicast = pstats->rxmulticastframes_g;\n\ts->rx_length_errors = pstats->rxlengtherror;\n\ts->rx_crc_errors = pstats->rxcrcerror;\n\ts->rx_fifo_errors = pstats->rxfifooverflow;\n\n\ts->tx_packets = pstats->txframecount_gb;\n\ts->tx_bytes = pstats->txoctetcount_gb;\n\ts->tx_errors = pstats->txframecount_gb - pstats->txframecount_g;\n\ts->tx_dropped = netdev->stats.tx_dropped;\n}\n\nstatic int xlgmac_set_mac_address(struct net_device *netdev, void *addr)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\tstruct sockaddr *saddr = addr;\n\n\tif (!is_valid_ether_addr(saddr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(netdev, saddr->sa_data);\n\n\thw_ops->set_mac_address(pdata, netdev->dev_addr);\n\n\treturn 0;\n}\n\nstatic int xlgmac_ioctl(struct net_device *netdev,\n\t\t\tstruct ifreq *ifreq, int cmd)\n{\n\tif (!netif_running(netdev))\n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\nstatic int xlgmac_change_mtu(struct net_device *netdev, int mtu)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tint ret;\n\n\tret = xlgmac_calc_rx_buf_size(netdev, mtu);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tpdata->rx_buf_size = ret;\n\tnetdev->mtu = mtu;\n\n\txlgmac_restart_dev(pdata);\n\n\treturn 0;\n}\n\nstatic int xlgmac_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t  __be16 proto,\n\t\t\t\t  u16 vid)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\n\tset_bit(vid, pdata->active_vlans);\n\thw_ops->update_vlan_hash_table(pdata);\n\n\treturn 0;\n}\n\nstatic int xlgmac_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t   __be16 proto,\n\t\t\t\t   u16 vid)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\n\tclear_bit(vid, pdata->active_vlans);\n\thw_ops->update_vlan_hash_table(pdata);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void xlgmac_poll_controller(struct net_device *netdev)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_channel *channel;\n\tunsigned int i;\n\n\tif (pdata->per_channel_irq) {\n\t\tchannel = pdata->channel_head;\n\t\tfor (i = 0; i < pdata->channel_count; i++, channel++)\n\t\t\txlgmac_dma_isr(channel->dma_irq, channel);\n\t} else {\n\t\tdisable_irq(pdata->dev_irq);\n\t\txlgmac_isr(pdata->dev_irq, pdata);\n\t\tenable_irq(pdata->dev_irq);\n\t}\n}\n#endif  \n\nstatic int xlgmac_set_features(struct net_device *netdev,\n\t\t\t       netdev_features_t features)\n{\n\tnetdev_features_t rxhash, rxcsum, rxvlan, rxvlan_filter;\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\tint ret = 0;\n\n\trxhash = pdata->netdev_features & NETIF_F_RXHASH;\n\trxcsum = pdata->netdev_features & NETIF_F_RXCSUM;\n\trxvlan = pdata->netdev_features & NETIF_F_HW_VLAN_CTAG_RX;\n\trxvlan_filter = pdata->netdev_features & NETIF_F_HW_VLAN_CTAG_FILTER;\n\n\tif ((features & NETIF_F_RXHASH) && !rxhash)\n\t\tret = hw_ops->enable_rss(pdata);\n\telse if (!(features & NETIF_F_RXHASH) && rxhash)\n\t\tret = hw_ops->disable_rss(pdata);\n\tif (ret)\n\t\treturn ret;\n\n\tif ((features & NETIF_F_RXCSUM) && !rxcsum)\n\t\thw_ops->enable_rx_csum(pdata);\n\telse if (!(features & NETIF_F_RXCSUM) && rxcsum)\n\t\thw_ops->disable_rx_csum(pdata);\n\n\tif ((features & NETIF_F_HW_VLAN_CTAG_RX) && !rxvlan)\n\t\thw_ops->enable_rx_vlan_stripping(pdata);\n\telse if (!(features & NETIF_F_HW_VLAN_CTAG_RX) && rxvlan)\n\t\thw_ops->disable_rx_vlan_stripping(pdata);\n\n\tif ((features & NETIF_F_HW_VLAN_CTAG_FILTER) && !rxvlan_filter)\n\t\thw_ops->enable_rx_vlan_filtering(pdata);\n\telse if (!(features & NETIF_F_HW_VLAN_CTAG_FILTER) && rxvlan_filter)\n\t\thw_ops->disable_rx_vlan_filtering(pdata);\n\n\tpdata->netdev_features = features;\n\n\treturn 0;\n}\n\nstatic void xlgmac_set_rx_mode(struct net_device *netdev)\n{\n\tstruct xlgmac_pdata *pdata = netdev_priv(netdev);\n\tstruct xlgmac_hw_ops *hw_ops = &pdata->hw_ops;\n\n\thw_ops->config_rx_mode(pdata);\n}\n\nstatic const struct net_device_ops xlgmac_netdev_ops = {\n\t.ndo_open\t\t= xlgmac_open,\n\t.ndo_stop\t\t= xlgmac_close,\n\t.ndo_start_xmit\t\t= xlgmac_xmit,\n\t.ndo_tx_timeout\t\t= xlgmac_tx_timeout,\n\t.ndo_get_stats64\t= xlgmac_get_stats64,\n\t.ndo_change_mtu\t\t= xlgmac_change_mtu,\n\t.ndo_set_mac_address\t= xlgmac_set_mac_address,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_eth_ioctl\t\t= xlgmac_ioctl,\n\t.ndo_vlan_rx_add_vid\t= xlgmac_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= xlgmac_vlan_rx_kill_vid,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= xlgmac_poll_controller,\n#endif\n\t.ndo_set_features\t= xlgmac_set_features,\n\t.ndo_set_rx_mode\t= xlgmac_set_rx_mode,\n};\n\nconst struct net_device_ops *xlgmac_get_netdev_ops(void)\n{\n\treturn &xlgmac_netdev_ops;\n}\n\nstatic void xlgmac_rx_refresh(struct xlgmac_channel *channel)\n{\n\tstruct xlgmac_pdata *pdata = channel->pdata;\n\tstruct xlgmac_ring *ring = channel->rx_ring;\n\tstruct xlgmac_desc_data *desc_data;\n\tstruct xlgmac_desc_ops *desc_ops;\n\tstruct xlgmac_hw_ops *hw_ops;\n\n\tdesc_ops = &pdata->desc_ops;\n\thw_ops = &pdata->hw_ops;\n\n\twhile (ring->dirty != ring->cur) {\n\t\tdesc_data = XLGMAC_GET_DESC_DATA(ring, ring->dirty);\n\n\t\t \n\t\tdesc_ops->unmap_desc_data(pdata, desc_data);\n\n\t\tif (desc_ops->map_rx_buffer(pdata, ring, desc_data))\n\t\t\tbreak;\n\n\t\thw_ops->rx_desc_reset(pdata, desc_data, ring->dirty);\n\n\t\tring->dirty++;\n\t}\n\n\t \n\twmb();\n\n\t \n\tdesc_data = XLGMAC_GET_DESC_DATA(ring, ring->dirty - 1);\n\twritel(lower_32_bits(desc_data->dma_desc_addr),\n\t       XLGMAC_DMA_REG(channel, DMA_CH_RDTR_LO));\n}\n\nstatic struct sk_buff *xlgmac_create_skb(struct xlgmac_pdata *pdata,\n\t\t\t\t\t struct napi_struct *napi,\n\t\t\t\t\t struct xlgmac_desc_data *desc_data,\n\t\t\t\t\t unsigned int len)\n{\n\tunsigned int copy_len;\n\tstruct sk_buff *skb;\n\tu8 *packet;\n\n\tskb = napi_alloc_skb(napi, desc_data->rx.hdr.dma_len);\n\tif (!skb)\n\t\treturn NULL;\n\n\t \n\tdma_sync_single_range_for_cpu(pdata->dev, desc_data->rx.hdr.dma_base,\n\t\t\t\t      desc_data->rx.hdr.dma_off,\n\t\t\t\t      desc_data->rx.hdr.dma_len,\n\t\t\t\t      DMA_FROM_DEVICE);\n\n\tpacket = page_address(desc_data->rx.hdr.pa.pages) +\n\t\t desc_data->rx.hdr.pa.pages_offset;\n\tcopy_len = (desc_data->rx.hdr_len) ? desc_data->rx.hdr_len : len;\n\tcopy_len = min(desc_data->rx.hdr.dma_len, copy_len);\n\tskb_copy_to_linear_data(skb, packet, copy_len);\n\tskb_put(skb, copy_len);\n\n\tlen -= copy_len;\n\tif (len) {\n\t\t \n\t\tdma_sync_single_range_for_cpu(pdata->dev,\n\t\t\t\t\t      desc_data->rx.buf.dma_base,\n\t\t\t\t\t      desc_data->rx.buf.dma_off,\n\t\t\t\t\t      desc_data->rx.buf.dma_len,\n\t\t\t\t\t      DMA_FROM_DEVICE);\n\n\t\tskb_add_rx_frag(skb, skb_shinfo(skb)->nr_frags,\n\t\t\t\tdesc_data->rx.buf.pa.pages,\n\t\t\t\tdesc_data->rx.buf.pa.pages_offset,\n\t\t\t\tlen, desc_data->rx.buf.dma_len);\n\t\tdesc_data->rx.buf.pa.pages = NULL;\n\t}\n\n\treturn skb;\n}\n\nstatic int xlgmac_tx_poll(struct xlgmac_channel *channel)\n{\n\tstruct xlgmac_pdata *pdata = channel->pdata;\n\tstruct xlgmac_ring *ring = channel->tx_ring;\n\tstruct net_device *netdev = pdata->netdev;\n\tunsigned int tx_packets = 0, tx_bytes = 0;\n\tstruct xlgmac_desc_data *desc_data;\n\tstruct xlgmac_dma_desc *dma_desc;\n\tstruct xlgmac_desc_ops *desc_ops;\n\tstruct xlgmac_hw_ops *hw_ops;\n\tstruct netdev_queue *txq;\n\tint processed = 0;\n\tunsigned int cur;\n\n\tdesc_ops = &pdata->desc_ops;\n\thw_ops = &pdata->hw_ops;\n\n\t \n\tif (!ring)\n\t\treturn 0;\n\n\tcur = ring->cur;\n\n\t \n\tsmp_rmb();\n\n\ttxq = netdev_get_tx_queue(netdev, channel->queue_index);\n\n\twhile ((processed < XLGMAC_TX_DESC_MAX_PROC) &&\n\t       (ring->dirty != cur)) {\n\t\tdesc_data = XLGMAC_GET_DESC_DATA(ring, ring->dirty);\n\t\tdma_desc = desc_data->dma_desc;\n\n\t\tif (!hw_ops->tx_complete(dma_desc))\n\t\t\tbreak;\n\n\t\t \n\t\tdma_rmb();\n\n\t\tif (netif_msg_tx_done(pdata))\n\t\t\txlgmac_dump_tx_desc(pdata, ring, ring->dirty, 1, 0);\n\n\t\tif (hw_ops->is_last_desc(dma_desc)) {\n\t\t\ttx_packets += desc_data->tx.packets;\n\t\t\ttx_bytes += desc_data->tx.bytes;\n\t\t}\n\n\t\t \n\t\tdesc_ops->unmap_desc_data(pdata, desc_data);\n\t\thw_ops->tx_desc_reset(desc_data);\n\n\t\tprocessed++;\n\t\tring->dirty++;\n\t}\n\n\tif (!processed)\n\t\treturn 0;\n\n\tnetdev_tx_completed_queue(txq, tx_packets, tx_bytes);\n\n\tif ((ring->tx.queue_stopped == 1) &&\n\t    (xlgmac_tx_avail_desc(ring) > XLGMAC_TX_DESC_MIN_FREE)) {\n\t\tring->tx.queue_stopped = 0;\n\t\tnetif_tx_wake_queue(txq);\n\t}\n\n\tXLGMAC_PR(\"processed=%d\\n\", processed);\n\n\treturn processed;\n}\n\nstatic int xlgmac_rx_poll(struct xlgmac_channel *channel, int budget)\n{\n\tstruct xlgmac_pdata *pdata = channel->pdata;\n\tstruct xlgmac_ring *ring = channel->rx_ring;\n\tstruct net_device *netdev = pdata->netdev;\n\tunsigned int len, dma_desc_len, max_len;\n\tunsigned int context_next, context;\n\tstruct xlgmac_desc_data *desc_data;\n\tstruct xlgmac_pkt_info *pkt_info;\n\tunsigned int incomplete, error;\n\tstruct xlgmac_hw_ops *hw_ops;\n\tunsigned int received = 0;\n\tstruct napi_struct *napi;\n\tstruct sk_buff *skb;\n\tint packet_count = 0;\n\n\thw_ops = &pdata->hw_ops;\n\n\t \n\tif (!ring)\n\t\treturn 0;\n\n\tincomplete = 0;\n\tcontext_next = 0;\n\n\tnapi = (pdata->per_channel_irq) ? &channel->napi : &pdata->napi;\n\n\tdesc_data = XLGMAC_GET_DESC_DATA(ring, ring->cur);\n\tpkt_info = &ring->pkt_info;\n\twhile (packet_count < budget) {\n\t\t \n\t\tif (!received && desc_data->state_saved) {\n\t\t\tskb = desc_data->state.skb;\n\t\t\terror = desc_data->state.error;\n\t\t\tlen = desc_data->state.len;\n\t\t} else {\n\t\t\tmemset(pkt_info, 0, sizeof(*pkt_info));\n\t\t\tskb = NULL;\n\t\t\terror = 0;\n\t\t\tlen = 0;\n\t\t}\n\nread_again:\n\t\tdesc_data = XLGMAC_GET_DESC_DATA(ring, ring->cur);\n\n\t\tif (xlgmac_rx_dirty_desc(ring) > XLGMAC_RX_DESC_MAX_DIRTY)\n\t\t\txlgmac_rx_refresh(channel);\n\n\t\tif (hw_ops->dev_read(channel))\n\t\t\tbreak;\n\n\t\treceived++;\n\t\tring->cur++;\n\n\t\tincomplete = XLGMAC_GET_REG_BITS(\n\t\t\t\t\tpkt_info->attributes,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_INCOMPLETE_POS,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_INCOMPLETE_LEN);\n\t\tcontext_next = XLGMAC_GET_REG_BITS(\n\t\t\t\t\tpkt_info->attributes,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_CONTEXT_NEXT_POS,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_CONTEXT_NEXT_LEN);\n\t\tcontext = XLGMAC_GET_REG_BITS(\n\t\t\t\t\tpkt_info->attributes,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_CONTEXT_POS,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_CONTEXT_LEN);\n\n\t\t \n\t\tif ((incomplete || context_next) && error)\n\t\t\tgoto read_again;\n\n\t\tif (error || pkt_info->errors) {\n\t\t\tif (pkt_info->errors)\n\t\t\t\tnetif_err(pdata, rx_err, netdev,\n\t\t\t\t\t  \"error in received packet\\n\");\n\t\t\tdev_kfree_skb(skb);\n\t\t\tgoto next_packet;\n\t\t}\n\n\t\tif (!context) {\n\t\t\t \n\t\t\tdma_desc_len = desc_data->rx.len - len;\n\t\t\tlen += dma_desc_len;\n\n\t\t\tif (dma_desc_len && !skb) {\n\t\t\t\tskb = xlgmac_create_skb(pdata, napi, desc_data,\n\t\t\t\t\t\t\tdma_desc_len);\n\t\t\t\tif (!skb)\n\t\t\t\t\terror = 1;\n\t\t\t} else if (dma_desc_len) {\n\t\t\t\tdma_sync_single_range_for_cpu(\n\t\t\t\t\t\tpdata->dev,\n\t\t\t\t\t\tdesc_data->rx.buf.dma_base,\n\t\t\t\t\t\tdesc_data->rx.buf.dma_off,\n\t\t\t\t\t\tdesc_data->rx.buf.dma_len,\n\t\t\t\t\t\tDMA_FROM_DEVICE);\n\n\t\t\t\tskb_add_rx_frag(\n\t\t\t\t\tskb, skb_shinfo(skb)->nr_frags,\n\t\t\t\t\tdesc_data->rx.buf.pa.pages,\n\t\t\t\t\tdesc_data->rx.buf.pa.pages_offset,\n\t\t\t\t\tdma_desc_len,\n\t\t\t\t\tdesc_data->rx.buf.dma_len);\n\t\t\t\tdesc_data->rx.buf.pa.pages = NULL;\n\t\t\t}\n\t\t}\n\n\t\tif (incomplete || context_next)\n\t\t\tgoto read_again;\n\n\t\tif (!skb)\n\t\t\tgoto next_packet;\n\n\t\t \n\t\tmax_len = netdev->mtu + ETH_HLEN;\n\t\tif (!(netdev->features & NETIF_F_HW_VLAN_CTAG_RX) &&\n\t\t    (skb->protocol == htons(ETH_P_8021Q)))\n\t\t\tmax_len += VLAN_HLEN;\n\n\t\tif (skb->len > max_len) {\n\t\t\tnetif_err(pdata, rx_err, netdev,\n\t\t\t\t  \"packet length exceeds configured MTU\\n\");\n\t\t\tdev_kfree_skb(skb);\n\t\t\tgoto next_packet;\n\t\t}\n\n\t\tif (netif_msg_pktdata(pdata))\n\t\t\txlgmac_print_pkt(netdev, skb, false);\n\n\t\tskb_checksum_none_assert(skb);\n\t\tif (XLGMAC_GET_REG_BITS(pkt_info->attributes,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_CSUM_DONE_POS,\n\t\t\t\t    RX_PACKET_ATTRIBUTES_CSUM_DONE_LEN))\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\n\t\tif (XLGMAC_GET_REG_BITS(pkt_info->attributes,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_VLAN_CTAG_POS,\n\t\t\t\t    RX_PACKET_ATTRIBUTES_VLAN_CTAG_LEN)) {\n\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),\n\t\t\t\t\t       pkt_info->vlan_ctag);\n\t\t\tpdata->stats.rx_vlan_packets++;\n\t\t}\n\n\t\tif (XLGMAC_GET_REG_BITS(pkt_info->attributes,\n\t\t\t\t\tRX_PACKET_ATTRIBUTES_RSS_HASH_POS,\n\t\t\t\t    RX_PACKET_ATTRIBUTES_RSS_HASH_LEN))\n\t\t\tskb_set_hash(skb, pkt_info->rss_hash,\n\t\t\t\t     pkt_info->rss_hash_type);\n\n\t\tskb->dev = netdev;\n\t\tskb->protocol = eth_type_trans(skb, netdev);\n\t\tskb_record_rx_queue(skb, channel->queue_index);\n\n\t\tnapi_gro_receive(napi, skb);\n\nnext_packet:\n\t\tpacket_count++;\n\t}\n\n\t \n\tif (received && (incomplete || context_next)) {\n\t\tdesc_data = XLGMAC_GET_DESC_DATA(ring, ring->cur);\n\t\tdesc_data->state_saved = 1;\n\t\tdesc_data->state.skb = skb;\n\t\tdesc_data->state.len = len;\n\t\tdesc_data->state.error = error;\n\t}\n\n\tXLGMAC_PR(\"packet_count = %d\\n\", packet_count);\n\n\treturn packet_count;\n}\n\nstatic int xlgmac_one_poll(struct napi_struct *napi, int budget)\n{\n\tstruct xlgmac_channel *channel = container_of(napi,\n\t\t\t\t\t\tstruct xlgmac_channel,\n\t\t\t\t\t\tnapi);\n\tint processed = 0;\n\n\tXLGMAC_PR(\"budget=%d\\n\", budget);\n\n\t \n\txlgmac_tx_poll(channel);\n\n\t \n\tprocessed = xlgmac_rx_poll(channel, budget);\n\n\t \n\tif (processed < budget) {\n\t\t \n\t\tnapi_complete_done(napi, processed);\n\n\t\t \n\t\tenable_irq(channel->dma_irq);\n\t}\n\n\tXLGMAC_PR(\"received = %d\\n\", processed);\n\n\treturn processed;\n}\n\nstatic int xlgmac_all_poll(struct napi_struct *napi, int budget)\n{\n\tstruct xlgmac_pdata *pdata = container_of(napi,\n\t\t\t\t\t\t   struct xlgmac_pdata,\n\t\t\t\t\t\t   napi);\n\tstruct xlgmac_channel *channel;\n\tint processed, last_processed;\n\tint ring_budget;\n\tunsigned int i;\n\n\tXLGMAC_PR(\"budget=%d\\n\", budget);\n\n\tprocessed = 0;\n\tring_budget = budget / pdata->rx_ring_count;\n\tdo {\n\t\tlast_processed = processed;\n\n\t\tchannel = pdata->channel_head;\n\t\tfor (i = 0; i < pdata->channel_count; i++, channel++) {\n\t\t\t \n\t\t\txlgmac_tx_poll(channel);\n\n\t\t\t \n\t\t\tif (ring_budget > (budget - processed))\n\t\t\t\tring_budget = budget - processed;\n\t\t\tprocessed += xlgmac_rx_poll(channel, ring_budget);\n\t\t}\n\t} while ((processed < budget) && (processed != last_processed));\n\n\t \n\tif (processed < budget) {\n\t\t \n\t\tnapi_complete_done(napi, processed);\n\n\t\t \n\t\txlgmac_enable_rx_tx_ints(pdata);\n\t}\n\n\tXLGMAC_PR(\"received = %d\\n\", processed);\n\n\treturn processed;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}