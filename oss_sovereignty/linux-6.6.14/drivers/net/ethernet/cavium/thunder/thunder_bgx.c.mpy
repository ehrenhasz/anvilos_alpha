{
  "module_name": "thunder_bgx.c",
  "hash_id": "8176256e9b5172b377fd75bb9fc8f5bdfefb5d45f4d9db4735e10d082eba9e07",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/cavium/thunder/thunder_bgx.c",
  "human_readable_source": "\n \n\n#include <linux/acpi.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/phy.h>\n#include <linux/of.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n\n#include \"nic_reg.h\"\n#include \"nic.h\"\n#include \"thunder_bgx.h\"\n\n#define DRV_NAME\t\"thunder_bgx\"\n#define DRV_VERSION\t\"1.0\"\n\n \nenum MCAST_MODE {\n\t\tMCAST_MODE_REJECT = 0x0,\n\t\tMCAST_MODE_ACCEPT = 0x1,\n\t\tMCAST_MODE_CAM_FILTER = 0x2,\n\t\tRSVD = 0x3\n};\n\n#define BCAST_ACCEPT      BIT(0)\n#define CAM_ACCEPT        BIT(3)\n#define MCAST_MODE_MASK   0x3\n#define BGX_MCAST_MODE(x) (x << 1)\n\nstruct dmac_map {\n\tu64                     vf_map;\n\tu64                     dmac;\n};\n\nstruct lmac {\n\tstruct bgx\t\t*bgx;\n\t \n\tu8\t\t\tdmacs_cfg;\n\t \n\tu8                      dmacs_count;\n\tstruct dmac_map         *dmacs;  \n\tu8\t\t\tmac[ETH_ALEN];\n\tu8                      lmac_type;\n\tu8                      lane_to_sds;\n\tbool                    use_training;\n\tbool                    autoneg;\n\tbool\t\t\tlink_up;\n\tint\t\t\tlmacid;  \n\tint\t\t\tlmacid_bd;  \n\tstruct net_device       netdev;\n\tstruct phy_device       *phydev;\n\tunsigned int            last_duplex;\n\tunsigned int            last_link;\n\tunsigned int            last_speed;\n\tbool\t\t\tis_sgmii;\n\tstruct delayed_work\tdwork;\n\tstruct workqueue_struct *check_link;\n};\n\nstruct bgx {\n\tu8\t\t\tbgx_id;\n\tstruct\tlmac\t\tlmac[MAX_LMAC_PER_BGX];\n\tu8\t\t\tlmac_count;\n\tu8\t\t\tmax_lmac;\n\tu8                      acpi_lmac_idx;\n\tvoid __iomem\t\t*reg_base;\n\tstruct pci_dev\t\t*pdev;\n\tbool                    is_dlm;\n\tbool                    is_rgx;\n};\n\nstatic struct bgx *bgx_vnic[MAX_BGX_THUNDER];\nstatic int lmac_count;  \n\nstatic int bgx_xaui_check_link(struct lmac *lmac);\n\n \nstatic const struct pci_device_id bgx_id_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVICE_ID_THUNDER_BGX) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVICE_ID_THUNDER_RGX) },\n\t{ 0, }   \n};\n\nMODULE_AUTHOR(\"Cavium Inc\");\nMODULE_DESCRIPTION(\"Cavium Thunder BGX/MAC Driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_VERSION(DRV_VERSION);\nMODULE_DEVICE_TABLE(pci, bgx_id_table);\n\n \n\n \nstatic u64 bgx_reg_read(struct bgx *bgx, u8 lmac, u64 offset)\n{\n\tvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\n\n\treturn readq_relaxed(addr);\n}\n\nstatic void bgx_reg_write(struct bgx *bgx, u8 lmac, u64 offset, u64 val)\n{\n\tvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\n\n\twriteq_relaxed(val, addr);\n}\n\nstatic void bgx_reg_modify(struct bgx *bgx, u8 lmac, u64 offset, u64 val)\n{\n\tvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\n\n\twriteq_relaxed(val | readq_relaxed(addr), addr);\n}\n\nstatic int bgx_poll_reg(struct bgx *bgx, u8 lmac, u64 reg, u64 mask, bool zero)\n{\n\tint timeout = 100;\n\tu64 reg_val;\n\n\twhile (timeout) {\n\t\treg_val = bgx_reg_read(bgx, lmac, reg);\n\t\tif (zero && !(reg_val & mask))\n\t\t\treturn 0;\n\t\tif (!zero && (reg_val & mask))\n\t\t\treturn 0;\n\t\tusleep_range(1000, 2000);\n\t\ttimeout--;\n\t}\n\treturn 1;\n}\n\nstatic int max_bgx_per_node;\nstatic void set_max_bgx_per_node(struct pci_dev *pdev)\n{\n\tu16 sdevid;\n\n\tif (max_bgx_per_node)\n\t\treturn;\n\n\tpci_read_config_word(pdev, PCI_SUBSYSTEM_ID, &sdevid);\n\tswitch (sdevid) {\n\tcase PCI_SUBSYS_DEVID_81XX_BGX:\n\tcase PCI_SUBSYS_DEVID_81XX_RGX:\n\t\tmax_bgx_per_node = MAX_BGX_PER_CN81XX;\n\t\tbreak;\n\tcase PCI_SUBSYS_DEVID_83XX_BGX:\n\t\tmax_bgx_per_node = MAX_BGX_PER_CN83XX;\n\t\tbreak;\n\tcase PCI_SUBSYS_DEVID_88XX_BGX:\n\tdefault:\n\t\tmax_bgx_per_node = MAX_BGX_PER_CN88XX;\n\t\tbreak;\n\t}\n}\n\nstatic struct bgx *get_bgx(int node, int bgx_idx)\n{\n\tint idx = (node * max_bgx_per_node) + bgx_idx;\n\n\treturn bgx_vnic[idx];\n}\n\n \nunsigned bgx_get_map(int node)\n{\n\tint i;\n\tunsigned map = 0;\n\n\tfor (i = 0; i < max_bgx_per_node; i++) {\n\t\tif (bgx_vnic[(node * max_bgx_per_node) + i])\n\t\t\tmap |= (1 << i);\n\t}\n\n\treturn map;\n}\nEXPORT_SYMBOL(bgx_get_map);\n\n \nint bgx_get_lmac_count(int node, int bgx_idx)\n{\n\tstruct bgx *bgx;\n\n\tbgx = get_bgx(node, bgx_idx);\n\tif (bgx)\n\t\treturn bgx->lmac_count;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(bgx_get_lmac_count);\n\n \nvoid bgx_get_lmac_link_state(int node, int bgx_idx, int lmacid, void *status)\n{\n\tstruct bgx_link_status *link = (struct bgx_link_status *)status;\n\tstruct bgx *bgx;\n\tstruct lmac *lmac;\n\n\tbgx = get_bgx(node, bgx_idx);\n\tif (!bgx)\n\t\treturn;\n\n\tlmac = &bgx->lmac[lmacid];\n\tlink->mac_type = lmac->lmac_type;\n\tlink->link_up = lmac->link_up;\n\tlink->duplex = lmac->last_duplex;\n\tlink->speed = lmac->last_speed;\n}\nEXPORT_SYMBOL(bgx_get_lmac_link_state);\n\nconst u8 *bgx_get_lmac_mac(int node, int bgx_idx, int lmacid)\n{\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\n\tif (bgx)\n\t\treturn bgx->lmac[lmacid].mac;\n\n\treturn NULL;\n}\nEXPORT_SYMBOL(bgx_get_lmac_mac);\n\nvoid bgx_set_lmac_mac(int node, int bgx_idx, int lmacid, const u8 *mac)\n{\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\n\tif (!bgx)\n\t\treturn;\n\n\tether_addr_copy(bgx->lmac[lmacid].mac, mac);\n}\nEXPORT_SYMBOL(bgx_set_lmac_mac);\n\nstatic void bgx_flush_dmac_cam_filter(struct bgx *bgx, int lmacid)\n{\n\tstruct lmac *lmac = NULL;\n\tu8  idx = 0;\n\n\tlmac = &bgx->lmac[lmacid];\n\t \n\tfor (idx = 0; idx < lmac->dmacs_count; idx++)\n\t\tbgx_reg_write(bgx, 0, BGX_CMR_RX_DMACX_CAM +\n\t\t\t      ((lmacid * lmac->dmacs_count) + idx) *\n\t\t\t      sizeof(u64), 0);\n}\n\nstatic void bgx_lmac_remove_filters(struct lmac *lmac, u8 vf_id)\n{\n\tint i = 0;\n\n\tif (!lmac)\n\t\treturn;\n\n\t \n\tfor (i = lmac->dmacs_cfg - 1; i >= 0; i--) {\n\t\tlmac->dmacs[i].vf_map &= ~BIT_ULL(vf_id);\n\t\tif (!lmac->dmacs[i].vf_map) {\n\t\t\tlmac->dmacs_cfg--;\n\t\t\tlmac->dmacs[i].dmac = 0;\n\t\t\tlmac->dmacs[i].vf_map = 0;\n\t\t}\n\t}\n}\n\nstatic int bgx_lmac_save_filter(struct lmac *lmac, u64 dmac, u8 vf_id)\n{\n\tu8 i = 0;\n\n\tif (!lmac)\n\t\treturn -1;\n\n\t \n\tfor (i = 0; i < lmac->dmacs_cfg; i++) {\n\t\tif (lmac->dmacs[i].dmac == dmac) {\n\t\t\tlmac->dmacs[i].vf_map |= BIT_ULL(vf_id);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (!(lmac->dmacs_cfg < lmac->dmacs_count))\n\t\treturn -1;\n\n\t \n\tlmac->dmacs[lmac->dmacs_cfg].dmac = dmac;\n\tlmac->dmacs[lmac->dmacs_cfg].vf_map = BIT_ULL(vf_id);\n\tlmac->dmacs_cfg++;\n\treturn 0;\n}\n\nstatic int bgx_set_dmac_cam_filter_mac(struct bgx *bgx, int lmacid,\n\t\t\t\t       u64 cam_dmac, u8 idx)\n{\n\tstruct lmac *lmac = NULL;\n\tu64 cfg = 0;\n\n\t \n\tif (!cam_dmac || !bgx)\n\t\treturn -1;\n\n\tlmac = &bgx->lmac[lmacid];\n\n\t \n\tcfg = RX_DMACX_CAM_LMACID(lmacid & LMAC_ID_MASK) |\n\t\tRX_DMACX_CAM_EN | cam_dmac;\n\tbgx_reg_write(bgx, 0, BGX_CMR_RX_DMACX_CAM +\n\t\t      ((lmacid * lmac->dmacs_count) + idx) * sizeof(u64), cfg);\n\treturn 0;\n}\n\nvoid bgx_set_dmac_cam_filter(int node, int bgx_idx, int lmacid,\n\t\t\t     u64 cam_dmac, u8 vf_id)\n{\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\tstruct lmac *lmac = NULL;\n\n\tif (!bgx)\n\t\treturn;\n\n\tlmac = &bgx->lmac[lmacid];\n\n\tif (!cam_dmac)\n\t\tcam_dmac = ether_addr_to_u64(lmac->mac);\n\n\t \n\tbgx_lmac_save_filter(lmac, cam_dmac, vf_id);\n}\nEXPORT_SYMBOL(bgx_set_dmac_cam_filter);\n\nvoid bgx_set_xcast_mode(int node, int bgx_idx, int lmacid, u8 mode)\n{\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\tstruct lmac *lmac = NULL;\n\tu64 cfg = 0;\n\tu8 i = 0;\n\n\tif (!bgx)\n\t\treturn;\n\n\tlmac = &bgx->lmac[lmacid];\n\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_RX_DMAC_CTL);\n\tif (mode & BGX_XCAST_BCAST_ACCEPT)\n\t\tcfg |= BCAST_ACCEPT;\n\telse\n\t\tcfg &= ~BCAST_ACCEPT;\n\n\t \n\tcfg &= ~(CAM_ACCEPT | BGX_MCAST_MODE(MCAST_MODE_MASK));\n\n\t \n\tif (mode & (BGX_XCAST_MCAST_ACCEPT)) {\n\t\tcfg |= (BGX_MCAST_MODE(MCAST_MODE_ACCEPT));\n\t} else if (mode & BGX_XCAST_MCAST_FILTER) {\n\t\tcfg |= (BGX_MCAST_MODE(MCAST_MODE_CAM_FILTER) | CAM_ACCEPT);\n\t\tfor (i = 0; i < lmac->dmacs_cfg; i++)\n\t\t\tbgx_set_dmac_cam_filter_mac(bgx, lmacid,\n\t\t\t\t\t\t    lmac->dmacs[i].dmac, i);\n\t}\n\tbgx_reg_write(bgx, lmacid, BGX_CMRX_RX_DMAC_CTL, cfg);\n}\nEXPORT_SYMBOL(bgx_set_xcast_mode);\n\nvoid bgx_reset_xcast_mode(int node, int bgx_idx, int lmacid, u8 vf_id)\n{\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\n\tif (!bgx)\n\t\treturn;\n\n\tbgx_lmac_remove_filters(&bgx->lmac[lmacid], vf_id);\n\tbgx_flush_dmac_cam_filter(bgx, lmacid);\n\tbgx_set_xcast_mode(node, bgx_idx, lmacid,\n\t\t\t   (BGX_XCAST_BCAST_ACCEPT | BGX_XCAST_MCAST_ACCEPT));\n}\nEXPORT_SYMBOL(bgx_reset_xcast_mode);\n\nvoid bgx_lmac_rx_tx_enable(int node, int bgx_idx, int lmacid, bool enable)\n{\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\tstruct lmac *lmac;\n\tu64 cfg;\n\n\tif (!bgx)\n\t\treturn;\n\tlmac = &bgx->lmac[lmacid];\n\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\n\tif (enable) {\n\t\tcfg |= CMR_PKT_RX_EN | CMR_PKT_TX_EN;\n\n\t\t \n\t\tbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_INT_ENA_W1S,\n\t\t\t       GMI_TXX_INT_UNDFLW);\n\t} else {\n\t\tcfg &= ~(CMR_PKT_RX_EN | CMR_PKT_TX_EN);\n\n\t\t \n\t\tbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_INT_ENA_W1C,\n\t\t\t       GMI_TXX_INT_UNDFLW);\n\t}\n\tbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\n\n\tif (bgx->is_rgx)\n\t\txcv_setup_link(enable ? lmac->link_up : 0, lmac->last_speed);\n}\nEXPORT_SYMBOL(bgx_lmac_rx_tx_enable);\n\n \nvoid bgx_config_timestamping(int node, int bgx_idx, int lmacid, bool enable)\n{\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\tstruct lmac *lmac;\n\tu64 csr_offset, cfg;\n\n\tif (!bgx)\n\t\treturn;\n\n\tlmac = &bgx->lmac[lmacid];\n\n\tif (lmac->lmac_type == BGX_MODE_SGMII ||\n\t    lmac->lmac_type == BGX_MODE_QSGMII ||\n\t    lmac->lmac_type == BGX_MODE_RGMII)\n\t\tcsr_offset = BGX_GMP_GMI_RXX_FRM_CTL;\n\telse\n\t\tcsr_offset = BGX_SMUX_RX_FRM_CTL;\n\n\tcfg = bgx_reg_read(bgx, lmacid, csr_offset);\n\n\tif (enable)\n\t\tcfg |= BGX_PKT_RX_PTP_EN;\n\telse\n\t\tcfg &= ~BGX_PKT_RX_PTP_EN;\n\tbgx_reg_write(bgx, lmacid, csr_offset, cfg);\n}\nEXPORT_SYMBOL(bgx_config_timestamping);\n\nvoid bgx_lmac_get_pfc(int node, int bgx_idx, int lmacid, void *pause)\n{\n\tstruct pfc *pfc = (struct pfc *)pause;\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\tstruct lmac *lmac;\n\tu64 cfg;\n\n\tif (!bgx)\n\t\treturn;\n\tlmac = &bgx->lmac[lmacid];\n\tif (lmac->is_sgmii)\n\t\treturn;\n\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_CBFC_CTL);\n\tpfc->fc_rx = cfg & RX_EN;\n\tpfc->fc_tx = cfg & TX_EN;\n\tpfc->autoneg = 0;\n}\nEXPORT_SYMBOL(bgx_lmac_get_pfc);\n\nvoid bgx_lmac_set_pfc(int node, int bgx_idx, int lmacid, void *pause)\n{\n\tstruct pfc *pfc = (struct pfc *)pause;\n\tstruct bgx *bgx = get_bgx(node, bgx_idx);\n\tstruct lmac *lmac;\n\tu64 cfg;\n\n\tif (!bgx)\n\t\treturn;\n\tlmac = &bgx->lmac[lmacid];\n\tif (lmac->is_sgmii)\n\t\treturn;\n\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_CBFC_CTL);\n\tcfg &= ~(RX_EN | TX_EN);\n\tcfg |= (pfc->fc_rx ? RX_EN : 0x00);\n\tcfg |= (pfc->fc_tx ? TX_EN : 0x00);\n\tbgx_reg_write(bgx, lmacid, BGX_SMUX_CBFC_CTL, cfg);\n}\nEXPORT_SYMBOL(bgx_lmac_set_pfc);\n\nstatic void bgx_sgmii_change_link_state(struct lmac *lmac)\n{\n\tstruct bgx *bgx = lmac->bgx;\n\tu64 cmr_cfg;\n\tu64 port_cfg = 0;\n\tu64 misc_ctl = 0;\n\tbool tx_en, rx_en;\n\n\tcmr_cfg = bgx_reg_read(bgx, lmac->lmacid, BGX_CMRX_CFG);\n\ttx_en = cmr_cfg & CMR_PKT_TX_EN;\n\trx_en = cmr_cfg & CMR_PKT_RX_EN;\n\tcmr_cfg &= ~(CMR_PKT_RX_EN | CMR_PKT_TX_EN);\n\tbgx_reg_write(bgx, lmac->lmacid, BGX_CMRX_CFG, cmr_cfg);\n\n\t \n\tif (bgx_poll_reg(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG,\n\t\t\t GMI_PORT_CFG_RX_IDLE, false)) {\n\t\tdev_err(&bgx->pdev->dev, \"BGX%d LMAC%d GMI RX not idle\\n\",\n\t\t\tbgx->bgx_id, lmac->lmacid);\n\t\treturn;\n\t}\n\n\t \n\tif (bgx_poll_reg(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG,\n\t\t\t GMI_PORT_CFG_TX_IDLE, false)) {\n\t\tdev_err(&bgx->pdev->dev, \"BGX%d LMAC%d GMI TX not idle\\n\",\n\t\t\tbgx->bgx_id, lmac->lmacid);\n\t\treturn;\n\t}\n\n\tport_cfg = bgx_reg_read(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG);\n\tmisc_ctl = bgx_reg_read(bgx, lmac->lmacid, BGX_GMP_PCS_MISCX_CTL);\n\n\tif (lmac->link_up) {\n\t\tmisc_ctl &= ~PCS_MISC_CTL_GMX_ENO;\n\t\tport_cfg &= ~GMI_PORT_CFG_DUPLEX;\n\t\tport_cfg |=  (lmac->last_duplex << 2);\n\t} else {\n\t\tmisc_ctl |= PCS_MISC_CTL_GMX_ENO;\n\t}\n\n\tswitch (lmac->last_speed) {\n\tcase 10:\n\t\tport_cfg &= ~GMI_PORT_CFG_SPEED;  \n\t\tport_cfg |= GMI_PORT_CFG_SPEED_MSB;   \n\t\tport_cfg &= ~GMI_PORT_CFG_SLOT_TIME;  \n\t\tmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\n\t\tmisc_ctl |= 50;  \n\t\tbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 64);\n\t\tbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_BURST, 0);\n\t\tbreak;\n\tcase 100:\n\t\tport_cfg &= ~GMI_PORT_CFG_SPEED;  \n\t\tport_cfg &= ~GMI_PORT_CFG_SPEED_MSB;  \n\t\tport_cfg &= ~GMI_PORT_CFG_SLOT_TIME;  \n\t\tmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\n\t\tmisc_ctl |= 5;  \n\t\tbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 64);\n\t\tbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_BURST, 0);\n\t\tbreak;\n\tcase 1000:\n\t\tport_cfg |= GMI_PORT_CFG_SPEED;  \n\t\tport_cfg &= ~GMI_PORT_CFG_SPEED_MSB;  \n\t\tport_cfg |= GMI_PORT_CFG_SLOT_TIME;  \n\t\tmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\n\t\tmisc_ctl |= 1;  \n\t\tbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 512);\n\t\tif (lmac->last_duplex)\n\t\t\tbgx_reg_write(bgx, lmac->lmacid,\n\t\t\t\t      BGX_GMP_GMI_TXX_BURST, 0);\n\t\telse\n\t\t\tbgx_reg_write(bgx, lmac->lmacid,\n\t\t\t\t      BGX_GMP_GMI_TXX_BURST, 8192);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\tbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_PCS_MISCX_CTL, misc_ctl);\n\tbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG, port_cfg);\n\n\t \n\tcmr_cfg |= (rx_en ? CMR_PKT_RX_EN : 0) | (tx_en ? CMR_PKT_TX_EN : 0);\n\tbgx_reg_write(bgx, lmac->lmacid, BGX_CMRX_CFG, cmr_cfg);\n\n\tif (bgx->is_rgx && (cmr_cfg & (CMR_PKT_RX_EN | CMR_PKT_TX_EN)))\n\t\txcv_setup_link(lmac->link_up, lmac->last_speed);\n}\n\nstatic void bgx_lmac_handler(struct net_device *netdev)\n{\n\tstruct lmac *lmac = container_of(netdev, struct lmac, netdev);\n\tstruct phy_device *phydev;\n\tint link_changed = 0;\n\n\tphydev = lmac->phydev;\n\n\tif (!phydev->link && lmac->last_link)\n\t\tlink_changed = -1;\n\n\tif (phydev->link &&\n\t    (lmac->last_duplex != phydev->duplex ||\n\t     lmac->last_link != phydev->link ||\n\t     lmac->last_speed != phydev->speed)) {\n\t\t\tlink_changed = 1;\n\t}\n\n\tlmac->last_link = phydev->link;\n\tlmac->last_speed = phydev->speed;\n\tlmac->last_duplex = phydev->duplex;\n\n\tif (!link_changed)\n\t\treturn;\n\n\tif (link_changed > 0)\n\t\tlmac->link_up = true;\n\telse\n\t\tlmac->link_up = false;\n\n\tif (lmac->is_sgmii)\n\t\tbgx_sgmii_change_link_state(lmac);\n\telse\n\t\tbgx_xaui_check_link(lmac);\n}\n\nu64 bgx_get_rx_stats(int node, int bgx_idx, int lmac, int idx)\n{\n\tstruct bgx *bgx;\n\n\tbgx = get_bgx(node, bgx_idx);\n\tif (!bgx)\n\t\treturn 0;\n\n\tif (idx > 8)\n\t\tlmac = 0;\n\treturn bgx_reg_read(bgx, lmac, BGX_CMRX_RX_STAT0 + (idx * 8));\n}\nEXPORT_SYMBOL(bgx_get_rx_stats);\n\nu64 bgx_get_tx_stats(int node, int bgx_idx, int lmac, int idx)\n{\n\tstruct bgx *bgx;\n\n\tbgx = get_bgx(node, bgx_idx);\n\tif (!bgx)\n\t\treturn 0;\n\n\treturn bgx_reg_read(bgx, lmac, BGX_CMRX_TX_STAT0 + (idx * 8));\n}\nEXPORT_SYMBOL(bgx_get_tx_stats);\n\n \nvoid bgx_lmac_internal_loopback(int node, int bgx_idx,\n\t\t\t\tint lmac_idx, bool enable)\n{\n\tstruct bgx *bgx;\n\tstruct lmac *lmac;\n\tu64    cfg;\n\n\tbgx = get_bgx(node, bgx_idx);\n\tif (!bgx)\n\t\treturn;\n\n\tlmac = &bgx->lmac[lmac_idx];\n\tif (lmac->is_sgmii) {\n\t\tcfg = bgx_reg_read(bgx, lmac_idx, BGX_GMP_PCS_MRX_CTL);\n\t\tif (enable)\n\t\t\tcfg |= PCS_MRX_CTL_LOOPBACK1;\n\t\telse\n\t\t\tcfg &= ~PCS_MRX_CTL_LOOPBACK1;\n\t\tbgx_reg_write(bgx, lmac_idx, BGX_GMP_PCS_MRX_CTL, cfg);\n\t} else {\n\t\tcfg = bgx_reg_read(bgx, lmac_idx, BGX_SPUX_CONTROL1);\n\t\tif (enable)\n\t\t\tcfg |= SPU_CTL_LOOPBACK;\n\t\telse\n\t\t\tcfg &= ~SPU_CTL_LOOPBACK;\n\t\tbgx_reg_write(bgx, lmac_idx, BGX_SPUX_CONTROL1, cfg);\n\t}\n}\nEXPORT_SYMBOL(bgx_lmac_internal_loopback);\n\nstatic int bgx_lmac_sgmii_init(struct bgx *bgx, struct lmac *lmac)\n{\n\tint lmacid = lmac->lmacid;\n\tu64 cfg;\n\n\tbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_THRESH, 0x30);\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_RXX_JABBER, MAX_FRAME_SIZE);\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND);\n\tif (cfg & 1)\n\t\tbgx_reg_write(bgx, lmacid, BGX_GMP_GMI_TXX_SGMII_CTL, 0);\n\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\n\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_GMP_PCS_MRX_CTL, PCS_MRX_CTL_RESET);\n\tif (bgx_poll_reg(bgx, lmacid, BGX_GMP_PCS_MRX_CTL,\n\t\t\t PCS_MRX_CTL_RESET, true)) {\n\t\tdev_err(&bgx->pdev->dev, \"BGX PCS reset not completed\\n\");\n\t\treturn -1;\n\t}\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_GMP_PCS_MRX_CTL);\n\tcfg &= ~PCS_MRX_CTL_PWR_DN;\n\tcfg |= PCS_MRX_CTL_RST_AN;\n\tif (lmac->phydev) {\n\t\tcfg |= PCS_MRX_CTL_AN_EN;\n\t} else {\n\t\t \n\t\tif (cfg & PCS_MRX_CTL_AN_EN)\n\t\t\tlmac->autoneg = true;\n\t}\n\tbgx_reg_write(bgx, lmacid, BGX_GMP_PCS_MRX_CTL, cfg);\n\n\tif (lmac->lmac_type == BGX_MODE_QSGMII) {\n\t\t \n\t\tcfg = bgx_reg_read(bgx, lmacid, BGX_GMP_PCS_MISCX_CTL);\n\t\tcfg &= ~PCS_MISC_CTL_DISP_EN;\n\t\tbgx_reg_write(bgx, lmacid, BGX_GMP_PCS_MISCX_CTL, cfg);\n\t\treturn 0;\n\t}\n\n\tif ((lmac->lmac_type == BGX_MODE_SGMII) && lmac->phydev) {\n\t\tif (bgx_poll_reg(bgx, lmacid, BGX_GMP_PCS_MRX_STATUS,\n\t\t\t\t PCS_MRX_STATUS_AN_CPT, false)) {\n\t\t\tdev_err(&bgx->pdev->dev, \"BGX AN_CPT not completed\\n\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int bgx_lmac_xaui_init(struct bgx *bgx, struct lmac *lmac)\n{\n\tu64 cfg;\n\tint lmacid = lmac->lmacid;\n\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET);\n\tif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET, true)) {\n\t\tdev_err(&bgx->pdev->dev, \"BGX SPU reset not completed\\n\");\n\t\treturn -1;\n\t}\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\n\tcfg &= ~CMR_EN;\n\tbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\n\n\tbgx_reg_modify(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_LOW_POWER);\n\t \n\tif (lmac->lmac_type == BGX_MODE_RXAUI)\n\t\tbgx_reg_modify(bgx, lmacid, BGX_SPUX_MISC_CONTROL,\n\t\t\t       SPU_MISC_CTL_INTLV_RDISP);\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_MISC_CONTROL);\n\tcfg &= ~SPU_MISC_CTL_RX_DIS;\n\tbgx_reg_write(bgx, lmacid, BGX_SPUX_MISC_CONTROL, cfg);\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_RX_INT);\n\tbgx_reg_write(bgx, lmacid, BGX_SMUX_RX_INT, cfg);\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_INT);\n\tbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_INT, cfg);\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\n\tbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\n\n\tif (lmac->use_training) {\n\t\tbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LP_CUP, 0x00);\n\t\tbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LD_CUP, 0x00);\n\t\tbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LD_REP, 0x00);\n\t\t \n\t\tbgx_reg_modify(bgx, lmacid,\n\t\t\t       BGX_SPUX_BR_PMD_CRTL, SPU_PMD_CRTL_TRAIN_EN);\n\t}\n\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_APPEND, SMU_TX_APPEND_FCS_D);\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_FEC_CONTROL);\n\tcfg &= ~SPU_FEC_CTL_FEC_EN;\n\tbgx_reg_write(bgx, lmacid, BGX_SPUX_FEC_CONTROL, cfg);\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_AN_CONTROL);\n\tcfg = cfg & ~(SPU_AN_CTL_AN_EN | SPU_AN_CTL_XNP_EN);\n\tbgx_reg_write(bgx, lmacid, BGX_SPUX_AN_CONTROL, cfg);\n\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_AN_ADV);\n\tif (lmac->lmac_type == BGX_MODE_10G_KR)\n\t\tcfg |= (1 << 23);\n\telse if (lmac->lmac_type == BGX_MODE_40G_KR)\n\t\tcfg |= (1 << 24);\n\telse\n\t\tcfg &= ~((1 << 23) | (1 << 24));\n\tcfg = cfg & (~((1ULL << 25) | (1ULL << 22) | (1ULL << 12)));\n\tbgx_reg_write(bgx, lmacid, BGX_SPUX_AN_ADV, cfg);\n\n\tcfg = bgx_reg_read(bgx, 0, BGX_SPU_DBG_CONTROL);\n\tcfg &= ~SPU_DBG_CTL_AN_ARB_LINK_CHK_EN;\n\tbgx_reg_write(bgx, 0, BGX_SPU_DBG_CONTROL, cfg);\n\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\n\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_CONTROL1);\n\tcfg &= ~SPU_CTL_LOW_POWER;\n\tbgx_reg_write(bgx, lmacid, BGX_SPUX_CONTROL1, cfg);\n\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_CTL);\n\tcfg &= ~SMU_TX_CTL_UNI_EN;\n\tcfg |= SMU_TX_CTL_DIC_EN;\n\tbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_CTL, cfg);\n\n\t \n\tbgx_reg_write(bgx, lmacid, BGX_SMUX_CBFC_CTL, ((0xffffULL << 32) |\n\t\t      BCK_EN | DRP_EN | TX_EN | RX_EN));\n\t \n\tbgx_reg_write(bgx, lmacid,\n\t\t      BGX_SMUX_TX_PAUSE_PKT_TIME, DEFAULT_PAUSE_TIME);\n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_PAUSE_PKT_INTERVAL);\n\tcfg &= ~0xFFFFull;\n\tbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_PAUSE_PKT_INTERVAL,\n\t\t      cfg | (DEFAULT_PAUSE_TIME - 0x1000));\n\tbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_PAUSE_ZERO, 0x01);\n\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_THRESH, (0x100 - 1));\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_SMUX_RX_JABBER, MAX_FRAME_SIZE);\n\n\treturn 0;\n}\n\nstatic int bgx_xaui_check_link(struct lmac *lmac)\n{\n\tstruct bgx *bgx = lmac->bgx;\n\tint lmacid = lmac->lmacid;\n\tint lmac_type = lmac->lmac_type;\n\tu64 cfg;\n\n\tif (lmac->use_training) {\n\t\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\n\t\tif (!(cfg & (1ull << 13))) {\n\t\t\tcfg = (1ull << 13) | (1ull << 14);\n\t\t\tbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\n\t\t\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL);\n\t\t\tcfg |= (1ull << 0);\n\t\t\tbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL, cfg);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t \n\tif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET, true)) {\n\t\tdev_err(&bgx->pdev->dev, \"BGX SPU reset not completed\\n\");\n\t\treturn -1;\n\t}\n\n\tif ((lmac_type == BGX_MODE_10G_KR) || (lmac_type == BGX_MODE_XFI) ||\n\t    (lmac_type == BGX_MODE_40G_KR) || (lmac_type == BGX_MODE_XLAUI)) {\n\t\tif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_BR_STATUS1,\n\t\t\t\t SPU_BR_STATUS_BLK_LOCK, false)) {\n\t\t\tdev_err(&bgx->pdev->dev,\n\t\t\t\t\"SPU_BR_STATUS_BLK_LOCK not completed\\n\");\n\t\t\treturn -1;\n\t\t}\n\t} else {\n\t\tif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_BX_STATUS,\n\t\t\t\t SPU_BX_STATUS_RX_ALIGN, false)) {\n\t\t\tdev_err(&bgx->pdev->dev,\n\t\t\t\t\"SPU_BX_STATUS_RX_ALIGN not completed\\n\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t \n\tif (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) & SPU_STATUS2_RCVFLT)\n\t\tbgx_reg_modify(bgx, lmacid,\n\t\t\t       BGX_SPUX_STATUS2, SPU_STATUS2_RCVFLT);\n\tif (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) & SPU_STATUS2_RCVFLT) {\n\t\tdev_err(&bgx->pdev->dev, \"Receive fault, retry training\\n\");\n\t\tif (lmac->use_training) {\n\t\t\tcfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\n\t\t\tif (!(cfg & (1ull << 13))) {\n\t\t\t\tcfg = (1ull << 13) | (1ull << 14);\n\t\t\t\tbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\n\t\t\t\tcfg = bgx_reg_read(bgx, lmacid,\n\t\t\t\t\t\t   BGX_SPUX_BR_PMD_CRTL);\n\t\t\t\tcfg |= (1ull << 0);\n\t\t\t\tbgx_reg_write(bgx, lmacid,\n\t\t\t\t\t      BGX_SPUX_BR_PMD_CRTL, cfg);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\treturn -1;\n\t}\n\n\t \n\tif (bgx_poll_reg(bgx, lmacid, BGX_SMUX_CTL, SMU_CTL_RX_IDLE, false)) {\n\t\tdev_err(&bgx->pdev->dev, \"SMU RX not idle\\n\");\n\t\treturn -1;\n\t}\n\n\t \n\tif (bgx_poll_reg(bgx, lmacid, BGX_SMUX_CTL, SMU_CTL_TX_IDLE, false)) {\n\t\tdev_err(&bgx->pdev->dev, \"SMU TX not idle\\n\");\n\t\treturn -1;\n\t}\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_RX_CTL);\n\t \n\tcfg &= SMU_RX_CTL_STATUS;\n\tif (!cfg)\n\t\treturn 0;\n\n\t \n\tbgx_lmac_xaui_init(bgx, lmac);\n\n\treturn -1;\n}\n\nstatic void bgx_poll_for_sgmii_link(struct lmac *lmac)\n{\n\tu64 pcs_link, an_result;\n\tu8 speed;\n\n\tpcs_link = bgx_reg_read(lmac->bgx, lmac->lmacid,\n\t\t\t\tBGX_GMP_PCS_MRX_STATUS);\n\n\t \n\tif (!(pcs_link & PCS_MRX_STATUS_LINK))\n\t\tpcs_link = bgx_reg_read(lmac->bgx, lmac->lmacid,\n\t\t\t\t\tBGX_GMP_PCS_MRX_STATUS);\n\n\tif (bgx_poll_reg(lmac->bgx, lmac->lmacid, BGX_GMP_PCS_MRX_STATUS,\n\t\t\t PCS_MRX_STATUS_AN_CPT, false)) {\n\t\tlmac->link_up = false;\n\t\tlmac->last_speed = SPEED_UNKNOWN;\n\t\tlmac->last_duplex = DUPLEX_UNKNOWN;\n\t\tgoto next_poll;\n\t}\n\n\tlmac->link_up = ((pcs_link & PCS_MRX_STATUS_LINK) != 0) ? true : false;\n\tan_result = bgx_reg_read(lmac->bgx, lmac->lmacid,\n\t\t\t\t BGX_GMP_PCS_ANX_AN_RESULTS);\n\n\tspeed = (an_result >> 3) & 0x3;\n\tlmac->last_duplex = (an_result >> 1) & 0x1;\n\tswitch (speed) {\n\tcase 0:\n\t\tlmac->last_speed = SPEED_10;\n\t\tbreak;\n\tcase 1:\n\t\tlmac->last_speed = SPEED_100;\n\t\tbreak;\n\tcase 2:\n\t\tlmac->last_speed = SPEED_1000;\n\t\tbreak;\n\tdefault:\n\t\tlmac->link_up = false;\n\t\tlmac->last_speed = SPEED_UNKNOWN;\n\t\tlmac->last_duplex = DUPLEX_UNKNOWN;\n\t\tbreak;\n\t}\n\nnext_poll:\n\n\tif (lmac->last_link != lmac->link_up) {\n\t\tif (lmac->link_up)\n\t\t\tbgx_sgmii_change_link_state(lmac);\n\t\tlmac->last_link = lmac->link_up;\n\t}\n\n\tqueue_delayed_work(lmac->check_link, &lmac->dwork, HZ * 3);\n}\n\nstatic void bgx_poll_for_link(struct work_struct *work)\n{\n\tstruct lmac *lmac;\n\tu64 spu_link, smu_link;\n\n\tlmac = container_of(work, struct lmac, dwork.work);\n\tif (lmac->is_sgmii) {\n\t\tbgx_poll_for_sgmii_link(lmac);\n\t\treturn;\n\t}\n\n\t \n\tbgx_reg_modify(lmac->bgx, lmac->lmacid,\n\t\t       BGX_SPUX_STATUS1, SPU_STATUS1_RCV_LNK);\n\tbgx_poll_reg(lmac->bgx, lmac->lmacid, BGX_SPUX_STATUS1,\n\t\t     SPU_STATUS1_RCV_LNK, false);\n\n\tspu_link = bgx_reg_read(lmac->bgx, lmac->lmacid, BGX_SPUX_STATUS1);\n\tsmu_link = bgx_reg_read(lmac->bgx, lmac->lmacid, BGX_SMUX_RX_CTL);\n\n\tif ((spu_link & SPU_STATUS1_RCV_LNK) &&\n\t    !(smu_link & SMU_RX_CTL_STATUS)) {\n\t\tlmac->link_up = true;\n\t\tif (lmac->lmac_type == BGX_MODE_XLAUI)\n\t\t\tlmac->last_speed = SPEED_40000;\n\t\telse\n\t\t\tlmac->last_speed = SPEED_10000;\n\t\tlmac->last_duplex = DUPLEX_FULL;\n\t} else {\n\t\tlmac->link_up = false;\n\t\tlmac->last_speed = SPEED_UNKNOWN;\n\t\tlmac->last_duplex = DUPLEX_UNKNOWN;\n\t}\n\n\tif (lmac->last_link != lmac->link_up) {\n\t\tif (lmac->link_up) {\n\t\t\tif (bgx_xaui_check_link(lmac)) {\n\t\t\t\t \n\t\t\t\tlmac->link_up = false;\n\t\t\t\tlmac->last_speed = SPEED_UNKNOWN;\n\t\t\t\tlmac->last_duplex = DUPLEX_UNKNOWN;\n\t\t\t}\n\t\t}\n\t\tlmac->last_link = lmac->link_up;\n\t}\n\n\tqueue_delayed_work(lmac->check_link, &lmac->dwork, HZ * 2);\n}\n\nstatic int phy_interface_mode(u8 lmac_type)\n{\n\tif (lmac_type == BGX_MODE_QSGMII)\n\t\treturn PHY_INTERFACE_MODE_QSGMII;\n\tif (lmac_type == BGX_MODE_RGMII)\n\t\treturn PHY_INTERFACE_MODE_RGMII_RXID;\n\n\treturn PHY_INTERFACE_MODE_SGMII;\n}\n\nstatic int bgx_lmac_enable(struct bgx *bgx, u8 lmacid)\n{\n\tstruct lmac *lmac;\n\tu64 cfg;\n\n\tlmac = &bgx->lmac[lmacid];\n\tlmac->bgx = bgx;\n\n\tif ((lmac->lmac_type == BGX_MODE_SGMII) ||\n\t    (lmac->lmac_type == BGX_MODE_QSGMII) ||\n\t    (lmac->lmac_type == BGX_MODE_RGMII)) {\n\t\tlmac->is_sgmii = true;\n\t\tif (bgx_lmac_sgmii_init(bgx, lmac))\n\t\t\treturn -1;\n\t} else {\n\t\tlmac->is_sgmii = false;\n\t\tif (bgx_lmac_xaui_init(bgx, lmac))\n\t\t\treturn -1;\n\t}\n\n\tif (lmac->is_sgmii) {\n\t\tcfg = bgx_reg_read(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND);\n\t\tcfg |= ((1ull << 2) | (1ull << 1));  \n\t\tbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND, cfg);\n\t\tbgx_reg_write(bgx, lmacid, BGX_GMP_GMI_TXX_MIN_PKT, 60 - 1);\n\t} else {\n\t\tcfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_APPEND);\n\t\tcfg |= ((1ull << 2) | (1ull << 1));  \n\t\tbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_APPEND, cfg);\n\t\tbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_MIN_PKT, 60 + 4);\n\t}\n\n\t \n\tlmac->dmacs_count = (RX_DMAC_COUNT / bgx->lmac_count);\n\tlmac->dmacs = kcalloc(lmac->dmacs_count, sizeof(*lmac->dmacs),\n\t\t\t      GFP_KERNEL);\n\tif (!lmac->dmacs)\n\t\treturn -ENOMEM;\n\n\t \n\tbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\n\n\t \n\tbgx_reg_write(bgx, lmacid, BGX_CMRX_RX_DMAC_CTL, 0x03);\n\n\tif ((lmac->lmac_type != BGX_MODE_XFI) &&\n\t    (lmac->lmac_type != BGX_MODE_XLAUI) &&\n\t    (lmac->lmac_type != BGX_MODE_40G_KR) &&\n\t    (lmac->lmac_type != BGX_MODE_10G_KR)) {\n\t\tif (!lmac->phydev) {\n\t\t\tif (lmac->autoneg) {\n\t\t\t\tbgx_reg_write(bgx, lmacid,\n\t\t\t\t\t      BGX_GMP_PCS_LINKX_TIMER,\n\t\t\t\t\t      PCS_LINKX_TIMER_COUNT);\n\t\t\t\tgoto poll;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tlmac->link_up = true;\n\t\t\t\tlmac->last_speed = SPEED_1000;\n\t\t\t\tlmac->last_duplex = DUPLEX_FULL;\n\t\t\t\tbgx_sgmii_change_link_state(lmac);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tlmac->phydev->dev_flags = 0;\n\n\t\tif (phy_connect_direct(&lmac->netdev, lmac->phydev,\n\t\t\t\t       bgx_lmac_handler,\n\t\t\t\t       phy_interface_mode(lmac->lmac_type)))\n\t\t\treturn -ENODEV;\n\n\t\tphy_start(lmac->phydev);\n\t\treturn 0;\n\t}\n\npoll:\n\tlmac->check_link = alloc_ordered_workqueue(\"check_link\", WQ_MEM_RECLAIM);\n\tif (!lmac->check_link)\n\t\treturn -ENOMEM;\n\tINIT_DELAYED_WORK(&lmac->dwork, bgx_poll_for_link);\n\tqueue_delayed_work(lmac->check_link, &lmac->dwork, 0);\n\n\treturn 0;\n}\n\nstatic void bgx_lmac_disable(struct bgx *bgx, u8 lmacid)\n{\n\tstruct lmac *lmac;\n\tu64 cfg;\n\n\tlmac = &bgx->lmac[lmacid];\n\tif (lmac->check_link) {\n\t\t \n\t\tcancel_delayed_work_sync(&lmac->dwork);\n\t\tdestroy_workqueue(lmac->check_link);\n\t}\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\n\tcfg &= ~CMR_PKT_RX_EN;\n\tbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\n\n\t \n\tbgx_poll_reg(bgx, lmacid, BGX_CMRX_RX_FIFO_LEN, (u64)0x1FFF, true);\n\tbgx_poll_reg(bgx, lmacid, BGX_CMRX_TX_FIFO_LEN, (u64)0x3FFF, true);\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\n\tcfg &= ~CMR_PKT_TX_EN;\n\tbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\n\n\t \n        if (!lmac->is_sgmii)\n                bgx_reg_modify(bgx, lmacid,\n                               BGX_SPUX_CONTROL1, SPU_CTL_LOW_POWER);\n        else\n                bgx_reg_modify(bgx, lmacid,\n                               BGX_GMP_PCS_MRX_CTL, PCS_MRX_CTL_PWR_DN);\n\n\t \n\tcfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\n\tcfg &= ~CMR_EN;\n\tbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\n\n\tbgx_flush_dmac_cam_filter(bgx, lmacid);\n\tkfree(lmac->dmacs);\n\n\tif ((lmac->lmac_type != BGX_MODE_XFI) &&\n\t    (lmac->lmac_type != BGX_MODE_XLAUI) &&\n\t    (lmac->lmac_type != BGX_MODE_40G_KR) &&\n\t    (lmac->lmac_type != BGX_MODE_10G_KR) && lmac->phydev)\n\t\tphy_disconnect(lmac->phydev);\n\n\tlmac->phydev = NULL;\n}\n\nstatic void bgx_init_hw(struct bgx *bgx)\n{\n\tint i;\n\tstruct lmac *lmac;\n\n\tbgx_reg_modify(bgx, 0, BGX_CMR_GLOBAL_CFG, CMR_GLOBAL_CFG_FCS_STRIP);\n\tif (bgx_reg_read(bgx, 0, BGX_CMR_BIST_STATUS))\n\t\tdev_err(&bgx->pdev->dev, \"BGX%d BIST failed\\n\", bgx->bgx_id);\n\n\t \n\tfor (i = 0; i < bgx->lmac_count; i++) {\n\t\tlmac = &bgx->lmac[i];\n\t\tbgx_reg_write(bgx, i, BGX_CMRX_CFG,\n\t\t\t      (lmac->lmac_type << 8) | lmac->lane_to_sds);\n\t\tbgx->lmac[i].lmacid_bd = lmac_count;\n\t\tlmac_count++;\n\t}\n\n\tbgx_reg_write(bgx, 0, BGX_CMR_TX_LMACS, bgx->lmac_count);\n\tbgx_reg_write(bgx, 0, BGX_CMR_RX_LMACS, bgx->lmac_count);\n\n\t \n\tfor (i = 0; i < bgx->lmac_count; i++)\n\t\tbgx_reg_modify(bgx, 0, BGX_CMR_CHAN_MSK_AND,\n\t\t\t       ((1ULL << MAX_BGX_CHANS_PER_LMAC) - 1) <<\n\t\t\t       (i * MAX_BGX_CHANS_PER_LMAC));\n\n\t \n\tfor (i = 0; i < RX_DMAC_COUNT; i++)\n\t\tbgx_reg_write(bgx, 0, BGX_CMR_RX_DMACX_CAM + (i * 8), 0x00);\n\n\t \n\tfor (i = 0; i < RX_TRAFFIC_STEER_RULE_COUNT; i++)\n\t\tbgx_reg_write(bgx, 0, BGX_CMR_RX_STEERING + (i * 8), 0x00);\n}\n\nstatic u8 bgx_get_lane2sds_cfg(struct bgx *bgx, struct lmac *lmac)\n{\n\treturn (u8)(bgx_reg_read(bgx, lmac->lmacid, BGX_CMRX_CFG) & 0xFF);\n}\n\nstatic void bgx_print_qlm_mode(struct bgx *bgx, u8 lmacid)\n{\n\tstruct device *dev = &bgx->pdev->dev;\n\tstruct lmac *lmac;\n\tchar str[27];\n\n\tif (!bgx->is_dlm && lmacid)\n\t\treturn;\n\n\tlmac = &bgx->lmac[lmacid];\n\tif (!bgx->is_dlm)\n\t\tsprintf(str, \"BGX%d QLM mode\", bgx->bgx_id);\n\telse\n\t\tsprintf(str, \"BGX%d LMAC%d mode\", bgx->bgx_id, lmacid);\n\n\tswitch (lmac->lmac_type) {\n\tcase BGX_MODE_SGMII:\n\t\tdev_info(dev, \"%s: SGMII\\n\", (char *)str);\n\t\tbreak;\n\tcase BGX_MODE_XAUI:\n\t\tdev_info(dev, \"%s: XAUI\\n\", (char *)str);\n\t\tbreak;\n\tcase BGX_MODE_RXAUI:\n\t\tdev_info(dev, \"%s: RXAUI\\n\", (char *)str);\n\t\tbreak;\n\tcase BGX_MODE_XFI:\n\t\tif (!lmac->use_training)\n\t\t\tdev_info(dev, \"%s: XFI\\n\", (char *)str);\n\t\telse\n\t\t\tdev_info(dev, \"%s: 10G_KR\\n\", (char *)str);\n\t\tbreak;\n\tcase BGX_MODE_XLAUI:\n\t\tif (!lmac->use_training)\n\t\t\tdev_info(dev, \"%s: XLAUI\\n\", (char *)str);\n\t\telse\n\t\t\tdev_info(dev, \"%s: 40G_KR4\\n\", (char *)str);\n\t\tbreak;\n\tcase BGX_MODE_QSGMII:\n\t\tdev_info(dev, \"%s: QSGMII\\n\", (char *)str);\n\t\tbreak;\n\tcase BGX_MODE_RGMII:\n\t\tdev_info(dev, \"%s: RGMII\\n\", (char *)str);\n\t\tbreak;\n\tcase BGX_MODE_INVALID:\n\t\t \n\t\tbreak;\n\t}\n}\n\nstatic void lmac_set_lane2sds(struct bgx *bgx, struct lmac *lmac)\n{\n\tswitch (lmac->lmac_type) {\n\tcase BGX_MODE_SGMII:\n\tcase BGX_MODE_XFI:\n\t\tlmac->lane_to_sds = lmac->lmacid;\n\t\tbreak;\n\tcase BGX_MODE_XAUI:\n\tcase BGX_MODE_XLAUI:\n\tcase BGX_MODE_RGMII:\n\t\tlmac->lane_to_sds = 0xE4;\n\t\tbreak;\n\tcase BGX_MODE_RXAUI:\n\t\tlmac->lane_to_sds = (lmac->lmacid) ? 0xE : 0x4;\n\t\tbreak;\n\tcase BGX_MODE_QSGMII:\n\t\t \n\t\tlmac->lane_to_sds = bgx_get_lane2sds_cfg(bgx, lmac);\n\t\tbreak;\n\tdefault:\n\t\tlmac->lane_to_sds = 0;\n\t\tbreak;\n\t}\n}\n\nstatic void lmac_set_training(struct bgx *bgx, struct lmac *lmac, int lmacid)\n{\n\tif ((lmac->lmac_type != BGX_MODE_10G_KR) &&\n\t    (lmac->lmac_type != BGX_MODE_40G_KR)) {\n\t\tlmac->use_training = false;\n\t\treturn;\n\t}\n\n\tlmac->use_training = bgx_reg_read(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL) &\n\t\t\t\t\t\t\tSPU_PMD_CRTL_TRAIN_EN;\n}\n\nstatic void bgx_set_lmac_config(struct bgx *bgx, u8 idx)\n{\n\tstruct lmac *lmac;\n\tu64 cmr_cfg;\n\tu8 lmac_type;\n\tu8 lane_to_sds;\n\n\tlmac = &bgx->lmac[idx];\n\n\tif (!bgx->is_dlm || bgx->is_rgx) {\n\t\t \n\t\tcmr_cfg = bgx_reg_read(bgx, 0, BGX_CMRX_CFG);\n\t\tlmac->lmac_type = (cmr_cfg >> 8) & 0x07;\n\t\tif (bgx->is_rgx)\n\t\t\tlmac->lmac_type = BGX_MODE_RGMII;\n\t\tlmac_set_training(bgx, lmac, 0);\n\t\tlmac_set_lane2sds(bgx, lmac);\n\t\treturn;\n\t}\n\n\t \n\tcmr_cfg = bgx_reg_read(bgx, idx, BGX_CMRX_CFG);\n\tlmac_type = (u8)((cmr_cfg >> 8) & 0x07);\n\tlane_to_sds = (u8)(cmr_cfg & 0xFF);\n\t \n\tif ((lmac_type == 0) && (lane_to_sds == 0xE4))\n\t\tlmac->lmac_type = BGX_MODE_INVALID;\n\telse\n\t\tlmac->lmac_type = lmac_type;\n\tlmac->lane_to_sds = lane_to_sds;\n\tlmac_set_training(bgx, lmac, lmac->lmacid);\n}\n\nstatic void bgx_get_qlm_mode(struct bgx *bgx)\n{\n\tstruct lmac *lmac;\n\tu8  idx;\n\n\t \n\tfor (idx = 0; idx < bgx->max_lmac; idx++) {\n\t\tlmac = &bgx->lmac[idx];\n\t\tlmac->lmacid = idx;\n\t\tlmac->lmac_type = BGX_MODE_INVALID;\n\t\tlmac->use_training = false;\n\t}\n\n\t \n\tbgx->lmac_count = bgx_reg_read(bgx, 0, BGX_CMR_RX_LMACS) & 0x7;\n\tif (bgx->lmac_count > bgx->max_lmac)\n\t\tbgx->lmac_count = bgx->max_lmac;\n\n\tfor (idx = 0; idx < bgx->lmac_count; idx++) {\n\t\tbgx_set_lmac_config(bgx, idx);\n\t\tbgx_print_qlm_mode(bgx, idx);\n\t}\n}\n\n#ifdef CONFIG_ACPI\n\nstatic int acpi_get_mac_address(struct device *dev, struct acpi_device *adev,\n\t\t\t\tu8 *dst)\n{\n\tu8 mac[ETH_ALEN];\n\tint ret;\n\n\tret = fwnode_get_mac_address(acpi_fwnode_handle(adev), mac);\n\tif (ret) {\n\t\tdev_err(dev, \"MAC address invalid: %pM\\n\", mac);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_info(dev, \"MAC address set to: %pM\\n\", mac);\n\n\tether_addr_copy(dst, mac);\n\treturn 0;\n}\n\n \nstatic acpi_status bgx_acpi_register_phy(acpi_handle handle,\n\t\t\t\t\t u32 lvl, void *context, void **rv)\n{\n\tstruct bgx *bgx = context;\n\tstruct device *dev = &bgx->pdev->dev;\n\tstruct acpi_device *adev;\n\n\tadev = acpi_fetch_acpi_dev(handle);\n\tif (!adev)\n\t\tgoto out;\n\n\tacpi_get_mac_address(dev, adev, bgx->lmac[bgx->acpi_lmac_idx].mac);\n\n\tSET_NETDEV_DEV(&bgx->lmac[bgx->acpi_lmac_idx].netdev, dev);\n\n\tbgx->lmac[bgx->acpi_lmac_idx].lmacid = bgx->acpi_lmac_idx;\n\tbgx->acpi_lmac_idx++;  \nout:\n\treturn AE_OK;\n}\n\nstatic acpi_status bgx_acpi_match_id(acpi_handle handle, u32 lvl,\n\t\t\t\t     void *context, void **ret_val)\n{\n\tstruct acpi_buffer string = { ACPI_ALLOCATE_BUFFER, NULL };\n\tstruct bgx *bgx = context;\n\tchar bgx_sel[5];\n\n\tsnprintf(bgx_sel, 5, \"BGX%d\", bgx->bgx_id);\n\tif (ACPI_FAILURE(acpi_get_name(handle, ACPI_SINGLE_NAME, &string))) {\n\t\tpr_warn(\"Invalid link device\\n\");\n\t\treturn AE_OK;\n\t}\n\n\tif (strncmp(string.pointer, bgx_sel, 4)) {\n\t\tkfree(string.pointer);\n\t\treturn AE_OK;\n\t}\n\n\tacpi_walk_namespace(ACPI_TYPE_DEVICE, handle, 1,\n\t\t\t    bgx_acpi_register_phy, NULL, bgx, NULL);\n\n\tkfree(string.pointer);\n\treturn AE_CTRL_TERMINATE;\n}\n\nstatic int bgx_init_acpi_phy(struct bgx *bgx)\n{\n\tacpi_get_devices(NULL, bgx_acpi_match_id, bgx, (void **)NULL);\n\treturn 0;\n}\n\n#else\n\nstatic int bgx_init_acpi_phy(struct bgx *bgx)\n{\n\treturn -ENODEV;\n}\n\n#endif  \n\n#if IS_ENABLED(CONFIG_OF_MDIO)\n\nstatic int bgx_init_of_phy(struct bgx *bgx)\n{\n\tstruct fwnode_handle *fwn;\n\tstruct device_node *node = NULL;\n\tu8 lmac = 0;\n\n\tdevice_for_each_child_node(&bgx->pdev->dev, fwn) {\n\t\tstruct phy_device *pd;\n\t\tstruct device_node *phy_np;\n\n\t\t \n\t\tnode = to_of_node(fwn);\n\t\tif (!node)\n\t\t\tbreak;\n\n\t\tof_get_mac_address(node, bgx->lmac[lmac].mac);\n\n\t\tSET_NETDEV_DEV(&bgx->lmac[lmac].netdev, &bgx->pdev->dev);\n\t\tbgx->lmac[lmac].lmacid = lmac;\n\n\t\tphy_np = of_parse_phandle(node, \"phy-handle\", 0);\n\t\t \n\t\tif (phy_np &&\n\t\t    !of_device_is_compatible(phy_np, \"cortina,cs4223-slice\")) {\n\t\t\t \n\t\t\tpd = of_phy_find_device(phy_np);\n\t\t\tif (!pd)\n\t\t\t\tgoto defer;\n\t\t\tbgx->lmac[lmac].phydev = pd;\n\t\t}\n\n\t\tlmac++;\n\t\tif (lmac == bgx->max_lmac) {\n\t\t\tof_node_put(node);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn 0;\n\ndefer:\n\t \n\twhile (lmac) {\n\t\tif (bgx->lmac[lmac].phydev) {\n\t\t\tput_device(&bgx->lmac[lmac].phydev->mdio.dev);\n\t\t\tbgx->lmac[lmac].phydev = NULL;\n\t\t}\n\t\tlmac--;\n\t}\n\tof_node_put(node);\n\treturn -EPROBE_DEFER;\n}\n\n#else\n\nstatic int bgx_init_of_phy(struct bgx *bgx)\n{\n\treturn -ENODEV;\n}\n\n#endif  \n\nstatic int bgx_init_phy(struct bgx *bgx)\n{\n\tif (!acpi_disabled)\n\t\treturn bgx_init_acpi_phy(bgx);\n\n\treturn bgx_init_of_phy(bgx);\n}\n\nstatic irqreturn_t bgx_intr_handler(int irq, void *data)\n{\n\tstruct bgx *bgx = (struct bgx *)data;\n\tu64 status, val;\n\tint lmac;\n\n\tfor (lmac = 0; lmac < bgx->lmac_count; lmac++) {\n\t\tstatus = bgx_reg_read(bgx, lmac, BGX_GMP_GMI_TXX_INT);\n\t\tif (status & GMI_TXX_INT_UNDFLW) {\n\t\t\tpci_err(bgx->pdev, \"BGX%d lmac%d UNDFLW\\n\",\n\t\t\t\tbgx->bgx_id, lmac);\n\t\t\tval = bgx_reg_read(bgx, lmac, BGX_CMRX_CFG);\n\t\t\tval &= ~CMR_EN;\n\t\t\tbgx_reg_write(bgx, lmac, BGX_CMRX_CFG, val);\n\t\t\tval |= CMR_EN;\n\t\t\tbgx_reg_write(bgx, lmac, BGX_CMRX_CFG, val);\n\t\t}\n\t\t \n\t\tbgx_reg_write(bgx, lmac, BGX_GMP_GMI_TXX_INT, status);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void bgx_register_intr(struct pci_dev *pdev)\n{\n\tstruct bgx *bgx = pci_get_drvdata(pdev);\n\tint ret;\n\n\tret = pci_alloc_irq_vectors(pdev, BGX_LMAC_VEC_OFFSET,\n\t\t\t\t    BGX_LMAC_VEC_OFFSET, PCI_IRQ_ALL_TYPES);\n\tif (ret < 0) {\n\t\tpci_err(pdev, \"Req for #%d msix vectors failed\\n\",\n\t\t\tBGX_LMAC_VEC_OFFSET);\n\t\treturn;\n\t}\n\tret = pci_request_irq(pdev, GMPX_GMI_TX_INT, bgx_intr_handler, NULL,\n\t\t\t      bgx, \"BGX%d\", bgx->bgx_id);\n\tif (ret)\n\t\tpci_free_irq(pdev, GMPX_GMI_TX_INT, bgx);\n}\n\nstatic int bgx_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tint err;\n\tstruct device *dev = &pdev->dev;\n\tstruct bgx *bgx = NULL;\n\tu8 lmac;\n\tu16 sdevid;\n\n\tbgx = devm_kzalloc(dev, sizeof(*bgx), GFP_KERNEL);\n\tif (!bgx)\n\t\treturn -ENOMEM;\n\tbgx->pdev = pdev;\n\n\tpci_set_drvdata(pdev, bgx);\n\n\terr = pcim_enable_device(pdev);\n\tif (err) {\n\t\tpci_set_drvdata(pdev, NULL);\n\t\treturn dev_err_probe(dev, err, \"Failed to enable PCI device\\n\");\n\t}\n\n\terr = pci_request_regions(pdev, DRV_NAME);\n\tif (err) {\n\t\tdev_err(dev, \"PCI request regions failed 0x%x\\n\", err);\n\t\tgoto err_disable_device;\n\t}\n\n\t \n\tbgx->reg_base = pcim_iomap(pdev, PCI_CFG_REG_BAR_NUM, 0);\n\tif (!bgx->reg_base) {\n\t\tdev_err(dev, \"BGX: Cannot map CSR memory space, aborting\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_release_regions;\n\t}\n\n\tset_max_bgx_per_node(pdev);\n\n\tpci_read_config_word(pdev, PCI_DEVICE_ID, &sdevid);\n\tif (sdevid != PCI_DEVICE_ID_THUNDER_RGX) {\n\t\tbgx->bgx_id = (pci_resource_start(pdev,\n\t\t\tPCI_CFG_REG_BAR_NUM) >> 24) & BGX_ID_MASK;\n\t\tbgx->bgx_id += nic_get_node_id(pdev) * max_bgx_per_node;\n\t\tbgx->max_lmac = MAX_LMAC_PER_BGX;\n\t\tbgx_vnic[bgx->bgx_id] = bgx;\n\t} else {\n\t\tbgx->is_rgx = true;\n\t\tbgx->max_lmac = 1;\n\t\tbgx->bgx_id = MAX_BGX_PER_CN81XX - 1;\n\t\tbgx_vnic[bgx->bgx_id] = bgx;\n\t\txcv_init_hw();\n\t}\n\n\t \n\tpci_read_config_word(pdev, PCI_SUBSYSTEM_ID, &sdevid);\n\tif ((sdevid == PCI_SUBSYS_DEVID_81XX_BGX) ||\n\t    ((sdevid == PCI_SUBSYS_DEVID_83XX_BGX) && (bgx->bgx_id == 2)))\n\t\tbgx->is_dlm = true;\n\n\tbgx_get_qlm_mode(bgx);\n\n\terr = bgx_init_phy(bgx);\n\tif (err)\n\t\tgoto err_enable;\n\n\tbgx_init_hw(bgx);\n\n\tbgx_register_intr(pdev);\n\n\t \n\tfor (lmac = 0; lmac < bgx->lmac_count; lmac++) {\n\t\terr = bgx_lmac_enable(bgx, lmac);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"BGX%d failed to enable lmac%d\\n\",\n\t\t\t\tbgx->bgx_id, lmac);\n\t\t\twhile (lmac)\n\t\t\t\tbgx_lmac_disable(bgx, --lmac);\n\t\t\tgoto err_enable;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_enable:\n\tbgx_vnic[bgx->bgx_id] = NULL;\n\tpci_free_irq(pdev, GMPX_GMI_TX_INT, bgx);\nerr_release_regions:\n\tpci_release_regions(pdev);\nerr_disable_device:\n\tpci_disable_device(pdev);\n\tpci_set_drvdata(pdev, NULL);\n\treturn err;\n}\n\nstatic void bgx_remove(struct pci_dev *pdev)\n{\n\tstruct bgx *bgx = pci_get_drvdata(pdev);\n\tu8 lmac;\n\n\t \n\tfor (lmac = 0; lmac < bgx->lmac_count; lmac++)\n\t\tbgx_lmac_disable(bgx, lmac);\n\n\tpci_free_irq(pdev, GMPX_GMI_TX_INT, bgx);\n\n\tbgx_vnic[bgx->bgx_id] = NULL;\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\tpci_set_drvdata(pdev, NULL);\n}\n\nstatic struct pci_driver bgx_driver = {\n\t.name = DRV_NAME,\n\t.id_table = bgx_id_table,\n\t.probe = bgx_probe,\n\t.remove = bgx_remove,\n};\n\nstatic int __init bgx_init_module(void)\n{\n\tpr_info(\"%s, ver %s\\n\", DRV_NAME, DRV_VERSION);\n\n\treturn pci_register_driver(&bgx_driver);\n}\n\nstatic void __exit bgx_cleanup_module(void)\n{\n\tpci_unregister_driver(&bgx_driver);\n}\n\nmodule_init(bgx_init_module);\nmodule_exit(bgx_cleanup_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}