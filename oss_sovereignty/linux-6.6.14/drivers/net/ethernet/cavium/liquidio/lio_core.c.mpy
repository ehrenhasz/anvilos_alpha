{
  "module_name": "lio_core.c",
  "hash_id": "343f4d909a0606e64d359fe46302e388fafadabedef6d50495a9c3d5d10d9c28",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/cavium/liquidio/lio_core.c",
  "human_readable_source": " \n#include <linux/pci.h>\n#include <linux/if_vlan.h>\n#include \"liquidio_common.h\"\n#include \"octeon_droq.h\"\n#include \"octeon_iq.h\"\n#include \"response_manager.h\"\n#include \"octeon_device.h\"\n#include \"octeon_nic.h\"\n#include \"octeon_main.h\"\n#include \"octeon_network.h\"\n\nMODULE_AUTHOR(\"Cavium Networks, <support@cavium.com>\");\nMODULE_LICENSE(\"GPL\");\n\n \n#define LIO_OOM_POLL_INTERVAL_MS 250\n\n#define OCTNIC_MAX_SG  MAX_SKB_FRAGS\n\n \nvoid lio_delete_glists(struct lio *lio)\n{\n\tstruct octnic_gather *g;\n\tint i;\n\n\tkfree(lio->glist_lock);\n\tlio->glist_lock = NULL;\n\n\tif (!lio->glist)\n\t\treturn;\n\n\tfor (i = 0; i < lio->oct_dev->num_iqs; i++) {\n\t\tdo {\n\t\t\tg = (struct octnic_gather *)\n\t\t\t    lio_list_delete_head(&lio->glist[i]);\n\t\t\tkfree(g);\n\t\t} while (g);\n\n\t\tif (lio->glists_virt_base && lio->glists_virt_base[i] &&\n\t\t    lio->glists_dma_base && lio->glists_dma_base[i]) {\n\t\t\tlio_dma_free(lio->oct_dev,\n\t\t\t\t     lio->glist_entry_size * lio->tx_qsize,\n\t\t\t\t     lio->glists_virt_base[i],\n\t\t\t\t     lio->glists_dma_base[i]);\n\t\t}\n\t}\n\n\tkfree(lio->glists_virt_base);\n\tlio->glists_virt_base = NULL;\n\n\tkfree(lio->glists_dma_base);\n\tlio->glists_dma_base = NULL;\n\n\tkfree(lio->glist);\n\tlio->glist = NULL;\n}\nEXPORT_SYMBOL_GPL(lio_delete_glists);\n\n \nint lio_setup_glists(struct octeon_device *oct, struct lio *lio, int num_iqs)\n{\n\tstruct octnic_gather *g;\n\tint i, j;\n\n\tlio->glist_lock =\n\t    kcalloc(num_iqs, sizeof(*lio->glist_lock), GFP_KERNEL);\n\tif (!lio->glist_lock)\n\t\treturn -ENOMEM;\n\n\tlio->glist =\n\t    kcalloc(num_iqs, sizeof(*lio->glist), GFP_KERNEL);\n\tif (!lio->glist) {\n\t\tkfree(lio->glist_lock);\n\t\tlio->glist_lock = NULL;\n\t\treturn -ENOMEM;\n\t}\n\n\tlio->glist_entry_size =\n\t\tROUNDUP8((ROUNDUP4(OCTNIC_MAX_SG) >> 2) * OCT_SG_ENTRY_SIZE);\n\n\t \n\tlio->glists_virt_base = kcalloc(num_iqs, sizeof(*lio->glists_virt_base),\n\t\t\t\t\tGFP_KERNEL);\n\tlio->glists_dma_base = kcalloc(num_iqs, sizeof(*lio->glists_dma_base),\n\t\t\t\t       GFP_KERNEL);\n\n\tif (!lio->glists_virt_base || !lio->glists_dma_base) {\n\t\tlio_delete_glists(lio);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < num_iqs; i++) {\n\t\tint numa_node = dev_to_node(&oct->pci_dev->dev);\n\n\t\tspin_lock_init(&lio->glist_lock[i]);\n\n\t\tINIT_LIST_HEAD(&lio->glist[i]);\n\n\t\tlio->glists_virt_base[i] =\n\t\t\tlio_dma_alloc(oct,\n\t\t\t\t      lio->glist_entry_size * lio->tx_qsize,\n\t\t\t\t      &lio->glists_dma_base[i]);\n\n\t\tif (!lio->glists_virt_base[i]) {\n\t\t\tlio_delete_glists(lio);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tfor (j = 0; j < lio->tx_qsize; j++) {\n\t\t\tg = kzalloc_node(sizeof(*g), GFP_KERNEL,\n\t\t\t\t\t numa_node);\n\t\t\tif (!g)\n\t\t\t\tg = kzalloc(sizeof(*g), GFP_KERNEL);\n\t\t\tif (!g)\n\t\t\t\tbreak;\n\n\t\t\tg->sg = lio->glists_virt_base[i] +\n\t\t\t\t(j * lio->glist_entry_size);\n\n\t\t\tg->sg_dma_ptr = lio->glists_dma_base[i] +\n\t\t\t\t\t(j * lio->glist_entry_size);\n\n\t\t\tlist_add_tail(&g->list, &lio->glist[i]);\n\t\t}\n\n\t\tif (j != lio->tx_qsize) {\n\t\t\tlio_delete_glists(lio);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(lio_setup_glists);\n\nint liquidio_set_feature(struct net_device *netdev, int cmd, u16 param1)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = cmd;\n\tnctrl.ncmd.s.param1 = param1;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"Feature change failed in core (ret: 0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(liquidio_set_feature);\n\nvoid octeon_report_tx_completion_to_bql(void *txq, unsigned int pkts_compl,\n\t\t\t\t\tunsigned int bytes_compl)\n{\n\tstruct netdev_queue *netdev_queue = txq;\n\n\tnetdev_tx_completed_queue(netdev_queue, pkts_compl, bytes_compl);\n}\n\nvoid octeon_update_tx_completion_counters(void *buf, int reqtype,\n\t\t\t\t\t  unsigned int *pkts_compl,\n\t\t\t\t\t  unsigned int *bytes_compl)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tstruct sk_buff *skb = NULL;\n\tstruct octeon_soft_command *sc;\n\n\tswitch (reqtype) {\n\tcase REQTYPE_NORESP_NET:\n\tcase REQTYPE_NORESP_NET_SG:\n\t\tfinfo = buf;\n\t\tskb = finfo->skb;\n\t\tbreak;\n\n\tcase REQTYPE_RESP_NET_SG:\n\tcase REQTYPE_RESP_NET:\n\t\tsc = buf;\n\t\tskb = sc->callback_arg;\n\t\tbreak;\n\n\tdefault:\n\t\treturn;\n\t}\n\n\t(*pkts_compl)++;\n\t*bytes_compl += skb->len;\n}\n\nint octeon_report_sent_bytes_to_bql(void *buf, int reqtype)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tstruct sk_buff *skb;\n\tstruct octeon_soft_command *sc;\n\tstruct netdev_queue *txq;\n\n\tswitch (reqtype) {\n\tcase REQTYPE_NORESP_NET:\n\tcase REQTYPE_NORESP_NET_SG:\n\t\tfinfo = buf;\n\t\tskb = finfo->skb;\n\t\tbreak;\n\n\tcase REQTYPE_RESP_NET_SG:\n\tcase REQTYPE_RESP_NET:\n\t\tsc = buf;\n\t\tskb = sc->callback_arg;\n\t\tbreak;\n\n\tdefault:\n\t\treturn 0;\n\t}\n\n\ttxq = netdev_get_tx_queue(skb->dev, skb_get_queue_mapping(skb));\n\tnetdev_tx_sent_queue(txq, skb->len);\n\n\treturn netif_xmit_stopped(txq);\n}\n\nvoid liquidio_link_ctrl_cmd_completion(void *nctrl_ptr)\n{\n\tstruct octnic_ctrl_pkt *nctrl = (struct octnic_ctrl_pkt *)nctrl_ptr;\n\tstruct net_device *netdev = (struct net_device *)nctrl->netpndev;\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tu8 *mac;\n\n\tif (nctrl->sc_status)\n\t\treturn;\n\n\tswitch (nctrl->ncmd.s.cmd) {\n\tcase OCTNET_CMD_CHANGE_DEVFLAGS:\n\tcase OCTNET_CMD_SET_MULTI_LIST:\n\tcase OCTNET_CMD_SET_UC_LIST:\n\t\tbreak;\n\n\tcase OCTNET_CMD_CHANGE_MACADDR:\n\t\tmac = ((u8 *)&nctrl->udd[0]) + 2;\n\t\tif (nctrl->ncmd.s.param1) {\n\t\t\t \n\t\t\tint vfidx = nctrl->ncmd.s.param1 - 1;\n\t\t\tbool mac_is_admin_assigned = nctrl->ncmd.s.param2;\n\n\t\t\tif (mac_is_admin_assigned)\n\t\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t\t   \"MAC Address %pM is configured for VF %d\\n\",\n\t\t\t\t\t   mac, vfidx);\n\t\t} else {\n\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t   \" MACAddr changed to %pM\\n\",\n\t\t\t\t   mac);\n\t\t}\n\t\tbreak;\n\n\tcase OCTNET_CMD_GPIO_ACCESS:\n\t\tnetif_info(lio, probe, lio->netdev, \"LED Flashing visual identification\\n\");\n\n\t\tbreak;\n\n\tcase OCTNET_CMD_ID_ACTIVE:\n\t\tnetif_info(lio, probe, lio->netdev, \"LED Flashing visual identification\\n\");\n\n\t\tbreak;\n\n\tcase OCTNET_CMD_LRO_ENABLE:\n\t\tdev_info(&oct->pci_dev->dev, \"%s LRO Enabled\\n\", netdev->name);\n\t\tbreak;\n\n\tcase OCTNET_CMD_LRO_DISABLE:\n\t\tdev_info(&oct->pci_dev->dev, \"%s LRO Disabled\\n\",\n\t\t\t netdev->name);\n\t\tbreak;\n\n\tcase OCTNET_CMD_VERBOSE_ENABLE:\n\t\tdev_info(&oct->pci_dev->dev, \"%s Firmware debug enabled\\n\",\n\t\t\t netdev->name);\n\t\tbreak;\n\n\tcase OCTNET_CMD_VERBOSE_DISABLE:\n\t\tdev_info(&oct->pci_dev->dev, \"%s Firmware debug disabled\\n\",\n\t\t\t netdev->name);\n\t\tbreak;\n\n\tcase OCTNET_CMD_VLAN_FILTER_CTL:\n\t\tif (nctrl->ncmd.s.param1)\n\t\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t\t \"%s VLAN filter enabled\\n\", netdev->name);\n\t\telse\n\t\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t\t \"%s VLAN filter disabled\\n\", netdev->name);\n\t\tbreak;\n\n\tcase OCTNET_CMD_ADD_VLAN_FILTER:\n\t\tdev_info(&oct->pci_dev->dev, \"%s VLAN filter %d added\\n\",\n\t\t\t netdev->name, nctrl->ncmd.s.param1);\n\t\tbreak;\n\n\tcase OCTNET_CMD_DEL_VLAN_FILTER:\n\t\tdev_info(&oct->pci_dev->dev, \"%s VLAN filter %d removed\\n\",\n\t\t\t netdev->name, nctrl->ncmd.s.param1);\n\t\tbreak;\n\n\tcase OCTNET_CMD_SET_SETTINGS:\n\t\tdev_info(&oct->pci_dev->dev, \"%s settings changed\\n\",\n\t\t\t netdev->name);\n\n\t\tbreak;\n\n\t \n\tcase OCTNET_CMD_TNL_RX_CSUM_CTL:\n\t\tif (nctrl->ncmd.s.param1 == OCTNET_CMD_RXCSUM_ENABLE) {\n\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t   \"RX Checksum Offload Enabled\\n\");\n\t\t} else if (nctrl->ncmd.s.param1 ==\n\t\t\t   OCTNET_CMD_RXCSUM_DISABLE) {\n\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t   \"RX Checksum Offload Disabled\\n\");\n\t\t}\n\t\tbreak;\n\n\t\t \n\tcase OCTNET_CMD_TNL_TX_CSUM_CTL:\n\t\tif (nctrl->ncmd.s.param1 == OCTNET_CMD_TXCSUM_ENABLE) {\n\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t   \"TX Checksum Offload Enabled\\n\");\n\t\t} else if (nctrl->ncmd.s.param1 ==\n\t\t\t   OCTNET_CMD_TXCSUM_DISABLE) {\n\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t   \"TX Checksum Offload Disabled\\n\");\n\t\t}\n\t\tbreak;\n\n\t\t \n\tcase OCTNET_CMD_VXLAN_PORT_CONFIG:\n\t\tif (nctrl->ncmd.s.more == OCTNET_CMD_VXLAN_PORT_ADD) {\n\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t   \"VxLAN Destination UDP PORT:%d ADDED\\n\",\n\t\t\t\t   nctrl->ncmd.s.param1);\n\t\t} else if (nctrl->ncmd.s.more ==\n\t\t\t   OCTNET_CMD_VXLAN_PORT_DEL) {\n\t\t\tnetif_info(lio, probe, lio->netdev,\n\t\t\t\t   \"VxLAN Destination UDP PORT:%d DELETED\\n\",\n\t\t\t\t   nctrl->ncmd.s.param1);\n\t\t}\n\t\tbreak;\n\n\tcase OCTNET_CMD_SET_FLOW_CTL:\n\t\tnetif_info(lio, probe, lio->netdev, \"Set RX/TX flow control parameters\\n\");\n\t\tbreak;\n\n\tcase OCTNET_CMD_QUEUE_COUNT_CTL:\n\t\tnetif_info(lio, probe, lio->netdev, \"Queue count updated to %d\\n\",\n\t\t\t   nctrl->ncmd.s.param1);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(&oct->pci_dev->dev, \"%s Unknown cmd %d\\n\", __func__,\n\t\t\tnctrl->ncmd.s.cmd);\n\t}\n}\nEXPORT_SYMBOL_GPL(liquidio_link_ctrl_cmd_completion);\n\nvoid octeon_pf_changed_vf_macaddr(struct octeon_device *oct, u8 *mac)\n{\n\tbool macaddr_changed = false;\n\tstruct net_device *netdev;\n\tstruct lio *lio;\n\n\trtnl_lock();\n\n\tnetdev = oct->props[0].netdev;\n\tlio = GET_LIO(netdev);\n\n\tlio->linfo.macaddr_is_admin_asgnd = true;\n\n\tif (!ether_addr_equal(netdev->dev_addr, mac)) {\n\t\tmacaddr_changed = true;\n\t\teth_hw_addr_set(netdev, mac);\n\t\tether_addr_copy(((u8 *)&lio->linfo.hw_addr) + 2, mac);\n\t\tcall_netdevice_notifiers(NETDEV_CHANGEADDR, netdev);\n\t}\n\n\trtnl_unlock();\n\n\tif (macaddr_changed)\n\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t \"PF changed VF's MAC address to %pM\\n\", mac);\n\n\t \n}\n\nvoid octeon_schedule_rxq_oom_work(struct octeon_device *oct,\n\t\t\t\t  struct octeon_droq *droq)\n{\n\tstruct net_device *netdev = oct->props[0].netdev;\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct cavium_wq *wq = &lio->rxq_status_wq[droq->q_no];\n\n\tqueue_delayed_work(wq->wq, &wq->wk.work,\n\t\t\t   msecs_to_jiffies(LIO_OOM_POLL_INTERVAL_MS));\n}\n\nstatic void octnet_poll_check_rxq_oom_status(struct work_struct *work)\n{\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\tstruct lio *lio = (struct lio *)wk->ctxptr;\n\tstruct octeon_device *oct = lio->oct_dev;\n\tint q_no = wk->ctxul;\n\tstruct octeon_droq *droq = oct->droq[q_no];\n\n\tif (!ifstate_check(lio, LIO_IFSTATE_RUNNING) || !droq)\n\t\treturn;\n\n\tif (octeon_retry_droq_refill(droq))\n\t\tocteon_schedule_rxq_oom_work(oct, droq);\n}\n\nint setup_rx_oom_poll_fn(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct cavium_wq *wq;\n\tint q, q_no;\n\n\tfor (q = 0; q < oct->num_oqs; q++) {\n\t\tq_no = lio->linfo.rxpciq[q].s.q_no;\n\t\twq = &lio->rxq_status_wq[q_no];\n\t\twq->wq = alloc_workqueue(\"rxq-oom-status\",\n\t\t\t\t\t WQ_MEM_RECLAIM, 0);\n\t\tif (!wq->wq) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"unable to create cavium rxq oom status wq\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tINIT_DELAYED_WORK(&wq->wk.work,\n\t\t\t\t  octnet_poll_check_rxq_oom_status);\n\t\twq->wk.ctxptr = lio;\n\t\twq->wk.ctxul = q_no;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(setup_rx_oom_poll_fn);\n\nvoid cleanup_rx_oom_poll_fn(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct cavium_wq *wq;\n\tint q_no;\n\n\tfor (q_no = 0; q_no < oct->num_oqs; q_no++) {\n\t\twq = &lio->rxq_status_wq[q_no];\n\t\tif (wq->wq) {\n\t\t\tcancel_delayed_work_sync(&wq->wk.work);\n\t\t\tdestroy_workqueue(wq->wq);\n\t\t\twq->wq = NULL;\n\t\t}\n\t}\n}\nEXPORT_SYMBOL_GPL(cleanup_rx_oom_poll_fn);\n\n \nstatic void lio_update_txq_status(struct octeon_device *oct, int iq_num)\n{\n\tstruct octeon_instr_queue *iq = oct->instr_queue[iq_num];\n\tstruct net_device *netdev;\n\tstruct lio *lio;\n\n\tnetdev = oct->props[iq->ifidx].netdev;\n\n\t \n\tif (!netdev)\n\t\treturn;\n\n\tlio = GET_LIO(netdev);\n\tif (__netif_subqueue_stopped(netdev, iq->q_index) &&\n\t    lio->linfo.link.s.link_up &&\n\t    (!octnet_iq_is_full(oct, iq_num))) {\n\t\tnetif_wake_subqueue(netdev, iq->q_index);\n\t\tINCR_INSTRQUEUE_PKT_COUNT(lio->oct_dev, iq_num,\n\t\t\t\t\t  tx_restart, 1);\n\t}\n}\n\n \nstatic int octeon_setup_droq(struct octeon_device *oct, int q_no, int num_descs,\n\t\t\t     int desc_size, void *app_ctx)\n{\n\tint ret_val;\n\n\tdev_dbg(&oct->pci_dev->dev, \"Creating Droq: %d\\n\", q_no);\n\t \n\tret_val = octeon_create_droq(oct, q_no, num_descs, desc_size, app_ctx);\n\tif (ret_val < 0)\n\t\treturn ret_val;\n\n\tif (ret_val == 1) {\n\t\tdev_dbg(&oct->pci_dev->dev, \"Using default droq %d\\n\", q_no);\n\t\treturn 0;\n\t}\n\n\t \n\tocteon_set_droq_pkt_op(oct, q_no, 1);\n\n\t \n\twritel(oct->droq[q_no]->max_count, oct->droq[q_no]->pkts_credit_reg);\n\n\treturn ret_val;\n}\n\n \nstatic void\nliquidio_push_packet(u32 __maybe_unused octeon_id,\n\t\t     void *skbuff,\n\t\t     u32 len,\n\t\t     union octeon_rh *rh,\n\t\t     void *param,\n\t\t     void *arg)\n{\n\tstruct net_device *netdev = (struct net_device *)arg;\n\tstruct octeon_droq *droq =\n\t    container_of(param, struct octeon_droq, napi);\n\tstruct sk_buff *skb = (struct sk_buff *)skbuff;\n\tstruct skb_shared_hwtstamps *shhwtstamps;\n\tstruct napi_struct *napi = param;\n\tu16 vtag = 0;\n\tu32 r_dh_off;\n\tu64 ns;\n\n\tif (netdev) {\n\t\tstruct lio *lio = GET_LIO(netdev);\n\t\tstruct octeon_device *oct = lio->oct_dev;\n\n\t\t \n\t\tif (!ifstate_check(lio, LIO_IFSTATE_RUNNING)) {\n\t\t\trecv_buffer_free(skb);\n\t\t\tdroq->stats.rx_dropped++;\n\t\t\treturn;\n\t\t}\n\n\t\tskb->dev = netdev;\n\n\t\tskb_record_rx_queue(skb, droq->q_no);\n\t\tif (likely(len > MIN_SKB_SIZE)) {\n\t\t\tstruct octeon_skb_page_info *pg_info;\n\t\t\tunsigned char *va;\n\n\t\t\tpg_info = ((struct octeon_skb_page_info *)(skb->cb));\n\t\t\tif (pg_info->page) {\n\t\t\t\t \n\t\t\t\tva = page_address(pg_info->page) +\n\t\t\t\t\tpg_info->page_offset;\n\t\t\t\tmemcpy(skb->data, va, MIN_SKB_SIZE);\n\t\t\t\tskb_put(skb, MIN_SKB_SIZE);\n\t\t\t\tskb_add_rx_frag(skb, skb_shinfo(skb)->nr_frags,\n\t\t\t\t\t\tpg_info->page,\n\t\t\t\t\t\tpg_info->page_offset +\n\t\t\t\t\t\tMIN_SKB_SIZE,\n\t\t\t\t\t\tlen - MIN_SKB_SIZE,\n\t\t\t\t\t\tLIO_RXBUFFER_SZ);\n\t\t\t}\n\t\t} else {\n\t\t\tstruct octeon_skb_page_info *pg_info =\n\t\t\t\t((struct octeon_skb_page_info *)(skb->cb));\n\t\t\tskb_copy_to_linear_data(skb, page_address(pg_info->page)\n\t\t\t\t\t\t+ pg_info->page_offset, len);\n\t\t\tskb_put(skb, len);\n\t\t\tput_page(pg_info->page);\n\t\t}\n\n\t\tr_dh_off = (rh->r_dh.len - 1) * BYTES_PER_DHLEN_UNIT;\n\n\t\tif (oct->ptp_enable) {\n\t\t\tif (rh->r_dh.has_hwtstamp) {\n\t\t\t\t \n\t\t\t\tif (ifstate_check\n\t\t\t\t\t(lio,\n\t\t\t\t\t LIO_IFSTATE_RX_TIMESTAMP_ENABLED)) {\n\t\t\t\t\t \n\t\t\t\t\tmemcpy(&ns, (skb->data + r_dh_off),\n\t\t\t\t\t       sizeof(ns));\n\t\t\t\t\tr_dh_off -= BYTES_PER_DHLEN_UNIT;\n\t\t\t\t\tshhwtstamps = skb_hwtstamps(skb);\n\t\t\t\t\tshhwtstamps->hwtstamp =\n\t\t\t\t\t\tns_to_ktime(ns +\n\t\t\t\t\t\t\t    lio->ptp_adjust);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (rh->r_dh.has_hash) {\n\t\t\t__be32 *hash_be = (__be32 *)(skb->data + r_dh_off);\n\t\t\tu32 hash = be32_to_cpu(*hash_be);\n\n\t\t\tskb_set_hash(skb, hash, PKT_HASH_TYPE_L4);\n\t\t\tr_dh_off -= BYTES_PER_DHLEN_UNIT;\n\t\t}\n\n\t\tskb_pull(skb, rh->r_dh.len * BYTES_PER_DHLEN_UNIT);\n\t\tskb->protocol = eth_type_trans(skb, skb->dev);\n\n\t\tif ((netdev->features & NETIF_F_RXCSUM) &&\n\t\t    (((rh->r_dh.encap_on) &&\n\t\t      (rh->r_dh.csum_verified & CNNIC_TUN_CSUM_VERIFIED)) ||\n\t\t     (!(rh->r_dh.encap_on) &&\n\t\t      ((rh->r_dh.csum_verified & CNNIC_CSUM_VERIFIED) ==\n\t\t\tCNNIC_CSUM_VERIFIED))))\n\t\t\t \n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\telse\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\t \n\t\tif (rh->r_dh.encap_on) {\n\t\t\tskb->encapsulation = 1;\n\t\t\tskb->csum_level = 1;\n\t\t\tdroq->stats.rx_vxlan++;\n\t\t}\n\n\t\t \n\t\tif ((netdev->features & NETIF_F_HW_VLAN_CTAG_RX) &&\n\t\t    rh->r_dh.vlan) {\n\t\t\tu16 priority = rh->r_dh.priority;\n\t\t\tu16 vid = rh->r_dh.vlan;\n\n\t\t\tvtag = (priority << VLAN_PRIO_SHIFT) | vid;\n\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vtag);\n\t\t}\n\n\t\tnapi_gro_receive(napi, skb);\n\n\t\tdroq->stats.rx_bytes_received += len -\n\t\t\trh->r_dh.len * BYTES_PER_DHLEN_UNIT;\n\t\tdroq->stats.rx_pkts_received++;\n\t} else {\n\t\trecv_buffer_free(skb);\n\t}\n}\n\n \nstatic void napi_schedule_wrapper(void *param)\n{\n\tstruct napi_struct *napi = param;\n\n\tnapi_schedule(napi);\n}\n\n \nstatic void liquidio_napi_drv_callback(void *arg)\n{\n\tstruct octeon_device *oct;\n\tstruct octeon_droq *droq = arg;\n\tint this_cpu = smp_processor_id();\n\n\toct = droq->oct_dev;\n\n\tif (OCTEON_CN23XX_PF(oct) || OCTEON_CN23XX_VF(oct) ||\n\t    droq->cpu_id == this_cpu) {\n\t\tnapi_schedule_irqoff(&droq->napi);\n\t} else {\n\t\tINIT_CSD(&droq->csd, napi_schedule_wrapper, &droq->napi);\n\t\tsmp_call_function_single_async(droq->cpu_id, &droq->csd);\n\t}\n}\n\n \nstatic int liquidio_napi_poll(struct napi_struct *napi, int budget)\n{\n\tstruct octeon_instr_queue *iq;\n\tstruct octeon_device *oct;\n\tstruct octeon_droq *droq;\n\tint tx_done = 0, iq_no;\n\tint work_done;\n\n\tdroq = container_of(napi, struct octeon_droq, napi);\n\toct = droq->oct_dev;\n\tiq_no = droq->q_no;\n\n\t \n\twork_done = octeon_droq_process_poll_pkts(oct, droq, budget);\n\n\t \n\tiq = oct->instr_queue[iq_no];\n\tif (iq) {\n\t\t \n\t\tif (atomic_read(&iq->instr_pending))\n\t\t\t \n\t\t\ttx_done = octeon_flush_iq(oct, iq, budget);\n\t\telse\n\t\t\ttx_done = 1;\n\t\t \n\t\t \n\t\tlio_update_txq_status(oct, iq_no);\n\t} else {\n\t\tdev_err(&oct->pci_dev->dev, \"%s:  iq (%d) num invalid\\n\",\n\t\t\t__func__, iq_no);\n\t}\n\n#define MAX_REG_CNT  2000000U\n\t \n\tif ((work_done < budget && tx_done) ||\n\t    (iq && iq->pkt_in_done >= MAX_REG_CNT) ||\n\t    (droq->pkt_count >= MAX_REG_CNT)) {\n\t\tnapi_complete_done(napi, work_done);\n\n\t\tocteon_enable_irq(droq->oct_dev, droq->q_no);\n\t\treturn 0;\n\t}\n\n\treturn (!tx_done) ? (budget) : (work_done);\n}\n\n \nint liquidio_setup_io_queues(struct octeon_device *octeon_dev, int ifidx,\n\t\t\t     u32 num_iqs, u32 num_oqs)\n{\n\tstruct octeon_droq_ops droq_ops;\n\tstruct net_device *netdev;\n\tstruct octeon_droq *droq;\n\tstruct napi_struct *napi;\n\tint cpu_id_modulus;\n\tint num_tx_descs;\n\tstruct lio *lio;\n\tint retval = 0;\n\tint q, q_no;\n\tint cpu_id;\n\n\tnetdev = octeon_dev->props[ifidx].netdev;\n\n\tlio = GET_LIO(netdev);\n\n\tmemset(&droq_ops, 0, sizeof(struct octeon_droq_ops));\n\n\tdroq_ops.fptr = liquidio_push_packet;\n\tdroq_ops.farg = netdev;\n\n\tdroq_ops.poll_mode = 1;\n\tdroq_ops.napi_fn = liquidio_napi_drv_callback;\n\tcpu_id = 0;\n\tcpu_id_modulus = num_present_cpus();\n\n\t \n\tfor (q = 0; q < num_oqs; q++) {\n\t\tq_no = lio->linfo.rxpciq[q].s.q_no;\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"%s index:%d linfo.rxpciq.s.q_no:%d\\n\",\n\t\t\t__func__, q, q_no);\n\t\tretval = octeon_setup_droq(\n\t\t    octeon_dev, q_no,\n\t\t    CFG_GET_NUM_RX_DESCS_NIC_IF(octeon_get_conf(octeon_dev),\n\t\t\t\t\t\tlio->ifidx),\n\t\t    CFG_GET_NUM_RX_BUF_SIZE_NIC_IF(octeon_get_conf(octeon_dev),\n\t\t\t\t\t\t   lio->ifidx),\n\t\t    NULL);\n\t\tif (retval) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"%s : Runtime DROQ(RxQ) creation failed.\\n\",\n\t\t\t\t__func__);\n\t\t\treturn 1;\n\t\t}\n\n\t\tdroq = octeon_dev->droq[q_no];\n\t\tnapi = &droq->napi;\n\t\tdev_dbg(&octeon_dev->pci_dev->dev, \"netif_napi_add netdev:%llx oct:%llx\\n\",\n\t\t\t(u64)netdev, (u64)octeon_dev);\n\t\tnetif_napi_add(netdev, napi, liquidio_napi_poll);\n\n\t\t \n\t\tdroq->cpu_id = cpu_id;\n\t\tcpu_id++;\n\t\tif (cpu_id >= cpu_id_modulus)\n\t\t\tcpu_id = 0;\n\n\t\tocteon_register_droq_ops(octeon_dev, q_no, &droq_ops);\n\t}\n\n\tif (OCTEON_CN23XX_PF(octeon_dev) || OCTEON_CN23XX_VF(octeon_dev)) {\n\t\t \n\t\tocteon_dev->droq[0]->ops.poll_mode = 0;\n\t}\n\n\t \n\tfor (q = 0; q < num_iqs; q++) {\n\t\tnum_tx_descs = CFG_GET_NUM_TX_DESCS_NIC_IF(\n\t\t    octeon_get_conf(octeon_dev), lio->ifidx);\n\t\tretval = octeon_setup_iq(octeon_dev, ifidx, q,\n\t\t\t\t\t lio->linfo.txpciq[q], num_tx_descs,\n\t\t\t\t\t netdev_get_tx_queue(netdev, q));\n\t\tif (retval) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\" %s : Runtime IQ(TxQ) creation failed.\\n\",\n\t\t\t\t__func__);\n\t\t\treturn 1;\n\t\t}\n\n\t\t \n\t\tif (!OCTEON_CN23XX_VF(octeon_dev) && octeon_dev->msix_on &&\n\t\t    octeon_dev->ioq_vector) {\n\t\t\tstruct octeon_ioq_vector    *ioq_vector;\n\n\t\t\tioq_vector = &octeon_dev->ioq_vector[q];\n\t\t\tnetif_set_xps_queue(netdev,\n\t\t\t\t\t    &ioq_vector->affinity_mask,\n\t\t\t\t\t    ioq_vector->iq_index);\n\t\t}\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(liquidio_setup_io_queues);\n\nstatic\nint liquidio_schedule_msix_droq_pkt_handler(struct octeon_droq *droq, u64 ret)\n{\n\tstruct octeon_device *oct = droq->oct_dev;\n\tstruct octeon_device_priv *oct_priv =\n\t    (struct octeon_device_priv *)oct->priv;\n\n\tif (droq->ops.poll_mode) {\n\t\tdroq->ops.napi_fn(droq);\n\t} else {\n\t\tif (ret & MSIX_PO_INT) {\n\t\t\tif (OCTEON_CN23XX_VF(oct))\n\t\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\t\"should not come here should not get rx when poll mode = 0 for vf\\n\");\n\t\t\ttasklet_schedule(&oct_priv->droq_tasklet);\n\t\t\treturn 1;\n\t\t}\n\t\t \n\t\tif (ret & MSIX_PI_INT)\n\t\t\treturn 0;\n\t}\n\n\treturn 0;\n}\n\nirqreturn_t\nliquidio_msix_intr_handler(int __maybe_unused irq, void *dev)\n{\n\tstruct octeon_ioq_vector *ioq_vector = (struct octeon_ioq_vector *)dev;\n\tstruct octeon_device *oct = ioq_vector->oct_dev;\n\tstruct octeon_droq *droq = oct->droq[ioq_vector->droq_index];\n\tu64 ret;\n\n\tret = oct->fn_list.msix_interrupt_handler(ioq_vector);\n\n\tif (ret & MSIX_PO_INT || ret & MSIX_PI_INT)\n\t\tliquidio_schedule_msix_droq_pkt_handler(droq, ret);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void liquidio_schedule_droq_pkt_handlers(struct octeon_device *oct)\n{\n\tstruct octeon_device_priv *oct_priv =\n\t\t(struct octeon_device_priv *)oct->priv;\n\tstruct octeon_droq *droq;\n\tu64 oq_no;\n\n\tif (oct->int_status & OCT_DEV_INTR_PKT_DATA) {\n\t\tfor (oq_no = 0; oq_no < MAX_OCTEON_OUTPUT_QUEUES(oct);\n\t\t     oq_no++) {\n\t\t\tif (!(oct->droq_intr & BIT_ULL(oq_no)))\n\t\t\t\tcontinue;\n\n\t\t\tdroq = oct->droq[oq_no];\n\n\t\t\tif (droq->ops.poll_mode) {\n\t\t\t\tdroq->ops.napi_fn(droq);\n\t\t\t\toct_priv->napi_mask |= BIT_ULL(oq_no);\n\t\t\t} else {\n\t\t\t\ttasklet_schedule(&oct_priv->droq_tasklet);\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic\nirqreturn_t liquidio_legacy_intr_handler(int __maybe_unused irq, void *dev)\n{\n\tstruct octeon_device *oct = (struct octeon_device *)dev;\n\tirqreturn_t ret;\n\n\t \n\toct->fn_list.disable_interrupt(oct, OCTEON_ALL_INTR);\n\n\tret = oct->fn_list.process_interrupt_regs(oct);\n\n\tif (ret == IRQ_HANDLED)\n\t\tliquidio_schedule_droq_pkt_handlers(oct);\n\n\t \n\tif (!(atomic_read(&oct->status) == OCT_DEV_IN_RESET))\n\t\toct->fn_list.enable_interrupt(oct, OCTEON_ALL_INTR);\n\n\treturn ret;\n}\n\n \nint octeon_setup_interrupt(struct octeon_device *oct, u32 num_ioqs)\n{\n\tstruct msix_entry *msix_entries;\n\tchar *queue_irq_names = NULL;\n\tint i, num_interrupts = 0;\n\tint num_alloc_ioq_vectors;\n\tchar *aux_irq_name = NULL;\n\tint num_ioq_vectors;\n\tint irqret, err;\n\n\tif (oct->msix_on) {\n\t\toct->num_msix_irqs = num_ioqs;\n\t\tif (OCTEON_CN23XX_PF(oct)) {\n\t\t\tnum_interrupts = MAX_IOQ_INTERRUPTS_PER_PF + 1;\n\n\t\t\t \n\t\t\toct->num_msix_irqs += 1;\n\t\t} else if (OCTEON_CN23XX_VF(oct)) {\n\t\t\tnum_interrupts = MAX_IOQ_INTERRUPTS_PER_VF;\n\t\t}\n\n\t\t \n\t\toct->irq_name_storage =\n\t\t\tkcalloc(num_interrupts, INTRNAMSIZ, GFP_KERNEL);\n\t\tif (!oct->irq_name_storage) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"Irq name storage alloc failed...\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tqueue_irq_names = oct->irq_name_storage;\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\taux_irq_name = &queue_irq_names\n\t\t\t\t[IRQ_NAME_OFF(MAX_IOQ_INTERRUPTS_PER_PF)];\n\n\t\toct->msix_entries = kcalloc(oct->num_msix_irqs,\n\t\t\t\t\t    sizeof(struct msix_entry),\n\t\t\t\t\t    GFP_KERNEL);\n\t\tif (!oct->msix_entries) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"Memory Alloc failed...\\n\");\n\t\t\tkfree(oct->irq_name_storage);\n\t\t\toct->irq_name_storage = NULL;\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tmsix_entries = (struct msix_entry *)oct->msix_entries;\n\n\t\t \n\t\tif (OCTEON_CN23XX_PF(oct)) {\n\t\t\tfor (i = 0; i < oct->num_msix_irqs - 1; i++)\n\t\t\t\tmsix_entries[i].entry =\n\t\t\t\t\toct->sriov_info.pf_srn + i;\n\n\t\t\tmsix_entries[oct->num_msix_irqs - 1].entry =\n\t\t\t\toct->sriov_info.trs;\n\t\t} else if (OCTEON_CN23XX_VF(oct)) {\n\t\t\tfor (i = 0; i < oct->num_msix_irqs; i++)\n\t\t\t\tmsix_entries[i].entry = i;\n\t\t}\n\t\tnum_alloc_ioq_vectors = pci_enable_msix_range(\n\t\t\t\t\t\toct->pci_dev, msix_entries,\n\t\t\t\t\t\toct->num_msix_irqs,\n\t\t\t\t\t\toct->num_msix_irqs);\n\t\tif (num_alloc_ioq_vectors < 0) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"unable to Allocate MSI-X interrupts\\n\");\n\t\t\tkfree(oct->msix_entries);\n\t\t\toct->msix_entries = NULL;\n\t\t\tkfree(oct->irq_name_storage);\n\t\t\toct->irq_name_storage = NULL;\n\t\t\treturn num_alloc_ioq_vectors;\n\t\t}\n\n\t\tdev_dbg(&oct->pci_dev->dev, \"OCTEON: Enough MSI-X interrupts are allocated...\\n\");\n\n\t\tnum_ioq_vectors = oct->num_msix_irqs;\n\t\t \n\t\tif (OCTEON_CN23XX_PF(oct)) {\n\t\t\tnum_ioq_vectors -= 1;\n\n\t\t\tsnprintf(aux_irq_name, INTRNAMSIZ,\n\t\t\t\t \"LiquidIO%u-pf%u-aux\", oct->octeon_id,\n\t\t\t\t oct->pf_num);\n\t\t\tirqret = request_irq(\n\t\t\t\t\tmsix_entries[num_ioq_vectors].vector,\n\t\t\t\t\tliquidio_legacy_intr_handler, 0,\n\t\t\t\t\taux_irq_name, oct);\n\t\t\tif (irqret) {\n\t\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\t\"Request_irq failed for MSIX interrupt Error: %d\\n\",\n\t\t\t\t\tirqret);\n\t\t\t\tpci_disable_msix(oct->pci_dev);\n\t\t\t\tkfree(oct->msix_entries);\n\t\t\t\tkfree(oct->irq_name_storage);\n\t\t\t\toct->irq_name_storage = NULL;\n\t\t\t\toct->msix_entries = NULL;\n\t\t\t\treturn irqret;\n\t\t\t}\n\t\t}\n\t\tfor (i = 0 ; i < num_ioq_vectors ; i++) {\n\t\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\t\tsnprintf(&queue_irq_names[IRQ_NAME_OFF(i)],\n\t\t\t\t\t INTRNAMSIZ, \"LiquidIO%u-pf%u-rxtx-%u\",\n\t\t\t\t\t oct->octeon_id, oct->pf_num, i);\n\n\t\t\tif (OCTEON_CN23XX_VF(oct))\n\t\t\t\tsnprintf(&queue_irq_names[IRQ_NAME_OFF(i)],\n\t\t\t\t\t INTRNAMSIZ, \"LiquidIO%u-vf%u-rxtx-%u\",\n\t\t\t\t\t oct->octeon_id, oct->vf_num, i);\n\n\t\t\tirqret = request_irq(msix_entries[i].vector,\n\t\t\t\t\t     liquidio_msix_intr_handler, 0,\n\t\t\t\t\t     &queue_irq_names[IRQ_NAME_OFF(i)],\n\t\t\t\t\t     &oct->ioq_vector[i]);\n\n\t\t\tif (irqret) {\n\t\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\t\"Request_irq failed for MSIX interrupt Error: %d\\n\",\n\t\t\t\t\tirqret);\n\t\t\t\t \n\t\t\t\tfree_irq(msix_entries[num_ioq_vectors].vector,\n\t\t\t\t\t oct);\n\n\t\t\t\twhile (i) {\n\t\t\t\t\ti--;\n\t\t\t\t\t \n\t\t\t\t\tirq_set_affinity_hint(\n\t\t\t\t\t\t      msix_entries[i].vector,\n\t\t\t\t\t\t      NULL);\n\t\t\t\t\tfree_irq(msix_entries[i].vector,\n\t\t\t\t\t\t &oct->ioq_vector[i]);\n\t\t\t\t}\n\t\t\t\tpci_disable_msix(oct->pci_dev);\n\t\t\t\tkfree(oct->msix_entries);\n\t\t\t\tkfree(oct->irq_name_storage);\n\t\t\t\toct->irq_name_storage = NULL;\n\t\t\t\toct->msix_entries = NULL;\n\t\t\t\treturn irqret;\n\t\t\t}\n\t\t\toct->ioq_vector[i].vector = msix_entries[i].vector;\n\t\t\t \n\t\t\tirq_set_affinity_hint(msix_entries[i].vector,\n\t\t\t\t\t      &oct->ioq_vector[i].affinity_mask\n\t\t\t\t\t      );\n\t\t}\n\t\tdev_dbg(&oct->pci_dev->dev, \"OCTEON[%d]: MSI-X enabled\\n\",\n\t\t\toct->octeon_id);\n\t} else {\n\t\terr = pci_enable_msi(oct->pci_dev);\n\t\tif (err)\n\t\t\tdev_warn(&oct->pci_dev->dev, \"Reverting to legacy interrupts. Error: %d\\n\",\n\t\t\t\t err);\n\t\telse\n\t\t\toct->flags |= LIO_FLAG_MSI_ENABLED;\n\n\t\t \n\t\toct->irq_name_storage = kzalloc(INTRNAMSIZ, GFP_KERNEL);\n\t\tif (!oct->irq_name_storage)\n\t\t\treturn -ENOMEM;\n\n\t\tqueue_irq_names = oct->irq_name_storage;\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\tsnprintf(&queue_irq_names[IRQ_NAME_OFF(0)], INTRNAMSIZ,\n\t\t\t\t \"LiquidIO%u-pf%u-rxtx-%u\",\n\t\t\t\t oct->octeon_id, oct->pf_num, 0);\n\n\t\tif (OCTEON_CN23XX_VF(oct))\n\t\t\tsnprintf(&queue_irq_names[IRQ_NAME_OFF(0)], INTRNAMSIZ,\n\t\t\t\t \"LiquidIO%u-vf%u-rxtx-%u\",\n\t\t\t\t oct->octeon_id, oct->vf_num, 0);\n\n\t\tirqret = request_irq(oct->pci_dev->irq,\n\t\t\t\t     liquidio_legacy_intr_handler,\n\t\t\t\t     IRQF_SHARED,\n\t\t\t\t     &queue_irq_names[IRQ_NAME_OFF(0)], oct);\n\t\tif (irqret) {\n\t\t\tif (oct->flags & LIO_FLAG_MSI_ENABLED)\n\t\t\t\tpci_disable_msi(oct->pci_dev);\n\t\t\tdev_err(&oct->pci_dev->dev, \"Request IRQ failed with code: %d\\n\",\n\t\t\t\tirqret);\n\t\t\tkfree(oct->irq_name_storage);\n\t\t\toct->irq_name_storage = NULL;\n\t\t\treturn irqret;\n\t\t}\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(octeon_setup_interrupt);\n\n \nint liquidio_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octeon_soft_command *sc;\n\tunion octnet_cmd *ncmd;\n\tint ret = 0;\n\n\tsc = (struct octeon_soft_command *)\n\t\tocteon_alloc_soft_command(oct, OCTNET_CMD_SIZE, 16, 0);\n\tif (!sc) {\n\t\tnetif_info(lio, rx_err, lio->netdev,\n\t\t\t   \"Failed to allocate soft command\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tncmd = (union octnet_cmd *)sc->virtdptr;\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tncmd->u64 = 0;\n\tncmd->s.cmd = OCTNET_CMD_CHANGE_MTU;\n\tncmd->s.param1 = new_mtu;\n\n\tocteon_swap_8B_data((u64 *)ncmd, (OCTNET_CMD_SIZE >> 3));\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_CMD, 0, 0, 0);\n\n\tret = octeon_send_soft_command(oct, sc);\n\tif (ret == IQ_SEND_FAILED) {\n\t\tnetif_info(lio, rx_err, lio->netdev, \"Failed to change MTU\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t\treturn -EINVAL;\n\t}\n\t \n\tret = wait_for_sc_completion_timeout(oct, sc, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tif (sc->sc_status) {\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\treturn -EINVAL;\n\t}\n\n\tnetdev->mtu = new_mtu;\n\tlio->mtu = new_mtu;\n\n\tWRITE_ONCE(sc->caller_is_done, true);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(liquidio_change_mtu);\n\nint lio_wait_for_clean_oq(struct octeon_device *oct)\n{\n\tint retry = 100, pending_pkts = 0;\n\tint idx;\n\n\tdo {\n\t\tpending_pkts = 0;\n\n\t\tfor (idx = 0; idx < MAX_OCTEON_OUTPUT_QUEUES(oct); idx++) {\n\t\t\tif (!(oct->io_qmask.oq & BIT_ULL(idx)))\n\t\t\t\tcontinue;\n\t\t\tpending_pkts +=\n\t\t\t\tatomic_read(&oct->droq[idx]->pkts_pending);\n\t\t}\n\n\t\tif (pending_pkts > 0)\n\t\t\tschedule_timeout_uninterruptible(1);\n\n\t} while (retry-- && pending_pkts);\n\n\treturn pending_pkts;\n}\nEXPORT_SYMBOL_GPL(lio_wait_for_clean_oq);\n\nstatic void\noctnet_nic_stats_callback(struct octeon_device *oct_dev,\n\t\t\t  u32 status, void *ptr)\n{\n\tstruct octeon_soft_command *sc = (struct octeon_soft_command *)ptr;\n\tstruct oct_nic_stats_resp *resp =\n\t    (struct oct_nic_stats_resp *)sc->virtrptr;\n\tstruct nic_rx_stats *rsp_rstats = &resp->stats.fromwire;\n\tstruct nic_tx_stats *rsp_tstats = &resp->stats.fromhost;\n\tstruct nic_rx_stats *rstats = &oct_dev->link_stats.fromwire;\n\tstruct nic_tx_stats *tstats = &oct_dev->link_stats.fromhost;\n\n\tif (status != OCTEON_REQUEST_TIMEOUT && !resp->status) {\n\t\tocteon_swap_8B_data((u64 *)&resp->stats,\n\t\t\t\t    (sizeof(struct oct_link_stats)) >> 3);\n\n\t\t \n\t\trstats->total_rcvd = rsp_rstats->total_rcvd;\n\t\trstats->bytes_rcvd = rsp_rstats->bytes_rcvd;\n\t\trstats->total_bcst = rsp_rstats->total_bcst;\n\t\trstats->total_mcst = rsp_rstats->total_mcst;\n\t\trstats->runts      = rsp_rstats->runts;\n\t\trstats->ctl_rcvd   = rsp_rstats->ctl_rcvd;\n\t\t \n\t\trstats->fifo_err  = rsp_rstats->fifo_err;\n\t\trstats->dmac_drop = rsp_rstats->dmac_drop;\n\t\trstats->fcs_err   = rsp_rstats->fcs_err;\n\t\trstats->jabber_err = rsp_rstats->jabber_err;\n\t\trstats->l2_err    = rsp_rstats->l2_err;\n\t\trstats->frame_err = rsp_rstats->frame_err;\n\t\trstats->red_drops = rsp_rstats->red_drops;\n\n\t\t \n\t\trstats->fw_total_rcvd = rsp_rstats->fw_total_rcvd;\n\t\trstats->fw_total_fwd = rsp_rstats->fw_total_fwd;\n\t\trstats->fw_total_mcast = rsp_rstats->fw_total_mcast;\n\t\trstats->fw_total_bcast = rsp_rstats->fw_total_bcast;\n\t\trstats->fw_err_pko = rsp_rstats->fw_err_pko;\n\t\trstats->fw_err_link = rsp_rstats->fw_err_link;\n\t\trstats->fw_err_drop = rsp_rstats->fw_err_drop;\n\t\trstats->fw_rx_vxlan = rsp_rstats->fw_rx_vxlan;\n\t\trstats->fw_rx_vxlan_err = rsp_rstats->fw_rx_vxlan_err;\n\n\t\t \n\t\trstats->fw_lro_pkts = rsp_rstats->fw_lro_pkts;\n\t\t \n\t\trstats->fw_lro_octs = rsp_rstats->fw_lro_octs;\n\t\t \n\t\trstats->fw_total_lro = rsp_rstats->fw_total_lro;\n\t\t \n\t\trstats->fw_lro_aborts = rsp_rstats->fw_lro_aborts;\n\t\trstats->fw_lro_aborts_port = rsp_rstats->fw_lro_aborts_port;\n\t\trstats->fw_lro_aborts_seq = rsp_rstats->fw_lro_aborts_seq;\n\t\trstats->fw_lro_aborts_tsval = rsp_rstats->fw_lro_aborts_tsval;\n\t\trstats->fw_lro_aborts_timer = rsp_rstats->fw_lro_aborts_timer;\n\t\t \n\t\trstats->fwd_rate = rsp_rstats->fwd_rate;\n\n\t\t \n\t\ttstats->total_pkts_sent = rsp_tstats->total_pkts_sent;\n\t\ttstats->total_bytes_sent = rsp_tstats->total_bytes_sent;\n\t\ttstats->mcast_pkts_sent = rsp_tstats->mcast_pkts_sent;\n\t\ttstats->bcast_pkts_sent = rsp_tstats->bcast_pkts_sent;\n\t\ttstats->ctl_sent = rsp_tstats->ctl_sent;\n\t\t \n\t\ttstats->one_collision_sent = rsp_tstats->one_collision_sent;\n\t\t \n\t\ttstats->multi_collision_sent = rsp_tstats->multi_collision_sent;\n\t\t \n\t\ttstats->max_collision_fail = rsp_tstats->max_collision_fail;\n\t\t \n\t\ttstats->max_deferral_fail = rsp_tstats->max_deferral_fail;\n\t\t \n\t\ttstats->fifo_err = rsp_tstats->fifo_err;\n\t\ttstats->runts = rsp_tstats->runts;\n\t\t \n\t\ttstats->total_collisions = rsp_tstats->total_collisions;\n\n\t\t \n\t\ttstats->fw_total_sent = rsp_tstats->fw_total_sent;\n\t\ttstats->fw_total_fwd = rsp_tstats->fw_total_fwd;\n\t\ttstats->fw_total_mcast_sent = rsp_tstats->fw_total_mcast_sent;\n\t\ttstats->fw_total_bcast_sent = rsp_tstats->fw_total_bcast_sent;\n\t\ttstats->fw_err_pko = rsp_tstats->fw_err_pko;\n\t\ttstats->fw_err_pki = rsp_tstats->fw_err_pki;\n\t\ttstats->fw_err_link = rsp_tstats->fw_err_link;\n\t\ttstats->fw_err_drop = rsp_tstats->fw_err_drop;\n\t\ttstats->fw_tso = rsp_tstats->fw_tso;\n\t\ttstats->fw_tso_fwd = rsp_tstats->fw_tso_fwd;\n\t\ttstats->fw_err_tso = rsp_tstats->fw_err_tso;\n\t\ttstats->fw_tx_vxlan = rsp_tstats->fw_tx_vxlan;\n\n\t\tresp->status = 1;\n\t} else {\n\t\tdev_err(&oct_dev->pci_dev->dev, \"sc OPCODE_NIC_PORT_STATS command failed\\n\");\n\t\tresp->status = -1;\n\t}\n}\n\nstatic int lio_fetch_vf_stats(struct lio *lio)\n{\n\tstruct octeon_device *oct_dev = lio->oct_dev;\n\tstruct octeon_soft_command *sc;\n\tstruct oct_nic_vf_stats_resp *resp;\n\n\tint retval;\n\n\t \n\tsc = (struct octeon_soft_command *)\n\t\tocteon_alloc_soft_command(oct_dev,\n\t\t\t\t\t  0,\n\t\t\t\t\t  sizeof(struct oct_nic_vf_stats_resp),\n\t\t\t\t\t  0);\n\n\tif (!sc) {\n\t\tdev_err(&oct_dev->pci_dev->dev, \"Soft command allocation failed\\n\");\n\t\tretval = -ENOMEM;\n\t\tgoto lio_fetch_vf_stats_exit;\n\t}\n\n\tresp = (struct oct_nic_vf_stats_resp *)sc->virtrptr;\n\tmemset(resp, 0, sizeof(struct oct_nic_vf_stats_resp));\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct_dev, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_VF_PORT_STATS, 0, 0, 0);\n\n\tretval = octeon_send_soft_command(oct_dev, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tocteon_free_soft_command(oct_dev, sc);\n\t\tgoto lio_fetch_vf_stats_exit;\n\t}\n\n\tretval =\n\t\twait_for_sc_completion_timeout(oct_dev, sc,\n\t\t\t\t\t       (2 * LIO_SC_MAX_TMO_MS));\n\tif (retval)  {\n\t\tdev_err(&oct_dev->pci_dev->dev,\n\t\t\t\"sc OPCODE_NIC_VF_PORT_STATS command failed\\n\");\n\t\tgoto lio_fetch_vf_stats_exit;\n\t}\n\n\tif (sc->sc_status != OCTEON_REQUEST_TIMEOUT && !resp->status) {\n\t\tocteon_swap_8B_data((u64 *)&resp->spoofmac_cnt,\n\t\t\t\t    (sizeof(u64)) >> 3);\n\n\t\tif (resp->spoofmac_cnt != 0) {\n\t\t\tdev_warn(&oct_dev->pci_dev->dev,\n\t\t\t\t \"%llu Spoofed packets detected\\n\",\n\t\t\t\t resp->spoofmac_cnt);\n\t\t}\n\t}\n\tWRITE_ONCE(sc->caller_is_done, 1);\n\nlio_fetch_vf_stats_exit:\n\treturn retval;\n}\n\nvoid lio_fetch_stats(struct work_struct *work)\n{\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\tstruct lio *lio = wk->ctxptr;\n\tstruct octeon_device *oct_dev = lio->oct_dev;\n\tstruct octeon_soft_command *sc;\n\tstruct oct_nic_stats_resp *resp;\n\tunsigned long time_in_jiffies;\n\tint retval;\n\n\tif (OCTEON_CN23XX_PF(oct_dev)) {\n\t\t \n\t\tif (!(oct_dev->vfstats_poll % LIO_VFSTATS_POLL) &&\n\t\t    (oct_dev->fw_info.app_cap_flags & LIQUIDIO_SPOOFCHK_CAP) &&\n\t\t    oct_dev->sriov_info.num_vfs_alloced) {\n\t\t\tlio_fetch_vf_stats(lio);\n\t\t}\n\n\t\toct_dev->vfstats_poll++;\n\t}\n\n\t \n\tsc = (struct octeon_soft_command *)\n\t\tocteon_alloc_soft_command(oct_dev,\n\t\t\t\t\t  0,\n\t\t\t\t\t  sizeof(struct oct_nic_stats_resp),\n\t\t\t\t\t  0);\n\n\tif (!sc) {\n\t\tdev_err(&oct_dev->pci_dev->dev, \"Soft command allocation failed\\n\");\n\t\tgoto lio_fetch_stats_exit;\n\t}\n\n\tresp = (struct oct_nic_stats_resp *)sc->virtrptr;\n\tmemset(resp, 0, sizeof(struct oct_nic_stats_resp));\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct_dev, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_PORT_STATS, 0, 0, 0);\n\n\tretval = octeon_send_soft_command(oct_dev, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tocteon_free_soft_command(oct_dev, sc);\n\t\tgoto lio_fetch_stats_exit;\n\t}\n\n\tretval = wait_for_sc_completion_timeout(oct_dev, sc,\n\t\t\t\t\t\t(2 * LIO_SC_MAX_TMO_MS));\n\tif (retval)  {\n\t\tdev_err(&oct_dev->pci_dev->dev, \"sc OPCODE_NIC_PORT_STATS command failed\\n\");\n\t\tgoto lio_fetch_stats_exit;\n\t}\n\n\toctnet_nic_stats_callback(oct_dev, sc->sc_status, sc);\n\tWRITE_ONCE(sc->caller_is_done, true);\n\nlio_fetch_stats_exit:\n\ttime_in_jiffies = msecs_to_jiffies(LIQUIDIO_NDEV_STATS_POLL_TIME_MS);\n\tif (ifstate_check(lio, LIO_IFSTATE_RUNNING))\n\t\tschedule_delayed_work(&lio->stats_wk.work, time_in_jiffies);\n\n\treturn;\n}\nEXPORT_SYMBOL_GPL(lio_fetch_stats);\n\nint liquidio_set_speed(struct lio *lio, int speed)\n{\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct oct_nic_seapi_resp *resp;\n\tstruct octeon_soft_command *sc;\n\tunion octnet_cmd *ncmd;\n\tint retval;\n\tu32 var;\n\n\tif (oct->speed_setting == speed)\n\t\treturn 0;\n\n\tif (!OCTEON_CN23XX_PF(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s: SET SPEED only for PF\\n\",\n\t\t\t__func__);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tsc = octeon_alloc_soft_command(oct, OCTNET_CMD_SIZE,\n\t\t\t\t       sizeof(struct oct_nic_seapi_resp),\n\t\t\t\t       0);\n\tif (!sc)\n\t\treturn -ENOMEM;\n\n\tncmd = sc->virtdptr;\n\tresp = sc->virtrptr;\n\tmemset(resp, 0, sizeof(struct oct_nic_seapi_resp));\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tncmd->u64 = 0;\n\tncmd->s.cmd = SEAPI_CMD_SPEED_SET;\n\tncmd->s.param1 = speed;\n\n\tocteon_swap_8B_data((u64 *)ncmd, (OCTNET_CMD_SIZE >> 3));\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_UBOOT_CTL, 0, 0, 0);\n\n\tretval = octeon_send_soft_command(oct, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tdev_info(&oct->pci_dev->dev, \"Failed to send soft command\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t\tretval = -EBUSY;\n\t} else {\n\t\t \n\t\tretval = wait_for_sc_completion_timeout(oct, sc, 0);\n\t\tif (retval)\n\t\t\treturn retval;\n\n\t\tretval = resp->status;\n\n\t\tif (retval) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"%s failed, retval=%d\\n\",\n\t\t\t\t__func__, retval);\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tvar = be32_to_cpu((__force __be32)resp->speed);\n\t\tif (var != speed) {\n\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\"%s: setting failed speed= %x, expect %x\\n\",\n\t\t\t\t__func__, var, speed);\n\t\t}\n\n\t\toct->speed_setting = var;\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t}\n\n\treturn retval;\n}\n\nint liquidio_get_speed(struct lio *lio)\n{\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct oct_nic_seapi_resp *resp;\n\tstruct octeon_soft_command *sc;\n\tunion octnet_cmd *ncmd;\n\tint retval;\n\n\tsc = octeon_alloc_soft_command(oct, OCTNET_CMD_SIZE,\n\t\t\t\t       sizeof(struct oct_nic_seapi_resp),\n\t\t\t\t       0);\n\tif (!sc)\n\t\treturn -ENOMEM;\n\n\tncmd = sc->virtdptr;\n\tresp = sc->virtrptr;\n\tmemset(resp, 0, sizeof(struct oct_nic_seapi_resp));\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tncmd->u64 = 0;\n\tncmd->s.cmd = SEAPI_CMD_SPEED_GET;\n\n\tocteon_swap_8B_data((u64 *)ncmd, (OCTNET_CMD_SIZE >> 3));\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_UBOOT_CTL, 0, 0, 0);\n\n\tretval = octeon_send_soft_command(oct, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tdev_info(&oct->pci_dev->dev, \"Failed to send soft command\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t\tretval = -EIO;\n\t} else {\n\t\tretval = wait_for_sc_completion_timeout(oct, sc, 0);\n\t\tif (retval)\n\t\t\treturn retval;\n\n\t\tretval = resp->status;\n\t\tif (retval) {\n\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\"%s failed retval=%d\\n\", __func__, retval);\n\t\t\tretval = -EIO;\n\t\t} else {\n\t\t\tu32 var;\n\n\t\t\tvar = be32_to_cpu((__force __be32)resp->speed);\n\t\t\toct->speed_setting = var;\n\t\t\tif (var == 0xffff) {\n\t\t\t\t \n\t\t\t\tif (oct->subsystem_id ==\n\t\t\t\t\t\tOCTEON_CN2350_25GB_SUBSYS_ID ||\n\t\t\t\t    oct->subsystem_id ==\n\t\t\t\t\t\tOCTEON_CN2360_25GB_SUBSYS_ID) {\n\t\t\t\t\toct->no_speed_setting = 1;\n\t\t\t\t\toct->speed_setting = 25;\n\t\t\t\t} else {\n\t\t\t\t\toct->speed_setting = 10;\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t}\n\n\treturn retval;\n}\nEXPORT_SYMBOL_GPL(liquidio_get_speed);\n\nint liquidio_set_fec(struct lio *lio, int on_off)\n{\n\tstruct oct_nic_seapi_resp *resp;\n\tstruct octeon_soft_command *sc;\n\tstruct octeon_device *oct;\n\tunion octnet_cmd *ncmd;\n\tint retval;\n\tu32 var;\n\n\toct = lio->oct_dev;\n\n\tif (oct->props[lio->ifidx].fec == on_off)\n\t\treturn 0;\n\n\tif (!OCTEON_CN23XX_PF(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s: SET FEC only for PF\\n\",\n\t\t\t__func__);\n\t\treturn -1;\n\t}\n\n\tif (oct->speed_boot != 25)  {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Set FEC only when link speed is 25G during insmod\\n\");\n\t\treturn -1;\n\t}\n\n\tsc = octeon_alloc_soft_command(oct, OCTNET_CMD_SIZE,\n\t\t\t\t       sizeof(struct oct_nic_seapi_resp), 0);\n\tif (!sc) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Failed to allocate soft command\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tncmd = sc->virtdptr;\n\tresp = sc->virtrptr;\n\tmemset(resp, 0, sizeof(struct oct_nic_seapi_resp));\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tncmd->u64 = 0;\n\tncmd->s.cmd = SEAPI_CMD_FEC_SET;\n\tncmd->s.param1 = on_off;\n\t \n\n\tocteon_swap_8B_data((u64 *)ncmd, (OCTNET_CMD_SIZE >> 3));\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_UBOOT_CTL, 0, 0, 0);\n\n\tretval = octeon_send_soft_command(oct, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tdev_info(&oct->pci_dev->dev, \"Failed to send soft command\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t\treturn -EIO;\n\t}\n\n\tretval = wait_for_sc_completion_timeout(oct, sc, 0);\n\tif (retval)\n\t\treturn (-EIO);\n\n\tvar = be32_to_cpu(resp->fec_setting);\n\tresp->fec_setting = var;\n\tif (var != on_off) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Setting failed fec= %x, expect %x\\n\",\n\t\t\tvar, on_off);\n\t\toct->props[lio->ifidx].fec = var;\n\t\tif (resp->fec_setting == SEAPI_CMD_FEC_SET_RS)\n\t\t\toct->props[lio->ifidx].fec = 1;\n\t\telse\n\t\t\toct->props[lio->ifidx].fec = 0;\n\t}\n\n\tWRITE_ONCE(sc->caller_is_done, true);\n\n\tif (oct->props[lio->ifidx].fec !=\n\t    oct->props[lio->ifidx].fec_boot) {\n\t\tdev_dbg(&oct->pci_dev->dev,\n\t\t\t\"Reload driver to change fec to %s\\n\",\n\t\t\toct->props[lio->ifidx].fec ? \"on\" : \"off\");\n\t}\n\n\treturn retval;\n}\n\nint liquidio_get_fec(struct lio *lio)\n{\n\tstruct oct_nic_seapi_resp *resp;\n\tstruct octeon_soft_command *sc;\n\tstruct octeon_device *oct;\n\tunion octnet_cmd *ncmd;\n\tint retval;\n\tu32 var;\n\n\toct = lio->oct_dev;\n\n\tsc = octeon_alloc_soft_command(oct, OCTNET_CMD_SIZE,\n\t\t\t\t       sizeof(struct oct_nic_seapi_resp), 0);\n\tif (!sc)\n\t\treturn -ENOMEM;\n\n\tncmd = sc->virtdptr;\n\tresp = sc->virtrptr;\n\tmemset(resp, 0, sizeof(struct oct_nic_seapi_resp));\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tncmd->u64 = 0;\n\tncmd->s.cmd = SEAPI_CMD_FEC_GET;\n\n\tocteon_swap_8B_data((u64 *)ncmd, (OCTNET_CMD_SIZE >> 3));\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_UBOOT_CTL, 0, 0, 0);\n\n\tretval = octeon_send_soft_command(oct, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t \"%s: Failed to send soft command\\n\", __func__);\n\t\tocteon_free_soft_command(oct, sc);\n\t\treturn -EIO;\n\t}\n\n\tretval = wait_for_sc_completion_timeout(oct, sc, 0);\n\tif (retval)\n\t\treturn retval;\n\n\tvar = be32_to_cpu(resp->fec_setting);\n\tresp->fec_setting = var;\n\tif (resp->fec_setting == SEAPI_CMD_FEC_SET_RS)\n\t\toct->props[lio->ifidx].fec = 1;\n\telse\n\t\toct->props[lio->ifidx].fec = 0;\n\n\tWRITE_ONCE(sc->caller_is_done, true);\n\n\tif (oct->props[lio->ifidx].fec !=\n\t    oct->props[lio->ifidx].fec_boot) {\n\t\tdev_dbg(&oct->pci_dev->dev,\n\t\t\t\"Reload driver to change fec to %s\\n\",\n\t\t\toct->props[lio->ifidx].fec ? \"on\" : \"off\");\n\t}\n\n\treturn retval;\n}\nEXPORT_SYMBOL_GPL(liquidio_get_fec);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}