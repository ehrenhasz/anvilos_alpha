{
  "module_name": "lio_main.c",
  "hash_id": "bb05cec9fc88d0b290e537c9a46aed95b80afa88f6e24baec061b0c0b5ab6925",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/cavium/liquidio/lio_main.c",
  "human_readable_source": " \n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/firmware.h>\n#include <net/vxlan.h>\n#include <linux/kthread.h>\n#include \"liquidio_common.h\"\n#include \"octeon_droq.h\"\n#include \"octeon_iq.h\"\n#include \"response_manager.h\"\n#include \"octeon_device.h\"\n#include \"octeon_nic.h\"\n#include \"octeon_main.h\"\n#include \"octeon_network.h\"\n#include \"cn66xx_regs.h\"\n#include \"cn66xx_device.h\"\n#include \"cn68xx_device.h\"\n#include \"cn23xx_pf_device.h\"\n#include \"liquidio_image.h\"\n#include \"lio_vf_rep.h\"\n\nMODULE_AUTHOR(\"Cavium Networks, <support@cavium.com>\");\nMODULE_DESCRIPTION(\"Cavium LiquidIO Intelligent Server Adapter Driver\");\nMODULE_LICENSE(\"GPL\");\nMODULE_FIRMWARE(LIO_FW_DIR LIO_FW_BASE_NAME LIO_210SV_NAME\n\t\t\"_\" LIO_FW_NAME_TYPE_NIC LIO_FW_NAME_SUFFIX);\nMODULE_FIRMWARE(LIO_FW_DIR LIO_FW_BASE_NAME LIO_210NV_NAME\n\t\t\"_\" LIO_FW_NAME_TYPE_NIC LIO_FW_NAME_SUFFIX);\nMODULE_FIRMWARE(LIO_FW_DIR LIO_FW_BASE_NAME LIO_410NV_NAME\n\t\t\"_\" LIO_FW_NAME_TYPE_NIC LIO_FW_NAME_SUFFIX);\nMODULE_FIRMWARE(LIO_FW_DIR LIO_FW_BASE_NAME LIO_23XX_NAME\n\t\t\"_\" LIO_FW_NAME_TYPE_NIC LIO_FW_NAME_SUFFIX);\n\nstatic int ddr_timeout = 10000;\nmodule_param(ddr_timeout, int, 0644);\nMODULE_PARM_DESC(ddr_timeout,\n\t\t \"Number of milliseconds to wait for DDR initialization. 0 waits for ddr_timeout to be set to non-zero value before starting to check\");\n\n#define DEFAULT_MSG_ENABLE (NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_LINK)\n\nstatic int debug = -1;\nmodule_param(debug, int, 0644);\nMODULE_PARM_DESC(debug, \"NETIF_MSG debug bits\");\n\nstatic char fw_type[LIO_MAX_FW_TYPE_LEN] = LIO_FW_NAME_TYPE_AUTO;\nmodule_param_string(fw_type, fw_type, sizeof(fw_type), 0444);\nMODULE_PARM_DESC(fw_type, \"Type of firmware to be loaded (default is \\\"auto\\\"), which uses firmware in flash, if present, else loads \\\"nic\\\".\");\n\nstatic u32 console_bitmask;\nmodule_param(console_bitmask, int, 0644);\nMODULE_PARM_DESC(console_bitmask,\n\t\t \"Bitmask indicating which consoles have debug output redirected to syslog.\");\n\n \nstatic int octeon_console_debug_enabled(u32 console)\n{\n\treturn (console_bitmask >> (console)) & 0x1;\n}\n\n \n#define LIQUIDIO_STARTER_POLL_INTERVAL_MS 100\n\n \n#define LIQUIDIO_LINK_QUERY_INTERVAL_MS         1000\n \n#define LIO_SYNC_OCTEON_TIME_INTERVAL_MS 60000\n\n \n#define WAIT_INFLIGHT_REQUEST\tmsecs_to_jiffies(1000)\n\nstruct oct_link_status_resp {\n\tu64 rh;\n\tstruct oct_link_info link_info;\n\tu64 status;\n};\n\nstruct oct_timestamp_resp {\n\tu64 rh;\n\tu64 timestamp;\n\tu64 status;\n};\n\n#define OCT_TIMESTAMP_RESP_SIZE (sizeof(struct oct_timestamp_resp))\n\nunion tx_info {\n\tu64 u64;\n\tstruct {\n#ifdef __BIG_ENDIAN_BITFIELD\n\t\tu16 gso_size;\n\t\tu16 gso_segs;\n\t\tu32 reserved;\n#else\n\t\tu32 reserved;\n\t\tu16 gso_segs;\n\t\tu16 gso_size;\n#endif\n\t} s;\n};\n\n \n\n#define OCTNIC_GSO_MAX_HEADER_SIZE 128\n#define OCTNIC_GSO_MAX_SIZE                                                    \\\n\t(CN23XX_DEFAULT_INPUT_JABBER - OCTNIC_GSO_MAX_HEADER_SIZE)\n\nstruct handshake {\n\tstruct completion init;\n\tstruct completion started;\n\tstruct pci_dev *pci_dev;\n\tint init_ok;\n\tint started_ok;\n};\n\n#ifdef CONFIG_PCI_IOV\nstatic int liquidio_enable_sriov(struct pci_dev *dev, int num_vfs);\n#endif\n\nstatic int octeon_dbg_console_print(struct octeon_device *oct, u32 console_num,\n\t\t\t\t    char *prefix, char *suffix);\n\nstatic int octeon_device_init(struct octeon_device *);\nstatic int liquidio_stop(struct net_device *netdev);\nstatic void liquidio_remove(struct pci_dev *pdev);\nstatic int liquidio_probe(struct pci_dev *pdev,\n\t\t\t  const struct pci_device_id *ent);\nstatic int liquidio_set_vf_link_state(struct net_device *netdev, int vfidx,\n\t\t\t\t      int linkstate);\n\nstatic struct handshake handshake[MAX_OCTEON_DEVICES];\nstatic struct completion first_stage;\n\nstatic void octeon_droq_bh(struct tasklet_struct *t)\n{\n\tint q_no;\n\tint reschedule = 0;\n\tstruct octeon_device_priv *oct_priv = from_tasklet(oct_priv, t,\n\t\t\t\t\t\t\t  droq_tasklet);\n\tstruct octeon_device *oct = oct_priv->dev;\n\n\tfor (q_no = 0; q_no < MAX_OCTEON_OUTPUT_QUEUES(oct); q_no++) {\n\t\tif (!(oct->io_qmask.oq & BIT_ULL(q_no)))\n\t\t\tcontinue;\n\t\treschedule |= octeon_droq_process_packets(oct, oct->droq[q_no],\n\t\t\t\t\t\t\t  MAX_PACKET_BUDGET);\n\t\tlio_enable_irq(oct->droq[q_no], NULL);\n\n\t\tif (OCTEON_CN23XX_PF(oct) && oct->msix_on) {\n\t\t\t \n\t\t\tint adjusted_q_no = q_no + oct->sriov_info.pf_srn;\n\n\t\t\tocteon_write_csr64(\n\t\t\t    oct, CN23XX_SLI_OQ_PKT_INT_LEVELS(adjusted_q_no),\n\t\t\t    0x5700000040ULL);\n\t\t\tocteon_write_csr64(\n\t\t\t    oct, CN23XX_SLI_OQ_PKTS_SENT(adjusted_q_no), 0);\n\t\t}\n\t}\n\n\tif (reschedule)\n\t\ttasklet_schedule(&oct_priv->droq_tasklet);\n}\n\nstatic int lio_wait_for_oq_pkts(struct octeon_device *oct)\n{\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tint retry = 100, pkt_cnt = 0, pending_pkts = 0;\n\tint i;\n\n\tdo {\n\t\tpending_pkts = 0;\n\n\t\tfor (i = 0; i < MAX_OCTEON_OUTPUT_QUEUES(oct); i++) {\n\t\t\tif (!(oct->io_qmask.oq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tpkt_cnt += octeon_droq_check_hw_for_pkts(oct->droq[i]);\n\t\t}\n\t\tif (pkt_cnt > 0) {\n\t\t\tpending_pkts += pkt_cnt;\n\t\t\ttasklet_schedule(&oct_priv->droq_tasklet);\n\t\t}\n\t\tpkt_cnt = 0;\n\t\tschedule_timeout_uninterruptible(1);\n\n\t} while (retry-- && pending_pkts);\n\n\treturn pkt_cnt;\n}\n\n \nstatic void force_io_queues_off(struct octeon_device *oct)\n{\n\tif ((oct->chip_id == OCTEON_CN66XX) ||\n\t    (oct->chip_id == OCTEON_CN68XX)) {\n\t\t \n\t\tocteon_write_csr(oct, CN6XXX_SLI_PKT_INSTR_ENB, 0);\n\n\t\t \n\t\tocteon_write_csr(oct, CN6XXX_SLI_PKT_OUT_ENB, 0);\n\t}\n}\n\n \nstatic inline void pcierror_quiesce_device(struct octeon_device *oct)\n{\n\tint i;\n\n\t \n\tforce_io_queues_off(oct);\n\n\t \n\tschedule_timeout_uninterruptible(WAIT_INFLIGHT_REQUEST);\n\n\tif (wait_for_pending_requests(oct))\n\t\tdev_err(&oct->pci_dev->dev, \"There were pending requests\\n\");\n\n\t \n\tfor (i = 0; i < MAX_OCTEON_INSTR_QUEUES(oct); i++) {\n\t\tstruct octeon_instr_queue *iq;\n\n\t\tif (!(oct->io_qmask.iq & BIT_ULL(i)))\n\t\t\tcontinue;\n\t\tiq = oct->instr_queue[i];\n\n\t\tif (atomic_read(&iq->instr_pending)) {\n\t\t\tspin_lock_bh(&iq->lock);\n\t\t\tiq->fill_cnt = 0;\n\t\t\tiq->octeon_read_index = iq->host_write_index;\n\t\t\tiq->stats.instr_processed +=\n\t\t\t\tatomic_read(&iq->instr_pending);\n\t\t\tlio_process_iq_request_list(oct, iq, 0);\n\t\t\tspin_unlock_bh(&iq->lock);\n\t\t}\n\t}\n\n\t \n\tlio_process_ordered_list(oct, 1);\n\n\t \n}\n\n \nstatic void cleanup_aer_uncorrect_error_status(struct pci_dev *dev)\n{\n\tint pos = 0x100;\n\tu32 status, mask;\n\n\tpr_info(\"%s :\\n\", __func__);\n\n\tpci_read_config_dword(dev, pos + PCI_ERR_UNCOR_STATUS, &status);\n\tpci_read_config_dword(dev, pos + PCI_ERR_UNCOR_SEVER, &mask);\n\tif (dev->error_state == pci_channel_io_normal)\n\t\tstatus &= ~mask;         \n\telse\n\t\tstatus &= mask;          \n\tpci_write_config_dword(dev, pos + PCI_ERR_UNCOR_STATUS, status);\n}\n\n \nstatic void stop_pci_io(struct octeon_device *oct)\n{\n\t \n\tatomic_set(&oct->status, OCT_DEV_IN_RESET);\n\n\tpci_disable_device(oct->pci_dev);\n\n\t \n\toct->fn_list.disable_interrupt(oct, OCTEON_ALL_INTR);\n\n\tpcierror_quiesce_device(oct);\n\n\t \n\tfree_irq(oct->pci_dev->irq, oct);\n\n\tif (oct->flags & LIO_FLAG_MSI_ENABLED)\n\t\tpci_disable_msi(oct->pci_dev);\n\n\tdev_dbg(&oct->pci_dev->dev, \"Device state is now %s\\n\",\n\t\tlio_get_state_string(&oct->status));\n\n\t \n\tcleanup_aer_uncorrect_error_status(oct->pci_dev);\n}\n\n \nstatic pci_ers_result_t liquidio_pcie_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\t     pci_channel_state_t state)\n{\n\tstruct octeon_device *oct = pci_get_drvdata(pdev);\n\n\t \n\tif (state == pci_channel_io_normal) {\n\t\tdev_err(&oct->pci_dev->dev, \"Non-correctable non-fatal error reported:\\n\");\n\t\tcleanup_aer_uncorrect_error_status(oct->pci_dev);\n\t\treturn PCI_ERS_RESULT_CAN_RECOVER;\n\t}\n\n\t \n\tdev_err(&oct->pci_dev->dev, \"Non-correctable FATAL reported by PCI AER driver\\n\");\n\tstop_pci_io(oct);\n\n\t \n\treturn PCI_ERS_RESULT_DISCONNECT;\n}\n\n \nstatic pci_ers_result_t liquidio_pcie_mmio_enabled(struct pci_dev __maybe_unused *pdev)\n{\n\t \n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n \nstatic pci_ers_result_t liquidio_pcie_slot_reset(struct pci_dev __maybe_unused *pdev)\n{\n\t \n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n \nstatic void liquidio_pcie_resume(struct pci_dev __maybe_unused *pdev)\n{\n\t \n}\n\n#define liquidio_suspend NULL\n#define liquidio_resume NULL\n\n \nstatic const struct pci_error_handlers liquidio_err_handler = {\n\t.error_detected = liquidio_pcie_error_detected,\n\t.mmio_enabled\t= liquidio_pcie_mmio_enabled,\n\t.slot_reset\t= liquidio_pcie_slot_reset,\n\t.resume\t\t= liquidio_pcie_resume,\n};\n\nstatic const struct pci_device_id liquidio_pci_tbl[] = {\n\t{        \n\t\tPCI_VENDOR_ID_CAVIUM, 0x91, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0\n\t},\n\t{        \n\t\tPCI_VENDOR_ID_CAVIUM, 0x92, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0\n\t},\n\t{        \n\t\tPCI_VENDOR_ID_CAVIUM, 0x9702, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0\n\t},\n\t{\n\t\t0, 0, 0, 0, 0, 0, 0\n\t}\n};\nMODULE_DEVICE_TABLE(pci, liquidio_pci_tbl);\n\nstatic SIMPLE_DEV_PM_OPS(liquidio_pm_ops, liquidio_suspend, liquidio_resume);\n\nstatic struct pci_driver liquidio_pci_driver = {\n\t.name\t\t= \"LiquidIO\",\n\t.id_table\t= liquidio_pci_tbl,\n\t.probe\t\t= liquidio_probe,\n\t.remove\t\t= liquidio_remove,\n\t.err_handler\t= &liquidio_err_handler,     \n\t.driver.pm\t= &liquidio_pm_ops,\n#ifdef CONFIG_PCI_IOV\n\t.sriov_configure = liquidio_enable_sriov,\n#endif\n};\n\n \nstatic int liquidio_init_pci(void)\n{\n\treturn pci_register_driver(&liquidio_pci_driver);\n}\n\n \nstatic void liquidio_deinit_pci(void)\n{\n\tpci_unregister_driver(&liquidio_pci_driver);\n}\n\n \nstatic inline int check_txq_status(struct lio *lio)\n{\n\tint numqs = lio->netdev->real_num_tx_queues;\n\tint ret_val = 0;\n\tint q, iq;\n\n\t \n\tfor (q = 0; q < numqs; q++) {\n\t\tiq = lio->linfo.txpciq[q %\n\t\t\tlio->oct_dev->num_iqs].s.q_no;\n\t\tif (octnet_iq_is_full(lio->oct_dev, iq))\n\t\t\tcontinue;\n\t\tif (__netif_subqueue_stopped(lio->netdev, q)) {\n\t\t\tnetif_wake_subqueue(lio->netdev, q);\n\t\t\tINCR_INSTRQUEUE_PKT_COUNT(lio->oct_dev, iq,\n\t\t\t\t\t\t  tx_restart, 1);\n\t\t\tret_val++;\n\t\t}\n\t}\n\n\treturn ret_val;\n}\n\n \nstatic void print_link_info(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\n\tif (!ifstate_check(lio, LIO_IFSTATE_RESETTING) &&\n\t    ifstate_check(lio, LIO_IFSTATE_REGISTERED)) {\n\t\tstruct oct_link_info *linfo = &lio->linfo;\n\n\t\tif (linfo->link.s.link_up) {\n\t\t\tnetif_info(lio, link, lio->netdev, \"%d Mbps %s Duplex UP\\n\",\n\t\t\t\t   linfo->link.s.speed,\n\t\t\t\t   (linfo->link.s.duplex) ? \"Full\" : \"Half\");\n\t\t} else {\n\t\t\tnetif_info(lio, link, lio->netdev, \"Link Down\\n\");\n\t\t}\n\t}\n}\n\n \nstatic void octnet_link_status_change(struct work_struct *work)\n{\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\tstruct lio *lio = (struct lio *)wk->ctxptr;\n\n\t \n\trtnl_lock();\n\tdev_set_mtu(lio->netdev, lio->linfo.link.s.mtu);\n\trtnl_unlock();\n}\n\n \nstatic inline int setup_link_status_change_wq(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tlio->link_status_wq.wq = alloc_workqueue(\"link-status\",\n\t\t\t\t\t\t WQ_MEM_RECLAIM, 0);\n\tif (!lio->link_status_wq.wq) {\n\t\tdev_err(&oct->pci_dev->dev, \"unable to create cavium link status wq\\n\");\n\t\treturn -1;\n\t}\n\tINIT_DELAYED_WORK(&lio->link_status_wq.wk.work,\n\t\t\t  octnet_link_status_change);\n\tlio->link_status_wq.wk.ctxptr = lio;\n\n\treturn 0;\n}\n\nstatic inline void cleanup_link_status_change_wq(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\n\tif (lio->link_status_wq.wq) {\n\t\tcancel_delayed_work_sync(&lio->link_status_wq.wk.work);\n\t\tdestroy_workqueue(lio->link_status_wq.wq);\n\t}\n}\n\n \nstatic inline void update_link_status(struct net_device *netdev,\n\t\t\t\t      union oct_link_status *ls)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tint changed = (lio->linfo.link.u64 != ls->u64);\n\tint current_max_mtu = lio->linfo.link.s.mtu;\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tdev_dbg(&oct->pci_dev->dev, \"%s: lio->linfo.link.u64=%llx, ls->u64=%llx\\n\",\n\t\t__func__, lio->linfo.link.u64, ls->u64);\n\tlio->linfo.link.u64 = ls->u64;\n\n\tif ((lio->intf_open) && (changed)) {\n\t\tprint_link_info(netdev);\n\t\tlio->link_changes++;\n\n\t\tif (lio->linfo.link.s.link_up) {\n\t\t\tdev_dbg(&oct->pci_dev->dev, \"%s: link_up\", __func__);\n\t\t\tnetif_carrier_on(netdev);\n\t\t\twake_txqs(netdev);\n\t\t} else {\n\t\t\tdev_dbg(&oct->pci_dev->dev, \"%s: link_off\", __func__);\n\t\t\tnetif_carrier_off(netdev);\n\t\t\tstop_txqs(netdev);\n\t\t}\n\t\tif (lio->linfo.link.s.mtu != current_max_mtu) {\n\t\t\tnetif_info(lio, probe, lio->netdev, \"Max MTU changed from %d to %d\\n\",\n\t\t\t\t   current_max_mtu, lio->linfo.link.s.mtu);\n\t\t\tnetdev->max_mtu = lio->linfo.link.s.mtu;\n\t\t}\n\t\tif (lio->linfo.link.s.mtu < netdev->mtu) {\n\t\t\tdev_warn(&oct->pci_dev->dev,\n\t\t\t\t \"Current MTU is higher than new max MTU; Reducing the current mtu from %d to %d\\n\",\n\t\t\t\t     netdev->mtu, lio->linfo.link.s.mtu);\n\t\t\tqueue_delayed_work(lio->link_status_wq.wq,\n\t\t\t\t\t   &lio->link_status_wq.wk.work, 0);\n\t\t}\n\t}\n}\n\n \nstatic void lio_sync_octeon_time(struct work_struct *work)\n{\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\tstruct lio *lio = (struct lio *)wk->ctxptr;\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octeon_soft_command *sc;\n\tstruct timespec64 ts;\n\tstruct lio_time *lt;\n\tint ret;\n\n\tsc = octeon_alloc_soft_command(oct, sizeof(struct lio_time), 16, 0);\n\tif (!sc) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Failed to sync time to octeon: soft command allocation failed\\n\");\n\t\treturn;\n\t}\n\n\tlt = (struct lio_time *)sc->virtdptr;\n\n\t \n\tktime_get_real_ts64(&ts);\n\tlt->sec = ts.tv_sec;\n\tlt->nsec = ts.tv_nsec;\n\tocteon_swap_8B_data((u64 *)lt, (sizeof(struct lio_time)) / 8);\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_SYNC_OCTEON_TIME, 0, 0, 0);\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tret = octeon_send_soft_command(oct, sc);\n\tif (ret == IQ_SEND_FAILED) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Failed to sync time to octeon: failed to send soft command\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t} else {\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t}\n\n\tqueue_delayed_work(lio->sync_octeon_time_wq.wq,\n\t\t\t   &lio->sync_octeon_time_wq.wk.work,\n\t\t\t   msecs_to_jiffies(LIO_SYNC_OCTEON_TIME_INTERVAL_MS));\n}\n\n \nstatic inline int setup_sync_octeon_time_wq(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tlio->sync_octeon_time_wq.wq =\n\t\talloc_workqueue(\"update-octeon-time\", WQ_MEM_RECLAIM, 0);\n\tif (!lio->sync_octeon_time_wq.wq) {\n\t\tdev_err(&oct->pci_dev->dev, \"Unable to create wq to update octeon time\\n\");\n\t\treturn -1;\n\t}\n\tINIT_DELAYED_WORK(&lio->sync_octeon_time_wq.wk.work,\n\t\t\t  lio_sync_octeon_time);\n\tlio->sync_octeon_time_wq.wk.ctxptr = lio;\n\tqueue_delayed_work(lio->sync_octeon_time_wq.wq,\n\t\t\t   &lio->sync_octeon_time_wq.wk.work,\n\t\t\t   msecs_to_jiffies(LIO_SYNC_OCTEON_TIME_INTERVAL_MS));\n\n\treturn 0;\n}\n\n \nstatic inline void cleanup_sync_octeon_time_wq(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct cavium_wq *time_wq = &lio->sync_octeon_time_wq;\n\n\tif (time_wq->wq) {\n\t\tcancel_delayed_work_sync(&time_wq->wk.work);\n\t\tdestroy_workqueue(time_wq->wq);\n\t}\n}\n\nstatic struct octeon_device *get_other_octeon_device(struct octeon_device *oct)\n{\n\tstruct octeon_device *other_oct;\n\n\tother_oct = lio_get_device(oct->octeon_id + 1);\n\n\tif (other_oct && other_oct->pci_dev) {\n\t\tint oct_busnum, other_oct_busnum;\n\n\t\toct_busnum = oct->pci_dev->bus->number;\n\t\tother_oct_busnum = other_oct->pci_dev->bus->number;\n\n\t\tif (oct_busnum == other_oct_busnum) {\n\t\t\tint oct_slot, other_oct_slot;\n\n\t\t\toct_slot = PCI_SLOT(oct->pci_dev->devfn);\n\t\t\tother_oct_slot = PCI_SLOT(other_oct->pci_dev->devfn);\n\n\t\t\tif (oct_slot == other_oct_slot)\n\t\t\t\treturn other_oct;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic void disable_all_vf_links(struct octeon_device *oct)\n{\n\tstruct net_device *netdev;\n\tint max_vfs, vf, i;\n\n\tif (!oct)\n\t\treturn;\n\n\tmax_vfs = oct->sriov_info.max_vfs;\n\n\tfor (i = 0; i < oct->ifcount; i++) {\n\t\tnetdev = oct->props[i].netdev;\n\t\tif (!netdev)\n\t\t\tcontinue;\n\n\t\tfor (vf = 0; vf < max_vfs; vf++)\n\t\t\tliquidio_set_vf_link_state(netdev, vf,\n\t\t\t\t\t\t   IFLA_VF_LINK_STATE_DISABLE);\n\t}\n}\n\nstatic int liquidio_watchdog(void *param)\n{\n\tbool err_msg_was_printed[LIO_MAX_CORES];\n\tu16 mask_of_crashed_or_stuck_cores = 0;\n\tbool all_vf_links_are_disabled = false;\n\tstruct octeon_device *oct = param;\n\tstruct octeon_device *other_oct;\n#ifdef CONFIG_MODULE_UNLOAD\n\tlong refcount, vfs_referencing_pf;\n\tu64 vfs_mask1, vfs_mask2;\n#endif\n\tint core;\n\n\tmemset(err_msg_was_printed, 0, sizeof(err_msg_was_printed));\n\n\twhile (!kthread_should_stop()) {\n\t\t \n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tschedule_timeout(msecs_to_jiffies(2000));\n\n\t\tmask_of_crashed_or_stuck_cores =\n\t\t    (u16)octeon_read_csr64(oct, CN23XX_SLI_SCRATCH2);\n\n\t\tif (!mask_of_crashed_or_stuck_cores)\n\t\t\tcontinue;\n\n\t\tWRITE_ONCE(oct->cores_crashed, true);\n\t\tother_oct = get_other_octeon_device(oct);\n\t\tif (other_oct)\n\t\t\tWRITE_ONCE(other_oct->cores_crashed, true);\n\n\t\tfor (core = 0; core < LIO_MAX_CORES; core++) {\n\t\t\tbool core_crashed_or_got_stuck;\n\n\t\t\tcore_crashed_or_got_stuck =\n\t\t\t\t\t\t(mask_of_crashed_or_stuck_cores\n\t\t\t\t\t\t >> core) & 1;\n\n\t\t\tif (core_crashed_or_got_stuck &&\n\t\t\t    !err_msg_was_printed[core]) {\n\t\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\t\"ERROR: Octeon core %d crashed or got stuck!  See oct-fwdump for details.\\n\",\n\t\t\t\t\tcore);\n\t\t\t\terr_msg_was_printed[core] = true;\n\t\t\t}\n\t\t}\n\n\t\tif (all_vf_links_are_disabled)\n\t\t\tcontinue;\n\n\t\tdisable_all_vf_links(oct);\n\t\tdisable_all_vf_links(other_oct);\n\t\tall_vf_links_are_disabled = true;\n\n#ifdef CONFIG_MODULE_UNLOAD\n\t\tvfs_mask1 = READ_ONCE(oct->sriov_info.vf_drv_loaded_mask);\n\t\tvfs_mask2 = READ_ONCE(other_oct->sriov_info.vf_drv_loaded_mask);\n\n\t\tvfs_referencing_pf  = hweight64(vfs_mask1);\n\t\tvfs_referencing_pf += hweight64(vfs_mask2);\n\n\t\trefcount = module_refcount(THIS_MODULE);\n\t\tif (refcount >= vfs_referencing_pf) {\n\t\t\twhile (vfs_referencing_pf) {\n\t\t\t\tmodule_put(THIS_MODULE);\n\t\t\t\tvfs_referencing_pf--;\n\t\t\t}\n\t\t}\n#endif\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nliquidio_probe(struct pci_dev *pdev, const struct pci_device_id __maybe_unused *ent)\n{\n\tstruct octeon_device *oct_dev = NULL;\n\tstruct handshake *hs;\n\n\toct_dev = octeon_allocate_device(pdev->device,\n\t\t\t\t\t sizeof(struct octeon_device_priv));\n\tif (!oct_dev) {\n\t\tdev_err(&pdev->dev, \"Unable to allocate device\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (pdev->device == OCTEON_CN23XX_PF_VID)\n\t\toct_dev->msix_on = LIO_FLAG_MSIX_ENABLED;\n\n\t \n\tif (((pdev->device == OCTEON_CN66XX) ||\n\t     (pdev->device == OCTEON_CN68XX)))\n\t\toct_dev->ptp_enable = true;\n\telse\n\t\toct_dev->ptp_enable = false;\n\n\tdev_info(&pdev->dev, \"Initializing device %x:%x.\\n\",\n\t\t (u32)pdev->vendor, (u32)pdev->device);\n\n\t \n\tpci_set_drvdata(pdev, oct_dev);\n\n\t \n\toct_dev->pci_dev = (void *)pdev;\n\n\toct_dev->subsystem_id = pdev->subsystem_vendor |\n\t\t(pdev->subsystem_device << 16);\n\n\ths = &handshake[oct_dev->octeon_id];\n\tinit_completion(&hs->init);\n\tinit_completion(&hs->started);\n\ths->pci_dev = pdev;\n\n\tif (oct_dev->octeon_id == 0)\n\t\t \n\t\tcomplete(&first_stage);\n\n\tif (octeon_device_init(oct_dev)) {\n\t\tcomplete(&hs->init);\n\t\tliquidio_remove(pdev);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (OCTEON_CN23XX_PF(oct_dev)) {\n\t\tu8 bus, device, function;\n\n\t\tif (atomic_read(oct_dev->adapter_refcount) == 1) {\n\t\t\t \n\t\t\tbus = pdev->bus->number;\n\t\t\tdevice = PCI_SLOT(pdev->devfn);\n\t\t\tfunction = PCI_FUNC(pdev->devfn);\n\t\t\toct_dev->watchdog_task = kthread_run(liquidio_watchdog,\n\t\t\t\t\t\t\t     oct_dev,\n\t\t\t\t\t\t\t     \"liowd/%02hhx:%02hhx.%hhx\",\n\t\t\t\t\t\t\t     bus, device, function);\n\t\t\tif (IS_ERR(oct_dev->watchdog_task)) {\n\t\t\t\toct_dev->watchdog_task = NULL;\n\t\t\t\tdev_err(&oct_dev->pci_dev->dev,\n\t\t\t\t\t\"failed to create kernel_thread\\n\");\n\t\t\t\tliquidio_remove(pdev);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\n\toct_dev->rx_pause = 1;\n\toct_dev->tx_pause = 1;\n\n\tdev_dbg(&oct_dev->pci_dev->dev, \"Device is ready\\n\");\n\n\treturn 0;\n}\n\nstatic bool fw_type_is_auto(void)\n{\n\treturn strncmp(fw_type, LIO_FW_NAME_TYPE_AUTO,\n\t\t       sizeof(LIO_FW_NAME_TYPE_AUTO)) == 0;\n}\n\n \nstatic void octeon_pci_flr(struct octeon_device *oct)\n{\n\tint rc;\n\n\tpci_save_state(oct->pci_dev);\n\n\tpci_cfg_access_lock(oct->pci_dev);\n\n\t \n\tpci_write_config_word(oct->pci_dev, PCI_COMMAND,\n\t\t\t      PCI_COMMAND_INTX_DISABLE);\n\n\trc = __pci_reset_function_locked(oct->pci_dev);\n\n\tif (rc != 0)\n\t\tdev_err(&oct->pci_dev->dev, \"Error %d resetting PCI function %d\\n\",\n\t\t\trc, oct->pf_num);\n\n\tpci_cfg_access_unlock(oct->pci_dev);\n\n\tpci_restore_state(oct->pci_dev);\n}\n\n \nstatic void octeon_destroy_resources(struct octeon_device *oct)\n{\n\tint i, refcount;\n\tstruct msix_entry *msix_entries;\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\n\tstruct handshake *hs;\n\n\tswitch (atomic_read(&oct->status)) {\n\tcase OCT_DEV_RUNNING:\n\tcase OCT_DEV_CORE_OK:\n\n\t\t \n\t\tatomic_set(&oct->status, OCT_DEV_IN_RESET);\n\n\t\toct->app_mode = CVM_DRV_INVALID_APP;\n\t\tdev_dbg(&oct->pci_dev->dev, \"Device state is now %s\\n\",\n\t\t\tlio_get_state_string(&oct->status));\n\n\t\tschedule_timeout_uninterruptible(HZ / 10);\n\n\t\tfallthrough;\n\tcase OCT_DEV_HOST_OK:\n\n\tcase OCT_DEV_CONSOLE_INIT_DONE:\n\t\t \n\t\tocteon_remove_consoles(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_IO_QUEUES_DONE:\n\t\tif (lio_wait_for_instr_fetch(oct))\n\t\t\tdev_err(&oct->pci_dev->dev, \"IQ had pending instructions\\n\");\n\n\t\tif (wait_for_pending_requests(oct))\n\t\t\tdev_err(&oct->pci_dev->dev, \"There were pending requests\\n\");\n\n\t\t \n\t\toct->fn_list.disable_io_queues(oct);\n\n\t\tif (lio_wait_for_oq_pkts(oct))\n\t\t\tdev_err(&oct->pci_dev->dev, \"OQ had pending packets\\n\");\n\n\t\t \n\t\tfor (i = 0; i < MAX_OCTEON_INSTR_QUEUES(oct); i++) {\n\t\t\tstruct octeon_instr_queue *iq;\n\n\t\t\tif (!(oct->io_qmask.iq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tiq = oct->instr_queue[i];\n\n\t\t\tif (atomic_read(&iq->instr_pending)) {\n\t\t\t\tspin_lock_bh(&iq->lock);\n\t\t\t\tiq->fill_cnt = 0;\n\t\t\t\tiq->octeon_read_index = iq->host_write_index;\n\t\t\t\tiq->stats.instr_processed +=\n\t\t\t\t\tatomic_read(&iq->instr_pending);\n\t\t\t\tlio_process_iq_request_list(oct, iq, 0);\n\t\t\t\tspin_unlock_bh(&iq->lock);\n\t\t\t}\n\t\t}\n\n\t\tlio_process_ordered_list(oct, 1);\n\t\tocteon_free_sc_done_list(oct);\n\t\tocteon_free_sc_zombie_list(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_INTR_SET_DONE:\n\t\t \n\t\toct->fn_list.disable_interrupt(oct, OCTEON_ALL_INTR);\n\n\t\tif (oct->msix_on) {\n\t\t\tmsix_entries = (struct msix_entry *)oct->msix_entries;\n\t\t\tfor (i = 0; i < oct->num_msix_irqs - 1; i++) {\n\t\t\t\tif (oct->ioq_vector[i].vector) {\n\t\t\t\t\t \n\t\t\t\t\tirq_set_affinity_hint(\n\t\t\t\t\t\t\tmsix_entries[i].vector,\n\t\t\t\t\t\t\tNULL);\n\t\t\t\t\tfree_irq(msix_entries[i].vector,\n\t\t\t\t\t\t &oct->ioq_vector[i]);\n\t\t\t\t\toct->ioq_vector[i].vector = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\t \n\t\t\tfree_irq(msix_entries[i].vector, oct);\n\n\t\t\tpci_disable_msix(oct->pci_dev);\n\t\t\tkfree(oct->msix_entries);\n\t\t\toct->msix_entries = NULL;\n\t\t} else {\n\t\t\t \n\t\t\tfree_irq(oct->pci_dev->irq, oct);\n\n\t\t\tif (oct->flags & LIO_FLAG_MSI_ENABLED)\n\t\t\t\tpci_disable_msi(oct->pci_dev);\n\t\t}\n\n\t\tkfree(oct->irq_name_storage);\n\t\toct->irq_name_storage = NULL;\n\n\t\tfallthrough;\n\tcase OCT_DEV_MSIX_ALLOC_VECTOR_DONE:\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\tocteon_free_ioq_vector(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_MBOX_SETUP_DONE:\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\toct->fn_list.free_mbox(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_IN_RESET:\n\tcase OCT_DEV_DROQ_INIT_DONE:\n\t\t \n\t\tmdelay(100);\n\t\tfor (i = 0; i < MAX_OCTEON_OUTPUT_QUEUES(oct); i++) {\n\t\t\tif (!(oct->io_qmask.oq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tocteon_delete_droq(oct, i);\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < MAX_OCTEON_DEVICES; i++) {\n\t\t\ths = &handshake[i];\n\n\t\t\tif (hs->pci_dev) {\n\t\t\t\thandshake[oct->octeon_id].init_ok = 0;\n\t\t\t\tcomplete(&handshake[oct->octeon_id].init);\n\t\t\t\thandshake[oct->octeon_id].started_ok = 0;\n\t\t\t\tcomplete(&handshake[oct->octeon_id].started);\n\t\t\t}\n\t\t}\n\n\t\tfallthrough;\n\tcase OCT_DEV_RESP_LIST_INIT_DONE:\n\t\tocteon_delete_response_list(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_INSTR_QUEUE_INIT_DONE:\n\t\tfor (i = 0; i < MAX_OCTEON_INSTR_QUEUES(oct); i++) {\n\t\t\tif (!(oct->io_qmask.iq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tocteon_delete_instr_queue(oct, i);\n\t\t}\n#ifdef CONFIG_PCI_IOV\n\t\tif (oct->sriov_info.sriov_enabled)\n\t\t\tpci_disable_sriov(oct->pci_dev);\n#endif\n\t\tfallthrough;\n\tcase OCT_DEV_SC_BUFF_POOL_INIT_DONE:\n\t\tocteon_free_sc_buffer_pool(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_DISPATCH_INIT_DONE:\n\t\tocteon_delete_dispatch_list(oct);\n\t\tcancel_delayed_work_sync(&oct->nic_poll_work.work);\n\n\t\tfallthrough;\n\tcase OCT_DEV_PCI_MAP_DONE:\n\t\trefcount = octeon_deregister_device(oct);\n\n\t\t \n\t\tif (atomic_read(oct->adapter_fw_state) == FW_IS_PRELOADED)\n\t\t\tocteon_pci_flr(oct);\n\t\telse if (OCTEON_CN6XXX(oct) || !refcount)\n\t\t\toct->fn_list.soft_reset(oct);\n\n\t\tocteon_unmap_pci_barx(oct, 0);\n\t\tocteon_unmap_pci_barx(oct, 1);\n\n\t\tfallthrough;\n\tcase OCT_DEV_PCI_ENABLE_DONE:\n\t\t \n\t\tpci_disable_device(oct->pci_dev);\n\n\t\tfallthrough;\n\tcase OCT_DEV_BEGIN_STATE:\n\t\t \n\t\tbreak;\n\t}                        \n\n\ttasklet_kill(&oct_priv->droq_tasklet);\n}\n\n \nstatic int send_rx_ctrl_cmd(struct lio *lio, int start_stop)\n{\n\tstruct octeon_soft_command *sc;\n\tunion octnet_cmd *ncmd;\n\tstruct octeon_device *oct = (struct octeon_device *)lio->oct_dev;\n\tint retval;\n\n\tif (oct->props[lio->ifidx].rx_on == start_stop)\n\t\treturn 0;\n\n\tsc = (struct octeon_soft_command *)\n\t\tocteon_alloc_soft_command(oct, OCTNET_CMD_SIZE,\n\t\t\t\t\t  16, 0);\n\tif (!sc) {\n\t\tnetif_info(lio, rx_err, lio->netdev,\n\t\t\t   \"Failed to allocate octeon_soft_command struct\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tncmd = (union octnet_cmd *)sc->virtdptr;\n\n\tncmd->u64 = 0;\n\tncmd->s.cmd = OCTNET_CMD_RX_CTL;\n\tncmd->s.param1 = start_stop;\n\n\tocteon_swap_8B_data((u64 *)ncmd, (OCTNET_CMD_SIZE >> 3));\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_CMD, 0, 0, 0);\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tretval = octeon_send_soft_command(oct, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tnetif_info(lio, rx_err, lio->netdev, \"Failed to send RX Control message\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t} else {\n\t\t \n\t\tretval = wait_for_sc_completion_timeout(oct, sc, 0);\n\t\tif (retval)\n\t\t\treturn retval;\n\n\t\toct->props[lio->ifidx].rx_on = start_stop;\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t}\n\n\treturn retval;\n}\n\n \nstatic void liquidio_destroy_nic_device(struct octeon_device *oct, int ifidx)\n{\n\tstruct net_device *netdev = oct->props[ifidx].netdev;\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tstruct napi_struct *napi, *n;\n\tstruct lio *lio;\n\n\tif (!netdev) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s No netdevice ptr for index %d\\n\",\n\t\t\t__func__, ifidx);\n\t\treturn;\n\t}\n\n\tlio = GET_LIO(netdev);\n\n\tdev_dbg(&oct->pci_dev->dev, \"NIC device cleanup\\n\");\n\n\tif (atomic_read(&lio->ifstate) & LIO_IFSTATE_RUNNING)\n\t\tliquidio_stop(netdev);\n\n\tif (oct->props[lio->ifidx].napi_enabled == 1) {\n\t\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\t\tnapi_disable(napi);\n\n\t\toct->props[lio->ifidx].napi_enabled = 0;\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\toct->droq[0]->ops.poll_mode = 0;\n\t}\n\n\t \n\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\tnetif_napi_del(napi);\n\n\ttasklet_enable(&oct_priv->droq_tasklet);\n\n\tif (atomic_read(&lio->ifstate) & LIO_IFSTATE_REGISTERED)\n\t\tunregister_netdev(netdev);\n\n\tcleanup_sync_octeon_time_wq(netdev);\n\tcleanup_link_status_change_wq(netdev);\n\n\tcleanup_rx_oom_poll_fn(netdev);\n\n\tlio_delete_glists(lio);\n\n\tfree_netdev(netdev);\n\n\toct->props[ifidx].gmxport = -1;\n\n\toct->props[ifidx].netdev = NULL;\n}\n\n \nstatic int liquidio_stop_nic_module(struct octeon_device *oct)\n{\n\tint i, j;\n\tstruct lio *lio;\n\n\tdev_dbg(&oct->pci_dev->dev, \"Stopping network interfaces\\n\");\n\tdevice_lock(&oct->pci_dev->dev);\n\tif (oct->devlink) {\n\t\tdevlink_unregister(oct->devlink);\n\t\tdevlink_free(oct->devlink);\n\t\toct->devlink = NULL;\n\t}\n\tdevice_unlock(&oct->pci_dev->dev);\n\n\tif (!oct->ifcount) {\n\t\tdev_err(&oct->pci_dev->dev, \"Init for Octeon was not completed\\n\");\n\t\treturn 1;\n\t}\n\n\tspin_lock_bh(&oct->cmd_resp_wqlock);\n\toct->cmd_resp_state = OCT_DRV_OFFLINE;\n\tspin_unlock_bh(&oct->cmd_resp_wqlock);\n\n\tlio_vf_rep_destroy(oct);\n\n\tfor (i = 0; i < oct->ifcount; i++) {\n\t\tlio = GET_LIO(oct->props[i].netdev);\n\t\tfor (j = 0; j < oct->num_oqs; j++)\n\t\t\tocteon_unregister_droq_ops(oct,\n\t\t\t\t\t\t   lio->linfo.rxpciq[j].s.q_no);\n\t}\n\n\tfor (i = 0; i < oct->ifcount; i++)\n\t\tliquidio_destroy_nic_device(oct, i);\n\n\tdev_dbg(&oct->pci_dev->dev, \"Network interfaces stopped\\n\");\n\treturn 0;\n}\n\n \nstatic void liquidio_remove(struct pci_dev *pdev)\n{\n\tstruct octeon_device *oct_dev = pci_get_drvdata(pdev);\n\n\tdev_dbg(&oct_dev->pci_dev->dev, \"Stopping device\\n\");\n\n\tif (oct_dev->watchdog_task)\n\t\tkthread_stop(oct_dev->watchdog_task);\n\n\tif (!oct_dev->octeon_id &&\n\t    oct_dev->fw_info.app_cap_flags & LIQUIDIO_SWITCHDEV_CAP)\n\t\tlio_vf_rep_modexit();\n\n\tif (oct_dev->app_mode && (oct_dev->app_mode == CVM_DRV_NIC_APP))\n\t\tliquidio_stop_nic_module(oct_dev);\n\n\t \n\tocteon_destroy_resources(oct_dev);\n\n\tdev_info(&oct_dev->pci_dev->dev, \"Device removed\\n\");\n\n\t \n\tocteon_free_device_mem(oct_dev);\n}\n\n \nstatic int octeon_chip_specific_setup(struct octeon_device *oct)\n{\n\tu32 dev_id, rev_id;\n\tint ret = 1;\n\n\tpci_read_config_dword(oct->pci_dev, 0, &dev_id);\n\tpci_read_config_dword(oct->pci_dev, 8, &rev_id);\n\toct->rev_id = rev_id & 0xff;\n\n\tswitch (dev_id) {\n\tcase OCTEON_CN68XX_PCIID:\n\t\toct->chip_id = OCTEON_CN68XX;\n\t\tret = lio_setup_cn68xx_octeon_device(oct);\n\t\tbreak;\n\n\tcase OCTEON_CN66XX_PCIID:\n\t\toct->chip_id = OCTEON_CN66XX;\n\t\tret = lio_setup_cn66xx_octeon_device(oct);\n\t\tbreak;\n\n\tcase OCTEON_CN23XX_PCIID_PF:\n\t\toct->chip_id = OCTEON_CN23XX_PF_VID;\n\t\tret = setup_cn23xx_octeon_pf_device(oct);\n\t\tif (ret)\n\t\t\tbreak;\n#ifdef CONFIG_PCI_IOV\n\t\tif (!ret)\n\t\t\tpci_sriov_set_totalvfs(oct->pci_dev,\n\t\t\t\t\t       oct->sriov_info.max_vfs);\n#endif\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(&oct->pci_dev->dev, \"Unknown device found (dev_id: %x)\\n\",\n\t\t\tdev_id);\n\t}\n\n\treturn ret;\n}\n\n \nstatic int octeon_pci_os_setup(struct octeon_device *oct)\n{\n\t \n\tif (pci_enable_device(oct->pci_dev)) {\n\t\tdev_err(&oct->pci_dev->dev, \"pci_enable_device failed\\n\");\n\t\treturn 1;\n\t}\n\n\tif (dma_set_mask_and_coherent(&oct->pci_dev->dev, DMA_BIT_MASK(64))) {\n\t\tdev_err(&oct->pci_dev->dev, \"Unexpected DMA device capability\\n\");\n\t\tpci_disable_device(oct->pci_dev);\n\t\treturn 1;\n\t}\n\n\t \n\tpci_set_master(oct->pci_dev);\n\n\treturn 0;\n}\n\n \nstatic void free_netbuf(void *buf)\n{\n\tstruct sk_buff *skb;\n\tstruct octnet_buf_free_info *finfo;\n\tstruct lio *lio;\n\n\tfinfo = (struct octnet_buf_free_info *)buf;\n\tskb = finfo->skb;\n\tlio = finfo->lio;\n\n\tdma_unmap_single(&lio->oct_dev->pci_dev->dev, finfo->dptr, skb->len,\n\t\t\t DMA_TO_DEVICE);\n\n\ttx_buffer_free(skb);\n}\n\n \nstatic void free_netsgbuf(void *buf)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tstruct sk_buff *skb;\n\tstruct lio *lio;\n\tstruct octnic_gather *g;\n\tint i, frags, iq;\n\n\tfinfo = (struct octnet_buf_free_info *)buf;\n\tskb = finfo->skb;\n\tlio = finfo->lio;\n\tg = finfo->g;\n\tfrags = skb_shinfo(skb)->nr_frags;\n\n\tdma_unmap_single(&lio->oct_dev->pci_dev->dev,\n\t\t\t g->sg[0].ptr[0], (skb->len - skb->data_len),\n\t\t\t DMA_TO_DEVICE);\n\n\ti = 1;\n\twhile (frags--) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i - 1];\n\n\t\tdma_unmap_page(&lio->oct_dev->pci_dev->dev,\n\t\t\t       g->sg[(i >> 2)].ptr[(i & 3)],\n\t\t\t       skb_frag_size(frag), DMA_TO_DEVICE);\n\t\ti++;\n\t}\n\n\tiq = skb_iq(lio->oct_dev, skb);\n\tspin_lock(&lio->glist_lock[iq]);\n\tlist_add_tail(&g->list, &lio->glist[iq]);\n\tspin_unlock(&lio->glist_lock[iq]);\n\n\ttx_buffer_free(skb);\n}\n\n \nstatic void free_netsgbuf_with_resp(void *buf)\n{\n\tstruct octeon_soft_command *sc;\n\tstruct octnet_buf_free_info *finfo;\n\tstruct sk_buff *skb;\n\tstruct lio *lio;\n\tstruct octnic_gather *g;\n\tint i, frags, iq;\n\n\tsc = (struct octeon_soft_command *)buf;\n\tskb = (struct sk_buff *)sc->callback_arg;\n\tfinfo = (struct octnet_buf_free_info *)&skb->cb;\n\n\tlio = finfo->lio;\n\tg = finfo->g;\n\tfrags = skb_shinfo(skb)->nr_frags;\n\n\tdma_unmap_single(&lio->oct_dev->pci_dev->dev,\n\t\t\t g->sg[0].ptr[0], (skb->len - skb->data_len),\n\t\t\t DMA_TO_DEVICE);\n\n\ti = 1;\n\twhile (frags--) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i - 1];\n\n\t\tdma_unmap_page(&lio->oct_dev->pci_dev->dev,\n\t\t\t       g->sg[(i >> 2)].ptr[(i & 3)],\n\t\t\t       skb_frag_size(frag), DMA_TO_DEVICE);\n\t\ti++;\n\t}\n\n\tiq = skb_iq(lio->oct_dev, skb);\n\n\tspin_lock(&lio->glist_lock[iq]);\n\tlist_add_tail(&g->list, &lio->glist[iq]);\n\tspin_unlock(&lio->glist_lock[iq]);\n\n\t \n}\n\n \nstatic int liquidio_ptp_adjfine(struct ptp_clock_info *ptp, long scaled_ppm)\n{\n\tstruct lio *lio = container_of(ptp, struct lio, ptp_info);\n\tstruct octeon_device *oct = (struct octeon_device *)lio->oct_dev;\n\ts32 ppb = scaled_ppm_to_ppb(scaled_ppm);\n\tu64 comp, delta;\n\tunsigned long flags;\n\tbool neg_adj = false;\n\n\tif (ppb < 0) {\n\t\tneg_adj = true;\n\t\tppb = -ppb;\n\t}\n\n\t \n\tdelta = (u64)ppb << 32;\n\tdo_div(delta, oct->coproc_clock_rate);\n\n\tspin_lock_irqsave(&lio->ptp_lock, flags);\n\tcomp = lio_pci_readq(oct, CN6XXX_MIO_PTP_CLOCK_COMP);\n\tif (neg_adj)\n\t\tcomp -= delta;\n\telse\n\t\tcomp += delta;\n\tlio_pci_writeq(oct, comp, CN6XXX_MIO_PTP_CLOCK_COMP);\n\tspin_unlock_irqrestore(&lio->ptp_lock, flags);\n\n\treturn 0;\n}\n\n \nstatic int liquidio_ptp_adjtime(struct ptp_clock_info *ptp, s64 delta)\n{\n\tunsigned long flags;\n\tstruct lio *lio = container_of(ptp, struct lio, ptp_info);\n\n\tspin_lock_irqsave(&lio->ptp_lock, flags);\n\tlio->ptp_adjust += delta;\n\tspin_unlock_irqrestore(&lio->ptp_lock, flags);\n\n\treturn 0;\n}\n\n \nstatic int liquidio_ptp_gettime(struct ptp_clock_info *ptp,\n\t\t\t\tstruct timespec64 *ts)\n{\n\tu64 ns;\n\tunsigned long flags;\n\tstruct lio *lio = container_of(ptp, struct lio, ptp_info);\n\tstruct octeon_device *oct = (struct octeon_device *)lio->oct_dev;\n\n\tspin_lock_irqsave(&lio->ptp_lock, flags);\n\tns = lio_pci_readq(oct, CN6XXX_MIO_PTP_CLOCK_HI);\n\tns += lio->ptp_adjust;\n\tspin_unlock_irqrestore(&lio->ptp_lock, flags);\n\n\t*ts = ns_to_timespec64(ns);\n\n\treturn 0;\n}\n\n \nstatic int liquidio_ptp_settime(struct ptp_clock_info *ptp,\n\t\t\t\tconst struct timespec64 *ts)\n{\n\tu64 ns;\n\tunsigned long flags;\n\tstruct lio *lio = container_of(ptp, struct lio, ptp_info);\n\tstruct octeon_device *oct = (struct octeon_device *)lio->oct_dev;\n\n\tns = timespec64_to_ns(ts);\n\n\tspin_lock_irqsave(&lio->ptp_lock, flags);\n\tlio_pci_writeq(oct, ns, CN6XXX_MIO_PTP_CLOCK_HI);\n\tlio->ptp_adjust = 0;\n\tspin_unlock_irqrestore(&lio->ptp_lock, flags);\n\n\treturn 0;\n}\n\n \nstatic int\nliquidio_ptp_enable(struct ptp_clock_info __maybe_unused *ptp,\n\t\t    struct ptp_clock_request __maybe_unused *rq,\n\t\t    int __maybe_unused on)\n{\n\treturn -EOPNOTSUPP;\n}\n\n \nstatic void oct_ptp_open(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = (struct octeon_device *)lio->oct_dev;\n\n\tspin_lock_init(&lio->ptp_lock);\n\n\tsnprintf(lio->ptp_info.name, 16, \"%s\", netdev->name);\n\tlio->ptp_info.owner = THIS_MODULE;\n\tlio->ptp_info.max_adj = 250000000;\n\tlio->ptp_info.n_alarm = 0;\n\tlio->ptp_info.n_ext_ts = 0;\n\tlio->ptp_info.n_per_out = 0;\n\tlio->ptp_info.pps = 0;\n\tlio->ptp_info.adjfine = liquidio_ptp_adjfine;\n\tlio->ptp_info.adjtime = liquidio_ptp_adjtime;\n\tlio->ptp_info.gettime64 = liquidio_ptp_gettime;\n\tlio->ptp_info.settime64 = liquidio_ptp_settime;\n\tlio->ptp_info.enable = liquidio_ptp_enable;\n\n\tlio->ptp_adjust = 0;\n\n\tlio->ptp_clock = ptp_clock_register(&lio->ptp_info,\n\t\t\t\t\t     &oct->pci_dev->dev);\n\n\tif (IS_ERR(lio->ptp_clock))\n\t\tlio->ptp_clock = NULL;\n}\n\n \nstatic void liquidio_ptp_init(struct octeon_device *oct)\n{\n\tu64 clock_comp, cfg;\n\n\tclock_comp = (u64)NSEC_PER_SEC << 32;\n\tdo_div(clock_comp, oct->coproc_clock_rate);\n\tlio_pci_writeq(oct, clock_comp, CN6XXX_MIO_PTP_CLOCK_COMP);\n\n\t \n\tcfg = lio_pci_readq(oct, CN6XXX_MIO_PTP_CLOCK_CFG);\n\tlio_pci_writeq(oct, cfg | 0x01, CN6XXX_MIO_PTP_CLOCK_CFG);\n}\n\n \nstatic int load_firmware(struct octeon_device *oct)\n{\n\tint ret = 0;\n\tconst struct firmware *fw;\n\tchar fw_name[LIO_MAX_FW_FILENAME_LEN];\n\tchar *tmp_fw_type;\n\n\tif (fw_type_is_auto()) {\n\t\ttmp_fw_type = LIO_FW_NAME_TYPE_NIC;\n\t\tstrncpy(fw_type, tmp_fw_type, sizeof(fw_type));\n\t} else {\n\t\ttmp_fw_type = fw_type;\n\t}\n\n\tsprintf(fw_name, \"%s%s%s_%s%s\", LIO_FW_DIR, LIO_FW_BASE_NAME,\n\t\tocteon_get_conf(oct)->card_name, tmp_fw_type,\n\t\tLIO_FW_NAME_SUFFIX);\n\n\tret = request_firmware(&fw, fw_name, &oct->pci_dev->dev);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"Request firmware failed. Could not find file %s.\\n\",\n\t\t\tfw_name);\n\t\trelease_firmware(fw);\n\t\treturn ret;\n\t}\n\n\tret = octeon_download_firmware(oct, fw->data, fw->size);\n\n\trelease_firmware(fw);\n\n\treturn ret;\n}\n\n \nstatic void octnet_poll_check_txq_status(struct work_struct *work)\n{\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\tstruct lio *lio = (struct lio *)wk->ctxptr;\n\n\tif (!ifstate_check(lio, LIO_IFSTATE_RUNNING))\n\t\treturn;\n\n\tcheck_txq_status(lio);\n\tqueue_delayed_work(lio->txq_status_wq.wq,\n\t\t\t   &lio->txq_status_wq.wk.work, msecs_to_jiffies(1));\n}\n\n \nstatic inline int setup_tx_poll_fn(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tlio->txq_status_wq.wq = alloc_workqueue(\"txq-status\",\n\t\t\t\t\t\tWQ_MEM_RECLAIM, 0);\n\tif (!lio->txq_status_wq.wq) {\n\t\tdev_err(&oct->pci_dev->dev, \"unable to create cavium txq status wq\\n\");\n\t\treturn -1;\n\t}\n\tINIT_DELAYED_WORK(&lio->txq_status_wq.wk.work,\n\t\t\t  octnet_poll_check_txq_status);\n\tlio->txq_status_wq.wk.ctxptr = lio;\n\tqueue_delayed_work(lio->txq_status_wq.wq,\n\t\t\t   &lio->txq_status_wq.wk.work, msecs_to_jiffies(1));\n\treturn 0;\n}\n\nstatic inline void cleanup_tx_poll_fn(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\n\tif (lio->txq_status_wq.wq) {\n\t\tcancel_delayed_work_sync(&lio->txq_status_wq.wk.work);\n\t\tdestroy_workqueue(lio->txq_status_wq.wq);\n\t}\n}\n\n \nstatic int liquidio_open(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tstruct napi_struct *napi, *n;\n\tint ret = 0;\n\n\tif (oct->props[lio->ifidx].napi_enabled == 0) {\n\t\ttasklet_disable(&oct_priv->droq_tasklet);\n\n\t\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\t\tnapi_enable(napi);\n\n\t\toct->props[lio->ifidx].napi_enabled = 1;\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\toct->droq[0]->ops.poll_mode = 1;\n\t}\n\n\tif (oct->ptp_enable)\n\t\toct_ptp_open(netdev);\n\n\tifstate_set(lio, LIO_IFSTATE_RUNNING);\n\n\tif (!OCTEON_CN23XX_PF(oct) || !oct->msix_on) {\n\t\tret = setup_tx_poll_fn(netdev);\n\t\tif (ret)\n\t\t\tgoto err_poll;\n\t}\n\n\tnetif_tx_start_all_queues(netdev);\n\n\t \n\tlio->intf_open = 1;\n\n\tnetif_info(lio, ifup, lio->netdev, \"Interface Open, ready for traffic\\n\");\n\n\t \n\tret = send_rx_ctrl_cmd(lio, 1);\n\tif (ret)\n\t\tgoto err_rx_ctrl;\n\n\t \n\tINIT_DELAYED_WORK(&lio->stats_wk.work, lio_fetch_stats);\n\tlio->stats_wk.ctxptr = lio;\n\tschedule_delayed_work(&lio->stats_wk.work, msecs_to_jiffies\n\t\t\t\t\t(LIQUIDIO_NDEV_STATS_POLL_TIME_MS));\n\n\tdev_info(&oct->pci_dev->dev, \"%s interface is opened\\n\",\n\t\t netdev->name);\n\n\treturn 0;\n\nerr_rx_ctrl:\n\tif (!OCTEON_CN23XX_PF(oct) || !oct->msix_on)\n\t\tcleanup_tx_poll_fn(netdev);\nerr_poll:\n\tif (lio->ptp_clock) {\n\t\tptp_clock_unregister(lio->ptp_clock);\n\t\tlio->ptp_clock = NULL;\n\t}\n\n\tif (oct->props[lio->ifidx].napi_enabled == 1) {\n\t\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\t\tnapi_disable(napi);\n\n\t\toct->props[lio->ifidx].napi_enabled = 0;\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\toct->droq[0]->ops.poll_mode = 0;\n\t}\n\n\treturn ret;\n}\n\n \nstatic int liquidio_stop(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tstruct napi_struct *napi, *n;\n\tint ret = 0;\n\n\tifstate_reset(lio, LIO_IFSTATE_RUNNING);\n\n\t \n\tlio->intf_open = 0;\n\n\tstop_txqs(netdev);\n\n\t \n\tnetif_carrier_off(netdev);\n\tnetif_tx_disable(netdev);\n\n\tlio->linfo.link.s.link_up = 0;\n\tlio->link_changes++;\n\n\t \n\tret = send_rx_ctrl_cmd(lio, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tif (OCTEON_CN23XX_PF(oct)) {\n\t\tif (!oct->msix_on)\n\t\t\tcleanup_tx_poll_fn(netdev);\n\t} else {\n\t\tcleanup_tx_poll_fn(netdev);\n\t}\n\n\tcancel_delayed_work_sync(&lio->stats_wk.work);\n\n\tif (lio->ptp_clock) {\n\t\tptp_clock_unregister(lio->ptp_clock);\n\t\tlio->ptp_clock = NULL;\n\t}\n\n\t \n\tif (lio_wait_for_clean_oq(oct))\n\t\tnetif_info(lio, rx_err, lio->netdev,\n\t\t\t   \"Proceeding with stop interface after partial RX desc processing\\n\");\n\n\tif (oct->props[lio->ifidx].napi_enabled == 1) {\n\t\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\t\tnapi_disable(napi);\n\n\t\toct->props[lio->ifidx].napi_enabled = 0;\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\toct->droq[0]->ops.poll_mode = 0;\n\n\t\ttasklet_enable(&oct_priv->droq_tasklet);\n\t}\n\n\tdev_info(&oct->pci_dev->dev, \"%s interface is stopped\\n\", netdev->name);\n\n\treturn ret;\n}\n\n \nstatic inline enum octnet_ifflags get_new_flags(struct net_device *netdev)\n{\n\tenum octnet_ifflags f = OCTNET_IFFLAG_UNICAST;\n\n\tif (netdev->flags & IFF_PROMISC)\n\t\tf |= OCTNET_IFFLAG_PROMISC;\n\n\tif (netdev->flags & IFF_ALLMULTI)\n\t\tf |= OCTNET_IFFLAG_ALLMULTI;\n\n\tif (netdev->flags & IFF_MULTICAST) {\n\t\tf |= OCTNET_IFFLAG_MULTICAST;\n\n\t\t \n\t\tif (netdev_mc_count(netdev) > MAX_OCTEON_MULTICAST_ADDR)\n\t\t\tf |= OCTNET_IFFLAG_ALLMULTI;\n\t}\n\n\tif (netdev->flags & IFF_BROADCAST)\n\t\tf |= OCTNET_IFFLAG_BROADCAST;\n\n\treturn f;\n}\n\n \nstatic void liquidio_set_mcast_list(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tstruct netdev_hw_addr *ha;\n\tu64 *mc;\n\tint ret;\n\tint mc_count = min(netdev_mc_count(netdev), MAX_OCTEON_MULTICAST_ADDR);\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\t \n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_SET_MULTI_LIST;\n\tnctrl.ncmd.s.param1 = get_new_flags(netdev);\n\tnctrl.ncmd.s.param2 = mc_count;\n\tnctrl.ncmd.s.more = mc_count;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\t \n\tmc = &nctrl.udd[0];\n\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\t*mc = 0;\n\t\tmemcpy(((u8 *)mc) + 2, ha->addr, ETH_ALEN);\n\t\t \n\n\t\tif (++mc > &nctrl.udd[mc_count])\n\t\t\tbreak;\n\t}\n\n\t \n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"DEVFLAGS change failed in core (ret: 0x%x)\\n\",\n\t\t\tret);\n\t}\n}\n\n \nstatic int liquidio_set_mac(struct net_device *netdev, void *p)\n{\n\tint ret = 0;\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct sockaddr *addr = (struct sockaddr *)p;\n\tstruct octnic_ctrl_pkt nctrl;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_CHANGE_MACADDR;\n\tnctrl.ncmd.s.param1 = 0;\n\tnctrl.ncmd.s.more = 1;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\n\tnctrl.udd[0] = 0;\n\t \n\tmemcpy((u8 *)&nctrl.udd[0] + 2, addr->sa_data, ETH_ALEN);\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret < 0) {\n\t\tdev_err(&oct->pci_dev->dev, \"MAC Address change failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (nctrl.sc_status) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"%s: MAC Address change failed. sc return=%x\\n\",\n\t\t\t __func__, nctrl.sc_status);\n\t\treturn -EIO;\n\t}\n\n\teth_hw_addr_set(netdev, addr->sa_data);\n\tmemcpy(((u8 *)&lio->linfo.hw_addr) + 2, addr->sa_data, ETH_ALEN);\n\n\treturn 0;\n}\n\nstatic void\nliquidio_get_stats64(struct net_device *netdev,\n\t\t     struct rtnl_link_stats64 *lstats)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct;\n\tu64 pkts = 0, drop = 0, bytes = 0;\n\tstruct oct_droq_stats *oq_stats;\n\tstruct oct_iq_stats *iq_stats;\n\tint i, iq_no, oq_no;\n\n\toct = lio->oct_dev;\n\n\tif (ifstate_check(lio, LIO_IFSTATE_RESETTING))\n\t\treturn;\n\n\tfor (i = 0; i < oct->num_iqs; i++) {\n\t\tiq_no = lio->linfo.txpciq[i].s.q_no;\n\t\tiq_stats = &oct->instr_queue[iq_no]->stats;\n\t\tpkts += iq_stats->tx_done;\n\t\tdrop += iq_stats->tx_dropped;\n\t\tbytes += iq_stats->tx_tot_bytes;\n\t}\n\n\tlstats->tx_packets = pkts;\n\tlstats->tx_bytes = bytes;\n\tlstats->tx_dropped = drop;\n\n\tpkts = 0;\n\tdrop = 0;\n\tbytes = 0;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\toq_no = lio->linfo.rxpciq[i].s.q_no;\n\t\toq_stats = &oct->droq[oq_no]->stats;\n\t\tpkts += oq_stats->rx_pkts_received;\n\t\tdrop += (oq_stats->rx_dropped +\n\t\t\t oq_stats->dropped_nodispatch +\n\t\t\t oq_stats->dropped_toomany +\n\t\t\t oq_stats->dropped_nomem);\n\t\tbytes += oq_stats->rx_bytes_received;\n\t}\n\n\tlstats->rx_bytes = bytes;\n\tlstats->rx_packets = pkts;\n\tlstats->rx_dropped = drop;\n\n\tlstats->multicast = oct->link_stats.fromwire.fw_total_mcast;\n\tlstats->collisions = oct->link_stats.fromhost.total_collisions;\n\n\t \n\tlstats->rx_length_errors = oct->link_stats.fromwire.l2_err;\n\t \n\tlstats->rx_crc_errors = oct->link_stats.fromwire.fcs_err;\n\t \n\tlstats->rx_frame_errors = oct->link_stats.fromwire.frame_err;\n\t \n\tlstats->rx_fifo_errors = oct->link_stats.fromwire.fifo_err;\n\n\tlstats->rx_errors = lstats->rx_length_errors + lstats->rx_crc_errors +\n\t\tlstats->rx_frame_errors + lstats->rx_fifo_errors;\n\n\t \n\tlstats->tx_aborted_errors = oct->link_stats.fromhost.fw_err_pko;\n\tlstats->tx_carrier_errors = oct->link_stats.fromhost.fw_err_link;\n\tlstats->tx_fifo_errors = oct->link_stats.fromhost.fifo_err;\n\n\tlstats->tx_errors = lstats->tx_aborted_errors +\n\t\tlstats->tx_carrier_errors +\n\t\tlstats->tx_fifo_errors;\n}\n\n \nstatic int hwtstamp_ioctl(struct net_device *netdev, struct ifreq *ifr)\n{\n\tstruct hwtstamp_config conf;\n\tstruct lio *lio = GET_LIO(netdev);\n\n\tif (copy_from_user(&conf, ifr->ifr_data, sizeof(conf)))\n\t\treturn -EFAULT;\n\n\tswitch (conf.tx_type) {\n\tcase HWTSTAMP_TX_ON:\n\tcase HWTSTAMP_TX_OFF:\n\t\tbreak;\n\tdefault:\n\t\treturn -ERANGE;\n\t}\n\n\tswitch (conf.rx_filter) {\n\tcase HWTSTAMP_FILTER_NONE:\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_ALL:\n\tcase HWTSTAMP_FILTER_SOME:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_NTP_ALL:\n\t\tconf.rx_filter = HWTSTAMP_FILTER_ALL;\n\t\tbreak;\n\tdefault:\n\t\treturn -ERANGE;\n\t}\n\n\tif (conf.rx_filter == HWTSTAMP_FILTER_ALL)\n\t\tifstate_set(lio, LIO_IFSTATE_RX_TIMESTAMP_ENABLED);\n\n\telse\n\t\tifstate_reset(lio, LIO_IFSTATE_RX_TIMESTAMP_ENABLED);\n\n\treturn copy_to_user(ifr->ifr_data, &conf, sizeof(conf)) ? -EFAULT : 0;\n}\n\n \nstatic int liquidio_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\n\tswitch (cmd) {\n\tcase SIOCSHWTSTAMP:\n\t\tif (lio->oct_dev->ptp_enable)\n\t\t\treturn hwtstamp_ioctl(netdev, ifr);\n\t\tfallthrough;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n \nstatic void handle_timestamp(struct octeon_device *oct,\n\t\t\t     u32 status,\n\t\t\t     void *buf)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tstruct octeon_soft_command *sc;\n\tstruct oct_timestamp_resp *resp;\n\tstruct lio *lio;\n\tstruct sk_buff *skb = (struct sk_buff *)buf;\n\n\tfinfo = (struct octnet_buf_free_info *)skb->cb;\n\tlio = finfo->lio;\n\tsc = finfo->sc;\n\toct = lio->oct_dev;\n\tresp = (struct oct_timestamp_resp *)sc->virtrptr;\n\n\tif (status != OCTEON_REQUEST_DONE) {\n\t\tdev_err(&oct->pci_dev->dev, \"Tx timestamp instruction failed. Status: %llx\\n\",\n\t\t\tCVM_CAST64(status));\n\t\tresp->timestamp = 0;\n\t}\n\n\tocteon_swap_8B_data(&resp->timestamp, 1);\n\n\tif (unlikely((skb_shinfo(skb)->tx_flags & SKBTX_IN_PROGRESS) != 0)) {\n\t\tstruct skb_shared_hwtstamps ts;\n\t\tu64 ns = resp->timestamp;\n\n\t\tnetif_info(lio, tx_done, lio->netdev,\n\t\t\t   \"Got resulting SKBTX_HW_TSTAMP skb=%p ns=%016llu\\n\",\n\t\t\t   skb, (unsigned long long)ns);\n\t\tts.hwtstamp = ns_to_ktime(ns + lio->ptp_adjust);\n\t\tskb_tstamp_tx(skb, &ts);\n\t}\n\n\tocteon_free_soft_command(oct, sc);\n\ttx_buffer_free(skb);\n}\n\n \nstatic inline int send_nic_timestamp_pkt(struct octeon_device *oct,\n\t\t\t\t\t struct octnic_data_pkt *ndata,\n\t\t\t\t\t struct octnet_buf_free_info *finfo,\n\t\t\t\t\t int xmit_more)\n{\n\tint retval;\n\tstruct octeon_soft_command *sc;\n\tstruct lio *lio;\n\tint ring_doorbell;\n\tu32 len;\n\n\tlio = finfo->lio;\n\n\tsc = octeon_alloc_soft_command_resp(oct, &ndata->cmd,\n\t\t\t\t\t    sizeof(struct oct_timestamp_resp));\n\tfinfo->sc = sc;\n\n\tif (!sc) {\n\t\tdev_err(&oct->pci_dev->dev, \"No memory for timestamped data packet\\n\");\n\t\treturn IQ_SEND_FAILED;\n\t}\n\n\tif (ndata->reqtype == REQTYPE_NORESP_NET)\n\t\tndata->reqtype = REQTYPE_RESP_NET;\n\telse if (ndata->reqtype == REQTYPE_NORESP_NET_SG)\n\t\tndata->reqtype = REQTYPE_RESP_NET_SG;\n\n\tsc->callback = handle_timestamp;\n\tsc->callback_arg = finfo->skb;\n\tsc->iq_no = ndata->q_no;\n\n\tif (OCTEON_CN23XX_PF(oct))\n\t\tlen = (u32)((struct octeon_instr_ih3 *)\n\t\t\t    (&sc->cmd.cmd3.ih3))->dlengsz;\n\telse\n\t\tlen = (u32)((struct octeon_instr_ih2 *)\n\t\t\t    (&sc->cmd.cmd2.ih2))->dlengsz;\n\n\tring_doorbell = !xmit_more;\n\n\tretval = octeon_send_command(oct, sc->iq_no, ring_doorbell, &sc->cmd,\n\t\t\t\t     sc, len, ndata->reqtype);\n\n\tif (retval == IQ_SEND_FAILED) {\n\t\tdev_err(&oct->pci_dev->dev, \"timestamp data packet failed status: %x\\n\",\n\t\t\tretval);\n\t\tocteon_free_soft_command(oct, sc);\n\t} else {\n\t\tnetif_info(lio, tx_queued, lio->netdev, \"Queued timestamp packet\\n\");\n\t}\n\n\treturn retval;\n}\n\n \nstatic netdev_tx_t liquidio_xmit(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct lio *lio;\n\tstruct octnet_buf_free_info *finfo;\n\tunion octnic_cmd_setup cmdsetup;\n\tstruct octnic_data_pkt ndata;\n\tstruct octeon_device *oct;\n\tstruct oct_iq_stats *stats;\n\tstruct octeon_instr_irh *irh;\n\tunion tx_info *tx_info;\n\tint status = 0;\n\tint q_idx = 0, iq_no = 0;\n\tint j, xmit_more = 0;\n\tu64 dptr = 0;\n\tu32 tag = 0;\n\n\tlio = GET_LIO(netdev);\n\toct = lio->oct_dev;\n\n\tq_idx = skb_iq(oct, skb);\n\ttag = q_idx;\n\tiq_no = lio->linfo.txpciq[q_idx].s.q_no;\n\n\tstats = &oct->instr_queue[iq_no]->stats;\n\n\t \n\tif (!(atomic_read(&lio->ifstate) & LIO_IFSTATE_RUNNING) ||\n\t    (!lio->linfo.link.s.link_up) ||\n\t    (skb->len <= 0)) {\n\t\tnetif_info(lio, tx_err, lio->netdev,\n\t\t\t   \"Transmit failed link_status : %d\\n\",\n\t\t\t   lio->linfo.link.s.link_up);\n\t\tgoto lio_xmit_failed;\n\t}\n\n\t \n\tfinfo = (struct octnet_buf_free_info *)skb->cb;\n\tfinfo->lio = lio;\n\tfinfo->skb = skb;\n\tfinfo->sc = NULL;\n\n\t \n\tmemset(&ndata, 0, sizeof(struct octnic_data_pkt));\n\n\tndata.buf = (void *)finfo;\n\n\tndata.q_no = iq_no;\n\n\tif (octnet_iq_is_full(oct, ndata.q_no)) {\n\t\t \n\t\tnetif_info(lio, tx_err, lio->netdev, \"Transmit failed iq:%d full\\n\",\n\t\t\t   ndata.q_no);\n\t\tstats->tx_iq_busy++;\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\t \n\n\tndata.datasize = skb->len;\n\n\tcmdsetup.u64 = 0;\n\tcmdsetup.s.iq_no = iq_no;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tif (skb->encapsulation) {\n\t\t\tcmdsetup.s.tnl_csum = 1;\n\t\t\tstats->tx_vxlan++;\n\t\t} else {\n\t\t\tcmdsetup.s.transport_csum = 1;\n\t\t}\n\t}\n\tif (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP)) {\n\t\tskb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;\n\t\tcmdsetup.s.timestamp = 1;\n\t}\n\n\tif (skb_shinfo(skb)->nr_frags == 0) {\n\t\tcmdsetup.s.u.datasize = skb->len;\n\t\toctnet_prepare_pci_cmd(oct, &ndata.cmd, &cmdsetup, tag);\n\n\t\t \n\t\tdptr = dma_map_single(&oct->pci_dev->dev,\n\t\t\t\t      skb->data,\n\t\t\t\t      skb->len,\n\t\t\t\t      DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&oct->pci_dev->dev, dptr)) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"%s DMA mapping error 1\\n\",\n\t\t\t\t__func__);\n\t\t\tstats->tx_dmamap_fail++;\n\t\t\treturn NETDEV_TX_BUSY;\n\t\t}\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\tndata.cmd.cmd3.dptr = dptr;\n\t\telse\n\t\t\tndata.cmd.cmd2.dptr = dptr;\n\t\tfinfo->dptr = dptr;\n\t\tndata.reqtype = REQTYPE_NORESP_NET;\n\n\t} else {\n\t\tint i, frags;\n\t\tskb_frag_t *frag;\n\t\tstruct octnic_gather *g;\n\n\t\tspin_lock(&lio->glist_lock[q_idx]);\n\t\tg = (struct octnic_gather *)\n\t\t\tlio_list_delete_head(&lio->glist[q_idx]);\n\t\tspin_unlock(&lio->glist_lock[q_idx]);\n\n\t\tif (!g) {\n\t\t\tnetif_info(lio, tx_err, lio->netdev,\n\t\t\t\t   \"Transmit scatter gather: glist null!\\n\");\n\t\t\tgoto lio_xmit_failed;\n\t\t}\n\n\t\tcmdsetup.s.gather = 1;\n\t\tcmdsetup.s.u.gatherptrs = (skb_shinfo(skb)->nr_frags + 1);\n\t\toctnet_prepare_pci_cmd(oct, &ndata.cmd, &cmdsetup, tag);\n\n\t\tmemset(g->sg, 0, g->sg_size);\n\n\t\tg->sg[0].ptr[0] = dma_map_single(&oct->pci_dev->dev,\n\t\t\t\t\t\t skb->data,\n\t\t\t\t\t\t (skb->len - skb->data_len),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&oct->pci_dev->dev, g->sg[0].ptr[0])) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"%s DMA mapping error 2\\n\",\n\t\t\t\t__func__);\n\t\t\tstats->tx_dmamap_fail++;\n\t\t\treturn NETDEV_TX_BUSY;\n\t\t}\n\t\tadd_sg_size(&g->sg[0], (skb->len - skb->data_len), 0);\n\n\t\tfrags = skb_shinfo(skb)->nr_frags;\n\t\ti = 1;\n\t\twhile (frags--) {\n\t\t\tfrag = &skb_shinfo(skb)->frags[i - 1];\n\n\t\t\tg->sg[(i >> 2)].ptr[(i & 3)] =\n\t\t\t\tskb_frag_dma_map(&oct->pci_dev->dev,\n\t\t\t\t\t         frag, 0, skb_frag_size(frag),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\n\t\t\tif (dma_mapping_error(&oct->pci_dev->dev,\n\t\t\t\t\t      g->sg[i >> 2].ptr[i & 3])) {\n\t\t\t\tdma_unmap_single(&oct->pci_dev->dev,\n\t\t\t\t\t\t g->sg[0].ptr[0],\n\t\t\t\t\t\t skb->len - skb->data_len,\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\t\tfor (j = 1; j < i; j++) {\n\t\t\t\t\tfrag = &skb_shinfo(skb)->frags[j - 1];\n\t\t\t\t\tdma_unmap_page(&oct->pci_dev->dev,\n\t\t\t\t\t\t       g->sg[j >> 2].ptr[j & 3],\n\t\t\t\t\t\t       skb_frag_size(frag),\n\t\t\t\t\t\t       DMA_TO_DEVICE);\n\t\t\t\t}\n\t\t\t\tdev_err(&oct->pci_dev->dev, \"%s DMA mapping error 3\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\treturn NETDEV_TX_BUSY;\n\t\t\t}\n\n\t\t\tadd_sg_size(&g->sg[(i >> 2)], skb_frag_size(frag),\n\t\t\t\t    (i & 3));\n\t\t\ti++;\n\t\t}\n\n\t\tdptr = g->sg_dma_ptr;\n\n\t\tif (OCTEON_CN23XX_PF(oct))\n\t\t\tndata.cmd.cmd3.dptr = dptr;\n\t\telse\n\t\t\tndata.cmd.cmd2.dptr = dptr;\n\t\tfinfo->dptr = dptr;\n\t\tfinfo->g = g;\n\n\t\tndata.reqtype = REQTYPE_NORESP_NET_SG;\n\t}\n\n\tif (OCTEON_CN23XX_PF(oct)) {\n\t\tirh = (struct octeon_instr_irh *)&ndata.cmd.cmd3.irh;\n\t\ttx_info = (union tx_info *)&ndata.cmd.cmd3.ossp[0];\n\t} else {\n\t\tirh = (struct octeon_instr_irh *)&ndata.cmd.cmd2.irh;\n\t\ttx_info = (union tx_info *)&ndata.cmd.cmd2.ossp[0];\n\t}\n\n\tif (skb_shinfo(skb)->gso_size) {\n\t\ttx_info->s.gso_size = skb_shinfo(skb)->gso_size;\n\t\ttx_info->s.gso_segs = skb_shinfo(skb)->gso_segs;\n\t\tstats->tx_gso++;\n\t}\n\n\t \n\tif (skb_vlan_tag_present(skb)) {\n\t\tirh->priority = skb_vlan_tag_get(skb) >> 13;\n\t\tirh->vlan = skb_vlan_tag_get(skb) & 0xfff;\n\t}\n\n\txmit_more = netdev_xmit_more();\n\n\tif (unlikely(cmdsetup.s.timestamp))\n\t\tstatus = send_nic_timestamp_pkt(oct, &ndata, finfo, xmit_more);\n\telse\n\t\tstatus = octnet_send_nic_data_pkt(oct, &ndata, xmit_more);\n\tif (status == IQ_SEND_FAILED)\n\t\tgoto lio_xmit_failed;\n\n\tnetif_info(lio, tx_queued, lio->netdev, \"Transmit queued successfully\\n\");\n\n\tif (status == IQ_SEND_STOP)\n\t\tnetif_stop_subqueue(netdev, q_idx);\n\n\tnetif_trans_update(netdev);\n\n\tif (tx_info->s.gso_segs)\n\t\tstats->tx_done += tx_info->s.gso_segs;\n\telse\n\t\tstats->tx_done++;\n\tstats->tx_tot_bytes += ndata.datasize;\n\n\treturn NETDEV_TX_OK;\n\nlio_xmit_failed:\n\tstats->tx_dropped++;\n\tnetif_info(lio, tx_err, lio->netdev, \"IQ%d Transmit dropped:%llu\\n\",\n\t\t   iq_no, stats->tx_dropped);\n\tif (dptr)\n\t\tdma_unmap_single(&oct->pci_dev->dev, dptr,\n\t\t\t\t ndata.datasize, DMA_TO_DEVICE);\n\n\tocteon_ring_doorbell_locked(oct, iq_no);\n\n\ttx_buffer_free(skb);\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic void liquidio_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct lio *lio;\n\n\tlio = GET_LIO(netdev);\n\n\tnetif_info(lio, tx_err, lio->netdev,\n\t\t   \"Transmit timeout tx_dropped:%ld, waking up queues now!!\\n\",\n\t\t   netdev->stats.tx_dropped);\n\tnetif_trans_update(netdev);\n\twake_txqs(netdev);\n}\n\nstatic int liquidio_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t    __be16 proto __attribute__((unused)),\n\t\t\t\t    u16 vid)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_ADD_VLAN_FILTER;\n\tnctrl.ncmd.s.param1 = vid;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"Add VLAN filter failed in core (ret: 0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\n\treturn ret;\n}\n\nstatic int liquidio_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t     __be16 proto __attribute__((unused)),\n\t\t\t\t     u16 vid)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_DEL_VLAN_FILTER;\n\tnctrl.ncmd.s.param1 = vid;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"Del VLAN filter failed in core (ret: 0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\treturn ret;\n}\n\n \nstatic int liquidio_set_rxcsum_command(struct net_device *netdev, int command,\n\t\t\t\t       u8 rx_cmd)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = command;\n\tnctrl.ncmd.s.param1 = rx_cmd;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"DEVFLAGS RXCSUM change failed in core(ret:0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\treturn ret;\n}\n\n \nstatic int liquidio_vxlan_port_command(struct net_device *netdev, int command,\n\t\t\t\t       u16 vxlan_port, u8 vxlan_cmd_bit)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = command;\n\tnctrl.ncmd.s.more = vxlan_cmd_bit;\n\tnctrl.ncmd.s.param1 = vxlan_port;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"VxLAN port add/delete failed in core (ret:0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\treturn ret;\n}\n\nstatic int liquidio_udp_tunnel_set_port(struct net_device *netdev,\n\t\t\t\t\tunsigned int table, unsigned int entry,\n\t\t\t\t\tstruct udp_tunnel_info *ti)\n{\n\treturn liquidio_vxlan_port_command(netdev,\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_CONFIG,\n\t\t\t\t\t   htons(ti->port),\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_ADD);\n}\n\nstatic int liquidio_udp_tunnel_unset_port(struct net_device *netdev,\n\t\t\t\t\t  unsigned int table,\n\t\t\t\t\t  unsigned int entry,\n\t\t\t\t\t  struct udp_tunnel_info *ti)\n{\n\treturn liquidio_vxlan_port_command(netdev,\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_CONFIG,\n\t\t\t\t\t   htons(ti->port),\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_DEL);\n}\n\nstatic const struct udp_tunnel_nic_info liquidio_udp_tunnels = {\n\t.set_port\t= liquidio_udp_tunnel_set_port,\n\t.unset_port\t= liquidio_udp_tunnel_unset_port,\n\t.tables\t\t= {\n\t\t{ .n_entries = 1024, .tunnel_types = UDP_TUNNEL_TYPE_VXLAN, },\n\t},\n};\n\n \nstatic netdev_features_t liquidio_fix_features(struct net_device *netdev,\n\t\t\t\t\t       netdev_features_t request)\n{\n\tstruct lio *lio = netdev_priv(netdev);\n\n\tif ((request & NETIF_F_RXCSUM) &&\n\t    !(lio->dev_capability & NETIF_F_RXCSUM))\n\t\trequest &= ~NETIF_F_RXCSUM;\n\n\tif ((request & NETIF_F_HW_CSUM) &&\n\t    !(lio->dev_capability & NETIF_F_HW_CSUM))\n\t\trequest &= ~NETIF_F_HW_CSUM;\n\n\tif ((request & NETIF_F_TSO) && !(lio->dev_capability & NETIF_F_TSO))\n\t\trequest &= ~NETIF_F_TSO;\n\n\tif ((request & NETIF_F_TSO6) && !(lio->dev_capability & NETIF_F_TSO6))\n\t\trequest &= ~NETIF_F_TSO6;\n\n\tif ((request & NETIF_F_LRO) && !(lio->dev_capability & NETIF_F_LRO))\n\t\trequest &= ~NETIF_F_LRO;\n\n\t \n\tif (!(request & NETIF_F_RXCSUM) && (netdev->features & NETIF_F_LRO) &&\n\t    (lio->dev_capability & NETIF_F_LRO))\n\t\trequest &= ~NETIF_F_LRO;\n\n\tif ((request & NETIF_F_HW_VLAN_CTAG_FILTER) &&\n\t    !(lio->dev_capability & NETIF_F_HW_VLAN_CTAG_FILTER))\n\t\trequest &= ~NETIF_F_HW_VLAN_CTAG_FILTER;\n\n\treturn request;\n}\n\n \nstatic int liquidio_set_features(struct net_device *netdev,\n\t\t\t\t netdev_features_t features)\n{\n\tstruct lio *lio = netdev_priv(netdev);\n\n\tif ((features & NETIF_F_LRO) &&\n\t    (lio->dev_capability & NETIF_F_LRO) &&\n\t    !(netdev->features & NETIF_F_LRO))\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_LRO_ENABLE,\n\t\t\t\t     OCTNIC_LROIPV4 | OCTNIC_LROIPV6);\n\telse if (!(features & NETIF_F_LRO) &&\n\t\t (lio->dev_capability & NETIF_F_LRO) &&\n\t\t (netdev->features & NETIF_F_LRO))\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_LRO_DISABLE,\n\t\t\t\t     OCTNIC_LROIPV4 | OCTNIC_LROIPV6);\n\n\t \n\tif (!(netdev->features & NETIF_F_RXCSUM) &&\n\t    (lio->enc_dev_capability & NETIF_F_RXCSUM) &&\n\t    (features & NETIF_F_RXCSUM))\n\t\tliquidio_set_rxcsum_command(netdev,\n\t\t\t\t\t    OCTNET_CMD_TNL_RX_CSUM_CTL,\n\t\t\t\t\t    OCTNET_CMD_RXCSUM_ENABLE);\n\telse if ((netdev->features & NETIF_F_RXCSUM) &&\n\t\t (lio->enc_dev_capability & NETIF_F_RXCSUM) &&\n\t\t !(features & NETIF_F_RXCSUM))\n\t\tliquidio_set_rxcsum_command(netdev, OCTNET_CMD_TNL_RX_CSUM_CTL,\n\t\t\t\t\t    OCTNET_CMD_RXCSUM_DISABLE);\n\n\tif ((features & NETIF_F_HW_VLAN_CTAG_FILTER) &&\n\t    (lio->dev_capability & NETIF_F_HW_VLAN_CTAG_FILTER) &&\n\t    !(netdev->features & NETIF_F_HW_VLAN_CTAG_FILTER))\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_VLAN_FILTER_CTL,\n\t\t\t\t     OCTNET_CMD_VLAN_FILTER_ENABLE);\n\telse if (!(features & NETIF_F_HW_VLAN_CTAG_FILTER) &&\n\t\t (lio->dev_capability & NETIF_F_HW_VLAN_CTAG_FILTER) &&\n\t\t (netdev->features & NETIF_F_HW_VLAN_CTAG_FILTER))\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_VLAN_FILTER_CTL,\n\t\t\t\t     OCTNET_CMD_VLAN_FILTER_DISABLE);\n\n\treturn 0;\n}\n\nstatic int __liquidio_set_vf_mac(struct net_device *netdev, int vfidx,\n\t\t\t\t u8 *mac, bool is_admin_assigned)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tif (!is_valid_ether_addr(mac))\n\t\treturn -EINVAL;\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.max_vfs)\n\t\treturn -EINVAL;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_CHANGE_MACADDR;\n\t \n\tnctrl.ncmd.s.param1 = vfidx + 1;\n\tnctrl.ncmd.s.more = 1;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tif (is_admin_assigned) {\n\t\tnctrl.ncmd.s.param2 = true;\n\t\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\t}\n\n\tnctrl.udd[0] = 0;\n\t \n\tether_addr_copy((u8 *)&nctrl.udd[0] + 2, mac);\n\n\toct->sriov_info.vf_macaddr[vfidx] = nctrl.udd[0];\n\n\tret = octnet_send_nic_ctrl_pkt(oct, &nctrl);\n\tif (ret > 0)\n\t\tret = -EIO;\n\n\treturn ret;\n}\n\nstatic int liquidio_set_vf_mac(struct net_device *netdev, int vfidx, u8 *mac)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tint retval;\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.num_vfs_alloced)\n\t\treturn -EINVAL;\n\n\tretval = __liquidio_set_vf_mac(netdev, vfidx, mac, true);\n\tif (!retval)\n\t\tcn23xx_tell_vf_its_macaddr_changed(oct, vfidx, mac);\n\n\treturn retval;\n}\n\nstatic int liquidio_set_vf_spoofchk(struct net_device *netdev, int vfidx,\n\t\t\t\t    bool enable)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint retval;\n\n\tif (!(oct->fw_info.app_cap_flags & LIQUIDIO_SPOOFCHK_CAP)) {\n\t\tnetif_info(lio, drv, lio->netdev,\n\t\t\t   \"firmware does not support spoofchk\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.num_vfs_alloced) {\n\t\tnetif_info(lio, drv, lio->netdev, \"Invalid vfidx %d\\n\", vfidx);\n\t\treturn -EINVAL;\n\t}\n\n\tif (enable) {\n\t\tif (oct->sriov_info.vf_spoofchk[vfidx])\n\t\t\treturn 0;\n\t} else {\n\t\t \n\t\tif (!oct->sriov_info.vf_spoofchk[vfidx])\n\t\t\treturn 0;\n\t}\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\tnctrl.ncmd.s.cmdgroup = OCTNET_CMD_GROUP1;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_SET_VF_SPOOFCHK;\n\tnctrl.ncmd.s.param1 =\n\t\tvfidx + 1;  \n\tnctrl.ncmd.s.param2 = enable;\n\tnctrl.ncmd.s.more = 0;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.cb_fn = NULL;\n\n\tretval = octnet_send_nic_ctrl_pkt(oct, &nctrl);\n\n\tif (retval) {\n\t\tnetif_info(lio, drv, lio->netdev,\n\t\t\t   \"Failed to set VF %d spoofchk %s\\n\", vfidx,\n\t\t\tenable ? \"on\" : \"off\");\n\t\treturn -1;\n\t}\n\n\toct->sriov_info.vf_spoofchk[vfidx] = enable;\n\tnetif_info(lio, drv, lio->netdev, \"VF %u spoofchk is %s\\n\", vfidx,\n\t\t   enable ? \"on\" : \"off\");\n\n\treturn 0;\n}\n\nstatic int liquidio_set_vf_vlan(struct net_device *netdev, int vfidx,\n\t\t\t\tu16 vlan, u8 qos, __be16 vlan_proto)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tu16 vlantci;\n\tint ret = 0;\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.num_vfs_alloced)\n\t\treturn -EINVAL;\n\n\tif (vlan_proto != htons(ETH_P_8021Q))\n\t\treturn -EPROTONOSUPPORT;\n\n\tif (vlan >= VLAN_N_VID || qos > 7)\n\t\treturn -EINVAL;\n\n\tif (vlan)\n\t\tvlantci = vlan | (u16)qos << VLAN_PRIO_SHIFT;\n\telse\n\t\tvlantci = 0;\n\n\tif (oct->sriov_info.vf_vlantci[vfidx] == vlantci)\n\t\treturn 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tif (vlan)\n\t\tnctrl.ncmd.s.cmd = OCTNET_CMD_ADD_VLAN_FILTER;\n\telse\n\t\tnctrl.ncmd.s.cmd = OCTNET_CMD_DEL_VLAN_FILTER;\n\n\tnctrl.ncmd.s.param1 = vlantci;\n\tnctrl.ncmd.s.param2 =\n\t    vfidx + 1;  \n\tnctrl.ncmd.s.more = 0;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.cb_fn = NULL;\n\n\tret = octnet_send_nic_ctrl_pkt(oct, &nctrl);\n\tif (ret) {\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t\treturn ret;\n\t}\n\n\toct->sriov_info.vf_vlantci[vfidx] = vlantci;\n\n\treturn ret;\n}\n\nstatic int liquidio_get_vf_config(struct net_device *netdev, int vfidx,\n\t\t\t\t  struct ifla_vf_info *ivi)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tu8 *macaddr;\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.num_vfs_alloced)\n\t\treturn -EINVAL;\n\n\tmemset(ivi, 0, sizeof(struct ifla_vf_info));\n\n\tivi->vf = vfidx;\n\tmacaddr = 2 + (u8 *)&oct->sriov_info.vf_macaddr[vfidx];\n\tether_addr_copy(&ivi->mac[0], macaddr);\n\tivi->vlan = oct->sriov_info.vf_vlantci[vfidx] & VLAN_VID_MASK;\n\tivi->qos = oct->sriov_info.vf_vlantci[vfidx] >> VLAN_PRIO_SHIFT;\n\tif (oct->sriov_info.trusted_vf.active &&\n\t    oct->sriov_info.trusted_vf.id == vfidx)\n\t\tivi->trusted = true;\n\telse\n\t\tivi->trusted = false;\n\tivi->linkstate = oct->sriov_info.vf_linkstate[vfidx];\n\tivi->spoofchk = oct->sriov_info.vf_spoofchk[vfidx];\n\tivi->max_tx_rate = lio->linfo.link.s.speed;\n\tivi->min_tx_rate = 0;\n\n\treturn 0;\n}\n\nstatic int liquidio_send_vf_trust_cmd(struct lio *lio, int vfidx, bool trusted)\n{\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octeon_soft_command *sc;\n\tint retval;\n\n\tsc = octeon_alloc_soft_command(oct, 0, 16, 0);\n\tif (!sc)\n\t\treturn -ENOMEM;\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\t \n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_SET_TRUSTED_VF, 0, vfidx + 1,\n\t\t\t\t    trusted);\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tretval = octeon_send_soft_command(oct, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tocteon_free_soft_command(oct, sc);\n\t\tretval = -1;\n\t} else {\n\t\t \n\t\tretval = wait_for_sc_completion_timeout(oct, sc, 0);\n\t\tif (retval)\n\t\t\treturn (retval);\n\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t}\n\n\treturn retval;\n}\n\nstatic int liquidio_set_vf_trust(struct net_device *netdev, int vfidx,\n\t\t\t\t bool setting)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tif (strcmp(oct->fw_info.liquidio_firmware_version, \"1.7.1\") < 0) {\n\t\t \n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.num_vfs_alloced) {\n\t\tnetif_info(lio, drv, lio->netdev, \"Invalid vfidx %d\\n\", vfidx);\n\t\treturn -EINVAL;\n\t}\n\n\tif (setting) {\n\t\t \n\n\t\tif (oct->sriov_info.trusted_vf.active &&\n\t\t    oct->sriov_info.trusted_vf.id == vfidx)\n\t\t\treturn 0;\n\n\t\tif (oct->sriov_info.trusted_vf.active) {\n\t\t\tnetif_info(lio, drv, lio->netdev, \"More than one trusted VF is not allowed\\n\");\n\t\t\treturn -EPERM;\n\t\t}\n\t} else {\n\t\t \n\n\t\tif (!oct->sriov_info.trusted_vf.active)\n\t\t\treturn 0;\n\t}\n\n\tif (!liquidio_send_vf_trust_cmd(lio, vfidx, setting)) {\n\t\tif (setting) {\n\t\t\toct->sriov_info.trusted_vf.id = vfidx;\n\t\t\toct->sriov_info.trusted_vf.active = true;\n\t\t} else {\n\t\t\toct->sriov_info.trusted_vf.active = false;\n\t\t}\n\n\t\tnetif_info(lio, drv, lio->netdev, \"VF %u is %strusted\\n\", vfidx,\n\t\t\t   setting ? \"\" : \"not \");\n\t} else {\n\t\tnetif_info(lio, drv, lio->netdev, \"Failed to set VF trusted\\n\");\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic int liquidio_set_vf_link_state(struct net_device *netdev, int vfidx,\n\t\t\t\t      int linkstate)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.num_vfs_alloced)\n\t\treturn -EINVAL;\n\n\tif (oct->sriov_info.vf_linkstate[vfidx] == linkstate)\n\t\treturn 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_SET_VF_LINKSTATE;\n\tnctrl.ncmd.s.param1 =\n\t    vfidx + 1;  \n\tnctrl.ncmd.s.param2 = linkstate;\n\tnctrl.ncmd.s.more = 0;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.cb_fn = NULL;\n\n\tret = octnet_send_nic_ctrl_pkt(oct, &nctrl);\n\n\tif (!ret)\n\t\toct->sriov_info.vf_linkstate[vfidx] = linkstate;\n\telse if (ret > 0)\n\t\tret = -EIO;\n\n\treturn ret;\n}\n\nstatic int\nliquidio_eswitch_mode_get(struct devlink *devlink, u16 *mode)\n{\n\tstruct lio_devlink_priv *priv;\n\tstruct octeon_device *oct;\n\n\tpriv = devlink_priv(devlink);\n\toct = priv->oct;\n\n\t*mode = oct->eswitch_mode;\n\n\treturn 0;\n}\n\nstatic int\nliquidio_eswitch_mode_set(struct devlink *devlink, u16 mode,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct lio_devlink_priv *priv;\n\tstruct octeon_device *oct;\n\tint ret = 0;\n\n\tpriv = devlink_priv(devlink);\n\toct = priv->oct;\n\n\tif (!(oct->fw_info.app_cap_flags & LIQUIDIO_SWITCHDEV_CAP))\n\t\treturn -EINVAL;\n\n\tif (oct->eswitch_mode == mode)\n\t\treturn 0;\n\n\tswitch (mode) {\n\tcase DEVLINK_ESWITCH_MODE_SWITCHDEV:\n\t\toct->eswitch_mode = mode;\n\t\tret = lio_vf_rep_create(oct);\n\t\tbreak;\n\n\tcase DEVLINK_ESWITCH_MODE_LEGACY:\n\t\tlio_vf_rep_destroy(oct);\n\t\toct->eswitch_mode = mode;\n\t\tbreak;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic const struct devlink_ops liquidio_devlink_ops = {\n\t.eswitch_mode_get = liquidio_eswitch_mode_get,\n\t.eswitch_mode_set = liquidio_eswitch_mode_set,\n};\n\nstatic int\nliquidio_get_port_parent_id(struct net_device *dev,\n\t\t\t    struct netdev_phys_item_id *ppid)\n{\n\tstruct lio *lio = GET_LIO(dev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tif (oct->eswitch_mode != DEVLINK_ESWITCH_MODE_SWITCHDEV)\n\t\treturn -EOPNOTSUPP;\n\n\tppid->id_len = ETH_ALEN;\n\tether_addr_copy(ppid->id, (void *)&lio->linfo.hw_addr + 2);\n\n\treturn 0;\n}\n\nstatic int liquidio_get_vf_stats(struct net_device *netdev, int vfidx,\n\t\t\t\t struct ifla_vf_stats *vf_stats)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct oct_vf_stats stats;\n\tint ret;\n\n\tif (vfidx < 0 || vfidx >= oct->sriov_info.num_vfs_alloced)\n\t\treturn -EINVAL;\n\n\tmemset(&stats, 0, sizeof(struct oct_vf_stats));\n\tret = cn23xx_get_vf_stats(oct, vfidx, &stats);\n\tif (!ret) {\n\t\tvf_stats->rx_packets = stats.rx_packets;\n\t\tvf_stats->tx_packets = stats.tx_packets;\n\t\tvf_stats->rx_bytes = stats.rx_bytes;\n\t\tvf_stats->tx_bytes = stats.tx_bytes;\n\t\tvf_stats->broadcast = stats.broadcast;\n\t\tvf_stats->multicast = stats.multicast;\n\t}\n\n\treturn ret;\n}\n\nstatic const struct net_device_ops lionetdevops = {\n\t.ndo_open\t\t= liquidio_open,\n\t.ndo_stop\t\t= liquidio_stop,\n\t.ndo_start_xmit\t\t= liquidio_xmit,\n\t.ndo_get_stats64\t= liquidio_get_stats64,\n\t.ndo_set_mac_address\t= liquidio_set_mac,\n\t.ndo_set_rx_mode\t= liquidio_set_mcast_list,\n\t.ndo_tx_timeout\t\t= liquidio_tx_timeout,\n\n\t.ndo_vlan_rx_add_vid    = liquidio_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid   = liquidio_vlan_rx_kill_vid,\n\t.ndo_change_mtu\t\t= liquidio_change_mtu,\n\t.ndo_eth_ioctl\t\t= liquidio_ioctl,\n\t.ndo_fix_features\t= liquidio_fix_features,\n\t.ndo_set_features\t= liquidio_set_features,\n\t.ndo_set_vf_mac\t\t= liquidio_set_vf_mac,\n\t.ndo_set_vf_vlan\t= liquidio_set_vf_vlan,\n\t.ndo_get_vf_config\t= liquidio_get_vf_config,\n\t.ndo_set_vf_spoofchk\t= liquidio_set_vf_spoofchk,\n\t.ndo_set_vf_trust\t= liquidio_set_vf_trust,\n\t.ndo_set_vf_link_state  = liquidio_set_vf_link_state,\n\t.ndo_get_vf_stats\t= liquidio_get_vf_stats,\n\t.ndo_get_port_parent_id\t= liquidio_get_port_parent_id,\n};\n\n \nstatic int __init liquidio_init(void)\n{\n\tint i;\n\tstruct handshake *hs;\n\n\tinit_completion(&first_stage);\n\n\tocteon_init_device_list(OCTEON_CONFIG_TYPE_DEFAULT);\n\n\tif (liquidio_init_pci())\n\t\treturn -EINVAL;\n\n\twait_for_completion_timeout(&first_stage, msecs_to_jiffies(1000));\n\n\tfor (i = 0; i < MAX_OCTEON_DEVICES; i++) {\n\t\ths = &handshake[i];\n\t\tif (hs->pci_dev) {\n\t\t\twait_for_completion(&hs->init);\n\t\t\tif (!hs->init_ok) {\n\t\t\t\t \n\t\t\t\tdev_err(&hs->pci_dev->dev,\n\t\t\t\t\t\"Failed to init device\\n\");\n\t\t\t\tliquidio_deinit_pci();\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = 0; i < MAX_OCTEON_DEVICES; i++) {\n\t\ths = &handshake[i];\n\t\tif (hs->pci_dev) {\n\t\t\twait_for_completion_timeout(&hs->started,\n\t\t\t\t\t\t    msecs_to_jiffies(30000));\n\t\t\tif (!hs->started_ok) {\n\t\t\t\t \n\t\t\t\tdev_err(&hs->pci_dev->dev,\n\t\t\t\t\t\"Firmware failed to start\\n\");\n\t\t\t\tliquidio_deinit_pci();\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int lio_nic_info(struct octeon_recv_info *recv_info, void *buf)\n{\n\tstruct octeon_device *oct = (struct octeon_device *)buf;\n\tstruct octeon_recv_pkt *recv_pkt = recv_info->recv_pkt;\n\tint gmxport = 0;\n\tunion oct_link_status *ls;\n\tint i;\n\n\tif (recv_pkt->buffer_size[0] != (sizeof(*ls) + OCT_DROQ_INFO_SIZE)) {\n\t\tdev_err(&oct->pci_dev->dev, \"Malformed NIC_INFO, len=%d, ifidx=%d\\n\",\n\t\t\trecv_pkt->buffer_size[0],\n\t\t\trecv_pkt->rh.r_nic_info.gmxport);\n\t\tgoto nic_info_err;\n\t}\n\n\tgmxport = recv_pkt->rh.r_nic_info.gmxport;\n\tls = (union oct_link_status *)(get_rbd(recv_pkt->buffer_ptr[0]) +\n\t\tOCT_DROQ_INFO_SIZE);\n\n\tocteon_swap_8B_data((u64 *)ls, (sizeof(union oct_link_status)) >> 3);\n\tfor (i = 0; i < oct->ifcount; i++) {\n\t\tif (oct->props[i].gmxport == gmxport) {\n\t\t\tupdate_link_status(oct->props[i].netdev, ls);\n\t\t\tbreak;\n\t\t}\n\t}\n\nnic_info_err:\n\tfor (i = 0; i < recv_pkt->buffer_count; i++)\n\t\trecv_buffer_free(recv_pkt->buffer_ptr[i]);\n\tocteon_free_recv_info(recv_info);\n\treturn 0;\n}\n\n \nstatic int setup_nic_devices(struct octeon_device *octeon_dev)\n{\n\tstruct lio *lio = NULL;\n\tstruct net_device *netdev;\n\tu8 mac[6], i, j, *fw_ver, *micro_ver;\n\tunsigned long micro;\n\tu32 cur_ver;\n\tstruct octeon_soft_command *sc;\n\tstruct liquidio_if_cfg_resp *resp;\n\tstruct octdev_props *props;\n\tint retval, num_iqueues, num_oqueues;\n\tint max_num_queues = 0;\n\tunion oct_nic_if_cfg if_cfg;\n\tunsigned int base_queue;\n\tunsigned int gmx_port_id;\n\tu32 resp_size, data_size;\n\tu32 ifidx_or_pfnum;\n\tstruct lio_version *vdata;\n\tstruct devlink *devlink;\n\tstruct lio_devlink_priv *lio_devlink;\n\n\t \n\tocteon_register_dispatch_fn(octeon_dev, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_INFO,\n\t\t\t\t    lio_nic_info, octeon_dev);\n\n\t \n\tocteon_register_reqtype_free_fn(octeon_dev, REQTYPE_NORESP_NET,\n\t\t\t\t\tfree_netbuf);\n\n\tocteon_register_reqtype_free_fn(octeon_dev, REQTYPE_NORESP_NET_SG,\n\t\t\t\t\tfree_netsgbuf);\n\n\tocteon_register_reqtype_free_fn(octeon_dev, REQTYPE_RESP_NET_SG,\n\t\t\t\t\tfree_netsgbuf_with_resp);\n\n\tfor (i = 0; i < octeon_dev->ifcount; i++) {\n\t\tresp_size = sizeof(struct liquidio_if_cfg_resp);\n\t\tdata_size = sizeof(struct lio_version);\n\t\tsc = (struct octeon_soft_command *)\n\t\t\tocteon_alloc_soft_command(octeon_dev, data_size,\n\t\t\t\t\t\t  resp_size, 0);\n\t\tresp = (struct liquidio_if_cfg_resp *)sc->virtrptr;\n\t\tvdata = (struct lio_version *)sc->virtdptr;\n\n\t\t*((u64 *)vdata) = 0;\n\t\tvdata->major = cpu_to_be16(LIQUIDIO_BASE_MAJOR_VERSION);\n\t\tvdata->minor = cpu_to_be16(LIQUIDIO_BASE_MINOR_VERSION);\n\t\tvdata->micro = cpu_to_be16(LIQUIDIO_BASE_MICRO_VERSION);\n\n\t\tif (OCTEON_CN23XX_PF(octeon_dev)) {\n\t\t\tnum_iqueues = octeon_dev->sriov_info.num_pf_rings;\n\t\t\tnum_oqueues = octeon_dev->sriov_info.num_pf_rings;\n\t\t\tbase_queue = octeon_dev->sriov_info.pf_srn;\n\n\t\t\tgmx_port_id = octeon_dev->pf_num;\n\t\t\tifidx_or_pfnum = octeon_dev->pf_num;\n\t\t} else {\n\t\t\tnum_iqueues = CFG_GET_NUM_TXQS_NIC_IF(\n\t\t\t\t\t\tocteon_get_conf(octeon_dev), i);\n\t\t\tnum_oqueues = CFG_GET_NUM_RXQS_NIC_IF(\n\t\t\t\t\t\tocteon_get_conf(octeon_dev), i);\n\t\t\tbase_queue = CFG_GET_BASE_QUE_NIC_IF(\n\t\t\t\t\t\tocteon_get_conf(octeon_dev), i);\n\t\t\tgmx_port_id = CFG_GET_GMXID_NIC_IF(\n\t\t\t\t\t\tocteon_get_conf(octeon_dev), i);\n\t\t\tifidx_or_pfnum = i;\n\t\t}\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"requesting config for interface %d, iqs %d, oqs %d\\n\",\n\t\t\tifidx_or_pfnum, num_iqueues, num_oqueues);\n\n\t\tif_cfg.u64 = 0;\n\t\tif_cfg.s.num_iqueues = num_iqueues;\n\t\tif_cfg.s.num_oqueues = num_oqueues;\n\t\tif_cfg.s.base_queue = base_queue;\n\t\tif_cfg.s.gmx_port_id = gmx_port_id;\n\n\t\tsc->iq_no = 0;\n\n\t\tocteon_prepare_soft_command(octeon_dev, sc, OPCODE_NIC,\n\t\t\t\t\t    OPCODE_NIC_IF_CFG, 0,\n\t\t\t\t\t    if_cfg.u64, 0);\n\n\t\tinit_completion(&sc->complete);\n\t\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\t\tretval = octeon_send_soft_command(octeon_dev, sc);\n\t\tif (retval == IQ_SEND_FAILED) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"iq/oq config failed status: %x\\n\",\n\t\t\t\tretval);\n\t\t\t \n\t\t\tocteon_free_soft_command(octeon_dev, sc);\n\t\t\treturn(-EIO);\n\t\t}\n\n\t\t \n\t\tretval = wait_for_sc_completion_timeout(octeon_dev, sc, 0);\n\t\tif (retval)\n\t\t\treturn retval;\n\n\t\tretval = resp->status;\n\t\tif (retval) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"iq/oq config failed\\n\");\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_done;\n\t\t}\n\t\tsnprintf(octeon_dev->fw_info.liquidio_firmware_version,\n\t\t\t 32, \"%s\",\n\t\t\t resp->cfg_info.liquidio_firmware_version);\n\n\t\t \n\t\tfw_ver = octeon_dev->fw_info.liquidio_firmware_version;\n\t\tif (memcmp(LIQUIDIO_BASE_VERSION,\n\t\t\t   fw_ver,\n\t\t\t   strlen(LIQUIDIO_BASE_VERSION))) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"Unmatched firmware version. Expected %s.x, got %s.\\n\",\n\t\t\t\tLIQUIDIO_BASE_VERSION, fw_ver);\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_done;\n\t\t} else if (atomic_read(octeon_dev->adapter_fw_state) ==\n\t\t\t   FW_IS_PRELOADED) {\n\t\t\tdev_info(&octeon_dev->pci_dev->dev,\n\t\t\t\t \"Using auto-loaded firmware version %s.\\n\",\n\t\t\t\t fw_ver);\n\t\t}\n\n\t\t \n\t\tmicro_ver = fw_ver + strlen(LIQUIDIO_BASE_VERSION) + 1;\n\t\tif (kstrtoul(micro_ver, 10, &micro) != 0)\n\t\t\tmicro = 0;\n\t\tocteon_dev->fw_info.ver.maj = LIQUIDIO_BASE_MAJOR_VERSION;\n\t\tocteon_dev->fw_info.ver.min = LIQUIDIO_BASE_MINOR_VERSION;\n\t\tocteon_dev->fw_info.ver.rev = micro;\n\n\t\tocteon_swap_8B_data((u64 *)(&resp->cfg_info),\n\t\t\t\t    (sizeof(struct liquidio_if_cfg_info)) >> 3);\n\n\t\tnum_iqueues = hweight64(resp->cfg_info.iqmask);\n\t\tnum_oqueues = hweight64(resp->cfg_info.oqmask);\n\n\t\tif (!(num_iqueues) || !(num_oqueues)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"Got bad iqueues (%016llx) or oqueues (%016llx) from firmware.\\n\",\n\t\t\t\tresp->cfg_info.iqmask,\n\t\t\t\tresp->cfg_info.oqmask);\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_done;\n\t\t}\n\n\t\tif (OCTEON_CN6XXX(octeon_dev)) {\n\t\t\tmax_num_queues = CFG_GET_IQ_MAX_Q(CHIP_CONF(octeon_dev,\n\t\t\t\t\t\t\t\t    cn6xxx));\n\t\t} else if (OCTEON_CN23XX_PF(octeon_dev)) {\n\t\t\tmax_num_queues = CFG_GET_IQ_MAX_Q(CHIP_CONF(octeon_dev,\n\t\t\t\t\t\t\t\t    cn23xx_pf));\n\t\t}\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"interface %d, iqmask %016llx, oqmask %016llx, numiqueues %d, numoqueues %d max_num_queues: %d\\n\",\n\t\t\ti, resp->cfg_info.iqmask, resp->cfg_info.oqmask,\n\t\t\tnum_iqueues, num_oqueues, max_num_queues);\n\t\tnetdev = alloc_etherdev_mq(LIO_SIZE, max_num_queues);\n\n\t\tif (!netdev) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Device allocation failed\\n\");\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_done;\n\t\t}\n\n\t\tSET_NETDEV_DEV(netdev, &octeon_dev->pci_dev->dev);\n\n\t\t \n\t\tnetdev->netdev_ops = &lionetdevops;\n\n\t\tretval = netif_set_real_num_rx_queues(netdev, num_oqueues);\n\t\tif (retval) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"setting real number rx failed\\n\");\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\tretval = netif_set_real_num_tx_queues(netdev, num_iqueues);\n\t\tif (retval) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"setting real number tx failed\\n\");\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\tlio = GET_LIO(netdev);\n\n\t\tmemset(lio, 0, sizeof(struct lio));\n\n\t\tlio->ifidx = ifidx_or_pfnum;\n\n\t\tprops = &octeon_dev->props[i];\n\t\tprops->gmxport = resp->cfg_info.linfo.gmxport;\n\t\tprops->netdev = netdev;\n\n\t\tlio->linfo.num_rxpciq = num_oqueues;\n\t\tlio->linfo.num_txpciq = num_iqueues;\n\t\tfor (j = 0; j < num_oqueues; j++) {\n\t\t\tlio->linfo.rxpciq[j].u64 =\n\t\t\t\tresp->cfg_info.linfo.rxpciq[j].u64;\n\t\t}\n\t\tfor (j = 0; j < num_iqueues; j++) {\n\t\t\tlio->linfo.txpciq[j].u64 =\n\t\t\t\tresp->cfg_info.linfo.txpciq[j].u64;\n\t\t}\n\t\tlio->linfo.hw_addr = resp->cfg_info.linfo.hw_addr;\n\t\tlio->linfo.gmxport = resp->cfg_info.linfo.gmxport;\n\t\tlio->linfo.link.u64 = resp->cfg_info.linfo.link.u64;\n\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\n\t\tlio->msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);\n\n\t\tif (OCTEON_CN23XX_PF(octeon_dev) ||\n\t\t    OCTEON_CN6XXX(octeon_dev)) {\n\t\t\tlio->dev_capability = NETIF_F_HIGHDMA\n\t\t\t\t\t      | NETIF_F_IP_CSUM\n\t\t\t\t\t      | NETIF_F_IPV6_CSUM\n\t\t\t\t\t      | NETIF_F_SG | NETIF_F_RXCSUM\n\t\t\t\t\t      | NETIF_F_GRO\n\t\t\t\t\t      | NETIF_F_TSO | NETIF_F_TSO6\n\t\t\t\t\t      | NETIF_F_LRO;\n\t\t}\n\t\tnetif_set_tso_max_size(netdev, OCTNIC_GSO_MAX_SIZE);\n\n\t\t \n\t\tlio->enc_dev_capability = NETIF_F_IP_CSUM\n\t\t\t\t\t  | NETIF_F_IPV6_CSUM\n\t\t\t\t\t  | NETIF_F_GSO_UDP_TUNNEL\n\t\t\t\t\t  | NETIF_F_HW_CSUM | NETIF_F_SG\n\t\t\t\t\t  | NETIF_F_RXCSUM\n\t\t\t\t\t  | NETIF_F_TSO | NETIF_F_TSO6\n\t\t\t\t\t  | NETIF_F_LRO;\n\n\t\tnetdev->hw_enc_features = (lio->enc_dev_capability &\n\t\t\t\t\t   ~NETIF_F_LRO);\n\n\t\tnetdev->udp_tunnel_nic_info = &liquidio_udp_tunnels;\n\n\t\tlio->dev_capability |= NETIF_F_GSO_UDP_TUNNEL;\n\n\t\tnetdev->vlan_features = lio->dev_capability;\n\t\t \n\t\tlio->dev_capability |=  NETIF_F_HW_VLAN_CTAG_FILTER |\n\t\t\t\t\tNETIF_F_HW_VLAN_CTAG_RX |\n\t\t\t\t\tNETIF_F_HW_VLAN_CTAG_TX;\n\n\t\tnetdev->features = (lio->dev_capability & ~NETIF_F_LRO);\n\n\t\tnetdev->hw_features = lio->dev_capability;\n\t\t \n\t\tnetdev->hw_features = netdev->hw_features &\n\t\t\t~NETIF_F_HW_VLAN_CTAG_RX;\n\n\t\t \n\t\tnetdev->min_mtu = LIO_MIN_MTU_SIZE;\n\t\tnetdev->max_mtu = LIO_MAX_MTU_SIZE;\n\n\t\t \n\t\tlio->oct_dev = octeon_dev;\n\t\tlio->octprops = props;\n\t\tlio->netdev = netdev;\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"if%d gmx: %d hw_addr: 0x%llx\\n\", i,\n\t\t\tlio->linfo.gmxport, CVM_CAST64(lio->linfo.hw_addr));\n\n\t\tfor (j = 0; j < octeon_dev->sriov_info.max_vfs; j++) {\n\t\t\tu8 vfmac[ETH_ALEN];\n\n\t\t\teth_random_addr(vfmac);\n\t\t\tif (__liquidio_set_vf_mac(netdev, j, vfmac, false)) {\n\t\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\t\"Error setting VF%d MAC address\\n\",\n\t\t\t\t\tj);\n\t\t\t\tgoto setup_nic_dev_free;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tocteon_swap_8B_data(&lio->linfo.hw_addr, 1);\n\t\tfor (j = 0; j < 6; j++)\n\t\t\tmac[j] = *((u8 *)(((u8 *)&lio->linfo.hw_addr) + 2 + j));\n\n\t\t \n\n\t\teth_hw_addr_set(netdev, mac);\n\n\t\t \n\t\tlio->txq = lio->linfo.txpciq[0].s.q_no;\n\t\tlio->rxq = lio->linfo.rxpciq[0].s.q_no;\n\t\tif (liquidio_setup_io_queues(octeon_dev, i,\n\t\t\t\t\t     lio->linfo.num_txpciq,\n\t\t\t\t\t     lio->linfo.num_rxpciq)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"I/O queues creation failed\\n\");\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\tifstate_set(lio, LIO_IFSTATE_DROQ_OPS);\n\n\t\tlio->tx_qsize = octeon_get_tx_qsize(octeon_dev, lio->txq);\n\t\tlio->rx_qsize = octeon_get_rx_qsize(octeon_dev, lio->rxq);\n\n\t\tif (lio_setup_glists(octeon_dev, lio, num_iqueues)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"Gather list allocation failed\\n\");\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\t \n\t\tliquidio_set_ethtool_ops(netdev);\n\t\tif (lio->oct_dev->chip_id == OCTEON_CN23XX_PF_VID)\n\t\t\tocteon_dev->priv_flags = OCT_PRIV_FLAG_DEFAULT;\n\t\telse\n\t\t\tocteon_dev->priv_flags = 0x0;\n\n\t\tif (netdev->features & NETIF_F_LRO)\n\t\t\tliquidio_set_feature(netdev, OCTNET_CMD_LRO_ENABLE,\n\t\t\t\t\t     OCTNIC_LROIPV4 | OCTNIC_LROIPV6);\n\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_VLAN_FILTER_CTL,\n\t\t\t\t     OCTNET_CMD_VLAN_FILTER_ENABLE);\n\n\t\tif ((debug != -1) && (debug & NETIF_MSG_HW))\n\t\t\tliquidio_set_feature(netdev,\n\t\t\t\t\t     OCTNET_CMD_VERBOSE_ENABLE, 0);\n\n\t\tif (setup_link_status_change_wq(netdev))\n\t\t\tgoto setup_nic_dev_free;\n\n\t\tif ((octeon_dev->fw_info.app_cap_flags &\n\t\t     LIQUIDIO_TIME_SYNC_CAP) &&\n\t\t    setup_sync_octeon_time_wq(netdev))\n\t\t\tgoto setup_nic_dev_free;\n\n\t\tif (setup_rx_oom_poll_fn(netdev))\n\t\t\tgoto setup_nic_dev_free;\n\n\t\t \n\t\tif (register_netdev(netdev)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Device registration failed\\n\");\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"Setup NIC ifidx:%d mac:%02x%02x%02x%02x%02x%02x\\n\",\n\t\t\ti, mac[0], mac[1], mac[2], mac[3], mac[4], mac[5]);\n\t\tnetif_carrier_off(netdev);\n\t\tlio->link_changes++;\n\n\t\tifstate_set(lio, LIO_IFSTATE_REGISTERED);\n\n\t\t \n\t\tliquidio_set_rxcsum_command(netdev, OCTNET_CMD_TNL_RX_CSUM_CTL,\n\t\t\t\t\t    OCTNET_CMD_RXCSUM_ENABLE);\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_TNL_TX_CSUM_CTL,\n\t\t\t\t     OCTNET_CMD_TXCSUM_ENABLE);\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"NIC ifidx:%d Setup successful\\n\", i);\n\n\t\tif (octeon_dev->subsystem_id ==\n\t\t\tOCTEON_CN2350_25GB_SUBSYS_ID ||\n\t\t    octeon_dev->subsystem_id ==\n\t\t\tOCTEON_CN2360_25GB_SUBSYS_ID) {\n\t\t\tcur_ver = OCT_FW_VER(octeon_dev->fw_info.ver.maj,\n\t\t\t\t\t     octeon_dev->fw_info.ver.min,\n\t\t\t\t\t     octeon_dev->fw_info.ver.rev);\n\n\t\t\t \n\t\t\tif (cur_ver < OCT_FW_VER(1, 7, 2)) {\n\t\t\t\tdev_info(&octeon_dev->pci_dev->dev,\n\t\t\t\t\t \"speed setting not supported by f/w.\");\n\t\t\t\tocteon_dev->speed_setting = 25;\n\t\t\t\tocteon_dev->no_speed_setting = 1;\n\t\t\t} else {\n\t\t\t\tliquidio_get_speed(lio);\n\t\t\t}\n\n\t\t\tif (octeon_dev->speed_setting == 0) {\n\t\t\t\tocteon_dev->speed_setting = 25;\n\t\t\t\tocteon_dev->no_speed_setting = 1;\n\t\t\t}\n\t\t} else {\n\t\t\tocteon_dev->no_speed_setting = 1;\n\t\t\tocteon_dev->speed_setting = 10;\n\t\t}\n\t\tocteon_dev->speed_boot = octeon_dev->speed_setting;\n\n\t\t \n\t\tif (octeon_dev->speed_boot == 25 &&\n\t\t    !octeon_dev->no_speed_setting) {\n\t\t\tliquidio_get_fec(lio);\n\t\t\tocteon_dev->props[lio->ifidx].fec_boot =\n\t\t\t\tocteon_dev->props[lio->ifidx].fec;\n\t\t}\n\t}\n\n\tdevice_lock(&octeon_dev->pci_dev->dev);\n\tdevlink = devlink_alloc(&liquidio_devlink_ops,\n\t\t\t\tsizeof(struct lio_devlink_priv),\n\t\t\t\t&octeon_dev->pci_dev->dev);\n\tif (!devlink) {\n\t\tdevice_unlock(&octeon_dev->pci_dev->dev);\n\t\tdev_err(&octeon_dev->pci_dev->dev, \"devlink alloc failed\\n\");\n\t\tgoto setup_nic_dev_free;\n\t}\n\n\tlio_devlink = devlink_priv(devlink);\n\tlio_devlink->oct = octeon_dev;\n\n\tocteon_dev->devlink = devlink;\n\tocteon_dev->eswitch_mode = DEVLINK_ESWITCH_MODE_LEGACY;\n\tdevlink_register(devlink);\n\tdevice_unlock(&octeon_dev->pci_dev->dev);\n\n\treturn 0;\n\nsetup_nic_dev_free:\n\n\twhile (i--) {\n\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\"NIC ifidx:%d Setup failed\\n\", i);\n\t\tliquidio_destroy_nic_device(octeon_dev, i);\n\t}\n\nsetup_nic_dev_done:\n\n\treturn -ENODEV;\n}\n\n#ifdef CONFIG_PCI_IOV\nstatic int octeon_enable_sriov(struct octeon_device *oct)\n{\n\tunsigned int num_vfs_alloced = oct->sriov_info.num_vfs_alloced;\n\tstruct pci_dev *vfdev;\n\tint err;\n\tu32 u;\n\n\tif (OCTEON_CN23XX_PF(oct) && num_vfs_alloced) {\n\t\terr = pci_enable_sriov(oct->pci_dev,\n\t\t\t\t       oct->sriov_info.num_vfs_alloced);\n\t\tif (err) {\n\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\"OCTEON: Failed to enable PCI sriov: %d\\n\",\n\t\t\t\terr);\n\t\t\toct->sriov_info.num_vfs_alloced = 0;\n\t\t\treturn err;\n\t\t}\n\t\toct->sriov_info.sriov_enabled = 1;\n\n\t\t \n\t\tu = 0;\n\t\tvfdev = pci_get_device(PCI_VENDOR_ID_CAVIUM,\n\t\t\t\t       OCTEON_CN23XX_VF_VID, NULL);\n\t\twhile (vfdev) {\n\t\t\tif (vfdev->is_virtfn &&\n\t\t\t    (vfdev->physfn == oct->pci_dev)) {\n\t\t\t\toct->sriov_info.dpiring_to_vfpcidev_lut[u] =\n\t\t\t\t\tvfdev;\n\t\t\t\tu += oct->sriov_info.rings_per_vf;\n\t\t\t}\n\t\t\tvfdev = pci_get_device(PCI_VENDOR_ID_CAVIUM,\n\t\t\t\t\t       OCTEON_CN23XX_VF_VID, vfdev);\n\t\t}\n\t}\n\n\treturn num_vfs_alloced;\n}\n\nstatic int lio_pci_sriov_disable(struct octeon_device *oct)\n{\n\tint u;\n\n\tif (pci_vfs_assigned(oct->pci_dev)) {\n\t\tdev_err(&oct->pci_dev->dev, \"VFs are still assigned to VMs.\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tpci_disable_sriov(oct->pci_dev);\n\n\tu = 0;\n\twhile (u < MAX_POSSIBLE_VFS) {\n\t\toct->sriov_info.dpiring_to_vfpcidev_lut[u] = NULL;\n\t\tu += oct->sriov_info.rings_per_vf;\n\t}\n\n\toct->sriov_info.num_vfs_alloced = 0;\n\tdev_info(&oct->pci_dev->dev, \"oct->pf_num:%d disabled VFs\\n\",\n\t\t oct->pf_num);\n\n\treturn 0;\n}\n\nstatic int liquidio_enable_sriov(struct pci_dev *dev, int num_vfs)\n{\n\tstruct octeon_device *oct = pci_get_drvdata(dev);\n\tint ret = 0;\n\n\tif ((num_vfs == oct->sriov_info.num_vfs_alloced) &&\n\t    (oct->sriov_info.sriov_enabled)) {\n\t\tdev_info(&oct->pci_dev->dev, \"oct->pf_num:%d already enabled num_vfs:%d\\n\",\n\t\t\t oct->pf_num, num_vfs);\n\t\treturn 0;\n\t}\n\n\tif (!num_vfs) {\n\t\tlio_vf_rep_destroy(oct);\n\t\tret = lio_pci_sriov_disable(oct);\n\t} else if (num_vfs > oct->sriov_info.max_vfs) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"OCTEON: Max allowed VFs:%d user requested:%d\",\n\t\t\toct->sriov_info.max_vfs, num_vfs);\n\t\tret = -EPERM;\n\t} else {\n\t\toct->sriov_info.num_vfs_alloced = num_vfs;\n\t\tret = octeon_enable_sriov(oct);\n\t\tdev_info(&oct->pci_dev->dev, \"oct->pf_num:%d num_vfs:%d\\n\",\n\t\t\t oct->pf_num, num_vfs);\n\t\tret = lio_vf_rep_create(oct);\n\t\tif (ret)\n\t\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t\t \"vf representor create failed\");\n\t}\n\n\treturn ret;\n}\n#endif\n\n \nstatic int liquidio_init_nic_module(struct octeon_device *oct)\n{\n\tint i, retval = 0;\n\tint num_nic_ports = CFG_GET_NUM_NIC_PORTS(octeon_get_conf(oct));\n\n\tdev_dbg(&oct->pci_dev->dev, \"Initializing network interfaces\\n\");\n\n\t \n\t \n\toct->ifcount = num_nic_ports;\n\n\tmemset(oct->props, 0, sizeof(struct octdev_props) * num_nic_ports);\n\n\tfor (i = 0; i < MAX_OCTEON_LINKS; i++)\n\t\toct->props[i].gmxport = -1;\n\n\tretval = setup_nic_devices(oct);\n\tif (retval) {\n\t\tdev_err(&oct->pci_dev->dev, \"Setup NIC devices failed\\n\");\n\t\tgoto octnet_init_failure;\n\t}\n\n\t \n\tif (!oct->octeon_id &&\n\t    oct->fw_info.app_cap_flags & LIQUIDIO_SWITCHDEV_CAP) {\n\t\tretval = lio_vf_rep_modinit();\n\t\tif (retval) {\n\t\t\tliquidio_stop_nic_module(oct);\n\t\t\tgoto octnet_init_failure;\n\t\t}\n\t}\n\n\tliquidio_ptp_init(oct);\n\n\tdev_dbg(&oct->pci_dev->dev, \"Network interfaces ready\\n\");\n\n\treturn retval;\n\noctnet_init_failure:\n\n\toct->ifcount = 0;\n\n\treturn retval;\n}\n\n \nstatic void nic_starter(struct work_struct *work)\n{\n\tstruct octeon_device *oct;\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\n\toct = (struct octeon_device *)wk->ctxptr;\n\n\tif (atomic_read(&oct->status) == OCT_DEV_RUNNING)\n\t\treturn;\n\n\t \n\tif (atomic_read(&oct->status) != OCT_DEV_CORE_OK) {\n\t\tschedule_delayed_work(&oct->nic_poll_work.work,\n\t\t\t\t      LIQUIDIO_STARTER_POLL_INTERVAL_MS);\n\t\treturn;\n\t}\n\n\tatomic_set(&oct->status, OCT_DEV_RUNNING);\n\n\tif (oct->app_mode && oct->app_mode == CVM_DRV_NIC_APP) {\n\t\tdev_dbg(&oct->pci_dev->dev, \"Starting NIC module\\n\");\n\n\t\tif (liquidio_init_nic_module(oct))\n\t\t\tdev_err(&oct->pci_dev->dev, \"NIC initialization failed\\n\");\n\t\telse\n\t\t\thandshake[oct->octeon_id].started_ok = 1;\n\t} else {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Unexpected application running on NIC (%d). Check firmware.\\n\",\n\t\t\toct->app_mode);\n\t}\n\n\tcomplete(&handshake[oct->octeon_id].started);\n}\n\nstatic int\nocteon_recv_vf_drv_notice(struct octeon_recv_info *recv_info, void *buf)\n{\n\tstruct octeon_device *oct = (struct octeon_device *)buf;\n\tstruct octeon_recv_pkt *recv_pkt = recv_info->recv_pkt;\n\tint i, notice, vf_idx;\n\tbool cores_crashed;\n\tu64 *data, vf_num;\n\n\tnotice = recv_pkt->rh.r.ossp;\n\tdata = (u64 *)(get_rbd(recv_pkt->buffer_ptr[0]) + OCT_DROQ_INFO_SIZE);\n\n\t \n\tvf_num = data[0];\n\tocteon_swap_8B_data(&vf_num, 1);\n\tvf_idx = (int)vf_num - 1;\n\n\tcores_crashed = READ_ONCE(oct->cores_crashed);\n\n\tif (notice == VF_DRV_LOADED) {\n\t\tif (!(oct->sriov_info.vf_drv_loaded_mask & BIT_ULL(vf_idx))) {\n\t\t\toct->sriov_info.vf_drv_loaded_mask |= BIT_ULL(vf_idx);\n\t\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t\t \"driver for VF%d was loaded\\n\", vf_idx);\n\t\t\tif (!cores_crashed)\n\t\t\t\ttry_module_get(THIS_MODULE);\n\t\t}\n\t} else if (notice == VF_DRV_REMOVED) {\n\t\tif (oct->sriov_info.vf_drv_loaded_mask & BIT_ULL(vf_idx)) {\n\t\t\toct->sriov_info.vf_drv_loaded_mask &= ~BIT_ULL(vf_idx);\n\t\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t\t \"driver for VF%d was removed\\n\", vf_idx);\n\t\t\tif (!cores_crashed)\n\t\t\t\tmodule_put(THIS_MODULE);\n\t\t}\n\t} else if (notice == VF_DRV_MACADDR_CHANGED) {\n\t\tu8 *b = (u8 *)&data[1];\n\n\t\toct->sriov_info.vf_macaddr[vf_idx] = data[1];\n\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t \"VF driver changed VF%d's MAC address to %pM\\n\",\n\t\t\t vf_idx, b + 2);\n\t}\n\n\tfor (i = 0; i < recv_pkt->buffer_count; i++)\n\t\trecv_buffer_free(recv_pkt->buffer_ptr[i]);\n\tocteon_free_recv_info(recv_info);\n\n\treturn 0;\n}\n\n \nstatic int octeon_device_init(struct octeon_device *octeon_dev)\n{\n\tint j, ret;\n\tchar bootcmd[] = \"\\n\";\n\tchar *dbg_enb = NULL;\n\tenum lio_fw_state fw_state;\n\tstruct octeon_device_priv *oct_priv = octeon_dev->priv;\n\tatomic_set(&octeon_dev->status, OCT_DEV_BEGIN_STATE);\n\n\t \n\tif (octeon_pci_os_setup(octeon_dev))\n\t\treturn 1;\n\n\tatomic_set(&octeon_dev->status, OCT_DEV_PCI_ENABLE_DONE);\n\n\t \n\tif (octeon_chip_specific_setup(octeon_dev)) {\n\t\tdev_err(&octeon_dev->pci_dev->dev, \"Chip specific setup failed\\n\");\n\t\treturn 1;\n\t}\n\n\tatomic_set(&octeon_dev->status, OCT_DEV_PCI_MAP_DONE);\n\n\t \n\tocteon_register_device(octeon_dev, octeon_dev->pci_dev->bus->number,\n\t\t\t       PCI_SLOT(octeon_dev->pci_dev->devfn),\n\t\t\t       PCI_FUNC(octeon_dev->pci_dev->devfn),\n\t\t\t       true);\n\n\tocteon_dev->app_mode = CVM_DRV_INVALID_APP;\n\n\t \n\tif (OCTEON_CN23XX_PF(octeon_dev) &&\n\t    cn23xx_fw_loaded(octeon_dev) && fw_type_is_auto()) {\n\t\tatomic_cmpxchg(octeon_dev->adapter_fw_state,\n\t\t\t       FW_NEEDS_TO_BE_LOADED, FW_IS_PRELOADED);\n\t}\n\n\t \n\tfw_state = atomic_cmpxchg(octeon_dev->adapter_fw_state,\n\t\t\t\t  FW_NEEDS_TO_BE_LOADED,\n\t\t\t\t  FW_IS_BEING_LOADED);\n\n\t \n\n\t \n\tif (fw_state == FW_NEEDS_TO_BE_LOADED)\n\t\tif (octeon_dev->fn_list.soft_reset(octeon_dev))\n\t\t\treturn 1;\n\n\t \n\tif (octeon_init_dispatch_list(octeon_dev))\n\t\treturn 1;\n\n\tocteon_register_dispatch_fn(octeon_dev, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_CORE_DRV_ACTIVE,\n\t\t\t\t    octeon_core_drv_init,\n\t\t\t\t    octeon_dev);\n\n\tocteon_register_dispatch_fn(octeon_dev, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_VF_DRV_NOTICE,\n\t\t\t\t    octeon_recv_vf_drv_notice, octeon_dev);\n\tINIT_DELAYED_WORK(&octeon_dev->nic_poll_work.work, nic_starter);\n\tocteon_dev->nic_poll_work.ctxptr = (void *)octeon_dev;\n\tschedule_delayed_work(&octeon_dev->nic_poll_work.work,\n\t\t\t      LIQUIDIO_STARTER_POLL_INTERVAL_MS);\n\n\tatomic_set(&octeon_dev->status, OCT_DEV_DISPATCH_INIT_DONE);\n\n\tif (octeon_set_io_queues_off(octeon_dev)) {\n\t\tdev_err(&octeon_dev->pci_dev->dev, \"setting io queues off failed\\n\");\n\t\treturn 1;\n\t}\n\n\tif (OCTEON_CN23XX_PF(octeon_dev)) {\n\t\tret = octeon_dev->fn_list.setup_device_regs(octeon_dev);\n\t\tif (ret) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"OCTEON: Failed to configure device registers\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tif (octeon_setup_sc_buffer_pool(octeon_dev)) {\n\t\tdev_err(&octeon_dev->pci_dev->dev, \"sc buffer pool allocation failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&octeon_dev->status, OCT_DEV_SC_BUFF_POOL_INIT_DONE);\n\n\t \n\tif (octeon_setup_instr_queues(octeon_dev)) {\n\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\"instruction queue initialization failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&octeon_dev->status, OCT_DEV_INSTR_QUEUE_INIT_DONE);\n\n\t \n\tif (octeon_setup_response_list(octeon_dev)) {\n\t\tdev_err(&octeon_dev->pci_dev->dev, \"Response list allocation failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&octeon_dev->status, OCT_DEV_RESP_LIST_INIT_DONE);\n\n\tif (octeon_setup_output_queues(octeon_dev)) {\n\t\tdev_err(&octeon_dev->pci_dev->dev, \"Output queue initialization failed\\n\");\n\t\treturn 1;\n\t}\n\n\tatomic_set(&octeon_dev->status, OCT_DEV_DROQ_INIT_DONE);\n\n\tif (OCTEON_CN23XX_PF(octeon_dev)) {\n\t\tif (octeon_dev->fn_list.setup_mbox(octeon_dev)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"OCTEON: Mailbox setup failed\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tatomic_set(&octeon_dev->status, OCT_DEV_MBOX_SETUP_DONE);\n\n\t\tif (octeon_allocate_ioq_vector\n\t\t\t\t(octeon_dev,\n\t\t\t\t octeon_dev->sriov_info.num_pf_rings)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"OCTEON: ioq vector allocation failed\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tatomic_set(&octeon_dev->status, OCT_DEV_MSIX_ALLOC_VECTOR_DONE);\n\n\t} else {\n\t\t \n\t\tret = octeon_dev->fn_list.setup_device_regs(octeon_dev);\n\t\tif (ret) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"Failed to configure device registers\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tdev_dbg(&octeon_dev->pci_dev->dev, \"Initializing droq tasklet\\n\");\n\ttasklet_setup(&oct_priv->droq_tasklet, octeon_droq_bh);\n\n\t \n\tif (octeon_setup_interrupt(octeon_dev,\n\t\t\t\t   octeon_dev->sriov_info.num_pf_rings))\n\t\treturn 1;\n\n\t \n\tocteon_dev->fn_list.enable_interrupt(octeon_dev, OCTEON_ALL_INTR);\n\n\tatomic_set(&octeon_dev->status, OCT_DEV_INTR_SET_DONE);\n\n\t \n\tfor (j = 0; j < octeon_dev->num_oqs; j++)\n\t\twritel(octeon_dev->droq[j]->max_count,\n\t\t       octeon_dev->droq[j]->pkts_credit_reg);\n\n\t \n\tret = octeon_dev->fn_list.enable_io_queues(octeon_dev);\n\tif (ret) {\n\t\tdev_err(&octeon_dev->pci_dev->dev, \"Failed to enable input/output queues\");\n\t\treturn ret;\n\t}\n\n\tatomic_set(&octeon_dev->status, OCT_DEV_IO_QUEUES_DONE);\n\n\tif (fw_state == FW_NEEDS_TO_BE_LOADED) {\n\t\tdev_dbg(&octeon_dev->pci_dev->dev, \"Waiting for DDR initialization...\\n\");\n\t\tif (!ddr_timeout) {\n\t\t\tdev_info(&octeon_dev->pci_dev->dev,\n\t\t\t\t \"WAITING. Set ddr_timeout to non-zero value to proceed with initialization.\\n\");\n\t\t}\n\n\t\tschedule_timeout_uninterruptible(HZ * LIO_RESET_SECS);\n\n\t\t \n\t\twhile (!ddr_timeout) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\tif (schedule_timeout(HZ / 10)) {\n\t\t\t\t \n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t\tret = octeon_wait_for_ddr_init(octeon_dev, &ddr_timeout);\n\t\tif (ret) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"DDR not initialized. Please confirm that board is configured to boot from Flash, ret: %d\\n\",\n\t\t\t\tret);\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (octeon_wait_for_bootloader(octeon_dev, 1000)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Board not responding\\n\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t \n\t\tret = octeon_console_send_cmd(octeon_dev, bootcmd, 50);\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev, \"Initializing consoles\\n\");\n\t\tret = octeon_init_consoles(octeon_dev);\n\t\tif (ret) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Could not access board consoles\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\t \n\t\tdbg_enb = octeon_console_debug_enabled(0) ? \"\" : NULL;\n\t\tret = octeon_add_console(octeon_dev, 0, dbg_enb);\n\t\tif (ret) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Could not access board console\\n\");\n\t\t\treturn 1;\n\t\t} else if (octeon_console_debug_enabled(0)) {\n\t\t\t \n\t\t\tocteon_dev->console[0].print = octeon_dbg_console_print;\n\t\t}\n\n\t\tatomic_set(&octeon_dev->status, OCT_DEV_CONSOLE_INIT_DONE);\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev, \"Loading firmware\\n\");\n\t\tret = load_firmware(octeon_dev);\n\t\tif (ret) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Could not load firmware to board\\n\");\n\t\t\treturn 1;\n\t\t}\n\n\t\tatomic_set(octeon_dev->adapter_fw_state, FW_HAS_BEEN_LOADED);\n\t}\n\n\thandshake[octeon_dev->octeon_id].init_ok = 1;\n\tcomplete(&handshake[octeon_dev->octeon_id].init);\n\n\tatomic_set(&octeon_dev->status, OCT_DEV_HOST_OK);\n\toct_priv->dev = octeon_dev;\n\n\treturn 0;\n}\n\n \nstatic int octeon_dbg_console_print(struct octeon_device *oct, u32 console_num,\n\t\t\t\t    char *prefix, char *suffix)\n{\n\tif (prefix && suffix)\n\t\tdev_info(&oct->pci_dev->dev, \"%u: %s%s\\n\", console_num, prefix,\n\t\t\t suffix);\n\telse if (prefix)\n\t\tdev_info(&oct->pci_dev->dev, \"%u: %s\\n\", console_num, prefix);\n\telse if (suffix)\n\t\tdev_info(&oct->pci_dev->dev, \"%u: %s\\n\", console_num, suffix);\n\n\treturn 0;\n}\n\n \nstatic void __exit liquidio_exit(void)\n{\n\tliquidio_deinit_pci();\n\n\tpr_info(\"LiquidIO network module is now unloaded\\n\");\n}\n\nmodule_init(liquidio_init);\nmodule_exit(liquidio_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}