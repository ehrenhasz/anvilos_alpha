{
  "module_name": "cn66xx_device.c",
  "hash_id": "cb0b58a41ea9d1c79161692dd8420a6edbf9b625cfc23004814e8175c6beffb3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/cavium/liquidio/cn66xx_device.c",
  "human_readable_source": " \n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include \"liquidio_common.h\"\n#include \"octeon_droq.h\"\n#include \"octeon_iq.h\"\n#include \"response_manager.h\"\n#include \"octeon_device.h\"\n#include \"octeon_main.h\"\n#include \"cn66xx_regs.h\"\n#include \"cn66xx_device.h\"\n\nint lio_cn6xxx_soft_reset(struct octeon_device *oct)\n{\n\tocteon_write_csr64(oct, CN6XXX_WIN_WR_MASK_REG, 0xFF);\n\n\tdev_dbg(&oct->pci_dev->dev, \"BIST enabled for soft reset\\n\");\n\n\tlio_pci_writeq(oct, 1, CN6XXX_CIU_SOFT_BIST);\n\tocteon_write_csr64(oct, CN6XXX_SLI_SCRATCH1, 0x1234ULL);\n\n\tlio_pci_readq(oct, CN6XXX_CIU_SOFT_RST);\n\tlio_pci_writeq(oct, 1, CN6XXX_CIU_SOFT_RST);\n\n\t \n\tmdelay(100);\n\n\tif (octeon_read_csr64(oct, CN6XXX_SLI_SCRATCH1)) {\n\t\tdev_err(&oct->pci_dev->dev, \"Soft reset failed\\n\");\n\t\treturn 1;\n\t}\n\n\tdev_dbg(&oct->pci_dev->dev, \"Reset completed\\n\");\n\tocteon_write_csr64(oct, CN6XXX_WIN_WR_MASK_REG, 0xFF);\n\n\treturn 0;\n}\n\nvoid lio_cn6xxx_enable_error_reporting(struct octeon_device *oct)\n{\n\tu32 val;\n\n\tpci_read_config_dword(oct->pci_dev, CN6XXX_PCIE_DEVCTL, &val);\n\tif (val & 0x000c0000) {\n\t\tdev_err(&oct->pci_dev->dev, \"PCI-E Link error detected: 0x%08x\\n\",\n\t\t\tval & 0x000c0000);\n\t}\n\n\tval |= 0xf;           \n\n\tdev_dbg(&oct->pci_dev->dev, \"Enabling PCI-E error reporting..\\n\");\n\tpci_write_config_dword(oct->pci_dev, CN6XXX_PCIE_DEVCTL, val);\n}\n\nvoid lio_cn6xxx_setup_pcie_mps(struct octeon_device *oct,\n\t\t\t       enum octeon_pcie_mps mps)\n{\n\tu32 val;\n\tu64 r64;\n\n\t \n\tpci_read_config_dword(oct->pci_dev, CN6XXX_PCIE_DEVCTL, &val);\n\n\tif (mps == PCIE_MPS_DEFAULT) {\n\t\tmps = ((val & (0x7 << 5)) >> 5);\n\t} else {\n\t\tval &= ~(0x7 << 5);   \n\t\tval |= (mps << 5);    \n\t\tpci_write_config_dword(oct->pci_dev, CN6XXX_PCIE_DEVCTL, val);\n\t}\n\n\t \n\tr64 = lio_pci_readq(oct, CN6XXX_DPI_SLI_PRTX_CFG(oct->pcie_port));\n\tr64 |= (mps << 4);\n\tlio_pci_writeq(oct, r64, CN6XXX_DPI_SLI_PRTX_CFG(oct->pcie_port));\n}\n\nvoid lio_cn6xxx_setup_pcie_mrrs(struct octeon_device *oct,\n\t\t\t\tenum octeon_pcie_mrrs mrrs)\n{\n\tu32 val;\n\tu64 r64;\n\n\t \n\tpci_read_config_dword(oct->pci_dev, CN6XXX_PCIE_DEVCTL, &val);\n\n\tif (mrrs == PCIE_MRRS_DEFAULT) {\n\t\tmrrs = ((val & (0x7 << 12)) >> 12);\n\t} else {\n\t\tval &= ~(0x7 << 12);  \n\t\tval |= (mrrs << 12);  \n\t\tpci_write_config_dword(oct->pci_dev, CN6XXX_PCIE_DEVCTL, val);\n\t}\n\n\t \n\tr64 = octeon_read_csr64(oct, CN6XXX_SLI_S2M_PORTX_CTL(oct->pcie_port));\n\tr64 |= mrrs;\n\tocteon_write_csr64(oct, CN6XXX_SLI_S2M_PORTX_CTL(oct->pcie_port), r64);\n\n\t \n\tr64 = lio_pci_readq(oct, CN6XXX_DPI_SLI_PRTX_CFG(oct->pcie_port));\n\tr64 |= mrrs;\n\tlio_pci_writeq(oct, r64, CN6XXX_DPI_SLI_PRTX_CFG(oct->pcie_port));\n}\n\nu32 lio_cn6xxx_coprocessor_clock(struct octeon_device *oct)\n{\n\t \n\treturn ((lio_pci_readq(oct, CN6XXX_MIO_RST_BOOT) >> 24) & 0x3f) * 50;\n}\n\nu32 lio_cn6xxx_get_oq_ticks(struct octeon_device *oct,\n\t\t\t    u32 time_intr_in_us)\n{\n\t \n\tu32 oqticks_per_us = lio_cn6xxx_coprocessor_clock(oct);\n\n\t \n\n\t \n\toqticks_per_us *= 1000;\n\n\t \n\toqticks_per_us /= 1024;\n\n\t \n\toqticks_per_us *= time_intr_in_us;\n\toqticks_per_us /= 1000;\n\n\treturn oqticks_per_us;\n}\n\nvoid lio_cn6xxx_setup_global_input_regs(struct octeon_device *oct)\n{\n\t \n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_INPUT_CONTROL,\n\t\t\t CN6XXX_INPUT_CTL_MASK);\n\n\t \n\tocteon_write_csr64(oct, CN6XXX_SLI_PKT_INSTR_RD_SIZE,\n\t\t\t   0xFFFFFFFFFFFFFFFFULL);\n\n\t \n\tocteon_write_csr64(oct, CN6XXX_SLI_IN_PCIE_PORT,\n\t\t\t   (oct->pcie_port * 0x5555555555555555ULL));\n}\n\nstatic void lio_cn66xx_setup_pkt_ctl_regs(struct octeon_device *oct)\n{\n\tu64 pktctl;\n\n\tstruct octeon_cn6xxx *cn6xxx = (struct octeon_cn6xxx *)oct->chip;\n\n\tpktctl = octeon_read_csr64(oct, CN6XXX_SLI_PKT_CTL);\n\n\t \n\tif (CFG_GET_OQ_MAX_Q(cn6xxx->conf) <= 4)\n\t\t \n\t\tpktctl &= ~(1 << 4);\n\telse\n\t\tpktctl |= (1 << 4);\n\n\tif (CFG_GET_IS_SLI_BP_ON(cn6xxx->conf))\n\t\tpktctl |= 0xF;\n\telse\n\t\t \n\t\tpktctl &= ~0xF;\n\tocteon_write_csr64(oct, CN6XXX_SLI_PKT_CTL, pktctl);\n}\n\nvoid lio_cn6xxx_setup_global_output_regs(struct octeon_device *oct)\n{\n\tu32 time_threshold;\n\tstruct octeon_cn6xxx *cn6xxx = (struct octeon_cn6xxx *)oct->chip;\n\n\t \n\tocteon_write_csr64(oct, CN6XXX_SLI_PKT_PCIE_PORT64,\n\t\t\t   (oct->pcie_port * 0x5555555555555555ULL));\n\n\tif (CFG_GET_IS_SLI_BP_ON(cn6xxx->conf)) {\n\t\tocteon_write_csr64(oct, CN6XXX_SLI_OQ_WMARK, 32);\n\t} else {\n\t\t \n\t\tocteon_write_csr64(oct, CN6XXX_SLI_OQ_WMARK, 0);\n\t}\n\n\t \n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_OUT_BMODE, 0);\n\n\t \n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_DPADDR, 0xFFFFFFFF);\n\n\t \n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_SLIST_ROR, 0);\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_SLIST_NS, 0);\n\n\t \n#ifdef __BIG_ENDIAN_BITFIELD\n\tocteon_write_csr64(oct, CN6XXX_SLI_PKT_SLIST_ES64,\n\t\t\t   0x5555555555555555ULL);\n#else\n\tocteon_write_csr64(oct, CN6XXX_SLI_PKT_SLIST_ES64, 0ULL);\n#endif\n\n\t \n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_DATA_OUT_ROR, 0);\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_DATA_OUT_NS, 0);\n\tocteon_write_csr64(oct, CN6XXX_SLI_PKT_DATA_OUT_ES64,\n\t\t\t   0x5555555555555555ULL);\n\n\t \n\tocteon_write_csr(oct, CN6XXX_SLI_OQ_INT_LEVEL_PKTS,\n\t\t\t (u32)CFG_GET_OQ_INTR_PKT(cn6xxx->conf));\n\ttime_threshold =\n\t\tlio_cn6xxx_get_oq_ticks(oct, (u32)\n\t\t\t\t\tCFG_GET_OQ_INTR_TIME(cn6xxx->conf));\n\n\tocteon_write_csr(oct, CN6XXX_SLI_OQ_INT_LEVEL_TIME, time_threshold);\n}\n\nstatic int lio_cn6xxx_setup_device_regs(struct octeon_device *oct)\n{\n\tlio_cn6xxx_setup_pcie_mps(oct, PCIE_MPS_DEFAULT);\n\tlio_cn6xxx_setup_pcie_mrrs(oct, PCIE_MRRS_512B);\n\tlio_cn6xxx_enable_error_reporting(oct);\n\n\tlio_cn6xxx_setup_global_input_regs(oct);\n\tlio_cn66xx_setup_pkt_ctl_regs(oct);\n\tlio_cn6xxx_setup_global_output_regs(oct);\n\n\t \n\tocteon_write_csr64(oct, CN6XXX_SLI_WINDOW_CTL, 0x200000ULL);\n\treturn 0;\n}\n\nvoid lio_cn6xxx_setup_iq_regs(struct octeon_device *oct, u32 iq_no)\n{\n\tstruct octeon_instr_queue *iq = oct->instr_queue[iq_no];\n\n\tocteon_write_csr64(oct, CN6XXX_SLI_IQ_PKT_INSTR_HDR64(iq_no), 0);\n\n\t \n\tocteon_write_csr64(oct, CN6XXX_SLI_IQ_BASE_ADDR64(iq_no),\n\t\t\t   iq->base_addr_dma);\n\tocteon_write_csr(oct, CN6XXX_SLI_IQ_SIZE(iq_no), iq->max_count);\n\n\t \n\tiq->doorbell_reg = oct->mmio[0].hw_addr + CN6XXX_SLI_IQ_DOORBELL(iq_no);\n\tiq->inst_cnt_reg = oct->mmio[0].hw_addr\n\t\t\t   + CN6XXX_SLI_IQ_INSTR_COUNT(iq_no);\n\tdev_dbg(&oct->pci_dev->dev, \"InstQ[%d]:dbell reg @ 0x%p instcnt_reg @ 0x%p\\n\",\n\t\tiq_no, iq->doorbell_reg, iq->inst_cnt_reg);\n\n\t \n\tiq->reset_instr_cnt = readl(iq->inst_cnt_reg);\n}\n\nstatic void lio_cn66xx_setup_iq_regs(struct octeon_device *oct, u32 iq_no)\n{\n\tlio_cn6xxx_setup_iq_regs(oct, iq_no);\n\n\t \n\tocteon_write_csr64(oct, CN66XX_SLI_IQ_BP64(iq_no),\n\t\t\t   (0xFFFFFFFFULL << 32));\n}\n\nvoid lio_cn6xxx_setup_oq_regs(struct octeon_device *oct, u32 oq_no)\n{\n\tu32 intr;\n\tstruct octeon_droq *droq = oct->droq[oq_no];\n\n\tocteon_write_csr64(oct, CN6XXX_SLI_OQ_BASE_ADDR64(oq_no),\n\t\t\t   droq->desc_ring_dma);\n\tocteon_write_csr(oct, CN6XXX_SLI_OQ_SIZE(oq_no), droq->max_count);\n\n\tocteon_write_csr(oct, CN6XXX_SLI_OQ_BUFF_INFO_SIZE(oq_no),\n\t\t\t droq->buffer_size);\n\n\t \n\tdroq->pkts_sent_reg =\n\t\toct->mmio[0].hw_addr + CN6XXX_SLI_OQ_PKTS_SENT(oq_no);\n\tdroq->pkts_credit_reg =\n\t\toct->mmio[0].hw_addr + CN6XXX_SLI_OQ_PKTS_CREDIT(oq_no);\n\n\t \n\tintr = octeon_read_csr(oct, CN6XXX_SLI_PKT_TIME_INT_ENB);\n\tintr |= (1 << oq_no);\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_TIME_INT_ENB, intr);\n\n\t \n\tintr = octeon_read_csr(oct, CN6XXX_SLI_PKT_CNT_INT_ENB);\n\tintr |= (1 << oq_no);\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_CNT_INT_ENB, intr);\n}\n\nint lio_cn6xxx_enable_io_queues(struct octeon_device *oct)\n{\n\tu32 mask;\n\n\tmask = octeon_read_csr(oct, CN6XXX_SLI_PKT_INSTR_SIZE);\n\tmask |= oct->io_qmask.iq64B;\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_INSTR_SIZE, mask);\n\n\tmask = octeon_read_csr(oct, CN6XXX_SLI_PKT_INSTR_ENB);\n\tmask |= oct->io_qmask.iq;\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_INSTR_ENB, mask);\n\n\tmask = octeon_read_csr(oct, CN6XXX_SLI_PKT_OUT_ENB);\n\tmask |= oct->io_qmask.oq;\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_OUT_ENB, mask);\n\n\treturn 0;\n}\n\nvoid lio_cn6xxx_disable_io_queues(struct octeon_device *oct)\n{\n\tint i;\n\tu32 mask, loop = HZ;\n\tu32 d32;\n\n\t \n\tmask = octeon_read_csr(oct, CN6XXX_SLI_PKT_INSTR_ENB);\n\tmask ^= oct->io_qmask.iq;\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_INSTR_ENB, mask);\n\n\t \n\tmask = (u32)oct->io_qmask.iq;\n\td32 = octeon_read_csr(oct, CN6XXX_SLI_PORT_IN_RST_IQ);\n\twhile (((d32 & mask) != mask) && loop--) {\n\t\td32 = octeon_read_csr(oct, CN6XXX_SLI_PORT_IN_RST_IQ);\n\t\tschedule_timeout_uninterruptible(1);\n\t}\n\n\t \n\tfor (i = 0; i < MAX_OCTEON_INSTR_QUEUES(oct); i++) {\n\t\tif (!(oct->io_qmask.iq & BIT_ULL(i)))\n\t\t\tcontinue;\n\t\tocteon_write_csr(oct, CN6XXX_SLI_IQ_DOORBELL(i), 0xFFFFFFFF);\n\t\td32 = octeon_read_csr(oct, CN6XXX_SLI_IQ_DOORBELL(i));\n\t}\n\n\t \n\tmask = octeon_read_csr(oct, CN6XXX_SLI_PKT_OUT_ENB);\n\tmask ^= oct->io_qmask.oq;\n\tocteon_write_csr(oct, CN6XXX_SLI_PKT_OUT_ENB, mask);\n\n\t \n\tloop = HZ;\n\tmask = (u32)oct->io_qmask.oq;\n\td32 = octeon_read_csr(oct, CN6XXX_SLI_PORT_IN_RST_OQ);\n\twhile (((d32 & mask) != mask) && loop--) {\n\t\td32 = octeon_read_csr(oct, CN6XXX_SLI_PORT_IN_RST_OQ);\n\t\tschedule_timeout_uninterruptible(1);\n\t}\n\t;\n\n\t \n\tfor (i = 0; i < MAX_OCTEON_OUTPUT_QUEUES(oct); i++) {\n\t\tif (!(oct->io_qmask.oq & BIT_ULL(i)))\n\t\t\tcontinue;\n\t\tocteon_write_csr(oct, CN6XXX_SLI_OQ_PKTS_CREDIT(i), 0xFFFFFFFF);\n\t\td32 = octeon_read_csr(oct, CN6XXX_SLI_OQ_PKTS_CREDIT(i));\n\n\t\td32 = octeon_read_csr(oct, CN6XXX_SLI_OQ_PKTS_SENT(i));\n\t\tocteon_write_csr(oct, CN6XXX_SLI_OQ_PKTS_SENT(i), d32);\n\t}\n\n\td32 = octeon_read_csr(oct, CN6XXX_SLI_PKT_CNT_INT);\n\tif (d32)\n\t\tocteon_write_csr(oct, CN6XXX_SLI_PKT_CNT_INT, d32);\n\n\td32 = octeon_read_csr(oct, CN6XXX_SLI_PKT_TIME_INT);\n\tif (d32)\n\t\tocteon_write_csr(oct, CN6XXX_SLI_PKT_TIME_INT, d32);\n}\n\nvoid\nlio_cn6xxx_bar1_idx_setup(struct octeon_device *oct,\n\t\t\t  u64 core_addr,\n\t\t\t  u32 idx,\n\t\t\t  int valid)\n{\n\tu64 bar1;\n\n\tif (valid == 0) {\n\t\tbar1 = lio_pci_readq(oct, CN6XXX_BAR1_REG(idx, oct->pcie_port));\n\t\tlio_pci_writeq(oct, (bar1 & 0xFFFFFFFEULL),\n\t\t\t       CN6XXX_BAR1_REG(idx, oct->pcie_port));\n\t\tbar1 = lio_pci_readq(oct, CN6XXX_BAR1_REG(idx, oct->pcie_port));\n\t\treturn;\n\t}\n\n\t \n\tlio_pci_writeq(oct, (((core_addr >> 22) << 4) | PCI_BAR1_MASK),\n\t\t       CN6XXX_BAR1_REG(idx, oct->pcie_port));\n\n\tbar1 = lio_pci_readq(oct, CN6XXX_BAR1_REG(idx, oct->pcie_port));\n}\n\nvoid lio_cn6xxx_bar1_idx_write(struct octeon_device *oct,\n\t\t\t       u32 idx,\n\t\t\t       u32 mask)\n{\n\tlio_pci_writeq(oct, mask, CN6XXX_BAR1_REG(idx, oct->pcie_port));\n}\n\nu32 lio_cn6xxx_bar1_idx_read(struct octeon_device *oct, u32 idx)\n{\n\treturn (u32)lio_pci_readq(oct, CN6XXX_BAR1_REG(idx, oct->pcie_port));\n}\n\nu32\nlio_cn6xxx_update_read_index(struct octeon_instr_queue *iq)\n{\n\tu32 new_idx = readl(iq->inst_cnt_reg);\n\n\t \n\tif (iq->reset_instr_cnt < new_idx)\n\t\tnew_idx -= iq->reset_instr_cnt;\n\telse\n\t\tnew_idx += (0xffffffff - iq->reset_instr_cnt) + 1;\n\n\t \n\tnew_idx %= iq->max_count;\n\n\treturn new_idx;\n}\n\nvoid lio_cn6xxx_enable_interrupt(struct octeon_device *oct,\n\t\t\t\t u8 unused __attribute__((unused)))\n{\n\tstruct octeon_cn6xxx *cn6xxx = (struct octeon_cn6xxx *)oct->chip;\n\tu64 mask = cn6xxx->intr_mask64 | CN6XXX_INTR_DMA0_FORCE;\n\n\t \n\twriteq(mask, cn6xxx->intr_enb_reg64);\n}\n\nvoid lio_cn6xxx_disable_interrupt(struct octeon_device *oct,\n\t\t\t\t  u8 unused __attribute__((unused)))\n{\n\tstruct octeon_cn6xxx *cn6xxx = (struct octeon_cn6xxx *)oct->chip;\n\n\t \n\twriteq(0, cn6xxx->intr_enb_reg64);\n}\n\nstatic void lio_cn6xxx_get_pcie_qlmport(struct octeon_device *oct)\n{\n\t \n\toct->pcie_port = octeon_read_csr(oct, CN6XXX_SLI_MAC_NUMBER) & 0xff;\n\n\tdev_dbg(&oct->pci_dev->dev, \"Using PCIE Port %d\\n\", oct->pcie_port);\n}\n\nstatic void\nlio_cn6xxx_process_pcie_error_intr(struct octeon_device *oct, u64 intr64)\n{\n\tdev_err(&oct->pci_dev->dev, \"Error Intr: 0x%016llx\\n\",\n\t\tCVM_CAST64(intr64));\n}\n\nstatic int lio_cn6xxx_process_droq_intr_regs(struct octeon_device *oct)\n{\n\tstruct octeon_droq *droq;\n\tint oq_no;\n\tu32 pkt_count, droq_time_mask, droq_mask, droq_int_enb;\n\tu32 droq_cnt_enb, droq_cnt_mask;\n\n\tdroq_cnt_enb = octeon_read_csr(oct, CN6XXX_SLI_PKT_CNT_INT_ENB);\n\tdroq_cnt_mask = octeon_read_csr(oct, CN6XXX_SLI_PKT_CNT_INT);\n\tdroq_mask = droq_cnt_mask & droq_cnt_enb;\n\n\tdroq_time_mask = octeon_read_csr(oct, CN6XXX_SLI_PKT_TIME_INT);\n\tdroq_int_enb = octeon_read_csr(oct, CN6XXX_SLI_PKT_TIME_INT_ENB);\n\tdroq_mask |= (droq_time_mask & droq_int_enb);\n\n\tdroq_mask &= oct->io_qmask.oq;\n\n\toct->droq_intr = 0;\n\n\tfor (oq_no = 0; oq_no < MAX_OCTEON_OUTPUT_QUEUES(oct); oq_no++) {\n\t\tif (!(droq_mask & BIT_ULL(oq_no)))\n\t\t\tcontinue;\n\n\t\tdroq = oct->droq[oq_no];\n\t\tpkt_count = octeon_droq_check_hw_for_pkts(droq);\n\t\tif (pkt_count) {\n\t\t\toct->droq_intr |= BIT_ULL(oq_no);\n\t\t\tif (droq->ops.poll_mode) {\n\t\t\t\tu32 value;\n\t\t\t\tu32 reg;\n\n\t\t\t\tstruct octeon_cn6xxx *cn6xxx =\n\t\t\t\t\t(struct octeon_cn6xxx *)oct->chip;\n\n\t\t\t\t \n\t\t\t\tspin_lock\n\t\t\t\t\t(&cn6xxx->lock_for_droq_int_enb_reg);\n\t\t\t\treg = CN6XXX_SLI_PKT_TIME_INT_ENB;\n\t\t\t\tvalue = octeon_read_csr(oct, reg);\n\t\t\t\tvalue &= ~(1 << oq_no);\n\t\t\t\tocteon_write_csr(oct, reg, value);\n\t\t\t\treg = CN6XXX_SLI_PKT_CNT_INT_ENB;\n\t\t\t\tvalue = octeon_read_csr(oct, reg);\n\t\t\t\tvalue &= ~(1 << oq_no);\n\t\t\t\tocteon_write_csr(oct, reg, value);\n\n\t\t\t\tspin_unlock(&cn6xxx->lock_for_droq_int_enb_reg);\n\t\t\t}\n\t\t}\n\t}\n\n\tdroq_time_mask &= oct->io_qmask.oq;\n\tdroq_cnt_mask &= oct->io_qmask.oq;\n\n\t \n\tif (droq_time_mask)\n\t\tocteon_write_csr(oct, CN6XXX_SLI_PKT_TIME_INT, droq_time_mask);\n\n\tif (droq_cnt_mask)       \n\t\tocteon_write_csr(oct, CN6XXX_SLI_PKT_CNT_INT, droq_cnt_mask);\n\n\treturn 0;\n}\n\nirqreturn_t lio_cn6xxx_process_interrupt_regs(void *dev)\n{\n\tstruct octeon_device *oct = (struct octeon_device *)dev;\n\tstruct octeon_cn6xxx *cn6xxx = (struct octeon_cn6xxx *)oct->chip;\n\tu64 intr64;\n\n\tintr64 = readq(cn6xxx->intr_sum_reg64);\n\n\t \n\tif (!intr64 || (intr64 == 0xFFFFFFFFFFFFFFFFULL))\n\t\treturn IRQ_NONE;\n\n\toct->int_status = 0;\n\n\tif (intr64 & CN6XXX_INTR_ERR)\n\t\tlio_cn6xxx_process_pcie_error_intr(oct, intr64);\n\n\tif (intr64 & CN6XXX_INTR_PKT_DATA) {\n\t\tlio_cn6xxx_process_droq_intr_regs(oct);\n\t\toct->int_status |= OCT_DEV_INTR_PKT_DATA;\n\t}\n\n\tif (intr64 & CN6XXX_INTR_DMA0_FORCE)\n\t\toct->int_status |= OCT_DEV_INTR_DMA0_FORCE;\n\n\tif (intr64 & CN6XXX_INTR_DMA1_FORCE)\n\t\toct->int_status |= OCT_DEV_INTR_DMA1_FORCE;\n\n\t \n\twriteq(intr64, cn6xxx->intr_sum_reg64);\n\n\treturn IRQ_HANDLED;\n}\n\nvoid lio_cn6xxx_setup_reg_address(struct octeon_device *oct,\n\t\t\t\t  void *chip,\n\t\t\t\t  struct octeon_reg_list *reg_list)\n{\n\tu8 __iomem *bar0_pciaddr = oct->mmio[0].hw_addr;\n\tstruct octeon_cn6xxx *cn6xxx = (struct octeon_cn6xxx *)chip;\n\n\treg_list->pci_win_wr_addr_hi =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_WR_ADDR_HI);\n\treg_list->pci_win_wr_addr_lo =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_WR_ADDR_LO);\n\treg_list->pci_win_wr_addr =\n\t\t(u64 __iomem *)(bar0_pciaddr + CN6XXX_WIN_WR_ADDR64);\n\n\treg_list->pci_win_rd_addr_hi =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_RD_ADDR_HI);\n\treg_list->pci_win_rd_addr_lo =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_RD_ADDR_LO);\n\treg_list->pci_win_rd_addr =\n\t\t(u64 __iomem *)(bar0_pciaddr + CN6XXX_WIN_RD_ADDR64);\n\n\treg_list->pci_win_wr_data_hi =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_WR_DATA_HI);\n\treg_list->pci_win_wr_data_lo =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_WR_DATA_LO);\n\treg_list->pci_win_wr_data =\n\t\t(u64 __iomem *)(bar0_pciaddr + CN6XXX_WIN_WR_DATA64);\n\n\treg_list->pci_win_rd_data_hi =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_RD_DATA_HI);\n\treg_list->pci_win_rd_data_lo =\n\t\t(u32 __iomem *)(bar0_pciaddr + CN6XXX_WIN_RD_DATA_LO);\n\treg_list->pci_win_rd_data =\n\t\t(u64 __iomem *)(bar0_pciaddr + CN6XXX_WIN_RD_DATA64);\n\n\tlio_cn6xxx_get_pcie_qlmport(oct);\n\n\tcn6xxx->intr_sum_reg64 = bar0_pciaddr + CN6XXX_SLI_INT_SUM64;\n\tcn6xxx->intr_mask64 = CN6XXX_INTR_MASK;\n\tcn6xxx->intr_enb_reg64 =\n\t\tbar0_pciaddr + CN6XXX_SLI_INT_ENB64(oct->pcie_port);\n}\n\nint lio_setup_cn66xx_octeon_device(struct octeon_device *oct)\n{\n\tstruct octeon_cn6xxx *cn6xxx = (struct octeon_cn6xxx *)oct->chip;\n\n\tif (octeon_map_pci_barx(oct, 0, 0))\n\t\treturn 1;\n\n\tif (octeon_map_pci_barx(oct, 1, MAX_BAR1_IOREMAP_SIZE)) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s CN66XX BAR1 map failed\\n\",\n\t\t\t__func__);\n\t\tocteon_unmap_pci_barx(oct, 0);\n\t\treturn 1;\n\t}\n\n\tspin_lock_init(&cn6xxx->lock_for_droq_int_enb_reg);\n\n\toct->fn_list.setup_iq_regs = lio_cn66xx_setup_iq_regs;\n\toct->fn_list.setup_oq_regs = lio_cn6xxx_setup_oq_regs;\n\n\toct->fn_list.soft_reset = lio_cn6xxx_soft_reset;\n\toct->fn_list.setup_device_regs = lio_cn6xxx_setup_device_regs;\n\toct->fn_list.update_iq_read_idx = lio_cn6xxx_update_read_index;\n\n\toct->fn_list.bar1_idx_setup = lio_cn6xxx_bar1_idx_setup;\n\toct->fn_list.bar1_idx_write = lio_cn6xxx_bar1_idx_write;\n\toct->fn_list.bar1_idx_read = lio_cn6xxx_bar1_idx_read;\n\n\toct->fn_list.process_interrupt_regs = lio_cn6xxx_process_interrupt_regs;\n\toct->fn_list.enable_interrupt = lio_cn6xxx_enable_interrupt;\n\toct->fn_list.disable_interrupt = lio_cn6xxx_disable_interrupt;\n\n\toct->fn_list.enable_io_queues = lio_cn6xxx_enable_io_queues;\n\toct->fn_list.disable_io_queues = lio_cn6xxx_disable_io_queues;\n\n\tlio_cn6xxx_setup_reg_address(oct, oct->chip, &oct->reg_list);\n\n\tcn6xxx->conf = (struct octeon_config *)\n\t\t       oct_get_config_info(oct, LIO_210SV);\n\tif (!cn6xxx->conf) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s No Config found for CN66XX\\n\",\n\t\t\t__func__);\n\t\tocteon_unmap_pci_barx(oct, 0);\n\t\tocteon_unmap_pci_barx(oct, 1);\n\t\treturn 1;\n\t}\n\n\toct->coproc_clock_rate = 1000000ULL * lio_cn6xxx_coprocessor_clock(oct);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(lio_setup_cn66xx_octeon_device);\n\nint lio_validate_cn6xxx_config_info(struct octeon_device *oct,\n\t\t\t\t    struct octeon_config *conf6xxx)\n{\n\tif (CFG_GET_IQ_MAX_Q(conf6xxx) > CN6XXX_MAX_INPUT_QUEUES) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s: Num IQ (%d) exceeds Max (%d)\\n\",\n\t\t\t__func__, CFG_GET_IQ_MAX_Q(conf6xxx),\n\t\t\tCN6XXX_MAX_INPUT_QUEUES);\n\t\treturn 1;\n\t}\n\n\tif (CFG_GET_OQ_MAX_Q(conf6xxx) > CN6XXX_MAX_OUTPUT_QUEUES) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s: Num OQ (%d) exceeds Max (%d)\\n\",\n\t\t\t__func__, CFG_GET_OQ_MAX_Q(conf6xxx),\n\t\t\tCN6XXX_MAX_OUTPUT_QUEUES);\n\t\treturn 1;\n\t}\n\n\tif (CFG_GET_IQ_INSTR_TYPE(conf6xxx) != OCTEON_32BYTE_INSTR &&\n\t    CFG_GET_IQ_INSTR_TYPE(conf6xxx) != OCTEON_64BYTE_INSTR) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s: Invalid instr type for IQ\\n\",\n\t\t\t__func__);\n\t\treturn 1;\n\t}\n\tif (!CFG_GET_OQ_REFILL_THRESHOLD(conf6xxx)) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s: Invalid parameter for OQ\\n\",\n\t\t\t__func__);\n\t\treturn 1;\n\t}\n\n\tif (!(CFG_GET_OQ_INTR_TIME(conf6xxx))) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s: No Time Interrupt for OQ\\n\",\n\t\t\t__func__);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}