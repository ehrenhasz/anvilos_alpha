{
  "module_name": "lio_vf_main.c",
  "hash_id": "692ce18876f6f29625f36ddf09c751c788b84824aad492cb8850908632a9805a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/cavium/liquidio/lio_vf_main.c",
  "human_readable_source": " \n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <net/vxlan.h>\n#include \"liquidio_common.h\"\n#include \"octeon_droq.h\"\n#include \"octeon_iq.h\"\n#include \"response_manager.h\"\n#include \"octeon_device.h\"\n#include \"octeon_nic.h\"\n#include \"octeon_main.h\"\n#include \"octeon_network.h\"\n#include \"cn23xx_vf_device.h\"\n\nMODULE_AUTHOR(\"Cavium Networks, <support@cavium.com>\");\nMODULE_DESCRIPTION(\"Cavium LiquidIO Intelligent Server Adapter Virtual Function Driver\");\nMODULE_LICENSE(\"GPL\");\n\nstatic int debug = -1;\nmodule_param(debug, int, 0644);\nMODULE_PARM_DESC(debug, \"NETIF_MSG debug bits\");\n\n#define DEFAULT_MSG_ENABLE (NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_LINK)\n\nstruct oct_timestamp_resp {\n\tu64 rh;\n\tu64 timestamp;\n\tu64 status;\n};\n\nunion tx_info {\n\tu64 u64;\n\tstruct {\n#ifdef __BIG_ENDIAN_BITFIELD\n\t\tu16 gso_size;\n\t\tu16 gso_segs;\n\t\tu32 reserved;\n#else\n\t\tu32 reserved;\n\t\tu16 gso_segs;\n\t\tu16 gso_size;\n#endif\n\t} s;\n};\n\n#define OCTNIC_GSO_MAX_HEADER_SIZE 128\n#define OCTNIC_GSO_MAX_SIZE \\\n\t\t(CN23XX_DEFAULT_INPUT_JABBER - OCTNIC_GSO_MAX_HEADER_SIZE)\n\nstatic int\nliquidio_vf_probe(struct pci_dev *pdev, const struct pci_device_id *ent);\nstatic void liquidio_vf_remove(struct pci_dev *pdev);\nstatic int octeon_device_init(struct octeon_device *oct);\nstatic int liquidio_stop(struct net_device *netdev);\n\nstatic int lio_wait_for_oq_pkts(struct octeon_device *oct)\n{\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tint retry = MAX_IO_PENDING_PKT_COUNT;\n\tint pkt_cnt = 0, pending_pkts;\n\tint i;\n\n\tdo {\n\t\tpending_pkts = 0;\n\n\t\tfor (i = 0; i < MAX_OCTEON_OUTPUT_QUEUES(oct); i++) {\n\t\t\tif (!(oct->io_qmask.oq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tpkt_cnt += octeon_droq_check_hw_for_pkts(oct->droq[i]);\n\t\t}\n\t\tif (pkt_cnt > 0) {\n\t\t\tpending_pkts += pkt_cnt;\n\t\t\ttasklet_schedule(&oct_priv->droq_tasklet);\n\t\t}\n\t\tpkt_cnt = 0;\n\t\tschedule_timeout_uninterruptible(1);\n\n\t} while (retry-- && pending_pkts);\n\n\treturn pkt_cnt;\n}\n\n \nstatic void pcierror_quiesce_device(struct octeon_device *oct)\n{\n\tint i;\n\n\t \n\n\t \n\tschedule_timeout_uninterruptible(100);\n\n\tif (wait_for_pending_requests(oct))\n\t\tdev_err(&oct->pci_dev->dev, \"There were pending requests\\n\");\n\n\t \n\tfor (i = 0; i < MAX_OCTEON_INSTR_QUEUES(oct); i++) {\n\t\tstruct octeon_instr_queue *iq;\n\n\t\tif (!(oct->io_qmask.iq & BIT_ULL(i)))\n\t\t\tcontinue;\n\t\tiq = oct->instr_queue[i];\n\n\t\tif (atomic_read(&iq->instr_pending)) {\n\t\t\tspin_lock_bh(&iq->lock);\n\t\t\tiq->fill_cnt = 0;\n\t\t\tiq->octeon_read_index = iq->host_write_index;\n\t\t\tiq->stats.instr_processed +=\n\t\t\t    atomic_read(&iq->instr_pending);\n\t\t\tlio_process_iq_request_list(oct, iq, 0);\n\t\t\tspin_unlock_bh(&iq->lock);\n\t\t}\n\t}\n\n\t \n\tlio_process_ordered_list(oct, 1);\n\n\t \n}\n\n \nstatic void cleanup_aer_uncorrect_error_status(struct pci_dev *dev)\n{\n\tu32 status, mask;\n\tint pos = 0x100;\n\n\tpr_info(\"%s :\\n\", __func__);\n\n\tpci_read_config_dword(dev, pos + PCI_ERR_UNCOR_STATUS, &status);\n\tpci_read_config_dword(dev, pos + PCI_ERR_UNCOR_SEVER, &mask);\n\tif (dev->error_state == pci_channel_io_normal)\n\t\tstatus &= ~mask;  \n\telse\n\t\tstatus &= mask;  \n\tpci_write_config_dword(dev, pos + PCI_ERR_UNCOR_STATUS, status);\n}\n\n \nstatic void stop_pci_io(struct octeon_device *oct)\n{\n\tstruct msix_entry *msix_entries;\n\tint i;\n\n\t \n\tatomic_set(&oct->status, OCT_DEV_IN_RESET);\n\n\tfor (i = 0; i < oct->ifcount; i++)\n\t\tnetif_device_detach(oct->props[i].netdev);\n\n\t \n\toct->fn_list.disable_interrupt(oct, OCTEON_ALL_INTR);\n\n\tpcierror_quiesce_device(oct);\n\tif (oct->msix_on) {\n\t\tmsix_entries = (struct msix_entry *)oct->msix_entries;\n\t\tfor (i = 0; i < oct->num_msix_irqs; i++) {\n\t\t\t \n\t\t\tirq_set_affinity_hint(msix_entries[i].vector,\n\t\t\t\t\t      NULL);\n\t\t\tfree_irq(msix_entries[i].vector,\n\t\t\t\t &oct->ioq_vector[i]);\n\t\t}\n\t\tpci_disable_msix(oct->pci_dev);\n\t\tkfree(oct->msix_entries);\n\t\toct->msix_entries = NULL;\n\t\tocteon_free_ioq_vector(oct);\n\t}\n\tdev_dbg(&oct->pci_dev->dev, \"Device state is now %s\\n\",\n\t\tlio_get_state_string(&oct->status));\n\n\t \n\tcleanup_aer_uncorrect_error_status(oct->pci_dev);\n\n\tpci_disable_device(oct->pci_dev);\n}\n\n \nstatic pci_ers_result_t liquidio_pcie_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\t     pci_channel_state_t state)\n{\n\tstruct octeon_device *oct = pci_get_drvdata(pdev);\n\n\t \n\tif (state == pci_channel_io_normal) {\n\t\tdev_err(&oct->pci_dev->dev, \"Non-correctable non-fatal error reported:\\n\");\n\t\tcleanup_aer_uncorrect_error_status(oct->pci_dev);\n\t\treturn PCI_ERS_RESULT_CAN_RECOVER;\n\t}\n\n\t \n\tdev_err(&oct->pci_dev->dev, \"Non-correctable FATAL reported by PCI AER driver\\n\");\n\tstop_pci_io(oct);\n\n\treturn PCI_ERS_RESULT_DISCONNECT;\n}\n\n \nstatic const struct pci_error_handlers liquidio_vf_err_handler = {\n\t.error_detected = liquidio_pcie_error_detected,\n};\n\nstatic const struct pci_device_id liquidio_vf_pci_tbl[] = {\n\t{\n\t\tPCI_VENDOR_ID_CAVIUM, OCTEON_CN23XX_VF_VID,\n\t\tPCI_ANY_ID, PCI_ANY_ID, 0, 0, 0\n\t},\n\t{\n\t\t0, 0, 0, 0, 0, 0, 0\n\t}\n};\nMODULE_DEVICE_TABLE(pci, liquidio_vf_pci_tbl);\n\nstatic struct pci_driver liquidio_vf_pci_driver = {\n\t.name\t\t= \"LiquidIO_VF\",\n\t.id_table\t= liquidio_vf_pci_tbl,\n\t.probe\t\t= liquidio_vf_probe,\n\t.remove\t\t= liquidio_vf_remove,\n\t.err_handler\t= &liquidio_vf_err_handler,     \n};\n\n \nstatic void print_link_info(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\n\tif (!ifstate_check(lio, LIO_IFSTATE_RESETTING) &&\n\t    ifstate_check(lio, LIO_IFSTATE_REGISTERED)) {\n\t\tstruct oct_link_info *linfo = &lio->linfo;\n\n\t\tif (linfo->link.s.link_up) {\n\t\t\tnetif_info(lio, link, lio->netdev, \"%d Mbps %s Duplex UP\\n\",\n\t\t\t\t   linfo->link.s.speed,\n\t\t\t\t   (linfo->link.s.duplex) ? \"Full\" : \"Half\");\n\t\t} else {\n\t\t\tnetif_info(lio, link, lio->netdev, \"Link Down\\n\");\n\t\t}\n\t}\n}\n\n \nstatic void octnet_link_status_change(struct work_struct *work)\n{\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\tstruct lio *lio = (struct lio *)wk->ctxptr;\n\n\t \n\trtnl_lock();\n\tdev_set_mtu(lio->netdev, lio->linfo.link.s.mtu);\n\trtnl_unlock();\n}\n\n \nstatic int setup_link_status_change_wq(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tlio->link_status_wq.wq = alloc_workqueue(\"link-status\",\n\t\t\t\t\t\t WQ_MEM_RECLAIM, 0);\n\tif (!lio->link_status_wq.wq) {\n\t\tdev_err(&oct->pci_dev->dev, \"unable to create cavium link status wq\\n\");\n\t\treturn -1;\n\t}\n\tINIT_DELAYED_WORK(&lio->link_status_wq.wk.work,\n\t\t\t  octnet_link_status_change);\n\tlio->link_status_wq.wk.ctxptr = lio;\n\n\treturn 0;\n}\n\nstatic void cleanup_link_status_change_wq(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\n\tif (lio->link_status_wq.wq) {\n\t\tcancel_delayed_work_sync(&lio->link_status_wq.wk.work);\n\t\tdestroy_workqueue(lio->link_status_wq.wq);\n\t}\n}\n\n \nstatic void update_link_status(struct net_device *netdev,\n\t\t\t       union oct_link_status *ls)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tint current_max_mtu = lio->linfo.link.s.mtu;\n\tstruct octeon_device *oct = lio->oct_dev;\n\n\tif ((lio->intf_open) && (lio->linfo.link.u64 != ls->u64)) {\n\t\tlio->linfo.link.u64 = ls->u64;\n\n\t\tprint_link_info(netdev);\n\t\tlio->link_changes++;\n\n\t\tif (lio->linfo.link.s.link_up) {\n\t\t\tnetif_carrier_on(netdev);\n\t\t\twake_txqs(netdev);\n\t\t} else {\n\t\t\tnetif_carrier_off(netdev);\n\t\t\tstop_txqs(netdev);\n\t\t}\n\n\t\tif (lio->linfo.link.s.mtu != current_max_mtu) {\n\t\t\tdev_info(&oct->pci_dev->dev,\n\t\t\t\t \"Max MTU Changed from %d to %d\\n\",\n\t\t\t\t current_max_mtu, lio->linfo.link.s.mtu);\n\t\t\tnetdev->max_mtu = lio->linfo.link.s.mtu;\n\t\t}\n\n\t\tif (lio->linfo.link.s.mtu < netdev->mtu) {\n\t\t\tdev_warn(&oct->pci_dev->dev,\n\t\t\t\t \"Current MTU is higher than new max MTU; Reducing the current mtu from %d to %d\\n\",\n\t\t\t\t netdev->mtu, lio->linfo.link.s.mtu);\n\t\t\tqueue_delayed_work(lio->link_status_wq.wq,\n\t\t\t\t\t   &lio->link_status_wq.wk.work, 0);\n\t\t}\n\t}\n}\n\n \nstatic int\nliquidio_vf_probe(struct pci_dev *pdev,\n\t\t  const struct pci_device_id __maybe_unused *ent)\n{\n\tstruct octeon_device *oct_dev = NULL;\n\n\toct_dev = octeon_allocate_device(pdev->device,\n\t\t\t\t\t sizeof(struct octeon_device_priv));\n\n\tif (!oct_dev) {\n\t\tdev_err(&pdev->dev, \"Unable to allocate device\\n\");\n\t\treturn -ENOMEM;\n\t}\n\toct_dev->msix_on = LIO_FLAG_MSIX_ENABLED;\n\n\tdev_info(&pdev->dev, \"Initializing device %x:%x.\\n\",\n\t\t (u32)pdev->vendor, (u32)pdev->device);\n\n\t \n\tpci_set_drvdata(pdev, oct_dev);\n\n\t \n\toct_dev->pci_dev = pdev;\n\n\toct_dev->subsystem_id = pdev->subsystem_vendor |\n\t\t(pdev->subsystem_device << 16);\n\n\tif (octeon_device_init(oct_dev)) {\n\t\tliquidio_vf_remove(pdev);\n\t\treturn -ENOMEM;\n\t}\n\n\tdev_dbg(&oct_dev->pci_dev->dev, \"Device is ready\\n\");\n\n\treturn 0;\n}\n\n \nstatic void octeon_pci_flr(struct octeon_device *oct)\n{\n\tpci_save_state(oct->pci_dev);\n\n\tpci_cfg_access_lock(oct->pci_dev);\n\n\t \n\tpci_write_config_word(oct->pci_dev, PCI_COMMAND,\n\t\t\t      PCI_COMMAND_INTX_DISABLE);\n\n\tpcie_flr(oct->pci_dev);\n\n\tpci_cfg_access_unlock(oct->pci_dev);\n\n\tpci_restore_state(oct->pci_dev);\n}\n\n \nstatic void octeon_destroy_resources(struct octeon_device *oct)\n{\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tstruct msix_entry *msix_entries;\n\tint i;\n\n\tswitch (atomic_read(&oct->status)) {\n\tcase OCT_DEV_RUNNING:\n\tcase OCT_DEV_CORE_OK:\n\t\t \n\t\tatomic_set(&oct->status, OCT_DEV_IN_RESET);\n\n\t\toct->app_mode = CVM_DRV_INVALID_APP;\n\t\tdev_dbg(&oct->pci_dev->dev, \"Device state is now %s\\n\",\n\t\t\tlio_get_state_string(&oct->status));\n\n\t\tschedule_timeout_uninterruptible(HZ / 10);\n\n\t\tfallthrough;\n\tcase OCT_DEV_HOST_OK:\n\tcase OCT_DEV_IO_QUEUES_DONE:\n\t\tif (lio_wait_for_instr_fetch(oct))\n\t\t\tdev_err(&oct->pci_dev->dev, \"IQ had pending instructions\\n\");\n\n\t\tif (wait_for_pending_requests(oct))\n\t\t\tdev_err(&oct->pci_dev->dev, \"There were pending requests\\n\");\n\n\t\t \n\t\toct->fn_list.disable_io_queues(oct);\n\n\t\tif (lio_wait_for_oq_pkts(oct))\n\t\t\tdev_err(&oct->pci_dev->dev, \"OQ had pending packets\\n\");\n\n\t\t \n\t\tfor (i = 0; i < MAX_OCTEON_INSTR_QUEUES(oct); i++) {\n\t\t\tstruct octeon_instr_queue *iq;\n\n\t\t\tif (!(oct->io_qmask.iq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tiq = oct->instr_queue[i];\n\n\t\t\tif (atomic_read(&iq->instr_pending)) {\n\t\t\t\tspin_lock_bh(&iq->lock);\n\t\t\t\tiq->fill_cnt = 0;\n\t\t\t\tiq->octeon_read_index = iq->host_write_index;\n\t\t\t\tiq->stats.instr_processed +=\n\t\t\t\t\tatomic_read(&iq->instr_pending);\n\t\t\t\tlio_process_iq_request_list(oct, iq, 0);\n\t\t\t\tspin_unlock_bh(&iq->lock);\n\t\t\t}\n\t\t}\n\n\t\tlio_process_ordered_list(oct, 1);\n\t\tocteon_free_sc_done_list(oct);\n\t\tocteon_free_sc_zombie_list(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_INTR_SET_DONE:\n\t\t \n\t\toct->fn_list.disable_interrupt(oct, OCTEON_ALL_INTR);\n\n\t\tif (oct->msix_on) {\n\t\t\tmsix_entries = (struct msix_entry *)oct->msix_entries;\n\t\t\tfor (i = 0; i < oct->num_msix_irqs; i++) {\n\t\t\t\tif (oct->ioq_vector[i].vector) {\n\t\t\t\t\tirq_set_affinity_hint(\n\t\t\t\t\t\t\tmsix_entries[i].vector,\n\t\t\t\t\t\t\tNULL);\n\t\t\t\t\tfree_irq(msix_entries[i].vector,\n\t\t\t\t\t\t &oct->ioq_vector[i]);\n\t\t\t\t\toct->ioq_vector[i].vector = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tpci_disable_msix(oct->pci_dev);\n\t\t\tkfree(oct->msix_entries);\n\t\t\toct->msix_entries = NULL;\n\t\t\tkfree(oct->irq_name_storage);\n\t\t\toct->irq_name_storage = NULL;\n\t\t}\n\t\t \n\t\tif (!pcie_reset_flr(oct->pci_dev, PCI_RESET_PROBE))\n\t\t\tocteon_pci_flr(oct);\n\t\telse\n\t\t\tcn23xx_vf_ask_pf_to_do_flr(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_MSIX_ALLOC_VECTOR_DONE:\n\t\tocteon_free_ioq_vector(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_MBOX_SETUP_DONE:\n\t\toct->fn_list.free_mbox(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_IN_RESET:\n\tcase OCT_DEV_DROQ_INIT_DONE:\n\t\tmdelay(100);\n\t\tfor (i = 0; i < MAX_OCTEON_OUTPUT_QUEUES(oct); i++) {\n\t\t\tif (!(oct->io_qmask.oq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tocteon_delete_droq(oct, i);\n\t\t}\n\n\t\tfallthrough;\n\tcase OCT_DEV_RESP_LIST_INIT_DONE:\n\t\tocteon_delete_response_list(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_INSTR_QUEUE_INIT_DONE:\n\t\tfor (i = 0; i < MAX_OCTEON_INSTR_QUEUES(oct); i++) {\n\t\t\tif (!(oct->io_qmask.iq & BIT_ULL(i)))\n\t\t\t\tcontinue;\n\t\t\tocteon_delete_instr_queue(oct, i);\n\t\t}\n\n\t\tfallthrough;\n\tcase OCT_DEV_SC_BUFF_POOL_INIT_DONE:\n\t\tocteon_free_sc_buffer_pool(oct);\n\n\t\tfallthrough;\n\tcase OCT_DEV_DISPATCH_INIT_DONE:\n\t\tocteon_delete_dispatch_list(oct);\n\t\tcancel_delayed_work_sync(&oct->nic_poll_work.work);\n\n\t\tfallthrough;\n\tcase OCT_DEV_PCI_MAP_DONE:\n\t\tocteon_unmap_pci_barx(oct, 0);\n\t\tocteon_unmap_pci_barx(oct, 1);\n\n\t\tfallthrough;\n\tcase OCT_DEV_PCI_ENABLE_DONE:\n\t\t \n\t\tpci_disable_device(oct->pci_dev);\n\n\t\tfallthrough;\n\tcase OCT_DEV_BEGIN_STATE:\n\t\t \n\t\tbreak;\n\t}\n\n\ttasklet_kill(&oct_priv->droq_tasklet);\n}\n\n \nstatic int send_rx_ctrl_cmd(struct lio *lio, int start_stop)\n{\n\tstruct octeon_device *oct = (struct octeon_device *)lio->oct_dev;\n\tstruct octeon_soft_command *sc;\n\tunion octnet_cmd *ncmd;\n\tint retval;\n\n\tif (oct->props[lio->ifidx].rx_on == start_stop)\n\t\treturn 0;\n\n\tsc = (struct octeon_soft_command *)\n\t\tocteon_alloc_soft_command(oct, OCTNET_CMD_SIZE,\n\t\t\t\t\t  16, 0);\n\tif (!sc) {\n\t\tnetif_info(lio, rx_err, lio->netdev,\n\t\t\t   \"Failed to allocate octeon_soft_command struct\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tncmd = (union octnet_cmd *)sc->virtdptr;\n\n\tncmd->u64 = 0;\n\tncmd->s.cmd = OCTNET_CMD_RX_CTL;\n\tncmd->s.param1 = start_stop;\n\n\tocteon_swap_8B_data((u64 *)ncmd, (OCTNET_CMD_SIZE >> 3));\n\n\tsc->iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_CMD, 0, 0, 0);\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tretval = octeon_send_soft_command(oct, sc);\n\tif (retval == IQ_SEND_FAILED) {\n\t\tnetif_info(lio, rx_err, lio->netdev, \"Failed to send RX Control message\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t} else {\n\t\t \n\t\tretval = wait_for_sc_completion_timeout(oct, sc, 0);\n\t\tif (retval)\n\t\t\treturn retval;\n\n\t\toct->props[lio->ifidx].rx_on = start_stop;\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t}\n\n\treturn retval;\n}\n\n \nstatic void liquidio_destroy_nic_device(struct octeon_device *oct, int ifidx)\n{\n\tstruct net_device *netdev = oct->props[ifidx].netdev;\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tstruct napi_struct *napi, *n;\n\tstruct lio *lio;\n\n\tif (!netdev) {\n\t\tdev_err(&oct->pci_dev->dev, \"%s No netdevice ptr for index %d\\n\",\n\t\t\t__func__, ifidx);\n\t\treturn;\n\t}\n\n\tlio = GET_LIO(netdev);\n\n\tdev_dbg(&oct->pci_dev->dev, \"NIC device cleanup\\n\");\n\n\tif (atomic_read(&lio->ifstate) & LIO_IFSTATE_RUNNING)\n\t\tliquidio_stop(netdev);\n\n\tif (oct->props[lio->ifidx].napi_enabled == 1) {\n\t\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\t\tnapi_disable(napi);\n\n\t\toct->props[lio->ifidx].napi_enabled = 0;\n\n\t\toct->droq[0]->ops.poll_mode = 0;\n\t}\n\n\t \n\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\tnetif_napi_del(napi);\n\n\ttasklet_enable(&oct_priv->droq_tasklet);\n\n\tif (atomic_read(&lio->ifstate) & LIO_IFSTATE_REGISTERED)\n\t\tunregister_netdev(netdev);\n\n\tcleanup_rx_oom_poll_fn(netdev);\n\n\tcleanup_link_status_change_wq(netdev);\n\n\tlio_delete_glists(lio);\n\n\tfree_netdev(netdev);\n\n\toct->props[ifidx].gmxport = -1;\n\n\toct->props[ifidx].netdev = NULL;\n}\n\n \nstatic int liquidio_stop_nic_module(struct octeon_device *oct)\n{\n\tstruct lio *lio;\n\tint i, j;\n\n\tdev_dbg(&oct->pci_dev->dev, \"Stopping network interfaces\\n\");\n\tif (!oct->ifcount) {\n\t\tdev_err(&oct->pci_dev->dev, \"Init for Octeon was not completed\\n\");\n\t\treturn 1;\n\t}\n\n\tspin_lock_bh(&oct->cmd_resp_wqlock);\n\toct->cmd_resp_state = OCT_DRV_OFFLINE;\n\tspin_unlock_bh(&oct->cmd_resp_wqlock);\n\n\tfor (i = 0; i < oct->ifcount; i++) {\n\t\tlio = GET_LIO(oct->props[i].netdev);\n\t\tfor (j = 0; j < oct->num_oqs; j++)\n\t\t\tocteon_unregister_droq_ops(oct,\n\t\t\t\t\t\t   lio->linfo.rxpciq[j].s.q_no);\n\t}\n\n\tfor (i = 0; i < oct->ifcount; i++)\n\t\tliquidio_destroy_nic_device(oct, i);\n\n\tdev_dbg(&oct->pci_dev->dev, \"Network interfaces stopped\\n\");\n\treturn 0;\n}\n\n \nstatic void liquidio_vf_remove(struct pci_dev *pdev)\n{\n\tstruct octeon_device *oct_dev = pci_get_drvdata(pdev);\n\n\tdev_dbg(&oct_dev->pci_dev->dev, \"Stopping device\\n\");\n\n\tif (oct_dev->app_mode == CVM_DRV_NIC_APP)\n\t\tliquidio_stop_nic_module(oct_dev);\n\n\t \n\tocteon_destroy_resources(oct_dev);\n\n\tdev_info(&oct_dev->pci_dev->dev, \"Device removed\\n\");\n\n\t \n\tocteon_free_device_mem(oct_dev);\n}\n\n \nstatic int octeon_pci_os_setup(struct octeon_device *oct)\n{\n#ifdef CONFIG_PCI_IOV\n\t \n\tif (!oct->pci_dev->physfn)\n\t\tocteon_pci_flr(oct);\n#endif\n\n\tif (pci_enable_device(oct->pci_dev)) {\n\t\tdev_err(&oct->pci_dev->dev, \"pci_enable_device failed\\n\");\n\t\treturn 1;\n\t}\n\n\tif (dma_set_mask_and_coherent(&oct->pci_dev->dev, DMA_BIT_MASK(64))) {\n\t\tdev_err(&oct->pci_dev->dev, \"Unexpected DMA device capability\\n\");\n\t\tpci_disable_device(oct->pci_dev);\n\t\treturn 1;\n\t}\n\n\t \n\tpci_set_master(oct->pci_dev);\n\n\treturn 0;\n}\n\n \nstatic void free_netbuf(void *buf)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tstruct sk_buff *skb;\n\tstruct lio *lio;\n\n\tfinfo = (struct octnet_buf_free_info *)buf;\n\tskb = finfo->skb;\n\tlio = finfo->lio;\n\n\tdma_unmap_single(&lio->oct_dev->pci_dev->dev, finfo->dptr, skb->len,\n\t\t\t DMA_TO_DEVICE);\n\n\ttx_buffer_free(skb);\n}\n\n \nstatic void free_netsgbuf(void *buf)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tstruct octnic_gather *g;\n\tstruct sk_buff *skb;\n\tint i, frags, iq;\n\tstruct lio *lio;\n\n\tfinfo = (struct octnet_buf_free_info *)buf;\n\tskb = finfo->skb;\n\tlio = finfo->lio;\n\tg = finfo->g;\n\tfrags = skb_shinfo(skb)->nr_frags;\n\n\tdma_unmap_single(&lio->oct_dev->pci_dev->dev,\n\t\t\t g->sg[0].ptr[0], (skb->len - skb->data_len),\n\t\t\t DMA_TO_DEVICE);\n\n\ti = 1;\n\twhile (frags--) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i - 1];\n\n\t\tdma_unmap_page(&lio->oct_dev->pci_dev->dev,\n\t\t\t       g->sg[(i >> 2)].ptr[(i & 3)],\n\t\t\t       skb_frag_size(frag), DMA_TO_DEVICE);\n\t\ti++;\n\t}\n\n\tiq = skb_iq(lio->oct_dev, skb);\n\n\tspin_lock(&lio->glist_lock[iq]);\n\tlist_add_tail(&g->list, &lio->glist[iq]);\n\tspin_unlock(&lio->glist_lock[iq]);\n\n\ttx_buffer_free(skb);\n}\n\n \nstatic void free_netsgbuf_with_resp(void *buf)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tstruct octeon_soft_command *sc;\n\tstruct octnic_gather *g;\n\tstruct sk_buff *skb;\n\tint i, frags, iq;\n\tstruct lio *lio;\n\n\tsc = (struct octeon_soft_command *)buf;\n\tskb = (struct sk_buff *)sc->callback_arg;\n\tfinfo = (struct octnet_buf_free_info *)&skb->cb;\n\n\tlio = finfo->lio;\n\tg = finfo->g;\n\tfrags = skb_shinfo(skb)->nr_frags;\n\n\tdma_unmap_single(&lio->oct_dev->pci_dev->dev,\n\t\t\t g->sg[0].ptr[0], (skb->len - skb->data_len),\n\t\t\t DMA_TO_DEVICE);\n\n\ti = 1;\n\twhile (frags--) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i - 1];\n\n\t\tdma_unmap_page(&lio->oct_dev->pci_dev->dev,\n\t\t\t       g->sg[(i >> 2)].ptr[(i & 3)],\n\t\t\t       skb_frag_size(frag), DMA_TO_DEVICE);\n\t\ti++;\n\t}\n\n\tiq = skb_iq(lio->oct_dev, skb);\n\n\tspin_lock(&lio->glist_lock[iq]);\n\tlist_add_tail(&g->list, &lio->glist[iq]);\n\tspin_unlock(&lio->glist_lock[iq]);\n\n\t \n}\n\n \nstatic int liquidio_open(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tstruct napi_struct *napi, *n;\n\tint ret = 0;\n\n\tif (!oct->props[lio->ifidx].napi_enabled) {\n\t\ttasklet_disable(&oct_priv->droq_tasklet);\n\n\t\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\t\tnapi_enable(napi);\n\n\t\toct->props[lio->ifidx].napi_enabled = 1;\n\n\t\toct->droq[0]->ops.poll_mode = 1;\n\t}\n\n\tifstate_set(lio, LIO_IFSTATE_RUNNING);\n\n\t \n\tlio->intf_open = 1;\n\n\tnetif_info(lio, ifup, lio->netdev, \"Interface Open, ready for traffic\\n\");\n\tstart_txqs(netdev);\n\n\tINIT_DELAYED_WORK(&lio->stats_wk.work, lio_fetch_stats);\n\tlio->stats_wk.ctxptr = lio;\n\tschedule_delayed_work(&lio->stats_wk.work, msecs_to_jiffies\n\t\t\t\t\t(LIQUIDIO_NDEV_STATS_POLL_TIME_MS));\n\n\t \n\tret = send_rx_ctrl_cmd(lio, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_info(&oct->pci_dev->dev, \"%s interface is opened\\n\", netdev->name);\n\n\treturn ret;\n}\n\n \nstatic int liquidio_stop(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octeon_device_priv *oct_priv = oct->priv;\n\tstruct napi_struct *napi, *n;\n\tint ret = 0;\n\n\t \n\tret = send_rx_ctrl_cmd(lio, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tnetif_info(lio, ifdown, lio->netdev, \"Stopping interface!\\n\");\n\t \n\tlio->intf_open = 0;\n\tlio->linfo.link.s.link_up = 0;\n\n\tnetif_carrier_off(netdev);\n\tlio->link_changes++;\n\n\tifstate_reset(lio, LIO_IFSTATE_RUNNING);\n\n\tstop_txqs(netdev);\n\n\t \n\tif (lio_wait_for_clean_oq(oct))\n\t\tnetif_info(lio, rx_err, lio->netdev,\n\t\t\t   \"Proceeding with stop interface after partial RX desc processing\\n\");\n\n\tif (oct->props[lio->ifidx].napi_enabled == 1) {\n\t\tlist_for_each_entry_safe(napi, n, &netdev->napi_list, dev_list)\n\t\t\tnapi_disable(napi);\n\n\t\toct->props[lio->ifidx].napi_enabled = 0;\n\n\t\toct->droq[0]->ops.poll_mode = 0;\n\n\t\ttasklet_enable(&oct_priv->droq_tasklet);\n\t}\n\n\tcancel_delayed_work_sync(&lio->stats_wk.work);\n\n\tdev_info(&oct->pci_dev->dev, \"%s interface is stopped\\n\", netdev->name);\n\n\treturn ret;\n}\n\n \nstatic enum octnet_ifflags get_new_flags(struct net_device *netdev)\n{\n\tenum octnet_ifflags f = OCTNET_IFFLAG_UNICAST;\n\n\tif (netdev->flags & IFF_PROMISC)\n\t\tf |= OCTNET_IFFLAG_PROMISC;\n\n\tif (netdev->flags & IFF_ALLMULTI)\n\t\tf |= OCTNET_IFFLAG_ALLMULTI;\n\n\tif (netdev->flags & IFF_MULTICAST) {\n\t\tf |= OCTNET_IFFLAG_MULTICAST;\n\n\t\t \n\t\tif (netdev_mc_count(netdev) > MAX_OCTEON_MULTICAST_ADDR)\n\t\t\tf |= OCTNET_IFFLAG_ALLMULTI;\n\t}\n\n\tif (netdev->flags & IFF_BROADCAST)\n\t\tf |= OCTNET_IFFLAG_BROADCAST;\n\n\treturn f;\n}\n\nstatic void liquidio_set_uc_list(struct net_device *netdev)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tstruct netdev_hw_addr *ha;\n\tu64 *mac;\n\n\tif (lio->netdev_uc_count == netdev_uc_count(netdev))\n\t\treturn;\n\n\tif (netdev_uc_count(netdev) > MAX_NCTRL_UDD) {\n\t\tdev_err(&oct->pci_dev->dev, \"too many MAC addresses in netdev uc list\\n\");\n\t\treturn;\n\t}\n\n\tlio->netdev_uc_count = netdev_uc_count(netdev);\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_SET_UC_LIST;\n\tnctrl.ncmd.s.more = lio->netdev_uc_count;\n\tnctrl.ncmd.s.param1 = oct->vf_num;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\t \n\tmac = &nctrl.udd[0];\n\tnetdev_for_each_uc_addr(ha, netdev) {\n\t\tether_addr_copy(((u8 *)mac) + 2, ha->addr);\n\t\tmac++;\n\t}\n\n\toctnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n}\n\n \nstatic void liquidio_set_mcast_list(struct net_device *netdev)\n{\n\tint mc_count = min(netdev_mc_count(netdev), MAX_OCTEON_MULTICAST_ADDR);\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tstruct netdev_hw_addr *ha;\n\tu64 *mc;\n\tint ret;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\t \n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_SET_MULTI_LIST;\n\tnctrl.ncmd.s.param1 = get_new_flags(netdev);\n\tnctrl.ncmd.s.param2 = mc_count;\n\tnctrl.ncmd.s.more = mc_count;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\t \n\tmc = &nctrl.udd[0];\n\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\t*mc = 0;\n\t\tether_addr_copy(((u8 *)mc) + 2, ha->addr);\n\t\t \n\t\tif (++mc > &nctrl.udd[mc_count])\n\t\t\tbreak;\n\t}\n\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\n\t \n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"DEVFLAGS change failed in core (ret: 0x%x)\\n\",\n\t\t\tret);\n\t}\n\n\tliquidio_set_uc_list(netdev);\n}\n\n \nstatic int liquidio_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct sockaddr *addr = (struct sockaddr *)p;\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (ether_addr_equal(addr->sa_data, netdev->dev_addr))\n\t\treturn 0;\n\n\tif (lio->linfo.macaddr_is_admin_asgnd)\n\t\treturn -EPERM;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_CHANGE_MACADDR;\n\tnctrl.ncmd.s.param1 = 0;\n\tnctrl.ncmd.s.more = 1;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\n\tnctrl.udd[0] = 0;\n\t \n\tether_addr_copy((u8 *)&nctrl.udd[0] + 2, addr->sa_data);\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret < 0) {\n\t\tdev_err(&oct->pci_dev->dev, \"MAC Address change failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (nctrl.sc_status ==\n\t    FIRMWARE_STATUS_CODE(OCTEON_REQUEST_NO_PERMISSION)) {\n\t\tdev_err(&oct->pci_dev->dev, \"MAC Address change failed: no permission\\n\");\n\t\treturn -EPERM;\n\t}\n\n\teth_hw_addr_set(netdev, addr->sa_data);\n\tether_addr_copy(((u8 *)&lio->linfo.hw_addr) + 2, addr->sa_data);\n\n\treturn 0;\n}\n\nstatic void\nliquidio_get_stats64(struct net_device *netdev,\n\t\t     struct rtnl_link_stats64 *lstats)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct;\n\tu64 pkts = 0, drop = 0, bytes = 0;\n\tstruct oct_droq_stats *oq_stats;\n\tstruct oct_iq_stats *iq_stats;\n\tint i, iq_no, oq_no;\n\n\toct = lio->oct_dev;\n\n\tif (ifstate_check(lio, LIO_IFSTATE_RESETTING))\n\t\treturn;\n\n\tfor (i = 0; i < oct->num_iqs; i++) {\n\t\tiq_no = lio->linfo.txpciq[i].s.q_no;\n\t\tiq_stats = &oct->instr_queue[iq_no]->stats;\n\t\tpkts += iq_stats->tx_done;\n\t\tdrop += iq_stats->tx_dropped;\n\t\tbytes += iq_stats->tx_tot_bytes;\n\t}\n\n\tlstats->tx_packets = pkts;\n\tlstats->tx_bytes = bytes;\n\tlstats->tx_dropped = drop;\n\n\tpkts = 0;\n\tdrop = 0;\n\tbytes = 0;\n\n\tfor (i = 0; i < oct->num_oqs; i++) {\n\t\toq_no = lio->linfo.rxpciq[i].s.q_no;\n\t\toq_stats = &oct->droq[oq_no]->stats;\n\t\tpkts += oq_stats->rx_pkts_received;\n\t\tdrop += (oq_stats->rx_dropped +\n\t\t\t oq_stats->dropped_nodispatch +\n\t\t\t oq_stats->dropped_toomany +\n\t\t\t oq_stats->dropped_nomem);\n\t\tbytes += oq_stats->rx_bytes_received;\n\t}\n\n\tlstats->rx_bytes = bytes;\n\tlstats->rx_packets = pkts;\n\tlstats->rx_dropped = drop;\n\n\tlstats->multicast = oct->link_stats.fromwire.fw_total_mcast;\n\n\t \n\tlstats->rx_length_errors = oct->link_stats.fromwire.l2_err;\n\t \n\tlstats->rx_crc_errors = oct->link_stats.fromwire.fcs_err;\n\t \n\tlstats->rx_frame_errors = oct->link_stats.fromwire.frame_err;\n\n\tlstats->rx_errors = lstats->rx_length_errors + lstats->rx_crc_errors +\n\t\t\t    lstats->rx_frame_errors;\n\n\t \n\tlstats->tx_aborted_errors = oct->link_stats.fromhost.fw_err_pko;\n\tlstats->tx_carrier_errors = oct->link_stats.fromhost.fw_err_link;\n\n\tlstats->tx_errors = lstats->tx_aborted_errors +\n\t\tlstats->tx_carrier_errors;\n}\n\n \nstatic int hwtstamp_ioctl(struct net_device *netdev, struct ifreq *ifr)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct hwtstamp_config conf;\n\n\tif (copy_from_user(&conf, ifr->ifr_data, sizeof(conf)))\n\t\treturn -EFAULT;\n\n\tswitch (conf.tx_type) {\n\tcase HWTSTAMP_TX_ON:\n\tcase HWTSTAMP_TX_OFF:\n\t\tbreak;\n\tdefault:\n\t\treturn -ERANGE;\n\t}\n\n\tswitch (conf.rx_filter) {\n\tcase HWTSTAMP_FILTER_NONE:\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_ALL:\n\tcase HWTSTAMP_FILTER_SOME:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_NTP_ALL:\n\t\tconf.rx_filter = HWTSTAMP_FILTER_ALL;\n\t\tbreak;\n\tdefault:\n\t\treturn -ERANGE;\n\t}\n\n\tif (conf.rx_filter == HWTSTAMP_FILTER_ALL)\n\t\tifstate_set(lio, LIO_IFSTATE_RX_TIMESTAMP_ENABLED);\n\n\telse\n\t\tifstate_reset(lio, LIO_IFSTATE_RX_TIMESTAMP_ENABLED);\n\n\treturn copy_to_user(ifr->ifr_data, &conf, sizeof(conf)) ? -EFAULT : 0;\n}\n\n \nstatic int liquidio_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tswitch (cmd) {\n\tcase SIOCSHWTSTAMP:\n\t\treturn hwtstamp_ioctl(netdev, ifr);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void handle_timestamp(struct octeon_device *oct, u32 status, void *buf)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)buf;\n\tstruct octnet_buf_free_info *finfo;\n\tstruct oct_timestamp_resp *resp;\n\tstruct octeon_soft_command *sc;\n\tstruct lio *lio;\n\n\tfinfo = (struct octnet_buf_free_info *)skb->cb;\n\tlio = finfo->lio;\n\tsc = finfo->sc;\n\toct = lio->oct_dev;\n\tresp = (struct oct_timestamp_resp *)sc->virtrptr;\n\n\tif (status != OCTEON_REQUEST_DONE) {\n\t\tdev_err(&oct->pci_dev->dev, \"Tx timestamp instruction failed. Status: %llx\\n\",\n\t\t\tCVM_CAST64(status));\n\t\tresp->timestamp = 0;\n\t}\n\n\tocteon_swap_8B_data(&resp->timestamp, 1);\n\n\tif (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_IN_PROGRESS)) {\n\t\tstruct skb_shared_hwtstamps ts;\n\t\tu64 ns = resp->timestamp;\n\n\t\tnetif_info(lio, tx_done, lio->netdev,\n\t\t\t   \"Got resulting SKBTX_HW_TSTAMP skb=%p ns=%016llu\\n\",\n\t\t\t   skb, (unsigned long long)ns);\n\t\tts.hwtstamp = ns_to_ktime(ns + lio->ptp_adjust);\n\t\tskb_tstamp_tx(skb, &ts);\n\t}\n\n\tocteon_free_soft_command(oct, sc);\n\ttx_buffer_free(skb);\n}\n\n \nstatic int send_nic_timestamp_pkt(struct octeon_device *oct,\n\t\t\t\t  struct octnic_data_pkt *ndata,\n\t\t\t\t  struct octnet_buf_free_info *finfo,\n\t\t\t\t  int xmit_more)\n{\n\tstruct octeon_soft_command *sc;\n\tint ring_doorbell;\n\tstruct lio *lio;\n\tint retval;\n\tu32 len;\n\n\tlio = finfo->lio;\n\n\tsc = octeon_alloc_soft_command_resp(oct, &ndata->cmd,\n\t\t\t\t\t    sizeof(struct oct_timestamp_resp));\n\tfinfo->sc = sc;\n\n\tif (!sc) {\n\t\tdev_err(&oct->pci_dev->dev, \"No memory for timestamped data packet\\n\");\n\t\treturn IQ_SEND_FAILED;\n\t}\n\n\tif (ndata->reqtype == REQTYPE_NORESP_NET)\n\t\tndata->reqtype = REQTYPE_RESP_NET;\n\telse if (ndata->reqtype == REQTYPE_NORESP_NET_SG)\n\t\tndata->reqtype = REQTYPE_RESP_NET_SG;\n\n\tsc->callback = handle_timestamp;\n\tsc->callback_arg = finfo->skb;\n\tsc->iq_no = ndata->q_no;\n\n\tlen = (u32)((struct octeon_instr_ih3 *)(&sc->cmd.cmd3.ih3))->dlengsz;\n\n\tring_doorbell = !xmit_more;\n\n\tretval = octeon_send_command(oct, sc->iq_no, ring_doorbell, &sc->cmd,\n\t\t\t\t     sc, len, ndata->reqtype);\n\n\tif (retval == IQ_SEND_FAILED) {\n\t\tdev_err(&oct->pci_dev->dev, \"timestamp data packet failed status: %x\\n\",\n\t\t\tretval);\n\t\tocteon_free_soft_command(oct, sc);\n\t} else {\n\t\tnetif_info(lio, tx_queued, lio->netdev, \"Queued timestamp packet\\n\");\n\t}\n\n\treturn retval;\n}\n\n \nstatic netdev_tx_t liquidio_xmit(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct octnet_buf_free_info *finfo;\n\tunion octnic_cmd_setup cmdsetup;\n\tstruct octnic_data_pkt ndata;\n\tstruct octeon_instr_irh *irh;\n\tstruct oct_iq_stats *stats;\n\tstruct octeon_device *oct;\n\tint q_idx = 0, iq_no = 0;\n\tunion tx_info *tx_info;\n\tint xmit_more = 0;\n\tstruct lio *lio;\n\tint status = 0;\n\tu64 dptr = 0;\n\tu32 tag = 0;\n\tint j;\n\n\tlio = GET_LIO(netdev);\n\toct = lio->oct_dev;\n\n\tq_idx = skb_iq(lio->oct_dev, skb);\n\ttag = q_idx;\n\tiq_no = lio->linfo.txpciq[q_idx].s.q_no;\n\n\tstats = &oct->instr_queue[iq_no]->stats;\n\n\t \n\tif (!(atomic_read(&lio->ifstate) & LIO_IFSTATE_RUNNING) ||\n\t    (!lio->linfo.link.s.link_up) || (skb->len <= 0)) {\n\t\tnetif_info(lio, tx_err, lio->netdev, \"Transmit failed link_status : %d\\n\",\n\t\t\t   lio->linfo.link.s.link_up);\n\t\tgoto lio_xmit_failed;\n\t}\n\n\t \n\tfinfo = (struct octnet_buf_free_info *)skb->cb;\n\tfinfo->lio = lio;\n\tfinfo->skb = skb;\n\tfinfo->sc = NULL;\n\n\t \n\tmemset(&ndata, 0, sizeof(struct octnic_data_pkt));\n\n\tndata.buf = finfo;\n\n\tndata.q_no = iq_no;\n\n\tif (octnet_iq_is_full(oct, ndata.q_no)) {\n\t\t \n\t\tnetif_info(lio, tx_err, lio->netdev, \"Transmit failed iq:%d full\\n\",\n\t\t\t   ndata.q_no);\n\t\tstats->tx_iq_busy++;\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tndata.datasize = skb->len;\n\n\tcmdsetup.u64 = 0;\n\tcmdsetup.s.iq_no = iq_no;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tif (skb->encapsulation) {\n\t\t\tcmdsetup.s.tnl_csum = 1;\n\t\t\tstats->tx_vxlan++;\n\t\t} else {\n\t\t\tcmdsetup.s.transport_csum = 1;\n\t\t}\n\t}\n\tif (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP)) {\n\t\tskb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;\n\t\tcmdsetup.s.timestamp = 1;\n\t}\n\n\tif (!skb_shinfo(skb)->nr_frags) {\n\t\tcmdsetup.s.u.datasize = skb->len;\n\t\toctnet_prepare_pci_cmd(oct, &ndata.cmd, &cmdsetup, tag);\n\t\t \n\t\tdptr = dma_map_single(&oct->pci_dev->dev,\n\t\t\t\t      skb->data,\n\t\t\t\t      skb->len,\n\t\t\t\t      DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&oct->pci_dev->dev, dptr)) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"%s DMA mapping error 1\\n\",\n\t\t\t\t__func__);\n\t\t\treturn NETDEV_TX_BUSY;\n\t\t}\n\n\t\tndata.cmd.cmd3.dptr = dptr;\n\t\tfinfo->dptr = dptr;\n\t\tndata.reqtype = REQTYPE_NORESP_NET;\n\n\t} else {\n\t\tskb_frag_t *frag;\n\t\tstruct octnic_gather *g;\n\t\tint i, frags;\n\n\t\tspin_lock(&lio->glist_lock[q_idx]);\n\t\tg = (struct octnic_gather *)\n\t\t\tlio_list_delete_head(&lio->glist[q_idx]);\n\t\tspin_unlock(&lio->glist_lock[q_idx]);\n\n\t\tif (!g) {\n\t\t\tnetif_info(lio, tx_err, lio->netdev,\n\t\t\t\t   \"Transmit scatter gather: glist null!\\n\");\n\t\t\tgoto lio_xmit_failed;\n\t\t}\n\n\t\tcmdsetup.s.gather = 1;\n\t\tcmdsetup.s.u.gatherptrs = (skb_shinfo(skb)->nr_frags + 1);\n\t\toctnet_prepare_pci_cmd(oct, &ndata.cmd, &cmdsetup, tag);\n\n\t\tmemset(g->sg, 0, g->sg_size);\n\n\t\tg->sg[0].ptr[0] = dma_map_single(&oct->pci_dev->dev,\n\t\t\t\t\t\t skb->data,\n\t\t\t\t\t\t (skb->len - skb->data_len),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&oct->pci_dev->dev, g->sg[0].ptr[0])) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"%s DMA mapping error 2\\n\",\n\t\t\t\t__func__);\n\t\t\treturn NETDEV_TX_BUSY;\n\t\t}\n\t\tadd_sg_size(&g->sg[0], (skb->len - skb->data_len), 0);\n\n\t\tfrags = skb_shinfo(skb)->nr_frags;\n\t\ti = 1;\n\t\twhile (frags--) {\n\t\t\tfrag = &skb_shinfo(skb)->frags[i - 1];\n\n\t\t\tg->sg[(i >> 2)].ptr[(i & 3)] =\n\t\t\t\tskb_frag_dma_map(&oct->pci_dev->dev,\n\t\t\t\t\t\t frag, 0, skb_frag_size(frag),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\tif (dma_mapping_error(&oct->pci_dev->dev,\n\t\t\t\t\t      g->sg[i >> 2].ptr[i & 3])) {\n\t\t\t\tdma_unmap_single(&oct->pci_dev->dev,\n\t\t\t\t\t\t g->sg[0].ptr[0],\n\t\t\t\t\t\t skb->len - skb->data_len,\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\t\tfor (j = 1; j < i; j++) {\n\t\t\t\t\tfrag = &skb_shinfo(skb)->frags[j - 1];\n\t\t\t\t\tdma_unmap_page(&oct->pci_dev->dev,\n\t\t\t\t\t\t       g->sg[j >> 2].ptr[j & 3],\n\t\t\t\t\t\t       skb_frag_size(frag),\n\t\t\t\t\t\t       DMA_TO_DEVICE);\n\t\t\t\t}\n\t\t\t\tdev_err(&oct->pci_dev->dev, \"%s DMA mapping error 3\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\treturn NETDEV_TX_BUSY;\n\t\t\t}\n\n\t\t\tadd_sg_size(&g->sg[(i >> 2)], skb_frag_size(frag),\n\t\t\t\t    (i & 3));\n\t\t\ti++;\n\t\t}\n\n\t\tdptr = g->sg_dma_ptr;\n\n\t\tndata.cmd.cmd3.dptr = dptr;\n\t\tfinfo->dptr = dptr;\n\t\tfinfo->g = g;\n\n\t\tndata.reqtype = REQTYPE_NORESP_NET_SG;\n\t}\n\n\tirh = (struct octeon_instr_irh *)&ndata.cmd.cmd3.irh;\n\ttx_info = (union tx_info *)&ndata.cmd.cmd3.ossp[0];\n\n\tif (skb_shinfo(skb)->gso_size) {\n\t\ttx_info->s.gso_size = skb_shinfo(skb)->gso_size;\n\t\ttx_info->s.gso_segs = skb_shinfo(skb)->gso_segs;\n\t}\n\n\t \n\tif (skb_vlan_tag_present(skb)) {\n\t\tirh->priority = skb_vlan_tag_get(skb) >> VLAN_PRIO_SHIFT;\n\t\tirh->vlan = skb_vlan_tag_get(skb) & VLAN_VID_MASK;\n\t}\n\n\txmit_more = netdev_xmit_more();\n\n\tif (unlikely(cmdsetup.s.timestamp))\n\t\tstatus = send_nic_timestamp_pkt(oct, &ndata, finfo, xmit_more);\n\telse\n\t\tstatus = octnet_send_nic_data_pkt(oct, &ndata, xmit_more);\n\tif (status == IQ_SEND_FAILED)\n\t\tgoto lio_xmit_failed;\n\n\tnetif_info(lio, tx_queued, lio->netdev, \"Transmit queued successfully\\n\");\n\n\tif (status == IQ_SEND_STOP) {\n\t\tdev_err(&oct->pci_dev->dev, \"Rcvd IQ_SEND_STOP signal; stopping IQ-%d\\n\",\n\t\t\tiq_no);\n\t\tnetif_stop_subqueue(netdev, q_idx);\n\t}\n\n\tnetif_trans_update(netdev);\n\n\tif (tx_info->s.gso_segs)\n\t\tstats->tx_done += tx_info->s.gso_segs;\n\telse\n\t\tstats->tx_done++;\n\tstats->tx_tot_bytes += ndata.datasize;\n\n\treturn NETDEV_TX_OK;\n\nlio_xmit_failed:\n\tstats->tx_dropped++;\n\tnetif_info(lio, tx_err, lio->netdev, \"IQ%d Transmit dropped:%llu\\n\",\n\t\t   iq_no, stats->tx_dropped);\n\tif (dptr)\n\t\tdma_unmap_single(&oct->pci_dev->dev, dptr,\n\t\t\t\t ndata.datasize, DMA_TO_DEVICE);\n\n\tocteon_ring_doorbell_locked(oct, iq_no);\n\n\ttx_buffer_free(skb);\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic void liquidio_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct lio *lio;\n\n\tlio = GET_LIO(netdev);\n\n\tnetif_info(lio, tx_err, lio->netdev,\n\t\t   \"Transmit timeout tx_dropped:%ld, waking up queues now!!\\n\",\n\t\t   netdev->stats.tx_dropped);\n\tnetif_trans_update(netdev);\n\twake_txqs(netdev);\n}\n\nstatic int\nliquidio_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t __be16 proto __attribute__((unused)), u16 vid)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_ADD_VLAN_FILTER;\n\tnctrl.ncmd.s.param1 = vid;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"Add VLAN filter failed in core (ret: 0x%x)\\n\",\n\t\t\tret);\n\t\treturn -EPERM;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nliquidio_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t  __be16 proto __attribute__((unused)), u16 vid)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = OCTNET_CMD_DEL_VLAN_FILTER;\n\tnctrl.ncmd.s.param1 = vid;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"Del VLAN filter failed in core (ret: 0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\treturn ret;\n}\n\n \nstatic int liquidio_set_rxcsum_command(struct net_device *netdev, int command,\n\t\t\t\t       u8 rx_cmd)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = command;\n\tnctrl.ncmd.s.param1 = rx_cmd;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev, \"DEVFLAGS RXCSUM change failed in core (ret:0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\treturn ret;\n}\n\n \nstatic int liquidio_vxlan_port_command(struct net_device *netdev, int command,\n\t\t\t\t       u16 vxlan_port, u8 vxlan_cmd_bit)\n{\n\tstruct lio *lio = GET_LIO(netdev);\n\tstruct octeon_device *oct = lio->oct_dev;\n\tstruct octnic_ctrl_pkt nctrl;\n\tint ret = 0;\n\n\tmemset(&nctrl, 0, sizeof(struct octnic_ctrl_pkt));\n\n\tnctrl.ncmd.u64 = 0;\n\tnctrl.ncmd.s.cmd = command;\n\tnctrl.ncmd.s.more = vxlan_cmd_bit;\n\tnctrl.ncmd.s.param1 = vxlan_port;\n\tnctrl.iq_no = lio->linfo.txpciq[0].s.q_no;\n\tnctrl.netpndev = (u64)netdev;\n\tnctrl.cb_fn = liquidio_link_ctrl_cmd_completion;\n\n\tret = octnet_send_nic_ctrl_pkt(lio->oct_dev, &nctrl);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"DEVFLAGS VxLAN port add/delete failed in core (ret : 0x%x)\\n\",\n\t\t\tret);\n\t\tif (ret > 0)\n\t\t\tret = -EIO;\n\t}\n\treturn ret;\n}\n\nstatic int liquidio_udp_tunnel_set_port(struct net_device *netdev,\n\t\t\t\t\tunsigned int table, unsigned int entry,\n\t\t\t\t\tstruct udp_tunnel_info *ti)\n{\n\treturn liquidio_vxlan_port_command(netdev,\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_CONFIG,\n\t\t\t\t\t   htons(ti->port),\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_ADD);\n}\n\nstatic int liquidio_udp_tunnel_unset_port(struct net_device *netdev,\n\t\t\t\t\t  unsigned int table,\n\t\t\t\t\t  unsigned int entry,\n\t\t\t\t\t  struct udp_tunnel_info *ti)\n{\n\treturn liquidio_vxlan_port_command(netdev,\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_CONFIG,\n\t\t\t\t\t   htons(ti->port),\n\t\t\t\t\t   OCTNET_CMD_VXLAN_PORT_DEL);\n}\n\nstatic const struct udp_tunnel_nic_info liquidio_udp_tunnels = {\n\t.set_port\t= liquidio_udp_tunnel_set_port,\n\t.unset_port\t= liquidio_udp_tunnel_unset_port,\n\t.tables\t\t= {\n\t\t{ .n_entries = 1024, .tunnel_types = UDP_TUNNEL_TYPE_VXLAN, },\n\t},\n};\n\n \nstatic netdev_features_t liquidio_fix_features(struct net_device *netdev,\n\t\t\t\t\t       netdev_features_t request)\n{\n\tstruct lio *lio = netdev_priv(netdev);\n\n\tif ((request & NETIF_F_RXCSUM) &&\n\t    !(lio->dev_capability & NETIF_F_RXCSUM))\n\t\trequest &= ~NETIF_F_RXCSUM;\n\n\tif ((request & NETIF_F_HW_CSUM) &&\n\t    !(lio->dev_capability & NETIF_F_HW_CSUM))\n\t\trequest &= ~NETIF_F_HW_CSUM;\n\n\tif ((request & NETIF_F_TSO) && !(lio->dev_capability & NETIF_F_TSO))\n\t\trequest &= ~NETIF_F_TSO;\n\n\tif ((request & NETIF_F_TSO6) && !(lio->dev_capability & NETIF_F_TSO6))\n\t\trequest &= ~NETIF_F_TSO6;\n\n\tif ((request & NETIF_F_LRO) && !(lio->dev_capability & NETIF_F_LRO))\n\t\trequest &= ~NETIF_F_LRO;\n\n\t \n\tif (!(request & NETIF_F_RXCSUM) && (netdev->features & NETIF_F_LRO) &&\n\t    (lio->dev_capability & NETIF_F_LRO))\n\t\trequest &= ~NETIF_F_LRO;\n\n\treturn request;\n}\n\n \nstatic int liquidio_set_features(struct net_device *netdev,\n\t\t\t\t netdev_features_t features)\n{\n\tstruct lio *lio = netdev_priv(netdev);\n\n\tif (!((netdev->features ^ features) & NETIF_F_LRO))\n\t\treturn 0;\n\n\tif ((features & NETIF_F_LRO) && (lio->dev_capability & NETIF_F_LRO))\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_LRO_ENABLE,\n\t\t\t\t     OCTNIC_LROIPV4 | OCTNIC_LROIPV6);\n\telse if (!(features & NETIF_F_LRO) &&\n\t\t (lio->dev_capability & NETIF_F_LRO))\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_LRO_DISABLE,\n\t\t\t\t     OCTNIC_LROIPV4 | OCTNIC_LROIPV6);\n\tif (!(netdev->features & NETIF_F_RXCSUM) &&\n\t    (lio->enc_dev_capability & NETIF_F_RXCSUM) &&\n\t    (features & NETIF_F_RXCSUM))\n\t\tliquidio_set_rxcsum_command(netdev, OCTNET_CMD_TNL_RX_CSUM_CTL,\n\t\t\t\t\t    OCTNET_CMD_RXCSUM_ENABLE);\n\telse if ((netdev->features & NETIF_F_RXCSUM) &&\n\t\t (lio->enc_dev_capability & NETIF_F_RXCSUM) &&\n\t\t !(features & NETIF_F_RXCSUM))\n\t\tliquidio_set_rxcsum_command(netdev, OCTNET_CMD_TNL_RX_CSUM_CTL,\n\t\t\t\t\t    OCTNET_CMD_RXCSUM_DISABLE);\n\n\treturn 0;\n}\n\nstatic const struct net_device_ops lionetdevops = {\n\t.ndo_open\t\t= liquidio_open,\n\t.ndo_stop\t\t= liquidio_stop,\n\t.ndo_start_xmit\t\t= liquidio_xmit,\n\t.ndo_get_stats64\t= liquidio_get_stats64,\n\t.ndo_set_mac_address\t= liquidio_set_mac,\n\t.ndo_set_rx_mode\t= liquidio_set_mcast_list,\n\t.ndo_tx_timeout\t\t= liquidio_tx_timeout,\n\t.ndo_vlan_rx_add_vid    = liquidio_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid   = liquidio_vlan_rx_kill_vid,\n\t.ndo_change_mtu\t\t= liquidio_change_mtu,\n\t.ndo_eth_ioctl\t\t= liquidio_ioctl,\n\t.ndo_fix_features\t= liquidio_fix_features,\n\t.ndo_set_features\t= liquidio_set_features,\n};\n\nstatic int lio_nic_info(struct octeon_recv_info *recv_info, void *buf)\n{\n\tstruct octeon_device *oct = (struct octeon_device *)buf;\n\tstruct octeon_recv_pkt *recv_pkt = recv_info->recv_pkt;\n\tunion oct_link_status *ls;\n\tint gmxport = 0;\n\tint i;\n\n\tif (recv_pkt->buffer_size[0] != (sizeof(*ls) + OCT_DROQ_INFO_SIZE)) {\n\t\tdev_err(&oct->pci_dev->dev, \"Malformed NIC_INFO, len=%d, ifidx=%d\\n\",\n\t\t\trecv_pkt->buffer_size[0],\n\t\t\trecv_pkt->rh.r_nic_info.gmxport);\n\t\tgoto nic_info_err;\n\t}\n\n\tgmxport = recv_pkt->rh.r_nic_info.gmxport;\n\tls = (union oct_link_status *)(get_rbd(recv_pkt->buffer_ptr[0]) +\n\t\tOCT_DROQ_INFO_SIZE);\n\n\tocteon_swap_8B_data((u64 *)ls, (sizeof(union oct_link_status)) >> 3);\n\n\tfor (i = 0; i < oct->ifcount; i++) {\n\t\tif (oct->props[i].gmxport == gmxport) {\n\t\t\tupdate_link_status(oct->props[i].netdev, ls);\n\t\t\tbreak;\n\t\t}\n\t}\n\nnic_info_err:\n\tfor (i = 0; i < recv_pkt->buffer_count; i++)\n\t\trecv_buffer_free(recv_pkt->buffer_ptr[i]);\n\tocteon_free_recv_info(recv_info);\n\treturn 0;\n}\n\n \nstatic int setup_nic_devices(struct octeon_device *octeon_dev)\n{\n\tint retval, num_iqueues, num_oqueues;\n\tu32 resp_size, data_size;\n\tstruct liquidio_if_cfg_resp *resp;\n\tstruct octeon_soft_command *sc;\n\tunion oct_nic_if_cfg if_cfg;\n\tstruct octdev_props *props;\n\tstruct net_device *netdev;\n\tstruct lio_version *vdata;\n\tstruct lio *lio = NULL;\n\tu8 mac[ETH_ALEN], i, j;\n\tu32 ifidx_or_pfnum;\n\n\tifidx_or_pfnum = octeon_dev->pf_num;\n\n\t \n\tocteon_register_dispatch_fn(octeon_dev, OPCODE_NIC, OPCODE_NIC_INFO,\n\t\t\t\t    lio_nic_info, octeon_dev);\n\n\t \n\tocteon_register_reqtype_free_fn(octeon_dev, REQTYPE_NORESP_NET,\n\t\t\t\t\tfree_netbuf);\n\n\tocteon_register_reqtype_free_fn(octeon_dev, REQTYPE_NORESP_NET_SG,\n\t\t\t\t\tfree_netsgbuf);\n\n\tocteon_register_reqtype_free_fn(octeon_dev, REQTYPE_RESP_NET_SG,\n\t\t\t\t\tfree_netsgbuf_with_resp);\n\n\tfor (i = 0; i < octeon_dev->ifcount; i++) {\n\t\tresp_size = sizeof(struct liquidio_if_cfg_resp);\n\t\tdata_size = sizeof(struct lio_version);\n\t\tsc = (struct octeon_soft_command *)\n\t\t\tocteon_alloc_soft_command(octeon_dev, data_size,\n\t\t\t\t\t\t  resp_size, 0);\n\t\tresp = (struct liquidio_if_cfg_resp *)sc->virtrptr;\n\t\tvdata = (struct lio_version *)sc->virtdptr;\n\n\t\t*((u64 *)vdata) = 0;\n\t\tvdata->major = cpu_to_be16(LIQUIDIO_BASE_MAJOR_VERSION);\n\t\tvdata->minor = cpu_to_be16(LIQUIDIO_BASE_MINOR_VERSION);\n\t\tvdata->micro = cpu_to_be16(LIQUIDIO_BASE_MICRO_VERSION);\n\n\t\tif_cfg.u64 = 0;\n\n\t\tif_cfg.s.num_iqueues = octeon_dev->sriov_info.rings_per_vf;\n\t\tif_cfg.s.num_oqueues = octeon_dev->sriov_info.rings_per_vf;\n\t\tif_cfg.s.base_queue = 0;\n\n\t\tsc->iq_no = 0;\n\n\t\tocteon_prepare_soft_command(octeon_dev, sc, OPCODE_NIC,\n\t\t\t\t\t    OPCODE_NIC_IF_CFG, 0, if_cfg.u64,\n\t\t\t\t\t    0);\n\n\t\tinit_completion(&sc->complete);\n\t\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\t\tretval = octeon_send_soft_command(octeon_dev, sc);\n\t\tif (retval == IQ_SEND_FAILED) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"iq/oq config failed status: %x\\n\", retval);\n\t\t\t \n\t\t\tocteon_free_soft_command(octeon_dev, sc);\n\t\t\treturn(-EIO);\n\t\t}\n\n\t\t \n\t\tretval = wait_for_sc_completion_timeout(octeon_dev, sc, 0);\n\t\tif (retval)\n\t\t\treturn retval;\n\n\t\tretval = resp->status;\n\t\tif (retval) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"iq/oq config failed, retval = %d\\n\", retval);\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tsnprintf(octeon_dev->fw_info.liquidio_firmware_version,\n\t\t\t 32, \"%s\",\n\t\t\t resp->cfg_info.liquidio_firmware_version);\n\n\t\tocteon_swap_8B_data((u64 *)(&resp->cfg_info),\n\t\t\t\t    (sizeof(struct liquidio_if_cfg_info)) >> 3);\n\n\t\tnum_iqueues = hweight64(resp->cfg_info.iqmask);\n\t\tnum_oqueues = hweight64(resp->cfg_info.oqmask);\n\n\t\tif (!(num_iqueues) || !(num_oqueues)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"Got bad iqueues (%016llx) or oqueues (%016llx) from firmware.\\n\",\n\t\t\t\tresp->cfg_info.iqmask, resp->cfg_info.oqmask);\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_done;\n\t\t}\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"interface %d, iqmask %016llx, oqmask %016llx, numiqueues %d, numoqueues %d\\n\",\n\t\t\ti, resp->cfg_info.iqmask, resp->cfg_info.oqmask,\n\t\t\tnum_iqueues, num_oqueues);\n\n\t\tnetdev = alloc_etherdev_mq(LIO_SIZE, num_iqueues);\n\n\t\tif (!netdev) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Device allocation failed\\n\");\n\t\t\tWRITE_ONCE(sc->caller_is_done, true);\n\t\t\tgoto setup_nic_dev_done;\n\t\t}\n\n\t\tSET_NETDEV_DEV(netdev, &octeon_dev->pci_dev->dev);\n\n\t\t \n\t\tnetdev->netdev_ops = &lionetdevops;\n\n\t\tlio = GET_LIO(netdev);\n\n\t\tmemset(lio, 0, sizeof(struct lio));\n\n\t\tlio->ifidx = ifidx_or_pfnum;\n\n\t\tprops = &octeon_dev->props[i];\n\t\tprops->gmxport = resp->cfg_info.linfo.gmxport;\n\t\tprops->netdev = netdev;\n\n\t\tlio->linfo.num_rxpciq = num_oqueues;\n\t\tlio->linfo.num_txpciq = num_iqueues;\n\n\t\tfor (j = 0; j < num_oqueues; j++) {\n\t\t\tlio->linfo.rxpciq[j].u64 =\n\t\t\t    resp->cfg_info.linfo.rxpciq[j].u64;\n\t\t}\n\t\tfor (j = 0; j < num_iqueues; j++) {\n\t\t\tlio->linfo.txpciq[j].u64 =\n\t\t\t    resp->cfg_info.linfo.txpciq[j].u64;\n\t\t}\n\n\t\tlio->linfo.hw_addr = resp->cfg_info.linfo.hw_addr;\n\t\tlio->linfo.gmxport = resp->cfg_info.linfo.gmxport;\n\t\tlio->linfo.link.u64 = resp->cfg_info.linfo.link.u64;\n\t\tlio->linfo.macaddr_is_admin_asgnd =\n\t\t\tresp->cfg_info.linfo.macaddr_is_admin_asgnd;\n\t\tlio->linfo.macaddr_spoofchk =\n\t\t\tresp->cfg_info.linfo.macaddr_spoofchk;\n\n\t\tlio->msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);\n\n\t\tlio->dev_capability = NETIF_F_HIGHDMA\n\t\t\t\t      | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM\n\t\t\t\t      | NETIF_F_SG | NETIF_F_RXCSUM\n\t\t\t\t      | NETIF_F_TSO | NETIF_F_TSO6\n\t\t\t\t      | NETIF_F_GRO\n\t\t\t\t      | NETIF_F_LRO;\n\t\tnetif_set_tso_max_size(netdev, OCTNIC_GSO_MAX_SIZE);\n\n\t\t \n\t\tlio->enc_dev_capability = NETIF_F_IP_CSUM\n\t\t\t\t\t  | NETIF_F_IPV6_CSUM\n\t\t\t\t\t  | NETIF_F_GSO_UDP_TUNNEL\n\t\t\t\t\t  | NETIF_F_HW_CSUM | NETIF_F_SG\n\t\t\t\t\t  | NETIF_F_RXCSUM\n\t\t\t\t\t  | NETIF_F_TSO | NETIF_F_TSO6\n\t\t\t\t\t  | NETIF_F_LRO;\n\n\t\tnetdev->hw_enc_features =\n\t\t    (lio->enc_dev_capability & ~NETIF_F_LRO);\n\t\tnetdev->udp_tunnel_nic_info = &liquidio_udp_tunnels;\n\n\t\tnetdev->vlan_features = lio->dev_capability;\n\t\t \n\t\tlio->dev_capability |= NETIF_F_HW_VLAN_CTAG_FILTER |\n\t\t\t\t       NETIF_F_HW_VLAN_CTAG_RX |\n\t\t\t\t       NETIF_F_HW_VLAN_CTAG_TX;\n\n\t\tnetdev->features = (lio->dev_capability & ~NETIF_F_LRO);\n\n\t\tnetdev->hw_features = lio->dev_capability;\n\t\tnetdev->hw_features &= ~NETIF_F_HW_VLAN_CTAG_RX;\n\n\t\t \n\t\tnetdev->min_mtu = LIO_MIN_MTU_SIZE;\n\t\tnetdev->max_mtu = LIO_MAX_MTU_SIZE;\n\n\t\tWRITE_ONCE(sc->caller_is_done, true);\n\n\t\t \n\t\tlio->oct_dev = octeon_dev;\n\t\tlio->octprops = props;\n\t\tlio->netdev = netdev;\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"if%d gmx: %d hw_addr: 0x%llx\\n\", i,\n\t\t\tlio->linfo.gmxport, CVM_CAST64(lio->linfo.hw_addr));\n\n\t\t \n\t\tocteon_swap_8B_data(&lio->linfo.hw_addr, 1);\n\t\tfor (j = 0; j < ETH_ALEN; j++)\n\t\t\tmac[j] = *((u8 *)(((u8 *)&lio->linfo.hw_addr) + 2 + j));\n\n\t\t \n\t\teth_hw_addr_set(netdev, mac);\n\n\t\tif (liquidio_setup_io_queues(octeon_dev, i,\n\t\t\t\t\t     lio->linfo.num_txpciq,\n\t\t\t\t\t     lio->linfo.num_rxpciq)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"I/O queues creation failed\\n\");\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\tifstate_set(lio, LIO_IFSTATE_DROQ_OPS);\n\n\t\t \n\t\tocteon_dev->fn_list.enable_interrupt(octeon_dev,\n\t\t\t\t\t\t     OCTEON_ALL_INTR);\n\n\t\t \n\t\tlio->txq = lio->linfo.txpciq[0].s.q_no;\n\t\tlio->rxq = lio->linfo.rxpciq[0].s.q_no;\n\n\t\tlio->tx_qsize = octeon_get_tx_qsize(octeon_dev, lio->txq);\n\t\tlio->rx_qsize = octeon_get_rx_qsize(octeon_dev, lio->rxq);\n\n\t\tif (lio_setup_glists(octeon_dev, lio, num_iqueues)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\t\"Gather list allocation failed\\n\");\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\t \n\t\tliquidio_set_ethtool_ops(netdev);\n\t\tif (lio->oct_dev->chip_id == OCTEON_CN23XX_VF_VID)\n\t\t\tocteon_dev->priv_flags = OCT_PRIV_FLAG_DEFAULT;\n\t\telse\n\t\t\tocteon_dev->priv_flags = 0x0;\n\n\t\tif (netdev->features & NETIF_F_LRO)\n\t\t\tliquidio_set_feature(netdev, OCTNET_CMD_LRO_ENABLE,\n\t\t\t\t\t     OCTNIC_LROIPV4 | OCTNIC_LROIPV6);\n\n\t\tif (setup_link_status_change_wq(netdev))\n\t\t\tgoto setup_nic_dev_free;\n\n\t\tif (setup_rx_oom_poll_fn(netdev))\n\t\t\tgoto setup_nic_dev_free;\n\n\t\t \n\t\tif (register_netdev(netdev)) {\n\t\t\tdev_err(&octeon_dev->pci_dev->dev, \"Device registration failed\\n\");\n\t\t\tgoto setup_nic_dev_free;\n\t\t}\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"Setup NIC ifidx:%d mac:%02x%02x%02x%02x%02x%02x\\n\",\n\t\t\ti, mac[0], mac[1], mac[2], mac[3], mac[4], mac[5]);\n\t\tnetif_carrier_off(netdev);\n\t\tlio->link_changes++;\n\n\t\tifstate_set(lio, LIO_IFSTATE_REGISTERED);\n\n\t\t \n\t\tliquidio_set_rxcsum_command(netdev, OCTNET_CMD_TNL_RX_CSUM_CTL,\n\t\t\t\t\t    OCTNET_CMD_RXCSUM_ENABLE);\n\t\tliquidio_set_feature(netdev, OCTNET_CMD_TNL_TX_CSUM_CTL,\n\t\t\t\t     OCTNET_CMD_TXCSUM_ENABLE);\n\n\t\tdev_dbg(&octeon_dev->pci_dev->dev,\n\t\t\t\"NIC ifidx:%d Setup successful\\n\", i);\n\n\t\tocteon_dev->no_speed_setting = 1;\n\t}\n\n\treturn 0;\n\nsetup_nic_dev_free:\n\n\twhile (i--) {\n\t\tdev_err(&octeon_dev->pci_dev->dev,\n\t\t\t\"NIC ifidx:%d Setup failed\\n\", i);\n\t\tliquidio_destroy_nic_device(octeon_dev, i);\n\t}\n\nsetup_nic_dev_done:\n\n\treturn -ENODEV;\n}\n\n \nstatic int liquidio_init_nic_module(struct octeon_device *oct)\n{\n\tint num_nic_ports = 1;\n\tint i, retval = 0;\n\n\tdev_dbg(&oct->pci_dev->dev, \"Initializing network interfaces\\n\");\n\n\t \n\toct->ifcount = num_nic_ports;\n\tmemset(oct->props, 0,\n\t       sizeof(struct octdev_props) * num_nic_ports);\n\n\tfor (i = 0; i < MAX_OCTEON_LINKS; i++)\n\t\toct->props[i].gmxport = -1;\n\n\tretval = setup_nic_devices(oct);\n\tif (retval) {\n\t\tdev_err(&oct->pci_dev->dev, \"Setup NIC devices failed\\n\");\n\t\tgoto octnet_init_failure;\n\t}\n\n\tdev_dbg(&oct->pci_dev->dev, \"Network interfaces ready\\n\");\n\n\treturn retval;\n\noctnet_init_failure:\n\n\toct->ifcount = 0;\n\n\treturn retval;\n}\n\n \nstatic int octeon_device_init(struct octeon_device *oct)\n{\n\tu32 rev_id;\n\tint j;\n\n\tatomic_set(&oct->status, OCT_DEV_BEGIN_STATE);\n\n\t \n\tif (octeon_pci_os_setup(oct))\n\t\treturn 1;\n\tatomic_set(&oct->status, OCT_DEV_PCI_ENABLE_DONE);\n\n\toct->chip_id = OCTEON_CN23XX_VF_VID;\n\tpci_read_config_dword(oct->pci_dev, 8, &rev_id);\n\toct->rev_id = rev_id & 0xff;\n\n\tif (cn23xx_setup_octeon_vf_device(oct))\n\t\treturn 1;\n\n\tatomic_set(&oct->status, OCT_DEV_PCI_MAP_DONE);\n\n\toct->app_mode = CVM_DRV_NIC_APP;\n\n\t \n\tif (octeon_init_dispatch_list(oct))\n\t\treturn 1;\n\n\tatomic_set(&oct->status, OCT_DEV_DISPATCH_INIT_DONE);\n\n\tif (octeon_set_io_queues_off(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"setting io queues off failed\\n\");\n\t\treturn 1;\n\t}\n\n\tif (oct->fn_list.setup_device_regs(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"device registers configuration failed\\n\");\n\t\treturn 1;\n\t}\n\n\t \n\tif (octeon_setup_sc_buffer_pool(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"sc buffer pool allocation failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&oct->status, OCT_DEV_SC_BUFF_POOL_INIT_DONE);\n\n\t \n\tif (octeon_setup_instr_queues(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"instruction queue initialization failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&oct->status, OCT_DEV_INSTR_QUEUE_INIT_DONE);\n\n\t \n\tif (octeon_setup_response_list(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"Response list allocation failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&oct->status, OCT_DEV_RESP_LIST_INIT_DONE);\n\n\tif (octeon_setup_output_queues(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"Output queue initialization failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&oct->status, OCT_DEV_DROQ_INIT_DONE);\n\n\tif (oct->fn_list.setup_mbox(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"Mailbox setup failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&oct->status, OCT_DEV_MBOX_SETUP_DONE);\n\n\tif (octeon_allocate_ioq_vector(oct, oct->sriov_info.rings_per_vf)) {\n\t\tdev_err(&oct->pci_dev->dev, \"ioq vector allocation failed\\n\");\n\t\treturn 1;\n\t}\n\tatomic_set(&oct->status, OCT_DEV_MSIX_ALLOC_VECTOR_DONE);\n\n\tdev_info(&oct->pci_dev->dev, \"OCTEON_CN23XX VF: %d ioqs\\n\",\n\t\t oct->sriov_info.rings_per_vf);\n\n\t \n\tif (octeon_setup_interrupt(oct, oct->sriov_info.rings_per_vf))\n\t\treturn 1;\n\n\tatomic_set(&oct->status, OCT_DEV_INTR_SET_DONE);\n\n\t \n\n\t \n\toct->fn_list.enable_interrupt(oct, OCTEON_ALL_INTR);\n\n\tif (cn23xx_octeon_pfvf_handshake(oct))\n\t\treturn 1;\n\n\t \n\n\t \n\toct->fn_list.enable_interrupt(oct, OCTEON_ALL_INTR);\n\t \n\n\t \n\tif (oct->fn_list.enable_io_queues(oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"enabling io queues failed\\n\");\n\t\treturn 1;\n\t}\n\n\tatomic_set(&oct->status, OCT_DEV_IO_QUEUES_DONE);\n\n\tatomic_set(&oct->status, OCT_DEV_HOST_OK);\n\n\t \n\tfor (j = 0; j < oct->num_oqs; j++)\n\t\twritel(oct->droq[j]->max_count, oct->droq[j]->pkts_credit_reg);\n\n\t \n\n\tatomic_set(&oct->status, OCT_DEV_CORE_OK);\n\n\tatomic_set(&oct->status, OCT_DEV_RUNNING);\n\n\tif (liquidio_init_nic_module(oct))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic int __init liquidio_vf_init(void)\n{\n\tocteon_init_device_list(0);\n\treturn pci_register_driver(&liquidio_vf_pci_driver);\n}\n\nstatic void __exit liquidio_vf_exit(void)\n{\n\tpci_unregister_driver(&liquidio_vf_pci_driver);\n\n\tpr_info(\"LiquidIO_VF network module is now unloaded\\n\");\n}\n\nmodule_init(liquidio_vf_init);\nmodule_exit(liquidio_vf_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}