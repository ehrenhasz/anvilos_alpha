{
  "module_name": "lio_vf_rep.c",
  "hash_id": "bd247d9e8c79070bc89863e2c9ea74b02725967f5d535f4c16d4927c351af933",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/cavium/liquidio/lio_vf_rep.c",
  "human_readable_source": " \n#include <linux/pci.h>\n#include <linux/if_vlan.h>\n#include \"liquidio_common.h\"\n#include \"octeon_droq.h\"\n#include \"octeon_iq.h\"\n#include \"response_manager.h\"\n#include \"octeon_device.h\"\n#include \"octeon_nic.h\"\n#include \"octeon_main.h\"\n#include \"octeon_network.h\"\n#include \"lio_vf_rep.h\"\n\nstatic int lio_vf_rep_open(struct net_device *ndev);\nstatic int lio_vf_rep_stop(struct net_device *ndev);\nstatic netdev_tx_t lio_vf_rep_pkt_xmit(struct sk_buff *skb,\n\t\t\t\t       struct net_device *ndev);\nstatic void lio_vf_rep_tx_timeout(struct net_device *netdev, unsigned int txqueue);\nstatic int lio_vf_rep_phys_port_name(struct net_device *dev,\n\t\t\t\t     char *buf, size_t len);\nstatic void lio_vf_rep_get_stats64(struct net_device *dev,\n\t\t\t\t   struct rtnl_link_stats64 *stats64);\nstatic int lio_vf_rep_change_mtu(struct net_device *ndev, int new_mtu);\nstatic int lio_vf_get_port_parent_id(struct net_device *dev,\n\t\t\t\t     struct netdev_phys_item_id *ppid);\n\nstatic const struct net_device_ops lio_vf_rep_ndev_ops = {\n\t.ndo_open = lio_vf_rep_open,\n\t.ndo_stop = lio_vf_rep_stop,\n\t.ndo_start_xmit = lio_vf_rep_pkt_xmit,\n\t.ndo_tx_timeout = lio_vf_rep_tx_timeout,\n\t.ndo_get_phys_port_name = lio_vf_rep_phys_port_name,\n\t.ndo_get_stats64 = lio_vf_rep_get_stats64,\n\t.ndo_change_mtu = lio_vf_rep_change_mtu,\n\t.ndo_get_port_parent_id = lio_vf_get_port_parent_id,\n};\n\nstatic int\nlio_vf_rep_send_soft_command(struct octeon_device *oct,\n\t\t\t     void *req, int req_size,\n\t\t\t     void *resp, int resp_size)\n{\n\tint tot_resp_size = sizeof(struct lio_vf_rep_resp) + resp_size;\n\tstruct octeon_soft_command *sc = NULL;\n\tstruct lio_vf_rep_resp *rep_resp;\n\tvoid *sc_req;\n\tint err;\n\n\tsc = (struct octeon_soft_command *)\n\t\tocteon_alloc_soft_command(oct, req_size,\n\t\t\t\t\t  tot_resp_size, 0);\n\tif (!sc)\n\t\treturn -ENOMEM;\n\n\tinit_completion(&sc->complete);\n\tsc->sc_status = OCTEON_REQUEST_PENDING;\n\n\tsc_req = (struct lio_vf_rep_req *)sc->virtdptr;\n\tmemcpy(sc_req, req, req_size);\n\n\trep_resp = (struct lio_vf_rep_resp *)sc->virtrptr;\n\tmemset(rep_resp, 0, tot_resp_size);\n\tWRITE_ONCE(rep_resp->status, 1);\n\n\tsc->iq_no = 0;\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC,\n\t\t\t\t    OPCODE_NIC_VF_REP_CMD, 0, 0, 0);\n\n\terr = octeon_send_soft_command(oct, sc);\n\tif (err == IQ_SEND_FAILED)\n\t\tgoto free_buff;\n\n\terr = wait_for_sc_completion_timeout(oct, sc, 0);\n\tif (err)\n\t\treturn err;\n\n\terr = READ_ONCE(rep_resp->status) ? -EBUSY : 0;\n\tif (err)\n\t\tdev_err(&oct->pci_dev->dev, \"VF rep send config failed\\n\");\n\telse if (resp)\n\t\tmemcpy(resp, (rep_resp + 1), resp_size);\n\n\tWRITE_ONCE(sc->caller_is_done, true);\n\treturn err;\n\nfree_buff:\n\tocteon_free_soft_command(oct, sc);\n\n\treturn err;\n}\n\nstatic int\nlio_vf_rep_open(struct net_device *ndev)\n{\n\tstruct lio_vf_rep_desc *vf_rep = netdev_priv(ndev);\n\tstruct lio_vf_rep_req rep_cfg;\n\tstruct octeon_device *oct;\n\tint ret;\n\n\toct = vf_rep->oct;\n\n\tmemset(&rep_cfg, 0, sizeof(rep_cfg));\n\trep_cfg.req_type = LIO_VF_REP_REQ_STATE;\n\trep_cfg.ifidx = vf_rep->ifidx;\n\trep_cfg.rep_state.state = LIO_VF_REP_STATE_UP;\n\n\tret = lio_vf_rep_send_soft_command(oct, &rep_cfg,\n\t\t\t\t\t   sizeof(rep_cfg), NULL, 0);\n\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"VF_REP open failed with err %d\\n\", ret);\n\t\treturn -EIO;\n\t}\n\n\tatomic_set(&vf_rep->ifstate, (atomic_read(&vf_rep->ifstate) |\n\t\t\t\t      LIO_IFSTATE_RUNNING));\n\n\tnetif_carrier_on(ndev);\n\tnetif_start_queue(ndev);\n\n\treturn 0;\n}\n\nstatic int\nlio_vf_rep_stop(struct net_device *ndev)\n{\n\tstruct lio_vf_rep_desc *vf_rep = netdev_priv(ndev);\n\tstruct lio_vf_rep_req rep_cfg;\n\tstruct octeon_device *oct;\n\tint ret;\n\n\toct = vf_rep->oct;\n\n\tmemset(&rep_cfg, 0, sizeof(rep_cfg));\n\trep_cfg.req_type = LIO_VF_REP_REQ_STATE;\n\trep_cfg.ifidx = vf_rep->ifidx;\n\trep_cfg.rep_state.state = LIO_VF_REP_STATE_DOWN;\n\n\tret = lio_vf_rep_send_soft_command(oct, &rep_cfg,\n\t\t\t\t\t   sizeof(rep_cfg), NULL, 0);\n\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"VF_REP dev stop failed with err %d\\n\", ret);\n\t\treturn -EIO;\n\t}\n\n\tatomic_set(&vf_rep->ifstate, (atomic_read(&vf_rep->ifstate) &\n\t\t\t\t      ~LIO_IFSTATE_RUNNING));\n\n\tnetif_tx_disable(ndev);\n\tnetif_carrier_off(ndev);\n\n\treturn 0;\n}\n\nstatic void\nlio_vf_rep_tx_timeout(struct net_device *ndev, unsigned int txqueue)\n{\n\tnetif_trans_update(ndev);\n\n\tnetif_wake_queue(ndev);\n}\n\nstatic void\nlio_vf_rep_get_stats64(struct net_device *dev,\n\t\t       struct rtnl_link_stats64 *stats64)\n{\n\tstruct lio_vf_rep_desc *vf_rep = netdev_priv(dev);\n\n\t \n\tstats64->tx_packets = vf_rep->stats.rx_packets;\n\tstats64->tx_bytes   = vf_rep->stats.rx_bytes;\n\tstats64->tx_dropped = vf_rep->stats.rx_dropped;\n\n\tstats64->rx_packets = vf_rep->stats.tx_packets;\n\tstats64->rx_bytes   = vf_rep->stats.tx_bytes;\n\tstats64->rx_dropped = vf_rep->stats.tx_dropped;\n}\n\nstatic int\nlio_vf_rep_change_mtu(struct net_device *ndev, int new_mtu)\n{\n\tstruct lio_vf_rep_desc *vf_rep = netdev_priv(ndev);\n\tstruct lio_vf_rep_req rep_cfg;\n\tstruct octeon_device *oct;\n\tint ret;\n\n\toct = vf_rep->oct;\n\n\tmemset(&rep_cfg, 0, sizeof(rep_cfg));\n\trep_cfg.req_type = LIO_VF_REP_REQ_MTU;\n\trep_cfg.ifidx = vf_rep->ifidx;\n\trep_cfg.rep_mtu.mtu = cpu_to_be32(new_mtu);\n\n\tret = lio_vf_rep_send_soft_command(oct, &rep_cfg,\n\t\t\t\t\t   sizeof(rep_cfg), NULL, 0);\n\tif (ret) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Change MTU failed with err %d\\n\", ret);\n\t\treturn -EIO;\n\t}\n\n\tndev->mtu = new_mtu;\n\n\treturn 0;\n}\n\nstatic int\nlio_vf_rep_phys_port_name(struct net_device *dev,\n\t\t\t  char *buf, size_t len)\n{\n\tstruct lio_vf_rep_desc *vf_rep = netdev_priv(dev);\n\tstruct octeon_device *oct = vf_rep->oct;\n\tint ret;\n\n\tret = snprintf(buf, len, \"pf%dvf%d\", oct->pf_num,\n\t\t       vf_rep->ifidx - oct->pf_num * 64 - 1);\n\tif (ret >= len)\n\t\treturn -EOPNOTSUPP;\n\n\treturn 0;\n}\n\nstatic struct net_device *\nlio_vf_rep_get_ndev(struct octeon_device *oct, int ifidx)\n{\n\tint vf_id, max_vfs = CN23XX_MAX_VFS_PER_PF + 1;\n\tint vfid_mask = max_vfs - 1;\n\n\tif (ifidx <= oct->pf_num * max_vfs ||\n\t    ifidx >= oct->pf_num * max_vfs + max_vfs)\n\t\treturn NULL;\n\n\t \n\tvf_id = (ifidx & vfid_mask) - 1;\n\n\treturn oct->vf_rep_list.ndev[vf_id];\n}\n\nstatic void\nlio_vf_rep_copy_packet(struct octeon_device *oct,\n\t\t       struct sk_buff *skb,\n\t\t       int len)\n{\n\tif (likely(len > MIN_SKB_SIZE)) {\n\t\tstruct octeon_skb_page_info *pg_info;\n\t\tunsigned char *va;\n\n\t\tpg_info = ((struct octeon_skb_page_info *)(skb->cb));\n\t\tif (pg_info->page) {\n\t\t\tva = page_address(pg_info->page) +\n\t\t\t\tpg_info->page_offset;\n\t\t\tmemcpy(skb->data, va, MIN_SKB_SIZE);\n\t\t\tskb_put(skb, MIN_SKB_SIZE);\n\t\t}\n\n\t\tskb_add_rx_frag(skb, skb_shinfo(skb)->nr_frags,\n\t\t\t\tpg_info->page,\n\t\t\t\tpg_info->page_offset + MIN_SKB_SIZE,\n\t\t\t\tlen - MIN_SKB_SIZE,\n\t\t\t\tLIO_RXBUFFER_SZ);\n\t} else {\n\t\tstruct octeon_skb_page_info *pg_info =\n\t\t\t((struct octeon_skb_page_info *)(skb->cb));\n\n\t\tskb_copy_to_linear_data(skb, page_address(pg_info->page) +\n\t\t\t\t\tpg_info->page_offset, len);\n\t\tskb_put(skb, len);\n\t\tput_page(pg_info->page);\n\t}\n}\n\nstatic int\nlio_vf_rep_pkt_recv(struct octeon_recv_info *recv_info, void *buf)\n{\n\tstruct octeon_recv_pkt *recv_pkt = recv_info->recv_pkt;\n\tstruct lio_vf_rep_desc *vf_rep;\n\tstruct net_device *vf_ndev;\n\tstruct octeon_device *oct;\n\tunion octeon_rh *rh;\n\tstruct sk_buff *skb;\n\tint i, ifidx;\n\n\toct = lio_get_device(recv_pkt->octeon_id);\n\tif (!oct)\n\t\tgoto free_buffers;\n\n\tskb = recv_pkt->buffer_ptr[0];\n\trh = &recv_pkt->rh;\n\tifidx = rh->r.ossp;\n\n\tvf_ndev = lio_vf_rep_get_ndev(oct, ifidx);\n\tif (!vf_ndev)\n\t\tgoto free_buffers;\n\n\tvf_rep = netdev_priv(vf_ndev);\n\tif (!(atomic_read(&vf_rep->ifstate) & LIO_IFSTATE_RUNNING) ||\n\t    recv_pkt->buffer_count > 1)\n\t\tgoto free_buffers;\n\n\tskb->dev = vf_ndev;\n\n\t \n\tlio_vf_rep_copy_packet(oct, skb, recv_pkt->buffer_size[0]);\n\n\tskb_pull(skb, rh->r_dh.len * BYTES_PER_DHLEN_UNIT);\n\tskb->protocol = eth_type_trans(skb, skb->dev);\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\tnetif_rx(skb);\n\n\tocteon_free_recv_info(recv_info);\n\n\treturn 0;\n\nfree_buffers:\n\tfor (i = 0; i < recv_pkt->buffer_count; i++)\n\t\trecv_buffer_free(recv_pkt->buffer_ptr[i]);\n\n\tocteon_free_recv_info(recv_info);\n\n\treturn 0;\n}\n\nstatic void\nlio_vf_rep_packet_sent_callback(struct octeon_device *oct,\n\t\t\t\tu32 status, void *buf)\n{\n\tstruct octeon_soft_command *sc = (struct octeon_soft_command *)buf;\n\tstruct sk_buff *skb = sc->ctxptr;\n\tstruct net_device *ndev = skb->dev;\n\tu32 iq_no;\n\n\tdma_unmap_single(&oct->pci_dev->dev, sc->dmadptr,\n\t\t\t sc->datasize, DMA_TO_DEVICE);\n\tdev_kfree_skb_any(skb);\n\tiq_no = sc->iq_no;\n\tocteon_free_soft_command(oct, sc);\n\n\tif (octnet_iq_is_full(oct, iq_no))\n\t\treturn;\n\n\tif (netif_queue_stopped(ndev))\n\t\tnetif_wake_queue(ndev);\n}\n\nstatic netdev_tx_t\nlio_vf_rep_pkt_xmit(struct sk_buff *skb, struct net_device *ndev)\n{\n\tstruct lio_vf_rep_desc *vf_rep = netdev_priv(ndev);\n\tstruct net_device *parent_ndev = vf_rep->parent_ndev;\n\tstruct octeon_device *oct = vf_rep->oct;\n\tstruct octeon_instr_pki_ih3 *pki_ih3;\n\tstruct octeon_soft_command *sc;\n\tstruct lio *parent_lio;\n\tint status;\n\n\tparent_lio = GET_LIO(parent_ndev);\n\n\tif (!(atomic_read(&vf_rep->ifstate) & LIO_IFSTATE_RUNNING) ||\n\t    skb->len <= 0)\n\t\tgoto xmit_failed;\n\n\tif (octnet_iq_is_full(vf_rep->oct, parent_lio->txq)) {\n\t\tdev_err(&oct->pci_dev->dev, \"VF rep: Device IQ full\\n\");\n\t\tnetif_stop_queue(ndev);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tsc = (struct octeon_soft_command *)\n\t\tocteon_alloc_soft_command(oct, 0, 16, 0);\n\tif (!sc) {\n\t\tdev_err(&oct->pci_dev->dev, \"VF rep: Soft command alloc failed\\n\");\n\t\tgoto xmit_failed;\n\t}\n\n\t \n\tif (skb_shinfo(skb)->nr_frags != 0) {\n\t\tdev_err(&oct->pci_dev->dev, \"VF rep: nr_frags != 0. Dropping packet\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t\tgoto xmit_failed;\n\t}\n\n\tsc->dmadptr = dma_map_single(&oct->pci_dev->dev,\n\t\t\t\t     skb->data, skb->len, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&oct->pci_dev->dev, sc->dmadptr)) {\n\t\tdev_err(&oct->pci_dev->dev, \"VF rep: DMA mapping failed\\n\");\n\t\tocteon_free_soft_command(oct, sc);\n\t\tgoto xmit_failed;\n\t}\n\n\tsc->virtdptr = skb->data;\n\tsc->datasize = skb->len;\n\tsc->ctxptr = skb;\n\tsc->iq_no = parent_lio->txq;\n\n\tocteon_prepare_soft_command(oct, sc, OPCODE_NIC, OPCODE_NIC_VF_REP_PKT,\n\t\t\t\t    vf_rep->ifidx, 0, 0);\n\tpki_ih3 = (struct octeon_instr_pki_ih3 *)&sc->cmd.cmd3.pki_ih3;\n\tpki_ih3->tagtype = ORDERED_TAG;\n\n\tsc->callback = lio_vf_rep_packet_sent_callback;\n\tsc->callback_arg = sc;\n\n\tstatus = octeon_send_soft_command(oct, sc);\n\tif (status == IQ_SEND_FAILED) {\n\t\tdma_unmap_single(&oct->pci_dev->dev, sc->dmadptr,\n\t\t\t\t sc->datasize, DMA_TO_DEVICE);\n\t\tocteon_free_soft_command(oct, sc);\n\t\tgoto xmit_failed;\n\t}\n\n\tif (status == IQ_SEND_STOP)\n\t\tnetif_stop_queue(ndev);\n\n\tnetif_trans_update(ndev);\n\n\treturn NETDEV_TX_OK;\n\nxmit_failed:\n\tdev_kfree_skb_any(skb);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic int lio_vf_get_port_parent_id(struct net_device *dev,\n\t\t\t\t     struct netdev_phys_item_id *ppid)\n{\n\tstruct lio_vf_rep_desc *vf_rep = netdev_priv(dev);\n\tstruct net_device *parent_ndev = vf_rep->parent_ndev;\n\tstruct lio *lio = GET_LIO(parent_ndev);\n\n\tppid->id_len = ETH_ALEN;\n\tether_addr_copy(ppid->id, (void *)&lio->linfo.hw_addr + 2);\n\n\treturn 0;\n}\n\nstatic void\nlio_vf_rep_fetch_stats(struct work_struct *work)\n{\n\tstruct cavium_wk *wk = (struct cavium_wk *)work;\n\tstruct lio_vf_rep_desc *vf_rep = wk->ctxptr;\n\tstruct lio_vf_rep_stats stats;\n\tstruct lio_vf_rep_req rep_cfg;\n\tstruct octeon_device *oct;\n\tint ret;\n\n\toct = vf_rep->oct;\n\n\tmemset(&rep_cfg, 0, sizeof(rep_cfg));\n\trep_cfg.req_type = LIO_VF_REP_REQ_STATS;\n\trep_cfg.ifidx = vf_rep->ifidx;\n\n\tret = lio_vf_rep_send_soft_command(oct, &rep_cfg, sizeof(rep_cfg),\n\t\t\t\t\t   &stats, sizeof(stats));\n\n\tif (!ret) {\n\t\tocteon_swap_8B_data((u64 *)&stats, (sizeof(stats) >> 3));\n\t\tmemcpy(&vf_rep->stats, &stats, sizeof(stats));\n\t}\n\n\tschedule_delayed_work(&vf_rep->stats_wk.work,\n\t\t\t      msecs_to_jiffies(LIO_VF_REP_STATS_POLL_TIME_MS));\n}\n\nint\nlio_vf_rep_create(struct octeon_device *oct)\n{\n\tstruct lio_vf_rep_desc *vf_rep;\n\tstruct net_device *ndev;\n\tint i, num_vfs;\n\n\tif (oct->eswitch_mode != DEVLINK_ESWITCH_MODE_SWITCHDEV)\n\t\treturn 0;\n\n\tif (!oct->sriov_info.sriov_enabled)\n\t\treturn 0;\n\n\tnum_vfs = oct->sriov_info.num_vfs_alloced;\n\n\toct->vf_rep_list.num_vfs = 0;\n\tfor (i = 0; i < num_vfs; i++) {\n\t\tndev = alloc_etherdev(sizeof(struct lio_vf_rep_desc));\n\n\t\tif (!ndev) {\n\t\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\t\"VF rep device %d creation failed\\n\", i);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tndev->min_mtu = LIO_MIN_MTU_SIZE;\n\t\tndev->max_mtu = LIO_MAX_MTU_SIZE;\n\t\tndev->netdev_ops = &lio_vf_rep_ndev_ops;\n\n\t\tvf_rep = netdev_priv(ndev);\n\t\tmemset(vf_rep, 0, sizeof(*vf_rep));\n\n\t\tvf_rep->ndev = ndev;\n\t\tvf_rep->oct = oct;\n\t\tvf_rep->parent_ndev = oct->props[0].netdev;\n\t\tvf_rep->ifidx = (oct->pf_num * 64) + i + 1;\n\n\t\teth_hw_addr_random(ndev);\n\n\t\tif (register_netdev(ndev)) {\n\t\t\tdev_err(&oct->pci_dev->dev, \"VF rep nerdev registration failed\\n\");\n\n\t\t\tfree_netdev(ndev);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tnetif_carrier_off(ndev);\n\n\t\tINIT_DELAYED_WORK(&vf_rep->stats_wk.work,\n\t\t\t\t  lio_vf_rep_fetch_stats);\n\t\tvf_rep->stats_wk.ctxptr = (void *)vf_rep;\n\t\tschedule_delayed_work(&vf_rep->stats_wk.work,\n\t\t\t\t      msecs_to_jiffies\n\t\t\t\t      (LIO_VF_REP_STATS_POLL_TIME_MS));\n\t\toct->vf_rep_list.num_vfs++;\n\t\toct->vf_rep_list.ndev[i] = ndev;\n\t}\n\n\tif (octeon_register_dispatch_fn(oct, OPCODE_NIC,\n\t\t\t\t\tOPCODE_NIC_VF_REP_PKT,\n\t\t\t\t\tlio_vf_rep_pkt_recv, oct)) {\n\t\tdev_err(&oct->pci_dev->dev, \"VF rep Dispatch func registration failed\\n\");\n\n\t\tgoto cleanup;\n\t}\n\n\treturn 0;\n\ncleanup:\n\tfor (i = 0; i < oct->vf_rep_list.num_vfs; i++) {\n\t\tndev = oct->vf_rep_list.ndev[i];\n\t\toct->vf_rep_list.ndev[i] = NULL;\n\t\tif (ndev) {\n\t\t\tvf_rep = netdev_priv(ndev);\n\t\t\tcancel_delayed_work_sync\n\t\t\t\t(&vf_rep->stats_wk.work);\n\t\t\tunregister_netdev(ndev);\n\t\t\tfree_netdev(ndev);\n\t\t}\n\t}\n\n\toct->vf_rep_list.num_vfs = 0;\n\n\treturn -1;\n}\n\nvoid\nlio_vf_rep_destroy(struct octeon_device *oct)\n{\n\tstruct lio_vf_rep_desc *vf_rep;\n\tstruct net_device *ndev;\n\tint i;\n\n\tif (oct->eswitch_mode != DEVLINK_ESWITCH_MODE_SWITCHDEV)\n\t\treturn;\n\n\tif (!oct->sriov_info.sriov_enabled)\n\t\treturn;\n\n\tfor (i = 0; i < oct->vf_rep_list.num_vfs; i++) {\n\t\tndev = oct->vf_rep_list.ndev[i];\n\t\toct->vf_rep_list.ndev[i] = NULL;\n\t\tif (ndev) {\n\t\t\tvf_rep = netdev_priv(ndev);\n\t\t\tcancel_delayed_work_sync\n\t\t\t\t(&vf_rep->stats_wk.work);\n\t\t\tnetif_tx_disable(ndev);\n\t\t\tnetif_carrier_off(ndev);\n\n\t\t\tunregister_netdev(ndev);\n\t\t\tfree_netdev(ndev);\n\t\t}\n\t}\n\n\toct->vf_rep_list.num_vfs = 0;\n}\n\nstatic int\nlio_vf_rep_netdev_event(struct notifier_block *nb,\n\t\t\tunsigned long event, void *ptr)\n{\n\tstruct net_device *ndev = netdev_notifier_info_to_dev(ptr);\n\tstruct lio_vf_rep_desc *vf_rep;\n\tstruct lio_vf_rep_req rep_cfg;\n\tstruct octeon_device *oct;\n\tint ret;\n\n\tswitch (event) {\n\tcase NETDEV_REGISTER:\n\tcase NETDEV_CHANGENAME:\n\t\tbreak;\n\n\tdefault:\n\t\treturn NOTIFY_DONE;\n\t}\n\n\tif (ndev->netdev_ops != &lio_vf_rep_ndev_ops)\n\t\treturn NOTIFY_DONE;\n\n\tvf_rep = netdev_priv(ndev);\n\toct = vf_rep->oct;\n\n\tif (strlen(ndev->name) > LIO_IF_NAME_SIZE) {\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"Device name change sync failed as the size is > %d\\n\",\n\t\t\tLIO_IF_NAME_SIZE);\n\t\treturn NOTIFY_DONE;\n\t}\n\n\tmemset(&rep_cfg, 0, sizeof(rep_cfg));\n\trep_cfg.req_type = LIO_VF_REP_REQ_DEVNAME;\n\trep_cfg.ifidx = vf_rep->ifidx;\n\tstrncpy(rep_cfg.rep_name.name, ndev->name, LIO_IF_NAME_SIZE);\n\n\tret = lio_vf_rep_send_soft_command(oct, &rep_cfg,\n\t\t\t\t\t   sizeof(rep_cfg), NULL, 0);\n\tif (ret)\n\t\tdev_err(&oct->pci_dev->dev,\n\t\t\t\"vf_rep netdev name change failed with err %d\\n\", ret);\n\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block lio_vf_rep_netdev_notifier = {\n\t.notifier_call = lio_vf_rep_netdev_event,\n};\n\nint\nlio_vf_rep_modinit(void)\n{\n\tif (register_netdevice_notifier(&lio_vf_rep_netdev_notifier)) {\n\t\tpr_err(\"netdev notifier registration failed\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nvoid\nlio_vf_rep_modexit(void)\n{\n\tif (unregister_netdevice_notifier(&lio_vf_rep_netdev_notifier))\n\t\tpr_err(\"netdev notifier unregister failed\\n\");\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}