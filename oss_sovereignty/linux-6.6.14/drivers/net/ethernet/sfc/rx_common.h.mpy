{
  "module_name": "rx_common.h",
  "hash_id": "a77583c260e45897a815fc2cb5844a40c94b83a6c166453500695cd5bf5229ef",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sfc/rx_common.h",
  "human_readable_source": " \n \n\n#ifndef EFX_RX_COMMON_H\n#define EFX_RX_COMMON_H\n\n \n#define EFX_RX_PREFERRED_BATCH 8U\n\n \n#define EFX_RX_MAX_FRAGS DIV_ROUND_UP(EFX_MAX_FRAME_LEN(EFX_MAX_MTU), \\\n\t\t\t\t      EFX_RX_USR_BUF_SIZE)\n\n \n#define EFX_RECYCLE_RING_SIZE_10G\t256\n\nstatic inline u8 *efx_rx_buf_va(struct efx_rx_buffer *buf)\n{\n\treturn page_address(buf->page) + buf->page_offset;\n}\n\nstatic inline u32 efx_rx_buf_hash(struct efx_nic *efx, const u8 *eh)\n{\n#if defined(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS)\n\treturn __le32_to_cpup((const __le32 *)(eh + efx->rx_packet_hash_offset));\n#else\n\tconst u8 *data = eh + efx->rx_packet_hash_offset;\n\n\treturn (u32)data[0]\t  |\n\t       (u32)data[1] << 8  |\n\t       (u32)data[2] << 16 |\n\t       (u32)data[3] << 24;\n#endif\n}\n\nvoid efx_rx_slow_fill(struct timer_list *t);\n\nvoid efx_recycle_rx_pages(struct efx_channel *channel,\n\t\t\t  struct efx_rx_buffer *rx_buf,\n\t\t\t  unsigned int n_frags);\nvoid efx_discard_rx_packet(struct efx_channel *channel,\n\t\t\t   struct efx_rx_buffer *rx_buf,\n\t\t\t   unsigned int n_frags);\n\nint efx_probe_rx_queue(struct efx_rx_queue *rx_queue);\nvoid efx_init_rx_queue(struct efx_rx_queue *rx_queue);\nvoid efx_fini_rx_queue(struct efx_rx_queue *rx_queue);\nvoid efx_remove_rx_queue(struct efx_rx_queue *rx_queue);\nvoid efx_destroy_rx_queue(struct efx_rx_queue *rx_queue);\n\nvoid efx_init_rx_buffer(struct efx_rx_queue *rx_queue,\n\t\t\tstruct page *page,\n\t\t\tunsigned int page_offset,\n\t\t\tu16 flags);\nvoid efx_unmap_rx_buffer(struct efx_nic *efx, struct efx_rx_buffer *rx_buf);\n\nstatic inline void efx_sync_rx_buffer(struct efx_nic *efx,\n\t\t\t\t      struct efx_rx_buffer *rx_buf,\n\t\t\t\t      unsigned int len)\n{\n\tdma_sync_single_for_cpu(&efx->pci_dev->dev, rx_buf->dma_addr, len,\n\t\t\t\tDMA_FROM_DEVICE);\n}\n\nvoid efx_free_rx_buffers(struct efx_rx_queue *rx_queue,\n\t\t\t struct efx_rx_buffer *rx_buf,\n\t\t\t unsigned int num_bufs);\n\nvoid efx_schedule_slow_fill(struct efx_rx_queue *rx_queue);\nvoid efx_rx_config_page_split(struct efx_nic *efx);\nvoid efx_fast_push_rx_descriptors(struct efx_rx_queue *rx_queue, bool atomic);\n\nvoid\nefx_rx_packet_gro(struct efx_channel *channel, struct efx_rx_buffer *rx_buf,\n\t\t  unsigned int n_frags, u8 *eh, __wsum csum);\n\nstruct efx_rss_context *efx_alloc_rss_context_entry(struct efx_nic *efx);\nstruct efx_rss_context *efx_find_rss_context_entry(struct efx_nic *efx, u32 id);\nvoid efx_free_rss_context_entry(struct efx_rss_context *ctx);\nvoid efx_set_default_rx_indir_table(struct efx_nic *efx,\n\t\t\t\t    struct efx_rss_context *ctx);\n\nbool efx_filter_is_mc_recipient(const struct efx_filter_spec *spec);\nbool efx_filter_spec_equal(const struct efx_filter_spec *left,\n\t\t\t   const struct efx_filter_spec *right);\nu32 efx_filter_spec_hash(const struct efx_filter_spec *spec);\n\n#ifdef CONFIG_RFS_ACCEL\nbool efx_rps_check_rule(struct efx_arfs_rule *rule, unsigned int filter_idx,\n\t\t\tbool *force);\nstruct efx_arfs_rule *efx_rps_hash_find(struct efx_nic *efx,\n\t\t\t\t\tconst struct efx_filter_spec *spec);\nstruct efx_arfs_rule *efx_rps_hash_add(struct efx_nic *efx,\n\t\t\t\t       const struct efx_filter_spec *spec,\n\t\t\t\t       bool *new);\nvoid efx_rps_hash_del(struct efx_nic *efx, const struct efx_filter_spec *spec);\n\nint efx_filter_rfs(struct net_device *net_dev, const struct sk_buff *skb,\n\t\t   u16 rxq_index, u32 flow_id);\nbool __efx_filter_rfs_expire(struct efx_channel *channel, unsigned int quota);\n#endif\n\nint efx_probe_filters(struct efx_nic *efx);\nvoid efx_remove_filters(struct efx_nic *efx);\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}