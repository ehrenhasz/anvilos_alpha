{
  "module_name": "farch.c",
  "hash_id": "eedfcd59c39572145d438a862b4e4a21f8e84d47c56bd7120bd87732f3d72967",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sfc/siena/farch.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/module.h>\n#include <linux/seq_file.h>\n#include <linux/crc32.h>\n#include \"net_driver.h\"\n#include \"bitfield.h\"\n#include \"efx.h\"\n#include \"rx_common.h\"\n#include \"tx_common.h\"\n#include \"nic.h\"\n#include \"farch_regs.h\"\n#include \"sriov.h\"\n#include \"siena_sriov.h\"\n#include \"io.h\"\n#include \"workarounds.h\"\n\n \n\n \n\n \n#define TX_DC_ENTRIES 16\n#define TX_DC_ENTRIES_ORDER 1\n\n#define RX_DC_ENTRIES 64\n#define RX_DC_ENTRIES_ORDER 3\n\n \n#define EFX_INT_ERROR_EXPIRE 3600\n#define EFX_MAX_INT_ERRORS 5\n\n \n#define EFX_RX_FLUSH_COUNT 4\n\n \n#define _EFX_CHANNEL_MAGIC_TEST\t\t0x000101\n#define _EFX_CHANNEL_MAGIC_FILL\t\t0x000102\n#define _EFX_CHANNEL_MAGIC_RX_DRAIN\t0x000103\n#define _EFX_CHANNEL_MAGIC_TX_DRAIN\t0x000104\n\n#define _EFX_CHANNEL_MAGIC(_code, _data)\t((_code) << 8 | (_data))\n#define _EFX_CHANNEL_MAGIC_CODE(_magic)\t\t((_magic) >> 8)\n\n#define EFX_CHANNEL_MAGIC_TEST(_channel)\t\t\t\t\\\n\t_EFX_CHANNEL_MAGIC(_EFX_CHANNEL_MAGIC_TEST, (_channel)->channel)\n#define EFX_CHANNEL_MAGIC_FILL(_rx_queue)\t\t\t\t\\\n\t_EFX_CHANNEL_MAGIC(_EFX_CHANNEL_MAGIC_FILL,\t\t\t\\\n\t\t\t   efx_rx_queue_index(_rx_queue))\n#define EFX_CHANNEL_MAGIC_RX_DRAIN(_rx_queue)\t\t\t\t\\\n\t_EFX_CHANNEL_MAGIC(_EFX_CHANNEL_MAGIC_RX_DRAIN,\t\t\t\\\n\t\t\t   efx_rx_queue_index(_rx_queue))\n#define EFX_CHANNEL_MAGIC_TX_DRAIN(_tx_queue)\t\t\t\t\\\n\t_EFX_CHANNEL_MAGIC(_EFX_CHANNEL_MAGIC_TX_DRAIN,\t\t\t\\\n\t\t\t   (_tx_queue)->queue)\n\nstatic void efx_farch_magic_event(struct efx_channel *channel, u32 magic);\n\n \n\nstatic inline void efx_write_buf_tbl(struct efx_nic *efx, efx_qword_t *value,\n\t\t\t\t     unsigned int index)\n{\n\tefx_sram_writeq(efx, efx->membase + efx->type->buf_tbl_base,\n\t\t\tvalue, index);\n}\n\nstatic bool efx_masked_compare_oword(const efx_oword_t *a, const efx_oword_t *b,\n\t\t\t\t     const efx_oword_t *mask)\n{\n\treturn ((a->u64[0] ^ b->u64[0]) & mask->u64[0]) ||\n\t\t((a->u64[1] ^ b->u64[1]) & mask->u64[1]);\n}\n\nint efx_farch_test_registers(struct efx_nic *efx,\n\t\t\t     const struct efx_farch_register_test *regs,\n\t\t\t     size_t n_regs)\n{\n\tunsigned address = 0;\n\tint i, j;\n\tefx_oword_t mask, imask, original, reg, buf;\n\n\tfor (i = 0; i < n_regs; ++i) {\n\t\taddress = regs[i].address;\n\t\tmask = imask = regs[i].mask;\n\t\tEFX_INVERT_OWORD(imask);\n\n\t\tefx_reado(efx, &original, address);\n\n\t\t \n\t\tfor (j = 0; j < 128; j++) {\n\t\t\tif (!EFX_EXTRACT_OWORD32(mask, j, j))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tEFX_AND_OWORD(reg, original, mask);\n\t\t\tEFX_SET_OWORD32(reg, j, j, 1);\n\n\t\t\tefx_writeo(efx, &reg, address);\n\t\t\tefx_reado(efx, &buf, address);\n\n\t\t\tif (efx_masked_compare_oword(&reg, &buf, &mask))\n\t\t\t\tgoto fail;\n\n\t\t\t \n\t\t\tEFX_OR_OWORD(reg, original, mask);\n\t\t\tEFX_SET_OWORD32(reg, j, j, 0);\n\n\t\t\tefx_writeo(efx, &reg, address);\n\t\t\tefx_reado(efx, &buf, address);\n\n\t\t\tif (efx_masked_compare_oword(&reg, &buf, &mask))\n\t\t\t\tgoto fail;\n\t\t}\n\n\t\tefx_writeo(efx, &original, address);\n\t}\n\n\treturn 0;\n\nfail:\n\tnetif_err(efx, hw, efx->net_dev,\n\t\t  \"wrote \"EFX_OWORD_FMT\" read \"EFX_OWORD_FMT\n\t\t  \" at address 0x%x mask \"EFX_OWORD_FMT\"\\n\", EFX_OWORD_VAL(reg),\n\t\t  EFX_OWORD_VAL(buf), address, EFX_OWORD_VAL(mask));\n\treturn -EIO;\n}\n\n \n\n \nstatic void\nefx_init_special_buffer(struct efx_nic *efx, struct efx_special_buffer *buffer)\n{\n\tefx_qword_t buf_desc;\n\tunsigned int index;\n\tdma_addr_t dma_addr;\n\tint i;\n\n\tEFX_WARN_ON_PARANOID(!buffer->buf.addr);\n\n\t \n\tfor (i = 0; i < buffer->entries; i++) {\n\t\tindex = buffer->index + i;\n\t\tdma_addr = buffer->buf.dma_addr + (i * EFX_BUF_SIZE);\n\t\tnetif_dbg(efx, probe, efx->net_dev,\n\t\t\t  \"mapping special buffer %d at %llx\\n\",\n\t\t\t  index, (unsigned long long)dma_addr);\n\t\tEFX_POPULATE_QWORD_3(buf_desc,\n\t\t\t\t     FRF_AZ_BUF_ADR_REGION, 0,\n\t\t\t\t     FRF_AZ_BUF_ADR_FBUF, dma_addr >> 12,\n\t\t\t\t     FRF_AZ_BUF_OWNER_ID_FBUF, 0);\n\t\tefx_write_buf_tbl(efx, &buf_desc, index);\n\t}\n}\n\n \nstatic void\nefx_fini_special_buffer(struct efx_nic *efx, struct efx_special_buffer *buffer)\n{\n\tefx_oword_t buf_tbl_upd;\n\tunsigned int start = buffer->index;\n\tunsigned int end = (buffer->index + buffer->entries - 1);\n\n\tif (!buffer->entries)\n\t\treturn;\n\n\tnetif_dbg(efx, hw, efx->net_dev, \"unmapping special buffers %d-%d\\n\",\n\t\t  buffer->index, buffer->index + buffer->entries - 1);\n\n\tEFX_POPULATE_OWORD_4(buf_tbl_upd,\n\t\t\t     FRF_AZ_BUF_UPD_CMD, 0,\n\t\t\t     FRF_AZ_BUF_CLR_CMD, 1,\n\t\t\t     FRF_AZ_BUF_CLR_END_ID, end,\n\t\t\t     FRF_AZ_BUF_CLR_START_ID, start);\n\tefx_writeo(efx, &buf_tbl_upd, FR_AZ_BUF_TBL_UPD);\n}\n\n \nstatic int efx_alloc_special_buffer(struct efx_nic *efx,\n\t\t\t\t    struct efx_special_buffer *buffer,\n\t\t\t\t    unsigned int len)\n{\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n#endif\n\tlen = ALIGN(len, EFX_BUF_SIZE);\n\n\tif (efx_siena_alloc_buffer(efx, &buffer->buf, len, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\tbuffer->entries = len / EFX_BUF_SIZE;\n\tBUG_ON(buffer->buf.dma_addr & (EFX_BUF_SIZE - 1));\n\n\t \n\tbuffer->index = efx->next_buffer_table;\n\tefx->next_buffer_table += buffer->entries;\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\tBUG_ON(efx_siena_sriov_enabled(efx) &&\n\t       nic_data->vf_buftbl_base < efx->next_buffer_table);\n#endif\n\n\tnetif_dbg(efx, probe, efx->net_dev,\n\t\t  \"allocating special buffers %d-%d at %llx+%x \"\n\t\t  \"(virt %p phys %llx)\\n\", buffer->index,\n\t\t  buffer->index + buffer->entries - 1,\n\t\t  (u64)buffer->buf.dma_addr, len,\n\t\t  buffer->buf.addr, (u64)virt_to_phys(buffer->buf.addr));\n\n\treturn 0;\n}\n\nstatic void\nefx_free_special_buffer(struct efx_nic *efx, struct efx_special_buffer *buffer)\n{\n\tif (!buffer->buf.addr)\n\t\treturn;\n\n\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t  \"deallocating special buffers %d-%d at %llx+%x \"\n\t\t  \"(virt %p phys %llx)\\n\", buffer->index,\n\t\t  buffer->index + buffer->entries - 1,\n\t\t  (u64)buffer->buf.dma_addr, buffer->buf.len,\n\t\t  buffer->buf.addr, (u64)virt_to_phys(buffer->buf.addr));\n\n\tefx_siena_free_buffer(efx, &buffer->buf);\n\tbuffer->entries = 0;\n}\n\n \n\n \nstatic inline void efx_farch_notify_tx_desc(struct efx_tx_queue *tx_queue)\n{\n\tunsigned write_ptr;\n\tefx_dword_t reg;\n\n\twrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\n\tEFX_POPULATE_DWORD_1(reg, FRF_AZ_TX_DESC_WPTR_DWORD, write_ptr);\n\tefx_writed_page(tx_queue->efx, &reg,\n\t\t\tFR_AZ_TX_DESC_UPD_DWORD_P0, tx_queue->queue);\n}\n\n \nstatic inline void efx_farch_push_tx_desc(struct efx_tx_queue *tx_queue,\n\t\t\t\t\t  const efx_qword_t *txd)\n{\n\tunsigned write_ptr;\n\tefx_oword_t reg;\n\n\tBUILD_BUG_ON(FRF_AZ_TX_DESC_LBN != 0);\n\tBUILD_BUG_ON(FR_AA_TX_DESC_UPD_KER != FR_BZ_TX_DESC_UPD_P0);\n\n\twrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\n\tEFX_POPULATE_OWORD_2(reg, FRF_AZ_TX_DESC_PUSH_CMD, true,\n\t\t\t     FRF_AZ_TX_DESC_WPTR, write_ptr);\n\treg.qword[0] = *txd;\n\tefx_writeo_page(tx_queue->efx, &reg,\n\t\t\tFR_BZ_TX_DESC_UPD_P0, tx_queue->queue);\n}\n\n\n \nvoid efx_farch_tx_write(struct efx_tx_queue *tx_queue)\n{\n\tstruct efx_tx_buffer *buffer;\n\tefx_qword_t *txd;\n\tunsigned write_ptr;\n\tunsigned old_write_count = tx_queue->write_count;\n\n\ttx_queue->xmit_pending = false;\n\tif (unlikely(tx_queue->write_count == tx_queue->insert_count))\n\t\treturn;\n\n\tdo {\n\t\twrite_ptr = tx_queue->write_count & tx_queue->ptr_mask;\n\t\tbuffer = &tx_queue->buffer[write_ptr];\n\t\ttxd = efx_tx_desc(tx_queue, write_ptr);\n\t\t++tx_queue->write_count;\n\n\t\tEFX_WARN_ON_ONCE_PARANOID(buffer->flags & EFX_TX_BUF_OPTION);\n\n\t\t \n\t\tBUILD_BUG_ON(EFX_TX_BUF_CONT != 1);\n\t\tEFX_POPULATE_QWORD_4(*txd,\n\t\t\t\t     FSF_AZ_TX_KER_CONT,\n\t\t\t\t     buffer->flags & EFX_TX_BUF_CONT,\n\t\t\t\t     FSF_AZ_TX_KER_BYTE_COUNT, buffer->len,\n\t\t\t\t     FSF_AZ_TX_KER_BUF_REGION, 0,\n\t\t\t\t     FSF_AZ_TX_KER_BUF_ADDR, buffer->dma_addr);\n\t} while (tx_queue->write_count != tx_queue->insert_count);\n\n\twmb();  \n\n\tif (efx_nic_may_push_tx_desc(tx_queue, old_write_count)) {\n\t\ttxd = efx_tx_desc(tx_queue,\n\t\t\t\t  old_write_count & tx_queue->ptr_mask);\n\t\tefx_farch_push_tx_desc(tx_queue, txd);\n\t\t++tx_queue->pushes;\n\t} else {\n\t\tefx_farch_notify_tx_desc(tx_queue);\n\t}\n}\n\nunsigned int efx_farch_tx_limit_len(struct efx_tx_queue *tx_queue,\n\t\t\t\t    dma_addr_t dma_addr, unsigned int len)\n{\n\t \n\tunsigned int limit = (~dma_addr & (EFX_PAGE_SIZE - 1)) + 1;\n\n\tlen = min(limit, len);\n\n\treturn len;\n}\n\n\n \nint efx_farch_tx_probe(struct efx_tx_queue *tx_queue)\n{\n\tstruct efx_nic *efx = tx_queue->efx;\n\tunsigned entries;\n\n\ttx_queue->type = ((tx_queue->label & 1) ? EFX_TXQ_TYPE_OUTER_CSUM : 0) |\n\t\t\t ((tx_queue->label & 2) ? EFX_TXQ_TYPE_HIGHPRI : 0);\n\tentries = tx_queue->ptr_mask + 1;\n\treturn efx_alloc_special_buffer(efx, &tx_queue->txd,\n\t\t\t\t\tentries * sizeof(efx_qword_t));\n}\n\nvoid efx_farch_tx_init(struct efx_tx_queue *tx_queue)\n{\n\tint csum = tx_queue->type & EFX_TXQ_TYPE_OUTER_CSUM;\n\tstruct efx_nic *efx = tx_queue->efx;\n\tefx_oword_t reg;\n\n\t \n\tefx_init_special_buffer(efx, &tx_queue->txd);\n\n\t \n\tEFX_POPULATE_OWORD_10(reg,\n\t\t\t      FRF_AZ_TX_DESCQ_EN, 1,\n\t\t\t      FRF_AZ_TX_ISCSI_DDIG_EN, 0,\n\t\t\t      FRF_AZ_TX_ISCSI_HDIG_EN, 0,\n\t\t\t      FRF_AZ_TX_DESCQ_BUF_BASE_ID, tx_queue->txd.index,\n\t\t\t      FRF_AZ_TX_DESCQ_EVQ_ID,\n\t\t\t      tx_queue->channel->channel,\n\t\t\t      FRF_AZ_TX_DESCQ_OWNER_ID, 0,\n\t\t\t      FRF_AZ_TX_DESCQ_LABEL, tx_queue->label,\n\t\t\t      FRF_AZ_TX_DESCQ_SIZE,\n\t\t\t      __ffs(tx_queue->txd.entries),\n\t\t\t      FRF_AZ_TX_DESCQ_TYPE, 0,\n\t\t\t      FRF_BZ_TX_NON_IP_DROP_DIS, 1);\n\n\tEFX_SET_OWORD_FIELD(reg, FRF_BZ_TX_IP_CHKSM_DIS, !csum);\n\tEFX_SET_OWORD_FIELD(reg, FRF_BZ_TX_TCP_CHKSM_DIS, !csum);\n\n\tefx_writeo_table(efx, &reg, efx->type->txd_ptr_tbl_base,\n\t\t\t tx_queue->queue);\n\n\tEFX_POPULATE_OWORD_1(reg,\n\t\t\t     FRF_BZ_TX_PACE,\n\t\t\t     (tx_queue->type & EFX_TXQ_TYPE_HIGHPRI) ?\n\t\t\t     FFE_BZ_TX_PACE_OFF :\n\t\t\t     FFE_BZ_TX_PACE_RESERVED);\n\tefx_writeo_table(efx, &reg, FR_BZ_TX_PACE_TBL, tx_queue->queue);\n\n\ttx_queue->tso_version = 1;\n}\n\nstatic void efx_farch_flush_tx_queue(struct efx_tx_queue *tx_queue)\n{\n\tstruct efx_nic *efx = tx_queue->efx;\n\tefx_oword_t tx_flush_descq;\n\n\tWARN_ON(atomic_read(&tx_queue->flush_outstanding));\n\tatomic_set(&tx_queue->flush_outstanding, 1);\n\n\tEFX_POPULATE_OWORD_2(tx_flush_descq,\n\t\t\t     FRF_AZ_TX_FLUSH_DESCQ_CMD, 1,\n\t\t\t     FRF_AZ_TX_FLUSH_DESCQ, tx_queue->queue);\n\tefx_writeo(efx, &tx_flush_descq, FR_AZ_TX_FLUSH_DESCQ);\n}\n\nvoid efx_farch_tx_fini(struct efx_tx_queue *tx_queue)\n{\n\tstruct efx_nic *efx = tx_queue->efx;\n\tefx_oword_t tx_desc_ptr;\n\n\t \n\tEFX_ZERO_OWORD(tx_desc_ptr);\n\tefx_writeo_table(efx, &tx_desc_ptr, efx->type->txd_ptr_tbl_base,\n\t\t\t tx_queue->queue);\n\n\t \n\tefx_fini_special_buffer(efx, &tx_queue->txd);\n}\n\n \nvoid efx_farch_tx_remove(struct efx_tx_queue *tx_queue)\n{\n\tefx_free_special_buffer(tx_queue->efx, &tx_queue->txd);\n}\n\n \n\n \nstatic inline void\nefx_farch_build_rx_desc(struct efx_rx_queue *rx_queue, unsigned index)\n{\n\tstruct efx_rx_buffer *rx_buf;\n\tefx_qword_t *rxd;\n\n\trxd = efx_rx_desc(rx_queue, index);\n\trx_buf = efx_rx_buffer(rx_queue, index);\n\tEFX_POPULATE_QWORD_3(*rxd,\n\t\t\t     FSF_AZ_RX_KER_BUF_SIZE,\n\t\t\t     rx_buf->len -\n\t\t\t     rx_queue->efx->type->rx_buffer_padding,\n\t\t\t     FSF_AZ_RX_KER_BUF_REGION, 0,\n\t\t\t     FSF_AZ_RX_KER_BUF_ADDR, rx_buf->dma_addr);\n}\n\n \nvoid efx_farch_rx_write(struct efx_rx_queue *rx_queue)\n{\n\tstruct efx_nic *efx = rx_queue->efx;\n\tefx_dword_t reg;\n\tunsigned write_ptr;\n\n\twhile (rx_queue->notified_count != rx_queue->added_count) {\n\t\tefx_farch_build_rx_desc(\n\t\t\trx_queue,\n\t\t\trx_queue->notified_count & rx_queue->ptr_mask);\n\t\t++rx_queue->notified_count;\n\t}\n\n\twmb();\n\twrite_ptr = rx_queue->added_count & rx_queue->ptr_mask;\n\tEFX_POPULATE_DWORD_1(reg, FRF_AZ_RX_DESC_WPTR_DWORD, write_ptr);\n\tefx_writed_page(efx, &reg, FR_AZ_RX_DESC_UPD_DWORD_P0,\n\t\t\tefx_rx_queue_index(rx_queue));\n}\n\nint efx_farch_rx_probe(struct efx_rx_queue *rx_queue)\n{\n\tstruct efx_nic *efx = rx_queue->efx;\n\tunsigned entries;\n\n\tentries = rx_queue->ptr_mask + 1;\n\treturn efx_alloc_special_buffer(efx, &rx_queue->rxd,\n\t\t\t\t\tentries * sizeof(efx_qword_t));\n}\n\nvoid efx_farch_rx_init(struct efx_rx_queue *rx_queue)\n{\n\tefx_oword_t rx_desc_ptr;\n\tstruct efx_nic *efx = rx_queue->efx;\n\tbool jumbo_en;\n\n\t \n\tjumbo_en = efx->rx_scatter;\n\n\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t  \"RX queue %d ring in special buffers %d-%d\\n\",\n\t\t  efx_rx_queue_index(rx_queue), rx_queue->rxd.index,\n\t\t  rx_queue->rxd.index + rx_queue->rxd.entries - 1);\n\n\trx_queue->scatter_n = 0;\n\n\t \n\tefx_init_special_buffer(efx, &rx_queue->rxd);\n\n\t \n\tEFX_POPULATE_OWORD_10(rx_desc_ptr,\n\t\t\t      FRF_AZ_RX_ISCSI_DDIG_EN, true,\n\t\t\t      FRF_AZ_RX_ISCSI_HDIG_EN, true,\n\t\t\t      FRF_AZ_RX_DESCQ_BUF_BASE_ID, rx_queue->rxd.index,\n\t\t\t      FRF_AZ_RX_DESCQ_EVQ_ID,\n\t\t\t      efx_rx_queue_channel(rx_queue)->channel,\n\t\t\t      FRF_AZ_RX_DESCQ_OWNER_ID, 0,\n\t\t\t      FRF_AZ_RX_DESCQ_LABEL,\n\t\t\t      efx_rx_queue_index(rx_queue),\n\t\t\t      FRF_AZ_RX_DESCQ_SIZE,\n\t\t\t      __ffs(rx_queue->rxd.entries),\n\t\t\t      FRF_AZ_RX_DESCQ_TYPE, 0   ,\n\t\t\t      FRF_AZ_RX_DESCQ_JUMBO, jumbo_en,\n\t\t\t      FRF_AZ_RX_DESCQ_EN, 1);\n\tefx_writeo_table(efx, &rx_desc_ptr, efx->type->rxd_ptr_tbl_base,\n\t\t\t efx_rx_queue_index(rx_queue));\n}\n\nstatic void efx_farch_flush_rx_queue(struct efx_rx_queue *rx_queue)\n{\n\tstruct efx_nic *efx = rx_queue->efx;\n\tefx_oword_t rx_flush_descq;\n\n\tEFX_POPULATE_OWORD_2(rx_flush_descq,\n\t\t\t     FRF_AZ_RX_FLUSH_DESCQ_CMD, 1,\n\t\t\t     FRF_AZ_RX_FLUSH_DESCQ,\n\t\t\t     efx_rx_queue_index(rx_queue));\n\tefx_writeo(efx, &rx_flush_descq, FR_AZ_RX_FLUSH_DESCQ);\n}\n\nvoid efx_farch_rx_fini(struct efx_rx_queue *rx_queue)\n{\n\tefx_oword_t rx_desc_ptr;\n\tstruct efx_nic *efx = rx_queue->efx;\n\n\t \n\tEFX_ZERO_OWORD(rx_desc_ptr);\n\tefx_writeo_table(efx, &rx_desc_ptr, efx->type->rxd_ptr_tbl_base,\n\t\t\t efx_rx_queue_index(rx_queue));\n\n\t \n\tefx_fini_special_buffer(efx, &rx_queue->rxd);\n}\n\n \nvoid efx_farch_rx_remove(struct efx_rx_queue *rx_queue)\n{\n\tefx_free_special_buffer(rx_queue->efx, &rx_queue->rxd);\n}\n\n \n\n \nstatic bool efx_farch_flush_wake(struct efx_nic *efx)\n{\n\t \n\tsmp_mb();\n\n\treturn (atomic_read(&efx->active_queues) == 0 ||\n\t\t(atomic_read(&efx->rxq_flush_outstanding) < EFX_RX_FLUSH_COUNT\n\t\t && atomic_read(&efx->rxq_flush_pending) > 0));\n}\n\nstatic bool efx_check_tx_flush_complete(struct efx_nic *efx)\n{\n\tbool i = true;\n\tefx_oword_t txd_ptr_tbl;\n\tstruct efx_channel *channel;\n\tstruct efx_tx_queue *tx_queue;\n\n\tefx_for_each_channel(channel, efx) {\n\t\tefx_for_each_channel_tx_queue(tx_queue, channel) {\n\t\t\tefx_reado_table(efx, &txd_ptr_tbl,\n\t\t\t\t\tFR_BZ_TX_DESC_PTR_TBL, tx_queue->queue);\n\t\t\tif (EFX_OWORD_FIELD(txd_ptr_tbl,\n\t\t\t\t\t    FRF_AZ_TX_DESCQ_FLUSH) ||\n\t\t\t    EFX_OWORD_FIELD(txd_ptr_tbl,\n\t\t\t\t\t    FRF_AZ_TX_DESCQ_EN)) {\n\t\t\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t\t\t  \"flush did not complete on TXQ %d\\n\",\n\t\t\t\t\t  tx_queue->queue);\n\t\t\t\ti = false;\n\t\t\t} else if (atomic_cmpxchg(&tx_queue->flush_outstanding,\n\t\t\t\t\t\t  1, 0)) {\n\t\t\t\t \n\t\t\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t\t\t  \"flush complete on TXQ %d, so drain \"\n\t\t\t\t\t  \"the queue\\n\", tx_queue->queue);\n\t\t\t\t \n\t\t\t\tefx_farch_magic_event(channel,\n\t\t\t\t\t\t      EFX_CHANNEL_MAGIC_TX_DRAIN(\n\t\t\t\t\t\t\t      tx_queue));\n\t\t\t}\n\t\t}\n\t}\n\n\treturn i;\n}\n\n \nstatic int efx_farch_do_flush(struct efx_nic *efx)\n{\n\tunsigned timeout = msecs_to_jiffies(5000);  \n\tstruct efx_channel *channel;\n\tstruct efx_rx_queue *rx_queue;\n\tstruct efx_tx_queue *tx_queue;\n\tint rc = 0;\n\n\tefx_for_each_channel(channel, efx) {\n\t\tefx_for_each_channel_tx_queue(tx_queue, channel) {\n\t\t\tefx_farch_flush_tx_queue(tx_queue);\n\t\t}\n\t\tefx_for_each_channel_rx_queue(rx_queue, channel) {\n\t\t\trx_queue->flush_pending = true;\n\t\t\tatomic_inc(&efx->rxq_flush_pending);\n\t\t}\n\t}\n\n\twhile (timeout && atomic_read(&efx->active_queues) > 0) {\n\t\t \n\t\tif (efx_siena_sriov_enabled(efx)) {\n\t\t\trc = efx_siena_mcdi_flush_rxqs(efx);\n\t\t\tif (!rc)\n\t\t\t\tgoto wait;\n\t\t}\n\n\t\t \n\t\tefx_for_each_channel(channel, efx) {\n\t\t\tefx_for_each_channel_rx_queue(rx_queue, channel) {\n\t\t\t\tif (atomic_read(&efx->rxq_flush_outstanding) >=\n\t\t\t\t    EFX_RX_FLUSH_COUNT)\n\t\t\t\t\tbreak;\n\n\t\t\t\tif (rx_queue->flush_pending) {\n\t\t\t\t\trx_queue->flush_pending = false;\n\t\t\t\t\tatomic_dec(&efx->rxq_flush_pending);\n\t\t\t\t\tatomic_inc(&efx->rxq_flush_outstanding);\n\t\t\t\t\tefx_farch_flush_rx_queue(rx_queue);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\twait:\n\t\ttimeout = wait_event_timeout(efx->flush_wq,\n\t\t\t\t\t     efx_farch_flush_wake(efx),\n\t\t\t\t\t     timeout);\n\t}\n\n\tif (atomic_read(&efx->active_queues) &&\n\t    !efx_check_tx_flush_complete(efx)) {\n\t\tnetif_err(efx, hw, efx->net_dev, \"failed to flush %d queues \"\n\t\t\t  \"(rx %d+%d)\\n\", atomic_read(&efx->active_queues),\n\t\t\t  atomic_read(&efx->rxq_flush_outstanding),\n\t\t\t  atomic_read(&efx->rxq_flush_pending));\n\t\trc = -ETIMEDOUT;\n\n\t\tatomic_set(&efx->active_queues, 0);\n\t\tatomic_set(&efx->rxq_flush_pending, 0);\n\t\tatomic_set(&efx->rxq_flush_outstanding, 0);\n\t}\n\n\treturn rc;\n}\n\nint efx_farch_fini_dmaq(struct efx_nic *efx)\n{\n\tstruct efx_channel *channel;\n\tstruct efx_tx_queue *tx_queue;\n\tstruct efx_rx_queue *rx_queue;\n\tint rc = 0;\n\n\t \n\tif (efx->state != STATE_RECOVERY) {\n\t\t \n\t\tif (efx->pci_dev->is_busmaster) {\n\t\t\tefx->type->prepare_flush(efx);\n\t\t\trc = efx_farch_do_flush(efx);\n\t\t\tefx->type->finish_flush(efx);\n\t\t}\n\n\t\tefx_for_each_channel(channel, efx) {\n\t\t\tefx_for_each_channel_rx_queue(rx_queue, channel)\n\t\t\t\tefx_farch_rx_fini(rx_queue);\n\t\t\tefx_for_each_channel_tx_queue(tx_queue, channel)\n\t\t\t\tefx_farch_tx_fini(tx_queue);\n\t\t}\n\t}\n\n\treturn rc;\n}\n\n \nvoid efx_farch_finish_flr(struct efx_nic *efx)\n{\n\tatomic_set(&efx->rxq_flush_pending, 0);\n\tatomic_set(&efx->rxq_flush_outstanding, 0);\n\tatomic_set(&efx->active_queues, 0);\n}\n\n\n \n\n \nvoid efx_farch_ev_read_ack(struct efx_channel *channel)\n{\n\tefx_dword_t reg;\n\tstruct efx_nic *efx = channel->efx;\n\n\tEFX_POPULATE_DWORD_1(reg, FRF_AZ_EVQ_RPTR,\n\t\t\t     channel->eventq_read_ptr & channel->eventq_mask);\n\n\t \n\tefx_writed(efx, &reg,\n\t\t   efx->type->evq_rptr_tbl_base +\n\t\t   FR_BZ_EVQ_RPTR_STEP * channel->channel);\n}\n\n \nvoid efx_farch_generate_event(struct efx_nic *efx, unsigned int evq,\n\t\t\t      efx_qword_t *event)\n{\n\tefx_oword_t drv_ev_reg;\n\n\tBUILD_BUG_ON(FRF_AZ_DRV_EV_DATA_LBN != 0 ||\n\t\t     FRF_AZ_DRV_EV_DATA_WIDTH != 64);\n\tdrv_ev_reg.u32[0] = event->u32[0];\n\tdrv_ev_reg.u32[1] = event->u32[1];\n\tdrv_ev_reg.u32[2] = 0;\n\tdrv_ev_reg.u32[3] = 0;\n\tEFX_SET_OWORD_FIELD(drv_ev_reg, FRF_AZ_DRV_EV_QID, evq);\n\tefx_writeo(efx, &drv_ev_reg, FR_AZ_DRV_EV);\n}\n\nstatic void efx_farch_magic_event(struct efx_channel *channel, u32 magic)\n{\n\tefx_qword_t event;\n\n\tEFX_POPULATE_QWORD_2(event, FSF_AZ_EV_CODE,\n\t\t\t     FSE_AZ_EV_CODE_DRV_GEN_EV,\n\t\t\t     FSF_AZ_DRV_GEN_EV_MAGIC, magic);\n\tefx_farch_generate_event(channel->efx, channel->channel, &event);\n}\n\n \nstatic void\nefx_farch_handle_tx_event(struct efx_channel *channel, efx_qword_t *event)\n{\n\tunsigned int tx_ev_desc_ptr;\n\tunsigned int tx_ev_q_label;\n\tstruct efx_tx_queue *tx_queue;\n\tstruct efx_nic *efx = channel->efx;\n\n\tif (unlikely(READ_ONCE(efx->reset_pending)))\n\t\treturn;\n\n\tif (likely(EFX_QWORD_FIELD(*event, FSF_AZ_TX_EV_COMP))) {\n\t\t \n\t\ttx_ev_desc_ptr = EFX_QWORD_FIELD(*event, FSF_AZ_TX_EV_DESC_PTR);\n\t\ttx_ev_q_label = EFX_QWORD_FIELD(*event, FSF_AZ_TX_EV_Q_LABEL);\n\t\ttx_queue = channel->tx_queue +\n\t\t\t\t(tx_ev_q_label % EFX_MAX_TXQ_PER_CHANNEL);\n\t\tefx_siena_xmit_done(tx_queue, tx_ev_desc_ptr);\n\t} else if (EFX_QWORD_FIELD(*event, FSF_AZ_TX_EV_WQ_FF_FULL)) {\n\t\t \n\t\ttx_ev_q_label = EFX_QWORD_FIELD(*event, FSF_AZ_TX_EV_Q_LABEL);\n\t\ttx_queue = channel->tx_queue +\n\t\t\t\t(tx_ev_q_label % EFX_MAX_TXQ_PER_CHANNEL);\n\n\t\tnetif_tx_lock(efx->net_dev);\n\t\tefx_farch_notify_tx_desc(tx_queue);\n\t\tnetif_tx_unlock(efx->net_dev);\n\t} else if (EFX_QWORD_FIELD(*event, FSF_AZ_TX_EV_PKT_ERR)) {\n\t\tefx_siena_schedule_reset(efx, RESET_TYPE_DMA_ERROR);\n\t} else {\n\t\tnetif_err(efx, tx_err, efx->net_dev,\n\t\t\t  \"channel %d unexpected TX event \"\n\t\t\t  EFX_QWORD_FMT\"\\n\", channel->channel,\n\t\t\t  EFX_QWORD_VAL(*event));\n\t}\n}\n\n \nstatic u16 efx_farch_handle_rx_not_ok(struct efx_rx_queue *rx_queue,\n\t\t\t\t      const efx_qword_t *event)\n{\n\tstruct efx_channel *channel = efx_rx_queue_channel(rx_queue);\n\tstruct efx_nic *efx = rx_queue->efx;\n\tbool rx_ev_buf_owner_id_err, rx_ev_ip_hdr_chksum_err;\n\tbool rx_ev_tcp_udp_chksum_err, rx_ev_eth_crc_err;\n\tbool rx_ev_frm_trunc, rx_ev_tobe_disc;\n\tbool rx_ev_other_err, rx_ev_pause_frm;\n\n\trx_ev_tobe_disc = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_TOBE_DISC);\n\trx_ev_buf_owner_id_err = EFX_QWORD_FIELD(*event,\n\t\t\t\t\t\t FSF_AZ_RX_EV_BUF_OWNER_ID_ERR);\n\trx_ev_ip_hdr_chksum_err = EFX_QWORD_FIELD(*event,\n\t\t\t\t\t\t  FSF_AZ_RX_EV_IP_HDR_CHKSUM_ERR);\n\trx_ev_tcp_udp_chksum_err = EFX_QWORD_FIELD(*event,\n\t\t\t\t\t\t   FSF_AZ_RX_EV_TCP_UDP_CHKSUM_ERR);\n\trx_ev_eth_crc_err = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_ETH_CRC_ERR);\n\trx_ev_frm_trunc = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_FRM_TRUNC);\n\trx_ev_pause_frm = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_PAUSE_FRM_ERR);\n\n\t \n\trx_ev_other_err = (rx_ev_tcp_udp_chksum_err |\n\t\t\t   rx_ev_buf_owner_id_err | rx_ev_eth_crc_err |\n\t\t\t   rx_ev_frm_trunc | rx_ev_ip_hdr_chksum_err);\n\n\t \n\tif (rx_ev_frm_trunc)\n\t\t++channel->n_rx_frm_trunc;\n\telse if (rx_ev_tobe_disc)\n\t\t++channel->n_rx_tobe_disc;\n\telse if (!efx->loopback_selftest) {\n\t\tif (rx_ev_ip_hdr_chksum_err)\n\t\t\t++channel->n_rx_ip_hdr_chksum_err;\n\t\telse if (rx_ev_tcp_udp_chksum_err)\n\t\t\t++channel->n_rx_tcp_udp_chksum_err;\n\t}\n\n\t \n#ifdef DEBUG\n\tif (rx_ev_other_err && net_ratelimit()) {\n\t\tnetif_dbg(efx, rx_err, efx->net_dev,\n\t\t\t  \" RX queue %d unexpected RX event \"\n\t\t\t  EFX_QWORD_FMT \"%s%s%s%s%s%s%s\\n\",\n\t\t\t  efx_rx_queue_index(rx_queue), EFX_QWORD_VAL(*event),\n\t\t\t  rx_ev_buf_owner_id_err ? \" [OWNER_ID_ERR]\" : \"\",\n\t\t\t  rx_ev_ip_hdr_chksum_err ?\n\t\t\t  \" [IP_HDR_CHKSUM_ERR]\" : \"\",\n\t\t\t  rx_ev_tcp_udp_chksum_err ?\n\t\t\t  \" [TCP_UDP_CHKSUM_ERR]\" : \"\",\n\t\t\t  rx_ev_eth_crc_err ? \" [ETH_CRC_ERR]\" : \"\",\n\t\t\t  rx_ev_frm_trunc ? \" [FRM_TRUNC]\" : \"\",\n\t\t\t  rx_ev_tobe_disc ? \" [TOBE_DISC]\" : \"\",\n\t\t\t  rx_ev_pause_frm ? \" [PAUSE]\" : \"\");\n\t}\n#else\n\t(void) rx_ev_other_err;\n#endif\n\n\tif (efx->net_dev->features & NETIF_F_RXALL)\n\t\t \n\t\trx_ev_eth_crc_err = false;\n\n\t \n\treturn (rx_ev_eth_crc_err | rx_ev_frm_trunc |\n\t\trx_ev_tobe_disc | rx_ev_pause_frm) ?\n\t\tEFX_RX_PKT_DISCARD : 0;\n}\n\n \nstatic bool\nefx_farch_handle_rx_bad_index(struct efx_rx_queue *rx_queue, unsigned index)\n{\n\tstruct efx_channel *channel = efx_rx_queue_channel(rx_queue);\n\tstruct efx_nic *efx = rx_queue->efx;\n\tunsigned expected, dropped;\n\n\tif (rx_queue->scatter_n &&\n\t    index == ((rx_queue->removed_count + rx_queue->scatter_n - 1) &\n\t\t      rx_queue->ptr_mask)) {\n\t\t++channel->n_rx_nodesc_trunc;\n\t\treturn true;\n\t}\n\n\texpected = rx_queue->removed_count & rx_queue->ptr_mask;\n\tdropped = (index - expected) & rx_queue->ptr_mask;\n\tnetif_info(efx, rx_err, efx->net_dev,\n\t\t   \"dropped %d events (index=%d expected=%d)\\n\",\n\t\t   dropped, index, expected);\n\n\tefx_siena_schedule_reset(efx, RESET_TYPE_DISABLE);\n\treturn false;\n}\n\n \nstatic void\nefx_farch_handle_rx_event(struct efx_channel *channel, const efx_qword_t *event)\n{\n\tunsigned int rx_ev_desc_ptr, rx_ev_byte_cnt;\n\tunsigned int rx_ev_hdr_type, rx_ev_mcast_pkt;\n\tunsigned expected_ptr;\n\tbool rx_ev_pkt_ok, rx_ev_sop, rx_ev_cont;\n\tu16 flags;\n\tstruct efx_rx_queue *rx_queue;\n\tstruct efx_nic *efx = channel->efx;\n\n\tif (unlikely(READ_ONCE(efx->reset_pending)))\n\t\treturn;\n\n\trx_ev_cont = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_JUMBO_CONT);\n\trx_ev_sop = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_SOP);\n\tWARN_ON(EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_Q_LABEL) !=\n\t\tchannel->channel);\n\n\trx_queue = efx_channel_get_rx_queue(channel);\n\n\trx_ev_desc_ptr = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_DESC_PTR);\n\texpected_ptr = ((rx_queue->removed_count + rx_queue->scatter_n) &\n\t\t\trx_queue->ptr_mask);\n\n\t \n\tif (unlikely(rx_ev_desc_ptr != expected_ptr) ||\n\t    unlikely(rx_ev_sop != (rx_queue->scatter_n == 0))) {\n\t\tif (rx_ev_desc_ptr != expected_ptr &&\n\t\t    !efx_farch_handle_rx_bad_index(rx_queue, rx_ev_desc_ptr))\n\t\t\treturn;\n\n\t\t \n\t\tif (rx_queue->scatter_n) {\n\t\t\tefx_siena_rx_packet(\n\t\t\t\trx_queue,\n\t\t\t\trx_queue->removed_count & rx_queue->ptr_mask,\n\t\t\t\trx_queue->scatter_n, 0, EFX_RX_PKT_DISCARD);\n\t\t\trx_queue->removed_count += rx_queue->scatter_n;\n\t\t\trx_queue->scatter_n = 0;\n\t\t}\n\n\t\t \n\t\tif (rx_ev_desc_ptr != expected_ptr)\n\t\t\treturn;\n\n\t\t \n\t\tif (!rx_ev_sop) {\n\t\t\tefx_siena_rx_packet(\n\t\t\t\trx_queue,\n\t\t\t\trx_queue->removed_count & rx_queue->ptr_mask,\n\t\t\t\t1, 0, EFX_RX_PKT_DISCARD);\n\t\t\t++rx_queue->removed_count;\n\t\t\treturn;\n\t\t}\n\t}\n\n\t++rx_queue->scatter_n;\n\tif (rx_ev_cont)\n\t\treturn;\n\n\trx_ev_byte_cnt = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_BYTE_CNT);\n\trx_ev_pkt_ok = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_PKT_OK);\n\trx_ev_hdr_type = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_HDR_TYPE);\n\n\tif (likely(rx_ev_pkt_ok)) {\n\t\t \n\t\tflags = 0;\n\t\tswitch (rx_ev_hdr_type) {\n\t\tcase FSE_CZ_RX_EV_HDR_TYPE_IPV4V6_TCP:\n\t\t\tflags |= EFX_RX_PKT_TCP;\n\t\t\tfallthrough;\n\t\tcase FSE_CZ_RX_EV_HDR_TYPE_IPV4V6_UDP:\n\t\t\tflags |= EFX_RX_PKT_CSUMMED;\n\t\t\tfallthrough;\n\t\tcase FSE_CZ_RX_EV_HDR_TYPE_IPV4V6_OTHER:\n\t\tcase FSE_AZ_RX_EV_HDR_TYPE_OTHER:\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tflags = efx_farch_handle_rx_not_ok(rx_queue, event);\n\t}\n\n\t \n\trx_ev_mcast_pkt = EFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_MCAST_PKT);\n\tif (rx_ev_mcast_pkt) {\n\t\tunsigned int rx_ev_mcast_hash_match =\n\t\t\tEFX_QWORD_FIELD(*event, FSF_AZ_RX_EV_MCAST_HASH_MATCH);\n\n\t\tif (unlikely(!rx_ev_mcast_hash_match)) {\n\t\t\t++channel->n_rx_mcast_mismatch;\n\t\t\tflags |= EFX_RX_PKT_DISCARD;\n\t\t}\n\t}\n\n\tchannel->irq_mod_score += 2;\n\n\t \n\tefx_siena_rx_packet(rx_queue,\n\t\t\t    rx_queue->removed_count & rx_queue->ptr_mask,\n\t\t\t    rx_queue->scatter_n, rx_ev_byte_cnt, flags);\n\trx_queue->removed_count += rx_queue->scatter_n;\n\trx_queue->scatter_n = 0;\n}\n\n \nstatic void\nefx_farch_handle_tx_flush_done(struct efx_nic *efx, efx_qword_t *event)\n{\n\tstruct efx_tx_queue *tx_queue;\n\tstruct efx_channel *channel;\n\tint qid;\n\n\tqid = EFX_QWORD_FIELD(*event, FSF_AZ_DRIVER_EV_SUBDATA);\n\tif (qid < EFX_MAX_TXQ_PER_CHANNEL * (efx->n_tx_channels + efx->n_extra_tx_channels)) {\n\t\tchannel = efx_get_tx_channel(efx, qid / EFX_MAX_TXQ_PER_CHANNEL);\n\t\ttx_queue = channel->tx_queue + (qid % EFX_MAX_TXQ_PER_CHANNEL);\n\t\tif (atomic_cmpxchg(&tx_queue->flush_outstanding, 1, 0))\n\t\t\tefx_farch_magic_event(tx_queue->channel,\n\t\t\t\t\t      EFX_CHANNEL_MAGIC_TX_DRAIN(tx_queue));\n\t}\n}\n\n \nstatic void\nefx_farch_handle_rx_flush_done(struct efx_nic *efx, efx_qword_t *event)\n{\n\tstruct efx_channel *channel;\n\tstruct efx_rx_queue *rx_queue;\n\tint qid;\n\tbool failed;\n\n\tqid = EFX_QWORD_FIELD(*event, FSF_AZ_DRIVER_EV_RX_DESCQ_ID);\n\tfailed = EFX_QWORD_FIELD(*event, FSF_AZ_DRIVER_EV_RX_FLUSH_FAIL);\n\tif (qid >= efx->n_channels)\n\t\treturn;\n\tchannel = efx_get_channel(efx, qid);\n\tif (!efx_channel_has_rx_queue(channel))\n\t\treturn;\n\trx_queue = efx_channel_get_rx_queue(channel);\n\n\tif (failed) {\n\t\tnetif_info(efx, hw, efx->net_dev,\n\t\t\t   \"RXQ %d flush retry\\n\", qid);\n\t\trx_queue->flush_pending = true;\n\t\tatomic_inc(&efx->rxq_flush_pending);\n\t} else {\n\t\tefx_farch_magic_event(efx_rx_queue_channel(rx_queue),\n\t\t\t\t      EFX_CHANNEL_MAGIC_RX_DRAIN(rx_queue));\n\t}\n\tatomic_dec(&efx->rxq_flush_outstanding);\n\tif (efx_farch_flush_wake(efx))\n\t\twake_up(&efx->flush_wq);\n}\n\nstatic void\nefx_farch_handle_drain_event(struct efx_channel *channel)\n{\n\tstruct efx_nic *efx = channel->efx;\n\n\tWARN_ON(atomic_read(&efx->active_queues) == 0);\n\tatomic_dec(&efx->active_queues);\n\tif (efx_farch_flush_wake(efx))\n\t\twake_up(&efx->flush_wq);\n}\n\nstatic void efx_farch_handle_generated_event(struct efx_channel *channel,\n\t\t\t\t\t     efx_qword_t *event)\n{\n\tstruct efx_nic *efx = channel->efx;\n\tstruct efx_rx_queue *rx_queue =\n\t\tefx_channel_has_rx_queue(channel) ?\n\t\tefx_channel_get_rx_queue(channel) : NULL;\n\tunsigned magic, code;\n\n\tmagic = EFX_QWORD_FIELD(*event, FSF_AZ_DRV_GEN_EV_MAGIC);\n\tcode = _EFX_CHANNEL_MAGIC_CODE(magic);\n\n\tif (magic == EFX_CHANNEL_MAGIC_TEST(channel)) {\n\t\tchannel->event_test_cpu = raw_smp_processor_id();\n\t} else if (rx_queue && magic == EFX_CHANNEL_MAGIC_FILL(rx_queue)) {\n\t\t \n\t\tefx_siena_fast_push_rx_descriptors(rx_queue, true);\n\t} else if (rx_queue && magic == EFX_CHANNEL_MAGIC_RX_DRAIN(rx_queue)) {\n\t\tefx_farch_handle_drain_event(channel);\n\t} else if (code == _EFX_CHANNEL_MAGIC_TX_DRAIN) {\n\t\tefx_farch_handle_drain_event(channel);\n\t} else {\n\t\tnetif_dbg(efx, hw, efx->net_dev, \"channel %d received \"\n\t\t\t  \"generated event \"EFX_QWORD_FMT\"\\n\",\n\t\t\t  channel->channel, EFX_QWORD_VAL(*event));\n\t}\n}\n\nstatic void\nefx_farch_handle_driver_event(struct efx_channel *channel, efx_qword_t *event)\n{\n\tstruct efx_nic *efx = channel->efx;\n\tunsigned int ev_sub_code;\n\tunsigned int ev_sub_data;\n\n\tev_sub_code = EFX_QWORD_FIELD(*event, FSF_AZ_DRIVER_EV_SUBCODE);\n\tev_sub_data = EFX_QWORD_FIELD(*event, FSF_AZ_DRIVER_EV_SUBDATA);\n\n\tswitch (ev_sub_code) {\n\tcase FSE_AZ_TX_DESCQ_FLS_DONE_EV:\n\t\tnetif_vdbg(efx, hw, efx->net_dev, \"channel %d TXQ %d flushed\\n\",\n\t\t\t   channel->channel, ev_sub_data);\n\t\tefx_farch_handle_tx_flush_done(efx, event);\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\t\tefx_siena_sriov_tx_flush_done(efx, event);\n#endif\n\t\tbreak;\n\tcase FSE_AZ_RX_DESCQ_FLS_DONE_EV:\n\t\tnetif_vdbg(efx, hw, efx->net_dev, \"channel %d RXQ %d flushed\\n\",\n\t\t\t   channel->channel, ev_sub_data);\n\t\tefx_farch_handle_rx_flush_done(efx, event);\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\t\tefx_siena_sriov_rx_flush_done(efx, event);\n#endif\n\t\tbreak;\n\tcase FSE_AZ_EVQ_INIT_DONE_EV:\n\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t  \"channel %d EVQ %d initialised\\n\",\n\t\t\t  channel->channel, ev_sub_data);\n\t\tbreak;\n\tcase FSE_AZ_SRM_UPD_DONE_EV:\n\t\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t\t   \"channel %d SRAM update done\\n\", channel->channel);\n\t\tbreak;\n\tcase FSE_AZ_WAKE_UP_EV:\n\t\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t\t   \"channel %d RXQ %d wakeup event\\n\",\n\t\t\t   channel->channel, ev_sub_data);\n\t\tbreak;\n\tcase FSE_AZ_TIMER_EV:\n\t\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t\t   \"channel %d RX queue %d timer expired\\n\",\n\t\t\t   channel->channel, ev_sub_data);\n\t\tbreak;\n\tcase FSE_AA_RX_RECOVER_EV:\n\t\tnetif_err(efx, rx_err, efx->net_dev,\n\t\t\t  \"channel %d seen DRIVER RX_RESET event. \"\n\t\t\t\"Resetting.\\n\", channel->channel);\n\t\tatomic_inc(&efx->rx_reset);\n\t\tefx_siena_schedule_reset(efx, RESET_TYPE_DISABLE);\n\t\tbreak;\n\tcase FSE_BZ_RX_DSC_ERROR_EV:\n\t\tif (ev_sub_data < EFX_VI_BASE) {\n\t\t\tnetif_err(efx, rx_err, efx->net_dev,\n\t\t\t\t  \"RX DMA Q %d reports descriptor fetch error.\"\n\t\t\t\t  \" RX Q %d is disabled.\\n\", ev_sub_data,\n\t\t\t\t  ev_sub_data);\n\t\t\tefx_siena_schedule_reset(efx, RESET_TYPE_DMA_ERROR);\n\t\t}\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\t\telse\n\t\t\tefx_siena_sriov_desc_fetch_err(efx, ev_sub_data);\n#endif\n\t\tbreak;\n\tcase FSE_BZ_TX_DSC_ERROR_EV:\n\t\tif (ev_sub_data < EFX_VI_BASE) {\n\t\t\tnetif_err(efx, tx_err, efx->net_dev,\n\t\t\t\t  \"TX DMA Q %d reports descriptor fetch error.\"\n\t\t\t\t  \" TX Q %d is disabled.\\n\", ev_sub_data,\n\t\t\t\t  ev_sub_data);\n\t\t\tefx_siena_schedule_reset(efx, RESET_TYPE_DMA_ERROR);\n\t\t}\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\t\telse\n\t\t\tefx_siena_sriov_desc_fetch_err(efx, ev_sub_data);\n#endif\n\t\tbreak;\n\tdefault:\n\t\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t\t   \"channel %d unknown driver event code %d \"\n\t\t\t   \"data %04x\\n\", channel->channel, ev_sub_code,\n\t\t\t   ev_sub_data);\n\t\tbreak;\n\t}\n}\n\nint efx_farch_ev_process(struct efx_channel *channel, int budget)\n{\n\tstruct efx_nic *efx = channel->efx;\n\tunsigned int read_ptr;\n\tefx_qword_t event, *p_event;\n\tint ev_code;\n\tint spent = 0;\n\n\tif (budget <= 0)\n\t\treturn spent;\n\n\tread_ptr = channel->eventq_read_ptr;\n\n\tfor (;;) {\n\t\tp_event = efx_event(channel, read_ptr);\n\t\tevent = *p_event;\n\n\t\tif (!efx_event_present(&event))\n\t\t\t \n\t\t\tbreak;\n\n\t\tnetif_vdbg(channel->efx, intr, channel->efx->net_dev,\n\t\t\t   \"channel %d event is \"EFX_QWORD_FMT\"\\n\",\n\t\t\t   channel->channel, EFX_QWORD_VAL(event));\n\n\t\t \n\t\tEFX_SET_QWORD(*p_event);\n\n\t\t++read_ptr;\n\n\t\tev_code = EFX_QWORD_FIELD(event, FSF_AZ_EV_CODE);\n\n\t\tswitch (ev_code) {\n\t\tcase FSE_AZ_EV_CODE_RX_EV:\n\t\t\tefx_farch_handle_rx_event(channel, &event);\n\t\t\tif (++spent == budget)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\tcase FSE_AZ_EV_CODE_TX_EV:\n\t\t\tefx_farch_handle_tx_event(channel, &event);\n\t\t\tbreak;\n\t\tcase FSE_AZ_EV_CODE_DRV_GEN_EV:\n\t\t\tefx_farch_handle_generated_event(channel, &event);\n\t\t\tbreak;\n\t\tcase FSE_AZ_EV_CODE_DRIVER_EV:\n\t\t\tefx_farch_handle_driver_event(channel, &event);\n\t\t\tbreak;\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\t\tcase FSE_CZ_EV_CODE_USER_EV:\n\t\t\tefx_siena_sriov_event(channel, &event);\n\t\t\tbreak;\n#endif\n\t\tcase FSE_CZ_EV_CODE_MCDI_EV:\n\t\t\tefx_siena_mcdi_process_event(channel, &event);\n\t\t\tbreak;\n\t\tcase FSE_AZ_EV_CODE_GLOBAL_EV:\n\t\t\tif (efx->type->handle_global_event &&\n\t\t\t    efx->type->handle_global_event(channel, &event))\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tdefault:\n\t\t\tnetif_err(channel->efx, hw, channel->efx->net_dev,\n\t\t\t\t  \"channel %d unknown event type %d (data \"\n\t\t\t\t  EFX_QWORD_FMT \")\\n\", channel->channel,\n\t\t\t\t  ev_code, EFX_QWORD_VAL(event));\n\t\t}\n\t}\n\nout:\n\tchannel->eventq_read_ptr = read_ptr;\n\treturn spent;\n}\n\n \nint efx_farch_ev_probe(struct efx_channel *channel)\n{\n\tstruct efx_nic *efx = channel->efx;\n\tunsigned entries;\n\n\tentries = channel->eventq_mask + 1;\n\treturn efx_alloc_special_buffer(efx, &channel->eventq,\n\t\t\t\t\tentries * sizeof(efx_qword_t));\n}\n\nint efx_farch_ev_init(struct efx_channel *channel)\n{\n\tefx_oword_t reg;\n\tstruct efx_nic *efx = channel->efx;\n\n\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t  \"channel %d event queue in special buffers %d-%d\\n\",\n\t\t  channel->channel, channel->eventq.index,\n\t\t  channel->eventq.index + channel->eventq.entries - 1);\n\n\tEFX_POPULATE_OWORD_3(reg,\n\t\t\t     FRF_CZ_TIMER_Q_EN, 1,\n\t\t\t     FRF_CZ_HOST_NOTIFY_MODE, 0,\n\t\t\t     FRF_CZ_TIMER_MODE, FFE_CZ_TIMER_MODE_DIS);\n\tefx_writeo_table(efx, &reg, FR_BZ_TIMER_TBL, channel->channel);\n\n\t \n\tefx_init_special_buffer(efx, &channel->eventq);\n\n\t \n\tmemset(channel->eventq.buf.addr, 0xff, channel->eventq.buf.len);\n\n\t \n\tEFX_POPULATE_OWORD_3(reg,\n\t\t\t     FRF_AZ_EVQ_EN, 1,\n\t\t\t     FRF_AZ_EVQ_SIZE, __ffs(channel->eventq.entries),\n\t\t\t     FRF_AZ_EVQ_BUF_BASE_ID, channel->eventq.index);\n\tefx_writeo_table(efx, &reg, efx->type->evq_ptr_tbl_base,\n\t\t\t channel->channel);\n\n\treturn 0;\n}\n\nvoid efx_farch_ev_fini(struct efx_channel *channel)\n{\n\tefx_oword_t reg;\n\tstruct efx_nic *efx = channel->efx;\n\n\t \n\tEFX_ZERO_OWORD(reg);\n\tefx_writeo_table(efx, &reg, efx->type->evq_ptr_tbl_base,\n\t\t\t channel->channel);\n\tefx_writeo_table(efx, &reg, FR_BZ_TIMER_TBL, channel->channel);\n\n\t \n\tefx_fini_special_buffer(efx, &channel->eventq);\n}\n\n \nvoid efx_farch_ev_remove(struct efx_channel *channel)\n{\n\tefx_free_special_buffer(channel->efx, &channel->eventq);\n}\n\n\nvoid efx_farch_ev_test_generate(struct efx_channel *channel)\n{\n\tefx_farch_magic_event(channel, EFX_CHANNEL_MAGIC_TEST(channel));\n}\n\nvoid efx_farch_rx_defer_refill(struct efx_rx_queue *rx_queue)\n{\n\tefx_farch_magic_event(efx_rx_queue_channel(rx_queue),\n\t\t\t      EFX_CHANNEL_MAGIC_FILL(rx_queue));\n}\n\n \n\n \nstatic inline void efx_farch_interrupts(struct efx_nic *efx,\n\t\t\t\t      bool enabled, bool force)\n{\n\tefx_oword_t int_en_reg_ker;\n\n\tEFX_POPULATE_OWORD_3(int_en_reg_ker,\n\t\t\t     FRF_AZ_KER_INT_LEVE_SEL, efx->irq_level,\n\t\t\t     FRF_AZ_KER_INT_KER, force,\n\t\t\t     FRF_AZ_DRV_INT_EN_KER, enabled);\n\tefx_writeo(efx, &int_en_reg_ker, FR_AZ_INT_EN_KER);\n}\n\nvoid efx_farch_irq_enable_master(struct efx_nic *efx)\n{\n\tEFX_ZERO_OWORD(*((efx_oword_t *) efx->irq_status.addr));\n\twmb();  \n\n\tefx_farch_interrupts(efx, true, false);\n}\n\nvoid efx_farch_irq_disable_master(struct efx_nic *efx)\n{\n\t \n\tefx_farch_interrupts(efx, false, false);\n}\n\n \nint efx_farch_irq_test_generate(struct efx_nic *efx)\n{\n\tefx_farch_interrupts(efx, true, true);\n\treturn 0;\n}\n\n \nirqreturn_t efx_farch_fatal_interrupt(struct efx_nic *efx)\n{\n\tefx_oword_t *int_ker = efx->irq_status.addr;\n\tefx_oword_t fatal_intr;\n\tint error, mem_perr;\n\n\tefx_reado(efx, &fatal_intr, FR_AZ_FATAL_INTR_KER);\n\terror = EFX_OWORD_FIELD(fatal_intr, FRF_AZ_FATAL_INTR);\n\n\tnetif_err(efx, hw, efx->net_dev, \"SYSTEM ERROR \"EFX_OWORD_FMT\" status \"\n\t\t  EFX_OWORD_FMT \": %s\\n\", EFX_OWORD_VAL(*int_ker),\n\t\t  EFX_OWORD_VAL(fatal_intr),\n\t\t  error ? \"disabling bus mastering\" : \"no recognised error\");\n\n\t \n\tmem_perr = (EFX_OWORD_FIELD(fatal_intr, FRF_AZ_MEM_PERR_INT_KER) ||\n\t\t    EFX_OWORD_FIELD(fatal_intr, FRF_AZ_SRM_PERR_INT_KER));\n\tif (mem_perr) {\n\t\tefx_oword_t reg;\n\t\tefx_reado(efx, &reg, FR_AZ_MEM_STAT);\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"SYSTEM ERROR: memory parity error \"EFX_OWORD_FMT\"\\n\",\n\t\t\t  EFX_OWORD_VAL(reg));\n\t}\n\n\t \n\tpci_clear_master(efx->pci_dev);\n\tefx_farch_irq_disable_master(efx);\n\n\t \n\tif (efx->int_error_count == 0 ||\n\t    time_after(jiffies, efx->int_error_expire)) {\n\t\tefx->int_error_count = 0;\n\t\tefx->int_error_expire =\n\t\t\tjiffies + EFX_INT_ERROR_EXPIRE * HZ;\n\t}\n\tif (++efx->int_error_count < EFX_MAX_INT_ERRORS) {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"SYSTEM ERROR - reset scheduled\\n\");\n\t\tefx_siena_schedule_reset(efx, RESET_TYPE_INT_ERROR);\n\t} else {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"SYSTEM ERROR - max number of errors seen.\"\n\t\t\t  \"NIC will be disabled\\n\");\n\t\tefx_siena_schedule_reset(efx, RESET_TYPE_DISABLE);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n \nirqreturn_t efx_farch_legacy_interrupt(int irq, void *dev_id)\n{\n\tstruct efx_nic *efx = dev_id;\n\tbool soft_enabled = READ_ONCE(efx->irq_soft_enabled);\n\tefx_oword_t *int_ker = efx->irq_status.addr;\n\tirqreturn_t result = IRQ_NONE;\n\tstruct efx_channel *channel;\n\tefx_dword_t reg;\n\tu32 queues;\n\tint syserr;\n\n\t \n\tefx_readd(efx, &reg, FR_BZ_INT_ISR0);\n\tqueues = EFX_EXTRACT_DWORD(reg, 0, 31);\n\n\t \n\tif (EFX_DWORD_IS_ALL_ONES(reg) && efx_siena_try_recovery(efx) &&\n\t    !efx->eeh_disabled_legacy_irq) {\n\t\tdisable_irq_nosync(efx->legacy_irq);\n\t\tefx->eeh_disabled_legacy_irq = true;\n\t}\n\n\t \n\tif (queues & (1U << efx->irq_level) && soft_enabled) {\n\t\tsyserr = EFX_OWORD_FIELD(*int_ker, FSF_AZ_NET_IVEC_FATAL_INT);\n\t\tif (unlikely(syserr))\n\t\t\treturn efx_farch_fatal_interrupt(efx);\n\t\tefx->last_irq_cpu = raw_smp_processor_id();\n\t}\n\n\tif (queues != 0) {\n\t\tefx->irq_zero_count = 0;\n\n\t\t \n\t\tif (likely(soft_enabled)) {\n\t\t\tefx_for_each_channel(channel, efx) {\n\t\t\t\tif (queues & 1)\n\t\t\t\t\tefx_schedule_channel_irq(channel);\n\t\t\t\tqueues >>= 1;\n\t\t\t}\n\t\t}\n\t\tresult = IRQ_HANDLED;\n\n\t} else {\n\t\tefx_qword_t *event;\n\n\t\t \n\n\t\t \n\t\tif (efx->irq_zero_count++ == 0)\n\t\t\tresult = IRQ_HANDLED;\n\n\t\t \n\t\tif (likely(soft_enabled)) {\n\t\t\tefx_for_each_channel(channel, efx) {\n\t\t\t\tevent = efx_event(channel,\n\t\t\t\t\t\t  channel->eventq_read_ptr);\n\t\t\t\tif (efx_event_present(event))\n\t\t\t\t\tefx_schedule_channel_irq(channel);\n\t\t\t\telse\n\t\t\t\t\tefx_farch_ev_read_ack(channel);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (result == IRQ_HANDLED)\n\t\tnetif_vdbg(efx, intr, efx->net_dev,\n\t\t\t   \"IRQ %d on CPU %d status \" EFX_DWORD_FMT \"\\n\",\n\t\t\t   irq, raw_smp_processor_id(), EFX_DWORD_VAL(reg));\n\n\treturn result;\n}\n\n \nirqreturn_t efx_farch_msi_interrupt(int irq, void *dev_id)\n{\n\tstruct efx_msi_context *context = dev_id;\n\tstruct efx_nic *efx = context->efx;\n\tefx_oword_t *int_ker = efx->irq_status.addr;\n\tint syserr;\n\n\tnetif_vdbg(efx, intr, efx->net_dev,\n\t\t   \"IRQ %d on CPU %d status \" EFX_OWORD_FMT \"\\n\",\n\t\t   irq, raw_smp_processor_id(), EFX_OWORD_VAL(*int_ker));\n\n\tif (!likely(READ_ONCE(efx->irq_soft_enabled)))\n\t\treturn IRQ_HANDLED;\n\n\t \n\tif (context->index == efx->irq_level) {\n\t\tsyserr = EFX_OWORD_FIELD(*int_ker, FSF_AZ_NET_IVEC_FATAL_INT);\n\t\tif (unlikely(syserr))\n\t\t\treturn efx_farch_fatal_interrupt(efx);\n\t\tefx->last_irq_cpu = raw_smp_processor_id();\n\t}\n\n\t \n\tefx_schedule_channel_irq(efx->channel[context->index]);\n\n\treturn IRQ_HANDLED;\n}\n\n \nvoid efx_farch_rx_push_indir_table(struct efx_nic *efx)\n{\n\tsize_t i = 0;\n\tefx_dword_t dword;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(efx->rss_context.rx_indir_table) !=\n\t\t     FR_BZ_RX_INDIRECTION_TBL_ROWS);\n\n\tfor (i = 0; i < FR_BZ_RX_INDIRECTION_TBL_ROWS; i++) {\n\t\tEFX_POPULATE_DWORD_1(dword, FRF_BZ_IT_QUEUE,\n\t\t\t\t     efx->rss_context.rx_indir_table[i]);\n\t\tefx_writed(efx, &dword,\n\t\t\t   FR_BZ_RX_INDIRECTION_TBL +\n\t\t\t   FR_BZ_RX_INDIRECTION_TBL_STEP * i);\n\t}\n}\n\nvoid efx_farch_rx_pull_indir_table(struct efx_nic *efx)\n{\n\tsize_t i = 0;\n\tefx_dword_t dword;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(efx->rss_context.rx_indir_table) !=\n\t\t     FR_BZ_RX_INDIRECTION_TBL_ROWS);\n\n\tfor (i = 0; i < FR_BZ_RX_INDIRECTION_TBL_ROWS; i++) {\n\t\tefx_readd(efx, &dword,\n\t\t\t   FR_BZ_RX_INDIRECTION_TBL +\n\t\t\t   FR_BZ_RX_INDIRECTION_TBL_STEP * i);\n\t\tefx->rss_context.rx_indir_table[i] = EFX_DWORD_FIELD(dword, FRF_BZ_IT_QUEUE);\n\t}\n}\n\n \nvoid efx_farch_dimension_resources(struct efx_nic *efx, unsigned sram_lim_qw)\n{\n\tunsigned vi_count, total_tx_channels;\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\tstruct siena_nic_data *nic_data;\n\tunsigned buftbl_min;\n#endif\n\n\ttotal_tx_channels = efx->n_tx_channels + efx->n_extra_tx_channels;\n\tvi_count = max(efx->n_channels, total_tx_channels * EFX_MAX_TXQ_PER_CHANNEL);\n\n#ifdef CONFIG_SFC_SIENA_SRIOV\n\tnic_data = efx->nic_data;\n\t \n\tbuftbl_min = ((efx->n_rx_channels * EFX_MAX_DMAQ_SIZE +\n\t\t       total_tx_channels * EFX_MAX_TXQ_PER_CHANNEL * EFX_MAX_DMAQ_SIZE +\n\t\t       efx->n_channels * EFX_MAX_EVQ_SIZE)\n\t\t      * sizeof(efx_qword_t) / EFX_BUF_SIZE);\n\tif (efx->type->sriov_wanted) {\n\t\tif (efx->type->sriov_wanted(efx)) {\n\t\t\tunsigned vi_dc_entries, buftbl_free;\n\t\t\tunsigned entries_per_vf, vf_limit;\n\n\t\t\tnic_data->vf_buftbl_base = buftbl_min;\n\n\t\t\tvi_dc_entries = RX_DC_ENTRIES + TX_DC_ENTRIES;\n\t\t\tvi_count = max(vi_count, EFX_VI_BASE);\n\t\t\tbuftbl_free = (sram_lim_qw - buftbl_min -\n\t\t\t\t       vi_count * vi_dc_entries);\n\n\t\t\tentries_per_vf = ((vi_dc_entries +\n\t\t\t\t\t   EFX_VF_BUFTBL_PER_VI) *\n\t\t\t\t\t  efx_vf_size(efx));\n\t\t\tvf_limit = min(buftbl_free / entries_per_vf,\n\t\t\t\t       (1024U - EFX_VI_BASE) >> efx->vi_scale);\n\n\t\t\tif (efx->vf_count > vf_limit) {\n\t\t\t\tnetif_err(efx, probe, efx->net_dev,\n\t\t\t\t\t  \"Reducing VF count from from %d to %d\\n\",\n\t\t\t\t\t  efx->vf_count, vf_limit);\n\t\t\t\tefx->vf_count = vf_limit;\n\t\t\t}\n\t\t\tvi_count += efx->vf_count * efx_vf_size(efx);\n\t\t}\n\t}\n#endif\n\n\tefx->tx_dc_base = sram_lim_qw - vi_count * TX_DC_ENTRIES;\n\tefx->rx_dc_base = efx->tx_dc_base - vi_count * RX_DC_ENTRIES;\n}\n\nu32 efx_farch_fpga_ver(struct efx_nic *efx)\n{\n\tefx_oword_t altera_build;\n\tefx_reado(efx, &altera_build, FR_AZ_ALTERA_BUILD);\n\treturn EFX_OWORD_FIELD(altera_build, FRF_AZ_ALTERA_BUILD_VER);\n}\n\nvoid efx_farch_init_common(struct efx_nic *efx)\n{\n\tefx_oword_t temp;\n\n\t \n\tEFX_POPULATE_OWORD_1(temp, FRF_AZ_SRM_TX_DC_BASE_ADR, efx->tx_dc_base);\n\tefx_writeo(efx, &temp, FR_AZ_SRM_TX_DC_CFG);\n\tEFX_POPULATE_OWORD_1(temp, FRF_AZ_SRM_RX_DC_BASE_ADR, efx->rx_dc_base);\n\tefx_writeo(efx, &temp, FR_AZ_SRM_RX_DC_CFG);\n\n\t \n\tBUILD_BUG_ON(TX_DC_ENTRIES != (8 << TX_DC_ENTRIES_ORDER));\n\tEFX_POPULATE_OWORD_1(temp, FRF_AZ_TX_DC_SIZE, TX_DC_ENTRIES_ORDER);\n\tefx_writeo(efx, &temp, FR_AZ_TX_DC_CFG);\n\n\t \n\tBUILD_BUG_ON(RX_DC_ENTRIES != (8 << RX_DC_ENTRIES_ORDER));\n\tEFX_POPULATE_OWORD_1(temp, FRF_AZ_RX_DC_SIZE, RX_DC_ENTRIES_ORDER);\n\tefx_writeo(efx, &temp, FR_AZ_RX_DC_CFG);\n\tEFX_POPULATE_OWORD_1(temp, FRF_AZ_RX_DC_PF_LWM, RX_DC_ENTRIES - 8);\n\tefx_writeo(efx, &temp, FR_AZ_RX_DC_PF_WM);\n\n\t \n\tEFX_POPULATE_OWORD_2(temp,\n\t\t\t     FRF_AZ_NORM_INT_VEC_DIS_KER,\n\t\t\t     EFX_INT_MODE_USE_MSI(efx),\n\t\t\t     FRF_AZ_INT_ADR_KER, efx->irq_status.dma_addr);\n\tefx_writeo(efx, &temp, FR_AZ_INT_ADR_KER);\n\n\tif (EFX_WORKAROUND_17213(efx) && !EFX_INT_MODE_USE_MSI(efx))\n\t\t \n\t\tefx->irq_level = 0x1f;\n\telse\n\t\t \n\t\tefx->irq_level = 0;\n\n\t \n\tEFX_POPULATE_OWORD_3(temp,\n\t\t\t     FRF_AZ_ILL_ADR_INT_KER_EN, 1,\n\t\t\t     FRF_AZ_RBUF_OWN_INT_KER_EN, 1,\n\t\t\t     FRF_AZ_TBUF_OWN_INT_KER_EN, 1);\n\tEFX_SET_OWORD_FIELD(temp, FRF_CZ_SRAM_PERR_INT_P_KER_EN, 1);\n\tEFX_INVERT_OWORD(temp);\n\tefx_writeo(efx, &temp, FR_AZ_FATAL_INTR_KER);\n\n\t \n\tefx_reado(efx, &temp, FR_AZ_TX_RESERVED);\n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_RX_SPACER, 0xfe);\n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_RX_SPACER_EN, 1);\n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_ONE_PKT_PER_Q, 1);\n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_PUSH_EN, 1);\n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_DIS_NON_IP_EV, 1);\n\t \n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_SOFT_EVT_EN, 1);\n\t \n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_PREF_THRESHOLD, 2);\n\t \n\tEFX_SET_OWORD_FIELD(temp, FRF_AZ_TX_PREF_WD_TMR, 0x3fffff);\n\t \n\tEFX_SET_OWORD_FIELD(temp, FRF_BZ_TX_FLUSH_MIN_LEN_EN, 1);\n\tefx_writeo(efx, &temp, FR_AZ_TX_RESERVED);\n\n\tEFX_POPULATE_OWORD_4(temp,\n\t\t\t      \n\t\t\t     FRF_BZ_TX_PACE_SB_NOT_AF, 0x15,\n\t\t\t     FRF_BZ_TX_PACE_SB_AF, 0xb,\n\t\t\t     FRF_BZ_TX_PACE_FB_BASE, 0,\n\t\t\t      \n\t\t\t     FRF_BZ_TX_PACE_BIN_TH,\n\t\t\t     FFE_BZ_TX_PACE_RESERVED);\n\tefx_writeo(efx, &temp, FR_BZ_TX_PACE);\n}\n\n \n\n \n#define EFX_FARCH_FILTER_CTL_SRCH_FUDGE_WILD 3\n#define EFX_FARCH_FILTER_CTL_SRCH_FUDGE_FULL 1\n\n \n#define EFX_FARCH_FILTER_CTL_SRCH_MAX 200\n\n \n#define EFX_FARCH_FILTER_CTL_SRCH_HINT_MAX 5\n\nenum efx_farch_filter_type {\n\tEFX_FARCH_FILTER_TCP_FULL = 0,\n\tEFX_FARCH_FILTER_TCP_WILD,\n\tEFX_FARCH_FILTER_UDP_FULL,\n\tEFX_FARCH_FILTER_UDP_WILD,\n\tEFX_FARCH_FILTER_MAC_FULL = 4,\n\tEFX_FARCH_FILTER_MAC_WILD,\n\tEFX_FARCH_FILTER_UC_DEF = 8,\n\tEFX_FARCH_FILTER_MC_DEF,\n\tEFX_FARCH_FILTER_TYPE_COUNT,\t\t \n};\n\nenum efx_farch_filter_table_id {\n\tEFX_FARCH_FILTER_TABLE_RX_IP = 0,\n\tEFX_FARCH_FILTER_TABLE_RX_MAC,\n\tEFX_FARCH_FILTER_TABLE_RX_DEF,\n\tEFX_FARCH_FILTER_TABLE_TX_MAC,\n\tEFX_FARCH_FILTER_TABLE_COUNT,\n};\n\nenum efx_farch_filter_index {\n\tEFX_FARCH_FILTER_INDEX_UC_DEF,\n\tEFX_FARCH_FILTER_INDEX_MC_DEF,\n\tEFX_FARCH_FILTER_SIZE_RX_DEF,\n};\n\nstruct efx_farch_filter_spec {\n\tu8\ttype:4;\n\tu8\tpriority:4;\n\tu8\tflags;\n\tu16\tdmaq_id;\n\tu32\tdata[3];\n};\n\nstruct efx_farch_filter_table {\n\tenum efx_farch_filter_table_id id;\n\tu32\t\toffset;\t\t \n\tunsigned\tsize;\t\t \n\tunsigned\tstep;\t\t \n\tunsigned\tused;\t\t \n\tunsigned long\t*used_bitmap;\n\tstruct efx_farch_filter_spec *spec;\n\tunsigned\tsearch_limit[EFX_FARCH_FILTER_TYPE_COUNT];\n};\n\nstruct efx_farch_filter_state {\n\tstruct rw_semaphore lock;  \n\tstruct efx_farch_filter_table table[EFX_FARCH_FILTER_TABLE_COUNT];\n};\n\nstatic void\nefx_farch_filter_table_clear_entry(struct efx_nic *efx,\n\t\t\t\t   struct efx_farch_filter_table *table,\n\t\t\t\t   unsigned int filter_idx);\n\n \nstatic u16 efx_farch_filter_hash(u32 key)\n{\n\tu16 tmp;\n\n\t \n\ttmp = 0x1fff ^ key >> 16;\n\ttmp = tmp ^ tmp >> 3 ^ tmp >> 6;\n\ttmp = tmp ^ tmp >> 9;\n\t \n\ttmp = tmp ^ tmp << 13 ^ key;\n\ttmp = tmp ^ tmp >> 3 ^ tmp >> 6;\n\treturn tmp ^ tmp >> 9;\n}\n\n \nstatic u16 efx_farch_filter_increment(u32 key)\n{\n\treturn key * 2 - 1;\n}\n\nstatic enum efx_farch_filter_table_id\nefx_farch_filter_spec_table_id(const struct efx_farch_filter_spec *spec)\n{\n\tBUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP !=\n\t\t     (EFX_FARCH_FILTER_TCP_FULL >> 2));\n\tBUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP !=\n\t\t     (EFX_FARCH_FILTER_TCP_WILD >> 2));\n\tBUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP !=\n\t\t     (EFX_FARCH_FILTER_UDP_FULL >> 2));\n\tBUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_IP !=\n\t\t     (EFX_FARCH_FILTER_UDP_WILD >> 2));\n\tBUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_MAC !=\n\t\t     (EFX_FARCH_FILTER_MAC_FULL >> 2));\n\tBUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_RX_MAC !=\n\t\t     (EFX_FARCH_FILTER_MAC_WILD >> 2));\n\tBUILD_BUG_ON(EFX_FARCH_FILTER_TABLE_TX_MAC !=\n\t\t     EFX_FARCH_FILTER_TABLE_RX_MAC + 2);\n\treturn (spec->type >> 2) + ((spec->flags & EFX_FILTER_FLAG_TX) ? 2 : 0);\n}\n\nstatic void efx_farch_filter_push_rx_config(struct efx_nic *efx)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tstruct efx_farch_filter_table *table;\n\tefx_oword_t filter_ctl;\n\n\tefx_reado(efx, &filter_ctl, FR_BZ_RX_FILTER_CTL);\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_IP];\n\tEFX_SET_OWORD_FIELD(filter_ctl, FRF_BZ_TCP_FULL_SRCH_LIMIT,\n\t\t\t    table->search_limit[EFX_FARCH_FILTER_TCP_FULL] +\n\t\t\t    EFX_FARCH_FILTER_CTL_SRCH_FUDGE_FULL);\n\tEFX_SET_OWORD_FIELD(filter_ctl, FRF_BZ_TCP_WILD_SRCH_LIMIT,\n\t\t\t    table->search_limit[EFX_FARCH_FILTER_TCP_WILD] +\n\t\t\t    EFX_FARCH_FILTER_CTL_SRCH_FUDGE_WILD);\n\tEFX_SET_OWORD_FIELD(filter_ctl, FRF_BZ_UDP_FULL_SRCH_LIMIT,\n\t\t\t    table->search_limit[EFX_FARCH_FILTER_UDP_FULL] +\n\t\t\t    EFX_FARCH_FILTER_CTL_SRCH_FUDGE_FULL);\n\tEFX_SET_OWORD_FIELD(filter_ctl, FRF_BZ_UDP_WILD_SRCH_LIMIT,\n\t\t\t    table->search_limit[EFX_FARCH_FILTER_UDP_WILD] +\n\t\t\t    EFX_FARCH_FILTER_CTL_SRCH_FUDGE_WILD);\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_MAC];\n\tif (table->size) {\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_CZ_ETHERNET_FULL_SEARCH_LIMIT,\n\t\t\ttable->search_limit[EFX_FARCH_FILTER_MAC_FULL] +\n\t\t\tEFX_FARCH_FILTER_CTL_SRCH_FUDGE_FULL);\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_CZ_ETHERNET_WILDCARD_SEARCH_LIMIT,\n\t\t\ttable->search_limit[EFX_FARCH_FILTER_MAC_WILD] +\n\t\t\tEFX_FARCH_FILTER_CTL_SRCH_FUDGE_WILD);\n\t}\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_DEF];\n\tif (table->size) {\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_CZ_UNICAST_NOMATCH_Q_ID,\n\t\t\ttable->spec[EFX_FARCH_FILTER_INDEX_UC_DEF].dmaq_id);\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_CZ_UNICAST_NOMATCH_RSS_ENABLED,\n\t\t\t!!(table->spec[EFX_FARCH_FILTER_INDEX_UC_DEF].flags &\n\t\t\t   EFX_FILTER_FLAG_RX_RSS));\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_CZ_MULTICAST_NOMATCH_Q_ID,\n\t\t\ttable->spec[EFX_FARCH_FILTER_INDEX_MC_DEF].dmaq_id);\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_CZ_MULTICAST_NOMATCH_RSS_ENABLED,\n\t\t\t!!(table->spec[EFX_FARCH_FILTER_INDEX_MC_DEF].flags &\n\t\t\t   EFX_FILTER_FLAG_RX_RSS));\n\n\t\t \n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_BZ_SCATTER_ENBL_NO_MATCH_Q,\n\t\t\t!!(table->spec[EFX_FARCH_FILTER_INDEX_UC_DEF].flags &\n\t\t\t   table->spec[EFX_FARCH_FILTER_INDEX_MC_DEF].flags &\n\t\t\t   EFX_FILTER_FLAG_RX_SCATTER));\n\t} else {\n\t\t \n\t\tEFX_SET_OWORD_FIELD(\n\t\t\tfilter_ctl, FRF_BZ_SCATTER_ENBL_NO_MATCH_Q,\n\t\t\tefx->rx_scatter);\n\t}\n\n\tefx_writeo(efx, &filter_ctl, FR_BZ_RX_FILTER_CTL);\n}\n\nstatic void efx_farch_filter_push_tx_limits(struct efx_nic *efx)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tstruct efx_farch_filter_table *table;\n\tefx_oword_t tx_cfg;\n\n\tefx_reado(efx, &tx_cfg, FR_AZ_TX_CFG);\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_TX_MAC];\n\tif (table->size) {\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\ttx_cfg, FRF_CZ_TX_ETH_FILTER_FULL_SEARCH_RANGE,\n\t\t\ttable->search_limit[EFX_FARCH_FILTER_MAC_FULL] +\n\t\t\tEFX_FARCH_FILTER_CTL_SRCH_FUDGE_FULL);\n\t\tEFX_SET_OWORD_FIELD(\n\t\t\ttx_cfg, FRF_CZ_TX_ETH_FILTER_WILD_SEARCH_RANGE,\n\t\t\ttable->search_limit[EFX_FARCH_FILTER_MAC_WILD] +\n\t\t\tEFX_FARCH_FILTER_CTL_SRCH_FUDGE_WILD);\n\t}\n\n\tefx_writeo(efx, &tx_cfg, FR_AZ_TX_CFG);\n}\n\nstatic int\nefx_farch_filter_from_gen_spec(struct efx_farch_filter_spec *spec,\n\t\t\t       const struct efx_filter_spec *gen_spec)\n{\n\tbool is_full = false;\n\n\tif ((gen_spec->flags & EFX_FILTER_FLAG_RX_RSS) && gen_spec->rss_context)\n\t\treturn -EINVAL;\n\n\tspec->priority = gen_spec->priority;\n\tspec->flags = gen_spec->flags;\n\tspec->dmaq_id = gen_spec->dmaq_id;\n\n\tswitch (gen_spec->match_flags) {\n\tcase (EFX_FILTER_MATCH_ETHER_TYPE | EFX_FILTER_MATCH_IP_PROTO |\n\t      EFX_FILTER_MATCH_LOC_HOST | EFX_FILTER_MATCH_LOC_PORT |\n\t      EFX_FILTER_MATCH_REM_HOST | EFX_FILTER_MATCH_REM_PORT):\n\t\tis_full = true;\n\t\tfallthrough;\n\tcase (EFX_FILTER_MATCH_ETHER_TYPE | EFX_FILTER_MATCH_IP_PROTO |\n\t      EFX_FILTER_MATCH_LOC_HOST | EFX_FILTER_MATCH_LOC_PORT): {\n\t\t__be32 rhost, host1, host2;\n\t\t__be16 rport, port1, port2;\n\n\t\tEFX_WARN_ON_PARANOID(!(gen_spec->flags & EFX_FILTER_FLAG_RX));\n\n\t\tif (gen_spec->ether_type != htons(ETH_P_IP))\n\t\t\treturn -EPROTONOSUPPORT;\n\t\tif (gen_spec->loc_port == 0 ||\n\t\t    (is_full && gen_spec->rem_port == 0))\n\t\t\treturn -EADDRNOTAVAIL;\n\t\tswitch (gen_spec->ip_proto) {\n\t\tcase IPPROTO_TCP:\n\t\t\tspec->type = (is_full ? EFX_FARCH_FILTER_TCP_FULL :\n\t\t\t\t      EFX_FARCH_FILTER_TCP_WILD);\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\t\tspec->type = (is_full ? EFX_FARCH_FILTER_UDP_FULL :\n\t\t\t\t      EFX_FARCH_FILTER_UDP_WILD);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EPROTONOSUPPORT;\n\t\t}\n\n\t\t \n\t\trhost = is_full ? gen_spec->rem_host[0] : 0;\n\t\trport = is_full ? gen_spec->rem_port : 0;\n\t\thost1 = rhost;\n\t\thost2 = gen_spec->loc_host[0];\n\t\tif (!is_full && gen_spec->ip_proto == IPPROTO_UDP) {\n\t\t\tport1 = gen_spec->loc_port;\n\t\t\tport2 = rport;\n\t\t} else {\n\t\t\tport1 = rport;\n\t\t\tport2 = gen_spec->loc_port;\n\t\t}\n\t\tspec->data[0] = ntohl(host1) << 16 | ntohs(port1);\n\t\tspec->data[1] = ntohs(port2) << 16 | ntohl(host1) >> 16;\n\t\tspec->data[2] = ntohl(host2);\n\n\t\tbreak;\n\t}\n\n\tcase EFX_FILTER_MATCH_LOC_MAC | EFX_FILTER_MATCH_OUTER_VID:\n\t\tis_full = true;\n\t\tfallthrough;\n\tcase EFX_FILTER_MATCH_LOC_MAC:\n\t\tspec->type = (is_full ? EFX_FARCH_FILTER_MAC_FULL :\n\t\t\t      EFX_FARCH_FILTER_MAC_WILD);\n\t\tspec->data[0] = is_full ? ntohs(gen_spec->outer_vid) : 0;\n\t\tspec->data[1] = (gen_spec->loc_mac[2] << 24 |\n\t\t\t\t gen_spec->loc_mac[3] << 16 |\n\t\t\t\t gen_spec->loc_mac[4] << 8 |\n\t\t\t\t gen_spec->loc_mac[5]);\n\t\tspec->data[2] = (gen_spec->loc_mac[0] << 8 |\n\t\t\t\t gen_spec->loc_mac[1]);\n\t\tbreak;\n\n\tcase EFX_FILTER_MATCH_LOC_MAC_IG:\n\t\tspec->type = (is_multicast_ether_addr(gen_spec->loc_mac) ?\n\t\t\t      EFX_FARCH_FILTER_MC_DEF :\n\t\t\t      EFX_FARCH_FILTER_UC_DEF);\n\t\tmemset(spec->data, 0, sizeof(spec->data));  \n\t\tbreak;\n\n\tdefault:\n\t\treturn -EPROTONOSUPPORT;\n\t}\n\n\treturn 0;\n}\n\nstatic void\nefx_farch_filter_to_gen_spec(struct efx_filter_spec *gen_spec,\n\t\t\t     const struct efx_farch_filter_spec *spec)\n{\n\tbool is_full = false;\n\n\t \n\tmemset(gen_spec, 0, sizeof(*gen_spec));\n\n\tgen_spec->priority = spec->priority;\n\tgen_spec->flags = spec->flags;\n\tgen_spec->dmaq_id = spec->dmaq_id;\n\n\tswitch (spec->type) {\n\tcase EFX_FARCH_FILTER_TCP_FULL:\n\tcase EFX_FARCH_FILTER_UDP_FULL:\n\t\tis_full = true;\n\t\tfallthrough;\n\tcase EFX_FARCH_FILTER_TCP_WILD:\n\tcase EFX_FARCH_FILTER_UDP_WILD: {\n\t\t__be32 host1, host2;\n\t\t__be16 port1, port2;\n\n\t\tgen_spec->match_flags =\n\t\t\tEFX_FILTER_MATCH_ETHER_TYPE |\n\t\t\tEFX_FILTER_MATCH_IP_PROTO |\n\t\t\tEFX_FILTER_MATCH_LOC_HOST | EFX_FILTER_MATCH_LOC_PORT;\n\t\tif (is_full)\n\t\t\tgen_spec->match_flags |= (EFX_FILTER_MATCH_REM_HOST |\n\t\t\t\t\t\t  EFX_FILTER_MATCH_REM_PORT);\n\t\tgen_spec->ether_type = htons(ETH_P_IP);\n\t\tgen_spec->ip_proto =\n\t\t\t(spec->type == EFX_FARCH_FILTER_TCP_FULL ||\n\t\t\t spec->type == EFX_FARCH_FILTER_TCP_WILD) ?\n\t\t\tIPPROTO_TCP : IPPROTO_UDP;\n\n\t\thost1 = htonl(spec->data[0] >> 16 | spec->data[1] << 16);\n\t\tport1 = htons(spec->data[0]);\n\t\thost2 = htonl(spec->data[2]);\n\t\tport2 = htons(spec->data[1] >> 16);\n\t\tif (spec->flags & EFX_FILTER_FLAG_TX) {\n\t\t\tgen_spec->loc_host[0] = host1;\n\t\t\tgen_spec->rem_host[0] = host2;\n\t\t} else {\n\t\t\tgen_spec->loc_host[0] = host2;\n\t\t\tgen_spec->rem_host[0] = host1;\n\t\t}\n\t\tif (!!(gen_spec->flags & EFX_FILTER_FLAG_TX) ^\n\t\t    (!is_full && gen_spec->ip_proto == IPPROTO_UDP)) {\n\t\t\tgen_spec->loc_port = port1;\n\t\t\tgen_spec->rem_port = port2;\n\t\t} else {\n\t\t\tgen_spec->loc_port = port2;\n\t\t\tgen_spec->rem_port = port1;\n\t\t}\n\n\t\tbreak;\n\t}\n\n\tcase EFX_FARCH_FILTER_MAC_FULL:\n\t\tis_full = true;\n\t\tfallthrough;\n\tcase EFX_FARCH_FILTER_MAC_WILD:\n\t\tgen_spec->match_flags = EFX_FILTER_MATCH_LOC_MAC;\n\t\tif (is_full)\n\t\t\tgen_spec->match_flags |= EFX_FILTER_MATCH_OUTER_VID;\n\t\tgen_spec->loc_mac[0] = spec->data[2] >> 8;\n\t\tgen_spec->loc_mac[1] = spec->data[2];\n\t\tgen_spec->loc_mac[2] = spec->data[1] >> 24;\n\t\tgen_spec->loc_mac[3] = spec->data[1] >> 16;\n\t\tgen_spec->loc_mac[4] = spec->data[1] >> 8;\n\t\tgen_spec->loc_mac[5] = spec->data[1];\n\t\tgen_spec->outer_vid = htons(spec->data[0]);\n\t\tbreak;\n\n\tcase EFX_FARCH_FILTER_UC_DEF:\n\tcase EFX_FARCH_FILTER_MC_DEF:\n\t\tgen_spec->match_flags = EFX_FILTER_MATCH_LOC_MAC_IG;\n\t\tgen_spec->loc_mac[0] = spec->type == EFX_FARCH_FILTER_MC_DEF;\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t\tbreak;\n\t}\n}\n\nstatic void\nefx_farch_filter_init_rx_auto(struct efx_nic *efx,\n\t\t\t      struct efx_farch_filter_spec *spec)\n{\n\t \n\tspec->priority = EFX_FILTER_PRI_AUTO;\n\tspec->flags = (EFX_FILTER_FLAG_RX |\n\t\t       (efx_rss_enabled(efx) ? EFX_FILTER_FLAG_RX_RSS : 0) |\n\t\t       (efx->rx_scatter ? EFX_FILTER_FLAG_RX_SCATTER : 0));\n\tspec->dmaq_id = 0;\n}\n\n \nstatic u32 efx_farch_filter_build(efx_oword_t *filter,\n\t\t\t\t  struct efx_farch_filter_spec *spec)\n{\n\tu32 data3;\n\n\tswitch (efx_farch_filter_spec_table_id(spec)) {\n\tcase EFX_FARCH_FILTER_TABLE_RX_IP: {\n\t\tbool is_udp = (spec->type == EFX_FARCH_FILTER_UDP_FULL ||\n\t\t\t       spec->type == EFX_FARCH_FILTER_UDP_WILD);\n\t\tEFX_POPULATE_OWORD_7(\n\t\t\t*filter,\n\t\t\tFRF_BZ_RSS_EN,\n\t\t\t!!(spec->flags & EFX_FILTER_FLAG_RX_RSS),\n\t\t\tFRF_BZ_SCATTER_EN,\n\t\t\t!!(spec->flags & EFX_FILTER_FLAG_RX_SCATTER),\n\t\t\tFRF_BZ_TCP_UDP, is_udp,\n\t\t\tFRF_BZ_RXQ_ID, spec->dmaq_id,\n\t\t\tEFX_DWORD_2, spec->data[2],\n\t\t\tEFX_DWORD_1, spec->data[1],\n\t\t\tEFX_DWORD_0, spec->data[0]);\n\t\tdata3 = is_udp;\n\t\tbreak;\n\t}\n\n\tcase EFX_FARCH_FILTER_TABLE_RX_MAC: {\n\t\tbool is_wild = spec->type == EFX_FARCH_FILTER_MAC_WILD;\n\t\tEFX_POPULATE_OWORD_7(\n\t\t\t*filter,\n\t\t\tFRF_CZ_RMFT_RSS_EN,\n\t\t\t!!(spec->flags & EFX_FILTER_FLAG_RX_RSS),\n\t\t\tFRF_CZ_RMFT_SCATTER_EN,\n\t\t\t!!(spec->flags & EFX_FILTER_FLAG_RX_SCATTER),\n\t\t\tFRF_CZ_RMFT_RXQ_ID, spec->dmaq_id,\n\t\t\tFRF_CZ_RMFT_WILDCARD_MATCH, is_wild,\n\t\t\tFRF_CZ_RMFT_DEST_MAC_HI, spec->data[2],\n\t\t\tFRF_CZ_RMFT_DEST_MAC_LO, spec->data[1],\n\t\t\tFRF_CZ_RMFT_VLAN_ID, spec->data[0]);\n\t\tdata3 = is_wild;\n\t\tbreak;\n\t}\n\n\tcase EFX_FARCH_FILTER_TABLE_TX_MAC: {\n\t\tbool is_wild = spec->type == EFX_FARCH_FILTER_MAC_WILD;\n\t\tEFX_POPULATE_OWORD_5(*filter,\n\t\t\t\t     FRF_CZ_TMFT_TXQ_ID, spec->dmaq_id,\n\t\t\t\t     FRF_CZ_TMFT_WILDCARD_MATCH, is_wild,\n\t\t\t\t     FRF_CZ_TMFT_SRC_MAC_HI, spec->data[2],\n\t\t\t\t     FRF_CZ_TMFT_SRC_MAC_LO, spec->data[1],\n\t\t\t\t     FRF_CZ_TMFT_VLAN_ID, spec->data[0]);\n\t\tdata3 = is_wild | spec->dmaq_id << 1;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn spec->data[0] ^ spec->data[1] ^ spec->data[2] ^ data3;\n}\n\nstatic bool efx_farch_filter_equal(const struct efx_farch_filter_spec *left,\n\t\t\t\t   const struct efx_farch_filter_spec *right)\n{\n\tif (left->type != right->type ||\n\t    memcmp(left->data, right->data, sizeof(left->data)))\n\t\treturn false;\n\n\tif (left->flags & EFX_FILTER_FLAG_TX &&\n\t    left->dmaq_id != right->dmaq_id)\n\t\treturn false;\n\n\treturn true;\n}\n\n \n\n#define EFX_FARCH_FILTER_MATCH_PRI_COUNT\t5\n\nstatic const u8 efx_farch_filter_type_match_pri[EFX_FARCH_FILTER_TYPE_COUNT] = {\n\t[EFX_FARCH_FILTER_TCP_FULL]\t= 0,\n\t[EFX_FARCH_FILTER_UDP_FULL]\t= 0,\n\t[EFX_FARCH_FILTER_TCP_WILD]\t= 1,\n\t[EFX_FARCH_FILTER_UDP_WILD]\t= 1,\n\t[EFX_FARCH_FILTER_MAC_FULL]\t= 2,\n\t[EFX_FARCH_FILTER_MAC_WILD]\t= 3,\n\t[EFX_FARCH_FILTER_UC_DEF]\t= 4,\n\t[EFX_FARCH_FILTER_MC_DEF]\t= 4,\n};\n\nstatic const enum efx_farch_filter_table_id efx_farch_filter_range_table[] = {\n\tEFX_FARCH_FILTER_TABLE_RX_IP,\t \n\tEFX_FARCH_FILTER_TABLE_RX_IP,\n\tEFX_FARCH_FILTER_TABLE_RX_MAC,\n\tEFX_FARCH_FILTER_TABLE_RX_MAC,\n\tEFX_FARCH_FILTER_TABLE_RX_DEF,\t \n\tEFX_FARCH_FILTER_TABLE_TX_MAC,\t \n\tEFX_FARCH_FILTER_TABLE_TX_MAC,\t \n};\n\n#define EFX_FARCH_FILTER_INDEX_WIDTH 13\n#define EFX_FARCH_FILTER_INDEX_MASK ((1 << EFX_FARCH_FILTER_INDEX_WIDTH) - 1)\n\nstatic inline u32\nefx_farch_filter_make_id(const struct efx_farch_filter_spec *spec,\n\t\t\t unsigned int index)\n{\n\tunsigned int range;\n\n\trange = efx_farch_filter_type_match_pri[spec->type];\n\tif (!(spec->flags & EFX_FILTER_FLAG_RX))\n\t\trange += EFX_FARCH_FILTER_MATCH_PRI_COUNT;\n\n\treturn range << EFX_FARCH_FILTER_INDEX_WIDTH | index;\n}\n\nstatic inline enum efx_farch_filter_table_id\nefx_farch_filter_id_table_id(u32 id)\n{\n\tunsigned int range = id >> EFX_FARCH_FILTER_INDEX_WIDTH;\n\n\tif (range < ARRAY_SIZE(efx_farch_filter_range_table))\n\t\treturn efx_farch_filter_range_table[range];\n\telse\n\t\treturn EFX_FARCH_FILTER_TABLE_COUNT;  \n}\n\nstatic inline unsigned int efx_farch_filter_id_index(u32 id)\n{\n\treturn id & EFX_FARCH_FILTER_INDEX_MASK;\n}\n\nu32 efx_farch_filter_get_rx_id_limit(struct efx_nic *efx)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tunsigned int range = EFX_FARCH_FILTER_MATCH_PRI_COUNT - 1;\n\tenum efx_farch_filter_table_id table_id;\n\n\tdo {\n\t\ttable_id = efx_farch_filter_range_table[range];\n\t\tif (state->table[table_id].size != 0)\n\t\t\treturn range << EFX_FARCH_FILTER_INDEX_WIDTH |\n\t\t\t\tstate->table[table_id].size;\n\t} while (range--);\n\n\treturn 0;\n}\n\ns32 efx_farch_filter_insert(struct efx_nic *efx,\n\t\t\t    struct efx_filter_spec *gen_spec,\n\t\t\t    bool replace_equal)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tstruct efx_farch_filter_table *table;\n\tstruct efx_farch_filter_spec spec;\n\tefx_oword_t filter;\n\tint rep_index, ins_index;\n\tunsigned int depth = 0;\n\tint rc;\n\n\trc = efx_farch_filter_from_gen_spec(&spec, gen_spec);\n\tif (rc)\n\t\treturn rc;\n\n\tdown_write(&state->lock);\n\n\ttable = &state->table[efx_farch_filter_spec_table_id(&spec)];\n\tif (table->size == 0) {\n\t\trc = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t   \"%s: type %d search_limit=%d\", __func__, spec.type,\n\t\t   table->search_limit[spec.type]);\n\n\tif (table->id == EFX_FARCH_FILTER_TABLE_RX_DEF) {\n\t\t \n\t\tBUILD_BUG_ON(EFX_FARCH_FILTER_INDEX_UC_DEF != 0);\n\t\tBUILD_BUG_ON(EFX_FARCH_FILTER_INDEX_MC_DEF !=\n\t\t\t     EFX_FARCH_FILTER_MC_DEF - EFX_FARCH_FILTER_UC_DEF);\n\t\trep_index = spec.type - EFX_FARCH_FILTER_UC_DEF;\n\t\tins_index = rep_index;\n\t} else {\n\t\t \n\t\tu32 key = efx_farch_filter_build(&filter, &spec);\n\t\tunsigned int hash = efx_farch_filter_hash(key);\n\t\tunsigned int incr = efx_farch_filter_increment(key);\n\t\tunsigned int max_rep_depth = table->search_limit[spec.type];\n\t\tunsigned int max_ins_depth =\n\t\t\tspec.priority <= EFX_FILTER_PRI_HINT ?\n\t\t\tEFX_FARCH_FILTER_CTL_SRCH_HINT_MAX :\n\t\t\tEFX_FARCH_FILTER_CTL_SRCH_MAX;\n\t\tunsigned int i = hash & (table->size - 1);\n\n\t\tins_index = -1;\n\t\tdepth = 1;\n\n\t\tfor (;;) {\n\t\t\tif (!test_bit(i, table->used_bitmap)) {\n\t\t\t\tif (ins_index < 0)\n\t\t\t\t\tins_index = i;\n\t\t\t} else if (efx_farch_filter_equal(&spec,\n\t\t\t\t\t\t\t  &table->spec[i])) {\n\t\t\t\t \n\t\t\t\tif (ins_index < 0)\n\t\t\t\t\tins_index = i;\n\t\t\t\trep_index = i;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (depth >= max_rep_depth &&\n\t\t\t    (ins_index >= 0 || depth >= max_ins_depth)) {\n\t\t\t\t \n\t\t\t\tif (ins_index < 0) {\n\t\t\t\t\trc = -EBUSY;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t\trep_index = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\ti = (i + incr) & (table->size - 1);\n\t\t\t++depth;\n\t\t}\n\t}\n\n\t \n\tif (rep_index >= 0) {\n\t\tstruct efx_farch_filter_spec *saved_spec =\n\t\t\t&table->spec[rep_index];\n\n\t\tif (spec.priority == saved_spec->priority && !replace_equal) {\n\t\t\trc = -EEXIST;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (spec.priority < saved_spec->priority) {\n\t\t\trc = -EPERM;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (saved_spec->priority == EFX_FILTER_PRI_AUTO ||\n\t\t    saved_spec->flags & EFX_FILTER_FLAG_RX_OVER_AUTO)\n\t\t\tspec.flags |= EFX_FILTER_FLAG_RX_OVER_AUTO;\n\t}\n\n\t \n\tif (ins_index != rep_index) {\n\t\t__set_bit(ins_index, table->used_bitmap);\n\t\t++table->used;\n\t}\n\ttable->spec[ins_index] = spec;\n\n\tif (table->id == EFX_FARCH_FILTER_TABLE_RX_DEF) {\n\t\tefx_farch_filter_push_rx_config(efx);\n\t} else {\n\t\tif (table->search_limit[spec.type] < depth) {\n\t\t\ttable->search_limit[spec.type] = depth;\n\t\t\tif (spec.flags & EFX_FILTER_FLAG_TX)\n\t\t\t\tefx_farch_filter_push_tx_limits(efx);\n\t\t\telse\n\t\t\t\tefx_farch_filter_push_rx_config(efx);\n\t\t}\n\n\t\tefx_writeo(efx, &filter,\n\t\t\t   table->offset + table->step * ins_index);\n\n\t\t \n\t\tif (ins_index != rep_index && rep_index >= 0)\n\t\t\tefx_farch_filter_table_clear_entry(efx, table,\n\t\t\t\t\t\t\t   rep_index);\n\t}\n\n\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t   \"%s: filter type %d index %d rxq %u set\",\n\t\t   __func__, spec.type, ins_index, spec.dmaq_id);\n\trc = efx_farch_filter_make_id(&spec, ins_index);\n\nout_unlock:\n\tup_write(&state->lock);\n\treturn rc;\n}\n\nstatic void\nefx_farch_filter_table_clear_entry(struct efx_nic *efx,\n\t\t\t\t   struct efx_farch_filter_table *table,\n\t\t\t\t   unsigned int filter_idx)\n{\n\tstatic efx_oword_t filter;\n\n\tEFX_WARN_ON_PARANOID(!test_bit(filter_idx, table->used_bitmap));\n\tBUG_ON(table->offset == 0);  \n\n\t__clear_bit(filter_idx, table->used_bitmap);\n\t--table->used;\n\tmemset(&table->spec[filter_idx], 0, sizeof(table->spec[0]));\n\n\tefx_writeo(efx, &filter, table->offset + table->step * filter_idx);\n\n\t \n\tif (unlikely(table->used == 0)) {\n\t\tmemset(table->search_limit, 0, sizeof(table->search_limit));\n\t\tif (table->id == EFX_FARCH_FILTER_TABLE_TX_MAC)\n\t\t\tefx_farch_filter_push_tx_limits(efx);\n\t\telse\n\t\t\tefx_farch_filter_push_rx_config(efx);\n\t}\n}\n\nstatic int efx_farch_filter_remove(struct efx_nic *efx,\n\t\t\t\t   struct efx_farch_filter_table *table,\n\t\t\t\t   unsigned int filter_idx,\n\t\t\t\t   enum efx_filter_priority priority)\n{\n\tstruct efx_farch_filter_spec *spec = &table->spec[filter_idx];\n\n\tif (!test_bit(filter_idx, table->used_bitmap) ||\n\t    spec->priority != priority)\n\t\treturn -ENOENT;\n\n\tif (spec->flags & EFX_FILTER_FLAG_RX_OVER_AUTO) {\n\t\tefx_farch_filter_init_rx_auto(efx, spec);\n\t\tefx_farch_filter_push_rx_config(efx);\n\t} else {\n\t\tefx_farch_filter_table_clear_entry(efx, table, filter_idx);\n\t}\n\n\treturn 0;\n}\n\nint efx_farch_filter_remove_safe(struct efx_nic *efx,\n\t\t\t\t enum efx_filter_priority priority,\n\t\t\t\t u32 filter_id)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tenum efx_farch_filter_table_id table_id;\n\tstruct efx_farch_filter_table *table;\n\tunsigned int filter_idx;\n\tint rc;\n\n\ttable_id = efx_farch_filter_id_table_id(filter_id);\n\tif ((unsigned int)table_id >= EFX_FARCH_FILTER_TABLE_COUNT)\n\t\treturn -ENOENT;\n\ttable = &state->table[table_id];\n\n\tfilter_idx = efx_farch_filter_id_index(filter_id);\n\tif (filter_idx >= table->size)\n\t\treturn -ENOENT;\n\tdown_write(&state->lock);\n\n\trc = efx_farch_filter_remove(efx, table, filter_idx, priority);\n\tup_write(&state->lock);\n\n\treturn rc;\n}\n\nint efx_farch_filter_get_safe(struct efx_nic *efx,\n\t\t\t      enum efx_filter_priority priority,\n\t\t\t      u32 filter_id, struct efx_filter_spec *spec_buf)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tenum efx_farch_filter_table_id table_id;\n\tstruct efx_farch_filter_table *table;\n\tstruct efx_farch_filter_spec *spec;\n\tunsigned int filter_idx;\n\tint rc = -ENOENT;\n\n\tdown_read(&state->lock);\n\n\ttable_id = efx_farch_filter_id_table_id(filter_id);\n\tif ((unsigned int)table_id >= EFX_FARCH_FILTER_TABLE_COUNT)\n\t\tgoto out_unlock;\n\ttable = &state->table[table_id];\n\n\tfilter_idx = efx_farch_filter_id_index(filter_id);\n\tif (filter_idx >= table->size)\n\t\tgoto out_unlock;\n\tspec = &table->spec[filter_idx];\n\n\tif (test_bit(filter_idx, table->used_bitmap) &&\n\t    spec->priority == priority) {\n\t\tefx_farch_filter_to_gen_spec(spec_buf, spec);\n\t\trc = 0;\n\t}\n\nout_unlock:\n\tup_read(&state->lock);\n\treturn rc;\n}\n\nstatic void\nefx_farch_filter_table_clear(struct efx_nic *efx,\n\t\t\t     enum efx_farch_filter_table_id table_id,\n\t\t\t     enum efx_filter_priority priority)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tstruct efx_farch_filter_table *table = &state->table[table_id];\n\tunsigned int filter_idx;\n\n\tdown_write(&state->lock);\n\tfor (filter_idx = 0; filter_idx < table->size; ++filter_idx) {\n\t\tif (table->spec[filter_idx].priority != EFX_FILTER_PRI_AUTO)\n\t\t\tefx_farch_filter_remove(efx, table,\n\t\t\t\t\t\tfilter_idx, priority);\n\t}\n\tup_write(&state->lock);\n}\n\nint efx_farch_filter_clear_rx(struct efx_nic *efx,\n\t\t\t       enum efx_filter_priority priority)\n{\n\tefx_farch_filter_table_clear(efx, EFX_FARCH_FILTER_TABLE_RX_IP,\n\t\t\t\t     priority);\n\tefx_farch_filter_table_clear(efx, EFX_FARCH_FILTER_TABLE_RX_MAC,\n\t\t\t\t     priority);\n\tefx_farch_filter_table_clear(efx, EFX_FARCH_FILTER_TABLE_RX_DEF,\n\t\t\t\t     priority);\n\treturn 0;\n}\n\nu32 efx_farch_filter_count_rx_used(struct efx_nic *efx,\n\t\t\t\t   enum efx_filter_priority priority)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tenum efx_farch_filter_table_id table_id;\n\tstruct efx_farch_filter_table *table;\n\tunsigned int filter_idx;\n\tu32 count = 0;\n\n\tdown_read(&state->lock);\n\n\tfor (table_id = EFX_FARCH_FILTER_TABLE_RX_IP;\n\t     table_id <= EFX_FARCH_FILTER_TABLE_RX_DEF;\n\t     table_id++) {\n\t\ttable = &state->table[table_id];\n\t\tfor (filter_idx = 0; filter_idx < table->size; filter_idx++) {\n\t\t\tif (test_bit(filter_idx, table->used_bitmap) &&\n\t\t\t    table->spec[filter_idx].priority == priority)\n\t\t\t\t++count;\n\t\t}\n\t}\n\n\tup_read(&state->lock);\n\n\treturn count;\n}\n\ns32 efx_farch_filter_get_rx_ids(struct efx_nic *efx,\n\t\t\t\tenum efx_filter_priority priority,\n\t\t\t\tu32 *buf, u32 size)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tenum efx_farch_filter_table_id table_id;\n\tstruct efx_farch_filter_table *table;\n\tunsigned int filter_idx;\n\ts32 count = 0;\n\n\tdown_read(&state->lock);\n\n\tfor (table_id = EFX_FARCH_FILTER_TABLE_RX_IP;\n\t     table_id <= EFX_FARCH_FILTER_TABLE_RX_DEF;\n\t     table_id++) {\n\t\ttable = &state->table[table_id];\n\t\tfor (filter_idx = 0; filter_idx < table->size; filter_idx++) {\n\t\t\tif (test_bit(filter_idx, table->used_bitmap) &&\n\t\t\t    table->spec[filter_idx].priority == priority) {\n\t\t\t\tif (count == size) {\n\t\t\t\t\tcount = -EMSGSIZE;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tbuf[count++] = efx_farch_filter_make_id(\n\t\t\t\t\t&table->spec[filter_idx], filter_idx);\n\t\t\t}\n\t\t}\n\t}\nout:\n\tup_read(&state->lock);\n\n\treturn count;\n}\n\n \nvoid efx_farch_filter_table_restore(struct efx_nic *efx)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tenum efx_farch_filter_table_id table_id;\n\tstruct efx_farch_filter_table *table;\n\tefx_oword_t filter;\n\tunsigned int filter_idx;\n\n\tdown_write(&state->lock);\n\n\tfor (table_id = 0; table_id < EFX_FARCH_FILTER_TABLE_COUNT; table_id++) {\n\t\ttable = &state->table[table_id];\n\n\t\t \n\t\tif (table->step == 0)\n\t\t\tcontinue;\n\n\t\tfor (filter_idx = 0; filter_idx < table->size; filter_idx++) {\n\t\t\tif (!test_bit(filter_idx, table->used_bitmap))\n\t\t\t\tcontinue;\n\t\t\tefx_farch_filter_build(&filter, &table->spec[filter_idx]);\n\t\t\tefx_writeo(efx, &filter,\n\t\t\t\t   table->offset + table->step * filter_idx);\n\t\t}\n\t}\n\n\tefx_farch_filter_push_rx_config(efx);\n\tefx_farch_filter_push_tx_limits(efx);\n\n\tup_write(&state->lock);\n}\n\nvoid efx_farch_filter_table_remove(struct efx_nic *efx)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tenum efx_farch_filter_table_id table_id;\n\n\tfor (table_id = 0; table_id < EFX_FARCH_FILTER_TABLE_COUNT; table_id++) {\n\t\tbitmap_free(state->table[table_id].used_bitmap);\n\t\tvfree(state->table[table_id].spec);\n\t}\n\tkfree(state);\n}\n\nint efx_farch_filter_table_probe(struct efx_nic *efx)\n{\n\tstruct efx_farch_filter_state *state;\n\tstruct efx_farch_filter_table *table;\n\tunsigned table_id;\n\n\tstate = kzalloc(sizeof(struct efx_farch_filter_state), GFP_KERNEL);\n\tif (!state)\n\t\treturn -ENOMEM;\n\tefx->filter_state = state;\n\tinit_rwsem(&state->lock);\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_IP];\n\ttable->id = EFX_FARCH_FILTER_TABLE_RX_IP;\n\ttable->offset = FR_BZ_RX_FILTER_TBL0;\n\ttable->size = FR_BZ_RX_FILTER_TBL0_ROWS;\n\ttable->step = FR_BZ_RX_FILTER_TBL0_STEP;\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_MAC];\n\ttable->id = EFX_FARCH_FILTER_TABLE_RX_MAC;\n\ttable->offset = FR_CZ_RX_MAC_FILTER_TBL0;\n\ttable->size = FR_CZ_RX_MAC_FILTER_TBL0_ROWS;\n\ttable->step = FR_CZ_RX_MAC_FILTER_TBL0_STEP;\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_DEF];\n\ttable->id = EFX_FARCH_FILTER_TABLE_RX_DEF;\n\ttable->size = EFX_FARCH_FILTER_SIZE_RX_DEF;\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_TX_MAC];\n\ttable->id = EFX_FARCH_FILTER_TABLE_TX_MAC;\n\ttable->offset = FR_CZ_TX_MAC_FILTER_TBL0;\n\ttable->size = FR_CZ_TX_MAC_FILTER_TBL0_ROWS;\n\ttable->step = FR_CZ_TX_MAC_FILTER_TBL0_STEP;\n\n\tfor (table_id = 0; table_id < EFX_FARCH_FILTER_TABLE_COUNT; table_id++) {\n\t\ttable = &state->table[table_id];\n\t\tif (table->size == 0)\n\t\t\tcontinue;\n\t\ttable->used_bitmap = bitmap_zalloc(table->size, GFP_KERNEL);\n\t\tif (!table->used_bitmap)\n\t\t\tgoto fail;\n\t\ttable->spec = vzalloc(array_size(sizeof(*table->spec),\n\t\t\t\t\t\t table->size));\n\t\tif (!table->spec)\n\t\t\tgoto fail;\n\t}\n\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_DEF];\n\tif (table->size) {\n\t\t \n\t\tstruct efx_farch_filter_spec *spec;\n\t\tunsigned i;\n\n\t\tfor (i = 0; i < EFX_FARCH_FILTER_SIZE_RX_DEF; i++) {\n\t\t\tspec = &table->spec[i];\n\t\t\tspec->type = EFX_FARCH_FILTER_UC_DEF + i;\n\t\t\tefx_farch_filter_init_rx_auto(efx, spec);\n\t\t\t__set_bit(i, table->used_bitmap);\n\t\t}\n\t}\n\n\tefx_farch_filter_push_rx_config(efx);\n\n\treturn 0;\n\nfail:\n\tefx_farch_filter_table_remove(efx);\n\treturn -ENOMEM;\n}\n\n \nvoid efx_farch_filter_update_rx_scatter(struct efx_nic *efx)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tenum efx_farch_filter_table_id table_id;\n\tstruct efx_farch_filter_table *table;\n\tefx_oword_t filter;\n\tunsigned int filter_idx;\n\n\tdown_write(&state->lock);\n\n\tfor (table_id = EFX_FARCH_FILTER_TABLE_RX_IP;\n\t     table_id <= EFX_FARCH_FILTER_TABLE_RX_DEF;\n\t     table_id++) {\n\t\ttable = &state->table[table_id];\n\n\t\tfor (filter_idx = 0; filter_idx < table->size; filter_idx++) {\n\t\t\tif (!test_bit(filter_idx, table->used_bitmap) ||\n\t\t\t    table->spec[filter_idx].dmaq_id >=\n\t\t\t    efx->n_rx_channels)\n\t\t\t\tcontinue;\n\n\t\t\tif (efx->rx_scatter)\n\t\t\t\ttable->spec[filter_idx].flags |=\n\t\t\t\t\tEFX_FILTER_FLAG_RX_SCATTER;\n\t\t\telse\n\t\t\t\ttable->spec[filter_idx].flags &=\n\t\t\t\t\t~EFX_FILTER_FLAG_RX_SCATTER;\n\n\t\t\tif (table_id == EFX_FARCH_FILTER_TABLE_RX_DEF)\n\t\t\t\t \n\t\t\t\tcontinue;\n\n\t\t\tefx_farch_filter_build(&filter, &table->spec[filter_idx]);\n\t\t\tefx_writeo(efx, &filter,\n\t\t\t\t   table->offset + table->step * filter_idx);\n\t\t}\n\t}\n\n\tefx_farch_filter_push_rx_config(efx);\n\n\tup_write(&state->lock);\n}\n\n#ifdef CONFIG_RFS_ACCEL\n\nbool efx_farch_filter_rfs_expire_one(struct efx_nic *efx, u32 flow_id,\n\t\t\t\t     unsigned int index)\n{\n\tstruct efx_farch_filter_state *state = efx->filter_state;\n\tstruct efx_farch_filter_table *table;\n\tbool ret = false, force = false;\n\tu16 arfs_id;\n\n\tdown_write(&state->lock);\n\tspin_lock_bh(&efx->rps_hash_lock);\n\ttable = &state->table[EFX_FARCH_FILTER_TABLE_RX_IP];\n\tif (test_bit(index, table->used_bitmap) &&\n\t    table->spec[index].priority == EFX_FILTER_PRI_HINT) {\n\t\tstruct efx_arfs_rule *rule = NULL;\n\t\tstruct efx_filter_spec spec;\n\n\t\tefx_farch_filter_to_gen_spec(&spec, &table->spec[index]);\n\t\tif (!efx->rps_hash_table) {\n\t\t\t \n\t\t\tarfs_id = 0;\n\t\t} else {\n\t\t\trule = efx_siena_rps_hash_find(efx, &spec);\n\t\t\tif (!rule) {\n\t\t\t\t \n\t\t\t\tforce = true;\n\t\t\t} else {\n\t\t\t\tarfs_id = rule->arfs_id;\n\t\t\t\tif (!efx_siena_rps_check_rule(rule, index,\n\t\t\t\t\t\t\t      &force))\n\t\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t}\n\t\tif (force || rps_may_expire_flow(efx->net_dev, spec.dmaq_id,\n\t\t\t\t\t\t flow_id, arfs_id)) {\n\t\t\tif (rule)\n\t\t\t\trule->filter_id = EFX_ARFS_FILTER_ID_REMOVING;\n\t\t\tefx_siena_rps_hash_del(efx, &spec);\n\t\t\tefx_farch_filter_table_clear_entry(efx, table, index);\n\t\t\tret = true;\n\t\t}\n\t}\nout_unlock:\n\tspin_unlock_bh(&efx->rps_hash_lock);\n\tup_write(&state->lock);\n\treturn ret;\n}\n\n#endif  \n\nvoid efx_farch_filter_sync_rx_mode(struct efx_nic *efx)\n{\n\tstruct net_device *net_dev = efx->net_dev;\n\tstruct netdev_hw_addr *ha;\n\tunion efx_multicast_hash *mc_hash = &efx->multicast_hash;\n\tu32 crc;\n\tint bit;\n\n\tif (!efx_dev_registered(efx))\n\t\treturn;\n\n\tnetif_addr_lock_bh(net_dev);\n\n\tefx->unicast_filter = !(net_dev->flags & IFF_PROMISC);\n\n\t \n\tif (net_dev->flags & (IFF_PROMISC | IFF_ALLMULTI)) {\n\t\tmemset(mc_hash, 0xff, sizeof(*mc_hash));\n\t} else {\n\t\tmemset(mc_hash, 0x00, sizeof(*mc_hash));\n\t\tnetdev_for_each_mc_addr(ha, net_dev) {\n\t\t\tcrc = ether_crc_le(ETH_ALEN, ha->addr);\n\t\t\tbit = crc & (EFX_MCAST_HASH_ENTRIES - 1);\n\t\t\t__set_bit_le(bit, mc_hash);\n\t\t}\n\n\t\t \n\t\t__set_bit_le(0xff, mc_hash);\n\t}\n\n\tnetif_addr_unlock_bh(net_dev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}