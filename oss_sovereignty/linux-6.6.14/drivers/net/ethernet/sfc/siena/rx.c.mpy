{
  "module_name": "rx.c",
  "hash_id": "e738e3698774667c8ede02d5215c24f651eb81d092d7ad025a9f1da393d25b88",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sfc/siena/rx.c",
  "human_readable_source": "\n \n\n#include <linux/socket.h>\n#include <linux/in.h>\n#include <linux/slab.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <linux/prefetch.h>\n#include <linux/moduleparam.h>\n#include <linux/iommu.h>\n#include <net/ip.h>\n#include <net/checksum.h>\n#include <net/xdp.h>\n#include <linux/bpf_trace.h>\n#include \"net_driver.h\"\n#include \"efx.h\"\n#include \"rx_common.h\"\n#include \"filter.h\"\n#include \"nic.h\"\n#include \"selftest.h\"\n#include \"workarounds.h\"\n\n \n#define EFX_RX_PREFERRED_BATCH 8U\n\n \n#define EFX_MAX_RX_PREFIX_SIZE 16\n\n \n#define EFX_SKB_HEADERS  128u\n\n \n#define EFX_RX_MAX_FRAGS DIV_ROUND_UP(EFX_MAX_FRAME_LEN(EFX_MAX_MTU), \\\n\t\t\t\t      EFX_RX_USR_BUF_SIZE)\n\nstatic void efx_rx_packet__check_len(struct efx_rx_queue *rx_queue,\n\t\t\t\t     struct efx_rx_buffer *rx_buf,\n\t\t\t\t     int len)\n{\n\tstruct efx_nic *efx = rx_queue->efx;\n\tunsigned max_len = rx_buf->len - efx->type->rx_buffer_padding;\n\n\tif (likely(len <= max_len))\n\t\treturn;\n\n\t \n\trx_buf->flags |= EFX_RX_PKT_DISCARD;\n\n\tif (net_ratelimit())\n\t\tnetif_err(efx, rx_err, efx->net_dev,\n\t\t\t  \"RX queue %d overlength RX event (%#x > %#x)\\n\",\n\t\t\t  efx_rx_queue_index(rx_queue), len, max_len);\n\n\tefx_rx_queue_channel(rx_queue)->n_rx_overlength++;\n}\n\n \nstatic struct sk_buff *efx_rx_mk_skb(struct efx_channel *channel,\n\t\t\t\t     struct efx_rx_buffer *rx_buf,\n\t\t\t\t     unsigned int n_frags,\n\t\t\t\t     u8 *eh, int hdr_len)\n{\n\tstruct efx_nic *efx = channel->efx;\n\tstruct sk_buff *skb;\n\n\t \n\tskb = netdev_alloc_skb(efx->net_dev,\n\t\t\t       efx->rx_ip_align + efx->rx_prefix_size +\n\t\t\t       hdr_len);\n\tif (unlikely(skb == NULL)) {\n\t\tatomic_inc(&efx->n_rx_noskb_drops);\n\t\treturn NULL;\n\t}\n\n\tEFX_WARN_ON_ONCE_PARANOID(rx_buf->len < hdr_len);\n\n\tmemcpy(skb->data + efx->rx_ip_align, eh - efx->rx_prefix_size,\n\t       efx->rx_prefix_size + hdr_len);\n\tskb_reserve(skb, efx->rx_ip_align + efx->rx_prefix_size);\n\t__skb_put(skb, hdr_len);\n\n\t \n\tif (rx_buf->len > hdr_len) {\n\t\trx_buf->page_offset += hdr_len;\n\t\trx_buf->len -= hdr_len;\n\n\t\tfor (;;) {\n\t\t\tskb_add_rx_frag(skb, skb_shinfo(skb)->nr_frags,\n\t\t\t\t\trx_buf->page, rx_buf->page_offset,\n\t\t\t\t\trx_buf->len, efx->rx_buffer_truesize);\n\t\t\trx_buf->page = NULL;\n\n\t\t\tif (skb_shinfo(skb)->nr_frags == n_frags)\n\t\t\t\tbreak;\n\n\t\t\trx_buf = efx_rx_buf_next(&channel->rx_queue, rx_buf);\n\t\t}\n\t} else {\n\t\t__free_pages(rx_buf->page, efx->rx_buffer_order);\n\t\trx_buf->page = NULL;\n\t\tn_frags = 0;\n\t}\n\n\t \n\tskb->protocol = eth_type_trans(skb, efx->net_dev);\n\n\tskb_mark_napi_id(skb, &channel->napi_str);\n\n\treturn skb;\n}\n\nvoid efx_siena_rx_packet(struct efx_rx_queue *rx_queue, unsigned int index,\n\t\t\t unsigned int n_frags, unsigned int len, u16 flags)\n{\n\tstruct efx_nic *efx = rx_queue->efx;\n\tstruct efx_channel *channel = efx_rx_queue_channel(rx_queue);\n\tstruct efx_rx_buffer *rx_buf;\n\n\trx_queue->rx_packets++;\n\n\trx_buf = efx_rx_buffer(rx_queue, index);\n\trx_buf->flags |= flags;\n\n\t \n\tif (n_frags == 1) {\n\t\tif (!(flags & EFX_RX_PKT_PREFIX_LEN))\n\t\t\tefx_rx_packet__check_len(rx_queue, rx_buf, len);\n\t} else if (unlikely(n_frags > EFX_RX_MAX_FRAGS) ||\n\t\t   unlikely(len <= (n_frags - 1) * efx->rx_dma_len) ||\n\t\t   unlikely(len > n_frags * efx->rx_dma_len) ||\n\t\t   unlikely(!efx->rx_scatter)) {\n\t\t \n\t\tWARN_ON(!(len == 0 && rx_buf->flags & EFX_RX_PKT_DISCARD));\n\t\trx_buf->flags |= EFX_RX_PKT_DISCARD;\n\t}\n\n\tnetif_vdbg(efx, rx_status, efx->net_dev,\n\t\t   \"RX queue %d received ids %x-%x len %d %s%s\\n\",\n\t\t   efx_rx_queue_index(rx_queue), index,\n\t\t   (index + n_frags - 1) & rx_queue->ptr_mask, len,\n\t\t   (rx_buf->flags & EFX_RX_PKT_CSUMMED) ? \" [SUMMED]\" : \"\",\n\t\t   (rx_buf->flags & EFX_RX_PKT_DISCARD) ? \" [DISCARD]\" : \"\");\n\n\t \n\tif (unlikely(rx_buf->flags & EFX_RX_PKT_DISCARD)) {\n\t\tefx_rx_flush_packet(channel);\n\t\tefx_siena_discard_rx_packet(channel, rx_buf, n_frags);\n\t\treturn;\n\t}\n\n\tif (n_frags == 1 && !(flags & EFX_RX_PKT_PREFIX_LEN))\n\t\trx_buf->len = len;\n\n\t \n\tefx_sync_rx_buffer(efx, rx_buf, rx_buf->len);\n\n\t \n\tprefetch(efx_rx_buf_va(rx_buf));\n\n\trx_buf->page_offset += efx->rx_prefix_size;\n\trx_buf->len -= efx->rx_prefix_size;\n\n\tif (n_frags > 1) {\n\t\t \n\t\tunsigned int tail_frags = n_frags - 1;\n\n\t\tfor (;;) {\n\t\t\trx_buf = efx_rx_buf_next(rx_queue, rx_buf);\n\t\t\tif (--tail_frags == 0)\n\t\t\t\tbreak;\n\t\t\tefx_sync_rx_buffer(efx, rx_buf, efx->rx_dma_len);\n\t\t}\n\t\trx_buf->len = len - (n_frags - 1) * efx->rx_dma_len;\n\t\tefx_sync_rx_buffer(efx, rx_buf, rx_buf->len);\n\t}\n\n\t \n\trx_buf = efx_rx_buffer(rx_queue, index);\n\tefx_siena_recycle_rx_pages(channel, rx_buf, n_frags);\n\n\t \n\tefx_rx_flush_packet(channel);\n\tchannel->rx_pkt_n_frags = n_frags;\n\tchannel->rx_pkt_index = index;\n}\n\nstatic void efx_rx_deliver(struct efx_channel *channel, u8 *eh,\n\t\t\t   struct efx_rx_buffer *rx_buf,\n\t\t\t   unsigned int n_frags)\n{\n\tstruct sk_buff *skb;\n\tu16 hdr_len = min_t(u16, rx_buf->len, EFX_SKB_HEADERS);\n\n\tskb = efx_rx_mk_skb(channel, rx_buf, n_frags, eh, hdr_len);\n\tif (unlikely(skb == NULL)) {\n\t\tstruct efx_rx_queue *rx_queue;\n\n\t\trx_queue = efx_channel_get_rx_queue(channel);\n\t\tefx_siena_free_rx_buffers(rx_queue, rx_buf, n_frags);\n\t\treturn;\n\t}\n\tskb_record_rx_queue(skb, channel->rx_queue.core_index);\n\n\t \n\tskb_checksum_none_assert(skb);\n\tif (likely(rx_buf->flags & EFX_RX_PKT_CSUMMED)) {\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\tskb->csum_level = !!(rx_buf->flags & EFX_RX_PKT_CSUM_LEVEL);\n\t}\n\n\tefx_rx_skb_attach_timestamp(channel, skb);\n\n\tif (channel->type->receive_skb)\n\t\tif (channel->type->receive_skb(channel, skb))\n\t\t\treturn;\n\n\t \n\tif (channel->rx_list != NULL)\n\t\t \n\t\tlist_add_tail(&skb->list, channel->rx_list);\n\telse\n\t\t \n\t\tnetif_receive_skb(skb);\n}\n\n \nstatic bool efx_do_xdp(struct efx_nic *efx, struct efx_channel *channel,\n\t\t       struct efx_rx_buffer *rx_buf, u8 **ehp)\n{\n\tu8 rx_prefix[EFX_MAX_RX_PREFIX_SIZE];\n\tstruct efx_rx_queue *rx_queue;\n\tstruct bpf_prog *xdp_prog;\n\tstruct xdp_frame *xdpf;\n\tstruct xdp_buff xdp;\n\tu32 xdp_act;\n\ts16 offset;\n\tint err;\n\n\txdp_prog = rcu_dereference_bh(efx->xdp_prog);\n\tif (!xdp_prog)\n\t\treturn true;\n\n\trx_queue = efx_channel_get_rx_queue(channel);\n\n\tif (unlikely(channel->rx_pkt_n_frags > 1)) {\n\t\t \n\t\tefx_siena_free_rx_buffers(rx_queue, rx_buf,\n\t\t\t\t\t  channel->rx_pkt_n_frags);\n\t\tif (net_ratelimit())\n\t\t\tnetif_err(efx, rx_err, efx->net_dev,\n\t\t\t\t  \"XDP is not possible with multiple receive fragments (%d)\\n\",\n\t\t\t\t  channel->rx_pkt_n_frags);\n\t\tchannel->n_rx_xdp_bad_drops++;\n\t\treturn false;\n\t}\n\n\tdma_sync_single_for_cpu(&efx->pci_dev->dev, rx_buf->dma_addr,\n\t\t\t\trx_buf->len, DMA_FROM_DEVICE);\n\n\t \n\tEFX_WARN_ON_PARANOID(efx->rx_prefix_size > EFX_MAX_RX_PREFIX_SIZE);\n\tmemcpy(rx_prefix, *ehp - efx->rx_prefix_size,\n\t       efx->rx_prefix_size);\n\n\txdp_init_buff(&xdp, efx->rx_page_buf_step, &rx_queue->xdp_rxq_info);\n\t \n\txdp_prepare_buff(&xdp, *ehp - EFX_XDP_HEADROOM, EFX_XDP_HEADROOM,\n\t\t\t rx_buf->len, false);\n\n\txdp_act = bpf_prog_run_xdp(xdp_prog, &xdp);\n\n\toffset = (u8 *)xdp.data - *ehp;\n\n\tswitch (xdp_act) {\n\tcase XDP_PASS:\n\t\t \n\t\tif (offset) {\n\t\t\t*ehp += offset;\n\t\t\trx_buf->page_offset += offset;\n\t\t\trx_buf->len -= offset;\n\t\t\tmemcpy(*ehp - efx->rx_prefix_size, rx_prefix,\n\t\t\t       efx->rx_prefix_size);\n\t\t}\n\t\tbreak;\n\n\tcase XDP_TX:\n\t\t \n\t\txdpf = xdp_convert_buff_to_frame(&xdp);\n\t\terr = efx_siena_xdp_tx_buffers(efx, 1, &xdpf, true);\n\t\tif (unlikely(err != 1)) {\n\t\t\tefx_siena_free_rx_buffers(rx_queue, rx_buf, 1);\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetif_err(efx, rx_err, efx->net_dev,\n\t\t\t\t\t  \"XDP TX failed (%d)\\n\", err);\n\t\t\tchannel->n_rx_xdp_bad_drops++;\n\t\t\ttrace_xdp_exception(efx->net_dev, xdp_prog, xdp_act);\n\t\t} else {\n\t\t\tchannel->n_rx_xdp_tx++;\n\t\t}\n\t\tbreak;\n\n\tcase XDP_REDIRECT:\n\t\terr = xdp_do_redirect(efx->net_dev, &xdp, xdp_prog);\n\t\tif (unlikely(err)) {\n\t\t\tefx_siena_free_rx_buffers(rx_queue, rx_buf, 1);\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetif_err(efx, rx_err, efx->net_dev,\n\t\t\t\t\t  \"XDP redirect failed (%d)\\n\", err);\n\t\t\tchannel->n_rx_xdp_bad_drops++;\n\t\t\ttrace_xdp_exception(efx->net_dev, xdp_prog, xdp_act);\n\t\t} else {\n\t\t\tchannel->n_rx_xdp_redirect++;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbpf_warn_invalid_xdp_action(efx->net_dev, xdp_prog, xdp_act);\n\t\tefx_siena_free_rx_buffers(rx_queue, rx_buf, 1);\n\t\tchannel->n_rx_xdp_bad_drops++;\n\t\ttrace_xdp_exception(efx->net_dev, xdp_prog, xdp_act);\n\t\tbreak;\n\n\tcase XDP_ABORTED:\n\t\ttrace_xdp_exception(efx->net_dev, xdp_prog, xdp_act);\n\t\tfallthrough;\n\tcase XDP_DROP:\n\t\tefx_siena_free_rx_buffers(rx_queue, rx_buf, 1);\n\t\tchannel->n_rx_xdp_drops++;\n\t\tbreak;\n\t}\n\n\treturn xdp_act == XDP_PASS;\n}\n\n \nvoid __efx_siena_rx_packet(struct efx_channel *channel)\n{\n\tstruct efx_nic *efx = channel->efx;\n\tstruct efx_rx_buffer *rx_buf =\n\t\tefx_rx_buffer(&channel->rx_queue, channel->rx_pkt_index);\n\tu8 *eh = efx_rx_buf_va(rx_buf);\n\n\t \n\tif (rx_buf->flags & EFX_RX_PKT_PREFIX_LEN)\n\t\trx_buf->len = le16_to_cpup((__le16 *)\n\t\t\t\t\t   (eh + efx->rx_packet_len_offset));\n\n\t \n\tif (unlikely(efx->loopback_selftest)) {\n\t\tstruct efx_rx_queue *rx_queue;\n\n\t\tefx_siena_loopback_rx_packet(efx, eh, rx_buf->len);\n\t\trx_queue = efx_channel_get_rx_queue(channel);\n\t\tefx_siena_free_rx_buffers(rx_queue, rx_buf,\n\t\t\t\t\t  channel->rx_pkt_n_frags);\n\t\tgoto out;\n\t}\n\n\tif (!efx_do_xdp(efx, channel, rx_buf, &eh))\n\t\tgoto out;\n\n\tif (unlikely(!(efx->net_dev->features & NETIF_F_RXCSUM)))\n\t\trx_buf->flags &= ~EFX_RX_PKT_CSUMMED;\n\n\tif ((rx_buf->flags & EFX_RX_PKT_TCP) && !channel->type->receive_skb)\n\t\tefx_siena_rx_packet_gro(channel, rx_buf,\n\t\t\t\t\tchannel->rx_pkt_n_frags, eh, 0);\n\telse\n\t\tefx_rx_deliver(channel, eh, rx_buf, channel->rx_pkt_n_frags);\nout:\n\tchannel->rx_pkt_n_frags = 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}