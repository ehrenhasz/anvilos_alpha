{
  "module_name": "siena_sriov.c",
  "hash_id": "0bc4a3b425f137d97c8a5ed171cb293775db9b2a4ade0a98dd186a47a72a9891",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sfc/siena/siena_sriov.c",
  "human_readable_source": "\n \n#include <linux/pci.h>\n#include <linux/module.h>\n#include \"net_driver.h\"\n#include \"efx.h\"\n#include \"efx_channels.h\"\n#include \"nic.h\"\n#include \"io.h\"\n#include \"mcdi.h\"\n#include \"filter.h\"\n#include \"mcdi_pcol.h\"\n#include \"farch_regs.h\"\n#include \"siena_sriov.h\"\n#include \"vfdi.h\"\n\n \n#define VI_MASK_LENGTH BITS_TO_LONGS(1 << EFX_VI_SCALE_MAX)\n\n \n#define VF_MAX_RX_QUEUES 63\n\n \nenum efx_vf_tx_filter_mode {\n\tVF_TX_FILTER_OFF,\n\tVF_TX_FILTER_AUTO,\n\tVF_TX_FILTER_ON,\n};\n\n \nstruct siena_vf {\n\tstruct efx_nic *efx;\n\tunsigned int pci_rid;\n\tchar pci_name[13];  \n\tunsigned int index;\n\tstruct work_struct req;\n\tu64 req_addr;\n\tint req_type;\n\tunsigned req_seqno;\n\tunsigned msg_seqno;\n\tbool busy;\n\tstruct efx_buffer buf;\n\tunsigned buftbl_base;\n\tbool rx_filtering;\n\tenum efx_filter_flags rx_filter_flags;\n\tunsigned rx_filter_qid;\n\tint rx_filter_id;\n\tenum efx_vf_tx_filter_mode tx_filter_mode;\n\tint tx_filter_id;\n\tstruct vfdi_endpoint addr;\n\tu64 status_addr;\n\tstruct mutex status_lock;\n\tu64 *peer_page_addrs;\n\tunsigned peer_page_count;\n\tu64 evq0_addrs[EFX_MAX_VF_EVQ_SIZE * sizeof(efx_qword_t) /\n\t\t       EFX_BUF_SIZE];\n\tunsigned evq0_count;\n\twait_queue_head_t flush_waitq;\n\tstruct mutex txq_lock;\n\tunsigned long txq_mask[VI_MASK_LENGTH];\n\tunsigned txq_count;\n\tunsigned long rxq_mask[VI_MASK_LENGTH];\n\tunsigned rxq_count;\n\tunsigned long rxq_retry_mask[VI_MASK_LENGTH];\n\tatomic_t rxq_retry_count;\n\tstruct work_struct reset_work;\n};\n\nstruct efx_memcpy_req {\n\tunsigned int from_rid;\n\tvoid *from_buf;\n\tu64 from_addr;\n\tunsigned int to_rid;\n\tu64 to_addr;\n\tunsigned length;\n};\n\n \nstruct efx_local_addr {\n\tstruct list_head link;\n\tu8 addr[ETH_ALEN];\n};\n\n \nstruct efx_endpoint_page {\n\tstruct list_head link;\n\tvoid *ptr;\n\tdma_addr_t addr;\n};\n\n \n#define EFX_BUFTBL_TXQ_BASE(_vf, _qid)\t\t\t\t\t\\\n\t((_vf)->buftbl_base + EFX_VF_BUFTBL_PER_VI * (_qid))\n#define EFX_BUFTBL_RXQ_BASE(_vf, _qid)\t\t\t\t\t\\\n\t(EFX_BUFTBL_TXQ_BASE(_vf, _qid) +\t\t\t\t\\\n\t (EFX_MAX_DMAQ_SIZE * sizeof(efx_qword_t) / EFX_BUF_SIZE))\n#define EFX_BUFTBL_EVQ_BASE(_vf, _qid)\t\t\t\t\t\\\n\t(EFX_BUFTBL_TXQ_BASE(_vf, _qid) +\t\t\t\t\\\n\t (2 * EFX_MAX_DMAQ_SIZE * sizeof(efx_qword_t) / EFX_BUF_SIZE))\n\n#define EFX_FIELD_MASK(_field)\t\t\t\\\n\t((1 << _field ## _WIDTH) - 1)\n\n \nstatic unsigned int vf_max_tx_channels = 2;\nmodule_param(vf_max_tx_channels, uint, 0444);\nMODULE_PARM_DESC(vf_max_tx_channels,\n\t\t \"Limit the number of TX channels VFs can use\");\n\nstatic int max_vfs = -1;\nmodule_param(max_vfs, int, 0444);\nMODULE_PARM_DESC(max_vfs,\n\t\t \"Reduce the number of VFs initialized by the driver\");\n\n \nstatic struct workqueue_struct *vfdi_workqueue;\n\nstatic unsigned abs_index(struct siena_vf *vf, unsigned index)\n{\n\treturn EFX_VI_BASE + vf->index * efx_vf_size(vf->efx) + index;\n}\n\nstatic int efx_siena_sriov_cmd(struct efx_nic *efx, bool enable,\n\t\t\t       unsigned *vi_scale_out, unsigned *vf_total_out)\n{\n\tMCDI_DECLARE_BUF(inbuf, MC_CMD_SRIOV_IN_LEN);\n\tMCDI_DECLARE_BUF(outbuf, MC_CMD_SRIOV_OUT_LEN);\n\tunsigned vi_scale, vf_total;\n\tsize_t outlen;\n\tint rc;\n\n\tMCDI_SET_DWORD(inbuf, SRIOV_IN_ENABLE, enable ? 1 : 0);\n\tMCDI_SET_DWORD(inbuf, SRIOV_IN_VI_BASE, EFX_VI_BASE);\n\tMCDI_SET_DWORD(inbuf, SRIOV_IN_VF_COUNT, efx->vf_count);\n\n\trc = efx_siena_mcdi_rpc_quiet(efx, MC_CMD_SRIOV, inbuf,\n\t\t\t\t      MC_CMD_SRIOV_IN_LEN, outbuf,\n\t\t\t\t      MC_CMD_SRIOV_OUT_LEN, &outlen);\n\tif (rc)\n\t\treturn rc;\n\tif (outlen < MC_CMD_SRIOV_OUT_LEN)\n\t\treturn -EIO;\n\n\tvf_total = MCDI_DWORD(outbuf, SRIOV_OUT_VF_TOTAL);\n\tvi_scale = MCDI_DWORD(outbuf, SRIOV_OUT_VI_SCALE);\n\tif (vi_scale > EFX_VI_SCALE_MAX)\n\t\treturn -EOPNOTSUPP;\n\n\tif (vi_scale_out)\n\t\t*vi_scale_out = vi_scale;\n\tif (vf_total_out)\n\t\t*vf_total_out = vf_total;\n\n\treturn 0;\n}\n\nstatic void efx_siena_sriov_usrev(struct efx_nic *efx, bool enabled)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tefx_oword_t reg;\n\n\tEFX_POPULATE_OWORD_2(reg,\n\t\t\t     FRF_CZ_USREV_DIS, enabled ? 0 : 1,\n\t\t\t     FRF_CZ_DFLT_EVQ, nic_data->vfdi_channel->channel);\n\tefx_writeo(efx, &reg, FR_CZ_USR_EV_CFG);\n}\n\nstatic int efx_siena_sriov_memcpy(struct efx_nic *efx,\n\t\t\t\t  struct efx_memcpy_req *req,\n\t\t\t\t  unsigned int count)\n{\n\tMCDI_DECLARE_BUF(inbuf, MCDI_CTL_SDU_LEN_MAX_V1);\n\tMCDI_DECLARE_STRUCT_PTR(record);\n\tunsigned int index, used;\n\tu64 from_addr;\n\tu32 from_rid;\n\tint rc;\n\n\tmb();\t \n\n\tif (WARN_ON(count > MC_CMD_MEMCPY_IN_RECORD_MAXNUM))\n\t\treturn -ENOBUFS;\n\tused = MC_CMD_MEMCPY_IN_LEN(count);\n\n\tfor (index = 0; index < count; index++) {\n\t\trecord = MCDI_ARRAY_STRUCT_PTR(inbuf, MEMCPY_IN_RECORD, index);\n\t\tMCDI_SET_DWORD(record, MEMCPY_RECORD_TYPEDEF_NUM_RECORDS,\n\t\t\t       count);\n\t\tMCDI_SET_DWORD(record, MEMCPY_RECORD_TYPEDEF_TO_RID,\n\t\t\t       req->to_rid);\n\t\tMCDI_SET_QWORD(record, MEMCPY_RECORD_TYPEDEF_TO_ADDR,\n\t\t\t       req->to_addr);\n\t\tif (req->from_buf == NULL) {\n\t\t\tfrom_rid = req->from_rid;\n\t\t\tfrom_addr = req->from_addr;\n\t\t} else {\n\t\t\tif (WARN_ON(used + req->length >\n\t\t\t\t    MCDI_CTL_SDU_LEN_MAX_V1)) {\n\t\t\t\trc = -ENOBUFS;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tfrom_rid = MC_CMD_MEMCPY_RECORD_TYPEDEF_RID_INLINE;\n\t\t\tfrom_addr = used;\n\t\t\tmemcpy(_MCDI_PTR(inbuf, used), req->from_buf,\n\t\t\t       req->length);\n\t\t\tused += req->length;\n\t\t}\n\n\t\tMCDI_SET_DWORD(record, MEMCPY_RECORD_TYPEDEF_FROM_RID, from_rid);\n\t\tMCDI_SET_QWORD(record, MEMCPY_RECORD_TYPEDEF_FROM_ADDR,\n\t\t\t       from_addr);\n\t\tMCDI_SET_DWORD(record, MEMCPY_RECORD_TYPEDEF_LENGTH,\n\t\t\t       req->length);\n\n\t\t++req;\n\t}\n\n\trc = efx_siena_mcdi_rpc(efx, MC_CMD_MEMCPY, inbuf, used, NULL, 0, NULL);\nout:\n\tmb();\t \n\n\treturn rc;\n}\n\n \nstatic void efx_siena_sriov_reset_tx_filter(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct efx_filter_spec filter;\n\tu16 vlan;\n\tint rc;\n\n\tif (vf->tx_filter_id != -1) {\n\t\tefx_filter_remove_id_safe(efx, EFX_FILTER_PRI_REQUIRED,\n\t\t\t\t\t  vf->tx_filter_id);\n\t\tnetif_dbg(efx, hw, efx->net_dev, \"Removed vf %s tx filter %d\\n\",\n\t\t\t  vf->pci_name, vf->tx_filter_id);\n\t\tvf->tx_filter_id = -1;\n\t}\n\n\tif (is_zero_ether_addr(vf->addr.mac_addr))\n\t\treturn;\n\n\t \n\tif (vf->tx_filter_mode == VF_TX_FILTER_AUTO && vf_max_tx_channels <= 2)\n\t\tvf->tx_filter_mode = VF_TX_FILTER_ON;\n\n\tvlan = ntohs(vf->addr.tci) & VLAN_VID_MASK;\n\tefx_filter_init_tx(&filter, abs_index(vf, 0));\n\trc = efx_filter_set_eth_local(&filter,\n\t\t\t\t      vlan ? vlan : EFX_FILTER_VID_UNSPEC,\n\t\t\t\t      vf->addr.mac_addr);\n\tBUG_ON(rc);\n\n\trc = efx_filter_insert_filter(efx, &filter, true);\n\tif (rc < 0) {\n\t\tnetif_warn(efx, hw, efx->net_dev,\n\t\t\t   \"Unable to migrate tx filter for vf %s\\n\",\n\t\t\t   vf->pci_name);\n\t} else {\n\t\tnetif_dbg(efx, hw, efx->net_dev, \"Inserted vf %s tx filter %d\\n\",\n\t\t\t  vf->pci_name, rc);\n\t\tvf->tx_filter_id = rc;\n\t}\n}\n\n \nstatic void efx_siena_sriov_reset_rx_filter(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct efx_filter_spec filter;\n\tu16 vlan;\n\tint rc;\n\n\tif (vf->rx_filter_id != -1) {\n\t\tefx_filter_remove_id_safe(efx, EFX_FILTER_PRI_REQUIRED,\n\t\t\t\t\t  vf->rx_filter_id);\n\t\tnetif_dbg(efx, hw, efx->net_dev, \"Removed vf %s rx filter %d\\n\",\n\t\t\t  vf->pci_name, vf->rx_filter_id);\n\t\tvf->rx_filter_id = -1;\n\t}\n\n\tif (!vf->rx_filtering || is_zero_ether_addr(vf->addr.mac_addr))\n\t\treturn;\n\n\tvlan = ntohs(vf->addr.tci) & VLAN_VID_MASK;\n\tefx_filter_init_rx(&filter, EFX_FILTER_PRI_REQUIRED,\n\t\t\t   vf->rx_filter_flags,\n\t\t\t   abs_index(vf, vf->rx_filter_qid));\n\trc = efx_filter_set_eth_local(&filter,\n\t\t\t\t      vlan ? vlan : EFX_FILTER_VID_UNSPEC,\n\t\t\t\t      vf->addr.mac_addr);\n\tBUG_ON(rc);\n\n\trc = efx_filter_insert_filter(efx, &filter, true);\n\tif (rc < 0) {\n\t\tnetif_warn(efx, hw, efx->net_dev,\n\t\t\t   \"Unable to insert rx filter for vf %s\\n\",\n\t\t\t   vf->pci_name);\n\t} else {\n\t\tnetif_dbg(efx, hw, efx->net_dev, \"Inserted vf %s rx filter %d\\n\",\n\t\t\t  vf->pci_name, rc);\n\t\tvf->rx_filter_id = rc;\n\t}\n}\n\nstatic void __efx_siena_sriov_update_vf_addr(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\n\tefx_siena_sriov_reset_tx_filter(vf);\n\tefx_siena_sriov_reset_rx_filter(vf);\n\tqueue_work(vfdi_workqueue, &nic_data->peer_work);\n}\n\n \nstatic void __efx_siena_sriov_push_vf_status(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct vfdi_status *status = nic_data->vfdi_status.addr;\n\tstruct efx_memcpy_req copy[4];\n\tstruct efx_endpoint_page *epp;\n\tunsigned int pos, count;\n\tunsigned data_offset;\n\tefx_qword_t event;\n\n\tWARN_ON(!mutex_is_locked(&vf->status_lock));\n\tWARN_ON(!vf->status_addr);\n\n\tstatus->local = vf->addr;\n\tstatus->generation_end = ++status->generation_start;\n\n\tmemset(copy, '\\0', sizeof(copy));\n\t \n\tcopy[0].from_buf = &status->generation_start;\n\tcopy[0].to_rid = vf->pci_rid;\n\tcopy[0].to_addr = vf->status_addr + offsetof(struct vfdi_status,\n\t\t\t\t\t\t     generation_start);\n\tcopy[0].length = sizeof(status->generation_start);\n\t \n\tdata_offset = offsetof(struct vfdi_status, version);\n\tcopy[1].from_rid = efx->pci_dev->devfn;\n\tcopy[1].from_addr = nic_data->vfdi_status.dma_addr + data_offset;\n\tcopy[1].to_rid = vf->pci_rid;\n\tcopy[1].to_addr = vf->status_addr + data_offset;\n\tcopy[1].length =  status->length - data_offset;\n\n\t \n\tpos = 2;\n\tcount = 0;\n\tlist_for_each_entry(epp, &nic_data->local_page_list, link) {\n\t\tif (count == vf->peer_page_count) {\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\t\tcopy[pos].from_buf = NULL;\n\t\tcopy[pos].from_rid = efx->pci_dev->devfn;\n\t\tcopy[pos].from_addr = epp->addr;\n\t\tcopy[pos].to_rid = vf->pci_rid;\n\t\tcopy[pos].to_addr = vf->peer_page_addrs[count];\n\t\tcopy[pos].length = EFX_PAGE_SIZE;\n\n\t\tif (++pos == ARRAY_SIZE(copy)) {\n\t\t\tefx_siena_sriov_memcpy(efx, copy, ARRAY_SIZE(copy));\n\t\t\tpos = 0;\n\t\t}\n\t\t++count;\n\t}\n\n\t \n\tcopy[pos].from_buf = &status->generation_end;\n\tcopy[pos].to_rid = vf->pci_rid;\n\tcopy[pos].to_addr = vf->status_addr + offsetof(struct vfdi_status,\n\t\t\t\t\t\t       generation_end);\n\tcopy[pos].length = sizeof(status->generation_end);\n\tefx_siena_sriov_memcpy(efx, copy, pos + 1);\n\n\t \n\tEFX_POPULATE_QWORD_3(event,\n\t\t\t     FSF_AZ_EV_CODE, FSE_CZ_EV_CODE_USER_EV,\n\t\t\t     VFDI_EV_SEQ, (vf->msg_seqno & 0xff),\n\t\t\t     VFDI_EV_TYPE, VFDI_EV_TYPE_STATUS);\n\t++vf->msg_seqno;\n\tefx_farch_generate_event(efx,\n\t\t\t\t EFX_VI_BASE + vf->index * efx_vf_size(efx),\n\t\t\t\t &event);\n}\n\nstatic void efx_siena_sriov_bufs(struct efx_nic *efx, unsigned offset,\n\t\t\t\t u64 *addr, unsigned count)\n{\n\tefx_qword_t buf;\n\tunsigned pos;\n\n\tfor (pos = 0; pos < count; ++pos) {\n\t\tEFX_POPULATE_QWORD_3(buf,\n\t\t\t\t     FRF_AZ_BUF_ADR_REGION, 0,\n\t\t\t\t     FRF_AZ_BUF_ADR_FBUF,\n\t\t\t\t     addr ? addr[pos] >> 12 : 0,\n\t\t\t\t     FRF_AZ_BUF_OWNER_ID_FBUF, 0);\n\t\tefx_sram_writeq(efx, efx->membase + FR_BZ_BUF_FULL_TBL,\n\t\t\t\t&buf, offset + pos);\n\t}\n}\n\nstatic bool bad_vf_index(struct efx_nic *efx, unsigned index)\n{\n\treturn index >= efx_vf_size(efx);\n}\n\nstatic bool bad_buf_count(unsigned buf_count, unsigned max_entry_count)\n{\n\tunsigned max_buf_count = max_entry_count *\n\t\tsizeof(efx_qword_t) / EFX_BUF_SIZE;\n\n\treturn ((buf_count & (buf_count - 1)) || buf_count > max_buf_count);\n}\n\n \nstatic bool map_vi_index(struct efx_nic *efx, unsigned abs_index,\n\t\t\t struct siena_vf **vf_out, unsigned *rel_index_out)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tunsigned vf_i;\n\n\tif (abs_index < EFX_VI_BASE)\n\t\treturn true;\n\tvf_i = (abs_index - EFX_VI_BASE) / efx_vf_size(efx);\n\tif (vf_i >= efx->vf_init_count)\n\t\treturn true;\n\n\tif (vf_out)\n\t\t*vf_out = nic_data->vf + vf_i;\n\tif (rel_index_out)\n\t\t*rel_index_out = abs_index % efx_vf_size(efx);\n\treturn false;\n}\n\nstatic int efx_vfdi_init_evq(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct vfdi_req *req = vf->buf.addr;\n\tunsigned vf_evq = req->u.init_evq.index;\n\tunsigned buf_count = req->u.init_evq.buf_count;\n\tunsigned abs_evq = abs_index(vf, vf_evq);\n\tunsigned buftbl = EFX_BUFTBL_EVQ_BASE(vf, vf_evq);\n\tefx_oword_t reg;\n\n\tif (bad_vf_index(efx, vf_evq) ||\n\t    bad_buf_count(buf_count, EFX_MAX_VF_EVQ_SIZE)) {\n\t\tif (net_ratelimit())\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"ERROR: Invalid INIT_EVQ from %s: evq %d bufs %d\\n\",\n\t\t\t\t  vf->pci_name, vf_evq, buf_count);\n\t\treturn VFDI_RC_EINVAL;\n\t}\n\n\tefx_siena_sriov_bufs(efx, buftbl, req->u.init_evq.addr, buf_count);\n\n\tEFX_POPULATE_OWORD_3(reg,\n\t\t\t     FRF_CZ_TIMER_Q_EN, 1,\n\t\t\t     FRF_CZ_HOST_NOTIFY_MODE, 0,\n\t\t\t     FRF_CZ_TIMER_MODE, FFE_CZ_TIMER_MODE_DIS);\n\tefx_writeo_table(efx, &reg, FR_BZ_TIMER_TBL, abs_evq);\n\tEFX_POPULATE_OWORD_3(reg,\n\t\t\t     FRF_AZ_EVQ_EN, 1,\n\t\t\t     FRF_AZ_EVQ_SIZE, __ffs(buf_count),\n\t\t\t     FRF_AZ_EVQ_BUF_BASE_ID, buftbl);\n\tefx_writeo_table(efx, &reg, FR_BZ_EVQ_PTR_TBL, abs_evq);\n\n\tif (vf_evq == 0) {\n\t\tmemcpy(vf->evq0_addrs, req->u.init_evq.addr,\n\t\t       buf_count * sizeof(u64));\n\t\tvf->evq0_count = buf_count;\n\t}\n\n\treturn VFDI_RC_SUCCESS;\n}\n\nstatic int efx_vfdi_init_rxq(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct vfdi_req *req = vf->buf.addr;\n\tunsigned vf_rxq = req->u.init_rxq.index;\n\tunsigned vf_evq = req->u.init_rxq.evq;\n\tunsigned buf_count = req->u.init_rxq.buf_count;\n\tunsigned buftbl = EFX_BUFTBL_RXQ_BASE(vf, vf_rxq);\n\tunsigned label;\n\tefx_oword_t reg;\n\n\tif (bad_vf_index(efx, vf_evq) || bad_vf_index(efx, vf_rxq) ||\n\t    vf_rxq >= VF_MAX_RX_QUEUES ||\n\t    bad_buf_count(buf_count, EFX_MAX_DMAQ_SIZE)) {\n\t\tif (net_ratelimit())\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"ERROR: Invalid INIT_RXQ from %s: rxq %d evq %d \"\n\t\t\t\t  \"buf_count %d\\n\", vf->pci_name, vf_rxq,\n\t\t\t\t  vf_evq, buf_count);\n\t\treturn VFDI_RC_EINVAL;\n\t}\n\tif (__test_and_set_bit(req->u.init_rxq.index, vf->rxq_mask))\n\t\t++vf->rxq_count;\n\tefx_siena_sriov_bufs(efx, buftbl, req->u.init_rxq.addr, buf_count);\n\n\tlabel = req->u.init_rxq.label & EFX_FIELD_MASK(FRF_AZ_RX_DESCQ_LABEL);\n\tEFX_POPULATE_OWORD_6(reg,\n\t\t\t     FRF_AZ_RX_DESCQ_BUF_BASE_ID, buftbl,\n\t\t\t     FRF_AZ_RX_DESCQ_EVQ_ID, abs_index(vf, vf_evq),\n\t\t\t     FRF_AZ_RX_DESCQ_LABEL, label,\n\t\t\t     FRF_AZ_RX_DESCQ_SIZE, __ffs(buf_count),\n\t\t\t     FRF_AZ_RX_DESCQ_JUMBO,\n\t\t\t     !!(req->u.init_rxq.flags &\n\t\t\t\tVFDI_RXQ_FLAG_SCATTER_EN),\n\t\t\t     FRF_AZ_RX_DESCQ_EN, 1);\n\tefx_writeo_table(efx, &reg, FR_BZ_RX_DESC_PTR_TBL,\n\t\t\t abs_index(vf, vf_rxq));\n\n\treturn VFDI_RC_SUCCESS;\n}\n\nstatic int efx_vfdi_init_txq(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct vfdi_req *req = vf->buf.addr;\n\tunsigned vf_txq = req->u.init_txq.index;\n\tunsigned vf_evq = req->u.init_txq.evq;\n\tunsigned buf_count = req->u.init_txq.buf_count;\n\tunsigned buftbl = EFX_BUFTBL_TXQ_BASE(vf, vf_txq);\n\tunsigned label, eth_filt_en;\n\tefx_oword_t reg;\n\n\tif (bad_vf_index(efx, vf_evq) || bad_vf_index(efx, vf_txq) ||\n\t    vf_txq >= vf_max_tx_channels ||\n\t    bad_buf_count(buf_count, EFX_MAX_DMAQ_SIZE)) {\n\t\tif (net_ratelimit())\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"ERROR: Invalid INIT_TXQ from %s: txq %d evq %d \"\n\t\t\t\t  \"buf_count %d\\n\", vf->pci_name, vf_txq,\n\t\t\t\t  vf_evq, buf_count);\n\t\treturn VFDI_RC_EINVAL;\n\t}\n\n\tmutex_lock(&vf->txq_lock);\n\tif (__test_and_set_bit(req->u.init_txq.index, vf->txq_mask))\n\t\t++vf->txq_count;\n\tmutex_unlock(&vf->txq_lock);\n\tefx_siena_sriov_bufs(efx, buftbl, req->u.init_txq.addr, buf_count);\n\n\teth_filt_en = vf->tx_filter_mode == VF_TX_FILTER_ON;\n\n\tlabel = req->u.init_txq.label & EFX_FIELD_MASK(FRF_AZ_TX_DESCQ_LABEL);\n\tEFX_POPULATE_OWORD_8(reg,\n\t\t\t     FRF_CZ_TX_DPT_Q_MASK_WIDTH, min(efx->vi_scale, 1U),\n\t\t\t     FRF_CZ_TX_DPT_ETH_FILT_EN, eth_filt_en,\n\t\t\t     FRF_AZ_TX_DESCQ_EN, 1,\n\t\t\t     FRF_AZ_TX_DESCQ_BUF_BASE_ID, buftbl,\n\t\t\t     FRF_AZ_TX_DESCQ_EVQ_ID, abs_index(vf, vf_evq),\n\t\t\t     FRF_AZ_TX_DESCQ_LABEL, label,\n\t\t\t     FRF_AZ_TX_DESCQ_SIZE, __ffs(buf_count),\n\t\t\t     FRF_BZ_TX_NON_IP_DROP_DIS, 1);\n\tefx_writeo_table(efx, &reg, FR_BZ_TX_DESC_PTR_TBL,\n\t\t\t abs_index(vf, vf_txq));\n\n\treturn VFDI_RC_SUCCESS;\n}\n\n \nstatic bool efx_vfdi_flush_wake(struct siena_vf *vf)\n{\n\t \n\tsmp_mb();\n\n\treturn (!vf->txq_count && !vf->rxq_count) ||\n\t\tatomic_read(&vf->rxq_retry_count);\n}\n\nstatic void efx_vfdi_flush_clear(struct siena_vf *vf)\n{\n\tmemset(vf->txq_mask, 0, sizeof(vf->txq_mask));\n\tvf->txq_count = 0;\n\tmemset(vf->rxq_mask, 0, sizeof(vf->rxq_mask));\n\tvf->rxq_count = 0;\n\tmemset(vf->rxq_retry_mask, 0, sizeof(vf->rxq_retry_mask));\n\tatomic_set(&vf->rxq_retry_count, 0);\n}\n\nstatic int efx_vfdi_fini_all_queues(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tefx_oword_t reg;\n\tunsigned count = efx_vf_size(efx);\n\tunsigned vf_offset = EFX_VI_BASE + vf->index * efx_vf_size(efx);\n\tunsigned timeout = HZ;\n\tunsigned index, rxqs_count;\n\tMCDI_DECLARE_BUF(inbuf, MC_CMD_FLUSH_RX_QUEUES_IN_LENMAX);\n\tint rc;\n\n\tBUILD_BUG_ON(VF_MAX_RX_QUEUES >\n\t\t     MC_CMD_FLUSH_RX_QUEUES_IN_QID_OFST_MAXNUM);\n\n\trtnl_lock();\n\tefx_siena_prepare_flush(efx);\n\trtnl_unlock();\n\n\t \n\trxqs_count = 0;\n\tfor (index = 0; index < count; ++index) {\n\t\tif (test_bit(index, vf->txq_mask)) {\n\t\t\tEFX_POPULATE_OWORD_2(reg,\n\t\t\t\t\t     FRF_AZ_TX_FLUSH_DESCQ_CMD, 1,\n\t\t\t\t\t     FRF_AZ_TX_FLUSH_DESCQ,\n\t\t\t\t\t     vf_offset + index);\n\t\t\tefx_writeo(efx, &reg, FR_AZ_TX_FLUSH_DESCQ);\n\t\t}\n\t\tif (test_bit(index, vf->rxq_mask)) {\n\t\t\tMCDI_SET_ARRAY_DWORD(\n\t\t\t\tinbuf, FLUSH_RX_QUEUES_IN_QID_OFST,\n\t\t\t\trxqs_count, vf_offset + index);\n\t\t\trxqs_count++;\n\t\t}\n\t}\n\n\tatomic_set(&vf->rxq_retry_count, 0);\n\twhile (timeout && (vf->rxq_count || vf->txq_count)) {\n\t\trc = efx_siena_mcdi_rpc(efx, MC_CMD_FLUSH_RX_QUEUES, inbuf,\n\t\t\t\t  MC_CMD_FLUSH_RX_QUEUES_IN_LEN(rxqs_count),\n\t\t\t\t  NULL, 0, NULL);\n\t\tWARN_ON(rc < 0);\n\n\t\ttimeout = wait_event_timeout(vf->flush_waitq,\n\t\t\t\t\t     efx_vfdi_flush_wake(vf),\n\t\t\t\t\t     timeout);\n\t\trxqs_count = 0;\n\t\tfor (index = 0; index < count; ++index) {\n\t\t\tif (test_and_clear_bit(index, vf->rxq_retry_mask)) {\n\t\t\t\tatomic_dec(&vf->rxq_retry_count);\n\t\t\t\tMCDI_SET_ARRAY_DWORD(\n\t\t\t\t\tinbuf, FLUSH_RX_QUEUES_IN_QID_OFST,\n\t\t\t\t\trxqs_count, vf_offset + index);\n\t\t\t\trxqs_count++;\n\t\t\t}\n\t\t}\n\t}\n\n\trtnl_lock();\n\tsiena_finish_flush(efx);\n\trtnl_unlock();\n\n\t \n\tEFX_ZERO_OWORD(reg);\n\tfor (index = 0; index < count; ++index) {\n\t\tefx_writeo_table(efx, &reg, FR_BZ_RX_DESC_PTR_TBL,\n\t\t\t\t vf_offset + index);\n\t\tefx_writeo_table(efx, &reg, FR_BZ_TX_DESC_PTR_TBL,\n\t\t\t\t vf_offset + index);\n\t\tefx_writeo_table(efx, &reg, FR_BZ_EVQ_PTR_TBL,\n\t\t\t\t vf_offset + index);\n\t\tefx_writeo_table(efx, &reg, FR_BZ_TIMER_TBL,\n\t\t\t\t vf_offset + index);\n\t}\n\tefx_siena_sriov_bufs(efx, vf->buftbl_base, NULL,\n\t\t\t     EFX_VF_BUFTBL_PER_VI * efx_vf_size(efx));\n\tefx_vfdi_flush_clear(vf);\n\n\tvf->evq0_count = 0;\n\n\treturn timeout ? 0 : VFDI_RC_ETIMEDOUT;\n}\n\nstatic int efx_vfdi_insert_filter(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct vfdi_req *req = vf->buf.addr;\n\tunsigned vf_rxq = req->u.mac_filter.rxq;\n\tunsigned flags;\n\n\tif (bad_vf_index(efx, vf_rxq) || vf->rx_filtering) {\n\t\tif (net_ratelimit())\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"ERROR: Invalid INSERT_FILTER from %s: rxq %d \"\n\t\t\t\t  \"flags 0x%x\\n\", vf->pci_name, vf_rxq,\n\t\t\t\t  req->u.mac_filter.flags);\n\t\treturn VFDI_RC_EINVAL;\n\t}\n\n\tflags = 0;\n\tif (req->u.mac_filter.flags & VFDI_MAC_FILTER_FLAG_RSS)\n\t\tflags |= EFX_FILTER_FLAG_RX_RSS;\n\tif (req->u.mac_filter.flags & VFDI_MAC_FILTER_FLAG_SCATTER)\n\t\tflags |= EFX_FILTER_FLAG_RX_SCATTER;\n\tvf->rx_filter_flags = flags;\n\tvf->rx_filter_qid = vf_rxq;\n\tvf->rx_filtering = true;\n\n\tefx_siena_sriov_reset_rx_filter(vf);\n\tqueue_work(vfdi_workqueue, &nic_data->peer_work);\n\n\treturn VFDI_RC_SUCCESS;\n}\n\nstatic int efx_vfdi_remove_all_filters(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\n\tvf->rx_filtering = false;\n\tefx_siena_sriov_reset_rx_filter(vf);\n\tqueue_work(vfdi_workqueue, &nic_data->peer_work);\n\n\treturn VFDI_RC_SUCCESS;\n}\n\nstatic int efx_vfdi_set_status_page(struct siena_vf *vf)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct vfdi_req *req = vf->buf.addr;\n\tu64 page_count = req->u.set_status_page.peer_page_count;\n\tu64 max_page_count =\n\t\t(EFX_PAGE_SIZE -\n\t\t offsetof(struct vfdi_req, u.set_status_page.peer_page_addr[0]))\n\t\t/ sizeof(req->u.set_status_page.peer_page_addr[0]);\n\n\tif (!req->u.set_status_page.dma_addr || page_count > max_page_count) {\n\t\tif (net_ratelimit())\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"ERROR: Invalid SET_STATUS_PAGE from %s\\n\",\n\t\t\t\t  vf->pci_name);\n\t\treturn VFDI_RC_EINVAL;\n\t}\n\n\tmutex_lock(&nic_data->local_lock);\n\tmutex_lock(&vf->status_lock);\n\tvf->status_addr = req->u.set_status_page.dma_addr;\n\n\tkfree(vf->peer_page_addrs);\n\tvf->peer_page_addrs = NULL;\n\tvf->peer_page_count = 0;\n\n\tif (page_count) {\n\t\tvf->peer_page_addrs = kcalloc(page_count, sizeof(u64),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (vf->peer_page_addrs) {\n\t\t\tmemcpy(vf->peer_page_addrs,\n\t\t\t       req->u.set_status_page.peer_page_addr,\n\t\t\t       page_count * sizeof(u64));\n\t\t\tvf->peer_page_count = page_count;\n\t\t}\n\t}\n\n\t__efx_siena_sriov_push_vf_status(vf);\n\tmutex_unlock(&vf->status_lock);\n\tmutex_unlock(&nic_data->local_lock);\n\n\treturn VFDI_RC_SUCCESS;\n}\n\nstatic int efx_vfdi_clear_status_page(struct siena_vf *vf)\n{\n\tmutex_lock(&vf->status_lock);\n\tvf->status_addr = 0;\n\tmutex_unlock(&vf->status_lock);\n\n\treturn VFDI_RC_SUCCESS;\n}\n\ntypedef int (*efx_vfdi_op_t)(struct siena_vf *vf);\n\nstatic const efx_vfdi_op_t vfdi_ops[VFDI_OP_LIMIT] = {\n\t[VFDI_OP_INIT_EVQ] = efx_vfdi_init_evq,\n\t[VFDI_OP_INIT_TXQ] = efx_vfdi_init_txq,\n\t[VFDI_OP_INIT_RXQ] = efx_vfdi_init_rxq,\n\t[VFDI_OP_FINI_ALL_QUEUES] = efx_vfdi_fini_all_queues,\n\t[VFDI_OP_INSERT_FILTER] = efx_vfdi_insert_filter,\n\t[VFDI_OP_REMOVE_ALL_FILTERS] = efx_vfdi_remove_all_filters,\n\t[VFDI_OP_SET_STATUS_PAGE] = efx_vfdi_set_status_page,\n\t[VFDI_OP_CLEAR_STATUS_PAGE] = efx_vfdi_clear_status_page,\n};\n\nstatic void efx_siena_sriov_vfdi(struct work_struct *work)\n{\n\tstruct siena_vf *vf = container_of(work, struct siena_vf, req);\n\tstruct efx_nic *efx = vf->efx;\n\tstruct vfdi_req *req = vf->buf.addr;\n\tstruct efx_memcpy_req copy[2];\n\tint rc;\n\n\t \n\tmemset(copy, '\\0', sizeof(copy));\n\tcopy[0].from_rid = vf->pci_rid;\n\tcopy[0].from_addr = vf->req_addr;\n\tcopy[0].to_rid = efx->pci_dev->devfn;\n\tcopy[0].to_addr = vf->buf.dma_addr;\n\tcopy[0].length = EFX_PAGE_SIZE;\n\trc = efx_siena_sriov_memcpy(efx, copy, 1);\n\tif (rc) {\n\t\t \n\t\tif (net_ratelimit())\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"ERROR: Unable to fetch VFDI request from %s rc %d\\n\",\n\t\t\t\t  vf->pci_name, -rc);\n\t\tvf->busy = false;\n\t\treturn;\n\t}\n\n\tif (req->op < VFDI_OP_LIMIT && vfdi_ops[req->op] != NULL) {\n\t\trc = vfdi_ops[req->op](vf);\n\t\tif (rc == 0) {\n\t\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t\t  \"vfdi request %d from %s ok\\n\",\n\t\t\t\t  req->op, vf->pci_name);\n\t\t}\n\t} else {\n\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t  \"ERROR: Unrecognised request %d from VF %s addr \"\n\t\t\t  \"%llx\\n\", req->op, vf->pci_name,\n\t\t\t  (unsigned long long)vf->req_addr);\n\t\trc = VFDI_RC_EOPNOTSUPP;\n\t}\n\n\t \n\tvf->busy = false;\n\tsmp_wmb();\n\n\t \n\treq->rc = rc;\n\treq->op = VFDI_OP_RESPONSE;\n\n\tmemset(copy, '\\0', sizeof(copy));\n\tcopy[0].from_buf = &req->rc;\n\tcopy[0].to_rid = vf->pci_rid;\n\tcopy[0].to_addr = vf->req_addr + offsetof(struct vfdi_req, rc);\n\tcopy[0].length = sizeof(req->rc);\n\tcopy[1].from_buf = &req->op;\n\tcopy[1].to_rid = vf->pci_rid;\n\tcopy[1].to_addr = vf->req_addr + offsetof(struct vfdi_req, op);\n\tcopy[1].length = sizeof(req->op);\n\n\t(void)efx_siena_sriov_memcpy(efx, copy, ARRAY_SIZE(copy));\n}\n\n\n\n \n\nstatic void efx_siena_sriov_reset_vf(struct siena_vf *vf,\n\t\t\t\t     struct efx_buffer *buffer)\n{\n\tstruct efx_nic *efx = vf->efx;\n\tstruct efx_memcpy_req copy_req[4];\n\tefx_qword_t event;\n\tunsigned int pos, count, k, buftbl, abs_evq;\n\tefx_oword_t reg;\n\tefx_dword_t ptr;\n\tint rc;\n\n\tBUG_ON(buffer->len != EFX_PAGE_SIZE);\n\n\tif (!vf->evq0_count)\n\t\treturn;\n\tBUG_ON(vf->evq0_count & (vf->evq0_count - 1));\n\n\tmutex_lock(&vf->status_lock);\n\tEFX_POPULATE_QWORD_3(event,\n\t\t\t     FSF_AZ_EV_CODE, FSE_CZ_EV_CODE_USER_EV,\n\t\t\t     VFDI_EV_SEQ, vf->msg_seqno,\n\t\t\t     VFDI_EV_TYPE, VFDI_EV_TYPE_RESET);\n\tvf->msg_seqno++;\n\tfor (pos = 0; pos < EFX_PAGE_SIZE; pos += sizeof(event))\n\t\tmemcpy(buffer->addr + pos, &event, sizeof(event));\n\n\tfor (pos = 0; pos < vf->evq0_count; pos += count) {\n\t\tcount = min_t(unsigned, vf->evq0_count - pos,\n\t\t\t      ARRAY_SIZE(copy_req));\n\t\tfor (k = 0; k < count; k++) {\n\t\t\tcopy_req[k].from_buf = NULL;\n\t\t\tcopy_req[k].from_rid = efx->pci_dev->devfn;\n\t\t\tcopy_req[k].from_addr = buffer->dma_addr;\n\t\t\tcopy_req[k].to_rid = vf->pci_rid;\n\t\t\tcopy_req[k].to_addr = vf->evq0_addrs[pos + k];\n\t\t\tcopy_req[k].length = EFX_PAGE_SIZE;\n\t\t}\n\t\trc = efx_siena_sriov_memcpy(efx, copy_req, count);\n\t\tif (rc) {\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t\t  \"ERROR: Unable to notify %s of reset\"\n\t\t\t\t\t  \": %d\\n\", vf->pci_name, -rc);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tabs_evq = abs_index(vf, 0);\n\tbuftbl = EFX_BUFTBL_EVQ_BASE(vf, 0);\n\tefx_siena_sriov_bufs(efx, buftbl, vf->evq0_addrs, vf->evq0_count);\n\n\tEFX_POPULATE_OWORD_3(reg,\n\t\t\t     FRF_CZ_TIMER_Q_EN, 1,\n\t\t\t     FRF_CZ_HOST_NOTIFY_MODE, 0,\n\t\t\t     FRF_CZ_TIMER_MODE, FFE_CZ_TIMER_MODE_DIS);\n\tefx_writeo_table(efx, &reg, FR_BZ_TIMER_TBL, abs_evq);\n\tEFX_POPULATE_OWORD_3(reg,\n\t\t\t     FRF_AZ_EVQ_EN, 1,\n\t\t\t     FRF_AZ_EVQ_SIZE, __ffs(vf->evq0_count),\n\t\t\t     FRF_AZ_EVQ_BUF_BASE_ID, buftbl);\n\tefx_writeo_table(efx, &reg, FR_BZ_EVQ_PTR_TBL, abs_evq);\n\tEFX_POPULATE_DWORD_1(ptr, FRF_AZ_EVQ_RPTR, 0);\n\tefx_writed(efx, &ptr, FR_BZ_EVQ_RPTR + FR_BZ_EVQ_RPTR_STEP * abs_evq);\n\n\tmutex_unlock(&vf->status_lock);\n}\n\nstatic void efx_siena_sriov_reset_vf_work(struct work_struct *work)\n{\n\tstruct siena_vf *vf = container_of(work, struct siena_vf, req);\n\tstruct efx_nic *efx = vf->efx;\n\tstruct efx_buffer buf;\n\n\tif (!efx_siena_alloc_buffer(efx, &buf, EFX_PAGE_SIZE, GFP_NOIO)) {\n\t\tefx_siena_sriov_reset_vf(vf, &buf);\n\t\tefx_siena_free_buffer(efx, &buf);\n\t}\n}\n\nstatic void efx_siena_sriov_handle_no_channel(struct efx_nic *efx)\n{\n\tnetif_err(efx, drv, efx->net_dev,\n\t\t  \"ERROR: IOV requires MSI-X and 1 additional interrupt\"\n\t\t  \"vector. IOV disabled\\n\");\n\tefx->vf_count = 0;\n}\n\nstatic int efx_siena_sriov_probe_channel(struct efx_channel *channel)\n{\n\tstruct siena_nic_data *nic_data = channel->efx->nic_data;\n\tnic_data->vfdi_channel = channel;\n\n\treturn 0;\n}\n\nstatic void\nefx_siena_sriov_get_channel_name(struct efx_channel *channel,\n\t\t\t\t char *buf, size_t len)\n{\n\tsnprintf(buf, len, \"%s-iov\", channel->efx->name);\n}\n\nstatic const struct efx_channel_type efx_siena_sriov_channel_type = {\n\t.handle_no_channel\t= efx_siena_sriov_handle_no_channel,\n\t.pre_probe\t\t= efx_siena_sriov_probe_channel,\n\t.post_remove\t\t= efx_siena_channel_dummy_op_void,\n\t.get_name\t\t= efx_siena_sriov_get_channel_name,\n\t \n\t.keep_eventq\t\t= true,\n};\n\nvoid efx_siena_sriov_probe(struct efx_nic *efx)\n{\n\tunsigned count;\n\n\tif (!max_vfs)\n\t\treturn;\n\n\tif (efx_siena_sriov_cmd(efx, false, &efx->vi_scale, &count)) {\n\t\tpci_info(efx->pci_dev, \"no SR-IOV VFs probed\\n\");\n\t\treturn;\n\t}\n\tif (count > 0 && count > max_vfs)\n\t\tcount = max_vfs;\n\n\t \n\tefx->vf_count = count;\n\n\tefx->extra_channel_type[EFX_EXTRA_CHANNEL_IOV] = &efx_siena_sriov_channel_type;\n}\n\n \nstatic void efx_siena_sriov_peer_work(struct work_struct *data)\n{\n\tstruct siena_nic_data *nic_data = container_of(data,\n\t\t\t\t\t\t       struct siena_nic_data,\n\t\t\t\t\t\t       peer_work);\n\tstruct efx_nic *efx = nic_data->efx;\n\tstruct vfdi_status *vfdi_status = nic_data->vfdi_status.addr;\n\tstruct siena_vf *vf;\n\tstruct efx_local_addr *local_addr;\n\tstruct vfdi_endpoint *peer;\n\tstruct efx_endpoint_page *epp;\n\tstruct list_head pages;\n\tunsigned int peer_space;\n\tunsigned int peer_count;\n\tunsigned int pos;\n\n\tmutex_lock(&nic_data->local_lock);\n\n\t \n\tINIT_LIST_HEAD(&pages);\n\tlist_splice_tail_init(&nic_data->local_page_list, &pages);\n\n\t \n\tpeer = vfdi_status->peers + 1;\n\tpeer_space = ARRAY_SIZE(vfdi_status->peers) - 1;\n\tpeer_count = 1;\n\tfor (pos = 0; pos < efx->vf_count; ++pos) {\n\t\tvf = nic_data->vf + pos;\n\n\t\tmutex_lock(&vf->status_lock);\n\t\tif (vf->rx_filtering && !is_zero_ether_addr(vf->addr.mac_addr)) {\n\t\t\t*peer++ = vf->addr;\n\t\t\t++peer_count;\n\t\t\t--peer_space;\n\t\t\tBUG_ON(peer_space == 0);\n\t\t}\n\t\tmutex_unlock(&vf->status_lock);\n\t}\n\n\t \n\tlist_for_each_entry(local_addr, &nic_data->local_addr_list, link) {\n\t\tether_addr_copy(peer->mac_addr, local_addr->addr);\n\t\tpeer->tci = 0;\n\t\t++peer;\n\t\t++peer_count;\n\t\tif (--peer_space == 0) {\n\t\t\tif (list_empty(&pages)) {\n\t\t\t\tepp = kmalloc(sizeof(*epp), GFP_KERNEL);\n\t\t\t\tif (!epp)\n\t\t\t\t\tbreak;\n\t\t\t\tepp->ptr = dma_alloc_coherent(\n\t\t\t\t\t&efx->pci_dev->dev, EFX_PAGE_SIZE,\n\t\t\t\t\t&epp->addr, GFP_KERNEL);\n\t\t\t\tif (!epp->ptr) {\n\t\t\t\t\tkfree(epp);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tepp = list_first_entry(\n\t\t\t\t\t&pages, struct efx_endpoint_page, link);\n\t\t\t\tlist_del(&epp->link);\n\t\t\t}\n\n\t\t\tlist_add_tail(&epp->link, &nic_data->local_page_list);\n\t\t\tpeer = (struct vfdi_endpoint *)epp->ptr;\n\t\t\tpeer_space = EFX_PAGE_SIZE / sizeof(struct vfdi_endpoint);\n\t\t}\n\t}\n\tvfdi_status->peer_count = peer_count;\n\tmutex_unlock(&nic_data->local_lock);\n\n\t \n\twhile (!list_empty(&pages)) {\n\t\tepp = list_first_entry(\n\t\t\t&pages, struct efx_endpoint_page, link);\n\t\tlist_del(&epp->link);\n\t\tdma_free_coherent(&efx->pci_dev->dev, EFX_PAGE_SIZE,\n\t\t\t\t  epp->ptr, epp->addr);\n\t\tkfree(epp);\n\t}\n\n\t \n\tfor (pos = 0; pos < efx->vf_count; ++pos) {\n\t\tvf = nic_data->vf + pos;\n\n\t\tmutex_lock(&vf->status_lock);\n\t\tif (vf->status_addr)\n\t\t\t__efx_siena_sriov_push_vf_status(vf);\n\t\tmutex_unlock(&vf->status_lock);\n\t}\n}\n\nstatic void efx_siena_sriov_free_local(struct efx_nic *efx)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct efx_local_addr *local_addr;\n\tstruct efx_endpoint_page *epp;\n\n\twhile (!list_empty(&nic_data->local_addr_list)) {\n\t\tlocal_addr = list_first_entry(&nic_data->local_addr_list,\n\t\t\t\t\t      struct efx_local_addr, link);\n\t\tlist_del(&local_addr->link);\n\t\tkfree(local_addr);\n\t}\n\n\twhile (!list_empty(&nic_data->local_page_list)) {\n\t\tepp = list_first_entry(&nic_data->local_page_list,\n\t\t\t\t       struct efx_endpoint_page, link);\n\t\tlist_del(&epp->link);\n\t\tdma_free_coherent(&efx->pci_dev->dev, EFX_PAGE_SIZE,\n\t\t\t\t  epp->ptr, epp->addr);\n\t\tkfree(epp);\n\t}\n}\n\nstatic int efx_siena_sriov_vf_alloc(struct efx_nic *efx)\n{\n\tunsigned index;\n\tstruct siena_vf *vf;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\n\tnic_data->vf = kcalloc(efx->vf_count, sizeof(*nic_data->vf),\n\t\t\t       GFP_KERNEL);\n\tif (!nic_data->vf)\n\t\treturn -ENOMEM;\n\n\tfor (index = 0; index < efx->vf_count; ++index) {\n\t\tvf = nic_data->vf + index;\n\n\t\tvf->efx = efx;\n\t\tvf->index = index;\n\t\tvf->rx_filter_id = -1;\n\t\tvf->tx_filter_mode = VF_TX_FILTER_AUTO;\n\t\tvf->tx_filter_id = -1;\n\t\tINIT_WORK(&vf->req, efx_siena_sriov_vfdi);\n\t\tINIT_WORK(&vf->reset_work, efx_siena_sriov_reset_vf_work);\n\t\tinit_waitqueue_head(&vf->flush_waitq);\n\t\tmutex_init(&vf->status_lock);\n\t\tmutex_init(&vf->txq_lock);\n\t}\n\n\treturn 0;\n}\n\nstatic void efx_siena_sriov_vfs_fini(struct efx_nic *efx)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct siena_vf *vf;\n\tunsigned int pos;\n\n\tfor (pos = 0; pos < efx->vf_count; ++pos) {\n\t\tvf = nic_data->vf + pos;\n\n\t\tefx_siena_free_buffer(efx, &vf->buf);\n\t\tkfree(vf->peer_page_addrs);\n\t\tvf->peer_page_addrs = NULL;\n\t\tvf->peer_page_count = 0;\n\n\t\tvf->evq0_count = 0;\n\t}\n}\n\nstatic int efx_siena_sriov_vfs_init(struct efx_nic *efx)\n{\n\tstruct pci_dev *pci_dev = efx->pci_dev;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tunsigned index, devfn, sriov, buftbl_base;\n\tu16 offset, stride;\n\tstruct siena_vf *vf;\n\tint rc;\n\n\tsriov = pci_find_ext_capability(pci_dev, PCI_EXT_CAP_ID_SRIOV);\n\tif (!sriov)\n\t\treturn -ENOENT;\n\n\tpci_read_config_word(pci_dev, sriov + PCI_SRIOV_VF_OFFSET, &offset);\n\tpci_read_config_word(pci_dev, sriov + PCI_SRIOV_VF_STRIDE, &stride);\n\n\tbuftbl_base = nic_data->vf_buftbl_base;\n\tdevfn = pci_dev->devfn + offset;\n\tfor (index = 0; index < efx->vf_count; ++index) {\n\t\tvf = nic_data->vf + index;\n\n\t\t \n\t\tvf->buftbl_base = buftbl_base;\n\t\tbuftbl_base += EFX_VF_BUFTBL_PER_VI * efx_vf_size(efx);\n\n\t\tvf->pci_rid = devfn;\n\t\tsnprintf(vf->pci_name, sizeof(vf->pci_name),\n\t\t\t \"%04x:%02x:%02x.%d\",\n\t\t\t pci_domain_nr(pci_dev->bus), pci_dev->bus->number,\n\t\t\t PCI_SLOT(devfn), PCI_FUNC(devfn));\n\n\t\trc = efx_siena_alloc_buffer(efx, &vf->buf, EFX_PAGE_SIZE,\n\t\t\t\t\t    GFP_KERNEL);\n\t\tif (rc)\n\t\t\tgoto fail;\n\n\t\tdevfn += stride;\n\t}\n\n\treturn 0;\n\nfail:\n\tefx_siena_sriov_vfs_fini(efx);\n\treturn rc;\n}\n\nint efx_siena_sriov_init(struct efx_nic *efx)\n{\n\tstruct net_device *net_dev = efx->net_dev;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct vfdi_status *vfdi_status;\n\tint rc;\n\n\t \n\tBUILD_BUG_ON(EFX_MAX_CHANNELS + 1 >= EFX_VI_BASE);\n\t \n\tBUILD_BUG_ON(EFX_VI_BASE & ((1 << EFX_VI_SCALE_MAX) - 1));\n\n\tif (efx->vf_count == 0)\n\t\treturn 0;\n\n\trc = efx_siena_sriov_cmd(efx, true, NULL, NULL);\n\tif (rc)\n\t\tgoto fail_cmd;\n\n\trc = efx_siena_alloc_buffer(efx, &nic_data->vfdi_status,\n\t\t\t\t    sizeof(*vfdi_status), GFP_KERNEL);\n\tif (rc)\n\t\tgoto fail_status;\n\tvfdi_status = nic_data->vfdi_status.addr;\n\tmemset(vfdi_status, 0, sizeof(*vfdi_status));\n\tvfdi_status->version = 1;\n\tvfdi_status->length = sizeof(*vfdi_status);\n\tvfdi_status->max_tx_channels = vf_max_tx_channels;\n\tvfdi_status->vi_scale = efx->vi_scale;\n\tvfdi_status->rss_rxq_count = efx->rss_spread;\n\tvfdi_status->peer_count = 1 + efx->vf_count;\n\tvfdi_status->timer_quantum_ns = efx->timer_quantum_ns;\n\n\trc = efx_siena_sriov_vf_alloc(efx);\n\tif (rc)\n\t\tgoto fail_alloc;\n\n\tmutex_init(&nic_data->local_lock);\n\tINIT_WORK(&nic_data->peer_work, efx_siena_sriov_peer_work);\n\tINIT_LIST_HEAD(&nic_data->local_addr_list);\n\tINIT_LIST_HEAD(&nic_data->local_page_list);\n\n\trc = efx_siena_sriov_vfs_init(efx);\n\tif (rc)\n\t\tgoto fail_vfs;\n\n\trtnl_lock();\n\tether_addr_copy(vfdi_status->peers[0].mac_addr, net_dev->dev_addr);\n\tefx->vf_init_count = efx->vf_count;\n\trtnl_unlock();\n\n\tefx_siena_sriov_usrev(efx, true);\n\n\t \n\n\trc = pci_enable_sriov(efx->pci_dev, efx->vf_count);\n\tif (rc)\n\t\tgoto fail_pci;\n\n\tnetif_info(efx, probe, net_dev,\n\t\t   \"enabled SR-IOV for %d VFs, %d VI per VF\\n\",\n\t\t   efx->vf_count, efx_vf_size(efx));\n\treturn 0;\n\nfail_pci:\n\tefx_siena_sriov_usrev(efx, false);\n\trtnl_lock();\n\tefx->vf_init_count = 0;\n\trtnl_unlock();\n\tefx_siena_sriov_vfs_fini(efx);\nfail_vfs:\n\tcancel_work_sync(&nic_data->peer_work);\n\tefx_siena_sriov_free_local(efx);\n\tkfree(nic_data->vf);\nfail_alloc:\n\tefx_siena_free_buffer(efx, &nic_data->vfdi_status);\nfail_status:\n\tefx_siena_sriov_cmd(efx, false, NULL, NULL);\nfail_cmd:\n\treturn rc;\n}\n\nvoid efx_siena_sriov_fini(struct efx_nic *efx)\n{\n\tstruct siena_vf *vf;\n\tunsigned int pos;\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\n\tif (efx->vf_init_count == 0)\n\t\treturn;\n\n\t \n\tBUG_ON(nic_data->vfdi_channel->enabled);\n\tefx_siena_sriov_usrev(efx, false);\n\trtnl_lock();\n\tefx->vf_init_count = 0;\n\trtnl_unlock();\n\n\t \n\tfor (pos = 0; pos < efx->vf_count; ++pos) {\n\t\tvf = nic_data->vf + pos;\n\t\tcancel_work_sync(&vf->req);\n\t\tcancel_work_sync(&vf->reset_work);\n\t}\n\tcancel_work_sync(&nic_data->peer_work);\n\n\tpci_disable_sriov(efx->pci_dev);\n\n\t \n\tefx_siena_sriov_vfs_fini(efx);\n\tefx_siena_sriov_free_local(efx);\n\tkfree(nic_data->vf);\n\tefx_siena_free_buffer(efx, &nic_data->vfdi_status);\n\tefx_siena_sriov_cmd(efx, false, NULL, NULL);\n}\n\nvoid efx_siena_sriov_event(struct efx_channel *channel, efx_qword_t *event)\n{\n\tstruct efx_nic *efx = channel->efx;\n\tstruct siena_vf *vf;\n\tunsigned qid, seq, type, data;\n\n\tqid = EFX_QWORD_FIELD(*event, FSF_CZ_USER_QID);\n\n\t \n\tBUILD_BUG_ON(FSF_CZ_USER_EV_REG_VALUE_LBN != 0);\n\tseq = EFX_QWORD_FIELD(*event, VFDI_EV_SEQ);\n\ttype = EFX_QWORD_FIELD(*event, VFDI_EV_TYPE);\n\tdata = EFX_QWORD_FIELD(*event, VFDI_EV_DATA);\n\n\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t   \"USR_EV event from qid %d seq 0x%x type %d data 0x%x\\n\",\n\t\t   qid, seq, type, data);\n\n\tif (map_vi_index(efx, qid, &vf, NULL))\n\t\treturn;\n\tif (vf->busy)\n\t\tgoto error;\n\n\tif (type == VFDI_EV_TYPE_REQ_WORD0) {\n\t\t \n\t\tvf->req_type = VFDI_EV_TYPE_REQ_WORD0;\n\t\tvf->req_seqno = seq + 1;\n\t\tvf->req_addr = 0;\n\t} else if (seq != (vf->req_seqno++ & 0xff) || type != vf->req_type)\n\t\tgoto error;\n\n\tswitch (vf->req_type) {\n\tcase VFDI_EV_TYPE_REQ_WORD0:\n\tcase VFDI_EV_TYPE_REQ_WORD1:\n\tcase VFDI_EV_TYPE_REQ_WORD2:\n\t\tvf->req_addr |= (u64)data << (vf->req_type << 4);\n\t\t++vf->req_type;\n\t\treturn;\n\n\tcase VFDI_EV_TYPE_REQ_WORD3:\n\t\tvf->req_addr |= (u64)data << 48;\n\t\tvf->req_type = VFDI_EV_TYPE_REQ_WORD0;\n\t\tvf->busy = true;\n\t\tqueue_work(vfdi_workqueue, &vf->req);\n\t\treturn;\n\t}\n\nerror:\n\tif (net_ratelimit())\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"ERROR: Screaming VFDI request from %s\\n\",\n\t\t\t  vf->pci_name);\n\t \n\tvf->req_type = VFDI_EV_TYPE_REQ_WORD0;\n\tvf->req_seqno = seq + 1;\n}\n\nvoid efx_siena_sriov_flr(struct efx_nic *efx, unsigned vf_i)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct siena_vf *vf;\n\n\tif (vf_i > efx->vf_init_count)\n\t\treturn;\n\tvf = nic_data->vf + vf_i;\n\tnetif_info(efx, hw, efx->net_dev,\n\t\t   \"FLR on VF %s\\n\", vf->pci_name);\n\n\tvf->status_addr = 0;\n\tefx_vfdi_remove_all_filters(vf);\n\tefx_vfdi_flush_clear(vf);\n\n\tvf->evq0_count = 0;\n}\n\nint efx_siena_sriov_mac_address_changed(struct efx_nic *efx)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct vfdi_status *vfdi_status = nic_data->vfdi_status.addr;\n\n\tif (!efx->vf_init_count)\n\t\treturn 0;\n\tether_addr_copy(vfdi_status->peers[0].mac_addr,\n\t\t\tefx->net_dev->dev_addr);\n\tqueue_work(vfdi_workqueue, &nic_data->peer_work);\n\n\treturn 0;\n}\n\nvoid efx_siena_sriov_tx_flush_done(struct efx_nic *efx, efx_qword_t *event)\n{\n\tstruct siena_vf *vf;\n\tunsigned queue, qid;\n\n\tqueue = EFX_QWORD_FIELD(*event,  FSF_AZ_DRIVER_EV_SUBDATA);\n\tif (map_vi_index(efx, queue, &vf, &qid))\n\t\treturn;\n\t \n\tif (!test_bit(qid, vf->txq_mask))\n\t\treturn;\n\n\t__clear_bit(qid, vf->txq_mask);\n\t--vf->txq_count;\n\n\tif (efx_vfdi_flush_wake(vf))\n\t\twake_up(&vf->flush_waitq);\n}\n\nvoid efx_siena_sriov_rx_flush_done(struct efx_nic *efx, efx_qword_t *event)\n{\n\tstruct siena_vf *vf;\n\tunsigned ev_failed, queue, qid;\n\n\tqueue = EFX_QWORD_FIELD(*event, FSF_AZ_DRIVER_EV_RX_DESCQ_ID);\n\tev_failed = EFX_QWORD_FIELD(*event,\n\t\t\t\t    FSF_AZ_DRIVER_EV_RX_FLUSH_FAIL);\n\tif (map_vi_index(efx, queue, &vf, &qid))\n\t\treturn;\n\tif (!test_bit(qid, vf->rxq_mask))\n\t\treturn;\n\n\tif (ev_failed) {\n\t\tset_bit(qid, vf->rxq_retry_mask);\n\t\tatomic_inc(&vf->rxq_retry_count);\n\t} else {\n\t\t__clear_bit(qid, vf->rxq_mask);\n\t\t--vf->rxq_count;\n\t}\n\tif (efx_vfdi_flush_wake(vf))\n\t\twake_up(&vf->flush_waitq);\n}\n\n \nvoid efx_siena_sriov_desc_fetch_err(struct efx_nic *efx, unsigned dmaq)\n{\n\tstruct siena_vf *vf;\n\tunsigned int rel;\n\n\tif (map_vi_index(efx, dmaq, &vf, &rel))\n\t\treturn;\n\n\tif (net_ratelimit())\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"VF %d DMA Q %d reports descriptor fetch error.\\n\",\n\t\t\t  vf->index, rel);\n\tqueue_work(vfdi_workqueue, &vf->reset_work);\n}\n\n \nvoid efx_siena_sriov_reset(struct efx_nic *efx)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tunsigned int vf_i;\n\tstruct efx_buffer buf;\n\tstruct siena_vf *vf;\n\n\tASSERT_RTNL();\n\n\tif (efx->vf_init_count == 0)\n\t\treturn;\n\n\tefx_siena_sriov_usrev(efx, true);\n\t(void)efx_siena_sriov_cmd(efx, true, NULL, NULL);\n\n\tif (efx_siena_alloc_buffer(efx, &buf, EFX_PAGE_SIZE, GFP_NOIO))\n\t\treturn;\n\n\tfor (vf_i = 0; vf_i < efx->vf_init_count; ++vf_i) {\n\t\tvf = nic_data->vf + vf_i;\n\t\tefx_siena_sriov_reset_vf(vf, &buf);\n\t}\n\n\tefx_siena_free_buffer(efx, &buf);\n}\n\nint efx_init_sriov(void)\n{\n\t \n\tvfdi_workqueue = create_singlethread_workqueue(\"sfc_vfdi\");\n\tif (!vfdi_workqueue)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid efx_fini_sriov(void)\n{\n\tdestroy_workqueue(vfdi_workqueue);\n}\n\nint efx_siena_sriov_set_vf_mac(struct efx_nic *efx, int vf_i, const u8 *mac)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct siena_vf *vf;\n\n\tif (vf_i >= efx->vf_init_count)\n\t\treturn -EINVAL;\n\tvf = nic_data->vf + vf_i;\n\n\tmutex_lock(&vf->status_lock);\n\tether_addr_copy(vf->addr.mac_addr, mac);\n\t__efx_siena_sriov_update_vf_addr(vf);\n\tmutex_unlock(&vf->status_lock);\n\n\treturn 0;\n}\n\nint efx_siena_sriov_set_vf_vlan(struct efx_nic *efx, int vf_i,\n\t\t\t\tu16 vlan, u8 qos)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct siena_vf *vf;\n\tu16 tci;\n\n\tif (vf_i >= efx->vf_init_count)\n\t\treturn -EINVAL;\n\tvf = nic_data->vf + vf_i;\n\n\tmutex_lock(&vf->status_lock);\n\ttci = (vlan & VLAN_VID_MASK) | ((qos & 0x7) << VLAN_PRIO_SHIFT);\n\tvf->addr.tci = htons(tci);\n\t__efx_siena_sriov_update_vf_addr(vf);\n\tmutex_unlock(&vf->status_lock);\n\n\treturn 0;\n}\n\nint efx_siena_sriov_set_vf_spoofchk(struct efx_nic *efx, int vf_i,\n\t\t\t\t    bool spoofchk)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct siena_vf *vf;\n\tint rc;\n\n\tif (vf_i >= efx->vf_init_count)\n\t\treturn -EINVAL;\n\tvf = nic_data->vf + vf_i;\n\n\tmutex_lock(&vf->txq_lock);\n\tif (vf->txq_count == 0) {\n\t\tvf->tx_filter_mode =\n\t\t\tspoofchk ? VF_TX_FILTER_ON : VF_TX_FILTER_OFF;\n\t\trc = 0;\n\t} else {\n\t\t \n\t\trc = -EBUSY;\n\t}\n\tmutex_unlock(&vf->txq_lock);\n\treturn rc;\n}\n\nint efx_siena_sriov_get_vf_config(struct efx_nic *efx, int vf_i,\n\t\t\t\t  struct ifla_vf_info *ivi)\n{\n\tstruct siena_nic_data *nic_data = efx->nic_data;\n\tstruct siena_vf *vf;\n\tu16 tci;\n\n\tif (vf_i >= efx->vf_init_count)\n\t\treturn -EINVAL;\n\tvf = nic_data->vf + vf_i;\n\n\tivi->vf = vf_i;\n\tether_addr_copy(ivi->mac, vf->addr.mac_addr);\n\tivi->max_tx_rate = 0;\n\tivi->min_tx_rate = 0;\n\ttci = ntohs(vf->addr.tci);\n\tivi->vlan = tci & VLAN_VID_MASK;\n\tivi->qos = (tci >> VLAN_PRIO_SHIFT) & 0x7;\n\tivi->spoofchk = vf->tx_filter_mode == VF_TX_FILTER_ON;\n\n\treturn 0;\n}\n\nbool efx_siena_sriov_wanted(struct efx_nic *efx)\n{\n\treturn efx->vf_count != 0;\n}\n\nint efx_siena_sriov_configure(struct efx_nic *efx, int num_vfs)\n{\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}