{
  "module_name": "falcon.c",
  "hash_id": "2718f0380eba1a5d8fdeed102c1fe1f0fb62b206206c63f74aae25dcaab14aed",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sfc/falcon/falcon.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/pci.h>\n#include <linux/module.h>\n#include <linux/seq_file.h>\n#include <linux/i2c.h>\n#include <linux/mii.h>\n#include <linux/slab.h>\n#include <linux/sched/signal.h>\n\n#include \"net_driver.h\"\n#include \"bitfield.h\"\n#include \"efx.h\"\n#include \"nic.h\"\n#include \"farch_regs.h\"\n#include \"io.h\"\n#include \"phy.h\"\n#include \"workarounds.h\"\n#include \"selftest.h\"\n#include \"mdio_10g.h\"\n\n \n\n \n\n#define FALCON_MAC_STATS_SIZE 0x100\n\n#define XgRxOctets_offset 0x0\n#define XgRxOctets_WIDTH 48\n#define XgRxOctetsOK_offset 0x8\n#define XgRxOctetsOK_WIDTH 48\n#define XgRxPkts_offset 0x10\n#define XgRxPkts_WIDTH 32\n#define XgRxPktsOK_offset 0x14\n#define XgRxPktsOK_WIDTH 32\n#define XgRxBroadcastPkts_offset 0x18\n#define XgRxBroadcastPkts_WIDTH 32\n#define XgRxMulticastPkts_offset 0x1C\n#define XgRxMulticastPkts_WIDTH 32\n#define XgRxUnicastPkts_offset 0x20\n#define XgRxUnicastPkts_WIDTH 32\n#define XgRxUndersizePkts_offset 0x24\n#define XgRxUndersizePkts_WIDTH 32\n#define XgRxOversizePkts_offset 0x28\n#define XgRxOversizePkts_WIDTH 32\n#define XgRxJabberPkts_offset 0x2C\n#define XgRxJabberPkts_WIDTH 32\n#define XgRxUndersizeFCSerrorPkts_offset 0x30\n#define XgRxUndersizeFCSerrorPkts_WIDTH 32\n#define XgRxDropEvents_offset 0x34\n#define XgRxDropEvents_WIDTH 32\n#define XgRxFCSerrorPkts_offset 0x38\n#define XgRxFCSerrorPkts_WIDTH 32\n#define XgRxAlignError_offset 0x3C\n#define XgRxAlignError_WIDTH 32\n#define XgRxSymbolError_offset 0x40\n#define XgRxSymbolError_WIDTH 32\n#define XgRxInternalMACError_offset 0x44\n#define XgRxInternalMACError_WIDTH 32\n#define XgRxControlPkts_offset 0x48\n#define XgRxControlPkts_WIDTH 32\n#define XgRxPausePkts_offset 0x4C\n#define XgRxPausePkts_WIDTH 32\n#define XgRxPkts64Octets_offset 0x50\n#define XgRxPkts64Octets_WIDTH 32\n#define XgRxPkts65to127Octets_offset 0x54\n#define XgRxPkts65to127Octets_WIDTH 32\n#define XgRxPkts128to255Octets_offset 0x58\n#define XgRxPkts128to255Octets_WIDTH 32\n#define XgRxPkts256to511Octets_offset 0x5C\n#define XgRxPkts256to511Octets_WIDTH 32\n#define XgRxPkts512to1023Octets_offset 0x60\n#define XgRxPkts512to1023Octets_WIDTH 32\n#define XgRxPkts1024to15xxOctets_offset 0x64\n#define XgRxPkts1024to15xxOctets_WIDTH 32\n#define XgRxPkts15xxtoMaxOctets_offset 0x68\n#define XgRxPkts15xxtoMaxOctets_WIDTH 32\n#define XgRxLengthError_offset 0x6C\n#define XgRxLengthError_WIDTH 32\n#define XgTxPkts_offset 0x80\n#define XgTxPkts_WIDTH 32\n#define XgTxOctets_offset 0x88\n#define XgTxOctets_WIDTH 48\n#define XgTxMulticastPkts_offset 0x90\n#define XgTxMulticastPkts_WIDTH 32\n#define XgTxBroadcastPkts_offset 0x94\n#define XgTxBroadcastPkts_WIDTH 32\n#define XgTxUnicastPkts_offset 0x98\n#define XgTxUnicastPkts_WIDTH 32\n#define XgTxControlPkts_offset 0x9C\n#define XgTxControlPkts_WIDTH 32\n#define XgTxPausePkts_offset 0xA0\n#define XgTxPausePkts_WIDTH 32\n#define XgTxPkts64Octets_offset 0xA4\n#define XgTxPkts64Octets_WIDTH 32\n#define XgTxPkts65to127Octets_offset 0xA8\n#define XgTxPkts65to127Octets_WIDTH 32\n#define XgTxPkts128to255Octets_offset 0xAC\n#define XgTxPkts128to255Octets_WIDTH 32\n#define XgTxPkts256to511Octets_offset 0xB0\n#define XgTxPkts256to511Octets_WIDTH 32\n#define XgTxPkts512to1023Octets_offset 0xB4\n#define XgTxPkts512to1023Octets_WIDTH 32\n#define XgTxPkts1024to15xxOctets_offset 0xB8\n#define XgTxPkts1024to15xxOctets_WIDTH 32\n#define XgTxPkts1519toMaxOctets_offset 0xBC\n#define XgTxPkts1519toMaxOctets_WIDTH 32\n#define XgTxUndersizePkts_offset 0xC0\n#define XgTxUndersizePkts_WIDTH 32\n#define XgTxOversizePkts_offset 0xC4\n#define XgTxOversizePkts_WIDTH 32\n#define XgTxNonTcpUdpPkt_offset 0xC8\n#define XgTxNonTcpUdpPkt_WIDTH 16\n#define XgTxMacSrcErrPkt_offset 0xCC\n#define XgTxMacSrcErrPkt_WIDTH 16\n#define XgTxIpSrcErrPkt_offset 0xD0\n#define XgTxIpSrcErrPkt_WIDTH 16\n#define XgDmaDone_offset 0xD4\n#define XgDmaDone_WIDTH 32\n\n#define FALCON_XMAC_STATS_DMA_FLAG(efx)\t\t\t\t\\\n\t(*(u32 *)((efx)->stats_buffer.addr + XgDmaDone_offset))\n\n#define FALCON_DMA_STAT(ext_name, hw_name)\t\t\t\t\\\n\t[FALCON_STAT_ ## ext_name] =\t\t\t\t\t\\\n\t{ #ext_name,\t\t\t\t\t\t\t\\\n\t   \t\t\\\n\t  hw_name ## _ ## WIDTH == 48 ? 64 : hw_name ## _ ## WIDTH,\t\\\n\t  hw_name ## _ ## offset }\n#define FALCON_OTHER_STAT(ext_name)\t\t\t\t\t\\\n\t[FALCON_STAT_ ## ext_name] = { #ext_name, 0, 0 }\n#define GENERIC_SW_STAT(ext_name)\t\t\t\t\\\n\t[GENERIC_STAT_ ## ext_name] = { #ext_name, 0, 0 }\n\nstatic const struct ef4_hw_stat_desc falcon_stat_desc[FALCON_STAT_COUNT] = {\n\tFALCON_DMA_STAT(tx_bytes, XgTxOctets),\n\tFALCON_DMA_STAT(tx_packets, XgTxPkts),\n\tFALCON_DMA_STAT(tx_pause, XgTxPausePkts),\n\tFALCON_DMA_STAT(tx_control, XgTxControlPkts),\n\tFALCON_DMA_STAT(tx_unicast, XgTxUnicastPkts),\n\tFALCON_DMA_STAT(tx_multicast, XgTxMulticastPkts),\n\tFALCON_DMA_STAT(tx_broadcast, XgTxBroadcastPkts),\n\tFALCON_DMA_STAT(tx_lt64, XgTxUndersizePkts),\n\tFALCON_DMA_STAT(tx_64, XgTxPkts64Octets),\n\tFALCON_DMA_STAT(tx_65_to_127, XgTxPkts65to127Octets),\n\tFALCON_DMA_STAT(tx_128_to_255, XgTxPkts128to255Octets),\n\tFALCON_DMA_STAT(tx_256_to_511, XgTxPkts256to511Octets),\n\tFALCON_DMA_STAT(tx_512_to_1023, XgTxPkts512to1023Octets),\n\tFALCON_DMA_STAT(tx_1024_to_15xx, XgTxPkts1024to15xxOctets),\n\tFALCON_DMA_STAT(tx_15xx_to_jumbo, XgTxPkts1519toMaxOctets),\n\tFALCON_DMA_STAT(tx_gtjumbo, XgTxOversizePkts),\n\tFALCON_DMA_STAT(tx_non_tcpudp, XgTxNonTcpUdpPkt),\n\tFALCON_DMA_STAT(tx_mac_src_error, XgTxMacSrcErrPkt),\n\tFALCON_DMA_STAT(tx_ip_src_error, XgTxIpSrcErrPkt),\n\tFALCON_DMA_STAT(rx_bytes, XgRxOctets),\n\tFALCON_DMA_STAT(rx_good_bytes, XgRxOctetsOK),\n\tFALCON_OTHER_STAT(rx_bad_bytes),\n\tFALCON_DMA_STAT(rx_packets, XgRxPkts),\n\tFALCON_DMA_STAT(rx_good, XgRxPktsOK),\n\tFALCON_DMA_STAT(rx_bad, XgRxFCSerrorPkts),\n\tFALCON_DMA_STAT(rx_pause, XgRxPausePkts),\n\tFALCON_DMA_STAT(rx_control, XgRxControlPkts),\n\tFALCON_DMA_STAT(rx_unicast, XgRxUnicastPkts),\n\tFALCON_DMA_STAT(rx_multicast, XgRxMulticastPkts),\n\tFALCON_DMA_STAT(rx_broadcast, XgRxBroadcastPkts),\n\tFALCON_DMA_STAT(rx_lt64, XgRxUndersizePkts),\n\tFALCON_DMA_STAT(rx_64, XgRxPkts64Octets),\n\tFALCON_DMA_STAT(rx_65_to_127, XgRxPkts65to127Octets),\n\tFALCON_DMA_STAT(rx_128_to_255, XgRxPkts128to255Octets),\n\tFALCON_DMA_STAT(rx_256_to_511, XgRxPkts256to511Octets),\n\tFALCON_DMA_STAT(rx_512_to_1023, XgRxPkts512to1023Octets),\n\tFALCON_DMA_STAT(rx_1024_to_15xx, XgRxPkts1024to15xxOctets),\n\tFALCON_DMA_STAT(rx_15xx_to_jumbo, XgRxPkts15xxtoMaxOctets),\n\tFALCON_DMA_STAT(rx_gtjumbo, XgRxOversizePkts),\n\tFALCON_DMA_STAT(rx_bad_lt64, XgRxUndersizeFCSerrorPkts),\n\tFALCON_DMA_STAT(rx_bad_gtjumbo, XgRxJabberPkts),\n\tFALCON_DMA_STAT(rx_overflow, XgRxDropEvents),\n\tFALCON_DMA_STAT(rx_symbol_error, XgRxSymbolError),\n\tFALCON_DMA_STAT(rx_align_error, XgRxAlignError),\n\tFALCON_DMA_STAT(rx_length_error, XgRxLengthError),\n\tFALCON_DMA_STAT(rx_internal_error, XgRxInternalMACError),\n\tFALCON_OTHER_STAT(rx_nodesc_drop_cnt),\n\tGENERIC_SW_STAT(rx_nodesc_trunc),\n\tGENERIC_SW_STAT(rx_noskb_drops),\n};\nstatic const unsigned long falcon_stat_mask[] = {\n\t[0 ... BITS_TO_LONGS(FALCON_STAT_COUNT) - 1] = ~0UL,\n};\n\n \n\n#define SPI_WRSR 0x01\t\t \n#define SPI_WRITE 0x02\t\t \n#define SPI_READ 0x03\t\t \n#define SPI_WRDI 0x04\t\t \n#define SPI_RDSR 0x05\t\t \n#define SPI_WREN 0x06\t\t \n#define SPI_SST_EWSR 0x50\t \n\n#define SPI_STATUS_WPEN 0x80\t \n#define SPI_STATUS_BP2 0x10\t \n#define SPI_STATUS_BP1 0x08\t \n#define SPI_STATUS_BP0 0x04\t \n#define SPI_STATUS_WEN 0x02\t \n#define SPI_STATUS_NRDY 0x01\t \n\n \n\n \n#define FALCON_NVCONFIG_END 0x400U\n#define FALCON_FLASH_BOOTCODE_START 0x8000U\n#define FALCON_EEPROM_BOOTCONFIG_START 0x800U\n#define FALCON_EEPROM_BOOTCONFIG_END 0x1800U\n\n \nstruct falcon_nvconfig_board_v2 {\n\t__le16 nports;\n\tu8 port0_phy_addr;\n\tu8 port0_phy_type;\n\tu8 port1_phy_addr;\n\tu8 port1_phy_type;\n\t__le16 asic_sub_revision;\n\t__le16 board_revision;\n} __packed;\n\n \nstruct falcon_nvconfig_board_v3 {\n\t__le32 spi_device_type[2];\n} __packed;\n\n \n#define SPI_DEV_TYPE_SIZE_LBN 0\n#define SPI_DEV_TYPE_SIZE_WIDTH 5\n#define SPI_DEV_TYPE_ADDR_LEN_LBN 6\n#define SPI_DEV_TYPE_ADDR_LEN_WIDTH 2\n#define SPI_DEV_TYPE_ERASE_CMD_LBN 8\n#define SPI_DEV_TYPE_ERASE_CMD_WIDTH 8\n#define SPI_DEV_TYPE_ERASE_SIZE_LBN 16\n#define SPI_DEV_TYPE_ERASE_SIZE_WIDTH 5\n#define SPI_DEV_TYPE_BLOCK_SIZE_LBN 24\n#define SPI_DEV_TYPE_BLOCK_SIZE_WIDTH 5\n#define SPI_DEV_TYPE_FIELD(type, field)\t\t\t\t\t\\\n\t(((type) >> EF4_LOW_BIT(field)) & EF4_MASK32(EF4_WIDTH(field)))\n\n#define FALCON_NVCONFIG_OFFSET 0x300\n\n#define FALCON_NVCONFIG_BOARD_MAGIC_NUM 0xFA1C\nstruct falcon_nvconfig {\n\tef4_oword_t ee_vpd_cfg_reg;\t\t\t \n\tu8 mac_address[2][8];\t\t\t \n\tef4_oword_t pcie_sd_ctl0123_reg;\t\t \n\tef4_oword_t pcie_sd_ctl45_reg;\t\t\t \n\tef4_oword_t pcie_pcs_ctl_stat_reg;\t\t \n\tef4_oword_t hw_init_reg;\t\t\t \n\tef4_oword_t nic_stat_reg;\t\t\t \n\tef4_oword_t glb_ctl_reg;\t\t\t \n\tef4_oword_t srm_cfg_reg;\t\t\t \n\tef4_oword_t spare_reg;\t\t\t\t \n\t__le16 board_magic_num;\t\t\t \n\t__le16 board_struct_ver;\n\t__le16 board_checksum;\n\tstruct falcon_nvconfig_board_v2 board_v2;\n\tef4_oword_t ee_base_page_reg;\t\t\t \n\tstruct falcon_nvconfig_board_v3 board_v3;\t \n} __packed;\n\n \n\nstatic int falcon_reset_hw(struct ef4_nic *efx, enum reset_type method);\nstatic void falcon_reconfigure_mac_wrapper(struct ef4_nic *efx);\n\nstatic const unsigned int\n \nlarge_eeprom_type = ((13 << SPI_DEV_TYPE_SIZE_LBN)\n\t\t     | (2 << SPI_DEV_TYPE_ADDR_LEN_LBN)\n\t\t     | (5 << SPI_DEV_TYPE_BLOCK_SIZE_LBN)),\n \ndefault_flash_type = ((17 << SPI_DEV_TYPE_SIZE_LBN)\n\t\t      | (3 << SPI_DEV_TYPE_ADDR_LEN_LBN)\n\t\t      | (0x52 << SPI_DEV_TYPE_ERASE_CMD_LBN)\n\t\t      | (15 << SPI_DEV_TYPE_ERASE_SIZE_LBN)\n\t\t      | (8 << SPI_DEV_TYPE_BLOCK_SIZE_LBN));\n\n \nstatic void falcon_setsda(void *data, int state)\n{\n\tstruct ef4_nic *efx = (struct ef4_nic *)data;\n\tef4_oword_t reg;\n\n\tef4_reado(efx, &reg, FR_AB_GPIO_CTL);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_GPIO3_OEN, !state);\n\tef4_writeo(efx, &reg, FR_AB_GPIO_CTL);\n}\n\nstatic void falcon_setscl(void *data, int state)\n{\n\tstruct ef4_nic *efx = (struct ef4_nic *)data;\n\tef4_oword_t reg;\n\n\tef4_reado(efx, &reg, FR_AB_GPIO_CTL);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_GPIO0_OEN, !state);\n\tef4_writeo(efx, &reg, FR_AB_GPIO_CTL);\n}\n\nstatic int falcon_getsda(void *data)\n{\n\tstruct ef4_nic *efx = (struct ef4_nic *)data;\n\tef4_oword_t reg;\n\n\tef4_reado(efx, &reg, FR_AB_GPIO_CTL);\n\treturn EF4_OWORD_FIELD(reg, FRF_AB_GPIO3_IN);\n}\n\nstatic int falcon_getscl(void *data)\n{\n\tstruct ef4_nic *efx = (struct ef4_nic *)data;\n\tef4_oword_t reg;\n\n\tef4_reado(efx, &reg, FR_AB_GPIO_CTL);\n\treturn EF4_OWORD_FIELD(reg, FRF_AB_GPIO0_IN);\n}\n\nstatic const struct i2c_algo_bit_data falcon_i2c_bit_operations = {\n\t.setsda\t\t= falcon_setsda,\n\t.setscl\t\t= falcon_setscl,\n\t.getsda\t\t= falcon_getsda,\n\t.getscl\t\t= falcon_getscl,\n\t.udelay\t\t= 5,\n\t \n\t.timeout\t= DIV_ROUND_UP(HZ, 20),\n};\n\nstatic void falcon_push_irq_moderation(struct ef4_channel *channel)\n{\n\tef4_dword_t timer_cmd;\n\tstruct ef4_nic *efx = channel->efx;\n\n\t \n\tif (channel->irq_moderation_us) {\n\t\tunsigned int ticks;\n\n\t\tticks = ef4_usecs_to_ticks(efx, channel->irq_moderation_us);\n\t\tEF4_POPULATE_DWORD_2(timer_cmd,\n\t\t\t\t     FRF_AB_TC_TIMER_MODE,\n\t\t\t\t     FFE_BB_TIMER_MODE_INT_HLDOFF,\n\t\t\t\t     FRF_AB_TC_TIMER_VAL,\n\t\t\t\t     ticks - 1);\n\t} else {\n\t\tEF4_POPULATE_DWORD_2(timer_cmd,\n\t\t\t\t     FRF_AB_TC_TIMER_MODE,\n\t\t\t\t     FFE_BB_TIMER_MODE_DIS,\n\t\t\t\t     FRF_AB_TC_TIMER_VAL, 0);\n\t}\n\tBUILD_BUG_ON(FR_AA_TIMER_COMMAND_KER != FR_BZ_TIMER_COMMAND_P0);\n\tef4_writed_page_locked(efx, &timer_cmd, FR_BZ_TIMER_COMMAND_P0,\n\t\t\t       channel->channel);\n}\n\nstatic void falcon_deconfigure_mac_wrapper(struct ef4_nic *efx);\n\nstatic void falcon_prepare_flush(struct ef4_nic *efx)\n{\n\tfalcon_deconfigure_mac_wrapper(efx);\n\n\t \n\tmsleep(10);\n}\n\n \nstatic inline void falcon_irq_ack_a1(struct ef4_nic *efx)\n{\n\tef4_dword_t reg;\n\n\tEF4_POPULATE_DWORD_1(reg, FRF_AA_INT_ACK_KER_FIELD, 0xb7eb7e);\n\tef4_writed(efx, &reg, FR_AA_INT_ACK_KER);\n\tef4_readd(efx, &reg, FR_AA_WORK_AROUND_BROKEN_PCI_READS);\n}\n\nstatic irqreturn_t falcon_legacy_interrupt_a1(int irq, void *dev_id)\n{\n\tstruct ef4_nic *efx = dev_id;\n\tef4_oword_t *int_ker = efx->irq_status.addr;\n\tint syserr;\n\tint queues;\n\n\t \n\tif (unlikely(EF4_OWORD_IS_ZERO(*int_ker))) {\n\t\tnetif_vdbg(efx, intr, efx->net_dev,\n\t\t\t   \"IRQ %d on CPU %d not for me\\n\", irq,\n\t\t\t   raw_smp_processor_id());\n\t\treturn IRQ_NONE;\n\t}\n\tefx->last_irq_cpu = raw_smp_processor_id();\n\tnetif_vdbg(efx, intr, efx->net_dev,\n\t\t   \"IRQ %d on CPU %d status \" EF4_OWORD_FMT \"\\n\",\n\t\t   irq, raw_smp_processor_id(), EF4_OWORD_VAL(*int_ker));\n\n\tif (!likely(READ_ONCE(efx->irq_soft_enabled)))\n\t\treturn IRQ_HANDLED;\n\n\t \n\tsyserr = EF4_OWORD_FIELD(*int_ker, FSF_AZ_NET_IVEC_FATAL_INT);\n\tif (unlikely(syserr))\n\t\treturn ef4_farch_fatal_interrupt(efx);\n\n\t \n\tBUILD_BUG_ON(FSF_AZ_NET_IVEC_INT_Q_WIDTH > EF4_MAX_CHANNELS);\n\tqueues = EF4_OWORD_FIELD(*int_ker, FSF_AZ_NET_IVEC_INT_Q);\n\tEF4_ZERO_OWORD(*int_ker);\n\twmb();  \n\tfalcon_irq_ack_a1(efx);\n\n\tif (queues & 1)\n\t\tef4_schedule_channel_irq(ef4_get_channel(efx, 0));\n\tif (queues & 2)\n\t\tef4_schedule_channel_irq(ef4_get_channel(efx, 1));\n\treturn IRQ_HANDLED;\n}\n\n \nstatic int dummy_rx_push_rss_config(struct ef4_nic *efx, bool user,\n\t\t\t\t    const u32 *rx_indir_table)\n{\n\t(void) efx;\n\t(void) user;\n\t(void) rx_indir_table;\n\treturn -ENOSYS;\n}\n\nstatic int falcon_b0_rx_push_rss_config(struct ef4_nic *efx, bool user,\n\t\t\t\t\tconst u32 *rx_indir_table)\n{\n\tef4_oword_t temp;\n\n\t(void) user;\n\t \n\tmemcpy(&temp, efx->rx_hash_key, sizeof(temp));\n\tef4_writeo(efx, &temp, FR_BZ_RX_RSS_TKEY);\n\n\tmemcpy(efx->rx_indir_table, rx_indir_table,\n\t       sizeof(efx->rx_indir_table));\n\tef4_farch_rx_push_indir_table(efx);\n\treturn 0;\n}\n\n \n\n#define FALCON_SPI_MAX_LEN sizeof(ef4_oword_t)\n\nstatic int falcon_spi_poll(struct ef4_nic *efx)\n{\n\tef4_oword_t reg;\n\tef4_reado(efx, &reg, FR_AB_EE_SPI_HCMD);\n\treturn EF4_OWORD_FIELD(reg, FRF_AB_EE_SPI_HCMD_CMD_EN) ? -EBUSY : 0;\n}\n\n \nstatic int falcon_spi_wait(struct ef4_nic *efx)\n{\n\t \n\tunsigned long timeout = jiffies + 1 + DIV_ROUND_UP(HZ, 10);\n\tint i;\n\n\tfor (i = 0; i < 10; i++) {\n\t\tif (!falcon_spi_poll(efx))\n\t\t\treturn 0;\n\t\tudelay(10);\n\t}\n\n\tfor (;;) {\n\t\tif (!falcon_spi_poll(efx))\n\t\t\treturn 0;\n\t\tif (time_after_eq(jiffies, timeout)) {\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"timed out waiting for SPI\\n\");\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t\tschedule_timeout_uninterruptible(1);\n\t}\n}\n\nstatic int\nfalcon_spi_cmd(struct ef4_nic *efx, const struct falcon_spi_device *spi,\n\t       unsigned int command, int address,\n\t       const void *in, void *out, size_t len)\n{\n\tbool addressed = (address >= 0);\n\tbool reading = (out != NULL);\n\tef4_oword_t reg;\n\tint rc;\n\n\t \n\tif (len > FALCON_SPI_MAX_LEN)\n\t\treturn -EINVAL;\n\n\t \n\trc = falcon_spi_poll(efx);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (addressed) {\n\t\tEF4_POPULATE_OWORD_1(reg, FRF_AB_EE_SPI_HADR_ADR, address);\n\t\tef4_writeo(efx, &reg, FR_AB_EE_SPI_HADR);\n\t}\n\n\t \n\tif (in != NULL) {\n\t\tmemcpy(&reg, in, len);\n\t\tef4_writeo(efx, &reg, FR_AB_EE_SPI_HDATA);\n\t}\n\n\t \n\tEF4_POPULATE_OWORD_7(reg,\n\t\t\t     FRF_AB_EE_SPI_HCMD_CMD_EN, 1,\n\t\t\t     FRF_AB_EE_SPI_HCMD_SF_SEL, spi->device_id,\n\t\t\t     FRF_AB_EE_SPI_HCMD_DABCNT, len,\n\t\t\t     FRF_AB_EE_SPI_HCMD_READ, reading,\n\t\t\t     FRF_AB_EE_SPI_HCMD_DUBCNT, 0,\n\t\t\t     FRF_AB_EE_SPI_HCMD_ADBCNT,\n\t\t\t     (addressed ? spi->addr_len : 0),\n\t\t\t     FRF_AB_EE_SPI_HCMD_ENC, command);\n\tef4_writeo(efx, &reg, FR_AB_EE_SPI_HCMD);\n\n\t \n\trc = falcon_spi_wait(efx);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (out != NULL) {\n\t\tef4_reado(efx, &reg, FR_AB_EE_SPI_HDATA);\n\t\tmemcpy(out, &reg, len);\n\t}\n\n\treturn 0;\n}\n\nstatic inline u8\nfalcon_spi_munge_command(const struct falcon_spi_device *spi,\n\t\t\t const u8 command, const unsigned int address)\n{\n\treturn command | (((address >> 8) & spi->munge_address) << 3);\n}\n\nstatic int\nfalcon_spi_read(struct ef4_nic *efx, const struct falcon_spi_device *spi,\n\t\tloff_t start, size_t len, size_t *retlen, u8 *buffer)\n{\n\tsize_t block_len, pos = 0;\n\tunsigned int command;\n\tint rc = 0;\n\n\twhile (pos < len) {\n\t\tblock_len = min(len - pos, FALCON_SPI_MAX_LEN);\n\n\t\tcommand = falcon_spi_munge_command(spi, SPI_READ, start + pos);\n\t\trc = falcon_spi_cmd(efx, spi, command, start + pos, NULL,\n\t\t\t\t    buffer + pos, block_len);\n\t\tif (rc)\n\t\t\tbreak;\n\t\tpos += block_len;\n\n\t\t \n\t\tcond_resched();\n\t\tif (signal_pending(current)) {\n\t\t\trc = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (retlen)\n\t\t*retlen = pos;\n\treturn rc;\n}\n\n#ifdef CONFIG_SFC_FALCON_MTD\n\nstruct falcon_mtd_partition {\n\tstruct ef4_mtd_partition common;\n\tconst struct falcon_spi_device *spi;\n\tsize_t offset;\n};\n\n#define to_falcon_mtd_partition(mtd)\t\t\t\t\\\n\tcontainer_of(mtd, struct falcon_mtd_partition, common.mtd)\n\nstatic size_t\nfalcon_spi_write_limit(const struct falcon_spi_device *spi, size_t start)\n{\n\treturn min(FALCON_SPI_MAX_LEN,\n\t\t   (spi->block_size - (start & (spi->block_size - 1))));\n}\n\n \nstatic int\nfalcon_spi_wait_write(struct ef4_nic *efx, const struct falcon_spi_device *spi)\n{\n\tunsigned long timeout = jiffies + 1 + DIV_ROUND_UP(HZ, 100);\n\tu8 status;\n\tint rc;\n\n\tfor (;;) {\n\t\trc = falcon_spi_cmd(efx, spi, SPI_RDSR, -1, NULL,\n\t\t\t\t    &status, sizeof(status));\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tif (!(status & SPI_STATUS_NRDY))\n\t\t\treturn 0;\n\t\tif (time_after_eq(jiffies, timeout)) {\n\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t  \"SPI write timeout on device %d\"\n\t\t\t\t  \" last status=0x%02x\\n\",\n\t\t\t\t  spi->device_id, status);\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t\tschedule_timeout_uninterruptible(1);\n\t}\n}\n\nstatic int\nfalcon_spi_write(struct ef4_nic *efx, const struct falcon_spi_device *spi,\n\t\t loff_t start, size_t len, size_t *retlen, const u8 *buffer)\n{\n\tu8 verify_buffer[FALCON_SPI_MAX_LEN];\n\tsize_t block_len, pos = 0;\n\tunsigned int command;\n\tint rc = 0;\n\n\twhile (pos < len) {\n\t\trc = falcon_spi_cmd(efx, spi, SPI_WREN, -1, NULL, NULL, 0);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tblock_len = min(len - pos,\n\t\t\t\tfalcon_spi_write_limit(spi, start + pos));\n\t\tcommand = falcon_spi_munge_command(spi, SPI_WRITE, start + pos);\n\t\trc = falcon_spi_cmd(efx, spi, command, start + pos,\n\t\t\t\t    buffer + pos, NULL, block_len);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\trc = falcon_spi_wait_write(efx, spi);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tcommand = falcon_spi_munge_command(spi, SPI_READ, start + pos);\n\t\trc = falcon_spi_cmd(efx, spi, command, start + pos,\n\t\t\t\t    NULL, verify_buffer, block_len);\n\t\tif (memcmp(verify_buffer, buffer + pos, block_len)) {\n\t\t\trc = -EIO;\n\t\t\tbreak;\n\t\t}\n\n\t\tpos += block_len;\n\n\t\t \n\t\tcond_resched();\n\t\tif (signal_pending(current)) {\n\t\t\trc = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (retlen)\n\t\t*retlen = pos;\n\treturn rc;\n}\n\nstatic int\nfalcon_spi_slow_wait(struct falcon_mtd_partition *part, bool uninterruptible)\n{\n\tconst struct falcon_spi_device *spi = part->spi;\n\tstruct ef4_nic *efx = part->common.mtd.priv;\n\tu8 status;\n\tint rc, i;\n\n\t \n\tfor (i = 0; i < 40; i++) {\n\t\t__set_current_state(uninterruptible ?\n\t\t\t\t    TASK_UNINTERRUPTIBLE : TASK_INTERRUPTIBLE);\n\t\tschedule_timeout(HZ / 10);\n\t\trc = falcon_spi_cmd(efx, spi, SPI_RDSR, -1, NULL,\n\t\t\t\t    &status, sizeof(status));\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tif (!(status & SPI_STATUS_NRDY))\n\t\t\treturn 0;\n\t\tif (signal_pending(current))\n\t\t\treturn -EINTR;\n\t}\n\tpr_err(\"%s: timed out waiting for %s\\n\",\n\t       part->common.name, part->common.dev_type_name);\n\treturn -ETIMEDOUT;\n}\n\nstatic int\nfalcon_spi_unlock(struct ef4_nic *efx, const struct falcon_spi_device *spi)\n{\n\tconst u8 unlock_mask = (SPI_STATUS_BP2 | SPI_STATUS_BP1 |\n\t\t\t\tSPI_STATUS_BP0);\n\tu8 status;\n\tint rc;\n\n\trc = falcon_spi_cmd(efx, spi, SPI_RDSR, -1, NULL,\n\t\t\t    &status, sizeof(status));\n\tif (rc)\n\t\treturn rc;\n\n\tif (!(status & unlock_mask))\n\t\treturn 0;  \n\n\trc = falcon_spi_cmd(efx, spi, SPI_WREN, -1, NULL, NULL, 0);\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_cmd(efx, spi, SPI_SST_EWSR, -1, NULL, NULL, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tstatus &= ~unlock_mask;\n\trc = falcon_spi_cmd(efx, spi, SPI_WRSR, -1, &status,\n\t\t\t    NULL, sizeof(status));\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_wait_write(efx, spi);\n\tif (rc)\n\t\treturn rc;\n\n\treturn 0;\n}\n\n#define FALCON_SPI_VERIFY_BUF_LEN 16\n\nstatic int\nfalcon_spi_erase(struct falcon_mtd_partition *part, loff_t start, size_t len)\n{\n\tconst struct falcon_spi_device *spi = part->spi;\n\tstruct ef4_nic *efx = part->common.mtd.priv;\n\tunsigned pos, block_len;\n\tu8 empty[FALCON_SPI_VERIFY_BUF_LEN];\n\tu8 buffer[FALCON_SPI_VERIFY_BUF_LEN];\n\tint rc;\n\n\tif (len != spi->erase_size)\n\t\treturn -EINVAL;\n\n\tif (spi->erase_command == 0)\n\t\treturn -EOPNOTSUPP;\n\n\trc = falcon_spi_unlock(efx, spi);\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_cmd(efx, spi, SPI_WREN, -1, NULL, NULL, 0);\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_cmd(efx, spi, spi->erase_command, start, NULL,\n\t\t\t    NULL, 0);\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_slow_wait(part, false);\n\n\t \n\tmemset(empty, 0xff, sizeof(empty));\n\tfor (pos = 0; pos < len; pos += block_len) {\n\t\tblock_len = min(len - pos, sizeof(buffer));\n\t\trc = falcon_spi_read(efx, spi, start + pos, block_len,\n\t\t\t\t     NULL, buffer);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tif (memcmp(empty, buffer, block_len))\n\t\t\treturn -EIO;\n\n\t\t \n\t\tcond_resched();\n\t\tif (signal_pending(current))\n\t\t\treturn -EINTR;\n\t}\n\n\treturn rc;\n}\n\nstatic void falcon_mtd_rename(struct ef4_mtd_partition *part)\n{\n\tstruct ef4_nic *efx = part->mtd.priv;\n\n\tsnprintf(part->name, sizeof(part->name), \"%s %s\",\n\t\t efx->name, part->type_name);\n}\n\nstatic int falcon_mtd_read(struct mtd_info *mtd, loff_t start,\n\t\t\t   size_t len, size_t *retlen, u8 *buffer)\n{\n\tstruct falcon_mtd_partition *part = to_falcon_mtd_partition(mtd);\n\tstruct ef4_nic *efx = mtd->priv;\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tint rc;\n\n\trc = mutex_lock_interruptible(&nic_data->spi_lock);\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_read(efx, part->spi, part->offset + start,\n\t\t\t     len, retlen, buffer);\n\tmutex_unlock(&nic_data->spi_lock);\n\treturn rc;\n}\n\nstatic int falcon_mtd_erase(struct mtd_info *mtd, loff_t start, size_t len)\n{\n\tstruct falcon_mtd_partition *part = to_falcon_mtd_partition(mtd);\n\tstruct ef4_nic *efx = mtd->priv;\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tint rc;\n\n\trc = mutex_lock_interruptible(&nic_data->spi_lock);\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_erase(part, part->offset + start, len);\n\tmutex_unlock(&nic_data->spi_lock);\n\treturn rc;\n}\n\nstatic int falcon_mtd_write(struct mtd_info *mtd, loff_t start,\n\t\t\t    size_t len, size_t *retlen, const u8 *buffer)\n{\n\tstruct falcon_mtd_partition *part = to_falcon_mtd_partition(mtd);\n\tstruct ef4_nic *efx = mtd->priv;\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tint rc;\n\n\trc = mutex_lock_interruptible(&nic_data->spi_lock);\n\tif (rc)\n\t\treturn rc;\n\trc = falcon_spi_write(efx, part->spi, part->offset + start,\n\t\t\t      len, retlen, buffer);\n\tmutex_unlock(&nic_data->spi_lock);\n\treturn rc;\n}\n\nstatic int falcon_mtd_sync(struct mtd_info *mtd)\n{\n\tstruct falcon_mtd_partition *part = to_falcon_mtd_partition(mtd);\n\tstruct ef4_nic *efx = mtd->priv;\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tint rc;\n\n\tmutex_lock(&nic_data->spi_lock);\n\trc = falcon_spi_slow_wait(part, true);\n\tmutex_unlock(&nic_data->spi_lock);\n\treturn rc;\n}\n\nstatic int falcon_mtd_probe(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tstruct falcon_mtd_partition *parts;\n\tstruct falcon_spi_device *spi;\n\tsize_t n_parts;\n\tint rc = -ENODEV;\n\n\tASSERT_RTNL();\n\n\t \n\tparts = kcalloc(2, sizeof(*parts), GFP_KERNEL);\n\tif (!parts)\n\t\treturn -ENOMEM;\n\tn_parts = 0;\n\n\tspi = &nic_data->spi_flash;\n\tif (falcon_spi_present(spi) && spi->size > FALCON_FLASH_BOOTCODE_START) {\n\t\tparts[n_parts].spi = spi;\n\t\tparts[n_parts].offset = FALCON_FLASH_BOOTCODE_START;\n\t\tparts[n_parts].common.dev_type_name = \"flash\";\n\t\tparts[n_parts].common.type_name = \"sfc_flash_bootrom\";\n\t\tparts[n_parts].common.mtd.type = MTD_NORFLASH;\n\t\tparts[n_parts].common.mtd.flags = MTD_CAP_NORFLASH;\n\t\tparts[n_parts].common.mtd.size = spi->size - FALCON_FLASH_BOOTCODE_START;\n\t\tparts[n_parts].common.mtd.erasesize = spi->erase_size;\n\t\tn_parts++;\n\t}\n\n\tspi = &nic_data->spi_eeprom;\n\tif (falcon_spi_present(spi) && spi->size > FALCON_EEPROM_BOOTCONFIG_START) {\n\t\tparts[n_parts].spi = spi;\n\t\tparts[n_parts].offset = FALCON_EEPROM_BOOTCONFIG_START;\n\t\tparts[n_parts].common.dev_type_name = \"EEPROM\";\n\t\tparts[n_parts].common.type_name = \"sfc_bootconfig\";\n\t\tparts[n_parts].common.mtd.type = MTD_RAM;\n\t\tparts[n_parts].common.mtd.flags = MTD_CAP_RAM;\n\t\tparts[n_parts].common.mtd.size =\n\t\t\tmin(spi->size, FALCON_EEPROM_BOOTCONFIG_END) -\n\t\t\tFALCON_EEPROM_BOOTCONFIG_START;\n\t\tparts[n_parts].common.mtd.erasesize = spi->erase_size;\n\t\tn_parts++;\n\t}\n\n\trc = ef4_mtd_add(efx, &parts[0].common, n_parts, sizeof(*parts));\n\tif (rc)\n\t\tkfree(parts);\n\treturn rc;\n}\n\n#endif  \n\n \n\n \nstatic void falcon_setup_xaui(struct ef4_nic *efx)\n{\n\tef4_oword_t sdctl, txdrv;\n\n\t \n\tif (efx->phy_type == PHY_TYPE_NONE)\n\t\treturn;\n\n\tef4_reado(efx, &sdctl, FR_AB_XX_SD_CTL);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_HIDRVD, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_LODRVD, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_HIDRVC, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_LODRVC, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_HIDRVB, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_LODRVB, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_HIDRVA, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tEF4_SET_OWORD_FIELD(sdctl, FRF_AB_XX_LODRVA, FFE_AB_XX_SD_CTL_DRV_DEF);\n\tef4_writeo(efx, &sdctl, FR_AB_XX_SD_CTL);\n\n\tEF4_POPULATE_OWORD_8(txdrv,\n\t\t\t     FRF_AB_XX_DEQD, FFE_AB_XX_TXDRV_DEQ_DEF,\n\t\t\t     FRF_AB_XX_DEQC, FFE_AB_XX_TXDRV_DEQ_DEF,\n\t\t\t     FRF_AB_XX_DEQB, FFE_AB_XX_TXDRV_DEQ_DEF,\n\t\t\t     FRF_AB_XX_DEQA, FFE_AB_XX_TXDRV_DEQ_DEF,\n\t\t\t     FRF_AB_XX_DTXD, FFE_AB_XX_TXDRV_DTX_DEF,\n\t\t\t     FRF_AB_XX_DTXC, FFE_AB_XX_TXDRV_DTX_DEF,\n\t\t\t     FRF_AB_XX_DTXB, FFE_AB_XX_TXDRV_DTX_DEF,\n\t\t\t     FRF_AB_XX_DTXA, FFE_AB_XX_TXDRV_DTX_DEF);\n\tef4_writeo(efx, &txdrv, FR_AB_XX_TXDRV_CTL);\n}\n\nint falcon_reset_xaui(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t reg;\n\tint count;\n\n\t \n\tWARN_ON(nic_data->stats_disable_count == 0);\n\n\t \n\tEF4_POPULATE_OWORD_1(reg, FRF_AB_XX_RST_XX_EN, 1);\n\tef4_writeo(efx, &reg, FR_AB_XX_PWR_RST);\n\n\t \n\tfor (count = 0; count < 1000; count++) {\n\t\tef4_reado(efx, &reg, FR_AB_XX_PWR_RST);\n\t\tif (EF4_OWORD_FIELD(reg, FRF_AB_XX_RST_XX_EN) == 0 &&\n\t\t    EF4_OWORD_FIELD(reg, FRF_AB_XX_SD_RST_ACT) == 0) {\n\t\t\tfalcon_setup_xaui(efx);\n\t\t\treturn 0;\n\t\t}\n\t\tudelay(10);\n\t}\n\tnetif_err(efx, hw, efx->net_dev,\n\t\t  \"timed out waiting for XAUI/XGXS reset\\n\");\n\treturn -ETIMEDOUT;\n}\n\nstatic void falcon_ack_status_intr(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t reg;\n\n\tif ((ef4_nic_rev(efx) != EF4_REV_FALCON_B0) || LOOPBACK_INTERNAL(efx))\n\t\treturn;\n\n\t \n\tif (!efx->link_state.up)\n\t\treturn;\n\n\t \n\tif (nic_data->xmac_poll_required)\n\t\treturn;\n\n\tef4_reado(efx, &reg, FR_AB_XM_MGT_INT_MSK);\n}\n\nstatic bool falcon_xgxs_link_ok(struct ef4_nic *efx)\n{\n\tef4_oword_t reg;\n\tbool align_done, link_ok = false;\n\tint sync_status;\n\n\t \n\tef4_reado(efx, &reg, FR_AB_XX_CORE_STAT);\n\n\talign_done = EF4_OWORD_FIELD(reg, FRF_AB_XX_ALIGN_DONE);\n\tsync_status = EF4_OWORD_FIELD(reg, FRF_AB_XX_SYNC_STAT);\n\tif (align_done && (sync_status == FFE_AB_XX_STAT_ALL_LANES))\n\t\tlink_ok = true;\n\n\t \n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_COMMA_DET, FFE_AB_XX_STAT_ALL_LANES);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_CHAR_ERR, FFE_AB_XX_STAT_ALL_LANES);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_DISPERR, FFE_AB_XX_STAT_ALL_LANES);\n\tef4_writeo(efx, &reg, FR_AB_XX_CORE_STAT);\n\n\treturn link_ok;\n}\n\nstatic bool falcon_xmac_link_ok(struct ef4_nic *efx)\n{\n\t \n\treturn (efx->loopback_mode == LOOPBACK_XGMII ||\n\t\tfalcon_xgxs_link_ok(efx)) &&\n\t\t(!(efx->mdio.mmds & (1 << MDIO_MMD_PHYXS)) ||\n\t\t LOOPBACK_INTERNAL(efx) ||\n\t\t ef4_mdio_phyxgxs_lane_sync(efx));\n}\n\nstatic void falcon_reconfigure_xmac_core(struct ef4_nic *efx)\n{\n\tunsigned int max_frame_len;\n\tef4_oword_t reg;\n\tbool rx_fc = !!(efx->link_state.fc & EF4_FC_RX);\n\tbool tx_fc = !!(efx->link_state.fc & EF4_FC_TX);\n\n\t \n\tEF4_POPULATE_OWORD_3(reg,\n\t\t\t     FRF_AB_XM_RX_JUMBO_MODE, 1,\n\t\t\t     FRF_AB_XM_TX_STAT_EN, 1,\n\t\t\t     FRF_AB_XM_RX_STAT_EN, 1);\n\tef4_writeo(efx, &reg, FR_AB_XM_GLB_CFG);\n\n\t \n\tEF4_POPULATE_OWORD_6(reg,\n\t\t\t     FRF_AB_XM_TXEN, 1,\n\t\t\t     FRF_AB_XM_TX_PRMBL, 1,\n\t\t\t     FRF_AB_XM_AUTO_PAD, 1,\n\t\t\t     FRF_AB_XM_TXCRC, 1,\n\t\t\t     FRF_AB_XM_FCNTL, tx_fc,\n\t\t\t     FRF_AB_XM_IPG, 0x3);\n\tef4_writeo(efx, &reg, FR_AB_XM_TX_CFG);\n\n\t \n\tEF4_POPULATE_OWORD_5(reg,\n\t\t\t     FRF_AB_XM_RXEN, 1,\n\t\t\t     FRF_AB_XM_AUTO_DEPAD, 0,\n\t\t\t     FRF_AB_XM_ACPT_ALL_MCAST, 1,\n\t\t\t     FRF_AB_XM_ACPT_ALL_UCAST, !efx->unicast_filter,\n\t\t\t     FRF_AB_XM_PASS_CRC_ERR, 1);\n\tef4_writeo(efx, &reg, FR_AB_XM_RX_CFG);\n\n\t \n\tmax_frame_len = EF4_MAX_FRAME_LEN(efx->net_dev->mtu);\n\tEF4_POPULATE_OWORD_1(reg, FRF_AB_XM_MAX_RX_FRM_SIZE, max_frame_len);\n\tef4_writeo(efx, &reg, FR_AB_XM_RX_PARAM);\n\tEF4_POPULATE_OWORD_2(reg,\n\t\t\t     FRF_AB_XM_MAX_TX_FRM_SIZE, max_frame_len,\n\t\t\t     FRF_AB_XM_TX_JUMBO_MODE, 1);\n\tef4_writeo(efx, &reg, FR_AB_XM_TX_PARAM);\n\n\tEF4_POPULATE_OWORD_2(reg,\n\t\t\t     FRF_AB_XM_PAUSE_TIME, 0xfffe,  \n\t\t\t     FRF_AB_XM_DIS_FCNTL, !rx_fc);\n\tef4_writeo(efx, &reg, FR_AB_XM_FC);\n\n\t \n\tmemcpy(&reg, &efx->net_dev->dev_addr[0], 4);\n\tef4_writeo(efx, &reg, FR_AB_XM_ADR_LO);\n\tmemcpy(&reg, &efx->net_dev->dev_addr[4], 2);\n\tef4_writeo(efx, &reg, FR_AB_XM_ADR_HI);\n}\n\nstatic void falcon_reconfigure_xgxs_core(struct ef4_nic *efx)\n{\n\tef4_oword_t reg;\n\tbool xgxs_loopback = (efx->loopback_mode == LOOPBACK_XGXS);\n\tbool xaui_loopback = (efx->loopback_mode == LOOPBACK_XAUI);\n\tbool xgmii_loopback = (efx->loopback_mode == LOOPBACK_XGMII);\n\tbool old_xgmii_loopback, old_xgxs_loopback, old_xaui_loopback;\n\n\t \n\tef4_reado(efx, &reg, FR_AB_XX_CORE_STAT);\n\told_xgxs_loopback = EF4_OWORD_FIELD(reg, FRF_AB_XX_XGXS_LB_EN);\n\told_xgmii_loopback = EF4_OWORD_FIELD(reg, FRF_AB_XX_XGMII_LB_EN);\n\n\tef4_reado(efx, &reg, FR_AB_XX_SD_CTL);\n\told_xaui_loopback = EF4_OWORD_FIELD(reg, FRF_AB_XX_LPBKA);\n\n\t \n\tif ((xgxs_loopback != old_xgxs_loopback) ||\n\t    (xaui_loopback != old_xaui_loopback) ||\n\t    (xgmii_loopback != old_xgmii_loopback))\n\t\tfalcon_reset_xaui(efx);\n\n\tef4_reado(efx, &reg, FR_AB_XX_CORE_STAT);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_FORCE_SIG,\n\t\t\t    (xgxs_loopback || xaui_loopback) ?\n\t\t\t    FFE_AB_XX_FORCE_SIG_ALL_LANES : 0);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_XGXS_LB_EN, xgxs_loopback);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_XGMII_LB_EN, xgmii_loopback);\n\tef4_writeo(efx, &reg, FR_AB_XX_CORE_STAT);\n\n\tef4_reado(efx, &reg, FR_AB_XX_SD_CTL);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_LPBKD, xaui_loopback);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_LPBKC, xaui_loopback);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_LPBKB, xaui_loopback);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_XX_LPBKA, xaui_loopback);\n\tef4_writeo(efx, &reg, FR_AB_XX_SD_CTL);\n}\n\n\n \nstatic bool falcon_xmac_link_ok_retry(struct ef4_nic *efx, int tries)\n{\n\tbool mac_up = falcon_xmac_link_ok(efx);\n\n\tif (LOOPBACK_MASK(efx) & LOOPBACKS_EXTERNAL(efx) & LOOPBACKS_WS ||\n\t    ef4_phy_mode_disabled(efx->phy_mode))\n\t\t \n\t\treturn mac_up;\n\n\tfalcon_stop_nic_stats(efx);\n\n\twhile (!mac_up && tries) {\n\t\tnetif_dbg(efx, hw, efx->net_dev, \"bashing xaui\\n\");\n\t\tfalcon_reset_xaui(efx);\n\t\tudelay(200);\n\n\t\tmac_up = falcon_xmac_link_ok(efx);\n\t\t--tries;\n\t}\n\n\tfalcon_start_nic_stats(efx);\n\n\treturn mac_up;\n}\n\nstatic bool falcon_xmac_check_fault(struct ef4_nic *efx)\n{\n\treturn !falcon_xmac_link_ok_retry(efx, 5);\n}\n\nstatic int falcon_reconfigure_xmac(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\n\tef4_farch_filter_sync_rx_mode(efx);\n\n\tfalcon_reconfigure_xgxs_core(efx);\n\tfalcon_reconfigure_xmac_core(efx);\n\n\tfalcon_reconfigure_mac_wrapper(efx);\n\n\tnic_data->xmac_poll_required = !falcon_xmac_link_ok_retry(efx, 5);\n\tfalcon_ack_status_intr(efx);\n\n\treturn 0;\n}\n\nstatic void falcon_poll_xmac(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\n\t \n\tif (!efx->link_state.up || !nic_data->xmac_poll_required)\n\t\treturn;\n\n\tnic_data->xmac_poll_required = !falcon_xmac_link_ok_retry(efx, 1);\n\tfalcon_ack_status_intr(efx);\n}\n\n \n\nstatic void falcon_push_multicast_hash(struct ef4_nic *efx)\n{\n\tunion ef4_multicast_hash *mc_hash = &efx->multicast_hash;\n\n\tWARN_ON(!mutex_is_locked(&efx->mac_lock));\n\n\tef4_writeo(efx, &mc_hash->oword[0], FR_AB_MAC_MC_HASH_REG0);\n\tef4_writeo(efx, &mc_hash->oword[1], FR_AB_MAC_MC_HASH_REG1);\n}\n\nstatic void falcon_reset_macs(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t reg, mac_ctrl;\n\tint count;\n\n\tif (ef4_nic_rev(efx) < EF4_REV_FALCON_B0) {\n\t\t \n\t\tEF4_POPULATE_OWORD_1(reg, FRF_AB_XM_CORE_RST, 1);\n\t\tef4_writeo(efx, &reg, FR_AB_XM_GLB_CFG);\n\n\t\tfor (count = 0; count < 10000; count++) {\n\t\t\tef4_reado(efx, &reg, FR_AB_XM_GLB_CFG);\n\t\t\tif (EF4_OWORD_FIELD(reg, FRF_AB_XM_CORE_RST) ==\n\t\t\t    0)\n\t\t\t\treturn;\n\t\t\tudelay(10);\n\t\t}\n\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"timed out waiting for XMAC core reset\\n\");\n\t}\n\n\t \n\tWARN_ON(nic_data->stats_disable_count == 0);\n\n\tef4_reado(efx, &mac_ctrl, FR_AB_MAC_CTRL);\n\tEF4_SET_OWORD_FIELD(mac_ctrl, FRF_BB_TXFIFO_DRAIN_EN, 1);\n\tef4_writeo(efx, &mac_ctrl, FR_AB_MAC_CTRL);\n\n\tef4_reado(efx, &reg, FR_AB_GLB_CTL);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_RST_XGTX, 1);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_RST_XGRX, 1);\n\tEF4_SET_OWORD_FIELD(reg, FRF_AB_RST_EM, 1);\n\tef4_writeo(efx, &reg, FR_AB_GLB_CTL);\n\n\tcount = 0;\n\twhile (1) {\n\t\tef4_reado(efx, &reg, FR_AB_GLB_CTL);\n\t\tif (!EF4_OWORD_FIELD(reg, FRF_AB_RST_XGTX) &&\n\t\t    !EF4_OWORD_FIELD(reg, FRF_AB_RST_XGRX) &&\n\t\t    !EF4_OWORD_FIELD(reg, FRF_AB_RST_EM)) {\n\t\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t\t  \"Completed MAC reset after %d loops\\n\",\n\t\t\t\t  count);\n\t\t\tbreak;\n\t\t}\n\t\tif (count > 20) {\n\t\t\tnetif_err(efx, hw, efx->net_dev, \"MAC reset failed\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tcount++;\n\t\tudelay(10);\n\t}\n\n\t \n\tef4_writeo(efx, &mac_ctrl, FR_AB_MAC_CTRL);\n\n\tfalcon_setup_xaui(efx);\n}\n\nstatic void falcon_drain_tx_fifo(struct ef4_nic *efx)\n{\n\tef4_oword_t reg;\n\n\tif ((ef4_nic_rev(efx) < EF4_REV_FALCON_B0) ||\n\t    (efx->loopback_mode != LOOPBACK_NONE))\n\t\treturn;\n\n\tef4_reado(efx, &reg, FR_AB_MAC_CTRL);\n\t \n\tif (EF4_OWORD_FIELD(reg, FRF_BB_TXFIFO_DRAIN_EN))\n\t\treturn;\n\n\tfalcon_reset_macs(efx);\n}\n\nstatic void falcon_deconfigure_mac_wrapper(struct ef4_nic *efx)\n{\n\tef4_oword_t reg;\n\n\tif (ef4_nic_rev(efx) < EF4_REV_FALCON_B0)\n\t\treturn;\n\n\t \n\tef4_reado(efx, &reg, FR_AZ_RX_CFG);\n\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_INGR_EN, 0);\n\tef4_writeo(efx, &reg, FR_AZ_RX_CFG);\n\n\t \n\tfalcon_drain_tx_fifo(efx);\n}\n\nstatic void falcon_reconfigure_mac_wrapper(struct ef4_nic *efx)\n{\n\tstruct ef4_link_state *link_state = &efx->link_state;\n\tef4_oword_t reg;\n\tint link_speed, isolate;\n\n\tisolate = !!READ_ONCE(efx->reset_pending);\n\n\tswitch (link_state->speed) {\n\tcase 10000: link_speed = 3; break;\n\tcase 1000:  link_speed = 2; break;\n\tcase 100:   link_speed = 1; break;\n\tdefault:    link_speed = 0; break;\n\t}\n\n\t \n\tEF4_POPULATE_OWORD_5(reg,\n\t\t\t     FRF_AB_MAC_XOFF_VAL, 0xffff  ,\n\t\t\t     FRF_AB_MAC_BCAD_ACPT, 1,\n\t\t\t     FRF_AB_MAC_UC_PROM, !efx->unicast_filter,\n\t\t\t     FRF_AB_MAC_LINK_STATUS, 1,  \n\t\t\t     FRF_AB_MAC_SPEED, link_speed);\n\t \n\tif (ef4_nic_rev(efx) >= EF4_REV_FALCON_B0) {\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BB_TXFIFO_DRAIN_EN,\n\t\t\t\t    !link_state->up || isolate);\n\t}\n\n\tef4_writeo(efx, &reg, FR_AB_MAC_CTRL);\n\n\t \n\tfalcon_push_multicast_hash(efx);\n\n\tef4_reado(efx, &reg, FR_AZ_RX_CFG);\n\t \n\tEF4_SET_OWORD_FIELD(reg, FRF_AZ_RX_XOFF_MAC_EN, 1);\n\t \n\tif (ef4_nic_rev(efx) >= EF4_REV_FALCON_B0)\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_INGR_EN, !isolate);\n\tef4_writeo(efx, &reg, FR_AZ_RX_CFG);\n}\n\nstatic void falcon_stats_request(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t reg;\n\n\tWARN_ON(nic_data->stats_pending);\n\tWARN_ON(nic_data->stats_disable_count);\n\n\tFALCON_XMAC_STATS_DMA_FLAG(efx) = 0;\n\tnic_data->stats_pending = true;\n\twmb();  \n\n\t \n\tEF4_POPULATE_OWORD_2(reg,\n\t\t\t     FRF_AB_MAC_STAT_DMA_CMD, 1,\n\t\t\t     FRF_AB_MAC_STAT_DMA_ADR,\n\t\t\t     efx->stats_buffer.dma_addr);\n\tef4_writeo(efx, &reg, FR_AB_MAC_STAT_DMA);\n\n\tmod_timer(&nic_data->stats_timer, round_jiffies_up(jiffies + HZ / 2));\n}\n\nstatic void falcon_stats_complete(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\n\tif (!nic_data->stats_pending)\n\t\treturn;\n\n\tnic_data->stats_pending = false;\n\tif (FALCON_XMAC_STATS_DMA_FLAG(efx)) {\n\t\trmb();  \n\t\tef4_nic_update_stats(falcon_stat_desc, FALCON_STAT_COUNT,\n\t\t\t\t     falcon_stat_mask, nic_data->stats,\n\t\t\t\t     efx->stats_buffer.addr, true);\n\t} else {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"timed out waiting for statistics\\n\");\n\t}\n}\n\nstatic void falcon_stats_timer_func(struct timer_list *t)\n{\n\tstruct falcon_nic_data *nic_data = from_timer(nic_data, t,\n\t\t\t\t\t\t      stats_timer);\n\tstruct ef4_nic *efx = nic_data->efx;\n\n\tspin_lock(&efx->stats_lock);\n\n\tfalcon_stats_complete(efx);\n\tif (nic_data->stats_disable_count == 0)\n\t\tfalcon_stats_request(efx);\n\n\tspin_unlock(&efx->stats_lock);\n}\n\nstatic bool falcon_loopback_link_poll(struct ef4_nic *efx)\n{\n\tstruct ef4_link_state old_state = efx->link_state;\n\n\tWARN_ON(!mutex_is_locked(&efx->mac_lock));\n\tWARN_ON(!LOOPBACK_INTERNAL(efx));\n\n\tefx->link_state.fd = true;\n\tefx->link_state.fc = efx->wanted_fc;\n\tefx->link_state.up = true;\n\tefx->link_state.speed = 10000;\n\n\treturn !ef4_link_state_equal(&efx->link_state, &old_state);\n}\n\nstatic int falcon_reconfigure_port(struct ef4_nic *efx)\n{\n\tint rc;\n\n\tWARN_ON(ef4_nic_rev(efx) > EF4_REV_FALCON_B0);\n\n\t \n\tif (LOOPBACK_INTERNAL(efx))\n\t\tfalcon_loopback_link_poll(efx);\n\telse\n\t\tefx->phy_op->poll(efx);\n\n\tfalcon_stop_nic_stats(efx);\n\tfalcon_deconfigure_mac_wrapper(efx);\n\n\tfalcon_reset_macs(efx);\n\n\tefx->phy_op->reconfigure(efx);\n\trc = falcon_reconfigure_xmac(efx);\n\tBUG_ON(rc);\n\n\tfalcon_start_nic_stats(efx);\n\n\t \n\tef4_link_status_changed(efx);\n\n\treturn 0;\n}\n\n \n\nstatic void falcon_a1_prepare_enable_fc_tx(struct ef4_nic *efx)\n{\n\t \n\tef4_schedule_reset(efx, RESET_TYPE_INVISIBLE);\n}\n\nstatic void falcon_b0_prepare_enable_fc_tx(struct ef4_nic *efx)\n{\n\t \n\tfalcon_stop_nic_stats(efx);\n\tfalcon_drain_tx_fifo(efx);\n\tfalcon_reconfigure_xmac(efx);\n\tfalcon_start_nic_stats(efx);\n}\n\n \n\n \nstatic int falcon_gmii_wait(struct ef4_nic *efx)\n{\n\tef4_oword_t md_stat;\n\tint count;\n\n\t \n\tfor (count = 0; count < 5000; count++) {\n\t\tef4_reado(efx, &md_stat, FR_AB_MD_STAT);\n\t\tif (EF4_OWORD_FIELD(md_stat, FRF_AB_MD_BSY) == 0) {\n\t\t\tif (EF4_OWORD_FIELD(md_stat, FRF_AB_MD_LNFL) != 0 ||\n\t\t\t    EF4_OWORD_FIELD(md_stat, FRF_AB_MD_BSERR) != 0) {\n\t\t\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t\t\t  \"error from GMII access \"\n\t\t\t\t\t  EF4_OWORD_FMT\"\\n\",\n\t\t\t\t\t  EF4_OWORD_VAL(md_stat));\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t\tudelay(10);\n\t}\n\tnetif_err(efx, hw, efx->net_dev, \"timed out waiting for GMII\\n\");\n\treturn -ETIMEDOUT;\n}\n\n \nstatic int falcon_mdio_write(struct net_device *net_dev,\n\t\t\t     int prtad, int devad, u16 addr, u16 value)\n{\n\tstruct ef4_nic *efx = netdev_priv(net_dev);\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t reg;\n\tint rc;\n\n\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t   \"writing MDIO %d register %d.%d with 0x%04x\\n\",\n\t\t    prtad, devad, addr, value);\n\n\tmutex_lock(&nic_data->mdio_lock);\n\n\t \n\trc = falcon_gmii_wait(efx);\n\tif (rc)\n\t\tgoto out;\n\n\t \n\tEF4_POPULATE_OWORD_1(reg, FRF_AB_MD_PHY_ADR, addr);\n\tef4_writeo(efx, &reg, FR_AB_MD_PHY_ADR);\n\n\tEF4_POPULATE_OWORD_2(reg, FRF_AB_MD_PRT_ADR, prtad,\n\t\t\t     FRF_AB_MD_DEV_ADR, devad);\n\tef4_writeo(efx, &reg, FR_AB_MD_ID);\n\n\t \n\tEF4_POPULATE_OWORD_1(reg, FRF_AB_MD_TXD, value);\n\tef4_writeo(efx, &reg, FR_AB_MD_TXD);\n\n\tEF4_POPULATE_OWORD_2(reg,\n\t\t\t     FRF_AB_MD_WRC, 1,\n\t\t\t     FRF_AB_MD_GC, 0);\n\tef4_writeo(efx, &reg, FR_AB_MD_CS);\n\n\t \n\trc = falcon_gmii_wait(efx);\n\tif (rc) {\n\t\t \n\t\tEF4_POPULATE_OWORD_2(reg,\n\t\t\t\t     FRF_AB_MD_WRC, 0,\n\t\t\t\t     FRF_AB_MD_GC, 1);\n\t\tef4_writeo(efx, &reg, FR_AB_MD_CS);\n\t\tudelay(10);\n\t}\n\nout:\n\tmutex_unlock(&nic_data->mdio_lock);\n\treturn rc;\n}\n\n \nstatic int falcon_mdio_read(struct net_device *net_dev,\n\t\t\t    int prtad, int devad, u16 addr)\n{\n\tstruct ef4_nic *efx = netdev_priv(net_dev);\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t reg;\n\tint rc;\n\n\tmutex_lock(&nic_data->mdio_lock);\n\n\t \n\trc = falcon_gmii_wait(efx);\n\tif (rc)\n\t\tgoto out;\n\n\tEF4_POPULATE_OWORD_1(reg, FRF_AB_MD_PHY_ADR, addr);\n\tef4_writeo(efx, &reg, FR_AB_MD_PHY_ADR);\n\n\tEF4_POPULATE_OWORD_2(reg, FRF_AB_MD_PRT_ADR, prtad,\n\t\t\t     FRF_AB_MD_DEV_ADR, devad);\n\tef4_writeo(efx, &reg, FR_AB_MD_ID);\n\n\t \n\tEF4_POPULATE_OWORD_2(reg, FRF_AB_MD_RDC, 1, FRF_AB_MD_GC, 0);\n\tef4_writeo(efx, &reg, FR_AB_MD_CS);\n\n\t \n\trc = falcon_gmii_wait(efx);\n\tif (rc == 0) {\n\t\tef4_reado(efx, &reg, FR_AB_MD_RXD);\n\t\trc = EF4_OWORD_FIELD(reg, FRF_AB_MD_RXD);\n\t\tnetif_vdbg(efx, hw, efx->net_dev,\n\t\t\t   \"read from MDIO %d register %d.%d, got %04x\\n\",\n\t\t\t   prtad, devad, addr, rc);\n\t} else {\n\t\t \n\t\tEF4_POPULATE_OWORD_2(reg,\n\t\t\t\t     FRF_AB_MD_RIC, 0,\n\t\t\t\t     FRF_AB_MD_GC, 1);\n\t\tef4_writeo(efx, &reg, FR_AB_MD_CS);\n\n\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t  \"read from MDIO %d register %d.%d, got error %d\\n\",\n\t\t\t  prtad, devad, addr, rc);\n\t}\n\nout:\n\tmutex_unlock(&nic_data->mdio_lock);\n\treturn rc;\n}\n\n \nstatic int falcon_probe_port(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tint rc;\n\n\tswitch (efx->phy_type) {\n\tcase PHY_TYPE_SFX7101:\n\t\tefx->phy_op = &falcon_sfx7101_phy_ops;\n\t\tbreak;\n\tcase PHY_TYPE_QT2022C2:\n\tcase PHY_TYPE_QT2025C:\n\t\tefx->phy_op = &falcon_qt202x_phy_ops;\n\t\tbreak;\n\tcase PHY_TYPE_TXC43128:\n\t\tefx->phy_op = &falcon_txc_phy_ops;\n\t\tbreak;\n\tdefault:\n\t\tnetif_err(efx, probe, efx->net_dev, \"Unknown PHY type %d\\n\",\n\t\t\t  efx->phy_type);\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tmutex_init(&nic_data->mdio_lock);\n\tefx->mdio.mdio_read = falcon_mdio_read;\n\tefx->mdio.mdio_write = falcon_mdio_write;\n\trc = efx->phy_op->probe(efx);\n\tif (rc != 0)\n\t\treturn rc;\n\n\t \n\tefx->link_state.speed = 10000;\n\tefx->link_state.fd = true;\n\n\t \n\tif (ef4_nic_rev(efx) >= EF4_REV_FALCON_B0)\n\t\tefx->wanted_fc = EF4_FC_RX | EF4_FC_TX;\n\telse\n\t\tefx->wanted_fc = EF4_FC_RX;\n\tif (efx->mdio.mmds & MDIO_DEVS_AN)\n\t\tefx->wanted_fc |= EF4_FC_AUTO;\n\n\t \n\trc = ef4_nic_alloc_buffer(efx, &efx->stats_buffer,\n\t\t\t\t  FALCON_MAC_STATS_SIZE, GFP_KERNEL);\n\tif (rc)\n\t\treturn rc;\n\tnetif_dbg(efx, probe, efx->net_dev,\n\t\t  \"stats buffer at %llx (virt %p phys %llx)\\n\",\n\t\t  (u64)efx->stats_buffer.dma_addr,\n\t\t  efx->stats_buffer.addr,\n\t\t  (u64)virt_to_phys(efx->stats_buffer.addr));\n\n\treturn 0;\n}\n\nstatic void falcon_remove_port(struct ef4_nic *efx)\n{\n\tefx->phy_op->remove(efx);\n\tef4_nic_free_buffer(efx, &efx->stats_buffer);\n}\n\n \nstatic bool\nfalcon_handle_global_event(struct ef4_channel *channel, ef4_qword_t *event)\n{\n\tstruct ef4_nic *efx = channel->efx;\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\n\tif (EF4_QWORD_FIELD(*event, FSF_AB_GLB_EV_G_PHY0_INTR) ||\n\t    EF4_QWORD_FIELD(*event, FSF_AB_GLB_EV_XG_PHY0_INTR) ||\n\t    EF4_QWORD_FIELD(*event, FSF_AB_GLB_EV_XFP_PHY0_INTR))\n\t\t \n\t\treturn true;\n\n\tif ((ef4_nic_rev(efx) == EF4_REV_FALCON_B0) &&\n\t    EF4_QWORD_FIELD(*event, FSF_BB_GLB_EV_XG_MGT_INTR)) {\n\t\tnic_data->xmac_poll_required = true;\n\t\treturn true;\n\t}\n\n\tif (ef4_nic_rev(efx) <= EF4_REV_FALCON_A1 ?\n\t    EF4_QWORD_FIELD(*event, FSF_AA_GLB_EV_RX_RECOVERY) :\n\t    EF4_QWORD_FIELD(*event, FSF_BB_GLB_EV_RX_RECOVERY)) {\n\t\tnetif_err(efx, rx_err, efx->net_dev,\n\t\t\t  \"channel %d seen global RX_RESET event. Resetting.\\n\",\n\t\t\t  channel->channel);\n\n\t\tatomic_inc(&efx->rx_reset);\n\t\tef4_schedule_reset(efx, EF4_WORKAROUND_6555(efx) ?\n\t\t\t\t   RESET_TYPE_RX_RECOVERY : RESET_TYPE_DISABLE);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \n\nstatic int\nfalcon_read_nvram(struct ef4_nic *efx, struct falcon_nvconfig *nvconfig_out)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tstruct falcon_nvconfig *nvconfig;\n\tstruct falcon_spi_device *spi;\n\tvoid *region;\n\tint rc, magic_num, struct_ver;\n\t__le16 *word, *limit;\n\tu32 csum;\n\n\tif (falcon_spi_present(&nic_data->spi_flash))\n\t\tspi = &nic_data->spi_flash;\n\telse if (falcon_spi_present(&nic_data->spi_eeprom))\n\t\tspi = &nic_data->spi_eeprom;\n\telse\n\t\treturn -EINVAL;\n\n\tregion = kmalloc(FALCON_NVCONFIG_END, GFP_KERNEL);\n\tif (!region)\n\t\treturn -ENOMEM;\n\tnvconfig = region + FALCON_NVCONFIG_OFFSET;\n\n\tmutex_lock(&nic_data->spi_lock);\n\trc = falcon_spi_read(efx, spi, 0, FALCON_NVCONFIG_END, NULL, region);\n\tmutex_unlock(&nic_data->spi_lock);\n\tif (rc) {\n\t\tnetif_err(efx, hw, efx->net_dev, \"Failed to read %s\\n\",\n\t\t\t  falcon_spi_present(&nic_data->spi_flash) ?\n\t\t\t  \"flash\" : \"EEPROM\");\n\t\trc = -EIO;\n\t\tgoto out;\n\t}\n\n\tmagic_num = le16_to_cpu(nvconfig->board_magic_num);\n\tstruct_ver = le16_to_cpu(nvconfig->board_struct_ver);\n\n\trc = -EINVAL;\n\tif (magic_num != FALCON_NVCONFIG_BOARD_MAGIC_NUM) {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"NVRAM bad magic 0x%x\\n\", magic_num);\n\t\tgoto out;\n\t}\n\tif (struct_ver < 2) {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"NVRAM has ancient version 0x%x\\n\", struct_ver);\n\t\tgoto out;\n\t} else if (struct_ver < 4) {\n\t\tword = &nvconfig->board_magic_num;\n\t\tlimit = (__le16 *) (nvconfig + 1);\n\t} else {\n\t\tword = region;\n\t\tlimit = region + FALCON_NVCONFIG_END;\n\t}\n\tfor (csum = 0; word < limit; ++word)\n\t\tcsum += le16_to_cpu(*word);\n\n\tif (~csum & 0xffff) {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"NVRAM has incorrect checksum\\n\");\n\t\tgoto out;\n\t}\n\n\trc = 0;\n\tif (nvconfig_out)\n\t\tmemcpy(nvconfig_out, nvconfig, sizeof(*nvconfig));\n\n out:\n\tkfree(region);\n\treturn rc;\n}\n\nstatic int falcon_test_nvram(struct ef4_nic *efx)\n{\n\treturn falcon_read_nvram(efx, NULL);\n}\n\nstatic const struct ef4_farch_register_test falcon_b0_register_tests[] = {\n\t{ FR_AZ_ADR_REGION,\n\t  EF4_OWORD32(0x0003FFFF, 0x0003FFFF, 0x0003FFFF, 0x0003FFFF) },\n\t{ FR_AZ_RX_CFG,\n\t  EF4_OWORD32(0xFFFFFFFE, 0x00017FFF, 0x00000000, 0x00000000) },\n\t{ FR_AZ_TX_CFG,\n\t  EF4_OWORD32(0x7FFF0037, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AZ_TX_RESERVED,\n\t  EF4_OWORD32(0xFFFEFE80, 0x1FFFFFFF, 0x020000FE, 0x007FFFFF) },\n\t{ FR_AB_MAC_CTRL,\n\t  EF4_OWORD32(0xFFFF0000, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AZ_SRM_TX_DC_CFG,\n\t  EF4_OWORD32(0x001FFFFF, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AZ_RX_DC_CFG,\n\t  EF4_OWORD32(0x0000000F, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AZ_RX_DC_PF_WM,\n\t  EF4_OWORD32(0x000003FF, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_BZ_DP_CTRL,\n\t  EF4_OWORD32(0x00000FFF, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_GM_CFG2,\n\t  EF4_OWORD32(0x00007337, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_GMF_CFG0,\n\t  EF4_OWORD32(0x00001F1F, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_XM_GLB_CFG,\n\t  EF4_OWORD32(0x00000C68, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_XM_TX_CFG,\n\t  EF4_OWORD32(0x00080164, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_XM_RX_CFG,\n\t  EF4_OWORD32(0x07100A0C, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_XM_RX_PARAM,\n\t  EF4_OWORD32(0x00001FF8, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_XM_FC,\n\t  EF4_OWORD32(0xFFFF0001, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_XM_ADR_LO,\n\t  EF4_OWORD32(0xFFFFFFFF, 0x00000000, 0x00000000, 0x00000000) },\n\t{ FR_AB_XX_SD_CTL,\n\t  EF4_OWORD32(0x0003FF0F, 0x00000000, 0x00000000, 0x00000000) },\n};\n\nstatic int\nfalcon_b0_test_chip(struct ef4_nic *efx, struct ef4_self_tests *tests)\n{\n\tenum reset_type reset_method = RESET_TYPE_INVISIBLE;\n\tint rc, rc2;\n\n\tmutex_lock(&efx->mac_lock);\n\tif (efx->loopback_modes) {\n\t\t \n\t\tif (efx->loopback_modes & (1 << LOOPBACK_XGMII))\n\t\t\tefx->loopback_mode = LOOPBACK_XGMII;\n\t\telse\n\t\t\tefx->loopback_mode = __ffs(efx->loopback_modes);\n\t}\n\t__ef4_reconfigure_port(efx);\n\tmutex_unlock(&efx->mac_lock);\n\n\tef4_reset_down(efx, reset_method);\n\n\ttests->registers =\n\t\tef4_farch_test_registers(efx, falcon_b0_register_tests,\n\t\t\t\t\t ARRAY_SIZE(falcon_b0_register_tests))\n\t\t? -1 : 1;\n\n\trc = falcon_reset_hw(efx, reset_method);\n\trc2 = ef4_reset_up(efx, reset_method, rc == 0);\n\treturn rc ? rc : rc2;\n}\n\n \n\nstatic enum reset_type falcon_map_reset_reason(enum reset_type reason)\n{\n\tswitch (reason) {\n\tcase RESET_TYPE_RX_RECOVERY:\n\tcase RESET_TYPE_DMA_ERROR:\n\tcase RESET_TYPE_TX_SKIP:\n\t\t \n\t\treturn RESET_TYPE_INVISIBLE;\n\tdefault:\n\t\treturn RESET_TYPE_ALL;\n\t}\n}\n\nstatic int falcon_map_reset_flags(u32 *flags)\n{\n\tenum {\n\t\tFALCON_RESET_INVISIBLE = (ETH_RESET_DMA | ETH_RESET_FILTER |\n\t\t\t\t\t  ETH_RESET_OFFLOAD | ETH_RESET_MAC),\n\t\tFALCON_RESET_ALL = FALCON_RESET_INVISIBLE | ETH_RESET_PHY,\n\t\tFALCON_RESET_WORLD = FALCON_RESET_ALL | ETH_RESET_IRQ,\n\t};\n\n\tif ((*flags & FALCON_RESET_WORLD) == FALCON_RESET_WORLD) {\n\t\t*flags &= ~FALCON_RESET_WORLD;\n\t\treturn RESET_TYPE_WORLD;\n\t}\n\n\tif ((*flags & FALCON_RESET_ALL) == FALCON_RESET_ALL) {\n\t\t*flags &= ~FALCON_RESET_ALL;\n\t\treturn RESET_TYPE_ALL;\n\t}\n\n\tif ((*flags & FALCON_RESET_INVISIBLE) == FALCON_RESET_INVISIBLE) {\n\t\t*flags &= ~FALCON_RESET_INVISIBLE;\n\t\treturn RESET_TYPE_INVISIBLE;\n\t}\n\n\treturn -EINVAL;\n}\n\n \nstatic int __falcon_reset_hw(struct ef4_nic *efx, enum reset_type method)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t glb_ctl_reg_ker;\n\tint rc;\n\n\tnetif_dbg(efx, hw, efx->net_dev, \"performing %s hardware reset\\n\",\n\t\t  RESET_TYPE(method));\n\n\t \n\tif (method == RESET_TYPE_WORLD) {\n\t\trc = pci_save_state(efx->pci_dev);\n\t\tif (rc) {\n\t\t\tnetif_err(efx, drv, efx->net_dev,\n\t\t\t\t  \"failed to backup PCI state of primary \"\n\t\t\t\t  \"function prior to hardware reset\\n\");\n\t\t\tgoto fail1;\n\t\t}\n\t\tif (ef4_nic_is_dual_func(efx)) {\n\t\t\trc = pci_save_state(nic_data->pci_dev2);\n\t\t\tif (rc) {\n\t\t\t\tnetif_err(efx, drv, efx->net_dev,\n\t\t\t\t\t  \"failed to backup PCI state of \"\n\t\t\t\t\t  \"secondary function prior to \"\n\t\t\t\t\t  \"hardware reset\\n\");\n\t\t\t\tgoto fail2;\n\t\t\t}\n\t\t}\n\n\t\tEF4_POPULATE_OWORD_2(glb_ctl_reg_ker,\n\t\t\t\t     FRF_AB_EXT_PHY_RST_DUR,\n\t\t\t\t     FFE_AB_EXT_PHY_RST_DUR_10240US,\n\t\t\t\t     FRF_AB_SWRST, 1);\n\t} else {\n\t\tEF4_POPULATE_OWORD_7(glb_ctl_reg_ker,\n\t\t\t\t      \n\t\t\t\t     FRF_AB_EXT_PHY_RST_CTL,\n\t\t\t\t     method == RESET_TYPE_INVISIBLE,\n\t\t\t\t      \n\t\t\t\t     FRF_AB_PCIE_CORE_RST_CTL, 1,\n\t\t\t\t     FRF_AB_PCIE_NSTKY_RST_CTL, 1,\n\t\t\t\t     FRF_AB_PCIE_SD_RST_CTL, 1,\n\t\t\t\t     FRF_AB_EE_RST_CTL, 1,\n\t\t\t\t     FRF_AB_EXT_PHY_RST_DUR,\n\t\t\t\t     FFE_AB_EXT_PHY_RST_DUR_10240US,\n\t\t\t\t     FRF_AB_SWRST, 1);\n\t}\n\tef4_writeo(efx, &glb_ctl_reg_ker, FR_AB_GLB_CTL);\n\n\tnetif_dbg(efx, hw, efx->net_dev, \"waiting for hardware reset\\n\");\n\tschedule_timeout_uninterruptible(HZ / 20);\n\n\t \n\tif (method == RESET_TYPE_WORLD) {\n\t\tif (ef4_nic_is_dual_func(efx))\n\t\t\tpci_restore_state(nic_data->pci_dev2);\n\t\tpci_restore_state(efx->pci_dev);\n\t\tnetif_dbg(efx, drv, efx->net_dev,\n\t\t\t  \"successfully restored PCI config\\n\");\n\t}\n\n\t \n\tef4_reado(efx, &glb_ctl_reg_ker, FR_AB_GLB_CTL);\n\tif (EF4_OWORD_FIELD(glb_ctl_reg_ker, FRF_AB_SWRST) != 0) {\n\t\trc = -ETIMEDOUT;\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"timed out waiting for hardware reset\\n\");\n\t\tgoto fail3;\n\t}\n\tnetif_dbg(efx, hw, efx->net_dev, \"hardware reset complete\\n\");\n\n\treturn 0;\n\n\t \nfail2:\n\tpci_restore_state(efx->pci_dev);\nfail1:\nfail3:\n\treturn rc;\n}\n\nstatic int falcon_reset_hw(struct ef4_nic *efx, enum reset_type method)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tint rc;\n\n\tmutex_lock(&nic_data->spi_lock);\n\trc = __falcon_reset_hw(efx, method);\n\tmutex_unlock(&nic_data->spi_lock);\n\n\treturn rc;\n}\n\nstatic void falcon_monitor(struct ef4_nic *efx)\n{\n\tbool link_changed;\n\tint rc;\n\n\tBUG_ON(!mutex_is_locked(&efx->mac_lock));\n\n\trc = falcon_board(efx)->type->monitor(efx);\n\tif (rc) {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"Board sensor %s; shutting down PHY\\n\",\n\t\t\t  (rc == -ERANGE) ? \"reported fault\" : \"failed\");\n\t\tefx->phy_mode |= PHY_MODE_LOW_POWER;\n\t\trc = __ef4_reconfigure_port(efx);\n\t\tWARN_ON(rc);\n\t}\n\n\tif (LOOPBACK_INTERNAL(efx))\n\t\tlink_changed = falcon_loopback_link_poll(efx);\n\telse\n\t\tlink_changed = efx->phy_op->poll(efx);\n\n\tif (link_changed) {\n\t\tfalcon_stop_nic_stats(efx);\n\t\tfalcon_deconfigure_mac_wrapper(efx);\n\n\t\tfalcon_reset_macs(efx);\n\t\trc = falcon_reconfigure_xmac(efx);\n\t\tBUG_ON(rc);\n\n\t\tfalcon_start_nic_stats(efx);\n\n\t\tef4_link_status_changed(efx);\n\t}\n\n\tfalcon_poll_xmac(efx);\n}\n\n \nstatic int falcon_reset_sram(struct ef4_nic *efx)\n{\n\tef4_oword_t srm_cfg_reg_ker, gpio_cfg_reg_ker;\n\tint count;\n\n\t \n\tef4_reado(efx, &gpio_cfg_reg_ker, FR_AB_GPIO_CTL);\n\tEF4_SET_OWORD_FIELD(gpio_cfg_reg_ker, FRF_AB_GPIO1_OEN, 1);\n\tEF4_SET_OWORD_FIELD(gpio_cfg_reg_ker, FRF_AB_GPIO1_OUT, 1);\n\tef4_writeo(efx, &gpio_cfg_reg_ker, FR_AB_GPIO_CTL);\n\n\t \n\tEF4_POPULATE_OWORD_2(srm_cfg_reg_ker,\n\t\t\t     FRF_AZ_SRM_INIT_EN, 1,\n\t\t\t     FRF_AZ_SRM_NB_SZ, 0);\n\tef4_writeo(efx, &srm_cfg_reg_ker, FR_AZ_SRM_CFG);\n\n\t \n\tcount = 0;\n\tdo {\n\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t  \"waiting for SRAM reset (attempt %d)...\\n\", count);\n\n\t\t \n\t\tschedule_timeout_uninterruptible(HZ / 50);\n\n\t\t \n\t\tef4_reado(efx, &srm_cfg_reg_ker, FR_AZ_SRM_CFG);\n\t\tif (!EF4_OWORD_FIELD(srm_cfg_reg_ker, FRF_AZ_SRM_INIT_EN)) {\n\t\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t\t  \"SRAM reset complete\\n\");\n\n\t\t\treturn 0;\n\t\t}\n\t} while (++count < 20);\t \n\n\tnetif_err(efx, hw, efx->net_dev, \"timed out waiting for SRAM reset\\n\");\n\treturn -ETIMEDOUT;\n}\n\nstatic void falcon_spi_device_init(struct ef4_nic *efx,\n\t\t\t\t  struct falcon_spi_device *spi_device,\n\t\t\t\t  unsigned int device_id, u32 device_type)\n{\n\tif (device_type != 0) {\n\t\tspi_device->device_id = device_id;\n\t\tspi_device->size =\n\t\t\t1 << SPI_DEV_TYPE_FIELD(device_type, SPI_DEV_TYPE_SIZE);\n\t\tspi_device->addr_len =\n\t\t\tSPI_DEV_TYPE_FIELD(device_type, SPI_DEV_TYPE_ADDR_LEN);\n\t\tspi_device->munge_address = (spi_device->size == 1 << 9 &&\n\t\t\t\t\t     spi_device->addr_len == 1);\n\t\tspi_device->erase_command =\n\t\t\tSPI_DEV_TYPE_FIELD(device_type, SPI_DEV_TYPE_ERASE_CMD);\n\t\tspi_device->erase_size =\n\t\t\t1 << SPI_DEV_TYPE_FIELD(device_type,\n\t\t\t\t\t\tSPI_DEV_TYPE_ERASE_SIZE);\n\t\tspi_device->block_size =\n\t\t\t1 << SPI_DEV_TYPE_FIELD(device_type,\n\t\t\t\t\t\tSPI_DEV_TYPE_BLOCK_SIZE);\n\t} else {\n\t\tspi_device->size = 0;\n\t}\n}\n\n \nstatic int falcon_probe_nvconfig(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tstruct falcon_nvconfig *nvconfig;\n\tint rc;\n\n\tnvconfig = kmalloc(sizeof(*nvconfig), GFP_KERNEL);\n\tif (!nvconfig)\n\t\treturn -ENOMEM;\n\n\trc = falcon_read_nvram(efx, nvconfig);\n\tif (rc)\n\t\tgoto out;\n\n\tefx->phy_type = nvconfig->board_v2.port0_phy_type;\n\tefx->mdio.prtad = nvconfig->board_v2.port0_phy_addr;\n\n\tif (le16_to_cpu(nvconfig->board_struct_ver) >= 3) {\n\t\tfalcon_spi_device_init(\n\t\t\tefx, &nic_data->spi_flash, FFE_AB_SPI_DEVICE_FLASH,\n\t\t\tle32_to_cpu(nvconfig->board_v3\n\t\t\t\t    .spi_device_type[FFE_AB_SPI_DEVICE_FLASH]));\n\t\tfalcon_spi_device_init(\n\t\t\tefx, &nic_data->spi_eeprom, FFE_AB_SPI_DEVICE_EEPROM,\n\t\t\tle32_to_cpu(nvconfig->board_v3\n\t\t\t\t    .spi_device_type[FFE_AB_SPI_DEVICE_EEPROM]));\n\t}\n\n\t \n\tether_addr_copy(efx->net_dev->perm_addr, nvconfig->mac_address[0]);\n\n\tnetif_dbg(efx, probe, efx->net_dev, \"PHY is %d phy_id %d\\n\",\n\t\t  efx->phy_type, efx->mdio.prtad);\n\n\trc = falcon_probe_board(efx,\n\t\t\t\tle16_to_cpu(nvconfig->board_v2.board_revision));\nout:\n\tkfree(nvconfig);\n\treturn rc;\n}\n\nstatic int falcon_dimension_resources(struct ef4_nic *efx)\n{\n\tefx->rx_dc_base = 0x20000;\n\tefx->tx_dc_base = 0x26000;\n\treturn 0;\n}\n\n \nstatic void falcon_probe_spi_devices(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tef4_oword_t nic_stat, gpio_ctl, ee_vpd_cfg;\n\tint boot_dev;\n\n\tef4_reado(efx, &gpio_ctl, FR_AB_GPIO_CTL);\n\tef4_reado(efx, &nic_stat, FR_AB_NIC_STAT);\n\tef4_reado(efx, &ee_vpd_cfg, FR_AB_EE_VPD_CFG0);\n\n\tif (EF4_OWORD_FIELD(gpio_ctl, FRF_AB_GPIO3_PWRUP_VALUE)) {\n\t\tboot_dev = (EF4_OWORD_FIELD(nic_stat, FRF_AB_SF_PRST) ?\n\t\t\t    FFE_AB_SPI_DEVICE_FLASH : FFE_AB_SPI_DEVICE_EEPROM);\n\t\tnetif_dbg(efx, probe, efx->net_dev, \"Booted from %s\\n\",\n\t\t\t  boot_dev == FFE_AB_SPI_DEVICE_FLASH ?\n\t\t\t  \"flash\" : \"EEPROM\");\n\t} else {\n\t\t \n\t\tboot_dev = -1;\n\t\tnetif_dbg(efx, probe, efx->net_dev,\n\t\t\t  \"Booted from internal ASIC settings;\"\n\t\t\t  \" setting SPI config\\n\");\n\t\tEF4_POPULATE_OWORD_3(ee_vpd_cfg, FRF_AB_EE_VPD_EN, 0,\n\t\t\t\t      \n\t\t\t\t     FRF_AB_EE_SF_CLOCK_DIV, 7,\n\t\t\t\t      \n\t\t\t\t     FRF_AB_EE_EE_CLOCK_DIV, 63);\n\t\tef4_writeo(efx, &ee_vpd_cfg, FR_AB_EE_VPD_CFG0);\n\t}\n\n\tmutex_init(&nic_data->spi_lock);\n\n\tif (boot_dev == FFE_AB_SPI_DEVICE_FLASH)\n\t\tfalcon_spi_device_init(efx, &nic_data->spi_flash,\n\t\t\t\t       FFE_AB_SPI_DEVICE_FLASH,\n\t\t\t\t       default_flash_type);\n\tif (boot_dev == FFE_AB_SPI_DEVICE_EEPROM)\n\t\tfalcon_spi_device_init(efx, &nic_data->spi_eeprom,\n\t\t\t\t       FFE_AB_SPI_DEVICE_EEPROM,\n\t\t\t\t       large_eeprom_type);\n}\n\nstatic unsigned int falcon_a1_mem_map_size(struct ef4_nic *efx)\n{\n\treturn 0x20000;\n}\n\nstatic unsigned int falcon_b0_mem_map_size(struct ef4_nic *efx)\n{\n\t \n\treturn FR_BZ_RX_INDIRECTION_TBL +\n\t\tFR_BZ_RX_INDIRECTION_TBL_STEP * FR_BZ_RX_INDIRECTION_TBL_ROWS;\n}\n\nstatic int falcon_probe_nic(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data;\n\tstruct falcon_board *board;\n\tint rc;\n\n\tefx->primary = efx;  \n\n\t \n\tnic_data = kzalloc(sizeof(*nic_data), GFP_KERNEL);\n\tif (!nic_data)\n\t\treturn -ENOMEM;\n\tefx->nic_data = nic_data;\n\tnic_data->efx = efx;\n\n\trc = -ENODEV;\n\n\tif (ef4_farch_fpga_ver(efx) != 0) {\n\t\tnetif_err(efx, probe, efx->net_dev,\n\t\t\t  \"Falcon FPGA not supported\\n\");\n\t\tgoto fail1;\n\t}\n\n\tif (ef4_nic_rev(efx) <= EF4_REV_FALCON_A1) {\n\t\tef4_oword_t nic_stat;\n\t\tstruct pci_dev *dev;\n\t\tu8 pci_rev = efx->pci_dev->revision;\n\n\t\tif ((pci_rev == 0xff) || (pci_rev == 0)) {\n\t\t\tnetif_err(efx, probe, efx->net_dev,\n\t\t\t\t  \"Falcon rev A0 not supported\\n\");\n\t\t\tgoto fail1;\n\t\t}\n\t\tef4_reado(efx, &nic_stat, FR_AB_NIC_STAT);\n\t\tif (EF4_OWORD_FIELD(nic_stat, FRF_AB_STRAP_10G) == 0) {\n\t\t\tnetif_err(efx, probe, efx->net_dev,\n\t\t\t\t  \"Falcon rev A1 1G not supported\\n\");\n\t\t\tgoto fail1;\n\t\t}\n\t\tif (EF4_OWORD_FIELD(nic_stat, FRF_AA_STRAP_PCIE) == 0) {\n\t\t\tnetif_err(efx, probe, efx->net_dev,\n\t\t\t\t  \"Falcon rev A1 PCI-X not supported\\n\");\n\t\t\tgoto fail1;\n\t\t}\n\n\t\tdev = pci_dev_get(efx->pci_dev);\n\t\twhile ((dev = pci_get_device(PCI_VENDOR_ID_SOLARFLARE,\n\t\t\t\t\t     PCI_DEVICE_ID_SOLARFLARE_SFC4000A_1,\n\t\t\t\t\t     dev))) {\n\t\t\tif (dev->bus == efx->pci_dev->bus &&\n\t\t\t    dev->devfn == efx->pci_dev->devfn + 1) {\n\t\t\t\tnic_data->pci_dev2 = dev;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!nic_data->pci_dev2) {\n\t\t\tnetif_err(efx, probe, efx->net_dev,\n\t\t\t\t  \"failed to find secondary function\\n\");\n\t\t\trc = -ENODEV;\n\t\t\tgoto fail2;\n\t\t}\n\t}\n\n\t \n\trc = __falcon_reset_hw(efx, RESET_TYPE_ALL);\n\tif (rc) {\n\t\tnetif_err(efx, probe, efx->net_dev, \"failed to reset NIC\\n\");\n\t\tgoto fail3;\n\t}\n\n\t \n\trc = ef4_nic_alloc_buffer(efx, &efx->irq_status, sizeof(ef4_oword_t),\n\t\t\t\t  GFP_KERNEL);\n\tif (rc)\n\t\tgoto fail4;\n\tBUG_ON(efx->irq_status.dma_addr & 0x0f);\n\n\tnetif_dbg(efx, probe, efx->net_dev,\n\t\t  \"INT_KER at %llx (virt %p phys %llx)\\n\",\n\t\t  (u64)efx->irq_status.dma_addr,\n\t\t  efx->irq_status.addr,\n\t\t  (u64)virt_to_phys(efx->irq_status.addr));\n\n\tfalcon_probe_spi_devices(efx);\n\n\t \n\trc = falcon_probe_nvconfig(efx);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tnetif_err(efx, probe, efx->net_dev, \"NVRAM is invalid\\n\");\n\t\tgoto fail5;\n\t}\n\n\tefx->max_channels = (ef4_nic_rev(efx) <= EF4_REV_FALCON_A1 ? 4 :\n\t\t\t     EF4_MAX_CHANNELS);\n\tefx->max_tx_channels = efx->max_channels;\n\tefx->timer_quantum_ns = 4968;  \n\tefx->timer_max_ns = efx->type->timer_period_max *\n\t\t\t    efx->timer_quantum_ns;\n\n\t \n\tboard = falcon_board(efx);\n\tboard->i2c_adap.owner = THIS_MODULE;\n\tboard->i2c_data = falcon_i2c_bit_operations;\n\tboard->i2c_data.data = efx;\n\tboard->i2c_adap.algo_data = &board->i2c_data;\n\tboard->i2c_adap.dev.parent = &efx->pci_dev->dev;\n\tstrscpy(board->i2c_adap.name, \"SFC4000 GPIO\",\n\t\tsizeof(board->i2c_adap.name));\n\trc = i2c_bit_add_bus(&board->i2c_adap);\n\tif (rc)\n\t\tgoto fail5;\n\n\trc = falcon_board(efx)->type->init(efx);\n\tif (rc) {\n\t\tnetif_err(efx, probe, efx->net_dev,\n\t\t\t  \"failed to initialise board\\n\");\n\t\tgoto fail6;\n\t}\n\n\tnic_data->stats_disable_count = 1;\n\ttimer_setup(&nic_data->stats_timer, falcon_stats_timer_func, 0);\n\n\treturn 0;\n\n fail6:\n\ti2c_del_adapter(&board->i2c_adap);\n\tmemset(&board->i2c_adap, 0, sizeof(board->i2c_adap));\n fail5:\n\tef4_nic_free_buffer(efx, &efx->irq_status);\n fail4:\n fail3:\n\tif (nic_data->pci_dev2) {\n\t\tpci_dev_put(nic_data->pci_dev2);\n\t\tnic_data->pci_dev2 = NULL;\n\t}\n fail2:\n fail1:\n\tkfree(efx->nic_data);\n\treturn rc;\n}\n\nstatic void falcon_init_rx_cfg(struct ef4_nic *efx)\n{\n\t \n\tconst unsigned ctrl_xon_thr = 20;\n\tconst unsigned ctrl_xoff_thr = 25;\n\tef4_oword_t reg;\n\n\tef4_reado(efx, &reg, FR_AZ_RX_CFG);\n\tif (ef4_nic_rev(efx) <= EF4_REV_FALCON_A1) {\n\t\t \n\t\tEF4_SET_OWORD_FIELD(reg, FRF_AA_RX_DESC_PUSH_EN, 0);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_AA_RX_USR_BUF_SIZE,\n\t\t\t\t    (3 * 4096) >> 5);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_AA_RX_XON_MAC_TH, 512 >> 8);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_AA_RX_XOFF_MAC_TH, 2048 >> 8);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_AA_RX_XON_TX_TH, ctrl_xon_thr);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_AA_RX_XOFF_TX_TH, ctrl_xoff_thr);\n\t} else {\n\t\t \n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_DESC_PUSH_EN, 0);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_USR_BUF_SIZE,\n\t\t\t\t    EF4_RX_USR_BUF_SIZE >> 5);\n\t\t \n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_XON_MAC_TH, 27648 >> 8);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_XOFF_MAC_TH, 54272 >> 8);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_XON_TX_TH, ctrl_xon_thr);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_XOFF_TX_TH, ctrl_xoff_thr);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_INGR_EN, 1);\n\n\t\t \n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_HASH_INSRT_HDR, 1);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_HASH_ALG, 1);\n\t\tEF4_SET_OWORD_FIELD(reg, FRF_BZ_RX_IP_HASH, 1);\n\t}\n\t \n\tEF4_SET_OWORD_FIELD(reg, FRF_AZ_RX_XOFF_MAC_EN, 1);\n\tef4_writeo(efx, &reg, FR_AZ_RX_CFG);\n}\n\n \nstatic int falcon_init_nic(struct ef4_nic *efx)\n{\n\tef4_oword_t temp;\n\tint rc;\n\n\t \n\tef4_reado(efx, &temp, FR_AB_NIC_STAT);\n\tEF4_SET_OWORD_FIELD(temp, FRF_AB_ONCHIP_SRAM, 1);\n\tef4_writeo(efx, &temp, FR_AB_NIC_STAT);\n\n\trc = falcon_reset_sram(efx);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (EF4_WORKAROUND_5129(efx)) {\n\t\tef4_reado(efx, &temp, FR_AZ_CSR_SPARE);\n\t\tEF4_SET_OWORD_FIELD(temp, FRF_AB_MEM_PERR_EN_TX_DATA, 0);\n\t\tef4_writeo(efx, &temp, FR_AZ_CSR_SPARE);\n\t}\n\n\tif (EF4_WORKAROUND_7244(efx)) {\n\t\tef4_reado(efx, &temp, FR_BZ_RX_FILTER_CTL);\n\t\tEF4_SET_OWORD_FIELD(temp, FRF_BZ_UDP_FULL_SRCH_LIMIT, 8);\n\t\tEF4_SET_OWORD_FIELD(temp, FRF_BZ_UDP_WILD_SRCH_LIMIT, 8);\n\t\tEF4_SET_OWORD_FIELD(temp, FRF_BZ_TCP_FULL_SRCH_LIMIT, 8);\n\t\tEF4_SET_OWORD_FIELD(temp, FRF_BZ_TCP_WILD_SRCH_LIMIT, 8);\n\t\tef4_writeo(efx, &temp, FR_BZ_RX_FILTER_CTL);\n\t}\n\n\t \n\t \n\tef4_reado(efx, &temp, FR_AA_RX_SELF_RST);\n\tEF4_SET_OWORD_FIELD(temp, FRF_AA_RX_NODESC_WAIT_DIS, 1);\n\tEF4_SET_OWORD_FIELD(temp, FRF_AA_RX_SELF_RST_EN, 1);\n\tif (EF4_WORKAROUND_5583(efx))\n\t\tEF4_SET_OWORD_FIELD(temp, FRF_AA_RX_ISCSI_DIS, 1);\n\tef4_writeo(efx, &temp, FR_AA_RX_SELF_RST);\n\n\t \n\tef4_reado(efx, &temp, FR_AZ_TX_CFG);\n\tEF4_SET_OWORD_FIELD(temp, FRF_AZ_TX_NO_EOP_DISC_EN, 0);\n\tef4_writeo(efx, &temp, FR_AZ_TX_CFG);\n\n\tfalcon_init_rx_cfg(efx);\n\n\tif (ef4_nic_rev(efx) >= EF4_REV_FALCON_B0) {\n\t\tfalcon_b0_rx_push_rss_config(efx, false, efx->rx_indir_table);\n\n\t\t \n\t\tEF4_POPULATE_OWORD_1(temp, FRF_BZ_FLS_EVQ_ID, 0);\n\t\tef4_writeo(efx, &temp, FR_BZ_DP_CTRL);\n\t}\n\n\tef4_farch_init_common(efx);\n\n\treturn 0;\n}\n\nstatic void falcon_remove_nic(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tstruct falcon_board *board = falcon_board(efx);\n\n\tboard->type->fini(efx);\n\n\t \n\ti2c_del_adapter(&board->i2c_adap);\n\tmemset(&board->i2c_adap, 0, sizeof(board->i2c_adap));\n\n\tef4_nic_free_buffer(efx, &efx->irq_status);\n\n\t__falcon_reset_hw(efx, RESET_TYPE_ALL);\n\n\t \n\tif (nic_data->pci_dev2) {\n\t\tpci_dev_put(nic_data->pci_dev2);\n\t\tnic_data->pci_dev2 = NULL;\n\t}\n\n\t \n\tkfree(efx->nic_data);\n\tefx->nic_data = NULL;\n}\n\nstatic size_t falcon_describe_nic_stats(struct ef4_nic *efx, u8 *names)\n{\n\treturn ef4_nic_describe_stats(falcon_stat_desc, FALCON_STAT_COUNT,\n\t\t\t\t      falcon_stat_mask, names);\n}\n\nstatic size_t falcon_update_nic_stats(struct ef4_nic *efx, u64 *full_stats,\n\t\t\t\t      struct rtnl_link_stats64 *core_stats)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tu64 *stats = nic_data->stats;\n\tef4_oword_t cnt;\n\n\tif (!nic_data->stats_disable_count) {\n\t\tef4_reado(efx, &cnt, FR_AZ_RX_NODESC_DROP);\n\t\tstats[FALCON_STAT_rx_nodesc_drop_cnt] +=\n\t\t\tEF4_OWORD_FIELD(cnt, FRF_AB_RX_NODESC_DROP_CNT);\n\n\t\tif (nic_data->stats_pending &&\n\t\t    FALCON_XMAC_STATS_DMA_FLAG(efx)) {\n\t\t\tnic_data->stats_pending = false;\n\t\t\trmb();  \n\t\t\tef4_nic_update_stats(\n\t\t\t\tfalcon_stat_desc, FALCON_STAT_COUNT,\n\t\t\t\tfalcon_stat_mask,\n\t\t\t\tstats, efx->stats_buffer.addr, true);\n\t\t}\n\n\t\t \n\t\tef4_update_diff_stat(&stats[FALCON_STAT_rx_bad_bytes],\n\t\t\t\t     stats[FALCON_STAT_rx_bytes] -\n\t\t\t\t     stats[FALCON_STAT_rx_good_bytes] -\n\t\t\t\t     stats[FALCON_STAT_rx_control] * 64);\n\t\tef4_update_sw_stats(efx, stats);\n\t}\n\n\tif (full_stats)\n\t\tmemcpy(full_stats, stats, sizeof(u64) * FALCON_STAT_COUNT);\n\n\tif (core_stats) {\n\t\tcore_stats->rx_packets = stats[FALCON_STAT_rx_packets];\n\t\tcore_stats->tx_packets = stats[FALCON_STAT_tx_packets];\n\t\tcore_stats->rx_bytes = stats[FALCON_STAT_rx_bytes];\n\t\tcore_stats->tx_bytes = stats[FALCON_STAT_tx_bytes];\n\t\tcore_stats->rx_dropped = stats[FALCON_STAT_rx_nodesc_drop_cnt] +\n\t\t\t\t\t stats[GENERIC_STAT_rx_nodesc_trunc] +\n\t\t\t\t\t stats[GENERIC_STAT_rx_noskb_drops];\n\t\tcore_stats->multicast = stats[FALCON_STAT_rx_multicast];\n\t\tcore_stats->rx_length_errors =\n\t\t\tstats[FALCON_STAT_rx_gtjumbo] +\n\t\t\tstats[FALCON_STAT_rx_length_error];\n\t\tcore_stats->rx_crc_errors = stats[FALCON_STAT_rx_bad];\n\t\tcore_stats->rx_frame_errors = stats[FALCON_STAT_rx_align_error];\n\t\tcore_stats->rx_fifo_errors = stats[FALCON_STAT_rx_overflow];\n\n\t\tcore_stats->rx_errors = (core_stats->rx_length_errors +\n\t\t\t\t\t core_stats->rx_crc_errors +\n\t\t\t\t\t core_stats->rx_frame_errors +\n\t\t\t\t\t stats[FALCON_STAT_rx_symbol_error]);\n\t}\n\n\treturn FALCON_STAT_COUNT;\n}\n\nvoid falcon_start_nic_stats(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\n\tspin_lock_bh(&efx->stats_lock);\n\tif (--nic_data->stats_disable_count == 0)\n\t\tfalcon_stats_request(efx);\n\tspin_unlock_bh(&efx->stats_lock);\n}\n\n \nstatic void falcon_pull_nic_stats(struct ef4_nic *efx)\n{\n\tmsleep(10);\n}\n\nvoid falcon_stop_nic_stats(struct ef4_nic *efx)\n{\n\tstruct falcon_nic_data *nic_data = efx->nic_data;\n\tint i;\n\n\tmight_sleep();\n\n\tspin_lock_bh(&efx->stats_lock);\n\t++nic_data->stats_disable_count;\n\tspin_unlock_bh(&efx->stats_lock);\n\n\tdel_timer_sync(&nic_data->stats_timer);\n\n\t \n\tfor (i = 0; i < 4 && nic_data->stats_pending; i++) {\n\t\tif (FALCON_XMAC_STATS_DMA_FLAG(efx))\n\t\t\tbreak;\n\t\tmsleep(1);\n\t}\n\n\tspin_lock_bh(&efx->stats_lock);\n\tfalcon_stats_complete(efx);\n\tspin_unlock_bh(&efx->stats_lock);\n}\n\nstatic void falcon_set_id_led(struct ef4_nic *efx, enum ef4_led_mode mode)\n{\n\tfalcon_board(efx)->type->set_id_led(efx, mode);\n}\n\n \n\nstatic void falcon_get_wol(struct ef4_nic *efx, struct ethtool_wolinfo *wol)\n{\n\twol->supported = 0;\n\twol->wolopts = 0;\n\tmemset(&wol->sopass, 0, sizeof(wol->sopass));\n}\n\nstatic int falcon_set_wol(struct ef4_nic *efx, u32 type)\n{\n\tif (type != 0)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\n \n\nconst struct ef4_nic_type falcon_a1_nic_type = {\n\t.mem_bar = EF4_MEM_BAR,\n\t.mem_map_size = falcon_a1_mem_map_size,\n\t.probe = falcon_probe_nic,\n\t.remove = falcon_remove_nic,\n\t.init = falcon_init_nic,\n\t.dimension_resources = falcon_dimension_resources,\n\t.fini = falcon_irq_ack_a1,\n\t.monitor = falcon_monitor,\n\t.map_reset_reason = falcon_map_reset_reason,\n\t.map_reset_flags = falcon_map_reset_flags,\n\t.reset = falcon_reset_hw,\n\t.probe_port = falcon_probe_port,\n\t.remove_port = falcon_remove_port,\n\t.handle_global_event = falcon_handle_global_event,\n\t.fini_dmaq = ef4_farch_fini_dmaq,\n\t.prepare_flush = falcon_prepare_flush,\n\t.finish_flush = ef4_port_dummy_op_void,\n\t.prepare_flr = ef4_port_dummy_op_void,\n\t.finish_flr = ef4_farch_finish_flr,\n\t.describe_stats = falcon_describe_nic_stats,\n\t.update_stats = falcon_update_nic_stats,\n\t.start_stats = falcon_start_nic_stats,\n\t.pull_stats = falcon_pull_nic_stats,\n\t.stop_stats = falcon_stop_nic_stats,\n\t.set_id_led = falcon_set_id_led,\n\t.push_irq_moderation = falcon_push_irq_moderation,\n\t.reconfigure_port = falcon_reconfigure_port,\n\t.prepare_enable_fc_tx = falcon_a1_prepare_enable_fc_tx,\n\t.reconfigure_mac = falcon_reconfigure_xmac,\n\t.check_mac_fault = falcon_xmac_check_fault,\n\t.get_wol = falcon_get_wol,\n\t.set_wol = falcon_set_wol,\n\t.resume_wol = ef4_port_dummy_op_void,\n\t.test_nvram = falcon_test_nvram,\n\t.irq_enable_master = ef4_farch_irq_enable_master,\n\t.irq_test_generate = ef4_farch_irq_test_generate,\n\t.irq_disable_non_ev = ef4_farch_irq_disable_master,\n\t.irq_handle_msi = ef4_farch_msi_interrupt,\n\t.irq_handle_legacy = falcon_legacy_interrupt_a1,\n\t.tx_probe = ef4_farch_tx_probe,\n\t.tx_init = ef4_farch_tx_init,\n\t.tx_remove = ef4_farch_tx_remove,\n\t.tx_write = ef4_farch_tx_write,\n\t.tx_limit_len = ef4_farch_tx_limit_len,\n\t.rx_push_rss_config = dummy_rx_push_rss_config,\n\t.rx_probe = ef4_farch_rx_probe,\n\t.rx_init = ef4_farch_rx_init,\n\t.rx_remove = ef4_farch_rx_remove,\n\t.rx_write = ef4_farch_rx_write,\n\t.rx_defer_refill = ef4_farch_rx_defer_refill,\n\t.ev_probe = ef4_farch_ev_probe,\n\t.ev_init = ef4_farch_ev_init,\n\t.ev_fini = ef4_farch_ev_fini,\n\t.ev_remove = ef4_farch_ev_remove,\n\t.ev_process = ef4_farch_ev_process,\n\t.ev_read_ack = ef4_farch_ev_read_ack,\n\t.ev_test_generate = ef4_farch_ev_test_generate,\n\n\t \n\t.filter_table_probe = ef4_farch_filter_table_probe,\n\t.filter_table_restore = ef4_farch_filter_table_restore,\n\t.filter_table_remove = ef4_farch_filter_table_remove,\n\t.filter_insert = ef4_farch_filter_insert,\n\t.filter_remove_safe = ef4_farch_filter_remove_safe,\n\t.filter_get_safe = ef4_farch_filter_get_safe,\n\t.filter_clear_rx = ef4_farch_filter_clear_rx,\n\t.filter_count_rx_used = ef4_farch_filter_count_rx_used,\n\t.filter_get_rx_id_limit = ef4_farch_filter_get_rx_id_limit,\n\t.filter_get_rx_ids = ef4_farch_filter_get_rx_ids,\n\n#ifdef CONFIG_SFC_FALCON_MTD\n\t.mtd_probe = falcon_mtd_probe,\n\t.mtd_rename = falcon_mtd_rename,\n\t.mtd_read = falcon_mtd_read,\n\t.mtd_erase = falcon_mtd_erase,\n\t.mtd_write = falcon_mtd_write,\n\t.mtd_sync = falcon_mtd_sync,\n#endif\n\n\t.revision = EF4_REV_FALCON_A1,\n\t.txd_ptr_tbl_base = FR_AA_TX_DESC_PTR_TBL_KER,\n\t.rxd_ptr_tbl_base = FR_AA_RX_DESC_PTR_TBL_KER,\n\t.buf_tbl_base = FR_AA_BUF_FULL_TBL_KER,\n\t.evq_ptr_tbl_base = FR_AA_EVQ_PTR_TBL_KER,\n\t.evq_rptr_tbl_base = FR_AA_EVQ_RPTR_KER,\n\t.max_dma_mask = DMA_BIT_MASK(FSF_AZ_TX_KER_BUF_ADDR_WIDTH),\n\t.rx_buffer_padding = 0x24,\n\t.can_rx_scatter = false,\n\t.max_interrupt_mode = EF4_INT_MODE_MSI,\n\t.timer_period_max =  1 << FRF_AB_TC_TIMER_VAL_WIDTH,\n\t.offload_features = NETIF_F_IP_CSUM,\n};\n\nconst struct ef4_nic_type falcon_b0_nic_type = {\n\t.mem_bar = EF4_MEM_BAR,\n\t.mem_map_size = falcon_b0_mem_map_size,\n\t.probe = falcon_probe_nic,\n\t.remove = falcon_remove_nic,\n\t.init = falcon_init_nic,\n\t.dimension_resources = falcon_dimension_resources,\n\t.fini = ef4_port_dummy_op_void,\n\t.monitor = falcon_monitor,\n\t.map_reset_reason = falcon_map_reset_reason,\n\t.map_reset_flags = falcon_map_reset_flags,\n\t.reset = falcon_reset_hw,\n\t.probe_port = falcon_probe_port,\n\t.remove_port = falcon_remove_port,\n\t.handle_global_event = falcon_handle_global_event,\n\t.fini_dmaq = ef4_farch_fini_dmaq,\n\t.prepare_flush = falcon_prepare_flush,\n\t.finish_flush = ef4_port_dummy_op_void,\n\t.prepare_flr = ef4_port_dummy_op_void,\n\t.finish_flr = ef4_farch_finish_flr,\n\t.describe_stats = falcon_describe_nic_stats,\n\t.update_stats = falcon_update_nic_stats,\n\t.start_stats = falcon_start_nic_stats,\n\t.pull_stats = falcon_pull_nic_stats,\n\t.stop_stats = falcon_stop_nic_stats,\n\t.set_id_led = falcon_set_id_led,\n\t.push_irq_moderation = falcon_push_irq_moderation,\n\t.reconfigure_port = falcon_reconfigure_port,\n\t.prepare_enable_fc_tx = falcon_b0_prepare_enable_fc_tx,\n\t.reconfigure_mac = falcon_reconfigure_xmac,\n\t.check_mac_fault = falcon_xmac_check_fault,\n\t.get_wol = falcon_get_wol,\n\t.set_wol = falcon_set_wol,\n\t.resume_wol = ef4_port_dummy_op_void,\n\t.test_chip = falcon_b0_test_chip,\n\t.test_nvram = falcon_test_nvram,\n\t.irq_enable_master = ef4_farch_irq_enable_master,\n\t.irq_test_generate = ef4_farch_irq_test_generate,\n\t.irq_disable_non_ev = ef4_farch_irq_disable_master,\n\t.irq_handle_msi = ef4_farch_msi_interrupt,\n\t.irq_handle_legacy = ef4_farch_legacy_interrupt,\n\t.tx_probe = ef4_farch_tx_probe,\n\t.tx_init = ef4_farch_tx_init,\n\t.tx_remove = ef4_farch_tx_remove,\n\t.tx_write = ef4_farch_tx_write,\n\t.tx_limit_len = ef4_farch_tx_limit_len,\n\t.rx_push_rss_config = falcon_b0_rx_push_rss_config,\n\t.rx_probe = ef4_farch_rx_probe,\n\t.rx_init = ef4_farch_rx_init,\n\t.rx_remove = ef4_farch_rx_remove,\n\t.rx_write = ef4_farch_rx_write,\n\t.rx_defer_refill = ef4_farch_rx_defer_refill,\n\t.ev_probe = ef4_farch_ev_probe,\n\t.ev_init = ef4_farch_ev_init,\n\t.ev_fini = ef4_farch_ev_fini,\n\t.ev_remove = ef4_farch_ev_remove,\n\t.ev_process = ef4_farch_ev_process,\n\t.ev_read_ack = ef4_farch_ev_read_ack,\n\t.ev_test_generate = ef4_farch_ev_test_generate,\n\t.filter_table_probe = ef4_farch_filter_table_probe,\n\t.filter_table_restore = ef4_farch_filter_table_restore,\n\t.filter_table_remove = ef4_farch_filter_table_remove,\n\t.filter_update_rx_scatter = ef4_farch_filter_update_rx_scatter,\n\t.filter_insert = ef4_farch_filter_insert,\n\t.filter_remove_safe = ef4_farch_filter_remove_safe,\n\t.filter_get_safe = ef4_farch_filter_get_safe,\n\t.filter_clear_rx = ef4_farch_filter_clear_rx,\n\t.filter_count_rx_used = ef4_farch_filter_count_rx_used,\n\t.filter_get_rx_id_limit = ef4_farch_filter_get_rx_id_limit,\n\t.filter_get_rx_ids = ef4_farch_filter_get_rx_ids,\n#ifdef CONFIG_RFS_ACCEL\n\t.filter_rfs_insert = ef4_farch_filter_rfs_insert,\n\t.filter_rfs_expire_one = ef4_farch_filter_rfs_expire_one,\n#endif\n#ifdef CONFIG_SFC_FALCON_MTD\n\t.mtd_probe = falcon_mtd_probe,\n\t.mtd_rename = falcon_mtd_rename,\n\t.mtd_read = falcon_mtd_read,\n\t.mtd_erase = falcon_mtd_erase,\n\t.mtd_write = falcon_mtd_write,\n\t.mtd_sync = falcon_mtd_sync,\n#endif\n\n\t.revision = EF4_REV_FALCON_B0,\n\t.txd_ptr_tbl_base = FR_BZ_TX_DESC_PTR_TBL,\n\t.rxd_ptr_tbl_base = FR_BZ_RX_DESC_PTR_TBL,\n\t.buf_tbl_base = FR_BZ_BUF_FULL_TBL,\n\t.evq_ptr_tbl_base = FR_BZ_EVQ_PTR_TBL,\n\t.evq_rptr_tbl_base = FR_BZ_EVQ_RPTR,\n\t.max_dma_mask = DMA_BIT_MASK(FSF_AZ_TX_KER_BUF_ADDR_WIDTH),\n\t.rx_prefix_size = FS_BZ_RX_PREFIX_SIZE,\n\t.rx_hash_offset = FS_BZ_RX_PREFIX_HASH_OFST,\n\t.rx_buffer_padding = 0,\n\t.can_rx_scatter = true,\n\t.max_interrupt_mode = EF4_INT_MODE_MSIX,\n\t.timer_period_max =  1 << FRF_AB_TC_TIMER_VAL_WIDTH,\n\t.offload_features = NETIF_F_IP_CSUM | NETIF_F_RXHASH | NETIF_F_NTUPLE,\n\t.max_rx_ip_filters = FR_BZ_RX_FILTER_TBL0_ROWS,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}