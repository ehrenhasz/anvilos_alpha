{
  "module_name": "nic.c",
  "hash_id": "2c237b31013ae4fdb702ef94ad3451646230032d6c29f9b309345efac05076aa",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sfc/nic.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/module.h>\n#include <linux/seq_file.h>\n#include <linux/cpu_rmap.h>\n#include \"net_driver.h\"\n#include \"bitfield.h\"\n#include \"efx.h\"\n#include \"nic.h\"\n#include \"ef10_regs.h\"\n#include \"io.h\"\n#include \"workarounds.h\"\n#include \"mcdi_pcol.h\"\n\n \n\nint efx_nic_alloc_buffer(struct efx_nic *efx, struct efx_buffer *buffer,\n\t\t\t unsigned int len, gfp_t gfp_flags)\n{\n\tbuffer->addr = dma_alloc_coherent(&efx->pci_dev->dev, len,\n\t\t\t\t\t  &buffer->dma_addr, gfp_flags);\n\tif (!buffer->addr)\n\t\treturn -ENOMEM;\n\tbuffer->len = len;\n\treturn 0;\n}\n\nvoid efx_nic_free_buffer(struct efx_nic *efx, struct efx_buffer *buffer)\n{\n\tif (buffer->addr) {\n\t\tdma_free_coherent(&efx->pci_dev->dev, buffer->len,\n\t\t\t\t  buffer->addr, buffer->dma_addr);\n\t\tbuffer->addr = NULL;\n\t}\n}\n\n \nbool efx_nic_event_present(struct efx_channel *channel)\n{\n\treturn efx_event_present(efx_event(channel, channel->eventq_read_ptr));\n}\n\nvoid efx_nic_event_test_start(struct efx_channel *channel)\n{\n\tchannel->event_test_cpu = -1;\n\tsmp_wmb();\n\tchannel->efx->type->ev_test_generate(channel);\n}\n\nint efx_nic_irq_test_start(struct efx_nic *efx)\n{\n\tefx->last_irq_cpu = -1;\n\tsmp_wmb();\n\treturn efx->type->irq_test_generate(efx);\n}\n\n \nint efx_nic_init_interrupt(struct efx_nic *efx)\n{\n\tstruct efx_channel *channel;\n\tunsigned int n_irqs;\n\tint rc;\n\n\tif (!EFX_INT_MODE_USE_MSI(efx)) {\n\t\trc = request_irq(efx->legacy_irq,\n\t\t\t\t efx->type->irq_handle_legacy, IRQF_SHARED,\n\t\t\t\t efx->name, efx);\n\t\tif (rc) {\n\t\t\tnetif_err(efx, drv, efx->net_dev,\n\t\t\t\t  \"failed to hook legacy IRQ %d\\n\",\n\t\t\t\t  efx->pci_dev->irq);\n\t\t\tgoto fail1;\n\t\t}\n\t\tefx->irqs_hooked = true;\n\t\treturn 0;\n\t}\n\n#ifdef CONFIG_RFS_ACCEL\n\tif (efx->interrupt_mode == EFX_INT_MODE_MSIX) {\n\t\tefx->net_dev->rx_cpu_rmap =\n\t\t\talloc_irq_cpu_rmap(efx->n_rx_channels);\n\t\tif (!efx->net_dev->rx_cpu_rmap) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto fail1;\n\t\t}\n\t}\n#endif\n\n\t \n\tn_irqs = 0;\n\tefx_for_each_channel(channel, efx) {\n\t\trc = request_irq(channel->irq, efx->type->irq_handle_msi,\n\t\t\t\t IRQF_PROBE_SHARED,  \n\t\t\t\t efx->msi_context[channel->channel].name,\n\t\t\t\t &efx->msi_context[channel->channel]);\n\t\tif (rc) {\n\t\t\tnetif_err(efx, drv, efx->net_dev,\n\t\t\t\t  \"failed to hook IRQ %d\\n\", channel->irq);\n\t\t\tgoto fail2;\n\t\t}\n\t\t++n_irqs;\n\n#ifdef CONFIG_RFS_ACCEL\n\t\tif (efx->interrupt_mode == EFX_INT_MODE_MSIX &&\n\t\t    channel->channel < efx->n_rx_channels) {\n\t\t\trc = irq_cpu_rmap_add(efx->net_dev->rx_cpu_rmap,\n\t\t\t\t\t      channel->irq);\n\t\t\tif (rc)\n\t\t\t\tgoto fail2;\n\t\t}\n#endif\n\t}\n\n\tefx->irqs_hooked = true;\n\treturn 0;\n\n fail2:\n#ifdef CONFIG_RFS_ACCEL\n\tfree_irq_cpu_rmap(efx->net_dev->rx_cpu_rmap);\n\tefx->net_dev->rx_cpu_rmap = NULL;\n#endif\n\tefx_for_each_channel(channel, efx) {\n\t\tif (n_irqs-- == 0)\n\t\t\tbreak;\n\t\tfree_irq(channel->irq, &efx->msi_context[channel->channel]);\n\t}\n fail1:\n\treturn rc;\n}\n\nvoid efx_nic_fini_interrupt(struct efx_nic *efx)\n{\n\tstruct efx_channel *channel;\n\n#ifdef CONFIG_RFS_ACCEL\n\tfree_irq_cpu_rmap(efx->net_dev->rx_cpu_rmap);\n\tefx->net_dev->rx_cpu_rmap = NULL;\n#endif\n\n\tif (!efx->irqs_hooked)\n\t\treturn;\n\tif (EFX_INT_MODE_USE_MSI(efx)) {\n\t\t \n\t\tefx_for_each_channel(channel, efx)\n\t\t\tfree_irq(channel->irq,\n\t\t\t\t &efx->msi_context[channel->channel]);\n\t} else {\n\t\t \n\t\tfree_irq(efx->legacy_irq, efx);\n\t}\n\tefx->irqs_hooked = false;\n}\n\n \n\n#define REGISTER_REVISION_ED\t4\n#define REGISTER_REVISION_EZ\t4\t \n\nstruct efx_nic_reg {\n\tu32 offset:24;\n\tu32 min_revision:3, max_revision:3;\n};\n\n#define REGISTER(name, arch, min_rev, max_rev) {\t\t\t\\\n\tarch ## R_ ## min_rev ## max_rev ## _ ## name,\t\t\t\\\n\tREGISTER_REVISION_ ## arch ## min_rev,\t\t\t\t\\\n\tREGISTER_REVISION_ ## arch ## max_rev\t\t\t\t\\\n}\n#define REGISTER_DZ(name) REGISTER(name, E, D, Z)\n\nstatic const struct efx_nic_reg efx_nic_regs[] = {\n\t \n\t \n\tREGISTER_DZ(BIU_HW_REV_ID),\n\tREGISTER_DZ(MC_DB_LWRD),\n\tREGISTER_DZ(MC_DB_HWRD),\n};\n\nstruct efx_nic_reg_table {\n\tu32 offset:24;\n\tu32 min_revision:3, max_revision:3;\n\tu32 step:6, rows:21;\n};\n\n#define REGISTER_TABLE_DIMENSIONS(_, offset, arch, min_rev, max_rev, step, rows) { \\\n\toffset,\t\t\t\t\t\t\t\t\\\n\tREGISTER_REVISION_ ## arch ## min_rev,\t\t\t\t\\\n\tREGISTER_REVISION_ ## arch ## max_rev,\t\t\t\t\\\n\tstep, rows\t\t\t\t\t\t\t\\\n}\n#define REGISTER_TABLE(name, arch, min_rev, max_rev)\t\t\t\\\n\tREGISTER_TABLE_DIMENSIONS(\t\t\t\t\t\\\n\t\tname, arch ## R_ ## min_rev ## max_rev ## _ ## name,\t\\\n\t\tarch, min_rev, max_rev,\t\t\t\t\t\\\n\t\tarch ## R_ ## min_rev ## max_rev ## _ ## name ## _STEP,\t\\\n\t\tarch ## R_ ## min_rev ## max_rev ## _ ## name ## _ROWS)\n#define REGISTER_TABLE_DZ(name) REGISTER_TABLE(name, E, D, Z)\n\nstatic const struct efx_nic_reg_table efx_nic_reg_tables[] = {\n\tREGISTER_TABLE_DZ(BIU_MC_SFT_STATUS),\n};\n\nsize_t efx_nic_get_regs_len(struct efx_nic *efx)\n{\n\tconst struct efx_nic_reg *reg;\n\tconst struct efx_nic_reg_table *table;\n\tsize_t len = 0;\n\n\tfor (reg = efx_nic_regs;\n\t     reg < efx_nic_regs + ARRAY_SIZE(efx_nic_regs);\n\t     reg++)\n\t\tif (efx->type->revision >= reg->min_revision &&\n\t\t    efx->type->revision <= reg->max_revision)\n\t\t\tlen += sizeof(efx_oword_t);\n\n\tfor (table = efx_nic_reg_tables;\n\t     table < efx_nic_reg_tables + ARRAY_SIZE(efx_nic_reg_tables);\n\t     table++)\n\t\tif (efx->type->revision >= table->min_revision &&\n\t\t    efx->type->revision <= table->max_revision)\n\t\t\tlen += table->rows * min_t(size_t, table->step, 16);\n\n\treturn len;\n}\n\nvoid efx_nic_get_regs(struct efx_nic *efx, void *buf)\n{\n\tconst struct efx_nic_reg *reg;\n\tconst struct efx_nic_reg_table *table;\n\n\tfor (reg = efx_nic_regs;\n\t     reg < efx_nic_regs + ARRAY_SIZE(efx_nic_regs);\n\t     reg++) {\n\t\tif (efx->type->revision >= reg->min_revision &&\n\t\t    efx->type->revision <= reg->max_revision) {\n\t\t\tefx_reado(efx, (efx_oword_t *)buf, reg->offset);\n\t\t\tbuf += sizeof(efx_oword_t);\n\t\t}\n\t}\n\n\tfor (table = efx_nic_reg_tables;\n\t     table < efx_nic_reg_tables + ARRAY_SIZE(efx_nic_reg_tables);\n\t     table++) {\n\t\tsize_t size, i;\n\n\t\tif (!(efx->type->revision >= table->min_revision &&\n\t\t      efx->type->revision <= table->max_revision))\n\t\t\tcontinue;\n\n\t\tsize = min_t(size_t, table->step, 16);\n\n\t\tfor (i = 0; i < table->rows; i++) {\n\t\t\tswitch (table->step) {\n\t\t\tcase 4:  \n\t\t\t\tefx_readd(efx, buf, table->offset + 4 * i);\n\t\t\t\tbreak;\n\t\t\tcase 16:  \n\t\t\t\tefx_reado_table(efx, buf, table->offset, i);\n\t\t\t\tbreak;\n\t\t\tcase 32:  \n\t\t\t\tefx_reado_table(efx, buf, table->offset, 2 * i);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON(1);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbuf += size;\n\t\t}\n\t}\n}\n\n \nsize_t efx_nic_describe_stats(const struct efx_hw_stat_desc *desc, size_t count,\n\t\t\t      const unsigned long *mask, u8 *names)\n{\n\tsize_t visible = 0;\n\tsize_t index;\n\n\tfor_each_set_bit(index, mask, count) {\n\t\tif (desc[index].name) {\n\t\t\tif (names) {\n\t\t\t\tstrscpy(names, desc[index].name,\n\t\t\t\t\tETH_GSTRING_LEN);\n\t\t\t\tnames += ETH_GSTRING_LEN;\n\t\t\t}\n\t\t\t++visible;\n\t\t}\n\t}\n\n\treturn visible;\n}\n\n \nint efx_nic_copy_stats(struct efx_nic *efx, __le64 *dest)\n{\n\t__le64 *dma_stats = efx->stats_buffer.addr;\n\t__le64 generation_start, generation_end;\n\tint rc = 0, retry;\n\n\tif (!dest)\n\t\treturn 0;\n\n\tif (!dma_stats)\n\t\tgoto return_zeroes;\n\n\t \n\tfor (retry = 0; retry < 100; ++retry) {\n\t\tgeneration_end = dma_stats[efx->num_mac_stats - 1];\n\t\tif (generation_end == EFX_MC_STATS_GENERATION_INVALID)\n\t\t\tgoto return_zeroes;\n\t\trmb();\n\t\tmemcpy(dest, dma_stats, efx->num_mac_stats * sizeof(__le64));\n\t\trmb();\n\t\tgeneration_start = dma_stats[MC_CMD_MAC_GENERATION_START];\n\t\tif (generation_end == generation_start)\n\t\t\treturn 0;  \n\t\tudelay(100);\n\t}\n\n\trc = -EIO;\n\nreturn_zeroes:\n\tmemset(dest, 0, efx->num_mac_stats * sizeof(u64));\n\treturn rc;\n}\n\n \nvoid efx_nic_update_stats(const struct efx_hw_stat_desc *desc, size_t count,\n\t\t\t  const unsigned long *mask,\n\t\t\t  u64 *stats, const void *dma_buf, bool accumulate)\n{\n\tsize_t index;\n\n\tfor_each_set_bit(index, mask, count) {\n\t\tif (desc[index].dma_width) {\n\t\t\tconst void *addr = dma_buf + desc[index].offset;\n\t\t\tu64 val;\n\n\t\t\tswitch (desc[index].dma_width) {\n\t\t\tcase 16:\n\t\t\t\tval = le16_to_cpup((__le16 *)addr);\n\t\t\t\tbreak;\n\t\t\tcase 32:\n\t\t\t\tval = le32_to_cpup((__le32 *)addr);\n\t\t\t\tbreak;\n\t\t\tcase 64:\n\t\t\t\tval = le64_to_cpup((__le64 *)addr);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWARN_ON(1);\n\t\t\t\tval = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (accumulate)\n\t\t\t\tstats[index] += val;\n\t\t\telse\n\t\t\t\tstats[index] = val;\n\t\t}\n\t}\n}\n\nvoid efx_nic_fix_nodesc_drop_stat(struct efx_nic *efx, u64 *rx_nodesc_drops)\n{\n\t \n\tif (!(efx->net_dev->flags & IFF_UP) || !efx->rx_nodesc_drops_prev_state)\n\t\tefx->rx_nodesc_drops_while_down +=\n\t\t\t*rx_nodesc_drops - efx->rx_nodesc_drops_total;\n\tefx->rx_nodesc_drops_total = *rx_nodesc_drops;\n\tefx->rx_nodesc_drops_prev_state = !!(efx->net_dev->flags & IFF_UP);\n\t*rx_nodesc_drops -= efx->rx_nodesc_drops_while_down;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}