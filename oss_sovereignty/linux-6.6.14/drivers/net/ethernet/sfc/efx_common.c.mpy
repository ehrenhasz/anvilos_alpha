{
  "module_name": "efx_common.c",
  "hash_id": "c06c10ce6c30c88e3c08261605d221ce39f194fdba93c4009416d89ceb58b89f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sfc/efx_common.c",
  "human_readable_source": "\n \n\n#include \"net_driver.h\"\n#include <linux/filter.h>\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <net/gre.h>\n#include \"efx_common.h\"\n#include \"efx_channels.h\"\n#include \"efx.h\"\n#include \"mcdi.h\"\n#include \"selftest.h\"\n#include \"rx_common.h\"\n#include \"tx_common.h\"\n#include \"nic.h\"\n#include \"mcdi_port_common.h\"\n#include \"io.h\"\n#include \"mcdi_pcol.h\"\n#include \"ef100_rep.h\"\n\nstatic unsigned int debug = (NETIF_MSG_DRV | NETIF_MSG_PROBE |\n\t\t\t     NETIF_MSG_LINK | NETIF_MSG_IFDOWN |\n\t\t\t     NETIF_MSG_IFUP | NETIF_MSG_RX_ERR |\n\t\t\t     NETIF_MSG_TX_ERR | NETIF_MSG_HW);\nmodule_param(debug, uint, 0);\nMODULE_PARM_DESC(debug, \"Bitmapped debugging message enable value\");\n\n \nstatic unsigned int efx_monitor_interval = 1 * HZ;\n\n \n#define BIST_WAIT_DELAY_MS\t100\n#define BIST_WAIT_DELAY_COUNT\t100\n\n \n#define STATS_PERIOD_MS_DEFAULT 1000\n\nstatic const unsigned int efx_reset_type_max = RESET_TYPE_MAX;\nstatic const char *const efx_reset_type_names[] = {\n\t[RESET_TYPE_INVISIBLE]          = \"INVISIBLE\",\n\t[RESET_TYPE_ALL]                = \"ALL\",\n\t[RESET_TYPE_RECOVER_OR_ALL]     = \"RECOVER_OR_ALL\",\n\t[RESET_TYPE_WORLD]              = \"WORLD\",\n\t[RESET_TYPE_RECOVER_OR_DISABLE] = \"RECOVER_OR_DISABLE\",\n\t[RESET_TYPE_DATAPATH]           = \"DATAPATH\",\n\t[RESET_TYPE_MC_BIST]\t\t= \"MC_BIST\",\n\t[RESET_TYPE_DISABLE]            = \"DISABLE\",\n\t[RESET_TYPE_TX_WATCHDOG]        = \"TX_WATCHDOG\",\n\t[RESET_TYPE_INT_ERROR]          = \"INT_ERROR\",\n\t[RESET_TYPE_DMA_ERROR]          = \"DMA_ERROR\",\n\t[RESET_TYPE_TX_SKIP]            = \"TX_SKIP\",\n\t[RESET_TYPE_MC_FAILURE]         = \"MC_FAILURE\",\n\t[RESET_TYPE_MCDI_TIMEOUT]\t= \"MCDI_TIMEOUT (FLR)\",\n};\n\n#define RESET_TYPE(type) \\\n\tSTRING_TABLE_LOOKUP(type, efx_reset_type)\n\n \nconst unsigned int efx_loopback_mode_max = LOOPBACK_MAX;\nconst char *const efx_loopback_mode_names[] = {\n\t[LOOPBACK_NONE]\t\t= \"NONE\",\n\t[LOOPBACK_DATA]\t\t= \"DATAPATH\",\n\t[LOOPBACK_GMAC]\t\t= \"GMAC\",\n\t[LOOPBACK_XGMII]\t= \"XGMII\",\n\t[LOOPBACK_XGXS]\t\t= \"XGXS\",\n\t[LOOPBACK_XAUI]\t\t= \"XAUI\",\n\t[LOOPBACK_GMII]\t\t= \"GMII\",\n\t[LOOPBACK_SGMII]\t= \"SGMII\",\n\t[LOOPBACK_XGBR]\t\t= \"XGBR\",\n\t[LOOPBACK_XFI]\t\t= \"XFI\",\n\t[LOOPBACK_XAUI_FAR]\t= \"XAUI_FAR\",\n\t[LOOPBACK_GMII_FAR]\t= \"GMII_FAR\",\n\t[LOOPBACK_SGMII_FAR]\t= \"SGMII_FAR\",\n\t[LOOPBACK_XFI_FAR]\t= \"XFI_FAR\",\n\t[LOOPBACK_GPHY]\t\t= \"GPHY\",\n\t[LOOPBACK_PHYXS]\t= \"PHYXS\",\n\t[LOOPBACK_PCS]\t\t= \"PCS\",\n\t[LOOPBACK_PMAPMD]\t= \"PMA/PMD\",\n\t[LOOPBACK_XPORT]\t= \"XPORT\",\n\t[LOOPBACK_XGMII_WS]\t= \"XGMII_WS\",\n\t[LOOPBACK_XAUI_WS]\t= \"XAUI_WS\",\n\t[LOOPBACK_XAUI_WS_FAR]  = \"XAUI_WS_FAR\",\n\t[LOOPBACK_XAUI_WS_NEAR] = \"XAUI_WS_NEAR\",\n\t[LOOPBACK_GMII_WS]\t= \"GMII_WS\",\n\t[LOOPBACK_XFI_WS]\t= \"XFI_WS\",\n\t[LOOPBACK_XFI_WS_FAR]\t= \"XFI_WS_FAR\",\n\t[LOOPBACK_PHYXS_WS]\t= \"PHYXS_WS\",\n};\n\n \nstatic struct workqueue_struct *reset_workqueue;\n\nint efx_create_reset_workqueue(void)\n{\n\treset_workqueue = create_singlethread_workqueue(\"sfc_reset\");\n\tif (!reset_workqueue) {\n\t\tprintk(KERN_ERR \"Failed to create reset workqueue\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nvoid efx_queue_reset_work(struct efx_nic *efx)\n{\n\tqueue_work(reset_workqueue, &efx->reset_work);\n}\n\nvoid efx_flush_reset_workqueue(struct efx_nic *efx)\n{\n\tcancel_work_sync(&efx->reset_work);\n}\n\nvoid efx_destroy_reset_workqueue(void)\n{\n\tif (reset_workqueue) {\n\t\tdestroy_workqueue(reset_workqueue);\n\t\treset_workqueue = NULL;\n\t}\n}\n\n \nvoid efx_mac_reconfigure(struct efx_nic *efx, bool mtu_only)\n{\n\tif (efx->type->reconfigure_mac) {\n\t\tdown_read(&efx->filter_sem);\n\t\tefx->type->reconfigure_mac(efx, mtu_only);\n\t\tup_read(&efx->filter_sem);\n\t}\n}\n\n \nstatic void efx_mac_work(struct work_struct *data)\n{\n\tstruct efx_nic *efx = container_of(data, struct efx_nic, mac_work);\n\n\tmutex_lock(&efx->mac_lock);\n\tif (efx->port_enabled)\n\t\tefx_mac_reconfigure(efx, false);\n\tmutex_unlock(&efx->mac_lock);\n}\n\nint efx_set_mac_address(struct net_device *net_dev, void *data)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\tstruct sockaddr *addr = data;\n\tu8 *new_addr = addr->sa_data;\n\tu8 old_addr[6];\n\tint rc;\n\n\tif (!is_valid_ether_addr(new_addr)) {\n\t\tnetif_err(efx, drv, efx->net_dev,\n\t\t\t  \"invalid ethernet MAC address requested: %pM\\n\",\n\t\t\t  new_addr);\n\t\treturn -EADDRNOTAVAIL;\n\t}\n\n\t \n\tether_addr_copy(old_addr, net_dev->dev_addr);\n\teth_hw_addr_set(net_dev, new_addr);\n\tif (efx->type->set_mac_address) {\n\t\trc = efx->type->set_mac_address(efx);\n\t\tif (rc) {\n\t\t\teth_hw_addr_set(net_dev, old_addr);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\t \n\tmutex_lock(&efx->mac_lock);\n\tefx_mac_reconfigure(efx, false);\n\tmutex_unlock(&efx->mac_lock);\n\n\treturn 0;\n}\n\n \nvoid efx_set_rx_mode(struct net_device *net_dev)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\n\tif (efx->port_enabled)\n\t\tqueue_work(efx->workqueue, &efx->mac_work);\n\t \n}\n\nint efx_set_features(struct net_device *net_dev, netdev_features_t data)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\tint rc;\n\n\t \n\tif (net_dev->features & ~data & NETIF_F_NTUPLE) {\n\t\trc = efx->type->filter_clear_rx(efx, EFX_FILTER_PRI_MANUAL);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t \n\tif ((net_dev->features ^ data) & (NETIF_F_HW_VLAN_CTAG_FILTER |\n\t\t\t\t\t  NETIF_F_RXFCS)) {\n\t\t \n\t\tefx_set_rx_mode(net_dev);\n\t}\n\n\treturn 0;\n}\n\n \nvoid efx_link_status_changed(struct efx_nic *efx)\n{\n\tstruct efx_link_state *link_state = &efx->link_state;\n\n\t \n\tif (!netif_running(efx->net_dev))\n\t\treturn;\n\n\tif (link_state->up != netif_carrier_ok(efx->net_dev)) {\n\t\tefx->n_link_state_changes++;\n\n\t\tif (link_state->up)\n\t\t\tnetif_carrier_on(efx->net_dev);\n\t\telse\n\t\t\tnetif_carrier_off(efx->net_dev);\n\t}\n\n\t \n\tif (link_state->up)\n\t\tnetif_info(efx, link, efx->net_dev,\n\t\t\t   \"link up at %uMbps %s-duplex (MTU %d)\\n\",\n\t\t\t   link_state->speed, link_state->fd ? \"full\" : \"half\",\n\t\t\t   efx->net_dev->mtu);\n\telse\n\t\tnetif_info(efx, link, efx->net_dev, \"link down\\n\");\n}\n\nunsigned int efx_xdp_max_mtu(struct efx_nic *efx)\n{\n\t \n\tint overhead = EFX_MAX_FRAME_LEN(0) + sizeof(struct efx_rx_page_state) +\n\t\t       efx->rx_prefix_size + efx->type->rx_buffer_padding +\n\t\t       efx->rx_ip_align + EFX_XDP_HEADROOM + EFX_XDP_TAILROOM;\n\n\treturn PAGE_SIZE - overhead;\n}\n\n \nint efx_change_mtu(struct net_device *net_dev, int new_mtu)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\tint rc;\n\n\trc = efx_check_disabled(efx);\n\tif (rc)\n\t\treturn rc;\n\n\tif (rtnl_dereference(efx->xdp_prog) &&\n\t    new_mtu > efx_xdp_max_mtu(efx)) {\n\t\tnetif_err(efx, drv, efx->net_dev,\n\t\t\t  \"Requested MTU of %d too big for XDP (max: %d)\\n\",\n\t\t\t  new_mtu, efx_xdp_max_mtu(efx));\n\t\treturn -EINVAL;\n\t}\n\n\tnetif_dbg(efx, drv, efx->net_dev, \"changing MTU to %d\\n\", new_mtu);\n\n\tefx_device_detach_sync(efx);\n\tefx_stop_all(efx);\n\n\tmutex_lock(&efx->mac_lock);\n\tnet_dev->mtu = new_mtu;\n\tefx_mac_reconfigure(efx, true);\n\tmutex_unlock(&efx->mac_lock);\n\n\tefx_start_all(efx);\n\tefx_device_attach_if_not_resetting(efx);\n\treturn 0;\n}\n\n \n\n \nstatic void efx_monitor(struct work_struct *data)\n{\n\tstruct efx_nic *efx = container_of(data, struct efx_nic,\n\t\t\t\t\t   monitor_work.work);\n\n\tnetif_vdbg(efx, timer, efx->net_dev,\n\t\t   \"hardware monitor executing on CPU %d\\n\",\n\t\t   raw_smp_processor_id());\n\tBUG_ON(efx->type->monitor == NULL);\n\n\t \n\tif (mutex_trylock(&efx->mac_lock)) {\n\t\tif (efx->port_enabled && efx->type->monitor)\n\t\t\tefx->type->monitor(efx);\n\t\tmutex_unlock(&efx->mac_lock);\n\t}\n\n\tefx_start_monitor(efx);\n}\n\nvoid efx_start_monitor(struct efx_nic *efx)\n{\n\tif (efx->type->monitor)\n\t\tqueue_delayed_work(efx->workqueue, &efx->monitor_work,\n\t\t\t\t   efx_monitor_interval);\n}\n\n \n\n \nstatic void efx_start_datapath(struct efx_nic *efx)\n{\n\tnetdev_features_t old_features = efx->net_dev->features;\n\tbool old_rx_scatter = efx->rx_scatter;\n\tsize_t rx_buf_len;\n\n\t \n\tefx->rx_dma_len = (efx->rx_prefix_size +\n\t\t\t   EFX_MAX_FRAME_LEN(efx->net_dev->mtu) +\n\t\t\t   efx->type->rx_buffer_padding);\n\trx_buf_len = (sizeof(struct efx_rx_page_state)   + EFX_XDP_HEADROOM +\n\t\t      efx->rx_ip_align + efx->rx_dma_len + EFX_XDP_TAILROOM);\n\n\tif (rx_buf_len <= PAGE_SIZE) {\n\t\tefx->rx_scatter = efx->type->always_rx_scatter;\n\t\tefx->rx_buffer_order = 0;\n\t} else if (efx->type->can_rx_scatter) {\n\t\tBUILD_BUG_ON(EFX_RX_USR_BUF_SIZE % L1_CACHE_BYTES);\n\t\tBUILD_BUG_ON(sizeof(struct efx_rx_page_state) +\n\t\t\t     2 * ALIGN(NET_IP_ALIGN + EFX_RX_USR_BUF_SIZE,\n\t\t\t\t       EFX_RX_BUF_ALIGNMENT) >\n\t\t\t     PAGE_SIZE);\n\t\tefx->rx_scatter = true;\n\t\tefx->rx_dma_len = EFX_RX_USR_BUF_SIZE;\n\t\tefx->rx_buffer_order = 0;\n\t} else {\n\t\tefx->rx_scatter = false;\n\t\tefx->rx_buffer_order = get_order(rx_buf_len);\n\t}\n\n\tefx_rx_config_page_split(efx);\n\tif (efx->rx_buffer_order)\n\t\tnetif_dbg(efx, drv, efx->net_dev,\n\t\t\t  \"RX buf len=%u; page order=%u batch=%u\\n\",\n\t\t\t  efx->rx_dma_len, efx->rx_buffer_order,\n\t\t\t  efx->rx_pages_per_batch);\n\telse\n\t\tnetif_dbg(efx, drv, efx->net_dev,\n\t\t\t  \"RX buf len=%u step=%u bpp=%u; page batch=%u\\n\",\n\t\t\t  efx->rx_dma_len, efx->rx_page_buf_step,\n\t\t\t  efx->rx_bufs_per_page, efx->rx_pages_per_batch);\n\n\t \n\tefx->net_dev->hw_features |= efx->net_dev->features;\n\tefx->net_dev->hw_features &= ~efx->fixed_features;\n\tefx->net_dev->features |= efx->fixed_features;\n\tif (efx->net_dev->features != old_features)\n\t\tnetdev_features_change(efx->net_dev);\n\n\t \n\tif ((efx->rx_scatter != old_rx_scatter) &&\n\t    efx->type->filter_update_rx_scatter)\n\t\tefx->type->filter_update_rx_scatter(efx);\n\n\t \n\tefx->txq_stop_thresh = efx->txq_entries - efx_tx_max_skb_descs(efx);\n\tefx->txq_wake_thresh = efx->txq_stop_thresh / 2;\n\n\t \n\tefx_start_channels(efx);\n\n\tefx_ptp_start_datapath(efx);\n\n\tif (netif_device_present(efx->net_dev))\n\t\tnetif_tx_wake_all_queues(efx->net_dev);\n}\n\nstatic void efx_stop_datapath(struct efx_nic *efx)\n{\n\tEFX_ASSERT_RESET_SERIALISED(efx);\n\tBUG_ON(efx->port_enabled);\n\n\tefx_ptp_stop_datapath(efx);\n\n\tefx_stop_channels(efx);\n}\n\n \n\n \nvoid efx_link_clear_advertising(struct efx_nic *efx)\n{\n\tbitmap_zero(efx->link_advertising, __ETHTOOL_LINK_MODE_MASK_NBITS);\n\tefx->wanted_fc &= ~(EFX_FC_TX | EFX_FC_RX);\n}\n\nvoid efx_link_set_wanted_fc(struct efx_nic *efx, u8 wanted_fc)\n{\n\tefx->wanted_fc = wanted_fc;\n\tif (efx->link_advertising[0]) {\n\t\tif (wanted_fc & EFX_FC_RX)\n\t\t\tefx->link_advertising[0] |= (ADVERTISED_Pause |\n\t\t\t\t\t\t     ADVERTISED_Asym_Pause);\n\t\telse\n\t\t\tefx->link_advertising[0] &= ~(ADVERTISED_Pause |\n\t\t\t\t\t\t      ADVERTISED_Asym_Pause);\n\t\tif (wanted_fc & EFX_FC_TX)\n\t\t\tefx->link_advertising[0] ^= ADVERTISED_Asym_Pause;\n\t}\n}\n\nstatic void efx_start_port(struct efx_nic *efx)\n{\n\tnetif_dbg(efx, ifup, efx->net_dev, \"start port\\n\");\n\tBUG_ON(efx->port_enabled);\n\n\tmutex_lock(&efx->mac_lock);\n\tefx->port_enabled = true;\n\n\t \n\tefx_mac_reconfigure(efx, false);\n\n\tmutex_unlock(&efx->mac_lock);\n}\n\n \nstatic void efx_stop_port(struct efx_nic *efx)\n{\n\tnetif_dbg(efx, ifdown, efx->net_dev, \"stop port\\n\");\n\n\tEFX_ASSERT_RESET_SERIALISED(efx);\n\n\tmutex_lock(&efx->mac_lock);\n\tefx->port_enabled = false;\n\tmutex_unlock(&efx->mac_lock);\n\n\t \n\tnetif_addr_lock_bh(efx->net_dev);\n\tnetif_addr_unlock_bh(efx->net_dev);\n\n\tcancel_delayed_work_sync(&efx->monitor_work);\n\tefx_selftest_async_cancel(efx);\n\tcancel_work_sync(&efx->mac_work);\n}\n\n \nvoid efx_start_all(struct efx_nic *efx)\n{\n\tEFX_ASSERT_RESET_SERIALISED(efx);\n\tBUG_ON(efx->state == STATE_DISABLED);\n\n\t \n\tif (efx->port_enabled || !netif_running(efx->net_dev) ||\n\t    efx->reset_pending)\n\t\treturn;\n\n\tefx_start_port(efx);\n\tefx_start_datapath(efx);\n\n\t \n\tefx_start_monitor(efx);\n\n\tefx_selftest_async_start(efx);\n\n\t \n\tmutex_lock(&efx->mac_lock);\n\tif (efx_mcdi_phy_poll(efx))\n\t\tefx_link_status_changed(efx);\n\tmutex_unlock(&efx->mac_lock);\n\n\tif (efx->type->start_stats) {\n\t\tefx->type->start_stats(efx);\n\t\tefx->type->pull_stats(efx);\n\t\tspin_lock_bh(&efx->stats_lock);\n\t\tefx->type->update_stats(efx, NULL, NULL);\n\t\tspin_unlock_bh(&efx->stats_lock);\n\t}\n}\n\n \nvoid efx_stop_all(struct efx_nic *efx)\n{\n\tEFX_ASSERT_RESET_SERIALISED(efx);\n\n\t \n\tif (!efx->port_enabled)\n\t\treturn;\n\n\tif (efx->type->update_stats) {\n\t\t \n\t\tefx->type->pull_stats(efx);\n\t\tspin_lock_bh(&efx->stats_lock);\n\t\tefx->type->update_stats(efx, NULL, NULL);\n\t\tspin_unlock_bh(&efx->stats_lock);\n\t\tefx->type->stop_stats(efx);\n\t}\n\n\tefx_stop_port(efx);\n\n\t \n\tWARN_ON(netif_running(efx->net_dev) &&\n\t\tnetif_device_present(efx->net_dev));\n\tnetif_tx_disable(efx->net_dev);\n\n\tefx_stop_datapath(efx);\n}\n\n \nvoid efx_net_stats(struct net_device *net_dev, struct rtnl_link_stats64 *stats)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\n\tspin_lock_bh(&efx->stats_lock);\n\tefx_nic_update_stats_atomic(efx, NULL, stats);\n\tspin_unlock_bh(&efx->stats_lock);\n}\n\n \nint __efx_reconfigure_port(struct efx_nic *efx)\n{\n\tenum efx_phy_mode phy_mode;\n\tint rc = 0;\n\n\tWARN_ON(!mutex_is_locked(&efx->mac_lock));\n\n\t \n\tphy_mode = efx->phy_mode;\n\tif (LOOPBACK_INTERNAL(efx))\n\t\tefx->phy_mode |= PHY_MODE_TX_DISABLED;\n\telse\n\t\tefx->phy_mode &= ~PHY_MODE_TX_DISABLED;\n\n\tif (efx->type->reconfigure_port)\n\t\trc = efx->type->reconfigure_port(efx);\n\n\tif (rc)\n\t\tefx->phy_mode = phy_mode;\n\n\treturn rc;\n}\n\n \nint efx_reconfigure_port(struct efx_nic *efx)\n{\n\tint rc;\n\n\tEFX_ASSERT_RESET_SERIALISED(efx);\n\n\tmutex_lock(&efx->mac_lock);\n\trc = __efx_reconfigure_port(efx);\n\tmutex_unlock(&efx->mac_lock);\n\n\treturn rc;\n}\n\n \n\nstatic void efx_wait_for_bist_end(struct efx_nic *efx)\n{\n\tint i;\n\n\tfor (i = 0; i < BIST_WAIT_DELAY_COUNT; ++i) {\n\t\tif (efx_mcdi_poll_reboot(efx))\n\t\t\tgoto out;\n\t\tmsleep(BIST_WAIT_DELAY_MS);\n\t}\n\n\tnetif_err(efx, drv, efx->net_dev, \"Warning: No MC reboot after BIST mode\\n\");\nout:\n\t \n\tefx->mc_bist_for_other_fn = false;\n}\n\n \nint efx_try_recovery(struct efx_nic *efx)\n{\n#ifdef CONFIG_EEH\n\t \n\tstruct eeh_dev *eehdev = pci_dev_to_eeh_dev(efx->pci_dev);\n\tif (eeh_dev_check_failure(eehdev)) {\n\t\t \n\t\treturn 1;\n\t}\n#endif\n\treturn 0;\n}\n\n \nvoid efx_reset_down(struct efx_nic *efx, enum reset_type method)\n{\n\tEFX_ASSERT_RESET_SERIALISED(efx);\n\n\tif (method == RESET_TYPE_MCDI_TIMEOUT)\n\t\tefx->type->prepare_flr(efx);\n\n\tefx_stop_all(efx);\n\tefx_disable_interrupts(efx);\n\n\tmutex_lock(&efx->mac_lock);\n\tdown_write(&efx->filter_sem);\n\tmutex_lock(&efx->rss_lock);\n\tefx->type->fini(efx);\n}\n\n \nvoid efx_watchdog(struct net_device *net_dev, unsigned int txqueue)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\n\tnetif_err(efx, tx_err, efx->net_dev,\n\t\t  \"TX stuck with port_enabled=%d: resetting channels\\n\",\n\t\t  efx->port_enabled);\n\n\tefx_schedule_reset(efx, RESET_TYPE_TX_WATCHDOG);\n}\n\n \nint efx_reset_up(struct efx_nic *efx, enum reset_type method, bool ok)\n{\n\tint rc;\n\n\tEFX_ASSERT_RESET_SERIALISED(efx);\n\n\tif (method == RESET_TYPE_MCDI_TIMEOUT)\n\t\tefx->type->finish_flr(efx);\n\n\t \n\trc = efx->type->init(efx);\n\tif (rc) {\n\t\tnetif_err(efx, drv, efx->net_dev, \"failed to initialise NIC\\n\");\n\t\tgoto fail;\n\t}\n\n\tif (!ok)\n\t\tgoto fail;\n\n\tif (efx->port_initialized && method != RESET_TYPE_INVISIBLE &&\n\t    method != RESET_TYPE_DATAPATH) {\n\t\trc = efx_mcdi_port_reconfigure(efx);\n\t\tif (rc && rc != -EPERM)\n\t\t\tnetif_err(efx, drv, efx->net_dev,\n\t\t\t\t  \"could not restore PHY settings\\n\");\n\t}\n\n\trc = efx_enable_interrupts(efx);\n\tif (rc)\n\t\tgoto fail;\n\n#ifdef CONFIG_SFC_SRIOV\n\trc = efx->type->vswitching_restore(efx);\n\tif (rc)  \n\t\tnetif_warn(efx, probe, efx->net_dev,\n\t\t\t   \"failed to restore vswitching rc=%d;\"\n\t\t\t   \" VFs may not function\\n\", rc);\n#endif\n\n\tif (efx->type->rx_restore_rss_contexts)\n\t\tefx->type->rx_restore_rss_contexts(efx);\n\tmutex_unlock(&efx->rss_lock);\n\tefx->type->filter_table_restore(efx);\n\tup_write(&efx->filter_sem);\n\n\tmutex_unlock(&efx->mac_lock);\n\n\tefx_start_all(efx);\n\n\tif (efx->type->udp_tnl_push_ports)\n\t\tefx->type->udp_tnl_push_ports(efx);\n\n\treturn 0;\n\nfail:\n\tefx->port_initialized = false;\n\n\tmutex_unlock(&efx->rss_lock);\n\tup_write(&efx->filter_sem);\n\tmutex_unlock(&efx->mac_lock);\n\n\treturn rc;\n}\n\n \nint efx_reset(struct efx_nic *efx, enum reset_type method)\n{\n\tint rc, rc2 = 0;\n\tbool disabled;\n\n\tnetif_info(efx, drv, efx->net_dev, \"resetting (%s)\\n\",\n\t\t   RESET_TYPE(method));\n\n\tefx_device_detach_sync(efx);\n\t \n\tif (efx_nic_rev(efx) != EFX_REV_EF100)\n\t\tefx_reset_down(efx, method);\n\n\trc = efx->type->reset(efx, method);\n\tif (rc) {\n\t\tnetif_err(efx, drv, efx->net_dev, \"failed to reset hardware\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\tif (method < RESET_TYPE_MAX_METHOD)\n\t\tefx->reset_pending &= -(1 << (method + 1));\n\telse  \n\t\t__clear_bit(method, &efx->reset_pending);\n\n\t \n\tpci_set_master(efx->pci_dev);\n\nout:\n\t \n\tdisabled = rc ||\n\t\tmethod == RESET_TYPE_DISABLE ||\n\t\tmethod == RESET_TYPE_RECOVER_OR_DISABLE;\n\tif (efx_nic_rev(efx) != EFX_REV_EF100)\n\t\trc2 = efx_reset_up(efx, method, !disabled);\n\tif (rc2) {\n\t\tdisabled = true;\n\t\tif (!rc)\n\t\t\trc = rc2;\n\t}\n\n\tif (disabled) {\n\t\tdev_close(efx->net_dev);\n\t\tnetif_err(efx, drv, efx->net_dev, \"has been disabled\\n\");\n\t\tefx->state = STATE_DISABLED;\n\t} else {\n\t\tnetif_dbg(efx, drv, efx->net_dev, \"reset complete\\n\");\n\t\tefx_device_attach_if_not_resetting(efx);\n\t}\n\treturn rc;\n}\n\n \nstatic void efx_reset_work(struct work_struct *data)\n{\n\tstruct efx_nic *efx = container_of(data, struct efx_nic, reset_work);\n\tunsigned long pending;\n\tenum reset_type method;\n\n\tpending = READ_ONCE(efx->reset_pending);\n\tmethod = fls(pending) - 1;\n\n\tif (method == RESET_TYPE_MC_BIST)\n\t\tefx_wait_for_bist_end(efx);\n\n\tif ((method == RESET_TYPE_RECOVER_OR_DISABLE ||\n\t     method == RESET_TYPE_RECOVER_OR_ALL) &&\n\t    efx_try_recovery(efx))\n\t\treturn;\n\n\tif (!pending)\n\t\treturn;\n\n\trtnl_lock();\n\n\t \n\tif (efx_net_active(efx->state))\n\t\t(void)efx_reset(efx, method);\n\n\trtnl_unlock();\n}\n\nvoid efx_schedule_reset(struct efx_nic *efx, enum reset_type type)\n{\n\tenum reset_type method;\n\n\tif (efx_recovering(efx->state)) {\n\t\tnetif_dbg(efx, drv, efx->net_dev,\n\t\t\t  \"recovering: skip scheduling %s reset\\n\",\n\t\t\t  RESET_TYPE(type));\n\t\treturn;\n\t}\n\n\tswitch (type) {\n\tcase RESET_TYPE_INVISIBLE:\n\tcase RESET_TYPE_ALL:\n\tcase RESET_TYPE_RECOVER_OR_ALL:\n\tcase RESET_TYPE_WORLD:\n\tcase RESET_TYPE_DISABLE:\n\tcase RESET_TYPE_RECOVER_OR_DISABLE:\n\tcase RESET_TYPE_DATAPATH:\n\tcase RESET_TYPE_MC_BIST:\n\tcase RESET_TYPE_MCDI_TIMEOUT:\n\t\tmethod = type;\n\t\tnetif_dbg(efx, drv, efx->net_dev, \"scheduling %s reset\\n\",\n\t\t\t  RESET_TYPE(method));\n\t\tbreak;\n\tdefault:\n\t\tmethod = efx->type->map_reset_reason(type);\n\t\tnetif_dbg(efx, drv, efx->net_dev,\n\t\t\t  \"scheduling %s reset for %s\\n\",\n\t\t\t  RESET_TYPE(method), RESET_TYPE(type));\n\t\tbreak;\n\t}\n\n\tset_bit(method, &efx->reset_pending);\n\tsmp_mb();  \n\n\t \n\tif (!efx_net_active(READ_ONCE(efx->state)))\n\t\treturn;\n\n\t \n\tefx_mcdi_mode_poll(efx);\n\n\tefx_queue_reset_work(efx);\n}\n\n \nint efx_port_dummy_op_int(struct efx_nic *efx)\n{\n\treturn 0;\n}\nvoid efx_port_dummy_op_void(struct efx_nic *efx) {}\n\n \n\n \nint efx_init_struct(struct efx_nic *efx, struct pci_dev *pci_dev)\n{\n\tint rc = -ENOMEM;\n\n\t \n\tINIT_LIST_HEAD(&efx->node);\n\tINIT_LIST_HEAD(&efx->secondary_list);\n\tspin_lock_init(&efx->biu_lock);\n#ifdef CONFIG_SFC_MTD\n\tINIT_LIST_HEAD(&efx->mtd_list);\n#endif\n\tINIT_WORK(&efx->reset_work, efx_reset_work);\n\tINIT_DELAYED_WORK(&efx->monitor_work, efx_monitor);\n\tefx_selftest_async_init(efx);\n\tefx->pci_dev = pci_dev;\n\tefx->msg_enable = debug;\n\tefx->state = STATE_UNINIT;\n\tstrscpy(efx->name, pci_name(pci_dev), sizeof(efx->name));\n\n\tefx->rx_prefix_size = efx->type->rx_prefix_size;\n\tefx->rx_ip_align =\n\t\tNET_IP_ALIGN ? (efx->rx_prefix_size + NET_IP_ALIGN) % 4 : 0;\n\tefx->rx_packet_hash_offset =\n\t\tefx->type->rx_hash_offset - efx->type->rx_prefix_size;\n\tefx->rx_packet_ts_offset =\n\t\tefx->type->rx_ts_offset - efx->type->rx_prefix_size;\n\tINIT_LIST_HEAD(&efx->rss_context.list);\n\tefx->rss_context.context_id = EFX_MCDI_RSS_CONTEXT_INVALID;\n\tmutex_init(&efx->rss_lock);\n\tefx->vport_id = EVB_PORT_ID_ASSIGNED;\n\tspin_lock_init(&efx->stats_lock);\n\tefx->vi_stride = EFX_DEFAULT_VI_STRIDE;\n\tefx->num_mac_stats = MC_CMD_MAC_NSTATS;\n\tBUILD_BUG_ON(MC_CMD_MAC_NSTATS - 1 != MC_CMD_MAC_GENERATION_END);\n\tmutex_init(&efx->mac_lock);\n\tinit_rwsem(&efx->filter_sem);\n#ifdef CONFIG_RFS_ACCEL\n\tmutex_init(&efx->rps_mutex);\n\tspin_lock_init(&efx->rps_hash_lock);\n\t \n\tefx->rps_hash_table = kcalloc(EFX_ARFS_HASH_TABLE_SIZE,\n\t\t\t\t      sizeof(*efx->rps_hash_table), GFP_KERNEL);\n#endif\n\tspin_lock_init(&efx->vf_reps_lock);\n\tINIT_LIST_HEAD(&efx->vf_reps);\n\tINIT_WORK(&efx->mac_work, efx_mac_work);\n\tinit_waitqueue_head(&efx->flush_wq);\n\n\tefx->tx_queues_per_channel = 1;\n\tefx->rxq_entries = EFX_DEFAULT_DMAQ_SIZE;\n\tefx->txq_entries = EFX_DEFAULT_DMAQ_SIZE;\n\n\tefx->mem_bar = UINT_MAX;\n\n\trc = efx_init_channels(efx);\n\tif (rc)\n\t\tgoto fail;\n\n\t \n\tsnprintf(efx->workqueue_name, sizeof(efx->workqueue_name), \"sfc%s\",\n\t\t pci_name(pci_dev));\n\tefx->workqueue = create_singlethread_workqueue(efx->workqueue_name);\n\tif (!efx->workqueue) {\n\t\trc = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\treturn 0;\n\nfail:\n\tefx_fini_struct(efx);\n\treturn rc;\n}\n\nvoid efx_fini_struct(struct efx_nic *efx)\n{\n#ifdef CONFIG_RFS_ACCEL\n\tkfree(efx->rps_hash_table);\n#endif\n\n\tefx_fini_channels(efx);\n\n\tkfree(efx->vpd_sn);\n\n\tif (efx->workqueue) {\n\t\tdestroy_workqueue(efx->workqueue);\n\t\tefx->workqueue = NULL;\n\t}\n}\n\n \nint efx_init_io(struct efx_nic *efx, int bar, dma_addr_t dma_mask,\n\t\tunsigned int mem_map_size)\n{\n\tstruct pci_dev *pci_dev = efx->pci_dev;\n\tint rc;\n\n\tefx->mem_bar = UINT_MAX;\n\tpci_dbg(pci_dev, \"initialising I/O bar=%d\\n\", bar);\n\n\trc = pci_enable_device(pci_dev);\n\tif (rc) {\n\t\tpci_err(pci_dev, \"failed to enable PCI device\\n\");\n\t\tgoto fail1;\n\t}\n\n\tpci_set_master(pci_dev);\n\n\trc = dma_set_mask_and_coherent(&pci_dev->dev, dma_mask);\n\tif (rc) {\n\t\tpci_err(efx->pci_dev, \"could not find a suitable DMA mask\\n\");\n\t\tgoto fail2;\n\t}\n\tpci_dbg(efx->pci_dev, \"using DMA mask %llx\\n\", (unsigned long long)dma_mask);\n\n\tefx->membase_phys = pci_resource_start(efx->pci_dev, bar);\n\tif (!efx->membase_phys) {\n\t\tpci_err(efx->pci_dev,\n\t\t\t\"ERROR: No BAR%d mapping from the BIOS. Try pci=realloc on the kernel command line\\n\",\n\t\t\tbar);\n\t\trc = -ENODEV;\n\t\tgoto fail3;\n\t}\n\n\trc = pci_request_region(pci_dev, bar, \"sfc\");\n\tif (rc) {\n\t\tpci_err(efx->pci_dev,\n\t\t\t\"request for memory BAR[%d] failed\\n\", bar);\n\t\trc = -EIO;\n\t\tgoto fail3;\n\t}\n\tefx->mem_bar = bar;\n\tefx->membase = ioremap(efx->membase_phys, mem_map_size);\n\tif (!efx->membase) {\n\t\tpci_err(efx->pci_dev,\n\t\t\t\"could not map memory BAR[%d] at %llx+%x\\n\", bar,\n\t\t\t(unsigned long long)efx->membase_phys, mem_map_size);\n\t\trc = -ENOMEM;\n\t\tgoto fail4;\n\t}\n\tpci_dbg(efx->pci_dev,\n\t\t\"memory BAR[%d] at %llx+%x (virtual %p)\\n\", bar,\n\t\t(unsigned long long)efx->membase_phys, mem_map_size,\n\t\tefx->membase);\n\n\treturn 0;\n\nfail4:\n\tpci_release_region(efx->pci_dev, bar);\nfail3:\n\tefx->membase_phys = 0;\nfail2:\n\tpci_disable_device(efx->pci_dev);\nfail1:\n\treturn rc;\n}\n\nvoid efx_fini_io(struct efx_nic *efx)\n{\n\tpci_dbg(efx->pci_dev, \"shutting down I/O\\n\");\n\n\tif (efx->membase) {\n\t\tiounmap(efx->membase);\n\t\tefx->membase = NULL;\n\t}\n\n\tif (efx->membase_phys) {\n\t\tpci_release_region(efx->pci_dev, efx->mem_bar);\n\t\tefx->membase_phys = 0;\n\t\tefx->mem_bar = UINT_MAX;\n\t}\n\n\t \n\tif (!pci_vfs_assigned(efx->pci_dev))\n\t\tpci_disable_device(efx->pci_dev);\n}\n\n#ifdef CONFIG_SFC_MCDI_LOGGING\nstatic ssize_t mcdi_logging_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr,\n\t\t\t\t char *buf)\n{\n\tstruct efx_nic *efx = dev_get_drvdata(dev);\n\tstruct efx_mcdi_iface *mcdi = efx_mcdi(efx);\n\n\treturn sysfs_emit(buf, \"%d\\n\", mcdi->logging_enabled);\n}\n\nstatic ssize_t mcdi_logging_store(struct device *dev,\n\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t  const char *buf, size_t count)\n{\n\tstruct efx_nic *efx = dev_get_drvdata(dev);\n\tstruct efx_mcdi_iface *mcdi = efx_mcdi(efx);\n\tbool enable = count > 0 && *buf != '0';\n\n\tmcdi->logging_enabled = enable;\n\treturn count;\n}\n\nstatic DEVICE_ATTR_RW(mcdi_logging);\n\nvoid efx_init_mcdi_logging(struct efx_nic *efx)\n{\n\tint rc = device_create_file(&efx->pci_dev->dev, &dev_attr_mcdi_logging);\n\n\tif (rc) {\n\t\tnetif_warn(efx, drv, efx->net_dev,\n\t\t\t   \"failed to init net dev attributes\\n\");\n\t}\n}\n\nvoid efx_fini_mcdi_logging(struct efx_nic *efx)\n{\n\tdevice_remove_file(&efx->pci_dev->dev, &dev_attr_mcdi_logging);\n}\n#endif\n\n \nstatic pci_ers_result_t efx_io_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t      pci_channel_state_t state)\n{\n\tpci_ers_result_t status = PCI_ERS_RESULT_RECOVERED;\n\tstruct efx_nic *efx = pci_get_drvdata(pdev);\n\n\tif (state == pci_channel_io_perm_failure)\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\n\trtnl_lock();\n\n\tif (efx->state != STATE_DISABLED) {\n\t\tefx->state = efx_recover(efx->state);\n\t\tefx->reset_pending = 0;\n\n\t\tefx_device_detach_sync(efx);\n\n\t\tif (efx_net_active(efx->state)) {\n\t\t\tefx_stop_all(efx);\n\t\t\tefx_disable_interrupts(efx);\n\t\t}\n\n\t\tstatus = PCI_ERS_RESULT_NEED_RESET;\n\t} else {\n\t\t \n\t\tstatus = PCI_ERS_RESULT_RECOVERED;\n\t}\n\n\trtnl_unlock();\n\n\tpci_disable_device(pdev);\n\n\treturn status;\n}\n\n \nstatic pci_ers_result_t efx_io_slot_reset(struct pci_dev *pdev)\n{\n\tstruct efx_nic *efx = pci_get_drvdata(pdev);\n\tpci_ers_result_t status = PCI_ERS_RESULT_RECOVERED;\n\n\tif (pci_enable_device(pdev)) {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"Cannot re-enable PCI device after reset.\\n\");\n\t\tstatus =  PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\treturn status;\n}\n\n \nstatic void efx_io_resume(struct pci_dev *pdev)\n{\n\tstruct efx_nic *efx = pci_get_drvdata(pdev);\n\tint rc;\n\n\trtnl_lock();\n\n\tif (efx->state == STATE_DISABLED)\n\t\tgoto out;\n\n\trc = efx_reset(efx, RESET_TYPE_ALL);\n\tif (rc) {\n\t\tnetif_err(efx, hw, efx->net_dev,\n\t\t\t  \"efx_reset failed after PCI error (%d)\\n\", rc);\n\t} else {\n\t\tefx->state = efx_recovered(efx->state);\n\t\tnetif_dbg(efx, hw, efx->net_dev,\n\t\t\t  \"Done resetting and resuming IO after PCI error.\\n\");\n\t}\n\nout:\n\trtnl_unlock();\n}\n\n \nconst struct pci_error_handlers efx_err_handlers = {\n\t.error_detected = efx_io_error_detected,\n\t.slot_reset\t= efx_io_slot_reset,\n\t.resume\t\t= efx_io_resume,\n};\n\n \nstatic bool efx_can_encap_offloads(struct efx_nic *efx, struct sk_buff *skb)\n{\n\tstruct gre_base_hdr *greh;\n\t__be16 dst_port;\n\tu8 ipproto;\n\n\t \n\tif (WARN_ON_ONCE(!efx->type->udp_tnl_has_port))\n\t\treturn false;\n\n\t \n\tswitch (skb->protocol) {\n\tcase htons(ETH_P_IP):\n\t\tipproto = ip_hdr(skb)->protocol;\n\t\tbreak;\n\tcase htons(ETH_P_IPV6):\n\t\t \n\t\tipproto = ipv6_hdr(skb)->nexthdr;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn false;\n\t}\n\tswitch (ipproto) {\n\tcase IPPROTO_GRE:\n\t\t \n\t\tif (skb->inner_protocol_type != ENCAP_TYPE_ETHER)\n\t\t\treturn false;\n\t\tif (ntohs(skb->inner_protocol) != ETH_P_TEB)\n\t\t\treturn false;\n\t\tif (skb_inner_mac_header(skb) - skb_transport_header(skb) != 8)\n\t\t\treturn false;\n\t\tgreh = (struct gre_base_hdr *)skb_transport_header(skb);\n\t\treturn !(greh->flags & (GRE_CSUM | GRE_SEQ));\n\tcase IPPROTO_UDP:\n\t\t \n\t\tdst_port = udp_hdr(skb)->dest;\n\t\treturn efx->type->udp_tnl_has_port(efx, dst_port);\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nnetdev_features_t efx_features_check(struct sk_buff *skb, struct net_device *dev,\n\t\t\t\t     netdev_features_t features)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(dev);\n\n\tif (skb->encapsulation) {\n\t\tif (features & NETIF_F_GSO_MASK)\n\t\t\t \n\t\t\tif (skb_inner_transport_offset(skb) >\n\t\t\t    EFX_TSO2_MAX_HDRLEN)\n\t\t\t\tfeatures &= ~(NETIF_F_GSO_MASK);\n\t\tif (features & (NETIF_F_GSO_MASK | NETIF_F_CSUM_MASK))\n\t\t\tif (!efx_can_encap_offloads(efx, skb))\n\t\t\t\tfeatures &= ~(NETIF_F_GSO_MASK |\n\t\t\t\t\t      NETIF_F_CSUM_MASK);\n\t}\n\treturn features;\n}\n\nint efx_get_phys_port_id(struct net_device *net_dev,\n\t\t\t struct netdev_phys_item_id *ppid)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\n\tif (efx->type->get_phys_port_id)\n\t\treturn efx->type->get_phys_port_id(efx, ppid);\n\telse\n\t\treturn -EOPNOTSUPP;\n}\n\nint efx_get_phys_port_name(struct net_device *net_dev, char *name, size_t len)\n{\n\tstruct efx_nic *efx = efx_netdev_priv(net_dev);\n\n\tif (snprintf(name, len, \"p%u\", efx->port_num) >= len)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nvoid efx_detach_reps(struct efx_nic *efx)\n{\n\tstruct net_device *rep_dev;\n\tstruct efx_rep *efv;\n\n\tASSERT_RTNL();\n\tnetif_dbg(efx, drv, efx->net_dev, \"Detaching VF representors\\n\");\n\tlist_for_each_entry(efv, &efx->vf_reps, list) {\n\t\trep_dev = efv->net_dev;\n\t\tif (!rep_dev)\n\t\t\tcontinue;\n\t\tnetif_carrier_off(rep_dev);\n\t\t \n\t\tnetif_tx_lock_bh(rep_dev);\n\t\tnetif_tx_stop_all_queues(rep_dev);\n\t\tnetif_tx_unlock_bh(rep_dev);\n\t}\n}\n\nvoid efx_attach_reps(struct efx_nic *efx)\n{\n\tstruct net_device *rep_dev;\n\tstruct efx_rep *efv;\n\n\tASSERT_RTNL();\n\tnetif_dbg(efx, drv, efx->net_dev, \"Attaching VF representors\\n\");\n\tlist_for_each_entry(efv, &efx->vf_reps, list) {\n\t\trep_dev = efv->net_dev;\n\t\tif (!rep_dev)\n\t\t\tcontinue;\n\t\tnetif_tx_wake_all_queues(rep_dev);\n\t\tnetif_carrier_on(rep_dev);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}