{
  "module_name": "fm10k_pf.c",
  "hash_id": "8a946cb2fa72aecbdad9c78fdce6b8aee28f2f950f3abaecdda32b59b79eb518",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/fm10k/fm10k_pf.c",
  "human_readable_source": "\n \n\n#include \"fm10k_pf.h\"\n#include \"fm10k_vf.h\"\n\n \nstatic s32 fm10k_reset_hw_pf(struct fm10k_hw *hw)\n{\n\ts32 err;\n\tu32 reg;\n\tu16 i;\n\n\t \n\tfm10k_write_reg(hw, FM10K_EIMR, FM10K_EIMR_DISABLE(ALL));\n\n\t \n\tfm10k_write_reg(hw, FM10K_ITR2(0), 0);\n\tfm10k_write_reg(hw, FM10K_INT_CTRL, 0);\n\n\t \n\n\t \n\tfor (i = 0; i < FM10K_TQMAP_TABLE_SIZE; i++) {\n\t\tfm10k_write_reg(hw, FM10K_TQMAP(i), 0);\n\t\tfm10k_write_reg(hw, FM10K_RQMAP(i), 0);\n\t}\n\n\t \n\terr = fm10k_disable_queues_generic(hw, FM10K_MAX_QUEUES);\n\tif (err == FM10K_ERR_REQUESTS_PENDING) {\n\t\thw->mac.reset_while_pending++;\n\t\tgoto force_reset;\n\t} else if (err) {\n\t\treturn err;\n\t}\n\n\t \n\treg = fm10k_read_reg(hw, FM10K_DMA_CTRL);\n\tif (reg & (FM10K_DMA_CTRL_TX_ACTIVE | FM10K_DMA_CTRL_RX_ACTIVE))\n\t\treturn FM10K_ERR_DMA_PENDING;\n\nforce_reset:\n\t \n\treg = FM10K_DMA_CTRL_DATAPATH_RESET;\n\tfm10k_write_reg(hw, FM10K_DMA_CTRL, reg);\n\n\t \n\tfm10k_write_flush(hw);\n\tudelay(FM10K_RESET_TIMEOUT);\n\n\t \n\treg = fm10k_read_reg(hw, FM10K_IP);\n\tif (!(reg & FM10K_IP_NOTINRESET))\n\t\treturn FM10K_ERR_RESET_FAILED;\n\n\treturn 0;\n}\n\n \nstatic bool fm10k_is_ari_hierarchy_pf(struct fm10k_hw *hw)\n{\n\tu16 sriov_ctrl = fm10k_read_pci_cfg_word(hw, FM10K_PCIE_SRIOV_CTRL);\n\n\treturn !!(sriov_ctrl & FM10K_PCIE_SRIOV_CTRL_VFARI);\n}\n\n \nstatic s32 fm10k_init_hw_pf(struct fm10k_hw *hw)\n{\n\tu32 dma_ctrl, txqctl;\n\tu16 i;\n\n\t \n\tfm10k_write_reg(hw, FM10K_DGLORTDEC(fm10k_dglort_default), 0);\n\tfm10k_write_reg(hw, FM10K_DGLORTMAP(fm10k_dglort_default),\n\t\t\tFM10K_DGLORTMAP_ANY);\n\n\t \n\tfor (i = 1; i < FM10K_DGLORT_COUNT; i++)\n\t\tfm10k_write_reg(hw, FM10K_DGLORTMAP(i), FM10K_DGLORTMAP_NONE);\n\n\t \n\tfm10k_write_reg(hw, FM10K_ITR2(0), 0);\n\n\t \n\tfm10k_write_reg(hw, FM10K_ITR2(FM10K_ITR_REG_COUNT_PF), 0);\n\n\t \n\tfor (i = 1; i < FM10K_ITR_REG_COUNT_PF; i++)\n\t\tfm10k_write_reg(hw, FM10K_ITR2(i), i - 1);\n\n\t \n\tfm10k_write_reg(hw, FM10K_INT_CTRL, FM10K_INT_CTRL_ENABLEMODERATOR);\n\n\t \n\ttxqctl = FM10K_TXQCTL_PF | FM10K_TXQCTL_UNLIMITED_BW |\n\t\t (hw->mac.default_vid << FM10K_TXQCTL_VID_SHIFT);\n\n\tfor (i = 0; i < FM10K_MAX_QUEUES; i++) {\n\t\t \n\t\tfm10k_write_reg(hw, FM10K_TQDLOC(i),\n\t\t\t\t(i * FM10K_TQDLOC_BASE_32_DESC) |\n\t\t\t\tFM10K_TQDLOC_SIZE_32_DESC);\n\t\tfm10k_write_reg(hw, FM10K_TXQCTL(i), txqctl);\n\n\t\t \n\t\tfm10k_write_reg(hw, FM10K_TPH_TXCTRL(i),\n\t\t\t\tFM10K_TPH_TXCTRL_DESC_TPHEN |\n\t\t\t\tFM10K_TPH_TXCTRL_DESC_RROEN |\n\t\t\t\tFM10K_TPH_TXCTRL_DESC_WROEN |\n\t\t\t\tFM10K_TPH_TXCTRL_DATA_RROEN);\n\t\tfm10k_write_reg(hw, FM10K_TPH_RXCTRL(i),\n\t\t\t\tFM10K_TPH_RXCTRL_DESC_TPHEN |\n\t\t\t\tFM10K_TPH_RXCTRL_DESC_RROEN |\n\t\t\t\tFM10K_TPH_RXCTRL_DATA_WROEN |\n\t\t\t\tFM10K_TPH_RXCTRL_HDR_WROEN);\n\t}\n\n\t \n\tswitch (hw->bus.speed) {\n\tcase fm10k_bus_speed_2500:\n\t\tdma_ctrl = FM10K_DMA_CTRL_MAX_HOLD_1US_GEN1;\n\t\thw->mac.itr_scale = FM10K_TDLEN_ITR_SCALE_GEN1;\n\t\tbreak;\n\tcase fm10k_bus_speed_5000:\n\t\tdma_ctrl = FM10K_DMA_CTRL_MAX_HOLD_1US_GEN2;\n\t\thw->mac.itr_scale = FM10K_TDLEN_ITR_SCALE_GEN2;\n\t\tbreak;\n\tcase fm10k_bus_speed_8000:\n\t\tdma_ctrl = FM10K_DMA_CTRL_MAX_HOLD_1US_GEN3;\n\t\thw->mac.itr_scale = FM10K_TDLEN_ITR_SCALE_GEN3;\n\t\tbreak;\n\tdefault:\n\t\tdma_ctrl = 0;\n\t\t \n\t\thw->mac.itr_scale = FM10K_TDLEN_ITR_SCALE_GEN3;\n\t\tbreak;\n\t}\n\n\t \n\tfm10k_write_reg(hw, FM10K_DTXTCPFLGL, FM10K_TSO_FLAGS_LOW);\n\tfm10k_write_reg(hw, FM10K_DTXTCPFLGH, FM10K_TSO_FLAGS_HI);\n\n\t \n\tdma_ctrl |= FM10K_DMA_CTRL_TX_ENABLE | FM10K_DMA_CTRL_RX_ENABLE |\n\t\t    FM10K_DMA_CTRL_RX_DESC_SIZE | FM10K_DMA_CTRL_MINMSS_64 |\n\t\t    FM10K_DMA_CTRL_32_DESC;\n\n\tfm10k_write_reg(hw, FM10K_DMA_CTRL, dma_ctrl);\n\n\t \n\thw->mac.max_queues = FM10K_MAX_QUEUES_PF;\n\n\t \n\thw->iov.total_vfs = fm10k_is_ari_hierarchy_pf(hw) ? 64 : 7;\n\n\treturn 0;\n}\n\n \nstatic s32 fm10k_update_vlan_pf(struct fm10k_hw *hw, u32 vid, u8 vsi, bool set)\n{\n\tu32 vlan_table, reg, mask, bit, len;\n\n\t \n\tif (vsi > FM10K_VLAN_TABLE_VSI_MAX)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tlen = vid >> 16;\n\tvid = (vid << 17) >> 17;\n\n\t \n\tif (len >= FM10K_VLAN_TABLE_VID_MAX || vid >= FM10K_VLAN_TABLE_VID_MAX)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tfor (reg = FM10K_VLAN_TABLE(vsi, vid / 32), bit = vid % 32;\n\t     len < FM10K_VLAN_TABLE_VID_MAX;\n\t     len -= 32 - bit, reg++, bit = 0) {\n\t\t \n\t\tvlan_table = fm10k_read_reg(hw, reg);\n\n\t\t \n\t\tmask = (~(u32)0 >> ((len < 31) ? 31 - len : 0)) << bit;\n\n\t\t \n\t\tmask &= set ? ~vlan_table : vlan_table;\n\t\tif (mask)\n\t\t\tfm10k_write_reg(hw, reg, vlan_table ^ mask);\n\t}\n\n\treturn 0;\n}\n\n \nstatic s32 fm10k_read_mac_addr_pf(struct fm10k_hw *hw)\n{\n\tu8 perm_addr[ETH_ALEN];\n\tu32 serial_num;\n\n\tserial_num = fm10k_read_reg(hw, FM10K_SM_AREA(1));\n\n\t \n\tif ((~serial_num) << 24)\n\t\treturn  FM10K_ERR_INVALID_MAC_ADDR;\n\n\tperm_addr[0] = (u8)(serial_num >> 24);\n\tperm_addr[1] = (u8)(serial_num >> 16);\n\tperm_addr[2] = (u8)(serial_num >> 8);\n\n\tserial_num = fm10k_read_reg(hw, FM10K_SM_AREA(0));\n\n\t \n\tif ((~serial_num) >> 24)\n\t\treturn  FM10K_ERR_INVALID_MAC_ADDR;\n\n\tperm_addr[3] = (u8)(serial_num >> 16);\n\tperm_addr[4] = (u8)(serial_num >> 8);\n\tperm_addr[5] = (u8)(serial_num);\n\n\tether_addr_copy(hw->mac.perm_addr, perm_addr);\n\tether_addr_copy(hw->mac.addr, perm_addr);\n\n\treturn 0;\n}\n\n \nbool fm10k_glort_valid_pf(struct fm10k_hw *hw, u16 glort)\n{\n\tglort &= hw->mac.dglort_map >> FM10K_DGLORTMAP_MASK_SHIFT;\n\n\treturn glort == (hw->mac.dglort_map & FM10K_DGLORTMAP_NONE);\n}\n\n \nstatic s32 fm10k_update_xc_addr_pf(struct fm10k_hw *hw, u16 glort,\n\t\t\t\t   const u8 *mac, u16 vid, bool add, u8 flags)\n{\n\tstruct fm10k_mbx_info *mbx = &hw->mbx;\n\tstruct fm10k_mac_update mac_update;\n\tu32 msg[5];\n\n\t \n\tvid &= ~FM10K_VLAN_CLEAR;\n\n\t \n\tif (!fm10k_glort_valid_pf(hw, glort) || vid >= FM10K_VLAN_TABLE_VID_MAX)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tmac_update.mac_lower = cpu_to_le32(((u32)mac[2] << 24) |\n\t\t\t\t\t\t ((u32)mac[3] << 16) |\n\t\t\t\t\t\t ((u32)mac[4] << 8) |\n\t\t\t\t\t\t ((u32)mac[5]));\n\tmac_update.mac_upper = cpu_to_le16(((u16)mac[0] << 8) |\n\t\t\t\t\t   ((u16)mac[1]));\n\tmac_update.vlan = cpu_to_le16(vid);\n\tmac_update.glort = cpu_to_le16(glort);\n\tmac_update.action = add ? 0 : 1;\n\tmac_update.flags = flags;\n\n\t \n\tfm10k_tlv_msg_init(msg, FM10K_PF_MSG_ID_UPDATE_MAC_FWD_RULE);\n\tfm10k_tlv_attr_put_le_struct(msg, FM10K_PF_ATTR_ID_MAC_UPDATE,\n\t\t\t\t     &mac_update, sizeof(mac_update));\n\n\t \n\treturn mbx->ops.enqueue_tx(hw, mbx, msg);\n}\n\n \nstatic s32 fm10k_update_uc_addr_pf(struct fm10k_hw *hw, u16 glort,\n\t\t\t\t   const u8 *mac, u16 vid, bool add, u8 flags)\n{\n\t \n\tif (!is_valid_ether_addr(mac))\n\t\treturn FM10K_ERR_PARAM;\n\n\treturn fm10k_update_xc_addr_pf(hw, glort, mac, vid, add, flags);\n}\n\n \nstatic s32 fm10k_update_mc_addr_pf(struct fm10k_hw *hw, u16 glort,\n\t\t\t\t   const u8 *mac, u16 vid, bool add)\n{\n\t \n\tif (!is_multicast_ether_addr(mac))\n\t\treturn FM10K_ERR_PARAM;\n\n\treturn fm10k_update_xc_addr_pf(hw, glort, mac, vid, add, 0);\n}\n\n \nstatic s32 fm10k_update_xcast_mode_pf(struct fm10k_hw *hw, u16 glort, u8 mode)\n{\n\tstruct fm10k_mbx_info *mbx = &hw->mbx;\n\tu32 msg[3], xcast_mode;\n\n\tif (mode > FM10K_XCAST_MODE_NONE)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tif (!fm10k_glort_valid_pf(hw, glort))\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\txcast_mode = ((u32)mode << 16) | glort;\n\n\t \n\tfm10k_tlv_msg_init(msg, FM10K_PF_MSG_ID_XCAST_MODES);\n\tfm10k_tlv_attr_put_u32(msg, FM10K_PF_ATTR_ID_XCAST_MODE, xcast_mode);\n\n\t \n\treturn mbx->ops.enqueue_tx(hw, mbx, msg);\n}\n\n \nstatic void fm10k_update_int_moderator_pf(struct fm10k_hw *hw)\n{\n\tu32 i;\n\n\t \n\tfm10k_write_reg(hw, FM10K_INT_CTRL, 0);\n\n\t \n\tfor (i = FM10K_ITR_REG_COUNT_PF - 1; i; i--) {\n\t\tif (!fm10k_read_reg(hw, FM10K_MSIX_VECTOR_MASK(i)))\n\t\t\tbreak;\n\t}\n\n\t \n\tfm10k_write_reg(hw, FM10K_ITR2(FM10K_ITR_REG_COUNT_PF), i);\n\n\t \n\tif (!hw->iov.num_vfs)\n\t\tfm10k_write_reg(hw, FM10K_ITR2(0), i);\n\n\t \n\tfm10k_write_reg(hw, FM10K_INT_CTRL, FM10K_INT_CTRL_ENABLEMODERATOR);\n}\n\n \nstatic s32 fm10k_update_lport_state_pf(struct fm10k_hw *hw, u16 glort,\n\t\t\t\t       u16 count, bool enable)\n{\n\tstruct fm10k_mbx_info *mbx = &hw->mbx;\n\tu32 msg[3], lport_msg;\n\n\t \n\tif (!count)\n\t\treturn 0;\n\n\t \n\tif (!fm10k_glort_valid_pf(hw, glort))\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tif (!enable)\n\t\tfm10k_update_xcast_mode_pf(hw, glort, FM10K_XCAST_MODE_NONE);\n\n\t \n\tlport_msg = ((u32)count << 16) | glort;\n\n\t \n\tfm10k_tlv_msg_init(msg, enable ? FM10K_PF_MSG_ID_LPORT_CREATE :\n\t\t\t\t\t FM10K_PF_MSG_ID_LPORT_DELETE);\n\tfm10k_tlv_attr_put_u32(msg, FM10K_PF_ATTR_ID_PORT, lport_msg);\n\n\t \n\treturn mbx->ops.enqueue_tx(hw, mbx, msg);\n}\n\n \nstatic s32 fm10k_configure_dglort_map_pf(struct fm10k_hw *hw,\n\t\t\t\t\t struct fm10k_dglort_cfg *dglort)\n{\n\tu16 glort, queue_count, vsi_count, pc_count;\n\tu16 vsi, queue, pc, q_idx;\n\tu32 txqctl, dglortdec, dglortmap;\n\n\t \n\tif (!dglort)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tif ((dglort->idx > 7) || (dglort->rss_l > 7) || (dglort->pc_l > 3) ||\n\t    (dglort->vsi_l > 6) || (dglort->vsi_b > 64) ||\n\t    (dglort->queue_l > 8) || (dglort->queue_b >= 256))\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tqueue_count = BIT(dglort->rss_l + dglort->pc_l);\n\tvsi_count = BIT(dglort->vsi_l + dglort->queue_l);\n\tglort = dglort->glort;\n\tq_idx = dglort->queue_b;\n\n\t \n\tfor (vsi = 0; vsi < vsi_count; vsi++, glort++) {\n\t\tfor (queue = 0; queue < queue_count; queue++, q_idx++) {\n\t\t\tif (q_idx >= FM10K_MAX_QUEUES)\n\t\t\t\tbreak;\n\n\t\t\tfm10k_write_reg(hw, FM10K_TX_SGLORT(q_idx), glort);\n\t\t\tfm10k_write_reg(hw, FM10K_RX_SGLORT(q_idx), glort);\n\t\t}\n\t}\n\n\t \n\tqueue_count = BIT(dglort->queue_l + dglort->rss_l + dglort->vsi_l);\n\tpc_count = BIT(dglort->pc_l);\n\n\t \n\tfor (pc = 0; pc < pc_count; pc++) {\n\t\tq_idx = pc + dglort->queue_b;\n\t\tfor (queue = 0; queue < queue_count; queue++) {\n\t\t\tif (q_idx >= FM10K_MAX_QUEUES)\n\t\t\t\tbreak;\n\n\t\t\ttxqctl = fm10k_read_reg(hw, FM10K_TXQCTL(q_idx));\n\t\t\ttxqctl &= ~FM10K_TXQCTL_PC_MASK;\n\t\t\ttxqctl |= pc << FM10K_TXQCTL_PC_SHIFT;\n\t\t\tfm10k_write_reg(hw, FM10K_TXQCTL(q_idx), txqctl);\n\n\t\t\tq_idx += pc_count;\n\t\t}\n\t}\n\n\t \n\tdglortdec = ((u32)(dglort->rss_l) << FM10K_DGLORTDEC_RSSLENGTH_SHIFT) |\n\t\t    ((u32)(dglort->queue_b) << FM10K_DGLORTDEC_QBASE_SHIFT) |\n\t\t    ((u32)(dglort->pc_l) << FM10K_DGLORTDEC_PCLENGTH_SHIFT) |\n\t\t    ((u32)(dglort->vsi_b) << FM10K_DGLORTDEC_VSIBASE_SHIFT) |\n\t\t    ((u32)(dglort->vsi_l) << FM10K_DGLORTDEC_VSILENGTH_SHIFT) |\n\t\t    ((u32)(dglort->queue_l));\n\tif (dglort->inner_rss)\n\t\tdglortdec |=  FM10K_DGLORTDEC_INNERRSS_ENABLE;\n\n\t \n\tdglortmap = (dglort->idx == fm10k_dglort_default) ?\n\t\t\tFM10K_DGLORTMAP_ANY : FM10K_DGLORTMAP_ZERO;\n\tdglortmap <<= dglort->vsi_l + dglort->queue_l + dglort->shared_l;\n\tdglortmap |= dglort->glort;\n\n\t \n\tfm10k_write_reg(hw, FM10K_DGLORTDEC(dglort->idx), dglortdec);\n\tfm10k_write_reg(hw, FM10K_DGLORTMAP(dglort->idx), dglortmap);\n\n\treturn 0;\n}\n\nu16 fm10k_queues_per_pool(struct fm10k_hw *hw)\n{\n\tu16 num_pools = hw->iov.num_pools;\n\n\treturn (num_pools > 32) ? 2 : (num_pools > 16) ? 4 : (num_pools > 8) ?\n\t       8 : FM10K_MAX_QUEUES_POOL;\n}\n\nu16 fm10k_vf_queue_index(struct fm10k_hw *hw, u16 vf_idx)\n{\n\tu16 num_vfs = hw->iov.num_vfs;\n\tu16 vf_q_idx = FM10K_MAX_QUEUES;\n\n\tvf_q_idx -= fm10k_queues_per_pool(hw) * (num_vfs - vf_idx);\n\n\treturn vf_q_idx;\n}\n\nstatic u16 fm10k_vectors_per_pool(struct fm10k_hw *hw)\n{\n\tu16 num_pools = hw->iov.num_pools;\n\n\treturn (num_pools > 32) ? 8 : (num_pools > 16) ? 16 :\n\t       FM10K_MAX_VECTORS_POOL;\n}\n\nstatic u16 fm10k_vf_vector_index(struct fm10k_hw *hw, u16 vf_idx)\n{\n\tu16 vf_v_idx = FM10K_MAX_VECTORS_PF;\n\n\tvf_v_idx += fm10k_vectors_per_pool(hw) * vf_idx;\n\n\treturn vf_v_idx;\n}\n\n \nstatic s32 fm10k_iov_assign_resources_pf(struct fm10k_hw *hw, u16 num_vfs,\n\t\t\t\t\t u16 num_pools)\n{\n\tu16 qmap_stride, qpp, vpp, vf_q_idx, vf_q_idx0, qmap_idx;\n\tu32 vid = hw->mac.default_vid << FM10K_TXQCTL_VID_SHIFT;\n\tint i, j;\n\n\t \n\tif (num_pools > 64)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tif ((num_vfs > num_pools) || (num_vfs > hw->iov.total_vfs))\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\thw->iov.num_vfs = num_vfs;\n\thw->iov.num_pools = num_pools;\n\n\t \n\tqmap_stride = (num_vfs > 8) ? 32 : 256;\n\tqpp = fm10k_queues_per_pool(hw);\n\tvpp = fm10k_vectors_per_pool(hw);\n\n\t \n\tvf_q_idx = fm10k_vf_queue_index(hw, 0);\n\tqmap_idx = 0;\n\n\t \n\tfor (i = 0; i < num_vfs; i++) {\n\t\tfm10k_write_reg(hw, FM10K_TC_MAXCREDIT(i), 0);\n\t\tfm10k_write_reg(hw, FM10K_TC_RATE(i), 0);\n\t\tfm10k_write_reg(hw, FM10K_TC_CREDIT(i),\n\t\t\t\tFM10K_TC_CREDIT_CREDIT_MASK);\n\t}\n\n\t \n\tfor (i = FM10K_VFMBMEM_LEN * num_vfs; i--;)\n\t\tfm10k_write_reg(hw, FM10K_MBMEM(i), 0);\n\n\t \n\tfm10k_write_reg(hw, FM10K_PFVFLREC(0), ~0);\n\tfm10k_write_reg(hw, FM10K_PFVFLREC(1), ~0);\n\n\t \n\tfor (i = FM10K_MAX_QUEUES_PF; i < vf_q_idx; i++) {\n\t\tfm10k_write_reg(hw, FM10K_TXDCTL(i), 0);\n\t\tfm10k_write_reg(hw, FM10K_TXQCTL(i), FM10K_TXQCTL_PF |\n\t\t\t\tFM10K_TXQCTL_UNLIMITED_BW | vid);\n\t\tfm10k_write_reg(hw, FM10K_RXQCTL(i), FM10K_RXQCTL_PF);\n\t}\n\n\t \n\n\t \n\tfor (i = FM10K_ITR_REG_COUNT_PF + 1; i < FM10K_ITR_REG_COUNT; i++) {\n\t\tif (!(i & (vpp - 1)))\n\t\t\tfm10k_write_reg(hw, FM10K_ITR2(i), i - vpp);\n\t\telse\n\t\t\tfm10k_write_reg(hw, FM10K_ITR2(i), i - 1);\n\t}\n\n\t \n\tfm10k_write_reg(hw, FM10K_ITR2(0),\n\t\t\tfm10k_vf_vector_index(hw, num_vfs - 1));\n\n\t \n\tfor (i = 0; i < num_vfs; i++) {\n\t\t \n\t\tvf_q_idx0 = vf_q_idx;\n\n\t\tfor (j = 0; j < qpp; j++, qmap_idx++, vf_q_idx++) {\n\t\t\t \n\t\t\tfm10k_write_reg(hw, FM10K_TXDCTL(vf_q_idx), 0);\n\t\t\tfm10k_write_reg(hw, FM10K_TXQCTL(vf_q_idx),\n\t\t\t\t\t(i << FM10K_TXQCTL_TC_SHIFT) | i |\n\t\t\t\t\tFM10K_TXQCTL_VF | vid);\n\t\t\tfm10k_write_reg(hw, FM10K_RXDCTL(vf_q_idx),\n\t\t\t\t\tFM10K_RXDCTL_WRITE_BACK_MIN_DELAY |\n\t\t\t\t\tFM10K_RXDCTL_DROP_ON_EMPTY);\n\t\t\tfm10k_write_reg(hw, FM10K_RXQCTL(vf_q_idx),\n\t\t\t\t\t(i << FM10K_RXQCTL_VF_SHIFT) |\n\t\t\t\t\tFM10K_RXQCTL_VF);\n\n\t\t\t \n\t\t\tfm10k_write_reg(hw, FM10K_TQMAP(qmap_idx), vf_q_idx);\n\t\t\tfm10k_write_reg(hw, FM10K_RQMAP(qmap_idx), vf_q_idx);\n\t\t}\n\n\t\t \n\t\tfor (; j < qmap_stride; j++, qmap_idx++) {\n\t\t\tfm10k_write_reg(hw, FM10K_TQMAP(qmap_idx), vf_q_idx0);\n\t\t\tfm10k_write_reg(hw, FM10K_RQMAP(qmap_idx), vf_q_idx0);\n\t\t}\n\t}\n\n\t \n\twhile (qmap_idx < FM10K_TQMAP_TABLE_SIZE) {\n\t\tfm10k_write_reg(hw, FM10K_TQMAP(qmap_idx), 0);\n\t\tfm10k_write_reg(hw, FM10K_RQMAP(qmap_idx), 0);\n\t\tqmap_idx++;\n\t}\n\n\treturn 0;\n}\n\n \nstatic s32 fm10k_iov_configure_tc_pf(struct fm10k_hw *hw, u16 vf_idx, int rate)\n{\n\t \n\tu32 interval = FM10K_TC_RATE_INTERVAL_4US_GEN3;\n\tu32 tc_rate = FM10K_TC_RATE_QUANTA_MASK;\n\n\t \n\tif (vf_idx >= hw->iov.num_vfs)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tswitch (hw->bus.speed) {\n\tcase fm10k_bus_speed_2500:\n\t\tinterval = FM10K_TC_RATE_INTERVAL_4US_GEN1;\n\t\tbreak;\n\tcase fm10k_bus_speed_5000:\n\t\tinterval = FM10K_TC_RATE_INTERVAL_4US_GEN2;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (rate) {\n\t\tif (rate > FM10K_VF_TC_MAX || rate < FM10K_VF_TC_MIN)\n\t\t\treturn FM10K_ERR_PARAM;\n\n\t\t \n\t\ttc_rate = (rate * 128) / 125;\n\n\t\t \n\t\tif (rate < 4000)\n\t\t\tinterval <<= 1;\n\t\telse\n\t\t\ttc_rate >>= 1;\n\t}\n\n\t \n\tfm10k_write_reg(hw, FM10K_TC_RATE(vf_idx), tc_rate | interval);\n\tfm10k_write_reg(hw, FM10K_TC_MAXCREDIT(vf_idx), FM10K_TC_MAXCREDIT_64K);\n\tfm10k_write_reg(hw, FM10K_TC_CREDIT(vf_idx), FM10K_TC_MAXCREDIT_64K);\n\n\treturn 0;\n}\n\n \nstatic s32 fm10k_iov_assign_int_moderator_pf(struct fm10k_hw *hw, u16 vf_idx)\n{\n\tu16 vf_v_idx, vf_v_limit, i;\n\n\t \n\tif (vf_idx >= hw->iov.num_vfs)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tvf_v_idx = fm10k_vf_vector_index(hw, vf_idx);\n\tvf_v_limit = vf_v_idx + fm10k_vectors_per_pool(hw);\n\n\t \n\tfor (i = vf_v_limit - 1; i > vf_v_idx; i--) {\n\t\tif (!fm10k_read_reg(hw, FM10K_MSIX_VECTOR_MASK(i)))\n\t\t\tbreak;\n\t}\n\n\t \n\tif (vf_idx == (hw->iov.num_vfs - 1))\n\t\tfm10k_write_reg(hw, FM10K_ITR2(0), i);\n\telse\n\t\tfm10k_write_reg(hw, FM10K_ITR2(vf_v_limit), i);\n\n\treturn 0;\n}\n\n \nstatic s32 fm10k_iov_assign_default_mac_vlan_pf(struct fm10k_hw *hw,\n\t\t\t\t\t\tstruct fm10k_vf_info *vf_info)\n{\n\tu16 qmap_stride, queues_per_pool, vf_q_idx, timeout, qmap_idx, i;\n\tu32 msg[4], txdctl, txqctl, tdbal = 0, tdbah = 0;\n\ts32 err = 0;\n\tu16 vf_idx, vf_vid;\n\n\t \n\tif (!vf_info || vf_info->vf_idx >= hw->iov.num_vfs)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tqmap_stride = (hw->iov.num_vfs > 8) ? 32 : 256;\n\tqueues_per_pool = fm10k_queues_per_pool(hw);\n\n\t \n\tvf_idx = vf_info->vf_idx;\n\tvf_q_idx = fm10k_vf_queue_index(hw, vf_idx);\n\tqmap_idx = qmap_stride * vf_idx;\n\n\t \n\tif (vf_info->pf_vid)\n\t\tvf_vid = vf_info->pf_vid | FM10K_VLAN_OVERRIDE;\n\telse\n\t\tvf_vid = vf_info->sw_vid;\n\n\t \n\tfm10k_tlv_msg_init(msg, FM10K_VF_MSG_ID_MAC_VLAN);\n\tfm10k_tlv_attr_put_mac_vlan(msg, FM10K_MAC_VLAN_MSG_DEFAULT_MAC,\n\t\t\t\t    vf_info->mac, vf_vid);\n\n\t \n\ttxqctl = ((u32)vf_vid << FM10K_TXQCTL_VID_SHIFT) &\n\t\t FM10K_TXQCTL_VID_MASK;\n\ttxqctl |= (vf_idx << FM10K_TXQCTL_TC_SHIFT) |\n\t\t  FM10K_TXQCTL_VF | vf_idx;\n\n\tfor (i = 0; i < queues_per_pool; i++)\n\t\tfm10k_write_reg(hw, FM10K_TXQCTL(vf_q_idx + i), txqctl);\n\n\t \n\tif (vf_info->mbx.ops.enqueue_tx) {\n\t\terr = vf_info->mbx.ops.enqueue_tx(hw, &vf_info->mbx, msg);\n\t\tif (err != FM10K_MBX_ERR_NO_MBX)\n\t\t\treturn err;\n\t\terr = 0;\n\t}\n\n\t \n\n\t \n\tfm10k_write_reg(hw, FM10K_TQMAP(qmap_idx), 0);\n\tfm10k_write_reg(hw, FM10K_TXDCTL(vf_q_idx), 0);\n\n\t \n\ttxdctl = fm10k_read_reg(hw, FM10K_TXDCTL(vf_q_idx));\n\tfor (timeout = 0; txdctl & FM10K_TXDCTL_ENABLE; timeout++) {\n\t\t \n\t\tif (timeout == 10) {\n\t\t\terr = FM10K_ERR_DMA_PENDING;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tusleep_range(100, 200);\n\t\ttxdctl = fm10k_read_reg(hw, FM10K_TXDCTL(vf_q_idx));\n\t}\n\n\t \n\tif (is_valid_ether_addr(vf_info->mac)) {\n\t\ttdbal = (((u32)vf_info->mac[3]) << 24) |\n\t\t\t(((u32)vf_info->mac[4]) << 16) |\n\t\t\t(((u32)vf_info->mac[5]) << 8);\n\n\t\ttdbah = (((u32)0xFF)\t        << 24) |\n\t\t\t(((u32)vf_info->mac[0]) << 16) |\n\t\t\t(((u32)vf_info->mac[1]) << 8) |\n\t\t\t((u32)vf_info->mac[2]);\n\t}\n\n\t \n\tfm10k_write_reg(hw, FM10K_TDBAL(vf_q_idx), tdbal);\n\tfm10k_write_reg(hw, FM10K_TDBAH(vf_q_idx), tdbah);\n\n\t \n\tfm10k_write_reg(hw, FM10K_TDLEN(vf_q_idx), hw->mac.itr_scale <<\n\t\t\t\t\t\t   FM10K_TDLEN_ITR_SCALE_SHIFT);\n\nerr_out:\n\t \n\tfm10k_write_reg(hw, FM10K_TQMAP(qmap_idx), vf_q_idx);\n\treturn err;\n}\n\n \nstatic s32 fm10k_iov_reset_resources_pf(struct fm10k_hw *hw,\n\t\t\t\t\tstruct fm10k_vf_info *vf_info)\n{\n\tu16 qmap_stride, queues_per_pool, vf_q_idx, qmap_idx;\n\tu32 tdbal = 0, tdbah = 0, txqctl, rxqctl;\n\tu16 vf_v_idx, vf_v_limit, vf_vid;\n\tu8 vf_idx = vf_info->vf_idx;\n\tint i;\n\n\t \n\tif (vf_idx >= hw->iov.num_vfs)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tfm10k_write_reg(hw, FM10K_PFVFLREC(vf_idx / 32), BIT(vf_idx % 32));\n\n\t \n\tvf_info->mbx.timeout = 0;\n\tif (vf_info->mbx.ops.disconnect)\n\t\tvf_info->mbx.ops.disconnect(hw, &vf_info->mbx);\n\n\t \n\tvf_v_idx = fm10k_vf_vector_index(hw, vf_idx);\n\tvf_v_limit = vf_v_idx + fm10k_vectors_per_pool(hw);\n\n\t \n\tqmap_stride = (hw->iov.num_vfs > 8) ? 32 : 256;\n\tqueues_per_pool = fm10k_queues_per_pool(hw);\n\tqmap_idx = qmap_stride * vf_idx;\n\n\t \n\tfor (i = qmap_idx; i < (qmap_idx + qmap_stride); i++) {\n\t\tfm10k_write_reg(hw, FM10K_TQMAP(i), 0);\n\t\tfm10k_write_reg(hw, FM10K_RQMAP(i), 0);\n\t}\n\n\t \n\tvf_q_idx = fm10k_vf_queue_index(hw, vf_idx);\n\n\t \n\tif (vf_info->pf_vid)\n\t\tvf_vid = vf_info->pf_vid;\n\telse\n\t\tvf_vid = vf_info->sw_vid;\n\n\t \n\ttxqctl = ((u32)vf_vid << FM10K_TXQCTL_VID_SHIFT) |\n\t\t (vf_idx << FM10K_TXQCTL_TC_SHIFT) |\n\t\t FM10K_TXQCTL_VF | vf_idx;\n\trxqctl = (vf_idx << FM10K_RXQCTL_VF_SHIFT) | FM10K_RXQCTL_VF;\n\n\t \n\tfor (i = vf_q_idx; i < (queues_per_pool + vf_q_idx); i++) {\n\t\tfm10k_write_reg(hw, FM10K_TXDCTL(i), 0);\n\t\tfm10k_write_reg(hw, FM10K_TXQCTL(i), txqctl);\n\t\tfm10k_write_reg(hw, FM10K_RXDCTL(i),\n\t\t\t\tFM10K_RXDCTL_WRITE_BACK_MIN_DELAY |\n\t\t\t\tFM10K_RXDCTL_DROP_ON_EMPTY);\n\t\tfm10k_write_reg(hw, FM10K_RXQCTL(i), rxqctl);\n\t}\n\n\t \n\tfm10k_write_reg(hw, FM10K_TC_MAXCREDIT(vf_idx), 0);\n\tfm10k_write_reg(hw, FM10K_TC_RATE(vf_idx), 0);\n\tfm10k_write_reg(hw, FM10K_TC_CREDIT(vf_idx),\n\t\t\tFM10K_TC_CREDIT_CREDIT_MASK);\n\n\t \n\tif (!vf_idx)\n\t\thw->mac.ops.update_int_moderator(hw);\n\telse\n\t\thw->iov.ops.assign_int_moderator(hw, vf_idx - 1);\n\n\t \n\tif (vf_idx == (hw->iov.num_vfs - 1))\n\t\tfm10k_write_reg(hw, FM10K_ITR2(0), vf_v_idx);\n\telse\n\t\tfm10k_write_reg(hw, FM10K_ITR2(vf_v_limit), vf_v_idx);\n\n\t \n\tfor (vf_v_idx++; vf_v_idx < vf_v_limit; vf_v_idx++)\n\t\tfm10k_write_reg(hw, FM10K_ITR2(vf_v_idx), vf_v_idx - 1);\n\n\t \n\tfor (i = FM10K_VFMBMEM_LEN; i--;)\n\t\tfm10k_write_reg(hw, FM10K_MBMEM_VF(vf_idx, i), 0);\n\tfor (i = FM10K_VLAN_TABLE_SIZE; i--;)\n\t\tfm10k_write_reg(hw, FM10K_VLAN_TABLE(vf_info->vsi, i), 0);\n\tfor (i = FM10K_RETA_SIZE; i--;)\n\t\tfm10k_write_reg(hw, FM10K_RETA(vf_info->vsi, i), 0);\n\tfor (i = FM10K_RSSRK_SIZE; i--;)\n\t\tfm10k_write_reg(hw, FM10K_RSSRK(vf_info->vsi, i), 0);\n\tfm10k_write_reg(hw, FM10K_MRQC(vf_info->vsi), 0);\n\n\t \n\tif (is_valid_ether_addr(vf_info->mac)) {\n\t\ttdbal = (((u32)vf_info->mac[3]) << 24) |\n\t\t\t(((u32)vf_info->mac[4]) << 16) |\n\t\t\t(((u32)vf_info->mac[5]) << 8);\n\t\ttdbah = (((u32)0xFF)\t   << 24) |\n\t\t\t(((u32)vf_info->mac[0]) << 16) |\n\t\t\t(((u32)vf_info->mac[1]) << 8) |\n\t\t\t((u32)vf_info->mac[2]);\n\t}\n\n\t \n\tfor (i = queues_per_pool; i--;) {\n\t\tfm10k_write_reg(hw, FM10K_TDBAL(vf_q_idx + i), tdbal);\n\t\tfm10k_write_reg(hw, FM10K_TDBAH(vf_q_idx + i), tdbah);\n\t\t \n\t\tfm10k_write_reg(hw, FM10K_TDLEN(vf_q_idx + i),\n\t\t\t\thw->mac.itr_scale <<\n\t\t\t\tFM10K_TDLEN_ITR_SCALE_SHIFT);\n\t\tfm10k_write_reg(hw, FM10K_TQMAP(qmap_idx + i), vf_q_idx + i);\n\t\tfm10k_write_reg(hw, FM10K_RQMAP(qmap_idx + i), vf_q_idx + i);\n\t}\n\n\t \n\tfor (i = queues_per_pool; i < qmap_stride; i++) {\n\t\tfm10k_write_reg(hw, FM10K_TQMAP(qmap_idx + i), vf_q_idx);\n\t\tfm10k_write_reg(hw, FM10K_RQMAP(qmap_idx + i), vf_q_idx);\n\t}\n\n\treturn 0;\n}\n\n \nstatic s32 fm10k_iov_set_lport_pf(struct fm10k_hw *hw,\n\t\t\t\t  struct fm10k_vf_info *vf_info,\n\t\t\t\t  u16 lport_idx, u8 flags)\n{\n\tu16 glort = (hw->mac.dglort_map + lport_idx) & FM10K_DGLORTMAP_NONE;\n\n\t \n\tif (!fm10k_glort_valid_pf(hw, glort))\n\t\treturn FM10K_ERR_PARAM;\n\n\tvf_info->vf_flags = flags | FM10K_VF_FLAG_NONE_CAPABLE;\n\tvf_info->glort = glort;\n\n\treturn 0;\n}\n\n \nstatic void fm10k_iov_reset_lport_pf(struct fm10k_hw *hw,\n\t\t\t\t     struct fm10k_vf_info *vf_info)\n{\n\tu32 msg[1];\n\n\t \n\tif (FM10K_VF_FLAG_ENABLED(vf_info)) {\n\t\t \n\t\tfm10k_update_lport_state_pf(hw, vf_info->glort, 1, false);\n\n\t\t \n\t\tfm10k_tlv_msg_init(msg, FM10K_VF_MSG_ID_LPORT_STATE);\n\t\tvf_info->mbx.ops.enqueue_tx(hw, &vf_info->mbx, msg);\n\t}\n\n\t \n\tvf_info->vf_flags = 0;\n\tvf_info->glort = 0;\n}\n\n \nstatic void fm10k_iov_update_stats_pf(struct fm10k_hw *hw,\n\t\t\t\t      struct fm10k_hw_stats_q *q,\n\t\t\t\t      u16 vf_idx)\n{\n\tu32 idx, qpp;\n\n\t \n\tqpp = fm10k_queues_per_pool(hw);\n\tidx = fm10k_vf_queue_index(hw, vf_idx);\n\tfm10k_update_hw_stats_q(hw, q, idx, qpp);\n}\n\n \ns32 fm10k_iov_msg_msix_pf(struct fm10k_hw *hw, u32 __always_unused **results,\n\t\t\t  struct fm10k_mbx_info *mbx)\n{\n\tstruct fm10k_vf_info *vf_info = (struct fm10k_vf_info *)mbx;\n\tu8 vf_idx = vf_info->vf_idx;\n\n\treturn hw->iov.ops.assign_int_moderator(hw, vf_idx);\n}\n\n \ns32 fm10k_iov_select_vid(struct fm10k_vf_info *vf_info, u16 vid)\n{\n\tif (!vid)\n\t\treturn vf_info->pf_vid ? vf_info->pf_vid : vf_info->sw_vid;\n\telse if (vf_info->pf_vid && vid != vf_info->pf_vid)\n\t\treturn FM10K_ERR_PARAM;\n\telse\n\t\treturn vid;\n}\n\n \ns32 fm10k_iov_msg_mac_vlan_pf(struct fm10k_hw *hw, u32 **results,\n\t\t\t      struct fm10k_mbx_info *mbx)\n{\n\tstruct fm10k_vf_info *vf_info = (struct fm10k_vf_info *)mbx;\n\tu8 mac[ETH_ALEN];\n\tu32 *result;\n\tint err = 0;\n\tbool set;\n\tu16 vlan;\n\tu32 vid;\n\n\t \n\tif (!FM10K_VF_FLAG_ENABLED(vf_info))\n\t\terr = FM10K_ERR_PARAM;\n\n\tif (!err && !!results[FM10K_MAC_VLAN_MSG_VLAN]) {\n\t\tresult = results[FM10K_MAC_VLAN_MSG_VLAN];\n\n\t\t \n\t\terr = fm10k_tlv_attr_get_u32(result, &vid);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tset = !(vid & FM10K_VLAN_CLEAR);\n\t\tvid &= ~FM10K_VLAN_CLEAR;\n\n\t\t \n\n\t\tif (vid >> 16) {\n\t\t\t \n\t\t\tif (vf_info->pf_vid)\n\t\t\t\treturn FM10K_ERR_PARAM;\n\t\t} else {\n\t\t\terr = fm10k_iov_select_vid(vf_info, (u16)vid);\n\t\t\tif (err < 0)\n\t\t\t\treturn err;\n\n\t\t\tvid = err;\n\t\t}\n\n\t\t \n\t\terr = hw->mac.ops.update_vlan(hw, vid, vf_info->vsi, set);\n\t}\n\n\tif (!err && !!results[FM10K_MAC_VLAN_MSG_MAC]) {\n\t\tresult = results[FM10K_MAC_VLAN_MSG_MAC];\n\n\t\t \n\t\terr = fm10k_tlv_attr_get_mac_vlan(result, mac, &vlan);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t \n\t\tif (is_valid_ether_addr(vf_info->mac) &&\n\t\t    !ether_addr_equal(mac, vf_info->mac))\n\t\t\treturn FM10K_ERR_PARAM;\n\n\t\tset = !(vlan & FM10K_VLAN_CLEAR);\n\t\tvlan &= ~FM10K_VLAN_CLEAR;\n\n\t\terr = fm10k_iov_select_vid(vf_info, vlan);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tvlan = (u16)err;\n\n\t\t \n\t\terr = hw->mac.ops.update_uc_addr(hw, vf_info->glort,\n\t\t\t\t\t\t mac, vlan, set, 0);\n\t}\n\n\tif (!err && !!results[FM10K_MAC_VLAN_MSG_MULTICAST]) {\n\t\tresult = results[FM10K_MAC_VLAN_MSG_MULTICAST];\n\n\t\t \n\t\terr = fm10k_tlv_attr_get_mac_vlan(result, mac, &vlan);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t \n\t\tif (!(vf_info->vf_flags & FM10K_VF_FLAG_MULTI_ENABLED))\n\t\t\treturn FM10K_ERR_PARAM;\n\n\t\tset = !(vlan & FM10K_VLAN_CLEAR);\n\t\tvlan &= ~FM10K_VLAN_CLEAR;\n\n\t\terr = fm10k_iov_select_vid(vf_info, vlan);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tvlan = (u16)err;\n\n\t\t \n\t\terr = hw->mac.ops.update_mc_addr(hw, vf_info->glort,\n\t\t\t\t\t\t mac, vlan, set);\n\t}\n\n\treturn err;\n}\n\n \nstatic u8 fm10k_iov_supported_xcast_mode_pf(struct fm10k_vf_info *vf_info,\n\t\t\t\t\t    u8 mode)\n{\n\tu8 vf_flags = vf_info->vf_flags;\n\n\t \n\tswitch (mode) {\n\tcase FM10K_XCAST_MODE_PROMISC:\n\t\tif (vf_flags & FM10K_VF_FLAG_PROMISC_CAPABLE)\n\t\t\treturn FM10K_XCAST_MODE_PROMISC;\n\t\tfallthrough;\n\tcase FM10K_XCAST_MODE_ALLMULTI:\n\t\tif (vf_flags & FM10K_VF_FLAG_ALLMULTI_CAPABLE)\n\t\t\treturn FM10K_XCAST_MODE_ALLMULTI;\n\t\tfallthrough;\n\tcase FM10K_XCAST_MODE_MULTI:\n\t\tif (vf_flags & FM10K_VF_FLAG_MULTI_CAPABLE)\n\t\t\treturn FM10K_XCAST_MODE_MULTI;\n\t\tfallthrough;\n\tcase FM10K_XCAST_MODE_NONE:\n\t\tif (vf_flags & FM10K_VF_FLAG_NONE_CAPABLE)\n\t\t\treturn FM10K_XCAST_MODE_NONE;\n\t\tfallthrough;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\treturn FM10K_XCAST_MODE_DISABLE;\n}\n\n \ns32 fm10k_iov_msg_lport_state_pf(struct fm10k_hw *hw, u32 **results,\n\t\t\t\t struct fm10k_mbx_info *mbx)\n{\n\tstruct fm10k_vf_info *vf_info = (struct fm10k_vf_info *)mbx;\n\ts32 err = 0;\n\tu32 msg[2];\n\tu8 mode = 0;\n\n\t \n\tif (!(vf_info->vf_flags & FM10K_VF_FLAG_NONE_CAPABLE))\n\t\treturn FM10K_ERR_PARAM;\n\n\tif (!!results[FM10K_LPORT_STATE_MSG_XCAST_MODE]) {\n\t\tu32 *result = results[FM10K_LPORT_STATE_MSG_XCAST_MODE];\n\n\t\t \n\t\terr = fm10k_tlv_attr_get_u8(result, &mode);\n\t\tif (err)\n\t\t\treturn FM10K_ERR_PARAM;\n\n\t\t \n\t\tmode = fm10k_iov_supported_xcast_mode_pf(vf_info, mode);\n\n\t\t \n\t\tif (!(FM10K_VF_FLAG_ENABLED(vf_info) & BIT(mode)))\n\t\t\tfm10k_update_xcast_mode_pf(hw, vf_info->glort, mode);\n\n\t\t \n\t\tmode = FM10K_VF_FLAG_SET_MODE(mode);\n\t} else if (!results[FM10K_LPORT_STATE_MSG_DISABLE]) {\n\t\t \n\t\tif (FM10K_VF_FLAG_ENABLED(vf_info))\n\t\t\terr = fm10k_update_lport_state_pf(hw, vf_info->glort,\n\t\t\t\t\t\t\t  1, false);\n\n\t\t \n\t\tif (!err)\n\t\t\tvf_info->vf_flags = FM10K_VF_FLAG_CAPABLE(vf_info);\n\n\t\t \n\t\thw->iov.ops.configure_tc(hw, vf_info->vf_idx, vf_info->rate);\n\n\t\t \n\t\tmode = FM10K_VF_FLAG_SET_MODE_NONE;\n\n\t\t \n\t\tfm10k_tlv_msg_init(msg, FM10K_VF_MSG_ID_LPORT_STATE);\n\t\tfm10k_tlv_attr_put_bool(msg, FM10K_LPORT_STATE_MSG_READY);\n\t\tmbx->ops.enqueue_tx(hw, mbx, msg);\n\t}\n\n\t \n\tif (!err && (!FM10K_VF_FLAG_ENABLED(vf_info) != !mode))\n\t\terr = fm10k_update_lport_state_pf(hw, vf_info->glort, 1,\n\t\t\t\t\t\t  !!mode);\n\n\t \n\tmode |= FM10K_VF_FLAG_CAPABLE(vf_info);\n\tif (!err)\n\t\tvf_info->vf_flags = mode;\n\n\treturn err;\n}\n\n \nstatic void fm10k_update_hw_stats_pf(struct fm10k_hw *hw,\n\t\t\t\t     struct fm10k_hw_stats *stats)\n{\n\tu32 timeout, ur, ca, um, xec, vlan_drop, loopback_drop, nodesc_drop;\n\tu32 id, id_prev;\n\n\t \n\tid = fm10k_read_reg(hw, FM10K_TXQCTL(0));\n\n\t \n\tdo {\n\t\ttimeout = fm10k_read_hw_stats_32b(hw, FM10K_STATS_TIMEOUT,\n\t\t\t\t\t\t  &stats->timeout);\n\t\tur = fm10k_read_hw_stats_32b(hw, FM10K_STATS_UR, &stats->ur);\n\t\tca = fm10k_read_hw_stats_32b(hw, FM10K_STATS_CA, &stats->ca);\n\t\tum = fm10k_read_hw_stats_32b(hw, FM10K_STATS_UM, &stats->um);\n\t\txec = fm10k_read_hw_stats_32b(hw, FM10K_STATS_XEC, &stats->xec);\n\t\tvlan_drop = fm10k_read_hw_stats_32b(hw, FM10K_STATS_VLAN_DROP,\n\t\t\t\t\t\t    &stats->vlan_drop);\n\t\tloopback_drop =\n\t\t\tfm10k_read_hw_stats_32b(hw,\n\t\t\t\t\t\tFM10K_STATS_LOOPBACK_DROP,\n\t\t\t\t\t\t&stats->loopback_drop);\n\t\tnodesc_drop = fm10k_read_hw_stats_32b(hw,\n\t\t\t\t\t\t      FM10K_STATS_NODESC_DROP,\n\t\t\t\t\t\t      &stats->nodesc_drop);\n\n\t\t \n\t\tid_prev = id;\n\t\tid = fm10k_read_reg(hw, FM10K_TXQCTL(0));\n\t} while ((id ^ id_prev) & FM10K_TXQCTL_ID_MASK);\n\n\t \n\tid &= FM10K_TXQCTL_ID_MASK;\n\tid |= FM10K_STAT_VALID;\n\n\t \n\tif (stats->stats_idx == id) {\n\t\tstats->timeout.count += timeout;\n\t\tstats->ur.count += ur;\n\t\tstats->ca.count += ca;\n\t\tstats->um.count += um;\n\t\tstats->xec.count += xec;\n\t\tstats->vlan_drop.count += vlan_drop;\n\t\tstats->loopback_drop.count += loopback_drop;\n\t\tstats->nodesc_drop.count += nodesc_drop;\n\t}\n\n\t \n\tfm10k_update_hw_base_32b(&stats->timeout, timeout);\n\tfm10k_update_hw_base_32b(&stats->ur, ur);\n\tfm10k_update_hw_base_32b(&stats->ca, ca);\n\tfm10k_update_hw_base_32b(&stats->um, um);\n\tfm10k_update_hw_base_32b(&stats->xec, xec);\n\tfm10k_update_hw_base_32b(&stats->vlan_drop, vlan_drop);\n\tfm10k_update_hw_base_32b(&stats->loopback_drop, loopback_drop);\n\tfm10k_update_hw_base_32b(&stats->nodesc_drop, nodesc_drop);\n\tstats->stats_idx = id;\n\n\t \n\tfm10k_update_hw_stats_q(hw, stats->q, 0, hw->mac.max_queues);\n}\n\n \nstatic void fm10k_rebind_hw_stats_pf(struct fm10k_hw *hw,\n\t\t\t\t     struct fm10k_hw_stats *stats)\n{\n\t \n\tfm10k_unbind_hw_stats_32b(&stats->timeout);\n\tfm10k_unbind_hw_stats_32b(&stats->ur);\n\tfm10k_unbind_hw_stats_32b(&stats->ca);\n\tfm10k_unbind_hw_stats_32b(&stats->um);\n\tfm10k_unbind_hw_stats_32b(&stats->xec);\n\tfm10k_unbind_hw_stats_32b(&stats->vlan_drop);\n\tfm10k_unbind_hw_stats_32b(&stats->loopback_drop);\n\tfm10k_unbind_hw_stats_32b(&stats->nodesc_drop);\n\n\t \n\tfm10k_unbind_hw_stats_q(stats->q, 0, hw->mac.max_queues);\n\n\t \n\tfm10k_update_hw_stats_pf(hw, stats);\n}\n\n \nstatic void fm10k_set_dma_mask_pf(struct fm10k_hw *hw, u64 dma_mask)\n{\n\t \n\tu32 phyaddr = (u32)(dma_mask >> 32);\n\n\tfm10k_write_reg(hw, FM10K_PHYADDR, phyaddr);\n}\n\n \nstatic s32 fm10k_get_fault_pf(struct fm10k_hw *hw, int type,\n\t\t\t      struct fm10k_fault *fault)\n{\n\tu32 func;\n\n\t \n\tswitch (type) {\n\tcase FM10K_PCA_FAULT:\n\tcase FM10K_THI_FAULT:\n\tcase FM10K_FUM_FAULT:\n\t\tbreak;\n\tdefault:\n\t\treturn FM10K_ERR_PARAM;\n\t}\n\n\t \n\tfunc = fm10k_read_reg(hw, type + FM10K_FAULT_FUNC);\n\tif (!(func & FM10K_FAULT_FUNC_VALID))\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tfault->address = fm10k_read_reg(hw, type + FM10K_FAULT_ADDR_HI);\n\tfault->address <<= 32;\n\tfault->address |= fm10k_read_reg(hw, type + FM10K_FAULT_ADDR_LO);\n\tfault->specinfo = fm10k_read_reg(hw, type + FM10K_FAULT_SPECINFO);\n\n\t \n\tfm10k_write_reg(hw, type + FM10K_FAULT_FUNC, FM10K_FAULT_FUNC_VALID);\n\n\t \n\tif (func & FM10K_FAULT_FUNC_PF)\n\t\tfault->func = 0;\n\telse\n\t\tfault->func = 1 + ((func & FM10K_FAULT_FUNC_VF_MASK) >>\n\t\t\t\t   FM10K_FAULT_FUNC_VF_SHIFT);\n\n\t \n\tfault->type = func & FM10K_FAULT_FUNC_TYPE_MASK;\n\n\treturn 0;\n}\n\n \nstatic s32 fm10k_request_lport_map_pf(struct fm10k_hw *hw)\n{\n\tstruct fm10k_mbx_info *mbx = &hw->mbx;\n\tu32 msg[1];\n\n\t \n\tfm10k_tlv_msg_init(msg, FM10K_PF_MSG_ID_LPORT_MAP);\n\n\t \n\treturn mbx->ops.enqueue_tx(hw, mbx, msg);\n}\n\n \nstatic s32 fm10k_get_host_state_pf(struct fm10k_hw *hw, bool *switch_ready)\n{\n\tu32 dma_ctrl2;\n\n\t \n\tdma_ctrl2 = fm10k_read_reg(hw, FM10K_DMA_CTRL2);\n\tif (!(dma_ctrl2 & FM10K_DMA_CTRL2_SWITCH_READY))\n\t\treturn 0;\n\n\t \n\treturn fm10k_get_host_state_generic(hw, switch_ready);\n}\n\n \nconst struct fm10k_tlv_attr fm10k_lport_map_msg_attr[] = {\n\tFM10K_TLV_ATTR_LE_STRUCT(FM10K_PF_ATTR_ID_ERR,\n\t\t\t\t sizeof(struct fm10k_swapi_error)),\n\tFM10K_TLV_ATTR_U32(FM10K_PF_ATTR_ID_LPORT_MAP),\n\tFM10K_TLV_ATTR_LAST\n};\n\n \ns32 fm10k_msg_lport_map_pf(struct fm10k_hw *hw, u32 **results,\n\t\t\t   struct fm10k_mbx_info __always_unused *mbx)\n{\n\tu16 glort, mask;\n\tu32 dglort_map;\n\ts32 err;\n\n\terr = fm10k_tlv_attr_get_u32(results[FM10K_PF_ATTR_ID_LPORT_MAP],\n\t\t\t\t     &dglort_map);\n\tif (err)\n\t\treturn err;\n\n\t \n\tglort = FM10K_MSG_HDR_FIELD_GET(dglort_map, LPORT_MAP_GLORT);\n\tmask = FM10K_MSG_HDR_FIELD_GET(dglort_map, LPORT_MAP_MASK);\n\n\t \n\tif (!mask || (glort & ~mask))\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tif (((~(mask - 1) & mask) + mask) & FM10K_DGLORTMAP_NONE)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\thw->mac.dglort_map = dglort_map;\n\n\treturn 0;\n}\n\nconst struct fm10k_tlv_attr fm10k_update_pvid_msg_attr[] = {\n\tFM10K_TLV_ATTR_U32(FM10K_PF_ATTR_ID_UPDATE_PVID),\n\tFM10K_TLV_ATTR_LAST\n};\n\n \nstatic s32 fm10k_msg_update_pvid_pf(struct fm10k_hw *hw, u32 **results,\n\t\t\t\t    struct fm10k_mbx_info __always_unused *mbx)\n{\n\tu16 glort, pvid;\n\tu32 pvid_update;\n\ts32 err;\n\n\terr = fm10k_tlv_attr_get_u32(results[FM10K_PF_ATTR_ID_UPDATE_PVID],\n\t\t\t\t     &pvid_update);\n\tif (err)\n\t\treturn err;\n\n\t \n\tglort = FM10K_MSG_HDR_FIELD_GET(pvid_update, UPDATE_PVID_GLORT);\n\tpvid = FM10K_MSG_HDR_FIELD_GET(pvid_update, UPDATE_PVID_PVID);\n\n\t \n\tif (!fm10k_glort_valid_pf(hw, glort))\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\tif (pvid >= FM10K_VLAN_TABLE_VID_MAX)\n\t\treturn FM10K_ERR_PARAM;\n\n\t \n\thw->mac.default_vid = pvid;\n\n\treturn 0;\n}\n\n \nstatic void fm10k_record_global_table_data(struct fm10k_global_table_data *from,\n\t\t\t\t\t   struct fm10k_swapi_table_info *to)\n{\n\t \n\tto->used = le32_to_cpu(from->used);\n\tto->avail = le32_to_cpu(from->avail);\n}\n\nconst struct fm10k_tlv_attr fm10k_err_msg_attr[] = {\n\tFM10K_TLV_ATTR_LE_STRUCT(FM10K_PF_ATTR_ID_ERR,\n\t\t\t\t sizeof(struct fm10k_swapi_error)),\n\tFM10K_TLV_ATTR_LAST\n};\n\n \ns32 fm10k_msg_err_pf(struct fm10k_hw *hw, u32 **results,\n\t\t     struct fm10k_mbx_info __always_unused *mbx)\n{\n\tstruct fm10k_swapi_error err_msg;\n\ts32 err;\n\n\t \n\terr = fm10k_tlv_attr_get_le_struct(results[FM10K_PF_ATTR_ID_ERR],\n\t\t\t\t\t   &err_msg, sizeof(err_msg));\n\tif (err)\n\t\treturn err;\n\n\t \n\tfm10k_record_global_table_data(&err_msg.mac, &hw->swapi.mac);\n\tfm10k_record_global_table_data(&err_msg.nexthop, &hw->swapi.nexthop);\n\tfm10k_record_global_table_data(&err_msg.ffu, &hw->swapi.ffu);\n\n\t \n\thw->swapi.status = le32_to_cpu(err_msg.status);\n\n\treturn 0;\n}\n\nstatic const struct fm10k_msg_data fm10k_msg_data_pf[] = {\n\tFM10K_PF_MSG_ERR_HANDLER(XCAST_MODES, fm10k_msg_err_pf),\n\tFM10K_PF_MSG_ERR_HANDLER(UPDATE_MAC_FWD_RULE, fm10k_msg_err_pf),\n\tFM10K_PF_MSG_LPORT_MAP_HANDLER(fm10k_msg_lport_map_pf),\n\tFM10K_PF_MSG_ERR_HANDLER(LPORT_CREATE, fm10k_msg_err_pf),\n\tFM10K_PF_MSG_ERR_HANDLER(LPORT_DELETE, fm10k_msg_err_pf),\n\tFM10K_PF_MSG_UPDATE_PVID_HANDLER(fm10k_msg_update_pvid_pf),\n\tFM10K_TLV_MSG_ERROR_HANDLER(fm10k_tlv_msg_error),\n};\n\nstatic const struct fm10k_mac_ops mac_ops_pf = {\n\t.get_bus_info\t\t= fm10k_get_bus_info_generic,\n\t.reset_hw\t\t= fm10k_reset_hw_pf,\n\t.init_hw\t\t= fm10k_init_hw_pf,\n\t.start_hw\t\t= fm10k_start_hw_generic,\n\t.stop_hw\t\t= fm10k_stop_hw_generic,\n\t.update_vlan\t\t= fm10k_update_vlan_pf,\n\t.read_mac_addr\t\t= fm10k_read_mac_addr_pf,\n\t.update_uc_addr\t\t= fm10k_update_uc_addr_pf,\n\t.update_mc_addr\t\t= fm10k_update_mc_addr_pf,\n\t.update_xcast_mode\t= fm10k_update_xcast_mode_pf,\n\t.update_int_moderator\t= fm10k_update_int_moderator_pf,\n\t.update_lport_state\t= fm10k_update_lport_state_pf,\n\t.update_hw_stats\t= fm10k_update_hw_stats_pf,\n\t.rebind_hw_stats\t= fm10k_rebind_hw_stats_pf,\n\t.configure_dglort_map\t= fm10k_configure_dglort_map_pf,\n\t.set_dma_mask\t\t= fm10k_set_dma_mask_pf,\n\t.get_fault\t\t= fm10k_get_fault_pf,\n\t.get_host_state\t\t= fm10k_get_host_state_pf,\n\t.request_lport_map\t= fm10k_request_lport_map_pf,\n};\n\nstatic const struct fm10k_iov_ops iov_ops_pf = {\n\t.assign_resources\t\t= fm10k_iov_assign_resources_pf,\n\t.configure_tc\t\t\t= fm10k_iov_configure_tc_pf,\n\t.assign_int_moderator\t\t= fm10k_iov_assign_int_moderator_pf,\n\t.assign_default_mac_vlan\t= fm10k_iov_assign_default_mac_vlan_pf,\n\t.reset_resources\t\t= fm10k_iov_reset_resources_pf,\n\t.set_lport\t\t\t= fm10k_iov_set_lport_pf,\n\t.reset_lport\t\t\t= fm10k_iov_reset_lport_pf,\n\t.update_stats\t\t\t= fm10k_iov_update_stats_pf,\n};\n\nstatic s32 fm10k_get_invariants_pf(struct fm10k_hw *hw)\n{\n\tfm10k_get_invariants_generic(hw);\n\n\treturn fm10k_sm_mbx_init(hw, &hw->mbx, fm10k_msg_data_pf);\n}\n\nconst struct fm10k_info fm10k_pf_info = {\n\t.mac\t\t= fm10k_mac_pf,\n\t.get_invariants\t= fm10k_get_invariants_pf,\n\t.mac_ops\t= &mac_ops_pf,\n\t.iov_ops\t= &iov_ops_pf,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}