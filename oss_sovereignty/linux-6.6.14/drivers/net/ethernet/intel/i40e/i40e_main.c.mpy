{
  "module_name": "i40e_main.c",
  "hash_id": "225bb87a49fe74a5aac6569f371fc3ff4f9051af4e64e960e027832898a4d411",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/i40e/i40e_main.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <linux/of_net.h>\n#include <linux/pci.h>\n#include <linux/bpf.h>\n#include <generated/utsrelease.h>\n#include <linux/crash_dump.h>\n\n \n#include \"i40e.h\"\n#include \"i40e_diag.h\"\n#include \"i40e_xsk.h\"\n#include <net/udp_tunnel.h>\n#include <net/xdp_sock_drv.h>\n \n#define CREATE_TRACE_POINTS\n#include \"i40e_trace.h\"\n\nconst char i40e_driver_name[] = \"i40e\";\nstatic const char i40e_driver_string[] =\n\t\t\t\"Intel(R) Ethernet Connection XL710 Network Driver\";\n\nstatic const char i40e_copyright[] = \"Copyright (c) 2013 - 2019 Intel Corporation.\";\n\n \nstatic void i40e_vsi_reinit_locked(struct i40e_vsi *vsi);\nstatic void i40e_handle_reset_warning(struct i40e_pf *pf, bool lock_acquired);\nstatic int i40e_add_vsi(struct i40e_vsi *vsi);\nstatic int i40e_add_veb(struct i40e_veb *veb, struct i40e_vsi *vsi);\nstatic int i40e_setup_pf_switch(struct i40e_pf *pf, bool reinit, bool lock_acquired);\nstatic int i40e_setup_misc_vector(struct i40e_pf *pf);\nstatic void i40e_determine_queue_usage(struct i40e_pf *pf);\nstatic int i40e_setup_pf_filter_control(struct i40e_pf *pf);\nstatic void i40e_prep_for_reset(struct i40e_pf *pf);\nstatic void i40e_reset_and_rebuild(struct i40e_pf *pf, bool reinit,\n\t\t\t\t   bool lock_acquired);\nstatic int i40e_reset(struct i40e_pf *pf);\nstatic void i40e_rebuild(struct i40e_pf *pf, bool reinit, bool lock_acquired);\nstatic int i40e_setup_misc_vector_for_recovery_mode(struct i40e_pf *pf);\nstatic int i40e_restore_interrupt_scheme(struct i40e_pf *pf);\nstatic bool i40e_check_recovery_mode(struct i40e_pf *pf);\nstatic int i40e_init_recovery_mode(struct i40e_pf *pf, struct i40e_hw *hw);\nstatic void i40e_fdir_sb_setup(struct i40e_pf *pf);\nstatic int i40e_veb_get_bw_info(struct i40e_veb *veb);\nstatic int i40e_get_capabilities(struct i40e_pf *pf,\n\t\t\t\t enum i40e_admin_queue_opc list_type);\nstatic bool i40e_is_total_port_shutdown_enabled(struct i40e_pf *pf);\n\n \nstatic const struct pci_device_id i40e_pci_tbl[] = {\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_XL710), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QEMU), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_C), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_A), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_C), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_1G_BASE_T_BC), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T4), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T_BC), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_SFP), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_KX_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_QSFP_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_1G_BASE_T_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_10G_BASE_T_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_I_X722), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_SFP_X722_A), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_20G_KR2), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_20G_KR2_A), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_X710_N3000), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_XXV710_N3000), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_25G_B), 0},\n\t{PCI_VDEVICE(INTEL, I40E_DEV_ID_25G_SFP28), 0},\n\t \n\t{0, }\n};\nMODULE_DEVICE_TABLE(pci, i40e_pci_tbl);\n\n#define I40E_MAX_VF_COUNT 128\nstatic int debug = -1;\nmodule_param(debug, uint, 0);\nMODULE_PARM_DESC(debug, \"Debug level (0=none,...,16=all), Debug mask (0x8XXXXXXX)\");\n\nMODULE_AUTHOR(\"Intel Corporation, <e1000-devel@lists.sourceforge.net>\");\nMODULE_DESCRIPTION(\"Intel(R) Ethernet Connection XL710 Network Driver\");\nMODULE_LICENSE(\"GPL v2\");\n\nstatic struct workqueue_struct *i40e_wq;\n\nstatic void netdev_hw_addr_refcnt(struct i40e_mac_filter *f,\n\t\t\t\t  struct net_device *netdev, int delta)\n{\n\tstruct netdev_hw_addr_list *ha_list;\n\tstruct netdev_hw_addr *ha;\n\n\tif (!f || !netdev)\n\t\treturn;\n\n\tif (is_unicast_ether_addr(f->macaddr) || is_link_local_ether_addr(f->macaddr))\n\t\tha_list = &netdev->uc;\n\telse\n\t\tha_list = &netdev->mc;\n\n\tnetdev_hw_addr_list_for_each(ha, ha_list) {\n\t\tif (ether_addr_equal(ha->addr, f->macaddr)) {\n\t\t\tha->refcount += delta;\n\t\t\tif (ha->refcount <= 0)\n\t\t\t\tha->refcount = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nint i40e_allocate_dma_mem_d(struct i40e_hw *hw, struct i40e_dma_mem *mem,\n\t\t\t    u64 size, u32 alignment)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)hw->back;\n\n\tmem->size = ALIGN(size, alignment);\n\tmem->va = dma_alloc_coherent(&pf->pdev->dev, mem->size, &mem->pa,\n\t\t\t\t     GFP_KERNEL);\n\tif (!mem->va)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n \nint i40e_free_dma_mem_d(struct i40e_hw *hw, struct i40e_dma_mem *mem)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)hw->back;\n\n\tdma_free_coherent(&pf->pdev->dev, mem->size, mem->va, mem->pa);\n\tmem->va = NULL;\n\tmem->pa = 0;\n\tmem->size = 0;\n\n\treturn 0;\n}\n\n \nint i40e_allocate_virt_mem_d(struct i40e_hw *hw, struct i40e_virt_mem *mem,\n\t\t\t     u32 size)\n{\n\tmem->size = size;\n\tmem->va = kzalloc(size, GFP_KERNEL);\n\n\tif (!mem->va)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n \nint i40e_free_virt_mem_d(struct i40e_hw *hw, struct i40e_virt_mem *mem)\n{\n\t \n\tkfree(mem->va);\n\tmem->va = NULL;\n\tmem->size = 0;\n\n\treturn 0;\n}\n\n \nstatic int i40e_get_lump(struct i40e_pf *pf, struct i40e_lump_tracking *pile,\n\t\t\t u16 needed, u16 id)\n{\n\tint ret = -ENOMEM;\n\tint i, j;\n\n\tif (!pile || needed == 0 || id >= I40E_PILE_VALID_BIT) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"param err: pile=%s needed=%d id=0x%04x\\n\",\n\t\t\t pile ? \"<valid>\" : \"<null>\", needed, id);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (pile == pf->qp_pile && pf->vsi[id]->type == I40E_VSI_FDIR) {\n\t\tif (pile->list[pile->num_entries - 1] & I40E_PILE_VALID_BIT) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Cannot allocate queue %d for I40E_VSI_FDIR\\n\",\n\t\t\t\tpile->num_entries - 1);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tpile->list[pile->num_entries - 1] = id | I40E_PILE_VALID_BIT;\n\t\treturn pile->num_entries - 1;\n\t}\n\n\ti = 0;\n\twhile (i < pile->num_entries) {\n\t\t \n\t\tif (pile->list[i] & I40E_PILE_VALID_BIT) {\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tfor (j = 0; (j < needed) && ((i+j) < pile->num_entries); j++) {\n\t\t\tif (pile->list[i+j] & I40E_PILE_VALID_BIT)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (j == needed) {\n\t\t\t \n\t\t\tfor (j = 0; j < needed; j++)\n\t\t\t\tpile->list[i+j] = id | I40E_PILE_VALID_BIT;\n\t\t\tret = i;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\ti += j;\n\t}\n\n\treturn ret;\n}\n\n \nstatic int i40e_put_lump(struct i40e_lump_tracking *pile, u16 index, u16 id)\n{\n\tint valid_id = (id | I40E_PILE_VALID_BIT);\n\tint count = 0;\n\tu16 i;\n\n\tif (!pile || index >= pile->num_entries)\n\t\treturn -EINVAL;\n\n\tfor (i = index;\n\t     i < pile->num_entries && pile->list[i] == valid_id;\n\t     i++) {\n\t\tpile->list[i] = 0;\n\t\tcount++;\n\t}\n\n\n\treturn count;\n}\n\n \nstruct i40e_vsi *i40e_find_vsi_from_id(struct i40e_pf *pf, u16 id)\n{\n\tint i;\n\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->id == id))\n\t\t\treturn pf->vsi[i];\n\n\treturn NULL;\n}\n\n \nvoid i40e_service_event_schedule(struct i40e_pf *pf)\n{\n\tif ((!test_bit(__I40E_DOWN, pf->state) &&\n\t     !test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state)) ||\n\t      test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\tqueue_work(i40e_wq, &pf->service_task);\n}\n\n \nstatic void i40e_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_ring *tx_ring = NULL;\n\tunsigned int i;\n\tu32 head, val;\n\n\tpf->tx_timeout_count++;\n\n\t \n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\tif (vsi->tx_rings[i] && vsi->tx_rings[i]->desc) {\n\t\t\tif (txqueue ==\n\t\t\t    vsi->tx_rings[i]->queue_index) {\n\t\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (time_after(jiffies, (pf->tx_timeout_last_recovery + HZ*20)))\n\t\tpf->tx_timeout_recovery_level = 1;   \n\telse if (time_before(jiffies,\n\t\t      (pf->tx_timeout_last_recovery + netdev->watchdog_timeo)))\n\t\treturn;    \n\n\t \n\tif (test_and_set_bit(__I40E_TIMEOUT_RECOVERY_PENDING, pf->state))\n\t\treturn;\n\n\tif (tx_ring) {\n\t\thead = i40e_get_head(tx_ring);\n\t\t \n\t\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tval = rd32(&pf->hw,\n\t\t\t     I40E_PFINT_DYN_CTLN(tx_ring->q_vector->v_idx +\n\t\t\t\t\t\ttx_ring->vsi->base_vector - 1));\n\t\telse\n\t\t\tval = rd32(&pf->hw, I40E_PFINT_DYN_CTL0);\n\n\t\tnetdev_info(netdev, \"tx_timeout: VSI_seid: %d, Q %d, NTC: 0x%x, HWB: 0x%x, NTU: 0x%x, TAIL: 0x%x, INT: 0x%x\\n\",\n\t\t\t    vsi->seid, txqueue, tx_ring->next_to_clean,\n\t\t\t    head, tx_ring->next_to_use,\n\t\t\t    readl(tx_ring->tail), val);\n\t}\n\n\tpf->tx_timeout_last_recovery = jiffies;\n\tnetdev_info(netdev, \"tx_timeout recovery level %d, txqueue %d\\n\",\n\t\t    pf->tx_timeout_recovery_level, txqueue);\n\n\tswitch (pf->tx_timeout_recovery_level) {\n\tcase 1:\n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tcase 2:\n\t\tset_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tcase 3:\n\t\tset_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state);\n\t\tbreak;\n\tdefault:\n\t\tnetdev_err(netdev, \"tx_timeout recovery unsuccessful, device is in non-recoverable state.\\n\");\n\t\tset_bit(__I40E_DOWN_REQUESTED, pf->state);\n\t\tset_bit(__I40E_VSI_DOWN_REQUESTED, vsi->state);\n\t\tbreak;\n\t}\n\n\ti40e_service_event_schedule(pf);\n\tpf->tx_timeout_recovery_level++;\n}\n\n \nstruct rtnl_link_stats64 *i40e_get_vsi_stats_struct(struct i40e_vsi *vsi)\n{\n\treturn &vsi->net_stats;\n}\n\n \nstatic void i40e_get_netdev_stats_struct_tx(struct i40e_ring *ring,\n\t\t\t\t\t    struct rtnl_link_stats64 *stats)\n{\n\tu64 bytes, packets;\n\tunsigned int start;\n\n\tdo {\n\t\tstart = u64_stats_fetch_begin(&ring->syncp);\n\t\tpackets = ring->stats.packets;\n\t\tbytes   = ring->stats.bytes;\n\t} while (u64_stats_fetch_retry(&ring->syncp, start));\n\n\tstats->tx_packets += packets;\n\tstats->tx_bytes   += bytes;\n}\n\n \nstatic void i40e_get_netdev_stats_struct(struct net_device *netdev,\n\t\t\t\t  struct rtnl_link_stats64 *stats)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct rtnl_link_stats64 *vsi_stats = i40e_get_vsi_stats_struct(vsi);\n\tstruct i40e_ring *ring;\n\tint i;\n\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tif (!vsi->tx_rings)\n\t\treturn;\n\n\trcu_read_lock();\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\tu64 bytes, packets;\n\t\tunsigned int start;\n\n\t\tring = READ_ONCE(vsi->tx_rings[i]);\n\t\tif (!ring)\n\t\t\tcontinue;\n\t\ti40e_get_netdev_stats_struct_tx(ring, stats);\n\n\t\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t\tring = READ_ONCE(vsi->xdp_rings[i]);\n\t\t\tif (!ring)\n\t\t\t\tcontinue;\n\t\t\ti40e_get_netdev_stats_struct_tx(ring, stats);\n\t\t}\n\n\t\tring = READ_ONCE(vsi->rx_rings[i]);\n\t\tif (!ring)\n\t\t\tcontinue;\n\t\tdo {\n\t\t\tstart   = u64_stats_fetch_begin(&ring->syncp);\n\t\t\tpackets = ring->stats.packets;\n\t\t\tbytes   = ring->stats.bytes;\n\t\t} while (u64_stats_fetch_retry(&ring->syncp, start));\n\n\t\tstats->rx_packets += packets;\n\t\tstats->rx_bytes   += bytes;\n\n\t}\n\trcu_read_unlock();\n\n\t \n\tstats->multicast\t= vsi_stats->multicast;\n\tstats->tx_errors\t= vsi_stats->tx_errors;\n\tstats->tx_dropped\t= vsi_stats->tx_dropped;\n\tstats->rx_errors\t= vsi_stats->rx_errors;\n\tstats->rx_dropped\t= vsi_stats->rx_dropped;\n\tstats->rx_crc_errors\t= vsi_stats->rx_crc_errors;\n\tstats->rx_length_errors\t= vsi_stats->rx_length_errors;\n}\n\n \nvoid i40e_vsi_reset_stats(struct i40e_vsi *vsi)\n{\n\tstruct rtnl_link_stats64 *ns;\n\tint i;\n\n\tif (!vsi)\n\t\treturn;\n\n\tns = i40e_get_vsi_stats_struct(vsi);\n\tmemset(ns, 0, sizeof(*ns));\n\tmemset(&vsi->net_stats_offsets, 0, sizeof(vsi->net_stats_offsets));\n\tmemset(&vsi->eth_stats, 0, sizeof(vsi->eth_stats));\n\tmemset(&vsi->eth_stats_offsets, 0, sizeof(vsi->eth_stats_offsets));\n\tif (vsi->rx_rings && vsi->rx_rings[0]) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\tmemset(&vsi->rx_rings[i]->stats, 0,\n\t\t\t       sizeof(vsi->rx_rings[i]->stats));\n\t\t\tmemset(&vsi->rx_rings[i]->rx_stats, 0,\n\t\t\t       sizeof(vsi->rx_rings[i]->rx_stats));\n\t\t\tmemset(&vsi->tx_rings[i]->stats, 0,\n\t\t\t       sizeof(vsi->tx_rings[i]->stats));\n\t\t\tmemset(&vsi->tx_rings[i]->tx_stats, 0,\n\t\t\t       sizeof(vsi->tx_rings[i]->tx_stats));\n\t\t}\n\t}\n\tvsi->stat_offsets_loaded = false;\n}\n\n \nvoid i40e_pf_reset_stats(struct i40e_pf *pf)\n{\n\tint i;\n\n\tmemset(&pf->stats, 0, sizeof(pf->stats));\n\tmemset(&pf->stats_offsets, 0, sizeof(pf->stats_offsets));\n\tpf->stat_offsets_loaded = false;\n\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (pf->veb[i]) {\n\t\t\tmemset(&pf->veb[i]->stats, 0,\n\t\t\t       sizeof(pf->veb[i]->stats));\n\t\t\tmemset(&pf->veb[i]->stats_offsets, 0,\n\t\t\t       sizeof(pf->veb[i]->stats_offsets));\n\t\t\tmemset(&pf->veb[i]->tc_stats, 0,\n\t\t\t       sizeof(pf->veb[i]->tc_stats));\n\t\t\tmemset(&pf->veb[i]->tc_stats_offsets, 0,\n\t\t\t       sizeof(pf->veb[i]->tc_stats_offsets));\n\t\t\tpf->veb[i]->stat_offsets_loaded = false;\n\t\t}\n\t}\n\tpf->hw_csum_rx_error = 0;\n}\n\n \nstatic u32 i40e_compute_pci_to_hw_id(struct i40e_vsi *vsi, struct i40e_hw *hw)\n{\n\tint pf_count = i40e_get_pf_count(hw);\n\n\tif (vsi->type == I40E_VSI_SRIOV)\n\t\treturn (hw->port * BIT(7)) / pf_count + vsi->vf_id;\n\n\treturn hw->port + BIT(7);\n}\n\n \nstatic void i40e_stat_update64(struct i40e_hw *hw, u32 hireg, u32 loreg,\n\t\t\t       bool offset_loaded, u64 *offset, u64 *stat)\n{\n\tu64 new_data;\n\n\tnew_data = rd64(hw, loreg);\n\n\tif (!offset_loaded || new_data < *offset)\n\t\t*offset = new_data;\n\t*stat = new_data - *offset;\n}\n\n \nstatic void i40e_stat_update48(struct i40e_hw *hw, u32 hireg, u32 loreg,\n\t\t\t       bool offset_loaded, u64 *offset, u64 *stat)\n{\n\tu64 new_data;\n\n\tif (hw->device_id == I40E_DEV_ID_QEMU) {\n\t\tnew_data = rd32(hw, loreg);\n\t\tnew_data |= ((u64)(rd32(hw, hireg) & 0xFFFF)) << 32;\n\t} else {\n\t\tnew_data = rd64(hw, loreg);\n\t}\n\tif (!offset_loaded)\n\t\t*offset = new_data;\n\tif (likely(new_data >= *offset))\n\t\t*stat = new_data - *offset;\n\telse\n\t\t*stat = (new_data + BIT_ULL(48)) - *offset;\n\t*stat &= 0xFFFFFFFFFFFFULL;\n}\n\n \nstatic void i40e_stat_update32(struct i40e_hw *hw, u32 reg,\n\t\t\t       bool offset_loaded, u64 *offset, u64 *stat)\n{\n\tu32 new_data;\n\n\tnew_data = rd32(hw, reg);\n\tif (!offset_loaded)\n\t\t*offset = new_data;\n\tif (likely(new_data >= *offset))\n\t\t*stat = (u32)(new_data - *offset);\n\telse\n\t\t*stat = (u32)((new_data + BIT_ULL(32)) - *offset);\n}\n\n \nstatic void i40e_stat_update_and_clear32(struct i40e_hw *hw, u32 reg, u64 *stat)\n{\n\tu32 new_data = rd32(hw, reg);\n\n\twr32(hw, reg, 1);  \n\t*stat += new_data;\n}\n\n \nstatic void\ni40e_stats_update_rx_discards(struct i40e_vsi *vsi, struct i40e_hw *hw,\n\t\t\t      int stat_idx, bool offset_loaded,\n\t\t\t      struct i40e_eth_stats *stat_offset,\n\t\t\t      struct i40e_eth_stats *stat)\n{\n\tu64 rx_rdpc, rx_rxerr;\n\n\ti40e_stat_update32(hw, I40E_GLV_RDPC(stat_idx), offset_loaded,\n\t\t\t   &stat_offset->rx_discards, &rx_rdpc);\n\ti40e_stat_update64(hw,\n\t\t\t   I40E_GL_RXERR1H(i40e_compute_pci_to_hw_id(vsi, hw)),\n\t\t\t   I40E_GL_RXERR1L(i40e_compute_pci_to_hw_id(vsi, hw)),\n\t\t\t   offset_loaded, &stat_offset->rx_discards_other,\n\t\t\t   &rx_rxerr);\n\n\tstat->rx_discards = rx_rdpc + rx_rxerr;\n}\n\n \nvoid i40e_update_eth_stats(struct i40e_vsi *vsi)\n{\n\tint stat_idx = le16_to_cpu(vsi->info.stat_counter_idx);\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;      \n\n\tes = &vsi->eth_stats;\n\toes = &vsi->eth_stats_offsets;\n\n\t \n\ti40e_stat_update32(hw, I40E_GLV_TEPC(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_errors, &es->tx_errors);\n\ti40e_stat_update32(hw, I40E_GLV_RDPC(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_discards, &es->rx_discards);\n\ti40e_stat_update32(hw, I40E_GLV_RUPP(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_unknown_protocol, &es->rx_unknown_protocol);\n\n\ti40e_stat_update48(hw, I40E_GLV_GORCH(stat_idx),\n\t\t\t   I40E_GLV_GORCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_bytes, &es->rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLV_UPRCH(stat_idx),\n\t\t\t   I40E_GLV_UPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_unicast, &es->rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLV_MPRCH(stat_idx),\n\t\t\t   I40E_GLV_MPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_multicast, &es->rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLV_BPRCH(stat_idx),\n\t\t\t   I40E_GLV_BPRCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->rx_broadcast, &es->rx_broadcast);\n\n\ti40e_stat_update48(hw, I40E_GLV_GOTCH(stat_idx),\n\t\t\t   I40E_GLV_GOTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_bytes, &es->tx_bytes);\n\ti40e_stat_update48(hw, I40E_GLV_UPTCH(stat_idx),\n\t\t\t   I40E_GLV_UPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_unicast, &es->tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLV_MPTCH(stat_idx),\n\t\t\t   I40E_GLV_MPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_multicast, &es->tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLV_BPTCH(stat_idx),\n\t\t\t   I40E_GLV_BPTCL(stat_idx),\n\t\t\t   vsi->stat_offsets_loaded,\n\t\t\t   &oes->tx_broadcast, &es->tx_broadcast);\n\n\ti40e_stats_update_rx_discards(vsi, hw, stat_idx,\n\t\t\t\t      vsi->stat_offsets_loaded, oes, es);\n\n\tvsi->stat_offsets_loaded = true;\n}\n\n \nvoid i40e_update_veb_stats(struct i40e_veb *veb)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;      \n\tstruct i40e_veb_tc_stats *veb_oes;\n\tstruct i40e_veb_tc_stats *veb_es;\n\tint i, idx = 0;\n\n\tidx = veb->stats_idx;\n\tes = &veb->stats;\n\toes = &veb->stats_offsets;\n\tveb_es = &veb->tc_stats;\n\tveb_oes = &veb->tc_stats_offsets;\n\n\t \n\ti40e_stat_update32(hw, I40E_GLSW_TDPC(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_discards, &es->tx_discards);\n\tif (hw->revision_id > 0)\n\t\ti40e_stat_update32(hw, I40E_GLSW_RUPP(idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &oes->rx_unknown_protocol,\n\t\t\t\t   &es->rx_unknown_protocol);\n\ti40e_stat_update48(hw, I40E_GLSW_GORCH(idx), I40E_GLSW_GORCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_bytes, &es->rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLSW_UPRCH(idx), I40E_GLSW_UPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_unicast, &es->rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLSW_MPRCH(idx), I40E_GLSW_MPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_multicast, &es->rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLSW_BPRCH(idx), I40E_GLSW_BPRCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->rx_broadcast, &es->rx_broadcast);\n\n\ti40e_stat_update48(hw, I40E_GLSW_GOTCH(idx), I40E_GLSW_GOTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_bytes, &es->tx_bytes);\n\ti40e_stat_update48(hw, I40E_GLSW_UPTCH(idx), I40E_GLSW_UPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_unicast, &es->tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLSW_MPTCH(idx), I40E_GLSW_MPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_multicast, &es->tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLSW_BPTCH(idx), I40E_GLSW_BPTCL(idx),\n\t\t\t   veb->stat_offsets_loaded,\n\t\t\t   &oes->tx_broadcast, &es->tx_broadcast);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_RPCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_RPCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_rx_packets[i],\n\t\t\t\t   &veb_es->tc_rx_packets[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_RBCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_RBCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_rx_bytes[i],\n\t\t\t\t   &veb_es->tc_rx_bytes[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_TPCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_TPCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_tx_packets[i],\n\t\t\t\t   &veb_es->tc_tx_packets[i]);\n\t\ti40e_stat_update48(hw, I40E_GLVEBTC_TBCH(i, idx),\n\t\t\t\t   I40E_GLVEBTC_TBCL(i, idx),\n\t\t\t\t   veb->stat_offsets_loaded,\n\t\t\t\t   &veb_oes->tc_tx_bytes[i],\n\t\t\t\t   &veb_es->tc_tx_bytes[i]);\n\t}\n\tveb->stat_offsets_loaded = true;\n}\n\n \nstatic void i40e_update_vsi_stats(struct i40e_vsi *vsi)\n{\n\tu64 rx_page, rx_buf, rx_reuse, rx_alloc, rx_waive, rx_busy;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct rtnl_link_stats64 *ons;\n\tstruct rtnl_link_stats64 *ns;    \n\tstruct i40e_eth_stats *oes;\n\tstruct i40e_eth_stats *es;      \n\tu64 tx_restart, tx_busy;\n\tstruct i40e_ring *p;\n\tu64 bytes, packets;\n\tunsigned int start;\n\tu64 tx_linearize;\n\tu64 tx_force_wb;\n\tu64 tx_stopped;\n\tu64 rx_p, rx_b;\n\tu64 tx_p, tx_b;\n\tu16 q;\n\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state) ||\n\t    test_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\treturn;\n\n\tns = i40e_get_vsi_stats_struct(vsi);\n\tons = &vsi->net_stats_offsets;\n\tes = &vsi->eth_stats;\n\toes = &vsi->eth_stats_offsets;\n\n\t \n\trx_b = rx_p = 0;\n\ttx_b = tx_p = 0;\n\ttx_restart = tx_busy = tx_linearize = tx_force_wb = 0;\n\ttx_stopped = 0;\n\trx_page = 0;\n\trx_buf = 0;\n\trx_reuse = 0;\n\trx_alloc = 0;\n\trx_waive = 0;\n\trx_busy = 0;\n\trcu_read_lock();\n\tfor (q = 0; q < vsi->num_queue_pairs; q++) {\n\t\t \n\t\tp = READ_ONCE(vsi->tx_rings[q]);\n\t\tif (!p)\n\t\t\tcontinue;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&p->syncp);\n\t\t\tpackets = p->stats.packets;\n\t\t\tbytes = p->stats.bytes;\n\t\t} while (u64_stats_fetch_retry(&p->syncp, start));\n\t\ttx_b += bytes;\n\t\ttx_p += packets;\n\t\ttx_restart += p->tx_stats.restart_queue;\n\t\ttx_busy += p->tx_stats.tx_busy;\n\t\ttx_linearize += p->tx_stats.tx_linearize;\n\t\ttx_force_wb += p->tx_stats.tx_force_wb;\n\t\ttx_stopped += p->tx_stats.tx_stopped;\n\n\t\t \n\t\tp = READ_ONCE(vsi->rx_rings[q]);\n\t\tif (!p)\n\t\t\tcontinue;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&p->syncp);\n\t\t\tpackets = p->stats.packets;\n\t\t\tbytes = p->stats.bytes;\n\t\t} while (u64_stats_fetch_retry(&p->syncp, start));\n\t\trx_b += bytes;\n\t\trx_p += packets;\n\t\trx_buf += p->rx_stats.alloc_buff_failed;\n\t\trx_page += p->rx_stats.alloc_page_failed;\n\t\trx_reuse += p->rx_stats.page_reuse_count;\n\t\trx_alloc += p->rx_stats.page_alloc_count;\n\t\trx_waive += p->rx_stats.page_waive_count;\n\t\trx_busy += p->rx_stats.page_busy_count;\n\n\t\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t\t \n\t\t\tp = READ_ONCE(vsi->xdp_rings[q]);\n\t\t\tif (!p)\n\t\t\t\tcontinue;\n\n\t\t\tdo {\n\t\t\t\tstart = u64_stats_fetch_begin(&p->syncp);\n\t\t\t\tpackets = p->stats.packets;\n\t\t\t\tbytes = p->stats.bytes;\n\t\t\t} while (u64_stats_fetch_retry(&p->syncp, start));\n\t\t\ttx_b += bytes;\n\t\t\ttx_p += packets;\n\t\t\ttx_restart += p->tx_stats.restart_queue;\n\t\t\ttx_busy += p->tx_stats.tx_busy;\n\t\t\ttx_linearize += p->tx_stats.tx_linearize;\n\t\t\ttx_force_wb += p->tx_stats.tx_force_wb;\n\t\t}\n\t}\n\trcu_read_unlock();\n\tvsi->tx_restart = tx_restart;\n\tvsi->tx_busy = tx_busy;\n\tvsi->tx_linearize = tx_linearize;\n\tvsi->tx_force_wb = tx_force_wb;\n\tvsi->tx_stopped = tx_stopped;\n\tvsi->rx_page_failed = rx_page;\n\tvsi->rx_buf_failed = rx_buf;\n\tvsi->rx_page_reuse = rx_reuse;\n\tvsi->rx_page_alloc = rx_alloc;\n\tvsi->rx_page_waive = rx_waive;\n\tvsi->rx_page_busy = rx_busy;\n\n\tns->rx_packets = rx_p;\n\tns->rx_bytes = rx_b;\n\tns->tx_packets = tx_p;\n\tns->tx_bytes = tx_b;\n\n\t \n\ti40e_update_eth_stats(vsi);\n\tons->tx_errors = oes->tx_errors;\n\tns->tx_errors = es->tx_errors;\n\tons->multicast = oes->rx_multicast;\n\tns->multicast = es->rx_multicast;\n\tons->rx_dropped = oes->rx_discards;\n\tns->rx_dropped = es->rx_discards;\n\tons->tx_dropped = oes->tx_discards;\n\tns->tx_dropped = es->tx_discards;\n\n\t \n\tif (vsi == pf->vsi[pf->lan_vsi]) {\n\t\tns->rx_crc_errors = pf->stats.crc_errors;\n\t\tns->rx_errors = pf->stats.crc_errors + pf->stats.illegal_bytes;\n\t\tns->rx_length_errors = pf->stats.rx_length_errors;\n\t}\n}\n\n \nstatic void i40e_update_pf_stats(struct i40e_pf *pf)\n{\n\tstruct i40e_hw_port_stats *osd = &pf->stats_offsets;\n\tstruct i40e_hw_port_stats *nsd = &pf->stats;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\tint i;\n\n\ti40e_stat_update48(hw, I40E_GLPRT_GORCH(hw->port),\n\t\t\t   I40E_GLPRT_GORCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_bytes, &nsd->eth.rx_bytes);\n\ti40e_stat_update48(hw, I40E_GLPRT_GOTCH(hw->port),\n\t\t\t   I40E_GLPRT_GOTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_bytes, &nsd->eth.tx_bytes);\n\ti40e_stat_update32(hw, I40E_GLPRT_RDPC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_discards,\n\t\t\t   &nsd->eth.rx_discards);\n\ti40e_stat_update48(hw, I40E_GLPRT_UPRCH(hw->port),\n\t\t\t   I40E_GLPRT_UPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_unicast,\n\t\t\t   &nsd->eth.rx_unicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_MPRCH(hw->port),\n\t\t\t   I40E_GLPRT_MPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_multicast,\n\t\t\t   &nsd->eth.rx_multicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_BPRCH(hw->port),\n\t\t\t   I40E_GLPRT_BPRCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.rx_broadcast,\n\t\t\t   &nsd->eth.rx_broadcast);\n\ti40e_stat_update48(hw, I40E_GLPRT_UPTCH(hw->port),\n\t\t\t   I40E_GLPRT_UPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_unicast,\n\t\t\t   &nsd->eth.tx_unicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_MPTCH(hw->port),\n\t\t\t   I40E_GLPRT_MPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_multicast,\n\t\t\t   &nsd->eth.tx_multicast);\n\ti40e_stat_update48(hw, I40E_GLPRT_BPTCH(hw->port),\n\t\t\t   I40E_GLPRT_BPTCL(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->eth.tx_broadcast,\n\t\t\t   &nsd->eth.tx_broadcast);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_TDOLD(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_dropped_link_down,\n\t\t\t   &nsd->tx_dropped_link_down);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_CRCERRS(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->crc_errors, &nsd->crc_errors);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_ILLERRC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->illegal_bytes, &nsd->illegal_bytes);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_MLFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->mac_local_faults,\n\t\t\t   &nsd->mac_local_faults);\n\ti40e_stat_update32(hw, I40E_GLPRT_MRFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->mac_remote_faults,\n\t\t\t   &nsd->mac_remote_faults);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_RLEC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_length_errors,\n\t\t\t   &nsd->rx_length_errors);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_LXONRXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xon_rx, &nsd->link_xon_rx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXONTXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xon_tx, &nsd->link_xon_tx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXOFFRXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xoff_rx, &nsd->link_xoff_rx);\n\ti40e_stat_update32(hw, I40E_GLPRT_LXOFFTXC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->link_xoff_tx, &nsd->link_xoff_tx);\n\n\tfor (i = 0; i < 8; i++) {\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXOFFRXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xoff_rx[i],\n\t\t\t\t   &nsd->priority_xoff_rx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXONRXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_rx[i],\n\t\t\t\t   &nsd->priority_xon_rx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXONTXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_tx[i],\n\t\t\t\t   &nsd->priority_xon_tx[i]);\n\t\ti40e_stat_update32(hw, I40E_GLPRT_PXOFFTXC(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xoff_tx[i],\n\t\t\t\t   &nsd->priority_xoff_tx[i]);\n\t\ti40e_stat_update32(hw,\n\t\t\t\t   I40E_GLPRT_RXON2OFFCNT(hw->port, i),\n\t\t\t\t   pf->stat_offsets_loaded,\n\t\t\t\t   &osd->priority_xon_2_xoff[i],\n\t\t\t\t   &nsd->priority_xon_2_xoff[i]);\n\t}\n\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC64H(hw->port),\n\t\t\t   I40E_GLPRT_PRC64L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_64, &nsd->rx_size_64);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC127H(hw->port),\n\t\t\t   I40E_GLPRT_PRC127L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_127, &nsd->rx_size_127);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC255H(hw->port),\n\t\t\t   I40E_GLPRT_PRC255L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_255, &nsd->rx_size_255);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC511H(hw->port),\n\t\t\t   I40E_GLPRT_PRC511L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_511, &nsd->rx_size_511);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC1023H(hw->port),\n\t\t\t   I40E_GLPRT_PRC1023L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_1023, &nsd->rx_size_1023);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC1522H(hw->port),\n\t\t\t   I40E_GLPRT_PRC1522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_1522, &nsd->rx_size_1522);\n\ti40e_stat_update48(hw, I40E_GLPRT_PRC9522H(hw->port),\n\t\t\t   I40E_GLPRT_PRC9522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_size_big, &nsd->rx_size_big);\n\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC64H(hw->port),\n\t\t\t   I40E_GLPRT_PTC64L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_64, &nsd->tx_size_64);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC127H(hw->port),\n\t\t\t   I40E_GLPRT_PTC127L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_127, &nsd->tx_size_127);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC255H(hw->port),\n\t\t\t   I40E_GLPRT_PTC255L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_255, &nsd->tx_size_255);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC511H(hw->port),\n\t\t\t   I40E_GLPRT_PTC511L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_511, &nsd->tx_size_511);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC1023H(hw->port),\n\t\t\t   I40E_GLPRT_PTC1023L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_1023, &nsd->tx_size_1023);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC1522H(hw->port),\n\t\t\t   I40E_GLPRT_PTC1522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_1522, &nsd->tx_size_1522);\n\ti40e_stat_update48(hw, I40E_GLPRT_PTC9522H(hw->port),\n\t\t\t   I40E_GLPRT_PTC9522L(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_size_big, &nsd->tx_size_big);\n\n\ti40e_stat_update32(hw, I40E_GLPRT_RUC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_undersize, &nsd->rx_undersize);\n\ti40e_stat_update32(hw, I40E_GLPRT_RFC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_fragments, &nsd->rx_fragments);\n\ti40e_stat_update32(hw, I40E_GLPRT_ROC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_oversize, &nsd->rx_oversize);\n\ti40e_stat_update32(hw, I40E_GLPRT_RJC(hw->port),\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_jabber, &nsd->rx_jabber);\n\n\t \n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_ATR_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_atr_match);\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_SB_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_sb_match);\n\ti40e_stat_update_and_clear32(hw,\n\t\t\tI40E_GLQF_PCNT(I40E_FD_ATR_TUNNEL_STAT_IDX(hw->pf_id)),\n\t\t\t&nsd->fd_atr_tunnel_match);\n\n\tval = rd32(hw, I40E_PRTPM_EEE_STAT);\n\tnsd->tx_lpi_status =\n\t\t       (val & I40E_PRTPM_EEE_STAT_TX_LPI_STATUS_MASK) >>\n\t\t\tI40E_PRTPM_EEE_STAT_TX_LPI_STATUS_SHIFT;\n\tnsd->rx_lpi_status =\n\t\t       (val & I40E_PRTPM_EEE_STAT_RX_LPI_STATUS_MASK) >>\n\t\t\tI40E_PRTPM_EEE_STAT_RX_LPI_STATUS_SHIFT;\n\ti40e_stat_update32(hw, I40E_PRTPM_TLPIC,\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->tx_lpi_count, &nsd->tx_lpi_count);\n\ti40e_stat_update32(hw, I40E_PRTPM_RLPIC,\n\t\t\t   pf->stat_offsets_loaded,\n\t\t\t   &osd->rx_lpi_count, &nsd->rx_lpi_count);\n\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED &&\n\t    !test_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state))\n\t\tnsd->fd_sb_status = true;\n\telse\n\t\tnsd->fd_sb_status = false;\n\n\tif (pf->flags & I40E_FLAG_FD_ATR_ENABLED &&\n\t    !test_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state))\n\t\tnsd->fd_atr_status = true;\n\telse\n\t\tnsd->fd_atr_status = false;\n\n\tpf->stat_offsets_loaded = true;\n}\n\n \nvoid i40e_update_stats(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (vsi == pf->vsi[pf->lan_vsi])\n\t\ti40e_update_pf_stats(pf);\n\n\ti40e_update_vsi_stats(vsi);\n}\n\n \nint i40e_count_filters(struct i40e_vsi *vsi)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\tint cnt = 0;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist)\n\t\t++cnt;\n\n\treturn cnt;\n}\n\n \nstatic struct i40e_mac_filter *i40e_find_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t\tconst u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tkey = i40e_addr_to_hkey(macaddr);\n\thash_for_each_possible(vsi->mac_filter_hash, f, hlist, key) {\n\t\tif ((ether_addr_equal(macaddr, f->macaddr)) &&\n\t\t    (vlan == f->vlan))\n\t\t\treturn f;\n\t}\n\treturn NULL;\n}\n\n \nstruct i40e_mac_filter *i40e_find_mac(struct i40e_vsi *vsi, const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tkey = i40e_addr_to_hkey(macaddr);\n\thash_for_each_possible(vsi->mac_filter_hash, f, hlist, key) {\n\t\tif ((ether_addr_equal(macaddr, f->macaddr)))\n\t\t\treturn f;\n\t}\n\treturn NULL;\n}\n\n \nbool i40e_is_vsi_in_vlan(struct i40e_vsi *vsi)\n{\n\t \n\tif (vsi->info.pvid)\n\t\treturn true;\n\n\t \n\treturn vsi->has_vlan_filter;\n}\n\n \nstatic int i40e_correct_mac_vlan_filters(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *tmp_add_list,\n\t\t\t\t\t struct hlist_head *tmp_del_list,\n\t\t\t\t\t int vlan_filters)\n{\n\ts16 pvid = le16_to_cpu(vsi->info.pvid);\n\tstruct i40e_mac_filter *f, *add_head;\n\tstruct i40e_new_mac_filter *new;\n\tstruct hlist_node *h;\n\tint bkt, new_vlan;\n\n\t \n\n\t \n\thlist_for_each_entry(new, tmp_add_list, hlist) {\n\t\tif (pvid && new->f->vlan != pvid)\n\t\t\tnew->f->vlan = pvid;\n\t\telse if (vlan_filters && new->f->vlan == I40E_VLAN_ANY)\n\t\t\tnew->f->vlan = 0;\n\t\telse if (!vlan_filters && new->f->vlan == 0)\n\t\t\tnew->f->vlan = I40E_VLAN_ANY;\n\t}\n\n\t \n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\t \n\t\tif ((pvid && f->vlan != pvid) ||\n\t\t    (vlan_filters && f->vlan == I40E_VLAN_ANY) ||\n\t\t    (!vlan_filters && f->vlan == 0)) {\n\t\t\t \n\t\t\tif (pvid)\n\t\t\t\tnew_vlan = pvid;\n\t\t\telse if (vlan_filters)\n\t\t\t\tnew_vlan = 0;\n\t\t\telse\n\t\t\t\tnew_vlan = I40E_VLAN_ANY;\n\n\t\t\t \n\t\t\tadd_head = i40e_add_filter(vsi, f->macaddr, new_vlan);\n\t\t\tif (!add_head)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\t \n\t\t\tnew = kzalloc(sizeof(*new), GFP_ATOMIC);\n\t\t\tif (!new)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tnew->f = add_head;\n\t\t\tnew->state = add_head->state;\n\n\t\t\t \n\t\t\thlist_add_head(&new->hlist, tmp_add_list);\n\n\t\t\t \n\t\t\tf->state = I40E_FILTER_REMOVE;\n\t\t\thash_del(&f->hlist);\n\t\t\thlist_add_head(&f->hlist, tmp_del_list);\n\t\t}\n\t}\n\n\tvsi->has_vlan_filter = !!vlan_filters;\n\n\treturn 0;\n}\n\n \nstatic s16 i40e_get_vf_new_vlan(struct i40e_vsi *vsi,\n\t\t\t\tstruct i40e_new_mac_filter *new_mac,\n\t\t\t\tstruct i40e_mac_filter *f,\n\t\t\t\tint vlan_filters,\n\t\t\t\tbool trusted)\n{\n\ts16 pvid = le16_to_cpu(vsi->info.pvid);\n\tstruct i40e_pf *pf = vsi->back;\n\tbool is_any;\n\n\tif (new_mac)\n\t\tf = new_mac->f;\n\n\tif (pvid && f->vlan != pvid)\n\t\treturn pvid;\n\n\tis_any = (trusted ||\n\t\t  !(pf->flags & I40E_FLAG_VF_VLAN_PRUNING));\n\n\tif ((vlan_filters && f->vlan == I40E_VLAN_ANY) ||\n\t    (!is_any && !vlan_filters && f->vlan == I40E_VLAN_ANY) ||\n\t    (is_any && !vlan_filters && f->vlan == 0)) {\n\t\tif (is_any)\n\t\t\treturn I40E_VLAN_ANY;\n\t\telse\n\t\t\treturn 0;\n\t}\n\n\treturn f->vlan;\n}\n\n \nstatic int i40e_correct_vf_mac_vlan_filters(struct i40e_vsi *vsi,\n\t\t\t\t\t    struct hlist_head *tmp_add_list,\n\t\t\t\t\t    struct hlist_head *tmp_del_list,\n\t\t\t\t\t    int vlan_filters,\n\t\t\t\t\t    bool trusted)\n{\n\tstruct i40e_mac_filter *f, *add_head;\n\tstruct i40e_new_mac_filter *new_mac;\n\tstruct hlist_node *h;\n\tint bkt, new_vlan;\n\n\thlist_for_each_entry(new_mac, tmp_add_list, hlist) {\n\t\tnew_mac->f->vlan = i40e_get_vf_new_vlan(vsi, new_mac, NULL,\n\t\t\t\t\t\t\tvlan_filters, trusted);\n\t}\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tnew_vlan = i40e_get_vf_new_vlan(vsi, NULL, f, vlan_filters,\n\t\t\t\t\t\ttrusted);\n\t\tif (new_vlan != f->vlan) {\n\t\t\tadd_head = i40e_add_filter(vsi, f->macaddr, new_vlan);\n\t\t\tif (!add_head)\n\t\t\t\treturn -ENOMEM;\n\t\t\t \n\t\t\tnew_mac = kzalloc(sizeof(*new_mac), GFP_ATOMIC);\n\t\t\tif (!new_mac)\n\t\t\t\treturn -ENOMEM;\n\t\t\tnew_mac->f = add_head;\n\t\t\tnew_mac->state = add_head->state;\n\n\t\t\t \n\t\t\thlist_add_head(&new_mac->hlist, tmp_add_list);\n\n\t\t\t \n\t\t\tf->state = I40E_FILTER_REMOVE;\n\t\t\thash_del(&f->hlist);\n\t\t\thlist_add_head(&f->hlist, tmp_del_list);\n\t\t}\n\t}\n\n\tvsi->has_vlan_filter = !!vlan_filters;\n\treturn 0;\n}\n\n \nstatic void i40e_rm_default_mac_filter(struct i40e_vsi *vsi, u8 *macaddr)\n{\n\tstruct i40e_aqc_remove_macvlan_element_data element;\n\tstruct i40e_pf *pf = vsi->back;\n\n\t \n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn;\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\t \n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\ti40e_aq_remove_macvlan(&pf->hw, vsi->seid, &element, 1, NULL);\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\t \n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH |\n\t\t\tI40E_AQC_MACVLAN_DEL_IGNORE_VLAN;\n\ti40e_aq_remove_macvlan(&pf->hw, vsi->seid, &element, 1, NULL);\n}\n\n \nstruct i40e_mac_filter *i40e_add_filter(struct i40e_vsi *vsi,\n\t\t\t\t\tconst u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\tu64 key;\n\n\tif (!vsi || !macaddr)\n\t\treturn NULL;\n\n\tf = i40e_find_filter(vsi, macaddr, vlan);\n\tif (!f) {\n\t\tf = kzalloc(sizeof(*f), GFP_ATOMIC);\n\t\tif (!f)\n\t\t\treturn NULL;\n\n\t\t \n\t\tif (vlan >= 0)\n\t\t\tvsi->has_vlan_filter = true;\n\n\t\tether_addr_copy(f->macaddr, macaddr);\n\t\tf->vlan = vlan;\n\t\tf->state = I40E_FILTER_NEW;\n\t\tINIT_HLIST_NODE(&f->hlist);\n\n\t\tkey = i40e_addr_to_hkey(macaddr);\n\t\thash_add(vsi->mac_filter_hash, &f->hlist, key);\n\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n\t}\n\n\t \n\tif (f->state == I40E_FILTER_REMOVE)\n\t\tf->state = I40E_FILTER_ACTIVE;\n\n\treturn f;\n}\n\n \nvoid __i40e_del_filter(struct i40e_vsi *vsi, struct i40e_mac_filter *f)\n{\n\tif (!f)\n\t\treturn;\n\n\t \n\tif ((f->state == I40E_FILTER_FAILED) ||\n\t    (f->state == I40E_FILTER_NEW)) {\n\t\thash_del(&f->hlist);\n\t\tkfree(f);\n\t} else {\n\t\tf->state = I40E_FILTER_REMOVE;\n\t}\n\n\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n}\n\n \nvoid i40e_del_filter(struct i40e_vsi *vsi, const u8 *macaddr, s16 vlan)\n{\n\tstruct i40e_mac_filter *f;\n\n\tif (!vsi || !macaddr)\n\t\treturn;\n\n\tf = i40e_find_filter(vsi, macaddr, vlan);\n\t__i40e_del_filter(vsi, f);\n}\n\n \nstruct i40e_mac_filter *i40e_add_mac_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t    const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f, *add = NULL;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\tif (vsi->info.pvid)\n\t\treturn i40e_add_filter(vsi, macaddr,\n\t\t\t\t       le16_to_cpu(vsi->info.pvid));\n\n\tif (!i40e_is_vsi_in_vlan(vsi))\n\t\treturn i40e_add_filter(vsi, macaddr, I40E_VLAN_ANY);\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->state == I40E_FILTER_REMOVE)\n\t\t\tcontinue;\n\t\tadd = i40e_add_filter(vsi, macaddr, f->vlan);\n\t\tif (!add)\n\t\t\treturn NULL;\n\t}\n\n\treturn add;\n}\n\n \nint i40e_del_mac_filter(struct i40e_vsi *vsi, const u8 *macaddr)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tbool found = false;\n\tint bkt;\n\n\tlockdep_assert_held(&vsi->mac_filter_hash_lock);\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (ether_addr_equal(macaddr, f->macaddr)) {\n\t\t\t__i40e_del_filter(vsi, f);\n\t\t\tfound = true;\n\t\t}\n\t}\n\n\tif (found)\n\t\treturn 0;\n\telse\n\t\treturn -ENOENT;\n}\n\n \nstatic int i40e_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct sockaddr *addr = p;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\treturn -EADDRNOTAVAIL;\n\n\tif (ether_addr_equal(hw->mac.addr, addr->sa_data))\n\t\tnetdev_info(netdev, \"returning to hw mac address %pM\\n\",\n\t\t\t    hw->mac.addr);\n\telse\n\t\tnetdev_info(netdev, \"set new mac address %pM\\n\", addr->sa_data);\n\n\t \n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_del_mac_filter(vsi, netdev->dev_addr);\n\teth_hw_addr_set(netdev, addr->sa_data);\n\ti40e_add_mac_filter(vsi, netdev->dev_addr);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tint ret;\n\n\t\tret = i40e_aq_mac_address_write(hw, I40E_AQC_WRITE_TYPE_LAA_WOL,\n\t\t\t\t\t\taddr->sa_data, NULL);\n\t\tif (ret)\n\t\t\tnetdev_info(netdev, \"Ignoring error from firmware on LAA update, status %pe, AQ ret %s\\n\",\n\t\t\t\t    ERR_PTR(ret),\n\t\t\t\t    i40e_aq_str(hw, hw->aq.asq_last_status));\n\t}\n\n\t \n\ti40e_service_event_schedule(pf);\n\treturn 0;\n}\n\n \nstatic int i40e_config_rss_aq(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t      u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret = 0;\n\n\tif (seed) {\n\t\tstruct i40e_aqc_get_set_rss_key_data *seed_dw =\n\t\t\t(struct i40e_aqc_get_set_rss_key_data *)seed;\n\t\tret = i40e_aq_set_rss_key(hw, vsi->id, seed_dw);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot set RSS key, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\tif (lut) {\n\t\tbool pf_lut = vsi->type == I40E_VSI_MAIN;\n\n\t\tret = i40e_aq_set_rss_lut(hw, vsi->id, pf_lut, lut, lut_size);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot set RSS lut, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn ret;\n}\n\n \nstatic int i40e_vsi_config_rss(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tu8 *lut;\n\tint ret;\n\n\tif (!(pf->hw_features & I40E_HW_RSS_AQ_CAPABLE))\n\t\treturn 0;\n\tif (!vsi->rss_size)\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size,\n\t\t\t\t      vsi->num_queue_pairs);\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t \n\tif (vsi->rss_lut_user)\n\t\tmemcpy(lut, vsi->rss_lut_user, vsi->rss_table_size);\n\telse\n\t\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, vsi->rss_size);\n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\tret = i40e_config_rss_aq(vsi, seed, lut, vsi->rss_table_size);\n\tkfree(lut);\n\treturn ret;\n}\n\n \nstatic int i40e_vsi_setup_queue_map_mqprio(struct i40e_vsi *vsi,\n\t\t\t\t\t   struct i40e_vsi_context *ctxt,\n\t\t\t\t\t   u8 enabled_tc)\n{\n\tu16 qcount = 0, max_qcount, qmap, sections = 0;\n\tint i, override_q, pow, num_qps, ret;\n\tu8 netdev_tc = 0, offset = 0;\n\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn -EINVAL;\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\tvsi->tc_config.numtc = vsi->mqprio_qopt.qopt.num_tc;\n\tvsi->tc_config.enabled_tc = enabled_tc ? enabled_tc : 1;\n\tnum_qps = vsi->mqprio_qopt.qopt.count[0];\n\n\t \n\tpow = ilog2(num_qps);\n\tif (!is_power_of_2(num_qps))\n\t\tpow++;\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t \n\tmax_qcount = vsi->mqprio_qopt.qopt.count[0];\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t \n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\toffset = vsi->mqprio_qopt.qopt.offset[i];\n\t\t\tqcount = vsi->mqprio_qopt.qopt.count[i];\n\t\t\tif (qcount > max_qcount)\n\t\t\t\tmax_qcount = qcount;\n\t\t\tvsi->tc_config.tc_info[i].qoffset = offset;\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = netdev_tc++;\n\t\t} else {\n\t\t\t \n\t\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\t\t}\n\t}\n\n\t \n\tvsi->num_queue_pairs = offset + qcount;\n\n\t \n\tctxt->info.tc_mapping[0] = cpu_to_le16(qmap);\n\tctxt->info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt->info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n\n\t \n\tvsi->rss_size = max_qcount;\n\tret = i40e_vsi_config_rss(vsi);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to reconfig rss for num_queues (%u)\\n\",\n\t\t\t max_qcount);\n\t\treturn ret;\n\t}\n\tvsi->reconfig_rss = true;\n\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\"Reconfigured rss with num_queues (%u)\\n\", max_qcount);\n\n\t \n\toverride_q = vsi->mqprio_qopt.qopt.count[0];\n\tif (override_q && override_q < vsi->num_queue_pairs) {\n\t\tvsi->cnt_q_avail = vsi->num_queue_pairs - override_q;\n\t\tvsi->next_base_queue = override_q;\n\t}\n\treturn 0;\n}\n\n \nstatic void i40e_vsi_setup_queue_map(struct i40e_vsi *vsi,\n\t\t\t\t     struct i40e_vsi_context *ctxt,\n\t\t\t\t     u8 enabled_tc,\n\t\t\t\t     bool is_add)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu16 num_tc_qps = 0;\n\tu16 sections = 0;\n\tu8 netdev_tc = 0;\n\tu16 numtc = 1;\n\tu16 qcount;\n\tu8 offset;\n\tu16 qmap;\n\tint i;\n\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\toffset = 0;\n\t \n\tmemset(ctxt->info.queue_mapping, 0, sizeof(ctxt->info.queue_mapping));\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t \n\t\tif (vsi->req_queue_pairs > 0)\n\t\t\tvsi->num_queue_pairs = vsi->req_queue_pairs;\n\t\telse if (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tvsi->num_queue_pairs = pf->num_lan_msix;\n\t\telse\n\t\t\tvsi->num_queue_pairs = 1;\n\t}\n\n\t \n\tif (vsi->type == I40E_VSI_MAIN ||\n\t    (vsi->type == I40E_VSI_SRIOV && vsi->num_queue_pairs != 0))\n\t\tnum_tc_qps = vsi->num_queue_pairs;\n\telse\n\t\tnum_tc_qps = vsi->alloc_queue_pairs;\n\n\tif (enabled_tc && (vsi->back->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t \n\t\tfor (i = 0, numtc = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t\tif (enabled_tc & BIT(i))  \n\t\t\t\tnumtc++;\n\t\t}\n\t\tif (!numtc) {\n\t\t\tdev_warn(&pf->pdev->dev, \"DCB is enabled but no TC enabled, forcing TC0\\n\");\n\t\t\tnumtc = 1;\n\t\t}\n\t\tnum_tc_qps = num_tc_qps / numtc;\n\t\tnum_tc_qps = min_t(int, num_tc_qps,\n\t\t\t\t   i40e_pf_get_max_q_per_tc(pf));\n\t}\n\n\tvsi->tc_config.numtc = numtc;\n\tvsi->tc_config.enabled_tc = enabled_tc ? enabled_tc : 1;\n\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tnum_tc_qps = min_t(int, num_tc_qps, pf->num_lan_msix);\n\n\t \n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t \n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\t \n\t\t\tint pow, num_qps;\n\n\t\t\tswitch (vsi->type) {\n\t\t\tcase I40E_VSI_MAIN:\n\t\t\t\tif (!(pf->flags & (I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t    I40E_FLAG_FD_ATR_ENABLED)) ||\n\t\t\t\t    vsi->tc_config.enabled_tc != 1) {\n\t\t\t\t\tqcount = min_t(int, pf->alloc_rss_size,\n\t\t\t\t\t\t       num_tc_qps);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tfallthrough;\n\t\t\tcase I40E_VSI_FDIR:\n\t\t\tcase I40E_VSI_SRIOV:\n\t\t\tcase I40E_VSI_VMDQ2:\n\t\t\tdefault:\n\t\t\t\tqcount = num_tc_qps;\n\t\t\t\tWARN_ON(i != 0);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvsi->tc_config.tc_info[i].qoffset = offset;\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\n\t\t\t \n\t\t\tnum_qps = qcount;\n\t\t\tpow = 0;\n\t\t\twhile (num_qps && (BIT_ULL(pow) < qcount)) {\n\t\t\t\tpow++;\n\t\t\t\tnum_qps >>= 1;\n\t\t\t}\n\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = netdev_tc++;\n\t\t\tqmap =\n\t\t\t    (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t\t    (pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t\t\toffset += qcount;\n\t\t} else {\n\t\t\t \n\t\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\n\t\t\tqmap = 0;\n\t\t}\n\t\tctxt->info.tc_mapping[i] = cpu_to_le16(qmap);\n\t}\n\t \n\tif ((vsi->type == I40E_VSI_MAIN && numtc != 1) ||\n\t    (vsi->type == I40E_VSI_SRIOV && vsi->num_queue_pairs == 0) ||\n\t    (vsi->type != I40E_VSI_MAIN && vsi->type != I40E_VSI_SRIOV))\n\t\tvsi->num_queue_pairs = offset;\n\n\t \n\tif (is_add) {\n\t\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\n\t\tctxt->info.up_enable_bits = enabled_tc;\n\t}\n\tif (vsi->type == I40E_VSI_SRIOV) {\n\t\tctxt->info.mapping_flags |=\n\t\t\t\t     cpu_to_le16(I40E_AQ_VSI_QUE_MAP_NONCONTIG);\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tctxt->info.queue_mapping[i] =\n\t\t\t\t\t       cpu_to_le16(vsi->base_queue + i);\n\t} else {\n\t\tctxt->info.mapping_flags |=\n\t\t\t\t\tcpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\t\tctxt->info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\t}\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n}\n\n \nstatic int i40e_addr_sync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (i40e_add_mac_filter(vsi, addr))\n\t\treturn 0;\n\telse\n\t\treturn -ENOMEM;\n}\n\n \nstatic int i40e_addr_unsync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\t \n\tif (ether_addr_equal(addr, netdev->dev_addr))\n\t\treturn 0;\n\n\ti40e_del_mac_filter(vsi, addr);\n\n\treturn 0;\n}\n\n \nstatic void i40e_set_rx_mode(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\n\t__dev_uc_sync(netdev, i40e_addr_sync, i40e_addr_unsync);\n\t__dev_mc_sync(netdev, i40e_addr_sync, i40e_addr_unsync);\n\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t \n\tif (vsi->current_netdev_flags != vsi->netdev->flags) {\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, vsi->back->state);\n\t}\n}\n\n \nstatic void i40e_undo_del_filter_entries(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *from)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\n\thlist_for_each_entry_safe(f, h, from, hlist) {\n\t\tu64 key = i40e_addr_to_hkey(f->macaddr);\n\n\t\t \n\t\thlist_del(&f->hlist);\n\t\thash_add(vsi->mac_filter_hash, &f->hlist, key);\n\t}\n}\n\n \nstatic void i40e_undo_add_filter_entries(struct i40e_vsi *vsi,\n\t\t\t\t\t struct hlist_head *from)\n{\n\tstruct i40e_new_mac_filter *new;\n\tstruct hlist_node *h;\n\n\thlist_for_each_entry_safe(new, h, from, hlist) {\n\t\t \n\t\thlist_del(&new->hlist);\n\t\tnetdev_hw_addr_refcnt(new->f, vsi->netdev, -1);\n\t\tkfree(new);\n\t}\n}\n\n \nstatic\nstruct i40e_new_mac_filter *i40e_next_filter(struct i40e_new_mac_filter *next)\n{\n\thlist_for_each_entry_continue(next, hlist) {\n\t\tif (!is_broadcast_ether_addr(next->f->macaddr))\n\t\t\treturn next;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic int\ni40e_update_filter_state(int count,\n\t\t\t struct i40e_aqc_add_macvlan_element_data *add_list,\n\t\t\t struct i40e_new_mac_filter *add_head)\n{\n\tint retval = 0;\n\tint i;\n\n\tfor (i = 0; i < count; i++) {\n\t\t \n\t\tif (add_list[i].match_method == I40E_AQC_MM_ERR_NO_RES) {\n\t\t\tadd_head->state = I40E_FILTER_FAILED;\n\t\t} else {\n\t\t\tadd_head->state = I40E_FILTER_ACTIVE;\n\t\t\tretval++;\n\t\t}\n\n\t\tadd_head = i40e_next_filter(add_head);\n\t\tif (!add_head)\n\t\t\tbreak;\n\t}\n\n\treturn retval;\n}\n\n \nstatic\nvoid i40e_aqc_del_filters(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_aqc_remove_macvlan_element_data *list,\n\t\t\t  int num_del, int *retval)\n{\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tenum i40e_admin_queue_err aq_status;\n\tint aq_ret;\n\n\taq_ret = i40e_aq_remove_macvlan_v2(hw, vsi->seid, list, num_del, NULL,\n\t\t\t\t\t   &aq_status);\n\n\t \n\tif (aq_ret && !(aq_status == I40E_AQ_RC_ENOENT)) {\n\t\t*retval = -EIO;\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"ignoring delete macvlan error on %s, err %pe, aq_err %s\\n\",\n\t\t\t vsi_name, ERR_PTR(aq_ret),\n\t\t\t i40e_aq_str(hw, aq_status));\n\t}\n}\n\n \nstatic\nvoid i40e_aqc_add_filters(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_aqc_add_macvlan_element_data *list,\n\t\t\t  struct i40e_new_mac_filter *add_head,\n\t\t\t  int num_add)\n{\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tenum i40e_admin_queue_err aq_status;\n\tint fcnt;\n\n\ti40e_aq_add_macvlan_v2(hw, vsi->seid, list, num_add, NULL, &aq_status);\n\tfcnt = i40e_update_filter_state(num_add, list, add_head);\n\n\tif (fcnt != num_add) {\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tset_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, promiscuous mode forced on\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_status), vsi_name);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV ||\n\t\t\t   vsi->type == I40E_VSI_VMDQ1 ||\n\t\t\t   vsi->type == I40E_VSI_VMDQ2) {\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, please set promiscuous on manually for %s\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_status), vsi_name,\n\t\t\t\t\t     vsi_name);\n\t\t} else {\n\t\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t\t \"Error %s adding RX filters on %s, incorrect VSI type: %i.\\n\",\n\t\t\t\t i40e_aq_str(hw, aq_status), vsi_name,\n\t\t\t\t\t     vsi->type);\n\t\t}\n\t}\n}\n\n \nstatic int\ni40e_aqc_broadcast_filter(struct i40e_vsi *vsi, const char *vsi_name,\n\t\t\t  struct i40e_mac_filter *f)\n{\n\tbool enable = f->state == I40E_FILTER_NEW;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tint aq_ret;\n\n\tif (f->vlan == I40E_VLAN_ANY) {\n\t\taq_ret = i40e_aq_set_vsi_broadcast(hw,\n\t\t\t\t\t\t   vsi->seid,\n\t\t\t\t\t\t   enable,\n\t\t\t\t\t\t   NULL);\n\t} else {\n\t\taq_ret = i40e_aq_set_vsi_bc_promisc_on_vlan(hw,\n\t\t\t\t\t\t\t    vsi->seid,\n\t\t\t\t\t\t\t    enable,\n\t\t\t\t\t\t\t    f->vlan,\n\t\t\t\t\t\t\t    NULL);\n\t}\n\n\tif (aq_ret) {\n\t\tset_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t \"Error %s, forcing overflow promiscuous on %s\\n\",\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status),\n\t\t\t vsi_name);\n\t}\n\n\treturn aq_ret;\n}\n\n \nstatic int i40e_set_promiscuous(struct i40e_pf *pf, bool promisc)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_hw *hw = &pf->hw;\n\tint aq_ret;\n\n\tif (vsi->type == I40E_VSI_MAIN &&\n\t    pf->lan_veb != I40E_NO_VEB &&\n\t    !(pf->flags & I40E_FLAG_MFP_ENABLED)) {\n\t\t \n\t\tif (promisc)\n\t\t\taq_ret = i40e_aq_set_default_vsi(hw,\n\t\t\t\t\t\t\t vsi->seid,\n\t\t\t\t\t\t\t NULL);\n\t\telse\n\t\t\taq_ret = i40e_aq_clear_default_vsi(hw,\n\t\t\t\t\t\t\t   vsi->seid,\n\t\t\t\t\t\t\t   NULL);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Set default VSI failed, err %pe, aq_err %s\\n\",\n\t\t\t\t ERR_PTR(aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t} else {\n\t\taq_ret = i40e_aq_set_vsi_unicast_promiscuous(\n\t\t\t\t\t\t  hw,\n\t\t\t\t\t\t  vsi->seid,\n\t\t\t\t\t\t  promisc, NULL,\n\t\t\t\t\t\t  true);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set unicast promisc failed, err %pe, aq_err %s\\n\",\n\t\t\t\t ERR_PTR(aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t\taq_ret = i40e_aq_set_vsi_multicast_promiscuous(\n\t\t\t\t\t\t  hw,\n\t\t\t\t\t\t  vsi->seid,\n\t\t\t\t\t\t  promisc, NULL);\n\t\tif (aq_ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set multicast promisc failed, err %pe, aq_err %s\\n\",\n\t\t\t\t ERR_PTR(aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t}\n\n\tif (!aq_ret)\n\t\tpf->cur_promisc = promisc;\n\n\treturn aq_ret;\n}\n\n \nint i40e_sync_vsi_filters(struct i40e_vsi *vsi)\n{\n\tstruct hlist_head tmp_add_list, tmp_del_list;\n\tstruct i40e_mac_filter *f;\n\tstruct i40e_new_mac_filter *new, *add_head = NULL;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tbool old_overflow, new_overflow;\n\tunsigned int failed_filters = 0;\n\tunsigned int vlan_filters = 0;\n\tchar vsi_name[16] = \"PF\";\n\tint filter_list_len = 0;\n\tu32 changed_flags = 0;\n\tstruct hlist_node *h;\n\tstruct i40e_pf *pf;\n\tint num_add = 0;\n\tint num_del = 0;\n\tint aq_ret = 0;\n\tint retval = 0;\n\tu16 cmd_flags;\n\tint list_size;\n\tint bkt;\n\n\t \n\tstruct i40e_aqc_add_macvlan_element_data *add_list;\n\tstruct i40e_aqc_remove_macvlan_element_data *del_list;\n\n\twhile (test_and_set_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state))\n\t\tusleep_range(1000, 2000);\n\tpf = vsi->back;\n\n\told_overflow = test_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\n\tif (vsi->netdev) {\n\t\tchanged_flags = vsi->current_netdev_flags ^ vsi->netdev->flags;\n\t\tvsi->current_netdev_flags = vsi->netdev->flags;\n\t}\n\n\tINIT_HLIST_HEAD(&tmp_add_list);\n\tINIT_HLIST_HEAD(&tmp_del_list);\n\n\tif (vsi->type == I40E_VSI_SRIOV)\n\t\tsnprintf(vsi_name, sizeof(vsi_name) - 1, \"VF %d\", vsi->vf_id);\n\telse if (vsi->type != I40E_VSI_MAIN)\n\t\tsnprintf(vsi_name, sizeof(vsi_name) - 1, \"vsi %d\", vsi->seid);\n\n\tif (vsi->flags & I40E_VSI_FLAG_FILTER_CHANGED) {\n\t\tvsi->flags &= ~I40E_VSI_FLAG_FILTER_CHANGED;\n\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\t \n\t\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\t\tif (f->state == I40E_FILTER_REMOVE) {\n\t\t\t\t \n\t\t\t\thash_del(&f->hlist);\n\t\t\t\thlist_add_head(&f->hlist, &tmp_del_list);\n\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (f->state == I40E_FILTER_NEW) {\n\t\t\t\t \n\t\t\t\tnew = kzalloc(sizeof(*new), GFP_ATOMIC);\n\t\t\t\tif (!new)\n\t\t\t\t\tgoto err_no_memory_locked;\n\n\t\t\t\t \n\t\t\t\tnew->f = f;\n\t\t\t\tnew->state = f->state;\n\n\t\t\t\t \n\t\t\t\thlist_add_head(&new->hlist, &tmp_add_list);\n\t\t\t}\n\n\t\t\t \n\t\t\tif (f->vlan > 0)\n\t\t\t\tvlan_filters++;\n\t\t}\n\n\t\tif (vsi->type != I40E_VSI_SRIOV)\n\t\t\tretval = i40e_correct_mac_vlan_filters\n\t\t\t\t(vsi, &tmp_add_list, &tmp_del_list,\n\t\t\t\t vlan_filters);\n\t\telse if (pf->vf)\n\t\t\tretval = i40e_correct_vf_mac_vlan_filters\n\t\t\t\t(vsi, &tmp_add_list, &tmp_del_list,\n\t\t\t\t vlan_filters, pf->vf[vsi->vf_id].trusted);\n\n\t\thlist_for_each_entry(new, &tmp_add_list, hlist)\n\t\t\tnetdev_hw_addr_refcnt(new->f, vsi->netdev, 1);\n\n\t\tif (retval)\n\t\t\tgoto err_no_memory_locked;\n\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t}\n\n\t \n\tif (!hlist_empty(&tmp_del_list)) {\n\t\tfilter_list_len = hw->aq.asq_buf_size /\n\t\t\t    sizeof(struct i40e_aqc_remove_macvlan_element_data);\n\t\tlist_size = filter_list_len *\n\t\t\t    sizeof(struct i40e_aqc_remove_macvlan_element_data);\n\t\tdel_list = kzalloc(list_size, GFP_ATOMIC);\n\t\tif (!del_list)\n\t\t\tgoto err_no_memory;\n\n\t\thlist_for_each_entry_safe(f, h, &tmp_del_list, hlist) {\n\t\t\tcmd_flags = 0;\n\n\t\t\t \n\t\t\tif (is_broadcast_ether_addr(f->macaddr)) {\n\t\t\t\ti40e_aqc_broadcast_filter(vsi, vsi_name, f);\n\n\t\t\t\thlist_del(&f->hlist);\n\t\t\t\tkfree(f);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tether_addr_copy(del_list[num_del].mac_addr, f->macaddr);\n\t\t\tif (f->vlan == I40E_VLAN_ANY) {\n\t\t\t\tdel_list[num_del].vlan_tag = 0;\n\t\t\t\tcmd_flags |= I40E_AQC_MACVLAN_DEL_IGNORE_VLAN;\n\t\t\t} else {\n\t\t\t\tdel_list[num_del].vlan_tag =\n\t\t\t\t\tcpu_to_le16((u16)(f->vlan));\n\t\t\t}\n\n\t\t\tcmd_flags |= I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\t\t\tdel_list[num_del].flags = cmd_flags;\n\t\t\tnum_del++;\n\n\t\t\t \n\t\t\tif (num_del == filter_list_len) {\n\t\t\t\ti40e_aqc_del_filters(vsi, vsi_name, del_list,\n\t\t\t\t\t\t     num_del, &retval);\n\t\t\t\tmemset(del_list, 0, list_size);\n\t\t\t\tnum_del = 0;\n\t\t\t}\n\t\t\t \n\t\t\thlist_del(&f->hlist);\n\t\t\tkfree(f);\n\t\t}\n\n\t\tif (num_del) {\n\t\t\ti40e_aqc_del_filters(vsi, vsi_name, del_list,\n\t\t\t\t\t     num_del, &retval);\n\t\t}\n\n\t\tkfree(del_list);\n\t\tdel_list = NULL;\n\t}\n\n\tif (!hlist_empty(&tmp_add_list)) {\n\t\t \n\t\tfilter_list_len = hw->aq.asq_buf_size /\n\t\t\t       sizeof(struct i40e_aqc_add_macvlan_element_data);\n\t\tlist_size = filter_list_len *\n\t\t\t       sizeof(struct i40e_aqc_add_macvlan_element_data);\n\t\tadd_list = kzalloc(list_size, GFP_ATOMIC);\n\t\tif (!add_list)\n\t\t\tgoto err_no_memory;\n\n\t\tnum_add = 0;\n\t\thlist_for_each_entry_safe(new, h, &tmp_add_list, hlist) {\n\t\t\t \n\t\t\tif (is_broadcast_ether_addr(new->f->macaddr)) {\n\t\t\t\tif (i40e_aqc_broadcast_filter(vsi, vsi_name,\n\t\t\t\t\t\t\t      new->f))\n\t\t\t\t\tnew->state = I40E_FILTER_FAILED;\n\t\t\t\telse\n\t\t\t\t\tnew->state = I40E_FILTER_ACTIVE;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (num_add == 0)\n\t\t\t\tadd_head = new;\n\t\t\tcmd_flags = 0;\n\t\t\tether_addr_copy(add_list[num_add].mac_addr,\n\t\t\t\t\tnew->f->macaddr);\n\t\t\tif (new->f->vlan == I40E_VLAN_ANY) {\n\t\t\t\tadd_list[num_add].vlan_tag = 0;\n\t\t\t\tcmd_flags |= I40E_AQC_MACVLAN_ADD_IGNORE_VLAN;\n\t\t\t} else {\n\t\t\t\tadd_list[num_add].vlan_tag =\n\t\t\t\t\tcpu_to_le16((u16)(new->f->vlan));\n\t\t\t}\n\t\t\tadd_list[num_add].queue_number = 0;\n\t\t\t \n\t\t\tadd_list[num_add].match_method = I40E_AQC_MM_ERR_NO_RES;\n\t\t\tcmd_flags |= I40E_AQC_MACVLAN_ADD_PERFECT_MATCH;\n\t\t\tadd_list[num_add].flags = cpu_to_le16(cmd_flags);\n\t\t\tnum_add++;\n\n\t\t\t \n\t\t\tif (num_add == filter_list_len) {\n\t\t\t\ti40e_aqc_add_filters(vsi, vsi_name, add_list,\n\t\t\t\t\t\t     add_head, num_add);\n\t\t\t\tmemset(add_list, 0, list_size);\n\t\t\t\tnum_add = 0;\n\t\t\t}\n\t\t}\n\t\tif (num_add) {\n\t\t\ti40e_aqc_add_filters(vsi, vsi_name, add_list, add_head,\n\t\t\t\t\t     num_add);\n\t\t}\n\t\t \n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\thlist_for_each_entry_safe(new, h, &tmp_add_list, hlist) {\n\t\t\t \n\t\t\tif (new->f->state == I40E_FILTER_NEW)\n\t\t\t\tnew->f->state = new->state;\n\t\t\thlist_del(&new->hlist);\n\t\t\tnetdev_hw_addr_refcnt(new->f, vsi->netdev, -1);\n\t\t\tkfree(new);\n\t\t}\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t\tkfree(add_list);\n\t\tadd_list = NULL;\n\t}\n\n\t \n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\tvsi->active_filters = 0;\n\thash_for_each(vsi->mac_filter_hash, bkt, f, hlist) {\n\t\tif (f->state == I40E_FILTER_ACTIVE)\n\t\t\tvsi->active_filters++;\n\t\telse if (f->state == I40E_FILTER_FAILED)\n\t\t\tfailed_filters++;\n\t}\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t \n\tif (old_overflow && !failed_filters &&\n\t    vsi->active_filters < vsi->promisc_threshold) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"filter logjam cleared on %s, leaving overflow promiscuous mode\\n\",\n\t\t\t vsi_name);\n\t\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tvsi->promisc_threshold = 0;\n\t}\n\n\t \n\tif (vsi->type == I40E_VSI_SRIOV && pf->vf &&\n\t    !pf->vf[vsi->vf_id].trusted) {\n\t\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\t\tgoto out;\n\t}\n\n\tnew_overflow = test_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\n\t \n\tif (!old_overflow && new_overflow)\n\t\tvsi->promisc_threshold = (vsi->active_filters * 3) / 4;\n\n\t \n\tif (changed_flags & IFF_ALLMULTI) {\n\t\tbool cur_multipromisc;\n\n\t\tcur_multipromisc = !!(vsi->current_netdev_flags & IFF_ALLMULTI);\n\t\taq_ret = i40e_aq_set_vsi_multicast_promiscuous(&vsi->back->hw,\n\t\t\t\t\t\t\t       vsi->seid,\n\t\t\t\t\t\t\t       cur_multipromisc,\n\t\t\t\t\t\t\t       NULL);\n\t\tif (aq_ret) {\n\t\t\tretval = i40e_aq_rc_to_posix(aq_ret,\n\t\t\t\t\t\t     hw->aq.asq_last_status);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"set multi promisc failed on %s, err %pe aq_err %s\\n\",\n\t\t\t\t vsi_name,\n\t\t\t\t ERR_PTR(aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t} else {\n\t\t\tdev_info(&pf->pdev->dev, \"%s allmulti mode.\\n\",\n\t\t\t\t cur_multipromisc ? \"entering\" : \"leaving\");\n\t\t}\n\t}\n\n\tif ((changed_flags & IFF_PROMISC) || old_overflow != new_overflow) {\n\t\tbool cur_promisc;\n\n\t\tcur_promisc = (!!(vsi->current_netdev_flags & IFF_PROMISC) ||\n\t\t\t       new_overflow);\n\t\taq_ret = i40e_set_promiscuous(pf, cur_promisc);\n\t\tif (aq_ret) {\n\t\t\tretval = i40e_aq_rc_to_posix(aq_ret,\n\t\t\t\t\t\t     hw->aq.asq_last_status);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Setting promiscuous %s failed on %s, err %pe aq_err %s\\n\",\n\t\t\t\t cur_promisc ? \"on\" : \"off\",\n\t\t\t\t vsi_name,\n\t\t\t\t ERR_PTR(aq_ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t}\n\t}\nout:\n\t \n\tif (retval)\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\n\tclear_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state);\n\treturn retval;\n\nerr_no_memory:\n\t \n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\nerr_no_memory_locked:\n\ti40e_undo_del_filter_entries(vsi, &tmp_del_list);\n\ti40e_undo_add_filter_entries(vsi, &tmp_add_list);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\tclear_bit(__I40E_VSI_SYNCING_FILTERS, vsi->state);\n\treturn -ENOMEM;\n}\n\n \nstatic void i40e_sync_filters_subtask(struct i40e_pf *pf)\n{\n\tint v;\n\n\tif (!pf)\n\t\treturn;\n\tif (!test_and_clear_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state))\n\t\treturn;\n\tif (test_bit(__I40E_VF_DISABLE, pf->state)) {\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state);\n\t\treturn;\n\t}\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v] &&\n\t\t    (pf->vsi[v]->flags & I40E_VSI_FLAG_FILTER_CHANGED) &&\n\t\t    !test_bit(__I40E_VSI_RELEASING, pf->vsi[v]->state)) {\n\t\t\tint ret = i40e_sync_vsi_filters(pf->vsi[v]);\n\n\t\t\tif (ret) {\n\t\t\t\t \n\t\t\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING,\n\t\t\t\t\tpf->state);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic u16 i40e_calculate_vsi_rx_buf_len(struct i40e_vsi *vsi)\n{\n\tif (!vsi->netdev || (vsi->back->flags & I40E_FLAG_LEGACY_RX))\n\t\treturn SKB_WITH_OVERHEAD(I40E_RXBUFFER_2048);\n\n\treturn PAGE_SIZE < 8192 ? I40E_RXBUFFER_3072 : I40E_RXBUFFER_2048;\n}\n\n \nstatic int i40e_max_vsi_frame_size(struct i40e_vsi *vsi,\n\t\t\t\t   struct bpf_prog *xdp_prog)\n{\n\tu16 rx_buf_len = i40e_calculate_vsi_rx_buf_len(vsi);\n\tu16 chain_len;\n\n\tif (xdp_prog && !xdp_prog->aux->xdp_has_frags)\n\t\tchain_len = 1;\n\telse\n\t\tchain_len = I40E_MAX_CHAINED_RX_BUFFERS;\n\n\treturn min_t(u16, rx_buf_len * chain_len, I40E_MAX_RXBUFFER);\n}\n\n \nstatic int i40e_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tint frame_size;\n\n\tframe_size = i40e_max_vsi_frame_size(vsi, vsi->xdp_prog);\n\tif (new_mtu > frame_size - I40E_PACKET_HDR_PAD) {\n\t\tnetdev_err(netdev, \"Error changing mtu to %d, Max is %d\\n\",\n\t\t\t   new_mtu, frame_size - I40E_PACKET_HDR_PAD);\n\t\treturn -EINVAL;\n\t}\n\n\tnetdev_dbg(netdev, \"changing MTU from %d to %d\\n\",\n\t\t   netdev->mtu, new_mtu);\n\tnetdev->mtu = new_mtu;\n\tif (netif_running(netdev))\n\t\ti40e_vsi_reinit_locked(vsi);\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\tset_bit(__I40E_CLIENT_L2_CHANGE, pf->state);\n\treturn 0;\n}\n\n \nint i40e_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\n\tswitch (cmd) {\n\tcase SIOCGHWTSTAMP:\n\t\treturn i40e_ptp_get_ts_config(pf, ifr);\n\tcase SIOCSHWTSTAMP:\n\t\treturn i40e_ptp_set_ts_config(pf, ifr);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n \nvoid i40e_vlan_stripping_enable(struct i40e_vsi *vsi)\n{\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\t \n\tif (vsi->info.pvid)\n\t\treturn;\n\n\tif ((vsi->info.valid_sections &\n\t     cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID)) &&\n\t    ((vsi->info.port_vlan_flags & I40E_AQ_VSI_PVLAN_MODE_MASK) == 0))\n\t\treturn;   \n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_ALL |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_STR_BOTH;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"update vlan stripping failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t}\n}\n\n \nvoid i40e_vlan_stripping_disable(struct i40e_vsi *vsi)\n{\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\t \n\tif (vsi->info.pvid)\n\t\treturn;\n\n\tif ((vsi->info.valid_sections &\n\t     cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID)) &&\n\t    ((vsi->info.port_vlan_flags & I40E_AQ_VSI_PVLAN_EMOD_MASK) ==\n\t     I40E_AQ_VSI_PVLAN_EMOD_MASK))\n\t\treturn;   \n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_ALL |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_NOTHING;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"update vlan stripping failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t}\n}\n\n \nint i40e_add_vlan_all_mac(struct i40e_vsi *vsi, s16 vid)\n{\n\tstruct i40e_mac_filter *f, *add_f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\t \n\t\tif (f->state == I40E_FILTER_REMOVE && f->vlan == vid) {\n\t\t\tf->state = I40E_FILTER_ACTIVE;\n\t\t\tcontinue;\n\t\t} else if (f->state == I40E_FILTER_REMOVE) {\n\t\t\tcontinue;\n\t\t}\n\t\tadd_f = i40e_add_filter(vsi, f->macaddr, vid);\n\t\tif (!add_f) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Could not add vlan filter %d for %pM\\n\",\n\t\t\t\t vid, f->macaddr);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nint i40e_vsi_add_vlan(struct i40e_vsi *vsi, u16 vid)\n{\n\tint err;\n\n\tif (vsi->info.pvid)\n\t\treturn -EINVAL;\n\n\t \n\tif (!vid)\n\t\treturn 0;\n\n\t \n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\terr = i40e_add_vlan_all_mac(vsi, vid);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\tif (err)\n\t\treturn err;\n\n\t \n\ti40e_service_event_schedule(vsi->back);\n\treturn 0;\n}\n\n \nvoid i40e_rm_vlan_all_mac(struct i40e_vsi *vsi, s16 vid)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tif (f->vlan == vid)\n\t\t\t__i40e_del_filter(vsi, f);\n\t}\n}\n\n \nvoid i40e_vsi_kill_vlan(struct i40e_vsi *vsi, u16 vid)\n{\n\tif (!vid || vsi->info.pvid)\n\t\treturn;\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_rm_vlan_all_mac(vsi, vid);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t \n\ti40e_service_event_schedule(vsi->back);\n}\n\n \nstatic int i40e_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t__always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tint ret = 0;\n\n\tif (vid >= VLAN_N_VID)\n\t\treturn -EINVAL;\n\n\tret = i40e_vsi_add_vlan(vsi, vid);\n\tif (!ret)\n\t\tset_bit(vid, vsi->active_vlans);\n\n\treturn ret;\n}\n\n \nstatic void i40e_vlan_rx_add_vid_up(struct net_device *netdev,\n\t\t\t\t    __always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (vid >= VLAN_N_VID)\n\t\treturn;\n\tset_bit(vid, vsi->active_vlans);\n}\n\n \nstatic int i40e_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t __always_unused __be16 proto, u16 vid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\t \n\ti40e_vsi_kill_vlan(vsi, vid);\n\n\tclear_bit(vid, vsi->active_vlans);\n\n\treturn 0;\n}\n\n \nstatic void i40e_restore_vlan(struct i40e_vsi *vsi)\n{\n\tu16 vid;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tif (vsi->netdev->features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\ti40e_vlan_stripping_enable(vsi);\n\telse\n\t\ti40e_vlan_stripping_disable(vsi);\n\n\tfor_each_set_bit(vid, vsi->active_vlans, VLAN_N_VID)\n\t\ti40e_vlan_rx_add_vid_up(vsi->netdev, htons(ETH_P_8021Q),\n\t\t\t\t\tvid);\n}\n\n \nint i40e_vsi_add_pvid(struct i40e_vsi *vsi, u16 vid)\n{\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\tvsi->info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\tvsi->info.pvid = cpu_to_le16(vid);\n\tvsi->info.port_vlan_flags = I40E_AQ_VSI_PVLAN_MODE_TAGGED |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_INSERT_PVID |\n\t\t\t\t    I40E_AQ_VSI_PVLAN_EMOD_STR;\n\n\tctxt.seid = vsi->seid;\n\tctxt.info = vsi->info;\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"add pvid failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&vsi->back->hw,\n\t\t\t\t     vsi->back->hw.aq.asq_last_status));\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\n \nvoid i40e_vsi_remove_pvid(struct i40e_vsi *vsi)\n{\n\tvsi->info.pvid = 0;\n\n\ti40e_vlan_stripping_disable(vsi);\n}\n\n \nstatic int i40e_vsi_setup_tx_resources(struct i40e_vsi *vsi)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_tx_descriptors(vsi->tx_rings[i]);\n\n\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\treturn err;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_tx_descriptors(vsi->xdp_rings[i]);\n\n\treturn err;\n}\n\n \nstatic void i40e_vsi_free_tx_resources(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (vsi->tx_rings) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->tx_rings[i] && vsi->tx_rings[i]->desc)\n\t\t\t\ti40e_free_tx_resources(vsi->tx_rings[i]);\n\t}\n\n\tif (vsi->xdp_rings) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->xdp_rings[i] && vsi->xdp_rings[i]->desc)\n\t\t\t\ti40e_free_tx_resources(vsi->xdp_rings[i]);\n\t}\n}\n\n \nstatic int i40e_vsi_setup_rx_resources(struct i40e_vsi *vsi)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_setup_rx_descriptors(vsi->rx_rings[i]);\n\treturn err;\n}\n\n \nstatic void i40e_vsi_free_rx_resources(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (!vsi->rx_rings)\n\t\treturn;\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\tif (vsi->rx_rings[i] && vsi->rx_rings[i]->desc)\n\t\t\ti40e_free_rx_resources(vsi->rx_rings[i]);\n}\n\n \nstatic void i40e_config_xps_tx_ring(struct i40e_ring *ring)\n{\n\tint cpu;\n\n\tif (!ring->q_vector || !ring->netdev || ring->ch)\n\t\treturn;\n\n\t \n\tif (test_and_set_bit(__I40E_TX_XPS_INIT_DONE, ring->state))\n\t\treturn;\n\n\tcpu = cpumask_local_spread(ring->q_vector->v_idx, -1);\n\tnetif_set_xps_queue(ring->netdev, get_cpu_mask(cpu),\n\t\t\t    ring->queue_index);\n}\n\n \nstatic struct xsk_buff_pool *i40e_xsk_pool(struct i40e_ring *ring)\n{\n\tbool xdp_on = i40e_enabled_xdp_vsi(ring->vsi);\n\tint qid = ring->queue_index;\n\n\tif (ring_is_xdp(ring))\n\t\tqid -= ring->vsi->alloc_queue_pairs;\n\n\tif (!xdp_on || !test_bit(qid, ring->vsi->af_xdp_zc_qps))\n\t\treturn NULL;\n\n\treturn xsk_get_pool_from_qid(ring->vsi->netdev, qid);\n}\n\n \nstatic int i40e_configure_tx_ring(struct i40e_ring *ring)\n{\n\tstruct i40e_vsi *vsi = ring->vsi;\n\tu16 pf_q = vsi->base_queue + ring->queue_index;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tstruct i40e_hmc_obj_txq tx_ctx;\n\tu32 qtx_ctl = 0;\n\tint err = 0;\n\n\tif (ring_is_xdp(ring))\n\t\tring->xsk_pool = i40e_xsk_pool(ring);\n\n\t \n\tif (vsi->back->flags & I40E_FLAG_FD_ATR_ENABLED) {\n\t\tring->atr_sample_rate = vsi->back->atr_sample_rate;\n\t\tring->atr_count = 0;\n\t} else {\n\t\tring->atr_sample_rate = 0;\n\t}\n\n\t \n\ti40e_config_xps_tx_ring(ring);\n\n\t \n\tmemset(&tx_ctx, 0, sizeof(tx_ctx));\n\n\ttx_ctx.new_context = 1;\n\ttx_ctx.base = (ring->dma / 128);\n\ttx_ctx.qlen = ring->count;\n\ttx_ctx.fd_ena = !!(vsi->back->flags & (I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t\t       I40E_FLAG_FD_ATR_ENABLED));\n\ttx_ctx.timesync_ena = !!(vsi->back->flags & I40E_FLAG_PTP);\n\t \n\tif (vsi->type != I40E_VSI_FDIR)\n\t\ttx_ctx.head_wb_ena = 1;\n\ttx_ctx.head_wb_addr = ring->dma +\n\t\t\t      (ring->count * sizeof(struct i40e_tx_desc));\n\n\t \n\n\tif (ring->ch)\n\t\ttx_ctx.rdylist =\n\t\t\tle16_to_cpu(ring->ch->info.qs_handle[ring->dcb_tc]);\n\n\telse\n\t\ttx_ctx.rdylist = le16_to_cpu(vsi->info.qs_handle[ring->dcb_tc]);\n\n\ttx_ctx.rdylist_act = 0;\n\n\t \n\terr = i40e_clear_lan_tx_queue_context(hw, pf_q);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to clear LAN Tx queue context on Tx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\terr = i40e_set_lan_tx_queue_context(hw, pf_q, &tx_ctx);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to set LAN Tx queue context on Tx ring %d (pf_q %d, error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tif (ring->ch) {\n\t\tif (ring->ch->type == I40E_VSI_VMDQ2)\n\t\t\tqtx_ctl = I40E_QTX_CTL_VM_QUEUE;\n\t\telse\n\t\t\treturn -EINVAL;\n\n\t\tqtx_ctl |= (ring->ch->vsi_number <<\n\t\t\t    I40E_QTX_CTL_VFVM_INDX_SHIFT) &\n\t\t\t    I40E_QTX_CTL_VFVM_INDX_MASK;\n\t} else {\n\t\tif (vsi->type == I40E_VSI_VMDQ2) {\n\t\t\tqtx_ctl = I40E_QTX_CTL_VM_QUEUE;\n\t\t\tqtx_ctl |= ((vsi->id) << I40E_QTX_CTL_VFVM_INDX_SHIFT) &\n\t\t\t\t    I40E_QTX_CTL_VFVM_INDX_MASK;\n\t\t} else {\n\t\t\tqtx_ctl = I40E_QTX_CTL_PF_QUEUE;\n\t\t}\n\t}\n\n\tqtx_ctl |= ((hw->pf_id << I40E_QTX_CTL_PF_INDX_SHIFT) &\n\t\t    I40E_QTX_CTL_PF_INDX_MASK);\n\twr32(hw, I40E_QTX_CTL(pf_q), qtx_ctl);\n\ti40e_flush(hw);\n\n\t \n\tring->tail = hw->hw_addr + I40E_QTX_TAIL(pf_q);\n\n\treturn 0;\n}\n\n \nstatic unsigned int i40e_rx_offset(struct i40e_ring *rx_ring)\n{\n\treturn ring_uses_build_skb(rx_ring) ? I40E_SKB_PAD : 0;\n}\n\n \nstatic int i40e_configure_rx_ring(struct i40e_ring *ring)\n{\n\tstruct i40e_vsi *vsi = ring->vsi;\n\tu32 chain_len = vsi->back->hw.func_caps.rx_buf_chain_len;\n\tu16 pf_q = vsi->base_queue + ring->queue_index;\n\tstruct i40e_hw *hw = &vsi->back->hw;\n\tstruct i40e_hmc_obj_rxq rx_ctx;\n\tint err = 0;\n\tbool ok;\n\tint ret;\n\n\tbitmap_zero(ring->state, __I40E_RING_STATE_NBITS);\n\n\t \n\tmemset(&rx_ctx, 0, sizeof(rx_ctx));\n\n\tif (ring->vsi->type == I40E_VSI_MAIN)\n\t\txdp_rxq_info_unreg_mem_model(&ring->xdp_rxq);\n\n\tring->xsk_pool = i40e_xsk_pool(ring);\n\tif (ring->xsk_pool) {\n\t\tring->rx_buf_len =\n\t\t  xsk_pool_get_rx_frame_size(ring->xsk_pool);\n\t\tret = xdp_rxq_info_reg_mem_model(&ring->xdp_rxq,\n\t\t\t\t\t\t MEM_TYPE_XSK_BUFF_POOL,\n\t\t\t\t\t\t NULL);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Registered XDP mem model MEM_TYPE_XSK_BUFF_POOL on Rx ring %d\\n\",\n\t\t\t ring->queue_index);\n\n\t} else {\n\t\tring->rx_buf_len = vsi->rx_buf_len;\n\t\tif (ring->vsi->type == I40E_VSI_MAIN) {\n\t\t\tret = xdp_rxq_info_reg_mem_model(&ring->xdp_rxq,\n\t\t\t\t\t\t\t MEM_TYPE_PAGE_SHARED,\n\t\t\t\t\t\t\t NULL);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\txdp_init_buff(&ring->xdp, i40e_rx_pg_size(ring) / 2, &ring->xdp_rxq);\n\n\trx_ctx.dbuff = DIV_ROUND_UP(ring->rx_buf_len,\n\t\t\t\t    BIT_ULL(I40E_RXQ_CTX_DBUFF_SHIFT));\n\n\trx_ctx.base = (ring->dma / 128);\n\trx_ctx.qlen = ring->count;\n\n\t \n\trx_ctx.dsize = 0;\n\n\t \n\trx_ctx.hsplit_0 = 0;\n\n\trx_ctx.rxmax = min_t(u16, vsi->max_frame, chain_len * ring->rx_buf_len);\n\tif (hw->revision_id == 0)\n\t\trx_ctx.lrxqthresh = 0;\n\telse\n\t\trx_ctx.lrxqthresh = 1;\n\trx_ctx.crcstrip = 1;\n\trx_ctx.l2tsel = 1;\n\t \n\trx_ctx.showiv = 0;\n\t \n\trx_ctx.prefena = 1;\n\n\t \n\terr = i40e_clear_lan_rx_queue_context(hw, pf_q);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to clear LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\terr = i40e_set_lan_rx_queue_context(hw, pf_q, &rx_ctx);\n\tif (err) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to set LAN Rx queue context on Rx ring %d (pf_q %d), error: %d\\n\",\n\t\t\t ring->queue_index, pf_q, err);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tif (!vsi->netdev || (vsi->back->flags & I40E_FLAG_LEGACY_RX)) {\n\t\tif (I40E_2K_TOO_SMALL_WITH_PADDING) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"2k Rx buffer is too small to fit standard MTU and skb_shared_info\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tclear_ring_build_skb_enabled(ring);\n\t} else {\n\t\tset_ring_build_skb_enabled(ring);\n\t}\n\n\tring->rx_offset = i40e_rx_offset(ring);\n\n\t \n\tring->tail = hw->hw_addr + I40E_QRX_TAIL(pf_q);\n\twritel(0, ring->tail);\n\n\tif (ring->xsk_pool) {\n\t\txsk_pool_set_rxq_info(ring->xsk_pool, &ring->xdp_rxq);\n\t\tok = i40e_alloc_rx_buffers_zc(ring, I40E_DESC_UNUSED(ring));\n\t} else {\n\t\tok = !i40e_alloc_rx_buffers(ring, I40E_DESC_UNUSED(ring));\n\t}\n\tif (!ok) {\n\t\t \n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed to allocate some buffers on %sRx ring %d (pf_q %d)\\n\",\n\t\t\t ring->xsk_pool ? \"AF_XDP ZC enabled \" : \"\",\n\t\t\t ring->queue_index, pf_q);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int i40e_vsi_configure_tx(struct i40e_vsi *vsi)\n{\n\tint err = 0;\n\tu16 i;\n\n\tfor (i = 0; (i < vsi->num_queue_pairs) && !err; i++)\n\t\terr = i40e_configure_tx_ring(vsi->tx_rings[i]);\n\n\tif (err || !i40e_enabled_xdp_vsi(vsi))\n\t\treturn err;\n\n\tfor (i = 0; (i < vsi->num_queue_pairs) && !err; i++)\n\t\terr = i40e_configure_tx_ring(vsi->xdp_rings[i]);\n\n\treturn err;\n}\n\n \nstatic int i40e_vsi_configure_rx(struct i40e_vsi *vsi)\n{\n\tint err = 0;\n\tu16 i;\n\n\tvsi->max_frame = i40e_max_vsi_frame_size(vsi, vsi->xdp_prog);\n\tvsi->rx_buf_len = i40e_calculate_vsi_rx_buf_len(vsi);\n\n#if (PAGE_SIZE < 8192)\n\tif (vsi->netdev && !I40E_2K_TOO_SMALL_WITH_PADDING &&\n\t    vsi->netdev->mtu <= ETH_DATA_LEN) {\n\t\tvsi->rx_buf_len = I40E_RXBUFFER_1536 - NET_IP_ALIGN;\n\t\tvsi->max_frame = vsi->rx_buf_len;\n\t}\n#endif\n\n\t \n\tfor (i = 0; i < vsi->num_queue_pairs && !err; i++)\n\t\terr = i40e_configure_rx_ring(vsi->rx_rings[i]);\n\n\treturn err;\n}\n\n \nstatic void i40e_vsi_config_dcb_rings(struct i40e_vsi *vsi)\n{\n\tstruct i40e_ring *tx_ring, *rx_ring;\n\tu16 qoffset, qcount;\n\tint i, n;\n\n\tif (!(vsi->back->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t \n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\t\trx_ring = vsi->rx_rings[i];\n\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\trx_ring->dcb_tc = 0;\n\t\t\ttx_ring->dcb_tc = 0;\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (n = 0; n < I40E_MAX_TRAFFIC_CLASS; n++) {\n\t\tif (!(vsi->tc_config.enabled_tc & BIT_ULL(n)))\n\t\t\tcontinue;\n\n\t\tqoffset = vsi->tc_config.tc_info[n].qoffset;\n\t\tqcount = vsi->tc_config.tc_info[n].qcount;\n\t\tfor (i = qoffset; i < (qoffset + qcount); i++) {\n\t\t\trx_ring = vsi->rx_rings[i];\n\t\t\ttx_ring = vsi->tx_rings[i];\n\t\t\trx_ring->dcb_tc = n;\n\t\t\ttx_ring->dcb_tc = n;\n\t\t}\n\t}\n}\n\n \nstatic void i40e_set_vsi_rx_mode(struct i40e_vsi *vsi)\n{\n\tif (vsi->netdev)\n\t\ti40e_set_rx_mode(vsi->netdev);\n}\n\n \nstatic void i40e_reset_fdir_filter_cnt(struct i40e_pf *pf)\n{\n\tpf->fd_tcp4_filter_cnt = 0;\n\tpf->fd_udp4_filter_cnt = 0;\n\tpf->fd_sctp4_filter_cnt = 0;\n\tpf->fd_ip4_filter_cnt = 0;\n\tpf->fd_tcp6_filter_cnt = 0;\n\tpf->fd_udp6_filter_cnt = 0;\n\tpf->fd_sctp6_filter_cnt = 0;\n\tpf->fd_ip6_filter_cnt = 0;\n}\n\n \nstatic void i40e_fdir_filter_restore(struct i40e_vsi *vsi)\n{\n\tstruct i40e_fdir_filter *filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\n\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\treturn;\n\n\t \n\ti40e_reset_fdir_filter_cnt(pf);\n\n\thlist_for_each_entry_safe(filter, node,\n\t\t\t\t  &pf->fdir_filter_list, fdir_node) {\n\t\ti40e_add_del_fdir(vsi, filter, true);\n\t}\n}\n\n \nstatic int i40e_vsi_configure(struct i40e_vsi *vsi)\n{\n\tint err;\n\n\ti40e_set_vsi_rx_mode(vsi);\n\ti40e_restore_vlan(vsi);\n\ti40e_vsi_config_dcb_rings(vsi);\n\terr = i40e_vsi_configure_tx(vsi);\n\tif (!err)\n\t\terr = i40e_vsi_configure_rx(vsi);\n\n\treturn err;\n}\n\n \nstatic void i40e_vsi_configure_msix(struct i40e_vsi *vsi)\n{\n\tbool has_xdp = i40e_enabled_xdp_vsi(vsi);\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vector;\n\tint i, q;\n\tu32 qp;\n\n\t \n\tqp = vsi->base_queue;\n\tvector = vsi->base_vector;\n\tfor (i = 0; i < vsi->num_q_vectors; i++, vector++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[i];\n\n\t\tq_vector->rx.next_update = jiffies + 1;\n\t\tq_vector->rx.target_itr =\n\t\t\tITR_TO_REG(vsi->rx_rings[i]->itr_setting);\n\t\twr32(hw, I40E_PFINT_ITRN(I40E_RX_ITR, vector - 1),\n\t\t     q_vector->rx.target_itr >> 1);\n\t\tq_vector->rx.current_itr = q_vector->rx.target_itr;\n\n\t\tq_vector->tx.next_update = jiffies + 1;\n\t\tq_vector->tx.target_itr =\n\t\t\tITR_TO_REG(vsi->tx_rings[i]->itr_setting);\n\t\twr32(hw, I40E_PFINT_ITRN(I40E_TX_ITR, vector - 1),\n\t\t     q_vector->tx.target_itr >> 1);\n\t\tq_vector->tx.current_itr = q_vector->tx.target_itr;\n\n\t\twr32(hw, I40E_PFINT_RATEN(vector - 1),\n\t\t     i40e_intrl_usec_to_reg(vsi->int_rate_limit));\n\n\t\t \n\t\twr32(hw, I40E_PFINT_LNKLSTN(vector - 1), qp);\n\t\tfor (q = 0; q < q_vector->num_ringpairs; q++) {\n\t\t\tu32 nextqp = has_xdp ? qp + vsi->alloc_queue_pairs : qp;\n\t\t\tu32 val;\n\n\t\t\tval = I40E_QINT_RQCTL_CAUSE_ENA_MASK |\n\t\t\t      (I40E_RX_ITR << I40E_QINT_RQCTL_ITR_INDX_SHIFT) |\n\t\t\t      (vector << I40E_QINT_RQCTL_MSIX_INDX_SHIFT) |\n\t\t\t      (nextqp << I40E_QINT_RQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t      (I40E_QUEUE_TYPE_TX <<\n\t\t\t       I40E_QINT_RQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\t\tif (has_xdp) {\n\t\t\t\t \n\t\t\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK |\n\t\t\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t\t\t\t      (vector << I40E_QINT_TQCTL_MSIX_INDX_SHIFT) |\n\t\t\t\t      (qp << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t\t      (I40E_QUEUE_TYPE_TX <<\n\t\t\t\t       I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\t\twr32(hw, I40E_QINT_TQCTL(nextqp), val);\n\t\t\t}\n\t\t\t \n\t\t\tval = I40E_QINT_TQCTL_CAUSE_ENA_MASK |\n\t\t\t      (I40E_TX_ITR << I40E_QINT_TQCTL_ITR_INDX_SHIFT) |\n\t\t\t      (vector << I40E_QINT_TQCTL_MSIX_INDX_SHIFT) |\n\t\t\t      ((qp + 1) << I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT) |\n\t\t\t      (I40E_QUEUE_TYPE_RX <<\n\t\t\t       I40E_QINT_TQCTL_NEXTQ_TYPE_SHIFT);\n\n\t\t\t \n\t\t\tif (q == (q_vector->num_ringpairs - 1))\n\t\t\t\tval |= (I40E_QUEUE_END_OF_LIST <<\n\t\t\t\t\tI40E_QINT_TQCTL_NEXTQ_INDX_SHIFT);\n\n\t\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t\t\tqp++;\n\t\t}\n\t}\n\n\ti40e_flush(hw);\n}\n\n \nstatic void i40e_enable_misc_int_causes(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\t \n\twr32(hw, I40E_PFINT_ICR0_ENA, 0);   \n\trd32(hw, I40E_PFINT_ICR0);          \n\n\tval = I40E_PFINT_ICR0_ENA_ECC_ERR_MASK       |\n\t      I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK    |\n\t      I40E_PFINT_ICR0_ENA_GRST_MASK          |\n\t      I40E_PFINT_ICR0_ENA_PCI_EXCEPTION_MASK |\n\t      I40E_PFINT_ICR0_ENA_GPIO_MASK          |\n\t      I40E_PFINT_ICR0_ENA_HMC_ERR_MASK       |\n\t      I40E_PFINT_ICR0_ENA_VFLR_MASK          |\n\t      I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED)\n\t\tval |= I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK;\n\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\tval |= I40E_PFINT_ICR0_ENA_TIMESYNC_MASK;\n\n\twr32(hw, I40E_PFINT_ICR0_ENA, val);\n\n\t \n\twr32(hw, I40E_PFINT_DYN_CTL0, I40E_PFINT_DYN_CTL0_SW_ITR_INDX_MASK |\n\t\t\t\t\tI40E_PFINT_DYN_CTL0_INTENA_MSK_MASK);\n\n\t \n\twr32(hw, I40E_PFINT_STAT_CTL0, 0);\n}\n\n \nstatic void i40e_configure_msi_and_legacy(struct i40e_vsi *vsi)\n{\n\tu32 nextqp = i40e_enabled_xdp_vsi(vsi) ? vsi->alloc_queue_pairs : 0;\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[0];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t \n\tq_vector->rx.next_update = jiffies + 1;\n\tq_vector->rx.target_itr = ITR_TO_REG(vsi->rx_rings[0]->itr_setting);\n\twr32(hw, I40E_PFINT_ITR0(I40E_RX_ITR), q_vector->rx.target_itr >> 1);\n\tq_vector->rx.current_itr = q_vector->rx.target_itr;\n\tq_vector->tx.next_update = jiffies + 1;\n\tq_vector->tx.target_itr = ITR_TO_REG(vsi->tx_rings[0]->itr_setting);\n\twr32(hw, I40E_PFINT_ITR0(I40E_TX_ITR), q_vector->tx.target_itr >> 1);\n\tq_vector->tx.current_itr = q_vector->tx.target_itr;\n\n\ti40e_enable_misc_int_causes(pf);\n\n\t \n\twr32(hw, I40E_PFINT_LNKLST0, 0);\n\n\t \n\twr32(hw, I40E_QINT_RQCTL(0), I40E_QINT_RQCTL_VAL(nextqp, 0, TX));\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t \n\t\twr32(hw, I40E_QINT_TQCTL(nextqp),\n\t\t     I40E_QINT_TQCTL_VAL(nextqp, 0, TX));\n\t}\n\n\t \n\twr32(hw, I40E_QINT_TQCTL(0),\n\t     I40E_QINT_TQCTL_VAL(I40E_QUEUE_END_OF_LIST, 0, RX));\n\ti40e_flush(hw);\n}\n\n \nvoid i40e_irq_dynamic_disable_icr0(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\n\twr32(hw, I40E_PFINT_DYN_CTL0,\n\t     I40E_ITR_NONE << I40E_PFINT_DYN_CTLN_ITR_INDX_SHIFT);\n\ti40e_flush(hw);\n}\n\n \nvoid i40e_irq_dynamic_enable_icr0(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 val;\n\n\tval = I40E_PFINT_DYN_CTL0_INTENA_MASK   |\n\t      I40E_PFINT_DYN_CTL0_CLEARPBA_MASK |\n\t      (I40E_ITR_NONE << I40E_PFINT_DYN_CTL0_ITR_INDX_SHIFT);\n\n\twr32(hw, I40E_PFINT_DYN_CTL0, val);\n\ti40e_flush(hw);\n}\n\n \nstatic irqreturn_t i40e_msix_clean_rings(int irq, void *data)\n{\n\tstruct i40e_q_vector *q_vector = data;\n\n\tif (!q_vector->tx.ring && !q_vector->rx.ring)\n\t\treturn IRQ_HANDLED;\n\n\tnapi_schedule_irqoff(&q_vector->napi);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void i40e_irq_affinity_notify(struct irq_affinity_notify *notify,\n\t\t\t\t     const cpumask_t *mask)\n{\n\tstruct i40e_q_vector *q_vector =\n\t\tcontainer_of(notify, struct i40e_q_vector, affinity_notify);\n\n\tcpumask_copy(&q_vector->affinity_mask, mask);\n}\n\n \nstatic void i40e_irq_affinity_release(struct kref *ref) {}\n\n \nstatic int i40e_vsi_request_irq_msix(struct i40e_vsi *vsi, char *basename)\n{\n\tint q_vectors = vsi->num_q_vectors;\n\tstruct i40e_pf *pf = vsi->back;\n\tint base = vsi->base_vector;\n\tint rx_int_idx = 0;\n\tint tx_int_idx = 0;\n\tint vector, err;\n\tint irq_num;\n\tint cpu;\n\n\tfor (vector = 0; vector < q_vectors; vector++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[vector];\n\n\t\tirq_num = pf->msix_entries[base + vector].vector;\n\n\t\tif (q_vector->tx.ring && q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"TxRx\", rx_int_idx++);\n\t\t\ttx_int_idx++;\n\t\t} else if (q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"rx\", rx_int_idx++);\n\t\t} else if (q_vector->tx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name) - 1,\n\t\t\t\t \"%s-%s-%d\", basename, \"tx\", tx_int_idx++);\n\t\t} else {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\t\terr = request_irq(irq_num,\n\t\t\t\t  vsi->irq_handler,\n\t\t\t\t  0,\n\t\t\t\t  q_vector->name,\n\t\t\t\t  q_vector);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSIX request_irq failed, error: %d\\n\", err);\n\t\t\tgoto free_queue_irqs;\n\t\t}\n\n\t\t \n\t\tq_vector->irq_num = irq_num;\n\t\tq_vector->affinity_notify.notify = i40e_irq_affinity_notify;\n\t\tq_vector->affinity_notify.release = i40e_irq_affinity_release;\n\t\tirq_set_affinity_notifier(irq_num, &q_vector->affinity_notify);\n\t\t \n\t\tcpu = cpumask_local_spread(q_vector->v_idx, -1);\n\t\tirq_update_affinity_hint(irq_num, get_cpu_mask(cpu));\n\t}\n\n\tvsi->irqs_ready = true;\n\treturn 0;\n\nfree_queue_irqs:\n\twhile (vector) {\n\t\tvector--;\n\t\tirq_num = pf->msix_entries[base + vector].vector;\n\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\tirq_update_affinity_hint(irq_num, NULL);\n\t\tfree_irq(irq_num, &vsi->q_vectors[vector]);\n\t}\n\treturn err;\n}\n\n \nstatic void i40e_vsi_disable_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint base = vsi->base_vector;\n\tint i;\n\n\t \n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\tu32 val;\n\n\t\tval = rd32(hw, I40E_QINT_TQCTL(vsi->tx_rings[i]->reg_idx));\n\t\tval &= ~I40E_QINT_TQCTL_CAUSE_ENA_MASK;\n\t\twr32(hw, I40E_QINT_TQCTL(vsi->tx_rings[i]->reg_idx), val);\n\n\t\tval = rd32(hw, I40E_QINT_RQCTL(vsi->rx_rings[i]->reg_idx));\n\t\tval &= ~I40E_QINT_RQCTL_CAUSE_ENA_MASK;\n\t\twr32(hw, I40E_QINT_RQCTL(vsi->rx_rings[i]->reg_idx), val);\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tcontinue;\n\t\twr32(hw, I40E_QINT_TQCTL(vsi->xdp_rings[i]->reg_idx), 0);\n\t}\n\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = vsi->base_vector;\n\t\t     i < (vsi->num_q_vectors + vsi->base_vector); i++)\n\t\t\twr32(hw, I40E_PFINT_DYN_CTLN(i - 1), 0);\n\n\t\ti40e_flush(hw);\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\tsynchronize_irq(pf->msix_entries[i + base].vector);\n\t} else {\n\t\t \n\t\twr32(hw, I40E_PFINT_ICR0_ENA, 0);\n\t\twr32(hw, I40E_PFINT_DYN_CTL0, 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->pdev->irq);\n\t}\n}\n\n \nstatic int i40e_vsi_enable_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\ti40e_irq_dynamic_enable(vsi, i);\n\t} else {\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\ti40e_flush(&pf->hw);\n\treturn 0;\n}\n\n \nstatic void i40e_free_misc_vector(struct i40e_pf *pf)\n{\n\t \n\twr32(&pf->hw, I40E_PFINT_ICR0_ENA, 0);\n\ti40e_flush(&pf->hw);\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED && pf->msix_entries) {\n\t\tfree_irq(pf->msix_entries[0].vector, pf);\n\t\tclear_bit(__I40E_MISC_IRQ_REQUESTED, pf->state);\n\t}\n}\n\n \nstatic irqreturn_t i40e_intr(int irq, void *data)\n{\n\tstruct i40e_pf *pf = (struct i40e_pf *)data;\n\tstruct i40e_hw *hw = &pf->hw;\n\tirqreturn_t ret = IRQ_NONE;\n\tu32 icr0, icr0_remaining;\n\tu32 val, ena_mask;\n\n\ticr0 = rd32(hw, I40E_PFINT_ICR0);\n\tena_mask = rd32(hw, I40E_PFINT_ICR0_ENA);\n\n\t \n\tif ((icr0 & I40E_PFINT_ICR0_INTEVENT_MASK) == 0)\n\t\tgoto enable_intr;\n\n\t \n\tif (((icr0 & ~I40E_PFINT_ICR0_INTEVENT_MASK) == 0) ||\n\t    (icr0 & I40E_PFINT_ICR0_SWINT_MASK))\n\t\tpf->sw_int_count++;\n\n\tif ((pf->flags & I40E_FLAG_IWARP_ENABLED) &&\n\t    (icr0 & I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK)) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_PE_CRITERR_MASK;\n\t\tdev_dbg(&pf->pdev->dev, \"cleared PE_CRITERR\\n\");\n\t\tset_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t}\n\n\t \n\tif (icr0 & I40E_PFINT_ICR0_QUEUE_0_MASK) {\n\t\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[0];\n\n\t\t \n\t\tif (!test_bit(__I40E_DOWN, pf->state))\n\t\t\tnapi_schedule_irqoff(&q_vector->napi);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_ADMINQ_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\t\tset_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state);\n\t\ti40e_debug(&pf->hw, I40E_DEBUG_NVM, \"AdminQ event\\n\");\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_MAL_DETECT_MASK) {\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK;\n\t\tset_bit(__I40E_MDD_EVENT_PENDING, pf->state);\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_VFLR_MASK) {\n\t\t \n\t\tif (test_bit(__I40E_VF_RESETS_DISABLED, pf->state)) {\n\t\t\tu32 reg = rd32(hw, I40E_PFINT_ICR0_ENA);\n\n\t\t\treg &= ~I40E_PFINT_ICR0_VFLR_MASK;\n\t\t\twr32(hw, I40E_PFINT_ICR0_ENA, reg);\n\t\t} else {\n\t\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_VFLR_MASK;\n\t\t\tset_bit(__I40E_VFLR_EVENT_PENDING, pf->state);\n\t\t}\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_GRST_MASK) {\n\t\tif (!test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\t\tset_bit(__I40E_RESET_INTR_RECEIVED, pf->state);\n\t\tena_mask &= ~I40E_PFINT_ICR0_ENA_GRST_MASK;\n\t\tval = rd32(hw, I40E_GLGEN_RSTAT);\n\t\tval = (val & I40E_GLGEN_RSTAT_RESET_TYPE_MASK)\n\t\t       >> I40E_GLGEN_RSTAT_RESET_TYPE_SHIFT;\n\t\tif (val == I40E_RESET_CORER) {\n\t\t\tpf->corer_count++;\n\t\t} else if (val == I40E_RESET_GLOBR) {\n\t\t\tpf->globr_count++;\n\t\t} else if (val == I40E_RESET_EMPR) {\n\t\t\tpf->empr_count++;\n\t\t\tset_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state);\n\t\t}\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_HMC_ERR_MASK) {\n\t\ticr0 &= ~I40E_PFINT_ICR0_HMC_ERR_MASK;\n\t\tdev_info(&pf->pdev->dev, \"HMC error interrupt\\n\");\n\t\tdev_info(&pf->pdev->dev, \"HMC error info 0x%x, HMC error data 0x%x\\n\",\n\t\t\t rd32(hw, I40E_PFHMC_ERRORINFO),\n\t\t\t rd32(hw, I40E_PFHMC_ERRORDATA));\n\t}\n\n\tif (icr0 & I40E_PFINT_ICR0_TIMESYNC_MASK) {\n\t\tu32 prttsyn_stat = rd32(hw, I40E_PRTTSYN_STAT_0);\n\n\t\tif (prttsyn_stat & I40E_PRTTSYN_STAT_0_EVENT0_MASK)\n\t\t\tschedule_work(&pf->ptp_extts0_work);\n\n\t\tif (prttsyn_stat & I40E_PRTTSYN_STAT_0_TXTIME_MASK)\n\t\t\ti40e_ptp_tx_hwtstamp(pf);\n\n\t\ticr0 &= ~I40E_PFINT_ICR0_ENA_TIMESYNC_MASK;\n\t}\n\n\t \n\ticr0_remaining = icr0 & ena_mask;\n\tif (icr0_remaining) {\n\t\tdev_info(&pf->pdev->dev, \"unhandled interrupt icr0=0x%08x\\n\",\n\t\t\t icr0_remaining);\n\t\tif ((icr0_remaining & I40E_PFINT_ICR0_PE_CRITERR_MASK) ||\n\t\t    (icr0_remaining & I40E_PFINT_ICR0_PCI_EXCEPTION_MASK) ||\n\t\t    (icr0_remaining & I40E_PFINT_ICR0_ECC_ERR_MASK)) {\n\t\t\tdev_info(&pf->pdev->dev, \"device will be reset\\n\");\n\t\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\t\ti40e_service_event_schedule(pf);\n\t\t}\n\t\tena_mask &= ~icr0_remaining;\n\t}\n\tret = IRQ_HANDLED;\n\nenable_intr:\n\t \n\twr32(hw, I40E_PFINT_ICR0_ENA, ena_mask);\n\tif (!test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\ti40e_service_event_schedule(pf);\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\treturn ret;\n}\n\n \nstatic bool i40e_clean_fdir_tx_irq(struct i40e_ring *tx_ring, int budget)\n{\n\tstruct i40e_vsi *vsi = tx_ring->vsi;\n\tu16 i = tx_ring->next_to_clean;\n\tstruct i40e_tx_buffer *tx_buf;\n\tstruct i40e_tx_desc *tx_desc;\n\n\ttx_buf = &tx_ring->tx_bi[i];\n\ttx_desc = I40E_TX_DESC(tx_ring, i);\n\ti -= tx_ring->count;\n\n\tdo {\n\t\tstruct i40e_tx_desc *eop_desc = tx_buf->next_to_watch;\n\n\t\t \n\t\tif (!eop_desc)\n\t\t\tbreak;\n\n\t\t \n\t\tsmp_rmb();\n\n\t\t \n\t\tif (!(eop_desc->cmd_type_offset_bsz &\n\t\t      cpu_to_le64(I40E_TX_DESC_DTYPE_DESC_DONE)))\n\t\t\tbreak;\n\n\t\t \n\t\ttx_buf->next_to_watch = NULL;\n\n\t\ttx_desc->buffer_addr = 0;\n\t\ttx_desc->cmd_type_offset_bsz = 0;\n\t\t \n\t\ttx_buf++;\n\t\ttx_desc++;\n\t\ti++;\n\t\tif (unlikely(!i)) {\n\t\t\ti -= tx_ring->count;\n\t\t\ttx_buf = tx_ring->tx_bi;\n\t\t\ttx_desc = I40E_TX_DESC(tx_ring, 0);\n\t\t}\n\t\t \n\t\tdma_unmap_single(tx_ring->dev,\n\t\t\t\t dma_unmap_addr(tx_buf, dma),\n\t\t\t\t dma_unmap_len(tx_buf, len),\n\t\t\t\t DMA_TO_DEVICE);\n\t\tif (tx_buf->tx_flags & I40E_TX_FLAGS_FD_SB)\n\t\t\tkfree(tx_buf->raw_buf);\n\n\t\ttx_buf->raw_buf = NULL;\n\t\ttx_buf->tx_flags = 0;\n\t\ttx_buf->next_to_watch = NULL;\n\t\tdma_unmap_len_set(tx_buf, len, 0);\n\t\ttx_desc->buffer_addr = 0;\n\t\ttx_desc->cmd_type_offset_bsz = 0;\n\n\t\t \n\t\ttx_buf++;\n\t\ttx_desc++;\n\t\ti++;\n\t\tif (unlikely(!i)) {\n\t\t\ti -= tx_ring->count;\n\t\t\ttx_buf = tx_ring->tx_bi;\n\t\t\ttx_desc = I40E_TX_DESC(tx_ring, 0);\n\t\t}\n\n\t\t \n\t\tbudget--;\n\t} while (likely(budget));\n\n\ti += tx_ring->count;\n\ttx_ring->next_to_clean = i;\n\n\tif (vsi->back->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_irq_dynamic_enable(vsi, tx_ring->q_vector->v_idx);\n\n\treturn budget > 0;\n}\n\n \nstatic irqreturn_t i40e_fdir_clean_ring(int irq, void *data)\n{\n\tstruct i40e_q_vector *q_vector = data;\n\tstruct i40e_vsi *vsi;\n\n\tif (!q_vector->tx.ring)\n\t\treturn IRQ_HANDLED;\n\n\tvsi = q_vector->tx.ring->vsi;\n\ti40e_clean_fdir_tx_irq(q_vector->tx.ring, vsi->work_limit);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void i40e_map_vector_to_qp(struct i40e_vsi *vsi, int v_idx, int qp_idx)\n{\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_idx];\n\tstruct i40e_ring *tx_ring = vsi->tx_rings[qp_idx];\n\tstruct i40e_ring *rx_ring = vsi->rx_rings[qp_idx];\n\n\ttx_ring->q_vector = q_vector;\n\ttx_ring->next = q_vector->tx.ring;\n\tq_vector->tx.ring = tx_ring;\n\tq_vector->tx.count++;\n\n\t \n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tstruct i40e_ring *xdp_ring = vsi->xdp_rings[qp_idx];\n\n\t\txdp_ring->q_vector = q_vector;\n\t\txdp_ring->next = q_vector->tx.ring;\n\t\tq_vector->tx.ring = xdp_ring;\n\t\tq_vector->tx.count++;\n\t}\n\n\trx_ring->q_vector = q_vector;\n\trx_ring->next = q_vector->rx.ring;\n\tq_vector->rx.ring = rx_ring;\n\tq_vector->rx.count++;\n}\n\n \nstatic void i40e_vsi_map_rings_to_vectors(struct i40e_vsi *vsi)\n{\n\tint qp_remaining = vsi->num_queue_pairs;\n\tint q_vectors = vsi->num_q_vectors;\n\tint num_ringpairs;\n\tint v_start = 0;\n\tint qp_idx = 0;\n\n\t \n\tfor (; v_start < q_vectors; v_start++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_start];\n\n\t\tnum_ringpairs = DIV_ROUND_UP(qp_remaining, q_vectors - v_start);\n\n\t\tq_vector->num_ringpairs = num_ringpairs;\n\t\tq_vector->reg_idx = q_vector->v_idx + vsi->base_vector - 1;\n\n\t\tq_vector->rx.count = 0;\n\t\tq_vector->tx.count = 0;\n\t\tq_vector->rx.ring = NULL;\n\t\tq_vector->tx.ring = NULL;\n\n\t\twhile (num_ringpairs--) {\n\t\t\ti40e_map_vector_to_qp(vsi, v_start, qp_idx);\n\t\t\tqp_idx++;\n\t\t\tqp_remaining--;\n\t\t}\n\t}\n}\n\n \nstatic int i40e_vsi_request_irq(struct i40e_vsi *vsi, char *basename)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\terr = i40e_vsi_request_irq_msix(vsi, basename);\n\telse if (pf->flags & I40E_FLAG_MSI_ENABLED)\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, 0,\n\t\t\t\t  pf->int_name, pf);\n\telse\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, IRQF_SHARED,\n\t\t\t\t  pf->int_name, pf);\n\n\tif (err)\n\t\tdev_info(&pf->pdev->dev, \"request_irq failed, Error %d\\n\", err);\n\n\treturn err;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\n \nstatic void i40e_netpoll(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tint i;\n\n\t \n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++)\n\t\t\ti40e_msix_clean_rings(0, vsi->q_vectors[i]);\n\t} else {\n\t\ti40e_intr(pf->pdev->irq, netdev);\n\t}\n}\n#endif\n\n#define I40E_QTX_ENA_WAIT_COUNT 50\n\n \nstatic int i40e_pf_txq_wait(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint i;\n\tu32 tx_reg;\n\n\tfor (i = 0; i < I40E_QUEUE_WAIT_RETRY_LIMIT; i++) {\n\t\ttx_reg = rd32(&pf->hw, I40E_QTX_ENA(pf_q));\n\t\tif (enable == !!(tx_reg & I40E_QTX_ENA_QENA_STAT_MASK))\n\t\t\tbreak;\n\n\t\tusleep_range(10, 20);\n\t}\n\tif (i >= I40E_QUEUE_WAIT_RETRY_LIMIT)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\n \nstatic void i40e_control_tx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 tx_reg;\n\tint i;\n\n\t \n\ti40e_pre_tx_queue_cfg(&pf->hw, pf_q, enable);\n\tif (!enable)\n\t\tusleep_range(10, 20);\n\n\tfor (i = 0; i < I40E_QTX_ENA_WAIT_COUNT; i++) {\n\t\ttx_reg = rd32(hw, I40E_QTX_ENA(pf_q));\n\t\tif (((tx_reg >> I40E_QTX_ENA_QENA_REQ_SHIFT) & 1) ==\n\t\t    ((tx_reg >> I40E_QTX_ENA_QENA_STAT_SHIFT) & 1))\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\t \n\tif (enable == !!(tx_reg & I40E_QTX_ENA_QENA_STAT_MASK))\n\t\treturn;\n\n\t \n\tif (enable) {\n\t\twr32(hw, I40E_QTX_HEAD(pf_q), 0);\n\t\ttx_reg |= I40E_QTX_ENA_QENA_REQ_MASK;\n\t} else {\n\t\ttx_reg &= ~I40E_QTX_ENA_QENA_REQ_MASK;\n\t}\n\n\twr32(hw, I40E_QTX_ENA(pf_q), tx_reg);\n}\n\n \nint i40e_control_wait_tx_q(int seid, struct i40e_pf *pf, int pf_q,\n\t\t\t   bool is_xdp, bool enable)\n{\n\tint ret;\n\n\ti40e_control_tx_q(pf, pf_q, enable);\n\n\t \n\tret = i40e_pf_txq_wait(pf, pf_q, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d %sTx ring %d %sable timeout\\n\",\n\t\t\t seid, (is_xdp ? \"XDP \" : \"\"), pf_q,\n\t\t\t (enable ? \"en\" : \"dis\"));\n\t}\n\n\treturn ret;\n}\n\n \nstatic int i40e_vsi_enable_tx(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t\t     pf_q,\n\t\t\t\t\t     false  , true);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tcontinue;\n\n\t\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t\t     pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t\t     true  , true);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\n \nstatic int i40e_pf_rxq_wait(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint i;\n\tu32 rx_reg;\n\n\tfor (i = 0; i < I40E_QUEUE_WAIT_RETRY_LIMIT; i++) {\n\t\trx_reg = rd32(&pf->hw, I40E_QRX_ENA(pf_q));\n\t\tif (enable == !!(rx_reg & I40E_QRX_ENA_QENA_STAT_MASK))\n\t\t\tbreak;\n\n\t\tusleep_range(10, 20);\n\t}\n\tif (i >= I40E_QUEUE_WAIT_RETRY_LIMIT)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\n \nstatic void i40e_control_rx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 rx_reg;\n\tint i;\n\n\tfor (i = 0; i < I40E_QTX_ENA_WAIT_COUNT; i++) {\n\t\trx_reg = rd32(hw, I40E_QRX_ENA(pf_q));\n\t\tif (((rx_reg >> I40E_QRX_ENA_QENA_REQ_SHIFT) & 1) ==\n\t\t    ((rx_reg >> I40E_QRX_ENA_QENA_STAT_SHIFT) & 1))\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\t \n\tif (enable == !!(rx_reg & I40E_QRX_ENA_QENA_STAT_MASK))\n\t\treturn;\n\n\t \n\tif (enable)\n\t\trx_reg |= I40E_QRX_ENA_QENA_REQ_MASK;\n\telse\n\t\trx_reg &= ~I40E_QRX_ENA_QENA_REQ_MASK;\n\n\twr32(hw, I40E_QRX_ENA(pf_q), rx_reg);\n}\n\n \nint i40e_control_wait_rx_q(struct i40e_pf *pf, int pf_q, bool enable)\n{\n\tint ret = 0;\n\n\ti40e_control_rx_q(pf, pf_q, enable);\n\n\t \n\tret = i40e_pf_rxq_wait(pf, pf_q, enable);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\n\n \nstatic int i40e_vsi_enable_rx(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\tret = i40e_control_wait_rx_q(pf, pf_q, true);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Rx ring %d enable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n \nint i40e_vsi_start_rings(struct i40e_vsi *vsi)\n{\n\tint ret = 0;\n\n\t \n\tret = i40e_vsi_enable_rx(vsi);\n\tif (ret)\n\t\treturn ret;\n\tret = i40e_vsi_enable_tx(vsi);\n\n\treturn ret;\n}\n\n#define I40E_DISABLE_TX_GAP_MSEC\t50\n\n \nvoid i40e_vsi_stop_rings(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint pf_q, err, q_end;\n\n\t \n\tif (test_bit(__I40E_PORT_SUSPENDED, vsi->back->state))\n\t\treturn i40e_vsi_stop_rings_no_wait(vsi);\n\n\tq_end = vsi->base_queue + vsi->num_queue_pairs;\n\tfor (pf_q = vsi->base_queue; pf_q < q_end; pf_q++)\n\t\ti40e_pre_tx_queue_cfg(&pf->hw, (u32)pf_q, false);\n\n\tfor (pf_q = vsi->base_queue; pf_q < q_end; pf_q++) {\n\t\terr = i40e_control_wait_rx_q(pf, pf_q, false);\n\t\tif (err)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Rx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t}\n\n\tmsleep(I40E_DISABLE_TX_GAP_MSEC);\n\tpf_q = vsi->base_queue;\n\tfor (pf_q = vsi->base_queue; pf_q < q_end; pf_q++)\n\t\twr32(&pf->hw, I40E_QTX_ENA(pf_q), 0);\n\n\ti40e_vsi_wait_queues_disabled(vsi);\n}\n\n \nvoid i40e_vsi_stop_rings_no_wait(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\ti40e_control_tx_q(pf, pf_q, false);\n\t\ti40e_control_rx_q(pf, pf_q, false);\n\t}\n}\n\n \nstatic void i40e_vsi_free_irq(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint base = vsi->base_vector;\n\tu32 val, qp;\n\tint i;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tif (!vsi->q_vectors)\n\t\t\treturn;\n\n\t\tif (!vsi->irqs_ready)\n\t\t\treturn;\n\n\t\tvsi->irqs_ready = false;\n\t\tfor (i = 0; i < vsi->num_q_vectors; i++) {\n\t\t\tint irq_num;\n\t\t\tu16 vector;\n\n\t\t\tvector = i + base;\n\t\t\tirq_num = pf->msix_entries[vector].vector;\n\n\t\t\t \n\t\t\tif (!vsi->q_vectors[i] ||\n\t\t\t    !vsi->q_vectors[i]->num_ringpairs)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\t\t \n\t\t\tirq_update_affinity_hint(irq_num, NULL);\n\t\t\tfree_irq(irq_num, vsi->q_vectors[i]);\n\n\t\t\t \n\t\t\tval = rd32(hw, I40E_PFINT_LNKLSTN(vector - 1));\n\t\t\tqp = (val & I40E_PFINT_LNKLSTN_FIRSTQ_INDX_MASK)\n\t\t\t\t>> I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\t\tval |= I40E_QUEUE_END_OF_LIST\n\t\t\t\t<< I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\t\twr32(hw, I40E_PFINT_LNKLSTN(vector - 1), val);\n\n\t\t\twhile (qp != I40E_QUEUE_END_OF_LIST) {\n\t\t\t\tu32 next;\n\n\t\t\t\tval = rd32(hw, I40E_QINT_RQCTL(qp));\n\n\t\t\t\tval &= ~(I40E_QINT_RQCTL_MSIX_INDX_MASK  |\n\t\t\t\t\t I40E_QINT_RQCTL_MSIX0_INDX_MASK |\n\t\t\t\t\t I40E_QINT_RQCTL_CAUSE_ENA_MASK  |\n\t\t\t\t\t I40E_QINT_RQCTL_INTEVENT_MASK);\n\n\t\t\t\tval |= (I40E_QINT_RQCTL_ITR_INDX_MASK |\n\t\t\t\t\t I40E_QINT_RQCTL_NEXTQ_INDX_MASK);\n\n\t\t\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\t\t\tval = rd32(hw, I40E_QINT_TQCTL(qp));\n\n\t\t\t\tnext = (val & I40E_QINT_TQCTL_NEXTQ_INDX_MASK)\n\t\t\t\t\t>> I40E_QINT_TQCTL_NEXTQ_INDX_SHIFT;\n\n\t\t\t\tval &= ~(I40E_QINT_TQCTL_MSIX_INDX_MASK  |\n\t\t\t\t\t I40E_QINT_TQCTL_MSIX0_INDX_MASK |\n\t\t\t\t\t I40E_QINT_TQCTL_CAUSE_ENA_MASK  |\n\t\t\t\t\t I40E_QINT_TQCTL_INTEVENT_MASK);\n\n\t\t\t\tval |= (I40E_QINT_TQCTL_ITR_INDX_MASK |\n\t\t\t\t\t I40E_QINT_TQCTL_NEXTQ_INDX_MASK);\n\n\t\t\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t\t\t\tqp = next;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t\tval = rd32(hw, I40E_PFINT_LNKLST0);\n\t\tqp = (val & I40E_PFINT_LNKLSTN_FIRSTQ_INDX_MASK)\n\t\t\t>> I40E_PFINT_LNKLSTN_FIRSTQ_INDX_SHIFT;\n\t\tval |= I40E_QUEUE_END_OF_LIST\n\t\t\t<< I40E_PFINT_LNKLST0_FIRSTQ_INDX_SHIFT;\n\t\twr32(hw, I40E_PFINT_LNKLST0, val);\n\n\t\tval = rd32(hw, I40E_QINT_RQCTL(qp));\n\t\tval &= ~(I40E_QINT_RQCTL_MSIX_INDX_MASK  |\n\t\t\t I40E_QINT_RQCTL_MSIX0_INDX_MASK |\n\t\t\t I40E_QINT_RQCTL_CAUSE_ENA_MASK  |\n\t\t\t I40E_QINT_RQCTL_INTEVENT_MASK);\n\n\t\tval |= (I40E_QINT_RQCTL_ITR_INDX_MASK |\n\t\t\tI40E_QINT_RQCTL_NEXTQ_INDX_MASK);\n\n\t\twr32(hw, I40E_QINT_RQCTL(qp), val);\n\n\t\tval = rd32(hw, I40E_QINT_TQCTL(qp));\n\n\t\tval &= ~(I40E_QINT_TQCTL_MSIX_INDX_MASK  |\n\t\t\t I40E_QINT_TQCTL_MSIX0_INDX_MASK |\n\t\t\t I40E_QINT_TQCTL_CAUSE_ENA_MASK  |\n\t\t\t I40E_QINT_TQCTL_INTEVENT_MASK);\n\n\t\tval |= (I40E_QINT_TQCTL_ITR_INDX_MASK |\n\t\t\tI40E_QINT_TQCTL_NEXTQ_INDX_MASK);\n\n\t\twr32(hw, I40E_QINT_TQCTL(qp), val);\n\t}\n}\n\n \nstatic void i40e_free_q_vector(struct i40e_vsi *vsi, int v_idx)\n{\n\tstruct i40e_q_vector *q_vector = vsi->q_vectors[v_idx];\n\tstruct i40e_ring *ring;\n\n\tif (!q_vector)\n\t\treturn;\n\n\t \n\ti40e_for_each_ring(ring, q_vector->tx)\n\t\tring->q_vector = NULL;\n\n\ti40e_for_each_ring(ring, q_vector->rx)\n\t\tring->q_vector = NULL;\n\n\t \n\tif (vsi->netdev)\n\t\tnetif_napi_del(&q_vector->napi);\n\n\tvsi->q_vectors[v_idx] = NULL;\n\n\tkfree_rcu(q_vector, rcu);\n}\n\n \nstatic void i40e_vsi_free_q_vectors(struct i40e_vsi *vsi)\n{\n\tint v_idx;\n\n\tfor (v_idx = 0; v_idx < vsi->num_q_vectors; v_idx++)\n\t\ti40e_free_q_vector(vsi, v_idx);\n}\n\n \nstatic void i40e_reset_interrupt_capability(struct i40e_pf *pf)\n{\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tpci_disable_msix(pf->pdev);\n\t\tkfree(pf->msix_entries);\n\t\tpf->msix_entries = NULL;\n\t\tkfree(pf->irq_pile);\n\t\tpf->irq_pile = NULL;\n\t} else if (pf->flags & I40E_FLAG_MSI_ENABLED) {\n\t\tpci_disable_msi(pf->pdev);\n\t}\n\tpf->flags &= ~(I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED);\n}\n\n \nstatic void i40e_clear_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint i;\n\n\tif (test_bit(__I40E_MISC_IRQ_REQUESTED, pf->state))\n\t\ti40e_free_misc_vector(pf);\n\n\ti40e_put_lump(pf->irq_pile, pf->iwarp_base_vector,\n\t\t      I40E_IWARP_IRQ_PILE_ID);\n\n\ti40e_put_lump(pf->irq_pile, 0, I40E_PILE_VALID_BIT-1);\n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i])\n\t\t\ti40e_vsi_free_q_vectors(pf->vsi[i]);\n\ti40e_reset_interrupt_capability(pf);\n}\n\n \nstatic void i40e_napi_enable_all(struct i40e_vsi *vsi)\n{\n\tint q_idx;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tfor (q_idx = 0; q_idx < vsi->num_q_vectors; q_idx++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[q_idx];\n\n\t\tif (q_vector->rx.ring || q_vector->tx.ring)\n\t\t\tnapi_enable(&q_vector->napi);\n\t}\n}\n\n \nstatic void i40e_napi_disable_all(struct i40e_vsi *vsi)\n{\n\tint q_idx;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\tfor (q_idx = 0; q_idx < vsi->num_q_vectors; q_idx++) {\n\t\tstruct i40e_q_vector *q_vector = vsi->q_vectors[q_idx];\n\n\t\tif (q_vector->rx.ring || q_vector->tx.ring)\n\t\t\tnapi_disable(&q_vector->napi);\n\t}\n}\n\n \nstatic void i40e_vsi_close(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tif (!test_and_set_bit(__I40E_VSI_DOWN, vsi->state))\n\t\ti40e_down(vsi);\n\ti40e_vsi_free_irq(vsi);\n\ti40e_vsi_free_tx_resources(vsi);\n\ti40e_vsi_free_rx_resources(vsi);\n\tvsi->current_netdev_flags = 0;\n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\tset_bit(__I40E_CLIENT_RESET, pf->state);\n}\n\n \nstatic void i40e_quiesce_vsi(struct i40e_vsi *vsi)\n{\n\tif (test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tset_bit(__I40E_VSI_NEEDS_RESTART, vsi->state);\n\tif (vsi->netdev && netif_running(vsi->netdev))\n\t\tvsi->netdev->netdev_ops->ndo_stop(vsi->netdev);\n\telse\n\t\ti40e_vsi_close(vsi);\n}\n\n \nstatic void i40e_unquiesce_vsi(struct i40e_vsi *vsi)\n{\n\tif (!test_and_clear_bit(__I40E_VSI_NEEDS_RESTART, vsi->state))\n\t\treturn;\n\n\tif (vsi->netdev && netif_running(vsi->netdev))\n\t\tvsi->netdev->netdev_ops->ndo_open(vsi->netdev);\n\telse\n\t\ti40e_vsi_open(vsi);    \n}\n\n \nstatic void i40e_pf_quiesce_all_vsi(struct i40e_pf *pf)\n{\n\tint v;\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\ti40e_quiesce_vsi(pf->vsi[v]);\n\t}\n}\n\n \nstatic void i40e_pf_unquiesce_all_vsi(struct i40e_pf *pf)\n{\n\tint v;\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v])\n\t\t\ti40e_unquiesce_vsi(pf->vsi[v]);\n\t}\n}\n\n \nint i40e_vsi_wait_queues_disabled(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint i, pf_q, ret;\n\n\tpf_q = vsi->base_queue;\n\tfor (i = 0; i < vsi->num_queue_pairs; i++, pf_q++) {\n\t\t \n\t\tret = i40e_pf_txq_wait(pf, pf_q, false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Tx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tgoto wait_rx;\n\n\t\t \n\t\tret = i40e_pf_txq_wait(pf, pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t       false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d XDP Tx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\nwait_rx:\n\t\t \n\t\tret = i40e_pf_rxq_wait(pf, pf_q, false);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"VSI seid %d Rx ring %d disable timeout\\n\",\n\t\t\t\t vsi->seid, pf_q);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n#ifdef CONFIG_I40E_DCB\n \nstatic int i40e_pf_wait_queues_disabled(struct i40e_pf *pf)\n{\n\tint v, ret = 0;\n\n\tfor (v = 0; v < pf->hw.func_caps.num_vsis; v++) {\n\t\tif (pf->vsi[v]) {\n\t\t\tret = i40e_vsi_wait_queues_disabled(pf->vsi[v]);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n#endif\n\n \nstatic u8 i40e_get_iscsi_tc_map(struct i40e_pf *pf)\n{\n\tstruct i40e_dcb_app_priority_table app;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 enabled_tc = 1;  \n\tu8 tc, i;\n\t \n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tfor (i = 0; i < dcbcfg->numapps; i++) {\n\t\tapp = dcbcfg->app[i];\n\t\tif (app.selector == I40E_APP_SEL_TCPIP &&\n\t\t    app.protocolid == I40E_APP_PROTOID_ISCSI) {\n\t\t\ttc = dcbcfg->etscfg.prioritytable[app.priority];\n\t\t\tenabled_tc |= BIT(tc);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn enabled_tc;\n}\n\n \nstatic u8 i40e_dcb_get_num_tc(struct i40e_dcbx_config *dcbcfg)\n{\n\tint i, tc_unused = 0;\n\tu8 num_tc = 0;\n\tu8 ret = 0;\n\n\t \n\tfor (i = 0; i < I40E_MAX_USER_PRIORITY; i++)\n\t\tnum_tc |= BIT(dcbcfg->etscfg.prioritytable[i]);\n\n\t \n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (num_tc & BIT(i)) {\n\t\t\tif (!tc_unused) {\n\t\t\t\tret++;\n\t\t\t} else {\n\t\t\t\tpr_err(\"Non-contiguous TC - Disabling DCB\\n\");\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t} else {\n\t\t\ttc_unused = 1;\n\t\t}\n\t}\n\n\t \n\tif (!ret)\n\t\tret = 1;\n\n\treturn ret;\n}\n\n \nstatic u8 i40e_dcb_get_enabled_tc(struct i40e_dcbx_config *dcbcfg)\n{\n\tu8 num_tc = i40e_dcb_get_num_tc(dcbcfg);\n\tu8 enabled_tc = 1;\n\tu8 i;\n\n\tfor (i = 0; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\n\treturn enabled_tc;\n}\n\n \nstatic u8 i40e_mqprio_get_enabled_tc(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 num_tc = vsi->mqprio_qopt.qopt.num_tc;\n\tu8 enabled_tc = 1, i;\n\n\tfor (i = 1; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\treturn enabled_tc;\n}\n\n \nstatic u8 i40e_pf_get_num_tc(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 i, enabled_tc = 1;\n\tu8 num_tc = 0;\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tif (i40e_is_tc_mqprio_enabled(pf))\n\t\treturn pf->vsi[pf->lan_vsi]->mqprio_qopt.qopt.num_tc;\n\n\t \n\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED))\n\t\treturn 1;\n\n\t \n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\treturn i40e_dcb_get_num_tc(dcbcfg);\n\n\t \n\tif (pf->hw.func_caps.iscsi)\n\t\tenabled_tc =  i40e_get_iscsi_tc_map(pf);\n\telse\n\t\treturn 1;  \n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tnum_tc++;\n\t}\n\treturn num_tc;\n}\n\n \nstatic u8 i40e_pf_get_tc_map(struct i40e_pf *pf)\n{\n\tif (i40e_is_tc_mqprio_enabled(pf))\n\t\treturn i40e_mqprio_get_enabled_tc(pf);\n\n\t \n\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED))\n\t\treturn I40E_DEFAULT_TRAFFIC_CLASS;\n\n\t \n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\treturn i40e_dcb_get_enabled_tc(&pf->hw.local_dcbx_config);\n\n\t \n\tif (pf->hw.func_caps.iscsi)\n\t\treturn i40e_get_iscsi_tc_map(pf);\n\telse\n\t\treturn I40E_DEFAULT_TRAFFIC_CLASS;\n}\n\n \nstatic int i40e_vsi_get_bw_info(struct i40e_vsi *vsi)\n{\n\tstruct i40e_aqc_query_vsi_ets_sla_config_resp bw_ets_config = {0};\n\tstruct i40e_aqc_query_vsi_bw_config_resp bw_config = {0};\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 tc_bw_max;\n\tint ret;\n\tint i;\n\n\t \n\tret = i40e_aq_query_vsi_bw_config(hw, vsi->seid, &bw_config, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi bw config, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tret = i40e_aq_query_vsi_ets_sla_config(hw, vsi->seid, &bw_ets_config,\n\t\t\t\t\t       NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi ets bw config, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EINVAL;\n\t}\n\n\tif (bw_config.tc_valid_bits != bw_ets_config.tc_valid_bits) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Enabled TCs mismatch from querying VSI BW info 0x%08x 0x%08x\\n\",\n\t\t\t bw_config.tc_valid_bits,\n\t\t\t bw_ets_config.tc_valid_bits);\n\t\t \n\t}\n\n\tvsi->bw_limit = le16_to_cpu(bw_config.port_bw_limit);\n\tvsi->bw_max_quanta = bw_config.max_bw;\n\ttc_bw_max = le16_to_cpu(bw_ets_config.tc_bw_max[0]) |\n\t\t    (le16_to_cpu(bw_ets_config.tc_bw_max[1]) << 16);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tvsi->bw_ets_share_credits[i] = bw_ets_config.share_credits[i];\n\t\tvsi->bw_ets_limit_credits[i] =\n\t\t\t\t\tle16_to_cpu(bw_ets_config.credits[i]);\n\t\t \n\t\tvsi->bw_ets_max_quanta[i] = (u8)((tc_bw_max >> (i*4)) & 0x7);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int i40e_vsi_configure_bw_alloc(struct i40e_vsi *vsi, u8 enabled_tc,\n\t\t\t\t       u8 *bw_share)\n{\n\tstruct i40e_aqc_configure_vsi_tc_bw_data bw_data;\n\tstruct i40e_pf *pf = vsi->back;\n\tint ret;\n\tint i;\n\n\t \n\tif (i40e_is_tc_mqprio_enabled(pf))\n\t\treturn 0;\n\tif (!vsi->mqprio_qopt.qopt.hw && !(pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\tret = i40e_set_bw_limit(vsi, vsi->seid, 0);\n\t\tif (ret)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed to reset tx rate for vsi->seid %u\\n\",\n\t\t\t\t vsi->seid);\n\t\treturn ret;\n\t}\n\tmemset(&bw_data, 0, sizeof(bw_data));\n\tbw_data.tc_valid_bits = enabled_tc;\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tbw_data.tc_bw_credits[i] = bw_share[i];\n\n\tret = i40e_aq_config_vsi_tc_bw(&pf->hw, vsi->seid, &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"AQ command Config VSI BW allocation per TC failed = %d\\n\",\n\t\t\t pf->hw.aq.asq_last_status);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tvsi->info.qs_handle[i] = bw_data.qs_handles[i];\n\n\treturn 0;\n}\n\n \nstatic void i40e_vsi_config_netdev_tc(struct i40e_vsi *vsi, u8 enabled_tc)\n{\n\tstruct net_device *netdev = vsi->netdev;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 netdev_tc = 0;\n\tint i;\n\tstruct i40e_dcbx_config *dcbcfg = &hw->local_dcbx_config;\n\n\tif (!netdev)\n\t\treturn;\n\n\tif (!enabled_tc) {\n\t\tnetdev_reset_tc(netdev);\n\t\treturn;\n\t}\n\n\t \n\tif (netdev_set_num_tc(netdev, vsi->tc_config.numtc))\n\t\treturn;\n\n\t \n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t \n\t\tif (vsi->tc_config.enabled_tc & BIT(i))\n\t\t\tnetdev_set_tc_queue(netdev,\n\t\t\t\t\tvsi->tc_config.tc_info[i].netdev_tc,\n\t\t\t\t\tvsi->tc_config.tc_info[i].qcount,\n\t\t\t\t\tvsi->tc_config.tc_info[i].qoffset);\n\t}\n\n\tif (i40e_is_tc_mqprio_enabled(pf))\n\t\treturn;\n\n\t \n\tfor (i = 0; i < I40E_MAX_USER_PRIORITY; i++) {\n\t\t \n\t\tu8 ets_tc = dcbcfg->etscfg.prioritytable[i];\n\t\t \n\t\tnetdev_tc =  vsi->tc_config.tc_info[ets_tc].netdev_tc;\n\t\tnetdev_set_prio_tc_map(netdev, i, netdev_tc);\n\t}\n}\n\n \nstatic void i40e_vsi_update_queue_map(struct i40e_vsi *vsi,\n\t\t\t\t      struct i40e_vsi_context *ctxt)\n{\n\t \n\tvsi->info.mapping_flags = ctxt->info.mapping_flags;\n\tmemcpy(&vsi->info.queue_mapping,\n\t       &ctxt->info.queue_mapping, sizeof(vsi->info.queue_mapping));\n\tmemcpy(&vsi->info.tc_mapping, ctxt->info.tc_mapping,\n\t       sizeof(vsi->info.tc_mapping));\n}\n\n \nint i40e_update_adq_vsi_queues(struct i40e_vsi *vsi, int vsi_offset)\n{\n\tstruct i40e_vsi_context ctxt = {};\n\tstruct i40e_pf *pf;\n\tstruct i40e_hw *hw;\n\tint ret;\n\n\tif (!vsi)\n\t\treturn -EINVAL;\n\tpf = vsi->back;\n\thw = &pf->hw;\n\n\tctxt.seid = vsi->seid;\n\tctxt.pf_num = hw->pf_id;\n\tctxt.vf_num = vsi->vf_id + hw->func_caps.vf_base_id + vsi_offset;\n\tctxt.uplink_seid = vsi->uplink_seid;\n\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\tctxt.flags = I40E_AQ_VSI_TYPE_VF;\n\tctxt.info = vsi->info;\n\n\ti40e_vsi_setup_queue_map(vsi, &ctxt, vsi->tc_config.enabled_tc,\n\t\t\t\t false);\n\tif (vsi->reconfig_rss) {\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size,\n\t\t\t\t      vsi->num_queue_pairs);\n\t\tret = i40e_vsi_config_rss(vsi);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev, \"Failed to reconfig rss for num_queues\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tvsi->reconfig_rss = false;\n\t}\n\n\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"Update vsi config failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn ret;\n\t}\n\t \n\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\tvsi->info.valid_sections = 0;\n\n\treturn ret;\n}\n\n \nstatic int i40e_vsi_config_tc(struct i40e_vsi *vsi, u8 enabled_tc)\n{\n\tu8 bw_share[I40E_MAX_TRAFFIC_CLASS] = {0};\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tint ret = 0;\n\tint i;\n\n\t \n\tif (vsi->tc_config.enabled_tc == enabled_tc &&\n\t    vsi->mqprio_qopt.mode != TC_MQPRIO_MODE_CHANNEL)\n\t\treturn ret;\n\n\t \n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tbw_share[i] = 1;\n\t}\n\n\tret = i40e_vsi_configure_bw_alloc(vsi, enabled_tc, bw_share);\n\tif (ret) {\n\t\tstruct i40e_aqc_query_vsi_bw_config_resp bw_config = {0};\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed configuring TC map %d for VSI %d\\n\",\n\t\t\t enabled_tc, vsi->seid);\n\t\tret = i40e_aq_query_vsi_bw_config(hw, vsi->seid,\n\t\t\t\t\t\t  &bw_config, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed querying vsi bw info, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\t\tgoto out;\n\t\t}\n\t\tif ((bw_config.tc_valid_bits & enabled_tc) != enabled_tc) {\n\t\t\tu8 valid_tc = bw_config.tc_valid_bits & enabled_tc;\n\n\t\t\tif (!valid_tc)\n\t\t\t\tvalid_tc = bw_config.tc_valid_bits;\n\t\t\t \n\t\t\tvalid_tc |= 1;\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Requested tc 0x%x, but FW reports 0x%x as valid. Attempting to use 0x%x.\\n\",\n\t\t\t\t enabled_tc, bw_config.tc_valid_bits, valid_tc);\n\t\t\tenabled_tc = valid_tc;\n\t\t}\n\n\t\tret = i40e_vsi_configure_bw_alloc(vsi, enabled_tc, bw_share);\n\t\tif (ret) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Unable to  configure TC map %d for VSI %d\\n\",\n\t\t\t\tenabled_tc, vsi->seid);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tctxt.seid = vsi->seid;\n\tctxt.pf_num = vsi->back->hw.pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = vsi->uplink_seid;\n\tctxt.info = vsi->info;\n\tif (i40e_is_tc_mqprio_enabled(pf)) {\n\t\tret = i40e_vsi_setup_queue_map_mqprio(vsi, &ctxt, enabled_tc);\n\t\tif (ret)\n\t\t\tgoto out;\n\t} else {\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, false);\n\t}\n\n\t \n\tif (!vsi->mqprio_qopt.qopt.hw && vsi->reconfig_rss) {\n\t\tvsi->rss_size = min_t(int, vsi->back->alloc_rss_size,\n\t\t\t\t      vsi->num_queue_pairs);\n\t\tret = i40e_vsi_config_rss(vsi);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Failed to reconfig rss for num_queues\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tvsi->reconfig_rss = false;\n\t}\n\tif (vsi->back->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_QUEUE_OPT_VALID);\n\t\tctxt.info.queueing_opt_flags |= I40E_AQ_VSI_QUE_OPT_TCP_ENA;\n\t}\n\n\t \n\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Update vsi tc config failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\t \n\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\tvsi->info.valid_sections = 0;\n\n\t \n\tret = i40e_vsi_get_bw_info(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed updating vsi bw info, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t \n\ti40e_vsi_config_netdev_tc(vsi, enabled_tc);\nout:\n\treturn ret;\n}\n\n \nstatic int i40e_get_link_speed(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tswitch (pf->hw.phy.link_info.link_speed) {\n\tcase I40E_LINK_SPEED_40GB:\n\t\treturn 40000;\n\tcase I40E_LINK_SPEED_25GB:\n\t\treturn 25000;\n\tcase I40E_LINK_SPEED_20GB:\n\t\treturn 20000;\n\tcase I40E_LINK_SPEED_10GB:\n\t\treturn 10000;\n\tcase I40E_LINK_SPEED_1GB:\n\t\treturn 1000;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n \nstatic u64 i40e_bw_bytes_to_mbits(struct i40e_vsi *vsi, u64 max_tx_rate)\n{\n\tif (max_tx_rate < I40E_BW_MBPS_DIVISOR) {\n\t\tdev_warn(&vsi->back->pdev->dev,\n\t\t\t \"Setting max tx rate to minimum usable value of 50Mbps.\\n\");\n\t\tmax_tx_rate = I40E_BW_CREDIT_DIVISOR;\n\t} else {\n\t\tdo_div(max_tx_rate, I40E_BW_MBPS_DIVISOR);\n\t}\n\n\treturn max_tx_rate;\n}\n\n \nint i40e_set_bw_limit(struct i40e_vsi *vsi, u16 seid, u64 max_tx_rate)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu64 credits = 0;\n\tint speed = 0;\n\tint ret = 0;\n\n\tspeed = i40e_get_link_speed(vsi);\n\tif (max_tx_rate > speed) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Invalid max tx rate %llu specified for VSI seid %d.\",\n\t\t\tmax_tx_rate, seid);\n\t\treturn -EINVAL;\n\t}\n\tif (max_tx_rate && max_tx_rate < I40E_BW_CREDIT_DIVISOR) {\n\t\tdev_warn(&pf->pdev->dev,\n\t\t\t \"Setting max tx rate to minimum usable value of 50Mbps.\\n\");\n\t\tmax_tx_rate = I40E_BW_CREDIT_DIVISOR;\n\t}\n\n\t \n\tcredits = max_tx_rate;\n\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\tret = i40e_aq_config_vsi_bw_limit(&pf->hw, seid, credits,\n\t\t\t\t\t  I40E_MAX_BW_INACTIVE_ACCUM, NULL);\n\tif (ret)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed set tx rate (%llu Mbps) for vsi->seid %u, err %pe aq_err %s\\n\",\n\t\t\tmax_tx_rate, seid, ERR_PTR(ret),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\treturn ret;\n}\n\n \nstatic void i40e_remove_queue_channels(struct i40e_vsi *vsi)\n{\n\tenum i40e_admin_queue_err last_aq_status;\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\tint ret, i;\n\n\t \n\tvsi->current_rss_size = 0;\n\n\t \n\tif (list_empty(&vsi->ch_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tstruct i40e_vsi *p_vsi;\n\n\t\tlist_del(&ch->list);\n\t\tp_vsi = ch->parent_vsi;\n\t\tif (!p_vsi || !ch->initialized) {\n\t\t\tkfree(ch);\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\t\tu16 pf_q;\n\n\t\t\tpf_q = ch->base_queue + i;\n\t\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\t\ttx_ring->ch = NULL;\n\n\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\trx_ring->ch = NULL;\n\t\t}\n\n\t\t \n\t\tret = i40e_set_bw_limit(vsi, ch->seid, 0);\n\t\tif (ret)\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"Failed to reset tx rate for ch->seid %u\\n\",\n\t\t\t\t ch->seid);\n\n\t\t \n\t\thlist_for_each_entry_safe(cfilter, node,\n\t\t\t\t\t  &pf->cloud_filter_list, cloud_node) {\n\t\t\tif (cfilter->seid != ch->seid)\n\t\t\t\tcontinue;\n\n\t\t\thash_del(&cfilter->cloud_node);\n\t\t\tif (cfilter->dst_port)\n\t\t\t\tret = i40e_add_del_cloud_filter_big_buf(vsi,\n\t\t\t\t\t\t\t\t\tcfilter,\n\t\t\t\t\t\t\t\t\tfalse);\n\t\t\telse\n\t\t\t\tret = i40e_add_del_cloud_filter(vsi, cfilter,\n\t\t\t\t\t\t\t\tfalse);\n\t\t\tlast_aq_status = pf->hw.aq.asq_last_status;\n\t\t\tif (ret)\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"Failed to delete cloud filter, err %pe aq_err %s\\n\",\n\t\t\t\t\t ERR_PTR(ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\t\tkfree(cfilter);\n\t\t}\n\n\t\t \n\t\tret = i40e_aq_delete_element(&vsi->back->hw, ch->seid,\n\t\t\t\t\t     NULL);\n\t\tif (ret)\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"unable to remove channel (%d) for parent VSI(%d)\\n\",\n\t\t\t\tch->seid, p_vsi->seid);\n\t\tkfree(ch);\n\t}\n\tINIT_LIST_HEAD(&vsi->ch_list);\n}\n\n \nstatic int i40e_get_max_queues_for_channel(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tint max = 0;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (!ch->initialized)\n\t\t\tcontinue;\n\t\tif (ch->num_queue_pairs > max)\n\t\t\tmax = ch->num_queue_pairs;\n\t}\n\n\treturn max;\n}\n\n \nstatic int i40e_validate_num_queues(struct i40e_pf *pf, int num_queues,\n\t\t\t\t    struct i40e_vsi *vsi, bool *reconfig_rss)\n{\n\tint max_ch_queues;\n\n\tif (!reconfig_rss)\n\t\treturn -EINVAL;\n\n\t*reconfig_rss = false;\n\tif (vsi->current_rss_size) {\n\t\tif (num_queues > vsi->current_rss_size) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) > vsi's current_size(%d)\\n\",\n\t\t\t\tnum_queues, vsi->current_rss_size);\n\t\t\treturn -EINVAL;\n\t\t} else if ((num_queues < vsi->current_rss_size) &&\n\t\t\t   (!is_power_of_2(num_queues))) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) < vsi's current_size(%d), but not power of 2\\n\",\n\t\t\t\tnum_queues, vsi->current_rss_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!is_power_of_2(num_queues)) {\n\t\t \n\t\tmax_ch_queues = i40e_get_max_queues_for_channel(vsi);\n\t\tif (num_queues < max_ch_queues) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Error: num_queues (%d) < max queues configured for channel(%d)\\n\",\n\t\t\t\tnum_queues, max_ch_queues);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*reconfig_rss = true;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int i40e_vsi_reconfig_rss(struct i40e_vsi *vsi, u16 rss_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tstruct i40e_hw *hw = &pf->hw;\n\tint local_rss_size;\n\tu8 *lut;\n\tint ret;\n\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tif (rss_size > vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tlocal_rss_size = min_t(int, vsi->rss_size, rss_size);\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t \n\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, local_rss_size);\n\n\t \n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\n\tret = i40e_config_rss(vsi, seed, lut, vsi->rss_table_size);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot set RSS lut, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\tkfree(lut);\n\t\treturn ret;\n\t}\n\tkfree(lut);\n\n\t \n\tif (!vsi->orig_rss_size)\n\t\tvsi->orig_rss_size = vsi->rss_size;\n\tvsi->current_rss_size = local_rss_size;\n\n\treturn ret;\n}\n\n \nstatic void i40e_channel_setup_queue_map(struct i40e_pf *pf,\n\t\t\t\t\t struct i40e_vsi_context *ctxt,\n\t\t\t\t\t struct i40e_channel *ch)\n{\n\tu16 qcount, qmap, sections = 0;\n\tu8 offset = 0;\n\tint pow;\n\n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\n\tqcount = min_t(int, ch->num_queue_pairs, pf->num_lan_msix);\n\tch->num_queue_pairs = qcount;\n\n\t \n\tpow = ilog2(qcount);\n\tif (!is_power_of_2(qcount))\n\t\tpow++;\n\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t \n\tctxt->info.tc_mapping[0] = cpu_to_le16(qmap);\n\n\tctxt->info.up_enable_bits = 0x1;  \n\tctxt->info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt->info.queue_mapping[0] = cpu_to_le16(ch->base_queue);\n\tctxt->info.valid_sections |= cpu_to_le16(sections);\n}\n\n \nstatic int i40e_add_channel(struct i40e_pf *pf, u16 uplink_seid,\n\t\t\t    struct i40e_channel *ch)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tu8 enabled_tc = 0x1;  \n\tint ret;\n\n\tif (ch->type != I40E_VSI_VMDQ2) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"add new vsi failed, ch->type %d\\n\", ch->type);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tctxt.pf_num = hw->pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = uplink_seid;\n\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\tif (ch->type == I40E_VSI_VMDQ2)\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VMDQ2;\n\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED) {\n\t\tctxt.info.valid_sections |=\n\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\tctxt.info.switch_id =\n\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t}\n\n\t \n\ti40e_channel_setup_queue_map(pf, &ctxt, ch);\n\n\t \n\tret = i40e_aq_add_vsi(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"add new vsi failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\treturn -ENOENT;\n\t}\n\n\t \n\tch->enabled_tc = !i40e_is_channel_macvlan(ch) && enabled_tc;\n\tch->seid = ctxt.seid;\n\tch->vsi_number = ctxt.vsi_number;\n\tch->stat_counter_idx = le16_to_cpu(ctxt.info.stat_counter_idx);\n\n\t \n\tch->info.mapping_flags = ctxt.info.mapping_flags;\n\tmemcpy(&ch->info.queue_mapping,\n\t       &ctxt.info.queue_mapping, sizeof(ctxt.info.queue_mapping));\n\tmemcpy(&ch->info.tc_mapping, ctxt.info.tc_mapping,\n\t       sizeof(ctxt.info.tc_mapping));\n\n\treturn 0;\n}\n\nstatic int i40e_channel_config_bw(struct i40e_vsi *vsi, struct i40e_channel *ch,\n\t\t\t\t  u8 *bw_share)\n{\n\tstruct i40e_aqc_configure_vsi_tc_bw_data bw_data;\n\tint ret;\n\tint i;\n\n\tmemset(&bw_data, 0, sizeof(bw_data));\n\tbw_data.tc_valid_bits = ch->enabled_tc;\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tbw_data.tc_bw_credits[i] = bw_share[i];\n\n\tret = i40e_aq_config_vsi_tc_bw(&vsi->back->hw, ch->seid,\n\t\t\t\t       &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Config VSI BW allocation per TC failed, aq_err: %d for new_vsi->seid %u\\n\",\n\t\t\t vsi->back->hw.aq.asq_last_status, ch->seid);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++)\n\t\tch->info.qs_handle[i] = bw_data.qs_handles[i];\n\n\treturn 0;\n}\n\n \nstatic int i40e_channel_config_tx_ring(struct i40e_pf *pf,\n\t\t\t\t       struct i40e_vsi *vsi,\n\t\t\t\t       struct i40e_channel *ch)\n{\n\tu8 bw_share[I40E_MAX_TRAFFIC_CLASS] = {0};\n\tint ret;\n\tint i;\n\n\t \n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (ch->enabled_tc & BIT(i))\n\t\t\tbw_share[i] = 1;\n\t}\n\n\t \n\tret = i40e_channel_config_bw(vsi, ch, bw_share);\n\tif (ret) {\n\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t \"Failed configuring TC map %d for channel (seid %u)\\n\",\n\t\t\t ch->enabled_tc, ch->seid);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\tu16 pf_q;\n\n\t\tpf_q = ch->base_queue + i;\n\n\t\t \n\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\ttx_ring->ch = ch;\n\n\t\t \n\t\trx_ring = vsi->rx_rings[pf_q];\n\t\trx_ring->ch = ch;\n\t}\n\n\treturn 0;\n}\n\n \nstatic inline int i40e_setup_hw_channel(struct i40e_pf *pf,\n\t\t\t\t\tstruct i40e_vsi *vsi,\n\t\t\t\t\tstruct i40e_channel *ch,\n\t\t\t\t\tu16 uplink_seid, u8 type)\n{\n\tint ret;\n\n\tch->initialized = false;\n\tch->base_queue = vsi->next_base_queue;\n\tch->type = type;\n\n\t \n\tret = i40e_add_channel(pf, uplink_seid, ch);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to add_channel using uplink_seid %u\\n\",\n\t\t\t uplink_seid);\n\t\treturn ret;\n\t}\n\n\t \n\tch->initialized = true;\n\n\t \n\tret = i40e_channel_config_tx_ring(pf, vsi, ch);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to configure TX rings for channel %u\\n\",\n\t\t\t ch->seid);\n\t\treturn ret;\n\t}\n\n\t \n\tvsi->next_base_queue = vsi->next_base_queue + ch->num_queue_pairs;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"Added channel: vsi_seid %u, vsi_number %u, stat_counter_idx %u, num_queue_pairs %u, pf->next_base_queue %d\\n\",\n\t\tch->seid, ch->vsi_number, ch->stat_counter_idx,\n\t\tch->num_queue_pairs,\n\t\tvsi->next_base_queue);\n\treturn ret;\n}\n\n \nstatic bool i40e_setup_channel(struct i40e_pf *pf, struct i40e_vsi *vsi,\n\t\t\t       struct i40e_channel *ch)\n{\n\tu8 vsi_type;\n\tu16 seid;\n\tint ret;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tvsi_type = I40E_VSI_VMDQ2;\n\t} else {\n\t\tdev_err(&pf->pdev->dev, \"unsupported parent vsi type(%d)\\n\",\n\t\t\tvsi->type);\n\t\treturn false;\n\t}\n\n\t \n\tseid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\n\t \n\tret = i40e_setup_hw_channel(pf, vsi, ch, seid, vsi_type);\n\tif (ret) {\n\t\tdev_err(&pf->pdev->dev, \"failed to setup hw_channel\\n\");\n\t\treturn false;\n\t}\n\n\treturn ch->initialized ? true : false;\n}\n\n \nstatic int i40e_validate_and_set_switch_mode(struct i40e_vsi *vsi)\n{\n\tu8 mode;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_get_capabilities(pf, i40e_aqc_opc_list_dev_capabilities);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tif (hw->dev_caps.switch_mode) {\n\t\t \n\t\tu32 switch_mode = hw->dev_caps.switch_mode &\n\t\t\t\t  I40E_SWITCH_MODE_MASK;\n\t\tif (switch_mode >= I40E_CLOUD_FILTER_MODE1) {\n\t\t\tif (switch_mode == I40E_CLOUD_FILTER_MODE2)\n\t\t\t\treturn 0;\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Invalid switch_mode (%d), only non-tunneled mode for cloud filter is supported\\n\",\n\t\t\t\thw->dev_caps.switch_mode);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t \n\tmode = I40E_AQ_SET_SWITCH_BIT7_VALID;\n\n\t \n\tmode |= I40E_AQ_SET_SWITCH_L4_TYPE_TCP;\n\n\t \n\tmode |= I40E_AQ_SET_SWITCH_MODE_NON_TUNNEL;\n\n\t \n\tret = i40e_aq_set_switch_config(hw, pf->last_sw_conf_flags,\n\t\t\t\t\tpf->last_sw_conf_valid_flags,\n\t\t\t\t\tmode, NULL);\n\tif (ret && hw->aq.asq_last_status != I40E_AQ_RC_ESRCH)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"couldn't set switch config bits, err %pe aq_err %s\\n\",\n\t\t\tERR_PTR(ret),\n\t\t\ti40e_aq_str(hw,\n\t\t\t\t    hw->aq.asq_last_status));\n\n\treturn ret;\n}\n\n \nint i40e_create_queue_channel(struct i40e_vsi *vsi,\n\t\t\t      struct i40e_channel *ch)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tbool reconfig_rss;\n\tint err;\n\n\tif (!ch)\n\t\treturn -EINVAL;\n\n\tif (!ch->num_queue_pairs) {\n\t\tdev_err(&pf->pdev->dev, \"Invalid num_queues requested: %d\\n\",\n\t\t\tch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\terr = i40e_validate_num_queues(pf, ch->num_queue_pairs, vsi,\n\t\t\t\t       &reconfig_rss);\n\tif (err) {\n\t\tdev_info(&pf->pdev->dev, \"Failed to validate num_queues (%d)\\n\",\n\t\t\t ch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\n\tif (!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) {\n\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tif (i40e_is_tc_mqprio_enabled(pf))\n\t\t\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\t\t\telse\n\t\t\t\ti40e_do_reset_safe(pf, I40E_PF_RESET_FLAG);\n\t\t}\n\t\t \n\t}\n\n\t \n\tif (!vsi->cnt_q_avail || vsi->cnt_q_avail < ch->num_queue_pairs) {\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Error: cnt_q_avail (%u) less than num_queues %d\\n\",\n\t\t\tvsi->cnt_q_avail, ch->num_queue_pairs);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (reconfig_rss && (vsi->type == I40E_VSI_MAIN)) {\n\t\terr = i40e_vsi_reconfig_rss(vsi, ch->num_queue_pairs);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Error: unable to reconfig rss for num_queues (%u)\\n\",\n\t\t\t\t ch->num_queue_pairs);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!i40e_setup_channel(pf, vsi, ch)) {\n\t\tdev_info(&pf->pdev->dev, \"Failed to setup channel\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev_info(&pf->pdev->dev,\n\t\t \"Setup channel (id:%u) utilizing num_queues %d\\n\",\n\t\t ch->seid, ch->num_queue_pairs);\n\n\t \n\tif (ch->max_tx_rate) {\n\t\tu64 credits = ch->max_tx_rate;\n\n\t\tif (i40e_set_bw_limit(vsi, ch->seid, ch->max_tx_rate))\n\t\t\treturn -EINVAL;\n\n\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\tch->max_tx_rate,\n\t\t\tcredits,\n\t\t\tch->seid);\n\t}\n\n\t \n\tch->parent_vsi = vsi;\n\n\t \n\tvsi->cnt_q_avail -= ch->num_queue_pairs;\n\n\treturn 0;\n}\n\n \nstatic int i40e_configure_queue_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch;\n\tu64 max_rate = 0;\n\tint ret = 0, i;\n\n\t \n\tvsi->tc_seid_map[0] = vsi->seid;\n\tfor (i = 1; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (vsi->tc_config.enabled_tc & BIT(i)) {\n\t\t\tch = kzalloc(sizeof(*ch), GFP_KERNEL);\n\t\t\tif (!ch) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto err_free;\n\t\t\t}\n\n\t\t\tINIT_LIST_HEAD(&ch->list);\n\t\t\tch->num_queue_pairs =\n\t\t\t\tvsi->tc_config.tc_info[i].qcount;\n\t\t\tch->base_queue =\n\t\t\t\tvsi->tc_config.tc_info[i].qoffset;\n\n\t\t\t \n\t\t\tmax_rate = vsi->mqprio_qopt.max_rate[i];\n\t\t\tdo_div(max_rate, I40E_BW_MBPS_DIVISOR);\n\t\t\tch->max_tx_rate = max_rate;\n\n\t\t\tlist_add_tail(&ch->list, &vsi->ch_list);\n\n\t\t\tret = i40e_create_queue_channel(vsi, ch);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\t\"Failed creating queue channel with TC%d: queues %d\\n\",\n\t\t\t\t\ti, ch->num_queue_pairs);\n\t\t\t\tgoto err_free;\n\t\t\t}\n\t\t\tvsi->tc_seid_map[i] = ch->seid;\n\t\t}\n\t}\n\n\t \n\ti40e_do_reset(vsi->back, I40E_PF_RESET_FLAG, true);\n\treturn ret;\n\nerr_free:\n\ti40e_remove_queue_channels(vsi);\n\treturn ret;\n}\n\n \nint i40e_veb_config_tc(struct i40e_veb *veb, u8 enabled_tc)\n{\n\tstruct i40e_aqc_configure_switching_comp_bw_config_data bw_data = {0};\n\tstruct i40e_pf *pf = veb->pf;\n\tint ret = 0;\n\tint i;\n\n\t \n\tif (!enabled_tc || veb->enabled_tc == enabled_tc)\n\t\treturn ret;\n\n\tbw_data.tc_valid_bits = enabled_tc;\n\t \n\n\t \n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tif (enabled_tc & BIT(i))\n\t\t\tbw_data.tc_bw_share_credits[i] = 1;\n\t}\n\n\tret = i40e_aq_config_switch_comp_bw_config(&pf->hw, veb->seid,\n\t\t\t\t\t\t   &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VEB bw config failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t \n\tret = i40e_veb_get_bw_info(veb);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed getting veb bw config, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n\nout:\n\treturn ret;\n}\n\n#ifdef CONFIG_I40E_DCB\n \nstatic void i40e_dcb_reconfigure(struct i40e_pf *pf)\n{\n\tu8 tc_map = 0;\n\tint ret;\n\tu8 v;\n\n\t \n\ttc_map = i40e_pf_get_tc_map(pf);\n\tif (tc_map == I40E_DEFAULT_TRAFFIC_CLASS)\n\t\treturn;\n\n\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\tif (!pf->veb[v])\n\t\t\tcontinue;\n\t\tret = i40e_veb_config_tc(pf->veb[v], tc_map);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed configuring TC for VEB seid=%d\\n\",\n\t\t\t\t pf->veb[v]->seid);\n\t\t\t \n\t\t}\n\t}\n\n\t \n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (!pf->vsi[v])\n\t\t\tcontinue;\n\n\t\t \n\t\tif (v == pf->lan_vsi)\n\t\t\ttc_map = i40e_pf_get_tc_map(pf);\n\t\telse\n\t\t\ttc_map = I40E_DEFAULT_TRAFFIC_CLASS;\n\n\t\tret = i40e_vsi_config_tc(pf->vsi[v], tc_map);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed configuring TC for VSI seid=%d\\n\",\n\t\t\t\t pf->vsi[v]->seid);\n\t\t\t \n\t\t} else {\n\t\t\t \n\t\t\ti40e_vsi_map_rings_to_vectors(pf->vsi[v]);\n\t\t\tif (pf->vsi[v]->netdev)\n\t\t\t\ti40e_dcbnl_set_all(pf->vsi[v]);\n\t\t}\n\t}\n}\n\n \nstatic int i40e_resume_port_tx(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_aq_resume_port_tx(hw, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Resume Port Tx failed, err %pe aq_err %s\\n\",\n\t\t\t  ERR_PTR(ret),\n\t\t\t  i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\t \n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\ti40e_service_event_schedule(pf);\n\t}\n\n\treturn ret;\n}\n\n \nstatic int i40e_suspend_port_tx(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_aq_suspend_port_tx(hw, pf->mac_seid, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Suspend Port Tx failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\t \n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\ti40e_service_event_schedule(pf);\n\t}\n\n\treturn ret;\n}\n\n \nstatic int i40e_hw_set_dcb_config(struct i40e_pf *pf,\n\t\t\t\t  struct i40e_dcbx_config *new_cfg)\n{\n\tstruct i40e_dcbx_config *old_cfg = &pf->hw.local_dcbx_config;\n\tint ret;\n\n\t \n\tif (!memcmp(&new_cfg, &old_cfg, sizeof(new_cfg))) {\n\t\tdev_dbg(&pf->pdev->dev, \"No Change in DCB Config required.\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\ti40e_pf_quiesce_all_vsi(pf);\n\n\t \n\t*old_cfg = *new_cfg;\n\told_cfg->etsrec = old_cfg->etscfg;\n\tret = i40e_set_dcb_config(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Set DCB Config failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t \n\ti40e_dcb_reconfigure(pf);\nout:\n\t \n\tif (!test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state)) {\n\t\t \n\t\tret = i40e_resume_port_tx(pf);\n\t\t \n\t\tif (ret)\n\t\t\tgoto err;\n\t\ti40e_pf_unquiesce_all_vsi(pf);\n\t}\nerr:\n\treturn ret;\n}\n\n \nint i40e_hw_dcb_config(struct i40e_pf *pf, struct i40e_dcbx_config *new_cfg)\n{\n\tstruct i40e_aqc_configure_switching_comp_ets_data ets_data;\n\tu8 prio_type[I40E_MAX_TRAFFIC_CLASS] = {0};\n\tu32 mfs_tc[I40E_MAX_TRAFFIC_CLASS];\n\tstruct i40e_dcbx_config *old_cfg;\n\tu8 mode[I40E_MAX_TRAFFIC_CLASS];\n\tstruct i40e_rx_pb_config pb_cfg;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 num_ports = hw->num_ports;\n\tbool need_reconfig;\n\tint ret = -EINVAL;\n\tu8 lltc_map = 0;\n\tu8 tc_map = 0;\n\tu8 new_numtc;\n\tu8 i;\n\n\tdev_dbg(&pf->pdev->dev, \"Configuring DCB registers directly\\n\");\n\t \n\n\tnew_numtc = i40e_dcb_get_num_tc(new_cfg);\n\n\tmemset(&ets_data, 0, sizeof(ets_data));\n\tfor (i = 0; i < new_numtc; i++) {\n\t\ttc_map |= BIT(i);\n\t\tswitch (new_cfg->etscfg.tsatable[i]) {\n\t\tcase I40E_IEEE_TSA_ETS:\n\t\t\tprio_type[i] = I40E_DCB_PRIO_TYPE_ETS;\n\t\t\tets_data.tc_bw_share_credits[i] =\n\t\t\t\t\tnew_cfg->etscfg.tcbwtable[i];\n\t\t\tbreak;\n\t\tcase I40E_IEEE_TSA_STRICT:\n\t\t\tprio_type[i] = I40E_DCB_PRIO_TYPE_STRICT;\n\t\t\tlltc_map |= BIT(i);\n\t\t\tets_data.tc_bw_share_credits[i] =\n\t\t\t\t\tI40E_DCB_STRICT_PRIO_CREDITS;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tneed_reconfig = false;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\told_cfg = &hw->local_dcbx_config;\n\t \n\tneed_reconfig = i40e_dcb_need_reconfig(pf, old_cfg, new_cfg);\n\n\t \n\tif (need_reconfig) {\n\t\t \n\t\tif (new_numtc > 1)\n\t\t\tpf->flags |= I40E_FLAG_DCB_ENABLED;\n\t\telse\n\t\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\n\t\tset_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t\t \n\t\ti40e_pf_quiesce_all_vsi(pf);\n\t\tret = i40e_suspend_port_tx(pf);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\t \n\tets_data.tc_valid_bits = tc_map;\n\tets_data.tc_strict_priority_flags = lltc_map;\n\tret = i40e_aq_config_switch_comp_ets\n\t\t(hw, pf->mac_seid, &ets_data,\n\t\t i40e_aqc_opc_modify_switching_comp_ets, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Modify Port ETS failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t \n\tmemset(&mode, I40E_DCB_ARB_MODE_ROUND_ROBIN, sizeof(mode));\n\ti40e_dcb_hw_set_num_tc(hw, new_numtc);\n\ti40e_dcb_hw_rx_fifo_config(hw, I40E_DCB_ARB_MODE_ROUND_ROBIN,\n\t\t\t\t   I40E_DCB_ARB_MODE_STRICT_PRIORITY,\n\t\t\t\t   I40E_DCB_DEFAULT_MAX_EXPONENT,\n\t\t\t\t   lltc_map);\n\ti40e_dcb_hw_rx_cmd_monitor_config(hw, new_numtc, num_ports);\n\ti40e_dcb_hw_rx_ets_bw_config(hw, new_cfg->etscfg.tcbwtable, mode,\n\t\t\t\t     prio_type);\n\ti40e_dcb_hw_pfc_config(hw, new_cfg->pfc.pfcenable,\n\t\t\t       new_cfg->etscfg.prioritytable);\n\ti40e_dcb_hw_rx_up2tc_config(hw, new_cfg->etscfg.prioritytable);\n\n\t \n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tmfs_tc[i] = pf->vsi[pf->lan_vsi]->netdev->mtu;\n\t\tmfs_tc[i] += I40E_PACKET_HDR_PAD;\n\t}\n\n\ti40e_dcb_hw_calculate_pool_sizes(hw, num_ports,\n\t\t\t\t\t false, new_cfg->pfc.pfcenable,\n\t\t\t\t\t mfs_tc, &pb_cfg);\n\ti40e_dcb_hw_rx_pb_config(hw, &pf->pb_cfg, &pb_cfg);\n\n\t \n\tpf->pb_cfg = pb_cfg;\n\n\t \n\tret = i40e_aq_dcb_updated(&pf->hw, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"DCB Updated failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\t \n\t*old_cfg = *new_cfg;\n\n\t \n\ti40e_dcb_reconfigure(pf);\nout:\n\t \n\tif (need_reconfig) {\n\t\tret = i40e_resume_port_tx(pf);\n\n\t\tclear_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t\t \n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\t \n\t\tret = i40e_pf_wait_queues_disabled(pf);\n\t\tif (ret) {\n\t\t\t \n\t\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\t\ti40e_service_event_schedule(pf);\n\t\t\tgoto err;\n\t\t} else {\n\t\t\ti40e_pf_unquiesce_all_vsi(pf);\n\t\t\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\t\t\tset_bit(__I40E_CLIENT_L2_CHANGE, pf->state);\n\t\t}\n\t\t \n\t\tif (pf->hw_features & I40E_HW_USE_SET_LLDP_MIB)\n\t\t\tret = i40e_hw_set_dcb_config(pf, new_cfg);\n\t}\n\nerr:\n\treturn ret;\n}\n\n \nint i40e_dcb_sw_default_config(struct i40e_pf *pf)\n{\n\tstruct i40e_dcbx_config *dcb_cfg = &pf->hw.local_dcbx_config;\n\tstruct i40e_aqc_configure_switching_comp_ets_data ets_data;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint err;\n\n\tif (pf->hw_features & I40E_HW_USE_SET_LLDP_MIB) {\n\t\t \n\t\tmemset(&pf->tmp_cfg, 0, sizeof(struct i40e_dcbx_config));\n\t\tpf->tmp_cfg.etscfg.willing = I40E_IEEE_DEFAULT_ETS_WILLING;\n\t\tpf->tmp_cfg.etscfg.maxtcs = 0;\n\t\tpf->tmp_cfg.etscfg.tcbwtable[0] = I40E_IEEE_DEFAULT_ETS_TCBW;\n\t\tpf->tmp_cfg.etscfg.tsatable[0] = I40E_IEEE_TSA_ETS;\n\t\tpf->tmp_cfg.pfc.willing = I40E_IEEE_DEFAULT_PFC_WILLING;\n\t\tpf->tmp_cfg.pfc.pfccap = I40E_MAX_TRAFFIC_CLASS;\n\t\t \n\t\tpf->tmp_cfg.numapps = I40E_IEEE_DEFAULT_NUM_APPS;\n\t\tpf->tmp_cfg.app[0].selector = I40E_APP_SEL_ETHTYPE;\n\t\tpf->tmp_cfg.app[0].priority = I40E_IEEE_DEFAULT_APP_PRIO;\n\t\tpf->tmp_cfg.app[0].protocolid = I40E_APP_PROTOID_FCOE;\n\n\t\treturn i40e_hw_set_dcb_config(pf, &pf->tmp_cfg);\n\t}\n\n\tmemset(&ets_data, 0, sizeof(ets_data));\n\tets_data.tc_valid_bits = I40E_DEFAULT_TRAFFIC_CLASS;  \n\tets_data.tc_strict_priority_flags = 0;  \n\tets_data.tc_bw_share_credits[0] = I40E_IEEE_DEFAULT_ETS_TCBW;  \n\n\t \n\terr = i40e_aq_config_switch_comp_ets\n\t\t(hw, pf->mac_seid, &ets_data,\n\t\t i40e_aqc_opc_enable_switching_comp_ets, NULL);\n\tif (err) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Enable Port ETS failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(err),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\t \n\tdcb_cfg->etscfg.willing = I40E_IEEE_DEFAULT_ETS_WILLING;\n\tdcb_cfg->etscfg.cbs = 0;\n\tdcb_cfg->etscfg.maxtcs = I40E_MAX_TRAFFIC_CLASS;\n\tdcb_cfg->etscfg.tcbwtable[0] = I40E_IEEE_DEFAULT_ETS_TCBW;\n\nout:\n\treturn err;\n}\n\n \nstatic int i40e_init_pf_dcb(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint err;\n\n\t \n\tif (pf->hw_features & I40E_HW_NO_DCB_SUPPORT) {\n\t\tdev_info(&pf->pdev->dev, \"DCB is not supported.\\n\");\n\t\terr = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\tif (pf->flags & I40E_FLAG_DISABLE_FW_LLDP) {\n\t\tdev_info(&pf->pdev->dev, \"FW LLDP is disabled, attempting SW DCB\\n\");\n\t\terr = i40e_dcb_sw_default_config(pf);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev, \"Could not initialize SW DCB\\n\");\n\t\t\tgoto out;\n\t\t}\n\t\tdev_info(&pf->pdev->dev, \"SW DCB initialization succeeded.\\n\");\n\t\tpf->dcbx_cap = DCB_CAP_DCBX_HOST |\n\t\t\t       DCB_CAP_DCBX_VER_IEEE;\n\t\t \n\t\tpf->flags |= I40E_FLAG_DCB_CAPABLE;\n\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\tgoto out;\n\t}\n\terr = i40e_init_dcb(hw, true);\n\tif (!err) {\n\t\t \n\t\tif ((!hw->func_caps.dcb) ||\n\t\t    (hw->dcbx_status == I40E_DCBX_STATUS_DISABLED)) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"DCBX offload is not supported or is disabled for this PF.\\n\");\n\t\t} else {\n\t\t\t \n\t\t\tpf->dcbx_cap = DCB_CAP_DCBX_LLD_MANAGED |\n\t\t\t\t       DCB_CAP_DCBX_VER_IEEE;\n\n\t\t\tpf->flags |= I40E_FLAG_DCB_CAPABLE;\n\t\t\t \n\t\t\tif (i40e_dcb_get_num_tc(&hw->local_dcbx_config) > 1)\n\t\t\t\tpf->flags |= I40E_FLAG_DCB_ENABLED;\n\t\t\telse\n\t\t\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"DCBX offload is supported for this PF.\\n\");\n\t\t}\n\t} else if (pf->hw.aq.asq_last_status == I40E_AQ_RC_EPERM) {\n\t\tdev_info(&pf->pdev->dev, \"FW LLDP disabled for this PF.\\n\");\n\t\tpf->flags |= I40E_FLAG_DISABLE_FW_LLDP;\n\t} else {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Query for DCB configuration failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(err),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n\nout:\n\treturn err;\n}\n#endif  \n\n \nvoid i40e_print_link_message(struct i40e_vsi *vsi, bool isup)\n{\n\tenum i40e_aq_link_speed new_speed;\n\tstruct i40e_pf *pf = vsi->back;\n\tchar *speed = \"Unknown\";\n\tchar *fc = \"Unknown\";\n\tchar *fec = \"\";\n\tchar *req_fec = \"\";\n\tchar *an = \"\";\n\n\tif (isup)\n\t\tnew_speed = pf->hw.phy.link_info.link_speed;\n\telse\n\t\tnew_speed = I40E_LINK_SPEED_UNKNOWN;\n\n\tif ((vsi->current_isup == isup) && (vsi->current_speed == new_speed))\n\t\treturn;\n\tvsi->current_isup = isup;\n\tvsi->current_speed = new_speed;\n\tif (!isup) {\n\t\tnetdev_info(vsi->netdev, \"NIC Link is Down\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (pf->hw.func_caps.npar_enable &&\n\t    (pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_1GB ||\n\t     pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_100MB))\n\t\tnetdev_warn(vsi->netdev,\n\t\t\t    \"The partition detected link speed that is less than 10Gbps\\n\");\n\n\tswitch (pf->hw.phy.link_info.link_speed) {\n\tcase I40E_LINK_SPEED_40GB:\n\t\tspeed = \"40 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_20GB:\n\t\tspeed = \"20 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_25GB:\n\t\tspeed = \"25 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_10GB:\n\t\tspeed = \"10 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_5GB:\n\t\tspeed = \"5 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_2_5GB:\n\t\tspeed = \"2.5 G\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_1GB:\n\t\tspeed = \"1000 M\";\n\t\tbreak;\n\tcase I40E_LINK_SPEED_100MB:\n\t\tspeed = \"100 M\";\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tswitch (pf->hw.fc.current_mode) {\n\tcase I40E_FC_FULL:\n\t\tfc = \"RX/TX\";\n\t\tbreak;\n\tcase I40E_FC_TX_PAUSE:\n\t\tfc = \"TX\";\n\t\tbreak;\n\tcase I40E_FC_RX_PAUSE:\n\t\tfc = \"RX\";\n\t\tbreak;\n\tdefault:\n\t\tfc = \"None\";\n\t\tbreak;\n\t}\n\n\tif (pf->hw.phy.link_info.link_speed == I40E_LINK_SPEED_25GB) {\n\t\treq_fec = \"None\";\n\t\tfec = \"None\";\n\t\tan = \"False\";\n\n\t\tif (pf->hw.phy.link_info.an_info & I40E_AQ_AN_COMPLETED)\n\t\t\tan = \"True\";\n\n\t\tif (pf->hw.phy.link_info.fec_info &\n\t\t    I40E_AQ_CONFIG_FEC_KR_ENA)\n\t\t\tfec = \"CL74 FC-FEC/BASE-R\";\n\t\telse if (pf->hw.phy.link_info.fec_info &\n\t\t\t I40E_AQ_CONFIG_FEC_RS_ENA)\n\t\t\tfec = \"CL108 RS-FEC\";\n\n\t\t \n\t\tif (vsi->back->hw.phy.link_info.req_fec_info &\n\t\t    (I40E_AQ_REQUEST_FEC_KR | I40E_AQ_REQUEST_FEC_RS)) {\n\t\t\tif (vsi->back->hw.phy.link_info.req_fec_info &\n\t\t\t    I40E_AQ_REQUEST_FEC_RS)\n\t\t\t\treq_fec = \"CL108 RS-FEC\";\n\t\t\telse\n\t\t\t\treq_fec = \"CL74 FC-FEC/BASE-R\";\n\t\t}\n\t\tnetdev_info(vsi->netdev,\n\t\t\t    \"NIC Link is Up, %sbps Full Duplex, Requested FEC: %s, Negotiated FEC: %s, Autoneg: %s, Flow Control: %s\\n\",\n\t\t\t    speed, req_fec, fec, an, fc);\n\t} else if (pf->hw.device_id == I40E_DEV_ID_KX_X722) {\n\t\treq_fec = \"None\";\n\t\tfec = \"None\";\n\t\tan = \"False\";\n\n\t\tif (pf->hw.phy.link_info.an_info & I40E_AQ_AN_COMPLETED)\n\t\t\tan = \"True\";\n\n\t\tif (pf->hw.phy.link_info.fec_info &\n\t\t    I40E_AQ_CONFIG_FEC_KR_ENA)\n\t\t\tfec = \"CL74 FC-FEC/BASE-R\";\n\n\t\tif (pf->hw.phy.link_info.req_fec_info &\n\t\t    I40E_AQ_REQUEST_FEC_KR)\n\t\t\treq_fec = \"CL74 FC-FEC/BASE-R\";\n\n\t\tnetdev_info(vsi->netdev,\n\t\t\t    \"NIC Link is Up, %sbps Full Duplex, Requested FEC: %s, Negotiated FEC: %s, Autoneg: %s, Flow Control: %s\\n\",\n\t\t\t    speed, req_fec, fec, an, fc);\n\t} else {\n\t\tnetdev_info(vsi->netdev,\n\t\t\t    \"NIC Link is Up, %sbps Full Duplex, Flow Control: %s\\n\",\n\t\t\t    speed, fc);\n\t}\n\n}\n\n \nstatic int i40e_up_complete(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_vsi_configure_msix(vsi);\n\telse\n\t\ti40e_configure_msi_and_legacy(vsi);\n\n\t \n\terr = i40e_vsi_start_rings(vsi);\n\tif (err)\n\t\treturn err;\n\n\tclear_bit(__I40E_VSI_DOWN, vsi->state);\n\ti40e_napi_enable_all(vsi);\n\ti40e_vsi_enable_irq(vsi);\n\n\tif ((pf->hw.phy.link_info.link_info & I40E_AQ_LINK_UP) &&\n\t    (vsi->netdev)) {\n\t\ti40e_print_link_message(vsi, true);\n\t\tnetif_tx_start_all_queues(vsi->netdev);\n\t\tnetif_carrier_on(vsi->netdev);\n\t}\n\n\t \n\tif (vsi->type == I40E_VSI_FDIR) {\n\t\t \n\t\tpf->fd_add_err = 0;\n\t\tpf->fd_atr_cnt = 0;\n\t\ti40e_fdir_filter_restore(vsi);\n\t}\n\n\t \n\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\ti40e_service_event_schedule(pf);\n\n\treturn 0;\n}\n\n \nstatic void i40e_vsi_reinit_locked(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\twhile (test_and_set_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\tusleep_range(1000, 2000);\n\ti40e_down(vsi);\n\n\ti40e_up(vsi);\n\tclear_bit(__I40E_CONFIG_BUSY, pf->state);\n}\n\n \nstatic int i40e_force_link_state(struct i40e_pf *pf, bool is_up)\n{\n\tstruct i40e_aq_get_phy_abilities_resp abilities;\n\tstruct i40e_aq_set_phy_config config = {0};\n\tbool non_zero_phy_type = is_up;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu64 mask;\n\tu8 speed;\n\tint err;\n\n\t \n\terr = i40e_aq_get_phy_capabilities(hw, false, true, &abilities,\n\t\t\t\t\t   NULL);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"failed to get phy cap., ret =  %pe last_status =  %s\\n\",\n\t\t\tERR_PTR(err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn err;\n\t}\n\tspeed = abilities.link_speed;\n\n\t \n\terr = i40e_aq_get_phy_capabilities(hw, false, false, &abilities,\n\t\t\t\t\t   NULL);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"failed to get phy cap., ret =  %pe last_status =  %s\\n\",\n\t\t\tERR_PTR(err),\n\t\t\ti40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn err;\n\t}\n\n\t \n\tif (pf->flags & I40E_FLAG_TOTAL_PORT_SHUTDOWN_ENABLED)\n\t\tnon_zero_phy_type = true;\n\telse if (is_up && abilities.phy_type != 0 && abilities.link_speed != 0)\n\t\treturn 0;\n\n\t \n\tmask = I40E_PHY_TYPES_BITMASK;\n\tconfig.phy_type =\n\t\tnon_zero_phy_type ? cpu_to_le32((u32)(mask & 0xffffffff)) : 0;\n\tconfig.phy_type_ext =\n\t\tnon_zero_phy_type ? (u8)((mask >> 32) & 0xff) : 0;\n\t \n\tconfig.abilities = abilities.abilities;\n\tif (pf->flags & I40E_FLAG_TOTAL_PORT_SHUTDOWN_ENABLED) {\n\t\tif (is_up)\n\t\t\tconfig.abilities |= I40E_AQ_PHY_ENABLE_LINK;\n\t\telse\n\t\t\tconfig.abilities &= ~(I40E_AQ_PHY_ENABLE_LINK);\n\t}\n\tif (abilities.link_speed != 0)\n\t\tconfig.link_speed = abilities.link_speed;\n\telse\n\t\tconfig.link_speed = speed;\n\tconfig.eee_capability = abilities.eee_capability;\n\tconfig.eeer = abilities.eeer_val;\n\tconfig.low_power_ctrl = abilities.d3_lpan;\n\tconfig.fec_config = abilities.fec_cfg_curr_mod_ext_info &\n\t\t\t    I40E_AQ_PHY_FEC_CONFIG_MASK;\n\terr = i40e_aq_set_phy_config(hw, &config, NULL);\n\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"set phy config ret =  %pe last_status =  %s\\n\",\n\t\t\tERR_PTR(err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn err;\n\t}\n\n\t \n\terr = i40e_update_link_info(hw);\n\tif (err) {\n\t\t \n\t\tmsleep(1000);\n\t\ti40e_update_link_info(hw);\n\t}\n\n\ti40e_aq_set_link_restart_an(hw, is_up, NULL);\n\n\treturn 0;\n}\n\n \nint i40e_up(struct i40e_vsi *vsi)\n{\n\tint err;\n\n\tif (vsi->type == I40E_VSI_MAIN &&\n\t    (vsi->back->flags & I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED ||\n\t     vsi->back->flags & I40E_FLAG_TOTAL_PORT_SHUTDOWN_ENABLED))\n\t\ti40e_force_link_state(vsi->back, true);\n\n\terr = i40e_vsi_configure(vsi);\n\tif (!err)\n\t\terr = i40e_up_complete(vsi);\n\n\treturn err;\n}\n\n \nvoid i40e_down(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\t \n\tif (vsi->netdev) {\n\t\tnetif_carrier_off(vsi->netdev);\n\t\tnetif_tx_disable(vsi->netdev);\n\t}\n\ti40e_vsi_disable_irq(vsi);\n\ti40e_vsi_stop_rings(vsi);\n\tif (vsi->type == I40E_VSI_MAIN &&\n\t   (vsi->back->flags & I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED ||\n\t    vsi->back->flags & I40E_FLAG_TOTAL_PORT_SHUTDOWN_ENABLED))\n\t\ti40e_force_link_state(vsi->back, false);\n\ti40e_napi_disable_all(vsi);\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++) {\n\t\ti40e_clean_tx_ring(vsi->tx_rings[i]);\n\t\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t\t \n\t\t\tsynchronize_rcu();\n\t\t\ti40e_clean_tx_ring(vsi->xdp_rings[i]);\n\t\t}\n\t\ti40e_clean_rx_ring(vsi->rx_rings[i]);\n\t}\n\n}\n\n \nstatic int i40e_validate_mqprio_qopt(struct i40e_vsi *vsi,\n\t\t\t\t     struct tc_mqprio_qopt_offload *mqprio_qopt)\n{\n\tu64 sum_max_rate = 0;\n\tu64 max_rate = 0;\n\tint i;\n\n\tif (mqprio_qopt->qopt.offset[0] != 0 ||\n\t    mqprio_qopt->qopt.num_tc < 1 ||\n\t    mqprio_qopt->qopt.num_tc > I40E_MAX_TRAFFIC_CLASS)\n\t\treturn -EINVAL;\n\tfor (i = 0; ; i++) {\n\t\tif (!mqprio_qopt->qopt.count[i])\n\t\t\treturn -EINVAL;\n\t\tif (mqprio_qopt->min_rate[i]) {\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"Invalid min tx rate (greater than 0) specified\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmax_rate = mqprio_qopt->max_rate[i];\n\t\tdo_div(max_rate, I40E_BW_MBPS_DIVISOR);\n\t\tsum_max_rate += max_rate;\n\n\t\tif (i >= mqprio_qopt->qopt.num_tc - 1)\n\t\t\tbreak;\n\t\tif (mqprio_qopt->qopt.offset[i + 1] !=\n\t\t    (mqprio_qopt->qopt.offset[i] + mqprio_qopt->qopt.count[i]))\n\t\t\treturn -EINVAL;\n\t}\n\tif (vsi->num_queue_pairs <\n\t    (mqprio_qopt->qopt.offset[i] + mqprio_qopt->qopt.count[i])) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Failed to create traffic channel, insufficient number of queues.\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (sum_max_rate > i40e_get_link_speed(vsi)) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Invalid max tx rate specified\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n \nstatic void i40e_vsi_set_default_tc_config(struct i40e_vsi *vsi)\n{\n\tu16 qcount;\n\tint i;\n\n\t \n\tvsi->tc_config.numtc = 1;\n\tvsi->tc_config.enabled_tc = 1;\n\tqcount = min_t(int, vsi->alloc_queue_pairs,\n\t\t       i40e_pf_get_max_q_per_tc(vsi->back));\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\t \n\t\tvsi->tc_config.tc_info[i].qoffset = 0;\n\t\tif (i == 0)\n\t\t\tvsi->tc_config.tc_info[i].qcount = qcount;\n\t\telse\n\t\t\tvsi->tc_config.tc_info[i].qcount = 1;\n\t\tvsi->tc_config.tc_info[i].netdev_tc = 0;\n\t}\n}\n\n \nstatic int i40e_del_macvlan_filter(struct i40e_hw *hw, u16 seid,\n\t\t\t\t   const u8 *macaddr, int *aq_err)\n{\n\tstruct i40e_aqc_remove_macvlan_element_data element;\n\tint status;\n\n\tmemset(&element, 0, sizeof(element));\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\telement.flags = I40E_AQC_MACVLAN_DEL_PERFECT_MATCH;\n\tstatus = i40e_aq_remove_macvlan(hw, seid, &element, 1, NULL);\n\t*aq_err = hw->aq.asq_last_status;\n\n\treturn status;\n}\n\n \nstatic int i40e_add_macvlan_filter(struct i40e_hw *hw, u16 seid,\n\t\t\t\t   const u8 *macaddr, int *aq_err)\n{\n\tstruct i40e_aqc_add_macvlan_element_data element;\n\tu16 cmd_flags = 0;\n\tint status;\n\n\tether_addr_copy(element.mac_addr, macaddr);\n\telement.vlan_tag = 0;\n\telement.queue_number = 0;\n\telement.match_method = I40E_AQC_MM_ERR_NO_RES;\n\tcmd_flags |= I40E_AQC_MACVLAN_ADD_PERFECT_MATCH;\n\telement.flags = cpu_to_le16(cmd_flags);\n\tstatus = i40e_aq_add_macvlan(hw, seid, &element, 1, NULL);\n\t*aq_err = hw->aq.asq_last_status;\n\n\treturn status;\n}\n\n \nstatic void i40e_reset_ch_rings(struct i40e_vsi *vsi, struct i40e_channel *ch)\n{\n\tstruct i40e_ring *tx_ring, *rx_ring;\n\tu16 pf_q;\n\tint i;\n\n\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\tpf_q = ch->base_queue + i;\n\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\ttx_ring->ch = NULL;\n\t\trx_ring = vsi->rx_rings[pf_q];\n\t\trx_ring->ch = NULL;\n\t}\n}\n\n \nstatic void i40e_free_macvlan_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tint ret;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tstruct i40e_vsi *parent_vsi;\n\n\t\tif (i40e_is_channel_macvlan(ch)) {\n\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\tnetdev_unbind_sb_channel(vsi->netdev, ch->fwd->netdev);\n\t\t\tnetdev_set_sb_channel(ch->fwd->netdev, 0);\n\t\t\tkfree(ch->fwd);\n\t\t\tch->fwd = NULL;\n\t\t}\n\n\t\tlist_del(&ch->list);\n\t\tparent_vsi = ch->parent_vsi;\n\t\tif (!parent_vsi || !ch->initialized) {\n\t\t\tkfree(ch);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tret = i40e_aq_delete_element(&vsi->back->hw, ch->seid,\n\t\t\t\t\t     NULL);\n\t\tif (ret)\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"unable to remove channel (%d) for parent VSI(%d)\\n\",\n\t\t\t\tch->seid, parent_vsi->seid);\n\t\tkfree(ch);\n\t}\n\tvsi->macvlan_cnt = 0;\n}\n\n \nstatic int i40e_fwd_ring_up(struct i40e_vsi *vsi, struct net_device *vdev,\n\t\t\t    struct i40e_fwd_adapter *fwd)\n{\n\tstruct i40e_channel *ch = NULL, *ch_tmp, *iter;\n\tint ret = 0, num_tc = 1,  i, aq_err;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t \n\tlist_for_each_entry_safe(iter, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (!i40e_is_channel_macvlan(iter)) {\n\t\t\titer->fwd = fwd;\n\t\t\t \n\t\t\tfor (i = 0; i < num_tc; i++)\n\t\t\t\tnetdev_bind_sb_channel_queue(vsi->netdev, vdev,\n\t\t\t\t\t\t\t     i,\n\t\t\t\t\t\t\t     iter->num_queue_pairs,\n\t\t\t\t\t\t\t     iter->base_queue);\n\t\t\tfor (i = 0; i < iter->num_queue_pairs; i++) {\n\t\t\t\tstruct i40e_ring *tx_ring, *rx_ring;\n\t\t\t\tu16 pf_q;\n\n\t\t\t\tpf_q = iter->base_queue + i;\n\n\t\t\t\t \n\t\t\t\ttx_ring = vsi->tx_rings[pf_q];\n\t\t\t\ttx_ring->ch = iter;\n\n\t\t\t\t \n\t\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\t\trx_ring->ch = iter;\n\t\t\t}\n\t\t\tch = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!ch)\n\t\treturn -EINVAL;\n\n\t \n\twmb();\n\n\t \n\tret = i40e_add_macvlan_filter(hw, ch->seid, vdev->dev_addr, &aq_err);\n\tif (ret) {\n\t\t \n\t\tmacvlan_release_l2fw_offload(vdev);\n\t\tfor (i = 0; i < ch->num_queue_pairs; i++) {\n\t\t\tstruct i40e_ring *rx_ring;\n\t\t\tu16 pf_q;\n\n\t\t\tpf_q = ch->base_queue + i;\n\t\t\trx_ring = vsi->rx_rings[pf_q];\n\t\t\trx_ring->netdev = NULL;\n\t\t}\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Error adding mac filter on macvlan err %pe, aq_err %s\\n\",\n\t\t\t  ERR_PTR(ret),\n\t\t\t  i40e_aq_str(hw, aq_err));\n\t\tnetdev_err(vdev, \"L2fwd offload disabled to L2 filter error\\n\");\n\t}\n\n\treturn ret;\n}\n\n \nstatic int i40e_setup_macvlans(struct i40e_vsi *vsi, u16 macvlan_cnt, u16 qcnt,\n\t\t\t       struct net_device *vdev)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tu16 sections, qmap, num_qps;\n\tstruct i40e_channel *ch;\n\tint i, pow, ret = 0;\n\tu8 offset = 0;\n\n\tif (vsi->type != I40E_VSI_MAIN || !macvlan_cnt)\n\t\treturn -EINVAL;\n\n\tnum_qps = vsi->num_queue_pairs - (macvlan_cnt * qcnt);\n\n\t \n\tpow = fls(roundup_pow_of_two(num_qps) - 1);\n\n\tqmap = (offset << I40E_AQ_VSI_TC_QUE_OFFSET_SHIFT) |\n\t\t(pow << I40E_AQ_VSI_TC_QUE_NUMBER_SHIFT);\n\n\t \n\tsections = I40E_AQ_VSI_PROP_QUEUE_MAP_VALID;\n\tsections |= I40E_AQ_VSI_PROP_SCHED_VALID;\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tctxt.seid = vsi->seid;\n\tctxt.pf_num = vsi->back->hw.pf_id;\n\tctxt.vf_num = 0;\n\tctxt.uplink_seid = vsi->uplink_seid;\n\tctxt.info = vsi->info;\n\tctxt.info.tc_mapping[0] = cpu_to_le16(qmap);\n\tctxt.info.mapping_flags |= cpu_to_le16(I40E_AQ_VSI_QUE_MAP_CONTIG);\n\tctxt.info.queue_mapping[0] = cpu_to_le16(vsi->base_queue);\n\tctxt.info.valid_sections |= cpu_to_le16(sections);\n\n\t \n\tvsi->rss_size = max_t(u16, num_qps, qcnt);\n\tret = i40e_vsi_config_rss(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Failed to reconfig RSS for num_queues (%u)\\n\",\n\t\t\t vsi->rss_size);\n\t\treturn ret;\n\t}\n\tvsi->reconfig_rss = true;\n\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\"Reconfigured RSS with num_queues (%u)\\n\", vsi->rss_size);\n\tvsi->next_base_queue = num_qps;\n\tvsi->cnt_q_avail = vsi->num_queue_pairs - num_qps;\n\n\t \n\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Update vsi tc config failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn ret;\n\t}\n\t \n\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\tvsi->info.valid_sections = 0;\n\n\t \n\tINIT_LIST_HEAD(&vsi->macvlan_list);\n\tfor (i = 0; i < macvlan_cnt; i++) {\n\t\tch = kzalloc(sizeof(*ch), GFP_KERNEL);\n\t\tif (!ch) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free;\n\t\t}\n\t\tINIT_LIST_HEAD(&ch->list);\n\t\tch->num_queue_pairs = qcnt;\n\t\tif (!i40e_setup_channel(pf, vsi, ch)) {\n\t\t\tret = -EINVAL;\n\t\t\tkfree(ch);\n\t\t\tgoto err_free;\n\t\t}\n\t\tch->parent_vsi = vsi;\n\t\tvsi->cnt_q_avail -= ch->num_queue_pairs;\n\t\tvsi->macvlan_cnt++;\n\t\tlist_add_tail(&ch->list, &vsi->macvlan_list);\n\t}\n\n\treturn ret;\n\nerr_free:\n\tdev_info(&pf->pdev->dev, \"Failed to setup macvlans\\n\");\n\ti40e_free_macvlan_channels(vsi);\n\n\treturn ret;\n}\n\n \nstatic void *i40e_fwd_add(struct net_device *netdev, struct net_device *vdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tu16 q_per_macvlan = 0, macvlan_cnt = 0, vectors;\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_fwd_adapter *fwd;\n\tint avail_macvlan, ret;\n\n\tif ((pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\tnetdev_info(netdev, \"Macvlans are not supported when DCB is enabled\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif (i40e_is_tc_mqprio_enabled(pf)) {\n\t\tnetdev_info(netdev, \"Macvlans are not supported when HW TC offload is on\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif (pf->num_lan_msix < I40E_MIN_MACVLAN_VECTORS) {\n\t\tnetdev_info(netdev, \"Not enough vectors available to support macvlans\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\t \n\tif (netif_is_multiqueue(vdev))\n\t\treturn ERR_PTR(-ERANGE);\n\n\tif (!vsi->macvlan_cnt) {\n\t\t \n\t\tset_bit(0, vsi->fwd_bitmask);\n\n\t\t \n\t\tvectors = pf->num_lan_msix;\n\t\tif (vectors <= I40E_MAX_MACVLANS && vectors > 64) {\n\t\t\t \n\t\t\tq_per_macvlan = 4;\n\t\t\tmacvlan_cnt = (vectors - 32) / 4;\n\t\t} else if (vectors <= 64 && vectors > 32) {\n\t\t\t \n\t\t\tq_per_macvlan = 2;\n\t\t\tmacvlan_cnt = (vectors - 16) / 2;\n\t\t} else if (vectors <= 32 && vectors > 16) {\n\t\t\t \n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 16;\n\t\t} else if (vectors <= 16 && vectors > 8) {\n\t\t\t \n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 8;\n\t\t} else {\n\t\t\t \n\t\t\tq_per_macvlan = 1;\n\t\t\tmacvlan_cnt = vectors - 1;\n\t\t}\n\n\t\tif (macvlan_cnt == 0)\n\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\t \n\t\ti40e_quiesce_vsi(vsi);\n\n\t\t \n\t\tret = i40e_setup_macvlans(vsi, macvlan_cnt, q_per_macvlan,\n\t\t\t\t\t  vdev);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\n\t\t \n\t\ti40e_unquiesce_vsi(vsi);\n\t}\n\tavail_macvlan = find_first_zero_bit(vsi->fwd_bitmask,\n\t\t\t\t\t    vsi->macvlan_cnt);\n\tif (avail_macvlan >= I40E_MAX_MACVLANS)\n\t\treturn ERR_PTR(-EBUSY);\n\n\t \n\tfwd = kzalloc(sizeof(*fwd), GFP_KERNEL);\n\tif (!fwd)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tset_bit(avail_macvlan, vsi->fwd_bitmask);\n\tfwd->bit_no = avail_macvlan;\n\tnetdev_set_sb_channel(vdev, avail_macvlan);\n\tfwd->netdev = vdev;\n\n\tif (!netif_running(netdev))\n\t\treturn fwd;\n\n\t \n\tret = i40e_fwd_ring_up(vsi, vdev, fwd);\n\tif (ret) {\n\t\t \n\t\tnetdev_unbind_sb_channel(netdev, vdev);\n\t\tnetdev_set_sb_channel(vdev, 0);\n\n\t\tkfree(fwd);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\treturn fwd;\n}\n\n \nstatic void i40e_del_all_macvlans(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint aq_err, ret = 0;\n\n\tif (list_empty(&vsi->macvlan_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (i40e_is_channel_macvlan(ch)) {\n\t\t\tret = i40e_del_macvlan_filter(hw, ch->seid,\n\t\t\t\t\t\t      i40e_channel_mac(ch),\n\t\t\t\t\t\t      &aq_err);\n\t\t\tif (!ret) {\n\t\t\t\t \n\t\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\t\tnetdev_unbind_sb_channel(vsi->netdev,\n\t\t\t\t\t\t\t ch->fwd->netdev);\n\t\t\t\tnetdev_set_sb_channel(ch->fwd->netdev, 0);\n\t\t\t\tkfree(ch->fwd);\n\t\t\t\tch->fwd = NULL;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic void i40e_fwd_del(struct net_device *netdev, void *vdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_fwd_adapter *fwd = vdev;\n\tstruct i40e_channel *ch, *ch_tmp;\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint aq_err, ret = 0;\n\n\t \n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->macvlan_list, list) {\n\t\tif (i40e_is_channel_macvlan(ch) &&\n\t\t    ether_addr_equal(i40e_channel_mac(ch),\n\t\t\t\t     fwd->netdev->dev_addr)) {\n\t\t\tret = i40e_del_macvlan_filter(hw, ch->seid,\n\t\t\t\t\t\t      i40e_channel_mac(ch),\n\t\t\t\t\t\t      &aq_err);\n\t\t\tif (!ret) {\n\t\t\t\t \n\t\t\t\ti40e_reset_ch_rings(vsi, ch);\n\t\t\t\tclear_bit(ch->fwd->bit_no, vsi->fwd_bitmask);\n\t\t\t\tnetdev_unbind_sb_channel(netdev, fwd->netdev);\n\t\t\t\tnetdev_set_sb_channel(fwd->netdev, 0);\n\t\t\t\tkfree(ch->fwd);\n\t\t\t\tch->fwd = NULL;\n\t\t\t} else {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"Error deleting mac filter on macvlan err %pe, aq_err %s\\n\",\n\t\t\t\t\t  ERR_PTR(ret),\n\t\t\t\t\t  i40e_aq_str(hw, aq_err));\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nstatic int i40e_setup_tc(struct net_device *netdev, void *type_data)\n{\n\tstruct tc_mqprio_qopt_offload *mqprio_qopt = type_data;\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 enabled_tc = 0, num_tc, hw;\n\tbool need_reset = false;\n\tint old_queue_pairs;\n\tint ret = -EINVAL;\n\tu16 mode;\n\tint i;\n\n\told_queue_pairs = vsi->num_queue_pairs;\n\tnum_tc = mqprio_qopt->qopt.num_tc;\n\thw = mqprio_qopt->qopt.hw;\n\tmode = mqprio_qopt->mode;\n\tif (!hw) {\n\t\tpf->flags &= ~I40E_FLAG_TC_MQPRIO;\n\t\tmemcpy(&vsi->mqprio_qopt, mqprio_qopt, sizeof(*mqprio_qopt));\n\t\tgoto config_tc;\n\t}\n\n\t \n\tif (pf->flags & I40E_FLAG_MFP_ENABLED) {\n\t\tnetdev_info(netdev,\n\t\t\t    \"Configuring TC not supported in MFP mode\\n\");\n\t\treturn ret;\n\t}\n\tswitch (mode) {\n\tcase TC_MQPRIO_MODE_DCB:\n\t\tpf->flags &= ~I40E_FLAG_TC_MQPRIO;\n\n\t\t \n\t\tif (!(pf->flags & I40E_FLAG_DCB_ENABLED)) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"DCB is not enabled for adapter\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tif (num_tc > i40e_pf_get_num_tc(pf)) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"TC count greater than enabled on link for adapter\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\tcase TC_MQPRIO_MODE_CHANNEL:\n\t\tif (pf->flags & I40E_FLAG_DCB_ENABLED) {\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"Full offload of TC Mqprio options is not supported when DCB is enabled\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\t\treturn ret;\n\t\tret = i40e_validate_mqprio_qopt(vsi, mqprio_qopt);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tmemcpy(&vsi->mqprio_qopt, mqprio_qopt,\n\t\t       sizeof(*mqprio_qopt));\n\t\tpf->flags |= I40E_FLAG_TC_MQPRIO;\n\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nconfig_tc:\n\t \n\tfor (i = 0; i < num_tc; i++)\n\t\tenabled_tc |= BIT(i);\n\n\t \n\tif (enabled_tc == vsi->tc_config.enabled_tc &&\n\t    mode != TC_MQPRIO_MODE_CHANNEL)\n\t\treturn 0;\n\n\t \n\ti40e_quiesce_vsi(vsi);\n\n\tif (!hw && !i40e_is_tc_mqprio_enabled(pf))\n\t\ti40e_remove_queue_channels(vsi);\n\n\t \n\tret = i40e_vsi_config_tc(vsi, enabled_tc);\n\tif (ret) {\n\t\tnetdev_info(netdev, \"Failed configuring TC for VSI seid=%d\\n\",\n\t\t\t    vsi->seid);\n\t\tneed_reset = true;\n\t\tgoto exit;\n\t} else if (enabled_tc &&\n\t\t   (!is_power_of_2(vsi->tc_config.tc_info[0].qcount))) {\n\t\tnetdev_info(netdev,\n\t\t\t    \"Failed to create channel. Override queues (%u) not power of 2\\n\",\n\t\t\t    vsi->tc_config.tc_info[0].qcount);\n\t\tret = -EINVAL;\n\t\tneed_reset = true;\n\t\tgoto exit;\n\t}\n\n\tdev_info(&vsi->back->pdev->dev,\n\t\t \"Setup channel (id:%u) utilizing num_queues %d\\n\",\n\t\t vsi->seid, vsi->tc_config.tc_info[0].qcount);\n\n\tif (i40e_is_tc_mqprio_enabled(pf)) {\n\t\tif (vsi->mqprio_qopt.max_rate[0]) {\n\t\t\tu64 max_tx_rate = i40e_bw_bytes_to_mbits(vsi,\n\t\t\t\t\t\t  vsi->mqprio_qopt.max_rate[0]);\n\n\t\t\tret = i40e_set_bw_limit(vsi, vsi->seid, max_tx_rate);\n\t\t\tif (!ret) {\n\t\t\t\tu64 credits = max_tx_rate;\n\n\t\t\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\t\t\tmax_tx_rate,\n\t\t\t\t\tcredits,\n\t\t\t\t\tvsi->seid);\n\t\t\t} else {\n\t\t\t\tneed_reset = true;\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tret = i40e_configure_queue_channels(vsi);\n\t\tif (ret) {\n\t\t\tvsi->num_queue_pairs = old_queue_pairs;\n\t\t\tnetdev_info(netdev,\n\t\t\t\t    \"Failed configuring queue channels\\n\");\n\t\t\tneed_reset = true;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\nexit:\n\t \n\tif (need_reset) {\n\t\ti40e_vsi_set_default_tc_config(vsi);\n\t\tneed_reset = false;\n\t}\n\n\t \n\ti40e_unquiesce_vsi(vsi);\n\treturn ret;\n}\n\n \nstatic inline void\ni40e_set_cld_element(struct i40e_cloud_filter *filter,\n\t\t     struct i40e_aqc_cloud_filters_element_data *cld)\n{\n\tu32 ipa;\n\tint i;\n\n\tmemset(cld, 0, sizeof(*cld));\n\tether_addr_copy(cld->outer_mac, filter->dst_mac);\n\tether_addr_copy(cld->inner_mac, filter->src_mac);\n\n\tif (filter->n_proto != ETH_P_IP && filter->n_proto != ETH_P_IPV6)\n\t\treturn;\n\n\tif (filter->n_proto == ETH_P_IPV6) {\n#define IPV6_MAX_INDEX\t(ARRAY_SIZE(filter->dst_ipv6) - 1)\n\t\tfor (i = 0; i < ARRAY_SIZE(filter->dst_ipv6); i++) {\n\t\t\tipa = be32_to_cpu(filter->dst_ipv6[IPV6_MAX_INDEX - i]);\n\n\t\t\t*(__le32 *)&cld->ipaddr.raw_v6.data[i * 2] = cpu_to_le32(ipa);\n\t\t}\n\t} else {\n\t\tipa = be32_to_cpu(filter->dst_ipv4);\n\n\t\tmemcpy(&cld->ipaddr.v4.data, &ipa, sizeof(ipa));\n\t}\n\n\tcld->inner_vlan = cpu_to_le16(ntohs(filter->vlan_id));\n\n\t \n\tif (filter->tenant_id)\n\t\treturn;\n}\n\n \nint i40e_add_del_cloud_filter(struct i40e_vsi *vsi,\n\t\t\t      struct i40e_cloud_filter *filter, bool add)\n{\n\tstruct i40e_aqc_cloud_filters_element_data cld_filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tint ret;\n\tstatic const u16 flag_table[128] = {\n\t\t[I40E_CLOUD_FILTER_FLAGS_OMAC]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_OMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_IVLAN]  =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_IVLAN,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_TEN_ID] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_TEN_ID,\n\t\t[I40E_CLOUD_FILTER_FLAGS_OMAC_TEN_ID_IMAC] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_OMAC_TEN_ID_IMAC,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IMAC_IVLAN_TEN_ID] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IMAC_IVLAN_TEN_ID,\n\t\t[I40E_CLOUD_FILTER_FLAGS_IIP] =\n\t\t\tI40E_AQC_ADD_CLOUD_FILTER_IIP,\n\t};\n\n\tif (filter->flags >= ARRAY_SIZE(flag_table))\n\t\treturn -EIO;\n\n\tmemset(&cld_filter, 0, sizeof(cld_filter));\n\n\t \n\ti40e_set_cld_element(filter, &cld_filter);\n\n\tif (filter->tunnel_type != I40E_CLOUD_TNL_TYPE_NONE)\n\t\tcld_filter.flags = cpu_to_le16(filter->tunnel_type <<\n\t\t\t\t\t     I40E_AQC_ADD_CLOUD_TNL_TYPE_SHIFT);\n\n\tif (filter->n_proto == ETH_P_IPV6)\n\t\tcld_filter.flags |= cpu_to_le16(flag_table[filter->flags] |\n\t\t\t\t\t\tI40E_AQC_ADD_CLOUD_FLAGS_IPV6);\n\telse\n\t\tcld_filter.flags |= cpu_to_le16(flag_table[filter->flags] |\n\t\t\t\t\t\tI40E_AQC_ADD_CLOUD_FLAGS_IPV4);\n\n\tif (add)\n\t\tret = i40e_aq_add_cloud_filters(&pf->hw, filter->seid,\n\t\t\t\t\t\t&cld_filter, 1);\n\telse\n\t\tret = i40e_aq_rem_cloud_filters(&pf->hw, filter->seid,\n\t\t\t\t\t\t&cld_filter, 1);\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Failed to %s cloud filter using l4 port %u, err %d aq_err %d\\n\",\n\t\t\tadd ? \"add\" : \"delete\", filter->dst_port, ret,\n\t\t\tpf->hw.aq.asq_last_status);\n\telse\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"%s cloud filter for VSI: %d\\n\",\n\t\t\t add ? \"Added\" : \"Deleted\", filter->seid);\n\treturn ret;\n}\n\n \nint i40e_add_del_cloud_filter_big_buf(struct i40e_vsi *vsi,\n\t\t\t\t      struct i40e_cloud_filter *filter,\n\t\t\t\t      bool add)\n{\n\tstruct i40e_aqc_cloud_filters_element_bb cld_filter;\n\tstruct i40e_pf *pf = vsi->back;\n\tint ret;\n\n\t \n\tif ((is_valid_ether_addr(filter->dst_mac) &&\n\t     is_valid_ether_addr(filter->src_mac)) ||\n\t    (is_multicast_ether_addr(filter->dst_mac) &&\n\t     is_multicast_ether_addr(filter->src_mac)))\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (!filter->dst_port || filter->ip_proto == IPPROTO_UDP)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (filter->src_port ||\n\t    (filter->src_ipv4 && filter->n_proto != ETH_P_IPV6) ||\n\t    !ipv6_addr_any(&filter->ip.v6.src_ip6))\n\t\treturn -EOPNOTSUPP;\n\n\tmemset(&cld_filter, 0, sizeof(cld_filter));\n\n\t \n\ti40e_set_cld_element(filter, &cld_filter.element);\n\n\tif (is_valid_ether_addr(filter->dst_mac) ||\n\t    is_valid_ether_addr(filter->src_mac) ||\n\t    is_multicast_ether_addr(filter->dst_mac) ||\n\t    is_multicast_ether_addr(filter->src_mac)) {\n\t\t \n\t\tif (filter->dst_ipv4)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t \n\t\tcld_filter.element.flags =\n\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_MAC_PORT);\n\n\t\tif (filter->vlan_id) {\n\t\t\tcld_filter.element.flags =\n\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_MAC_VLAN_PORT);\n\t\t}\n\n\t} else if ((filter->dst_ipv4 && filter->n_proto != ETH_P_IPV6) ||\n\t\t   !ipv6_addr_any(&filter->ip.v6.dst_ip6)) {\n\t\tcld_filter.element.flags =\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FILTER_IP_PORT);\n\t\tif (filter->n_proto == ETH_P_IPV6)\n\t\t\tcld_filter.element.flags |=\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FLAGS_IPV6);\n\t\telse\n\t\t\tcld_filter.element.flags |=\n\t\t\t\tcpu_to_le16(I40E_AQC_ADD_CLOUD_FLAGS_IPV4);\n\t} else {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"either mac or ip has to be valid for cloud filter\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tcld_filter.general_fields[I40E_AQC_ADD_CLOUD_FV_FLU_0X16_WORD0] =\n\t\t\t\t\t\tbe16_to_cpu(filter->dst_port);\n\n\tif (add) {\n\t\t \n\t\tret = i40e_validate_and_set_switch_mode(vsi);\n\t\tif (ret) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"failed to set switch mode, ret %d\\n\",\n\t\t\t\tret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = i40e_aq_add_cloud_filters_bb(&pf->hw, filter->seid,\n\t\t\t\t\t\t   &cld_filter, 1);\n\t} else {\n\t\tret = i40e_aq_rem_cloud_filters_bb(&pf->hw, filter->seid,\n\t\t\t\t\t\t   &cld_filter, 1);\n\t}\n\n\tif (ret)\n\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\"Failed to %s cloud filter(big buffer) err %d aq_err %d\\n\",\n\t\t\tadd ? \"add\" : \"delete\", ret, pf->hw.aq.asq_last_status);\n\telse\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"%s cloud filter for VSI: %d, L4 port: %d\\n\",\n\t\t\t add ? \"add\" : \"delete\", filter->seid,\n\t\t\t ntohs(filter->dst_port));\n\treturn ret;\n}\n\n \nstatic int i40e_parse_cls_flower(struct i40e_vsi *vsi,\n\t\t\t\t struct flow_cls_offload *f,\n\t\t\t\t struct i40e_cloud_filter *filter)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tu16 n_proto_mask = 0, n_proto_key = 0, addr_type = 0;\n\tstruct i40e_pf *pf = vsi->back;\n\tu8 field_flags = 0;\n\n\tif (dissector->used_keys &\n\t    ~(BIT_ULL(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ETH_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_VLAN) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_PORTS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ENC_KEYID))) {\n\t\tdev_err(&pf->pdev->dev, \"Unsupported key used: 0x%llx\\n\",\n\t\t\tdissector->used_keys);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_KEYID)) {\n\t\tstruct flow_match_enc_keyid match;\n\n\t\tflow_rule_match_enc_keyid(rule, &match);\n\t\tif (match.mask->keyid != 0)\n\t\t\tfield_flags |= I40E_CLOUD_FIELD_TEN_ID;\n\n\t\tfilter->tenant_id = be32_to_cpu(match.key->keyid);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tn_proto_key = ntohs(match.key->n_proto);\n\t\tn_proto_mask = ntohs(match.mask->n_proto);\n\n\t\tif (n_proto_key == ETH_P_ALL) {\n\t\t\tn_proto_key = 0;\n\t\t\tn_proto_mask = 0;\n\t\t}\n\t\tfilter->n_proto = n_proto_key & n_proto_mask;\n\t\tfilter->ip_proto = match.key->ip_proto;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct flow_match_eth_addrs match;\n\n\t\tflow_rule_match_eth_addrs(rule, &match);\n\n\t\t \n\t\tif (!is_zero_ether_addr(match.mask->dst)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->dst)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_OMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ether dest mask %pM\\n\",\n\t\t\t\t\tmatch.mask->dst);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tif (!is_zero_ether_addr(match.mask->src)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->src)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ether src mask %pM\\n\",\n\t\t\t\t\tmatch.mask->src);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t\tether_addr_copy(filter->dst_mac, match.key->dst);\n\t\tether_addr_copy(filter->src_mac, match.key->src);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {\n\t\tstruct flow_match_vlan match;\n\n\t\tflow_rule_match_vlan(rule, &match);\n\t\tif (match.mask->vlan_id) {\n\t\t\tif (match.mask->vlan_id == VLAN_VID_MASK) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IVLAN;\n\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad vlan mask 0x%04x\\n\",\n\t\t\t\t\tmatch.mask->vlan_id);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tfilter->vlan_id = cpu_to_be16(match.key->vlan_id);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {\n\t\tstruct flow_match_control match;\n\n\t\tflow_rule_match_control(rule, &match);\n\t\taddr_type = match.key->addr_type;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\n\t\tstruct flow_match_ipv4_addrs match;\n\n\t\tflow_rule_match_ipv4_addrs(rule, &match);\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ip dst mask %pI4b\\n\",\n\t\t\t\t\t&match.mask->dst);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad ip src mask %pI4b\\n\",\n\t\t\t\t\t&match.mask->src);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tif (field_flags & I40E_CLOUD_FIELD_TEN_ID) {\n\t\t\tdev_err(&pf->pdev->dev, \"Tenant id not allowed for ip filter\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tfilter->dst_ipv4 = match.key->dst;\n\t\tfilter->src_ipv4 = match.key->src;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\n\t\tstruct flow_match_ipv6_addrs match;\n\n\t\tflow_rule_match_ipv6_addrs(rule, &match);\n\n\t\t \n\t\tif (ipv6_addr_loopback(&match.key->dst) ||\n\t\t    ipv6_addr_loopback(&match.key->src)) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Bad ipv6, addr is LOOPBACK\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tif (!ipv6_addr_any(&match.mask->dst) ||\n\t\t    !ipv6_addr_any(&match.mask->src))\n\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\n\t\tmemcpy(&filter->src_ipv6, &match.key->src.s6_addr32,\n\t\t       sizeof(filter->src_ipv6));\n\t\tmemcpy(&filter->dst_ipv6, &match.key->dst.s6_addr32,\n\t\t       sizeof(filter->dst_ipv6));\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS)) {\n\t\tstruct flow_match_ports match;\n\n\t\tflow_rule_match_ports(rule, &match);\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad src port mask 0x%04x\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->src));\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= I40E_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&pf->pdev->dev, \"Bad dst port mask 0x%04x\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->dst));\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tfilter->dst_port = match.key->dst;\n\t\tfilter->src_port = match.key->src;\n\n\t\tswitch (filter->ip_proto) {\n\t\tcase IPPROTO_TCP:\n\t\tcase IPPROTO_UDP:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Only UDP and TCP transport are supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tfilter->flags = field_flags;\n\treturn 0;\n}\n\n \nstatic int i40e_handle_tclass(struct i40e_vsi *vsi, u32 tc,\n\t\t\t      struct i40e_cloud_filter *filter)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\n\t \n\tif (tc == 0) {\n\t\tfilter->seid = vsi->seid;\n\t\treturn 0;\n\t} else if (vsi->tc_config.enabled_tc & BIT(tc)) {\n\t\tif (!filter->dst_port) {\n\t\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\t\"Specify destination port to direct to traffic class that is not default\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (list_empty(&vsi->ch_list))\n\t\t\treturn -EINVAL;\n\t\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list,\n\t\t\t\t\t list) {\n\t\t\tif (ch->seid == vsi->tc_seid_map[tc])\n\t\t\t\tfilter->seid = ch->seid;\n\t\t}\n\t\treturn 0;\n\t}\n\tdev_err(&vsi->back->pdev->dev, \"TC is not enabled\\n\");\n\treturn -EINVAL;\n}\n\n \nstatic int i40e_configure_clsflower(struct i40e_vsi *vsi,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tint tc = tc_classid_to_hwtc(vsi->netdev, cls_flower->classid);\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err = 0;\n\n\tif (tc < 0) {\n\t\tdev_err(&vsi->back->pdev->dev, \"Invalid traffic class\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!tc) {\n\t\tdev_err(&pf->pdev->dev, \"Unable to add filter because of invalid destination\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state) ||\n\t    test_bit(__I40E_RESET_INTR_RECEIVED, pf->state))\n\t\treturn -EBUSY;\n\n\tif (pf->fdir_pf_active_filters ||\n\t    (!hlist_empty(&pf->fdir_filter_list))) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Flow Director Sideband filters exists, turn ntuple off to configure cloud filters\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (vsi->back->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tdev_err(&vsi->back->pdev->dev,\n\t\t\t\"Disable Flow Director Sideband, configuring Cloud filters via tc-flower\\n\");\n\t\tvsi->back->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tvsi->back->flags |= I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t}\n\n\tfilter = kzalloc(sizeof(*filter), GFP_KERNEL);\n\tif (!filter)\n\t\treturn -ENOMEM;\n\n\tfilter->cookie = cls_flower->cookie;\n\n\terr = i40e_parse_cls_flower(vsi, cls_flower, filter);\n\tif (err < 0)\n\t\tgoto err;\n\n\terr = i40e_handle_tclass(vsi, tc, filter);\n\tif (err < 0)\n\t\tgoto err;\n\n\t \n\tif (filter->dst_port)\n\t\terr = i40e_add_del_cloud_filter_big_buf(vsi, filter, true);\n\telse\n\t\terr = i40e_add_del_cloud_filter(vsi, filter, true);\n\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev, \"Failed to add cloud filter, err %d\\n\",\n\t\t\terr);\n\t\tgoto err;\n\t}\n\n\t \n\tINIT_HLIST_NODE(&filter->cloud_node);\n\n\thlist_add_head(&filter->cloud_node, &pf->cloud_filter_list);\n\n\tpf->num_cloud_filters++;\n\n\treturn err;\nerr:\n\tkfree(filter);\n\treturn err;\n}\n\n \nstatic struct i40e_cloud_filter *i40e_find_cloud_filter(struct i40e_vsi *vsi,\n\t\t\t\t\t\t\tunsigned long *cookie)\n{\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct hlist_node *node2;\n\n\thlist_for_each_entry_safe(filter, node2,\n\t\t\t\t  &vsi->back->cloud_filter_list, cloud_node)\n\t\tif (!memcmp(cookie, &filter->cookie, sizeof(filter->cookie)))\n\t\t\treturn filter;\n\treturn NULL;\n}\n\n \nstatic int i40e_delete_clsflower(struct i40e_vsi *vsi,\n\t\t\t\t struct flow_cls_offload *cls_flower)\n{\n\tstruct i40e_cloud_filter *filter = NULL;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err = 0;\n\n\tfilter = i40e_find_cloud_filter(vsi, &cls_flower->cookie);\n\n\tif (!filter)\n\t\treturn -EINVAL;\n\n\thash_del(&filter->cloud_node);\n\n\tif (filter->dst_port)\n\t\terr = i40e_add_del_cloud_filter_big_buf(vsi, filter, false);\n\telse\n\t\terr = i40e_add_del_cloud_filter(vsi, filter, false);\n\n\tkfree(filter);\n\tif (err) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to delete cloud filter, err %pe\\n\",\n\t\t\tERR_PTR(err));\n\t\treturn i40e_aq_rc_to_posix(err, pf->hw.aq.asq_last_status);\n\t}\n\n\tpf->num_cloud_filters--;\n\tif (!pf->num_cloud_filters)\n\t\tif ((pf->flags & I40E_FLAG_FD_SB_TO_CLOUD_FILTER) &&\n\t\t    !(pf->flags & I40E_FLAG_FD_SB_INACTIVE)) {\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t\t}\n\treturn 0;\n}\n\n \nstatic int i40e_setup_tc_cls_flower(struct i40e_netdev_priv *np,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tswitch (cls_flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn i40e_configure_clsflower(vsi, cls_flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn i40e_delete_clsflower(vsi, cls_flower);\n\tcase FLOW_CLS_STATS:\n\t\treturn -EOPNOTSUPP;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int i40e_setup_tc_block_cb(enum tc_setup_type type, void *type_data,\n\t\t\t\t  void *cb_priv)\n{\n\tstruct i40e_netdev_priv *np = cb_priv;\n\n\tif (!tc_cls_can_offload_and_chain0(np->vsi->netdev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\treturn i40e_setup_tc_cls_flower(np, type_data);\n\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic LIST_HEAD(i40e_block_cb_list);\n\nstatic int __i40e_setup_tc(struct net_device *netdev, enum tc_setup_type type,\n\t\t\t   void *type_data)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\n\tswitch (type) {\n\tcase TC_SETUP_QDISC_MQPRIO:\n\t\treturn i40e_setup_tc(netdev, type_data);\n\tcase TC_SETUP_BLOCK:\n\t\treturn flow_block_cb_setup_simple(type_data,\n\t\t\t\t\t\t  &i40e_block_cb_list,\n\t\t\t\t\t\t  i40e_setup_tc_block_cb,\n\t\t\t\t\t\t  np, np, true);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n \nint i40e_open(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tint err;\n\n\t \n\tif (test_bit(__I40E_TESTING, pf->state) ||\n\t    test_bit(__I40E_BAD_EEPROM, pf->state))\n\t\treturn -EBUSY;\n\n\tnetif_carrier_off(netdev);\n\n\tif (i40e_force_link_state(pf, true))\n\t\treturn -EAGAIN;\n\n\terr = i40e_vsi_open(vsi);\n\tif (err)\n\t\treturn err;\n\n\t \n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_F, be32_to_cpu(TCP_FLAG_PSH |\n\t\t\t\t\t\t       TCP_FLAG_FIN) >> 16);\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_M, be32_to_cpu(TCP_FLAG_PSH |\n\t\t\t\t\t\t       TCP_FLAG_FIN |\n\t\t\t\t\t\t       TCP_FLAG_CWR) >> 16);\n\twr32(&pf->hw, I40E_GLLAN_TSOMSK_L, be32_to_cpu(TCP_FLAG_CWR) >> 16);\n\tudp_tunnel_get_rx_info(netdev);\n\n\treturn 0;\n}\n\n \nstatic int i40e_netif_set_realnum_tx_rx_queues(struct i40e_vsi *vsi)\n{\n\tint ret;\n\n\tret = netif_set_real_num_rx_queues(vsi->netdev,\n\t\t\t\t\t   vsi->num_queue_pairs);\n\tif (ret)\n\t\treturn ret;\n\n\treturn netif_set_real_num_tx_queues(vsi->netdev,\n\t\t\t\t\t    vsi->num_queue_pairs);\n}\n\n \nint i40e_vsi_open(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tchar int_name[I40E_INT_NAME_STR_LEN];\n\tint err;\n\n\t \n\terr = i40e_vsi_setup_tx_resources(vsi);\n\tif (err)\n\t\tgoto err_setup_tx;\n\terr = i40e_vsi_setup_rx_resources(vsi);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\terr = i40e_vsi_configure(vsi);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\tif (vsi->netdev) {\n\t\tsnprintf(int_name, sizeof(int_name) - 1, \"%s-%s\",\n\t\t\t dev_driver_string(&pf->pdev->dev), vsi->netdev->name);\n\t\terr = i40e_vsi_request_irq(vsi, int_name);\n\t\tif (err)\n\t\t\tgoto err_setup_rx;\n\n\t\t \n\t\terr = i40e_netif_set_realnum_tx_rx_queues(vsi);\n\t\tif (err)\n\t\t\tgoto err_set_queues;\n\n\t} else if (vsi->type == I40E_VSI_FDIR) {\n\t\tsnprintf(int_name, sizeof(int_name) - 1, \"%s-%s:fdir\",\n\t\t\t dev_driver_string(&pf->pdev->dev),\n\t\t\t dev_name(&pf->pdev->dev));\n\t\terr = i40e_vsi_request_irq(vsi, int_name);\n\t\tif (err)\n\t\t\tgoto err_setup_rx;\n\n\t} else {\n\t\terr = -EINVAL;\n\t\tgoto err_setup_rx;\n\t}\n\n\terr = i40e_up_complete(vsi);\n\tif (err)\n\t\tgoto err_up_complete;\n\n\treturn 0;\n\nerr_up_complete:\n\ti40e_down(vsi);\nerr_set_queues:\n\ti40e_vsi_free_irq(vsi);\nerr_setup_rx:\n\ti40e_vsi_free_rx_resources(vsi);\nerr_setup_tx:\n\ti40e_vsi_free_tx_resources(vsi);\n\tif (vsi == pf->vsi[pf->lan_vsi])\n\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\n\treturn err;\n}\n\n \nstatic void i40e_fdir_filter_exit(struct i40e_pf *pf)\n{\n\tstruct i40e_fdir_filter *filter;\n\tstruct i40e_flex_pit *pit_entry, *tmp;\n\tstruct hlist_node *node2;\n\n\thlist_for_each_entry_safe(filter, node2,\n\t\t\t\t  &pf->fdir_filter_list, fdir_node) {\n\t\thlist_del(&filter->fdir_node);\n\t\tkfree(filter);\n\t}\n\n\tlist_for_each_entry_safe(pit_entry, tmp, &pf->l3_flex_pit_list, list) {\n\t\tlist_del(&pit_entry->list);\n\t\tkfree(pit_entry);\n\t}\n\tINIT_LIST_HEAD(&pf->l3_flex_pit_list);\n\n\tlist_for_each_entry_safe(pit_entry, tmp, &pf->l4_flex_pit_list, list) {\n\t\tlist_del(&pit_entry->list);\n\t\tkfree(pit_entry);\n\t}\n\tINIT_LIST_HEAD(&pf->l4_flex_pit_list);\n\n\tpf->fdir_pf_active_filters = 0;\n\ti40e_reset_fdir_filter_cnt(pf);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_TCP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV6_TCP,\n\t\t\t\tI40E_L3_V6_SRC_MASK | I40E_L3_V6_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_UDP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV6_UDP,\n\t\t\t\tI40E_L3_V6_SRC_MASK | I40E_L3_V6_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_SCTP,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV6_SCTP,\n\t\t\t\tI40E_L3_V6_SRC_MASK | I40E_L3_V6_DST_MASK |\n\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_OTHER,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_FRAG_IPV4,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n\n\t \n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV6_OTHER,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n\n\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_FRAG_IPV6,\n\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK);\n}\n\n \nstatic void i40e_cloud_filter_exit(struct i40e_pf *pf)\n{\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct hlist_node *node;\n\n\thlist_for_each_entry_safe(cfilter, node,\n\t\t\t\t  &pf->cloud_filter_list, cloud_node) {\n\t\thlist_del(&cfilter->cloud_node);\n\t\tkfree(cfilter);\n\t}\n\tpf->num_cloud_filters = 0;\n\n\tif ((pf->flags & I40E_FLAG_FD_SB_TO_CLOUD_FILTER) &&\n\t    !(pf->flags & I40E_FLAG_FD_SB_INACTIVE)) {\n\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_TO_CLOUD_FILTER;\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t}\n}\n\n \nint i40e_close(struct net_device *netdev)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\ti40e_vsi_close(vsi);\n\n\treturn 0;\n}\n\n \nvoid i40e_do_reset(struct i40e_pf *pf, u32 reset_flags, bool lock_acquired)\n{\n\tu32 val;\n\n\t \n\tif (reset_flags & BIT_ULL(__I40E_GLOBAL_RESET_REQUESTED)) {\n\n\t\t \n\t\tdev_dbg(&pf->pdev->dev, \"GlobalR requested\\n\");\n\t\tval = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tval |= I40E_GLGEN_RTRIG_GLOBR_MASK;\n\t\twr32(&pf->hw, I40E_GLGEN_RTRIG, val);\n\n\t} else if (reset_flags & BIT_ULL(__I40E_CORE_RESET_REQUESTED)) {\n\n\t\t \n\t\tdev_dbg(&pf->pdev->dev, \"CoreR requested\\n\");\n\t\tval = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tval |= I40E_GLGEN_RTRIG_CORER_MASK;\n\t\twr32(&pf->hw, I40E_GLGEN_RTRIG, val);\n\t\ti40e_flush(&pf->hw);\n\n\t} else if (reset_flags & I40E_PF_RESET_FLAG) {\n\n\t\t \n\t\tdev_dbg(&pf->pdev->dev, \"PFR requested\\n\");\n\t\ti40e_handle_reset_warning(pf, lock_acquired);\n\n\t} else if (reset_flags & I40E_PF_RESET_AND_REBUILD_FLAG) {\n\t\t \n\t\ti40e_prep_for_reset(pf);\n\t\ti40e_reset_and_rebuild(pf, true, lock_acquired);\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t pf->flags & I40E_FLAG_DISABLE_FW_LLDP ?\n\t\t\t \"FW LLDP is disabled\\n\" :\n\t\t\t \"FW LLDP is enabled\\n\");\n\n\t} else if (reset_flags & BIT_ULL(__I40E_REINIT_REQUESTED)) {\n\t\tint v;\n\n\t\t \n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI reinit requested\\n\");\n\t\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tif (vsi != NULL &&\n\t\t\t    test_and_clear_bit(__I40E_VSI_REINIT_REQUESTED,\n\t\t\t\t\t       vsi->state))\n\t\t\t\ti40e_vsi_reinit_locked(pf->vsi[v]);\n\t\t}\n\t} else if (reset_flags & BIT_ULL(__I40E_DOWN_REQUESTED)) {\n\t\tint v;\n\n\t\t \n\t\tdev_info(&pf->pdev->dev, \"VSI down requested\\n\");\n\t\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tif (vsi != NULL &&\n\t\t\t    test_and_clear_bit(__I40E_VSI_DOWN_REQUESTED,\n\t\t\t\t\t       vsi->state)) {\n\t\t\t\tset_bit(__I40E_VSI_DOWN, vsi->state);\n\t\t\t\ti40e_down(vsi);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"bad reset request 0x%08x\\n\", reset_flags);\n\t}\n}\n\n#ifdef CONFIG_I40E_DCB\n \nbool i40e_dcb_need_reconfig(struct i40e_pf *pf,\n\t\t\t    struct i40e_dcbx_config *old_cfg,\n\t\t\t    struct i40e_dcbx_config *new_cfg)\n{\n\tbool need_reconfig = false;\n\n\t \n\tif (memcmp(&new_cfg->etscfg,\n\t\t   &old_cfg->etscfg,\n\t\t   sizeof(new_cfg->etscfg))) {\n\t\t \n\t\tif (memcmp(&new_cfg->etscfg.prioritytable,\n\t\t\t   &old_cfg->etscfg.prioritytable,\n\t\t\t   sizeof(new_cfg->etscfg.prioritytable))) {\n\t\t\tneed_reconfig = true;\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS UP2TC changed.\\n\");\n\t\t}\n\n\t\tif (memcmp(&new_cfg->etscfg.tcbwtable,\n\t\t\t   &old_cfg->etscfg.tcbwtable,\n\t\t\t   sizeof(new_cfg->etscfg.tcbwtable)))\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS TC BW Table changed.\\n\");\n\n\t\tif (memcmp(&new_cfg->etscfg.tsatable,\n\t\t\t   &old_cfg->etscfg.tsatable,\n\t\t\t   sizeof(new_cfg->etscfg.tsatable)))\n\t\t\tdev_dbg(&pf->pdev->dev, \"ETS TSA Table changed.\\n\");\n\t}\n\n\t \n\tif (memcmp(&new_cfg->pfc,\n\t\t   &old_cfg->pfc,\n\t\t   sizeof(new_cfg->pfc))) {\n\t\tneed_reconfig = true;\n\t\tdev_dbg(&pf->pdev->dev, \"PFC config change detected.\\n\");\n\t}\n\n\t \n\tif (memcmp(&new_cfg->app,\n\t\t   &old_cfg->app,\n\t\t   sizeof(new_cfg->app))) {\n\t\tneed_reconfig = true;\n\t\tdev_dbg(&pf->pdev->dev, \"APP Table change detected.\\n\");\n\t}\n\n\tdev_dbg(&pf->pdev->dev, \"dcb need_reconfig=%d\\n\", need_reconfig);\n\treturn need_reconfig;\n}\n\n \nstatic int i40e_handle_lldp_event(struct i40e_pf *pf,\n\t\t\t\t  struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_lldp_get_mib *mib =\n\t\t(struct i40e_aqc_lldp_get_mib *)&e->desc.params.raw;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_dcbx_config tmp_dcbx_cfg;\n\tbool need_reconfig = false;\n\tint ret = 0;\n\tu8 type;\n\n\t \n\tif (I40E_IS_X710TL_DEVICE(hw->device_id) &&\n\t    (hw->phy.link_info.link_speed &\n\t     ~(I40E_LINK_SPEED_2_5GB | I40E_LINK_SPEED_5GB)) &&\n\t     !(pf->flags & I40E_FLAG_DCB_CAPABLE))\n\t\t \n\t\tpf->flags |= I40E_FLAG_DCB_CAPABLE;\n\n\t \n\tif (!(pf->flags & I40E_FLAG_DCB_CAPABLE))\n\t\treturn ret;\n\n\t \n\ttype = ((mib->type >> I40E_AQ_LLDP_BRIDGE_TYPE_SHIFT)\n\t\t& I40E_AQ_LLDP_BRIDGE_TYPE_MASK);\n\tdev_dbg(&pf->pdev->dev, \"LLDP event mib bridge type 0x%x\\n\", type);\n\tif (type != I40E_AQ_LLDP_BRIDGE_TYPE_NEAREST_BRIDGE)\n\t\treturn ret;\n\n\t \n\ttype = mib->type & I40E_AQ_LLDP_MIB_TYPE_MASK;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"LLDP event mib type %s\\n\", type ? \"remote\" : \"local\");\n\tif (type == I40E_AQ_LLDP_MIB_REMOTE) {\n\t\t \n\t\tret = i40e_aq_get_dcb_config(hw, I40E_AQ_LLDP_MIB_REMOTE,\n\t\t\t\tI40E_AQ_LLDP_BRIDGE_TYPE_NEAREST_BRIDGE,\n\t\t\t\t&hw->remote_dcbx_config);\n\t\tgoto exit;\n\t}\n\n\t \n\ttmp_dcbx_cfg = hw->local_dcbx_config;\n\n\t \n\tmemset(&hw->local_dcbx_config, 0, sizeof(hw->local_dcbx_config));\n\t \n\tret = i40e_get_dcb_config(&pf->hw);\n\tif (ret) {\n\t\t \n\t\tif (I40E_IS_X710TL_DEVICE(hw->device_id) &&\n\t\t    (hw->phy.link_info.link_speed &\n\t\t     (I40E_LINK_SPEED_2_5GB | I40E_LINK_SPEED_5GB))) {\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"DCB is not supported for X710-T*L 2.5/5G speeds\\n\");\n\t\t\tpf->flags &= ~I40E_FLAG_DCB_CAPABLE;\n\t\t} else {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Failed querying DCB configuration data from firmware, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t}\n\t\tgoto exit;\n\t}\n\n\t \n\tif (!memcmp(&tmp_dcbx_cfg, &hw->local_dcbx_config,\n\t\t    sizeof(tmp_dcbx_cfg))) {\n\t\tdev_dbg(&pf->pdev->dev, \"No change detected in DCBX configuration.\\n\");\n\t\tgoto exit;\n\t}\n\n\tneed_reconfig = i40e_dcb_need_reconfig(pf, &tmp_dcbx_cfg,\n\t\t\t\t\t       &hw->local_dcbx_config);\n\n\ti40e_dcbnl_flush_apps(pf, &tmp_dcbx_cfg, &hw->local_dcbx_config);\n\n\tif (!need_reconfig)\n\t\tgoto exit;\n\n\t \n\tif (i40e_dcb_get_num_tc(&hw->local_dcbx_config) > 1)\n\t\tpf->flags |= I40E_FLAG_DCB_ENABLED;\n\telse\n\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\n\tset_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t \n\ti40e_pf_quiesce_all_vsi(pf);\n\n\t \n\ti40e_dcb_reconfigure(pf);\n\n\tret = i40e_resume_port_tx(pf);\n\n\tclear_bit(__I40E_PORT_SUSPENDED, pf->state);\n\t \n\tif (ret)\n\t\tgoto exit;\n\n\t \n\tret = i40e_pf_wait_queues_disabled(pf);\n\tif (ret) {\n\t\t \n\t\tset_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t\ti40e_service_event_schedule(pf);\n\t} else {\n\t\ti40e_pf_unquiesce_all_vsi(pf);\n\t\tset_bit(__I40E_CLIENT_SERVICE_REQUESTED, pf->state);\n\t\tset_bit(__I40E_CLIENT_L2_CHANGE, pf->state);\n\t}\n\nexit:\n\treturn ret;\n}\n#endif  \n\n \nvoid i40e_do_reset_safe(struct i40e_pf *pf, u32 reset_flags)\n{\n\trtnl_lock();\n\ti40e_do_reset(pf, reset_flags, true);\n\trtnl_unlock();\n}\n\n \nstatic void i40e_handle_lan_overflow_event(struct i40e_pf *pf,\n\t\t\t\t\t   struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_lan_overflow *data =\n\t\t(struct i40e_aqc_lan_overflow *)&e->desc.params.raw;\n\tu32 queue = le32_to_cpu(data->prtdcb_rupto);\n\tu32 qtx_ctl = le32_to_cpu(data->otx_ctl);\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vf *vf;\n\tu16 vf_id;\n\n\tdev_dbg(&pf->pdev->dev, \"overflow Rx Queue Number = %d QTX_CTL=0x%08x\\n\",\n\t\tqueue, qtx_ctl);\n\n\t \n\tif (((qtx_ctl & I40E_QTX_CTL_PFVF_Q_MASK)\n\t    >> I40E_QTX_CTL_PFVF_Q_SHIFT) == I40E_QTX_CTL_VF_QUEUE) {\n\t\tvf_id = (u16)((qtx_ctl & I40E_QTX_CTL_VFVM_INDX_MASK)\n\t\t\t >> I40E_QTX_CTL_VFVM_INDX_SHIFT);\n\t\tvf_id -= hw->func_caps.vf_base_id;\n\t\tvf = &pf->vf[vf_id];\n\t\ti40e_vc_notify_vf_reset(vf);\n\t\t \n\t\tmsleep(20);\n\t\ti40e_reset_vf(vf, false);\n\t}\n}\n\n \nu32 i40e_get_cur_guaranteed_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_PFQF_FDSTAT);\n\tfcnt_prog = (val & I40E_PFQF_FDSTAT_GUARANT_CNT_MASK);\n\treturn fcnt_prog;\n}\n\n \nu32 i40e_get_current_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_PFQF_FDSTAT);\n\tfcnt_prog = (val & I40E_PFQF_FDSTAT_GUARANT_CNT_MASK) +\n\t\t    ((val & I40E_PFQF_FDSTAT_BEST_CNT_MASK) >>\n\t\t      I40E_PFQF_FDSTAT_BEST_CNT_SHIFT);\n\treturn fcnt_prog;\n}\n\n \nu32 i40e_get_global_fd_count(struct i40e_pf *pf)\n{\n\tu32 val, fcnt_prog;\n\n\tval = rd32(&pf->hw, I40E_GLQF_FDCNT_0);\n\tfcnt_prog = (val & I40E_GLQF_FDCNT_0_GUARANT_CNT_MASK) +\n\t\t    ((val & I40E_GLQF_FDCNT_0_BESTCNT_MASK) >>\n\t\t     I40E_GLQF_FDCNT_0_BESTCNT_SHIFT);\n\treturn fcnt_prog;\n}\n\n \nstatic void i40e_reenable_fdir_sb(struct i40e_pf *pf)\n{\n\tif (test_and_clear_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state))\n\t\tif ((pf->flags & I40E_FLAG_FD_SB_ENABLED) &&\n\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\tdev_info(&pf->pdev->dev, \"FD Sideband/ntuple is being enabled since we have space in the table now\\n\");\n}\n\n \nstatic void i40e_reenable_fdir_atr(struct i40e_pf *pf)\n{\n\tif (test_and_clear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state)) {\n\t\t \n\t\ti40e_write_fd_input_set(pf, I40E_FILTER_PCTYPE_NONF_IPV4_TCP,\n\t\t\t\t\tI40E_L3_SRC_MASK | I40E_L3_DST_MASK |\n\t\t\t\t\tI40E_L4_SRC_MASK | I40E_L4_DST_MASK);\n\n\t\tif ((pf->flags & I40E_FLAG_FD_ATR_ENABLED) &&\n\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\tdev_info(&pf->pdev->dev, \"ATR is being enabled since we have space in the table and there are no conflicting ntuple rules\\n\");\n\t}\n}\n\n \nstatic void i40e_delete_invalid_filter(struct i40e_pf *pf,\n\t\t\t\t       struct i40e_fdir_filter *filter)\n{\n\t \n\tpf->fdir_pf_active_filters--;\n\tpf->fd_inv = 0;\n\n\tswitch (filter->flow_type) {\n\tcase TCP_V4_FLOW:\n\t\tpf->fd_tcp4_filter_cnt--;\n\t\tbreak;\n\tcase UDP_V4_FLOW:\n\t\tpf->fd_udp4_filter_cnt--;\n\t\tbreak;\n\tcase SCTP_V4_FLOW:\n\t\tpf->fd_sctp4_filter_cnt--;\n\t\tbreak;\n\tcase TCP_V6_FLOW:\n\t\tpf->fd_tcp6_filter_cnt--;\n\t\tbreak;\n\tcase UDP_V6_FLOW:\n\t\tpf->fd_udp6_filter_cnt--;\n\t\tbreak;\n\tcase SCTP_V6_FLOW:\n\t\tpf->fd_udp6_filter_cnt--;\n\t\tbreak;\n\tcase IP_USER_FLOW:\n\t\tswitch (filter->ipl4_proto) {\n\t\tcase IPPROTO_TCP:\n\t\t\tpf->fd_tcp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\t\tpf->fd_udp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_SCTP:\n\t\t\tpf->fd_sctp4_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_IP:\n\t\t\tpf->fd_ip4_filter_cnt--;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase IPV6_USER_FLOW:\n\t\tswitch (filter->ipl4_proto) {\n\t\tcase IPPROTO_TCP:\n\t\t\tpf->fd_tcp6_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_UDP:\n\t\t\tpf->fd_udp6_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_SCTP:\n\t\t\tpf->fd_sctp6_filter_cnt--;\n\t\t\tbreak;\n\t\tcase IPPROTO_IP:\n\t\t\tpf->fd_ip6_filter_cnt--;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\n\t \n\thlist_del(&filter->fdir_node);\n\tkfree(filter);\n}\n\n \nvoid i40e_fdir_check_and_reenable(struct i40e_pf *pf)\n{\n\tstruct i40e_fdir_filter *filter;\n\tu32 fcnt_prog, fcnt_avail;\n\tstruct hlist_node *node;\n\n\tif (test_bit(__I40E_FD_FLUSH_REQUESTED, pf->state))\n\t\treturn;\n\n\t \n\tfcnt_prog = i40e_get_global_fd_count(pf);\n\tfcnt_avail = pf->fdir_pf_filter_count;\n\tif ((fcnt_prog < (fcnt_avail - I40E_FDIR_BUFFER_HEAD_ROOM)) ||\n\t    (pf->fd_add_err == 0) ||\n\t    (i40e_get_current_atr_cnt(pf) < pf->fd_atr_cnt))\n\t\ti40e_reenable_fdir_sb(pf);\n\n\t \n\tif ((fcnt_prog < (fcnt_avail - I40E_FDIR_BUFFER_HEAD_ROOM_FOR_ATR)) &&\n\t    pf->fd_tcp4_filter_cnt == 0 && pf->fd_tcp6_filter_cnt == 0)\n\t\ti40e_reenable_fdir_atr(pf);\n\n\t \n\tif (pf->fd_inv > 0) {\n\t\thlist_for_each_entry_safe(filter, node,\n\t\t\t\t\t  &pf->fdir_filter_list, fdir_node)\n\t\t\tif (filter->fd_id == pf->fd_inv)\n\t\t\t\ti40e_delete_invalid_filter(pf, filter);\n\t}\n}\n\n#define I40E_MIN_FD_FLUSH_INTERVAL 10\n#define I40E_MIN_FD_FLUSH_SB_ATR_UNSTABLE 30\n \nstatic void i40e_fdir_flush_and_replay(struct i40e_pf *pf)\n{\n\tunsigned long min_flush_time;\n\tint flush_wait_retry = 50;\n\tbool disable_atr = false;\n\tint fd_room;\n\tint reg;\n\n\tif (!time_after(jiffies, pf->fd_flush_timestamp +\n\t\t\t\t (I40E_MIN_FD_FLUSH_INTERVAL * HZ)))\n\t\treturn;\n\n\t \n\tmin_flush_time = pf->fd_flush_timestamp +\n\t\t\t (I40E_MIN_FD_FLUSH_SB_ATR_UNSTABLE * HZ);\n\tfd_room = pf->fdir_pf_filter_count - pf->fdir_pf_active_filters;\n\n\tif (!(time_after(jiffies, min_flush_time)) &&\n\t    (fd_room < I40E_FDIR_BUFFER_HEAD_ROOM_FOR_ATR)) {\n\t\tif (I40E_DEBUG_FD & pf->hw.debug_mask)\n\t\t\tdev_info(&pf->pdev->dev, \"ATR disabled, not enough FD filter space.\\n\");\n\t\tdisable_atr = true;\n\t}\n\n\tpf->fd_flush_timestamp = jiffies;\n\tset_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state);\n\t \n\twr32(&pf->hw, I40E_PFQF_CTL_1,\n\t     I40E_PFQF_CTL_1_CLEARFDTABLE_MASK);\n\ti40e_flush(&pf->hw);\n\tpf->fd_flush_cnt++;\n\tpf->fd_add_err = 0;\n\tdo {\n\t\t \n\t\tusleep_range(5000, 6000);\n\t\treg = rd32(&pf->hw, I40E_PFQF_CTL_1);\n\t\tif (!(reg & I40E_PFQF_CTL_1_CLEARFDTABLE_MASK))\n\t\t\tbreak;\n\t} while (flush_wait_retry--);\n\tif (reg & I40E_PFQF_CTL_1_CLEARFDTABLE_MASK) {\n\t\tdev_warn(&pf->pdev->dev, \"FD table did not flush, needs more time\\n\");\n\t} else {\n\t\t \n\t\ti40e_fdir_filter_restore(pf->vsi[pf->lan_vsi]);\n\t\tif (!disable_atr && !pf->fd_tcp4_filter_cnt)\n\t\t\tclear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state);\n\t\tclear_bit(__I40E_FD_FLUSH_REQUESTED, pf->state);\n\t\tif (I40E_DEBUG_FD & pf->hw.debug_mask)\n\t\t\tdev_info(&pf->pdev->dev, \"FD Filter table flushed and FD-SB replayed.\\n\");\n\t}\n}\n\n \nu32 i40e_get_current_atr_cnt(struct i40e_pf *pf)\n{\n\treturn i40e_get_current_fd_count(pf) - pf->fdir_pf_active_filters;\n}\n\n \nstatic void i40e_fdir_reinit_subtask(struct i40e_pf *pf)\n{\n\n\t \n\tif (test_bit(__I40E_DOWN, pf->state))\n\t\treturn;\n\n\tif (test_bit(__I40E_FD_FLUSH_REQUESTED, pf->state))\n\t\ti40e_fdir_flush_and_replay(pf);\n\n\ti40e_fdir_check_and_reenable(pf);\n\n}\n\n \nstatic void i40e_vsi_link_event(struct i40e_vsi *vsi, bool link_up)\n{\n\tif (!vsi || test_bit(__I40E_VSI_DOWN, vsi->state))\n\t\treturn;\n\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\tif (!vsi->netdev || !vsi->netdev_registered)\n\t\t\tbreak;\n\n\t\tif (link_up) {\n\t\t\tnetif_carrier_on(vsi->netdev);\n\t\t\tnetif_tx_wake_all_queues(vsi->netdev);\n\t\t} else {\n\t\t\tnetif_carrier_off(vsi->netdev);\n\t\t\tnetif_tx_stop_all_queues(vsi->netdev);\n\t\t}\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\tcase I40E_VSI_VMDQ2:\n\tcase I40E_VSI_CTRL:\n\tcase I40E_VSI_IWARP:\n\tcase I40E_VSI_MIRROR:\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n}\n\n \nstatic void i40e_veb_link_event(struct i40e_veb *veb, bool link_up)\n{\n\tstruct i40e_pf *pf;\n\tint i;\n\n\tif (!veb || !veb->pf)\n\t\treturn;\n\tpf = veb->pf;\n\n\t \n\tfor (i = 0; i < I40E_MAX_VEB; i++)\n\t\tif (pf->veb[i] && (pf->veb[i]->uplink_seid == veb->seid))\n\t\t\ti40e_veb_link_event(pf->veb[i], link_up);\n\n\t \n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->uplink_seid == veb->seid))\n\t\t\ti40e_vsi_link_event(pf->vsi[i], link_up);\n}\n\n \nstatic void i40e_link_event(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 new_link_speed, old_link_speed;\n\tbool new_link, old_link;\n\tint status;\n#ifdef CONFIG_I40E_DCB\n\tint err;\n#endif  \n\n\t \n\tpf->hw.phy.get_link_info = true;\n\told_link = (pf->hw.phy.link_info_old.link_info & I40E_AQ_LINK_UP);\n\tstatus = i40e_get_link_status(&pf->hw, &new_link);\n\n\t \n\tif (status == 0) {\n\t\tclear_bit(__I40E_TEMP_LINK_POLLING, pf->state);\n\t} else {\n\t\t \n\t\tset_bit(__I40E_TEMP_LINK_POLLING, pf->state);\n\t\tdev_dbg(&pf->pdev->dev, \"couldn't get link state, status: %d\\n\",\n\t\t\tstatus);\n\t\treturn;\n\t}\n\n\told_link_speed = pf->hw.phy.link_info_old.link_speed;\n\tnew_link_speed = pf->hw.phy.link_info.link_speed;\n\n\tif (new_link == old_link &&\n\t    new_link_speed == old_link_speed &&\n\t    (test_bit(__I40E_VSI_DOWN, vsi->state) ||\n\t     new_link == netif_carrier_ok(vsi->netdev)))\n\t\treturn;\n\n\ti40e_print_link_message(vsi, new_link);\n\n\t \n\tif (pf->lan_veb < I40E_MAX_VEB && pf->veb[pf->lan_veb])\n\t\ti40e_veb_link_event(pf->veb[pf->lan_veb], new_link);\n\telse\n\t\ti40e_vsi_link_event(vsi, new_link);\n\n\tif (pf->vf)\n\t\ti40e_vc_notify_link_state(pf);\n\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\ti40e_ptp_set_increment(pf);\n#ifdef CONFIG_I40E_DCB\n\tif (new_link == old_link)\n\t\treturn;\n\t \n\tif (pf->dcbx_cap & DCB_CAP_DCBX_LLD_MANAGED)\n\t\treturn;\n\n\t \n\tif (!new_link) {\n\t\tdev_dbg(&pf->pdev->dev, \"Reconfig DCB to single TC as result of Link Down\\n\");\n\t\tmemset(&pf->tmp_cfg, 0, sizeof(pf->tmp_cfg));\n\t\terr = i40e_dcb_sw_default_config(pf);\n\t\tif (err) {\n\t\t\tpf->flags &= ~(I40E_FLAG_DCB_CAPABLE |\n\t\t\t\t       I40E_FLAG_DCB_ENABLED);\n\t\t} else {\n\t\t\tpf->dcbx_cap = DCB_CAP_DCBX_HOST |\n\t\t\t\t       DCB_CAP_DCBX_VER_IEEE;\n\t\t\tpf->flags |= I40E_FLAG_DCB_CAPABLE;\n\t\t\tpf->flags &= ~I40E_FLAG_DCB_ENABLED;\n\t\t}\n\t}\n#endif  \n}\n\n \nstatic void i40e_watchdog_subtask(struct i40e_pf *pf)\n{\n\tint i;\n\n\t \n\tif (test_bit(__I40E_DOWN, pf->state) ||\n\t    test_bit(__I40E_CONFIG_BUSY, pf->state))\n\t\treturn;\n\n\t \n\tif (time_before(jiffies, (pf->service_timer_previous +\n\t\t\t\t  pf->service_timer_period)))\n\t\treturn;\n\tpf->service_timer_previous = jiffies;\n\n\tif ((pf->flags & I40E_FLAG_LINK_POLLING_ENABLED) ||\n\t    test_bit(__I40E_TEMP_LINK_POLLING, pf->state))\n\t\ti40e_link_event(pf);\n\n\t \n\tfor (i = 0; i < pf->num_alloc_vsi; i++)\n\t\tif (pf->vsi[i] && pf->vsi[i]->netdev)\n\t\t\ti40e_update_stats(pf->vsi[i]);\n\n\tif (pf->flags & I40E_FLAG_VEB_STATS_ENABLED) {\n\t\t \n\t\tfor (i = 0; i < I40E_MAX_VEB; i++)\n\t\t\tif (pf->veb[i])\n\t\t\t\ti40e_update_veb_stats(pf->veb[i]);\n\t}\n\n\ti40e_ptp_rx_hang(pf);\n\ti40e_ptp_tx_hang(pf);\n}\n\n \nstatic void i40e_reset_subtask(struct i40e_pf *pf)\n{\n\tu32 reset_flags = 0;\n\n\tif (test_bit(__I40E_REINIT_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_REINIT_REQUESTED);\n\t\tclear_bit(__I40E_REINIT_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_PF_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_PF_RESET_REQUESTED);\n\t\tclear_bit(__I40E_PF_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_CORE_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_CORE_RESET_REQUESTED);\n\t\tclear_bit(__I40E_CORE_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_GLOBAL_RESET_REQUESTED);\n\t\tclear_bit(__I40E_GLOBAL_RESET_REQUESTED, pf->state);\n\t}\n\tif (test_bit(__I40E_DOWN_REQUESTED, pf->state)) {\n\t\treset_flags |= BIT(__I40E_DOWN_REQUESTED);\n\t\tclear_bit(__I40E_DOWN_REQUESTED, pf->state);\n\t}\n\n\t \n\tif (test_bit(__I40E_RESET_INTR_RECEIVED, pf->state)) {\n\t\ti40e_prep_for_reset(pf);\n\t\ti40e_reset(pf);\n\t\ti40e_rebuild(pf, false, false);\n\t}\n\n\t \n\tif (reset_flags &&\n\t    !test_bit(__I40E_DOWN, pf->state) &&\n\t    !test_bit(__I40E_CONFIG_BUSY, pf->state)) {\n\t\ti40e_do_reset(pf, reset_flags, false);\n\t}\n}\n\n \nstatic void i40e_handle_link_event(struct i40e_pf *pf,\n\t\t\t\t   struct i40e_arq_event_info *e)\n{\n\tstruct i40e_aqc_get_link_status *status =\n\t\t(struct i40e_aqc_get_link_status *)&e->desc.params.raw;\n\n\t \n\ti40e_link_event(pf);\n\n\t \n\tif (status->phy_type == I40E_PHY_TYPE_NOT_SUPPORTED_HIGH_TEMP) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Rx/Tx is disabled on this device because the module does not meet thermal requirements.\\n\");\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for a list of supported modules.\\n\");\n\t} else {\n\t\t \n\t\tif ((status->link_info & I40E_AQ_MEDIA_AVAILABLE) &&\n\t\t    (!(status->an_info & I40E_AQ_QUALIFIED_MODULE)) &&\n\t\t    (!(status->link_info & I40E_AQ_LINK_UP)) &&\n\t\t    (!(pf->flags & I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED))) {\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Rx/Tx is disabled on this device because an unsupported SFP module type was detected.\\n\");\n\t\t\tdev_err(&pf->pdev->dev,\n\t\t\t\t\"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for a list of supported modules.\\n\");\n\t\t}\n\t}\n}\n\n \nstatic void i40e_clean_adminq_subtask(struct i40e_pf *pf)\n{\n\tstruct i40e_arq_event_info event;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 pending, i = 0;\n\tu16 opcode;\n\tu32 oldval;\n\tint ret;\n\tu32 val;\n\n\t \n\tif (test_bit(__I40E_RESET_FAILED, pf->state))\n\t\treturn;\n\n\t \n\tval = rd32(&pf->hw, pf->hw.aq.arq.len);\n\toldval = val;\n\tif (val & I40E_PF_ARQLEN_ARQVFE_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ VF Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQVFE_MASK;\n\t}\n\tif (val & I40E_PF_ARQLEN_ARQOVFL_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ Overflow Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQOVFL_MASK;\n\t\tpf->arq_overflows++;\n\t}\n\tif (val & I40E_PF_ARQLEN_ARQCRIT_MASK) {\n\t\tif (hw->debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ Critical Error detected\\n\");\n\t\tval &= ~I40E_PF_ARQLEN_ARQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(&pf->hw, pf->hw.aq.arq.len, val);\n\n\tval = rd32(&pf->hw, pf->hw.aq.asq.len);\n\toldval = val;\n\tif (val & I40E_PF_ATQLEN_ATQVFE_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ VF Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQVFE_MASK;\n\t}\n\tif (val & I40E_PF_ATQLEN_ATQOVFL_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ Overflow Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQOVFL_MASK;\n\t}\n\tif (val & I40E_PF_ATQLEN_ATQCRIT_MASK) {\n\t\tif (pf->hw.debug_mask & I40E_DEBUG_AQ)\n\t\t\tdev_info(&pf->pdev->dev, \"ASQ Critical Error detected\\n\");\n\t\tval &= ~I40E_PF_ATQLEN_ATQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(&pf->hw, pf->hw.aq.asq.len, val);\n\n\tevent.buf_len = I40E_MAX_AQ_BUF_SIZE;\n\tevent.msg_buf = kzalloc(event.buf_len, GFP_KERNEL);\n\tif (!event.msg_buf)\n\t\treturn;\n\n\tdo {\n\t\tret = i40e_clean_arq_element(hw, &event, &pending);\n\t\tif (ret == -EALREADY)\n\t\t\tbreak;\n\t\telse if (ret) {\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ event error %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\n\t\topcode = le16_to_cpu(event.desc.opcode);\n\t\tswitch (opcode) {\n\n\t\tcase i40e_aqc_opc_get_link_status:\n\t\t\trtnl_lock();\n\t\t\ti40e_handle_link_event(pf, &event);\n\t\t\trtnl_unlock();\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_send_msg_to_pf:\n\t\t\tret = i40e_vc_process_vf_msg(pf,\n\t\t\t\t\tle16_to_cpu(event.desc.retval),\n\t\t\t\t\tle32_to_cpu(event.desc.cookie_high),\n\t\t\t\t\tle32_to_cpu(event.desc.cookie_low),\n\t\t\t\t\tevent.msg_buf,\n\t\t\t\t\tevent.msg_len);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_lldp_update_mib:\n\t\t\tdev_dbg(&pf->pdev->dev, \"ARQ: Update LLDP MIB event received\\n\");\n#ifdef CONFIG_I40E_DCB\n\t\t\trtnl_lock();\n\t\t\ti40e_handle_lldp_event(pf, &event);\n\t\t\trtnl_unlock();\n#endif  \n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_event_lan_overflow:\n\t\t\tdev_dbg(&pf->pdev->dev, \"ARQ LAN queue overflow event received\\n\");\n\t\t\ti40e_handle_lan_overflow_event(pf, &event);\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_send_msg_to_peer:\n\t\t\tdev_info(&pf->pdev->dev, \"ARQ: Msg from other pf\\n\");\n\t\t\tbreak;\n\t\tcase i40e_aqc_opc_nvm_erase:\n\t\tcase i40e_aqc_opc_nvm_update:\n\t\tcase i40e_aqc_opc_oem_post_update:\n\t\t\ti40e_debug(&pf->hw, I40E_DEBUG_NVM,\n\t\t\t\t   \"ARQ NVM operation 0x%04x completed\\n\",\n\t\t\t\t   opcode);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"ARQ: Unknown event 0x%04x ignored\\n\",\n\t\t\t\t opcode);\n\t\t\tbreak;\n\t\t}\n\t} while (i++ < pf->adminq_work_limit);\n\n\tif (i < pf->adminq_work_limit)\n\t\tclear_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state);\n\n\t \n\tval = rd32(hw, I40E_PFINT_ICR0_ENA);\n\tval |=  I40E_PFINT_ICR0_ENA_ADMINQ_MASK;\n\twr32(hw, I40E_PFINT_ICR0_ENA, val);\n\ti40e_flush(hw);\n\n\tkfree(event.msg_buf);\n}\n\n \nstatic void i40e_verify_eeprom(struct i40e_pf *pf)\n{\n\tint err;\n\n\terr = i40e_diag_eeprom_test(&pf->hw);\n\tif (err) {\n\t\t \n\t\terr = i40e_diag_eeprom_test(&pf->hw);\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev, \"eeprom check failed (%d), Tx/Rx traffic disabled\\n\",\n\t\t\t\t err);\n\t\t\tset_bit(__I40E_BAD_EEPROM, pf->state);\n\t\t}\n\t}\n\n\tif (!err && test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\tdev_info(&pf->pdev->dev, \"eeprom check passed, Tx/Rx traffic enabled\\n\");\n\t\tclear_bit(__I40E_BAD_EEPROM, pf->state);\n\t}\n}\n\n \nstatic void i40e_enable_pf_switch_lb(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\tctxt.seid = pf->main_vsi_seid;\n\tctxt.pf_num = pf->hw.pf_id;\n\tctxt.vf_num = 0;\n\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi config, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn;\n\t}\n\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\tctxt.info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\tctxt.info.switch_id |= cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"update vsi switch failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n}\n\n \nstatic void i40e_disable_pf_switch_lb(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_vsi_context ctxt;\n\tint ret;\n\n\tctxt.seid = pf->main_vsi_seid;\n\tctxt.pf_num = pf->hw.pf_id;\n\tctxt.vf_num = 0;\n\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get PF vsi config, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn;\n\t}\n\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\tctxt.info.valid_sections = cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\tctxt.info.switch_id &= ~cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\n\tret = i40e_aq_update_vsi_params(&vsi->back->hw, &ctxt, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"update vsi switch failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t}\n}\n\n \nstatic void i40e_config_bridge_mode(struct i40e_veb *veb)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\n\tif (pf->hw.debug_mask & I40E_DEBUG_LAN)\n\t\tdev_info(&pf->pdev->dev, \"enabling bridge mode: %s\\n\",\n\t\t\t veb->bridge_mode == BRIDGE_MODE_VEPA ? \"VEPA\" : \"VEB\");\n\tif (veb->bridge_mode & BRIDGE_MODE_VEPA)\n\t\ti40e_disable_pf_switch_lb(pf);\n\telse\n\t\ti40e_enable_pf_switch_lb(pf);\n}\n\n \nstatic int i40e_reconstitute_veb(struct i40e_veb *veb)\n{\n\tstruct i40e_vsi *ctl_vsi = NULL;\n\tstruct i40e_pf *pf = veb->pf;\n\tint v, veb_idx;\n\tint ret;\n\n\t \n\tfor (v = 0; v < pf->num_alloc_vsi && !ctl_vsi; v++) {\n\t\tif (pf->vsi[v] &&\n\t\t    pf->vsi[v]->veb_idx == veb->idx &&\n\t\t    pf->vsi[v]->flags & I40E_VSI_FLAG_VEB_OWNER) {\n\t\t\tctl_vsi = pf->vsi[v];\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!ctl_vsi) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"missing owner VSI for veb_idx %d\\n\", veb->idx);\n\t\tret = -ENOENT;\n\t\tgoto end_reconstitute;\n\t}\n\tif (ctl_vsi != pf->vsi[pf->lan_vsi])\n\t\tctl_vsi->uplink_seid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\tret = i40e_add_vsi(ctl_vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"rebuild of veb_idx %d owner VSI failed: %d\\n\",\n\t\t\t veb->idx, ret);\n\t\tgoto end_reconstitute;\n\t}\n\ti40e_vsi_reset_stats(ctl_vsi);\n\n\t \n\tret = i40e_add_veb(veb, ctl_vsi);\n\tif (ret)\n\t\tgoto end_reconstitute;\n\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED)\n\t\tveb->bridge_mode = BRIDGE_MODE_VEB;\n\telse\n\t\tveb->bridge_mode = BRIDGE_MODE_VEPA;\n\ti40e_config_bridge_mode(veb);\n\n\t \n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (!pf->vsi[v] || pf->vsi[v] == ctl_vsi)\n\t\t\tcontinue;\n\n\t\tif (pf->vsi[v]->veb_idx == veb->idx) {\n\t\t\tstruct i40e_vsi *vsi = pf->vsi[v];\n\n\t\t\tvsi->uplink_seid = veb->seid;\n\t\t\tret = i40e_add_vsi(vsi);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"rebuild of vsi_idx %d failed: %d\\n\",\n\t\t\t\t\t v, ret);\n\t\t\t\tgoto end_reconstitute;\n\t\t\t}\n\t\t\ti40e_vsi_reset_stats(vsi);\n\t\t}\n\t}\n\n\t \n\tfor (veb_idx = 0; veb_idx < I40E_MAX_VEB; veb_idx++) {\n\t\tif (pf->veb[veb_idx] && pf->veb[veb_idx]->veb_idx == veb->idx) {\n\t\t\tpf->veb[veb_idx]->uplink_seid = veb->seid;\n\t\t\tret = i40e_reconstitute_veb(pf->veb[veb_idx]);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\nend_reconstitute:\n\treturn ret;\n}\n\n \nstatic int i40e_get_capabilities(struct i40e_pf *pf,\n\t\t\t\t enum i40e_admin_queue_opc list_type)\n{\n\tstruct i40e_aqc_list_capabilities_element_resp *cap_buf;\n\tu16 data_size;\n\tint buf_len;\n\tint err;\n\n\tbuf_len = 40 * sizeof(struct i40e_aqc_list_capabilities_element_resp);\n\tdo {\n\t\tcap_buf = kzalloc(buf_len, GFP_KERNEL);\n\t\tif (!cap_buf)\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\terr = i40e_aq_discover_capabilities(&pf->hw, cap_buf, buf_len,\n\t\t\t\t\t\t    &data_size, list_type,\n\t\t\t\t\t\t    NULL);\n\t\t \n\t\tkfree(cap_buf);\n\n\t\tif (pf->hw.aq.asq_last_status == I40E_AQ_RC_ENOMEM) {\n\t\t\t \n\t\t\tbuf_len = data_size;\n\t\t} else if (pf->hw.aq.asq_last_status != I40E_AQ_RC_OK || err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"capability discovery failed, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(err),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn -ENODEV;\n\t\t}\n\t} while (err);\n\n\tif (pf->hw.debug_mask & I40E_DEBUG_USER) {\n\t\tif (list_type == i40e_aqc_opc_list_func_capabilities) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"pf=%d, num_vfs=%d, msix_pf=%d, msix_vf=%d, fd_g=%d, fd_b=%d, pf_max_q=%d num_vsi=%d\\n\",\n\t\t\t\t pf->hw.pf_id, pf->hw.func_caps.num_vfs,\n\t\t\t\t pf->hw.func_caps.num_msix_vectors,\n\t\t\t\t pf->hw.func_caps.num_msix_vectors_vf,\n\t\t\t\t pf->hw.func_caps.fd_filters_guaranteed,\n\t\t\t\t pf->hw.func_caps.fd_filters_best_effort,\n\t\t\t\t pf->hw.func_caps.num_tx_qp,\n\t\t\t\t pf->hw.func_caps.num_vsis);\n\t\t} else if (list_type == i40e_aqc_opc_list_dev_capabilities) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"switch_mode=0x%04x, function_valid=0x%08x\\n\",\n\t\t\t\t pf->hw.dev_caps.switch_mode,\n\t\t\t\t pf->hw.dev_caps.valid_functions);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"SR-IOV=%d, num_vfs for all function=%u\\n\",\n\t\t\t\t pf->hw.dev_caps.sr_iov_1_1,\n\t\t\t\t pf->hw.dev_caps.num_vfs);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"num_vsis=%u, num_rx:%u, num_tx=%u\\n\",\n\t\t\t\t pf->hw.dev_caps.num_vsis,\n\t\t\t\t pf->hw.dev_caps.num_rx_qp,\n\t\t\t\t pf->hw.dev_caps.num_tx_qp);\n\t\t}\n\t}\n\tif (list_type == i40e_aqc_opc_list_func_capabilities) {\n#define DEF_NUM_VSI (1 + (pf->hw.func_caps.fcoe ? 1 : 0) \\\n\t\t       + pf->hw.func_caps.num_vfs)\n\t\tif (pf->hw.revision_id == 0 &&\n\t\t    pf->hw.func_caps.num_vsis < DEF_NUM_VSI) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"got num_vsis %d, setting num_vsis to %d\\n\",\n\t\t\t\t pf->hw.func_caps.num_vsis, DEF_NUM_VSI);\n\t\t\tpf->hw.func_caps.num_vsis = DEF_NUM_VSI;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int i40e_vsi_clear(struct i40e_vsi *vsi);\n\n \nstatic void i40e_fdir_sb_setup(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi;\n\n\t \n\tif (!rd32(&pf->hw, I40E_GLQF_HKEY(0))) {\n\t\tstatic const u32 hkey[] = {\n\t\t\t0xe640d33f, 0xcdfe98ab, 0x73fa7161, 0x0d7a7d36,\n\t\t\t0xeacb7d61, 0xaa4f05b6, 0x9c5c89ed, 0xfc425ddb,\n\t\t\t0xa4654832, 0xfc7461d4, 0x8f827619, 0xf5c63c21,\n\t\t\t0x95b3a76d};\n\t\tint i;\n\n\t\tfor (i = 0; i <= I40E_GLQF_HKEY_MAX_INDEX; i++)\n\t\t\twr32(&pf->hw, I40E_GLQF_HKEY(i), hkey[i]);\n\t}\n\n\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\treturn;\n\n\t \n\tvsi = i40e_find_vsi_by_type(pf, I40E_VSI_FDIR);\n\n\t \n\tif (!vsi) {\n\t\tvsi = i40e_vsi_setup(pf, I40E_VSI_FDIR,\n\t\t\t\t     pf->vsi[pf->lan_vsi]->seid, 0);\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"Couldn't create FDir VSI\\n\");\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t\t\treturn;\n\t\t}\n\t}\n\n\ti40e_vsi_setup_irqhandler(vsi, i40e_fdir_clean_ring);\n}\n\n \nstatic void i40e_fdir_teardown(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi;\n\n\ti40e_fdir_filter_exit(pf);\n\tvsi = i40e_find_vsi_by_type(pf, I40E_VSI_FDIR);\n\tif (vsi)\n\t\ti40e_vsi_release(vsi);\n}\n\n \nstatic int i40e_rebuild_cloud_filters(struct i40e_vsi *vsi, u16 seid)\n{\n\tstruct i40e_cloud_filter *cfilter;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct hlist_node *node;\n\tint ret;\n\n\t \n\thlist_for_each_entry_safe(cfilter, node, &pf->cloud_filter_list,\n\t\t\t\t  cloud_node) {\n\t\tif (cfilter->seid != seid)\n\t\t\tcontinue;\n\n\t\tif (cfilter->dst_port)\n\t\t\tret = i40e_add_del_cloud_filter_big_buf(vsi, cfilter,\n\t\t\t\t\t\t\t\ttrue);\n\t\telse\n\t\t\tret = i40e_add_del_cloud_filter(vsi, cfilter, true);\n\n\t\tif (ret) {\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"Failed to rebuild cloud filter, err %pe aq_err %s\\n\",\n\t\t\t\tERR_PTR(ret),\n\t\t\t\ti40e_aq_str(&pf->hw,\n\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic int i40e_rebuild_channels(struct i40e_vsi *vsi)\n{\n\tstruct i40e_channel *ch, *ch_tmp;\n\tint ret;\n\n\tif (list_empty(&vsi->ch_list))\n\t\treturn 0;\n\n\tlist_for_each_entry_safe(ch, ch_tmp, &vsi->ch_list, list) {\n\t\tif (!ch->initialized)\n\t\t\tbreak;\n\t\t \n\t\tret = i40e_add_channel(vsi->back, vsi->uplink_seid, ch);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"failed to rebuild channels using uplink_seid %u\\n\",\n\t\t\t\t vsi->uplink_seid);\n\t\t\treturn ret;\n\t\t}\n\t\t \n\t\tret = i40e_channel_config_tx_ring(vsi->back, vsi, ch);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"failed to configure TX rings for channel %u\\n\",\n\t\t\t\t ch->seid);\n\t\t\treturn ret;\n\t\t}\n\t\t \n\t\tvsi->next_base_queue = vsi->next_base_queue +\n\t\t\t\t\t\t\tch->num_queue_pairs;\n\t\tif (ch->max_tx_rate) {\n\t\t\tu64 credits = ch->max_tx_rate;\n\n\t\t\tif (i40e_set_bw_limit(vsi, ch->seid,\n\t\t\t\t\t      ch->max_tx_rate))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\t\tch->max_tx_rate,\n\t\t\t\tcredits,\n\t\t\t\tch->seid);\n\t\t}\n\t\tret = i40e_rebuild_cloud_filters(vsi, ch->seid);\n\t\tif (ret) {\n\t\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\t\"Failed to rebuild cloud filters for channel VSI %u\\n\",\n\t\t\t\tch->seid);\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic void i40e_clean_xps_state(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (vsi->tx_rings)\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->tx_rings[i])\n\t\t\t\tclear_bit(__I40E_TX_XPS_INIT_DONE,\n\t\t\t\t\t  vsi->tx_rings[i]->state);\n}\n\n \nstatic void i40e_prep_for_reset(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret = 0;\n\tu32 v;\n\n\tclear_bit(__I40E_RESET_INTR_RECEIVED, pf->state);\n\tif (test_and_set_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\treturn;\n\tif (i40e_check_asq_alive(&pf->hw))\n\t\ti40e_vc_notify_reset(pf);\n\n\tdev_dbg(&pf->pdev->dev, \"Tearing down internal switch for reset\\n\");\n\n\t \n\ti40e_pf_quiesce_all_vsi(pf);\n\n\tfor (v = 0; v < pf->num_alloc_vsi; v++) {\n\t\tif (pf->vsi[v]) {\n\t\t\ti40e_clean_xps_state(pf->vsi[v]);\n\t\t\tpf->vsi[v]->seid = 0;\n\t\t}\n\t}\n\n\ti40e_shutdown_adminq(&pf->hw);\n\n\t \n\tif (hw->hmc.hmc_obj) {\n\t\tret = i40e_shutdown_lan_hmc(hw);\n\t\tif (ret)\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"shutdown_lan_hmc failed: %d\\n\", ret);\n\t}\n\n\t \n\ti40e_ptp_save_hw_time(pf);\n}\n\n \nstatic void i40e_send_version(struct i40e_pf *pf)\n{\n\tstruct i40e_driver_version dv;\n\n\tdv.major_version = 0xff;\n\tdv.minor_version = 0xff;\n\tdv.build_version = 0xff;\n\tdv.subbuild_version = 0;\n\tstrscpy(dv.driver_string, UTS_RELEASE, sizeof(dv.driver_string));\n\ti40e_aq_send_driver_version(&pf->hw, &dv, NULL);\n}\n\n \nstatic void i40e_get_oem_version(struct i40e_hw *hw)\n{\n\tu16 block_offset = 0xffff;\n\tu16 block_length = 0;\n\tu16 capabilities = 0;\n\tu16 gen_snap = 0;\n\tu16 release = 0;\n\n#define I40E_SR_NVM_OEM_VERSION_PTR\t\t0x1B\n#define I40E_NVM_OEM_LENGTH_OFFSET\t\t0x00\n#define I40E_NVM_OEM_CAPABILITIES_OFFSET\t0x01\n#define I40E_NVM_OEM_GEN_OFFSET\t\t\t0x02\n#define I40E_NVM_OEM_RELEASE_OFFSET\t\t0x03\n#define I40E_NVM_OEM_CAPABILITIES_MASK\t\t0x000F\n#define I40E_NVM_OEM_LENGTH\t\t\t3\n\n\t \n\ti40e_read_nvm_word(hw, I40E_SR_NVM_OEM_VERSION_PTR, &block_offset);\n\tif (block_offset == 0xffff)\n\t\treturn;\n\n\t \n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_LENGTH_OFFSET,\n\t\t\t   &block_length);\n\tif (block_length < I40E_NVM_OEM_LENGTH)\n\t\treturn;\n\n\t \n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_CAPABILITIES_OFFSET,\n\t\t\t   &capabilities);\n\tif ((capabilities & I40E_NVM_OEM_CAPABILITIES_MASK) != 0)\n\t\treturn;\n\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_GEN_OFFSET,\n\t\t\t   &gen_snap);\n\ti40e_read_nvm_word(hw, block_offset + I40E_NVM_OEM_RELEASE_OFFSET,\n\t\t\t   &release);\n\thw->nvm.oem_ver = (gen_snap << I40E_OEM_SNAP_SHIFT) | release;\n\thw->nvm.eetrack = I40E_OEM_EETRACK_ID;\n}\n\n \nstatic int i40e_reset(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_pf_reset(hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"PF reset failed, %d\\n\", ret);\n\t\tset_bit(__I40E_RESET_FAILED, pf->state);\n\t\tclear_bit(__I40E_RESET_RECOVERY_PENDING, pf->state);\n\t} else {\n\t\tpf->pfr_count++;\n\t}\n\treturn ret;\n}\n\n \nstatic void i40e_rebuild(struct i40e_pf *pf, bool reinit, bool lock_acquired)\n{\n\tconst bool is_recovery_mode_reported = i40e_check_recovery_mode(pf);\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\tu32 val;\n\tint v;\n\n\tif (test_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state) &&\n\t    is_recovery_mode_reported)\n\t\ti40e_set_ethtool_ops(pf->vsi[pf->lan_vsi]->netdev);\n\n\tif (test_bit(__I40E_DOWN, pf->state) &&\n\t    !test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\tgoto clear_recovery;\n\tdev_dbg(&pf->pdev->dev, \"Rebuilding internal switch\\n\");\n\n\t \n\tret = i40e_init_adminq(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"Rebuild AdminQ failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\tgoto clear_recovery;\n\t}\n\ti40e_get_oem_version(&pf->hw);\n\n\tif (test_and_clear_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state)) {\n\t\t \n\t\tmdelay(1000);\n\t}\n\n\t \n\tif (test_and_clear_bit(__I40E_EMP_RESET_INTR_RECEIVED, pf->state))\n\t\ti40e_verify_eeprom(pf);\n\n\t \n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\tif (i40e_get_capabilities(pf,\n\t\t\t\t\t  i40e_aqc_opc_list_func_capabilities))\n\t\t\tgoto end_unlock;\n\n\t\tif (is_recovery_mode_reported) {\n\t\t\t \n\t\t\tif (i40e_setup_misc_vector_for_recovery_mode(pf))\n\t\t\t\tgoto end_unlock;\n\t\t} else {\n\t\t\tif (!lock_acquired)\n\t\t\t\trtnl_lock();\n\t\t\t \n\t\t\tfree_irq(pf->pdev->irq, pf);\n\t\t\ti40e_clear_interrupt_scheme(pf);\n\t\t\tif (i40e_restore_interrupt_scheme(pf))\n\t\t\t\tgoto end_unlock;\n\t\t}\n\n\t\t \n\t\ti40e_send_version(pf);\n\n\t\t \n\t\tgoto end_unlock;\n\t}\n\n\ti40e_clear_pxe_mode(hw);\n\tret = i40e_get_capabilities(pf, i40e_aqc_opc_list_func_capabilities);\n\tif (ret)\n\t\tgoto end_core_reset;\n\n\tret = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp,\n\t\t\t\thw->func_caps.num_rx_qp, 0, 0);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"init_lan_hmc failed: %d\\n\", ret);\n\t\tgoto end_core_reset;\n\t}\n\tret = i40e_configure_lan_hmc(hw, I40E_HMC_MODEL_DIRECT_ONLY);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"configure_lan_hmc failed: %d\\n\", ret);\n\t\tgoto end_core_reset;\n\t}\n\n#ifdef CONFIG_I40E_DCB\n\t \n\tif (i40e_is_tc_mqprio_enabled(pf)) {\n\t\ti40e_aq_set_dcb_parameters(hw, false, NULL);\n\t} else {\n\t\tif (I40E_IS_X710TL_DEVICE(hw->device_id) &&\n\t\t    (hw->phy.link_info.link_speed &\n\t\t     (I40E_LINK_SPEED_2_5GB | I40E_LINK_SPEED_5GB))) {\n\t\t\ti40e_aq_set_dcb_parameters(hw, false, NULL);\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"DCB is not supported for X710-T*L 2.5/5G speeds\\n\");\n\t\t\tpf->flags &= ~I40E_FLAG_DCB_CAPABLE;\n\t\t} else {\n\t\t\ti40e_aq_set_dcb_parameters(hw, true, NULL);\n\t\t\tret = i40e_init_pf_dcb(pf);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev, \"DCB init failed %d, disabled\\n\",\n\t\t\t\t\t ret);\n\t\t\t\tpf->flags &= ~I40E_FLAG_DCB_CAPABLE;\n\t\t\t\t \n\t\t\t}\n\t\t}\n\t}\n\n#endif  \n\tif (!lock_acquired)\n\t\trtnl_lock();\n\tret = i40e_setup_pf_switch(pf, reinit, true);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t \n\tret = i40e_aq_set_phy_int_mask(&pf->hw,\n\t\t\t\t       ~(I40E_AQ_EVENT_LINK_UPDOWN |\n\t\t\t\t\t I40E_AQ_EVENT_MEDIA_NA |\n\t\t\t\t\t I40E_AQ_EVENT_MODULE_QUAL_FAIL), NULL);\n\tif (ret)\n\t\tdev_info(&pf->pdev->dev, \"set phy mask fail, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t \n\tif (vsi->uplink_seid != pf->mac_seid) {\n\t\tdev_dbg(&pf->pdev->dev, \"attempting to rebuild switch\\n\");\n\t\t \n\t\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\t\tif (!pf->veb[v])\n\t\t\t\tcontinue;\n\n\t\t\tif (pf->veb[v]->uplink_seid == pf->mac_seid ||\n\t\t\t    pf->veb[v]->uplink_seid == 0) {\n\t\t\t\tret = i40e_reconstitute_veb(pf->veb[v]);\n\n\t\t\t\tif (!ret)\n\t\t\t\t\tcontinue;\n\n\t\t\t\t \n\t\t\t\tif (pf->veb[v]->uplink_seid == pf->mac_seid) {\n\t\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t\t \"rebuild of switch failed: %d, will try to set up simple PF connection\\n\",\n\t\t\t\t\t\t ret);\n\t\t\t\t\tvsi->uplink_seid = pf->mac_seid;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (pf->veb[v]->uplink_seid == 0) {\n\t\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t\t \"rebuild of orphan VEB failed: %d\\n\",\n\t\t\t\t\t\t ret);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (vsi->uplink_seid == pf->mac_seid) {\n\t\tdev_dbg(&pf->pdev->dev, \"attempting to rebuild PF VSI\\n\");\n\t\t \n\t\tret = i40e_add_vsi(vsi);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"rebuild of Main VSI failed: %d\\n\", ret);\n\t\t\tgoto end_unlock;\n\t\t}\n\t}\n\n\tif (vsi->mqprio_qopt.max_rate[0]) {\n\t\tu64 max_tx_rate = i40e_bw_bytes_to_mbits(vsi,\n\t\t\t\t\t\t  vsi->mqprio_qopt.max_rate[0]);\n\t\tu64 credits = 0;\n\n\t\tret = i40e_set_bw_limit(vsi, vsi->seid, max_tx_rate);\n\t\tif (ret)\n\t\t\tgoto end_unlock;\n\n\t\tcredits = max_tx_rate;\n\t\tdo_div(credits, I40E_BW_CREDIT_DIVISOR);\n\t\tdev_dbg(&vsi->back->pdev->dev,\n\t\t\t\"Set tx rate of %llu Mbps (count of 50Mbps %llu) for vsi->seid %u\\n\",\n\t\t\tmax_tx_rate,\n\t\t\tcredits,\n\t\t\tvsi->seid);\n\t}\n\n\tret = i40e_rebuild_cloud_filters(vsi, vsi->seid);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t \n\tret = i40e_rebuild_channels(vsi);\n\tif (ret)\n\t\tgoto end_unlock;\n\n\t \n#define I40E_REG_MSS          0x000E64DC\n#define I40E_REG_MSS_MIN_MASK 0x3FF0000\n#define I40E_64BYTE_MSS       0x400000\n\tval = rd32(hw, I40E_REG_MSS);\n\tif ((val & I40E_REG_MSS_MIN_MASK) > I40E_64BYTE_MSS) {\n\t\tval &= ~I40E_REG_MSS_MIN_MASK;\n\t\tval |= I40E_64BYTE_MSS;\n\t\twr32(hw, I40E_REG_MSS, val);\n\t}\n\n\tif (pf->hw_features & I40E_HW_RESTART_AUTONEG) {\n\t\tmsleep(75);\n\t\tret = i40e_aq_set_link_restart_an(&pf->hw, true, NULL);\n\t\tif (ret)\n\t\t\tdev_info(&pf->pdev->dev, \"link restart failed, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t}\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tret = i40e_setup_misc_vector(pf);\n\t\tif (ret)\n\t\t\tgoto end_unlock;\n\t}\n\n\t \n\ti40e_add_filter_to_drop_tx_flow_control_frames(&pf->hw,\n\t\t\t\t\t\t       pf->main_vsi_seid);\n\n\t \n\ti40e_pf_unquiesce_all_vsi(pf);\n\n\t \n\tif (!lock_acquired)\n\t\trtnl_unlock();\n\n\t \n\tret = i40e_set_promiscuous(pf, pf->cur_promisc);\n\tif (ret)\n\t\tdev_warn(&pf->pdev->dev,\n\t\t\t \"Failed to restore promiscuous setting: %s, err %pe aq_err %s\\n\",\n\t\t\t pf->cur_promisc ? \"on\" : \"off\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\ti40e_reset_all_vfs(pf, true);\n\n\t \n\ti40e_send_version(pf);\n\n\t \n\tgoto end_core_reset;\n\nend_unlock:\n\tif (!lock_acquired)\n\t\trtnl_unlock();\nend_core_reset:\n\tclear_bit(__I40E_RESET_FAILED, pf->state);\nclear_recovery:\n\tclear_bit(__I40E_RESET_RECOVERY_PENDING, pf->state);\n\tclear_bit(__I40E_TIMEOUT_RECOVERY_PENDING, pf->state);\n}\n\n \nstatic void i40e_reset_and_rebuild(struct i40e_pf *pf, bool reinit,\n\t\t\t\t   bool lock_acquired)\n{\n\tint ret;\n\n\tif (test_bit(__I40E_IN_REMOVE, pf->state))\n\t\treturn;\n\t \n\tret = i40e_reset(pf);\n\tif (!ret)\n\t\ti40e_rebuild(pf, reinit, lock_acquired);\n}\n\n \nstatic void i40e_handle_reset_warning(struct i40e_pf *pf, bool lock_acquired)\n{\n\ti40e_prep_for_reset(pf);\n\ti40e_reset_and_rebuild(pf, false, lock_acquired);\n}\n\n \nstatic void i40e_handle_mdd_event(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tbool mdd_detected = false;\n\tstruct i40e_vf *vf;\n\tu32 reg;\n\tint i;\n\n\tif (!test_bit(__I40E_MDD_EVENT_PENDING, pf->state))\n\t\treturn;\n\n\t \n\treg = rd32(hw, I40E_GL_MDET_TX);\n\tif (reg & I40E_GL_MDET_TX_VALID_MASK) {\n\t\tu8 pf_num = (reg & I40E_GL_MDET_TX_PF_NUM_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_PF_NUM_SHIFT;\n\t\tu16 vf_num = (reg & I40E_GL_MDET_TX_VF_NUM_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_VF_NUM_SHIFT;\n\t\tu8 event = (reg & I40E_GL_MDET_TX_EVENT_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_EVENT_SHIFT;\n\t\tu16 queue = ((reg & I40E_GL_MDET_TX_QUEUE_MASK) >>\n\t\t\t\tI40E_GL_MDET_TX_QUEUE_SHIFT) -\n\t\t\t\tpf->hw.func_caps.base_queue;\n\t\tif (netif_msg_tx_err(pf))\n\t\t\tdev_info(&pf->pdev->dev, \"Malicious Driver Detection event 0x%02x on TX queue %d PF number 0x%02x VF number 0x%02x\\n\",\n\t\t\t\t event, queue, pf_num, vf_num);\n\t\twr32(hw, I40E_GL_MDET_TX, 0xffffffff);\n\t\tmdd_detected = true;\n\t}\n\treg = rd32(hw, I40E_GL_MDET_RX);\n\tif (reg & I40E_GL_MDET_RX_VALID_MASK) {\n\t\tu8 func = (reg & I40E_GL_MDET_RX_FUNCTION_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_FUNCTION_SHIFT;\n\t\tu8 event = (reg & I40E_GL_MDET_RX_EVENT_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_EVENT_SHIFT;\n\t\tu16 queue = ((reg & I40E_GL_MDET_RX_QUEUE_MASK) >>\n\t\t\t\tI40E_GL_MDET_RX_QUEUE_SHIFT) -\n\t\t\t\tpf->hw.func_caps.base_queue;\n\t\tif (netif_msg_rx_err(pf))\n\t\t\tdev_info(&pf->pdev->dev, \"Malicious Driver Detection event 0x%02x on RX queue %d of function 0x%02x\\n\",\n\t\t\t\t event, queue, func);\n\t\twr32(hw, I40E_GL_MDET_RX, 0xffffffff);\n\t\tmdd_detected = true;\n\t}\n\n\tif (mdd_detected) {\n\t\treg = rd32(hw, I40E_PF_MDET_TX);\n\t\tif (reg & I40E_PF_MDET_TX_VALID_MASK) {\n\t\t\twr32(hw, I40E_PF_MDET_TX, 0xFFFF);\n\t\t\tdev_dbg(&pf->pdev->dev, \"TX driver issue detected on PF\\n\");\n\t\t}\n\t\treg = rd32(hw, I40E_PF_MDET_RX);\n\t\tif (reg & I40E_PF_MDET_RX_VALID_MASK) {\n\t\t\twr32(hw, I40E_PF_MDET_RX, 0xFFFF);\n\t\t\tdev_dbg(&pf->pdev->dev, \"RX driver issue detected on PF\\n\");\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < pf->num_alloc_vfs && mdd_detected; i++) {\n\t\tvf = &(pf->vf[i]);\n\t\treg = rd32(hw, I40E_VP_MDET_TX(i));\n\t\tif (reg & I40E_VP_MDET_TX_VALID_MASK) {\n\t\t\twr32(hw, I40E_VP_MDET_TX(i), 0xFFFF);\n\t\t\tvf->num_mdd_events++;\n\t\t\tdev_info(&pf->pdev->dev, \"TX driver issue detected on VF %d\\n\",\n\t\t\t\t i);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Use PF Control I/F to re-enable the VF\\n\");\n\t\t\tset_bit(I40E_VF_STATE_DISABLED, &vf->vf_states);\n\t\t}\n\n\t\treg = rd32(hw, I40E_VP_MDET_RX(i));\n\t\tif (reg & I40E_VP_MDET_RX_VALID_MASK) {\n\t\t\twr32(hw, I40E_VP_MDET_RX(i), 0xFFFF);\n\t\t\tvf->num_mdd_events++;\n\t\t\tdev_info(&pf->pdev->dev, \"RX driver issue detected on VF %d\\n\",\n\t\t\t\t i);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Use PF Control I/F to re-enable the VF\\n\");\n\t\t\tset_bit(I40E_VF_STATE_DISABLED, &vf->vf_states);\n\t\t}\n\t}\n\n\t \n\tclear_bit(__I40E_MDD_EVENT_PENDING, pf->state);\n\treg = rd32(hw, I40E_PFINT_ICR0_ENA);\n\treg |=  I40E_PFINT_ICR0_ENA_MAL_DETECT_MASK;\n\twr32(hw, I40E_PFINT_ICR0_ENA, reg);\n\ti40e_flush(hw);\n}\n\n \nstatic void i40e_service_task(struct work_struct *work)\n{\n\tstruct i40e_pf *pf = container_of(work,\n\t\t\t\t\t  struct i40e_pf,\n\t\t\t\t\t  service_task);\n\tunsigned long start_time = jiffies;\n\n\t \n\tif (test_bit(__I40E_RESET_RECOVERY_PENDING, pf->state) ||\n\t    test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn;\n\n\tif (test_and_set_bit(__I40E_SERVICE_SCHED, pf->state))\n\t\treturn;\n\n\tif (!test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\ti40e_detect_recover_hung(pf->vsi[pf->lan_vsi]);\n\t\ti40e_sync_filters_subtask(pf);\n\t\ti40e_reset_subtask(pf);\n\t\ti40e_handle_mdd_event(pf);\n\t\ti40e_vc_process_vflr_event(pf);\n\t\ti40e_watchdog_subtask(pf);\n\t\ti40e_fdir_reinit_subtask(pf);\n\t\tif (test_and_clear_bit(__I40E_CLIENT_RESET, pf->state)) {\n\t\t\t \n\t\t\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi],\n\t\t\t\t\t\t\t   true);\n\t\t} else {\n\t\t\ti40e_client_subtask(pf);\n\t\t\tif (test_and_clear_bit(__I40E_CLIENT_L2_CHANGE,\n\t\t\t\t\t       pf->state))\n\t\t\t\ti40e_notify_client_of_l2_param_changes(\n\t\t\t\t\t\t\t\tpf->vsi[pf->lan_vsi]);\n\t\t}\n\t\ti40e_sync_filters_subtask(pf);\n\t} else {\n\t\ti40e_reset_subtask(pf);\n\t}\n\n\ti40e_clean_adminq_subtask(pf);\n\n\t \n\tsmp_mb__before_atomic();\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\t \n\tif (time_after(jiffies, (start_time + pf->service_timer_period)) ||\n\t    test_bit(__I40E_ADMINQ_EVENT_PENDING, pf->state)\t\t ||\n\t    test_bit(__I40E_MDD_EVENT_PENDING, pf->state)\t\t ||\n\t    test_bit(__I40E_VFLR_EVENT_PENDING, pf->state))\n\t\ti40e_service_event_schedule(pf);\n}\n\n \nstatic void i40e_service_timer(struct timer_list *t)\n{\n\tstruct i40e_pf *pf = from_timer(pf, t, service_timer);\n\n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\ti40e_service_event_schedule(pf);\n}\n\n \nstatic int i40e_set_num_rings_in_vsi(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\tvsi->alloc_queue_pairs = pf->num_lan_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\t\tvsi->num_q_vectors = pf->num_lan_msix;\n\t\telse\n\t\t\tvsi->num_q_vectors = 1;\n\n\t\tbreak;\n\n\tcase I40E_VSI_FDIR:\n\t\tvsi->alloc_queue_pairs = 1;\n\t\tvsi->num_tx_desc = ALIGN(I40E_FDIR_RING_COUNT,\n\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_rx_desc = ALIGN(I40E_FDIR_RING_COUNT,\n\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_q_vectors = pf->num_fdsb_msix;\n\t\tbreak;\n\n\tcase I40E_VSI_VMDQ2:\n\t\tvsi->alloc_queue_pairs = pf->num_vmdq_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tvsi->num_q_vectors = pf->num_vmdq_msix;\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\t\tvsi->alloc_queue_pairs = pf->num_vf_qps;\n\t\tif (!vsi->num_tx_desc)\n\t\t\tvsi->num_tx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tif (!vsi->num_rx_desc)\n\t\t\tvsi->num_rx_desc = ALIGN(I40E_DEFAULT_NUM_DESCRIPTORS,\n\t\t\t\t\t\t I40E_REQ_DESCRIPTOR_MULTIPLE);\n\t\tbreak;\n\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -ENODATA;\n\t}\n\n\tif (is_kdump_kernel()) {\n\t\tvsi->num_tx_desc = I40E_MIN_NUM_DESCRIPTORS;\n\t\tvsi->num_rx_desc = I40E_MIN_NUM_DESCRIPTORS;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int i40e_vsi_alloc_arrays(struct i40e_vsi *vsi, bool alloc_qvectors)\n{\n\tstruct i40e_ring **next_rings;\n\tint size;\n\tint ret = 0;\n\n\t \n\tsize = sizeof(struct i40e_ring *) * vsi->alloc_queue_pairs *\n\t       (i40e_enabled_xdp_vsi(vsi) ? 3 : 2);\n\tvsi->tx_rings = kzalloc(size, GFP_KERNEL);\n\tif (!vsi->tx_rings)\n\t\treturn -ENOMEM;\n\tnext_rings = vsi->tx_rings + vsi->alloc_queue_pairs;\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tvsi->xdp_rings = next_rings;\n\t\tnext_rings += vsi->alloc_queue_pairs;\n\t}\n\tvsi->rx_rings = next_rings;\n\n\tif (alloc_qvectors) {\n\t\t \n\t\tsize = sizeof(struct i40e_q_vector *) * vsi->num_q_vectors;\n\t\tvsi->q_vectors = kzalloc(size, GFP_KERNEL);\n\t\tif (!vsi->q_vectors) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_vectors;\n\t\t}\n\t}\n\treturn ret;\n\nerr_vectors:\n\tkfree(vsi->tx_rings);\n\treturn ret;\n}\n\n \nstatic int i40e_vsi_mem_alloc(struct i40e_pf *pf, enum i40e_vsi_type type)\n{\n\tint ret = -ENODEV;\n\tstruct i40e_vsi *vsi;\n\tint vsi_idx;\n\tint i;\n\n\t \n\tmutex_lock(&pf->switch_mutex);\n\n\t \n\ti = pf->next_vsi;\n\twhile (i < pf->num_alloc_vsi && pf->vsi[i])\n\t\ti++;\n\tif (i >= pf->num_alloc_vsi) {\n\t\ti = 0;\n\t\twhile (i < pf->next_vsi && pf->vsi[i])\n\t\t\ti++;\n\t}\n\n\tif (i < pf->num_alloc_vsi && !pf->vsi[i]) {\n\t\tvsi_idx = i;              \n\t} else {\n\t\tret = -ENODEV;\n\t\tgoto unlock_pf;   \n\t}\n\tpf->next_vsi = ++i;\n\n\tvsi = kzalloc(sizeof(*vsi), GFP_KERNEL);\n\tif (!vsi) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock_pf;\n\t}\n\tvsi->type = type;\n\tvsi->back = pf;\n\tset_bit(__I40E_VSI_DOWN, vsi->state);\n\tvsi->flags = 0;\n\tvsi->idx = vsi_idx;\n\tvsi->int_rate_limit = 0;\n\tvsi->rss_table_size = (vsi->type == I40E_VSI_MAIN) ?\n\t\t\t\tpf->rss_table_size : 64;\n\tvsi->netdev_registered = false;\n\tvsi->work_limit = I40E_DEFAULT_IRQ_WORK;\n\thash_init(vsi->mac_filter_hash);\n\tvsi->irqs_ready = false;\n\n\tif (type == I40E_VSI_MAIN) {\n\t\tvsi->af_xdp_zc_qps = bitmap_zalloc(pf->num_lan_qps, GFP_KERNEL);\n\t\tif (!vsi->af_xdp_zc_qps)\n\t\t\tgoto err_rings;\n\t}\n\n\tret = i40e_set_num_rings_in_vsi(vsi);\n\tif (ret)\n\t\tgoto err_rings;\n\n\tret = i40e_vsi_alloc_arrays(vsi, true);\n\tif (ret)\n\t\tgoto err_rings;\n\n\t \n\ti40e_vsi_setup_irqhandler(vsi, i40e_msix_clean_rings);\n\n\t \n\tspin_lock_init(&vsi->mac_filter_hash_lock);\n\tpf->vsi[vsi_idx] = vsi;\n\tret = vsi_idx;\n\tgoto unlock_pf;\n\nerr_rings:\n\tbitmap_free(vsi->af_xdp_zc_qps);\n\tpf->next_vsi = i - 1;\n\tkfree(vsi);\nunlock_pf:\n\tmutex_unlock(&pf->switch_mutex);\n\treturn ret;\n}\n\n \nstatic void i40e_vsi_free_arrays(struct i40e_vsi *vsi, bool free_qvectors)\n{\n\t \n\tif (free_qvectors) {\n\t\tkfree(vsi->q_vectors);\n\t\tvsi->q_vectors = NULL;\n\t}\n\tkfree(vsi->tx_rings);\n\tvsi->tx_rings = NULL;\n\tvsi->rx_rings = NULL;\n\tvsi->xdp_rings = NULL;\n}\n\n \nstatic void i40e_clear_rss_config_user(struct i40e_vsi *vsi)\n{\n\tif (!vsi)\n\t\treturn;\n\n\tkfree(vsi->rss_hkey_user);\n\tvsi->rss_hkey_user = NULL;\n\n\tkfree(vsi->rss_lut_user);\n\tvsi->rss_lut_user = NULL;\n}\n\n \nstatic int i40e_vsi_clear(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf;\n\n\tif (!vsi)\n\t\treturn 0;\n\n\tif (!vsi->back)\n\t\tgoto free_vsi;\n\tpf = vsi->back;\n\n\tmutex_lock(&pf->switch_mutex);\n\tif (!pf->vsi[vsi->idx]) {\n\t\tdev_err(&pf->pdev->dev, \"pf->vsi[%d] is NULL, just free vsi[%d](type %d)\\n\",\n\t\t\tvsi->idx, vsi->idx, vsi->type);\n\t\tgoto unlock_vsi;\n\t}\n\n\tif (pf->vsi[vsi->idx] != vsi) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"pf->vsi[%d](type %d) != vsi[%d](type %d): no free!\\n\",\n\t\t\tpf->vsi[vsi->idx]->idx,\n\t\t\tpf->vsi[vsi->idx]->type,\n\t\t\tvsi->idx, vsi->type);\n\t\tgoto unlock_vsi;\n\t}\n\n\t \n\ti40e_put_lump(pf->qp_pile, vsi->base_queue, vsi->idx);\n\ti40e_put_lump(pf->irq_pile, vsi->base_vector, vsi->idx);\n\n\tbitmap_free(vsi->af_xdp_zc_qps);\n\ti40e_vsi_free_arrays(vsi, true);\n\ti40e_clear_rss_config_user(vsi);\n\n\tpf->vsi[vsi->idx] = NULL;\n\tif (vsi->idx < pf->next_vsi)\n\t\tpf->next_vsi = vsi->idx;\n\nunlock_vsi:\n\tmutex_unlock(&pf->switch_mutex);\nfree_vsi:\n\tkfree(vsi);\n\n\treturn 0;\n}\n\n \nstatic void i40e_vsi_clear_rings(struct i40e_vsi *vsi)\n{\n\tint i;\n\n\tif (vsi->tx_rings && vsi->tx_rings[0]) {\n\t\tfor (i = 0; i < vsi->alloc_queue_pairs; i++) {\n\t\t\tkfree_rcu(vsi->tx_rings[i], rcu);\n\t\t\tWRITE_ONCE(vsi->tx_rings[i], NULL);\n\t\t\tWRITE_ONCE(vsi->rx_rings[i], NULL);\n\t\t\tif (vsi->xdp_rings)\n\t\t\t\tWRITE_ONCE(vsi->xdp_rings[i], NULL);\n\t\t}\n\t}\n}\n\n \nstatic int i40e_alloc_rings(struct i40e_vsi *vsi)\n{\n\tint i, qpv = i40e_enabled_xdp_vsi(vsi) ? 3 : 2;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_ring *ring;\n\n\t \n\tfor (i = 0; i < vsi->alloc_queue_pairs; i++) {\n\t\t \n\t\tring = kcalloc(qpv, sizeof(struct i40e_ring), GFP_KERNEL);\n\t\tif (!ring)\n\t\t\tgoto err_out;\n\n\t\tring->queue_index = i;\n\t\tring->reg_idx = vsi->base_queue + i;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = vsi->netdev;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_tx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tif (vsi->back->hw_features & I40E_HW_WB_ON_ITR_CAPABLE)\n\t\t\tring->flags = I40E_TXR_FLAGS_WB_ON_ITR;\n\t\tring->itr_setting = pf->tx_itr_default;\n\t\tWRITE_ONCE(vsi->tx_rings[i], ring++);\n\n\t\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\t\tgoto setup_rx;\n\n\t\tring->queue_index = vsi->alloc_queue_pairs + i;\n\t\tring->reg_idx = vsi->base_queue + ring->queue_index;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = NULL;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_tx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tif (vsi->back->hw_features & I40E_HW_WB_ON_ITR_CAPABLE)\n\t\t\tring->flags = I40E_TXR_FLAGS_WB_ON_ITR;\n\t\tset_ring_xdp(ring);\n\t\tring->itr_setting = pf->tx_itr_default;\n\t\tWRITE_ONCE(vsi->xdp_rings[i], ring++);\n\nsetup_rx:\n\t\tring->queue_index = i;\n\t\tring->reg_idx = vsi->base_queue + i;\n\t\tring->ring_active = false;\n\t\tring->vsi = vsi;\n\t\tring->netdev = vsi->netdev;\n\t\tring->dev = &pf->pdev->dev;\n\t\tring->count = vsi->num_rx_desc;\n\t\tring->size = 0;\n\t\tring->dcb_tc = 0;\n\t\tring->itr_setting = pf->rx_itr_default;\n\t\tWRITE_ONCE(vsi->rx_rings[i], ring);\n\t}\n\n\treturn 0;\n\nerr_out:\n\ti40e_vsi_clear_rings(vsi);\n\treturn -ENOMEM;\n}\n\n \nstatic int i40e_reserve_msix_vectors(struct i40e_pf *pf, int vectors)\n{\n\tvectors = pci_enable_msix_range(pf->pdev, pf->msix_entries,\n\t\t\t\t\tI40E_MIN_MSIX, vectors);\n\tif (vectors < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"MSI-X vector reservation failed: %d\\n\", vectors);\n\t\tvectors = 0;\n\t}\n\n\treturn vectors;\n}\n\n \nstatic int i40e_init_msix(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint cpus, extra_vectors;\n\tint vectors_left;\n\tint v_budget, i;\n\tint v_actual;\n\tint iwarp_requested = 0;\n\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\treturn -ENODEV;\n\n\t \n\tvectors_left = hw->func_caps.num_msix_vectors;\n\tv_budget = 0;\n\n\t \n\tif (vectors_left) {\n\t\tv_budget++;\n\t\tvectors_left--;\n\t}\n\n\t \n\tcpus = num_online_cpus();\n\tpf->num_lan_msix = min_t(int, cpus, vectors_left / 2);\n\tvectors_left -= pf->num_lan_msix;\n\n\t \n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tif (vectors_left) {\n\t\t\tpf->num_fdsb_msix = 1;\n\t\t\tv_budget++;\n\t\t\tvectors_left--;\n\t\t} else {\n\t\t\tpf->num_fdsb_msix = 0;\n\t\t}\n\t}\n\n\t \n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tiwarp_requested = pf->num_iwarp_msix;\n\n\t\tif (!vectors_left)\n\t\t\tpf->num_iwarp_msix = 0;\n\t\telse if (vectors_left < pf->num_iwarp_msix)\n\t\t\tpf->num_iwarp_msix = 1;\n\t\tv_budget += pf->num_iwarp_msix;\n\t\tvectors_left -= pf->num_iwarp_msix;\n\t}\n\n\t \n\tif (pf->flags & I40E_FLAG_VMDQ_ENABLED) {\n\t\tif (!vectors_left) {\n\t\t\tpf->num_vmdq_msix = 0;\n\t\t\tpf->num_vmdq_qps = 0;\n\t\t} else {\n\t\t\tint vmdq_vecs_wanted =\n\t\t\t\tpf->num_vmdq_vsis * pf->num_vmdq_qps;\n\t\t\tint vmdq_vecs =\n\t\t\t\tmin_t(int, vectors_left, vmdq_vecs_wanted);\n\n\t\t\t \n\t\t\tif (vectors_left < vmdq_vecs_wanted) {\n\t\t\t\tpf->num_vmdq_qps = 1;\n\t\t\t\tvmdq_vecs_wanted = pf->num_vmdq_vsis;\n\t\t\t\tvmdq_vecs = min_t(int,\n\t\t\t\t\t\t  vectors_left,\n\t\t\t\t\t\t  vmdq_vecs_wanted);\n\t\t\t}\n\t\t\tpf->num_vmdq_msix = pf->num_vmdq_qps;\n\n\t\t\tv_budget += vmdq_vecs;\n\t\t\tvectors_left -= vmdq_vecs;\n\t\t}\n\t}\n\n\t \n\textra_vectors = min_t(int, cpus - pf->num_lan_msix, vectors_left);\n\tpf->num_lan_msix += extra_vectors;\n\tvectors_left -= extra_vectors;\n\n\tWARN(vectors_left < 0,\n\t     \"Calculation of remaining vectors underflowed. This is an accounting bug when determining total MSI-X vectors.\\n\");\n\n\tv_budget += pf->num_lan_msix;\n\tpf->msix_entries = kcalloc(v_budget, sizeof(struct msix_entry),\n\t\t\t\t   GFP_KERNEL);\n\tif (!pf->msix_entries)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < v_budget; i++)\n\t\tpf->msix_entries[i].entry = i;\n\tv_actual = i40e_reserve_msix_vectors(pf, v_budget);\n\n\tif (v_actual < I40E_MIN_MSIX) {\n\t\tpf->flags &= ~I40E_FLAG_MSIX_ENABLED;\n\t\tkfree(pf->msix_entries);\n\t\tpf->msix_entries = NULL;\n\t\tpci_disable_msix(pf->pdev);\n\t\treturn -ENODEV;\n\n\t} else if (v_actual == I40E_MIN_MSIX) {\n\t\t \n\t\tpf->num_vmdq_vsis = 0;\n\t\tpf->num_vmdq_qps = 0;\n\t\tpf->num_lan_qps = 1;\n\t\tpf->num_lan_msix = 1;\n\n\t} else if (v_actual != v_budget) {\n\t\t \n\t\tint vec;\n\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"MSI-X vector limit reached with %d, wanted %d, attempting to redistribute vectors\\n\",\n\t\t\t v_actual, v_budget);\n\t\t \n\t\tvec = v_actual - 1;\n\n\t\t \n\t\tpf->num_vmdq_msix = 1;     \n\t\tpf->num_vmdq_vsis = 1;\n\t\tpf->num_vmdq_qps = 1;\n\n\t\t \n\t\tswitch (vec) {\n\t\tcase 2:\n\t\t\tpf->num_lan_msix = 1;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\t\tpf->num_lan_msix = 1;\n\t\t\t\tpf->num_iwarp_msix = 1;\n\t\t\t} else {\n\t\t\t\tpf->num_lan_msix = 2;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\t\tpf->num_iwarp_msix = min_t(int, (vec / 3),\n\t\t\t\t\t\t iwarp_requested);\n\t\t\t\tpf->num_vmdq_vsis = min_t(int, (vec / 3),\n\t\t\t\t\t\t  I40E_DEFAULT_NUM_VMDQ_VSI);\n\t\t\t} else {\n\t\t\t\tpf->num_vmdq_vsis = min_t(int, (vec / 2),\n\t\t\t\t\t\t  I40E_DEFAULT_NUM_VMDQ_VSI);\n\t\t\t}\n\t\t\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\t\t\tpf->num_fdsb_msix = 1;\n\t\t\t\tvec--;\n\t\t\t}\n\t\t\tpf->num_lan_msix = min_t(int,\n\t\t\t       (vec - (pf->num_iwarp_msix + pf->num_vmdq_vsis)),\n\t\t\t\t\t\t\t      pf->num_lan_msix);\n\t\t\tpf->num_lan_qps = pf->num_lan_msix;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif ((pf->flags & I40E_FLAG_FD_SB_ENABLED) &&\n\t    (pf->num_fdsb_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"Sideband Flowdir disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t}\n\tif ((pf->flags & I40E_FLAG_VMDQ_ENABLED) &&\n\t    (pf->num_vmdq_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"VMDq disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_VMDQ_ENABLED;\n\t}\n\n\tif ((pf->flags & I40E_FLAG_IWARP_ENABLED) &&\n\t    (pf->num_iwarp_msix == 0)) {\n\t\tdev_info(&pf->pdev->dev, \"IWARP disabled, not enough MSI-X vectors\\n\");\n\t\tpf->flags &= ~I40E_FLAG_IWARP_ENABLED;\n\t}\n\ti40e_debug(&pf->hw, I40E_DEBUG_INIT,\n\t\t   \"MSI-X vector distribution: PF %d, VMDq %d, FDSB %d, iWARP %d\\n\",\n\t\t   pf->num_lan_msix,\n\t\t   pf->num_vmdq_msix * pf->num_vmdq_vsis,\n\t\t   pf->num_fdsb_msix,\n\t\t   pf->num_iwarp_msix);\n\n\treturn v_actual;\n}\n\n \nstatic int i40e_vsi_alloc_q_vector(struct i40e_vsi *vsi, int v_idx)\n{\n\tstruct i40e_q_vector *q_vector;\n\n\t \n\tq_vector = kzalloc(sizeof(struct i40e_q_vector), GFP_KERNEL);\n\tif (!q_vector)\n\t\treturn -ENOMEM;\n\n\tq_vector->vsi = vsi;\n\tq_vector->v_idx = v_idx;\n\tcpumask_copy(&q_vector->affinity_mask, cpu_possible_mask);\n\n\tif (vsi->netdev)\n\t\tnetif_napi_add(vsi->netdev, &q_vector->napi, i40e_napi_poll);\n\n\t \n\tvsi->q_vectors[v_idx] = q_vector;\n\n\treturn 0;\n}\n\n \nstatic int i40e_vsi_alloc_q_vectors(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint err, v_idx, num_q_vectors;\n\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\tnum_q_vectors = vsi->num_q_vectors;\n\telse if (vsi == pf->vsi[pf->lan_vsi])\n\t\tnum_q_vectors = 1;\n\telse\n\t\treturn -EINVAL;\n\n\tfor (v_idx = 0; v_idx < num_q_vectors; v_idx++) {\n\t\terr = i40e_vsi_alloc_q_vector(vsi, v_idx);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t}\n\n\treturn 0;\n\nerr_out:\n\twhile (v_idx--)\n\t\ti40e_free_q_vector(vsi, v_idx);\n\n\treturn err;\n}\n\n \nstatic int i40e_init_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint vectors = 0;\n\tssize_t size;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tvectors = i40e_init_msix(pf);\n\t\tif (vectors < 0) {\n\t\t\tpf->flags &= ~(I40E_FLAG_MSIX_ENABLED\t|\n\t\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t\t       I40E_FLAG_RSS_ENABLED\t|\n\t\t\t\t       I40E_FLAG_DCB_CAPABLE\t|\n\t\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t\t       I40E_FLAG_SRIOV_ENABLED\t|\n\t\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\n\t\t\t \n\t\t\ti40e_determine_queue_usage(pf);\n\t\t}\n\t}\n\n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSI_ENABLED)) {\n\t\tdev_info(&pf->pdev->dev, \"MSI-X not available, trying MSI\\n\");\n\t\tvectors = pci_enable_msi(pf->pdev);\n\t\tif (vectors < 0) {\n\t\t\tdev_info(&pf->pdev->dev, \"MSI init failed - %d\\n\",\n\t\t\t\t vectors);\n\t\t\tpf->flags &= ~I40E_FLAG_MSI_ENABLED;\n\t\t}\n\t\tvectors = 1;   \n\t}\n\n\tif (!(pf->flags & (I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED)))\n\t\tdev_info(&pf->pdev->dev, \"MSI-X and MSI not available, falling back to Legacy IRQ\\n\");\n\n\t \n\tsize = sizeof(struct i40e_lump_tracking) + (sizeof(u16) * vectors);\n\tpf->irq_pile = kzalloc(size, GFP_KERNEL);\n\tif (!pf->irq_pile)\n\t\treturn -ENOMEM;\n\n\tpf->irq_pile->num_entries = vectors;\n\n\t \n\t(void)i40e_get_lump(pf, pf->irq_pile, 1, I40E_PILE_VALID_BIT - 1);\n\n\treturn 0;\n}\n\n \nstatic int i40e_restore_interrupt_scheme(struct i40e_pf *pf)\n{\n\tint err, i;\n\n\t \n\tpf->flags |= (I40E_FLAG_MSIX_ENABLED | I40E_FLAG_MSI_ENABLED);\n\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\treturn err;\n\n\t \n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i]) {\n\t\t\terr = i40e_vsi_alloc_q_vectors(pf->vsi[i]);\n\t\t\tif (err)\n\t\t\t\tgoto err_unwind;\n\t\t\ti40e_vsi_map_rings_to_vectors(pf->vsi[i]);\n\t\t}\n\t}\n\n\terr = i40e_setup_misc_vector(pf);\n\tif (err)\n\t\tgoto err_unwind;\n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED)\n\t\ti40e_client_update_msix_info(pf);\n\n\treturn 0;\n\nerr_unwind:\n\twhile (i--) {\n\t\tif (pf->vsi[i])\n\t\t\ti40e_vsi_free_q_vectors(pf->vsi[i]);\n\t}\n\n\treturn err;\n}\n\n \nstatic int i40e_setup_misc_vector_for_recovery_mode(struct i40e_pf *pf)\n{\n\tint err;\n\n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\terr = i40e_setup_misc_vector(pf);\n\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSI-X misc vector request failed, error %d\\n\",\n\t\t\t\t err);\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\tu32 flags = pf->flags & I40E_FLAG_MSI_ENABLED ? 0 : IRQF_SHARED;\n\n\t\terr = request_irq(pf->pdev->irq, i40e_intr, flags,\n\t\t\t\t  pf->int_name, pf);\n\n\t\tif (err) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"MSI/legacy misc vector request failed, error %d\\n\",\n\t\t\t\t err);\n\t\t\treturn err;\n\t\t}\n\t\ti40e_enable_misc_int_causes(pf);\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int i40e_setup_misc_vector(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tint err = 0;\n\n\t \n\tif (!test_and_set_bit(__I40E_MISC_IRQ_REQUESTED, pf->state)) {\n\t\terr = request_irq(pf->msix_entries[0].vector,\n\t\t\t\t  i40e_intr, 0, pf->int_name, pf);\n\t\tif (err) {\n\t\t\tclear_bit(__I40E_MISC_IRQ_REQUESTED, pf->state);\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"request_irq for %s failed: %d\\n\",\n\t\t\t\t pf->int_name, err);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\ti40e_enable_misc_int_causes(pf);\n\n\t \n\twr32(hw, I40E_PFINT_LNKLST0, I40E_QUEUE_END_OF_LIST);\n\twr32(hw, I40E_PFINT_ITR0(I40E_RX_ITR), I40E_ITR_8K >> 1);\n\n\ti40e_flush(hw);\n\n\ti40e_irq_dynamic_enable_icr0(pf);\n\n\treturn err;\n}\n\n \nstatic int i40e_get_rss_aq(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t   u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret = 0;\n\n\tif (seed) {\n\t\tret = i40e_aq_get_rss_key(hw, vsi->id,\n\t\t\t(struct i40e_aqc_get_set_rss_key_data *)seed);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot get RSS key, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (lut) {\n\t\tbool pf_lut = vsi->type == I40E_VSI_MAIN;\n\n\t\tret = i40e_aq_get_rss_lut(hw, vsi->id, pf_lut, lut, lut_size);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Cannot get RSS lut, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n \nstatic int i40e_config_rss_reg(struct i40e_vsi *vsi, const u8 *seed,\n\t\t\t       const u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vf_id = vsi->vf_id;\n\tu8 i;\n\n\t \n\tif (seed) {\n\t\tu32 *seed_dw = (u32 *)seed;\n\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tfor (i = 0; i <= I40E_PFQF_HKEY_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_PFQF_HKEY(i), seed_dw[i]);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\t\tfor (i = 0; i <= I40E_VFQF_HKEY1_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_VFQF_HKEY1(i, vf_id), seed_dw[i]);\n\t\t} else {\n\t\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS seed - invalid VSI type\\n\");\n\t\t}\n\t}\n\n\tif (lut) {\n\t\tu32 *lut_dw = (u32 *)lut;\n\n\t\tif (vsi->type == I40E_VSI_MAIN) {\n\t\t\tif (lut_size != I40E_HLUT_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_PFQF_HLUT(i), lut_dw[i]);\n\t\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\t\tif (lut_size != I40E_VF_HLUT_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tfor (i = 0; i <= I40E_VFQF_HLUT_MAX_INDEX; i++)\n\t\t\t\twr32(hw, I40E_VFQF_HLUT1(i, vf_id), lut_dw[i]);\n\t\t} else {\n\t\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS LUT - invalid VSI type\\n\");\n\t\t}\n\t}\n\ti40e_flush(hw);\n\n\treturn 0;\n}\n\n \nstatic int i40e_get_rss_reg(struct i40e_vsi *vsi, u8 *seed,\n\t\t\t    u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 i;\n\n\tif (seed) {\n\t\tu32 *seed_dw = (u32 *)seed;\n\n\t\tfor (i = 0; i <= I40E_PFQF_HKEY_MAX_INDEX; i++)\n\t\t\tseed_dw[i] = i40e_read_rx_ctl(hw, I40E_PFQF_HKEY(i));\n\t}\n\tif (lut) {\n\t\tu32 *lut_dw = (u32 *)lut;\n\n\t\tif (lut_size != I40E_HLUT_ARRAY_SIZE)\n\t\t\treturn -EINVAL;\n\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\tlut_dw[i] = rd32(hw, I40E_PFQF_HLUT(i));\n\t}\n\n\treturn 0;\n}\n\n \nint i40e_config_rss(struct i40e_vsi *vsi, u8 *seed, u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (pf->hw_features & I40E_HW_RSS_AQ_CAPABLE)\n\t\treturn i40e_config_rss_aq(vsi, seed, lut, lut_size);\n\telse\n\t\treturn i40e_config_rss_reg(vsi, seed, lut, lut_size);\n}\n\n \nint i40e_get_rss(struct i40e_vsi *vsi, u8 *seed, u8 *lut, u16 lut_size)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (pf->hw_features & I40E_HW_RSS_AQ_CAPABLE)\n\t\treturn i40e_get_rss_aq(vsi, seed, lut, lut_size);\n\telse\n\t\treturn i40e_get_rss_reg(vsi, seed, lut, lut_size);\n}\n\n \nvoid i40e_fill_rss_lut(struct i40e_pf *pf, u8 *lut,\n\t\t       u16 rss_table_size, u16 rss_size)\n{\n\tu16 i;\n\n\tfor (i = 0; i < rss_table_size; i++)\n\t\tlut[i] = i % rss_size;\n}\n\n \nstatic int i40e_pf_config_rss(struct i40e_pf *pf)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tu8 seed[I40E_HKEY_ARRAY_SIZE];\n\tu8 *lut;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 reg_val;\n\tu64 hena;\n\tint ret;\n\n\t \n\thena = (u64)i40e_read_rx_ctl(hw, I40E_PFQF_HENA(0)) |\n\t\t((u64)i40e_read_rx_ctl(hw, I40E_PFQF_HENA(1)) << 32);\n\thena |= i40e_pf_get_default_rss_hena(pf);\n\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(0), (u32)hena);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(1), (u32)(hena >> 32));\n\n\t \n\treg_val = i40e_read_rx_ctl(hw, I40E_PFQF_CTL_0);\n\treg_val = (pf->rss_table_size == 512) ?\n\t\t\t(reg_val | I40E_PFQF_CTL_0_HASHLUTSIZE_512) :\n\t\t\t(reg_val & ~I40E_PFQF_CTL_0_HASHLUTSIZE_512);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_CTL_0, reg_val);\n\n\t \n\tif (!vsi->rss_size) {\n\t\tu16 qcount;\n\t\t \n\t\tqcount = vsi->num_queue_pairs /\n\t\t\t (vsi->tc_config.numtc ? vsi->tc_config.numtc : 1);\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size, qcount);\n\t}\n\tif (!vsi->rss_size)\n\t\treturn -EINVAL;\n\n\tlut = kzalloc(vsi->rss_table_size, GFP_KERNEL);\n\tif (!lut)\n\t\treturn -ENOMEM;\n\n\t \n\tif (vsi->rss_lut_user)\n\t\tmemcpy(lut, vsi->rss_lut_user, vsi->rss_table_size);\n\telse\n\t\ti40e_fill_rss_lut(pf, lut, vsi->rss_table_size, vsi->rss_size);\n\n\t \n\tif (vsi->rss_hkey_user)\n\t\tmemcpy(seed, vsi->rss_hkey_user, I40E_HKEY_ARRAY_SIZE);\n\telse\n\t\tnetdev_rss_key_fill((void *)seed, I40E_HKEY_ARRAY_SIZE);\n\tret = i40e_config_rss(vsi, seed, lut, vsi->rss_table_size);\n\tkfree(lut);\n\n\treturn ret;\n}\n\n \nint i40e_reconfig_rss_queues(struct i40e_pf *pf, int queue_count)\n{\n\tstruct i40e_vsi *vsi = pf->vsi[pf->lan_vsi];\n\tint new_rss_size;\n\n\tif (!(pf->flags & I40E_FLAG_RSS_ENABLED))\n\t\treturn 0;\n\n\tqueue_count = min_t(int, queue_count, num_online_cpus());\n\tnew_rss_size = min_t(int, queue_count, pf->rss_size_max);\n\n\tif (queue_count != vsi->num_queue_pairs) {\n\t\tu16 qcount;\n\n\t\tvsi->req_queue_pairs = queue_count;\n\t\ti40e_prep_for_reset(pf);\n\t\tif (test_bit(__I40E_IN_REMOVE, pf->state))\n\t\t\treturn pf->alloc_rss_size;\n\n\t\tpf->alloc_rss_size = new_rss_size;\n\n\t\ti40e_reset_and_rebuild(pf, true, true);\n\n\t\t \n\t\tif (queue_count < vsi->rss_size) {\n\t\t\ti40e_clear_rss_config_user(vsi);\n\t\t\tdev_dbg(&pf->pdev->dev,\n\t\t\t\t\"discard user configured hash keys and lut\\n\");\n\t\t}\n\n\t\t \n\t\tqcount = vsi->num_queue_pairs / vsi->tc_config.numtc;\n\t\tvsi->rss_size = min_t(int, pf->alloc_rss_size, qcount);\n\n\t\ti40e_pf_config_rss(pf);\n\t}\n\tdev_info(&pf->pdev->dev, \"User requested queue count/HW max RSS count:  %d/%d\\n\",\n\t\t vsi->req_queue_pairs, pf->rss_size_max);\n\treturn pf->alloc_rss_size;\n}\n\n \nint i40e_get_partition_bw_setting(struct i40e_pf *pf)\n{\n\tbool min_valid, max_valid;\n\tu32 max_bw, min_bw;\n\tint status;\n\n\tstatus = i40e_read_bw_from_alt_ram(&pf->hw, &max_bw, &min_bw,\n\t\t\t\t\t   &min_valid, &max_valid);\n\n\tif (!status) {\n\t\tif (min_valid)\n\t\t\tpf->min_bw = min_bw;\n\t\tif (max_valid)\n\t\t\tpf->max_bw = max_bw;\n\t}\n\n\treturn status;\n}\n\n \nint i40e_set_partition_bw_setting(struct i40e_pf *pf)\n{\n\tstruct i40e_aqc_configure_partition_bw_data bw_data;\n\tint status;\n\n\tmemset(&bw_data, 0, sizeof(bw_data));\n\n\t \n\tbw_data.pf_valid_bits = cpu_to_le16(BIT(pf->hw.pf_id));\n\tbw_data.max_bw[pf->hw.pf_id] = pf->max_bw & I40E_ALT_BW_VALUE_MASK;\n\tbw_data.min_bw[pf->hw.pf_id] = pf->min_bw & I40E_ALT_BW_VALUE_MASK;\n\n\t \n\tstatus = i40e_aq_configure_partition_bw(&pf->hw, &bw_data, NULL);\n\n\treturn status;\n}\n\n \nint i40e_commit_partition_bw_setting(struct i40e_pf *pf)\n{\n\t \n\tenum i40e_admin_queue_err last_aq_status;\n\tu16 nvm_word;\n\tint ret;\n\n\tif (pf->hw.partition_id != 1) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Commit BW only works on partition 1! This is partition %d\",\n\t\t\t pf->hw.partition_id);\n\t\tret = -EOPNOTSUPP;\n\t\tgoto bw_commit_out;\n\t}\n\n\t \n\tret = i40e_acquire_nvm(&pf->hw, I40E_RESOURCE_READ);\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot acquire NVM for read access, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\n\t \n\tret = i40e_aq_read_nvm(&pf->hw,\n\t\t\t       I40E_SR_NVM_CONTROL_WORD,\n\t\t\t       0x10, sizeof(nvm_word), &nvm_word,\n\t\t\t       false, NULL);\n\t \n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\ti40e_release_nvm(&pf->hw);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"NVM read error, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\n\t \n\tmsleep(50);\n\n\t \n\tret = i40e_acquire_nvm(&pf->hw, I40E_RESOURCE_WRITE);\n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"Cannot acquire NVM for write access, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\n\t\tgoto bw_commit_out;\n\t}\n\t \n\tret = i40e_aq_update_nvm(&pf->hw,\n\t\t\t\t I40E_SR_NVM_CONTROL_WORD,\n\t\t\t\t 0x10, sizeof(nvm_word),\n\t\t\t\t &nvm_word, true, 0, NULL);\n\t \n\tlast_aq_status = pf->hw.aq.asq_last_status;\n\ti40e_release_nvm(&pf->hw);\n\tif (ret)\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"BW settings NOT SAVED, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, last_aq_status));\nbw_commit_out:\n\n\treturn ret;\n}\n\n \nstatic bool i40e_is_total_port_shutdown_enabled(struct i40e_pf *pf)\n{\n#define I40E_TOTAL_PORT_SHUTDOWN_ENABLED\tBIT(4)\n#define I40E_FEATURES_ENABLE_PTR\t\t0x2A\n#define I40E_CURRENT_SETTING_PTR\t\t0x2B\n#define I40E_LINK_BEHAVIOR_WORD_OFFSET\t\t0x2D\n#define I40E_LINK_BEHAVIOR_WORD_LENGTH\t\t0x1\n#define I40E_LINK_BEHAVIOR_OS_FORCED_ENABLED\tBIT(0)\n#define I40E_LINK_BEHAVIOR_PORT_BIT_LENGTH\t4\n\tu16 sr_emp_sr_settings_ptr = 0;\n\tu16 features_enable = 0;\n\tu16 link_behavior = 0;\n\tint read_status = 0;\n\tbool ret = false;\n\n\tread_status = i40e_read_nvm_word(&pf->hw,\n\t\t\t\t\t I40E_SR_EMP_SR_SETTINGS_PTR,\n\t\t\t\t\t &sr_emp_sr_settings_ptr);\n\tif (read_status)\n\t\tgoto err_nvm;\n\tread_status = i40e_read_nvm_word(&pf->hw,\n\t\t\t\t\t sr_emp_sr_settings_ptr +\n\t\t\t\t\t I40E_FEATURES_ENABLE_PTR,\n\t\t\t\t\t &features_enable);\n\tif (read_status)\n\t\tgoto err_nvm;\n\tif (I40E_TOTAL_PORT_SHUTDOWN_ENABLED & features_enable) {\n\t\tread_status = i40e_read_nvm_module_data(&pf->hw,\n\t\t\t\t\t\t\tI40E_SR_EMP_SR_SETTINGS_PTR,\n\t\t\t\t\t\t\tI40E_CURRENT_SETTING_PTR,\n\t\t\t\t\t\t\tI40E_LINK_BEHAVIOR_WORD_OFFSET,\n\t\t\t\t\t\t\tI40E_LINK_BEHAVIOR_WORD_LENGTH,\n\t\t\t\t\t\t\t&link_behavior);\n\t\tif (read_status)\n\t\t\tgoto err_nvm;\n\t\tlink_behavior >>= (pf->hw.port * I40E_LINK_BEHAVIOR_PORT_BIT_LENGTH);\n\t\tret = I40E_LINK_BEHAVIOR_OS_FORCED_ENABLED & link_behavior;\n\t}\n\treturn ret;\n\nerr_nvm:\n\tdev_warn(&pf->pdev->dev,\n\t\t \"total-port-shutdown feature is off due to read nvm error: %pe\\n\",\n\t\t ERR_PTR(read_status));\n\treturn ret;\n}\n\n \nstatic int i40e_sw_init(struct i40e_pf *pf)\n{\n\tint err = 0;\n\tint size;\n\tu16 pow;\n\n\t \n\tpf->flags = I40E_FLAG_RX_CSUM_ENABLED |\n\t\t    I40E_FLAG_MSI_ENABLED     |\n\t\t    I40E_FLAG_MSIX_ENABLED;\n\n\t \n\tpf->rx_itr_default = I40E_ITR_RX_DEF;\n\tpf->tx_itr_default = I40E_ITR_TX_DEF;\n\n\t \n\tpf->rss_size_max = BIT(pf->hw.func_caps.rss_table_entry_width);\n\tpf->alloc_rss_size = 1;\n\tpf->rss_table_size = pf->hw.func_caps.rss_table_size;\n\tpf->rss_size_max = min_t(int, pf->rss_size_max,\n\t\t\t\t pf->hw.func_caps.num_tx_qp);\n\n\t \n\tpow = roundup_pow_of_two(num_online_cpus());\n\tpf->rss_size_max = min_t(int, pf->rss_size_max, pow);\n\n\tif (pf->hw.func_caps.rss) {\n\t\tpf->flags |= I40E_FLAG_RSS_ENABLED;\n\t\tpf->alloc_rss_size = min_t(int, pf->rss_size_max,\n\t\t\t\t\t   num_online_cpus());\n\t}\n\n\t \n\tif (pf->hw.func_caps.npar_enable || pf->hw.func_caps.flex10_enable) {\n\t\tpf->flags |= I40E_FLAG_MFP_ENABLED;\n\t\tdev_info(&pf->pdev->dev, \"MFP mode Enabled\\n\");\n\t\tif (i40e_get_partition_bw_setting(pf)) {\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"Could not get partition bw settings\\n\");\n\t\t} else {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Partition BW Min = %8.8x, Max = %8.8x\\n\",\n\t\t\t\t pf->min_bw, pf->max_bw);\n\n\t\t\t \n\t\t\ti40e_set_partition_bw_setting(pf);\n\t\t}\n\t}\n\n\tif ((pf->hw.func_caps.fd_filters_guaranteed > 0) ||\n\t    (pf->hw.func_caps.fd_filters_best_effort > 0)) {\n\t\tpf->flags |= I40E_FLAG_FD_ATR_ENABLED;\n\t\tpf->atr_sample_rate = I40E_DEFAULT_ATR_SAMPLE_RATE;\n\t\tif (pf->flags & I40E_FLAG_MFP_ENABLED &&\n\t\t    pf->hw.num_partitions > 1)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"Flow Director Sideband mode Disabled in MFP mode\\n\");\n\t\telse\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\tpf->fdir_pf_filter_count =\n\t\t\t\t pf->hw.func_caps.fd_filters_guaranteed;\n\t\tpf->hw.fdir_shared_filter_count =\n\t\t\t\t pf->hw.func_caps.fd_filters_best_effort;\n\t}\n\n\tif (pf->hw.mac.type == I40E_MAC_X722) {\n\t\tpf->hw_features |= (I40E_HW_RSS_AQ_CAPABLE |\n\t\t\t\t    I40E_HW_128_QP_RSS_CAPABLE |\n\t\t\t\t    I40E_HW_ATR_EVICT_CAPABLE |\n\t\t\t\t    I40E_HW_WB_ON_ITR_CAPABLE |\n\t\t\t\t    I40E_HW_MULTIPLE_TCP_UDP_RSS_PCTYPE |\n\t\t\t\t    I40E_HW_NO_PCI_LINK_CHECK |\n\t\t\t\t    I40E_HW_USE_SET_LLDP_MIB |\n\t\t\t\t    I40E_HW_GENEVE_OFFLOAD_CAPABLE |\n\t\t\t\t    I40E_HW_PTP_L4_CAPABLE |\n\t\t\t\t    I40E_HW_WOL_MC_MAGIC_PKT_WAKE |\n\t\t\t\t    I40E_HW_OUTER_UDP_CSUM_CAPABLE);\n\n#define I40E_FDEVICT_PCTYPE_DEFAULT 0xc03\n\t\tif (rd32(&pf->hw, I40E_GLQF_FDEVICTENA(1)) !=\n\t\t    I40E_FDEVICT_PCTYPE_DEFAULT) {\n\t\t\tdev_warn(&pf->pdev->dev,\n\t\t\t\t \"FD EVICT PCTYPES are not right, disable FD HW EVICT\\n\");\n\t\t\tpf->hw_features &= ~I40E_HW_ATR_EVICT_CAPABLE;\n\t\t}\n\t} else if ((pf->hw.aq.api_maj_ver > 1) ||\n\t\t   ((pf->hw.aq.api_maj_ver == 1) &&\n\t\t    (pf->hw.aq.api_min_ver > 4))) {\n\t\t \n\t\tpf->hw_features |= I40E_HW_GENEVE_OFFLOAD_CAPABLE;\n\t}\n\n\t \n\tif (pf->hw_features & I40E_HW_ATR_EVICT_CAPABLE)\n\t\tpf->flags |= I40E_FLAG_HW_ATR_EVICT_ENABLED;\n\n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver < 33)) ||\n\t    (pf->hw.aq.fw_maj_ver < 4))) {\n\t\tpf->hw_features |= I40E_HW_RESTART_AUTONEG;\n\t\t \n\t\tpf->hw_features |= I40E_HW_NO_DCB_SUPPORT;\n\t}\n\n\t \n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver < 3)) ||\n\t    (pf->hw.aq.fw_maj_ver < 4)))\n\t\tpf->hw_features |= I40E_HW_STOP_FW_LLDP;\n\n\t \n\tif ((pf->hw.mac.type == I40E_MAC_XL710) &&\n\t    (((pf->hw.aq.fw_maj_ver == 4) && (pf->hw.aq.fw_min_ver >= 40)) ||\n\t    (pf->hw.aq.fw_maj_ver >= 5)))\n\t\tpf->hw_features |= I40E_HW_USE_SET_LLDP_MIB;\n\n\t \n\tif (pf->hw.mac.type == I40E_MAC_XL710 &&\n\t    pf->hw.aq.fw_maj_ver >= 6)\n\t\tpf->hw_features |= I40E_HW_PTP_L4_CAPABLE;\n\n\tif (pf->hw.func_caps.vmdq && num_online_cpus() != 1) {\n\t\tpf->num_vmdq_vsis = I40E_DEFAULT_NUM_VMDQ_VSI;\n\t\tpf->flags |= I40E_FLAG_VMDQ_ENABLED;\n\t\tpf->num_vmdq_qps = i40e_default_queues_per_vmdq(pf);\n\t}\n\n\tif (pf->hw.func_caps.iwarp && num_online_cpus() != 1) {\n\t\tpf->flags |= I40E_FLAG_IWARP_ENABLED;\n\t\t \n\t\tpf->num_iwarp_msix = (int)num_online_cpus() + 1;\n\t}\n\t \n\tif (pf->hw.mac.type == I40E_MAC_XL710 &&\n\t    pf->hw.func_caps.npar_enable &&\n\t    (pf->hw.flags & I40E_HW_FLAG_FW_LLDP_STOPPABLE))\n\t\tpf->hw.flags &= ~I40E_HW_FLAG_FW_LLDP_STOPPABLE;\n\n#ifdef CONFIG_PCI_IOV\n\tif (pf->hw.func_caps.num_vfs && pf->hw.partition_id == 1) {\n\t\tpf->num_vf_qps = I40E_DEFAULT_QUEUES_PER_VF;\n\t\tpf->flags |= I40E_FLAG_SRIOV_ENABLED;\n\t\tpf->num_req_vfs = min_t(int,\n\t\t\t\t\tpf->hw.func_caps.num_vfs,\n\t\t\t\t\tI40E_MAX_VF_COUNT);\n\t}\n#endif  \n\tpf->eeprom_version = 0xDEAD;\n\tpf->lan_veb = I40E_NO_VEB;\n\tpf->lan_vsi = I40E_NO_VSI;\n\n\t \n\tpf->flags &= ~I40E_FLAG_VEB_STATS_ENABLED;\n\n\t \n\tsize = sizeof(struct i40e_lump_tracking)\n\t\t+ (sizeof(u16) * pf->hw.func_caps.num_tx_qp);\n\tpf->qp_pile = kzalloc(size, GFP_KERNEL);\n\tif (!pf->qp_pile) {\n\t\terr = -ENOMEM;\n\t\tgoto sw_init_done;\n\t}\n\tpf->qp_pile->num_entries = pf->hw.func_caps.num_tx_qp;\n\n\tpf->tx_timeout_recovery_level = 1;\n\n\tif (pf->hw.mac.type != I40E_MAC_X722 &&\n\t    i40e_is_total_port_shutdown_enabled(pf)) {\n\t\t \n\t\tpf->flags |= (I40E_FLAG_TOTAL_PORT_SHUTDOWN_ENABLED |\n\t\t\t      I40E_FLAG_LINK_DOWN_ON_CLOSE_ENABLED);\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"total-port-shutdown was enabled, link-down-on-close is forced on\\n\");\n\t}\n\tmutex_init(&pf->switch_mutex);\n\nsw_init_done:\n\treturn err;\n}\n\n \nbool i40e_set_ntuple(struct i40e_pf *pf, netdev_features_t features)\n{\n\tbool need_reset = false;\n\n\t \n\tif (features & NETIF_F_NTUPLE) {\n\t\t \n\t\tif (!(pf->flags & I40E_FLAG_FD_SB_ENABLED))\n\t\t\tneed_reset = true;\n\t\t \n\t\tif (pf->num_fdsb_msix > 0 && !pf->num_cloud_filters) {\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_INACTIVE;\n\t\t}\n\t} else {\n\t\t \n\t\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\t\tneed_reset = true;\n\t\t\ti40e_fdir_filter_exit(pf);\n\t\t}\n\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\tclear_bit(__I40E_FD_SB_AUTO_DISABLED, pf->state);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\n\t\t \n\t\tpf->fd_add_err = 0;\n\t\tpf->fd_atr_cnt = 0;\n\t\t \n\t\tif (test_and_clear_bit(__I40E_FD_ATR_AUTO_DISABLED, pf->state))\n\t\t\tif ((pf->flags & I40E_FLAG_FD_ATR_ENABLED) &&\n\t\t\t    (I40E_DEBUG_FD & pf->hw.debug_mask))\n\t\t\t\tdev_info(&pf->pdev->dev, \"ATR re-enabled.\\n\");\n\t}\n\treturn need_reset;\n}\n\n \nstatic void i40e_clear_rss_lut(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu16 vf_id = vsi->vf_id;\n\tu8 i;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tfor (i = 0; i <= I40E_PFQF_HLUT_MAX_INDEX; i++)\n\t\t\twr32(hw, I40E_PFQF_HLUT(i), 0);\n\t} else if (vsi->type == I40E_VSI_SRIOV) {\n\t\tfor (i = 0; i <= I40E_VFQF_HLUT_MAX_INDEX; i++)\n\t\t\ti40e_write_rx_ctl(hw, I40E_VFQF_HLUT1(i, vf_id), 0);\n\t} else {\n\t\tdev_err(&pf->pdev->dev, \"Cannot set RSS LUT - invalid VSI type\\n\");\n\t}\n}\n\n \nstatic int i40e_set_loopback(struct i40e_vsi *vsi, bool ena)\n{\n\tbool if_running = netif_running(vsi->netdev) &&\n\t\t\t  !test_and_set_bit(__I40E_VSI_DOWN, vsi->state);\n\tint ret;\n\n\tif (if_running)\n\t\ti40e_down(vsi);\n\n\tret = i40e_aq_set_mac_loopback(&vsi->back->hw, ena, NULL);\n\tif (ret)\n\t\tnetdev_err(vsi->netdev, \"Failed to toggle loopback state\\n\");\n\tif (if_running)\n\t\ti40e_up(vsi);\n\n\treturn ret;\n}\n\n \nstatic int i40e_set_features(struct net_device *netdev,\n\t\t\t     netdev_features_t features)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tbool need_reset;\n\n\tif (features & NETIF_F_RXHASH && !(netdev->features & NETIF_F_RXHASH))\n\t\ti40e_pf_config_rss(pf);\n\telse if (!(features & NETIF_F_RXHASH) &&\n\t\t netdev->features & NETIF_F_RXHASH)\n\t\ti40e_clear_rss_lut(vsi);\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\ti40e_vlan_stripping_enable(vsi);\n\telse\n\t\ti40e_vlan_stripping_disable(vsi);\n\n\tif (!(features & NETIF_F_HW_TC) &&\n\t    (netdev->features & NETIF_F_HW_TC) && pf->num_cloud_filters) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Offloaded tc filters active, can't turn hw_tc_offload off\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!(features & NETIF_F_HW_L2FW_DOFFLOAD) && vsi->macvlan_cnt)\n\t\ti40e_del_all_macvlans(vsi);\n\n\tneed_reset = i40e_set_ntuple(pf, features);\n\n\tif (need_reset)\n\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\n\tif ((features ^ netdev->features) & NETIF_F_LOOPBACK)\n\t\treturn i40e_set_loopback(vsi, !!(features & NETIF_F_LOOPBACK));\n\n\treturn 0;\n}\n\nstatic int i40e_udp_tunnel_set_port(struct net_device *netdev,\n\t\t\t\t    unsigned int table, unsigned int idx,\n\t\t\t\t    struct udp_tunnel_info *ti)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_hw *hw = &np->vsi->back->hw;\n\tu8 type, filter_index;\n\tint ret;\n\n\ttype = ti->type == UDP_TUNNEL_TYPE_VXLAN ? I40E_AQC_TUNNEL_TYPE_VXLAN :\n\t\t\t\t\t\t   I40E_AQC_TUNNEL_TYPE_NGE;\n\n\tret = i40e_aq_add_udp_tunnel(hw, ntohs(ti->port), type, &filter_index,\n\t\t\t\t     NULL);\n\tif (ret) {\n\t\tnetdev_info(netdev, \"add UDP port failed, err %pe aq_err %s\\n\",\n\t\t\t    ERR_PTR(ret),\n\t\t\t    i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn -EIO;\n\t}\n\n\tudp_tunnel_nic_set_port_priv(netdev, table, idx, filter_index);\n\treturn 0;\n}\n\nstatic int i40e_udp_tunnel_unset_port(struct net_device *netdev,\n\t\t\t\t      unsigned int table, unsigned int idx,\n\t\t\t\t      struct udp_tunnel_info *ti)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_hw *hw = &np->vsi->back->hw;\n\tint ret;\n\n\tret = i40e_aq_del_udp_tunnel(hw, ti->hw_priv, NULL);\n\tif (ret) {\n\t\tnetdev_info(netdev, \"delete UDP port failed, err %pe aq_err %s\\n\",\n\t\t\t    ERR_PTR(ret),\n\t\t\t    i40e_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic int i40e_get_phys_port_id(struct net_device *netdev,\n\t\t\t\t struct netdev_phys_item_id *ppid)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(netdev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tif (!(pf->hw_features & I40E_HW_PORT_ID_VALID))\n\t\treturn -EOPNOTSUPP;\n\n\tppid->id_len = min_t(int, sizeof(hw->mac.port_addr), sizeof(ppid->id));\n\tmemcpy(ppid->id, hw->mac.port_addr, ppid->id_len);\n\n\treturn 0;\n}\n\n \nstatic int i40e_ndo_fdb_add(struct ndmsg *ndm, struct nlattr *tb[],\n\t\t\t    struct net_device *dev,\n\t\t\t    const unsigned char *addr, u16 vid,\n\t\t\t    u16 flags,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_pf *pf = np->vsi->back;\n\tint err = 0;\n\n\tif (!(pf->flags & I40E_FLAG_SRIOV_ENABLED))\n\t\treturn -EOPNOTSUPP;\n\n\tif (vid) {\n\t\tpr_info(\"%s: vlans aren't supported yet for dev_uc|mc_add()\\n\", dev->name);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (ndm->ndm_state && !(ndm->ndm_state & NUD_PERMANENT)) {\n\t\tnetdev_info(dev, \"FDB only supports static addresses\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (is_unicast_ether_addr(addr) || is_link_local_ether_addr(addr))\n\t\terr = dev_uc_add_excl(dev, addr);\n\telse if (is_multicast_ether_addr(addr))\n\t\terr = dev_mc_add_excl(dev, addr);\n\telse\n\t\terr = -EINVAL;\n\n\t \n\tif (err == -EEXIST && !(flags & NLM_F_EXCL))\n\t\terr = 0;\n\n\treturn err;\n}\n\n \nstatic int i40e_ndo_bridge_setlink(struct net_device *dev,\n\t\t\t\t   struct nlmsghdr *nlh,\n\t\t\t\t   u16 flags,\n\t\t\t\t   struct netlink_ext_ack *extack)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_veb *veb = NULL;\n\tstruct nlattr *attr, *br_spec;\n\tint i, rem;\n\n\t \n\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\n\tbr_spec = nlmsg_find_attr(nlh, sizeof(struct ifinfomsg), IFLA_AF_SPEC);\n\tif (!br_spec)\n\t\treturn -EINVAL;\n\n\tnla_for_each_nested(attr, br_spec, rem) {\n\t\t__u16 mode;\n\n\t\tif (nla_type(attr) != IFLA_BRIDGE_MODE)\n\t\t\tcontinue;\n\n\t\tmode = nla_get_u16(attr);\n\t\tif ((mode != BRIDGE_MODE_VEPA) &&\n\t\t    (mode != BRIDGE_MODE_VEB))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (!veb) {\n\t\t\tveb = i40e_veb_setup(pf, 0, vsi->uplink_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\t\tif (veb) {\n\t\t\t\tveb->bridge_mode = mode;\n\t\t\t\ti40e_config_bridge_mode(veb);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\treturn -ENOENT;\n\t\t\t}\n\t\t\tbreak;\n\t\t} else if (mode != veb->bridge_mode) {\n\t\t\t \n\t\t\tveb->bridge_mode = mode;\n\t\t\t \n\t\t\tif (mode == BRIDGE_MODE_VEB)\n\t\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\telse\n\t\t\t\tpf->flags &= ~I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\ti40e_do_reset(pf, I40E_PF_RESET_FLAG, true);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int i40e_ndo_bridge_getlink(struct sk_buff *skb, u32 pid, u32 seq,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   u32 __always_unused filter_mask,\n\t\t\t\t   int nlflags)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_veb *veb = NULL;\n\tint i;\n\n\t \n\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\n\tif (!veb)\n\t\treturn 0;\n\n\treturn ndo_dflt_bridge_getlink(skb, pid, seq, dev, veb->bridge_mode,\n\t\t\t\t       0, 0, nlflags, filter_mask, NULL);\n}\n\n \nstatic netdev_features_t i40e_features_check(struct sk_buff *skb,\n\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t     netdev_features_t features)\n{\n\tsize_t len;\n\n\t \n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn features;\n\n\t \n\tif (skb_is_gso(skb) && (skb_shinfo(skb)->gso_size < 64))\n\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\n\t \n\tlen = skb_network_header(skb) - skb->data;\n\tif (len & ~(63 * 2))\n\t\tgoto out_err;\n\n\t \n\tlen = skb_transport_header(skb) - skb_network_header(skb);\n\tif (len & ~(127 * 4))\n\t\tgoto out_err;\n\n\tif (skb->encapsulation) {\n\t\t \n\t\tlen = skb_inner_network_header(skb) - skb_transport_header(skb);\n\t\tif (len & ~(127 * 2))\n\t\t\tgoto out_err;\n\n\t\t \n\t\tlen = skb_inner_transport_header(skb) -\n\t\t      skb_inner_network_header(skb);\n\t\tif (len & ~(127 * 4))\n\t\t\tgoto out_err;\n\t}\n\n\t \n\n\treturn features;\nout_err:\n\treturn features & ~(NETIF_F_CSUM_MASK | NETIF_F_GSO_MASK);\n}\n\n \nstatic int i40e_xdp_setup(struct i40e_vsi *vsi, struct bpf_prog *prog,\n\t\t\t  struct netlink_ext_ack *extack)\n{\n\tint frame_size = i40e_max_vsi_frame_size(vsi, prog);\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct bpf_prog *old_prog;\n\tbool need_reset;\n\tint i;\n\n\t \n\tif (vsi->netdev->mtu > frame_size - I40E_PACKET_HDR_PAD) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"MTU too large for linear frames and XDP prog does not support frags\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tneed_reset = (i40e_enabled_xdp_vsi(vsi) != !!prog);\n\n\tif (need_reset)\n\t\ti40e_prep_for_reset(pf);\n\n\t \n\tif (test_bit(__I40E_IN_REMOVE, pf->state))\n\t\treturn -EINVAL;\n\n\told_prog = xchg(&vsi->xdp_prog, prog);\n\n\tif (need_reset) {\n\t\tif (!prog) {\n\t\t\txdp_features_clear_redirect_target(vsi->netdev);\n\t\t\t \n\t\t\tsynchronize_rcu();\n\t\t}\n\t\ti40e_reset_and_rebuild(pf, true, true);\n\t}\n\n\tif (!i40e_enabled_xdp_vsi(vsi) && prog) {\n\t\tif (i40e_realloc_rx_bi_zc(vsi, true))\n\t\t\treturn -ENOMEM;\n\t} else if (i40e_enabled_xdp_vsi(vsi) && !prog) {\n\t\tif (i40e_realloc_rx_bi_zc(vsi, false))\n\t\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\tWRITE_ONCE(vsi->rx_rings[i]->xdp_prog, vsi->xdp_prog);\n\n\tif (old_prog)\n\t\tbpf_prog_put(old_prog);\n\n\t \n\tif (need_reset && prog) {\n\t\tfor (i = 0; i < vsi->num_queue_pairs; i++)\n\t\t\tif (vsi->xdp_rings[i]->xsk_pool)\n\t\t\t\t(void)i40e_xsk_wakeup(vsi->netdev, i,\n\t\t\t\t\t\t      XDP_WAKEUP_RX);\n\t\txdp_features_set_redirect_target(vsi->netdev, true);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int i40e_enter_busy_conf(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint timeout = 50;\n\n\twhile (test_and_set_bit(__I40E_CONFIG_BUSY, pf->state)) {\n\t\ttimeout--;\n\t\tif (!timeout)\n\t\t\treturn -EBUSY;\n\t\tusleep_range(1000, 2000);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void i40e_exit_busy_conf(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\n\tclear_bit(__I40E_CONFIG_BUSY, pf->state);\n}\n\n \nstatic void i40e_queue_pair_reset_stats(struct i40e_vsi *vsi, int queue_pair)\n{\n\tmemset(&vsi->rx_rings[queue_pair]->rx_stats, 0,\n\t       sizeof(vsi->rx_rings[queue_pair]->rx_stats));\n\tmemset(&vsi->tx_rings[queue_pair]->stats, 0,\n\t       sizeof(vsi->tx_rings[queue_pair]->stats));\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\tmemset(&vsi->xdp_rings[queue_pair]->stats, 0,\n\t\t       sizeof(vsi->xdp_rings[queue_pair]->stats));\n\t}\n}\n\n \nstatic void i40e_queue_pair_clean_rings(struct i40e_vsi *vsi, int queue_pair)\n{\n\ti40e_clean_tx_ring(vsi->tx_rings[queue_pair]);\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\t \n\t\tsynchronize_rcu();\n\t\ti40e_clean_tx_ring(vsi->xdp_rings[queue_pair]);\n\t}\n\ti40e_clean_rx_ring(vsi->rx_rings[queue_pair]);\n}\n\n \nstatic void i40e_queue_pair_toggle_napi(struct i40e_vsi *vsi, int queue_pair,\n\t\t\t\t\tbool enable)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_q_vector *q_vector = rxr->q_vector;\n\n\tif (!vsi->netdev)\n\t\treturn;\n\n\t \n\tif (q_vector->rx.ring || q_vector->tx.ring) {\n\t\tif (enable)\n\t\t\tnapi_enable(&q_vector->napi);\n\t\telse\n\t\t\tnapi_disable(&q_vector->napi);\n\t}\n}\n\n \nstatic int i40e_queue_pair_toggle_rings(struct i40e_vsi *vsi, int queue_pair,\n\t\t\t\t\tbool enable)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tint pf_q, ret = 0;\n\n\tpf_q = vsi->base_queue + queue_pair;\n\tret = i40e_control_wait_tx_q(vsi->seid, pf, pf_q,\n\t\t\t\t     false  , enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d Tx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\treturn ret;\n\t}\n\n\ti40e_control_rx_q(pf, pf_q, enable);\n\tret = i40e_pf_rxq_wait(pf, pf_q, enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d Rx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t\treturn ret;\n\t}\n\n\t \n\tif (!enable)\n\t\tmdelay(50);\n\n\tif (!i40e_enabled_xdp_vsi(vsi))\n\t\treturn ret;\n\n\tret = i40e_control_wait_tx_q(vsi->seid, pf,\n\t\t\t\t     pf_q + vsi->alloc_queue_pairs,\n\t\t\t\t     true  , enable);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"VSI seid %d XDP Tx ring %d %sable timeout\\n\",\n\t\t\t vsi->seid, pf_q, (enable ? \"en\" : \"dis\"));\n\t}\n\n\treturn ret;\n}\n\n \nstatic void i40e_queue_pair_enable_irq(struct i40e_vsi *vsi, int queue_pair)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED)\n\t\ti40e_irq_dynamic_enable(vsi, rxr->q_vector->v_idx);\n\telse\n\t\ti40e_irq_dynamic_enable_icr0(pf);\n\n\ti40e_flush(hw);\n}\n\n \nstatic void i40e_queue_pair_disable_irq(struct i40e_vsi *vsi, int queue_pair)\n{\n\tstruct i40e_ring *rxr = vsi->rx_rings[queue_pair];\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\tu32 intpf = vsi->base_vector + rxr->q_vector->v_idx;\n\n\t\twr32(hw, I40E_PFINT_DYN_CTLN(intpf - 1), 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->msix_entries[intpf].vector);\n\t} else {\n\t\t \n\t\twr32(hw, I40E_PFINT_ICR0_ENA, 0);\n\t\twr32(hw, I40E_PFINT_DYN_CTL0, 0);\n\t\ti40e_flush(hw);\n\t\tsynchronize_irq(pf->pdev->irq);\n\t}\n}\n\n \nint i40e_queue_pair_disable(struct i40e_vsi *vsi, int queue_pair)\n{\n\tint err;\n\n\terr = i40e_enter_busy_conf(vsi);\n\tif (err)\n\t\treturn err;\n\n\ti40e_queue_pair_disable_irq(vsi, queue_pair);\n\terr = i40e_queue_pair_toggle_rings(vsi, queue_pair, false  );\n\ti40e_clean_rx_ring(vsi->rx_rings[queue_pair]);\n\ti40e_queue_pair_toggle_napi(vsi, queue_pair, false  );\n\ti40e_queue_pair_clean_rings(vsi, queue_pair);\n\ti40e_queue_pair_reset_stats(vsi, queue_pair);\n\n\treturn err;\n}\n\n \nint i40e_queue_pair_enable(struct i40e_vsi *vsi, int queue_pair)\n{\n\tint err;\n\n\terr = i40e_configure_tx_ring(vsi->tx_rings[queue_pair]);\n\tif (err)\n\t\treturn err;\n\n\tif (i40e_enabled_xdp_vsi(vsi)) {\n\t\terr = i40e_configure_tx_ring(vsi->xdp_rings[queue_pair]);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = i40e_configure_rx_ring(vsi->rx_rings[queue_pair]);\n\tif (err)\n\t\treturn err;\n\n\terr = i40e_queue_pair_toggle_rings(vsi, queue_pair, true  );\n\ti40e_queue_pair_toggle_napi(vsi, queue_pair, true  );\n\ti40e_queue_pair_enable_irq(vsi, queue_pair);\n\n\ti40e_exit_busy_conf(vsi);\n\n\treturn err;\n}\n\n \nstatic int i40e_xdp(struct net_device *dev,\n\t\t    struct netdev_bpf *xdp)\n{\n\tstruct i40e_netdev_priv *np = netdev_priv(dev);\n\tstruct i40e_vsi *vsi = np->vsi;\n\n\tif (vsi->type != I40E_VSI_MAIN)\n\t\treturn -EINVAL;\n\n\tswitch (xdp->command) {\n\tcase XDP_SETUP_PROG:\n\t\treturn i40e_xdp_setup(vsi, xdp->prog, xdp->extack);\n\tcase XDP_SETUP_XSK_POOL:\n\t\treturn i40e_xsk_pool_setup(vsi, xdp->xsk.pool,\n\t\t\t\t\t   xdp->xsk.queue_id);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic const struct net_device_ops i40e_netdev_ops = {\n\t.ndo_open\t\t= i40e_open,\n\t.ndo_stop\t\t= i40e_close,\n\t.ndo_start_xmit\t\t= i40e_lan_xmit_frame,\n\t.ndo_get_stats64\t= i40e_get_netdev_stats_struct,\n\t.ndo_set_rx_mode\t= i40e_set_rx_mode,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= i40e_set_mac,\n\t.ndo_change_mtu\t\t= i40e_change_mtu,\n\t.ndo_eth_ioctl\t\t= i40e_ioctl,\n\t.ndo_tx_timeout\t\t= i40e_tx_timeout,\n\t.ndo_vlan_rx_add_vid\t= i40e_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= i40e_vlan_rx_kill_vid,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= i40e_netpoll,\n#endif\n\t.ndo_setup_tc\t\t= __i40e_setup_tc,\n\t.ndo_select_queue\t= i40e_lan_select_queue,\n\t.ndo_set_features\t= i40e_set_features,\n\t.ndo_set_vf_mac\t\t= i40e_ndo_set_vf_mac,\n\t.ndo_set_vf_vlan\t= i40e_ndo_set_vf_port_vlan,\n\t.ndo_get_vf_stats\t= i40e_get_vf_stats,\n\t.ndo_set_vf_rate\t= i40e_ndo_set_vf_bw,\n\t.ndo_get_vf_config\t= i40e_ndo_get_vf_config,\n\t.ndo_set_vf_link_state\t= i40e_ndo_set_vf_link_state,\n\t.ndo_set_vf_spoofchk\t= i40e_ndo_set_vf_spoofchk,\n\t.ndo_set_vf_trust\t= i40e_ndo_set_vf_trust,\n\t.ndo_get_phys_port_id\t= i40e_get_phys_port_id,\n\t.ndo_fdb_add\t\t= i40e_ndo_fdb_add,\n\t.ndo_features_check\t= i40e_features_check,\n\t.ndo_bridge_getlink\t= i40e_ndo_bridge_getlink,\n\t.ndo_bridge_setlink\t= i40e_ndo_bridge_setlink,\n\t.ndo_bpf\t\t= i40e_xdp,\n\t.ndo_xdp_xmit\t\t= i40e_xdp_xmit,\n\t.ndo_xsk_wakeup\t        = i40e_xsk_wakeup,\n\t.ndo_dfwd_add_station\t= i40e_fwd_add,\n\t.ndo_dfwd_del_station\t= i40e_fwd_del,\n};\n\n \nstatic int i40e_config_netdev(struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_netdev_priv *np;\n\tstruct net_device *netdev;\n\tu8 broadcast[ETH_ALEN];\n\tu8 mac_addr[ETH_ALEN];\n\tint etherdev_size;\n\tnetdev_features_t hw_enc_features;\n\tnetdev_features_t hw_features;\n\n\tetherdev_size = sizeof(struct i40e_netdev_priv);\n\tnetdev = alloc_etherdev_mq(etherdev_size, vsi->alloc_queue_pairs);\n\tif (!netdev)\n\t\treturn -ENOMEM;\n\n\tvsi->netdev = netdev;\n\tnp = netdev_priv(netdev);\n\tnp->vsi = vsi;\n\n\thw_enc_features = NETIF_F_SG\t\t\t|\n\t\t\t  NETIF_F_HW_CSUM\t\t|\n\t\t\t  NETIF_F_HIGHDMA\t\t|\n\t\t\t  NETIF_F_SOFT_FEATURES\t\t|\n\t\t\t  NETIF_F_TSO\t\t\t|\n\t\t\t  NETIF_F_TSO_ECN\t\t|\n\t\t\t  NETIF_F_TSO6\t\t\t|\n\t\t\t  NETIF_F_GSO_GRE\t\t|\n\t\t\t  NETIF_F_GSO_GRE_CSUM\t\t|\n\t\t\t  NETIF_F_GSO_PARTIAL\t\t|\n\t\t\t  NETIF_F_GSO_IPXIP4\t\t|\n\t\t\t  NETIF_F_GSO_IPXIP6\t\t|\n\t\t\t  NETIF_F_GSO_UDP_TUNNEL\t|\n\t\t\t  NETIF_F_GSO_UDP_TUNNEL_CSUM\t|\n\t\t\t  NETIF_F_GSO_UDP_L4\t\t|\n\t\t\t  NETIF_F_SCTP_CRC\t\t|\n\t\t\t  NETIF_F_RXHASH\t\t|\n\t\t\t  NETIF_F_RXCSUM\t\t|\n\t\t\t  0;\n\n\tif (!(pf->hw_features & I40E_HW_OUTER_UDP_CSUM_CAPABLE))\n\t\tnetdev->gso_partial_features |= NETIF_F_GSO_UDP_TUNNEL_CSUM;\n\n\tnetdev->udp_tunnel_nic_info = &pf->udp_tunnel_nic;\n\n\tnetdev->gso_partial_features |= NETIF_F_GSO_GRE_CSUM;\n\n\tnetdev->hw_enc_features |= hw_enc_features;\n\n\t \n\tnetdev->vlan_features |= hw_enc_features | NETIF_F_TSO_MANGLEID;\n\n#define I40E_GSO_PARTIAL_FEATURES (NETIF_F_GSO_GRE |\t\t\\\n\t\t\t\t   NETIF_F_GSO_GRE_CSUM |\t\\\n\t\t\t\t   NETIF_F_GSO_IPXIP4 |\t\t\\\n\t\t\t\t   NETIF_F_GSO_IPXIP6 |\t\t\\\n\t\t\t\t   NETIF_F_GSO_UDP_TUNNEL |\t\\\n\t\t\t\t   NETIF_F_GSO_UDP_TUNNEL_CSUM)\n\n\tnetdev->gso_partial_features = I40E_GSO_PARTIAL_FEATURES;\n\tnetdev->features |= NETIF_F_GSO_PARTIAL |\n\t\t\t    I40E_GSO_PARTIAL_FEATURES;\n\n\tnetdev->mpls_features |= NETIF_F_SG;\n\tnetdev->mpls_features |= NETIF_F_HW_CSUM;\n\tnetdev->mpls_features |= NETIF_F_TSO;\n\tnetdev->mpls_features |= NETIF_F_TSO6;\n\tnetdev->mpls_features |= I40E_GSO_PARTIAL_FEATURES;\n\n\t \n\tnetdev->hw_features |= NETIF_F_HW_L2FW_DOFFLOAD;\n\n\thw_features = hw_enc_features\t\t|\n\t\t      NETIF_F_HW_VLAN_CTAG_TX\t|\n\t\t      NETIF_F_HW_VLAN_CTAG_RX;\n\n\tif (!(pf->flags & I40E_FLAG_MFP_ENABLED))\n\t\thw_features |= NETIF_F_NTUPLE | NETIF_F_HW_TC;\n\n\tnetdev->hw_features |= hw_features | NETIF_F_LOOPBACK;\n\n\tnetdev->features |= hw_features | NETIF_F_HW_VLAN_CTAG_FILTER;\n\tnetdev->hw_enc_features |= NETIF_F_TSO_MANGLEID;\n\n\tnetdev->features &= ~NETIF_F_HW_TC;\n\n\tif (vsi->type == I40E_VSI_MAIN) {\n\t\tSET_NETDEV_DEV(netdev, &pf->pdev->dev);\n\t\tether_addr_copy(mac_addr, hw->mac.perm_addr);\n\t\t \n\t\ti40e_rm_default_mac_filter(vsi, mac_addr);\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\ti40e_add_mac_filter(vsi, mac_addr);\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\t\tnetdev->xdp_features = NETDEV_XDP_ACT_BASIC |\n\t\t\t\t       NETDEV_XDP_ACT_REDIRECT |\n\t\t\t\t       NETDEV_XDP_ACT_XSK_ZEROCOPY |\n\t\t\t\t       NETDEV_XDP_ACT_RX_SG;\n\t\tnetdev->xdp_zc_max_segs = I40E_MAX_BUFFER_TXD;\n\t} else {\n\t\t \n\t\tsnprintf(netdev->name, IFNAMSIZ, \"%.*sv%%d\",\n\t\t\t IFNAMSIZ - 4,\n\t\t\t pf->vsi[pf->lan_vsi]->netdev->name);\n\t\teth_random_addr(mac_addr);\n\n\t\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\t\ti40e_add_mac_filter(vsi, mac_addr);\n\t\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\t}\n\n\t \n\teth_broadcast_addr(broadcast);\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\ti40e_add_mac_filter(vsi, broadcast);\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\teth_hw_addr_set(netdev, mac_addr);\n\tether_addr_copy(netdev->perm_addr, mac_addr);\n\n\t \n\tnetdev->neigh_priv_len = sizeof(u32) * 4;\n\n\tnetdev->priv_flags |= IFF_UNICAST_FLT;\n\tnetdev->priv_flags |= IFF_SUPP_NOFCS;\n\t \n\ti40e_vsi_config_netdev_tc(vsi, vsi->tc_config.enabled_tc);\n\n\tnetdev->netdev_ops = &i40e_netdev_ops;\n\tnetdev->watchdog_timeo = 5 * HZ;\n\ti40e_set_ethtool_ops(netdev);\n\n\t \n\tnetdev->min_mtu = ETH_MIN_MTU;\n\tnetdev->max_mtu = I40E_MAX_RXBUFFER - I40E_PACKET_HDR_PAD;\n\n\treturn 0;\n}\n\n \nstatic void i40e_vsi_delete(struct i40e_vsi *vsi)\n{\n\t \n\tif (vsi == vsi->back->vsi[vsi->back->lan_vsi])\n\t\treturn;\n\n\ti40e_aq_delete_element(&vsi->back->hw, vsi->seid, NULL);\n}\n\n \nint i40e_is_vsi_uplink_mode_veb(struct i40e_vsi *vsi)\n{\n\tstruct i40e_veb *veb;\n\tstruct i40e_pf *pf = vsi->back;\n\n\t \n\tif (vsi->veb_idx >= I40E_MAX_VEB)\n\t\treturn 1;\n\n\tveb = pf->veb[vsi->veb_idx];\n\tif (!veb) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"There is no veb associated with the bridge\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\t \n\tif (veb->bridge_mode & BRIDGE_MODE_VEPA) {\n\t\treturn 0;\n\t} else {\n\t\t \n\t\treturn 1;\n\t}\n\n\t \n\treturn 0;\n}\n\n \nstatic int i40e_add_vsi(struct i40e_vsi *vsi)\n{\n\tint ret = -ENODEV;\n\tstruct i40e_pf *pf = vsi->back;\n\tstruct i40e_hw *hw = &pf->hw;\n\tstruct i40e_vsi_context ctxt;\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tint bkt;\n\n\tu8 enabled_tc = 0x1;  \n\tint f_count = 0;\n\n\tmemset(&ctxt, 0, sizeof(ctxt));\n\tswitch (vsi->type) {\n\tcase I40E_VSI_MAIN:\n\t\t \n\t\tctxt.seid = pf->main_vsi_seid;\n\t\tctxt.pf_num = pf->hw.pf_id;\n\t\tctxt.vf_num = 0;\n\t\tret = i40e_aq_get_vsi_params(&pf->hw, &ctxt, NULL);\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"couldn't get PF vsi config, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tvsi->info = ctxt.info;\n\t\tvsi->info.valid_sections = 0;\n\n\t\tvsi->seid = ctxt.seid;\n\t\tvsi->id = ctxt.vsi_number;\n\n\t\tenabled_tc = i40e_pf_get_tc_map(pf);\n\n\t\t \n\t\tif (pf->flags & I40E_FLAG_SOURCE_PRUNING_DISABLED) {\n\t\t\tmemset(&ctxt, 0, sizeof(ctxt));\n\t\t\tctxt.seid = pf->main_vsi_seid;\n\t\t\tctxt.pf_num = pf->hw.pf_id;\n\t\t\tctxt.vf_num = 0;\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_LOCAL_LB);\n\t\t\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"update vsi failed, err %d aq_err %s\\n\",\n\t\t\t\t\t ret,\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif ((pf->flags & I40E_FLAG_MFP_ENABLED) &&\n\t\t    !(pf->hw.func_caps.iscsi)) {  \n\t\t\tmemset(&ctxt, 0, sizeof(ctxt));\n\t\t\tctxt.seid = pf->main_vsi_seid;\n\t\t\tctxt.pf_num = pf->hw.pf_id;\n\t\t\tctxt.vf_num = 0;\n\t\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, false);\n\t\t\tret = i40e_aq_update_vsi_params(hw, &ctxt, NULL);\n\t\t\tif (ret) {\n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"update vsi failed, err %pe aq_err %s\\n\",\n\t\t\t\t\t ERR_PTR(ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\t \n\t\t\ti40e_vsi_update_queue_map(vsi, &ctxt);\n\t\t\tvsi->info.valid_sections = 0;\n\t\t} else {\n\t\t\t \n\t\t\tret = i40e_vsi_config_tc(vsi, enabled_tc);\n\t\t\tif (ret) {\n\t\t\t\t \n\t\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t\t \"failed to configure TCs for main VSI tc_map 0x%08x, err %pe aq_err %s\\n\",\n\t\t\t\t\t enabled_tc,\n\t\t\t\t\t ERR_PTR(ret),\n\t\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t\t    pf->hw.aq.asq_last_status));\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase I40E_VSI_FDIR:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = 0;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_PF;\n\t\tif ((pf->flags & I40E_FLAG_VEB_MODE_ENABLED) &&\n\t\t    (i40e_is_vsi_uplink_mode_veb(vsi))) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t     cpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t   cpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_VMDQ2:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = 0;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VMDQ2;\n\n\t\t \n\t\tif (i40e_is_vsi_uplink_mode_veb(vsi)) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\n\t\t \n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_SRIOV:\n\t\tctxt.pf_num = hw->pf_id;\n\t\tctxt.vf_num = vsi->vf_id + hw->func_caps.vf_base_id;\n\t\tctxt.uplink_seid = vsi->uplink_seid;\n\t\tctxt.connection_type = I40E_AQ_VSI_CONN_TYPE_NORMAL;\n\t\tctxt.flags = I40E_AQ_VSI_TYPE_VF;\n\n\t\t \n\t\tif (i40e_is_vsi_uplink_mode_veb(vsi)) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SWITCH_VALID);\n\t\t\tctxt.info.switch_id =\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_SW_ID_FLAG_ALLOW_LB);\n\t\t}\n\n\t\tif (vsi->back->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_QUEUE_OPT_VALID);\n\t\t\tctxt.info.queueing_opt_flags |=\n\t\t\t\t(I40E_AQ_VSI_QUE_OPT_TCP_ENA |\n\t\t\t\t I40E_AQ_VSI_QUE_OPT_RSS_LUT_VSI);\n\t\t}\n\n\t\tctxt.info.valid_sections |= cpu_to_le16(I40E_AQ_VSI_PROP_VLAN_VALID);\n\t\tctxt.info.port_vlan_flags |= I40E_AQ_VSI_PVLAN_MODE_ALL;\n\t\tif (pf->vf[vsi->vf_id].spoofchk) {\n\t\t\tctxt.info.valid_sections |=\n\t\t\t\tcpu_to_le16(I40E_AQ_VSI_PROP_SECURITY_VALID);\n\t\t\tctxt.info.sec_flags |=\n\t\t\t\t(I40E_AQ_VSI_SEC_FLAG_ENABLE_VLAN_CHK |\n\t\t\t\t I40E_AQ_VSI_SEC_FLAG_ENABLE_MAC_CHK);\n\t\t}\n\t\t \n\t\ti40e_vsi_setup_queue_map(vsi, &ctxt, enabled_tc, true);\n\t\tbreak;\n\n\tcase I40E_VSI_IWARP:\n\t\t \n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENODEV;\n\t}\n\n\tif (vsi->type != I40E_VSI_MAIN) {\n\t\tret = i40e_aq_add_vsi(hw, &ctxt, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t \"add vsi failed, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\tret = -ENOENT;\n\t\t\tgoto err;\n\t\t}\n\t\tvsi->info = ctxt.info;\n\t\tvsi->info.valid_sections = 0;\n\t\tvsi->seid = ctxt.seid;\n\t\tvsi->id = ctxt.vsi_number;\n\t}\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\tvsi->active_filters = 0;\n\t \n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist) {\n\t\tf->state = I40E_FILTER_NEW;\n\t\tf_count++;\n\t}\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\tclear_bit(__I40E_VSI_OVERFLOW_PROMISC, vsi->state);\n\n\tif (f_count) {\n\t\tvsi->flags |= I40E_VSI_FLAG_FILTER_CHANGED;\n\t\tset_bit(__I40E_MACVLAN_SYNC_PENDING, pf->state);\n\t}\n\n\t \n\tret = i40e_vsi_get_bw_info(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get vsi bw info, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\t \n\t\tret = 0;\n\t}\n\nerr:\n\treturn ret;\n}\n\n \nint i40e_vsi_release(struct i40e_vsi *vsi)\n{\n\tstruct i40e_mac_filter *f;\n\tstruct hlist_node *h;\n\tstruct i40e_veb *veb = NULL;\n\tstruct i40e_pf *pf;\n\tu16 uplink_seid;\n\tint i, n, bkt;\n\n\tpf = vsi->back;\n\n\t \n\tif (vsi->flags & I40E_VSI_FLAG_VEB_OWNER) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has existing VEB %d\\n\",\n\t\t\t vsi->seid, vsi->uplink_seid);\n\t\treturn -ENODEV;\n\t}\n\tif (vsi == pf->vsi[pf->lan_vsi] &&\n\t    !test_bit(__I40E_DOWN, pf->state)) {\n\t\tdev_info(&pf->pdev->dev, \"Can't remove PF VSI\\n\");\n\t\treturn -ENODEV;\n\t}\n\tset_bit(__I40E_VSI_RELEASING, vsi->state);\n\tuplink_seid = vsi->uplink_seid;\n\tif (vsi->type != I40E_VSI_SRIOV) {\n\t\tif (vsi->netdev_registered) {\n\t\t\tvsi->netdev_registered = false;\n\t\t\tif (vsi->netdev) {\n\t\t\t\t \n\t\t\t\tunregister_netdev(vsi->netdev);\n\t\t\t}\n\t\t} else {\n\t\t\ti40e_vsi_close(vsi);\n\t\t}\n\t\ti40e_vsi_disable_irq(vsi);\n\t}\n\n\tspin_lock_bh(&vsi->mac_filter_hash_lock);\n\n\t \n\tif (vsi->netdev) {\n\t\t__dev_uc_unsync(vsi->netdev, NULL);\n\t\t__dev_mc_unsync(vsi->netdev, NULL);\n\t}\n\n\t \n\thash_for_each_safe(vsi->mac_filter_hash, bkt, h, f, hlist)\n\t\t__i40e_del_filter(vsi, f);\n\n\tspin_unlock_bh(&vsi->mac_filter_hash_lock);\n\n\ti40e_sync_vsi_filters(vsi);\n\n\ti40e_vsi_delete(vsi);\n\ti40e_vsi_free_q_vectors(vsi);\n\tif (vsi->netdev) {\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\n\ti40e_vsi_clear_rings(vsi);\n\ti40e_vsi_clear(vsi);\n\n\t \n\tfor (n = 0, i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] &&\n\t\t    pf->vsi[i]->uplink_seid == uplink_seid &&\n\t\t    (pf->vsi[i]->flags & I40E_VSI_FLAG_VEB_OWNER) == 0) {\n\t\t\tn++;       \n\t\t}\n\t}\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\t\tif (pf->veb[i]->uplink_seid == uplink_seid)\n\t\t\tn++;      \n\t\tif (pf->veb[i]->seid == uplink_seid)\n\t\t\tveb = pf->veb[i];\n\t}\n\tif (n == 0 && veb && veb->uplink_seid != 0)\n\t\ti40e_veb_release(veb);\n\n\treturn 0;\n}\n\n \nstatic int i40e_vsi_setup_vectors(struct i40e_vsi *vsi)\n{\n\tint ret = -ENOENT;\n\tstruct i40e_pf *pf = vsi->back;\n\n\tif (vsi->q_vectors[0]) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has existing q_vectors\\n\",\n\t\t\t vsi->seid);\n\t\treturn -EEXIST;\n\t}\n\n\tif (vsi->base_vector) {\n\t\tdev_info(&pf->pdev->dev, \"VSI %d has non-zero base vector %d\\n\",\n\t\t\t vsi->seid, vsi->base_vector);\n\t\treturn -EEXIST;\n\t}\n\n\tret = i40e_vsi_alloc_q_vectors(vsi);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to allocate %d q_vector for VSI %d, ret=%d\\n\",\n\t\t\t vsi->num_q_vectors, vsi->seid, ret);\n\t\tvsi->num_q_vectors = 0;\n\t\tgoto vector_setup_out;\n\t}\n\n\t \n\tif (!(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\treturn ret;\n\tif (vsi->num_q_vectors)\n\t\tvsi->base_vector = i40e_get_lump(pf, pf->irq_pile,\n\t\t\t\t\t\t vsi->num_q_vectors, vsi->idx);\n\tif (vsi->base_vector < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d vectors for VSI %d, err=%d\\n\",\n\t\t\t vsi->num_q_vectors, vsi->seid, vsi->base_vector);\n\t\ti40e_vsi_free_q_vectors(vsi);\n\t\tret = -ENOENT;\n\t\tgoto vector_setup_out;\n\t}\n\nvector_setup_out:\n\treturn ret;\n}\n\n \nstatic struct i40e_vsi *i40e_vsi_reinit_setup(struct i40e_vsi *vsi)\n{\n\tu16 alloc_queue_pairs;\n\tstruct i40e_pf *pf;\n\tu8 enabled_tc;\n\tint ret;\n\n\tif (!vsi)\n\t\treturn NULL;\n\n\tpf = vsi->back;\n\n\ti40e_put_lump(pf->qp_pile, vsi->base_queue, vsi->idx);\n\ti40e_vsi_clear_rings(vsi);\n\n\ti40e_vsi_free_arrays(vsi, false);\n\ti40e_set_num_rings_in_vsi(vsi);\n\tret = i40e_vsi_alloc_arrays(vsi, false);\n\tif (ret)\n\t\tgoto err_vsi;\n\n\talloc_queue_pairs = vsi->alloc_queue_pairs *\n\t\t\t    (i40e_enabled_xdp_vsi(vsi) ? 2 : 1);\n\n\tret = i40e_get_lump(pf, pf->qp_pile, alloc_queue_pairs, vsi->idx);\n\tif (ret < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d queues for VSI %d err %d\\n\",\n\t\t\t alloc_queue_pairs, vsi->seid, ret);\n\t\tgoto err_vsi;\n\t}\n\tvsi->base_queue = ret;\n\n\t \n\tenabled_tc = pf->vsi[pf->lan_vsi]->tc_config.enabled_tc;\n\tpf->vsi[pf->lan_vsi]->tc_config.enabled_tc = 0;\n\tpf->vsi[pf->lan_vsi]->seid = pf->main_vsi_seid;\n\ti40e_vsi_config_tc(pf->vsi[pf->lan_vsi], enabled_tc);\n\tif (vsi->type == I40E_VSI_MAIN)\n\t\ti40e_rm_default_mac_filter(vsi, pf->hw.mac.perm_addr);\n\n\t \n\tret = i40e_alloc_rings(vsi);\n\tif (ret)\n\t\tgoto err_rings;\n\n\t \n\ti40e_vsi_map_rings_to_vectors(vsi);\n\treturn vsi;\n\nerr_rings:\n\ti40e_vsi_free_q_vectors(vsi);\n\tif (vsi->netdev_registered) {\n\t\tvsi->netdev_registered = false;\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\n\ti40e_aq_delete_element(&pf->hw, vsi->seid, NULL);\nerr_vsi:\n\ti40e_vsi_clear(vsi);\n\treturn NULL;\n}\n\n \nstruct i40e_vsi *i40e_vsi_setup(struct i40e_pf *pf, u8 type,\n\t\t\t\tu16 uplink_seid, u32 param1)\n{\n\tstruct i40e_vsi *vsi = NULL;\n\tstruct i40e_veb *veb = NULL;\n\tu16 alloc_queue_pairs;\n\tint ret, i;\n\tint v_idx;\n\n\t \n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (pf->veb[i] && pf->veb[i]->seid == uplink_seid) {\n\t\t\tveb = pf->veb[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!veb && uplink_seid != pf->mac_seid) {\n\n\t\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\t\tif (pf->vsi[i] && pf->vsi[i]->seid == uplink_seid) {\n\t\t\t\tvsi = pf->vsi[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"no such uplink_seid %d\\n\",\n\t\t\t\t uplink_seid);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (vsi->uplink_seid == pf->mac_seid)\n\t\t\tveb = i40e_veb_setup(pf, 0, pf->mac_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\telse if ((vsi->flags & I40E_VSI_FLAG_VEB_OWNER) == 0)\n\t\t\tveb = i40e_veb_setup(pf, 0, vsi->uplink_seid, vsi->seid,\n\t\t\t\t\t     vsi->tc_config.enabled_tc);\n\t\tif (veb) {\n\t\t\tif (vsi->seid != pf->vsi[pf->lan_vsi]->seid) {\n\t\t\t\tdev_info(&vsi->back->pdev->dev,\n\t\t\t\t\t \"New VSI creation error, uplink seid of LAN VSI expected.\\n\");\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\t \n\t\t\tif (!(pf->flags & I40E_FLAG_VEB_MODE_ENABLED)) {\n\t\t\t\tveb->bridge_mode = BRIDGE_MODE_VEPA;\n\t\t\t\tpf->flags &= ~I40E_FLAG_VEB_MODE_ENABLED;\n\t\t\t}\n\t\t\ti40e_config_bridge_mode(veb);\n\t\t}\n\t\tfor (i = 0; i < I40E_MAX_VEB && !veb; i++) {\n\t\t\tif (pf->veb[i] && pf->veb[i]->seid == vsi->uplink_seid)\n\t\t\t\tveb = pf->veb[i];\n\t\t}\n\t\tif (!veb) {\n\t\t\tdev_info(&pf->pdev->dev, \"couldn't add VEB\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tvsi->flags |= I40E_VSI_FLAG_VEB_OWNER;\n\t\tuplink_seid = veb->seid;\n\t}\n\n\t \n\tv_idx = i40e_vsi_mem_alloc(pf, type);\n\tif (v_idx < 0)\n\t\tgoto err_alloc;\n\tvsi = pf->vsi[v_idx];\n\tif (!vsi)\n\t\tgoto err_alloc;\n\tvsi->type = type;\n\tvsi->veb_idx = (veb ? veb->idx : I40E_NO_VEB);\n\n\tif (type == I40E_VSI_MAIN)\n\t\tpf->lan_vsi = v_idx;\n\telse if (type == I40E_VSI_SRIOV)\n\t\tvsi->vf_id = param1;\n\t \n\talloc_queue_pairs = vsi->alloc_queue_pairs *\n\t\t\t    (i40e_enabled_xdp_vsi(vsi) ? 2 : 1);\n\n\tret = i40e_get_lump(pf, pf->qp_pile, alloc_queue_pairs, vsi->idx);\n\tif (ret < 0) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"failed to get tracking for %d queues for VSI %d err=%d\\n\",\n\t\t\t alloc_queue_pairs, vsi->seid, ret);\n\t\tgoto err_vsi;\n\t}\n\tvsi->base_queue = ret;\n\n\t \n\tvsi->uplink_seid = uplink_seid;\n\tret = i40e_add_vsi(vsi);\n\tif (ret)\n\t\tgoto err_vsi;\n\n\tswitch (vsi->type) {\n\t \n\tcase I40E_VSI_MAIN:\n\tcase I40E_VSI_VMDQ2:\n\t\tret = i40e_config_netdev(vsi);\n\t\tif (ret)\n\t\t\tgoto err_netdev;\n\t\tret = i40e_netif_set_realnum_tx_rx_queues(vsi);\n\t\tif (ret)\n\t\t\tgoto err_netdev;\n\t\tret = register_netdev(vsi->netdev);\n\t\tif (ret)\n\t\t\tgoto err_netdev;\n\t\tvsi->netdev_registered = true;\n\t\tnetif_carrier_off(vsi->netdev);\n#ifdef CONFIG_I40E_DCB\n\t\t \n\t\ti40e_dcbnl_setup(vsi);\n#endif  \n\t\tfallthrough;\n\tcase I40E_VSI_FDIR:\n\t\t \n\t\tret = i40e_vsi_setup_vectors(vsi);\n\t\tif (ret)\n\t\t\tgoto err_msix;\n\n\t\tret = i40e_alloc_rings(vsi);\n\t\tif (ret)\n\t\t\tgoto err_rings;\n\n\t\t \n\t\ti40e_vsi_map_rings_to_vectors(vsi);\n\n\t\ti40e_vsi_reset_stats(vsi);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\n\tif ((pf->hw_features & I40E_HW_RSS_AQ_CAPABLE) &&\n\t    (vsi->type == I40E_VSI_VMDQ2)) {\n\t\tret = i40e_vsi_config_rss(vsi);\n\t}\n\treturn vsi;\n\nerr_rings:\n\ti40e_vsi_free_q_vectors(vsi);\nerr_msix:\n\tif (vsi->netdev_registered) {\n\t\tvsi->netdev_registered = false;\n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\t\tvsi->netdev = NULL;\n\t}\nerr_netdev:\n\ti40e_aq_delete_element(&pf->hw, vsi->seid, NULL);\nerr_vsi:\n\ti40e_vsi_clear(vsi);\nerr_alloc:\n\treturn NULL;\n}\n\n \nstatic int i40e_veb_get_bw_info(struct i40e_veb *veb)\n{\n\tstruct i40e_aqc_query_switching_comp_ets_config_resp ets_data;\n\tstruct i40e_aqc_query_switching_comp_bw_config_resp bw_data;\n\tstruct i40e_pf *pf = veb->pf;\n\tstruct i40e_hw *hw = &pf->hw;\n\tu32 tc_bw_max;\n\tint ret = 0;\n\tint i;\n\n\tret = i40e_aq_query_switch_comp_bw_config(hw, veb->seid,\n\t\t\t\t\t\t  &bw_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"query veb bw config failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\tret = i40e_aq_query_switch_comp_ets_config(hw, veb->seid,\n\t\t\t\t\t\t   &ets_data, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"query veb bw ets config failed, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, hw->aq.asq_last_status));\n\t\tgoto out;\n\t}\n\n\tveb->bw_limit = le16_to_cpu(ets_data.port_bw_limit);\n\tveb->bw_max_quanta = ets_data.tc_bw_max;\n\tveb->is_abs_credits = bw_data.absolute_credits_enable;\n\tveb->enabled_tc = ets_data.tc_valid_bits;\n\ttc_bw_max = le16_to_cpu(bw_data.tc_bw_max[0]) |\n\t\t    (le16_to_cpu(bw_data.tc_bw_max[1]) << 16);\n\tfor (i = 0; i < I40E_MAX_TRAFFIC_CLASS; i++) {\n\t\tveb->bw_tc_share_credits[i] = bw_data.tc_bw_share_credits[i];\n\t\tveb->bw_tc_limit_credits[i] =\n\t\t\t\t\tle16_to_cpu(bw_data.tc_bw_limits[i]);\n\t\tveb->bw_tc_max_quanta[i] = ((tc_bw_max >> (i*4)) & 0x7);\n\t}\n\nout:\n\treturn ret;\n}\n\n \nstatic int i40e_veb_mem_alloc(struct i40e_pf *pf)\n{\n\tint ret = -ENOENT;\n\tstruct i40e_veb *veb;\n\tint i;\n\n\t \n\tmutex_lock(&pf->switch_mutex);\n\n\t \n\ti = 0;\n\twhile ((i < I40E_MAX_VEB) && (pf->veb[i] != NULL))\n\t\ti++;\n\tif (i >= I40E_MAX_VEB) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc_veb;   \n\t}\n\n\tveb = kzalloc(sizeof(*veb), GFP_KERNEL);\n\tif (!veb) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc_veb;\n\t}\n\tveb->pf = pf;\n\tveb->idx = i;\n\tveb->enabled_tc = 1;\n\n\tpf->veb[i] = veb;\n\tret = i;\nerr_alloc_veb:\n\tmutex_unlock(&pf->switch_mutex);\n\treturn ret;\n}\n\n \nstatic void i40e_switch_branch_release(struct i40e_veb *branch)\n{\n\tstruct i40e_pf *pf = branch->pf;\n\tu16 branch_seid = branch->seid;\n\tu16 veb_idx = branch->idx;\n\tint i;\n\n\t \n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\t\tif (pf->veb[i]->uplink_seid == branch->seid)\n\t\t\ti40e_switch_branch_release(pf->veb[i]);\n\t}\n\n\t \n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (!pf->vsi[i])\n\t\t\tcontinue;\n\t\tif (pf->vsi[i]->uplink_seid == branch_seid &&\n\t\t   (pf->vsi[i]->flags & I40E_VSI_FLAG_VEB_OWNER) == 0) {\n\t\t\ti40e_vsi_release(pf->vsi[i]);\n\t\t}\n\t}\n\n\t \n\tif (pf->veb[veb_idx])\n\t\ti40e_veb_release(pf->veb[veb_idx]);\n}\n\n \nstatic void i40e_veb_clear(struct i40e_veb *veb)\n{\n\tif (!veb)\n\t\treturn;\n\n\tif (veb->pf) {\n\t\tstruct i40e_pf *pf = veb->pf;\n\n\t\tmutex_lock(&pf->switch_mutex);\n\t\tif (pf->veb[veb->idx] == veb)\n\t\t\tpf->veb[veb->idx] = NULL;\n\t\tmutex_unlock(&pf->switch_mutex);\n\t}\n\n\tkfree(veb);\n}\n\n \nvoid i40e_veb_release(struct i40e_veb *veb)\n{\n\tstruct i40e_vsi *vsi = NULL;\n\tstruct i40e_pf *pf;\n\tint i, n = 0;\n\n\tpf = veb->pf;\n\n\t \n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] && pf->vsi[i]->uplink_seid == veb->seid) {\n\t\t\tn++;\n\t\t\tvsi = pf->vsi[i];\n\t\t}\n\t}\n\tif (n != 1) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"can't remove VEB %d with %d VSIs left\\n\",\n\t\t\t veb->seid, n);\n\t\treturn;\n\t}\n\n\t \n\tvsi->flags &= ~I40E_VSI_FLAG_VEB_OWNER;\n\tif (veb->uplink_seid) {\n\t\tvsi->uplink_seid = veb->uplink_seid;\n\t\tif (veb->uplink_seid == pf->mac_seid)\n\t\t\tvsi->veb_idx = I40E_NO_VEB;\n\t\telse\n\t\t\tvsi->veb_idx = veb->veb_idx;\n\t} else {\n\t\t \n\t\tvsi->uplink_seid = pf->vsi[pf->lan_vsi]->uplink_seid;\n\t\tvsi->veb_idx = pf->vsi[pf->lan_vsi]->veb_idx;\n\t}\n\n\ti40e_aq_delete_element(&pf->hw, veb->seid, NULL);\n\ti40e_veb_clear(veb);\n}\n\n \nstatic int i40e_add_veb(struct i40e_veb *veb, struct i40e_vsi *vsi)\n{\n\tstruct i40e_pf *pf = veb->pf;\n\tbool enable_stats = !!(pf->flags & I40E_FLAG_VEB_STATS_ENABLED);\n\tint ret;\n\n\tret = i40e_aq_add_veb(&pf->hw, veb->uplink_seid, vsi->seid,\n\t\t\t      veb->enabled_tc, false,\n\t\t\t      &veb->seid, enable_stats, NULL);\n\n\t \n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't add VEB, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EPERM;\n\t}\n\n\t \n\tret = i40e_aq_get_veb_parameters(&pf->hw, veb->seid, NULL, NULL,\n\t\t\t\t\t &veb->stats_idx, NULL, NULL, NULL);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get VEB statistics idx, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn -EPERM;\n\t}\n\tret = i40e_veb_get_bw_info(veb);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't get VEB bw info, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\ti40e_aq_delete_element(&pf->hw, veb->seid, NULL);\n\t\treturn -ENOENT;\n\t}\n\n\tvsi->uplink_seid = veb->seid;\n\tvsi->veb_idx = veb->idx;\n\tvsi->flags |= I40E_VSI_FLAG_VEB_OWNER;\n\n\treturn 0;\n}\n\n \nstruct i40e_veb *i40e_veb_setup(struct i40e_pf *pf, u16 flags,\n\t\t\t\tu16 uplink_seid, u16 vsi_seid,\n\t\t\t\tu8 enabled_tc)\n{\n\tstruct i40e_veb *veb, *uplink_veb = NULL;\n\tint vsi_idx, veb_idx;\n\tint ret;\n\n\t \n\tif ((uplink_seid == 0 || vsi_seid == 0) &&\n\t    (uplink_seid + vsi_seid != 0)) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"one, not both seid's are 0: uplink=%d vsi=%d\\n\",\n\t\t\t uplink_seid, vsi_seid);\n\t\treturn NULL;\n\t}\n\n\t \n\tfor (vsi_idx = 0; vsi_idx < pf->num_alloc_vsi; vsi_idx++)\n\t\tif (pf->vsi[vsi_idx] && pf->vsi[vsi_idx]->seid == vsi_seid)\n\t\t\tbreak;\n\tif (vsi_idx == pf->num_alloc_vsi && vsi_seid != 0) {\n\t\tdev_info(&pf->pdev->dev, \"vsi seid %d not found\\n\",\n\t\t\t vsi_seid);\n\t\treturn NULL;\n\t}\n\n\tif (uplink_seid && uplink_seid != pf->mac_seid) {\n\t\tfor (veb_idx = 0; veb_idx < I40E_MAX_VEB; veb_idx++) {\n\t\t\tif (pf->veb[veb_idx] &&\n\t\t\t    pf->veb[veb_idx]->seid == uplink_seid) {\n\t\t\t\tuplink_veb = pf->veb[veb_idx];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!uplink_veb) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"uplink seid %d not found\\n\", uplink_seid);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t \n\tveb_idx = i40e_veb_mem_alloc(pf);\n\tif (veb_idx < 0)\n\t\tgoto err_alloc;\n\tveb = pf->veb[veb_idx];\n\tveb->flags = flags;\n\tveb->uplink_seid = uplink_seid;\n\tveb->veb_idx = (uplink_veb ? uplink_veb->idx : I40E_NO_VEB);\n\tveb->enabled_tc = (enabled_tc ? enabled_tc : 0x1);\n\n\t \n\tret = i40e_add_veb(veb, pf->vsi[vsi_idx]);\n\tif (ret)\n\t\tgoto err_veb;\n\tif (vsi_idx == pf->lan_vsi)\n\t\tpf->lan_veb = veb->idx;\n\n\treturn veb;\n\nerr_veb:\n\ti40e_veb_clear(veb);\nerr_alloc:\n\treturn NULL;\n}\n\n \nstatic void i40e_setup_pf_switch_element(struct i40e_pf *pf,\n\t\t\t\tstruct i40e_aqc_switch_config_element_resp *ele,\n\t\t\t\tu16 num_reported, bool printconfig)\n{\n\tu16 downlink_seid = le16_to_cpu(ele->downlink_seid);\n\tu16 uplink_seid = le16_to_cpu(ele->uplink_seid);\n\tu8 element_type = ele->element_type;\n\tu16 seid = le16_to_cpu(ele->seid);\n\n\tif (printconfig)\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"type=%d seid=%d uplink=%d downlink=%d\\n\",\n\t\t\t element_type, seid, uplink_seid, downlink_seid);\n\n\tswitch (element_type) {\n\tcase I40E_SWITCH_ELEMENT_TYPE_MAC:\n\t\tpf->mac_seid = seid;\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_VEB:\n\t\t \n\t\tif (uplink_seid != pf->mac_seid)\n\t\t\tbreak;\n\t\tif (pf->lan_veb >= I40E_MAX_VEB) {\n\t\t\tint v;\n\n\t\t\t \n\t\t\tfor (v = 0; v < I40E_MAX_VEB; v++) {\n\t\t\t\tif (pf->veb[v] && (pf->veb[v]->seid == seid)) {\n\t\t\t\t\tpf->lan_veb = v;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (pf->lan_veb >= I40E_MAX_VEB) {\n\t\t\t\tv = i40e_veb_mem_alloc(pf);\n\t\t\t\tif (v < 0)\n\t\t\t\t\tbreak;\n\t\t\t\tpf->lan_veb = v;\n\t\t\t}\n\t\t}\n\t\tif (pf->lan_veb >= I40E_MAX_VEB)\n\t\t\tbreak;\n\n\t\tpf->veb[pf->lan_veb]->seid = seid;\n\t\tpf->veb[pf->lan_veb]->uplink_seid = pf->mac_seid;\n\t\tpf->veb[pf->lan_veb]->pf = pf;\n\t\tpf->veb[pf->lan_veb]->veb_idx = I40E_NO_VEB;\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_VSI:\n\t\tif (num_reported != 1)\n\t\t\tbreak;\n\t\t \n\t\tpf->mac_seid = uplink_seid;\n\t\tpf->pf_seid = downlink_seid;\n\t\tpf->main_vsi_seid = seid;\n\t\tif (printconfig)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"pf_seid=%d main_vsi_seid=%d\\n\",\n\t\t\t\t pf->pf_seid, pf->main_vsi_seid);\n\t\tbreak;\n\tcase I40E_SWITCH_ELEMENT_TYPE_PF:\n\tcase I40E_SWITCH_ELEMENT_TYPE_VF:\n\tcase I40E_SWITCH_ELEMENT_TYPE_EMP:\n\tcase I40E_SWITCH_ELEMENT_TYPE_BMC:\n\tcase I40E_SWITCH_ELEMENT_TYPE_PE:\n\tcase I40E_SWITCH_ELEMENT_TYPE_PA:\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tdev_info(&pf->pdev->dev, \"unknown element type=%d seid=%d\\n\",\n\t\t\t element_type, seid);\n\t\tbreak;\n\t}\n}\n\n \nint i40e_fetch_switch_configuration(struct i40e_pf *pf, bool printconfig)\n{\n\tstruct i40e_aqc_get_switch_config_resp *sw_config;\n\tu16 next_seid = 0;\n\tint ret = 0;\n\tu8 *aq_buf;\n\tint i;\n\n\taq_buf = kzalloc(I40E_AQ_LARGE_BUF, GFP_KERNEL);\n\tif (!aq_buf)\n\t\treturn -ENOMEM;\n\n\tsw_config = (struct i40e_aqc_get_switch_config_resp *)aq_buf;\n\tdo {\n\t\tu16 num_reported, num_total;\n\n\t\tret = i40e_aq_get_switch_config(&pf->hw, sw_config,\n\t\t\t\t\t\tI40E_AQ_LARGE_BUF,\n\t\t\t\t\t\t&next_seid, NULL);\n\t\tif (ret) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"get switch config failed err %d aq_err %s\\n\",\n\t\t\t\t ret,\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\tkfree(aq_buf);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tnum_reported = le16_to_cpu(sw_config->header.num_reported);\n\t\tnum_total = le16_to_cpu(sw_config->header.num_total);\n\n\t\tif (printconfig)\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"header: %d reported %d total\\n\",\n\t\t\t\t num_reported, num_total);\n\n\t\tfor (i = 0; i < num_reported; i++) {\n\t\t\tstruct i40e_aqc_switch_config_element_resp *ele =\n\t\t\t\t&sw_config->element[i];\n\n\t\t\ti40e_setup_pf_switch_element(pf, ele, num_reported,\n\t\t\t\t\t\t     printconfig);\n\t\t}\n\t} while (next_seid != 0);\n\n\tkfree(aq_buf);\n\treturn ret;\n}\n\n \nstatic int i40e_setup_pf_switch(struct i40e_pf *pf, bool reinit, bool lock_acquired)\n{\n\tu16 flags = 0;\n\tint ret;\n\n\t \n\tret = i40e_fetch_switch_configuration(pf, false);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev,\n\t\t\t \"couldn't fetch switch config, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(ret),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\t\treturn ret;\n\t}\n\ti40e_pf_reset_stats(pf);\n\n\t \n\n\tif ((pf->hw.pf_id == 0) &&\n\t    !(pf->flags & I40E_FLAG_TRUE_PROMISC_SUPPORT)) {\n\t\tflags = I40E_AQ_SET_SWITCH_CFG_PROMISC;\n\t\tpf->last_sw_conf_flags = flags;\n\t}\n\n\tif (pf->hw.pf_id == 0) {\n\t\tu16 valid_flags;\n\n\t\tvalid_flags = I40E_AQ_SET_SWITCH_CFG_PROMISC;\n\t\tret = i40e_aq_set_switch_config(&pf->hw, flags, valid_flags, 0,\n\t\t\t\t\t\tNULL);\n\t\tif (ret && pf->hw.aq.asq_last_status != I40E_AQ_RC_ESRCH) {\n\t\t\tdev_info(&pf->pdev->dev,\n\t\t\t\t \"couldn't set switch config bits, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(ret),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t\t\t \n\t\t}\n\t\tpf->last_sw_conf_valid_flags = valid_flags;\n\t}\n\n\t \n\tif (pf->lan_vsi == I40E_NO_VSI || reinit) {\n\t\tstruct i40e_vsi *vsi = NULL;\n\t\tu16 uplink_seid;\n\n\t\t \n\t\tif (pf->lan_veb < I40E_MAX_VEB && pf->veb[pf->lan_veb])\n\t\t\tuplink_seid = pf->veb[pf->lan_veb]->seid;\n\t\telse\n\t\t\tuplink_seid = pf->mac_seid;\n\t\tif (pf->lan_vsi == I40E_NO_VSI)\n\t\t\tvsi = i40e_vsi_setup(pf, I40E_VSI_MAIN, uplink_seid, 0);\n\t\telse if (reinit)\n\t\t\tvsi = i40e_vsi_reinit_setup(pf->vsi[pf->lan_vsi]);\n\t\tif (!vsi) {\n\t\t\tdev_info(&pf->pdev->dev, \"setup of MAIN VSI failed\\n\");\n\t\t\ti40e_cloud_filter_exit(pf);\n\t\t\ti40e_fdir_teardown(pf);\n\t\t\treturn -EAGAIN;\n\t\t}\n\t} else {\n\t\t \n\t\tu8 enabled_tc = pf->vsi[pf->lan_vsi]->tc_config.enabled_tc;\n\n\t\tpf->vsi[pf->lan_vsi]->tc_config.enabled_tc = 0;\n\t\tpf->vsi[pf->lan_vsi]->seid = pf->main_vsi_seid;\n\t\ti40e_vsi_config_tc(pf->vsi[pf->lan_vsi], enabled_tc);\n\t}\n\ti40e_vlan_stripping_disable(pf->vsi[pf->lan_vsi]);\n\n\ti40e_fdir_sb_setup(pf);\n\n\t \n\tret = i40e_setup_pf_filter_control(pf);\n\tif (ret) {\n\t\tdev_info(&pf->pdev->dev, \"setup_pf_filter_control failed: %d\\n\",\n\t\t\t ret);\n\t\t \n\t}\n\n\t \n\tif ((pf->flags & I40E_FLAG_RSS_ENABLED))\n\t\ti40e_pf_config_rss(pf);\n\n\t \n\ti40e_link_event(pf);\n\n\t \n\tpf->fc_autoneg_status = ((pf->hw.phy.link_info.an_info &\n\t\t\t\t  I40E_AQ_AN_COMPLETED) ? true : false);\n\n\ti40e_ptp_init(pf);\n\n\tif (!lock_acquired)\n\t\trtnl_lock();\n\n\t \n\tudp_tunnel_nic_reset_ntf(pf->vsi[pf->lan_vsi]->netdev);\n\n\tif (!lock_acquired)\n\t\trtnl_unlock();\n\n\treturn ret;\n}\n\n \nstatic void i40e_determine_queue_usage(struct i40e_pf *pf)\n{\n\tint queues_left;\n\tint q_max;\n\n\tpf->num_lan_qps = 0;\n\n\t \n\tqueues_left = pf->hw.func_caps.num_tx_qp;\n\n\tif ((queues_left == 1) ||\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED)) {\n\t\t \n\t\tqueues_left = 0;\n\t\tpf->alloc_rss_size = pf->num_lan_qps = 1;\n\n\t\t \n\t\tpf->flags &= ~(I40E_FLAG_RSS_ENABLED\t|\n\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t       I40E_FLAG_DCB_CAPABLE\t|\n\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t       I40E_FLAG_SRIOV_ENABLED\t|\n\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t} else if (!(pf->flags & (I40E_FLAG_RSS_ENABLED |\n\t\t\t\t  I40E_FLAG_FD_SB_ENABLED |\n\t\t\t\t  I40E_FLAG_FD_ATR_ENABLED |\n\t\t\t\t  I40E_FLAG_DCB_CAPABLE))) {\n\t\t \n\t\tpf->alloc_rss_size = pf->num_lan_qps = 1;\n\t\tqueues_left -= pf->num_lan_qps;\n\n\t\tpf->flags &= ~(I40E_FLAG_RSS_ENABLED\t|\n\t\t\t       I40E_FLAG_IWARP_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_SB_ENABLED\t|\n\t\t\t       I40E_FLAG_FD_ATR_ENABLED\t|\n\t\t\t       I40E_FLAG_DCB_ENABLED\t|\n\t\t\t       I40E_FLAG_VMDQ_ENABLED);\n\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t} else {\n\t\t \n\t\tif ((pf->flags & I40E_FLAG_DCB_CAPABLE) &&\n\t\t    (queues_left < I40E_MAX_TRAFFIC_CLASS)) {\n\t\t\tpf->flags &= ~(I40E_FLAG_DCB_CAPABLE |\n\t\t\t\t\tI40E_FLAG_DCB_ENABLED);\n\t\t\tdev_info(&pf->pdev->dev, \"not enough queues for DCB. DCB is disabled.\\n\");\n\t\t}\n\n\t\t \n\t\tq_max = max_t(int, pf->rss_size_max, num_online_cpus());\n\t\tq_max = min_t(int, q_max, pf->hw.func_caps.num_tx_qp);\n\t\tq_max = min_t(int, q_max, pf->hw.func_caps.num_msix_vectors);\n\t\tpf->num_lan_qps = q_max;\n\n\t\tqueues_left -= pf->num_lan_qps;\n\t}\n\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\tif (queues_left > 1) {\n\t\t\tqueues_left -= 1;  \n\t\t} else {\n\t\t\tpf->flags &= ~I40E_FLAG_FD_SB_ENABLED;\n\t\t\tpf->flags |= I40E_FLAG_FD_SB_INACTIVE;\n\t\t\tdev_info(&pf->pdev->dev, \"not enough queues for Flow Director. Flow Director feature is disabled\\n\");\n\t\t}\n\t}\n\n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    pf->num_vf_qps && pf->num_req_vfs && queues_left) {\n\t\tpf->num_req_vfs = min_t(int, pf->num_req_vfs,\n\t\t\t\t\t(queues_left / pf->num_vf_qps));\n\t\tqueues_left -= (pf->num_req_vfs * pf->num_vf_qps);\n\t}\n\n\tif ((pf->flags & I40E_FLAG_VMDQ_ENABLED) &&\n\t    pf->num_vmdq_vsis && pf->num_vmdq_qps && queues_left) {\n\t\tpf->num_vmdq_vsis = min_t(int, pf->num_vmdq_vsis,\n\t\t\t\t\t  (queues_left / pf->num_vmdq_qps));\n\t\tqueues_left -= (pf->num_vmdq_vsis * pf->num_vmdq_qps);\n\t}\n\n\tpf->queues_left = queues_left;\n\tdev_dbg(&pf->pdev->dev,\n\t\t\"qs_avail=%d FD SB=%d lan_qs=%d lan_tc0=%d vf=%d*%d vmdq=%d*%d, remaining=%d\\n\",\n\t\tpf->hw.func_caps.num_tx_qp,\n\t\t!!(pf->flags & I40E_FLAG_FD_SB_ENABLED),\n\t\tpf->num_lan_qps, pf->alloc_rss_size, pf->num_req_vfs,\n\t\tpf->num_vf_qps, pf->num_vmdq_vsis, pf->num_vmdq_qps,\n\t\tqueues_left);\n}\n\n \nstatic int i40e_setup_pf_filter_control(struct i40e_pf *pf)\n{\n\tstruct i40e_filter_control_settings *settings = &pf->filter_settings;\n\n\tsettings->hash_lut_size = I40E_HASH_LUT_SIZE_128;\n\n\t \n\tif (pf->flags & (I40E_FLAG_FD_SB_ENABLED | I40E_FLAG_FD_ATR_ENABLED))\n\t\tsettings->enable_fdir = true;\n\n\t \n\tsettings->enable_ethtype = true;\n\tsettings->enable_macvlan = true;\n\n\tif (i40e_set_filter_control(&pf->hw, settings))\n\t\treturn -ENOENT;\n\n\treturn 0;\n}\n\n#define INFO_STRING_LEN 255\n#define REMAIN(__x) (INFO_STRING_LEN - (__x))\nstatic void i40e_print_features(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tchar *buf;\n\tint i;\n\n\tbuf = kmalloc(INFO_STRING_LEN, GFP_KERNEL);\n\tif (!buf)\n\t\treturn;\n\n\ti = snprintf(buf, INFO_STRING_LEN, \"Features: PF-id[%d]\", hw->pf_id);\n#ifdef CONFIG_PCI_IOV\n\ti += scnprintf(&buf[i], REMAIN(i), \" VFs: %d\", pf->num_req_vfs);\n#endif\n\ti += scnprintf(&buf[i], REMAIN(i), \" VSIs: %d QP: %d\",\n\t\t      pf->hw.func_caps.num_vsis,\n\t\t      pf->vsi[pf->lan_vsi]->num_queue_pairs);\n\tif (pf->flags & I40E_FLAG_RSS_ENABLED)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" RSS\");\n\tif (pf->flags & I40E_FLAG_FD_ATR_ENABLED)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" FD_ATR\");\n\tif (pf->flags & I40E_FLAG_FD_SB_ENABLED) {\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" FD_SB\");\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" NTUPLE\");\n\t}\n\tif (pf->flags & I40E_FLAG_DCB_CAPABLE)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" DCB\");\n\ti += scnprintf(&buf[i], REMAIN(i), \" VxLAN\");\n\ti += scnprintf(&buf[i], REMAIN(i), \" Geneve\");\n\tif (pf->flags & I40E_FLAG_PTP)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" PTP\");\n\tif (pf->flags & I40E_FLAG_VEB_MODE_ENABLED)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" VEB\");\n\telse\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" VEPA\");\n\n\tdev_info(&pf->pdev->dev, \"%s\\n\", buf);\n\tkfree(buf);\n\tWARN_ON(i > INFO_STRING_LEN);\n}\n\n \nstatic void i40e_get_platform_mac_addr(struct pci_dev *pdev, struct i40e_pf *pf)\n{\n\tif (eth_platform_get_mac_address(&pdev->dev, pf->hw.mac.addr))\n\t\ti40e_get_mac_addr(&pf->hw, pf->hw.mac.addr);\n}\n\n \nvoid i40e_set_fec_in_flags(u8 fec_cfg, u32 *flags)\n{\n\tif (fec_cfg & I40E_AQ_SET_FEC_AUTO)\n\t\t*flags |= I40E_FLAG_RS_FEC | I40E_FLAG_BASE_R_FEC;\n\tif ((fec_cfg & I40E_AQ_SET_FEC_REQUEST_RS) ||\n\t    (fec_cfg & I40E_AQ_SET_FEC_ABILITY_RS)) {\n\t\t*flags |= I40E_FLAG_RS_FEC;\n\t\t*flags &= ~I40E_FLAG_BASE_R_FEC;\n\t}\n\tif ((fec_cfg & I40E_AQ_SET_FEC_REQUEST_KR) ||\n\t    (fec_cfg & I40E_AQ_SET_FEC_ABILITY_KR)) {\n\t\t*flags |= I40E_FLAG_BASE_R_FEC;\n\t\t*flags &= ~I40E_FLAG_RS_FEC;\n\t}\n\tif (fec_cfg == 0)\n\t\t*flags &= ~(I40E_FLAG_RS_FEC | I40E_FLAG_BASE_R_FEC);\n}\n\n \nstatic bool i40e_check_recovery_mode(struct i40e_pf *pf)\n{\n\tu32 val = rd32(&pf->hw, I40E_GL_FWSTS);\n\n\tif (val & I40E_GL_FWSTS_FWS1B_MASK) {\n\t\tdev_crit(&pf->pdev->dev, \"Firmware recovery mode detected. Limiting functionality.\\n\");\n\t\tdev_crit(&pf->pdev->dev, \"Refer to the Intel(R) Ethernet Adapters and Devices User Guide for details on firmware recovery mode.\\n\");\n\t\tset_bit(__I40E_RECOVERY_MODE, pf->state);\n\n\t\treturn true;\n\t}\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\tdev_info(&pf->pdev->dev, \"Please do Power-On Reset to initialize adapter in normal mode with full functionality.\\n\");\n\n\treturn false;\n}\n\n \nstatic int i40e_pf_loop_reset(struct i40e_pf *pf)\n{\n\t \n\tconst unsigned long time_end = jiffies + 10 * HZ;\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret;\n\n\tret = i40e_pf_reset(hw);\n\twhile (ret != 0 && time_before(jiffies, time_end)) {\n\t\tusleep_range(10000, 20000);\n\t\tret = i40e_pf_reset(hw);\n\t}\n\n\tif (ret == 0)\n\t\tpf->pfr_count++;\n\telse\n\t\tdev_info(&pf->pdev->dev, \"PF reset failed: %d\\n\", ret);\n\n\treturn ret;\n}\n\n \nstatic bool i40e_check_fw_empr(struct i40e_pf *pf)\n{\n\tconst u32 fw_sts = rd32(&pf->hw, I40E_GL_FWSTS) &\n\t\t\t   I40E_GL_FWSTS_FWS1B_MASK;\n\treturn (fw_sts > I40E_GL_FWSTS_FWS1B_EMPR_0) &&\n\t       (fw_sts <= I40E_GL_FWSTS_FWS1B_EMPR_10);\n}\n\n \nstatic int i40e_handle_resets(struct i40e_pf *pf)\n{\n\tconst int pfr = i40e_pf_loop_reset(pf);\n\tconst bool is_empr = i40e_check_fw_empr(pf);\n\n\tif (is_empr || pfr != 0)\n\t\tdev_crit(&pf->pdev->dev, \"Entering recovery mode due to repeated FW resets. This may take several minutes. Refer to the Intel(R) Ethernet Adapters and Devices User Guide.\\n\");\n\n\treturn is_empr ? -EIO : pfr;\n}\n\n \nstatic int i40e_init_recovery_mode(struct i40e_pf *pf, struct i40e_hw *hw)\n{\n\tstruct i40e_vsi *vsi;\n\tint err;\n\tint v_idx;\n\n\tpci_set_drvdata(pf->pdev, pf);\n\tpci_save_state(pf->pdev);\n\n\t \n\ttimer_setup(&pf->service_timer, i40e_service_timer, 0);\n\tpf->service_timer_period = HZ;\n\n\tINIT_WORK(&pf->service_task, i40e_service_task);\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t \n\tif (pf->hw.func_caps.num_vsis < I40E_MIN_VSI_ALLOC)\n\t\tpf->num_alloc_vsi = I40E_MIN_VSI_ALLOC;\n\telse\n\t\tpf->num_alloc_vsi = pf->hw.func_caps.num_vsis;\n\n\t \n\tpf->vsi = kcalloc(pf->num_alloc_vsi, sizeof(struct i40e_vsi *),\n\t\t\t  GFP_KERNEL);\n\tif (!pf->vsi) {\n\t\terr = -ENOMEM;\n\t\tgoto err_switch_setup;\n\t}\n\n\t \n\tv_idx = i40e_vsi_mem_alloc(pf, I40E_VSI_MAIN);\n\tif (v_idx < 0) {\n\t\terr = v_idx;\n\t\tgoto err_switch_setup;\n\t}\n\tpf->lan_vsi = v_idx;\n\tvsi = pf->vsi[v_idx];\n\tif (!vsi) {\n\t\terr = -EFAULT;\n\t\tgoto err_switch_setup;\n\t}\n\tvsi->alloc_queue_pairs = 1;\n\terr = i40e_config_netdev(vsi);\n\tif (err)\n\t\tgoto err_switch_setup;\n\terr = register_netdev(vsi->netdev);\n\tif (err)\n\t\tgoto err_switch_setup;\n\tvsi->netdev_registered = true;\n\ti40e_dbg_pf_init(pf);\n\n\terr = i40e_setup_misc_vector_for_recovery_mode(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t \n\ti40e_send_version(pf);\n\n\t \n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\treturn 0;\n\nerr_switch_setup:\n\ti40e_reset_interrupt_capability(pf);\n\ttimer_shutdown_sync(&pf->service_timer);\n\ti40e_shutdown_adminq(hw);\n\tiounmap(hw->hw_addr);\n\tpci_release_mem_regions(pf->pdev);\n\tpci_disable_device(pf->pdev);\n\tkfree(pf);\n\n\treturn err;\n}\n\n \nstatic inline void i40e_set_subsystem_device_id(struct i40e_hw *hw)\n{\n\tstruct pci_dev *pdev = ((struct i40e_pf *)hw->back)->pdev;\n\n\thw->subsystem_device_id = pdev->subsystem_device ?\n\t\tpdev->subsystem_device :\n\t\t(ushort)(rd32(hw, I40E_PFPCI_SUBSYSID) & USHRT_MAX);\n}\n\n \nstatic int i40e_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct i40e_aq_get_phy_abilities_resp abilities;\n#ifdef CONFIG_I40E_DCB\n\tenum i40e_get_fw_lldp_status_resp lldp_status;\n#endif  \n\tstruct i40e_pf *pf;\n\tstruct i40e_hw *hw;\n\tstatic u16 pfs_found;\n\tu16 wol_nvm_bits;\n\tu16 link_status;\n#ifdef CONFIG_I40E_DCB\n\tint status;\n#endif  \n\tint err;\n\tu32 val;\n\tu32 i;\n\n\terr = pci_enable_device_mem(pdev);\n\tif (err)\n\t\treturn err;\n\n\t \n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"DMA configuration failed: 0x%x\\n\", err);\n\t\tgoto err_dma;\n\t}\n\n\t \n\terr = pci_request_mem_regions(pdev, i40e_driver_name);\n\tif (err) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"pci_request_selected_regions failed %d\\n\", err);\n\t\tgoto err_pci_reg;\n\t}\n\n\tpci_set_master(pdev);\n\n\t \n\tpf = kzalloc(sizeof(*pf), GFP_KERNEL);\n\tif (!pf) {\n\t\terr = -ENOMEM;\n\t\tgoto err_pf_alloc;\n\t}\n\tpf->next_vsi = 0;\n\tpf->pdev = pdev;\n\tset_bit(__I40E_DOWN, pf->state);\n\n\thw = &pf->hw;\n\thw->back = pf;\n\n\tpf->ioremap_len = min_t(int, pci_resource_len(pdev, 0),\n\t\t\t\tI40E_MAX_CSR_SPACE);\n\t \n\tif (pf->ioremap_len < I40E_GLGEN_STAT_CLEAR) {\n\t\tdev_err(&pdev->dev, \"Cannot map registers, bar size 0x%X too small, aborting\\n\",\n\t\t\tpf->ioremap_len);\n\t\terr = -ENOMEM;\n\t\tgoto err_ioremap;\n\t}\n\thw->hw_addr = ioremap(pci_resource_start(pdev, 0), pf->ioremap_len);\n\tif (!hw->hw_addr) {\n\t\terr = -EIO;\n\t\tdev_info(&pdev->dev, \"ioremap(0x%04x, 0x%04x) failed: 0x%x\\n\",\n\t\t\t (unsigned int)pci_resource_start(pdev, 0),\n\t\t\t pf->ioremap_len, err);\n\t\tgoto err_ioremap;\n\t}\n\thw->vendor_id = pdev->vendor;\n\thw->device_id = pdev->device;\n\tpci_read_config_byte(pdev, PCI_REVISION_ID, &hw->revision_id);\n\thw->subsystem_vendor_id = pdev->subsystem_vendor;\n\ti40e_set_subsystem_device_id(hw);\n\thw->bus.device = PCI_SLOT(pdev->devfn);\n\thw->bus.func = PCI_FUNC(pdev->devfn);\n\thw->bus.bus_id = pdev->bus->number;\n\tpf->instance = pfs_found;\n\n\t \n\thw->switch_tag = 0xffff;\n\thw->first_tag = ETH_P_8021AD;\n\thw->second_tag = ETH_P_8021Q;\n\n\tINIT_LIST_HEAD(&pf->l3_flex_pit_list);\n\tINIT_LIST_HEAD(&pf->l4_flex_pit_list);\n\tINIT_LIST_HEAD(&pf->ddp_old_prof);\n\n\t \n\tmutex_init(&hw->aq.asq_mutex);\n\tmutex_init(&hw->aq.arq_mutex);\n\n\tpf->msg_enable = netif_msg_init(debug,\n\t\t\t\t\tNETIF_MSG_DRV |\n\t\t\t\t\tNETIF_MSG_PROBE |\n\t\t\t\t\tNETIF_MSG_LINK);\n\tif (debug < -1)\n\t\tpf->hw.debug_mask = debug;\n\n\t \n\tif (hw->revision_id == 0 &&\n\t    (rd32(hw, I40E_GLLAN_RCTL_0) & I40E_GLLAN_RCTL_0_PXE_MODE_MASK)) {\n\t\twr32(hw, I40E_GLGEN_RTRIG, I40E_GLGEN_RTRIG_CORER_MASK);\n\t\ti40e_flush(hw);\n\t\tmsleep(200);\n\t\tpf->corer_count++;\n\n\t\ti40e_clear_pxe_mode(hw);\n\t}\n\n\t \n\ti40e_clear_hw(hw);\n\n\terr = i40e_set_mac_type(hw);\n\tif (err) {\n\t\tdev_warn(&pdev->dev, \"unidentified MAC or BLANK NVM: %d\\n\",\n\t\t\t err);\n\t\tgoto err_pf_reset;\n\t}\n\n\terr = i40e_handle_resets(pf);\n\tif (err)\n\t\tgoto err_pf_reset;\n\n\ti40e_check_recovery_mode(pf);\n\n\tif (is_kdump_kernel()) {\n\t\thw->aq.num_arq_entries = I40E_MIN_ARQ_LEN;\n\t\thw->aq.num_asq_entries = I40E_MIN_ASQ_LEN;\n\t} else {\n\t\thw->aq.num_arq_entries = I40E_AQ_LEN;\n\t\thw->aq.num_asq_entries = I40E_AQ_LEN;\n\t}\n\thw->aq.arq_buf_size = I40E_MAX_AQ_BUF_SIZE;\n\thw->aq.asq_buf_size = I40E_MAX_AQ_BUF_SIZE;\n\tpf->adminq_work_limit = I40E_AQ_WORK_LIMIT;\n\n\tsnprintf(pf->int_name, sizeof(pf->int_name) - 1,\n\t\t \"%s-%s:misc\",\n\t\t dev_driver_string(&pf->pdev->dev), dev_name(&pdev->dev));\n\n\terr = i40e_init_shared_code(hw);\n\tif (err) {\n\t\tdev_warn(&pdev->dev, \"unidentified MAC or BLANK NVM: %d\\n\",\n\t\t\t err);\n\t\tgoto err_pf_reset;\n\t}\n\n\t \n\tpf->hw.fc.requested_mode = I40E_FC_NONE;\n\n\terr = i40e_init_adminq(hw);\n\tif (err) {\n\t\tif (err == -EIO)\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"The driver for the device stopped because the NVM image v%u.%u is newer than expected v%u.%u. You must install the most recent version of the network driver.\\n\",\n\t\t\t\t hw->aq.api_maj_ver,\n\t\t\t\t hw->aq.api_min_ver,\n\t\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t\t I40E_FW_MINOR_VERSION(hw));\n\t\telse\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"The driver for the device stopped because the device firmware failed to init. Try updating your NVM image.\\n\");\n\n\t\tgoto err_pf_reset;\n\t}\n\ti40e_get_oem_version(hw);\n\n\t \n\tdev_info(&pdev->dev, \"fw %d.%d.%05d api %d.%d nvm %s [%04x:%04x] [%04x:%04x]\\n\",\n\t\t hw->aq.fw_maj_ver, hw->aq.fw_min_ver, hw->aq.fw_build,\n\t\t hw->aq.api_maj_ver, hw->aq.api_min_ver,\n\t\t i40e_nvm_version_str(hw), hw->vendor_id, hw->device_id,\n\t\t hw->subsystem_vendor_id, hw->subsystem_device_id);\n\n\tif (hw->aq.api_maj_ver == I40E_FW_API_VERSION_MAJOR &&\n\t    hw->aq.api_min_ver > I40E_FW_MINOR_VERSION(hw))\n\t\tdev_dbg(&pdev->dev,\n\t\t\t\"The driver for the device detected a newer version of the NVM image v%u.%u than v%u.%u.\\n\",\n\t\t\t hw->aq.api_maj_ver,\n\t\t\t hw->aq.api_min_ver,\n\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t I40E_FW_MINOR_VERSION(hw));\n\telse if (hw->aq.api_maj_ver == 1 && hw->aq.api_min_ver < 4)\n\t\tdev_info(&pdev->dev,\n\t\t\t \"The driver for the device detected an older version of the NVM image v%u.%u than expected v%u.%u. Please update the NVM image.\\n\",\n\t\t\t hw->aq.api_maj_ver,\n\t\t\t hw->aq.api_min_ver,\n\t\t\t I40E_FW_API_VERSION_MAJOR,\n\t\t\t I40E_FW_MINOR_VERSION(hw));\n\n\ti40e_verify_eeprom(pf);\n\n\t \n\tif (hw->revision_id < 1)\n\t\tdev_warn(&pdev->dev, \"This device is a pre-production adapter/LOM. Please be aware there may be issues with your hardware. If you are experiencing problems please contact your Intel or hardware representative who provided you with this hardware.\\n\");\n\n\ti40e_clear_pxe_mode(hw);\n\n\terr = i40e_get_capabilities(pf, i40e_aqc_opc_list_func_capabilities);\n\tif (err)\n\t\tgoto err_adminq_setup;\n\n\terr = i40e_sw_init(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"sw_init failed: %d\\n\", err);\n\t\tgoto err_sw_init;\n\t}\n\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\treturn i40e_init_recovery_mode(pf, hw);\n\n\terr = i40e_init_lan_hmc(hw, hw->func_caps.num_tx_qp,\n\t\t\t\thw->func_caps.num_rx_qp, 0, 0);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"init_lan_hmc failed: %d\\n\", err);\n\t\tgoto err_init_lan_hmc;\n\t}\n\n\terr = i40e_configure_lan_hmc(hw, I40E_HMC_MODEL_DIRECT_ONLY);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"configure_lan_hmc failed: %d\\n\", err);\n\t\terr = -ENOENT;\n\t\tgoto err_configure_lan_hmc;\n\t}\n\n\t \n\tif (pf->hw_features & I40E_HW_STOP_FW_LLDP) {\n\t\tdev_info(&pdev->dev, \"Stopping firmware LLDP agent.\\n\");\n\t\ti40e_aq_stop_lldp(hw, true, false, NULL);\n\t}\n\n\t \n\ti40e_get_platform_mac_addr(pdev, pf);\n\n\tif (!is_valid_ether_addr(hw->mac.addr)) {\n\t\tdev_info(&pdev->dev, \"invalid MAC address %pM\\n\", hw->mac.addr);\n\t\terr = -EIO;\n\t\tgoto err_mac_addr;\n\t}\n\tdev_info(&pdev->dev, \"MAC address: %pM\\n\", hw->mac.addr);\n\tether_addr_copy(hw->mac.perm_addr, hw->mac.addr);\n\ti40e_get_port_mac_addr(hw, hw->mac.port_addr);\n\tif (is_valid_ether_addr(hw->mac.port_addr))\n\t\tpf->hw_features |= I40E_HW_PORT_ID_VALID;\n\n\ti40e_ptp_alloc_pins(pf);\n\tpci_set_drvdata(pdev, pf);\n\tpci_save_state(pdev);\n\n#ifdef CONFIG_I40E_DCB\n\tstatus = i40e_get_fw_lldp_status(&pf->hw, &lldp_status);\n\t(!status &&\n\t lldp_status == I40E_GET_FW_LLDP_STATUS_ENABLED) ?\n\t\t(pf->flags &= ~I40E_FLAG_DISABLE_FW_LLDP) :\n\t\t(pf->flags |= I40E_FLAG_DISABLE_FW_LLDP);\n\tdev_info(&pdev->dev,\n\t\t (pf->flags & I40E_FLAG_DISABLE_FW_LLDP) ?\n\t\t\t\"FW LLDP is disabled\\n\" :\n\t\t\t\"FW LLDP is enabled\\n\");\n\n\t \n\ti40e_aq_set_dcb_parameters(hw, true, NULL);\n\n\terr = i40e_init_pf_dcb(pf);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"DCB init failed %d, disabled\\n\", err);\n\t\tpf->flags &= ~(I40E_FLAG_DCB_CAPABLE | I40E_FLAG_DCB_ENABLED);\n\t\t \n\t}\n#endif  \n\n\t \n\ttimer_setup(&pf->service_timer, i40e_service_timer, 0);\n\tpf->service_timer_period = HZ;\n\n\tINIT_WORK(&pf->service_task, i40e_service_task);\n\tclear_bit(__I40E_SERVICE_SCHED, pf->state);\n\n\t \n\ti40e_read_nvm_word(hw, I40E_SR_NVM_WAKE_ON_LAN, &wol_nvm_bits);\n\tif (BIT (hw->port) & wol_nvm_bits || hw->partition_id != 1)\n\t\tpf->wol_en = false;\n\telse\n\t\tpf->wol_en = true;\n\tdevice_set_wakeup_enable(&pf->pdev->dev, pf->wol_en);\n\n\t \n\ti40e_determine_queue_usage(pf);\n\terr = i40e_init_interrupt_scheme(pf);\n\tif (err)\n\t\tgoto err_switch_setup;\n\n\t \n\tif (is_kdump_kernel())\n\t\tpf->num_lan_msix = 1;\n\n\tpf->udp_tunnel_nic.set_port = i40e_udp_tunnel_set_port;\n\tpf->udp_tunnel_nic.unset_port = i40e_udp_tunnel_unset_port;\n\tpf->udp_tunnel_nic.flags = UDP_TUNNEL_NIC_INFO_MAY_SLEEP;\n\tpf->udp_tunnel_nic.shared = &pf->udp_tunnel_shared;\n\tpf->udp_tunnel_nic.tables[0].n_entries = I40E_MAX_PF_UDP_OFFLOAD_PORTS;\n\tpf->udp_tunnel_nic.tables[0].tunnel_types = UDP_TUNNEL_TYPE_VXLAN |\n\t\t\t\t\t\t    UDP_TUNNEL_TYPE_GENEVE;\n\n\t \n\tif (pf->hw.func_caps.num_vsis < I40E_MIN_VSI_ALLOC)\n\t\tpf->num_alloc_vsi = I40E_MIN_VSI_ALLOC;\n\telse\n\t\tpf->num_alloc_vsi = pf->hw.func_caps.num_vsis;\n\tif (pf->num_alloc_vsi > UDP_TUNNEL_NIC_MAX_SHARING_DEVICES) {\n\t\tdev_warn(&pf->pdev->dev,\n\t\t\t \"limiting the VSI count due to UDP tunnel limitation %d > %d\\n\",\n\t\t\t pf->num_alloc_vsi, UDP_TUNNEL_NIC_MAX_SHARING_DEVICES);\n\t\tpf->num_alloc_vsi = UDP_TUNNEL_NIC_MAX_SHARING_DEVICES;\n\t}\n\n\t \n\tpf->vsi = kcalloc(pf->num_alloc_vsi, sizeof(struct i40e_vsi *),\n\t\t\t  GFP_KERNEL);\n\tif (!pf->vsi) {\n\t\terr = -ENOMEM;\n\t\tgoto err_switch_setup;\n\t}\n\n#ifdef CONFIG_PCI_IOV\n\t \n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    !test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\tif (pci_num_vf(pdev))\n\t\t\tpf->flags |= I40E_FLAG_VEB_MODE_ENABLED;\n\t}\n#endif\n\terr = i40e_setup_pf_switch(pf, false, false);\n\tif (err) {\n\t\tdev_info(&pdev->dev, \"setup_pf_switch failed: %d\\n\", err);\n\t\tgoto err_vsis;\n\t}\n\tINIT_LIST_HEAD(&pf->vsi[pf->lan_vsi]->ch_list);\n\n\t \n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i] && pf->vsi[i]->type == I40E_VSI_FDIR) {\n\t\t\ti40e_vsi_open(pf->vsi[i]);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\terr = i40e_aq_set_phy_int_mask(&pf->hw,\n\t\t\t\t       ~(I40E_AQ_EVENT_LINK_UPDOWN |\n\t\t\t\t\t I40E_AQ_EVENT_MEDIA_NA |\n\t\t\t\t\t I40E_AQ_EVENT_MODULE_QUAL_FAIL), NULL);\n\tif (err)\n\t\tdev_info(&pf->pdev->dev, \"set phy mask fail, err %pe aq_err %s\\n\",\n\t\t\t ERR_PTR(err),\n\t\t\t i40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t \n\tval = rd32(hw, I40E_REG_MSS);\n\tif ((val & I40E_REG_MSS_MIN_MASK) > I40E_64BYTE_MSS) {\n\t\tval &= ~I40E_REG_MSS_MIN_MASK;\n\t\tval |= I40E_64BYTE_MSS;\n\t\twr32(hw, I40E_REG_MSS, val);\n\t}\n\n\tif (pf->hw_features & I40E_HW_RESTART_AUTONEG) {\n\t\tmsleep(75);\n\t\terr = i40e_aq_set_link_restart_an(&pf->hw, true, NULL);\n\t\tif (err)\n\t\t\tdev_info(&pf->pdev->dev, \"link restart failed, err %pe aq_err %s\\n\",\n\t\t\t\t ERR_PTR(err),\n\t\t\t\t i40e_aq_str(&pf->hw,\n\t\t\t\t\t     pf->hw.aq.asq_last_status));\n\t}\n\t \n\tclear_bit(__I40E_DOWN, pf->state);\n\n\t \n\tif (pf->flags & I40E_FLAG_MSIX_ENABLED) {\n\t\terr = i40e_setup_misc_vector(pf);\n\t\tif (err) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"setup of misc vector failed: %d\\n\", err);\n\t\t\ti40e_cloud_filter_exit(pf);\n\t\t\ti40e_fdir_teardown(pf);\n\t\t\tgoto err_vsis;\n\t\t}\n\t}\n\n#ifdef CONFIG_PCI_IOV\n\t \n\tif ((pf->flags & I40E_FLAG_SRIOV_ENABLED) &&\n\t    (pf->flags & I40E_FLAG_MSIX_ENABLED) &&\n\t    !test_bit(__I40E_BAD_EEPROM, pf->state)) {\n\t\t \n\t\tval = rd32(hw, I40E_PFGEN_PORTMDIO_NUM);\n\t\tval &= ~I40E_PFGEN_PORTMDIO_NUM_VFLINK_STAT_ENA_MASK;\n\t\twr32(hw, I40E_PFGEN_PORTMDIO_NUM, val);\n\t\ti40e_flush(hw);\n\n\t\tif (pci_num_vf(pdev)) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"Active VFs found, allocating resources.\\n\");\n\t\t\terr = i40e_alloc_vfs(pf, pci_num_vf(pdev));\n\t\t\tif (err)\n\t\t\t\tdev_info(&pdev->dev,\n\t\t\t\t\t \"Error %d allocating resources for existing VFs\\n\",\n\t\t\t\t\t err);\n\t\t}\n\t}\n#endif  \n\n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tpf->iwarp_base_vector = i40e_get_lump(pf, pf->irq_pile,\n\t\t\t\t\t\t      pf->num_iwarp_msix,\n\t\t\t\t\t\t      I40E_IWARP_IRQ_PILE_ID);\n\t\tif (pf->iwarp_base_vector < 0) {\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"failed to get tracking for %d vectors for IWARP err=%d\\n\",\n\t\t\t\t pf->num_iwarp_msix, pf->iwarp_base_vector);\n\t\t\tpf->flags &= ~I40E_FLAG_IWARP_ENABLED;\n\t\t}\n\t}\n\n\ti40e_dbg_pf_init(pf);\n\n\t \n\ti40e_send_version(pf);\n\n\t \n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\t \n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\terr = i40e_lan_add_device(pf);\n\t\tif (err)\n\t\t\tdev_info(&pdev->dev, \"Failed to add PF to client API service list: %d\\n\",\n\t\t\t\t err);\n\t}\n\n#define PCI_SPEED_SIZE 8\n#define PCI_WIDTH_SIZE 8\n\t \n\tif (!(pf->hw_features & I40E_HW_NO_PCI_LINK_CHECK)) {\n\t\tchar speed[PCI_SPEED_SIZE] = \"Unknown\";\n\t\tchar width[PCI_WIDTH_SIZE] = \"Unknown\";\n\n\t\t \n\t\tpcie_capability_read_word(pf->pdev, PCI_EXP_LNKSTA,\n\t\t\t\t\t  &link_status);\n\n\t\ti40e_set_pci_config_data(hw, link_status);\n\n\t\tswitch (hw->bus.speed) {\n\t\tcase i40e_bus_speed_8000:\n\t\t\tstrscpy(speed, \"8.0\", PCI_SPEED_SIZE); break;\n\t\tcase i40e_bus_speed_5000:\n\t\t\tstrscpy(speed, \"5.0\", PCI_SPEED_SIZE); break;\n\t\tcase i40e_bus_speed_2500:\n\t\t\tstrscpy(speed, \"2.5\", PCI_SPEED_SIZE); break;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tswitch (hw->bus.width) {\n\t\tcase i40e_bus_width_pcie_x8:\n\t\t\tstrscpy(width, \"8\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x4:\n\t\t\tstrscpy(width, \"4\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x2:\n\t\t\tstrscpy(width, \"2\", PCI_WIDTH_SIZE); break;\n\t\tcase i40e_bus_width_pcie_x1:\n\t\t\tstrscpy(width, \"1\", PCI_WIDTH_SIZE); break;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tdev_info(&pdev->dev, \"PCI-Express: Speed %sGT/s Width x%s\\n\",\n\t\t\t speed, width);\n\n\t\tif (hw->bus.width < i40e_bus_width_pcie_x8 ||\n\t\t    hw->bus.speed < i40e_bus_speed_8000) {\n\t\t\tdev_warn(&pdev->dev, \"PCI-Express bandwidth available for this device may be insufficient for optimal performance.\\n\");\n\t\t\tdev_warn(&pdev->dev, \"Please move the device to a different PCI-e link with more lanes and/or higher transfer rate.\\n\");\n\t\t}\n\t}\n\n\t \n\terr = i40e_aq_get_phy_capabilities(hw, false, false, &abilities, NULL);\n\tif (err)\n\t\tdev_dbg(&pf->pdev->dev, \"get requested speeds ret =  %pe last_status =  %s\\n\",\n\t\t\tERR_PTR(err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\tpf->hw.phy.link_info.requested_speeds = abilities.link_speed;\n\n\t \n\ti40e_set_fec_in_flags(abilities.fec_cfg_curr_mod_ext_info, &pf->flags);\n\n\t \n\terr = i40e_aq_get_phy_capabilities(hw, false, true, &abilities, NULL);\n\tif (err)\n\t\tdev_dbg(&pf->pdev->dev, \"get supported phy types ret =  %pe last_status =  %s\\n\",\n\t\t\tERR_PTR(err),\n\t\t\ti40e_aq_str(&pf->hw, pf->hw.aq.asq_last_status));\n\n\t \n#define MAX_FRAME_SIZE_DEFAULT 0x2600\n\tval = (rd32(&pf->hw, I40E_PRTGL_SAH) &\n\t       I40E_PRTGL_SAH_MFS_MASK) >> I40E_PRTGL_SAH_MFS_SHIFT;\n\tif (val < MAX_FRAME_SIZE_DEFAULT)\n\t\tdev_warn(&pdev->dev, \"MFS for port %x has been set below the default: %x\\n\",\n\t\t\t pf->hw.port, val);\n\n\t \n\ti40e_add_filter_to_drop_tx_flow_control_frames(&pf->hw,\n\t\t\t\t\t\t       pf->main_vsi_seid);\n\n\tif ((pf->hw.device_id == I40E_DEV_ID_10G_BASE_T) ||\n\t\t(pf->hw.device_id == I40E_DEV_ID_10G_BASE_T4))\n\t\tpf->hw_features |= I40E_HW_PHY_CONTROLS_LEDS;\n\tif (pf->hw.device_id == I40E_DEV_ID_SFP_I_X722)\n\t\tpf->hw_features |= I40E_HW_HAVE_CRT_RETIMER;\n\t \n\ti40e_print_features(pf);\n\n\treturn 0;\n\n\t \nerr_vsis:\n\tset_bit(__I40E_DOWN, pf->state);\n\ti40e_clear_interrupt_scheme(pf);\n\tkfree(pf->vsi);\nerr_switch_setup:\n\ti40e_reset_interrupt_capability(pf);\n\ttimer_shutdown_sync(&pf->service_timer);\nerr_mac_addr:\nerr_configure_lan_hmc:\n\t(void)i40e_shutdown_lan_hmc(hw);\nerr_init_lan_hmc:\n\tkfree(pf->qp_pile);\nerr_sw_init:\nerr_adminq_setup:\nerr_pf_reset:\n\tiounmap(hw->hw_addr);\nerr_ioremap:\n\tkfree(pf);\nerr_pf_alloc:\n\tpci_release_mem_regions(pdev);\nerr_pci_reg:\nerr_dma:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n \nstatic void i40e_remove(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tstruct i40e_hw *hw = &pf->hw;\n\tint ret_code;\n\tint i;\n\n\ti40e_dbg_pf_exit(pf);\n\n\ti40e_ptp_stop(pf);\n\n\t \n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(0), 0);\n\ti40e_write_rx_ctl(hw, I40E_PFQF_HENA(1), 0);\n\n\t \n\twhile (test_and_set_bit(__I40E_RESET_RECOVERY_PENDING, pf->state))\n\t\tusleep_range(1000, 2000);\n\tset_bit(__I40E_IN_REMOVE, pf->state);\n\n\tif (pf->flags & I40E_FLAG_SRIOV_ENABLED) {\n\t\tset_bit(__I40E_VF_RESETS_DISABLED, pf->state);\n\t\ti40e_free_vfs(pf);\n\t\tpf->flags &= ~I40E_FLAG_SRIOV_ENABLED;\n\t}\n\t \n\tset_bit(__I40E_SUSPENDED, pf->state);\n\tset_bit(__I40E_DOWN, pf->state);\n\tif (pf->service_timer.function)\n\t\ttimer_shutdown_sync(&pf->service_timer);\n\tif (pf->service_task.func)\n\t\tcancel_work_sync(&pf->service_task);\n\n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state)) {\n\t\tstruct i40e_vsi *vsi = pf->vsi[0];\n\n\t\t \n\t\tunregister_netdev(vsi->netdev);\n\t\tfree_netdev(vsi->netdev);\n\n\t\tgoto unmap;\n\t}\n\n\t \n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\ti40e_fdir_teardown(pf);\n\n\t \n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tif (!pf->veb[i])\n\t\t\tcontinue;\n\n\t\tif (pf->veb[i]->uplink_seid == pf->mac_seid ||\n\t\t    pf->veb[i]->uplink_seid == 0)\n\t\t\ti40e_switch_branch_release(pf->veb[i]);\n\t}\n\n\t \n\tfor (i = pf->num_alloc_vsi; i--;)\n\t\tif (pf->vsi[i]) {\n\t\t\ti40e_vsi_close(pf->vsi[i]);\n\t\t\ti40e_vsi_release(pf->vsi[i]);\n\t\t\tpf->vsi[i] = NULL;\n\t\t}\n\n\ti40e_cloud_filter_exit(pf);\n\n\t \n\tif (pf->flags & I40E_FLAG_IWARP_ENABLED) {\n\t\tret_code = i40e_lan_del_device(pf);\n\t\tif (ret_code)\n\t\t\tdev_warn(&pdev->dev, \"Failed to delete client device: %d\\n\",\n\t\t\t\t ret_code);\n\t}\n\n\t \n\tif (hw->hmc.hmc_obj) {\n\t\tret_code = i40e_shutdown_lan_hmc(hw);\n\t\tif (ret_code)\n\t\t\tdev_warn(&pdev->dev,\n\t\t\t\t \"Failed to destroy the HMC resources: %d\\n\",\n\t\t\t\t ret_code);\n\t}\n\nunmap:\n\t \n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t \n\ti40e_shutdown_adminq(hw);\n\n\t \n\tmutex_destroy(&hw->aq.arq_mutex);\n\tmutex_destroy(&hw->aq.asq_mutex);\n\n\t \n\trtnl_lock();\n\ti40e_clear_interrupt_scheme(pf);\n\tfor (i = 0; i < pf->num_alloc_vsi; i++) {\n\t\tif (pf->vsi[i]) {\n\t\t\tif (!test_bit(__I40E_RECOVERY_MODE, pf->state))\n\t\t\t\ti40e_vsi_clear_rings(pf->vsi[i]);\n\t\t\ti40e_vsi_clear(pf->vsi[i]);\n\t\t\tpf->vsi[i] = NULL;\n\t\t}\n\t}\n\trtnl_unlock();\n\n\tfor (i = 0; i < I40E_MAX_VEB; i++) {\n\t\tkfree(pf->veb[i]);\n\t\tpf->veb[i] = NULL;\n\t}\n\n\tkfree(pf->qp_pile);\n\tkfree(pf->vsi);\n\n\tiounmap(hw->hw_addr);\n\tkfree(pf);\n\tpci_release_mem_regions(pdev);\n\n\tpci_disable_device(pdev);\n}\n\n \nstatic pci_ers_result_t i40e_pci_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\tpci_channel_state_t error)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\tdev_info(&pdev->dev, \"%s: error %d\\n\", __func__, error);\n\n\tif (!pf) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"Cannot recover - error happened during device probe\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\t \n\tif (!test_bit(__I40E_SUSPENDED, pf->state))\n\t\ti40e_prep_for_reset(pf);\n\n\t \n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\n \nstatic pci_ers_result_t i40e_pci_error_slot_reset(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tpci_ers_result_t result;\n\tu32 reg;\n\n\tdev_dbg(&pdev->dev, \"%s\\n\", __func__);\n\tif (pci_enable_device_mem(pdev)) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"Cannot re-enable PCI device after reset.\\n\");\n\t\tresult = PCI_ERS_RESULT_DISCONNECT;\n\t} else {\n\t\tpci_set_master(pdev);\n\t\tpci_restore_state(pdev);\n\t\tpci_save_state(pdev);\n\t\tpci_wake_from_d3(pdev, false);\n\n\t\treg = rd32(&pf->hw, I40E_GLGEN_RTRIG);\n\t\tif (reg == 0)\n\t\t\tresult = PCI_ERS_RESULT_RECOVERED;\n\t\telse\n\t\t\tresult = PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\treturn result;\n}\n\n \nstatic void i40e_pci_error_reset_prepare(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\ti40e_prep_for_reset(pf);\n}\n\n \nstatic void i40e_pci_error_reset_done(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\tif (test_bit(__I40E_IN_REMOVE, pf->state))\n\t\treturn;\n\n\ti40e_reset_and_rebuild(pf, false, false);\n#ifdef CONFIG_PCI_IOV\n\ti40e_restore_all_vfs_msi_state(pdev);\n#endif  \n}\n\n \nstatic void i40e_pci_error_resume(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\n\tdev_dbg(&pdev->dev, \"%s\\n\", __func__);\n\tif (test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn;\n\n\ti40e_handle_reset_warning(pf, false);\n}\n\n \nstatic void i40e_enable_mc_magic_wake(struct i40e_pf *pf)\n{\n\tstruct i40e_hw *hw = &pf->hw;\n\tu8 mac_addr[6];\n\tu16 flags = 0;\n\tint ret;\n\n\t \n\tif (pf->vsi[pf->lan_vsi] && pf->vsi[pf->lan_vsi]->netdev) {\n\t\tether_addr_copy(mac_addr,\n\t\t\t\tpf->vsi[pf->lan_vsi]->netdev->dev_addr);\n\t} else {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to retrieve MAC address; using default\\n\");\n\t\tether_addr_copy(mac_addr, hw->mac.addr);\n\t}\n\n\t \n\tflags = I40E_AQC_WRITE_TYPE_LAA_WOL;\n\n\tif (hw->func_caps.flex10_enable && hw->partition_id != 1)\n\t\tflags = I40E_AQC_WRITE_TYPE_LAA_ONLY;\n\n\tret = i40e_aq_mac_address_write(hw, flags, mac_addr, NULL);\n\tif (ret) {\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to update MAC address registers; cannot enable Multicast Magic packet wake up\");\n\t\treturn;\n\t}\n\n\tflags = I40E_AQC_MC_MAG_EN\n\t\t\t| I40E_AQC_WOL_PRESERVE_ON_PFR\n\t\t\t| I40E_AQC_WRITE_TYPE_UPDATE_MC_MAG;\n\tret = i40e_aq_mac_address_write(hw, flags, mac_addr, NULL);\n\tif (ret)\n\t\tdev_err(&pf->pdev->dev,\n\t\t\t\"Failed to enable Multicast Magic Packet wake up\\n\");\n}\n\n \nstatic void i40e_shutdown(struct pci_dev *pdev)\n{\n\tstruct i40e_pf *pf = pci_get_drvdata(pdev);\n\tstruct i40e_hw *hw = &pf->hw;\n\n\tset_bit(__I40E_SUSPENDED, pf->state);\n\tset_bit(__I40E_DOWN, pf->state);\n\n\tdel_timer_sync(&pf->service_timer);\n\tcancel_work_sync(&pf->service_task);\n\ti40e_cloud_filter_exit(pf);\n\ti40e_fdir_teardown(pf);\n\n\t \n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->wol_en && (pf->hw_features & I40E_HW_WOL_MC_MAGIC_PKT_WAKE))\n\t\ti40e_enable_mc_magic_wake(pf);\n\n\ti40e_prep_for_reset(pf);\n\n\twr32(hw, I40E_PFPM_APM,\n\t     (pf->wol_en ? I40E_PFPM_APM_APME_MASK : 0));\n\twr32(hw, I40E_PFPM_WUFC,\n\t     (pf->wol_en ? I40E_PFPM_WUFC_MAG_MASK : 0));\n\n\t \n\tif (test_bit(__I40E_RECOVERY_MODE, pf->state) &&\n\t    !(pf->flags & I40E_FLAG_MSIX_ENABLED))\n\t\tfree_irq(pf->pdev->irq, pf);\n\n\t \n\trtnl_lock();\n\ti40e_clear_interrupt_scheme(pf);\n\trtnl_unlock();\n\n\tif (system_state == SYSTEM_POWER_OFF) {\n\t\tpci_wake_from_d3(pdev, pf->wol_en);\n\t\tpci_set_power_state(pdev, PCI_D3hot);\n\t}\n}\n\n \nstatic int __maybe_unused i40e_suspend(struct device *dev)\n{\n\tstruct i40e_pf *pf = dev_get_drvdata(dev);\n\tstruct i40e_hw *hw = &pf->hw;\n\n\t \n\tif (test_and_set_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn 0;\n\n\tset_bit(__I40E_DOWN, pf->state);\n\n\t \n\tdel_timer_sync(&pf->service_timer);\n\tcancel_work_sync(&pf->service_task);\n\n\t \n\ti40e_notify_client_of_netdev_close(pf->vsi[pf->lan_vsi], false);\n\n\tif (pf->wol_en && (pf->hw_features & I40E_HW_WOL_MC_MAGIC_PKT_WAKE))\n\t\ti40e_enable_mc_magic_wake(pf);\n\n\t \n\trtnl_lock();\n\n\ti40e_prep_for_reset(pf);\n\n\twr32(hw, I40E_PFPM_APM, (pf->wol_en ? I40E_PFPM_APM_APME_MASK : 0));\n\twr32(hw, I40E_PFPM_WUFC, (pf->wol_en ? I40E_PFPM_WUFC_MAG_MASK : 0));\n\n\t \n\ti40e_clear_interrupt_scheme(pf);\n\n\trtnl_unlock();\n\n\treturn 0;\n}\n\n \nstatic int __maybe_unused i40e_resume(struct device *dev)\n{\n\tstruct i40e_pf *pf = dev_get_drvdata(dev);\n\tint err;\n\n\t \n\tif (!test_bit(__I40E_SUSPENDED, pf->state))\n\t\treturn 0;\n\n\t \n\trtnl_lock();\n\n\t \n\terr = i40e_restore_interrupt_scheme(pf);\n\tif (err) {\n\t\tdev_err(dev, \"Cannot restore interrupt scheme: %d\\n\",\n\t\t\terr);\n\t}\n\n\tclear_bit(__I40E_DOWN, pf->state);\n\ti40e_reset_and_rebuild(pf, false, true);\n\n\trtnl_unlock();\n\n\t \n\tclear_bit(__I40E_SUSPENDED, pf->state);\n\n\t \n\tmod_timer(&pf->service_timer,\n\t\t  round_jiffies(jiffies + pf->service_timer_period));\n\n\treturn 0;\n}\n\nstatic const struct pci_error_handlers i40e_err_handler = {\n\t.error_detected = i40e_pci_error_detected,\n\t.slot_reset = i40e_pci_error_slot_reset,\n\t.reset_prepare = i40e_pci_error_reset_prepare,\n\t.reset_done = i40e_pci_error_reset_done,\n\t.resume = i40e_pci_error_resume,\n};\n\nstatic SIMPLE_DEV_PM_OPS(i40e_pm_ops, i40e_suspend, i40e_resume);\n\nstatic struct pci_driver i40e_driver = {\n\t.name     = i40e_driver_name,\n\t.id_table = i40e_pci_tbl,\n\t.probe    = i40e_probe,\n\t.remove   = i40e_remove,\n\t.driver   = {\n\t\t.pm = &i40e_pm_ops,\n\t},\n\t.shutdown = i40e_shutdown,\n\t.err_handler = &i40e_err_handler,\n\t.sriov_configure = i40e_pci_sriov_configure,\n};\n\n \nstatic int __init i40e_init_module(void)\n{\n\tint err;\n\n\tpr_info(\"%s: %s\\n\", i40e_driver_name, i40e_driver_string);\n\tpr_info(\"%s: %s\\n\", i40e_driver_name, i40e_copyright);\n\n\t \n\ti40e_wq = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0, i40e_driver_name);\n\tif (!i40e_wq) {\n\t\tpr_err(\"%s: Failed to create workqueue\\n\", i40e_driver_name);\n\t\treturn -ENOMEM;\n\t}\n\n\ti40e_dbg_init();\n\terr = pci_register_driver(&i40e_driver);\n\tif (err) {\n\t\tdestroy_workqueue(i40e_wq);\n\t\ti40e_dbg_exit();\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\nmodule_init(i40e_init_module);\n\n \nstatic void __exit i40e_exit_module(void)\n{\n\tpci_unregister_driver(&i40e_driver);\n\tdestroy_workqueue(i40e_wq);\n\tida_destroy(&i40e_client_ida);\n\ti40e_dbg_exit();\n}\nmodule_exit(i40e_exit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}