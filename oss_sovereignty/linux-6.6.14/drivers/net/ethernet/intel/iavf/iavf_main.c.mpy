{
  "module_name": "iavf_main.c",
  "hash_id": "d0a47c18407b8247c5e6aeb6fa373514b2cda86b0952d232db42dd6fd06b2f89",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/iavf/iavf_main.c",
  "human_readable_source": "\n \n\n#include \"iavf.h\"\n#include \"iavf_prototype.h\"\n#include \"iavf_client.h\"\n \n#define CREATE_TRACE_POINTS\n#include \"iavf_trace.h\"\n\nstatic int iavf_setup_all_tx_resources(struct iavf_adapter *adapter);\nstatic int iavf_setup_all_rx_resources(struct iavf_adapter *adapter);\nstatic int iavf_close(struct net_device *netdev);\nstatic void iavf_init_get_resources(struct iavf_adapter *adapter);\nstatic int iavf_check_reset_complete(struct iavf_hw *hw);\n\nchar iavf_driver_name[] = \"iavf\";\nstatic const char iavf_driver_string[] =\n\t\"Intel(R) Ethernet Adaptive Virtual Function Network Driver\";\n\nstatic const char iavf_copyright[] =\n\t\"Copyright (c) 2013 - 2018 Intel Corporation.\";\n\n \nstatic const struct pci_device_id iavf_pci_tbl[] = {\n\t{PCI_VDEVICE(INTEL, IAVF_DEV_ID_VF), 0},\n\t{PCI_VDEVICE(INTEL, IAVF_DEV_ID_VF_HV), 0},\n\t{PCI_VDEVICE(INTEL, IAVF_DEV_ID_X722_VF), 0},\n\t{PCI_VDEVICE(INTEL, IAVF_DEV_ID_ADAPTIVE_VF), 0},\n\t \n\t{0, }\n};\n\nMODULE_DEVICE_TABLE(pci, iavf_pci_tbl);\n\nMODULE_ALIAS(\"i40evf\");\nMODULE_AUTHOR(\"Intel Corporation, <linux.nics@intel.com>\");\nMODULE_DESCRIPTION(\"Intel(R) Ethernet Adaptive Virtual Function Network Driver\");\nMODULE_LICENSE(\"GPL v2\");\n\nstatic const struct net_device_ops iavf_netdev_ops;\n\nint iavf_status_to_errno(enum iavf_status status)\n{\n\tswitch (status) {\n\tcase IAVF_SUCCESS:\n\t\treturn 0;\n\tcase IAVF_ERR_PARAM:\n\tcase IAVF_ERR_MAC_TYPE:\n\tcase IAVF_ERR_INVALID_MAC_ADDR:\n\tcase IAVF_ERR_INVALID_LINK_SETTINGS:\n\tcase IAVF_ERR_INVALID_PD_ID:\n\tcase IAVF_ERR_INVALID_QP_ID:\n\tcase IAVF_ERR_INVALID_CQ_ID:\n\tcase IAVF_ERR_INVALID_CEQ_ID:\n\tcase IAVF_ERR_INVALID_AEQ_ID:\n\tcase IAVF_ERR_INVALID_SIZE:\n\tcase IAVF_ERR_INVALID_ARP_INDEX:\n\tcase IAVF_ERR_INVALID_FPM_FUNC_ID:\n\tcase IAVF_ERR_QP_INVALID_MSG_SIZE:\n\tcase IAVF_ERR_INVALID_FRAG_COUNT:\n\tcase IAVF_ERR_INVALID_ALIGNMENT:\n\tcase IAVF_ERR_INVALID_PUSH_PAGE_INDEX:\n\tcase IAVF_ERR_INVALID_IMM_DATA_SIZE:\n\tcase IAVF_ERR_INVALID_VF_ID:\n\tcase IAVF_ERR_INVALID_HMCFN_ID:\n\tcase IAVF_ERR_INVALID_PBLE_INDEX:\n\tcase IAVF_ERR_INVALID_SD_INDEX:\n\tcase IAVF_ERR_INVALID_PAGE_DESC_INDEX:\n\tcase IAVF_ERR_INVALID_SD_TYPE:\n\tcase IAVF_ERR_INVALID_HMC_OBJ_INDEX:\n\tcase IAVF_ERR_INVALID_HMC_OBJ_COUNT:\n\tcase IAVF_ERR_INVALID_SRQ_ARM_LIMIT:\n\t\treturn -EINVAL;\n\tcase IAVF_ERR_NVM:\n\tcase IAVF_ERR_NVM_CHECKSUM:\n\tcase IAVF_ERR_PHY:\n\tcase IAVF_ERR_CONFIG:\n\tcase IAVF_ERR_UNKNOWN_PHY:\n\tcase IAVF_ERR_LINK_SETUP:\n\tcase IAVF_ERR_ADAPTER_STOPPED:\n\tcase IAVF_ERR_PRIMARY_REQUESTS_PENDING:\n\tcase IAVF_ERR_AUTONEG_NOT_COMPLETE:\n\tcase IAVF_ERR_RESET_FAILED:\n\tcase IAVF_ERR_BAD_PTR:\n\tcase IAVF_ERR_SWFW_SYNC:\n\tcase IAVF_ERR_QP_TOOMANY_WRS_POSTED:\n\tcase IAVF_ERR_QUEUE_EMPTY:\n\tcase IAVF_ERR_FLUSHED_QUEUE:\n\tcase IAVF_ERR_OPCODE_MISMATCH:\n\tcase IAVF_ERR_CQP_COMPL_ERROR:\n\tcase IAVF_ERR_BACKING_PAGE_ERROR:\n\tcase IAVF_ERR_NO_PBLCHUNKS_AVAILABLE:\n\tcase IAVF_ERR_MEMCPY_FAILED:\n\tcase IAVF_ERR_SRQ_ENABLED:\n\tcase IAVF_ERR_ADMIN_QUEUE_ERROR:\n\tcase IAVF_ERR_ADMIN_QUEUE_FULL:\n\tcase IAVF_ERR_BAD_RDMA_CQE:\n\tcase IAVF_ERR_NVM_BLANK_MODE:\n\tcase IAVF_ERR_PE_DOORBELL_NOT_ENABLED:\n\tcase IAVF_ERR_DIAG_TEST_FAILED:\n\tcase IAVF_ERR_FIRMWARE_API_VERSION:\n\tcase IAVF_ERR_ADMIN_QUEUE_CRITICAL_ERROR:\n\t\treturn -EIO;\n\tcase IAVF_ERR_DEVICE_NOT_SUPPORTED:\n\t\treturn -ENODEV;\n\tcase IAVF_ERR_NO_AVAILABLE_VSI:\n\tcase IAVF_ERR_RING_FULL:\n\t\treturn -ENOSPC;\n\tcase IAVF_ERR_NO_MEMORY:\n\t\treturn -ENOMEM;\n\tcase IAVF_ERR_TIMEOUT:\n\tcase IAVF_ERR_ADMIN_QUEUE_TIMEOUT:\n\t\treturn -ETIMEDOUT;\n\tcase IAVF_ERR_NOT_IMPLEMENTED:\n\tcase IAVF_NOT_SUPPORTED:\n\t\treturn -EOPNOTSUPP;\n\tcase IAVF_ERR_ADMIN_QUEUE_NO_WORK:\n\t\treturn -EALREADY;\n\tcase IAVF_ERR_NOT_READY:\n\t\treturn -EBUSY;\n\tcase IAVF_ERR_BUF_TOO_SHORT:\n\t\treturn -EMSGSIZE;\n\t}\n\n\treturn -EIO;\n}\n\nint virtchnl_status_to_errno(enum virtchnl_status_code v_status)\n{\n\tswitch (v_status) {\n\tcase VIRTCHNL_STATUS_SUCCESS:\n\t\treturn 0;\n\tcase VIRTCHNL_STATUS_ERR_PARAM:\n\tcase VIRTCHNL_STATUS_ERR_INVALID_VF_ID:\n\t\treturn -EINVAL;\n\tcase VIRTCHNL_STATUS_ERR_NO_MEMORY:\n\t\treturn -ENOMEM;\n\tcase VIRTCHNL_STATUS_ERR_OPCODE_MISMATCH:\n\tcase VIRTCHNL_STATUS_ERR_CQP_COMPL_ERROR:\n\tcase VIRTCHNL_STATUS_ERR_ADMIN_QUEUE_ERROR:\n\t\treturn -EIO;\n\tcase VIRTCHNL_STATUS_ERR_NOT_SUPPORTED:\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn -EIO;\n}\n\n \nstatic struct iavf_adapter *iavf_pdev_to_adapter(struct pci_dev *pdev)\n{\n\treturn netdev_priv(pci_get_drvdata(pdev));\n}\n\n \nstatic bool iavf_is_reset_in_progress(struct iavf_adapter *adapter)\n{\n\tif (adapter->state == __IAVF_RESETTING ||\n\t    adapter->flags & (IAVF_FLAG_RESET_PENDING |\n\t\t\t      IAVF_FLAG_RESET_NEEDED))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nint iavf_wait_for_reset(struct iavf_adapter *adapter)\n{\n\tint ret = wait_event_interruptible_timeout(adapter->reset_waitqueue,\n\t\t\t\t\t!iavf_is_reset_in_progress(adapter),\n\t\t\t\t\tmsecs_to_jiffies(5000));\n\n\t \n\tif (ret > 0)\n\t\treturn 0;\n\telse if (ret < 0)\n\t\treturn -EINTR;\n\telse\n\t\treturn -EBUSY;\n}\n\n \nenum iavf_status iavf_allocate_dma_mem_d(struct iavf_hw *hw,\n\t\t\t\t\t struct iavf_dma_mem *mem,\n\t\t\t\t\t u64 size, u32 alignment)\n{\n\tstruct iavf_adapter *adapter = (struct iavf_adapter *)hw->back;\n\n\tif (!mem)\n\t\treturn IAVF_ERR_PARAM;\n\n\tmem->size = ALIGN(size, alignment);\n\tmem->va = dma_alloc_coherent(&adapter->pdev->dev, mem->size,\n\t\t\t\t     (dma_addr_t *)&mem->pa, GFP_KERNEL);\n\tif (mem->va)\n\t\treturn 0;\n\telse\n\t\treturn IAVF_ERR_NO_MEMORY;\n}\n\n \nenum iavf_status iavf_free_dma_mem(struct iavf_hw *hw, struct iavf_dma_mem *mem)\n{\n\tstruct iavf_adapter *adapter = (struct iavf_adapter *)hw->back;\n\n\tif (!mem || !mem->va)\n\t\treturn IAVF_ERR_PARAM;\n\tdma_free_coherent(&adapter->pdev->dev, mem->size,\n\t\t\t  mem->va, (dma_addr_t)mem->pa);\n\treturn 0;\n}\n\n \nenum iavf_status iavf_allocate_virt_mem(struct iavf_hw *hw,\n\t\t\t\t\tstruct iavf_virt_mem *mem, u32 size)\n{\n\tif (!mem)\n\t\treturn IAVF_ERR_PARAM;\n\n\tmem->size = size;\n\tmem->va = kzalloc(size, GFP_KERNEL);\n\n\tif (mem->va)\n\t\treturn 0;\n\telse\n\t\treturn IAVF_ERR_NO_MEMORY;\n}\n\n \nvoid iavf_free_virt_mem(struct iavf_hw *hw, struct iavf_virt_mem *mem)\n{\n\tkfree(mem->va);\n}\n\n \nvoid iavf_schedule_reset(struct iavf_adapter *adapter, u64 flags)\n{\n\tif (!test_bit(__IAVF_IN_REMOVE_TASK, &adapter->crit_section) &&\n\t    !(adapter->flags &\n\t    (IAVF_FLAG_RESET_PENDING | IAVF_FLAG_RESET_NEEDED))) {\n\t\tadapter->flags |= flags;\n\t\tqueue_work(adapter->wq, &adapter->reset_task);\n\t}\n}\n\n \nvoid iavf_schedule_aq_request(struct iavf_adapter *adapter, u64 flags)\n{\n\tadapter->aq_required |= flags;\n\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n}\n\n \nstatic void iavf_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tadapter->tx_timeout_count++;\n\tiavf_schedule_reset(adapter, IAVF_FLAG_RESET_NEEDED);\n}\n\n \nstatic void iavf_misc_irq_disable(struct iavf_adapter *adapter)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\tif (!adapter->msix_entries)\n\t\treturn;\n\n\twr32(hw, IAVF_VFINT_DYN_CTL01, 0);\n\n\tiavf_flush(hw);\n\n\tsynchronize_irq(adapter->msix_entries[0].vector);\n}\n\n \nstatic void iavf_misc_irq_enable(struct iavf_adapter *adapter)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\twr32(hw, IAVF_VFINT_DYN_CTL01, IAVF_VFINT_DYN_CTL01_INTENA_MASK |\n\t\t\t\t       IAVF_VFINT_DYN_CTL01_ITR_INDX_MASK);\n\twr32(hw, IAVF_VFINT_ICR0_ENA1, IAVF_VFINT_ICR0_ENA1_ADMINQ_MASK);\n\n\tiavf_flush(hw);\n}\n\n \nstatic void iavf_irq_disable(struct iavf_adapter *adapter)\n{\n\tint i;\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\tif (!adapter->msix_entries)\n\t\treturn;\n\n\tfor (i = 1; i < adapter->num_msix_vectors; i++) {\n\t\twr32(hw, IAVF_VFINT_DYN_CTLN1(i - 1), 0);\n\t\tsynchronize_irq(adapter->msix_entries[i].vector);\n\t}\n\tiavf_flush(hw);\n}\n\n \nstatic void iavf_irq_enable_queues(struct iavf_adapter *adapter)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\tint i;\n\n\tfor (i = 1; i < adapter->num_msix_vectors; i++) {\n\t\twr32(hw, IAVF_VFINT_DYN_CTLN1(i - 1),\n\t\t     IAVF_VFINT_DYN_CTLN1_INTENA_MASK |\n\t\t     IAVF_VFINT_DYN_CTLN1_ITR_INDX_MASK);\n\t}\n}\n\n \nvoid iavf_irq_enable(struct iavf_adapter *adapter, bool flush)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\tiavf_misc_irq_enable(adapter);\n\tiavf_irq_enable_queues(adapter);\n\n\tif (flush)\n\t\tiavf_flush(hw);\n}\n\n \nstatic irqreturn_t iavf_msix_aq(int irq, void *data)\n{\n\tstruct net_device *netdev = data;\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\t \n\trd32(hw, IAVF_VFINT_ICR01);\n\trd32(hw, IAVF_VFINT_ICR0_ENA1);\n\n\tif (adapter->state != __IAVF_REMOVE)\n\t\t \n\t\tqueue_work(adapter->wq, &adapter->adminq_task);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t iavf_msix_clean_rings(int irq, void *data)\n{\n\tstruct iavf_q_vector *q_vector = data;\n\n\tif (!q_vector->tx.ring && !q_vector->rx.ring)\n\t\treturn IRQ_HANDLED;\n\n\tnapi_schedule_irqoff(&q_vector->napi);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void\niavf_map_vector_to_rxq(struct iavf_adapter *adapter, int v_idx, int r_idx)\n{\n\tstruct iavf_q_vector *q_vector = &adapter->q_vectors[v_idx];\n\tstruct iavf_ring *rx_ring = &adapter->rx_rings[r_idx];\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\trx_ring->q_vector = q_vector;\n\trx_ring->next = q_vector->rx.ring;\n\trx_ring->vsi = &adapter->vsi;\n\tq_vector->rx.ring = rx_ring;\n\tq_vector->rx.count++;\n\tq_vector->rx.next_update = jiffies + 1;\n\tq_vector->rx.target_itr = ITR_TO_REG(rx_ring->itr_setting);\n\tq_vector->ring_mask |= BIT(r_idx);\n\twr32(hw, IAVF_VFINT_ITRN1(IAVF_RX_ITR, q_vector->reg_idx),\n\t     q_vector->rx.current_itr >> 1);\n\tq_vector->rx.current_itr = q_vector->rx.target_itr;\n}\n\n \nstatic void\niavf_map_vector_to_txq(struct iavf_adapter *adapter, int v_idx, int t_idx)\n{\n\tstruct iavf_q_vector *q_vector = &adapter->q_vectors[v_idx];\n\tstruct iavf_ring *tx_ring = &adapter->tx_rings[t_idx];\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\ttx_ring->q_vector = q_vector;\n\ttx_ring->next = q_vector->tx.ring;\n\ttx_ring->vsi = &adapter->vsi;\n\tq_vector->tx.ring = tx_ring;\n\tq_vector->tx.count++;\n\tq_vector->tx.next_update = jiffies + 1;\n\tq_vector->tx.target_itr = ITR_TO_REG(tx_ring->itr_setting);\n\tq_vector->num_ringpairs++;\n\twr32(hw, IAVF_VFINT_ITRN1(IAVF_TX_ITR, q_vector->reg_idx),\n\t     q_vector->tx.target_itr >> 1);\n\tq_vector->tx.current_itr = q_vector->tx.target_itr;\n}\n\n \nstatic void iavf_map_rings_to_vectors(struct iavf_adapter *adapter)\n{\n\tint rings_remaining = adapter->num_active_queues;\n\tint ridx = 0, vidx = 0;\n\tint q_vectors;\n\n\tq_vectors = adapter->num_msix_vectors - NONQ_VECS;\n\n\tfor (; ridx < rings_remaining; ridx++) {\n\t\tiavf_map_vector_to_rxq(adapter, vidx, ridx);\n\t\tiavf_map_vector_to_txq(adapter, vidx, ridx);\n\n\t\t \n\t\tif (++vidx >= q_vectors)\n\t\t\tvidx = 0;\n\t}\n\n\tadapter->aq_required |= IAVF_FLAG_AQ_MAP_VECTORS;\n}\n\n \nstatic void iavf_irq_affinity_notify(struct irq_affinity_notify *notify,\n\t\t\t\t     const cpumask_t *mask)\n{\n\tstruct iavf_q_vector *q_vector =\n\t\tcontainer_of(notify, struct iavf_q_vector, affinity_notify);\n\n\tcpumask_copy(&q_vector->affinity_mask, mask);\n}\n\n \nstatic void iavf_irq_affinity_release(struct kref *ref) {}\n\n \nstatic int\niavf_request_traffic_irqs(struct iavf_adapter *adapter, char *basename)\n{\n\tunsigned int vector, q_vectors;\n\tunsigned int rx_int_idx = 0, tx_int_idx = 0;\n\tint irq_num, err;\n\tint cpu;\n\n\tiavf_irq_disable(adapter);\n\t \n\tq_vectors = adapter->num_msix_vectors - NONQ_VECS;\n\n\tfor (vector = 0; vector < q_vectors; vector++) {\n\t\tstruct iavf_q_vector *q_vector = &adapter->q_vectors[vector];\n\n\t\tirq_num = adapter->msix_entries[vector + NONQ_VECS].vector;\n\n\t\tif (q_vector->tx.ring && q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name),\n\t\t\t\t \"iavf-%s-TxRx-%u\", basename, rx_int_idx++);\n\t\t\ttx_int_idx++;\n\t\t} else if (q_vector->rx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name),\n\t\t\t\t \"iavf-%s-rx-%u\", basename, rx_int_idx++);\n\t\t} else if (q_vector->tx.ring) {\n\t\t\tsnprintf(q_vector->name, sizeof(q_vector->name),\n\t\t\t\t \"iavf-%s-tx-%u\", basename, tx_int_idx++);\n\t\t} else {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\t\terr = request_irq(irq_num,\n\t\t\t\t  iavf_msix_clean_rings,\n\t\t\t\t  0,\n\t\t\t\t  q_vector->name,\n\t\t\t\t  q_vector);\n\t\tif (err) {\n\t\t\tdev_info(&adapter->pdev->dev,\n\t\t\t\t \"Request_irq failed, error: %d\\n\", err);\n\t\t\tgoto free_queue_irqs;\n\t\t}\n\t\t \n\t\tq_vector->affinity_notify.notify = iavf_irq_affinity_notify;\n\t\tq_vector->affinity_notify.release =\n\t\t\t\t\t\t   iavf_irq_affinity_release;\n\t\tirq_set_affinity_notifier(irq_num, &q_vector->affinity_notify);\n\t\t \n\t\tcpu = cpumask_local_spread(q_vector->v_idx, -1);\n\t\tirq_update_affinity_hint(irq_num, get_cpu_mask(cpu));\n\t}\n\n\treturn 0;\n\nfree_queue_irqs:\n\twhile (vector) {\n\t\tvector--;\n\t\tirq_num = adapter->msix_entries[vector + NONQ_VECS].vector;\n\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\tirq_update_affinity_hint(irq_num, NULL);\n\t\tfree_irq(irq_num, &adapter->q_vectors[vector]);\n\t}\n\treturn err;\n}\n\n \nstatic int iavf_request_misc_irq(struct iavf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint err;\n\n\tsnprintf(adapter->misc_vector_name,\n\t\t sizeof(adapter->misc_vector_name) - 1, \"iavf-%s:mbx\",\n\t\t dev_name(&adapter->pdev->dev));\n\terr = request_irq(adapter->msix_entries[0].vector,\n\t\t\t  &iavf_msix_aq, 0,\n\t\t\t  adapter->misc_vector_name, netdev);\n\tif (err) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"request_irq for %s failed: %d\\n\",\n\t\t\tadapter->misc_vector_name, err);\n\t\tfree_irq(adapter->msix_entries[0].vector, netdev);\n\t}\n\treturn err;\n}\n\n \nstatic void iavf_free_traffic_irqs(struct iavf_adapter *adapter)\n{\n\tint vector, irq_num, q_vectors;\n\n\tif (!adapter->msix_entries)\n\t\treturn;\n\n\tq_vectors = adapter->num_msix_vectors - NONQ_VECS;\n\n\tfor (vector = 0; vector < q_vectors; vector++) {\n\t\tirq_num = adapter->msix_entries[vector + NONQ_VECS].vector;\n\t\tirq_set_affinity_notifier(irq_num, NULL);\n\t\tirq_update_affinity_hint(irq_num, NULL);\n\t\tfree_irq(irq_num, &adapter->q_vectors[vector]);\n\t}\n}\n\n \nstatic void iavf_free_misc_irq(struct iavf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tif (!adapter->msix_entries)\n\t\treturn;\n\n\tfree_irq(adapter->msix_entries[0].vector, netdev);\n}\n\n \nstatic void iavf_configure_tx(struct iavf_adapter *adapter)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\tint i;\n\n\tfor (i = 0; i < adapter->num_active_queues; i++)\n\t\tadapter->tx_rings[i].tail = hw->hw_addr + IAVF_QTX_TAIL1(i);\n}\n\n \nstatic void iavf_configure_rx(struct iavf_adapter *adapter)\n{\n\tunsigned int rx_buf_len = IAVF_RXBUFFER_2048;\n\tstruct iavf_hw *hw = &adapter->hw;\n\tint i;\n\n\t \n#if (PAGE_SIZE < 8192)\n\tif (!(adapter->flags & IAVF_FLAG_LEGACY_RX)) {\n\t\tstruct net_device *netdev = adapter->netdev;\n\n\t\t \n\t\trx_buf_len = IAVF_RXBUFFER_3072;\n\n\t\t \n\t\tif (!IAVF_2K_TOO_SMALL_WITH_PADDING &&\n\t\t    (netdev->mtu <= ETH_DATA_LEN))\n\t\t\trx_buf_len = IAVF_RXBUFFER_1536 - NET_IP_ALIGN;\n\t}\n#endif\n\n\tfor (i = 0; i < adapter->num_active_queues; i++) {\n\t\tadapter->rx_rings[i].tail = hw->hw_addr + IAVF_QRX_TAIL1(i);\n\t\tadapter->rx_rings[i].rx_buf_len = rx_buf_len;\n\n\t\tif (adapter->flags & IAVF_FLAG_LEGACY_RX)\n\t\t\tclear_ring_build_skb_enabled(&adapter->rx_rings[i]);\n\t\telse\n\t\t\tset_ring_build_skb_enabled(&adapter->rx_rings[i]);\n\t}\n}\n\n \nstatic struct\niavf_vlan_filter *iavf_find_vlan(struct iavf_adapter *adapter,\n\t\t\t\t struct iavf_vlan vlan)\n{\n\tstruct iavf_vlan_filter *f;\n\n\tlist_for_each_entry(f, &adapter->vlan_filter_list, list) {\n\t\tif (f->vlan.vid == vlan.vid &&\n\t\t    f->vlan.tpid == vlan.tpid)\n\t\t\treturn f;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic struct\niavf_vlan_filter *iavf_add_vlan(struct iavf_adapter *adapter,\n\t\t\t\tstruct iavf_vlan vlan)\n{\n\tstruct iavf_vlan_filter *f = NULL;\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\tf = iavf_find_vlan(adapter, vlan);\n\tif (!f) {\n\t\tf = kzalloc(sizeof(*f), GFP_ATOMIC);\n\t\tif (!f)\n\t\t\tgoto clearout;\n\n\t\tf->vlan = vlan;\n\n\t\tlist_add_tail(&f->list, &adapter->vlan_filter_list);\n\t\tf->state = IAVF_VLAN_ADD;\n\t\tadapter->num_vlan_filters++;\n\t\tiavf_schedule_aq_request(adapter, IAVF_FLAG_AQ_ADD_VLAN_FILTER);\n\t}\n\nclearout:\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\treturn f;\n}\n\n \nstatic void iavf_del_vlan(struct iavf_adapter *adapter, struct iavf_vlan vlan)\n{\n\tstruct iavf_vlan_filter *f;\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\tf = iavf_find_vlan(adapter, vlan);\n\tif (f) {\n\t\tf->state = IAVF_VLAN_REMOVE;\n\t\tiavf_schedule_aq_request(adapter, IAVF_FLAG_AQ_DEL_VLAN_FILTER);\n\t}\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n}\n\n \nstatic void iavf_restore_filters(struct iavf_adapter *adapter)\n{\n\tstruct iavf_vlan_filter *f;\n\n\t \n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\tlist_for_each_entry(f, &adapter->vlan_filter_list, list) {\n\t\tif (f->state == IAVF_VLAN_INACTIVE)\n\t\t\tf->state = IAVF_VLAN_ADD;\n\t}\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_VLAN_FILTER;\n}\n\n \nu16 iavf_get_num_vlans_added(struct iavf_adapter *adapter)\n{\n\treturn adapter->num_vlan_filters;\n}\n\n \nstatic u16 iavf_get_max_vlans_allowed(struct iavf_adapter *adapter)\n{\n\t \n\tif (VLAN_ALLOWED(adapter))\n\t\treturn VLAN_N_VID;\n\telse if (VLAN_V2_ALLOWED(adapter))\n\t\treturn adapter->vlan_v2_caps.filtering.max_filters;\n\n\treturn 0;\n}\n\n \nstatic bool iavf_max_vlans_added(struct iavf_adapter *adapter)\n{\n\tif (iavf_get_num_vlans_added(adapter) <\n\t    iavf_get_max_vlans_allowed(adapter))\n\t\treturn false;\n\n\treturn true;\n}\n\n \nstatic int iavf_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t__always_unused __be16 proto, u16 vid)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tif (!vid)\n\t\treturn 0;\n\n\tif (!VLAN_FILTERING_ALLOWED(adapter))\n\t\treturn -EIO;\n\n\tif (iavf_max_vlans_added(adapter)) {\n\t\tnetdev_err(netdev, \"Max allowed VLAN filters %u. Remove existing VLANs or disable filtering via Ethtool if supported.\\n\",\n\t\t\t   iavf_get_max_vlans_allowed(adapter));\n\t\treturn -EIO;\n\t}\n\n\tif (!iavf_add_vlan(adapter, IAVF_VLAN(vid, be16_to_cpu(proto))))\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n \nstatic int iavf_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t __always_unused __be16 proto, u16 vid)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tif (!vid)\n\t\treturn 0;\n\n\tiavf_del_vlan(adapter, IAVF_VLAN(vid, be16_to_cpu(proto)));\n\treturn 0;\n}\n\n \nstatic struct\niavf_mac_filter *iavf_find_filter(struct iavf_adapter *adapter,\n\t\t\t\t  const u8 *macaddr)\n{\n\tstruct iavf_mac_filter *f;\n\n\tif (!macaddr)\n\t\treturn NULL;\n\n\tlist_for_each_entry(f, &adapter->mac_filter_list, list) {\n\t\tif (ether_addr_equal(macaddr, f->macaddr))\n\t\t\treturn f;\n\t}\n\treturn NULL;\n}\n\n \nstruct iavf_mac_filter *iavf_add_filter(struct iavf_adapter *adapter,\n\t\t\t\t\tconst u8 *macaddr)\n{\n\tstruct iavf_mac_filter *f;\n\n\tif (!macaddr)\n\t\treturn NULL;\n\n\tf = iavf_find_filter(adapter, macaddr);\n\tif (!f) {\n\t\tf = kzalloc(sizeof(*f), GFP_ATOMIC);\n\t\tif (!f)\n\t\t\treturn f;\n\n\t\tether_addr_copy(f->macaddr, macaddr);\n\n\t\tlist_add_tail(&f->list, &adapter->mac_filter_list);\n\t\tf->add = true;\n\t\tf->add_handled = false;\n\t\tf->is_new_mac = true;\n\t\tf->is_primary = ether_addr_equal(macaddr, adapter->hw.mac.addr);\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_MAC_FILTER;\n\t} else {\n\t\tf->remove = false;\n\t}\n\n\treturn f;\n}\n\n \nstatic int iavf_replace_primary_mac(struct iavf_adapter *adapter,\n\t\t\t\t    const u8 *new_mac)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\tstruct iavf_mac_filter *new_f;\n\tstruct iavf_mac_filter *old_f;\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\tnew_f = iavf_add_filter(adapter, new_mac);\n\tif (!new_f) {\n\t\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\t\treturn -ENOMEM;\n\t}\n\n\told_f = iavf_find_filter(adapter, hw->mac.addr);\n\tif (old_f) {\n\t\told_f->is_primary = false;\n\t\told_f->remove = true;\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_MAC_FILTER;\n\t}\n\t \n\tnew_f->is_primary = true;\n\tnew_f->add = true;\n\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_MAC_FILTER;\n\tether_addr_copy(hw->mac.addr, new_mac);\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\n\t \n\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n\treturn 0;\n}\n\n \nstatic bool iavf_is_mac_set_handled(struct net_device *netdev,\n\t\t\t\t    const u8 *macaddr)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tstruct iavf_mac_filter *f;\n\tbool ret = false;\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\tf = iavf_find_filter(adapter, macaddr);\n\n\tif (!f || (!f->add && f->add_handled))\n\t\tret = true;\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\n\treturn ret;\n}\n\n \nstatic int iavf_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tstruct sockaddr *addr = p;\n\tint ret;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tret = iavf_replace_primary_mac(adapter, addr->sa_data);\n\n\tif (ret)\n\t\treturn ret;\n\n\tret = wait_event_interruptible_timeout(adapter->vc_waitqueue,\n\t\t\t\t\t       iavf_is_mac_set_handled(netdev, addr->sa_data),\n\t\t\t\t\t       msecs_to_jiffies(2500));\n\n\t \n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (!ret)\n\t\treturn -EAGAIN;\n\n\tif (!ether_addr_equal(netdev->dev_addr, addr->sa_data))\n\t\treturn -EACCES;\n\n\treturn 0;\n}\n\n \nstatic int iavf_addr_sync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tif (iavf_add_filter(adapter, addr))\n\t\treturn 0;\n\telse\n\t\treturn -ENOMEM;\n}\n\n \nstatic int iavf_addr_unsync(struct net_device *netdev, const u8 *addr)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tstruct iavf_mac_filter *f;\n\n\t \n\tif (ether_addr_equal(addr, netdev->dev_addr))\n\t\treturn 0;\n\n\tf = iavf_find_filter(adapter, addr);\n\tif (f) {\n\t\tf->remove = true;\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_MAC_FILTER;\n\t}\n\treturn 0;\n}\n\n \nbool iavf_promiscuous_mode_changed(struct iavf_adapter *adapter)\n{\n\treturn (adapter->current_netdev_promisc_flags ^ adapter->netdev->flags) &\n\t\t(IFF_PROMISC | IFF_ALLMULTI);\n}\n\n \nstatic void iavf_set_rx_mode(struct net_device *netdev)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\t__dev_uc_sync(netdev, iavf_addr_sync, iavf_addr_unsync);\n\t__dev_mc_sync(netdev, iavf_addr_sync, iavf_addr_unsync);\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\n\tspin_lock_bh(&adapter->current_netdev_promisc_flags_lock);\n\tif (iavf_promiscuous_mode_changed(adapter))\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_CONFIGURE_PROMISC_MODE;\n\tspin_unlock_bh(&adapter->current_netdev_promisc_flags_lock);\n}\n\n \nstatic void iavf_napi_enable_all(struct iavf_adapter *adapter)\n{\n\tint q_idx;\n\tstruct iavf_q_vector *q_vector;\n\tint q_vectors = adapter->num_msix_vectors - NONQ_VECS;\n\n\tfor (q_idx = 0; q_idx < q_vectors; q_idx++) {\n\t\tstruct napi_struct *napi;\n\n\t\tq_vector = &adapter->q_vectors[q_idx];\n\t\tnapi = &q_vector->napi;\n\t\tnapi_enable(napi);\n\t}\n}\n\n \nstatic void iavf_napi_disable_all(struct iavf_adapter *adapter)\n{\n\tint q_idx;\n\tstruct iavf_q_vector *q_vector;\n\tint q_vectors = adapter->num_msix_vectors - NONQ_VECS;\n\n\tfor (q_idx = 0; q_idx < q_vectors; q_idx++) {\n\t\tq_vector = &adapter->q_vectors[q_idx];\n\t\tnapi_disable(&q_vector->napi);\n\t}\n}\n\n \nstatic void iavf_configure(struct iavf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint i;\n\n\tiavf_set_rx_mode(netdev);\n\n\tiavf_configure_tx(adapter);\n\tiavf_configure_rx(adapter);\n\tadapter->aq_required |= IAVF_FLAG_AQ_CONFIGURE_QUEUES;\n\n\tfor (i = 0; i < adapter->num_active_queues; i++) {\n\t\tstruct iavf_ring *ring = &adapter->rx_rings[i];\n\n\t\tiavf_alloc_rx_buffers(ring, IAVF_DESC_UNUSED(ring));\n\t}\n}\n\n \nstatic void iavf_up_complete(struct iavf_adapter *adapter)\n{\n\tiavf_change_state(adapter, __IAVF_RUNNING);\n\tclear_bit(__IAVF_VSI_DOWN, adapter->vsi.state);\n\n\tiavf_napi_enable_all(adapter);\n\n\tadapter->aq_required |= IAVF_FLAG_AQ_ENABLE_QUEUES;\n\tif (CLIENT_ENABLED(adapter))\n\t\tadapter->flags |= IAVF_FLAG_CLIENT_NEEDS_OPEN;\n\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n}\n\n \nstatic void iavf_clear_mac_vlan_filters(struct iavf_adapter *adapter)\n{\n\tstruct iavf_vlan_filter *vlf, *vlftmp;\n\tstruct iavf_mac_filter *f, *ftmp;\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\t \n\t__dev_uc_unsync(adapter->netdev, NULL);\n\t__dev_mc_unsync(adapter->netdev, NULL);\n\n\t \n\tlist_for_each_entry_safe(f, ftmp, &adapter->mac_filter_list,\n\t\t\t\t list) {\n\t\tif (f->add) {\n\t\t\tlist_del(&f->list);\n\t\t\tkfree(f);\n\t\t} else {\n\t\t\tf->remove = true;\n\t\t}\n\t}\n\n\t \n\tlist_for_each_entry_safe(vlf, vlftmp, &adapter->vlan_filter_list,\n\t\t\t\t list)\n\t\tvlf->state = IAVF_VLAN_DISABLE;\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n}\n\n \nstatic void iavf_clear_cloud_filters(struct iavf_adapter *adapter)\n{\n\tstruct iavf_cloud_filter *cf, *cftmp;\n\n\t \n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tlist_for_each_entry_safe(cf, cftmp, &adapter->cloud_filter_list,\n\t\t\t\t list) {\n\t\tif (cf->add) {\n\t\t\tlist_del(&cf->list);\n\t\t\tkfree(cf);\n\t\t\tadapter->num_cloud_filters--;\n\t\t} else {\n\t\t\tcf->del = true;\n\t\t}\n\t}\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\n}\n\n \nstatic void iavf_clear_fdir_filters(struct iavf_adapter *adapter)\n{\n\tstruct iavf_fdir_fltr *fdir;\n\n\t \n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\tlist_for_each_entry(fdir, &adapter->fdir_list_head, list) {\n\t\tif (fdir->state == IAVF_FDIR_FLTR_ADD_REQUEST) {\n\t\t\t \n\t\t\tfdir->state = IAVF_FDIR_FLTR_INACTIVE;\n\t\t} else if (fdir->state == IAVF_FDIR_FLTR_ADD_PENDING ||\n\t\t\t fdir->state == IAVF_FDIR_FLTR_ACTIVE) {\n\t\t\t \n\t\t\tfdir->state = IAVF_FDIR_FLTR_DIS_REQUEST;\n\t\t}\n\t}\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n}\n\n \nstatic void iavf_clear_adv_rss_conf(struct iavf_adapter *adapter)\n{\n\tstruct iavf_adv_rss *rss, *rsstmp;\n\n\t \n\tspin_lock_bh(&adapter->adv_rss_lock);\n\tlist_for_each_entry_safe(rss, rsstmp, &adapter->adv_rss_list_head,\n\t\t\t\t list) {\n\t\tif (rss->state == IAVF_ADV_RSS_ADD_REQUEST) {\n\t\t\tlist_del(&rss->list);\n\t\t\tkfree(rss);\n\t\t} else {\n\t\t\trss->state = IAVF_ADV_RSS_DEL_REQUEST;\n\t\t}\n\t}\n\tspin_unlock_bh(&adapter->adv_rss_lock);\n}\n\n \nvoid iavf_down(struct iavf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tif (adapter->state <= __IAVF_DOWN_PENDING)\n\t\treturn;\n\n\tnetif_carrier_off(netdev);\n\tnetif_tx_disable(netdev);\n\tadapter->link_up = false;\n\tiavf_napi_disable_all(adapter);\n\tiavf_irq_disable(adapter);\n\n\tiavf_clear_mac_vlan_filters(adapter);\n\tiavf_clear_cloud_filters(adapter);\n\tiavf_clear_fdir_filters(adapter);\n\tiavf_clear_adv_rss_conf(adapter);\n\n\tif (!(adapter->flags & IAVF_FLAG_PF_COMMS_FAILED) &&\n\t    !(test_bit(__IAVF_IN_REMOVE_TASK, &adapter->crit_section))) {\n\t\t \n\t\tadapter->current_op = VIRTCHNL_OP_UNKNOWN;\n\t\t \n\t\tif (!list_empty(&adapter->mac_filter_list))\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_MAC_FILTER;\n\t\tif (!list_empty(&adapter->vlan_filter_list))\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_VLAN_FILTER;\n\t\tif (!list_empty(&adapter->cloud_filter_list))\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_CLOUD_FILTER;\n\t\tif (!list_empty(&adapter->fdir_list_head))\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_FDIR_FILTER;\n\t\tif (!list_empty(&adapter->adv_rss_list_head))\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_ADV_RSS_CFG;\n\t}\n\n\tadapter->aq_required |= IAVF_FLAG_AQ_DISABLE_QUEUES;\n\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n}\n\n \nstatic int\niavf_acquire_msix_vectors(struct iavf_adapter *adapter, int vectors)\n{\n\tint err, vector_threshold;\n\n\t \n\tvector_threshold = MIN_MSIX_COUNT;\n\n\t \n\terr = pci_enable_msix_range(adapter->pdev, adapter->msix_entries,\n\t\t\t\t    vector_threshold, vectors);\n\tif (err < 0) {\n\t\tdev_err(&adapter->pdev->dev, \"Unable to allocate MSI-X interrupts\\n\");\n\t\tkfree(adapter->msix_entries);\n\t\tadapter->msix_entries = NULL;\n\t\treturn err;\n\t}\n\n\t \n\tadapter->num_msix_vectors = err;\n\treturn 0;\n}\n\n \nstatic void iavf_free_queues(struct iavf_adapter *adapter)\n{\n\tif (!adapter->vsi_res)\n\t\treturn;\n\tadapter->num_active_queues = 0;\n\tkfree(adapter->tx_rings);\n\tadapter->tx_rings = NULL;\n\tkfree(adapter->rx_rings);\n\tadapter->rx_rings = NULL;\n}\n\n \nvoid iavf_set_queue_vlan_tag_loc(struct iavf_adapter *adapter)\n{\n\tint i;\n\n\tfor (i = 0; i < adapter->num_active_queues; i++) {\n\t\tstruct iavf_ring *tx_ring = &adapter->tx_rings[i];\n\t\tstruct iavf_ring *rx_ring = &adapter->rx_rings[i];\n\n\t\t \n\t\ttx_ring->flags &=\n\t\t\t~(IAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1 |\n\t\t\t  IAVF_TXR_FLAGS_VLAN_TAG_LOC_L2TAG2);\n\t\trx_ring->flags &=\n\t\t\t~(IAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1 |\n\t\t\t  IAVF_RXR_FLAGS_VLAN_TAG_LOC_L2TAG2_2);\n\n\t\tif (VLAN_ALLOWED(adapter)) {\n\t\t\ttx_ring->flags |= IAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1;\n\t\t\trx_ring->flags |= IAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1;\n\t\t} else if (VLAN_V2_ALLOWED(adapter)) {\n\t\t\tstruct virtchnl_vlan_supported_caps *stripping_support;\n\t\t\tstruct virtchnl_vlan_supported_caps *insertion_support;\n\n\t\t\tstripping_support =\n\t\t\t\t&adapter->vlan_v2_caps.offloads.stripping_support;\n\t\t\tinsertion_support =\n\t\t\t\t&adapter->vlan_v2_caps.offloads.insertion_support;\n\n\t\t\tif (stripping_support->outer) {\n\t\t\t\tif (stripping_support->outer &\n\t\t\t\t    VIRTCHNL_VLAN_TAG_LOCATION_L2TAG1)\n\t\t\t\t\trx_ring->flags |=\n\t\t\t\t\t\tIAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1;\n\t\t\t\telse if (stripping_support->outer &\n\t\t\t\t\t VIRTCHNL_VLAN_TAG_LOCATION_L2TAG2_2)\n\t\t\t\t\trx_ring->flags |=\n\t\t\t\t\t\tIAVF_RXR_FLAGS_VLAN_TAG_LOC_L2TAG2_2;\n\t\t\t} else if (stripping_support->inner) {\n\t\t\t\tif (stripping_support->inner &\n\t\t\t\t    VIRTCHNL_VLAN_TAG_LOCATION_L2TAG1)\n\t\t\t\t\trx_ring->flags |=\n\t\t\t\t\t\tIAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1;\n\t\t\t\telse if (stripping_support->inner &\n\t\t\t\t\t VIRTCHNL_VLAN_TAG_LOCATION_L2TAG2_2)\n\t\t\t\t\trx_ring->flags |=\n\t\t\t\t\t\tIAVF_RXR_FLAGS_VLAN_TAG_LOC_L2TAG2_2;\n\t\t\t}\n\n\t\t\tif (insertion_support->outer) {\n\t\t\t\tif (insertion_support->outer &\n\t\t\t\t    VIRTCHNL_VLAN_TAG_LOCATION_L2TAG1)\n\t\t\t\t\ttx_ring->flags |=\n\t\t\t\t\t\tIAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1;\n\t\t\t\telse if (insertion_support->outer &\n\t\t\t\t\t VIRTCHNL_VLAN_TAG_LOCATION_L2TAG2)\n\t\t\t\t\ttx_ring->flags |=\n\t\t\t\t\t\tIAVF_TXR_FLAGS_VLAN_TAG_LOC_L2TAG2;\n\t\t\t} else if (insertion_support->inner) {\n\t\t\t\tif (insertion_support->inner &\n\t\t\t\t    VIRTCHNL_VLAN_TAG_LOCATION_L2TAG1)\n\t\t\t\t\ttx_ring->flags |=\n\t\t\t\t\t\tIAVF_TXRX_FLAGS_VLAN_TAG_LOC_L2TAG1;\n\t\t\t\telse if (insertion_support->inner &\n\t\t\t\t\t VIRTCHNL_VLAN_TAG_LOCATION_L2TAG2)\n\t\t\t\t\ttx_ring->flags |=\n\t\t\t\t\t\tIAVF_TXR_FLAGS_VLAN_TAG_LOC_L2TAG2;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic int iavf_alloc_queues(struct iavf_adapter *adapter)\n{\n\tint i, num_active_queues;\n\n\t \n\tif (adapter->num_req_queues)\n\t\tnum_active_queues = adapter->num_req_queues;\n\telse if ((adapter->vf_res->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_ADQ) &&\n\t\t adapter->num_tc)\n\t\tnum_active_queues = adapter->ch_config.total_qps;\n\telse\n\t\tnum_active_queues = min_t(int,\n\t\t\t\t\t  adapter->vsi_res->num_queue_pairs,\n\t\t\t\t\t  (int)(num_online_cpus()));\n\n\n\tadapter->tx_rings = kcalloc(num_active_queues,\n\t\t\t\t    sizeof(struct iavf_ring), GFP_KERNEL);\n\tif (!adapter->tx_rings)\n\t\tgoto err_out;\n\tadapter->rx_rings = kcalloc(num_active_queues,\n\t\t\t\t    sizeof(struct iavf_ring), GFP_KERNEL);\n\tif (!adapter->rx_rings)\n\t\tgoto err_out;\n\n\tfor (i = 0; i < num_active_queues; i++) {\n\t\tstruct iavf_ring *tx_ring;\n\t\tstruct iavf_ring *rx_ring;\n\n\t\ttx_ring = &adapter->tx_rings[i];\n\n\t\ttx_ring->queue_index = i;\n\t\ttx_ring->netdev = adapter->netdev;\n\t\ttx_ring->dev = &adapter->pdev->dev;\n\t\ttx_ring->count = adapter->tx_desc_count;\n\t\ttx_ring->itr_setting = IAVF_ITR_TX_DEF;\n\t\tif (adapter->flags & IAVF_FLAG_WB_ON_ITR_CAPABLE)\n\t\t\ttx_ring->flags |= IAVF_TXR_FLAGS_WB_ON_ITR;\n\n\t\trx_ring = &adapter->rx_rings[i];\n\t\trx_ring->queue_index = i;\n\t\trx_ring->netdev = adapter->netdev;\n\t\trx_ring->dev = &adapter->pdev->dev;\n\t\trx_ring->count = adapter->rx_desc_count;\n\t\trx_ring->itr_setting = IAVF_ITR_RX_DEF;\n\t}\n\n\tadapter->num_active_queues = num_active_queues;\n\n\tiavf_set_queue_vlan_tag_loc(adapter);\n\n\treturn 0;\n\nerr_out:\n\tiavf_free_queues(adapter);\n\treturn -ENOMEM;\n}\n\n \nstatic int iavf_set_interrupt_capability(struct iavf_adapter *adapter)\n{\n\tint vector, v_budget;\n\tint pairs = 0;\n\tint err = 0;\n\n\tif (!adapter->vsi_res) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\tpairs = adapter->num_active_queues;\n\n\t \n\tv_budget = min_t(int, pairs + NONQ_VECS,\n\t\t\t (int)adapter->vf_res->max_vectors);\n\n\tadapter->msix_entries = kcalloc(v_budget,\n\t\t\t\t\tsizeof(struct msix_entry), GFP_KERNEL);\n\tif (!adapter->msix_entries) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tfor (vector = 0; vector < v_budget; vector++)\n\t\tadapter->msix_entries[vector].entry = vector;\n\n\terr = iavf_acquire_msix_vectors(adapter, v_budget);\n\tif (!err)\n\t\tiavf_schedule_finish_config(adapter);\n\nout:\n\treturn err;\n}\n\n \nstatic int iavf_config_rss_aq(struct iavf_adapter *adapter)\n{\n\tstruct iavf_aqc_get_set_rss_key_data *rss_key =\n\t\t(struct iavf_aqc_get_set_rss_key_data *)adapter->rss_key;\n\tstruct iavf_hw *hw = &adapter->hw;\n\tenum iavf_status status;\n\n\tif (adapter->current_op != VIRTCHNL_OP_UNKNOWN) {\n\t\t \n\t\tdev_err(&adapter->pdev->dev, \"Cannot configure RSS, command %d pending\\n\",\n\t\t\tadapter->current_op);\n\t\treturn -EBUSY;\n\t}\n\n\tstatus = iavf_aq_set_rss_key(hw, adapter->vsi.id, rss_key);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev, \"Cannot set RSS key, err %s aq_err %s\\n\",\n\t\t\tiavf_stat_str(hw, status),\n\t\t\tiavf_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn iavf_status_to_errno(status);\n\n\t}\n\n\tstatus = iavf_aq_set_rss_lut(hw, adapter->vsi.id, false,\n\t\t\t\t     adapter->rss_lut, adapter->rss_lut_size);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev, \"Cannot set RSS lut, err %s aq_err %s\\n\",\n\t\t\tiavf_stat_str(hw, status),\n\t\t\tiavf_aq_str(hw, hw->aq.asq_last_status));\n\t\treturn iavf_status_to_errno(status);\n\t}\n\n\treturn 0;\n\n}\n\n \nstatic int iavf_config_rss_reg(struct iavf_adapter *adapter)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\tu32 *dw;\n\tu16 i;\n\n\tdw = (u32 *)adapter->rss_key;\n\tfor (i = 0; i <= adapter->rss_key_size / 4; i++)\n\t\twr32(hw, IAVF_VFQF_HKEY(i), dw[i]);\n\n\tdw = (u32 *)adapter->rss_lut;\n\tfor (i = 0; i <= adapter->rss_lut_size / 4; i++)\n\t\twr32(hw, IAVF_VFQF_HLUT(i), dw[i]);\n\n\tiavf_flush(hw);\n\n\treturn 0;\n}\n\n \nint iavf_config_rss(struct iavf_adapter *adapter)\n{\n\n\tif (RSS_PF(adapter)) {\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_SET_RSS_LUT |\n\t\t\t\t\tIAVF_FLAG_AQ_SET_RSS_KEY;\n\t\treturn 0;\n\t} else if (RSS_AQ(adapter)) {\n\t\treturn iavf_config_rss_aq(adapter);\n\t} else {\n\t\treturn iavf_config_rss_reg(adapter);\n\t}\n}\n\n \nstatic void iavf_fill_rss_lut(struct iavf_adapter *adapter)\n{\n\tu16 i;\n\n\tfor (i = 0; i < adapter->rss_lut_size; i++)\n\t\tadapter->rss_lut[i] = i % adapter->num_active_queues;\n}\n\n \nstatic int iavf_init_rss(struct iavf_adapter *adapter)\n{\n\tstruct iavf_hw *hw = &adapter->hw;\n\n\tif (!RSS_PF(adapter)) {\n\t\t \n\t\tif (adapter->vf_res->vf_cap_flags &\n\t\t    VIRTCHNL_VF_OFFLOAD_RSS_PCTYPE_V2)\n\t\t\tadapter->hena = IAVF_DEFAULT_RSS_HENA_EXPANDED;\n\t\telse\n\t\t\tadapter->hena = IAVF_DEFAULT_RSS_HENA;\n\n\t\twr32(hw, IAVF_VFQF_HENA(0), (u32)adapter->hena);\n\t\twr32(hw, IAVF_VFQF_HENA(1), (u32)(adapter->hena >> 32));\n\t}\n\n\tiavf_fill_rss_lut(adapter);\n\tnetdev_rss_key_fill((void *)adapter->rss_key, adapter->rss_key_size);\n\n\treturn iavf_config_rss(adapter);\n}\n\n \nstatic int iavf_alloc_q_vectors(struct iavf_adapter *adapter)\n{\n\tint q_idx = 0, num_q_vectors;\n\tstruct iavf_q_vector *q_vector;\n\n\tnum_q_vectors = adapter->num_msix_vectors - NONQ_VECS;\n\tadapter->q_vectors = kcalloc(num_q_vectors, sizeof(*q_vector),\n\t\t\t\t     GFP_KERNEL);\n\tif (!adapter->q_vectors)\n\t\treturn -ENOMEM;\n\n\tfor (q_idx = 0; q_idx < num_q_vectors; q_idx++) {\n\t\tq_vector = &adapter->q_vectors[q_idx];\n\t\tq_vector->adapter = adapter;\n\t\tq_vector->vsi = &adapter->vsi;\n\t\tq_vector->v_idx = q_idx;\n\t\tq_vector->reg_idx = q_idx;\n\t\tcpumask_copy(&q_vector->affinity_mask, cpu_possible_mask);\n\t\tnetif_napi_add(adapter->netdev, &q_vector->napi,\n\t\t\t       iavf_napi_poll);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void iavf_free_q_vectors(struct iavf_adapter *adapter)\n{\n\tint q_idx, num_q_vectors;\n\n\tif (!adapter->q_vectors)\n\t\treturn;\n\n\tnum_q_vectors = adapter->num_msix_vectors - NONQ_VECS;\n\n\tfor (q_idx = 0; q_idx < num_q_vectors; q_idx++) {\n\t\tstruct iavf_q_vector *q_vector = &adapter->q_vectors[q_idx];\n\n\t\tnetif_napi_del(&q_vector->napi);\n\t}\n\tkfree(adapter->q_vectors);\n\tadapter->q_vectors = NULL;\n}\n\n \nstatic void iavf_reset_interrupt_capability(struct iavf_adapter *adapter)\n{\n\tif (!adapter->msix_entries)\n\t\treturn;\n\n\tpci_disable_msix(adapter->pdev);\n\tkfree(adapter->msix_entries);\n\tadapter->msix_entries = NULL;\n}\n\n \nstatic int iavf_init_interrupt_scheme(struct iavf_adapter *adapter)\n{\n\tint err;\n\n\terr = iavf_alloc_queues(adapter);\n\tif (err) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Unable to allocate memory for queues\\n\");\n\t\tgoto err_alloc_queues;\n\t}\n\n\terr = iavf_set_interrupt_capability(adapter);\n\tif (err) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Unable to setup interrupt capabilities\\n\");\n\t\tgoto err_set_interrupt;\n\t}\n\n\terr = iavf_alloc_q_vectors(adapter);\n\tif (err) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Unable to allocate memory for queue vectors\\n\");\n\t\tgoto err_alloc_q_vectors;\n\t}\n\n\t \n\tif ((adapter->vf_res->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_ADQ) &&\n\t    adapter->num_tc)\n\t\tdev_info(&adapter->pdev->dev, \"ADq Enabled, %u TCs created\",\n\t\t\t adapter->num_tc);\n\n\tdev_info(&adapter->pdev->dev, \"Multiqueue %s: Queue pair count = %u\",\n\t\t (adapter->num_active_queues > 1) ? \"Enabled\" : \"Disabled\",\n\t\t adapter->num_active_queues);\n\n\treturn 0;\nerr_alloc_q_vectors:\n\tiavf_reset_interrupt_capability(adapter);\nerr_set_interrupt:\n\tiavf_free_queues(adapter);\nerr_alloc_queues:\n\treturn err;\n}\n\n \nstatic void iavf_free_rss(struct iavf_adapter *adapter)\n{\n\tkfree(adapter->rss_key);\n\tadapter->rss_key = NULL;\n\n\tkfree(adapter->rss_lut);\n\tadapter->rss_lut = NULL;\n}\n\n \nstatic int iavf_reinit_interrupt_scheme(struct iavf_adapter *adapter, bool running)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint err;\n\n\tif (running)\n\t\tiavf_free_traffic_irqs(adapter);\n\tiavf_free_misc_irq(adapter);\n\tiavf_reset_interrupt_capability(adapter);\n\tiavf_free_q_vectors(adapter);\n\tiavf_free_queues(adapter);\n\n\terr =  iavf_init_interrupt_scheme(adapter);\n\tif (err)\n\t\tgoto err;\n\n\tnetif_tx_stop_all_queues(netdev);\n\n\terr = iavf_request_misc_irq(adapter);\n\tif (err)\n\t\tgoto err;\n\n\tset_bit(__IAVF_VSI_DOWN, adapter->vsi.state);\n\n\tiavf_map_rings_to_vectors(adapter);\nerr:\n\treturn err;\n}\n\n \nstatic void iavf_finish_config(struct work_struct *work)\n{\n\tstruct iavf_adapter *adapter;\n\tint pairs, err;\n\n\tadapter = container_of(work, struct iavf_adapter, finish_config);\n\n\t \n\trtnl_lock();\n\tmutex_lock(&adapter->crit_lock);\n\n\tif ((adapter->flags & IAVF_FLAG_SETUP_NETDEV_FEATURES) &&\n\t    adapter->netdev_registered &&\n\t    !test_bit(__IAVF_IN_REMOVE_TASK, &adapter->crit_section)) {\n\t\tnetdev_update_features(adapter->netdev);\n\t\tadapter->flags &= ~IAVF_FLAG_SETUP_NETDEV_FEATURES;\n\t}\n\n\tswitch (adapter->state) {\n\tcase __IAVF_DOWN:\n\t\tif (!adapter->netdev_registered) {\n\t\t\terr = register_netdevice(adapter->netdev);\n\t\t\tif (err) {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Unable to register netdev (%d)\\n\",\n\t\t\t\t\terr);\n\n\t\t\t\t \n\t\t\t\tiavf_free_rss(adapter);\n\t\t\t\tiavf_free_misc_irq(adapter);\n\t\t\t\tiavf_reset_interrupt_capability(adapter);\n\t\t\t\tiavf_change_state(adapter,\n\t\t\t\t\t\t  __IAVF_INIT_CONFIG_ADAPTER);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tadapter->netdev_registered = true;\n\t\t}\n\n\t\t \n\t\tfallthrough;\n\tcase __IAVF_RUNNING:\n\t\tpairs = adapter->num_active_queues;\n\t\tnetif_set_real_num_rx_queues(adapter->netdev, pairs);\n\t\tnetif_set_real_num_tx_queues(adapter->netdev, pairs);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\nout:\n\tmutex_unlock(&adapter->crit_lock);\n\trtnl_unlock();\n}\n\n \nvoid iavf_schedule_finish_config(struct iavf_adapter *adapter)\n{\n\tif (!test_bit(__IAVF_IN_REMOVE_TASK, &adapter->crit_section))\n\t\tqueue_work(adapter->wq, &adapter->finish_config);\n}\n\n \nstatic int iavf_process_aq_command(struct iavf_adapter *adapter)\n{\n\tif (adapter->aq_required & IAVF_FLAG_AQ_GET_CONFIG)\n\t\treturn iavf_send_vf_config_msg(adapter);\n\tif (adapter->aq_required & IAVF_FLAG_AQ_GET_OFFLOAD_VLAN_V2_CAPS)\n\t\treturn iavf_send_vf_offload_vlan_v2_msg(adapter);\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DISABLE_QUEUES) {\n\t\tiavf_disable_queues(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_MAP_VECTORS) {\n\t\tiavf_map_queues(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ADD_MAC_FILTER) {\n\t\tiavf_add_ether_addrs(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ADD_VLAN_FILTER) {\n\t\tiavf_add_vlans(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DEL_MAC_FILTER) {\n\t\tiavf_del_ether_addrs(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DEL_VLAN_FILTER) {\n\t\tiavf_del_vlans(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ENABLE_VLAN_STRIPPING) {\n\t\tiavf_enable_vlan_stripping(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DISABLE_VLAN_STRIPPING) {\n\t\tiavf_disable_vlan_stripping(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_CONFIGURE_QUEUES) {\n\t\tiavf_configure_queues(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ENABLE_QUEUES) {\n\t\tiavf_enable_queues(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_CONFIGURE_RSS) {\n\t\t \n\t\tadapter->aq_required &= ~IAVF_FLAG_AQ_CONFIGURE_RSS;\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_GET_HENA) {\n\t\tiavf_get_hena(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_SET_HENA) {\n\t\tiavf_set_hena(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_SET_RSS_KEY) {\n\t\tiavf_set_rss_key(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_SET_RSS_LUT) {\n\t\tiavf_set_rss_lut(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_CONFIGURE_PROMISC_MODE) {\n\t\tiavf_set_promiscuous(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ENABLE_CHANNELS) {\n\t\tiavf_enable_channels(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DISABLE_CHANNELS) {\n\t\tiavf_disable_channels(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ADD_CLOUD_FILTER) {\n\t\tiavf_add_cloud_filter(adapter);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DEL_CLOUD_FILTER) {\n\t\tiavf_del_cloud_filter(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DEL_CLOUD_FILTER) {\n\t\tiavf_del_cloud_filter(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ADD_CLOUD_FILTER) {\n\t\tiavf_add_cloud_filter(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ADD_FDIR_FILTER) {\n\t\tiavf_add_fdir_filter(adapter);\n\t\treturn IAVF_SUCCESS;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DEL_FDIR_FILTER) {\n\t\tiavf_del_fdir_filter(adapter);\n\t\treturn IAVF_SUCCESS;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ADD_ADV_RSS_CFG) {\n\t\tiavf_add_adv_rss_cfg(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DEL_ADV_RSS_CFG) {\n\t\tiavf_del_adv_rss_cfg(adapter);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DISABLE_CTAG_VLAN_STRIPPING) {\n\t\tiavf_disable_vlan_stripping_v2(adapter, ETH_P_8021Q);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DISABLE_STAG_VLAN_STRIPPING) {\n\t\tiavf_disable_vlan_stripping_v2(adapter, ETH_P_8021AD);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ENABLE_CTAG_VLAN_STRIPPING) {\n\t\tiavf_enable_vlan_stripping_v2(adapter, ETH_P_8021Q);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ENABLE_STAG_VLAN_STRIPPING) {\n\t\tiavf_enable_vlan_stripping_v2(adapter, ETH_P_8021AD);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DISABLE_CTAG_VLAN_INSERTION) {\n\t\tiavf_disable_vlan_insertion_v2(adapter, ETH_P_8021Q);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_DISABLE_STAG_VLAN_INSERTION) {\n\t\tiavf_disable_vlan_insertion_v2(adapter, ETH_P_8021AD);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ENABLE_CTAG_VLAN_INSERTION) {\n\t\tiavf_enable_vlan_insertion_v2(adapter, ETH_P_8021Q);\n\t\treturn 0;\n\t}\n\tif (adapter->aq_required & IAVF_FLAG_AQ_ENABLE_STAG_VLAN_INSERTION) {\n\t\tiavf_enable_vlan_insertion_v2(adapter, ETH_P_8021AD);\n\t\treturn 0;\n\t}\n\n\tif (adapter->aq_required & IAVF_FLAG_AQ_REQUEST_STATS) {\n\t\tiavf_request_stats(adapter);\n\t\treturn 0;\n\t}\n\n\treturn -EAGAIN;\n}\n\n \nstatic void\niavf_set_vlan_offload_features(struct iavf_adapter *adapter,\n\t\t\t       netdev_features_t prev_features,\n\t\t\t       netdev_features_t features)\n{\n\tbool enable_stripping = true, enable_insertion = true;\n\tu16 vlan_ethertype = 0;\n\tu64 aq_required = 0;\n\n\t \n\tif (features & (NETIF_F_HW_VLAN_STAG_RX | NETIF_F_HW_VLAN_STAG_TX))\n\t\tvlan_ethertype = ETH_P_8021AD;\n\telse if (features & (NETIF_F_HW_VLAN_CTAG_RX | NETIF_F_HW_VLAN_CTAG_TX))\n\t\tvlan_ethertype = ETH_P_8021Q;\n\telse if (prev_features & (NETIF_F_HW_VLAN_STAG_RX | NETIF_F_HW_VLAN_STAG_TX))\n\t\tvlan_ethertype = ETH_P_8021AD;\n\telse if (prev_features & (NETIF_F_HW_VLAN_CTAG_RX | NETIF_F_HW_VLAN_CTAG_TX))\n\t\tvlan_ethertype = ETH_P_8021Q;\n\telse\n\t\tvlan_ethertype = ETH_P_8021Q;\n\n\tif (!(features & (NETIF_F_HW_VLAN_STAG_RX | NETIF_F_HW_VLAN_CTAG_RX)))\n\t\tenable_stripping = false;\n\tif (!(features & (NETIF_F_HW_VLAN_STAG_TX | NETIF_F_HW_VLAN_CTAG_TX)))\n\t\tenable_insertion = false;\n\n\tif (VLAN_ALLOWED(adapter)) {\n\t\t \n\t\tif (enable_stripping)\n\t\t\taq_required |= IAVF_FLAG_AQ_ENABLE_VLAN_STRIPPING;\n\t\telse\n\t\t\taq_required |= IAVF_FLAG_AQ_DISABLE_VLAN_STRIPPING;\n\n\t} else if (VLAN_V2_ALLOWED(adapter)) {\n\t\tswitch (vlan_ethertype) {\n\t\tcase ETH_P_8021Q:\n\t\t\tif (enable_stripping)\n\t\t\t\taq_required |= IAVF_FLAG_AQ_ENABLE_CTAG_VLAN_STRIPPING;\n\t\t\telse\n\t\t\t\taq_required |= IAVF_FLAG_AQ_DISABLE_CTAG_VLAN_STRIPPING;\n\n\t\t\tif (enable_insertion)\n\t\t\t\taq_required |= IAVF_FLAG_AQ_ENABLE_CTAG_VLAN_INSERTION;\n\t\t\telse\n\t\t\t\taq_required |= IAVF_FLAG_AQ_DISABLE_CTAG_VLAN_INSERTION;\n\t\t\tbreak;\n\t\tcase ETH_P_8021AD:\n\t\t\tif (enable_stripping)\n\t\t\t\taq_required |= IAVF_FLAG_AQ_ENABLE_STAG_VLAN_STRIPPING;\n\t\t\telse\n\t\t\t\taq_required |= IAVF_FLAG_AQ_DISABLE_STAG_VLAN_STRIPPING;\n\n\t\t\tif (enable_insertion)\n\t\t\t\taq_required |= IAVF_FLAG_AQ_ENABLE_STAG_VLAN_INSERTION;\n\t\t\telse\n\t\t\t\taq_required |= IAVF_FLAG_AQ_DISABLE_STAG_VLAN_INSERTION;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (aq_required) {\n\t\tadapter->aq_required |= aq_required;\n\t\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n\t}\n}\n\n \nstatic void iavf_startup(struct iavf_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct iavf_hw *hw = &adapter->hw;\n\tenum iavf_status status;\n\tint ret;\n\n\tWARN_ON(adapter->state != __IAVF_STARTUP);\n\n\t \n\tadapter->flags &= ~IAVF_FLAG_PF_COMMS_FAILED;\n\tadapter->flags &= ~IAVF_FLAG_RESET_PENDING;\n\tstatus = iavf_set_mac_type(hw);\n\tif (status) {\n\t\tdev_err(&pdev->dev, \"Failed to set MAC type (%d)\\n\", status);\n\t\tgoto err;\n\t}\n\n\tret = iavf_check_reset_complete(hw);\n\tif (ret) {\n\t\tdev_info(&pdev->dev, \"Device is still in reset (%d), retrying\\n\",\n\t\t\t ret);\n\t\tgoto err;\n\t}\n\thw->aq.num_arq_entries = IAVF_AQ_LEN;\n\thw->aq.num_asq_entries = IAVF_AQ_LEN;\n\thw->aq.arq_buf_size = IAVF_MAX_AQ_BUF_SIZE;\n\thw->aq.asq_buf_size = IAVF_MAX_AQ_BUF_SIZE;\n\n\tstatus = iavf_init_adminq(hw);\n\tif (status) {\n\t\tdev_err(&pdev->dev, \"Failed to init Admin Queue (%d)\\n\",\n\t\t\tstatus);\n\t\tgoto err;\n\t}\n\tret = iavf_send_api_ver(adapter);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Unable to send to PF (%d)\\n\", ret);\n\t\tiavf_shutdown_adminq(hw);\n\t\tgoto err;\n\t}\n\tiavf_change_state(adapter, __IAVF_INIT_VERSION_CHECK);\n\treturn;\nerr:\n\tiavf_change_state(adapter, __IAVF_INIT_FAILED);\n}\n\n \nstatic void iavf_init_version_check(struct iavf_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct iavf_hw *hw = &adapter->hw;\n\tint err = -EAGAIN;\n\n\tWARN_ON(adapter->state != __IAVF_INIT_VERSION_CHECK);\n\n\tif (!iavf_asq_done(hw)) {\n\t\tdev_err(&pdev->dev, \"Admin queue command never completed\\n\");\n\t\tiavf_shutdown_adminq(hw);\n\t\tiavf_change_state(adapter, __IAVF_STARTUP);\n\t\tgoto err;\n\t}\n\n\t \n\terr = iavf_verify_api_ver(adapter);\n\tif (err) {\n\t\tif (err == -EALREADY)\n\t\t\terr = iavf_send_api_ver(adapter);\n\t\telse\n\t\t\tdev_err(&pdev->dev, \"Unsupported PF API version %d.%d, expected %d.%d\\n\",\n\t\t\t\tadapter->pf_version.major,\n\t\t\t\tadapter->pf_version.minor,\n\t\t\t\tVIRTCHNL_VERSION_MAJOR,\n\t\t\t\tVIRTCHNL_VERSION_MINOR);\n\t\tgoto err;\n\t}\n\terr = iavf_send_vf_config_msg(adapter);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Unable to send config request (%d)\\n\",\n\t\t\terr);\n\t\tgoto err;\n\t}\n\tiavf_change_state(adapter, __IAVF_INIT_GET_RESOURCES);\n\treturn;\nerr:\n\tiavf_change_state(adapter, __IAVF_INIT_FAILED);\n}\n\n \nint iavf_parse_vf_resource_msg(struct iavf_adapter *adapter)\n{\n\tint i, num_req_queues = adapter->num_req_queues;\n\tstruct iavf_vsi *vsi = &adapter->vsi;\n\n\tfor (i = 0; i < adapter->vf_res->num_vsis; i++) {\n\t\tif (adapter->vf_res->vsi_res[i].vsi_type == VIRTCHNL_VSI_SRIOV)\n\t\t\tadapter->vsi_res = &adapter->vf_res->vsi_res[i];\n\t}\n\tif (!adapter->vsi_res) {\n\t\tdev_err(&adapter->pdev->dev, \"No LAN VSI found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (num_req_queues &&\n\t    num_req_queues > adapter->vsi_res->num_queue_pairs) {\n\t\t \n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Requested %d queues, but PF only gave us %d.\\n\",\n\t\t\tnum_req_queues,\n\t\t\tadapter->vsi_res->num_queue_pairs);\n\t\tadapter->flags |= IAVF_FLAG_REINIT_MSIX_NEEDED;\n\t\tadapter->num_req_queues = adapter->vsi_res->num_queue_pairs;\n\t\tiavf_schedule_reset(adapter, IAVF_FLAG_RESET_NEEDED);\n\n\t\treturn -EAGAIN;\n\t}\n\tadapter->num_req_queues = 0;\n\tadapter->vsi.id = adapter->vsi_res->vsi_id;\n\n\tadapter->vsi.back = adapter;\n\tadapter->vsi.base_vector = 1;\n\tvsi->netdev = adapter->netdev;\n\tvsi->qs_handle = adapter->vsi_res->qset_handle;\n\tif (adapter->vf_res->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_RSS_PF) {\n\t\tadapter->rss_key_size = adapter->vf_res->rss_key_size;\n\t\tadapter->rss_lut_size = adapter->vf_res->rss_lut_size;\n\t} else {\n\t\tadapter->rss_key_size = IAVF_HKEY_ARRAY_SIZE;\n\t\tadapter->rss_lut_size = IAVF_HLUT_ARRAY_SIZE;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void iavf_init_get_resources(struct iavf_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct iavf_hw *hw = &adapter->hw;\n\tint err;\n\n\tWARN_ON(adapter->state != __IAVF_INIT_GET_RESOURCES);\n\t \n\tif (!adapter->vf_res) {\n\t\tadapter->vf_res = kzalloc(IAVF_VIRTCHNL_VF_RESOURCE_SIZE,\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!adapter->vf_res) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\t}\n\terr = iavf_get_vf_config(adapter);\n\tif (err == -EALREADY) {\n\t\terr = iavf_send_vf_config_msg(adapter);\n\t\tgoto err;\n\t} else if (err == -EINVAL) {\n\t\t \n\t\tiavf_shutdown_adminq(hw);\n\t\tdev_err(&pdev->dev, \"Unable to get VF config due to PF error condition, not retrying\\n\");\n\t\treturn;\n\t}\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Unable to get VF config (%d)\\n\", err);\n\t\tgoto err_alloc;\n\t}\n\n\terr = iavf_parse_vf_resource_msg(adapter);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to parse VF resource message from PF (%d)\\n\",\n\t\t\terr);\n\t\tgoto err_alloc;\n\t}\n\t \n\tadapter->extended_caps = IAVF_EXTENDED_CAPS;\n\n\tiavf_change_state(adapter, __IAVF_INIT_EXTENDED_CAPS);\n\treturn;\n\nerr_alloc:\n\tkfree(adapter->vf_res);\n\tadapter->vf_res = NULL;\nerr:\n\tiavf_change_state(adapter, __IAVF_INIT_FAILED);\n}\n\n \nstatic void iavf_init_send_offload_vlan_v2_caps(struct iavf_adapter *adapter)\n{\n\tint ret;\n\n\tWARN_ON(!(adapter->extended_caps & IAVF_EXTENDED_CAP_SEND_VLAN_V2));\n\n\tret = iavf_send_vf_offload_vlan_v2_msg(adapter);\n\tif (ret && ret == -EOPNOTSUPP) {\n\t\t \n\t\tadapter->extended_caps &= ~IAVF_EXTENDED_CAP_RECV_VLAN_V2;\n\t}\n\n\t \n\tadapter->extended_caps &= ~IAVF_EXTENDED_CAP_SEND_VLAN_V2;\n}\n\n \nstatic void iavf_init_recv_offload_vlan_v2_caps(struct iavf_adapter *adapter)\n{\n\tint ret;\n\n\tWARN_ON(!(adapter->extended_caps & IAVF_EXTENDED_CAP_RECV_VLAN_V2));\n\n\tmemset(&adapter->vlan_v2_caps, 0, sizeof(adapter->vlan_v2_caps));\n\n\tret = iavf_get_vf_vlan_v2_caps(adapter);\n\tif (ret)\n\t\tgoto err;\n\n\t \n\tadapter->extended_caps &= ~IAVF_EXTENDED_CAP_RECV_VLAN_V2;\n\treturn;\nerr:\n\t \n\tadapter->extended_caps |= IAVF_EXTENDED_CAP_SEND_VLAN_V2;\n\tiavf_change_state(adapter, __IAVF_INIT_FAILED);\n}\n\n \nstatic void iavf_init_process_extended_caps(struct iavf_adapter *adapter)\n{\n\tWARN_ON(adapter->state != __IAVF_INIT_EXTENDED_CAPS);\n\n\t \n\tif (adapter->extended_caps & IAVF_EXTENDED_CAP_SEND_VLAN_V2) {\n\t\tiavf_init_send_offload_vlan_v2_caps(adapter);\n\t\treturn;\n\t} else if (adapter->extended_caps & IAVF_EXTENDED_CAP_RECV_VLAN_V2) {\n\t\tiavf_init_recv_offload_vlan_v2_caps(adapter);\n\t\treturn;\n\t}\n\n\t \n\tiavf_change_state(adapter, __IAVF_INIT_CONFIG_ADAPTER);\n}\n\n \nstatic void iavf_init_config_adapter(struct iavf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tint err;\n\n\tWARN_ON(adapter->state != __IAVF_INIT_CONFIG_ADAPTER);\n\n\tif (iavf_process_config(adapter))\n\t\tgoto err;\n\n\tadapter->current_op = VIRTCHNL_OP_UNKNOWN;\n\n\tadapter->flags |= IAVF_FLAG_RX_CSUM_ENABLED;\n\n\tnetdev->netdev_ops = &iavf_netdev_ops;\n\tiavf_set_ethtool_ops(netdev);\n\tnetdev->watchdog_timeo = 5 * HZ;\n\n\t \n\tnetdev->min_mtu = ETH_MIN_MTU;\n\tnetdev->max_mtu = IAVF_MAX_RXBUFFER - IAVF_PACKET_HDR_PAD;\n\n\tif (!is_valid_ether_addr(adapter->hw.mac.addr)) {\n\t\tdev_info(&pdev->dev, \"Invalid MAC address %pM, using random\\n\",\n\t\t\t adapter->hw.mac.addr);\n\t\teth_hw_addr_random(netdev);\n\t\tether_addr_copy(adapter->hw.mac.addr, netdev->dev_addr);\n\t} else {\n\t\teth_hw_addr_set(netdev, adapter->hw.mac.addr);\n\t\tether_addr_copy(netdev->perm_addr, adapter->hw.mac.addr);\n\t}\n\n\tadapter->tx_desc_count = IAVF_DEFAULT_TXD;\n\tadapter->rx_desc_count = IAVF_DEFAULT_RXD;\n\terr = iavf_init_interrupt_scheme(adapter);\n\tif (err)\n\t\tgoto err_sw_init;\n\tiavf_map_rings_to_vectors(adapter);\n\tif (adapter->vf_res->vf_cap_flags &\n\t\tVIRTCHNL_VF_OFFLOAD_WB_ON_ITR)\n\t\tadapter->flags |= IAVF_FLAG_WB_ON_ITR_CAPABLE;\n\n\terr = iavf_request_misc_irq(adapter);\n\tif (err)\n\t\tgoto err_sw_init;\n\n\tnetif_carrier_off(netdev);\n\tadapter->link_up = false;\n\tnetif_tx_stop_all_queues(netdev);\n\n\tif (CLIENT_ALLOWED(adapter)) {\n\t\terr = iavf_lan_add_device(adapter);\n\t\tif (err)\n\t\t\tdev_info(&pdev->dev, \"Failed to add VF to client API service list: %d\\n\",\n\t\t\t\t err);\n\t}\n\tdev_info(&pdev->dev, \"MAC address: %pM\\n\", adapter->hw.mac.addr);\n\tif (netdev->features & NETIF_F_GRO)\n\t\tdev_info(&pdev->dev, \"GRO is enabled\\n\");\n\n\tiavf_change_state(adapter, __IAVF_DOWN);\n\tset_bit(__IAVF_VSI_DOWN, adapter->vsi.state);\n\n\tiavf_misc_irq_enable(adapter);\n\twake_up(&adapter->down_waitqueue);\n\n\tadapter->rss_key = kzalloc(adapter->rss_key_size, GFP_KERNEL);\n\tadapter->rss_lut = kzalloc(adapter->rss_lut_size, GFP_KERNEL);\n\tif (!adapter->rss_key || !adapter->rss_lut) {\n\t\terr = -ENOMEM;\n\t\tgoto err_mem;\n\t}\n\tif (RSS_AQ(adapter))\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_CONFIGURE_RSS;\n\telse\n\t\tiavf_init_rss(adapter);\n\n\tif (VLAN_V2_ALLOWED(adapter))\n\t\t \n\t\tiavf_set_vlan_offload_features(adapter, 0, netdev->features);\n\n\tiavf_schedule_finish_config(adapter);\n\treturn;\n\nerr_mem:\n\tiavf_free_rss(adapter);\n\tiavf_free_misc_irq(adapter);\nerr_sw_init:\n\tiavf_reset_interrupt_capability(adapter);\nerr:\n\tiavf_change_state(adapter, __IAVF_INIT_FAILED);\n}\n\n \nstatic void iavf_watchdog_task(struct work_struct *work)\n{\n\tstruct iavf_adapter *adapter = container_of(work,\n\t\t\t\t\t\t    struct iavf_adapter,\n\t\t\t\t\t\t    watchdog_task.work);\n\tstruct iavf_hw *hw = &adapter->hw;\n\tu32 reg_val;\n\n\tif (!mutex_trylock(&adapter->crit_lock)) {\n\t\tif (adapter->state == __IAVF_REMOVE)\n\t\t\treturn;\n\n\t\tgoto restart_watchdog;\n\t}\n\n\tif (adapter->flags & IAVF_FLAG_PF_COMMS_FAILED)\n\t\tiavf_change_state(adapter, __IAVF_COMM_FAILED);\n\n\tswitch (adapter->state) {\n\tcase __IAVF_STARTUP:\n\t\tiavf_startup(adapter);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   msecs_to_jiffies(30));\n\t\treturn;\n\tcase __IAVF_INIT_VERSION_CHECK:\n\t\tiavf_init_version_check(adapter);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   msecs_to_jiffies(30));\n\t\treturn;\n\tcase __IAVF_INIT_GET_RESOURCES:\n\t\tiavf_init_get_resources(adapter);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   msecs_to_jiffies(1));\n\t\treturn;\n\tcase __IAVF_INIT_EXTENDED_CAPS:\n\t\tiavf_init_process_extended_caps(adapter);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   msecs_to_jiffies(1));\n\t\treturn;\n\tcase __IAVF_INIT_CONFIG_ADAPTER:\n\t\tiavf_init_config_adapter(adapter);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   msecs_to_jiffies(1));\n\t\treturn;\n\tcase __IAVF_INIT_FAILED:\n\t\tif (test_bit(__IAVF_IN_REMOVE_TASK,\n\t\t\t     &adapter->crit_section)) {\n\t\t\t \n\t\t\tmutex_unlock(&adapter->crit_lock);\n\t\t\treturn;\n\t\t}\n\t\tif (++adapter->aq_wait_count > IAVF_AQ_MAX_ERR) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Failed to communicate with PF; waiting before retry\\n\");\n\t\t\tadapter->flags |= IAVF_FLAG_PF_COMMS_FAILED;\n\t\t\tiavf_shutdown_adminq(hw);\n\t\t\tmutex_unlock(&adapter->crit_lock);\n\t\t\tqueue_delayed_work(adapter->wq,\n\t\t\t\t\t   &adapter->watchdog_task, (5 * HZ));\n\t\t\treturn;\n\t\t}\n\t\t \n\t\tiavf_change_state(adapter, adapter->last_state);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task, HZ);\n\t\treturn;\n\tcase __IAVF_COMM_FAILED:\n\t\tif (test_bit(__IAVF_IN_REMOVE_TASK,\n\t\t\t     &adapter->crit_section)) {\n\t\t\t \n\t\t\tiavf_change_state(adapter, __IAVF_INIT_FAILED);\n\t\t\tadapter->flags &= ~IAVF_FLAG_PF_COMMS_FAILED;\n\t\t\tmutex_unlock(&adapter->crit_lock);\n\t\t\treturn;\n\t\t}\n\t\treg_val = rd32(hw, IAVF_VFGEN_RSTAT) &\n\t\t\t  IAVF_VFGEN_RSTAT_VFR_STATE_MASK;\n\t\tif (reg_val == VIRTCHNL_VFR_VFACTIVE ||\n\t\t    reg_val == VIRTCHNL_VFR_COMPLETED) {\n\t\t\t \n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Hardware came out of reset. Attempting reinit.\\n\");\n\t\t\t \n\t\t\tiavf_change_state(adapter, __IAVF_STARTUP);\n\t\t\tadapter->flags &= ~IAVF_FLAG_PF_COMMS_FAILED;\n\t\t}\n\t\tadapter->aq_required = 0;\n\t\tadapter->current_op = VIRTCHNL_OP_UNKNOWN;\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq,\n\t\t\t\t   &adapter->watchdog_task,\n\t\t\t\t   msecs_to_jiffies(10));\n\t\treturn;\n\tcase __IAVF_RESETTING:\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   HZ * 2);\n\t\treturn;\n\tcase __IAVF_DOWN:\n\tcase __IAVF_DOWN_PENDING:\n\tcase __IAVF_TESTING:\n\tcase __IAVF_RUNNING:\n\t\tif (adapter->current_op) {\n\t\t\tif (!iavf_asq_done(hw)) {\n\t\t\t\tdev_dbg(&adapter->pdev->dev,\n\t\t\t\t\t\"Admin queue timeout\\n\");\n\t\t\t\tiavf_send_api_ver(adapter);\n\t\t\t}\n\t\t} else {\n\t\t\tint ret = iavf_process_aq_command(adapter);\n\n\t\t\t \n\t\t\tif (ret && ret != -EOPNOTSUPP &&\n\t\t\t    adapter->state == __IAVF_RUNNING)\n\t\t\t\tiavf_request_stats(adapter);\n\t\t}\n\t\tif (adapter->state == __IAVF_RUNNING)\n\t\t\tiavf_detect_recover_hung(&adapter->vsi);\n\t\tbreak;\n\tcase __IAVF_REMOVE:\n\tdefault:\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\treturn;\n\t}\n\n\t \n\treg_val = rd32(hw, IAVF_VF_ARQLEN1) & IAVF_VF_ARQLEN1_ARQENABLE_MASK;\n\tif (!reg_val) {\n\t\tadapter->aq_required = 0;\n\t\tadapter->current_op = VIRTCHNL_OP_UNKNOWN;\n\t\tdev_err(&adapter->pdev->dev, \"Hardware reset detected\\n\");\n\t\tiavf_schedule_reset(adapter, IAVF_FLAG_RESET_PENDING);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tqueue_delayed_work(adapter->wq,\n\t\t\t\t   &adapter->watchdog_task, HZ * 2);\n\t\treturn;\n\t}\n\n\tschedule_delayed_work(&adapter->client_task, msecs_to_jiffies(5));\n\tmutex_unlock(&adapter->crit_lock);\nrestart_watchdog:\n\tif (adapter->state >= __IAVF_DOWN)\n\t\tqueue_work(adapter->wq, &adapter->adminq_task);\n\tif (adapter->aq_required)\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   msecs_to_jiffies(20));\n\telse\n\t\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t\t   HZ * 2);\n}\n\n \nstatic void iavf_disable_vf(struct iavf_adapter *adapter)\n{\n\tstruct iavf_mac_filter *f, *ftmp;\n\tstruct iavf_vlan_filter *fv, *fvtmp;\n\tstruct iavf_cloud_filter *cf, *cftmp;\n\n\tadapter->flags |= IAVF_FLAG_PF_COMMS_FAILED;\n\n\t \n\tif (adapter->state == __IAVF_RUNNING) {\n\t\tset_bit(__IAVF_VSI_DOWN, adapter->vsi.state);\n\t\tnetif_carrier_off(adapter->netdev);\n\t\tnetif_tx_disable(adapter->netdev);\n\t\tadapter->link_up = false;\n\t\tiavf_napi_disable_all(adapter);\n\t\tiavf_irq_disable(adapter);\n\t\tiavf_free_traffic_irqs(adapter);\n\t\tiavf_free_all_tx_resources(adapter);\n\t\tiavf_free_all_rx_resources(adapter);\n\t}\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\t \n\tlist_for_each_entry_safe(f, ftmp, &adapter->mac_filter_list, list) {\n\t\tlist_del(&f->list);\n\t\tkfree(f);\n\t}\n\n\tlist_for_each_entry_safe(fv, fvtmp, &adapter->vlan_filter_list, list) {\n\t\tlist_del(&fv->list);\n\t\tkfree(fv);\n\t}\n\tadapter->num_vlan_filters = 0;\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tlist_for_each_entry_safe(cf, cftmp, &adapter->cloud_filter_list, list) {\n\t\tlist_del(&cf->list);\n\t\tkfree(cf);\n\t\tadapter->num_cloud_filters--;\n\t}\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\n\n\tiavf_free_misc_irq(adapter);\n\tiavf_reset_interrupt_capability(adapter);\n\tiavf_free_q_vectors(adapter);\n\tiavf_free_queues(adapter);\n\tmemset(adapter->vf_res, 0, IAVF_VIRTCHNL_VF_RESOURCE_SIZE);\n\tiavf_shutdown_adminq(&adapter->hw);\n\tadapter->flags &= ~IAVF_FLAG_RESET_PENDING;\n\tiavf_change_state(adapter, __IAVF_DOWN);\n\twake_up(&adapter->down_waitqueue);\n\tdev_info(&adapter->pdev->dev, \"Reset task did not complete, VF disabled\\n\");\n}\n\n \nstatic void iavf_reset_task(struct work_struct *work)\n{\n\tstruct iavf_adapter *adapter = container_of(work,\n\t\t\t\t\t\t      struct iavf_adapter,\n\t\t\t\t\t\t      reset_task);\n\tstruct virtchnl_vf_resource *vfres = adapter->vf_res;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct iavf_hw *hw = &adapter->hw;\n\tstruct iavf_mac_filter *f, *ftmp;\n\tstruct iavf_cloud_filter *cf;\n\tenum iavf_status status;\n\tu32 reg_val;\n\tint i = 0, err;\n\tbool running;\n\n\t \n\tif (!mutex_trylock(&adapter->crit_lock)) {\n\t\tif (adapter->state != __IAVF_REMOVE)\n\t\t\tqueue_work(adapter->wq, &adapter->reset_task);\n\n\t\treturn;\n\t}\n\n\twhile (!mutex_trylock(&adapter->client_lock))\n\t\tusleep_range(500, 1000);\n\tif (CLIENT_ENABLED(adapter)) {\n\t\tadapter->flags &= ~(IAVF_FLAG_CLIENT_NEEDS_OPEN |\n\t\t\t\t    IAVF_FLAG_CLIENT_NEEDS_CLOSE |\n\t\t\t\t    IAVF_FLAG_CLIENT_NEEDS_L2_PARAMS |\n\t\t\t\t    IAVF_FLAG_SERVICE_CLIENT_REQUESTED);\n\t\tcancel_delayed_work_sync(&adapter->client_task);\n\t\tiavf_notify_client_close(&adapter->vsi, true);\n\t}\n\tiavf_misc_irq_disable(adapter);\n\tif (adapter->flags & IAVF_FLAG_RESET_NEEDED) {\n\t\tadapter->flags &= ~IAVF_FLAG_RESET_NEEDED;\n\t\t \n\t\tiavf_shutdown_adminq(hw);\n\t\tiavf_init_adminq(hw);\n\t\tiavf_request_reset(adapter);\n\t}\n\tadapter->flags |= IAVF_FLAG_RESET_PENDING;\n\n\t \n\tfor (i = 0; i < IAVF_RESET_WAIT_DETECTED_COUNT; i++) {\n\t\treg_val = rd32(hw, IAVF_VF_ARQLEN1) &\n\t\t\t  IAVF_VF_ARQLEN1_ARQENABLE_MASK;\n\t\tif (!reg_val)\n\t\t\tbreak;\n\t\tusleep_range(5000, 10000);\n\t}\n\tif (i == IAVF_RESET_WAIT_DETECTED_COUNT) {\n\t\tdev_info(&adapter->pdev->dev, \"Never saw reset\\n\");\n\t\tgoto continue_reset;  \n\t}\n\n\t \n\tfor (i = 0; i < IAVF_RESET_WAIT_COMPLETE_COUNT; i++) {\n\t\t \n\t\tmsleep(IAVF_RESET_WAIT_MS);\n\n\t\treg_val = rd32(hw, IAVF_VFGEN_RSTAT) &\n\t\t\t  IAVF_VFGEN_RSTAT_VFR_STATE_MASK;\n\t\tif (reg_val == VIRTCHNL_VFR_VFACTIVE)\n\t\t\tbreak;\n\t}\n\n\tpci_set_master(adapter->pdev);\n\tpci_restore_msi_state(adapter->pdev);\n\n\tif (i == IAVF_RESET_WAIT_COMPLETE_COUNT) {\n\t\tdev_err(&adapter->pdev->dev, \"Reset never finished (%x)\\n\",\n\t\t\treg_val);\n\t\tiavf_disable_vf(adapter);\n\t\tmutex_unlock(&adapter->client_lock);\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\treturn;  \n\t}\n\ncontinue_reset:\n\t \n\trunning = adapter->state == __IAVF_RUNNING;\n\n\tif (running) {\n\t\tnetif_carrier_off(netdev);\n\t\tnetif_tx_stop_all_queues(netdev);\n\t\tadapter->link_up = false;\n\t\tiavf_napi_disable_all(adapter);\n\t}\n\tiavf_irq_disable(adapter);\n\n\tiavf_change_state(adapter, __IAVF_RESETTING);\n\tadapter->flags &= ~IAVF_FLAG_RESET_PENDING;\n\n\t \n\tiavf_free_all_rx_resources(adapter);\n\tiavf_free_all_tx_resources(adapter);\n\n\tadapter->flags |= IAVF_FLAG_QUEUES_DISABLED;\n\t \n\tiavf_shutdown_adminq(hw);\n\tadapter->current_op = VIRTCHNL_OP_UNKNOWN;\n\tstatus = iavf_init_adminq(hw);\n\tif (status) {\n\t\tdev_info(&adapter->pdev->dev, \"Failed to init adminq: %d\\n\",\n\t\t\t status);\n\t\tgoto reset_err;\n\t}\n\tadapter->aq_required = 0;\n\n\tif ((adapter->flags & IAVF_FLAG_REINIT_MSIX_NEEDED) ||\n\t    (adapter->flags & IAVF_FLAG_REINIT_ITR_NEEDED)) {\n\t\terr = iavf_reinit_interrupt_scheme(adapter, running);\n\t\tif (err)\n\t\t\tgoto reset_err;\n\t}\n\n\tif (RSS_AQ(adapter)) {\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_CONFIGURE_RSS;\n\t} else {\n\t\terr = iavf_init_rss(adapter);\n\t\tif (err)\n\t\t\tgoto reset_err;\n\t}\n\n\tadapter->aq_required |= IAVF_FLAG_AQ_GET_CONFIG;\n\t \n\tadapter->aq_required |= IAVF_FLAG_AQ_GET_OFFLOAD_VLAN_V2_CAPS;\n\tadapter->aq_required |= IAVF_FLAG_AQ_MAP_VECTORS;\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\t \n\tlist_for_each_entry_safe(f, ftmp, &adapter->mac_filter_list, list) {\n\t\tif (ether_addr_equal(f->macaddr, adapter->hw.mac.addr)) {\n\t\t\tlist_del(&f->list);\n\t\t\tkfree(f);\n\t\t}\n\t}\n\t \n\tlist_for_each_entry(f, &adapter->mac_filter_list, list) {\n\t\tf->add = true;\n\t}\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\n\t \n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tif ((vfres->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_ADQ) &&\n\t    adapter->num_tc) {\n\t\tlist_for_each_entry(cf, &adapter->cloud_filter_list, list) {\n\t\t\tcf->add = true;\n\t\t}\n\t}\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\n\n\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_MAC_FILTER;\n\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_CLOUD_FILTER;\n\tiavf_misc_irq_enable(adapter);\n\n\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 2);\n\n\t \n\tif (running) {\n\t\t \n\t\terr = iavf_setup_all_tx_resources(adapter);\n\t\tif (err)\n\t\t\tgoto reset_err;\n\n\t\t \n\t\terr = iavf_setup_all_rx_resources(adapter);\n\t\tif (err)\n\t\t\tgoto reset_err;\n\n\t\tif ((adapter->flags & IAVF_FLAG_REINIT_MSIX_NEEDED) ||\n\t\t    (adapter->flags & IAVF_FLAG_REINIT_ITR_NEEDED)) {\n\t\t\terr = iavf_request_traffic_irqs(adapter, netdev->name);\n\t\t\tif (err)\n\t\t\t\tgoto reset_err;\n\n\t\t\tadapter->flags &= ~IAVF_FLAG_REINIT_MSIX_NEEDED;\n\t\t}\n\n\t\tiavf_configure(adapter);\n\n\t\t \n\t\tiavf_up_complete(adapter);\n\n\t\tiavf_irq_enable(adapter, true);\n\t} else {\n\t\tiavf_change_state(adapter, __IAVF_DOWN);\n\t\twake_up(&adapter->down_waitqueue);\n\t}\n\n\tadapter->flags &= ~IAVF_FLAG_REINIT_ITR_NEEDED;\n\n\twake_up(&adapter->reset_waitqueue);\n\tmutex_unlock(&adapter->client_lock);\n\tmutex_unlock(&adapter->crit_lock);\n\n\treturn;\nreset_err:\n\tif (running) {\n\t\tset_bit(__IAVF_VSI_DOWN, adapter->vsi.state);\n\t\tiavf_free_traffic_irqs(adapter);\n\t}\n\tiavf_disable_vf(adapter);\n\n\tmutex_unlock(&adapter->client_lock);\n\tmutex_unlock(&adapter->crit_lock);\n\tdev_err(&adapter->pdev->dev, \"failed to allocate resources during reinit\\n\");\n}\n\n \nstatic void iavf_adminq_task(struct work_struct *work)\n{\n\tstruct iavf_adapter *adapter =\n\t\tcontainer_of(work, struct iavf_adapter, adminq_task);\n\tstruct iavf_hw *hw = &adapter->hw;\n\tstruct iavf_arq_event_info event;\n\tenum virtchnl_ops v_op;\n\tenum iavf_status ret, v_ret;\n\tu32 val, oldval;\n\tu16 pending;\n\n\tif (!mutex_trylock(&adapter->crit_lock)) {\n\t\tif (adapter->state == __IAVF_REMOVE)\n\t\t\treturn;\n\n\t\tqueue_work(adapter->wq, &adapter->adminq_task);\n\t\tgoto out;\n\t}\n\n\tif (adapter->flags & IAVF_FLAG_PF_COMMS_FAILED)\n\t\tgoto unlock;\n\n\tevent.buf_len = IAVF_MAX_AQ_BUF_SIZE;\n\tevent.msg_buf = kzalloc(event.buf_len, GFP_KERNEL);\n\tif (!event.msg_buf)\n\t\tgoto unlock;\n\n\tdo {\n\t\tret = iavf_clean_arq_element(hw, &event, &pending);\n\t\tv_op = (enum virtchnl_ops)le32_to_cpu(event.desc.cookie_high);\n\t\tv_ret = (enum iavf_status)le32_to_cpu(event.desc.cookie_low);\n\n\t\tif (ret || !v_op)\n\t\t\tbreak;  \n\n\t\tiavf_virtchnl_completion(adapter, v_op, v_ret, event.msg_buf,\n\t\t\t\t\t event.msg_len);\n\t\tif (pending != 0)\n\t\t\tmemset(event.msg_buf, 0, IAVF_MAX_AQ_BUF_SIZE);\n\t} while (pending);\n\n\tif (iavf_is_reset_in_progress(adapter))\n\t\tgoto freedom;\n\n\t \n\tval = rd32(hw, hw->aq.arq.len);\n\tif (val == 0xdeadbeef || val == 0xffffffff)  \n\t\tgoto freedom;\n\toldval = val;\n\tif (val & IAVF_VF_ARQLEN1_ARQVFE_MASK) {\n\t\tdev_info(&adapter->pdev->dev, \"ARQ VF Error detected\\n\");\n\t\tval &= ~IAVF_VF_ARQLEN1_ARQVFE_MASK;\n\t}\n\tif (val & IAVF_VF_ARQLEN1_ARQOVFL_MASK) {\n\t\tdev_info(&adapter->pdev->dev, \"ARQ Overflow Error detected\\n\");\n\t\tval &= ~IAVF_VF_ARQLEN1_ARQOVFL_MASK;\n\t}\n\tif (val & IAVF_VF_ARQLEN1_ARQCRIT_MASK) {\n\t\tdev_info(&adapter->pdev->dev, \"ARQ Critical Error detected\\n\");\n\t\tval &= ~IAVF_VF_ARQLEN1_ARQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(hw, hw->aq.arq.len, val);\n\n\tval = rd32(hw, hw->aq.asq.len);\n\toldval = val;\n\tif (val & IAVF_VF_ATQLEN1_ATQVFE_MASK) {\n\t\tdev_info(&adapter->pdev->dev, \"ASQ VF Error detected\\n\");\n\t\tval &= ~IAVF_VF_ATQLEN1_ATQVFE_MASK;\n\t}\n\tif (val & IAVF_VF_ATQLEN1_ATQOVFL_MASK) {\n\t\tdev_info(&adapter->pdev->dev, \"ASQ Overflow Error detected\\n\");\n\t\tval &= ~IAVF_VF_ATQLEN1_ATQOVFL_MASK;\n\t}\n\tif (val & IAVF_VF_ATQLEN1_ATQCRIT_MASK) {\n\t\tdev_info(&adapter->pdev->dev, \"ASQ Critical Error detected\\n\");\n\t\tval &= ~IAVF_VF_ATQLEN1_ATQCRIT_MASK;\n\t}\n\tif (oldval != val)\n\t\twr32(hw, hw->aq.asq.len, val);\n\nfreedom:\n\tkfree(event.msg_buf);\nunlock:\n\tmutex_unlock(&adapter->crit_lock);\nout:\n\t \n\tiavf_misc_irq_enable(adapter);\n}\n\n \nstatic void iavf_client_task(struct work_struct *work)\n{\n\tstruct iavf_adapter *adapter =\n\t\tcontainer_of(work, struct iavf_adapter, client_task.work);\n\n\t \n\n\tif (!mutex_trylock(&adapter->client_lock))\n\t\treturn;\n\n\tif (adapter->flags & IAVF_FLAG_SERVICE_CLIENT_REQUESTED) {\n\t\tiavf_client_subtask(adapter);\n\t\tadapter->flags &= ~IAVF_FLAG_SERVICE_CLIENT_REQUESTED;\n\t\tgoto out;\n\t}\n\tif (adapter->flags & IAVF_FLAG_CLIENT_NEEDS_L2_PARAMS) {\n\t\tiavf_notify_client_l2_params(&adapter->vsi);\n\t\tadapter->flags &= ~IAVF_FLAG_CLIENT_NEEDS_L2_PARAMS;\n\t\tgoto out;\n\t}\n\tif (adapter->flags & IAVF_FLAG_CLIENT_NEEDS_CLOSE) {\n\t\tiavf_notify_client_close(&adapter->vsi, false);\n\t\tadapter->flags &= ~IAVF_FLAG_CLIENT_NEEDS_CLOSE;\n\t\tgoto out;\n\t}\n\tif (adapter->flags & IAVF_FLAG_CLIENT_NEEDS_OPEN) {\n\t\tiavf_notify_client_open(&adapter->vsi);\n\t\tadapter->flags &= ~IAVF_FLAG_CLIENT_NEEDS_OPEN;\n\t}\nout:\n\tmutex_unlock(&adapter->client_lock);\n}\n\n \nvoid iavf_free_all_tx_resources(struct iavf_adapter *adapter)\n{\n\tint i;\n\n\tif (!adapter->tx_rings)\n\t\treturn;\n\n\tfor (i = 0; i < adapter->num_active_queues; i++)\n\t\tif (adapter->tx_rings[i].desc)\n\t\t\tiavf_free_tx_resources(&adapter->tx_rings[i]);\n}\n\n \nstatic int iavf_setup_all_tx_resources(struct iavf_adapter *adapter)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < adapter->num_active_queues; i++) {\n\t\tadapter->tx_rings[i].count = adapter->tx_desc_count;\n\t\terr = iavf_setup_tx_descriptors(&adapter->tx_rings[i]);\n\t\tif (!err)\n\t\t\tcontinue;\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Allocation for Tx Queue %u failed\\n\", i);\n\t\tbreak;\n\t}\n\n\treturn err;\n}\n\n \nstatic int iavf_setup_all_rx_resources(struct iavf_adapter *adapter)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < adapter->num_active_queues; i++) {\n\t\tadapter->rx_rings[i].count = adapter->rx_desc_count;\n\t\terr = iavf_setup_rx_descriptors(&adapter->rx_rings[i]);\n\t\tif (!err)\n\t\t\tcontinue;\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Allocation for Rx Queue %u failed\\n\", i);\n\t\tbreak;\n\t}\n\treturn err;\n}\n\n \nvoid iavf_free_all_rx_resources(struct iavf_adapter *adapter)\n{\n\tint i;\n\n\tif (!adapter->rx_rings)\n\t\treturn;\n\n\tfor (i = 0; i < adapter->num_active_queues; i++)\n\t\tif (adapter->rx_rings[i].desc)\n\t\t\tiavf_free_rx_resources(&adapter->rx_rings[i]);\n}\n\n \nstatic int iavf_validate_tx_bandwidth(struct iavf_adapter *adapter,\n\t\t\t\t      u64 max_tx_rate)\n{\n\tint speed = 0, ret = 0;\n\n\tif (ADV_LINK_SUPPORT(adapter)) {\n\t\tif (adapter->link_speed_mbps < U32_MAX) {\n\t\t\tspeed = adapter->link_speed_mbps;\n\t\t\tgoto validate_bw;\n\t\t} else {\n\t\t\tdev_err(&adapter->pdev->dev, \"Unknown link speed\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tswitch (adapter->link_speed) {\n\tcase VIRTCHNL_LINK_SPEED_40GB:\n\t\tspeed = SPEED_40000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_25GB:\n\t\tspeed = SPEED_25000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_20GB:\n\t\tspeed = SPEED_20000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_10GB:\n\t\tspeed = SPEED_10000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_5GB:\n\t\tspeed = SPEED_5000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_2_5GB:\n\t\tspeed = SPEED_2500;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_1GB:\n\t\tspeed = SPEED_1000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_100MB:\n\t\tspeed = SPEED_100;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\nvalidate_bw:\n\tif (max_tx_rate > speed) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Invalid tx rate specified\\n\");\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\n \nstatic int iavf_validate_ch_config(struct iavf_adapter *adapter,\n\t\t\t\t   struct tc_mqprio_qopt_offload *mqprio_qopt)\n{\n\tu64 total_max_rate = 0;\n\tu32 tx_rate_rem = 0;\n\tint i, num_qps = 0;\n\tu64 tx_rate = 0;\n\tint ret = 0;\n\n\tif (mqprio_qopt->qopt.num_tc > IAVF_MAX_TRAFFIC_CLASS ||\n\t    mqprio_qopt->qopt.num_tc < 1)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i <= mqprio_qopt->qopt.num_tc - 1; i++) {\n\t\tif (!mqprio_qopt->qopt.count[i] ||\n\t\t    mqprio_qopt->qopt.offset[i] != num_qps)\n\t\t\treturn -EINVAL;\n\t\tif (mqprio_qopt->min_rate[i]) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Invalid min tx rate (greater than 0) specified for TC%d\\n\",\n\t\t\t\ti);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\ttx_rate = div_u64(mqprio_qopt->max_rate[i],\n\t\t\t\t  IAVF_MBPS_DIVISOR);\n\n\t\tif (mqprio_qopt->max_rate[i] &&\n\t\t    tx_rate < IAVF_MBPS_QUANTA) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Invalid max tx rate for TC%d, minimum %dMbps\\n\",\n\t\t\t\ti, IAVF_MBPS_QUANTA);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t(void)div_u64_rem(tx_rate, IAVF_MBPS_QUANTA, &tx_rate_rem);\n\n\t\tif (tx_rate_rem != 0) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Invalid max tx rate for TC%d, not divisible by %d\\n\",\n\t\t\t\ti, IAVF_MBPS_QUANTA);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\ttotal_max_rate += tx_rate;\n\t\tnum_qps += mqprio_qopt->qopt.count[i];\n\t}\n\tif (num_qps > adapter->num_active_queues) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot support requested number of queues\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = iavf_validate_tx_bandwidth(adapter, total_max_rate);\n\treturn ret;\n}\n\n \nstatic void iavf_del_all_cloud_filters(struct iavf_adapter *adapter)\n{\n\tstruct iavf_cloud_filter *cf, *cftmp;\n\n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tlist_for_each_entry_safe(cf, cftmp, &adapter->cloud_filter_list,\n\t\t\t\t list) {\n\t\tlist_del(&cf->list);\n\t\tkfree(cf);\n\t\tadapter->num_cloud_filters--;\n\t}\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\n}\n\n \nstatic int __iavf_setup_tc(struct net_device *netdev, void *type_data)\n{\n\tstruct tc_mqprio_qopt_offload *mqprio_qopt = type_data;\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tstruct virtchnl_vf_resource *vfres = adapter->vf_res;\n\tu8 num_tc = 0, total_qps = 0;\n\tint ret = 0, netdev_tc = 0;\n\tu64 max_tx_rate;\n\tu16 mode;\n\tint i;\n\n\tnum_tc = mqprio_qopt->qopt.num_tc;\n\tmode = mqprio_qopt->mode;\n\n\t \n\tif (!mqprio_qopt->qopt.hw) {\n\t\tif (adapter->ch_config.state == __IAVF_TC_RUNNING) {\n\t\t\t \n\t\t\tnetdev_reset_tc(netdev);\n\t\t\tadapter->num_tc = 0;\n\t\t\tnetif_tx_stop_all_queues(netdev);\n\t\t\tnetif_tx_disable(netdev);\n\t\t\tiavf_del_all_cloud_filters(adapter);\n\t\t\tadapter->aq_required = IAVF_FLAG_AQ_DISABLE_CHANNELS;\n\t\t\ttotal_qps = adapter->orig_num_active_queues;\n\t\t\tgoto exit;\n\t\t} else {\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t \n\tif (mode == TC_MQPRIO_MODE_CHANNEL) {\n\t\tif (!(vfres->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_ADQ)) {\n\t\t\tdev_err(&adapter->pdev->dev, \"ADq not supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (adapter->ch_config.state != __IAVF_TC_INVALID) {\n\t\t\tdev_err(&adapter->pdev->dev, \"TC configuration already exists\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = iavf_validate_ch_config(adapter, mqprio_qopt);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\t \n\t\tif (adapter->num_tc == num_tc)\n\t\t\treturn 0;\n\t\tadapter->num_tc = num_tc;\n\n\t\tfor (i = 0; i < IAVF_MAX_TRAFFIC_CLASS; i++) {\n\t\t\tif (i < num_tc) {\n\t\t\t\tadapter->ch_config.ch_info[i].count =\n\t\t\t\t\tmqprio_qopt->qopt.count[i];\n\t\t\t\tadapter->ch_config.ch_info[i].offset =\n\t\t\t\t\tmqprio_qopt->qopt.offset[i];\n\t\t\t\ttotal_qps += mqprio_qopt->qopt.count[i];\n\t\t\t\tmax_tx_rate = mqprio_qopt->max_rate[i];\n\t\t\t\t \n\t\t\t\tmax_tx_rate = div_u64(max_tx_rate,\n\t\t\t\t\t\t      IAVF_MBPS_DIVISOR);\n\t\t\t\tadapter->ch_config.ch_info[i].max_tx_rate =\n\t\t\t\t\tmax_tx_rate;\n\t\t\t} else {\n\t\t\t\tadapter->ch_config.ch_info[i].count = 1;\n\t\t\t\tadapter->ch_config.ch_info[i].offset = 0;\n\t\t\t}\n\t\t}\n\n\t\t \n\n\t\tadapter->orig_num_active_queues = adapter->num_active_queues;\n\n\t\t \n\t\tadapter->ch_config.total_qps = total_qps;\n\n\t\tnetif_tx_stop_all_queues(netdev);\n\t\tnetif_tx_disable(netdev);\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_ENABLE_CHANNELS;\n\t\tnetdev_reset_tc(netdev);\n\t\t \n\t\tnetdev_set_num_tc(adapter->netdev, num_tc);\n\t\tfor (i = 0; i < IAVF_MAX_TRAFFIC_CLASS; i++) {\n\t\t\tu16 qcount = mqprio_qopt->qopt.count[i];\n\t\t\tu16 qoffset = mqprio_qopt->qopt.offset[i];\n\n\t\t\tif (i < num_tc)\n\t\t\t\tnetdev_set_tc_queue(netdev, netdev_tc++, qcount,\n\t\t\t\t\t\t    qoffset);\n\t\t}\n\t}\nexit:\n\tif (test_bit(__IAVF_IN_REMOVE_TASK, &adapter->crit_section))\n\t\treturn 0;\n\n\tnetif_set_real_num_rx_queues(netdev, total_qps);\n\tnetif_set_real_num_tx_queues(netdev, total_qps);\n\n\treturn ret;\n}\n\n \nstatic int iavf_parse_cls_flower(struct iavf_adapter *adapter,\n\t\t\t\t struct flow_cls_offload *f,\n\t\t\t\t struct iavf_cloud_filter *filter)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(f);\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tu16 n_proto_mask = 0;\n\tu16 n_proto_key = 0;\n\tu8 field_flags = 0;\n\tu16 addr_type = 0;\n\tu16 n_proto = 0;\n\tint i = 0;\n\tstruct virtchnl_filter *vf = &filter->f;\n\n\tif (dissector->used_keys &\n\t    ~(BIT_ULL(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ETH_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_VLAN) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_PORTS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ENC_KEYID))) {\n\t\tdev_err(&adapter->pdev->dev, \"Unsupported key used: 0x%llx\\n\",\n\t\t\tdissector->used_keys);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_KEYID)) {\n\t\tstruct flow_match_enc_keyid match;\n\n\t\tflow_rule_match_enc_keyid(rule, &match);\n\t\tif (match.mask->keyid != 0)\n\t\t\tfield_flags |= IAVF_CLOUD_FIELD_TEN_ID;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tn_proto_key = ntohs(match.key->n_proto);\n\t\tn_proto_mask = ntohs(match.mask->n_proto);\n\n\t\tif (n_proto_key == ETH_P_ALL) {\n\t\t\tn_proto_key = 0;\n\t\t\tn_proto_mask = 0;\n\t\t}\n\t\tn_proto = n_proto_key & n_proto_mask;\n\t\tif (n_proto != ETH_P_IP && n_proto != ETH_P_IPV6)\n\t\t\treturn -EINVAL;\n\t\tif (n_proto == ETH_P_IPV6) {\n\t\t\t \n\t\t\tvf->flow_type = VIRTCHNL_TCP_V6_FLOW;\n\t\t}\n\n\t\tif (match.key->ip_proto != IPPROTO_TCP) {\n\t\t\tdev_info(&adapter->pdev->dev, \"Only TCP transport is supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct flow_match_eth_addrs match;\n\n\t\tflow_rule_match_eth_addrs(rule, &match);\n\n\t\t \n\t\tif (!is_zero_ether_addr(match.mask->dst)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->dst)) {\n\t\t\t\tfield_flags |= IAVF_CLOUD_FIELD_OMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Bad ether dest mask %pM\\n\",\n\t\t\t\t\tmatch.mask->dst);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tif (!is_zero_ether_addr(match.mask->src)) {\n\t\t\tif (is_broadcast_ether_addr(match.mask->src)) {\n\t\t\t\tfield_flags |= IAVF_CLOUD_FIELD_IMAC;\n\t\t\t} else {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Bad ether src mask %pM\\n\",\n\t\t\t\t\tmatch.mask->src);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tif (!is_zero_ether_addr(match.key->dst))\n\t\t\tif (is_valid_ether_addr(match.key->dst) ||\n\t\t\t    is_multicast_ether_addr(match.key->dst)) {\n\t\t\t\t \n\t\t\t\tfor (i = 0; i < ETH_ALEN; i++)\n\t\t\t\t\tvf->mask.tcp_spec.dst_mac[i] |= 0xff;\n\t\t\t\tether_addr_copy(vf->data.tcp_spec.dst_mac,\n\t\t\t\t\t\tmatch.key->dst);\n\t\t\t}\n\n\t\tif (!is_zero_ether_addr(match.key->src))\n\t\t\tif (is_valid_ether_addr(match.key->src) ||\n\t\t\t    is_multicast_ether_addr(match.key->src)) {\n\t\t\t\t \n\t\t\t\tfor (i = 0; i < ETH_ALEN; i++)\n\t\t\t\t\tvf->mask.tcp_spec.src_mac[i] |= 0xff;\n\t\t\t\tether_addr_copy(vf->data.tcp_spec.src_mac,\n\t\t\t\t\t\tmatch.key->src);\n\t\t}\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {\n\t\tstruct flow_match_vlan match;\n\n\t\tflow_rule_match_vlan(rule, &match);\n\t\tif (match.mask->vlan_id) {\n\t\t\tif (match.mask->vlan_id == VLAN_VID_MASK) {\n\t\t\t\tfield_flags |= IAVF_CLOUD_FIELD_IVLAN;\n\t\t\t} else {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Bad vlan mask %u\\n\",\n\t\t\t\t\tmatch.mask->vlan_id);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t\tvf->mask.tcp_spec.vlan_id |= cpu_to_be16(0xffff);\n\t\tvf->data.tcp_spec.vlan_id = cpu_to_be16(match.key->vlan_id);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {\n\t\tstruct flow_match_control match;\n\n\t\tflow_rule_match_control(rule, &match);\n\t\taddr_type = match.key->addr_type;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\n\t\tstruct flow_match_ipv4_addrs match;\n\n\t\tflow_rule_match_ipv4_addrs(rule, &match);\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= IAVF_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Bad ip dst mask 0x%08x\\n\",\n\t\t\t\t\tbe32_to_cpu(match.mask->dst));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be32(0xffffffff)) {\n\t\t\t\tfield_flags |= IAVF_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Bad ip src mask 0x%08x\\n\",\n\t\t\t\t\tbe32_to_cpu(match.mask->src));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tif (field_flags & IAVF_CLOUD_FIELD_TEN_ID) {\n\t\t\tdev_info(&adapter->pdev->dev, \"Tenant id not allowed for ip filter\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (match.key->dst) {\n\t\t\tvf->mask.tcp_spec.dst_ip[0] |= cpu_to_be32(0xffffffff);\n\t\t\tvf->data.tcp_spec.dst_ip[0] = match.key->dst;\n\t\t}\n\t\tif (match.key->src) {\n\t\t\tvf->mask.tcp_spec.src_ip[0] |= cpu_to_be32(0xffffffff);\n\t\t\tvf->data.tcp_spec.src_ip[0] = match.key->src;\n\t\t}\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\n\t\tstruct flow_match_ipv6_addrs match;\n\n\t\tflow_rule_match_ipv6_addrs(rule, &match);\n\n\t\t \n\t\tif (ipv6_addr_any(&match.mask->dst)) {\n\t\t\tdev_err(&adapter->pdev->dev, \"Bad ipv6 dst mask 0x%02x\\n\",\n\t\t\t\tIPV6_ADDR_ANY);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (ipv6_addr_loopback(&match.key->dst) ||\n\t\t    ipv6_addr_loopback(&match.key->src)) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"ipv6 addr should not be loopback\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!ipv6_addr_any(&match.mask->dst) ||\n\t\t    !ipv6_addr_any(&match.mask->src))\n\t\t\tfield_flags |= IAVF_CLOUD_FIELD_IIP;\n\n\t\tfor (i = 0; i < 4; i++)\n\t\t\tvf->mask.tcp_spec.dst_ip[i] |= cpu_to_be32(0xffffffff);\n\t\tmemcpy(&vf->data.tcp_spec.dst_ip, &match.key->dst.s6_addr32,\n\t\t       sizeof(vf->data.tcp_spec.dst_ip));\n\t\tfor (i = 0; i < 4; i++)\n\t\t\tvf->mask.tcp_spec.src_ip[i] |= cpu_to_be32(0xffffffff);\n\t\tmemcpy(&vf->data.tcp_spec.src_ip, &match.key->src.s6_addr32,\n\t\t       sizeof(vf->data.tcp_spec.src_ip));\n\t}\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS)) {\n\t\tstruct flow_match_ports match;\n\n\t\tflow_rule_match_ports(rule, &match);\n\t\tif (match.mask->src) {\n\t\t\tif (match.mask->src == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= IAVF_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Bad src port mask %u\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->src));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tif (match.mask->dst) {\n\t\t\tif (match.mask->dst == cpu_to_be16(0xffff)) {\n\t\t\t\tfield_flags |= IAVF_CLOUD_FIELD_IIP;\n\t\t\t} else {\n\t\t\t\tdev_err(&adapter->pdev->dev, \"Bad dst port mask %u\\n\",\n\t\t\t\t\tbe16_to_cpu(match.mask->dst));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t\tif (match.key->dst) {\n\t\t\tvf->mask.tcp_spec.dst_port |= cpu_to_be16(0xffff);\n\t\t\tvf->data.tcp_spec.dst_port = match.key->dst;\n\t\t}\n\n\t\tif (match.key->src) {\n\t\t\tvf->mask.tcp_spec.src_port |= cpu_to_be16(0xffff);\n\t\t\tvf->data.tcp_spec.src_port = match.key->src;\n\t\t}\n\t}\n\tvf->field_flags = field_flags;\n\n\treturn 0;\n}\n\n \nstatic int iavf_handle_tclass(struct iavf_adapter *adapter, u32 tc,\n\t\t\t      struct iavf_cloud_filter *filter)\n{\n\tif (tc == 0)\n\t\treturn 0;\n\tif (tc < adapter->num_tc) {\n\t\tif (!filter->f.data.tcp_spec.dst_port) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Specify destination port to redirect to traffic class other than TC0\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\t \n\tfilter->f.action = VIRTCHNL_ACTION_TC_REDIRECT;\n\tfilter->f.action_meta = tc;\n\treturn 0;\n}\n\n \nstatic struct iavf_cloud_filter *iavf_find_cf(struct iavf_adapter *adapter,\n\t\t\t\t\t      unsigned long *cookie)\n{\n\tstruct iavf_cloud_filter *filter = NULL;\n\n\tif (!cookie)\n\t\treturn NULL;\n\n\tlist_for_each_entry(filter, &adapter->cloud_filter_list, list) {\n\t\tif (!memcmp(cookie, &filter->cookie, sizeof(filter->cookie)))\n\t\t\treturn filter;\n\t}\n\treturn NULL;\n}\n\n \nstatic int iavf_configure_clsflower(struct iavf_adapter *adapter,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tint tc = tc_classid_to_hwtc(adapter->netdev, cls_flower->classid);\n\tstruct iavf_cloud_filter *filter = NULL;\n\tint err = -EINVAL, count = 50;\n\n\tif (tc < 0) {\n\t\tdev_err(&adapter->pdev->dev, \"Invalid traffic class\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tfilter = kzalloc(sizeof(*filter), GFP_KERNEL);\n\tif (!filter)\n\t\treturn -ENOMEM;\n\n\twhile (!mutex_trylock(&adapter->crit_lock)) {\n\t\tif (--count == 0) {\n\t\t\tkfree(filter);\n\t\t\treturn err;\n\t\t}\n\t\tudelay(1);\n\t}\n\n\tfilter->cookie = cls_flower->cookie;\n\n\t \n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tif (iavf_find_cf(adapter, &cls_flower->cookie)) {\n\t\tdev_err(&adapter->pdev->dev, \"Failed to add TC Flower filter, it already exists\\n\");\n\t\terr = -EEXIST;\n\t\tgoto spin_unlock;\n\t}\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\n\n\t \n\tmemset(&filter->f.mask.tcp_spec, 0, sizeof(struct virtchnl_l4_spec));\n\t \n\tfilter->f.flow_type = VIRTCHNL_TCP_V4_FLOW;\n\terr = iavf_parse_cls_flower(adapter, cls_flower, filter);\n\tif (err)\n\t\tgoto err;\n\n\terr = iavf_handle_tclass(adapter, tc, filter);\n\tif (err)\n\t\tgoto err;\n\n\t \n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tlist_add_tail(&filter->list, &adapter->cloud_filter_list);\n\tadapter->num_cloud_filters++;\n\tfilter->add = true;\n\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_CLOUD_FILTER;\nspin_unlock:\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\nerr:\n\tif (err)\n\t\tkfree(filter);\n\n\tmutex_unlock(&adapter->crit_lock);\n\treturn err;\n}\n\n \nstatic int iavf_delete_clsflower(struct iavf_adapter *adapter,\n\t\t\t\t struct flow_cls_offload *cls_flower)\n{\n\tstruct iavf_cloud_filter *filter = NULL;\n\tint err = 0;\n\n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tfilter = iavf_find_cf(adapter, &cls_flower->cookie);\n\tif (filter) {\n\t\tfilter->del = true;\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_CLOUD_FILTER;\n\t} else {\n\t\terr = -EINVAL;\n\t}\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\n\n\treturn err;\n}\n\n \nstatic int iavf_setup_tc_cls_flower(struct iavf_adapter *adapter,\n\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tswitch (cls_flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn iavf_configure_clsflower(adapter, cls_flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn iavf_delete_clsflower(adapter, cls_flower);\n\tcase FLOW_CLS_STATS:\n\t\treturn -EOPNOTSUPP;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n \nstatic int iavf_setup_tc_block_cb(enum tc_setup_type type, void *type_data,\n\t\t\t\t  void *cb_priv)\n{\n\tstruct iavf_adapter *adapter = cb_priv;\n\n\tif (!tc_cls_can_offload_and_chain0(adapter->netdev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\treturn iavf_setup_tc_cls_flower(cb_priv, type_data);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic LIST_HEAD(iavf_block_cb_list);\n\n \nstatic int iavf_setup_tc(struct net_device *netdev, enum tc_setup_type type,\n\t\t\t void *type_data)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tswitch (type) {\n\tcase TC_SETUP_QDISC_MQPRIO:\n\t\treturn __iavf_setup_tc(netdev, type_data);\n\tcase TC_SETUP_BLOCK:\n\t\treturn flow_block_cb_setup_simple(type_data,\n\t\t\t\t\t\t  &iavf_block_cb_list,\n\t\t\t\t\t\t  iavf_setup_tc_block_cb,\n\t\t\t\t\t\t  adapter, adapter, true);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n \nstatic void iavf_restore_fdir_filters(struct iavf_adapter *adapter)\n{\n\tstruct iavf_fdir_fltr *f;\n\n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\tlist_for_each_entry(f, &adapter->fdir_list_head, list) {\n\t\tif (f->state == IAVF_FDIR_FLTR_DIS_REQUEST) {\n\t\t\t \n\t\t\tf->state = IAVF_FDIR_FLTR_ACTIVE;\n\t\t} else if (f->state == IAVF_FDIR_FLTR_DIS_PENDING ||\n\t\t\t   f->state == IAVF_FDIR_FLTR_INACTIVE) {\n\t\t\t \n\t\t\tf->state = IAVF_FDIR_FLTR_ADD_REQUEST;\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_FDIR_FILTER;\n\t\t}\n\t}\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n}\n\n \nstatic int iavf_open(struct net_device *netdev)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tint err;\n\n\tif (adapter->flags & IAVF_FLAG_PF_COMMS_FAILED) {\n\t\tdev_err(&adapter->pdev->dev, \"Unable to open device due to PF driver failure.\\n\");\n\t\treturn -EIO;\n\t}\n\n\twhile (!mutex_trylock(&adapter->crit_lock)) {\n\t\t \n\t\tif (adapter->state == __IAVF_INIT_CONFIG_ADAPTER)\n\t\t\treturn -EBUSY;\n\n\t\tusleep_range(500, 1000);\n\t}\n\n\tif (adapter->state != __IAVF_DOWN) {\n\t\terr = -EBUSY;\n\t\tgoto err_unlock;\n\t}\n\n\tif (adapter->state == __IAVF_RUNNING &&\n\t    !test_bit(__IAVF_VSI_DOWN, adapter->vsi.state)) {\n\t\tdev_dbg(&adapter->pdev->dev, \"VF is already open.\\n\");\n\t\terr = 0;\n\t\tgoto err_unlock;\n\t}\n\n\t \n\terr = iavf_setup_all_tx_resources(adapter);\n\tif (err)\n\t\tgoto err_setup_tx;\n\n\t \n\terr = iavf_setup_all_rx_resources(adapter);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\t \n\terr = iavf_request_traffic_irqs(adapter, netdev->name);\n\tif (err)\n\t\tgoto err_req_irq;\n\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\n\tiavf_add_filter(adapter, adapter->hw.mac.addr);\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\n\t \n\tiavf_restore_filters(adapter);\n\tiavf_restore_fdir_filters(adapter);\n\n\tiavf_configure(adapter);\n\n\tiavf_up_complete(adapter);\n\n\tiavf_irq_enable(adapter, true);\n\n\tmutex_unlock(&adapter->crit_lock);\n\n\treturn 0;\n\nerr_req_irq:\n\tiavf_down(adapter);\n\tiavf_free_traffic_irqs(adapter);\nerr_setup_rx:\n\tiavf_free_all_rx_resources(adapter);\nerr_setup_tx:\n\tiavf_free_all_tx_resources(adapter);\nerr_unlock:\n\tmutex_unlock(&adapter->crit_lock);\n\n\treturn err;\n}\n\n \nstatic int iavf_close(struct net_device *netdev)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tu64 aq_to_restore;\n\tint status;\n\n\tmutex_lock(&adapter->crit_lock);\n\n\tif (adapter->state <= __IAVF_DOWN_PENDING) {\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\treturn 0;\n\t}\n\n\tset_bit(__IAVF_VSI_DOWN, adapter->vsi.state);\n\tif (CLIENT_ENABLED(adapter))\n\t\tadapter->flags |= IAVF_FLAG_CLIENT_NEEDS_CLOSE;\n\t \n\taq_to_restore = adapter->aq_required;\n\tadapter->aq_required &= IAVF_FLAG_AQ_GET_CONFIG;\n\n\t \n\taq_to_restore &= ~(IAVF_FLAG_AQ_GET_CONFIG\t\t|\n\t\t\t   IAVF_FLAG_AQ_ENABLE_QUEUES\t\t|\n\t\t\t   IAVF_FLAG_AQ_CONFIGURE_QUEUES\t|\n\t\t\t   IAVF_FLAG_AQ_ADD_VLAN_FILTER\t\t|\n\t\t\t   IAVF_FLAG_AQ_ADD_MAC_FILTER\t\t|\n\t\t\t   IAVF_FLAG_AQ_ADD_CLOUD_FILTER\t|\n\t\t\t   IAVF_FLAG_AQ_ADD_FDIR_FILTER\t\t|\n\t\t\t   IAVF_FLAG_AQ_ADD_ADV_RSS_CFG);\n\n\tiavf_down(adapter);\n\tiavf_change_state(adapter, __IAVF_DOWN_PENDING);\n\tiavf_free_traffic_irqs(adapter);\n\n\tmutex_unlock(&adapter->crit_lock);\n\n\t \n\n\tstatus = wait_event_timeout(adapter->down_waitqueue,\n\t\t\t\t    adapter->state == __IAVF_DOWN,\n\t\t\t\t    msecs_to_jiffies(500));\n\tif (!status)\n\t\tnetdev_warn(netdev, \"Device resources not yet released\\n\");\n\n\tmutex_lock(&adapter->crit_lock);\n\tadapter->aq_required |= aq_to_restore;\n\tmutex_unlock(&adapter->crit_lock);\n\treturn 0;\n}\n\n \nstatic int iavf_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tint ret = 0;\n\n\tnetdev_dbg(netdev, \"changing MTU from %d to %d\\n\",\n\t\t   netdev->mtu, new_mtu);\n\tnetdev->mtu = new_mtu;\n\tif (CLIENT_ENABLED(adapter)) {\n\t\tiavf_notify_client_l2_params(&adapter->vsi);\n\t\tadapter->flags |= IAVF_FLAG_SERVICE_CLIENT_REQUESTED;\n\t}\n\n\tif (netif_running(netdev)) {\n\t\tiavf_schedule_reset(adapter, IAVF_FLAG_RESET_NEEDED);\n\t\tret = iavf_wait_for_reset(adapter);\n\t\tif (ret < 0)\n\t\t\tnetdev_warn(netdev, \"MTU change interrupted waiting for reset\");\n\t\telse if (ret)\n\t\t\tnetdev_warn(netdev, \"MTU change timed out waiting for reset\");\n\t}\n\n\treturn ret;\n}\n\n \nstatic void iavf_disable_fdir(struct iavf_adapter *adapter)\n{\n\tstruct iavf_fdir_fltr *fdir, *fdirtmp;\n\tbool del_filters = false;\n\n\tadapter->flags &= ~IAVF_FLAG_FDIR_ENABLED;\n\n\t \n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\tlist_for_each_entry_safe(fdir, fdirtmp, &adapter->fdir_list_head,\n\t\t\t\t list) {\n\t\tif (fdir->state == IAVF_FDIR_FLTR_ADD_REQUEST ||\n\t\t    fdir->state == IAVF_FDIR_FLTR_INACTIVE) {\n\t\t\t \n\t\t\tlist_del(&fdir->list);\n\t\t\tkfree(fdir);\n\t\t\tadapter->fdir_active_fltr--;\n\t\t} else if (fdir->state == IAVF_FDIR_FLTR_ADD_PENDING ||\n\t\t\t   fdir->state == IAVF_FDIR_FLTR_DIS_REQUEST ||\n\t\t\t   fdir->state == IAVF_FDIR_FLTR_ACTIVE) {\n\t\t\t \n\t\t\tfdir->state = IAVF_FDIR_FLTR_DEL_REQUEST;\n\t\t\tdel_filters = true;\n\t\t} else if (fdir->state == IAVF_FDIR_FLTR_DIS_PENDING) {\n\t\t\t \n\t\t\tfdir->state = IAVF_FDIR_FLTR_DEL_PENDING;\n\t\t}\n\t}\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\n\tif (del_filters) {\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_FDIR_FILTER;\n\t\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n\t}\n}\n\n#define NETIF_VLAN_OFFLOAD_FEATURES\t(NETIF_F_HW_VLAN_CTAG_RX | \\\n\t\t\t\t\t NETIF_F_HW_VLAN_CTAG_TX | \\\n\t\t\t\t\t NETIF_F_HW_VLAN_STAG_RX | \\\n\t\t\t\t\t NETIF_F_HW_VLAN_STAG_TX)\n\n \nstatic int iavf_set_features(struct net_device *netdev,\n\t\t\t     netdev_features_t features)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tif ((netdev->features & NETIF_VLAN_OFFLOAD_FEATURES) ^\n\t    (features & NETIF_VLAN_OFFLOAD_FEATURES))\n\t\tiavf_set_vlan_offload_features(adapter, netdev->features,\n\t\t\t\t\t       features);\n\n\tif ((netdev->features & NETIF_F_NTUPLE) ^ (features & NETIF_F_NTUPLE)) {\n\t\tif (features & NETIF_F_NTUPLE)\n\t\t\tadapter->flags |= IAVF_FLAG_FDIR_ENABLED;\n\t\telse\n\t\t\tiavf_disable_fdir(adapter);\n\t}\n\n\treturn 0;\n}\n\n \nstatic netdev_features_t iavf_features_check(struct sk_buff *skb,\n\t\t\t\t\t     struct net_device *dev,\n\t\t\t\t\t     netdev_features_t features)\n{\n\tsize_t len;\n\n\t \n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn features;\n\n\t \n\tif (skb_is_gso(skb) && (skb_shinfo(skb)->gso_size < 64))\n\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\n\t \n\tlen = skb_network_header(skb) - skb->data;\n\tif (len & ~(63 * 2))\n\t\tgoto out_err;\n\n\t \n\tlen = skb_transport_header(skb) - skb_network_header(skb);\n\tif (len & ~(127 * 4))\n\t\tgoto out_err;\n\n\tif (skb->encapsulation) {\n\t\t \n\t\tlen = skb_inner_network_header(skb) - skb_transport_header(skb);\n\t\tif (len & ~(127 * 2))\n\t\t\tgoto out_err;\n\n\t\t \n\t\tlen = skb_inner_transport_header(skb) -\n\t\t      skb_inner_network_header(skb);\n\t\tif (len & ~(127 * 4))\n\t\t\tgoto out_err;\n\t}\n\n\t \n\n\treturn features;\nout_err:\n\treturn features & ~(NETIF_F_CSUM_MASK | NETIF_F_GSO_MASK);\n}\n\n \nstatic netdev_features_t\niavf_get_netdev_vlan_hw_features(struct iavf_adapter *adapter)\n{\n\tnetdev_features_t hw_features = 0;\n\n\tif (!adapter->vf_res || !adapter->vf_res->vf_cap_flags)\n\t\treturn hw_features;\n\n\t \n\tif (VLAN_ALLOWED(adapter)) {\n\t\thw_features |= (NETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\tNETIF_F_HW_VLAN_CTAG_RX);\n\t} else if (VLAN_V2_ALLOWED(adapter)) {\n\t\tstruct virtchnl_vlan_caps *vlan_v2_caps =\n\t\t\t&adapter->vlan_v2_caps;\n\t\tstruct virtchnl_vlan_supported_caps *stripping_support =\n\t\t\t&vlan_v2_caps->offloads.stripping_support;\n\t\tstruct virtchnl_vlan_supported_caps *insertion_support =\n\t\t\t&vlan_v2_caps->offloads.insertion_support;\n\n\t\tif (stripping_support->outer != VIRTCHNL_VLAN_UNSUPPORTED &&\n\t\t    stripping_support->outer & VIRTCHNL_VLAN_TOGGLE) {\n\t\t\tif (stripping_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\thw_features |= NETIF_F_HW_VLAN_CTAG_RX;\n\t\t\tif (stripping_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_88A8)\n\t\t\t\thw_features |= NETIF_F_HW_VLAN_STAG_RX;\n\t\t} else if (stripping_support->inner !=\n\t\t\t   VIRTCHNL_VLAN_UNSUPPORTED &&\n\t\t\t   stripping_support->inner & VIRTCHNL_VLAN_TOGGLE) {\n\t\t\tif (stripping_support->inner &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\thw_features |= NETIF_F_HW_VLAN_CTAG_RX;\n\t\t}\n\n\t\tif (insertion_support->outer != VIRTCHNL_VLAN_UNSUPPORTED &&\n\t\t    insertion_support->outer & VIRTCHNL_VLAN_TOGGLE) {\n\t\t\tif (insertion_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\thw_features |= NETIF_F_HW_VLAN_CTAG_TX;\n\t\t\tif (insertion_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_88A8)\n\t\t\t\thw_features |= NETIF_F_HW_VLAN_STAG_TX;\n\t\t} else if (insertion_support->inner &&\n\t\t\t   insertion_support->inner & VIRTCHNL_VLAN_TOGGLE) {\n\t\t\tif (insertion_support->inner &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\thw_features |= NETIF_F_HW_VLAN_CTAG_TX;\n\t\t}\n\t}\n\n\treturn hw_features;\n}\n\n \nstatic netdev_features_t\niavf_get_netdev_vlan_features(struct iavf_adapter *adapter)\n{\n\tnetdev_features_t features = 0;\n\n\tif (!adapter->vf_res || !adapter->vf_res->vf_cap_flags)\n\t\treturn features;\n\n\tif (VLAN_ALLOWED(adapter)) {\n\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_FILTER |\n\t\t\tNETIF_F_HW_VLAN_CTAG_RX | NETIF_F_HW_VLAN_CTAG_TX;\n\t} else if (VLAN_V2_ALLOWED(adapter)) {\n\t\tstruct virtchnl_vlan_caps *vlan_v2_caps =\n\t\t\t&adapter->vlan_v2_caps;\n\t\tstruct virtchnl_vlan_supported_caps *filtering_support =\n\t\t\t&vlan_v2_caps->filtering.filtering_support;\n\t\tstruct virtchnl_vlan_supported_caps *stripping_support =\n\t\t\t&vlan_v2_caps->offloads.stripping_support;\n\t\tstruct virtchnl_vlan_supported_caps *insertion_support =\n\t\t\t&vlan_v2_caps->offloads.insertion_support;\n\t\tu32 ethertype_init;\n\n\t\t \n\t\tethertype_init = vlan_v2_caps->offloads.ethertype_init;\n\t\tif (stripping_support->outer != VIRTCHNL_VLAN_UNSUPPORTED) {\n\t\t\tif (stripping_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_RX;\n\t\t\telse if (stripping_support->outer &\n\t\t\t\t VIRTCHNL_VLAN_ETHERTYPE_88A8 &&\n\t\t\t\t ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_88A8)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_STAG_RX;\n\t\t} else if (stripping_support->inner !=\n\t\t\t   VIRTCHNL_VLAN_UNSUPPORTED) {\n\t\t\tif (stripping_support->inner &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_RX;\n\t\t}\n\n\t\t \n\t\tif (insertion_support->outer != VIRTCHNL_VLAN_UNSUPPORTED) {\n\t\t\tif (insertion_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_TX;\n\t\t\telse if (insertion_support->outer &\n\t\t\t\t VIRTCHNL_VLAN_ETHERTYPE_88A8 &&\n\t\t\t\t ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_88A8)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_STAG_TX;\n\t\t} else if (insertion_support->inner !=\n\t\t\t   VIRTCHNL_VLAN_UNSUPPORTED) {\n\t\t\tif (insertion_support->inner &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_TX;\n\t\t}\n\n\t\t \n\t\tethertype_init = vlan_v2_caps->filtering.ethertype_init;\n\t\tif (filtering_support->outer != VIRTCHNL_VLAN_UNSUPPORTED) {\n\t\t\tif (filtering_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\t\t\tif (filtering_support->outer &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_88A8 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_88A8)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_STAG_FILTER;\n\t\t} else if (filtering_support->inner !=\n\t\t\t   VIRTCHNL_VLAN_UNSUPPORTED) {\n\t\t\tif (filtering_support->inner &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_8100 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_8100)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\t\t\tif (filtering_support->inner &\n\t\t\t    VIRTCHNL_VLAN_ETHERTYPE_88A8 &&\n\t\t\t    ethertype_init & VIRTCHNL_VLAN_ETHERTYPE_88A8)\n\t\t\t\tfeatures |= NETIF_F_HW_VLAN_STAG_FILTER;\n\t\t}\n\t}\n\n\treturn features;\n}\n\n#define IAVF_NETDEV_VLAN_FEATURE_ALLOWED(requested, allowed, feature_bit) \\\n\t(!(((requested) & (feature_bit)) && \\\n\t   !((allowed) & (feature_bit))))\n\n \nstatic netdev_features_t\niavf_fix_netdev_vlan_features(struct iavf_adapter *adapter,\n\t\t\t      netdev_features_t requested_features)\n{\n\tnetdev_features_t allowed_features;\n\n\tallowed_features = iavf_get_netdev_vlan_hw_features(adapter) |\n\t\tiavf_get_netdev_vlan_features(adapter);\n\n\tif (!IAVF_NETDEV_VLAN_FEATURE_ALLOWED(requested_features,\n\t\t\t\t\t      allowed_features,\n\t\t\t\t\t      NETIF_F_HW_VLAN_CTAG_TX))\n\t\trequested_features &= ~NETIF_F_HW_VLAN_CTAG_TX;\n\n\tif (!IAVF_NETDEV_VLAN_FEATURE_ALLOWED(requested_features,\n\t\t\t\t\t      allowed_features,\n\t\t\t\t\t      NETIF_F_HW_VLAN_CTAG_RX))\n\t\trequested_features &= ~NETIF_F_HW_VLAN_CTAG_RX;\n\n\tif (!IAVF_NETDEV_VLAN_FEATURE_ALLOWED(requested_features,\n\t\t\t\t\t      allowed_features,\n\t\t\t\t\t      NETIF_F_HW_VLAN_STAG_TX))\n\t\trequested_features &= ~NETIF_F_HW_VLAN_STAG_TX;\n\tif (!IAVF_NETDEV_VLAN_FEATURE_ALLOWED(requested_features,\n\t\t\t\t\t      allowed_features,\n\t\t\t\t\t      NETIF_F_HW_VLAN_STAG_RX))\n\t\trequested_features &= ~NETIF_F_HW_VLAN_STAG_RX;\n\n\tif (!IAVF_NETDEV_VLAN_FEATURE_ALLOWED(requested_features,\n\t\t\t\t\t      allowed_features,\n\t\t\t\t\t      NETIF_F_HW_VLAN_CTAG_FILTER))\n\t\trequested_features &= ~NETIF_F_HW_VLAN_CTAG_FILTER;\n\n\tif (!IAVF_NETDEV_VLAN_FEATURE_ALLOWED(requested_features,\n\t\t\t\t\t      allowed_features,\n\t\t\t\t\t      NETIF_F_HW_VLAN_STAG_FILTER))\n\t\trequested_features &= ~NETIF_F_HW_VLAN_STAG_FILTER;\n\n\tif ((requested_features &\n\t     (NETIF_F_HW_VLAN_CTAG_RX | NETIF_F_HW_VLAN_CTAG_TX)) &&\n\t    (requested_features &\n\t     (NETIF_F_HW_VLAN_STAG_RX | NETIF_F_HW_VLAN_STAG_TX)) &&\n\t    adapter->vlan_v2_caps.offloads.ethertype_match ==\n\t    VIRTCHNL_ETHERTYPE_STRIPPING_MATCHES_INSERTION) {\n\t\tnetdev_warn(adapter->netdev, \"cannot support CTAG and STAG VLAN stripping and/or insertion simultaneously since CTAG and STAG offloads are mutually exclusive, clearing STAG offload settings\\n\");\n\t\trequested_features &= ~(NETIF_F_HW_VLAN_STAG_RX |\n\t\t\t\t\tNETIF_F_HW_VLAN_STAG_TX);\n\t}\n\n\treturn requested_features;\n}\n\n \nstatic netdev_features_t iavf_fix_features(struct net_device *netdev,\n\t\t\t\t\t   netdev_features_t features)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tif (!FDIR_FLTR_SUPPORT(adapter))\n\t\tfeatures &= ~NETIF_F_NTUPLE;\n\n\treturn iavf_fix_netdev_vlan_features(adapter, features);\n}\n\nstatic const struct net_device_ops iavf_netdev_ops = {\n\t.ndo_open\t\t= iavf_open,\n\t.ndo_stop\t\t= iavf_close,\n\t.ndo_start_xmit\t\t= iavf_xmit_frame,\n\t.ndo_set_rx_mode\t= iavf_set_rx_mode,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= iavf_set_mac,\n\t.ndo_change_mtu\t\t= iavf_change_mtu,\n\t.ndo_tx_timeout\t\t= iavf_tx_timeout,\n\t.ndo_vlan_rx_add_vid\t= iavf_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= iavf_vlan_rx_kill_vid,\n\t.ndo_features_check\t= iavf_features_check,\n\t.ndo_fix_features\t= iavf_fix_features,\n\t.ndo_set_features\t= iavf_set_features,\n\t.ndo_setup_tc\t\t= iavf_setup_tc,\n};\n\n \nstatic int iavf_check_reset_complete(struct iavf_hw *hw)\n{\n\tu32 rstat;\n\tint i;\n\n\tfor (i = 0; i < IAVF_RESET_WAIT_COMPLETE_COUNT; i++) {\n\t\trstat = rd32(hw, IAVF_VFGEN_RSTAT) &\n\t\t\t     IAVF_VFGEN_RSTAT_VFR_STATE_MASK;\n\t\tif ((rstat == VIRTCHNL_VFR_VFACTIVE) ||\n\t\t    (rstat == VIRTCHNL_VFR_COMPLETED))\n\t\t\treturn 0;\n\t\tusleep_range(10, 20);\n\t}\n\treturn -EBUSY;\n}\n\n \nint iavf_process_config(struct iavf_adapter *adapter)\n{\n\tstruct virtchnl_vf_resource *vfres = adapter->vf_res;\n\tnetdev_features_t hw_vlan_features, vlan_features;\n\tstruct net_device *netdev = adapter->netdev;\n\tnetdev_features_t hw_enc_features;\n\tnetdev_features_t hw_features;\n\n\thw_enc_features = NETIF_F_SG\t\t\t|\n\t\t\t  NETIF_F_IP_CSUM\t\t|\n\t\t\t  NETIF_F_IPV6_CSUM\t\t|\n\t\t\t  NETIF_F_HIGHDMA\t\t|\n\t\t\t  NETIF_F_SOFT_FEATURES\t|\n\t\t\t  NETIF_F_TSO\t\t\t|\n\t\t\t  NETIF_F_TSO_ECN\t\t|\n\t\t\t  NETIF_F_TSO6\t\t\t|\n\t\t\t  NETIF_F_SCTP_CRC\t\t|\n\t\t\t  NETIF_F_RXHASH\t\t|\n\t\t\t  NETIF_F_RXCSUM\t\t|\n\t\t\t  0;\n\n\t \n\tif (vfres->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_ENCAP) {\n\t\thw_enc_features |= NETIF_F_GSO_UDP_TUNNEL\t|\n\t\t\t\t   NETIF_F_GSO_GRE\t\t|\n\t\t\t\t   NETIF_F_GSO_GRE_CSUM\t\t|\n\t\t\t\t   NETIF_F_GSO_IPXIP4\t\t|\n\t\t\t\t   NETIF_F_GSO_IPXIP6\t\t|\n\t\t\t\t   NETIF_F_GSO_UDP_TUNNEL_CSUM\t|\n\t\t\t\t   NETIF_F_GSO_PARTIAL\t\t|\n\t\t\t\t   0;\n\n\t\tif (!(vfres->vf_cap_flags &\n\t\t      VIRTCHNL_VF_OFFLOAD_ENCAP_CSUM))\n\t\t\tnetdev->gso_partial_features |=\n\t\t\t\tNETIF_F_GSO_UDP_TUNNEL_CSUM;\n\n\t\tnetdev->gso_partial_features |= NETIF_F_GSO_GRE_CSUM;\n\t\tnetdev->hw_enc_features |= NETIF_F_TSO_MANGLEID;\n\t\tnetdev->hw_enc_features |= hw_enc_features;\n\t}\n\t \n\tnetdev->vlan_features |= hw_enc_features | NETIF_F_TSO_MANGLEID;\n\n\t \n\thw_features = hw_enc_features;\n\n\t \n\thw_vlan_features = iavf_get_netdev_vlan_hw_features(adapter);\n\n\t \n\tif (vfres->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_ADQ)\n\t\thw_features |= NETIF_F_HW_TC;\n\tif (vfres->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_USO)\n\t\thw_features |= NETIF_F_GSO_UDP_L4;\n\n\tnetdev->hw_features |= hw_features | hw_vlan_features;\n\tvlan_features = iavf_get_netdev_vlan_features(adapter);\n\n\tnetdev->features |= hw_features | vlan_features;\n\n\tif (vfres->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_VLAN)\n\t\tnetdev->features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\n\tif (FDIR_FLTR_SUPPORT(adapter)) {\n\t\tnetdev->hw_features |= NETIF_F_NTUPLE;\n\t\tnetdev->features |= NETIF_F_NTUPLE;\n\t\tadapter->flags |= IAVF_FLAG_FDIR_ENABLED;\n\t}\n\n\tnetdev->priv_flags |= IFF_UNICAST_FLT;\n\n\t \n\tif (netdev->wanted_features) {\n\t\tif (!(netdev->wanted_features & NETIF_F_TSO) ||\n\t\t    netdev->mtu < 576)\n\t\t\tnetdev->features &= ~NETIF_F_TSO;\n\t\tif (!(netdev->wanted_features & NETIF_F_TSO6) ||\n\t\t    netdev->mtu < 576)\n\t\t\tnetdev->features &= ~NETIF_F_TSO6;\n\t\tif (!(netdev->wanted_features & NETIF_F_TSO_ECN))\n\t\t\tnetdev->features &= ~NETIF_F_TSO_ECN;\n\t\tif (!(netdev->wanted_features & NETIF_F_GRO))\n\t\t\tnetdev->features &= ~NETIF_F_GRO;\n\t\tif (!(netdev->wanted_features & NETIF_F_GSO))\n\t\t\tnetdev->features &= ~NETIF_F_GSO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int iavf_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct net_device *netdev;\n\tstruct iavf_adapter *adapter = NULL;\n\tstruct iavf_hw *hw = NULL;\n\tint err;\n\n\terr = pci_enable_device(pdev);\n\tif (err)\n\t\treturn err;\n\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"DMA configuration failed: 0x%x\\n\", err);\n\t\tgoto err_dma;\n\t}\n\n\terr = pci_request_regions(pdev, iavf_driver_name);\n\tif (err) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"pci_request_regions failed 0x%x\\n\", err);\n\t\tgoto err_pci_reg;\n\t}\n\n\tpci_set_master(pdev);\n\n\tnetdev = alloc_etherdev_mq(sizeof(struct iavf_adapter),\n\t\t\t\t   IAVF_MAX_REQ_QUEUES);\n\tif (!netdev) {\n\t\terr = -ENOMEM;\n\t\tgoto err_alloc_etherdev;\n\t}\n\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\n\tpci_set_drvdata(pdev, netdev);\n\tadapter = netdev_priv(netdev);\n\n\tadapter->netdev = netdev;\n\tadapter->pdev = pdev;\n\n\thw = &adapter->hw;\n\thw->back = adapter;\n\n\tadapter->wq = alloc_ordered_workqueue(\"%s\", WQ_MEM_RECLAIM,\n\t\t\t\t\t      iavf_driver_name);\n\tif (!adapter->wq) {\n\t\terr = -ENOMEM;\n\t\tgoto err_alloc_wq;\n\t}\n\n\tadapter->msg_enable = BIT(DEFAULT_DEBUG_LEVEL_SHIFT) - 1;\n\tiavf_change_state(adapter, __IAVF_STARTUP);\n\n\t \n\tpci_save_state(pdev);\n\n\thw->hw_addr = ioremap(pci_resource_start(pdev, 0),\n\t\t\t      pci_resource_len(pdev, 0));\n\tif (!hw->hw_addr) {\n\t\terr = -EIO;\n\t\tgoto err_ioremap;\n\t}\n\thw->vendor_id = pdev->vendor;\n\thw->device_id = pdev->device;\n\tpci_read_config_byte(pdev, PCI_REVISION_ID, &hw->revision_id);\n\thw->subsystem_vendor_id = pdev->subsystem_vendor;\n\thw->subsystem_device_id = pdev->subsystem_device;\n\thw->bus.device = PCI_SLOT(pdev->devfn);\n\thw->bus.func = PCI_FUNC(pdev->devfn);\n\thw->bus.bus_id = pdev->bus->number;\n\n\t \n\tmutex_init(&adapter->crit_lock);\n\tmutex_init(&adapter->client_lock);\n\tmutex_init(&hw->aq.asq_mutex);\n\tmutex_init(&hw->aq.arq_mutex);\n\n\tspin_lock_init(&adapter->mac_vlan_list_lock);\n\tspin_lock_init(&adapter->cloud_filter_list_lock);\n\tspin_lock_init(&adapter->fdir_fltr_lock);\n\tspin_lock_init(&adapter->adv_rss_lock);\n\tspin_lock_init(&adapter->current_netdev_promisc_flags_lock);\n\n\tINIT_LIST_HEAD(&adapter->mac_filter_list);\n\tINIT_LIST_HEAD(&adapter->vlan_filter_list);\n\tINIT_LIST_HEAD(&adapter->cloud_filter_list);\n\tINIT_LIST_HEAD(&adapter->fdir_list_head);\n\tINIT_LIST_HEAD(&adapter->adv_rss_list_head);\n\n\tINIT_WORK(&adapter->reset_task, iavf_reset_task);\n\tINIT_WORK(&adapter->adminq_task, iavf_adminq_task);\n\tINIT_WORK(&adapter->finish_config, iavf_finish_config);\n\tINIT_DELAYED_WORK(&adapter->watchdog_task, iavf_watchdog_task);\n\tINIT_DELAYED_WORK(&adapter->client_task, iavf_client_task);\n\n\t \n\tinit_waitqueue_head(&adapter->down_waitqueue);\n\n\t \n\tinit_waitqueue_head(&adapter->reset_waitqueue);\n\n\t \n\tinit_waitqueue_head(&adapter->vc_waitqueue);\n\n\tqueue_delayed_work(adapter->wq, &adapter->watchdog_task,\n\t\t\t   msecs_to_jiffies(5 * (pdev->devfn & 0x07)));\n\t \n\treturn 0;\n\nerr_ioremap:\n\tdestroy_workqueue(adapter->wq);\nerr_alloc_wq:\n\tfree_netdev(netdev);\nerr_alloc_etherdev:\n\tpci_release_regions(pdev);\nerr_pci_reg:\nerr_dma:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n \nstatic int __maybe_unused iavf_suspend(struct device *dev_d)\n{\n\tstruct net_device *netdev = dev_get_drvdata(dev_d);\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tnetif_device_detach(netdev);\n\n\twhile (!mutex_trylock(&adapter->crit_lock))\n\t\tusleep_range(500, 1000);\n\n\tif (netif_running(netdev)) {\n\t\trtnl_lock();\n\t\tiavf_down(adapter);\n\t\trtnl_unlock();\n\t}\n\tiavf_free_misc_irq(adapter);\n\tiavf_reset_interrupt_capability(adapter);\n\n\tmutex_unlock(&adapter->crit_lock);\n\n\treturn 0;\n}\n\n \nstatic int __maybe_unused iavf_resume(struct device *dev_d)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev_d);\n\tstruct iavf_adapter *adapter;\n\tu32 err;\n\n\tadapter = iavf_pdev_to_adapter(pdev);\n\n\tpci_set_master(pdev);\n\n\trtnl_lock();\n\terr = iavf_set_interrupt_capability(adapter);\n\tif (err) {\n\t\trtnl_unlock();\n\t\tdev_err(&pdev->dev, \"Cannot enable MSI-X interrupts.\\n\");\n\t\treturn err;\n\t}\n\terr = iavf_request_misc_irq(adapter);\n\trtnl_unlock();\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Cannot get interrupt vector.\\n\");\n\t\treturn err;\n\t}\n\n\tqueue_work(adapter->wq, &adapter->reset_task);\n\n\tnetif_device_attach(adapter->netdev);\n\n\treturn err;\n}\n\n \nstatic void iavf_remove(struct pci_dev *pdev)\n{\n\tstruct iavf_fdir_fltr *fdir, *fdirtmp;\n\tstruct iavf_vlan_filter *vlf, *vlftmp;\n\tstruct iavf_cloud_filter *cf, *cftmp;\n\tstruct iavf_adv_rss *rss, *rsstmp;\n\tstruct iavf_mac_filter *f, *ftmp;\n\tstruct iavf_adapter *adapter;\n\tstruct net_device *netdev;\n\tstruct iavf_hw *hw;\n\tint err;\n\n\t \n\tnetdev = pci_get_drvdata(pdev);\n\tif (!netdev)\n\t\treturn;\n\n\tadapter = iavf_pdev_to_adapter(pdev);\n\thw = &adapter->hw;\n\n\tif (test_and_set_bit(__IAVF_IN_REMOVE_TASK, &adapter->crit_section))\n\t\treturn;\n\n\t \n\twhile (1) {\n\t\tmutex_lock(&adapter->crit_lock);\n\t\tif (adapter->state == __IAVF_RUNNING ||\n\t\t    adapter->state == __IAVF_DOWN ||\n\t\t    adapter->state == __IAVF_INIT_FAILED) {\n\t\t\tmutex_unlock(&adapter->crit_lock);\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif (adapter->state == __IAVF_REMOVE) {\n\t\t\tmutex_unlock(&adapter->crit_lock);\n\t\t\treturn;\n\t\t}\n\n\t\tmutex_unlock(&adapter->crit_lock);\n\t\tusleep_range(500, 1000);\n\t}\n\tcancel_delayed_work_sync(&adapter->watchdog_task);\n\tcancel_work_sync(&adapter->finish_config);\n\n\trtnl_lock();\n\tif (adapter->netdev_registered) {\n\t\tunregister_netdevice(netdev);\n\t\tadapter->netdev_registered = false;\n\t}\n\trtnl_unlock();\n\n\tif (CLIENT_ALLOWED(adapter)) {\n\t\terr = iavf_lan_del_device(adapter);\n\t\tif (err)\n\t\t\tdev_warn(&pdev->dev, \"Failed to delete client device: %d\\n\",\n\t\t\t\t err);\n\t}\n\n\tmutex_lock(&adapter->crit_lock);\n\tdev_info(&adapter->pdev->dev, \"Removing device\\n\");\n\tiavf_change_state(adapter, __IAVF_REMOVE);\n\n\tiavf_request_reset(adapter);\n\tmsleep(50);\n\t \n\tif (!iavf_asq_done(hw)) {\n\t\tiavf_request_reset(adapter);\n\t\tmsleep(50);\n\t}\n\n\tiavf_misc_irq_disable(adapter);\n\t \n\tcancel_work_sync(&adapter->reset_task);\n\tcancel_delayed_work_sync(&adapter->watchdog_task);\n\tcancel_work_sync(&adapter->adminq_task);\n\tcancel_delayed_work_sync(&adapter->client_task);\n\n\tadapter->aq_required = 0;\n\tadapter->flags &= ~IAVF_FLAG_REINIT_ITR_NEEDED;\n\n\tiavf_free_all_tx_resources(adapter);\n\tiavf_free_all_rx_resources(adapter);\n\tiavf_free_misc_irq(adapter);\n\n\tiavf_reset_interrupt_capability(adapter);\n\tiavf_free_q_vectors(adapter);\n\n\tiavf_free_rss(adapter);\n\n\tif (hw->aq.asq.count)\n\t\tiavf_shutdown_adminq(hw);\n\n\t \n\tmutex_destroy(&hw->aq.arq_mutex);\n\tmutex_destroy(&hw->aq.asq_mutex);\n\tmutex_destroy(&adapter->client_lock);\n\tmutex_unlock(&adapter->crit_lock);\n\tmutex_destroy(&adapter->crit_lock);\n\n\tiounmap(hw->hw_addr);\n\tpci_release_regions(pdev);\n\tiavf_free_queues(adapter);\n\tkfree(adapter->vf_res);\n\tspin_lock_bh(&adapter->mac_vlan_list_lock);\n\t \n\tlist_for_each_entry_safe(f, ftmp, &adapter->mac_filter_list, list) {\n\t\tlist_del(&f->list);\n\t\tkfree(f);\n\t}\n\tlist_for_each_entry_safe(vlf, vlftmp, &adapter->vlan_filter_list,\n\t\t\t\t list) {\n\t\tlist_del(&vlf->list);\n\t\tkfree(vlf);\n\t}\n\n\tspin_unlock_bh(&adapter->mac_vlan_list_lock);\n\n\tspin_lock_bh(&adapter->cloud_filter_list_lock);\n\tlist_for_each_entry_safe(cf, cftmp, &adapter->cloud_filter_list, list) {\n\t\tlist_del(&cf->list);\n\t\tkfree(cf);\n\t}\n\tspin_unlock_bh(&adapter->cloud_filter_list_lock);\n\n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\tlist_for_each_entry_safe(fdir, fdirtmp, &adapter->fdir_list_head, list) {\n\t\tlist_del(&fdir->list);\n\t\tkfree(fdir);\n\t}\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\n\tspin_lock_bh(&adapter->adv_rss_lock);\n\tlist_for_each_entry_safe(rss, rsstmp, &adapter->adv_rss_list_head,\n\t\t\t\t list) {\n\t\tlist_del(&rss->list);\n\t\tkfree(rss);\n\t}\n\tspin_unlock_bh(&adapter->adv_rss_lock);\n\n\tdestroy_workqueue(adapter->wq);\n\n\tpci_set_drvdata(pdev, NULL);\n\n\tfree_netdev(netdev);\n\n\tpci_disable_device(pdev);\n}\n\n \nstatic void iavf_shutdown(struct pci_dev *pdev)\n{\n\tiavf_remove(pdev);\n\n\tif (system_state == SYSTEM_POWER_OFF)\n\t\tpci_set_power_state(pdev, PCI_D3hot);\n}\n\nstatic SIMPLE_DEV_PM_OPS(iavf_pm_ops, iavf_suspend, iavf_resume);\n\nstatic struct pci_driver iavf_driver = {\n\t.name      = iavf_driver_name,\n\t.id_table  = iavf_pci_tbl,\n\t.probe     = iavf_probe,\n\t.remove    = iavf_remove,\n\t.driver.pm = &iavf_pm_ops,\n\t.shutdown  = iavf_shutdown,\n};\n\n \nstatic int __init iavf_init_module(void)\n{\n\tpr_info(\"iavf: %s\\n\", iavf_driver_string);\n\n\tpr_info(\"%s\\n\", iavf_copyright);\n\n\treturn pci_register_driver(&iavf_driver);\n}\n\nmodule_init(iavf_init_module);\n\n \nstatic void __exit iavf_exit_module(void)\n{\n\tpci_unregister_driver(&iavf_driver);\n}\n\nmodule_exit(iavf_exit_module);\n\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}