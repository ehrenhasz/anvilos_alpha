{
  "module_name": "iavf_ethtool.c",
  "hash_id": "80151d26a4771ce7ebf7b9b7e538c895747391a83428faa13c7fff766d533263",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/iavf/iavf_ethtool.c",
  "human_readable_source": "\n \n\n \n#include \"iavf.h\"\n\n#include <linux/uaccess.h>\n\n \n\n \nstruct iavf_stats {\n\tchar stat_string[ETH_GSTRING_LEN];\n\tint sizeof_stat;\n\tint stat_offset;\n};\n\n \n#define IAVF_STAT(_type, _name, _stat) { \\\n\t.stat_string = _name, \\\n\t.sizeof_stat = sizeof_field(_type, _stat), \\\n\t.stat_offset = offsetof(_type, _stat) \\\n}\n\n \n#define IAVF_QUEUE_STAT(_name, _stat) \\\n\tIAVF_STAT(struct iavf_ring, _name, _stat)\n\n \nstatic const struct iavf_stats iavf_gstrings_queue_stats[] = {\n\tIAVF_QUEUE_STAT(\"%s-%u.packets\", stats.packets),\n\tIAVF_QUEUE_STAT(\"%s-%u.bytes\", stats.bytes),\n};\n\n \nstatic void\niavf_add_one_ethtool_stat(u64 *data, void *pointer,\n\t\t\t  const struct iavf_stats *stat)\n{\n\tchar *p;\n\n\tif (!pointer) {\n\t\t \n\t\t*data = 0;\n\t\treturn;\n\t}\n\n\tp = (char *)pointer + stat->stat_offset;\n\tswitch (stat->sizeof_stat) {\n\tcase sizeof(u64):\n\t\t*data = *((u64 *)p);\n\t\tbreak;\n\tcase sizeof(u32):\n\t\t*data = *((u32 *)p);\n\t\tbreak;\n\tcase sizeof(u16):\n\t\t*data = *((u16 *)p);\n\t\tbreak;\n\tcase sizeof(u8):\n\t\t*data = *((u8 *)p);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ONCE(1, \"unexpected stat size for %s\",\n\t\t\t  stat->stat_string);\n\t\t*data = 0;\n\t}\n}\n\n \nstatic void\n__iavf_add_ethtool_stats(u64 **data, void *pointer,\n\t\t\t const struct iavf_stats stats[],\n\t\t\t const unsigned int size)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < size; i++)\n\t\tiavf_add_one_ethtool_stat((*data)++, pointer, &stats[i]);\n}\n\n \n#define iavf_add_ethtool_stats(data, pointer, stats) \\\n\t__iavf_add_ethtool_stats(data, pointer, stats, ARRAY_SIZE(stats))\n\n \nstatic void\niavf_add_queue_stats(u64 **data, struct iavf_ring *ring)\n{\n\tconst unsigned int size = ARRAY_SIZE(iavf_gstrings_queue_stats);\n\tconst struct iavf_stats *stats = iavf_gstrings_queue_stats;\n\tunsigned int start;\n\tunsigned int i;\n\n\t \n\tdo {\n\t\tstart = !ring ? 0 : u64_stats_fetch_begin(&ring->syncp);\n\t\tfor (i = 0; i < size; i++)\n\t\t\tiavf_add_one_ethtool_stat(&(*data)[i], ring, &stats[i]);\n\t} while (ring && u64_stats_fetch_retry(&ring->syncp, start));\n\n\t \n\t*data += size;\n}\n\n \nstatic void __iavf_add_stat_strings(u8 **p, const struct iavf_stats stats[],\n\t\t\t\t    const unsigned int size, ...)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < size; i++) {\n\t\tva_list args;\n\n\t\tva_start(args, size);\n\t\tvsnprintf(*p, ETH_GSTRING_LEN, stats[i].stat_string, args);\n\t\t*p += ETH_GSTRING_LEN;\n\t\tva_end(args);\n\t}\n}\n\n \n#define iavf_add_stat_strings(p, stats, ...) \\\n\t__iavf_add_stat_strings(p, stats, ARRAY_SIZE(stats), ## __VA_ARGS__)\n\n#define VF_STAT(_name, _stat) \\\n\tIAVF_STAT(struct iavf_adapter, _name, _stat)\n\nstatic const struct iavf_stats iavf_gstrings_stats[] = {\n\tVF_STAT(\"rx_bytes\", current_stats.rx_bytes),\n\tVF_STAT(\"rx_unicast\", current_stats.rx_unicast),\n\tVF_STAT(\"rx_multicast\", current_stats.rx_multicast),\n\tVF_STAT(\"rx_broadcast\", current_stats.rx_broadcast),\n\tVF_STAT(\"rx_discards\", current_stats.rx_discards),\n\tVF_STAT(\"rx_unknown_protocol\", current_stats.rx_unknown_protocol),\n\tVF_STAT(\"tx_bytes\", current_stats.tx_bytes),\n\tVF_STAT(\"tx_unicast\", current_stats.tx_unicast),\n\tVF_STAT(\"tx_multicast\", current_stats.tx_multicast),\n\tVF_STAT(\"tx_broadcast\", current_stats.tx_broadcast),\n\tVF_STAT(\"tx_discards\", current_stats.tx_discards),\n\tVF_STAT(\"tx_errors\", current_stats.tx_errors),\n};\n\n#define IAVF_STATS_LEN\tARRAY_SIZE(iavf_gstrings_stats)\n\n#define IAVF_QUEUE_STATS_LEN\tARRAY_SIZE(iavf_gstrings_queue_stats)\n\n \nstruct iavf_priv_flags {\n\tchar flag_string[ETH_GSTRING_LEN];\n\tu32 flag;\n\tbool read_only;\n};\n\n#define IAVF_PRIV_FLAG(_name, _flag, _read_only) { \\\n\t.flag_string = _name, \\\n\t.flag = _flag, \\\n\t.read_only = _read_only, \\\n}\n\nstatic const struct iavf_priv_flags iavf_gstrings_priv_flags[] = {\n\tIAVF_PRIV_FLAG(\"legacy-rx\", IAVF_FLAG_LEGACY_RX, 0),\n};\n\n#define IAVF_PRIV_FLAGS_STR_LEN ARRAY_SIZE(iavf_gstrings_priv_flags)\n\n \nstatic int iavf_get_link_ksettings(struct net_device *netdev,\n\t\t\t\t   struct ethtool_link_ksettings *cmd)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tethtool_link_ksettings_zero_link_mode(cmd, supported);\n\tcmd->base.autoneg = AUTONEG_DISABLE;\n\tcmd->base.port = PORT_NONE;\n\tcmd->base.duplex = DUPLEX_FULL;\n\n\tif (ADV_LINK_SUPPORT(adapter)) {\n\t\tif (adapter->link_speed_mbps &&\n\t\t    adapter->link_speed_mbps < U32_MAX)\n\t\t\tcmd->base.speed = adapter->link_speed_mbps;\n\t\telse\n\t\t\tcmd->base.speed = SPEED_UNKNOWN;\n\n\t\treturn 0;\n\t}\n\n\tswitch (adapter->link_speed) {\n\tcase VIRTCHNL_LINK_SPEED_40GB:\n\t\tcmd->base.speed = SPEED_40000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_25GB:\n\t\tcmd->base.speed = SPEED_25000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_20GB:\n\t\tcmd->base.speed = SPEED_20000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_10GB:\n\t\tcmd->base.speed = SPEED_10000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_5GB:\n\t\tcmd->base.speed = SPEED_5000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_2_5GB:\n\t\tcmd->base.speed = SPEED_2500;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_1GB:\n\t\tcmd->base.speed = SPEED_1000;\n\t\tbreak;\n\tcase VIRTCHNL_LINK_SPEED_100MB:\n\t\tcmd->base.speed = SPEED_100;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int iavf_get_sset_count(struct net_device *netdev, int sset)\n{\n\t \n\n\tif (sset == ETH_SS_STATS)\n\t\treturn IAVF_STATS_LEN +\n\t\t\t(IAVF_QUEUE_STATS_LEN * 2 *\n\t\t\t netdev->real_num_tx_queues);\n\telse if (sset == ETH_SS_PRIV_FLAGS)\n\t\treturn IAVF_PRIV_FLAGS_STR_LEN;\n\telse\n\t\treturn -EINVAL;\n}\n\n \nstatic void iavf_get_ethtool_stats(struct net_device *netdev,\n\t\t\t\t   struct ethtool_stats *stats, u64 *data)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tunsigned int i;\n\n\t \n\tiavf_schedule_aq_request(adapter, IAVF_FLAG_AQ_REQUEST_STATS);\n\n\tiavf_add_ethtool_stats(&data, adapter, iavf_gstrings_stats);\n\n\trcu_read_lock();\n\t \n\tfor (i = 0; i < adapter->num_active_queues; i++) {\n\t\tstruct iavf_ring *ring;\n\n\t\t \n\t\tring = &adapter->tx_rings[i];\n\t\tiavf_add_queue_stats(&data, ring);\n\n\t\t \n\t\tring = &adapter->rx_rings[i];\n\t\tiavf_add_queue_stats(&data, ring);\n\t}\n\trcu_read_unlock();\n}\n\n \nstatic void iavf_get_priv_flag_strings(struct net_device *netdev, u8 *data)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < IAVF_PRIV_FLAGS_STR_LEN; i++) {\n\t\tsnprintf(data, ETH_GSTRING_LEN, \"%s\",\n\t\t\t iavf_gstrings_priv_flags[i].flag_string);\n\t\tdata += ETH_GSTRING_LEN;\n\t}\n}\n\n \nstatic void iavf_get_stat_strings(struct net_device *netdev, u8 *data)\n{\n\tunsigned int i;\n\n\tiavf_add_stat_strings(&data, iavf_gstrings_stats);\n\n\t \n\tfor (i = 0; i < netdev->real_num_tx_queues; i++) {\n\t\tiavf_add_stat_strings(&data, iavf_gstrings_queue_stats,\n\t\t\t\t      \"tx\", i);\n\t\tiavf_add_stat_strings(&data, iavf_gstrings_queue_stats,\n\t\t\t\t      \"rx\", i);\n\t}\n}\n\n \nstatic void iavf_get_strings(struct net_device *netdev, u32 sset, u8 *data)\n{\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\tiavf_get_stat_strings(netdev, data);\n\t\tbreak;\n\tcase ETH_SS_PRIV_FLAGS:\n\t\tiavf_get_priv_flag_strings(netdev, data);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nstatic u32 iavf_get_priv_flags(struct net_device *netdev)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tu32 i, ret_flags = 0;\n\n\tfor (i = 0; i < IAVF_PRIV_FLAGS_STR_LEN; i++) {\n\t\tconst struct iavf_priv_flags *priv_flags;\n\n\t\tpriv_flags = &iavf_gstrings_priv_flags[i];\n\n\t\tif (priv_flags->flag & adapter->flags)\n\t\t\tret_flags |= BIT(i);\n\t}\n\n\treturn ret_flags;\n}\n\n \nstatic int iavf_set_priv_flags(struct net_device *netdev, u32 flags)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tu32 orig_flags, new_flags, changed_flags;\n\tint ret = 0;\n\tu32 i;\n\n\torig_flags = READ_ONCE(adapter->flags);\n\tnew_flags = orig_flags;\n\n\tfor (i = 0; i < IAVF_PRIV_FLAGS_STR_LEN; i++) {\n\t\tconst struct iavf_priv_flags *priv_flags;\n\n\t\tpriv_flags = &iavf_gstrings_priv_flags[i];\n\n\t\tif (flags & BIT(i))\n\t\t\tnew_flags |= priv_flags->flag;\n\t\telse\n\t\t\tnew_flags &= ~(priv_flags->flag);\n\n\t\tif (priv_flags->read_only &&\n\t\t    ((orig_flags ^ new_flags) & ~BIT(i)))\n\t\t\treturn -EOPNOTSUPP;\n\t}\n\n\t \n\n\t \n\tif (cmpxchg(&adapter->flags, orig_flags, new_flags) != orig_flags) {\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"Unable to update adapter->flags as it was modified by another thread...\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\tchanged_flags = orig_flags ^ new_flags;\n\n\t \n\n\t \n\tif (changed_flags & IAVF_FLAG_LEGACY_RX) {\n\t\tif (netif_running(netdev)) {\n\t\t\tiavf_schedule_reset(adapter, IAVF_FLAG_RESET_NEEDED);\n\t\t\tret = iavf_wait_for_reset(adapter);\n\t\t\tif (ret)\n\t\t\t\tnetdev_warn(netdev, \"Changing private flags timeout or interrupted waiting for reset\");\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n \nstatic u32 iavf_get_msglevel(struct net_device *netdev)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\treturn adapter->msg_enable;\n}\n\n \nstatic void iavf_set_msglevel(struct net_device *netdev, u32 data)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tif (IAVF_DEBUG_USER & data)\n\t\tadapter->hw.debug_mask = data;\n\tadapter->msg_enable = data;\n}\n\n \nstatic void iavf_get_drvinfo(struct net_device *netdev,\n\t\t\t     struct ethtool_drvinfo *drvinfo)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tstrscpy(drvinfo->driver, iavf_driver_name, 32);\n\tstrscpy(drvinfo->fw_version, \"N/A\", 4);\n\tstrscpy(drvinfo->bus_info, pci_name(adapter->pdev), 32);\n\tdrvinfo->n_priv_flags = IAVF_PRIV_FLAGS_STR_LEN;\n}\n\n \nstatic void iavf_get_ringparam(struct net_device *netdev,\n\t\t\t       struct ethtool_ringparam *ring,\n\t\t\t       struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\tring->rx_max_pending = IAVF_MAX_RXD;\n\tring->tx_max_pending = IAVF_MAX_TXD;\n\tring->rx_pending = adapter->rx_desc_count;\n\tring->tx_pending = adapter->tx_desc_count;\n}\n\n \nstatic int iavf_set_ringparam(struct net_device *netdev,\n\t\t\t      struct ethtool_ringparam *ring,\n\t\t\t      struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tu32 new_rx_count, new_tx_count;\n\tint ret = 0;\n\n\tif ((ring->rx_mini_pending) || (ring->rx_jumbo_pending))\n\t\treturn -EINVAL;\n\n\tif (ring->tx_pending > IAVF_MAX_TXD ||\n\t    ring->tx_pending < IAVF_MIN_TXD ||\n\t    ring->rx_pending > IAVF_MAX_RXD ||\n\t    ring->rx_pending < IAVF_MIN_RXD) {\n\t\tnetdev_err(netdev, \"Descriptors requested (Tx: %d / Rx: %d) out of range [%d-%d] (increment %d)\\n\",\n\t\t\t   ring->tx_pending, ring->rx_pending, IAVF_MIN_TXD,\n\t\t\t   IAVF_MAX_RXD, IAVF_REQ_DESCRIPTOR_MULTIPLE);\n\t\treturn -EINVAL;\n\t}\n\n\tnew_tx_count = ALIGN(ring->tx_pending, IAVF_REQ_DESCRIPTOR_MULTIPLE);\n\tif (new_tx_count != ring->tx_pending)\n\t\tnetdev_info(netdev, \"Requested Tx descriptor count rounded up to %d\\n\",\n\t\t\t    new_tx_count);\n\n\tnew_rx_count = ALIGN(ring->rx_pending, IAVF_REQ_DESCRIPTOR_MULTIPLE);\n\tif (new_rx_count != ring->rx_pending)\n\t\tnetdev_info(netdev, \"Requested Rx descriptor count rounded up to %d\\n\",\n\t\t\t    new_rx_count);\n\n\t \n\tif ((new_tx_count == adapter->tx_desc_count) &&\n\t    (new_rx_count == adapter->rx_desc_count)) {\n\t\tnetdev_dbg(netdev, \"Nothing to change, descriptor count is same as requested\\n\");\n\t\treturn 0;\n\t}\n\n\tif (new_tx_count != adapter->tx_desc_count) {\n\t\tnetdev_dbg(netdev, \"Changing Tx descriptor count from %d to %d\\n\",\n\t\t\t   adapter->tx_desc_count, new_tx_count);\n\t\tadapter->tx_desc_count = new_tx_count;\n\t}\n\n\tif (new_rx_count != adapter->rx_desc_count) {\n\t\tnetdev_dbg(netdev, \"Changing Rx descriptor count from %d to %d\\n\",\n\t\t\t   adapter->rx_desc_count, new_rx_count);\n\t\tadapter->rx_desc_count = new_rx_count;\n\t}\n\n\tif (netif_running(netdev)) {\n\t\tiavf_schedule_reset(adapter, IAVF_FLAG_RESET_NEEDED);\n\t\tret = iavf_wait_for_reset(adapter);\n\t\tif (ret)\n\t\t\tnetdev_warn(netdev, \"Changing ring parameters timeout or interrupted waiting for reset\");\n\t}\n\n\treturn ret;\n}\n\n \nstatic int __iavf_get_coalesce(struct net_device *netdev,\n\t\t\t       struct ethtool_coalesce *ec, int queue)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tstruct iavf_ring *rx_ring, *tx_ring;\n\n\t \n\tif (queue < 0)\n\t\tqueue = 0;\n\telse if (queue >= adapter->num_active_queues)\n\t\treturn -EINVAL;\n\n\trx_ring = &adapter->rx_rings[queue];\n\ttx_ring = &adapter->tx_rings[queue];\n\n\tif (ITR_IS_DYNAMIC(rx_ring->itr_setting))\n\t\tec->use_adaptive_rx_coalesce = 1;\n\n\tif (ITR_IS_DYNAMIC(tx_ring->itr_setting))\n\t\tec->use_adaptive_tx_coalesce = 1;\n\n\tec->rx_coalesce_usecs = rx_ring->itr_setting & ~IAVF_ITR_DYNAMIC;\n\tec->tx_coalesce_usecs = tx_ring->itr_setting & ~IAVF_ITR_DYNAMIC;\n\n\treturn 0;\n}\n\n \nstatic int iavf_get_coalesce(struct net_device *netdev,\n\t\t\t     struct ethtool_coalesce *ec,\n\t\t\t     struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\treturn __iavf_get_coalesce(netdev, ec, -1);\n}\n\n \nstatic int iavf_get_per_queue_coalesce(struct net_device *netdev, u32 queue,\n\t\t\t\t       struct ethtool_coalesce *ec)\n{\n\treturn __iavf_get_coalesce(netdev, ec, queue);\n}\n\n \nstatic int iavf_set_itr_per_queue(struct iavf_adapter *adapter,\n\t\t\t\t  struct ethtool_coalesce *ec, int queue)\n{\n\tstruct iavf_ring *rx_ring = &adapter->rx_rings[queue];\n\tstruct iavf_ring *tx_ring = &adapter->tx_rings[queue];\n\tstruct iavf_q_vector *q_vector;\n\tu16 itr_setting;\n\n\titr_setting = rx_ring->itr_setting & ~IAVF_ITR_DYNAMIC;\n\n\tif (ec->rx_coalesce_usecs != itr_setting &&\n\t    ec->use_adaptive_rx_coalesce) {\n\t\tnetif_info(adapter, drv, adapter->netdev,\n\t\t\t   \"Rx interrupt throttling cannot be changed if adaptive-rx is enabled\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\titr_setting = tx_ring->itr_setting & ~IAVF_ITR_DYNAMIC;\n\n\tif (ec->tx_coalesce_usecs != itr_setting &&\n\t    ec->use_adaptive_tx_coalesce) {\n\t\tnetif_info(adapter, drv, adapter->netdev,\n\t\t\t   \"Tx interrupt throttling cannot be changed if adaptive-tx is enabled\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\trx_ring->itr_setting = ITR_REG_ALIGN(ec->rx_coalesce_usecs);\n\ttx_ring->itr_setting = ITR_REG_ALIGN(ec->tx_coalesce_usecs);\n\n\trx_ring->itr_setting |= IAVF_ITR_DYNAMIC;\n\tif (!ec->use_adaptive_rx_coalesce)\n\t\trx_ring->itr_setting ^= IAVF_ITR_DYNAMIC;\n\n\ttx_ring->itr_setting |= IAVF_ITR_DYNAMIC;\n\tif (!ec->use_adaptive_tx_coalesce)\n\t\ttx_ring->itr_setting ^= IAVF_ITR_DYNAMIC;\n\n\tq_vector = rx_ring->q_vector;\n\tq_vector->rx.target_itr = ITR_TO_REG(rx_ring->itr_setting);\n\n\tq_vector = tx_ring->q_vector;\n\tq_vector->tx.target_itr = ITR_TO_REG(tx_ring->itr_setting);\n\n\t \n\treturn 0;\n}\n\n \nstatic int __iavf_set_coalesce(struct net_device *netdev,\n\t\t\t       struct ethtool_coalesce *ec, int queue)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tint i;\n\n\tif (ec->rx_coalesce_usecs > IAVF_MAX_ITR) {\n\t\tnetif_info(adapter, drv, netdev, \"Invalid value, rx-usecs range is 0-8160\\n\");\n\t\treturn -EINVAL;\n\t} else if (ec->tx_coalesce_usecs > IAVF_MAX_ITR) {\n\t\tnetif_info(adapter, drv, netdev, \"Invalid value, tx-usecs range is 0-8160\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (queue < 0) {\n\t\tfor (i = 0; i < adapter->num_active_queues; i++)\n\t\t\tif (iavf_set_itr_per_queue(adapter, ec, i))\n\t\t\t\treturn -EINVAL;\n\t} else if (queue < adapter->num_active_queues) {\n\t\tif (iavf_set_itr_per_queue(adapter, ec, queue))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tnetif_info(adapter, drv, netdev, \"Invalid queue value, queue range is 0 - %d\\n\",\n\t\t\t   adapter->num_active_queues - 1);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int iavf_set_coalesce(struct net_device *netdev,\n\t\t\t     struct ethtool_coalesce *ec,\n\t\t\t     struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\treturn __iavf_set_coalesce(netdev, ec, -1);\n}\n\n \nstatic int iavf_set_per_queue_coalesce(struct net_device *netdev, u32 queue,\n\t\t\t\t       struct ethtool_coalesce *ec)\n{\n\treturn __iavf_set_coalesce(netdev, ec, queue);\n}\n\n \nstatic int iavf_fltr_to_ethtool_flow(enum iavf_fdir_flow_type flow)\n{\n\tswitch (flow) {\n\tcase IAVF_FDIR_FLOW_IPV4_TCP:\n\t\treturn TCP_V4_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV4_UDP:\n\t\treturn UDP_V4_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV4_SCTP:\n\t\treturn SCTP_V4_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV4_AH:\n\t\treturn AH_V4_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV4_ESP:\n\t\treturn ESP_V4_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV4_OTHER:\n\t\treturn IPV4_USER_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV6_TCP:\n\t\treturn TCP_V6_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV6_UDP:\n\t\treturn UDP_V6_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV6_SCTP:\n\t\treturn SCTP_V6_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV6_AH:\n\t\treturn AH_V6_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV6_ESP:\n\t\treturn ESP_V6_FLOW;\n\tcase IAVF_FDIR_FLOW_IPV6_OTHER:\n\t\treturn IPV6_USER_FLOW;\n\tcase IAVF_FDIR_FLOW_NON_IP_L2:\n\t\treturn ETHER_FLOW;\n\tdefault:\n\t\t \n\t\treturn 0;\n\t}\n}\n\n \nstatic enum iavf_fdir_flow_type iavf_ethtool_flow_to_fltr(int eth)\n{\n\tswitch (eth) {\n\tcase TCP_V4_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV4_TCP;\n\tcase UDP_V4_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV4_UDP;\n\tcase SCTP_V4_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV4_SCTP;\n\tcase AH_V4_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV4_AH;\n\tcase ESP_V4_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV4_ESP;\n\tcase IPV4_USER_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV4_OTHER;\n\tcase TCP_V6_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV6_TCP;\n\tcase UDP_V6_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV6_UDP;\n\tcase SCTP_V6_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV6_SCTP;\n\tcase AH_V6_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV6_AH;\n\tcase ESP_V6_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV6_ESP;\n\tcase IPV6_USER_FLOW:\n\t\treturn IAVF_FDIR_FLOW_IPV6_OTHER;\n\tcase ETHER_FLOW:\n\t\treturn IAVF_FDIR_FLOW_NON_IP_L2;\n\tdefault:\n\t\treturn IAVF_FDIR_FLOW_NONE;\n\t}\n}\n\n \nstatic bool iavf_is_mask_valid(u64 mask, u64 field)\n{\n\treturn (mask & field) == field;\n}\n\n \nstatic int\niavf_parse_rx_flow_user_data(struct ethtool_rx_flow_spec *fsp,\n\t\t\t     struct iavf_fdir_fltr *fltr)\n{\n\tstruct iavf_flex_word *flex;\n\tint i, cnt = 0;\n\n\tif (!(fsp->flow_type & FLOW_EXT))\n\t\treturn 0;\n\n\tfor (i = 0; i < IAVF_FLEX_WORD_NUM; i++) {\n#define IAVF_USERDEF_FLEX_WORD_M\tGENMASK(15, 0)\n#define IAVF_USERDEF_FLEX_OFFS_S\t16\n#define IAVF_USERDEF_FLEX_OFFS_M\tGENMASK(31, IAVF_USERDEF_FLEX_OFFS_S)\n#define IAVF_USERDEF_FLEX_FLTR_M\tGENMASK(31, 0)\n\t\tu32 value = be32_to_cpu(fsp->h_ext.data[i]);\n\t\tu32 mask = be32_to_cpu(fsp->m_ext.data[i]);\n\n\t\tif (!value || !mask)\n\t\t\tcontinue;\n\n\t\tif (!iavf_is_mask_valid(mask, IAVF_USERDEF_FLEX_FLTR_M))\n\t\t\treturn -EINVAL;\n\n\t\t \n#define IAVF_USERDEF_FLEX_MAX_OFFS_VAL 504\n\t\tflex = &fltr->flex_words[cnt++];\n\t\tflex->word = value & IAVF_USERDEF_FLEX_WORD_M;\n\t\tflex->offset = (value & IAVF_USERDEF_FLEX_OFFS_M) >>\n\t\t\t     IAVF_USERDEF_FLEX_OFFS_S;\n\t\tif (flex->offset > IAVF_USERDEF_FLEX_MAX_OFFS_VAL)\n\t\t\treturn -EINVAL;\n\t}\n\n\tfltr->flex_cnt = cnt;\n\n\treturn 0;\n}\n\n \nstatic void\niavf_fill_rx_flow_ext_data(struct ethtool_rx_flow_spec *fsp,\n\t\t\t   struct iavf_fdir_fltr *fltr)\n{\n\tif (!fltr->ext_mask.usr_def[0] && !fltr->ext_mask.usr_def[1])\n\t\treturn;\n\n\tfsp->flow_type |= FLOW_EXT;\n\n\tmemcpy(fsp->h_ext.data, fltr->ext_data.usr_def, sizeof(fsp->h_ext.data));\n\tmemcpy(fsp->m_ext.data, fltr->ext_mask.usr_def, sizeof(fsp->m_ext.data));\n}\n\n \nstatic int\niavf_get_ethtool_fdir_entry(struct iavf_adapter *adapter,\n\t\t\t    struct ethtool_rxnfc *cmd)\n{\n\tstruct ethtool_rx_flow_spec *fsp = (struct ethtool_rx_flow_spec *)&cmd->fs;\n\tstruct iavf_fdir_fltr *rule = NULL;\n\tint ret = 0;\n\n\tif (!(adapter->flags & IAVF_FLAG_FDIR_ENABLED))\n\t\treturn -EOPNOTSUPP;\n\n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\n\trule = iavf_find_fdir_fltr_by_loc(adapter, fsp->location);\n\tif (!rule) {\n\t\tret = -EINVAL;\n\t\tgoto release_lock;\n\t}\n\n\tfsp->flow_type = iavf_fltr_to_ethtool_flow(rule->flow_type);\n\n\tmemset(&fsp->m_u, 0, sizeof(fsp->m_u));\n\tmemset(&fsp->m_ext, 0, sizeof(fsp->m_ext));\n\n\tswitch (fsp->flow_type) {\n\tcase TCP_V4_FLOW:\n\tcase UDP_V4_FLOW:\n\tcase SCTP_V4_FLOW:\n\t\tfsp->h_u.tcp_ip4_spec.ip4src = rule->ip_data.v4_addrs.src_ip;\n\t\tfsp->h_u.tcp_ip4_spec.ip4dst = rule->ip_data.v4_addrs.dst_ip;\n\t\tfsp->h_u.tcp_ip4_spec.psrc = rule->ip_data.src_port;\n\t\tfsp->h_u.tcp_ip4_spec.pdst = rule->ip_data.dst_port;\n\t\tfsp->h_u.tcp_ip4_spec.tos = rule->ip_data.tos;\n\t\tfsp->m_u.tcp_ip4_spec.ip4src = rule->ip_mask.v4_addrs.src_ip;\n\t\tfsp->m_u.tcp_ip4_spec.ip4dst = rule->ip_mask.v4_addrs.dst_ip;\n\t\tfsp->m_u.tcp_ip4_spec.psrc = rule->ip_mask.src_port;\n\t\tfsp->m_u.tcp_ip4_spec.pdst = rule->ip_mask.dst_port;\n\t\tfsp->m_u.tcp_ip4_spec.tos = rule->ip_mask.tos;\n\t\tbreak;\n\tcase AH_V4_FLOW:\n\tcase ESP_V4_FLOW:\n\t\tfsp->h_u.ah_ip4_spec.ip4src = rule->ip_data.v4_addrs.src_ip;\n\t\tfsp->h_u.ah_ip4_spec.ip4dst = rule->ip_data.v4_addrs.dst_ip;\n\t\tfsp->h_u.ah_ip4_spec.spi = rule->ip_data.spi;\n\t\tfsp->h_u.ah_ip4_spec.tos = rule->ip_data.tos;\n\t\tfsp->m_u.ah_ip4_spec.ip4src = rule->ip_mask.v4_addrs.src_ip;\n\t\tfsp->m_u.ah_ip4_spec.ip4dst = rule->ip_mask.v4_addrs.dst_ip;\n\t\tfsp->m_u.ah_ip4_spec.spi = rule->ip_mask.spi;\n\t\tfsp->m_u.ah_ip4_spec.tos = rule->ip_mask.tos;\n\t\tbreak;\n\tcase IPV4_USER_FLOW:\n\t\tfsp->h_u.usr_ip4_spec.ip4src = rule->ip_data.v4_addrs.src_ip;\n\t\tfsp->h_u.usr_ip4_spec.ip4dst = rule->ip_data.v4_addrs.dst_ip;\n\t\tfsp->h_u.usr_ip4_spec.l4_4_bytes = rule->ip_data.l4_header;\n\t\tfsp->h_u.usr_ip4_spec.tos = rule->ip_data.tos;\n\t\tfsp->h_u.usr_ip4_spec.ip_ver = ETH_RX_NFC_IP4;\n\t\tfsp->h_u.usr_ip4_spec.proto = rule->ip_data.proto;\n\t\tfsp->m_u.usr_ip4_spec.ip4src = rule->ip_mask.v4_addrs.src_ip;\n\t\tfsp->m_u.usr_ip4_spec.ip4dst = rule->ip_mask.v4_addrs.dst_ip;\n\t\tfsp->m_u.usr_ip4_spec.l4_4_bytes = rule->ip_mask.l4_header;\n\t\tfsp->m_u.usr_ip4_spec.tos = rule->ip_mask.tos;\n\t\tfsp->m_u.usr_ip4_spec.ip_ver = 0xFF;\n\t\tfsp->m_u.usr_ip4_spec.proto = rule->ip_mask.proto;\n\t\tbreak;\n\tcase TCP_V6_FLOW:\n\tcase UDP_V6_FLOW:\n\tcase SCTP_V6_FLOW:\n\t\tmemcpy(fsp->h_u.usr_ip6_spec.ip6src, &rule->ip_data.v6_addrs.src_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(fsp->h_u.usr_ip6_spec.ip6dst, &rule->ip_data.v6_addrs.dst_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tfsp->h_u.tcp_ip6_spec.psrc = rule->ip_data.src_port;\n\t\tfsp->h_u.tcp_ip6_spec.pdst = rule->ip_data.dst_port;\n\t\tfsp->h_u.tcp_ip6_spec.tclass = rule->ip_data.tclass;\n\t\tmemcpy(fsp->m_u.usr_ip6_spec.ip6src, &rule->ip_mask.v6_addrs.src_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(fsp->m_u.usr_ip6_spec.ip6dst, &rule->ip_mask.v6_addrs.dst_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tfsp->m_u.tcp_ip6_spec.psrc = rule->ip_mask.src_port;\n\t\tfsp->m_u.tcp_ip6_spec.pdst = rule->ip_mask.dst_port;\n\t\tfsp->m_u.tcp_ip6_spec.tclass = rule->ip_mask.tclass;\n\t\tbreak;\n\tcase AH_V6_FLOW:\n\tcase ESP_V6_FLOW:\n\t\tmemcpy(fsp->h_u.ah_ip6_spec.ip6src, &rule->ip_data.v6_addrs.src_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(fsp->h_u.ah_ip6_spec.ip6dst, &rule->ip_data.v6_addrs.dst_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tfsp->h_u.ah_ip6_spec.spi = rule->ip_data.spi;\n\t\tfsp->h_u.ah_ip6_spec.tclass = rule->ip_data.tclass;\n\t\tmemcpy(fsp->m_u.ah_ip6_spec.ip6src, &rule->ip_mask.v6_addrs.src_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(fsp->m_u.ah_ip6_spec.ip6dst, &rule->ip_mask.v6_addrs.dst_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tfsp->m_u.ah_ip6_spec.spi = rule->ip_mask.spi;\n\t\tfsp->m_u.ah_ip6_spec.tclass = rule->ip_mask.tclass;\n\t\tbreak;\n\tcase IPV6_USER_FLOW:\n\t\tmemcpy(fsp->h_u.usr_ip6_spec.ip6src, &rule->ip_data.v6_addrs.src_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(fsp->h_u.usr_ip6_spec.ip6dst, &rule->ip_data.v6_addrs.dst_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tfsp->h_u.usr_ip6_spec.l4_4_bytes = rule->ip_data.l4_header;\n\t\tfsp->h_u.usr_ip6_spec.tclass = rule->ip_data.tclass;\n\t\tfsp->h_u.usr_ip6_spec.l4_proto = rule->ip_data.proto;\n\t\tmemcpy(fsp->m_u.usr_ip6_spec.ip6src, &rule->ip_mask.v6_addrs.src_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(fsp->m_u.usr_ip6_spec.ip6dst, &rule->ip_mask.v6_addrs.dst_ip,\n\t\t       sizeof(struct in6_addr));\n\t\tfsp->m_u.usr_ip6_spec.l4_4_bytes = rule->ip_mask.l4_header;\n\t\tfsp->m_u.usr_ip6_spec.tclass = rule->ip_mask.tclass;\n\t\tfsp->m_u.usr_ip6_spec.l4_proto = rule->ip_mask.proto;\n\t\tbreak;\n\tcase ETHER_FLOW:\n\t\tfsp->h_u.ether_spec.h_proto = rule->eth_data.etype;\n\t\tfsp->m_u.ether_spec.h_proto = rule->eth_mask.etype;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\tiavf_fill_rx_flow_ext_data(fsp, rule);\n\n\tif (rule->action == VIRTCHNL_ACTION_DROP)\n\t\tfsp->ring_cookie = RX_CLS_FLOW_DISC;\n\telse\n\t\tfsp->ring_cookie = rule->q_index;\n\nrelease_lock:\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\treturn ret;\n}\n\n \nstatic int\niavf_get_fdir_fltr_ids(struct iavf_adapter *adapter, struct ethtool_rxnfc *cmd,\n\t\t       u32 *rule_locs)\n{\n\tstruct iavf_fdir_fltr *fltr;\n\tunsigned int cnt = 0;\n\tint val = 0;\n\n\tif (!(adapter->flags & IAVF_FLAG_FDIR_ENABLED))\n\t\treturn -EOPNOTSUPP;\n\n\tcmd->data = IAVF_MAX_FDIR_FILTERS;\n\n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\n\tlist_for_each_entry(fltr, &adapter->fdir_list_head, list) {\n\t\tif (cnt == cmd->rule_cnt) {\n\t\t\tval = -EMSGSIZE;\n\t\t\tgoto release_lock;\n\t\t}\n\t\trule_locs[cnt] = fltr->loc;\n\t\tcnt++;\n\t}\n\nrelease_lock:\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\tif (!val)\n\t\tcmd->rule_cnt = cnt;\n\n\treturn val;\n}\n\n \nstatic int\niavf_add_fdir_fltr_info(struct iavf_adapter *adapter, struct ethtool_rx_flow_spec *fsp,\n\t\t\tstruct iavf_fdir_fltr *fltr)\n{\n\tu32 flow_type, q_index = 0;\n\tenum virtchnl_action act;\n\tint err;\n\n\tif (fsp->ring_cookie == RX_CLS_FLOW_DISC) {\n\t\tact = VIRTCHNL_ACTION_DROP;\n\t} else {\n\t\tq_index = fsp->ring_cookie;\n\t\tif (q_index >= adapter->num_active_queues)\n\t\t\treturn -EINVAL;\n\n\t\tact = VIRTCHNL_ACTION_QUEUE;\n\t}\n\n\tfltr->action = act;\n\tfltr->loc = fsp->location;\n\tfltr->q_index = q_index;\n\n\tif (fsp->flow_type & FLOW_EXT) {\n\t\tmemcpy(fltr->ext_data.usr_def, fsp->h_ext.data,\n\t\t       sizeof(fltr->ext_data.usr_def));\n\t\tmemcpy(fltr->ext_mask.usr_def, fsp->m_ext.data,\n\t\t       sizeof(fltr->ext_mask.usr_def));\n\t}\n\n\tflow_type = fsp->flow_type & ~(FLOW_EXT | FLOW_MAC_EXT | FLOW_RSS);\n\tfltr->flow_type = iavf_ethtool_flow_to_fltr(flow_type);\n\n\tswitch (flow_type) {\n\tcase TCP_V4_FLOW:\n\tcase UDP_V4_FLOW:\n\tcase SCTP_V4_FLOW:\n\t\tfltr->ip_data.v4_addrs.src_ip = fsp->h_u.tcp_ip4_spec.ip4src;\n\t\tfltr->ip_data.v4_addrs.dst_ip = fsp->h_u.tcp_ip4_spec.ip4dst;\n\t\tfltr->ip_data.src_port = fsp->h_u.tcp_ip4_spec.psrc;\n\t\tfltr->ip_data.dst_port = fsp->h_u.tcp_ip4_spec.pdst;\n\t\tfltr->ip_data.tos = fsp->h_u.tcp_ip4_spec.tos;\n\t\tfltr->ip_mask.v4_addrs.src_ip = fsp->m_u.tcp_ip4_spec.ip4src;\n\t\tfltr->ip_mask.v4_addrs.dst_ip = fsp->m_u.tcp_ip4_spec.ip4dst;\n\t\tfltr->ip_mask.src_port = fsp->m_u.tcp_ip4_spec.psrc;\n\t\tfltr->ip_mask.dst_port = fsp->m_u.tcp_ip4_spec.pdst;\n\t\tfltr->ip_mask.tos = fsp->m_u.tcp_ip4_spec.tos;\n\t\tfltr->ip_ver = 4;\n\t\tbreak;\n\tcase AH_V4_FLOW:\n\tcase ESP_V4_FLOW:\n\t\tfltr->ip_data.v4_addrs.src_ip = fsp->h_u.ah_ip4_spec.ip4src;\n\t\tfltr->ip_data.v4_addrs.dst_ip = fsp->h_u.ah_ip4_spec.ip4dst;\n\t\tfltr->ip_data.spi = fsp->h_u.ah_ip4_spec.spi;\n\t\tfltr->ip_data.tos = fsp->h_u.ah_ip4_spec.tos;\n\t\tfltr->ip_mask.v4_addrs.src_ip = fsp->m_u.ah_ip4_spec.ip4src;\n\t\tfltr->ip_mask.v4_addrs.dst_ip = fsp->m_u.ah_ip4_spec.ip4dst;\n\t\tfltr->ip_mask.spi = fsp->m_u.ah_ip4_spec.spi;\n\t\tfltr->ip_mask.tos = fsp->m_u.ah_ip4_spec.tos;\n\t\tfltr->ip_ver = 4;\n\t\tbreak;\n\tcase IPV4_USER_FLOW:\n\t\tfltr->ip_data.v4_addrs.src_ip = fsp->h_u.usr_ip4_spec.ip4src;\n\t\tfltr->ip_data.v4_addrs.dst_ip = fsp->h_u.usr_ip4_spec.ip4dst;\n\t\tfltr->ip_data.l4_header = fsp->h_u.usr_ip4_spec.l4_4_bytes;\n\t\tfltr->ip_data.tos = fsp->h_u.usr_ip4_spec.tos;\n\t\tfltr->ip_data.proto = fsp->h_u.usr_ip4_spec.proto;\n\t\tfltr->ip_mask.v4_addrs.src_ip = fsp->m_u.usr_ip4_spec.ip4src;\n\t\tfltr->ip_mask.v4_addrs.dst_ip = fsp->m_u.usr_ip4_spec.ip4dst;\n\t\tfltr->ip_mask.l4_header = fsp->m_u.usr_ip4_spec.l4_4_bytes;\n\t\tfltr->ip_mask.tos = fsp->m_u.usr_ip4_spec.tos;\n\t\tfltr->ip_mask.proto = fsp->m_u.usr_ip4_spec.proto;\n\t\tfltr->ip_ver = 4;\n\t\tbreak;\n\tcase TCP_V6_FLOW:\n\tcase UDP_V6_FLOW:\n\tcase SCTP_V6_FLOW:\n\t\tmemcpy(&fltr->ip_data.v6_addrs.src_ip, fsp->h_u.usr_ip6_spec.ip6src,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(&fltr->ip_data.v6_addrs.dst_ip, fsp->h_u.usr_ip6_spec.ip6dst,\n\t\t       sizeof(struct in6_addr));\n\t\tfltr->ip_data.src_port = fsp->h_u.tcp_ip6_spec.psrc;\n\t\tfltr->ip_data.dst_port = fsp->h_u.tcp_ip6_spec.pdst;\n\t\tfltr->ip_data.tclass = fsp->h_u.tcp_ip6_spec.tclass;\n\t\tmemcpy(&fltr->ip_mask.v6_addrs.src_ip, fsp->m_u.usr_ip6_spec.ip6src,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(&fltr->ip_mask.v6_addrs.dst_ip, fsp->m_u.usr_ip6_spec.ip6dst,\n\t\t       sizeof(struct in6_addr));\n\t\tfltr->ip_mask.src_port = fsp->m_u.tcp_ip6_spec.psrc;\n\t\tfltr->ip_mask.dst_port = fsp->m_u.tcp_ip6_spec.pdst;\n\t\tfltr->ip_mask.tclass = fsp->m_u.tcp_ip6_spec.tclass;\n\t\tfltr->ip_ver = 6;\n\t\tbreak;\n\tcase AH_V6_FLOW:\n\tcase ESP_V6_FLOW:\n\t\tmemcpy(&fltr->ip_data.v6_addrs.src_ip, fsp->h_u.ah_ip6_spec.ip6src,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(&fltr->ip_data.v6_addrs.dst_ip, fsp->h_u.ah_ip6_spec.ip6dst,\n\t\t       sizeof(struct in6_addr));\n\t\tfltr->ip_data.spi = fsp->h_u.ah_ip6_spec.spi;\n\t\tfltr->ip_data.tclass = fsp->h_u.ah_ip6_spec.tclass;\n\t\tmemcpy(&fltr->ip_mask.v6_addrs.src_ip, fsp->m_u.ah_ip6_spec.ip6src,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(&fltr->ip_mask.v6_addrs.dst_ip, fsp->m_u.ah_ip6_spec.ip6dst,\n\t\t       sizeof(struct in6_addr));\n\t\tfltr->ip_mask.spi = fsp->m_u.ah_ip6_spec.spi;\n\t\tfltr->ip_mask.tclass = fsp->m_u.ah_ip6_spec.tclass;\n\t\tfltr->ip_ver = 6;\n\t\tbreak;\n\tcase IPV6_USER_FLOW:\n\t\tmemcpy(&fltr->ip_data.v6_addrs.src_ip, fsp->h_u.usr_ip6_spec.ip6src,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(&fltr->ip_data.v6_addrs.dst_ip, fsp->h_u.usr_ip6_spec.ip6dst,\n\t\t       sizeof(struct in6_addr));\n\t\tfltr->ip_data.l4_header = fsp->h_u.usr_ip6_spec.l4_4_bytes;\n\t\tfltr->ip_data.tclass = fsp->h_u.usr_ip6_spec.tclass;\n\t\tfltr->ip_data.proto = fsp->h_u.usr_ip6_spec.l4_proto;\n\t\tmemcpy(&fltr->ip_mask.v6_addrs.src_ip, fsp->m_u.usr_ip6_spec.ip6src,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(&fltr->ip_mask.v6_addrs.dst_ip, fsp->m_u.usr_ip6_spec.ip6dst,\n\t\t       sizeof(struct in6_addr));\n\t\tfltr->ip_mask.l4_header = fsp->m_u.usr_ip6_spec.l4_4_bytes;\n\t\tfltr->ip_mask.tclass = fsp->m_u.usr_ip6_spec.tclass;\n\t\tfltr->ip_mask.proto = fsp->m_u.usr_ip6_spec.l4_proto;\n\t\tfltr->ip_ver = 6;\n\t\tbreak;\n\tcase ETHER_FLOW:\n\t\tfltr->eth_data.etype = fsp->h_u.ether_spec.h_proto;\n\t\tfltr->eth_mask.etype = fsp->m_u.ether_spec.h_proto;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\terr = iavf_validate_fdir_fltr_masks(adapter, fltr);\n\tif (err)\n\t\treturn err;\n\n\tif (iavf_fdir_is_dup_fltr(adapter, fltr))\n\t\treturn -EEXIST;\n\n\terr = iavf_parse_rx_flow_user_data(fsp, fltr);\n\tif (err)\n\t\treturn err;\n\n\treturn iavf_fill_fdir_add_msg(adapter, fltr);\n}\n\n \nstatic int iavf_add_fdir_ethtool(struct iavf_adapter *adapter, struct ethtool_rxnfc *cmd)\n{\n\tstruct ethtool_rx_flow_spec *fsp = &cmd->fs;\n\tstruct iavf_fdir_fltr *fltr;\n\tint count = 50;\n\tint err;\n\n\tif (!(adapter->flags & IAVF_FLAG_FDIR_ENABLED))\n\t\treturn -EOPNOTSUPP;\n\n\tif (fsp->flow_type & FLOW_MAC_EXT)\n\t\treturn -EINVAL;\n\n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\tif (adapter->fdir_active_fltr >= IAVF_MAX_FDIR_FILTERS) {\n\t\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Unable to add Flow Director filter because VF reached the limit of max allowed filters (%u)\\n\",\n\t\t\tIAVF_MAX_FDIR_FILTERS);\n\t\treturn -ENOSPC;\n\t}\n\n\tif (iavf_find_fdir_fltr_by_loc(adapter, fsp->location)) {\n\t\tdev_err(&adapter->pdev->dev, \"Failed to add Flow Director filter, it already exists\\n\");\n\t\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\t\treturn -EEXIST;\n\t}\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\n\tfltr = kzalloc(sizeof(*fltr), GFP_KERNEL);\n\tif (!fltr)\n\t\treturn -ENOMEM;\n\n\twhile (!mutex_trylock(&adapter->crit_lock)) {\n\t\tif (--count == 0) {\n\t\t\tkfree(fltr);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tudelay(1);\n\t}\n\n\terr = iavf_add_fdir_fltr_info(adapter, fsp, fltr);\n\tif (err)\n\t\tgoto ret;\n\n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\tiavf_fdir_list_add_fltr(adapter, fltr);\n\tadapter->fdir_active_fltr++;\n\tif (adapter->link_up) {\n\t\tfltr->state = IAVF_FDIR_FLTR_ADD_REQUEST;\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_FDIR_FILTER;\n\t} else {\n\t\tfltr->state = IAVF_FDIR_FLTR_INACTIVE;\n\t}\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\n\tif (adapter->link_up)\n\t\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\nret:\n\tif (err && fltr)\n\t\tkfree(fltr);\n\n\tmutex_unlock(&adapter->crit_lock);\n\treturn err;\n}\n\n \nstatic int iavf_del_fdir_ethtool(struct iavf_adapter *adapter, struct ethtool_rxnfc *cmd)\n{\n\tstruct ethtool_rx_flow_spec *fsp = (struct ethtool_rx_flow_spec *)&cmd->fs;\n\tstruct iavf_fdir_fltr *fltr = NULL;\n\tint err = 0;\n\n\tif (!(adapter->flags & IAVF_FLAG_FDIR_ENABLED))\n\t\treturn -EOPNOTSUPP;\n\n\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\tfltr = iavf_find_fdir_fltr_by_loc(adapter, fsp->location);\n\tif (fltr) {\n\t\tif (fltr->state == IAVF_FDIR_FLTR_ACTIVE) {\n\t\t\tfltr->state = IAVF_FDIR_FLTR_DEL_REQUEST;\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_DEL_FDIR_FILTER;\n\t\t} else if (fltr->state == IAVF_FDIR_FLTR_INACTIVE) {\n\t\t\tlist_del(&fltr->list);\n\t\t\tkfree(fltr);\n\t\t\tadapter->fdir_active_fltr--;\n\t\t\tfltr = NULL;\n\t\t} else {\n\t\t\terr = -EBUSY;\n\t\t}\n\t} else if (adapter->fdir_active_fltr) {\n\t\terr = -EINVAL;\n\t}\n\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\n\tif (fltr && fltr->state == IAVF_FDIR_FLTR_DEL_REQUEST)\n\t\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n\n\treturn err;\n}\n\n \nstatic u32 iavf_adv_rss_parse_hdrs(struct ethtool_rxnfc *cmd)\n{\n\tu32 hdrs = IAVF_ADV_RSS_FLOW_SEG_HDR_NONE;\n\n\tswitch (cmd->flow_type) {\n\tcase TCP_V4_FLOW:\n\t\thdrs |= IAVF_ADV_RSS_FLOW_SEG_HDR_TCP |\n\t\t\tIAVF_ADV_RSS_FLOW_SEG_HDR_IPV4;\n\t\tbreak;\n\tcase UDP_V4_FLOW:\n\t\thdrs |= IAVF_ADV_RSS_FLOW_SEG_HDR_UDP |\n\t\t\tIAVF_ADV_RSS_FLOW_SEG_HDR_IPV4;\n\t\tbreak;\n\tcase SCTP_V4_FLOW:\n\t\thdrs |= IAVF_ADV_RSS_FLOW_SEG_HDR_SCTP |\n\t\t\tIAVF_ADV_RSS_FLOW_SEG_HDR_IPV4;\n\t\tbreak;\n\tcase TCP_V6_FLOW:\n\t\thdrs |= IAVF_ADV_RSS_FLOW_SEG_HDR_TCP |\n\t\t\tIAVF_ADV_RSS_FLOW_SEG_HDR_IPV6;\n\t\tbreak;\n\tcase UDP_V6_FLOW:\n\t\thdrs |= IAVF_ADV_RSS_FLOW_SEG_HDR_UDP |\n\t\t\tIAVF_ADV_RSS_FLOW_SEG_HDR_IPV6;\n\t\tbreak;\n\tcase SCTP_V6_FLOW:\n\t\thdrs |= IAVF_ADV_RSS_FLOW_SEG_HDR_SCTP |\n\t\t\tIAVF_ADV_RSS_FLOW_SEG_HDR_IPV6;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn hdrs;\n}\n\n \nstatic u64 iavf_adv_rss_parse_hash_flds(struct ethtool_rxnfc *cmd)\n{\n\tu64 hfld = IAVF_ADV_RSS_HASH_INVALID;\n\n\tif (cmd->data & RXH_IP_SRC || cmd->data & RXH_IP_DST) {\n\t\tswitch (cmd->flow_type) {\n\t\tcase TCP_V4_FLOW:\n\t\tcase UDP_V4_FLOW:\n\t\tcase SCTP_V4_FLOW:\n\t\t\tif (cmd->data & RXH_IP_SRC)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_IPV4_SA;\n\t\t\tif (cmd->data & RXH_IP_DST)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_IPV4_DA;\n\t\t\tbreak;\n\t\tcase TCP_V6_FLOW:\n\t\tcase UDP_V6_FLOW:\n\t\tcase SCTP_V6_FLOW:\n\t\t\tif (cmd->data & RXH_IP_SRC)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_IPV6_SA;\n\t\t\tif (cmd->data & RXH_IP_DST)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_IPV6_DA;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (cmd->data & RXH_L4_B_0_1 || cmd->data & RXH_L4_B_2_3) {\n\t\tswitch (cmd->flow_type) {\n\t\tcase TCP_V4_FLOW:\n\t\tcase TCP_V6_FLOW:\n\t\t\tif (cmd->data & RXH_L4_B_0_1)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_TCP_SRC_PORT;\n\t\t\tif (cmd->data & RXH_L4_B_2_3)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_TCP_DST_PORT;\n\t\t\tbreak;\n\t\tcase UDP_V4_FLOW:\n\t\tcase UDP_V6_FLOW:\n\t\t\tif (cmd->data & RXH_L4_B_0_1)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_UDP_SRC_PORT;\n\t\t\tif (cmd->data & RXH_L4_B_2_3)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_UDP_DST_PORT;\n\t\t\tbreak;\n\t\tcase SCTP_V4_FLOW:\n\t\tcase SCTP_V6_FLOW:\n\t\t\tif (cmd->data & RXH_L4_B_0_1)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_SCTP_SRC_PORT;\n\t\t\tif (cmd->data & RXH_L4_B_2_3)\n\t\t\t\thfld |= IAVF_ADV_RSS_HASH_FLD_SCTP_DST_PORT;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn hfld;\n}\n\n \nstatic int\niavf_set_adv_rss_hash_opt(struct iavf_adapter *adapter,\n\t\t\t  struct ethtool_rxnfc *cmd)\n{\n\tstruct iavf_adv_rss *rss_old, *rss_new;\n\tbool rss_new_add = false;\n\tint count = 50, err = 0;\n\tu64 hash_flds;\n\tu32 hdrs;\n\n\tif (!ADV_RSS_SUPPORT(adapter))\n\t\treturn -EOPNOTSUPP;\n\n\thdrs = iavf_adv_rss_parse_hdrs(cmd);\n\tif (hdrs == IAVF_ADV_RSS_FLOW_SEG_HDR_NONE)\n\t\treturn -EINVAL;\n\n\thash_flds = iavf_adv_rss_parse_hash_flds(cmd);\n\tif (hash_flds == IAVF_ADV_RSS_HASH_INVALID)\n\t\treturn -EINVAL;\n\n\trss_new = kzalloc(sizeof(*rss_new), GFP_KERNEL);\n\tif (!rss_new)\n\t\treturn -ENOMEM;\n\n\tif (iavf_fill_adv_rss_cfg_msg(&rss_new->cfg_msg, hdrs, hash_flds)) {\n\t\tkfree(rss_new);\n\t\treturn -EINVAL;\n\t}\n\n\twhile (!mutex_trylock(&adapter->crit_lock)) {\n\t\tif (--count == 0) {\n\t\t\tkfree(rss_new);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tudelay(1);\n\t}\n\n\tspin_lock_bh(&adapter->adv_rss_lock);\n\trss_old = iavf_find_adv_rss_cfg_by_hdrs(adapter, hdrs);\n\tif (rss_old) {\n\t\tif (rss_old->state != IAVF_ADV_RSS_ACTIVE) {\n\t\t\terr = -EBUSY;\n\t\t} else if (rss_old->hash_flds != hash_flds) {\n\t\t\trss_old->state = IAVF_ADV_RSS_ADD_REQUEST;\n\t\t\trss_old->hash_flds = hash_flds;\n\t\t\tmemcpy(&rss_old->cfg_msg, &rss_new->cfg_msg,\n\t\t\t       sizeof(rss_new->cfg_msg));\n\t\t\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_ADV_RSS_CFG;\n\t\t} else {\n\t\t\terr = -EEXIST;\n\t\t}\n\t} else {\n\t\trss_new_add = true;\n\t\trss_new->state = IAVF_ADV_RSS_ADD_REQUEST;\n\t\trss_new->packet_hdrs = hdrs;\n\t\trss_new->hash_flds = hash_flds;\n\t\tlist_add_tail(&rss_new->list, &adapter->adv_rss_list_head);\n\t\tadapter->aq_required |= IAVF_FLAG_AQ_ADD_ADV_RSS_CFG;\n\t}\n\tspin_unlock_bh(&adapter->adv_rss_lock);\n\n\tif (!err)\n\t\tmod_delayed_work(adapter->wq, &adapter->watchdog_task, 0);\n\n\tmutex_unlock(&adapter->crit_lock);\n\n\tif (!rss_new_add)\n\t\tkfree(rss_new);\n\n\treturn err;\n}\n\n \nstatic int\niavf_get_adv_rss_hash_opt(struct iavf_adapter *adapter,\n\t\t\t  struct ethtool_rxnfc *cmd)\n{\n\tstruct iavf_adv_rss *rss;\n\tu64 hash_flds;\n\tu32 hdrs;\n\n\tif (!ADV_RSS_SUPPORT(adapter))\n\t\treturn -EOPNOTSUPP;\n\n\tcmd->data = 0;\n\n\thdrs = iavf_adv_rss_parse_hdrs(cmd);\n\tif (hdrs == IAVF_ADV_RSS_FLOW_SEG_HDR_NONE)\n\t\treturn -EINVAL;\n\n\tspin_lock_bh(&adapter->adv_rss_lock);\n\trss = iavf_find_adv_rss_cfg_by_hdrs(adapter, hdrs);\n\tif (rss)\n\t\thash_flds = rss->hash_flds;\n\telse\n\t\thash_flds = IAVF_ADV_RSS_HASH_INVALID;\n\tspin_unlock_bh(&adapter->adv_rss_lock);\n\n\tif (hash_flds == IAVF_ADV_RSS_HASH_INVALID)\n\t\treturn -EINVAL;\n\n\tif (hash_flds & (IAVF_ADV_RSS_HASH_FLD_IPV4_SA |\n\t\t\t IAVF_ADV_RSS_HASH_FLD_IPV6_SA))\n\t\tcmd->data |= (u64)RXH_IP_SRC;\n\n\tif (hash_flds & (IAVF_ADV_RSS_HASH_FLD_IPV4_DA |\n\t\t\t IAVF_ADV_RSS_HASH_FLD_IPV6_DA))\n\t\tcmd->data |= (u64)RXH_IP_DST;\n\n\tif (hash_flds & (IAVF_ADV_RSS_HASH_FLD_TCP_SRC_PORT |\n\t\t\t IAVF_ADV_RSS_HASH_FLD_UDP_SRC_PORT |\n\t\t\t IAVF_ADV_RSS_HASH_FLD_SCTP_SRC_PORT))\n\t\tcmd->data |= (u64)RXH_L4_B_0_1;\n\n\tif (hash_flds & (IAVF_ADV_RSS_HASH_FLD_TCP_DST_PORT |\n\t\t\t IAVF_ADV_RSS_HASH_FLD_UDP_DST_PORT |\n\t\t\t IAVF_ADV_RSS_HASH_FLD_SCTP_DST_PORT))\n\t\tcmd->data |= (u64)RXH_L4_B_2_3;\n\n\treturn 0;\n}\n\n \nstatic int iavf_set_rxnfc(struct net_device *netdev, struct ethtool_rxnfc *cmd)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tint ret = -EOPNOTSUPP;\n\n\tswitch (cmd->cmd) {\n\tcase ETHTOOL_SRXCLSRLINS:\n\t\tret = iavf_add_fdir_ethtool(adapter, cmd);\n\t\tbreak;\n\tcase ETHTOOL_SRXCLSRLDEL:\n\t\tret = iavf_del_fdir_ethtool(adapter, cmd);\n\t\tbreak;\n\tcase ETHTOOL_SRXFH:\n\t\tret = iavf_set_adv_rss_hash_opt(adapter, cmd);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n \nstatic int iavf_get_rxnfc(struct net_device *netdev, struct ethtool_rxnfc *cmd,\n\t\t\t  u32 *rule_locs)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tint ret = -EOPNOTSUPP;\n\n\tswitch (cmd->cmd) {\n\tcase ETHTOOL_GRXRINGS:\n\t\tcmd->data = adapter->num_active_queues;\n\t\tret = 0;\n\t\tbreak;\n\tcase ETHTOOL_GRXCLSRLCNT:\n\t\tif (!(adapter->flags & IAVF_FLAG_FDIR_ENABLED))\n\t\t\tbreak;\n\t\tspin_lock_bh(&adapter->fdir_fltr_lock);\n\t\tcmd->rule_cnt = adapter->fdir_active_fltr;\n\t\tspin_unlock_bh(&adapter->fdir_fltr_lock);\n\t\tcmd->data = IAVF_MAX_FDIR_FILTERS;\n\t\tret = 0;\n\t\tbreak;\n\tcase ETHTOOL_GRXCLSRULE:\n\t\tret = iavf_get_ethtool_fdir_entry(adapter, cmd);\n\t\tbreak;\n\tcase ETHTOOL_GRXCLSRLALL:\n\t\tret = iavf_get_fdir_fltr_ids(adapter, cmd, (u32 *)rule_locs);\n\t\tbreak;\n\tcase ETHTOOL_GRXFH:\n\t\tret = iavf_get_adv_rss_hash_opt(adapter, cmd);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n \nstatic void iavf_get_channels(struct net_device *netdev,\n\t\t\t      struct ethtool_channels *ch)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tch->max_combined = adapter->vsi_res->num_queue_pairs;\n\n\tch->max_other = NONQ_VECS;\n\tch->other_count = NONQ_VECS;\n\n\tch->combined_count = adapter->num_active_queues;\n}\n\n \nstatic int iavf_set_channels(struct net_device *netdev,\n\t\t\t     struct ethtool_channels *ch)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tu32 num_req = ch->combined_count;\n\tint ret = 0;\n\n\tif ((adapter->vf_res->vf_cap_flags & VIRTCHNL_VF_OFFLOAD_ADQ) &&\n\t    adapter->num_tc) {\n\t\tdev_info(&adapter->pdev->dev, \"Cannot set channels since ADq is enabled.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (num_req == 0 || num_req > adapter->vsi_res->num_queue_pairs)\n\t\treturn -EINVAL;\n\n\tif (num_req == adapter->num_active_queues)\n\t\treturn 0;\n\n\tif (ch->rx_count || ch->tx_count || ch->other_count != NONQ_VECS)\n\t\treturn -EINVAL;\n\n\tadapter->num_req_queues = num_req;\n\tadapter->flags |= IAVF_FLAG_REINIT_ITR_NEEDED;\n\tiavf_schedule_reset(adapter, IAVF_FLAG_RESET_NEEDED);\n\n\tret = iavf_wait_for_reset(adapter);\n\tif (ret)\n\t\tnetdev_warn(netdev, \"Changing channel count timeout or interrupted waiting for reset\");\n\n\treturn ret;\n}\n\n \nstatic u32 iavf_get_rxfh_key_size(struct net_device *netdev)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\treturn adapter->rss_key_size;\n}\n\n \nstatic u32 iavf_get_rxfh_indir_size(struct net_device *netdev)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\n\treturn adapter->rss_lut_size;\n}\n\n \nstatic int iavf_get_rxfh(struct net_device *netdev, u32 *indir, u8 *key,\n\t\t\t u8 *hfunc)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tu16 i;\n\n\tif (hfunc)\n\t\t*hfunc = ETH_RSS_HASH_TOP;\n\tif (key)\n\t\tmemcpy(key, adapter->rss_key, adapter->rss_key_size);\n\n\tif (indir)\n\t\t \n\t\tfor (i = 0; i < adapter->rss_lut_size; i++)\n\t\t\tindir[i] = (u32)adapter->rss_lut[i];\n\n\treturn 0;\n}\n\n \nstatic int iavf_set_rxfh(struct net_device *netdev, const u32 *indir,\n\t\t\t const u8 *key, const u8 hfunc)\n{\n\tstruct iavf_adapter *adapter = netdev_priv(netdev);\n\tu16 i;\n\n\t \n\tif (hfunc != ETH_RSS_HASH_NO_CHANGE && hfunc != ETH_RSS_HASH_TOP)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!key && !indir)\n\t\treturn 0;\n\n\tif (key)\n\t\tmemcpy(adapter->rss_key, key, adapter->rss_key_size);\n\n\tif (indir) {\n\t\t \n\t\tfor (i = 0; i < adapter->rss_lut_size; i++)\n\t\t\tadapter->rss_lut[i] = (u8)(indir[i]);\n\t}\n\n\treturn iavf_config_rss(adapter);\n}\n\nstatic const struct ethtool_ops iavf_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS |\n\t\t\t\t     ETHTOOL_COALESCE_USE_ADAPTIVE,\n\t.get_drvinfo\t\t= iavf_get_drvinfo,\n\t.get_link\t\t= ethtool_op_get_link,\n\t.get_ringparam\t\t= iavf_get_ringparam,\n\t.set_ringparam\t\t= iavf_set_ringparam,\n\t.get_strings\t\t= iavf_get_strings,\n\t.get_ethtool_stats\t= iavf_get_ethtool_stats,\n\t.get_sset_count\t\t= iavf_get_sset_count,\n\t.get_priv_flags\t\t= iavf_get_priv_flags,\n\t.set_priv_flags\t\t= iavf_set_priv_flags,\n\t.get_msglevel\t\t= iavf_get_msglevel,\n\t.set_msglevel\t\t= iavf_set_msglevel,\n\t.get_coalesce\t\t= iavf_get_coalesce,\n\t.set_coalesce\t\t= iavf_set_coalesce,\n\t.get_per_queue_coalesce = iavf_get_per_queue_coalesce,\n\t.set_per_queue_coalesce = iavf_set_per_queue_coalesce,\n\t.set_rxnfc\t\t= iavf_set_rxnfc,\n\t.get_rxnfc\t\t= iavf_get_rxnfc,\n\t.get_rxfh_indir_size\t= iavf_get_rxfh_indir_size,\n\t.get_rxfh\t\t= iavf_get_rxfh,\n\t.set_rxfh\t\t= iavf_set_rxfh,\n\t.get_channels\t\t= iavf_get_channels,\n\t.set_channels\t\t= iavf_set_channels,\n\t.get_rxfh_key_size\t= iavf_get_rxfh_key_size,\n\t.get_link_ksettings\t= iavf_get_link_ksettings,\n};\n\n \nvoid iavf_set_ethtool_ops(struct net_device *netdev)\n{\n\tnetdev->ethtool_ops = &iavf_ethtool_ops;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}