{
  "module_name": "ixgbe.h",
  "hash_id": "21f7d8a184fc0c998ce229ba6da5778fa10eebc3c02bc9b360e7020002b6631a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ixgbe/ixgbe.h",
  "human_readable_source": " \n \n\n#ifndef _IXGBE_H_\n#define _IXGBE_H_\n\n#include <linux/bitops.h>\n#include <linux/types.h>\n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include <linux/cpumask.h>\n#include <linux/if_vlan.h>\n#include <linux/jiffies.h>\n#include <linux/phy.h>\n\n#include <linux/timecounter.h>\n#include <linux/net_tstamp.h>\n#include <linux/ptp_clock_kernel.h>\n\n#include \"ixgbe_type.h\"\n#include \"ixgbe_common.h\"\n#include \"ixgbe_dcb.h\"\n#if IS_ENABLED(CONFIG_FCOE)\n#define IXGBE_FCOE\n#include \"ixgbe_fcoe.h\"\n#endif  \n#ifdef CONFIG_IXGBE_DCA\n#include <linux/dca.h>\n#endif\n#include \"ixgbe_ipsec.h\"\n\n#include <net/xdp.h>\n\n \n#undef pr_fmt\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n \n#define IXGBE_DEFAULT_TXD\t\t    512\n#define IXGBE_DEFAULT_TX_WORK\t\t    256\n#define IXGBE_MAX_TXD_82598\t\t   4096\n#define IXGBE_MAX_TXD_82599\t\t   8192\n#define IXGBE_MAX_TXD_X540\t\t   8192\n#define IXGBE_MAX_TXD_X550\t\t  32768\n#define IXGBE_MIN_TXD\t\t\t     64\n\n#if (PAGE_SIZE < 8192)\n#define IXGBE_DEFAULT_RXD\t\t    512\n#else\n#define IXGBE_DEFAULT_RXD\t\t    128\n#endif\n#define IXGBE_MAX_RXD_82598\t\t   4096\n#define IXGBE_MAX_RXD_82599\t\t   8192\n#define IXGBE_MAX_RXD_X540\t\t   8192\n#define IXGBE_MAX_RXD_X550\t\t  32768\n#define IXGBE_MIN_RXD\t\t\t     64\n\n \n#define IXGBE_MIN_FCRTL\t\t\t   0x40\n#define IXGBE_MAX_FCRTL\t\t\t0x7FF80\n#define IXGBE_MIN_FCRTH\t\t\t  0x600\n#define IXGBE_MAX_FCRTH\t\t\t0x7FFF0\n#define IXGBE_DEFAULT_FCPAUSE\t\t 0xFFFF\n#define IXGBE_MIN_FCPAUSE\t\t      0\n#define IXGBE_MAX_FCPAUSE\t\t 0xFFFF\n\n \n#define IXGBE_RXBUFFER_256    256   \n#define IXGBE_RXBUFFER_1536  1536\n#define IXGBE_RXBUFFER_2K    2048\n#define IXGBE_RXBUFFER_3K    3072\n#define IXGBE_RXBUFFER_4K    4096\n#define IXGBE_MAX_RXBUFFER  16384   \n\n#define IXGBE_PKT_HDR_PAD   (ETH_HLEN + ETH_FCS_LEN + (VLAN_HLEN * 2))\n\n \n#if (PAGE_SIZE < 8192)\n#define IXGBE_MAX_2K_FRAME_BUILD_SKB (IXGBE_RXBUFFER_1536 - NET_IP_ALIGN)\n#define IXGBE_2K_TOO_SMALL_WITH_PADDING \\\n((NET_SKB_PAD + IXGBE_RXBUFFER_1536) > SKB_WITH_OVERHEAD(IXGBE_RXBUFFER_2K))\n\nstatic inline int ixgbe_compute_pad(int rx_buf_len)\n{\n\tint page_size, pad_size;\n\n\tpage_size = ALIGN(rx_buf_len, PAGE_SIZE / 2);\n\tpad_size = SKB_WITH_OVERHEAD(page_size) - rx_buf_len;\n\n\treturn pad_size;\n}\n\nstatic inline int ixgbe_skb_pad(void)\n{\n\tint rx_buf_len;\n\n\t \n\tif (IXGBE_2K_TOO_SMALL_WITH_PADDING)\n\t\trx_buf_len = IXGBE_RXBUFFER_3K + SKB_DATA_ALIGN(NET_IP_ALIGN);\n\telse\n\t\trx_buf_len = IXGBE_RXBUFFER_1536;\n\n\t \n\trx_buf_len -= NET_IP_ALIGN;\n\n\treturn ixgbe_compute_pad(rx_buf_len);\n}\n\n#define IXGBE_SKB_PAD\tixgbe_skb_pad()\n#else\n#define IXGBE_SKB_PAD\t(NET_SKB_PAD + NET_IP_ALIGN)\n#endif\n\n \n#define IXGBE_RX_HDR_SIZE IXGBE_RXBUFFER_256\n\n \n#define IXGBE_RX_BUFFER_WRITE\t16\t \n\n#define IXGBE_RX_DMA_ATTR \\\n\t(DMA_ATTR_SKIP_CPU_SYNC | DMA_ATTR_WEAK_ORDERING)\n\nenum ixgbe_tx_flags {\n\t \n\tIXGBE_TX_FLAGS_HW_VLAN\t= 0x01,\n\tIXGBE_TX_FLAGS_TSO\t= 0x02,\n\tIXGBE_TX_FLAGS_TSTAMP\t= 0x04,\n\n\t \n\tIXGBE_TX_FLAGS_CC\t= 0x08,\n\tIXGBE_TX_FLAGS_IPV4\t= 0x10,\n\tIXGBE_TX_FLAGS_CSUM\t= 0x20,\n\tIXGBE_TX_FLAGS_IPSEC\t= 0x40,\n\n\t \n\tIXGBE_TX_FLAGS_SW_VLAN\t= 0x80,\n\tIXGBE_TX_FLAGS_FCOE\t= 0x100,\n};\n\n \n#define IXGBE_TX_FLAGS_VLAN_MASK\t0xffff0000\n#define IXGBE_TX_FLAGS_VLAN_PRIO_MASK\t0xe0000000\n#define IXGBE_TX_FLAGS_VLAN_PRIO_SHIFT  29\n#define IXGBE_TX_FLAGS_VLAN_SHIFT\t16\n\n#define IXGBE_MAX_VF_MC_ENTRIES         30\n#define IXGBE_MAX_VF_FUNCTIONS          64\n#define IXGBE_MAX_VFTA_ENTRIES          128\n#define MAX_EMULATION_MAC_ADDRS         16\n#define IXGBE_MAX_PF_MACVLANS           15\n#define VMDQ_P(p)   ((p) + adapter->ring_feature[RING_F_VMDQ].offset)\n#define IXGBE_82599_VF_DEVICE_ID        0x10ED\n#define IXGBE_X540_VF_DEVICE_ID         0x1515\n\n#define UPDATE_VF_COUNTER_32bit(reg, last_counter, counter)\t\\\n\t{\t\t\t\t\t\t\t\\\n\t\tu32 current_counter = IXGBE_READ_REG(hw, reg);\t\\\n\t\tif (current_counter < last_counter)\t\t\\\n\t\t\tcounter += 0x100000000LL;\t\t\\\n\t\tlast_counter = current_counter;\t\t\t\\\n\t\tcounter &= 0xFFFFFFFF00000000LL;\t\t\\\n\t\tcounter |= current_counter;\t\t\t\\\n\t}\n\n#define UPDATE_VF_COUNTER_36bit(reg_lsb, reg_msb, last_counter, counter) \\\n\t{\t\t\t\t\t\t\t\t \\\n\t\tu64 current_counter_lsb = IXGBE_READ_REG(hw, reg_lsb);\t \\\n\t\tu64 current_counter_msb = IXGBE_READ_REG(hw, reg_msb);\t \\\n\t\tu64 current_counter = (current_counter_msb << 32) |\t \\\n\t\t\tcurrent_counter_lsb;\t\t\t\t \\\n\t\tif (current_counter < last_counter)\t\t\t \\\n\t\t\tcounter += 0x1000000000LL;\t\t\t \\\n\t\tlast_counter = current_counter;\t\t\t\t \\\n\t\tcounter &= 0xFFFFFFF000000000LL;\t\t\t \\\n\t\tcounter |= current_counter;\t\t\t\t \\\n\t}\n\nstruct vf_stats {\n\tu64 gprc;\n\tu64 gorc;\n\tu64 gptc;\n\tu64 gotc;\n\tu64 mprc;\n};\n\nstruct vf_data_storage {\n\tstruct pci_dev *vfdev;\n\tunsigned char vf_mac_addresses[ETH_ALEN];\n\tu16 vf_mc_hashes[IXGBE_MAX_VF_MC_ENTRIES];\n\tu16 num_vf_mc_hashes;\n\tbool clear_to_send;\n\tstruct vf_stats vfstats;\n\tstruct vf_stats last_vfstats;\n\tstruct vf_stats saved_rst_vfstats;\n\tbool pf_set_mac;\n\tu16 pf_vlan;  \n\tu16 pf_qos;\n\tu16 tx_rate;\n\tint link_enable;\n\tint link_state;\n\tu8 spoofchk_enabled;\n\tbool rss_query_enabled;\n\tu8 trusted;\n\tint xcast_mode;\n\tunsigned int vf_api;\n\tu8 primary_abort_count;\n};\n\nenum ixgbevf_xcast_modes {\n\tIXGBEVF_XCAST_MODE_NONE = 0,\n\tIXGBEVF_XCAST_MODE_MULTI,\n\tIXGBEVF_XCAST_MODE_ALLMULTI,\n\tIXGBEVF_XCAST_MODE_PROMISC,\n};\n\nstruct vf_macvlans {\n\tstruct list_head l;\n\tint vf;\n\tbool free;\n\tbool is_macvlan;\n\tu8 vf_macvlan[ETH_ALEN];\n};\n\n#define IXGBE_MAX_TXD_PWR\t14\n#define IXGBE_MAX_DATA_PER_TXD\t(1u << IXGBE_MAX_TXD_PWR)\n\n \n#define TXD_USE_COUNT(S) DIV_ROUND_UP((S), IXGBE_MAX_DATA_PER_TXD)\n#define DESC_NEEDED (MAX_SKB_FRAGS + 4)\n\n \nstruct ixgbe_tx_buffer {\n\tunion ixgbe_adv_tx_desc *next_to_watch;\n\tunsigned long time_stamp;\n\tunion {\n\t\tstruct sk_buff *skb;\n\t\tstruct xdp_frame *xdpf;\n\t};\n\tunsigned int bytecount;\n\tunsigned short gso_segs;\n\t__be16 protocol;\n\tDEFINE_DMA_UNMAP_ADDR(dma);\n\tDEFINE_DMA_UNMAP_LEN(len);\n\tu32 tx_flags;\n};\n\nstruct ixgbe_rx_buffer {\n\tunion {\n\t\tstruct {\n\t\t\tstruct sk_buff *skb;\n\t\t\tdma_addr_t dma;\n\t\t\tstruct page *page;\n\t\t\t__u32 page_offset;\n\t\t\t__u16 pagecnt_bias;\n\t\t};\n\t\tstruct {\n\t\t\tbool discard;\n\t\t\tstruct xdp_buff *xdp;\n\t\t};\n\t};\n};\n\nstruct ixgbe_queue_stats {\n\tu64 packets;\n\tu64 bytes;\n};\n\nstruct ixgbe_tx_queue_stats {\n\tu64 restart_queue;\n\tu64 tx_busy;\n\tu64 tx_done_old;\n};\n\nstruct ixgbe_rx_queue_stats {\n\tu64 rsc_count;\n\tu64 rsc_flush;\n\tu64 non_eop_descs;\n\tu64 alloc_rx_page;\n\tu64 alloc_rx_page_failed;\n\tu64 alloc_rx_buff_failed;\n\tu64 csum_err;\n};\n\n#define IXGBE_TS_HDR_LEN 8\n\nenum ixgbe_ring_state_t {\n\t__IXGBE_RX_3K_BUFFER,\n\t__IXGBE_RX_BUILD_SKB_ENABLED,\n\t__IXGBE_RX_RSC_ENABLED,\n\t__IXGBE_RX_CSUM_UDP_ZERO_ERR,\n\t__IXGBE_RX_FCOE,\n\t__IXGBE_TX_FDIR_INIT_DONE,\n\t__IXGBE_TX_XPS_INIT_DONE,\n\t__IXGBE_TX_DETECT_HANG,\n\t__IXGBE_HANG_CHECK_ARMED,\n\t__IXGBE_TX_XDP_RING,\n\t__IXGBE_TX_DISABLED,\n};\n\n#define ring_uses_build_skb(ring) \\\n\ttest_bit(__IXGBE_RX_BUILD_SKB_ENABLED, &(ring)->state)\n\nstruct ixgbe_fwd_adapter {\n\tunsigned long active_vlans[BITS_TO_LONGS(VLAN_N_VID)];\n\tstruct net_device *netdev;\n\tunsigned int tx_base_queue;\n\tunsigned int rx_base_queue;\n\tint pool;\n};\n\n#define check_for_tx_hang(ring) \\\n\ttest_bit(__IXGBE_TX_DETECT_HANG, &(ring)->state)\n#define set_check_for_tx_hang(ring) \\\n\tset_bit(__IXGBE_TX_DETECT_HANG, &(ring)->state)\n#define clear_check_for_tx_hang(ring) \\\n\tclear_bit(__IXGBE_TX_DETECT_HANG, &(ring)->state)\n#define ring_is_rsc_enabled(ring) \\\n\ttest_bit(__IXGBE_RX_RSC_ENABLED, &(ring)->state)\n#define set_ring_rsc_enabled(ring) \\\n\tset_bit(__IXGBE_RX_RSC_ENABLED, &(ring)->state)\n#define clear_ring_rsc_enabled(ring) \\\n\tclear_bit(__IXGBE_RX_RSC_ENABLED, &(ring)->state)\n#define ring_is_xdp(ring) \\\n\ttest_bit(__IXGBE_TX_XDP_RING, &(ring)->state)\n#define set_ring_xdp(ring) \\\n\tset_bit(__IXGBE_TX_XDP_RING, &(ring)->state)\n#define clear_ring_xdp(ring) \\\n\tclear_bit(__IXGBE_TX_XDP_RING, &(ring)->state)\nstruct ixgbe_ring {\n\tstruct ixgbe_ring *next;\t \n\tstruct ixgbe_q_vector *q_vector;  \n\tstruct net_device *netdev;\t \n\tstruct bpf_prog *xdp_prog;\n\tstruct device *dev;\t\t \n\tvoid *desc;\t\t\t \n\tunion {\n\t\tstruct ixgbe_tx_buffer *tx_buffer_info;\n\t\tstruct ixgbe_rx_buffer *rx_buffer_info;\n\t};\n\tunsigned long state;\n\tu8 __iomem *tail;\n\tdma_addr_t dma;\t\t\t \n\tunsigned int size;\t\t \n\n\tu16 count;\t\t\t \n\n\tu8 queue_index;  \n\tu8 reg_idx;\t\t\t \n\tu16 next_to_use;\n\tu16 next_to_clean;\n\n\tunsigned long last_rx_timestamp;\n\n\tunion {\n\t\tu16 next_to_alloc;\n\t\tstruct {\n\t\t\tu8 atr_sample_rate;\n\t\t\tu8 atr_count;\n\t\t};\n\t};\n\n\tu8 dcb_tc;\n\tstruct ixgbe_queue_stats stats;\n\tstruct u64_stats_sync syncp;\n\tunion {\n\t\tstruct ixgbe_tx_queue_stats tx_stats;\n\t\tstruct ixgbe_rx_queue_stats rx_stats;\n\t};\n\tu16 rx_offset;\n\tstruct xdp_rxq_info xdp_rxq;\n\tspinlock_t tx_lock;\t \n\tstruct xsk_buff_pool *xsk_pool;\n\tu16 ring_idx;\t\t \n\tu16 rx_buf_len;\n} ____cacheline_internodealigned_in_smp;\n\nenum ixgbe_ring_f_enum {\n\tRING_F_NONE = 0,\n\tRING_F_VMDQ,   \n\tRING_F_RSS,\n\tRING_F_FDIR,\n#ifdef IXGBE_FCOE\n\tRING_F_FCOE,\n#endif  \n\n\tRING_F_ARRAY_SIZE       \n};\n\n#define IXGBE_MAX_RSS_INDICES\t\t16\n#define IXGBE_MAX_RSS_INDICES_X550\t63\n#define IXGBE_MAX_VMDQ_INDICES\t\t64\n#define IXGBE_MAX_FDIR_INDICES\t\t63\t \n#define IXGBE_MAX_FCOE_INDICES\t\t8\n#define MAX_RX_QUEUES\t\t\t(IXGBE_MAX_FDIR_INDICES + 1)\n#define MAX_TX_QUEUES\t\t\t(IXGBE_MAX_FDIR_INDICES + 1)\n#define IXGBE_MAX_XDP_QS\t\t(IXGBE_MAX_FDIR_INDICES + 1)\n#define IXGBE_MAX_L2A_QUEUES\t\t4\n#define IXGBE_BAD_L2A_QUEUE\t\t3\n#define IXGBE_MAX_MACVLANS\t\t63\n\nDECLARE_STATIC_KEY_FALSE(ixgbe_xdp_locking_key);\n\nstruct ixgbe_ring_feature {\n\tu16 limit;\t \n\tu16 indices;\t \n\tu16 mask;\t \n\tu16 offset;\t \n} ____cacheline_internodealigned_in_smp;\n\n#define IXGBE_82599_VMDQ_8Q_MASK 0x78\n#define IXGBE_82599_VMDQ_4Q_MASK 0x7C\n#define IXGBE_82599_VMDQ_2Q_MASK 0x7E\n\n \nstatic inline unsigned int ixgbe_rx_bufsz(struct ixgbe_ring *ring)\n{\n\tif (test_bit(__IXGBE_RX_3K_BUFFER, &ring->state))\n\t\treturn IXGBE_RXBUFFER_3K;\n#if (PAGE_SIZE < 8192)\n\tif (ring_uses_build_skb(ring))\n\t\treturn IXGBE_MAX_2K_FRAME_BUILD_SKB;\n#endif\n\treturn IXGBE_RXBUFFER_2K;\n}\n\nstatic inline unsigned int ixgbe_rx_pg_order(struct ixgbe_ring *ring)\n{\n#if (PAGE_SIZE < 8192)\n\tif (test_bit(__IXGBE_RX_3K_BUFFER, &ring->state))\n\t\treturn 1;\n#endif\n\treturn 0;\n}\n#define ixgbe_rx_pg_size(_ring) (PAGE_SIZE << ixgbe_rx_pg_order(_ring))\n\n#define IXGBE_ITR_ADAPTIVE_MIN_INC\t2\n#define IXGBE_ITR_ADAPTIVE_MIN_USECS\t10\n#define IXGBE_ITR_ADAPTIVE_MAX_USECS\t126\n#define IXGBE_ITR_ADAPTIVE_LATENCY\t0x80\n#define IXGBE_ITR_ADAPTIVE_BULK\t\t0x00\n\nstruct ixgbe_ring_container {\n\tstruct ixgbe_ring *ring;\t \n\tunsigned long next_update;\t \n\tunsigned int total_bytes;\t \n\tunsigned int total_packets;\t \n\tu16 work_limit;\t\t\t \n\tu8 count;\t\t\t \n\tu8 itr;\t\t\t\t \n};\n\n \n#define ixgbe_for_each_ring(pos, head) \\\n\tfor (pos = (head).ring; pos != NULL; pos = pos->next)\n\n#define MAX_RX_PACKET_BUFFERS ((adapter->flags & IXGBE_FLAG_DCB_ENABLED) \\\n\t\t\t      ? 8 : 1)\n#define MAX_TX_PACKET_BUFFERS MAX_RX_PACKET_BUFFERS\n\n \nstruct ixgbe_q_vector {\n\tstruct ixgbe_adapter *adapter;\n#ifdef CONFIG_IXGBE_DCA\n\tint cpu;\t     \n#endif\n\tu16 v_idx;\t\t \n\tu16 itr;\t\t \n\tstruct ixgbe_ring_container rx, tx;\n\n\tstruct napi_struct napi;\n\tcpumask_t affinity_mask;\n\tint numa_node;\n\tstruct rcu_head rcu;\t \n\tchar name[IFNAMSIZ + 9];\n\n\t \n\tstruct ixgbe_ring ring[] ____cacheline_internodealigned_in_smp;\n};\n\n#ifdef CONFIG_IXGBE_HWMON\n\n#define IXGBE_HWMON_TYPE_LOC\t\t0\n#define IXGBE_HWMON_TYPE_TEMP\t\t1\n#define IXGBE_HWMON_TYPE_CAUTION\t2\n#define IXGBE_HWMON_TYPE_MAX\t\t3\n\nstruct hwmon_attr {\n\tstruct device_attribute dev_attr;\n\tstruct ixgbe_hw *hw;\n\tstruct ixgbe_thermal_diode_data *sensor;\n\tchar name[12];\n};\n\nstruct hwmon_buff {\n\tstruct attribute_group group;\n\tconst struct attribute_group *groups[2];\n\tstruct attribute *attrs[IXGBE_MAX_SENSORS * 4 + 1];\n\tstruct hwmon_attr hwmon_list[IXGBE_MAX_SENSORS * 4];\n\tunsigned int n_hwmon;\n};\n#endif  \n\n \n#define IXGBE_MIN_RSC_ITR\t24\n#define IXGBE_100K_ITR\t\t40\n#define IXGBE_20K_ITR\t\t200\n#define IXGBE_12K_ITR\t\t336\n\n \nstatic inline __le32 ixgbe_test_staterr(union ixgbe_adv_rx_desc *rx_desc,\n\t\t\t\t\tconst u32 stat_err_bits)\n{\n\treturn rx_desc->wb.upper.status_error & cpu_to_le32(stat_err_bits);\n}\n\nstatic inline u16 ixgbe_desc_unused(struct ixgbe_ring *ring)\n{\n\tu16 ntc = ring->next_to_clean;\n\tu16 ntu = ring->next_to_use;\n\n\treturn ((ntc > ntu) ? 0 : ring->count) + ntc - ntu - 1;\n}\n\n#define IXGBE_RX_DESC(R, i)\t    \\\n\t(&(((union ixgbe_adv_rx_desc *)((R)->desc))[i]))\n#define IXGBE_TX_DESC(R, i)\t    \\\n\t(&(((union ixgbe_adv_tx_desc *)((R)->desc))[i]))\n#define IXGBE_TX_CTXTDESC(R, i)\t    \\\n\t(&(((struct ixgbe_adv_tx_context_desc *)((R)->desc))[i]))\n\n#define IXGBE_MAX_JUMBO_FRAME_SIZE\t9728  \n#ifdef IXGBE_FCOE\n \n#define IXGBE_FCOE_JUMBO_FRAME_SIZE       3072\n#endif  \n\n#define OTHER_VECTOR 1\n#define NON_Q_VECTORS (OTHER_VECTOR)\n\n#define MAX_MSIX_VECTORS_82599 64\n#define MAX_Q_VECTORS_82599 64\n#define MAX_MSIX_VECTORS_82598 18\n#define MAX_Q_VECTORS_82598 16\n\nstruct ixgbe_mac_addr {\n\tu8 addr[ETH_ALEN];\n\tu16 pool;\n\tu16 state;  \n};\n\n#define IXGBE_MAC_STATE_DEFAULT\t\t0x1\n#define IXGBE_MAC_STATE_MODIFIED\t0x2\n#define IXGBE_MAC_STATE_IN_USE\t\t0x4\n\n#define MAX_Q_VECTORS MAX_Q_VECTORS_82599\n#define MAX_MSIX_COUNT MAX_MSIX_VECTORS_82599\n\n#define MIN_MSIX_Q_VECTORS 1\n#define MIN_MSIX_COUNT (MIN_MSIX_Q_VECTORS + NON_Q_VECTORS)\n\n \n#define IXGBE_TRY_LINK_TIMEOUT (4 * HZ)\n#define IXGBE_SFP_POLL_JIFFIES (2 * HZ)\t \n\n#define IXGBE_PRIMARY_ABORT_LIMIT\t5\n\n \nstruct ixgbe_adapter {\n\tunsigned long active_vlans[BITS_TO_LONGS(VLAN_N_VID)];\n\t \n\tstruct net_device *netdev;\n\tstruct bpf_prog *xdp_prog;\n\tstruct pci_dev *pdev;\n\tstruct mii_bus *mii_bus;\n\n\tunsigned long state;\n\n\t \n\tu32 flags;\n#define IXGBE_FLAG_MSI_ENABLED\t\t\tBIT(1)\n#define IXGBE_FLAG_MSIX_ENABLED\t\t\tBIT(3)\n#define IXGBE_FLAG_RX_1BUF_CAPABLE\t\tBIT(4)\n#define IXGBE_FLAG_RX_PS_CAPABLE\t\tBIT(5)\n#define IXGBE_FLAG_RX_PS_ENABLED\t\tBIT(6)\n#define IXGBE_FLAG_DCA_ENABLED\t\t\tBIT(8)\n#define IXGBE_FLAG_DCA_CAPABLE\t\t\tBIT(9)\n#define IXGBE_FLAG_IMIR_ENABLED\t\t\tBIT(10)\n#define IXGBE_FLAG_MQ_CAPABLE\t\t\tBIT(11)\n#define IXGBE_FLAG_DCB_ENABLED\t\t\tBIT(12)\n#define IXGBE_FLAG_VMDQ_CAPABLE\t\t\tBIT(13)\n#define IXGBE_FLAG_VMDQ_ENABLED\t\t\tBIT(14)\n#define IXGBE_FLAG_FAN_FAIL_CAPABLE\t\tBIT(15)\n#define IXGBE_FLAG_NEED_LINK_UPDATE\t\tBIT(16)\n#define IXGBE_FLAG_NEED_LINK_CONFIG\t\tBIT(17)\n#define IXGBE_FLAG_FDIR_HASH_CAPABLE\t\tBIT(18)\n#define IXGBE_FLAG_FDIR_PERFECT_CAPABLE\t\tBIT(19)\n#define IXGBE_FLAG_FCOE_CAPABLE\t\t\tBIT(20)\n#define IXGBE_FLAG_FCOE_ENABLED\t\t\tBIT(21)\n#define IXGBE_FLAG_SRIOV_CAPABLE\t\tBIT(22)\n#define IXGBE_FLAG_SRIOV_ENABLED\t\tBIT(23)\n#define IXGBE_FLAG_RX_HWTSTAMP_ENABLED\t\tBIT(25)\n#define IXGBE_FLAG_RX_HWTSTAMP_IN_REGISTER\tBIT(26)\n#define IXGBE_FLAG_DCB_CAPABLE\t\t\tBIT(27)\n\n\tu32 flags2;\n#define IXGBE_FLAG2_RSC_CAPABLE\t\t\tBIT(0)\n#define IXGBE_FLAG2_RSC_ENABLED\t\t\tBIT(1)\n#define IXGBE_FLAG2_TEMP_SENSOR_CAPABLE\t\tBIT(2)\n#define IXGBE_FLAG2_TEMP_SENSOR_EVENT\t\tBIT(3)\n#define IXGBE_FLAG2_SEARCH_FOR_SFP\t\tBIT(4)\n#define IXGBE_FLAG2_SFP_NEEDS_RESET\t\tBIT(5)\n#define IXGBE_FLAG2_FDIR_REQUIRES_REINIT\tBIT(7)\n#define IXGBE_FLAG2_RSS_FIELD_IPV4_UDP\t\tBIT(8)\n#define IXGBE_FLAG2_RSS_FIELD_IPV6_UDP\t\tBIT(9)\n#define IXGBE_FLAG2_PTP_PPS_ENABLED\t\tBIT(10)\n#define IXGBE_FLAG2_PHY_INTERRUPT\t\tBIT(11)\n#define IXGBE_FLAG2_VLAN_PROMISC\t\tBIT(13)\n#define IXGBE_FLAG2_EEE_CAPABLE\t\t\tBIT(14)\n#define IXGBE_FLAG2_EEE_ENABLED\t\t\tBIT(15)\n#define IXGBE_FLAG2_RX_LEGACY\t\t\tBIT(16)\n#define IXGBE_FLAG2_IPSEC_ENABLED\t\tBIT(17)\n#define IXGBE_FLAG2_VF_IPSEC_ENABLED\t\tBIT(18)\n#define IXGBE_FLAG2_AUTO_DISABLE_VF\t\tBIT(19)\n\n\t \n\tint num_tx_queues;\n\tu16 tx_itr_setting;\n\tu16 tx_work_limit;\n\tu64 tx_ipsec;\n\n\t \n\tint num_rx_queues;\n\tu16 rx_itr_setting;\n\tu64 rx_ipsec;\n\n\t \n\t__be16 vxlan_port;\n\t__be16 geneve_port;\n\n\t \n\tint num_xdp_queues;\n\tstruct ixgbe_ring *xdp_ring[IXGBE_MAX_XDP_QS];\n\tunsigned long *af_xdp_zc_qps;  \n\n\t \n\tstruct ixgbe_ring *tx_ring[MAX_TX_QUEUES] ____cacheline_aligned_in_smp;\n\n\tu64 restart_queue;\n\tu64 lsc_int;\n\tu32 tx_timeout_count;\n\n\t \n\tstruct ixgbe_ring *rx_ring[MAX_RX_QUEUES];\n\tint num_rx_pools;\t\t \n\tint num_rx_queues_per_pool;\t \n\tu64 hw_csum_rx_error;\n\tu64 hw_rx_no_dma_resources;\n\tu64 rsc_total_count;\n\tu64 rsc_total_flush;\n\tu64 non_eop_descs;\n\tu32 alloc_rx_page;\n\tu32 alloc_rx_page_failed;\n\tu32 alloc_rx_buff_failed;\n\n\tstruct ixgbe_q_vector *q_vector[MAX_Q_VECTORS];\n\n\t \n\tstruct ieee_pfc *ixgbe_ieee_pfc;\n\tstruct ieee_ets *ixgbe_ieee_ets;\n\tstruct ixgbe_dcb_config dcb_cfg;\n\tstruct ixgbe_dcb_config temp_dcb_cfg;\n\tu8 hw_tcs;\n\tu8 dcb_set_bitmap;\n\tu8 dcbx_cap;\n\tenum ixgbe_fc_mode last_lfc_mode;\n\n\tint num_q_vectors;\t \n\tint max_q_vectors;\t \n\tstruct ixgbe_ring_feature ring_feature[RING_F_ARRAY_SIZE];\n\tstruct msix_entry *msix_entries;\n\n\tu32 test_icr;\n\tstruct ixgbe_ring test_tx_ring;\n\tstruct ixgbe_ring test_rx_ring;\n\n\t \n\tstruct ixgbe_hw hw;\n\tu16 msg_enable;\n\tstruct ixgbe_hw_stats stats;\n\n\tu64 tx_busy;\n\tunsigned int tx_ring_count;\n\tunsigned int xdp_ring_count;\n\tunsigned int rx_ring_count;\n\n\tu32 link_speed;\n\tbool link_up;\n\tunsigned long sfp_poll_time;\n\tunsigned long link_check_timeout;\n\n\tstruct timer_list service_timer;\n\tstruct work_struct service_task;\n\n\tstruct hlist_head fdir_filter_list;\n\tunsigned long fdir_overflow;  \n\tunion ixgbe_atr_input fdir_mask;\n\tint fdir_filter_count;\n\tu32 fdir_pballoc;\n\tu32 atr_sample_rate;\n\tspinlock_t fdir_perfect_lock;\n\n#ifdef IXGBE_FCOE\n\tstruct ixgbe_fcoe fcoe;\n#endif  \n\tu8 __iomem *io_addr;  \n\tu32 wol;\n\n\tu16 bridge_mode;\n\n\tchar eeprom_id[NVM_VER_SIZE];\n\tu16 eeprom_cap;\n\n\tu32 interrupt_event;\n\tu32 led_reg;\n\n\tstruct ptp_clock *ptp_clock;\n\tstruct ptp_clock_info ptp_caps;\n\tstruct work_struct ptp_tx_work;\n\tstruct sk_buff *ptp_tx_skb;\n\tstruct hwtstamp_config tstamp_config;\n\tunsigned long ptp_tx_start;\n\tunsigned long last_overflow_check;\n\tunsigned long last_rx_ptp_check;\n\tunsigned long last_rx_timestamp;\n\tspinlock_t tmreg_lock;\n\tstruct cyclecounter hw_cc;\n\tstruct timecounter hw_tc;\n\tu32 base_incval;\n\tu32 tx_hwtstamp_timeouts;\n\tu32 tx_hwtstamp_skipped;\n\tu32 rx_hwtstamp_cleared;\n\tvoid (*ptp_setup_sdp)(struct ixgbe_adapter *);\n\n\t \n\tDECLARE_BITMAP(active_vfs, IXGBE_MAX_VF_FUNCTIONS);\n\tunsigned int num_vfs;\n\tstruct vf_data_storage *vfinfo;\n\tint vf_rate_link_speed;\n\tstruct vf_macvlans vf_mvs;\n\tstruct vf_macvlans *mv_list;\n\n\tu32 timer_event_accumulator;\n\tu32 vferr_refcount;\n\tstruct ixgbe_mac_addr *mac_table;\n\tstruct kobject *info_kobj;\n#ifdef CONFIG_IXGBE_HWMON\n\tstruct hwmon_buff *ixgbe_hwmon_buff;\n#endif  \n#ifdef CONFIG_DEBUG_FS\n\tstruct dentry *ixgbe_dbg_adapter;\n#endif  \n\n\tu8 default_up;\n\t \n\tDECLARE_BITMAP(fwd_bitmask, IXGBE_MAX_MACVLANS + 1);\n\n#define IXGBE_MAX_LINK_HANDLE 10\n\tstruct ixgbe_jump_table *jump_tables[IXGBE_MAX_LINK_HANDLE];\n\tunsigned long tables;\n\n \n#define IXGBE_MAX_RETA_ENTRIES 512\n\tu8 rss_indir_tbl[IXGBE_MAX_RETA_ENTRIES];\n\n#define IXGBE_RSS_KEY_SIZE     40   \n\tu32 *rss_key;\n\n#ifdef CONFIG_IXGBE_IPSEC\n\tstruct ixgbe_ipsec *ipsec;\n#endif  \n\tspinlock_t vfs_lock;\n};\n\nstatic inline int ixgbe_determine_xdp_q_idx(int cpu)\n{\n\tif (static_key_enabled(&ixgbe_xdp_locking_key))\n\t\treturn cpu % IXGBE_MAX_XDP_QS;\n\telse\n\t\treturn cpu;\n}\n\nstatic inline\nstruct ixgbe_ring *ixgbe_determine_xdp_ring(struct ixgbe_adapter *adapter)\n{\n\tint index = ixgbe_determine_xdp_q_idx(smp_processor_id());\n\n\treturn adapter->xdp_ring[index];\n}\n\nstatic inline u8 ixgbe_max_rss_indices(struct ixgbe_adapter *adapter)\n{\n\tswitch (adapter->hw.mac.type) {\n\tcase ixgbe_mac_82598EB:\n\tcase ixgbe_mac_82599EB:\n\tcase ixgbe_mac_X540:\n\t\treturn IXGBE_MAX_RSS_INDICES;\n\tcase ixgbe_mac_X550:\n\tcase ixgbe_mac_X550EM_x:\n\tcase ixgbe_mac_x550em_a:\n\t\treturn IXGBE_MAX_RSS_INDICES_X550;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstruct ixgbe_fdir_filter {\n\tstruct hlist_node fdir_node;\n\tunion ixgbe_atr_input filter;\n\tu16 sw_idx;\n\tu64 action;\n};\n\nenum ixgbe_state_t {\n\t__IXGBE_TESTING,\n\t__IXGBE_RESETTING,\n\t__IXGBE_DOWN,\n\t__IXGBE_DISABLED,\n\t__IXGBE_REMOVING,\n\t__IXGBE_SERVICE_SCHED,\n\t__IXGBE_SERVICE_INITED,\n\t__IXGBE_IN_SFP_INIT,\n\t__IXGBE_PTP_RUNNING,\n\t__IXGBE_PTP_TX_IN_PROGRESS,\n\t__IXGBE_RESET_REQUESTED,\n};\n\nstruct ixgbe_cb {\n\tunion {\t\t\t\t \n\t\tstruct sk_buff *head;\n\t\tstruct sk_buff *tail;\n\t};\n\tdma_addr_t dma;\n\tu16 append_cnt;\n\tbool page_released;\n};\n#define IXGBE_CB(skb) ((struct ixgbe_cb *)(skb)->cb)\n\nenum ixgbe_boards {\n\tboard_82598,\n\tboard_82599,\n\tboard_X540,\n\tboard_X550,\n\tboard_X550EM_x,\n\tboard_x550em_x_fw,\n\tboard_x550em_a,\n\tboard_x550em_a_fw,\n};\n\nextern const struct ixgbe_info ixgbe_82598_info;\nextern const struct ixgbe_info ixgbe_82599_info;\nextern const struct ixgbe_info ixgbe_X540_info;\nextern const struct ixgbe_info ixgbe_X550_info;\nextern const struct ixgbe_info ixgbe_X550EM_x_info;\nextern const struct ixgbe_info ixgbe_x550em_x_fw_info;\nextern const struct ixgbe_info ixgbe_x550em_a_info;\nextern const struct ixgbe_info ixgbe_x550em_a_fw_info;\n#ifdef CONFIG_IXGBE_DCB\nextern const struct dcbnl_rtnl_ops ixgbe_dcbnl_ops;\n#endif\n\nextern char ixgbe_driver_name[];\n#ifdef IXGBE_FCOE\nextern char ixgbe_default_device_descr[];\n#endif  \n\nint ixgbe_open(struct net_device *netdev);\nint ixgbe_close(struct net_device *netdev);\nvoid ixgbe_up(struct ixgbe_adapter *adapter);\nvoid ixgbe_down(struct ixgbe_adapter *adapter);\nvoid ixgbe_reinit_locked(struct ixgbe_adapter *adapter);\nvoid ixgbe_reset(struct ixgbe_adapter *adapter);\nvoid ixgbe_set_ethtool_ops(struct net_device *netdev);\nint ixgbe_setup_rx_resources(struct ixgbe_adapter *, struct ixgbe_ring *);\nint ixgbe_setup_tx_resources(struct ixgbe_ring *);\nvoid ixgbe_free_rx_resources(struct ixgbe_ring *);\nvoid ixgbe_free_tx_resources(struct ixgbe_ring *);\nvoid ixgbe_configure_rx_ring(struct ixgbe_adapter *, struct ixgbe_ring *);\nvoid ixgbe_configure_tx_ring(struct ixgbe_adapter *, struct ixgbe_ring *);\nvoid ixgbe_disable_rx(struct ixgbe_adapter *adapter);\nvoid ixgbe_disable_tx(struct ixgbe_adapter *adapter);\nvoid ixgbe_update_stats(struct ixgbe_adapter *adapter);\nint ixgbe_init_interrupt_scheme(struct ixgbe_adapter *adapter);\nbool ixgbe_wol_supported(struct ixgbe_adapter *adapter, u16 device_id,\n\t\t\t u16 subdevice_id);\n#ifdef CONFIG_PCI_IOV\nvoid ixgbe_full_sync_mac_table(struct ixgbe_adapter *adapter);\n#endif\nint ixgbe_add_mac_filter(struct ixgbe_adapter *adapter,\n\t\t\t const u8 *addr, u16 queue);\nint ixgbe_del_mac_filter(struct ixgbe_adapter *adapter,\n\t\t\t const u8 *addr, u16 queue);\nvoid ixgbe_update_pf_promisc_vlvf(struct ixgbe_adapter *adapter, u32 vid);\nvoid ixgbe_clear_interrupt_scheme(struct ixgbe_adapter *adapter);\nnetdev_tx_t ixgbe_xmit_frame_ring(struct sk_buff *, struct ixgbe_adapter *,\n\t\t\t\t  struct ixgbe_ring *);\nvoid ixgbe_alloc_rx_buffers(struct ixgbe_ring *, u16);\nvoid ixgbe_write_eitr(struct ixgbe_q_vector *);\nint ixgbe_poll(struct napi_struct *napi, int budget);\nint ethtool_ioctl(struct ifreq *ifr);\ns32 ixgbe_reinit_fdir_tables_82599(struct ixgbe_hw *hw);\ns32 ixgbe_init_fdir_signature_82599(struct ixgbe_hw *hw, u32 fdirctrl);\ns32 ixgbe_init_fdir_perfect_82599(struct ixgbe_hw *hw, u32 fdirctrl);\ns32 ixgbe_fdir_add_signature_filter_82599(struct ixgbe_hw *hw,\n\t\t\t\t\t  union ixgbe_atr_hash_dword input,\n\t\t\t\t\t  union ixgbe_atr_hash_dword common,\n\t\t\t\t\t  u8 queue);\ns32 ixgbe_fdir_set_input_mask_82599(struct ixgbe_hw *hw,\n\t\t\t\t    union ixgbe_atr_input *input_mask);\ns32 ixgbe_fdir_write_perfect_filter_82599(struct ixgbe_hw *hw,\n\t\t\t\t\t  union ixgbe_atr_input *input,\n\t\t\t\t\t  u16 soft_id, u8 queue);\ns32 ixgbe_fdir_erase_perfect_filter_82599(struct ixgbe_hw *hw,\n\t\t\t\t\t  union ixgbe_atr_input *input,\n\t\t\t\t\t  u16 soft_id);\nvoid ixgbe_atr_compute_perfect_hash_82599(union ixgbe_atr_input *input,\n\t\t\t\t\t  union ixgbe_atr_input *mask);\nint ixgbe_update_ethtool_fdir_entry(struct ixgbe_adapter *adapter,\n\t\t\t\t    struct ixgbe_fdir_filter *input,\n\t\t\t\t    u16 sw_idx);\nvoid ixgbe_set_rx_mode(struct net_device *netdev);\n#ifdef CONFIG_IXGBE_DCB\nvoid ixgbe_set_rx_drop_en(struct ixgbe_adapter *adapter);\n#endif\nint ixgbe_setup_tc(struct net_device *dev, u8 tc);\nvoid ixgbe_tx_ctxtdesc(struct ixgbe_ring *, u32, u32, u32, u32);\nvoid ixgbe_do_reset(struct net_device *netdev);\n#ifdef CONFIG_IXGBE_HWMON\nvoid ixgbe_sysfs_exit(struct ixgbe_adapter *adapter);\nint ixgbe_sysfs_init(struct ixgbe_adapter *adapter);\n#endif  \n#ifdef IXGBE_FCOE\nvoid ixgbe_configure_fcoe(struct ixgbe_adapter *adapter);\nint ixgbe_fso(struct ixgbe_ring *tx_ring, struct ixgbe_tx_buffer *first,\n\t      u8 *hdr_len);\nint ixgbe_fcoe_ddp(struct ixgbe_adapter *adapter,\n\t\t   union ixgbe_adv_rx_desc *rx_desc, struct sk_buff *skb);\nint ixgbe_fcoe_ddp_get(struct net_device *netdev, u16 xid,\n\t\t       struct scatterlist *sgl, unsigned int sgc);\nint ixgbe_fcoe_ddp_target(struct net_device *netdev, u16 xid,\n\t\t\t  struct scatterlist *sgl, unsigned int sgc);\nint ixgbe_fcoe_ddp_put(struct net_device *netdev, u16 xid);\nint ixgbe_setup_fcoe_ddp_resources(struct ixgbe_adapter *adapter);\nvoid ixgbe_free_fcoe_ddp_resources(struct ixgbe_adapter *adapter);\nint ixgbe_fcoe_enable(struct net_device *netdev);\nint ixgbe_fcoe_disable(struct net_device *netdev);\nint ixgbe_fcoe_get_wwn(struct net_device *netdev, u64 *wwn, int type);\nint ixgbe_fcoe_get_hbainfo(struct net_device *netdev,\n\t\t\t   struct netdev_fcoe_hbainfo *info);\nu8 ixgbe_fcoe_get_tc(struct ixgbe_adapter *adapter);\n#endif  \n#ifdef CONFIG_DEBUG_FS\nvoid ixgbe_dbg_adapter_init(struct ixgbe_adapter *adapter);\nvoid ixgbe_dbg_adapter_exit(struct ixgbe_adapter *adapter);\nvoid ixgbe_dbg_init(void);\nvoid ixgbe_dbg_exit(void);\n#else\nstatic inline void ixgbe_dbg_adapter_init(struct ixgbe_adapter *adapter) {}\nstatic inline void ixgbe_dbg_adapter_exit(struct ixgbe_adapter *adapter) {}\nstatic inline void ixgbe_dbg_init(void) {}\nstatic inline void ixgbe_dbg_exit(void) {}\n#endif  \nstatic inline struct netdev_queue *txring_txq(const struct ixgbe_ring *ring)\n{\n\treturn netdev_get_tx_queue(ring->netdev, ring->queue_index);\n}\n\nvoid ixgbe_ptp_init(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_suspend(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_stop(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_overflow_check(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_rx_hang(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_tx_hang(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_rx_pktstamp(struct ixgbe_q_vector *, struct sk_buff *);\nvoid ixgbe_ptp_rx_rgtstamp(struct ixgbe_q_vector *, struct sk_buff *skb);\nstatic inline void ixgbe_ptp_rx_hwtstamp(struct ixgbe_ring *rx_ring,\n\t\t\t\t\t union ixgbe_adv_rx_desc *rx_desc,\n\t\t\t\t\t struct sk_buff *skb)\n{\n\tif (unlikely(ixgbe_test_staterr(rx_desc, IXGBE_RXD_STAT_TSIP))) {\n\t\tixgbe_ptp_rx_pktstamp(rx_ring->q_vector, skb);\n\t\treturn;\n\t}\n\n\tif (unlikely(!ixgbe_test_staterr(rx_desc, IXGBE_RXDADV_STAT_TS)))\n\t\treturn;\n\n\tixgbe_ptp_rx_rgtstamp(rx_ring->q_vector, skb);\n\n\t \n\trx_ring->last_rx_timestamp = jiffies;\n}\n\nint ixgbe_ptp_set_ts_config(struct ixgbe_adapter *adapter, struct ifreq *ifr);\nint ixgbe_ptp_get_ts_config(struct ixgbe_adapter *adapter, struct ifreq *ifr);\nvoid ixgbe_ptp_start_cyclecounter(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_reset(struct ixgbe_adapter *adapter);\nvoid ixgbe_ptp_check_pps_event(struct ixgbe_adapter *adapter);\n#ifdef CONFIG_PCI_IOV\nvoid ixgbe_sriov_reinit(struct ixgbe_adapter *adapter);\n#endif\n\nnetdev_tx_t ixgbe_xmit_frame_ring(struct sk_buff *skb,\n\t\t\t\t  struct ixgbe_adapter *adapter,\n\t\t\t\t  struct ixgbe_ring *tx_ring);\nu32 ixgbe_rss_indir_tbl_entries(struct ixgbe_adapter *adapter);\nvoid ixgbe_store_key(struct ixgbe_adapter *adapter);\nvoid ixgbe_store_reta(struct ixgbe_adapter *adapter);\ns32 ixgbe_negotiate_fc(struct ixgbe_hw *hw, u32 adv_reg, u32 lp_reg,\n\t\t       u32 adv_sym, u32 adv_asm, u32 lp_sym, u32 lp_asm);\n#ifdef CONFIG_IXGBE_IPSEC\nvoid ixgbe_init_ipsec_offload(struct ixgbe_adapter *adapter);\nvoid ixgbe_stop_ipsec_offload(struct ixgbe_adapter *adapter);\nvoid ixgbe_ipsec_restore(struct ixgbe_adapter *adapter);\nvoid ixgbe_ipsec_rx(struct ixgbe_ring *rx_ring,\n\t\t    union ixgbe_adv_rx_desc *rx_desc,\n\t\t    struct sk_buff *skb);\nint ixgbe_ipsec_tx(struct ixgbe_ring *tx_ring, struct ixgbe_tx_buffer *first,\n\t\t   struct ixgbe_ipsec_tx_data *itd);\nvoid ixgbe_ipsec_vf_clear(struct ixgbe_adapter *adapter, u32 vf);\nint ixgbe_ipsec_vf_add_sa(struct ixgbe_adapter *adapter, u32 *mbuf, u32 vf);\nint ixgbe_ipsec_vf_del_sa(struct ixgbe_adapter *adapter, u32 *mbuf, u32 vf);\n#else\nstatic inline void ixgbe_init_ipsec_offload(struct ixgbe_adapter *adapter) { }\nstatic inline void ixgbe_stop_ipsec_offload(struct ixgbe_adapter *adapter) { }\nstatic inline void ixgbe_ipsec_restore(struct ixgbe_adapter *adapter) { }\nstatic inline void ixgbe_ipsec_rx(struct ixgbe_ring *rx_ring,\n\t\t\t\t  union ixgbe_adv_rx_desc *rx_desc,\n\t\t\t\t  struct sk_buff *skb) { }\nstatic inline int ixgbe_ipsec_tx(struct ixgbe_ring *tx_ring,\n\t\t\t\t struct ixgbe_tx_buffer *first,\n\t\t\t\t struct ixgbe_ipsec_tx_data *itd) { return 0; }\nstatic inline void ixgbe_ipsec_vf_clear(struct ixgbe_adapter *adapter,\n\t\t\t\t\tu32 vf) { }\nstatic inline int ixgbe_ipsec_vf_add_sa(struct ixgbe_adapter *adapter,\n\t\t\t\t\tu32 *mbuf, u32 vf) { return -EACCES; }\nstatic inline int ixgbe_ipsec_vf_del_sa(struct ixgbe_adapter *adapter,\n\t\t\t\t\tu32 *mbuf, u32 vf) { return -EACCES; }\n#endif  \n\nstatic inline bool ixgbe_enabled_xdp_adapter(struct ixgbe_adapter *adapter)\n{\n\treturn !!adapter->xdp_prog;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}