{
  "module_name": "ixgbe_lib.c",
  "hash_id": "59074be3c8b4976f0158ee4c8c92a0baf1973e6786132b079aec1f945a24e88b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ixgbe/ixgbe_lib.c",
  "human_readable_source": "\n \n\n#include \"ixgbe.h\"\n#include \"ixgbe_sriov.h\"\n\n#ifdef CONFIG_IXGBE_DCB\n \nstatic bool ixgbe_cache_ring_dcb_sriov(struct ixgbe_adapter *adapter)\n{\n#ifdef IXGBE_FCOE\n\tstruct ixgbe_ring_feature *fcoe = &adapter->ring_feature[RING_F_FCOE];\n#endif  \n\tstruct ixgbe_ring_feature *vmdq = &adapter->ring_feature[RING_F_VMDQ];\n\tint i;\n\tu16 reg_idx, pool;\n\tu8 tcs = adapter->hw_tcs;\n\n\t \n\tif (tcs <= 1)\n\t\treturn false;\n\n\t \n\tif (!(adapter->flags & IXGBE_FLAG_SRIOV_ENABLED))\n\t\treturn false;\n\n\t \n\treg_idx = vmdq->offset * __ALIGN_MASK(1, ~vmdq->mask);\n\tfor (i = 0, pool = 0; i < adapter->num_rx_queues; i++, reg_idx++) {\n\t\t \n\t\tif ((reg_idx & ~vmdq->mask) >= tcs) {\n\t\t\tpool++;\n\t\t\treg_idx = __ALIGN_MASK(reg_idx, ~vmdq->mask);\n\t\t}\n\t\tadapter->rx_ring[i]->reg_idx = reg_idx;\n\t\tadapter->rx_ring[i]->netdev = pool ? NULL : adapter->netdev;\n\t}\n\n\treg_idx = vmdq->offset * __ALIGN_MASK(1, ~vmdq->mask);\n\tfor (i = 0; i < adapter->num_tx_queues; i++, reg_idx++) {\n\t\t \n\t\tif ((reg_idx & ~vmdq->mask) >= tcs)\n\t\t\treg_idx = __ALIGN_MASK(reg_idx, ~vmdq->mask);\n\t\tadapter->tx_ring[i]->reg_idx = reg_idx;\n\t}\n\n#ifdef IXGBE_FCOE\n\t \n\tif (!(adapter->flags & IXGBE_FLAG_FCOE_ENABLED))\n\t\treturn true;\n\n\t \n\tif (fcoe->offset < tcs)\n\t\treturn true;\n\n\t \n\tif (fcoe->indices) {\n\t\tu16 queues_per_pool = __ALIGN_MASK(1, ~vmdq->mask);\n\t\tu8 fcoe_tc = ixgbe_fcoe_get_tc(adapter);\n\n\t\treg_idx = (vmdq->offset + vmdq->indices) * queues_per_pool;\n\t\tfor (i = fcoe->offset; i < adapter->num_rx_queues; i++) {\n\t\t\treg_idx = __ALIGN_MASK(reg_idx, ~vmdq->mask) + fcoe_tc;\n\t\t\tadapter->rx_ring[i]->reg_idx = reg_idx;\n\t\t\tadapter->rx_ring[i]->netdev = adapter->netdev;\n\t\t\treg_idx++;\n\t\t}\n\n\t\treg_idx = (vmdq->offset + vmdq->indices) * queues_per_pool;\n\t\tfor (i = fcoe->offset; i < adapter->num_tx_queues; i++) {\n\t\t\treg_idx = __ALIGN_MASK(reg_idx, ~vmdq->mask) + fcoe_tc;\n\t\t\tadapter->tx_ring[i]->reg_idx = reg_idx;\n\t\t\treg_idx++;\n\t\t}\n\t}\n\n#endif  \n\treturn true;\n}\n\n \nstatic void ixgbe_get_first_reg_idx(struct ixgbe_adapter *adapter, u8 tc,\n\t\t\t\t    unsigned int *tx, unsigned int *rx)\n{\n\tstruct ixgbe_hw *hw = &adapter->hw;\n\tu8 num_tcs = adapter->hw_tcs;\n\n\t*tx = 0;\n\t*rx = 0;\n\n\tswitch (hw->mac.type) {\n\tcase ixgbe_mac_82598EB:\n\t\t \n\t\t*tx = tc << 2;  \n\t\t*rx = tc << 3;  \n\t\tbreak;\n\tcase ixgbe_mac_82599EB:\n\tcase ixgbe_mac_X540:\n\tcase ixgbe_mac_X550:\n\tcase ixgbe_mac_X550EM_x:\n\tcase ixgbe_mac_x550em_a:\n\t\tif (num_tcs > 4) {\n\t\t\t \n\t\t\t*rx = tc << 4;\n\t\t\tif (tc < 3)\n\t\t\t\t*tx = tc << 5;\t\t \n\t\t\telse if (tc < 5)\n\t\t\t\t*tx = (tc + 2) << 4;\t \n\t\t\telse\n\t\t\t\t*tx = (tc + 8) << 3;\t \n\t\t} else {\n\t\t\t \n\t\t\t*rx = tc << 5;\n\t\t\tif (tc < 2)\n\t\t\t\t*tx = tc << 6;\t\t \n\t\t\telse\n\t\t\t\t*tx = (tc + 4) << 4;\t \n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nstatic bool ixgbe_cache_ring_dcb(struct ixgbe_adapter *adapter)\n{\n\tu8 num_tcs = adapter->hw_tcs;\n\tunsigned int tx_idx, rx_idx;\n\tint tc, offset, rss_i, i;\n\n\t \n\tif (num_tcs <= 1)\n\t\treturn false;\n\n\trss_i = adapter->ring_feature[RING_F_RSS].indices;\n\n\tfor (tc = 0, offset = 0; tc < num_tcs; tc++, offset += rss_i) {\n\t\tixgbe_get_first_reg_idx(adapter, tc, &tx_idx, &rx_idx);\n\t\tfor (i = 0; i < rss_i; i++, tx_idx++, rx_idx++) {\n\t\t\tadapter->tx_ring[offset + i]->reg_idx = tx_idx;\n\t\t\tadapter->rx_ring[offset + i]->reg_idx = rx_idx;\n\t\t\tadapter->rx_ring[offset + i]->netdev = adapter->netdev;\n\t\t\tadapter->tx_ring[offset + i]->dcb_tc = tc;\n\t\t\tadapter->rx_ring[offset + i]->dcb_tc = tc;\n\t\t}\n\t}\n\n\treturn true;\n}\n\n#endif\n \nstatic bool ixgbe_cache_ring_sriov(struct ixgbe_adapter *adapter)\n{\n#ifdef IXGBE_FCOE\n\tstruct ixgbe_ring_feature *fcoe = &adapter->ring_feature[RING_F_FCOE];\n#endif  \n\tstruct ixgbe_ring_feature *vmdq = &adapter->ring_feature[RING_F_VMDQ];\n\tstruct ixgbe_ring_feature *rss = &adapter->ring_feature[RING_F_RSS];\n\tu16 reg_idx, pool;\n\tint i;\n\n\t \n\tif (!(adapter->flags & IXGBE_FLAG_VMDQ_ENABLED))\n\t\treturn false;\n\n\t \n\tpool = 0;\n\treg_idx = vmdq->offset * __ALIGN_MASK(1, ~vmdq->mask);\n\tfor (i = 0; i < adapter->num_rx_queues; i++, reg_idx++) {\n#ifdef IXGBE_FCOE\n\t\t \n\t\tif (fcoe->offset && (i > fcoe->offset))\n\t\t\tbreak;\n#endif\n\t\t \n\t\tif ((reg_idx & ~vmdq->mask) >= rss->indices) {\n\t\t\tpool++;\n\t\t\treg_idx = __ALIGN_MASK(reg_idx, ~vmdq->mask);\n\t\t}\n\t\tadapter->rx_ring[i]->reg_idx = reg_idx;\n\t\tadapter->rx_ring[i]->netdev = pool ? NULL : adapter->netdev;\n\t}\n\n#ifdef IXGBE_FCOE\n\t \n\tfor (; i < adapter->num_rx_queues; i++, reg_idx++) {\n\t\tadapter->rx_ring[i]->reg_idx = reg_idx;\n\t\tadapter->rx_ring[i]->netdev = adapter->netdev;\n\t}\n\n#endif\n\treg_idx = vmdq->offset * __ALIGN_MASK(1, ~vmdq->mask);\n\tfor (i = 0; i < adapter->num_tx_queues; i++, reg_idx++) {\n#ifdef IXGBE_FCOE\n\t\t \n\t\tif (fcoe->offset && (i > fcoe->offset))\n\t\t\tbreak;\n#endif\n\t\t \n\t\tif ((reg_idx & rss->mask) >= rss->indices)\n\t\t\treg_idx = __ALIGN_MASK(reg_idx, ~vmdq->mask);\n\t\tadapter->tx_ring[i]->reg_idx = reg_idx;\n\t}\n\n#ifdef IXGBE_FCOE\n\t \n\tfor (; i < adapter->num_tx_queues; i++, reg_idx++)\n\t\tadapter->tx_ring[i]->reg_idx = reg_idx;\n\n#endif\n\n\treturn true;\n}\n\n \nstatic bool ixgbe_cache_ring_rss(struct ixgbe_adapter *adapter)\n{\n\tint i, reg_idx;\n\n\tfor (i = 0; i < adapter->num_rx_queues; i++) {\n\t\tadapter->rx_ring[i]->reg_idx = i;\n\t\tadapter->rx_ring[i]->netdev = adapter->netdev;\n\t}\n\tfor (i = 0, reg_idx = 0; i < adapter->num_tx_queues; i++, reg_idx++)\n\t\tadapter->tx_ring[i]->reg_idx = reg_idx;\n\tfor (i = 0; i < adapter->num_xdp_queues; i++, reg_idx++)\n\t\tadapter->xdp_ring[i]->reg_idx = reg_idx;\n\n\treturn true;\n}\n\n \nstatic void ixgbe_cache_ring_register(struct ixgbe_adapter *adapter)\n{\n\t \n\tadapter->rx_ring[0]->reg_idx = 0;\n\tadapter->tx_ring[0]->reg_idx = 0;\n\n#ifdef CONFIG_IXGBE_DCB\n\tif (ixgbe_cache_ring_dcb_sriov(adapter))\n\t\treturn;\n\n\tif (ixgbe_cache_ring_dcb(adapter))\n\t\treturn;\n\n#endif\n\tif (ixgbe_cache_ring_sriov(adapter))\n\t\treturn;\n\n\tixgbe_cache_ring_rss(adapter);\n}\n\nstatic int ixgbe_xdp_queues(struct ixgbe_adapter *adapter)\n{\n\tint queues;\n\n\tqueues = min_t(int, IXGBE_MAX_XDP_QS, nr_cpu_ids);\n\treturn adapter->xdp_prog ? queues : 0;\n}\n\n#define IXGBE_RSS_64Q_MASK\t0x3F\n#define IXGBE_RSS_16Q_MASK\t0xF\n#define IXGBE_RSS_8Q_MASK\t0x7\n#define IXGBE_RSS_4Q_MASK\t0x3\n#define IXGBE_RSS_2Q_MASK\t0x1\n#define IXGBE_RSS_DISABLED_MASK\t0x0\n\n#ifdef CONFIG_IXGBE_DCB\n \nstatic bool ixgbe_set_dcb_sriov_queues(struct ixgbe_adapter *adapter)\n{\n\tint i;\n\tu16 vmdq_i = adapter->ring_feature[RING_F_VMDQ].limit;\n\tu16 vmdq_m = 0;\n#ifdef IXGBE_FCOE\n\tu16 fcoe_i = 0;\n#endif\n\tu8 tcs = adapter->hw_tcs;\n\n\t \n\tif (tcs <= 1)\n\t\treturn false;\n\n\t \n\tif (!(adapter->flags & IXGBE_FLAG_SRIOV_ENABLED))\n\t\treturn false;\n\n\t \n\tvmdq_i = min_t(u16, vmdq_i, MAX_TX_QUEUES / tcs);\n\n\t \n\tvmdq_i += adapter->ring_feature[RING_F_VMDQ].offset;\n\n\t \n\tif (tcs > 4) {\n\t\tvmdq_i = min_t(u16, vmdq_i, 16);\n\t\tvmdq_m = IXGBE_82599_VMDQ_8Q_MASK;\n\t \n\t} else {\n\t\tvmdq_i = min_t(u16, vmdq_i, 32);\n\t\tvmdq_m = IXGBE_82599_VMDQ_4Q_MASK;\n\t}\n\n#ifdef IXGBE_FCOE\n\t \n\tfcoe_i = (128 / __ALIGN_MASK(1, ~vmdq_m)) - vmdq_i;\n\n#endif\n\t \n\tvmdq_i -= adapter->ring_feature[RING_F_VMDQ].offset;\n\n\t \n\tadapter->ring_feature[RING_F_VMDQ].indices = vmdq_i;\n\tadapter->ring_feature[RING_F_VMDQ].mask = vmdq_m;\n\n\t \n\tadapter->ring_feature[RING_F_RSS].indices = 1;\n\tadapter->ring_feature[RING_F_RSS].mask = IXGBE_RSS_DISABLED_MASK;\n\n\t \n\tadapter->flags &= ~IXGBE_FLAG_FDIR_HASH_CAPABLE;\n\n\tadapter->num_rx_pools = vmdq_i;\n\tadapter->num_rx_queues_per_pool = tcs;\n\n\tadapter->num_tx_queues = vmdq_i * tcs;\n\tadapter->num_xdp_queues = 0;\n\tadapter->num_rx_queues = vmdq_i * tcs;\n\n#ifdef IXGBE_FCOE\n\tif (adapter->flags & IXGBE_FLAG_FCOE_ENABLED) {\n\t\tstruct ixgbe_ring_feature *fcoe;\n\n\t\tfcoe = &adapter->ring_feature[RING_F_FCOE];\n\n\t\t \n\t\tfcoe_i = min_t(u16, fcoe_i, fcoe->limit);\n\n\t\tif (fcoe_i) {\n\t\t\t \n\t\t\tfcoe->indices = fcoe_i;\n\t\t\tfcoe->offset = vmdq_i * tcs;\n\n\t\t\t \n\t\t\tadapter->num_tx_queues += fcoe_i;\n\t\t\tadapter->num_rx_queues += fcoe_i;\n\t\t} else if (tcs > 1) {\n\t\t\t \n\t\t\tfcoe->indices = 1;\n\t\t\tfcoe->offset = ixgbe_fcoe_get_tc(adapter);\n\t\t} else {\n\t\t\tadapter->flags &= ~IXGBE_FLAG_FCOE_ENABLED;\n\n\t\t\tfcoe->indices = 0;\n\t\t\tfcoe->offset = 0;\n\t\t}\n\t}\n\n#endif  \n\t \n\tfor (i = 0; i < tcs; i++)\n\t\tnetdev_set_tc_queue(adapter->netdev, i, 1, i);\n\n\treturn true;\n}\n\nstatic bool ixgbe_set_dcb_queues(struct ixgbe_adapter *adapter)\n{\n\tstruct net_device *dev = adapter->netdev;\n\tstruct ixgbe_ring_feature *f;\n\tint rss_i, rss_m, i;\n\tint tcs;\n\n\t \n\ttcs = adapter->hw_tcs;\n\n\t \n\tif (tcs <= 1)\n\t\treturn false;\n\n\t \n\trss_i = dev->num_tx_queues / tcs;\n\tif (adapter->hw.mac.type == ixgbe_mac_82598EB) {\n\t\t \n\t\trss_i = min_t(u16, rss_i, 4);\n\t\trss_m = IXGBE_RSS_4Q_MASK;\n\t} else if (tcs > 4) {\n\t\t \n\t\trss_i = min_t(u16, rss_i, 8);\n\t\trss_m = IXGBE_RSS_8Q_MASK;\n\t} else {\n\t\t \n\t\trss_i = min_t(u16, rss_i, 16);\n\t\trss_m = IXGBE_RSS_16Q_MASK;\n\t}\n\n\t \n\tf = &adapter->ring_feature[RING_F_RSS];\n\trss_i = min_t(int, rss_i, f->limit);\n\tf->indices = rss_i;\n\tf->mask = rss_m;\n\n\t \n\tadapter->flags &= ~IXGBE_FLAG_FDIR_HASH_CAPABLE;\n\n#ifdef IXGBE_FCOE\n\t \n\tif (adapter->flags & IXGBE_FLAG_FCOE_ENABLED) {\n\t\tu8 tc = ixgbe_fcoe_get_tc(adapter);\n\n\t\tf = &adapter->ring_feature[RING_F_FCOE];\n\t\tf->indices = min_t(u16, rss_i, f->limit);\n\t\tf->offset = rss_i * tc;\n\t}\n\n#endif  \n\tfor (i = 0; i < tcs; i++)\n\t\tnetdev_set_tc_queue(dev, i, rss_i, rss_i * i);\n\n\tadapter->num_tx_queues = rss_i * tcs;\n\tadapter->num_xdp_queues = 0;\n\tadapter->num_rx_queues = rss_i * tcs;\n\n\treturn true;\n}\n\n#endif\n \nstatic bool ixgbe_set_sriov_queues(struct ixgbe_adapter *adapter)\n{\n\tu16 vmdq_i = adapter->ring_feature[RING_F_VMDQ].limit;\n\tu16 vmdq_m = 0;\n\tu16 rss_i = adapter->ring_feature[RING_F_RSS].limit;\n\tu16 rss_m = IXGBE_RSS_DISABLED_MASK;\n#ifdef IXGBE_FCOE\n\tu16 fcoe_i = 0;\n#endif\n\n\t \n\tif (!(adapter->flags & IXGBE_FLAG_SRIOV_ENABLED))\n\t\treturn false;\n\n\t \n\trss_i = min_t(u16, rss_i, MAX_TX_QUEUES / vmdq_i);\n\n\t \n\tvmdq_i += adapter->ring_feature[RING_F_VMDQ].offset;\n\n\t \n\tvmdq_i = min_t(u16, IXGBE_MAX_VMDQ_INDICES, vmdq_i);\n\n\t \n\tif (vmdq_i > 32) {\n\t\tvmdq_m = IXGBE_82599_VMDQ_2Q_MASK;\n\t\trss_m = IXGBE_RSS_2Q_MASK;\n\t\trss_i = min_t(u16, rss_i, 2);\n\t \n\t} else {\n\t\tvmdq_m = IXGBE_82599_VMDQ_4Q_MASK;\n\t\trss_m = IXGBE_RSS_4Q_MASK;\n\t\t \n\t\trss_i = (rss_i > 3) ? 4 : (rss_i > 1) ? 2 : 1;\n\t}\n\n#ifdef IXGBE_FCOE\n\t \n\tfcoe_i = 128 - (vmdq_i * __ALIGN_MASK(1, ~vmdq_m));\n\n#endif\n\t \n\tvmdq_i -= adapter->ring_feature[RING_F_VMDQ].offset;\n\n\t \n\tadapter->ring_feature[RING_F_VMDQ].indices = vmdq_i;\n\tadapter->ring_feature[RING_F_VMDQ].mask = vmdq_m;\n\n\t \n\tadapter->ring_feature[RING_F_RSS].indices = rss_i;\n\tadapter->ring_feature[RING_F_RSS].mask = rss_m;\n\n\tadapter->num_rx_pools = vmdq_i;\n\tadapter->num_rx_queues_per_pool = rss_i;\n\n\tadapter->num_rx_queues = vmdq_i * rss_i;\n\tadapter->num_tx_queues = vmdq_i * rss_i;\n\tadapter->num_xdp_queues = 0;\n\n\t \n\tadapter->flags &= ~IXGBE_FLAG_FDIR_HASH_CAPABLE;\n\n#ifdef IXGBE_FCOE\n\t \n\tif (adapter->flags & IXGBE_FLAG_FCOE_ENABLED) {\n\t\tstruct ixgbe_ring_feature *fcoe;\n\n\t\tfcoe = &adapter->ring_feature[RING_F_FCOE];\n\n\t\t \n\t\tfcoe_i = min_t(u16, fcoe_i, fcoe->limit);\n\n\t\tif (vmdq_i > 1 && fcoe_i) {\n\t\t\t \n\t\t\tfcoe->indices = fcoe_i;\n\t\t\tfcoe->offset = vmdq_i * rss_i;\n\t\t} else {\n\t\t\t \n\t\t\tfcoe_i = min_t(u16, fcoe_i + rss_i, num_online_cpus());\n\n\t\t\t \n\t\t\tif (!(adapter->flags & IXGBE_FLAG_MSIX_ENABLED))\n\t\t\t\tfcoe_i = rss_i;\n\n\t\t\t \n\t\t\tfcoe->indices = min_t(u16, fcoe_i, fcoe->limit);\n\t\t\tfcoe->offset = fcoe_i - fcoe->indices;\n\n\t\t\tfcoe_i -= rss_i;\n\t\t}\n\n\t\t \n\t\tadapter->num_tx_queues += fcoe_i;\n\t\tadapter->num_rx_queues += fcoe_i;\n\t}\n\n#endif\n\t \n\tif (vmdq_i > 1)\n\t\tnetdev_set_num_tc(adapter->netdev, 1);\n\n\t \n\tnetdev_set_tc_queue(adapter->netdev, 0,\n\t\t\t    adapter->num_rx_queues_per_pool, 0);\n\n\treturn true;\n}\n\n \nstatic bool ixgbe_set_rss_queues(struct ixgbe_adapter *adapter)\n{\n\tstruct ixgbe_hw *hw = &adapter->hw;\n\tstruct ixgbe_ring_feature *f;\n\tu16 rss_i;\n\n\t \n\tf = &adapter->ring_feature[RING_F_RSS];\n\trss_i = f->limit;\n\n\tf->indices = rss_i;\n\n\tif (hw->mac.type < ixgbe_mac_X550)\n\t\tf->mask = IXGBE_RSS_16Q_MASK;\n\telse\n\t\tf->mask = IXGBE_RSS_64Q_MASK;\n\n\t \n\tadapter->flags &= ~IXGBE_FLAG_FDIR_HASH_CAPABLE;\n\n\t \n\tif (rss_i > 1 && adapter->atr_sample_rate) {\n\t\tf = &adapter->ring_feature[RING_F_FDIR];\n\n\t\trss_i = f->indices = f->limit;\n\n\t\tif (!(adapter->flags & IXGBE_FLAG_FDIR_PERFECT_CAPABLE))\n\t\t\tadapter->flags |= IXGBE_FLAG_FDIR_HASH_CAPABLE;\n\t}\n\n#ifdef IXGBE_FCOE\n\t \n\tif (adapter->flags & IXGBE_FLAG_FCOE_ENABLED) {\n\t\tstruct net_device *dev = adapter->netdev;\n\t\tu16 fcoe_i;\n\n\t\tf = &adapter->ring_feature[RING_F_FCOE];\n\n\t\t \n\t\tfcoe_i = min_t(u16, f->limit + rss_i, num_online_cpus());\n\t\tfcoe_i = min_t(u16, fcoe_i, dev->num_tx_queues);\n\n\t\t \n\t\tif (!(adapter->flags & IXGBE_FLAG_MSIX_ENABLED))\n\t\t\tfcoe_i = rss_i;\n\n\t\t \n\t\tf->indices = min_t(u16, fcoe_i, f->limit);\n\t\tf->offset = fcoe_i - f->indices;\n\t\trss_i = max_t(u16, fcoe_i, rss_i);\n\t}\n\n#endif  \n\tadapter->num_rx_queues = rss_i;\n\tadapter->num_tx_queues = rss_i;\n\tadapter->num_xdp_queues = ixgbe_xdp_queues(adapter);\n\n\treturn true;\n}\n\n \nstatic void ixgbe_set_num_queues(struct ixgbe_adapter *adapter)\n{\n\t \n\tadapter->num_rx_queues = 1;\n\tadapter->num_tx_queues = 1;\n\tadapter->num_xdp_queues = 0;\n\tadapter->num_rx_pools = 1;\n\tadapter->num_rx_queues_per_pool = 1;\n\n#ifdef CONFIG_IXGBE_DCB\n\tif (ixgbe_set_dcb_sriov_queues(adapter))\n\t\treturn;\n\n\tif (ixgbe_set_dcb_queues(adapter))\n\t\treturn;\n\n#endif\n\tif (ixgbe_set_sriov_queues(adapter))\n\t\treturn;\n\n\tixgbe_set_rss_queues(adapter);\n}\n\n \nstatic int ixgbe_acquire_msix_vectors(struct ixgbe_adapter *adapter)\n{\n\tstruct ixgbe_hw *hw = &adapter->hw;\n\tint i, vectors, vector_threshold;\n\n\t \n\tvectors = max(adapter->num_rx_queues, adapter->num_tx_queues);\n\tvectors = max(vectors, adapter->num_xdp_queues);\n\n\t \n\tvectors = min_t(int, vectors, num_online_cpus());\n\n\t \n\tvectors += NON_Q_VECTORS;\n\n\t \n\tvectors = min_t(int, vectors, hw->mac.max_msix_vectors);\n\n\t \n\tvector_threshold = MIN_MSIX_COUNT;\n\n\tadapter->msix_entries = kcalloc(vectors,\n\t\t\t\t\tsizeof(struct msix_entry),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!adapter->msix_entries)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < vectors; i++)\n\t\tadapter->msix_entries[i].entry = i;\n\n\tvectors = pci_enable_msix_range(adapter->pdev, adapter->msix_entries,\n\t\t\t\t\tvector_threshold, vectors);\n\n\tif (vectors < 0) {\n\t\t \n\t\te_dev_warn(\"Failed to allocate MSI-X interrupts. Err: %d\\n\",\n\t\t\t   vectors);\n\n\t\tadapter->flags &= ~IXGBE_FLAG_MSIX_ENABLED;\n\t\tkfree(adapter->msix_entries);\n\t\tadapter->msix_entries = NULL;\n\n\t\treturn vectors;\n\t}\n\n\t \n\tadapter->flags |= IXGBE_FLAG_MSIX_ENABLED;\n\n\t \n\tvectors -= NON_Q_VECTORS;\n\tadapter->num_q_vectors = min_t(int, vectors, adapter->max_q_vectors);\n\n\treturn 0;\n}\n\nstatic void ixgbe_add_ring(struct ixgbe_ring *ring,\n\t\t\t   struct ixgbe_ring_container *head)\n{\n\tring->next = head->ring;\n\thead->ring = ring;\n\thead->count++;\n\thead->next_update = jiffies + 1;\n}\n\n \nstatic int ixgbe_alloc_q_vector(struct ixgbe_adapter *adapter,\n\t\t\t\tint v_count, int v_idx,\n\t\t\t\tint txr_count, int txr_idx,\n\t\t\t\tint xdp_count, int xdp_idx,\n\t\t\t\tint rxr_count, int rxr_idx)\n{\n\tint node = dev_to_node(&adapter->pdev->dev);\n\tstruct ixgbe_q_vector *q_vector;\n\tstruct ixgbe_ring *ring;\n\tint cpu = -1;\n\tint ring_count;\n\tu8 tcs = adapter->hw_tcs;\n\n\tring_count = txr_count + rxr_count + xdp_count;\n\n\t \n\tif ((tcs <= 1) && !(adapter->flags & IXGBE_FLAG_SRIOV_ENABLED)) {\n\t\tu16 rss_i = adapter->ring_feature[RING_F_RSS].indices;\n\t\tif (rss_i > 1 && adapter->atr_sample_rate) {\n\t\t\tcpu = cpumask_local_spread(v_idx, node);\n\t\t\tnode = cpu_to_node(cpu);\n\t\t}\n\t}\n\n\t \n\tq_vector = kzalloc_node(struct_size(q_vector, ring, ring_count),\n\t\t\t\tGFP_KERNEL, node);\n\tif (!q_vector)\n\t\tq_vector = kzalloc(struct_size(q_vector, ring, ring_count),\n\t\t\t\t   GFP_KERNEL);\n\tif (!q_vector)\n\t\treturn -ENOMEM;\n\n\t \n\tif (cpu != -1)\n\t\tcpumask_set_cpu(cpu, &q_vector->affinity_mask);\n\tq_vector->numa_node = node;\n\n#ifdef CONFIG_IXGBE_DCA\n\t \n\tq_vector->cpu = -1;\n\n#endif\n\t \n\tnetif_napi_add(adapter->netdev, &q_vector->napi, ixgbe_poll);\n\n\t \n\tadapter->q_vector[v_idx] = q_vector;\n\tq_vector->adapter = adapter;\n\tq_vector->v_idx = v_idx;\n\n\t \n\tq_vector->tx.work_limit = adapter->tx_work_limit;\n\n\t \n\tq_vector->tx.itr = IXGBE_ITR_ADAPTIVE_MAX_USECS |\n\t\t\t   IXGBE_ITR_ADAPTIVE_LATENCY;\n\tq_vector->rx.itr = IXGBE_ITR_ADAPTIVE_MAX_USECS |\n\t\t\t   IXGBE_ITR_ADAPTIVE_LATENCY;\n\n\t \n\tif (txr_count && !rxr_count) {\n\t\t \n\t\tif (adapter->tx_itr_setting == 1)\n\t\t\tq_vector->itr = IXGBE_12K_ITR;\n\t\telse\n\t\t\tq_vector->itr = adapter->tx_itr_setting;\n\t} else {\n\t\t \n\t\tif (adapter->rx_itr_setting == 1)\n\t\t\tq_vector->itr = IXGBE_20K_ITR;\n\t\telse\n\t\t\tq_vector->itr = adapter->rx_itr_setting;\n\t}\n\n\t \n\tring = q_vector->ring;\n\n\twhile (txr_count) {\n\t\t \n\t\tring->dev = &adapter->pdev->dev;\n\t\tring->netdev = adapter->netdev;\n\n\t\t \n\t\tring->q_vector = q_vector;\n\n\t\t \n\t\tixgbe_add_ring(ring, &q_vector->tx);\n\n\t\t \n\t\tring->count = adapter->tx_ring_count;\n\t\tring->queue_index = txr_idx;\n\n\t\t \n\t\tWRITE_ONCE(adapter->tx_ring[txr_idx], ring);\n\n\t\t \n\t\ttxr_count--;\n\t\ttxr_idx += v_count;\n\n\t\t \n\t\tring++;\n\t}\n\n\twhile (xdp_count) {\n\t\t \n\t\tring->dev = &adapter->pdev->dev;\n\t\tring->netdev = adapter->netdev;\n\n\t\t \n\t\tring->q_vector = q_vector;\n\n\t\t \n\t\tixgbe_add_ring(ring, &q_vector->tx);\n\n\t\t \n\t\tring->count = adapter->tx_ring_count;\n\t\tring->queue_index = xdp_idx;\n\t\tset_ring_xdp(ring);\n\t\tspin_lock_init(&ring->tx_lock);\n\n\t\t \n\t\tWRITE_ONCE(adapter->xdp_ring[xdp_idx], ring);\n\n\t\t \n\t\txdp_count--;\n\t\txdp_idx++;\n\n\t\t \n\t\tring++;\n\t}\n\n\twhile (rxr_count) {\n\t\t \n\t\tring->dev = &adapter->pdev->dev;\n\t\tring->netdev = adapter->netdev;\n\n\t\t \n\t\tring->q_vector = q_vector;\n\n\t\t \n\t\tixgbe_add_ring(ring, &q_vector->rx);\n\n\t\t \n\t\tif (adapter->hw.mac.type == ixgbe_mac_82599EB)\n\t\t\tset_bit(__IXGBE_RX_CSUM_UDP_ZERO_ERR, &ring->state);\n\n#ifdef IXGBE_FCOE\n\t\tif (adapter->netdev->features & NETIF_F_FCOE_MTU) {\n\t\t\tstruct ixgbe_ring_feature *f;\n\t\t\tf = &adapter->ring_feature[RING_F_FCOE];\n\t\t\tif ((rxr_idx >= f->offset) &&\n\t\t\t    (rxr_idx < f->offset + f->indices))\n\t\t\t\tset_bit(__IXGBE_RX_FCOE, &ring->state);\n\t\t}\n\n#endif  \n\t\t \n\t\tring->count = adapter->rx_ring_count;\n\t\tring->queue_index = rxr_idx;\n\n\t\t \n\t\tWRITE_ONCE(adapter->rx_ring[rxr_idx], ring);\n\n\t\t \n\t\trxr_count--;\n\t\trxr_idx += v_count;\n\n\t\t \n\t\tring++;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void ixgbe_free_q_vector(struct ixgbe_adapter *adapter, int v_idx)\n{\n\tstruct ixgbe_q_vector *q_vector = adapter->q_vector[v_idx];\n\tstruct ixgbe_ring *ring;\n\n\tixgbe_for_each_ring(ring, q_vector->tx) {\n\t\tif (ring_is_xdp(ring))\n\t\t\tWRITE_ONCE(adapter->xdp_ring[ring->queue_index], NULL);\n\t\telse\n\t\t\tWRITE_ONCE(adapter->tx_ring[ring->queue_index], NULL);\n\t}\n\n\tixgbe_for_each_ring(ring, q_vector->rx)\n\t\tWRITE_ONCE(adapter->rx_ring[ring->queue_index], NULL);\n\n\tadapter->q_vector[v_idx] = NULL;\n\t__netif_napi_del(&q_vector->napi);\n\n\t \n\tkfree_rcu(q_vector, rcu);\n}\n\n \nstatic int ixgbe_alloc_q_vectors(struct ixgbe_adapter *adapter)\n{\n\tint q_vectors = adapter->num_q_vectors;\n\tint rxr_remaining = adapter->num_rx_queues;\n\tint txr_remaining = adapter->num_tx_queues;\n\tint xdp_remaining = adapter->num_xdp_queues;\n\tint rxr_idx = 0, txr_idx = 0, xdp_idx = 0, v_idx = 0;\n\tint err, i;\n\n\t \n\tif (!(adapter->flags & IXGBE_FLAG_MSIX_ENABLED))\n\t\tq_vectors = 1;\n\n\tif (q_vectors >= (rxr_remaining + txr_remaining + xdp_remaining)) {\n\t\tfor (; rxr_remaining; v_idx++) {\n\t\t\terr = ixgbe_alloc_q_vector(adapter, q_vectors, v_idx,\n\t\t\t\t\t\t   0, 0, 0, 0, 1, rxr_idx);\n\n\t\t\tif (err)\n\t\t\t\tgoto err_out;\n\n\t\t\t \n\t\t\trxr_remaining--;\n\t\t\trxr_idx++;\n\t\t}\n\t}\n\n\tfor (; v_idx < q_vectors; v_idx++) {\n\t\tint rqpv = DIV_ROUND_UP(rxr_remaining, q_vectors - v_idx);\n\t\tint tqpv = DIV_ROUND_UP(txr_remaining, q_vectors - v_idx);\n\t\tint xqpv = DIV_ROUND_UP(xdp_remaining, q_vectors - v_idx);\n\n\t\terr = ixgbe_alloc_q_vector(adapter, q_vectors, v_idx,\n\t\t\t\t\t   tqpv, txr_idx,\n\t\t\t\t\t   xqpv, xdp_idx,\n\t\t\t\t\t   rqpv, rxr_idx);\n\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\t \n\t\trxr_remaining -= rqpv;\n\t\ttxr_remaining -= tqpv;\n\t\txdp_remaining -= xqpv;\n\t\trxr_idx++;\n\t\ttxr_idx++;\n\t\txdp_idx += xqpv;\n\t}\n\n\tfor (i = 0; i < adapter->num_rx_queues; i++) {\n\t\tif (adapter->rx_ring[i])\n\t\t\tadapter->rx_ring[i]->ring_idx = i;\n\t}\n\n\tfor (i = 0; i < adapter->num_tx_queues; i++) {\n\t\tif (adapter->tx_ring[i])\n\t\t\tadapter->tx_ring[i]->ring_idx = i;\n\t}\n\n\tfor (i = 0; i < adapter->num_xdp_queues; i++) {\n\t\tif (adapter->xdp_ring[i])\n\t\t\tadapter->xdp_ring[i]->ring_idx = i;\n\t}\n\n\treturn 0;\n\nerr_out:\n\tadapter->num_tx_queues = 0;\n\tadapter->num_xdp_queues = 0;\n\tadapter->num_rx_queues = 0;\n\tadapter->num_q_vectors = 0;\n\n\twhile (v_idx--)\n\t\tixgbe_free_q_vector(adapter, v_idx);\n\n\treturn -ENOMEM;\n}\n\n \nstatic void ixgbe_free_q_vectors(struct ixgbe_adapter *adapter)\n{\n\tint v_idx = adapter->num_q_vectors;\n\n\tadapter->num_tx_queues = 0;\n\tadapter->num_xdp_queues = 0;\n\tadapter->num_rx_queues = 0;\n\tadapter->num_q_vectors = 0;\n\n\twhile (v_idx--)\n\t\tixgbe_free_q_vector(adapter, v_idx);\n}\n\nstatic void ixgbe_reset_interrupt_capability(struct ixgbe_adapter *adapter)\n{\n\tif (adapter->flags & IXGBE_FLAG_MSIX_ENABLED) {\n\t\tadapter->flags &= ~IXGBE_FLAG_MSIX_ENABLED;\n\t\tpci_disable_msix(adapter->pdev);\n\t\tkfree(adapter->msix_entries);\n\t\tadapter->msix_entries = NULL;\n\t} else if (adapter->flags & IXGBE_FLAG_MSI_ENABLED) {\n\t\tadapter->flags &= ~IXGBE_FLAG_MSI_ENABLED;\n\t\tpci_disable_msi(adapter->pdev);\n\t}\n}\n\n \nstatic void ixgbe_set_interrupt_capability(struct ixgbe_adapter *adapter)\n{\n\tint err;\n\n\t \n\tif (!ixgbe_acquire_msix_vectors(adapter))\n\t\treturn;\n\n\t \n\n\t \n\tif (adapter->hw_tcs > 1) {\n\t\te_dev_warn(\"Number of DCB TCs exceeds number of available queues. Disabling DCB support.\\n\");\n\t\tnetdev_reset_tc(adapter->netdev);\n\n\t\tif (adapter->hw.mac.type == ixgbe_mac_82598EB)\n\t\t\tadapter->hw.fc.requested_mode = adapter->last_lfc_mode;\n\n\t\tadapter->flags &= ~IXGBE_FLAG_DCB_ENABLED;\n\t\tadapter->temp_dcb_cfg.pfc_mode_enable = false;\n\t\tadapter->dcb_cfg.pfc_mode_enable = false;\n\t}\n\n\tadapter->hw_tcs = 0;\n\tadapter->dcb_cfg.num_tcs.pg_tcs = 1;\n\tadapter->dcb_cfg.num_tcs.pfc_tcs = 1;\n\n\t \n\te_dev_warn(\"Disabling SR-IOV support\\n\");\n\tixgbe_disable_sriov(adapter);\n\n\t \n\te_dev_warn(\"Disabling RSS support\\n\");\n\tadapter->ring_feature[RING_F_RSS].limit = 1;\n\n\t \n\tixgbe_set_num_queues(adapter);\n\tadapter->num_q_vectors = 1;\n\n\terr = pci_enable_msi(adapter->pdev);\n\tif (err)\n\t\te_dev_warn(\"Failed to allocate MSI interrupt, falling back to legacy. Error: %d\\n\",\n\t\t\t   err);\n\telse\n\t\tadapter->flags |= IXGBE_FLAG_MSI_ENABLED;\n}\n\n \nint ixgbe_init_interrupt_scheme(struct ixgbe_adapter *adapter)\n{\n\tint err;\n\n\t \n\tixgbe_set_num_queues(adapter);\n\n\t \n\tixgbe_set_interrupt_capability(adapter);\n\n\terr = ixgbe_alloc_q_vectors(adapter);\n\tif (err) {\n\t\te_dev_err(\"Unable to allocate memory for queue vectors\\n\");\n\t\tgoto err_alloc_q_vectors;\n\t}\n\n\tixgbe_cache_ring_register(adapter);\n\n\te_dev_info(\"Multiqueue %s: Rx Queue count = %u, Tx Queue count = %u XDP Queue count = %u\\n\",\n\t\t   (adapter->num_rx_queues > 1) ? \"Enabled\" : \"Disabled\",\n\t\t   adapter->num_rx_queues, adapter->num_tx_queues,\n\t\t   adapter->num_xdp_queues);\n\n\tset_bit(__IXGBE_DOWN, &adapter->state);\n\n\treturn 0;\n\nerr_alloc_q_vectors:\n\tixgbe_reset_interrupt_capability(adapter);\n\treturn err;\n}\n\n \nvoid ixgbe_clear_interrupt_scheme(struct ixgbe_adapter *adapter)\n{\n\tadapter->num_tx_queues = 0;\n\tadapter->num_xdp_queues = 0;\n\tadapter->num_rx_queues = 0;\n\n\tixgbe_free_q_vectors(adapter);\n\tixgbe_reset_interrupt_capability(adapter);\n}\n\nvoid ixgbe_tx_ctxtdesc(struct ixgbe_ring *tx_ring, u32 vlan_macip_lens,\n\t\t       u32 fceof_saidx, u32 type_tucmd, u32 mss_l4len_idx)\n{\n\tstruct ixgbe_adv_tx_context_desc *context_desc;\n\tu16 i = tx_ring->next_to_use;\n\n\tcontext_desc = IXGBE_TX_CTXTDESC(tx_ring, i);\n\n\ti++;\n\ttx_ring->next_to_use = (i < tx_ring->count) ? i : 0;\n\n\t \n\ttype_tucmd |= IXGBE_TXD_CMD_DEXT | IXGBE_ADVTXD_DTYP_CTXT;\n\n\tcontext_desc->vlan_macip_lens\t= cpu_to_le32(vlan_macip_lens);\n\tcontext_desc->fceof_saidx\t= cpu_to_le32(fceof_saidx);\n\tcontext_desc->type_tucmd_mlhl\t= cpu_to_le32(type_tucmd);\n\tcontext_desc->mss_l4len_idx\t= cpu_to_le32(mss_l4len_idx);\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}