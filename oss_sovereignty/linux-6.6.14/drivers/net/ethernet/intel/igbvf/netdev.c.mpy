{
  "module_name": "netdev.c",
  "hash_id": "37e419369209dc1a0d8a254cb240a9f224c296030f5af77b1ea8fe9947ad6ac3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/igbvf/netdev.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/init.h>\n#include <linux/pci.h>\n#include <linux/vmalloc.h>\n#include <linux/pagemap.h>\n#include <linux/delay.h>\n#include <linux/netdevice.h>\n#include <linux/tcp.h>\n#include <linux/ipv6.h>\n#include <linux/slab.h>\n#include <net/checksum.h>\n#include <net/ip6_checksum.h>\n#include <linux/mii.h>\n#include <linux/ethtool.h>\n#include <linux/if_vlan.h>\n#include <linux/prefetch.h>\n#include <linux/sctp.h>\n\n#include \"igbvf.h\"\n\nchar igbvf_driver_name[] = \"igbvf\";\nstatic const char igbvf_driver_string[] =\n\t\t  \"Intel(R) Gigabit Virtual Function Network Driver\";\nstatic const char igbvf_copyright[] =\n\t\t  \"Copyright (c) 2009 - 2012 Intel Corporation.\";\n\n#define DEFAULT_MSG_ENABLE (NETIF_MSG_DRV|NETIF_MSG_PROBE|NETIF_MSG_LINK)\nstatic int debug = -1;\nmodule_param(debug, int, 0);\nMODULE_PARM_DESC(debug, \"Debug level (0=none,...,16=all)\");\n\nstatic int igbvf_poll(struct napi_struct *napi, int budget);\nstatic void igbvf_reset(struct igbvf_adapter *);\nstatic void igbvf_set_interrupt_capability(struct igbvf_adapter *);\nstatic void igbvf_reset_interrupt_capability(struct igbvf_adapter *);\n\nstatic struct igbvf_info igbvf_vf_info = {\n\t.mac\t\t= e1000_vfadapt,\n\t.flags\t\t= 0,\n\t.pba\t\t= 10,\n\t.init_ops\t= e1000_init_function_pointers_vf,\n};\n\nstatic struct igbvf_info igbvf_i350_vf_info = {\n\t.mac\t\t= e1000_vfadapt_i350,\n\t.flags\t\t= 0,\n\t.pba\t\t= 10,\n\t.init_ops\t= e1000_init_function_pointers_vf,\n};\n\nstatic const struct igbvf_info *igbvf_info_tbl[] = {\n\t[board_vf]\t= &igbvf_vf_info,\n\t[board_i350_vf]\t= &igbvf_i350_vf_info,\n};\n\n \nstatic int igbvf_desc_unused(struct igbvf_ring *ring)\n{\n\tif (ring->next_to_clean > ring->next_to_use)\n\t\treturn ring->next_to_clean - ring->next_to_use - 1;\n\n\treturn ring->count + ring->next_to_clean - ring->next_to_use - 1;\n}\n\n \nstatic void igbvf_receive_skb(struct igbvf_adapter *adapter,\n\t\t\t      struct net_device *netdev,\n\t\t\t      struct sk_buff *skb,\n\t\t\t      u32 status, __le16 vlan)\n{\n\tu16 vid;\n\n\tif (status & E1000_RXD_STAT_VP) {\n\t\tif ((adapter->flags & IGBVF_FLAG_RX_LB_VLAN_BSWAP) &&\n\t\t    (status & E1000_RXDEXT_STATERR_LB))\n\t\t\tvid = be16_to_cpu((__force __be16)vlan) & E1000_RXD_SPC_VLAN_MASK;\n\t\telse\n\t\t\tvid = le16_to_cpu(vlan) & E1000_RXD_SPC_VLAN_MASK;\n\t\tif (test_bit(vid, adapter->active_vlans))\n\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\n\t}\n\n\tnapi_gro_receive(&adapter->rx_ring->napi, skb);\n}\n\nstatic inline void igbvf_rx_checksum_adv(struct igbvf_adapter *adapter,\n\t\t\t\t\t u32 status_err, struct sk_buff *skb)\n{\n\tskb_checksum_none_assert(skb);\n\n\t \n\tif ((status_err & E1000_RXD_STAT_IXSM) ||\n\t    (adapter->flags & IGBVF_FLAG_RX_CSUM_DISABLED))\n\t\treturn;\n\n\t \n\tif (status_err &\n\t    (E1000_RXDEXT_STATERR_TCPE | E1000_RXDEXT_STATERR_IPE)) {\n\t\t \n\t\tadapter->hw_csum_err++;\n\t\treturn;\n\t}\n\n\t \n\tif (status_err & (E1000_RXD_STAT_TCPCS | E1000_RXD_STAT_UDPCS))\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\n\tadapter->hw_csum_good++;\n}\n\n \nstatic void igbvf_alloc_rx_buffers(struct igbvf_ring *rx_ring,\n\t\t\t\t   int cleaned_count)\n{\n\tstruct igbvf_adapter *adapter = rx_ring->adapter;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tunion e1000_adv_rx_desc *rx_desc;\n\tstruct igbvf_buffer *buffer_info;\n\tstruct sk_buff *skb;\n\tunsigned int i;\n\tint bufsz;\n\n\ti = rx_ring->next_to_use;\n\tbuffer_info = &rx_ring->buffer_info[i];\n\n\tif (adapter->rx_ps_hdr_size)\n\t\tbufsz = adapter->rx_ps_hdr_size;\n\telse\n\t\tbufsz = adapter->rx_buffer_len;\n\n\twhile (cleaned_count--) {\n\t\trx_desc = IGBVF_RX_DESC_ADV(*rx_ring, i);\n\n\t\tif (adapter->rx_ps_hdr_size && !buffer_info->page_dma) {\n\t\t\tif (!buffer_info->page) {\n\t\t\t\tbuffer_info->page = alloc_page(GFP_ATOMIC);\n\t\t\t\tif (!buffer_info->page) {\n\t\t\t\t\tadapter->alloc_rx_buff_failed++;\n\t\t\t\t\tgoto no_buffers;\n\t\t\t\t}\n\t\t\t\tbuffer_info->page_offset = 0;\n\t\t\t} else {\n\t\t\t\tbuffer_info->page_offset ^= PAGE_SIZE / 2;\n\t\t\t}\n\t\t\tbuffer_info->page_dma =\n\t\t\t\tdma_map_page(&pdev->dev, buffer_info->page,\n\t\t\t\t\t     buffer_info->page_offset,\n\t\t\t\t\t     PAGE_SIZE / 2,\n\t\t\t\t\t     DMA_FROM_DEVICE);\n\t\t\tif (dma_mapping_error(&pdev->dev,\n\t\t\t\t\t      buffer_info->page_dma)) {\n\t\t\t\t__free_page(buffer_info->page);\n\t\t\t\tbuffer_info->page = NULL;\n\t\t\t\tdev_err(&pdev->dev, \"RX DMA map failed\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!buffer_info->skb) {\n\t\t\tskb = netdev_alloc_skb_ip_align(netdev, bufsz);\n\t\t\tif (!skb) {\n\t\t\t\tadapter->alloc_rx_buff_failed++;\n\t\t\t\tgoto no_buffers;\n\t\t\t}\n\n\t\t\tbuffer_info->skb = skb;\n\t\t\tbuffer_info->dma = dma_map_single(&pdev->dev, skb->data,\n\t\t\t\t\t\t\t  bufsz,\n\t\t\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\t\tif (dma_mapping_error(&pdev->dev, buffer_info->dma)) {\n\t\t\t\tdev_kfree_skb(buffer_info->skb);\n\t\t\t\tbuffer_info->skb = NULL;\n\t\t\t\tdev_err(&pdev->dev, \"RX DMA map failed\\n\");\n\t\t\t\tgoto no_buffers;\n\t\t\t}\n\t\t}\n\t\t \n\t\tif (adapter->rx_ps_hdr_size) {\n\t\t\trx_desc->read.pkt_addr =\n\t\t\t     cpu_to_le64(buffer_info->page_dma);\n\t\t\trx_desc->read.hdr_addr = cpu_to_le64(buffer_info->dma);\n\t\t} else {\n\t\t\trx_desc->read.pkt_addr = cpu_to_le64(buffer_info->dma);\n\t\t\trx_desc->read.hdr_addr = 0;\n\t\t}\n\n\t\ti++;\n\t\tif (i == rx_ring->count)\n\t\t\ti = 0;\n\t\tbuffer_info = &rx_ring->buffer_info[i];\n\t}\n\nno_buffers:\n\tif (rx_ring->next_to_use != i) {\n\t\trx_ring->next_to_use = i;\n\t\tif (i == 0)\n\t\t\ti = (rx_ring->count - 1);\n\t\telse\n\t\t\ti--;\n\n\t\t \n\t\twmb();\n\t\twritel(i, adapter->hw.hw_addr + rx_ring->tail);\n\t}\n}\n\n \nstatic bool igbvf_clean_rx_irq(struct igbvf_adapter *adapter,\n\t\t\t       int *work_done, int work_to_do)\n{\n\tstruct igbvf_ring *rx_ring = adapter->rx_ring;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tunion e1000_adv_rx_desc *rx_desc, *next_rxd;\n\tstruct igbvf_buffer *buffer_info, *next_buffer;\n\tstruct sk_buff *skb;\n\tbool cleaned = false;\n\tint cleaned_count = 0;\n\tunsigned int total_bytes = 0, total_packets = 0;\n\tunsigned int i;\n\tu32 length, hlen, staterr;\n\n\ti = rx_ring->next_to_clean;\n\trx_desc = IGBVF_RX_DESC_ADV(*rx_ring, i);\n\tstaterr = le32_to_cpu(rx_desc->wb.upper.status_error);\n\n\twhile (staterr & E1000_RXD_STAT_DD) {\n\t\tif (*work_done >= work_to_do)\n\t\t\tbreak;\n\t\t(*work_done)++;\n\t\trmb();  \n\n\t\tbuffer_info = &rx_ring->buffer_info[i];\n\n\t\t \n\t\thlen = (le16_to_cpu(rx_desc->wb.lower.lo_dword.hs_rss.hdr_info)\n\t\t       & E1000_RXDADV_HDRBUFLEN_MASK) >>\n\t\t       E1000_RXDADV_HDRBUFLEN_SHIFT;\n\t\tif (hlen > adapter->rx_ps_hdr_size)\n\t\t\thlen = adapter->rx_ps_hdr_size;\n\n\t\tlength = le16_to_cpu(rx_desc->wb.upper.length);\n\t\tcleaned = true;\n\t\tcleaned_count++;\n\n\t\tskb = buffer_info->skb;\n\t\tprefetch(skb->data - NET_IP_ALIGN);\n\t\tbuffer_info->skb = NULL;\n\t\tif (!adapter->rx_ps_hdr_size) {\n\t\t\tdma_unmap_single(&pdev->dev, buffer_info->dma,\n\t\t\t\t\t adapter->rx_buffer_len,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tbuffer_info->dma = 0;\n\t\t\tskb_put(skb, length);\n\t\t\tgoto send_up;\n\t\t}\n\n\t\tif (!skb_shinfo(skb)->nr_frags) {\n\t\t\tdma_unmap_single(&pdev->dev, buffer_info->dma,\n\t\t\t\t\t adapter->rx_ps_hdr_size,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tbuffer_info->dma = 0;\n\t\t\tskb_put(skb, hlen);\n\t\t}\n\n\t\tif (length) {\n\t\t\tdma_unmap_page(&pdev->dev, buffer_info->page_dma,\n\t\t\t\t       PAGE_SIZE / 2,\n\t\t\t\t       DMA_FROM_DEVICE);\n\t\t\tbuffer_info->page_dma = 0;\n\n\t\t\tskb_fill_page_desc(skb, skb_shinfo(skb)->nr_frags,\n\t\t\t\t\t   buffer_info->page,\n\t\t\t\t\t   buffer_info->page_offset,\n\t\t\t\t\t   length);\n\n\t\t\tif ((adapter->rx_buffer_len > (PAGE_SIZE / 2)) ||\n\t\t\t    (page_count(buffer_info->page) != 1))\n\t\t\t\tbuffer_info->page = NULL;\n\t\t\telse\n\t\t\t\tget_page(buffer_info->page);\n\n\t\t\tskb->len += length;\n\t\t\tskb->data_len += length;\n\t\t\tskb->truesize += PAGE_SIZE / 2;\n\t\t}\nsend_up:\n\t\ti++;\n\t\tif (i == rx_ring->count)\n\t\t\ti = 0;\n\t\tnext_rxd = IGBVF_RX_DESC_ADV(*rx_ring, i);\n\t\tprefetch(next_rxd);\n\t\tnext_buffer = &rx_ring->buffer_info[i];\n\n\t\tif (!(staterr & E1000_RXD_STAT_EOP)) {\n\t\t\tbuffer_info->skb = next_buffer->skb;\n\t\t\tbuffer_info->dma = next_buffer->dma;\n\t\t\tnext_buffer->skb = skb;\n\t\t\tnext_buffer->dma = 0;\n\t\t\tgoto next_desc;\n\t\t}\n\n\t\tif (staterr & E1000_RXDEXT_ERR_FRAME_ERR_MASK) {\n\t\t\tdev_kfree_skb_irq(skb);\n\t\t\tgoto next_desc;\n\t\t}\n\n\t\ttotal_bytes += skb->len;\n\t\ttotal_packets++;\n\n\t\tigbvf_rx_checksum_adv(adapter, staterr, skb);\n\n\t\tskb->protocol = eth_type_trans(skb, netdev);\n\n\t\tigbvf_receive_skb(adapter, netdev, skb, staterr,\n\t\t\t\t  rx_desc->wb.upper.vlan);\n\nnext_desc:\n\t\trx_desc->wb.upper.status_error = 0;\n\n\t\t \n\t\tif (cleaned_count >= IGBVF_RX_BUFFER_WRITE) {\n\t\t\tigbvf_alloc_rx_buffers(rx_ring, cleaned_count);\n\t\t\tcleaned_count = 0;\n\t\t}\n\n\t\t \n\t\trx_desc = next_rxd;\n\t\tbuffer_info = next_buffer;\n\n\t\tstaterr = le32_to_cpu(rx_desc->wb.upper.status_error);\n\t}\n\n\trx_ring->next_to_clean = i;\n\tcleaned_count = igbvf_desc_unused(rx_ring);\n\n\tif (cleaned_count)\n\t\tigbvf_alloc_rx_buffers(rx_ring, cleaned_count);\n\n\tadapter->total_rx_packets += total_packets;\n\tadapter->total_rx_bytes += total_bytes;\n\tnetdev->stats.rx_bytes += total_bytes;\n\tnetdev->stats.rx_packets += total_packets;\n\treturn cleaned;\n}\n\nstatic void igbvf_put_txbuf(struct igbvf_adapter *adapter,\n\t\t\t    struct igbvf_buffer *buffer_info)\n{\n\tif (buffer_info->dma) {\n\t\tif (buffer_info->mapped_as_page)\n\t\t\tdma_unmap_page(&adapter->pdev->dev,\n\t\t\t\t       buffer_info->dma,\n\t\t\t\t       buffer_info->length,\n\t\t\t\t       DMA_TO_DEVICE);\n\t\telse\n\t\t\tdma_unmap_single(&adapter->pdev->dev,\n\t\t\t\t\t buffer_info->dma,\n\t\t\t\t\t buffer_info->length,\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\tbuffer_info->dma = 0;\n\t}\n\tif (buffer_info->skb) {\n\t\tdev_kfree_skb_any(buffer_info->skb);\n\t\tbuffer_info->skb = NULL;\n\t}\n\tbuffer_info->time_stamp = 0;\n}\n\n \nint igbvf_setup_tx_resources(struct igbvf_adapter *adapter,\n\t\t\t     struct igbvf_ring *tx_ring)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tint size;\n\n\tsize = sizeof(struct igbvf_buffer) * tx_ring->count;\n\ttx_ring->buffer_info = vzalloc(size);\n\tif (!tx_ring->buffer_info)\n\t\tgoto err;\n\n\t \n\ttx_ring->size = tx_ring->count * sizeof(union e1000_adv_tx_desc);\n\ttx_ring->size = ALIGN(tx_ring->size, 4096);\n\n\ttx_ring->desc = dma_alloc_coherent(&pdev->dev, tx_ring->size,\n\t\t\t\t\t   &tx_ring->dma, GFP_KERNEL);\n\tif (!tx_ring->desc)\n\t\tgoto err;\n\n\ttx_ring->adapter = adapter;\n\ttx_ring->next_to_use = 0;\n\ttx_ring->next_to_clean = 0;\n\n\treturn 0;\nerr:\n\tvfree(tx_ring->buffer_info);\n\tdev_err(&adapter->pdev->dev,\n\t\t\"Unable to allocate memory for the transmit descriptor ring\\n\");\n\treturn -ENOMEM;\n}\n\n \nint igbvf_setup_rx_resources(struct igbvf_adapter *adapter,\n\t\t\t     struct igbvf_ring *rx_ring)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tint size, desc_len;\n\n\tsize = sizeof(struct igbvf_buffer) * rx_ring->count;\n\trx_ring->buffer_info = vzalloc(size);\n\tif (!rx_ring->buffer_info)\n\t\tgoto err;\n\n\tdesc_len = sizeof(union e1000_adv_rx_desc);\n\n\t \n\trx_ring->size = rx_ring->count * desc_len;\n\trx_ring->size = ALIGN(rx_ring->size, 4096);\n\n\trx_ring->desc = dma_alloc_coherent(&pdev->dev, rx_ring->size,\n\t\t\t\t\t   &rx_ring->dma, GFP_KERNEL);\n\tif (!rx_ring->desc)\n\t\tgoto err;\n\n\trx_ring->next_to_clean = 0;\n\trx_ring->next_to_use = 0;\n\n\trx_ring->adapter = adapter;\n\n\treturn 0;\n\nerr:\n\tvfree(rx_ring->buffer_info);\n\trx_ring->buffer_info = NULL;\n\tdev_err(&adapter->pdev->dev,\n\t\t\"Unable to allocate memory for the receive descriptor ring\\n\");\n\treturn -ENOMEM;\n}\n\n \nstatic void igbvf_clean_tx_ring(struct igbvf_ring *tx_ring)\n{\n\tstruct igbvf_adapter *adapter = tx_ring->adapter;\n\tstruct igbvf_buffer *buffer_info;\n\tunsigned long size;\n\tunsigned int i;\n\n\tif (!tx_ring->buffer_info)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < tx_ring->count; i++) {\n\t\tbuffer_info = &tx_ring->buffer_info[i];\n\t\tigbvf_put_txbuf(adapter, buffer_info);\n\t}\n\n\tsize = sizeof(struct igbvf_buffer) * tx_ring->count;\n\tmemset(tx_ring->buffer_info, 0, size);\n\n\t \n\tmemset(tx_ring->desc, 0, tx_ring->size);\n\n\ttx_ring->next_to_use = 0;\n\ttx_ring->next_to_clean = 0;\n\n\twritel(0, adapter->hw.hw_addr + tx_ring->head);\n\twritel(0, adapter->hw.hw_addr + tx_ring->tail);\n}\n\n \nvoid igbvf_free_tx_resources(struct igbvf_ring *tx_ring)\n{\n\tstruct pci_dev *pdev = tx_ring->adapter->pdev;\n\n\tigbvf_clean_tx_ring(tx_ring);\n\n\tvfree(tx_ring->buffer_info);\n\ttx_ring->buffer_info = NULL;\n\n\tdma_free_coherent(&pdev->dev, tx_ring->size, tx_ring->desc,\n\t\t\t  tx_ring->dma);\n\n\ttx_ring->desc = NULL;\n}\n\n \nstatic void igbvf_clean_rx_ring(struct igbvf_ring *rx_ring)\n{\n\tstruct igbvf_adapter *adapter = rx_ring->adapter;\n\tstruct igbvf_buffer *buffer_info;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tunsigned long size;\n\tunsigned int i;\n\n\tif (!rx_ring->buffer_info)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < rx_ring->count; i++) {\n\t\tbuffer_info = &rx_ring->buffer_info[i];\n\t\tif (buffer_info->dma) {\n\t\t\tif (adapter->rx_ps_hdr_size) {\n\t\t\t\tdma_unmap_single(&pdev->dev, buffer_info->dma,\n\t\t\t\t\t\t adapter->rx_ps_hdr_size,\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\t} else {\n\t\t\t\tdma_unmap_single(&pdev->dev, buffer_info->dma,\n\t\t\t\t\t\t adapter->rx_buffer_len,\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\t}\n\t\t\tbuffer_info->dma = 0;\n\t\t}\n\n\t\tif (buffer_info->skb) {\n\t\t\tdev_kfree_skb(buffer_info->skb);\n\t\t\tbuffer_info->skb = NULL;\n\t\t}\n\n\t\tif (buffer_info->page) {\n\t\t\tif (buffer_info->page_dma)\n\t\t\t\tdma_unmap_page(&pdev->dev,\n\t\t\t\t\t       buffer_info->page_dma,\n\t\t\t\t\t       PAGE_SIZE / 2,\n\t\t\t\t\t       DMA_FROM_DEVICE);\n\t\t\tput_page(buffer_info->page);\n\t\t\tbuffer_info->page = NULL;\n\t\t\tbuffer_info->page_dma = 0;\n\t\t\tbuffer_info->page_offset = 0;\n\t\t}\n\t}\n\n\tsize = sizeof(struct igbvf_buffer) * rx_ring->count;\n\tmemset(rx_ring->buffer_info, 0, size);\n\n\t \n\tmemset(rx_ring->desc, 0, rx_ring->size);\n\n\trx_ring->next_to_clean = 0;\n\trx_ring->next_to_use = 0;\n\n\twritel(0, adapter->hw.hw_addr + rx_ring->head);\n\twritel(0, adapter->hw.hw_addr + rx_ring->tail);\n}\n\n \n\nvoid igbvf_free_rx_resources(struct igbvf_ring *rx_ring)\n{\n\tstruct pci_dev *pdev = rx_ring->adapter->pdev;\n\n\tigbvf_clean_rx_ring(rx_ring);\n\n\tvfree(rx_ring->buffer_info);\n\trx_ring->buffer_info = NULL;\n\n\tdma_free_coherent(&pdev->dev, rx_ring->size, rx_ring->desc,\n\t\t\t  rx_ring->dma);\n\trx_ring->desc = NULL;\n}\n\n \nstatic enum latency_range igbvf_update_itr(struct igbvf_adapter *adapter,\n\t\t\t\t\t   enum latency_range itr_setting,\n\t\t\t\t\t   int packets, int bytes)\n{\n\tenum latency_range retval = itr_setting;\n\n\tif (packets == 0)\n\t\tgoto update_itr_done;\n\n\tswitch (itr_setting) {\n\tcase lowest_latency:\n\t\t \n\t\tif (bytes/packets > 8000)\n\t\t\tretval = bulk_latency;\n\t\telse if ((packets < 5) && (bytes > 512))\n\t\t\tretval = low_latency;\n\t\tbreak;\n\tcase low_latency:   \n\t\tif (bytes > 10000) {\n\t\t\t \n\t\t\tif (bytes/packets > 8000)\n\t\t\t\tretval = bulk_latency;\n\t\t\telse if ((packets < 10) || ((bytes/packets) > 1200))\n\t\t\t\tretval = bulk_latency;\n\t\t\telse if ((packets > 35))\n\t\t\t\tretval = lowest_latency;\n\t\t} else if (bytes/packets > 2000) {\n\t\t\tretval = bulk_latency;\n\t\t} else if (packets <= 2 && bytes < 512) {\n\t\t\tretval = lowest_latency;\n\t\t}\n\t\tbreak;\n\tcase bulk_latency:  \n\t\tif (bytes > 25000) {\n\t\t\tif (packets > 35)\n\t\t\t\tretval = low_latency;\n\t\t} else if (bytes < 6000) {\n\t\t\tretval = low_latency;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\nupdate_itr_done:\n\treturn retval;\n}\n\nstatic int igbvf_range_to_itr(enum latency_range current_range)\n{\n\tint new_itr;\n\n\tswitch (current_range) {\n\t \n\tcase lowest_latency:\n\t\tnew_itr = IGBVF_70K_ITR;\n\t\tbreak;\n\tcase low_latency:\n\t\tnew_itr = IGBVF_20K_ITR;\n\t\tbreak;\n\tcase bulk_latency:\n\t\tnew_itr = IGBVF_4K_ITR;\n\t\tbreak;\n\tdefault:\n\t\tnew_itr = IGBVF_START_ITR;\n\t\tbreak;\n\t}\n\treturn new_itr;\n}\n\nstatic void igbvf_set_itr(struct igbvf_adapter *adapter)\n{\n\tu32 new_itr;\n\n\tadapter->tx_ring->itr_range =\n\t\t\tigbvf_update_itr(adapter,\n\t\t\t\t\t adapter->tx_ring->itr_val,\n\t\t\t\t\t adapter->total_tx_packets,\n\t\t\t\t\t adapter->total_tx_bytes);\n\n\t \n\tif (adapter->requested_itr == 3 &&\n\t    adapter->tx_ring->itr_range == lowest_latency)\n\t\tadapter->tx_ring->itr_range = low_latency;\n\n\tnew_itr = igbvf_range_to_itr(adapter->tx_ring->itr_range);\n\n\tif (new_itr != adapter->tx_ring->itr_val) {\n\t\tu32 current_itr = adapter->tx_ring->itr_val;\n\t\t \n\t\tnew_itr = new_itr > current_itr ?\n\t\t\t  min(current_itr + (new_itr >> 2), new_itr) :\n\t\t\t  new_itr;\n\t\tadapter->tx_ring->itr_val = new_itr;\n\n\t\tadapter->tx_ring->set_itr = 1;\n\t}\n\n\tadapter->rx_ring->itr_range =\n\t\t\tigbvf_update_itr(adapter, adapter->rx_ring->itr_val,\n\t\t\t\t\t adapter->total_rx_packets,\n\t\t\t\t\t adapter->total_rx_bytes);\n\tif (adapter->requested_itr == 3 &&\n\t    adapter->rx_ring->itr_range == lowest_latency)\n\t\tadapter->rx_ring->itr_range = low_latency;\n\n\tnew_itr = igbvf_range_to_itr(adapter->rx_ring->itr_range);\n\n\tif (new_itr != adapter->rx_ring->itr_val) {\n\t\tu32 current_itr = adapter->rx_ring->itr_val;\n\n\t\tnew_itr = new_itr > current_itr ?\n\t\t\t  min(current_itr + (new_itr >> 2), new_itr) :\n\t\t\t  new_itr;\n\t\tadapter->rx_ring->itr_val = new_itr;\n\n\t\tadapter->rx_ring->set_itr = 1;\n\t}\n}\n\n \nstatic bool igbvf_clean_tx_irq(struct igbvf_ring *tx_ring)\n{\n\tstruct igbvf_adapter *adapter = tx_ring->adapter;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct igbvf_buffer *buffer_info;\n\tstruct sk_buff *skb;\n\tunion e1000_adv_tx_desc *tx_desc, *eop_desc;\n\tunsigned int total_bytes = 0, total_packets = 0;\n\tunsigned int i, count = 0;\n\tbool cleaned = false;\n\n\ti = tx_ring->next_to_clean;\n\tbuffer_info = &tx_ring->buffer_info[i];\n\teop_desc = buffer_info->next_to_watch;\n\n\tdo {\n\t\t \n\t\tif (!eop_desc)\n\t\t\tbreak;\n\n\t\t \n\t\tsmp_rmb();\n\n\t\t \n\t\tif (!(eop_desc->wb.status & cpu_to_le32(E1000_TXD_STAT_DD)))\n\t\t\tbreak;\n\n\t\t \n\t\tbuffer_info->next_to_watch = NULL;\n\n\t\tfor (cleaned = false; !cleaned; count++) {\n\t\t\ttx_desc = IGBVF_TX_DESC_ADV(*tx_ring, i);\n\t\t\tcleaned = (tx_desc == eop_desc);\n\t\t\tskb = buffer_info->skb;\n\n\t\t\tif (skb) {\n\t\t\t\tunsigned int segs, bytecount;\n\n\t\t\t\t \n\t\t\t\tsegs = skb_shinfo(skb)->gso_segs ?: 1;\n\t\t\t\t \n\t\t\t\tbytecount = ((segs - 1) * skb_headlen(skb)) +\n\t\t\t\t\t    skb->len;\n\t\t\t\ttotal_packets += segs;\n\t\t\t\ttotal_bytes += bytecount;\n\t\t\t}\n\n\t\t\tigbvf_put_txbuf(adapter, buffer_info);\n\t\t\ttx_desc->wb.status = 0;\n\n\t\t\ti++;\n\t\t\tif (i == tx_ring->count)\n\t\t\t\ti = 0;\n\n\t\t\tbuffer_info = &tx_ring->buffer_info[i];\n\t\t}\n\n\t\teop_desc = buffer_info->next_to_watch;\n\t} while (count < tx_ring->count);\n\n\ttx_ring->next_to_clean = i;\n\n\tif (unlikely(count && netif_carrier_ok(netdev) &&\n\t    igbvf_desc_unused(tx_ring) >= IGBVF_TX_QUEUE_WAKE)) {\n\t\t \n\t\tsmp_mb();\n\t\tif (netif_queue_stopped(netdev) &&\n\t\t    !(test_bit(__IGBVF_DOWN, &adapter->state))) {\n\t\t\tnetif_wake_queue(netdev);\n\t\t\t++adapter->restart_queue;\n\t\t}\n\t}\n\n\tnetdev->stats.tx_bytes += total_bytes;\n\tnetdev->stats.tx_packets += total_packets;\n\treturn count < tx_ring->count;\n}\n\nstatic irqreturn_t igbvf_msix_other(int irq, void *data)\n{\n\tstruct net_device *netdev = data;\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tadapter->int_counter1++;\n\n\thw->mac.get_link_status = 1;\n\tif (!test_bit(__IGBVF_DOWN, &adapter->state))\n\t\tmod_timer(&adapter->watchdog_timer, jiffies + 1);\n\n\tew32(EIMS, adapter->eims_other);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t igbvf_intr_msix_tx(int irq, void *data)\n{\n\tstruct net_device *netdev = data;\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct igbvf_ring *tx_ring = adapter->tx_ring;\n\n\tif (tx_ring->set_itr) {\n\t\twritel(tx_ring->itr_val,\n\t\t       adapter->hw.hw_addr + tx_ring->itr_register);\n\t\tadapter->tx_ring->set_itr = 0;\n\t}\n\n\tadapter->total_tx_bytes = 0;\n\tadapter->total_tx_packets = 0;\n\n\t \n\tif (!igbvf_clean_tx_irq(tx_ring))\n\t\t \n\t\tew32(EICS, tx_ring->eims_value);\n\telse\n\t\tew32(EIMS, tx_ring->eims_value);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t igbvf_intr_msix_rx(int irq, void *data)\n{\n\tstruct net_device *netdev = data;\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tadapter->int_counter0++;\n\n\t \n\tif (adapter->rx_ring->set_itr) {\n\t\twritel(adapter->rx_ring->itr_val,\n\t\t       adapter->hw.hw_addr + adapter->rx_ring->itr_register);\n\t\tadapter->rx_ring->set_itr = 0;\n\t}\n\n\tif (napi_schedule_prep(&adapter->rx_ring->napi)) {\n\t\tadapter->total_rx_bytes = 0;\n\t\tadapter->total_rx_packets = 0;\n\t\t__napi_schedule(&adapter->rx_ring->napi);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n#define IGBVF_NO_QUEUE -1\n\nstatic void igbvf_assign_vector(struct igbvf_adapter *adapter, int rx_queue,\n\t\t\t\tint tx_queue, int msix_vector)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\tu32 ivar, index;\n\n\t \n\tif (rx_queue > IGBVF_NO_QUEUE) {\n\t\tindex = (rx_queue >> 1);\n\t\tivar = array_er32(IVAR0, index);\n\t\tif (rx_queue & 0x1) {\n\t\t\t \n\t\t\tivar = ivar & 0xFF00FFFF;\n\t\t\tivar |= (msix_vector | E1000_IVAR_VALID) << 16;\n\t\t} else {\n\t\t\t \n\t\t\tivar = ivar & 0xFFFFFF00;\n\t\t\tivar |= msix_vector | E1000_IVAR_VALID;\n\t\t}\n\t\tadapter->rx_ring[rx_queue].eims_value = BIT(msix_vector);\n\t\tarray_ew32(IVAR0, index, ivar);\n\t}\n\tif (tx_queue > IGBVF_NO_QUEUE) {\n\t\tindex = (tx_queue >> 1);\n\t\tivar = array_er32(IVAR0, index);\n\t\tif (tx_queue & 0x1) {\n\t\t\t \n\t\t\tivar = ivar & 0x00FFFFFF;\n\t\t\tivar |= (msix_vector | E1000_IVAR_VALID) << 24;\n\t\t} else {\n\t\t\t \n\t\t\tivar = ivar & 0xFFFF00FF;\n\t\t\tivar |= (msix_vector | E1000_IVAR_VALID) << 8;\n\t\t}\n\t\tadapter->tx_ring[tx_queue].eims_value = BIT(msix_vector);\n\t\tarray_ew32(IVAR0, index, ivar);\n\t}\n}\n\n \nstatic void igbvf_configure_msix(struct igbvf_adapter *adapter)\n{\n\tu32 tmp;\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct igbvf_ring *tx_ring = adapter->tx_ring;\n\tstruct igbvf_ring *rx_ring = adapter->rx_ring;\n\tint vector = 0;\n\n\tadapter->eims_enable_mask = 0;\n\n\tigbvf_assign_vector(adapter, IGBVF_NO_QUEUE, 0, vector++);\n\tadapter->eims_enable_mask |= tx_ring->eims_value;\n\twritel(tx_ring->itr_val, hw->hw_addr + tx_ring->itr_register);\n\tigbvf_assign_vector(adapter, 0, IGBVF_NO_QUEUE, vector++);\n\tadapter->eims_enable_mask |= rx_ring->eims_value;\n\twritel(rx_ring->itr_val, hw->hw_addr + rx_ring->itr_register);\n\n\t \n\n\ttmp = (vector++ | E1000_IVAR_VALID);\n\n\tew32(IVAR_MISC, tmp);\n\n\tadapter->eims_enable_mask = GENMASK(vector - 1, 0);\n\tadapter->eims_other = BIT(vector - 1);\n\te1e_flush();\n}\n\nstatic void igbvf_reset_interrupt_capability(struct igbvf_adapter *adapter)\n{\n\tif (adapter->msix_entries) {\n\t\tpci_disable_msix(adapter->pdev);\n\t\tkfree(adapter->msix_entries);\n\t\tadapter->msix_entries = NULL;\n\t}\n}\n\n \nstatic void igbvf_set_interrupt_capability(struct igbvf_adapter *adapter)\n{\n\tint err = -ENOMEM;\n\tint i;\n\n\t \n\tadapter->msix_entries = kcalloc(3, sizeof(struct msix_entry),\n\t\t\t\t\tGFP_KERNEL);\n\tif (adapter->msix_entries) {\n\t\tfor (i = 0; i < 3; i++)\n\t\t\tadapter->msix_entries[i].entry = i;\n\n\t\terr = pci_enable_msix_range(adapter->pdev,\n\t\t\t\t\t    adapter->msix_entries, 3, 3);\n\t}\n\n\tif (err < 0) {\n\t\t \n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Failed to initialize MSI-X interrupts.\\n\");\n\t\tigbvf_reset_interrupt_capability(adapter);\n\t}\n}\n\n \nstatic int igbvf_request_msix(struct igbvf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint err = 0, vector = 0;\n\n\tif (strlen(netdev->name) < (IFNAMSIZ - 5)) {\n\t\tsprintf(adapter->tx_ring->name, \"%s-tx-0\", netdev->name);\n\t\tsprintf(adapter->rx_ring->name, \"%s-rx-0\", netdev->name);\n\t} else {\n\t\tmemcpy(adapter->tx_ring->name, netdev->name, IFNAMSIZ);\n\t\tmemcpy(adapter->rx_ring->name, netdev->name, IFNAMSIZ);\n\t}\n\n\terr = request_irq(adapter->msix_entries[vector].vector,\n\t\t\t  igbvf_intr_msix_tx, 0, adapter->tx_ring->name,\n\t\t\t  netdev);\n\tif (err)\n\t\tgoto out;\n\n\tadapter->tx_ring->itr_register = E1000_EITR(vector);\n\tadapter->tx_ring->itr_val = adapter->current_itr;\n\tvector++;\n\n\terr = request_irq(adapter->msix_entries[vector].vector,\n\t\t\t  igbvf_intr_msix_rx, 0, adapter->rx_ring->name,\n\t\t\t  netdev);\n\tif (err)\n\t\tgoto free_irq_tx;\n\n\tadapter->rx_ring->itr_register = E1000_EITR(vector);\n\tadapter->rx_ring->itr_val = adapter->current_itr;\n\tvector++;\n\n\terr = request_irq(adapter->msix_entries[vector].vector,\n\t\t\t  igbvf_msix_other, 0, netdev->name, netdev);\n\tif (err)\n\t\tgoto free_irq_rx;\n\n\tigbvf_configure_msix(adapter);\n\treturn 0;\nfree_irq_rx:\n\tfree_irq(adapter->msix_entries[--vector].vector, netdev);\nfree_irq_tx:\n\tfree_irq(adapter->msix_entries[--vector].vector, netdev);\nout:\n\treturn err;\n}\n\n \nstatic int igbvf_alloc_queues(struct igbvf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tadapter->tx_ring = kzalloc(sizeof(struct igbvf_ring), GFP_KERNEL);\n\tif (!adapter->tx_ring)\n\t\treturn -ENOMEM;\n\n\tadapter->rx_ring = kzalloc(sizeof(struct igbvf_ring), GFP_KERNEL);\n\tif (!adapter->rx_ring) {\n\t\tkfree(adapter->tx_ring);\n\t\treturn -ENOMEM;\n\t}\n\n\tnetif_napi_add(netdev, &adapter->rx_ring->napi, igbvf_poll);\n\n\treturn 0;\n}\n\n \nstatic int igbvf_request_irq(struct igbvf_adapter *adapter)\n{\n\tint err = -1;\n\n\t \n\tif (adapter->msix_entries)\n\t\terr = igbvf_request_msix(adapter);\n\n\tif (!err)\n\t\treturn err;\n\n\tdev_err(&adapter->pdev->dev,\n\t\t\"Unable to allocate interrupt, Error: %d\\n\", err);\n\n\treturn err;\n}\n\nstatic void igbvf_free_irq(struct igbvf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint vector;\n\n\tif (adapter->msix_entries) {\n\t\tfor (vector = 0; vector < 3; vector++)\n\t\t\tfree_irq(adapter->msix_entries[vector].vector, netdev);\n\t}\n}\n\n \nstatic void igbvf_irq_disable(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tew32(EIMC, ~0);\n\n\tif (adapter->msix_entries)\n\t\tew32(EIAC, 0);\n}\n\n \nstatic void igbvf_irq_enable(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tew32(EIAC, adapter->eims_enable_mask);\n\tew32(EIAM, adapter->eims_enable_mask);\n\tew32(EIMS, adapter->eims_enable_mask);\n}\n\n \nstatic int igbvf_poll(struct napi_struct *napi, int budget)\n{\n\tstruct igbvf_ring *rx_ring = container_of(napi, struct igbvf_ring, napi);\n\tstruct igbvf_adapter *adapter = rx_ring->adapter;\n\tstruct e1000_hw *hw = &adapter->hw;\n\tint work_done = 0;\n\n\tigbvf_clean_rx_irq(adapter, &work_done, budget);\n\n\tif (work_done == budget)\n\t\treturn budget;\n\n\t \n\tif (likely(napi_complete_done(napi, work_done))) {\n\t\tif (adapter->requested_itr & 3)\n\t\t\tigbvf_set_itr(adapter);\n\n\t\tif (!test_bit(__IGBVF_DOWN, &adapter->state))\n\t\t\tew32(EIMS, adapter->rx_ring->eims_value);\n\t}\n\n\treturn work_done;\n}\n\n \nstatic void igbvf_set_rlpml(struct igbvf_adapter *adapter)\n{\n\tint max_frame_size;\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tmax_frame_size = adapter->max_frame_size + VLAN_TAG_SIZE;\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\te1000_rlpml_set_vf(hw, max_frame_size);\n\n\tspin_unlock_bh(&hw->mbx_lock);\n}\n\nstatic int igbvf_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t __be16 proto, u16 vid)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\tif (hw->mac.ops.set_vfta(hw, vid, true)) {\n\t\tdev_warn(&adapter->pdev->dev, \"Vlan id %d\\n is not added\", vid);\n\t\tspin_unlock_bh(&hw->mbx_lock);\n\t\treturn -EINVAL;\n\t}\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\n\tset_bit(vid, adapter->active_vlans);\n\treturn 0;\n}\n\nstatic int igbvf_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t  __be16 proto, u16 vid)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\tif (hw->mac.ops.set_vfta(hw, vid, false)) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Failed to remove vlan id %d\\n\", vid);\n\t\tspin_unlock_bh(&hw->mbx_lock);\n\t\treturn -EINVAL;\n\t}\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\n\tclear_bit(vid, adapter->active_vlans);\n\treturn 0;\n}\n\nstatic void igbvf_restore_vlan(struct igbvf_adapter *adapter)\n{\n\tu16 vid;\n\n\tfor_each_set_bit(vid, adapter->active_vlans, VLAN_N_VID)\n\t\tigbvf_vlan_rx_add_vid(adapter->netdev, htons(ETH_P_8021Q), vid);\n}\n\n \nstatic void igbvf_configure_tx(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct igbvf_ring *tx_ring = adapter->tx_ring;\n\tu64 tdba;\n\tu32 txdctl, dca_txctrl;\n\n\t \n\ttxdctl = er32(TXDCTL(0));\n\tew32(TXDCTL(0), txdctl & ~E1000_TXDCTL_QUEUE_ENABLE);\n\te1e_flush();\n\tmsleep(10);\n\n\t \n\tew32(TDLEN(0), tx_ring->count * sizeof(union e1000_adv_tx_desc));\n\ttdba = tx_ring->dma;\n\tew32(TDBAL(0), (tdba & DMA_BIT_MASK(32)));\n\tew32(TDBAH(0), (tdba >> 32));\n\tew32(TDH(0), 0);\n\tew32(TDT(0), 0);\n\ttx_ring->head = E1000_TDH(0);\n\ttx_ring->tail = E1000_TDT(0);\n\n\t \n\tdca_txctrl = er32(DCA_TXCTRL(0));\n\tdca_txctrl &= ~E1000_DCA_TXCTRL_TX_WB_RO_EN;\n\tew32(DCA_TXCTRL(0), dca_txctrl);\n\n\t \n\ttxdctl |= E1000_TXDCTL_QUEUE_ENABLE;\n\tew32(TXDCTL(0), txdctl);\n\n\t \n\tadapter->txd_cmd = E1000_ADVTXD_DCMD_EOP | E1000_ADVTXD_DCMD_IFCS;\n\n\t \n\tadapter->txd_cmd |= E1000_ADVTXD_DCMD_RS;\n}\n\n \nstatic void igbvf_setup_srrctl(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\tu32 srrctl = 0;\n\n\tsrrctl &= ~(E1000_SRRCTL_DESCTYPE_MASK |\n\t\t    E1000_SRRCTL_BSIZEHDR_MASK |\n\t\t    E1000_SRRCTL_BSIZEPKT_MASK);\n\n\t \n\tsrrctl |= E1000_SRRCTL_DROP_EN;\n\n\t \n\tsrrctl |= ALIGN(adapter->rx_buffer_len, 1024) >>\n\t\t  E1000_SRRCTL_BSIZEPKT_SHIFT;\n\n\tif (adapter->rx_buffer_len < 2048) {\n\t\tadapter->rx_ps_hdr_size = 0;\n\t\tsrrctl |= E1000_SRRCTL_DESCTYPE_ADV_ONEBUF;\n\t} else {\n\t\tadapter->rx_ps_hdr_size = 128;\n\t\tsrrctl |= adapter->rx_ps_hdr_size <<\n\t\t\t  E1000_SRRCTL_BSIZEHDRSIZE_SHIFT;\n\t\tsrrctl |= E1000_SRRCTL_DESCTYPE_HDR_SPLIT_ALWAYS;\n\t}\n\n\tew32(SRRCTL(0), srrctl);\n}\n\n \nstatic void igbvf_configure_rx(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct igbvf_ring *rx_ring = adapter->rx_ring;\n\tu64 rdba;\n\tu32 rxdctl;\n\n\t \n\trxdctl = er32(RXDCTL(0));\n\tew32(RXDCTL(0), rxdctl & ~E1000_RXDCTL_QUEUE_ENABLE);\n\te1e_flush();\n\tmsleep(10);\n\n\t \n\trdba = rx_ring->dma;\n\tew32(RDBAL(0), (rdba & DMA_BIT_MASK(32)));\n\tew32(RDBAH(0), (rdba >> 32));\n\tew32(RDLEN(0), rx_ring->count * sizeof(union e1000_adv_rx_desc));\n\trx_ring->head = E1000_RDH(0);\n\trx_ring->tail = E1000_RDT(0);\n\tew32(RDH(0), 0);\n\tew32(RDT(0), 0);\n\n\trxdctl |= E1000_RXDCTL_QUEUE_ENABLE;\n\trxdctl &= 0xFFF00000;\n\trxdctl |= IGBVF_RX_PTHRESH;\n\trxdctl |= IGBVF_RX_HTHRESH << 8;\n\trxdctl |= IGBVF_RX_WTHRESH << 16;\n\n\tigbvf_set_rlpml(adapter);\n\n\t \n\tew32(RXDCTL(0), rxdctl);\n}\n\n \nstatic void igbvf_set_multi(struct net_device *netdev)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct netdev_hw_addr *ha;\n\tu8  *mta_list = NULL;\n\tint i;\n\n\tif (!netdev_mc_empty(netdev)) {\n\t\tmta_list = kmalloc_array(netdev_mc_count(netdev), ETH_ALEN,\n\t\t\t\t\t GFP_ATOMIC);\n\t\tif (!mta_list)\n\t\t\treturn;\n\t}\n\n\t \n\ti = 0;\n\tnetdev_for_each_mc_addr(ha, netdev)\n\t\tmemcpy(mta_list + (i++ * ETH_ALEN), ha->addr, ETH_ALEN);\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\thw->mac.ops.update_mc_addr_list(hw, mta_list, i, 0, 0);\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\tkfree(mta_list);\n}\n\n \nstatic int igbvf_set_uni(struct net_device *netdev)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tif (netdev_uc_count(netdev) > IGBVF_MAX_MAC_FILTERS) {\n\t\tpr_err(\"Too many unicast filters - No Space\\n\");\n\t\treturn -ENOSPC;\n\t}\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\t \n\thw->mac.ops.set_uc_addr(hw, E1000_VF_MAC_FILTER_CLR, NULL);\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\n\tif (!netdev_uc_empty(netdev)) {\n\t\tstruct netdev_hw_addr *ha;\n\n\t\t \n\t\tnetdev_for_each_uc_addr(ha, netdev) {\n\t\t\tspin_lock_bh(&hw->mbx_lock);\n\n\t\t\thw->mac.ops.set_uc_addr(hw, E1000_VF_MAC_FILTER_ADD,\n\t\t\t\t\t\tha->addr);\n\n\t\t\tspin_unlock_bh(&hw->mbx_lock);\n\t\t\tudelay(200);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void igbvf_set_rx_mode(struct net_device *netdev)\n{\n\tigbvf_set_multi(netdev);\n\tigbvf_set_uni(netdev);\n}\n\n \nstatic void igbvf_configure(struct igbvf_adapter *adapter)\n{\n\tigbvf_set_rx_mode(adapter->netdev);\n\n\tigbvf_restore_vlan(adapter);\n\n\tigbvf_configure_tx(adapter);\n\tigbvf_setup_srrctl(adapter);\n\tigbvf_configure_rx(adapter);\n\tigbvf_alloc_rx_buffers(adapter->rx_ring,\n\t\t\t       igbvf_desc_unused(adapter->rx_ring));\n}\n\n \nstatic void igbvf_reset(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_mac_info *mac = &adapter->hw.mac;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\t \n\tif (mac->ops.reset_hw(hw))\n\t\tdev_info(&adapter->pdev->dev, \"PF still resetting\\n\");\n\n\tmac->ops.init_hw(hw);\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\n\tif (is_valid_ether_addr(adapter->hw.mac.addr)) {\n\t\teth_hw_addr_set(netdev, adapter->hw.mac.addr);\n\t\tmemcpy(netdev->perm_addr, adapter->hw.mac.addr,\n\t\t       netdev->addr_len);\n\t}\n\n\tadapter->last_reset = jiffies;\n}\n\nint igbvf_up(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\t \n\tigbvf_configure(adapter);\n\n\tclear_bit(__IGBVF_DOWN, &adapter->state);\n\n\tnapi_enable(&adapter->rx_ring->napi);\n\tif (adapter->msix_entries)\n\t\tigbvf_configure_msix(adapter);\n\n\t \n\ter32(EICR);\n\tigbvf_irq_enable(adapter);\n\n\t \n\thw->mac.get_link_status = 1;\n\tmod_timer(&adapter->watchdog_timer, jiffies + 1);\n\n\treturn 0;\n}\n\nvoid igbvf_down(struct igbvf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct e1000_hw *hw = &adapter->hw;\n\tu32 rxdctl, txdctl;\n\n\t \n\tset_bit(__IGBVF_DOWN, &adapter->state);\n\n\t \n\trxdctl = er32(RXDCTL(0));\n\tew32(RXDCTL(0), rxdctl & ~E1000_RXDCTL_QUEUE_ENABLE);\n\n\tnetif_carrier_off(netdev);\n\tnetif_stop_queue(netdev);\n\n\t \n\ttxdctl = er32(TXDCTL(0));\n\tew32(TXDCTL(0), txdctl & ~E1000_TXDCTL_QUEUE_ENABLE);\n\n\t \n\te1e_flush();\n\tmsleep(10);\n\n\tnapi_disable(&adapter->rx_ring->napi);\n\n\tigbvf_irq_disable(adapter);\n\n\tdel_timer_sync(&adapter->watchdog_timer);\n\n\t \n\tigbvf_update_stats(adapter);\n\n\tadapter->link_speed = 0;\n\tadapter->link_duplex = 0;\n\n\tigbvf_reset(adapter);\n\tigbvf_clean_tx_ring(adapter->tx_ring);\n\tigbvf_clean_rx_ring(adapter->rx_ring);\n}\n\nvoid igbvf_reinit_locked(struct igbvf_adapter *adapter)\n{\n\tmight_sleep();\n\twhile (test_and_set_bit(__IGBVF_RESETTING, &adapter->state))\n\t\tusleep_range(1000, 2000);\n\tigbvf_down(adapter);\n\tigbvf_up(adapter);\n\tclear_bit(__IGBVF_RESETTING, &adapter->state);\n}\n\n \nstatic int igbvf_sw_init(struct igbvf_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\ts32 rc;\n\n\tadapter->rx_buffer_len = ETH_FRAME_LEN + VLAN_HLEN + ETH_FCS_LEN;\n\tadapter->rx_ps_hdr_size = 0;\n\tadapter->max_frame_size = netdev->mtu + ETH_HLEN + ETH_FCS_LEN;\n\tadapter->min_frame_size = ETH_ZLEN + ETH_FCS_LEN;\n\n\tadapter->tx_int_delay = 8;\n\tadapter->tx_abs_int_delay = 32;\n\tadapter->rx_int_delay = 0;\n\tadapter->rx_abs_int_delay = 8;\n\tadapter->requested_itr = 3;\n\tadapter->current_itr = IGBVF_START_ITR;\n\n\t \n\tadapter->ei->init_ops(&adapter->hw);\n\n\trc = adapter->hw.mac.ops.init_params(&adapter->hw);\n\tif (rc)\n\t\treturn rc;\n\n\trc = adapter->hw.mbx.ops.init_params(&adapter->hw);\n\tif (rc)\n\t\treturn rc;\n\n\tigbvf_set_interrupt_capability(adapter);\n\n\tif (igbvf_alloc_queues(adapter))\n\t\treturn -ENOMEM;\n\n\tspin_lock_init(&adapter->tx_queue_lock);\n\n\t \n\tigbvf_irq_disable(adapter);\n\n\tspin_lock_init(&adapter->stats_lock);\n\tspin_lock_init(&adapter->hw.mbx_lock);\n\n\tset_bit(__IGBVF_DOWN, &adapter->state);\n\treturn 0;\n}\n\nstatic void igbvf_initialize_last_counter_stats(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\tadapter->stats.last_gprc = er32(VFGPRC);\n\tadapter->stats.last_gorc = er32(VFGORC);\n\tadapter->stats.last_gptc = er32(VFGPTC);\n\tadapter->stats.last_gotc = er32(VFGOTC);\n\tadapter->stats.last_mprc = er32(VFMPRC);\n\tadapter->stats.last_gotlbc = er32(VFGOTLBC);\n\tadapter->stats.last_gptlbc = er32(VFGPTLBC);\n\tadapter->stats.last_gorlbc = er32(VFGORLBC);\n\tadapter->stats.last_gprlbc = er32(VFGPRLBC);\n\n\tadapter->stats.base_gprc = er32(VFGPRC);\n\tadapter->stats.base_gorc = er32(VFGORC);\n\tadapter->stats.base_gptc = er32(VFGPTC);\n\tadapter->stats.base_gotc = er32(VFGOTC);\n\tadapter->stats.base_mprc = er32(VFMPRC);\n\tadapter->stats.base_gotlbc = er32(VFGOTLBC);\n\tadapter->stats.base_gptlbc = er32(VFGPTLBC);\n\tadapter->stats.base_gorlbc = er32(VFGORLBC);\n\tadapter->stats.base_gprlbc = er32(VFGPRLBC);\n}\n\n \nstatic int igbvf_open(struct net_device *netdev)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\tint err;\n\n\t \n\tif (test_bit(__IGBVF_TESTING, &adapter->state))\n\t\treturn -EBUSY;\n\n\t \n\terr = igbvf_setup_tx_resources(adapter, adapter->tx_ring);\n\tif (err)\n\t\tgoto err_setup_tx;\n\n\t \n\terr = igbvf_setup_rx_resources(adapter, adapter->rx_ring);\n\tif (err)\n\t\tgoto err_setup_rx;\n\n\t \n\tigbvf_configure(adapter);\n\n\terr = igbvf_request_irq(adapter);\n\tif (err)\n\t\tgoto err_req_irq;\n\n\t \n\tclear_bit(__IGBVF_DOWN, &adapter->state);\n\n\tnapi_enable(&adapter->rx_ring->napi);\n\n\t \n\ter32(EICR);\n\n\tigbvf_irq_enable(adapter);\n\n\t \n\thw->mac.get_link_status = 1;\n\tmod_timer(&adapter->watchdog_timer, jiffies + 1);\n\n\treturn 0;\n\nerr_req_irq:\n\tigbvf_free_rx_resources(adapter->rx_ring);\nerr_setup_rx:\n\tigbvf_free_tx_resources(adapter->tx_ring);\nerr_setup_tx:\n\tigbvf_reset(adapter);\n\n\treturn err;\n}\n\n \nstatic int igbvf_close(struct net_device *netdev)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tWARN_ON(test_bit(__IGBVF_RESETTING, &adapter->state));\n\tigbvf_down(adapter);\n\n\tigbvf_free_irq(adapter);\n\n\tigbvf_free_tx_resources(adapter->tx_ring);\n\tigbvf_free_rx_resources(adapter->rx_ring);\n\n\treturn 0;\n}\n\n \nstatic int igbvf_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct sockaddr *addr = p;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\tmemcpy(hw->mac.addr, addr->sa_data, netdev->addr_len);\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\thw->mac.ops.rar_set(hw, hw->mac.addr, 0);\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\n\tif (!ether_addr_equal(addr->sa_data, hw->mac.addr))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(netdev, addr->sa_data);\n\n\treturn 0;\n}\n\n#define UPDATE_VF_COUNTER(reg, name) \\\n{ \\\n\tu32 current_counter = er32(reg); \\\n\tif (current_counter < adapter->stats.last_##name) \\\n\t\tadapter->stats.name += 0x100000000LL; \\\n\tadapter->stats.last_##name = current_counter; \\\n\tadapter->stats.name &= 0xFFFFFFFF00000000LL; \\\n\tadapter->stats.name |= current_counter; \\\n}\n\n \nvoid igbvf_update_stats(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct pci_dev *pdev = adapter->pdev;\n\n\t \n\tif (adapter->link_speed == 0)\n\t\treturn;\n\n\tif (test_bit(__IGBVF_RESETTING, &adapter->state))\n\t\treturn;\n\n\tif (pci_channel_offline(pdev))\n\t\treturn;\n\n\tUPDATE_VF_COUNTER(VFGPRC, gprc);\n\tUPDATE_VF_COUNTER(VFGORC, gorc);\n\tUPDATE_VF_COUNTER(VFGPTC, gptc);\n\tUPDATE_VF_COUNTER(VFGOTC, gotc);\n\tUPDATE_VF_COUNTER(VFMPRC, mprc);\n\tUPDATE_VF_COUNTER(VFGOTLBC, gotlbc);\n\tUPDATE_VF_COUNTER(VFGPTLBC, gptlbc);\n\tUPDATE_VF_COUNTER(VFGORLBC, gorlbc);\n\tUPDATE_VF_COUNTER(VFGPRLBC, gprlbc);\n\n\t \n\tadapter->netdev->stats.multicast = adapter->stats.mprc;\n}\n\nstatic void igbvf_print_link_info(struct igbvf_adapter *adapter)\n{\n\tdev_info(&adapter->pdev->dev, \"Link is Up %d Mbps %s Duplex\\n\",\n\t\t adapter->link_speed,\n\t\t adapter->link_duplex == FULL_DUPLEX ? \"Full\" : \"Half\");\n}\n\nstatic bool igbvf_has_link(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\ts32 ret_val = E1000_SUCCESS;\n\tbool link_active;\n\n\t \n\tif (test_bit(__IGBVF_DOWN, &adapter->state))\n\t\treturn false;\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\tret_val = hw->mac.ops.check_for_link(hw);\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\n\tlink_active = !hw->mac.get_link_status;\n\n\t \n\tif (ret_val && time_after(jiffies, adapter->last_reset + (10 * HZ)))\n\t\tschedule_work(&adapter->reset_task);\n\n\treturn link_active;\n}\n\n \nstatic void igbvf_watchdog(struct timer_list *t)\n{\n\tstruct igbvf_adapter *adapter = from_timer(adapter, t, watchdog_timer);\n\n\t \n\tschedule_work(&adapter->watchdog_task);\n}\n\nstatic void igbvf_watchdog_task(struct work_struct *work)\n{\n\tstruct igbvf_adapter *adapter = container_of(work,\n\t\t\t\t\t\t     struct igbvf_adapter,\n\t\t\t\t\t\t     watchdog_task);\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct e1000_mac_info *mac = &adapter->hw.mac;\n\tstruct igbvf_ring *tx_ring = adapter->tx_ring;\n\tstruct e1000_hw *hw = &adapter->hw;\n\tu32 link;\n\tint tx_pending = 0;\n\n\tlink = igbvf_has_link(adapter);\n\n\tif (link) {\n\t\tif (!netif_carrier_ok(netdev)) {\n\t\t\tmac->ops.get_link_up_info(&adapter->hw,\n\t\t\t\t\t\t  &adapter->link_speed,\n\t\t\t\t\t\t  &adapter->link_duplex);\n\t\t\tigbvf_print_link_info(adapter);\n\n\t\t\tnetif_carrier_on(netdev);\n\t\t\tnetif_wake_queue(netdev);\n\t\t}\n\t} else {\n\t\tif (netif_carrier_ok(netdev)) {\n\t\t\tadapter->link_speed = 0;\n\t\t\tadapter->link_duplex = 0;\n\t\t\tdev_info(&adapter->pdev->dev, \"Link is Down\\n\");\n\t\t\tnetif_carrier_off(netdev);\n\t\t\tnetif_stop_queue(netdev);\n\t\t}\n\t}\n\n\tif (netif_carrier_ok(netdev)) {\n\t\tigbvf_update_stats(adapter);\n\t} else {\n\t\ttx_pending = (igbvf_desc_unused(tx_ring) + 1 <\n\t\t\t      tx_ring->count);\n\t\tif (tx_pending) {\n\t\t\t \n\t\t\tadapter->tx_timeout_count++;\n\t\t\tschedule_work(&adapter->reset_task);\n\t\t}\n\t}\n\n\t \n\tew32(EICS, adapter->rx_ring->eims_value);\n\n\t \n\tif (!test_bit(__IGBVF_DOWN, &adapter->state))\n\t\tmod_timer(&adapter->watchdog_timer,\n\t\t\t  round_jiffies(jiffies + (2 * HZ)));\n}\n\n#define IGBVF_TX_FLAGS_CSUM\t\t0x00000001\n#define IGBVF_TX_FLAGS_VLAN\t\t0x00000002\n#define IGBVF_TX_FLAGS_TSO\t\t0x00000004\n#define IGBVF_TX_FLAGS_IPV4\t\t0x00000008\n#define IGBVF_TX_FLAGS_VLAN_MASK\t0xffff0000\n#define IGBVF_TX_FLAGS_VLAN_SHIFT\t16\n\nstatic void igbvf_tx_ctxtdesc(struct igbvf_ring *tx_ring, u32 vlan_macip_lens,\n\t\t\t      u32 type_tucmd, u32 mss_l4len_idx)\n{\n\tstruct e1000_adv_tx_context_desc *context_desc;\n\tstruct igbvf_buffer *buffer_info;\n\tu16 i = tx_ring->next_to_use;\n\n\tcontext_desc = IGBVF_TX_CTXTDESC_ADV(*tx_ring, i);\n\tbuffer_info = &tx_ring->buffer_info[i];\n\n\ti++;\n\ttx_ring->next_to_use = (i < tx_ring->count) ? i : 0;\n\n\t \n\ttype_tucmd |= E1000_TXD_CMD_DEXT | E1000_ADVTXD_DTYP_CTXT;\n\n\tcontext_desc->vlan_macip_lens\t= cpu_to_le32(vlan_macip_lens);\n\tcontext_desc->seqnum_seed\t= 0;\n\tcontext_desc->type_tucmd_mlhl\t= cpu_to_le32(type_tucmd);\n\tcontext_desc->mss_l4len_idx\t= cpu_to_le32(mss_l4len_idx);\n\n\tbuffer_info->time_stamp = jiffies;\n\tbuffer_info->dma = 0;\n}\n\nstatic int igbvf_tso(struct igbvf_ring *tx_ring,\n\t\t     struct sk_buff *skb, u32 tx_flags, u8 *hdr_len)\n{\n\tu32 vlan_macip_lens, type_tucmd, mss_l4len_idx;\n\tunion {\n\t\tstruct iphdr *v4;\n\t\tstruct ipv6hdr *v6;\n\t\tunsigned char *hdr;\n\t} ip;\n\tunion {\n\t\tstruct tcphdr *tcp;\n\t\tunsigned char *hdr;\n\t} l4;\n\tu32 paylen, l4_offset;\n\tint err;\n\n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn 0;\n\n\tif (!skb_is_gso(skb))\n\t\treturn 0;\n\n\terr = skb_cow_head(skb, 0);\n\tif (err < 0)\n\t\treturn err;\n\n\tip.hdr = skb_network_header(skb);\n\tl4.hdr = skb_checksum_start(skb);\n\n\t \n\ttype_tucmd = E1000_ADVTXD_TUCMD_L4T_TCP;\n\n\t \n\tif (ip.v4->version == 4) {\n\t\tunsigned char *csum_start = skb_checksum_start(skb);\n\t\tunsigned char *trans_start = ip.hdr + (ip.v4->ihl * 4);\n\n\t\t \n\t\tip.v4->check = csum_fold(csum_partial(trans_start,\n\t\t\t\t\t\t      csum_start - trans_start,\n\t\t\t\t\t\t      0));\n\t\ttype_tucmd |= E1000_ADVTXD_TUCMD_IPV4;\n\n\t\tip.v4->tot_len = 0;\n\t} else {\n\t\tip.v6->payload_len = 0;\n\t}\n\n\t \n\tl4_offset = l4.hdr - skb->data;\n\n\t \n\t*hdr_len = (l4.tcp->doff * 4) + l4_offset;\n\n\t \n\tpaylen = skb->len - l4_offset;\n\tcsum_replace_by_diff(&l4.tcp->check, (__force __wsum)htonl(paylen));\n\n\t \n\tmss_l4len_idx = (*hdr_len - l4_offset) << E1000_ADVTXD_L4LEN_SHIFT;\n\tmss_l4len_idx |= skb_shinfo(skb)->gso_size << E1000_ADVTXD_MSS_SHIFT;\n\n\t \n\tvlan_macip_lens = l4.hdr - ip.hdr;\n\tvlan_macip_lens |= (ip.hdr - skb->data) << E1000_ADVTXD_MACLEN_SHIFT;\n\tvlan_macip_lens |= tx_flags & IGBVF_TX_FLAGS_VLAN_MASK;\n\n\tigbvf_tx_ctxtdesc(tx_ring, vlan_macip_lens, type_tucmd, mss_l4len_idx);\n\n\treturn 1;\n}\n\nstatic bool igbvf_tx_csum(struct igbvf_ring *tx_ring, struct sk_buff *skb,\n\t\t\t  u32 tx_flags, __be16 protocol)\n{\n\tu32 vlan_macip_lens = 0;\n\tu32 type_tucmd = 0;\n\n\tif (skb->ip_summed != CHECKSUM_PARTIAL) {\ncsum_failed:\n\t\tif (!(tx_flags & IGBVF_TX_FLAGS_VLAN))\n\t\t\treturn false;\n\t\tgoto no_csum;\n\t}\n\n\tswitch (skb->csum_offset) {\n\tcase offsetof(struct tcphdr, check):\n\t\ttype_tucmd = E1000_ADVTXD_TUCMD_L4T_TCP;\n\t\tfallthrough;\n\tcase offsetof(struct udphdr, check):\n\t\tbreak;\n\tcase offsetof(struct sctphdr, checksum):\n\t\t \n\t\tif (skb_csum_is_sctp(skb)) {\n\t\t\ttype_tucmd = E1000_ADVTXD_TUCMD_L4T_SCTP;\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\n\tdefault:\n\t\tskb_checksum_help(skb);\n\t\tgoto csum_failed;\n\t}\n\n\tvlan_macip_lens = skb_checksum_start_offset(skb) -\n\t\t\t  skb_network_offset(skb);\nno_csum:\n\tvlan_macip_lens |= skb_network_offset(skb) << E1000_ADVTXD_MACLEN_SHIFT;\n\tvlan_macip_lens |= tx_flags & IGBVF_TX_FLAGS_VLAN_MASK;\n\n\tigbvf_tx_ctxtdesc(tx_ring, vlan_macip_lens, type_tucmd, 0);\n\treturn true;\n}\n\nstatic int igbvf_maybe_stop_tx(struct net_device *netdev, int size)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tif (igbvf_desc_unused(adapter->tx_ring) >= size)\n\t\treturn 0;\n\n\tnetif_stop_queue(netdev);\n\n\t \n\tsmp_mb();\n\n\t \n\tif (igbvf_desc_unused(adapter->tx_ring) < size)\n\t\treturn -EBUSY;\n\n\tnetif_wake_queue(netdev);\n\n\t++adapter->restart_queue;\n\treturn 0;\n}\n\n#define IGBVF_MAX_TXD_PWR\t16\n#define IGBVF_MAX_DATA_PER_TXD\t(1u << IGBVF_MAX_TXD_PWR)\n\nstatic inline int igbvf_tx_map_adv(struct igbvf_adapter *adapter,\n\t\t\t\t   struct igbvf_ring *tx_ring,\n\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct igbvf_buffer *buffer_info;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tunsigned int len = skb_headlen(skb);\n\tunsigned int count = 0, i;\n\tunsigned int f;\n\n\ti = tx_ring->next_to_use;\n\n\tbuffer_info = &tx_ring->buffer_info[i];\n\tBUG_ON(len >= IGBVF_MAX_DATA_PER_TXD);\n\tbuffer_info->length = len;\n\t \n\tbuffer_info->time_stamp = jiffies;\n\tbuffer_info->mapped_as_page = false;\n\tbuffer_info->dma = dma_map_single(&pdev->dev, skb->data, len,\n\t\t\t\t\t  DMA_TO_DEVICE);\n\tif (dma_mapping_error(&pdev->dev, buffer_info->dma))\n\t\tgoto dma_error;\n\n\tfor (f = 0; f < skb_shinfo(skb)->nr_frags; f++) {\n\t\tconst skb_frag_t *frag;\n\n\t\tcount++;\n\t\ti++;\n\t\tif (i == tx_ring->count)\n\t\t\ti = 0;\n\n\t\tfrag = &skb_shinfo(skb)->frags[f];\n\t\tlen = skb_frag_size(frag);\n\n\t\tbuffer_info = &tx_ring->buffer_info[i];\n\t\tBUG_ON(len >= IGBVF_MAX_DATA_PER_TXD);\n\t\tbuffer_info->length = len;\n\t\tbuffer_info->time_stamp = jiffies;\n\t\tbuffer_info->mapped_as_page = true;\n\t\tbuffer_info->dma = skb_frag_dma_map(&pdev->dev, frag, 0, len,\n\t\t\t\t\t\t    DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&pdev->dev, buffer_info->dma))\n\t\t\tgoto dma_error;\n\t}\n\n\ttx_ring->buffer_info[i].skb = skb;\n\n\treturn ++count;\n\ndma_error:\n\tdev_err(&pdev->dev, \"TX DMA map failed\\n\");\n\n\t \n\tbuffer_info->dma = 0;\n\tbuffer_info->time_stamp = 0;\n\tbuffer_info->length = 0;\n\tbuffer_info->mapped_as_page = false;\n\tif (count)\n\t\tcount--;\n\n\t \n\twhile (count--) {\n\t\tif (i == 0)\n\t\t\ti += tx_ring->count;\n\t\ti--;\n\t\tbuffer_info = &tx_ring->buffer_info[i];\n\t\tigbvf_put_txbuf(adapter, buffer_info);\n\t}\n\n\treturn 0;\n}\n\nstatic inline void igbvf_tx_queue_adv(struct igbvf_adapter *adapter,\n\t\t\t\t      struct igbvf_ring *tx_ring,\n\t\t\t\t      int tx_flags, int count,\n\t\t\t\t      unsigned int first, u32 paylen,\n\t\t\t\t      u8 hdr_len)\n{\n\tunion e1000_adv_tx_desc *tx_desc = NULL;\n\tstruct igbvf_buffer *buffer_info;\n\tu32 olinfo_status = 0, cmd_type_len;\n\tunsigned int i;\n\n\tcmd_type_len = (E1000_ADVTXD_DTYP_DATA | E1000_ADVTXD_DCMD_IFCS |\n\t\t\tE1000_ADVTXD_DCMD_DEXT);\n\n\tif (tx_flags & IGBVF_TX_FLAGS_VLAN)\n\t\tcmd_type_len |= E1000_ADVTXD_DCMD_VLE;\n\n\tif (tx_flags & IGBVF_TX_FLAGS_TSO) {\n\t\tcmd_type_len |= E1000_ADVTXD_DCMD_TSE;\n\n\t\t \n\t\tolinfo_status |= E1000_TXD_POPTS_TXSM << 8;\n\n\t\t \n\t\tif (tx_flags & IGBVF_TX_FLAGS_IPV4)\n\t\t\tolinfo_status |= E1000_TXD_POPTS_IXSM << 8;\n\n\t} else if (tx_flags & IGBVF_TX_FLAGS_CSUM) {\n\t\tolinfo_status |= E1000_TXD_POPTS_TXSM << 8;\n\t}\n\n\tolinfo_status |= ((paylen - hdr_len) << E1000_ADVTXD_PAYLEN_SHIFT);\n\n\ti = tx_ring->next_to_use;\n\twhile (count--) {\n\t\tbuffer_info = &tx_ring->buffer_info[i];\n\t\ttx_desc = IGBVF_TX_DESC_ADV(*tx_ring, i);\n\t\ttx_desc->read.buffer_addr = cpu_to_le64(buffer_info->dma);\n\t\ttx_desc->read.cmd_type_len =\n\t\t\t cpu_to_le32(cmd_type_len | buffer_info->length);\n\t\ttx_desc->read.olinfo_status = cpu_to_le32(olinfo_status);\n\t\ti++;\n\t\tif (i == tx_ring->count)\n\t\t\ti = 0;\n\t}\n\n\ttx_desc->read.cmd_type_len |= cpu_to_le32(adapter->txd_cmd);\n\t \n\twmb();\n\n\ttx_ring->buffer_info[first].next_to_watch = tx_desc;\n\ttx_ring->next_to_use = i;\n\twritel(i, adapter->hw.hw_addr + tx_ring->tail);\n}\n\nstatic netdev_tx_t igbvf_xmit_frame_ring_adv(struct sk_buff *skb,\n\t\t\t\t\t     struct net_device *netdev,\n\t\t\t\t\t     struct igbvf_ring *tx_ring)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tunsigned int first, tx_flags = 0;\n\tu8 hdr_len = 0;\n\tint count = 0;\n\tint tso = 0;\n\t__be16 protocol = vlan_get_protocol(skb);\n\n\tif (test_bit(__IGBVF_DOWN, &adapter->state)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tif (skb->len <= 0) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\t \n\tif (igbvf_maybe_stop_tx(netdev, skb_shinfo(skb)->nr_frags + 4)) {\n\t\t \n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\ttx_flags |= IGBVF_TX_FLAGS_VLAN;\n\t\ttx_flags |= (skb_vlan_tag_get(skb) <<\n\t\t\t     IGBVF_TX_FLAGS_VLAN_SHIFT);\n\t}\n\n\tif (protocol == htons(ETH_P_IP))\n\t\ttx_flags |= IGBVF_TX_FLAGS_IPV4;\n\n\tfirst = tx_ring->next_to_use;\n\n\ttso = igbvf_tso(tx_ring, skb, tx_flags, &hdr_len);\n\tif (unlikely(tso < 0)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tif (tso)\n\t\ttx_flags |= IGBVF_TX_FLAGS_TSO;\n\telse if (igbvf_tx_csum(tx_ring, skb, tx_flags, protocol) &&\n\t\t (skb->ip_summed == CHECKSUM_PARTIAL))\n\t\ttx_flags |= IGBVF_TX_FLAGS_CSUM;\n\n\t \n\tcount = igbvf_tx_map_adv(adapter, tx_ring, skb);\n\n\tif (count) {\n\t\tigbvf_tx_queue_adv(adapter, tx_ring, tx_flags, count,\n\t\t\t\t   first, skb->len, hdr_len);\n\t\t \n\t\tigbvf_maybe_stop_tx(netdev, MAX_SKB_FRAGS + 4);\n\t} else {\n\t\tdev_kfree_skb_any(skb);\n\t\ttx_ring->buffer_info[first].time_stamp = 0;\n\t\ttx_ring->next_to_use = first;\n\t}\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic netdev_tx_t igbvf_xmit_frame(struct sk_buff *skb,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct igbvf_ring *tx_ring;\n\n\tif (test_bit(__IGBVF_DOWN, &adapter->state)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\ttx_ring = &adapter->tx_ring[0];\n\n\treturn igbvf_xmit_frame_ring_adv(skb, netdev, tx_ring);\n}\n\n \nstatic void igbvf_tx_timeout(struct net_device *netdev, unsigned int __always_unused txqueue)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\t \n\tadapter->tx_timeout_count++;\n\tschedule_work(&adapter->reset_task);\n}\n\nstatic void igbvf_reset_task(struct work_struct *work)\n{\n\tstruct igbvf_adapter *adapter;\n\n\tadapter = container_of(work, struct igbvf_adapter, reset_task);\n\n\tigbvf_reinit_locked(adapter);\n}\n\n \nstatic int igbvf_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tint max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN;\n\n\twhile (test_and_set_bit(__IGBVF_RESETTING, &adapter->state))\n\t\tusleep_range(1000, 2000);\n\t \n\tadapter->max_frame_size = max_frame;\n\tif (netif_running(netdev))\n\t\tigbvf_down(adapter);\n\n\t \n\n\tif (max_frame <= 1024)\n\t\tadapter->rx_buffer_len = 1024;\n\telse if (max_frame <= 2048)\n\t\tadapter->rx_buffer_len = 2048;\n\telse\n#if (PAGE_SIZE / 2) > 16384\n\t\tadapter->rx_buffer_len = 16384;\n#else\n\t\tadapter->rx_buffer_len = PAGE_SIZE / 2;\n#endif\n\n\t \n\tif ((max_frame == ETH_FRAME_LEN + ETH_FCS_LEN) ||\n\t    (max_frame == ETH_FRAME_LEN + VLAN_HLEN + ETH_FCS_LEN))\n\t\tadapter->rx_buffer_len = ETH_FRAME_LEN + VLAN_HLEN +\n\t\t\t\t\t ETH_FCS_LEN;\n\n\tnetdev_dbg(netdev, \"changing MTU from %d to %d\\n\",\n\t\t   netdev->mtu, new_mtu);\n\tnetdev->mtu = new_mtu;\n\n\tif (netif_running(netdev))\n\t\tigbvf_up(adapter);\n\telse\n\t\tigbvf_reset(adapter);\n\n\tclear_bit(__IGBVF_RESETTING, &adapter->state);\n\n\treturn 0;\n}\n\nstatic int igbvf_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tswitch (cmd) {\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int igbvf_suspend(struct device *dev_d)\n{\n\tstruct net_device *netdev = dev_get_drvdata(dev_d);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tnetif_device_detach(netdev);\n\n\tif (netif_running(netdev)) {\n\t\tWARN_ON(test_bit(__IGBVF_RESETTING, &adapter->state));\n\t\tigbvf_down(adapter);\n\t\tigbvf_free_irq(adapter);\n\t}\n\n\treturn 0;\n}\n\nstatic int __maybe_unused igbvf_resume(struct device *dev_d)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev_d);\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tu32 err;\n\n\tpci_set_master(pdev);\n\n\tif (netif_running(netdev)) {\n\t\terr = igbvf_request_irq(adapter);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tigbvf_reset(adapter);\n\n\tif (netif_running(netdev))\n\t\tigbvf_up(adapter);\n\n\tnetif_device_attach(netdev);\n\n\treturn 0;\n}\n\nstatic void igbvf_shutdown(struct pci_dev *pdev)\n{\n\tigbvf_suspend(&pdev->dev);\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\n \nstatic void igbvf_netpoll(struct net_device *netdev)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tdisable_irq(adapter->pdev->irq);\n\n\tigbvf_clean_tx_irq(adapter->tx_ring);\n\n\tenable_irq(adapter->pdev->irq);\n}\n#endif\n\n \nstatic pci_ers_result_t igbvf_io_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\tpci_channel_state_t state)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tnetif_device_detach(netdev);\n\n\tif (state == pci_channel_io_perm_failure)\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\n\tif (netif_running(netdev))\n\t\tigbvf_down(adapter);\n\tpci_disable_device(pdev);\n\n\t \n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\n \nstatic pci_ers_result_t igbvf_io_slot_reset(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tif (pci_enable_device_mem(pdev)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Cannot re-enable PCI device after reset.\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\tpci_set_master(pdev);\n\n\tigbvf_reset(adapter);\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n \nstatic void igbvf_io_resume(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tif (netif_running(netdev)) {\n\t\tif (igbvf_up(adapter)) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"can't bring device back up after reset\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\tnetif_device_attach(netdev);\n}\n\n \nstatic void igbvf_io_prepare(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\twhile (test_and_set_bit(__IGBVF_RESETTING, &adapter->state))\n\t\tusleep_range(1000, 2000);\n\tigbvf_down(adapter);\n}\n\n \nstatic void igbvf_io_reset_done(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tigbvf_up(adapter);\n\tclear_bit(__IGBVF_RESETTING, &adapter->state);\n}\n\nstatic void igbvf_print_device_info(struct igbvf_adapter *adapter)\n{\n\tstruct e1000_hw *hw = &adapter->hw;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct pci_dev *pdev = adapter->pdev;\n\n\tif (hw->mac.type == e1000_vfadapt_i350)\n\t\tdev_info(&pdev->dev, \"Intel(R) I350 Virtual Function\\n\");\n\telse\n\t\tdev_info(&pdev->dev, \"Intel(R) 82576 Virtual Function\\n\");\n\tdev_info(&pdev->dev, \"Address: %pM\\n\", netdev->dev_addr);\n}\n\nstatic int igbvf_set_features(struct net_device *netdev,\n\t\t\t      netdev_features_t features)\n{\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\n\tif (features & NETIF_F_RXCSUM)\n\t\tadapter->flags &= ~IGBVF_FLAG_RX_CSUM_DISABLED;\n\telse\n\t\tadapter->flags |= IGBVF_FLAG_RX_CSUM_DISABLED;\n\n\treturn 0;\n}\n\n#define IGBVF_MAX_MAC_HDR_LEN\t\t127\n#define IGBVF_MAX_NETWORK_HDR_LEN\t511\n\nstatic netdev_features_t\nigbvf_features_check(struct sk_buff *skb, struct net_device *dev,\n\t\t     netdev_features_t features)\n{\n\tunsigned int network_hdr_len, mac_hdr_len;\n\n\t \n\tmac_hdr_len = skb_network_header(skb) - skb->data;\n\tif (unlikely(mac_hdr_len > IGBVF_MAX_MAC_HDR_LEN))\n\t\treturn features & ~(NETIF_F_HW_CSUM |\n\t\t\t\t    NETIF_F_SCTP_CRC |\n\t\t\t\t    NETIF_F_HW_VLAN_CTAG_TX |\n\t\t\t\t    NETIF_F_TSO |\n\t\t\t\t    NETIF_F_TSO6);\n\n\tnetwork_hdr_len = skb_checksum_start(skb) - skb_network_header(skb);\n\tif (unlikely(network_hdr_len >  IGBVF_MAX_NETWORK_HDR_LEN))\n\t\treturn features & ~(NETIF_F_HW_CSUM |\n\t\t\t\t    NETIF_F_SCTP_CRC |\n\t\t\t\t    NETIF_F_TSO |\n\t\t\t\t    NETIF_F_TSO6);\n\n\t \n\tif (skb->encapsulation && !(features & NETIF_F_TSO_MANGLEID))\n\t\tfeatures &= ~NETIF_F_TSO;\n\n\treturn features;\n}\n\nstatic const struct net_device_ops igbvf_netdev_ops = {\n\t.ndo_open\t\t= igbvf_open,\n\t.ndo_stop\t\t= igbvf_close,\n\t.ndo_start_xmit\t\t= igbvf_xmit_frame,\n\t.ndo_set_rx_mode\t= igbvf_set_rx_mode,\n\t.ndo_set_mac_address\t= igbvf_set_mac,\n\t.ndo_change_mtu\t\t= igbvf_change_mtu,\n\t.ndo_eth_ioctl\t\t= igbvf_ioctl,\n\t.ndo_tx_timeout\t\t= igbvf_tx_timeout,\n\t.ndo_vlan_rx_add_vid\t= igbvf_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= igbvf_vlan_rx_kill_vid,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= igbvf_netpoll,\n#endif\n\t.ndo_set_features\t= igbvf_set_features,\n\t.ndo_features_check\t= igbvf_features_check,\n};\n\n \nstatic int igbvf_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct net_device *netdev;\n\tstruct igbvf_adapter *adapter;\n\tstruct e1000_hw *hw;\n\tconst struct igbvf_info *ei = igbvf_info_tbl[ent->driver_data];\n\tstatic int cards_found;\n\tint err;\n\n\terr = pci_enable_device_mem(pdev);\n\tif (err)\n\t\treturn err;\n\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"No usable DMA configuration, aborting\\n\");\n\t\tgoto err_dma;\n\t}\n\n\terr = pci_request_regions(pdev, igbvf_driver_name);\n\tif (err)\n\t\tgoto err_pci_reg;\n\n\tpci_set_master(pdev);\n\n\terr = -ENOMEM;\n\tnetdev = alloc_etherdev(sizeof(struct igbvf_adapter));\n\tif (!netdev)\n\t\tgoto err_alloc_etherdev;\n\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\n\tpci_set_drvdata(pdev, netdev);\n\tadapter = netdev_priv(netdev);\n\thw = &adapter->hw;\n\tadapter->netdev = netdev;\n\tadapter->pdev = pdev;\n\tadapter->ei = ei;\n\tadapter->pba = ei->pba;\n\tadapter->flags = ei->flags;\n\tadapter->hw.back = adapter;\n\tadapter->hw.mac.type = ei->mac;\n\tadapter->msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);\n\n\t \n\n\thw->vendor_id = pdev->vendor;\n\thw->device_id = pdev->device;\n\thw->subsystem_vendor_id = pdev->subsystem_vendor;\n\thw->subsystem_device_id = pdev->subsystem_device;\n\thw->revision_id = pdev->revision;\n\n\terr = -EIO;\n\tadapter->hw.hw_addr = ioremap(pci_resource_start(pdev, 0),\n\t\t\t\t      pci_resource_len(pdev, 0));\n\n\tif (!adapter->hw.hw_addr)\n\t\tgoto err_ioremap;\n\n\tif (ei->get_variants) {\n\t\terr = ei->get_variants(adapter);\n\t\tif (err)\n\t\t\tgoto err_get_variants;\n\t}\n\n\t \n\terr = igbvf_sw_init(adapter);\n\tif (err)\n\t\tgoto err_sw_init;\n\n\t \n\tnetdev->netdev_ops = &igbvf_netdev_ops;\n\n\tigbvf_set_ethtool_ops(netdev);\n\tnetdev->watchdog_timeo = 5 * HZ;\n\tstrncpy(netdev->name, pci_name(pdev), sizeof(netdev->name) - 1);\n\n\tadapter->bd_number = cards_found++;\n\n\tnetdev->hw_features = NETIF_F_SG |\n\t\t\t      NETIF_F_TSO |\n\t\t\t      NETIF_F_TSO6 |\n\t\t\t      NETIF_F_RXCSUM |\n\t\t\t      NETIF_F_HW_CSUM |\n\t\t\t      NETIF_F_SCTP_CRC;\n\n#define IGBVF_GSO_PARTIAL_FEATURES (NETIF_F_GSO_GRE | \\\n\t\t\t\t    NETIF_F_GSO_GRE_CSUM | \\\n\t\t\t\t    NETIF_F_GSO_IPXIP4 | \\\n\t\t\t\t    NETIF_F_GSO_IPXIP6 | \\\n\t\t\t\t    NETIF_F_GSO_UDP_TUNNEL | \\\n\t\t\t\t    NETIF_F_GSO_UDP_TUNNEL_CSUM)\n\n\tnetdev->gso_partial_features = IGBVF_GSO_PARTIAL_FEATURES;\n\tnetdev->hw_features |= NETIF_F_GSO_PARTIAL |\n\t\t\t       IGBVF_GSO_PARTIAL_FEATURES;\n\n\tnetdev->features = netdev->hw_features | NETIF_F_HIGHDMA;\n\n\tnetdev->vlan_features |= netdev->features | NETIF_F_TSO_MANGLEID;\n\tnetdev->mpls_features |= NETIF_F_HW_CSUM;\n\tnetdev->hw_enc_features |= netdev->vlan_features;\n\n\t \n\tnetdev->features |= NETIF_F_HW_VLAN_CTAG_FILTER |\n\t\t\t    NETIF_F_HW_VLAN_CTAG_RX |\n\t\t\t    NETIF_F_HW_VLAN_CTAG_TX;\n\n\t \n\tnetdev->min_mtu = ETH_MIN_MTU;\n\tnetdev->max_mtu = MAX_STD_JUMBO_FRAME_SIZE;\n\n\tspin_lock_bh(&hw->mbx_lock);\n\n\t \n\terr = hw->mac.ops.reset_hw(hw);\n\tif (err) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"PF still in reset state. Is the PF interface up?\\n\");\n\t} else {\n\t\terr = hw->mac.ops.read_mac_addr(hw);\n\t\tif (err)\n\t\t\tdev_info(&pdev->dev, \"Error reading MAC address.\\n\");\n\t\telse if (is_zero_ether_addr(adapter->hw.mac.addr))\n\t\t\tdev_info(&pdev->dev,\n\t\t\t\t \"MAC address not assigned by administrator.\\n\");\n\t\teth_hw_addr_set(netdev, adapter->hw.mac.addr);\n\t}\n\n\tspin_unlock_bh(&hw->mbx_lock);\n\n\tif (!is_valid_ether_addr(netdev->dev_addr)) {\n\t\tdev_info(&pdev->dev, \"Assigning random MAC address.\\n\");\n\t\teth_hw_addr_random(netdev);\n\t\tmemcpy(adapter->hw.mac.addr, netdev->dev_addr,\n\t\t       netdev->addr_len);\n\t}\n\n\ttimer_setup(&adapter->watchdog_timer, igbvf_watchdog, 0);\n\n\tINIT_WORK(&adapter->reset_task, igbvf_reset_task);\n\tINIT_WORK(&adapter->watchdog_task, igbvf_watchdog_task);\n\n\t \n\tadapter->rx_ring->count = 1024;\n\tadapter->tx_ring->count = 1024;\n\n\t \n\tigbvf_reset(adapter);\n\n\t \n\tif (adapter->hw.mac.type == e1000_vfadapt_i350)\n\t\tadapter->flags |= IGBVF_FLAG_RX_LB_VLAN_BSWAP;\n\n\tstrcpy(netdev->name, \"eth%d\");\n\terr = register_netdev(netdev);\n\tif (err)\n\t\tgoto err_hw_init;\n\n\t \n\tnetif_carrier_off(netdev);\n\tnetif_stop_queue(netdev);\n\n\tigbvf_print_device_info(adapter);\n\n\tigbvf_initialize_last_counter_stats(adapter);\n\n\treturn 0;\n\nerr_hw_init:\n\tnetif_napi_del(&adapter->rx_ring->napi);\n\tkfree(adapter->tx_ring);\n\tkfree(adapter->rx_ring);\nerr_sw_init:\n\tigbvf_reset_interrupt_capability(adapter);\nerr_get_variants:\n\tiounmap(adapter->hw.hw_addr);\nerr_ioremap:\n\tfree_netdev(netdev);\nerr_alloc_etherdev:\n\tpci_release_regions(pdev);\nerr_pci_reg:\nerr_dma:\n\tpci_disable_device(pdev);\n\treturn err;\n}\n\n \nstatic void igbvf_remove(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct igbvf_adapter *adapter = netdev_priv(netdev);\n\tstruct e1000_hw *hw = &adapter->hw;\n\n\t \n\tset_bit(__IGBVF_DOWN, &adapter->state);\n\tdel_timer_sync(&adapter->watchdog_timer);\n\n\tcancel_work_sync(&adapter->reset_task);\n\tcancel_work_sync(&adapter->watchdog_task);\n\n\tunregister_netdev(netdev);\n\n\tigbvf_reset_interrupt_capability(adapter);\n\n\t \n\tnetif_napi_del(&adapter->rx_ring->napi);\n\tkfree(adapter->tx_ring);\n\tkfree(adapter->rx_ring);\n\n\tiounmap(hw->hw_addr);\n\tif (hw->flash_address)\n\t\tiounmap(hw->flash_address);\n\tpci_release_regions(pdev);\n\n\tfree_netdev(netdev);\n\n\tpci_disable_device(pdev);\n}\n\n \nstatic const struct pci_error_handlers igbvf_err_handler = {\n\t.error_detected = igbvf_io_error_detected,\n\t.slot_reset = igbvf_io_slot_reset,\n\t.resume = igbvf_io_resume,\n\t.reset_prepare = igbvf_io_prepare,\n\t.reset_done = igbvf_io_reset_done,\n};\n\nstatic const struct pci_device_id igbvf_pci_tbl[] = {\n\t{ PCI_VDEVICE(INTEL, E1000_DEV_ID_82576_VF), board_vf },\n\t{ PCI_VDEVICE(INTEL, E1000_DEV_ID_I350_VF), board_i350_vf },\n\t{ }  \n};\nMODULE_DEVICE_TABLE(pci, igbvf_pci_tbl);\n\nstatic SIMPLE_DEV_PM_OPS(igbvf_pm_ops, igbvf_suspend, igbvf_resume);\n\n \nstatic struct pci_driver igbvf_driver = {\n\t.name\t\t= igbvf_driver_name,\n\t.id_table\t= igbvf_pci_tbl,\n\t.probe\t\t= igbvf_probe,\n\t.remove\t\t= igbvf_remove,\n\t.driver.pm\t= &igbvf_pm_ops,\n\t.shutdown\t= igbvf_shutdown,\n\t.err_handler\t= &igbvf_err_handler\n};\n\n \nstatic int __init igbvf_init_module(void)\n{\n\tint ret;\n\n\tpr_info(\"%s\\n\", igbvf_driver_string);\n\tpr_info(\"%s\\n\", igbvf_copyright);\n\n\tret = pci_register_driver(&igbvf_driver);\n\n\treturn ret;\n}\nmodule_init(igbvf_init_module);\n\n \nstatic void __exit igbvf_exit_module(void)\n{\n\tpci_unregister_driver(&igbvf_driver);\n}\nmodule_exit(igbvf_exit_module);\n\nMODULE_AUTHOR(\"Intel Corporation, <e1000-devel@lists.sourceforge.net>\");\nMODULE_DESCRIPTION(\"Intel(R) Gigabit Virtual Function Network Driver\");\nMODULE_LICENSE(\"GPL v2\");\n\n \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}