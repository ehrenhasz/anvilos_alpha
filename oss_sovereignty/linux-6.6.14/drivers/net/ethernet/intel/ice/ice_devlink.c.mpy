{
  "module_name": "ice_devlink.c",
  "hash_id": "08bae16e4a7c9db47c396b18b3d461edfc1fd55e1a2d924a88f8462b99a3f014",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_devlink.c",
  "human_readable_source": "\n \n\n#include <linux/vmalloc.h>\n\n#include \"ice.h\"\n#include \"ice_lib.h\"\n#include \"ice_devlink.h\"\n#include \"ice_eswitch.h\"\n#include \"ice_fw_update.h\"\n#include \"ice_dcb_lib.h\"\n\nstatic int ice_active_port_option = -1;\n\n \nstruct ice_info_ctx {\n\tchar buf[128];\n\tstruct ice_orom_info pending_orom;\n\tstruct ice_nvm_info pending_nvm;\n\tstruct ice_netlist_info pending_netlist;\n\tstruct ice_hw_dev_caps dev_caps;\n};\n\n \n\nstatic void ice_info_get_dsn(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tu8 dsn[8];\n\n\t \n\tput_unaligned_be64(pci_get_dsn(pf->pdev), dsn);\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%8phD\", dsn);\n}\n\nstatic void ice_info_pba(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_hw *hw = &pf->hw;\n\tint status;\n\n\tstatus = ice_read_pba_string(hw, (u8 *)ctx->buf, sizeof(ctx->buf));\n\tif (status)\n\t\t \n\t\tdev_dbg(ice_pf_to_dev(pf), \"Failed to read Product Board Assembly string, status %d\\n\",\n\t\t\tstatus);\n}\n\nstatic void ice_info_fw_mgmt(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_hw *hw = &pf->hw;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%u.%u.%u\",\n\t\t hw->fw_maj_ver, hw->fw_min_ver, hw->fw_patch);\n}\n\nstatic void ice_info_fw_api(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_hw *hw = &pf->hw;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%u.%u.%u\", hw->api_maj_ver,\n\t\t hw->api_min_ver, hw->api_patch);\n}\n\nstatic void ice_info_fw_build(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_hw *hw = &pf->hw;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"0x%08x\", hw->fw_build);\n}\n\nstatic void ice_info_orom_ver(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_orom_info *orom = &pf->hw.flash.orom;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%u.%u.%u\",\n\t\t orom->major, orom->build, orom->patch);\n}\n\nstatic void\nice_info_pending_orom_ver(struct ice_pf __always_unused *pf,\n\t\t\t  struct ice_info_ctx *ctx)\n{\n\tstruct ice_orom_info *orom = &ctx->pending_orom;\n\n\tif (ctx->dev_caps.common_cap.nvm_update_pending_orom)\n\t\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%u.%u.%u\",\n\t\t\t orom->major, orom->build, orom->patch);\n}\n\nstatic void ice_info_nvm_ver(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_nvm_info *nvm = &pf->hw.flash.nvm;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%x.%02x\", nvm->major, nvm->minor);\n}\n\nstatic void\nice_info_pending_nvm_ver(struct ice_pf __always_unused *pf,\n\t\t\t struct ice_info_ctx *ctx)\n{\n\tstruct ice_nvm_info *nvm = &ctx->pending_nvm;\n\n\tif (ctx->dev_caps.common_cap.nvm_update_pending_nvm)\n\t\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%x.%02x\",\n\t\t\t nvm->major, nvm->minor);\n}\n\nstatic void ice_info_eetrack(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_nvm_info *nvm = &pf->hw.flash.nvm;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"0x%08x\", nvm->eetrack);\n}\n\nstatic void\nice_info_pending_eetrack(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_nvm_info *nvm = &ctx->pending_nvm;\n\n\tif (ctx->dev_caps.common_cap.nvm_update_pending_nvm)\n\t\tsnprintf(ctx->buf, sizeof(ctx->buf), \"0x%08x\", nvm->eetrack);\n}\n\nstatic void ice_info_ddp_pkg_name(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_hw *hw = &pf->hw;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%s\", hw->active_pkg_name);\n}\n\nstatic void\nice_info_ddp_pkg_version(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_pkg_ver *pkg = &pf->hw.active_pkg_ver;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%u.%u.%u.%u\",\n\t\t pkg->major, pkg->minor, pkg->update, pkg->draft);\n}\n\nstatic void\nice_info_ddp_pkg_bundle_id(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"0x%08x\", pf->hw.active_track_id);\n}\n\nstatic void ice_info_netlist_ver(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_netlist_info *netlist = &pf->hw.flash.netlist;\n\n\t \n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%x.%x.%x-%x.%x.%x\",\n\t\t netlist->major, netlist->minor,\n\t\t netlist->type >> 16, netlist->type & 0xFFFF,\n\t\t netlist->rev, netlist->cust_ver);\n}\n\nstatic void ice_info_netlist_build(struct ice_pf *pf, struct ice_info_ctx *ctx)\n{\n\tstruct ice_netlist_info *netlist = &pf->hw.flash.netlist;\n\n\tsnprintf(ctx->buf, sizeof(ctx->buf), \"0x%08x\", netlist->hash);\n}\n\nstatic void\nice_info_pending_netlist_ver(struct ice_pf __always_unused *pf,\n\t\t\t     struct ice_info_ctx *ctx)\n{\n\tstruct ice_netlist_info *netlist = &ctx->pending_netlist;\n\n\t \n\tif (ctx->dev_caps.common_cap.nvm_update_pending_netlist)\n\t\tsnprintf(ctx->buf, sizeof(ctx->buf), \"%x.%x.%x-%x.%x.%x\",\n\t\t\t netlist->major, netlist->minor,\n\t\t\t netlist->type >> 16, netlist->type & 0xFFFF,\n\t\t\t netlist->rev, netlist->cust_ver);\n}\n\nstatic void\nice_info_pending_netlist_build(struct ice_pf __always_unused *pf,\n\t\t\t       struct ice_info_ctx *ctx)\n{\n\tstruct ice_netlist_info *netlist = &ctx->pending_netlist;\n\n\tif (ctx->dev_caps.common_cap.nvm_update_pending_netlist)\n\t\tsnprintf(ctx->buf, sizeof(ctx->buf), \"0x%08x\", netlist->hash);\n}\n\n#define fixed(key, getter) { ICE_VERSION_FIXED, key, getter, NULL }\n#define running(key, getter) { ICE_VERSION_RUNNING, key, getter, NULL }\n#define stored(key, getter, fallback) { ICE_VERSION_STORED, key, getter, fallback }\n\n \n#define combined(key, active, pending) \\\n\trunning(key, active), \\\n\tstored(key, pending, active)\n\nenum ice_version_type {\n\tICE_VERSION_FIXED,\n\tICE_VERSION_RUNNING,\n\tICE_VERSION_STORED,\n};\n\nstatic const struct ice_devlink_version {\n\tenum ice_version_type type;\n\tconst char *key;\n\tvoid (*getter)(struct ice_pf *pf, struct ice_info_ctx *ctx);\n\tvoid (*fallback)(struct ice_pf *pf, struct ice_info_ctx *ctx);\n} ice_devlink_versions[] = {\n\tfixed(DEVLINK_INFO_VERSION_GENERIC_BOARD_ID, ice_info_pba),\n\trunning(DEVLINK_INFO_VERSION_GENERIC_FW_MGMT, ice_info_fw_mgmt),\n\trunning(\"fw.mgmt.api\", ice_info_fw_api),\n\trunning(\"fw.mgmt.build\", ice_info_fw_build),\n\tcombined(DEVLINK_INFO_VERSION_GENERIC_FW_UNDI, ice_info_orom_ver, ice_info_pending_orom_ver),\n\tcombined(\"fw.psid.api\", ice_info_nvm_ver, ice_info_pending_nvm_ver),\n\tcombined(DEVLINK_INFO_VERSION_GENERIC_FW_BUNDLE_ID, ice_info_eetrack, ice_info_pending_eetrack),\n\trunning(\"fw.app.name\", ice_info_ddp_pkg_name),\n\trunning(DEVLINK_INFO_VERSION_GENERIC_FW_APP, ice_info_ddp_pkg_version),\n\trunning(\"fw.app.bundle_id\", ice_info_ddp_pkg_bundle_id),\n\tcombined(\"fw.netlist\", ice_info_netlist_ver, ice_info_pending_netlist_ver),\n\tcombined(\"fw.netlist.build\", ice_info_netlist_build, ice_info_pending_netlist_build),\n};\n\n \nstatic int ice_devlink_info_get(struct devlink *devlink,\n\t\t\t\tstruct devlink_info_req *req,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tstruct ice_hw *hw = &pf->hw;\n\tstruct ice_info_ctx *ctx;\n\tsize_t i;\n\tint err;\n\n\terr = ice_wait_for_reset(pf, 10 * HZ);\n\tif (err) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Device is busy resetting\");\n\t\treturn err;\n\t}\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\t \n\terr = ice_discover_dev_caps(hw, &ctx->dev_caps);\n\tif (err) {\n\t\tdev_dbg(dev, \"Failed to discover device capabilities, status %d aq_err %s\\n\",\n\t\t\terr, ice_aq_str(hw->adminq.sq_last_status));\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unable to discover device capabilities\");\n\t\tgoto out_free_ctx;\n\t}\n\n\tif (ctx->dev_caps.common_cap.nvm_update_pending_orom) {\n\t\terr = ice_get_inactive_orom_ver(hw, &ctx->pending_orom);\n\t\tif (err) {\n\t\t\tdev_dbg(dev, \"Unable to read inactive Option ROM version data, status %d aq_err %s\\n\",\n\t\t\t\terr, ice_aq_str(hw->adminq.sq_last_status));\n\n\t\t\t \n\t\t\tctx->dev_caps.common_cap.nvm_update_pending_orom = false;\n\t\t}\n\t}\n\n\tif (ctx->dev_caps.common_cap.nvm_update_pending_nvm) {\n\t\terr = ice_get_inactive_nvm_ver(hw, &ctx->pending_nvm);\n\t\tif (err) {\n\t\t\tdev_dbg(dev, \"Unable to read inactive NVM version data, status %d aq_err %s\\n\",\n\t\t\t\terr, ice_aq_str(hw->adminq.sq_last_status));\n\n\t\t\t \n\t\t\tctx->dev_caps.common_cap.nvm_update_pending_nvm = false;\n\t\t}\n\t}\n\n\tif (ctx->dev_caps.common_cap.nvm_update_pending_netlist) {\n\t\terr = ice_get_inactive_netlist_ver(hw, &ctx->pending_netlist);\n\t\tif (err) {\n\t\t\tdev_dbg(dev, \"Unable to read inactive Netlist version data, status %d aq_err %s\\n\",\n\t\t\t\terr, ice_aq_str(hw->adminq.sq_last_status));\n\n\t\t\t \n\t\t\tctx->dev_caps.common_cap.nvm_update_pending_netlist = false;\n\t\t}\n\t}\n\n\tice_info_get_dsn(pf, ctx);\n\n\terr = devlink_info_serial_number_put(req, ctx->buf);\n\tif (err) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unable to set serial number\");\n\t\tgoto out_free_ctx;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(ice_devlink_versions); i++) {\n\t\tenum ice_version_type type = ice_devlink_versions[i].type;\n\t\tconst char *key = ice_devlink_versions[i].key;\n\n\t\tmemset(ctx->buf, 0, sizeof(ctx->buf));\n\n\t\tice_devlink_versions[i].getter(pf, ctx);\n\n\t\t \n\t\tif (ctx->buf[0] == '\\0' && ice_devlink_versions[i].fallback)\n\t\t\tice_devlink_versions[i].fallback(pf, ctx);\n\n\t\t \n\t\tif (ctx->buf[0] == '\\0')\n\t\t\tcontinue;\n\n\t\tswitch (type) {\n\t\tcase ICE_VERSION_FIXED:\n\t\t\terr = devlink_info_version_fixed_put(req, key, ctx->buf);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unable to set fixed version\");\n\t\t\t\tgoto out_free_ctx;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase ICE_VERSION_RUNNING:\n\t\t\terr = devlink_info_version_running_put(req, key, ctx->buf);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unable to set running version\");\n\t\t\t\tgoto out_free_ctx;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase ICE_VERSION_STORED:\n\t\t\terr = devlink_info_version_stored_put(req, key, ctx->buf);\n\t\t\tif (err) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Unable to set stored version\");\n\t\t\t\tgoto out_free_ctx;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\nout_free_ctx:\n\tkfree(ctx);\n\treturn err;\n}\n\n \nstatic int\nice_devlink_reload_empr_start(struct ice_pf *pf,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tstruct ice_hw *hw = &pf->hw;\n\tu8 pending;\n\tint err;\n\n\terr = ice_get_pending_updates(pf, &pending, extack);\n\tif (err)\n\t\treturn err;\n\n\t \n\tif (!pending) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"No pending firmware update\");\n\t\treturn -ECANCELED;\n\t}\n\n\tif (pf->fw_emp_reset_disabled) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"EMP reset is not available. To activate firmware, a reboot or power cycle is needed\");\n\t\treturn -ECANCELED;\n\t}\n\n\tdev_dbg(dev, \"Issuing device EMP reset to activate firmware\\n\");\n\n\terr = ice_aq_nvm_update_empr(hw);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to trigger EMP device reset to reload firmware, err %d aq_err %s\\n\",\n\t\t\terr, ice_aq_str(hw->adminq.sq_last_status));\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to trigger EMP device reset to reload firmware\");\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_devlink_reload_down(struct devlink *devlink, bool netns_change,\n\t\t\tenum devlink_reload_action action,\n\t\t\tenum devlink_reload_limit limit,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\n\tswitch (action) {\n\tcase DEVLINK_RELOAD_ACTION_DRIVER_REINIT:\n\t\tif (ice_is_eswitch_mode_switchdev(pf)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Go to legacy mode before doing reinit\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (ice_is_adq_active(pf)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Turn off ADQ before doing reinit\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (ice_has_vfs(pf)) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Remove all VFs before doing reinit\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tice_unload(pf);\n\t\treturn 0;\n\tcase DEVLINK_RELOAD_ACTION_FW_ACTIVATE:\n\t\treturn ice_devlink_reload_empr_start(pf, extack);\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\n \nstatic int\nice_devlink_reload_empr_finish(struct ice_pf *pf,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tint err;\n\n\terr = ice_wait_for_reset(pf, 60 * HZ);\n\tif (err) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Device still resetting after 1 minute\");\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n \nstatic const char *ice_devlink_port_opt_speed_str(u8 speed)\n{\n\tswitch (speed & ICE_AQC_PORT_OPT_MAX_LANE_M) {\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_100M:\n\t\treturn \"0.1\";\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_1G:\n\t\treturn \"1\";\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_2500M:\n\t\treturn \"2.5\";\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_5G:\n\t\treturn \"5\";\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_10G:\n\t\treturn \"10\";\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_25G:\n\t\treturn \"25\";\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_50G:\n\t\treturn \"50\";\n\tcase ICE_AQC_PORT_OPT_MAX_LANE_100G:\n\t\treturn \"100\";\n\t}\n\n\treturn \"-\";\n}\n\n#define ICE_PORT_OPT_DESC_LEN\t50\n \nstatic void ice_devlink_port_options_print(struct ice_pf *pf)\n{\n\tu8 i, j, options_count, cnt, speed, pending_idx, active_idx;\n\tstruct ice_aqc_get_port_options_elem *options, *opt;\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tbool active_valid, pending_valid;\n\tchar desc[ICE_PORT_OPT_DESC_LEN];\n\tconst char *str;\n\tint status;\n\n\toptions = kcalloc(ICE_AQC_PORT_OPT_MAX * ICE_MAX_PORT_PER_PCI_DEV,\n\t\t\t  sizeof(*options), GFP_KERNEL);\n\tif (!options)\n\t\treturn;\n\n\tfor (i = 0; i < ICE_MAX_PORT_PER_PCI_DEV; i++) {\n\t\topt = options + i * ICE_AQC_PORT_OPT_MAX;\n\t\toptions_count = ICE_AQC_PORT_OPT_MAX;\n\t\tactive_valid = 0;\n\n\t\tstatus = ice_aq_get_port_options(&pf->hw, opt, &options_count,\n\t\t\t\t\t\t i, true, &active_idx,\n\t\t\t\t\t\t &active_valid, &pending_idx,\n\t\t\t\t\t\t &pending_valid);\n\t\tif (status) {\n\t\t\tdev_dbg(dev, \"Couldn't read port option for port %d, err %d\\n\",\n\t\t\t\ti, status);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tdev_dbg(dev, \"Available port split options and max port speeds (Gbps):\\n\");\n\tdev_dbg(dev, \"Status  Split      Quad 0          Quad 1\\n\");\n\tdev_dbg(dev, \"        count  L0  L1  L2  L3  L4  L5  L6  L7\\n\");\n\n\tfor (i = 0; i < options_count; i++) {\n\t\tcnt = 0;\n\n\t\tif (i == ice_active_port_option)\n\t\t\tstr = \"Active\";\n\t\telse if ((i == pending_idx) && pending_valid)\n\t\t\tstr = \"Pending\";\n\t\telse\n\t\t\tstr = \"\";\n\n\t\tcnt += snprintf(&desc[cnt], ICE_PORT_OPT_DESC_LEN - cnt,\n\t\t\t\t\"%-8s\", str);\n\n\t\tcnt += snprintf(&desc[cnt], ICE_PORT_OPT_DESC_LEN - cnt,\n\t\t\t\t\"%-6u\", options[i].pmd);\n\n\t\tfor (j = 0; j < ICE_MAX_PORT_PER_PCI_DEV; ++j) {\n\t\t\tspeed = options[i + j * ICE_AQC_PORT_OPT_MAX].max_lane_speed;\n\t\t\tstr = ice_devlink_port_opt_speed_str(speed);\n\t\t\tcnt += snprintf(&desc[cnt], ICE_PORT_OPT_DESC_LEN - cnt,\n\t\t\t\t\t\"%3s \", str);\n\t\t}\n\n\t\tdev_dbg(dev, \"%s\\n\", desc);\n\t}\n\nerr:\n\tkfree(options);\n}\n\n \nstatic int\nice_devlink_aq_set_port_option(struct ice_pf *pf, u8 option_idx,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tint status;\n\n\tstatus = ice_aq_set_port_option(&pf->hw, 0, true, option_idx);\n\tif (status) {\n\t\tdev_dbg(dev, \"ice_aq_set_port_option, err %d aq_err %d\\n\",\n\t\t\tstatus, pf->hw.adminq.sq_last_status);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Port split request failed\");\n\t\treturn -EIO;\n\t}\n\n\tstatus = ice_acquire_nvm(&pf->hw, ICE_RES_WRITE);\n\tif (status) {\n\t\tdev_dbg(dev, \"ice_acquire_nvm failed, err %d aq_err %d\\n\",\n\t\t\tstatus, pf->hw.adminq.sq_last_status);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to acquire NVM semaphore\");\n\t\treturn -EIO;\n\t}\n\n\tstatus = ice_nvm_write_activate(&pf->hw, ICE_AQC_NVM_ACTIV_REQ_EMPR, NULL);\n\tif (status) {\n\t\tdev_dbg(dev, \"ice_nvm_write_activate failed, err %d aq_err %d\\n\",\n\t\t\tstatus, pf->hw.adminq.sq_last_status);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Port split request failed to save data\");\n\t\tice_release_nvm(&pf->hw);\n\t\treturn -EIO;\n\t}\n\n\tice_release_nvm(&pf->hw);\n\n\tNL_SET_ERR_MSG_MOD(extack, \"Reboot required to finish port split\");\n\treturn 0;\n}\n\n \nstatic int\nice_devlink_port_split(struct devlink *devlink, struct devlink_port *port,\n\t\t       unsigned int count, struct netlink_ext_ack *extack)\n{\n\tstruct ice_aqc_get_port_options_elem options[ICE_AQC_PORT_OPT_MAX];\n\tu8 i, j, active_idx, pending_idx, new_option;\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\tu8 option_count = ICE_AQC_PORT_OPT_MAX;\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tbool active_valid, pending_valid;\n\tint status;\n\n\tstatus = ice_aq_get_port_options(&pf->hw, options, &option_count,\n\t\t\t\t\t 0, true, &active_idx, &active_valid,\n\t\t\t\t\t &pending_idx, &pending_valid);\n\tif (status) {\n\t\tdev_dbg(dev, \"Couldn't read port split options, err = %d\\n\",\n\t\t\tstatus);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to get available port split options\");\n\t\treturn -EIO;\n\t}\n\n\tnew_option = ICE_AQC_PORT_OPT_MAX;\n\tactive_idx = pending_valid ? pending_idx : active_idx;\n\tfor (i = 1; i <= option_count; i++) {\n\t\t \n\t\tj = (active_idx + i) % option_count;\n\n\t\tif (count == options[j].pmd) {\n\t\t\tnew_option = j;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (new_option == active_idx) {\n\t\tdev_dbg(dev, \"request to split: count: %u is already set and there are no other options\\n\",\n\t\t\tcount);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Requested split count is already set\");\n\t\tice_devlink_port_options_print(pf);\n\t\treturn -EINVAL;\n\t}\n\n\tif (new_option == ICE_AQC_PORT_OPT_MAX) {\n\t\tdev_dbg(dev, \"request to split: count: %u not found\\n\", count);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Port split requested unsupported port config\");\n\t\tice_devlink_port_options_print(pf);\n\t\treturn -EINVAL;\n\t}\n\n\tstatus = ice_devlink_aq_set_port_option(pf, new_option, extack);\n\tif (status)\n\t\treturn status;\n\n\tice_devlink_port_options_print(pf);\n\n\treturn 0;\n}\n\n \nstatic int\nice_devlink_port_unsplit(struct devlink *devlink, struct devlink_port *port,\n\t\t\t struct netlink_ext_ack *extack)\n{\n\treturn ice_devlink_port_split(devlink, port, 1, extack);\n}\n\n \nvoid ice_tear_down_devlink_rate_tree(struct ice_pf *pf)\n{\n\tstruct devlink *devlink;\n\tstruct ice_vf *vf;\n\tunsigned int bkt;\n\n\tdevlink = priv_to_devlink(pf);\n\n\tdevl_lock(devlink);\n\tmutex_lock(&pf->vfs.table_lock);\n\tice_for_each_vf(pf, bkt, vf) {\n\t\tif (vf->devlink_port.devlink_rate)\n\t\t\tdevl_rate_leaf_destroy(&vf->devlink_port);\n\t}\n\tmutex_unlock(&pf->vfs.table_lock);\n\n\tdevl_rate_nodes_destroy(devlink);\n\tdevl_unlock(devlink);\n}\n\n \nstatic bool ice_enable_custom_tx(struct ice_pf *pf)\n{\n\tstruct ice_port_info *pi = ice_get_main_vsi(pf)->port_info;\n\tstruct device *dev = ice_pf_to_dev(pf);\n\n\tif (pi->is_custom_tx_enabled)\n\t\t \n\t\treturn true;\n\n\tif (ice_is_adq_active(pf)) {\n\t\tdev_err(dev, \"ADQ active, can't modify Tx scheduler tree\\n\");\n\t\treturn false;\n\t}\n\n\tif (ice_is_dcb_active(pf)) {\n\t\tdev_err(dev, \"DCB active, can't modify Tx scheduler tree\\n\");\n\t\treturn false;\n\t}\n\n\tpi->is_custom_tx_enabled = true;\n\n\treturn true;\n}\n\n \nstatic void ice_traverse_tx_tree(struct devlink *devlink, struct ice_sched_node *node,\n\t\t\t\t struct ice_sched_node *tc_node, struct ice_pf *pf)\n{\n\tstruct devlink_rate *rate_node = NULL;\n\tstruct ice_vf *vf;\n\tint i;\n\n\tif (node->parent == tc_node) {\n\t\t \n\t\trate_node = devl_rate_node_create(devlink, node, node->name, NULL);\n\t} else if (node->vsi_handle &&\n\t\t   pf->vsi[node->vsi_handle]->vf) {\n\t\tvf = pf->vsi[node->vsi_handle]->vf;\n\t\tif (!vf->devlink_port.devlink_rate)\n\t\t\t \n\t\t\tdevl_rate_leaf_create(&vf->devlink_port, node,\n\t\t\t\t\t      node->parent->rate_node);\n\t} else if (node->info.data.elem_type != ICE_AQC_ELEM_TYPE_LEAF &&\n\t\t   node->parent->rate_node) {\n\t\trate_node = devl_rate_node_create(devlink, node, node->name,\n\t\t\t\t\t\t  node->parent->rate_node);\n\t}\n\n\tif (rate_node && !IS_ERR(rate_node))\n\t\tnode->rate_node = rate_node;\n\n\tfor (i = 0; i < node->num_children; i++)\n\t\tice_traverse_tx_tree(devlink, node->children[i], tc_node, pf);\n}\n\n \nint ice_devlink_rate_init_tx_topology(struct devlink *devlink, struct ice_vsi *vsi)\n{\n\tstruct ice_port_info *pi = vsi->port_info;\n\tstruct ice_sched_node *tc_node;\n\tstruct ice_pf *pf = vsi->back;\n\tint i;\n\n\ttc_node = pi->root->children[0];\n\tmutex_lock(&pi->sched_lock);\n\tdevl_lock(devlink);\n\tfor (i = 0; i < tc_node->num_children; i++)\n\t\tice_traverse_tx_tree(devlink, tc_node->children[i], tc_node, pf);\n\tdevl_unlock(devlink);\n\tmutex_unlock(&pi->sched_lock);\n\n\treturn 0;\n}\n\n \nstatic int ice_set_object_tx_share(struct ice_port_info *pi, struct ice_sched_node *node,\n\t\t\t\t   u64 bw, struct netlink_ext_ack *extack)\n{\n\tint status;\n\n\tmutex_lock(&pi->sched_lock);\n\t \n\tnode->tx_share = div_u64(bw, 125);\n\tstatus = ice_sched_set_node_bw_lmt(pi, node, ICE_MIN_BW, node->tx_share);\n\tmutex_unlock(&pi->sched_lock);\n\n\tif (status)\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't set scheduling node tx_share\");\n\n\treturn status;\n}\n\n \nstatic int ice_set_object_tx_max(struct ice_port_info *pi, struct ice_sched_node *node,\n\t\t\t\t u64 bw, struct netlink_ext_ack *extack)\n{\n\tint status;\n\n\tmutex_lock(&pi->sched_lock);\n\t \n\tnode->tx_max = div_u64(bw, 125);\n\tstatus = ice_sched_set_node_bw_lmt(pi, node, ICE_MAX_BW, node->tx_max);\n\tmutex_unlock(&pi->sched_lock);\n\n\tif (status)\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't set scheduling node tx_max\");\n\n\treturn status;\n}\n\n \nstatic int ice_set_object_tx_priority(struct ice_port_info *pi, struct ice_sched_node *node,\n\t\t\t\t      u32 priority, struct netlink_ext_ack *extack)\n{\n\tint status;\n\n\tif (priority >= 8) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Priority should be less than 8\");\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_lock(&pi->sched_lock);\n\tnode->tx_priority = priority;\n\tstatus = ice_sched_set_node_priority(pi, node, node->tx_priority);\n\tmutex_unlock(&pi->sched_lock);\n\n\tif (status)\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't set scheduling node tx_priority\");\n\n\treturn status;\n}\n\n \nstatic int ice_set_object_tx_weight(struct ice_port_info *pi, struct ice_sched_node *node,\n\t\t\t\t    u32 weight, struct netlink_ext_ack *extack)\n{\n\tint status;\n\n\tif (weight > 200 || weight < 1) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Weight must be between 1 and 200\");\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_lock(&pi->sched_lock);\n\tnode->tx_weight = weight;\n\tstatus = ice_sched_set_node_weight(pi, node, node->tx_weight);\n\tmutex_unlock(&pi->sched_lock);\n\n\tif (status)\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't set scheduling node tx_weight\");\n\n\treturn status;\n}\n\n \nstatic struct ice_port_info *ice_get_pi_from_dev_rate(struct devlink_rate *rate_node)\n{\n\tstruct ice_pf *pf = devlink_priv(rate_node->devlink);\n\n\treturn ice_get_main_vsi(pf)->port_info;\n}\n\nstatic int ice_devlink_rate_node_new(struct devlink_rate *rate_node, void **priv,\n\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node;\n\tstruct ice_port_info *pi;\n\n\tpi = ice_get_pi_from_dev_rate(rate_node);\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_node->devlink)))\n\t\treturn -EBUSY;\n\n\t \n\tnode = devm_kzalloc(ice_hw_to_dev(pi->hw), sizeof(*node), GFP_KERNEL);\n\t*priv = node;\n\n\treturn 0;\n}\n\nstatic int ice_devlink_rate_node_del(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node, *tc_node;\n\tstruct ice_port_info *pi;\n\n\tpi = ice_get_pi_from_dev_rate(rate_node);\n\ttc_node = pi->root->children[0];\n\tnode = priv;\n\n\tif (!rate_node->parent || !node || tc_node == node || !extack)\n\t\treturn 0;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_node->devlink)))\n\t\treturn -EBUSY;\n\n\t \n\tif (node->num_children)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&pi->sched_lock);\n\tice_free_sched_node(pi, node);\n\tmutex_unlock(&pi->sched_lock);\n\n\treturn 0;\n}\n\nstatic int ice_devlink_rate_leaf_tx_max_set(struct devlink_rate *rate_leaf, void *priv,\n\t\t\t\t\t    u64 tx_max, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_leaf->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_max(ice_get_pi_from_dev_rate(rate_leaf),\n\t\t\t\t     node, tx_max, extack);\n}\n\nstatic int ice_devlink_rate_leaf_tx_share_set(struct devlink_rate *rate_leaf, void *priv,\n\t\t\t\t\t      u64 tx_share, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_leaf->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_share(ice_get_pi_from_dev_rate(rate_leaf), node,\n\t\t\t\t       tx_share, extack);\n}\n\nstatic int ice_devlink_rate_leaf_tx_priority_set(struct devlink_rate *rate_leaf, void *priv,\n\t\t\t\t\t\t u32 tx_priority, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_leaf->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_priority(ice_get_pi_from_dev_rate(rate_leaf), node,\n\t\t\t\t\t  tx_priority, extack);\n}\n\nstatic int ice_devlink_rate_leaf_tx_weight_set(struct devlink_rate *rate_leaf, void *priv,\n\t\t\t\t\t       u32 tx_weight, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_leaf->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_weight(ice_get_pi_from_dev_rate(rate_leaf), node,\n\t\t\t\t\ttx_weight, extack);\n}\n\nstatic int ice_devlink_rate_node_tx_max_set(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t\t    u64 tx_max, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_node->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_max(ice_get_pi_from_dev_rate(rate_node),\n\t\t\t\t     node, tx_max, extack);\n}\n\nstatic int ice_devlink_rate_node_tx_share_set(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t\t      u64 tx_share, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_node->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_share(ice_get_pi_from_dev_rate(rate_node),\n\t\t\t\t       node, tx_share, extack);\n}\n\nstatic int ice_devlink_rate_node_tx_priority_set(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t\t\t u32 tx_priority, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_node->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_priority(ice_get_pi_from_dev_rate(rate_node),\n\t\t\t\t\t  node, tx_priority, extack);\n}\n\nstatic int ice_devlink_rate_node_tx_weight_set(struct devlink_rate *rate_node, void *priv,\n\t\t\t\t\t       u32 tx_weight, struct netlink_ext_ack *extack)\n{\n\tstruct ice_sched_node *node = priv;\n\n\tif (!ice_enable_custom_tx(devlink_priv(rate_node->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!node)\n\t\treturn 0;\n\n\treturn ice_set_object_tx_weight(ice_get_pi_from_dev_rate(rate_node),\n\t\t\t\t\tnode, tx_weight, extack);\n}\n\nstatic int ice_devlink_set_parent(struct devlink_rate *devlink_rate,\n\t\t\t\t  struct devlink_rate *parent,\n\t\t\t\t  void *priv, void *parent_priv,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct ice_port_info *pi = ice_get_pi_from_dev_rate(devlink_rate);\n\tstruct ice_sched_node *tc_node, *node, *parent_node;\n\tu16 num_nodes_added;\n\tu32 first_node_teid;\n\tu32 node_teid;\n\tint status;\n\n\ttc_node = pi->root->children[0];\n\tnode = priv;\n\n\tif (!extack)\n\t\treturn 0;\n\n\tif (!ice_enable_custom_tx(devlink_priv(devlink_rate->devlink)))\n\t\treturn -EBUSY;\n\n\tif (!parent) {\n\t\tif (!node || tc_node == node || node->num_children)\n\t\t\treturn -EINVAL;\n\n\t\tmutex_lock(&pi->sched_lock);\n\t\tice_free_sched_node(pi, node);\n\t\tmutex_unlock(&pi->sched_lock);\n\n\t\treturn 0;\n\t}\n\n\tparent_node = parent_priv;\n\n\t \n\tif (!node->parent) {\n\t\tmutex_lock(&pi->sched_lock);\n\t\tstatus = ice_sched_add_elems(pi, tc_node, parent_node,\n\t\t\t\t\t     parent_node->tx_sched_layer + 1,\n\t\t\t\t\t     1, &num_nodes_added, &first_node_teid,\n\t\t\t\t\t     &node);\n\t\tmutex_unlock(&pi->sched_lock);\n\n\t\tif (status) {\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't add a new node\");\n\t\t\treturn status;\n\t\t}\n\n\t\tif (devlink_rate->tx_share)\n\t\t\tice_set_object_tx_share(pi, node, devlink_rate->tx_share, extack);\n\t\tif (devlink_rate->tx_max)\n\t\t\tice_set_object_tx_max(pi, node, devlink_rate->tx_max, extack);\n\t\tif (devlink_rate->tx_priority)\n\t\t\tice_set_object_tx_priority(pi, node, devlink_rate->tx_priority, extack);\n\t\tif (devlink_rate->tx_weight)\n\t\t\tice_set_object_tx_weight(pi, node, devlink_rate->tx_weight, extack);\n\t} else {\n\t\tnode_teid = le32_to_cpu(node->info.node_teid);\n\t\tmutex_lock(&pi->sched_lock);\n\t\tstatus = ice_sched_move_nodes(pi, parent_node, 1, &node_teid);\n\t\tmutex_unlock(&pi->sched_lock);\n\n\t\tif (status)\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Can't move existing node to a new parent\");\n\t}\n\n\treturn status;\n}\n\n \nstatic int\nice_devlink_reload_up(struct devlink *devlink,\n\t\t      enum devlink_reload_action action,\n\t\t      enum devlink_reload_limit limit,\n\t\t      u32 *actions_performed,\n\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\n\tswitch (action) {\n\tcase DEVLINK_RELOAD_ACTION_DRIVER_REINIT:\n\t\t*actions_performed = BIT(DEVLINK_RELOAD_ACTION_DRIVER_REINIT);\n\t\treturn ice_load(pf);\n\tcase DEVLINK_RELOAD_ACTION_FW_ACTIVATE:\n\t\t*actions_performed = BIT(DEVLINK_RELOAD_ACTION_FW_ACTIVATE);\n\t\treturn ice_devlink_reload_empr_finish(pf, extack);\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic const struct devlink_ops ice_devlink_ops = {\n\t.supported_flash_update_params = DEVLINK_SUPPORT_FLASH_UPDATE_OVERWRITE_MASK,\n\t.reload_actions = BIT(DEVLINK_RELOAD_ACTION_DRIVER_REINIT) |\n\t\t\t  BIT(DEVLINK_RELOAD_ACTION_FW_ACTIVATE),\n\t.reload_down = ice_devlink_reload_down,\n\t.reload_up = ice_devlink_reload_up,\n\t.eswitch_mode_get = ice_eswitch_mode_get,\n\t.eswitch_mode_set = ice_eswitch_mode_set,\n\t.info_get = ice_devlink_info_get,\n\t.flash_update = ice_devlink_flash_update,\n\n\t.rate_node_new = ice_devlink_rate_node_new,\n\t.rate_node_del = ice_devlink_rate_node_del,\n\n\t.rate_leaf_tx_max_set = ice_devlink_rate_leaf_tx_max_set,\n\t.rate_leaf_tx_share_set = ice_devlink_rate_leaf_tx_share_set,\n\t.rate_leaf_tx_priority_set = ice_devlink_rate_leaf_tx_priority_set,\n\t.rate_leaf_tx_weight_set = ice_devlink_rate_leaf_tx_weight_set,\n\n\t.rate_node_tx_max_set = ice_devlink_rate_node_tx_max_set,\n\t.rate_node_tx_share_set = ice_devlink_rate_node_tx_share_set,\n\t.rate_node_tx_priority_set = ice_devlink_rate_node_tx_priority_set,\n\t.rate_node_tx_weight_set = ice_devlink_rate_node_tx_weight_set,\n\n\t.rate_leaf_parent_set = ice_devlink_set_parent,\n\t.rate_node_parent_set = ice_devlink_set_parent,\n};\n\nstatic int\nice_devlink_enable_roce_get(struct devlink *devlink, u32 id,\n\t\t\t    struct devlink_param_gset_ctx *ctx)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\n\tctx->val.vbool = pf->rdma_mode & IIDC_RDMA_PROTOCOL_ROCEV2 ? true : false;\n\n\treturn 0;\n}\n\nstatic int\nice_devlink_enable_roce_set(struct devlink *devlink, u32 id,\n\t\t\t    struct devlink_param_gset_ctx *ctx)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\tbool roce_ena = ctx->val.vbool;\n\tint ret;\n\n\tif (!roce_ena) {\n\t\tice_unplug_aux_dev(pf);\n\t\tpf->rdma_mode &= ~IIDC_RDMA_PROTOCOL_ROCEV2;\n\t\treturn 0;\n\t}\n\n\tpf->rdma_mode |= IIDC_RDMA_PROTOCOL_ROCEV2;\n\tret = ice_plug_aux_dev(pf);\n\tif (ret)\n\t\tpf->rdma_mode &= ~IIDC_RDMA_PROTOCOL_ROCEV2;\n\n\treturn ret;\n}\n\nstatic int\nice_devlink_enable_roce_validate(struct devlink *devlink, u32 id,\n\t\t\t\t union devlink_param_value val,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\n\tif (!test_bit(ICE_FLAG_RDMA_ENA, pf->flags))\n\t\treturn -EOPNOTSUPP;\n\n\tif (pf->rdma_mode & IIDC_RDMA_PROTOCOL_IWARP) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"iWARP is currently enabled. This device cannot enable iWARP and RoCEv2 simultaneously\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nice_devlink_enable_iw_get(struct devlink *devlink, u32 id,\n\t\t\t  struct devlink_param_gset_ctx *ctx)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\n\tctx->val.vbool = pf->rdma_mode & IIDC_RDMA_PROTOCOL_IWARP;\n\n\treturn 0;\n}\n\nstatic int\nice_devlink_enable_iw_set(struct devlink *devlink, u32 id,\n\t\t\t  struct devlink_param_gset_ctx *ctx)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\tbool iw_ena = ctx->val.vbool;\n\tint ret;\n\n\tif (!iw_ena) {\n\t\tice_unplug_aux_dev(pf);\n\t\tpf->rdma_mode &= ~IIDC_RDMA_PROTOCOL_IWARP;\n\t\treturn 0;\n\t}\n\n\tpf->rdma_mode |= IIDC_RDMA_PROTOCOL_IWARP;\n\tret = ice_plug_aux_dev(pf);\n\tif (ret)\n\t\tpf->rdma_mode &= ~IIDC_RDMA_PROTOCOL_IWARP;\n\n\treturn ret;\n}\n\nstatic int\nice_devlink_enable_iw_validate(struct devlink *devlink, u32 id,\n\t\t\t       union devlink_param_value val,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\n\tif (!test_bit(ICE_FLAG_RDMA_ENA, pf->flags))\n\t\treturn -EOPNOTSUPP;\n\n\tif (pf->rdma_mode & IIDC_RDMA_PROTOCOL_ROCEV2) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"RoCEv2 is currently enabled. This device cannot enable iWARP and RoCEv2 simultaneously\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct devlink_param ice_devlink_params[] = {\n\tDEVLINK_PARAM_GENERIC(ENABLE_ROCE, BIT(DEVLINK_PARAM_CMODE_RUNTIME),\n\t\t\t      ice_devlink_enable_roce_get,\n\t\t\t      ice_devlink_enable_roce_set,\n\t\t\t      ice_devlink_enable_roce_validate),\n\tDEVLINK_PARAM_GENERIC(ENABLE_IWARP, BIT(DEVLINK_PARAM_CMODE_RUNTIME),\n\t\t\t      ice_devlink_enable_iw_get,\n\t\t\t      ice_devlink_enable_iw_set,\n\t\t\t      ice_devlink_enable_iw_validate),\n\n};\n\nstatic void ice_devlink_free(void *devlink_ptr)\n{\n\tdevlink_free((struct devlink *)devlink_ptr);\n}\n\n \nstruct ice_pf *ice_allocate_pf(struct device *dev)\n{\n\tstruct devlink *devlink;\n\n\tdevlink = devlink_alloc(&ice_devlink_ops, sizeof(struct ice_pf), dev);\n\tif (!devlink)\n\t\treturn NULL;\n\n\t \n\tif (devm_add_action_or_reset(dev, ice_devlink_free, devlink))\n\t\treturn NULL;\n\n\treturn devlink_priv(devlink);\n}\n\n \nvoid ice_devlink_register(struct ice_pf *pf)\n{\n\tstruct devlink *devlink = priv_to_devlink(pf);\n\n\tdevlink_register(devlink);\n}\n\n \nvoid ice_devlink_unregister(struct ice_pf *pf)\n{\n\tdevlink_unregister(priv_to_devlink(pf));\n}\n\n \nstatic void\nice_devlink_set_switch_id(struct ice_pf *pf, struct netdev_phys_item_id *ppid)\n{\n\tstruct pci_dev *pdev = pf->pdev;\n\tu64 id;\n\n\tid = pci_get_dsn(pdev);\n\n\tppid->id_len = sizeof(id);\n\tput_unaligned_be64(id, &ppid->id);\n}\n\nint ice_devlink_register_params(struct ice_pf *pf)\n{\n\tstruct devlink *devlink = priv_to_devlink(pf);\n\n\treturn devlink_params_register(devlink, ice_devlink_params,\n\t\t\t\t       ARRAY_SIZE(ice_devlink_params));\n}\n\nvoid ice_devlink_unregister_params(struct ice_pf *pf)\n{\n\tdevlink_params_unregister(priv_to_devlink(pf), ice_devlink_params,\n\t\t\t\t  ARRAY_SIZE(ice_devlink_params));\n}\n\n \nstatic void\nice_devlink_set_port_split_options(struct ice_pf *pf,\n\t\t\t\t   struct devlink_port_attrs *attrs)\n{\n\tstruct ice_aqc_get_port_options_elem options[ICE_AQC_PORT_OPT_MAX];\n\tu8 i, active_idx, pending_idx, option_count = ICE_AQC_PORT_OPT_MAX;\n\tbool active_valid, pending_valid;\n\tint status;\n\n\tstatus = ice_aq_get_port_options(&pf->hw, options, &option_count,\n\t\t\t\t\t 0, true, &active_idx, &active_valid,\n\t\t\t\t\t &pending_idx, &pending_valid);\n\tif (status) {\n\t\tdev_dbg(ice_pf_to_dev(pf), \"Couldn't read port split options, err = %d\\n\",\n\t\t\tstatus);\n\t\treturn;\n\t}\n\n\t \n\tfor (i = 0; i < option_count; i++)\n\t\tattrs->lanes = max_t(int, attrs->lanes, options[i].pmd);\n\n\tattrs->splittable = attrs->lanes ? 1 : 0;\n\tice_active_port_option = active_idx;\n}\n\nstatic const struct devlink_port_ops ice_devlink_port_ops = {\n\t.port_split = ice_devlink_port_split,\n\t.port_unsplit = ice_devlink_port_unsplit,\n};\n\n \nint ice_devlink_create_pf_port(struct ice_pf *pf)\n{\n\tstruct devlink_port_attrs attrs = {};\n\tstruct devlink_port *devlink_port;\n\tstruct devlink *devlink;\n\tstruct ice_vsi *vsi;\n\tstruct device *dev;\n\tint err;\n\n\tdev = ice_pf_to_dev(pf);\n\n\tdevlink_port = &pf->devlink_port;\n\n\tvsi = ice_get_main_vsi(pf);\n\tif (!vsi)\n\t\treturn -EIO;\n\n\tattrs.flavour = DEVLINK_PORT_FLAVOUR_PHYSICAL;\n\tattrs.phys.port_number = pf->hw.bus.func;\n\n\t \n\tif (pf->hw.pf_id == 0)\n\t\tice_devlink_set_port_split_options(pf, &attrs);\n\n\tice_devlink_set_switch_id(pf, &attrs.switch_id);\n\n\tdevlink_port_attrs_set(devlink_port, &attrs);\n\tdevlink = priv_to_devlink(pf);\n\n\terr = devlink_port_register_with_ops(devlink, devlink_port, vsi->idx,\n\t\t\t\t\t     &ice_devlink_port_ops);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to create devlink port for PF %d, error %d\\n\",\n\t\t\tpf->hw.pf_id, err);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n \nvoid ice_devlink_destroy_pf_port(struct ice_pf *pf)\n{\n\tdevlink_port_unregister(&pf->devlink_port);\n}\n\n \nint ice_devlink_create_vf_port(struct ice_vf *vf)\n{\n\tstruct devlink_port_attrs attrs = {};\n\tstruct devlink_port *devlink_port;\n\tstruct devlink *devlink;\n\tstruct ice_vsi *vsi;\n\tstruct device *dev;\n\tstruct ice_pf *pf;\n\tint err;\n\n\tpf = vf->pf;\n\tdev = ice_pf_to_dev(pf);\n\tdevlink_port = &vf->devlink_port;\n\n\tvsi = ice_get_vf_vsi(vf);\n\tif (!vsi)\n\t\treturn -EINVAL;\n\n\tattrs.flavour = DEVLINK_PORT_FLAVOUR_PCI_VF;\n\tattrs.pci_vf.pf = pf->hw.bus.func;\n\tattrs.pci_vf.vf = vf->vf_id;\n\n\tice_devlink_set_switch_id(pf, &attrs.switch_id);\n\n\tdevlink_port_attrs_set(devlink_port, &attrs);\n\tdevlink = priv_to_devlink(pf);\n\n\terr = devlink_port_register(devlink, devlink_port, vsi->idx);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to create devlink port for VF %d, error %d\\n\",\n\t\t\tvf->vf_id, err);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n \nvoid ice_devlink_destroy_vf_port(struct ice_vf *vf)\n{\n\tdevl_rate_leaf_destroy(&vf->devlink_port);\n\tdevlink_port_unregister(&vf->devlink_port);\n}\n\n#define ICE_DEVLINK_READ_BLK_SIZE (1024 * 1024)\n\nstatic const struct devlink_region_ops ice_nvm_region_ops;\nstatic const struct devlink_region_ops ice_sram_region_ops;\n\n \nstatic int ice_devlink_nvm_snapshot(struct devlink *devlink,\n\t\t\t\t    const struct devlink_region_ops *ops,\n\t\t\t\t    struct netlink_ext_ack *extack, u8 **data)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tstruct ice_hw *hw = &pf->hw;\n\tbool read_shadow_ram;\n\tu8 *nvm_data, *tmp, i;\n\tu32 nvm_size, left;\n\ts8 num_blks;\n\tint status;\n\n\tif (ops == &ice_nvm_region_ops) {\n\t\tread_shadow_ram = false;\n\t\tnvm_size = hw->flash.flash_size;\n\t} else if (ops == &ice_sram_region_ops) {\n\t\tread_shadow_ram = true;\n\t\tnvm_size = hw->flash.sr_words * 2u;\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unexpected region in snapshot function\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tnvm_data = vzalloc(nvm_size);\n\tif (!nvm_data)\n\t\treturn -ENOMEM;\n\n\tnum_blks = DIV_ROUND_UP(nvm_size, ICE_DEVLINK_READ_BLK_SIZE);\n\ttmp = nvm_data;\n\tleft = nvm_size;\n\n\t \n\tfor (i = 0; i < num_blks; i++) {\n\t\tu32 read_sz = min_t(u32, ICE_DEVLINK_READ_BLK_SIZE, left);\n\n\t\tstatus = ice_acquire_nvm(hw, ICE_RES_READ);\n\t\tif (status) {\n\t\t\tdev_dbg(dev, \"ice_acquire_nvm failed, err %d aq_err %d\\n\",\n\t\t\t\tstatus, hw->adminq.sq_last_status);\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to acquire NVM semaphore\");\n\t\t\tvfree(nvm_data);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tstatus = ice_read_flat_nvm(hw, i * ICE_DEVLINK_READ_BLK_SIZE,\n\t\t\t\t\t   &read_sz, tmp, read_shadow_ram);\n\t\tif (status) {\n\t\t\tdev_dbg(dev, \"ice_read_flat_nvm failed after reading %u bytes, err %d aq_err %d\\n\",\n\t\t\t\tread_sz, status, hw->adminq.sq_last_status);\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to read NVM contents\");\n\t\t\tice_release_nvm(hw);\n\t\t\tvfree(nvm_data);\n\t\t\treturn -EIO;\n\t\t}\n\t\tice_release_nvm(hw);\n\n\t\ttmp += read_sz;\n\t\tleft -= read_sz;\n\t}\n\n\t*data = nvm_data;\n\n\treturn 0;\n}\n\n \nstatic int ice_devlink_nvm_read(struct devlink *devlink,\n\t\t\t\tconst struct devlink_region_ops *ops,\n\t\t\t\tstruct netlink_ext_ack *extack,\n\t\t\t\tu64 offset, u32 size, u8 *data)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tstruct ice_hw *hw = &pf->hw;\n\tbool read_shadow_ram;\n\tu64 nvm_size;\n\tint status;\n\n\tif (ops == &ice_nvm_region_ops) {\n\t\tread_shadow_ram = false;\n\t\tnvm_size = hw->flash.flash_size;\n\t} else if (ops == &ice_sram_region_ops) {\n\t\tread_shadow_ram = true;\n\t\tnvm_size = hw->flash.sr_words * 2u;\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Unexpected region in snapshot function\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (offset + size >= nvm_size) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Cannot read beyond the region size\");\n\t\treturn -ERANGE;\n\t}\n\n\tstatus = ice_acquire_nvm(hw, ICE_RES_READ);\n\tif (status) {\n\t\tdev_dbg(dev, \"ice_acquire_nvm failed, err %d aq_err %d\\n\",\n\t\t\tstatus, hw->adminq.sq_last_status);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to acquire NVM semaphore\");\n\t\treturn -EIO;\n\t}\n\n\tstatus = ice_read_flat_nvm(hw, (u32)offset, &size, data,\n\t\t\t\t   read_shadow_ram);\n\tif (status) {\n\t\tdev_dbg(dev, \"ice_read_flat_nvm failed after reading %u bytes, err %d aq_err %d\\n\",\n\t\t\tsize, status, hw->adminq.sq_last_status);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to read NVM contents\");\n\t\tice_release_nvm(hw);\n\t\treturn -EIO;\n\t}\n\tice_release_nvm(hw);\n\n\treturn 0;\n}\n\n \nstatic int\nice_devlink_devcaps_snapshot(struct devlink *devlink,\n\t\t\t     const struct devlink_region_ops *ops,\n\t\t\t     struct netlink_ext_ack *extack, u8 **data)\n{\n\tstruct ice_pf *pf = devlink_priv(devlink);\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tstruct ice_hw *hw = &pf->hw;\n\tvoid *devcaps;\n\tint status;\n\n\tdevcaps = vzalloc(ICE_AQ_MAX_BUF_LEN);\n\tif (!devcaps)\n\t\treturn -ENOMEM;\n\n\tstatus = ice_aq_list_caps(hw, devcaps, ICE_AQ_MAX_BUF_LEN, NULL,\n\t\t\t\t  ice_aqc_opc_list_dev_caps, NULL);\n\tif (status) {\n\t\tdev_dbg(dev, \"ice_aq_list_caps: failed to read device capabilities, err %d aq_err %d\\n\",\n\t\t\tstatus, hw->adminq.sq_last_status);\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Failed to read device capabilities\");\n\t\tvfree(devcaps);\n\t\treturn status;\n\t}\n\n\t*data = (u8 *)devcaps;\n\n\treturn 0;\n}\n\nstatic const struct devlink_region_ops ice_nvm_region_ops = {\n\t.name = \"nvm-flash\",\n\t.destructor = vfree,\n\t.snapshot = ice_devlink_nvm_snapshot,\n\t.read = ice_devlink_nvm_read,\n};\n\nstatic const struct devlink_region_ops ice_sram_region_ops = {\n\t.name = \"shadow-ram\",\n\t.destructor = vfree,\n\t.snapshot = ice_devlink_nvm_snapshot,\n\t.read = ice_devlink_nvm_read,\n};\n\nstatic const struct devlink_region_ops ice_devcaps_region_ops = {\n\t.name = \"device-caps\",\n\t.destructor = vfree,\n\t.snapshot = ice_devlink_devcaps_snapshot,\n};\n\n \nvoid ice_devlink_init_regions(struct ice_pf *pf)\n{\n\tstruct devlink *devlink = priv_to_devlink(pf);\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tu64 nvm_size, sram_size;\n\n\tnvm_size = pf->hw.flash.flash_size;\n\tpf->nvm_region = devlink_region_create(devlink, &ice_nvm_region_ops, 1,\n\t\t\t\t\t       nvm_size);\n\tif (IS_ERR(pf->nvm_region)) {\n\t\tdev_err(dev, \"failed to create NVM devlink region, err %ld\\n\",\n\t\t\tPTR_ERR(pf->nvm_region));\n\t\tpf->nvm_region = NULL;\n\t}\n\n\tsram_size = pf->hw.flash.sr_words * 2u;\n\tpf->sram_region = devlink_region_create(devlink, &ice_sram_region_ops,\n\t\t\t\t\t\t1, sram_size);\n\tif (IS_ERR(pf->sram_region)) {\n\t\tdev_err(dev, \"failed to create shadow-ram devlink region, err %ld\\n\",\n\t\t\tPTR_ERR(pf->sram_region));\n\t\tpf->sram_region = NULL;\n\t}\n\n\tpf->devcaps_region = devlink_region_create(devlink,\n\t\t\t\t\t\t   &ice_devcaps_region_ops, 10,\n\t\t\t\t\t\t   ICE_AQ_MAX_BUF_LEN);\n\tif (IS_ERR(pf->devcaps_region)) {\n\t\tdev_err(dev, \"failed to create device-caps devlink region, err %ld\\n\",\n\t\t\tPTR_ERR(pf->devcaps_region));\n\t\tpf->devcaps_region = NULL;\n\t}\n}\n\n \nvoid ice_devlink_destroy_regions(struct ice_pf *pf)\n{\n\tif (pf->nvm_region)\n\t\tdevlink_region_destroy(pf->nvm_region);\n\n\tif (pf->sram_region)\n\t\tdevlink_region_destroy(pf->sram_region);\n\n\tif (pf->devcaps_region)\n\t\tdevlink_region_destroy(pf->devcaps_region);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}