{
  "module_name": "ice_repr.c",
  "hash_id": "88ac4d0cd60e72589577b19600e6b13a3603df8f1f55026343f88d7fce52d1ce",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_repr.c",
  "human_readable_source": "\n \n\n#include \"ice.h\"\n#include \"ice_eswitch.h\"\n#include \"ice_devlink.h\"\n#include \"ice_sriov.h\"\n#include \"ice_tc_lib.h\"\n#include \"ice_dcb_lib.h\"\n\n \nstatic int ice_repr_get_sw_port_id(struct ice_repr *repr)\n{\n\treturn repr->vf->pf->hw.port_info->lport;\n}\n\n \nstatic int\nice_repr_get_phys_port_name(struct net_device *netdev, char *buf, size_t len)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(netdev);\n\tstruct ice_repr *repr = np->repr;\n\tint res;\n\n\t \n\tif (repr->vf->devlink_port.devlink)\n\t\treturn -EOPNOTSUPP;\n\n\tres = snprintf(buf, len, \"pf%dvfr%d\", ice_repr_get_sw_port_id(repr),\n\t\t       repr->vf->vf_id);\n\tif (res <= 0)\n\t\treturn -EOPNOTSUPP;\n\treturn 0;\n}\n\n \nstatic void\nice_repr_get_stats64(struct net_device *netdev, struct rtnl_link_stats64 *stats)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(netdev);\n\tstruct ice_eth_stats *eth_stats;\n\tstruct ice_vsi *vsi;\n\n\tif (ice_is_vf_disabled(np->repr->vf))\n\t\treturn;\n\tvsi = np->repr->src_vsi;\n\n\tice_update_vsi_stats(vsi);\n\teth_stats = &vsi->eth_stats;\n\n\tstats->tx_packets = eth_stats->tx_unicast + eth_stats->tx_broadcast +\n\t\t\t    eth_stats->tx_multicast;\n\tstats->rx_packets = eth_stats->rx_unicast + eth_stats->rx_broadcast +\n\t\t\t    eth_stats->rx_multicast;\n\tstats->tx_bytes = eth_stats->tx_bytes;\n\tstats->rx_bytes = eth_stats->rx_bytes;\n\tstats->multicast = eth_stats->rx_multicast;\n\tstats->tx_errors = eth_stats->tx_errors;\n\tstats->tx_dropped = eth_stats->tx_discards;\n\tstats->rx_dropped = eth_stats->rx_discards;\n}\n\n \nstruct ice_repr *ice_netdev_to_repr(struct net_device *netdev)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(netdev);\n\n\treturn np->repr;\n}\n\n \nstatic int ice_repr_open(struct net_device *netdev)\n{\n\tstruct ice_repr *repr = ice_netdev_to_repr(netdev);\n\tstruct ice_vf *vf;\n\n\tvf = repr->vf;\n\tvf->link_forced = true;\n\tvf->link_up = true;\n\tice_vc_notify_vf_link_state(vf);\n\n\tnetif_carrier_on(netdev);\n\tnetif_tx_start_all_queues(netdev);\n\n\treturn 0;\n}\n\n \nstatic int ice_repr_stop(struct net_device *netdev)\n{\n\tstruct ice_repr *repr = ice_netdev_to_repr(netdev);\n\tstruct ice_vf *vf;\n\n\tvf = repr->vf;\n\tvf->link_forced = true;\n\tvf->link_up = false;\n\tice_vc_notify_vf_link_state(vf);\n\n\tnetif_carrier_off(netdev);\n\tnetif_tx_stop_all_queues(netdev);\n\n\treturn 0;\n}\n\n \nstatic int\nice_repr_sp_stats64(const struct net_device *dev,\n\t\t    struct rtnl_link_stats64 *stats)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(dev);\n\tint vf_id = np->repr->vf->vf_id;\n\tstruct ice_tx_ring *tx_ring;\n\tstruct ice_rx_ring *rx_ring;\n\tu64 pkts, bytes;\n\n\ttx_ring = np->vsi->tx_rings[vf_id];\n\tice_fetch_u64_stats_per_ring(&tx_ring->ring_stats->syncp,\n\t\t\t\t     tx_ring->ring_stats->stats,\n\t\t\t\t     &pkts, &bytes);\n\tstats->rx_packets = pkts;\n\tstats->rx_bytes = bytes;\n\n\trx_ring = np->vsi->rx_rings[vf_id];\n\tice_fetch_u64_stats_per_ring(&rx_ring->ring_stats->syncp,\n\t\t\t\t     rx_ring->ring_stats->stats,\n\t\t\t\t     &pkts, &bytes);\n\tstats->tx_packets = pkts;\n\tstats->tx_bytes = bytes;\n\tstats->tx_dropped = rx_ring->ring_stats->rx_stats.alloc_page_failed +\n\t\t\t    rx_ring->ring_stats->rx_stats.alloc_buf_failed;\n\n\treturn 0;\n}\n\nstatic bool\nice_repr_ndo_has_offload_stats(const struct net_device *dev, int attr_id)\n{\n\treturn attr_id == IFLA_OFFLOAD_XSTATS_CPU_HIT;\n}\n\nstatic int\nice_repr_ndo_get_offload_stats(int attr_id, const struct net_device *dev,\n\t\t\t       void *sp)\n{\n\tif (attr_id == IFLA_OFFLOAD_XSTATS_CPU_HIT)\n\t\treturn ice_repr_sp_stats64(dev, (struct rtnl_link_stats64 *)sp);\n\n\treturn -EINVAL;\n}\n\nstatic int\nice_repr_setup_tc_cls_flower(struct ice_repr *repr,\n\t\t\t     struct flow_cls_offload *flower)\n{\n\tswitch (flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn ice_add_cls_flower(repr->netdev, repr->src_vsi, flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn ice_del_cls_flower(repr->src_vsi, flower);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic int\nice_repr_setup_tc_block_cb(enum tc_setup_type type, void *type_data,\n\t\t\t   void *cb_priv)\n{\n\tstruct flow_cls_offload *flower = (struct flow_cls_offload *)type_data;\n\tstruct ice_netdev_priv *np = (struct ice_netdev_priv *)cb_priv;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\treturn ice_repr_setup_tc_cls_flower(np->repr, flower);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic LIST_HEAD(ice_repr_block_cb_list);\n\nstatic int\nice_repr_setup_tc(struct net_device *netdev, enum tc_setup_type type,\n\t\t  void *type_data)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(netdev);\n\n\tswitch (type) {\n\tcase TC_SETUP_BLOCK:\n\t\treturn flow_block_cb_setup_simple((struct flow_block_offload *)\n\t\t\t\t\t\t  type_data,\n\t\t\t\t\t\t  &ice_repr_block_cb_list,\n\t\t\t\t\t\t  ice_repr_setup_tc_block_cb,\n\t\t\t\t\t\t  np, np, true);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic const struct net_device_ops ice_repr_netdev_ops = {\n\t.ndo_get_phys_port_name = ice_repr_get_phys_port_name,\n\t.ndo_get_stats64 = ice_repr_get_stats64,\n\t.ndo_open = ice_repr_open,\n\t.ndo_stop = ice_repr_stop,\n\t.ndo_start_xmit = ice_eswitch_port_start_xmit,\n\t.ndo_setup_tc = ice_repr_setup_tc,\n\t.ndo_has_offload_stats = ice_repr_ndo_has_offload_stats,\n\t.ndo_get_offload_stats = ice_repr_ndo_get_offload_stats,\n};\n\n \nbool ice_is_port_repr_netdev(const struct net_device *netdev)\n{\n\treturn netdev && (netdev->netdev_ops == &ice_repr_netdev_ops);\n}\n\n \nstatic int\nice_repr_reg_netdev(struct net_device *netdev)\n{\n\teth_hw_addr_random(netdev);\n\tnetdev->netdev_ops = &ice_repr_netdev_ops;\n\tice_set_ethtool_repr_ops(netdev);\n\n\tnetdev->hw_features |= NETIF_F_HW_TC;\n\n\tnetif_carrier_off(netdev);\n\tnetif_tx_stop_all_queues(netdev);\n\n\treturn register_netdev(netdev);\n}\n\n \nstatic int ice_repr_add(struct ice_vf *vf)\n{\n\tstruct ice_q_vector *q_vector;\n\tstruct ice_netdev_priv *np;\n\tstruct ice_repr *repr;\n\tstruct ice_vsi *vsi;\n\tint err;\n\n\tvsi = ice_get_vf_vsi(vf);\n\tif (!vsi)\n\t\treturn -EINVAL;\n\n\trepr = kzalloc(sizeof(*repr), GFP_KERNEL);\n\tif (!repr)\n\t\treturn -ENOMEM;\n\n\trepr->netdev = alloc_etherdev(sizeof(struct ice_netdev_priv));\n\tif (!repr->netdev) {\n\t\terr =  -ENOMEM;\n\t\tgoto err_alloc;\n\t}\n\n\trepr->src_vsi = vsi;\n\trepr->vf = vf;\n\tvf->repr = repr;\n\tnp = netdev_priv(repr->netdev);\n\tnp->repr = repr;\n\n\tq_vector = kzalloc(sizeof(*q_vector), GFP_KERNEL);\n\tif (!q_vector) {\n\t\terr = -ENOMEM;\n\t\tgoto err_alloc_q_vector;\n\t}\n\trepr->q_vector = q_vector;\n\n\terr = ice_devlink_create_vf_port(vf);\n\tif (err)\n\t\tgoto err_devlink;\n\n\trepr->netdev->min_mtu = ETH_MIN_MTU;\n\trepr->netdev->max_mtu = ICE_MAX_MTU;\n\n\tSET_NETDEV_DEV(repr->netdev, ice_pf_to_dev(vf->pf));\n\tSET_NETDEV_DEVLINK_PORT(repr->netdev, &vf->devlink_port);\n\terr = ice_repr_reg_netdev(repr->netdev);\n\tif (err)\n\t\tgoto err_netdev;\n\n\tice_virtchnl_set_repr_ops(vf);\n\n\treturn 0;\n\nerr_netdev:\n\tice_devlink_destroy_vf_port(vf);\nerr_devlink:\n\tkfree(repr->q_vector);\n\tvf->repr->q_vector = NULL;\nerr_alloc_q_vector:\n\tfree_netdev(repr->netdev);\n\trepr->netdev = NULL;\nerr_alloc:\n\tkfree(repr);\n\tvf->repr = NULL;\n\treturn err;\n}\n\n \nstatic void ice_repr_rem(struct ice_vf *vf)\n{\n\tif (!vf->repr)\n\t\treturn;\n\n\tkfree(vf->repr->q_vector);\n\tvf->repr->q_vector = NULL;\n\tunregister_netdev(vf->repr->netdev);\n\tice_devlink_destroy_vf_port(vf);\n\tfree_netdev(vf->repr->netdev);\n\tvf->repr->netdev = NULL;\n\tkfree(vf->repr);\n\tvf->repr = NULL;\n\n\tice_virtchnl_set_dflt_ops(vf);\n}\n\n \nvoid ice_repr_rem_from_all_vfs(struct ice_pf *pf)\n{\n\tstruct devlink *devlink;\n\tstruct ice_vf *vf;\n\tunsigned int bkt;\n\n\tlockdep_assert_held(&pf->vfs.table_lock);\n\n\tice_for_each_vf(pf, bkt, vf)\n\t\tice_repr_rem(vf);\n\n\t \n\tdevlink = priv_to_devlink(pf);\n\tdevl_lock(devlink);\n\tdevl_rate_nodes_destroy(devlink);\n\tdevl_unlock(devlink);\n}\n\n \nint ice_repr_add_for_all_vfs(struct ice_pf *pf)\n{\n\tstruct devlink *devlink;\n\tstruct ice_vf *vf;\n\tunsigned int bkt;\n\tint err;\n\n\tlockdep_assert_held(&pf->vfs.table_lock);\n\n\tice_for_each_vf(pf, bkt, vf) {\n\t\terr = ice_repr_add(vf);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\t \n\tif (ice_is_adq_active(pf) || ice_is_dcb_active(pf))\n\t\treturn 0;\n\n\tdevlink = priv_to_devlink(pf);\n\tice_devlink_rate_init_tx_topology(devlink, ice_get_main_vsi(pf));\n\n\treturn 0;\n\nerr:\n\tice_repr_rem_from_all_vfs(pf);\n\n\treturn err;\n}\n\n \nvoid ice_repr_start_tx_queues(struct ice_repr *repr)\n{\n\tnetif_carrier_on(repr->netdev);\n\tnetif_tx_start_all_queues(repr->netdev);\n}\n\n \nvoid ice_repr_stop_tx_queues(struct ice_repr *repr)\n{\n\tnetif_carrier_off(repr->netdev);\n\tnetif_tx_stop_all_queues(repr->netdev);\n}\n\n \nvoid ice_repr_set_traffic_vsi(struct ice_repr *repr, struct ice_vsi *vsi)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(repr->netdev);\n\n\tnp->vsi = vsi;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}