{
  "module_name": "ice_sched.c",
  "hash_id": "cb4e324f43a164c9975489b09614467f2e271cc4f79849e6b84aa4167f77cad0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_sched.c",
  "human_readable_source": "\n \n\n#include <net/devlink.h>\n#include \"ice_sched.h\"\n\n \nstatic int\nice_sched_add_root_node(struct ice_port_info *pi,\n\t\t\tstruct ice_aqc_txsched_elem_data *info)\n{\n\tstruct ice_sched_node *root;\n\tstruct ice_hw *hw;\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\n\thw = pi->hw;\n\n\troot = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*root), GFP_KERNEL);\n\tif (!root)\n\t\treturn -ENOMEM;\n\n\t \n\troot->children = devm_kcalloc(ice_hw_to_dev(hw), hw->max_children[0],\n\t\t\t\t      sizeof(*root), GFP_KERNEL);\n\tif (!root->children) {\n\t\tdevm_kfree(ice_hw_to_dev(hw), root);\n\t\treturn -ENOMEM;\n\t}\n\n\tmemcpy(&root->info, info, sizeof(*info));\n\tpi->root = root;\n\treturn 0;\n}\n\n \nstruct ice_sched_node *\nice_sched_find_node_by_teid(struct ice_sched_node *start_node, u32 teid)\n{\n\tu16 i;\n\n\t \n\tif (ICE_TXSCHED_GET_NODE_TEID(start_node) == teid)\n\t\treturn start_node;\n\n\t \n\tif (!start_node->num_children ||\n\t    start_node->tx_sched_layer >= ICE_AQC_TOPO_MAX_LEVEL_NUM ||\n\t    start_node->info.data.elem_type == ICE_AQC_ELEM_TYPE_LEAF)\n\t\treturn NULL;\n\n\t \n\tfor (i = 0; i < start_node->num_children; i++)\n\t\tif (ICE_TXSCHED_GET_NODE_TEID(start_node->children[i]) == teid)\n\t\t\treturn start_node->children[i];\n\n\t \n\tfor (i = 0; i < start_node->num_children; i++) {\n\t\tstruct ice_sched_node *tmp;\n\n\t\ttmp = ice_sched_find_node_by_teid(start_node->children[i],\n\t\t\t\t\t\t  teid);\n\t\tif (tmp)\n\t\t\treturn tmp;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic int\nice_aqc_send_sched_elem_cmd(struct ice_hw *hw, enum ice_adminq_opc cmd_opc,\n\t\t\t    u16 elems_req, void *buf, u16 buf_size,\n\t\t\t    u16 *elems_resp, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_sched_elem_cmd *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tcmd = &desc.params.sched_elem_cmd;\n\tice_fill_dflt_direct_cmd_desc(&desc, cmd_opc);\n\tcmd->num_elem_req = cpu_to_le16(elems_req);\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\tstatus = ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n\tif (!status && elems_resp)\n\t\t*elems_resp = le16_to_cpu(cmd->num_elem_resp);\n\n\treturn status;\n}\n\n \nint\nice_aq_query_sched_elems(struct ice_hw *hw, u16 elems_req,\n\t\t\t struct ice_aqc_txsched_elem_data *buf, u16 buf_size,\n\t\t\t u16 *elems_ret, struct ice_sq_cd *cd)\n{\n\treturn ice_aqc_send_sched_elem_cmd(hw, ice_aqc_opc_get_sched_elems,\n\t\t\t\t\t   elems_req, (void *)buf, buf_size,\n\t\t\t\t\t   elems_ret, cd);\n}\n\n \nint\nice_sched_add_node(struct ice_port_info *pi, u8 layer,\n\t\t   struct ice_aqc_txsched_elem_data *info,\n\t\t   struct ice_sched_node *prealloc_node)\n{\n\tstruct ice_aqc_txsched_elem_data elem;\n\tstruct ice_sched_node *parent;\n\tstruct ice_sched_node *node;\n\tstruct ice_hw *hw;\n\tint status;\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\n\thw = pi->hw;\n\n\t \n\tparent = ice_sched_find_node_by_teid(pi->root,\n\t\t\t\t\t     le32_to_cpu(info->parent_teid));\n\tif (!parent) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"Parent Node not found for parent_teid=0x%x\\n\",\n\t\t\t  le32_to_cpu(info->parent_teid));\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tstatus = ice_sched_query_elem(hw, le32_to_cpu(info->node_teid), &elem);\n\tif (status)\n\t\treturn status;\n\n\tif (prealloc_node)\n\t\tnode = prealloc_node;\n\telse\n\t\tnode = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*node), GFP_KERNEL);\n\tif (!node)\n\t\treturn -ENOMEM;\n\tif (hw->max_children[layer]) {\n\t\t \n\t\tnode->children = devm_kcalloc(ice_hw_to_dev(hw),\n\t\t\t\t\t      hw->max_children[layer],\n\t\t\t\t\t      sizeof(*node), GFP_KERNEL);\n\t\tif (!node->children) {\n\t\t\tdevm_kfree(ice_hw_to_dev(hw), node);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tnode->in_use = true;\n\tnode->parent = parent;\n\tnode->tx_sched_layer = layer;\n\tparent->children[parent->num_children++] = node;\n\tnode->info = elem;\n\treturn 0;\n}\n\n \nstatic int\nice_aq_delete_sched_elems(struct ice_hw *hw, u16 grps_req,\n\t\t\t  struct ice_aqc_delete_elem *buf, u16 buf_size,\n\t\t\t  u16 *grps_del, struct ice_sq_cd *cd)\n{\n\treturn ice_aqc_send_sched_elem_cmd(hw, ice_aqc_opc_delete_sched_elems,\n\t\t\t\t\t   grps_req, (void *)buf, buf_size,\n\t\t\t\t\t   grps_del, cd);\n}\n\n \nstatic int\nice_sched_remove_elems(struct ice_hw *hw, struct ice_sched_node *parent,\n\t\t       u16 num_nodes, u32 *node_teids)\n{\n\tstruct ice_aqc_delete_elem *buf;\n\tu16 i, num_groups_removed = 0;\n\tu16 buf_size;\n\tint status;\n\n\tbuf_size = struct_size(buf, teid, num_nodes);\n\tbuf = devm_kzalloc(ice_hw_to_dev(hw), buf_size, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tbuf->hdr.parent_teid = parent->info.node_teid;\n\tbuf->hdr.num_elems = cpu_to_le16(num_nodes);\n\tfor (i = 0; i < num_nodes; i++)\n\t\tbuf->teid[i] = cpu_to_le32(node_teids[i]);\n\n\tstatus = ice_aq_delete_sched_elems(hw, 1, buf, buf_size,\n\t\t\t\t\t   &num_groups_removed, NULL);\n\tif (status || num_groups_removed != 1)\n\t\tice_debug(hw, ICE_DBG_SCHED, \"remove node failed FW error %d\\n\",\n\t\t\t  hw->adminq.sq_last_status);\n\n\tdevm_kfree(ice_hw_to_dev(hw), buf);\n\treturn status;\n}\n\n \nstatic struct ice_sched_node *\nice_sched_get_first_node(struct ice_port_info *pi,\n\t\t\t struct ice_sched_node *parent, u8 layer)\n{\n\treturn pi->sib_head[parent->tc_num][layer];\n}\n\n \nstruct ice_sched_node *ice_sched_get_tc_node(struct ice_port_info *pi, u8 tc)\n{\n\tu8 i;\n\n\tif (!pi || !pi->root)\n\t\treturn NULL;\n\tfor (i = 0; i < pi->root->num_children; i++)\n\t\tif (pi->root->children[i]->tc_num == tc)\n\t\t\treturn pi->root->children[i];\n\treturn NULL;\n}\n\n \nvoid ice_free_sched_node(struct ice_port_info *pi, struct ice_sched_node *node)\n{\n\tstruct ice_sched_node *parent;\n\tstruct ice_hw *hw = pi->hw;\n\tu8 i, j;\n\n\t \n\twhile (node->num_children)\n\t\tice_free_sched_node(pi, node->children[0]);\n\n\t \n\tif (node->tx_sched_layer >= hw->sw_entry_point_layer &&\n\t    node->info.data.elem_type != ICE_AQC_ELEM_TYPE_TC &&\n\t    node->info.data.elem_type != ICE_AQC_ELEM_TYPE_ROOT_PORT &&\n\t    node->info.data.elem_type != ICE_AQC_ELEM_TYPE_LEAF) {\n\t\tu32 teid = le32_to_cpu(node->info.node_teid);\n\n\t\tice_sched_remove_elems(hw, node->parent, 1, &teid);\n\t}\n\tparent = node->parent;\n\t \n\tif (parent) {\n\t\tstruct ice_sched_node *p;\n\n\t\t \n\t\tfor (i = 0; i < parent->num_children; i++)\n\t\t\tif (parent->children[i] == node) {\n\t\t\t\tfor (j = i + 1; j < parent->num_children; j++)\n\t\t\t\t\tparent->children[j - 1] =\n\t\t\t\t\t\tparent->children[j];\n\t\t\t\tparent->num_children--;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tp = ice_sched_get_first_node(pi, node, node->tx_sched_layer);\n\t\twhile (p) {\n\t\t\tif (p->sibling == node) {\n\t\t\t\tp->sibling = node->sibling;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tp = p->sibling;\n\t\t}\n\n\t\t \n\t\tif (pi->sib_head[node->tc_num][node->tx_sched_layer] == node)\n\t\t\tpi->sib_head[node->tc_num][node->tx_sched_layer] =\n\t\t\t\tnode->sibling;\n\t}\n\n\tdevm_kfree(ice_hw_to_dev(hw), node->children);\n\tkfree(node->name);\n\txa_erase(&pi->sched_node_ids, node->id);\n\tdevm_kfree(ice_hw_to_dev(hw), node);\n}\n\n \nstatic int\nice_aq_get_dflt_topo(struct ice_hw *hw, u8 lport,\n\t\t     struct ice_aqc_get_topo_elem *buf, u16 buf_size,\n\t\t     u8 *num_branches, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_get_topo *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tcmd = &desc.params.get_topo;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_dflt_topo);\n\tcmd->port_num = lport;\n\tstatus = ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n\tif (!status && num_branches)\n\t\t*num_branches = cmd->num_branches;\n\n\treturn status;\n}\n\n \nstatic int\nice_aq_add_sched_elems(struct ice_hw *hw, u16 grps_req,\n\t\t       struct ice_aqc_add_elem *buf, u16 buf_size,\n\t\t       u16 *grps_added, struct ice_sq_cd *cd)\n{\n\treturn ice_aqc_send_sched_elem_cmd(hw, ice_aqc_opc_add_sched_elems,\n\t\t\t\t\t   grps_req, (void *)buf, buf_size,\n\t\t\t\t\t   grps_added, cd);\n}\n\n \nstatic int\nice_aq_cfg_sched_elems(struct ice_hw *hw, u16 elems_req,\n\t\t       struct ice_aqc_txsched_elem_data *buf, u16 buf_size,\n\t\t       u16 *elems_cfgd, struct ice_sq_cd *cd)\n{\n\treturn ice_aqc_send_sched_elem_cmd(hw, ice_aqc_opc_cfg_sched_elems,\n\t\t\t\t\t   elems_req, (void *)buf, buf_size,\n\t\t\t\t\t   elems_cfgd, cd);\n}\n\n \nint\nice_aq_move_sched_elems(struct ice_hw *hw, u16 grps_req,\n\t\t\tstruct ice_aqc_move_elem *buf, u16 buf_size,\n\t\t\tu16 *grps_movd, struct ice_sq_cd *cd)\n{\n\treturn ice_aqc_send_sched_elem_cmd(hw, ice_aqc_opc_move_sched_elems,\n\t\t\t\t\t   grps_req, (void *)buf, buf_size,\n\t\t\t\t\t   grps_movd, cd);\n}\n\n \nstatic int\nice_aq_suspend_sched_elems(struct ice_hw *hw, u16 elems_req, __le32 *buf,\n\t\t\t   u16 buf_size, u16 *elems_ret, struct ice_sq_cd *cd)\n{\n\treturn ice_aqc_send_sched_elem_cmd(hw, ice_aqc_opc_suspend_sched_elems,\n\t\t\t\t\t   elems_req, (void *)buf, buf_size,\n\t\t\t\t\t   elems_ret, cd);\n}\n\n \nstatic int\nice_aq_resume_sched_elems(struct ice_hw *hw, u16 elems_req, __le32 *buf,\n\t\t\t  u16 buf_size, u16 *elems_ret, struct ice_sq_cd *cd)\n{\n\treturn ice_aqc_send_sched_elem_cmd(hw, ice_aqc_opc_resume_sched_elems,\n\t\t\t\t\t   elems_req, (void *)buf, buf_size,\n\t\t\t\t\t   elems_ret, cd);\n}\n\n \nstatic int\nice_aq_query_sched_res(struct ice_hw *hw, u16 buf_size,\n\t\t       struct ice_aqc_query_txsched_res_resp *buf,\n\t\t       struct ice_sq_cd *cd)\n{\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_query_sched_res);\n\treturn ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n}\n\n \nint\nice_sched_suspend_resume_elems(struct ice_hw *hw, u8 num_nodes, u32 *node_teids,\n\t\t\t       bool suspend)\n{\n\tu16 i, buf_size, num_elem_ret = 0;\n\t__le32 *buf;\n\tint status;\n\n\tbuf_size = sizeof(*buf) * num_nodes;\n\tbuf = devm_kzalloc(ice_hw_to_dev(hw), buf_size, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_nodes; i++)\n\t\tbuf[i] = cpu_to_le32(node_teids[i]);\n\n\tif (suspend)\n\t\tstatus = ice_aq_suspend_sched_elems(hw, num_nodes, buf,\n\t\t\t\t\t\t    buf_size, &num_elem_ret,\n\t\t\t\t\t\t    NULL);\n\telse\n\t\tstatus = ice_aq_resume_sched_elems(hw, num_nodes, buf,\n\t\t\t\t\t\t   buf_size, &num_elem_ret,\n\t\t\t\t\t\t   NULL);\n\tif (status || num_elem_ret != num_nodes)\n\t\tice_debug(hw, ICE_DBG_SCHED, \"suspend/resume failed\\n\");\n\n\tdevm_kfree(ice_hw_to_dev(hw), buf);\n\treturn status;\n}\n\n \nstatic int\nice_alloc_lan_q_ctx(struct ice_hw *hw, u16 vsi_handle, u8 tc, u16 new_numqs)\n{\n\tstruct ice_vsi_ctx *vsi_ctx;\n\tstruct ice_q_ctx *q_ctx;\n\tu16 idx;\n\n\tvsi_ctx = ice_get_vsi_ctx(hw, vsi_handle);\n\tif (!vsi_ctx)\n\t\treturn -EINVAL;\n\t \n\tif (!vsi_ctx->lan_q_ctx[tc]) {\n\t\tq_ctx = devm_kcalloc(ice_hw_to_dev(hw), new_numqs,\n\t\t\t\t     sizeof(*q_ctx), GFP_KERNEL);\n\t\tif (!q_ctx)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (idx = 0; idx < new_numqs; idx++) {\n\t\t\tq_ctx[idx].q_handle = ICE_INVAL_Q_HANDLE;\n\t\t\tq_ctx[idx].q_teid = ICE_INVAL_TEID;\n\t\t}\n\n\t\tvsi_ctx->lan_q_ctx[tc] = q_ctx;\n\t\tvsi_ctx->num_lan_q_entries[tc] = new_numqs;\n\t\treturn 0;\n\t}\n\t \n\tif (new_numqs > vsi_ctx->num_lan_q_entries[tc]) {\n\t\tu16 prev_num = vsi_ctx->num_lan_q_entries[tc];\n\n\t\tq_ctx = devm_kcalloc(ice_hw_to_dev(hw), new_numqs,\n\t\t\t\t     sizeof(*q_ctx), GFP_KERNEL);\n\t\tif (!q_ctx)\n\t\t\treturn -ENOMEM;\n\n\t\tmemcpy(q_ctx, vsi_ctx->lan_q_ctx[tc],\n\t\t       prev_num * sizeof(*q_ctx));\n\t\tdevm_kfree(ice_hw_to_dev(hw), vsi_ctx->lan_q_ctx[tc]);\n\n\t\tfor (idx = prev_num; idx < new_numqs; idx++) {\n\t\t\tq_ctx[idx].q_handle = ICE_INVAL_Q_HANDLE;\n\t\t\tq_ctx[idx].q_teid = ICE_INVAL_TEID;\n\t\t}\n\n\t\tvsi_ctx->lan_q_ctx[tc] = q_ctx;\n\t\tvsi_ctx->num_lan_q_entries[tc] = new_numqs;\n\t}\n\treturn 0;\n}\n\n \nstatic int\nice_alloc_rdma_q_ctx(struct ice_hw *hw, u16 vsi_handle, u8 tc, u16 new_numqs)\n{\n\tstruct ice_vsi_ctx *vsi_ctx;\n\tstruct ice_q_ctx *q_ctx;\n\n\tvsi_ctx = ice_get_vsi_ctx(hw, vsi_handle);\n\tif (!vsi_ctx)\n\t\treturn -EINVAL;\n\t \n\tif (!vsi_ctx->rdma_q_ctx[tc]) {\n\t\tvsi_ctx->rdma_q_ctx[tc] = devm_kcalloc(ice_hw_to_dev(hw),\n\t\t\t\t\t\t       new_numqs,\n\t\t\t\t\t\t       sizeof(*q_ctx),\n\t\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!vsi_ctx->rdma_q_ctx[tc])\n\t\t\treturn -ENOMEM;\n\t\tvsi_ctx->num_rdma_q_entries[tc] = new_numqs;\n\t\treturn 0;\n\t}\n\t \n\tif (new_numqs > vsi_ctx->num_rdma_q_entries[tc]) {\n\t\tu16 prev_num = vsi_ctx->num_rdma_q_entries[tc];\n\n\t\tq_ctx = devm_kcalloc(ice_hw_to_dev(hw), new_numqs,\n\t\t\t\t     sizeof(*q_ctx), GFP_KERNEL);\n\t\tif (!q_ctx)\n\t\t\treturn -ENOMEM;\n\t\tmemcpy(q_ctx, vsi_ctx->rdma_q_ctx[tc],\n\t\t       prev_num * sizeof(*q_ctx));\n\t\tdevm_kfree(ice_hw_to_dev(hw), vsi_ctx->rdma_q_ctx[tc]);\n\t\tvsi_ctx->rdma_q_ctx[tc] = q_ctx;\n\t\tvsi_ctx->num_rdma_q_entries[tc] = new_numqs;\n\t}\n\treturn 0;\n}\n\n \nstatic int\nice_aq_rl_profile(struct ice_hw *hw, enum ice_adminq_opc opcode,\n\t\t  u16 num_profiles, struct ice_aqc_rl_profile_elem *buf,\n\t\t  u16 buf_size, u16 *num_processed, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_rl_profile *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tcmd = &desc.params.rl_profile;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, opcode);\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\tcmd->num_profiles = cpu_to_le16(num_profiles);\n\tstatus = ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n\tif (!status && num_processed)\n\t\t*num_processed = le16_to_cpu(cmd->num_processed);\n\treturn status;\n}\n\n \nstatic int\nice_aq_add_rl_profile(struct ice_hw *hw, u16 num_profiles,\n\t\t      struct ice_aqc_rl_profile_elem *buf, u16 buf_size,\n\t\t      u16 *num_profiles_added, struct ice_sq_cd *cd)\n{\n\treturn ice_aq_rl_profile(hw, ice_aqc_opc_add_rl_profiles, num_profiles,\n\t\t\t\t buf, buf_size, num_profiles_added, cd);\n}\n\n \nstatic int\nice_aq_remove_rl_profile(struct ice_hw *hw, u16 num_profiles,\n\t\t\t struct ice_aqc_rl_profile_elem *buf, u16 buf_size,\n\t\t\t u16 *num_profiles_removed, struct ice_sq_cd *cd)\n{\n\treturn ice_aq_rl_profile(hw, ice_aqc_opc_remove_rl_profiles,\n\t\t\t\t num_profiles, buf, buf_size,\n\t\t\t\t num_profiles_removed, cd);\n}\n\n \nstatic int\nice_sched_del_rl_profile(struct ice_hw *hw,\n\t\t\t struct ice_aqc_rl_profile_info *rl_info)\n{\n\tstruct ice_aqc_rl_profile_elem *buf;\n\tu16 num_profiles_removed;\n\tu16 num_profiles = 1;\n\tint status;\n\n\tif (rl_info->prof_id_ref != 0)\n\t\treturn -EBUSY;\n\n\t \n\tbuf = &rl_info->profile;\n\tstatus = ice_aq_remove_rl_profile(hw, num_profiles, buf, sizeof(*buf),\n\t\t\t\t\t  &num_profiles_removed, NULL);\n\tif (status || num_profiles_removed != num_profiles)\n\t\treturn -EIO;\n\n\t \n\tlist_del(&rl_info->list_entry);\n\tdevm_kfree(ice_hw_to_dev(hw), rl_info);\n\treturn status;\n}\n\n \nstatic void ice_sched_clear_rl_prof(struct ice_port_info *pi)\n{\n\tu16 ln;\n\n\tfor (ln = 0; ln < pi->hw->num_tx_sched_layers; ln++) {\n\t\tstruct ice_aqc_rl_profile_info *rl_prof_elem;\n\t\tstruct ice_aqc_rl_profile_info *rl_prof_tmp;\n\n\t\tlist_for_each_entry_safe(rl_prof_elem, rl_prof_tmp,\n\t\t\t\t\t &pi->rl_prof_list[ln], list_entry) {\n\t\t\tstruct ice_hw *hw = pi->hw;\n\t\t\tint status;\n\n\t\t\trl_prof_elem->prof_id_ref = 0;\n\t\t\tstatus = ice_sched_del_rl_profile(hw, rl_prof_elem);\n\t\t\tif (status) {\n\t\t\t\tice_debug(hw, ICE_DBG_SCHED, \"Remove rl profile failed\\n\");\n\t\t\t\t \n\t\t\t\tlist_del(&rl_prof_elem->list_entry);\n\t\t\t\tdevm_kfree(ice_hw_to_dev(hw), rl_prof_elem);\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nvoid ice_sched_clear_agg(struct ice_hw *hw)\n{\n\tstruct ice_sched_agg_info *agg_info;\n\tstruct ice_sched_agg_info *atmp;\n\n\tlist_for_each_entry_safe(agg_info, atmp, &hw->agg_list, list_entry) {\n\t\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\t\tstruct ice_sched_agg_vsi_info *vtmp;\n\n\t\tlist_for_each_entry_safe(agg_vsi_info, vtmp,\n\t\t\t\t\t &agg_info->agg_vsi_list, list_entry) {\n\t\t\tlist_del(&agg_vsi_info->list_entry);\n\t\t\tdevm_kfree(ice_hw_to_dev(hw), agg_vsi_info);\n\t\t}\n\t\tlist_del(&agg_info->list_entry);\n\t\tdevm_kfree(ice_hw_to_dev(hw), agg_info);\n\t}\n}\n\n \nstatic void ice_sched_clear_tx_topo(struct ice_port_info *pi)\n{\n\tif (!pi)\n\t\treturn;\n\t \n\tice_sched_clear_rl_prof(pi);\n\tif (pi->root) {\n\t\tice_free_sched_node(pi, pi->root);\n\t\tpi->root = NULL;\n\t}\n}\n\n \nvoid ice_sched_clear_port(struct ice_port_info *pi)\n{\n\tif (!pi || pi->port_state != ICE_SCHED_PORT_STATE_READY)\n\t\treturn;\n\n\tpi->port_state = ICE_SCHED_PORT_STATE_INIT;\n\tmutex_lock(&pi->sched_lock);\n\tice_sched_clear_tx_topo(pi);\n\tmutex_unlock(&pi->sched_lock);\n\tmutex_destroy(&pi->sched_lock);\n}\n\n \nvoid ice_sched_cleanup_all(struct ice_hw *hw)\n{\n\tif (!hw)\n\t\treturn;\n\n\tdevm_kfree(ice_hw_to_dev(hw), hw->layer_info);\n\thw->layer_info = NULL;\n\n\tice_sched_clear_port(hw->port_info);\n\n\thw->num_tx_sched_layers = 0;\n\thw->num_tx_sched_phys_layers = 0;\n\thw->flattened_layers = 0;\n\thw->max_cgds = 0;\n}\n\n \nint\nice_sched_add_elems(struct ice_port_info *pi, struct ice_sched_node *tc_node,\n\t\t    struct ice_sched_node *parent, u8 layer, u16 num_nodes,\n\t\t    u16 *num_nodes_added, u32 *first_node_teid,\n\t\t    struct ice_sched_node **prealloc_nodes)\n{\n\tstruct ice_sched_node *prev, *new_node;\n\tstruct ice_aqc_add_elem *buf;\n\tu16 i, num_groups_added = 0;\n\tstruct ice_hw *hw = pi->hw;\n\tsize_t buf_size;\n\tint status = 0;\n\tu32 teid;\n\n\tbuf_size = struct_size(buf, generic, num_nodes);\n\tbuf = devm_kzalloc(ice_hw_to_dev(hw), buf_size, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tbuf->hdr.parent_teid = parent->info.node_teid;\n\tbuf->hdr.num_elems = cpu_to_le16(num_nodes);\n\tfor (i = 0; i < num_nodes; i++) {\n\t\tbuf->generic[i].parent_teid = parent->info.node_teid;\n\t\tbuf->generic[i].data.elem_type = ICE_AQC_ELEM_TYPE_SE_GENERIC;\n\t\tbuf->generic[i].data.valid_sections =\n\t\t\tICE_AQC_ELEM_VALID_GENERIC | ICE_AQC_ELEM_VALID_CIR |\n\t\t\tICE_AQC_ELEM_VALID_EIR;\n\t\tbuf->generic[i].data.generic = 0;\n\t\tbuf->generic[i].data.cir_bw.bw_profile_idx =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_RL_PROF_ID);\n\t\tbuf->generic[i].data.cir_bw.bw_alloc =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_BW_WT);\n\t\tbuf->generic[i].data.eir_bw.bw_profile_idx =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_RL_PROF_ID);\n\t\tbuf->generic[i].data.eir_bw.bw_alloc =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_BW_WT);\n\t}\n\n\tstatus = ice_aq_add_sched_elems(hw, 1, buf, buf_size,\n\t\t\t\t\t&num_groups_added, NULL);\n\tif (status || num_groups_added != 1) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"add node failed FW Error %d\\n\",\n\t\t\t  hw->adminq.sq_last_status);\n\t\tdevm_kfree(ice_hw_to_dev(hw), buf);\n\t\treturn -EIO;\n\t}\n\n\t*num_nodes_added = num_nodes;\n\t \n\tfor (i = 0; i < num_nodes; i++) {\n\t\tif (prealloc_nodes)\n\t\t\tstatus = ice_sched_add_node(pi, layer, &buf->generic[i], prealloc_nodes[i]);\n\t\telse\n\t\t\tstatus = ice_sched_add_node(pi, layer, &buf->generic[i], NULL);\n\n\t\tif (status) {\n\t\t\tice_debug(hw, ICE_DBG_SCHED, \"add nodes in SW DB failed status =%d\\n\",\n\t\t\t\t  status);\n\t\t\tbreak;\n\t\t}\n\n\t\tteid = le32_to_cpu(buf->generic[i].node_teid);\n\t\tnew_node = ice_sched_find_node_by_teid(parent, teid);\n\t\tif (!new_node) {\n\t\t\tice_debug(hw, ICE_DBG_SCHED, \"Node is missing for teid =%d\\n\", teid);\n\t\t\tbreak;\n\t\t}\n\n\t\tnew_node->sibling = NULL;\n\t\tnew_node->tc_num = tc_node->tc_num;\n\t\tnew_node->tx_weight = ICE_SCHED_DFLT_BW_WT;\n\t\tnew_node->tx_share = ICE_SCHED_DFLT_BW;\n\t\tnew_node->tx_max = ICE_SCHED_DFLT_BW;\n\t\tnew_node->name = kzalloc(SCHED_NODE_NAME_MAX_LEN, GFP_KERNEL);\n\t\tif (!new_node->name)\n\t\t\treturn -ENOMEM;\n\n\t\tstatus = xa_alloc(&pi->sched_node_ids, &new_node->id, NULL, XA_LIMIT(0, UINT_MAX),\n\t\t\t\t  GFP_KERNEL);\n\t\tif (status) {\n\t\t\tice_debug(hw, ICE_DBG_SCHED, \"xa_alloc failed for sched node status =%d\\n\",\n\t\t\t\t  status);\n\t\t\tbreak;\n\t\t}\n\n\t\tsnprintf(new_node->name, SCHED_NODE_NAME_MAX_LEN, \"node_%u\", new_node->id);\n\n\t\t \n\t\t \n\t\tprev = ice_sched_get_first_node(pi, tc_node, layer);\n\t\tif (prev && prev != new_node) {\n\t\t\twhile (prev->sibling)\n\t\t\t\tprev = prev->sibling;\n\t\t\tprev->sibling = new_node;\n\t\t}\n\n\t\t \n\t\tif (!pi->sib_head[tc_node->tc_num][layer])\n\t\t\tpi->sib_head[tc_node->tc_num][layer] = new_node;\n\n\t\tif (i == 0)\n\t\t\t*first_node_teid = teid;\n\t}\n\n\tdevm_kfree(ice_hw_to_dev(hw), buf);\n\treturn status;\n}\n\n \nstatic int\nice_sched_add_nodes_to_hw_layer(struct ice_port_info *pi,\n\t\t\t\tstruct ice_sched_node *tc_node,\n\t\t\t\tstruct ice_sched_node *parent, u8 layer,\n\t\t\t\tu16 num_nodes, u32 *first_node_teid,\n\t\t\t\tu16 *num_nodes_added)\n{\n\tu16 max_child_nodes;\n\n\t*num_nodes_added = 0;\n\n\tif (!num_nodes)\n\t\treturn 0;\n\n\tif (!parent || layer < pi->hw->sw_entry_point_layer)\n\t\treturn -EINVAL;\n\n\t \n\tmax_child_nodes = pi->hw->max_children[parent->tx_sched_layer];\n\n\t \n\tif ((parent->num_children + num_nodes) > max_child_nodes) {\n\t\t \n\t\tif (parent == tc_node)\n\t\t\treturn -EIO;\n\t\treturn -ENOSPC;\n\t}\n\n\treturn ice_sched_add_elems(pi, tc_node, parent, layer, num_nodes,\n\t\t\t\t   num_nodes_added, first_node_teid, NULL);\n}\n\n \nint\nice_sched_add_nodes_to_layer(struct ice_port_info *pi,\n\t\t\t     struct ice_sched_node *tc_node,\n\t\t\t     struct ice_sched_node *parent, u8 layer,\n\t\t\t     u16 num_nodes, u32 *first_node_teid,\n\t\t\t     u16 *num_nodes_added)\n{\n\tu32 *first_teid_ptr = first_node_teid;\n\tu16 new_num_nodes = num_nodes;\n\tint status = 0;\n\n\t*num_nodes_added = 0;\n\twhile (*num_nodes_added < num_nodes) {\n\t\tu16 max_child_nodes, num_added = 0;\n\t\tu32 temp;\n\n\t\tstatus = ice_sched_add_nodes_to_hw_layer(pi, tc_node, parent,\n\t\t\t\t\t\t\t layer,\tnew_num_nodes,\n\t\t\t\t\t\t\t first_teid_ptr,\n\t\t\t\t\t\t\t &num_added);\n\t\tif (!status)\n\t\t\t*num_nodes_added += num_added;\n\t\t \n\t\tif (*num_nodes_added > num_nodes) {\n\t\t\tice_debug(pi->hw, ICE_DBG_SCHED, \"added extra nodes %d %d\\n\", num_nodes,\n\t\t\t\t  *num_nodes_added);\n\t\t\tstatus = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif (!status && (*num_nodes_added == num_nodes))\n\t\t\tbreak;\n\t\t \n\t\tif (status && status != -ENOSPC)\n\t\t\tbreak;\n\t\t \n\t\tmax_child_nodes = pi->hw->max_children[parent->tx_sched_layer];\n\t\t \n\t\tif (parent->num_children < max_child_nodes) {\n\t\t\tnew_num_nodes = max_child_nodes - parent->num_children;\n\t\t} else {\n\t\t\t \n\t\t\tparent = parent->sibling;\n\t\t\t \n\t\t\tif (num_added)\n\t\t\t\tfirst_teid_ptr = &temp;\n\n\t\t\tnew_num_nodes = num_nodes - *num_nodes_added;\n\t\t}\n\t}\n\treturn status;\n}\n\n \nstatic u8 ice_sched_get_qgrp_layer(struct ice_hw *hw)\n{\n\t \n\treturn hw->num_tx_sched_layers - ICE_QGRP_LAYER_OFFSET;\n}\n\n \nu8 ice_sched_get_vsi_layer(struct ice_hw *hw)\n{\n\t \n\t \n\tif (hw->num_tx_sched_layers > ICE_VSI_LAYER_OFFSET + 1) {\n\t\tu8 layer = hw->num_tx_sched_layers - ICE_VSI_LAYER_OFFSET;\n\n\t\tif (layer > hw->sw_entry_point_layer)\n\t\t\treturn layer;\n\t}\n\treturn hw->sw_entry_point_layer;\n}\n\n \nu8 ice_sched_get_agg_layer(struct ice_hw *hw)\n{\n\t \n\t \n\tif (hw->num_tx_sched_layers > ICE_AGG_LAYER_OFFSET + 1) {\n\t\tu8 layer = hw->num_tx_sched_layers - ICE_AGG_LAYER_OFFSET;\n\n\t\tif (layer > hw->sw_entry_point_layer)\n\t\t\treturn layer;\n\t}\n\treturn hw->sw_entry_point_layer;\n}\n\n \nstatic void ice_rm_dflt_leaf_node(struct ice_port_info *pi)\n{\n\tstruct ice_sched_node *node;\n\n\tnode = pi->root;\n\twhile (node) {\n\t\tif (!node->num_children)\n\t\t\tbreak;\n\t\tnode = node->children[0];\n\t}\n\tif (node && node->info.data.elem_type == ICE_AQC_ELEM_TYPE_LEAF) {\n\t\tu32 teid = le32_to_cpu(node->info.node_teid);\n\t\tint status;\n\n\t\t \n\t\tstatus = ice_sched_remove_elems(pi->hw, node->parent, 1, &teid);\n\t\tif (!status)\n\t\t\tice_free_sched_node(pi, node);\n\t}\n}\n\n \nstatic void ice_sched_rm_dflt_nodes(struct ice_port_info *pi)\n{\n\tstruct ice_sched_node *node;\n\n\tice_rm_dflt_leaf_node(pi);\n\n\t \n\tnode = pi->root;\n\twhile (node) {\n\t\tif (node->tx_sched_layer >= pi->hw->sw_entry_point_layer &&\n\t\t    node->info.data.elem_type != ICE_AQC_ELEM_TYPE_TC &&\n\t\t    node->info.data.elem_type != ICE_AQC_ELEM_TYPE_ROOT_PORT) {\n\t\t\tice_free_sched_node(pi, node);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!node->num_children)\n\t\t\tbreak;\n\t\tnode = node->children[0];\n\t}\n}\n\n \nint ice_sched_init_port(struct ice_port_info *pi)\n{\n\tstruct ice_aqc_get_topo_elem *buf;\n\tstruct ice_hw *hw;\n\tu8 num_branches;\n\tu16 num_elems;\n\tint status;\n\tu8 i, j;\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\thw = pi->hw;\n\n\t \n\tbuf = kzalloc(ICE_AQ_MAX_BUF_LEN, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t \n\tstatus = ice_aq_get_dflt_topo(hw, pi->lport, buf, ICE_AQ_MAX_BUF_LEN,\n\t\t\t\t      &num_branches, NULL);\n\tif (status)\n\t\tgoto err_init_port;\n\n\t \n\tif (num_branches < 1 || num_branches > ICE_TXSCHED_MAX_BRANCHES) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"num_branches unexpected %d\\n\",\n\t\t\t  num_branches);\n\t\tstatus = -EINVAL;\n\t\tgoto err_init_port;\n\t}\n\n\t \n\tnum_elems = le16_to_cpu(buf[0].hdr.num_elems);\n\n\t \n\tif (num_elems < 1 || num_elems > ICE_AQC_TOPO_MAX_LEVEL_NUM) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"num_elems unexpected %d\\n\",\n\t\t\t  num_elems);\n\t\tstatus = -EINVAL;\n\t\tgoto err_init_port;\n\t}\n\n\t \n\tif (num_elems > 2 && buf[0].generic[num_elems - 1].data.elem_type ==\n\t    ICE_AQC_ELEM_TYPE_LEAF)\n\t\tpi->last_node_teid =\n\t\t\tle32_to_cpu(buf[0].generic[num_elems - 2].node_teid);\n\telse\n\t\tpi->last_node_teid =\n\t\t\tle32_to_cpu(buf[0].generic[num_elems - 1].node_teid);\n\n\t \n\tstatus = ice_sched_add_root_node(pi, &buf[0].generic[0]);\n\tif (status)\n\t\tgoto err_init_port;\n\n\t \n\tfor (i = 0; i < num_branches; i++) {\n\t\tnum_elems = le16_to_cpu(buf[i].hdr.num_elems);\n\n\t\t \n\t\tfor (j = 1; j < num_elems; j++) {\n\t\t\t \n\t\t\tif (buf[0].generic[j].data.elem_type ==\n\t\t\t    ICE_AQC_ELEM_TYPE_ENTRY_POINT)\n\t\t\t\thw->sw_entry_point_layer = j;\n\n\t\t\tstatus = ice_sched_add_node(pi, j, &buf[i].generic[j], NULL);\n\t\t\tif (status)\n\t\t\t\tgoto err_init_port;\n\t\t}\n\t}\n\n\t \n\tif (pi->root)\n\t\tice_sched_rm_dflt_nodes(pi);\n\n\t \n\tpi->port_state = ICE_SCHED_PORT_STATE_READY;\n\tmutex_init(&pi->sched_lock);\n\tfor (i = 0; i < ICE_AQC_TOPO_MAX_LEVEL_NUM; i++)\n\t\tINIT_LIST_HEAD(&pi->rl_prof_list[i]);\n\nerr_init_port:\n\tif (status && pi->root) {\n\t\tice_free_sched_node(pi, pi->root);\n\t\tpi->root = NULL;\n\t}\n\n\tkfree(buf);\n\treturn status;\n}\n\n \nint ice_sched_query_res_alloc(struct ice_hw *hw)\n{\n\tstruct ice_aqc_query_txsched_res_resp *buf;\n\t__le16 max_sibl;\n\tint status = 0;\n\tu16 i;\n\n\tif (hw->layer_info)\n\t\treturn status;\n\n\tbuf = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*buf), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tstatus = ice_aq_query_sched_res(hw, sizeof(*buf), buf, NULL);\n\tif (status)\n\t\tgoto sched_query_out;\n\n\thw->num_tx_sched_layers = le16_to_cpu(buf->sched_props.logical_levels);\n\thw->num_tx_sched_phys_layers =\n\t\tle16_to_cpu(buf->sched_props.phys_levels);\n\thw->flattened_layers = buf->sched_props.flattening_bitmap;\n\thw->max_cgds = buf->sched_props.max_pf_cgds;\n\n\t \n\tfor (i = 0; i < hw->num_tx_sched_layers - 1; i++) {\n\t\tmax_sibl = buf->layer_props[i + 1].max_sibl_grp_sz;\n\t\thw->max_children[i] = le16_to_cpu(max_sibl);\n\t}\n\n\thw->layer_info = devm_kmemdup(ice_hw_to_dev(hw), buf->layer_props,\n\t\t\t\t      (hw->num_tx_sched_layers *\n\t\t\t\t       sizeof(*hw->layer_info)),\n\t\t\t\t      GFP_KERNEL);\n\tif (!hw->layer_info) {\n\t\tstatus = -ENOMEM;\n\t\tgoto sched_query_out;\n\t}\n\nsched_query_out:\n\tdevm_kfree(ice_hw_to_dev(hw), buf);\n\treturn status;\n}\n\n \nvoid ice_sched_get_psm_clk_freq(struct ice_hw *hw)\n{\n\tu32 val, clk_src;\n\n\tval = rd32(hw, GLGEN_CLKSTAT_SRC);\n\tclk_src = (val & GLGEN_CLKSTAT_SRC_PSM_CLK_SRC_M) >>\n\t\tGLGEN_CLKSTAT_SRC_PSM_CLK_SRC_S;\n\n#define PSM_CLK_SRC_367_MHZ 0x0\n#define PSM_CLK_SRC_416_MHZ 0x1\n#define PSM_CLK_SRC_446_MHZ 0x2\n#define PSM_CLK_SRC_390_MHZ 0x3\n\n\tswitch (clk_src) {\n\tcase PSM_CLK_SRC_367_MHZ:\n\t\thw->psm_clk_freq = ICE_PSM_CLK_367MHZ_IN_HZ;\n\t\tbreak;\n\tcase PSM_CLK_SRC_416_MHZ:\n\t\thw->psm_clk_freq = ICE_PSM_CLK_416MHZ_IN_HZ;\n\t\tbreak;\n\tcase PSM_CLK_SRC_446_MHZ:\n\t\thw->psm_clk_freq = ICE_PSM_CLK_446MHZ_IN_HZ;\n\t\tbreak;\n\tcase PSM_CLK_SRC_390_MHZ:\n\t\thw->psm_clk_freq = ICE_PSM_CLK_390MHZ_IN_HZ;\n\t\tbreak;\n\tdefault:\n\t\tice_debug(hw, ICE_DBG_SCHED, \"PSM clk_src unexpected %u\\n\",\n\t\t\t  clk_src);\n\t\t \n\t\thw->psm_clk_freq = ICE_PSM_CLK_446MHZ_IN_HZ;\n\t}\n}\n\n \nstatic bool\nice_sched_find_node_in_subtree(struct ice_hw *hw, struct ice_sched_node *base,\n\t\t\t       struct ice_sched_node *node)\n{\n\tu8 i;\n\n\tfor (i = 0; i < base->num_children; i++) {\n\t\tstruct ice_sched_node *child = base->children[i];\n\n\t\tif (node == child)\n\t\t\treturn true;\n\n\t\tif (child->tx_sched_layer > node->tx_sched_layer)\n\t\t\treturn false;\n\n\t\t \n\t\tif (ice_sched_find_node_in_subtree(hw, child, node))\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic struct ice_sched_node *\nice_sched_get_free_qgrp(struct ice_port_info *pi,\n\t\t\tstruct ice_sched_node *vsi_node,\n\t\t\tstruct ice_sched_node *qgrp_node, u8 owner)\n{\n\tstruct ice_sched_node *min_qgrp;\n\tu8 min_children;\n\n\tif (!qgrp_node)\n\t\treturn qgrp_node;\n\tmin_children = qgrp_node->num_children;\n\tif (!min_children)\n\t\treturn qgrp_node;\n\tmin_qgrp = qgrp_node;\n\t \n\twhile (qgrp_node) {\n\t\t \n\t\tif (ice_sched_find_node_in_subtree(pi->hw, vsi_node, qgrp_node))\n\t\t\tif (qgrp_node->num_children < min_children &&\n\t\t\t    qgrp_node->owner == owner) {\n\t\t\t\t \n\t\t\t\tmin_qgrp = qgrp_node;\n\t\t\t\tmin_children = min_qgrp->num_children;\n\t\t\t\t \n\t\t\t\tif (!min_children)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\tqgrp_node = qgrp_node->sibling;\n\t}\n\treturn min_qgrp;\n}\n\n \nstruct ice_sched_node *\nice_sched_get_free_qparent(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t\t   u8 owner)\n{\n\tstruct ice_sched_node *vsi_node, *qgrp_node;\n\tstruct ice_vsi_ctx *vsi_ctx;\n\tu16 max_children;\n\tu8 qgrp_layer;\n\n\tqgrp_layer = ice_sched_get_qgrp_layer(pi->hw);\n\tmax_children = pi->hw->max_children[qgrp_layer];\n\n\tvsi_ctx = ice_get_vsi_ctx(pi->hw, vsi_handle);\n\tif (!vsi_ctx)\n\t\treturn NULL;\n\tvsi_node = vsi_ctx->sched.vsi_node[tc];\n\t \n\tif (!vsi_node)\n\t\treturn NULL;\n\n\t \n\tqgrp_node = ice_sched_get_first_node(pi, vsi_node, qgrp_layer);\n\twhile (qgrp_node) {\n\t\t \n\t\tif (ice_sched_find_node_in_subtree(pi->hw, vsi_node, qgrp_node))\n\t\t\tif (qgrp_node->num_children < max_children &&\n\t\t\t    qgrp_node->owner == owner)\n\t\t\t\tbreak;\n\t\tqgrp_node = qgrp_node->sibling;\n\t}\n\n\t \n\treturn ice_sched_get_free_qgrp(pi, vsi_node, qgrp_node, owner);\n}\n\n \nstatic struct ice_sched_node *\nice_sched_get_vsi_node(struct ice_port_info *pi, struct ice_sched_node *tc_node,\n\t\t       u16 vsi_handle)\n{\n\tstruct ice_sched_node *node;\n\tu8 vsi_layer;\n\n\tvsi_layer = ice_sched_get_vsi_layer(pi->hw);\n\tnode = ice_sched_get_first_node(pi, tc_node, vsi_layer);\n\n\t \n\twhile (node) {\n\t\tif (node->vsi_handle == vsi_handle)\n\t\t\treturn node;\n\t\tnode = node->sibling;\n\t}\n\n\treturn node;\n}\n\n \nstruct ice_sched_node *\nice_sched_get_agg_node(struct ice_port_info *pi, struct ice_sched_node *tc_node,\n\t\t       u32 agg_id)\n{\n\tstruct ice_sched_node *node;\n\tstruct ice_hw *hw = pi->hw;\n\tu8 agg_layer;\n\n\tif (!hw)\n\t\treturn NULL;\n\tagg_layer = ice_sched_get_agg_layer(hw);\n\tnode = ice_sched_get_first_node(pi, tc_node, agg_layer);\n\n\t \n\twhile (node) {\n\t\tif (node->agg_id == agg_id)\n\t\t\treturn node;\n\t\tnode = node->sibling;\n\t}\n\n\treturn node;\n}\n\n \nstatic void\nice_sched_calc_vsi_child_nodes(struct ice_hw *hw, u16 num_qs, u16 *num_nodes)\n{\n\tu16 num = num_qs;\n\tu8 i, qgl, vsil;\n\n\tqgl = ice_sched_get_qgrp_layer(hw);\n\tvsil = ice_sched_get_vsi_layer(hw);\n\n\t \n\tfor (i = qgl; i > vsil; i--) {\n\t\t \n\t\tnum = DIV_ROUND_UP(num, hw->max_children[i]);\n\n\t\t \n\t\tnum_nodes[i] = num ? num : 1;\n\t}\n}\n\n \nstatic int\nice_sched_add_vsi_child_nodes(struct ice_port_info *pi, u16 vsi_handle,\n\t\t\t      struct ice_sched_node *tc_node, u16 *num_nodes,\n\t\t\t      u8 owner)\n{\n\tstruct ice_sched_node *parent, *node;\n\tstruct ice_hw *hw = pi->hw;\n\tu32 first_node_teid;\n\tu16 num_added = 0;\n\tu8 i, qgl, vsil;\n\n\tqgl = ice_sched_get_qgrp_layer(hw);\n\tvsil = ice_sched_get_vsi_layer(hw);\n\tparent = ice_sched_get_vsi_node(pi, tc_node, vsi_handle);\n\tfor (i = vsil + 1; i <= qgl; i++) {\n\t\tint status;\n\n\t\tif (!parent)\n\t\t\treturn -EIO;\n\n\t\tstatus = ice_sched_add_nodes_to_layer(pi, tc_node, parent, i,\n\t\t\t\t\t\t      num_nodes[i],\n\t\t\t\t\t\t      &first_node_teid,\n\t\t\t\t\t\t      &num_added);\n\t\tif (status || num_nodes[i] != num_added)\n\t\t\treturn -EIO;\n\n\t\t \n\t\tif (num_added) {\n\t\t\tparent = ice_sched_find_node_by_teid(tc_node,\n\t\t\t\t\t\t\t     first_node_teid);\n\t\t\tnode = parent;\n\t\t\twhile (node) {\n\t\t\t\tnode->owner = owner;\n\t\t\t\tnode = node->sibling;\n\t\t\t}\n\t\t} else {\n\t\t\tparent = parent->children[0];\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic void\nice_sched_calc_vsi_support_nodes(struct ice_port_info *pi,\n\t\t\t\t struct ice_sched_node *tc_node, u16 *num_nodes)\n{\n\tstruct ice_sched_node *node;\n\tu8 vsil;\n\tint i;\n\n\tvsil = ice_sched_get_vsi_layer(pi->hw);\n\tfor (i = vsil; i >= pi->hw->sw_entry_point_layer; i--)\n\t\t \n\t\tif (!tc_node->num_children || i == vsil) {\n\t\t\tnum_nodes[i]++;\n\t\t} else {\n\t\t\t \n\t\t\tnode = ice_sched_get_first_node(pi, tc_node, (u8)i);\n\t\t\t \n\t\t\twhile (node) {\n\t\t\t\tif (node->num_children < pi->hw->max_children[i])\n\t\t\t\t\tbreak;\n\t\t\t\tnode = node->sibling;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (node)\n\t\t\t\tbreak;\n\t\t\t \n\t\t\tnum_nodes[i]++;\n\t\t}\n}\n\n \nstatic int\nice_sched_add_vsi_support_nodes(struct ice_port_info *pi, u16 vsi_handle,\n\t\t\t\tstruct ice_sched_node *tc_node, u16 *num_nodes)\n{\n\tstruct ice_sched_node *parent = tc_node;\n\tu32 first_node_teid;\n\tu16 num_added = 0;\n\tu8 i, vsil;\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\n\tvsil = ice_sched_get_vsi_layer(pi->hw);\n\tfor (i = pi->hw->sw_entry_point_layer; i <= vsil; i++) {\n\t\tint status;\n\n\t\tstatus = ice_sched_add_nodes_to_layer(pi, tc_node, parent,\n\t\t\t\t\t\t      i, num_nodes[i],\n\t\t\t\t\t\t      &first_node_teid,\n\t\t\t\t\t\t      &num_added);\n\t\tif (status || num_nodes[i] != num_added)\n\t\t\treturn -EIO;\n\n\t\t \n\t\tif (num_added)\n\t\t\tparent = ice_sched_find_node_by_teid(tc_node,\n\t\t\t\t\t\t\t     first_node_teid);\n\t\telse\n\t\t\tparent = parent->children[0];\n\n\t\tif (!parent)\n\t\t\treturn -EIO;\n\n\t\tif (i == vsil)\n\t\t\tparent->vsi_handle = vsi_handle;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_sched_add_vsi_to_topo(struct ice_port_info *pi, u16 vsi_handle, u8 tc)\n{\n\tu16 num_nodes[ICE_AQC_TOPO_MAX_LEVEL_NUM] = { 0 };\n\tstruct ice_sched_node *tc_node;\n\n\ttc_node = ice_sched_get_tc_node(pi, tc);\n\tif (!tc_node)\n\t\treturn -EINVAL;\n\n\t \n\tice_sched_calc_vsi_support_nodes(pi, tc_node, num_nodes);\n\n\t \n\treturn ice_sched_add_vsi_support_nodes(pi, vsi_handle, tc_node,\n\t\t\t\t\t       num_nodes);\n}\n\n \nstatic int\nice_sched_update_vsi_child_nodes(struct ice_port_info *pi, u16 vsi_handle,\n\t\t\t\t u8 tc, u16 new_numqs, u8 owner)\n{\n\tu16 new_num_nodes[ICE_AQC_TOPO_MAX_LEVEL_NUM] = { 0 };\n\tstruct ice_sched_node *vsi_node;\n\tstruct ice_sched_node *tc_node;\n\tstruct ice_vsi_ctx *vsi_ctx;\n\tstruct ice_hw *hw = pi->hw;\n\tu16 prev_numqs;\n\tint status = 0;\n\n\ttc_node = ice_sched_get_tc_node(pi, tc);\n\tif (!tc_node)\n\t\treturn -EIO;\n\n\tvsi_node = ice_sched_get_vsi_node(pi, tc_node, vsi_handle);\n\tif (!vsi_node)\n\t\treturn -EIO;\n\n\tvsi_ctx = ice_get_vsi_ctx(hw, vsi_handle);\n\tif (!vsi_ctx)\n\t\treturn -EINVAL;\n\n\tif (owner == ICE_SCHED_NODE_OWNER_LAN)\n\t\tprev_numqs = vsi_ctx->sched.max_lanq[tc];\n\telse\n\t\tprev_numqs = vsi_ctx->sched.max_rdmaq[tc];\n\t \n\tif (new_numqs <= prev_numqs)\n\t\treturn status;\n\tif (owner == ICE_SCHED_NODE_OWNER_LAN) {\n\t\tstatus = ice_alloc_lan_q_ctx(hw, vsi_handle, tc, new_numqs);\n\t\tif (status)\n\t\t\treturn status;\n\t} else {\n\t\tstatus = ice_alloc_rdma_q_ctx(hw, vsi_handle, tc, new_numqs);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\tif (new_numqs)\n\t\tice_sched_calc_vsi_child_nodes(hw, new_numqs, new_num_nodes);\n\t \n\tstatus = ice_sched_add_vsi_child_nodes(pi, vsi_handle, tc_node,\n\t\t\t\t\t       new_num_nodes, owner);\n\tif (status)\n\t\treturn status;\n\tif (owner == ICE_SCHED_NODE_OWNER_LAN)\n\t\tvsi_ctx->sched.max_lanq[tc] = new_numqs;\n\telse\n\t\tvsi_ctx->sched.max_rdmaq[tc] = new_numqs;\n\n\treturn 0;\n}\n\n \nint\nice_sched_cfg_vsi(struct ice_port_info *pi, u16 vsi_handle, u8 tc, u16 maxqs,\n\t\t  u8 owner, bool enable)\n{\n\tstruct ice_sched_node *vsi_node, *tc_node;\n\tstruct ice_vsi_ctx *vsi_ctx;\n\tstruct ice_hw *hw = pi->hw;\n\tint status = 0;\n\n\tice_debug(pi->hw, ICE_DBG_SCHED, \"add/config VSI %d\\n\", vsi_handle);\n\ttc_node = ice_sched_get_tc_node(pi, tc);\n\tif (!tc_node)\n\t\treturn -EINVAL;\n\tvsi_ctx = ice_get_vsi_ctx(hw, vsi_handle);\n\tif (!vsi_ctx)\n\t\treturn -EINVAL;\n\tvsi_node = ice_sched_get_vsi_node(pi, tc_node, vsi_handle);\n\n\t \n\tif (!enable) {\n\t\tif (vsi_node && vsi_node->in_use) {\n\t\t\tu32 teid = le32_to_cpu(vsi_node->info.node_teid);\n\n\t\t\tstatus = ice_sched_suspend_resume_elems(hw, 1, &teid,\n\t\t\t\t\t\t\t\ttrue);\n\t\t\tif (!status)\n\t\t\t\tvsi_node->in_use = false;\n\t\t}\n\t\treturn status;\n\t}\n\n\t \n\tif (!vsi_node) {\n\t\tstatus = ice_sched_add_vsi_to_topo(pi, vsi_handle, tc);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tvsi_node = ice_sched_get_vsi_node(pi, tc_node, vsi_handle);\n\t\tif (!vsi_node)\n\t\t\treturn -EIO;\n\n\t\tvsi_ctx->sched.vsi_node[tc] = vsi_node;\n\t\tvsi_node->in_use = true;\n\t\t \n\t\tvsi_ctx->sched.max_lanq[tc] = 0;\n\t\tvsi_ctx->sched.max_rdmaq[tc] = 0;\n\t}\n\n\t \n\tstatus = ice_sched_update_vsi_child_nodes(pi, vsi_handle, tc, maxqs,\n\t\t\t\t\t\t  owner);\n\tif (status)\n\t\treturn status;\n\n\t \n\tif (!vsi_node->in_use) {\n\t\tu32 teid = le32_to_cpu(vsi_node->info.node_teid);\n\n\t\tstatus = ice_sched_suspend_resume_elems(hw, 1, &teid, false);\n\t\tif (!status)\n\t\t\tvsi_node->in_use = true;\n\t}\n\n\treturn status;\n}\n\n \nstatic void ice_sched_rm_agg_vsi_info(struct ice_port_info *pi, u16 vsi_handle)\n{\n\tstruct ice_sched_agg_info *agg_info;\n\tstruct ice_sched_agg_info *atmp;\n\n\tlist_for_each_entry_safe(agg_info, atmp, &pi->hw->agg_list,\n\t\t\t\t list_entry) {\n\t\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\t\tstruct ice_sched_agg_vsi_info *vtmp;\n\n\t\tlist_for_each_entry_safe(agg_vsi_info, vtmp,\n\t\t\t\t\t &agg_info->agg_vsi_list, list_entry)\n\t\t\tif (agg_vsi_info->vsi_handle == vsi_handle) {\n\t\t\t\tlist_del(&agg_vsi_info->list_entry);\n\t\t\t\tdevm_kfree(ice_hw_to_dev(pi->hw),\n\t\t\t\t\t   agg_vsi_info);\n\t\t\t\treturn;\n\t\t\t}\n\t}\n}\n\n \nstatic bool ice_sched_is_leaf_node_present(struct ice_sched_node *node)\n{\n\tu8 i;\n\n\tfor (i = 0; i < node->num_children; i++)\n\t\tif (ice_sched_is_leaf_node_present(node->children[i]))\n\t\t\treturn true;\n\t \n\treturn (node->info.data.elem_type == ICE_AQC_ELEM_TYPE_LEAF);\n}\n\n \nstatic int\nice_sched_rm_vsi_cfg(struct ice_port_info *pi, u16 vsi_handle, u8 owner)\n{\n\tstruct ice_vsi_ctx *vsi_ctx;\n\tint status = -EINVAL;\n\tu8 i;\n\n\tice_debug(pi->hw, ICE_DBG_SCHED, \"removing VSI %d\\n\", vsi_handle);\n\tif (!ice_is_vsi_valid(pi->hw, vsi_handle))\n\t\treturn status;\n\tmutex_lock(&pi->sched_lock);\n\tvsi_ctx = ice_get_vsi_ctx(pi->hw, vsi_handle);\n\tif (!vsi_ctx)\n\t\tgoto exit_sched_rm_vsi_cfg;\n\n\tice_for_each_traffic_class(i) {\n\t\tstruct ice_sched_node *vsi_node, *tc_node;\n\t\tu8 j = 0;\n\n\t\ttc_node = ice_sched_get_tc_node(pi, i);\n\t\tif (!tc_node)\n\t\t\tcontinue;\n\n\t\tvsi_node = ice_sched_get_vsi_node(pi, tc_node, vsi_handle);\n\t\tif (!vsi_node)\n\t\t\tcontinue;\n\n\t\tif (ice_sched_is_leaf_node_present(vsi_node)) {\n\t\t\tice_debug(pi->hw, ICE_DBG_SCHED, \"VSI has leaf nodes in TC %d\\n\", i);\n\t\t\tstatus = -EBUSY;\n\t\t\tgoto exit_sched_rm_vsi_cfg;\n\t\t}\n\t\twhile (j < vsi_node->num_children) {\n\t\t\tif (vsi_node->children[j]->owner == owner) {\n\t\t\t\tice_free_sched_node(pi, vsi_node->children[j]);\n\n\t\t\t\t \n\t\t\t\tj = 0;\n\t\t\t} else {\n\t\t\t\tj++;\n\t\t\t}\n\t\t}\n\t\t \n\t\tif (!vsi_node->num_children) {\n\t\t\tice_free_sched_node(pi, vsi_node);\n\t\t\tvsi_ctx->sched.vsi_node[i] = NULL;\n\n\t\t\t \n\t\t\tice_sched_rm_agg_vsi_info(pi, vsi_handle);\n\t\t}\n\t\tif (owner == ICE_SCHED_NODE_OWNER_LAN)\n\t\t\tvsi_ctx->sched.max_lanq[i] = 0;\n\t\telse\n\t\t\tvsi_ctx->sched.max_rdmaq[i] = 0;\n\t}\n\tstatus = 0;\n\nexit_sched_rm_vsi_cfg:\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nint ice_rm_vsi_lan_cfg(struct ice_port_info *pi, u16 vsi_handle)\n{\n\treturn ice_sched_rm_vsi_cfg(pi, vsi_handle, ICE_SCHED_NODE_OWNER_LAN);\n}\n\n \nint ice_rm_vsi_rdma_cfg(struct ice_port_info *pi, u16 vsi_handle)\n{\n\treturn ice_sched_rm_vsi_cfg(pi, vsi_handle, ICE_SCHED_NODE_OWNER_RDMA);\n}\n\n \nstatic struct ice_sched_agg_info *\nice_get_agg_info(struct ice_hw *hw, u32 agg_id)\n{\n\tstruct ice_sched_agg_info *agg_info;\n\n\tlist_for_each_entry(agg_info, &hw->agg_list, list_entry)\n\t\tif (agg_info->agg_id == agg_id)\n\t\t\treturn agg_info;\n\n\treturn NULL;\n}\n\n \nstruct ice_sched_node *\nice_sched_get_free_vsi_parent(struct ice_hw *hw, struct ice_sched_node *node,\n\t\t\t      u16 *num_nodes)\n{\n\tu8 l = node->tx_sched_layer;\n\tu8 vsil, i;\n\n\tvsil = ice_sched_get_vsi_layer(hw);\n\n\t \n\tif (l == vsil - 1)\n\t\treturn (node->num_children < hw->max_children[l]) ? node : NULL;\n\n\t \n\tif (node->num_children < hw->max_children[l])\n\t\tnum_nodes[l] = 0;\n\t \n\n\tfor (i = 0; i < node->num_children; i++) {\n\t\tstruct ice_sched_node *parent;\n\n\t\tparent = ice_sched_get_free_vsi_parent(hw, node->children[i],\n\t\t\t\t\t\t       num_nodes);\n\t\tif (parent)\n\t\t\treturn parent;\n\t}\n\n\treturn NULL;\n}\n\n \nvoid\nice_sched_update_parent(struct ice_sched_node *new_parent,\n\t\t\tstruct ice_sched_node *node)\n{\n\tstruct ice_sched_node *old_parent;\n\tu8 i, j;\n\n\told_parent = node->parent;\n\n\t \n\tfor (i = 0; i < old_parent->num_children; i++)\n\t\tif (old_parent->children[i] == node) {\n\t\t\tfor (j = i + 1; j < old_parent->num_children; j++)\n\t\t\t\told_parent->children[j - 1] =\n\t\t\t\t\told_parent->children[j];\n\t\t\told_parent->num_children--;\n\t\t\tbreak;\n\t\t}\n\n\t \n\tnew_parent->children[new_parent->num_children++] = node;\n\tnode->parent = new_parent;\n\tnode->info.parent_teid = new_parent->info.node_teid;\n}\n\n \nint\nice_sched_move_nodes(struct ice_port_info *pi, struct ice_sched_node *parent,\n\t\t     u16 num_items, u32 *list)\n{\n\tstruct ice_aqc_move_elem *buf;\n\tstruct ice_sched_node *node;\n\tu16 i, grps_movd = 0;\n\tstruct ice_hw *hw;\n\tint status = 0;\n\tu16 buf_len;\n\n\thw = pi->hw;\n\n\tif (!parent || !num_items)\n\t\treturn -EINVAL;\n\n\t \n\tif (parent->num_children + num_items >\n\t    hw->max_children[parent->tx_sched_layer])\n\t\treturn -ENOSPC;\n\n\tbuf_len = struct_size(buf, teid, 1);\n\tbuf = kzalloc(buf_len, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_items; i++) {\n\t\tnode = ice_sched_find_node_by_teid(pi->root, list[i]);\n\t\tif (!node) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto move_err_exit;\n\t\t}\n\n\t\tbuf->hdr.src_parent_teid = node->info.parent_teid;\n\t\tbuf->hdr.dest_parent_teid = parent->info.node_teid;\n\t\tbuf->teid[0] = node->info.node_teid;\n\t\tbuf->hdr.num_elems = cpu_to_le16(1);\n\t\tstatus = ice_aq_move_sched_elems(hw, 1, buf, buf_len,\n\t\t\t\t\t\t &grps_movd, NULL);\n\t\tif (status && grps_movd != 1) {\n\t\t\tstatus = -EIO;\n\t\t\tgoto move_err_exit;\n\t\t}\n\n\t\t \n\t\tice_sched_update_parent(parent, node);\n\t}\n\nmove_err_exit:\n\tkfree(buf);\n\treturn status;\n}\n\n \nstatic int\nice_sched_move_vsi_to_agg(struct ice_port_info *pi, u16 vsi_handle, u32 agg_id,\n\t\t\t  u8 tc)\n{\n\tstruct ice_sched_node *vsi_node, *agg_node, *tc_node, *parent;\n\tu16 num_nodes[ICE_AQC_TOPO_MAX_LEVEL_NUM] = { 0 };\n\tu32 first_node_teid, vsi_teid;\n\tu16 num_nodes_added;\n\tu8 aggl, vsil, i;\n\tint status;\n\n\ttc_node = ice_sched_get_tc_node(pi, tc);\n\tif (!tc_node)\n\t\treturn -EIO;\n\n\tagg_node = ice_sched_get_agg_node(pi, tc_node, agg_id);\n\tif (!agg_node)\n\t\treturn -ENOENT;\n\n\tvsi_node = ice_sched_get_vsi_node(pi, tc_node, vsi_handle);\n\tif (!vsi_node)\n\t\treturn -ENOENT;\n\n\t \n\tif (ice_sched_find_node_in_subtree(pi->hw, agg_node, vsi_node))\n\t\treturn 0;\n\n\taggl = ice_sched_get_agg_layer(pi->hw);\n\tvsil = ice_sched_get_vsi_layer(pi->hw);\n\n\t \n\tfor (i = aggl + 1; i < vsil; i++)\n\t\tnum_nodes[i] = 1;\n\n\t \n\tfor (i = 0; i < agg_node->num_children; i++) {\n\t\tparent = ice_sched_get_free_vsi_parent(pi->hw,\n\t\t\t\t\t\t       agg_node->children[i],\n\t\t\t\t\t\t       num_nodes);\n\t\tif (parent)\n\t\t\tgoto move_nodes;\n\t}\n\n\t \n\tparent = agg_node;\n\tfor (i = aggl + 1; i < vsil; i++) {\n\t\tstatus = ice_sched_add_nodes_to_layer(pi, tc_node, parent, i,\n\t\t\t\t\t\t      num_nodes[i],\n\t\t\t\t\t\t      &first_node_teid,\n\t\t\t\t\t\t      &num_nodes_added);\n\t\tif (status || num_nodes[i] != num_nodes_added)\n\t\t\treturn -EIO;\n\n\t\t \n\t\tif (num_nodes_added)\n\t\t\tparent = ice_sched_find_node_by_teid(tc_node,\n\t\t\t\t\t\t\t     first_node_teid);\n\t\telse\n\t\t\tparent = parent->children[0];\n\n\t\tif (!parent)\n\t\t\treturn -EIO;\n\t}\n\nmove_nodes:\n\tvsi_teid = le32_to_cpu(vsi_node->info.node_teid);\n\treturn ice_sched_move_nodes(pi, parent, 1, &vsi_teid);\n}\n\n \nstatic int\nice_move_all_vsi_to_dflt_agg(struct ice_port_info *pi,\n\t\t\t     struct ice_sched_agg_info *agg_info, u8 tc,\n\t\t\t     bool rm_vsi_info)\n{\n\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\tstruct ice_sched_agg_vsi_info *tmp;\n\tint status = 0;\n\n\tlist_for_each_entry_safe(agg_vsi_info, tmp, &agg_info->agg_vsi_list,\n\t\t\t\t list_entry) {\n\t\tu16 vsi_handle = agg_vsi_info->vsi_handle;\n\n\t\t \n\t\tif (!ice_is_tc_ena(agg_vsi_info->tc_bitmap[0], tc))\n\t\t\tcontinue;\n\n\t\tstatus = ice_sched_move_vsi_to_agg(pi, vsi_handle,\n\t\t\t\t\t\t   ICE_DFLT_AGG_ID, tc);\n\t\tif (status)\n\t\t\tbreak;\n\n\t\tclear_bit(tc, agg_vsi_info->tc_bitmap);\n\t\tif (rm_vsi_info && !agg_vsi_info->tc_bitmap[0]) {\n\t\t\tlist_del(&agg_vsi_info->list_entry);\n\t\t\tdevm_kfree(ice_hw_to_dev(pi->hw), agg_vsi_info);\n\t\t}\n\t}\n\n\treturn status;\n}\n\n \nstatic bool\nice_sched_is_agg_inuse(struct ice_port_info *pi, struct ice_sched_node *node)\n{\n\tu8 vsil, i;\n\n\tvsil = ice_sched_get_vsi_layer(pi->hw);\n\tif (node->tx_sched_layer < vsil - 1) {\n\t\tfor (i = 0; i < node->num_children; i++)\n\t\t\tif (ice_sched_is_agg_inuse(pi, node->children[i]))\n\t\t\t\treturn true;\n\t\treturn false;\n\t} else {\n\t\treturn node->num_children ? true : false;\n\t}\n}\n\n \nstatic int\nice_sched_rm_agg_cfg(struct ice_port_info *pi, u32 agg_id, u8 tc)\n{\n\tstruct ice_sched_node *tc_node, *agg_node;\n\tstruct ice_hw *hw = pi->hw;\n\n\ttc_node = ice_sched_get_tc_node(pi, tc);\n\tif (!tc_node)\n\t\treturn -EIO;\n\n\tagg_node = ice_sched_get_agg_node(pi, tc_node, agg_id);\n\tif (!agg_node)\n\t\treturn -ENOENT;\n\n\t \n\tif (ice_sched_is_agg_inuse(pi, agg_node))\n\t\treturn -EBUSY;\n\n\t \n\twhile (agg_node->tx_sched_layer > hw->sw_entry_point_layer) {\n\t\tstruct ice_sched_node *parent = agg_node->parent;\n\n\t\tif (!parent)\n\t\t\treturn -EIO;\n\n\t\tif (parent->num_children > 1)\n\t\t\tbreak;\n\n\t\tagg_node = parent;\n\t}\n\n\tice_free_sched_node(pi, agg_node);\n\treturn 0;\n}\n\n \nstatic int\nice_rm_agg_cfg_tc(struct ice_port_info *pi, struct ice_sched_agg_info *agg_info,\n\t\t  u8 tc, bool rm_vsi_info)\n{\n\tint status = 0;\n\n\t \n\tif (!ice_is_tc_ena(agg_info->tc_bitmap[0], tc))\n\t\tgoto exit_rm_agg_cfg_tc;\n\n\tstatus = ice_move_all_vsi_to_dflt_agg(pi, agg_info, tc, rm_vsi_info);\n\tif (status)\n\t\tgoto exit_rm_agg_cfg_tc;\n\n\t \n\tstatus = ice_sched_rm_agg_cfg(pi, agg_info->agg_id, tc);\n\tif (status)\n\t\tgoto exit_rm_agg_cfg_tc;\n\n\tclear_bit(tc, agg_info->tc_bitmap);\nexit_rm_agg_cfg_tc:\n\treturn status;\n}\n\n \nstatic int\nice_save_agg_tc_bitmap(struct ice_port_info *pi, u32 agg_id,\n\t\t       unsigned long *tc_bitmap)\n{\n\tstruct ice_sched_agg_info *agg_info;\n\n\tagg_info = ice_get_agg_info(pi->hw, agg_id);\n\tif (!agg_info)\n\t\treturn -EINVAL;\n\tbitmap_copy(agg_info->replay_tc_bitmap, tc_bitmap,\n\t\t    ICE_MAX_TRAFFIC_CLASS);\n\treturn 0;\n}\n\n \nstatic int\nice_sched_add_agg_cfg(struct ice_port_info *pi, u32 agg_id, u8 tc)\n{\n\tstruct ice_sched_node *parent, *agg_node, *tc_node;\n\tu16 num_nodes[ICE_AQC_TOPO_MAX_LEVEL_NUM] = { 0 };\n\tstruct ice_hw *hw = pi->hw;\n\tu32 first_node_teid;\n\tu16 num_nodes_added;\n\tint status = 0;\n\tu8 i, aggl;\n\n\ttc_node = ice_sched_get_tc_node(pi, tc);\n\tif (!tc_node)\n\t\treturn -EIO;\n\n\tagg_node = ice_sched_get_agg_node(pi, tc_node, agg_id);\n\t \n\tif (agg_node)\n\t\treturn status;\n\n\taggl = ice_sched_get_agg_layer(hw);\n\n\t \n\tnum_nodes[aggl] = 1;\n\n\t \n\tfor (i = hw->sw_entry_point_layer; i < aggl; i++) {\n\t\tparent = ice_sched_get_first_node(pi, tc_node, i);\n\n\t\t \n\t\twhile (parent) {\n\t\t\tif (parent->num_children < hw->max_children[i])\n\t\t\t\tbreak;\n\t\t\tparent = parent->sibling;\n\t\t}\n\n\t\t \n\t\tif (!parent)\n\t\t\tnum_nodes[i]++;\n\t}\n\n\t \n\tparent = tc_node;\n\tfor (i = hw->sw_entry_point_layer; i <= aggl; i++) {\n\t\tif (!parent)\n\t\t\treturn -EIO;\n\n\t\tstatus = ice_sched_add_nodes_to_layer(pi, tc_node, parent, i,\n\t\t\t\t\t\t      num_nodes[i],\n\t\t\t\t\t\t      &first_node_teid,\n\t\t\t\t\t\t      &num_nodes_added);\n\t\tif (status || num_nodes[i] != num_nodes_added)\n\t\t\treturn -EIO;\n\n\t\t \n\t\tif (num_nodes_added) {\n\t\t\tparent = ice_sched_find_node_by_teid(tc_node,\n\t\t\t\t\t\t\t     first_node_teid);\n\t\t\t \n\t\t\tif (parent && i == aggl)\n\t\t\t\tparent->agg_id = agg_id;\n\t\t} else {\n\t\t\tparent = parent->children[0];\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_sched_cfg_agg(struct ice_port_info *pi, u32 agg_id,\n\t\t  enum ice_agg_type agg_type, unsigned long *tc_bitmap)\n{\n\tstruct ice_sched_agg_info *agg_info;\n\tstruct ice_hw *hw = pi->hw;\n\tint status = 0;\n\tu8 tc;\n\n\tagg_info = ice_get_agg_info(hw, agg_id);\n\tif (!agg_info) {\n\t\t \n\t\tagg_info = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*agg_info),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!agg_info)\n\t\t\treturn -ENOMEM;\n\n\t\tagg_info->agg_id = agg_id;\n\t\tagg_info->agg_type = agg_type;\n\t\tagg_info->tc_bitmap[0] = 0;\n\n\t\t \n\t\tINIT_LIST_HEAD(&agg_info->agg_vsi_list);\n\n\t\t \n\t\tlist_add(&agg_info->list_entry, &hw->agg_list);\n\t}\n\t \n\tice_for_each_traffic_class(tc) {\n\t\tif (!ice_is_tc_ena(*tc_bitmap, tc)) {\n\t\t\t \n\t\t\tstatus = ice_rm_agg_cfg_tc(pi, agg_info, tc, false);\n\t\t\tif (status)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (ice_is_tc_ena(agg_info->tc_bitmap[0], tc))\n\t\t\tcontinue;\n\n\t\t \n\t\tstatus = ice_sched_add_agg_cfg(pi, agg_id, tc);\n\t\tif (status)\n\t\t\tbreak;\n\n\t\t \n\t\tset_bit(tc, agg_info->tc_bitmap);\n\t}\n\n\treturn status;\n}\n\n \nint\nice_cfg_agg(struct ice_port_info *pi, u32 agg_id, enum ice_agg_type agg_type,\n\t    u8 tc_bitmap)\n{\n\tunsigned long bitmap = tc_bitmap;\n\tint status;\n\n\tmutex_lock(&pi->sched_lock);\n\tstatus = ice_sched_cfg_agg(pi, agg_id, agg_type, &bitmap);\n\tif (!status)\n\t\tstatus = ice_save_agg_tc_bitmap(pi, agg_id, &bitmap);\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nstatic struct ice_sched_agg_vsi_info *\nice_get_agg_vsi_info(struct ice_sched_agg_info *agg_info, u16 vsi_handle)\n{\n\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\n\tlist_for_each_entry(agg_vsi_info, &agg_info->agg_vsi_list, list_entry)\n\t\tif (agg_vsi_info->vsi_handle == vsi_handle)\n\t\t\treturn agg_vsi_info;\n\n\treturn NULL;\n}\n\n \nstatic struct ice_sched_agg_info *\nice_get_vsi_agg_info(struct ice_hw *hw, u16 vsi_handle)\n{\n\tstruct ice_sched_agg_info *agg_info;\n\n\tlist_for_each_entry(agg_info, &hw->agg_list, list_entry) {\n\t\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\n\t\tagg_vsi_info = ice_get_agg_vsi_info(agg_info, vsi_handle);\n\t\tif (agg_vsi_info)\n\t\t\treturn agg_info;\n\t}\n\treturn NULL;\n}\n\n \nstatic int\nice_save_agg_vsi_tc_bitmap(struct ice_port_info *pi, u32 agg_id, u16 vsi_handle,\n\t\t\t   unsigned long *tc_bitmap)\n{\n\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\tstruct ice_sched_agg_info *agg_info;\n\n\tagg_info = ice_get_agg_info(pi->hw, agg_id);\n\tif (!agg_info)\n\t\treturn -EINVAL;\n\t \n\tagg_vsi_info = ice_get_agg_vsi_info(agg_info, vsi_handle);\n\tif (!agg_vsi_info)\n\t\treturn -EINVAL;\n\tbitmap_copy(agg_vsi_info->replay_tc_bitmap, tc_bitmap,\n\t\t    ICE_MAX_TRAFFIC_CLASS);\n\treturn 0;\n}\n\n \nstatic int\nice_sched_assoc_vsi_to_agg(struct ice_port_info *pi, u32 agg_id,\n\t\t\t   u16 vsi_handle, unsigned long *tc_bitmap)\n{\n\tstruct ice_sched_agg_vsi_info *agg_vsi_info, *iter, *old_agg_vsi_info = NULL;\n\tstruct ice_sched_agg_info *agg_info, *old_agg_info;\n\tstruct ice_hw *hw = pi->hw;\n\tint status = 0;\n\tu8 tc;\n\n\tif (!ice_is_vsi_valid(pi->hw, vsi_handle))\n\t\treturn -EINVAL;\n\tagg_info = ice_get_agg_info(hw, agg_id);\n\tif (!agg_info)\n\t\treturn -EINVAL;\n\t \n\told_agg_info = ice_get_vsi_agg_info(hw, vsi_handle);\n\tif (old_agg_info && old_agg_info != agg_info) {\n\t\tstruct ice_sched_agg_vsi_info *vtmp;\n\n\t\tlist_for_each_entry_safe(iter, vtmp,\n\t\t\t\t\t &old_agg_info->agg_vsi_list,\n\t\t\t\t\t list_entry)\n\t\t\tif (iter->vsi_handle == vsi_handle) {\n\t\t\t\told_agg_vsi_info = iter;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t \n\tagg_vsi_info = ice_get_agg_vsi_info(agg_info, vsi_handle);\n\tif (!agg_vsi_info) {\n\t\t \n\t\tagg_vsi_info = devm_kzalloc(ice_hw_to_dev(hw),\n\t\t\t\t\t    sizeof(*agg_vsi_info), GFP_KERNEL);\n\t\tif (!agg_vsi_info)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tagg_vsi_info->vsi_handle = vsi_handle;\n\t\tlist_add(&agg_vsi_info->list_entry, &agg_info->agg_vsi_list);\n\t}\n\t \n\tice_for_each_traffic_class(tc) {\n\t\tif (!ice_is_tc_ena(*tc_bitmap, tc))\n\t\t\tcontinue;\n\n\t\t \n\t\tstatus = ice_sched_move_vsi_to_agg(pi, vsi_handle, agg_id, tc);\n\t\tif (status)\n\t\t\tbreak;\n\n\t\tset_bit(tc, agg_vsi_info->tc_bitmap);\n\t\tif (old_agg_vsi_info)\n\t\t\tclear_bit(tc, old_agg_vsi_info->tc_bitmap);\n\t}\n\tif (old_agg_vsi_info && !old_agg_vsi_info->tc_bitmap[0]) {\n\t\tlist_del(&old_agg_vsi_info->list_entry);\n\t\tdevm_kfree(ice_hw_to_dev(pi->hw), old_agg_vsi_info);\n\t}\n\treturn status;\n}\n\n \nstatic void ice_sched_rm_unused_rl_prof(struct ice_port_info *pi)\n{\n\tu16 ln;\n\n\tfor (ln = 0; ln < pi->hw->num_tx_sched_layers; ln++) {\n\t\tstruct ice_aqc_rl_profile_info *rl_prof_elem;\n\t\tstruct ice_aqc_rl_profile_info *rl_prof_tmp;\n\n\t\tlist_for_each_entry_safe(rl_prof_elem, rl_prof_tmp,\n\t\t\t\t\t &pi->rl_prof_list[ln], list_entry) {\n\t\t\tif (!ice_sched_del_rl_profile(pi->hw, rl_prof_elem))\n\t\t\t\tice_debug(pi->hw, ICE_DBG_SCHED, \"Removed rl profile\\n\");\n\t\t}\n\t}\n}\n\n \nstatic int\nice_sched_update_elem(struct ice_hw *hw, struct ice_sched_node *node,\n\t\t      struct ice_aqc_txsched_elem_data *info)\n{\n\tstruct ice_aqc_txsched_elem_data buf;\n\tu16 elem_cfgd = 0;\n\tu16 num_elems = 1;\n\tint status;\n\n\tbuf = *info;\n\t \n\tbuf.parent_teid = 0;\n\t \n\tbuf.data.elem_type = 0;\n\t \n\tbuf.data.flags = 0;\n\n\t \n\t \n\tstatus = ice_aq_cfg_sched_elems(hw, num_elems, &buf, sizeof(buf),\n\t\t\t\t\t&elem_cfgd, NULL);\n\tif (status || elem_cfgd != num_elems) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"Config sched elem error\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\t \n\t \n\tnode->info.data = info->data;\n\treturn status;\n}\n\n \nstatic int\nice_sched_cfg_node_bw_alloc(struct ice_hw *hw, struct ice_sched_node *node,\n\t\t\t    enum ice_rl_type rl_type, u16 bw_alloc)\n{\n\tstruct ice_aqc_txsched_elem_data buf;\n\tstruct ice_aqc_txsched_elem *data;\n\n\tbuf = node->info;\n\tdata = &buf.data;\n\tif (rl_type == ICE_MIN_BW) {\n\t\tdata->valid_sections |= ICE_AQC_ELEM_VALID_CIR;\n\t\tdata->cir_bw.bw_alloc = cpu_to_le16(bw_alloc);\n\t} else if (rl_type == ICE_MAX_BW) {\n\t\tdata->valid_sections |= ICE_AQC_ELEM_VALID_EIR;\n\t\tdata->eir_bw.bw_alloc = cpu_to_le16(bw_alloc);\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\t \n\treturn ice_sched_update_elem(hw, node, &buf);\n}\n\n \nint\nice_move_vsi_to_agg(struct ice_port_info *pi, u32 agg_id, u16 vsi_handle,\n\t\t    u8 tc_bitmap)\n{\n\tunsigned long bitmap = tc_bitmap;\n\tint status;\n\n\tmutex_lock(&pi->sched_lock);\n\tstatus = ice_sched_assoc_vsi_to_agg(pi, agg_id, vsi_handle,\n\t\t\t\t\t    (unsigned long *)&bitmap);\n\tif (!status)\n\t\tstatus = ice_save_agg_vsi_tc_bitmap(pi, agg_id, vsi_handle,\n\t\t\t\t\t\t    (unsigned long *)&bitmap);\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nstatic void ice_set_clear_cir_bw(struct ice_bw_type_info *bw_t_info, u32 bw)\n{\n\tif (bw == ICE_SCHED_DFLT_BW) {\n\t\tclear_bit(ICE_BW_TYPE_CIR, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->cir_bw.bw = 0;\n\t} else {\n\t\t \n\t\tset_bit(ICE_BW_TYPE_CIR, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->cir_bw.bw = bw;\n\t}\n}\n\n \nstatic void ice_set_clear_eir_bw(struct ice_bw_type_info *bw_t_info, u32 bw)\n{\n\tif (bw == ICE_SCHED_DFLT_BW) {\n\t\tclear_bit(ICE_BW_TYPE_EIR, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->eir_bw.bw = 0;\n\t} else {\n\t\t \n\t\tclear_bit(ICE_BW_TYPE_SHARED, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->shared_bw = 0;\n\t\t \n\t\tset_bit(ICE_BW_TYPE_EIR, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->eir_bw.bw = bw;\n\t}\n}\n\n \nstatic void ice_set_clear_shared_bw(struct ice_bw_type_info *bw_t_info, u32 bw)\n{\n\tif (bw == ICE_SCHED_DFLT_BW) {\n\t\tclear_bit(ICE_BW_TYPE_SHARED, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->shared_bw = 0;\n\t} else {\n\t\t \n\t\tclear_bit(ICE_BW_TYPE_EIR, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->eir_bw.bw = 0;\n\t\t \n\t\tset_bit(ICE_BW_TYPE_SHARED, bw_t_info->bw_t_bitmap);\n\t\tbw_t_info->shared_bw = bw;\n\t}\n}\n\n \nstatic int\nice_sched_save_vsi_bw(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t      enum ice_rl_type rl_type, u32 bw)\n{\n\tstruct ice_vsi_ctx *vsi_ctx;\n\n\tif (!ice_is_vsi_valid(pi->hw, vsi_handle))\n\t\treturn -EINVAL;\n\tvsi_ctx = ice_get_vsi_ctx(pi->hw, vsi_handle);\n\tif (!vsi_ctx)\n\t\treturn -EINVAL;\n\tswitch (rl_type) {\n\tcase ICE_MIN_BW:\n\t\tice_set_clear_cir_bw(&vsi_ctx->sched.bw_t_info[tc], bw);\n\t\tbreak;\n\tcase ICE_MAX_BW:\n\t\tice_set_clear_eir_bw(&vsi_ctx->sched.bw_t_info[tc], bw);\n\t\tbreak;\n\tcase ICE_SHARED_BW:\n\t\tice_set_clear_shared_bw(&vsi_ctx->sched.bw_t_info[tc], bw);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n \nstatic u16 ice_sched_calc_wakeup(struct ice_hw *hw, s32 bw)\n{\n\ts64 bytes_per_sec, wakeup_int, wakeup_a, wakeup_b, wakeup_f;\n\ts32 wakeup_f_int;\n\tu16 wakeup = 0;\n\n\t \n\tbytes_per_sec = div64_long(((s64)bw * 1000), BITS_PER_BYTE);\n\twakeup_int = div64_long(hw->psm_clk_freq, bytes_per_sec);\n\tif (wakeup_int > 63) {\n\t\twakeup = (u16)((1 << 15) | wakeup_int);\n\t} else {\n\t\t \n\t\twakeup_b = (s64)ICE_RL_PROF_MULTIPLIER * wakeup_int;\n\t\twakeup_a = div64_long((s64)ICE_RL_PROF_MULTIPLIER *\n\t\t\t\t\t   hw->psm_clk_freq, bytes_per_sec);\n\n\t\t \n\t\twakeup_f = wakeup_a - wakeup_b;\n\n\t\t \n\t\tif (wakeup_f > div64_long(ICE_RL_PROF_MULTIPLIER, 2))\n\t\t\twakeup_f += 1;\n\n\t\twakeup_f_int = (s32)div64_long(wakeup_f * ICE_RL_PROF_FRACTION,\n\t\t\t\t\t       ICE_RL_PROF_MULTIPLIER);\n\t\twakeup |= (u16)(wakeup_int << 9);\n\t\twakeup |= (u16)(0x1ff & wakeup_f_int);\n\t}\n\n\treturn wakeup;\n}\n\n \nstatic int\nice_sched_bw_to_rl_profile(struct ice_hw *hw, u32 bw,\n\t\t\t   struct ice_aqc_rl_profile_elem *profile)\n{\n\ts64 bytes_per_sec, ts_rate, mv_tmp;\n\tint status = -EINVAL;\n\tbool found = false;\n\ts32 encode = 0;\n\ts64 mv = 0;\n\ts32 i;\n\n\t \n\tif (bw < ICE_SCHED_MIN_BW || bw > ICE_SCHED_MAX_BW)\n\t\treturn status;\n\n\t \n\tbytes_per_sec = div64_long(((s64)bw * 1000), BITS_PER_BYTE);\n\n\t \n\tfor (i = 0; i < 64; i++) {\n\t\tu64 pow_result = BIT_ULL(i);\n\n\t\tts_rate = div64_long((s64)hw->psm_clk_freq,\n\t\t\t\t     pow_result * ICE_RL_PROF_TS_MULTIPLIER);\n\t\tif (ts_rate <= 0)\n\t\t\tcontinue;\n\n\t\t \n\t\tmv_tmp = div64_long(bytes_per_sec * ICE_RL_PROF_MULTIPLIER,\n\t\t\t\t    ts_rate);\n\n\t\t \n\t\tmv = round_up_64bit(mv_tmp, ICE_RL_PROF_MULTIPLIER);\n\n\t\t \n\t\tif (mv > ICE_RL_PROF_ACCURACY_BYTES) {\n\t\t\tencode = i;\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (found) {\n\t\tu16 wm;\n\n\t\twm = ice_sched_calc_wakeup(hw, bw);\n\t\tprofile->rl_multiply = cpu_to_le16(mv);\n\t\tprofile->wake_up_calc = cpu_to_le16(wm);\n\t\tprofile->rl_encode = cpu_to_le16(encode);\n\t\tstatus = 0;\n\t} else {\n\t\tstatus = -ENOENT;\n\t}\n\n\treturn status;\n}\n\n \nstatic struct ice_aqc_rl_profile_info *\nice_sched_add_rl_profile(struct ice_port_info *pi,\n\t\t\t enum ice_rl_type rl_type, u32 bw, u8 layer_num)\n{\n\tstruct ice_aqc_rl_profile_info *rl_prof_elem;\n\tu16 profiles_added = 0, num_profiles = 1;\n\tstruct ice_aqc_rl_profile_elem *buf;\n\tstruct ice_hw *hw;\n\tu8 profile_type;\n\tint status;\n\n\tif (layer_num >= ICE_AQC_TOPO_MAX_LEVEL_NUM)\n\t\treturn NULL;\n\tswitch (rl_type) {\n\tcase ICE_MIN_BW:\n\t\tprofile_type = ICE_AQC_RL_PROFILE_TYPE_CIR;\n\t\tbreak;\n\tcase ICE_MAX_BW:\n\t\tprofile_type = ICE_AQC_RL_PROFILE_TYPE_EIR;\n\t\tbreak;\n\tcase ICE_SHARED_BW:\n\t\tprofile_type = ICE_AQC_RL_PROFILE_TYPE_SRL;\n\t\tbreak;\n\tdefault:\n\t\treturn NULL;\n\t}\n\n\tif (!pi)\n\t\treturn NULL;\n\thw = pi->hw;\n\tlist_for_each_entry(rl_prof_elem, &pi->rl_prof_list[layer_num],\n\t\t\t    list_entry)\n\t\tif ((rl_prof_elem->profile.flags & ICE_AQC_RL_PROFILE_TYPE_M) ==\n\t\t    profile_type && rl_prof_elem->bw == bw)\n\t\t\t \n\t\t\treturn rl_prof_elem;\n\n\t \n\trl_prof_elem = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*rl_prof_elem),\n\t\t\t\t    GFP_KERNEL);\n\n\tif (!rl_prof_elem)\n\t\treturn NULL;\n\n\tstatus = ice_sched_bw_to_rl_profile(hw, bw, &rl_prof_elem->profile);\n\tif (status)\n\t\tgoto exit_add_rl_prof;\n\n\trl_prof_elem->bw = bw;\n\t \n\trl_prof_elem->profile.level = layer_num + 1;\n\trl_prof_elem->profile.flags = profile_type;\n\trl_prof_elem->profile.max_burst_size = cpu_to_le16(hw->max_burst_size);\n\n\t \n\tbuf = &rl_prof_elem->profile;\n\tstatus = ice_aq_add_rl_profile(hw, num_profiles, buf, sizeof(*buf),\n\t\t\t\t       &profiles_added, NULL);\n\tif (status || profiles_added != num_profiles)\n\t\tgoto exit_add_rl_prof;\n\n\t \n\trl_prof_elem->prof_id_ref = 0;\n\tlist_add(&rl_prof_elem->list_entry, &pi->rl_prof_list[layer_num]);\n\treturn rl_prof_elem;\n\nexit_add_rl_prof:\n\tdevm_kfree(ice_hw_to_dev(hw), rl_prof_elem);\n\treturn NULL;\n}\n\n \nstatic int\nice_sched_cfg_node_bw_lmt(struct ice_hw *hw, struct ice_sched_node *node,\n\t\t\t  enum ice_rl_type rl_type, u16 rl_prof_id)\n{\n\tstruct ice_aqc_txsched_elem_data buf;\n\tstruct ice_aqc_txsched_elem *data;\n\n\tbuf = node->info;\n\tdata = &buf.data;\n\tswitch (rl_type) {\n\tcase ICE_MIN_BW:\n\t\tdata->valid_sections |= ICE_AQC_ELEM_VALID_CIR;\n\t\tdata->cir_bw.bw_profile_idx = cpu_to_le16(rl_prof_id);\n\t\tbreak;\n\tcase ICE_MAX_BW:\n\t\t \n\t\tif (data->valid_sections & ICE_AQC_ELEM_VALID_SHARED)\n\t\t\treturn -EIO;\n\t\tdata->valid_sections |= ICE_AQC_ELEM_VALID_EIR;\n\t\tdata->eir_bw.bw_profile_idx = cpu_to_le16(rl_prof_id);\n\t\tbreak;\n\tcase ICE_SHARED_BW:\n\t\t \n\t\tif (rl_prof_id == ICE_SCHED_NO_SHARED_RL_PROF_ID) {\n\t\t\t \n\t\t\tdata->valid_sections &= ~ICE_AQC_ELEM_VALID_SHARED;\n\t\t\tdata->srl_id = 0;  \n\n\t\t\t \n\t\t\tdata->valid_sections |= ICE_AQC_ELEM_VALID_EIR;\n\t\t\tdata->eir_bw.bw_profile_idx =\n\t\t\t\tcpu_to_le16(ICE_SCHED_DFLT_RL_PROF_ID);\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif ((data->valid_sections & ICE_AQC_ELEM_VALID_EIR) &&\n\t\t    (le16_to_cpu(data->eir_bw.bw_profile_idx) !=\n\t\t\t    ICE_SCHED_DFLT_RL_PROF_ID))\n\t\t\treturn -EIO;\n\t\t \n\t\tdata->valid_sections &= ~ICE_AQC_ELEM_VALID_EIR;\n\t\t \n\t\tdata->valid_sections |= ICE_AQC_ELEM_VALID_SHARED;\n\t\tdata->srl_id = cpu_to_le16(rl_prof_id);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\t \n\treturn ice_sched_update_elem(hw, node, &buf);\n}\n\n \nstatic u16\nice_sched_get_node_rl_prof_id(struct ice_sched_node *node,\n\t\t\t      enum ice_rl_type rl_type)\n{\n\tu16 rl_prof_id = ICE_SCHED_INVAL_PROF_ID;\n\tstruct ice_aqc_txsched_elem *data;\n\n\tdata = &node->info.data;\n\tswitch (rl_type) {\n\tcase ICE_MIN_BW:\n\t\tif (data->valid_sections & ICE_AQC_ELEM_VALID_CIR)\n\t\t\trl_prof_id = le16_to_cpu(data->cir_bw.bw_profile_idx);\n\t\tbreak;\n\tcase ICE_MAX_BW:\n\t\tif (data->valid_sections & ICE_AQC_ELEM_VALID_EIR)\n\t\t\trl_prof_id = le16_to_cpu(data->eir_bw.bw_profile_idx);\n\t\tbreak;\n\tcase ICE_SHARED_BW:\n\t\tif (data->valid_sections & ICE_AQC_ELEM_VALID_SHARED)\n\t\t\trl_prof_id = le16_to_cpu(data->srl_id);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn rl_prof_id;\n}\n\n \nstatic u8\nice_sched_get_rl_prof_layer(struct ice_port_info *pi, enum ice_rl_type rl_type,\n\t\t\t    u8 layer_index)\n{\n\tstruct ice_hw *hw = pi->hw;\n\n\tif (layer_index >= hw->num_tx_sched_layers)\n\t\treturn ICE_SCHED_INVAL_LAYER_NUM;\n\tswitch (rl_type) {\n\tcase ICE_MIN_BW:\n\t\tif (hw->layer_info[layer_index].max_cir_rl_profiles)\n\t\t\treturn layer_index;\n\t\tbreak;\n\tcase ICE_MAX_BW:\n\t\tif (hw->layer_info[layer_index].max_eir_rl_profiles)\n\t\t\treturn layer_index;\n\t\tbreak;\n\tcase ICE_SHARED_BW:\n\t\t \n\t\tif (hw->layer_info[layer_index].max_srl_profiles)\n\t\t\treturn layer_index;\n\t\telse if (layer_index < hw->num_tx_sched_layers - 1 &&\n\t\t\t hw->layer_info[layer_index + 1].max_srl_profiles)\n\t\t\treturn layer_index + 1;\n\t\telse if (layer_index > 0 &&\n\t\t\t hw->layer_info[layer_index - 1].max_srl_profiles)\n\t\t\treturn layer_index - 1;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn ICE_SCHED_INVAL_LAYER_NUM;\n}\n\n \nstatic struct ice_sched_node *\nice_sched_get_srl_node(struct ice_sched_node *node, u8 srl_layer)\n{\n\tif (srl_layer > node->tx_sched_layer)\n\t\treturn node->children[0];\n\telse if (srl_layer < node->tx_sched_layer)\n\t\t \n\t\treturn node->parent;\n\telse\n\t\treturn node;\n}\n\n \nstatic int\nice_sched_rm_rl_profile(struct ice_port_info *pi, u8 layer_num, u8 profile_type,\n\t\t\tu16 profile_id)\n{\n\tstruct ice_aqc_rl_profile_info *rl_prof_elem;\n\tint status = 0;\n\n\tif (layer_num >= ICE_AQC_TOPO_MAX_LEVEL_NUM)\n\t\treturn -EINVAL;\n\t \n\tlist_for_each_entry(rl_prof_elem, &pi->rl_prof_list[layer_num],\n\t\t\t    list_entry)\n\t\tif ((rl_prof_elem->profile.flags & ICE_AQC_RL_PROFILE_TYPE_M) ==\n\t\t    profile_type &&\n\t\t    le16_to_cpu(rl_prof_elem->profile.profile_id) ==\n\t\t    profile_id) {\n\t\t\tif (rl_prof_elem->prof_id_ref)\n\t\t\t\trl_prof_elem->prof_id_ref--;\n\n\t\t\t \n\t\t\tstatus = ice_sched_del_rl_profile(pi->hw, rl_prof_elem);\n\t\t\tif (status && status != -EBUSY)\n\t\t\t\tice_debug(pi->hw, ICE_DBG_SCHED, \"Remove rl profile failed\\n\");\n\t\t\tbreak;\n\t\t}\n\tif (status == -EBUSY)\n\t\tstatus = 0;\n\treturn status;\n}\n\n \nstatic int\nice_sched_set_node_bw_dflt(struct ice_port_info *pi,\n\t\t\t   struct ice_sched_node *node,\n\t\t\t   enum ice_rl_type rl_type, u8 layer_num)\n{\n\tstruct ice_hw *hw;\n\tu8 profile_type;\n\tu16 rl_prof_id;\n\tu16 old_id;\n\tint status;\n\n\thw = pi->hw;\n\tswitch (rl_type) {\n\tcase ICE_MIN_BW:\n\t\tprofile_type = ICE_AQC_RL_PROFILE_TYPE_CIR;\n\t\trl_prof_id = ICE_SCHED_DFLT_RL_PROF_ID;\n\t\tbreak;\n\tcase ICE_MAX_BW:\n\t\tprofile_type = ICE_AQC_RL_PROFILE_TYPE_EIR;\n\t\trl_prof_id = ICE_SCHED_DFLT_RL_PROF_ID;\n\t\tbreak;\n\tcase ICE_SHARED_BW:\n\t\tprofile_type = ICE_AQC_RL_PROFILE_TYPE_SRL;\n\t\t \n\t\trl_prof_id = ICE_SCHED_NO_SHARED_RL_PROF_ID;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\t \n\told_id = ice_sched_get_node_rl_prof_id(node, rl_type);\n\t \n\tstatus = ice_sched_cfg_node_bw_lmt(hw, node, rl_type, rl_prof_id);\n\tif (status)\n\t\treturn status;\n\n\t \n\tif (old_id == ICE_SCHED_DFLT_RL_PROF_ID ||\n\t    old_id == ICE_SCHED_INVAL_PROF_ID)\n\t\treturn 0;\n\n\treturn ice_sched_rm_rl_profile(pi, layer_num, profile_type, old_id);\n}\n\n \nstatic int\nice_sched_set_eir_srl_excl(struct ice_port_info *pi,\n\t\t\t   struct ice_sched_node *node,\n\t\t\t   u8 layer_num, enum ice_rl_type rl_type, u32 bw)\n{\n\tif (rl_type == ICE_SHARED_BW) {\n\t\t \n\t\tif (bw == ICE_SCHED_DFLT_BW)\n\t\t\t \n\t\t\treturn 0;\n\n\t\t \n\t\treturn ice_sched_set_node_bw_dflt(pi, node, ICE_MAX_BW,\n\t\t\t\t\t\t  layer_num);\n\t} else if (rl_type == ICE_MAX_BW &&\n\t\t   node->info.data.valid_sections & ICE_AQC_ELEM_VALID_SHARED) {\n\t\t \n\t\treturn ice_sched_set_node_bw_dflt(pi, node,\n\t\t\t\t\t\t  ICE_SHARED_BW,\n\t\t\t\t\t\t  layer_num);\n\t}\n\treturn 0;\n}\n\n \nint\nice_sched_set_node_bw(struct ice_port_info *pi, struct ice_sched_node *node,\n\t\t      enum ice_rl_type rl_type, u32 bw, u8 layer_num)\n{\n\tstruct ice_aqc_rl_profile_info *rl_prof_info;\n\tstruct ice_hw *hw = pi->hw;\n\tu16 old_id, rl_prof_id;\n\tint status = -EINVAL;\n\n\trl_prof_info = ice_sched_add_rl_profile(pi, rl_type, bw, layer_num);\n\tif (!rl_prof_info)\n\t\treturn status;\n\n\trl_prof_id = le16_to_cpu(rl_prof_info->profile.profile_id);\n\n\t \n\told_id = ice_sched_get_node_rl_prof_id(node, rl_type);\n\t \n\tstatus = ice_sched_cfg_node_bw_lmt(hw, node, rl_type, rl_prof_id);\n\tif (status)\n\t\treturn status;\n\n\t \n\t \n\trl_prof_info->prof_id_ref++;\n\n\t \n\tif ((old_id == ICE_SCHED_DFLT_RL_PROF_ID && rl_type != ICE_SHARED_BW) ||\n\t    old_id == ICE_SCHED_INVAL_PROF_ID || old_id == rl_prof_id)\n\t\treturn 0;\n\n\treturn ice_sched_rm_rl_profile(pi, layer_num,\n\t\t\t\t       rl_prof_info->profile.flags &\n\t\t\t\t       ICE_AQC_RL_PROFILE_TYPE_M, old_id);\n}\n\n \nint\nice_sched_set_node_priority(struct ice_port_info *pi, struct ice_sched_node *node,\n\t\t\t    u16 priority)\n{\n\tstruct ice_aqc_txsched_elem_data buf;\n\tstruct ice_aqc_txsched_elem *data;\n\n\tbuf = node->info;\n\tdata = &buf.data;\n\n\tdata->valid_sections |= ICE_AQC_ELEM_VALID_GENERIC;\n\tdata->generic |= FIELD_PREP(ICE_AQC_ELEM_GENERIC_PRIO_M, priority);\n\n\treturn ice_sched_update_elem(pi->hw, node, &buf);\n}\n\n \nint\nice_sched_set_node_weight(struct ice_port_info *pi, struct ice_sched_node *node, u16 weight)\n{\n\tstruct ice_aqc_txsched_elem_data buf;\n\tstruct ice_aqc_txsched_elem *data;\n\n\tbuf = node->info;\n\tdata = &buf.data;\n\n\tdata->valid_sections = ICE_AQC_ELEM_VALID_CIR | ICE_AQC_ELEM_VALID_EIR |\n\t\t\t       ICE_AQC_ELEM_VALID_GENERIC;\n\tdata->cir_bw.bw_alloc = cpu_to_le16(weight);\n\tdata->eir_bw.bw_alloc = cpu_to_le16(weight);\n\n\tdata->generic |= FIELD_PREP(ICE_AQC_ELEM_GENERIC_SP_M, 0x0);\n\n\treturn ice_sched_update_elem(pi->hw, node, &buf);\n}\n\n \nint\nice_sched_set_node_bw_lmt(struct ice_port_info *pi, struct ice_sched_node *node,\n\t\t\t  enum ice_rl_type rl_type, u32 bw)\n{\n\tstruct ice_sched_node *cfg_node = node;\n\tint status;\n\n\tstruct ice_hw *hw;\n\tu8 layer_num;\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\thw = pi->hw;\n\t \n\tice_sched_rm_unused_rl_prof(pi);\n\tlayer_num = ice_sched_get_rl_prof_layer(pi, rl_type,\n\t\t\t\t\t\tnode->tx_sched_layer);\n\tif (layer_num >= hw->num_tx_sched_layers)\n\t\treturn -EINVAL;\n\n\tif (rl_type == ICE_SHARED_BW) {\n\t\t \n\t\tcfg_node = ice_sched_get_srl_node(node, layer_num);\n\t\tif (!cfg_node)\n\t\t\treturn -EIO;\n\t}\n\t \n\tstatus = ice_sched_set_eir_srl_excl(pi, cfg_node, layer_num, rl_type,\n\t\t\t\t\t    bw);\n\tif (status)\n\t\treturn status;\n\tif (bw == ICE_SCHED_DFLT_BW)\n\t\treturn ice_sched_set_node_bw_dflt(pi, cfg_node, rl_type,\n\t\t\t\t\t\t  layer_num);\n\treturn ice_sched_set_node_bw(pi, cfg_node, rl_type, bw, layer_num);\n}\n\n \nstatic int\nice_sched_set_node_bw_dflt_lmt(struct ice_port_info *pi,\n\t\t\t       struct ice_sched_node *node,\n\t\t\t       enum ice_rl_type rl_type)\n{\n\treturn ice_sched_set_node_bw_lmt(pi, node, rl_type,\n\t\t\t\t\t ICE_SCHED_DFLT_BW);\n}\n\n \nstatic int\nice_sched_validate_srl_node(struct ice_sched_node *node, u8 sel_layer)\n{\n\t \n\tif (sel_layer == node->tx_sched_layer ||\n\t    ((sel_layer == node->tx_sched_layer + 1) &&\n\t    node->num_children == 1) ||\n\t    ((sel_layer == node->tx_sched_layer - 1) &&\n\t    (node->parent && node->parent->num_children == 1)))\n\t\treturn 0;\n\n\treturn -EIO;\n}\n\n \nstatic int\nice_sched_save_q_bw(struct ice_q_ctx *q_ctx, enum ice_rl_type rl_type, u32 bw)\n{\n\tswitch (rl_type) {\n\tcase ICE_MIN_BW:\n\t\tice_set_clear_cir_bw(&q_ctx->bw_t_info, bw);\n\t\tbreak;\n\tcase ICE_MAX_BW:\n\t\tice_set_clear_eir_bw(&q_ctx->bw_t_info, bw);\n\t\tbreak;\n\tcase ICE_SHARED_BW:\n\t\tice_set_clear_shared_bw(&q_ctx->bw_t_info, bw);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n \nstatic int\nice_sched_set_q_bw_lmt(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t       u16 q_handle, enum ice_rl_type rl_type, u32 bw)\n{\n\tstruct ice_sched_node *node;\n\tstruct ice_q_ctx *q_ctx;\n\tint status = -EINVAL;\n\n\tif (!ice_is_vsi_valid(pi->hw, vsi_handle))\n\t\treturn -EINVAL;\n\tmutex_lock(&pi->sched_lock);\n\tq_ctx = ice_get_lan_q_ctx(pi->hw, vsi_handle, tc, q_handle);\n\tif (!q_ctx)\n\t\tgoto exit_q_bw_lmt;\n\tnode = ice_sched_find_node_by_teid(pi->root, q_ctx->q_teid);\n\tif (!node) {\n\t\tice_debug(pi->hw, ICE_DBG_SCHED, \"Wrong q_teid\\n\");\n\t\tgoto exit_q_bw_lmt;\n\t}\n\n\t \n\tif (node->info.data.elem_type != ICE_AQC_ELEM_TYPE_LEAF)\n\t\tgoto exit_q_bw_lmt;\n\n\t \n\tif (rl_type == ICE_SHARED_BW) {\n\t\tu8 sel_layer;  \n\n\t\tsel_layer = ice_sched_get_rl_prof_layer(pi, rl_type,\n\t\t\t\t\t\t\tnode->tx_sched_layer);\n\t\tif (sel_layer >= pi->hw->num_tx_sched_layers) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto exit_q_bw_lmt;\n\t\t}\n\t\tstatus = ice_sched_validate_srl_node(node, sel_layer);\n\t\tif (status)\n\t\t\tgoto exit_q_bw_lmt;\n\t}\n\n\tif (bw == ICE_SCHED_DFLT_BW)\n\t\tstatus = ice_sched_set_node_bw_dflt_lmt(pi, node, rl_type);\n\telse\n\t\tstatus = ice_sched_set_node_bw_lmt(pi, node, rl_type, bw);\n\n\tif (!status)\n\t\tstatus = ice_sched_save_q_bw(q_ctx, rl_type, bw);\n\nexit_q_bw_lmt:\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nint\nice_cfg_q_bw_lmt(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t u16 q_handle, enum ice_rl_type rl_type, u32 bw)\n{\n\treturn ice_sched_set_q_bw_lmt(pi, vsi_handle, tc, q_handle, rl_type,\n\t\t\t\t      bw);\n}\n\n \nint\nice_cfg_q_bw_dflt_lmt(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t      u16 q_handle, enum ice_rl_type rl_type)\n{\n\treturn ice_sched_set_q_bw_lmt(pi, vsi_handle, tc, q_handle, rl_type,\n\t\t\t\t      ICE_SCHED_DFLT_BW);\n}\n\n \nstatic struct ice_sched_node *\nice_sched_get_node_by_id_type(struct ice_port_info *pi, u32 id,\n\t\t\t      enum ice_agg_type agg_type, u8 tc)\n{\n\tstruct ice_sched_node *node = NULL;\n\n\tswitch (agg_type) {\n\tcase ICE_AGG_TYPE_VSI: {\n\t\tstruct ice_vsi_ctx *vsi_ctx;\n\t\tu16 vsi_handle = (u16)id;\n\n\t\tif (!ice_is_vsi_valid(pi->hw, vsi_handle))\n\t\t\tbreak;\n\t\t \n\t\tvsi_ctx = ice_get_vsi_ctx(pi->hw, vsi_handle);\n\t\tif (!vsi_ctx)\n\t\t\tbreak;\n\t\tnode = vsi_ctx->sched.vsi_node[tc];\n\t\tbreak;\n\t}\n\n\tcase ICE_AGG_TYPE_AGG: {\n\t\tstruct ice_sched_node *tc_node;\n\n\t\ttc_node = ice_sched_get_tc_node(pi, tc);\n\t\tif (tc_node)\n\t\t\tnode = ice_sched_get_agg_node(pi, tc_node, id);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn node;\n}\n\n \nstatic int\nice_sched_set_node_bw_lmt_per_tc(struct ice_port_info *pi, u32 id,\n\t\t\t\t enum ice_agg_type agg_type, u8 tc,\n\t\t\t\t enum ice_rl_type rl_type, u32 bw)\n{\n\tstruct ice_sched_node *node;\n\tint status = -EINVAL;\n\n\tif (!pi)\n\t\treturn status;\n\n\tif (rl_type == ICE_UNKNOWN_BW)\n\t\treturn status;\n\n\tmutex_lock(&pi->sched_lock);\n\tnode = ice_sched_get_node_by_id_type(pi, id, agg_type, tc);\n\tif (!node) {\n\t\tice_debug(pi->hw, ICE_DBG_SCHED, \"Wrong id, agg type, or tc\\n\");\n\t\tgoto exit_set_node_bw_lmt_per_tc;\n\t}\n\tif (bw == ICE_SCHED_DFLT_BW)\n\t\tstatus = ice_sched_set_node_bw_dflt_lmt(pi, node, rl_type);\n\telse\n\t\tstatus = ice_sched_set_node_bw_lmt(pi, node, rl_type, bw);\n\nexit_set_node_bw_lmt_per_tc:\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nint\nice_cfg_vsi_bw_lmt_per_tc(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t\t  enum ice_rl_type rl_type, u32 bw)\n{\n\tint status;\n\n\tstatus = ice_sched_set_node_bw_lmt_per_tc(pi, vsi_handle,\n\t\t\t\t\t\t  ICE_AGG_TYPE_VSI,\n\t\t\t\t\t\t  tc, rl_type, bw);\n\tif (!status) {\n\t\tmutex_lock(&pi->sched_lock);\n\t\tstatus = ice_sched_save_vsi_bw(pi, vsi_handle, tc, rl_type, bw);\n\t\tmutex_unlock(&pi->sched_lock);\n\t}\n\treturn status;\n}\n\n \nint\nice_cfg_vsi_bw_dflt_lmt_per_tc(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t\t       enum ice_rl_type rl_type)\n{\n\tint status;\n\n\tstatus = ice_sched_set_node_bw_lmt_per_tc(pi, vsi_handle,\n\t\t\t\t\t\t  ICE_AGG_TYPE_VSI,\n\t\t\t\t\t\t  tc, rl_type,\n\t\t\t\t\t\t  ICE_SCHED_DFLT_BW);\n\tif (!status) {\n\t\tmutex_lock(&pi->sched_lock);\n\t\tstatus = ice_sched_save_vsi_bw(pi, vsi_handle, tc, rl_type,\n\t\t\t\t\t       ICE_SCHED_DFLT_BW);\n\t\tmutex_unlock(&pi->sched_lock);\n\t}\n\treturn status;\n}\n\n \nint ice_cfg_rl_burst_size(struct ice_hw *hw, u32 bytes)\n{\n\tu16 burst_size_to_prog;\n\n\tif (bytes < ICE_MIN_BURST_SIZE_ALLOWED ||\n\t    bytes > ICE_MAX_BURST_SIZE_ALLOWED)\n\t\treturn -EINVAL;\n\tif (ice_round_to_num(bytes, 64) <=\n\t    ICE_MAX_BURST_SIZE_64_BYTE_GRANULARITY) {\n\t\t \n\t\t \n\t\tburst_size_to_prog = ICE_64_BYTE_GRANULARITY;\n\t\t \n\t\tbytes = ice_round_to_num(bytes, 64);\n\t\t \n\t\tburst_size_to_prog |= (u16)(bytes / 64);\n\t} else {\n\t\t \n\t\t \n\t\tburst_size_to_prog = ICE_KBYTE_GRANULARITY;\n\t\t \n\t\tbytes = ice_round_to_num(bytes, 1024);\n\t\t \n\t\tif (bytes > ICE_MAX_BURST_SIZE_KBYTE_GRANULARITY)\n\t\t\tbytes = ICE_MAX_BURST_SIZE_KBYTE_GRANULARITY;\n\t\t \n\t\tburst_size_to_prog |= (u16)(bytes / 1024);\n\t}\n\thw->max_burst_size = burst_size_to_prog;\n\treturn 0;\n}\n\n \nstatic int\nice_sched_replay_node_prio(struct ice_hw *hw, struct ice_sched_node *node,\n\t\t\t   u8 priority)\n{\n\tstruct ice_aqc_txsched_elem_data buf;\n\tstruct ice_aqc_txsched_elem *data;\n\tint status;\n\n\tbuf = node->info;\n\tdata = &buf.data;\n\tdata->valid_sections |= ICE_AQC_ELEM_VALID_GENERIC;\n\tdata->generic = priority;\n\n\t \n\tstatus = ice_sched_update_elem(hw, node, &buf);\n\treturn status;\n}\n\n \nstatic int\nice_sched_replay_node_bw(struct ice_hw *hw, struct ice_sched_node *node,\n\t\t\t struct ice_bw_type_info *bw_t_info)\n{\n\tstruct ice_port_info *pi = hw->port_info;\n\tint status = -EINVAL;\n\tu16 bw_alloc;\n\n\tif (!node)\n\t\treturn status;\n\tif (bitmap_empty(bw_t_info->bw_t_bitmap, ICE_BW_TYPE_CNT))\n\t\treturn 0;\n\tif (test_bit(ICE_BW_TYPE_PRIO, bw_t_info->bw_t_bitmap)) {\n\t\tstatus = ice_sched_replay_node_prio(hw, node,\n\t\t\t\t\t\t    bw_t_info->generic);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tif (test_bit(ICE_BW_TYPE_CIR, bw_t_info->bw_t_bitmap)) {\n\t\tstatus = ice_sched_set_node_bw_lmt(pi, node, ICE_MIN_BW,\n\t\t\t\t\t\t   bw_t_info->cir_bw.bw);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tif (test_bit(ICE_BW_TYPE_CIR_WT, bw_t_info->bw_t_bitmap)) {\n\t\tbw_alloc = bw_t_info->cir_bw.bw_alloc;\n\t\tstatus = ice_sched_cfg_node_bw_alloc(hw, node, ICE_MIN_BW,\n\t\t\t\t\t\t     bw_alloc);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tif (test_bit(ICE_BW_TYPE_EIR, bw_t_info->bw_t_bitmap)) {\n\t\tstatus = ice_sched_set_node_bw_lmt(pi, node, ICE_MAX_BW,\n\t\t\t\t\t\t   bw_t_info->eir_bw.bw);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tif (test_bit(ICE_BW_TYPE_EIR_WT, bw_t_info->bw_t_bitmap)) {\n\t\tbw_alloc = bw_t_info->eir_bw.bw_alloc;\n\t\tstatus = ice_sched_cfg_node_bw_alloc(hw, node, ICE_MAX_BW,\n\t\t\t\t\t\t     bw_alloc);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tif (test_bit(ICE_BW_TYPE_SHARED, bw_t_info->bw_t_bitmap))\n\t\tstatus = ice_sched_set_node_bw_lmt(pi, node, ICE_SHARED_BW,\n\t\t\t\t\t\t   bw_t_info->shared_bw);\n\treturn status;\n}\n\n \nstatic void\nice_sched_get_ena_tc_bitmap(struct ice_port_info *pi,\n\t\t\t    unsigned long *tc_bitmap,\n\t\t\t    unsigned long *ena_tc_bitmap)\n{\n\tu8 tc;\n\n\t \n\tice_for_each_traffic_class(tc)\n\t\tif (ice_is_tc_ena(*tc_bitmap, tc) &&\n\t\t    (ice_sched_get_tc_node(pi, tc)))\n\t\t\tset_bit(tc, ena_tc_bitmap);\n}\n\n \nvoid ice_sched_replay_agg(struct ice_hw *hw)\n{\n\tstruct ice_port_info *pi = hw->port_info;\n\tstruct ice_sched_agg_info *agg_info;\n\n\tmutex_lock(&pi->sched_lock);\n\tlist_for_each_entry(agg_info, &hw->agg_list, list_entry)\n\t\t \n\t\tif (!bitmap_equal(agg_info->tc_bitmap, agg_info->replay_tc_bitmap,\n\t\t\t\t  ICE_MAX_TRAFFIC_CLASS)) {\n\t\t\tDECLARE_BITMAP(replay_bitmap, ICE_MAX_TRAFFIC_CLASS);\n\t\t\tint status;\n\n\t\t\tbitmap_zero(replay_bitmap, ICE_MAX_TRAFFIC_CLASS);\n\t\t\tice_sched_get_ena_tc_bitmap(pi,\n\t\t\t\t\t\t    agg_info->replay_tc_bitmap,\n\t\t\t\t\t\t    replay_bitmap);\n\t\t\tstatus = ice_sched_cfg_agg(hw->port_info,\n\t\t\t\t\t\t   agg_info->agg_id,\n\t\t\t\t\t\t   ICE_AGG_TYPE_AGG,\n\t\t\t\t\t\t   replay_bitmap);\n\t\t\tif (status) {\n\t\t\t\tdev_info(ice_hw_to_dev(hw),\n\t\t\t\t\t \"Replay agg id[%d] failed\\n\",\n\t\t\t\t\t agg_info->agg_id);\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\tmutex_unlock(&pi->sched_lock);\n}\n\n \nvoid ice_sched_replay_agg_vsi_preinit(struct ice_hw *hw)\n{\n\tstruct ice_port_info *pi = hw->port_info;\n\tstruct ice_sched_agg_info *agg_info;\n\n\tmutex_lock(&pi->sched_lock);\n\tlist_for_each_entry(agg_info, &hw->agg_list, list_entry) {\n\t\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\n\t\tagg_info->tc_bitmap[0] = 0;\n\t\tlist_for_each_entry(agg_vsi_info, &agg_info->agg_vsi_list,\n\t\t\t\t    list_entry)\n\t\t\tagg_vsi_info->tc_bitmap[0] = 0;\n\t}\n\tmutex_unlock(&pi->sched_lock);\n}\n\n \nstatic int ice_sched_replay_vsi_agg(struct ice_hw *hw, u16 vsi_handle)\n{\n\tDECLARE_BITMAP(replay_bitmap, ICE_MAX_TRAFFIC_CLASS);\n\tstruct ice_sched_agg_vsi_info *agg_vsi_info;\n\tstruct ice_port_info *pi = hw->port_info;\n\tstruct ice_sched_agg_info *agg_info;\n\tint status;\n\n\tbitmap_zero(replay_bitmap, ICE_MAX_TRAFFIC_CLASS);\n\tif (!ice_is_vsi_valid(hw, vsi_handle))\n\t\treturn -EINVAL;\n\tagg_info = ice_get_vsi_agg_info(hw, vsi_handle);\n\tif (!agg_info)\n\t\treturn 0;  \n\tagg_vsi_info = ice_get_agg_vsi_info(agg_info, vsi_handle);\n\tif (!agg_vsi_info)\n\t\treturn 0;  \n\tice_sched_get_ena_tc_bitmap(pi, agg_info->replay_tc_bitmap,\n\t\t\t\t    replay_bitmap);\n\t \n\tstatus = ice_sched_cfg_agg(hw->port_info, agg_info->agg_id,\n\t\t\t\t   ICE_AGG_TYPE_AGG, replay_bitmap);\n\tif (status)\n\t\treturn status;\n\n\tbitmap_zero(replay_bitmap, ICE_MAX_TRAFFIC_CLASS);\n\tice_sched_get_ena_tc_bitmap(pi, agg_vsi_info->replay_tc_bitmap,\n\t\t\t\t    replay_bitmap);\n\t \n\treturn ice_sched_assoc_vsi_to_agg(pi, agg_info->agg_id, vsi_handle,\n\t\t\t\t\t  replay_bitmap);\n}\n\n \nint ice_replay_vsi_agg(struct ice_hw *hw, u16 vsi_handle)\n{\n\tstruct ice_port_info *pi = hw->port_info;\n\tint status;\n\n\tmutex_lock(&pi->sched_lock);\n\tstatus = ice_sched_replay_vsi_agg(hw, vsi_handle);\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nint ice_sched_replay_q_bw(struct ice_port_info *pi, struct ice_q_ctx *q_ctx)\n{\n\tstruct ice_sched_node *q_node;\n\n\t \n\tq_node = ice_sched_find_node_by_teid(pi->root, q_ctx->q_teid);\n\tif (!q_node)\n\t\treturn -EINVAL;\n\treturn ice_sched_replay_node_bw(pi->hw, q_node, &q_ctx->bw_t_info);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}