{
  "module_name": "ice_arfs.c",
  "hash_id": "f2164d58fc1507427c165c1456e7a9b8c34ec5beca1fca7edca960d89528b62a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_arfs.c",
  "human_readable_source": "\n \n\n#include \"ice.h\"\n\n \nstatic bool ice_is_arfs_active(struct ice_vsi *vsi)\n{\n\treturn !!vsi->arfs_fltr_list;\n}\n\n \nbool\nice_is_arfs_using_perfect_flow(struct ice_hw *hw, enum ice_fltr_ptype flow_type)\n{\n\tstruct ice_arfs_active_fltr_cntrs *arfs_fltr_cntrs;\n\tstruct ice_pf *pf = hw->back;\n\tstruct ice_vsi *vsi;\n\n\tvsi = ice_get_main_vsi(pf);\n\tif (!vsi)\n\t\treturn false;\n\n\tarfs_fltr_cntrs = vsi->arfs_fltr_cntrs;\n\n\t \n\tsmp_mb__before_atomic();\n\tswitch (flow_type) {\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_UDP:\n\t\treturn atomic_read(&arfs_fltr_cntrs->active_udpv4_cnt) > 0;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_UDP:\n\t\treturn atomic_read(&arfs_fltr_cntrs->active_udpv6_cnt) > 0;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_TCP:\n\t\treturn atomic_read(&arfs_fltr_cntrs->active_tcpv4_cnt) > 0;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_TCP:\n\t\treturn atomic_read(&arfs_fltr_cntrs->active_tcpv6_cnt) > 0;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstatic void\nice_arfs_update_active_fltr_cntrs(struct ice_vsi *vsi,\n\t\t\t\t  struct ice_arfs_entry *entry, bool add)\n{\n\tstruct ice_arfs_active_fltr_cntrs *fltr_cntrs = vsi->arfs_fltr_cntrs;\n\n\tswitch (entry->fltr_info.flow_type) {\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_TCP:\n\t\tif (add)\n\t\t\tatomic_inc(&fltr_cntrs->active_tcpv4_cnt);\n\t\telse\n\t\t\tatomic_dec(&fltr_cntrs->active_tcpv4_cnt);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_TCP:\n\t\tif (add)\n\t\t\tatomic_inc(&fltr_cntrs->active_tcpv6_cnt);\n\t\telse\n\t\t\tatomic_dec(&fltr_cntrs->active_tcpv6_cnt);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_UDP:\n\t\tif (add)\n\t\t\tatomic_inc(&fltr_cntrs->active_udpv4_cnt);\n\t\telse\n\t\t\tatomic_dec(&fltr_cntrs->active_udpv4_cnt);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_UDP:\n\t\tif (add)\n\t\t\tatomic_inc(&fltr_cntrs->active_udpv6_cnt);\n\t\telse\n\t\t\tatomic_dec(&fltr_cntrs->active_udpv6_cnt);\n\t\tbreak;\n\tdefault:\n\t\tdev_err(ice_pf_to_dev(vsi->back), \"aRFS: Failed to update filter counters, invalid filter type %d\\n\",\n\t\t\tentry->fltr_info.flow_type);\n\t}\n}\n\n \nstatic void\nice_arfs_del_flow_rules(struct ice_vsi *vsi, struct hlist_head *del_list_head)\n{\n\tstruct ice_arfs_entry *e;\n\tstruct hlist_node *n;\n\tstruct device *dev;\n\n\tdev = ice_pf_to_dev(vsi->back);\n\n\thlist_for_each_entry_safe(e, n, del_list_head, list_entry) {\n\t\tint result;\n\n\t\tresult = ice_fdir_write_fltr(vsi->back, &e->fltr_info, false,\n\t\t\t\t\t     false);\n\t\tif (!result)\n\t\t\tice_arfs_update_active_fltr_cntrs(vsi, e, false);\n\t\telse\n\t\t\tdev_dbg(dev, \"Unable to delete aRFS entry, err %d fltr_state %d fltr_id %d flow_id %d Q %d\\n\",\n\t\t\t\tresult, e->fltr_state, e->fltr_info.fltr_id,\n\t\t\t\te->flow_id, e->fltr_info.q_index);\n\n\t\t \n\t\thlist_del(&e->list_entry);\n\t\tdevm_kfree(dev, e);\n\t}\n}\n\n \nstatic void\nice_arfs_add_flow_rules(struct ice_vsi *vsi, struct hlist_head *add_list_head)\n{\n\tstruct ice_arfs_entry_ptr *ep;\n\tstruct hlist_node *n;\n\tstruct device *dev;\n\n\tdev = ice_pf_to_dev(vsi->back);\n\n\thlist_for_each_entry_safe(ep, n, add_list_head, list_entry) {\n\t\tint result;\n\n\t\tresult = ice_fdir_write_fltr(vsi->back,\n\t\t\t\t\t     &ep->arfs_entry->fltr_info, true,\n\t\t\t\t\t     false);\n\t\tif (!result)\n\t\t\tice_arfs_update_active_fltr_cntrs(vsi, ep->arfs_entry,\n\t\t\t\t\t\t\t  true);\n\t\telse\n\t\t\tdev_dbg(dev, \"Unable to add aRFS entry, err %d fltr_state %d fltr_id %d flow_id %d Q %d\\n\",\n\t\t\t\tresult, ep->arfs_entry->fltr_state,\n\t\t\t\tep->arfs_entry->fltr_info.fltr_id,\n\t\t\t\tep->arfs_entry->flow_id,\n\t\t\t\tep->arfs_entry->fltr_info.q_index);\n\n\t\thlist_del(&ep->list_entry);\n\t\tdevm_kfree(dev, ep);\n\t}\n}\n\n \nstatic bool\nice_arfs_is_flow_expired(struct ice_vsi *vsi, struct ice_arfs_entry *arfs_entry)\n{\n#define ICE_ARFS_TIME_DELTA_EXPIRATION\tmsecs_to_jiffies(5000)\n\tif (rps_may_expire_flow(vsi->netdev, arfs_entry->fltr_info.q_index,\n\t\t\t\tarfs_entry->flow_id,\n\t\t\t\tarfs_entry->fltr_info.fltr_id))\n\t\treturn true;\n\n\t \n\tif (arfs_entry->fltr_info.flow_type != ICE_FLTR_PTYPE_NONF_IPV4_UDP &&\n\t    arfs_entry->fltr_info.flow_type != ICE_FLTR_PTYPE_NONF_IPV6_UDP)\n\t\treturn false;\n\n\treturn time_in_range64(arfs_entry->time_activated +\n\t\t\t       ICE_ARFS_TIME_DELTA_EXPIRATION,\n\t\t\t       arfs_entry->time_activated, get_jiffies_64());\n}\n\n \nstatic void\nice_arfs_update_flow_rules(struct ice_vsi *vsi, u16 idx,\n\t\t\t   struct hlist_head *add_list,\n\t\t\t   struct hlist_head *del_list)\n{\n\tstruct ice_arfs_entry *e;\n\tstruct hlist_node *n;\n\tstruct device *dev;\n\n\tdev = ice_pf_to_dev(vsi->back);\n\n\t \n\thlist_for_each_entry_safe(e, n, &vsi->arfs_fltr_list[idx], list_entry)\n\t\t \n\t\tif (e->fltr_state == ICE_ARFS_INACTIVE) {\n\t\t\tenum ice_fltr_ptype flow_type = e->fltr_info.flow_type;\n\t\t\tstruct ice_arfs_entry_ptr *ep =\n\t\t\t\tdevm_kzalloc(dev, sizeof(*ep), GFP_ATOMIC);\n\n\t\t\tif (!ep)\n\t\t\t\tcontinue;\n\t\t\tINIT_HLIST_NODE(&ep->list_entry);\n\t\t\t \n\t\t\tep->arfs_entry = e;\n\t\t\thlist_add_head(&ep->list_entry, add_list);\n\t\t\te->fltr_state = ICE_ARFS_ACTIVE;\n\t\t\t \n\t\t\tif (flow_type == ICE_FLTR_PTYPE_NONF_IPV4_UDP ||\n\t\t\t    flow_type == ICE_FLTR_PTYPE_NONF_IPV6_UDP)\n\t\t\t\te->time_activated = get_jiffies_64();\n\t\t} else if (e->fltr_state == ICE_ARFS_ACTIVE) {\n\t\t\t \n\t\t\tif (ice_arfs_is_flow_expired(vsi, e)) {\n\t\t\t\t \n\t\t\t\thlist_del(&e->list_entry);\n\t\t\t\te->fltr_state = ICE_ARFS_TODEL;\n\t\t\t\t \n\t\t\t\thlist_add_head(&e->list_entry, del_list);\n\t\t\t}\n\t\t}\n}\n\n \nvoid ice_sync_arfs_fltrs(struct ice_pf *pf)\n{\n\tHLIST_HEAD(tmp_del_list);\n\tHLIST_HEAD(tmp_add_list);\n\tstruct ice_vsi *pf_vsi;\n\tunsigned int i;\n\n\tpf_vsi = ice_get_main_vsi(pf);\n\tif (!pf_vsi)\n\t\treturn;\n\n\tif (!ice_is_arfs_active(pf_vsi))\n\t\treturn;\n\n\tspin_lock_bh(&pf_vsi->arfs_lock);\n\t \n\tfor (i = 0; i < ICE_MAX_ARFS_LIST; i++)\n\t\tice_arfs_update_flow_rules(pf_vsi, i, &tmp_add_list,\n\t\t\t\t\t   &tmp_del_list);\n\tspin_unlock_bh(&pf_vsi->arfs_lock);\n\n\t \n\tice_arfs_del_flow_rules(pf_vsi, &tmp_del_list);\n\n\t \n\tice_arfs_add_flow_rules(pf_vsi, &tmp_add_list);\n}\n\n \nstatic struct ice_arfs_entry *\nice_arfs_build_entry(struct ice_vsi *vsi, const struct flow_keys *fk,\n\t\t     u16 rxq_idx, u32 flow_id)\n{\n\tstruct ice_arfs_entry *arfs_entry;\n\tstruct ice_fdir_fltr *fltr_info;\n\tu8 ip_proto;\n\n\tarfs_entry = devm_kzalloc(ice_pf_to_dev(vsi->back),\n\t\t\t\t  sizeof(*arfs_entry),\n\t\t\t\t  GFP_ATOMIC | __GFP_NOWARN);\n\tif (!arfs_entry)\n\t\treturn NULL;\n\n\tfltr_info = &arfs_entry->fltr_info;\n\tfltr_info->q_index = rxq_idx;\n\tfltr_info->dest_ctl = ICE_FLTR_PRGM_DESC_DEST_DIRECT_PKT_QINDEX;\n\tfltr_info->dest_vsi = vsi->idx;\n\tip_proto = fk->basic.ip_proto;\n\n\tif (fk->basic.n_proto == htons(ETH_P_IP)) {\n\t\tfltr_info->ip.v4.proto = ip_proto;\n\t\tfltr_info->flow_type = (ip_proto == IPPROTO_TCP) ?\n\t\t\tICE_FLTR_PTYPE_NONF_IPV4_TCP :\n\t\t\tICE_FLTR_PTYPE_NONF_IPV4_UDP;\n\t\tfltr_info->ip.v4.src_ip = fk->addrs.v4addrs.src;\n\t\tfltr_info->ip.v4.dst_ip = fk->addrs.v4addrs.dst;\n\t\tfltr_info->ip.v4.src_port = fk->ports.src;\n\t\tfltr_info->ip.v4.dst_port = fk->ports.dst;\n\t} else {  \n\t\tfltr_info->ip.v6.proto = ip_proto;\n\t\tfltr_info->flow_type = (ip_proto == IPPROTO_TCP) ?\n\t\t\tICE_FLTR_PTYPE_NONF_IPV6_TCP :\n\t\t\tICE_FLTR_PTYPE_NONF_IPV6_UDP;\n\t\tmemcpy(&fltr_info->ip.v6.src_ip, &fk->addrs.v6addrs.src,\n\t\t       sizeof(struct in6_addr));\n\t\tmemcpy(&fltr_info->ip.v6.dst_ip, &fk->addrs.v6addrs.dst,\n\t\t       sizeof(struct in6_addr));\n\t\tfltr_info->ip.v6.src_port = fk->ports.src;\n\t\tfltr_info->ip.v6.dst_port = fk->ports.dst;\n\t}\n\n\tarfs_entry->flow_id = flow_id;\n\tfltr_info->fltr_id =\n\t\tatomic_inc_return(vsi->arfs_last_fltr_id) % RPS_NO_FILTER;\n\n\treturn arfs_entry;\n}\n\n \nstatic bool\nice_arfs_is_perfect_flow_set(struct ice_hw *hw, __be16 l3_proto, u8 l4_proto)\n{\n\tunsigned long *perfect_fltr = hw->fdir_perfect_fltr;\n\n\t \n\tif (!perfect_fltr)\n\t\treturn true;\n\n\tif (l3_proto == htons(ETH_P_IP) && l4_proto == IPPROTO_UDP)\n\t\treturn test_bit(ICE_FLTR_PTYPE_NONF_IPV4_UDP, perfect_fltr);\n\telse if (l3_proto == htons(ETH_P_IP) && l4_proto == IPPROTO_TCP)\n\t\treturn test_bit(ICE_FLTR_PTYPE_NONF_IPV4_TCP, perfect_fltr);\n\telse if (l3_proto == htons(ETH_P_IPV6) && l4_proto == IPPROTO_UDP)\n\t\treturn test_bit(ICE_FLTR_PTYPE_NONF_IPV6_UDP, perfect_fltr);\n\telse if (l3_proto == htons(ETH_P_IPV6) && l4_proto == IPPROTO_TCP)\n\t\treturn test_bit(ICE_FLTR_PTYPE_NONF_IPV6_TCP, perfect_fltr);\n\n\treturn false;\n}\n\n \nint\nice_rx_flow_steer(struct net_device *netdev, const struct sk_buff *skb,\n\t\t  u16 rxq_idx, u32 flow_id)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(netdev);\n\tstruct ice_arfs_entry *arfs_entry;\n\tstruct ice_vsi *vsi = np->vsi;\n\tstruct flow_keys fk;\n\tstruct ice_pf *pf;\n\t__be16 n_proto;\n\tu8 ip_proto;\n\tu16 idx;\n\tint ret;\n\n\t \n\tif (unlikely(!vsi->arfs_fltr_list))\n\t\treturn -ENODEV;\n\n\tpf = vsi->back;\n\n\tif (skb->encapsulation)\n\t\treturn -EPROTONOSUPPORT;\n\n\tif (!skb_flow_dissect_flow_keys(skb, &fk, 0))\n\t\treturn -EPROTONOSUPPORT;\n\n\tn_proto = fk.basic.n_proto;\n\t \n\tif ((n_proto == htons(ETH_P_IP) && !ip_is_fragment(ip_hdr(skb))) ||\n\t    n_proto == htons(ETH_P_IPV6))\n\t\tip_proto = fk.basic.ip_proto;\n\telse\n\t\treturn -EPROTONOSUPPORT;\n\n\t \n\tif (ip_proto != IPPROTO_TCP && ip_proto != IPPROTO_UDP)\n\t\treturn -EPROTONOSUPPORT;\n\n\t \n\tif (!ice_arfs_is_perfect_flow_set(&pf->hw, n_proto, ip_proto))\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tidx = skb_get_hash_raw(skb) & ICE_ARFS_LST_MASK;\n\t \n\tspin_lock_bh(&vsi->arfs_lock);\n\thlist_for_each_entry(arfs_entry, &vsi->arfs_fltr_list[idx],\n\t\t\t     list_entry) {\n\t\tstruct ice_fdir_fltr *fltr_info;\n\n\t\t \n\t\tif (arfs_entry->flow_id != flow_id)\n\t\t\tcontinue;\n\n\t\tfltr_info = &arfs_entry->fltr_info;\n\t\tret = fltr_info->fltr_id;\n\n\t\tif (fltr_info->q_index == rxq_idx ||\n\t\t    arfs_entry->fltr_state != ICE_ARFS_ACTIVE)\n\t\t\tgoto out;\n\n\t\t \n\t\tfltr_info->q_index = rxq_idx;\n\t\tarfs_entry->fltr_state = ICE_ARFS_INACTIVE;\n\t\tice_arfs_update_active_fltr_cntrs(vsi, arfs_entry, false);\n\t\tgoto out_schedule_service_task;\n\t}\n\n\tarfs_entry = ice_arfs_build_entry(vsi, &fk, rxq_idx, flow_id);\n\tif (!arfs_entry) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = arfs_entry->fltr_info.fltr_id;\n\tINIT_HLIST_NODE(&arfs_entry->list_entry);\n\thlist_add_head(&arfs_entry->list_entry, &vsi->arfs_fltr_list[idx]);\nout_schedule_service_task:\n\tice_service_task_schedule(pf);\nout:\n\tspin_unlock_bh(&vsi->arfs_lock);\n\treturn ret;\n}\n\n \nstatic int ice_init_arfs_cntrs(struct ice_vsi *vsi)\n{\n\tif (!vsi || vsi->type != ICE_VSI_PF)\n\t\treturn -EINVAL;\n\n\tvsi->arfs_fltr_cntrs = kzalloc(sizeof(*vsi->arfs_fltr_cntrs),\n\t\t\t\t       GFP_KERNEL);\n\tif (!vsi->arfs_fltr_cntrs)\n\t\treturn -ENOMEM;\n\n\tvsi->arfs_last_fltr_id = kzalloc(sizeof(*vsi->arfs_last_fltr_id),\n\t\t\t\t\t GFP_KERNEL);\n\tif (!vsi->arfs_last_fltr_id) {\n\t\tkfree(vsi->arfs_fltr_cntrs);\n\t\tvsi->arfs_fltr_cntrs = NULL;\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\n \nvoid ice_init_arfs(struct ice_vsi *vsi)\n{\n\tstruct hlist_head *arfs_fltr_list;\n\tunsigned int i;\n\n\tif (!vsi || vsi->type != ICE_VSI_PF)\n\t\treturn;\n\n\tarfs_fltr_list = kcalloc(ICE_MAX_ARFS_LIST, sizeof(*arfs_fltr_list),\n\t\t\t\t GFP_KERNEL);\n\tif (!arfs_fltr_list)\n\t\treturn;\n\n\tif (ice_init_arfs_cntrs(vsi))\n\t\tgoto free_arfs_fltr_list;\n\n\tfor (i = 0; i < ICE_MAX_ARFS_LIST; i++)\n\t\tINIT_HLIST_HEAD(&arfs_fltr_list[i]);\n\n\tspin_lock_init(&vsi->arfs_lock);\n\n\tvsi->arfs_fltr_list = arfs_fltr_list;\n\n\treturn;\n\nfree_arfs_fltr_list:\n\tkfree(arfs_fltr_list);\n}\n\n \nvoid ice_clear_arfs(struct ice_vsi *vsi)\n{\n\tstruct device *dev;\n\tunsigned int i;\n\n\tif (!vsi || vsi->type != ICE_VSI_PF || !vsi->back ||\n\t    !vsi->arfs_fltr_list)\n\t\treturn;\n\n\tdev = ice_pf_to_dev(vsi->back);\n\tfor (i = 0; i < ICE_MAX_ARFS_LIST; i++) {\n\t\tstruct ice_arfs_entry *r;\n\t\tstruct hlist_node *n;\n\n\t\tspin_lock_bh(&vsi->arfs_lock);\n\t\thlist_for_each_entry_safe(r, n, &vsi->arfs_fltr_list[i],\n\t\t\t\t\t  list_entry) {\n\t\t\thlist_del(&r->list_entry);\n\t\t\tdevm_kfree(dev, r);\n\t\t}\n\t\tspin_unlock_bh(&vsi->arfs_lock);\n\t}\n\n\tkfree(vsi->arfs_fltr_list);\n\tvsi->arfs_fltr_list = NULL;\n\tkfree(vsi->arfs_last_fltr_id);\n\tvsi->arfs_last_fltr_id = NULL;\n\tkfree(vsi->arfs_fltr_cntrs);\n\tvsi->arfs_fltr_cntrs = NULL;\n}\n\n \nvoid ice_free_cpu_rx_rmap(struct ice_vsi *vsi)\n{\n\tstruct net_device *netdev;\n\n\tif (!vsi || vsi->type != ICE_VSI_PF)\n\t\treturn;\n\n\tnetdev = vsi->netdev;\n\tif (!netdev || !netdev->rx_cpu_rmap)\n\t\treturn;\n\n\tfree_irq_cpu_rmap(netdev->rx_cpu_rmap);\n\tnetdev->rx_cpu_rmap = NULL;\n}\n\n \nint ice_set_cpu_rx_rmap(struct ice_vsi *vsi)\n{\n\tstruct net_device *netdev;\n\tstruct ice_pf *pf;\n\tint i;\n\n\tif (!vsi || vsi->type != ICE_VSI_PF)\n\t\treturn 0;\n\n\tpf = vsi->back;\n\tnetdev = vsi->netdev;\n\tif (!pf || !netdev || !vsi->num_q_vectors)\n\t\treturn -EINVAL;\n\n\tnetdev_dbg(netdev, \"Setup CPU RMAP: vsi type 0x%x, ifname %s, q_vectors %d\\n\",\n\t\t   vsi->type, netdev->name, vsi->num_q_vectors);\n\n\tnetdev->rx_cpu_rmap = alloc_irq_cpu_rmap(vsi->num_q_vectors);\n\tif (unlikely(!netdev->rx_cpu_rmap))\n\t\treturn -EINVAL;\n\n\tice_for_each_q_vector(vsi, i)\n\t\tif (irq_cpu_rmap_add(netdev->rx_cpu_rmap,\n\t\t\t\t     vsi->q_vectors[i]->irq.virq)) {\n\t\t\tice_free_cpu_rx_rmap(vsi);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\treturn 0;\n}\n\n \nvoid ice_remove_arfs(struct ice_pf *pf)\n{\n\tstruct ice_vsi *pf_vsi;\n\n\tpf_vsi = ice_get_main_vsi(pf);\n\tif (!pf_vsi)\n\t\treturn;\n\n\tice_clear_arfs(pf_vsi);\n}\n\n \nvoid ice_rebuild_arfs(struct ice_pf *pf)\n{\n\tstruct ice_vsi *pf_vsi;\n\n\tpf_vsi = ice_get_main_vsi(pf);\n\tif (!pf_vsi)\n\t\treturn;\n\n\tice_remove_arfs(pf);\n\tice_init_arfs(pf_vsi);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}