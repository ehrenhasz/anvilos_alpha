{
  "module_name": "ice_txrx.h",
  "hash_id": "e356bb974d8f7149586796f903e6a576ce4b1917a5d4691a0bbf8fee05f7e065",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_txrx.h",
  "human_readable_source": " \n \n\n#ifndef _ICE_TXRX_H_\n#define _ICE_TXRX_H_\n\n#include \"ice_type.h\"\n\n#define ICE_DFLT_IRQ_WORK\t256\n#define ICE_RXBUF_3072\t\t3072\n#define ICE_RXBUF_2048\t\t2048\n#define ICE_RXBUF_1664\t\t1664\n#define ICE_RXBUF_1536\t\t1536\n#define ICE_MAX_CHAINED_RX_BUFS\t5\n#define ICE_MAX_BUF_TXD\t\t8\n#define ICE_MIN_TX_LEN\t\t17\n#define ICE_MAX_FRAME_LEGACY_RX 8320\n\n \n#define ICE_MAX_READ_REQ_SIZE\t4096\n#define ICE_MAX_DATA_PER_TXD\t(16 * 1024 - 1)\n#define ICE_MAX_DATA_PER_TXD_ALIGNED \\\n\t(~(ICE_MAX_READ_REQ_SIZE - 1) & ICE_MAX_DATA_PER_TXD)\n\n#define ICE_MAX_TXQ_PER_TXQG\t128\n\n \n#if (PAGE_SIZE < 8192)\n#define ICE_2K_TOO_SMALL_WITH_PADDING \\\n\t((unsigned int)(NET_SKB_PAD + ICE_RXBUF_1536) > \\\n\t\t\tSKB_WITH_OVERHEAD(ICE_RXBUF_2048))\n\n \nstatic inline int ice_compute_pad(int rx_buf_len)\n{\n\tint half_page_size;\n\n\thalf_page_size = ALIGN(rx_buf_len, PAGE_SIZE / 2);\n\treturn SKB_WITH_OVERHEAD(half_page_size) - rx_buf_len;\n}\n\n \nstatic inline int ice_skb_pad(void)\n{\n\tint rx_buf_len;\n\n\t \n\tif (ICE_2K_TOO_SMALL_WITH_PADDING)\n\t\trx_buf_len = ICE_RXBUF_3072 + SKB_DATA_ALIGN(NET_IP_ALIGN);\n\telse\n\t\trx_buf_len = ICE_RXBUF_1536;\n\n\t \n\trx_buf_len -= NET_IP_ALIGN;\n\n\treturn ice_compute_pad(rx_buf_len);\n}\n\n#define ICE_SKB_PAD ice_skb_pad()\n#else\n#define ICE_2K_TOO_SMALL_WITH_PADDING false\n#define ICE_SKB_PAD (NET_SKB_PAD + NET_IP_ALIGN)\n#endif\n\n \n#define ICE_CACHE_LINE_BYTES\t\t64\n#define ICE_DESCS_PER_CACHE_LINE\t(ICE_CACHE_LINE_BYTES / \\\n\t\t\t\t\t sizeof(struct ice_tx_desc))\n#define ICE_DESCS_FOR_CTX_DESC\t\t1\n#define ICE_DESCS_FOR_SKB_DATA_PTR\t1\n \n#define DESC_NEEDED (MAX_SKB_FRAGS + ICE_DESCS_FOR_CTX_DESC + \\\n\t\t     ICE_DESCS_PER_CACHE_LINE + ICE_DESCS_FOR_SKB_DATA_PTR)\n#define ICE_DESC_UNUSED(R)\t\\\n\t(u16)((((R)->next_to_clean > (R)->next_to_use) ? 0 : (R)->count) + \\\n\t      (R)->next_to_clean - (R)->next_to_use - 1)\n\n#define ICE_RX_DESC_UNUSED(R)\t\\\n\t((((R)->first_desc > (R)->next_to_use) ? 0 : (R)->count) + \\\n\t      (R)->first_desc - (R)->next_to_use - 1)\n\n#define ICE_RING_QUARTER(R) ((R)->count >> 2)\n\n#define ICE_TX_FLAGS_TSO\tBIT(0)\n#define ICE_TX_FLAGS_HW_VLAN\tBIT(1)\n#define ICE_TX_FLAGS_SW_VLAN\tBIT(2)\n \n#define ICE_TX_FLAGS_TSYN\tBIT(4)\n#define ICE_TX_FLAGS_IPV4\tBIT(5)\n#define ICE_TX_FLAGS_IPV6\tBIT(6)\n#define ICE_TX_FLAGS_TUNNEL\tBIT(7)\n#define ICE_TX_FLAGS_HW_OUTER_SINGLE_VLAN\tBIT(8)\n\n#define ICE_XDP_PASS\t\t0\n#define ICE_XDP_CONSUMED\tBIT(0)\n#define ICE_XDP_TX\t\tBIT(1)\n#define ICE_XDP_REDIR\t\tBIT(2)\n#define ICE_XDP_EXIT\t\tBIT(3)\n#define ICE_SKB_CONSUMED\tICE_XDP_CONSUMED\n\n#define ICE_RX_DMA_ATTR \\\n\t(DMA_ATTR_SKIP_CPU_SYNC | DMA_ATTR_WEAK_ORDERING)\n\n#define ICE_ETH_PKT_HDR_PAD\t(ETH_HLEN + ETH_FCS_LEN + (VLAN_HLEN * 2))\n\n#define ICE_TXD_LAST_DESC_CMD (ICE_TX_DESC_CMD_EOP | ICE_TX_DESC_CMD_RS)\n\n \nenum ice_tx_buf_type {\n\tICE_TX_BUF_EMPTY\t= 0U,\n\tICE_TX_BUF_DUMMY,\n\tICE_TX_BUF_FRAG,\n\tICE_TX_BUF_SKB,\n\tICE_TX_BUF_XDP_TX,\n\tICE_TX_BUF_XDP_XMIT,\n\tICE_TX_BUF_XSK_TX,\n};\n\nstruct ice_tx_buf {\n\tunion {\n\t\tstruct ice_tx_desc *next_to_watch;\n\t\tu32 rs_idx;\n\t};\n\tunion {\n\t\tvoid *raw_buf;\t\t \n\t\tstruct sk_buff *skb;\t \n\t\tstruct xdp_frame *xdpf;\t \n\t\tstruct xdp_buff *xdp;\t \n\t};\n\tunsigned int bytecount;\n\tunion {\n\t\tunsigned int gso_segs;\n\t\tunsigned int nr_frags;\t \n\t};\n\tu32 tx_flags:12;\n\tu32 type:4;\t\t\t \n\tu32 vid:16;\n\tDEFINE_DMA_UNMAP_LEN(len);\n\tDEFINE_DMA_UNMAP_ADDR(dma);\n};\n\nstruct ice_tx_offload_params {\n\tu64 cd_qw1;\n\tstruct ice_tx_ring *tx_ring;\n\tu32 td_cmd;\n\tu32 td_offset;\n\tu32 td_l2tag1;\n\tu32 cd_tunnel_params;\n\tu16 cd_l2tag2;\n\tu8 header_len;\n};\n\nstruct ice_rx_buf {\n\tdma_addr_t dma;\n\tstruct page *page;\n\tunsigned int page_offset;\n\tunsigned int pgcnt;\n\tunsigned int act;\n\tunsigned int pagecnt_bias;\n};\n\nstruct ice_q_stats {\n\tu64 pkts;\n\tu64 bytes;\n};\n\nstruct ice_txq_stats {\n\tu64 restart_q;\n\tu64 tx_busy;\n\tu64 tx_linearize;\n\tint prev_pkt;  \n};\n\nstruct ice_rxq_stats {\n\tu64 non_eop_descs;\n\tu64 alloc_page_failed;\n\tu64 alloc_buf_failed;\n};\n\nstruct ice_ring_stats {\n\tstruct rcu_head rcu;\t \n\tstruct ice_q_stats stats;\n\tstruct u64_stats_sync syncp;\n\tunion {\n\t\tstruct ice_txq_stats tx_stats;\n\t\tstruct ice_rxq_stats rx_stats;\n\t};\n};\n\nenum ice_ring_state_t {\n\tICE_TX_XPS_INIT_DONE,\n\tICE_TX_NBITS,\n};\n\n \nenum ice_dyn_idx_t {\n\tICE_IDX_ITR0 = 0,\n\tICE_IDX_ITR1 = 1,\n\tICE_IDX_ITR2 = 2,\n\tICE_ITR_NONE = 3\t \n};\n\n \nenum ice_rx_dtype {\n\tICE_RX_DTYPE_NO_SPLIT\t\t= 0,\n\tICE_RX_DTYPE_HEADER_SPLIT\t= 1,\n\tICE_RX_DTYPE_SPLIT_ALWAYS\t= 2,\n};\n\n \n#define ICE_RX_ITR\tICE_IDX_ITR0\n#define ICE_TX_ITR\tICE_IDX_ITR1\n#define ICE_ITR_8K\t124\n#define ICE_ITR_20K\t50\n#define ICE_ITR_MAX\t8160  \n#define ICE_DFLT_TX_ITR\tICE_ITR_20K\n#define ICE_DFLT_RX_ITR\tICE_ITR_20K\nenum ice_dynamic_itr {\n\tITR_STATIC = 0,\n\tITR_DYNAMIC = 1\n};\n\n#define ITR_IS_DYNAMIC(rc) ((rc)->itr_mode == ITR_DYNAMIC)\n#define ICE_ITR_GRAN_S\t\t1\t \n#define ICE_ITR_GRAN_US\t\tBIT(ICE_ITR_GRAN_S)\n#define ICE_ITR_MASK\t\t0x1FFE\t \n#define ITR_REG_ALIGN(setting)\t((setting) & ICE_ITR_MASK)\n\n#define ICE_DFLT_INTRL\t0\n#define ICE_MAX_INTRL\t236\n\n#define ICE_IN_WB_ON_ITR_MODE\t255\n \n#define ICE_GLINT_DYN_CTL_WB_ON_ITR(usecs, itr_idx)\t\\\n\t((((usecs) << (GLINT_DYN_CTL_INTERVAL_S - ICE_ITR_GRAN_S)) & \\\n\t  GLINT_DYN_CTL_INTERVAL_M) | \\\n\t (((itr_idx) << GLINT_DYN_CTL_ITR_INDX_S) & \\\n\t  GLINT_DYN_CTL_ITR_INDX_M) | GLINT_DYN_CTL_INTENA_MSK_M | \\\n\t GLINT_DYN_CTL_WB_ON_ITR_M)\n\n \n#define ICE_TX_ADVANCED\t0\n#define ICE_TX_LEGACY\t1\n\n \nstruct ice_rx_ring {\n\t \n\tstruct ice_rx_ring *next;\t \n\tvoid *desc;\t\t\t \n\tstruct device *dev;\t\t \n\tstruct net_device *netdev;\t \n\tstruct ice_vsi *vsi;\t\t \n\tstruct ice_q_vector *q_vector;\t \n\tu8 __iomem *tail;\n\tu16 q_index;\t\t\t \n\n\tu16 count;\t\t\t \n\tu16 reg_idx;\t\t\t \n\tu16 next_to_alloc;\n\t \n\tunion {\n\t\tstruct ice_rx_buf *rx_buf;\n\t\tstruct xdp_buff **xdp_buf;\n\t};\n\tstruct xdp_buff xdp;\n\t \n\tstruct bpf_prog *xdp_prog;\n\tu16 rx_offset;\n\n\t \n\tu16 next_to_use;\n\tu16 next_to_clean;\n\tu16 first_desc;\n\n\t \n\tstruct ice_ring_stats *ring_stats;\n\n\tstruct rcu_head rcu;\t\t \n\t \n\tstruct ice_channel *ch;\n\tstruct ice_tx_ring *xdp_ring;\n\tstruct xsk_buff_pool *xsk_pool;\n\tdma_addr_t dma;\t\t\t \n\tu64 cached_phctime;\n\tu16 rx_buf_len;\n\tu8 dcb_tc;\t\t\t \n\tu8 ptp_rx;\n#define ICE_RX_FLAGS_RING_BUILD_SKB\tBIT(1)\n#define ICE_RX_FLAGS_CRC_STRIP_DIS\tBIT(2)\n\tu8 flags;\n\t \n\tstruct xdp_rxq_info xdp_rxq;\n} ____cacheline_internodealigned_in_smp;\n\nstruct ice_tx_ring {\n\t \n\tstruct ice_tx_ring *next;\t \n\tvoid *desc;\t\t\t \n\tstruct device *dev;\t\t \n\tu8 __iomem *tail;\n\tstruct ice_tx_buf *tx_buf;\n\tstruct ice_q_vector *q_vector;\t \n\tstruct net_device *netdev;\t \n\tstruct ice_vsi *vsi;\t\t \n\t \n\tdma_addr_t dma;\t\t\t \n\tstruct xsk_buff_pool *xsk_pool;\n\tu16 next_to_use;\n\tu16 next_to_clean;\n\tu16 q_handle;\t\t\t \n\tu16 reg_idx;\t\t\t \n\tu16 count;\t\t\t \n\tu16 q_index;\t\t\t \n\tu16 xdp_tx_active;\n\t \n\tstruct ice_ring_stats *ring_stats;\n\t \n\tstruct rcu_head rcu;\t\t \n\tDECLARE_BITMAP(xps_state, ICE_TX_NBITS);\t \n\tstruct ice_channel *ch;\n\tstruct ice_ptp_tx *tx_tstamps;\n\tspinlock_t tx_lock;\n\tu32 txq_teid;\t\t\t \n\t \n#define ICE_TX_FLAGS_RING_XDP\t\tBIT(0)\n#define ICE_TX_FLAGS_RING_VLAN_L2TAG1\tBIT(1)\n#define ICE_TX_FLAGS_RING_VLAN_L2TAG2\tBIT(2)\n\tu8 flags;\n\tu8 dcb_tc;\t\t\t \n\tu8 ptp_tx;\n} ____cacheline_internodealigned_in_smp;\n\nstatic inline bool ice_ring_uses_build_skb(struct ice_rx_ring *ring)\n{\n\treturn !!(ring->flags & ICE_RX_FLAGS_RING_BUILD_SKB);\n}\n\nstatic inline void ice_set_ring_build_skb_ena(struct ice_rx_ring *ring)\n{\n\tring->flags |= ICE_RX_FLAGS_RING_BUILD_SKB;\n}\n\nstatic inline void ice_clear_ring_build_skb_ena(struct ice_rx_ring *ring)\n{\n\tring->flags &= ~ICE_RX_FLAGS_RING_BUILD_SKB;\n}\n\nstatic inline bool ice_ring_ch_enabled(struct ice_tx_ring *ring)\n{\n\treturn !!ring->ch;\n}\n\nstatic inline bool ice_ring_is_xdp(struct ice_tx_ring *ring)\n{\n\treturn !!(ring->flags & ICE_TX_FLAGS_RING_XDP);\n}\n\nenum ice_container_type {\n\tICE_RX_CONTAINER,\n\tICE_TX_CONTAINER,\n};\n\nstruct ice_ring_container {\n\t \n\tunion {\n\t\tstruct ice_rx_ring *rx_ring;\n\t\tstruct ice_tx_ring *tx_ring;\n\t};\n\tstruct dim dim;\t\t \n\tu16 itr_idx;\t\t \n\t \n\tunion {\n\t\tstruct {\n\t\t\tu16 itr_setting:13;\n\t\t\tu16 itr_reserved:2;\n\t\t\tu16 itr_mode:1;\n\t\t};\n\t\tu16 itr_settings;\n\t};\n\tenum ice_container_type type;\n};\n\nstruct ice_coalesce_stored {\n\tu16 itr_tx;\n\tu16 itr_rx;\n\tu8 intrl;\n\tu8 tx_valid;\n\tu8 rx_valid;\n};\n\n \n#define ice_for_each_rx_ring(pos, head) \\\n\tfor (pos = (head).rx_ring; pos; pos = pos->next)\n\n#define ice_for_each_tx_ring(pos, head) \\\n\tfor (pos = (head).tx_ring; pos; pos = pos->next)\n\nstatic inline unsigned int ice_rx_pg_order(struct ice_rx_ring *ring)\n{\n#if (PAGE_SIZE < 8192)\n\tif (ring->rx_buf_len > (PAGE_SIZE / 2))\n\t\treturn 1;\n#endif\n\treturn 0;\n}\n\n#define ice_rx_pg_size(_ring) (PAGE_SIZE << ice_rx_pg_order(_ring))\n\nunion ice_32b_rx_flex_desc;\n\nbool ice_alloc_rx_bufs(struct ice_rx_ring *rxr, unsigned int cleaned_count);\nnetdev_tx_t ice_start_xmit(struct sk_buff *skb, struct net_device *netdev);\nu16\nice_select_queue(struct net_device *dev, struct sk_buff *skb,\n\t\t struct net_device *sb_dev);\nvoid ice_clean_tx_ring(struct ice_tx_ring *tx_ring);\nvoid ice_clean_rx_ring(struct ice_rx_ring *rx_ring);\nint ice_setup_tx_ring(struct ice_tx_ring *tx_ring);\nint ice_setup_rx_ring(struct ice_rx_ring *rx_ring);\nvoid ice_free_tx_ring(struct ice_tx_ring *tx_ring);\nvoid ice_free_rx_ring(struct ice_rx_ring *rx_ring);\nint ice_napi_poll(struct napi_struct *napi, int budget);\nint\nice_prgm_fdir_fltr(struct ice_vsi *vsi, struct ice_fltr_desc *fdir_desc,\n\t\t   u8 *raw_packet);\nint ice_clean_rx_irq(struct ice_rx_ring *rx_ring, int budget);\nvoid ice_clean_ctrl_tx_irq(struct ice_tx_ring *tx_ring);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}