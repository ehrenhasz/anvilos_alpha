{
  "module_name": "ice_common.c",
  "hash_id": "20c65a7b8626bff33518051af1cd6f65ff1a974fd344fd39db053a516c3a9cd1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_common.c",
  "human_readable_source": "\n \n\n#include \"ice_common.h\"\n#include \"ice_sched.h\"\n#include \"ice_adminq_cmd.h\"\n#include \"ice_flow.h\"\n#include \"ice_ptp_hw.h\"\n\n#define ICE_PF_RESET_WAIT_COUNT\t300\n\nstatic const char * const ice_link_mode_str_low[] = {\n\t[0] = \"100BASE_TX\",\n\t[1] = \"100M_SGMII\",\n\t[2] = \"1000BASE_T\",\n\t[3] = \"1000BASE_SX\",\n\t[4] = \"1000BASE_LX\",\n\t[5] = \"1000BASE_KX\",\n\t[6] = \"1G_SGMII\",\n\t[7] = \"2500BASE_T\",\n\t[8] = \"2500BASE_X\",\n\t[9] = \"2500BASE_KX\",\n\t[10] = \"5GBASE_T\",\n\t[11] = \"5GBASE_KR\",\n\t[12] = \"10GBASE_T\",\n\t[13] = \"10G_SFI_DA\",\n\t[14] = \"10GBASE_SR\",\n\t[15] = \"10GBASE_LR\",\n\t[16] = \"10GBASE_KR_CR1\",\n\t[17] = \"10G_SFI_AOC_ACC\",\n\t[18] = \"10G_SFI_C2C\",\n\t[19] = \"25GBASE_T\",\n\t[20] = \"25GBASE_CR\",\n\t[21] = \"25GBASE_CR_S\",\n\t[22] = \"25GBASE_CR1\",\n\t[23] = \"25GBASE_SR\",\n\t[24] = \"25GBASE_LR\",\n\t[25] = \"25GBASE_KR\",\n\t[26] = \"25GBASE_KR_S\",\n\t[27] = \"25GBASE_KR1\",\n\t[28] = \"25G_AUI_AOC_ACC\",\n\t[29] = \"25G_AUI_C2C\",\n\t[30] = \"40GBASE_CR4\",\n\t[31] = \"40GBASE_SR4\",\n\t[32] = \"40GBASE_LR4\",\n\t[33] = \"40GBASE_KR4\",\n\t[34] = \"40G_XLAUI_AOC_ACC\",\n\t[35] = \"40G_XLAUI\",\n\t[36] = \"50GBASE_CR2\",\n\t[37] = \"50GBASE_SR2\",\n\t[38] = \"50GBASE_LR2\",\n\t[39] = \"50GBASE_KR2\",\n\t[40] = \"50G_LAUI2_AOC_ACC\",\n\t[41] = \"50G_LAUI2\",\n\t[42] = \"50G_AUI2_AOC_ACC\",\n\t[43] = \"50G_AUI2\",\n\t[44] = \"50GBASE_CP\",\n\t[45] = \"50GBASE_SR\",\n\t[46] = \"50GBASE_FR\",\n\t[47] = \"50GBASE_LR\",\n\t[48] = \"50GBASE_KR_PAM4\",\n\t[49] = \"50G_AUI1_AOC_ACC\",\n\t[50] = \"50G_AUI1\",\n\t[51] = \"100GBASE_CR4\",\n\t[52] = \"100GBASE_SR4\",\n\t[53] = \"100GBASE_LR4\",\n\t[54] = \"100GBASE_KR4\",\n\t[55] = \"100G_CAUI4_AOC_ACC\",\n\t[56] = \"100G_CAUI4\",\n\t[57] = \"100G_AUI4_AOC_ACC\",\n\t[58] = \"100G_AUI4\",\n\t[59] = \"100GBASE_CR_PAM4\",\n\t[60] = \"100GBASE_KR_PAM4\",\n\t[61] = \"100GBASE_CP2\",\n\t[62] = \"100GBASE_SR2\",\n\t[63] = \"100GBASE_DR\",\n};\n\nstatic const char * const ice_link_mode_str_high[] = {\n\t[0] = \"100GBASE_KR2_PAM4\",\n\t[1] = \"100G_CAUI2_AOC_ACC\",\n\t[2] = \"100G_CAUI2\",\n\t[3] = \"100G_AUI2_AOC_ACC\",\n\t[4] = \"100G_AUI2\",\n};\n\n \nstatic void\nice_dump_phy_type(struct ice_hw *hw, u64 low, u64 high, const char *prefix)\n{\n\tice_debug(hw, ICE_DBG_PHY, \"%s: phy_type_low: 0x%016llx\\n\", prefix, low);\n\n\tfor (u32 i = 0; i < BITS_PER_TYPE(typeof(low)); i++) {\n\t\tif (low & BIT_ULL(i))\n\t\t\tice_debug(hw, ICE_DBG_PHY, \"%s:   bit(%d): %s\\n\",\n\t\t\t\t  prefix, i, ice_link_mode_str_low[i]);\n\t}\n\n\tice_debug(hw, ICE_DBG_PHY, \"%s: phy_type_high: 0x%016llx\\n\", prefix, high);\n\n\tfor (u32 i = 0; i < BITS_PER_TYPE(typeof(high)); i++) {\n\t\tif (high & BIT_ULL(i))\n\t\t\tice_debug(hw, ICE_DBG_PHY, \"%s:   bit(%d): %s\\n\",\n\t\t\t\t  prefix, i, ice_link_mode_str_high[i]);\n\t}\n}\n\n \nstatic int ice_set_mac_type(struct ice_hw *hw)\n{\n\tif (hw->vendor_id != PCI_VENDOR_ID_INTEL)\n\t\treturn -ENODEV;\n\n\tswitch (hw->device_id) {\n\tcase ICE_DEV_ID_E810C_BACKPLANE:\n\tcase ICE_DEV_ID_E810C_QSFP:\n\tcase ICE_DEV_ID_E810C_SFP:\n\tcase ICE_DEV_ID_E810_XXV_BACKPLANE:\n\tcase ICE_DEV_ID_E810_XXV_QSFP:\n\tcase ICE_DEV_ID_E810_XXV_SFP:\n\t\thw->mac_type = ICE_MAC_E810;\n\t\tbreak;\n\tcase ICE_DEV_ID_E823C_10G_BASE_T:\n\tcase ICE_DEV_ID_E823C_BACKPLANE:\n\tcase ICE_DEV_ID_E823C_QSFP:\n\tcase ICE_DEV_ID_E823C_SFP:\n\tcase ICE_DEV_ID_E823C_SGMII:\n\tcase ICE_DEV_ID_E822C_10G_BASE_T:\n\tcase ICE_DEV_ID_E822C_BACKPLANE:\n\tcase ICE_DEV_ID_E822C_QSFP:\n\tcase ICE_DEV_ID_E822C_SFP:\n\tcase ICE_DEV_ID_E822C_SGMII:\n\tcase ICE_DEV_ID_E822L_10G_BASE_T:\n\tcase ICE_DEV_ID_E822L_BACKPLANE:\n\tcase ICE_DEV_ID_E822L_SFP:\n\tcase ICE_DEV_ID_E822L_SGMII:\n\tcase ICE_DEV_ID_E823L_10G_BASE_T:\n\tcase ICE_DEV_ID_E823L_1GBE:\n\tcase ICE_DEV_ID_E823L_BACKPLANE:\n\tcase ICE_DEV_ID_E823L_QSFP:\n\tcase ICE_DEV_ID_E823L_SFP:\n\t\thw->mac_type = ICE_MAC_GENERIC;\n\t\tbreak;\n\tdefault:\n\t\thw->mac_type = ICE_MAC_UNKNOWN;\n\t\tbreak;\n\t}\n\n\tice_debug(hw, ICE_DBG_INIT, \"mac_type: %d\\n\", hw->mac_type);\n\treturn 0;\n}\n\n \nbool ice_is_e810(struct ice_hw *hw)\n{\n\treturn hw->mac_type == ICE_MAC_E810;\n}\n\n \nbool ice_is_e810t(struct ice_hw *hw)\n{\n\tswitch (hw->device_id) {\n\tcase ICE_DEV_ID_E810C_SFP:\n\t\tswitch (hw->subsystem_device_id) {\n\t\tcase ICE_SUBDEV_ID_E810T:\n\t\tcase ICE_SUBDEV_ID_E810T2:\n\t\tcase ICE_SUBDEV_ID_E810T3:\n\t\tcase ICE_SUBDEV_ID_E810T4:\n\t\tcase ICE_SUBDEV_ID_E810T6:\n\t\tcase ICE_SUBDEV_ID_E810T7:\n\t\t\treturn true;\n\t\t}\n\t\tbreak;\n\tcase ICE_DEV_ID_E810C_QSFP:\n\t\tswitch (hw->subsystem_device_id) {\n\t\tcase ICE_SUBDEV_ID_E810T2:\n\t\tcase ICE_SUBDEV_ID_E810T3:\n\t\tcase ICE_SUBDEV_ID_E810T5:\n\t\t\treturn true;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn false;\n}\n\n \nbool ice_is_e823(struct ice_hw *hw)\n{\n\tswitch (hw->device_id) {\n\tcase ICE_DEV_ID_E823L_BACKPLANE:\n\tcase ICE_DEV_ID_E823L_SFP:\n\tcase ICE_DEV_ID_E823L_10G_BASE_T:\n\tcase ICE_DEV_ID_E823L_1GBE:\n\tcase ICE_DEV_ID_E823L_QSFP:\n\tcase ICE_DEV_ID_E823C_BACKPLANE:\n\tcase ICE_DEV_ID_E823C_QSFP:\n\tcase ICE_DEV_ID_E823C_SFP:\n\tcase ICE_DEV_ID_E823C_10G_BASE_T:\n\tcase ICE_DEV_ID_E823C_SGMII:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nint ice_clear_pf_cfg(struct ice_hw *hw)\n{\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_clear_pf_cfg);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, NULL);\n}\n\n \nstatic int\nice_aq_manage_mac_read(struct ice_hw *hw, void *buf, u16 buf_size,\n\t\t       struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_manage_mac_read_resp *resp;\n\tstruct ice_aqc_manage_mac_read *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\tu16 flags;\n\tu8 i;\n\n\tcmd = &desc.params.mac_read;\n\n\tif (buf_size < sizeof(*resp))\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_manage_mac_read);\n\n\tstatus = ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n\tif (status)\n\t\treturn status;\n\n\tresp = buf;\n\tflags = le16_to_cpu(cmd->flags) & ICE_AQC_MAN_MAC_READ_M;\n\n\tif (!(flags & ICE_AQC_MAN_MAC_LAN_ADDR_VALID)) {\n\t\tice_debug(hw, ICE_DBG_LAN, \"got invalid MAC address\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\tfor (i = 0; i < cmd->num_addr; i++)\n\t\tif (resp[i].addr_type == ICE_AQC_MAN_MAC_ADDR_TYPE_LAN) {\n\t\t\tether_addr_copy(hw->port_info->mac.lan_addr,\n\t\t\t\t\tresp[i].mac_addr);\n\t\t\tether_addr_copy(hw->port_info->mac.perm_addr,\n\t\t\t\t\tresp[i].mac_addr);\n\t\t\tbreak;\n\t\t}\n\n\treturn 0;\n}\n\n \nint\nice_aq_get_phy_caps(struct ice_port_info *pi, bool qual_mods, u8 report_mode,\n\t\t    struct ice_aqc_get_phy_caps_data *pcaps,\n\t\t    struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_get_phy_caps *cmd;\n\tu16 pcaps_size = sizeof(*pcaps);\n\tstruct ice_aq_desc desc;\n\tconst char *prefix;\n\tstruct ice_hw *hw;\n\tint status;\n\n\tcmd = &desc.params.get_phy;\n\n\tif (!pcaps || (report_mode & ~ICE_AQC_REPORT_MODE_M) || !pi)\n\t\treturn -EINVAL;\n\thw = pi->hw;\n\n\tif (report_mode == ICE_AQC_REPORT_DFLT_CFG &&\n\t    !ice_fw_supports_report_dflt_cfg(hw))\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_phy_caps);\n\n\tif (qual_mods)\n\t\tcmd->param0 |= cpu_to_le16(ICE_AQC_GET_PHY_RQM);\n\n\tcmd->param0 |= cpu_to_le16(report_mode);\n\tstatus = ice_aq_send_cmd(hw, &desc, pcaps, pcaps_size, cd);\n\n\tice_debug(hw, ICE_DBG_LINK, \"get phy caps dump\\n\");\n\n\tswitch (report_mode) {\n\tcase ICE_AQC_REPORT_TOPO_CAP_MEDIA:\n\t\tprefix = \"phy_caps_media\";\n\t\tbreak;\n\tcase ICE_AQC_REPORT_TOPO_CAP_NO_MEDIA:\n\t\tprefix = \"phy_caps_no_media\";\n\t\tbreak;\n\tcase ICE_AQC_REPORT_ACTIVE_CFG:\n\t\tprefix = \"phy_caps_active\";\n\t\tbreak;\n\tcase ICE_AQC_REPORT_DFLT_CFG:\n\t\tprefix = \"phy_caps_default\";\n\t\tbreak;\n\tdefault:\n\t\tprefix = \"phy_caps_invalid\";\n\t}\n\n\tice_dump_phy_type(hw, le64_to_cpu(pcaps->phy_type_low),\n\t\t\t  le64_to_cpu(pcaps->phy_type_high), prefix);\n\n\tice_debug(hw, ICE_DBG_LINK, \"%s: report_mode = 0x%x\\n\",\n\t\t  prefix, report_mode);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: caps = 0x%x\\n\", prefix, pcaps->caps);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: low_power_ctrl_an = 0x%x\\n\", prefix,\n\t\t  pcaps->low_power_ctrl_an);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: eee_cap = 0x%x\\n\", prefix,\n\t\t  pcaps->eee_cap);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: eeer_value = 0x%x\\n\", prefix,\n\t\t  pcaps->eeer_value);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: link_fec_options = 0x%x\\n\", prefix,\n\t\t  pcaps->link_fec_options);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: module_compliance_enforcement = 0x%x\\n\",\n\t\t  prefix, pcaps->module_compliance_enforcement);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: extended_compliance_code = 0x%x\\n\",\n\t\t  prefix, pcaps->extended_compliance_code);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: module_type[0] = 0x%x\\n\", prefix,\n\t\t  pcaps->module_type[0]);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: module_type[1] = 0x%x\\n\", prefix,\n\t\t  pcaps->module_type[1]);\n\tice_debug(hw, ICE_DBG_LINK, \"%s: module_type[2] = 0x%x\\n\", prefix,\n\t\t  pcaps->module_type[2]);\n\n\tif (!status && report_mode == ICE_AQC_REPORT_TOPO_CAP_MEDIA) {\n\t\tpi->phy.phy_type_low = le64_to_cpu(pcaps->phy_type_low);\n\t\tpi->phy.phy_type_high = le64_to_cpu(pcaps->phy_type_high);\n\t\tmemcpy(pi->phy.link_info.module_type, &pcaps->module_type,\n\t\t       sizeof(pi->phy.link_info.module_type));\n\t}\n\n\treturn status;\n}\n\n \nstatic int\nice_aq_get_link_topo_handle(struct ice_port_info *pi, u8 node_type,\n\t\t\t    struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_get_link_topo *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.get_link_topo;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_link_topo);\n\n\tcmd->addr.topo_params.node_type_ctx =\n\t\t(ICE_AQC_LINK_TOPO_NODE_CTX_PORT <<\n\t\t ICE_AQC_LINK_TOPO_NODE_CTX_S);\n\n\t \n\tcmd->addr.topo_params.node_type_ctx |=\n\t\t(ICE_AQC_LINK_TOPO_NODE_TYPE_M & node_type);\n\n\treturn ice_aq_send_cmd(pi->hw, &desc, NULL, 0, cd);\n}\n\n \nstatic bool ice_is_media_cage_present(struct ice_port_info *pi)\n{\n\t \n\treturn !ice_aq_get_link_topo_handle(pi,\n\t\t\t\t\t    ICE_AQC_LINK_TOPO_NODE_TYPE_CAGE,\n\t\t\t\t\t    NULL);\n}\n\n \nstatic enum ice_media_type ice_get_media_type(struct ice_port_info *pi)\n{\n\tstruct ice_link_status *hw_link_info;\n\n\tif (!pi)\n\t\treturn ICE_MEDIA_UNKNOWN;\n\n\thw_link_info = &pi->phy.link_info;\n\tif (hw_link_info->phy_type_low && hw_link_info->phy_type_high)\n\t\t \n\t\treturn ICE_MEDIA_UNKNOWN;\n\n\tif (hw_link_info->phy_type_low) {\n\t\t \n\t\tif (hw_link_info->phy_type_low == ICE_PHY_TYPE_LOW_1G_SGMII &&\n\t\t    (hw_link_info->module_type[ICE_AQC_MOD_TYPE_IDENT] ==\n\t\t    ICE_AQC_MOD_TYPE_BYTE1_SFP_PLUS_CU_ACTIVE ||\n\t\t    hw_link_info->module_type[ICE_AQC_MOD_TYPE_IDENT] ==\n\t\t    ICE_AQC_MOD_TYPE_BYTE1_SFP_PLUS_CU_PASSIVE))\n\t\t\treturn ICE_MEDIA_DA;\n\n\t\tswitch (hw_link_info->phy_type_low) {\n\t\tcase ICE_PHY_TYPE_LOW_1000BASE_SX:\n\t\tcase ICE_PHY_TYPE_LOW_1000BASE_LX:\n\t\tcase ICE_PHY_TYPE_LOW_10GBASE_SR:\n\t\tcase ICE_PHY_TYPE_LOW_10GBASE_LR:\n\t\tcase ICE_PHY_TYPE_LOW_10G_SFI_C2C:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_SR:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_LR:\n\t\tcase ICE_PHY_TYPE_LOW_40GBASE_SR4:\n\t\tcase ICE_PHY_TYPE_LOW_40GBASE_LR4:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_SR2:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_LR2:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_SR:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_FR:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_LR:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_SR4:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_LR4:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_SR2:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_DR:\n\t\tcase ICE_PHY_TYPE_LOW_10G_SFI_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_LOW_25G_AUI_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_LOW_40G_XLAUI_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_LOW_50G_LAUI2_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_LOW_50G_AUI2_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_LOW_50G_AUI1_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_LOW_100G_CAUI4_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_LOW_100G_AUI4_AOC_ACC:\n\t\t\treturn ICE_MEDIA_FIBER;\n\t\tcase ICE_PHY_TYPE_LOW_100BASE_TX:\n\t\tcase ICE_PHY_TYPE_LOW_1000BASE_T:\n\t\tcase ICE_PHY_TYPE_LOW_2500BASE_T:\n\t\tcase ICE_PHY_TYPE_LOW_5GBASE_T:\n\t\tcase ICE_PHY_TYPE_LOW_10GBASE_T:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_T:\n\t\t\treturn ICE_MEDIA_BASET;\n\t\tcase ICE_PHY_TYPE_LOW_10G_SFI_DA:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_CR:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_CR_S:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_CR1:\n\t\tcase ICE_PHY_TYPE_LOW_40GBASE_CR4:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_CR2:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_CP:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_CR4:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_CR_PAM4:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_CP2:\n\t\t\treturn ICE_MEDIA_DA;\n\t\tcase ICE_PHY_TYPE_LOW_25G_AUI_C2C:\n\t\tcase ICE_PHY_TYPE_LOW_40G_XLAUI:\n\t\tcase ICE_PHY_TYPE_LOW_50G_LAUI2:\n\t\tcase ICE_PHY_TYPE_LOW_50G_AUI2:\n\t\tcase ICE_PHY_TYPE_LOW_50G_AUI1:\n\t\tcase ICE_PHY_TYPE_LOW_100G_AUI4:\n\t\tcase ICE_PHY_TYPE_LOW_100G_CAUI4:\n\t\t\tif (ice_is_media_cage_present(pi))\n\t\t\t\treturn ICE_MEDIA_DA;\n\t\t\tfallthrough;\n\t\tcase ICE_PHY_TYPE_LOW_1000BASE_KX:\n\t\tcase ICE_PHY_TYPE_LOW_2500BASE_KX:\n\t\tcase ICE_PHY_TYPE_LOW_2500BASE_X:\n\t\tcase ICE_PHY_TYPE_LOW_5GBASE_KR:\n\t\tcase ICE_PHY_TYPE_LOW_10GBASE_KR_CR1:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_KR:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_KR1:\n\t\tcase ICE_PHY_TYPE_LOW_25GBASE_KR_S:\n\t\tcase ICE_PHY_TYPE_LOW_40GBASE_KR4:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_KR_PAM4:\n\t\tcase ICE_PHY_TYPE_LOW_50GBASE_KR2:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_KR4:\n\t\tcase ICE_PHY_TYPE_LOW_100GBASE_KR_PAM4:\n\t\t\treturn ICE_MEDIA_BACKPLANE;\n\t\t}\n\t} else {\n\t\tswitch (hw_link_info->phy_type_high) {\n\t\tcase ICE_PHY_TYPE_HIGH_100G_AUI2:\n\t\tcase ICE_PHY_TYPE_HIGH_100G_CAUI2:\n\t\t\tif (ice_is_media_cage_present(pi))\n\t\t\t\treturn ICE_MEDIA_DA;\n\t\t\tfallthrough;\n\t\tcase ICE_PHY_TYPE_HIGH_100GBASE_KR2_PAM4:\n\t\t\treturn ICE_MEDIA_BACKPLANE;\n\t\tcase ICE_PHY_TYPE_HIGH_100G_CAUI2_AOC_ACC:\n\t\tcase ICE_PHY_TYPE_HIGH_100G_AUI2_AOC_ACC:\n\t\t\treturn ICE_MEDIA_FIBER;\n\t\t}\n\t}\n\treturn ICE_MEDIA_UNKNOWN;\n}\n\n \nint\nice_aq_get_link_info(struct ice_port_info *pi, bool ena_lse,\n\t\t     struct ice_link_status *link, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_get_link_status_data link_data = { 0 };\n\tstruct ice_aqc_get_link_status *resp;\n\tstruct ice_link_status *li_old, *li;\n\tenum ice_media_type *hw_media_type;\n\tstruct ice_fc_info *hw_fc_info;\n\tbool tx_pause, rx_pause;\n\tstruct ice_aq_desc desc;\n\tstruct ice_hw *hw;\n\tu16 cmd_flags;\n\tint status;\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\thw = pi->hw;\n\tli_old = &pi->phy.link_info_old;\n\thw_media_type = &pi->phy.media_type;\n\tli = &pi->phy.link_info;\n\thw_fc_info = &pi->fc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_link_status);\n\tcmd_flags = (ena_lse) ? ICE_AQ_LSE_ENA : ICE_AQ_LSE_DIS;\n\tresp = &desc.params.get_link_status;\n\tresp->cmd_flags = cpu_to_le16(cmd_flags);\n\tresp->lport_num = pi->lport;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, &link_data, sizeof(link_data), cd);\n\n\tif (status)\n\t\treturn status;\n\n\t \n\t*li_old = *li;\n\n\t \n\tli->link_speed = le16_to_cpu(link_data.link_speed);\n\tli->phy_type_low = le64_to_cpu(link_data.phy_type_low);\n\tli->phy_type_high = le64_to_cpu(link_data.phy_type_high);\n\t*hw_media_type = ice_get_media_type(pi);\n\tli->link_info = link_data.link_info;\n\tli->link_cfg_err = link_data.link_cfg_err;\n\tli->an_info = link_data.an_info;\n\tli->ext_info = link_data.ext_info;\n\tli->max_frame_size = le16_to_cpu(link_data.max_frame_size);\n\tli->fec_info = link_data.cfg & ICE_AQ_FEC_MASK;\n\tli->topo_media_conflict = link_data.topo_media_conflict;\n\tli->pacing = link_data.cfg & (ICE_AQ_CFG_PACING_M |\n\t\t\t\t      ICE_AQ_CFG_PACING_TYPE_M);\n\n\t \n\ttx_pause = !!(link_data.an_info & ICE_AQ_LINK_PAUSE_TX);\n\trx_pause = !!(link_data.an_info & ICE_AQ_LINK_PAUSE_RX);\n\tif (tx_pause && rx_pause)\n\t\thw_fc_info->current_mode = ICE_FC_FULL;\n\telse if (tx_pause)\n\t\thw_fc_info->current_mode = ICE_FC_TX_PAUSE;\n\telse if (rx_pause)\n\t\thw_fc_info->current_mode = ICE_FC_RX_PAUSE;\n\telse\n\t\thw_fc_info->current_mode = ICE_FC_NONE;\n\n\tli->lse_ena = !!(resp->cmd_flags & cpu_to_le16(ICE_AQ_LSE_IS_ENABLED));\n\n\tice_debug(hw, ICE_DBG_LINK, \"get link info\\n\");\n\tice_debug(hw, ICE_DBG_LINK, \"\tlink_speed = 0x%x\\n\", li->link_speed);\n\tice_debug(hw, ICE_DBG_LINK, \"\tphy_type_low = 0x%llx\\n\",\n\t\t  (unsigned long long)li->phy_type_low);\n\tice_debug(hw, ICE_DBG_LINK, \"\tphy_type_high = 0x%llx\\n\",\n\t\t  (unsigned long long)li->phy_type_high);\n\tice_debug(hw, ICE_DBG_LINK, \"\tmedia_type = 0x%x\\n\", *hw_media_type);\n\tice_debug(hw, ICE_DBG_LINK, \"\tlink_info = 0x%x\\n\", li->link_info);\n\tice_debug(hw, ICE_DBG_LINK, \"\tlink_cfg_err = 0x%x\\n\", li->link_cfg_err);\n\tice_debug(hw, ICE_DBG_LINK, \"\tan_info = 0x%x\\n\", li->an_info);\n\tice_debug(hw, ICE_DBG_LINK, \"\text_info = 0x%x\\n\", li->ext_info);\n\tice_debug(hw, ICE_DBG_LINK, \"\tfec_info = 0x%x\\n\", li->fec_info);\n\tice_debug(hw, ICE_DBG_LINK, \"\tlse_ena = 0x%x\\n\", li->lse_ena);\n\tice_debug(hw, ICE_DBG_LINK, \"\tmax_frame = 0x%x\\n\",\n\t\t  li->max_frame_size);\n\tice_debug(hw, ICE_DBG_LINK, \"\tpacing = 0x%x\\n\", li->pacing);\n\n\t \n\tif (link)\n\t\t*link = *li;\n\n\t \n\tpi->phy.get_link_info = false;\n\n\treturn 0;\n}\n\n \nstatic void\nice_fill_tx_timer_and_fc_thresh(struct ice_hw *hw,\n\t\t\t\tstruct ice_aqc_set_mac_cfg *cmd)\n{\n\tu16 fc_thres_val, tx_timer_val;\n\tu32 val;\n\n\t \n#define IDX_OF_LFC PRTMAC_HSEC_CTL_TX_PAUSE_QUANTA_MAX_INDEX\n\n\t \n\tval = rd32(hw, PRTMAC_HSEC_CTL_TX_PAUSE_QUANTA(IDX_OF_LFC));\n\ttx_timer_val = val &\n\t\tPRTMAC_HSEC_CTL_TX_PAUSE_QUANTA_HSEC_CTL_TX_PAUSE_QUANTA_M;\n\tcmd->tx_tmr_value = cpu_to_le16(tx_timer_val);\n\n\t \n\tval = rd32(hw, PRTMAC_HSEC_CTL_TX_PAUSE_REFRESH_TIMER(IDX_OF_LFC));\n\tfc_thres_val = val & PRTMAC_HSEC_CTL_TX_PAUSE_REFRESH_TIMER_M;\n\n\tcmd->fc_refresh_threshold = cpu_to_le16(fc_thres_val);\n}\n\n \nint\nice_aq_set_mac_cfg(struct ice_hw *hw, u16 max_frame_size, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_set_mac_cfg *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.set_mac_cfg;\n\n\tif (max_frame_size == 0)\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_mac_cfg);\n\n\tcmd->max_frame_size = cpu_to_le16(max_frame_size);\n\n\tice_fill_tx_timer_and_fc_thresh(hw, cmd);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nstatic int ice_init_fltr_mgmt_struct(struct ice_hw *hw)\n{\n\tstruct ice_switch_info *sw;\n\tint status;\n\n\thw->switch_info = devm_kzalloc(ice_hw_to_dev(hw),\n\t\t\t\t       sizeof(*hw->switch_info), GFP_KERNEL);\n\tsw = hw->switch_info;\n\n\tif (!sw)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&sw->vsi_list_map_head);\n\tsw->prof_res_bm_init = 0;\n\n\tstatus = ice_init_def_sw_recp(hw);\n\tif (status) {\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->switch_info);\n\t\treturn status;\n\t}\n\treturn 0;\n}\n\n \nstatic void ice_cleanup_fltr_mgmt_struct(struct ice_hw *hw)\n{\n\tstruct ice_switch_info *sw = hw->switch_info;\n\tstruct ice_vsi_list_map_info *v_pos_map;\n\tstruct ice_vsi_list_map_info *v_tmp_map;\n\tstruct ice_sw_recipe *recps;\n\tu8 i;\n\n\tlist_for_each_entry_safe(v_pos_map, v_tmp_map, &sw->vsi_list_map_head,\n\t\t\t\t list_entry) {\n\t\tlist_del(&v_pos_map->list_entry);\n\t\tdevm_kfree(ice_hw_to_dev(hw), v_pos_map);\n\t}\n\trecps = sw->recp_list;\n\tfor (i = 0; i < ICE_MAX_NUM_RECIPES; i++) {\n\t\tstruct ice_recp_grp_entry *rg_entry, *tmprg_entry;\n\n\t\trecps[i].root_rid = i;\n\t\tlist_for_each_entry_safe(rg_entry, tmprg_entry,\n\t\t\t\t\t &recps[i].rg_list, l_entry) {\n\t\t\tlist_del(&rg_entry->l_entry);\n\t\t\tdevm_kfree(ice_hw_to_dev(hw), rg_entry);\n\t\t}\n\n\t\tif (recps[i].adv_rule) {\n\t\t\tstruct ice_adv_fltr_mgmt_list_entry *tmp_entry;\n\t\t\tstruct ice_adv_fltr_mgmt_list_entry *lst_itr;\n\n\t\t\tmutex_destroy(&recps[i].filt_rule_lock);\n\t\t\tlist_for_each_entry_safe(lst_itr, tmp_entry,\n\t\t\t\t\t\t &recps[i].filt_rules,\n\t\t\t\t\t\t list_entry) {\n\t\t\t\tlist_del(&lst_itr->list_entry);\n\t\t\t\tdevm_kfree(ice_hw_to_dev(hw), lst_itr->lkups);\n\t\t\t\tdevm_kfree(ice_hw_to_dev(hw), lst_itr);\n\t\t\t}\n\t\t} else {\n\t\t\tstruct ice_fltr_mgmt_list_entry *lst_itr, *tmp_entry;\n\n\t\t\tmutex_destroy(&recps[i].filt_rule_lock);\n\t\t\tlist_for_each_entry_safe(lst_itr, tmp_entry,\n\t\t\t\t\t\t &recps[i].filt_rules,\n\t\t\t\t\t\t list_entry) {\n\t\t\t\tlist_del(&lst_itr->list_entry);\n\t\t\t\tdevm_kfree(ice_hw_to_dev(hw), lst_itr);\n\t\t\t}\n\t\t}\n\t\tdevm_kfree(ice_hw_to_dev(hw), recps[i].root_buf);\n\t}\n\tice_rm_all_sw_replay_rule_info(hw);\n\tdevm_kfree(ice_hw_to_dev(hw), sw->recp_list);\n\tdevm_kfree(ice_hw_to_dev(hw), sw);\n}\n\n \nstatic int ice_get_fw_log_cfg(struct ice_hw *hw)\n{\n\tstruct ice_aq_desc desc;\n\t__le16 *config;\n\tint status;\n\tu16 size;\n\n\tsize = sizeof(*config) * ICE_AQC_FW_LOG_ID_MAX;\n\tconfig = kzalloc(size, GFP_KERNEL);\n\tif (!config)\n\t\treturn -ENOMEM;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_fw_logging_info);\n\n\tstatus = ice_aq_send_cmd(hw, &desc, config, size, NULL);\n\tif (!status) {\n\t\tu16 i;\n\n\t\t \n\t\tfor (i = 0; i < ICE_AQC_FW_LOG_ID_MAX; i++) {\n\t\t\tu16 v, m, flgs;\n\n\t\t\tv = le16_to_cpu(config[i]);\n\t\t\tm = (v & ICE_AQC_FW_LOG_ID_M) >> ICE_AQC_FW_LOG_ID_S;\n\t\t\tflgs = (v & ICE_AQC_FW_LOG_EN_M) >> ICE_AQC_FW_LOG_EN_S;\n\n\t\t\tif (m < ICE_AQC_FW_LOG_ID_MAX)\n\t\t\t\thw->fw_log.evnts[m].cur = flgs;\n\t\t}\n\t}\n\n\tkfree(config);\n\n\treturn status;\n}\n\n \nstatic int ice_cfg_fw_log(struct ice_hw *hw, bool enable)\n{\n\tstruct ice_aqc_fw_logging *cmd;\n\tu16 i, chgs = 0, len = 0;\n\tstruct ice_aq_desc desc;\n\t__le16 *data = NULL;\n\tu8 actv_evnts = 0;\n\tvoid *buf = NULL;\n\tint status = 0;\n\n\tif (!hw->fw_log.cq_en && !hw->fw_log.uart_en)\n\t\treturn 0;\n\n\t \n\tif (!enable &&\n\t    (!hw->fw_log.actv_evnts || !ice_check_sq_alive(hw, &hw->adminq)))\n\t\treturn 0;\n\n\t \n\tstatus = ice_get_fw_log_cfg(hw);\n\tif (status)\n\t\treturn status;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_fw_logging);\n\tcmd = &desc.params.fw_logging;\n\n\t \n\tif (hw->fw_log.cq_en)\n\t\tcmd->log_ctrl_valid |= ICE_AQC_FW_LOG_AQ_VALID;\n\n\tif (hw->fw_log.uart_en)\n\t\tcmd->log_ctrl_valid |= ICE_AQC_FW_LOG_UART_VALID;\n\n\tif (enable) {\n\t\t \n\t\tfor (i = 0; i < ICE_AQC_FW_LOG_ID_MAX; i++) {\n\t\t\tu16 val;\n\n\t\t\t \n\t\t\tactv_evnts |= hw->fw_log.evnts[i].cfg;\n\n\t\t\tif (hw->fw_log.evnts[i].cfg == hw->fw_log.evnts[i].cur)\n\t\t\t\tcontinue;\n\n\t\t\tif (!data) {\n\t\t\t\tdata = devm_kcalloc(ice_hw_to_dev(hw),\n\t\t\t\t\t\t    ICE_AQC_FW_LOG_ID_MAX,\n\t\t\t\t\t\t    sizeof(*data),\n\t\t\t\t\t\t    GFP_KERNEL);\n\t\t\t\tif (!data)\n\t\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\tval = i << ICE_AQC_FW_LOG_ID_S;\n\t\t\tval |= hw->fw_log.evnts[i].cfg << ICE_AQC_FW_LOG_EN_S;\n\t\t\tdata[chgs++] = cpu_to_le16(val);\n\t\t}\n\n\t\t \n\t\tif (actv_evnts) {\n\t\t\t \n\t\t\tif (!chgs)\n\t\t\t\tgoto out;\n\n\t\t\tif (hw->fw_log.cq_en)\n\t\t\t\tcmd->log_ctrl |= ICE_AQC_FW_LOG_AQ_EN;\n\n\t\t\tif (hw->fw_log.uart_en)\n\t\t\t\tcmd->log_ctrl |= ICE_AQC_FW_LOG_UART_EN;\n\n\t\t\tbuf = data;\n\t\t\tlen = sizeof(*data) * chgs;\n\t\t\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\t\t}\n\t}\n\n\tstatus = ice_aq_send_cmd(hw, &desc, buf, len, NULL);\n\tif (!status) {\n\t\t \n\t\tu16 cnt = enable ? chgs : (u16)ICE_AQC_FW_LOG_ID_MAX;\n\n\t\thw->fw_log.actv_evnts = actv_evnts;\n\t\tfor (i = 0; i < cnt; i++) {\n\t\t\tu16 v, m;\n\n\t\t\tif (!enable) {\n\t\t\t\t \n\t\t\t\thw->fw_log.evnts[i].cur = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tv = le16_to_cpu(data[i]);\n\t\t\tm = (v & ICE_AQC_FW_LOG_ID_M) >> ICE_AQC_FW_LOG_ID_S;\n\t\t\thw->fw_log.evnts[m].cur = hw->fw_log.evnts[m].cfg;\n\t\t}\n\t}\n\nout:\n\tdevm_kfree(ice_hw_to_dev(hw), data);\n\n\treturn status;\n}\n\n \nvoid ice_output_fw_log(struct ice_hw *hw, struct ice_aq_desc *desc, void *buf)\n{\n\tice_debug(hw, ICE_DBG_FW_LOG, \"[ FW Log Msg Start ]\\n\");\n\tice_debug_array(hw, ICE_DBG_FW_LOG, 16, 1, (u8 *)buf,\n\t\t\tle16_to_cpu(desc->datalen));\n\tice_debug(hw, ICE_DBG_FW_LOG, \"[ FW Log Msg End ]\\n\");\n}\n\n \nstatic void ice_get_itr_intrl_gran(struct ice_hw *hw)\n{\n\tu8 max_agg_bw = (rd32(hw, GL_PWR_MODE_CTL) &\n\t\t\t GL_PWR_MODE_CTL_CAR_MAX_BW_M) >>\n\t\t\tGL_PWR_MODE_CTL_CAR_MAX_BW_S;\n\n\tswitch (max_agg_bw) {\n\tcase ICE_MAX_AGG_BW_200G:\n\tcase ICE_MAX_AGG_BW_100G:\n\tcase ICE_MAX_AGG_BW_50G:\n\t\thw->itr_gran = ICE_ITR_GRAN_ABOVE_25;\n\t\thw->intrl_gran = ICE_INTRL_GRAN_ABOVE_25;\n\t\tbreak;\n\tcase ICE_MAX_AGG_BW_25G:\n\t\thw->itr_gran = ICE_ITR_GRAN_MAX_25;\n\t\thw->intrl_gran = ICE_INTRL_GRAN_MAX_25;\n\t\tbreak;\n\t}\n}\n\n \nint ice_init_hw(struct ice_hw *hw)\n{\n\tstruct ice_aqc_get_phy_caps_data *pcaps;\n\tu16 mac_buf_len;\n\tvoid *mac_buf;\n\tint status;\n\n\t \n\tstatus = ice_set_mac_type(hw);\n\tif (status)\n\t\treturn status;\n\n\thw->pf_id = (u8)(rd32(hw, PF_FUNC_RID) &\n\t\t\t PF_FUNC_RID_FUNC_NUM_M) >>\n\t\tPF_FUNC_RID_FUNC_NUM_S;\n\n\tstatus = ice_reset(hw, ICE_RESET_PFR);\n\tif (status)\n\t\treturn status;\n\n\tice_get_itr_intrl_gran(hw);\n\n\tstatus = ice_create_all_ctrlq(hw);\n\tif (status)\n\t\tgoto err_unroll_cqinit;\n\n\t \n\tstatus = ice_cfg_fw_log(hw, true);\n\tif (status)\n\t\tice_debug(hw, ICE_DBG_INIT, \"Failed to enable FW logging.\\n\");\n\n\tstatus = ice_clear_pf_cfg(hw);\n\tif (status)\n\t\tgoto err_unroll_cqinit;\n\n\t \n\twr32(hw, PFQF_FD_ENA, PFQF_FD_ENA_FD_ENA_M);\n\tINIT_LIST_HEAD(&hw->fdir_list_head);\n\n\tice_clear_pxe_mode(hw);\n\n\tstatus = ice_init_nvm(hw);\n\tif (status)\n\t\tgoto err_unroll_cqinit;\n\n\tstatus = ice_get_caps(hw);\n\tif (status)\n\t\tgoto err_unroll_cqinit;\n\n\tif (!hw->port_info)\n\t\thw->port_info = devm_kzalloc(ice_hw_to_dev(hw),\n\t\t\t\t\t     sizeof(*hw->port_info),\n\t\t\t\t\t     GFP_KERNEL);\n\tif (!hw->port_info) {\n\t\tstatus = -ENOMEM;\n\t\tgoto err_unroll_cqinit;\n\t}\n\n\t \n\thw->port_info->hw = hw;\n\n\t \n\tstatus = ice_get_initial_sw_cfg(hw);\n\tif (status)\n\t\tgoto err_unroll_alloc;\n\n\thw->evb_veb = true;\n\n\t \n\txa_init_flags(&hw->port_info->sched_node_ids, XA_FLAGS_ALLOC);\n\n\t \n\tstatus = ice_sched_query_res_alloc(hw);\n\tif (status) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"Failed to get scheduler allocated resources\\n\");\n\t\tgoto err_unroll_alloc;\n\t}\n\tice_sched_get_psm_clk_freq(hw);\n\n\t \n\tstatus = ice_sched_init_port(hw->port_info);\n\tif (status)\n\t\tgoto err_unroll_sched;\n\n\tpcaps = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*pcaps), GFP_KERNEL);\n\tif (!pcaps) {\n\t\tstatus = -ENOMEM;\n\t\tgoto err_unroll_sched;\n\t}\n\n\t \n\tstatus = ice_aq_get_phy_caps(hw->port_info, false,\n\t\t\t\t     ICE_AQC_REPORT_TOPO_CAP_MEDIA, pcaps,\n\t\t\t\t     NULL);\n\tdevm_kfree(ice_hw_to_dev(hw), pcaps);\n\tif (status)\n\t\tdev_warn(ice_hw_to_dev(hw), \"Get PHY capabilities failed status = %d, continuing anyway\\n\",\n\t\t\t status);\n\n\t \n\tstatus = ice_aq_get_link_info(hw->port_info, false, NULL, NULL);\n\tif (status)\n\t\tgoto err_unroll_sched;\n\n\t \n\tif (!hw->sw_entry_point_layer) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"invalid sw entry point\\n\");\n\t\tstatus = -EIO;\n\t\tgoto err_unroll_sched;\n\t}\n\tINIT_LIST_HEAD(&hw->agg_list);\n\t \n\tif (!hw->max_burst_size)\n\t\tice_cfg_rl_burst_size(hw, ICE_SCHED_DFLT_BURST_SIZE);\n\n\tstatus = ice_init_fltr_mgmt_struct(hw);\n\tif (status)\n\t\tgoto err_unroll_sched;\n\n\t \n\t \n\tmac_buf = devm_kcalloc(ice_hw_to_dev(hw), 2,\n\t\t\t       sizeof(struct ice_aqc_manage_mac_read_resp),\n\t\t\t       GFP_KERNEL);\n\tmac_buf_len = 2 * sizeof(struct ice_aqc_manage_mac_read_resp);\n\n\tif (!mac_buf) {\n\t\tstatus = -ENOMEM;\n\t\tgoto err_unroll_fltr_mgmt_struct;\n\t}\n\n\tstatus = ice_aq_manage_mac_read(hw, mac_buf, mac_buf_len, NULL);\n\tdevm_kfree(ice_hw_to_dev(hw), mac_buf);\n\n\tif (status)\n\t\tgoto err_unroll_fltr_mgmt_struct;\n\t \n\tstatus = ice_aq_set_mac_cfg(hw, ICE_AQ_SET_MAC_FRAME_SIZE_MAX, NULL);\n\tif (status)\n\t\tgoto err_unroll_fltr_mgmt_struct;\n\t \n\tstatus = ice_alloc_fd_res_cntr(hw, &hw->fd_ctr_base);\n\tif (status)\n\t\tgoto err_unroll_fltr_mgmt_struct;\n\tstatus = ice_init_hw_tbls(hw);\n\tif (status)\n\t\tgoto err_unroll_fltr_mgmt_struct;\n\tmutex_init(&hw->tnl_lock);\n\treturn 0;\n\nerr_unroll_fltr_mgmt_struct:\n\tice_cleanup_fltr_mgmt_struct(hw);\nerr_unroll_sched:\n\tice_sched_cleanup_all(hw);\nerr_unroll_alloc:\n\tdevm_kfree(ice_hw_to_dev(hw), hw->port_info);\nerr_unroll_cqinit:\n\tice_destroy_all_ctrlq(hw);\n\treturn status;\n}\n\n \nvoid ice_deinit_hw(struct ice_hw *hw)\n{\n\tice_free_fd_res_cntr(hw, hw->fd_ctr_base);\n\tice_cleanup_fltr_mgmt_struct(hw);\n\n\tice_sched_cleanup_all(hw);\n\tice_sched_clear_agg(hw);\n\tice_free_seg(hw);\n\tice_free_hw_tbls(hw);\n\tmutex_destroy(&hw->tnl_lock);\n\n\t \n\tice_cfg_fw_log(hw, false);\n\tice_destroy_all_ctrlq(hw);\n\n\t \n\tice_clear_all_vsi_ctx(hw);\n}\n\n \nint ice_check_reset(struct ice_hw *hw)\n{\n\tu32 cnt, reg = 0, grst_timeout, uld_mask;\n\n\t \n\tgrst_timeout = ((rd32(hw, GLGEN_RSTCTL) & GLGEN_RSTCTL_GRSTDEL_M) >>\n\t\t\tGLGEN_RSTCTL_GRSTDEL_S) + 10;\n\n\tfor (cnt = 0; cnt < grst_timeout; cnt++) {\n\t\tmdelay(100);\n\t\treg = rd32(hw, GLGEN_RSTAT);\n\t\tif (!(reg & GLGEN_RSTAT_DEVSTATE_M))\n\t\t\tbreak;\n\t}\n\n\tif (cnt == grst_timeout) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"Global reset polling failed to complete.\\n\");\n\t\treturn -EIO;\n\t}\n\n#define ICE_RESET_DONE_MASK\t(GLNVM_ULD_PCIER_DONE_M |\\\n\t\t\t\t GLNVM_ULD_PCIER_DONE_1_M |\\\n\t\t\t\t GLNVM_ULD_CORER_DONE_M |\\\n\t\t\t\t GLNVM_ULD_GLOBR_DONE_M |\\\n\t\t\t\t GLNVM_ULD_POR_DONE_M |\\\n\t\t\t\t GLNVM_ULD_POR_DONE_1_M |\\\n\t\t\t\t GLNVM_ULD_PCIER_DONE_2_M)\n\n\tuld_mask = ICE_RESET_DONE_MASK | (hw->func_caps.common_cap.rdma ?\n\t\t\t\t\t  GLNVM_ULD_PE_DONE_M : 0);\n\n\t \n\tfor (cnt = 0; cnt < ICE_PF_RESET_WAIT_COUNT; cnt++) {\n\t\treg = rd32(hw, GLNVM_ULD) & uld_mask;\n\t\tif (reg == uld_mask) {\n\t\t\tice_debug(hw, ICE_DBG_INIT, \"Global reset processes done. %d\\n\", cnt);\n\t\t\tbreak;\n\t\t}\n\t\tmdelay(10);\n\t}\n\n\tif (cnt == ICE_PF_RESET_WAIT_COUNT) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"Wait for Reset Done timed out. GLNVM_ULD = 0x%x\\n\",\n\t\t\t  reg);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int ice_pf_reset(struct ice_hw *hw)\n{\n\tu32 cnt, reg;\n\n\t \n\tif ((rd32(hw, GLGEN_RSTAT) & GLGEN_RSTAT_DEVSTATE_M) ||\n\t    (rd32(hw, GLNVM_ULD) & ICE_RESET_DONE_MASK) ^ ICE_RESET_DONE_MASK) {\n\t\t \n\t\tif (ice_check_reset(hw))\n\t\t\treturn -EIO;\n\n\t\treturn 0;\n\t}\n\n\t \n\treg = rd32(hw, PFGEN_CTRL);\n\n\twr32(hw, PFGEN_CTRL, (reg | PFGEN_CTRL_PFSWR_M));\n\n\t \n\tfor (cnt = 0; cnt < ICE_GLOBAL_CFG_LOCK_TIMEOUT +\n\t     ICE_PF_RESET_WAIT_COUNT; cnt++) {\n\t\treg = rd32(hw, PFGEN_CTRL);\n\t\tif (!(reg & PFGEN_CTRL_PFSWR_M))\n\t\t\tbreak;\n\n\t\tmdelay(1);\n\t}\n\n\tif (cnt == ICE_PF_RESET_WAIT_COUNT) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"PF reset polling failed to complete.\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nint ice_reset(struct ice_hw *hw, enum ice_reset_req req)\n{\n\tu32 val = 0;\n\n\tswitch (req) {\n\tcase ICE_RESET_PFR:\n\t\treturn ice_pf_reset(hw);\n\tcase ICE_RESET_CORER:\n\t\tice_debug(hw, ICE_DBG_INIT, \"CoreR requested\\n\");\n\t\tval = GLGEN_RTRIG_CORER_M;\n\t\tbreak;\n\tcase ICE_RESET_GLOBR:\n\t\tice_debug(hw, ICE_DBG_INIT, \"GlobalR requested\\n\");\n\t\tval = GLGEN_RTRIG_GLOBR_M;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tval |= rd32(hw, GLGEN_RTRIG);\n\twr32(hw, GLGEN_RTRIG, val);\n\tice_flush(hw);\n\n\t \n\treturn ice_check_reset(hw);\n}\n\n \nstatic int\nice_copy_rxq_ctx_to_hw(struct ice_hw *hw, u8 *ice_rxq_ctx, u32 rxq_index)\n{\n\tu8 i;\n\n\tif (!ice_rxq_ctx)\n\t\treturn -EINVAL;\n\n\tif (rxq_index > QRX_CTRL_MAX_INDEX)\n\t\treturn -EINVAL;\n\n\t \n\tfor (i = 0; i < ICE_RXQ_CTX_SIZE_DWORDS; i++) {\n\t\twr32(hw, QRX_CONTEXT(i, rxq_index),\n\t\t     *((u32 *)(ice_rxq_ctx + (i * sizeof(u32)))));\n\n\t\tice_debug(hw, ICE_DBG_QCTX, \"qrxdata[%d]: %08X\\n\", i,\n\t\t\t  *((u32 *)(ice_rxq_ctx + (i * sizeof(u32)))));\n\t}\n\n\treturn 0;\n}\n\n \nstatic const struct ice_ctx_ele ice_rlan_ctx_info[] = {\n\t \n\tICE_CTX_STORE(ice_rlan_ctx, head,\t\t13,\t0),\n\tICE_CTX_STORE(ice_rlan_ctx, cpuid,\t\t8,\t13),\n\tICE_CTX_STORE(ice_rlan_ctx, base,\t\t57,\t32),\n\tICE_CTX_STORE(ice_rlan_ctx, qlen,\t\t13,\t89),\n\tICE_CTX_STORE(ice_rlan_ctx, dbuf,\t\t7,\t102),\n\tICE_CTX_STORE(ice_rlan_ctx, hbuf,\t\t5,\t109),\n\tICE_CTX_STORE(ice_rlan_ctx, dtype,\t\t2,\t114),\n\tICE_CTX_STORE(ice_rlan_ctx, dsize,\t\t1,\t116),\n\tICE_CTX_STORE(ice_rlan_ctx, crcstrip,\t\t1,\t117),\n\tICE_CTX_STORE(ice_rlan_ctx, l2tsel,\t\t1,\t119),\n\tICE_CTX_STORE(ice_rlan_ctx, hsplit_0,\t\t4,\t120),\n\tICE_CTX_STORE(ice_rlan_ctx, hsplit_1,\t\t2,\t124),\n\tICE_CTX_STORE(ice_rlan_ctx, showiv,\t\t1,\t127),\n\tICE_CTX_STORE(ice_rlan_ctx, rxmax,\t\t14,\t174),\n\tICE_CTX_STORE(ice_rlan_ctx, tphrdesc_ena,\t1,\t193),\n\tICE_CTX_STORE(ice_rlan_ctx, tphwdesc_ena,\t1,\t194),\n\tICE_CTX_STORE(ice_rlan_ctx, tphdata_ena,\t1,\t195),\n\tICE_CTX_STORE(ice_rlan_ctx, tphhead_ena,\t1,\t196),\n\tICE_CTX_STORE(ice_rlan_ctx, lrxqthresh,\t\t3,\t198),\n\tICE_CTX_STORE(ice_rlan_ctx, prefena,\t\t1,\t201),\n\t{ 0 }\n};\n\n \nint\nice_write_rxq_ctx(struct ice_hw *hw, struct ice_rlan_ctx *rlan_ctx,\n\t\t  u32 rxq_index)\n{\n\tu8 ctx_buf[ICE_RXQ_CTX_SZ] = { 0 };\n\n\tif (!rlan_ctx)\n\t\treturn -EINVAL;\n\n\trlan_ctx->prefena = 1;\n\n\tice_set_ctx(hw, (u8 *)rlan_ctx, ctx_buf, ice_rlan_ctx_info);\n\treturn ice_copy_rxq_ctx_to_hw(hw, ctx_buf, rxq_index);\n}\n\n \nconst struct ice_ctx_ele ice_tlan_ctx_info[] = {\n\t\t\t\t     \n\tICE_CTX_STORE(ice_tlan_ctx, base,\t\t\t57,\t0),\n\tICE_CTX_STORE(ice_tlan_ctx, port_num,\t\t\t3,\t57),\n\tICE_CTX_STORE(ice_tlan_ctx, cgd_num,\t\t\t5,\t60),\n\tICE_CTX_STORE(ice_tlan_ctx, pf_num,\t\t\t3,\t65),\n\tICE_CTX_STORE(ice_tlan_ctx, vmvf_num,\t\t\t10,\t68),\n\tICE_CTX_STORE(ice_tlan_ctx, vmvf_type,\t\t\t2,\t78),\n\tICE_CTX_STORE(ice_tlan_ctx, src_vsi,\t\t\t10,\t80),\n\tICE_CTX_STORE(ice_tlan_ctx, tsyn_ena,\t\t\t1,\t90),\n\tICE_CTX_STORE(ice_tlan_ctx, internal_usage_flag,\t1,\t91),\n\tICE_CTX_STORE(ice_tlan_ctx, alt_vlan,\t\t\t1,\t92),\n\tICE_CTX_STORE(ice_tlan_ctx, cpuid,\t\t\t8,\t93),\n\tICE_CTX_STORE(ice_tlan_ctx, wb_mode,\t\t\t1,\t101),\n\tICE_CTX_STORE(ice_tlan_ctx, tphrd_desc,\t\t\t1,\t102),\n\tICE_CTX_STORE(ice_tlan_ctx, tphrd,\t\t\t1,\t103),\n\tICE_CTX_STORE(ice_tlan_ctx, tphwr_desc,\t\t\t1,\t104),\n\tICE_CTX_STORE(ice_tlan_ctx, cmpq_id,\t\t\t9,\t105),\n\tICE_CTX_STORE(ice_tlan_ctx, qnum_in_func,\t\t14,\t114),\n\tICE_CTX_STORE(ice_tlan_ctx, itr_notification_mode,\t1,\t128),\n\tICE_CTX_STORE(ice_tlan_ctx, adjust_prof_id,\t\t6,\t129),\n\tICE_CTX_STORE(ice_tlan_ctx, qlen,\t\t\t13,\t135),\n\tICE_CTX_STORE(ice_tlan_ctx, quanta_prof_idx,\t\t4,\t148),\n\tICE_CTX_STORE(ice_tlan_ctx, tso_ena,\t\t\t1,\t152),\n\tICE_CTX_STORE(ice_tlan_ctx, tso_qnum,\t\t\t11,\t153),\n\tICE_CTX_STORE(ice_tlan_ctx, legacy_int,\t\t\t1,\t164),\n\tICE_CTX_STORE(ice_tlan_ctx, drop_ena,\t\t\t1,\t165),\n\tICE_CTX_STORE(ice_tlan_ctx, cache_prof_idx,\t\t2,\t166),\n\tICE_CTX_STORE(ice_tlan_ctx, pkt_shaper_prof_idx,\t3,\t168),\n\tICE_CTX_STORE(ice_tlan_ctx, int_q_state,\t\t122,\t171),\n\t{ 0 }\n};\n\n \n\n \nstatic int\nice_sbq_send_cmd(struct ice_hw *hw, struct ice_sbq_cmd_desc *desc,\n\t\t void *buf, u16 buf_size, struct ice_sq_cd *cd)\n{\n\treturn ice_sq_send_cmd(hw, ice_get_sbq(hw),\n\t\t\t       (struct ice_aq_desc *)desc, buf, buf_size, cd);\n}\n\n \nint ice_sbq_rw_reg(struct ice_hw *hw, struct ice_sbq_msg_input *in)\n{\n\tstruct ice_sbq_cmd_desc desc = {0};\n\tstruct ice_sbq_msg_req msg = {0};\n\tu16 msg_len;\n\tint status;\n\n\tmsg_len = sizeof(msg);\n\n\tmsg.dest_dev = in->dest_dev;\n\tmsg.opcode = in->opcode;\n\tmsg.flags = ICE_SBQ_MSG_FLAGS;\n\tmsg.sbe_fbe = ICE_SBQ_MSG_SBE_FBE;\n\tmsg.msg_addr_low = cpu_to_le16(in->msg_addr_low);\n\tmsg.msg_addr_high = cpu_to_le32(in->msg_addr_high);\n\n\tif (in->opcode)\n\t\tmsg.data = cpu_to_le32(in->data);\n\telse\n\t\t \n\t\tmsg_len -= sizeof(msg.data);\n\n\tdesc.flags = cpu_to_le16(ICE_AQ_FLAG_RD);\n\tdesc.opcode = cpu_to_le16(ice_sbq_opc_neigh_dev_req);\n\tdesc.param0.cmd_len = cpu_to_le16(msg_len);\n\tstatus = ice_sbq_send_cmd(hw, &desc, &msg, msg_len, NULL);\n\tif (!status && !in->opcode)\n\t\tin->data = le32_to_cpu\n\t\t\t(((struct ice_sbq_msg_cmpl *)&msg)->data);\n\treturn status;\n}\n\n \n\n \nDEFINE_MUTEX(ice_global_cfg_lock_sw);\n\n \nstatic bool ice_should_retry_sq_send_cmd(u16 opcode)\n{\n\tswitch (opcode) {\n\tcase ice_aqc_opc_get_link_topo:\n\tcase ice_aqc_opc_lldp_stop:\n\tcase ice_aqc_opc_lldp_start:\n\tcase ice_aqc_opc_lldp_filter_ctrl:\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic int\nice_sq_send_cmd_retry(struct ice_hw *hw, struct ice_ctl_q_info *cq,\n\t\t      struct ice_aq_desc *desc, void *buf, u16 buf_size,\n\t\t      struct ice_sq_cd *cd)\n{\n\tstruct ice_aq_desc desc_cpy;\n\tbool is_cmd_for_retry;\n\tu8 idx = 0;\n\tu16 opcode;\n\tint status;\n\n\topcode = le16_to_cpu(desc->opcode);\n\tis_cmd_for_retry = ice_should_retry_sq_send_cmd(opcode);\n\tmemset(&desc_cpy, 0, sizeof(desc_cpy));\n\n\tif (is_cmd_for_retry) {\n\t\t \n\t\tWARN_ON(buf);\n\n\t\tmemcpy(&desc_cpy, desc, sizeof(desc_cpy));\n\t}\n\n\tdo {\n\t\tstatus = ice_sq_send_cmd(hw, cq, desc, buf, buf_size, cd);\n\n\t\tif (!is_cmd_for_retry || !status ||\n\t\t    hw->adminq.sq_last_status != ICE_AQ_RC_EBUSY)\n\t\t\tbreak;\n\n\t\tmemcpy(desc, &desc_cpy, sizeof(desc_cpy));\n\n\t\tmsleep(ICE_SQ_SEND_DELAY_TIME_MS);\n\n\t} while (++idx < ICE_SQ_SEND_MAX_EXECUTE);\n\n\treturn status;\n}\n\n \nint\nice_aq_send_cmd(struct ice_hw *hw, struct ice_aq_desc *desc, void *buf,\n\t\tu16 buf_size, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_req_res *cmd = &desc->params.res_owner;\n\tbool lock_acquired = false;\n\tint status;\n\n\t \n\tswitch (le16_to_cpu(desc->opcode)) {\n\tcase ice_aqc_opc_download_pkg:\n\tcase ice_aqc_opc_get_pkg_info_list:\n\tcase ice_aqc_opc_get_ver:\n\tcase ice_aqc_opc_upload_section:\n\tcase ice_aqc_opc_update_pkg:\n\tcase ice_aqc_opc_set_port_params:\n\tcase ice_aqc_opc_get_vlan_mode_parameters:\n\tcase ice_aqc_opc_set_vlan_mode_parameters:\n\tcase ice_aqc_opc_add_recipe:\n\tcase ice_aqc_opc_recipe_to_profile:\n\tcase ice_aqc_opc_get_recipe:\n\tcase ice_aqc_opc_get_recipe_to_profile:\n\t\tbreak;\n\tcase ice_aqc_opc_release_res:\n\t\tif (le16_to_cpu(cmd->res_id) == ICE_AQC_RES_ID_GLBL_LOCK)\n\t\t\tbreak;\n\t\tfallthrough;\n\tdefault:\n\t\tmutex_lock(&ice_global_cfg_lock_sw);\n\t\tlock_acquired = true;\n\t\tbreak;\n\t}\n\n\tstatus = ice_sq_send_cmd_retry(hw, &hw->adminq, desc, buf, buf_size, cd);\n\tif (lock_acquired)\n\t\tmutex_unlock(&ice_global_cfg_lock_sw);\n\n\treturn status;\n}\n\n \nint ice_aq_get_fw_ver(struct ice_hw *hw, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_get_ver *resp;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tresp = &desc.params.get_ver;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_ver);\n\n\tstatus = ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n\n\tif (!status) {\n\t\thw->fw_branch = resp->fw_branch;\n\t\thw->fw_maj_ver = resp->fw_major;\n\t\thw->fw_min_ver = resp->fw_minor;\n\t\thw->fw_patch = resp->fw_patch;\n\t\thw->fw_build = le32_to_cpu(resp->fw_build);\n\t\thw->api_branch = resp->api_branch;\n\t\thw->api_maj_ver = resp->api_major;\n\t\thw->api_min_ver = resp->api_minor;\n\t\thw->api_patch = resp->api_patch;\n\t}\n\n\treturn status;\n}\n\n \nint\nice_aq_send_driver_ver(struct ice_hw *hw, struct ice_driver_ver *dv,\n\t\t       struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_driver_ver *cmd;\n\tstruct ice_aq_desc desc;\n\tu16 len;\n\n\tcmd = &desc.params.driver_ver;\n\n\tif (!dv)\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_driver_ver);\n\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\tcmd->major_ver = dv->major_ver;\n\tcmd->minor_ver = dv->minor_ver;\n\tcmd->build_ver = dv->build_ver;\n\tcmd->subbuild_ver = dv->subbuild_ver;\n\n\tlen = 0;\n\twhile (len < sizeof(dv->driver_string) &&\n\t       isascii(dv->driver_string[len]) && dv->driver_string[len])\n\t\tlen++;\n\n\treturn ice_aq_send_cmd(hw, &desc, dv->driver_string, len, cd);\n}\n\n \nint ice_aq_q_shutdown(struct ice_hw *hw, bool unloading)\n{\n\tstruct ice_aqc_q_shutdown *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.q_shutdown;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_q_shutdown);\n\n\tif (unloading)\n\t\tcmd->driver_unloading = ICE_AQC_DRIVER_UNLOADING;\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, NULL);\n}\n\n \nstatic int\nice_aq_req_res(struct ice_hw *hw, enum ice_aq_res_ids res,\n\t       enum ice_aq_res_access_type access, u8 sdp_number, u32 *timeout,\n\t       struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_req_res *cmd_resp;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tcmd_resp = &desc.params.res_owner;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_req_res);\n\n\tcmd_resp->res_id = cpu_to_le16(res);\n\tcmd_resp->access_type = cpu_to_le16(access);\n\tcmd_resp->res_number = cpu_to_le32(sdp_number);\n\tcmd_resp->timeout = cpu_to_le32(*timeout);\n\t*timeout = 0;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n\n\t \n\n\t \n\tif (res == ICE_GLOBAL_CFG_LOCK_RES_ID) {\n\t\tif (le16_to_cpu(cmd_resp->status) == ICE_AQ_RES_GLBL_SUCCESS) {\n\t\t\t*timeout = le32_to_cpu(cmd_resp->timeout);\n\t\t\treturn 0;\n\t\t} else if (le16_to_cpu(cmd_resp->status) ==\n\t\t\t   ICE_AQ_RES_GLBL_IN_PROG) {\n\t\t\t*timeout = le32_to_cpu(cmd_resp->timeout);\n\t\t\treturn -EIO;\n\t\t} else if (le16_to_cpu(cmd_resp->status) ==\n\t\t\t   ICE_AQ_RES_GLBL_DONE) {\n\t\t\treturn -EALREADY;\n\t\t}\n\n\t\t \n\t\t*timeout = 0;\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (!status || hw->adminq.sq_last_status == ICE_AQ_RC_EBUSY)\n\t\t*timeout = le32_to_cpu(cmd_resp->timeout);\n\n\treturn status;\n}\n\n \nstatic int\nice_aq_release_res(struct ice_hw *hw, enum ice_aq_res_ids res, u8 sdp_number,\n\t\t   struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_req_res *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.res_owner;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_release_res);\n\n\tcmd->res_id = cpu_to_le16(res);\n\tcmd->res_number = cpu_to_le32(sdp_number);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_acquire_res(struct ice_hw *hw, enum ice_aq_res_ids res,\n\t\tenum ice_aq_res_access_type access, u32 timeout)\n{\n#define ICE_RES_POLLING_DELAY_MS\t10\n\tu32 delay = ICE_RES_POLLING_DELAY_MS;\n\tu32 time_left = timeout;\n\tint status;\n\n\tstatus = ice_aq_req_res(hw, res, access, 0, &time_left, NULL);\n\n\t \n\tif (status == -EALREADY)\n\t\tgoto ice_acquire_res_exit;\n\n\tif (status)\n\t\tice_debug(hw, ICE_DBG_RES, \"resource %d acquire type %d failed.\\n\", res, access);\n\n\t \n\ttimeout = time_left;\n\twhile (status && timeout && time_left) {\n\t\tmdelay(delay);\n\t\ttimeout = (timeout > delay) ? timeout - delay : 0;\n\t\tstatus = ice_aq_req_res(hw, res, access, 0, &time_left, NULL);\n\n\t\tif (status == -EALREADY)\n\t\t\t \n\t\t\tbreak;\n\n\t\tif (!status)\n\t\t\t \n\t\t\tbreak;\n\t}\n\tif (status && status != -EALREADY)\n\t\tice_debug(hw, ICE_DBG_RES, \"resource acquire timed out.\\n\");\n\nice_acquire_res_exit:\n\tif (status == -EALREADY) {\n\t\tif (access == ICE_RES_WRITE)\n\t\t\tice_debug(hw, ICE_DBG_RES, \"resource indicates no work to do.\\n\");\n\t\telse\n\t\t\tice_debug(hw, ICE_DBG_RES, \"Warning: -EALREADY not expected\\n\");\n\t}\n\treturn status;\n}\n\n \nvoid ice_release_res(struct ice_hw *hw, enum ice_aq_res_ids res)\n{\n\tunsigned long timeout;\n\tint status;\n\n\t \n\ttimeout = jiffies + 10 * ICE_CTL_Q_SQ_CMD_TIMEOUT;\n\tdo {\n\t\tstatus = ice_aq_release_res(hw, res, 0, NULL);\n\t\tif (status != -EIO)\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t} while (time_before(jiffies, timeout));\n}\n\n \nint ice_aq_alloc_free_res(struct ice_hw *hw,\n\t\t\t  struct ice_aqc_alloc_free_res_elem *buf, u16 buf_size,\n\t\t\t  enum ice_adminq_opc opc)\n{\n\tstruct ice_aqc_alloc_free_res_cmd *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.sw_res_ctrl;\n\n\tif (!buf || buf_size < flex_array_size(buf, elem, 1))\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, opc);\n\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tcmd->num_entries = cpu_to_le16(1);\n\n\treturn ice_aq_send_cmd(hw, &desc, buf, buf_size, NULL);\n}\n\n \nint\nice_alloc_hw_res(struct ice_hw *hw, u16 type, u16 num, bool btm, u16 *res)\n{\n\tstruct ice_aqc_alloc_free_res_elem *buf;\n\tu16 buf_len;\n\tint status;\n\n\tbuf_len = struct_size(buf, elem, num);\n\tbuf = kzalloc(buf_len, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t \n\tbuf->num_elems = cpu_to_le16(num);\n\tbuf->res_type = cpu_to_le16(type | ICE_AQC_RES_TYPE_FLAG_DEDICATED |\n\t\t\t\t    ICE_AQC_RES_TYPE_FLAG_IGNORE_INDEX);\n\tif (btm)\n\t\tbuf->res_type |= cpu_to_le16(ICE_AQC_RES_TYPE_FLAG_SCAN_BOTTOM);\n\n\tstatus = ice_aq_alloc_free_res(hw, buf, buf_len, ice_aqc_opc_alloc_res);\n\tif (status)\n\t\tgoto ice_alloc_res_exit;\n\n\tmemcpy(res, buf->elem, sizeof(*buf->elem) * num);\n\nice_alloc_res_exit:\n\tkfree(buf);\n\treturn status;\n}\n\n \nint ice_free_hw_res(struct ice_hw *hw, u16 type, u16 num, u16 *res)\n{\n\tstruct ice_aqc_alloc_free_res_elem *buf;\n\tu16 buf_len;\n\tint status;\n\n\tbuf_len = struct_size(buf, elem, num);\n\tbuf = kzalloc(buf_len, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t \n\tbuf->num_elems = cpu_to_le16(num);\n\tbuf->res_type = cpu_to_le16(type);\n\tmemcpy(buf->elem, res, sizeof(*buf->elem) * num);\n\n\tstatus = ice_aq_alloc_free_res(hw, buf, buf_len, ice_aqc_opc_free_res);\n\tif (status)\n\t\tice_debug(hw, ICE_DBG_SW, \"CQ CMD Buffer:\\n\");\n\n\tkfree(buf);\n\treturn status;\n}\n\n \nstatic u32 ice_get_num_per_func(struct ice_hw *hw, u32 max)\n{\n\tu8 funcs;\n\n#define ICE_CAPS_VALID_FUNCS_M\t0xFF\n\tfuncs = hweight8(hw->dev_caps.common_cap.valid_functions &\n\t\t\t ICE_CAPS_VALID_FUNCS_M);\n\n\tif (!funcs)\n\t\treturn 0;\n\n\treturn max / funcs;\n}\n\n \nstatic bool\nice_parse_common_caps(struct ice_hw *hw, struct ice_hw_common_caps *caps,\n\t\t      struct ice_aqc_list_caps_elem *elem, const char *prefix)\n{\n\tu32 logical_id = le32_to_cpu(elem->logical_id);\n\tu32 phys_id = le32_to_cpu(elem->phys_id);\n\tu32 number = le32_to_cpu(elem->number);\n\tu16 cap = le16_to_cpu(elem->cap);\n\tbool found = true;\n\n\tswitch (cap) {\n\tcase ICE_AQC_CAPS_VALID_FUNCTIONS:\n\t\tcaps->valid_functions = number;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: valid_functions (bitmap) = %d\\n\", prefix,\n\t\t\t  caps->valid_functions);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_SRIOV:\n\t\tcaps->sr_iov_1_1 = (number == 1);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: sr_iov_1_1 = %d\\n\", prefix,\n\t\t\t  caps->sr_iov_1_1);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_DCB:\n\t\tcaps->dcb = (number == 1);\n\t\tcaps->active_tc_bitmap = logical_id;\n\t\tcaps->maxtc = phys_id;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: dcb = %d\\n\", prefix, caps->dcb);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: active_tc_bitmap = %d\\n\", prefix,\n\t\t\t  caps->active_tc_bitmap);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: maxtc = %d\\n\", prefix, caps->maxtc);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_RSS:\n\t\tcaps->rss_table_size = number;\n\t\tcaps->rss_table_entry_width = logical_id;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: rss_table_size = %d\\n\", prefix,\n\t\t\t  caps->rss_table_size);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: rss_table_entry_width = %d\\n\", prefix,\n\t\t\t  caps->rss_table_entry_width);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_RXQS:\n\t\tcaps->num_rxq = number;\n\t\tcaps->rxq_first_id = phys_id;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: num_rxq = %d\\n\", prefix,\n\t\t\t  caps->num_rxq);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: rxq_first_id = %d\\n\", prefix,\n\t\t\t  caps->rxq_first_id);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_TXQS:\n\t\tcaps->num_txq = number;\n\t\tcaps->txq_first_id = phys_id;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: num_txq = %d\\n\", prefix,\n\t\t\t  caps->num_txq);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: txq_first_id = %d\\n\", prefix,\n\t\t\t  caps->txq_first_id);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_MSIX:\n\t\tcaps->num_msix_vectors = number;\n\t\tcaps->msix_vector_first_id = phys_id;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: num_msix_vectors = %d\\n\", prefix,\n\t\t\t  caps->num_msix_vectors);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: msix_vector_first_id = %d\\n\", prefix,\n\t\t\t  caps->msix_vector_first_id);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_PENDING_NVM_VER:\n\t\tcaps->nvm_update_pending_nvm = true;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: update_pending_nvm\\n\", prefix);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_PENDING_OROM_VER:\n\t\tcaps->nvm_update_pending_orom = true;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: update_pending_orom\\n\", prefix);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_PENDING_NET_VER:\n\t\tcaps->nvm_update_pending_netlist = true;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: update_pending_netlist\\n\", prefix);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_NVM_MGMT:\n\t\tcaps->nvm_unified_update =\n\t\t\t(number & ICE_NVM_MGMT_UNIFIED_UPD_SUPPORT) ?\n\t\t\ttrue : false;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: nvm_unified_update = %d\\n\", prefix,\n\t\t\t  caps->nvm_unified_update);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_RDMA:\n\t\tcaps->rdma = (number == 1);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: rdma = %d\\n\", prefix, caps->rdma);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_MAX_MTU:\n\t\tcaps->max_mtu = number;\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: max_mtu = %d\\n\",\n\t\t\t  prefix, caps->max_mtu);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_PCIE_RESET_AVOIDANCE:\n\t\tcaps->pcie_reset_avoidance = (number > 0);\n\t\tice_debug(hw, ICE_DBG_INIT,\n\t\t\t  \"%s: pcie_reset_avoidance = %d\\n\", prefix,\n\t\t\t  caps->pcie_reset_avoidance);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_POST_UPDATE_RESET_RESTRICT:\n\t\tcaps->reset_restrict_support = (number == 1);\n\t\tice_debug(hw, ICE_DBG_INIT,\n\t\t\t  \"%s: reset_restrict_support = %d\\n\", prefix,\n\t\t\t  caps->reset_restrict_support);\n\t\tbreak;\n\tcase ICE_AQC_CAPS_FW_LAG_SUPPORT:\n\t\tcaps->roce_lag = !!(number & ICE_AQC_BIT_ROCEV2_LAG);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: roce_lag = %u\\n\",\n\t\t\t  prefix, caps->roce_lag);\n\t\tcaps->sriov_lag = !!(number & ICE_AQC_BIT_SRIOV_LAG);\n\t\tice_debug(hw, ICE_DBG_INIT, \"%s: sriov_lag = %u\\n\",\n\t\t\t  prefix, caps->sriov_lag);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tfound = false;\n\t}\n\n\treturn found;\n}\n\n \nstatic void\nice_recalc_port_limited_caps(struct ice_hw *hw, struct ice_hw_common_caps *caps)\n{\n\t \n\tif (hw->dev_caps.num_funcs > 4) {\n\t\t \n\t\tcaps->maxtc = 4;\n\t\tice_debug(hw, ICE_DBG_INIT, \"reducing maxtc to %d (based on #ports)\\n\",\n\t\t\t  caps->maxtc);\n\t\tif (caps->rdma) {\n\t\t\tice_debug(hw, ICE_DBG_INIT, \"forcing RDMA off\\n\");\n\t\t\tcaps->rdma = 0;\n\t\t}\n\n\t\t \n\t\tif (caps == &hw->dev_caps.common_cap)\n\t\t\tdev_info(ice_hw_to_dev(hw), \"RDMA functionality is not available with the current device configuration.\\n\");\n\t}\n}\n\n \nstatic void\nice_parse_vf_func_caps(struct ice_hw *hw, struct ice_hw_func_caps *func_p,\n\t\t       struct ice_aqc_list_caps_elem *cap)\n{\n\tu32 logical_id = le32_to_cpu(cap->logical_id);\n\tu32 number = le32_to_cpu(cap->number);\n\n\tfunc_p->num_allocd_vfs = number;\n\tfunc_p->vf_base_id = logical_id;\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: num_allocd_vfs = %d\\n\",\n\t\t  func_p->num_allocd_vfs);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: vf_base_id = %d\\n\",\n\t\t  func_p->vf_base_id);\n}\n\n \nstatic void\nice_parse_vsi_func_caps(struct ice_hw *hw, struct ice_hw_func_caps *func_p,\n\t\t\tstruct ice_aqc_list_caps_elem *cap)\n{\n\tfunc_p->guar_num_vsi = ice_get_num_per_func(hw, ICE_MAX_VSI);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: guar_num_vsi (fw) = %d\\n\",\n\t\t  le32_to_cpu(cap->number));\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: guar_num_vsi = %d\\n\",\n\t\t  func_p->guar_num_vsi);\n}\n\n \nstatic void\nice_parse_1588_func_caps(struct ice_hw *hw, struct ice_hw_func_caps *func_p,\n\t\t\t struct ice_aqc_list_caps_elem *cap)\n{\n\tstruct ice_ts_func_info *info = &func_p->ts_func_info;\n\tu32 number = le32_to_cpu(cap->number);\n\n\tinfo->ena = ((number & ICE_TS_FUNC_ENA_M) != 0);\n\tfunc_p->common_cap.ieee_1588 = info->ena;\n\n\tinfo->src_tmr_owned = ((number & ICE_TS_SRC_TMR_OWND_M) != 0);\n\tinfo->tmr_ena = ((number & ICE_TS_TMR_ENA_M) != 0);\n\tinfo->tmr_index_owned = ((number & ICE_TS_TMR_IDX_OWND_M) != 0);\n\tinfo->tmr_index_assoc = ((number & ICE_TS_TMR_IDX_ASSOC_M) != 0);\n\n\tinfo->clk_freq = (number & ICE_TS_CLK_FREQ_M) >> ICE_TS_CLK_FREQ_S;\n\tinfo->clk_src = ((number & ICE_TS_CLK_SRC_M) != 0);\n\n\tif (info->clk_freq < NUM_ICE_TIME_REF_FREQ) {\n\t\tinfo->time_ref = (enum ice_time_ref_freq)info->clk_freq;\n\t} else {\n\t\t \n\t\tice_debug(hw, ICE_DBG_INIT, \"1588 func caps: unknown clock frequency %u\\n\",\n\t\t\t  info->clk_freq);\n\t\tinfo->time_ref = ICE_TIME_REF_FREQ_25_000;\n\t}\n\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: ieee_1588 = %u\\n\",\n\t\t  func_p->common_cap.ieee_1588);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: src_tmr_owned = %u\\n\",\n\t\t  info->src_tmr_owned);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: tmr_ena = %u\\n\",\n\t\t  info->tmr_ena);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: tmr_index_owned = %u\\n\",\n\t\t  info->tmr_index_owned);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: tmr_index_assoc = %u\\n\",\n\t\t  info->tmr_index_assoc);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: clk_freq = %u\\n\",\n\t\t  info->clk_freq);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: clk_src = %u\\n\",\n\t\t  info->clk_src);\n}\n\n \nstatic void\nice_parse_fdir_func_caps(struct ice_hw *hw, struct ice_hw_func_caps *func_p)\n{\n\tu32 reg_val, val;\n\n\treg_val = rd32(hw, GLQF_FD_SIZE);\n\tval = (reg_val & GLQF_FD_SIZE_FD_GSIZE_M) >>\n\t\tGLQF_FD_SIZE_FD_GSIZE_S;\n\tfunc_p->fd_fltr_guar =\n\t\tice_get_num_per_func(hw, val);\n\tval = (reg_val & GLQF_FD_SIZE_FD_BSIZE_M) >>\n\t\tGLQF_FD_SIZE_FD_BSIZE_S;\n\tfunc_p->fd_fltr_best_effort = val;\n\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: fd_fltr_guar = %d\\n\",\n\t\t  func_p->fd_fltr_guar);\n\tice_debug(hw, ICE_DBG_INIT, \"func caps: fd_fltr_best_effort = %d\\n\",\n\t\t  func_p->fd_fltr_best_effort);\n}\n\n \nstatic void\nice_parse_func_caps(struct ice_hw *hw, struct ice_hw_func_caps *func_p,\n\t\t    void *buf, u32 cap_count)\n{\n\tstruct ice_aqc_list_caps_elem *cap_resp;\n\tu32 i;\n\n\tcap_resp = buf;\n\n\tmemset(func_p, 0, sizeof(*func_p));\n\n\tfor (i = 0; i < cap_count; i++) {\n\t\tu16 cap = le16_to_cpu(cap_resp[i].cap);\n\t\tbool found;\n\n\t\tfound = ice_parse_common_caps(hw, &func_p->common_cap,\n\t\t\t\t\t      &cap_resp[i], \"func caps\");\n\n\t\tswitch (cap) {\n\t\tcase ICE_AQC_CAPS_VF:\n\t\t\tice_parse_vf_func_caps(hw, func_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tcase ICE_AQC_CAPS_VSI:\n\t\t\tice_parse_vsi_func_caps(hw, func_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tcase ICE_AQC_CAPS_1588:\n\t\t\tice_parse_1588_func_caps(hw, func_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tcase ICE_AQC_CAPS_FD:\n\t\t\tice_parse_fdir_func_caps(hw, func_p);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tif (!found)\n\t\t\t\tice_debug(hw, ICE_DBG_INIT, \"func caps: unknown capability[%d]: 0x%x\\n\",\n\t\t\t\t\t  i, cap);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tice_recalc_port_limited_caps(hw, &func_p->common_cap);\n}\n\n \nstatic void\nice_parse_valid_functions_cap(struct ice_hw *hw, struct ice_hw_dev_caps *dev_p,\n\t\t\t      struct ice_aqc_list_caps_elem *cap)\n{\n\tu32 number = le32_to_cpu(cap->number);\n\n\tdev_p->num_funcs = hweight32(number);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: num_funcs = %d\\n\",\n\t\t  dev_p->num_funcs);\n}\n\n \nstatic void\nice_parse_vf_dev_caps(struct ice_hw *hw, struct ice_hw_dev_caps *dev_p,\n\t\t      struct ice_aqc_list_caps_elem *cap)\n{\n\tu32 number = le32_to_cpu(cap->number);\n\n\tdev_p->num_vfs_exposed = number;\n\tice_debug(hw, ICE_DBG_INIT, \"dev_caps: num_vfs_exposed = %d\\n\",\n\t\t  dev_p->num_vfs_exposed);\n}\n\n \nstatic void\nice_parse_vsi_dev_caps(struct ice_hw *hw, struct ice_hw_dev_caps *dev_p,\n\t\t       struct ice_aqc_list_caps_elem *cap)\n{\n\tu32 number = le32_to_cpu(cap->number);\n\n\tdev_p->num_vsi_allocd_to_host = number;\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: num_vsi_allocd_to_host = %d\\n\",\n\t\t  dev_p->num_vsi_allocd_to_host);\n}\n\n \nstatic void\nice_parse_1588_dev_caps(struct ice_hw *hw, struct ice_hw_dev_caps *dev_p,\n\t\t\tstruct ice_aqc_list_caps_elem *cap)\n{\n\tstruct ice_ts_dev_info *info = &dev_p->ts_dev_info;\n\tu32 logical_id = le32_to_cpu(cap->logical_id);\n\tu32 phys_id = le32_to_cpu(cap->phys_id);\n\tu32 number = le32_to_cpu(cap->number);\n\n\tinfo->ena = ((number & ICE_TS_DEV_ENA_M) != 0);\n\tdev_p->common_cap.ieee_1588 = info->ena;\n\n\tinfo->tmr0_owner = number & ICE_TS_TMR0_OWNR_M;\n\tinfo->tmr0_owned = ((number & ICE_TS_TMR0_OWND_M) != 0);\n\tinfo->tmr0_ena = ((number & ICE_TS_TMR0_ENA_M) != 0);\n\n\tinfo->tmr1_owner = (number & ICE_TS_TMR1_OWNR_M) >> ICE_TS_TMR1_OWNR_S;\n\tinfo->tmr1_owned = ((number & ICE_TS_TMR1_OWND_M) != 0);\n\tinfo->tmr1_ena = ((number & ICE_TS_TMR1_ENA_M) != 0);\n\n\tinfo->ts_ll_read = ((number & ICE_TS_LL_TX_TS_READ_M) != 0);\n\n\tinfo->ena_ports = logical_id;\n\tinfo->tmr_own_map = phys_id;\n\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: ieee_1588 = %u\\n\",\n\t\t  dev_p->common_cap.ieee_1588);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: tmr0_owner = %u\\n\",\n\t\t  info->tmr0_owner);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: tmr0_owned = %u\\n\",\n\t\t  info->tmr0_owned);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: tmr0_ena = %u\\n\",\n\t\t  info->tmr0_ena);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: tmr1_owner = %u\\n\",\n\t\t  info->tmr1_owner);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: tmr1_owned = %u\\n\",\n\t\t  info->tmr1_owned);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: tmr1_ena = %u\\n\",\n\t\t  info->tmr1_ena);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: ts_ll_read = %u\\n\",\n\t\t  info->ts_ll_read);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: ieee_1588 ena_ports = %u\\n\",\n\t\t  info->ena_ports);\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: tmr_own_map = %u\\n\",\n\t\t  info->tmr_own_map);\n}\n\n \nstatic void\nice_parse_fdir_dev_caps(struct ice_hw *hw, struct ice_hw_dev_caps *dev_p,\n\t\t\tstruct ice_aqc_list_caps_elem *cap)\n{\n\tu32 number = le32_to_cpu(cap->number);\n\n\tdev_p->num_flow_director_fltr = number;\n\tice_debug(hw, ICE_DBG_INIT, \"dev caps: num_flow_director_fltr = %d\\n\",\n\t\t  dev_p->num_flow_director_fltr);\n}\n\n \nstatic void\nice_parse_dev_caps(struct ice_hw *hw, struct ice_hw_dev_caps *dev_p,\n\t\t   void *buf, u32 cap_count)\n{\n\tstruct ice_aqc_list_caps_elem *cap_resp;\n\tu32 i;\n\n\tcap_resp = buf;\n\n\tmemset(dev_p, 0, sizeof(*dev_p));\n\n\tfor (i = 0; i < cap_count; i++) {\n\t\tu16 cap = le16_to_cpu(cap_resp[i].cap);\n\t\tbool found;\n\n\t\tfound = ice_parse_common_caps(hw, &dev_p->common_cap,\n\t\t\t\t\t      &cap_resp[i], \"dev caps\");\n\n\t\tswitch (cap) {\n\t\tcase ICE_AQC_CAPS_VALID_FUNCTIONS:\n\t\t\tice_parse_valid_functions_cap(hw, dev_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tcase ICE_AQC_CAPS_VF:\n\t\t\tice_parse_vf_dev_caps(hw, dev_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tcase ICE_AQC_CAPS_VSI:\n\t\t\tice_parse_vsi_dev_caps(hw, dev_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tcase ICE_AQC_CAPS_1588:\n\t\t\tice_parse_1588_dev_caps(hw, dev_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tcase  ICE_AQC_CAPS_FD:\n\t\t\tice_parse_fdir_dev_caps(hw, dev_p, &cap_resp[i]);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tif (!found)\n\t\t\t\tice_debug(hw, ICE_DBG_INIT, \"dev caps: unknown capability[%d]: 0x%x\\n\",\n\t\t\t\t\t  i, cap);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tice_recalc_port_limited_caps(hw, &dev_p->common_cap);\n}\n\n \nstatic int\nice_aq_get_netlist_node(struct ice_hw *hw, struct ice_aqc_get_link_topo *cmd,\n\t\t\tu8 *node_part_number, u16 *node_handle)\n{\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_link_topo);\n\tdesc.params.get_link_topo = *cmd;\n\n\tif (ice_aq_send_cmd(hw, &desc, NULL, 0, NULL))\n\t\treturn -EIO;\n\n\tif (node_handle)\n\t\t*node_handle = le16_to_cpu(desc.params.get_link_topo.addr.handle);\n\tif (node_part_number)\n\t\t*node_part_number = desc.params.get_link_topo.node_part_num;\n\n\treturn 0;\n}\n\n \nbool ice_is_pf_c827(struct ice_hw *hw)\n{\n\tstruct ice_aqc_get_link_topo cmd = {};\n\tu8 node_part_number;\n\tu16 node_handle;\n\tint status;\n\n\tif (hw->mac_type != ICE_MAC_E810)\n\t\treturn false;\n\n\tif (hw->device_id != ICE_DEV_ID_E810C_QSFP)\n\t\treturn true;\n\n\tcmd.addr.topo_params.node_type_ctx =\n\t\tFIELD_PREP(ICE_AQC_LINK_TOPO_NODE_TYPE_M, ICE_AQC_LINK_TOPO_NODE_TYPE_PHY) |\n\t\tFIELD_PREP(ICE_AQC_LINK_TOPO_NODE_CTX_M, ICE_AQC_LINK_TOPO_NODE_CTX_PORT);\n\tcmd.addr.topo_params.index = 0;\n\n\tstatus = ice_aq_get_netlist_node(hw, &cmd, &node_part_number,\n\t\t\t\t\t &node_handle);\n\n\tif (status || node_part_number != ICE_AQC_GET_LINK_TOPO_NODE_NR_C827)\n\t\treturn false;\n\n\tif (node_handle == E810C_QSFP_C827_0_HANDLE || node_handle == E810C_QSFP_C827_1_HANDLE)\n\t\treturn true;\n\n\treturn false;\n}\n\n \nint\nice_aq_list_caps(struct ice_hw *hw, void *buf, u16 buf_size, u32 *cap_count,\n\t\t enum ice_adminq_opc opc, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_list_caps *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tcmd = &desc.params.get_cap;\n\n\tif (opc != ice_aqc_opc_list_func_caps &&\n\t    opc != ice_aqc_opc_list_dev_caps)\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, opc);\n\tstatus = ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n\n\tif (cap_count)\n\t\t*cap_count = le32_to_cpu(cmd->count);\n\n\treturn status;\n}\n\n \nint\nice_discover_dev_caps(struct ice_hw *hw, struct ice_hw_dev_caps *dev_caps)\n{\n\tu32 cap_count = 0;\n\tvoid *cbuf;\n\tint status;\n\n\tcbuf = kzalloc(ICE_AQ_MAX_BUF_LEN, GFP_KERNEL);\n\tif (!cbuf)\n\t\treturn -ENOMEM;\n\n\t \n\tcap_count = ICE_AQ_MAX_BUF_LEN / sizeof(struct ice_aqc_list_caps_elem);\n\n\tstatus = ice_aq_list_caps(hw, cbuf, ICE_AQ_MAX_BUF_LEN, &cap_count,\n\t\t\t\t  ice_aqc_opc_list_dev_caps, NULL);\n\tif (!status)\n\t\tice_parse_dev_caps(hw, dev_caps, cbuf, cap_count);\n\tkfree(cbuf);\n\n\treturn status;\n}\n\n \nstatic int\nice_discover_func_caps(struct ice_hw *hw, struct ice_hw_func_caps *func_caps)\n{\n\tu32 cap_count = 0;\n\tvoid *cbuf;\n\tint status;\n\n\tcbuf = kzalloc(ICE_AQ_MAX_BUF_LEN, GFP_KERNEL);\n\tif (!cbuf)\n\t\treturn -ENOMEM;\n\n\t \n\tcap_count = ICE_AQ_MAX_BUF_LEN / sizeof(struct ice_aqc_list_caps_elem);\n\n\tstatus = ice_aq_list_caps(hw, cbuf, ICE_AQ_MAX_BUF_LEN, &cap_count,\n\t\t\t\t  ice_aqc_opc_list_func_caps, NULL);\n\tif (!status)\n\t\tice_parse_func_caps(hw, func_caps, cbuf, cap_count);\n\tkfree(cbuf);\n\n\treturn status;\n}\n\n \nvoid ice_set_safe_mode_caps(struct ice_hw *hw)\n{\n\tstruct ice_hw_func_caps *func_caps = &hw->func_caps;\n\tstruct ice_hw_dev_caps *dev_caps = &hw->dev_caps;\n\tstruct ice_hw_common_caps cached_caps;\n\tu32 num_funcs;\n\n\t \n\tcached_caps = func_caps->common_cap;\n\n\t \n\tmemset(func_caps, 0, sizeof(*func_caps));\n\n#define ICE_RESTORE_FUNC_CAP(name) \\\n\tfunc_caps->common_cap.name = cached_caps.name\n\n\t \n\tICE_RESTORE_FUNC_CAP(valid_functions);\n\tICE_RESTORE_FUNC_CAP(txq_first_id);\n\tICE_RESTORE_FUNC_CAP(rxq_first_id);\n\tICE_RESTORE_FUNC_CAP(msix_vector_first_id);\n\tICE_RESTORE_FUNC_CAP(max_mtu);\n\tICE_RESTORE_FUNC_CAP(nvm_unified_update);\n\tICE_RESTORE_FUNC_CAP(nvm_update_pending_nvm);\n\tICE_RESTORE_FUNC_CAP(nvm_update_pending_orom);\n\tICE_RESTORE_FUNC_CAP(nvm_update_pending_netlist);\n\n\t \n\tfunc_caps->common_cap.num_rxq = 1;\n\tfunc_caps->common_cap.num_txq = 1;\n\n\t \n\tfunc_caps->common_cap.num_msix_vectors = 2;\n\tfunc_caps->guar_num_vsi = 1;\n\n\t \n\tcached_caps = dev_caps->common_cap;\n\tnum_funcs = dev_caps->num_funcs;\n\n\t \n\tmemset(dev_caps, 0, sizeof(*dev_caps));\n\n#define ICE_RESTORE_DEV_CAP(name) \\\n\tdev_caps->common_cap.name = cached_caps.name\n\n\t \n\tICE_RESTORE_DEV_CAP(valid_functions);\n\tICE_RESTORE_DEV_CAP(txq_first_id);\n\tICE_RESTORE_DEV_CAP(rxq_first_id);\n\tICE_RESTORE_DEV_CAP(msix_vector_first_id);\n\tICE_RESTORE_DEV_CAP(max_mtu);\n\tICE_RESTORE_DEV_CAP(nvm_unified_update);\n\tICE_RESTORE_DEV_CAP(nvm_update_pending_nvm);\n\tICE_RESTORE_DEV_CAP(nvm_update_pending_orom);\n\tICE_RESTORE_DEV_CAP(nvm_update_pending_netlist);\n\tdev_caps->num_funcs = num_funcs;\n\n\t \n\tdev_caps->common_cap.num_rxq = num_funcs;\n\tdev_caps->common_cap.num_txq = num_funcs;\n\n\t \n\tdev_caps->common_cap.num_msix_vectors = 2 * num_funcs;\n}\n\n \nint ice_get_caps(struct ice_hw *hw)\n{\n\tint status;\n\n\tstatus = ice_discover_dev_caps(hw, &hw->dev_caps);\n\tif (status)\n\t\treturn status;\n\n\treturn ice_discover_func_caps(hw, &hw->func_caps);\n}\n\n \nint\nice_aq_manage_mac_write(struct ice_hw *hw, const u8 *mac_addr, u8 flags,\n\t\t\tstruct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_manage_mac_write *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.mac_write;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_manage_mac_write);\n\n\tcmd->flags = flags;\n\tether_addr_copy(cmd->mac_addr, mac_addr);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nstatic int ice_aq_clear_pxe_mode(struct ice_hw *hw)\n{\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_clear_pxe_mode);\n\tdesc.params.clear_pxe.rx_cnt = ICE_AQC_CLEAR_PXE_RX_CNT;\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, NULL);\n}\n\n \nvoid ice_clear_pxe_mode(struct ice_hw *hw)\n{\n\tif (ice_check_sq_alive(hw, &hw->adminq))\n\t\tice_aq_clear_pxe_mode(hw);\n}\n\n \nint\nice_aq_set_port_params(struct ice_port_info *pi, bool double_vlan,\n\t\t       struct ice_sq_cd *cd)\n\n{\n\tstruct ice_aqc_set_port_params *cmd;\n\tstruct ice_hw *hw = pi->hw;\n\tstruct ice_aq_desc desc;\n\tu16 cmd_flags = 0;\n\n\tcmd = &desc.params.set_port_params;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_port_params);\n\tif (double_vlan)\n\t\tcmd_flags |= ICE_AQC_SET_P_PARAMS_DOUBLE_VLAN_ENA;\n\tcmd->cmd_flags = cpu_to_le16(cmd_flags);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nbool ice_is_100m_speed_supported(struct ice_hw *hw)\n{\n\tswitch (hw->device_id) {\n\tcase ICE_DEV_ID_E822C_SGMII:\n\tcase ICE_DEV_ID_E822L_SGMII:\n\tcase ICE_DEV_ID_E823L_1GBE:\n\tcase ICE_DEV_ID_E823C_SGMII:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstatic u16\nice_get_link_speed_based_on_phy_type(u64 phy_type_low, u64 phy_type_high)\n{\n\tu16 speed_phy_type_high = ICE_AQ_LINK_SPEED_UNKNOWN;\n\tu16 speed_phy_type_low = ICE_AQ_LINK_SPEED_UNKNOWN;\n\n\tswitch (phy_type_low) {\n\tcase ICE_PHY_TYPE_LOW_100BASE_TX:\n\tcase ICE_PHY_TYPE_LOW_100M_SGMII:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_100MB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_1000BASE_T:\n\tcase ICE_PHY_TYPE_LOW_1000BASE_SX:\n\tcase ICE_PHY_TYPE_LOW_1000BASE_LX:\n\tcase ICE_PHY_TYPE_LOW_1000BASE_KX:\n\tcase ICE_PHY_TYPE_LOW_1G_SGMII:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_1000MB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_2500BASE_T:\n\tcase ICE_PHY_TYPE_LOW_2500BASE_X:\n\tcase ICE_PHY_TYPE_LOW_2500BASE_KX:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_2500MB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_5GBASE_T:\n\tcase ICE_PHY_TYPE_LOW_5GBASE_KR:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_5GB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_10GBASE_T:\n\tcase ICE_PHY_TYPE_LOW_10G_SFI_DA:\n\tcase ICE_PHY_TYPE_LOW_10GBASE_SR:\n\tcase ICE_PHY_TYPE_LOW_10GBASE_LR:\n\tcase ICE_PHY_TYPE_LOW_10GBASE_KR_CR1:\n\tcase ICE_PHY_TYPE_LOW_10G_SFI_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_10G_SFI_C2C:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_10GB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_25GBASE_T:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_CR:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_CR_S:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_CR1:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_SR:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_LR:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_KR:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_KR_S:\n\tcase ICE_PHY_TYPE_LOW_25GBASE_KR1:\n\tcase ICE_PHY_TYPE_LOW_25G_AUI_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_25G_AUI_C2C:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_25GB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_40GBASE_CR4:\n\tcase ICE_PHY_TYPE_LOW_40GBASE_SR4:\n\tcase ICE_PHY_TYPE_LOW_40GBASE_LR4:\n\tcase ICE_PHY_TYPE_LOW_40GBASE_KR4:\n\tcase ICE_PHY_TYPE_LOW_40G_XLAUI_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_40G_XLAUI:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_40GB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_50GBASE_CR2:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_SR2:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_LR2:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_KR2:\n\tcase ICE_PHY_TYPE_LOW_50G_LAUI2_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_50G_LAUI2:\n\tcase ICE_PHY_TYPE_LOW_50G_AUI2_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_50G_AUI2:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_CP:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_SR:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_FR:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_LR:\n\tcase ICE_PHY_TYPE_LOW_50GBASE_KR_PAM4:\n\tcase ICE_PHY_TYPE_LOW_50G_AUI1_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_50G_AUI1:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_50GB;\n\t\tbreak;\n\tcase ICE_PHY_TYPE_LOW_100GBASE_CR4:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_SR4:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_LR4:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_KR4:\n\tcase ICE_PHY_TYPE_LOW_100G_CAUI4_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_100G_CAUI4:\n\tcase ICE_PHY_TYPE_LOW_100G_AUI4_AOC_ACC:\n\tcase ICE_PHY_TYPE_LOW_100G_AUI4:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_CR_PAM4:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_KR_PAM4:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_CP2:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_SR2:\n\tcase ICE_PHY_TYPE_LOW_100GBASE_DR:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_100GB;\n\t\tbreak;\n\tdefault:\n\t\tspeed_phy_type_low = ICE_AQ_LINK_SPEED_UNKNOWN;\n\t\tbreak;\n\t}\n\n\tswitch (phy_type_high) {\n\tcase ICE_PHY_TYPE_HIGH_100GBASE_KR2_PAM4:\n\tcase ICE_PHY_TYPE_HIGH_100G_CAUI2_AOC_ACC:\n\tcase ICE_PHY_TYPE_HIGH_100G_CAUI2:\n\tcase ICE_PHY_TYPE_HIGH_100G_AUI2_AOC_ACC:\n\tcase ICE_PHY_TYPE_HIGH_100G_AUI2:\n\t\tspeed_phy_type_high = ICE_AQ_LINK_SPEED_100GB;\n\t\tbreak;\n\tdefault:\n\t\tspeed_phy_type_high = ICE_AQ_LINK_SPEED_UNKNOWN;\n\t\tbreak;\n\t}\n\n\tif (speed_phy_type_low == ICE_AQ_LINK_SPEED_UNKNOWN &&\n\t    speed_phy_type_high == ICE_AQ_LINK_SPEED_UNKNOWN)\n\t\treturn ICE_AQ_LINK_SPEED_UNKNOWN;\n\telse if (speed_phy_type_low != ICE_AQ_LINK_SPEED_UNKNOWN &&\n\t\t speed_phy_type_high != ICE_AQ_LINK_SPEED_UNKNOWN)\n\t\treturn ICE_AQ_LINK_SPEED_UNKNOWN;\n\telse if (speed_phy_type_low != ICE_AQ_LINK_SPEED_UNKNOWN &&\n\t\t speed_phy_type_high == ICE_AQ_LINK_SPEED_UNKNOWN)\n\t\treturn speed_phy_type_low;\n\telse\n\t\treturn speed_phy_type_high;\n}\n\n \nvoid\nice_update_phy_type(u64 *phy_type_low, u64 *phy_type_high,\n\t\t    u16 link_speeds_bitmap)\n{\n\tu64 pt_high;\n\tu64 pt_low;\n\tint index;\n\tu16 speed;\n\n\t \n\tfor (index = 0; index <= ICE_PHY_TYPE_LOW_MAX_INDEX; index++) {\n\t\tpt_low = BIT_ULL(index);\n\t\tspeed = ice_get_link_speed_based_on_phy_type(pt_low, 0);\n\n\t\tif (link_speeds_bitmap & speed)\n\t\t\t*phy_type_low |= BIT_ULL(index);\n\t}\n\n\t \n\tfor (index = 0; index <= ICE_PHY_TYPE_HIGH_MAX_INDEX; index++) {\n\t\tpt_high = BIT_ULL(index);\n\t\tspeed = ice_get_link_speed_based_on_phy_type(0, pt_high);\n\n\t\tif (link_speeds_bitmap & speed)\n\t\t\t*phy_type_high |= BIT_ULL(index);\n\t}\n}\n\n \nint\nice_aq_set_phy_cfg(struct ice_hw *hw, struct ice_port_info *pi,\n\t\t   struct ice_aqc_set_phy_cfg_data *cfg, struct ice_sq_cd *cd)\n{\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tif (!cfg)\n\t\treturn -EINVAL;\n\n\t \n\tif (cfg->caps & ~ICE_AQ_PHY_ENA_VALID_MASK) {\n\t\tice_debug(hw, ICE_DBG_PHY, \"Invalid bit is set in ice_aqc_set_phy_cfg_data->caps : 0x%x\\n\",\n\t\t\t  cfg->caps);\n\n\t\tcfg->caps &= ICE_AQ_PHY_ENA_VALID_MASK;\n\t}\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_phy_cfg);\n\tdesc.params.set_phy.lport_num = pi->lport;\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tice_debug(hw, ICE_DBG_LINK, \"set phy cfg\\n\");\n\tice_debug(hw, ICE_DBG_LINK, \"\tphy_type_low = 0x%llx\\n\",\n\t\t  (unsigned long long)le64_to_cpu(cfg->phy_type_low));\n\tice_debug(hw, ICE_DBG_LINK, \"\tphy_type_high = 0x%llx\\n\",\n\t\t  (unsigned long long)le64_to_cpu(cfg->phy_type_high));\n\tice_debug(hw, ICE_DBG_LINK, \"\tcaps = 0x%x\\n\", cfg->caps);\n\tice_debug(hw, ICE_DBG_LINK, \"\tlow_power_ctrl_an = 0x%x\\n\",\n\t\t  cfg->low_power_ctrl_an);\n\tice_debug(hw, ICE_DBG_LINK, \"\teee_cap = 0x%x\\n\", cfg->eee_cap);\n\tice_debug(hw, ICE_DBG_LINK, \"\teeer_value = 0x%x\\n\", cfg->eeer_value);\n\tice_debug(hw, ICE_DBG_LINK, \"\tlink_fec_opt = 0x%x\\n\",\n\t\t  cfg->link_fec_opt);\n\n\tstatus = ice_aq_send_cmd(hw, &desc, cfg, sizeof(*cfg), cd);\n\tif (hw->adminq.sq_last_status == ICE_AQ_RC_EMODE)\n\t\tstatus = 0;\n\n\tif (!status)\n\t\tpi->phy.curr_user_phy_cfg = *cfg;\n\n\treturn status;\n}\n\n \nint ice_update_link_info(struct ice_port_info *pi)\n{\n\tstruct ice_link_status *li;\n\tint status;\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\n\tli = &pi->phy.link_info;\n\n\tstatus = ice_aq_get_link_info(pi, true, NULL, NULL);\n\tif (status)\n\t\treturn status;\n\n\tif (li->link_info & ICE_AQ_MEDIA_AVAILABLE) {\n\t\tstruct ice_aqc_get_phy_caps_data *pcaps;\n\t\tstruct ice_hw *hw;\n\n\t\thw = pi->hw;\n\t\tpcaps = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*pcaps),\n\t\t\t\t     GFP_KERNEL);\n\t\tif (!pcaps)\n\t\t\treturn -ENOMEM;\n\n\t\tstatus = ice_aq_get_phy_caps(pi, false, ICE_AQC_REPORT_TOPO_CAP_MEDIA,\n\t\t\t\t\t     pcaps, NULL);\n\n\t\tdevm_kfree(ice_hw_to_dev(hw), pcaps);\n\t}\n\n\treturn status;\n}\n\n \nstatic void\nice_cache_phy_user_req(struct ice_port_info *pi,\n\t\t       struct ice_phy_cache_mode_data cache_data,\n\t\t       enum ice_phy_cache_mode cache_mode)\n{\n\tif (!pi)\n\t\treturn;\n\n\tswitch (cache_mode) {\n\tcase ICE_FC_MODE:\n\t\tpi->phy.curr_user_fc_req = cache_data.data.curr_user_fc_req;\n\t\tbreak;\n\tcase ICE_SPEED_MODE:\n\t\tpi->phy.curr_user_speed_req =\n\t\t\tcache_data.data.curr_user_speed_req;\n\t\tbreak;\n\tcase ICE_FEC_MODE:\n\t\tpi->phy.curr_user_fec_req = cache_data.data.curr_user_fec_req;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\n \nenum ice_fc_mode ice_caps_to_fc_mode(u8 caps)\n{\n\tif (caps & ICE_AQC_PHY_EN_TX_LINK_PAUSE &&\n\t    caps & ICE_AQC_PHY_EN_RX_LINK_PAUSE)\n\t\treturn ICE_FC_FULL;\n\n\tif (caps & ICE_AQC_PHY_EN_TX_LINK_PAUSE)\n\t\treturn ICE_FC_TX_PAUSE;\n\n\tif (caps & ICE_AQC_PHY_EN_RX_LINK_PAUSE)\n\t\treturn ICE_FC_RX_PAUSE;\n\n\treturn ICE_FC_NONE;\n}\n\n \nenum ice_fec_mode ice_caps_to_fec_mode(u8 caps, u8 fec_options)\n{\n\tif (caps & ICE_AQC_PHY_EN_AUTO_FEC)\n\t\treturn ICE_FEC_AUTO;\n\n\tif (fec_options & (ICE_AQC_PHY_FEC_10G_KR_40G_KR4_EN |\n\t\t\t   ICE_AQC_PHY_FEC_10G_KR_40G_KR4_REQ |\n\t\t\t   ICE_AQC_PHY_FEC_25G_KR_CLAUSE74_EN |\n\t\t\t   ICE_AQC_PHY_FEC_25G_KR_REQ))\n\t\treturn ICE_FEC_BASER;\n\n\tif (fec_options & (ICE_AQC_PHY_FEC_25G_RS_528_REQ |\n\t\t\t   ICE_AQC_PHY_FEC_25G_RS_544_REQ |\n\t\t\t   ICE_AQC_PHY_FEC_25G_RS_CLAUSE91_EN))\n\t\treturn ICE_FEC_RS;\n\n\treturn ICE_FEC_NONE;\n}\n\n \nint\nice_cfg_phy_fc(struct ice_port_info *pi, struct ice_aqc_set_phy_cfg_data *cfg,\n\t       enum ice_fc_mode req_mode)\n{\n\tstruct ice_phy_cache_mode_data cache_data;\n\tu8 pause_mask = 0x0;\n\n\tif (!pi || !cfg)\n\t\treturn -EINVAL;\n\n\tswitch (req_mode) {\n\tcase ICE_FC_FULL:\n\t\tpause_mask |= ICE_AQC_PHY_EN_TX_LINK_PAUSE;\n\t\tpause_mask |= ICE_AQC_PHY_EN_RX_LINK_PAUSE;\n\t\tbreak;\n\tcase ICE_FC_RX_PAUSE:\n\t\tpause_mask |= ICE_AQC_PHY_EN_RX_LINK_PAUSE;\n\t\tbreak;\n\tcase ICE_FC_TX_PAUSE:\n\t\tpause_mask |= ICE_AQC_PHY_EN_TX_LINK_PAUSE;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tcfg->caps &= ~(ICE_AQC_PHY_EN_TX_LINK_PAUSE |\n\t\tICE_AQC_PHY_EN_RX_LINK_PAUSE);\n\n\t \n\tcfg->caps |= pause_mask;\n\n\t \n\tcache_data.data.curr_user_fc_req = req_mode;\n\tice_cache_phy_user_req(pi, cache_data, ICE_FC_MODE);\n\n\treturn 0;\n}\n\n \nint\nice_set_fc(struct ice_port_info *pi, u8 *aq_failures, bool ena_auto_link_update)\n{\n\tstruct ice_aqc_set_phy_cfg_data cfg = { 0 };\n\tstruct ice_aqc_get_phy_caps_data *pcaps;\n\tstruct ice_hw *hw;\n\tint status;\n\n\tif (!pi || !aq_failures)\n\t\treturn -EINVAL;\n\n\t*aq_failures = 0;\n\thw = pi->hw;\n\n\tpcaps = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*pcaps), GFP_KERNEL);\n\tif (!pcaps)\n\t\treturn -ENOMEM;\n\n\t \n\tstatus = ice_aq_get_phy_caps(pi, false, ICE_AQC_REPORT_ACTIVE_CFG,\n\t\t\t\t     pcaps, NULL);\n\tif (status) {\n\t\t*aq_failures = ICE_SET_FC_AQ_FAIL_GET;\n\t\tgoto out;\n\t}\n\n\tice_copy_phy_caps_to_cfg(pi, pcaps, &cfg);\n\n\t \n\tstatus = ice_cfg_phy_fc(pi, &cfg, pi->fc.req_mode);\n\tif (status)\n\t\tgoto out;\n\n\t \n\tif (cfg.caps != pcaps->caps) {\n\t\tint retry_count, retry_max = 10;\n\n\t\t \n\t\tif (ena_auto_link_update)\n\t\t\tcfg.caps |= ICE_AQ_PHY_ENA_AUTO_LINK_UPDT;\n\n\t\tstatus = ice_aq_set_phy_cfg(hw, pi, &cfg, NULL);\n\t\tif (status) {\n\t\t\t*aq_failures = ICE_SET_FC_AQ_FAIL_SET;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tfor (retry_count = 0; retry_count < retry_max; retry_count++) {\n\t\t\tstatus = ice_update_link_info(pi);\n\n\t\t\tif (!status)\n\t\t\t\tbreak;\n\n\t\t\tmdelay(100);\n\t\t}\n\n\t\tif (status)\n\t\t\t*aq_failures = ICE_SET_FC_AQ_FAIL_UPDATE;\n\t}\n\nout:\n\tdevm_kfree(ice_hw_to_dev(hw), pcaps);\n\treturn status;\n}\n\n \nbool\nice_phy_caps_equals_cfg(struct ice_aqc_get_phy_caps_data *phy_caps,\n\t\t\tstruct ice_aqc_set_phy_cfg_data *phy_cfg)\n{\n\tu8 caps_mask, cfg_mask;\n\n\tif (!phy_caps || !phy_cfg)\n\t\treturn false;\n\n\t \n\tcaps_mask = ICE_AQC_PHY_CAPS_MASK & ~(ICE_AQC_PHY_AN_MODE |\n\t\t\t\t\t      ICE_AQC_GET_PHY_EN_MOD_QUAL);\n\tcfg_mask = ICE_AQ_PHY_ENA_VALID_MASK & ~ICE_AQ_PHY_ENA_AUTO_LINK_UPDT;\n\n\tif (phy_caps->phy_type_low != phy_cfg->phy_type_low ||\n\t    phy_caps->phy_type_high != phy_cfg->phy_type_high ||\n\t    ((phy_caps->caps & caps_mask) != (phy_cfg->caps & cfg_mask)) ||\n\t    phy_caps->low_power_ctrl_an != phy_cfg->low_power_ctrl_an ||\n\t    phy_caps->eee_cap != phy_cfg->eee_cap ||\n\t    phy_caps->eeer_value != phy_cfg->eeer_value ||\n\t    phy_caps->link_fec_options != phy_cfg->link_fec_opt)\n\t\treturn false;\n\n\treturn true;\n}\n\n \nvoid\nice_copy_phy_caps_to_cfg(struct ice_port_info *pi,\n\t\t\t struct ice_aqc_get_phy_caps_data *caps,\n\t\t\t struct ice_aqc_set_phy_cfg_data *cfg)\n{\n\tif (!pi || !caps || !cfg)\n\t\treturn;\n\n\tmemset(cfg, 0, sizeof(*cfg));\n\tcfg->phy_type_low = caps->phy_type_low;\n\tcfg->phy_type_high = caps->phy_type_high;\n\tcfg->caps = caps->caps;\n\tcfg->low_power_ctrl_an = caps->low_power_ctrl_an;\n\tcfg->eee_cap = caps->eee_cap;\n\tcfg->eeer_value = caps->eeer_value;\n\tcfg->link_fec_opt = caps->link_fec_options;\n\tcfg->module_compliance_enforcement =\n\t\tcaps->module_compliance_enforcement;\n}\n\n \nint\nice_cfg_phy_fec(struct ice_port_info *pi, struct ice_aqc_set_phy_cfg_data *cfg,\n\t\tenum ice_fec_mode fec)\n{\n\tstruct ice_aqc_get_phy_caps_data *pcaps;\n\tstruct ice_hw *hw;\n\tint status;\n\n\tif (!pi || !cfg)\n\t\treturn -EINVAL;\n\n\thw = pi->hw;\n\n\tpcaps = kzalloc(sizeof(*pcaps), GFP_KERNEL);\n\tif (!pcaps)\n\t\treturn -ENOMEM;\n\n\tstatus = ice_aq_get_phy_caps(pi, false,\n\t\t\t\t     (ice_fw_supports_report_dflt_cfg(hw) ?\n\t\t\t\t      ICE_AQC_REPORT_DFLT_CFG :\n\t\t\t\t      ICE_AQC_REPORT_TOPO_CAP_MEDIA), pcaps, NULL);\n\tif (status)\n\t\tgoto out;\n\n\tcfg->caps |= pcaps->caps & ICE_AQC_PHY_EN_AUTO_FEC;\n\tcfg->link_fec_opt = pcaps->link_fec_options;\n\n\tswitch (fec) {\n\tcase ICE_FEC_BASER:\n\t\t \n\t\tcfg->link_fec_opt &= ICE_AQC_PHY_FEC_10G_KR_40G_KR4_EN |\n\t\t\tICE_AQC_PHY_FEC_25G_KR_CLAUSE74_EN;\n\t\tcfg->link_fec_opt |= ICE_AQC_PHY_FEC_10G_KR_40G_KR4_REQ |\n\t\t\tICE_AQC_PHY_FEC_25G_KR_REQ;\n\t\tbreak;\n\tcase ICE_FEC_RS:\n\t\t \n\t\tcfg->link_fec_opt &= ICE_AQC_PHY_FEC_25G_RS_CLAUSE91_EN;\n\t\tcfg->link_fec_opt |= ICE_AQC_PHY_FEC_25G_RS_528_REQ |\n\t\t\tICE_AQC_PHY_FEC_25G_RS_544_REQ;\n\t\tbreak;\n\tcase ICE_FEC_NONE:\n\t\t \n\t\tcfg->link_fec_opt &= ~ICE_AQC_PHY_FEC_MASK;\n\t\tbreak;\n\tcase ICE_FEC_AUTO:\n\t\t \n\t\tcfg->caps &= ICE_AQC_PHY_CAPS_MASK;\n\t\tcfg->link_fec_opt |= pcaps->link_fec_options;\n\t\tbreak;\n\tdefault:\n\t\tstatus = -EINVAL;\n\t\tbreak;\n\t}\n\n\tif (fec == ICE_FEC_AUTO && ice_fw_supports_link_override(hw) &&\n\t    !ice_fw_supports_report_dflt_cfg(hw)) {\n\t\tstruct ice_link_default_override_tlv tlv = { 0 };\n\n\t\tstatus = ice_get_link_default_override(&tlv, pi);\n\t\tif (status)\n\t\t\tgoto out;\n\n\t\tif (!(tlv.options & ICE_LINK_OVERRIDE_STRICT_MODE) &&\n\t\t    (tlv.options & ICE_LINK_OVERRIDE_EN))\n\t\t\tcfg->link_fec_opt = tlv.fec_options;\n\t}\n\nout:\n\tkfree(pcaps);\n\n\treturn status;\n}\n\n \nint ice_get_link_status(struct ice_port_info *pi, bool *link_up)\n{\n\tstruct ice_phy_info *phy_info;\n\tint status = 0;\n\n\tif (!pi || !link_up)\n\t\treturn -EINVAL;\n\n\tphy_info = &pi->phy;\n\n\tif (phy_info->get_link_info) {\n\t\tstatus = ice_update_link_info(pi);\n\n\t\tif (status)\n\t\t\tice_debug(pi->hw, ICE_DBG_LINK, \"get link status error, status = %d\\n\",\n\t\t\t\t  status);\n\t}\n\n\t*link_up = phy_info->link_info.link_info & ICE_AQ_LINK_UP;\n\n\treturn status;\n}\n\n \nint\nice_aq_set_link_restart_an(struct ice_port_info *pi, bool ena_link,\n\t\t\t   struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_restart_an *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.restart_an;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_restart_an);\n\n\tcmd->cmd_flags = ICE_AQC_RESTART_AN_LINK_RESTART;\n\tcmd->lport_num = pi->lport;\n\tif (ena_link)\n\t\tcmd->cmd_flags |= ICE_AQC_RESTART_AN_LINK_ENABLE;\n\telse\n\t\tcmd->cmd_flags &= ~ICE_AQC_RESTART_AN_LINK_ENABLE;\n\n\treturn ice_aq_send_cmd(pi->hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_aq_set_event_mask(struct ice_hw *hw, u8 port_num, u16 mask,\n\t\t      struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_set_event_mask *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.set_event_mask;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_event_mask);\n\n\tcmd->lport_num = port_num;\n\n\tcmd->event_mask = cpu_to_le16(mask);\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_aq_set_mac_loopback(struct ice_hw *hw, bool ena_lpbk, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_set_mac_lb *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.set_mac_lb;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_mac_lb);\n\tif (ena_lpbk)\n\t\tcmd->lb_mode = ICE_AQ_MAC_LB_EN;\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_aq_set_port_id_led(struct ice_port_info *pi, bool is_orig_mode,\n\t\t       struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_set_port_id_led *cmd;\n\tstruct ice_hw *hw = pi->hw;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.set_port_id_led;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_port_id_led);\n\n\tif (is_orig_mode)\n\t\tcmd->ident_mode = ICE_AQC_PORT_IDENT_LED_ORIG;\n\telse\n\t\tcmd->ident_mode = ICE_AQC_PORT_IDENT_LED_BLINK;\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_aq_get_port_options(struct ice_hw *hw,\n\t\t\tstruct ice_aqc_get_port_options_elem *options,\n\t\t\tu8 *option_count, u8 lport, bool lport_valid,\n\t\t\tu8 *active_option_idx, bool *active_option_valid,\n\t\t\tu8 *pending_option_idx, bool *pending_option_valid)\n{\n\tstruct ice_aqc_get_port_options *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\tu8 i;\n\n\t \n\tif (*option_count < ICE_AQC_PORT_OPT_COUNT_M)\n\t\treturn -EINVAL;\n\n\tcmd = &desc.params.get_port_options;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_port_options);\n\n\tif (lport_valid)\n\t\tcmd->lport_num = lport;\n\tcmd->lport_num_valid = lport_valid;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, options,\n\t\t\t\t *option_count * sizeof(*options), NULL);\n\tif (status)\n\t\treturn status;\n\n\t \n\t*option_count = FIELD_GET(ICE_AQC_PORT_OPT_COUNT_M,\n\t\t\t\t  cmd->port_options_count);\n\tice_debug(hw, ICE_DBG_PHY, \"options: %x\\n\", *option_count);\n\t*active_option_valid = FIELD_GET(ICE_AQC_PORT_OPT_VALID,\n\t\t\t\t\t cmd->port_options);\n\tif (*active_option_valid) {\n\t\t*active_option_idx = FIELD_GET(ICE_AQC_PORT_OPT_ACTIVE_M,\n\t\t\t\t\t       cmd->port_options);\n\t\tif (*active_option_idx > (*option_count - 1))\n\t\t\treturn -EIO;\n\t\tice_debug(hw, ICE_DBG_PHY, \"active idx: %x\\n\",\n\t\t\t  *active_option_idx);\n\t}\n\n\t*pending_option_valid = FIELD_GET(ICE_AQC_PENDING_PORT_OPT_VALID,\n\t\t\t\t\t  cmd->pending_port_option_status);\n\tif (*pending_option_valid) {\n\t\t*pending_option_idx = FIELD_GET(ICE_AQC_PENDING_PORT_OPT_IDX_M,\n\t\t\t\t\t\tcmd->pending_port_option_status);\n\t\tif (*pending_option_idx > (*option_count - 1))\n\t\t\treturn -EIO;\n\t\tice_debug(hw, ICE_DBG_PHY, \"pending idx: %x\\n\",\n\t\t\t  *pending_option_idx);\n\t}\n\n\t \n\tfor (i = 0; i < *option_count; i++) {\n\t\toptions[i].pmd = FIELD_GET(ICE_AQC_PORT_OPT_PMD_COUNT_M,\n\t\t\t\t\t   options[i].pmd);\n\t\toptions[i].max_lane_speed = FIELD_GET(ICE_AQC_PORT_OPT_MAX_LANE_M,\n\t\t\t\t\t\t      options[i].max_lane_speed);\n\t\tice_debug(hw, ICE_DBG_PHY, \"pmds: %x max speed: %x\\n\",\n\t\t\t  options[i].pmd, options[i].max_lane_speed);\n\t}\n\n\treturn 0;\n}\n\n \nint\nice_aq_set_port_option(struct ice_hw *hw, u8 lport, u8 lport_valid,\n\t\t       u8 new_option)\n{\n\tstruct ice_aqc_set_port_option *cmd;\n\tstruct ice_aq_desc desc;\n\n\tif (new_option > ICE_AQC_PORT_OPT_COUNT_M)\n\t\treturn -EINVAL;\n\n\tcmd = &desc.params.set_port_option;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_port_option);\n\n\tif (lport_valid)\n\t\tcmd->lport_num = lport;\n\n\tcmd->lport_num_valid = lport_valid;\n\tcmd->selected_port_option = new_option;\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, NULL);\n}\n\n \nint\nice_aq_sff_eeprom(struct ice_hw *hw, u16 lport, u8 bus_addr,\n\t\t  u16 mem_addr, u8 page, u8 set_page, u8 *data, u8 length,\n\t\t  bool write, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_sff_eeprom *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tif (!data || (mem_addr & 0xff00))\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_sff_eeprom);\n\tcmd = &desc.params.read_write_sff_param;\n\tdesc.flags = cpu_to_le16(ICE_AQ_FLAG_RD);\n\tcmd->lport_num = (u8)(lport & 0xff);\n\tcmd->lport_num_valid = (u8)((lport >> 8) & 0x01);\n\tcmd->i2c_bus_addr = cpu_to_le16(((bus_addr >> 1) &\n\t\t\t\t\t ICE_AQC_SFF_I2CBUS_7BIT_M) |\n\t\t\t\t\t((set_page <<\n\t\t\t\t\t  ICE_AQC_SFF_SET_EEPROM_PAGE_S) &\n\t\t\t\t\t ICE_AQC_SFF_SET_EEPROM_PAGE_M));\n\tcmd->i2c_mem_addr = cpu_to_le16(mem_addr & 0xff);\n\tcmd->eeprom_page = cpu_to_le16((u16)page << ICE_AQC_SFF_EEPROM_PAGE_S);\n\tif (write)\n\t\tcmd->i2c_bus_addr |= cpu_to_le16(ICE_AQC_SFF_IS_WRITE);\n\n\tstatus = ice_aq_send_cmd(hw, &desc, data, length, cd);\n\treturn status;\n}\n\nstatic enum ice_lut_size ice_lut_type_to_size(enum ice_lut_type type)\n{\n\tswitch (type) {\n\tcase ICE_LUT_VSI:\n\t\treturn ICE_LUT_VSI_SIZE;\n\tcase ICE_LUT_GLOBAL:\n\t\treturn ICE_LUT_GLOBAL_SIZE;\n\tcase ICE_LUT_PF:\n\t\treturn ICE_LUT_PF_SIZE;\n\t}\n\tWARN_ONCE(1, \"incorrect type passed\");\n\treturn ICE_LUT_VSI_SIZE;\n}\n\nstatic enum ice_aqc_lut_flags ice_lut_size_to_flag(enum ice_lut_size size)\n{\n\tswitch (size) {\n\tcase ICE_LUT_VSI_SIZE:\n\t\treturn ICE_AQC_LUT_SIZE_SMALL;\n\tcase ICE_LUT_GLOBAL_SIZE:\n\t\treturn ICE_AQC_LUT_SIZE_512;\n\tcase ICE_LUT_PF_SIZE:\n\t\treturn ICE_AQC_LUT_SIZE_2K;\n\t}\n\tWARN_ONCE(1, \"incorrect size passed\");\n\treturn 0;\n}\n\n \nstatic int\n__ice_aq_get_set_rss_lut(struct ice_hw *hw,\n\t\t\t struct ice_aq_get_set_rss_lut_params *params, bool set)\n{\n\tu16 opcode, vsi_id, vsi_handle = params->vsi_handle, glob_lut_idx = 0;\n\tenum ice_lut_type lut_type = params->lut_type;\n\tstruct ice_aqc_get_set_rss_lut *desc_params;\n\tenum ice_aqc_lut_flags flags;\n\tenum ice_lut_size lut_size;\n\tstruct ice_aq_desc desc;\n\tu8 *lut = params->lut;\n\n\n\tif (!lut || !ice_is_vsi_valid(hw, vsi_handle))\n\t\treturn -EINVAL;\n\n\tlut_size = ice_lut_type_to_size(lut_type);\n\tif (lut_size > params->lut_size)\n\t\treturn -EINVAL;\n\telse if (set && lut_size != params->lut_size)\n\t\treturn -EINVAL;\n\n\topcode = set ? ice_aqc_opc_set_rss_lut : ice_aqc_opc_get_rss_lut;\n\tice_fill_dflt_direct_cmd_desc(&desc, opcode);\n\tif (set)\n\t\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tdesc_params = &desc.params.get_set_rss_lut;\n\tvsi_id = ice_get_hw_vsi_num(hw, vsi_handle);\n\tdesc_params->vsi_id = cpu_to_le16(vsi_id | ICE_AQC_RSS_VSI_VALID);\n\n\tif (lut_type == ICE_LUT_GLOBAL)\n\t\tglob_lut_idx = FIELD_PREP(ICE_AQC_LUT_GLOBAL_IDX,\n\t\t\t\t\t  params->global_lut_id);\n\n\tflags = lut_type | glob_lut_idx | ice_lut_size_to_flag(lut_size);\n\tdesc_params->flags = cpu_to_le16(flags);\n\n\treturn ice_aq_send_cmd(hw, &desc, lut, lut_size, NULL);\n}\n\n \nint\nice_aq_get_rss_lut(struct ice_hw *hw, struct ice_aq_get_set_rss_lut_params *get_params)\n{\n\treturn __ice_aq_get_set_rss_lut(hw, get_params, false);\n}\n\n \nint\nice_aq_set_rss_lut(struct ice_hw *hw, struct ice_aq_get_set_rss_lut_params *set_params)\n{\n\treturn __ice_aq_get_set_rss_lut(hw, set_params, true);\n}\n\n \nstatic int\n__ice_aq_get_set_rss_key(struct ice_hw *hw, u16 vsi_id,\n\t\t\t struct ice_aqc_get_set_rss_keys *key, bool set)\n{\n\tstruct ice_aqc_get_set_rss_key *desc_params;\n\tu16 key_size = sizeof(*key);\n\tstruct ice_aq_desc desc;\n\n\tif (set) {\n\t\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_rss_key);\n\t\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\t} else {\n\t\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_rss_key);\n\t}\n\n\tdesc_params = &desc.params.get_set_rss_key;\n\tdesc_params->vsi_id = cpu_to_le16(vsi_id | ICE_AQC_RSS_VSI_VALID);\n\n\treturn ice_aq_send_cmd(hw, &desc, key, key_size, NULL);\n}\n\n \nint\nice_aq_get_rss_key(struct ice_hw *hw, u16 vsi_handle,\n\t\t   struct ice_aqc_get_set_rss_keys *key)\n{\n\tif (!ice_is_vsi_valid(hw, vsi_handle) || !key)\n\t\treturn -EINVAL;\n\n\treturn __ice_aq_get_set_rss_key(hw, ice_get_hw_vsi_num(hw, vsi_handle),\n\t\t\t\t\tkey, false);\n}\n\n \nint\nice_aq_set_rss_key(struct ice_hw *hw, u16 vsi_handle,\n\t\t   struct ice_aqc_get_set_rss_keys *keys)\n{\n\tif (!ice_is_vsi_valid(hw, vsi_handle) || !keys)\n\t\treturn -EINVAL;\n\n\treturn __ice_aq_get_set_rss_key(hw, ice_get_hw_vsi_num(hw, vsi_handle),\n\t\t\t\t\tkeys, true);\n}\n\n \nstatic int\nice_aq_add_lan_txq(struct ice_hw *hw, u8 num_qgrps,\n\t\t   struct ice_aqc_add_tx_qgrp *qg_list, u16 buf_size,\n\t\t   struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_add_tx_qgrp *list;\n\tstruct ice_aqc_add_txqs *cmd;\n\tstruct ice_aq_desc desc;\n\tu16 i, sum_size = 0;\n\n\tcmd = &desc.params.add_txqs;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_add_txqs);\n\n\tif (!qg_list)\n\t\treturn -EINVAL;\n\n\tif (num_qgrps > ICE_LAN_TXQ_MAX_QGRPS)\n\t\treturn -EINVAL;\n\n\tfor (i = 0, list = qg_list; i < num_qgrps; i++) {\n\t\tsum_size += struct_size(list, txqs, list->num_txqs);\n\t\tlist = (struct ice_aqc_add_tx_qgrp *)(list->txqs +\n\t\t\t\t\t\t      list->num_txqs);\n\t}\n\n\tif (buf_size != sum_size)\n\t\treturn -EINVAL;\n\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tcmd->num_qgrps = num_qgrps;\n\n\treturn ice_aq_send_cmd(hw, &desc, qg_list, buf_size, cd);\n}\n\n \nstatic int\nice_aq_dis_lan_txq(struct ice_hw *hw, u8 num_qgrps,\n\t\t   struct ice_aqc_dis_txq_item *qg_list, u16 buf_size,\n\t\t   enum ice_disq_rst_src rst_src, u16 vmvf_num,\n\t\t   struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_dis_txq_item *item;\n\tstruct ice_aqc_dis_txqs *cmd;\n\tstruct ice_aq_desc desc;\n\tu16 i, sz = 0;\n\tint status;\n\n\tcmd = &desc.params.dis_txqs;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_dis_txqs);\n\n\t \n\tif (!qg_list && !rst_src)\n\t\treturn -EINVAL;\n\n\tif (num_qgrps > ICE_LAN_TXQ_MAX_QGRPS)\n\t\treturn -EINVAL;\n\n\tcmd->num_entries = num_qgrps;\n\n\tcmd->vmvf_and_timeout = cpu_to_le16((5 << ICE_AQC_Q_DIS_TIMEOUT_S) &\n\t\t\t\t\t    ICE_AQC_Q_DIS_TIMEOUT_M);\n\n\tswitch (rst_src) {\n\tcase ICE_VM_RESET:\n\t\tcmd->cmd_type = ICE_AQC_Q_DIS_CMD_VM_RESET;\n\t\tcmd->vmvf_and_timeout |=\n\t\t\tcpu_to_le16(vmvf_num & ICE_AQC_Q_DIS_VMVF_NUM_M);\n\t\tbreak;\n\tcase ICE_VF_RESET:\n\t\tcmd->cmd_type = ICE_AQC_Q_DIS_CMD_VF_RESET;\n\t\t \n\t\tcmd->vmvf_and_timeout |=\n\t\t\tcpu_to_le16((vmvf_num + hw->func_caps.vf_base_id) &\n\t\t\t\t    ICE_AQC_Q_DIS_VMVF_NUM_M);\n\t\tbreak;\n\tcase ICE_NO_RESET:\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tcmd->cmd_type |= ICE_AQC_Q_DIS_CMD_FLUSH_PIPE;\n\t \n\tif (!qg_list)\n\t\tgoto do_aq;\n\n\t \n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tfor (i = 0, item = qg_list; i < num_qgrps; i++) {\n\t\tu16 item_size = struct_size(item, q_id, item->num_qs);\n\n\t\t \n\t\tif ((item->num_qs % 2) == 0)\n\t\t\titem_size += 2;\n\n\t\tsz += item_size;\n\n\t\titem = (struct ice_aqc_dis_txq_item *)((u8 *)item + item_size);\n\t}\n\n\tif (buf_size != sz)\n\t\treturn -EINVAL;\n\ndo_aq:\n\tstatus = ice_aq_send_cmd(hw, &desc, qg_list, buf_size, cd);\n\tif (status) {\n\t\tif (!qg_list)\n\t\t\tice_debug(hw, ICE_DBG_SCHED, \"VM%d disable failed %d\\n\",\n\t\t\t\t  vmvf_num, hw->adminq.sq_last_status);\n\t\telse\n\t\t\tice_debug(hw, ICE_DBG_SCHED, \"disable queue %d failed %d\\n\",\n\t\t\t\t  le16_to_cpu(qg_list[0].q_id[0]),\n\t\t\t\t  hw->adminq.sq_last_status);\n\t}\n\treturn status;\n}\n\n \nint\nice_aq_cfg_lan_txq(struct ice_hw *hw, struct ice_aqc_cfg_txqs_buf *buf,\n\t\t   u16 buf_size, u16 num_qs, u8 oldport, u8 newport,\n\t\t   struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_cfg_txqs *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tcmd = &desc.params.cfg_txqs;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_cfg_txqs);\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tif (!buf)\n\t\treturn -EINVAL;\n\n\tcmd->cmd_type = ICE_AQC_Q_CFG_TC_CHNG;\n\tcmd->num_qs = num_qs;\n\tcmd->port_num_chng = (oldport & ICE_AQC_Q_CFG_SRC_PRT_M);\n\tcmd->port_num_chng |= (newport << ICE_AQC_Q_CFG_DST_PRT_S) &\n\t\t\t      ICE_AQC_Q_CFG_DST_PRT_M;\n\tcmd->time_out = (5 << ICE_AQC_Q_CFG_TIMEOUT_S) &\n\t\t\tICE_AQC_Q_CFG_TIMEOUT_M;\n\tcmd->blocked_cgds = 0;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n\tif (status)\n\t\tice_debug(hw, ICE_DBG_SCHED, \"Failed to reconfigure nodes %d\\n\",\n\t\t\t  hw->adminq.sq_last_status);\n\treturn status;\n}\n\n \nstatic int\nice_aq_add_rdma_qsets(struct ice_hw *hw, u8 num_qset_grps,\n\t\t      struct ice_aqc_add_rdma_qset_data *qset_list,\n\t\t      u16 buf_size, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_add_rdma_qset_data *list;\n\tstruct ice_aqc_add_rdma_qset *cmd;\n\tstruct ice_aq_desc desc;\n\tu16 i, sum_size = 0;\n\n\tcmd = &desc.params.add_rdma_qset;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_add_rdma_qset);\n\n\tif (num_qset_grps > ICE_LAN_TXQ_MAX_QGRPS)\n\t\treturn -EINVAL;\n\n\tfor (i = 0, list = qset_list; i < num_qset_grps; i++) {\n\t\tu16 num_qsets = le16_to_cpu(list->num_qsets);\n\n\t\tsum_size += struct_size(list, rdma_qsets, num_qsets);\n\t\tlist = (struct ice_aqc_add_rdma_qset_data *)(list->rdma_qsets +\n\t\t\t\t\t\t\t     num_qsets);\n\t}\n\n\tif (buf_size != sum_size)\n\t\treturn -EINVAL;\n\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tcmd->num_qset_grps = num_qset_grps;\n\n\treturn ice_aq_send_cmd(hw, &desc, qset_list, buf_size, cd);\n}\n\n \n\n \nstatic void\nice_write_byte(u8 *src_ctx, u8 *dest_ctx, const struct ice_ctx_ele *ce_info)\n{\n\tu8 src_byte, dest_byte, mask;\n\tu8 *from, *dest;\n\tu16 shift_width;\n\n\t \n\tfrom = src_ctx + ce_info->offset;\n\n\t \n\tshift_width = ce_info->lsb % 8;\n\tmask = (u8)(BIT(ce_info->width) - 1);\n\n\tsrc_byte = *from;\n\tsrc_byte &= mask;\n\n\t \n\tmask <<= shift_width;\n\tsrc_byte <<= shift_width;\n\n\t \n\tdest = dest_ctx + (ce_info->lsb / 8);\n\n\tmemcpy(&dest_byte, dest, sizeof(dest_byte));\n\n\tdest_byte &= ~mask;\t \n\tdest_byte |= src_byte;\t \n\n\t \n\tmemcpy(dest, &dest_byte, sizeof(dest_byte));\n}\n\n \nstatic void\nice_write_word(u8 *src_ctx, u8 *dest_ctx, const struct ice_ctx_ele *ce_info)\n{\n\tu16 src_word, mask;\n\t__le16 dest_word;\n\tu8 *from, *dest;\n\tu16 shift_width;\n\n\t \n\tfrom = src_ctx + ce_info->offset;\n\n\t \n\tshift_width = ce_info->lsb % 8;\n\tmask = BIT(ce_info->width) - 1;\n\n\t \n\tsrc_word = *(u16 *)from;\n\tsrc_word &= mask;\n\n\t \n\tmask <<= shift_width;\n\tsrc_word <<= shift_width;\n\n\t \n\tdest = dest_ctx + (ce_info->lsb / 8);\n\n\tmemcpy(&dest_word, dest, sizeof(dest_word));\n\n\tdest_word &= ~(cpu_to_le16(mask));\t \n\tdest_word |= cpu_to_le16(src_word);\t \n\n\t \n\tmemcpy(dest, &dest_word, sizeof(dest_word));\n}\n\n \nstatic void\nice_write_dword(u8 *src_ctx, u8 *dest_ctx, const struct ice_ctx_ele *ce_info)\n{\n\tu32 src_dword, mask;\n\t__le32 dest_dword;\n\tu8 *from, *dest;\n\tu16 shift_width;\n\n\t \n\tfrom = src_ctx + ce_info->offset;\n\n\t \n\tshift_width = ce_info->lsb % 8;\n\n\t \n\tif (ce_info->width < 32)\n\t\tmask = BIT(ce_info->width) - 1;\n\telse\n\t\tmask = (u32)~0;\n\n\t \n\tsrc_dword = *(u32 *)from;\n\tsrc_dword &= mask;\n\n\t \n\tmask <<= shift_width;\n\tsrc_dword <<= shift_width;\n\n\t \n\tdest = dest_ctx + (ce_info->lsb / 8);\n\n\tmemcpy(&dest_dword, dest, sizeof(dest_dword));\n\n\tdest_dword &= ~(cpu_to_le32(mask));\t \n\tdest_dword |= cpu_to_le32(src_dword);\t \n\n\t \n\tmemcpy(dest, &dest_dword, sizeof(dest_dword));\n}\n\n \nstatic void\nice_write_qword(u8 *src_ctx, u8 *dest_ctx, const struct ice_ctx_ele *ce_info)\n{\n\tu64 src_qword, mask;\n\t__le64 dest_qword;\n\tu8 *from, *dest;\n\tu16 shift_width;\n\n\t \n\tfrom = src_ctx + ce_info->offset;\n\n\t \n\tshift_width = ce_info->lsb % 8;\n\n\t \n\tif (ce_info->width < 64)\n\t\tmask = BIT_ULL(ce_info->width) - 1;\n\telse\n\t\tmask = (u64)~0;\n\n\t \n\tsrc_qword = *(u64 *)from;\n\tsrc_qword &= mask;\n\n\t \n\tmask <<= shift_width;\n\tsrc_qword <<= shift_width;\n\n\t \n\tdest = dest_ctx + (ce_info->lsb / 8);\n\n\tmemcpy(&dest_qword, dest, sizeof(dest_qword));\n\n\tdest_qword &= ~(cpu_to_le64(mask));\t \n\tdest_qword |= cpu_to_le64(src_qword);\t \n\n\t \n\tmemcpy(dest, &dest_qword, sizeof(dest_qword));\n}\n\n \nint\nice_set_ctx(struct ice_hw *hw, u8 *src_ctx, u8 *dest_ctx,\n\t    const struct ice_ctx_ele *ce_info)\n{\n\tint f;\n\n\tfor (f = 0; ce_info[f].width; f++) {\n\t\t \n\t\tif (ce_info[f].width > (ce_info[f].size_of * BITS_PER_BYTE)) {\n\t\t\tice_debug(hw, ICE_DBG_QCTX, \"Field %d width of %d bits larger than size of %d byte(s) ... skipping write\\n\",\n\t\t\t\t  f, ce_info[f].width, ce_info[f].size_of);\n\t\t\tcontinue;\n\t\t}\n\t\tswitch (ce_info[f].size_of) {\n\t\tcase sizeof(u8):\n\t\t\tice_write_byte(src_ctx, dest_ctx, &ce_info[f]);\n\t\t\tbreak;\n\t\tcase sizeof(u16):\n\t\t\tice_write_word(src_ctx, dest_ctx, &ce_info[f]);\n\t\t\tbreak;\n\t\tcase sizeof(u32):\n\t\t\tice_write_dword(src_ctx, dest_ctx, &ce_info[f]);\n\t\t\tbreak;\n\t\tcase sizeof(u64):\n\t\t\tice_write_qword(src_ctx, dest_ctx, &ce_info[f]);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstruct ice_q_ctx *\nice_get_lan_q_ctx(struct ice_hw *hw, u16 vsi_handle, u8 tc, u16 q_handle)\n{\n\tstruct ice_vsi_ctx *vsi;\n\tstruct ice_q_ctx *q_ctx;\n\n\tvsi = ice_get_vsi_ctx(hw, vsi_handle);\n\tif (!vsi)\n\t\treturn NULL;\n\tif (q_handle >= vsi->num_lan_q_entries[tc])\n\t\treturn NULL;\n\tif (!vsi->lan_q_ctx[tc])\n\t\treturn NULL;\n\tq_ctx = vsi->lan_q_ctx[tc];\n\treturn &q_ctx[q_handle];\n}\n\n \nint\nice_ena_vsi_txq(struct ice_port_info *pi, u16 vsi_handle, u8 tc, u16 q_handle,\n\t\tu8 num_qgrps, struct ice_aqc_add_tx_qgrp *buf, u16 buf_size,\n\t\tstruct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_txsched_elem_data node = { 0 };\n\tstruct ice_sched_node *parent;\n\tstruct ice_q_ctx *q_ctx;\n\tstruct ice_hw *hw;\n\tint status;\n\n\tif (!pi || pi->port_state != ICE_SCHED_PORT_STATE_READY)\n\t\treturn -EIO;\n\n\tif (num_qgrps > 1 || buf->num_txqs > 1)\n\t\treturn -ENOSPC;\n\n\thw = pi->hw;\n\n\tif (!ice_is_vsi_valid(hw, vsi_handle))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&pi->sched_lock);\n\n\tq_ctx = ice_get_lan_q_ctx(hw, vsi_handle, tc, q_handle);\n\tif (!q_ctx) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"Enaq: invalid queue handle %d\\n\",\n\t\t\t  q_handle);\n\t\tstatus = -EINVAL;\n\t\tgoto ena_txq_exit;\n\t}\n\n\t \n\tparent = ice_sched_get_free_qparent(pi, vsi_handle, tc,\n\t\t\t\t\t    ICE_SCHED_NODE_OWNER_LAN);\n\tif (!parent) {\n\t\tstatus = -EINVAL;\n\t\tgoto ena_txq_exit;\n\t}\n\n\tbuf->parent_teid = parent->info.node_teid;\n\tnode.parent_teid = parent->info.node_teid;\n\t \n\tbuf->txqs[0].info.valid_sections =\n\t\tICE_AQC_ELEM_VALID_GENERIC | ICE_AQC_ELEM_VALID_CIR |\n\t\tICE_AQC_ELEM_VALID_EIR;\n\tbuf->txqs[0].info.generic = 0;\n\tbuf->txqs[0].info.cir_bw.bw_profile_idx =\n\t\tcpu_to_le16(ICE_SCHED_DFLT_RL_PROF_ID);\n\tbuf->txqs[0].info.cir_bw.bw_alloc =\n\t\tcpu_to_le16(ICE_SCHED_DFLT_BW_WT);\n\tbuf->txqs[0].info.eir_bw.bw_profile_idx =\n\t\tcpu_to_le16(ICE_SCHED_DFLT_RL_PROF_ID);\n\tbuf->txqs[0].info.eir_bw.bw_alloc =\n\t\tcpu_to_le16(ICE_SCHED_DFLT_BW_WT);\n\n\t \n\tstatus = ice_aq_add_lan_txq(hw, num_qgrps, buf, buf_size, cd);\n\tif (status) {\n\t\tice_debug(hw, ICE_DBG_SCHED, \"enable queue %d failed %d\\n\",\n\t\t\t  le16_to_cpu(buf->txqs[0].txq_id),\n\t\t\t  hw->adminq.sq_last_status);\n\t\tgoto ena_txq_exit;\n\t}\n\n\tnode.node_teid = buf->txqs[0].q_teid;\n\tnode.data.elem_type = ICE_AQC_ELEM_TYPE_LEAF;\n\tq_ctx->q_handle = q_handle;\n\tq_ctx->q_teid = le32_to_cpu(node.node_teid);\n\n\t \n\tstatus = ice_sched_add_node(pi, hw->num_tx_sched_layers - 1, &node, NULL);\n\tif (!status)\n\t\tstatus = ice_sched_replay_q_bw(pi, q_ctx);\n\nena_txq_exit:\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nint\nice_dis_vsi_txq(struct ice_port_info *pi, u16 vsi_handle, u8 tc, u8 num_queues,\n\t\tu16 *q_handles, u16 *q_ids, u32 *q_teids,\n\t\tenum ice_disq_rst_src rst_src, u16 vmvf_num,\n\t\tstruct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_dis_txq_item *qg_list;\n\tstruct ice_q_ctx *q_ctx;\n\tint status = -ENOENT;\n\tstruct ice_hw *hw;\n\tu16 i, buf_size;\n\n\tif (!pi || pi->port_state != ICE_SCHED_PORT_STATE_READY)\n\t\treturn -EIO;\n\n\thw = pi->hw;\n\n\tif (!num_queues) {\n\t\t \n\t\tif (rst_src)\n\t\t\treturn ice_aq_dis_lan_txq(hw, 0, NULL, 0, rst_src,\n\t\t\t\t\t\t  vmvf_num, NULL);\n\t\treturn -EIO;\n\t}\n\n\tbuf_size = struct_size(qg_list, q_id, 1);\n\tqg_list = kzalloc(buf_size, GFP_KERNEL);\n\tif (!qg_list)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&pi->sched_lock);\n\n\tfor (i = 0; i < num_queues; i++) {\n\t\tstruct ice_sched_node *node;\n\n\t\tnode = ice_sched_find_node_by_teid(pi->root, q_teids[i]);\n\t\tif (!node)\n\t\t\tcontinue;\n\t\tq_ctx = ice_get_lan_q_ctx(hw, vsi_handle, tc, q_handles[i]);\n\t\tif (!q_ctx) {\n\t\t\tice_debug(hw, ICE_DBG_SCHED, \"invalid queue handle%d\\n\",\n\t\t\t\t  q_handles[i]);\n\t\t\tcontinue;\n\t\t}\n\t\tif (q_ctx->q_handle != q_handles[i]) {\n\t\t\tice_debug(hw, ICE_DBG_SCHED, \"Err:handles %d %d\\n\",\n\t\t\t\t  q_ctx->q_handle, q_handles[i]);\n\t\t\tcontinue;\n\t\t}\n\t\tqg_list->parent_teid = node->info.parent_teid;\n\t\tqg_list->num_qs = 1;\n\t\tqg_list->q_id[0] = cpu_to_le16(q_ids[i]);\n\t\tstatus = ice_aq_dis_lan_txq(hw, 1, qg_list, buf_size, rst_src,\n\t\t\t\t\t    vmvf_num, cd);\n\n\t\tif (status)\n\t\t\tbreak;\n\t\tice_free_sched_node(pi, node);\n\t\tq_ctx->q_handle = ICE_INVAL_Q_HANDLE;\n\t\tq_ctx->q_teid = ICE_INVAL_TEID;\n\t}\n\tmutex_unlock(&pi->sched_lock);\n\tkfree(qg_list);\n\treturn status;\n}\n\n \nstatic int\nice_cfg_vsi_qs(struct ice_port_info *pi, u16 vsi_handle, u8 tc_bitmap,\n\t       u16 *maxqs, u8 owner)\n{\n\tint status = 0;\n\tu8 i;\n\n\tif (!pi || pi->port_state != ICE_SCHED_PORT_STATE_READY)\n\t\treturn -EIO;\n\n\tif (!ice_is_vsi_valid(pi->hw, vsi_handle))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&pi->sched_lock);\n\n\tice_for_each_traffic_class(i) {\n\t\t \n\t\tif (!ice_sched_get_tc_node(pi, i))\n\t\t\tcontinue;\n\n\t\tstatus = ice_sched_cfg_vsi(pi, vsi_handle, i, maxqs[i], owner,\n\t\t\t\t\t   ice_is_tc_ena(tc_bitmap, i));\n\t\tif (status)\n\t\t\tbreak;\n\t}\n\n\tmutex_unlock(&pi->sched_lock);\n\treturn status;\n}\n\n \nint\nice_cfg_vsi_lan(struct ice_port_info *pi, u16 vsi_handle, u8 tc_bitmap,\n\t\tu16 *max_lanqs)\n{\n\treturn ice_cfg_vsi_qs(pi, vsi_handle, tc_bitmap, max_lanqs,\n\t\t\t      ICE_SCHED_NODE_OWNER_LAN);\n}\n\n \nint\nice_cfg_vsi_rdma(struct ice_port_info *pi, u16 vsi_handle, u16 tc_bitmap,\n\t\t u16 *max_rdmaqs)\n{\n\treturn ice_cfg_vsi_qs(pi, vsi_handle, tc_bitmap, max_rdmaqs,\n\t\t\t      ICE_SCHED_NODE_OWNER_RDMA);\n}\n\n \nint\nice_ena_vsi_rdma_qset(struct ice_port_info *pi, u16 vsi_handle, u8 tc,\n\t\t      u16 *rdma_qset, u16 num_qsets, u32 *qset_teid)\n{\n\tstruct ice_aqc_txsched_elem_data node = { 0 };\n\tstruct ice_aqc_add_rdma_qset_data *buf;\n\tstruct ice_sched_node *parent;\n\tstruct ice_hw *hw;\n\tu16 i, buf_size;\n\tint ret;\n\n\tif (!pi || pi->port_state != ICE_SCHED_PORT_STATE_READY)\n\t\treturn -EIO;\n\thw = pi->hw;\n\n\tif (!ice_is_vsi_valid(hw, vsi_handle))\n\t\treturn -EINVAL;\n\n\tbuf_size = struct_size(buf, rdma_qsets, num_qsets);\n\tbuf = kzalloc(buf_size, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\tmutex_lock(&pi->sched_lock);\n\n\tparent = ice_sched_get_free_qparent(pi, vsi_handle, tc,\n\t\t\t\t\t    ICE_SCHED_NODE_OWNER_RDMA);\n\tif (!parent) {\n\t\tret = -EINVAL;\n\t\tgoto rdma_error_exit;\n\t}\n\tbuf->parent_teid = parent->info.node_teid;\n\tnode.parent_teid = parent->info.node_teid;\n\n\tbuf->num_qsets = cpu_to_le16(num_qsets);\n\tfor (i = 0; i < num_qsets; i++) {\n\t\tbuf->rdma_qsets[i].tx_qset_id = cpu_to_le16(rdma_qset[i]);\n\t\tbuf->rdma_qsets[i].info.valid_sections =\n\t\t\tICE_AQC_ELEM_VALID_GENERIC | ICE_AQC_ELEM_VALID_CIR |\n\t\t\tICE_AQC_ELEM_VALID_EIR;\n\t\tbuf->rdma_qsets[i].info.generic = 0;\n\t\tbuf->rdma_qsets[i].info.cir_bw.bw_profile_idx =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_RL_PROF_ID);\n\t\tbuf->rdma_qsets[i].info.cir_bw.bw_alloc =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_BW_WT);\n\t\tbuf->rdma_qsets[i].info.eir_bw.bw_profile_idx =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_RL_PROF_ID);\n\t\tbuf->rdma_qsets[i].info.eir_bw.bw_alloc =\n\t\t\tcpu_to_le16(ICE_SCHED_DFLT_BW_WT);\n\t}\n\tret = ice_aq_add_rdma_qsets(hw, 1, buf, buf_size, NULL);\n\tif (ret) {\n\t\tice_debug(hw, ICE_DBG_RDMA, \"add RDMA qset failed\\n\");\n\t\tgoto rdma_error_exit;\n\t}\n\tnode.data.elem_type = ICE_AQC_ELEM_TYPE_LEAF;\n\tfor (i = 0; i < num_qsets; i++) {\n\t\tnode.node_teid = buf->rdma_qsets[i].qset_teid;\n\t\tret = ice_sched_add_node(pi, hw->num_tx_sched_layers - 1,\n\t\t\t\t\t &node, NULL);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tqset_teid[i] = le32_to_cpu(node.node_teid);\n\t}\nrdma_error_exit:\n\tmutex_unlock(&pi->sched_lock);\n\tkfree(buf);\n\treturn ret;\n}\n\n \nint\nice_dis_vsi_rdma_qset(struct ice_port_info *pi, u16 count, u32 *qset_teid,\n\t\t      u16 *q_id)\n{\n\tstruct ice_aqc_dis_txq_item *qg_list;\n\tstruct ice_hw *hw;\n\tint status = 0;\n\tu16 qg_size;\n\tint i;\n\n\tif (!pi || pi->port_state != ICE_SCHED_PORT_STATE_READY)\n\t\treturn -EIO;\n\n\thw = pi->hw;\n\n\tqg_size = struct_size(qg_list, q_id, 1);\n\tqg_list = kzalloc(qg_size, GFP_KERNEL);\n\tif (!qg_list)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&pi->sched_lock);\n\n\tfor (i = 0; i < count; i++) {\n\t\tstruct ice_sched_node *node;\n\n\t\tnode = ice_sched_find_node_by_teid(pi->root, qset_teid[i]);\n\t\tif (!node)\n\t\t\tcontinue;\n\n\t\tqg_list->parent_teid = node->info.parent_teid;\n\t\tqg_list->num_qs = 1;\n\t\tqg_list->q_id[0] =\n\t\t\tcpu_to_le16(q_id[i] |\n\t\t\t\t    ICE_AQC_Q_DIS_BUF_ELEM_TYPE_RDMA_QSET);\n\n\t\tstatus = ice_aq_dis_lan_txq(hw, 1, qg_list, qg_size,\n\t\t\t\t\t    ICE_NO_RESET, 0, NULL);\n\t\tif (status)\n\t\t\tbreak;\n\n\t\tice_free_sched_node(pi, node);\n\t}\n\n\tmutex_unlock(&pi->sched_lock);\n\tkfree(qg_list);\n\treturn status;\n}\n\n \nstatic int ice_replay_pre_init(struct ice_hw *hw)\n{\n\tstruct ice_switch_info *sw = hw->switch_info;\n\tu8 i;\n\n\t \n\tice_rm_all_sw_replay_rule_info(hw);\n\t \n\tfor (i = 0; i < ICE_MAX_NUM_RECIPES; i++)\n\t\tlist_replace_init(&sw->recp_list[i].filt_rules,\n\t\t\t\t  &sw->recp_list[i].filt_replay_rules);\n\tice_sched_replay_agg_vsi_preinit(hw);\n\n\treturn 0;\n}\n\n \nint ice_replay_vsi(struct ice_hw *hw, u16 vsi_handle)\n{\n\tint status;\n\n\tif (!ice_is_vsi_valid(hw, vsi_handle))\n\t\treturn -EINVAL;\n\n\t \n\tif (vsi_handle == ICE_MAIN_VSI_HANDLE) {\n\t\tstatus = ice_replay_pre_init(hw);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\t \n\tstatus = ice_replay_rss_cfg(hw, vsi_handle);\n\tif (status)\n\t\treturn status;\n\t \n\tstatus = ice_replay_vsi_all_fltr(hw, vsi_handle);\n\tif (!status)\n\t\tstatus = ice_replay_vsi_agg(hw, vsi_handle);\n\treturn status;\n}\n\n \nvoid ice_replay_post(struct ice_hw *hw)\n{\n\t \n\tice_rm_all_sw_replay_rule_info(hw);\n\tice_sched_replay_agg(hw);\n}\n\n \nvoid\nice_stat_update40(struct ice_hw *hw, u32 reg, bool prev_stat_loaded,\n\t\t  u64 *prev_stat, u64 *cur_stat)\n{\n\tu64 new_data = rd64(hw, reg) & (BIT_ULL(40) - 1);\n\n\t \n\tif (!prev_stat_loaded) {\n\t\t*prev_stat = new_data;\n\t\treturn;\n\t}\n\n\t \n\tif (new_data >= *prev_stat)\n\t\t*cur_stat += new_data - *prev_stat;\n\telse\n\t\t \n\t\t*cur_stat += (new_data + BIT_ULL(40)) - *prev_stat;\n\n\t \n\t*prev_stat = new_data;\n}\n\n \nvoid\nice_stat_update32(struct ice_hw *hw, u32 reg, bool prev_stat_loaded,\n\t\t  u64 *prev_stat, u64 *cur_stat)\n{\n\tu32 new_data;\n\n\tnew_data = rd32(hw, reg);\n\n\t \n\tif (!prev_stat_loaded) {\n\t\t*prev_stat = new_data;\n\t\treturn;\n\t}\n\n\t \n\tif (new_data >= *prev_stat)\n\t\t*cur_stat += new_data - *prev_stat;\n\telse\n\t\t \n\t\t*cur_stat += (new_data + BIT_ULL(32)) - *prev_stat;\n\n\t \n\t*prev_stat = new_data;\n}\n\n \nint\nice_sched_query_elem(struct ice_hw *hw, u32 node_teid,\n\t\t     struct ice_aqc_txsched_elem_data *buf)\n{\n\tu16 buf_size, num_elem_ret = 0;\n\tint status;\n\n\tbuf_size = sizeof(*buf);\n\tmemset(buf, 0, buf_size);\n\tbuf->node_teid = cpu_to_le32(node_teid);\n\tstatus = ice_aq_query_sched_elems(hw, 1, buf, buf_size, &num_elem_ret,\n\t\t\t\t\t  NULL);\n\tif (status || num_elem_ret != 1)\n\t\tice_debug(hw, ICE_DBG_SCHED, \"query element failed\\n\");\n\treturn status;\n}\n\n \nint\nice_aq_read_i2c(struct ice_hw *hw, struct ice_aqc_link_topo_addr topo_addr,\n\t\tu16 bus_addr, __le16 addr, u8 params, u8 *data,\n\t\tstruct ice_sq_cd *cd)\n{\n\tstruct ice_aq_desc desc = { 0 };\n\tstruct ice_aqc_i2c *cmd;\n\tu8 data_size;\n\tint status;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_read_i2c);\n\tcmd = &desc.params.read_write_i2c;\n\n\tif (!data)\n\t\treturn -EINVAL;\n\n\tdata_size = FIELD_GET(ICE_AQC_I2C_DATA_SIZE_M, params);\n\n\tcmd->i2c_bus_addr = cpu_to_le16(bus_addr);\n\tcmd->topo_addr = topo_addr;\n\tcmd->i2c_params = params;\n\tcmd->i2c_addr = addr;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n\tif (!status) {\n\t\tstruct ice_aqc_read_i2c_resp *resp;\n\t\tu8 i;\n\n\t\tresp = &desc.params.read_i2c_resp;\n\t\tfor (i = 0; i < data_size; i++) {\n\t\t\t*data = resp->i2c_data[i];\n\t\t\tdata++;\n\t\t}\n\t}\n\n\treturn status;\n}\n\n \nint\nice_aq_write_i2c(struct ice_hw *hw, struct ice_aqc_link_topo_addr topo_addr,\n\t\t u16 bus_addr, __le16 addr, u8 params, const u8 *data,\n\t\t struct ice_sq_cd *cd)\n{\n\tstruct ice_aq_desc desc = { 0 };\n\tstruct ice_aqc_i2c *cmd;\n\tu8 data_size;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_write_i2c);\n\tcmd = &desc.params.read_write_i2c;\n\n\tdata_size = FIELD_GET(ICE_AQC_I2C_DATA_SIZE_M, params);\n\n\t \n\tif (data_size > 4)\n\t\treturn -EINVAL;\n\n\tcmd->i2c_bus_addr = cpu_to_le16(bus_addr);\n\tcmd->topo_addr = topo_addr;\n\tcmd->i2c_params = params;\n\tcmd->i2c_addr = addr;\n\n\tmemcpy(cmd->i2c_data, data, data_size);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_aq_set_driver_param(struct ice_hw *hw, enum ice_aqc_driver_params idx,\n\t\t\tu32 value, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_driver_shared_params *cmd;\n\tstruct ice_aq_desc desc;\n\n\tif (idx >= ICE_AQC_DRIVER_PARAM_MAX)\n\t\treturn -EIO;\n\n\tcmd = &desc.params.drv_shared_params;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_driver_shared_params);\n\n\tcmd->set_or_get_op = ICE_AQC_DRIVER_PARAM_SET;\n\tcmd->param_indx = idx;\n\tcmd->param_val = cpu_to_le32(value);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_aq_get_driver_param(struct ice_hw *hw, enum ice_aqc_driver_params idx,\n\t\t\tu32 *value, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_driver_shared_params *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tif (idx >= ICE_AQC_DRIVER_PARAM_MAX)\n\t\treturn -EIO;\n\n\tcmd = &desc.params.drv_shared_params;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_driver_shared_params);\n\n\tcmd->set_or_get_op = ICE_AQC_DRIVER_PARAM_GET;\n\tcmd->param_indx = idx;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n\tif (status)\n\t\treturn status;\n\n\t*value = le32_to_cpu(cmd->param_val);\n\n\treturn 0;\n}\n\n \nint\nice_aq_set_gpio(struct ice_hw *hw, u16 gpio_ctrl_handle, u8 pin_idx, bool value,\n\t\tstruct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_gpio *cmd;\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_gpio);\n\tcmd = &desc.params.read_write_gpio;\n\tcmd->gpio_ctrl_handle = cpu_to_le16(gpio_ctrl_handle);\n\tcmd->gpio_num = pin_idx;\n\tcmd->gpio_val = value ? 1 : 0;\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n}\n\n \nint\nice_aq_get_gpio(struct ice_hw *hw, u16 gpio_ctrl_handle, u8 pin_idx,\n\t\tbool *value, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_gpio *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_gpio);\n\tcmd = &desc.params.read_write_gpio;\n\tcmd->gpio_ctrl_handle = cpu_to_le16(gpio_ctrl_handle);\n\tcmd->gpio_num = pin_idx;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, NULL, 0, cd);\n\tif (status)\n\t\treturn status;\n\n\t*value = !!cmd->gpio_val;\n\treturn 0;\n}\n\n \nstatic bool ice_is_fw_api_min_ver(struct ice_hw *hw, u8 maj, u8 min, u8 patch)\n{\n\tif (hw->api_maj_ver == maj) {\n\t\tif (hw->api_min_ver > min)\n\t\t\treturn true;\n\t\tif (hw->api_min_ver == min && hw->api_patch >= patch)\n\t\t\treturn true;\n\t} else if (hw->api_maj_ver > maj) {\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nbool ice_fw_supports_link_override(struct ice_hw *hw)\n{\n\treturn ice_is_fw_api_min_ver(hw, ICE_FW_API_LINK_OVERRIDE_MAJ,\n\t\t\t\t     ICE_FW_API_LINK_OVERRIDE_MIN,\n\t\t\t\t     ICE_FW_API_LINK_OVERRIDE_PATCH);\n}\n\n \nint\nice_get_link_default_override(struct ice_link_default_override_tlv *ldo,\n\t\t\t      struct ice_port_info *pi)\n{\n\tu16 i, tlv, tlv_len, tlv_start, buf, offset;\n\tstruct ice_hw *hw = pi->hw;\n\tint status;\n\n\tstatus = ice_get_pfa_module_tlv(hw, &tlv, &tlv_len,\n\t\t\t\t\tICE_SR_LINK_DEFAULT_OVERRIDE_PTR);\n\tif (status) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"Failed to read link override TLV.\\n\");\n\t\treturn status;\n\t}\n\n\t \n\ttlv_start = tlv + pi->lport * ICE_SR_PFA_LINK_OVERRIDE_WORDS +\n\t\tICE_SR_PFA_LINK_OVERRIDE_OFFSET;\n\n\t \n\tstatus = ice_read_sr_word(hw, tlv_start, &buf);\n\tif (status) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"Failed to read override link options.\\n\");\n\t\treturn status;\n\t}\n\tldo->options = buf & ICE_LINK_OVERRIDE_OPT_M;\n\tldo->phy_config = (buf & ICE_LINK_OVERRIDE_PHY_CFG_M) >>\n\t\tICE_LINK_OVERRIDE_PHY_CFG_S;\n\n\t \n\toffset = tlv_start + ICE_SR_PFA_LINK_OVERRIDE_FEC_OFFSET;\n\tstatus = ice_read_sr_word(hw, offset, &buf);\n\tif (status) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"Failed to read override phy config.\\n\");\n\t\treturn status;\n\t}\n\tldo->fec_options = buf & ICE_LINK_OVERRIDE_FEC_OPT_M;\n\n\t \n\toffset = tlv_start + ICE_SR_PFA_LINK_OVERRIDE_PHY_OFFSET;\n\tfor (i = 0; i < ICE_SR_PFA_LINK_OVERRIDE_PHY_WORDS; i++) {\n\t\tstatus = ice_read_sr_word(hw, (offset + i), &buf);\n\t\tif (status) {\n\t\t\tice_debug(hw, ICE_DBG_INIT, \"Failed to read override link options.\\n\");\n\t\t\treturn status;\n\t\t}\n\t\t \n\t\tldo->phy_type_low |= ((u64)buf << (i * 16));\n\t}\n\n\t \n\toffset = tlv_start + ICE_SR_PFA_LINK_OVERRIDE_PHY_OFFSET +\n\t\tICE_SR_PFA_LINK_OVERRIDE_PHY_WORDS;\n\tfor (i = 0; i < ICE_SR_PFA_LINK_OVERRIDE_PHY_WORDS; i++) {\n\t\tstatus = ice_read_sr_word(hw, (offset + i), &buf);\n\t\tif (status) {\n\t\t\tice_debug(hw, ICE_DBG_INIT, \"Failed to read override link options.\\n\");\n\t\t\treturn status;\n\t\t}\n\t\t \n\t\tldo->phy_type_high |= ((u64)buf << (i * 16));\n\t}\n\n\treturn status;\n}\n\n \nbool ice_is_phy_caps_an_enabled(struct ice_aqc_get_phy_caps_data *caps)\n{\n\tif (caps->caps & ICE_AQC_PHY_AN_MODE ||\n\t    caps->low_power_ctrl_an & (ICE_AQC_PHY_AN_EN_CLAUSE28 |\n\t\t\t\t       ICE_AQC_PHY_AN_EN_CLAUSE73 |\n\t\t\t\t       ICE_AQC_PHY_AN_EN_CLAUSE37))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nint\nice_aq_set_lldp_mib(struct ice_hw *hw, u8 mib_type, void *buf, u16 buf_size,\n\t\t    struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_lldp_set_local_mib *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.lldp_set_mib;\n\n\tif (buf_size == 0 || !buf)\n\t\treturn -EINVAL;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_lldp_set_local_mib);\n\n\tdesc.flags |= cpu_to_le16((u16)ICE_AQ_FLAG_RD);\n\tdesc.datalen = cpu_to_le16(buf_size);\n\n\tcmd->type = mib_type;\n\tcmd->length = cpu_to_le16(buf_size);\n\n\treturn ice_aq_send_cmd(hw, &desc, buf, buf_size, cd);\n}\n\n \nbool ice_fw_supports_lldp_fltr_ctrl(struct ice_hw *hw)\n{\n\tif (hw->mac_type != ICE_MAC_E810)\n\t\treturn false;\n\n\treturn ice_is_fw_api_min_ver(hw, ICE_FW_API_LLDP_FLTR_MAJ,\n\t\t\t\t     ICE_FW_API_LLDP_FLTR_MIN,\n\t\t\t\t     ICE_FW_API_LLDP_FLTR_PATCH);\n}\n\n \nint\nice_lldp_fltr_add_remove(struct ice_hw *hw, u16 vsi_num, bool add)\n{\n\tstruct ice_aqc_lldp_filter_ctrl *cmd;\n\tstruct ice_aq_desc desc;\n\n\tcmd = &desc.params.lldp_filter_ctrl;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_lldp_filter_ctrl);\n\n\tif (add)\n\t\tcmd->cmd_flags = ICE_AQC_LLDP_FILTER_ACTION_ADD;\n\telse\n\t\tcmd->cmd_flags = ICE_AQC_LLDP_FILTER_ACTION_DELETE;\n\n\tcmd->vsi_num = cpu_to_le16(vsi_num);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, NULL);\n}\n\n \nint ice_lldp_execute_pending_mib(struct ice_hw *hw)\n{\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_lldp_execute_pending_mib);\n\n\treturn ice_aq_send_cmd(hw, &desc, NULL, 0, NULL);\n}\n\n \nbool ice_fw_supports_report_dflt_cfg(struct ice_hw *hw)\n{\n\treturn ice_is_fw_api_min_ver(hw, ICE_FW_API_REPORT_DFLT_CFG_MAJ,\n\t\t\t\t     ICE_FW_API_REPORT_DFLT_CFG_MIN,\n\t\t\t\t     ICE_FW_API_REPORT_DFLT_CFG_PATCH);\n}\n\n \nstatic const u32 ice_aq_to_link_speed[] = {\n\tSPEED_10,\t \n\tSPEED_100,\n\tSPEED_1000,\n\tSPEED_2500,\n\tSPEED_5000,\n\tSPEED_10000,\n\tSPEED_20000,\n\tSPEED_25000,\n\tSPEED_40000,\n\tSPEED_50000,\n\tSPEED_100000,\t \n};\n\n \nu32 ice_get_link_speed(u16 index)\n{\n\tif (index >= ARRAY_SIZE(ice_aq_to_link_speed))\n\t\treturn 0;\n\n\treturn ice_aq_to_link_speed[index];\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}