{
  "module_name": "ice_virtchnl_fdir.c",
  "hash_id": "44c38092190d14007a42cc8c47d2256fd6f6f619a7409d363c1dde191fc2ef9e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_virtchnl_fdir.c",
  "human_readable_source": "\n \n\n#include \"ice.h\"\n#include \"ice_base.h\"\n#include \"ice_lib.h\"\n#include \"ice_flow.h\"\n#include \"ice_vf_lib_private.h\"\n\n#define to_fltr_conf_from_desc(p) \\\n\tcontainer_of(p, struct virtchnl_fdir_fltr_conf, input)\n\n#define ICE_FLOW_PROF_TYPE_S\t0\n#define ICE_FLOW_PROF_TYPE_M\t(0xFFFFFFFFULL << ICE_FLOW_PROF_TYPE_S)\n#define ICE_FLOW_PROF_VSI_S\t32\n#define ICE_FLOW_PROF_VSI_M\t(0xFFFFFFFFULL << ICE_FLOW_PROF_VSI_S)\n\n \n#define ICE_FLOW_PROF_FD(vsi, flow, tun_offs) \\\n\t((u64)(((((flow) + (tun_offs)) & ICE_FLOW_PROF_TYPE_M)) | \\\n\t      (((u64)(vsi) << ICE_FLOW_PROF_VSI_S) & ICE_FLOW_PROF_VSI_M)))\n\n#define GTPU_TEID_OFFSET 4\n#define GTPU_EH_QFI_OFFSET 1\n#define GTPU_EH_QFI_MASK 0x3F\n#define PFCP_S_OFFSET 0\n#define PFCP_S_MASK 0x1\n#define PFCP_PORT_NR 8805\n\n#define FDIR_INSET_FLAG_ESP_S 0\n#define FDIR_INSET_FLAG_ESP_M BIT_ULL(FDIR_INSET_FLAG_ESP_S)\n#define FDIR_INSET_FLAG_ESP_UDP BIT_ULL(FDIR_INSET_FLAG_ESP_S)\n#define FDIR_INSET_FLAG_ESP_IPSEC (0ULL << FDIR_INSET_FLAG_ESP_S)\n\nenum ice_fdir_tunnel_type {\n\tICE_FDIR_TUNNEL_TYPE_NONE = 0,\n\tICE_FDIR_TUNNEL_TYPE_GTPU,\n\tICE_FDIR_TUNNEL_TYPE_GTPU_EH,\n};\n\nstruct virtchnl_fdir_fltr_conf {\n\tstruct ice_fdir_fltr input;\n\tenum ice_fdir_tunnel_type ttype;\n\tu64 inset_flag;\n\tu32 flow_id;\n};\n\nstruct virtchnl_fdir_inset_map {\n\tenum virtchnl_proto_hdr_field field;\n\tenum ice_flow_field fld;\n\tu64 flag;\n\tu64 mask;\n};\n\nstatic const struct virtchnl_fdir_inset_map fdir_inset_map[] = {\n\t{VIRTCHNL_PROTO_HDR_ETH_ETHERTYPE, ICE_FLOW_FIELD_IDX_ETH_TYPE, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV4_SRC, ICE_FLOW_FIELD_IDX_IPV4_SA, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV4_DST, ICE_FLOW_FIELD_IDX_IPV4_DA, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV4_DSCP, ICE_FLOW_FIELD_IDX_IPV4_DSCP, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV4_TTL, ICE_FLOW_FIELD_IDX_IPV4_TTL, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV4_PROT, ICE_FLOW_FIELD_IDX_IPV4_PROT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV6_SRC, ICE_FLOW_FIELD_IDX_IPV6_SA, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV6_DST, ICE_FLOW_FIELD_IDX_IPV6_DA, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV6_TC, ICE_FLOW_FIELD_IDX_IPV6_DSCP, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV6_HOP_LIMIT, ICE_FLOW_FIELD_IDX_IPV6_TTL, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_IPV6_PROT, ICE_FLOW_FIELD_IDX_IPV6_PROT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_UDP_SRC_PORT, ICE_FLOW_FIELD_IDX_UDP_SRC_PORT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_UDP_DST_PORT, ICE_FLOW_FIELD_IDX_UDP_DST_PORT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_TCP_SRC_PORT, ICE_FLOW_FIELD_IDX_TCP_SRC_PORT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_TCP_DST_PORT, ICE_FLOW_FIELD_IDX_TCP_DST_PORT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_SCTP_SRC_PORT, ICE_FLOW_FIELD_IDX_SCTP_SRC_PORT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_SCTP_DST_PORT, ICE_FLOW_FIELD_IDX_SCTP_DST_PORT, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_GTPU_IP_TEID, ICE_FLOW_FIELD_IDX_GTPU_IP_TEID, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_GTPU_EH_QFI, ICE_FLOW_FIELD_IDX_GTPU_EH_QFI, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_ESP_SPI, ICE_FLOW_FIELD_IDX_ESP_SPI,\n\t\tFDIR_INSET_FLAG_ESP_IPSEC, FDIR_INSET_FLAG_ESP_M},\n\t{VIRTCHNL_PROTO_HDR_ESP_SPI, ICE_FLOW_FIELD_IDX_NAT_T_ESP_SPI,\n\t\tFDIR_INSET_FLAG_ESP_UDP, FDIR_INSET_FLAG_ESP_M},\n\t{VIRTCHNL_PROTO_HDR_AH_SPI, ICE_FLOW_FIELD_IDX_AH_SPI, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_L2TPV3_SESS_ID, ICE_FLOW_FIELD_IDX_L2TPV3_SESS_ID, 0, 0},\n\t{VIRTCHNL_PROTO_HDR_PFCP_S_FIELD, ICE_FLOW_FIELD_IDX_UDP_DST_PORT, 0, 0},\n};\n\n \nstatic int\nice_vc_fdir_param_check(struct ice_vf *vf, u16 vsi_id)\n{\n\tstruct ice_pf *pf = vf->pf;\n\n\tif (!test_bit(ICE_FLAG_FD_ENA, pf->flags))\n\t\treturn -EINVAL;\n\n\tif (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states))\n\t\treturn -EINVAL;\n\n\tif (!(vf->driver_caps & VIRTCHNL_VF_OFFLOAD_FDIR_PF))\n\t\treturn -EINVAL;\n\n\tif (vsi_id != vf->lan_vsi_num)\n\t\treturn -EINVAL;\n\n\tif (!ice_vc_isvalid_vsi_id(vf, vsi_id))\n\t\treturn -EINVAL;\n\n\tif (!ice_get_vf_vsi(vf))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\n \nstatic int ice_vf_start_ctrl_vsi(struct ice_vf *vf)\n{\n\tstruct ice_pf *pf = vf->pf;\n\tstruct ice_vsi *ctrl_vsi;\n\tstruct device *dev;\n\tint err;\n\n\tdev = ice_pf_to_dev(pf);\n\tif (vf->ctrl_vsi_idx != ICE_NO_VSI)\n\t\treturn -EEXIST;\n\n\tctrl_vsi = ice_vf_ctrl_vsi_setup(vf);\n\tif (!ctrl_vsi) {\n\t\tdev_dbg(dev, \"Could not setup control VSI for VF %d\\n\",\n\t\t\tvf->vf_id);\n\t\treturn -ENOMEM;\n\t}\n\n\terr = ice_vsi_open_ctrl(ctrl_vsi);\n\tif (err) {\n\t\tdev_dbg(dev, \"Could not open control VSI for VF %d\\n\",\n\t\t\tvf->vf_id);\n\t\tgoto err_vsi_open;\n\t}\n\n\treturn 0;\n\nerr_vsi_open:\n\tice_vsi_release(ctrl_vsi);\n\tif (vf->ctrl_vsi_idx != ICE_NO_VSI) {\n\t\tpf->vsi[vf->ctrl_vsi_idx] = NULL;\n\t\tvf->ctrl_vsi_idx = ICE_NO_VSI;\n\t}\n\treturn err;\n}\n\n \nstatic int\nice_vc_fdir_alloc_prof(struct ice_vf *vf, enum ice_fltr_ptype flow)\n{\n\tstruct ice_vf_fdir *fdir = &vf->fdir;\n\n\tif (!fdir->fdir_prof) {\n\t\tfdir->fdir_prof = devm_kcalloc(ice_pf_to_dev(vf->pf),\n\t\t\t\t\t       ICE_FLTR_PTYPE_MAX,\n\t\t\t\t\t       sizeof(*fdir->fdir_prof),\n\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!fdir->fdir_prof)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tif (!fdir->fdir_prof[flow]) {\n\t\tfdir->fdir_prof[flow] = devm_kzalloc(ice_pf_to_dev(vf->pf),\n\t\t\t\t\t\t     sizeof(**fdir->fdir_prof),\n\t\t\t\t\t\t     GFP_KERNEL);\n\t\tif (!fdir->fdir_prof[flow])\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void\nice_vc_fdir_free_prof(struct ice_vf *vf, enum ice_fltr_ptype flow)\n{\n\tstruct ice_vf_fdir *fdir = &vf->fdir;\n\n\tif (!fdir->fdir_prof)\n\t\treturn;\n\n\tif (!fdir->fdir_prof[flow])\n\t\treturn;\n\n\tdevm_kfree(ice_pf_to_dev(vf->pf), fdir->fdir_prof[flow]);\n\tfdir->fdir_prof[flow] = NULL;\n}\n\n \nstatic void ice_vc_fdir_free_prof_all(struct ice_vf *vf)\n{\n\tstruct ice_vf_fdir *fdir = &vf->fdir;\n\tenum ice_fltr_ptype flow;\n\n\tif (!fdir->fdir_prof)\n\t\treturn;\n\n\tfor (flow = ICE_FLTR_PTYPE_NONF_NONE; flow < ICE_FLTR_PTYPE_MAX; flow++)\n\t\tice_vc_fdir_free_prof(vf, flow);\n\n\tdevm_kfree(ice_pf_to_dev(vf->pf), fdir->fdir_prof);\n\tfdir->fdir_prof = NULL;\n}\n\n \nstatic int\nice_vc_fdir_parse_flow_fld(struct virtchnl_proto_hdr *proto_hdr,\n\t\t\t   struct virtchnl_fdir_fltr_conf *conf,\n\t\t\t   enum ice_flow_field *fld, int *fld_cnt)\n{\n\tstruct virtchnl_proto_hdr hdr;\n\tu32 i;\n\n\tmemcpy(&hdr, proto_hdr, sizeof(hdr));\n\n\tfor (i = 0; (i < ARRAY_SIZE(fdir_inset_map)) &&\n\t     VIRTCHNL_GET_PROTO_HDR_FIELD(&hdr); i++)\n\t\tif (VIRTCHNL_TEST_PROTO_HDR(&hdr, fdir_inset_map[i].field)) {\n\t\t\tif (fdir_inset_map[i].mask &&\n\t\t\t    ((fdir_inset_map[i].mask & conf->inset_flag) !=\n\t\t\t     fdir_inset_map[i].flag))\n\t\t\t\tcontinue;\n\n\t\t\tfld[*fld_cnt] = fdir_inset_map[i].fld;\n\t\t\t*fld_cnt += 1;\n\t\t\tif (*fld_cnt >= ICE_FLOW_FIELD_IDX_MAX)\n\t\t\t\treturn -EINVAL;\n\t\t\tVIRTCHNL_DEL_PROTO_HDR_FIELD(&hdr,\n\t\t\t\t\t\t     fdir_inset_map[i].field);\n\t\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_vc_fdir_set_flow_fld(struct ice_vf *vf, struct virtchnl_fdir_add *fltr,\n\t\t\t struct virtchnl_fdir_fltr_conf *conf,\n\t\t\t struct ice_flow_seg_info *seg)\n{\n\tstruct virtchnl_fdir_rule *rule = &fltr->rule_cfg;\n\tenum ice_flow_field fld[ICE_FLOW_FIELD_IDX_MAX];\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tstruct virtchnl_proto_hdrs *proto;\n\tint fld_cnt = 0;\n\tint i;\n\n\tproto = &rule->proto_hdrs;\n\tfor (i = 0; i < proto->count; i++) {\n\t\tstruct virtchnl_proto_hdr *hdr = &proto->proto_hdr[i];\n\t\tint ret;\n\n\t\tret = ice_vc_fdir_parse_flow_fld(hdr, conf, fld, &fld_cnt);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (fld_cnt == 0) {\n\t\tdev_dbg(dev, \"Empty input set for VF %d\\n\", vf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < fld_cnt; i++)\n\t\tice_flow_set_fld(seg, fld[i],\n\t\t\t\t ICE_FLOW_FLD_OFF_INVAL,\n\t\t\t\t ICE_FLOW_FLD_OFF_INVAL,\n\t\t\t\t ICE_FLOW_FLD_OFF_INVAL, false);\n\n\treturn 0;\n}\n\n \nstatic int\nice_vc_fdir_set_flow_hdr(struct ice_vf *vf,\n\t\t\t struct virtchnl_fdir_fltr_conf *conf,\n\t\t\t struct ice_flow_seg_info *seg)\n{\n\tenum ice_fltr_ptype flow = conf->input.flow_type;\n\tenum ice_fdir_tunnel_type ttype = conf->ttype;\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\n\tswitch (flow) {\n\tcase ICE_FLTR_PTYPE_NON_IP_L2:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_ETH_NON_IP);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_L2TPV3:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_L2TPV3 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_ESP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_ESP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_AH:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_AH |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_NAT_T_ESP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_NAT_T_ESP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_PFCP_NODE:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_PFCP_NODE |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_PFCP_SESSION:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_PFCP_SESSION |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_OTHER:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_TCP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_TCP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_UDP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_UDP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_GTPU_IPV4_UDP:\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_GTPU_IPV4_TCP:\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_GTPU_IPV4_ICMP:\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_GTPU_IPV4_OTHER:\n\t\tif (ttype == ICE_FDIR_TUNNEL_TYPE_GTPU) {\n\t\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_GTPU_IP |\n\t\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\t} else if (ttype == ICE_FDIR_TUNNEL_TYPE_GTPU_EH) {\n\t\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_GTPU_EH |\n\t\t\t\t\t  ICE_FLOW_SEG_HDR_GTPU_IP |\n\t\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\t} else {\n\t\t\tdev_dbg(dev, \"Invalid tunnel type 0x%x for VF %d\\n\",\n\t\t\t\tflow, vf->vf_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV4_SCTP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_SCTP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV4 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_L2TPV3:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_L2TPV3 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_ESP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_ESP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_AH:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_AH |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_NAT_T_ESP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_NAT_T_ESP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_PFCP_NODE:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_PFCP_NODE |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_PFCP_SESSION:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_PFCP_SESSION |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_OTHER:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_TCP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_TCP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_UDP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_UDP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tcase ICE_FLTR_PTYPE_NONF_IPV6_SCTP:\n\t\tICE_FLOW_SET_HDRS(seg, ICE_FLOW_SEG_HDR_SCTP |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV6 |\n\t\t\t\t  ICE_FLOW_SEG_HDR_IPV_OTHER);\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(dev, \"Invalid flow type 0x%x for VF %d failed\\n\",\n\t\t\tflow, vf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void\nice_vc_fdir_rem_prof(struct ice_vf *vf, enum ice_fltr_ptype flow, int tun)\n{\n\tstruct ice_vf_fdir *fdir = &vf->fdir;\n\tstruct ice_fd_hw_prof *vf_prof;\n\tstruct ice_pf *pf = vf->pf;\n\tstruct ice_vsi *vf_vsi;\n\tstruct device *dev;\n\tstruct ice_hw *hw;\n\tu64 prof_id;\n\tint i;\n\n\tdev = ice_pf_to_dev(pf);\n\thw = &pf->hw;\n\tif (!fdir->fdir_prof || !fdir->fdir_prof[flow])\n\t\treturn;\n\n\tvf_prof = fdir->fdir_prof[flow];\n\n\tvf_vsi = ice_get_vf_vsi(vf);\n\tif (!vf_vsi) {\n\t\tdev_dbg(dev, \"NULL vf %d vsi pointer\\n\", vf->vf_id);\n\t\treturn;\n\t}\n\n\tif (!fdir->prof_entry_cnt[flow][tun])\n\t\treturn;\n\n\tprof_id = ICE_FLOW_PROF_FD(vf_vsi->vsi_num,\n\t\t\t\t   flow, tun ? ICE_FLTR_PTYPE_MAX : 0);\n\n\tfor (i = 0; i < fdir->prof_entry_cnt[flow][tun]; i++)\n\t\tif (vf_prof->entry_h[i][tun]) {\n\t\t\tu16 vsi_num = ice_get_hw_vsi_num(hw, vf_prof->vsi_h[i]);\n\n\t\t\tice_rem_prof_id_flow(hw, ICE_BLK_FD, vsi_num, prof_id);\n\t\t\tice_flow_rem_entry(hw, ICE_BLK_FD,\n\t\t\t\t\t   vf_prof->entry_h[i][tun]);\n\t\t\tvf_prof->entry_h[i][tun] = 0;\n\t\t}\n\n\tice_flow_rem_prof(hw, ICE_BLK_FD, prof_id);\n\tdevm_kfree(dev, vf_prof->fdir_seg[tun]);\n\tvf_prof->fdir_seg[tun] = NULL;\n\n\tfor (i = 0; i < vf_prof->cnt; i++)\n\t\tvf_prof->vsi_h[i] = 0;\n\n\tfdir->prof_entry_cnt[flow][tun] = 0;\n}\n\n \nstatic void ice_vc_fdir_rem_prof_all(struct ice_vf *vf)\n{\n\tenum ice_fltr_ptype flow;\n\n\tfor (flow = ICE_FLTR_PTYPE_NONF_NONE;\n\t     flow < ICE_FLTR_PTYPE_MAX; flow++) {\n\t\tice_vc_fdir_rem_prof(vf, flow, 0);\n\t\tice_vc_fdir_rem_prof(vf, flow, 1);\n\t}\n}\n\n \nstatic void ice_vc_fdir_reset_cnt_all(struct ice_vf_fdir *fdir)\n{\n\tenum ice_fltr_ptype flow;\n\n\tfor (flow = ICE_FLTR_PTYPE_NONF_NONE;\n\t     flow < ICE_FLTR_PTYPE_MAX; flow++) {\n\t\tfdir->fdir_fltr_cnt[flow][0] = 0;\n\t\tfdir->fdir_fltr_cnt[flow][1] = 0;\n\t}\n}\n\n \nstatic bool\nice_vc_fdir_has_prof_conflict(struct ice_vf *vf,\n\t\t\t      struct virtchnl_fdir_fltr_conf *conf)\n{\n\tstruct ice_fdir_fltr *desc;\n\n\tlist_for_each_entry(desc, &vf->fdir.fdir_rule_list, fltr_node) {\n\t\tstruct virtchnl_fdir_fltr_conf *existing_conf;\n\t\tenum ice_fltr_ptype flow_type_a, flow_type_b;\n\t\tstruct ice_fdir_fltr *a, *b;\n\n\t\texisting_conf = to_fltr_conf_from_desc(desc);\n\t\ta = &existing_conf->input;\n\t\tb = &conf->input;\n\t\tflow_type_a = a->flow_type;\n\t\tflow_type_b = b->flow_type;\n\n\t\t \n\t\tif (existing_conf->ttype != conf->ttype ||\n\t\t    flow_type_a == flow_type_b)\n\t\t\tcontinue;\n\n\t\tswitch (flow_type_a) {\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV4_UDP:\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV4_TCP:\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV4_SCTP:\n\t\t\tif (flow_type_b == ICE_FLTR_PTYPE_NONF_IPV4_OTHER)\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV4_OTHER:\n\t\t\tif (flow_type_b == ICE_FLTR_PTYPE_NONF_IPV4_UDP ||\n\t\t\t    flow_type_b == ICE_FLTR_PTYPE_NONF_IPV4_TCP ||\n\t\t\t    flow_type_b == ICE_FLTR_PTYPE_NONF_IPV4_SCTP)\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV6_UDP:\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV6_TCP:\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV6_SCTP:\n\t\t\tif (flow_type_b == ICE_FLTR_PTYPE_NONF_IPV6_OTHER)\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tcase ICE_FLTR_PTYPE_NONF_IPV6_OTHER:\n\t\t\tif (flow_type_b == ICE_FLTR_PTYPE_NONF_IPV6_UDP ||\n\t\t\t    flow_type_b == ICE_FLTR_PTYPE_NONF_IPV6_TCP ||\n\t\t\t    flow_type_b == ICE_FLTR_PTYPE_NONF_IPV6_SCTP)\n\t\t\t\treturn true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn false;\n}\n\n \nstatic int\nice_vc_fdir_write_flow_prof(struct ice_vf *vf, enum ice_fltr_ptype flow,\n\t\t\t    struct ice_flow_seg_info *seg, int tun)\n{\n\tstruct ice_vf_fdir *fdir = &vf->fdir;\n\tstruct ice_vsi *vf_vsi, *ctrl_vsi;\n\tstruct ice_flow_seg_info *old_seg;\n\tstruct ice_flow_prof *prof = NULL;\n\tstruct ice_fd_hw_prof *vf_prof;\n\tstruct device *dev;\n\tstruct ice_pf *pf;\n\tstruct ice_hw *hw;\n\tu64 entry1_h = 0;\n\tu64 entry2_h = 0;\n\tu64 prof_id;\n\tint ret;\n\n\tpf = vf->pf;\n\tdev = ice_pf_to_dev(pf);\n\thw = &pf->hw;\n\tvf_vsi = ice_get_vf_vsi(vf);\n\tif (!vf_vsi)\n\t\treturn -EINVAL;\n\n\tctrl_vsi = pf->vsi[vf->ctrl_vsi_idx];\n\tif (!ctrl_vsi)\n\t\treturn -EINVAL;\n\n\tvf_prof = fdir->fdir_prof[flow];\n\told_seg = vf_prof->fdir_seg[tun];\n\tif (old_seg) {\n\t\tif (!memcmp(old_seg, seg, sizeof(*seg))) {\n\t\t\tdev_dbg(dev, \"Duplicated profile for VF %d!\\n\",\n\t\t\t\tvf->vf_id);\n\t\t\treturn -EEXIST;\n\t\t}\n\n\t\tif (fdir->fdir_fltr_cnt[flow][tun]) {\n\t\t\tret = -EINVAL;\n\t\t\tdev_dbg(dev, \"Input set conflicts for VF %d\\n\",\n\t\t\t\tvf->vf_id);\n\t\t\tgoto err_exit;\n\t\t}\n\n\t\t \n\t\tice_vc_fdir_rem_prof(vf, flow, tun);\n\t}\n\n\tprof_id = ICE_FLOW_PROF_FD(vf_vsi->vsi_num, flow,\n\t\t\t\t   tun ? ICE_FLTR_PTYPE_MAX : 0);\n\n\tret = ice_flow_add_prof(hw, ICE_BLK_FD, ICE_FLOW_RX, prof_id, seg,\n\t\t\t\ttun + 1, &prof);\n\tif (ret) {\n\t\tdev_dbg(dev, \"Could not add VSI flow 0x%x for VF %d\\n\",\n\t\t\tflow, vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tret = ice_flow_add_entry(hw, ICE_BLK_FD, prof_id, vf_vsi->idx,\n\t\t\t\t vf_vsi->idx, ICE_FLOW_PRIO_NORMAL,\n\t\t\t\t seg, &entry1_h);\n\tif (ret) {\n\t\tdev_dbg(dev, \"Could not add flow 0x%x VSI entry for VF %d\\n\",\n\t\t\tflow, vf->vf_id);\n\t\tgoto err_prof;\n\t}\n\n\tret = ice_flow_add_entry(hw, ICE_BLK_FD, prof_id, vf_vsi->idx,\n\t\t\t\t ctrl_vsi->idx, ICE_FLOW_PRIO_NORMAL,\n\t\t\t\t seg, &entry2_h);\n\tif (ret) {\n\t\tdev_dbg(dev,\n\t\t\t\"Could not add flow 0x%x Ctrl VSI entry for VF %d\\n\",\n\t\t\tflow, vf->vf_id);\n\t\tgoto err_entry_1;\n\t}\n\n\tvf_prof->fdir_seg[tun] = seg;\n\tvf_prof->cnt = 0;\n\tfdir->prof_entry_cnt[flow][tun] = 0;\n\n\tvf_prof->entry_h[vf_prof->cnt][tun] = entry1_h;\n\tvf_prof->vsi_h[vf_prof->cnt] = vf_vsi->idx;\n\tvf_prof->cnt++;\n\tfdir->prof_entry_cnt[flow][tun]++;\n\n\tvf_prof->entry_h[vf_prof->cnt][tun] = entry2_h;\n\tvf_prof->vsi_h[vf_prof->cnt] = ctrl_vsi->idx;\n\tvf_prof->cnt++;\n\tfdir->prof_entry_cnt[flow][tun]++;\n\n\treturn 0;\n\nerr_entry_1:\n\tice_rem_prof_id_flow(hw, ICE_BLK_FD,\n\t\t\t     ice_get_hw_vsi_num(hw, vf_vsi->idx), prof_id);\n\tice_flow_rem_entry(hw, ICE_BLK_FD, entry1_h);\nerr_prof:\n\tice_flow_rem_prof(hw, ICE_BLK_FD, prof_id);\nerr_exit:\n\treturn ret;\n}\n\n \nstatic int\nice_vc_fdir_config_input_set(struct ice_vf *vf, struct virtchnl_fdir_add *fltr,\n\t\t\t     struct virtchnl_fdir_fltr_conf *conf, int tun)\n{\n\tstruct ice_fdir_fltr *input = &conf->input;\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tstruct ice_flow_seg_info *seg;\n\tenum ice_fltr_ptype flow;\n\tint ret;\n\n\tret = ice_vc_fdir_has_prof_conflict(vf, conf);\n\tif (ret) {\n\t\tdev_dbg(dev, \"Found flow profile conflict for VF %d\\n\",\n\t\t\tvf->vf_id);\n\t\treturn ret;\n\t}\n\n\tflow = input->flow_type;\n\tret = ice_vc_fdir_alloc_prof(vf, flow);\n\tif (ret) {\n\t\tdev_dbg(dev, \"Alloc flow prof for VF %d failed\\n\", vf->vf_id);\n\t\treturn ret;\n\t}\n\n\tseg = devm_kzalloc(dev, sizeof(*seg), GFP_KERNEL);\n\tif (!seg)\n\t\treturn -ENOMEM;\n\n\tret = ice_vc_fdir_set_flow_fld(vf, fltr, conf, seg);\n\tif (ret) {\n\t\tdev_dbg(dev, \"Set flow field for VF %d failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tret = ice_vc_fdir_set_flow_hdr(vf, conf, seg);\n\tif (ret) {\n\t\tdev_dbg(dev, \"Set flow hdr for VF %d failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tret = ice_vc_fdir_write_flow_prof(vf, flow, seg, tun);\n\tif (ret == -EEXIST) {\n\t\tdevm_kfree(dev, seg);\n\t} else if (ret) {\n\t\tdev_dbg(dev, \"Write flow profile for VF %d failed\\n\",\n\t\t\tvf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\treturn 0;\n\nerr_exit:\n\tdevm_kfree(dev, seg);\n\treturn ret;\n}\n\n \nstatic int\nice_vc_fdir_parse_pattern(struct ice_vf *vf, struct virtchnl_fdir_add *fltr,\n\t\t\t  struct virtchnl_fdir_fltr_conf *conf)\n{\n\tstruct virtchnl_proto_hdrs *proto = &fltr->rule_cfg.proto_hdrs;\n\tenum virtchnl_proto_hdr_type l3 = VIRTCHNL_PROTO_HDR_NONE;\n\tenum virtchnl_proto_hdr_type l4 = VIRTCHNL_PROTO_HDR_NONE;\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tstruct ice_fdir_fltr *input = &conf->input;\n\tint i;\n\n\tif (proto->count > VIRTCHNL_MAX_NUM_PROTO_HDRS) {\n\t\tdev_dbg(dev, \"Invalid protocol count:0x%x for VF %d\\n\",\n\t\t\tproto->count, vf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < proto->count; i++) {\n\t\tstruct virtchnl_proto_hdr *hdr = &proto->proto_hdr[i];\n\t\tstruct ip_esp_hdr *esph;\n\t\tstruct ip_auth_hdr *ah;\n\t\tstruct sctphdr *sctph;\n\t\tstruct ipv6hdr *ip6h;\n\t\tstruct udphdr *udph;\n\t\tstruct tcphdr *tcph;\n\t\tstruct ethhdr *eth;\n\t\tstruct iphdr *iph;\n\t\tu8 s_field;\n\t\tu8 *rawh;\n\n\t\tswitch (hdr->type) {\n\t\tcase VIRTCHNL_PROTO_HDR_ETH:\n\t\t\teth = (struct ethhdr *)hdr->buffer;\n\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NON_IP_L2;\n\n\t\t\tif (hdr->field_selector)\n\t\t\t\tinput->ext_data.ether_type = eth->h_proto;\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_IPV4:\n\t\t\tiph = (struct iphdr *)hdr->buffer;\n\t\t\tl3 = VIRTCHNL_PROTO_HDR_IPV4;\n\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_OTHER;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tinput->ip.v4.src_ip = iph->saddr;\n\t\t\t\tinput->ip.v4.dst_ip = iph->daddr;\n\t\t\t\tinput->ip.v4.tos = iph->tos;\n\t\t\t\tinput->ip.v4.proto = iph->protocol;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_IPV6:\n\t\t\tip6h = (struct ipv6hdr *)hdr->buffer;\n\t\t\tl3 = VIRTCHNL_PROTO_HDR_IPV6;\n\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_OTHER;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tmemcpy(input->ip.v6.src_ip,\n\t\t\t\t       ip6h->saddr.in6_u.u6_addr8,\n\t\t\t\t       sizeof(ip6h->saddr));\n\t\t\t\tmemcpy(input->ip.v6.dst_ip,\n\t\t\t\t       ip6h->daddr.in6_u.u6_addr8,\n\t\t\t\t       sizeof(ip6h->daddr));\n\t\t\t\tinput->ip.v6.tc = ((u8)(ip6h->priority) << 4) |\n\t\t\t\t\t\t  (ip6h->flow_lbl[0] >> 4);\n\t\t\t\tinput->ip.v6.proto = ip6h->nexthdr;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_TCP:\n\t\t\ttcph = (struct tcphdr *)hdr->buffer;\n\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_TCP;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_TCP;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4) {\n\t\t\t\t\tinput->ip.v4.src_port = tcph->source;\n\t\t\t\t\tinput->ip.v4.dst_port = tcph->dest;\n\t\t\t\t} else if (l3 == VIRTCHNL_PROTO_HDR_IPV6) {\n\t\t\t\t\tinput->ip.v6.src_port = tcph->source;\n\t\t\t\t\tinput->ip.v6.dst_port = tcph->dest;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_UDP:\n\t\t\tudph = (struct udphdr *)hdr->buffer;\n\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_UDP;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_UDP;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4) {\n\t\t\t\t\tinput->ip.v4.src_port = udph->source;\n\t\t\t\t\tinput->ip.v4.dst_port = udph->dest;\n\t\t\t\t} else if (l3 == VIRTCHNL_PROTO_HDR_IPV6) {\n\t\t\t\t\tinput->ip.v6.src_port = udph->source;\n\t\t\t\t\tinput->ip.v6.dst_port = udph->dest;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_SCTP:\n\t\t\tsctph = (struct sctphdr *)hdr->buffer;\n\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\tinput->flow_type =\n\t\t\t\t\tICE_FLTR_PTYPE_NONF_IPV4_SCTP;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\tinput->flow_type =\n\t\t\t\t\tICE_FLTR_PTYPE_NONF_IPV6_SCTP;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4) {\n\t\t\t\t\tinput->ip.v4.src_port = sctph->source;\n\t\t\t\t\tinput->ip.v4.dst_port = sctph->dest;\n\t\t\t\t} else if (l3 == VIRTCHNL_PROTO_HDR_IPV6) {\n\t\t\t\t\tinput->ip.v6.src_port = sctph->source;\n\t\t\t\t\tinput->ip.v6.dst_port = sctph->dest;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_L2TPV3:\n\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_L2TPV3;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_L2TPV3;\n\n\t\t\tif (hdr->field_selector)\n\t\t\t\tinput->l2tpv3_data.session_id = *((__be32 *)hdr->buffer);\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_ESP:\n\t\t\tesph = (struct ip_esp_hdr *)hdr->buffer;\n\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4 &&\n\t\t\t    l4 == VIRTCHNL_PROTO_HDR_UDP)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_NAT_T_ESP;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6 &&\n\t\t\t\t l4 == VIRTCHNL_PROTO_HDR_UDP)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_NAT_T_ESP;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV4 &&\n\t\t\t\t l4 == VIRTCHNL_PROTO_HDR_NONE)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_ESP;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6 &&\n\t\t\t\t l4 == VIRTCHNL_PROTO_HDR_NONE)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_ESP;\n\n\t\t\tif (l4 == VIRTCHNL_PROTO_HDR_UDP)\n\t\t\t\tconf->inset_flag |= FDIR_INSET_FLAG_ESP_UDP;\n\t\t\telse\n\t\t\t\tconf->inset_flag |= FDIR_INSET_FLAG_ESP_IPSEC;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\t\tinput->ip.v4.sec_parm_idx = esph->spi;\n\t\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\t\tinput->ip.v6.sec_parm_idx = esph->spi;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_AH:\n\t\t\tah = (struct ip_auth_hdr *)hdr->buffer;\n\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_AH;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_AH;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\t\tinput->ip.v4.sec_parm_idx = ah->spi;\n\t\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\t\tinput->ip.v6.sec_parm_idx = ah->spi;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_PFCP:\n\t\t\trawh = (u8 *)hdr->buffer;\n\t\t\ts_field = (rawh[0] >> PFCP_S_OFFSET) & PFCP_S_MASK;\n\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4 && s_field == 0)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_PFCP_NODE;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV4 && s_field == 1)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_PFCP_SESSION;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6 && s_field == 0)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_PFCP_NODE;\n\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6 && s_field == 1)\n\t\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV6_PFCP_SESSION;\n\n\t\t\tif (hdr->field_selector) {\n\t\t\t\tif (l3 == VIRTCHNL_PROTO_HDR_IPV4)\n\t\t\t\t\tinput->ip.v4.dst_port = cpu_to_be16(PFCP_PORT_NR);\n\t\t\t\telse if (l3 == VIRTCHNL_PROTO_HDR_IPV6)\n\t\t\t\t\tinput->ip.v6.dst_port = cpu_to_be16(PFCP_PORT_NR);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_GTPU_IP:\n\t\t\trawh = (u8 *)hdr->buffer;\n\t\t\tinput->flow_type = ICE_FLTR_PTYPE_NONF_IPV4_GTPU_IPV4_OTHER;\n\n\t\t\tif (hdr->field_selector)\n\t\t\t\tinput->gtpu_data.teid = *(__be32 *)(&rawh[GTPU_TEID_OFFSET]);\n\t\t\tconf->ttype = ICE_FDIR_TUNNEL_TYPE_GTPU;\n\t\t\tbreak;\n\t\tcase VIRTCHNL_PROTO_HDR_GTPU_EH:\n\t\t\trawh = (u8 *)hdr->buffer;\n\n\t\t\tif (hdr->field_selector)\n\t\t\t\tinput->gtpu_data.qfi = rawh[GTPU_EH_QFI_OFFSET] & GTPU_EH_QFI_MASK;\n\t\t\tconf->ttype = ICE_FDIR_TUNNEL_TYPE_GTPU_EH;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_dbg(dev, \"Invalid header type 0x:%x for VF %d\\n\",\n\t\t\t\thdr->type, vf->vf_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_vc_fdir_parse_action(struct ice_vf *vf, struct virtchnl_fdir_add *fltr,\n\t\t\t struct virtchnl_fdir_fltr_conf *conf)\n{\n\tstruct virtchnl_filter_action_set *as = &fltr->rule_cfg.action_set;\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tstruct ice_fdir_fltr *input = &conf->input;\n\tu32 dest_num = 0;\n\tu32 mark_num = 0;\n\tint i;\n\n\tif (as->count > VIRTCHNL_MAX_NUM_ACTIONS) {\n\t\tdev_dbg(dev, \"Invalid action numbers:0x%x for VF %d\\n\",\n\t\t\tas->count, vf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < as->count; i++) {\n\t\tstruct virtchnl_filter_action *action = &as->actions[i];\n\n\t\tswitch (action->type) {\n\t\tcase VIRTCHNL_ACTION_PASSTHRU:\n\t\t\tdest_num++;\n\t\t\tinput->dest_ctl = ICE_FLTR_PRGM_DESC_DEST_DIRECT_PKT_OTHER;\n\t\t\tbreak;\n\t\tcase VIRTCHNL_ACTION_DROP:\n\t\t\tdest_num++;\n\t\t\tinput->dest_ctl = ICE_FLTR_PRGM_DESC_DEST_DROP_PKT;\n\t\t\tbreak;\n\t\tcase VIRTCHNL_ACTION_QUEUE:\n\t\t\tdest_num++;\n\t\t\tinput->dest_ctl = ICE_FLTR_PRGM_DESC_DEST_DIRECT_PKT_QINDEX;\n\t\t\tinput->q_index = action->act_conf.queue.index;\n\t\t\tbreak;\n\t\tcase VIRTCHNL_ACTION_Q_REGION:\n\t\t\tdest_num++;\n\t\t\tinput->dest_ctl = ICE_FLTR_PRGM_DESC_DEST_DIRECT_PKT_QGROUP;\n\t\t\tinput->q_index = action->act_conf.queue.index;\n\t\t\tinput->q_region = action->act_conf.queue.region;\n\t\t\tbreak;\n\t\tcase VIRTCHNL_ACTION_MARK:\n\t\t\tmark_num++;\n\t\t\tinput->fltr_id = action->act_conf.mark_id;\n\t\t\tinput->fdid_prio = ICE_FXD_FLTR_QW1_FDID_PRI_THREE;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_dbg(dev, \"Invalid action type:0x%x for VF %d\\n\",\n\t\t\t\taction->type, vf->vf_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (dest_num == 0 || dest_num >= 2) {\n\t\tdev_dbg(dev, \"Invalid destination action for VF %d\\n\",\n\t\t\tvf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (mark_num >= 2) {\n\t\tdev_dbg(dev, \"Too many mark actions for VF %d\\n\", vf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_vc_validate_fdir_fltr(struct ice_vf *vf, struct virtchnl_fdir_add *fltr,\n\t\t\t  struct virtchnl_fdir_fltr_conf *conf)\n{\n\tstruct virtchnl_proto_hdrs *proto = &fltr->rule_cfg.proto_hdrs;\n\tint ret;\n\n\tif (!ice_vc_validate_pattern(vf, proto))\n\t\treturn -EINVAL;\n\n\tret = ice_vc_fdir_parse_pattern(vf, fltr, conf);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ice_vc_fdir_parse_action(vf, fltr, conf);\n}\n\n \nstatic bool\nice_vc_fdir_comp_rules(struct virtchnl_fdir_fltr_conf *conf_a,\n\t\t       struct virtchnl_fdir_fltr_conf *conf_b)\n{\n\tstruct ice_fdir_fltr *a = &conf_a->input;\n\tstruct ice_fdir_fltr *b = &conf_b->input;\n\n\tif (conf_a->ttype != conf_b->ttype)\n\t\treturn false;\n\tif (a->flow_type != b->flow_type)\n\t\treturn false;\n\tif (memcmp(&a->ip, &b->ip, sizeof(a->ip)))\n\t\treturn false;\n\tif (memcmp(&a->mask, &b->mask, sizeof(a->mask)))\n\t\treturn false;\n\tif (memcmp(&a->gtpu_data, &b->gtpu_data, sizeof(a->gtpu_data)))\n\t\treturn false;\n\tif (memcmp(&a->gtpu_mask, &b->gtpu_mask, sizeof(a->gtpu_mask)))\n\t\treturn false;\n\tif (memcmp(&a->l2tpv3_data, &b->l2tpv3_data, sizeof(a->l2tpv3_data)))\n\t\treturn false;\n\tif (memcmp(&a->l2tpv3_mask, &b->l2tpv3_mask, sizeof(a->l2tpv3_mask)))\n\t\treturn false;\n\tif (memcmp(&a->ext_data, &b->ext_data, sizeof(a->ext_data)))\n\t\treturn false;\n\tif (memcmp(&a->ext_mask, &b->ext_mask, sizeof(a->ext_mask)))\n\t\treturn false;\n\n\treturn true;\n}\n\n \nstatic bool\nice_vc_fdir_is_dup_fltr(struct ice_vf *vf, struct virtchnl_fdir_fltr_conf *conf)\n{\n\tstruct ice_fdir_fltr *desc;\n\tbool ret;\n\n\tlist_for_each_entry(desc, &vf->fdir.fdir_rule_list, fltr_node) {\n\t\tstruct virtchnl_fdir_fltr_conf *node =\n\t\t\t\tto_fltr_conf_from_desc(desc);\n\n\t\tret = ice_vc_fdir_comp_rules(node, conf);\n\t\tif (ret)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic int\nice_vc_fdir_insert_entry(struct ice_vf *vf,\n\t\t\t struct virtchnl_fdir_fltr_conf *conf, u32 *id)\n{\n\tstruct ice_fdir_fltr *input = &conf->input;\n\tint i;\n\n\t \n\ti = idr_alloc(&vf->fdir.fdir_rule_idr, conf, 0,\n\t\t      ICE_FDIR_MAX_FLTRS, GFP_KERNEL);\n\tif (i < 0)\n\t\treturn -EINVAL;\n\t*id = i;\n\n\tlist_add(&input->fltr_node, &vf->fdir.fdir_rule_list);\n\treturn 0;\n}\n\n \nstatic void\nice_vc_fdir_remove_entry(struct ice_vf *vf,\n\t\t\t struct virtchnl_fdir_fltr_conf *conf, u32 id)\n{\n\tstruct ice_fdir_fltr *input = &conf->input;\n\n\tidr_remove(&vf->fdir.fdir_rule_idr, id);\n\tlist_del(&input->fltr_node);\n}\n\n \nstatic struct virtchnl_fdir_fltr_conf *\nice_vc_fdir_lookup_entry(struct ice_vf *vf, u32 id)\n{\n\treturn idr_find(&vf->fdir.fdir_rule_idr, id);\n}\n\n \nstatic void ice_vc_fdir_flush_entry(struct ice_vf *vf)\n{\n\tstruct virtchnl_fdir_fltr_conf *conf;\n\tstruct ice_fdir_fltr *desc, *temp;\n\n\tlist_for_each_entry_safe(desc, temp,\n\t\t\t\t &vf->fdir.fdir_rule_list, fltr_node) {\n\t\tconf = to_fltr_conf_from_desc(desc);\n\t\tlist_del(&desc->fltr_node);\n\t\tdevm_kfree(ice_pf_to_dev(vf->pf), conf);\n\t}\n}\n\n \nstatic int ice_vc_fdir_write_fltr(struct ice_vf *vf,\n\t\t\t\t  struct virtchnl_fdir_fltr_conf *conf,\n\t\t\t\t  bool add, bool is_tun)\n{\n\tstruct ice_fdir_fltr *input = &conf->input;\n\tstruct ice_vsi *vsi, *ctrl_vsi;\n\tstruct ice_fltr_desc desc;\n\tstruct device *dev;\n\tstruct ice_pf *pf;\n\tstruct ice_hw *hw;\n\tint ret;\n\tu8 *pkt;\n\n\tpf = vf->pf;\n\tdev = ice_pf_to_dev(pf);\n\thw = &pf->hw;\n\tvsi = ice_get_vf_vsi(vf);\n\tif (!vsi) {\n\t\tdev_dbg(dev, \"Invalid vsi for VF %d\\n\", vf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\tinput->dest_vsi = vsi->idx;\n\tinput->comp_report = ICE_FXD_FLTR_QW0_COMP_REPORT_SW;\n\n\tctrl_vsi = pf->vsi[vf->ctrl_vsi_idx];\n\tif (!ctrl_vsi) {\n\t\tdev_dbg(dev, \"Invalid ctrl_vsi for VF %d\\n\", vf->vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\tpkt = devm_kzalloc(dev, ICE_FDIR_MAX_RAW_PKT_SIZE, GFP_KERNEL);\n\tif (!pkt)\n\t\treturn -ENOMEM;\n\n\tice_fdir_get_prgm_desc(hw, input, &desc, add);\n\tret = ice_fdir_get_gen_prgm_pkt(hw, input, pkt, false, is_tun);\n\tif (ret) {\n\t\tdev_dbg(dev, \"Gen training pkt for VF %d ptype %d failed\\n\",\n\t\t\tvf->vf_id, input->flow_type);\n\t\tgoto err_free_pkt;\n\t}\n\n\tret = ice_prgm_fdir_fltr(ctrl_vsi, &desc, pkt);\n\tif (ret)\n\t\tgoto err_free_pkt;\n\n\treturn 0;\n\nerr_free_pkt:\n\tdevm_kfree(dev, pkt);\n\treturn ret;\n}\n\n \nstatic void ice_vf_fdir_timer(struct timer_list *t)\n{\n\tstruct ice_vf_fdir_ctx *ctx_irq = from_timer(ctx_irq, t, rx_tmr);\n\tstruct ice_vf_fdir_ctx *ctx_done;\n\tstruct ice_vf_fdir *fdir;\n\tunsigned long flags;\n\tstruct ice_vf *vf;\n\tstruct ice_pf *pf;\n\n\tfdir = container_of(ctx_irq, struct ice_vf_fdir, ctx_irq);\n\tvf = container_of(fdir, struct ice_vf, fdir);\n\tctx_done = &fdir->ctx_done;\n\tpf = vf->pf;\n\tspin_lock_irqsave(&fdir->ctx_lock, flags);\n\tif (!(ctx_irq->flags & ICE_VF_FDIR_CTX_VALID)) {\n\t\tspin_unlock_irqrestore(&fdir->ctx_lock, flags);\n\t\tWARN_ON_ONCE(1);\n\t\treturn;\n\t}\n\n\tctx_irq->flags &= ~ICE_VF_FDIR_CTX_VALID;\n\n\tctx_done->flags |= ICE_VF_FDIR_CTX_VALID;\n\tctx_done->conf = ctx_irq->conf;\n\tctx_done->stat = ICE_FDIR_CTX_TIMEOUT;\n\tctx_done->v_opcode = ctx_irq->v_opcode;\n\tspin_unlock_irqrestore(&fdir->ctx_lock, flags);\n\n\tset_bit(ICE_FD_VF_FLUSH_CTX, pf->state);\n\tice_service_task_schedule(pf);\n}\n\n \nvoid\nice_vc_fdir_irq_handler(struct ice_vsi *ctrl_vsi,\n\t\t\tunion ice_32b_rx_flex_desc *rx_desc)\n{\n\tstruct ice_pf *pf = ctrl_vsi->back;\n\tstruct ice_vf *vf = ctrl_vsi->vf;\n\tstruct ice_vf_fdir_ctx *ctx_done;\n\tstruct ice_vf_fdir_ctx *ctx_irq;\n\tstruct ice_vf_fdir *fdir;\n\tunsigned long flags;\n\tstruct device *dev;\n\tint ret;\n\n\tif (WARN_ON(!vf))\n\t\treturn;\n\n\tfdir = &vf->fdir;\n\tctx_done = &fdir->ctx_done;\n\tctx_irq = &fdir->ctx_irq;\n\tdev = ice_pf_to_dev(pf);\n\tspin_lock_irqsave(&fdir->ctx_lock, flags);\n\tif (!(ctx_irq->flags & ICE_VF_FDIR_CTX_VALID)) {\n\t\tspin_unlock_irqrestore(&fdir->ctx_lock, flags);\n\t\tWARN_ON_ONCE(1);\n\t\treturn;\n\t}\n\n\tctx_irq->flags &= ~ICE_VF_FDIR_CTX_VALID;\n\n\tctx_done->flags |= ICE_VF_FDIR_CTX_VALID;\n\tctx_done->conf = ctx_irq->conf;\n\tctx_done->stat = ICE_FDIR_CTX_IRQ;\n\tctx_done->v_opcode = ctx_irq->v_opcode;\n\tmemcpy(&ctx_done->rx_desc, rx_desc, sizeof(*rx_desc));\n\tspin_unlock_irqrestore(&fdir->ctx_lock, flags);\n\n\tret = del_timer(&ctx_irq->rx_tmr);\n\tif (!ret)\n\t\tdev_err(dev, \"VF %d: Unexpected inactive timer!\\n\", vf->vf_id);\n\n\tset_bit(ICE_FD_VF_FLUSH_CTX, pf->state);\n\tice_service_task_schedule(pf);\n}\n\n \nstatic void ice_vf_fdir_dump_info(struct ice_vf *vf)\n{\n\tstruct ice_vsi *vf_vsi;\n\tu32 fd_size, fd_cnt;\n\tstruct device *dev;\n\tstruct ice_pf *pf;\n\tstruct ice_hw *hw;\n\tu16 vsi_num;\n\n\tpf = vf->pf;\n\thw = &pf->hw;\n\tdev = ice_pf_to_dev(pf);\n\tvf_vsi = ice_get_vf_vsi(vf);\n\tif (!vf_vsi) {\n\t\tdev_dbg(dev, \"VF %d: invalid VSI pointer\\n\", vf->vf_id);\n\t\treturn;\n\t}\n\n\tvsi_num = ice_get_hw_vsi_num(hw, vf_vsi->idx);\n\n\tfd_size = rd32(hw, VSIQF_FD_SIZE(vsi_num));\n\tfd_cnt = rd32(hw, VSIQF_FD_CNT(vsi_num));\n\tdev_dbg(dev, \"VF %d: space allocated: guar:0x%x, be:0x%x, space consumed: guar:0x%x, be:0x%x\\n\",\n\t\tvf->vf_id,\n\t\t(fd_size & VSIQF_FD_CNT_FD_GCNT_M) >> VSIQF_FD_CNT_FD_GCNT_S,\n\t\t(fd_size & VSIQF_FD_CNT_FD_BCNT_M) >> VSIQF_FD_CNT_FD_BCNT_S,\n\t\t(fd_cnt & VSIQF_FD_CNT_FD_GCNT_M) >> VSIQF_FD_CNT_FD_GCNT_S,\n\t\t(fd_cnt & VSIQF_FD_CNT_FD_BCNT_M) >> VSIQF_FD_CNT_FD_BCNT_S);\n}\n\n \nstatic int\nice_vf_verify_rx_desc(struct ice_vf *vf, struct ice_vf_fdir_ctx *ctx,\n\t\t      enum virtchnl_fdir_prgm_status *status)\n{\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tu32 stat_err, error, prog_id;\n\tint ret;\n\n\tstat_err = le16_to_cpu(ctx->rx_desc.wb.status_error0);\n\tif (((stat_err & ICE_FXD_FLTR_WB_QW1_DD_M) >>\n\t    ICE_FXD_FLTR_WB_QW1_DD_S) != ICE_FXD_FLTR_WB_QW1_DD_YES) {\n\t\t*status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tdev_err(dev, \"VF %d: Desc Done not set\\n\", vf->vf_id);\n\t\tret = -EINVAL;\n\t\tgoto err_exit;\n\t}\n\n\tprog_id = (stat_err & ICE_FXD_FLTR_WB_QW1_PROG_ID_M) >>\n\t\tICE_FXD_FLTR_WB_QW1_PROG_ID_S;\n\tif (prog_id == ICE_FXD_FLTR_WB_QW1_PROG_ADD &&\n\t    ctx->v_opcode != VIRTCHNL_OP_ADD_FDIR_FILTER) {\n\t\tdev_err(dev, \"VF %d: Desc show add, but ctx not\",\n\t\t\tvf->vf_id);\n\t\t*status = VIRTCHNL_FDIR_FAILURE_RULE_INVALID;\n\t\tret = -EINVAL;\n\t\tgoto err_exit;\n\t}\n\n\tif (prog_id == ICE_FXD_FLTR_WB_QW1_PROG_DEL &&\n\t    ctx->v_opcode != VIRTCHNL_OP_DEL_FDIR_FILTER) {\n\t\tdev_err(dev, \"VF %d: Desc show del, but ctx not\",\n\t\t\tvf->vf_id);\n\t\t*status = VIRTCHNL_FDIR_FAILURE_RULE_INVALID;\n\t\tret = -EINVAL;\n\t\tgoto err_exit;\n\t}\n\n\terror = (stat_err & ICE_FXD_FLTR_WB_QW1_FAIL_M) >>\n\t\tICE_FXD_FLTR_WB_QW1_FAIL_S;\n\tif (error == ICE_FXD_FLTR_WB_QW1_FAIL_YES) {\n\t\tif (prog_id == ICE_FXD_FLTR_WB_QW1_PROG_ADD) {\n\t\t\tdev_err(dev, \"VF %d, Failed to add FDIR rule due to no space in the table\",\n\t\t\t\tvf->vf_id);\n\t\t\t*status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\t} else {\n\t\t\tdev_err(dev, \"VF %d, Failed to remove FDIR rule, attempt to remove non-existent entry\",\n\t\t\t\tvf->vf_id);\n\t\t\t*status = VIRTCHNL_FDIR_FAILURE_RULE_NONEXIST;\n\t\t}\n\t\tret = -EINVAL;\n\t\tgoto err_exit;\n\t}\n\n\terror = (stat_err & ICE_FXD_FLTR_WB_QW1_FAIL_PROF_M) >>\n\t\tICE_FXD_FLTR_WB_QW1_FAIL_PROF_S;\n\tif (error == ICE_FXD_FLTR_WB_QW1_FAIL_PROF_YES) {\n\t\tdev_err(dev, \"VF %d: Profile matching error\", vf->vf_id);\n\t\t*status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tret = -EINVAL;\n\t\tgoto err_exit;\n\t}\n\n\t*status = VIRTCHNL_FDIR_SUCCESS;\n\n\treturn 0;\n\nerr_exit:\n\tice_vf_fdir_dump_info(vf);\n\treturn ret;\n}\n\n \nstatic int\nice_vc_add_fdir_fltr_post(struct ice_vf *vf, struct ice_vf_fdir_ctx *ctx,\n\t\t\t  enum virtchnl_fdir_prgm_status status,\n\t\t\t  bool success)\n{\n\tstruct virtchnl_fdir_fltr_conf *conf = ctx->conf;\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tenum virtchnl_status_code v_ret;\n\tstruct virtchnl_fdir_add *resp;\n\tint ret, len, is_tun;\n\n\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\tlen = sizeof(*resp);\n\tresp = kzalloc(len, GFP_KERNEL);\n\tif (!resp) {\n\t\tlen = 0;\n\t\tv_ret = VIRTCHNL_STATUS_ERR_NO_MEMORY;\n\t\tdev_dbg(dev, \"VF %d: Alloc resp buf fail\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tif (!success)\n\t\tgoto err_exit;\n\n\tis_tun = 0;\n\tresp->status = status;\n\tresp->flow_id = conf->flow_id;\n\tvf->fdir.fdir_fltr_cnt[conf->input.flow_type][is_tun]++;\n\n\tret = ice_vc_send_msg_to_vf(vf, ctx->v_opcode, v_ret,\n\t\t\t\t    (u8 *)resp, len);\n\tkfree(resp);\n\n\tdev_dbg(dev, \"VF %d: flow_id:0x%X, FDIR %s success!\\n\",\n\t\tvf->vf_id, conf->flow_id,\n\t\t(ctx->v_opcode == VIRTCHNL_OP_ADD_FDIR_FILTER) ?\n\t\t\"add\" : \"del\");\n\treturn ret;\n\nerr_exit:\n\tif (resp)\n\t\tresp->status = status;\n\tice_vc_fdir_remove_entry(vf, conf, conf->flow_id);\n\tdevm_kfree(dev, conf);\n\n\tret = ice_vc_send_msg_to_vf(vf, ctx->v_opcode, v_ret,\n\t\t\t\t    (u8 *)resp, len);\n\tkfree(resp);\n\treturn ret;\n}\n\n \nstatic int\nice_vc_del_fdir_fltr_post(struct ice_vf *vf, struct ice_vf_fdir_ctx *ctx,\n\t\t\t  enum virtchnl_fdir_prgm_status status,\n\t\t\t  bool success)\n{\n\tstruct virtchnl_fdir_fltr_conf *conf = ctx->conf;\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tenum virtchnl_status_code v_ret;\n\tstruct virtchnl_fdir_del *resp;\n\tint ret, len, is_tun;\n\n\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\tlen = sizeof(*resp);\n\tresp = kzalloc(len, GFP_KERNEL);\n\tif (!resp) {\n\t\tlen = 0;\n\t\tv_ret = VIRTCHNL_STATUS_ERR_NO_MEMORY;\n\t\tdev_dbg(dev, \"VF %d: Alloc resp buf fail\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tif (!success)\n\t\tgoto err_exit;\n\n\tis_tun = 0;\n\tresp->status = status;\n\tice_vc_fdir_remove_entry(vf, conf, conf->flow_id);\n\tvf->fdir.fdir_fltr_cnt[conf->input.flow_type][is_tun]--;\n\n\tret = ice_vc_send_msg_to_vf(vf, ctx->v_opcode, v_ret,\n\t\t\t\t    (u8 *)resp, len);\n\tkfree(resp);\n\n\tdev_dbg(dev, \"VF %d: flow_id:0x%X, FDIR %s success!\\n\",\n\t\tvf->vf_id, conf->flow_id,\n\t\t(ctx->v_opcode == VIRTCHNL_OP_ADD_FDIR_FILTER) ?\n\t\t\"add\" : \"del\");\n\tdevm_kfree(dev, conf);\n\treturn ret;\n\nerr_exit:\n\tif (resp)\n\t\tresp->status = status;\n\tif (success)\n\t\tdevm_kfree(dev, conf);\n\n\tret = ice_vc_send_msg_to_vf(vf, ctx->v_opcode, v_ret,\n\t\t\t\t    (u8 *)resp, len);\n\tkfree(resp);\n\treturn ret;\n}\n\n \nvoid ice_flush_fdir_ctx(struct ice_pf *pf)\n{\n\tstruct ice_vf *vf;\n\tunsigned int bkt;\n\n\tif (!test_and_clear_bit(ICE_FD_VF_FLUSH_CTX, pf->state))\n\t\treturn;\n\n\tmutex_lock(&pf->vfs.table_lock);\n\tice_for_each_vf(pf, bkt, vf) {\n\t\tstruct device *dev = ice_pf_to_dev(pf);\n\t\tenum virtchnl_fdir_prgm_status status;\n\t\tstruct ice_vf_fdir_ctx *ctx;\n\t\tunsigned long flags;\n\t\tint ret;\n\n\t\tif (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states))\n\t\t\tcontinue;\n\n\t\tif (vf->ctrl_vsi_idx == ICE_NO_VSI)\n\t\t\tcontinue;\n\n\t\tctx = &vf->fdir.ctx_done;\n\t\tspin_lock_irqsave(&vf->fdir.ctx_lock, flags);\n\t\tif (!(ctx->flags & ICE_VF_FDIR_CTX_VALID)) {\n\t\t\tspin_unlock_irqrestore(&vf->fdir.ctx_lock, flags);\n\t\t\tcontinue;\n\t\t}\n\t\tspin_unlock_irqrestore(&vf->fdir.ctx_lock, flags);\n\n\t\tWARN_ON(ctx->stat == ICE_FDIR_CTX_READY);\n\t\tif (ctx->stat == ICE_FDIR_CTX_TIMEOUT) {\n\t\t\tstatus = VIRTCHNL_FDIR_FAILURE_RULE_TIMEOUT;\n\t\t\tdev_err(dev, \"VF %d: ctrl_vsi irq timeout\\n\",\n\t\t\t\tvf->vf_id);\n\t\t\tgoto err_exit;\n\t\t}\n\n\t\tret = ice_vf_verify_rx_desc(vf, ctx, &status);\n\t\tif (ret)\n\t\t\tgoto err_exit;\n\n\t\tif (ctx->v_opcode == VIRTCHNL_OP_ADD_FDIR_FILTER)\n\t\t\tice_vc_add_fdir_fltr_post(vf, ctx, status, true);\n\t\telse if (ctx->v_opcode == VIRTCHNL_OP_DEL_FDIR_FILTER)\n\t\t\tice_vc_del_fdir_fltr_post(vf, ctx, status, true);\n\t\telse\n\t\t\tdev_err(dev, \"VF %d: Unsupported opcode\\n\", vf->vf_id);\n\n\t\tspin_lock_irqsave(&vf->fdir.ctx_lock, flags);\n\t\tctx->flags &= ~ICE_VF_FDIR_CTX_VALID;\n\t\tspin_unlock_irqrestore(&vf->fdir.ctx_lock, flags);\n\t\tcontinue;\nerr_exit:\n\t\tif (ctx->v_opcode == VIRTCHNL_OP_ADD_FDIR_FILTER)\n\t\t\tice_vc_add_fdir_fltr_post(vf, ctx, status, false);\n\t\telse if (ctx->v_opcode == VIRTCHNL_OP_DEL_FDIR_FILTER)\n\t\t\tice_vc_del_fdir_fltr_post(vf, ctx, status, false);\n\t\telse\n\t\t\tdev_err(dev, \"VF %d: Unsupported opcode\\n\", vf->vf_id);\n\n\t\tspin_lock_irqsave(&vf->fdir.ctx_lock, flags);\n\t\tctx->flags &= ~ICE_VF_FDIR_CTX_VALID;\n\t\tspin_unlock_irqrestore(&vf->fdir.ctx_lock, flags);\n\t}\n\tmutex_unlock(&pf->vfs.table_lock);\n}\n\n \nstatic int\nice_vc_fdir_set_irq_ctx(struct ice_vf *vf, struct virtchnl_fdir_fltr_conf *conf,\n\t\t\tenum virtchnl_ops v_opcode)\n{\n\tstruct device *dev = ice_pf_to_dev(vf->pf);\n\tstruct ice_vf_fdir_ctx *ctx;\n\tunsigned long flags;\n\n\tctx = &vf->fdir.ctx_irq;\n\tspin_lock_irqsave(&vf->fdir.ctx_lock, flags);\n\tif ((vf->fdir.ctx_irq.flags & ICE_VF_FDIR_CTX_VALID) ||\n\t    (vf->fdir.ctx_done.flags & ICE_VF_FDIR_CTX_VALID)) {\n\t\tspin_unlock_irqrestore(&vf->fdir.ctx_lock, flags);\n\t\tdev_dbg(dev, \"VF %d: Last request is still in progress\\n\",\n\t\t\tvf->vf_id);\n\t\treturn -EBUSY;\n\t}\n\tctx->flags |= ICE_VF_FDIR_CTX_VALID;\n\tspin_unlock_irqrestore(&vf->fdir.ctx_lock, flags);\n\n\tctx->conf = conf;\n\tctx->v_opcode = v_opcode;\n\tctx->stat = ICE_FDIR_CTX_READY;\n\ttimer_setup(&ctx->rx_tmr, ice_vf_fdir_timer, 0);\n\n\tmod_timer(&ctx->rx_tmr, round_jiffies(msecs_to_jiffies(10) + jiffies));\n\n\treturn 0;\n}\n\n \nstatic void ice_vc_fdir_clear_irq_ctx(struct ice_vf *vf)\n{\n\tstruct ice_vf_fdir_ctx *ctx = &vf->fdir.ctx_irq;\n\tunsigned long flags;\n\n\tdel_timer(&ctx->rx_tmr);\n\tspin_lock_irqsave(&vf->fdir.ctx_lock, flags);\n\tctx->flags &= ~ICE_VF_FDIR_CTX_VALID;\n\tspin_unlock_irqrestore(&vf->fdir.ctx_lock, flags);\n}\n\n \nint ice_vc_add_fdir_fltr(struct ice_vf *vf, u8 *msg)\n{\n\tstruct virtchnl_fdir_add *fltr = (struct virtchnl_fdir_add *)msg;\n\tstruct virtchnl_fdir_add *stat = NULL;\n\tstruct virtchnl_fdir_fltr_conf *conf;\n\tenum virtchnl_status_code v_ret;\n\tstruct device *dev;\n\tstruct ice_pf *pf;\n\tint is_tun = 0;\n\tint len = 0;\n\tint ret;\n\n\tpf = vf->pf;\n\tdev = ice_pf_to_dev(pf);\n\tret = ice_vc_fdir_param_check(vf, fltr->vsi_id);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_ERR_PARAM;\n\t\tdev_dbg(dev, \"Parameter check for VF %d failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tret = ice_vf_start_ctrl_vsi(vf);\n\tif (ret && (ret != -EEXIST)) {\n\t\tv_ret = VIRTCHNL_STATUS_ERR_PARAM;\n\t\tdev_err(dev, \"Init FDIR for VF %d failed, ret:%d\\n\",\n\t\t\tvf->vf_id, ret);\n\t\tgoto err_exit;\n\t}\n\n\tstat = kzalloc(sizeof(*stat), GFP_KERNEL);\n\tif (!stat) {\n\t\tv_ret = VIRTCHNL_STATUS_ERR_NO_MEMORY;\n\t\tdev_dbg(dev, \"Alloc stat for VF %d failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tconf = devm_kzalloc(dev, sizeof(*conf), GFP_KERNEL);\n\tif (!conf) {\n\t\tv_ret = VIRTCHNL_STATUS_ERR_NO_MEMORY;\n\t\tdev_dbg(dev, \"Alloc conf for VF %d failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tlen = sizeof(*stat);\n\tret = ice_vc_validate_fdir_fltr(vf, fltr, conf);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_INVALID;\n\t\tdev_dbg(dev, \"Invalid FDIR filter from VF %d\\n\", vf->vf_id);\n\t\tgoto err_free_conf;\n\t}\n\n\tif (fltr->validate_only) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_SUCCESS;\n\t\tdevm_kfree(dev, conf);\n\t\tret = ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_ADD_FDIR_FILTER,\n\t\t\t\t\t    v_ret, (u8 *)stat, len);\n\t\tgoto exit;\n\t}\n\n\tret = ice_vc_fdir_config_input_set(vf, fltr, conf, is_tun);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_CONFLICT;\n\t\tdev_err(dev, \"VF %d: FDIR input set configure failed, ret:%d\\n\",\n\t\t\tvf->vf_id, ret);\n\t\tgoto err_free_conf;\n\t}\n\n\tret = ice_vc_fdir_is_dup_fltr(vf, conf);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_EXIST;\n\t\tdev_dbg(dev, \"VF %d: duplicated FDIR rule detected\\n\",\n\t\t\tvf->vf_id);\n\t\tgoto err_free_conf;\n\t}\n\n\tret = ice_vc_fdir_insert_entry(vf, conf, &conf->flow_id);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tdev_dbg(dev, \"VF %d: insert FDIR list failed\\n\", vf->vf_id);\n\t\tgoto err_free_conf;\n\t}\n\n\tret = ice_vc_fdir_set_irq_ctx(vf, conf, VIRTCHNL_OP_ADD_FDIR_FILTER);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tdev_dbg(dev, \"VF %d: set FDIR context failed\\n\", vf->vf_id);\n\t\tgoto err_rem_entry;\n\t}\n\n\tret = ice_vc_fdir_write_fltr(vf, conf, true, is_tun);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tdev_err(dev, \"VF %d: writing FDIR rule failed, ret:%d\\n\",\n\t\t\tvf->vf_id, ret);\n\t\tgoto err_clr_irq;\n\t}\n\nexit:\n\tkfree(stat);\n\treturn ret;\n\nerr_clr_irq:\n\tice_vc_fdir_clear_irq_ctx(vf);\nerr_rem_entry:\n\tice_vc_fdir_remove_entry(vf, conf, conf->flow_id);\nerr_free_conf:\n\tdevm_kfree(dev, conf);\nerr_exit:\n\tret = ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_ADD_FDIR_FILTER, v_ret,\n\t\t\t\t    (u8 *)stat, len);\n\tkfree(stat);\n\treturn ret;\n}\n\n \nint ice_vc_del_fdir_fltr(struct ice_vf *vf, u8 *msg)\n{\n\tstruct virtchnl_fdir_del *fltr = (struct virtchnl_fdir_del *)msg;\n\tstruct virtchnl_fdir_del *stat = NULL;\n\tstruct virtchnl_fdir_fltr_conf *conf;\n\tenum virtchnl_status_code v_ret;\n\tstruct device *dev;\n\tstruct ice_pf *pf;\n\tint is_tun = 0;\n\tint len = 0;\n\tint ret;\n\n\tpf = vf->pf;\n\tdev = ice_pf_to_dev(pf);\n\tret = ice_vc_fdir_param_check(vf, fltr->vsi_id);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_ERR_PARAM;\n\t\tdev_dbg(dev, \"Parameter check for VF %d failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tstat = kzalloc(sizeof(*stat), GFP_KERNEL);\n\tif (!stat) {\n\t\tv_ret = VIRTCHNL_STATUS_ERR_NO_MEMORY;\n\t\tdev_dbg(dev, \"Alloc stat for VF %d failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tlen = sizeof(*stat);\n\n\tconf = ice_vc_fdir_lookup_entry(vf, fltr->flow_id);\n\tif (!conf) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_NONEXIST;\n\t\tdev_dbg(dev, \"VF %d: FDIR invalid flow_id:0x%X\\n\",\n\t\t\tvf->vf_id, fltr->flow_id);\n\t\tgoto err_exit;\n\t}\n\n\t \n\tif (vf->ctrl_vsi_idx == ICE_NO_VSI) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tdev_err(dev, \"Invalid FDIR ctrl_vsi for VF %d\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tret = ice_vc_fdir_set_irq_ctx(vf, conf, VIRTCHNL_OP_DEL_FDIR_FILTER);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tdev_dbg(dev, \"VF %d: set FDIR context failed\\n\", vf->vf_id);\n\t\tgoto err_exit;\n\t}\n\n\tret = ice_vc_fdir_write_fltr(vf, conf, false, is_tun);\n\tif (ret) {\n\t\tv_ret = VIRTCHNL_STATUS_SUCCESS;\n\t\tstat->status = VIRTCHNL_FDIR_FAILURE_RULE_NORESOURCE;\n\t\tdev_err(dev, \"VF %d: writing FDIR rule failed, ret:%d\\n\",\n\t\t\tvf->vf_id, ret);\n\t\tgoto err_del_tmr;\n\t}\n\n\tkfree(stat);\n\n\treturn ret;\n\nerr_del_tmr:\n\tice_vc_fdir_clear_irq_ctx(vf);\nerr_exit:\n\tret = ice_vc_send_msg_to_vf(vf, VIRTCHNL_OP_DEL_FDIR_FILTER, v_ret,\n\t\t\t\t    (u8 *)stat, len);\n\tkfree(stat);\n\treturn ret;\n}\n\n \nvoid ice_vf_fdir_init(struct ice_vf *vf)\n{\n\tstruct ice_vf_fdir *fdir = &vf->fdir;\n\n\tidr_init(&fdir->fdir_rule_idr);\n\tINIT_LIST_HEAD(&fdir->fdir_rule_list);\n\n\tspin_lock_init(&fdir->ctx_lock);\n\tfdir->ctx_irq.flags = 0;\n\tfdir->ctx_done.flags = 0;\n\tice_vc_fdir_reset_cnt_all(fdir);\n}\n\n \nvoid ice_vf_fdir_exit(struct ice_vf *vf)\n{\n\tice_vc_fdir_flush_entry(vf);\n\tidr_destroy(&vf->fdir.fdir_rule_idr);\n\tice_vc_fdir_rem_prof_all(vf);\n\tice_vc_fdir_free_prof_all(vf);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}