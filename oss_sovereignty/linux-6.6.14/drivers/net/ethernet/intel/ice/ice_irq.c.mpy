{
  "module_name": "ice_irq.c",
  "hash_id": "4c9a001a3a91b44c718fec5336e3ec7c7af48627f3e44e1ddb8f5266aa793f43",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_irq.c",
  "human_readable_source": "\n \n\n#include \"ice.h\"\n#include \"ice_lib.h\"\n#include \"ice_irq.h\"\n\n \nstatic void\nice_init_irq_tracker(struct ice_pf *pf, unsigned int max_vectors,\n\t\t     unsigned int num_static)\n{\n\tpf->irq_tracker.num_entries = max_vectors;\n\tpf->irq_tracker.num_static = num_static;\n\txa_init_flags(&pf->irq_tracker.entries, XA_FLAGS_ALLOC);\n}\n\n \nstatic void ice_deinit_irq_tracker(struct ice_pf *pf)\n{\n\txa_destroy(&pf->irq_tracker.entries);\n}\n\n \nstatic void ice_free_irq_res(struct ice_pf *pf, u16 index)\n{\n\tstruct ice_irq_entry *entry;\n\n\tentry = xa_erase(&pf->irq_tracker.entries, index);\n\tkfree(entry);\n}\n\n \nstatic struct ice_irq_entry *ice_get_irq_res(struct ice_pf *pf, bool dyn_only)\n{\n\tstruct xa_limit limit = { .max = pf->irq_tracker.num_entries,\n\t\t\t\t  .min = 0 };\n\tunsigned int num_static = pf->irq_tracker.num_static;\n\tstruct ice_irq_entry *entry;\n\tunsigned int index;\n\tint ret;\n\n\tentry = kzalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry)\n\t\treturn NULL;\n\n\t \n\tif (dyn_only)\n\t\tlimit.min = num_static;\n\n\tret = xa_alloc(&pf->irq_tracker.entries, &index, entry, limit,\n\t\t       GFP_KERNEL);\n\n\tif (ret) {\n\t\tkfree(entry);\n\t\tentry = NULL;\n\t} else {\n\t\tentry->index = index;\n\t\tentry->dynamic = index >= num_static;\n\t}\n\n\treturn entry;\n}\n\n \nstatic void ice_reduce_msix_usage(struct ice_pf *pf, int v_remain)\n{\n\tint v_rdma;\n\n\tif (!ice_is_rdma_ena(pf)) {\n\t\tpf->num_lan_msix = v_remain;\n\t\treturn;\n\t}\n\n\t \n\tv_rdma = ICE_RDMA_NUM_AEQ_MSIX + 1;\n\n\tif (v_remain < ICE_MIN_LAN_TXRX_MSIX + ICE_MIN_RDMA_MSIX) {\n\t\tdev_warn(ice_pf_to_dev(pf), \"Not enough MSI-X vectors to support RDMA.\\n\");\n\t\tclear_bit(ICE_FLAG_RDMA_ENA, pf->flags);\n\n\t\tpf->num_rdma_msix = 0;\n\t\tpf->num_lan_msix = ICE_MIN_LAN_TXRX_MSIX;\n\t} else if ((v_remain < ICE_MIN_LAN_TXRX_MSIX + v_rdma) ||\n\t\t   (v_remain - v_rdma < v_rdma)) {\n\t\t \n\t\tpf->num_rdma_msix = ICE_MIN_RDMA_MSIX;\n\t\tpf->num_lan_msix = v_remain - ICE_MIN_RDMA_MSIX;\n\t} else {\n\t\t \n\t\tpf->num_rdma_msix = (v_remain - ICE_RDMA_NUM_AEQ_MSIX) / 2 +\n\t\t\t\t    ICE_RDMA_NUM_AEQ_MSIX;\n\t\tpf->num_lan_msix = v_remain - pf->num_rdma_msix;\n\t}\n}\n\n \nstatic int ice_ena_msix_range(struct ice_pf *pf)\n{\n\tint num_cpus, hw_num_msix, v_other, v_wanted, v_actual;\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tint err;\n\n\thw_num_msix = pf->hw.func_caps.common_cap.num_msix_vectors;\n\tnum_cpus = num_online_cpus();\n\n\t \n\tv_other = ICE_MIN_LAN_OICR_MSIX;\n\n\t \n\tif (test_bit(ICE_FLAG_FD_ENA, pf->flags))\n\t\tv_other += ICE_FDIR_MSIX;\n\n\t \n\tv_other += ICE_ESWITCH_MSIX;\n\n\tv_wanted = v_other;\n\n\t \n\tpf->num_lan_msix = num_cpus;\n\tv_wanted += pf->num_lan_msix;\n\n\t \n\tif (ice_is_rdma_ena(pf)) {\n\t\tpf->num_rdma_msix = num_cpus + ICE_RDMA_NUM_AEQ_MSIX;\n\t\tv_wanted += pf->num_rdma_msix;\n\t}\n\n\tif (v_wanted > hw_num_msix) {\n\t\tint v_remain;\n\n\t\tdev_warn(dev, \"not enough device MSI-X vectors. wanted = %d, available = %d\\n\",\n\t\t\t v_wanted, hw_num_msix);\n\n\t\tif (hw_num_msix < ICE_MIN_MSIX) {\n\t\t\terr = -ERANGE;\n\t\t\tgoto exit_err;\n\t\t}\n\n\t\tv_remain = hw_num_msix - v_other;\n\t\tif (v_remain < ICE_MIN_LAN_TXRX_MSIX) {\n\t\t\tv_other = ICE_MIN_MSIX - ICE_MIN_LAN_TXRX_MSIX;\n\t\t\tv_remain = ICE_MIN_LAN_TXRX_MSIX;\n\t\t}\n\n\t\tice_reduce_msix_usage(pf, v_remain);\n\t\tv_wanted = pf->num_lan_msix + pf->num_rdma_msix + v_other;\n\n\t\tdev_notice(dev, \"Reducing request to %d MSI-X vectors for LAN traffic.\\n\",\n\t\t\t   pf->num_lan_msix);\n\t\tif (ice_is_rdma_ena(pf))\n\t\t\tdev_notice(dev, \"Reducing request to %d MSI-X vectors for RDMA.\\n\",\n\t\t\t\t   pf->num_rdma_msix);\n\t}\n\n\t \n\tv_actual = pci_alloc_irq_vectors(pf->pdev, ICE_MIN_MSIX, v_wanted,\n\t\t\t\t\t PCI_IRQ_MSIX);\n\tif (v_actual < 0) {\n\t\tdev_err(dev, \"unable to reserve MSI-X vectors\\n\");\n\t\terr = v_actual;\n\t\tgoto exit_err;\n\t}\n\n\tif (v_actual < v_wanted) {\n\t\tdev_warn(dev, \"not enough OS MSI-X vectors. requested = %d, obtained = %d\\n\",\n\t\t\t v_wanted, v_actual);\n\n\t\tif (v_actual < ICE_MIN_MSIX) {\n\t\t\t \n\t\t\tpci_free_irq_vectors(pf->pdev);\n\t\t\terr = -ERANGE;\n\t\t\tgoto exit_err;\n\t\t} else {\n\t\t\tint v_remain = v_actual - v_other;\n\n\t\t\tif (v_remain < ICE_MIN_LAN_TXRX_MSIX)\n\t\t\t\tv_remain = ICE_MIN_LAN_TXRX_MSIX;\n\n\t\t\tice_reduce_msix_usage(pf, v_remain);\n\n\t\t\tdev_notice(dev, \"Enabled %d MSI-X vectors for LAN traffic.\\n\",\n\t\t\t\t   pf->num_lan_msix);\n\n\t\t\tif (ice_is_rdma_ena(pf))\n\t\t\t\tdev_notice(dev, \"Enabled %d MSI-X vectors for RDMA.\\n\",\n\t\t\t\t\t   pf->num_rdma_msix);\n\t\t}\n\t}\n\n\treturn v_actual;\n\nexit_err:\n\tpf->num_rdma_msix = 0;\n\tpf->num_lan_msix = 0;\n\treturn err;\n}\n\n \nvoid ice_clear_interrupt_scheme(struct ice_pf *pf)\n{\n\tpci_free_irq_vectors(pf->pdev);\n\tice_deinit_irq_tracker(pf);\n}\n\n \nint ice_init_interrupt_scheme(struct ice_pf *pf)\n{\n\tint total_vectors = pf->hw.func_caps.common_cap.num_msix_vectors;\n\tint vectors, max_vectors;\n\n\tvectors = ice_ena_msix_range(pf);\n\n\tif (vectors < 0)\n\t\treturn -ENOMEM;\n\n\tif (pci_msix_can_alloc_dyn(pf->pdev))\n\t\tmax_vectors = total_vectors;\n\telse\n\t\tmax_vectors = vectors;\n\n\tice_init_irq_tracker(pf, max_vectors, vectors);\n\n\treturn 0;\n}\n\n \nstruct msi_map ice_alloc_irq(struct ice_pf *pf, bool dyn_only)\n{\n\tint sriov_base_vector = pf->sriov_base_vector;\n\tstruct msi_map map = { .index = -ENOENT };\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tstruct ice_irq_entry *entry;\n\n\tentry = ice_get_irq_res(pf, dyn_only);\n\tif (!entry)\n\t\treturn map;\n\n\t \n\tif (sriov_base_vector && entry->index >= sriov_base_vector)\n\t\tgoto exit_free_res;\n\n\tif (pci_msix_can_alloc_dyn(pf->pdev) && entry->dynamic) {\n\t\tmap = pci_msix_alloc_irq_at(pf->pdev, entry->index, NULL);\n\t\tif (map.index < 0)\n\t\t\tgoto exit_free_res;\n\t\tdev_dbg(dev, \"allocated new irq at index %d\\n\", map.index);\n\t} else {\n\t\tmap.index = entry->index;\n\t\tmap.virq = pci_irq_vector(pf->pdev, map.index);\n\t}\n\n\treturn map;\n\nexit_free_res:\n\tdev_err(dev, \"Could not allocate irq at idx %d\\n\", entry->index);\n\tice_free_irq_res(pf, entry->index);\n\treturn map;\n}\n\n \nvoid ice_free_irq(struct ice_pf *pf, struct msi_map map)\n{\n\tstruct ice_irq_entry *entry;\n\n\tentry = xa_load(&pf->irq_tracker.entries, map.index);\n\n\tif (!entry) {\n\t\tdev_err(ice_pf_to_dev(pf), \"Failed to get MSIX interrupt entry at index %d\",\n\t\t\tmap.index);\n\t\treturn;\n\t}\n\n\tdev_dbg(ice_pf_to_dev(pf), \"Free irq at index %d\\n\", map.index);\n\n\tif (entry->dynamic)\n\t\tpci_msix_free_irq(pf->pdev, map);\n\n\tice_free_irq_res(pf, map.index);\n}\n\n \nint ice_get_max_used_msix_vector(struct ice_pf *pf)\n{\n\tunsigned long start, index, max_idx;\n\tvoid *entry;\n\n\t \n\tstart = pf->irq_tracker.num_static;\n\tmax_idx = start - 1;\n\n\txa_for_each_start(&pf->irq_tracker.entries, index, entry, start) {\n\t\tif (index > max_idx)\n\t\t\tmax_idx = index;\n\t}\n\n\treturn max_idx;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}