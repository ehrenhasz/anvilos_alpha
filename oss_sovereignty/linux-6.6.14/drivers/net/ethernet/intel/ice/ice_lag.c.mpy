{
  "module_name": "ice_lag.c",
  "hash_id": "b6defae9e728ffb57b30f7711b1024de7fe07ca6fe8ad1165c4f7160956de392",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_lag.c",
  "human_readable_source": "\n \n\n \n\n#include \"ice.h\"\n#include \"ice_lib.h\"\n#include \"ice_lag.h\"\n\n#define ICE_LAG_RES_SHARED\tBIT(14)\n#define ICE_LAG_RES_VALID\tBIT(15)\n\n#define LACP_TRAIN_PKT_LEN\t\t16\nstatic const u8 lacp_train_pkt[LACP_TRAIN_PKT_LEN] = { 0, 0, 0, 0, 0, 0,\n\t\t\t\t\t\t       0, 0, 0, 0, 0, 0,\n\t\t\t\t\t\t       0x88, 0x09, 0, 0 };\n\n#define ICE_RECIPE_LEN\t\t\t64\nstatic const u8 ice_dflt_vsi_rcp[ICE_RECIPE_LEN] = {\n\t0x05, 0, 0, 0, 0x20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\t0x85, 0, 0x01, 0, 0, 0, 0xff, 0xff, 0x08, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0x30, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n\n \nstatic void ice_lag_set_primary(struct ice_lag *lag)\n{\n\tstruct ice_pf *pf = lag->pf;\n\n\tif (!pf)\n\t\treturn;\n\n\tif (lag->role != ICE_LAG_UNSET && lag->role != ICE_LAG_BACKUP) {\n\t\tdev_warn(ice_pf_to_dev(pf), \"%s: Attempt to be Primary, but incompatible state.\\n\",\n\t\t\t netdev_name(lag->netdev));\n\t\treturn;\n\t}\n\n\tlag->role = ICE_LAG_PRIMARY;\n}\n\n \nstatic void ice_lag_set_backup(struct ice_lag *lag)\n{\n\tstruct ice_pf *pf = lag->pf;\n\n\tif (!pf)\n\t\treturn;\n\n\tif (lag->role != ICE_LAG_UNSET && lag->role != ICE_LAG_PRIMARY) {\n\t\tdev_dbg(ice_pf_to_dev(pf), \"%s: Attempt to be Backup, but incompatible state\\n\",\n\t\t\tnetdev_name(lag->netdev));\n\t\treturn;\n\t}\n\n\tlag->role = ICE_LAG_BACKUP;\n}\n\n \nstatic bool netif_is_same_ice(struct ice_pf *pf, struct net_device *netdev)\n{\n\tstruct ice_netdev_priv *np;\n\tstruct ice_pf *test_pf;\n\tstruct ice_vsi *vsi;\n\n\tif (!netif_is_ice(netdev))\n\t\treturn false;\n\n\tnp = netdev_priv(netdev);\n\tif (!np)\n\t\treturn false;\n\n\tvsi = np->vsi;\n\tif (!vsi)\n\t\treturn false;\n\n\ttest_pf = vsi->back;\n\tif (!test_pf)\n\t\treturn false;\n\n\tif (pf->pdev->bus != test_pf->pdev->bus ||\n\t    pf->pdev->slot != test_pf->pdev->slot)\n\t\treturn false;\n\n\treturn true;\n}\n\n \nstatic struct ice_lag *ice_netdev_to_lag(struct net_device *netdev)\n{\n\tstruct ice_netdev_priv *np;\n\tstruct ice_vsi *vsi;\n\n\tif (!netif_is_ice(netdev))\n\t\treturn NULL;\n\n\tnp = netdev_priv(netdev);\n\tif (!np)\n\t\treturn NULL;\n\n\tvsi = np->vsi;\n\tif (!vsi)\n\t\treturn NULL;\n\n\treturn vsi->back->lag;\n}\n\n \nstatic struct ice_hw *\nice_lag_find_hw_by_lport(struct ice_lag *lag, u8 lport)\n{\n\tstruct ice_lag_netdev_list *entry;\n\tstruct net_device *tmp_netdev;\n\tstruct ice_netdev_priv *np;\n\tstruct ice_hw *hw;\n\n\tlist_for_each_entry(entry, lag->netdev_head, node) {\n\t\ttmp_netdev = entry->netdev;\n\t\tif (!tmp_netdev || !netif_is_ice(tmp_netdev))\n\t\t\tcontinue;\n\n\t\tnp = netdev_priv(tmp_netdev);\n\t\tif (!np || !np->vsi)\n\t\t\tcontinue;\n\n\t\thw = &np->vsi->back->hw;\n\t\tif (hw->port_info->lport == lport)\n\t\t\treturn hw;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic struct ice_lag *ice_lag_find_primary(struct ice_lag *lag)\n{\n\tstruct ice_lag *primary_lag = NULL;\n\tstruct list_head *tmp;\n\n\tlist_for_each(tmp, lag->netdev_head) {\n\t\tstruct ice_lag_netdev_list *entry;\n\t\tstruct ice_lag *tmp_lag;\n\n\t\tentry = list_entry(tmp, struct ice_lag_netdev_list, node);\n\t\ttmp_lag = ice_netdev_to_lag(entry->netdev);\n\t\tif (tmp_lag && tmp_lag->primary) {\n\t\t\tprimary_lag = tmp_lag;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn primary_lag;\n}\n\n \nstatic int\nice_lag_cfg_dflt_fltr(struct ice_lag *lag, bool add)\n{\n\tstruct ice_sw_rule_lkup_rx_tx *s_rule;\n\tu16 s_rule_sz, vsi_num;\n\tstruct ice_hw *hw;\n\tu32 act, opc;\n\tu8 *eth_hdr;\n\tint err;\n\n\thw = &lag->pf->hw;\n\tvsi_num = ice_get_hw_vsi_num(hw, 0);\n\n\ts_rule_sz = ICE_SW_RULE_RX_TX_ETH_HDR_SIZE(s_rule);\n\ts_rule = kzalloc(s_rule_sz, GFP_KERNEL);\n\tif (!s_rule) {\n\t\tdev_err(ice_pf_to_dev(lag->pf), \"error allocating rule for LAG default VSI\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (add) {\n\t\teth_hdr = s_rule->hdr_data;\n\t\tice_fill_eth_hdr(eth_hdr);\n\n\t\tact = (vsi_num << ICE_SINGLE_ACT_VSI_ID_S) &\n\t\t\tICE_SINGLE_ACT_VSI_ID_M;\n\t\tact |= ICE_SINGLE_ACT_VSI_FORWARDING |\n\t\t\tICE_SINGLE_ACT_VALID_BIT | ICE_SINGLE_ACT_LAN_ENABLE;\n\n\t\ts_rule->hdr.type = cpu_to_le16(ICE_AQC_SW_RULES_T_LKUP_RX);\n\t\ts_rule->recipe_id = cpu_to_le16(lag->pf_recipe);\n\t\ts_rule->src = cpu_to_le16(hw->port_info->lport);\n\t\ts_rule->act = cpu_to_le32(act);\n\t\ts_rule->hdr_len = cpu_to_le16(DUMMY_ETH_HDR_LEN);\n\t\topc = ice_aqc_opc_add_sw_rules;\n\t} else {\n\t\ts_rule->index = cpu_to_le16(lag->pf_rule_id);\n\t\topc = ice_aqc_opc_remove_sw_rules;\n\t}\n\n\terr = ice_aq_sw_rules(&lag->pf->hw, s_rule, s_rule_sz, 1, opc, NULL);\n\tif (err)\n\t\tgoto dflt_fltr_free;\n\n\tif (add)\n\t\tlag->pf_rule_id = le16_to_cpu(s_rule->index);\n\telse\n\t\tlag->pf_rule_id = 0;\n\ndflt_fltr_free:\n\tkfree(s_rule);\n\treturn err;\n}\n\n \nstatic void\nice_lag_cfg_pf_fltrs(struct ice_lag *lag, void *ptr)\n{\n\tstruct netdev_notifier_bonding_info *info;\n\tstruct netdev_bonding_info *bonding_info;\n\tstruct net_device *event_netdev;\n\tstruct device *dev;\n\n\tevent_netdev = netdev_notifier_info_to_dev(ptr);\n\t \n\tif (event_netdev != lag->netdev)\n\t\treturn;\n\n\tinfo = (struct netdev_notifier_bonding_info *)ptr;\n\tbonding_info = &info->bonding_info;\n\tdev = ice_pf_to_dev(lag->pf);\n\n\t \n\tif (bonding_info->slave.state && lag->pf_rule_id) {\n\t\tif (ice_lag_cfg_dflt_fltr(lag, false))\n\t\t\tdev_err(dev, \"Error removing old default VSI filter\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (!bonding_info->slave.state && !lag->pf_rule_id)\n\t\tif (ice_lag_cfg_dflt_fltr(lag, true))\n\t\t\tdev_err(dev, \"Error adding new default VSI filter\\n\");\n}\n\n \nstatic void ice_display_lag_info(struct ice_lag *lag)\n{\n\tconst char *name, *upper, *role, *bonded, *primary;\n\tstruct device *dev = &lag->pf->pdev->dev;\n\n\tname = lag->netdev ? netdev_name(lag->netdev) : \"unset\";\n\tupper = lag->upper_netdev ? netdev_name(lag->upper_netdev) : \"unset\";\n\tprimary = lag->primary ? \"TRUE\" : \"FALSE\";\n\tbonded = lag->bonded ? \"BONDED\" : \"UNBONDED\";\n\n\tswitch (lag->role) {\n\tcase ICE_LAG_NONE:\n\t\trole = \"NONE\";\n\t\tbreak;\n\tcase ICE_LAG_PRIMARY:\n\t\trole = \"PRIMARY\";\n\t\tbreak;\n\tcase ICE_LAG_BACKUP:\n\t\trole = \"BACKUP\";\n\t\tbreak;\n\tcase ICE_LAG_UNSET:\n\t\trole = \"UNSET\";\n\t\tbreak;\n\tdefault:\n\t\trole = \"ERROR\";\n\t}\n\n\tdev_dbg(dev, \"%s %s, upper:%s, role:%s, primary:%s\\n\", name, bonded,\n\t\tupper, role, primary);\n}\n\n \nstatic u16\nice_lag_qbuf_recfg(struct ice_hw *hw, struct ice_aqc_cfg_txqs_buf *qbuf,\n\t\t   u16 vsi_num, u16 numq, u8 tc)\n{\n\tstruct ice_q_ctx *q_ctx;\n\tu16 qid, count = 0;\n\tstruct ice_pf *pf;\n\tint i;\n\n\tpf = hw->back;\n\tfor (i = 0; i < numq; i++) {\n\t\tq_ctx = ice_get_lan_q_ctx(hw, vsi_num, tc, i);\n\t\tif (!q_ctx) {\n\t\t\tdev_dbg(ice_hw_to_dev(hw), \"%s queue %d NO Q CONTEXT\\n\",\n\t\t\t\t__func__, i);\n\t\t\tcontinue;\n\t\t}\n\t\tif (q_ctx->q_teid == ICE_INVAL_TEID) {\n\t\t\tdev_dbg(ice_hw_to_dev(hw), \"%s queue %d INVAL TEID\\n\",\n\t\t\t\t__func__, i);\n\t\t\tcontinue;\n\t\t}\n\t\tif (q_ctx->q_handle == ICE_INVAL_Q_HANDLE) {\n\t\t\tdev_dbg(ice_hw_to_dev(hw), \"%s queue %d INVAL Q HANDLE\\n\",\n\t\t\t\t__func__, i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tqid = pf->vsi[vsi_num]->txq_map[q_ctx->q_handle];\n\t\tqbuf->queue_info[count].q_handle = cpu_to_le16(qid);\n\t\tqbuf->queue_info[count].tc = tc;\n\t\tqbuf->queue_info[count].q_teid = cpu_to_le32(q_ctx->q_teid);\n\t\tcount++;\n\t}\n\n\treturn count;\n}\n\n \nstatic struct ice_sched_node *\nice_lag_get_sched_parent(struct ice_hw *hw, u8 tc)\n{\n\tstruct ice_sched_node *tc_node, *aggnode, *parent = NULL;\n\tu16 num_nodes[ICE_AQC_TOPO_MAX_LEVEL_NUM] = { 0 };\n\tstruct ice_port_info *pi = hw->port_info;\n\tstruct device *dev;\n\tu8 aggl, vsil;\n\tint n;\n\n\tdev = ice_hw_to_dev(hw);\n\n\ttc_node = ice_sched_get_tc_node(pi, tc);\n\tif (!tc_node) {\n\t\tdev_warn(dev, \"Failure to find TC node for LAG move\\n\");\n\t\treturn parent;\n\t}\n\n\taggnode = ice_sched_get_agg_node(pi, tc_node, ICE_DFLT_AGG_ID);\n\tif (!aggnode) {\n\t\tdev_warn(dev, \"Failure to find aggregate node for LAG move\\n\");\n\t\treturn parent;\n\t}\n\n\taggl = ice_sched_get_agg_layer(hw);\n\tvsil = ice_sched_get_vsi_layer(hw);\n\n\tfor (n = aggl + 1; n < vsil; n++)\n\t\tnum_nodes[n] = 1;\n\n\tfor (n = 0; n < aggnode->num_children; n++) {\n\t\tparent = ice_sched_get_free_vsi_parent(hw, aggnode->children[n],\n\t\t\t\t\t\t       num_nodes);\n\t\tif (parent)\n\t\t\treturn parent;\n\t}\n\n\t \n\tparent = aggnode;\n\tfor (n = aggl + 1; n < vsil; n++) {\n\t\tu16 num_nodes_added;\n\t\tu32 first_teid;\n\t\tint err;\n\n\t\terr = ice_sched_add_nodes_to_layer(pi, tc_node, parent, n,\n\t\t\t\t\t\t   num_nodes[n], &first_teid,\n\t\t\t\t\t\t   &num_nodes_added);\n\t\tif (err || num_nodes[n] != num_nodes_added)\n\t\t\treturn NULL;\n\n\t\tif (num_nodes_added)\n\t\t\tparent = ice_sched_find_node_by_teid(tc_node,\n\t\t\t\t\t\t\t     first_teid);\n\t\telse\n\t\t\tparent = parent->children[0];\n\t\tif (!parent) {\n\t\t\tdev_warn(dev, \"Failure to add new parent for LAG move\\n\");\n\t\t\treturn parent;\n\t\t}\n\t}\n\n\treturn parent;\n}\n\n \nstatic void\nice_lag_move_vf_node_tc(struct ice_lag *lag, u8 oldport, u8 newport,\n\t\t\tu16 vsi_num, u8 tc)\n{\n\tu16 numq, valq, buf_size, num_moved, qbuf_size;\n\tstruct device *dev = ice_pf_to_dev(lag->pf);\n\tstruct ice_aqc_cfg_txqs_buf *qbuf;\n\tstruct ice_aqc_move_elem *buf;\n\tstruct ice_sched_node *n_prt;\n\tstruct ice_hw *new_hw = NULL;\n\t__le32 teid, parent_teid;\n\tstruct ice_vsi_ctx *ctx;\n\tu32 tmp_teid;\n\n\tctx = ice_get_vsi_ctx(&lag->pf->hw, vsi_num);\n\tif (!ctx) {\n\t\tdev_warn(dev, \"Unable to locate VSI context for LAG failover\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (!ctx->sched.vsi_node[tc])\n\t\treturn;\n\n\t \n\tnew_hw = ice_lag_find_hw_by_lport(lag, newport);\n\tif (!new_hw) {\n\t\tdev_warn(dev, \"Unable to locate HW struct for LAG node destination\\n\");\n\t\treturn;\n\t}\n\n\tnumq = ctx->num_lan_q_entries[tc];\n\tteid = ctx->sched.vsi_node[tc]->info.node_teid;\n\ttmp_teid = le32_to_cpu(teid);\n\tparent_teid = ctx->sched.vsi_node[tc]->info.parent_teid;\n\t \n\tif (!tmp_teid || !numq)\n\t\treturn;\n\n\t \n\tif (ice_sched_suspend_resume_elems(&lag->pf->hw, 1, &tmp_teid, true))\n\t\tdev_dbg(dev, \"Problem suspending traffic for LAG node move\\n\");\n\n\t \n\tqbuf_size = struct_size(qbuf, queue_info, numq);\n\tqbuf = kzalloc(qbuf_size, GFP_KERNEL);\n\tif (!qbuf) {\n\t\tdev_warn(dev, \"Failure allocating memory for VF queue recfg buffer\\n\");\n\t\tgoto resume_traffic;\n\t}\n\n\t \n\tvalq = ice_lag_qbuf_recfg(&lag->pf->hw, qbuf, vsi_num, numq, tc);\n\tif (!valq) {\n\t\tdev_dbg(dev, \"No valid queues found for LAG failover\\n\");\n\t\tgoto qbuf_none;\n\t}\n\n\tif (ice_aq_cfg_lan_txq(&lag->pf->hw, qbuf, qbuf_size, valq, oldport,\n\t\t\t       newport, NULL)) {\n\t\tdev_warn(dev, \"Failure to configure queues for LAG failover\\n\");\n\t\tgoto qbuf_err;\n\t}\n\nqbuf_none:\n\tkfree(qbuf);\n\n\t \n\tn_prt = ice_lag_get_sched_parent(new_hw, tc);\n\tif (!n_prt)\n\t\tgoto resume_traffic;\n\n\t \n\tbuf_size = struct_size(buf, teid, 1);\n\tbuf = kzalloc(buf_size, GFP_KERNEL);\n\tif (!buf) {\n\t\tdev_warn(dev, \"Failure to alloc memory for VF node failover\\n\");\n\t\tgoto resume_traffic;\n\t}\n\n\tbuf->hdr.src_parent_teid = parent_teid;\n\tbuf->hdr.dest_parent_teid = n_prt->info.node_teid;\n\tbuf->hdr.num_elems = cpu_to_le16(1);\n\tbuf->hdr.mode = ICE_AQC_MOVE_ELEM_MODE_KEEP_OWN;\n\tbuf->teid[0] = teid;\n\n\tif (ice_aq_move_sched_elems(&lag->pf->hw, 1, buf, buf_size, &num_moved,\n\t\t\t\t    NULL))\n\t\tdev_warn(dev, \"Failure to move VF nodes for failover\\n\");\n\telse\n\t\tice_sched_update_parent(n_prt, ctx->sched.vsi_node[tc]);\n\n\tkfree(buf);\n\tgoto resume_traffic;\n\nqbuf_err:\n\tkfree(qbuf);\n\nresume_traffic:\n\t \n\tif (ice_sched_suspend_resume_elems(&lag->pf->hw, 1, &tmp_teid, false))\n\t\tdev_dbg(dev, \"Problem restarting traffic for LAG node move\\n\");\n}\n\n \nstatic void ice_lag_build_netdev_list(struct ice_lag *lag,\n\t\t\t\t      struct ice_lag_netdev_list *ndlist)\n{\n\tstruct ice_lag_netdev_list *nl;\n\tstruct net_device *tmp_nd;\n\n\tINIT_LIST_HEAD(&ndlist->node);\n\trcu_read_lock();\n\tfor_each_netdev_in_bond_rcu(lag->upper_netdev, tmp_nd) {\n\t\tnl = kzalloc(sizeof(*nl), GFP_ATOMIC);\n\t\tif (!nl)\n\t\t\tbreak;\n\n\t\tnl->netdev = tmp_nd;\n\t\tlist_add(&nl->node, &ndlist->node);\n\t}\n\trcu_read_unlock();\n\tlag->netdev_head = &ndlist->node;\n}\n\n \nstatic void ice_lag_destroy_netdev_list(struct ice_lag *lag,\n\t\t\t\t\tstruct ice_lag_netdev_list *ndlist)\n{\n\tstruct ice_lag_netdev_list *entry, *n;\n\n\trcu_read_lock();\n\tlist_for_each_entry_safe(entry, n, &ndlist->node, node) {\n\t\tlist_del(&entry->node);\n\t\tkfree(entry);\n\t}\n\trcu_read_unlock();\n\tlag->netdev_head = NULL;\n}\n\n \nstatic void\nice_lag_move_single_vf_nodes(struct ice_lag *lag, u8 oldport, u8 newport,\n\t\t\t     u16 vsi_num)\n{\n\tu8 tc;\n\n\tice_for_each_traffic_class(tc)\n\t\tice_lag_move_vf_node_tc(lag, oldport, newport, vsi_num, tc);\n}\n\n \nvoid ice_lag_move_new_vf_nodes(struct ice_vf *vf)\n{\n\tstruct ice_lag_netdev_list ndlist;\n\tu8 pri_port, act_port;\n\tstruct ice_lag *lag;\n\tstruct ice_vsi *vsi;\n\tstruct ice_pf *pf;\n\n\tvsi = ice_get_vf_vsi(vf);\n\n\tif (WARN_ON(!vsi))\n\t\treturn;\n\n\tif (WARN_ON(vsi->type != ICE_VSI_VF))\n\t\treturn;\n\n\tpf = vf->pf;\n\tlag = pf->lag;\n\n\tmutex_lock(&pf->lag_mutex);\n\tif (!lag->bonded)\n\t\tgoto new_vf_unlock;\n\n\tpri_port = pf->hw.port_info->lport;\n\tact_port = lag->active_port;\n\n\tif (lag->upper_netdev)\n\t\tice_lag_build_netdev_list(lag, &ndlist);\n\n\tif (ice_is_feature_supported(pf, ICE_F_SRIOV_LAG) &&\n\t    lag->bonded && lag->primary && pri_port != act_port &&\n\t    !list_empty(lag->netdev_head))\n\t\tice_lag_move_single_vf_nodes(lag, pri_port, act_port, vsi->idx);\n\n\tice_lag_destroy_netdev_list(lag, &ndlist);\n\nnew_vf_unlock:\n\tmutex_unlock(&pf->lag_mutex);\n}\n\n \nstatic void ice_lag_move_vf_nodes(struct ice_lag *lag, u8 oldport, u8 newport)\n{\n\tstruct ice_pf *pf;\n\tint i;\n\n\tif (!lag->primary)\n\t\treturn;\n\n\tpf = lag->pf;\n\tice_for_each_vsi(pf, i)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->type == ICE_VSI_VF ||\n\t\t\t\t   pf->vsi[i]->type == ICE_VSI_SWITCHDEV_CTRL))\n\t\t\tice_lag_move_single_vf_nodes(lag, oldport, newport, i);\n}\n\n \nvoid ice_lag_move_vf_nodes_cfg(struct ice_lag *lag, u8 src_prt, u8 dst_prt)\n{\n\tstruct ice_lag_netdev_list ndlist;\n\n\tice_lag_build_netdev_list(lag, &ndlist);\n\tice_lag_move_vf_nodes(lag, src_prt, dst_prt);\n\tice_lag_destroy_netdev_list(lag, &ndlist);\n}\n\n#define ICE_LAG_SRIOV_CP_RECIPE\t\t10\n#define ICE_LAG_SRIOV_TRAIN_PKT_LEN\t16\n\n \nstatic void\nice_lag_cfg_cp_fltr(struct ice_lag *lag, bool add)\n{\n\tstruct ice_sw_rule_lkup_rx_tx *s_rule = NULL;\n\tstruct ice_vsi *vsi;\n\tu16 buf_len, opc;\n\n\tvsi = lag->pf->vsi[0];\n\n\tbuf_len = ICE_SW_RULE_RX_TX_HDR_SIZE(s_rule,\n\t\t\t\t\t     ICE_LAG_SRIOV_TRAIN_PKT_LEN);\n\ts_rule = kzalloc(buf_len, GFP_KERNEL);\n\tif (!s_rule) {\n\t\tnetdev_warn(lag->netdev, \"-ENOMEM error configuring CP filter\\n\");\n\t\treturn;\n\t}\n\n\tif (add) {\n\t\ts_rule->hdr.type = cpu_to_le16(ICE_AQC_SW_RULES_T_LKUP_RX);\n\t\ts_rule->recipe_id = cpu_to_le16(ICE_LAG_SRIOV_CP_RECIPE);\n\t\ts_rule->src = cpu_to_le16(vsi->port_info->lport);\n\t\ts_rule->act = cpu_to_le32(ICE_FWD_TO_VSI |\n\t\t\t\t\t  ICE_SINGLE_ACT_LAN_ENABLE |\n\t\t\t\t\t  ICE_SINGLE_ACT_VALID_BIT |\n\t\t\t\t\t  ((vsi->vsi_num <<\n\t\t\t\t\t    ICE_SINGLE_ACT_VSI_ID_S) &\n\t\t\t\t\t   ICE_SINGLE_ACT_VSI_ID_M));\n\t\ts_rule->hdr_len = cpu_to_le16(ICE_LAG_SRIOV_TRAIN_PKT_LEN);\n\t\tmemcpy(s_rule->hdr_data, lacp_train_pkt, LACP_TRAIN_PKT_LEN);\n\t\topc = ice_aqc_opc_add_sw_rules;\n\t} else {\n\t\topc = ice_aqc_opc_remove_sw_rules;\n\t\ts_rule->index = cpu_to_le16(lag->cp_rule_idx);\n\t}\n\tif (ice_aq_sw_rules(&lag->pf->hw, s_rule, buf_len, 1, opc, NULL)) {\n\t\tnetdev_warn(lag->netdev, \"Error %s CP rule for fail-over\\n\",\n\t\t\t    add ? \"ADDING\" : \"REMOVING\");\n\t\tgoto cp_free;\n\t}\n\n\tif (add)\n\t\tlag->cp_rule_idx = le16_to_cpu(s_rule->index);\n\telse\n\t\tlag->cp_rule_idx = 0;\n\ncp_free:\n\tkfree(s_rule);\n}\n\n \nstatic void ice_lag_info_event(struct ice_lag *lag, void *ptr)\n{\n\tstruct netdev_notifier_bonding_info *info;\n\tstruct netdev_bonding_info *bonding_info;\n\tstruct net_device *event_netdev;\n\tconst char *lag_netdev_name;\n\n\tevent_netdev = netdev_notifier_info_to_dev(ptr);\n\tinfo = ptr;\n\tlag_netdev_name = netdev_name(lag->netdev);\n\tbonding_info = &info->bonding_info;\n\n\tif (event_netdev != lag->netdev || !lag->bonded || !lag->upper_netdev)\n\t\treturn;\n\n\tif (bonding_info->master.bond_mode != BOND_MODE_ACTIVEBACKUP) {\n\t\tnetdev_dbg(lag->netdev, \"Bonding event recv, but mode not active/backup\\n\");\n\t\tgoto lag_out;\n\t}\n\n\tif (strcmp(bonding_info->slave.slave_name, lag_netdev_name)) {\n\t\tnetdev_dbg(lag->netdev, \"Bonding event recv, but secondary info not for us\\n\");\n\t\tgoto lag_out;\n\t}\n\n\tif (bonding_info->slave.state)\n\t\tice_lag_set_backup(lag);\n\telse\n\t\tice_lag_set_primary(lag);\n\nlag_out:\n\tice_display_lag_info(lag);\n}\n\n \nstatic void\nice_lag_reclaim_vf_tc(struct ice_lag *lag, struct ice_hw *src_hw, u16 vsi_num,\n\t\t      u8 tc)\n{\n\tu16 numq, valq, buf_size, num_moved, qbuf_size;\n\tstruct device *dev = ice_pf_to_dev(lag->pf);\n\tstruct ice_aqc_cfg_txqs_buf *qbuf;\n\tstruct ice_aqc_move_elem *buf;\n\tstruct ice_sched_node *n_prt;\n\t__le32 teid, parent_teid;\n\tstruct ice_vsi_ctx *ctx;\n\tstruct ice_hw *hw;\n\tu32 tmp_teid;\n\n\thw = &lag->pf->hw;\n\tctx = ice_get_vsi_ctx(hw, vsi_num);\n\tif (!ctx) {\n\t\tdev_warn(dev, \"Unable to locate VSI context for LAG reclaim\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (!ctx->sched.vsi_node[tc])\n\t\treturn;\n\n\tnumq = ctx->num_lan_q_entries[tc];\n\tteid = ctx->sched.vsi_node[tc]->info.node_teid;\n\ttmp_teid = le32_to_cpu(teid);\n\tparent_teid = ctx->sched.vsi_node[tc]->info.parent_teid;\n\n\t \n\tif (!tmp_teid || !numq)\n\t\treturn;\n\n\t \n\tif (ice_sched_suspend_resume_elems(hw, 1, &tmp_teid, true))\n\t\tdev_dbg(dev, \"Problem suspending traffic for LAG node move\\n\");\n\n\t \n\tqbuf_size = struct_size(qbuf, queue_info, numq);\n\tqbuf = kzalloc(qbuf_size, GFP_KERNEL);\n\tif (!qbuf) {\n\t\tdev_warn(dev, \"Failure allocating memory for VF queue recfg buffer\\n\");\n\t\tgoto resume_reclaim;\n\t}\n\n\t \n\tvalq = ice_lag_qbuf_recfg(hw, qbuf, vsi_num, numq, tc);\n\tif (!valq) {\n\t\tdev_dbg(dev, \"No valid queues found for LAG reclaim\\n\");\n\t\tgoto reclaim_none;\n\t}\n\n\tif (ice_aq_cfg_lan_txq(hw, qbuf, qbuf_size, numq,\n\t\t\t       src_hw->port_info->lport, hw->port_info->lport,\n\t\t\t       NULL)) {\n\t\tdev_warn(dev, \"Failure to configure queues for LAG failover\\n\");\n\t\tgoto reclaim_qerr;\n\t}\n\nreclaim_none:\n\tkfree(qbuf);\n\n\t \n\tn_prt = ice_lag_get_sched_parent(hw, tc);\n\tif (!n_prt)\n\t\tgoto resume_reclaim;\n\n\t \n\tbuf_size = struct_size(buf, teid, 1);\n\tbuf = kzalloc(buf_size, GFP_KERNEL);\n\tif (!buf) {\n\t\tdev_warn(dev, \"Failure to alloc memory for VF node failover\\n\");\n\t\tgoto resume_reclaim;\n\t}\n\n\tbuf->hdr.src_parent_teid = parent_teid;\n\tbuf->hdr.dest_parent_teid = n_prt->info.node_teid;\n\tbuf->hdr.num_elems = cpu_to_le16(1);\n\tbuf->hdr.mode = ICE_AQC_MOVE_ELEM_MODE_KEEP_OWN;\n\tbuf->teid[0] = teid;\n\n\tif (ice_aq_move_sched_elems(&lag->pf->hw, 1, buf, buf_size, &num_moved,\n\t\t\t\t    NULL))\n\t\tdev_warn(dev, \"Failure to move VF nodes for LAG reclaim\\n\");\n\telse\n\t\tice_sched_update_parent(n_prt, ctx->sched.vsi_node[tc]);\n\n\tkfree(buf);\n\tgoto resume_reclaim;\n\nreclaim_qerr:\n\tkfree(qbuf);\n\nresume_reclaim:\n\t \n\tif (ice_sched_suspend_resume_elems(hw, 1, &tmp_teid, false))\n\t\tdev_warn(dev, \"Problem restarting traffic for LAG node reclaim\\n\");\n}\n\n \nstatic void\nice_lag_reclaim_vf_nodes(struct ice_lag *lag, struct ice_hw *src_hw)\n{\n\tstruct ice_pf *pf;\n\tint i, tc;\n\n\tif (!lag->primary || !src_hw)\n\t\treturn;\n\n\tpf = lag->pf;\n\tice_for_each_vsi(pf, i)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->type == ICE_VSI_VF ||\n\t\t\t\t   pf->vsi[i]->type == ICE_VSI_SWITCHDEV_CTRL))\n\t\t\tice_for_each_traffic_class(tc)\n\t\t\t\tice_lag_reclaim_vf_tc(lag, src_hw, i, tc);\n}\n\n \nstatic void ice_lag_link(struct ice_lag *lag)\n{\n\tstruct ice_pf *pf = lag->pf;\n\n\tif (lag->bonded)\n\t\tdev_warn(ice_pf_to_dev(pf), \"%s Already part of a bond\\n\",\n\t\t\t netdev_name(lag->netdev));\n\n\tlag->bonded = true;\n\tlag->role = ICE_LAG_UNSET;\n\tnetdev_info(lag->netdev, \"Shared SR-IOV resources in bond are active\\n\");\n}\n\n \nstatic void ice_lag_unlink(struct ice_lag *lag)\n{\n\tu8 pri_port, act_port, loc_port;\n\tstruct ice_pf *pf = lag->pf;\n\n\tif (!lag->bonded) {\n\t\tnetdev_dbg(lag->netdev, \"bonding unlink event on non-LAG netdev\\n\");\n\t\treturn;\n\t}\n\n\tif (lag->primary) {\n\t\tact_port = lag->active_port;\n\t\tpri_port = lag->pf->hw.port_info->lport;\n\t\tif (act_port != pri_port && act_port != ICE_LAG_INVALID_PORT)\n\t\t\tice_lag_move_vf_nodes(lag, act_port, pri_port);\n\t\tlag->primary = false;\n\t\tlag->active_port = ICE_LAG_INVALID_PORT;\n\t} else {\n\t\tstruct ice_lag *primary_lag;\n\n\t\tprimary_lag = ice_lag_find_primary(lag);\n\t\tif (primary_lag) {\n\t\t\tact_port = primary_lag->active_port;\n\t\t\tpri_port = primary_lag->pf->hw.port_info->lport;\n\t\t\tloc_port = pf->hw.port_info->lport;\n\t\t\tif (act_port == loc_port &&\n\t\t\t    act_port != ICE_LAG_INVALID_PORT) {\n\t\t\t\tice_lag_reclaim_vf_nodes(primary_lag,\n\t\t\t\t\t\t\t &lag->pf->hw);\n\t\t\t\tprimary_lag->active_port = ICE_LAG_INVALID_PORT;\n\t\t\t}\n\t\t}\n\t}\n\n\tlag->bonded = false;\n\tlag->role = ICE_LAG_NONE;\n\tlag->upper_netdev = NULL;\n}\n\n \nstatic void ice_lag_link_unlink(struct ice_lag *lag, void *ptr)\n{\n\tstruct net_device *netdev = netdev_notifier_info_to_dev(ptr);\n\tstruct netdev_notifier_changeupper_info *info = ptr;\n\n\tif (netdev != lag->netdev)\n\t\treturn;\n\n\tif (info->linking)\n\t\tice_lag_link(lag);\n\telse\n\t\tice_lag_unlink(lag);\n}\n\n \nstatic void\nice_lag_set_swid(u16 primary_swid, struct ice_lag *local_lag,\n\t\t bool link)\n{\n\tstruct ice_aqc_alloc_free_res_elem *buf;\n\tstruct ice_aqc_set_port_params *cmd;\n\tstruct ice_aq_desc desc;\n\tu16 buf_len, swid;\n\tint status, i;\n\n\tbuf_len = struct_size(buf, elem, 1);\n\tbuf = kzalloc(buf_len, GFP_KERNEL);\n\tif (!buf) {\n\t\tdev_err(ice_pf_to_dev(local_lag->pf), \"-ENOMEM error setting SWID\\n\");\n\t\treturn;\n\t}\n\n\tbuf->num_elems = cpu_to_le16(1);\n\tbuf->res_type = cpu_to_le16(ICE_AQC_RES_TYPE_SWID);\n\t \n\tif (!link && local_lag->bond_swid) {\n\t\tbuf->elem[0].e.sw_resp = cpu_to_le16(local_lag->bond_swid);\n\t\tstatus = ice_aq_alloc_free_res(&local_lag->pf->hw, buf,\n\t\t\t\t\t       buf_len, ice_aqc_opc_free_res);\n\t\tif (status)\n\t\t\tdev_err(ice_pf_to_dev(local_lag->pf), \"Error freeing SWID during LAG unlink\\n\");\n\t\tlocal_lag->bond_swid = 0;\n\t}\n\n\tif (link) {\n\t\tbuf->res_type |=  cpu_to_le16(ICE_LAG_RES_SHARED |\n\t\t\t\t\t      ICE_LAG_RES_VALID);\n\t\t \n\t\tlocal_lag->bond_swid = primary_swid;\n\t\tbuf->elem[0].e.sw_resp = cpu_to_le16(local_lag->bond_swid);\n\t} else {\n\t\tbuf->elem[0].e.sw_resp =\n\t\t\tcpu_to_le16(local_lag->pf->hw.port_info->sw_id);\n\t}\n\n\tstatus = ice_aq_alloc_free_res(&local_lag->pf->hw, buf, buf_len,\n\t\t\t\t       ice_aqc_opc_alloc_res);\n\tif (status)\n\t\tdev_err(ice_pf_to_dev(local_lag->pf), \"Error subscribing to SWID 0x%04X\\n\",\n\t\t\tlocal_lag->bond_swid);\n\n\tkfree(buf);\n\n\t \n\tif (link)\n\t\tswid = primary_swid;\n\telse\n\t\tswid = local_lag->pf->hw.port_info->sw_id;\n\n\tcmd = &desc.params.set_port_params;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_set_port_params);\n\n\tcmd->swid = cpu_to_le16(ICE_AQC_PORT_SWID_VALID | swid);\n\t \n\tfor (i = 0; i < ICE_LAG_RESET_RETRIES; i++) {\n\t\tstatus = ice_aq_send_cmd(&local_lag->pf->hw, &desc, NULL, 0,\n\t\t\t\t\t NULL);\n\t\tif (!status)\n\t\t\tbreak;\n\n\t\tusleep_range(1000, 2000);\n\t}\n\n\tif (status)\n\t\tdev_err(ice_pf_to_dev(local_lag->pf), \"Error setting SWID in port params %d\\n\",\n\t\t\tstatus);\n}\n\n \nstatic void ice_lag_primary_swid(struct ice_lag *lag, bool link)\n{\n\tstruct ice_hw *hw;\n\tu16 swid;\n\n\thw = &lag->pf->hw;\n\tswid = hw->port_info->sw_id;\n\n\tif (ice_share_res(hw, ICE_AQC_RES_TYPE_SWID, link, swid))\n\t\tdev_warn(ice_pf_to_dev(lag->pf), \"Failure to set primary interface shared status\\n\");\n}\n\n \nstatic void ice_lag_add_prune_list(struct ice_lag *lag, struct ice_pf *event_pf)\n{\n\tu16 num_vsi, rule_buf_sz, vsi_list_id, event_vsi_num, prim_vsi_idx;\n\tstruct ice_sw_rule_vsi_list *s_rule = NULL;\n\tstruct device *dev;\n\n\tnum_vsi = 1;\n\n\tdev = ice_pf_to_dev(lag->pf);\n\tevent_vsi_num = event_pf->vsi[0]->vsi_num;\n\tprim_vsi_idx = lag->pf->vsi[0]->idx;\n\n\tif (!ice_find_vsi_list_entry(&lag->pf->hw, ICE_SW_LKUP_VLAN,\n\t\t\t\t     prim_vsi_idx, &vsi_list_id)) {\n\t\tdev_warn(dev, \"Could not locate prune list when setting up SRIOV LAG\\n\");\n\t\treturn;\n\t}\n\n\trule_buf_sz = (u16)ICE_SW_RULE_VSI_LIST_SIZE(s_rule, num_vsi);\n\ts_rule = kzalloc(rule_buf_sz, GFP_KERNEL);\n\tif (!s_rule) {\n\t\tdev_warn(dev, \"Error allocating space for prune list when configuring SRIOV LAG\\n\");\n\t\treturn;\n\t}\n\n\ts_rule->hdr.type = cpu_to_le16(ICE_AQC_SW_RULES_T_PRUNE_LIST_SET);\n\ts_rule->index = cpu_to_le16(vsi_list_id);\n\ts_rule->number_vsi = cpu_to_le16(num_vsi);\n\ts_rule->vsi[0] = cpu_to_le16(event_vsi_num);\n\n\tif (ice_aq_sw_rules(&event_pf->hw, s_rule, rule_buf_sz, 1,\n\t\t\t    ice_aqc_opc_update_sw_rules, NULL))\n\t\tdev_warn(dev, \"Error adding VSI prune list\\n\");\n\tkfree(s_rule);\n}\n\n \nstatic void ice_lag_del_prune_list(struct ice_lag *lag, struct ice_pf *event_pf)\n{\n\tu16 num_vsi, vsi_num, vsi_idx, rule_buf_sz, vsi_list_id;\n\tstruct ice_sw_rule_vsi_list *s_rule = NULL;\n\tstruct device *dev;\n\n\tnum_vsi = 1;\n\n\tdev = ice_pf_to_dev(lag->pf);\n\tvsi_num = event_pf->vsi[0]->vsi_num;\n\tvsi_idx = lag->pf->vsi[0]->idx;\n\n\tif (!ice_find_vsi_list_entry(&lag->pf->hw, ICE_SW_LKUP_VLAN,\n\t\t\t\t     vsi_idx, &vsi_list_id)) {\n\t\tdev_warn(dev, \"Could not locate prune list when unwinding SRIOV LAG\\n\");\n\t\treturn;\n\t}\n\n\trule_buf_sz = (u16)ICE_SW_RULE_VSI_LIST_SIZE(s_rule, num_vsi);\n\ts_rule = kzalloc(rule_buf_sz, GFP_KERNEL);\n\tif (!s_rule) {\n\t\tdev_warn(dev, \"Error allocating prune list when unwinding SRIOV LAG\\n\");\n\t\treturn;\n\t}\n\n\ts_rule->hdr.type = cpu_to_le16(ICE_AQC_SW_RULES_T_PRUNE_LIST_CLEAR);\n\ts_rule->index = cpu_to_le16(vsi_list_id);\n\ts_rule->number_vsi = cpu_to_le16(num_vsi);\n\ts_rule->vsi[0] = cpu_to_le16(vsi_num);\n\n\tif (ice_aq_sw_rules(&event_pf->hw, (struct ice_aqc_sw_rules *)s_rule,\n\t\t\t    rule_buf_sz, 1, ice_aqc_opc_update_sw_rules, NULL))\n\t\tdev_warn(dev, \"Error clearing VSI prune list\\n\");\n\n\tkfree(s_rule);\n}\n\n \nstatic void ice_lag_init_feature_support_flag(struct ice_pf *pf)\n{\n\tstruct ice_hw_common_caps *caps;\n\n\tcaps = &pf->hw.dev_caps.common_cap;\n\tif (caps->roce_lag)\n\t\tice_set_feature_support(pf, ICE_F_ROCE_LAG);\n\telse\n\t\tice_clear_feature_support(pf, ICE_F_ROCE_LAG);\n\n\tif (caps->sriov_lag)\n\t\tice_set_feature_support(pf, ICE_F_SRIOV_LAG);\n\telse\n\t\tice_clear_feature_support(pf, ICE_F_SRIOV_LAG);\n}\n\n \nstatic void ice_lag_changeupper_event(struct ice_lag *lag, void *ptr)\n{\n\tstruct netdev_notifier_changeupper_info *info;\n\tstruct ice_lag *primary_lag;\n\tstruct net_device *netdev;\n\n\tinfo = ptr;\n\tnetdev = netdev_notifier_info_to_dev(ptr);\n\n\t \n\tif (netdev != lag->netdev)\n\t\treturn;\n\n\tprimary_lag = ice_lag_find_primary(lag);\n\tif (info->linking) {\n\t\tlag->upper_netdev = info->upper_dev;\n\t\t \n\t\tif (!primary_lag) {\n\t\t\tlag->primary = true;\n\t\t\t \n\t\t\tice_lag_primary_swid(lag, true);\n\t\t\tprimary_lag = lag;\n\t\t} else {\n\t\t\tu16 swid;\n\n\t\t\tswid = primary_lag->pf->hw.port_info->sw_id;\n\t\t\tice_lag_set_swid(swid, lag, true);\n\t\t\tice_lag_add_prune_list(primary_lag, lag->pf);\n\t\t}\n\t\t \n\t\tice_lag_cfg_cp_fltr(lag, true);\n\t} else {\n\t\tif (!primary_lag && lag->primary)\n\t\t\tprimary_lag = lag;\n\n\t\tif (!lag->primary) {\n\t\t\tice_lag_set_swid(0, lag, false);\n\t\t} else {\n\t\t\tif (primary_lag && lag->primary) {\n\t\t\t\tice_lag_primary_swid(lag, false);\n\t\t\t\tice_lag_del_prune_list(primary_lag, lag->pf);\n\t\t\t}\n\t\t}\n\t\t \n\t\tice_lag_cfg_cp_fltr(lag, false);\n\t}\n}\n\n \nstatic void ice_lag_monitor_link(struct ice_lag *lag, void *ptr)\n{\n\tstruct netdev_notifier_changeupper_info *info;\n\tstruct ice_hw *prim_hw, *active_hw;\n\tstruct net_device *event_netdev;\n\tstruct ice_pf *pf;\n\tu8 prim_port;\n\n\tif (!lag->primary)\n\t\treturn;\n\n\tevent_netdev = netdev_notifier_info_to_dev(ptr);\n\tif (!netif_is_same_ice(lag->pf, event_netdev))\n\t\treturn;\n\n\tpf = lag->pf;\n\tprim_hw = &pf->hw;\n\tprim_port = prim_hw->port_info->lport;\n\n\tinfo = (struct netdev_notifier_changeupper_info *)ptr;\n\tif (info->upper_dev != lag->upper_netdev)\n\t\treturn;\n\n\tif (!info->linking) {\n\t\t \n\t\tif (prim_port != lag->active_port &&\n\t\t    lag->active_port != ICE_LAG_INVALID_PORT) {\n\t\t\tactive_hw = ice_lag_find_hw_by_lport(lag,\n\t\t\t\t\t\t\t     lag->active_port);\n\t\t\tice_lag_reclaim_vf_nodes(lag, active_hw);\n\t\t\tlag->active_port = ICE_LAG_INVALID_PORT;\n\t\t}\n\t}\n}\n\n \nstatic void ice_lag_monitor_active(struct ice_lag *lag, void *ptr)\n{\n\tstruct net_device *event_netdev, *event_upper;\n\tstruct netdev_notifier_bonding_info *info;\n\tstruct netdev_bonding_info *bonding_info;\n\tstruct ice_netdev_priv *event_np;\n\tstruct ice_pf *pf, *event_pf;\n\tu8 prim_port, event_port;\n\n\tif (!lag->primary)\n\t\treturn;\n\n\tpf = lag->pf;\n\tif (!pf)\n\t\treturn;\n\n\tevent_netdev = netdev_notifier_info_to_dev(ptr);\n\trcu_read_lock();\n\tevent_upper = netdev_master_upper_dev_get_rcu(event_netdev);\n\trcu_read_unlock();\n\tif (!netif_is_ice(event_netdev) || event_upper != lag->upper_netdev)\n\t\treturn;\n\n\tevent_np = netdev_priv(event_netdev);\n\tevent_pf = event_np->vsi->back;\n\tevent_port = event_pf->hw.port_info->lport;\n\tprim_port = pf->hw.port_info->lport;\n\n\tinfo = (struct netdev_notifier_bonding_info *)ptr;\n\tbonding_info = &info->bonding_info;\n\n\tif (!bonding_info->slave.state) {\n\t\t \n\t\tif (lag->active_port == ICE_LAG_INVALID_PORT) {\n\t\t\tif (event_port != prim_port)\n\t\t\t\tice_lag_move_vf_nodes(lag, prim_port,\n\t\t\t\t\t\t      event_port);\n\t\t\tlag->active_port = event_port;\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tif (lag->active_port == event_port)\n\t\t\treturn;\n\t\t \n\t\tice_lag_move_vf_nodes(lag, lag->active_port, event_port);\n\t\tlag->active_port = event_port;\n\t} else {\n\t\t \n\t\tif (lag->active_port != event_port)\n\t\t\treturn;\n\t\t \n\t\tif (event_port != prim_port)\n\t\t\tice_lag_move_vf_nodes(lag, event_port, prim_port);\n\t\tlag->active_port = ICE_LAG_INVALID_PORT;\n\t}\n}\n\n \nstatic bool\nice_lag_chk_comp(struct ice_lag *lag, void *ptr)\n{\n\tstruct net_device *event_netdev, *event_upper;\n\tstruct netdev_notifier_bonding_info *info;\n\tstruct netdev_bonding_info *bonding_info;\n\tstruct list_head *tmp;\n\tstruct device *dev;\n\tint count = 0;\n\n\tif (!lag->primary)\n\t\treturn true;\n\n\tevent_netdev = netdev_notifier_info_to_dev(ptr);\n\trcu_read_lock();\n\tevent_upper = netdev_master_upper_dev_get_rcu(event_netdev);\n\trcu_read_unlock();\n\tif (event_upper != lag->upper_netdev)\n\t\treturn true;\n\n\tdev = ice_pf_to_dev(lag->pf);\n\n\t \n\tif (!ice_is_switchdev_running(lag->pf)) {\n\t\tdev_info(dev, \"Primary interface not in switchdev mode - VF LAG disabled\\n\");\n\t\treturn false;\n\t}\n\n\tinfo = (struct netdev_notifier_bonding_info *)ptr;\n\tbonding_info = &info->bonding_info;\n\tlag->bond_mode = bonding_info->master.bond_mode;\n\tif (lag->bond_mode != BOND_MODE_ACTIVEBACKUP) {\n\t\tdev_info(dev, \"Bond Mode not ACTIVE-BACKUP - VF LAG disabled\\n\");\n\t\treturn false;\n\t}\n\n\tlist_for_each(tmp, lag->netdev_head) {\n\t\tstruct ice_dcbx_cfg *dcb_cfg, *peer_dcb_cfg;\n\t\tstruct ice_lag_netdev_list *entry;\n\t\tstruct ice_netdev_priv *peer_np;\n\t\tstruct net_device *peer_netdev;\n\t\tstruct ice_vsi *vsi, *peer_vsi;\n\t\tstruct ice_pf *peer_pf;\n\n\t\tentry = list_entry(tmp, struct ice_lag_netdev_list, node);\n\t\tpeer_netdev = entry->netdev;\n\t\tif (!netif_is_ice(peer_netdev)) {\n\t\t\tdev_info(dev, \"Found %s non-ice netdev in LAG - VF LAG disabled\\n\",\n\t\t\t\t netdev_name(peer_netdev));\n\t\t\treturn false;\n\t\t}\n\n\t\tcount++;\n\t\tif (count > 2) {\n\t\t\tdev_info(dev, \"Found more than two netdevs in LAG - VF LAG disabled\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tpeer_np = netdev_priv(peer_netdev);\n\t\tvsi = ice_get_main_vsi(lag->pf);\n\t\tpeer_vsi = peer_np->vsi;\n\t\tif (lag->pf->pdev->bus != peer_vsi->back->pdev->bus ||\n\t\t    lag->pf->pdev->slot != peer_vsi->back->pdev->slot) {\n\t\t\tdev_info(dev, \"Found %s on different device in LAG - VF LAG disabled\\n\",\n\t\t\t\t netdev_name(peer_netdev));\n\t\t\treturn false;\n\t\t}\n\n\t\tdcb_cfg = &vsi->port_info->qos_cfg.local_dcbx_cfg;\n\t\tpeer_dcb_cfg = &peer_vsi->port_info->qos_cfg.local_dcbx_cfg;\n\t\tif (memcmp(dcb_cfg, peer_dcb_cfg,\n\t\t\t   sizeof(struct ice_dcbx_cfg))) {\n\t\t\tdev_info(dev, \"Found %s with different DCB in LAG - VF LAG disabled\\n\",\n\t\t\t\t netdev_name(peer_netdev));\n\t\t\treturn false;\n\t\t}\n\n\t\tpeer_pf = peer_vsi->back;\n\t\tif (test_bit(ICE_FLAG_FW_LLDP_AGENT, peer_pf->flags)) {\n\t\t\tdev_warn(dev, \"Found %s with FW LLDP agent active - VF LAG disabled\\n\",\n\t\t\t\t netdev_name(peer_netdev));\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}\n\n \nstatic void\nice_lag_unregister(struct ice_lag *lag, struct net_device *event_netdev)\n{\n\tstruct ice_netdev_priv *np;\n\tstruct ice_pf *event_pf;\n\tstruct ice_lag *p_lag;\n\n\tp_lag = ice_lag_find_primary(lag);\n\tnp = netdev_priv(event_netdev);\n\tevent_pf = np->vsi->back;\n\n\tif (p_lag) {\n\t\tif (p_lag->active_port != p_lag->pf->hw.port_info->lport &&\n\t\t    p_lag->active_port != ICE_LAG_INVALID_PORT) {\n\t\t\tstruct ice_hw *active_hw;\n\n\t\t\tactive_hw = ice_lag_find_hw_by_lport(lag,\n\t\t\t\t\t\t\t     p_lag->active_port);\n\t\t\tif (active_hw)\n\t\t\t\tice_lag_reclaim_vf_nodes(p_lag, active_hw);\n\t\t\tlag->active_port = ICE_LAG_INVALID_PORT;\n\t\t}\n\t}\n\n\t \n\tif (lag->primary && lag->netdev == event_netdev)\n\t\tice_lag_primary_swid(lag, false);\n\n\t \n\tif (lag->primary && lag->netdev != event_netdev)\n\t\tice_lag_del_prune_list(lag, event_pf);\n\n\t \n\tif (!lag->primary && lag->netdev == event_netdev)\n\t\tice_lag_set_swid(0, lag, false);\n}\n\n \nstatic void\nice_lag_monitor_rdma(struct ice_lag *lag, void *ptr)\n{\n\tstruct netdev_notifier_changeupper_info *info;\n\tstruct net_device *netdev;\n\n\tinfo = ptr;\n\tnetdev = netdev_notifier_info_to_dev(ptr);\n\n\tif (netdev != lag->netdev)\n\t\treturn;\n\n\tif (info->linking)\n\t\tice_clear_rdma_cap(lag->pf);\n\telse\n\t\tice_set_rdma_cap(lag->pf);\n}\n\n \nstatic void ice_lag_chk_disabled_bond(struct ice_lag *lag, void *ptr)\n{\n\tstruct net_device *netdev = netdev_notifier_info_to_dev(ptr);\n\tstruct netdev_notifier_changeupper_info *info = ptr;\n\tstruct ice_lag *prim_lag;\n\n\tif (netdev != lag->netdev)\n\t\treturn;\n\n\tif (info->linking) {\n\t\tprim_lag = ice_lag_find_primary(lag);\n\t\tif (prim_lag &&\n\t\t    !ice_is_feature_supported(prim_lag->pf, ICE_F_SRIOV_LAG)) {\n\t\t\tice_clear_feature_support(lag->pf, ICE_F_SRIOV_LAG);\n\t\t\tnetdev_info(netdev, \"Interface added to non-compliant SRIOV LAG aggregate\\n\");\n\t\t}\n\t} else {\n\t\tice_lag_init_feature_support_flag(lag->pf);\n\t}\n}\n\n \nstatic void ice_lag_disable_sriov_bond(struct ice_lag *lag)\n{\n\tstruct ice_netdev_priv *np;\n\tstruct ice_pf *pf;\n\n\tnp = netdev_priv(lag->netdev);\n\tpf = np->vsi->back;\n\tice_clear_feature_support(pf, ICE_F_SRIOV_LAG);\n}\n\n \nstatic void ice_lag_process_event(struct work_struct *work)\n{\n\tstruct netdev_notifier_changeupper_info *info;\n\tstruct ice_lag_work *lag_work;\n\tstruct net_device *netdev;\n\tstruct list_head *tmp, *n;\n\tstruct ice_pf *pf;\n\n\tlag_work = container_of(work, struct ice_lag_work, lag_task);\n\tpf = lag_work->lag->pf;\n\n\tmutex_lock(&pf->lag_mutex);\n\tlag_work->lag->netdev_head = &lag_work->netdev_list.node;\n\n\tswitch (lag_work->event) {\n\tcase NETDEV_CHANGEUPPER:\n\t\tinfo = &lag_work->info.changeupper_info;\n\t\tice_lag_chk_disabled_bond(lag_work->lag, info);\n\t\tif (ice_is_feature_supported(pf, ICE_F_SRIOV_LAG)) {\n\t\t\tice_lag_monitor_link(lag_work->lag, info);\n\t\t\tice_lag_changeupper_event(lag_work->lag, info);\n\t\t\tice_lag_link_unlink(lag_work->lag, info);\n\t\t}\n\t\tice_lag_monitor_rdma(lag_work->lag, info);\n\t\tbreak;\n\tcase NETDEV_BONDING_INFO:\n\t\tif (ice_is_feature_supported(pf, ICE_F_SRIOV_LAG)) {\n\t\t\tif (!ice_lag_chk_comp(lag_work->lag,\n\t\t\t\t\t      &lag_work->info.bonding_info)) {\n\t\t\t\tnetdev = lag_work->info.bonding_info.info.dev;\n\t\t\t\tice_lag_disable_sriov_bond(lag_work->lag);\n\t\t\t\tice_lag_unregister(lag_work->lag, netdev);\n\t\t\t\tgoto lag_cleanup;\n\t\t\t}\n\t\t\tice_lag_monitor_active(lag_work->lag,\n\t\t\t\t\t       &lag_work->info.bonding_info);\n\t\t\tice_lag_cfg_pf_fltrs(lag_work->lag,\n\t\t\t\t\t     &lag_work->info.bonding_info);\n\t\t}\n\t\tice_lag_info_event(lag_work->lag, &lag_work->info.bonding_info);\n\t\tbreak;\n\tcase NETDEV_UNREGISTER:\n\t\tif (ice_is_feature_supported(pf, ICE_F_SRIOV_LAG)) {\n\t\t\tnetdev = lag_work->info.bonding_info.info.dev;\n\t\t\tif ((netdev == lag_work->lag->netdev ||\n\t\t\t     lag_work->lag->primary) && lag_work->lag->bonded)\n\t\t\t\tice_lag_unregister(lag_work->lag, netdev);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\nlag_cleanup:\n\t \n\tlist_for_each_safe(tmp, n, &lag_work->netdev_list.node) {\n\t\tstruct ice_lag_netdev_list *entry;\n\n\t\tentry = list_entry(tmp, struct ice_lag_netdev_list, node);\n\t\tlist_del(&entry->node);\n\t\tkfree(entry);\n\t}\n\tlag_work->lag->netdev_head = NULL;\n\n\tmutex_unlock(&pf->lag_mutex);\n\n\tkfree(lag_work);\n}\n\n \nstatic int\nice_lag_event_handler(struct notifier_block *notif_blk, unsigned long event,\n\t\t      void *ptr)\n{\n\tstruct net_device *netdev = netdev_notifier_info_to_dev(ptr);\n\tstruct net_device *upper_netdev;\n\tstruct ice_lag_work *lag_work;\n\tstruct ice_lag *lag;\n\n\tif (!netif_is_ice(netdev))\n\t\treturn NOTIFY_DONE;\n\n\tif (event != NETDEV_CHANGEUPPER && event != NETDEV_BONDING_INFO &&\n\t    event != NETDEV_UNREGISTER)\n\t\treturn NOTIFY_DONE;\n\n\tif (!(netdev->priv_flags & IFF_BONDING))\n\t\treturn NOTIFY_DONE;\n\n\tlag = container_of(notif_blk, struct ice_lag, notif_block);\n\tif (!lag->netdev)\n\t\treturn NOTIFY_DONE;\n\n\tif (!net_eq(dev_net(netdev), &init_net))\n\t\treturn NOTIFY_DONE;\n\n\t \n\tlag_work = kzalloc(sizeof(*lag_work), GFP_KERNEL);\n\tif (!lag_work)\n\t\treturn -ENOMEM;\n\n\tlag_work->event_netdev = netdev;\n\tlag_work->lag = lag;\n\tlag_work->event = event;\n\tif (event == NETDEV_CHANGEUPPER) {\n\t\tstruct netdev_notifier_changeupper_info *info;\n\n\t\tinfo = ptr;\n\t\tupper_netdev = info->upper_dev;\n\t} else {\n\t\tupper_netdev = netdev_master_upper_dev_get(netdev);\n\t}\n\n\tINIT_LIST_HEAD(&lag_work->netdev_list.node);\n\tif (upper_netdev) {\n\t\tstruct ice_lag_netdev_list *nd_list;\n\t\tstruct net_device *tmp_nd;\n\n\t\trcu_read_lock();\n\t\tfor_each_netdev_in_bond_rcu(upper_netdev, tmp_nd) {\n\t\t\tnd_list = kzalloc(sizeof(*nd_list), GFP_ATOMIC);\n\t\t\tif (!nd_list)\n\t\t\t\tbreak;\n\n\t\t\tnd_list->netdev = tmp_nd;\n\t\t\tlist_add(&nd_list->node, &lag_work->netdev_list.node);\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tswitch (event) {\n\tcase NETDEV_CHANGEUPPER:\n\t\tlag_work->info.changeupper_info =\n\t\t\t*((struct netdev_notifier_changeupper_info *)ptr);\n\t\tbreak;\n\tcase NETDEV_BONDING_INFO:\n\t\tlag_work->info.bonding_info =\n\t\t\t*((struct netdev_notifier_bonding_info *)ptr);\n\t\tbreak;\n\tdefault:\n\t\tlag_work->info.notifier_info =\n\t\t\t*((struct netdev_notifier_info *)ptr);\n\t\tbreak;\n\t}\n\n\tINIT_WORK(&lag_work->lag_task, ice_lag_process_event);\n\tqueue_work(ice_lag_wq, &lag_work->lag_task);\n\n\treturn NOTIFY_DONE;\n}\n\n \nstatic int ice_register_lag_handler(struct ice_lag *lag)\n{\n\tstruct device *dev = ice_pf_to_dev(lag->pf);\n\tstruct notifier_block *notif_blk;\n\n\tnotif_blk = &lag->notif_block;\n\n\tif (!notif_blk->notifier_call) {\n\t\tnotif_blk->notifier_call = ice_lag_event_handler;\n\t\tif (register_netdevice_notifier(notif_blk)) {\n\t\t\tnotif_blk->notifier_call = NULL;\n\t\t\tdev_err(dev, \"FAIL register LAG event handler!\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tdev_dbg(dev, \"LAG event handler registered\\n\");\n\t}\n\treturn 0;\n}\n\n \nstatic void ice_unregister_lag_handler(struct ice_lag *lag)\n{\n\tstruct device *dev = ice_pf_to_dev(lag->pf);\n\tstruct notifier_block *notif_blk;\n\n\tnotif_blk = &lag->notif_block;\n\tif (notif_blk->notifier_call) {\n\t\tunregister_netdevice_notifier(notif_blk);\n\t\tdev_dbg(dev, \"LAG event handler unregistered\\n\");\n\t}\n}\n\n \nstatic int ice_create_lag_recipe(struct ice_hw *hw, u16 *rid,\n\t\t\t\t const u8 *base_recipe, u8 prio)\n{\n\tstruct ice_aqc_recipe_data_elem *new_rcp;\n\tint err;\n\n\terr = ice_alloc_recipe(hw, rid);\n\tif (err)\n\t\treturn err;\n\n\tnew_rcp = kzalloc(ICE_RECIPE_LEN * ICE_MAX_NUM_RECIPES, GFP_KERNEL);\n\tif (!new_rcp)\n\t\treturn -ENOMEM;\n\n\tmemcpy(new_rcp, base_recipe, ICE_RECIPE_LEN);\n\tnew_rcp->content.act_ctrl_fwd_priority = prio;\n\tnew_rcp->content.rid = *rid | ICE_AQ_RECIPE_ID_IS_ROOT;\n\tnew_rcp->recipe_indx = *rid;\n\tbitmap_zero((unsigned long *)new_rcp->recipe_bitmap,\n\t\t    ICE_MAX_NUM_RECIPES);\n\tset_bit(*rid, (unsigned long *)new_rcp->recipe_bitmap);\n\n\terr = ice_aq_add_recipe(hw, new_rcp, 1, NULL);\n\tif (err)\n\t\t*rid = 0;\n\n\tkfree(new_rcp);\n\treturn err;\n}\n\n \nstatic void\nice_lag_move_vf_nodes_tc_sync(struct ice_lag *lag, struct ice_hw *dest_hw,\n\t\t\t      u16 vsi_num, u8 tc)\n{\n\tu16 numq, valq, buf_size, num_moved, qbuf_size;\n\tstruct device *dev = ice_pf_to_dev(lag->pf);\n\tstruct ice_aqc_cfg_txqs_buf *qbuf;\n\tstruct ice_aqc_move_elem *buf;\n\tstruct ice_sched_node *n_prt;\n\t__le32 teid, parent_teid;\n\tstruct ice_vsi_ctx *ctx;\n\tstruct ice_hw *hw;\n\tu32 tmp_teid;\n\n\thw = &lag->pf->hw;\n\tctx = ice_get_vsi_ctx(hw, vsi_num);\n\tif (!ctx) {\n\t\tdev_warn(dev, \"LAG rebuild failed after reset due to VSI Context failure\\n\");\n\t\treturn;\n\t}\n\n\tif (!ctx->sched.vsi_node[tc])\n\t\treturn;\n\n\tnumq = ctx->num_lan_q_entries[tc];\n\tteid = ctx->sched.vsi_node[tc]->info.node_teid;\n\ttmp_teid = le32_to_cpu(teid);\n\tparent_teid = ctx->sched.vsi_node[tc]->info.parent_teid;\n\n\tif (!tmp_teid || !numq)\n\t\treturn;\n\n\tif (ice_sched_suspend_resume_elems(hw, 1, &tmp_teid, true))\n\t\tdev_dbg(dev, \"Problem suspending traffic during reset rebuild\\n\");\n\n\t \n\tqbuf_size = struct_size(qbuf, queue_info, numq);\n\tqbuf = kzalloc(qbuf_size, GFP_KERNEL);\n\tif (!qbuf) {\n\t\tdev_warn(dev, \"Failure allocating VF queue recfg buffer for reset rebuild\\n\");\n\t\tgoto resume_sync;\n\t}\n\n\t \n\tvalq = ice_lag_qbuf_recfg(hw, qbuf, vsi_num, numq, tc);\n\tif (!valq) {\n\t\tdev_warn(dev, \"Failure to reconfig queues for LAG reset rebuild\\n\");\n\t\tgoto sync_none;\n\t}\n\n\tif (ice_aq_cfg_lan_txq(hw, qbuf, qbuf_size, numq, hw->port_info->lport,\n\t\t\t       dest_hw->port_info->lport, NULL)) {\n\t\tdev_warn(dev, \"Failure to configure queues for LAG reset rebuild\\n\");\n\t\tgoto sync_qerr;\n\t}\n\nsync_none:\n\tkfree(qbuf);\n\n\t \n\tn_prt = ice_lag_get_sched_parent(dest_hw, tc);\n\tif (!n_prt)\n\t\tgoto resume_sync;\n\n\t \n\tbuf_size = struct_size(buf, teid, 1);\n\tbuf = kzalloc(buf_size, GFP_KERNEL);\n\tif (!buf) {\n\t\tdev_warn(dev, \"Failure to alloc for VF node move in reset rebuild\\n\");\n\t\tgoto resume_sync;\n\t}\n\n\tbuf->hdr.src_parent_teid = parent_teid;\n\tbuf->hdr.dest_parent_teid = n_prt->info.node_teid;\n\tbuf->hdr.num_elems = cpu_to_le16(1);\n\tbuf->hdr.mode = ICE_AQC_MOVE_ELEM_MODE_KEEP_OWN;\n\tbuf->teid[0] = teid;\n\n\tif (ice_aq_move_sched_elems(&lag->pf->hw, 1, buf, buf_size, &num_moved,\n\t\t\t\t    NULL))\n\t\tdev_warn(dev, \"Failure to move VF nodes for LAG reset rebuild\\n\");\n\telse\n\t\tice_sched_update_parent(n_prt, ctx->sched.vsi_node[tc]);\n\n\tkfree(buf);\n\tgoto resume_sync;\n\nsync_qerr:\n\tkfree(qbuf);\n\nresume_sync:\n\tif (ice_sched_suspend_resume_elems(hw, 1, &tmp_teid, false))\n\t\tdev_warn(dev, \"Problem restarting traffic for LAG node reset rebuild\\n\");\n}\n\n \nstatic void\nice_lag_move_vf_nodes_sync(struct ice_lag *lag, struct ice_hw *dest_hw)\n{\n\tstruct ice_pf *pf;\n\tint i, tc;\n\n\tif (!lag->primary || !dest_hw)\n\t\treturn;\n\n\tpf = lag->pf;\n\tice_for_each_vsi(pf, i)\n\t\tif (pf->vsi[i] && (pf->vsi[i]->type == ICE_VSI_VF ||\n\t\t\t\t   pf->vsi[i]->type == ICE_VSI_SWITCHDEV_CTRL))\n\t\t\tice_for_each_traffic_class(tc)\n\t\t\t\tice_lag_move_vf_nodes_tc_sync(lag, dest_hw, i,\n\t\t\t\t\t\t\t      tc);\n}\n\n \nint ice_init_lag(struct ice_pf *pf)\n{\n\tstruct device *dev = ice_pf_to_dev(pf);\n\tstruct ice_lag *lag;\n\tstruct ice_vsi *vsi;\n\tu64 recipe_bits = 0;\n\tint n, err;\n\n\tice_lag_init_feature_support_flag(pf);\n\tif (!ice_is_feature_supported(pf, ICE_F_SRIOV_LAG))\n\t\treturn 0;\n\n\tpf->lag = kzalloc(sizeof(*lag), GFP_KERNEL);\n\tif (!pf->lag)\n\t\treturn -ENOMEM;\n\tlag = pf->lag;\n\n\tvsi = ice_get_main_vsi(pf);\n\tif (!vsi) {\n\t\tdev_err(dev, \"couldn't get main vsi, link aggregation init fail\\n\");\n\t\terr = -EIO;\n\t\tgoto lag_error;\n\t}\n\n\tlag->pf = pf;\n\tlag->netdev = vsi->netdev;\n\tlag->role = ICE_LAG_NONE;\n\tlag->active_port = ICE_LAG_INVALID_PORT;\n\tlag->bonded = false;\n\tlag->upper_netdev = NULL;\n\tlag->notif_block.notifier_call = NULL;\n\n\terr = ice_register_lag_handler(lag);\n\tif (err) {\n\t\tdev_warn(dev, \"INIT LAG: Failed to register event handler\\n\");\n\t\tgoto lag_error;\n\t}\n\n\terr = ice_create_lag_recipe(&pf->hw, &lag->pf_recipe, ice_dflt_vsi_rcp,\n\t\t\t\t    1);\n\tif (err)\n\t\tgoto lag_error;\n\n\t \n\tfor (n = 0; n < ICE_PROFID_IPV6_GTPU_IPV6_TCP_INNER; n++) {\n\t\terr = ice_aq_get_recipe_to_profile(&pf->hw, n,\n\t\t\t\t\t\t   (u8 *)&recipe_bits, NULL);\n\t\tif (err)\n\t\t\tcontinue;\n\n\t\tif (recipe_bits & BIT(ICE_SW_LKUP_DFLT)) {\n\t\t\trecipe_bits |= BIT(lag->pf_recipe);\n\t\t\tice_aq_map_recipe_to_profile(&pf->hw, n,\n\t\t\t\t\t\t     (u8 *)&recipe_bits, NULL);\n\t\t}\n\t}\n\n\tice_display_lag_info(lag);\n\n\tdev_dbg(dev, \"INIT LAG complete\\n\");\n\treturn 0;\n\nlag_error:\n\tkfree(lag);\n\tpf->lag = NULL;\n\treturn err;\n}\n\n \nvoid ice_deinit_lag(struct ice_pf *pf)\n{\n\tstruct ice_lag *lag;\n\n\tlag = pf->lag;\n\n\tif (!lag)\n\t\treturn;\n\n\tif (lag->pf)\n\t\tice_unregister_lag_handler(lag);\n\n\tflush_workqueue(ice_lag_wq);\n\n\tice_free_hw_res(&pf->hw, ICE_AQC_RES_TYPE_RECIPE, 1,\n\t\t\t&pf->lag->pf_recipe);\n\n\tkfree(lag);\n\n\tpf->lag = NULL;\n}\n\n \nvoid ice_lag_rebuild(struct ice_pf *pf)\n{\n\tstruct ice_lag_netdev_list ndlist;\n\tstruct ice_lag *lag, *prim_lag;\n\tu8 act_port, loc_port;\n\n\tif (!pf->lag || !pf->lag->bonded)\n\t\treturn;\n\n\tmutex_lock(&pf->lag_mutex);\n\n\tlag = pf->lag;\n\tif (lag->primary) {\n\t\tprim_lag = lag;\n\t} else {\n\t\tice_lag_build_netdev_list(lag, &ndlist);\n\t\tprim_lag = ice_lag_find_primary(lag);\n\t}\n\n\tif (!prim_lag) {\n\t\tdev_dbg(ice_pf_to_dev(pf), \"No primary interface in aggregate, can't rebuild\\n\");\n\t\tgoto lag_rebuild_out;\n\t}\n\n\tact_port = prim_lag->active_port;\n\tloc_port = lag->pf->hw.port_info->lport;\n\n\t \n\tif (lag->primary) {\n\t\tice_lag_primary_swid(lag, true);\n\t} else {\n\t\tice_lag_set_swid(prim_lag->pf->hw.port_info->sw_id, lag, true);\n\t\tice_lag_add_prune_list(prim_lag, pf);\n\t\tif (act_port == loc_port)\n\t\t\tice_lag_move_vf_nodes_sync(prim_lag, &pf->hw);\n\t}\n\n\tice_lag_cfg_cp_fltr(lag, true);\n\n\tif (lag->pf_rule_id)\n\t\tif (ice_lag_cfg_dflt_fltr(lag, true))\n\t\t\tdev_err(ice_pf_to_dev(pf), \"Error adding default VSI rule in rebuild\\n\");\n\n\tice_clear_rdma_cap(pf);\nlag_rebuild_out:\n\tice_lag_destroy_netdev_list(lag, &ndlist);\n\tmutex_unlock(&pf->lag_mutex);\n}\n\n \nbool ice_lag_is_switchdev_running(struct ice_pf *pf)\n{\n\tstruct ice_lag *lag = pf->lag;\n\tstruct net_device *tmp_nd;\n\n\tif (!ice_is_feature_supported(pf, ICE_F_SRIOV_LAG) || !lag)\n\t\treturn false;\n\n\trcu_read_lock();\n\tfor_each_netdev_in_bond_rcu(lag->upper_netdev, tmp_nd) {\n\t\tstruct ice_netdev_priv *priv = netdev_priv(tmp_nd);\n\n\t\tif (!netif_is_ice(tmp_nd) || !priv || !priv->vsi ||\n\t\t    !priv->vsi->back)\n\t\t\tcontinue;\n\n\t\tif (ice_is_switchdev_running(priv->vsi->back)) {\n\t\t\trcu_read_unlock();\n\t\t\treturn true;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn false;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}