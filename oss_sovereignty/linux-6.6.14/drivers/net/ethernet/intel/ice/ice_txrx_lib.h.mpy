{
  "module_name": "ice_txrx_lib.h",
  "hash_id": "3408cfc8c0d981cb6c1accce3fb01ba4ca3237077451870afcca816adb90758c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_txrx_lib.h",
  "human_readable_source": " \n \n\n#ifndef _ICE_TXRX_LIB_H_\n#define _ICE_TXRX_LIB_H_\n#include \"ice.h\"\n\n \nstatic inline void\nice_set_rx_bufs_act(struct xdp_buff *xdp, const struct ice_rx_ring *rx_ring,\n\t\t    const unsigned int act)\n{\n\tconst struct skb_shared_info *sinfo = xdp_get_shared_info_from_buff(xdp);\n\tu32 first = rx_ring->first_desc;\n\tu32 nr_frags = sinfo->nr_frags;\n\tu32 cnt = rx_ring->count;\n\tstruct ice_rx_buf *buf;\n\n\tfor (int i = 0; i < nr_frags; i++) {\n\t\tbuf = &rx_ring->rx_buf[first];\n\t\tbuf->act = act;\n\n\t\tif (++first == cnt)\n\t\t\tfirst = 0;\n\t}\n}\n\n \nstatic inline bool\nice_test_staterr(__le16 status_err_n, const u16 stat_err_bits)\n{\n\treturn !!(status_err_n & cpu_to_le16(stat_err_bits));\n}\n\n \nstatic inline bool\nice_is_non_eop(const struct ice_rx_ring *rx_ring,\n\t       const union ice_32b_rx_flex_desc *rx_desc)\n{\n\t \n#define ICE_RXD_EOF BIT(ICE_RX_FLEX_DESC_STATUS0_EOF_S)\n\tif (likely(ice_test_staterr(rx_desc->wb.status_error0, ICE_RXD_EOF)))\n\t\treturn false;\n\n\trx_ring->ring_stats->rx_stats.non_eop_descs++;\n\n\treturn true;\n}\n\nstatic inline __le64\nice_build_ctob(u64 td_cmd, u64 td_offset, unsigned int size, u64 td_tag)\n{\n\treturn cpu_to_le64(ICE_TX_DESC_DTYPE_DATA |\n\t\t\t   (td_cmd    << ICE_TXD_QW1_CMD_S) |\n\t\t\t   (td_offset << ICE_TXD_QW1_OFFSET_S) |\n\t\t\t   ((u64)size << ICE_TXD_QW1_TX_BUF_SZ_S) |\n\t\t\t   (td_tag    << ICE_TXD_QW1_L2TAG1_S));\n}\n\n \nstatic inline u16\nice_get_vlan_tag_from_rx_desc(union ice_32b_rx_flex_desc *rx_desc)\n{\n\tu16 stat_err_bits;\n\n\tstat_err_bits = BIT(ICE_RX_FLEX_DESC_STATUS0_L2TAG1P_S);\n\tif (ice_test_staterr(rx_desc->wb.status_error0, stat_err_bits))\n\t\treturn le16_to_cpu(rx_desc->wb.l2tag1);\n\n\tstat_err_bits = BIT(ICE_RX_FLEX_DESC_STATUS1_L2TAG2P_S);\n\tif (ice_test_staterr(rx_desc->wb.status_error1, stat_err_bits))\n\t\treturn le16_to_cpu(rx_desc->wb.l2tag2_2nd);\n\n\treturn 0;\n}\n\n \nstatic inline void ice_xdp_ring_update_tail(struct ice_tx_ring *xdp_ring)\n{\n\t \n\twmb();\n\twritel_relaxed(xdp_ring->next_to_use, xdp_ring->tail);\n}\n\n \nstatic inline u32 ice_set_rs_bit(const struct ice_tx_ring *xdp_ring)\n{\n\tu32 rs_idx = xdp_ring->next_to_use ? xdp_ring->next_to_use - 1 : xdp_ring->count - 1;\n\tstruct ice_tx_desc *tx_desc;\n\n\ttx_desc = ICE_TX_DESC(xdp_ring, rs_idx);\n\ttx_desc->cmd_type_offset_bsz |=\n\t\tcpu_to_le64(ICE_TX_DESC_CMD_RS << ICE_TXD_QW1_CMD_S);\n\n\treturn rs_idx;\n}\n\nvoid ice_finalize_xdp_rx(struct ice_tx_ring *xdp_ring, unsigned int xdp_res, u32 first_idx);\nint ice_xmit_xdp_buff(struct xdp_buff *xdp, struct ice_tx_ring *xdp_ring);\nint __ice_xmit_xdp_ring(struct xdp_buff *xdp, struct ice_tx_ring *xdp_ring,\n\t\t\tbool frame);\nvoid ice_release_rx_desc(struct ice_rx_ring *rx_ring, u16 val);\nvoid\nice_process_skb_fields(struct ice_rx_ring *rx_ring,\n\t\t       union ice_32b_rx_flex_desc *rx_desc,\n\t\t       struct sk_buff *skb, u16 ptype);\nvoid\nice_receive_skb(struct ice_rx_ring *rx_ring, struct sk_buff *skb, u16 vlan_tag);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}