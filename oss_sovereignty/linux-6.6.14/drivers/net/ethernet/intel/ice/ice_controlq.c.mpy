{
  "module_name": "ice_controlq.c",
  "hash_id": "030abcd4d2f2d900961a07d462723e1bb9390d342ae465606c5b912ebe0ab163",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_controlq.c",
  "human_readable_source": "\n \n\n#include \"ice_common.h\"\n\n#define ICE_CQ_INIT_REGS(qinfo, prefix)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\\\n\t(qinfo)->sq.head = prefix##_ATQH;\t\t\t\\\n\t(qinfo)->sq.tail = prefix##_ATQT;\t\t\t\\\n\t(qinfo)->sq.len = prefix##_ATQLEN;\t\t\t\\\n\t(qinfo)->sq.bah = prefix##_ATQBAH;\t\t\t\\\n\t(qinfo)->sq.bal = prefix##_ATQBAL;\t\t\t\\\n\t(qinfo)->sq.len_mask = prefix##_ATQLEN_ATQLEN_M;\t\\\n\t(qinfo)->sq.len_ena_mask = prefix##_ATQLEN_ATQENABLE_M;\t\\\n\t(qinfo)->sq.len_crit_mask = prefix##_ATQLEN_ATQCRIT_M;\t\\\n\t(qinfo)->sq.head_mask = prefix##_ATQH_ATQH_M;\t\t\\\n\t(qinfo)->rq.head = prefix##_ARQH;\t\t\t\\\n\t(qinfo)->rq.tail = prefix##_ARQT;\t\t\t\\\n\t(qinfo)->rq.len = prefix##_ARQLEN;\t\t\t\\\n\t(qinfo)->rq.bah = prefix##_ARQBAH;\t\t\t\\\n\t(qinfo)->rq.bal = prefix##_ARQBAL;\t\t\t\\\n\t(qinfo)->rq.len_mask = prefix##_ARQLEN_ARQLEN_M;\t\\\n\t(qinfo)->rq.len_ena_mask = prefix##_ARQLEN_ARQENABLE_M;\t\\\n\t(qinfo)->rq.len_crit_mask = prefix##_ARQLEN_ARQCRIT_M;\t\\\n\t(qinfo)->rq.head_mask = prefix##_ARQH_ARQH_M;\t\t\\\n} while (0)\n\n \nstatic void ice_adminq_init_regs(struct ice_hw *hw)\n{\n\tstruct ice_ctl_q_info *cq = &hw->adminq;\n\n\tICE_CQ_INIT_REGS(cq, PF_FW);\n}\n\n \nstatic void ice_mailbox_init_regs(struct ice_hw *hw)\n{\n\tstruct ice_ctl_q_info *cq = &hw->mailboxq;\n\n\tICE_CQ_INIT_REGS(cq, PF_MBX);\n}\n\n \nstatic void ice_sb_init_regs(struct ice_hw *hw)\n{\n\tstruct ice_ctl_q_info *cq = &hw->sbq;\n\n\tICE_CQ_INIT_REGS(cq, PF_SB);\n}\n\n \nbool ice_check_sq_alive(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\t \n\tif (cq->sq.len && cq->sq.len_mask && cq->sq.len_ena_mask)\n\t\treturn (rd32(hw, cq->sq.len) & (cq->sq.len_mask |\n\t\t\t\t\t\tcq->sq.len_ena_mask)) ==\n\t\t\t(cq->num_sq_entries | cq->sq.len_ena_mask);\n\n\treturn false;\n}\n\n \nstatic int\nice_alloc_ctrlq_sq_ring(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tsize_t size = cq->num_sq_entries * sizeof(struct ice_aq_desc);\n\n\tcq->sq.desc_buf.va = dmam_alloc_coherent(ice_hw_to_dev(hw), size,\n\t\t\t\t\t\t &cq->sq.desc_buf.pa,\n\t\t\t\t\t\t GFP_KERNEL | __GFP_ZERO);\n\tif (!cq->sq.desc_buf.va)\n\t\treturn -ENOMEM;\n\tcq->sq.desc_buf.size = size;\n\n\tcq->sq.cmd_buf = devm_kcalloc(ice_hw_to_dev(hw), cq->num_sq_entries,\n\t\t\t\t      sizeof(struct ice_sq_cd), GFP_KERNEL);\n\tif (!cq->sq.cmd_buf) {\n\t\tdmam_free_coherent(ice_hw_to_dev(hw), cq->sq.desc_buf.size,\n\t\t\t\t   cq->sq.desc_buf.va, cq->sq.desc_buf.pa);\n\t\tcq->sq.desc_buf.va = NULL;\n\t\tcq->sq.desc_buf.pa = 0;\n\t\tcq->sq.desc_buf.size = 0;\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_alloc_ctrlq_rq_ring(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tsize_t size = cq->num_rq_entries * sizeof(struct ice_aq_desc);\n\n\tcq->rq.desc_buf.va = dmam_alloc_coherent(ice_hw_to_dev(hw), size,\n\t\t\t\t\t\t &cq->rq.desc_buf.pa,\n\t\t\t\t\t\t GFP_KERNEL | __GFP_ZERO);\n\tif (!cq->rq.desc_buf.va)\n\t\treturn -ENOMEM;\n\tcq->rq.desc_buf.size = size;\n\treturn 0;\n}\n\n \nstatic void ice_free_cq_ring(struct ice_hw *hw, struct ice_ctl_q_ring *ring)\n{\n\tdmam_free_coherent(ice_hw_to_dev(hw), ring->desc_buf.size,\n\t\t\t   ring->desc_buf.va, ring->desc_buf.pa);\n\tring->desc_buf.va = NULL;\n\tring->desc_buf.pa = 0;\n\tring->desc_buf.size = 0;\n}\n\n \nstatic int\nice_alloc_rq_bufs(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tint i;\n\n\t \n\tcq->rq.dma_head = devm_kcalloc(ice_hw_to_dev(hw), cq->num_rq_entries,\n\t\t\t\t       sizeof(cq->rq.desc_buf), GFP_KERNEL);\n\tif (!cq->rq.dma_head)\n\t\treturn -ENOMEM;\n\tcq->rq.r.rq_bi = (struct ice_dma_mem *)cq->rq.dma_head;\n\n\t \n\tfor (i = 0; i < cq->num_rq_entries; i++) {\n\t\tstruct ice_aq_desc *desc;\n\t\tstruct ice_dma_mem *bi;\n\n\t\tbi = &cq->rq.r.rq_bi[i];\n\t\tbi->va = dmam_alloc_coherent(ice_hw_to_dev(hw),\n\t\t\t\t\t     cq->rq_buf_size, &bi->pa,\n\t\t\t\t\t     GFP_KERNEL | __GFP_ZERO);\n\t\tif (!bi->va)\n\t\t\tgoto unwind_alloc_rq_bufs;\n\t\tbi->size = cq->rq_buf_size;\n\n\t\t \n\t\tdesc = ICE_CTL_Q_DESC(cq->rq, i);\n\n\t\tdesc->flags = cpu_to_le16(ICE_AQ_FLAG_BUF);\n\t\tif (cq->rq_buf_size > ICE_AQ_LG_BUF)\n\t\t\tdesc->flags |= cpu_to_le16(ICE_AQ_FLAG_LB);\n\t\tdesc->opcode = 0;\n\t\t \n\t\tdesc->datalen = cpu_to_le16(bi->size);\n\t\tdesc->retval = 0;\n\t\tdesc->cookie_high = 0;\n\t\tdesc->cookie_low = 0;\n\t\tdesc->params.generic.addr_high =\n\t\t\tcpu_to_le32(upper_32_bits(bi->pa));\n\t\tdesc->params.generic.addr_low =\n\t\t\tcpu_to_le32(lower_32_bits(bi->pa));\n\t\tdesc->params.generic.param0 = 0;\n\t\tdesc->params.generic.param1 = 0;\n\t}\n\treturn 0;\n\nunwind_alloc_rq_bufs:\n\t \n\ti--;\n\tfor (; i >= 0; i--) {\n\t\tdmam_free_coherent(ice_hw_to_dev(hw), cq->rq.r.rq_bi[i].size,\n\t\t\t\t   cq->rq.r.rq_bi[i].va, cq->rq.r.rq_bi[i].pa);\n\t\tcq->rq.r.rq_bi[i].va = NULL;\n\t\tcq->rq.r.rq_bi[i].pa = 0;\n\t\tcq->rq.r.rq_bi[i].size = 0;\n\t}\n\tcq->rq.r.rq_bi = NULL;\n\tdevm_kfree(ice_hw_to_dev(hw), cq->rq.dma_head);\n\tcq->rq.dma_head = NULL;\n\n\treturn -ENOMEM;\n}\n\n \nstatic int\nice_alloc_sq_bufs(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tint i;\n\n\t \n\tcq->sq.dma_head = devm_kcalloc(ice_hw_to_dev(hw), cq->num_sq_entries,\n\t\t\t\t       sizeof(cq->sq.desc_buf), GFP_KERNEL);\n\tif (!cq->sq.dma_head)\n\t\treturn -ENOMEM;\n\tcq->sq.r.sq_bi = (struct ice_dma_mem *)cq->sq.dma_head;\n\n\t \n\tfor (i = 0; i < cq->num_sq_entries; i++) {\n\t\tstruct ice_dma_mem *bi;\n\n\t\tbi = &cq->sq.r.sq_bi[i];\n\t\tbi->va = dmam_alloc_coherent(ice_hw_to_dev(hw),\n\t\t\t\t\t     cq->sq_buf_size, &bi->pa,\n\t\t\t\t\t     GFP_KERNEL | __GFP_ZERO);\n\t\tif (!bi->va)\n\t\t\tgoto unwind_alloc_sq_bufs;\n\t\tbi->size = cq->sq_buf_size;\n\t}\n\treturn 0;\n\nunwind_alloc_sq_bufs:\n\t \n\ti--;\n\tfor (; i >= 0; i--) {\n\t\tdmam_free_coherent(ice_hw_to_dev(hw), cq->sq.r.sq_bi[i].size,\n\t\t\t\t   cq->sq.r.sq_bi[i].va, cq->sq.r.sq_bi[i].pa);\n\t\tcq->sq.r.sq_bi[i].va = NULL;\n\t\tcq->sq.r.sq_bi[i].pa = 0;\n\t\tcq->sq.r.sq_bi[i].size = 0;\n\t}\n\tcq->sq.r.sq_bi = NULL;\n\tdevm_kfree(ice_hw_to_dev(hw), cq->sq.dma_head);\n\tcq->sq.dma_head = NULL;\n\n\treturn -ENOMEM;\n}\n\nstatic int\nice_cfg_cq_regs(struct ice_hw *hw, struct ice_ctl_q_ring *ring, u16 num_entries)\n{\n\t \n\twr32(hw, ring->head, 0);\n\twr32(hw, ring->tail, 0);\n\n\t \n\twr32(hw, ring->len, (num_entries | ring->len_ena_mask));\n\twr32(hw, ring->bal, lower_32_bits(ring->desc_buf.pa));\n\twr32(hw, ring->bah, upper_32_bits(ring->desc_buf.pa));\n\n\t \n\tif (rd32(hw, ring->bal) != lower_32_bits(ring->desc_buf.pa))\n\t\treturn -EIO;\n\n\treturn 0;\n}\n\n \nstatic int ice_cfg_sq_regs(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\treturn ice_cfg_cq_regs(hw, &cq->sq, cq->num_sq_entries);\n}\n\n \nstatic int ice_cfg_rq_regs(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tint status;\n\n\tstatus = ice_cfg_cq_regs(hw, &cq->rq, cq->num_rq_entries);\n\tif (status)\n\t\treturn status;\n\n\t \n\twr32(hw, cq->rq.tail, (u32)(cq->num_rq_entries - 1));\n\n\treturn 0;\n}\n\n#define ICE_FREE_CQ_BUFS(hw, qi, ring)\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\t \t\t\t\t\t\t\\\n\tif ((qi)->ring.r.ring##_bi) {\t\t\t\t\t\\\n\t\tint i;\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\tfor (i = 0; i < (qi)->num_##ring##_entries; i++)\t\\\n\t\t\tif ((qi)->ring.r.ring##_bi[i].pa) {\t\t\\\n\t\t\t\tdmam_free_coherent(ice_hw_to_dev(hw),\t\\\n\t\t\t\t\t(qi)->ring.r.ring##_bi[i].size,\t\\\n\t\t\t\t\t(qi)->ring.r.ring##_bi[i].va,\t\\\n\t\t\t\t\t(qi)->ring.r.ring##_bi[i].pa);\t\\\n\t\t\t\t\t(qi)->ring.r.ring##_bi[i].va = NULL;\\\n\t\t\t\t\t(qi)->ring.r.ring##_bi[i].pa = 0;\\\n\t\t\t\t\t(qi)->ring.r.ring##_bi[i].size = 0;\\\n\t\t}\t\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\tdevm_kfree(ice_hw_to_dev(hw), (qi)->ring.cmd_buf);\t\t\\\n\t \t\t\t\t\t\t\\\n\tdevm_kfree(ice_hw_to_dev(hw), (qi)->ring.dma_head);\t\t\\\n} while (0)\n\n \nstatic int ice_init_sq(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tint ret_code;\n\n\tif (cq->sq.count > 0) {\n\t\t \n\t\tret_code = -EBUSY;\n\t\tgoto init_ctrlq_exit;\n\t}\n\n\t \n\tif (!cq->num_sq_entries || !cq->sq_buf_size) {\n\t\tret_code = -EIO;\n\t\tgoto init_ctrlq_exit;\n\t}\n\n\tcq->sq.next_to_use = 0;\n\tcq->sq.next_to_clean = 0;\n\n\t \n\tret_code = ice_alloc_ctrlq_sq_ring(hw, cq);\n\tif (ret_code)\n\t\tgoto init_ctrlq_exit;\n\n\t \n\tret_code = ice_alloc_sq_bufs(hw, cq);\n\tif (ret_code)\n\t\tgoto init_ctrlq_free_rings;\n\n\t \n\tret_code = ice_cfg_sq_regs(hw, cq);\n\tif (ret_code)\n\t\tgoto init_ctrlq_free_rings;\n\n\t \n\tcq->sq.count = cq->num_sq_entries;\n\tgoto init_ctrlq_exit;\n\ninit_ctrlq_free_rings:\n\tICE_FREE_CQ_BUFS(hw, cq, sq);\n\tice_free_cq_ring(hw, &cq->sq);\n\ninit_ctrlq_exit:\n\treturn ret_code;\n}\n\n \nstatic int ice_init_rq(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tint ret_code;\n\n\tif (cq->rq.count > 0) {\n\t\t \n\t\tret_code = -EBUSY;\n\t\tgoto init_ctrlq_exit;\n\t}\n\n\t \n\tif (!cq->num_rq_entries || !cq->rq_buf_size) {\n\t\tret_code = -EIO;\n\t\tgoto init_ctrlq_exit;\n\t}\n\n\tcq->rq.next_to_use = 0;\n\tcq->rq.next_to_clean = 0;\n\n\t \n\tret_code = ice_alloc_ctrlq_rq_ring(hw, cq);\n\tif (ret_code)\n\t\tgoto init_ctrlq_exit;\n\n\t \n\tret_code = ice_alloc_rq_bufs(hw, cq);\n\tif (ret_code)\n\t\tgoto init_ctrlq_free_rings;\n\n\t \n\tret_code = ice_cfg_rq_regs(hw, cq);\n\tif (ret_code)\n\t\tgoto init_ctrlq_free_rings;\n\n\t \n\tcq->rq.count = cq->num_rq_entries;\n\tgoto init_ctrlq_exit;\n\ninit_ctrlq_free_rings:\n\tICE_FREE_CQ_BUFS(hw, cq, rq);\n\tice_free_cq_ring(hw, &cq->rq);\n\ninit_ctrlq_exit:\n\treturn ret_code;\n}\n\n \nstatic int ice_shutdown_sq(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tint ret_code = 0;\n\n\tmutex_lock(&cq->sq_lock);\n\n\tif (!cq->sq.count) {\n\t\tret_code = -EBUSY;\n\t\tgoto shutdown_sq_out;\n\t}\n\n\t \n\twr32(hw, cq->sq.head, 0);\n\twr32(hw, cq->sq.tail, 0);\n\twr32(hw, cq->sq.len, 0);\n\twr32(hw, cq->sq.bal, 0);\n\twr32(hw, cq->sq.bah, 0);\n\n\tcq->sq.count = 0;\t \n\n\t \n\tICE_FREE_CQ_BUFS(hw, cq, sq);\n\tice_free_cq_ring(hw, &cq->sq);\n\nshutdown_sq_out:\n\tmutex_unlock(&cq->sq_lock);\n\treturn ret_code;\n}\n\n \nstatic bool ice_aq_ver_check(struct ice_hw *hw)\n{\n\tif (hw->api_maj_ver > EXP_FW_API_VER_MAJOR) {\n\t\t \n\t\tdev_warn(ice_hw_to_dev(hw),\n\t\t\t \"The driver for the device stopped because the NVM image is newer than expected. You must install the most recent version of the network driver.\\n\");\n\t\treturn false;\n\t} else if (hw->api_maj_ver == EXP_FW_API_VER_MAJOR) {\n\t\tif (hw->api_min_ver > (EXP_FW_API_VER_MINOR + 2))\n\t\t\tdev_info(ice_hw_to_dev(hw),\n\t\t\t\t \"The driver for the device detected a newer version of the NVM image than expected. Please install the most recent version of the network driver.\\n\");\n\t\telse if ((hw->api_min_ver + 2) < EXP_FW_API_VER_MINOR)\n\t\t\tdev_info(ice_hw_to_dev(hw),\n\t\t\t\t \"The driver for the device detected an older version of the NVM image than expected. Please update the NVM image.\\n\");\n\t} else {\n\t\t \n\t\tdev_info(ice_hw_to_dev(hw),\n\t\t\t \"The driver for the device detected an older version of the NVM image than expected. Please update the NVM image.\\n\");\n\t}\n\treturn true;\n}\n\n \nstatic int ice_shutdown_rq(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tint ret_code = 0;\n\n\tmutex_lock(&cq->rq_lock);\n\n\tif (!cq->rq.count) {\n\t\tret_code = -EBUSY;\n\t\tgoto shutdown_rq_out;\n\t}\n\n\t \n\twr32(hw, cq->rq.head, 0);\n\twr32(hw, cq->rq.tail, 0);\n\twr32(hw, cq->rq.len, 0);\n\twr32(hw, cq->rq.bal, 0);\n\twr32(hw, cq->rq.bah, 0);\n\n\t \n\tcq->rq.count = 0;\n\n\t \n\tICE_FREE_CQ_BUFS(hw, cq, rq);\n\tice_free_cq_ring(hw, &cq->rq);\n\nshutdown_rq_out:\n\tmutex_unlock(&cq->rq_lock);\n\treturn ret_code;\n}\n\n \nstatic int ice_init_check_adminq(struct ice_hw *hw)\n{\n\tstruct ice_ctl_q_info *cq = &hw->adminq;\n\tint status;\n\n\tstatus = ice_aq_get_fw_ver(hw, NULL);\n\tif (status)\n\t\tgoto init_ctrlq_free_rq;\n\n\tif (!ice_aq_ver_check(hw)) {\n\t\tstatus = -EIO;\n\t\tgoto init_ctrlq_free_rq;\n\t}\n\n\treturn 0;\n\ninit_ctrlq_free_rq:\n\tice_shutdown_rq(hw, cq);\n\tice_shutdown_sq(hw, cq);\n\treturn status;\n}\n\n \nstatic int ice_init_ctrlq(struct ice_hw *hw, enum ice_ctl_q q_type)\n{\n\tstruct ice_ctl_q_info *cq;\n\tint ret_code;\n\n\tswitch (q_type) {\n\tcase ICE_CTL_Q_ADMIN:\n\t\tice_adminq_init_regs(hw);\n\t\tcq = &hw->adminq;\n\t\tbreak;\n\tcase ICE_CTL_Q_SB:\n\t\tice_sb_init_regs(hw);\n\t\tcq = &hw->sbq;\n\t\tbreak;\n\tcase ICE_CTL_Q_MAILBOX:\n\t\tice_mailbox_init_regs(hw);\n\t\tcq = &hw->mailboxq;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tcq->qtype = q_type;\n\n\t \n\tif (!cq->num_rq_entries || !cq->num_sq_entries ||\n\t    !cq->rq_buf_size || !cq->sq_buf_size) {\n\t\treturn -EIO;\n\t}\n\n\t \n\tret_code = ice_init_sq(hw, cq);\n\tif (ret_code)\n\t\treturn ret_code;\n\n\t \n\tret_code = ice_init_rq(hw, cq);\n\tif (ret_code)\n\t\tgoto init_ctrlq_free_sq;\n\n\t \n\treturn 0;\n\ninit_ctrlq_free_sq:\n\tice_shutdown_sq(hw, cq);\n\treturn ret_code;\n}\n\n \nbool ice_is_sbq_supported(struct ice_hw *hw)\n{\n\t \n\treturn hw->mac_type == ICE_MAC_GENERIC;\n}\n\n \nstruct ice_ctl_q_info *ice_get_sbq(struct ice_hw *hw)\n{\n\tif (ice_is_sbq_supported(hw))\n\t\treturn &hw->sbq;\n\treturn &hw->adminq;\n}\n\n \nstatic void ice_shutdown_ctrlq(struct ice_hw *hw, enum ice_ctl_q q_type)\n{\n\tstruct ice_ctl_q_info *cq;\n\n\tswitch (q_type) {\n\tcase ICE_CTL_Q_ADMIN:\n\t\tcq = &hw->adminq;\n\t\tif (ice_check_sq_alive(hw, cq))\n\t\t\tice_aq_q_shutdown(hw, true);\n\t\tbreak;\n\tcase ICE_CTL_Q_SB:\n\t\tcq = &hw->sbq;\n\t\tbreak;\n\tcase ICE_CTL_Q_MAILBOX:\n\t\tcq = &hw->mailboxq;\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\tice_shutdown_sq(hw, cq);\n\tice_shutdown_rq(hw, cq);\n}\n\n \nvoid ice_shutdown_all_ctrlq(struct ice_hw *hw)\n{\n\t \n\tice_shutdown_ctrlq(hw, ICE_CTL_Q_ADMIN);\n\t \n\tif (ice_is_sbq_supported(hw))\n\t\tice_shutdown_ctrlq(hw, ICE_CTL_Q_SB);\n\t \n\tice_shutdown_ctrlq(hw, ICE_CTL_Q_MAILBOX);\n}\n\n \nint ice_init_all_ctrlq(struct ice_hw *hw)\n{\n\tu32 retry = 0;\n\tint status;\n\n\t \n\tdo {\n\t\tstatus = ice_init_ctrlq(hw, ICE_CTL_Q_ADMIN);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tstatus = ice_init_check_adminq(hw);\n\t\tif (status != -EIO)\n\t\t\tbreak;\n\n\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Retry Admin Queue init due to FW critical error\\n\");\n\t\tice_shutdown_ctrlq(hw, ICE_CTL_Q_ADMIN);\n\t\tmsleep(ICE_CTL_Q_ADMIN_INIT_MSEC);\n\t} while (retry++ < ICE_CTL_Q_ADMIN_INIT_TIMEOUT);\n\n\tif (status)\n\t\treturn status;\n\t \n\tif (ice_is_sbq_supported(hw)) {\n\t\tstatus = ice_init_ctrlq(hw, ICE_CTL_Q_SB);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\t \n\treturn ice_init_ctrlq(hw, ICE_CTL_Q_MAILBOX);\n}\n\n \nstatic void ice_init_ctrlq_locks(struct ice_ctl_q_info *cq)\n{\n\tmutex_init(&cq->sq_lock);\n\tmutex_init(&cq->rq_lock);\n}\n\n \nint ice_create_all_ctrlq(struct ice_hw *hw)\n{\n\tice_init_ctrlq_locks(&hw->adminq);\n\tif (ice_is_sbq_supported(hw))\n\t\tice_init_ctrlq_locks(&hw->sbq);\n\tice_init_ctrlq_locks(&hw->mailboxq);\n\n\treturn ice_init_all_ctrlq(hw);\n}\n\n \nstatic void ice_destroy_ctrlq_locks(struct ice_ctl_q_info *cq)\n{\n\tmutex_destroy(&cq->sq_lock);\n\tmutex_destroy(&cq->rq_lock);\n}\n\n \nvoid ice_destroy_all_ctrlq(struct ice_hw *hw)\n{\n\t \n\tice_shutdown_all_ctrlq(hw);\n\n\tice_destroy_ctrlq_locks(&hw->adminq);\n\tif (ice_is_sbq_supported(hw))\n\t\tice_destroy_ctrlq_locks(&hw->sbq);\n\tice_destroy_ctrlq_locks(&hw->mailboxq);\n}\n\n \nstatic u16 ice_clean_sq(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\tstruct ice_ctl_q_ring *sq = &cq->sq;\n\tu16 ntc = sq->next_to_clean;\n\tstruct ice_sq_cd *details;\n\tstruct ice_aq_desc *desc;\n\n\tdesc = ICE_CTL_Q_DESC(*sq, ntc);\n\tdetails = ICE_CTL_Q_DETAILS(*sq, ntc);\n\n\twhile (rd32(hw, cq->sq.head) != ntc) {\n\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"ntc %d head %d.\\n\", ntc, rd32(hw, cq->sq.head));\n\t\tmemset(desc, 0, sizeof(*desc));\n\t\tmemset(details, 0, sizeof(*details));\n\t\tntc++;\n\t\tif (ntc == sq->count)\n\t\t\tntc = 0;\n\t\tdesc = ICE_CTL_Q_DESC(*sq, ntc);\n\t\tdetails = ICE_CTL_Q_DETAILS(*sq, ntc);\n\t}\n\n\tsq->next_to_clean = ntc;\n\n\treturn ICE_CTL_Q_DESC_UNUSED(sq);\n}\n\n \nstatic void ice_debug_cq(struct ice_hw *hw, void *desc, void *buf, u16 buf_len)\n{\n\tstruct ice_aq_desc *cq_desc = desc;\n\tu16 len;\n\n\tif (!IS_ENABLED(CONFIG_DYNAMIC_DEBUG) &&\n\t    !((ICE_DBG_AQ_DESC | ICE_DBG_AQ_DESC_BUF) & hw->debug_mask))\n\t\treturn;\n\n\tif (!desc)\n\t\treturn;\n\n\tlen = le16_to_cpu(cq_desc->datalen);\n\n\tice_debug(hw, ICE_DBG_AQ_DESC, \"CQ CMD: opcode 0x%04X, flags 0x%04X, datalen 0x%04X, retval 0x%04X\\n\",\n\t\t  le16_to_cpu(cq_desc->opcode),\n\t\t  le16_to_cpu(cq_desc->flags),\n\t\t  le16_to_cpu(cq_desc->datalen), le16_to_cpu(cq_desc->retval));\n\tice_debug(hw, ICE_DBG_AQ_DESC, \"\\tcookie (h,l) 0x%08X 0x%08X\\n\",\n\t\t  le32_to_cpu(cq_desc->cookie_high),\n\t\t  le32_to_cpu(cq_desc->cookie_low));\n\tice_debug(hw, ICE_DBG_AQ_DESC, \"\\tparam (0,1)  0x%08X 0x%08X\\n\",\n\t\t  le32_to_cpu(cq_desc->params.generic.param0),\n\t\t  le32_to_cpu(cq_desc->params.generic.param1));\n\tice_debug(hw, ICE_DBG_AQ_DESC, \"\\taddr (h,l)   0x%08X 0x%08X\\n\",\n\t\t  le32_to_cpu(cq_desc->params.generic.addr_high),\n\t\t  le32_to_cpu(cq_desc->params.generic.addr_low));\n\tif (buf && cq_desc->datalen != 0) {\n\t\tice_debug(hw, ICE_DBG_AQ_DESC_BUF, \"Buffer:\\n\");\n\t\tif (buf_len < len)\n\t\t\tlen = buf_len;\n\n\t\tice_debug_array(hw, ICE_DBG_AQ_DESC_BUF, 16, 1, buf, len);\n\t}\n}\n\n \nstatic bool ice_sq_done(struct ice_hw *hw, struct ice_ctl_q_info *cq)\n{\n\t \n\treturn rd32(hw, cq->sq.head) == cq->sq.next_to_use;\n}\n\n \nint\nice_sq_send_cmd(struct ice_hw *hw, struct ice_ctl_q_info *cq,\n\t\tstruct ice_aq_desc *desc, void *buf, u16 buf_size,\n\t\tstruct ice_sq_cd *cd)\n{\n\tstruct ice_dma_mem *dma_buf = NULL;\n\tstruct ice_aq_desc *desc_on_ring;\n\tbool cmd_completed = false;\n\tstruct ice_sq_cd *details;\n\tunsigned long timeout;\n\tint status = 0;\n\tu16 retval = 0;\n\tu32 val = 0;\n\n\t \n\tif (hw->reset_ongoing)\n\t\treturn -EBUSY;\n\tmutex_lock(&cq->sq_lock);\n\n\tcq->sq_last_status = ICE_AQ_RC_OK;\n\n\tif (!cq->sq.count) {\n\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Control Send queue not initialized.\\n\");\n\t\tstatus = -EIO;\n\t\tgoto sq_send_command_error;\n\t}\n\n\tif ((buf && !buf_size) || (!buf && buf_size)) {\n\t\tstatus = -EINVAL;\n\t\tgoto sq_send_command_error;\n\t}\n\n\tif (buf) {\n\t\tif (buf_size > cq->sq_buf_size) {\n\t\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Invalid buffer size for Control Send queue: %d.\\n\",\n\t\t\t\t  buf_size);\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto sq_send_command_error;\n\t\t}\n\n\t\tdesc->flags |= cpu_to_le16(ICE_AQ_FLAG_BUF);\n\t\tif (buf_size > ICE_AQ_LG_BUF)\n\t\t\tdesc->flags |= cpu_to_le16(ICE_AQ_FLAG_LB);\n\t}\n\n\tval = rd32(hw, cq->sq.head);\n\tif (val >= cq->num_sq_entries) {\n\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"head overrun at %d in the Control Send Queue ring\\n\",\n\t\t\t  val);\n\t\tstatus = -EIO;\n\t\tgoto sq_send_command_error;\n\t}\n\n\tdetails = ICE_CTL_Q_DETAILS(cq->sq, cq->sq.next_to_use);\n\tif (cd)\n\t\t*details = *cd;\n\telse\n\t\tmemset(details, 0, sizeof(*details));\n\n\t \n\tif (ice_clean_sq(hw, cq) == 0) {\n\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Error: Control Send Queue is full.\\n\");\n\t\tstatus = -ENOSPC;\n\t\tgoto sq_send_command_error;\n\t}\n\n\t \n\tdesc_on_ring = ICE_CTL_Q_DESC(cq->sq, cq->sq.next_to_use);\n\n\t \n\tmemcpy(desc_on_ring, desc, sizeof(*desc_on_ring));\n\n\t \n\tif (buf) {\n\t\tdma_buf = &cq->sq.r.sq_bi[cq->sq.next_to_use];\n\t\t \n\t\tmemcpy(dma_buf->va, buf, buf_size);\n\t\tdesc_on_ring->datalen = cpu_to_le16(buf_size);\n\n\t\t \n\t\tdesc_on_ring->params.generic.addr_high =\n\t\t\tcpu_to_le32(upper_32_bits(dma_buf->pa));\n\t\tdesc_on_ring->params.generic.addr_low =\n\t\t\tcpu_to_le32(lower_32_bits(dma_buf->pa));\n\t}\n\n\t \n\tice_debug(hw, ICE_DBG_AQ_DESC, \"ATQ: Control Send queue desc and buffer:\\n\");\n\n\tice_debug_cq(hw, (void *)desc_on_ring, buf, buf_size);\n\n\t(cq->sq.next_to_use)++;\n\tif (cq->sq.next_to_use == cq->sq.count)\n\t\tcq->sq.next_to_use = 0;\n\twr32(hw, cq->sq.tail, cq->sq.next_to_use);\n\tice_flush(hw);\n\n\t \n\tudelay(5);\n\n\ttimeout = jiffies + ICE_CTL_Q_SQ_CMD_TIMEOUT;\n\tdo {\n\t\tif (ice_sq_done(hw, cq))\n\t\t\tbreak;\n\n\t\tusleep_range(100, 150);\n\t} while (time_before(jiffies, timeout));\n\n\t \n\tif (ice_sq_done(hw, cq)) {\n\t\tmemcpy(desc, desc_on_ring, sizeof(*desc));\n\t\tif (buf) {\n\t\t\t \n\t\t\tu16 copy_size = le16_to_cpu(desc->datalen);\n\n\t\t\tif (copy_size > buf_size) {\n\t\t\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Return len %d > than buf len %d\\n\",\n\t\t\t\t\t  copy_size, buf_size);\n\t\t\t\tstatus = -EIO;\n\t\t\t} else {\n\t\t\t\tmemcpy(buf, dma_buf->va, copy_size);\n\t\t\t}\n\t\t}\n\t\tretval = le16_to_cpu(desc->retval);\n\t\tif (retval) {\n\t\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Control Send Queue command 0x%04X completed with error 0x%X\\n\",\n\t\t\t\t  le16_to_cpu(desc->opcode),\n\t\t\t\t  retval);\n\n\t\t\t \n\t\t\tretval &= 0xff;\n\t\t}\n\t\tcmd_completed = true;\n\t\tif (!status && retval != ICE_AQ_RC_OK)\n\t\t\tstatus = -EIO;\n\t\tcq->sq_last_status = (enum ice_aq_err)retval;\n\t}\n\n\tice_debug(hw, ICE_DBG_AQ_MSG, \"ATQ: desc and buffer writeback:\\n\");\n\n\tice_debug_cq(hw, (void *)desc, buf, buf_size);\n\n\t \n\tif (details->wb_desc)\n\t\tmemcpy(details->wb_desc, desc_on_ring,\n\t\t       sizeof(*details->wb_desc));\n\n\t \n\tif (!cmd_completed) {\n\t\tif (rd32(hw, cq->rq.len) & cq->rq.len_crit_mask ||\n\t\t    rd32(hw, cq->sq.len) & cq->sq.len_crit_mask) {\n\t\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Critical FW error.\\n\");\n\t\t\tstatus = -EIO;\n\t\t} else {\n\t\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Control Send Queue Writeback timeout.\\n\");\n\t\t\tstatus = -EIO;\n\t\t}\n\t}\n\nsq_send_command_error:\n\tmutex_unlock(&cq->sq_lock);\n\treturn status;\n}\n\n \nvoid ice_fill_dflt_direct_cmd_desc(struct ice_aq_desc *desc, u16 opcode)\n{\n\t \n\tmemset(desc, 0, sizeof(*desc));\n\tdesc->opcode = cpu_to_le16(opcode);\n\tdesc->flags = cpu_to_le16(ICE_AQ_FLAG_SI);\n}\n\n \nint\nice_clean_rq_elem(struct ice_hw *hw, struct ice_ctl_q_info *cq,\n\t\t  struct ice_rq_event_info *e, u16 *pending)\n{\n\tu16 ntc = cq->rq.next_to_clean;\n\tenum ice_aq_err rq_last_status;\n\tstruct ice_aq_desc *desc;\n\tstruct ice_dma_mem *bi;\n\tint ret_code = 0;\n\tu16 desc_idx;\n\tu16 datalen;\n\tu16 flags;\n\tu16 ntu;\n\n\t \n\tmemset(&e->desc, 0, sizeof(e->desc));\n\n\t \n\tmutex_lock(&cq->rq_lock);\n\n\tif (!cq->rq.count) {\n\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Control Receive queue not initialized.\\n\");\n\t\tret_code = -EIO;\n\t\tgoto clean_rq_elem_err;\n\t}\n\n\t \n\tntu = (u16)(rd32(hw, cq->rq.head) & cq->rq.head_mask);\n\n\tif (ntu == ntc) {\n\t\t \n\t\tret_code = -EALREADY;\n\t\tgoto clean_rq_elem_out;\n\t}\n\n\t \n\tdesc = ICE_CTL_Q_DESC(cq->rq, ntc);\n\tdesc_idx = ntc;\n\n\trq_last_status = (enum ice_aq_err)le16_to_cpu(desc->retval);\n\tflags = le16_to_cpu(desc->flags);\n\tif (flags & ICE_AQ_FLAG_ERR) {\n\t\tret_code = -EIO;\n\t\tice_debug(hw, ICE_DBG_AQ_MSG, \"Control Receive Queue Event 0x%04X received with error 0x%X\\n\",\n\t\t\t  le16_to_cpu(desc->opcode), rq_last_status);\n\t}\n\tmemcpy(&e->desc, desc, sizeof(e->desc));\n\tdatalen = le16_to_cpu(desc->datalen);\n\te->msg_len = min_t(u16, datalen, e->buf_len);\n\tif (e->msg_buf && e->msg_len)\n\t\tmemcpy(e->msg_buf, cq->rq.r.rq_bi[desc_idx].va, e->msg_len);\n\n\tice_debug(hw, ICE_DBG_AQ_DESC, \"ARQ: desc and buffer:\\n\");\n\n\tice_debug_cq(hw, (void *)desc, e->msg_buf, cq->rq_buf_size);\n\n\t \n\tbi = &cq->rq.r.rq_bi[ntc];\n\tmemset(desc, 0, sizeof(*desc));\n\n\tdesc->flags = cpu_to_le16(ICE_AQ_FLAG_BUF);\n\tif (cq->rq_buf_size > ICE_AQ_LG_BUF)\n\t\tdesc->flags |= cpu_to_le16(ICE_AQ_FLAG_LB);\n\tdesc->datalen = cpu_to_le16(bi->size);\n\tdesc->params.generic.addr_high = cpu_to_le32(upper_32_bits(bi->pa));\n\tdesc->params.generic.addr_low = cpu_to_le32(lower_32_bits(bi->pa));\n\n\t \n\twr32(hw, cq->rq.tail, ntc);\n\t \n\tntc++;\n\tif (ntc == cq->num_rq_entries)\n\t\tntc = 0;\n\tcq->rq.next_to_clean = ntc;\n\tcq->rq.next_to_use = ntu;\n\nclean_rq_elem_out:\n\t \n\tif (pending) {\n\t\t \n\t\tntu = (u16)(rd32(hw, cq->rq.head) & cq->rq.head_mask);\n\t\t*pending = (u16)((ntc > ntu ? cq->rq.count : 0) + (ntu - ntc));\n\t}\nclean_rq_elem_err:\n\tmutex_unlock(&cq->rq_lock);\n\n\treturn ret_code;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}