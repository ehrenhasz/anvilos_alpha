{
  "module_name": "ice_idc.c",
  "hash_id": "6ef13416ab8f7a2b358291e182bb2d12c21658c0d715da69c628deea68b22048",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_idc.c",
  "human_readable_source": "\n \n\n \n#include \"ice.h\"\n#include \"ice_lib.h\"\n#include \"ice_dcb_lib.h\"\n\nstatic DEFINE_XARRAY_ALLOC1(ice_aux_id);\n\n \nstatic struct iidc_auxiliary_drv *ice_get_auxiliary_drv(struct ice_pf *pf)\n{\n\tstruct auxiliary_device *adev;\n\n\tadev = pf->adev;\n\tif (!adev || !adev->dev.driver)\n\t\treturn NULL;\n\n\treturn container_of(adev->dev.driver, struct iidc_auxiliary_drv,\n\t\t\t    adrv.driver);\n}\n\n \nvoid ice_send_event_to_aux(struct ice_pf *pf, struct iidc_event *event)\n{\n\tstruct iidc_auxiliary_drv *iadrv;\n\n\tif (WARN_ON_ONCE(!in_task()))\n\t\treturn;\n\n\tmutex_lock(&pf->adev_mutex);\n\tif (!pf->adev)\n\t\tgoto finish;\n\n\tdevice_lock(&pf->adev->dev);\n\tiadrv = ice_get_auxiliary_drv(pf);\n\tif (iadrv && iadrv->event_handler)\n\t\tiadrv->event_handler(pf, event);\n\tdevice_unlock(&pf->adev->dev);\nfinish:\n\tmutex_unlock(&pf->adev_mutex);\n}\n\n \nint ice_add_rdma_qset(struct ice_pf *pf, struct iidc_rdma_qset_params *qset)\n{\n\tu16 max_rdmaqs[ICE_MAX_TRAFFIC_CLASS];\n\tstruct ice_vsi *vsi;\n\tstruct device *dev;\n\tu32 qset_teid;\n\tu16 qs_handle;\n\tint status;\n\tint i;\n\n\tif (WARN_ON(!pf || !qset))\n\t\treturn -EINVAL;\n\n\tdev = ice_pf_to_dev(pf);\n\n\tif (!ice_is_rdma_ena(pf))\n\t\treturn -EINVAL;\n\n\tvsi = ice_get_main_vsi(pf);\n\tif (!vsi) {\n\t\tdev_err(dev, \"RDMA QSet invalid VSI\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tice_for_each_traffic_class(i)\n\t\tmax_rdmaqs[i] = 0;\n\n\tmax_rdmaqs[qset->tc]++;\n\tqs_handle = qset->qs_handle;\n\n\tstatus = ice_cfg_vsi_rdma(vsi->port_info, vsi->idx, vsi->tc_cfg.ena_tc,\n\t\t\t\t  max_rdmaqs);\n\tif (status) {\n\t\tdev_err(dev, \"Failed VSI RDMA Qset config\\n\");\n\t\treturn status;\n\t}\n\n\tstatus = ice_ena_vsi_rdma_qset(vsi->port_info, vsi->idx, qset->tc,\n\t\t\t\t       &qs_handle, 1, &qset_teid);\n\tif (status) {\n\t\tdev_err(dev, \"Failed VSI RDMA Qset enable\\n\");\n\t\treturn status;\n\t}\n\tvsi->qset_handle[qset->tc] = qset->qs_handle;\n\tqset->teid = qset_teid;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(ice_add_rdma_qset);\n\n \nint ice_del_rdma_qset(struct ice_pf *pf, struct iidc_rdma_qset_params *qset)\n{\n\tstruct ice_vsi *vsi;\n\tu32 teid;\n\tu16 q_id;\n\n\tif (WARN_ON(!pf || !qset))\n\t\treturn -EINVAL;\n\n\tvsi = ice_find_vsi(pf, qset->vport_id);\n\tif (!vsi) {\n\t\tdev_err(ice_pf_to_dev(pf), \"RDMA Invalid VSI\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tq_id = qset->qs_handle;\n\tteid = qset->teid;\n\n\tvsi->qset_handle[qset->tc] = 0;\n\n\treturn ice_dis_vsi_rdma_qset(vsi->port_info, 1, &teid, &q_id);\n}\nEXPORT_SYMBOL_GPL(ice_del_rdma_qset);\n\n \nint ice_rdma_request_reset(struct ice_pf *pf, enum iidc_reset_type reset_type)\n{\n\tenum ice_reset_req reset;\n\n\tif (WARN_ON(!pf))\n\t\treturn -EINVAL;\n\n\tswitch (reset_type) {\n\tcase IIDC_PFR:\n\t\treset = ICE_RESET_PFR;\n\t\tbreak;\n\tcase IIDC_CORER:\n\t\treset = ICE_RESET_CORER;\n\t\tbreak;\n\tcase IIDC_GLOBR:\n\t\treset = ICE_RESET_GLOBR;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(ice_pf_to_dev(pf), \"incorrect reset request\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn ice_schedule_reset(pf, reset);\n}\nEXPORT_SYMBOL_GPL(ice_rdma_request_reset);\n\n \nint ice_rdma_update_vsi_filter(struct ice_pf *pf, u16 vsi_id, bool enable)\n{\n\tstruct ice_vsi *vsi;\n\tint status;\n\n\tif (WARN_ON(!pf))\n\t\treturn -EINVAL;\n\n\tvsi = ice_find_vsi(pf, vsi_id);\n\tif (!vsi)\n\t\treturn -EINVAL;\n\n\tstatus = ice_cfg_rdma_fltr(&pf->hw, vsi->idx, enable);\n\tif (status) {\n\t\tdev_err(ice_pf_to_dev(pf), \"Failed to  %sable RDMA filtering\\n\",\n\t\t\tenable ? \"en\" : \"dis\");\n\t} else {\n\t\tif (enable)\n\t\t\tvsi->info.q_opt_flags |= ICE_AQ_VSI_Q_OPT_PE_FLTR_EN;\n\t\telse\n\t\t\tvsi->info.q_opt_flags &= ~ICE_AQ_VSI_Q_OPT_PE_FLTR_EN;\n\t}\n\n\treturn status;\n}\nEXPORT_SYMBOL_GPL(ice_rdma_update_vsi_filter);\n\n \nvoid ice_get_qos_params(struct ice_pf *pf, struct iidc_qos_params *qos)\n{\n\tstruct ice_dcbx_cfg *dcbx_cfg;\n\tunsigned int i;\n\tu32 up2tc;\n\n\tdcbx_cfg = &pf->hw.port_info->qos_cfg.local_dcbx_cfg;\n\tup2tc = rd32(&pf->hw, PRTDCB_TUP2TC);\n\n\tqos->num_tc = ice_dcb_get_num_tc(dcbx_cfg);\n\tfor (i = 0; i < IIDC_MAX_USER_PRIORITY; i++)\n\t\tqos->up2tc[i] = (up2tc >> (i * 3)) & 0x7;\n\n\tfor (i = 0; i < IEEE_8021QAZ_MAX_TCS; i++)\n\t\tqos->tc_info[i].rel_bw = dcbx_cfg->etscfg.tcbwtable[i];\n\n\tqos->pfc_mode = dcbx_cfg->pfc_mode;\n\tif (qos->pfc_mode == IIDC_DSCP_PFC_MODE)\n\t\tfor (i = 0; i < IIDC_MAX_DSCP_MAPPING; i++)\n\t\t\tqos->dscp_map[i] = dcbx_cfg->dscp_map[i];\n}\nEXPORT_SYMBOL_GPL(ice_get_qos_params);\n\n \nstatic int ice_alloc_rdma_qvectors(struct ice_pf *pf)\n{\n\tif (ice_is_rdma_ena(pf)) {\n\t\tint i;\n\n\t\tpf->msix_entries = kcalloc(pf->num_rdma_msix,\n\t\t\t\t\t   sizeof(*pf->msix_entries),\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!pf->msix_entries)\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\tpf->rdma_base_vector = 0;\n\n\t\tfor (i = 0; i < pf->num_rdma_msix; i++) {\n\t\t\tstruct msix_entry *entry = &pf->msix_entries[i];\n\t\t\tstruct msi_map map;\n\n\t\t\tmap = ice_alloc_irq(pf, false);\n\t\t\tif (map.index < 0)\n\t\t\t\tbreak;\n\n\t\t\tentry->entry = map.index;\n\t\t\tentry->vector = map.virq;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic void ice_free_rdma_qvector(struct ice_pf *pf)\n{\n\tint i;\n\n\tif (!pf->msix_entries)\n\t\treturn;\n\n\tfor (i = 0; i < pf->num_rdma_msix; i++) {\n\t\tstruct msi_map map;\n\n\t\tmap.index = pf->msix_entries[i].entry;\n\t\tmap.virq = pf->msix_entries[i].vector;\n\t\tice_free_irq(pf, map);\n\t}\n\n\tkfree(pf->msix_entries);\n\tpf->msix_entries = NULL;\n}\n\n \nstatic void ice_adev_release(struct device *dev)\n{\n\tstruct iidc_auxiliary_dev *iadev;\n\n\tiadev = container_of(dev, struct iidc_auxiliary_dev, adev.dev);\n\tkfree(iadev);\n}\n\n \nint ice_plug_aux_dev(struct ice_pf *pf)\n{\n\tstruct iidc_auxiliary_dev *iadev;\n\tstruct auxiliary_device *adev;\n\tint ret;\n\n\t \n\tif (!ice_is_rdma_ena(pf))\n\t\treturn 0;\n\n\tiadev = kzalloc(sizeof(*iadev), GFP_KERNEL);\n\tif (!iadev)\n\t\treturn -ENOMEM;\n\n\tadev = &iadev->adev;\n\tiadev->pf = pf;\n\n\tadev->id = pf->aux_idx;\n\tadev->dev.release = ice_adev_release;\n\tadev->dev.parent = &pf->pdev->dev;\n\tadev->name = pf->rdma_mode & IIDC_RDMA_PROTOCOL_ROCEV2 ? \"roce\" : \"iwarp\";\n\n\tret = auxiliary_device_init(adev);\n\tif (ret) {\n\t\tkfree(iadev);\n\t\treturn ret;\n\t}\n\n\tret = auxiliary_device_add(adev);\n\tif (ret) {\n\t\tauxiliary_device_uninit(adev);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&pf->adev_mutex);\n\tpf->adev = adev;\n\tmutex_unlock(&pf->adev_mutex);\n\n\treturn 0;\n}\n\n \nvoid ice_unplug_aux_dev(struct ice_pf *pf)\n{\n\tstruct auxiliary_device *adev;\n\n\tmutex_lock(&pf->adev_mutex);\n\tadev = pf->adev;\n\tpf->adev = NULL;\n\tmutex_unlock(&pf->adev_mutex);\n\n\tif (adev) {\n\t\tauxiliary_device_delete(adev);\n\t\tauxiliary_device_uninit(adev);\n\t}\n}\n\n \nint ice_init_rdma(struct ice_pf *pf)\n{\n\tstruct device *dev = &pf->pdev->dev;\n\tint ret;\n\n\tif (!ice_is_rdma_ena(pf)) {\n\t\tdev_warn(dev, \"RDMA is not supported on this device\\n\");\n\t\treturn 0;\n\t}\n\n\tret = xa_alloc(&ice_aux_id, &pf->aux_idx, NULL, XA_LIMIT(1, INT_MAX),\n\t\t       GFP_KERNEL);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to allocate device ID for AUX driver\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tret = ice_alloc_rdma_qvectors(pf);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"failed to reserve vectors for RDMA\\n\");\n\t\tgoto err_reserve_rdma_qvector;\n\t}\n\tpf->rdma_mode |= IIDC_RDMA_PROTOCOL_ROCEV2;\n\tret = ice_plug_aux_dev(pf);\n\tif (ret)\n\t\tgoto err_plug_aux_dev;\n\treturn 0;\n\nerr_plug_aux_dev:\n\tice_free_rdma_qvector(pf);\nerr_reserve_rdma_qvector:\n\tpf->adev = NULL;\n\txa_erase(&ice_aux_id, pf->aux_idx);\n\treturn ret;\n}\n\n \nvoid ice_deinit_rdma(struct ice_pf *pf)\n{\n\tif (!ice_is_rdma_ena(pf))\n\t\treturn;\n\n\tice_unplug_aux_dev(pf);\n\tice_free_rdma_qvector(pf);\n\txa_erase(&ice_aux_id, pf->aux_idx);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}