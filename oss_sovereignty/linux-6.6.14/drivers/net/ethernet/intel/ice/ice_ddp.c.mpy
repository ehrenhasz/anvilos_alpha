{
  "module_name": "ice_ddp.c",
  "hash_id": "9760cea036c4d22c793bb4ab57404a6cc726b7b20bceed2cb31fff22444ce398",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_ddp.c",
  "human_readable_source": "\n \n\n#include \"ice_common.h\"\n#include \"ice.h\"\n#include \"ice_ddp.h\"\n\n \n#define ICE_DVM_PRE \"BOOST_MAC_VLAN_DVM\"  \n#define ICE_SVM_PRE \"BOOST_MAC_VLAN_SVM\"  \n\n \n#define ICE_TNL_PRE \"TNL_\"\nstatic const struct ice_tunnel_type_scan tnls[] = {\n\t{ TNL_VXLAN, \"TNL_VXLAN_PF\" },\n\t{ TNL_GENEVE, \"TNL_GENEVE_PF\" },\n\t{ TNL_LAST, \"\" }\n};\n\n \nstatic enum ice_ddp_state ice_verify_pkg(struct ice_pkg_hdr *pkg, u32 len)\n{\n\tu32 seg_count;\n\tu32 i;\n\n\tif (len < struct_size(pkg, seg_offset, 1))\n\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\n\tif (pkg->pkg_format_ver.major != ICE_PKG_FMT_VER_MAJ ||\n\t    pkg->pkg_format_ver.minor != ICE_PKG_FMT_VER_MNR ||\n\t    pkg->pkg_format_ver.update != ICE_PKG_FMT_VER_UPD ||\n\t    pkg->pkg_format_ver.draft != ICE_PKG_FMT_VER_DFT)\n\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\n\t \n\tseg_count = le32_to_cpu(pkg->seg_count);\n\tif (seg_count < 1)\n\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\n\t \n\tif (len < struct_size(pkg, seg_offset, seg_count))\n\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\n\t \n\tfor (i = 0; i < seg_count; i++) {\n\t\tu32 off = le32_to_cpu(pkg->seg_offset[i]);\n\t\tstruct ice_generic_seg_hdr *seg;\n\n\t\t \n\t\tif (len < off + sizeof(*seg))\n\t\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\n\t\tseg = (struct ice_generic_seg_hdr *)((u8 *)pkg + off);\n\n\t\t \n\t\tif (len < off + le32_to_cpu(seg->seg_size))\n\t\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\t}\n\n\treturn ICE_DDP_PKG_SUCCESS;\n}\n\n \nvoid ice_free_seg(struct ice_hw *hw)\n{\n\tif (hw->pkg_copy) {\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->pkg_copy);\n\t\thw->pkg_copy = NULL;\n\t\thw->pkg_size = 0;\n\t}\n\thw->seg = NULL;\n}\n\n \nstatic enum ice_ddp_state ice_chk_pkg_version(struct ice_pkg_ver *pkg_ver)\n{\n\tif (pkg_ver->major > ICE_PKG_SUPP_VER_MAJ ||\n\t    (pkg_ver->major == ICE_PKG_SUPP_VER_MAJ &&\n\t     pkg_ver->minor > ICE_PKG_SUPP_VER_MNR))\n\t\treturn ICE_DDP_PKG_FILE_VERSION_TOO_HIGH;\n\telse if (pkg_ver->major < ICE_PKG_SUPP_VER_MAJ ||\n\t\t (pkg_ver->major == ICE_PKG_SUPP_VER_MAJ &&\n\t\t  pkg_ver->minor < ICE_PKG_SUPP_VER_MNR))\n\t\treturn ICE_DDP_PKG_FILE_VERSION_TOO_LOW;\n\n\treturn ICE_DDP_PKG_SUCCESS;\n}\n\n \nstatic struct ice_buf_hdr *ice_pkg_val_buf(struct ice_buf *buf)\n{\n\tstruct ice_buf_hdr *hdr;\n\tu16 section_count;\n\tu16 data_end;\n\n\thdr = (struct ice_buf_hdr *)buf->buf;\n\t \n\tsection_count = le16_to_cpu(hdr->section_count);\n\tif (section_count < ICE_MIN_S_COUNT || section_count > ICE_MAX_S_COUNT)\n\t\treturn NULL;\n\n\tdata_end = le16_to_cpu(hdr->data_end);\n\tif (data_end < ICE_MIN_S_DATA_END || data_end > ICE_MAX_S_DATA_END)\n\t\treturn NULL;\n\n\treturn hdr;\n}\n\n \nstatic struct ice_buf_table *ice_find_buf_table(struct ice_seg *ice_seg)\n{\n\tstruct ice_nvm_table *nvms = (struct ice_nvm_table *)\n\t\t(ice_seg->device_table + le32_to_cpu(ice_seg->device_table_count));\n\n\treturn (__force struct ice_buf_table *)(nvms->vers +\n\t\t\t\t\t\tle32_to_cpu(nvms->table_count));\n}\n\n \nstatic struct ice_buf_hdr *ice_pkg_enum_buf(struct ice_seg *ice_seg,\n\t\t\t\t\t    struct ice_pkg_enum *state)\n{\n\tif (ice_seg) {\n\t\tstate->buf_table = ice_find_buf_table(ice_seg);\n\t\tif (!state->buf_table)\n\t\t\treturn NULL;\n\n\t\tstate->buf_idx = 0;\n\t\treturn ice_pkg_val_buf(state->buf_table->buf_array);\n\t}\n\n\tif (++state->buf_idx < le32_to_cpu(state->buf_table->buf_count))\n\t\treturn ice_pkg_val_buf(state->buf_table->buf_array +\n\t\t\t\t       state->buf_idx);\n\telse\n\t\treturn NULL;\n}\n\n \nstatic bool ice_pkg_advance_sect(struct ice_seg *ice_seg,\n\t\t\t\t struct ice_pkg_enum *state)\n{\n\tif (!ice_seg && !state->buf)\n\t\treturn false;\n\n\tif (!ice_seg && state->buf)\n\t\tif (++state->sect_idx < le16_to_cpu(state->buf->section_count))\n\t\t\treturn true;\n\n\tstate->buf = ice_pkg_enum_buf(ice_seg, state);\n\tif (!state->buf)\n\t\treturn false;\n\n\t \n\tstate->sect_idx = 0;\n\treturn true;\n}\n\n \nvoid *ice_pkg_enum_section(struct ice_seg *ice_seg, struct ice_pkg_enum *state,\n\t\t\t   u32 sect_type)\n{\n\tu16 offset, size;\n\n\tif (ice_seg)\n\t\tstate->type = sect_type;\n\n\tif (!ice_pkg_advance_sect(ice_seg, state))\n\t\treturn NULL;\n\n\t \n\twhile (state->buf->section_entry[state->sect_idx].type !=\n\t       cpu_to_le32(state->type))\n\t\tif (!ice_pkg_advance_sect(NULL, state))\n\t\t\treturn NULL;\n\n\t \n\toffset = le16_to_cpu(state->buf->section_entry[state->sect_idx].offset);\n\tif (offset < ICE_MIN_S_OFF || offset > ICE_MAX_S_OFF)\n\t\treturn NULL;\n\n\tsize = le16_to_cpu(state->buf->section_entry[state->sect_idx].size);\n\tif (size < ICE_MIN_S_SZ || size > ICE_MAX_S_SZ)\n\t\treturn NULL;\n\n\t \n\tif (offset + size > ICE_PKG_BUF_SIZE)\n\t\treturn NULL;\n\n\tstate->sect_type =\n\t\tle32_to_cpu(state->buf->section_entry[state->sect_idx].type);\n\n\t \n\tstate->sect =\n\t\t((u8 *)state->buf) +\n\t\tle16_to_cpu(state->buf->section_entry[state->sect_idx].offset);\n\n\treturn state->sect;\n}\n\n \nstatic void *ice_pkg_enum_entry(struct ice_seg *ice_seg,\n\t\t\t\tstruct ice_pkg_enum *state, u32 sect_type,\n\t\t\t\tu32 *offset,\n\t\t\t\tvoid *(*handler)(u32 sect_type, void *section,\n\t\t\t\t\t\t u32 index, u32 *offset))\n{\n\tvoid *entry;\n\n\tif (ice_seg) {\n\t\tif (!handler)\n\t\t\treturn NULL;\n\n\t\tif (!ice_pkg_enum_section(ice_seg, state, sect_type))\n\t\t\treturn NULL;\n\n\t\tstate->entry_idx = 0;\n\t\tstate->handler = handler;\n\t} else {\n\t\tstate->entry_idx++;\n\t}\n\n\tif (!state->handler)\n\t\treturn NULL;\n\n\t \n\tentry = state->handler(state->sect_type, state->sect, state->entry_idx,\n\t\t\t       offset);\n\tif (!entry) {\n\t\t \n\t\tif (!ice_pkg_enum_section(NULL, state, 0))\n\t\t\treturn NULL;\n\n\t\tstate->entry_idx = 0;\n\t\tentry = state->handler(state->sect_type, state->sect,\n\t\t\t\t       state->entry_idx, offset);\n\t}\n\n\treturn entry;\n}\n\n \nstatic void *ice_sw_fv_handler(u32 sect_type, void *section, u32 index,\n\t\t\t       u32 *offset)\n{\n\tstruct ice_sw_fv_section *fv_section = section;\n\n\tif (!section || sect_type != ICE_SID_FLD_VEC_SW)\n\t\treturn NULL;\n\tif (index >= le16_to_cpu(fv_section->count))\n\t\treturn NULL;\n\tif (offset)\n\t\t \n\t\t*offset = le16_to_cpu(fv_section->base_offset) + index;\n\treturn fv_section->fv + index;\n}\n\n \nstatic int ice_get_prof_index_max(struct ice_hw *hw)\n{\n\tu16 prof_index = 0, j, max_prof_index = 0;\n\tstruct ice_pkg_enum state;\n\tstruct ice_seg *ice_seg;\n\tbool flag = false;\n\tstruct ice_fv *fv;\n\tu32 offset;\n\n\tmemset(&state, 0, sizeof(state));\n\n\tif (!hw->seg)\n\t\treturn -EINVAL;\n\n\tice_seg = hw->seg;\n\n\tdo {\n\t\tfv = ice_pkg_enum_entry(ice_seg, &state, ICE_SID_FLD_VEC_SW,\n\t\t\t\t\t&offset, ice_sw_fv_handler);\n\t\tif (!fv)\n\t\t\tbreak;\n\t\tice_seg = NULL;\n\n\t\t \n\t\tfor (j = 0; j < hw->blk[ICE_BLK_SW].es.fvw; j++)\n\t\t\tif (fv->ew[j].prot_id != ICE_PROT_INVALID ||\n\t\t\t    fv->ew[j].off != ICE_FV_OFFSET_INVAL)\n\t\t\t\tflag = true;\n\t\tif (flag && prof_index > max_prof_index)\n\t\t\tmax_prof_index = prof_index;\n\n\t\tprof_index++;\n\t\tflag = false;\n\t} while (fv);\n\n\thw->switch_info->max_used_prof_index = max_prof_index;\n\n\treturn 0;\n}\n\n \nstatic enum ice_ddp_state ice_get_ddp_pkg_state(struct ice_hw *hw,\n\t\t\t\t\t\tbool already_loaded)\n{\n\tif (hw->pkg_ver.major == hw->active_pkg_ver.major &&\n\t    hw->pkg_ver.minor == hw->active_pkg_ver.minor &&\n\t    hw->pkg_ver.update == hw->active_pkg_ver.update &&\n\t    hw->pkg_ver.draft == hw->active_pkg_ver.draft &&\n\t    !memcmp(hw->pkg_name, hw->active_pkg_name, sizeof(hw->pkg_name))) {\n\t\tif (already_loaded)\n\t\t\treturn ICE_DDP_PKG_SAME_VERSION_ALREADY_LOADED;\n\t\telse\n\t\t\treturn ICE_DDP_PKG_SUCCESS;\n\t} else if (hw->active_pkg_ver.major != ICE_PKG_SUPP_VER_MAJ ||\n\t\t   hw->active_pkg_ver.minor != ICE_PKG_SUPP_VER_MNR) {\n\t\treturn ICE_DDP_PKG_ALREADY_LOADED_NOT_SUPPORTED;\n\t} else if (hw->active_pkg_ver.major == ICE_PKG_SUPP_VER_MAJ &&\n\t\t   hw->active_pkg_ver.minor == ICE_PKG_SUPP_VER_MNR) {\n\t\treturn ICE_DDP_PKG_COMPATIBLE_ALREADY_LOADED;\n\t} else {\n\t\treturn ICE_DDP_PKG_ERR;\n\t}\n}\n\n \nstatic void ice_init_pkg_regs(struct ice_hw *hw)\n{\n#define ICE_SW_BLK_INP_MASK_L 0xFFFFFFFF\n#define ICE_SW_BLK_INP_MASK_H 0x0000FFFF\n#define ICE_SW_BLK_IDX 0\n\n\t \n\twr32(hw, GL_PREEXT_L2_PMASK0(ICE_SW_BLK_IDX), ICE_SW_BLK_INP_MASK_L);\n\twr32(hw, GL_PREEXT_L2_PMASK1(ICE_SW_BLK_IDX), ICE_SW_BLK_INP_MASK_H);\n}\n\n \nstatic void *ice_marker_ptype_tcam_handler(u32 sect_type, void *section,\n\t\t\t\t\t   u32 index, u32 *offset)\n{\n\tstruct ice_marker_ptype_tcam_section *marker_ptype;\n\n\tif (sect_type != ICE_SID_RXPARSER_MARKER_PTYPE)\n\t\treturn NULL;\n\n\tif (index > ICE_MAX_MARKER_PTYPE_TCAMS_IN_BUF)\n\t\treturn NULL;\n\n\tif (offset)\n\t\t*offset = 0;\n\n\tmarker_ptype = section;\n\tif (index >= le16_to_cpu(marker_ptype->count))\n\t\treturn NULL;\n\n\treturn marker_ptype->tcam + index;\n}\n\n \nstatic void ice_add_dvm_hint(struct ice_hw *hw, u16 val, bool enable)\n{\n\tif (hw->dvm_upd.count < ICE_DVM_MAX_ENTRIES) {\n\t\thw->dvm_upd.tbl[hw->dvm_upd.count].boost_addr = val;\n\t\thw->dvm_upd.tbl[hw->dvm_upd.count].enable = enable;\n\t\thw->dvm_upd.count++;\n\t}\n}\n\n \nstatic void ice_add_tunnel_hint(struct ice_hw *hw, char *label_name, u16 val)\n{\n\tif (hw->tnl.count < ICE_TUNNEL_MAX_ENTRIES) {\n\t\tu16 i;\n\n\t\tfor (i = 0; tnls[i].type != TNL_LAST; i++) {\n\t\t\tsize_t len = strlen(tnls[i].label_prefix);\n\n\t\t\t \n\t\t\tif (strncmp(label_name, tnls[i].label_prefix, len))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif ((label_name[len] - '0') == hw->pf_id) {\n\t\t\t\thw->tnl.tbl[hw->tnl.count].type = tnls[i].type;\n\t\t\t\thw->tnl.tbl[hw->tnl.count].valid = false;\n\t\t\t\thw->tnl.tbl[hw->tnl.count].boost_addr = val;\n\t\t\t\thw->tnl.tbl[hw->tnl.count].port = 0;\n\t\t\t\thw->tnl.count++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic void *ice_label_enum_handler(u32 __always_unused sect_type,\n\t\t\t\t    void *section, u32 index, u32 *offset)\n{\n\tstruct ice_label_section *labels;\n\n\tif (!section)\n\t\treturn NULL;\n\n\tif (index > ICE_MAX_LABELS_IN_BUF)\n\t\treturn NULL;\n\n\tif (offset)\n\t\t*offset = 0;\n\n\tlabels = section;\n\tif (index >= le16_to_cpu(labels->count))\n\t\treturn NULL;\n\n\treturn labels->label + index;\n}\n\n \nstatic char *ice_enum_labels(struct ice_seg *ice_seg, u32 type,\n\t\t\t     struct ice_pkg_enum *state, u16 *value)\n{\n\tstruct ice_label *label;\n\n\t \n\tif (type && !(type >= ICE_SID_LBL_FIRST && type <= ICE_SID_LBL_LAST))\n\t\treturn NULL;\n\n\tlabel = ice_pkg_enum_entry(ice_seg, state, type, NULL,\n\t\t\t\t   ice_label_enum_handler);\n\tif (!label)\n\t\treturn NULL;\n\n\t*value = le16_to_cpu(label->value);\n\treturn label->name;\n}\n\n \nstatic void *ice_boost_tcam_handler(u32 sect_type, void *section, u32 index,\n\t\t\t\t    u32 *offset)\n{\n\tstruct ice_boost_tcam_section *boost;\n\n\tif (!section)\n\t\treturn NULL;\n\n\tif (sect_type != ICE_SID_RXPARSER_BOOST_TCAM)\n\t\treturn NULL;\n\n\tif (index > ICE_MAX_BST_TCAMS_IN_BUF)\n\t\treturn NULL;\n\n\tif (offset)\n\t\t*offset = 0;\n\n\tboost = section;\n\tif (index >= le16_to_cpu(boost->count))\n\t\treturn NULL;\n\n\treturn boost->tcam + index;\n}\n\n \nstatic int ice_find_boost_entry(struct ice_seg *ice_seg, u16 addr,\n\t\t\t\tstruct ice_boost_tcam_entry **entry)\n{\n\tstruct ice_boost_tcam_entry *tcam;\n\tstruct ice_pkg_enum state;\n\n\tmemset(&state, 0, sizeof(state));\n\n\tif (!ice_seg)\n\t\treturn -EINVAL;\n\n\tdo {\n\t\ttcam = ice_pkg_enum_entry(ice_seg, &state,\n\t\t\t\t\t  ICE_SID_RXPARSER_BOOST_TCAM, NULL,\n\t\t\t\t\t  ice_boost_tcam_handler);\n\t\tif (tcam && le16_to_cpu(tcam->addr) == addr) {\n\t\t\t*entry = tcam;\n\t\t\treturn 0;\n\t\t}\n\n\t\tice_seg = NULL;\n\t} while (tcam);\n\n\t*entry = NULL;\n\treturn -EIO;\n}\n\n \nbool ice_is_init_pkg_successful(enum ice_ddp_state state)\n{\n\tswitch (state) {\n\tcase ICE_DDP_PKG_SUCCESS:\n\tcase ICE_DDP_PKG_SAME_VERSION_ALREADY_LOADED:\n\tcase ICE_DDP_PKG_COMPATIBLE_ALREADY_LOADED:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstruct ice_buf_build *ice_pkg_buf_alloc(struct ice_hw *hw)\n{\n\tstruct ice_buf_build *bld;\n\tstruct ice_buf_hdr *buf;\n\n\tbld = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*bld), GFP_KERNEL);\n\tif (!bld)\n\t\treturn NULL;\n\n\tbuf = (struct ice_buf_hdr *)bld;\n\tbuf->data_end =\n\t\tcpu_to_le16(offsetof(struct ice_buf_hdr, section_entry));\n\treturn bld;\n}\n\nstatic bool ice_is_gtp_u_profile(u16 prof_idx)\n{\n\treturn (prof_idx >= ICE_PROFID_IPV6_GTPU_TEID &&\n\t\tprof_idx <= ICE_PROFID_IPV6_GTPU_IPV6_TCP_INNER) ||\n\t       prof_idx == ICE_PROFID_IPV4_GTPU_TEID;\n}\n\nstatic bool ice_is_gtp_c_profile(u16 prof_idx)\n{\n\tswitch (prof_idx) {\n\tcase ICE_PROFID_IPV4_GTPC_TEID:\n\tcase ICE_PROFID_IPV4_GTPC_NO_TEID:\n\tcase ICE_PROFID_IPV6_GTPC_TEID:\n\tcase ICE_PROFID_IPV6_GTPC_NO_TEID:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nstatic enum ice_prof_type ice_get_sw_prof_type(struct ice_hw *hw,\n\t\t\t\t\t       struct ice_fv *fv, u32 prof_idx)\n{\n\tu16 i;\n\n\tif (ice_is_gtp_c_profile(prof_idx))\n\t\treturn ICE_PROF_TUN_GTPC;\n\n\tif (ice_is_gtp_u_profile(prof_idx))\n\t\treturn ICE_PROF_TUN_GTPU;\n\n\tfor (i = 0; i < hw->blk[ICE_BLK_SW].es.fvw; i++) {\n\t\t \n\t\tif (fv->ew[i].prot_id == (u8)ICE_PROT_UDP_OF &&\n\t\t    fv->ew[i].off == ICE_VNI_OFFSET)\n\t\t\treturn ICE_PROF_TUN_UDP;\n\n\t\t \n\t\tif (fv->ew[i].prot_id == (u8)ICE_PROT_GRE_OF)\n\t\t\treturn ICE_PROF_TUN_GRE;\n\t}\n\n\treturn ICE_PROF_NON_TUN;\n}\n\n \nvoid ice_get_sw_fv_bitmap(struct ice_hw *hw, enum ice_prof_type req_profs,\n\t\t\t  unsigned long *bm)\n{\n\tstruct ice_pkg_enum state;\n\tstruct ice_seg *ice_seg;\n\tstruct ice_fv *fv;\n\n\tif (req_profs == ICE_PROF_ALL) {\n\t\tbitmap_set(bm, 0, ICE_MAX_NUM_PROFILES);\n\t\treturn;\n\t}\n\n\tmemset(&state, 0, sizeof(state));\n\tbitmap_zero(bm, ICE_MAX_NUM_PROFILES);\n\tice_seg = hw->seg;\n\tdo {\n\t\tenum ice_prof_type prof_type;\n\t\tu32 offset;\n\n\t\tfv = ice_pkg_enum_entry(ice_seg, &state, ICE_SID_FLD_VEC_SW,\n\t\t\t\t\t&offset, ice_sw_fv_handler);\n\t\tice_seg = NULL;\n\n\t\tif (fv) {\n\t\t\t \n\t\t\tprof_type = ice_get_sw_prof_type(hw, fv, offset);\n\n\t\t\tif (req_profs & prof_type)\n\t\t\t\tset_bit((u16)offset, bm);\n\t\t}\n\t} while (fv);\n}\n\n \nint ice_get_sw_fv_list(struct ice_hw *hw, struct ice_prot_lkup_ext *lkups,\n\t\t       unsigned long *bm, struct list_head *fv_list)\n{\n\tstruct ice_sw_fv_list_entry *fvl;\n\tstruct ice_sw_fv_list_entry *tmp;\n\tstruct ice_pkg_enum state;\n\tstruct ice_seg *ice_seg;\n\tstruct ice_fv *fv;\n\tu32 offset;\n\n\tmemset(&state, 0, sizeof(state));\n\n\tif (!lkups->n_val_words || !hw->seg)\n\t\treturn -EINVAL;\n\n\tice_seg = hw->seg;\n\tdo {\n\t\tu16 i;\n\n\t\tfv = ice_pkg_enum_entry(ice_seg, &state, ICE_SID_FLD_VEC_SW,\n\t\t\t\t\t&offset, ice_sw_fv_handler);\n\t\tif (!fv)\n\t\t\tbreak;\n\t\tice_seg = NULL;\n\n\t\t \n\t\tif (!test_bit((u16)offset, bm))\n\t\t\tcontinue;\n\n\t\tfor (i = 0; i < lkups->n_val_words; i++) {\n\t\t\tint j;\n\n\t\t\tfor (j = 0; j < hw->blk[ICE_BLK_SW].es.fvw; j++)\n\t\t\t\tif (fv->ew[j].prot_id ==\n\t\t\t\t\t    lkups->fv_words[i].prot_id &&\n\t\t\t\t    fv->ew[j].off == lkups->fv_words[i].off)\n\t\t\t\t\tbreak;\n\t\t\tif (j >= hw->blk[ICE_BLK_SW].es.fvw)\n\t\t\t\tbreak;\n\t\t\tif (i + 1 == lkups->n_val_words) {\n\t\t\t\tfvl = devm_kzalloc(ice_hw_to_dev(hw),\n\t\t\t\t\t\t   sizeof(*fvl), GFP_KERNEL);\n\t\t\t\tif (!fvl)\n\t\t\t\t\tgoto err;\n\t\t\t\tfvl->fv_ptr = fv;\n\t\t\t\tfvl->profile_id = offset;\n\t\t\t\tlist_add(&fvl->list_entry, fv_list);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} while (fv);\n\tif (list_empty(fv_list)) {\n\t\tdev_warn(ice_hw_to_dev(hw),\n\t\t\t \"Required profiles not found in currently loaded DDP package\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n\nerr:\n\tlist_for_each_entry_safe(fvl, tmp, fv_list, list_entry) {\n\t\tlist_del(&fvl->list_entry);\n\t\tdevm_kfree(ice_hw_to_dev(hw), fvl);\n\t}\n\n\treturn -ENOMEM;\n}\n\n \nvoid ice_init_prof_result_bm(struct ice_hw *hw)\n{\n\tstruct ice_pkg_enum state;\n\tstruct ice_seg *ice_seg;\n\tstruct ice_fv *fv;\n\n\tmemset(&state, 0, sizeof(state));\n\n\tif (!hw->seg)\n\t\treturn;\n\n\tice_seg = hw->seg;\n\tdo {\n\t\tu32 off;\n\t\tu16 i;\n\n\t\tfv = ice_pkg_enum_entry(ice_seg, &state, ICE_SID_FLD_VEC_SW,\n\t\t\t\t\t&off, ice_sw_fv_handler);\n\t\tice_seg = NULL;\n\t\tif (!fv)\n\t\t\tbreak;\n\n\t\tbitmap_zero(hw->switch_info->prof_res_bm[off],\n\t\t\t    ICE_MAX_FV_WORDS);\n\n\t\t \n\t\tfor (i = 1; i < ICE_MAX_FV_WORDS; i++)\n\t\t\tif (fv->ew[i].prot_id == ICE_PROT_INVALID &&\n\t\t\t    fv->ew[i].off == ICE_FV_OFFSET_INVAL)\n\t\t\t\tset_bit(i, hw->switch_info->prof_res_bm[off]);\n\t} while (fv);\n}\n\n \nvoid ice_pkg_buf_free(struct ice_hw *hw, struct ice_buf_build *bld)\n{\n\tdevm_kfree(ice_hw_to_dev(hw), bld);\n}\n\n \nint ice_pkg_buf_reserve_section(struct ice_buf_build *bld, u16 count)\n{\n\tstruct ice_buf_hdr *buf;\n\tu16 section_count;\n\tu16 data_end;\n\n\tif (!bld)\n\t\treturn -EINVAL;\n\n\tbuf = (struct ice_buf_hdr *)&bld->buf;\n\n\t \n\tsection_count = le16_to_cpu(buf->section_count);\n\tif (section_count > 0)\n\t\treturn -EIO;\n\n\tif (bld->reserved_section_table_entries + count > ICE_MAX_S_COUNT)\n\t\treturn -EIO;\n\tbld->reserved_section_table_entries += count;\n\n\tdata_end = le16_to_cpu(buf->data_end) +\n\t\t   flex_array_size(buf, section_entry, count);\n\tbuf->data_end = cpu_to_le16(data_end);\n\n\treturn 0;\n}\n\n \nvoid *ice_pkg_buf_alloc_section(struct ice_buf_build *bld, u32 type, u16 size)\n{\n\tstruct ice_buf_hdr *buf;\n\tu16 sect_count;\n\tu16 data_end;\n\n\tif (!bld || !type || !size)\n\t\treturn NULL;\n\n\tbuf = (struct ice_buf_hdr *)&bld->buf;\n\n\t \n\tdata_end = le16_to_cpu(buf->data_end);\n\n\t \n\tdata_end = ALIGN(data_end, 4);\n\n\tif ((data_end + size) > ICE_MAX_S_DATA_END)\n\t\treturn NULL;\n\n\t \n\tsect_count = le16_to_cpu(buf->section_count);\n\tif (sect_count < bld->reserved_section_table_entries) {\n\t\tvoid *section_ptr = ((u8 *)buf) + data_end;\n\n\t\tbuf->section_entry[sect_count].offset = cpu_to_le16(data_end);\n\t\tbuf->section_entry[sect_count].size = cpu_to_le16(size);\n\t\tbuf->section_entry[sect_count].type = cpu_to_le32(type);\n\n\t\tdata_end += size;\n\t\tbuf->data_end = cpu_to_le16(data_end);\n\n\t\tbuf->section_count = cpu_to_le16(sect_count + 1);\n\t\treturn section_ptr;\n\t}\n\n\t \n\treturn NULL;\n}\n\n \nstruct ice_buf_build *ice_pkg_buf_alloc_single_section(struct ice_hw *hw,\n\t\t\t\t\t\t       u32 type, u16 size,\n\t\t\t\t\t\t       void **section)\n{\n\tstruct ice_buf_build *buf;\n\n\tif (!section)\n\t\treturn NULL;\n\n\tbuf = ice_pkg_buf_alloc(hw);\n\tif (!buf)\n\t\treturn NULL;\n\n\tif (ice_pkg_buf_reserve_section(buf, 1))\n\t\tgoto ice_pkg_buf_alloc_single_section_err;\n\n\t*section = ice_pkg_buf_alloc_section(buf, type, size);\n\tif (!*section)\n\t\tgoto ice_pkg_buf_alloc_single_section_err;\n\n\treturn buf;\n\nice_pkg_buf_alloc_single_section_err:\n\tice_pkg_buf_free(hw, buf);\n\treturn NULL;\n}\n\n \nu16 ice_pkg_buf_get_active_sections(struct ice_buf_build *bld)\n{\n\tstruct ice_buf_hdr *buf;\n\n\tif (!bld)\n\t\treturn 0;\n\n\tbuf = (struct ice_buf_hdr *)&bld->buf;\n\treturn le16_to_cpu(buf->section_count);\n}\n\n \nstruct ice_buf *ice_pkg_buf(struct ice_buf_build *bld)\n{\n\tif (!bld)\n\t\treturn NULL;\n\n\treturn &bld->buf;\n}\n\nstatic enum ice_ddp_state ice_map_aq_err_to_ddp_state(enum ice_aq_err aq_err)\n{\n\tswitch (aq_err) {\n\tcase ICE_AQ_RC_ENOSEC:\n\tcase ICE_AQ_RC_EBADSIG:\n\t\treturn ICE_DDP_PKG_FILE_SIGNATURE_INVALID;\n\tcase ICE_AQ_RC_ESVN:\n\t\treturn ICE_DDP_PKG_FILE_REVISION_TOO_LOW;\n\tcase ICE_AQ_RC_EBADMAN:\n\tcase ICE_AQ_RC_EBADBUF:\n\t\treturn ICE_DDP_PKG_LOAD_ERROR;\n\tdefault:\n\t\treturn ICE_DDP_PKG_ERR;\n\t}\n}\n\n \nstatic int ice_acquire_global_cfg_lock(struct ice_hw *hw,\n\t\t\t\t       enum ice_aq_res_access_type access)\n{\n\tint status;\n\n\tstatus = ice_acquire_res(hw, ICE_GLOBAL_CFG_LOCK_RES_ID, access,\n\t\t\t\t ICE_GLOBAL_CFG_LOCK_TIMEOUT);\n\n\tif (!status)\n\t\tmutex_lock(&ice_global_cfg_lock_sw);\n\telse if (status == -EALREADY)\n\t\tice_debug(hw, ICE_DBG_PKG,\n\t\t\t  \"Global config lock: No work to do\\n\");\n\n\treturn status;\n}\n\n \nstatic void ice_release_global_cfg_lock(struct ice_hw *hw)\n{\n\tmutex_unlock(&ice_global_cfg_lock_sw);\n\tice_release_res(hw, ICE_GLOBAL_CFG_LOCK_RES_ID);\n}\n\n \nstatic int\nice_aq_download_pkg(struct ice_hw *hw, struct ice_buf_hdr *pkg_buf,\n\t\t    u16 buf_size, bool last_buf, u32 *error_offset,\n\t\t    u32 *error_info, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_download_pkg *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tif (error_offset)\n\t\t*error_offset = 0;\n\tif (error_info)\n\t\t*error_info = 0;\n\n\tcmd = &desc.params.download_pkg;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_download_pkg);\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tif (last_buf)\n\t\tcmd->flags |= ICE_AQC_DOWNLOAD_PKG_LAST_BUF;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, pkg_buf, buf_size, cd);\n\tif (status == -EIO) {\n\t\t \n\t\tstruct ice_aqc_download_pkg_resp *resp;\n\n\t\tresp = (struct ice_aqc_download_pkg_resp *)pkg_buf;\n\t\tif (error_offset)\n\t\t\t*error_offset = le32_to_cpu(resp->error_offset);\n\t\tif (error_info)\n\t\t\t*error_info = le32_to_cpu(resp->error_info);\n\t}\n\n\treturn status;\n}\n\n \nstatic enum ice_ddp_state ice_dwnld_cfg_bufs(struct ice_hw *hw,\n\t\t\t\t\t     struct ice_buf *bufs, u32 count)\n{\n\tenum ice_ddp_state state = ICE_DDP_PKG_SUCCESS;\n\tstruct ice_buf_hdr *bh;\n\tenum ice_aq_err err;\n\tu32 offset, info, i;\n\tint status;\n\n\tif (!bufs || !count)\n\t\treturn ICE_DDP_PKG_ERR;\n\n\t \n\tbh = (struct ice_buf_hdr *)bufs;\n\tif (le32_to_cpu(bh->section_entry[0].type) & ICE_METADATA_BUF)\n\t\treturn ICE_DDP_PKG_SUCCESS;\n\n\tstatus = ice_acquire_global_cfg_lock(hw, ICE_RES_WRITE);\n\tif (status) {\n\t\tif (status == -EALREADY)\n\t\t\treturn ICE_DDP_PKG_ALREADY_LOADED;\n\t\treturn ice_map_aq_err_to_ddp_state(hw->adminq.sq_last_status);\n\t}\n\n\tfor (i = 0; i < count; i++) {\n\t\tbool last = ((i + 1) == count);\n\n\t\tif (!last) {\n\t\t\t \n\t\t\tbh = (struct ice_buf_hdr *)(bufs + i + 1);\n\n\t\t\t \n\t\t\tif (le16_to_cpu(bh->section_count))\n\t\t\t\tif (le32_to_cpu(bh->section_entry[0].type) &\n\t\t\t\t    ICE_METADATA_BUF)\n\t\t\t\t\tlast = true;\n\t\t}\n\n\t\tbh = (struct ice_buf_hdr *)(bufs + i);\n\n\t\tstatus = ice_aq_download_pkg(hw, bh, ICE_PKG_BUF_SIZE, last,\n\t\t\t\t\t     &offset, &info, NULL);\n\n\t\t \n\t\tif (status) {\n\t\t\tice_debug(hw, ICE_DBG_PKG,\n\t\t\t\t  \"Pkg download failed: err %d off %d inf %d\\n\",\n\t\t\t\t  status, offset, info);\n\t\t\terr = hw->adminq.sq_last_status;\n\t\t\tstate = ice_map_aq_err_to_ddp_state(err);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (last)\n\t\t\tbreak;\n\t}\n\n\tif (!status) {\n\t\tstatus = ice_set_vlan_mode(hw);\n\t\tif (status)\n\t\t\tice_debug(hw, ICE_DBG_PKG,\n\t\t\t\t  \"Failed to set VLAN mode: err %d\\n\", status);\n\t}\n\n\tice_release_global_cfg_lock(hw);\n\n\treturn state;\n}\n\n \nstatic int ice_aq_get_pkg_info_list(struct ice_hw *hw,\n\t\t\t\t    struct ice_aqc_get_pkg_info_resp *pkg_info,\n\t\t\t\t    u16 buf_size, struct ice_sq_cd *cd)\n{\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_get_pkg_info_list);\n\n\treturn ice_aq_send_cmd(hw, &desc, pkg_info, buf_size, cd);\n}\n\n \nstatic enum ice_ddp_state ice_download_pkg(struct ice_hw *hw,\n\t\t\t\t\t   struct ice_seg *ice_seg)\n{\n\tstruct ice_buf_table *ice_buf_tbl;\n\tint status;\n\n\tice_debug(hw, ICE_DBG_PKG, \"Segment format version: %d.%d.%d.%d\\n\",\n\t\t  ice_seg->hdr.seg_format_ver.major,\n\t\t  ice_seg->hdr.seg_format_ver.minor,\n\t\t  ice_seg->hdr.seg_format_ver.update,\n\t\t  ice_seg->hdr.seg_format_ver.draft);\n\n\tice_debug(hw, ICE_DBG_PKG, \"Seg: type 0x%X, size %d, name %s\\n\",\n\t\t  le32_to_cpu(ice_seg->hdr.seg_type),\n\t\t  le32_to_cpu(ice_seg->hdr.seg_size), ice_seg->hdr.seg_id);\n\n\tice_buf_tbl = ice_find_buf_table(ice_seg);\n\n\tice_debug(hw, ICE_DBG_PKG, \"Seg buf count: %d\\n\",\n\t\t  le32_to_cpu(ice_buf_tbl->buf_count));\n\n\tstatus = ice_dwnld_cfg_bufs(hw, ice_buf_tbl->buf_array,\n\t\t\t\t    le32_to_cpu(ice_buf_tbl->buf_count));\n\n\tice_post_pkg_dwnld_vlan_mode_cfg(hw);\n\n\treturn status;\n}\n\n \nstatic int ice_aq_update_pkg(struct ice_hw *hw, struct ice_buf_hdr *pkg_buf,\n\t\t\t     u16 buf_size, bool last_buf, u32 *error_offset,\n\t\t\t     u32 *error_info, struct ice_sq_cd *cd)\n{\n\tstruct ice_aqc_download_pkg *cmd;\n\tstruct ice_aq_desc desc;\n\tint status;\n\n\tif (error_offset)\n\t\t*error_offset = 0;\n\tif (error_info)\n\t\t*error_info = 0;\n\n\tcmd = &desc.params.download_pkg;\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_update_pkg);\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\tif (last_buf)\n\t\tcmd->flags |= ICE_AQC_DOWNLOAD_PKG_LAST_BUF;\n\n\tstatus = ice_aq_send_cmd(hw, &desc, pkg_buf, buf_size, cd);\n\tif (status == -EIO) {\n\t\t \n\t\tstruct ice_aqc_download_pkg_resp *resp;\n\n\t\tresp = (struct ice_aqc_download_pkg_resp *)pkg_buf;\n\t\tif (error_offset)\n\t\t\t*error_offset = le32_to_cpu(resp->error_offset);\n\t\tif (error_info)\n\t\t\t*error_info = le32_to_cpu(resp->error_info);\n\t}\n\n\treturn status;\n}\n\n \nint ice_aq_upload_section(struct ice_hw *hw, struct ice_buf_hdr *pkg_buf,\n\t\t\t  u16 buf_size, struct ice_sq_cd *cd)\n{\n\tstruct ice_aq_desc desc;\n\n\tice_fill_dflt_direct_cmd_desc(&desc, ice_aqc_opc_upload_section);\n\tdesc.flags |= cpu_to_le16(ICE_AQ_FLAG_RD);\n\n\treturn ice_aq_send_cmd(hw, &desc, pkg_buf, buf_size, cd);\n}\n\n \nint ice_update_pkg_no_lock(struct ice_hw *hw, struct ice_buf *bufs, u32 count)\n{\n\tint status = 0;\n\tu32 i;\n\n\tfor (i = 0; i < count; i++) {\n\t\tstruct ice_buf_hdr *bh = (struct ice_buf_hdr *)(bufs + i);\n\t\tbool last = ((i + 1) == count);\n\t\tu32 offset, info;\n\n\t\tstatus = ice_aq_update_pkg(hw, bh, le16_to_cpu(bh->data_end),\n\t\t\t\t\t   last, &offset, &info, NULL);\n\n\t\tif (status) {\n\t\t\tice_debug(hw, ICE_DBG_PKG,\n\t\t\t\t  \"Update pkg failed: err %d off %d inf %d\\n\",\n\t\t\t\t  status, offset, info);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn status;\n}\n\n \nint ice_update_pkg(struct ice_hw *hw, struct ice_buf *bufs, u32 count)\n{\n\tint status;\n\n\tstatus = ice_acquire_change_lock(hw, ICE_RES_WRITE);\n\tif (status)\n\t\treturn status;\n\n\tstatus = ice_update_pkg_no_lock(hw, bufs, count);\n\n\tice_release_change_lock(hw);\n\n\treturn status;\n}\n\n \nstatic struct ice_generic_seg_hdr *\nice_find_seg_in_pkg(struct ice_hw *hw, u32 seg_type,\n\t\t    struct ice_pkg_hdr *pkg_hdr)\n{\n\tu32 i;\n\n\tice_debug(hw, ICE_DBG_PKG, \"Package format version: %d.%d.%d.%d\\n\",\n\t\t  pkg_hdr->pkg_format_ver.major, pkg_hdr->pkg_format_ver.minor,\n\t\t  pkg_hdr->pkg_format_ver.update,\n\t\t  pkg_hdr->pkg_format_ver.draft);\n\n\t \n\tfor (i = 0; i < le32_to_cpu(pkg_hdr->seg_count); i++) {\n\t\tstruct ice_generic_seg_hdr *seg;\n\n\t\tseg = (struct ice_generic_seg_hdr\n\t\t\t       *)((u8 *)pkg_hdr +\n\t\t\t\t  le32_to_cpu(pkg_hdr->seg_offset[i]));\n\n\t\tif (le32_to_cpu(seg->seg_type) == seg_type)\n\t\t\treturn seg;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic enum ice_ddp_state ice_init_pkg_info(struct ice_hw *hw,\n\t\t\t\t\t    struct ice_pkg_hdr *pkg_hdr)\n{\n\tstruct ice_generic_seg_hdr *seg_hdr;\n\n\tif (!pkg_hdr)\n\t\treturn ICE_DDP_PKG_ERR;\n\n\tseg_hdr = ice_find_seg_in_pkg(hw, SEGMENT_TYPE_ICE, pkg_hdr);\n\tif (seg_hdr) {\n\t\tstruct ice_meta_sect *meta;\n\t\tstruct ice_pkg_enum state;\n\n\t\tmemset(&state, 0, sizeof(state));\n\n\t\t \n\t\tmeta = ice_pkg_enum_section((struct ice_seg *)seg_hdr, &state,\n\t\t\t\t\t    ICE_SID_METADATA);\n\t\tif (!meta) {\n\t\t\tice_debug(hw, ICE_DBG_INIT,\n\t\t\t\t  \"Did not find ice metadata section in package\\n\");\n\t\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\t\t}\n\n\t\thw->pkg_ver = meta->ver;\n\t\tmemcpy(hw->pkg_name, meta->name, sizeof(meta->name));\n\n\t\tice_debug(hw, ICE_DBG_PKG, \"Pkg: %d.%d.%d.%d, %s\\n\",\n\t\t\t  meta->ver.major, meta->ver.minor, meta->ver.update,\n\t\t\t  meta->ver.draft, meta->name);\n\n\t\thw->ice_seg_fmt_ver = seg_hdr->seg_format_ver;\n\t\tmemcpy(hw->ice_seg_id, seg_hdr->seg_id, sizeof(hw->ice_seg_id));\n\n\t\tice_debug(hw, ICE_DBG_PKG, \"Ice Seg: %d.%d.%d.%d, %s\\n\",\n\t\t\t  seg_hdr->seg_format_ver.major,\n\t\t\t  seg_hdr->seg_format_ver.minor,\n\t\t\t  seg_hdr->seg_format_ver.update,\n\t\t\t  seg_hdr->seg_format_ver.draft, seg_hdr->seg_id);\n\t} else {\n\t\tice_debug(hw, ICE_DBG_INIT,\n\t\t\t  \"Did not find ice segment in driver package\\n\");\n\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\t}\n\n\treturn ICE_DDP_PKG_SUCCESS;\n}\n\n \nstatic enum ice_ddp_state ice_get_pkg_info(struct ice_hw *hw)\n{\n\tenum ice_ddp_state state = ICE_DDP_PKG_SUCCESS;\n\tstruct ice_aqc_get_pkg_info_resp *pkg_info;\n\tu16 size;\n\tu32 i;\n\n\tsize = struct_size(pkg_info, pkg_info, ICE_PKG_CNT);\n\tpkg_info = kzalloc(size, GFP_KERNEL);\n\tif (!pkg_info)\n\t\treturn ICE_DDP_PKG_ERR;\n\n\tif (ice_aq_get_pkg_info_list(hw, pkg_info, size, NULL)) {\n\t\tstate = ICE_DDP_PKG_ERR;\n\t\tgoto init_pkg_free_alloc;\n\t}\n\n\tfor (i = 0; i < le32_to_cpu(pkg_info->count); i++) {\n#define ICE_PKG_FLAG_COUNT 4\n\t\tchar flags[ICE_PKG_FLAG_COUNT + 1] = { 0 };\n\t\tu8 place = 0;\n\n\t\tif (pkg_info->pkg_info[i].is_active) {\n\t\t\tflags[place++] = 'A';\n\t\t\thw->active_pkg_ver = pkg_info->pkg_info[i].ver;\n\t\t\thw->active_track_id =\n\t\t\t\tle32_to_cpu(pkg_info->pkg_info[i].track_id);\n\t\t\tmemcpy(hw->active_pkg_name, pkg_info->pkg_info[i].name,\n\t\t\t       sizeof(pkg_info->pkg_info[i].name));\n\t\t\thw->active_pkg_in_nvm = pkg_info->pkg_info[i].is_in_nvm;\n\t\t}\n\t\tif (pkg_info->pkg_info[i].is_active_at_boot)\n\t\t\tflags[place++] = 'B';\n\t\tif (pkg_info->pkg_info[i].is_modified)\n\t\t\tflags[place++] = 'M';\n\t\tif (pkg_info->pkg_info[i].is_in_nvm)\n\t\t\tflags[place++] = 'N';\n\n\t\tice_debug(hw, ICE_DBG_PKG, \"Pkg[%d]: %d.%d.%d.%d,%s,%s\\n\", i,\n\t\t\t  pkg_info->pkg_info[i].ver.major,\n\t\t\t  pkg_info->pkg_info[i].ver.minor,\n\t\t\t  pkg_info->pkg_info[i].ver.update,\n\t\t\t  pkg_info->pkg_info[i].ver.draft,\n\t\t\t  pkg_info->pkg_info[i].name, flags);\n\t}\n\ninit_pkg_free_alloc:\n\tkfree(pkg_info);\n\n\treturn state;\n}\n\n \nstatic enum ice_ddp_state ice_chk_pkg_compat(struct ice_hw *hw,\n\t\t\t\t\t     struct ice_pkg_hdr *ospkg,\n\t\t\t\t\t     struct ice_seg **seg)\n{\n\tstruct ice_aqc_get_pkg_info_resp *pkg;\n\tenum ice_ddp_state state;\n\tu16 size;\n\tu32 i;\n\n\t \n\tstate = ice_chk_pkg_version(&hw->pkg_ver);\n\tif (state) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"Package version check failed.\\n\");\n\t\treturn state;\n\t}\n\n\t \n\t*seg = (struct ice_seg *)ice_find_seg_in_pkg(hw, SEGMENT_TYPE_ICE,\n\t\t\t\t\t\t     ospkg);\n\tif (!*seg) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"no ice segment in package.\\n\");\n\t\treturn ICE_DDP_PKG_INVALID_FILE;\n\t}\n\n\t \n\tsize = struct_size(pkg, pkg_info, ICE_PKG_CNT);\n\tpkg = kzalloc(size, GFP_KERNEL);\n\tif (!pkg)\n\t\treturn ICE_DDP_PKG_ERR;\n\n\tif (ice_aq_get_pkg_info_list(hw, pkg, size, NULL)) {\n\t\tstate = ICE_DDP_PKG_LOAD_ERROR;\n\t\tgoto fw_ddp_compat_free_alloc;\n\t}\n\n\tfor (i = 0; i < le32_to_cpu(pkg->count); i++) {\n\t\t \n\t\tif (!pkg->pkg_info[i].is_in_nvm)\n\t\t\tcontinue;\n\t\tif ((*seg)->hdr.seg_format_ver.major !=\n\t\t\t    pkg->pkg_info[i].ver.major ||\n\t\t    (*seg)->hdr.seg_format_ver.minor >\n\t\t\t    pkg->pkg_info[i].ver.minor) {\n\t\t\tstate = ICE_DDP_PKG_FW_MISMATCH;\n\t\t\tice_debug(hw, ICE_DBG_INIT,\n\t\t\t\t  \"OS package is not compatible with NVM.\\n\");\n\t\t}\n\t\t \n\t\tbreak;\n\t}\nfw_ddp_compat_free_alloc:\n\tkfree(pkg);\n\treturn state;\n}\n\n \nstatic void ice_init_pkg_hints(struct ice_hw *hw, struct ice_seg *ice_seg)\n{\n\tstruct ice_pkg_enum state;\n\tchar *label_name;\n\tu16 val;\n\tint i;\n\n\tmemset(&hw->tnl, 0, sizeof(hw->tnl));\n\tmemset(&state, 0, sizeof(state));\n\n\tif (!ice_seg)\n\t\treturn;\n\n\tlabel_name = ice_enum_labels(ice_seg, ICE_SID_LBL_RXPARSER_TMEM, &state,\n\t\t\t\t     &val);\n\n\twhile (label_name) {\n\t\tif (!strncmp(label_name, ICE_TNL_PRE, strlen(ICE_TNL_PRE)))\n\t\t\t \n\t\t\tice_add_tunnel_hint(hw, label_name, val);\n\n\t\t \n\t\telse if (!strncmp(label_name, ICE_DVM_PRE, strlen(ICE_DVM_PRE)))\n\t\t\tice_add_dvm_hint(hw, val, true);\n\n\t\t \n\t\telse if (!strncmp(label_name, ICE_SVM_PRE, strlen(ICE_SVM_PRE)))\n\t\t\tice_add_dvm_hint(hw, val, false);\n\n\t\tlabel_name = ice_enum_labels(NULL, 0, &state, &val);\n\t}\n\n\t \n\tfor (i = 0; i < hw->tnl.count; i++) {\n\t\tice_find_boost_entry(ice_seg, hw->tnl.tbl[i].boost_addr,\n\t\t\t\t     &hw->tnl.tbl[i].boost_entry);\n\t\tif (hw->tnl.tbl[i].boost_entry) {\n\t\t\thw->tnl.tbl[i].valid = true;\n\t\t\tif (hw->tnl.tbl[i].type < __TNL_TYPE_CNT)\n\t\t\t\thw->tnl.valid_count[hw->tnl.tbl[i].type]++;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < hw->dvm_upd.count; i++)\n\t\tice_find_boost_entry(ice_seg, hw->dvm_upd.tbl[i].boost_addr,\n\t\t\t\t     &hw->dvm_upd.tbl[i].boost_entry);\n}\n\n \nstatic void ice_fill_hw_ptype(struct ice_hw *hw)\n{\n\tstruct ice_marker_ptype_tcam_entry *tcam;\n\tstruct ice_seg *seg = hw->seg;\n\tstruct ice_pkg_enum state;\n\n\tbitmap_zero(hw->hw_ptype, ICE_FLOW_PTYPE_MAX);\n\tif (!seg)\n\t\treturn;\n\n\tmemset(&state, 0, sizeof(state));\n\n\tdo {\n\t\ttcam = ice_pkg_enum_entry(seg, &state,\n\t\t\t\t\t  ICE_SID_RXPARSER_MARKER_PTYPE, NULL,\n\t\t\t\t\t  ice_marker_ptype_tcam_handler);\n\t\tif (tcam &&\n\t\t    le16_to_cpu(tcam->addr) < ICE_MARKER_PTYPE_TCAM_ADDR_MAX &&\n\t\t    le16_to_cpu(tcam->ptype) < ICE_FLOW_PTYPE_MAX)\n\t\t\tset_bit(le16_to_cpu(tcam->ptype), hw->hw_ptype);\n\n\t\tseg = NULL;\n\t} while (tcam);\n}\n\n \nenum ice_ddp_state ice_init_pkg(struct ice_hw *hw, u8 *buf, u32 len)\n{\n\tbool already_loaded = false;\n\tenum ice_ddp_state state;\n\tstruct ice_pkg_hdr *pkg;\n\tstruct ice_seg *seg;\n\n\tif (!buf || !len)\n\t\treturn ICE_DDP_PKG_ERR;\n\n\tpkg = (struct ice_pkg_hdr *)buf;\n\tstate = ice_verify_pkg(pkg, len);\n\tif (state) {\n\t\tice_debug(hw, ICE_DBG_INIT, \"failed to verify pkg (err: %d)\\n\",\n\t\t\t  state);\n\t\treturn state;\n\t}\n\n\t \n\tstate = ice_init_pkg_info(hw, pkg);\n\tif (state)\n\t\treturn state;\n\n\t \n\tstate = ice_chk_pkg_compat(hw, pkg, &seg);\n\tif (state)\n\t\treturn state;\n\n\t \n\tice_init_pkg_hints(hw, seg);\n\tstate = ice_download_pkg(hw, seg);\n\tif (state == ICE_DDP_PKG_ALREADY_LOADED) {\n\t\tice_debug(hw, ICE_DBG_INIT,\n\t\t\t  \"package previously loaded - no work.\\n\");\n\t\talready_loaded = true;\n\t}\n\n\t \n\tif (!state || state == ICE_DDP_PKG_ALREADY_LOADED) {\n\t\tstate = ice_get_pkg_info(hw);\n\t\tif (!state)\n\t\t\tstate = ice_get_ddp_pkg_state(hw, already_loaded);\n\t}\n\n\tif (ice_is_init_pkg_successful(state)) {\n\t\thw->seg = seg;\n\t\t \n\t\tice_init_pkg_regs(hw);\n\t\tice_fill_blk_tbls(hw);\n\t\tice_fill_hw_ptype(hw);\n\t\tice_get_prof_index_max(hw);\n\t} else {\n\t\tice_debug(hw, ICE_DBG_INIT, \"package load failed, %d\\n\", state);\n\t}\n\n\treturn state;\n}\n\n \nenum ice_ddp_state ice_copy_and_init_pkg(struct ice_hw *hw, const u8 *buf,\n\t\t\t\t\t u32 len)\n{\n\tenum ice_ddp_state state;\n\tu8 *buf_copy;\n\n\tif (!buf || !len)\n\t\treturn ICE_DDP_PKG_ERR;\n\n\tbuf_copy = devm_kmemdup(ice_hw_to_dev(hw), buf, len, GFP_KERNEL);\n\n\tstate = ice_init_pkg(hw, buf_copy, len);\n\tif (!ice_is_init_pkg_successful(state)) {\n\t\t \n\t\tdevm_kfree(ice_hw_to_dev(hw), buf_copy);\n\t} else {\n\t\t \n\t\thw->pkg_copy = buf_copy;\n\t\thw->pkg_size = len;\n\t}\n\n\treturn state;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}