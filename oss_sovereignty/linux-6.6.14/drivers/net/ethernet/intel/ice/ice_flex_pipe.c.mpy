{
  "module_name": "ice_flex_pipe.c",
  "hash_id": "c542d7eb51d7e9cf3634f0db27d4ba3f131a769cd5054d713b8ab59d2f928ab5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/intel/ice/ice_flex_pipe.c",
  "human_readable_source": "\n \n\n#include \"ice_common.h\"\n#include \"ice_flex_pipe.h\"\n#include \"ice_flow.h\"\n#include \"ice.h\"\n\nstatic const u32 ice_sect_lkup[ICE_BLK_COUNT][ICE_SECT_COUNT] = {\n\t \n\t{\n\t\tICE_SID_XLT0_SW,\n\t\tICE_SID_XLT_KEY_BUILDER_SW,\n\t\tICE_SID_XLT1_SW,\n\t\tICE_SID_XLT2_SW,\n\t\tICE_SID_PROFID_TCAM_SW,\n\t\tICE_SID_PROFID_REDIR_SW,\n\t\tICE_SID_FLD_VEC_SW,\n\t\tICE_SID_CDID_KEY_BUILDER_SW,\n\t\tICE_SID_CDID_REDIR_SW\n\t},\n\n\t \n\t{\n\t\tICE_SID_XLT0_ACL,\n\t\tICE_SID_XLT_KEY_BUILDER_ACL,\n\t\tICE_SID_XLT1_ACL,\n\t\tICE_SID_XLT2_ACL,\n\t\tICE_SID_PROFID_TCAM_ACL,\n\t\tICE_SID_PROFID_REDIR_ACL,\n\t\tICE_SID_FLD_VEC_ACL,\n\t\tICE_SID_CDID_KEY_BUILDER_ACL,\n\t\tICE_SID_CDID_REDIR_ACL\n\t},\n\n\t \n\t{\n\t\tICE_SID_XLT0_FD,\n\t\tICE_SID_XLT_KEY_BUILDER_FD,\n\t\tICE_SID_XLT1_FD,\n\t\tICE_SID_XLT2_FD,\n\t\tICE_SID_PROFID_TCAM_FD,\n\t\tICE_SID_PROFID_REDIR_FD,\n\t\tICE_SID_FLD_VEC_FD,\n\t\tICE_SID_CDID_KEY_BUILDER_FD,\n\t\tICE_SID_CDID_REDIR_FD\n\t},\n\n\t \n\t{\n\t\tICE_SID_XLT0_RSS,\n\t\tICE_SID_XLT_KEY_BUILDER_RSS,\n\t\tICE_SID_XLT1_RSS,\n\t\tICE_SID_XLT2_RSS,\n\t\tICE_SID_PROFID_TCAM_RSS,\n\t\tICE_SID_PROFID_REDIR_RSS,\n\t\tICE_SID_FLD_VEC_RSS,\n\t\tICE_SID_CDID_KEY_BUILDER_RSS,\n\t\tICE_SID_CDID_REDIR_RSS\n\t},\n\n\t \n\t{\n\t\tICE_SID_XLT0_PE,\n\t\tICE_SID_XLT_KEY_BUILDER_PE,\n\t\tICE_SID_XLT1_PE,\n\t\tICE_SID_XLT2_PE,\n\t\tICE_SID_PROFID_TCAM_PE,\n\t\tICE_SID_PROFID_REDIR_PE,\n\t\tICE_SID_FLD_VEC_PE,\n\t\tICE_SID_CDID_KEY_BUILDER_PE,\n\t\tICE_SID_CDID_REDIR_PE\n\t}\n};\n\n \nstatic u32 ice_sect_id(enum ice_block blk, enum ice_sect sect)\n{\n\treturn ice_sect_lkup[blk][sect];\n}\n\n \nbool ice_hw_ptype_ena(struct ice_hw *hw, u16 ptype)\n{\n\treturn ptype < ICE_FLOW_PTYPE_MAX &&\n\t       test_bit(ptype, hw->hw_ptype);\n}\n\n \n\n#define ICE_DC_KEY\t0x1\t \n#define ICE_DC_KEYINV\t0x1\n#define ICE_NM_KEY\t0x0\t \n#define ICE_NM_KEYINV\t0x0\n#define ICE_0_KEY\t0x1\t \n#define ICE_0_KEYINV\t0x0\n#define ICE_1_KEY\t0x0\t \n#define ICE_1_KEYINV\t0x1\n\n \nstatic int\nice_gen_key_word(u8 val, u8 valid, u8 dont_care, u8 nvr_mtch, u8 *key,\n\t\t u8 *key_inv)\n{\n\tu8 in_key = *key, in_key_inv = *key_inv;\n\tu8 i;\n\n\t \n\tif ((dont_care ^ nvr_mtch) != (dont_care | nvr_mtch))\n\t\treturn -EIO;\n\n\t*key = 0;\n\t*key_inv = 0;\n\n\t \n\tfor (i = 0; i < 8; i++) {\n\t\t*key >>= 1;\n\t\t*key_inv >>= 1;\n\n\t\tif (!(valid & 0x1)) {  \n\t\t\t*key |= (in_key & 0x1) << 7;\n\t\t\t*key_inv |= (in_key_inv & 0x1) << 7;\n\t\t} else if (dont_care & 0x1) {  \n\t\t\t*key |= ICE_DC_KEY << 7;\n\t\t\t*key_inv |= ICE_DC_KEYINV << 7;\n\t\t} else if (nvr_mtch & 0x1) {  \n\t\t\t*key |= ICE_NM_KEY << 7;\n\t\t\t*key_inv |= ICE_NM_KEYINV << 7;\n\t\t} else if (val & 0x01) {  \n\t\t\t*key |= ICE_1_KEY << 7;\n\t\t\t*key_inv |= ICE_1_KEYINV << 7;\n\t\t} else {  \n\t\t\t*key |= ICE_0_KEY << 7;\n\t\t\t*key_inv |= ICE_0_KEYINV << 7;\n\t\t}\n\n\t\tdont_care >>= 1;\n\t\tnvr_mtch >>= 1;\n\t\tvalid >>= 1;\n\t\tval >>= 1;\n\t\tin_key >>= 1;\n\t\tin_key_inv >>= 1;\n\t}\n\n\treturn 0;\n}\n\n \nstatic bool ice_bits_max_set(const u8 *mask, u16 size, u16 max)\n{\n\tu16 count = 0;\n\tu16 i;\n\n\t \n\tfor (i = 0; i < size; i++) {\n\t\t \n\t\tif (!mask[i])\n\t\t\tcontinue;\n\n\t\t \n\t\tif (count == max)\n\t\t\treturn false;\n\n\t\t \n\t\tcount += hweight8(mask[i]);\n\t\tif (count > max)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic int\nice_set_key(u8 *key, u16 size, u8 *val, u8 *upd, u8 *dc, u8 *nm, u16 off,\n\t    u16 len)\n{\n\tu16 half_size;\n\tu16 i;\n\n\t \n\tif (size % 2)\n\t\treturn -EIO;\n\n\thalf_size = size / 2;\n\tif (off + len > half_size)\n\t\treturn -EIO;\n\n\t \n#define ICE_NVR_MTCH_BITS_MAX\t1\n\tif (nm && !ice_bits_max_set(nm, len, ICE_NVR_MTCH_BITS_MAX))\n\t\treturn -EIO;\n\n\tfor (i = 0; i < len; i++)\n\t\tif (ice_gen_key_word(val[i], upd ? upd[i] : 0xff,\n\t\t\t\t     dc ? dc[i] : 0, nm ? nm[i] : 0,\n\t\t\t\t     key + off + i, key + half_size + off + i))\n\t\t\treturn -EIO;\n\n\treturn 0;\n}\n\n \nint\nice_acquire_change_lock(struct ice_hw *hw, enum ice_aq_res_access_type access)\n{\n\treturn ice_acquire_res(hw, ICE_CHANGE_LOCK_RES_ID, access,\n\t\t\t       ICE_CHANGE_LOCK_TIMEOUT);\n}\n\n \nvoid ice_release_change_lock(struct ice_hw *hw)\n{\n\tice_release_res(hw, ICE_CHANGE_LOCK_RES_ID);\n}\n\n \nbool\nice_get_open_tunnel_port(struct ice_hw *hw, u16 *port,\n\t\t\t enum ice_tunnel_type type)\n{\n\tbool res = false;\n\tu16 i;\n\n\tmutex_lock(&hw->tnl_lock);\n\n\tfor (i = 0; i < hw->tnl.count && i < ICE_TUNNEL_MAX_ENTRIES; i++)\n\t\tif (hw->tnl.tbl[i].valid && hw->tnl.tbl[i].port &&\n\t\t    (type == TNL_LAST || type == hw->tnl.tbl[i].type)) {\n\t\t\t*port = hw->tnl.tbl[i].port;\n\t\t\tres = true;\n\t\t\tbreak;\n\t\t}\n\n\tmutex_unlock(&hw->tnl_lock);\n\n\treturn res;\n}\n\n \nstatic int\nice_upd_dvm_boost_entry(struct ice_hw *hw, struct ice_dvm_entry *entry)\n{\n\tstruct ice_boost_tcam_section *sect_rx, *sect_tx;\n\tint status = -ENOSPC;\n\tstruct ice_buf_build *bld;\n\tu8 val, dc, nm;\n\n\tbld = ice_pkg_buf_alloc(hw);\n\tif (!bld)\n\t\treturn -ENOMEM;\n\n\t \n\tif (ice_pkg_buf_reserve_section(bld, 2))\n\t\tgoto ice_upd_dvm_boost_entry_err;\n\n\tsect_rx = ice_pkg_buf_alloc_section(bld, ICE_SID_RXPARSER_BOOST_TCAM,\n\t\t\t\t\t    struct_size(sect_rx, tcam, 1));\n\tif (!sect_rx)\n\t\tgoto ice_upd_dvm_boost_entry_err;\n\tsect_rx->count = cpu_to_le16(1);\n\n\tsect_tx = ice_pkg_buf_alloc_section(bld, ICE_SID_TXPARSER_BOOST_TCAM,\n\t\t\t\t\t    struct_size(sect_tx, tcam, 1));\n\tif (!sect_tx)\n\t\tgoto ice_upd_dvm_boost_entry_err;\n\tsect_tx->count = cpu_to_le16(1);\n\n\t \n\tmemcpy(sect_rx->tcam, entry->boost_entry, sizeof(*sect_rx->tcam));\n\n\t \n\tif (entry->enable) {\n\t\t \n\t\tval = 0x00;\n\t\tdc = 0xFF;\n\t\tnm = 0x00;\n\t} else {\n\t\t \n\t\tval = 0x00;\n\t\tdc = 0xF7;\n\t\tnm = 0x08;\n\t}\n\n\tice_set_key((u8 *)&sect_rx->tcam[0].key, sizeof(sect_rx->tcam[0].key),\n\t\t    &val, NULL, &dc, &nm, 0, sizeof(u8));\n\n\t \n\tmemcpy(sect_tx->tcam, sect_rx->tcam, sizeof(*sect_tx->tcam));\n\n\tstatus = ice_update_pkg_no_lock(hw, ice_pkg_buf(bld), 1);\n\nice_upd_dvm_boost_entry_err:\n\tice_pkg_buf_free(hw, bld);\n\n\treturn status;\n}\n\n \nint ice_set_dvm_boost_entries(struct ice_hw *hw)\n{\n\tu16 i;\n\n\tfor (i = 0; i < hw->dvm_upd.count; i++) {\n\t\tint status;\n\n\t\tstatus = ice_upd_dvm_boost_entry(hw, &hw->dvm_upd.tbl[i]);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\treturn 0;\n}\n\n \nstatic u16 ice_tunnel_idx_to_entry(struct ice_hw *hw, enum ice_tunnel_type type,\n\t\t\t\t   u16 idx)\n{\n\tu16 i;\n\n\tfor (i = 0; i < hw->tnl.count && i < ICE_TUNNEL_MAX_ENTRIES; i++)\n\t\tif (hw->tnl.tbl[i].valid &&\n\t\t    hw->tnl.tbl[i].type == type &&\n\t\t    idx-- == 0)\n\t\t\treturn i;\n\n\tWARN_ON_ONCE(1);\n\treturn 0;\n}\n\n \nstatic int\nice_create_tunnel(struct ice_hw *hw, u16 index,\n\t\t  enum ice_tunnel_type type, u16 port)\n{\n\tstruct ice_boost_tcam_section *sect_rx, *sect_tx;\n\tstruct ice_buf_build *bld;\n\tint status = -ENOSPC;\n\n\tmutex_lock(&hw->tnl_lock);\n\n\tbld = ice_pkg_buf_alloc(hw);\n\tif (!bld) {\n\t\tstatus = -ENOMEM;\n\t\tgoto ice_create_tunnel_end;\n\t}\n\n\t \n\tif (ice_pkg_buf_reserve_section(bld, 2))\n\t\tgoto ice_create_tunnel_err;\n\n\tsect_rx = ice_pkg_buf_alloc_section(bld, ICE_SID_RXPARSER_BOOST_TCAM,\n\t\t\t\t\t    struct_size(sect_rx, tcam, 1));\n\tif (!sect_rx)\n\t\tgoto ice_create_tunnel_err;\n\tsect_rx->count = cpu_to_le16(1);\n\n\tsect_tx = ice_pkg_buf_alloc_section(bld, ICE_SID_TXPARSER_BOOST_TCAM,\n\t\t\t\t\t    struct_size(sect_tx, tcam, 1));\n\tif (!sect_tx)\n\t\tgoto ice_create_tunnel_err;\n\tsect_tx->count = cpu_to_le16(1);\n\n\t \n\tmemcpy(sect_rx->tcam, hw->tnl.tbl[index].boost_entry,\n\t       sizeof(*sect_rx->tcam));\n\n\t \n\tice_set_key((u8 *)&sect_rx->tcam[0].key, sizeof(sect_rx->tcam[0].key),\n\t\t    (u8 *)&port, NULL, NULL, NULL,\n\t\t    (u16)offsetof(struct ice_boost_key_value, hv_dst_port_key),\n\t\t    sizeof(sect_rx->tcam[0].key.key.hv_dst_port_key));\n\n\t \n\tmemcpy(sect_tx->tcam, sect_rx->tcam, sizeof(*sect_tx->tcam));\n\n\tstatus = ice_update_pkg(hw, ice_pkg_buf(bld), 1);\n\tif (!status)\n\t\thw->tnl.tbl[index].port = port;\n\nice_create_tunnel_err:\n\tice_pkg_buf_free(hw, bld);\n\nice_create_tunnel_end:\n\tmutex_unlock(&hw->tnl_lock);\n\n\treturn status;\n}\n\n \nstatic int\nice_destroy_tunnel(struct ice_hw *hw, u16 index, enum ice_tunnel_type type,\n\t\t   u16 port)\n{\n\tstruct ice_boost_tcam_section *sect_rx, *sect_tx;\n\tstruct ice_buf_build *bld;\n\tint status = -ENOSPC;\n\n\tmutex_lock(&hw->tnl_lock);\n\n\tif (WARN_ON(!hw->tnl.tbl[index].valid ||\n\t\t    hw->tnl.tbl[index].type != type ||\n\t\t    hw->tnl.tbl[index].port != port)) {\n\t\tstatus = -EIO;\n\t\tgoto ice_destroy_tunnel_end;\n\t}\n\n\tbld = ice_pkg_buf_alloc(hw);\n\tif (!bld) {\n\t\tstatus = -ENOMEM;\n\t\tgoto ice_destroy_tunnel_end;\n\t}\n\n\t \n\tif (ice_pkg_buf_reserve_section(bld, 2))\n\t\tgoto ice_destroy_tunnel_err;\n\n\tsect_rx = ice_pkg_buf_alloc_section(bld, ICE_SID_RXPARSER_BOOST_TCAM,\n\t\t\t\t\t    struct_size(sect_rx, tcam, 1));\n\tif (!sect_rx)\n\t\tgoto ice_destroy_tunnel_err;\n\tsect_rx->count = cpu_to_le16(1);\n\n\tsect_tx = ice_pkg_buf_alloc_section(bld, ICE_SID_TXPARSER_BOOST_TCAM,\n\t\t\t\t\t    struct_size(sect_tx, tcam, 1));\n\tif (!sect_tx)\n\t\tgoto ice_destroy_tunnel_err;\n\tsect_tx->count = cpu_to_le16(1);\n\n\t \n\tmemcpy(sect_rx->tcam, hw->tnl.tbl[index].boost_entry,\n\t       sizeof(*sect_rx->tcam));\n\tmemcpy(sect_tx->tcam, hw->tnl.tbl[index].boost_entry,\n\t       sizeof(*sect_tx->tcam));\n\n\tstatus = ice_update_pkg(hw, ice_pkg_buf(bld), 1);\n\tif (!status)\n\t\thw->tnl.tbl[index].port = 0;\n\nice_destroy_tunnel_err:\n\tice_pkg_buf_free(hw, bld);\n\nice_destroy_tunnel_end:\n\tmutex_unlock(&hw->tnl_lock);\n\n\treturn status;\n}\n\nint ice_udp_tunnel_set_port(struct net_device *netdev, unsigned int table,\n\t\t\t    unsigned int idx, struct udp_tunnel_info *ti)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(netdev);\n\tstruct ice_vsi *vsi = np->vsi;\n\tstruct ice_pf *pf = vsi->back;\n\tenum ice_tunnel_type tnl_type;\n\tint status;\n\tu16 index;\n\n\ttnl_type = ti->type == UDP_TUNNEL_TYPE_VXLAN ? TNL_VXLAN : TNL_GENEVE;\n\tindex = ice_tunnel_idx_to_entry(&pf->hw, tnl_type, idx);\n\n\tstatus = ice_create_tunnel(&pf->hw, index, tnl_type, ntohs(ti->port));\n\tif (status) {\n\t\tnetdev_err(netdev, \"Error adding UDP tunnel - %d\\n\",\n\t\t\t   status);\n\t\treturn -EIO;\n\t}\n\n\tudp_tunnel_nic_set_port_priv(netdev, table, idx, index);\n\treturn 0;\n}\n\nint ice_udp_tunnel_unset_port(struct net_device *netdev, unsigned int table,\n\t\t\t      unsigned int idx, struct udp_tunnel_info *ti)\n{\n\tstruct ice_netdev_priv *np = netdev_priv(netdev);\n\tstruct ice_vsi *vsi = np->vsi;\n\tstruct ice_pf *pf = vsi->back;\n\tenum ice_tunnel_type tnl_type;\n\tint status;\n\n\ttnl_type = ti->type == UDP_TUNNEL_TYPE_VXLAN ? TNL_VXLAN : TNL_GENEVE;\n\n\tstatus = ice_destroy_tunnel(&pf->hw, ti->hw_priv, tnl_type,\n\t\t\t\t    ntohs(ti->port));\n\tif (status) {\n\t\tnetdev_err(netdev, \"Error removing UDP tunnel - %d\\n\",\n\t\t\t   status);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nint\nice_find_prot_off(struct ice_hw *hw, enum ice_block blk, u8 prof, u16 fv_idx,\n\t\t  u8 *prot, u16 *off)\n{\n\tstruct ice_fv_word *fv_ext;\n\n\tif (prof >= hw->blk[blk].es.count)\n\t\treturn -EINVAL;\n\n\tif (fv_idx >= hw->blk[blk].es.fvw)\n\t\treturn -EINVAL;\n\n\tfv_ext = hw->blk[blk].es.t + (prof * hw->blk[blk].es.fvw);\n\n\t*prot = fv_ext[fv_idx].prot_id;\n\t*off = fv_ext[fv_idx].off;\n\n\treturn 0;\n}\n\n \n\n \nstatic int\nice_ptg_find_ptype(struct ice_hw *hw, enum ice_block blk, u16 ptype, u8 *ptg)\n{\n\tif (ptype >= ICE_XLT1_CNT || !ptg)\n\t\treturn -EINVAL;\n\n\t*ptg = hw->blk[blk].xlt1.ptypes[ptype].ptg;\n\treturn 0;\n}\n\n \nstatic void ice_ptg_alloc_val(struct ice_hw *hw, enum ice_block blk, u8 ptg)\n{\n\thw->blk[blk].xlt1.ptg_tbl[ptg].in_use = true;\n}\n\n \nstatic int\nice_ptg_remove_ptype(struct ice_hw *hw, enum ice_block blk, u16 ptype, u8 ptg)\n{\n\tstruct ice_ptg_ptype **ch;\n\tstruct ice_ptg_ptype *p;\n\n\tif (ptype > ICE_XLT1_CNT - 1)\n\t\treturn -EINVAL;\n\n\tif (!hw->blk[blk].xlt1.ptg_tbl[ptg].in_use)\n\t\treturn -ENOENT;\n\n\t \n\tif (!hw->blk[blk].xlt1.ptg_tbl[ptg].first_ptype)\n\t\treturn -EIO;\n\n\t \n\tp = hw->blk[blk].xlt1.ptg_tbl[ptg].first_ptype;\n\tch = &hw->blk[blk].xlt1.ptg_tbl[ptg].first_ptype;\n\twhile (p) {\n\t\tif (ptype == (p - hw->blk[blk].xlt1.ptypes)) {\n\t\t\t*ch = p->next_ptype;\n\t\t\tbreak;\n\t\t}\n\n\t\tch = &p->next_ptype;\n\t\tp = p->next_ptype;\n\t}\n\n\thw->blk[blk].xlt1.ptypes[ptype].ptg = ICE_DEFAULT_PTG;\n\thw->blk[blk].xlt1.ptypes[ptype].next_ptype = NULL;\n\n\treturn 0;\n}\n\n \nstatic int\nice_ptg_add_mv_ptype(struct ice_hw *hw, enum ice_block blk, u16 ptype, u8 ptg)\n{\n\tu8 original_ptg;\n\tint status;\n\n\tif (ptype > ICE_XLT1_CNT - 1)\n\t\treturn -EINVAL;\n\n\tif (!hw->blk[blk].xlt1.ptg_tbl[ptg].in_use && ptg != ICE_DEFAULT_PTG)\n\t\treturn -ENOENT;\n\n\tstatus = ice_ptg_find_ptype(hw, blk, ptype, &original_ptg);\n\tif (status)\n\t\treturn status;\n\n\t \n\tif (original_ptg == ptg)\n\t\treturn 0;\n\n\t \n\tif (original_ptg != ICE_DEFAULT_PTG)\n\t\tice_ptg_remove_ptype(hw, blk, ptype, original_ptg);\n\n\t \n\tif (ptg == ICE_DEFAULT_PTG)\n\t\treturn 0;\n\n\t \n\thw->blk[blk].xlt1.ptypes[ptype].next_ptype =\n\t\thw->blk[blk].xlt1.ptg_tbl[ptg].first_ptype;\n\thw->blk[blk].xlt1.ptg_tbl[ptg].first_ptype =\n\t\t&hw->blk[blk].xlt1.ptypes[ptype];\n\n\thw->blk[blk].xlt1.ptypes[ptype].ptg = ptg;\n\thw->blk[blk].xlt1.t[ptype] = ptg;\n\n\treturn 0;\n}\n\n \nstruct ice_blk_size_details {\n\tu16 xlt1;\t\t\t \n\tu16 xlt2;\t\t\t \n\tu16 prof_tcam;\t\t\t \n\tu16 prof_id;\t\t\t \n\tu8 prof_cdid_bits;\t\t \n\tu16 prof_redir;\t\t\t \n\tu16 es;\t\t\t\t \n\tu16 fvw;\t\t\t \n\tu8 overwrite;\t\t\t \n\tu8 reverse;\t\t\t \n};\n\nstatic const struct ice_blk_size_details blk_sizes[ICE_BLK_COUNT] = {\n\t \n\t \n\t \n\t  { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 256,   0,  256, 256,  48,\n\t\t    false, false },\n\t  { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 128,   0,  128, 128,  32,\n\t\t    false, false },\n\t  { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 128,   0,  128, 128,  24,\n\t\t    false, true  },\n\t  { ICE_XLT1_CNT, ICE_XLT2_CNT, 512, 128,   0,  128, 128,  24,\n\t\t    true,  true  },\n\t  { ICE_XLT1_CNT, ICE_XLT2_CNT,  64,  32,   0,   32,  32,  24,\n\t\t    false, false },\n};\n\nenum ice_sid_all {\n\tICE_SID_XLT1_OFF = 0,\n\tICE_SID_XLT2_OFF,\n\tICE_SID_PR_OFF,\n\tICE_SID_PR_REDIR_OFF,\n\tICE_SID_ES_OFF,\n\tICE_SID_OFF_COUNT,\n};\n\n \n\n \nstatic bool\nice_match_prop_lst(struct list_head *list1, struct list_head *list2)\n{\n\tstruct ice_vsig_prof *tmp1;\n\tstruct ice_vsig_prof *tmp2;\n\tu16 chk_count = 0;\n\tu16 count = 0;\n\n\t \n\tlist_for_each_entry(tmp1, list1, list)\n\t\tcount++;\n\tlist_for_each_entry(tmp2, list2, list)\n\t\tchk_count++;\n\tif (!count || count != chk_count)\n\t\treturn false;\n\n\ttmp1 = list_first_entry(list1, struct ice_vsig_prof, list);\n\ttmp2 = list_first_entry(list2, struct ice_vsig_prof, list);\n\n\t \n\twhile (count--) {\n\t\tif (tmp2->profile_cookie != tmp1->profile_cookie)\n\t\t\treturn false;\n\n\t\ttmp1 = list_next_entry(tmp1, list);\n\t\ttmp2 = list_next_entry(tmp2, list);\n\t}\n\n\treturn true;\n}\n\n \n\n \nstatic int\nice_vsig_find_vsi(struct ice_hw *hw, enum ice_block blk, u16 vsi, u16 *vsig)\n{\n\tif (!vsig || vsi >= ICE_MAX_VSI)\n\t\treturn -EINVAL;\n\n\t \n\t*vsig = hw->blk[blk].xlt2.vsis[vsi].vsig;\n\n\treturn 0;\n}\n\n \nstatic u16 ice_vsig_alloc_val(struct ice_hw *hw, enum ice_block blk, u16 vsig)\n{\n\tu16 idx = vsig & ICE_VSIG_IDX_M;\n\n\tif (!hw->blk[blk].xlt2.vsig_tbl[idx].in_use) {\n\t\tINIT_LIST_HEAD(&hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst);\n\t\thw->blk[blk].xlt2.vsig_tbl[idx].in_use = true;\n\t}\n\n\treturn ICE_VSIG_VALUE(idx, hw->pf_id);\n}\n\n \nstatic u16 ice_vsig_alloc(struct ice_hw *hw, enum ice_block blk)\n{\n\tu16 i;\n\n\tfor (i = 1; i < ICE_MAX_VSIGS; i++)\n\t\tif (!hw->blk[blk].xlt2.vsig_tbl[i].in_use)\n\t\t\treturn ice_vsig_alloc_val(hw, blk, i);\n\n\treturn ICE_DEFAULT_VSIG;\n}\n\n \nstatic int\nice_find_dup_props_vsig(struct ice_hw *hw, enum ice_block blk,\n\t\t\tstruct list_head *chs, u16 *vsig)\n{\n\tstruct ice_xlt2 *xlt2 = &hw->blk[blk].xlt2;\n\tu16 i;\n\n\tfor (i = 0; i < xlt2->count; i++)\n\t\tif (xlt2->vsig_tbl[i].in_use &&\n\t\t    ice_match_prop_lst(chs, &xlt2->vsig_tbl[i].prop_lst)) {\n\t\t\t*vsig = ICE_VSIG_VALUE(i, hw->pf_id);\n\t\t\treturn 0;\n\t\t}\n\n\treturn -ENOENT;\n}\n\n \nstatic int ice_vsig_free(struct ice_hw *hw, enum ice_block blk, u16 vsig)\n{\n\tstruct ice_vsig_prof *dtmp, *del;\n\tstruct ice_vsig_vsi *vsi_cur;\n\tu16 idx;\n\n\tidx = vsig & ICE_VSIG_IDX_M;\n\tif (idx >= ICE_MAX_VSIGS)\n\t\treturn -EINVAL;\n\n\tif (!hw->blk[blk].xlt2.vsig_tbl[idx].in_use)\n\t\treturn -ENOENT;\n\n\thw->blk[blk].xlt2.vsig_tbl[idx].in_use = false;\n\n\tvsi_cur = hw->blk[blk].xlt2.vsig_tbl[idx].first_vsi;\n\t \n\tif (vsi_cur) {\n\t\t \n\t\tdo {\n\t\t\tstruct ice_vsig_vsi *tmp = vsi_cur->next_vsi;\n\n\t\t\tvsi_cur->vsig = ICE_DEFAULT_VSIG;\n\t\t\tvsi_cur->changed = 1;\n\t\t\tvsi_cur->next_vsi = NULL;\n\t\t\tvsi_cur = tmp;\n\t\t} while (vsi_cur);\n\n\t\t \n\t\thw->blk[blk].xlt2.vsig_tbl[idx].first_vsi = NULL;\n\t}\n\n\t \n\tlist_for_each_entry_safe(del, dtmp,\n\t\t\t\t &hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst,\n\t\t\t\t list) {\n\t\tlist_del(&del->list);\n\t\tdevm_kfree(ice_hw_to_dev(hw), del);\n\t}\n\n\t \n\tINIT_LIST_HEAD(&hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst);\n\n\treturn 0;\n}\n\n \nstatic int\nice_vsig_remove_vsi(struct ice_hw *hw, enum ice_block blk, u16 vsi, u16 vsig)\n{\n\tstruct ice_vsig_vsi **vsi_head, *vsi_cur, *vsi_tgt;\n\tu16 idx;\n\n\tidx = vsig & ICE_VSIG_IDX_M;\n\n\tif (vsi >= ICE_MAX_VSI || idx >= ICE_MAX_VSIGS)\n\t\treturn -EINVAL;\n\n\tif (!hw->blk[blk].xlt2.vsig_tbl[idx].in_use)\n\t\treturn -ENOENT;\n\n\t \n\tif (idx == ICE_DEFAULT_VSIG)\n\t\treturn 0;\n\n\tvsi_head = &hw->blk[blk].xlt2.vsig_tbl[idx].first_vsi;\n\tif (!(*vsi_head))\n\t\treturn -EIO;\n\n\tvsi_tgt = &hw->blk[blk].xlt2.vsis[vsi];\n\tvsi_cur = (*vsi_head);\n\n\t \n\twhile (vsi_cur) {\n\t\tif (vsi_tgt == vsi_cur) {\n\t\t\t(*vsi_head) = vsi_cur->next_vsi;\n\t\t\tbreak;\n\t\t}\n\t\tvsi_head = &vsi_cur->next_vsi;\n\t\tvsi_cur = vsi_cur->next_vsi;\n\t}\n\n\t \n\tif (!vsi_cur)\n\t\treturn -ENOENT;\n\n\tvsi_cur->vsig = ICE_DEFAULT_VSIG;\n\tvsi_cur->changed = 1;\n\tvsi_cur->next_vsi = NULL;\n\n\treturn 0;\n}\n\n \nstatic int\nice_vsig_add_mv_vsi(struct ice_hw *hw, enum ice_block blk, u16 vsi, u16 vsig)\n{\n\tstruct ice_vsig_vsi *tmp;\n\tu16 orig_vsig, idx;\n\tint status;\n\n\tidx = vsig & ICE_VSIG_IDX_M;\n\n\tif (vsi >= ICE_MAX_VSI || idx >= ICE_MAX_VSIGS)\n\t\treturn -EINVAL;\n\n\t \n\tif (!hw->blk[blk].xlt2.vsig_tbl[idx].in_use &&\n\t    vsig != ICE_DEFAULT_VSIG)\n\t\treturn -ENOENT;\n\n\tstatus = ice_vsig_find_vsi(hw, blk, vsi, &orig_vsig);\n\tif (status)\n\t\treturn status;\n\n\t \n\tif (orig_vsig == vsig)\n\t\treturn 0;\n\n\tif (orig_vsig != ICE_DEFAULT_VSIG) {\n\t\t \n\t\tstatus = ice_vsig_remove_vsi(hw, blk, vsi, orig_vsig);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\tif (idx == ICE_DEFAULT_VSIG)\n\t\treturn 0;\n\n\t \n\thw->blk[blk].xlt2.vsis[vsi].vsig = vsig;\n\thw->blk[blk].xlt2.vsis[vsi].changed = 1;\n\n\t \n\ttmp = hw->blk[blk].xlt2.vsig_tbl[idx].first_vsi;\n\thw->blk[blk].xlt2.vsig_tbl[idx].first_vsi =\n\t\t&hw->blk[blk].xlt2.vsis[vsi];\n\thw->blk[blk].xlt2.vsis[vsi].next_vsi = tmp;\n\thw->blk[blk].xlt2.t[vsi] = vsig;\n\n\treturn 0;\n}\n\n \nstatic bool\nice_prof_has_mask_idx(struct ice_hw *hw, enum ice_block blk, u8 prof, u16 idx,\n\t\t      u16 mask)\n{\n\tbool expect_no_mask = false;\n\tbool found = false;\n\tbool match = false;\n\tu16 i;\n\n\t \n\tif (mask == 0 || mask == 0xffff)\n\t\texpect_no_mask = true;\n\n\t \n\tfor (i = hw->blk[blk].masks.first; i < hw->blk[blk].masks.first +\n\t     hw->blk[blk].masks.count; i++)\n\t\tif (hw->blk[blk].es.mask_ena[prof] & BIT(i))\n\t\t\tif (hw->blk[blk].masks.masks[i].in_use &&\n\t\t\t    hw->blk[blk].masks.masks[i].idx == idx) {\n\t\t\t\tfound = true;\n\t\t\t\tif (hw->blk[blk].masks.masks[i].mask == mask)\n\t\t\t\t\tmatch = true;\n\t\t\t\tbreak;\n\t\t\t}\n\n\tif (expect_no_mask) {\n\t\tif (found)\n\t\t\treturn false;\n\t} else {\n\t\tif (!match)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic bool\nice_prof_has_mask(struct ice_hw *hw, enum ice_block blk, u8 prof, u16 *masks)\n{\n\tu16 i;\n\n\t \n\tfor (i = 0; i < hw->blk[blk].es.fvw; i++)\n\t\tif (!ice_prof_has_mask_idx(hw, blk, prof, i, masks[i]))\n\t\t\treturn false;\n\n\treturn true;\n}\n\n \nstatic int\nice_find_prof_id_with_mask(struct ice_hw *hw, enum ice_block blk,\n\t\t\t   struct ice_fv_word *fv, u16 *masks, u8 *prof_id)\n{\n\tstruct ice_es *es = &hw->blk[blk].es;\n\tu8 i;\n\n\t \n\tif (blk == ICE_BLK_FD)\n\t\treturn -ENOENT;\n\n\tfor (i = 0; i < (u8)es->count; i++) {\n\t\tu16 off = i * es->fvw;\n\n\t\tif (memcmp(&es->t[off], fv, es->fvw * sizeof(*fv)))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (masks && !ice_prof_has_mask(hw, blk, i, masks))\n\t\t\tcontinue;\n\n\t\t*prof_id = i;\n\t\treturn 0;\n\t}\n\n\treturn -ENOENT;\n}\n\n \nstatic bool ice_prof_id_rsrc_type(enum ice_block blk, u16 *rsrc_type)\n{\n\tswitch (blk) {\n\tcase ICE_BLK_FD:\n\t\t*rsrc_type = ICE_AQC_RES_TYPE_FD_PROF_BLDR_PROFID;\n\t\tbreak;\n\tcase ICE_BLK_RSS:\n\t\t*rsrc_type = ICE_AQC_RES_TYPE_HASH_PROF_BLDR_PROFID;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\treturn true;\n}\n\n \nstatic bool ice_tcam_ent_rsrc_type(enum ice_block blk, u16 *rsrc_type)\n{\n\tswitch (blk) {\n\tcase ICE_BLK_FD:\n\t\t*rsrc_type = ICE_AQC_RES_TYPE_FD_PROF_BLDR_TCAM;\n\t\tbreak;\n\tcase ICE_BLK_RSS:\n\t\t*rsrc_type = ICE_AQC_RES_TYPE_HASH_PROF_BLDR_TCAM;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\treturn true;\n}\n\n \nstatic int\nice_alloc_tcam_ent(struct ice_hw *hw, enum ice_block blk, bool btm,\n\t\t   u16 *tcam_idx)\n{\n\tu16 res_type;\n\n\tif (!ice_tcam_ent_rsrc_type(blk, &res_type))\n\t\treturn -EINVAL;\n\n\treturn ice_alloc_hw_res(hw, res_type, 1, btm, tcam_idx);\n}\n\n \nstatic int\nice_free_tcam_ent(struct ice_hw *hw, enum ice_block blk, u16 tcam_idx)\n{\n\tu16 res_type;\n\n\tif (!ice_tcam_ent_rsrc_type(blk, &res_type))\n\t\treturn -EINVAL;\n\n\treturn ice_free_hw_res(hw, res_type, 1, &tcam_idx);\n}\n\n \nstatic int ice_alloc_prof_id(struct ice_hw *hw, enum ice_block blk, u8 *prof_id)\n{\n\tu16 res_type;\n\tu16 get_prof;\n\tint status;\n\n\tif (!ice_prof_id_rsrc_type(blk, &res_type))\n\t\treturn -EINVAL;\n\n\tstatus = ice_alloc_hw_res(hw, res_type, 1, false, &get_prof);\n\tif (!status)\n\t\t*prof_id = (u8)get_prof;\n\n\treturn status;\n}\n\n \nstatic int ice_free_prof_id(struct ice_hw *hw, enum ice_block blk, u8 prof_id)\n{\n\tu16 tmp_prof_id = (u16)prof_id;\n\tu16 res_type;\n\n\tif (!ice_prof_id_rsrc_type(blk, &res_type))\n\t\treturn -EINVAL;\n\n\treturn ice_free_hw_res(hw, res_type, 1, &tmp_prof_id);\n}\n\n \nstatic int ice_prof_inc_ref(struct ice_hw *hw, enum ice_block blk, u8 prof_id)\n{\n\tif (prof_id > hw->blk[blk].es.count)\n\t\treturn -EINVAL;\n\n\thw->blk[blk].es.ref_count[prof_id]++;\n\n\treturn 0;\n}\n\n \nstatic void\nice_write_prof_mask_reg(struct ice_hw *hw, enum ice_block blk, u16 mask_idx,\n\t\t\tu16 idx, u16 mask)\n{\n\tu32 offset;\n\tu32 val;\n\n\tswitch (blk) {\n\tcase ICE_BLK_RSS:\n\t\toffset = GLQF_HMASK(mask_idx);\n\t\tval = (idx << GLQF_HMASK_MSK_INDEX_S) & GLQF_HMASK_MSK_INDEX_M;\n\t\tval |= (mask << GLQF_HMASK_MASK_S) & GLQF_HMASK_MASK_M;\n\t\tbreak;\n\tcase ICE_BLK_FD:\n\t\toffset = GLQF_FDMASK(mask_idx);\n\t\tval = (idx << GLQF_FDMASK_MSK_INDEX_S) & GLQF_FDMASK_MSK_INDEX_M;\n\t\tval |= (mask << GLQF_FDMASK_MASK_S) & GLQF_FDMASK_MASK_M;\n\t\tbreak;\n\tdefault:\n\t\tice_debug(hw, ICE_DBG_PKG, \"No profile masks for block %d\\n\",\n\t\t\t  blk);\n\t\treturn;\n\t}\n\n\twr32(hw, offset, val);\n\tice_debug(hw, ICE_DBG_PKG, \"write mask, blk %d (%d): %x = %x\\n\",\n\t\t  blk, idx, offset, val);\n}\n\n \nstatic void\nice_write_prof_mask_enable_res(struct ice_hw *hw, enum ice_block blk,\n\t\t\t       u16 prof_id, u32 enable_mask)\n{\n\tu32 offset;\n\n\tswitch (blk) {\n\tcase ICE_BLK_RSS:\n\t\toffset = GLQF_HMASK_SEL(prof_id);\n\t\tbreak;\n\tcase ICE_BLK_FD:\n\t\toffset = GLQF_FDMASK_SEL(prof_id);\n\t\tbreak;\n\tdefault:\n\t\tice_debug(hw, ICE_DBG_PKG, \"No profile masks for block %d\\n\",\n\t\t\t  blk);\n\t\treturn;\n\t}\n\n\twr32(hw, offset, enable_mask);\n\tice_debug(hw, ICE_DBG_PKG, \"write mask enable, blk %d (%d): %x = %x\\n\",\n\t\t  blk, prof_id, offset, enable_mask);\n}\n\n \nstatic void ice_init_prof_masks(struct ice_hw *hw, enum ice_block blk)\n{\n\tu16 per_pf;\n\tu16 i;\n\n\tmutex_init(&hw->blk[blk].masks.lock);\n\n\tper_pf = ICE_PROF_MASK_COUNT / hw->dev_caps.num_funcs;\n\n\thw->blk[blk].masks.count = per_pf;\n\thw->blk[blk].masks.first = hw->pf_id * per_pf;\n\n\tmemset(hw->blk[blk].masks.masks, 0, sizeof(hw->blk[blk].masks.masks));\n\n\tfor (i = hw->blk[blk].masks.first;\n\t     i < hw->blk[blk].masks.first + hw->blk[blk].masks.count; i++)\n\t\tice_write_prof_mask_reg(hw, blk, i, 0, 0);\n}\n\n \nstatic void ice_init_all_prof_masks(struct ice_hw *hw)\n{\n\tice_init_prof_masks(hw, ICE_BLK_RSS);\n\tice_init_prof_masks(hw, ICE_BLK_FD);\n}\n\n \nstatic int\nice_alloc_prof_mask(struct ice_hw *hw, enum ice_block blk, u16 idx, u16 mask,\n\t\t    u16 *mask_idx)\n{\n\tbool found_unused = false, found_copy = false;\n\tu16 unused_idx = 0, copy_idx = 0;\n\tint status = -ENOSPC;\n\tu16 i;\n\n\tif (blk != ICE_BLK_RSS && blk != ICE_BLK_FD)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&hw->blk[blk].masks.lock);\n\n\tfor (i = hw->blk[blk].masks.first;\n\t     i < hw->blk[blk].masks.first + hw->blk[blk].masks.count; i++)\n\t\tif (hw->blk[blk].masks.masks[i].in_use) {\n\t\t\t \n\t\t\tif (hw->blk[blk].masks.masks[i].mask == mask &&\n\t\t\t    hw->blk[blk].masks.masks[i].idx == idx) {\n\t\t\t\tfound_copy = true;\n\t\t\t\tcopy_idx = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tif (!found_unused) {\n\t\t\t\tfound_unused = true;\n\t\t\t\tunused_idx = i;\n\t\t\t}\n\t\t}\n\n\tif (found_copy)\n\t\ti = copy_idx;\n\telse if (found_unused)\n\t\ti = unused_idx;\n\telse\n\t\tgoto err_ice_alloc_prof_mask;\n\n\t \n\tif (found_unused) {\n\t\thw->blk[blk].masks.masks[i].in_use = true;\n\t\thw->blk[blk].masks.masks[i].mask = mask;\n\t\thw->blk[blk].masks.masks[i].idx = idx;\n\t\thw->blk[blk].masks.masks[i].ref = 0;\n\t\tice_write_prof_mask_reg(hw, blk, i, idx, mask);\n\t}\n\n\thw->blk[blk].masks.masks[i].ref++;\n\t*mask_idx = i;\n\tstatus = 0;\n\nerr_ice_alloc_prof_mask:\n\tmutex_unlock(&hw->blk[blk].masks.lock);\n\n\treturn status;\n}\n\n \nstatic int\nice_free_prof_mask(struct ice_hw *hw, enum ice_block blk, u16 mask_idx)\n{\n\tif (blk != ICE_BLK_RSS && blk != ICE_BLK_FD)\n\t\treturn -EINVAL;\n\n\tif (!(mask_idx >= hw->blk[blk].masks.first &&\n\t      mask_idx < hw->blk[blk].masks.first + hw->blk[blk].masks.count))\n\t\treturn -ENOENT;\n\n\tmutex_lock(&hw->blk[blk].masks.lock);\n\n\tif (!hw->blk[blk].masks.masks[mask_idx].in_use)\n\t\tgoto exit_ice_free_prof_mask;\n\n\tif (hw->blk[blk].masks.masks[mask_idx].ref > 1) {\n\t\thw->blk[blk].masks.masks[mask_idx].ref--;\n\t\tgoto exit_ice_free_prof_mask;\n\t}\n\n\t \n\thw->blk[blk].masks.masks[mask_idx].in_use = false;\n\thw->blk[blk].masks.masks[mask_idx].mask = 0;\n\thw->blk[blk].masks.masks[mask_idx].idx = 0;\n\n\t \n\tice_debug(hw, ICE_DBG_PKG, \"Free mask, blk %d, mask %d\\n\", blk,\n\t\t  mask_idx);\n\tice_write_prof_mask_reg(hw, blk, mask_idx, 0, 0);\n\nexit_ice_free_prof_mask:\n\tmutex_unlock(&hw->blk[blk].masks.lock);\n\n\treturn 0;\n}\n\n \nstatic int\nice_free_prof_masks(struct ice_hw *hw, enum ice_block blk, u16 prof_id)\n{\n\tu32 mask_bm;\n\tu16 i;\n\n\tif (blk != ICE_BLK_RSS && blk != ICE_BLK_FD)\n\t\treturn -EINVAL;\n\n\tmask_bm = hw->blk[blk].es.mask_ena[prof_id];\n\tfor (i = 0; i < BITS_PER_BYTE * sizeof(mask_bm); i++)\n\t\tif (mask_bm & BIT(i))\n\t\t\tice_free_prof_mask(hw, blk, i);\n\n\treturn 0;\n}\n\n \nstatic void ice_shutdown_prof_masks(struct ice_hw *hw, enum ice_block blk)\n{\n\tu16 i;\n\n\tmutex_lock(&hw->blk[blk].masks.lock);\n\n\tfor (i = hw->blk[blk].masks.first;\n\t     i < hw->blk[blk].masks.first + hw->blk[blk].masks.count; i++) {\n\t\tice_write_prof_mask_reg(hw, blk, i, 0, 0);\n\n\t\thw->blk[blk].masks.masks[i].in_use = false;\n\t\thw->blk[blk].masks.masks[i].idx = 0;\n\t\thw->blk[blk].masks.masks[i].mask = 0;\n\t}\n\n\tmutex_unlock(&hw->blk[blk].masks.lock);\n\tmutex_destroy(&hw->blk[blk].masks.lock);\n}\n\n \nstatic void ice_shutdown_all_prof_masks(struct ice_hw *hw)\n{\n\tice_shutdown_prof_masks(hw, ICE_BLK_RSS);\n\tice_shutdown_prof_masks(hw, ICE_BLK_FD);\n}\n\n \nstatic int\nice_update_prof_masking(struct ice_hw *hw, enum ice_block blk, u16 prof_id,\n\t\t\tu16 *masks)\n{\n\tbool err = false;\n\tu32 ena_mask = 0;\n\tu16 idx;\n\tu16 i;\n\n\t \n\tif (blk != ICE_BLK_RSS && blk != ICE_BLK_FD)\n\t\treturn 0;\n\n\tfor (i = 0; i < hw->blk[blk].es.fvw; i++)\n\t\tif (masks[i] && masks[i] != 0xFFFF) {\n\t\t\tif (!ice_alloc_prof_mask(hw, blk, i, masks[i], &idx)) {\n\t\t\t\tena_mask |= BIT(idx);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\terr = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\tif (err) {\n\t\t \n\t\tfor (i = 0; i < BITS_PER_BYTE * sizeof(ena_mask); i++)\n\t\t\tif (ena_mask & BIT(i))\n\t\t\t\tice_free_prof_mask(hw, blk, i);\n\n\t\treturn -EIO;\n\t}\n\n\t \n\tice_write_prof_mask_enable_res(hw, blk, prof_id, ena_mask);\n\n\t \n\thw->blk[blk].es.mask_ena[prof_id] = ena_mask;\n\n\treturn 0;\n}\n\n \nstatic void\nice_write_es(struct ice_hw *hw, enum ice_block blk, u8 prof_id,\n\t     struct ice_fv_word *fv)\n{\n\tu16 off;\n\n\toff = prof_id * hw->blk[blk].es.fvw;\n\tif (!fv) {\n\t\tmemset(&hw->blk[blk].es.t[off], 0,\n\t\t       hw->blk[blk].es.fvw * sizeof(*fv));\n\t\thw->blk[blk].es.written[prof_id] = false;\n\t} else {\n\t\tmemcpy(&hw->blk[blk].es.t[off], fv,\n\t\t       hw->blk[blk].es.fvw * sizeof(*fv));\n\t}\n}\n\n \nstatic int\nice_prof_dec_ref(struct ice_hw *hw, enum ice_block blk, u8 prof_id)\n{\n\tif (prof_id > hw->blk[blk].es.count)\n\t\treturn -EINVAL;\n\n\tif (hw->blk[blk].es.ref_count[prof_id] > 0) {\n\t\tif (!--hw->blk[blk].es.ref_count[prof_id]) {\n\t\t\tice_write_es(hw, blk, prof_id, NULL);\n\t\t\tice_free_prof_masks(hw, blk, prof_id);\n\t\t\treturn ice_free_prof_id(hw, blk, prof_id);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic const u32 ice_blk_sids[ICE_BLK_COUNT][ICE_SID_OFF_COUNT] = {\n\t \n\t{\tICE_SID_XLT1_SW,\n\t\tICE_SID_XLT2_SW,\n\t\tICE_SID_PROFID_TCAM_SW,\n\t\tICE_SID_PROFID_REDIR_SW,\n\t\tICE_SID_FLD_VEC_SW\n\t},\n\n\t \n\t{\tICE_SID_XLT1_ACL,\n\t\tICE_SID_XLT2_ACL,\n\t\tICE_SID_PROFID_TCAM_ACL,\n\t\tICE_SID_PROFID_REDIR_ACL,\n\t\tICE_SID_FLD_VEC_ACL\n\t},\n\n\t \n\t{\tICE_SID_XLT1_FD,\n\t\tICE_SID_XLT2_FD,\n\t\tICE_SID_PROFID_TCAM_FD,\n\t\tICE_SID_PROFID_REDIR_FD,\n\t\tICE_SID_FLD_VEC_FD\n\t},\n\n\t \n\t{\tICE_SID_XLT1_RSS,\n\t\tICE_SID_XLT2_RSS,\n\t\tICE_SID_PROFID_TCAM_RSS,\n\t\tICE_SID_PROFID_REDIR_RSS,\n\t\tICE_SID_FLD_VEC_RSS\n\t},\n\n\t \n\t{\tICE_SID_XLT1_PE,\n\t\tICE_SID_XLT2_PE,\n\t\tICE_SID_PROFID_TCAM_PE,\n\t\tICE_SID_PROFID_REDIR_PE,\n\t\tICE_SID_FLD_VEC_PE\n\t}\n};\n\n \nstatic void ice_init_sw_xlt1_db(struct ice_hw *hw, enum ice_block blk)\n{\n\tu16 pt;\n\n\tfor (pt = 0; pt < hw->blk[blk].xlt1.count; pt++) {\n\t\tu8 ptg;\n\n\t\tptg = hw->blk[blk].xlt1.t[pt];\n\t\tif (ptg != ICE_DEFAULT_PTG) {\n\t\t\tice_ptg_alloc_val(hw, blk, ptg);\n\t\t\tice_ptg_add_mv_ptype(hw, blk, pt, ptg);\n\t\t}\n\t}\n}\n\n \nstatic void ice_init_sw_xlt2_db(struct ice_hw *hw, enum ice_block blk)\n{\n\tu16 vsi;\n\n\tfor (vsi = 0; vsi < hw->blk[blk].xlt2.count; vsi++) {\n\t\tu16 vsig;\n\n\t\tvsig = hw->blk[blk].xlt2.t[vsi];\n\t\tif (vsig) {\n\t\t\tice_vsig_alloc_val(hw, blk, vsig);\n\t\t\tice_vsig_add_mv_vsi(hw, blk, vsi, vsig);\n\t\t\t \n\t\t\thw->blk[blk].xlt2.vsis[vsi].changed = 0;\n\t\t}\n\t}\n}\n\n \nstatic void ice_init_sw_db(struct ice_hw *hw)\n{\n\tu16 i;\n\n\tfor (i = 0; i < ICE_BLK_COUNT; i++) {\n\t\tice_init_sw_xlt1_db(hw, (enum ice_block)i);\n\t\tice_init_sw_xlt2_db(hw, (enum ice_block)i);\n\t}\n}\n\n \nstatic void ice_fill_tbl(struct ice_hw *hw, enum ice_block block_id, u32 sid)\n{\n\tu32 dst_len, sect_len, offset = 0;\n\tstruct ice_prof_redir_section *pr;\n\tstruct ice_prof_id_section *pid;\n\tstruct ice_xlt1_section *xlt1;\n\tstruct ice_xlt2_section *xlt2;\n\tstruct ice_sw_fv_section *es;\n\tstruct ice_pkg_enum state;\n\tu8 *src, *dst;\n\tvoid *sect;\n\n\t \n\tif (!hw->seg) {\n\t\tice_debug(hw, ICE_DBG_PKG, \"hw->seg is NULL, tables are not filled\\n\");\n\t\treturn;\n\t}\n\n\tmemset(&state, 0, sizeof(state));\n\n\tsect = ice_pkg_enum_section(hw->seg, &state, sid);\n\n\twhile (sect) {\n\t\tswitch (sid) {\n\t\tcase ICE_SID_XLT1_SW:\n\t\tcase ICE_SID_XLT1_FD:\n\t\tcase ICE_SID_XLT1_RSS:\n\t\tcase ICE_SID_XLT1_ACL:\n\t\tcase ICE_SID_XLT1_PE:\n\t\t\txlt1 = sect;\n\t\t\tsrc = xlt1->value;\n\t\t\tsect_len = le16_to_cpu(xlt1->count) *\n\t\t\t\tsizeof(*hw->blk[block_id].xlt1.t);\n\t\t\tdst = hw->blk[block_id].xlt1.t;\n\t\t\tdst_len = hw->blk[block_id].xlt1.count *\n\t\t\t\tsizeof(*hw->blk[block_id].xlt1.t);\n\t\t\tbreak;\n\t\tcase ICE_SID_XLT2_SW:\n\t\tcase ICE_SID_XLT2_FD:\n\t\tcase ICE_SID_XLT2_RSS:\n\t\tcase ICE_SID_XLT2_ACL:\n\t\tcase ICE_SID_XLT2_PE:\n\t\t\txlt2 = sect;\n\t\t\tsrc = (__force u8 *)xlt2->value;\n\t\t\tsect_len = le16_to_cpu(xlt2->count) *\n\t\t\t\tsizeof(*hw->blk[block_id].xlt2.t);\n\t\t\tdst = (u8 *)hw->blk[block_id].xlt2.t;\n\t\t\tdst_len = hw->blk[block_id].xlt2.count *\n\t\t\t\tsizeof(*hw->blk[block_id].xlt2.t);\n\t\t\tbreak;\n\t\tcase ICE_SID_PROFID_TCAM_SW:\n\t\tcase ICE_SID_PROFID_TCAM_FD:\n\t\tcase ICE_SID_PROFID_TCAM_RSS:\n\t\tcase ICE_SID_PROFID_TCAM_ACL:\n\t\tcase ICE_SID_PROFID_TCAM_PE:\n\t\t\tpid = sect;\n\t\t\tsrc = (u8 *)pid->entry;\n\t\t\tsect_len = le16_to_cpu(pid->count) *\n\t\t\t\tsizeof(*hw->blk[block_id].prof.t);\n\t\t\tdst = (u8 *)hw->blk[block_id].prof.t;\n\t\t\tdst_len = hw->blk[block_id].prof.count *\n\t\t\t\tsizeof(*hw->blk[block_id].prof.t);\n\t\t\tbreak;\n\t\tcase ICE_SID_PROFID_REDIR_SW:\n\t\tcase ICE_SID_PROFID_REDIR_FD:\n\t\tcase ICE_SID_PROFID_REDIR_RSS:\n\t\tcase ICE_SID_PROFID_REDIR_ACL:\n\t\tcase ICE_SID_PROFID_REDIR_PE:\n\t\t\tpr = sect;\n\t\t\tsrc = pr->redir_value;\n\t\t\tsect_len = le16_to_cpu(pr->count) *\n\t\t\t\tsizeof(*hw->blk[block_id].prof_redir.t);\n\t\t\tdst = hw->blk[block_id].prof_redir.t;\n\t\t\tdst_len = hw->blk[block_id].prof_redir.count *\n\t\t\t\tsizeof(*hw->blk[block_id].prof_redir.t);\n\t\t\tbreak;\n\t\tcase ICE_SID_FLD_VEC_SW:\n\t\tcase ICE_SID_FLD_VEC_FD:\n\t\tcase ICE_SID_FLD_VEC_RSS:\n\t\tcase ICE_SID_FLD_VEC_ACL:\n\t\tcase ICE_SID_FLD_VEC_PE:\n\t\t\tes = sect;\n\t\t\tsrc = (u8 *)es->fv;\n\t\t\tsect_len = (u32)(le16_to_cpu(es->count) *\n\t\t\t\t\t hw->blk[block_id].es.fvw) *\n\t\t\t\tsizeof(*hw->blk[block_id].es.t);\n\t\t\tdst = (u8 *)hw->blk[block_id].es.t;\n\t\t\tdst_len = (u32)(hw->blk[block_id].es.count *\n\t\t\t\t\thw->blk[block_id].es.fvw) *\n\t\t\t\tsizeof(*hw->blk[block_id].es.t);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tif (offset > dst_len)\n\t\t\treturn;\n\n\t\t \n\t\tif ((offset + sect_len) > dst_len)\n\t\t\tsect_len = dst_len - offset;\n\n\t\tmemcpy(dst + offset, src, sect_len);\n\t\toffset += sect_len;\n\t\tsect = ice_pkg_enum_section(NULL, &state, sid);\n\t}\n}\n\n \nvoid ice_fill_blk_tbls(struct ice_hw *hw)\n{\n\tu8 i;\n\n\tfor (i = 0; i < ICE_BLK_COUNT; i++) {\n\t\tenum ice_block blk_id = (enum ice_block)i;\n\n\t\tice_fill_tbl(hw, blk_id, hw->blk[blk_id].xlt1.sid);\n\t\tice_fill_tbl(hw, blk_id, hw->blk[blk_id].xlt2.sid);\n\t\tice_fill_tbl(hw, blk_id, hw->blk[blk_id].prof.sid);\n\t\tice_fill_tbl(hw, blk_id, hw->blk[blk_id].prof_redir.sid);\n\t\tice_fill_tbl(hw, blk_id, hw->blk[blk_id].es.sid);\n\t}\n\n\tice_init_sw_db(hw);\n}\n\n \nstatic void ice_free_prof_map(struct ice_hw *hw, u8 blk_idx)\n{\n\tstruct ice_es *es = &hw->blk[blk_idx].es;\n\tstruct ice_prof_map *del, *tmp;\n\n\tmutex_lock(&es->prof_map_lock);\n\tlist_for_each_entry_safe(del, tmp, &es->prof_map, list) {\n\t\tlist_del(&del->list);\n\t\tdevm_kfree(ice_hw_to_dev(hw), del);\n\t}\n\tINIT_LIST_HEAD(&es->prof_map);\n\tmutex_unlock(&es->prof_map_lock);\n}\n\n \nstatic void ice_free_flow_profs(struct ice_hw *hw, u8 blk_idx)\n{\n\tstruct ice_flow_prof *p, *tmp;\n\n\tmutex_lock(&hw->fl_profs_locks[blk_idx]);\n\tlist_for_each_entry_safe(p, tmp, &hw->fl_profs[blk_idx], l_entry) {\n\t\tstruct ice_flow_entry *e, *t;\n\n\t\tlist_for_each_entry_safe(e, t, &p->entries, l_entry)\n\t\t\tice_flow_rem_entry(hw, (enum ice_block)blk_idx,\n\t\t\t\t\t   ICE_FLOW_ENTRY_HNDL(e));\n\n\t\tlist_del(&p->l_entry);\n\n\t\tmutex_destroy(&p->entries_lock);\n\t\tdevm_kfree(ice_hw_to_dev(hw), p);\n\t}\n\tmutex_unlock(&hw->fl_profs_locks[blk_idx]);\n\n\t \n\tINIT_LIST_HEAD(&hw->fl_profs[blk_idx]);\n}\n\n \nstatic void ice_free_vsig_tbl(struct ice_hw *hw, enum ice_block blk)\n{\n\tu16 i;\n\n\tif (!hw->blk[blk].xlt2.vsig_tbl)\n\t\treturn;\n\n\tfor (i = 1; i < ICE_MAX_VSIGS; i++)\n\t\tif (hw->blk[blk].xlt2.vsig_tbl[i].in_use)\n\t\t\tice_vsig_free(hw, blk, i);\n}\n\n \nvoid ice_free_hw_tbls(struct ice_hw *hw)\n{\n\tstruct ice_rss_cfg *r, *rt;\n\tu8 i;\n\n\tfor (i = 0; i < ICE_BLK_COUNT; i++) {\n\t\tif (hw->blk[i].is_list_init) {\n\t\t\tstruct ice_es *es = &hw->blk[i].es;\n\n\t\t\tice_free_prof_map(hw, i);\n\t\t\tmutex_destroy(&es->prof_map_lock);\n\n\t\t\tice_free_flow_profs(hw, i);\n\t\t\tmutex_destroy(&hw->fl_profs_locks[i]);\n\n\t\t\thw->blk[i].is_list_init = false;\n\t\t}\n\t\tice_free_vsig_tbl(hw, (enum ice_block)i);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].xlt1.ptypes);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].xlt1.ptg_tbl);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].xlt1.t);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].xlt2.t);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].xlt2.vsig_tbl);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].xlt2.vsis);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].prof.t);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].prof_redir.t);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].es.t);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].es.ref_count);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].es.written);\n\t\tdevm_kfree(ice_hw_to_dev(hw), hw->blk[i].es.mask_ena);\n\t}\n\n\tlist_for_each_entry_safe(r, rt, &hw->rss_list_head, l_entry) {\n\t\tlist_del(&r->l_entry);\n\t\tdevm_kfree(ice_hw_to_dev(hw), r);\n\t}\n\tmutex_destroy(&hw->rss_locks);\n\tice_shutdown_all_prof_masks(hw);\n\tmemset(hw->blk, 0, sizeof(hw->blk));\n}\n\n \nstatic void ice_init_flow_profs(struct ice_hw *hw, u8 blk_idx)\n{\n\tmutex_init(&hw->fl_profs_locks[blk_idx]);\n\tINIT_LIST_HEAD(&hw->fl_profs[blk_idx]);\n}\n\n \nvoid ice_clear_hw_tbls(struct ice_hw *hw)\n{\n\tu8 i;\n\n\tfor (i = 0; i < ICE_BLK_COUNT; i++) {\n\t\tstruct ice_prof_redir *prof_redir = &hw->blk[i].prof_redir;\n\t\tstruct ice_prof_tcam *prof = &hw->blk[i].prof;\n\t\tstruct ice_xlt1 *xlt1 = &hw->blk[i].xlt1;\n\t\tstruct ice_xlt2 *xlt2 = &hw->blk[i].xlt2;\n\t\tstruct ice_es *es = &hw->blk[i].es;\n\n\t\tif (hw->blk[i].is_list_init) {\n\t\t\tice_free_prof_map(hw, i);\n\t\t\tice_free_flow_profs(hw, i);\n\t\t}\n\n\t\tice_free_vsig_tbl(hw, (enum ice_block)i);\n\n\t\tmemset(xlt1->ptypes, 0, xlt1->count * sizeof(*xlt1->ptypes));\n\t\tmemset(xlt1->ptg_tbl, 0,\n\t\t       ICE_MAX_PTGS * sizeof(*xlt1->ptg_tbl));\n\t\tmemset(xlt1->t, 0, xlt1->count * sizeof(*xlt1->t));\n\n\t\tmemset(xlt2->vsis, 0, xlt2->count * sizeof(*xlt2->vsis));\n\t\tmemset(xlt2->vsig_tbl, 0,\n\t\t       xlt2->count * sizeof(*xlt2->vsig_tbl));\n\t\tmemset(xlt2->t, 0, xlt2->count * sizeof(*xlt2->t));\n\n\t\tmemset(prof->t, 0, prof->count * sizeof(*prof->t));\n\t\tmemset(prof_redir->t, 0,\n\t\t       prof_redir->count * sizeof(*prof_redir->t));\n\n\t\tmemset(es->t, 0, es->count * sizeof(*es->t) * es->fvw);\n\t\tmemset(es->ref_count, 0, es->count * sizeof(*es->ref_count));\n\t\tmemset(es->written, 0, es->count * sizeof(*es->written));\n\t\tmemset(es->mask_ena, 0, es->count * sizeof(*es->mask_ena));\n\t}\n}\n\n \nint ice_init_hw_tbls(struct ice_hw *hw)\n{\n\tu8 i;\n\n\tmutex_init(&hw->rss_locks);\n\tINIT_LIST_HEAD(&hw->rss_list_head);\n\tice_init_all_prof_masks(hw);\n\tfor (i = 0; i < ICE_BLK_COUNT; i++) {\n\t\tstruct ice_prof_redir *prof_redir = &hw->blk[i].prof_redir;\n\t\tstruct ice_prof_tcam *prof = &hw->blk[i].prof;\n\t\tstruct ice_xlt1 *xlt1 = &hw->blk[i].xlt1;\n\t\tstruct ice_xlt2 *xlt2 = &hw->blk[i].xlt2;\n\t\tstruct ice_es *es = &hw->blk[i].es;\n\t\tu16 j;\n\n\t\tif (hw->blk[i].is_list_init)\n\t\t\tcontinue;\n\n\t\tice_init_flow_profs(hw, i);\n\t\tmutex_init(&es->prof_map_lock);\n\t\tINIT_LIST_HEAD(&es->prof_map);\n\t\thw->blk[i].is_list_init = true;\n\n\t\thw->blk[i].overwrite = blk_sizes[i].overwrite;\n\t\tes->reverse = blk_sizes[i].reverse;\n\n\t\txlt1->sid = ice_blk_sids[i][ICE_SID_XLT1_OFF];\n\t\txlt1->count = blk_sizes[i].xlt1;\n\n\t\txlt1->ptypes = devm_kcalloc(ice_hw_to_dev(hw), xlt1->count,\n\t\t\t\t\t    sizeof(*xlt1->ptypes), GFP_KERNEL);\n\n\t\tif (!xlt1->ptypes)\n\t\t\tgoto err;\n\n\t\txlt1->ptg_tbl = devm_kcalloc(ice_hw_to_dev(hw), ICE_MAX_PTGS,\n\t\t\t\t\t     sizeof(*xlt1->ptg_tbl),\n\t\t\t\t\t     GFP_KERNEL);\n\n\t\tif (!xlt1->ptg_tbl)\n\t\t\tgoto err;\n\n\t\txlt1->t = devm_kcalloc(ice_hw_to_dev(hw), xlt1->count,\n\t\t\t\t       sizeof(*xlt1->t), GFP_KERNEL);\n\t\tif (!xlt1->t)\n\t\t\tgoto err;\n\n\t\txlt2->sid = ice_blk_sids[i][ICE_SID_XLT2_OFF];\n\t\txlt2->count = blk_sizes[i].xlt2;\n\n\t\txlt2->vsis = devm_kcalloc(ice_hw_to_dev(hw), xlt2->count,\n\t\t\t\t\t  sizeof(*xlt2->vsis), GFP_KERNEL);\n\n\t\tif (!xlt2->vsis)\n\t\t\tgoto err;\n\n\t\txlt2->vsig_tbl = devm_kcalloc(ice_hw_to_dev(hw), xlt2->count,\n\t\t\t\t\t      sizeof(*xlt2->vsig_tbl),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!xlt2->vsig_tbl)\n\t\t\tgoto err;\n\n\t\tfor (j = 0; j < xlt2->count; j++)\n\t\t\tINIT_LIST_HEAD(&xlt2->vsig_tbl[j].prop_lst);\n\n\t\txlt2->t = devm_kcalloc(ice_hw_to_dev(hw), xlt2->count,\n\t\t\t\t       sizeof(*xlt2->t), GFP_KERNEL);\n\t\tif (!xlt2->t)\n\t\t\tgoto err;\n\n\t\tprof->sid = ice_blk_sids[i][ICE_SID_PR_OFF];\n\t\tprof->count = blk_sizes[i].prof_tcam;\n\t\tprof->max_prof_id = blk_sizes[i].prof_id;\n\t\tprof->cdid_bits = blk_sizes[i].prof_cdid_bits;\n\t\tprof->t = devm_kcalloc(ice_hw_to_dev(hw), prof->count,\n\t\t\t\t       sizeof(*prof->t), GFP_KERNEL);\n\n\t\tif (!prof->t)\n\t\t\tgoto err;\n\n\t\tprof_redir->sid = ice_blk_sids[i][ICE_SID_PR_REDIR_OFF];\n\t\tprof_redir->count = blk_sizes[i].prof_redir;\n\t\tprof_redir->t = devm_kcalloc(ice_hw_to_dev(hw),\n\t\t\t\t\t     prof_redir->count,\n\t\t\t\t\t     sizeof(*prof_redir->t),\n\t\t\t\t\t     GFP_KERNEL);\n\n\t\tif (!prof_redir->t)\n\t\t\tgoto err;\n\n\t\tes->sid = ice_blk_sids[i][ICE_SID_ES_OFF];\n\t\tes->count = blk_sizes[i].es;\n\t\tes->fvw = blk_sizes[i].fvw;\n\t\tes->t = devm_kcalloc(ice_hw_to_dev(hw),\n\t\t\t\t     (u32)(es->count * es->fvw),\n\t\t\t\t     sizeof(*es->t), GFP_KERNEL);\n\t\tif (!es->t)\n\t\t\tgoto err;\n\n\t\tes->ref_count = devm_kcalloc(ice_hw_to_dev(hw), es->count,\n\t\t\t\t\t     sizeof(*es->ref_count),\n\t\t\t\t\t     GFP_KERNEL);\n\t\tif (!es->ref_count)\n\t\t\tgoto err;\n\n\t\tes->written = devm_kcalloc(ice_hw_to_dev(hw), es->count,\n\t\t\t\t\t   sizeof(*es->written), GFP_KERNEL);\n\t\tif (!es->written)\n\t\t\tgoto err;\n\n\t\tes->mask_ena = devm_kcalloc(ice_hw_to_dev(hw), es->count,\n\t\t\t\t\t    sizeof(*es->mask_ena), GFP_KERNEL);\n\t\tif (!es->mask_ena)\n\t\t\tgoto err;\n\t}\n\treturn 0;\n\nerr:\n\tice_free_hw_tbls(hw);\n\treturn -ENOMEM;\n}\n\n \nstatic int\nice_prof_gen_key(struct ice_hw *hw, enum ice_block blk, u8 ptg, u16 vsig,\n\t\t u8 cdid, u16 flags, u8 vl_msk[ICE_TCAM_KEY_VAL_SZ],\n\t\t u8 dc_msk[ICE_TCAM_KEY_VAL_SZ], u8 nm_msk[ICE_TCAM_KEY_VAL_SZ],\n\t\t u8 key[ICE_TCAM_KEY_SZ])\n{\n\tstruct ice_prof_id_key inkey;\n\n\tinkey.xlt1 = ptg;\n\tinkey.xlt2_cdid = cpu_to_le16(vsig);\n\tinkey.flags = cpu_to_le16(flags);\n\n\tswitch (hw->blk[blk].prof.cdid_bits) {\n\tcase 0:\n\t\tbreak;\n\tcase 2:\n#define ICE_CD_2_M 0xC000U\n#define ICE_CD_2_S 14\n\t\tinkey.xlt2_cdid &= ~cpu_to_le16(ICE_CD_2_M);\n\t\tinkey.xlt2_cdid |= cpu_to_le16(BIT(cdid) << ICE_CD_2_S);\n\t\tbreak;\n\tcase 4:\n#define ICE_CD_4_M 0xF000U\n#define ICE_CD_4_S 12\n\t\tinkey.xlt2_cdid &= ~cpu_to_le16(ICE_CD_4_M);\n\t\tinkey.xlt2_cdid |= cpu_to_le16(BIT(cdid) << ICE_CD_4_S);\n\t\tbreak;\n\tcase 8:\n#define ICE_CD_8_M 0xFF00U\n#define ICE_CD_8_S 16\n\t\tinkey.xlt2_cdid &= ~cpu_to_le16(ICE_CD_8_M);\n\t\tinkey.xlt2_cdid |= cpu_to_le16(BIT(cdid) << ICE_CD_8_S);\n\t\tbreak;\n\tdefault:\n\t\tice_debug(hw, ICE_DBG_PKG, \"Error in profile config\\n\");\n\t\tbreak;\n\t}\n\n\treturn ice_set_key(key, ICE_TCAM_KEY_SZ, (u8 *)&inkey, vl_msk, dc_msk,\n\t\t\t   nm_msk, 0, ICE_TCAM_KEY_SZ / 2);\n}\n\n \nstatic int\nice_tcam_write_entry(struct ice_hw *hw, enum ice_block blk, u16 idx,\n\t\t     u8 prof_id, u8 ptg, u16 vsig, u8 cdid, u16 flags,\n\t\t     u8 vl_msk[ICE_TCAM_KEY_VAL_SZ],\n\t\t     u8 dc_msk[ICE_TCAM_KEY_VAL_SZ],\n\t\t     u8 nm_msk[ICE_TCAM_KEY_VAL_SZ])\n{\n\tstruct ice_prof_tcam_entry;\n\tint status;\n\n\tstatus = ice_prof_gen_key(hw, blk, ptg, vsig, cdid, flags, vl_msk,\n\t\t\t\t  dc_msk, nm_msk, hw->blk[blk].prof.t[idx].key);\n\tif (!status) {\n\t\thw->blk[blk].prof.t[idx].addr = cpu_to_le16(idx);\n\t\thw->blk[blk].prof.t[idx].prof_id = prof_id;\n\t}\n\n\treturn status;\n}\n\n \nstatic int\nice_vsig_get_ref(struct ice_hw *hw, enum ice_block blk, u16 vsig, u16 *refs)\n{\n\tu16 idx = vsig & ICE_VSIG_IDX_M;\n\tstruct ice_vsig_vsi *ptr;\n\n\t*refs = 0;\n\n\tif (!hw->blk[blk].xlt2.vsig_tbl[idx].in_use)\n\t\treturn -ENOENT;\n\n\tptr = hw->blk[blk].xlt2.vsig_tbl[idx].first_vsi;\n\twhile (ptr) {\n\t\t(*refs)++;\n\t\tptr = ptr->next_vsi;\n\t}\n\n\treturn 0;\n}\n\n \nstatic bool\nice_has_prof_vsig(struct ice_hw *hw, enum ice_block blk, u16 vsig, u64 hdl)\n{\n\tu16 idx = vsig & ICE_VSIG_IDX_M;\n\tstruct ice_vsig_prof *ent;\n\n\tlist_for_each_entry(ent, &hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst,\n\t\t\t    list)\n\t\tif (ent->profile_cookie == hdl)\n\t\t\treturn true;\n\n\tice_debug(hw, ICE_DBG_INIT, \"Characteristic list for VSI group %d not found.\\n\",\n\t\t  vsig);\n\treturn false;\n}\n\n \nstatic int\nice_prof_bld_es(struct ice_hw *hw, enum ice_block blk,\n\t\tstruct ice_buf_build *bld, struct list_head *chgs)\n{\n\tu16 vec_size = hw->blk[blk].es.fvw * sizeof(struct ice_fv_word);\n\tstruct ice_chs_chg *tmp;\n\n\tlist_for_each_entry(tmp, chgs, list_entry)\n\t\tif (tmp->type == ICE_PTG_ES_ADD && tmp->add_prof) {\n\t\t\tu16 off = tmp->prof_id * hw->blk[blk].es.fvw;\n\t\t\tstruct ice_pkg_es *p;\n\t\t\tu32 id;\n\n\t\t\tid = ice_sect_id(blk, ICE_VEC_TBL);\n\t\t\tp = ice_pkg_buf_alloc_section(bld, id,\n\t\t\t\t\t\t      struct_size(p, es, 1) +\n\t\t\t\t\t\t      vec_size -\n\t\t\t\t\t\t      sizeof(p->es[0]));\n\n\t\t\tif (!p)\n\t\t\t\treturn -ENOSPC;\n\n\t\t\tp->count = cpu_to_le16(1);\n\t\t\tp->offset = cpu_to_le16(tmp->prof_id);\n\n\t\t\tmemcpy(p->es, &hw->blk[blk].es.t[off], vec_size);\n\t\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_prof_bld_tcam(struct ice_hw *hw, enum ice_block blk,\n\t\t  struct ice_buf_build *bld, struct list_head *chgs)\n{\n\tstruct ice_chs_chg *tmp;\n\n\tlist_for_each_entry(tmp, chgs, list_entry)\n\t\tif (tmp->type == ICE_TCAM_ADD && tmp->add_tcam_idx) {\n\t\t\tstruct ice_prof_id_section *p;\n\t\t\tu32 id;\n\n\t\t\tid = ice_sect_id(blk, ICE_PROF_TCAM);\n\t\t\tp = ice_pkg_buf_alloc_section(bld, id,\n\t\t\t\t\t\t      struct_size(p, entry, 1));\n\n\t\t\tif (!p)\n\t\t\t\treturn -ENOSPC;\n\n\t\t\tp->count = cpu_to_le16(1);\n\t\t\tp->entry[0].addr = cpu_to_le16(tmp->tcam_idx);\n\t\t\tp->entry[0].prof_id = tmp->prof_id;\n\n\t\t\tmemcpy(p->entry[0].key,\n\t\t\t       &hw->blk[blk].prof.t[tmp->tcam_idx].key,\n\t\t\t       sizeof(hw->blk[blk].prof.t->key));\n\t\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_prof_bld_xlt1(enum ice_block blk, struct ice_buf_build *bld,\n\t\t  struct list_head *chgs)\n{\n\tstruct ice_chs_chg *tmp;\n\n\tlist_for_each_entry(tmp, chgs, list_entry)\n\t\tif (tmp->type == ICE_PTG_ES_ADD && tmp->add_ptg) {\n\t\t\tstruct ice_xlt1_section *p;\n\t\t\tu32 id;\n\n\t\t\tid = ice_sect_id(blk, ICE_XLT1);\n\t\t\tp = ice_pkg_buf_alloc_section(bld, id,\n\t\t\t\t\t\t      struct_size(p, value, 1));\n\n\t\t\tif (!p)\n\t\t\t\treturn -ENOSPC;\n\n\t\t\tp->count = cpu_to_le16(1);\n\t\t\tp->offset = cpu_to_le16(tmp->ptype);\n\t\t\tp->value[0] = tmp->ptg;\n\t\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_prof_bld_xlt2(enum ice_block blk, struct ice_buf_build *bld,\n\t\t  struct list_head *chgs)\n{\n\tstruct ice_chs_chg *tmp;\n\n\tlist_for_each_entry(tmp, chgs, list_entry) {\n\t\tstruct ice_xlt2_section *p;\n\t\tu32 id;\n\n\t\tswitch (tmp->type) {\n\t\tcase ICE_VSIG_ADD:\n\t\tcase ICE_VSI_MOVE:\n\t\tcase ICE_VSIG_REM:\n\t\t\tid = ice_sect_id(blk, ICE_XLT2);\n\t\t\tp = ice_pkg_buf_alloc_section(bld, id,\n\t\t\t\t\t\t      struct_size(p, value, 1));\n\n\t\t\tif (!p)\n\t\t\t\treturn -ENOSPC;\n\n\t\t\tp->count = cpu_to_le16(1);\n\t\t\tp->offset = cpu_to_le16(tmp->vsi);\n\t\t\tp->value[0] = cpu_to_le16(tmp->vsig);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_upd_prof_hw(struct ice_hw *hw, enum ice_block blk,\n\t\tstruct list_head *chgs)\n{\n\tstruct ice_buf_build *b;\n\tstruct ice_chs_chg *tmp;\n\tu16 pkg_sects;\n\tu16 xlt1 = 0;\n\tu16 xlt2 = 0;\n\tu16 tcam = 0;\n\tu16 es = 0;\n\tint status;\n\tu16 sects;\n\n\t \n\tlist_for_each_entry(tmp, chgs, list_entry) {\n\t\tswitch (tmp->type) {\n\t\tcase ICE_PTG_ES_ADD:\n\t\t\tif (tmp->add_ptg)\n\t\t\t\txlt1++;\n\t\t\tif (tmp->add_prof)\n\t\t\t\tes++;\n\t\t\tbreak;\n\t\tcase ICE_TCAM_ADD:\n\t\t\ttcam++;\n\t\t\tbreak;\n\t\tcase ICE_VSIG_ADD:\n\t\tcase ICE_VSI_MOVE:\n\t\tcase ICE_VSIG_REM:\n\t\t\txlt2++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tsects = xlt1 + xlt2 + tcam + es;\n\n\tif (!sects)\n\t\treturn 0;\n\n\t \n\tb = ice_pkg_buf_alloc(hw);\n\tif (!b)\n\t\treturn -ENOMEM;\n\n\tstatus = ice_pkg_buf_reserve_section(b, sects);\n\tif (status)\n\t\tgoto error_tmp;\n\n\t \n\tif (es) {\n\t\tstatus = ice_prof_bld_es(hw, blk, b, chgs);\n\t\tif (status)\n\t\t\tgoto error_tmp;\n\t}\n\n\tif (tcam) {\n\t\tstatus = ice_prof_bld_tcam(hw, blk, b, chgs);\n\t\tif (status)\n\t\t\tgoto error_tmp;\n\t}\n\n\tif (xlt1) {\n\t\tstatus = ice_prof_bld_xlt1(blk, b, chgs);\n\t\tif (status)\n\t\t\tgoto error_tmp;\n\t}\n\n\tif (xlt2) {\n\t\tstatus = ice_prof_bld_xlt2(blk, b, chgs);\n\t\tif (status)\n\t\t\tgoto error_tmp;\n\t}\n\n\t \n\tpkg_sects = ice_pkg_buf_get_active_sections(b);\n\tif (!pkg_sects || pkg_sects != sects) {\n\t\tstatus = -EINVAL;\n\t\tgoto error_tmp;\n\t}\n\n\t \n\tstatus = ice_update_pkg(hw, ice_pkg_buf(b), 1);\n\tif (status == -EIO)\n\t\tice_debug(hw, ICE_DBG_INIT, \"Unable to update HW profile\\n\");\n\nerror_tmp:\n\tice_pkg_buf_free(hw, b);\n\treturn status;\n}\n\n \nstatic void ice_update_fd_mask(struct ice_hw *hw, u16 prof_id, u32 mask_sel)\n{\n\twr32(hw, GLQF_FDMASK_SEL(prof_id), mask_sel);\n\n\tice_debug(hw, ICE_DBG_INIT, \"fd mask(%d): %x = %x\\n\", prof_id,\n\t\t  GLQF_FDMASK_SEL(prof_id), mask_sel);\n}\n\nstruct ice_fd_src_dst_pair {\n\tu8 prot_id;\n\tu8 count;\n\tu16 off;\n};\n\nstatic const struct ice_fd_src_dst_pair ice_fd_pairs[] = {\n\t \n\t{ ICE_PROT_IPV4_OF_OR_S, 2, 12 },\n\t{ ICE_PROT_IPV4_OF_OR_S, 2, 16 },\n\n\t{ ICE_PROT_IPV4_IL, 2, 12 },\n\t{ ICE_PROT_IPV4_IL, 2, 16 },\n\n\t{ ICE_PROT_IPV6_OF_OR_S, 8, 8 },\n\t{ ICE_PROT_IPV6_OF_OR_S, 8, 24 },\n\n\t{ ICE_PROT_IPV6_IL, 8, 8 },\n\t{ ICE_PROT_IPV6_IL, 8, 24 },\n\n\t{ ICE_PROT_TCP_IL, 1, 0 },\n\t{ ICE_PROT_TCP_IL, 1, 2 },\n\n\t{ ICE_PROT_UDP_OF, 1, 0 },\n\t{ ICE_PROT_UDP_OF, 1, 2 },\n\n\t{ ICE_PROT_UDP_IL_OR_S, 1, 0 },\n\t{ ICE_PROT_UDP_IL_OR_S, 1, 2 },\n\n\t{ ICE_PROT_SCTP_IL, 1, 0 },\n\t{ ICE_PROT_SCTP_IL, 1, 2 }\n};\n\n#define ICE_FD_SRC_DST_PAIR_COUNT\tARRAY_SIZE(ice_fd_pairs)\n\n \nstatic int\nice_update_fd_swap(struct ice_hw *hw, u16 prof_id, struct ice_fv_word *es)\n{\n\tDECLARE_BITMAP(pair_list, ICE_FD_SRC_DST_PAIR_COUNT);\n\tu8 pair_start[ICE_FD_SRC_DST_PAIR_COUNT] = { 0 };\n#define ICE_FD_FV_NOT_FOUND (-2)\n\ts8 first_free = ICE_FD_FV_NOT_FOUND;\n\tu8 used[ICE_MAX_FV_WORDS] = { 0 };\n\ts8 orig_free, si;\n\tu32 mask_sel = 0;\n\tu8 i, j, k;\n\n\tbitmap_zero(pair_list, ICE_FD_SRC_DST_PAIR_COUNT);\n\n\t \n\n\t \n\tfor (i = 0; i < hw->blk[ICE_BLK_FD].es.fvw; i++) {\n\t\t \n\t\tif (first_free == ICE_FD_FV_NOT_FOUND && es[i].prot_id !=\n\t\t    ICE_PROT_INVALID)\n\t\t\tfirst_free = i - 1;\n\n\t\tfor (j = 0; j < ICE_FD_SRC_DST_PAIR_COUNT; j++)\n\t\t\tif (es[i].prot_id == ice_fd_pairs[j].prot_id &&\n\t\t\t    es[i].off == ice_fd_pairs[j].off) {\n\t\t\t\t__set_bit(j, pair_list);\n\t\t\t\tpair_start[j] = i;\n\t\t\t}\n\t}\n\n\torig_free = first_free;\n\n\t \n\tfor (i = 0; i < ICE_FD_SRC_DST_PAIR_COUNT; i += 2) {\n\t\tu8 bit1 = test_bit(i + 1, pair_list);\n\t\tu8 bit0 = test_bit(i, pair_list);\n\n\t\tif (bit0 ^ bit1) {\n\t\t\tu8 index;\n\n\t\t\t \n\t\t\tif (!bit0)\n\t\t\t\tindex = i;\n\t\t\telse\n\t\t\t\tindex = i + 1;\n\n\t\t\t \n\t\t\tif (first_free + 1 < (s8)ice_fd_pairs[index].count)\n\t\t\t\treturn -ENOSPC;\n\n\t\t\t \n\t\t\tfor (k = 0; k < ice_fd_pairs[index].count; k++) {\n\t\t\t\tes[first_free - k].prot_id =\n\t\t\t\t\tice_fd_pairs[index].prot_id;\n\t\t\t\tes[first_free - k].off =\n\t\t\t\t\tice_fd_pairs[index].off + (k * 2);\n\n\t\t\t\tif (k > first_free)\n\t\t\t\t\treturn -EIO;\n\n\t\t\t\t \n\t\t\t\tmask_sel |= BIT(first_free - k);\n\t\t\t}\n\n\t\t\tpair_start[index] = first_free;\n\t\t\tfirst_free -= ice_fd_pairs[index].count;\n\t\t}\n\t}\n\n\t \n\tsi = hw->blk[ICE_BLK_FD].es.fvw - 1;\n\twhile (si >= 0) {\n\t\tu8 indexes_used = 1;\n\n\t\t \n#define ICE_SWAP_VALID\t0x80\n\t\tused[si] = si | ICE_SWAP_VALID;\n\n\t\tif (orig_free == ICE_FD_FV_NOT_FOUND || si <= orig_free) {\n\t\t\tsi -= indexes_used;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tfor (j = 0; j < ICE_FD_SRC_DST_PAIR_COUNT; j++)\n\t\t\tif (es[si].prot_id == ice_fd_pairs[j].prot_id &&\n\t\t\t    es[si].off == ice_fd_pairs[j].off) {\n\t\t\t\tu8 idx;\n\n\t\t\t\t \n\t\t\t\tidx = j + ((j % 2) ? -1 : 1);\n\n\t\t\t\tindexes_used = ice_fd_pairs[idx].count;\n\t\t\t\tfor (k = 0; k < indexes_used; k++) {\n\t\t\t\t\tused[si - k] = (pair_start[idx] - k) |\n\t\t\t\t\t\tICE_SWAP_VALID;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tsi -= indexes_used;\n\t}\n\n\t \n\tfor (j = 0; j < hw->blk[ICE_BLK_FD].es.fvw / 4; j++) {\n\t\tu32 raw_swap = 0;\n\t\tu32 raw_in = 0;\n\n\t\tfor (k = 0; k < 4; k++) {\n\t\t\tu8 idx;\n\n\t\t\tidx = (j * 4) + k;\n\t\t\tif (used[idx] && !(mask_sel & BIT(idx))) {\n\t\t\t\traw_swap |= used[idx] << (k * BITS_PER_BYTE);\n#define ICE_INSET_DFLT 0x9f\n\t\t\t\traw_in |= ICE_INSET_DFLT << (k * BITS_PER_BYTE);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\twr32(hw, GLQF_FDSWAP(prof_id, j), raw_swap);\n\n\t\tice_debug(hw, ICE_DBG_INIT, \"swap wr(%d, %d): %x = %08x\\n\",\n\t\t\t  prof_id, j, GLQF_FDSWAP(prof_id, j), raw_swap);\n\n\t\t \n\t\twr32(hw, GLQF_FDINSET(prof_id, j), raw_in);\n\n\t\tice_debug(hw, ICE_DBG_INIT, \"inset wr(%d, %d): %x = %08x\\n\",\n\t\t\t  prof_id, j, GLQF_FDINSET(prof_id, j), raw_in);\n\t}\n\n\t \n\tice_update_fd_mask(hw, prof_id, 0);\n\n\treturn 0;\n}\n\n \nstatic const struct ice_ptype_attrib_info ice_ptype_attributes[] = {\n\t{ ICE_GTP_PDU_EH,\tICE_GTP_PDU_FLAG_MASK },\n\t{ ICE_GTP_SESSION,\tICE_GTP_FLAGS_MASK },\n\t{ ICE_GTP_DOWNLINK,\tICE_GTP_FLAGS_MASK },\n\t{ ICE_GTP_UPLINK,\tICE_GTP_FLAGS_MASK },\n};\n\n \nstatic void\nice_get_ptype_attrib_info(enum ice_ptype_attrib_type type,\n\t\t\t  struct ice_ptype_attrib_info *info)\n{\n\t*info = ice_ptype_attributes[type];\n}\n\n \nstatic int\nice_add_prof_attrib(struct ice_prof_map *prof, u8 ptg, u16 ptype,\n\t\t    const struct ice_ptype_attributes *attr, u16 attr_cnt)\n{\n\tbool found = false;\n\tu16 i;\n\n\tfor (i = 0; i < attr_cnt; i++)\n\t\tif (attr[i].ptype == ptype) {\n\t\t\tfound = true;\n\n\t\t\tprof->ptg[prof->ptg_cnt] = ptg;\n\t\t\tice_get_ptype_attrib_info(attr[i].attrib,\n\t\t\t\t\t\t  &prof->attr[prof->ptg_cnt]);\n\n\t\t\tif (++prof->ptg_cnt >= ICE_MAX_PTG_PER_PROFILE)\n\t\t\t\treturn -ENOSPC;\n\t\t}\n\n\tif (!found)\n\t\treturn -ENOENT;\n\n\treturn 0;\n}\n\n \nint\nice_add_prof(struct ice_hw *hw, enum ice_block blk, u64 id, u8 ptypes[],\n\t     const struct ice_ptype_attributes *attr, u16 attr_cnt,\n\t     struct ice_fv_word *es, u16 *masks)\n{\n\tu32 bytes = DIV_ROUND_UP(ICE_FLOW_PTYPE_MAX, BITS_PER_BYTE);\n\tDECLARE_BITMAP(ptgs_used, ICE_XLT1_CNT);\n\tstruct ice_prof_map *prof;\n\tu8 byte = 0;\n\tu8 prof_id;\n\tint status;\n\n\tbitmap_zero(ptgs_used, ICE_XLT1_CNT);\n\n\tmutex_lock(&hw->blk[blk].es.prof_map_lock);\n\n\t \n\tstatus = ice_find_prof_id_with_mask(hw, blk, es, masks, &prof_id);\n\tif (status) {\n\t\t \n\t\tstatus = ice_alloc_prof_id(hw, blk, &prof_id);\n\t\tif (status)\n\t\t\tgoto err_ice_add_prof;\n\t\tif (blk == ICE_BLK_FD) {\n\t\t\t \n\t\t\tstatus = ice_update_fd_swap(hw, prof_id, es);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof;\n\t\t}\n\t\tstatus = ice_update_prof_masking(hw, blk, prof_id, masks);\n\t\tif (status)\n\t\t\tgoto err_ice_add_prof;\n\n\t\t \n\t\tice_write_es(hw, blk, prof_id, es);\n\t}\n\n\tice_prof_inc_ref(hw, blk, prof_id);\n\n\t \n\tprof = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*prof), GFP_KERNEL);\n\tif (!prof) {\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ice_add_prof;\n\t}\n\n\tprof->profile_cookie = id;\n\tprof->prof_id = prof_id;\n\tprof->ptg_cnt = 0;\n\tprof->context = 0;\n\n\t \n\twhile (bytes && prof->ptg_cnt < ICE_MAX_PTG_PER_PROFILE) {\n\t\tu8 bit;\n\n\t\tif (!ptypes[byte]) {\n\t\t\tbytes--;\n\t\t\tbyte++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tfor_each_set_bit(bit, (unsigned long *)&ptypes[byte],\n\t\t\t\t BITS_PER_BYTE) {\n\t\t\tu16 ptype;\n\t\t\tu8 ptg;\n\n\t\t\tptype = byte * BITS_PER_BYTE + bit;\n\n\t\t\t \n\t\t\tif (ice_ptg_find_ptype(hw, blk, ptype, &ptg))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (test_bit(ptg, ptgs_used))\n\t\t\t\tcontinue;\n\n\t\t\t__set_bit(ptg, ptgs_used);\n\t\t\t \n\t\t\tstatus = ice_add_prof_attrib(prof, ptg, ptype,\n\t\t\t\t\t\t     attr, attr_cnt);\n\t\t\tif (status == -ENOSPC)\n\t\t\t\tbreak;\n\t\t\tif (status) {\n\t\t\t\t \n\t\t\t\tprof->ptg[prof->ptg_cnt] = ptg;\n\t\t\t\tprof->attr[prof->ptg_cnt].flags = 0;\n\t\t\t\tprof->attr[prof->ptg_cnt].mask = 0;\n\n\t\t\t\tif (++prof->ptg_cnt >=\n\t\t\t\t    ICE_MAX_PTG_PER_PROFILE)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tbytes--;\n\t\tbyte++;\n\t}\n\n\tlist_add(&prof->list, &hw->blk[blk].es.prof_map);\n\tstatus = 0;\n\nerr_ice_add_prof:\n\tmutex_unlock(&hw->blk[blk].es.prof_map_lock);\n\treturn status;\n}\n\n \nstatic struct ice_prof_map *\nice_search_prof_id(struct ice_hw *hw, enum ice_block blk, u64 id)\n{\n\tstruct ice_prof_map *entry = NULL;\n\tstruct ice_prof_map *map;\n\n\tlist_for_each_entry(map, &hw->blk[blk].es.prof_map, list)\n\t\tif (map->profile_cookie == id) {\n\t\t\tentry = map;\n\t\t\tbreak;\n\t\t}\n\n\treturn entry;\n}\n\n \nstatic u16\nice_vsig_prof_id_count(struct ice_hw *hw, enum ice_block blk, u16 vsig)\n{\n\tu16 idx = vsig & ICE_VSIG_IDX_M, count = 0;\n\tstruct ice_vsig_prof *p;\n\n\tlist_for_each_entry(p, &hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst,\n\t\t\t    list)\n\t\tcount++;\n\n\treturn count;\n}\n\n \nstatic int ice_rel_tcam_idx(struct ice_hw *hw, enum ice_block blk, u16 idx)\n{\n\t \n\tu8 vl_msk[ICE_TCAM_KEY_VAL_SZ] = { 0xFF, 0xFF, 0xFF, 0xFF, 0xFF };\n\tu8 dc_msk[ICE_TCAM_KEY_VAL_SZ] = { 0xFE, 0xFF, 0xFF, 0xFF, 0xFF };\n\tu8 nm_msk[ICE_TCAM_KEY_VAL_SZ] = { 0x01, 0x00, 0x00, 0x00, 0x00 };\n\tint status;\n\n\t \n\tstatus = ice_tcam_write_entry(hw, blk, idx, 0, 0, 0, 0, 0, vl_msk,\n\t\t\t\t      dc_msk, nm_msk);\n\tif (status)\n\t\treturn status;\n\n\t \n\tstatus = ice_free_tcam_ent(hw, blk, idx);\n\n\treturn status;\n}\n\n \nstatic int\nice_rem_prof_id(struct ice_hw *hw, enum ice_block blk,\n\t\tstruct ice_vsig_prof *prof)\n{\n\tint status;\n\tu16 i;\n\n\tfor (i = 0; i < prof->tcam_count; i++)\n\t\tif (prof->tcam[i].in_use) {\n\t\t\tprof->tcam[i].in_use = false;\n\t\t\tstatus = ice_rel_tcam_idx(hw, blk,\n\t\t\t\t\t\t  prof->tcam[i].tcam_idx);\n\t\t\tif (status)\n\t\t\t\treturn -EIO;\n\t\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_rem_vsig(struct ice_hw *hw, enum ice_block blk, u16 vsig,\n\t     struct list_head *chg)\n{\n\tu16 idx = vsig & ICE_VSIG_IDX_M;\n\tstruct ice_vsig_vsi *vsi_cur;\n\tstruct ice_vsig_prof *d, *t;\n\n\t \n\tlist_for_each_entry_safe(d, t,\n\t\t\t\t &hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst,\n\t\t\t\t list) {\n\t\tint status;\n\n\t\tstatus = ice_rem_prof_id(hw, blk, d);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tlist_del(&d->list);\n\t\tdevm_kfree(ice_hw_to_dev(hw), d);\n\t}\n\n\t \n\tvsi_cur = hw->blk[blk].xlt2.vsig_tbl[idx].first_vsi;\n\t \n\tif (vsi_cur)\n\t\tdo {\n\t\t\tstruct ice_vsig_vsi *tmp = vsi_cur->next_vsi;\n\t\t\tstruct ice_chs_chg *p;\n\n\t\t\tp = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*p),\n\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (!p)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tp->type = ICE_VSIG_REM;\n\t\t\tp->orig_vsig = vsig;\n\t\t\tp->vsig = ICE_DEFAULT_VSIG;\n\t\t\tp->vsi = vsi_cur - hw->blk[blk].xlt2.vsis;\n\n\t\t\tlist_add(&p->list_entry, chg);\n\n\t\t\tvsi_cur = tmp;\n\t\t} while (vsi_cur);\n\n\treturn ice_vsig_free(hw, blk, vsig);\n}\n\n \nstatic int\nice_rem_prof_id_vsig(struct ice_hw *hw, enum ice_block blk, u16 vsig, u64 hdl,\n\t\t     struct list_head *chg)\n{\n\tu16 idx = vsig & ICE_VSIG_IDX_M;\n\tstruct ice_vsig_prof *p, *t;\n\n\tlist_for_each_entry_safe(p, t,\n\t\t\t\t &hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst,\n\t\t\t\t list)\n\t\tif (p->profile_cookie == hdl) {\n\t\t\tint status;\n\n\t\t\tif (ice_vsig_prof_id_count(hw, blk, vsig) == 1)\n\t\t\t\t \n\t\t\t\treturn ice_rem_vsig(hw, blk, vsig, chg);\n\n\t\t\tstatus = ice_rem_prof_id(hw, blk, p);\n\t\t\tif (!status) {\n\t\t\t\tlist_del(&p->list);\n\t\t\t\tdevm_kfree(ice_hw_to_dev(hw), p);\n\t\t\t}\n\t\t\treturn status;\n\t\t}\n\n\treturn -ENOENT;\n}\n\n \nstatic int ice_rem_flow_all(struct ice_hw *hw, enum ice_block blk, u64 id)\n{\n\tstruct ice_chs_chg *del, *tmp;\n\tstruct list_head chg;\n\tint status;\n\tu16 i;\n\n\tINIT_LIST_HEAD(&chg);\n\n\tfor (i = 1; i < ICE_MAX_VSIGS; i++)\n\t\tif (hw->blk[blk].xlt2.vsig_tbl[i].in_use) {\n\t\t\tif (ice_has_prof_vsig(hw, blk, i, id)) {\n\t\t\t\tstatus = ice_rem_prof_id_vsig(hw, blk, i, id,\n\t\t\t\t\t\t\t      &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_flow_all;\n\t\t\t}\n\t\t}\n\n\tstatus = ice_upd_prof_hw(hw, blk, &chg);\n\nerr_ice_rem_flow_all:\n\tlist_for_each_entry_safe(del, tmp, &chg, list_entry) {\n\t\tlist_del(&del->list_entry);\n\t\tdevm_kfree(ice_hw_to_dev(hw), del);\n\t}\n\n\treturn status;\n}\n\n \nint ice_rem_prof(struct ice_hw *hw, enum ice_block blk, u64 id)\n{\n\tstruct ice_prof_map *pmap;\n\tint status;\n\n\tmutex_lock(&hw->blk[blk].es.prof_map_lock);\n\n\tpmap = ice_search_prof_id(hw, blk, id);\n\tif (!pmap) {\n\t\tstatus = -ENOENT;\n\t\tgoto err_ice_rem_prof;\n\t}\n\n\t \n\tstatus = ice_rem_flow_all(hw, blk, pmap->profile_cookie);\n\tif (status)\n\t\tgoto err_ice_rem_prof;\n\n\t \n\tice_prof_dec_ref(hw, blk, pmap->prof_id);\n\n\tlist_del(&pmap->list);\n\tdevm_kfree(ice_hw_to_dev(hw), pmap);\n\nerr_ice_rem_prof:\n\tmutex_unlock(&hw->blk[blk].es.prof_map_lock);\n\treturn status;\n}\n\n \nstatic int\nice_get_prof(struct ice_hw *hw, enum ice_block blk, u64 hdl,\n\t     struct list_head *chg)\n{\n\tstruct ice_prof_map *map;\n\tstruct ice_chs_chg *p;\n\tint status = 0;\n\tu16 i;\n\n\tmutex_lock(&hw->blk[blk].es.prof_map_lock);\n\t \n\tmap = ice_search_prof_id(hw, blk, hdl);\n\tif (!map) {\n\t\tstatus = -ENOENT;\n\t\tgoto err_ice_get_prof;\n\t}\n\n\tfor (i = 0; i < map->ptg_cnt; i++)\n\t\tif (!hw->blk[blk].es.written[map->prof_id]) {\n\t\t\t \n\t\t\tp = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*p),\n\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (!p) {\n\t\t\t\tstatus = -ENOMEM;\n\t\t\t\tgoto err_ice_get_prof;\n\t\t\t}\n\n\t\t\tp->type = ICE_PTG_ES_ADD;\n\t\t\tp->ptype = 0;\n\t\t\tp->ptg = map->ptg[i];\n\t\t\tp->add_ptg = 0;\n\n\t\t\tp->add_prof = 1;\n\t\t\tp->prof_id = map->prof_id;\n\n\t\t\thw->blk[blk].es.written[map->prof_id] = true;\n\n\t\t\tlist_add(&p->list_entry, chg);\n\t\t}\n\nerr_ice_get_prof:\n\tmutex_unlock(&hw->blk[blk].es.prof_map_lock);\n\t \n\treturn status;\n}\n\n \nstatic int\nice_get_profs_vsig(struct ice_hw *hw, enum ice_block blk, u16 vsig,\n\t\t   struct list_head *lst)\n{\n\tstruct ice_vsig_prof *ent1, *ent2;\n\tu16 idx = vsig & ICE_VSIG_IDX_M;\n\n\tlist_for_each_entry(ent1, &hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst,\n\t\t\t    list) {\n\t\tstruct ice_vsig_prof *p;\n\n\t\t \n\t\tp = devm_kmemdup(ice_hw_to_dev(hw), ent1, sizeof(*p),\n\t\t\t\t GFP_KERNEL);\n\t\tif (!p)\n\t\t\tgoto err_ice_get_profs_vsig;\n\n\t\tlist_add_tail(&p->list, lst);\n\t}\n\n\treturn 0;\n\nerr_ice_get_profs_vsig:\n\tlist_for_each_entry_safe(ent1, ent2, lst, list) {\n\t\tlist_del(&ent1->list);\n\t\tdevm_kfree(ice_hw_to_dev(hw), ent1);\n\t}\n\n\treturn -ENOMEM;\n}\n\n \nstatic int\nice_add_prof_to_lst(struct ice_hw *hw, enum ice_block blk,\n\t\t    struct list_head *lst, u64 hdl)\n{\n\tstruct ice_prof_map *map;\n\tstruct ice_vsig_prof *p;\n\tint status = 0;\n\tu16 i;\n\n\tmutex_lock(&hw->blk[blk].es.prof_map_lock);\n\tmap = ice_search_prof_id(hw, blk, hdl);\n\tif (!map) {\n\t\tstatus = -ENOENT;\n\t\tgoto err_ice_add_prof_to_lst;\n\t}\n\n\tp = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*p), GFP_KERNEL);\n\tif (!p) {\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ice_add_prof_to_lst;\n\t}\n\n\tp->profile_cookie = map->profile_cookie;\n\tp->prof_id = map->prof_id;\n\tp->tcam_count = map->ptg_cnt;\n\n\tfor (i = 0; i < map->ptg_cnt; i++) {\n\t\tp->tcam[i].prof_id = map->prof_id;\n\t\tp->tcam[i].tcam_idx = ICE_INVALID_TCAM;\n\t\tp->tcam[i].ptg = map->ptg[i];\n\t}\n\n\tlist_add(&p->list, lst);\n\nerr_ice_add_prof_to_lst:\n\tmutex_unlock(&hw->blk[blk].es.prof_map_lock);\n\treturn status;\n}\n\n \nstatic int\nice_move_vsi(struct ice_hw *hw, enum ice_block blk, u16 vsi, u16 vsig,\n\t     struct list_head *chg)\n{\n\tstruct ice_chs_chg *p;\n\tu16 orig_vsig;\n\tint status;\n\n\tp = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*p), GFP_KERNEL);\n\tif (!p)\n\t\treturn -ENOMEM;\n\n\tstatus = ice_vsig_find_vsi(hw, blk, vsi, &orig_vsig);\n\tif (!status)\n\t\tstatus = ice_vsig_add_mv_vsi(hw, blk, vsi, vsig);\n\n\tif (status) {\n\t\tdevm_kfree(ice_hw_to_dev(hw), p);\n\t\treturn status;\n\t}\n\n\tp->type = ICE_VSI_MOVE;\n\tp->vsi = vsi;\n\tp->orig_vsig = orig_vsig;\n\tp->vsig = vsig;\n\n\tlist_add(&p->list_entry, chg);\n\n\treturn 0;\n}\n\n \nstatic void\nice_rem_chg_tcam_ent(struct ice_hw *hw, u16 idx, struct list_head *chg)\n{\n\tstruct ice_chs_chg *pos, *tmp;\n\n\tlist_for_each_entry_safe(tmp, pos, chg, list_entry)\n\t\tif (tmp->type == ICE_TCAM_ADD && tmp->tcam_idx == idx) {\n\t\t\tlist_del(&tmp->list_entry);\n\t\t\tdevm_kfree(ice_hw_to_dev(hw), tmp);\n\t\t}\n}\n\n \nstatic int\nice_prof_tcam_ena_dis(struct ice_hw *hw, enum ice_block blk, bool enable,\n\t\t      u16 vsig, struct ice_tcam_inf *tcam,\n\t\t      struct list_head *chg)\n{\n\tstruct ice_chs_chg *p;\n\tint status;\n\n\tu8 vl_msk[ICE_TCAM_KEY_VAL_SZ] = { 0xFF, 0xFF, 0xFF, 0xFF, 0xFF };\n\tu8 dc_msk[ICE_TCAM_KEY_VAL_SZ] = { 0xFF, 0xFF, 0x00, 0x00, 0x00 };\n\tu8 nm_msk[ICE_TCAM_KEY_VAL_SZ] = { 0x00, 0x00, 0x00, 0x00, 0x00 };\n\n\t \n\tif (!enable) {\n\t\tstatus = ice_rel_tcam_idx(hw, blk, tcam->tcam_idx);\n\n\t\t \n\t\tice_rem_chg_tcam_ent(hw, tcam->tcam_idx, chg);\n\t\ttcam->tcam_idx = 0;\n\t\ttcam->in_use = 0;\n\t\treturn status;\n\t}\n\n\t \n\t \n\tstatus = ice_alloc_tcam_ent(hw, blk, tcam->attr.mask == 0,\n\t\t\t\t    &tcam->tcam_idx);\n\tif (status)\n\t\treturn status;\n\n\t \n\tp = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*p), GFP_KERNEL);\n\tif (!p)\n\t\treturn -ENOMEM;\n\n\tstatus = ice_tcam_write_entry(hw, blk, tcam->tcam_idx, tcam->prof_id,\n\t\t\t\t      tcam->ptg, vsig, 0, tcam->attr.flags,\n\t\t\t\t      vl_msk, dc_msk, nm_msk);\n\tif (status)\n\t\tgoto err_ice_prof_tcam_ena_dis;\n\n\ttcam->in_use = 1;\n\n\tp->type = ICE_TCAM_ADD;\n\tp->add_tcam_idx = true;\n\tp->prof_id = tcam->prof_id;\n\tp->ptg = tcam->ptg;\n\tp->vsig = 0;\n\tp->tcam_idx = tcam->tcam_idx;\n\n\t \n\tlist_add(&p->list_entry, chg);\n\n\treturn 0;\n\nerr_ice_prof_tcam_ena_dis:\n\tdevm_kfree(ice_hw_to_dev(hw), p);\n\treturn status;\n}\n\n \nstatic int\nice_adj_prof_priorities(struct ice_hw *hw, enum ice_block blk, u16 vsig,\n\t\t\tstruct list_head *chg)\n{\n\tDECLARE_BITMAP(ptgs_used, ICE_XLT1_CNT);\n\tstruct ice_vsig_prof *t;\n\tint status;\n\tu16 idx;\n\n\tbitmap_zero(ptgs_used, ICE_XLT1_CNT);\n\tidx = vsig & ICE_VSIG_IDX_M;\n\n\t \n\n\tlist_for_each_entry(t, &hw->blk[blk].xlt2.vsig_tbl[idx].prop_lst,\n\t\t\t    list) {\n\t\tu16 i;\n\n\t\tfor (i = 0; i < t->tcam_count; i++) {\n\t\t\t \n\t\t\tif (test_bit(t->tcam[i].ptg, ptgs_used) &&\n\t\t\t    t->tcam[i].in_use) {\n\t\t\t\t \n\t\t\t\tstatus = ice_prof_tcam_ena_dis(hw, blk, false,\n\t\t\t\t\t\t\t       vsig,\n\t\t\t\t\t\t\t       &t->tcam[i],\n\t\t\t\t\t\t\t       chg);\n\t\t\t\tif (status)\n\t\t\t\t\treturn status;\n\t\t\t} else if (!test_bit(t->tcam[i].ptg, ptgs_used) &&\n\t\t\t\t   !t->tcam[i].in_use) {\n\t\t\t\t \n\t\t\t\tstatus = ice_prof_tcam_ena_dis(hw, blk, true,\n\t\t\t\t\t\t\t       vsig,\n\t\t\t\t\t\t\t       &t->tcam[i],\n\t\t\t\t\t\t\t       chg);\n\t\t\t\tif (status)\n\t\t\t\t\treturn status;\n\t\t\t}\n\n\t\t\t \n\t\t\t__set_bit(t->tcam[i].ptg, ptgs_used);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nice_add_prof_id_vsig(struct ice_hw *hw, enum ice_block blk, u16 vsig, u64 hdl,\n\t\t     bool rev, struct list_head *chg)\n{\n\t \n\tu8 vl_msk[ICE_TCAM_KEY_VAL_SZ] = { 0xFF, 0xFF, 0xFF, 0xFF, 0xFF };\n\tu8 dc_msk[ICE_TCAM_KEY_VAL_SZ] = { 0xFF, 0xFF, 0x00, 0x00, 0x00 };\n\tu8 nm_msk[ICE_TCAM_KEY_VAL_SZ] = { 0x00, 0x00, 0x00, 0x00, 0x00 };\n\tstruct ice_prof_map *map;\n\tstruct ice_vsig_prof *t;\n\tstruct ice_chs_chg *p;\n\tu16 vsig_idx, i;\n\tint status = 0;\n\n\t \n\tif (ice_has_prof_vsig(hw, blk, vsig, hdl))\n\t\treturn -EEXIST;\n\n\t \n\tt = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*t), GFP_KERNEL);\n\tif (!t)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&hw->blk[blk].es.prof_map_lock);\n\t \n\tmap = ice_search_prof_id(hw, blk, hdl);\n\tif (!map) {\n\t\tstatus = -ENOENT;\n\t\tgoto err_ice_add_prof_id_vsig;\n\t}\n\n\tt->profile_cookie = map->profile_cookie;\n\tt->prof_id = map->prof_id;\n\tt->tcam_count = map->ptg_cnt;\n\n\t \n\tfor (i = 0; i < map->ptg_cnt; i++) {\n\t\tu16 tcam_idx;\n\n\t\t \n\t\tp = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*p), GFP_KERNEL);\n\t\tif (!p) {\n\t\t\tstatus = -ENOMEM;\n\t\t\tgoto err_ice_add_prof_id_vsig;\n\t\t}\n\n\t\t \n\t\t \n\t\tstatus = ice_alloc_tcam_ent(hw, blk, map->attr[i].mask == 0,\n\t\t\t\t\t    &tcam_idx);\n\t\tif (status) {\n\t\t\tdevm_kfree(ice_hw_to_dev(hw), p);\n\t\t\tgoto err_ice_add_prof_id_vsig;\n\t\t}\n\n\t\tt->tcam[i].ptg = map->ptg[i];\n\t\tt->tcam[i].prof_id = map->prof_id;\n\t\tt->tcam[i].tcam_idx = tcam_idx;\n\t\tt->tcam[i].attr = map->attr[i];\n\t\tt->tcam[i].in_use = true;\n\n\t\tp->type = ICE_TCAM_ADD;\n\t\tp->add_tcam_idx = true;\n\t\tp->prof_id = t->tcam[i].prof_id;\n\t\tp->ptg = t->tcam[i].ptg;\n\t\tp->vsig = vsig;\n\t\tp->tcam_idx = t->tcam[i].tcam_idx;\n\n\t\t \n\t\tstatus = ice_tcam_write_entry(hw, blk, t->tcam[i].tcam_idx,\n\t\t\t\t\t      t->tcam[i].prof_id,\n\t\t\t\t\t      t->tcam[i].ptg, vsig, 0, 0,\n\t\t\t\t\t      vl_msk, dc_msk, nm_msk);\n\t\tif (status) {\n\t\t\tdevm_kfree(ice_hw_to_dev(hw), p);\n\t\t\tgoto err_ice_add_prof_id_vsig;\n\t\t}\n\n\t\t \n\t\tlist_add(&p->list_entry, chg);\n\t}\n\n\t \n\tvsig_idx = vsig & ICE_VSIG_IDX_M;\n\tif (rev)\n\t\tlist_add_tail(&t->list,\n\t\t\t      &hw->blk[blk].xlt2.vsig_tbl[vsig_idx].prop_lst);\n\telse\n\t\tlist_add(&t->list,\n\t\t\t &hw->blk[blk].xlt2.vsig_tbl[vsig_idx].prop_lst);\n\n\tmutex_unlock(&hw->blk[blk].es.prof_map_lock);\n\treturn status;\n\nerr_ice_add_prof_id_vsig:\n\tmutex_unlock(&hw->blk[blk].es.prof_map_lock);\n\t \n\tdevm_kfree(ice_hw_to_dev(hw), t);\n\treturn status;\n}\n\n \nstatic int\nice_create_prof_id_vsig(struct ice_hw *hw, enum ice_block blk, u16 vsi, u64 hdl,\n\t\t\tstruct list_head *chg)\n{\n\tstruct ice_chs_chg *p;\n\tu16 new_vsig;\n\tint status;\n\n\tp = devm_kzalloc(ice_hw_to_dev(hw), sizeof(*p), GFP_KERNEL);\n\tif (!p)\n\t\treturn -ENOMEM;\n\n\tnew_vsig = ice_vsig_alloc(hw, blk);\n\tif (!new_vsig) {\n\t\tstatus = -EIO;\n\t\tgoto err_ice_create_prof_id_vsig;\n\t}\n\n\tstatus = ice_move_vsi(hw, blk, vsi, new_vsig, chg);\n\tif (status)\n\t\tgoto err_ice_create_prof_id_vsig;\n\n\tstatus = ice_add_prof_id_vsig(hw, blk, new_vsig, hdl, false, chg);\n\tif (status)\n\t\tgoto err_ice_create_prof_id_vsig;\n\n\tp->type = ICE_VSIG_ADD;\n\tp->vsi = vsi;\n\tp->orig_vsig = ICE_DEFAULT_VSIG;\n\tp->vsig = new_vsig;\n\n\tlist_add(&p->list_entry, chg);\n\n\treturn 0;\n\nerr_ice_create_prof_id_vsig:\n\t \n\tdevm_kfree(ice_hw_to_dev(hw), p);\n\treturn status;\n}\n\n \nstatic int\nice_create_vsig_from_lst(struct ice_hw *hw, enum ice_block blk, u16 vsi,\n\t\t\t struct list_head *lst, u16 *new_vsig,\n\t\t\t struct list_head *chg)\n{\n\tstruct ice_vsig_prof *t;\n\tint status;\n\tu16 vsig;\n\n\tvsig = ice_vsig_alloc(hw, blk);\n\tif (!vsig)\n\t\treturn -EIO;\n\n\tstatus = ice_move_vsi(hw, blk, vsi, vsig, chg);\n\tif (status)\n\t\treturn status;\n\n\tlist_for_each_entry(t, lst, list) {\n\t\t \n\t\tstatus = ice_add_prof_id_vsig(hw, blk, vsig, t->profile_cookie,\n\t\t\t\t\t      true, chg);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\t*new_vsig = vsig;\n\n\treturn 0;\n}\n\n \nstatic bool\nice_find_prof_vsig(struct ice_hw *hw, enum ice_block blk, u64 hdl, u16 *vsig)\n{\n\tstruct ice_vsig_prof *t;\n\tstruct list_head lst;\n\tint status;\n\n\tINIT_LIST_HEAD(&lst);\n\n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (!t)\n\t\treturn false;\n\n\tt->profile_cookie = hdl;\n\tlist_add(&t->list, &lst);\n\n\tstatus = ice_find_dup_props_vsig(hw, blk, &lst, vsig);\n\n\tlist_del(&t->list);\n\tkfree(t);\n\n\treturn !status;\n}\n\n \nint\nice_add_prof_id_flow(struct ice_hw *hw, enum ice_block blk, u16 vsi, u64 hdl)\n{\n\tstruct ice_vsig_prof *tmp1, *del1;\n\tstruct ice_chs_chg *tmp, *del;\n\tstruct list_head union_lst;\n\tstruct list_head chg;\n\tint status;\n\tu16 vsig;\n\n\tINIT_LIST_HEAD(&union_lst);\n\tINIT_LIST_HEAD(&chg);\n\n\t \n\tstatus = ice_get_prof(hw, blk, hdl, &chg);\n\tif (status)\n\t\treturn status;\n\n\t \n\tstatus = ice_vsig_find_vsi(hw, blk, vsi, &vsig);\n\tif (!status && vsig) {\n\t\tbool only_vsi;\n\t\tu16 or_vsig;\n\t\tu16 ref;\n\n\t\t \n\t\tor_vsig = vsig;\n\n\t\t \n\t\tif (ice_has_prof_vsig(hw, blk, vsig, hdl)) {\n\t\t\tstatus = -EEXIST;\n\t\t\tgoto err_ice_add_prof_id_flow;\n\t\t}\n\n\t\t \n\t\tstatus = ice_vsig_get_ref(hw, blk, vsig, &ref);\n\t\tif (status)\n\t\t\tgoto err_ice_add_prof_id_flow;\n\t\tonly_vsi = (ref == 1);\n\n\t\t \n\t\tstatus = ice_get_profs_vsig(hw, blk, vsig, &union_lst);\n\t\tif (status)\n\t\t\tgoto err_ice_add_prof_id_flow;\n\n\t\tstatus = ice_add_prof_to_lst(hw, blk, &union_lst, hdl);\n\t\tif (status)\n\t\t\tgoto err_ice_add_prof_id_flow;\n\n\t\t \n\t\tstatus = ice_find_dup_props_vsig(hw, blk, &union_lst, &vsig);\n\t\tif (!status) {\n\t\t\t \n\t\t\tstatus = ice_move_vsi(hw, blk, vsi, vsig, &chg);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof_id_flow;\n\n\t\t\t \n\t\t\tif (only_vsi) {\n\t\t\t\tstatus = ice_rem_vsig(hw, blk, or_vsig, &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_add_prof_id_flow;\n\t\t\t}\n\t\t} else if (only_vsi) {\n\t\t\t \n\t\t\tstatus = ice_add_prof_id_vsig(hw, blk, vsig, hdl, false,\n\t\t\t\t\t\t      &chg);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof_id_flow;\n\n\t\t\t \n\t\t\tstatus = ice_adj_prof_priorities(hw, blk, vsig, &chg);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof_id_flow;\n\t\t} else {\n\t\t\t \n\t\t\tstatus = ice_create_vsig_from_lst(hw, blk, vsi,\n\t\t\t\t\t\t\t  &union_lst, &vsig,\n\t\t\t\t\t\t\t  &chg);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof_id_flow;\n\n\t\t\t \n\t\t\tstatus = ice_adj_prof_priorities(hw, blk, vsig, &chg);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof_id_flow;\n\t\t}\n\t} else {\n\t\t \n\t\t \n\t\tif (ice_find_prof_vsig(hw, blk, hdl, &vsig)) {\n\t\t\t \n\t\t\t \n\t\t\tstatus = ice_move_vsi(hw, blk, vsi, vsig, &chg);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof_id_flow;\n\t\t} else {\n\t\t\t \n\t\t\t \n\t\t\tstatus = ice_create_prof_id_vsig(hw, blk, vsi, hdl,\n\t\t\t\t\t\t\t &chg);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_add_prof_id_flow;\n\t\t}\n\t}\n\n\t \n\tif (!status)\n\t\tstatus = ice_upd_prof_hw(hw, blk, &chg);\n\nerr_ice_add_prof_id_flow:\n\tlist_for_each_entry_safe(del, tmp, &chg, list_entry) {\n\t\tlist_del(&del->list_entry);\n\t\tdevm_kfree(ice_hw_to_dev(hw), del);\n\t}\n\n\tlist_for_each_entry_safe(del1, tmp1, &union_lst, list) {\n\t\tlist_del(&del1->list);\n\t\tdevm_kfree(ice_hw_to_dev(hw), del1);\n\t}\n\n\treturn status;\n}\n\n \nstatic int\nice_rem_prof_from_list(struct ice_hw *hw, struct list_head *lst, u64 hdl)\n{\n\tstruct ice_vsig_prof *ent, *tmp;\n\n\tlist_for_each_entry_safe(ent, tmp, lst, list)\n\t\tif (ent->profile_cookie == hdl) {\n\t\t\tlist_del(&ent->list);\n\t\t\tdevm_kfree(ice_hw_to_dev(hw), ent);\n\t\t\treturn 0;\n\t\t}\n\n\treturn -ENOENT;\n}\n\n \nint\nice_rem_prof_id_flow(struct ice_hw *hw, enum ice_block blk, u16 vsi, u64 hdl)\n{\n\tstruct ice_vsig_prof *tmp1, *del1;\n\tstruct ice_chs_chg *tmp, *del;\n\tstruct list_head chg, copy;\n\tint status;\n\tu16 vsig;\n\n\tINIT_LIST_HEAD(&copy);\n\tINIT_LIST_HEAD(&chg);\n\n\t \n\tstatus = ice_vsig_find_vsi(hw, blk, vsi, &vsig);\n\tif (!status && vsig) {\n\t\tbool last_profile;\n\t\tbool only_vsi;\n\t\tu16 ref;\n\n\t\t \n\t\tlast_profile = ice_vsig_prof_id_count(hw, blk, vsig) == 1;\n\t\tstatus = ice_vsig_get_ref(hw, blk, vsig, &ref);\n\t\tif (status)\n\t\t\tgoto err_ice_rem_prof_id_flow;\n\t\tonly_vsi = (ref == 1);\n\n\t\tif (only_vsi) {\n\t\t\t \n\n\t\t\tif (last_profile) {\n\t\t\t\t \n\t\t\t\tstatus = ice_rem_vsig(hw, blk, vsig, &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\t\t\t} else {\n\t\t\t\tstatus = ice_rem_prof_id_vsig(hw, blk, vsig,\n\t\t\t\t\t\t\t      hdl, &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\n\t\t\t\t \n\t\t\t\tstatus = ice_adj_prof_priorities(hw, blk, vsig,\n\t\t\t\t\t\t\t\t &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\t\t\t}\n\n\t\t} else {\n\t\t\t \n\t\t\tstatus = ice_get_profs_vsig(hw, blk, vsig, &copy);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\n\t\t\t \n\t\t\tstatus = ice_rem_prof_from_list(hw, &copy, hdl);\n\t\t\tif (status)\n\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\n\t\t\tif (list_empty(&copy)) {\n\t\t\t\tstatus = ice_move_vsi(hw, blk, vsi,\n\t\t\t\t\t\t      ICE_DEFAULT_VSIG, &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\n\t\t\t} else if (!ice_find_dup_props_vsig(hw, blk, &copy,\n\t\t\t\t\t\t\t    &vsig)) {\n\t\t\t\t \n\t\t\t\t \n\t\t\t\t \n\n\t\t\t\t \n\t\t\t\tstatus = ice_move_vsi(hw, blk, vsi, vsig, &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tstatus = ice_create_vsig_from_lst(hw, blk, vsi,\n\t\t\t\t\t\t\t\t  &copy, &vsig,\n\t\t\t\t\t\t\t\t  &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\n\t\t\t\t \n\t\t\t\tstatus = ice_adj_prof_priorities(hw, blk, vsig,\n\t\t\t\t\t\t\t\t &chg);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto err_ice_rem_prof_id_flow;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstatus = -ENOENT;\n\t}\n\n\t \n\tif (!status)\n\t\tstatus = ice_upd_prof_hw(hw, blk, &chg);\n\nerr_ice_rem_prof_id_flow:\n\tlist_for_each_entry_safe(del, tmp, &chg, list_entry) {\n\t\tlist_del(&del->list_entry);\n\t\tdevm_kfree(ice_hw_to_dev(hw), del);\n\t}\n\n\tlist_for_each_entry_safe(del1, tmp1, &copy, list) {\n\t\tlist_del(&del1->list);\n\t\tdevm_kfree(ice_hw_to_dev(hw), del1);\n\t}\n\n\treturn status;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}