{
  "module_name": "wx_hw.c",
  "hash_id": "8d380349ba87ed7bcfc224a4902ea738446580c6ce0b94afb34f2affe8bb94a0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/wangxun/libwx/wx_hw.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <linux/netdevice.h>\n#include <linux/if_ether.h>\n#include <linux/if_vlan.h>\n#include <linux/iopoll.h>\n#include <linux/pci.h>\n\n#include \"wx_type.h\"\n#include \"wx_lib.h\"\n#include \"wx_hw.h\"\n\nstatic void wx_intr_disable(struct wx *wx, u64 qmask)\n{\n\tu32 mask;\n\n\tmask = (qmask & U32_MAX);\n\tif (mask)\n\t\twr32(wx, WX_PX_IMS(0), mask);\n\n\tif (wx->mac.type == wx_mac_sp) {\n\t\tmask = (qmask >> 32);\n\t\tif (mask)\n\t\t\twr32(wx, WX_PX_IMS(1), mask);\n\t}\n}\n\nvoid wx_intr_enable(struct wx *wx, u64 qmask)\n{\n\tu32 mask;\n\n\tmask = (qmask & U32_MAX);\n\tif (mask)\n\t\twr32(wx, WX_PX_IMC(0), mask);\n\tif (wx->mac.type == wx_mac_sp) {\n\t\tmask = (qmask >> 32);\n\t\tif (mask)\n\t\t\twr32(wx, WX_PX_IMC(1), mask);\n\t}\n}\nEXPORT_SYMBOL(wx_intr_enable);\n\n \nvoid wx_irq_disable(struct wx *wx)\n{\n\tstruct pci_dev *pdev = wx->pdev;\n\n\twr32(wx, WX_PX_MISC_IEN, 0);\n\twx_intr_disable(wx, WX_INTR_ALL);\n\n\tif (pdev->msix_enabled) {\n\t\tint vector;\n\n\t\tfor (vector = 0; vector < wx->num_q_vectors; vector++)\n\t\t\tsynchronize_irq(wx->msix_entries[vector].vector);\n\n\t\tsynchronize_irq(wx->msix_entries[vector].vector);\n\t} else {\n\t\tsynchronize_irq(pdev->irq);\n\t}\n}\nEXPORT_SYMBOL(wx_irq_disable);\n\n \nstatic int wx_fmgr_cmd_op(struct wx *wx, u32 cmd, u32 cmd_addr)\n{\n\tu32 cmd_val = 0, val = 0;\n\n\tcmd_val = WX_SPI_CMD_CMD(cmd) |\n\t\t  WX_SPI_CMD_CLK(WX_SPI_CLK_DIV) |\n\t\t  cmd_addr;\n\twr32(wx, WX_SPI_CMD, cmd_val);\n\n\treturn read_poll_timeout(rd32, val, (val & 0x1), 10, 100000,\n\t\t\t\t false, wx, WX_SPI_STATUS);\n}\n\nstatic int wx_flash_read_dword(struct wx *wx, u32 addr, u32 *data)\n{\n\tint ret = 0;\n\n\tret = wx_fmgr_cmd_op(wx, WX_SPI_CMD_READ_DWORD, addr);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t*data = rd32(wx, WX_SPI_DATA);\n\n\treturn ret;\n}\n\nint wx_check_flash_load(struct wx *hw, u32 check_bit)\n{\n\tu32 reg = 0;\n\tint err = 0;\n\n\t \n\tif (!(rd32(hw, WX_SPI_STATUS) &\n\t      WX_SPI_STATUS_FLASH_BYPASS)) {\n\t\t \n\t\terr = read_poll_timeout(rd32, reg, !(reg & check_bit), 20000, 2000000,\n\t\t\t\t\tfalse, hw, WX_SPI_ILDR_STATUS);\n\t\tif (err < 0)\n\t\t\twx_err(hw, \"Check flash load timeout.\\n\");\n\t}\n\n\treturn err;\n}\nEXPORT_SYMBOL(wx_check_flash_load);\n\nvoid wx_control_hw(struct wx *wx, bool drv)\n{\n\t \n\twr32m(wx, WX_CFG_PORT_CTL, WX_CFG_PORT_CTL_DRV_LOAD,\n\t      drv ? WX_CFG_PORT_CTL_DRV_LOAD : 0);\n}\nEXPORT_SYMBOL(wx_control_hw);\n\n \nint wx_mng_present(struct wx *wx)\n{\n\tu32 fwsm;\n\n\tfwsm = rd32(wx, WX_MIS_ST);\n\tif (fwsm & WX_MIS_ST_MNG_INIT_DN)\n\t\treturn 0;\n\telse\n\t\treturn -EACCES;\n}\nEXPORT_SYMBOL(wx_mng_present);\n\n \nstatic DEFINE_MUTEX(wx_sw_sync_lock);\n\n \nstatic void wx_release_sw_sync(struct wx *wx, u32 mask)\n{\n\tmutex_lock(&wx_sw_sync_lock);\n\twr32m(wx, WX_MNG_SWFW_SYNC, mask, 0);\n\tmutex_unlock(&wx_sw_sync_lock);\n}\n\n \nstatic int wx_acquire_sw_sync(struct wx *wx, u32 mask)\n{\n\tu32 sem = 0;\n\tint ret = 0;\n\n\tmutex_lock(&wx_sw_sync_lock);\n\tret = read_poll_timeout(rd32, sem, !(sem & mask),\n\t\t\t\t5000, 2000000, false, wx, WX_MNG_SWFW_SYNC);\n\tif (!ret) {\n\t\tsem |= mask;\n\t\twr32(wx, WX_MNG_SWFW_SYNC, sem);\n\t} else {\n\t\twx_err(wx, \"SW Semaphore not granted: 0x%x.\\n\", sem);\n\t}\n\tmutex_unlock(&wx_sw_sync_lock);\n\n\treturn ret;\n}\n\n \nint wx_host_interface_command(struct wx *wx, u32 *buffer,\n\t\t\t      u32 length, u32 timeout, bool return_data)\n{\n\tu32 hdr_size = sizeof(struct wx_hic_hdr);\n\tu32 hicr, i, bi, buf[64] = {};\n\tint status = 0;\n\tu32 dword_len;\n\tu16 buf_len;\n\n\tif (length == 0 || length > WX_HI_MAX_BLOCK_BYTE_LENGTH) {\n\t\twx_err(wx, \"Buffer length failure buffersize=%d.\\n\", length);\n\t\treturn -EINVAL;\n\t}\n\n\tstatus = wx_acquire_sw_sync(wx, WX_MNG_SWFW_SYNC_SW_MB);\n\tif (status != 0)\n\t\treturn status;\n\n\t \n\tif ((length % (sizeof(u32))) != 0) {\n\t\twx_err(wx, \"Buffer length failure, not aligned to dword\");\n\t\tstatus = -EINVAL;\n\t\tgoto rel_out;\n\t}\n\n\tdword_len = length >> 2;\n\n\t \n\tfor (i = 0; i < dword_len; i++) {\n\t\twr32a(wx, WX_MNG_MBOX, i, (__force u32)cpu_to_le32(buffer[i]));\n\t\t \n\t\tbuf[i] = rd32a(wx, WX_MNG_MBOX, i);\n\t}\n\t \n\twr32m(wx, WX_MNG_MBOX_CTL,\n\t      WX_MNG_MBOX_CTL_SWRDY, WX_MNG_MBOX_CTL_SWRDY);\n\n\tstatus = read_poll_timeout(rd32, hicr, hicr & WX_MNG_MBOX_CTL_FWRDY, 1000,\n\t\t\t\t   timeout * 1000, false, wx, WX_MNG_MBOX_CTL);\n\n\t \n\tif (status) {\n\t\twx_dbg(wx, \"Command has failed with no status valid.\\n\");\n\n\t\tbuf[0] = rd32(wx, WX_MNG_MBOX);\n\t\tif ((buffer[0] & 0xff) != (~buf[0] >> 24)) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto rel_out;\n\t\t}\n\t\tif ((buf[0] & 0xff0000) >> 16 == 0x80) {\n\t\t\twx_dbg(wx, \"It's unknown cmd.\\n\");\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto rel_out;\n\t\t}\n\n\t\twx_dbg(wx, \"write value:\\n\");\n\t\tfor (i = 0; i < dword_len; i++)\n\t\t\twx_dbg(wx, \"%x \", buffer[i]);\n\t\twx_dbg(wx, \"read value:\\n\");\n\t\tfor (i = 0; i < dword_len; i++)\n\t\t\twx_dbg(wx, \"%x \", buf[i]);\n\t}\n\n\tif (!return_data)\n\t\tgoto rel_out;\n\n\t \n\tdword_len = hdr_size >> 2;\n\n\t \n\tfor (bi = 0; bi < dword_len; bi++) {\n\t\tbuffer[bi] = rd32a(wx, WX_MNG_MBOX, bi);\n\t\tle32_to_cpus(&buffer[bi]);\n\t}\n\n\t \n\tbuf_len = ((struct wx_hic_hdr *)buffer)->buf_len;\n\tif (buf_len == 0)\n\t\tgoto rel_out;\n\n\tif (length < buf_len + hdr_size) {\n\t\twx_err(wx, \"Buffer not large enough for reply message.\\n\");\n\t\tstatus = -EFAULT;\n\t\tgoto rel_out;\n\t}\n\n\t \n\tdword_len = (buf_len + 3) >> 2;\n\n\t \n\tfor (; bi <= dword_len; bi++) {\n\t\tbuffer[bi] = rd32a(wx, WX_MNG_MBOX, bi);\n\t\tle32_to_cpus(&buffer[bi]);\n\t}\n\nrel_out:\n\twx_release_sw_sync(wx, WX_MNG_SWFW_SYNC_SW_MB);\n\treturn status;\n}\nEXPORT_SYMBOL(wx_host_interface_command);\n\n \nstatic int wx_read_ee_hostif_data(struct wx *wx, u16 offset, u16 *data)\n{\n\tstruct wx_hic_read_shadow_ram buffer;\n\tint status;\n\n\tbuffer.hdr.req.cmd = FW_READ_SHADOW_RAM_CMD;\n\tbuffer.hdr.req.buf_lenh = 0;\n\tbuffer.hdr.req.buf_lenl = FW_READ_SHADOW_RAM_LEN;\n\tbuffer.hdr.req.checksum = FW_DEFAULT_CHECKSUM;\n\n\t \n\tbuffer.address = (__force u32)cpu_to_be32(offset * 2);\n\t \n\tbuffer.length = (__force u16)cpu_to_be16(sizeof(u16));\n\n\tstatus = wx_host_interface_command(wx, (u32 *)&buffer, sizeof(buffer),\n\t\t\t\t\t   WX_HI_COMMAND_TIMEOUT, false);\n\n\tif (status != 0)\n\t\treturn status;\n\n\t*data = (u16)rd32a(wx, WX_MNG_MBOX, FW_NVM_DATA_OFFSET);\n\n\treturn status;\n}\n\n \nint wx_read_ee_hostif(struct wx *wx, u16 offset, u16 *data)\n{\n\tint status = 0;\n\n\tstatus = wx_acquire_sw_sync(wx, WX_MNG_SWFW_SYNC_SW_FLASH);\n\tif (status == 0) {\n\t\tstatus = wx_read_ee_hostif_data(wx, offset, data);\n\t\twx_release_sw_sync(wx, WX_MNG_SWFW_SYNC_SW_FLASH);\n\t}\n\n\treturn status;\n}\nEXPORT_SYMBOL(wx_read_ee_hostif);\n\n \nint wx_read_ee_hostif_buffer(struct wx *wx,\n\t\t\t     u16 offset, u16 words, u16 *data)\n{\n\tstruct wx_hic_read_shadow_ram buffer;\n\tu32 current_word = 0;\n\tu16 words_to_read;\n\tu32 value = 0;\n\tint status;\n\tu32 i;\n\n\t \n\tstatus = wx_acquire_sw_sync(wx, WX_MNG_SWFW_SYNC_SW_FLASH);\n\tif (status != 0)\n\t\treturn status;\n\n\twhile (words) {\n\t\tif (words > FW_MAX_READ_BUFFER_SIZE / 2)\n\t\t\twords_to_read = FW_MAX_READ_BUFFER_SIZE / 2;\n\t\telse\n\t\t\twords_to_read = words;\n\n\t\tbuffer.hdr.req.cmd = FW_READ_SHADOW_RAM_CMD;\n\t\tbuffer.hdr.req.buf_lenh = 0;\n\t\tbuffer.hdr.req.buf_lenl = FW_READ_SHADOW_RAM_LEN;\n\t\tbuffer.hdr.req.checksum = FW_DEFAULT_CHECKSUM;\n\n\t\t \n\t\tbuffer.address = (__force u32)cpu_to_be32((offset + current_word) * 2);\n\t\tbuffer.length = (__force u16)cpu_to_be16(words_to_read * 2);\n\n\t\tstatus = wx_host_interface_command(wx, (u32 *)&buffer,\n\t\t\t\t\t\t   sizeof(buffer),\n\t\t\t\t\t\t   WX_HI_COMMAND_TIMEOUT,\n\t\t\t\t\t\t   false);\n\n\t\tif (status != 0) {\n\t\t\twx_err(wx, \"Host interface command failed\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tfor (i = 0; i < words_to_read; i++) {\n\t\t\tu32 reg = WX_MNG_MBOX + (FW_NVM_DATA_OFFSET << 2) + 2 * i;\n\n\t\t\tvalue = rd32(wx, reg);\n\t\t\tdata[current_word] = (u16)(value & 0xffff);\n\t\t\tcurrent_word++;\n\t\t\ti++;\n\t\t\tif (i < words_to_read) {\n\t\t\t\tvalue >>= 16;\n\t\t\t\tdata[current_word] = (u16)(value & 0xffff);\n\t\t\t\tcurrent_word++;\n\t\t\t}\n\t\t}\n\t\twords -= words_to_read;\n\t}\n\nout:\n\twx_release_sw_sync(wx, WX_MNG_SWFW_SYNC_SW_FLASH);\n\treturn status;\n}\nEXPORT_SYMBOL(wx_read_ee_hostif_buffer);\n\n \nvoid wx_init_eeprom_params(struct wx *wx)\n{\n\tstruct wx_eeprom_info *eeprom = &wx->eeprom;\n\tu16 eeprom_size;\n\tu16 data = 0x80;\n\n\tif (eeprom->type == wx_eeprom_uninitialized) {\n\t\teeprom->semaphore_delay = 10;\n\t\teeprom->type = wx_eeprom_none;\n\n\t\tif (!(rd32(wx, WX_SPI_STATUS) &\n\t\t      WX_SPI_STATUS_FLASH_BYPASS)) {\n\t\t\teeprom->type = wx_flash;\n\n\t\t\teeprom_size = 4096;\n\t\t\teeprom->word_size = eeprom_size >> 1;\n\n\t\t\twx_dbg(wx, \"Eeprom params: type = %d, size = %d\\n\",\n\t\t\t       eeprom->type, eeprom->word_size);\n\t\t}\n\t}\n\n\tif (wx->mac.type == wx_mac_sp) {\n\t\tif (wx_read_ee_hostif(wx, WX_SW_REGION_PTR, &data)) {\n\t\t\twx_err(wx, \"NVM Read Error\\n\");\n\t\t\treturn;\n\t\t}\n\t\tdata = data >> 1;\n\t}\n\n\teeprom->sw_region_offset = data;\n}\nEXPORT_SYMBOL(wx_init_eeprom_params);\n\n \nvoid wx_get_mac_addr(struct wx *wx, u8 *mac_addr)\n{\n\tu32 rar_high;\n\tu32 rar_low;\n\tu16 i;\n\n\twr32(wx, WX_PSR_MAC_SWC_IDX, 0);\n\trar_high = rd32(wx, WX_PSR_MAC_SWC_AD_H);\n\trar_low = rd32(wx, WX_PSR_MAC_SWC_AD_L);\n\n\tfor (i = 0; i < 2; i++)\n\t\tmac_addr[i] = (u8)(rar_high >> (1 - i) * 8);\n\n\tfor (i = 0; i < 4; i++)\n\t\tmac_addr[i + 2] = (u8)(rar_low >> (3 - i) * 8);\n}\nEXPORT_SYMBOL(wx_get_mac_addr);\n\n \nstatic int wx_set_rar(struct wx *wx, u32 index, u8 *addr, u64 pools,\n\t\t      u32 enable_addr)\n{\n\tu32 rar_entries = wx->mac.num_rar_entries;\n\tu32 rar_low, rar_high;\n\n\t \n\tif (index >= rar_entries) {\n\t\twx_err(wx, \"RAR index %d is out of range.\\n\", index);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\twr32(wx, WX_PSR_MAC_SWC_IDX, index);\n\n\t \n\twr32(wx, WX_PSR_MAC_SWC_VM_L, pools & 0xFFFFFFFF);\n\tif (wx->mac.type == wx_mac_sp)\n\t\twr32(wx, WX_PSR_MAC_SWC_VM_H, pools >> 32);\n\n\t \n\trar_low = ((u32)addr[5] |\n\t\t  ((u32)addr[4] << 8) |\n\t\t  ((u32)addr[3] << 16) |\n\t\t  ((u32)addr[2] << 24));\n\trar_high = ((u32)addr[1] |\n\t\t   ((u32)addr[0] << 8));\n\tif (enable_addr != 0)\n\t\trar_high |= WX_PSR_MAC_SWC_AD_H_AV;\n\n\twr32(wx, WX_PSR_MAC_SWC_AD_L, rar_low);\n\twr32m(wx, WX_PSR_MAC_SWC_AD_H,\n\t      (WX_PSR_MAC_SWC_AD_H_AD(U16_MAX) |\n\t       WX_PSR_MAC_SWC_AD_H_ADTYPE(1) |\n\t       WX_PSR_MAC_SWC_AD_H_AV),\n\t      rar_high);\n\n\treturn 0;\n}\n\n \nstatic int wx_clear_rar(struct wx *wx, u32 index)\n{\n\tu32 rar_entries = wx->mac.num_rar_entries;\n\n\t \n\tif (index >= rar_entries) {\n\t\twx_err(wx, \"RAR index %d is out of range.\\n\", index);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\twr32(wx, WX_PSR_MAC_SWC_IDX, index);\n\n\twr32(wx, WX_PSR_MAC_SWC_VM_L, 0);\n\twr32(wx, WX_PSR_MAC_SWC_VM_H, 0);\n\n\twr32(wx, WX_PSR_MAC_SWC_AD_L, 0);\n\twr32m(wx, WX_PSR_MAC_SWC_AD_H,\n\t      (WX_PSR_MAC_SWC_AD_H_AD(U16_MAX) |\n\t       WX_PSR_MAC_SWC_AD_H_ADTYPE(1) |\n\t       WX_PSR_MAC_SWC_AD_H_AV),\n\t      0);\n\n\treturn 0;\n}\n\n \nstatic int wx_clear_vmdq(struct wx *wx, u32 rar, u32 __maybe_unused vmdq)\n{\n\tu32 rar_entries = wx->mac.num_rar_entries;\n\tu32 mpsar_lo, mpsar_hi;\n\n\t \n\tif (rar >= rar_entries) {\n\t\twx_err(wx, \"RAR index %d is out of range.\\n\", rar);\n\t\treturn -EINVAL;\n\t}\n\n\twr32(wx, WX_PSR_MAC_SWC_IDX, rar);\n\tmpsar_lo = rd32(wx, WX_PSR_MAC_SWC_VM_L);\n\tmpsar_hi = rd32(wx, WX_PSR_MAC_SWC_VM_H);\n\n\tif (!mpsar_lo && !mpsar_hi)\n\t\treturn 0;\n\n\t \n\tif (mpsar_lo == 0 && mpsar_hi == 0 && rar != 0)\n\t\twx_clear_rar(wx, rar);\n\n\treturn 0;\n}\n\n \nstatic void wx_init_uta_tables(struct wx *wx)\n{\n\tint i;\n\n\twx_dbg(wx, \" Clearing UTA\\n\");\n\n\tfor (i = 0; i < 128; i++)\n\t\twr32(wx, WX_PSR_UC_TBL(i), 0);\n}\n\n \nvoid wx_init_rx_addrs(struct wx *wx)\n{\n\tu32 rar_entries = wx->mac.num_rar_entries;\n\tu32 psrctl;\n\tint i;\n\n\t \n\tif (!is_valid_ether_addr(wx->mac.addr)) {\n\t\t \n\t\twx_get_mac_addr(wx, wx->mac.addr);\n\t\twx_dbg(wx, \"Keeping Current RAR0 Addr = %pM\\n\", wx->mac.addr);\n\t} else {\n\t\t \n\t\twx_dbg(wx, \"Overriding MAC Address in RAR[0]\\n\");\n\t\twx_dbg(wx, \"New MAC Addr = %pM\\n\", wx->mac.addr);\n\n\t\twx_set_rar(wx, 0, wx->mac.addr, 0, WX_PSR_MAC_SWC_AD_H_AV);\n\n\t\tif (wx->mac.type == wx_mac_sp) {\n\t\t\t \n\t\t\twx_clear_vmdq(wx, 0, WX_CLEAR_VMDQ_ALL);\n\t\t}\n\t}\n\n\t \n\twx_dbg(wx, \"Clearing RAR[1-%d]\\n\", rar_entries - 1);\n\tfor (i = 1; i < rar_entries; i++) {\n\t\twr32(wx, WX_PSR_MAC_SWC_IDX, i);\n\t\twr32(wx, WX_PSR_MAC_SWC_AD_L, 0);\n\t\twr32(wx, WX_PSR_MAC_SWC_AD_H, 0);\n\t}\n\n\t \n\twx->addr_ctrl.mta_in_use = 0;\n\tpsrctl = rd32(wx, WX_PSR_CTL);\n\tpsrctl &= ~(WX_PSR_CTL_MO | WX_PSR_CTL_MFE);\n\tpsrctl |= wx->mac.mc_filter_type << WX_PSR_CTL_MO_SHIFT;\n\twr32(wx, WX_PSR_CTL, psrctl);\n\twx_dbg(wx, \" Clearing MTA\\n\");\n\tfor (i = 0; i < wx->mac.mcft_size; i++)\n\t\twr32(wx, WX_PSR_MC_TBL(i), 0);\n\n\twx_init_uta_tables(wx);\n}\nEXPORT_SYMBOL(wx_init_rx_addrs);\n\nstatic void wx_sync_mac_table(struct wx *wx)\n{\n\tint i;\n\n\tfor (i = 0; i < wx->mac.num_rar_entries; i++) {\n\t\tif (wx->mac_table[i].state & WX_MAC_STATE_MODIFIED) {\n\t\t\tif (wx->mac_table[i].state & WX_MAC_STATE_IN_USE) {\n\t\t\t\twx_set_rar(wx, i,\n\t\t\t\t\t   wx->mac_table[i].addr,\n\t\t\t\t\t   wx->mac_table[i].pools,\n\t\t\t\t\t   WX_PSR_MAC_SWC_AD_H_AV);\n\t\t\t} else {\n\t\t\t\twx_clear_rar(wx, i);\n\t\t\t}\n\t\t\twx->mac_table[i].state &= ~(WX_MAC_STATE_MODIFIED);\n\t\t}\n\t}\n}\n\n \nvoid wx_mac_set_default_filter(struct wx *wx, u8 *addr)\n{\n\tmemcpy(&wx->mac_table[0].addr, addr, ETH_ALEN);\n\twx->mac_table[0].pools = 1ULL;\n\twx->mac_table[0].state = (WX_MAC_STATE_DEFAULT | WX_MAC_STATE_IN_USE);\n\twx_set_rar(wx, 0, wx->mac_table[0].addr,\n\t\t   wx->mac_table[0].pools,\n\t\t   WX_PSR_MAC_SWC_AD_H_AV);\n}\nEXPORT_SYMBOL(wx_mac_set_default_filter);\n\nvoid wx_flush_sw_mac_table(struct wx *wx)\n{\n\tu32 i;\n\n\tfor (i = 0; i < wx->mac.num_rar_entries; i++) {\n\t\tif (!(wx->mac_table[i].state & WX_MAC_STATE_IN_USE))\n\t\t\tcontinue;\n\n\t\twx->mac_table[i].state |= WX_MAC_STATE_MODIFIED;\n\t\twx->mac_table[i].state &= ~WX_MAC_STATE_IN_USE;\n\t\tmemset(wx->mac_table[i].addr, 0, ETH_ALEN);\n\t\twx->mac_table[i].pools = 0;\n\t}\n\twx_sync_mac_table(wx);\n}\nEXPORT_SYMBOL(wx_flush_sw_mac_table);\n\nstatic int wx_add_mac_filter(struct wx *wx, u8 *addr, u16 pool)\n{\n\tu32 i;\n\n\tif (is_zero_ether_addr(addr))\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < wx->mac.num_rar_entries; i++) {\n\t\tif (wx->mac_table[i].state & WX_MAC_STATE_IN_USE) {\n\t\t\tif (ether_addr_equal(addr, wx->mac_table[i].addr)) {\n\t\t\t\tif (wx->mac_table[i].pools != (1ULL << pool)) {\n\t\t\t\t\tmemcpy(wx->mac_table[i].addr, addr, ETH_ALEN);\n\t\t\t\t\twx->mac_table[i].pools |= (1ULL << pool);\n\t\t\t\t\twx_sync_mac_table(wx);\n\t\t\t\t\treturn i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (wx->mac_table[i].state & WX_MAC_STATE_IN_USE)\n\t\t\tcontinue;\n\t\twx->mac_table[i].state |= (WX_MAC_STATE_MODIFIED |\n\t\t\t\t\t   WX_MAC_STATE_IN_USE);\n\t\tmemcpy(wx->mac_table[i].addr, addr, ETH_ALEN);\n\t\twx->mac_table[i].pools |= (1ULL << pool);\n\t\twx_sync_mac_table(wx);\n\t\treturn i;\n\t}\n\treturn -ENOMEM;\n}\n\nstatic int wx_del_mac_filter(struct wx *wx, u8 *addr, u16 pool)\n{\n\tu32 i;\n\n\tif (is_zero_ether_addr(addr))\n\t\treturn -EINVAL;\n\n\t \n\tfor (i = 0; i < wx->mac.num_rar_entries; i++) {\n\t\tif (!ether_addr_equal(addr, wx->mac_table[i].addr))\n\t\t\tcontinue;\n\n\t\twx->mac_table[i].state |= WX_MAC_STATE_MODIFIED;\n\t\twx->mac_table[i].pools &= ~(1ULL << pool);\n\t\tif (!wx->mac_table[i].pools) {\n\t\t\twx->mac_table[i].state &= ~WX_MAC_STATE_IN_USE;\n\t\t\tmemset(wx->mac_table[i].addr, 0, ETH_ALEN);\n\t\t}\n\t\twx_sync_mac_table(wx);\n\t\treturn 0;\n\t}\n\treturn -ENOMEM;\n}\n\nstatic int wx_available_rars(struct wx *wx)\n{\n\tu32 i, count = 0;\n\n\tfor (i = 0; i < wx->mac.num_rar_entries; i++) {\n\t\tif (wx->mac_table[i].state == 0)\n\t\t\tcount++;\n\t}\n\n\treturn count;\n}\n\n \nstatic int wx_write_uc_addr_list(struct net_device *netdev, int pool)\n{\n\tstruct wx *wx = netdev_priv(netdev);\n\tint count = 0;\n\n\t \n\tif (netdev_uc_count(netdev) > wx_available_rars(wx))\n\t\treturn -ENOMEM;\n\n\tif (!netdev_uc_empty(netdev)) {\n\t\tstruct netdev_hw_addr *ha;\n\n\t\tnetdev_for_each_uc_addr(ha, netdev) {\n\t\t\twx_del_mac_filter(wx, ha->addr, pool);\n\t\t\twx_add_mac_filter(wx, ha->addr, pool);\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}\n\n \nstatic u32 wx_mta_vector(struct wx *wx, u8 *mc_addr)\n{\n\tu32 vector = 0;\n\n\tswitch (wx->mac.mc_filter_type) {\n\tcase 0:    \n\t\tvector = ((mc_addr[4] >> 4) | (((u16)mc_addr[5]) << 4));\n\t\tbreak;\n\tcase 1:    \n\t\tvector = ((mc_addr[4] >> 3) | (((u16)mc_addr[5]) << 5));\n\t\tbreak;\n\tcase 2:    \n\t\tvector = ((mc_addr[4] >> 2) | (((u16)mc_addr[5]) << 6));\n\t\tbreak;\n\tcase 3:    \n\t\tvector = ((mc_addr[4]) | (((u16)mc_addr[5]) << 8));\n\t\tbreak;\n\tdefault:   \n\t\twx_err(wx, \"MC filter type param set incorrectly\\n\");\n\t\tbreak;\n\t}\n\n\t \n\tvector &= 0xFFF;\n\treturn vector;\n}\n\n \nstatic void wx_set_mta(struct wx *wx, u8 *mc_addr)\n{\n\tu32 vector, vector_bit, vector_reg;\n\n\twx->addr_ctrl.mta_in_use++;\n\n\tvector = wx_mta_vector(wx, mc_addr);\n\twx_dbg(wx, \" bit-vector = 0x%03X\\n\", vector);\n\n\t \n\tvector_reg = (vector >> 5) & 0x7F;\n\tvector_bit = vector & 0x1F;\n\twx->mac.mta_shadow[vector_reg] |= (1 << vector_bit);\n}\n\n \nstatic void wx_update_mc_addr_list(struct wx *wx, struct net_device *netdev)\n{\n\tstruct netdev_hw_addr *ha;\n\tu32 i, psrctl;\n\n\t \n\twx->addr_ctrl.num_mc_addrs = netdev_mc_count(netdev);\n\twx->addr_ctrl.mta_in_use = 0;\n\n\t \n\twx_dbg(wx, \" Clearing MTA\\n\");\n\tmemset(&wx->mac.mta_shadow, 0, sizeof(wx->mac.mta_shadow));\n\n\t \n\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\twx_dbg(wx, \" Adding the multicast addresses:\\n\");\n\t\twx_set_mta(wx, ha->addr);\n\t}\n\n\t \n\tfor (i = 0; i < wx->mac.mcft_size; i++)\n\t\twr32a(wx, WX_PSR_MC_TBL(0), i,\n\t\t      wx->mac.mta_shadow[i]);\n\n\tif (wx->addr_ctrl.mta_in_use > 0) {\n\t\tpsrctl = rd32(wx, WX_PSR_CTL);\n\t\tpsrctl &= ~(WX_PSR_CTL_MO | WX_PSR_CTL_MFE);\n\t\tpsrctl |= WX_PSR_CTL_MFE |\n\t\t\t  (wx->mac.mc_filter_type << WX_PSR_CTL_MO_SHIFT);\n\t\twr32(wx, WX_PSR_CTL, psrctl);\n\t}\n\n\twx_dbg(wx, \"Update mc addr list Complete\\n\");\n}\n\n \nstatic int wx_write_mc_addr_list(struct net_device *netdev)\n{\n\tstruct wx *wx = netdev_priv(netdev);\n\n\tif (!netif_running(netdev))\n\t\treturn 0;\n\n\twx_update_mc_addr_list(wx, netdev);\n\n\treturn netdev_mc_count(netdev);\n}\n\n \nint wx_set_mac(struct net_device *netdev, void *p)\n{\n\tstruct wx *wx = netdev_priv(netdev);\n\tstruct sockaddr *addr = p;\n\tint retval;\n\n\tretval = eth_prepare_mac_addr_change(netdev, addr);\n\tif (retval)\n\t\treturn retval;\n\n\twx_del_mac_filter(wx, wx->mac.addr, 0);\n\teth_hw_addr_set(netdev, addr->sa_data);\n\tmemcpy(wx->mac.addr, addr->sa_data, netdev->addr_len);\n\n\twx_mac_set_default_filter(wx, wx->mac.addr);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(wx_set_mac);\n\nvoid wx_disable_rx(struct wx *wx)\n{\n\tu32 pfdtxgswc;\n\tu32 rxctrl;\n\n\trxctrl = rd32(wx, WX_RDB_PB_CTL);\n\tif (rxctrl & WX_RDB_PB_CTL_RXEN) {\n\t\tpfdtxgswc = rd32(wx, WX_PSR_CTL);\n\t\tif (pfdtxgswc & WX_PSR_CTL_SW_EN) {\n\t\t\tpfdtxgswc &= ~WX_PSR_CTL_SW_EN;\n\t\t\twr32(wx, WX_PSR_CTL, pfdtxgswc);\n\t\t\twx->mac.set_lben = true;\n\t\t} else {\n\t\t\twx->mac.set_lben = false;\n\t\t}\n\t\trxctrl &= ~WX_RDB_PB_CTL_RXEN;\n\t\twr32(wx, WX_RDB_PB_CTL, rxctrl);\n\n\t\tif (!(((wx->subsystem_device_id & WX_NCSI_MASK) == WX_NCSI_SUP) ||\n\t\t      ((wx->subsystem_device_id & WX_WOL_MASK) == WX_WOL_SUP))) {\n\t\t\t \n\t\t\twr32m(wx, WX_MAC_RX_CFG,\n\t\t\t      WX_MAC_RX_CFG_RE, 0);\n\t\t}\n\t}\n}\nEXPORT_SYMBOL(wx_disable_rx);\n\nstatic void wx_enable_rx(struct wx *wx)\n{\n\tu32 psrctl;\n\n\t \n\twr32m(wx, WX_MAC_RX_CFG,\n\t      WX_MAC_RX_CFG_RE, WX_MAC_RX_CFG_RE);\n\n\twr32m(wx, WX_RDB_PB_CTL,\n\t      WX_RDB_PB_CTL_RXEN, WX_RDB_PB_CTL_RXEN);\n\n\tif (wx->mac.set_lben) {\n\t\tpsrctl = rd32(wx, WX_PSR_CTL);\n\t\tpsrctl |= WX_PSR_CTL_SW_EN;\n\t\twr32(wx, WX_PSR_CTL, psrctl);\n\t\twx->mac.set_lben = false;\n\t}\n}\n\n \nstatic void wx_set_rxpba(struct wx *wx)\n{\n\tu32 rxpktsize, txpktsize, txpbthresh;\n\n\trxpktsize = wx->mac.rx_pb_size << WX_RDB_PB_SZ_SHIFT;\n\twr32(wx, WX_RDB_PB_SZ(0), rxpktsize);\n\n\t \n\ttxpktsize = wx->mac.tx_pb_size;\n\ttxpbthresh = (txpktsize / 1024) - WX_TXPKT_SIZE_MAX;\n\twr32(wx, WX_TDB_PB_SZ(0), txpktsize);\n\twr32(wx, WX_TDM_PB_THRE(0), txpbthresh);\n}\n\nstatic void wx_configure_port(struct wx *wx)\n{\n\tu32 value, i;\n\n\tvalue = WX_CFG_PORT_CTL_D_VLAN | WX_CFG_PORT_CTL_QINQ;\n\twr32m(wx, WX_CFG_PORT_CTL,\n\t      WX_CFG_PORT_CTL_D_VLAN |\n\t      WX_CFG_PORT_CTL_QINQ,\n\t      value);\n\n\twr32(wx, WX_CFG_TAG_TPID(0),\n\t     ETH_P_8021Q | ETH_P_8021AD << 16);\n\twx->tpid[0] = ETH_P_8021Q;\n\twx->tpid[1] = ETH_P_8021AD;\n\tfor (i = 1; i < 4; i++)\n\t\twr32(wx, WX_CFG_TAG_TPID(i),\n\t\t     ETH_P_8021Q | ETH_P_8021Q << 16);\n\tfor (i = 2; i < 8; i++)\n\t\twx->tpid[i] = ETH_P_8021Q;\n}\n\n \nstatic int wx_disable_sec_rx_path(struct wx *wx)\n{\n\tu32 secrx;\n\n\twr32m(wx, WX_RSC_CTL,\n\t      WX_RSC_CTL_RX_DIS, WX_RSC_CTL_RX_DIS);\n\n\treturn read_poll_timeout(rd32, secrx, secrx & WX_RSC_ST_RSEC_RDY,\n\t\t\t\t 1000, 40000, false, wx, WX_RSC_ST);\n}\n\n \nstatic void wx_enable_sec_rx_path(struct wx *wx)\n{\n\twr32m(wx, WX_RSC_CTL, WX_RSC_CTL_RX_DIS, 0);\n\tWX_WRITE_FLUSH(wx);\n}\n\nstatic void wx_vlan_strip_control(struct wx *wx, bool enable)\n{\n\tint i, j;\n\n\tfor (i = 0; i < wx->num_rx_queues; i++) {\n\t\tstruct wx_ring *ring = wx->rx_ring[i];\n\n\t\tj = ring->reg_idx;\n\t\twr32m(wx, WX_PX_RR_CFG(j), WX_PX_RR_CFG_VLAN,\n\t\t      enable ? WX_PX_RR_CFG_VLAN : 0);\n\t}\n}\n\nvoid wx_set_rx_mode(struct net_device *netdev)\n{\n\tstruct wx *wx = netdev_priv(netdev);\n\tnetdev_features_t features;\n\tu32 fctrl, vmolr, vlnctrl;\n\tint count;\n\n\tfeatures = netdev->features;\n\n\t \n\tfctrl = rd32(wx, WX_PSR_CTL);\n\tfctrl &= ~(WX_PSR_CTL_UPE | WX_PSR_CTL_MPE);\n\tvmolr = rd32(wx, WX_PSR_VM_L2CTL(0));\n\tvmolr &= ~(WX_PSR_VM_L2CTL_UPE |\n\t\t   WX_PSR_VM_L2CTL_MPE |\n\t\t   WX_PSR_VM_L2CTL_ROPE |\n\t\t   WX_PSR_VM_L2CTL_ROMPE);\n\tvlnctrl = rd32(wx, WX_PSR_VLAN_CTL);\n\tvlnctrl &= ~(WX_PSR_VLAN_CTL_VFE | WX_PSR_VLAN_CTL_CFIEN);\n\n\t \n\tfctrl |= WX_PSR_CTL_BAM | WX_PSR_CTL_MFE;\n\tvmolr |= WX_PSR_VM_L2CTL_BAM |\n\t\t WX_PSR_VM_L2CTL_AUPE |\n\t\t WX_PSR_VM_L2CTL_VACC;\n\tvlnctrl |= WX_PSR_VLAN_CTL_VFE;\n\n\twx->addr_ctrl.user_set_promisc = false;\n\tif (netdev->flags & IFF_PROMISC) {\n\t\twx->addr_ctrl.user_set_promisc = true;\n\t\tfctrl |= WX_PSR_CTL_UPE | WX_PSR_CTL_MPE;\n\t\t \n\t\tvmolr |= WX_PSR_VM_L2CTL_MPE;\n\t\tvlnctrl &= ~WX_PSR_VLAN_CTL_VFE;\n\t}\n\n\tif (netdev->flags & IFF_ALLMULTI) {\n\t\tfctrl |= WX_PSR_CTL_MPE;\n\t\tvmolr |= WX_PSR_VM_L2CTL_MPE;\n\t}\n\n\tif (netdev->features & NETIF_F_RXALL) {\n\t\tvmolr |= (WX_PSR_VM_L2CTL_UPE | WX_PSR_VM_L2CTL_MPE);\n\t\tvlnctrl &= ~WX_PSR_VLAN_CTL_VFE;\n\t\t \n\t\twr32m(wx, WX_RSC_CTL,\n\t\t      WX_RSC_CTL_SAVE_MAC_ERR,\n\t\t      WX_RSC_CTL_SAVE_MAC_ERR);\n\t} else {\n\t\tvmolr |= WX_PSR_VM_L2CTL_ROPE | WX_PSR_VM_L2CTL_ROMPE;\n\t}\n\n\t \n\tcount = wx_write_uc_addr_list(netdev, 0);\n\tif (count < 0) {\n\t\tvmolr &= ~WX_PSR_VM_L2CTL_ROPE;\n\t\tvmolr |= WX_PSR_VM_L2CTL_UPE;\n\t}\n\n\t \n\tcount = wx_write_mc_addr_list(netdev);\n\tif (count < 0) {\n\t\tvmolr &= ~WX_PSR_VM_L2CTL_ROMPE;\n\t\tvmolr |= WX_PSR_VM_L2CTL_MPE;\n\t}\n\n\twr32(wx, WX_PSR_VLAN_CTL, vlnctrl);\n\twr32(wx, WX_PSR_CTL, fctrl);\n\twr32(wx, WX_PSR_VM_L2CTL(0), vmolr);\n\n\tif ((features & NETIF_F_HW_VLAN_CTAG_RX) &&\n\t    (features & NETIF_F_HW_VLAN_STAG_RX))\n\t\twx_vlan_strip_control(wx, true);\n\telse\n\t\twx_vlan_strip_control(wx, false);\n\n}\nEXPORT_SYMBOL(wx_set_rx_mode);\n\nstatic void wx_set_rx_buffer_len(struct wx *wx)\n{\n\tstruct net_device *netdev = wx->netdev;\n\tu32 mhadd, max_frame;\n\n\tmax_frame = netdev->mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\n\t \n\tif (max_frame < (ETH_FRAME_LEN + ETH_FCS_LEN))\n\t\tmax_frame = (ETH_FRAME_LEN + ETH_FCS_LEN);\n\n\tmhadd = rd32(wx, WX_PSR_MAX_SZ);\n\tif (max_frame != mhadd)\n\t\twr32(wx, WX_PSR_MAX_SZ, max_frame);\n}\n\n \nint wx_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct wx *wx = netdev_priv(netdev);\n\n\tnetdev->mtu = new_mtu;\n\twx_set_rx_buffer_len(wx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(wx_change_mtu);\n\n \nvoid wx_disable_rx_queue(struct wx *wx, struct wx_ring *ring)\n{\n\tu8 reg_idx = ring->reg_idx;\n\tu32 rxdctl;\n\tint ret;\n\n\t \n\twr32m(wx, WX_PX_RR_CFG(reg_idx),\n\t      WX_PX_RR_CFG_RR_EN, 0);\n\n\t \n\tret = read_poll_timeout(rd32, rxdctl, !(rxdctl & WX_PX_RR_CFG_RR_EN),\n\t\t\t\t10, 100, true, wx, WX_PX_RR_CFG(reg_idx));\n\n\tif (ret == -ETIMEDOUT) {\n\t\t \n\t\twx_err(wx,\n\t\t       \"RRCFG.EN on Rx queue %d not cleared within the polling period\\n\",\n\t\t       reg_idx);\n\t}\n}\nEXPORT_SYMBOL(wx_disable_rx_queue);\n\nstatic void wx_enable_rx_queue(struct wx *wx, struct wx_ring *ring)\n{\n\tu8 reg_idx = ring->reg_idx;\n\tu32 rxdctl;\n\tint ret;\n\n\tret = read_poll_timeout(rd32, rxdctl, rxdctl & WX_PX_RR_CFG_RR_EN,\n\t\t\t\t1000, 10000, true, wx, WX_PX_RR_CFG(reg_idx));\n\n\tif (ret == -ETIMEDOUT) {\n\t\t \n\t\twx_err(wx,\n\t\t       \"RRCFG.EN on Rx queue %d not set within the polling period\\n\",\n\t\t       reg_idx);\n\t}\n}\n\nstatic void wx_configure_srrctl(struct wx *wx,\n\t\t\t\tstruct wx_ring *rx_ring)\n{\n\tu16 reg_idx = rx_ring->reg_idx;\n\tu32 srrctl;\n\n\tsrrctl = rd32(wx, WX_PX_RR_CFG(reg_idx));\n\tsrrctl &= ~(WX_PX_RR_CFG_RR_HDR_SZ |\n\t\t    WX_PX_RR_CFG_RR_BUF_SZ |\n\t\t    WX_PX_RR_CFG_SPLIT_MODE);\n\t \n\tsrrctl |= WX_RXBUFFER_256 << WX_PX_RR_CFG_BHDRSIZE_SHIFT;\n\n\t \n\tsrrctl |= WX_RX_BUFSZ >> WX_PX_RR_CFG_BSIZEPKT_SHIFT;\n\n\twr32(wx, WX_PX_RR_CFG(reg_idx), srrctl);\n}\n\nstatic void wx_configure_tx_ring(struct wx *wx,\n\t\t\t\t struct wx_ring *ring)\n{\n\tu32 txdctl = WX_PX_TR_CFG_ENABLE;\n\tu8 reg_idx = ring->reg_idx;\n\tu64 tdba = ring->dma;\n\tint ret;\n\n\t \n\twr32(wx, WX_PX_TR_CFG(reg_idx), WX_PX_TR_CFG_SWFLSH);\n\tWX_WRITE_FLUSH(wx);\n\n\twr32(wx, WX_PX_TR_BAL(reg_idx), tdba & DMA_BIT_MASK(32));\n\twr32(wx, WX_PX_TR_BAH(reg_idx), upper_32_bits(tdba));\n\n\t \n\twr32(wx, WX_PX_TR_RP(reg_idx), 0);\n\twr32(wx, WX_PX_TR_WP(reg_idx), 0);\n\tring->tail = wx->hw_addr + WX_PX_TR_WP(reg_idx);\n\n\tif (ring->count < WX_MAX_TXD)\n\t\ttxdctl |= ring->count / 128 << WX_PX_TR_CFG_TR_SIZE_SHIFT;\n\ttxdctl |= 0x20 << WX_PX_TR_CFG_WTHRESH_SHIFT;\n\n\t \n\tmemset(ring->tx_buffer_info, 0,\n\t       sizeof(struct wx_tx_buffer) * ring->count);\n\n\t \n\twr32(wx, WX_PX_TR_CFG(reg_idx), txdctl);\n\n\t \n\tret = read_poll_timeout(rd32, txdctl, txdctl & WX_PX_TR_CFG_ENABLE,\n\t\t\t\t1000, 10000, true, wx, WX_PX_TR_CFG(reg_idx));\n\tif (ret == -ETIMEDOUT)\n\t\twx_err(wx, \"Could not enable Tx Queue %d\\n\", reg_idx);\n}\n\nstatic void wx_configure_rx_ring(struct wx *wx,\n\t\t\t\t struct wx_ring *ring)\n{\n\tu16 reg_idx = ring->reg_idx;\n\tunion wx_rx_desc *rx_desc;\n\tu64 rdba = ring->dma;\n\tu32 rxdctl;\n\n\t \n\trxdctl = rd32(wx, WX_PX_RR_CFG(reg_idx));\n\twx_disable_rx_queue(wx, ring);\n\n\twr32(wx, WX_PX_RR_BAL(reg_idx), rdba & DMA_BIT_MASK(32));\n\twr32(wx, WX_PX_RR_BAH(reg_idx), upper_32_bits(rdba));\n\n\tif (ring->count == WX_MAX_RXD)\n\t\trxdctl |= 0 << WX_PX_RR_CFG_RR_SIZE_SHIFT;\n\telse\n\t\trxdctl |= (ring->count / 128) << WX_PX_RR_CFG_RR_SIZE_SHIFT;\n\n\trxdctl |= 0x1 << WX_PX_RR_CFG_RR_THER_SHIFT;\n\twr32(wx, WX_PX_RR_CFG(reg_idx), rxdctl);\n\n\t \n\twr32(wx, WX_PX_RR_RP(reg_idx), 0);\n\twr32(wx, WX_PX_RR_WP(reg_idx), 0);\n\tring->tail = wx->hw_addr + WX_PX_RR_WP(reg_idx);\n\n\twx_configure_srrctl(wx, ring);\n\n\t \n\tmemset(ring->rx_buffer_info, 0,\n\t       sizeof(struct wx_rx_buffer) * ring->count);\n\n\t \n\trx_desc = WX_RX_DESC(ring, 0);\n\trx_desc->wb.upper.length = 0;\n\n\t \n\twr32m(wx, WX_PX_RR_CFG(reg_idx),\n\t      WX_PX_RR_CFG_RR_EN, WX_PX_RR_CFG_RR_EN);\n\n\twx_enable_rx_queue(wx, ring);\n\twx_alloc_rx_buffers(ring, wx_desc_unused(ring));\n}\n\n \nstatic void wx_configure_tx(struct wx *wx)\n{\n\tu32 i;\n\n\t \n\twr32m(wx, WX_TDM_CTL,\n\t      WX_TDM_CTL_TE, WX_TDM_CTL_TE);\n\n\t \n\tfor (i = 0; i < wx->num_tx_queues; i++)\n\t\twx_configure_tx_ring(wx, wx->tx_ring[i]);\n\n\twr32m(wx, WX_TSC_BUF_AE, WX_TSC_BUF_AE_THR, 0x10);\n\n\tif (wx->mac.type == wx_mac_em)\n\t\twr32m(wx, WX_TSC_CTL, WX_TSC_CTL_TX_DIS | WX_TSC_CTL_TSEC_DIS, 0x1);\n\n\t \n\twr32m(wx, WX_MAC_TX_CFG,\n\t      WX_MAC_TX_CFG_TE, WX_MAC_TX_CFG_TE);\n}\n\nstatic void wx_restore_vlan(struct wx *wx)\n{\n\tu16 vid = 1;\n\n\twx_vlan_rx_add_vid(wx->netdev, htons(ETH_P_8021Q), 0);\n\n\tfor_each_set_bit_from(vid, wx->active_vlans, VLAN_N_VID)\n\t\twx_vlan_rx_add_vid(wx->netdev, htons(ETH_P_8021Q), vid);\n}\n\n \nvoid wx_configure_rx(struct wx *wx)\n{\n\tu32 psrtype, i;\n\tint ret;\n\n\twx_disable_rx(wx);\n\n\tpsrtype = WX_RDB_PL_CFG_L4HDR |\n\t\t  WX_RDB_PL_CFG_L3HDR |\n\t\t  WX_RDB_PL_CFG_L2HDR |\n\t\t  WX_RDB_PL_CFG_TUN_TUNHDR;\n\twr32(wx, WX_RDB_PL_CFG(0), psrtype);\n\n\t \n\twr32m(wx, WX_RSC_CTL, WX_RSC_CTL_CRC_STRIP, WX_RSC_CTL_CRC_STRIP);\n\n\tif (wx->mac.type == wx_mac_sp) {\n\t\tu32 psrctl;\n\n\t\t \n\t\tpsrctl = rd32(wx, WX_PSR_CTL);\n\t\tpsrctl |= WX_PSR_CTL_RSC_ACK;  \n\t\tpsrctl |= WX_PSR_CTL_RSC_DIS;\n\t\twr32(wx, WX_PSR_CTL, psrctl);\n\t}\n\n\t \n\twx_set_rx_buffer_len(wx);\n\n\t \n\tfor (i = 0; i < wx->num_rx_queues; i++)\n\t\twx_configure_rx_ring(wx, wx->rx_ring[i]);\n\n\t \n\tret = wx_disable_sec_rx_path(wx);\n\tif (ret < 0)\n\t\twx_err(wx, \"The register status is abnormal, please check device.\");\n\n\twx_enable_rx(wx);\n\twx_enable_sec_rx_path(wx);\n}\nEXPORT_SYMBOL(wx_configure_rx);\n\nstatic void wx_configure_isb(struct wx *wx)\n{\n\t \n\twr32(wx, WX_PX_ISB_ADDR_L, wx->isb_dma & DMA_BIT_MASK(32));\n\tif (IS_ENABLED(CONFIG_ARCH_DMA_ADDR_T_64BIT))\n\t\twr32(wx, WX_PX_ISB_ADDR_H, upper_32_bits(wx->isb_dma));\n}\n\nvoid wx_configure(struct wx *wx)\n{\n\twx_set_rxpba(wx);\n\twx_configure_port(wx);\n\n\twx_set_rx_mode(wx->netdev);\n\twx_restore_vlan(wx);\n\twx_enable_sec_rx_path(wx);\n\n\twx_configure_tx(wx);\n\twx_configure_rx(wx);\n\twx_configure_isb(wx);\n}\nEXPORT_SYMBOL(wx_configure);\n\n \nint wx_disable_pcie_master(struct wx *wx)\n{\n\tint status = 0;\n\tu32 val;\n\n\t \n\tpci_clear_master(wx->pdev);\n\n\t \n\tif (!(rd32(wx, WX_PX_TRANSACTION_PENDING)))\n\t\treturn 0;\n\n\t \n\tstatus = read_poll_timeout(rd32, val, !val, 100, WX_PCI_MASTER_DISABLE_TIMEOUT,\n\t\t\t\t   false, wx, WX_PX_TRANSACTION_PENDING);\n\tif (status < 0)\n\t\twx_err(wx, \"PCIe transaction pending bit did not clear.\\n\");\n\n\treturn status;\n}\nEXPORT_SYMBOL(wx_disable_pcie_master);\n\n \nint wx_stop_adapter(struct wx *wx)\n{\n\tu16 i;\n\n\t \n\twx->adapter_stopped = true;\n\n\t \n\twx_disable_rx(wx);\n\n\t \n\twx_intr_disable(wx, WX_INTR_ALL);\n\n\t \n\twr32(wx, WX_PX_MISC_IC, 0xffffffff);\n\twr32(wx, WX_BME_CTL, 0x3);\n\n\t \n\tfor (i = 0; i < wx->mac.max_tx_queues; i++) {\n\t\twr32m(wx, WX_PX_TR_CFG(i),\n\t\t      WX_PX_TR_CFG_SWFLSH | WX_PX_TR_CFG_ENABLE,\n\t\t      WX_PX_TR_CFG_SWFLSH);\n\t}\n\n\t \n\tfor (i = 0; i < wx->mac.max_rx_queues; i++) {\n\t\twr32m(wx, WX_PX_RR_CFG(i),\n\t\t      WX_PX_RR_CFG_RR_EN, 0);\n\t}\n\n\t \n\tWX_WRITE_FLUSH(wx);\n\n\t \n\treturn wx_disable_pcie_master(wx);\n}\nEXPORT_SYMBOL(wx_stop_adapter);\n\nvoid wx_reset_misc(struct wx *wx)\n{\n\tint i;\n\n\t \n\twr32m(wx, WX_MAC_RX_CFG, WX_MAC_RX_CFG_JE, WX_MAC_RX_CFG_JE);\n\n\t \n\twr32m(wx, WX_MMC_CONTROL,\n\t      WX_MMC_CONTROL_RSTONRD, WX_MMC_CONTROL_RSTONRD);\n\n\twr32m(wx, WX_MAC_RX_FLOW_CTRL,\n\t      WX_MAC_RX_FLOW_CTRL_RFE, WX_MAC_RX_FLOW_CTRL_RFE);\n\n\twr32(wx, WX_MAC_PKT_FLT, WX_MAC_PKT_FLT_PR);\n\n\twr32m(wx, WX_MIS_RST_ST,\n\t      WX_MIS_RST_ST_RST_INIT, 0x1E00);\n\n\t \n\twr32(wx, WX_PSR_MNG_FLEX_SEL, 0);\n\tfor (i = 0; i < 16; i++) {\n\t\twr32(wx, WX_PSR_MNG_FLEX_DW_L(i), 0);\n\t\twr32(wx, WX_PSR_MNG_FLEX_DW_H(i), 0);\n\t\twr32(wx, WX_PSR_MNG_FLEX_MSK(i), 0);\n\t}\n\twr32(wx, WX_PSR_LAN_FLEX_SEL, 0);\n\tfor (i = 0; i < 16; i++) {\n\t\twr32(wx, WX_PSR_LAN_FLEX_DW_L(i), 0);\n\t\twr32(wx, WX_PSR_LAN_FLEX_DW_H(i), 0);\n\t\twr32(wx, WX_PSR_LAN_FLEX_MSK(i), 0);\n\t}\n\n\t \n\twr32(wx, WX_RDB_PFCMACDAL, 0xC2000001);\n\twr32(wx, WX_RDB_PFCMACDAH, 0x0180);\n}\nEXPORT_SYMBOL(wx_reset_misc);\n\n \nint wx_get_pcie_msix_counts(struct wx *wx, u16 *msix_count, u16 max_msix_count)\n{\n\tstruct pci_dev *pdev = wx->pdev;\n\tstruct device *dev = &pdev->dev;\n\tint pos;\n\n\t*msix_count = 1;\n\tpos = pci_find_capability(pdev, PCI_CAP_ID_MSIX);\n\tif (!pos) {\n\t\tdev_err(dev, \"Unable to find MSI-X Capabilities\\n\");\n\t\treturn -EINVAL;\n\t}\n\tpci_read_config_word(pdev,\n\t\t\t     pos + PCI_MSIX_FLAGS,\n\t\t\t     msix_count);\n\t*msix_count &= WX_PCIE_MSIX_TBL_SZ_MASK;\n\t \n\t*msix_count += 1;\n\n\tif (*msix_count > max_msix_count)\n\t\t*msix_count = max_msix_count;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(wx_get_pcie_msix_counts);\n\nint wx_sw_init(struct wx *wx)\n{\n\tstruct pci_dev *pdev = wx->pdev;\n\tu32 ssid = 0;\n\tint err = 0;\n\n\twx->vendor_id = pdev->vendor;\n\twx->device_id = pdev->device;\n\twx->revision_id = pdev->revision;\n\twx->oem_svid = pdev->subsystem_vendor;\n\twx->oem_ssid = pdev->subsystem_device;\n\twx->bus.device = PCI_SLOT(pdev->devfn);\n\twx->bus.func = PCI_FUNC(pdev->devfn);\n\n\tif (wx->oem_svid == PCI_VENDOR_ID_WANGXUN) {\n\t\twx->subsystem_vendor_id = pdev->subsystem_vendor;\n\t\twx->subsystem_device_id = pdev->subsystem_device;\n\t} else {\n\t\terr = wx_flash_read_dword(wx, 0xfffdc, &ssid);\n\t\tif (err < 0) {\n\t\t\twx_err(wx, \"read of internal subsystem device id failed\\n\");\n\t\t\treturn err;\n\t\t}\n\n\t\twx->subsystem_device_id = swab16((u16)ssid);\n\t}\n\n\twx->mac_table = kcalloc(wx->mac.num_rar_entries,\n\t\t\t\tsizeof(struct wx_mac_addr),\n\t\t\t\tGFP_KERNEL);\n\tif (!wx->mac_table) {\n\t\twx_err(wx, \"mac_table allocation failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(wx_sw_init);\n\n \nstatic int wx_find_vlvf_slot(struct wx *wx, u32 vlan)\n{\n\tu32 bits = 0, first_empty_slot = 0;\n\tint regindex;\n\n\t \n\tif (vlan == 0)\n\t\treturn 0;\n\n\t \n\tfor (regindex = 1; regindex < WX_PSR_VLAN_SWC_ENTRIES; regindex++) {\n\t\twr32(wx, WX_PSR_VLAN_SWC_IDX, regindex);\n\t\tbits = rd32(wx, WX_PSR_VLAN_SWC);\n\t\tif (!bits && !(first_empty_slot))\n\t\t\tfirst_empty_slot = regindex;\n\t\telse if ((bits & 0x0FFF) == vlan)\n\t\t\tbreak;\n\t}\n\n\tif (regindex >= WX_PSR_VLAN_SWC_ENTRIES) {\n\t\tif (first_empty_slot)\n\t\t\tregindex = first_empty_slot;\n\t\telse\n\t\t\tregindex = -ENOMEM;\n\t}\n\n\treturn regindex;\n}\n\n \nstatic int wx_set_vlvf(struct wx *wx, u32 vlan, u32 vind, bool vlan_on,\n\t\t       bool *vfta_changed)\n{\n\tint vlvf_index;\n\tu32 vt, bits;\n\n\t \n\tvt = rd32(wx, WX_CFG_PORT_CTL);\n\tif (!(vt & WX_CFG_PORT_CTL_NUM_VT_MASK))\n\t\treturn 0;\n\n\tvlvf_index = wx_find_vlvf_slot(wx, vlan);\n\tif (vlvf_index < 0)\n\t\treturn vlvf_index;\n\n\twr32(wx, WX_PSR_VLAN_SWC_IDX, vlvf_index);\n\tif (vlan_on) {\n\t\t \n\t\tif (vind < 32) {\n\t\t\tbits = rd32(wx, WX_PSR_VLAN_SWC_VM_L);\n\t\t\tbits |= (1 << vind);\n\t\t\twr32(wx, WX_PSR_VLAN_SWC_VM_L, bits);\n\t\t} else {\n\t\t\tbits = rd32(wx, WX_PSR_VLAN_SWC_VM_H);\n\t\t\tbits |= (1 << (vind - 32));\n\t\t\twr32(wx, WX_PSR_VLAN_SWC_VM_H, bits);\n\t\t}\n\t} else {\n\t\t \n\t\tif (vind < 32) {\n\t\t\tbits = rd32(wx, WX_PSR_VLAN_SWC_VM_L);\n\t\t\tbits &= ~(1 << vind);\n\t\t\twr32(wx, WX_PSR_VLAN_SWC_VM_L, bits);\n\t\t\tbits |= rd32(wx, WX_PSR_VLAN_SWC_VM_H);\n\t\t} else {\n\t\t\tbits = rd32(wx, WX_PSR_VLAN_SWC_VM_H);\n\t\t\tbits &= ~(1 << (vind - 32));\n\t\t\twr32(wx, WX_PSR_VLAN_SWC_VM_H, bits);\n\t\t\tbits |= rd32(wx, WX_PSR_VLAN_SWC_VM_L);\n\t\t}\n\t}\n\n\tif (bits) {\n\t\twr32(wx, WX_PSR_VLAN_SWC, (WX_PSR_VLAN_SWC_VIEN | vlan));\n\t\tif (!vlan_on && vfta_changed)\n\t\t\t*vfta_changed = false;\n\t} else {\n\t\twr32(wx, WX_PSR_VLAN_SWC, 0);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int wx_set_vfta(struct wx *wx, u32 vlan, u32 vind, bool vlan_on)\n{\n\tu32 bitindex, vfta, targetbit;\n\tbool vfta_changed = false;\n\tint regindex, ret;\n\n\t \n\n\t \n\tregindex = (vlan >> 5) & 0x7F;\n\tbitindex = vlan & 0x1F;\n\ttargetbit = (1 << bitindex);\n\t \n\tvfta = wx->mac.vft_shadow[regindex];\n\tif (vlan_on) {\n\t\tif (!(vfta & targetbit)) {\n\t\t\tvfta |= targetbit;\n\t\t\tvfta_changed = true;\n\t\t}\n\t} else {\n\t\tif ((vfta & targetbit)) {\n\t\t\tvfta &= ~targetbit;\n\t\t\tvfta_changed = true;\n\t\t}\n\t}\n\t \n\tret = wx_set_vlvf(wx, vlan, vind, vlan_on, &vfta_changed);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tif (vfta_changed)\n\t\twr32(wx, WX_PSR_VLAN_TBL(regindex), vfta);\n\twx->mac.vft_shadow[regindex] = vfta;\n\n\treturn 0;\n}\n\n \nstatic void wx_clear_vfta(struct wx *wx)\n{\n\tu32 offset;\n\n\tfor (offset = 0; offset < wx->mac.vft_size; offset++) {\n\t\twr32(wx, WX_PSR_VLAN_TBL(offset), 0);\n\t\twx->mac.vft_shadow[offset] = 0;\n\t}\n\n\tfor (offset = 0; offset < WX_PSR_VLAN_SWC_ENTRIES; offset++) {\n\t\twr32(wx, WX_PSR_VLAN_SWC_IDX, offset);\n\t\twr32(wx, WX_PSR_VLAN_SWC, 0);\n\t\twr32(wx, WX_PSR_VLAN_SWC_VM_L, 0);\n\t\twr32(wx, WX_PSR_VLAN_SWC_VM_H, 0);\n\t}\n}\n\nint wx_vlan_rx_add_vid(struct net_device *netdev,\n\t\t       __be16 proto, u16 vid)\n{\n\tstruct wx *wx = netdev_priv(netdev);\n\n\t \n\twx_set_vfta(wx, vid, VMDQ_P(0), true);\n\tset_bit(vid, wx->active_vlans);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(wx_vlan_rx_add_vid);\n\nint wx_vlan_rx_kill_vid(struct net_device *netdev, __be16 proto, u16 vid)\n{\n\tstruct wx *wx = netdev_priv(netdev);\n\n\t \n\tif (vid)\n\t\twx_set_vfta(wx, vid, VMDQ_P(0), false);\n\tclear_bit(vid, wx->active_vlans);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(wx_vlan_rx_kill_vid);\n\n \nvoid wx_start_hw(struct wx *wx)\n{\n\tint i;\n\n\t \n\twx_clear_vfta(wx);\n\tWX_WRITE_FLUSH(wx);\n\t \n\tfor (i = 0; i < wx->mac.max_tx_queues; i++) {\n\t\twr32(wx, WX_TDM_RP_IDX, i);\n\t\twr32(wx, WX_TDM_RP_RATE, 0);\n\t}\n}\nEXPORT_SYMBOL(wx_start_hw);\n\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}