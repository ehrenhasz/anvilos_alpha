{
  "module_name": "chtls_cm.h",
  "hash_id": "cdba513b1fd0cfefb48062cbde14a78fc105eb918b69212072e50de0fbf7a718",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.h",
  "human_readable_source": " \n \n\n#ifndef __CHTLS_CM_H__\n#define __CHTLS_CM_H__\n\n \n \n#define TCB_ULP_TYPE_W    0\n#define TCB_ULP_TYPE_S    0\n#define TCB_ULP_TYPE_M    0xfULL\n#define TCB_ULP_TYPE_V(x) ((x) << TCB_ULP_TYPE_S)\n\n \n#define TCB_ULP_RAW_W    0\n#define TCB_ULP_RAW_S    4\n#define TCB_ULP_RAW_M    0xffULL\n#define TCB_ULP_RAW_V(x) ((x) << TCB_ULP_RAW_S)\n\n#define TF_TLS_KEY_SIZE_S    7\n#define TF_TLS_KEY_SIZE_V(x) ((x) << TF_TLS_KEY_SIZE_S)\n\n#define TF_TLS_CONTROL_S     2\n#define TF_TLS_CONTROL_V(x) ((x) << TF_TLS_CONTROL_S)\n\n#define TF_TLS_ACTIVE_S      1\n#define TF_TLS_ACTIVE_V(x) ((x) << TF_TLS_ACTIVE_S)\n\n#define TF_TLS_ENABLE_S      0\n#define TF_TLS_ENABLE_V(x) ((x) << TF_TLS_ENABLE_S)\n\n#define TF_RX_QUIESCE_S    15\n#define TF_RX_QUIESCE_V(x) ((x) << TF_RX_QUIESCE_S)\n\n \n#define MAX_RCV_WND ((1U << 27) - 1)\n#define MAX_MSS     65536\n\n \n#define MIN_RCV_WND (24 * 1024U)\n#define LOOPBACK(x)     (((x) & htonl(0xff000000)) == htonl(0x7f000000))\n\n \n#define TX_HEADER_LEN \\\n\t(sizeof(struct fw_ofld_tx_data_wr) + sizeof(struct sge_opaque_hdr))\n#define TX_TLSHDR_LEN \\\n\t(sizeof(struct fw_tlstx_data_wr) + sizeof(struct cpl_tx_tls_sfo) + \\\n\t sizeof(struct sge_opaque_hdr))\n#define TXDATA_SKB_LEN 128\n\nenum {\n\tCPL_TX_TLS_SFO_TYPE_CCS,\n\tCPL_TX_TLS_SFO_TYPE_ALERT,\n\tCPL_TX_TLS_SFO_TYPE_HANDSHAKE,\n\tCPL_TX_TLS_SFO_TYPE_DATA,\n\tCPL_TX_TLS_SFO_TYPE_HEARTBEAT,\n};\n\nenum {\n\tTLS_HDR_TYPE_CCS = 20,\n\tTLS_HDR_TYPE_ALERT,\n\tTLS_HDR_TYPE_HANDSHAKE,\n\tTLS_HDR_TYPE_RECORD,\n\tTLS_HDR_TYPE_HEARTBEAT,\n};\n\ntypedef void (*defer_handler_t)(struct chtls_dev *dev, struct sk_buff *skb);\nextern struct request_sock_ops chtls_rsk_ops;\nextern struct request_sock_ops chtls_rsk_opsv6;\n\nstruct deferred_skb_cb {\n\tdefer_handler_t handler;\n\tstruct chtls_dev *dev;\n};\n\n#define DEFERRED_SKB_CB(skb) ((struct deferred_skb_cb *)(skb)->cb)\n#define failover_flowc_wr_len offsetof(struct fw_flowc_wr, mnemval[3])\n#define WR_SKB_CB(skb) ((struct wr_skb_cb *)(skb)->cb)\n#define ACCEPT_QUEUE(sk) (&inet_csk(sk)->icsk_accept_queue.rskq_accept_head)\n\n#define SND_WSCALE(tp) ((tp)->rx_opt.snd_wscale)\n#define RCV_WSCALE(tp) ((tp)->rx_opt.rcv_wscale)\n#define USER_MSS(tp) ((tp)->rx_opt.user_mss)\n#define TS_RECENT_STAMP(tp) ((tp)->rx_opt.ts_recent_stamp)\n#define WSCALE_OK(tp) ((tp)->rx_opt.wscale_ok)\n#define TSTAMP_OK(tp) ((tp)->rx_opt.tstamp_ok)\n#define SACK_OK(tp) ((tp)->rx_opt.sack_ok)\n#define INC_ORPHAN_COUNT(sk) this_cpu_inc(*(sk)->sk_prot->orphan_count)\n\n \n#define skb_ulp_tls_inline(skb)      (ULP_SKB_CB(skb)->ulp.tls.ofld)\n#define skb_ulp_tls_iv_imm(skb)      (ULP_SKB_CB(skb)->ulp.tls.iv)\n\nvoid chtls_defer_reply(struct sk_buff *skb, struct chtls_dev *dev,\n\t\t       defer_handler_t handler);\n\n \nstatic inline unsigned int sk_in_state(const struct sock *sk,\n\t\t\t\t       unsigned int states)\n{\n\treturn states & (1 << sk->sk_state);\n}\n\nstatic void chtls_rsk_destructor(struct request_sock *req)\n{\n\t \n}\n\nstatic inline void chtls_init_rsk_ops(struct proto *chtls_tcp_prot,\n\t\t\t\t      struct request_sock_ops *chtls_tcp_ops,\n\t\t\t\t      struct proto *tcp_prot, int family)\n{\n\tmemset(chtls_tcp_ops, 0, sizeof(*chtls_tcp_ops));\n\tchtls_tcp_ops->family = family;\n\tchtls_tcp_ops->obj_size = sizeof(struct tcp_request_sock);\n\tchtls_tcp_ops->destructor = chtls_rsk_destructor;\n\tchtls_tcp_ops->slab = tcp_prot->rsk_prot->slab;\n\tchtls_tcp_prot->rsk_prot = chtls_tcp_ops;\n}\n\nstatic inline void chtls_reqsk_free(struct request_sock *req)\n{\n\tif (req->rsk_listener)\n\t\tsock_put(req->rsk_listener);\n\tkmem_cache_free(req->rsk_ops->slab, req);\n}\n\n#define DECLARE_TASK_FUNC(task, task_param) \\\n\t\tstatic void task(struct work_struct *task_param)\n\nstatic inline void sk_wakeup_sleepers(struct sock *sk, bool interruptable)\n{\n\tstruct socket_wq *wq;\n\n\trcu_read_lock();\n\twq = rcu_dereference(sk->sk_wq);\n\tif (skwq_has_sleeper(wq)) {\n\t\tif (interruptable)\n\t\t\twake_up_interruptible(sk_sleep(sk));\n\t\telse\n\t\t\twake_up_all(sk_sleep(sk));\n\t}\n\trcu_read_unlock();\n}\n\nstatic inline void chtls_set_req_port(struct request_sock *oreq,\n\t\t\t\t      __be16 source, __be16 dest)\n{\n\tinet_rsk(oreq)->ir_rmt_port = source;\n\tinet_rsk(oreq)->ir_num = ntohs(dest);\n}\n\nstatic inline void chtls_set_req_addr(struct request_sock *oreq,\n\t\t\t\t      __be32 local_ip, __be32 peer_ip)\n{\n\tinet_rsk(oreq)->ir_loc_addr = local_ip;\n\tinet_rsk(oreq)->ir_rmt_addr = peer_ip;\n}\n\nstatic inline void chtls_free_skb(struct sock *sk, struct sk_buff *skb)\n{\n\tskb_dst_set(skb, NULL);\n\t__skb_unlink(skb, &sk->sk_receive_queue);\n\t__kfree_skb(skb);\n}\n\nstatic inline void chtls_kfree_skb(struct sock *sk, struct sk_buff *skb)\n{\n\tskb_dst_set(skb, NULL);\n\t__skb_unlink(skb, &sk->sk_receive_queue);\n\tkfree_skb(skb);\n}\n\nstatic inline void chtls_reset_wr_list(struct chtls_sock *csk)\n{\n\tcsk->wr_skb_head = NULL;\n\tcsk->wr_skb_tail = NULL;\n}\n\nstatic inline void enqueue_wr(struct chtls_sock *csk, struct sk_buff *skb)\n{\n\tWR_SKB_CB(skb)->next_wr = NULL;\n\n\tskb_get(skb);\n\n\tif (!csk->wr_skb_head)\n\t\tcsk->wr_skb_head = skb;\n\telse\n\t\tWR_SKB_CB(csk->wr_skb_tail)->next_wr = skb;\n\tcsk->wr_skb_tail = skb;\n}\n\nstatic inline struct sk_buff *dequeue_wr(struct sock *sk)\n{\n\tstruct chtls_sock *csk = rcu_dereference_sk_user_data(sk);\n\tstruct sk_buff *skb = NULL;\n\n\tskb = csk->wr_skb_head;\n\n\tif (likely(skb)) {\n\t  \n\t\tcsk->wr_skb_head = WR_SKB_CB(skb)->next_wr;\n\t\tWR_SKB_CB(skb)->next_wr = NULL;\n\t}\n\treturn skb;\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}