{
  "module_name": "cxgb3_offload.c",
  "hash_id": "4c98e0b0ac29c9a38fde1e06eea347c18c46e12a584d1b3f265c90c25934c88d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/list.h>\n#include <linux/slab.h>\n#include <net/neighbour.h>\n#include <linux/notifier.h>\n#include <linux/atomic.h>\n#include <linux/proc_fs.h>\n#include <linux/if_vlan.h>\n#include <net/netevent.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n\n#include \"common.h\"\n#include \"regs.h\"\n#include \"cxgb3_ioctl.h\"\n#include \"cxgb3_ctl_defs.h\"\n#include \"cxgb3_defs.h\"\n#include \"l2t.h\"\n#include \"firmware_exports.h\"\n#include \"cxgb3_offload.h\"\n\nstatic LIST_HEAD(client_list);\nstatic LIST_HEAD(ofld_dev_list);\nstatic DEFINE_MUTEX(cxgb3_db_lock);\n\nstatic DEFINE_RWLOCK(adapter_list_lock);\nstatic LIST_HEAD(adapter_list);\n\nstatic const unsigned int MAX_ATIDS = 64 * 1024;\nstatic const unsigned int ATID_BASE = 0x10000;\n\nstatic void cxgb_neigh_update(struct neighbour *neigh);\nstatic void cxgb_redirect(struct dst_entry *old, struct dst_entry *new,\n\t\t\t  struct neighbour *neigh, const void *daddr);\n\nstatic inline int offload_activated(struct t3cdev *tdev)\n{\n\tconst struct adapter *adapter = tdev2adap(tdev);\n\n\treturn test_bit(OFFLOAD_DEVMAP_BIT, &adapter->open_device_map);\n}\n\n \nvoid cxgb3_register_client(struct cxgb3_client *client)\n{\n\tstruct t3cdev *tdev;\n\n\tmutex_lock(&cxgb3_db_lock);\n\tlist_add_tail(&client->client_list, &client_list);\n\n\tif (client->add) {\n\t\tlist_for_each_entry(tdev, &ofld_dev_list, ofld_dev_list) {\n\t\t\tif (offload_activated(tdev))\n\t\t\t\tclient->add(tdev);\n\t\t}\n\t}\n\tmutex_unlock(&cxgb3_db_lock);\n}\n\nEXPORT_SYMBOL(cxgb3_register_client);\n\n \nvoid cxgb3_unregister_client(struct cxgb3_client *client)\n{\n\tstruct t3cdev *tdev;\n\n\tmutex_lock(&cxgb3_db_lock);\n\tlist_del(&client->client_list);\n\n\tif (client->remove) {\n\t\tlist_for_each_entry(tdev, &ofld_dev_list, ofld_dev_list) {\n\t\t\tif (offload_activated(tdev))\n\t\t\t\tclient->remove(tdev);\n\t\t}\n\t}\n\tmutex_unlock(&cxgb3_db_lock);\n}\n\nEXPORT_SYMBOL(cxgb3_unregister_client);\n\n \nvoid cxgb3_add_clients(struct t3cdev *tdev)\n{\n\tstruct cxgb3_client *client;\n\n\tmutex_lock(&cxgb3_db_lock);\n\tlist_for_each_entry(client, &client_list, client_list) {\n\t\tif (client->add)\n\t\t\tclient->add(tdev);\n\t}\n\tmutex_unlock(&cxgb3_db_lock);\n}\n\n \nvoid cxgb3_remove_clients(struct t3cdev *tdev)\n{\n\tstruct cxgb3_client *client;\n\n\tmutex_lock(&cxgb3_db_lock);\n\tlist_for_each_entry(client, &client_list, client_list) {\n\t\tif (client->remove)\n\t\t\tclient->remove(tdev);\n\t}\n\tmutex_unlock(&cxgb3_db_lock);\n}\n\nvoid cxgb3_event_notify(struct t3cdev *tdev, u32 event, u32 port)\n{\n\tstruct cxgb3_client *client;\n\n\tmutex_lock(&cxgb3_db_lock);\n\tlist_for_each_entry(client, &client_list, client_list) {\n\t\tif (client->event_handler)\n\t\t\tclient->event_handler(tdev, event, port);\n\t}\n\tmutex_unlock(&cxgb3_db_lock);\n}\n\nstatic struct net_device *get_iff_from_mac(struct adapter *adapter,\n\t\t\t\t\t   const unsigned char *mac,\n\t\t\t\t\t   unsigned int vlan)\n{\n\tint i;\n\n\tfor_each_port(adapter, i) {\n\t\tstruct net_device *dev = adapter->port[i];\n\n\t\tif (ether_addr_equal(dev->dev_addr, mac)) {\n\t\t\trcu_read_lock();\n\t\t\tif (vlan && vlan != VLAN_VID_MASK) {\n\t\t\t\tdev = __vlan_find_dev_deep_rcu(dev, htons(ETH_P_8021Q), vlan);\n\t\t\t} else if (netif_is_bond_slave(dev)) {\n\t\t\t\tstruct net_device *upper_dev;\n\n\t\t\t\twhile ((upper_dev =\n\t\t\t\t\tnetdev_master_upper_dev_get_rcu(dev)))\n\t\t\t\t\tdev = upper_dev;\n\t\t\t}\n\t\t\trcu_read_unlock();\n\t\t\treturn dev;\n\t\t}\n\t}\n\treturn NULL;\n}\n\nstatic int cxgb_ulp_iscsi_ctl(struct adapter *adapter, unsigned int req,\n\t\t\t      void *data)\n{\n\tint i;\n\tint ret = 0;\n\tunsigned int val = 0;\n\tstruct ulp_iscsi_info *uiip = data;\n\n\tswitch (req) {\n\tcase ULP_ISCSI_GET_PARAMS:\n\t\tuiip->pdev = adapter->pdev;\n\t\tuiip->llimit = t3_read_reg(adapter, A_ULPRX_ISCSI_LLIMIT);\n\t\tuiip->ulimit = t3_read_reg(adapter, A_ULPRX_ISCSI_ULIMIT);\n\t\tuiip->tagmask = t3_read_reg(adapter, A_ULPRX_ISCSI_TAGMASK);\n\n\t\tval = t3_read_reg(adapter, A_ULPRX_ISCSI_PSZ);\n\t\tfor (i = 0; i < 4; i++, val >>= 8)\n\t\t\tuiip->pgsz_factor[i] = val & 0xFF;\n\n\t\tval = t3_read_reg(adapter, A_TP_PARA_REG7);\n\t\tuiip->max_txsz =\n\t\tuiip->max_rxsz = min((val >> S_PMMAXXFERLEN0)&M_PMMAXXFERLEN0,\n\t\t\t\t     (val >> S_PMMAXXFERLEN1)&M_PMMAXXFERLEN1);\n\t\t \n\t\tval = min(adapter->params.tp.tx_pg_size,\n\t\t\t  t3_read_reg(adapter, A_PM1_TX_CFG) >> 17);\n\t\tuiip->max_txsz = min(val, uiip->max_txsz);\n\n\t\t \n\t\tval = t3_read_reg(adapter, A_TP_PARA_REG2);\n\t\tif ((val >> S_MAXRXDATA) != 0x3f60) {\n\t\t\tval &= (M_RXCOALESCESIZE << S_RXCOALESCESIZE);\n\t\t\tval |= V_MAXRXDATA(0x3f60);\n\t\t\tpr_info(\"%s, iscsi set MaxRxData to 16224 (0x%x)\\n\",\n\t\t\t\tadapter->name, val);\n\t\t\tt3_write_reg(adapter, A_TP_PARA_REG2, val);\n\t\t}\n\n\t\t \n\t\tval = min(adapter->params.tp.rx_pg_size,\n\t\t\t  ((t3_read_reg(adapter, A_TP_PARA_REG2)) >>\n\t\t\t\tS_MAXRXDATA) & M_MAXRXDATA);\n\t\tuiip->max_rxsz = min(val, uiip->max_rxsz);\n\t\tbreak;\n\tcase ULP_ISCSI_SET_PARAMS:\n\t\tt3_write_reg(adapter, A_ULPRX_ISCSI_TAGMASK, uiip->tagmask);\n\t\t \n\t\tfor (i = 0; i < 4; i++)\n\t\t\tval |= (uiip->pgsz_factor[i] & 0xF) << (8 * i);\n\t\tif (val && (val != t3_read_reg(adapter, A_ULPRX_ISCSI_PSZ))) {\n\t\t\tpr_info(\"%s, setting iscsi pgsz 0x%x, %u,%u,%u,%u\\n\",\n\t\t\t\tadapter->name, val, uiip->pgsz_factor[0],\n\t\t\t\tuiip->pgsz_factor[1], uiip->pgsz_factor[2],\n\t\t\t\tuiip->pgsz_factor[3]);\n\t\t\tt3_write_reg(adapter, A_ULPRX_ISCSI_PSZ, val);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tret = -EOPNOTSUPP;\n\t}\n\treturn ret;\n}\n\n \n#define ASYNC_NOTIF_RSPQ 0\n\nstatic int cxgb_rdma_ctl(struct adapter *adapter, unsigned int req, void *data)\n{\n\tint ret = 0;\n\n\tswitch (req) {\n\tcase RDMA_GET_PARAMS: {\n\t\tstruct rdma_info *rdma = data;\n\t\tstruct pci_dev *pdev = adapter->pdev;\n\n\t\trdma->udbell_physbase = pci_resource_start(pdev, 2);\n\t\trdma->udbell_len = pci_resource_len(pdev, 2);\n\t\trdma->tpt_base =\n\t\t\tt3_read_reg(adapter, A_ULPTX_TPT_LLIMIT);\n\t\trdma->tpt_top = t3_read_reg(adapter, A_ULPTX_TPT_ULIMIT);\n\t\trdma->pbl_base =\n\t\t\tt3_read_reg(adapter, A_ULPTX_PBL_LLIMIT);\n\t\trdma->pbl_top = t3_read_reg(adapter, A_ULPTX_PBL_ULIMIT);\n\t\trdma->rqt_base = t3_read_reg(adapter, A_ULPRX_RQ_LLIMIT);\n\t\trdma->rqt_top = t3_read_reg(adapter, A_ULPRX_RQ_ULIMIT);\n\t\trdma->kdb_addr = adapter->regs + A_SG_KDOORBELL;\n\t\trdma->pdev = pdev;\n\t\tbreak;\n\t}\n\tcase RDMA_CQ_OP:{\n\t\tunsigned long flags;\n\t\tstruct rdma_cq_op *rdma = data;\n\n\t\t \n\t\tspin_lock_irqsave(&adapter->sge.reg_lock, flags);\n\t\tret = t3_sge_cqcntxt_op(adapter, rdma->id, rdma->op,\n\t\t\t\t\trdma->credits);\n\t\tspin_unlock_irqrestore(&adapter->sge.reg_lock, flags);\n\t\tbreak;\n\t}\n\tcase RDMA_GET_MEM:{\n\t\tstruct ch_mem_range *t = data;\n\t\tstruct mc7 *mem;\n\n\t\tif ((t->addr & 7) || (t->len & 7))\n\t\t\treturn -EINVAL;\n\t\tif (t->mem_id == MEM_CM)\n\t\t\tmem = &adapter->cm;\n\t\telse if (t->mem_id == MEM_PMRX)\n\t\t\tmem = &adapter->pmrx;\n\t\telse if (t->mem_id == MEM_PMTX)\n\t\t\tmem = &adapter->pmtx;\n\t\telse\n\t\t\treturn -EINVAL;\n\n\t\tret =\n\t\t\tt3_mc7_bd_read(mem, t->addr / 8, t->len / 8,\n\t\t\t\t\t(u64 *) t->buf);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tbreak;\n\t}\n\tcase RDMA_CQ_SETUP:{\n\t\tstruct rdma_cq_setup *rdma = data;\n\n\t\tspin_lock_irq(&adapter->sge.reg_lock);\n\t\tret =\n\t\t\tt3_sge_init_cqcntxt(adapter, rdma->id,\n\t\t\t\t\trdma->base_addr, rdma->size,\n\t\t\t\t\tASYNC_NOTIF_RSPQ,\n\t\t\t\t\trdma->ovfl_mode, rdma->credits,\n\t\t\t\t\trdma->credit_thres);\n\t\tspin_unlock_irq(&adapter->sge.reg_lock);\n\t\tbreak;\n\t}\n\tcase RDMA_CQ_DISABLE:\n\t\tspin_lock_irq(&adapter->sge.reg_lock);\n\t\tret = t3_sge_disable_cqcntxt(adapter, *(unsigned int *)data);\n\t\tspin_unlock_irq(&adapter->sge.reg_lock);\n\t\tbreak;\n\tcase RDMA_CTRL_QP_SETUP:{\n\t\tstruct rdma_ctrlqp_setup *rdma = data;\n\n\t\tspin_lock_irq(&adapter->sge.reg_lock);\n\t\tret = t3_sge_init_ecntxt(adapter, FW_RI_SGEEC_START, 0,\n\t\t\t\t\t\tSGE_CNTXT_RDMA,\n\t\t\t\t\t\tASYNC_NOTIF_RSPQ,\n\t\t\t\t\t\trdma->base_addr, rdma->size,\n\t\t\t\t\t\tFW_RI_TID_START, 1, 0);\n\t\tspin_unlock_irq(&adapter->sge.reg_lock);\n\t\tbreak;\n\t}\n\tcase RDMA_GET_MIB: {\n\t\tspin_lock(&adapter->stats_lock);\n\t\tt3_tp_get_mib_stats(adapter, (struct tp_mib_stats *)data);\n\t\tspin_unlock(&adapter->stats_lock);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tret = -EOPNOTSUPP;\n\t}\n\treturn ret;\n}\n\nstatic int cxgb_offload_ctl(struct t3cdev *tdev, unsigned int req, void *data)\n{\n\tstruct adapter *adapter = tdev2adap(tdev);\n\tstruct tid_range *tid;\n\tstruct mtutab *mtup;\n\tstruct iff_mac *iffmacp;\n\tstruct ddp_params *ddpp;\n\tstruct adap_ports *ports;\n\tstruct ofld_page_info *rx_page_info;\n\tstruct tp_params *tp = &adapter->params.tp;\n\tint i;\n\n\tswitch (req) {\n\tcase GET_MAX_OUTSTANDING_WR:\n\t\t*(unsigned int *)data = FW_WR_NUM;\n\t\tbreak;\n\tcase GET_WR_LEN:\n\t\t*(unsigned int *)data = WR_FLITS;\n\t\tbreak;\n\tcase GET_TX_MAX_CHUNK:\n\t\t*(unsigned int *)data = 1 << 20;\t \n\t\tbreak;\n\tcase GET_TID_RANGE:\n\t\ttid = data;\n\t\ttid->num = t3_mc5_size(&adapter->mc5) -\n\t\t    adapter->params.mc5.nroutes -\n\t\t    adapter->params.mc5.nfilters - adapter->params.mc5.nservers;\n\t\ttid->base = 0;\n\t\tbreak;\n\tcase GET_STID_RANGE:\n\t\ttid = data;\n\t\ttid->num = adapter->params.mc5.nservers;\n\t\ttid->base = t3_mc5_size(&adapter->mc5) - tid->num -\n\t\t    adapter->params.mc5.nfilters - adapter->params.mc5.nroutes;\n\t\tbreak;\n\tcase GET_L2T_CAPACITY:\n\t\t*(unsigned int *)data = 2048;\n\t\tbreak;\n\tcase GET_MTUS:\n\t\tmtup = data;\n\t\tmtup->size = NMTUS;\n\t\tmtup->mtus = adapter->params.mtus;\n\t\tbreak;\n\tcase GET_IFF_FROM_MAC:\n\t\tiffmacp = data;\n\t\tiffmacp->dev = get_iff_from_mac(adapter, iffmacp->mac_addr,\n\t\t\t\t\t\tiffmacp->vlan_tag &\n\t\t\t\t\t\tVLAN_VID_MASK);\n\t\tbreak;\n\tcase GET_DDP_PARAMS:\n\t\tddpp = data;\n\t\tddpp->llimit = t3_read_reg(adapter, A_ULPRX_TDDP_LLIMIT);\n\t\tddpp->ulimit = t3_read_reg(adapter, A_ULPRX_TDDP_ULIMIT);\n\t\tddpp->tag_mask = t3_read_reg(adapter, A_ULPRX_TDDP_TAGMASK);\n\t\tbreak;\n\tcase GET_PORTS:\n\t\tports = data;\n\t\tports->nports = adapter->params.nports;\n\t\tfor_each_port(adapter, i)\n\t\t\tports->lldevs[i] = adapter->port[i];\n\t\tbreak;\n\tcase ULP_ISCSI_GET_PARAMS:\n\tcase ULP_ISCSI_SET_PARAMS:\n\t\tif (!offload_running(adapter))\n\t\t\treturn -EAGAIN;\n\t\treturn cxgb_ulp_iscsi_ctl(adapter, req, data);\n\tcase RDMA_GET_PARAMS:\n\tcase RDMA_CQ_OP:\n\tcase RDMA_CQ_SETUP:\n\tcase RDMA_CQ_DISABLE:\n\tcase RDMA_CTRL_QP_SETUP:\n\tcase RDMA_GET_MEM:\n\tcase RDMA_GET_MIB:\n\t\tif (!offload_running(adapter))\n\t\t\treturn -EAGAIN;\n\t\treturn cxgb_rdma_ctl(adapter, req, data);\n\tcase GET_RX_PAGE_INFO:\n\t\trx_page_info = data;\n\t\trx_page_info->page_size = tp->rx_pg_size;\n\t\trx_page_info->num = tp->rx_num_pgs;\n\t\tbreak;\n\tcase GET_ISCSI_IPV4ADDR: {\n\t\tstruct iscsi_ipv4addr *p = data;\n\t\tstruct port_info *pi = netdev_priv(p->dev);\n\t\tp->ipv4addr = pi->iscsi_ipv4addr;\n\t\tbreak;\n\t}\n\tcase GET_EMBEDDED_INFO: {\n\t\tstruct ch_embedded_info *e = data;\n\n\t\tspin_lock(&adapter->stats_lock);\n\t\tt3_get_fw_version(adapter, &e->fw_vers);\n\t\tt3_get_tp_version(adapter, &e->tp_vers);\n\t\tspin_unlock(&adapter->stats_lock);\n\t\tbreak;\n\t}\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\treturn 0;\n}\n\n \nstatic int rx_offload_blackhole(struct t3cdev *dev, struct sk_buff **skbs,\n\t\t\t\tint n)\n{\n\twhile (n--)\n\t\tdev_kfree_skb_any(skbs[n]);\n\treturn 0;\n}\n\nstatic void dummy_neigh_update(struct t3cdev *dev, struct neighbour *neigh)\n{\n}\n\nvoid cxgb3_set_dummy_ops(struct t3cdev *dev)\n{\n\tdev->recv = rx_offload_blackhole;\n\tdev->neigh_update = dummy_neigh_update;\n}\n\n \nvoid *cxgb3_free_atid(struct t3cdev *tdev, int atid)\n{\n\tstruct tid_info *t = &(T3C_DATA(tdev))->tid_maps;\n\tunion active_open_entry *p = atid2entry(t, atid);\n\tvoid *ctx = p->t3c_tid.ctx;\n\n\tspin_lock_bh(&t->atid_lock);\n\tp->next = t->afree;\n\tt->afree = p;\n\tt->atids_in_use--;\n\tspin_unlock_bh(&t->atid_lock);\n\n\treturn ctx;\n}\n\nEXPORT_SYMBOL(cxgb3_free_atid);\n\n \nvoid cxgb3_free_stid(struct t3cdev *tdev, int stid)\n{\n\tstruct tid_info *t = &(T3C_DATA(tdev))->tid_maps;\n\tunion listen_entry *p = stid2entry(t, stid);\n\n\tspin_lock_bh(&t->stid_lock);\n\tp->next = t->sfree;\n\tt->sfree = p;\n\tt->stids_in_use--;\n\tspin_unlock_bh(&t->stid_lock);\n}\n\nEXPORT_SYMBOL(cxgb3_free_stid);\n\nvoid cxgb3_insert_tid(struct t3cdev *tdev, struct cxgb3_client *client,\n\t\t      void *ctx, unsigned int tid)\n{\n\tstruct tid_info *t = &(T3C_DATA(tdev))->tid_maps;\n\n\tt->tid_tab[tid].client = client;\n\tt->tid_tab[tid].ctx = ctx;\n\tatomic_inc(&t->tids_in_use);\n}\n\nEXPORT_SYMBOL(cxgb3_insert_tid);\n\n \nstatic inline void mk_tid_release(struct sk_buff *skb, unsigned int tid)\n{\n\tstruct cpl_tid_release *req;\n\n\tskb->priority = CPL_PRIORITY_SETUP;\n\treq = __skb_put(skb, sizeof(*req));\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_TID_RELEASE, tid));\n}\n\nstatic void t3_process_tid_release_list(struct work_struct *work)\n{\n\tstruct t3c_data *td = container_of(work, struct t3c_data,\n\t\t\t\t\t   tid_release_task);\n\tstruct sk_buff *skb;\n\tstruct t3cdev *tdev = td->dev;\n\n\n\tspin_lock_bh(&td->tid_release_lock);\n\twhile (td->tid_release_list) {\n\t\tstruct t3c_tid_entry *p = td->tid_release_list;\n\n\t\ttd->tid_release_list = p->ctx;\n\t\tspin_unlock_bh(&td->tid_release_lock);\n\n\t\tskb = alloc_skb(sizeof(struct cpl_tid_release),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!skb)\n\t\t\tskb = td->nofail_skb;\n\t\tif (!skb) {\n\t\t\tspin_lock_bh(&td->tid_release_lock);\n\t\t\tp->ctx = (void *)td->tid_release_list;\n\t\t\ttd->tid_release_list = p;\n\t\t\tbreak;\n\t\t}\n\t\tmk_tid_release(skb, p - td->tid_maps.tid_tab);\n\t\tcxgb3_ofld_send(tdev, skb);\n\t\tp->ctx = NULL;\n\t\tif (skb == td->nofail_skb)\n\t\t\ttd->nofail_skb =\n\t\t\t\talloc_skb(sizeof(struct cpl_tid_release),\n\t\t\t\t\tGFP_KERNEL);\n\t\tspin_lock_bh(&td->tid_release_lock);\n\t}\n\ttd->release_list_incomplete = (td->tid_release_list == NULL) ? 0 : 1;\n\tspin_unlock_bh(&td->tid_release_lock);\n\n\tif (!td->nofail_skb)\n\t\ttd->nofail_skb =\n\t\t\talloc_skb(sizeof(struct cpl_tid_release),\n\t\t\t\tGFP_KERNEL);\n}\n\n \nvoid cxgb3_queue_tid_release(struct t3cdev *tdev, unsigned int tid)\n{\n\tstruct t3c_data *td = T3C_DATA(tdev);\n\tstruct t3c_tid_entry *p = &td->tid_maps.tid_tab[tid];\n\n\tspin_lock_bh(&td->tid_release_lock);\n\tp->ctx = (void *)td->tid_release_list;\n\tp->client = NULL;\n\ttd->tid_release_list = p;\n\tif (!p->ctx || td->release_list_incomplete)\n\t\tschedule_work(&td->tid_release_task);\n\tspin_unlock_bh(&td->tid_release_lock);\n}\n\nEXPORT_SYMBOL(cxgb3_queue_tid_release);\n\n \nvoid cxgb3_remove_tid(struct t3cdev *tdev, void *ctx, unsigned int tid)\n{\n\tstruct tid_info *t = &(T3C_DATA(tdev))->tid_maps;\n\n\tBUG_ON(tid >= t->ntids);\n\tif (tdev->type == T3A)\n\t\t(void)cmpxchg(&t->tid_tab[tid].ctx, ctx, NULL);\n\telse {\n\t\tstruct sk_buff *skb;\n\n\t\tskb = alloc_skb(sizeof(struct cpl_tid_release), GFP_ATOMIC);\n\t\tif (likely(skb)) {\n\t\t\tmk_tid_release(skb, tid);\n\t\t\tcxgb3_ofld_send(tdev, skb);\n\t\t\tt->tid_tab[tid].ctx = NULL;\n\t\t} else\n\t\t\tcxgb3_queue_tid_release(tdev, tid);\n\t}\n\tatomic_dec(&t->tids_in_use);\n}\n\nEXPORT_SYMBOL(cxgb3_remove_tid);\n\nint cxgb3_alloc_atid(struct t3cdev *tdev, struct cxgb3_client *client,\n\t\t     void *ctx)\n{\n\tint atid = -1;\n\tstruct tid_info *t = &(T3C_DATA(tdev))->tid_maps;\n\n\tspin_lock_bh(&t->atid_lock);\n\tif (t->afree &&\n\t    t->atids_in_use + atomic_read(&t->tids_in_use) + MC5_MIN_TIDS <=\n\t    t->ntids) {\n\t\tunion active_open_entry *p = t->afree;\n\n\t\tatid = (p - t->atid_tab) + t->atid_base;\n\t\tt->afree = p->next;\n\t\tp->t3c_tid.ctx = ctx;\n\t\tp->t3c_tid.client = client;\n\t\tt->atids_in_use++;\n\t}\n\tspin_unlock_bh(&t->atid_lock);\n\treturn atid;\n}\n\nEXPORT_SYMBOL(cxgb3_alloc_atid);\n\nint cxgb3_alloc_stid(struct t3cdev *tdev, struct cxgb3_client *client,\n\t\t     void *ctx)\n{\n\tint stid = -1;\n\tstruct tid_info *t = &(T3C_DATA(tdev))->tid_maps;\n\n\tspin_lock_bh(&t->stid_lock);\n\tif (t->sfree) {\n\t\tunion listen_entry *p = t->sfree;\n\n\t\tstid = (p - t->stid_tab) + t->stid_base;\n\t\tt->sfree = p->next;\n\t\tp->t3c_tid.ctx = ctx;\n\t\tp->t3c_tid.client = client;\n\t\tt->stids_in_use++;\n\t}\n\tspin_unlock_bh(&t->stid_lock);\n\treturn stid;\n}\n\nEXPORT_SYMBOL(cxgb3_alloc_stid);\n\n \nstruct t3cdev *dev2t3cdev(struct net_device *dev)\n{\n\tconst struct port_info *pi = netdev_priv(dev);\n\n\treturn (struct t3cdev *)pi->adapter;\n}\n\nEXPORT_SYMBOL(dev2t3cdev);\n\nstatic int do_smt_write_rpl(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_smt_write_rpl *rpl = cplhdr(skb);\n\n\tif (rpl->status != CPL_ERR_NONE)\n\t\tpr_err(\"Unexpected SMT_WRITE_RPL status %u for entry %u\\n\",\n\t\t       rpl->status, GET_TID(rpl));\n\n\treturn CPL_RET_BUF_DONE;\n}\n\nstatic int do_l2t_write_rpl(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_l2t_write_rpl *rpl = cplhdr(skb);\n\n\tif (rpl->status != CPL_ERR_NONE)\n\t\tpr_err(\"Unexpected L2T_WRITE_RPL status %u for entry %u\\n\",\n\t\t       rpl->status, GET_TID(rpl));\n\n\treturn CPL_RET_BUF_DONE;\n}\n\nstatic int do_rte_write_rpl(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_rte_write_rpl *rpl = cplhdr(skb);\n\n\tif (rpl->status != CPL_ERR_NONE)\n\t\tpr_err(\"Unexpected RTE_WRITE_RPL status %u for entry %u\\n\",\n\t\t       rpl->status, GET_TID(rpl));\n\n\treturn CPL_RET_BUF_DONE;\n}\n\nstatic int do_act_open_rpl(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_act_open_rpl *rpl = cplhdr(skb);\n\tunsigned int atid = G_TID(ntohl(rpl->atid));\n\tstruct t3c_tid_entry *t3c_tid;\n\n\tt3c_tid = lookup_atid(&(T3C_DATA(dev))->tid_maps, atid);\n\tif (t3c_tid && t3c_tid->ctx && t3c_tid->client &&\n\t    t3c_tid->client->handlers &&\n\t    t3c_tid->client->handlers[CPL_ACT_OPEN_RPL]) {\n\t\treturn t3c_tid->client->handlers[CPL_ACT_OPEN_RPL] (dev, skb,\n\t\t\t\t\t\t\t\t    t3c_tid->\n\t\t\t\t\t\t\t\t    ctx);\n\t} else {\n\t\tpr_err(\"%s: received clientless CPL command 0x%x\\n\",\n\t\t       dev->name, CPL_ACT_OPEN_RPL);\n\t\treturn CPL_RET_BUF_DONE | CPL_RET_BAD_MSG;\n\t}\n}\n\nstatic int do_stid_rpl(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tunion opcode_tid *p = cplhdr(skb);\n\tunsigned int stid = G_TID(ntohl(p->opcode_tid));\n\tstruct t3c_tid_entry *t3c_tid;\n\n\tt3c_tid = lookup_stid(&(T3C_DATA(dev))->tid_maps, stid);\n\tif (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers &&\n\t    t3c_tid->client->handlers[p->opcode]) {\n\t\treturn t3c_tid->client->handlers[p->opcode] (dev, skb,\n\t\t\t\t\t\t\t     t3c_tid->ctx);\n\t} else {\n\t\tpr_err(\"%s: received clientless CPL command 0x%x\\n\",\n\t\t       dev->name, p->opcode);\n\t\treturn CPL_RET_BUF_DONE | CPL_RET_BAD_MSG;\n\t}\n}\n\nstatic int do_hwtid_rpl(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tunion opcode_tid *p = cplhdr(skb);\n\tunsigned int hwtid = G_TID(ntohl(p->opcode_tid));\n\tstruct t3c_tid_entry *t3c_tid;\n\n\tt3c_tid = lookup_tid(&(T3C_DATA(dev))->tid_maps, hwtid);\n\tif (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers &&\n\t    t3c_tid->client->handlers[p->opcode]) {\n\t\treturn t3c_tid->client->handlers[p->opcode]\n\t\t    (dev, skb, t3c_tid->ctx);\n\t} else {\n\t\tpr_err(\"%s: received clientless CPL command 0x%x\\n\",\n\t\t       dev->name, p->opcode);\n\t\treturn CPL_RET_BUF_DONE | CPL_RET_BAD_MSG;\n\t}\n}\n\nstatic int do_cr(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_pass_accept_req *req = cplhdr(skb);\n\tunsigned int stid = G_PASS_OPEN_TID(ntohl(req->tos_tid));\n\tstruct tid_info *t = &(T3C_DATA(dev))->tid_maps;\n\tstruct t3c_tid_entry *t3c_tid;\n\tunsigned int tid = GET_TID(req);\n\n\tif (unlikely(tid >= t->ntids)) {\n\t\tprintk(\"%s: passive open TID %u too large\\n\",\n\t\t       dev->name, tid);\n\t\tt3_fatal_err(tdev2adap(dev));\n\t\treturn CPL_RET_BUF_DONE;\n\t}\n\n\tt3c_tid = lookup_stid(t, stid);\n\tif (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers &&\n\t    t3c_tid->client->handlers[CPL_PASS_ACCEPT_REQ]) {\n\t\treturn t3c_tid->client->handlers[CPL_PASS_ACCEPT_REQ]\n\t\t    (dev, skb, t3c_tid->ctx);\n\t} else {\n\t\tpr_err(\"%s: received clientless CPL command 0x%x\\n\",\n\t\t       dev->name, CPL_PASS_ACCEPT_REQ);\n\t\treturn CPL_RET_BUF_DONE | CPL_RET_BAD_MSG;\n\t}\n}\n\n \nstatic struct sk_buff *cxgb3_get_cpl_reply_skb(struct sk_buff *skb, size_t len,\n\t\t\t\t\t       gfp_t gfp)\n{\n\tif (likely(!skb_cloned(skb))) {\n\t\tBUG_ON(skb->len < len);\n\t\t__skb_trim(skb, len);\n\t\tskb_get(skb);\n\t} else {\n\t\tskb = alloc_skb(len, gfp);\n\t\tif (skb)\n\t\t\t__skb_put(skb, len);\n\t}\n\treturn skb;\n}\n\nstatic int do_abort_req_rss(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tunion opcode_tid *p = cplhdr(skb);\n\tunsigned int hwtid = G_TID(ntohl(p->opcode_tid));\n\tstruct t3c_tid_entry *t3c_tid;\n\n\tt3c_tid = lookup_tid(&(T3C_DATA(dev))->tid_maps, hwtid);\n\tif (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers &&\n\t    t3c_tid->client->handlers[p->opcode]) {\n\t\treturn t3c_tid->client->handlers[p->opcode]\n\t\t    (dev, skb, t3c_tid->ctx);\n\t} else {\n\t\tstruct cpl_abort_req_rss *req = cplhdr(skb);\n\t\tstruct cpl_abort_rpl *rpl;\n\t\tstruct sk_buff *reply_skb;\n\t\tunsigned int tid = GET_TID(req);\n\t\tu8 cmd = req->status;\n\n\t\tif (req->status == CPL_ERR_RTX_NEG_ADVICE ||\n\t\t    req->status == CPL_ERR_PERSIST_NEG_ADVICE)\n\t\t\tgoto out;\n\n\t\treply_skb = cxgb3_get_cpl_reply_skb(skb,\n\t\t\t\t\t\t    sizeof(struct\n\t\t\t\t\t\t\t   cpl_abort_rpl),\n\t\t\t\t\t\t    GFP_ATOMIC);\n\n\t\tif (!reply_skb) {\n\t\t\tprintk(\"do_abort_req_rss: couldn't get skb!\\n\");\n\t\t\tgoto out;\n\t\t}\n\t\treply_skb->priority = CPL_PRIORITY_DATA;\n\t\t__skb_put(reply_skb, sizeof(struct cpl_abort_rpl));\n\t\trpl = cplhdr(reply_skb);\n\t\trpl->wr.wr_hi =\n\t\t    htonl(V_WR_OP(FW_WROPCODE_OFLD_HOST_ABORT_CON_RPL));\n\t\trpl->wr.wr_lo = htonl(V_WR_TID(tid));\n\t\tOPCODE_TID(rpl) = htonl(MK_OPCODE_TID(CPL_ABORT_RPL, tid));\n\t\trpl->cmd = cmd;\n\t\tcxgb3_ofld_send(dev, reply_skb);\nout:\n\t\treturn CPL_RET_BUF_DONE;\n\t}\n}\n\nstatic int do_act_establish(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_act_establish *req = cplhdr(skb);\n\tunsigned int atid = G_PASS_OPEN_TID(ntohl(req->tos_tid));\n\tstruct tid_info *t = &(T3C_DATA(dev))->tid_maps;\n\tstruct t3c_tid_entry *t3c_tid;\n\tunsigned int tid = GET_TID(req);\n\n\tif (unlikely(tid >= t->ntids)) {\n\t\tprintk(\"%s: active establish TID %u too large\\n\",\n\t\t       dev->name, tid);\n\t\tt3_fatal_err(tdev2adap(dev));\n\t\treturn CPL_RET_BUF_DONE;\n\t}\n\n\tt3c_tid = lookup_atid(t, atid);\n\tif (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers &&\n\t    t3c_tid->client->handlers[CPL_ACT_ESTABLISH]) {\n\t\treturn t3c_tid->client->handlers[CPL_ACT_ESTABLISH]\n\t\t    (dev, skb, t3c_tid->ctx);\n\t} else {\n\t\tpr_err(\"%s: received clientless CPL command 0x%x\\n\",\n\t\t       dev->name, CPL_ACT_ESTABLISH);\n\t\treturn CPL_RET_BUF_DONE | CPL_RET_BAD_MSG;\n\t}\n}\n\nstatic int do_trace(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_trace_pkt *p = cplhdr(skb);\n\n\tskb->protocol = htons(0xffff);\n\tskb->dev = dev->lldev;\n\tskb_pull(skb, sizeof(*p));\n\tskb_reset_mac_header(skb);\n\tnetif_receive_skb(skb);\n\treturn 0;\n}\n\n \n\nstatic inline u32 get_hwtid(struct sk_buff *skb)\n{\n\treturn ntohl((__force __be32)skb->priority) >> 8 & 0xfffff;\n}\n\nstatic inline u32 get_opcode(struct sk_buff *skb)\n{\n\treturn G_OPCODE(ntohl((__force __be32)skb->csum));\n}\n\nstatic int do_term(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tunsigned int hwtid = get_hwtid(skb);\n\tunsigned int opcode = get_opcode(skb);\n\tstruct t3c_tid_entry *t3c_tid;\n\n\tt3c_tid = lookup_tid(&(T3C_DATA(dev))->tid_maps, hwtid);\n\tif (t3c_tid && t3c_tid->ctx && t3c_tid->client->handlers &&\n\t    t3c_tid->client->handlers[opcode]) {\n\t\treturn t3c_tid->client->handlers[opcode] (dev, skb,\n\t\t\t\t\t\t\t  t3c_tid->ctx);\n\t} else {\n\t\tpr_err(\"%s: received clientless CPL command 0x%x\\n\",\n\t\t       dev->name, opcode);\n\t\treturn CPL_RET_BUF_DONE | CPL_RET_BAD_MSG;\n\t}\n}\n\nstatic int nb_callback(struct notifier_block *self, unsigned long event,\n\t\t       void *ctx)\n{\n\tswitch (event) {\n\tcase (NETEVENT_NEIGH_UPDATE):{\n\t\tcxgb_neigh_update((struct neighbour *)ctx);\n\t\tbreak;\n\t}\n\tcase (NETEVENT_REDIRECT):{\n\t\tstruct netevent_redirect *nr = ctx;\n\t\tcxgb_redirect(nr->old, nr->new, nr->neigh,\n\t\t\t      nr->daddr);\n\t\tcxgb_neigh_update(nr->neigh);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic struct notifier_block nb = {\n\t.notifier_call = nb_callback\n};\n\n \nstatic int do_bad_cpl(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tpr_err(\"%s: received bad CPL command 0x%x\\n\", dev->name, *skb->data);\n\treturn CPL_RET_BUF_DONE | CPL_RET_BAD_MSG;\n}\n\n \nstatic cpl_handler_func cpl_handlers[NUM_CPL_CMDS];\n\n \nvoid t3_register_cpl_handler(unsigned int opcode, cpl_handler_func h)\n{\n\tif (opcode < NUM_CPL_CMDS)\n\t\tcpl_handlers[opcode] = h ? h : do_bad_cpl;\n\telse\n\t\tpr_err(\"T3C: handler registration for opcode %x failed\\n\",\n\t\t       opcode);\n}\n\nEXPORT_SYMBOL(t3_register_cpl_handler);\n\n \nstatic int process_rx(struct t3cdev *dev, struct sk_buff **skbs, int n)\n{\n\twhile (n--) {\n\t\tstruct sk_buff *skb = *skbs++;\n\t\tunsigned int opcode = get_opcode(skb);\n\t\tint ret = cpl_handlers[opcode] (dev, skb);\n\n#if VALIDATE_TID\n\t\tif (ret & CPL_RET_UNKNOWN_TID) {\n\t\t\tunion opcode_tid *p = cplhdr(skb);\n\n\t\t\tpr_err(\"%s: CPL message (opcode %u) had unknown TID %u\\n\",\n\t\t\t       dev->name, opcode, G_TID(ntohl(p->opcode_tid)));\n\t\t}\n#endif\n\t\tif (ret & CPL_RET_BUF_DONE)\n\t\t\tkfree_skb(skb);\n\t}\n\treturn 0;\n}\n\n \nint cxgb3_ofld_send(struct t3cdev *dev, struct sk_buff *skb)\n{\n\tint r;\n\n\tlocal_bh_disable();\n\tr = dev->send(dev, skb);\n\tlocal_bh_enable();\n\treturn r;\n}\n\nEXPORT_SYMBOL(cxgb3_ofld_send);\n\nstatic int is_offloading(struct net_device *dev)\n{\n\tstruct adapter *adapter;\n\tint i;\n\n\tread_lock_bh(&adapter_list_lock);\n\tlist_for_each_entry(adapter, &adapter_list, adapter_list) {\n\t\tfor_each_port(adapter, i) {\n\t\t\tif (dev == adapter->port[i]) {\n\t\t\t\tread_unlock_bh(&adapter_list_lock);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\tread_unlock_bh(&adapter_list_lock);\n\treturn 0;\n}\n\nstatic void cxgb_neigh_update(struct neighbour *neigh)\n{\n\tstruct net_device *dev;\n\n\tif (!neigh)\n\t\treturn;\n\tdev = neigh->dev;\n\tif (dev && (is_offloading(dev))) {\n\t\tstruct t3cdev *tdev = dev2t3cdev(dev);\n\n\t\tBUG_ON(!tdev);\n\t\tt3_l2t_update(tdev, neigh);\n\t}\n}\n\nstatic void set_l2t_ix(struct t3cdev *tdev, u32 tid, struct l2t_entry *e)\n{\n\tstruct sk_buff *skb;\n\tstruct cpl_set_tcb_field *req;\n\n\tskb = alloc_skb(sizeof(*req), GFP_ATOMIC);\n\tif (!skb) {\n\t\tpr_err(\"%s: cannot allocate skb!\\n\", __func__);\n\t\treturn;\n\t}\n\tskb->priority = CPL_PRIORITY_CONTROL;\n\treq = skb_put(skb, sizeof(*req));\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_SET_TCB_FIELD, tid));\n\treq->reply = 0;\n\treq->cpu_idx = 0;\n\treq->word = htons(W_TCB_L2T_IX);\n\treq->mask = cpu_to_be64(V_TCB_L2T_IX(M_TCB_L2T_IX));\n\treq->val = cpu_to_be64(V_TCB_L2T_IX(e->idx));\n\ttdev->send(tdev, skb);\n}\n\nstatic void cxgb_redirect(struct dst_entry *old, struct dst_entry *new,\n\t\t\t  struct neighbour *neigh,\n\t\t\t  const void *daddr)\n{\n\tstruct net_device *dev;\n\tstruct tid_info *ti;\n\tstruct t3cdev *tdev;\n\tu32 tid;\n\tint update_tcb;\n\tstruct l2t_entry *e;\n\tstruct t3c_tid_entry *te;\n\n\tdev = neigh->dev;\n\n\tif (!is_offloading(dev))\n\t\treturn;\n\ttdev = dev2t3cdev(dev);\n\tBUG_ON(!tdev);\n\n\t \n\te = t3_l2t_get(tdev, new, dev, daddr);\n\tif (!e) {\n\t\tpr_err(\"%s: couldn't allocate new l2t entry!\\n\", __func__);\n\t\treturn;\n\t}\n\n\t \n\tti = &(T3C_DATA(tdev))->tid_maps;\n\tfor (tid = 0; tid < ti->ntids; tid++) {\n\t\tte = lookup_tid(ti, tid);\n\t\tBUG_ON(!te);\n\t\tif (te && te->ctx && te->client && te->client->redirect) {\n\t\t\tupdate_tcb = te->client->redirect(te->ctx, old, new, e);\n\t\t\tif (update_tcb) {\n\t\t\t\trcu_read_lock();\n\t\t\t\tl2t_hold(L2DATA(tdev), e);\n\t\t\t\trcu_read_unlock();\n\t\t\t\tset_l2t_ix(tdev, tid, e);\n\t\t\t}\n\t\t}\n\t}\n\tl2t_release(tdev, e);\n}\n\n \nstatic int init_tid_tabs(struct tid_info *t, unsigned int ntids,\n\t\t\t unsigned int natids, unsigned int nstids,\n\t\t\t unsigned int atid_base, unsigned int stid_base)\n{\n\tunsigned long size = ntids * sizeof(*t->tid_tab) +\n\t    natids * sizeof(*t->atid_tab) + nstids * sizeof(*t->stid_tab);\n\n\tt->tid_tab = kvzalloc(size, GFP_KERNEL);\n\tif (!t->tid_tab)\n\t\treturn -ENOMEM;\n\n\tt->stid_tab = (union listen_entry *)&t->tid_tab[ntids];\n\tt->atid_tab = (union active_open_entry *)&t->stid_tab[nstids];\n\tt->ntids = ntids;\n\tt->nstids = nstids;\n\tt->stid_base = stid_base;\n\tt->sfree = NULL;\n\tt->natids = natids;\n\tt->atid_base = atid_base;\n\tt->afree = NULL;\n\tt->stids_in_use = t->atids_in_use = 0;\n\tatomic_set(&t->tids_in_use, 0);\n\tspin_lock_init(&t->stid_lock);\n\tspin_lock_init(&t->atid_lock);\n\n\t \n\tif (nstids) {\n\t\twhile (--nstids)\n\t\t\tt->stid_tab[nstids - 1].next = &t->stid_tab[nstids];\n\t\tt->sfree = t->stid_tab;\n\t}\n\tif (natids) {\n\t\twhile (--natids)\n\t\t\tt->atid_tab[natids - 1].next = &t->atid_tab[natids];\n\t\tt->afree = t->atid_tab;\n\t}\n\treturn 0;\n}\n\nstatic void free_tid_maps(struct tid_info *t)\n{\n\tkvfree(t->tid_tab);\n}\n\nstatic inline void add_adapter(struct adapter *adap)\n{\n\twrite_lock_bh(&adapter_list_lock);\n\tlist_add_tail(&adap->adapter_list, &adapter_list);\n\twrite_unlock_bh(&adapter_list_lock);\n}\n\nstatic inline void remove_adapter(struct adapter *adap)\n{\n\twrite_lock_bh(&adapter_list_lock);\n\tlist_del(&adap->adapter_list);\n\twrite_unlock_bh(&adapter_list_lock);\n}\n\nint cxgb3_offload_activate(struct adapter *adapter)\n{\n\tstruct t3cdev *dev = &adapter->tdev;\n\tint natids, err;\n\tstruct t3c_data *t;\n\tstruct tid_range stid_range, tid_range;\n\tstruct mtutab mtutab;\n\tunsigned int l2t_capacity;\n\tstruct l2t_data *l2td;\n\n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (!t)\n\t\treturn -ENOMEM;\n\n\terr = -EOPNOTSUPP;\n\tif (dev->ctl(dev, GET_TX_MAX_CHUNK, &t->tx_max_chunk) < 0 ||\n\t    dev->ctl(dev, GET_MAX_OUTSTANDING_WR, &t->max_wrs) < 0 ||\n\t    dev->ctl(dev, GET_L2T_CAPACITY, &l2t_capacity) < 0 ||\n\t    dev->ctl(dev, GET_MTUS, &mtutab) < 0 ||\n\t    dev->ctl(dev, GET_TID_RANGE, &tid_range) < 0 ||\n\t    dev->ctl(dev, GET_STID_RANGE, &stid_range) < 0)\n\t\tgoto out_free;\n\n\terr = -ENOMEM;\n\tl2td = t3_init_l2t(l2t_capacity);\n\tif (!l2td)\n\t\tgoto out_free;\n\n\tnatids = min(tid_range.num / 2, MAX_ATIDS);\n\terr = init_tid_tabs(&t->tid_maps, tid_range.num, natids,\n\t\t\t    stid_range.num, ATID_BASE, stid_range.base);\n\tif (err)\n\t\tgoto out_free_l2t;\n\n\tt->mtus = mtutab.mtus;\n\tt->nmtus = mtutab.size;\n\n\tINIT_WORK(&t->tid_release_task, t3_process_tid_release_list);\n\tspin_lock_init(&t->tid_release_lock);\n\tINIT_LIST_HEAD(&t->list_node);\n\tt->dev = dev;\n\n\tRCU_INIT_POINTER(dev->l2opt, l2td);\n\tT3C_DATA(dev) = t;\n\tdev->recv = process_rx;\n\tdev->neigh_update = t3_l2t_update;\n\n\t \n\tif (list_empty(&adapter_list))\n\t\tregister_netevent_notifier(&nb);\n\n\tt->nofail_skb = alloc_skb(sizeof(struct cpl_tid_release), GFP_KERNEL);\n\tt->release_list_incomplete = 0;\n\n\tadd_adapter(adapter);\n\treturn 0;\n\nout_free_l2t:\n\tkvfree(l2td);\nout_free:\n\tkfree(t);\n\treturn err;\n}\n\nstatic void clean_l2_data(struct rcu_head *head)\n{\n\tstruct l2t_data *d = container_of(head, struct l2t_data, rcu_head);\n\tkvfree(d);\n}\n\n\nvoid cxgb3_offload_deactivate(struct adapter *adapter)\n{\n\tstruct t3cdev *tdev = &adapter->tdev;\n\tstruct t3c_data *t = T3C_DATA(tdev);\n\tstruct l2t_data *d;\n\n\tremove_adapter(adapter);\n\tif (list_empty(&adapter_list))\n\t\tunregister_netevent_notifier(&nb);\n\n\tfree_tid_maps(&t->tid_maps);\n\tT3C_DATA(tdev) = NULL;\n\trcu_read_lock();\n\td = L2DATA(tdev);\n\trcu_read_unlock();\n\tRCU_INIT_POINTER(tdev->l2opt, NULL);\n\tcall_rcu(&d->rcu_head, clean_l2_data);\n\tkfree_skb(t->nofail_skb);\n\tkfree(t);\n}\n\nstatic inline void register_tdev(struct t3cdev *tdev)\n{\n\tstatic int unit;\n\n\tmutex_lock(&cxgb3_db_lock);\n\tsnprintf(tdev->name, sizeof(tdev->name), \"ofld_dev%d\", unit++);\n\tlist_add_tail(&tdev->ofld_dev_list, &ofld_dev_list);\n\tmutex_unlock(&cxgb3_db_lock);\n}\n\nstatic inline void unregister_tdev(struct t3cdev *tdev)\n{\n\tmutex_lock(&cxgb3_db_lock);\n\tlist_del(&tdev->ofld_dev_list);\n\tmutex_unlock(&cxgb3_db_lock);\n}\n\nstatic inline int adap2type(struct adapter *adapter)\n{\n\tint type = 0;\n\n\tswitch (adapter->params.rev) {\n\tcase T3_REV_A:\n\t\ttype = T3A;\n\t\tbreak;\n\tcase T3_REV_B:\n\tcase T3_REV_B2:\n\t\ttype = T3B;\n\t\tbreak;\n\tcase T3_REV_C:\n\t\ttype = T3C;\n\t\tbreak;\n\t}\n\treturn type;\n}\n\nvoid cxgb3_adapter_ofld(struct adapter *adapter)\n{\n\tstruct t3cdev *tdev = &adapter->tdev;\n\n\tINIT_LIST_HEAD(&tdev->ofld_dev_list);\n\n\tcxgb3_set_dummy_ops(tdev);\n\ttdev->send = t3_offload_tx;\n\ttdev->ctl = cxgb_offload_ctl;\n\ttdev->type = adap2type(adapter);\n\n\tregister_tdev(tdev);\n}\n\nvoid cxgb3_adapter_unofld(struct adapter *adapter)\n{\n\tstruct t3cdev *tdev = &adapter->tdev;\n\n\ttdev->recv = NULL;\n\ttdev->neigh_update = NULL;\n\n\tunregister_tdev(tdev);\n}\n\nvoid __init cxgb3_offload_init(void)\n{\n\tint i;\n\n\tfor (i = 0; i < NUM_CPL_CMDS; ++i)\n\t\tcpl_handlers[i] = do_bad_cpl;\n\n\tt3_register_cpl_handler(CPL_SMT_WRITE_RPL, do_smt_write_rpl);\n\tt3_register_cpl_handler(CPL_L2T_WRITE_RPL, do_l2t_write_rpl);\n\tt3_register_cpl_handler(CPL_RTE_WRITE_RPL, do_rte_write_rpl);\n\tt3_register_cpl_handler(CPL_PASS_OPEN_RPL, do_stid_rpl);\n\tt3_register_cpl_handler(CPL_CLOSE_LISTSRV_RPL, do_stid_rpl);\n\tt3_register_cpl_handler(CPL_PASS_ACCEPT_REQ, do_cr);\n\tt3_register_cpl_handler(CPL_PASS_ESTABLISH, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_ABORT_RPL_RSS, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_ABORT_RPL, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_RX_URG_NOTIFY, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_RX_DATA, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_TX_DATA_ACK, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_TX_DMA_ACK, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_ACT_OPEN_RPL, do_act_open_rpl);\n\tt3_register_cpl_handler(CPL_PEER_CLOSE, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_CLOSE_CON_RPL, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_ABORT_REQ_RSS, do_abort_req_rss);\n\tt3_register_cpl_handler(CPL_ACT_ESTABLISH, do_act_establish);\n\tt3_register_cpl_handler(CPL_SET_TCB_RPL, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_GET_TCB_RPL, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_RDMA_TERMINATE, do_term);\n\tt3_register_cpl_handler(CPL_RDMA_EC_STATUS, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_TRACE_PKT, do_trace);\n\tt3_register_cpl_handler(CPL_RX_DATA_DDP, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_RX_DDP_COMPLETE, do_hwtid_rpl);\n\tt3_register_cpl_handler(CPL_ISCSI_HDR, do_hwtid_rpl);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}