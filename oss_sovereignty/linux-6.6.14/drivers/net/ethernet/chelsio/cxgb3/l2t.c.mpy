{
  "module_name": "l2t.c",
  "hash_id": "ff19621352491ada0af44c60d5712506036e73c489efe55d5267b4b57b69856c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/chelsio/cxgb3/l2t.c",
  "human_readable_source": " \n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include <linux/if.h>\n#include <linux/if_vlan.h>\n#include <linux/jhash.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <net/neighbour.h>\n#include \"common.h\"\n#include \"t3cdev.h\"\n#include \"cxgb3_defs.h\"\n#include \"l2t.h\"\n#include \"t3_cpl.h\"\n#include \"firmware_exports.h\"\n\n#define VLAN_NONE 0xfff\n\n \n\nstatic inline unsigned int vlan_prio(const struct l2t_entry *e)\n{\n\treturn e->vlan >> 13;\n}\n\nstatic inline unsigned int arp_hash(u32 key, int ifindex,\n\t\t\t\t    const struct l2t_data *d)\n{\n\treturn jhash_2words(key, ifindex, 0) & (d->nentries - 1);\n}\n\nstatic inline void neigh_replace(struct l2t_entry *e, struct neighbour *n)\n{\n\tneigh_hold(n);\n\tif (e->neigh)\n\t\tneigh_release(e->neigh);\n\te->neigh = n;\n}\n\n \nstatic int setup_l2e_send_pending(struct t3cdev *dev, struct sk_buff *skb,\n\t\t\t\t  struct l2t_entry *e)\n{\n\tstruct cpl_l2t_write_req *req;\n\tstruct sk_buff *tmp;\n\n\tif (!skb) {\n\t\tskb = alloc_skb(sizeof(*req), GFP_ATOMIC);\n\t\tif (!skb)\n\t\t\treturn -ENOMEM;\n\t}\n\n\treq = __skb_put(skb, sizeof(*req));\n\treq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_L2T_WRITE_REQ, e->idx));\n\treq->params = htonl(V_L2T_W_IDX(e->idx) | V_L2T_W_IFF(e->smt_idx) |\n\t\t\t    V_L2T_W_VLAN(e->vlan & VLAN_VID_MASK) |\n\t\t\t    V_L2T_W_PRIO(vlan_prio(e)));\n\tmemcpy(e->dmac, e->neigh->ha, sizeof(e->dmac));\n\tmemcpy(req->dst_mac, e->dmac, sizeof(req->dst_mac));\n\tskb->priority = CPL_PRIORITY_CONTROL;\n\tcxgb3_ofld_send(dev, skb);\n\n\tskb_queue_walk_safe(&e->arpq, skb, tmp) {\n\t\t__skb_unlink(skb, &e->arpq);\n\t\tcxgb3_ofld_send(dev, skb);\n\t}\n\te->state = L2T_STATE_VALID;\n\n\treturn 0;\n}\n\n \nstatic inline void arpq_enqueue(struct l2t_entry *e, struct sk_buff *skb)\n{\n\t__skb_queue_tail(&e->arpq, skb);\n}\n\nint t3_l2t_send_slow(struct t3cdev *dev, struct sk_buff *skb,\n\t\t     struct l2t_entry *e)\n{\nagain:\n\tswitch (e->state) {\n\tcase L2T_STATE_STALE:\t \n\t\tneigh_event_send(e->neigh, NULL);\n\t\tspin_lock_bh(&e->lock);\n\t\tif (e->state == L2T_STATE_STALE)\n\t\t\te->state = L2T_STATE_VALID;\n\t\tspin_unlock_bh(&e->lock);\n\t\tfallthrough;\n\tcase L2T_STATE_VALID:\t \n\t\treturn cxgb3_ofld_send(dev, skb);\n\tcase L2T_STATE_RESOLVING:\n\t\tspin_lock_bh(&e->lock);\n\t\tif (e->state != L2T_STATE_RESOLVING) {\n\t\t\t \n\t\t\tspin_unlock_bh(&e->lock);\n\t\t\tgoto again;\n\t\t}\n\t\tarpq_enqueue(e, skb);\n\t\tspin_unlock_bh(&e->lock);\n\n\t\t \n\t\tif (!neigh_event_send(e->neigh, NULL)) {\n\t\t\tskb = alloc_skb(sizeof(struct cpl_l2t_write_req),\n\t\t\t\t\tGFP_ATOMIC);\n\t\t\tif (!skb)\n\t\t\t\tbreak;\n\n\t\t\tspin_lock_bh(&e->lock);\n\t\t\tif (!skb_queue_empty(&e->arpq))\n\t\t\t\tsetup_l2e_send_pending(dev, skb, e);\n\t\t\telse\t \n\t\t\t\t__kfree_skb(skb);\n\t\t\tspin_unlock_bh(&e->lock);\n\t\t}\n\t}\n\treturn 0;\n}\n\nEXPORT_SYMBOL(t3_l2t_send_slow);\n\nvoid t3_l2t_send_event(struct t3cdev *dev, struct l2t_entry *e)\n{\nagain:\n\tswitch (e->state) {\n\tcase L2T_STATE_STALE:\t \n\t\tneigh_event_send(e->neigh, NULL);\n\t\tspin_lock_bh(&e->lock);\n\t\tif (e->state == L2T_STATE_STALE) {\n\t\t\te->state = L2T_STATE_VALID;\n\t\t}\n\t\tspin_unlock_bh(&e->lock);\n\t\treturn;\n\tcase L2T_STATE_VALID:\t \n\t\treturn;\n\tcase L2T_STATE_RESOLVING:\n\t\tspin_lock_bh(&e->lock);\n\t\tif (e->state != L2T_STATE_RESOLVING) {\n\t\t\t \n\t\t\tspin_unlock_bh(&e->lock);\n\t\t\tgoto again;\n\t\t}\n\t\tspin_unlock_bh(&e->lock);\n\n\t\t \n\t\tneigh_event_send(e->neigh, NULL);\n\t}\n}\n\nEXPORT_SYMBOL(t3_l2t_send_event);\n\n \nstatic struct l2t_entry *alloc_l2e(struct l2t_data *d)\n{\n\tstruct l2t_entry *end, *e, **p;\n\n\tif (!atomic_read(&d->nfree))\n\t\treturn NULL;\n\n\t \n\tfor (e = d->rover, end = &d->l2tab[d->nentries]; e != end; ++e)\n\t\tif (atomic_read(&e->refcnt) == 0)\n\t\t\tgoto found;\n\n\tfor (e = &d->l2tab[1]; atomic_read(&e->refcnt); ++e) ;\nfound:\n\td->rover = e + 1;\n\tatomic_dec(&d->nfree);\n\n\t \n\tif (e->state != L2T_STATE_UNUSED) {\n\t\tint hash = arp_hash(e->addr, e->ifindex, d);\n\n\t\tfor (p = &d->l2tab[hash].first; *p; p = &(*p)->next)\n\t\t\tif (*p == e) {\n\t\t\t\t*p = e->next;\n\t\t\t\tbreak;\n\t\t\t}\n\t\te->state = L2T_STATE_UNUSED;\n\t}\n\treturn e;\n}\n\n \nvoid t3_l2e_free(struct l2t_data *d, struct l2t_entry *e)\n{\n\tspin_lock_bh(&e->lock);\n\tif (atomic_read(&e->refcnt) == 0) {\t \n\t\tif (e->neigh) {\n\t\t\tneigh_release(e->neigh);\n\t\t\te->neigh = NULL;\n\t\t}\n\t}\n\tspin_unlock_bh(&e->lock);\n\tatomic_inc(&d->nfree);\n}\n\nEXPORT_SYMBOL(t3_l2e_free);\n\n \nstatic inline void reuse_entry(struct l2t_entry *e, struct neighbour *neigh)\n{\n\tunsigned int nud_state;\n\n\tspin_lock(&e->lock);\t \n\n\tif (neigh != e->neigh)\n\t\tneigh_replace(e, neigh);\n\tnud_state = neigh->nud_state;\n\tif (memcmp(e->dmac, neigh->ha, sizeof(e->dmac)) ||\n\t    !(nud_state & NUD_VALID))\n\t\te->state = L2T_STATE_RESOLVING;\n\telse if (nud_state & NUD_CONNECTED)\n\t\te->state = L2T_STATE_VALID;\n\telse\n\t\te->state = L2T_STATE_STALE;\n\tspin_unlock(&e->lock);\n}\n\nstruct l2t_entry *t3_l2t_get(struct t3cdev *cdev, struct dst_entry *dst,\n\t\t\t     struct net_device *dev, const void *daddr)\n{\n\tstruct l2t_entry *e = NULL;\n\tstruct neighbour *neigh;\n\tstruct port_info *p;\n\tstruct l2t_data *d;\n\tint hash;\n\tu32 addr;\n\tint ifidx;\n\tint smt_idx;\n\n\trcu_read_lock();\n\tneigh = dst_neigh_lookup(dst, daddr);\n\tif (!neigh)\n\t\tgoto done_rcu;\n\n\taddr = *(u32 *) neigh->primary_key;\n\tifidx = neigh->dev->ifindex;\n\n\tif (!dev)\n\t\tdev = neigh->dev;\n\tp = netdev_priv(dev);\n\tsmt_idx = p->port_id;\n\n\td = L2DATA(cdev);\n\tif (!d)\n\t\tgoto done_rcu;\n\n\thash = arp_hash(addr, ifidx, d);\n\n\twrite_lock_bh(&d->lock);\n\tfor (e = d->l2tab[hash].first; e; e = e->next)\n\t\tif (e->addr == addr && e->ifindex == ifidx &&\n\t\t    e->smt_idx == smt_idx) {\n\t\t\tl2t_hold(d, e);\n\t\t\tif (atomic_read(&e->refcnt) == 1)\n\t\t\t\treuse_entry(e, neigh);\n\t\t\tgoto done_unlock;\n\t\t}\n\n\t \n\te = alloc_l2e(d);\n\tif (e) {\n\t\tspin_lock(&e->lock);\t \n\t\te->next = d->l2tab[hash].first;\n\t\td->l2tab[hash].first = e;\n\t\te->state = L2T_STATE_RESOLVING;\n\t\te->addr = addr;\n\t\te->ifindex = ifidx;\n\t\te->smt_idx = smt_idx;\n\t\tatomic_set(&e->refcnt, 1);\n\t\tneigh_replace(e, neigh);\n\t\tif (is_vlan_dev(neigh->dev))\n\t\t\te->vlan = vlan_dev_vlan_id(neigh->dev);\n\t\telse\n\t\t\te->vlan = VLAN_NONE;\n\t\tspin_unlock(&e->lock);\n\t}\ndone_unlock:\n\twrite_unlock_bh(&d->lock);\ndone_rcu:\n\tif (neigh)\n\t\tneigh_release(neigh);\n\trcu_read_unlock();\n\treturn e;\n}\n\nEXPORT_SYMBOL(t3_l2t_get);\n\n \nstatic void handle_failed_resolution(struct t3cdev *dev, struct sk_buff_head *arpq)\n{\n\tstruct sk_buff *skb, *tmp;\n\n\tskb_queue_walk_safe(arpq, skb, tmp) {\n\t\tstruct l2t_skb_cb *cb = L2T_SKB_CB(skb);\n\n\t\t__skb_unlink(skb, arpq);\n\t\tif (cb->arp_failure_handler)\n\t\t\tcb->arp_failure_handler(dev, skb);\n\t\telse\n\t\t\tcxgb3_ofld_send(dev, skb);\n\t}\n}\n\n \nvoid t3_l2t_update(struct t3cdev *dev, struct neighbour *neigh)\n{\n\tstruct sk_buff_head arpq;\n\tstruct l2t_entry *e;\n\tstruct l2t_data *d = L2DATA(dev);\n\tu32 addr = *(u32 *) neigh->primary_key;\n\tint ifidx = neigh->dev->ifindex;\n\tint hash = arp_hash(addr, ifidx, d);\n\n\tread_lock_bh(&d->lock);\n\tfor (e = d->l2tab[hash].first; e; e = e->next)\n\t\tif (e->addr == addr && e->ifindex == ifidx) {\n\t\t\tspin_lock(&e->lock);\n\t\t\tgoto found;\n\t\t}\n\tread_unlock_bh(&d->lock);\n\treturn;\n\nfound:\n\t__skb_queue_head_init(&arpq);\n\n\tread_unlock(&d->lock);\n\tif (atomic_read(&e->refcnt)) {\n\t\tif (neigh != e->neigh)\n\t\t\tneigh_replace(e, neigh);\n\n\t\tif (e->state == L2T_STATE_RESOLVING) {\n\t\t\tif (neigh->nud_state & NUD_FAILED) {\n\t\t\t\tskb_queue_splice_init(&e->arpq, &arpq);\n\t\t\t} else if (neigh->nud_state & (NUD_CONNECTED|NUD_STALE))\n\t\t\t\tsetup_l2e_send_pending(dev, NULL, e);\n\t\t} else {\n\t\t\te->state = neigh->nud_state & NUD_CONNECTED ?\n\t\t\t    L2T_STATE_VALID : L2T_STATE_STALE;\n\t\t\tif (!ether_addr_equal(e->dmac, neigh->ha))\n\t\t\t\tsetup_l2e_send_pending(dev, NULL, e);\n\t\t}\n\t}\n\tspin_unlock_bh(&e->lock);\n\n\tif (!skb_queue_empty(&arpq))\n\t\thandle_failed_resolution(dev, &arpq);\n}\n\nstruct l2t_data *t3_init_l2t(unsigned int l2t_capacity)\n{\n\tstruct l2t_data *d;\n\tint i;\n\n\td = kvzalloc(struct_size(d, l2tab, l2t_capacity), GFP_KERNEL);\n\tif (!d)\n\t\treturn NULL;\n\n\td->nentries = l2t_capacity;\n\td->rover = &d->l2tab[1];\t \n\tatomic_set(&d->nfree, l2t_capacity - 1);\n\trwlock_init(&d->lock);\n\n\tfor (i = 0; i < l2t_capacity; ++i) {\n\t\td->l2tab[i].idx = i;\n\t\td->l2tab[i].state = L2T_STATE_UNUSED;\n\t\t__skb_queue_head_init(&d->l2tab[i].arpq);\n\t\tspin_lock_init(&d->l2tab[i].lock);\n\t\tatomic_set(&d->l2tab[i].refcnt, 0);\n\t}\n\treturn d;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}