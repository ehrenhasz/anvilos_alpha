{
  "module_name": "cxgb4_tc_flower.c",
  "hash_id": "aa4717aebfe093d5918c43b85cd8c9b6319f188b6b3f1a473a88436bba20e563",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c",
  "human_readable_source": " \n\n#include <net/tc_act/tc_mirred.h>\n#include <net/tc_act/tc_pedit.h>\n#include <net/tc_act/tc_gact.h>\n#include <net/tc_act/tc_vlan.h>\n\n#include \"cxgb4.h\"\n#include \"cxgb4_filter.h\"\n#include \"cxgb4_tc_flower.h\"\n\n#define STATS_CHECK_PERIOD (HZ / 2)\n\nstatic struct ch_tc_pedit_fields pedits[] = {\n\tPEDIT_FIELDS(ETH_, DMAC_31_0, 4, dmac, 0),\n\tPEDIT_FIELDS(ETH_, DMAC_47_32, 2, dmac, 4),\n\tPEDIT_FIELDS(ETH_, SMAC_15_0, 2, smac, 0),\n\tPEDIT_FIELDS(ETH_, SMAC_47_16, 4, smac, 2),\n\tPEDIT_FIELDS(IP4_, SRC, 4, nat_fip, 0),\n\tPEDIT_FIELDS(IP4_, DST, 4, nat_lip, 0),\n\tPEDIT_FIELDS(IP6_, SRC_31_0, 4, nat_fip, 0),\n\tPEDIT_FIELDS(IP6_, SRC_63_32, 4, nat_fip, 4),\n\tPEDIT_FIELDS(IP6_, SRC_95_64, 4, nat_fip, 8),\n\tPEDIT_FIELDS(IP6_, SRC_127_96, 4, nat_fip, 12),\n\tPEDIT_FIELDS(IP6_, DST_31_0, 4, nat_lip, 0),\n\tPEDIT_FIELDS(IP6_, DST_63_32, 4, nat_lip, 4),\n\tPEDIT_FIELDS(IP6_, DST_95_64, 4, nat_lip, 8),\n\tPEDIT_FIELDS(IP6_, DST_127_96, 4, nat_lip, 12),\n};\n\nstatic const struct cxgb4_natmode_config cxgb4_natmode_config_array[] = {\n\t \n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_NONE,\n\t\t.natmode = NAT_MODE_NONE,\n\t},\n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP,\n\t\t.natmode = NAT_MODE_DIP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP | CXGB4_ACTION_NATMODE_DPORT,\n\t\t.natmode = NAT_MODE_DIP_DP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP | CXGB4_ACTION_NATMODE_DPORT |\n\t\t\t CXGB4_ACTION_NATMODE_SIP,\n\t\t.natmode = NAT_MODE_DIP_DP_SIP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP | CXGB4_ACTION_NATMODE_DPORT |\n\t\t\t CXGB4_ACTION_NATMODE_SPORT,\n\t\t.natmode = NAT_MODE_DIP_DP_SP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_SIP | CXGB4_ACTION_NATMODE_SPORT,\n\t\t.natmode = NAT_MODE_SIP_SP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP | CXGB4_ACTION_NATMODE_SIP |\n\t\t\t CXGB4_ACTION_NATMODE_SPORT,\n\t\t.natmode = NAT_MODE_DIP_SIP_SP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T5,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP | CXGB4_ACTION_NATMODE_SIP |\n\t\t\t CXGB4_ACTION_NATMODE_DPORT |\n\t\t\t CXGB4_ACTION_NATMODE_SPORT,\n\t\t.natmode = NAT_MODE_ALL,\n\t},\n\t \n\t{\n\t\t.chip = CHELSIO_T6,\n\t\t.flags = CXGB4_ACTION_NATMODE_SIP,\n\t\t.natmode = NAT_MODE_SIP_SP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T6,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP | CXGB4_ACTION_NATMODE_SPORT,\n\t\t.natmode = NAT_MODE_DIP_DP_SP,\n\t},\n\t{\n\t\t.chip = CHELSIO_T6,\n\t\t.flags = CXGB4_ACTION_NATMODE_DIP | CXGB4_ACTION_NATMODE_SIP,\n\t\t.natmode = NAT_MODE_ALL,\n\t},\n};\n\nstatic void cxgb4_action_natmode_tweak(struct ch_filter_specification *fs,\n\t\t\t\t       u8 natmode_flags)\n{\n\tu8 i = 0;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(cxgb4_natmode_config_array); i++) {\n\t\tif (cxgb4_natmode_config_array[i].flags == natmode_flags) {\n\t\t\tfs->nat_mode = cxgb4_natmode_config_array[i].natmode;\n\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic struct ch_tc_flower_entry *allocate_flower_entry(void)\n{\n\tstruct ch_tc_flower_entry *new = kzalloc(sizeof(*new), GFP_KERNEL);\n\tif (new)\n\t\tspin_lock_init(&new->lock);\n\treturn new;\n}\n\n \nstatic struct ch_tc_flower_entry *ch_flower_lookup(struct adapter *adap,\n\t\t\t\t\t\t   unsigned long flower_cookie)\n{\n\treturn rhashtable_lookup_fast(&adap->flower_tbl, &flower_cookie,\n\t\t\t\t      adap->flower_ht_params);\n}\n\nstatic void cxgb4_process_flow_match(struct net_device *dev,\n\t\t\t\t     struct flow_rule *rule,\n\t\t\t\t     struct ch_filter_specification *fs)\n{\n\tu16 addr_type = 0;\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {\n\t\tstruct flow_match_control match;\n\n\t\tflow_rule_match_control(rule, &match);\n\t\taddr_type = match.key->addr_type;\n\t} else if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IPV4_ADDRS)) {\n\t\taddr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t} else if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IPV6_ADDRS)) {\n\t\taddr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\t\tu16 ethtype_key, ethtype_mask;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tethtype_key = ntohs(match.key->n_proto);\n\t\tethtype_mask = ntohs(match.mask->n_proto);\n\n\t\tif (ethtype_key == ETH_P_ALL) {\n\t\t\tethtype_key = 0;\n\t\t\tethtype_mask = 0;\n\t\t}\n\n\t\tif (ethtype_key == ETH_P_IPV6)\n\t\t\tfs->type = 1;\n\n\t\tfs->val.ethtype = ethtype_key;\n\t\tfs->mask.ethtype = ethtype_mask;\n\t\tfs->val.proto = match.key->ip_proto;\n\t\tfs->mask.proto = match.mask->ip_proto;\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {\n\t\tstruct flow_match_ipv4_addrs match;\n\n\t\tflow_rule_match_ipv4_addrs(rule, &match);\n\t\tfs->type = 0;\n\t\tmemcpy(&fs->val.lip[0], &match.key->dst, sizeof(match.key->dst));\n\t\tmemcpy(&fs->val.fip[0], &match.key->src, sizeof(match.key->src));\n\t\tmemcpy(&fs->mask.lip[0], &match.mask->dst, sizeof(match.mask->dst));\n\t\tmemcpy(&fs->mask.fip[0], &match.mask->src, sizeof(match.mask->src));\n\n\t\t \n\t\tmemcpy(&fs->nat_lip[0], &match.key->dst, sizeof(match.key->dst));\n\t\tmemcpy(&fs->nat_fip[0], &match.key->src, sizeof(match.key->src));\n\t}\n\n\tif (addr_type == FLOW_DISSECTOR_KEY_IPV6_ADDRS) {\n\t\tstruct flow_match_ipv6_addrs match;\n\n\t\tflow_rule_match_ipv6_addrs(rule, &match);\n\t\tfs->type = 1;\n\t\tmemcpy(&fs->val.lip[0], match.key->dst.s6_addr,\n\t\t       sizeof(match.key->dst));\n\t\tmemcpy(&fs->val.fip[0], match.key->src.s6_addr,\n\t\t       sizeof(match.key->src));\n\t\tmemcpy(&fs->mask.lip[0], match.mask->dst.s6_addr,\n\t\t       sizeof(match.mask->dst));\n\t\tmemcpy(&fs->mask.fip[0], match.mask->src.s6_addr,\n\t\t       sizeof(match.mask->src));\n\n\t\t \n\t\tmemcpy(&fs->nat_lip[0], match.key->dst.s6_addr,\n\t\t       sizeof(match.key->dst));\n\t\tmemcpy(&fs->nat_fip[0], match.key->src.s6_addr,\n\t\t       sizeof(match.key->src));\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS)) {\n\t\tstruct flow_match_ports match;\n\n\t\tflow_rule_match_ports(rule, &match);\n\t\tfs->val.lport = be16_to_cpu(match.key->dst);\n\t\tfs->mask.lport = be16_to_cpu(match.mask->dst);\n\t\tfs->val.fport = be16_to_cpu(match.key->src);\n\t\tfs->mask.fport = be16_to_cpu(match.mask->src);\n\n\t\t \n\t\tfs->nat_lport = fs->val.lport;\n\t\tfs->nat_fport = fs->val.fport;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IP)) {\n\t\tstruct flow_match_ip match;\n\n\t\tflow_rule_match_ip(rule, &match);\n\t\tfs->val.tos = match.key->tos;\n\t\tfs->mask.tos = match.mask->tos;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_KEYID)) {\n\t\tstruct flow_match_enc_keyid match;\n\n\t\tflow_rule_match_enc_keyid(rule, &match);\n\t\tfs->val.vni = be32_to_cpu(match.key->keyid);\n\t\tfs->mask.vni = be32_to_cpu(match.mask->keyid);\n\t\tif (fs->mask.vni) {\n\t\t\tfs->val.encap_vld = 1;\n\t\t\tfs->mask.encap_vld = 1;\n\t\t}\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_VLAN)) {\n\t\tstruct flow_match_vlan match;\n\t\tu16 vlan_tci, vlan_tci_mask;\n\n\t\tflow_rule_match_vlan(rule, &match);\n\t\tvlan_tci = match.key->vlan_id | (match.key->vlan_priority <<\n\t\t\t\t\t       VLAN_PRIO_SHIFT);\n\t\tvlan_tci_mask = match.mask->vlan_id | (match.mask->vlan_priority <<\n\t\t\t\t\t\t     VLAN_PRIO_SHIFT);\n\t\tfs->val.ivlan = vlan_tci;\n\t\tfs->mask.ivlan = vlan_tci_mask;\n\n\t\tfs->val.ivlan_vld = 1;\n\t\tfs->mask.ivlan_vld = 1;\n\n\t\t \n\t\tif (fs->val.ethtype == ETH_P_8021Q) {\n\t\t\tfs->val.ethtype = 0;\n\t\t\tfs->mask.ethtype = 0;\n\t\t}\n\t}\n\n\t \n\tfs->val.iport = netdev2pinfo(dev)->port_id;\n\tfs->mask.iport = ~0;\n}\n\nstatic int cxgb4_validate_flow_match(struct net_device *dev,\n\t\t\t\t     struct flow_rule *rule)\n{\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tu16 ethtype_mask = 0;\n\tu16 ethtype_key = 0;\n\n\tif (dissector->used_keys &\n\t    ~(BIT_ULL(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_PORTS) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ENC_KEYID) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_VLAN) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_IP))) {\n\t\tnetdev_warn(dev, \"Unsupported key used: 0x%llx\\n\",\n\t\t\t    dissector->used_keys);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {\n\t\tstruct flow_match_basic match;\n\n\t\tflow_rule_match_basic(rule, &match);\n\t\tethtype_key = ntohs(match.key->n_proto);\n\t\tethtype_mask = ntohs(match.mask->n_proto);\n\t}\n\n\tif (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_IP)) {\n\t\tu16 eth_ip_type = ethtype_key & ethtype_mask;\n\t\tstruct flow_match_ip match;\n\n\t\tif (eth_ip_type != ETH_P_IP && eth_ip_type != ETH_P_IPV6) {\n\t\t\tnetdev_err(dev, \"IP Key supported only with IPv4/v6\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tflow_rule_match_ip(rule, &match);\n\t\tif (match.mask->ttl) {\n\t\t\tnetdev_warn(dev, \"ttl match unsupported for offload\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void offload_pedit(struct ch_filter_specification *fs, u32 val, u32 mask,\n\t\t\t  u8 field)\n{\n\tu32 set_val = val & ~mask;\n\tu32 offset = 0;\n\tu8 size = 1;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(pedits); i++) {\n\t\tif (pedits[i].field == field) {\n\t\t\toffset = pedits[i].offset;\n\t\t\tsize = pedits[i].size;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmemcpy((u8 *)fs + offset, &set_val, size);\n}\n\nstatic void process_pedit_field(struct ch_filter_specification *fs, u32 val,\n\t\t\t\tu32 mask, u32 offset, u8 htype,\n\t\t\t\tu8 *natmode_flags)\n{\n\tswitch (htype) {\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_ETH:\n\t\tswitch (offset) {\n\t\tcase PEDIT_ETH_DMAC_31_0:\n\t\t\tfs->newdmac = 1;\n\t\t\toffload_pedit(fs, val, mask, ETH_DMAC_31_0);\n\t\t\tbreak;\n\t\tcase PEDIT_ETH_DMAC_47_32_SMAC_15_0:\n\t\t\tif (~mask & PEDIT_ETH_DMAC_MASK)\n\t\t\t\toffload_pedit(fs, val, mask, ETH_DMAC_47_32);\n\t\t\telse\n\t\t\t\toffload_pedit(fs, val >> 16, mask >> 16,\n\t\t\t\t\t      ETH_SMAC_15_0);\n\t\t\tbreak;\n\t\tcase PEDIT_ETH_SMAC_47_16:\n\t\t\tfs->newsmac = 1;\n\t\t\toffload_pedit(fs, val, mask, ETH_SMAC_47_16);\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_IP4:\n\t\tswitch (offset) {\n\t\tcase PEDIT_IP4_SRC:\n\t\t\toffload_pedit(fs, val, mask, IP4_SRC);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP4_DST:\n\t\t\toffload_pedit(fs, val, mask, IP4_DST);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DIP;\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_IP6:\n\t\tswitch (offset) {\n\t\tcase PEDIT_IP6_SRC_31_0:\n\t\t\toffload_pedit(fs, val, mask, IP6_SRC_31_0);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_SRC_63_32:\n\t\t\toffload_pedit(fs, val, mask, IP6_SRC_63_32);\n\t\t\t*natmode_flags |=  CXGB4_ACTION_NATMODE_SIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_SRC_95_64:\n\t\t\toffload_pedit(fs, val, mask, IP6_SRC_95_64);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_SRC_127_96:\n\t\t\toffload_pedit(fs, val, mask, IP6_SRC_127_96);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_DST_31_0:\n\t\t\toffload_pedit(fs, val, mask, IP6_DST_31_0);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_DST_63_32:\n\t\t\toffload_pedit(fs, val, mask, IP6_DST_63_32);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_DST_95_64:\n\t\t\toffload_pedit(fs, val, mask, IP6_DST_95_64);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_DST_127_96:\n\t\t\toffload_pedit(fs, val, mask, IP6_DST_127_96);\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DIP;\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_TCP:\n\t\tswitch (offset) {\n\t\tcase PEDIT_TCP_SPORT_DPORT:\n\t\t\tif (~mask & PEDIT_TCP_UDP_SPORT_MASK) {\n\t\t\t\tfs->nat_fport = val;\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SPORT;\n\t\t\t} else {\n\t\t\t\tfs->nat_lport = val >> 16;\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DPORT;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_UDP:\n\t\tswitch (offset) {\n\t\tcase PEDIT_UDP_SPORT_DPORT:\n\t\t\tif (~mask & PEDIT_TCP_UDP_SPORT_MASK) {\n\t\t\t\tfs->nat_fport = val;\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SPORT;\n\t\t\t} else {\n\t\t\t\tfs->nat_lport = val >> 16;\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DPORT;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n}\n\nstatic int cxgb4_action_natmode_validate(struct adapter *adap, u8 natmode_flags,\n\t\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tu8 i = 0;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(cxgb4_natmode_config_array); i++) {\n\t\tconst struct cxgb4_natmode_config *c;\n\n\t\tc = &cxgb4_natmode_config_array[i];\n\t\tif (CHELSIO_CHIP_VERSION(adap->params.chip) >= c->chip &&\n\t\t    natmode_flags == c->flags)\n\t\t\treturn 0;\n\t}\n\tNL_SET_ERR_MSG_MOD(extack, \"Unsupported NAT mode 4-tuple combination\");\n\treturn -EOPNOTSUPP;\n}\n\nvoid cxgb4_process_flow_actions(struct net_device *in,\n\t\t\t\tstruct flow_action *actions,\n\t\t\t\tstruct ch_filter_specification *fs)\n{\n\tstruct flow_action_entry *act;\n\tu8 natmode_flags = 0;\n\tint i;\n\n\tflow_action_for_each(i, act, actions) {\n\t\tswitch (act->id) {\n\t\tcase FLOW_ACTION_ACCEPT:\n\t\t\tfs->action = FILTER_PASS;\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_DROP:\n\t\t\tfs->action = FILTER_DROP;\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_MIRRED:\n\t\tcase FLOW_ACTION_REDIRECT: {\n\t\t\tstruct net_device *out = act->dev;\n\t\t\tstruct port_info *pi = netdev_priv(out);\n\n\t\t\tfs->action = FILTER_SWITCH;\n\t\t\tfs->eport = pi->port_id;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_VLAN_POP:\n\t\tcase FLOW_ACTION_VLAN_PUSH:\n\t\tcase FLOW_ACTION_VLAN_MANGLE: {\n\t\t\tu8 prio = act->vlan.prio;\n\t\t\tu16 vid = act->vlan.vid;\n\t\t\tu16 vlan_tci = (prio << VLAN_PRIO_SHIFT) | vid;\n\t\t\tswitch (act->id) {\n\t\t\tcase FLOW_ACTION_VLAN_POP:\n\t\t\t\tfs->newvlan |= VLAN_REMOVE;\n\t\t\t\tbreak;\n\t\t\tcase FLOW_ACTION_VLAN_PUSH:\n\t\t\t\tfs->newvlan |= VLAN_INSERT;\n\t\t\t\tfs->vlan = vlan_tci;\n\t\t\t\tbreak;\n\t\t\tcase FLOW_ACTION_VLAN_MANGLE:\n\t\t\t\tfs->newvlan |= VLAN_REWRITE;\n\t\t\t\tfs->vlan = vlan_tci;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_MANGLE: {\n\t\t\tu32 mask, val, offset;\n\t\t\tu8 htype;\n\n\t\t\thtype = act->mangle.htype;\n\t\t\tmask = act->mangle.mask;\n\t\t\tval = act->mangle.val;\n\t\t\toffset = act->mangle.offset;\n\n\t\t\tprocess_pedit_field(fs, val, mask, offset, htype,\n\t\t\t\t\t    &natmode_flags);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_QUEUE:\n\t\t\tfs->action = FILTER_PASS;\n\t\t\tfs->dirsteer = 1;\n\t\t\tfs->iq = act->queue.index;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (natmode_flags)\n\t\tcxgb4_action_natmode_tweak(fs, natmode_flags);\n\n}\n\nstatic bool valid_l4_mask(u32 mask)\n{\n\tu16 hi, lo;\n\n\t \n\thi = (mask >> 16) & 0xFFFF;\n\tlo = mask & 0xFFFF;\n\n\treturn hi && lo ? false : true;\n}\n\nstatic bool valid_pedit_action(struct net_device *dev,\n\t\t\t       const struct flow_action_entry *act,\n\t\t\t       u8 *natmode_flags)\n{\n\tu32 mask, offset;\n\tu8 htype;\n\n\thtype = act->mangle.htype;\n\tmask = act->mangle.mask;\n\toffset = act->mangle.offset;\n\n\tswitch (htype) {\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_ETH:\n\t\tswitch (offset) {\n\t\tcase PEDIT_ETH_DMAC_31_0:\n\t\tcase PEDIT_ETH_DMAC_47_32_SMAC_15_0:\n\t\tcase PEDIT_ETH_SMAC_47_16:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_err(dev, \"%s: Unsupported pedit field\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_IP4:\n\t\tswitch (offset) {\n\t\tcase PEDIT_IP4_SRC:\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP4_DST:\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DIP;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_err(dev, \"%s: Unsupported pedit field\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_IP6:\n\t\tswitch (offset) {\n\t\tcase PEDIT_IP6_SRC_31_0:\n\t\tcase PEDIT_IP6_SRC_63_32:\n\t\tcase PEDIT_IP6_SRC_95_64:\n\t\tcase PEDIT_IP6_SRC_127_96:\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SIP;\n\t\t\tbreak;\n\t\tcase PEDIT_IP6_DST_31_0:\n\t\tcase PEDIT_IP6_DST_63_32:\n\t\tcase PEDIT_IP6_DST_95_64:\n\t\tcase PEDIT_IP6_DST_127_96:\n\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DIP;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_err(dev, \"%s: Unsupported pedit field\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_TCP:\n\t\tswitch (offset) {\n\t\tcase PEDIT_TCP_SPORT_DPORT:\n\t\t\tif (!valid_l4_mask(~mask)) {\n\t\t\t\tnetdev_err(dev, \"%s: Unsupported mask for TCP L4 ports\\n\",\n\t\t\t\t\t   __func__);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (~mask & PEDIT_TCP_UDP_SPORT_MASK)\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SPORT;\n\t\t\telse\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DPORT;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_err(dev, \"%s: Unsupported pedit field\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase FLOW_ACT_MANGLE_HDR_TYPE_UDP:\n\t\tswitch (offset) {\n\t\tcase PEDIT_UDP_SPORT_DPORT:\n\t\t\tif (!valid_l4_mask(~mask)) {\n\t\t\t\tnetdev_err(dev, \"%s: Unsupported mask for UDP L4 ports\\n\",\n\t\t\t\t\t   __func__);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (~mask & PEDIT_TCP_UDP_SPORT_MASK)\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_SPORT;\n\t\t\telse\n\t\t\t\t*natmode_flags |= CXGB4_ACTION_NATMODE_DPORT;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_err(dev, \"%s: Unsupported pedit field\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tnetdev_err(dev, \"%s: Unsupported pedit type\\n\", __func__);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nint cxgb4_validate_flow_actions(struct net_device *dev,\n\t\t\t\tstruct flow_action *actions,\n\t\t\t\tstruct netlink_ext_ack *extack,\n\t\t\t\tu8 matchall_filter)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\tstruct flow_action_entry *act;\n\tbool act_redir = false;\n\tbool act_pedit = false;\n\tbool act_vlan = false;\n\tu8 natmode_flags = 0;\n\tint i;\n\n\tif (!flow_action_basic_hw_stats_check(actions, extack))\n\t\treturn -EOPNOTSUPP;\n\n\tflow_action_for_each(i, act, actions) {\n\t\tswitch (act->id) {\n\t\tcase FLOW_ACTION_ACCEPT:\n\t\tcase FLOW_ACTION_DROP:\n\t\t\t \n\t\t\tbreak;\n\t\tcase FLOW_ACTION_MIRRED:\n\t\tcase FLOW_ACTION_REDIRECT: {\n\t\t\tstruct net_device *n_dev, *target_dev;\n\t\t\tbool found = false;\n\t\t\tunsigned int i;\n\n\t\t\tif (act->id == FLOW_ACTION_MIRRED &&\n\t\t\t    !matchall_filter) {\n\t\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t\t   \"Egress mirror action is only supported for tc-matchall\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\ttarget_dev = act->dev;\n\t\t\tfor_each_port(adap, i) {\n\t\t\t\tn_dev = adap->port[i];\n\t\t\t\tif (target_dev == n_dev) {\n\t\t\t\t\tfound = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\tif (!found) {\n\t\t\t\tnetdev_err(dev, \"%s: Out port invalid\\n\",\n\t\t\t\t\t   __func__);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tact_redir = true;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_VLAN_POP:\n\t\tcase FLOW_ACTION_VLAN_PUSH:\n\t\tcase FLOW_ACTION_VLAN_MANGLE: {\n\t\t\tu16 proto = be16_to_cpu(act->vlan.proto);\n\n\t\t\tswitch (act->id) {\n\t\t\tcase FLOW_ACTION_VLAN_POP:\n\t\t\t\tbreak;\n\t\t\tcase FLOW_ACTION_VLAN_PUSH:\n\t\t\tcase FLOW_ACTION_VLAN_MANGLE:\n\t\t\t\tif (proto != ETH_P_8021Q) {\n\t\t\t\t\tnetdev_err(dev, \"%s: Unsupported vlan proto\\n\",\n\t\t\t\t\t\t   __func__);\n\t\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tnetdev_err(dev, \"%s: Unsupported vlan action\\n\",\n\t\t\t\t\t   __func__);\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t\tact_vlan = true;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_MANGLE: {\n\t\t\tbool pedit_valid = valid_pedit_action(dev, act,\n\t\t\t\t\t\t\t      &natmode_flags);\n\n\t\t\tif (!pedit_valid)\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\tact_pedit = true;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase FLOW_ACTION_QUEUE:\n\t\t\t \n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_err(dev, \"%s: Unsupported action\\n\", __func__);\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\n\tif ((act_pedit || act_vlan) && !act_redir) {\n\t\tnetdev_err(dev, \"%s: pedit/vlan rewrite invalid without egress redirect\\n\",\n\t\t\t   __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (act_pedit) {\n\t\tint ret;\n\n\t\tret = cxgb4_action_natmode_validate(adap, natmode_flags,\n\t\t\t\t\t\t    extack);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void cxgb4_tc_flower_hash_prio_add(struct adapter *adap, u32 tc_prio)\n{\n\tspin_lock_bh(&adap->tids.ftid_lock);\n\tif (adap->tids.tc_hash_tids_max_prio < tc_prio)\n\t\tadap->tids.tc_hash_tids_max_prio = tc_prio;\n\tspin_unlock_bh(&adap->tids.ftid_lock);\n}\n\nstatic void cxgb4_tc_flower_hash_prio_del(struct adapter *adap, u32 tc_prio)\n{\n\tstruct tid_info *t = &adap->tids;\n\tstruct ch_tc_flower_entry *fe;\n\tstruct rhashtable_iter iter;\n\tu32 found = 0;\n\n\tspin_lock_bh(&t->ftid_lock);\n\t \n\tif (t->tc_hash_tids_max_prio != tc_prio)\n\t\tgoto out_unlock;\n\n\t \n\trhashtable_walk_enter(&adap->flower_tbl, &iter);\n\tdo {\n\t\trhashtable_walk_start(&iter);\n\n\t\tfe = rhashtable_walk_next(&iter);\n\t\twhile (!IS_ERR_OR_NULL(fe)) {\n\t\t\tif (fe->fs.hash &&\n\t\t\t    fe->fs.tc_prio <= t->tc_hash_tids_max_prio) {\n\t\t\t\tt->tc_hash_tids_max_prio = fe->fs.tc_prio;\n\t\t\t\tfound++;\n\n\t\t\t\t \n\t\t\t\tif (fe->fs.tc_prio == tc_prio)\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tfe = rhashtable_walk_next(&iter);\n\t\t}\n\n\t\trhashtable_walk_stop(&iter);\n\t} while (fe == ERR_PTR(-EAGAIN));\n\trhashtable_walk_exit(&iter);\n\n\tif (!found)\n\t\tt->tc_hash_tids_max_prio = 0;\n\nout_unlock:\n\tspin_unlock_bh(&t->ftid_lock);\n}\n\nint cxgb4_flow_rule_replace(struct net_device *dev, struct flow_rule *rule,\n\t\t\t    u32 tc_prio, struct netlink_ext_ack *extack,\n\t\t\t    struct ch_filter_specification *fs, u32 *tid)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\tstruct filter_ctx ctx;\n\tu8 inet_family;\n\tint fidx, ret;\n\n\tif (cxgb4_validate_flow_actions(dev, &rule->action, extack, 0))\n\t\treturn -EOPNOTSUPP;\n\n\tif (cxgb4_validate_flow_match(dev, rule))\n\t\treturn -EOPNOTSUPP;\n\n\tcxgb4_process_flow_match(dev, rule, fs);\n\tcxgb4_process_flow_actions(dev, &rule->action, fs);\n\n\tfs->hash = is_filter_exact_match(adap, fs);\n\tinet_family = fs->type ? PF_INET6 : PF_INET;\n\n\t \n\tfidx = cxgb4_get_free_ftid(dev, inet_family, fs->hash,\n\t\t\t\t   tc_prio);\n\tif (fidx < 0) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"No free LETCAM index available\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (fidx < adap->tids.nhpftids) {\n\t\tfs->prio = 1;\n\t\tfs->hash = 0;\n\t}\n\n\t \n\tif (fs->hash)\n\t\tfidx = 0;\n\n\tfs->tc_prio = tc_prio;\n\n\tinit_completion(&ctx.completion);\n\tret = __cxgb4_set_filter(dev, fidx, fs, &ctx);\n\tif (ret) {\n\t\tnetdev_err(dev, \"%s: filter creation err %d\\n\",\n\t\t\t   __func__, ret);\n\t\treturn ret;\n\t}\n\n\t \n\tret = wait_for_completion_timeout(&ctx.completion, 10 * HZ);\n\tif (!ret)\n\t\treturn -ETIMEDOUT;\n\n\t \n\tif (ctx.result)\n\t\treturn ctx.result;\n\n\t*tid = ctx.tid;\n\n\tif (fs->hash)\n\t\tcxgb4_tc_flower_hash_prio_add(adap, tc_prio);\n\n\treturn 0;\n}\n\nint cxgb4_tc_flower_replace(struct net_device *dev,\n\t\t\t    struct flow_cls_offload *cls)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(cls);\n\tstruct netlink_ext_ack *extack = cls->common.extack;\n\tstruct adapter *adap = netdev2adap(dev);\n\tstruct ch_tc_flower_entry *ch_flower;\n\tstruct ch_filter_specification *fs;\n\tint ret;\n\n\tch_flower = allocate_flower_entry();\n\tif (!ch_flower) {\n\t\tnetdev_err(dev, \"%s: ch_flower alloc failed.\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tfs = &ch_flower->fs;\n\tfs->hitcnts = 1;\n\tfs->tc_cookie = cls->cookie;\n\n\tret = cxgb4_flow_rule_replace(dev, rule, cls->common.prio, extack, fs,\n\t\t\t\t      &ch_flower->filter_id);\n\tif (ret)\n\t\tgoto free_entry;\n\n\tch_flower->tc_flower_cookie = cls->cookie;\n\tret = rhashtable_insert_fast(&adap->flower_tbl, &ch_flower->node,\n\t\t\t\t     adap->flower_ht_params);\n\tif (ret)\n\t\tgoto del_filter;\n\n\treturn 0;\n\ndel_filter:\n\tif (fs->hash)\n\t\tcxgb4_tc_flower_hash_prio_del(adap, cls->common.prio);\n\n\tcxgb4_del_filter(dev, ch_flower->filter_id, &ch_flower->fs);\n\nfree_entry:\n\tkfree(ch_flower);\n\treturn ret;\n}\n\nint cxgb4_flow_rule_destroy(struct net_device *dev, u32 tc_prio,\n\t\t\t    struct ch_filter_specification *fs, int tid)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\tu8 hash;\n\tint ret;\n\n\thash = fs->hash;\n\n\tret = cxgb4_del_filter(dev, tid, fs);\n\tif (ret)\n\t\treturn ret;\n\n\tif (hash)\n\t\tcxgb4_tc_flower_hash_prio_del(adap, tc_prio);\n\n\treturn ret;\n}\n\nint cxgb4_tc_flower_destroy(struct net_device *dev,\n\t\t\t    struct flow_cls_offload *cls)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\tstruct ch_tc_flower_entry *ch_flower;\n\tint ret;\n\n\tch_flower = ch_flower_lookup(adap, cls->cookie);\n\tif (!ch_flower)\n\t\treturn -ENOENT;\n\n\trhashtable_remove_fast(&adap->flower_tbl, &ch_flower->node,\n\t\t\t       adap->flower_ht_params);\n\n\tret = cxgb4_flow_rule_destroy(dev, ch_flower->fs.tc_prio,\n\t\t\t\t      &ch_flower->fs, ch_flower->filter_id);\n\tif (ret)\n\t\tnetdev_err(dev, \"Flow rule destroy failed for tid: %u, ret: %d\",\n\t\t\t   ch_flower->filter_id, ret);\n\n\tkfree_rcu(ch_flower, rcu);\n\treturn ret;\n}\n\nstatic void ch_flower_stats_handler(struct work_struct *work)\n{\n\tstruct adapter *adap = container_of(work, struct adapter,\n\t\t\t\t\t    flower_stats_work);\n\tstruct ch_tc_flower_entry *flower_entry;\n\tstruct ch_tc_flower_stats *ofld_stats;\n\tstruct rhashtable_iter iter;\n\tu64 packets;\n\tu64 bytes;\n\tint ret;\n\n\trhashtable_walk_enter(&adap->flower_tbl, &iter);\n\tdo {\n\t\trhashtable_walk_start(&iter);\n\n\t\twhile ((flower_entry = rhashtable_walk_next(&iter)) &&\n\t\t       !IS_ERR(flower_entry)) {\n\t\t\tret = cxgb4_get_filter_counters(adap->port[0],\n\t\t\t\t\t\t\tflower_entry->filter_id,\n\t\t\t\t\t\t\t&packets, &bytes,\n\t\t\t\t\t\t\tflower_entry->fs.hash);\n\t\t\tif (!ret) {\n\t\t\t\tspin_lock(&flower_entry->lock);\n\t\t\t\tofld_stats = &flower_entry->stats;\n\n\t\t\t\tif (ofld_stats->prev_packet_count != packets) {\n\t\t\t\t\tofld_stats->prev_packet_count = packets;\n\t\t\t\t\tofld_stats->last_used = jiffies;\n\t\t\t\t}\n\t\t\t\tspin_unlock(&flower_entry->lock);\n\t\t\t}\n\t\t}\n\n\t\trhashtable_walk_stop(&iter);\n\n\t} while (flower_entry == ERR_PTR(-EAGAIN));\n\trhashtable_walk_exit(&iter);\n\tmod_timer(&adap->flower_stats_timer, jiffies + STATS_CHECK_PERIOD);\n}\n\nstatic void ch_flower_stats_cb(struct timer_list *t)\n{\n\tstruct adapter *adap = from_timer(adap, t, flower_stats_timer);\n\n\tschedule_work(&adap->flower_stats_work);\n}\n\nint cxgb4_tc_flower_stats(struct net_device *dev,\n\t\t\t  struct flow_cls_offload *cls)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\tstruct ch_tc_flower_stats *ofld_stats;\n\tstruct ch_tc_flower_entry *ch_flower;\n\tu64 packets;\n\tu64 bytes;\n\tint ret;\n\n\tch_flower = ch_flower_lookup(adap, cls->cookie);\n\tif (!ch_flower) {\n\t\tret = -ENOENT;\n\t\tgoto err;\n\t}\n\n\tret = cxgb4_get_filter_counters(dev, ch_flower->filter_id,\n\t\t\t\t\t&packets, &bytes,\n\t\t\t\t\tch_flower->fs.hash);\n\tif (ret < 0)\n\t\tgoto err;\n\n\tspin_lock_bh(&ch_flower->lock);\n\tofld_stats = &ch_flower->stats;\n\tif (ofld_stats->packet_count != packets) {\n\t\tif (ofld_stats->prev_packet_count != packets)\n\t\t\tofld_stats->last_used = jiffies;\n\t\tflow_stats_update(&cls->stats, bytes - ofld_stats->byte_count,\n\t\t\t\t  packets - ofld_stats->packet_count, 0,\n\t\t\t\t  ofld_stats->last_used,\n\t\t\t\t  FLOW_ACTION_HW_STATS_IMMEDIATE);\n\n\t\tofld_stats->packet_count = packets;\n\t\tofld_stats->byte_count = bytes;\n\t\tofld_stats->prev_packet_count = packets;\n\t}\n\tspin_unlock_bh(&ch_flower->lock);\n\treturn 0;\n\nerr:\n\treturn ret;\n}\n\nstatic const struct rhashtable_params cxgb4_tc_flower_ht_params = {\n\t.nelem_hint = 384,\n\t.head_offset = offsetof(struct ch_tc_flower_entry, node),\n\t.key_offset = offsetof(struct ch_tc_flower_entry, tc_flower_cookie),\n\t.key_len = sizeof(((struct ch_tc_flower_entry *)0)->tc_flower_cookie),\n\t.max_size = 524288,\n\t.min_size = 512,\n\t.automatic_shrinking = true\n};\n\nint cxgb4_init_tc_flower(struct adapter *adap)\n{\n\tint ret;\n\n\tif (adap->tc_flower_initialized)\n\t\treturn -EEXIST;\n\n\tadap->flower_ht_params = cxgb4_tc_flower_ht_params;\n\tret = rhashtable_init(&adap->flower_tbl, &adap->flower_ht_params);\n\tif (ret)\n\t\treturn ret;\n\n\tINIT_WORK(&adap->flower_stats_work, ch_flower_stats_handler);\n\ttimer_setup(&adap->flower_stats_timer, ch_flower_stats_cb, 0);\n\tmod_timer(&adap->flower_stats_timer, jiffies + STATS_CHECK_PERIOD);\n\tadap->tc_flower_initialized = true;\n\treturn 0;\n}\n\nvoid cxgb4_cleanup_tc_flower(struct adapter *adap)\n{\n\tif (!adap->tc_flower_initialized)\n\t\treturn;\n\n\tif (adap->flower_stats_timer.function)\n\t\ttimer_shutdown_sync(&adap->flower_stats_timer);\n\tcancel_work_sync(&adap->flower_stats_work);\n\trhashtable_destroy(&adap->flower_tbl);\n\tadap->tc_flower_initialized = false;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}