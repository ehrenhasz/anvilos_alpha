{
  "module_name": "cxgb4_uld.h",
  "hash_id": "ebc665adc0df28ff51a2f28ab80115c6bbeb355e74fa9a9c642e4f3441ca792a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/chelsio/cxgb4/cxgb4_uld.h",
  "human_readable_source": " \n\n#ifndef __CXGB4_ULD_H\n#define __CXGB4_ULD_H\n\n#include <linux/cache.h>\n#include <linux/spinlock.h>\n#include <linux/skbuff.h>\n#include <linux/inetdevice.h>\n#include <linux/atomic.h>\n#include <net/tls.h>\n#include \"cxgb4.h\"\n\n#define MAX_ULD_QSETS 16\n#define MAX_ULD_NPORTS 4\n\n \n#define MAX_IMM_ULPTX_WR_LEN (32 + 8 + 256 + 8)\n\n \nenum {\n\tCPL_PRIORITY_DATA     = 0,   \n\tCPL_PRIORITY_SETUP    = 1,   \n\tCPL_PRIORITY_TEARDOWN = 0,   \n\tCPL_PRIORITY_LISTEN   = 1,   \n\tCPL_PRIORITY_ACK      = 1,   \n\tCPL_PRIORITY_CONTROL  = 1    \n};\n\n#define INIT_TP_WR(w, tid) do { \\\n\t(w)->wr.wr_hi = htonl(FW_WR_OP_V(FW_TP_WR) | \\\n\t\t\t      FW_WR_IMMDLEN_V(sizeof(*w) - sizeof(w->wr))); \\\n\t(w)->wr.wr_mid = htonl(FW_WR_LEN16_V(DIV_ROUND_UP(sizeof(*w), 16)) | \\\n\t\t\t       FW_WR_FLOWID_V(tid)); \\\n\t(w)->wr.wr_lo = cpu_to_be64(0); \\\n} while (0)\n\n#define INIT_TP_WR_CPL(w, cpl, tid) do { \\\n\tINIT_TP_WR(w, tid); \\\n\tOPCODE_TID(w) = htonl(MK_OPCODE_TID(cpl, tid)); \\\n} while (0)\n\n#define INIT_ULPTX_WR(w, wrlen, atomic, tid) do { \\\n\t(w)->wr.wr_hi = htonl(FW_WR_OP_V(FW_ULPTX_WR) | \\\n\t\t\t      FW_WR_ATOMIC_V(atomic)); \\\n\t(w)->wr.wr_mid = htonl(FW_WR_LEN16_V(DIV_ROUND_UP(wrlen, 16)) | \\\n\t\t\t       FW_WR_FLOWID_V(tid)); \\\n\t(w)->wr.wr_lo = cpu_to_be64(0); \\\n} while (0)\n\n \n#define CXGB4_MSG_AN ((void *)1)\n#define TX_ULD(uld)(((uld) != CXGB4_ULD_CRYPTO) ? CXGB4_TX_OFLD :\\\n\t\t      CXGB4_TX_CRYPTO)\n\nstruct serv_entry {\n\tvoid *data;\n};\n\nunion aopen_entry {\n\tvoid *data;\n\tunion aopen_entry *next;\n};\n\nstruct eotid_entry {\n\tvoid *data;\n};\n\n \nstruct tid_info {\n\tvoid **tid_tab;\n\tunsigned int tid_base;\n\tunsigned int ntids;\n\n\tstruct serv_entry *stid_tab;\n\tunsigned long *stid_bmap;\n\tunsigned int nstids;\n\tunsigned int stid_base;\n\n\tunsigned int nhash;\n\tunsigned int hash_base;\n\n\tunion aopen_entry *atid_tab;\n\tunsigned int natids;\n\tunsigned int atid_base;\n\n\tstruct filter_entry *hpftid_tab;\n\tunsigned long *hpftid_bmap;\n\tunsigned int nhpftids;\n\tunsigned int hpftid_base;\n\n\tstruct filter_entry *ftid_tab;\n\tunsigned long *ftid_bmap;\n\tunsigned int nftids;\n\tunsigned int ftid_base;\n\tunsigned int aftid_base;\n\tunsigned int aftid_end;\n\t \n\tunsigned int sftid_base;\n\tunsigned int nsftids;\n\n\tspinlock_t atid_lock ____cacheline_aligned_in_smp;\n\tunion aopen_entry *afree;\n\tunsigned int atids_in_use;\n\n\tspinlock_t stid_lock;\n\tunsigned int stids_in_use;\n\tunsigned int v6_stids_in_use;\n\tunsigned int sftids_in_use;\n\n\t \n\tstruct eotid_entry *eotid_tab;\n\tunsigned long *eotid_bmap;\n\tunsigned int eotid_base;\n\tunsigned int neotids;\n\n\t \n\tatomic_t tids_in_use;\n\t \n\tatomic_t hash_tids_in_use;\n\tatomic_t conns_in_use;\n\t \n\tatomic_t eotids_in_use;\n\n\t \n\tspinlock_t ftid_lock;\n\n\tunsigned int tc_hash_tids_max_prio;\n};\n\nstatic inline void *lookup_tid(const struct tid_info *t, unsigned int tid)\n{\n\ttid -= t->tid_base;\n\treturn tid < t->ntids ? t->tid_tab[tid] : NULL;\n}\n\nstatic inline bool tid_out_of_range(const struct tid_info *t, unsigned int tid)\n{\n\treturn ((tid - t->tid_base) >= t->ntids);\n}\n\nstatic inline void *lookup_atid(const struct tid_info *t, unsigned int atid)\n{\n\treturn atid < t->natids ? t->atid_tab[atid].data : NULL;\n}\n\nstatic inline void *lookup_stid(const struct tid_info *t, unsigned int stid)\n{\n\t \n\tif (t->nsftids && (stid >= t->sftid_base)) {\n\t\tstid -= t->sftid_base;\n\t\tstid += t->nstids;\n\t} else {\n\t\tstid -= t->stid_base;\n\t}\n\n\treturn stid < (t->nstids + t->nsftids) ? t->stid_tab[stid].data : NULL;\n}\n\nstatic inline void cxgb4_insert_tid(struct tid_info *t, void *data,\n\t\t\t\t    unsigned int tid, unsigned short family)\n{\n\tt->tid_tab[tid - t->tid_base] = data;\n\tif (t->hash_base && (tid >= t->hash_base)) {\n\t\tif (family == AF_INET6)\n\t\t\tatomic_add(2, &t->hash_tids_in_use);\n\t\telse\n\t\t\tatomic_inc(&t->hash_tids_in_use);\n\t} else {\n\t\tif (family == AF_INET6)\n\t\t\tatomic_add(2, &t->tids_in_use);\n\t\telse\n\t\t\tatomic_inc(&t->tids_in_use);\n\t}\n\tatomic_inc(&t->conns_in_use);\n}\n\nstatic inline struct eotid_entry *cxgb4_lookup_eotid(struct tid_info *t,\n\t\t\t\t\t\t     u32 eotid)\n{\n\treturn eotid < t->neotids ? &t->eotid_tab[eotid] : NULL;\n}\n\nstatic inline int cxgb4_get_free_eotid(struct tid_info *t)\n{\n\tint eotid;\n\n\teotid = find_first_zero_bit(t->eotid_bmap, t->neotids);\n\tif (eotid >= t->neotids)\n\t\teotid = -1;\n\n\treturn eotid;\n}\n\nstatic inline void cxgb4_alloc_eotid(struct tid_info *t, u32 eotid, void *data)\n{\n\tset_bit(eotid, t->eotid_bmap);\n\tt->eotid_tab[eotid].data = data;\n\tatomic_inc(&t->eotids_in_use);\n}\n\nstatic inline void cxgb4_free_eotid(struct tid_info *t, u32 eotid)\n{\n\tclear_bit(eotid, t->eotid_bmap);\n\tt->eotid_tab[eotid].data = NULL;\n\tatomic_dec(&t->eotids_in_use);\n}\n\nint cxgb4_alloc_atid(struct tid_info *t, void *data);\nint cxgb4_alloc_stid(struct tid_info *t, int family, void *data);\nint cxgb4_alloc_sftid(struct tid_info *t, int family, void *data);\nvoid cxgb4_free_atid(struct tid_info *t, unsigned int atid);\nvoid cxgb4_free_stid(struct tid_info *t, unsigned int stid, int family);\nvoid cxgb4_remove_tid(struct tid_info *t, unsigned int qid, unsigned int tid,\n\t\t      unsigned short family);\nstruct in6_addr;\n\nint cxgb4_create_server(const struct net_device *dev, unsigned int stid,\n\t\t\t__be32 sip, __be16 sport, __be16 vlan,\n\t\t\tunsigned int queue);\nint cxgb4_create_server6(const struct net_device *dev, unsigned int stid,\n\t\t\t const struct in6_addr *sip, __be16 sport,\n\t\t\t unsigned int queue);\nint cxgb4_remove_server(const struct net_device *dev, unsigned int stid,\n\t\t\tunsigned int queue, bool ipv6);\nint cxgb4_create_server_filter(const struct net_device *dev, unsigned int stid,\n\t\t\t       __be32 sip, __be16 sport, __be16 vlan,\n\t\t\t       unsigned int queue,\n\t\t\t       unsigned char port, unsigned char mask);\nint cxgb4_remove_server_filter(const struct net_device *dev, unsigned int stid,\n\t\t\t       unsigned int queue, bool ipv6);\n\n \nstruct filter_ctx {\n\tstruct completion completion;\t \n\tvoid *closure;\t\t\t \n\tint result;\t\t\t \n\tu32 tid;\t\t\t \n};\n\nstruct chcr_ktls {\n\trefcount_t ktls_refcount;\n};\n\nstruct ch_filter_specification;\n\nint cxgb4_get_free_ftid(struct net_device *dev, u8 family, bool hash_en,\n\t\t\tu32 tc_prio);\nint __cxgb4_set_filter(struct net_device *dev, int filter_id,\n\t\t       struct ch_filter_specification *fs,\n\t\t       struct filter_ctx *ctx);\nint __cxgb4_del_filter(struct net_device *dev, int filter_id,\n\t\t       struct ch_filter_specification *fs,\n\t\t       struct filter_ctx *ctx);\nint cxgb4_set_filter(struct net_device *dev, int filter_id,\n\t\t     struct ch_filter_specification *fs);\nint cxgb4_del_filter(struct net_device *dev, int filter_id,\n\t\t     struct ch_filter_specification *fs);\nint cxgb4_get_filter_counters(struct net_device *dev, unsigned int fidx,\n\t\t\t      u64 *hitcnt, u64 *bytecnt, bool hash);\n\nstatic inline void set_wr_txq(struct sk_buff *skb, int prio, int queue)\n{\n\tskb_set_queue_mapping(skb, (queue << 1) | prio);\n}\n\nenum cxgb4_uld {\n\tCXGB4_ULD_INIT,\n\tCXGB4_ULD_RDMA,\n\tCXGB4_ULD_ISCSI,\n\tCXGB4_ULD_ISCSIT,\n\tCXGB4_ULD_CRYPTO,\n\tCXGB4_ULD_IPSEC,\n\tCXGB4_ULD_TLS,\n\tCXGB4_ULD_KTLS,\n\tCXGB4_ULD_MAX\n};\n\nenum cxgb4_tx_uld {\n\tCXGB4_TX_OFLD,\n\tCXGB4_TX_CRYPTO,\n\tCXGB4_TX_MAX\n};\n\nenum cxgb4_txq_type {\n\tCXGB4_TXQ_ETH,\n\tCXGB4_TXQ_ULD,\n\tCXGB4_TXQ_CTRL,\n\tCXGB4_TXQ_MAX\n};\n\nenum cxgb4_state {\n\tCXGB4_STATE_UP,\n\tCXGB4_STATE_START_RECOVERY,\n\tCXGB4_STATE_DOWN,\n\tCXGB4_STATE_DETACH,\n\tCXGB4_STATE_FATAL_ERROR\n};\n\nenum cxgb4_control {\n\tCXGB4_CONTROL_DB_FULL,\n\tCXGB4_CONTROL_DB_EMPTY,\n\tCXGB4_CONTROL_DB_DROP,\n};\n\nstruct adapter;\nstruct pci_dev;\nstruct l2t_data;\nstruct net_device;\nstruct pkt_gl;\nstruct tp_tcp_stats;\nstruct t4_lro_mgr;\n\nstruct cxgb4_range {\n\tunsigned int start;\n\tunsigned int size;\n};\n\nstruct cxgb4_virt_res {                       \n\tstruct cxgb4_range ddp;\n\tstruct cxgb4_range iscsi;\n\tstruct cxgb4_range stag;\n\tstruct cxgb4_range rq;\n\tstruct cxgb4_range srq;\n\tstruct cxgb4_range pbl;\n\tstruct cxgb4_range qp;\n\tstruct cxgb4_range cq;\n\tstruct cxgb4_range ocq;\n\tstruct cxgb4_range key;\n\tunsigned int ncrypto_fc;\n\tstruct cxgb4_range ppod_edram;\n};\n\n#if IS_ENABLED(CONFIG_CHELSIO_TLS_DEVICE)\nstruct ch_ktls_port_stats_debug {\n\tatomic64_t ktls_tx_connection_open;\n\tatomic64_t ktls_tx_connection_fail;\n\tatomic64_t ktls_tx_connection_close;\n\tatomic64_t ktls_tx_encrypted_packets;\n\tatomic64_t ktls_tx_encrypted_bytes;\n\tatomic64_t ktls_tx_ctx;\n\tatomic64_t ktls_tx_ooo;\n\tatomic64_t ktls_tx_skip_no_sync_data;\n\tatomic64_t ktls_tx_drop_no_sync_data;\n\tatomic64_t ktls_tx_drop_bypass_req;\n};\n\nstruct ch_ktls_stats_debug {\n\tstruct ch_ktls_port_stats_debug ktls_port[MAX_ULD_NPORTS];\n\tatomic64_t ktls_tx_send_records;\n\tatomic64_t ktls_tx_end_pkts;\n\tatomic64_t ktls_tx_start_pkts;\n\tatomic64_t ktls_tx_middle_pkts;\n\tatomic64_t ktls_tx_retransmit_pkts;\n\tatomic64_t ktls_tx_complete_pkts;\n\tatomic64_t ktls_tx_trimmed_pkts;\n\tatomic64_t ktls_tx_fallback;\n};\n#endif\n\nstruct chcr_stats_debug {\n\tatomic_t cipher_rqst;\n\tatomic_t digest_rqst;\n\tatomic_t aead_rqst;\n\tatomic_t complete;\n\tatomic_t error;\n\tatomic_t fallback;\n\tatomic_t tls_pdu_tx;\n\tatomic_t tls_pdu_rx;\n\tatomic_t tls_key;\n};\n\n#if IS_ENABLED(CONFIG_CHELSIO_IPSEC_INLINE)\nstruct ch_ipsec_stats_debug {\n\tatomic_t ipsec_cnt;\n};\n#endif\n\n#define OCQ_WIN_OFFSET(pdev, vres) \\\n\t(pci_resource_len((pdev), 2) - roundup_pow_of_two((vres)->ocq.size))\n\n \nstruct cxgb4_lld_info {\n\tstruct pci_dev *pdev;                 \n\tstruct l2t_data *l2t;                 \n\tstruct tid_info *tids;                \n\tstruct net_device **ports;            \n\tconst struct cxgb4_virt_res *vr;      \n\tconst unsigned short *mtus;           \n\tconst unsigned short *rxq_ids;        \n\tconst unsigned short *ciq_ids;        \n\tunsigned short nrxq;                  \n\tunsigned short ntxq;                  \n\tunsigned short nciq;\t\t      \n\tunsigned char nchan:4;                \n\tunsigned char nports:4;               \n\tunsigned char wr_cred;                \n\tunsigned char adapter_type;           \n\tunsigned char fw_api_ver;             \n\tunsigned char crypto;                 \n\tunsigned int fw_vers;                 \n\tunsigned int iscsi_iolen;             \n\tunsigned int cclk_ps;                 \n\tunsigned short udb_density;           \n\tunsigned short ucq_density;           \n\tunsigned int sge_host_page_size;      \n\tunsigned short filt_mode;             \n\tunsigned short tx_modq[NCHAN];        \n\t\t\t\t\t      \n\tvoid __iomem *gts_reg;                \n\tvoid __iomem *db_reg;                 \n\tint dbfifo_int_thresh;\t\t      \n\tunsigned int sge_ingpadboundary;      \n\tunsigned int sge_egrstatuspagesize;   \n\tunsigned int sge_pktshift;            \n\t\t\t\t\t      \n\tunsigned int pf;\t\t      \n\tbool enable_fw_ofld_conn;             \n\t\t\t\t\t      \n\tunsigned int max_ordird_qp;           \n\tunsigned int max_ird_adapter;         \n\tbool ulptx_memwrite_dsgl;             \n\tunsigned int iscsi_tagmask;\t      \n\tunsigned int iscsi_pgsz_order;\t      \n\tunsigned int iscsi_llimit;\t      \n\tunsigned int ulp_crypto;              \n\tvoid **iscsi_ppm;\t\t      \n\tint nodeid;\t\t\t      \n\tbool fr_nsmr_tpte_wr_support;\t      \n\tbool write_w_imm_support;          \n\tbool write_cmpl_support;              \n};\n\nstruct cxgb4_uld_info {\n\tchar name[IFNAMSIZ];\n\tvoid *handle;\n\tunsigned int nrxq;\n\tunsigned int rxq_size;\n\tunsigned int ntxq;\n\tbool ciq;\n\tbool lro;\n\tvoid *(*add)(const struct cxgb4_lld_info *p);\n\tint (*rx_handler)(void *handle, const __be64 *rsp,\n\t\t\t  const struct pkt_gl *gl);\n\tint (*state_change)(void *handle, enum cxgb4_state new_state);\n\tint (*control)(void *handle, enum cxgb4_control control, ...);\n\tint (*lro_rx_handler)(void *handle, const __be64 *rsp,\n\t\t\t      const struct pkt_gl *gl,\n\t\t\t      struct t4_lro_mgr *lro_mgr,\n\t\t\t      struct napi_struct *napi);\n\tvoid (*lro_flush)(struct t4_lro_mgr *);\n\tint (*tx_handler)(struct sk_buff *skb, struct net_device *dev);\n#if IS_ENABLED(CONFIG_CHELSIO_TLS_DEVICE)\n\tconst struct tlsdev_ops *tlsdev_ops;\n#endif\n#if IS_ENABLED(CONFIG_XFRM_OFFLOAD)\n\tconst struct xfrmdev_ops *xfrmdev_ops;\n#endif\n};\n\nvoid cxgb4_uld_enable(struct adapter *adap);\nvoid cxgb4_register_uld(enum cxgb4_uld type, const struct cxgb4_uld_info *p);\nint cxgb4_unregister_uld(enum cxgb4_uld type);\nint cxgb4_ofld_send(struct net_device *dev, struct sk_buff *skb);\nint cxgb4_immdata_send(struct net_device *dev, unsigned int idx,\n\t\t       const void *src, unsigned int len);\nint cxgb4_crypto_send(struct net_device *dev, struct sk_buff *skb);\nunsigned int cxgb4_dbfifo_count(const struct net_device *dev, int lpfifo);\nunsigned int cxgb4_port_chan(const struct net_device *dev);\nunsigned int cxgb4_port_e2cchan(const struct net_device *dev);\nunsigned int cxgb4_port_viid(const struct net_device *dev);\nunsigned int cxgb4_tp_smt_idx(enum chip_type chip, unsigned int viid);\nunsigned int cxgb4_port_idx(const struct net_device *dev);\nunsigned int cxgb4_best_mtu(const unsigned short *mtus, unsigned short mtu,\n\t\t\t    unsigned int *idx);\nunsigned int cxgb4_best_aligned_mtu(const unsigned short *mtus,\n\t\t\t\t    unsigned short header_size,\n\t\t\t\t    unsigned short data_size_max,\n\t\t\t\t    unsigned short data_size_align,\n\t\t\t\t    unsigned int *mtu_idxp);\nvoid cxgb4_get_tcp_stats(struct pci_dev *pdev, struct tp_tcp_stats *v4,\n\t\t\t struct tp_tcp_stats *v6);\nvoid cxgb4_iscsi_init(struct net_device *dev, unsigned int tag_mask,\n\t\t      const unsigned int *pgsz_order);\nstruct sk_buff *cxgb4_pktgl_to_skb(const struct pkt_gl *gl,\n\t\t\t\t   unsigned int skb_len, unsigned int pull_len);\nint cxgb4_sync_txq_pidx(struct net_device *dev, u16 qid, u16 pidx, u16 size);\nint cxgb4_flush_eq_cache(struct net_device *dev);\nint cxgb4_read_tpte(struct net_device *dev, u32 stag, __be32 *tpte);\nu64 cxgb4_read_sge_timestamp(struct net_device *dev);\n\nenum cxgb4_bar2_qtype { CXGB4_BAR2_QTYPE_EGRESS, CXGB4_BAR2_QTYPE_INGRESS };\nint cxgb4_bar2_sge_qregs(struct net_device *dev,\n\t\t\t unsigned int qid,\n\t\t\t enum cxgb4_bar2_qtype qtype,\n\t\t\t int user,\n\t\t\t u64 *pbar2_qoffset,\n\t\t\t unsigned int *pbar2_qid);\n\n#endif   \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}