{
  "module_name": "l2t.c",
  "hash_id": "7349b9940dab144f5f751fd530efbf7156d58bade0a916576604315d05261b33",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/chelsio/cxgb4/l2t.c",
  "human_readable_source": " \n\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include <linux/if.h>\n#include <linux/if_vlan.h>\n#include <linux/jhash.h>\n#include <linux/module.h>\n#include <linux/debugfs.h>\n#include <linux/seq_file.h>\n#include <net/neighbour.h>\n#include \"cxgb4.h\"\n#include \"l2t.h\"\n#include \"t4_msg.h\"\n#include \"t4fw_api.h\"\n#include \"t4_regs.h\"\n#include \"t4_values.h\"\n\n \n#define SYNC_WR_S    12\n#define SYNC_WR_V(x) ((x) << SYNC_WR_S)\n#define SYNC_WR_F    SYNC_WR_V(1)\n\nstruct l2t_data {\n\tunsigned int l2t_start;      \n\tunsigned int l2t_size;       \n\trwlock_t lock;\n\tatomic_t nfree;              \n\tstruct l2t_entry *rover;     \n\tstruct l2t_entry l2tab[];   \n};\n\nstatic inline unsigned int vlan_prio(const struct l2t_entry *e)\n{\n\treturn e->vlan >> VLAN_PRIO_SHIFT;\n}\n\nstatic inline void l2t_hold(struct l2t_data *d, struct l2t_entry *e)\n{\n\tif (atomic_add_return(1, &e->refcnt) == 1)   \n\t\tatomic_dec(&d->nfree);\n}\n\n \nenum {\n\tL2T_MIN_HASH_BUCKETS = 2,\n};\n\nstatic inline unsigned int arp_hash(struct l2t_data *d, const u32 *key,\n\t\t\t\t    int ifindex)\n{\n\tunsigned int l2t_size_half = d->l2t_size / 2;\n\n\treturn jhash_2words(*key, ifindex, 0) % l2t_size_half;\n}\n\nstatic inline unsigned int ipv6_hash(struct l2t_data *d, const u32 *key,\n\t\t\t\t     int ifindex)\n{\n\tunsigned int l2t_size_half = d->l2t_size / 2;\n\tu32 xor = key[0] ^ key[1] ^ key[2] ^ key[3];\n\n\treturn (l2t_size_half +\n\t\t(jhash_2words(xor, ifindex, 0) % l2t_size_half));\n}\n\nstatic unsigned int addr_hash(struct l2t_data *d, const u32 *addr,\n\t\t\t      int addr_len, int ifindex)\n{\n\treturn addr_len == 4 ? arp_hash(d, addr, ifindex) :\n\t\t\t       ipv6_hash(d, addr, ifindex);\n}\n\n \nstatic int addreq(const struct l2t_entry *e, const u32 *addr)\n{\n\tif (e->v6)\n\t\treturn (e->addr[0] ^ addr[0]) | (e->addr[1] ^ addr[1]) |\n\t\t       (e->addr[2] ^ addr[2]) | (e->addr[3] ^ addr[3]);\n\treturn e->addr[0] ^ addr[0];\n}\n\nstatic void neigh_replace(struct l2t_entry *e, struct neighbour *n)\n{\n\tneigh_hold(n);\n\tif (e->neigh)\n\t\tneigh_release(e->neigh);\n\te->neigh = n;\n}\n\n \nstatic int write_l2e(struct adapter *adap, struct l2t_entry *e, int sync)\n{\n\tstruct l2t_data *d = adap->l2t;\n\tunsigned int l2t_idx = e->idx + d->l2t_start;\n\tstruct sk_buff *skb;\n\tstruct cpl_l2t_write_req *req;\n\n\tskb = alloc_skb(sizeof(*req), GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\treq = __skb_put(skb, sizeof(*req));\n\tINIT_TP_WR(req, 0);\n\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_L2T_WRITE_REQ,\n\t\t\t\t\tl2t_idx | (sync ? SYNC_WR_F : 0) |\n\t\t\t\t\tTID_QID_V(adap->sge.fw_evtq.abs_id)));\n\treq->params = htons(L2T_W_PORT_V(e->lport) | L2T_W_NOREPLY_V(!sync));\n\treq->l2t_idx = htons(l2t_idx);\n\treq->vlan = htons(e->vlan);\n\tif (e->neigh && !(e->neigh->dev->flags & IFF_LOOPBACK))\n\t\tmemcpy(e->dmac, e->neigh->ha, sizeof(e->dmac));\n\tmemcpy(req->dst_mac, e->dmac, sizeof(req->dst_mac));\n\n\tt4_mgmt_tx(adap, skb);\n\n\tif (sync && e->state != L2T_STATE_SWITCHING)\n\t\te->state = L2T_STATE_SYNC_WRITE;\n\treturn 0;\n}\n\n \nstatic void send_pending(struct adapter *adap, struct l2t_entry *e)\n{\n\tstruct sk_buff *skb;\n\n\twhile ((skb = __skb_dequeue(&e->arpq)) != NULL)\n\t\tt4_ofld_send(adap, skb);\n}\n\n \nvoid do_l2t_write_rpl(struct adapter *adap, const struct cpl_l2t_write_rpl *rpl)\n{\n\tstruct l2t_data *d = adap->l2t;\n\tunsigned int tid = GET_TID(rpl);\n\tunsigned int l2t_idx = tid % L2T_SIZE;\n\n\tif (unlikely(rpl->status != CPL_ERR_NONE)) {\n\t\tdev_err(adap->pdev_dev,\n\t\t\t\"Unexpected L2T_WRITE_RPL status %u for entry %u\\n\",\n\t\t\trpl->status, l2t_idx);\n\t\treturn;\n\t}\n\n\tif (tid & SYNC_WR_F) {\n\t\tstruct l2t_entry *e = &d->l2tab[l2t_idx - d->l2t_start];\n\n\t\tspin_lock(&e->lock);\n\t\tif (e->state != L2T_STATE_SWITCHING) {\n\t\t\tsend_pending(adap, e);\n\t\t\te->state = (e->neigh->nud_state & NUD_STALE) ?\n\t\t\t\t\tL2T_STATE_STALE : L2T_STATE_VALID;\n\t\t}\n\t\tspin_unlock(&e->lock);\n\t}\n}\n\n \nstatic inline void arpq_enqueue(struct l2t_entry *e, struct sk_buff *skb)\n{\n\t__skb_queue_tail(&e->arpq, skb);\n}\n\nint cxgb4_l2t_send(struct net_device *dev, struct sk_buff *skb,\n\t\t   struct l2t_entry *e)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\nagain:\n\tswitch (e->state) {\n\tcase L2T_STATE_STALE:      \n\t\tneigh_event_send(e->neigh, NULL);\n\t\tspin_lock_bh(&e->lock);\n\t\tif (e->state == L2T_STATE_STALE)\n\t\t\te->state = L2T_STATE_VALID;\n\t\tspin_unlock_bh(&e->lock);\n\t\tfallthrough;\n\tcase L2T_STATE_VALID:      \n\t\treturn t4_ofld_send(adap, skb);\n\tcase L2T_STATE_RESOLVING:\n\tcase L2T_STATE_SYNC_WRITE:\n\t\tspin_lock_bh(&e->lock);\n\t\tif (e->state != L2T_STATE_SYNC_WRITE &&\n\t\t    e->state != L2T_STATE_RESOLVING) {\n\t\t\tspin_unlock_bh(&e->lock);\n\t\t\tgoto again;\n\t\t}\n\t\tarpq_enqueue(e, skb);\n\t\tspin_unlock_bh(&e->lock);\n\n\t\tif (e->state == L2T_STATE_RESOLVING &&\n\t\t    !neigh_event_send(e->neigh, NULL)) {\n\t\t\tspin_lock_bh(&e->lock);\n\t\t\tif (e->state == L2T_STATE_RESOLVING &&\n\t\t\t    !skb_queue_empty(&e->arpq))\n\t\t\t\twrite_l2e(adap, e, 1);\n\t\t\tspin_unlock_bh(&e->lock);\n\t\t}\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(cxgb4_l2t_send);\n\n \nstatic struct l2t_entry *alloc_l2e(struct l2t_data *d)\n{\n\tstruct l2t_entry *end, *e, **p;\n\n\tif (!atomic_read(&d->nfree))\n\t\treturn NULL;\n\n\t \n\tfor (e = d->rover, end = &d->l2tab[d->l2t_size]; e != end; ++e)\n\t\tif (atomic_read(&e->refcnt) == 0)\n\t\t\tgoto found;\n\n\tfor (e = d->l2tab; atomic_read(&e->refcnt); ++e)\n\t\t;\nfound:\n\td->rover = e + 1;\n\tatomic_dec(&d->nfree);\n\n\t \n\tif (e->state < L2T_STATE_SWITCHING)\n\t\tfor (p = &d->l2tab[e->hash].first; *p; p = &(*p)->next)\n\t\t\tif (*p == e) {\n\t\t\t\t*p = e->next;\n\t\t\t\te->next = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\te->state = L2T_STATE_UNUSED;\n\treturn e;\n}\n\nstatic struct l2t_entry *find_or_alloc_l2e(struct l2t_data *d, u16 vlan,\n\t\t\t\t\t   u8 port, u8 *dmac)\n{\n\tstruct l2t_entry *end, *e, **p;\n\tstruct l2t_entry *first_free = NULL;\n\n\tfor (e = &d->l2tab[0], end = &d->l2tab[d->l2t_size]; e != end; ++e) {\n\t\tif (atomic_read(&e->refcnt) == 0) {\n\t\t\tif (!first_free)\n\t\t\t\tfirst_free = e;\n\t\t} else {\n\t\t\tif (e->state == L2T_STATE_SWITCHING) {\n\t\t\t\tif (ether_addr_equal(e->dmac, dmac) &&\n\t\t\t\t    (e->vlan == vlan) && (e->lport == port))\n\t\t\t\t\tgoto exists;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (first_free) {\n\t\te = first_free;\n\t\tgoto found;\n\t}\n\n\treturn NULL;\n\nfound:\n\t \n\tif (e->state < L2T_STATE_SWITCHING)\n\t\tfor (p = &d->l2tab[e->hash].first; *p; p = &(*p)->next)\n\t\t\tif (*p == e) {\n\t\t\t\t*p = e->next;\n\t\t\t\te->next = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\te->state = L2T_STATE_UNUSED;\n\nexists:\n\treturn e;\n}\n\n \nstatic void _t4_l2e_free(struct l2t_entry *e)\n{\n\tstruct l2t_data *d;\n\n\tif (atomic_read(&e->refcnt) == 0) {   \n\t\tif (e->neigh) {\n\t\t\tneigh_release(e->neigh);\n\t\t\te->neigh = NULL;\n\t\t}\n\t\t__skb_queue_purge(&e->arpq);\n\t}\n\n\td = container_of(e, struct l2t_data, l2tab[e->idx]);\n\tatomic_inc(&d->nfree);\n}\n\n \nstatic void t4_l2e_free(struct l2t_entry *e)\n{\n\tstruct l2t_data *d;\n\n\tspin_lock_bh(&e->lock);\n\tif (atomic_read(&e->refcnt) == 0) {   \n\t\tif (e->neigh) {\n\t\t\tneigh_release(e->neigh);\n\t\t\te->neigh = NULL;\n\t\t}\n\t\t__skb_queue_purge(&e->arpq);\n\t}\n\tspin_unlock_bh(&e->lock);\n\n\td = container_of(e, struct l2t_data, l2tab[e->idx]);\n\tatomic_inc(&d->nfree);\n}\n\nvoid cxgb4_l2t_release(struct l2t_entry *e)\n{\n\tif (atomic_dec_and_test(&e->refcnt))\n\t\tt4_l2e_free(e);\n}\nEXPORT_SYMBOL(cxgb4_l2t_release);\n\n \nstatic void reuse_entry(struct l2t_entry *e, struct neighbour *neigh)\n{\n\tunsigned int nud_state;\n\n\tspin_lock(&e->lock);                 \n\tif (neigh != e->neigh)\n\t\tneigh_replace(e, neigh);\n\tnud_state = neigh->nud_state;\n\tif (memcmp(e->dmac, neigh->ha, sizeof(e->dmac)) ||\n\t    !(nud_state & NUD_VALID))\n\t\te->state = L2T_STATE_RESOLVING;\n\telse if (nud_state & NUD_CONNECTED)\n\t\te->state = L2T_STATE_VALID;\n\telse\n\t\te->state = L2T_STATE_STALE;\n\tspin_unlock(&e->lock);\n}\n\nstruct l2t_entry *cxgb4_l2t_get(struct l2t_data *d, struct neighbour *neigh,\n\t\t\t\tconst struct net_device *physdev,\n\t\t\t\tunsigned int priority)\n{\n\tu8 lport;\n\tu16 vlan;\n\tstruct l2t_entry *e;\n\tunsigned int addr_len = neigh->tbl->key_len;\n\tu32 *addr = (u32 *)neigh->primary_key;\n\tint ifidx = neigh->dev->ifindex;\n\tint hash = addr_hash(d, addr, addr_len, ifidx);\n\n\tif (neigh->dev->flags & IFF_LOOPBACK)\n\t\tlport = netdev2pinfo(physdev)->tx_chan + 4;\n\telse\n\t\tlport = netdev2pinfo(physdev)->lport;\n\n\tif (is_vlan_dev(neigh->dev)) {\n\t\tvlan = vlan_dev_vlan_id(neigh->dev);\n\t\tvlan |= vlan_dev_get_egress_qos_mask(neigh->dev, priority);\n\t} else {\n\t\tvlan = VLAN_NONE;\n\t}\n\n\twrite_lock_bh(&d->lock);\n\tfor (e = d->l2tab[hash].first; e; e = e->next)\n\t\tif (!addreq(e, addr) && e->ifindex == ifidx &&\n\t\t    e->vlan == vlan && e->lport == lport) {\n\t\t\tl2t_hold(d, e);\n\t\t\tif (atomic_read(&e->refcnt) == 1)\n\t\t\t\treuse_entry(e, neigh);\n\t\t\tgoto done;\n\t\t}\n\n\t \n\te = alloc_l2e(d);\n\tif (e) {\n\t\tspin_lock(&e->lock);           \n\t\te->state = L2T_STATE_RESOLVING;\n\t\tif (neigh->dev->flags & IFF_LOOPBACK)\n\t\t\tmemcpy(e->dmac, physdev->dev_addr, sizeof(e->dmac));\n\t\tmemcpy(e->addr, addr, addr_len);\n\t\te->ifindex = ifidx;\n\t\te->hash = hash;\n\t\te->lport = lport;\n\t\te->v6 = addr_len == 16;\n\t\tatomic_set(&e->refcnt, 1);\n\t\tneigh_replace(e, neigh);\n\t\te->vlan = vlan;\n\t\te->next = d->l2tab[hash].first;\n\t\td->l2tab[hash].first = e;\n\t\tspin_unlock(&e->lock);\n\t}\ndone:\n\twrite_unlock_bh(&d->lock);\n\treturn e;\n}\nEXPORT_SYMBOL(cxgb4_l2t_get);\n\nu64 cxgb4_select_ntuple(struct net_device *dev,\n\t\t\tconst struct l2t_entry *l2t)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\tstruct tp_params *tp = &adap->params.tp;\n\tu64 ntuple = 0;\n\n\t \n\tif (tp->vlan_shift >= 0 && l2t->vlan != VLAN_NONE)\n\t\tntuple |= (u64)(FT_VLAN_VLD_F | l2t->vlan) << tp->vlan_shift;\n\n\tif (tp->port_shift >= 0)\n\t\tntuple |= (u64)l2t->lport << tp->port_shift;\n\n\tif (tp->protocol_shift >= 0)\n\t\tntuple |= (u64)IPPROTO_TCP << tp->protocol_shift;\n\n\tif (tp->vnic_shift >= 0 && (tp->ingress_config & VNIC_F)) {\n\t\tstruct port_info *pi = (struct port_info *)netdev_priv(dev);\n\n\t\tntuple |= (u64)(FT_VNID_ID_VF_V(pi->vin) |\n\t\t\t\tFT_VNID_ID_PF_V(adap->pf) |\n\t\t\t\tFT_VNID_ID_VLD_V(pi->vivld)) << tp->vnic_shift;\n\t}\n\n\treturn ntuple;\n}\nEXPORT_SYMBOL(cxgb4_select_ntuple);\n\n \nvoid t4_l2t_update(struct adapter *adap, struct neighbour *neigh)\n{\n\tunsigned int addr_len = neigh->tbl->key_len;\n\tu32 *addr = (u32 *) neigh->primary_key;\n\tint hash, ifidx = neigh->dev->ifindex;\n\tstruct sk_buff_head *arpq = NULL;\n\tstruct l2t_data *d = adap->l2t;\n\tstruct l2t_entry *e;\n\n\thash = addr_hash(d, addr, addr_len, ifidx);\n\tread_lock_bh(&d->lock);\n\tfor (e = d->l2tab[hash].first; e; e = e->next)\n\t\tif (!addreq(e, addr) && e->ifindex == ifidx) {\n\t\t\tspin_lock(&e->lock);\n\t\t\tif (atomic_read(&e->refcnt))\n\t\t\t\tgoto found;\n\t\t\tspin_unlock(&e->lock);\n\t\t\tbreak;\n\t\t}\n\tread_unlock_bh(&d->lock);\n\treturn;\n\n found:\n\tread_unlock(&d->lock);\n\n\tif (neigh != e->neigh)\n\t\tneigh_replace(e, neigh);\n\n\tif (e->state == L2T_STATE_RESOLVING) {\n\t\tif (neigh->nud_state & NUD_FAILED) {\n\t\t\tarpq = &e->arpq;\n\t\t} else if ((neigh->nud_state & (NUD_CONNECTED | NUD_STALE)) &&\n\t\t\t   !skb_queue_empty(&e->arpq)) {\n\t\t\twrite_l2e(adap, e, 1);\n\t\t}\n\t} else {\n\t\te->state = neigh->nud_state & NUD_CONNECTED ?\n\t\t\tL2T_STATE_VALID : L2T_STATE_STALE;\n\t\tif (memcmp(e->dmac, neigh->ha, sizeof(e->dmac)))\n\t\t\twrite_l2e(adap, e, 0);\n\t}\n\n\tif (arpq) {\n\t\tstruct sk_buff *skb;\n\n\t\t \n\t\twhile ((skb = __skb_dequeue(&e->arpq)) != NULL) {\n\t\t\tconst struct l2t_skb_cb *cb = L2T_SKB_CB(skb);\n\n\t\t\tspin_unlock(&e->lock);\n\t\t\tif (cb->arp_err_handler)\n\t\t\t\tcb->arp_err_handler(cb->handle, skb);\n\t\t\telse\n\t\t\t\tt4_ofld_send(adap, skb);\n\t\t\tspin_lock(&e->lock);\n\t\t}\n\t}\n\tspin_unlock_bh(&e->lock);\n}\n\n \nstruct l2t_entry *t4_l2t_alloc_switching(struct adapter *adap, u16 vlan,\n\t\t\t\t\t u8 port, u8 *eth_addr)\n{\n\tstruct l2t_data *d = adap->l2t;\n\tstruct l2t_entry *e;\n\tint ret;\n\n\twrite_lock_bh(&d->lock);\n\te = find_or_alloc_l2e(d, vlan, port, eth_addr);\n\tif (e) {\n\t\tspin_lock(&e->lock);           \n\t\tif (!atomic_read(&e->refcnt)) {\n\t\t\te->state = L2T_STATE_SWITCHING;\n\t\t\te->vlan = vlan;\n\t\t\te->lport = port;\n\t\t\tether_addr_copy(e->dmac, eth_addr);\n\t\t\tatomic_set(&e->refcnt, 1);\n\t\t\tret = write_l2e(adap, e, 0);\n\t\t\tif (ret < 0) {\n\t\t\t\t_t4_l2e_free(e);\n\t\t\t\tspin_unlock(&e->lock);\n\t\t\t\twrite_unlock_bh(&d->lock);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t} else {\n\t\t\tatomic_inc(&e->refcnt);\n\t\t}\n\n\t\tspin_unlock(&e->lock);\n\t}\n\twrite_unlock_bh(&d->lock);\n\treturn e;\n}\n\n \nstruct l2t_entry *cxgb4_l2t_alloc_switching(struct net_device *dev, u16 vlan,\n\t\t\t\t\t    u8 port, u8 *dmac)\n{\n\tstruct adapter *adap = netdev2adap(dev);\n\n\treturn t4_l2t_alloc_switching(adap, vlan, port, dmac);\n}\nEXPORT_SYMBOL(cxgb4_l2t_alloc_switching);\n\nstruct l2t_data *t4_init_l2t(unsigned int l2t_start, unsigned int l2t_end)\n{\n\tunsigned int l2t_size;\n\tint i;\n\tstruct l2t_data *d;\n\n\tif (l2t_start >= l2t_end || l2t_end >= L2T_SIZE)\n\t\treturn NULL;\n\tl2t_size = l2t_end - l2t_start + 1;\n\tif (l2t_size < L2T_MIN_HASH_BUCKETS)\n\t\treturn NULL;\n\n\td = kvzalloc(struct_size(d, l2tab, l2t_size), GFP_KERNEL);\n\tif (!d)\n\t\treturn NULL;\n\n\td->l2t_start = l2t_start;\n\td->l2t_size = l2t_size;\n\n\td->rover = d->l2tab;\n\tatomic_set(&d->nfree, l2t_size);\n\trwlock_init(&d->lock);\n\n\tfor (i = 0; i < d->l2t_size; ++i) {\n\t\td->l2tab[i].idx = i;\n\t\td->l2tab[i].state = L2T_STATE_UNUSED;\n\t\tspin_lock_init(&d->l2tab[i].lock);\n\t\tatomic_set(&d->l2tab[i].refcnt, 0);\n\t\tskb_queue_head_init(&d->l2tab[i].arpq);\n\t}\n\treturn d;\n}\n\nstatic inline void *l2t_get_idx(struct seq_file *seq, loff_t pos)\n{\n\tstruct l2t_data *d = seq->private;\n\n\treturn pos >= d->l2t_size ? NULL : &d->l2tab[pos];\n}\n\nstatic void *l2t_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\treturn *pos ? l2t_get_idx(seq, *pos - 1) : SEQ_START_TOKEN;\n}\n\nstatic void *l2t_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tv = l2t_get_idx(seq, *pos);\n\t++(*pos);\n\treturn v;\n}\n\nstatic void l2t_seq_stop(struct seq_file *seq, void *v)\n{\n}\n\nstatic char l2e_state(const struct l2t_entry *e)\n{\n\tswitch (e->state) {\n\tcase L2T_STATE_VALID: return 'V';\n\tcase L2T_STATE_STALE: return 'S';\n\tcase L2T_STATE_SYNC_WRITE: return 'W';\n\tcase L2T_STATE_RESOLVING:\n\t\treturn skb_queue_empty(&e->arpq) ? 'R' : 'A';\n\tcase L2T_STATE_SWITCHING: return 'X';\n\tdefault:\n\t\treturn 'U';\n\t}\n}\n\nbool cxgb4_check_l2t_valid(struct l2t_entry *e)\n{\n\tbool valid;\n\n\tspin_lock(&e->lock);\n\tvalid = (e->state == L2T_STATE_VALID);\n\tspin_unlock(&e->lock);\n\treturn valid;\n}\nEXPORT_SYMBOL(cxgb4_check_l2t_valid);\n\nstatic int l2t_seq_show(struct seq_file *seq, void *v)\n{\n\tif (v == SEQ_START_TOKEN)\n\t\tseq_puts(seq, \" Idx IP address                \"\n\t\t\t \"Ethernet address  VLAN/P LP State Users Port\\n\");\n\telse {\n\t\tchar ip[60];\n\t\tstruct l2t_data *d = seq->private;\n\t\tstruct l2t_entry *e = v;\n\n\t\tspin_lock_bh(&e->lock);\n\t\tif (e->state == L2T_STATE_SWITCHING)\n\t\t\tip[0] = '\\0';\n\t\telse\n\t\t\tsprintf(ip, e->v6 ? \"%pI6c\" : \"%pI4\", e->addr);\n\t\tseq_printf(seq, \"%4u %-25s %17pM %4d %u %2u   %c   %5u %s\\n\",\n\t\t\t   e->idx + d->l2t_start, ip, e->dmac,\n\t\t\t   e->vlan & VLAN_VID_MASK, vlan_prio(e), e->lport,\n\t\t\t   l2e_state(e), atomic_read(&e->refcnt),\n\t\t\t   e->neigh ? e->neigh->dev->name : \"\");\n\t\tspin_unlock_bh(&e->lock);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations l2t_seq_ops = {\n\t.start = l2t_seq_start,\n\t.next = l2t_seq_next,\n\t.stop = l2t_seq_stop,\n\t.show = l2t_seq_show\n};\n\nstatic int l2t_seq_open(struct inode *inode, struct file *file)\n{\n\tint rc = seq_open(file, &l2t_seq_ops);\n\n\tif (!rc) {\n\t\tstruct adapter *adap = inode->i_private;\n\t\tstruct seq_file *seq = file->private_data;\n\n\t\tseq->private = adap->l2t;\n\t}\n\treturn rc;\n}\n\nconst struct file_operations t4_l2t_fops = {\n\t.owner = THIS_MODULE,\n\t.open = l2t_seq_open,\n\t.read = seq_read,\n\t.llseek = seq_lseek,\n\t.release = seq_release,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}