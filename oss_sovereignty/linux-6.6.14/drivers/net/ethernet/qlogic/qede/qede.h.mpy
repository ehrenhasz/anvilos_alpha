{
  "module_name": "qede.h",
  "hash_id": "aefd1ce9cd676a64d7162bf5da78c35e73bd63176c878d97a43e451b4d5d1c42",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qede/qede.h",
  "human_readable_source": " \n \n\n#ifndef _QEDE_H_\n#define _QEDE_H_\n#include <linux/workqueue.h>\n#include <linux/netdevice.h>\n#include <linux/interrupt.h>\n#include <linux/bitmap.h>\n#include <linux/kernel.h>\n#include <linux/mutex.h>\n#include <linux/bpf.h>\n#include <net/xdp.h>\n#include <linux/qed/qede_rdma.h>\n#include <linux/io.h>\n#ifdef CONFIG_RFS_ACCEL\n#include <linux/cpu_rmap.h>\n#endif\n#include <linux/qed/common_hsi.h>\n#include <linux/qed/eth_common.h>\n#include <linux/qed/qed_if.h>\n#include <linux/qed/qed_chain.h>\n#include <linux/qed/qed_eth_if.h>\n\n#include <net/pkt_cls.h>\n#include <net/tc_act/tc_gact.h>\n\n#define DRV_MODULE_SYM\t\tqede\n\nstruct qede_stats_common {\n\tu64 no_buff_discards;\n\tu64 packet_too_big_discard;\n\tu64 ttl0_discard;\n\tu64 rx_ucast_bytes;\n\tu64 rx_mcast_bytes;\n\tu64 rx_bcast_bytes;\n\tu64 rx_ucast_pkts;\n\tu64 rx_mcast_pkts;\n\tu64 rx_bcast_pkts;\n\tu64 mftag_filter_discards;\n\tu64 mac_filter_discards;\n\tu64 gft_filter_drop;\n\tu64 tx_ucast_bytes;\n\tu64 tx_mcast_bytes;\n\tu64 tx_bcast_bytes;\n\tu64 tx_ucast_pkts;\n\tu64 tx_mcast_pkts;\n\tu64 tx_bcast_pkts;\n\tu64 tx_err_drop_pkts;\n\tu64 coalesced_pkts;\n\tu64 coalesced_events;\n\tu64 coalesced_aborts_num;\n\tu64 non_coalesced_pkts;\n\tu64 coalesced_bytes;\n\tu64 link_change_count;\n\tu64 ptp_skip_txts;\n\n\t \n\tu64 rx_64_byte_packets;\n\tu64 rx_65_to_127_byte_packets;\n\tu64 rx_128_to_255_byte_packets;\n\tu64 rx_256_to_511_byte_packets;\n\tu64 rx_512_to_1023_byte_packets;\n\tu64 rx_1024_to_1518_byte_packets;\n\tu64 rx_crc_errors;\n\tu64 rx_mac_crtl_frames;\n\tu64 rx_pause_frames;\n\tu64 rx_pfc_frames;\n\tu64 rx_align_errors;\n\tu64 rx_carrier_errors;\n\tu64 rx_oversize_packets;\n\tu64 rx_jabbers;\n\tu64 rx_undersize_packets;\n\tu64 rx_fragments;\n\tu64 tx_64_byte_packets;\n\tu64 tx_65_to_127_byte_packets;\n\tu64 tx_128_to_255_byte_packets;\n\tu64 tx_256_to_511_byte_packets;\n\tu64 tx_512_to_1023_byte_packets;\n\tu64 tx_1024_to_1518_byte_packets;\n\tu64 tx_pause_frames;\n\tu64 tx_pfc_frames;\n\tu64 brb_truncates;\n\tu64 brb_discards;\n\tu64 tx_mac_ctrl_frames;\n};\n\nstruct qede_stats_bb {\n\tu64 rx_1519_to_1522_byte_packets;\n\tu64 rx_1519_to_2047_byte_packets;\n\tu64 rx_2048_to_4095_byte_packets;\n\tu64 rx_4096_to_9216_byte_packets;\n\tu64 rx_9217_to_16383_byte_packets;\n\tu64 tx_1519_to_2047_byte_packets;\n\tu64 tx_2048_to_4095_byte_packets;\n\tu64 tx_4096_to_9216_byte_packets;\n\tu64 tx_9217_to_16383_byte_packets;\n\tu64 tx_lpi_entry_count;\n\tu64 tx_total_collisions;\n};\n\nstruct qede_stats_ah {\n\tu64 rx_1519_to_max_byte_packets;\n\tu64 tx_1519_to_max_byte_packets;\n};\n\nstruct qede_stats {\n\tstruct qede_stats_common common;\n\n\tunion {\n\t\tstruct qede_stats_bb bb;\n\t\tstruct qede_stats_ah ah;\n\t};\n};\n\nstruct qede_vlan {\n\tstruct list_head list;\n\tu16 vid;\n\tbool configured;\n};\n\nstruct qede_rdma_dev {\n\tstruct qedr_dev *qedr_dev;\n\tstruct list_head entry;\n\tstruct list_head rdma_event_list;\n\tstruct workqueue_struct *rdma_wq;\n\tstruct kref refcnt;\n\tstruct completion event_comp;\n\tbool exp_recovery;\n};\n\nstruct qede_ptp;\n\n#define QEDE_RFS_MAX_FLTR\t256\n\nenum qede_flags_bit {\n\tQEDE_FLAGS_IS_VF = 0,\n\tQEDE_FLAGS_LINK_REQUESTED,\n\tQEDE_FLAGS_PTP_TX_IN_PRORGESS,\n\tQEDE_FLAGS_TX_TIMESTAMPING_EN\n};\n\n#define QEDE_DUMP_MAX_ARGS 4\nenum qede_dump_cmd {\n\tQEDE_DUMP_CMD_NONE = 0,\n\tQEDE_DUMP_CMD_NVM_CFG,\n\tQEDE_DUMP_CMD_GRCDUMP,\n\tQEDE_DUMP_CMD_MAX\n};\n\nstruct qede_dump_info {\n\tenum qede_dump_cmd cmd;\n\tu8 num_args;\n\tu32 args[QEDE_DUMP_MAX_ARGS];\n};\n\nstruct qede_coalesce {\n\tbool isvalid;\n\tu16 rxc;\n\tu16 txc;\n};\n\nstruct qede_dev {\n\tstruct qed_dev\t\t\t*cdev;\n\tstruct net_device\t\t*ndev;\n\tstruct pci_dev\t\t\t*pdev;\n\tstruct devlink\t\t\t*devlink;\n\n\tu32\t\t\t\tdp_module;\n\tu8\t\t\t\tdp_level;\n\n\tunsigned long\t\t\tflags;\n#define IS_VF(edev)\t\t\ttest_bit(QEDE_FLAGS_IS_VF, \\\n\t\t\t\t\t\t &(edev)->flags)\n\n\tconst struct qed_eth_ops\t*ops;\n\tstruct qede_ptp\t\t\t*ptp;\n\tu64\t\t\t\tptp_skip_txts;\n\n\tstruct qed_dev_eth_info\t\tdev_info;\n#define QEDE_MAX_RSS_CNT(edev)\t\t((edev)->dev_info.num_queues)\n#define QEDE_MAX_TSS_CNT(edev)\t\t((edev)->dev_info.num_queues)\n#define QEDE_IS_BB(edev) \\\n\t((edev)->dev_info.common.dev_type == QED_DEV_TYPE_BB)\n#define QEDE_IS_AH(edev) \\\n\t((edev)->dev_info.common.dev_type == QED_DEV_TYPE_AH)\n\n\tstruct qede_fastpath\t\t*fp_array;\n\tstruct qede_coalesce            *coal_entry;\n\tu8\t\t\t\treq_num_tx;\n\tu8\t\t\t\tfp_num_tx;\n\tu8\t\t\t\treq_num_rx;\n\tu8\t\t\t\tfp_num_rx;\n\tu16\t\t\t\treq_queues;\n\tu16\t\t\t\tnum_queues;\n\tu16\t\t\t\ttotal_xdp_queues;\n\n#define QEDE_QUEUE_CNT(edev)\t\t((edev)->num_queues)\n#define QEDE_RSS_COUNT(edev)\t\t((edev)->num_queues - (edev)->fp_num_tx)\n#define QEDE_RX_QUEUE_IDX(edev, i)\t(i)\n#define QEDE_TSS_COUNT(edev)\t\t((edev)->num_queues - (edev)->fp_num_rx)\n\n\tstruct qed_int_info\t\tint_info;\n\n\t \n\tstruct mutex\t\t\tqede_lock;\n\tu32\t\t\t\tstate;  \n\tu16\t\t\t\trx_buf_size;\n\tu32\t\t\t\trx_copybreak;\n\n\t \n#define ETH_OVERHEAD\t\t\t(ETH_HLEN + 8 + 8)\n\t \n#define QEDE_RX_ALIGN_SHIFT\t\tmax(6, min(8, L1_CACHE_SHIFT))\n\t \n#define QEDE_FW_RX_ALIGN_END\t\t\t\t\t\\\n\tmax_t(u64, 1UL << QEDE_RX_ALIGN_SHIFT,\t\t\t\\\n\t      SKB_DATA_ALIGN(sizeof(struct skb_shared_info)))\n\n\tstruct qede_stats\t\tstats;\n\n\t \n\tu32\t\t\t\trss_params_inited;\n#define QEDE_RSS_INDIR_INITED\t\tBIT(0)\n#define QEDE_RSS_KEY_INITED\t\tBIT(1)\n#define QEDE_RSS_CAPS_INITED\t\tBIT(2)\n\n\tu16\t\t\t\trss_ind_table[128];\n\tu32\t\t\t\trss_key[10];\n\tu8\t\t\t\trss_caps;\n\n\t \n\tu16\t\t\t\tq_num_rx_buffers;\n\tu16\t\t\t\tq_num_tx_buffers;\n\n\tbool\t\t\t\tgro_disable;\n\n\tstruct list_head\t\tvlan_list;\n\tu16\t\t\t\tconfigured_vlans;\n\tu16\t\t\t\tnon_configured_vlans;\n\tbool\t\t\t\taccept_any_vlan;\n\n\tstruct delayed_work\t\tsp_task;\n\tunsigned long\t\t\tsp_flags;\n\tu16\t\t\t\tvxlan_dst_port;\n\tu16\t\t\t\tgeneve_dst_port;\n\n\tstruct qede_arfs\t\t*arfs;\n\tbool\t\t\t\twol_enabled;\n\n\tstruct qede_rdma_dev\t\trdma_info;\n\n\tstruct bpf_prog\t\t\t*xdp_prog;\n\n\tenum qed_hw_err_type\t\tlast_err_type;\n\tunsigned long\t\t\terr_flags;\n#define QEDE_ERR_IS_HANDLED\t\t31\n#define QEDE_ERR_ATTN_CLR_EN\t\t0\n#define QEDE_ERR_GET_DBG_INFO\t\t1\n#define QEDE_ERR_IS_RECOVERABLE\t\t2\n#define QEDE_ERR_WARN\t\t\t3\n\n\tstruct qede_dump_info\t\tdump_info;\n\tstruct delayed_work\t\tperiodic_task;\n\tunsigned long\t\t\tstats_coal_ticks;\n\tu32\t\t\t\tstats_coal_usecs;\n\tspinlock_t\t\t\tstats_lock;  \n};\n\nenum QEDE_STATE {\n\tQEDE_STATE_CLOSED,\n\tQEDE_STATE_OPEN,\n\tQEDE_STATE_RECOVERY,\n};\n\n#define HILO_U64(hi, lo)\t\t((((u64)(hi)) << 32) + (lo))\n\n#define\tMAX_NUM_TC\t8\n#define\tMAX_NUM_PRI\t8\n\n \nstruct sw_rx_data {\n\tstruct page *data;\n\tdma_addr_t mapping;\n\tunsigned int page_offset;\n};\n\nenum qede_agg_state {\n\tQEDE_AGG_STATE_NONE  = 0,\n\tQEDE_AGG_STATE_START = 1,\n\tQEDE_AGG_STATE_ERROR = 2\n};\n\nstruct qede_agg_info {\n\t \n\tstruct sw_rx_data buffer;\n\tstruct sk_buff *skb;\n\n\t \n\tu16 vlan_tag;\n\n\tbool tpa_start_fail;\n\tu8 state;\n\tu8 frag_id;\n\n\tu8 tunnel_type;\n};\n\nstruct qede_rx_queue {\n\t__le16 *hw_cons_ptr;\n\tvoid __iomem *hw_rxq_prod_addr;\n\n\t \n\tstruct device *dev;\n\n\tstruct bpf_prog *xdp_prog;\n\n\tu16 sw_rx_cons;\n\tu16 sw_rx_prod;\n\n\tu16 filled_buffers;\n\tu8 data_direction;\n\tu8 rxq_id;\n\n\t \n\tu16 num_rx_buffers;\n\n\tu16 rx_headroom;\n\n\tu32 rx_buf_size;\n\tu32 rx_buf_seg_size;\n\n\tstruct sw_rx_data *sw_rx_ring;\n\tstruct qed_chain rx_bd_ring;\n\tstruct qed_chain rx_comp_ring ____cacheline_aligned;\n\n\t \n\tstruct qede_agg_info tpa_info[ETH_TPA_MAX_AGGS_NUM];\n\n\t \n\tu64 rcv_pkts;\n\n\tu64 rx_hw_errors;\n\tu64 rx_alloc_errors;\n\tu64 rx_ip_frags;\n\n\tu64 xdp_no_pass;\n\n\tvoid *handle;\n\tstruct xdp_rxq_info xdp_rxq;\n};\n\nunion db_prod {\n\tstruct eth_db_data data;\n\tu32\t\traw;\n};\n\nstruct sw_tx_bd {\n\tstruct sk_buff *skb;\n\tu8 flags;\n \n#define QEDE_TSO_SPLIT_BD\t\tBIT(0)\n};\n\nstruct sw_tx_xdp {\n\tstruct page\t\t\t*page;\n\tstruct xdp_frame\t\t*xdpf;\n\tdma_addr_t\t\t\tmapping;\n};\n\nstruct qede_tx_queue {\n\tu8\t\t\t\tis_xdp;\n\tbool\t\t\t\tis_legacy;\n\tu16\t\t\t\tsw_tx_cons;\n\tu16\t\t\t\tsw_tx_prod;\n\tu16\t\t\t\tnum_tx_buffers;  \n\n\tu64\t\t\t\txmit_pkts;\n\tu64\t\t\t\tstopped_cnt;\n\tu64\t\t\t\ttx_mem_alloc_err;\n\n\t__le16\t\t\t\t*hw_cons_ptr;\n\n\t \n\tstruct device\t\t\t*dev;\n\n\tvoid __iomem\t\t\t*doorbell_addr;\n\tunion db_prod\t\t\ttx_db;\n\n\t \n\tspinlock_t\t\t\txdp_tx_lock;\n\n\tint\t\t\t\tindex;  \n#define QEDE_TXQ_XDP_TO_IDX(edev, txq)\t((txq)->index - \\\n\t\t\t\t\t QEDE_MAX_TSS_CNT(edev))\n#define QEDE_TXQ_IDX_TO_XDP(edev, idx)\t((idx) + QEDE_MAX_TSS_CNT(edev))\n#define QEDE_NDEV_TXQ_ID_TO_FP_ID(edev, idx)\t((edev)->fp_num_rx + \\\n\t\t\t\t\t\t ((idx) % QEDE_TSS_COUNT(edev)))\n#define QEDE_NDEV_TXQ_ID_TO_TXQ_COS(edev, idx)\t((idx) / QEDE_TSS_COUNT(edev))\n#define QEDE_TXQ_TO_NDEV_TXQ_ID(edev, txq)\t((QEDE_TSS_COUNT(edev) * \\\n\t\t\t\t\t\t (txq)->cos) + (txq)->index)\n#define QEDE_NDEV_TXQ_ID_TO_TXQ(edev, idx)\t\\\n\t(&((edev)->fp_array[QEDE_NDEV_TXQ_ID_TO_FP_ID(edev, idx)].txq \\\n\t[QEDE_NDEV_TXQ_ID_TO_TXQ_COS(edev, idx)]))\n#define QEDE_FP_TC0_TXQ(fp)\t\t(&((fp)->txq[0]))\n\n\t \n\tunion {\n\t\tstruct sw_tx_bd\t\t*skbs;\n\t\tstruct sw_tx_xdp\t*xdp;\n\t}\t\t\t\tsw_tx_ring;\n\n\tstruct qed_chain\t\ttx_pbl;\n\n\t \n\tvoid\t\t\t\t*handle;\n\tu16\t\t\t\tcos;\n\tu16\t\t\t\tndev_txq_id;\n};\n\n#define BD_UNMAP_ADDR(bd)\t\tHILO_U64(le32_to_cpu((bd)->addr.hi), \\\n\t\t\t\t\t\t le32_to_cpu((bd)->addr.lo))\n#define BD_SET_UNMAP_ADDR_LEN(bd, maddr, len)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\t(bd)->addr.hi = cpu_to_le32(upper_32_bits(maddr));\t\\\n\t\t(bd)->addr.lo = cpu_to_le32(lower_32_bits(maddr));\t\\\n\t\t(bd)->nbytes = cpu_to_le16(len);\t\t\t\\\n\t} while (0)\n#define BD_UNMAP_LEN(bd)\t\t(le16_to_cpu((bd)->nbytes))\n\nstruct qede_fastpath {\n\tstruct qede_dev\t\t\t*edev;\n\n\tu8\t\t\t\ttype;\n#define QEDE_FASTPATH_TX\t\tBIT(0)\n#define QEDE_FASTPATH_RX\t\tBIT(1)\n#define QEDE_FASTPATH_XDP\t\tBIT(2)\n#define QEDE_FASTPATH_COMBINED\t\t(QEDE_FASTPATH_TX | QEDE_FASTPATH_RX)\n\n\tu8\t\t\t\tid;\n\n\tu8\t\t\t\txdp_xmit;\n#define QEDE_XDP_TX\t\t\tBIT(0)\n#define QEDE_XDP_REDIRECT\t\tBIT(1)\n\n\tstruct napi_struct\t\tnapi;\n\tstruct qed_sb_info\t\t*sb_info;\n\tstruct qede_rx_queue\t\t*rxq;\n\tstruct qede_tx_queue\t\t*txq;\n\tstruct qede_tx_queue\t\t*xdp_tx;\n\n\tchar\t\t\t\tname[IFNAMSIZ + 8];\n};\n\n \n#define DP_NAME(edev)\t\t\tnetdev_name((edev)->ndev)\n\n#define XMIT_PLAIN\t\t\t0\n#define XMIT_L4_CSUM\t\t\tBIT(0)\n#define XMIT_LSO\t\t\tBIT(1)\n#define XMIT_ENC\t\t\tBIT(2)\n#define XMIT_ENC_GSO_L4_CSUM\t\tBIT(3)\n\n#define QEDE_CSUM_ERROR\t\t\tBIT(0)\n#define QEDE_CSUM_UNNECESSARY\t\tBIT(1)\n#define QEDE_TUNN_CSUM_UNNECESSARY\tBIT(2)\n\n#define QEDE_SP_RECOVERY\t\t0\n#define QEDE_SP_RX_MODE\t\t\t1\n#define QEDE_SP_RSVD1                   2\n#define QEDE_SP_RSVD2                   3\n#define QEDE_SP_HW_ERR                  4\n#define QEDE_SP_ARFS_CONFIG             5\n#define QEDE_SP_AER\t\t\t7\n#define QEDE_SP_DISABLE\t\t\t8\n\n#ifdef CONFIG_RFS_ACCEL\nint qede_rx_flow_steer(struct net_device *dev, const struct sk_buff *skb,\n\t\t       u16 rxq_index, u32 flow_id);\n#define QEDE_SP_TASK_POLL_DELAY\t(5 * HZ)\n#endif\n\nvoid qede_process_arfs_filters(struct qede_dev *edev, bool free_fltr);\nvoid qede_poll_for_freeing_arfs_filters(struct qede_dev *edev);\nvoid qede_arfs_filter_op(void *dev, void *filter, u8 fw_rc);\nvoid qede_free_arfs(struct qede_dev *edev);\nint qede_alloc_arfs(struct qede_dev *edev);\nint qede_add_cls_rule(struct qede_dev *edev, struct ethtool_rxnfc *info);\nint qede_delete_flow_filter(struct qede_dev *edev, u64 cookie);\nint qede_get_cls_rule_entry(struct qede_dev *edev, struct ethtool_rxnfc *cmd);\nint qede_get_cls_rule_all(struct qede_dev *edev, struct ethtool_rxnfc *info,\n\t\t\t  u32 *rule_locs);\nint qede_get_arfs_filter_count(struct qede_dev *edev);\n\nstruct qede_reload_args {\n\tvoid (*func)(struct qede_dev *edev, struct qede_reload_args *args);\n\tunion {\n\t\tnetdev_features_t features;\n\t\tstruct bpf_prog *new_prog;\n\t\tu16 mtu;\n\t} u;\n};\n\n \nnetdev_tx_t qede_start_xmit(struct sk_buff *skb, struct net_device *ndev);\nint qede_xdp_transmit(struct net_device *dev, int n_frames,\n\t\t      struct xdp_frame **frames, u32 flags);\nu16 qede_select_queue(struct net_device *dev, struct sk_buff *skb,\n\t\t      struct net_device *sb_dev);\nnetdev_features_t qede_features_check(struct sk_buff *skb,\n\t\t\t\t      struct net_device *dev,\n\t\t\t\t      netdev_features_t features);\nint qede_alloc_rx_buffer(struct qede_rx_queue *rxq, bool allow_lazy);\nint qede_free_tx_pkt(struct qede_dev *edev,\n\t\t     struct qede_tx_queue *txq, int *len);\nint qede_poll(struct napi_struct *napi, int budget);\nirqreturn_t qede_msix_fp_int(int irq, void *fp_cookie);\n\n \nvoid qede_force_mac(void *dev, u8 *mac, bool forced);\nvoid qede_udp_ports_update(void *dev, u16 vxlan_port, u16 geneve_port);\nint qede_set_mac_addr(struct net_device *ndev, void *p);\n\nint qede_vlan_rx_add_vid(struct net_device *dev, __be16 proto, u16 vid);\nint qede_vlan_rx_kill_vid(struct net_device *dev, __be16 proto, u16 vid);\nvoid qede_vlan_mark_nonconfigured(struct qede_dev *edev);\nint qede_configure_vlan_filters(struct qede_dev *edev);\n\nnetdev_features_t qede_fix_features(struct net_device *dev,\n\t\t\t\t    netdev_features_t features);\nint qede_set_features(struct net_device *dev, netdev_features_t features);\nvoid qede_set_rx_mode(struct net_device *ndev);\nvoid qede_config_rx_mode(struct net_device *ndev);\nvoid qede_fill_rss_params(struct qede_dev *edev,\n\t\t\t  struct qed_update_vport_rss_params *rss, u8 *update);\n\nint qede_xdp(struct net_device *dev, struct netdev_bpf *xdp);\n\n#ifdef CONFIG_DCB\nvoid qede_set_dcbnl_ops(struct net_device *ndev);\n#endif\n\nvoid qede_config_debug(uint debug, u32 *p_dp_module, u8 *p_dp_level);\nvoid qede_set_ethtool_ops(struct net_device *netdev);\nvoid qede_set_udp_tunnels(struct qede_dev *edev);\nvoid qede_reload(struct qede_dev *edev,\n\t\t struct qede_reload_args *args, bool is_locked);\nint qede_change_mtu(struct net_device *dev, int new_mtu);\nvoid qede_fill_by_demand_stats(struct qede_dev *edev);\nvoid __qede_lock(struct qede_dev *edev);\nvoid __qede_unlock(struct qede_dev *edev);\nbool qede_has_rx_work(struct qede_rx_queue *rxq);\nint qede_txq_has_work(struct qede_tx_queue *txq);\nvoid qede_recycle_rx_bd_ring(struct qede_rx_queue *rxq, u8 count);\nvoid qede_update_rx_prod(struct qede_dev *edev, struct qede_rx_queue *rxq);\nint qede_add_tc_flower_fltr(struct qede_dev *edev, __be16 proto,\n\t\t\t    struct flow_cls_offload *f);\n\nvoid qede_forced_speed_maps_init(void);\nint qede_set_coalesce(struct net_device *dev, struct ethtool_coalesce *coal,\n\t\t      struct kernel_ethtool_coalesce *kernel_coal,\n\t\t      struct netlink_ext_ack *extack);\nint qede_set_per_coalesce(struct net_device *dev, u32 queue,\n\t\t\t  struct ethtool_coalesce *coal);\n\n#define RX_RING_SIZE_POW\t13\n#define RX_RING_SIZE\t\t((u16)BIT(RX_RING_SIZE_POW))\n#define NUM_RX_BDS_MAX\t\t(RX_RING_SIZE - 1)\n#define NUM_RX_BDS_MIN\t\t128\n#define NUM_RX_BDS_KDUMP_MIN\t63\n#define NUM_RX_BDS_DEF\t\t((u16)BIT(10) - 1)\n\n#define TX_RING_SIZE_POW\t13\n#define TX_RING_SIZE\t\t((u16)BIT(TX_RING_SIZE_POW))\n#define NUM_TX_BDS_MAX\t\t(TX_RING_SIZE - 1)\n#define NUM_TX_BDS_MIN\t\t128\n#define NUM_TX_BDS_KDUMP_MIN\t63\n#define NUM_TX_BDS_DEF\t\tNUM_TX_BDS_MAX\n\n#define QEDE_MIN_PKT_LEN\t\t64\n#define QEDE_RX_HDR_SIZE\t\t256\n#define QEDE_MAX_JUMBO_PACKET_SIZE\t9600\n#define\tfor_each_queue(i) for (i = 0; i < edev->num_queues; i++)\n#define for_each_cos_in_txq(edev, var) \\\n\tfor ((var) = 0; (var) < (edev)->dev_info.num_tc; (var)++)\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}