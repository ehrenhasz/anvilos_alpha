{
  "module_name": "qed_main.c",
  "hash_id": "b238260166c12dd31cc38b671eea722c9ea99bb56b15aa072f88337c26d3eac6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qed/qed_main.c",
  "human_readable_source": "\n \n\n#include <linux/stddef.h>\n#include <linux/pci.h>\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <asm/byteorder.h>\n#include <linux/dma-mapping.h>\n#include <linux/string.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/workqueue.h>\n#include <linux/ethtool.h>\n#include <linux/etherdevice.h>\n#include <linux/vmalloc.h>\n#include <linux/crash_dump.h>\n#include <linux/crc32.h>\n#include <linux/qed/qed_if.h>\n#include <linux/qed/qed_ll2_if.h>\n#include <net/devlink.h>\n#include <linux/phylink.h>\n\n#include \"qed.h\"\n#include \"qed_sriov.h\"\n#include \"qed_sp.h\"\n#include \"qed_dev_api.h\"\n#include \"qed_ll2.h\"\n#include \"qed_fcoe.h\"\n#include \"qed_iscsi.h\"\n\n#include \"qed_mcp.h\"\n#include \"qed_reg_addr.h\"\n#include \"qed_hw.h\"\n#include \"qed_selftest.h\"\n#include \"qed_debug.h\"\n#include \"qed_devlink.h\"\n\n#define QED_ROCE_QPS\t\t\t(8192)\n#define QED_ROCE_DPIS\t\t\t(8)\n#define QED_RDMA_SRQS                   QED_ROCE_QPS\n#define QED_NVM_CFG_GET_FLAGS\t\t0xA\n#define QED_NVM_CFG_GET_PF_FLAGS\t0x1A\n#define QED_NVM_CFG_MAX_ATTRS\t\t50\n\nstatic char version[] =\n\t\"QLogic FastLinQ 4xxxx Core Module qed\\n\";\n\nMODULE_DESCRIPTION(\"QLogic FastLinQ 4xxxx Core Module\");\nMODULE_LICENSE(\"GPL\");\n\n#define FW_FILE_VERSION\t\t\t\t\\\n\t__stringify(FW_MAJOR_VERSION) \".\"\t\\\n\t__stringify(FW_MINOR_VERSION) \".\"\t\\\n\t__stringify(FW_REVISION_VERSION) \".\"\t\\\n\t__stringify(FW_ENGINEERING_VERSION)\n\n#define QED_FW_FILE_NAME\t\\\n\t\"qed/qed_init_values_zipped-\" FW_FILE_VERSION \".bin\"\n\nMODULE_FIRMWARE(QED_FW_FILE_NAME);\n\n \n\nstruct qed_mfw_speed_map {\n\tu32\t\tmfw_val;\n\t__ETHTOOL_DECLARE_LINK_MODE_MASK(caps);\n\n\tconst u32\t*cap_arr;\n\tu32\t\tarr_size;\n};\n\n#define QED_MFW_SPEED_MAP(type, arr)\t\t\\\n{\t\t\t\t\t\t\\\n\t.mfw_val\t= (type),\t\t\\\n\t.cap_arr\t= (arr),\t\t\\\n\t.arr_size\t= ARRAY_SIZE(arr),\t\\\n}\n\nstatic const u32 qed_mfw_ext_1g[] __initconst = {\n\tETHTOOL_LINK_MODE_1000baseT_Full_BIT,\n\tETHTOOL_LINK_MODE_1000baseKX_Full_BIT,\n\tETHTOOL_LINK_MODE_1000baseX_Full_BIT,\n};\n\nstatic const u32 qed_mfw_ext_10g[] __initconst = {\n\tETHTOOL_LINK_MODE_10000baseT_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseKR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseKX4_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseR_FEC_BIT,\n\tETHTOOL_LINK_MODE_10000baseCR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseSR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseLR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseLRM_Full_BIT,\n};\n\nstatic const u32 qed_mfw_ext_25g[] __initconst = {\n\tETHTOOL_LINK_MODE_25000baseKR_Full_BIT,\n\tETHTOOL_LINK_MODE_25000baseCR_Full_BIT,\n\tETHTOOL_LINK_MODE_25000baseSR_Full_BIT,\n};\n\nstatic const u32 qed_mfw_ext_40g[] __initconst = {\n\tETHTOOL_LINK_MODE_40000baseLR4_Full_BIT,\n\tETHTOOL_LINK_MODE_40000baseKR4_Full_BIT,\n\tETHTOOL_LINK_MODE_40000baseCR4_Full_BIT,\n\tETHTOOL_LINK_MODE_40000baseSR4_Full_BIT,\n};\n\nstatic const u32 qed_mfw_ext_50g_base_r[] __initconst = {\n\tETHTOOL_LINK_MODE_50000baseKR_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseCR_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseSR_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseLR_ER_FR_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseDR_Full_BIT,\n};\n\nstatic const u32 qed_mfw_ext_50g_base_r2[] __initconst = {\n\tETHTOOL_LINK_MODE_50000baseKR2_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseCR2_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseSR2_Full_BIT,\n};\n\nstatic const u32 qed_mfw_ext_100g_base_r2[] __initconst = {\n\tETHTOOL_LINK_MODE_100000baseKR2_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseSR2_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseCR2_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseDR2_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseLR2_ER2_FR2_Full_BIT,\n};\n\nstatic const u32 qed_mfw_ext_100g_base_r4[] __initconst = {\n\tETHTOOL_LINK_MODE_100000baseKR4_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseSR4_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseCR4_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseLR4_ER4_Full_BIT,\n};\n\nstatic struct qed_mfw_speed_map qed_mfw_ext_maps[] __ro_after_init = {\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_1G, qed_mfw_ext_1g),\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_10G, qed_mfw_ext_10g),\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_25G, qed_mfw_ext_25g),\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_40G, qed_mfw_ext_40g),\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_50G_BASE_R,\n\t\t\t  qed_mfw_ext_50g_base_r),\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_50G_BASE_R2,\n\t\t\t  qed_mfw_ext_50g_base_r2),\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_100G_BASE_R2,\n\t\t\t  qed_mfw_ext_100g_base_r2),\n\tQED_MFW_SPEED_MAP(ETH_EXT_ADV_SPEED_100G_BASE_R4,\n\t\t\t  qed_mfw_ext_100g_base_r4),\n};\n\nstatic const u32 qed_mfw_legacy_1g[] __initconst = {\n\tETHTOOL_LINK_MODE_1000baseT_Full_BIT,\n\tETHTOOL_LINK_MODE_1000baseKX_Full_BIT,\n\tETHTOOL_LINK_MODE_1000baseX_Full_BIT,\n};\n\nstatic const u32 qed_mfw_legacy_10g[] __initconst = {\n\tETHTOOL_LINK_MODE_10000baseT_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseKR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseKX4_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseR_FEC_BIT,\n\tETHTOOL_LINK_MODE_10000baseCR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseSR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseLR_Full_BIT,\n\tETHTOOL_LINK_MODE_10000baseLRM_Full_BIT,\n};\n\nstatic const u32 qed_mfw_legacy_20g[] __initconst = {\n\tETHTOOL_LINK_MODE_20000baseKR2_Full_BIT,\n};\n\nstatic const u32 qed_mfw_legacy_25g[] __initconst = {\n\tETHTOOL_LINK_MODE_25000baseKR_Full_BIT,\n\tETHTOOL_LINK_MODE_25000baseCR_Full_BIT,\n\tETHTOOL_LINK_MODE_25000baseSR_Full_BIT,\n};\n\nstatic const u32 qed_mfw_legacy_40g[] __initconst = {\n\tETHTOOL_LINK_MODE_40000baseLR4_Full_BIT,\n\tETHTOOL_LINK_MODE_40000baseKR4_Full_BIT,\n\tETHTOOL_LINK_MODE_40000baseCR4_Full_BIT,\n\tETHTOOL_LINK_MODE_40000baseSR4_Full_BIT,\n};\n\nstatic const u32 qed_mfw_legacy_50g[] __initconst = {\n\tETHTOOL_LINK_MODE_50000baseKR2_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseCR2_Full_BIT,\n\tETHTOOL_LINK_MODE_50000baseSR2_Full_BIT,\n};\n\nstatic const u32 qed_mfw_legacy_bb_100g[] __initconst = {\n\tETHTOOL_LINK_MODE_100000baseKR4_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseSR4_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseCR4_Full_BIT,\n\tETHTOOL_LINK_MODE_100000baseLR4_ER4_Full_BIT,\n};\n\nstatic struct qed_mfw_speed_map qed_mfw_legacy_maps[] __ro_after_init = {\n\tQED_MFW_SPEED_MAP(NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G,\n\t\t\t  qed_mfw_legacy_1g),\n\tQED_MFW_SPEED_MAP(NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G,\n\t\t\t  qed_mfw_legacy_10g),\n\tQED_MFW_SPEED_MAP(NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_20G,\n\t\t\t  qed_mfw_legacy_20g),\n\tQED_MFW_SPEED_MAP(NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G,\n\t\t\t  qed_mfw_legacy_25g),\n\tQED_MFW_SPEED_MAP(NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G,\n\t\t\t  qed_mfw_legacy_40g),\n\tQED_MFW_SPEED_MAP(NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_50G,\n\t\t\t  qed_mfw_legacy_50g),\n\tQED_MFW_SPEED_MAP(NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G,\n\t\t\t  qed_mfw_legacy_bb_100g),\n};\n\nstatic void __init qed_mfw_speed_map_populate(struct qed_mfw_speed_map *map)\n{\n\tlinkmode_set_bit_array(map->cap_arr, map->arr_size, map->caps);\n\n\tmap->cap_arr = NULL;\n\tmap->arr_size = 0;\n}\n\nstatic void __init qed_mfw_speed_maps_init(void)\n{\n\tu32 i;\n\n\tfor (i = 0; i < ARRAY_SIZE(qed_mfw_ext_maps); i++)\n\t\tqed_mfw_speed_map_populate(qed_mfw_ext_maps + i);\n\n\tfor (i = 0; i < ARRAY_SIZE(qed_mfw_legacy_maps); i++)\n\t\tqed_mfw_speed_map_populate(qed_mfw_legacy_maps + i);\n}\n\nstatic int __init qed_init(void)\n{\n\tpr_info(\"%s\", version);\n\n\tqed_mfw_speed_maps_init();\n\n\treturn 0;\n}\nmodule_init(qed_init);\n\nstatic void __exit qed_exit(void)\n{\n\t \n}\nmodule_exit(qed_exit);\n\nstatic void qed_free_pci(struct qed_dev *cdev)\n{\n\tstruct pci_dev *pdev = cdev->pdev;\n\n\tif (cdev->doorbells && cdev->db_size)\n\t\tiounmap(cdev->doorbells);\n\tif (cdev->regview)\n\t\tiounmap(cdev->regview);\n\tif (atomic_read(&pdev->enable_cnt) == 1)\n\t\tpci_release_regions(pdev);\n\n\tpci_disable_device(pdev);\n}\n\n#define PCI_REVISION_ID_ERROR_VAL\t0xff\n\n \nstatic int qed_init_pci(struct qed_dev *cdev, struct pci_dev *pdev)\n{\n\tu8 rev_id;\n\tint rc;\n\n\tcdev->pdev = pdev;\n\n\trc = pci_enable_device(pdev);\n\tif (rc) {\n\t\tDP_NOTICE(cdev, \"Cannot enable PCI device\\n\");\n\t\tgoto err0;\n\t}\n\n\tif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\n\t\tDP_NOTICE(cdev, \"No memory region found in bar #0\\n\");\n\t\trc = -EIO;\n\t\tgoto err1;\n\t}\n\n\tif (IS_PF(cdev) && !(pci_resource_flags(pdev, 2) & IORESOURCE_MEM)) {\n\t\tDP_NOTICE(cdev, \"No memory region found in bar #2\\n\");\n\t\trc = -EIO;\n\t\tgoto err1;\n\t}\n\n\tif (atomic_read(&pdev->enable_cnt) == 1) {\n\t\trc = pci_request_regions(pdev, \"qed\");\n\t\tif (rc) {\n\t\t\tDP_NOTICE(cdev,\n\t\t\t\t  \"Failed to request PCI memory resources\\n\");\n\t\t\tgoto err1;\n\t\t}\n\t\tpci_set_master(pdev);\n\t\tpci_save_state(pdev);\n\t}\n\n\tpci_read_config_byte(pdev, PCI_REVISION_ID, &rev_id);\n\tif (rev_id == PCI_REVISION_ID_ERROR_VAL) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Detected PCI device error [rev_id 0x%x]. Probably due to prior indication. Aborting.\\n\",\n\t\t\t  rev_id);\n\t\trc = -ENODEV;\n\t\tgoto err2;\n\t}\n\tif (!pci_is_pcie(pdev)) {\n\t\tDP_NOTICE(cdev, \"The bus is not PCI Express\\n\");\n\t\trc = -EIO;\n\t\tgoto err2;\n\t}\n\n\tcdev->pci_params.pm_cap = pci_find_capability(pdev, PCI_CAP_ID_PM);\n\tif (IS_PF(cdev) && !cdev->pci_params.pm_cap)\n\t\tDP_NOTICE(cdev, \"Cannot find power management capability\\n\");\n\n\trc = dma_set_mask_and_coherent(&cdev->pdev->dev, DMA_BIT_MASK(64));\n\tif (rc) {\n\t\tDP_NOTICE(cdev, \"Can't request DMA addresses\\n\");\n\t\trc = -EIO;\n\t\tgoto err2;\n\t}\n\n\tcdev->pci_params.mem_start = pci_resource_start(pdev, 0);\n\tcdev->pci_params.mem_end = pci_resource_end(pdev, 0);\n\tcdev->pci_params.irq = pdev->irq;\n\n\tcdev->regview = pci_ioremap_bar(pdev, 0);\n\tif (!cdev->regview) {\n\t\tDP_NOTICE(cdev, \"Cannot map register space, aborting\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err2;\n\t}\n\n\tcdev->db_phys_addr = pci_resource_start(cdev->pdev, 2);\n\tcdev->db_size = pci_resource_len(cdev->pdev, 2);\n\tif (!cdev->db_size) {\n\t\tif (IS_PF(cdev)) {\n\t\t\tDP_NOTICE(cdev, \"No Doorbell bar available\\n\");\n\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tcdev->doorbells = ioremap_wc(cdev->db_phys_addr, cdev->db_size);\n\n\tif (!cdev->doorbells) {\n\t\tDP_NOTICE(cdev, \"Cannot map doorbell space\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n\nerr2:\n\tpci_release_regions(pdev);\nerr1:\n\tpci_disable_device(pdev);\nerr0:\n\treturn rc;\n}\n\nint qed_fill_dev_info(struct qed_dev *cdev,\n\t\t      struct qed_dev_info *dev_info)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_hw_info *hw_info = &p_hwfn->hw_info;\n\tstruct qed_tunnel_info *tun = &cdev->tunnel;\n\tstruct qed_ptt  *ptt;\n\n\tmemset(dev_info, 0, sizeof(struct qed_dev_info));\n\n\tif (tun->vxlan.tun_cls == QED_TUNN_CLSS_MAC_VLAN &&\n\t    tun->vxlan.b_mode_enabled)\n\t\tdev_info->vxlan_enable = true;\n\n\tif (tun->l2_gre.b_mode_enabled && tun->ip_gre.b_mode_enabled &&\n\t    tun->l2_gre.tun_cls == QED_TUNN_CLSS_MAC_VLAN &&\n\t    tun->ip_gre.tun_cls == QED_TUNN_CLSS_MAC_VLAN)\n\t\tdev_info->gre_enable = true;\n\n\tif (tun->l2_geneve.b_mode_enabled && tun->ip_geneve.b_mode_enabled &&\n\t    tun->l2_geneve.tun_cls == QED_TUNN_CLSS_MAC_VLAN &&\n\t    tun->ip_geneve.tun_cls == QED_TUNN_CLSS_MAC_VLAN)\n\t\tdev_info->geneve_enable = true;\n\n\tdev_info->num_hwfns = cdev->num_hwfns;\n\tdev_info->pci_mem_start = cdev->pci_params.mem_start;\n\tdev_info->pci_mem_end = cdev->pci_params.mem_end;\n\tdev_info->pci_irq = cdev->pci_params.irq;\n\tdev_info->rdma_supported = QED_IS_RDMA_PERSONALITY(p_hwfn);\n\tdev_info->dev_type = cdev->type;\n\tether_addr_copy(dev_info->hw_mac, hw_info->hw_mac_addr);\n\n\tif (IS_PF(cdev)) {\n\t\tdev_info->fw_major = FW_MAJOR_VERSION;\n\t\tdev_info->fw_minor = FW_MINOR_VERSION;\n\t\tdev_info->fw_rev = FW_REVISION_VERSION;\n\t\tdev_info->fw_eng = FW_ENGINEERING_VERSION;\n\t\tdev_info->b_inter_pf_switch = test_bit(QED_MF_INTER_PF_SWITCH,\n\t\t\t\t\t\t       &cdev->mf_bits);\n\t\tif (!test_bit(QED_MF_DISABLE_ARFS, &cdev->mf_bits))\n\t\t\tdev_info->b_arfs_capable = true;\n\t\tdev_info->tx_switching = true;\n\n\t\tif (hw_info->b_wol_support == QED_WOL_SUPPORT_PME)\n\t\t\tdev_info->wol_support = true;\n\n\t\tdev_info->smart_an = qed_mcp_is_smart_an_supported(p_hwfn);\n\t\tdev_info->esl = qed_mcp_is_esl_supported(p_hwfn);\n\t\tdev_info->abs_pf_id = QED_LEADING_HWFN(cdev)->abs_pf_id;\n\t} else {\n\t\tqed_vf_get_fw_version(&cdev->hwfns[0], &dev_info->fw_major,\n\t\t\t\t      &dev_info->fw_minor, &dev_info->fw_rev,\n\t\t\t\t      &dev_info->fw_eng);\n\t}\n\n\tif (IS_PF(cdev)) {\n\t\tptt = qed_ptt_acquire(QED_LEADING_HWFN(cdev));\n\t\tif (ptt) {\n\t\t\tqed_mcp_get_mfw_ver(QED_LEADING_HWFN(cdev), ptt,\n\t\t\t\t\t    &dev_info->mfw_rev, NULL);\n\n\t\t\tqed_mcp_get_mbi_ver(QED_LEADING_HWFN(cdev), ptt,\n\t\t\t\t\t    &dev_info->mbi_version);\n\n\t\t\tqed_mcp_get_flash_size(QED_LEADING_HWFN(cdev), ptt,\n\t\t\t\t\t       &dev_info->flash_size);\n\n\t\t\tqed_ptt_release(QED_LEADING_HWFN(cdev), ptt);\n\t\t}\n\t} else {\n\t\tqed_mcp_get_mfw_ver(QED_LEADING_HWFN(cdev), NULL,\n\t\t\t\t    &dev_info->mfw_rev, NULL);\n\t}\n\n\tdev_info->mtu = hw_info->mtu;\n\tcdev->common_dev_info = *dev_info;\n\n\treturn 0;\n}\n\nstatic void qed_free_cdev(struct qed_dev *cdev)\n{\n\tkfree((void *)cdev);\n}\n\nstatic struct qed_dev *qed_alloc_cdev(struct pci_dev *pdev)\n{\n\tstruct qed_dev *cdev;\n\n\tcdev = kzalloc(sizeof(*cdev), GFP_KERNEL);\n\tif (!cdev)\n\t\treturn cdev;\n\n\tqed_init_struct(cdev);\n\n\treturn cdev;\n}\n\n \nstatic int qed_set_power_state(struct qed_dev *cdev, pci_power_t state)\n{\n\tif (!cdev)\n\t\treturn -ENODEV;\n\n\tDP_VERBOSE(cdev, NETIF_MSG_DRV, \"Omitting Power state change\\n\");\n\treturn 0;\n}\n\n \nstatic struct qed_dev *qed_probe(struct pci_dev *pdev,\n\t\t\t\t struct qed_probe_params *params)\n{\n\tstruct qed_dev *cdev;\n\tint rc;\n\n\tcdev = qed_alloc_cdev(pdev);\n\tif (!cdev)\n\t\tgoto err0;\n\n\tcdev->drv_type = DRV_ID_DRV_TYPE_LINUX;\n\tcdev->protocol = params->protocol;\n\n\tif (params->is_vf)\n\t\tcdev->b_is_vf = true;\n\n\tqed_init_dp(cdev, params->dp_module, params->dp_level);\n\n\tcdev->recov_in_prog = params->recov_in_prog;\n\n\trc = qed_init_pci(cdev, pdev);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"init pci failed\\n\");\n\t\tgoto err1;\n\t}\n\tDP_INFO(cdev, \"PCI init completed successfully\\n\");\n\n\trc = qed_hw_prepare(cdev, QED_PCI_DEFAULT);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"hw prepare failed\\n\");\n\t\tgoto err2;\n\t}\n\n\tDP_INFO(cdev, \"%s completed successfully\\n\", __func__);\n\n\treturn cdev;\n\nerr2:\n\tqed_free_pci(cdev);\nerr1:\n\tqed_free_cdev(cdev);\nerr0:\n\treturn NULL;\n}\n\nstatic void qed_remove(struct qed_dev *cdev)\n{\n\tif (!cdev)\n\t\treturn;\n\n\tqed_hw_remove(cdev);\n\n\tqed_free_pci(cdev);\n\n\tqed_set_power_state(cdev, PCI_D3hot);\n\n\tqed_free_cdev(cdev);\n}\n\nstatic void qed_disable_msix(struct qed_dev *cdev)\n{\n\tif (cdev->int_params.out.int_mode == QED_INT_MODE_MSIX) {\n\t\tpci_disable_msix(cdev->pdev);\n\t\tkfree(cdev->int_params.msix_table);\n\t} else if (cdev->int_params.out.int_mode == QED_INT_MODE_MSI) {\n\t\tpci_disable_msi(cdev->pdev);\n\t}\n\n\tmemset(&cdev->int_params.out, 0, sizeof(struct qed_int_param));\n}\n\nstatic int qed_enable_msix(struct qed_dev *cdev,\n\t\t\t   struct qed_int_params *int_params)\n{\n\tint i, rc, cnt;\n\n\tcnt = int_params->in.num_vectors;\n\n\tfor (i = 0; i < cnt; i++)\n\t\tint_params->msix_table[i].entry = i;\n\n\trc = pci_enable_msix_range(cdev->pdev, int_params->msix_table,\n\t\t\t\t   int_params->in.min_msix_cnt, cnt);\n\tif (rc < cnt && rc >= int_params->in.min_msix_cnt &&\n\t    (rc % cdev->num_hwfns)) {\n\t\tpci_disable_msix(cdev->pdev);\n\n\t\t \n\t\tcnt = (rc / cdev->num_hwfns) * cdev->num_hwfns;\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Trying to enable MSI-X with less vectors (%d out of %d)\\n\",\n\t\t\t  cnt, int_params->in.num_vectors);\n\t\trc = pci_enable_msix_exact(cdev->pdev, int_params->msix_table,\n\t\t\t\t\t   cnt);\n\t\tif (!rc)\n\t\t\trc = cnt;\n\t}\n\n\t \n\tif ((IS_PF(cdev) && rc > 0) || (IS_VF(cdev) && rc == cnt)) {\n\t\t \n\t\tint_params->out.int_mode = QED_INT_MODE_MSIX;\n\t\tint_params->out.num_vectors = rc;\n\t\trc = 0;\n\t} else {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Failed to enable MSI-X [Requested %d vectors][rc %d]\\n\",\n\t\t\t  cnt, rc);\n\t}\n\n\treturn rc;\n}\n\n \nstatic int qed_set_int_mode(struct qed_dev *cdev, bool force_mode)\n{\n\tstruct qed_int_params *int_params = &cdev->int_params;\n\tstruct msix_entry *tbl;\n\tint rc = 0, cnt;\n\n\tswitch (int_params->in.int_mode) {\n\tcase QED_INT_MODE_MSIX:\n\t\t \n\t\tcnt = int_params->in.num_vectors;\n\t\tint_params->msix_table = kcalloc(cnt, sizeof(*tbl), GFP_KERNEL);\n\t\tif (!int_params->msix_table) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\trc = qed_enable_msix(cdev, int_params);\n\t\tif (!rc)\n\t\t\tgoto out;\n\n\t\tDP_NOTICE(cdev, \"Failed to enable MSI-X\\n\");\n\t\tkfree(int_params->msix_table);\n\t\tif (force_mode)\n\t\t\tgoto out;\n\t\tfallthrough;\n\n\tcase QED_INT_MODE_MSI:\n\t\tif (cdev->num_hwfns == 1) {\n\t\t\trc = pci_enable_msi(cdev->pdev);\n\t\t\tif (!rc) {\n\t\t\t\tint_params->out.int_mode = QED_INT_MODE_MSI;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tDP_NOTICE(cdev, \"Failed to enable MSI\\n\");\n\t\t\tif (force_mode)\n\t\t\t\tgoto out;\n\t\t}\n\t\tfallthrough;\n\n\tcase QED_INT_MODE_INTA:\n\t\t\tint_params->out.int_mode = QED_INT_MODE_INTA;\n\t\t\trc = 0;\n\t\t\tgoto out;\n\tdefault:\n\t\tDP_NOTICE(cdev, \"Unknown int_mode value %d\\n\",\n\t\t\t  int_params->in.int_mode);\n\t\trc = -EINVAL;\n\t}\n\nout:\n\tif (!rc)\n\t\tDP_INFO(cdev, \"Using %s interrupts\\n\",\n\t\t\tint_params->out.int_mode == QED_INT_MODE_INTA ?\n\t\t\t\"INTa\" : int_params->out.int_mode == QED_INT_MODE_MSI ?\n\t\t\t\"MSI\" : \"MSIX\");\n\tcdev->int_coalescing_mode = QED_COAL_MODE_ENABLE;\n\n\treturn rc;\n}\n\nstatic void qed_simd_handler_config(struct qed_dev *cdev, void *token,\n\t\t\t\t    int index, void(*handler)(void *))\n{\n\tstruct qed_hwfn *hwfn = &cdev->hwfns[index % cdev->num_hwfns];\n\tint relative_idx = index / cdev->num_hwfns;\n\n\thwfn->simd_proto_handler[relative_idx].func = handler;\n\thwfn->simd_proto_handler[relative_idx].token = token;\n}\n\nstatic void qed_simd_handler_clean(struct qed_dev *cdev, int index)\n{\n\tstruct qed_hwfn *hwfn = &cdev->hwfns[index % cdev->num_hwfns];\n\tint relative_idx = index / cdev->num_hwfns;\n\n\tmemset(&hwfn->simd_proto_handler[relative_idx], 0,\n\t       sizeof(struct qed_simd_fp_handler));\n}\n\nstatic irqreturn_t qed_msix_sp_int(int irq, void *tasklet)\n{\n\ttasklet_schedule((struct tasklet_struct *)tasklet);\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t qed_single_int(int irq, void *dev_instance)\n{\n\tstruct qed_dev *cdev = (struct qed_dev *)dev_instance;\n\tstruct qed_hwfn *hwfn;\n\tirqreturn_t rc = IRQ_NONE;\n\tu64 status;\n\tint i, j;\n\n\tfor (i = 0; i < cdev->num_hwfns; i++) {\n\t\tstatus = qed_int_igu_read_sisr_reg(&cdev->hwfns[i]);\n\n\t\tif (!status)\n\t\t\tcontinue;\n\n\t\thwfn = &cdev->hwfns[i];\n\n\t\t \n\t\tif (unlikely(status & 0x1)) {\n\t\t\ttasklet_schedule(&hwfn->sp_dpc);\n\t\t\tstatus &= ~0x1;\n\t\t\trc = IRQ_HANDLED;\n\t\t}\n\n\t\t \n\t\tfor (j = 0; j < 64; j++) {\n\t\t\tif ((0x2ULL << j) & status) {\n\t\t\t\tstruct qed_simd_fp_handler *p_handler =\n\t\t\t\t\t&hwfn->simd_proto_handler[j];\n\n\t\t\t\tif (p_handler->func)\n\t\t\t\t\tp_handler->func(p_handler->token);\n\t\t\t\telse\n\t\t\t\t\tDP_NOTICE(hwfn,\n\t\t\t\t\t\t  \"Not calling fastpath handler as it is NULL [handler #%d, status 0x%llx]\\n\",\n\t\t\t\t\t\t  j, status);\n\n\t\t\t\tstatus &= ~(0x2ULL << j);\n\t\t\t\trc = IRQ_HANDLED;\n\t\t\t}\n\t\t}\n\n\t\tif (unlikely(status))\n\t\t\tDP_VERBOSE(hwfn, NETIF_MSG_INTR,\n\t\t\t\t   \"got an unknown interrupt status 0x%llx\\n\",\n\t\t\t\t   status);\n\t}\n\n\treturn rc;\n}\n\nint qed_slowpath_irq_req(struct qed_hwfn *hwfn)\n{\n\tstruct qed_dev *cdev = hwfn->cdev;\n\tu32 int_mode;\n\tint rc = 0;\n\tu8 id;\n\n\tint_mode = cdev->int_params.out.int_mode;\n\tif (int_mode == QED_INT_MODE_MSIX) {\n\t\tid = hwfn->my_id;\n\t\tsnprintf(hwfn->name, NAME_SIZE, \"sp-%d-%02x:%02x.%02x\",\n\t\t\t id, cdev->pdev->bus->number,\n\t\t\t PCI_SLOT(cdev->pdev->devfn), hwfn->abs_pf_id);\n\t\trc = request_irq(cdev->int_params.msix_table[id].vector,\n\t\t\t\t qed_msix_sp_int, 0, hwfn->name, &hwfn->sp_dpc);\n\t} else {\n\t\tunsigned long flags = 0;\n\n\t\tsnprintf(cdev->name, NAME_SIZE, \"%02x:%02x.%02x\",\n\t\t\t cdev->pdev->bus->number, PCI_SLOT(cdev->pdev->devfn),\n\t\t\t PCI_FUNC(cdev->pdev->devfn));\n\n\t\tif (cdev->int_params.out.int_mode == QED_INT_MODE_INTA)\n\t\t\tflags |= IRQF_SHARED;\n\n\t\trc = request_irq(cdev->pdev->irq, qed_single_int,\n\t\t\t\t flags, cdev->name, cdev);\n\t}\n\n\tif (rc)\n\t\tDP_NOTICE(cdev, \"request_irq failed, rc = %d\\n\", rc);\n\telse\n\t\tDP_VERBOSE(hwfn, (NETIF_MSG_INTR | QED_MSG_SP),\n\t\t\t   \"Requested slowpath %s\\n\",\n\t\t\t   (int_mode == QED_INT_MODE_MSIX) ? \"MSI-X\" : \"IRQ\");\n\n\treturn rc;\n}\n\nstatic void qed_slowpath_tasklet_flush(struct qed_hwfn *p_hwfn)\n{\n\t \n\tif (p_hwfn->b_sp_dpc_enabled) {\n\t\ttasklet_disable(&p_hwfn->sp_dpc);\n\t\ttasklet_enable(&p_hwfn->sp_dpc);\n\t}\n}\n\nvoid qed_slowpath_irq_sync(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tu8 id = p_hwfn->my_id;\n\tu32 int_mode;\n\n\tint_mode = cdev->int_params.out.int_mode;\n\tif (int_mode == QED_INT_MODE_MSIX)\n\t\tsynchronize_irq(cdev->int_params.msix_table[id].vector);\n\telse\n\t\tsynchronize_irq(cdev->pdev->irq);\n\n\tqed_slowpath_tasklet_flush(p_hwfn);\n}\n\nstatic void qed_slowpath_irq_free(struct qed_dev *cdev)\n{\n\tint i;\n\n\tif (cdev->int_params.out.int_mode == QED_INT_MODE_MSIX) {\n\t\tfor_each_hwfn(cdev, i) {\n\t\t\tif (!cdev->hwfns[i].b_int_requested)\n\t\t\t\tbreak;\n\t\t\tfree_irq(cdev->int_params.msix_table[i].vector,\n\t\t\t\t &cdev->hwfns[i].sp_dpc);\n\t\t}\n\t} else {\n\t\tif (QED_LEADING_HWFN(cdev)->b_int_requested)\n\t\t\tfree_irq(cdev->pdev->irq, cdev);\n\t}\n\tqed_int_disable_post_isr_release(cdev);\n}\n\nstatic int qed_nic_stop(struct qed_dev *cdev)\n{\n\tint i, rc;\n\n\trc = qed_hw_stop(cdev);\n\n\tfor (i = 0; i < cdev->num_hwfns; i++) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tif (p_hwfn->b_sp_dpc_enabled) {\n\t\t\ttasklet_disable(&p_hwfn->sp_dpc);\n\t\t\tp_hwfn->b_sp_dpc_enabled = false;\n\t\t\tDP_VERBOSE(cdev, NETIF_MSG_IFDOWN,\n\t\t\t\t   \"Disabled sp tasklet [hwfn %d] at %p\\n\",\n\t\t\t\t   i, &p_hwfn->sp_dpc);\n\t\t}\n\t}\n\n\tqed_dbg_pf_exit(cdev);\n\n\treturn rc;\n}\n\nstatic int qed_nic_setup(struct qed_dev *cdev)\n{\n\tint rc, i;\n\n\t \n\tif (QED_LEADING_HWFN(cdev)->hw_info.personality != QED_PCI_ETH) {\n\t\tfor (i = 0; i < cdev->num_hwfns; i++) {\n\t\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\t\tp_hwfn->using_ll2 = true;\n\t\t}\n\t}\n\n\trc = qed_resc_alloc(cdev);\n\tif (rc)\n\t\treturn rc;\n\n\tDP_INFO(cdev, \"Allocated qed resources\\n\");\n\n\tqed_resc_setup(cdev);\n\n\treturn rc;\n}\n\nstatic int qed_set_int_fp(struct qed_dev *cdev, u16 cnt)\n{\n\tint limit = 0;\n\n\t \n\tcdev->int_params.fp_initialized = cnt ? true : false;\n\n\tif (cdev->int_params.out.int_mode != QED_INT_MODE_MSIX)\n\t\tlimit = cdev->num_hwfns * 63;\n\telse if (cdev->int_params.fp_msix_cnt)\n\t\tlimit = cdev->int_params.fp_msix_cnt;\n\n\tif (!limit)\n\t\treturn -ENOMEM;\n\n\treturn min_t(int, cnt, limit);\n}\n\nstatic int qed_get_int_fp(struct qed_dev *cdev, struct qed_int_info *info)\n{\n\tmemset(info, 0, sizeof(struct qed_int_info));\n\n\tif (!cdev->int_params.fp_initialized) {\n\t\tDP_INFO(cdev,\n\t\t\t\"Protocol driver requested interrupt information, but its support is not yet configured\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (cdev->int_params.out.int_mode == QED_INT_MODE_MSIX) {\n\t\tint msix_base = cdev->int_params.fp_msix_base;\n\n\t\tinfo->msix_cnt = cdev->int_params.fp_msix_cnt;\n\t\tinfo->msix = &cdev->int_params.msix_table[msix_base];\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_slowpath_setup_int(struct qed_dev *cdev,\n\t\t\t\t  enum qed_int_mode int_mode)\n{\n\tstruct qed_sb_cnt_info sb_cnt_info;\n\tint num_l2_queues = 0;\n\tint rc;\n\tint i;\n\n\tif ((int_mode == QED_INT_MODE_MSI) && (cdev->num_hwfns > 1)) {\n\t\tDP_NOTICE(cdev, \"MSI mode is not supported for CMT devices\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&cdev->int_params, 0, sizeof(struct qed_int_params));\n\tcdev->int_params.in.int_mode = int_mode;\n\tfor_each_hwfn(cdev, i) {\n\t\tmemset(&sb_cnt_info, 0, sizeof(sb_cnt_info));\n\t\tqed_int_get_num_sbs(&cdev->hwfns[i], &sb_cnt_info);\n\t\tcdev->int_params.in.num_vectors += sb_cnt_info.cnt;\n\t\tcdev->int_params.in.num_vectors++;  \n\t}\n\n\t \n\tcdev->int_params.in.min_msix_cnt = cdev->num_hwfns * 2;\n\n\tif (is_kdump_kernel()) {\n\t\tDP_INFO(cdev,\n\t\t\t\"Kdump kernel: Limit the max number of requested MSI-X vectors to %hd\\n\",\n\t\t\tcdev->int_params.in.min_msix_cnt);\n\t\tcdev->int_params.in.num_vectors =\n\t\t\tcdev->int_params.in.min_msix_cnt;\n\t}\n\n\trc = qed_set_int_mode(cdev, false);\n\tif (rc)  {\n\t\tDP_ERR(cdev, \"%s ERR\\n\", __func__);\n\t\treturn rc;\n\t}\n\n\tcdev->int_params.fp_msix_base = cdev->num_hwfns;\n\tcdev->int_params.fp_msix_cnt = cdev->int_params.out.num_vectors -\n\t\t\t\t       cdev->num_hwfns;\n\n\tif (!IS_ENABLED(CONFIG_QED_RDMA) ||\n\t    !QED_IS_RDMA_PERSONALITY(QED_LEADING_HWFN(cdev)))\n\t\treturn 0;\n\n\tfor_each_hwfn(cdev, i)\n\t\tnum_l2_queues += FEAT_NUM(&cdev->hwfns[i], QED_PF_L2_QUE);\n\n\tDP_VERBOSE(cdev, QED_MSG_RDMA,\n\t\t   \"cdev->int_params.fp_msix_cnt=%d num_l2_queues=%d\\n\",\n\t\t   cdev->int_params.fp_msix_cnt, num_l2_queues);\n\n\tif (cdev->int_params.fp_msix_cnt > num_l2_queues) {\n\t\tcdev->int_params.rdma_msix_cnt =\n\t\t\t(cdev->int_params.fp_msix_cnt - num_l2_queues)\n\t\t\t/ cdev->num_hwfns;\n\t\tcdev->int_params.rdma_msix_base =\n\t\t\tcdev->int_params.fp_msix_base + num_l2_queues;\n\t\tcdev->int_params.fp_msix_cnt = num_l2_queues;\n\t} else {\n\t\tcdev->int_params.rdma_msix_cnt = 0;\n\t}\n\n\tDP_VERBOSE(cdev, QED_MSG_RDMA, \"roce_msix_cnt=%d roce_msix_base=%d\\n\",\n\t\t   cdev->int_params.rdma_msix_cnt,\n\t\t   cdev->int_params.rdma_msix_base);\n\n\treturn 0;\n}\n\nstatic int qed_slowpath_vf_setup_int(struct qed_dev *cdev)\n{\n\tint rc;\n\n\tmemset(&cdev->int_params, 0, sizeof(struct qed_int_params));\n\tcdev->int_params.in.int_mode = QED_INT_MODE_MSIX;\n\n\tqed_vf_get_num_rxqs(QED_LEADING_HWFN(cdev),\n\t\t\t    &cdev->int_params.in.num_vectors);\n\tif (cdev->num_hwfns > 1) {\n\t\tu8 vectors = 0;\n\n\t\tqed_vf_get_num_rxqs(&cdev->hwfns[1], &vectors);\n\t\tcdev->int_params.in.num_vectors += vectors;\n\t}\n\n\t \n\tcdev->int_params.in.min_msix_cnt = cdev->num_hwfns;\n\n\trc = qed_set_int_mode(cdev, true);\n\tif (rc)\n\t\treturn rc;\n\n\tcdev->int_params.fp_msix_base = 0;\n\tcdev->int_params.fp_msix_cnt = cdev->int_params.out.num_vectors;\n\n\treturn 0;\n}\n\nu32 qed_unzip_data(struct qed_hwfn *p_hwfn, u32 input_len,\n\t\t   u8 *input_buf, u32 max_size, u8 *unzip_buf)\n{\n\tint rc;\n\n\tp_hwfn->stream->next_in = input_buf;\n\tp_hwfn->stream->avail_in = input_len;\n\tp_hwfn->stream->next_out = unzip_buf;\n\tp_hwfn->stream->avail_out = max_size;\n\n\trc = zlib_inflateInit2(p_hwfn->stream, MAX_WBITS);\n\n\tif (rc != Z_OK) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_DRV, \"zlib init failed, rc = %d\\n\",\n\t\t\t   rc);\n\t\treturn 0;\n\t}\n\n\trc = zlib_inflate(p_hwfn->stream, Z_FINISH);\n\tzlib_inflateEnd(p_hwfn->stream);\n\n\tif (rc != Z_OK && rc != Z_STREAM_END) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_DRV, \"FW unzip error: %s, rc=%d\\n\",\n\t\t\t   p_hwfn->stream->msg, rc);\n\t\treturn 0;\n\t}\n\n\treturn p_hwfn->stream->total_out / 4;\n}\n\nstatic int qed_alloc_stream_mem(struct qed_dev *cdev)\n{\n\tint i;\n\tvoid *workspace;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tp_hwfn->stream = kzalloc(sizeof(*p_hwfn->stream), GFP_KERNEL);\n\t\tif (!p_hwfn->stream)\n\t\t\treturn -ENOMEM;\n\n\t\tworkspace = vzalloc(zlib_inflate_workspacesize());\n\t\tif (!workspace)\n\t\t\treturn -ENOMEM;\n\t\tp_hwfn->stream->workspace = workspace;\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_free_stream_mem(struct qed_dev *cdev)\n{\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tif (!p_hwfn->stream)\n\t\t\treturn;\n\n\t\tvfree(p_hwfn->stream->workspace);\n\t\tkfree(p_hwfn->stream);\n\t}\n}\n\nstatic void qed_update_pf_params(struct qed_dev *cdev,\n\t\t\t\t struct qed_pf_params *params)\n{\n\tint i;\n\n\tif (IS_ENABLED(CONFIG_QED_RDMA)) {\n\t\tparams->rdma_pf_params.num_qps = QED_ROCE_QPS;\n\t\tparams->rdma_pf_params.min_dpis = QED_ROCE_DPIS;\n\t\tparams->rdma_pf_params.num_srqs = QED_RDMA_SRQS;\n\t\t \n\t\tparams->rdma_pf_params.gl_pi = QED_ROCE_PROTOCOL_INDEX;\n\t}\n\n\tif (cdev->num_hwfns > 1 || IS_VF(cdev))\n\t\tparams->eth_pf_params.num_arfs_filters = 0;\n\n\t \n\tif (QED_IS_RDMA_PERSONALITY(QED_LEADING_HWFN(cdev))) {\n\t\tu16 *num_cons;\n\n\t\tnum_cons = &params->eth_pf_params.num_cons;\n\t\t*num_cons = min_t(u16, *num_cons, QED_MAX_L2_CONS);\n\t}\n\n\tfor (i = 0; i < cdev->num_hwfns; i++) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tp_hwfn->pf_params = *params;\n\t}\n}\n\n#define QED_PERIODIC_DB_REC_COUNT\t\t10\n#define QED_PERIODIC_DB_REC_INTERVAL_MS\t\t100\n#define QED_PERIODIC_DB_REC_INTERVAL \\\n\tmsecs_to_jiffies(QED_PERIODIC_DB_REC_INTERVAL_MS)\n\nstatic int qed_slowpath_delayed_work(struct qed_hwfn *hwfn,\n\t\t\t\t     enum qed_slowpath_wq_flag wq_flag,\n\t\t\t\t     unsigned long delay)\n{\n\tif (!hwfn->slowpath_wq_active)\n\t\treturn -EINVAL;\n\n\t \n\tsmp_mb__before_atomic();\n\tset_bit(wq_flag, &hwfn->slowpath_task_flags);\n\t \n\tsmp_mb__after_atomic();\n\tqueue_delayed_work(hwfn->slowpath_wq, &hwfn->slowpath_task, delay);\n\n\treturn 0;\n}\n\nvoid qed_periodic_db_rec_start(struct qed_hwfn *p_hwfn)\n{\n\t \n\tp_hwfn->periodic_db_rec_count = QED_PERIODIC_DB_REC_COUNT;\n\n\t \n\tif (test_bit(QED_SLOWPATH_PERIODIC_DB_REC,\n\t\t     &p_hwfn->slowpath_task_flags))\n\t\treturn;\n\n\tqed_slowpath_delayed_work(p_hwfn, QED_SLOWPATH_PERIODIC_DB_REC,\n\t\t\t\t  QED_PERIODIC_DB_REC_INTERVAL);\n}\n\nstatic void qed_slowpath_wq_stop(struct qed_dev *cdev)\n{\n\tint i;\n\n\tif (IS_VF(cdev))\n\t\treturn;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tif (!cdev->hwfns[i].slowpath_wq)\n\t\t\tcontinue;\n\n\t\t \n\t\tcdev->hwfns[i].slowpath_wq_active = false;\n\n\t\tcancel_delayed_work(&cdev->hwfns[i].slowpath_task);\n\t\tdestroy_workqueue(cdev->hwfns[i].slowpath_wq);\n\t}\n}\n\nstatic void qed_slowpath_task(struct work_struct *work)\n{\n\tstruct qed_hwfn *hwfn = container_of(work, struct qed_hwfn,\n\t\t\t\t\t     slowpath_task.work);\n\tstruct qed_ptt *ptt = qed_ptt_acquire(hwfn);\n\n\tif (!ptt) {\n\t\tif (hwfn->slowpath_wq_active)\n\t\t\tqueue_delayed_work(hwfn->slowpath_wq,\n\t\t\t\t\t   &hwfn->slowpath_task, 0);\n\n\t\treturn;\n\t}\n\n\tif (test_and_clear_bit(QED_SLOWPATH_MFW_TLV_REQ,\n\t\t\t       &hwfn->slowpath_task_flags))\n\t\tqed_mfw_process_tlv_req(hwfn, ptt);\n\n\tif (test_and_clear_bit(QED_SLOWPATH_PERIODIC_DB_REC,\n\t\t\t       &hwfn->slowpath_task_flags)) {\n\t\t \n\t\tif (hwfn->cdev->recov_in_prog || !hwfn->slowpath_wq_active)\n\t\t\tgoto out;\n\n\t\tqed_db_rec_handler(hwfn, ptt);\n\t\tif (hwfn->periodic_db_rec_count--)\n\t\t\tqed_slowpath_delayed_work(hwfn,\n\t\t\t\t\t\t  QED_SLOWPATH_PERIODIC_DB_REC,\n\t\t\t\t\t\t  QED_PERIODIC_DB_REC_INTERVAL);\n\t}\n\nout:\n\tqed_ptt_release(hwfn, ptt);\n}\n\nstatic int qed_slowpath_wq_start(struct qed_dev *cdev)\n{\n\tstruct qed_hwfn *hwfn;\n\tchar name[NAME_SIZE];\n\tint i;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tfor_each_hwfn(cdev, i) {\n\t\thwfn = &cdev->hwfns[i];\n\n\t\tsnprintf(name, NAME_SIZE, \"slowpath-%02x:%02x.%02x\",\n\t\t\t cdev->pdev->bus->number,\n\t\t\t PCI_SLOT(cdev->pdev->devfn), hwfn->abs_pf_id);\n\n\t\thwfn->slowpath_wq = alloc_workqueue(name, 0, 0);\n\t\tif (!hwfn->slowpath_wq) {\n\t\t\tDP_NOTICE(hwfn, \"Cannot create slowpath workqueue\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tINIT_DELAYED_WORK(&hwfn->slowpath_task, qed_slowpath_task);\n\t\thwfn->slowpath_wq_active = true;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_slowpath_start(struct qed_dev *cdev,\n\t\t\t      struct qed_slowpath_params *params)\n{\n\tstruct qed_drv_load_params drv_load_params;\n\tstruct qed_hw_init_params hw_init_params;\n\tstruct qed_mcp_drv_version drv_version;\n\tstruct qed_tunnel_info tunn_info;\n\tconst u8 *data = NULL;\n\tstruct qed_hwfn *hwfn;\n\tstruct qed_ptt *p_ptt;\n\tint rc = -EINVAL;\n\n\tif (qed_iov_wq_start(cdev))\n\t\tgoto err;\n\n\tif (qed_slowpath_wq_start(cdev))\n\t\tgoto err;\n\n\tif (IS_PF(cdev)) {\n\t\trc = request_firmware(&cdev->firmware, QED_FW_FILE_NAME,\n\t\t\t\t      &cdev->pdev->dev);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(cdev,\n\t\t\t\t  \"Failed to find fw file - /lib/firmware/%s\\n\",\n\t\t\t\t  QED_FW_FILE_NAME);\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (cdev->num_hwfns == 1) {\n\t\t\tp_ptt = qed_ptt_acquire(QED_LEADING_HWFN(cdev));\n\t\t\tif (p_ptt) {\n\t\t\t\tQED_LEADING_HWFN(cdev)->p_arfs_ptt = p_ptt;\n\t\t\t} else {\n\t\t\t\tDP_NOTICE(cdev,\n\t\t\t\t\t  \"Failed to acquire PTT for aRFS\\n\");\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\t}\n\n\tcdev->rx_coalesce_usecs = QED_DEFAULT_RX_USECS;\n\trc = qed_nic_setup(cdev);\n\tif (rc)\n\t\tgoto err;\n\n\tif (IS_PF(cdev))\n\t\trc = qed_slowpath_setup_int(cdev, params->int_mode);\n\telse\n\t\trc = qed_slowpath_vf_setup_int(cdev);\n\tif (rc)\n\t\tgoto err1;\n\n\tif (IS_PF(cdev)) {\n\t\t \n\t\trc = qed_alloc_stream_mem(cdev);\n\t\tif (rc)\n\t\t\tgoto err2;\n\n\t\t \n\t\tdata = cdev->firmware->data + sizeof(u32);\n\n\t\tqed_dbg_pf_init(cdev);\n\t}\n\n\t \n\tmemset(&hw_init_params, 0, sizeof(hw_init_params));\n\tmemset(&tunn_info, 0, sizeof(tunn_info));\n\ttunn_info.vxlan.b_mode_enabled = true;\n\ttunn_info.l2_gre.b_mode_enabled = true;\n\ttunn_info.ip_gre.b_mode_enabled = true;\n\ttunn_info.l2_geneve.b_mode_enabled = true;\n\ttunn_info.ip_geneve.b_mode_enabled = true;\n\ttunn_info.vxlan.tun_cls = QED_TUNN_CLSS_MAC_VLAN;\n\ttunn_info.l2_gre.tun_cls = QED_TUNN_CLSS_MAC_VLAN;\n\ttunn_info.ip_gre.tun_cls = QED_TUNN_CLSS_MAC_VLAN;\n\ttunn_info.l2_geneve.tun_cls = QED_TUNN_CLSS_MAC_VLAN;\n\ttunn_info.ip_geneve.tun_cls = QED_TUNN_CLSS_MAC_VLAN;\n\thw_init_params.p_tunn = &tunn_info;\n\thw_init_params.b_hw_start = true;\n\thw_init_params.int_mode = cdev->int_params.out.int_mode;\n\thw_init_params.allow_npar_tx_switch = true;\n\thw_init_params.bin_fw_data = data;\n\n\tmemset(&drv_load_params, 0, sizeof(drv_load_params));\n\tdrv_load_params.is_crash_kernel = is_kdump_kernel();\n\tdrv_load_params.mfw_timeout_val = QED_LOAD_REQ_LOCK_TO_DEFAULT;\n\tdrv_load_params.avoid_eng_reset = false;\n\tdrv_load_params.override_force_load = QED_OVERRIDE_FORCE_LOAD_NONE;\n\thw_init_params.p_drv_load_params = &drv_load_params;\n\n\trc = qed_hw_init(cdev, &hw_init_params);\n\tif (rc)\n\t\tgoto err2;\n\n\tDP_INFO(cdev,\n\t\t\"HW initialization and function start completed successfully\\n\");\n\n\tif (IS_PF(cdev)) {\n\t\tcdev->tunn_feature_mask = (BIT(QED_MODE_VXLAN_TUNN) |\n\t\t\t\t\t   BIT(QED_MODE_L2GENEVE_TUNN) |\n\t\t\t\t\t   BIT(QED_MODE_IPGENEVE_TUNN) |\n\t\t\t\t\t   BIT(QED_MODE_L2GRE_TUNN) |\n\t\t\t\t\t   BIT(QED_MODE_IPGRE_TUNN));\n\t}\n\n\t \n\tif (QED_LEADING_HWFN(cdev)->using_ll2) {\n\t\trc = qed_ll2_alloc_if(cdev);\n\t\tif (rc)\n\t\t\tgoto err3;\n\t}\n\tif (IS_PF(cdev)) {\n\t\thwfn = QED_LEADING_HWFN(cdev);\n\t\tdrv_version.version = (params->drv_major << 24) |\n\t\t\t\t      (params->drv_minor << 16) |\n\t\t\t\t      (params->drv_rev << 8) |\n\t\t\t\t      (params->drv_eng);\n\t\tstrscpy(drv_version.name, params->name,\n\t\t\tMCP_DRV_VER_STR_SIZE - 4);\n\t\trc = qed_mcp_send_drv_version(hwfn, hwfn->p_main_ptt,\n\t\t\t\t\t      &drv_version);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(cdev, \"Failed sending drv version command\\n\");\n\t\t\tgoto err4;\n\t\t}\n\t}\n\n\tqed_reset_vport_stats(cdev);\n\n\treturn 0;\n\nerr4:\n\tqed_ll2_dealloc_if(cdev);\nerr3:\n\tqed_hw_stop(cdev);\nerr2:\n\tqed_hw_timers_stop_all(cdev);\n\tif (IS_PF(cdev))\n\t\tqed_slowpath_irq_free(cdev);\n\tqed_free_stream_mem(cdev);\n\tqed_disable_msix(cdev);\nerr1:\n\tqed_resc_free(cdev);\nerr:\n\tif (IS_PF(cdev))\n\t\trelease_firmware(cdev->firmware);\n\n\tif (IS_PF(cdev) && (cdev->num_hwfns == 1) &&\n\t    QED_LEADING_HWFN(cdev)->p_arfs_ptt)\n\t\tqed_ptt_release(QED_LEADING_HWFN(cdev),\n\t\t\t\tQED_LEADING_HWFN(cdev)->p_arfs_ptt);\n\n\tqed_iov_wq_stop(cdev, false);\n\n\tqed_slowpath_wq_stop(cdev);\n\n\treturn rc;\n}\n\nstatic int qed_slowpath_stop(struct qed_dev *cdev)\n{\n\tif (!cdev)\n\t\treturn -ENODEV;\n\n\tqed_slowpath_wq_stop(cdev);\n\n\tqed_ll2_dealloc_if(cdev);\n\n\tif (IS_PF(cdev)) {\n\t\tif (cdev->num_hwfns == 1)\n\t\t\tqed_ptt_release(QED_LEADING_HWFN(cdev),\n\t\t\t\t\tQED_LEADING_HWFN(cdev)->p_arfs_ptt);\n\t\tqed_free_stream_mem(cdev);\n\t\tif (IS_QED_ETH_IF(cdev))\n\t\t\tqed_sriov_disable(cdev, true);\n\t}\n\n\tqed_nic_stop(cdev);\n\n\tif (IS_PF(cdev))\n\t\tqed_slowpath_irq_free(cdev);\n\n\tqed_disable_msix(cdev);\n\n\tqed_resc_free(cdev);\n\n\tqed_iov_wq_stop(cdev, true);\n\n\tif (IS_PF(cdev))\n\t\trelease_firmware(cdev->firmware);\n\n\treturn 0;\n}\n\nstatic void qed_set_name(struct qed_dev *cdev, char name[NAME_SIZE])\n{\n\tint i;\n\n\tmemcpy(cdev->name, name, NAME_SIZE);\n\tfor_each_hwfn(cdev, i)\n\t\tsnprintf(cdev->hwfns[i].name, NAME_SIZE, \"%s-%d\", name, i);\n}\n\nstatic u32 qed_sb_init(struct qed_dev *cdev,\n\t\t       struct qed_sb_info *sb_info,\n\t\t       void *sb_virt_addr,\n\t\t       dma_addr_t sb_phy_addr, u16 sb_id,\n\t\t       enum qed_sb_type type)\n{\n\tstruct qed_hwfn *p_hwfn;\n\tstruct qed_ptt *p_ptt;\n\tu16 rel_sb_id;\n\tu32 rc;\n\n\t \n\tif (type == QED_SB_TYPE_L2_QUEUE) {\n\t\tp_hwfn = &cdev->hwfns[sb_id % cdev->num_hwfns];\n\t\trel_sb_id = sb_id / cdev->num_hwfns;\n\t} else {\n\t\tp_hwfn = QED_AFFIN_HWFN(cdev);\n\t\trel_sb_id = sb_id;\n\t}\n\n\tDP_VERBOSE(cdev, NETIF_MSG_INTR,\n\t\t   \"hwfn [%d] <--[init]-- SB %04x [0x%04x upper]\\n\",\n\t\t   IS_LEAD_HWFN(p_hwfn) ? 0 : 1, rel_sb_id, sb_id);\n\n\tif (IS_PF(p_hwfn->cdev)) {\n\t\tp_ptt = qed_ptt_acquire(p_hwfn);\n\t\tif (!p_ptt)\n\t\t\treturn -EBUSY;\n\n\t\trc = qed_int_sb_init(p_hwfn, p_ptt, sb_info, sb_virt_addr,\n\t\t\t\t     sb_phy_addr, rel_sb_id);\n\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t} else {\n\t\trc = qed_int_sb_init(p_hwfn, NULL, sb_info, sb_virt_addr,\n\t\t\t\t     sb_phy_addr, rel_sb_id);\n\t}\n\n\treturn rc;\n}\n\nstatic u32 qed_sb_release(struct qed_dev *cdev,\n\t\t\t  struct qed_sb_info *sb_info,\n\t\t\t  u16 sb_id,\n\t\t\t  enum qed_sb_type type)\n{\n\tstruct qed_hwfn *p_hwfn;\n\tu16 rel_sb_id;\n\tu32 rc;\n\n\t \n\tif (type == QED_SB_TYPE_L2_QUEUE) {\n\t\tp_hwfn = &cdev->hwfns[sb_id % cdev->num_hwfns];\n\t\trel_sb_id = sb_id / cdev->num_hwfns;\n\t} else {\n\t\tp_hwfn = QED_AFFIN_HWFN(cdev);\n\t\trel_sb_id = sb_id;\n\t}\n\n\tDP_VERBOSE(cdev, NETIF_MSG_INTR,\n\t\t   \"hwfn [%d] <--[init]-- SB %04x [0x%04x upper]\\n\",\n\t\t   IS_LEAD_HWFN(p_hwfn) ? 0 : 1, rel_sb_id, sb_id);\n\n\trc = qed_int_sb_release(p_hwfn, sb_info, rel_sb_id);\n\n\treturn rc;\n}\n\nstatic bool qed_can_link_change(struct qed_dev *cdev)\n{\n\treturn true;\n}\n\nstatic void qed_set_ext_speed_params(struct qed_mcp_link_params *link_params,\n\t\t\t\t     const struct qed_link_params *params)\n{\n\tstruct qed_mcp_link_speed_params *ext_speed = &link_params->ext_speed;\n\tconst struct qed_mfw_speed_map *map;\n\tu32 i;\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_SPEED_AUTONEG)\n\t\text_speed->autoneg = !!params->autoneg;\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_SPEED_ADV_SPEEDS) {\n\t\text_speed->advertised_speeds = 0;\n\n\t\tfor (i = 0; i < ARRAY_SIZE(qed_mfw_ext_maps); i++) {\n\t\t\tmap = qed_mfw_ext_maps + i;\n\n\t\t\tif (linkmode_intersects(params->adv_speeds, map->caps))\n\t\t\t\text_speed->advertised_speeds |= map->mfw_val;\n\t\t}\n\t}\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_SPEED_FORCED_SPEED) {\n\t\tswitch (params->forced_speed) {\n\t\tcase SPEED_1000:\n\t\t\text_speed->forced_speed = QED_EXT_SPEED_1G;\n\t\t\tbreak;\n\t\tcase SPEED_10000:\n\t\t\text_speed->forced_speed = QED_EXT_SPEED_10G;\n\t\t\tbreak;\n\t\tcase SPEED_20000:\n\t\t\text_speed->forced_speed = QED_EXT_SPEED_20G;\n\t\t\tbreak;\n\t\tcase SPEED_25000:\n\t\t\text_speed->forced_speed = QED_EXT_SPEED_25G;\n\t\t\tbreak;\n\t\tcase SPEED_40000:\n\t\t\text_speed->forced_speed = QED_EXT_SPEED_40G;\n\t\t\tbreak;\n\t\tcase SPEED_50000:\n\t\t\text_speed->forced_speed = QED_EXT_SPEED_50G_R |\n\t\t\t\t\t\t  QED_EXT_SPEED_50G_R2;\n\t\t\tbreak;\n\t\tcase SPEED_100000:\n\t\t\text_speed->forced_speed = QED_EXT_SPEED_100G_R2 |\n\t\t\t\t\t\t  QED_EXT_SPEED_100G_R4 |\n\t\t\t\t\t\t  QED_EXT_SPEED_100G_P4;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!(params->override_flags & QED_LINK_OVERRIDE_FEC_CONFIG))\n\t\treturn;\n\n\tswitch (params->forced_speed) {\n\tcase SPEED_25000:\n\t\tswitch (params->fec) {\n\t\tcase FEC_FORCE_MODE_NONE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_25G_NONE;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_FIRECODE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_25G_BASE_R;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_RS:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_25G_RS528;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_AUTO:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_25G_RS528 |\n\t\t\t\t\t\t    ETH_EXT_FEC_25G_BASE_R |\n\t\t\t\t\t\t    ETH_EXT_FEC_25G_NONE;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tbreak;\n\tcase SPEED_40000:\n\t\tswitch (params->fec) {\n\t\tcase FEC_FORCE_MODE_NONE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_40G_NONE;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_FIRECODE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_40G_BASE_R;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_AUTO:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_40G_BASE_R |\n\t\t\t\t\t\t    ETH_EXT_FEC_40G_NONE;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tbreak;\n\tcase SPEED_50000:\n\t\tswitch (params->fec) {\n\t\tcase FEC_FORCE_MODE_NONE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_50G_NONE;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_FIRECODE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_50G_BASE_R;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_RS:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_50G_RS528;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_AUTO:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_50G_RS528 |\n\t\t\t\t\t\t    ETH_EXT_FEC_50G_BASE_R |\n\t\t\t\t\t\t    ETH_EXT_FEC_50G_NONE;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tbreak;\n\tcase SPEED_100000:\n\t\tswitch (params->fec) {\n\t\tcase FEC_FORCE_MODE_NONE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_100G_NONE;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_FIRECODE:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_100G_BASE_R;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_RS:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_100G_RS528;\n\t\t\tbreak;\n\t\tcase FEC_FORCE_MODE_AUTO:\n\t\t\tlink_params->ext_fec_mode = ETH_EXT_FEC_100G_RS528 |\n\t\t\t\t\t\t    ETH_EXT_FEC_100G_BASE_R |\n\t\t\t\t\t\t    ETH_EXT_FEC_100G_NONE;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic int qed_set_link(struct qed_dev *cdev, struct qed_link_params *params)\n{\n\tstruct qed_mcp_link_params *link_params;\n\tstruct qed_mcp_link_speed_params *speed;\n\tconst struct qed_mfw_speed_map *map;\n\tstruct qed_hwfn *hwfn;\n\tstruct qed_ptt *ptt;\n\tint rc;\n\tu32 i;\n\n\tif (!cdev)\n\t\treturn -ENODEV;\n\n\t \n\thwfn = &cdev->hwfns[0];\n\n\t \n\tif (IS_VF(cdev)) {\n\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_VF_FORCE_LINK_QUERY_FLAG);\n\t\treturn 0;\n\t}\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EBUSY;\n\n\tlink_params = qed_mcp_get_link_params(hwfn);\n\tif (!link_params)\n\t\treturn -ENODATA;\n\n\tspeed = &link_params->speed;\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_SPEED_AUTONEG)\n\t\tspeed->autoneg = !!params->autoneg;\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_SPEED_ADV_SPEEDS) {\n\t\tspeed->advertised_speeds = 0;\n\n\t\tfor (i = 0; i < ARRAY_SIZE(qed_mfw_legacy_maps); i++) {\n\t\t\tmap = qed_mfw_legacy_maps + i;\n\n\t\t\tif (linkmode_intersects(params->adv_speeds, map->caps))\n\t\t\t\tspeed->advertised_speeds |= map->mfw_val;\n\t\t}\n\t}\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_SPEED_FORCED_SPEED)\n\t\tspeed->forced_speed = params->forced_speed;\n\n\tif (qed_mcp_is_ext_speed_supported(hwfn))\n\t\tqed_set_ext_speed_params(link_params, params);\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_PAUSE_CONFIG) {\n\t\tif (params->pause_config & QED_LINK_PAUSE_AUTONEG_ENABLE)\n\t\t\tlink_params->pause.autoneg = true;\n\t\telse\n\t\t\tlink_params->pause.autoneg = false;\n\t\tif (params->pause_config & QED_LINK_PAUSE_RX_ENABLE)\n\t\t\tlink_params->pause.forced_rx = true;\n\t\telse\n\t\t\tlink_params->pause.forced_rx = false;\n\t\tif (params->pause_config & QED_LINK_PAUSE_TX_ENABLE)\n\t\t\tlink_params->pause.forced_tx = true;\n\t\telse\n\t\t\tlink_params->pause.forced_tx = false;\n\t}\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_LOOPBACK_MODE) {\n\t\tswitch (params->loopback_mode) {\n\t\tcase QED_LINK_LOOPBACK_INT_PHY:\n\t\t\tlink_params->loopback_mode = ETH_LOOPBACK_INT_PHY;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_EXT_PHY:\n\t\t\tlink_params->loopback_mode = ETH_LOOPBACK_EXT_PHY;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_EXT:\n\t\t\tlink_params->loopback_mode = ETH_LOOPBACK_EXT;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_MAC:\n\t\t\tlink_params->loopback_mode = ETH_LOOPBACK_MAC;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_CNIG_AH_ONLY_0123:\n\t\t\tlink_params->loopback_mode =\n\t\t\t\tETH_LOOPBACK_CNIG_AH_ONLY_0123;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_CNIG_AH_ONLY_2301:\n\t\t\tlink_params->loopback_mode =\n\t\t\t\tETH_LOOPBACK_CNIG_AH_ONLY_2301;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_PCS_AH_ONLY:\n\t\t\tlink_params->loopback_mode = ETH_LOOPBACK_PCS_AH_ONLY;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_REVERSE_MAC_AH_ONLY:\n\t\t\tlink_params->loopback_mode =\n\t\t\t\tETH_LOOPBACK_REVERSE_MAC_AH_ONLY;\n\t\t\tbreak;\n\t\tcase QED_LINK_LOOPBACK_INT_PHY_FEA_AH_ONLY:\n\t\t\tlink_params->loopback_mode =\n\t\t\t\tETH_LOOPBACK_INT_PHY_FEA_AH_ONLY;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlink_params->loopback_mode = ETH_LOOPBACK_NONE;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_EEE_CONFIG)\n\t\tmemcpy(&link_params->eee, &params->eee,\n\t\t       sizeof(link_params->eee));\n\n\tif (params->override_flags & QED_LINK_OVERRIDE_FEC_CONFIG)\n\t\tlink_params->fec = params->fec;\n\n\trc = qed_mcp_set_link(hwfn, ptt, params->link_up);\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn rc;\n}\n\nstatic int qed_get_port_type(u32 media_type)\n{\n\tint port_type;\n\n\tswitch (media_type) {\n\tcase MEDIA_SFPP_10G_FIBER:\n\tcase MEDIA_SFP_1G_FIBER:\n\tcase MEDIA_XFP_FIBER:\n\tcase MEDIA_MODULE_FIBER:\n\t\tport_type = PORT_FIBRE;\n\t\tbreak;\n\tcase MEDIA_DA_TWINAX:\n\t\tport_type = PORT_DA;\n\t\tbreak;\n\tcase MEDIA_BASE_T:\n\t\tport_type = PORT_TP;\n\t\tbreak;\n\tcase MEDIA_KR:\n\tcase MEDIA_NOT_PRESENT:\n\t\tport_type = PORT_NONE;\n\t\tbreak;\n\tcase MEDIA_UNSPECIFIED:\n\tdefault:\n\t\tport_type = PORT_OTHER;\n\t\tbreak;\n\t}\n\treturn port_type;\n}\n\nstatic int qed_get_link_data(struct qed_hwfn *hwfn,\n\t\t\t     struct qed_mcp_link_params *params,\n\t\t\t     struct qed_mcp_link_state *link,\n\t\t\t     struct qed_mcp_link_capabilities *link_caps)\n{\n\tvoid *p;\n\n\tif (!IS_PF(hwfn->cdev)) {\n\t\tqed_vf_get_link_params(hwfn, params);\n\t\tqed_vf_get_link_state(hwfn, link);\n\t\tqed_vf_get_link_caps(hwfn, link_caps);\n\n\t\treturn 0;\n\t}\n\n\tp = qed_mcp_get_link_params(hwfn);\n\tif (!p)\n\t\treturn -ENXIO;\n\tmemcpy(params, p, sizeof(*params));\n\n\tp = qed_mcp_get_link_state(hwfn);\n\tif (!p)\n\t\treturn -ENXIO;\n\tmemcpy(link, p, sizeof(*link));\n\n\tp = qed_mcp_get_link_capabilities(hwfn);\n\tif (!p)\n\t\treturn -ENXIO;\n\tmemcpy(link_caps, p, sizeof(*link_caps));\n\n\treturn 0;\n}\n\nstatic void qed_fill_link_capability(struct qed_hwfn *hwfn,\n\t\t\t\t     struct qed_ptt *ptt, u32 capability,\n\t\t\t\t     unsigned long *if_caps)\n{\n\tu32 media_type, tcvr_state, tcvr_type;\n\tu32 speed_mask, board_cfg;\n\n\tif (qed_mcp_get_media_type(hwfn, ptt, &media_type))\n\t\tmedia_type = MEDIA_UNSPECIFIED;\n\n\tif (qed_mcp_get_transceiver_data(hwfn, ptt, &tcvr_state, &tcvr_type))\n\t\ttcvr_type = ETH_TRANSCEIVER_STATE_UNPLUGGED;\n\n\tif (qed_mcp_trans_speed_mask(hwfn, ptt, &speed_mask))\n\t\tspeed_mask = 0xFFFFFFFF;\n\n\tif (qed_mcp_get_board_config(hwfn, ptt, &board_cfg))\n\t\tboard_cfg = NVM_CFG1_PORT_PORT_TYPE_UNDEFINED;\n\n\tDP_VERBOSE(hwfn->cdev, NETIF_MSG_DRV,\n\t\t   \"Media_type = 0x%x tcvr_state = 0x%x tcvr_type = 0x%x speed_mask = 0x%x board_cfg = 0x%x\\n\",\n\t\t   media_type, tcvr_state, tcvr_type, speed_mask, board_cfg);\n\n\tswitch (media_type) {\n\tcase MEDIA_DA_TWINAX:\n\t\tphylink_set(if_caps, FIBRE);\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_20G)\n\t\t\tphylink_set(if_caps, 20000baseKR2_Full);\n\n\t\t \n\t\tcapability |= speed_mask;\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G)\n\t\t\tphylink_set(if_caps, 1000baseKX_Full);\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G)\n\t\t\tphylink_set(if_caps, 10000baseCR_Full);\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G)\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_40G_CR4:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_CR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_CR:\n\t\t\t\tphylink_set(if_caps, 40000baseCR4_Full);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G)\n\t\t\tphylink_set(if_caps, 25000baseCR_Full);\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_50G)\n\t\t\tphylink_set(if_caps, 50000baseCR2_Full);\n\n\t\tif (capability &\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G)\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_100G_CR4:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_CR:\n\t\t\t\tphylink_set(if_caps, 100000baseCR4_Full);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tbreak;\n\tcase MEDIA_BASE_T:\n\t\tphylink_set(if_caps, TP);\n\n\t\tif (board_cfg & NVM_CFG1_PORT_PORT_TYPE_EXT_PHY) {\n\t\t\tif (capability &\n\t\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G)\n\t\t\t\tphylink_set(if_caps, 1000baseT_Full);\n\t\t\tif (capability &\n\t\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G)\n\t\t\t\tphylink_set(if_caps, 10000baseT_Full);\n\t\t}\n\n\t\tif (board_cfg & NVM_CFG1_PORT_PORT_TYPE_MODULE) {\n\t\t\tphylink_set(if_caps, FIBRE);\n\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_1000BASET:\n\t\t\t\tphylink_set(if_caps, 1000baseT_Full);\n\t\t\t\tbreak;\n\t\t\tcase ETH_TRANSCEIVER_TYPE_10G_BASET:\n\t\t\t\tphylink_set(if_caps, 10000baseT_Full);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\tcase MEDIA_SFP_1G_FIBER:\n\tcase MEDIA_SFPP_10G_FIBER:\n\tcase MEDIA_XFP_FIBER:\n\tcase MEDIA_MODULE_FIBER:\n\t\tphylink_set(if_caps, FIBRE);\n\t\tcapability |= speed_mask;\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G)\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_1G_LX:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_1G_SX:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_1G_10G_SR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_1G_10G_LR:\n\t\t\t\tphylink_set(if_caps, 1000baseKX_Full);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G)\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_10G_SR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_SR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_25G_SR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_1G_10G_SR:\n\t\t\t\tphylink_set(if_caps, 10000baseSR_Full);\n\t\t\t\tbreak;\n\t\t\tcase ETH_TRANSCEIVER_TYPE_10G_LR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_LR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_25G_LR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_1G_10G_LR:\n\t\t\t\tphylink_set(if_caps, 10000baseLR_Full);\n\t\t\t\tbreak;\n\t\t\tcase ETH_TRANSCEIVER_TYPE_10G_LRM:\n\t\t\t\tphylink_set(if_caps, 10000baseLRM_Full);\n\t\t\t\tbreak;\n\t\t\tcase ETH_TRANSCEIVER_TYPE_10G_ER:\n\t\t\t\tphylink_set(if_caps, 10000baseR_FEC);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_20G)\n\t\t\tphylink_set(if_caps, 20000baseKR2_Full);\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G)\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_25G_SR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_25G_SR:\n\t\t\t\tphylink_set(if_caps, 25000baseSR_Full);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G)\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_40G_LR4:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_LR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_LR:\n\t\t\t\tphylink_set(if_caps, 40000baseLR4_Full);\n\t\t\t\tbreak;\n\t\t\tcase ETH_TRANSCEIVER_TYPE_40G_SR4:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_SR:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_SR:\n\t\t\t\tphylink_set(if_caps, 40000baseSR4_Full);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_50G)\n\t\t\tphylink_set(if_caps, 50000baseKR2_Full);\n\n\t\tif (capability &\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G)\n\t\t\tswitch (tcvr_type) {\n\t\t\tcase ETH_TRANSCEIVER_TYPE_100G_SR4:\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_SR:\n\t\t\t\tphylink_set(if_caps, 100000baseSR4_Full);\n\t\t\t\tbreak;\n\t\t\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_LR:\n\t\t\t\tphylink_set(if_caps, 100000baseLR4_ER4_Full);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tbreak;\n\tcase MEDIA_KR:\n\t\tphylink_set(if_caps, Backplane);\n\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_20G)\n\t\t\tphylink_set(if_caps, 20000baseKR2_Full);\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G)\n\t\t\tphylink_set(if_caps, 1000baseKX_Full);\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G)\n\t\t\tphylink_set(if_caps, 10000baseKR_Full);\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G)\n\t\t\tphylink_set(if_caps, 25000baseKR_Full);\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G)\n\t\t\tphylink_set(if_caps, 40000baseKR4_Full);\n\t\tif (capability & NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_50G)\n\t\t\tphylink_set(if_caps, 50000baseKR2_Full);\n\t\tif (capability &\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G)\n\t\t\tphylink_set(if_caps, 100000baseKR4_Full);\n\n\t\tbreak;\n\tcase MEDIA_UNSPECIFIED:\n\tcase MEDIA_NOT_PRESENT:\n\tdefault:\n\t\tDP_VERBOSE(hwfn->cdev, QED_MSG_DEBUG,\n\t\t\t   \"Unknown media and transceiver type;\\n\");\n\t\tbreak;\n\t}\n}\n\nstatic void qed_lp_caps_to_speed_mask(u32 caps, u32 *speed_mask)\n{\n\t*speed_mask = 0;\n\n\tif (caps &\n\t    (QED_LINK_PARTNER_SPEED_1G_FD | QED_LINK_PARTNER_SPEED_1G_HD))\n\t\t*speed_mask |= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G;\n\tif (caps & QED_LINK_PARTNER_SPEED_10G)\n\t\t*speed_mask |= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G;\n\tif (caps & QED_LINK_PARTNER_SPEED_20G)\n\t\t*speed_mask |= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_20G;\n\tif (caps & QED_LINK_PARTNER_SPEED_25G)\n\t\t*speed_mask |= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G;\n\tif (caps & QED_LINK_PARTNER_SPEED_40G)\n\t\t*speed_mask |= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G;\n\tif (caps & QED_LINK_PARTNER_SPEED_50G)\n\t\t*speed_mask |= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_50G;\n\tif (caps & QED_LINK_PARTNER_SPEED_100G)\n\t\t*speed_mask |= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G;\n}\n\nstatic void qed_fill_link(struct qed_hwfn *hwfn,\n\t\t\t  struct qed_ptt *ptt,\n\t\t\t  struct qed_link_output *if_link)\n{\n\tstruct qed_mcp_link_capabilities link_caps;\n\tstruct qed_mcp_link_params params;\n\tstruct qed_mcp_link_state link;\n\tu32 media_type, speed_mask;\n\n\tmemset(if_link, 0, sizeof(*if_link));\n\n\t \n\tif (qed_get_link_data(hwfn, &params, &link, &link_caps)) {\n\t\tdev_warn(&hwfn->cdev->pdev->dev, \"no link data available\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (link.link_up)\n\t\tif_link->link_up = true;\n\n\tif (IS_PF(hwfn->cdev) && qed_mcp_is_ext_speed_supported(hwfn)) {\n\t\tif (link_caps.default_ext_autoneg)\n\t\t\tphylink_set(if_link->supported_caps, Autoneg);\n\n\t\tlinkmode_copy(if_link->advertised_caps, if_link->supported_caps);\n\n\t\tif (params.ext_speed.autoneg)\n\t\t\tphylink_set(if_link->advertised_caps, Autoneg);\n\t\telse\n\t\t\tphylink_clear(if_link->advertised_caps, Autoneg);\n\n\t\tqed_fill_link_capability(hwfn, ptt,\n\t\t\t\t\t params.ext_speed.advertised_speeds,\n\t\t\t\t\t if_link->advertised_caps);\n\t} else {\n\t\tif (link_caps.default_speed_autoneg)\n\t\t\tphylink_set(if_link->supported_caps, Autoneg);\n\n\t\tlinkmode_copy(if_link->advertised_caps, if_link->supported_caps);\n\n\t\tif (params.speed.autoneg)\n\t\t\tphylink_set(if_link->advertised_caps, Autoneg);\n\t\telse\n\t\t\tphylink_clear(if_link->advertised_caps, Autoneg);\n\t}\n\n\tif (params.pause.autoneg ||\n\t    (params.pause.forced_rx && params.pause.forced_tx))\n\t\tphylink_set(if_link->supported_caps, Asym_Pause);\n\tif (params.pause.autoneg || params.pause.forced_rx ||\n\t    params.pause.forced_tx)\n\t\tphylink_set(if_link->supported_caps, Pause);\n\n\tif_link->sup_fec = link_caps.fec_default;\n\tif_link->active_fec = params.fec;\n\n\t \n\tqed_fill_link_capability(hwfn, ptt, params.speed.advertised_speeds,\n\t\t\t\t if_link->advertised_caps);\n\n\t \n\tqed_fill_link_capability(hwfn, ptt, link_caps.speed_capabilities,\n\t\t\t\t if_link->supported_caps);\n\n\t \n\tqed_lp_caps_to_speed_mask(link.partner_adv_speed, &speed_mask);\n\tqed_fill_link_capability(hwfn, ptt, speed_mask, if_link->lp_caps);\n\n\tif (link.link_up)\n\t\tif_link->speed = link.speed;\n\n\t \n\tif_link->duplex = DUPLEX_FULL;\n\tqed_mcp_get_media_type(hwfn, ptt, &media_type);\n\tif_link->port = qed_get_port_type(media_type);\n\n\tif_link->autoneg = params.speed.autoneg;\n\n\tif (params.pause.autoneg)\n\t\tif_link->pause_config |= QED_LINK_PAUSE_AUTONEG_ENABLE;\n\tif (params.pause.forced_rx)\n\t\tif_link->pause_config |= QED_LINK_PAUSE_RX_ENABLE;\n\tif (params.pause.forced_tx)\n\t\tif_link->pause_config |= QED_LINK_PAUSE_TX_ENABLE;\n\n\tif (link.an_complete)\n\t\tphylink_set(if_link->lp_caps, Autoneg);\n\tif (link.partner_adv_pause)\n\t\tphylink_set(if_link->lp_caps, Pause);\n\tif (link.partner_adv_pause == QED_LINK_PARTNER_ASYMMETRIC_PAUSE ||\n\t    link.partner_adv_pause == QED_LINK_PARTNER_BOTH_PAUSE)\n\t\tphylink_set(if_link->lp_caps, Asym_Pause);\n\n\tif (link_caps.default_eee == QED_MCP_EEE_UNSUPPORTED) {\n\t\tif_link->eee_supported = false;\n\t} else {\n\t\tif_link->eee_supported = true;\n\t\tif_link->eee_active = link.eee_active;\n\t\tif_link->sup_caps = link_caps.eee_speed_caps;\n\t\t \n\t\tif_link->eee.adv_caps = link.eee_adv_caps ? link.eee_adv_caps :\n\t\t\t\t\tparams.eee.adv_caps;\n\t\tif_link->eee.lp_adv_caps = link.eee_lp_adv_caps;\n\t\tif_link->eee.enable = params.eee.enable;\n\t\tif_link->eee.tx_lpi_enable = params.eee.tx_lpi_enable;\n\t\tif_link->eee.tx_lpi_timer = params.eee.tx_lpi_timer;\n\t}\n}\n\nstatic void qed_get_current_link(struct qed_dev *cdev,\n\t\t\t\t struct qed_link_output *if_link)\n{\n\tstruct qed_hwfn *hwfn;\n\tstruct qed_ptt *ptt;\n\tint i;\n\n\thwfn = &cdev->hwfns[0];\n\tif (IS_PF(cdev)) {\n\t\tptt = qed_ptt_acquire(hwfn);\n\t\tif (ptt) {\n\t\t\tqed_fill_link(hwfn, ptt, if_link);\n\t\t\tqed_ptt_release(hwfn, ptt);\n\t\t} else {\n\t\t\tDP_NOTICE(hwfn, \"Failed to fill link; No PTT\\n\");\n\t\t}\n\t} else {\n\t\tqed_fill_link(hwfn, NULL, if_link);\n\t}\n\n\tfor_each_hwfn(cdev, i)\n\t\tqed_inform_vf_link_state(&cdev->hwfns[i]);\n}\n\nvoid qed_link_update(struct qed_hwfn *hwfn, struct qed_ptt *ptt)\n{\n\tvoid *cookie = hwfn->cdev->ops_cookie;\n\tstruct qed_common_cb_ops *op = hwfn->cdev->protocol_ops.common;\n\tstruct qed_link_output if_link;\n\n\tqed_fill_link(hwfn, ptt, &if_link);\n\tqed_inform_vf_link_state(hwfn);\n\n\tif (IS_LEAD_HWFN(hwfn) && cookie)\n\t\top->link_update(cookie, &if_link);\n}\n\nvoid qed_bw_update(struct qed_hwfn *hwfn, struct qed_ptt *ptt)\n{\n\tvoid *cookie = hwfn->cdev->ops_cookie;\n\tstruct qed_common_cb_ops *op = hwfn->cdev->protocol_ops.common;\n\n\tif (IS_LEAD_HWFN(hwfn) && cookie && op && op->bw_update)\n\t\top->bw_update(cookie);\n}\n\nstatic int qed_drain(struct qed_dev *cdev)\n{\n\tstruct qed_hwfn *hwfn;\n\tstruct qed_ptt *ptt;\n\tint i, rc;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tfor_each_hwfn(cdev, i) {\n\t\thwfn = &cdev->hwfns[i];\n\t\tptt = qed_ptt_acquire(hwfn);\n\t\tif (!ptt) {\n\t\t\tDP_NOTICE(hwfn, \"Failed to drain NIG; No PTT\\n\");\n\t\t\treturn -EBUSY;\n\t\t}\n\t\trc = qed_mcp_drain(hwfn, ptt);\n\t\tqed_ptt_release(hwfn, ptt);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic u32 qed_nvm_flash_image_access_crc(struct qed_dev *cdev,\n\t\t\t\t\t  struct qed_nvm_image_att *nvm_image,\n\t\t\t\t\t  u32 *crc)\n{\n\tu8 *buf = NULL;\n\tint rc;\n\n\t \n\tbuf = kzalloc(nvm_image->length, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t \n\trc = qed_mcp_nvm_read(cdev, nvm_image->start_addr,\n\t\t\t      buf, nvm_image->length);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed reading image from nvm\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\tcpu_to_be32_array((__force __be32 *)buf, (const u32 *)buf,\n\t\t\t  DIV_ROUND_UP(nvm_image->length - 4, 4));\n\n\t \n\t*crc = ~crc32(~0U, buf, nvm_image->length - 4);\n\t*crc = (__force u32)cpu_to_be32p(crc);\n\nout:\n\tkfree(buf);\n\n\treturn rc;\n}\n\n \nstatic int qed_nvm_flash_image_access(struct qed_dev *cdev, const u8 **data,\n\t\t\t\t      bool *check_resp)\n{\n\tstruct qed_nvm_image_att nvm_image;\n\tstruct qed_hwfn *p_hwfn;\n\tbool is_crc = false;\n\tu32 image_type;\n\tint rc = 0, i;\n\tu16 len;\n\n\t*data += 4;\n\timage_type = **data;\n\tp_hwfn = QED_LEADING_HWFN(cdev);\n\tfor (i = 0; i < p_hwfn->nvm_info.num_images; i++)\n\t\tif (image_type == p_hwfn->nvm_info.image_att[i].image_type)\n\t\t\tbreak;\n\tif (i == p_hwfn->nvm_info.num_images) {\n\t\tDP_ERR(cdev, \"Failed to find nvram image of type %08x\\n\",\n\t\t       image_type);\n\t\treturn -ENOENT;\n\t}\n\n\tnvm_image.start_addr = p_hwfn->nvm_info.image_att[i].nvm_start_addr;\n\tnvm_image.length = p_hwfn->nvm_info.image_att[i].len;\n\n\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t   \"Read image %02x; type = %08x; NVM [%08x,...,%08x]\\n\",\n\t\t   **data, image_type, nvm_image.start_addr,\n\t\t   nvm_image.start_addr + nvm_image.length - 1);\n\t(*data)++;\n\tis_crc = !!(**data & BIT(0));\n\t(*data)++;\n\tlen = *((u16 *)*data);\n\t*data += 2;\n\tif (is_crc) {\n\t\tu32 crc = 0;\n\n\t\trc = qed_nvm_flash_image_access_crc(cdev, &nvm_image, &crc);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Failed calculating CRC, rc = %d\\n\", rc);\n\t\t\tgoto exit;\n\t\t}\n\n\t\trc = qed_mcp_nvm_write(cdev, QED_NVM_WRITE_NVRAM,\n\t\t\t\t       (nvm_image.start_addr +\n\t\t\t\t\tnvm_image.length - 4), (u8 *)&crc, 4);\n\t\tif (rc)\n\t\t\tDP_ERR(cdev, \"Failed writing to %08x, rc = %d\\n\",\n\t\t\t       nvm_image.start_addr + nvm_image.length - 4, rc);\n\t\tgoto exit;\n\t}\n\n\t \n\twhile (len) {\n\t\tu32 offset, mask, value, cur_value;\n\t\tu8 buf[4];\n\n\t\tvalue = *((u32 *)*data);\n\t\t*data += 4;\n\t\tmask = *((u32 *)*data);\n\t\t*data += 4;\n\t\toffset = *((u32 *)*data);\n\t\t*data += 4;\n\n\t\trc = qed_mcp_nvm_read(cdev, nvm_image.start_addr + offset, buf,\n\t\t\t\t      4);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Failed reading from %08x\\n\",\n\t\t\t       nvm_image.start_addr + offset);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tcur_value = le32_to_cpu(*((__le32 *)buf));\n\t\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t\t   \"NVM %08x: %08x -> %08x [Value %08x Mask %08x]\\n\",\n\t\t\t   nvm_image.start_addr + offset, cur_value,\n\t\t\t   (cur_value & ~mask) | (value & mask), value, mask);\n\t\tvalue = (value & mask) | (cur_value & ~mask);\n\t\trc = qed_mcp_nvm_write(cdev, QED_NVM_WRITE_NVRAM,\n\t\t\t\t       nvm_image.start_addr + offset,\n\t\t\t\t       (u8 *)&value, 4);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Failed writing to %08x\\n\",\n\t\t\t       nvm_image.start_addr + offset);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tlen--;\n\t}\nexit:\n\treturn rc;\n}\n\n \nstatic int qed_nvm_flash_image_file_start(struct qed_dev *cdev,\n\t\t\t\t\t  const u8 **data, bool *check_resp)\n{\n\tu32 file_type, file_size = 0;\n\tint rc;\n\n\t*data += 4;\n\t*check_resp = !!(**data & BIT(0));\n\t*data += 4;\n\tfile_type = **data;\n\n\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t   \"About to start a new file of type %02x\\n\", file_type);\n\tif (file_type == DRV_MB_PARAM_NVM_PUT_FILE_BEGIN_MBI) {\n\t\t*data += 4;\n\t\tfile_size = *((u32 *)(*data));\n\t}\n\n\trc = qed_mcp_nvm_write(cdev, QED_PUT_FILE_BEGIN, file_type,\n\t\t\t       (u8 *)(&file_size), 4);\n\t*data += 4;\n\n\treturn rc;\n}\n\n \nstatic int qed_nvm_flash_image_file_data(struct qed_dev *cdev,\n\t\t\t\t\t const u8 **data, bool *check_resp)\n{\n\tu32 offset, len;\n\tint rc;\n\n\t*data += 4;\n\tlen = *((u32 *)(*data));\n\t*data += 4;\n\t*check_resp = !!(**data & BIT(0));\n\t*data += 4;\n\toffset = *((u32 *)(*data));\n\t*data += 4;\n\n\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t   \"About to write File-data: %08x bytes to offset %08x\\n\",\n\t\t   len, offset);\n\n\trc = qed_mcp_nvm_write(cdev, QED_PUT_FILE_DATA, offset,\n\t\t\t       (char *)(*data), len);\n\t*data += len;\n\n\treturn rc;\n}\n\n \nstatic int qed_nvm_flash_image_validate(struct qed_dev *cdev,\n\t\t\t\t\tconst struct firmware *image,\n\t\t\t\t\tconst u8 **data)\n{\n\tu32 signature, len;\n\n\t \n\tif (image->size < 12) {\n\t\tDP_ERR(cdev, \"Image is too short [%08x]\\n\", (u32)image->size);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tsignature = *((u32 *)(*data));\n\tif (signature != QED_NVM_SIGNATURE) {\n\t\tDP_ERR(cdev, \"Wrong signature '%08x'\\n\", signature);\n\t\treturn -EINVAL;\n\t}\n\n\t*data += 4;\n\t \n\tlen = *((u32 *)(*data));\n\tif (len != image->size) {\n\t\tDP_ERR(cdev, \"Size mismatch: internal = %08x image = %08x\\n\",\n\t\t       len, (u32)image->size);\n\t\treturn -EINVAL;\n\t}\n\n\t*data += 4;\n\t \n\tif (*((u16 *)(*data)) >= QED_NVM_FLASH_CMD_NVM_MAX) {\n\t\tDP_ERR(cdev, \"File contains unsupported commands [Need %04x]\\n\",\n\t\t       *((u16 *)(*data)));\n\t\treturn -EINVAL;\n\t}\n\n\t*data += 4;\n\n\treturn 0;\n}\n\n \nstatic int qed_nvm_flash_cfg_write(struct qed_dev *cdev, const u8 **data)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tu8 entity_id, len, buf[32];\n\tbool need_nvm_init = true;\n\tstruct qed_ptt *ptt;\n\tu16 cfg_id, count;\n\tint rc = 0, i;\n\tu32 flags;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\t \n\t*data += 4;\n\tcount = *((u16 *)*data);\n\t*data += 4;\n\n\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t   \"Read config ids: num_attrs = %0d\\n\", count);\n\t \n\tfor (i = 1; i <= count; i++) {\n\t\tcfg_id = *((u16 *)*data);\n\t\t*data += 2;\n\t\tentity_id = **data;\n\t\t(*data)++;\n\t\tlen = **data;\n\t\t(*data)++;\n\t\tmemcpy(buf, *data, len);\n\t\t*data += len;\n\n\t\tflags = 0;\n\t\tif (need_nvm_init) {\n\t\t\tflags |= QED_NVM_CFG_OPTION_INIT;\n\t\t\tneed_nvm_init = false;\n\t\t}\n\n\t\t \n\t\tif (!(i % QED_NVM_CFG_MAX_ATTRS) || i == count) {\n\t\t\tflags |= QED_NVM_CFG_OPTION_COMMIT |\n\t\t\t\t QED_NVM_CFG_OPTION_FREE;\n\t\t\tneed_nvm_init = true;\n\t\t}\n\n\t\tif (entity_id)\n\t\t\tflags |= QED_NVM_CFG_OPTION_ENTITY_SEL;\n\n\t\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t\t   \"cfg_id = %d entity = %d len = %d\\n\", cfg_id,\n\t\t\t   entity_id, len);\n\t\trc = qed_mcp_nvm_set_cfg(hwfn, ptt, cfg_id, entity_id, flags,\n\t\t\t\t\t buf, len);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Error %d configuring %d\\n\", rc, cfg_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn rc;\n}\n\n#define QED_MAX_NVM_BUF_LEN\t32\nstatic int qed_nvm_flash_cfg_len(struct qed_dev *cdev, u32 cmd)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tu8 buf[QED_MAX_NVM_BUF_LEN];\n\tstruct qed_ptt *ptt;\n\tu32 len;\n\tint rc;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn QED_MAX_NVM_BUF_LEN;\n\n\trc = qed_mcp_nvm_get_cfg(hwfn, ptt, cmd, 0, QED_NVM_CFG_GET_FLAGS, buf,\n\t\t\t\t &len);\n\tif (rc || !len) {\n\t\tDP_ERR(cdev, \"Error %d reading %d\\n\", rc, cmd);\n\t\tlen = QED_MAX_NVM_BUF_LEN;\n\t}\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn len;\n}\n\nstatic int qed_nvm_flash_cfg_read(struct qed_dev *cdev, u8 **data,\n\t\t\t\t  u32 cmd, u32 entity_id)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tu32 flags, len;\n\tint rc = 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t   \"Read config cmd = %d entity id %d\\n\", cmd, entity_id);\n\tflags = entity_id ? QED_NVM_CFG_GET_PF_FLAGS : QED_NVM_CFG_GET_FLAGS;\n\trc = qed_mcp_nvm_get_cfg(hwfn, ptt, cmd, entity_id, flags, *data, &len);\n\tif (rc)\n\t\tDP_ERR(cdev, \"Error %d reading %d\\n\", rc, cmd);\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn rc;\n}\n\nstatic int qed_nvm_flash(struct qed_dev *cdev, const char *name)\n{\n\tconst struct firmware *image;\n\tconst u8 *data, *data_end;\n\tu32 cmd_type;\n\tint rc;\n\n\trc = request_firmware(&image, name, &cdev->pdev->dev);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed to find '%s'\\n\", name);\n\t\treturn rc;\n\t}\n\n\tDP_VERBOSE(cdev, NETIF_MSG_DRV,\n\t\t   \"Flashing '%s' - firmware's data at %p, size is %08x\\n\",\n\t\t   name, image->data, (u32)image->size);\n\tdata = image->data;\n\tdata_end = data + image->size;\n\n\trc = qed_nvm_flash_image_validate(cdev, image, &data);\n\tif (rc)\n\t\tgoto exit;\n\n\twhile (data < data_end) {\n\t\tbool check_resp = false;\n\n\t\t \n\t\tcmd_type = *((u32 *)data);\n\t\tswitch (cmd_type) {\n\t\tcase QED_NVM_FLASH_CMD_FILE_DATA:\n\t\t\trc = qed_nvm_flash_image_file_data(cdev, &data,\n\t\t\t\t\t\t\t   &check_resp);\n\t\t\tbreak;\n\t\tcase QED_NVM_FLASH_CMD_FILE_START:\n\t\t\trc = qed_nvm_flash_image_file_start(cdev, &data,\n\t\t\t\t\t\t\t    &check_resp);\n\t\t\tbreak;\n\t\tcase QED_NVM_FLASH_CMD_NVM_CHANGE:\n\t\t\trc = qed_nvm_flash_image_access(cdev, &data,\n\t\t\t\t\t\t\t&check_resp);\n\t\t\tbreak;\n\t\tcase QED_NVM_FLASH_CMD_NVM_CFG_ID:\n\t\t\trc = qed_nvm_flash_cfg_write(cdev, &data);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDP_ERR(cdev, \"Unknown command %08x\\n\", cmd_type);\n\t\t\trc = -EINVAL;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Command %08x failed\\n\", cmd_type);\n\t\t\tgoto exit;\n\t\t}\n\n\t\t \n\t\tif (check_resp) {\n\t\t\tu32 mcp_response = 0;\n\n\t\t\tif (qed_mcp_nvm_resp(cdev, (u8 *)&mcp_response)) {\n\t\t\t\tDP_ERR(cdev, \"Failed getting MCP response\\n\");\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto exit;\n\t\t\t}\n\n\t\t\tswitch (mcp_response & FW_MSG_CODE_MASK) {\n\t\t\tcase FW_MSG_CODE_OK:\n\t\t\tcase FW_MSG_CODE_NVM_OK:\n\t\t\tcase FW_MSG_CODE_NVM_PUT_FILE_FINISH_OK:\n\t\t\tcase FW_MSG_CODE_PHY_OK:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tDP_ERR(cdev, \"MFW returns error: %08x\\n\",\n\t\t\t\t       mcp_response);\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t}\n\nexit:\n\trelease_firmware(image);\n\n\treturn rc;\n}\n\nstatic int qed_nvm_get_image(struct qed_dev *cdev, enum qed_nvm_images type,\n\t\t\t     u8 *buf, u16 len)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\n\treturn qed_mcp_get_nvm_image(hwfn, type, buf, len);\n}\n\nvoid qed_schedule_recovery_handler(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_common_cb_ops *ops = p_hwfn->cdev->protocol_ops.common;\n\tvoid *cookie = p_hwfn->cdev->ops_cookie;\n\n\tif (ops && ops->schedule_recovery_handler)\n\t\tops->schedule_recovery_handler(cookie);\n}\n\nstatic const char * const qed_hw_err_type_descr[] = {\n\t[QED_HW_ERR_FAN_FAIL]\t\t= \"Fan Failure\",\n\t[QED_HW_ERR_MFW_RESP_FAIL]\t= \"MFW Response Failure\",\n\t[QED_HW_ERR_HW_ATTN]\t\t= \"HW Attention\",\n\t[QED_HW_ERR_DMAE_FAIL]\t\t= \"DMAE Failure\",\n\t[QED_HW_ERR_RAMROD_FAIL]\t= \"Ramrod Failure\",\n\t[QED_HW_ERR_FW_ASSERT]\t\t= \"FW Assertion\",\n\t[QED_HW_ERR_LAST]\t\t= \"Unknown\",\n};\n\nvoid qed_hw_error_occurred(struct qed_hwfn *p_hwfn,\n\t\t\t   enum qed_hw_err_type err_type)\n{\n\tstruct qed_common_cb_ops *ops = p_hwfn->cdev->protocol_ops.common;\n\tvoid *cookie = p_hwfn->cdev->ops_cookie;\n\tconst char *err_str;\n\n\tif (err_type > QED_HW_ERR_LAST)\n\t\terr_type = QED_HW_ERR_LAST;\n\terr_str = qed_hw_err_type_descr[err_type];\n\n\tDP_NOTICE(p_hwfn, \"HW error occurred [%s]\\n\", err_str);\n\n\t \n\tif (ops && ops->schedule_hw_err_handler)\n\t\tops->schedule_hw_err_handler(cookie, err_type);\n\telse\n\t\tqed_int_attn_clr_enable(p_hwfn->cdev, true);\n}\n\nstatic int qed_set_coalesce(struct qed_dev *cdev, u16 rx_coal, u16 tx_coal,\n\t\t\t    void *handle)\n{\n\t\treturn qed_set_queue_coalesce(rx_coal, tx_coal, handle);\n}\n\nstatic int qed_set_led(struct qed_dev *cdev, enum qed_led_mode mode)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint status = 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\tstatus = qed_mcp_set_led(hwfn, ptt, mode);\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn status;\n}\n\nint qed_recovery_process(struct qed_dev *cdev)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt;\n\tint rc = 0;\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\trc = qed_start_recovery_process(p_hwfn, p_ptt);\n\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nstatic int qed_update_wol(struct qed_dev *cdev, bool enabled)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint rc = 0;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\trc = qed_mcp_ov_update_wol(hwfn, ptt, enabled ? QED_OV_WOL_ENABLED\n\t\t\t\t   : QED_OV_WOL_DISABLED);\n\tif (rc)\n\t\tgoto out;\n\trc = qed_mcp_ov_update_current_config(hwfn, ptt, QED_OV_CLIENT_DRV);\n\nout:\n\tqed_ptt_release(hwfn, ptt);\n\treturn rc;\n}\n\nstatic int qed_update_drv_state(struct qed_dev *cdev, bool active)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint status = 0;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\tstatus = qed_mcp_ov_update_driver_state(hwfn, ptt, active ?\n\t\t\t\t\t\tQED_OV_DRIVER_STATE_ACTIVE :\n\t\t\t\t\t\tQED_OV_DRIVER_STATE_DISABLED);\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn status;\n}\n\nstatic int qed_update_mac(struct qed_dev *cdev, const u8 *mac)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint status = 0;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\tstatus = qed_mcp_ov_update_mac(hwfn, ptt, mac);\n\tif (status)\n\t\tgoto out;\n\n\tstatus = qed_mcp_ov_update_current_config(hwfn, ptt, QED_OV_CLIENT_DRV);\n\nout:\n\tqed_ptt_release(hwfn, ptt);\n\treturn status;\n}\n\nstatic int qed_update_mtu(struct qed_dev *cdev, u16 mtu)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint status = 0;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\tstatus = qed_mcp_ov_update_mtu(hwfn, ptt, mtu);\n\tif (status)\n\t\tgoto out;\n\n\tstatus = qed_mcp_ov_update_current_config(hwfn, ptt, QED_OV_CLIENT_DRV);\n\nout:\n\tqed_ptt_release(hwfn, ptt);\n\treturn status;\n}\n\nstatic int\nqed_get_sb_info(struct qed_dev *cdev, struct qed_sb_info *sb,\n\t\tu16 qid, struct qed_sb_info_dbg *sb_dbg)\n{\n\tstruct qed_hwfn *hwfn = &cdev->hwfns[qid % cdev->num_hwfns];\n\tstruct qed_ptt *ptt;\n\tint rc;\n\n\tif (IS_VF(cdev))\n\t\treturn -EINVAL;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt) {\n\t\tDP_NOTICE(hwfn, \"Can't acquire PTT\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\tmemset(sb_dbg, 0, sizeof(*sb_dbg));\n\trc = qed_int_get_sb_dbg(hwfn, ptt, sb, sb_dbg);\n\n\tqed_ptt_release(hwfn, ptt);\n\treturn rc;\n}\n\nstatic int qed_read_module_eeprom(struct qed_dev *cdev, char *buf,\n\t\t\t\t  u8 dev_addr, u32 offset, u32 len)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint rc = 0;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\trc = qed_mcp_phy_sfp_read(hwfn, ptt, MFW_PORT(hwfn), dev_addr,\n\t\t\t\t  offset, len, buf);\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn rc;\n}\n\nstatic int qed_set_grc_config(struct qed_dev *cdev, u32 cfg_id, u32 val)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint rc = 0;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\trc = qed_dbg_grc_config(hwfn, cfg_id, val);\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn rc;\n}\n\nstatic __printf(2, 3) void qed_mfw_report(struct qed_dev *cdev, char *fmt, ...)\n{\n\tchar buf[QED_MFW_REPORT_STR_SIZE];\n\tstruct qed_hwfn *p_hwfn;\n\tstruct qed_ptt *p_ptt;\n\tva_list vl;\n\n\tva_start(vl, fmt);\n\tvsnprintf(buf, QED_MFW_REPORT_STR_SIZE, fmt, vl);\n\tva_end(vl);\n\n\tif (IS_PF(cdev)) {\n\t\tp_hwfn = QED_LEADING_HWFN(cdev);\n\t\tp_ptt = qed_ptt_acquire(p_hwfn);\n\t\tif (p_ptt) {\n\t\t\tqed_mcp_send_raw_debug_data(p_hwfn, p_ptt, buf, strlen(buf));\n\t\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t\t}\n\t}\n}\n\nstatic u8 qed_get_affin_hwfn_idx(struct qed_dev *cdev)\n{\n\treturn QED_AFFIN_HWFN_IDX(cdev);\n}\n\nstatic int qed_get_esl_status(struct qed_dev *cdev, bool *esl_active)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *ptt;\n\tint rc = 0;\n\n\t*esl_active = false;\n\n\tif (IS_VF(cdev))\n\t\treturn 0;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt)\n\t\treturn -EAGAIN;\n\n\trc = qed_mcp_get_esl_status(hwfn, ptt, esl_active);\n\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn rc;\n}\n\nstatic struct qed_selftest_ops qed_selftest_ops_pass = {\n\t.selftest_memory = &qed_selftest_memory,\n\t.selftest_interrupt = &qed_selftest_interrupt,\n\t.selftest_register = &qed_selftest_register,\n\t.selftest_clock = &qed_selftest_clock,\n\t.selftest_nvram = &qed_selftest_nvram,\n};\n\nconst struct qed_common_ops qed_common_ops_pass = {\n\t.selftest = &qed_selftest_ops_pass,\n\t.probe = &qed_probe,\n\t.remove = &qed_remove,\n\t.set_power_state = &qed_set_power_state,\n\t.set_name = &qed_set_name,\n\t.update_pf_params = &qed_update_pf_params,\n\t.slowpath_start = &qed_slowpath_start,\n\t.slowpath_stop = &qed_slowpath_stop,\n\t.set_fp_int = &qed_set_int_fp,\n\t.get_fp_int = &qed_get_int_fp,\n\t.sb_init = &qed_sb_init,\n\t.sb_release = &qed_sb_release,\n\t.simd_handler_config = &qed_simd_handler_config,\n\t.simd_handler_clean = &qed_simd_handler_clean,\n\t.dbg_grc = &qed_dbg_grc,\n\t.dbg_grc_size = &qed_dbg_grc_size,\n\t.can_link_change = &qed_can_link_change,\n\t.set_link = &qed_set_link,\n\t.get_link = &qed_get_current_link,\n\t.drain = &qed_drain,\n\t.update_msglvl = &qed_init_dp,\n\t.devlink_register = qed_devlink_register,\n\t.devlink_unregister = qed_devlink_unregister,\n\t.report_fatal_error = qed_report_fatal_error,\n\t.dbg_all_data = &qed_dbg_all_data,\n\t.dbg_all_data_size = &qed_dbg_all_data_size,\n\t.chain_alloc = &qed_chain_alloc,\n\t.chain_free = &qed_chain_free,\n\t.nvm_flash = &qed_nvm_flash,\n\t.nvm_get_image = &qed_nvm_get_image,\n\t.set_coalesce = &qed_set_coalesce,\n\t.set_led = &qed_set_led,\n\t.recovery_process = &qed_recovery_process,\n\t.recovery_prolog = &qed_recovery_prolog,\n\t.attn_clr_enable = &qed_int_attn_clr_enable,\n\t.update_drv_state = &qed_update_drv_state,\n\t.update_mac = &qed_update_mac,\n\t.update_mtu = &qed_update_mtu,\n\t.update_wol = &qed_update_wol,\n\t.db_recovery_add = &qed_db_recovery_add,\n\t.db_recovery_del = &qed_db_recovery_del,\n\t.read_module_eeprom = &qed_read_module_eeprom,\n\t.get_affin_hwfn_idx = &qed_get_affin_hwfn_idx,\n\t.read_nvm_cfg = &qed_nvm_flash_cfg_read,\n\t.read_nvm_cfg_len = &qed_nvm_flash_cfg_len,\n\t.set_grc_config = &qed_set_grc_config,\n\t.mfw_report = &qed_mfw_report,\n\t.get_sb_info = &qed_get_sb_info,\n\t.get_esl_status = &qed_get_esl_status,\n};\n\nvoid qed_get_protocol_stats(struct qed_dev *cdev,\n\t\t\t    enum qed_mcp_protocol_type type,\n\t\t\t    union qed_mcp_protocol_stats *stats)\n{\n\tstruct qed_eth_stats eth_stats;\n\n\tmemset(stats, 0, sizeof(*stats));\n\n\tswitch (type) {\n\tcase QED_MCP_LAN_STATS:\n\t\tqed_get_vport_stats_context(cdev, &eth_stats, true);\n\t\tstats->lan_stats.ucast_rx_pkts =\n\t\t\t\t\teth_stats.common.rx_ucast_pkts;\n\t\tstats->lan_stats.ucast_tx_pkts =\n\t\t\t\t\teth_stats.common.tx_ucast_pkts;\n\t\tstats->lan_stats.fcs_err = -1;\n\t\tbreak;\n\tcase QED_MCP_FCOE_STATS:\n\t\tqed_get_protocol_stats_fcoe(cdev, &stats->fcoe_stats, true);\n\t\tbreak;\n\tcase QED_MCP_ISCSI_STATS:\n\t\tqed_get_protocol_stats_iscsi(cdev, &stats->iscsi_stats, true);\n\t\tbreak;\n\tdefault:\n\t\tDP_VERBOSE(cdev, QED_MSG_SP,\n\t\t\t   \"Invalid protocol type = %d\\n\", type);\n\t\treturn;\n\t}\n}\n\nint qed_mfw_tlv_req(struct qed_hwfn *hwfn)\n{\n\tDP_VERBOSE(hwfn->cdev, NETIF_MSG_DRV,\n\t\t   \"Scheduling slowpath task [Flag: %d]\\n\",\n\t\t   QED_SLOWPATH_MFW_TLV_REQ);\n\t \n\tsmp_mb__before_atomic();\n\tset_bit(QED_SLOWPATH_MFW_TLV_REQ, &hwfn->slowpath_task_flags);\n\t \n\tsmp_mb__after_atomic();\n\tqueue_delayed_work(hwfn->slowpath_wq, &hwfn->slowpath_task, 0);\n\n\treturn 0;\n}\n\nstatic void\nqed_fill_generic_tlv_data(struct qed_dev *cdev, struct qed_mfw_tlv_generic *tlv)\n{\n\tstruct qed_common_cb_ops *op = cdev->protocol_ops.common;\n\tstruct qed_eth_stats_common *p_common;\n\tstruct qed_generic_tlvs gen_tlvs;\n\tstruct qed_eth_stats stats;\n\tint i;\n\n\tmemset(&gen_tlvs, 0, sizeof(gen_tlvs));\n\top->get_generic_tlv_data(cdev->ops_cookie, &gen_tlvs);\n\n\tif (gen_tlvs.feat_flags & QED_TLV_IP_CSUM)\n\t\ttlv->flags.ipv4_csum_offload = true;\n\tif (gen_tlvs.feat_flags & QED_TLV_LSO)\n\t\ttlv->flags.lso_supported = true;\n\ttlv->flags.b_set = true;\n\n\tfor (i = 0; i < QED_TLV_MAC_COUNT; i++) {\n\t\tif (is_valid_ether_addr(gen_tlvs.mac[i])) {\n\t\t\tether_addr_copy(tlv->mac[i], gen_tlvs.mac[i]);\n\t\t\ttlv->mac_set[i] = true;\n\t\t}\n\t}\n\n\tqed_get_vport_stats(cdev, &stats);\n\tp_common = &stats.common;\n\ttlv->rx_frames = p_common->rx_ucast_pkts + p_common->rx_mcast_pkts +\n\t\t\t p_common->rx_bcast_pkts;\n\ttlv->rx_frames_set = true;\n\ttlv->rx_bytes = p_common->rx_ucast_bytes + p_common->rx_mcast_bytes +\n\t\t\tp_common->rx_bcast_bytes;\n\ttlv->rx_bytes_set = true;\n\ttlv->tx_frames = p_common->tx_ucast_pkts + p_common->tx_mcast_pkts +\n\t\t\t p_common->tx_bcast_pkts;\n\ttlv->tx_frames_set = true;\n\ttlv->tx_bytes = p_common->tx_ucast_bytes + p_common->tx_mcast_bytes +\n\t\t\tp_common->tx_bcast_bytes;\n\ttlv->rx_bytes_set = true;\n}\n\nint qed_mfw_fill_tlv_data(struct qed_hwfn *hwfn, enum qed_mfw_tlv_type type,\n\t\t\t  union qed_mfw_tlv_data *tlv_buf)\n{\n\tstruct qed_dev *cdev = hwfn->cdev;\n\tstruct qed_common_cb_ops *ops;\n\n\tops = cdev->protocol_ops.common;\n\tif (!ops || !ops->get_protocol_tlv_data || !ops->get_generic_tlv_data) {\n\t\tDP_NOTICE(hwfn, \"Can't collect TLV management info\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (type) {\n\tcase QED_MFW_TLV_GENERIC:\n\t\tqed_fill_generic_tlv_data(hwfn->cdev, &tlv_buf->generic);\n\t\tbreak;\n\tcase QED_MFW_TLV_ETH:\n\t\tops->get_protocol_tlv_data(cdev->ops_cookie, &tlv_buf->eth);\n\t\tbreak;\n\tcase QED_MFW_TLV_FCOE:\n\t\tops->get_protocol_tlv_data(cdev->ops_cookie, &tlv_buf->fcoe);\n\t\tbreak;\n\tcase QED_MFW_TLV_ISCSI:\n\t\tops->get_protocol_tlv_data(cdev->ops_cookie, &tlv_buf->iscsi);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nunsigned long qed_get_epoch_time(void)\n{\n\treturn ktime_get_real_seconds();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}