{
  "module_name": "qed_sriov.c",
  "hash_id": "4598c1aa4a980df408dc88992cc2a764f7f9b337daef9228e69495b2c58593d5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qed/qed_sriov.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <linux/crc32.h>\n#include <linux/vmalloc.h>\n#include <linux/crash_dump.h>\n#include <linux/qed/qed_iov_if.h>\n#include \"qed_cxt.h\"\n#include \"qed_hsi.h\"\n#include \"qed_iro_hsi.h\"\n#include \"qed_hw.h\"\n#include \"qed_init_ops.h\"\n#include \"qed_int.h\"\n#include \"qed_mcp.h\"\n#include \"qed_reg_addr.h\"\n#include \"qed_sp.h\"\n#include \"qed_sriov.h\"\n#include \"qed_vf.h\"\nstatic int qed_iov_bulletin_set_mac(struct qed_hwfn *p_hwfn, u8 *mac, int vfid);\n\nstatic u16 qed_vf_from_entity_id(__le16 entity_id)\n{\n\treturn le16_to_cpu(entity_id) - MAX_NUM_PFS;\n}\n\nstatic u8 qed_vf_calculate_legacy(struct qed_vf_info *p_vf)\n{\n\tu8 legacy = 0;\n\n\tif (p_vf->acquire.vfdev_info.eth_fp_hsi_minor ==\n\t    ETH_HSI_VER_NO_PKT_LEN_TUNN)\n\t\tlegacy |= QED_QCID_LEGACY_VF_RX_PROD;\n\n\tif (!(p_vf->acquire.vfdev_info.capabilities &\n\t      VFPF_ACQUIRE_CAP_QUEUE_QIDS))\n\t\tlegacy |= QED_QCID_LEGACY_VF_CID;\n\n\treturn legacy;\n}\n\n \nstatic int qed_sp_vf_start(struct qed_hwfn *p_hwfn, struct qed_vf_info *p_vf)\n{\n\tstruct vf_start_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc = -EINVAL;\n\tu8 fp_minor;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_vf->opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_VF_START,\n\t\t\t\t PROTOCOLID_COMMON, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.vf_start;\n\n\tp_ramrod->vf_id = GET_FIELD(p_vf->concrete_fid, PXP_CONCRETE_FID_VFID);\n\tp_ramrod->opaque_fid = cpu_to_le16(p_vf->opaque_fid);\n\n\tswitch (p_hwfn->hw_info.personality) {\n\tcase QED_PCI_ETH:\n\t\tp_ramrod->personality = PERSONALITY_ETH;\n\t\tbreak;\n\tcase QED_PCI_ETH_ROCE:\n\tcase QED_PCI_ETH_IWARP:\n\t\tp_ramrod->personality = PERSONALITY_RDMA_AND_ETH;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown VF personality %d\\n\",\n\t\t\t  p_hwfn->hw_info.personality);\n\t\tqed_sp_destroy_request(p_hwfn, p_ent);\n\t\treturn -EINVAL;\n\t}\n\n\tfp_minor = p_vf->acquire.vfdev_info.eth_fp_hsi_minor;\n\tif (fp_minor > ETH_HSI_VER_MINOR &&\n\t    fp_minor != ETH_HSI_VER_NO_PKT_LEN_TUNN) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF [%d] - Requested fp hsi %02x.%02x which is slightly newer than PF's %02x.%02x; Configuring PFs version\\n\",\n\t\t\t   p_vf->abs_vf_id,\n\t\t\t   ETH_HSI_VER_MAJOR,\n\t\t\t   fp_minor, ETH_HSI_VER_MAJOR, ETH_HSI_VER_MINOR);\n\t\tfp_minor = ETH_HSI_VER_MINOR;\n\t}\n\n\tp_ramrod->hsi_fp_ver.major_ver_arr[ETH_VER_KEY] = ETH_HSI_VER_MAJOR;\n\tp_ramrod->hsi_fp_ver.minor_ver_arr[ETH_VER_KEY] = fp_minor;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t   \"VF[%d] - Starting using HSI %02x.%02x\\n\",\n\t\t   p_vf->abs_vf_id, ETH_HSI_VER_MAJOR, fp_minor);\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nstatic int qed_sp_vf_stop(struct qed_hwfn *p_hwfn,\n\t\t\t  u32 concrete_vfid, u16 opaque_vfid)\n{\n\tstruct vf_stop_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc = -EINVAL;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = opaque_vfid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_VF_STOP,\n\t\t\t\t PROTOCOLID_COMMON, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.vf_stop;\n\n\tp_ramrod->vf_id = GET_FIELD(concrete_vfid, PXP_CONCRETE_FID_VFID);\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nbool qed_iov_is_valid_vfid(struct qed_hwfn *p_hwfn,\n\t\t\t   int rel_vf_id,\n\t\t\t   bool b_enabled_only, bool b_non_malicious)\n{\n\tif (!p_hwfn->pf_iov_info) {\n\t\tDP_NOTICE(p_hwfn->cdev, \"No iov info\\n\");\n\t\treturn false;\n\t}\n\n\tif ((rel_vf_id >= p_hwfn->cdev->p_iov_info->total_vfs) ||\n\t    (rel_vf_id < 0))\n\t\treturn false;\n\n\tif ((!p_hwfn->pf_iov_info->vfs_array[rel_vf_id].b_init) &&\n\t    b_enabled_only)\n\t\treturn false;\n\n\tif ((p_hwfn->pf_iov_info->vfs_array[rel_vf_id].b_malicious) &&\n\t    b_non_malicious)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic struct qed_vf_info *qed_iov_get_vf_info(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t       u16 relative_vf_id,\n\t\t\t\t\t       bool b_enabled_only)\n{\n\tstruct qed_vf_info *vf = NULL;\n\n\tif (!p_hwfn->pf_iov_info) {\n\t\tDP_NOTICE(p_hwfn->cdev, \"No iov info\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (qed_iov_is_valid_vfid(p_hwfn, relative_vf_id,\n\t\t\t\t  b_enabled_only, false))\n\t\tvf = &p_hwfn->pf_iov_info->vfs_array[relative_vf_id];\n\telse\n\t\tDP_ERR(p_hwfn, \"%s: VF[%d] is not enabled\\n\",\n\t\t       __func__, relative_vf_id);\n\n\treturn vf;\n}\n\nstatic struct qed_queue_cid *\nqed_iov_get_vf_rx_queue_cid(struct qed_vf_queue *p_queue)\n{\n\tint i;\n\n\tfor (i = 0; i < MAX_QUEUES_PER_QZONE; i++) {\n\t\tif (p_queue->cids[i].p_cid && !p_queue->cids[i].b_is_tx)\n\t\t\treturn p_queue->cids[i].p_cid;\n\t}\n\n\treturn NULL;\n}\n\nenum qed_iov_validate_q_mode {\n\tQED_IOV_VALIDATE_Q_NA,\n\tQED_IOV_VALIDATE_Q_ENABLE,\n\tQED_IOV_VALIDATE_Q_DISABLE,\n};\n\nstatic bool qed_iov_validate_queue_mode(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_vf_info *p_vf,\n\t\t\t\t\tu16 qid,\n\t\t\t\t\tenum qed_iov_validate_q_mode mode,\n\t\t\t\t\tbool b_is_tx)\n{\n\tint i;\n\n\tif (mode == QED_IOV_VALIDATE_Q_NA)\n\t\treturn true;\n\n\tfor (i = 0; i < MAX_QUEUES_PER_QZONE; i++) {\n\t\tstruct qed_vf_queue_cid *p_qcid;\n\n\t\tp_qcid = &p_vf->vf_queues[qid].cids[i];\n\n\t\tif (!p_qcid->p_cid)\n\t\t\tcontinue;\n\n\t\tif (p_qcid->b_is_tx != b_is_tx)\n\t\t\tcontinue;\n\n\t\treturn mode == QED_IOV_VALIDATE_Q_ENABLE;\n\t}\n\n\t \n\treturn mode == QED_IOV_VALIDATE_Q_DISABLE;\n}\n\nstatic bool qed_iov_validate_rxq(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_vf_info *p_vf,\n\t\t\t\t u16 rx_qid,\n\t\t\t\t enum qed_iov_validate_q_mode mode)\n{\n\tif (rx_qid >= p_vf->num_rxqs) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF[0x%02x] - can't touch Rx queue[%04x]; Only 0x%04x are allocated\\n\",\n\t\t\t   p_vf->abs_vf_id, rx_qid, p_vf->num_rxqs);\n\t\treturn false;\n\t}\n\n\treturn qed_iov_validate_queue_mode(p_hwfn, p_vf, rx_qid, mode, false);\n}\n\nstatic bool qed_iov_validate_txq(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_vf_info *p_vf,\n\t\t\t\t u16 tx_qid,\n\t\t\t\t enum qed_iov_validate_q_mode mode)\n{\n\tif (tx_qid >= p_vf->num_txqs) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF[0x%02x] - can't touch Tx queue[%04x]; Only 0x%04x are allocated\\n\",\n\t\t\t   p_vf->abs_vf_id, tx_qid, p_vf->num_txqs);\n\t\treturn false;\n\t}\n\n\treturn qed_iov_validate_queue_mode(p_hwfn, p_vf, tx_qid, mode, true);\n}\n\nstatic bool qed_iov_validate_sb(struct qed_hwfn *p_hwfn,\n\t\t\t\tstruct qed_vf_info *p_vf, u16 sb_idx)\n{\n\tint i;\n\n\tfor (i = 0; i < p_vf->num_sbs; i++)\n\t\tif (p_vf->igu_sbs[i] == sb_idx)\n\t\t\treturn true;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_IOV,\n\t\t   \"VF[0%02x] - tried using sb_idx %04x which doesn't exist as one of its 0x%02x SBs\\n\",\n\t\t   p_vf->abs_vf_id, sb_idx, p_vf->num_sbs);\n\n\treturn false;\n}\n\nstatic bool qed_iov_validate_active_rxq(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_vf_info *p_vf)\n{\n\tu8 i;\n\n\tfor (i = 0; i < p_vf->num_rxqs; i++)\n\t\tif (qed_iov_validate_queue_mode(p_hwfn, p_vf, i,\n\t\t\t\t\t\tQED_IOV_VALIDATE_Q_ENABLE,\n\t\t\t\t\t\tfalse))\n\t\t\treturn true;\n\n\treturn false;\n}\n\nstatic bool qed_iov_validate_active_txq(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_vf_info *p_vf)\n{\n\tu8 i;\n\n\tfor (i = 0; i < p_vf->num_txqs; i++)\n\t\tif (qed_iov_validate_queue_mode(p_hwfn, p_vf, i,\n\t\t\t\t\t\tQED_IOV_VALIDATE_Q_ENABLE,\n\t\t\t\t\t\ttrue))\n\t\t\treturn true;\n\n\treturn false;\n}\n\nstatic int qed_iov_post_vf_bulletin(struct qed_hwfn *p_hwfn,\n\t\t\t\t    int vfid, struct qed_ptt *p_ptt)\n{\n\tstruct qed_bulletin_content *p_bulletin;\n\tint crc_size = sizeof(p_bulletin->crc);\n\tstruct qed_dmae_params params;\n\tstruct qed_vf_info *p_vf;\n\n\tp_vf = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!p_vf)\n\t\treturn -EINVAL;\n\n\tif (!p_vf->vf_bulletin)\n\t\treturn -EINVAL;\n\n\tp_bulletin = p_vf->bulletin.p_virt;\n\n\t \n\tp_bulletin->version++;\n\tp_bulletin->crc = crc32(0, (u8 *)p_bulletin + crc_size,\n\t\t\t\tp_vf->bulletin.size - crc_size);\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t   \"Posting Bulletin 0x%08x to VF[%d] (CRC 0x%08x)\\n\",\n\t\t   p_bulletin->version, p_vf->relative_vf_id, p_bulletin->crc);\n\n\t \n\tmemset(&params, 0, sizeof(params));\n\tSET_FIELD(params.flags, QED_DMAE_PARAMS_DST_VF_VALID, 0x1);\n\tparams.dst_vfid = p_vf->abs_vf_id;\n\treturn qed_dmae_host2host(p_hwfn, p_ptt, p_vf->bulletin.phys,\n\t\t\t\t  p_vf->vf_bulletin, p_vf->bulletin.size / 4,\n\t\t\t\t  &params);\n}\n\nstatic int qed_iov_pci_cfg_info(struct qed_dev *cdev)\n{\n\tstruct qed_hw_sriov_info *iov = cdev->p_iov_info;\n\tint pos = iov->pos;\n\n\tDP_VERBOSE(cdev, QED_MSG_IOV, \"sriov ext pos %d\\n\", pos);\n\tpci_read_config_word(cdev->pdev, pos + PCI_SRIOV_CTRL, &iov->ctrl);\n\n\tpci_read_config_word(cdev->pdev,\n\t\t\t     pos + PCI_SRIOV_TOTAL_VF, &iov->total_vfs);\n\tpci_read_config_word(cdev->pdev,\n\t\t\t     pos + PCI_SRIOV_INITIAL_VF, &iov->initial_vfs);\n\n\tpci_read_config_word(cdev->pdev, pos + PCI_SRIOV_NUM_VF, &iov->num_vfs);\n\tif (iov->num_vfs) {\n\t\tDP_VERBOSE(cdev,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"Number of VFs are already set to non-zero value. Ignoring PCI configuration value\\n\");\n\t\tiov->num_vfs = 0;\n\t}\n\n\tpci_read_config_word(cdev->pdev,\n\t\t\t     pos + PCI_SRIOV_VF_OFFSET, &iov->offset);\n\n\tpci_read_config_word(cdev->pdev,\n\t\t\t     pos + PCI_SRIOV_VF_STRIDE, &iov->stride);\n\n\tpci_read_config_word(cdev->pdev,\n\t\t\t     pos + PCI_SRIOV_VF_DID, &iov->vf_device_id);\n\n\tpci_read_config_dword(cdev->pdev,\n\t\t\t      pos + PCI_SRIOV_SUP_PGSIZE, &iov->pgsz);\n\n\tpci_read_config_dword(cdev->pdev, pos + PCI_SRIOV_CAP, &iov->cap);\n\n\tpci_read_config_byte(cdev->pdev, pos + PCI_SRIOV_FUNC_LINK, &iov->link);\n\n\tDP_VERBOSE(cdev,\n\t\t   QED_MSG_IOV,\n\t\t   \"IOV info: nres %d, cap 0x%x, ctrl 0x%x, total %d, initial %d, num vfs %d, offset %d, stride %d, page size 0x%x\\n\",\n\t\t   iov->nres,\n\t\t   iov->cap,\n\t\t   iov->ctrl,\n\t\t   iov->total_vfs,\n\t\t   iov->initial_vfs,\n\t\t   iov->nr_virtfn, iov->offset, iov->stride, iov->pgsz);\n\n\t \n\tif (iov->num_vfs > NUM_OF_VFS(cdev) ||\n\t    iov->total_vfs > NUM_OF_VFS(cdev)) {\n\t\t \n\t\tDP_NOTICE(cdev,\n\t\t\t  \"IOV: Unexpected number of vfs set: %d setting num_vf to zero\\n\",\n\t\t\t  iov->num_vfs);\n\n\t\tiov->num_vfs = 0;\n\t\tiov->total_vfs = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_iov_setup_vfdb(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_hw_sriov_info *p_iov = p_hwfn->cdev->p_iov_info;\n\tstruct qed_pf_iov *p_iov_info = p_hwfn->pf_iov_info;\n\tstruct qed_bulletin_content *p_bulletin_virt;\n\tdma_addr_t req_p, rply_p, bulletin_p;\n\tunion pfvf_tlvs *p_reply_virt_addr;\n\tunion vfpf_tlvs *p_req_virt_addr;\n\tu8 idx = 0;\n\n\tmemset(p_iov_info->vfs_array, 0, sizeof(p_iov_info->vfs_array));\n\n\tp_req_virt_addr = p_iov_info->mbx_msg_virt_addr;\n\treq_p = p_iov_info->mbx_msg_phys_addr;\n\tp_reply_virt_addr = p_iov_info->mbx_reply_virt_addr;\n\trply_p = p_iov_info->mbx_reply_phys_addr;\n\tp_bulletin_virt = p_iov_info->p_bulletins;\n\tbulletin_p = p_iov_info->bulletins_phys;\n\tif (!p_req_virt_addr || !p_reply_virt_addr || !p_bulletin_virt) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"%s called without allocating mem first\\n\", __func__);\n\t\treturn;\n\t}\n\n\tfor (idx = 0; idx < p_iov->total_vfs; idx++) {\n\t\tstruct qed_vf_info *vf = &p_iov_info->vfs_array[idx];\n\t\tu32 concrete;\n\n\t\tvf->vf_mbx.req_virt = p_req_virt_addr + idx;\n\t\tvf->vf_mbx.req_phys = req_p + idx * sizeof(union vfpf_tlvs);\n\t\tvf->vf_mbx.reply_virt = p_reply_virt_addr + idx;\n\t\tvf->vf_mbx.reply_phys = rply_p + idx * sizeof(union pfvf_tlvs);\n\n\t\tvf->state = VF_STOPPED;\n\t\tvf->b_init = false;\n\n\t\tvf->bulletin.phys = idx *\n\t\t\t\t    sizeof(struct qed_bulletin_content) +\n\t\t\t\t    bulletin_p;\n\t\tvf->bulletin.p_virt = p_bulletin_virt + idx;\n\t\tvf->bulletin.size = sizeof(struct qed_bulletin_content);\n\n\t\tvf->relative_vf_id = idx;\n\t\tvf->abs_vf_id = idx + p_iov->first_vf_in_pf;\n\t\tconcrete = qed_vfid_to_concrete(p_hwfn, vf->abs_vf_id);\n\t\tvf->concrete_fid = concrete;\n\t\tvf->opaque_fid = (p_hwfn->hw_info.opaque_fid & 0xff) |\n\t\t\t\t (vf->abs_vf_id << 8);\n\t\tvf->vport_id = idx + 1;\n\n\t\tvf->num_mac_filters = QED_ETH_VF_NUM_MAC_FILTERS;\n\t\tvf->num_vlan_filters = QED_ETH_VF_NUM_VLAN_FILTERS;\n\t}\n}\n\nstatic int qed_iov_allocate_vfdb(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_pf_iov *p_iov_info = p_hwfn->pf_iov_info;\n\tvoid **p_v_addr;\n\tu16 num_vfs = 0;\n\n\tnum_vfs = p_hwfn->cdev->p_iov_info->total_vfs;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t   \"%s for %d VFs\\n\", __func__, num_vfs);\n\n\t \n\tp_iov_info->mbx_msg_size = sizeof(union vfpf_tlvs) * num_vfs;\n\tp_v_addr = &p_iov_info->mbx_msg_virt_addr;\n\t*p_v_addr = dma_alloc_coherent(&p_hwfn->cdev->pdev->dev,\n\t\t\t\t       p_iov_info->mbx_msg_size,\n\t\t\t\t       &p_iov_info->mbx_msg_phys_addr,\n\t\t\t\t       GFP_KERNEL);\n\tif (!*p_v_addr)\n\t\treturn -ENOMEM;\n\n\t \n\tp_iov_info->mbx_reply_size = sizeof(union pfvf_tlvs) * num_vfs;\n\tp_v_addr = &p_iov_info->mbx_reply_virt_addr;\n\t*p_v_addr = dma_alloc_coherent(&p_hwfn->cdev->pdev->dev,\n\t\t\t\t       p_iov_info->mbx_reply_size,\n\t\t\t\t       &p_iov_info->mbx_reply_phys_addr,\n\t\t\t\t       GFP_KERNEL);\n\tif (!*p_v_addr)\n\t\treturn -ENOMEM;\n\n\tp_iov_info->bulletins_size = sizeof(struct qed_bulletin_content) *\n\t\t\t\t     num_vfs;\n\tp_v_addr = &p_iov_info->p_bulletins;\n\t*p_v_addr = dma_alloc_coherent(&p_hwfn->cdev->pdev->dev,\n\t\t\t\t       p_iov_info->bulletins_size,\n\t\t\t\t       &p_iov_info->bulletins_phys,\n\t\t\t\t       GFP_KERNEL);\n\tif (!*p_v_addr)\n\t\treturn -ENOMEM;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_IOV,\n\t\t   \"PF's Requests mailbox [%p virt 0x%llx phys],  Response mailbox [%p virt 0x%llx phys] Bulletins [%p virt 0x%llx phys]\\n\",\n\t\t   p_iov_info->mbx_msg_virt_addr,\n\t\t   (u64)p_iov_info->mbx_msg_phys_addr,\n\t\t   p_iov_info->mbx_reply_virt_addr,\n\t\t   (u64)p_iov_info->mbx_reply_phys_addr,\n\t\t   p_iov_info->p_bulletins, (u64)p_iov_info->bulletins_phys);\n\n\treturn 0;\n}\n\nstatic void qed_iov_free_vfdb(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_pf_iov *p_iov_info = p_hwfn->pf_iov_info;\n\n\tif (p_hwfn->pf_iov_info->mbx_msg_virt_addr)\n\t\tdma_free_coherent(&p_hwfn->cdev->pdev->dev,\n\t\t\t\t  p_iov_info->mbx_msg_size,\n\t\t\t\t  p_iov_info->mbx_msg_virt_addr,\n\t\t\t\t  p_iov_info->mbx_msg_phys_addr);\n\n\tif (p_hwfn->pf_iov_info->mbx_reply_virt_addr)\n\t\tdma_free_coherent(&p_hwfn->cdev->pdev->dev,\n\t\t\t\t  p_iov_info->mbx_reply_size,\n\t\t\t\t  p_iov_info->mbx_reply_virt_addr,\n\t\t\t\t  p_iov_info->mbx_reply_phys_addr);\n\n\tif (p_iov_info->p_bulletins)\n\t\tdma_free_coherent(&p_hwfn->cdev->pdev->dev,\n\t\t\t\t  p_iov_info->bulletins_size,\n\t\t\t\t  p_iov_info->p_bulletins,\n\t\t\t\t  p_iov_info->bulletins_phys);\n}\n\nint qed_iov_alloc(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_pf_iov *p_sriov;\n\n\tif (!IS_PF_SRIOV(p_hwfn)) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"No SR-IOV - no need for IOV db\\n\");\n\t\treturn 0;\n\t}\n\n\tp_sriov = kzalloc(sizeof(*p_sriov), GFP_KERNEL);\n\tif (!p_sriov)\n\t\treturn -ENOMEM;\n\n\tp_hwfn->pf_iov_info = p_sriov;\n\n\tqed_spq_register_async_cb(p_hwfn, PROTOCOLID_COMMON,\n\t\t\t\t  qed_sriov_eqe_event);\n\n\treturn qed_iov_allocate_vfdb(p_hwfn);\n}\n\nvoid qed_iov_setup(struct qed_hwfn *p_hwfn)\n{\n\tif (!IS_PF_SRIOV(p_hwfn) || !IS_PF_SRIOV_ALLOC(p_hwfn))\n\t\treturn;\n\n\tqed_iov_setup_vfdb(p_hwfn);\n}\n\nvoid qed_iov_free(struct qed_hwfn *p_hwfn)\n{\n\tqed_spq_unregister_async_cb(p_hwfn, PROTOCOLID_COMMON);\n\n\tif (IS_PF_SRIOV_ALLOC(p_hwfn)) {\n\t\tqed_iov_free_vfdb(p_hwfn);\n\t\tkfree(p_hwfn->pf_iov_info);\n\t}\n}\n\nvoid qed_iov_free_hw_info(struct qed_dev *cdev)\n{\n\tkfree(cdev->p_iov_info);\n\tcdev->p_iov_info = NULL;\n}\n\nint qed_iov_hw_info(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tint pos;\n\tint rc;\n\n\tif (is_kdump_kernel())\n\t\treturn 0;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn 0;\n\n\t \n\tpos = pci_find_ext_capability(p_hwfn->cdev->pdev,\n\t\t\t\t      PCI_EXT_CAP_ID_SRIOV);\n\tif (!pos) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV, \"No PCIe IOV support\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tcdev->p_iov_info = kzalloc(sizeof(*cdev->p_iov_info), GFP_KERNEL);\n\tif (!cdev->p_iov_info)\n\t\treturn -ENOMEM;\n\n\tcdev->p_iov_info->pos = pos;\n\n\trc = qed_iov_pci_cfg_info(cdev);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (!cdev->p_iov_info->total_vfs) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"IOV capabilities, but no VFs are published\\n\");\n\t\tkfree(cdev->p_iov_info);\n\t\tcdev->p_iov_info = NULL;\n\t\treturn 0;\n\t}\n\n\t \n\n\tif (p_hwfn->cdev->p_iov_info->offset < (256 - p_hwfn->abs_pf_id)) {\n\t\tu32 first = p_hwfn->cdev->p_iov_info->offset +\n\t\t\t    p_hwfn->abs_pf_id - 16;\n\n\t\tcdev->p_iov_info->first_vf_in_pf = first;\n\n\t\tif (QED_PATH_ID(p_hwfn))\n\t\t\tcdev->p_iov_info->first_vf_in_pf -= MAX_NUM_VFS_BB;\n\t} else {\n\t\tu32 first = p_hwfn->cdev->p_iov_info->offset +\n\t\t\t    p_hwfn->abs_pf_id - 256;\n\n\t\tcdev->p_iov_info->first_vf_in_pf = first;\n\t}\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t   \"First VF in hwfn 0x%08x\\n\",\n\t\t   cdev->p_iov_info->first_vf_in_pf);\n\n\treturn 0;\n}\n\nstatic bool _qed_iov_pf_sanity_check(struct qed_hwfn *p_hwfn,\n\t\t\t\t     int vfid, bool b_fail_malicious)\n{\n\t \n\tif (IS_VF(p_hwfn->cdev) || !IS_QED_SRIOV(p_hwfn->cdev) ||\n\t    !IS_PF_SRIOV_ALLOC(p_hwfn))\n\t\treturn false;\n\n\t \n\tif (!qed_iov_is_valid_vfid(p_hwfn, vfid, true, b_fail_malicious))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool qed_iov_pf_sanity_check(struct qed_hwfn *p_hwfn, int vfid)\n{\n\treturn _qed_iov_pf_sanity_check(p_hwfn, vfid, true);\n}\n\nstatic void qed_iov_set_vf_to_disable(struct qed_dev *cdev,\n\t\t\t\t      u16 rel_vf_id, u8 to_disable)\n{\n\tstruct qed_vf_info *vf;\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tvf = qed_iov_get_vf_info(p_hwfn, rel_vf_id, false);\n\t\tif (!vf)\n\t\t\tcontinue;\n\n\t\tvf->to_disable = to_disable;\n\t}\n}\n\nstatic void qed_iov_set_vfs_to_disable(struct qed_dev *cdev, u8 to_disable)\n{\n\tu16 i;\n\n\tif (!IS_QED_SRIOV(cdev))\n\t\treturn;\n\n\tfor (i = 0; i < cdev->p_iov_info->total_vfs; i++)\n\t\tqed_iov_set_vf_to_disable(cdev, i, to_disable);\n}\n\nstatic void qed_iov_vf_pglue_clear_err(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt, u8 abs_vfid)\n{\n\tqed_wr(p_hwfn, p_ptt,\n\t       PGLUE_B_REG_WAS_ERROR_VF_31_0_CLR + (abs_vfid >> 5) * 4,\n\t       1 << (abs_vfid & 0x1f));\n}\n\nstatic void qed_iov_vf_igu_reset(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt, struct qed_vf_info *vf)\n{\n\tint i;\n\n\t \n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)vf->concrete_fid);\n\n\tqed_wr(p_hwfn, p_ptt, IGU_REG_STATISTIC_NUM_VF_MSG_SENT, 0);\n\n\t \n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)p_hwfn->hw_info.concrete_fid);\n\n\t \n\tfor (i = 0; i < vf->num_sbs; i++)\n\t\tqed_int_igu_init_pure_rt_single(p_hwfn, p_ptt,\n\t\t\t\t\t\tvf->igu_sbs[i],\n\t\t\t\t\t\tvf->opaque_fid, true);\n}\n\nstatic void qed_iov_vf_igu_set_int(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt,\n\t\t\t\t   struct qed_vf_info *vf, bool enable)\n{\n\tu32 igu_vf_conf;\n\n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)vf->concrete_fid);\n\n\tigu_vf_conf = qed_rd(p_hwfn, p_ptt, IGU_REG_VF_CONFIGURATION);\n\n\tif (enable)\n\t\tigu_vf_conf |= IGU_VF_CONF_MSI_MSIX_EN;\n\telse\n\t\tigu_vf_conf &= ~IGU_VF_CONF_MSI_MSIX_EN;\n\n\tqed_wr(p_hwfn, p_ptt, IGU_REG_VF_CONFIGURATION, igu_vf_conf);\n\n\t \n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)p_hwfn->hw_info.concrete_fid);\n}\n\nstatic int\nqed_iov_enable_vf_access_msix(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_ptt *p_ptt, u8 abs_vf_id, u8 num_sbs)\n{\n\tu8 current_max = 0;\n\tint i;\n\n\t \n\tif (!QED_IS_BB(p_hwfn->cdev)) {\n\t\tqed_for_each_vf(p_hwfn, i) {\n\t\t\tstruct qed_vf_info *p_vf;\n\n\t\t\tp_vf = qed_iov_get_vf_info(p_hwfn, (u16)i, true);\n\t\t\tif (!p_vf)\n\t\t\t\tcontinue;\n\n\t\t\tcurrent_max = max_t(u8, current_max, p_vf->num_sbs);\n\t\t}\n\t}\n\n\tif (num_sbs > current_max)\n\t\treturn qed_mcp_config_vf_msix(p_hwfn, p_ptt,\n\t\t\t\t\t      abs_vf_id, num_sbs);\n\n\treturn 0;\n}\n\nstatic int qed_iov_enable_vf_access(struct qed_hwfn *p_hwfn,\n\t\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t\t    struct qed_vf_info *vf)\n{\n\tu32 igu_vf_conf = IGU_VF_CONF_FUNC_EN;\n\tint rc;\n\n\t \n\tvf->b_malicious = false;\n\n\tif (vf->to_disable)\n\t\treturn 0;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_IOV,\n\t\t   \"Enable internal access for vf %x [abs %x]\\n\",\n\t\t   vf->abs_vf_id, QED_VF_ABS_ID(p_hwfn, vf));\n\n\tqed_iov_vf_pglue_clear_err(p_hwfn, p_ptt, QED_VF_ABS_ID(p_hwfn, vf));\n\n\tqed_iov_vf_igu_reset(p_hwfn, p_ptt, vf);\n\n\trc = qed_iov_enable_vf_access_msix(p_hwfn, p_ptt,\n\t\t\t\t\t   vf->abs_vf_id, vf->num_sbs);\n\tif (rc)\n\t\treturn rc;\n\n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)vf->concrete_fid);\n\n\tSET_FIELD(igu_vf_conf, IGU_VF_CONF_PARENT, p_hwfn->rel_pf_id);\n\tSTORE_RT_REG(p_hwfn, IGU_REG_VF_CONFIGURATION_RT_OFFSET, igu_vf_conf);\n\n\tqed_init_run(p_hwfn, p_ptt, PHASE_VF, vf->abs_vf_id,\n\t\t     p_hwfn->hw_info.hw_mode);\n\n\t \n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)p_hwfn->hw_info.concrete_fid);\n\n\tvf->state = VF_FREE;\n\n\treturn rc;\n}\n\n \nstatic void qed_iov_config_perm_table(struct qed_hwfn *p_hwfn,\n\t\t\t\t      struct qed_ptt *p_ptt,\n\t\t\t\t      struct qed_vf_info *vf, u8 enable)\n{\n\tu32 reg_addr, val;\n\tu16 qzone_id = 0;\n\tint qid;\n\n\tfor (qid = 0; qid < vf->num_rxqs; qid++) {\n\t\tqed_fw_l2_queue(p_hwfn, vf->vf_queues[qid].fw_rx_qid,\n\t\t\t\t&qzone_id);\n\n\t\treg_addr = PSWHST_REG_ZONE_PERMISSION_TABLE + qzone_id * 4;\n\t\tval = enable ? (vf->abs_vf_id | BIT(8)) : 0;\n\t\tqed_wr(p_hwfn, p_ptt, reg_addr, val);\n\t}\n}\n\nstatic void qed_iov_enable_vf_traffic(struct qed_hwfn *p_hwfn,\n\t\t\t\t      struct qed_ptt *p_ptt,\n\t\t\t\t      struct qed_vf_info *vf)\n{\n\t \n\tqed_iov_vf_igu_reset(p_hwfn, p_ptt, vf);\n\n\tqed_iov_vf_igu_set_int(p_hwfn, p_ptt, vf, 1);\n\n\t \n\tqed_iov_config_perm_table(p_hwfn, p_ptt, vf, true);\n}\n\nstatic u8 qed_iov_alloc_vf_igu_sbs(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt,\n\t\t\t\t   struct qed_vf_info *vf, u16 num_rx_queues)\n{\n\tstruct qed_igu_block *p_block;\n\tstruct cau_sb_entry sb_entry;\n\tint qid = 0;\n\tu32 val = 0;\n\n\tif (num_rx_queues > p_hwfn->hw_info.p_igu_info->usage.free_cnt_iov)\n\t\tnum_rx_queues = p_hwfn->hw_info.p_igu_info->usage.free_cnt_iov;\n\tp_hwfn->hw_info.p_igu_info->usage.free_cnt_iov -= num_rx_queues;\n\n\tSET_FIELD(val, IGU_MAPPING_LINE_FUNCTION_NUMBER, vf->abs_vf_id);\n\tSET_FIELD(val, IGU_MAPPING_LINE_VALID, 1);\n\tSET_FIELD(val, IGU_MAPPING_LINE_PF_VALID, 0);\n\n\tfor (qid = 0; qid < num_rx_queues; qid++) {\n\t\tp_block = qed_get_igu_free_sb(p_hwfn, false);\n\t\tvf->igu_sbs[qid] = p_block->igu_sb_id;\n\t\tp_block->status &= ~QED_IGU_STATUS_FREE;\n\t\tSET_FIELD(val, IGU_MAPPING_LINE_VECTOR_NUMBER, qid);\n\n\t\tqed_wr(p_hwfn, p_ptt,\n\t\t       IGU_REG_MAPPING_MEMORY +\n\t\t       sizeof(u32) * p_block->igu_sb_id, val);\n\n\t\t \n\t\tqed_init_cau_sb_entry(p_hwfn, &sb_entry,\n\t\t\t\t      p_hwfn->rel_pf_id, vf->abs_vf_id, 1);\n\n\t\tqed_dmae_host2grc(p_hwfn, p_ptt,\n\t\t\t\t  (u64)(uintptr_t)&sb_entry,\n\t\t\t\t  CAU_REG_SB_VAR_MEMORY +\n\t\t\t\t  p_block->igu_sb_id * sizeof(u64), 2, NULL);\n\t}\n\n\tvf->num_sbs = (u8)num_rx_queues;\n\n\treturn vf->num_sbs;\n}\n\nstatic void qed_iov_free_vf_igu_sbs(struct qed_hwfn *p_hwfn,\n\t\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t\t    struct qed_vf_info *vf)\n{\n\tstruct qed_igu_info *p_info = p_hwfn->hw_info.p_igu_info;\n\tint idx, igu_id;\n\tu32 addr, val;\n\n\t \n\tfor (idx = 0; idx < vf->num_sbs; idx++) {\n\t\tigu_id = vf->igu_sbs[idx];\n\t\taddr = IGU_REG_MAPPING_MEMORY + sizeof(u32) * igu_id;\n\n\t\tval = qed_rd(p_hwfn, p_ptt, addr);\n\t\tSET_FIELD(val, IGU_MAPPING_LINE_VALID, 0);\n\t\tqed_wr(p_hwfn, p_ptt, addr, val);\n\n\t\tp_info->entry[igu_id].status |= QED_IGU_STATUS_FREE;\n\t\tp_hwfn->hw_info.p_igu_info->usage.free_cnt_iov++;\n\t}\n\n\tvf->num_sbs = 0;\n}\n\nstatic void qed_iov_set_link(struct qed_hwfn *p_hwfn,\n\t\t\t     u16 vfid,\n\t\t\t     struct qed_mcp_link_params *params,\n\t\t\t     struct qed_mcp_link_state *link,\n\t\t\t     struct qed_mcp_link_capabilities *p_caps)\n{\n\tstruct qed_vf_info *p_vf = qed_iov_get_vf_info(p_hwfn,\n\t\t\t\t\t\t       vfid,\n\t\t\t\t\t\t       false);\n\tstruct qed_bulletin_content *p_bulletin;\n\n\tif (!p_vf)\n\t\treturn;\n\n\tp_bulletin = p_vf->bulletin.p_virt;\n\tp_bulletin->req_autoneg = params->speed.autoneg;\n\tp_bulletin->req_adv_speed = params->speed.advertised_speeds;\n\tp_bulletin->req_forced_speed = params->speed.forced_speed;\n\tp_bulletin->req_autoneg_pause = params->pause.autoneg;\n\tp_bulletin->req_forced_rx = params->pause.forced_rx;\n\tp_bulletin->req_forced_tx = params->pause.forced_tx;\n\tp_bulletin->req_loopback = params->loopback_mode;\n\n\tp_bulletin->link_up = link->link_up;\n\tp_bulletin->speed = link->speed;\n\tp_bulletin->full_duplex = link->full_duplex;\n\tp_bulletin->autoneg = link->an;\n\tp_bulletin->autoneg_complete = link->an_complete;\n\tp_bulletin->parallel_detection = link->parallel_detection;\n\tp_bulletin->pfc_enabled = link->pfc_enabled;\n\tp_bulletin->partner_adv_speed = link->partner_adv_speed;\n\tp_bulletin->partner_tx_flow_ctrl_en = link->partner_tx_flow_ctrl_en;\n\tp_bulletin->partner_rx_flow_ctrl_en = link->partner_rx_flow_ctrl_en;\n\tp_bulletin->partner_adv_pause = link->partner_adv_pause;\n\tp_bulletin->sfp_tx_fault = link->sfp_tx_fault;\n\n\tp_bulletin->capability_speed = p_caps->speed_capabilities;\n}\n\nstatic int qed_iov_init_hw_for_vf(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t\t  struct qed_iov_vf_init_params *p_params)\n{\n\tstruct qed_mcp_link_capabilities link_caps;\n\tstruct qed_mcp_link_params link_params;\n\tstruct qed_mcp_link_state link_state;\n\tu8 num_of_vf_avaiable_chains = 0;\n\tstruct qed_vf_info *vf = NULL;\n\tu16 qid, num_irqs;\n\tint rc = 0;\n\tu32 cids;\n\tu8 i;\n\n\tvf = qed_iov_get_vf_info(p_hwfn, p_params->rel_vf_id, false);\n\tif (!vf) {\n\t\tDP_ERR(p_hwfn, \"%s : vf is NULL\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (vf->b_init) {\n\t\tDP_NOTICE(p_hwfn, \"VF[%d] is already active.\\n\",\n\t\t\t  p_params->rel_vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tfor (i = 0; i < p_params->num_queues; i++) {\n\t\tu16 min_vf_qzone = FEAT_NUM(p_hwfn, QED_PF_L2_QUE);\n\t\tu16 max_vf_qzone = min_vf_qzone +\n\t\t    FEAT_NUM(p_hwfn, QED_VF_L2_QUE) - 1;\n\n\t\tqid = p_params->req_rx_queue[i];\n\t\tif (qid < min_vf_qzone || qid > max_vf_qzone) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Can't enable Rx qid [%04x] for VF[%d]: qids [0x%04x,...,0x%04x] available\\n\",\n\t\t\t\t  qid,\n\t\t\t\t  p_params->rel_vf_id,\n\t\t\t\t  min_vf_qzone, max_vf_qzone);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tqid = p_params->req_tx_queue[i];\n\t\tif (qid > max_vf_qzone) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Can't enable Tx qid [%04x] for VF[%d]: max qid 0x%04x\\n\",\n\t\t\t\t  qid, p_params->rel_vf_id, max_vf_qzone);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (qid < min_vf_qzone)\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"VF[%d] is using PF qid [0x%04x] for Txq[0x%02x]\\n\",\n\t\t\t\t   p_params->rel_vf_id, qid, i);\n\t}\n\n\t \n\tqed_cxt_get_proto_cid_count(p_hwfn, PROTOCOLID_ETH, &cids);\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_IOV,\n\t\t   \"VF[%d] - requesting to initialize for 0x%04x queues [0x%04x CIDs available]\\n\",\n\t\t   vf->relative_vf_id, p_params->num_queues, (u16)cids);\n\tnum_irqs = min_t(u16, p_params->num_queues, ((u16)cids));\n\n\tnum_of_vf_avaiable_chains = qed_iov_alloc_vf_igu_sbs(p_hwfn,\n\t\t\t\t\t\t\t     p_ptt,\n\t\t\t\t\t\t\t     vf, num_irqs);\n\tif (!num_of_vf_avaiable_chains) {\n\t\tDP_ERR(p_hwfn, \"no available igu sbs\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tvf->num_rxqs = num_of_vf_avaiable_chains;\n\tvf->num_txqs = num_of_vf_avaiable_chains;\n\n\tfor (i = 0; i < vf->num_rxqs; i++) {\n\t\tstruct qed_vf_queue *p_queue = &vf->vf_queues[i];\n\n\t\tp_queue->fw_rx_qid = p_params->req_rx_queue[i];\n\t\tp_queue->fw_tx_qid = p_params->req_tx_queue[i];\n\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF[%d] - Q[%d] SB %04x, qid [Rx %04x Tx %04x]\\n\",\n\t\t\t   vf->relative_vf_id, i, vf->igu_sbs[i],\n\t\t\t   p_queue->fw_rx_qid, p_queue->fw_tx_qid);\n\t}\n\n\t \n\tmemcpy(&link_params, qed_mcp_get_link_params(p_hwfn),\n\t       sizeof(link_params));\n\tmemcpy(&link_state, qed_mcp_get_link_state(p_hwfn), sizeof(link_state));\n\tmemcpy(&link_caps, qed_mcp_get_link_capabilities(p_hwfn),\n\t       sizeof(link_caps));\n\tqed_iov_set_link(p_hwfn, p_params->rel_vf_id,\n\t\t\t &link_params, &link_state, &link_caps);\n\n\trc = qed_iov_enable_vf_access(p_hwfn, p_ptt, vf);\n\tif (!rc) {\n\t\tvf->b_init = true;\n\n\t\tif (IS_LEAD_HWFN(p_hwfn))\n\t\t\tp_hwfn->cdev->p_iov_info->num_vfs++;\n\t}\n\n\treturn rc;\n}\n\nstatic int qed_iov_release_hw_for_vf(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt, u16 rel_vf_id)\n{\n\tstruct qed_mcp_link_capabilities caps;\n\tstruct qed_mcp_link_params params;\n\tstruct qed_mcp_link_state link;\n\tstruct qed_vf_info *vf = NULL;\n\n\tvf = qed_iov_get_vf_info(p_hwfn, rel_vf_id, true);\n\tif (!vf) {\n\t\tDP_ERR(p_hwfn, \"%s : vf is NULL\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (vf->bulletin.p_virt)\n\t\tmemset(vf->bulletin.p_virt, 0, sizeof(*vf->bulletin.p_virt));\n\n\tmemset(&vf->p_vf_info, 0, sizeof(vf->p_vf_info));\n\n\t \n\tmemcpy(&params, qed_mcp_get_link_params(p_hwfn), sizeof(params));\n\tmemcpy(&link, qed_mcp_get_link_state(p_hwfn), sizeof(link));\n\tmemcpy(&caps, qed_mcp_get_link_capabilities(p_hwfn), sizeof(caps));\n\tqed_iov_set_link(p_hwfn, rel_vf_id, &params, &link, &caps);\n\n\t \n\tmemset(&vf->acquire, 0, sizeof(vf->acquire));\n\n\t \n\t \n\tqed_iov_vf_igu_set_int(p_hwfn, p_ptt, vf, 0);\n\n\t \n\tqed_iov_config_perm_table(p_hwfn, p_ptt, vf, 0);\n\n\tvf->num_rxqs = 0;\n\tvf->num_txqs = 0;\n\tqed_iov_free_vf_igu_sbs(p_hwfn, p_ptt, vf);\n\n\tif (vf->b_init) {\n\t\tvf->b_init = false;\n\n\t\tif (IS_LEAD_HWFN(p_hwfn))\n\t\t\tp_hwfn->cdev->p_iov_info->num_vfs--;\n\t}\n\n\treturn 0;\n}\n\nstatic bool qed_iov_tlv_supported(u16 tlvtype)\n{\n\treturn CHANNEL_TLV_NONE < tlvtype && tlvtype < CHANNEL_TLV_MAX;\n}\n\n \nvoid *qed_add_tlv(struct qed_hwfn *p_hwfn, u8 **offset, u16 type, u16 length)\n{\n\tstruct channel_tlv *tl = (struct channel_tlv *)*offset;\n\n\ttl->type = type;\n\ttl->length = length;\n\n\t \n\t*offset += length;\n\n\t \n\treturn *offset - length;\n}\n\n \nvoid qed_dp_tlv_list(struct qed_hwfn *p_hwfn, void *tlvs_list)\n{\n\tu16 i = 1, total_length = 0;\n\tstruct channel_tlv *tlv;\n\n\tdo {\n\t\ttlv = (struct channel_tlv *)((u8 *)tlvs_list + total_length);\n\n\t\t \n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"TLV number %d: type %d, length %d\\n\",\n\t\t\t   i, tlv->type, tlv->length);\n\n\t\tif (tlv->type == CHANNEL_TLV_LIST_END)\n\t\t\treturn;\n\n\t\t \n\t\tif (!tlv->length) {\n\t\t\tDP_NOTICE(p_hwfn, \"TLV of length 0 found\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\ttotal_length += tlv->length;\n\n\t\tif (total_length >= sizeof(struct tlv_buffer_size)) {\n\t\t\tDP_NOTICE(p_hwfn, \"TLV ==> Buffer overflow\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\ti++;\n\t} while (1);\n}\n\nstatic void qed_iov_send_response(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t\t  struct qed_vf_info *p_vf,\n\t\t\t\t  u16 length, u8 status)\n{\n\tstruct qed_iov_vf_mbx *mbx = &p_vf->vf_mbx;\n\tstruct qed_dmae_params params;\n\tu8 eng_vf_id;\n\n\tmbx->reply_virt->default_resp.hdr.status = status;\n\n\tqed_dp_tlv_list(p_hwfn, mbx->reply_virt);\n\n\teng_vf_id = p_vf->abs_vf_id;\n\n\tmemset(&params, 0, sizeof(params));\n\tSET_FIELD(params.flags, QED_DMAE_PARAMS_DST_VF_VALID, 0x1);\n\tparams.dst_vfid = eng_vf_id;\n\n\tqed_dmae_host2host(p_hwfn, p_ptt, mbx->reply_phys + sizeof(u64),\n\t\t\t   mbx->req_virt->first_tlv.reply_address +\n\t\t\t   sizeof(u64),\n\t\t\t   (sizeof(union pfvf_tlvs) - sizeof(u64)) / 4,\n\t\t\t   &params);\n\n\t \n\tREG_WR(p_hwfn,\n\t       GET_GTT_REG_ADDR(GTT_BAR0_MAP_REG_USDM_RAM,\n\t\t\t\tUSTORM_VF_PF_CHANNEL_READY, eng_vf_id), 1);\n\n\tqed_dmae_host2host(p_hwfn, p_ptt, mbx->reply_phys,\n\t\t\t   mbx->req_virt->first_tlv.reply_address,\n\t\t\t   sizeof(u64) / 4, &params);\n}\n\nstatic u16 qed_iov_vport_to_tlv(struct qed_hwfn *p_hwfn,\n\t\t\t\tenum qed_iov_vport_update_flag flag)\n{\n\tswitch (flag) {\n\tcase QED_IOV_VP_UPDATE_ACTIVATE:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_ACTIVATE;\n\tcase QED_IOV_VP_UPDATE_VLAN_STRIP:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_VLAN_STRIP;\n\tcase QED_IOV_VP_UPDATE_TX_SWITCH:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_TX_SWITCH;\n\tcase QED_IOV_VP_UPDATE_MCAST:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_MCAST;\n\tcase QED_IOV_VP_UPDATE_ACCEPT_PARAM:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_ACCEPT_PARAM;\n\tcase QED_IOV_VP_UPDATE_RSS:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_RSS;\n\tcase QED_IOV_VP_UPDATE_ACCEPT_ANY_VLAN:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_ACCEPT_ANY_VLAN;\n\tcase QED_IOV_VP_UPDATE_SGE_TPA:\n\t\treturn CHANNEL_TLV_VPORT_UPDATE_SGE_TPA;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic u16 qed_iov_prep_vp_update_resp_tlvs(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t    struct qed_vf_info *p_vf,\n\t\t\t\t\t    struct qed_iov_vf_mbx *p_mbx,\n\t\t\t\t\t    u8 status,\n\t\t\t\t\t    u16 tlvs_mask, u16 tlvs_accepted)\n{\n\tstruct pfvf_def_resp_tlv *resp;\n\tu16 size, total_len, i;\n\n\tmemset(p_mbx->reply_virt, 0, sizeof(union pfvf_tlvs));\n\tp_mbx->offset = (u8 *)p_mbx->reply_virt;\n\tsize = sizeof(struct pfvf_def_resp_tlv);\n\ttotal_len = size;\n\n\tqed_add_tlv(p_hwfn, &p_mbx->offset, CHANNEL_TLV_VPORT_UPDATE, size);\n\n\t \n\tfor (i = 0; i < QED_IOV_VP_UPDATE_MAX; i++) {\n\t\tif (!(tlvs_mask & BIT(i)))\n\t\t\tcontinue;\n\n\t\tresp = qed_add_tlv(p_hwfn, &p_mbx->offset,\n\t\t\t\t   qed_iov_vport_to_tlv(p_hwfn, i), size);\n\n\t\tif (tlvs_accepted & BIT(i))\n\t\t\tresp->hdr.status = status;\n\t\telse\n\t\t\tresp->hdr.status = PFVF_STATUS_NOT_SUPPORTED;\n\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF[%d] - vport_update response: TLV %d, status %02x\\n\",\n\t\t\t   p_vf->relative_vf_id,\n\t\t\t   qed_iov_vport_to_tlv(p_hwfn, i), resp->hdr.status);\n\n\t\ttotal_len += size;\n\t}\n\n\tqed_add_tlv(p_hwfn, &p_mbx->offset, CHANNEL_TLV_LIST_END,\n\t\t    sizeof(struct channel_list_end_tlv));\n\n\treturn total_len;\n}\n\nstatic void qed_iov_prepare_resp(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt,\n\t\t\t\t struct qed_vf_info *vf_info,\n\t\t\t\t u16 type, u16 length, u8 status)\n{\n\tstruct qed_iov_vf_mbx *mbx = &vf_info->vf_mbx;\n\n\tmbx->offset = (u8 *)mbx->reply_virt;\n\n\tqed_add_tlv(p_hwfn, &mbx->offset, type, length);\n\tqed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_LIST_END,\n\t\t    sizeof(struct channel_list_end_tlv));\n\n\tqed_iov_send_response(p_hwfn, p_ptt, vf_info, length, status);\n}\n\nstatic struct\nqed_public_vf_info *qed_iov_get_public_vf_info(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t       u16 relative_vf_id,\n\t\t\t\t\t       bool b_enabled_only)\n{\n\tstruct qed_vf_info *vf = NULL;\n\n\tvf = qed_iov_get_vf_info(p_hwfn, relative_vf_id, b_enabled_only);\n\tif (!vf)\n\t\treturn NULL;\n\n\treturn &vf->p_vf_info;\n}\n\nstatic void qed_iov_clean_vf(struct qed_hwfn *p_hwfn, u8 vfid)\n{\n\tstruct qed_public_vf_info *vf_info;\n\n\tvf_info = qed_iov_get_public_vf_info(p_hwfn, vfid, false);\n\n\tif (!vf_info)\n\t\treturn;\n\n\t \n\teth_zero_addr(vf_info->mac);\n\n\tvf_info->rx_accept_mode = 0;\n\tvf_info->tx_accept_mode = 0;\n}\n\nstatic void qed_iov_vf_cleanup(struct qed_hwfn *p_hwfn,\n\t\t\t       struct qed_vf_info *p_vf)\n{\n\tu32 i, j;\n\n\tp_vf->vf_bulletin = 0;\n\tp_vf->vport_instance = 0;\n\tp_vf->configured_features = 0;\n\n\t \n\tp_vf->num_rxqs = p_vf->num_sbs;\n\tp_vf->num_txqs = p_vf->num_sbs;\n\n\tp_vf->num_active_rxqs = 0;\n\n\tfor (i = 0; i < QED_MAX_VF_CHAINS_PER_PF; i++) {\n\t\tstruct qed_vf_queue *p_queue = &p_vf->vf_queues[i];\n\n\t\tfor (j = 0; j < MAX_QUEUES_PER_QZONE; j++) {\n\t\t\tif (!p_queue->cids[j].p_cid)\n\t\t\t\tcontinue;\n\n\t\t\tqed_eth_queue_cid_release(p_hwfn,\n\t\t\t\t\t\t  p_queue->cids[j].p_cid);\n\t\t\tp_queue->cids[j].p_cid = NULL;\n\t\t}\n\t}\n\n\tmemset(&p_vf->shadow_config, 0, sizeof(p_vf->shadow_config));\n\tmemset(&p_vf->acquire, 0, sizeof(p_vf->acquire));\n\tqed_iov_clean_vf(p_hwfn, p_vf->relative_vf_id);\n}\n\n \nstatic u32 qed_iov_vf_db_bar_size(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_ptt *p_ptt)\n{\n\tu32 val = qed_rd(p_hwfn, p_ptt, PGLUE_B_REG_VF_BAR1_SIZE);\n\n\tif (val)\n\t\treturn val + 11;\n\treturn 0;\n}\n\nstatic void\nqed_iov_vf_mbx_acquire_resc_cids(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt,\n\t\t\t\t struct qed_vf_info *p_vf,\n\t\t\t\t struct vf_pf_resc_request *p_req,\n\t\t\t\t struct pf_vf_resc *p_resp)\n{\n\tu8 num_vf_cons = p_hwfn->pf_params.eth_pf_params.num_vf_cons;\n\tu8 db_size = qed_db_addr_vf(1, DQ_DEMS_LEGACY) -\n\t\t     qed_db_addr_vf(0, DQ_DEMS_LEGACY);\n\tu32 bar_size;\n\n\tp_resp->num_cids = min_t(u8, p_req->num_cids, num_vf_cons);\n\n\t \n\tif (!(p_vf->acquire.vfdev_info.capabilities &\n\t      VFPF_ACQUIRE_CAP_QUEUE_QIDS))\n\t\treturn;\n\n\t \n\tif (p_vf->acquire.vfdev_info.capabilities &\n\t    VFPF_ACQUIRE_CAP_PHYSICAL_BAR) {\n\t\tbar_size = qed_iov_vf_db_bar_size(p_hwfn, p_ptt);\n\t\tif (bar_size)\n\t\t\tbar_size = 1 << bar_size;\n\n\t\tif (p_hwfn->cdev->num_hwfns > 1)\n\t\t\tbar_size /= 2;\n\t} else {\n\t\tbar_size = PXP_VF_BAR0_DQ_LENGTH;\n\t}\n\n\tif (bar_size / db_size < 256)\n\t\tp_resp->num_cids = min_t(u8, p_resp->num_cids,\n\t\t\t\t\t (u8)(bar_size / db_size));\n}\n\nstatic u8 qed_iov_vf_mbx_acquire_resc(struct qed_hwfn *p_hwfn,\n\t\t\t\t      struct qed_ptt *p_ptt,\n\t\t\t\t      struct qed_vf_info *p_vf,\n\t\t\t\t      struct vf_pf_resc_request *p_req,\n\t\t\t\t      struct pf_vf_resc *p_resp)\n{\n\tu8 i;\n\n\t \n\tp_resp->num_rxqs = p_vf->num_rxqs;\n\tp_resp->num_txqs = p_vf->num_txqs;\n\tp_resp->num_sbs = p_vf->num_sbs;\n\n\tfor (i = 0; i < p_resp->num_sbs; i++) {\n\t\tp_resp->hw_sbs[i].hw_sb_id = p_vf->igu_sbs[i];\n\t\tp_resp->hw_sbs[i].sb_qid = 0;\n\t}\n\n\t \n\tfor (i = 0; i < p_resp->num_rxqs; i++) {\n\t\tqed_fw_l2_queue(p_hwfn, p_vf->vf_queues[i].fw_rx_qid,\n\t\t\t\t(u16 *)&p_resp->hw_qid[i]);\n\t\tp_resp->cid[i] = i;\n\t}\n\n\t \n\tp_resp->num_mac_filters = min_t(u8, p_vf->num_mac_filters,\n\t\t\t\t\tp_req->num_mac_filters);\n\tp_resp->num_vlan_filters = min_t(u8, p_vf->num_vlan_filters,\n\t\t\t\t\t p_req->num_vlan_filters);\n\n\tqed_iov_vf_mbx_acquire_resc_cids(p_hwfn, p_ptt, p_vf, p_req, p_resp);\n\n\t \n\tp_resp->num_mc_filters = QED_MAX_MC_ADDRS;\n\n\t \n\tif (p_resp->num_rxqs < p_req->num_rxqs ||\n\t    p_resp->num_txqs < p_req->num_txqs ||\n\t    p_resp->num_sbs < p_req->num_sbs ||\n\t    p_resp->num_mac_filters < p_req->num_mac_filters ||\n\t    p_resp->num_vlan_filters < p_req->num_vlan_filters ||\n\t    p_resp->num_mc_filters < p_req->num_mc_filters ||\n\t    p_resp->num_cids < p_req->num_cids) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF[%d] - Insufficient resources: rxq [%02x/%02x] txq [%02x/%02x] sbs [%02x/%02x] mac [%02x/%02x] vlan [%02x/%02x] mc [%02x/%02x] cids [%02x/%02x]\\n\",\n\t\t\t   p_vf->abs_vf_id,\n\t\t\t   p_req->num_rxqs,\n\t\t\t   p_resp->num_rxqs,\n\t\t\t   p_req->num_rxqs,\n\t\t\t   p_resp->num_txqs,\n\t\t\t   p_req->num_sbs,\n\t\t\t   p_resp->num_sbs,\n\t\t\t   p_req->num_mac_filters,\n\t\t\t   p_resp->num_mac_filters,\n\t\t\t   p_req->num_vlan_filters,\n\t\t\t   p_resp->num_vlan_filters,\n\t\t\t   p_req->num_mc_filters,\n\t\t\t   p_resp->num_mc_filters,\n\t\t\t   p_req->num_cids, p_resp->num_cids);\n\n\t\t \n\t\tif ((p_vf->acquire.vfdev_info.eth_fp_hsi_minor ==\n\t\t     ETH_HSI_VER_NO_PKT_LEN_TUNN) &&\n\t\t    (p_vf->acquire.vfdev_info.os_type ==\n\t\t     VFPF_ACQUIRE_OS_WINDOWS))\n\t\t\treturn PFVF_STATUS_SUCCESS;\n\n\t\treturn PFVF_STATUS_NO_RESOURCE;\n\t}\n\n\treturn PFVF_STATUS_SUCCESS;\n}\n\nstatic void qed_iov_vf_mbx_acquire_stats(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t struct pfvf_stats_info *p_stats)\n{\n\tp_stats->mstats.address = PXP_VF_BAR0_START_MSDM_ZONE_B +\n\t\t\t\t  offsetof(struct mstorm_vf_zone,\n\t\t\t\t\t   non_trigger.eth_queue_stat);\n\tp_stats->mstats.len = sizeof(struct eth_mstorm_per_queue_stat);\n\tp_stats->ustats.address = PXP_VF_BAR0_START_USDM_ZONE_B +\n\t\t\t\t  offsetof(struct ustorm_vf_zone,\n\t\t\t\t\t   non_trigger.eth_queue_stat);\n\tp_stats->ustats.len = sizeof(struct eth_ustorm_per_queue_stat);\n\tp_stats->pstats.address = PXP_VF_BAR0_START_PSDM_ZONE_B +\n\t\t\t\t  offsetof(struct pstorm_vf_zone,\n\t\t\t\t\t   non_trigger.eth_queue_stat);\n\tp_stats->pstats.len = sizeof(struct eth_pstorm_per_queue_stat);\n\tp_stats->tstats.address = 0;\n\tp_stats->tstats.len = 0;\n}\n\nstatic void qed_iov_vf_mbx_acquire(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt,\n\t\t\t\t   struct qed_vf_info *vf)\n{\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tstruct pfvf_acquire_resp_tlv *resp = &mbx->reply_virt->acquire_resp;\n\tstruct pf_vf_pfdev_info *pfdev_info = &resp->pfdev_info;\n\tstruct vfpf_acquire_tlv *req = &mbx->req_virt->acquire;\n\tu8 vfpf_status = PFVF_STATUS_NOT_SUPPORTED;\n\tstruct pf_vf_resc *resc = &resp->resc;\n\tint rc;\n\n\tmemset(resp, 0, sizeof(*resp));\n\n\t \n\tpfdev_info->major_fp_hsi = ETH_HSI_VER_MAJOR;\n\tpfdev_info->minor_fp_hsi = ETH_HSI_VER_MINOR;\n\n\tif (vf->state != VF_FREE && vf->state != VF_STOPPED) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF[%d] sent ACQUIRE but is already in state %d - fail request\\n\",\n\t\t\t   vf->abs_vf_id, vf->state);\n\t\tgoto out;\n\t}\n\n\t \n\tif (req->vfdev_info.eth_fp_hsi_major != ETH_HSI_VER_MAJOR) {\n\t\tif (req->vfdev_info.capabilities &\n\t\t    VFPF_ACQUIRE_CAP_PRE_FP_HSI) {\n\t\t\tstruct vf_pf_vfdev_info *p_vfdev = &req->vfdev_info;\n\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"VF[%d] is pre-fastpath HSI\\n\",\n\t\t\t\t   vf->abs_vf_id);\n\t\t\tp_vfdev->eth_fp_hsi_major = ETH_HSI_VER_MAJOR;\n\t\t\tp_vfdev->eth_fp_hsi_minor = ETH_HSI_VER_NO_PKT_LEN_TUNN;\n\t\t} else {\n\t\t\tDP_INFO(p_hwfn,\n\t\t\t\t\"VF[%d] needs fastpath HSI %02x.%02x, which is incompatible with loaded FW's fastpath HSI %02x.%02x\\n\",\n\t\t\t\tvf->abs_vf_id,\n\t\t\t\treq->vfdev_info.eth_fp_hsi_major,\n\t\t\t\treq->vfdev_info.eth_fp_hsi_minor,\n\t\t\t\tETH_HSI_VER_MAJOR, ETH_HSI_VER_MINOR);\n\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tif ((p_hwfn->cdev->num_hwfns > 1) &&\n\t    !(req->vfdev_info.capabilities & VFPF_ACQUIRE_CAP_100G)) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"VF[%d] is running an old driver that doesn't support 100g\\n\",\n\t\t\tvf->abs_vf_id);\n\t\tgoto out;\n\t}\n\n\t \n\tmemcpy(&vf->acquire, req, sizeof(vf->acquire));\n\n\tvf->opaque_fid = req->vfdev_info.opaque_fid;\n\n\tvf->vf_bulletin = req->bulletin_addr;\n\tvf->bulletin.size = (vf->bulletin.size < req->bulletin_size) ?\n\t\t\t    vf->bulletin.size : req->bulletin_size;\n\n\t \n\tpfdev_info->chip_num = p_hwfn->cdev->chip_num;\n\tpfdev_info->db_size = 0;\n\tpfdev_info->indices_per_sb = PIS_PER_SB;\n\n\tpfdev_info->capabilities = PFVF_ACQUIRE_CAP_DEFAULT_UNTAGGED |\n\t\t\t\t   PFVF_ACQUIRE_CAP_POST_FW_OVERRIDE;\n\tif (p_hwfn->cdev->num_hwfns > 1)\n\t\tpfdev_info->capabilities |= PFVF_ACQUIRE_CAP_100G;\n\n\t \n\tif (req->vfdev_info.capabilities & VFPF_ACQUIRE_CAP_QUEUE_QIDS)\n\t\tpfdev_info->capabilities |= PFVF_ACQUIRE_CAP_QUEUE_QIDS;\n\n\t \n\tresp->pfdev_info.bar_size = qed_iov_vf_db_bar_size(p_hwfn, p_ptt);\n\n\tqed_iov_vf_mbx_acquire_stats(p_hwfn, &pfdev_info->stats_info);\n\n\tmemcpy(pfdev_info->port_mac, p_hwfn->hw_info.hw_mac_addr, ETH_ALEN);\n\n\tpfdev_info->fw_major = FW_MAJOR_VERSION;\n\tpfdev_info->fw_minor = FW_MINOR_VERSION;\n\tpfdev_info->fw_rev = FW_REVISION_VERSION;\n\tpfdev_info->fw_eng = FW_ENGINEERING_VERSION;\n\n\t \n\tpfdev_info->minor_fp_hsi = min_t(u8, ETH_HSI_VER_MINOR,\n\t\t\t\t\t req->vfdev_info.eth_fp_hsi_minor);\n\tpfdev_info->os_type = VFPF_ACQUIRE_OS_LINUX;\n\tqed_mcp_get_mfw_ver(p_hwfn, p_ptt, &pfdev_info->mfw_ver, NULL);\n\n\tpfdev_info->dev_type = p_hwfn->cdev->type;\n\tpfdev_info->chip_rev = p_hwfn->cdev->chip_rev;\n\n\t \n\tvfpf_status = qed_iov_vf_mbx_acquire_resc(p_hwfn, p_ptt, vf,\n\t\t\t\t\t\t  &req->resc_request, resc);\n\tif (vfpf_status != PFVF_STATUS_SUCCESS)\n\t\tgoto out;\n\n\t \n\trc = qed_sp_vf_start(p_hwfn, vf);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to start VF[%02x]\\n\", vf->abs_vf_id);\n\t\tvfpf_status = PFVF_STATUS_FAILURE;\n\t\tgoto out;\n\t}\n\n\t \n\tresp->bulletin_size = vf->bulletin.size;\n\tqed_iov_post_vf_bulletin(p_hwfn, vf->relative_vf_id, p_ptt);\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_IOV,\n\t\t   \"VF[%d] ACQUIRE_RESPONSE: pfdev_info- chip_num=0x%x, db_size=%d, idx_per_sb=%d, pf_cap=0x%llx\\n\"\n\t\t   \"resources- n_rxq-%d, n_txq-%d, n_sbs-%d, n_macs-%d, n_vlans-%d\\n\",\n\t\t   vf->abs_vf_id,\n\t\t   resp->pfdev_info.chip_num,\n\t\t   resp->pfdev_info.db_size,\n\t\t   resp->pfdev_info.indices_per_sb,\n\t\t   resp->pfdev_info.capabilities,\n\t\t   resc->num_rxqs,\n\t\t   resc->num_txqs,\n\t\t   resc->num_sbs,\n\t\t   resc->num_mac_filters,\n\t\t   resc->num_vlan_filters);\n\tvf->state = VF_ACQUIRED;\n\n\t \nout:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_ACQUIRE,\n\t\t\t     sizeof(struct pfvf_acquire_resp_tlv), vfpf_status);\n}\n\nstatic int __qed_iov_spoofchk_set(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_vf_info *p_vf, bool val)\n{\n\tstruct qed_sp_vport_update_params params;\n\tint rc;\n\n\tif (val == p_vf->spoof_chk) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Spoofchk value[%d] is already configured\\n\", val);\n\t\treturn 0;\n\t}\n\n\tmemset(&params, 0, sizeof(struct qed_sp_vport_update_params));\n\tparams.opaque_fid = p_vf->opaque_fid;\n\tparams.vport_id = p_vf->vport_id;\n\tparams.update_anti_spoofing_en_flg = 1;\n\tparams.anti_spoofing_en = val;\n\n\trc = qed_sp_vport_update(p_hwfn, &params, QED_SPQ_MODE_EBLOCK, NULL);\n\tif (!rc) {\n\t\tp_vf->spoof_chk = val;\n\t\tp_vf->req_spoofchk_val = p_vf->spoof_chk;\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Spoofchk val[%d] configured\\n\", val);\n\t} else {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Spoofchk configuration[val:%d] failed for VF[%d]\\n\",\n\t\t\t   val, p_vf->relative_vf_id);\n\t}\n\n\treturn rc;\n}\n\nstatic int qed_iov_reconfigure_unicast_vlan(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t    struct qed_vf_info *p_vf)\n{\n\tstruct qed_filter_ucast filter;\n\tint rc = 0;\n\tint i;\n\n\tmemset(&filter, 0, sizeof(filter));\n\tfilter.is_rx_filter = 1;\n\tfilter.is_tx_filter = 1;\n\tfilter.vport_to_add_to = p_vf->vport_id;\n\tfilter.opcode = QED_FILTER_ADD;\n\n\t \n\tfor (i = 0; i < QED_ETH_VF_NUM_VLAN_FILTERS + 1; i++) {\n\t\tif (!p_vf->shadow_config.vlans[i].used)\n\t\t\tcontinue;\n\n\t\tfilter.type = QED_FILTER_VLAN;\n\t\tfilter.vlan = p_vf->shadow_config.vlans[i].vid;\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Reconfiguring VLAN [0x%04x] for VF [%04x]\\n\",\n\t\t\t   filter.vlan, p_vf->relative_vf_id);\n\t\trc = qed_sp_eth_filter_ucast(p_hwfn, p_vf->opaque_fid,\n\t\t\t\t\t     &filter, QED_SPQ_MODE_CB, NULL);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to configure VLAN [%04x] to VF [%04x]\\n\",\n\t\t\t\t  filter.vlan, p_vf->relative_vf_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn rc;\n}\n\nstatic int\nqed_iov_reconfigure_unicast_shadow(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_vf_info *p_vf, u64 events)\n{\n\tint rc = 0;\n\n\tif ((events & BIT(VLAN_ADDR_FORCED)) &&\n\t    !(p_vf->configured_features & (1 << VLAN_ADDR_FORCED)))\n\t\trc = qed_iov_reconfigure_unicast_vlan(p_hwfn, p_vf);\n\n\treturn rc;\n}\n\nstatic int qed_iov_configure_vport_forced(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t  struct qed_vf_info *p_vf, u64 events)\n{\n\tint rc = 0;\n\tstruct qed_filter_ucast filter;\n\n\tif (!p_vf->vport_instance)\n\t\treturn -EINVAL;\n\n\tif ((events & BIT(MAC_ADDR_FORCED)) ||\n\t    p_vf->p_vf_info.is_trusted_configured) {\n\t\t \n\t\tmemset(&filter, 0, sizeof(filter));\n\t\tfilter.type = QED_FILTER_MAC;\n\t\tfilter.opcode = QED_FILTER_REPLACE;\n\t\tfilter.is_rx_filter = 1;\n\t\tfilter.is_tx_filter = 1;\n\t\tfilter.vport_to_add_to = p_vf->vport_id;\n\t\tether_addr_copy(filter.mac, p_vf->bulletin.p_virt->mac);\n\n\t\trc = qed_sp_eth_filter_ucast(p_hwfn, p_vf->opaque_fid,\n\t\t\t\t\t     &filter, QED_SPQ_MODE_CB, NULL);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"PF failed to configure MAC for VF\\n\");\n\t\t\treturn rc;\n\t\t}\n\t\tif (p_vf->p_vf_info.is_trusted_configured)\n\t\t\tp_vf->configured_features |=\n\t\t\t\tBIT(VFPF_BULLETIN_MAC_ADDR);\n\t\telse\n\t\t\tp_vf->configured_features |=\n\t\t\t\tBIT(MAC_ADDR_FORCED);\n\t}\n\n\tif (events & BIT(VLAN_ADDR_FORCED)) {\n\t\tstruct qed_sp_vport_update_params vport_update;\n\t\tu8 removal;\n\t\tint i;\n\n\t\tmemset(&filter, 0, sizeof(filter));\n\t\tfilter.type = QED_FILTER_VLAN;\n\t\tfilter.is_rx_filter = 1;\n\t\tfilter.is_tx_filter = 1;\n\t\tfilter.vport_to_add_to = p_vf->vport_id;\n\t\tfilter.vlan = p_vf->bulletin.p_virt->pvid;\n\t\tfilter.opcode = filter.vlan ? QED_FILTER_REPLACE :\n\t\t\t\t\t      QED_FILTER_FLUSH;\n\n\t\t \n\t\trc = qed_sp_eth_filter_ucast(p_hwfn, p_vf->opaque_fid,\n\t\t\t\t\t     &filter, QED_SPQ_MODE_CB, NULL);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"PF failed to configure VLAN for VF\\n\");\n\t\t\treturn rc;\n\t\t}\n\n\t\t \n\t\tmemset(&vport_update, 0, sizeof(vport_update));\n\t\tvport_update.opaque_fid = p_vf->opaque_fid;\n\t\tvport_update.vport_id = p_vf->vport_id;\n\t\tvport_update.update_default_vlan_enable_flg = 1;\n\t\tvport_update.default_vlan_enable_flg = filter.vlan ? 1 : 0;\n\t\tvport_update.update_default_vlan_flg = 1;\n\t\tvport_update.default_vlan = filter.vlan;\n\n\t\tvport_update.update_inner_vlan_removal_flg = 1;\n\t\tremoval = filter.vlan ? 1\n\t\t\t\t      : p_vf->shadow_config.inner_vlan_removal;\n\t\tvport_update.inner_vlan_removal_flg = removal;\n\t\tvport_update.silent_vlan_removal_flg = filter.vlan ? 1 : 0;\n\t\trc = qed_sp_vport_update(p_hwfn,\n\t\t\t\t\t &vport_update,\n\t\t\t\t\t QED_SPQ_MODE_EBLOCK, NULL);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"PF failed to configure VF vport for vlan\\n\");\n\t\t\treturn rc;\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < QED_MAX_VF_CHAINS_PER_PF; i++) {\n\t\t\tstruct qed_vf_queue *p_queue = &p_vf->vf_queues[i];\n\t\t\tstruct qed_queue_cid *p_cid = NULL;\n\n\t\t\t \n\t\t\tp_cid = qed_iov_get_vf_rx_queue_cid(p_queue);\n\t\t\tif (!p_cid)\n\t\t\t\tcontinue;\n\n\t\t\trc = qed_sp_eth_rx_queues_update(p_hwfn,\n\t\t\t\t\t\t\t (void **)&p_cid,\n\t\t\t\t\t\t\t 1, 0, 1,\n\t\t\t\t\t\t\t QED_SPQ_MODE_EBLOCK,\n\t\t\t\t\t\t\t NULL);\n\t\t\tif (rc) {\n\t\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t\t  \"Failed to send Rx update fo queue[0x%04x]\\n\",\n\t\t\t\t\t  p_cid->rel.queue_id);\n\t\t\t\treturn rc;\n\t\t\t}\n\t\t}\n\n\t\tif (filter.vlan)\n\t\t\tp_vf->configured_features |= 1 << VLAN_ADDR_FORCED;\n\t\telse\n\t\t\tp_vf->configured_features &= ~BIT(VLAN_ADDR_FORCED);\n\t}\n\n\t \n\tif (events)\n\t\tqed_iov_reconfigure_unicast_shadow(p_hwfn, p_vf, events);\n\n\treturn rc;\n}\n\nstatic void qed_iov_vf_mbx_start_vport(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt,\n\t\t\t\t       struct qed_vf_info *vf)\n{\n\tstruct qed_sp_vport_start_params params = { 0 };\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tstruct vfpf_vport_start_tlv *start;\n\tu8 status = PFVF_STATUS_SUCCESS;\n\tstruct qed_vf_info *vf_info;\n\tu64 *p_bitmap;\n\tint sb_id;\n\tint rc;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vf->relative_vf_id, true);\n\tif (!vf_info) {\n\t\tDP_NOTICE(p_hwfn->cdev,\n\t\t\t  \"Failed to get VF info, invalid vfid [%d]\\n\",\n\t\t\t  vf->relative_vf_id);\n\t\treturn;\n\t}\n\n\tvf->state = VF_ENABLED;\n\tstart = &mbx->req_virt->start_vport;\n\n\tqed_iov_enable_vf_traffic(p_hwfn, p_ptt, vf);\n\n\t \n\tfor (sb_id = 0; sb_id < vf->num_sbs; sb_id++) {\n\t\tif (!start->sb_addr[sb_id]) {\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"VF[%d] did not fill the address of SB %d\\n\",\n\t\t\t\t   vf->relative_vf_id, sb_id);\n\t\t\tbreak;\n\t\t}\n\n\t\tqed_int_cau_conf_sb(p_hwfn, p_ptt,\n\t\t\t\t    start->sb_addr[sb_id],\n\t\t\t\t    vf->igu_sbs[sb_id], vf->abs_vf_id, 1);\n\t}\n\n\tvf->mtu = start->mtu;\n\tvf->shadow_config.inner_vlan_removal = start->inner_vlan_removal;\n\n\t \n\tp_bitmap = &vf_info->bulletin.p_virt->valid_bitmap;\n\tif (!(*p_bitmap & BIT(VFPF_BULLETIN_UNTAGGED_DEFAULT_FORCED))) {\n\t\tu8 vf_req = start->only_untagged;\n\n\t\tvf_info->bulletin.p_virt->default_only_untagged = vf_req;\n\t\t*p_bitmap |= 1 << VFPF_BULLETIN_UNTAGGED_DEFAULT;\n\t}\n\n\tparams.tpa_mode = start->tpa_mode;\n\tparams.remove_inner_vlan = start->inner_vlan_removal;\n\tparams.tx_switching = true;\n\n\tparams.only_untagged = vf_info->bulletin.p_virt->default_only_untagged;\n\tparams.drop_ttl0 = false;\n\tparams.concrete_fid = vf->concrete_fid;\n\tparams.opaque_fid = vf->opaque_fid;\n\tparams.vport_id = vf->vport_id;\n\tparams.max_buffers_per_cqe = start->max_buffers_per_cqe;\n\tparams.mtu = vf->mtu;\n\n\t \n\tparams.check_mac = !vf->p_vf_info.is_trusted_configured;\n\n\trc = qed_sp_eth_vport_start(p_hwfn, &params);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"%s returned error %d\\n\", __func__, rc);\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t} else {\n\t\tvf->vport_instance++;\n\n\t\t \n\t\tqed_iov_configure_vport_forced(p_hwfn, vf, *p_bitmap);\n\n\t\t__qed_iov_spoofchk_set(p_hwfn, vf, vf->req_spoofchk_val);\n\t}\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_VPORT_START,\n\t\t\t     sizeof(struct pfvf_def_resp_tlv), status);\n}\n\nstatic void qed_iov_vf_mbx_stop_vport(struct qed_hwfn *p_hwfn,\n\t\t\t\t      struct qed_ptt *p_ptt,\n\t\t\t\t      struct qed_vf_info *vf)\n{\n\tu8 status = PFVF_STATUS_SUCCESS;\n\tint rc;\n\n\tvf->vport_instance--;\n\tvf->spoof_chk = false;\n\n\tif ((qed_iov_validate_active_rxq(p_hwfn, vf)) ||\n\t    (qed_iov_validate_active_txq(p_hwfn, vf))) {\n\t\tvf->b_malicious = true;\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"VF [%02x] - considered malicious; Unable to stop RX/TX queues\\n\",\n\t\t\t  vf->abs_vf_id);\n\t\tstatus = PFVF_STATUS_MALICIOUS;\n\t\tgoto out;\n\t}\n\n\trc = qed_sp_vport_stop(p_hwfn, vf->opaque_fid, vf->vport_id);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"%s returned error %d\\n\",\n\t\t       __func__, rc);\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t}\n\n\t \n\tvf->configured_features = 0;\n\tmemset(&vf->shadow_config, 0, sizeof(vf->shadow_config));\n\nout:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_VPORT_TEARDOWN,\n\t\t\t     sizeof(struct pfvf_def_resp_tlv), status);\n}\n\nstatic void qed_iov_vf_mbx_start_rxq_resp(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t\t\t  struct qed_vf_info *vf,\n\t\t\t\t\t  u8 status, bool b_legacy)\n{\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tstruct pfvf_start_queue_resp_tlv *p_tlv;\n\tstruct vfpf_start_rxq_tlv *req;\n\tu16 length;\n\n\tmbx->offset = (u8 *)mbx->reply_virt;\n\n\t \n\tif (!b_legacy)\n\t\tlength = sizeof(*p_tlv);\n\telse\n\t\tlength = sizeof(struct pfvf_def_resp_tlv);\n\n\tp_tlv = qed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_START_RXQ,\n\t\t\t    length);\n\tqed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_LIST_END,\n\t\t    sizeof(struct channel_list_end_tlv));\n\n\t \n\tif ((status == PFVF_STATUS_SUCCESS) && !b_legacy) {\n\t\treq = &mbx->req_virt->start_rxq;\n\t\tp_tlv->offset = PXP_VF_BAR0_START_MSDM_ZONE_B +\n\t\t\t\toffsetof(struct mstorm_vf_zone,\n\t\t\t\t\t non_trigger.eth_rx_queue_producers) +\n\t\t\t\tsizeof(struct eth_rx_prod_data) * req->rx_qid;\n\t}\n\n\tqed_iov_send_response(p_hwfn, p_ptt, vf, length, status);\n}\n\nstatic u8 qed_iov_vf_mbx_qid(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_vf_info *p_vf, bool b_is_tx)\n{\n\tstruct qed_iov_vf_mbx *p_mbx = &p_vf->vf_mbx;\n\tstruct vfpf_qid_tlv *p_qid_tlv;\n\n\t \n\tif (!(p_vf->acquire.vfdev_info.capabilities &\n\t      VFPF_ACQUIRE_CAP_QUEUE_QIDS)) {\n\t\tif (b_is_tx)\n\t\t\treturn QED_IOV_LEGACY_QID_TX;\n\t\telse\n\t\t\treturn QED_IOV_LEGACY_QID_RX;\n\t}\n\n\tp_qid_tlv = (struct vfpf_qid_tlv *)\n\t\t    qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt,\n\t\t\t\t\t     CHANNEL_TLV_QID);\n\tif (!p_qid_tlv) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF[%2x]: Failed to provide qid\\n\",\n\t\t\t   p_vf->relative_vf_id);\n\n\t\treturn QED_IOV_QID_INVALID;\n\t}\n\n\tif (p_qid_tlv->qid >= MAX_QUEUES_PER_QZONE) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF[%02x]: Provided qid out-of-bounds %02x\\n\",\n\t\t\t   p_vf->relative_vf_id, p_qid_tlv->qid);\n\t\treturn QED_IOV_QID_INVALID;\n\t}\n\n\treturn p_qid_tlv->qid;\n}\n\nstatic void qed_iov_vf_mbx_start_rxq(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t     struct qed_vf_info *vf)\n{\n\tstruct qed_queue_start_common_params params;\n\tstruct qed_queue_cid_vf_params vf_params;\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tu8 status = PFVF_STATUS_NO_RESOURCE;\n\tu8 qid_usage_idx, vf_legacy = 0;\n\tstruct vfpf_start_rxq_tlv *req;\n\tstruct qed_vf_queue *p_queue;\n\tstruct qed_queue_cid *p_cid;\n\tstruct qed_sb_info sb_dummy;\n\tint rc;\n\n\treq = &mbx->req_virt->start_rxq;\n\n\tif (!qed_iov_validate_rxq(p_hwfn, vf, req->rx_qid,\n\t\t\t\t  QED_IOV_VALIDATE_Q_DISABLE) ||\n\t    !qed_iov_validate_sb(p_hwfn, vf, req->hw_sb))\n\t\tgoto out;\n\n\tqid_usage_idx = qed_iov_vf_mbx_qid(p_hwfn, vf, false);\n\tif (qid_usage_idx == QED_IOV_QID_INVALID)\n\t\tgoto out;\n\n\tp_queue = &vf->vf_queues[req->rx_qid];\n\tif (p_queue->cids[qid_usage_idx].p_cid)\n\t\tgoto out;\n\n\tvf_legacy = qed_vf_calculate_legacy(vf);\n\n\t \n\tmemset(&params, 0, sizeof(params));\n\tparams.queue_id = p_queue->fw_rx_qid;\n\tparams.vport_id = vf->vport_id;\n\tparams.stats_id = vf->abs_vf_id + 0x10;\n\t \n\tmemset(&sb_dummy, 0, sizeof(sb_dummy));\n\tsb_dummy.igu_sb_id = req->hw_sb;\n\tparams.p_sb = &sb_dummy;\n\tparams.sb_idx = req->sb_index;\n\n\tmemset(&vf_params, 0, sizeof(vf_params));\n\tvf_params.vfid = vf->relative_vf_id;\n\tvf_params.vf_qid = (u8)req->rx_qid;\n\tvf_params.vf_legacy = vf_legacy;\n\tvf_params.qid_usage_idx = qid_usage_idx;\n\tp_cid = qed_eth_queue_to_cid(p_hwfn, vf->opaque_fid,\n\t\t\t\t     &params, true, &vf_params);\n\tif (!p_cid)\n\t\tgoto out;\n\n\t \n\tif (!(vf_legacy & QED_QCID_LEGACY_VF_RX_PROD))\n\t\tqed_wr(p_hwfn, p_ptt, MSEM_REG_FAST_MEMORY +\n\t\t       SEM_FAST_REG_INT_RAM +\n\t\t       MSTORM_ETH_VF_PRODS_OFFSET(vf->abs_vf_id,\n\t\t\t\t\t\t  req->rx_qid), 0);\n\n\trc = qed_eth_rxq_start_ramrod(p_hwfn, p_cid,\n\t\t\t\t      req->bd_max_bytes,\n\t\t\t\t      req->rxq_addr,\n\t\t\t\t      req->cqe_pbl_addr, req->cqe_pbl_size);\n\tif (rc) {\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tqed_eth_queue_cid_release(p_hwfn, p_cid);\n\t} else {\n\t\tp_queue->cids[qid_usage_idx].p_cid = p_cid;\n\t\tp_queue->cids[qid_usage_idx].b_is_tx = false;\n\t\tstatus = PFVF_STATUS_SUCCESS;\n\t\tvf->num_active_rxqs++;\n\t}\n\nout:\n\tqed_iov_vf_mbx_start_rxq_resp(p_hwfn, p_ptt, vf, status,\n\t\t\t\t      !!(vf_legacy &\n\t\t\t\t\t QED_QCID_LEGACY_VF_RX_PROD));\n}\n\nstatic void\nqed_iov_pf_update_tun_response(struct pfvf_update_tunn_param_tlv *p_resp,\n\t\t\t       struct qed_tunnel_info *p_tun,\n\t\t\t       u16 tunn_feature_mask)\n{\n\tp_resp->tunn_feature_mask = tunn_feature_mask;\n\tp_resp->vxlan_mode = p_tun->vxlan.b_mode_enabled;\n\tp_resp->l2geneve_mode = p_tun->l2_geneve.b_mode_enabled;\n\tp_resp->ipgeneve_mode = p_tun->ip_geneve.b_mode_enabled;\n\tp_resp->l2gre_mode = p_tun->l2_gre.b_mode_enabled;\n\tp_resp->ipgre_mode = p_tun->l2_gre.b_mode_enabled;\n\tp_resp->vxlan_clss = p_tun->vxlan.tun_cls;\n\tp_resp->l2gre_clss = p_tun->l2_gre.tun_cls;\n\tp_resp->ipgre_clss = p_tun->ip_gre.tun_cls;\n\tp_resp->l2geneve_clss = p_tun->l2_geneve.tun_cls;\n\tp_resp->ipgeneve_clss = p_tun->ip_geneve.tun_cls;\n\tp_resp->geneve_udp_port = p_tun->geneve_port.port;\n\tp_resp->vxlan_udp_port = p_tun->vxlan_port.port;\n}\n\nstatic void\n__qed_iov_pf_update_tun_param(struct vfpf_update_tunn_param_tlv *p_req,\n\t\t\t      struct qed_tunn_update_type *p_tun,\n\t\t\t      enum qed_tunn_mode mask, u8 tun_cls)\n{\n\tif (p_req->tun_mode_update_mask & BIT(mask)) {\n\t\tp_tun->b_update_mode = true;\n\n\t\tif (p_req->tunn_mode & BIT(mask))\n\t\t\tp_tun->b_mode_enabled = true;\n\t}\n\n\tp_tun->tun_cls = tun_cls;\n}\n\nstatic void\nqed_iov_pf_update_tun_param(struct vfpf_update_tunn_param_tlv *p_req,\n\t\t\t    struct qed_tunn_update_type *p_tun,\n\t\t\t    struct qed_tunn_update_udp_port *p_port,\n\t\t\t    enum qed_tunn_mode mask,\n\t\t\t    u8 tun_cls, u8 update_port, u16 port)\n{\n\tif (update_port) {\n\t\tp_port->b_update_port = true;\n\t\tp_port->port = port;\n\t}\n\n\t__qed_iov_pf_update_tun_param(p_req, p_tun, mask, tun_cls);\n}\n\nstatic bool\nqed_iov_pf_validate_tunn_param(struct vfpf_update_tunn_param_tlv *p_req)\n{\n\tbool b_update_requested = false;\n\n\tif (p_req->tun_mode_update_mask || p_req->update_tun_cls ||\n\t    p_req->update_geneve_port || p_req->update_vxlan_port)\n\t\tb_update_requested = true;\n\n\treturn b_update_requested;\n}\n\nstatic void qed_pf_validate_tunn_mode(struct qed_tunn_update_type *tun, int *rc)\n{\n\tif (tun->b_update_mode && !tun->b_mode_enabled) {\n\t\ttun->b_update_mode = false;\n\t\t*rc = -EINVAL;\n\t}\n}\n\nstatic int\nqed_pf_validate_modify_tunn_config(struct qed_hwfn *p_hwfn,\n\t\t\t\t   u16 *tun_features, bool *update,\n\t\t\t\t   struct qed_tunnel_info *tun_src)\n{\n\tstruct qed_eth_cb_ops *ops = p_hwfn->cdev->protocol_ops.eth;\n\tstruct qed_tunnel_info *tun = &p_hwfn->cdev->tunnel;\n\tu16 bultn_vxlan_port, bultn_geneve_port;\n\tvoid *cookie = p_hwfn->cdev->ops_cookie;\n\tint i, rc = 0;\n\n\t*tun_features = p_hwfn->cdev->tunn_feature_mask;\n\tbultn_vxlan_port = tun->vxlan_port.port;\n\tbultn_geneve_port = tun->geneve_port.port;\n\tqed_pf_validate_tunn_mode(&tun_src->vxlan, &rc);\n\tqed_pf_validate_tunn_mode(&tun_src->l2_geneve, &rc);\n\tqed_pf_validate_tunn_mode(&tun_src->ip_geneve, &rc);\n\tqed_pf_validate_tunn_mode(&tun_src->l2_gre, &rc);\n\tqed_pf_validate_tunn_mode(&tun_src->ip_gre, &rc);\n\n\tif ((tun_src->b_update_rx_cls || tun_src->b_update_tx_cls) &&\n\t    (tun_src->vxlan.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||\n\t     tun_src->l2_geneve.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||\n\t     tun_src->ip_geneve.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||\n\t     tun_src->l2_gre.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||\n\t     tun_src->ip_gre.tun_cls != QED_TUNN_CLSS_MAC_VLAN)) {\n\t\ttun_src->b_update_rx_cls = false;\n\t\ttun_src->b_update_tx_cls = false;\n\t\trc = -EINVAL;\n\t}\n\n\tif (tun_src->vxlan_port.b_update_port) {\n\t\tif (tun_src->vxlan_port.port == tun->vxlan_port.port) {\n\t\t\ttun_src->vxlan_port.b_update_port = false;\n\t\t} else {\n\t\t\t*update = true;\n\t\t\tbultn_vxlan_port = tun_src->vxlan_port.port;\n\t\t}\n\t}\n\n\tif (tun_src->geneve_port.b_update_port) {\n\t\tif (tun_src->geneve_port.port == tun->geneve_port.port) {\n\t\t\ttun_src->geneve_port.b_update_port = false;\n\t\t} else {\n\t\t\t*update = true;\n\t\t\tbultn_geneve_port = tun_src->geneve_port.port;\n\t\t}\n\t}\n\n\tqed_for_each_vf(p_hwfn, i) {\n\t\tqed_iov_bulletin_set_udp_ports(p_hwfn, i, bultn_vxlan_port,\n\t\t\t\t\t       bultn_geneve_port);\n\t}\n\n\tqed_schedule_iov(p_hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n\tops->ports_update(cookie, bultn_vxlan_port, bultn_geneve_port);\n\n\treturn rc;\n}\n\nstatic void qed_iov_vf_mbx_update_tunn_param(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t\t     struct qed_vf_info *p_vf)\n{\n\tstruct qed_tunnel_info *p_tun = &p_hwfn->cdev->tunnel;\n\tstruct qed_iov_vf_mbx *mbx = &p_vf->vf_mbx;\n\tstruct pfvf_update_tunn_param_tlv *p_resp;\n\tstruct vfpf_update_tunn_param_tlv *p_req;\n\tu8 status = PFVF_STATUS_SUCCESS;\n\tbool b_update_required = false;\n\tstruct qed_tunnel_info tunn;\n\tu16 tunn_feature_mask = 0;\n\tint i, rc = 0;\n\n\tmbx->offset = (u8 *)mbx->reply_virt;\n\n\tmemset(&tunn, 0, sizeof(tunn));\n\tp_req = &mbx->req_virt->tunn_param_update;\n\n\tif (!qed_iov_pf_validate_tunn_param(p_req)) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"No tunnel update requested by VF\\n\");\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tgoto send_resp;\n\t}\n\n\ttunn.b_update_rx_cls = p_req->update_tun_cls;\n\ttunn.b_update_tx_cls = p_req->update_tun_cls;\n\n\tqed_iov_pf_update_tun_param(p_req, &tunn.vxlan, &tunn.vxlan_port,\n\t\t\t\t    QED_MODE_VXLAN_TUNN, p_req->vxlan_clss,\n\t\t\t\t    p_req->update_vxlan_port,\n\t\t\t\t    p_req->vxlan_port);\n\tqed_iov_pf_update_tun_param(p_req, &tunn.l2_geneve, &tunn.geneve_port,\n\t\t\t\t    QED_MODE_L2GENEVE_TUNN,\n\t\t\t\t    p_req->l2geneve_clss,\n\t\t\t\t    p_req->update_geneve_port,\n\t\t\t\t    p_req->geneve_port);\n\t__qed_iov_pf_update_tun_param(p_req, &tunn.ip_geneve,\n\t\t\t\t      QED_MODE_IPGENEVE_TUNN,\n\t\t\t\t      p_req->ipgeneve_clss);\n\t__qed_iov_pf_update_tun_param(p_req, &tunn.l2_gre,\n\t\t\t\t      QED_MODE_L2GRE_TUNN, p_req->l2gre_clss);\n\t__qed_iov_pf_update_tun_param(p_req, &tunn.ip_gre,\n\t\t\t\t      QED_MODE_IPGRE_TUNN, p_req->ipgre_clss);\n\n\t \n\trc = qed_pf_validate_modify_tunn_config(p_hwfn, &tunn_feature_mask,\n\t\t\t\t\t\t&b_update_required, &tunn);\n\n\tif (rc)\n\t\tstatus = PFVF_STATUS_FAILURE;\n\n\t \n\tif (b_update_required) {\n\t\tu16 geneve_port;\n\n\t\trc = qed_sp_pf_update_tunn_cfg(p_hwfn, p_ptt, &tunn,\n\t\t\t\t\t       QED_SPQ_MODE_EBLOCK, NULL);\n\t\tif (rc)\n\t\t\tstatus = PFVF_STATUS_FAILURE;\n\n\t\tgeneve_port = p_tun->geneve_port.port;\n\t\tqed_for_each_vf(p_hwfn, i) {\n\t\t\tqed_iov_bulletin_set_udp_ports(p_hwfn, i,\n\t\t\t\t\t\t       p_tun->vxlan_port.port,\n\t\t\t\t\t\t       geneve_port);\n\t\t}\n\t}\n\nsend_resp:\n\tp_resp = qed_add_tlv(p_hwfn, &mbx->offset,\n\t\t\t     CHANNEL_TLV_UPDATE_TUNN_PARAM, sizeof(*p_resp));\n\n\tqed_iov_pf_update_tun_response(p_resp, p_tun, tunn_feature_mask);\n\tqed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_LIST_END,\n\t\t    sizeof(struct channel_list_end_tlv));\n\n\tqed_iov_send_response(p_hwfn, p_ptt, p_vf, sizeof(*p_resp), status);\n}\n\nstatic void qed_iov_vf_mbx_start_txq_resp(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t\t\t  struct qed_vf_info *p_vf,\n\t\t\t\t\t  u32 cid, u8 status)\n{\n\tstruct qed_iov_vf_mbx *mbx = &p_vf->vf_mbx;\n\tstruct pfvf_start_queue_resp_tlv *p_tlv;\n\tbool b_legacy = false;\n\tu16 length;\n\n\tmbx->offset = (u8 *)mbx->reply_virt;\n\n\t \n\tif (p_vf->acquire.vfdev_info.eth_fp_hsi_minor ==\n\t    ETH_HSI_VER_NO_PKT_LEN_TUNN)\n\t\tb_legacy = true;\n\n\tif (!b_legacy)\n\t\tlength = sizeof(*p_tlv);\n\telse\n\t\tlength = sizeof(struct pfvf_def_resp_tlv);\n\n\tp_tlv = qed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_START_TXQ,\n\t\t\t    length);\n\tqed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_LIST_END,\n\t\t    sizeof(struct channel_list_end_tlv));\n\n\t \n\tif ((status == PFVF_STATUS_SUCCESS) && !b_legacy)\n\t\tp_tlv->offset = qed_db_addr_vf(cid, DQ_DEMS_LEGACY);\n\n\tqed_iov_send_response(p_hwfn, p_ptt, p_vf, length, status);\n}\n\nstatic void qed_iov_vf_mbx_start_txq(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t     struct qed_vf_info *vf)\n{\n\tstruct qed_queue_start_common_params params;\n\tstruct qed_queue_cid_vf_params vf_params;\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tu8 status = PFVF_STATUS_NO_RESOURCE;\n\tstruct vfpf_start_txq_tlv *req;\n\tstruct qed_vf_queue *p_queue;\n\tstruct qed_queue_cid *p_cid;\n\tstruct qed_sb_info sb_dummy;\n\tu8 qid_usage_idx, vf_legacy;\n\tu32 cid = 0;\n\tint rc;\n\tu16 pq;\n\n\tmemset(&params, 0, sizeof(params));\n\treq = &mbx->req_virt->start_txq;\n\n\tif (!qed_iov_validate_txq(p_hwfn, vf, req->tx_qid,\n\t\t\t\t  QED_IOV_VALIDATE_Q_NA) ||\n\t    !qed_iov_validate_sb(p_hwfn, vf, req->hw_sb))\n\t\tgoto out;\n\n\tqid_usage_idx = qed_iov_vf_mbx_qid(p_hwfn, vf, true);\n\tif (qid_usage_idx == QED_IOV_QID_INVALID)\n\t\tgoto out;\n\n\tp_queue = &vf->vf_queues[req->tx_qid];\n\tif (p_queue->cids[qid_usage_idx].p_cid)\n\t\tgoto out;\n\n\tvf_legacy = qed_vf_calculate_legacy(vf);\n\n\t \n\tparams.queue_id = p_queue->fw_tx_qid;\n\tparams.vport_id = vf->vport_id;\n\tparams.stats_id = vf->abs_vf_id + 0x10;\n\n\t \n\tmemset(&sb_dummy, 0, sizeof(sb_dummy));\n\tsb_dummy.igu_sb_id = req->hw_sb;\n\tparams.p_sb = &sb_dummy;\n\tparams.sb_idx = req->sb_index;\n\n\tmemset(&vf_params, 0, sizeof(vf_params));\n\tvf_params.vfid = vf->relative_vf_id;\n\tvf_params.vf_qid = (u8)req->tx_qid;\n\tvf_params.vf_legacy = vf_legacy;\n\tvf_params.qid_usage_idx = qid_usage_idx;\n\n\tp_cid = qed_eth_queue_to_cid(p_hwfn, vf->opaque_fid,\n\t\t\t\t     &params, false, &vf_params);\n\tif (!p_cid)\n\t\tgoto out;\n\n\tpq = qed_get_cm_pq_idx_vf(p_hwfn, vf->relative_vf_id);\n\trc = qed_eth_txq_start_ramrod(p_hwfn, p_cid,\n\t\t\t\t      req->pbl_addr, req->pbl_size, pq);\n\tif (rc) {\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tqed_eth_queue_cid_release(p_hwfn, p_cid);\n\t} else {\n\t\tstatus = PFVF_STATUS_SUCCESS;\n\t\tp_queue->cids[qid_usage_idx].p_cid = p_cid;\n\t\tp_queue->cids[qid_usage_idx].b_is_tx = true;\n\t\tcid = p_cid->cid;\n\t}\n\nout:\n\tqed_iov_vf_mbx_start_txq_resp(p_hwfn, p_ptt, vf, cid, status);\n}\n\nstatic int qed_iov_vf_stop_rxqs(struct qed_hwfn *p_hwfn,\n\t\t\t\tstruct qed_vf_info *vf,\n\t\t\t\tu16 rxq_id,\n\t\t\t\tu8 qid_usage_idx, bool cqe_completion)\n{\n\tstruct qed_vf_queue *p_queue;\n\tint rc = 0;\n\n\tif (!qed_iov_validate_rxq(p_hwfn, vf, rxq_id, QED_IOV_VALIDATE_Q_NA)) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF[%d] Tried Closing Rx 0x%04x.%02x which is inactive\\n\",\n\t\t\t   vf->relative_vf_id, rxq_id, qid_usage_idx);\n\t\treturn -EINVAL;\n\t}\n\n\tp_queue = &vf->vf_queues[rxq_id];\n\n\t \n\tif (!p_queue->cids[qid_usage_idx].p_cid ||\n\t    p_queue->cids[qid_usage_idx].b_is_tx) {\n\t\tstruct qed_queue_cid *p_cid;\n\n\t\tp_cid = qed_iov_get_vf_rx_queue_cid(p_queue);\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"VF[%d] - Tried Closing Rx 0x%04x.%02x, but Rx is at %04x.%02x\\n\",\n\t\t\t   vf->relative_vf_id,\n\t\t\t   rxq_id, qid_usage_idx, rxq_id, p_cid->qid_usage_idx);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\trc = qed_eth_rx_queue_stop(p_hwfn,\n\t\t\t\t   p_queue->cids[qid_usage_idx].p_cid,\n\t\t\t\t   false, cqe_completion);\n\tif (rc)\n\t\treturn rc;\n\n\tp_queue->cids[qid_usage_idx].p_cid = NULL;\n\tvf->num_active_rxqs--;\n\n\treturn 0;\n}\n\nstatic int qed_iov_vf_stop_txqs(struct qed_hwfn *p_hwfn,\n\t\t\t\tstruct qed_vf_info *vf,\n\t\t\t\tu16 txq_id, u8 qid_usage_idx)\n{\n\tstruct qed_vf_queue *p_queue;\n\tint rc = 0;\n\n\tif (!qed_iov_validate_txq(p_hwfn, vf, txq_id, QED_IOV_VALIDATE_Q_NA))\n\t\treturn -EINVAL;\n\n\tp_queue = &vf->vf_queues[txq_id];\n\tif (!p_queue->cids[qid_usage_idx].p_cid ||\n\t    !p_queue->cids[qid_usage_idx].b_is_tx)\n\t\treturn -EINVAL;\n\n\trc = qed_eth_tx_queue_stop(p_hwfn, p_queue->cids[qid_usage_idx].p_cid);\n\tif (rc)\n\t\treturn rc;\n\n\tp_queue->cids[qid_usage_idx].p_cid = NULL;\n\treturn 0;\n}\n\nstatic void qed_iov_vf_mbx_stop_rxqs(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t     struct qed_vf_info *vf)\n{\n\tu16 length = sizeof(struct pfvf_def_resp_tlv);\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tu8 status = PFVF_STATUS_FAILURE;\n\tstruct vfpf_stop_rxqs_tlv *req;\n\tu8 qid_usage_idx;\n\tint rc;\n\n\t \n\treq = &mbx->req_virt->stop_rxqs;\n\tif (req->num_rxqs != 1) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Odd; VF[%d] tried stopping multiple Rx queues\\n\",\n\t\t\t   vf->relative_vf_id);\n\t\tstatus = PFVF_STATUS_NOT_SUPPORTED;\n\t\tgoto out;\n\t}\n\n\t \n\tqid_usage_idx = qed_iov_vf_mbx_qid(p_hwfn, vf, false);\n\tif (qid_usage_idx == QED_IOV_QID_INVALID)\n\t\tgoto out;\n\n\trc = qed_iov_vf_stop_rxqs(p_hwfn, vf, req->rx_qid,\n\t\t\t\t  qid_usage_idx, req->cqe_completion);\n\tif (!rc)\n\t\tstatus = PFVF_STATUS_SUCCESS;\nout:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_STOP_RXQS,\n\t\t\t     length, status);\n}\n\nstatic void qed_iov_vf_mbx_stop_txqs(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t     struct qed_vf_info *vf)\n{\n\tu16 length = sizeof(struct pfvf_def_resp_tlv);\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tu8 status = PFVF_STATUS_FAILURE;\n\tstruct vfpf_stop_txqs_tlv *req;\n\tu8 qid_usage_idx;\n\tint rc;\n\n\t \n\treq = &mbx->req_virt->stop_txqs;\n\tif (req->num_txqs != 1) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Odd; VF[%d] tried stopping multiple Tx queues\\n\",\n\t\t\t   vf->relative_vf_id);\n\t\tstatus = PFVF_STATUS_NOT_SUPPORTED;\n\t\tgoto out;\n\t}\n\n\t \n\tqid_usage_idx = qed_iov_vf_mbx_qid(p_hwfn, vf, true);\n\tif (qid_usage_idx == QED_IOV_QID_INVALID)\n\t\tgoto out;\n\n\trc = qed_iov_vf_stop_txqs(p_hwfn, vf, req->tx_qid, qid_usage_idx);\n\tif (!rc)\n\t\tstatus = PFVF_STATUS_SUCCESS;\n\nout:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_STOP_TXQS,\n\t\t\t     length, status);\n}\n\nstatic void qed_iov_vf_mbx_update_rxqs(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt,\n\t\t\t\t       struct qed_vf_info *vf)\n{\n\tstruct qed_queue_cid *handlers[QED_MAX_VF_CHAINS_PER_PF];\n\tu16 length = sizeof(struct pfvf_def_resp_tlv);\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tstruct vfpf_update_rxq_tlv *req;\n\tu8 status = PFVF_STATUS_FAILURE;\n\tu8 complete_event_flg;\n\tu8 complete_cqe_flg;\n\tu8 qid_usage_idx;\n\tint rc;\n\tu8 i;\n\n\treq = &mbx->req_virt->update_rxq;\n\tcomplete_cqe_flg = !!(req->flags & VFPF_RXQ_UPD_COMPLETE_CQE_FLAG);\n\tcomplete_event_flg = !!(req->flags & VFPF_RXQ_UPD_COMPLETE_EVENT_FLAG);\n\n\tqid_usage_idx = qed_iov_vf_mbx_qid(p_hwfn, vf, false);\n\tif (qid_usage_idx == QED_IOV_QID_INVALID)\n\t\tgoto out;\n\n\t \n\tif ((vf->acquire.vfdev_info.capabilities &\n\t     VFPF_ACQUIRE_CAP_QUEUE_QIDS) && req->num_rxqs != 1) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF[%d] supports QIDs but sends multiple queues\\n\",\n\t\t\t   vf->relative_vf_id);\n\t\tgoto out;\n\t}\n\n\t \n\tfor (i = req->rx_qid; i < req->rx_qid + req->num_rxqs; i++) {\n\t\tif (!qed_iov_validate_rxq(p_hwfn, vf, i,\n\t\t\t\t\t  QED_IOV_VALIDATE_Q_NA) ||\n\t\t    !vf->vf_queues[i].cids[qid_usage_idx].p_cid ||\n\t\t    vf->vf_queues[i].cids[qid_usage_idx].b_is_tx) {\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"VF[%d]: Incorrect Rxqs [%04x, %02x]\\n\",\n\t\t\t\t   vf->relative_vf_id, req->rx_qid,\n\t\t\t\t   req->num_rxqs);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < req->num_rxqs; i++) {\n\t\tu16 qid = req->rx_qid + i;\n\n\t\thandlers[i] = vf->vf_queues[qid].cids[qid_usage_idx].p_cid;\n\t}\n\n\trc = qed_sp_eth_rx_queues_update(p_hwfn, (void **)&handlers,\n\t\t\t\t\t req->num_rxqs,\n\t\t\t\t\t complete_cqe_flg,\n\t\t\t\t\t complete_event_flg,\n\t\t\t\t\t QED_SPQ_MODE_EBLOCK, NULL);\n\tif (rc)\n\t\tgoto out;\n\n\tstatus = PFVF_STATUS_SUCCESS;\nout:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_UPDATE_RXQ,\n\t\t\t     length, status);\n}\n\nvoid *qed_iov_search_list_tlvs(struct qed_hwfn *p_hwfn,\n\t\t\t       void *p_tlvs_list, u16 req_type)\n{\n\tstruct channel_tlv *p_tlv = (struct channel_tlv *)p_tlvs_list;\n\tint len = 0;\n\n\tdo {\n\t\tif (!p_tlv->length) {\n\t\t\tDP_NOTICE(p_hwfn, \"Zero length TLV found\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (p_tlv->type == req_type) {\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"Extended tlv type %d, length %d found\\n\",\n\t\t\t\t   p_tlv->type, p_tlv->length);\n\t\t\treturn p_tlv;\n\t\t}\n\n\t\tlen += p_tlv->length;\n\t\tp_tlv = (struct channel_tlv *)((u8 *)p_tlv + p_tlv->length);\n\n\t\tif ((len + p_tlv->length) > TLV_BUFFER_SIZE) {\n\t\t\tDP_NOTICE(p_hwfn, \"TLVs has overrun the buffer size\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t} while (p_tlv->type != CHANNEL_TLV_LIST_END);\n\n\treturn NULL;\n}\n\nstatic void\nqed_iov_vp_update_act_param(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_sp_vport_update_params *p_data,\n\t\t\t    struct qed_iov_vf_mbx *p_mbx, u16 *tlvs_mask)\n{\n\tstruct vfpf_vport_update_activate_tlv *p_act_tlv;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_ACTIVATE;\n\n\tp_act_tlv = (struct vfpf_vport_update_activate_tlv *)\n\t\t    qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt, tlv);\n\tif (!p_act_tlv)\n\t\treturn;\n\n\tp_data->update_vport_active_rx_flg = p_act_tlv->update_rx;\n\tp_data->vport_active_rx_flg = p_act_tlv->active_rx;\n\tp_data->update_vport_active_tx_flg = p_act_tlv->update_tx;\n\tp_data->vport_active_tx_flg = p_act_tlv->active_tx;\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_ACTIVATE;\n}\n\nstatic void\nqed_iov_vp_update_vlan_param(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_sp_vport_update_params *p_data,\n\t\t\t     struct qed_vf_info *p_vf,\n\t\t\t     struct qed_iov_vf_mbx *p_mbx, u16 *tlvs_mask)\n{\n\tstruct vfpf_vport_update_vlan_strip_tlv *p_vlan_tlv;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_VLAN_STRIP;\n\n\tp_vlan_tlv = (struct vfpf_vport_update_vlan_strip_tlv *)\n\t\t     qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt, tlv);\n\tif (!p_vlan_tlv)\n\t\treturn;\n\n\tp_vf->shadow_config.inner_vlan_removal = p_vlan_tlv->remove_vlan;\n\n\t \n\tif (!(p_vf->configured_features & BIT(VLAN_ADDR_FORCED))) {\n\t\tp_data->update_inner_vlan_removal_flg = 1;\n\t\tp_data->inner_vlan_removal_flg = p_vlan_tlv->remove_vlan;\n\t}\n\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_VLAN_STRIP;\n}\n\nstatic void\nqed_iov_vp_update_tx_switch(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_sp_vport_update_params *p_data,\n\t\t\t    struct qed_iov_vf_mbx *p_mbx, u16 *tlvs_mask)\n{\n\tstruct vfpf_vport_update_tx_switch_tlv *p_tx_switch_tlv;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_TX_SWITCH;\n\n\tp_tx_switch_tlv = (struct vfpf_vport_update_tx_switch_tlv *)\n\t\t\t  qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt,\n\t\t\t\t\t\t   tlv);\n\tif (!p_tx_switch_tlv)\n\t\treturn;\n\n\tp_data->update_tx_switching_flg = 1;\n\tp_data->tx_switching_flg = p_tx_switch_tlv->tx_switching;\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_TX_SWITCH;\n}\n\nstatic void\nqed_iov_vp_update_mcast_bin_param(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_sp_vport_update_params *p_data,\n\t\t\t\t  struct qed_iov_vf_mbx *p_mbx, u16 *tlvs_mask)\n{\n\tstruct vfpf_vport_update_mcast_bin_tlv *p_mcast_tlv;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_MCAST;\n\n\tp_mcast_tlv = (struct vfpf_vport_update_mcast_bin_tlv *)\n\t    qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt, tlv);\n\tif (!p_mcast_tlv)\n\t\treturn;\n\n\tp_data->update_approx_mcast_flg = 1;\n\tmemcpy(p_data->bins, p_mcast_tlv->bins,\n\t       sizeof(u32) * ETH_MULTICAST_MAC_BINS_IN_REGS);\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_MCAST;\n}\n\nstatic void\nqed_iov_vp_update_accept_flag(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_sp_vport_update_params *p_data,\n\t\t\t      struct qed_iov_vf_mbx *p_mbx, u16 *tlvs_mask)\n{\n\tstruct qed_filter_accept_flags *p_flags = &p_data->accept_flags;\n\tstruct vfpf_vport_update_accept_param_tlv *p_accept_tlv;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_ACCEPT_PARAM;\n\n\tp_accept_tlv = (struct vfpf_vport_update_accept_param_tlv *)\n\t    qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt, tlv);\n\tif (!p_accept_tlv)\n\t\treturn;\n\n\tp_flags->update_rx_mode_config = p_accept_tlv->update_rx_mode;\n\tp_flags->rx_accept_filter = p_accept_tlv->rx_accept_filter;\n\tp_flags->update_tx_mode_config = p_accept_tlv->update_tx_mode;\n\tp_flags->tx_accept_filter = p_accept_tlv->tx_accept_filter;\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_ACCEPT_PARAM;\n}\n\nstatic void\nqed_iov_vp_update_accept_any_vlan(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_sp_vport_update_params *p_data,\n\t\t\t\t  struct qed_iov_vf_mbx *p_mbx, u16 *tlvs_mask)\n{\n\tstruct vfpf_vport_update_accept_any_vlan_tlv *p_accept_any_vlan;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_ACCEPT_ANY_VLAN;\n\n\tp_accept_any_vlan = (struct vfpf_vport_update_accept_any_vlan_tlv *)\n\t\t\t    qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt,\n\t\t\t\t\t\t     tlv);\n\tif (!p_accept_any_vlan)\n\t\treturn;\n\n\tp_data->accept_any_vlan = p_accept_any_vlan->accept_any_vlan;\n\tp_data->update_accept_any_vlan_flg =\n\t\t    p_accept_any_vlan->update_accept_any_vlan_flg;\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_ACCEPT_ANY_VLAN;\n}\n\nstatic void\nqed_iov_vp_update_rss_param(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_vf_info *vf,\n\t\t\t    struct qed_sp_vport_update_params *p_data,\n\t\t\t    struct qed_rss_params *p_rss,\n\t\t\t    struct qed_iov_vf_mbx *p_mbx,\n\t\t\t    u16 *tlvs_mask, u16 *tlvs_accepted)\n{\n\tstruct vfpf_vport_update_rss_tlv *p_rss_tlv;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_RSS;\n\tbool b_reject = false;\n\tu16 table_size;\n\tu16 i, q_idx;\n\n\tp_rss_tlv = (struct vfpf_vport_update_rss_tlv *)\n\t\t    qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt, tlv);\n\tif (!p_rss_tlv) {\n\t\tp_data->rss_params = NULL;\n\t\treturn;\n\t}\n\n\tmemset(p_rss, 0, sizeof(struct qed_rss_params));\n\n\tp_rss->update_rss_config = !!(p_rss_tlv->update_rss_flags &\n\t\t\t\t      VFPF_UPDATE_RSS_CONFIG_FLAG);\n\tp_rss->update_rss_capabilities = !!(p_rss_tlv->update_rss_flags &\n\t\t\t\t\t    VFPF_UPDATE_RSS_CAPS_FLAG);\n\tp_rss->update_rss_ind_table = !!(p_rss_tlv->update_rss_flags &\n\t\t\t\t\t VFPF_UPDATE_RSS_IND_TABLE_FLAG);\n\tp_rss->update_rss_key = !!(p_rss_tlv->update_rss_flags &\n\t\t\t\t   VFPF_UPDATE_RSS_KEY_FLAG);\n\n\tp_rss->rss_enable = p_rss_tlv->rss_enable;\n\tp_rss->rss_eng_id = vf->relative_vf_id + 1;\n\tp_rss->rss_caps = p_rss_tlv->rss_caps;\n\tp_rss->rss_table_size_log = p_rss_tlv->rss_table_size_log;\n\tmemcpy(p_rss->rss_key, p_rss_tlv->rss_key, sizeof(p_rss->rss_key));\n\n\ttable_size = min_t(u16, ARRAY_SIZE(p_rss->rss_ind_table),\n\t\t\t   (1 << p_rss_tlv->rss_table_size_log));\n\n\tfor (i = 0; i < table_size; i++) {\n\t\tstruct qed_queue_cid *p_cid;\n\n\t\tq_idx = p_rss_tlv->rss_ind_table[i];\n\t\tif (!qed_iov_validate_rxq(p_hwfn, vf, q_idx,\n\t\t\t\t\t  QED_IOV_VALIDATE_Q_ENABLE)) {\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"VF[%d]: Omitting RSS due to wrong queue %04x\\n\",\n\t\t\t\t   vf->relative_vf_id, q_idx);\n\t\t\tb_reject = true;\n\t\t\tgoto out;\n\t\t}\n\n\t\tp_cid = qed_iov_get_vf_rx_queue_cid(&vf->vf_queues[q_idx]);\n\t\tp_rss->rss_ind_table[i] = p_cid;\n\t}\n\n\tp_data->rss_params = p_rss;\nout:\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_RSS;\n\tif (!b_reject)\n\t\t*tlvs_accepted |= 1 << QED_IOV_VP_UPDATE_RSS;\n}\n\nstatic void\nqed_iov_vp_update_sge_tpa_param(struct qed_hwfn *p_hwfn,\n\t\t\t\tstruct qed_vf_info *vf,\n\t\t\t\tstruct qed_sp_vport_update_params *p_data,\n\t\t\t\tstruct qed_sge_tpa_params *p_sge_tpa,\n\t\t\t\tstruct qed_iov_vf_mbx *p_mbx, u16 *tlvs_mask)\n{\n\tstruct vfpf_vport_update_sge_tpa_tlv *p_sge_tpa_tlv;\n\tu16 tlv = CHANNEL_TLV_VPORT_UPDATE_SGE_TPA;\n\n\tp_sge_tpa_tlv = (struct vfpf_vport_update_sge_tpa_tlv *)\n\t    qed_iov_search_list_tlvs(p_hwfn, p_mbx->req_virt, tlv);\n\n\tif (!p_sge_tpa_tlv) {\n\t\tp_data->sge_tpa_params = NULL;\n\t\treturn;\n\t}\n\n\tmemset(p_sge_tpa, 0, sizeof(struct qed_sge_tpa_params));\n\n\tp_sge_tpa->update_tpa_en_flg =\n\t    !!(p_sge_tpa_tlv->update_sge_tpa_flags & VFPF_UPDATE_TPA_EN_FLAG);\n\tp_sge_tpa->update_tpa_param_flg =\n\t    !!(p_sge_tpa_tlv->update_sge_tpa_flags &\n\t\tVFPF_UPDATE_TPA_PARAM_FLAG);\n\n\tp_sge_tpa->tpa_ipv4_en_flg =\n\t    !!(p_sge_tpa_tlv->sge_tpa_flags & VFPF_TPA_IPV4_EN_FLAG);\n\tp_sge_tpa->tpa_ipv6_en_flg =\n\t    !!(p_sge_tpa_tlv->sge_tpa_flags & VFPF_TPA_IPV6_EN_FLAG);\n\tp_sge_tpa->tpa_pkt_split_flg =\n\t    !!(p_sge_tpa_tlv->sge_tpa_flags & VFPF_TPA_PKT_SPLIT_FLAG);\n\tp_sge_tpa->tpa_hdr_data_split_flg =\n\t    !!(p_sge_tpa_tlv->sge_tpa_flags & VFPF_TPA_HDR_DATA_SPLIT_FLAG);\n\tp_sge_tpa->tpa_gro_consistent_flg =\n\t    !!(p_sge_tpa_tlv->sge_tpa_flags & VFPF_TPA_GRO_CONSIST_FLAG);\n\n\tp_sge_tpa->tpa_max_aggs_num = p_sge_tpa_tlv->tpa_max_aggs_num;\n\tp_sge_tpa->tpa_max_size = p_sge_tpa_tlv->tpa_max_size;\n\tp_sge_tpa->tpa_min_size_to_start = p_sge_tpa_tlv->tpa_min_size_to_start;\n\tp_sge_tpa->tpa_min_size_to_cont = p_sge_tpa_tlv->tpa_min_size_to_cont;\n\tp_sge_tpa->max_buffers_per_cqe = p_sge_tpa_tlv->max_buffers_per_cqe;\n\n\tp_data->sge_tpa_params = p_sge_tpa;\n\n\t*tlvs_mask |= 1 << QED_IOV_VP_UPDATE_SGE_TPA;\n}\n\nstatic int qed_iov_pre_update_vport(struct qed_hwfn *hwfn,\n\t\t\t\t    u8 vfid,\n\t\t\t\t    struct qed_sp_vport_update_params *params,\n\t\t\t\t    u16 *tlvs)\n{\n\tu8 mask = QED_ACCEPT_UCAST_UNMATCHED | QED_ACCEPT_MCAST_UNMATCHED;\n\tstruct qed_filter_accept_flags *flags = &params->accept_flags;\n\tstruct qed_public_vf_info *vf_info;\n\tu16 tlv_mask;\n\n\ttlv_mask = BIT(QED_IOV_VP_UPDATE_ACCEPT_PARAM) |\n\t\t   BIT(QED_IOV_VP_UPDATE_ACCEPT_ANY_VLAN);\n\n\t \n\tif (!(*tlvs & tlv_mask))\n\t\treturn 0;\n\n\tvf_info = qed_iov_get_public_vf_info(hwfn, vfid, true);\n\n\tif (flags->update_rx_mode_config) {\n\t\tvf_info->rx_accept_mode = flags->rx_accept_filter;\n\t\tif (!vf_info->is_trusted_configured)\n\t\t\tflags->rx_accept_filter &= ~mask;\n\t}\n\n\tif (flags->update_tx_mode_config) {\n\t\tvf_info->tx_accept_mode = flags->tx_accept_filter;\n\t\tif (!vf_info->is_trusted_configured)\n\t\t\tflags->tx_accept_filter &= ~mask;\n\t}\n\n\tif (params->update_accept_any_vlan_flg) {\n\t\tvf_info->accept_any_vlan = params->accept_any_vlan;\n\n\t\tif (vf_info->forced_vlan && !vf_info->is_trusted_configured)\n\t\t\tparams->accept_any_vlan = false;\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_iov_vf_mbx_vport_update(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_ptt *p_ptt,\n\t\t\t\t\tstruct qed_vf_info *vf)\n{\n\tstruct qed_rss_params *p_rss_params = NULL;\n\tstruct qed_sp_vport_update_params params;\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tstruct qed_sge_tpa_params sge_tpa_params;\n\tu16 tlvs_mask = 0, tlvs_accepted = 0;\n\tu8 status = PFVF_STATUS_SUCCESS;\n\tu16 length;\n\tint rc;\n\n\t \n\tif (!vf->vport_instance) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"No VPORT instance available for VF[%d], failing vport update\\n\",\n\t\t\t   vf->abs_vf_id);\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tgoto out;\n\t}\n\tp_rss_params = vzalloc(sizeof(*p_rss_params));\n\tif (!p_rss_params) {\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tgoto out;\n\t}\n\n\tmemset(&params, 0, sizeof(params));\n\tparams.opaque_fid = vf->opaque_fid;\n\tparams.vport_id = vf->vport_id;\n\tparams.rss_params = NULL;\n\n\t \n\tqed_iov_vp_update_act_param(p_hwfn, &params, mbx, &tlvs_mask);\n\tqed_iov_vp_update_vlan_param(p_hwfn, &params, vf, mbx, &tlvs_mask);\n\tqed_iov_vp_update_tx_switch(p_hwfn, &params, mbx, &tlvs_mask);\n\tqed_iov_vp_update_mcast_bin_param(p_hwfn, &params, mbx, &tlvs_mask);\n\tqed_iov_vp_update_accept_flag(p_hwfn, &params, mbx, &tlvs_mask);\n\tqed_iov_vp_update_accept_any_vlan(p_hwfn, &params, mbx, &tlvs_mask);\n\tqed_iov_vp_update_sge_tpa_param(p_hwfn, vf, &params,\n\t\t\t\t\t&sge_tpa_params, mbx, &tlvs_mask);\n\n\ttlvs_accepted = tlvs_mask;\n\n\t \n\tqed_iov_vp_update_rss_param(p_hwfn, vf, &params, p_rss_params,\n\t\t\t\t    mbx, &tlvs_mask, &tlvs_accepted);\n\n\tif (qed_iov_pre_update_vport(p_hwfn, vf->relative_vf_id,\n\t\t\t\t     &params, &tlvs_accepted)) {\n\t\ttlvs_accepted = 0;\n\t\tstatus = PFVF_STATUS_NOT_SUPPORTED;\n\t\tgoto out;\n\t}\n\n\tif (!tlvs_accepted) {\n\t\tif (tlvs_mask)\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"Upper-layer prevents VF vport configuration\\n\");\n\t\telse\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"No feature tlvs found for vport update\\n\");\n\t\tstatus = PFVF_STATUS_NOT_SUPPORTED;\n\t\tgoto out;\n\t}\n\n\trc = qed_sp_vport_update(p_hwfn, &params, QED_SPQ_MODE_EBLOCK, NULL);\n\n\tif (rc)\n\t\tstatus = PFVF_STATUS_FAILURE;\n\nout:\n\tvfree(p_rss_params);\n\tlength = qed_iov_prep_vp_update_resp_tlvs(p_hwfn, vf, mbx, status,\n\t\t\t\t\t\t  tlvs_mask, tlvs_accepted);\n\tqed_iov_send_response(p_hwfn, p_ptt, vf, length, status);\n}\n\nstatic int qed_iov_vf_update_vlan_shadow(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t struct qed_vf_info *p_vf,\n\t\t\t\t\t struct qed_filter_ucast *p_params)\n{\n\tint i;\n\n\t \n\tif (p_params->opcode == QED_FILTER_REMOVE) {\n\t\tfor (i = 0; i < QED_ETH_VF_NUM_VLAN_FILTERS + 1; i++)\n\t\t\tif (p_vf->shadow_config.vlans[i].used &&\n\t\t\t    p_vf->shadow_config.vlans[i].vid ==\n\t\t\t    p_params->vlan) {\n\t\t\t\tp_vf->shadow_config.vlans[i].used = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\tif (i == QED_ETH_VF_NUM_VLAN_FILTERS + 1) {\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"VF [%d] - Tries to remove a non-existing vlan\\n\",\n\t\t\t\t   p_vf->relative_vf_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (p_params->opcode == QED_FILTER_REPLACE ||\n\t\t   p_params->opcode == QED_FILTER_FLUSH) {\n\t\tfor (i = 0; i < QED_ETH_VF_NUM_VLAN_FILTERS + 1; i++)\n\t\t\tp_vf->shadow_config.vlans[i].used = false;\n\t}\n\n\t \n\tif (p_vf->bulletin.p_virt->valid_bitmap & BIT(VLAN_ADDR_FORCED))\n\t\treturn 0;\n\n\tif (p_params->opcode == QED_FILTER_ADD ||\n\t    p_params->opcode == QED_FILTER_REPLACE) {\n\t\tfor (i = 0; i < QED_ETH_VF_NUM_VLAN_FILTERS + 1; i++) {\n\t\t\tif (p_vf->shadow_config.vlans[i].used)\n\t\t\t\tcontinue;\n\n\t\t\tp_vf->shadow_config.vlans[i].used = true;\n\t\t\tp_vf->shadow_config.vlans[i].vid = p_params->vlan;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (i == QED_ETH_VF_NUM_VLAN_FILTERS + 1) {\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"VF [%d] - Tries to configure more than %d vlan filters\\n\",\n\t\t\t\t   p_vf->relative_vf_id,\n\t\t\t\t   QED_ETH_VF_NUM_VLAN_FILTERS + 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_iov_vf_update_mac_shadow(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_vf_info *p_vf,\n\t\t\t\t\tstruct qed_filter_ucast *p_params)\n{\n\tint i;\n\n\t \n\tif (p_vf->bulletin.p_virt->valid_bitmap & BIT(MAC_ADDR_FORCED))\n\t\treturn 0;\n\n\t \n\tif (p_vf->p_vf_info.is_trusted_configured)\n\t\treturn 0;\n\n\t \n\tif (p_params->opcode == QED_FILTER_REMOVE) {\n\t\tfor (i = 0; i < QED_ETH_VF_NUM_MAC_FILTERS; i++) {\n\t\t\tif (ether_addr_equal(p_vf->shadow_config.macs[i],\n\t\t\t\t\t     p_params->mac)) {\n\t\t\t\teth_zero_addr(p_vf->shadow_config.macs[i]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (i == QED_ETH_VF_NUM_MAC_FILTERS) {\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"MAC isn't configured\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (p_params->opcode == QED_FILTER_REPLACE ||\n\t\t   p_params->opcode == QED_FILTER_FLUSH) {\n\t\tfor (i = 0; i < QED_ETH_VF_NUM_MAC_FILTERS; i++)\n\t\t\teth_zero_addr(p_vf->shadow_config.macs[i]);\n\t}\n\n\t \n\tif (p_params->opcode != QED_FILTER_ADD &&\n\t    p_params->opcode != QED_FILTER_REPLACE)\n\t\treturn 0;\n\n\tfor (i = 0; i < QED_ETH_VF_NUM_MAC_FILTERS; i++) {\n\t\tif (is_zero_ether_addr(p_vf->shadow_config.macs[i])) {\n\t\t\tether_addr_copy(p_vf->shadow_config.macs[i],\n\t\t\t\t\tp_params->mac);\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"Added MAC at %d entry in shadow\\n\", i);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == QED_ETH_VF_NUM_MAC_FILTERS) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV, \"No available place for MAC\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nqed_iov_vf_update_unicast_shadow(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_vf_info *p_vf,\n\t\t\t\t struct qed_filter_ucast *p_params)\n{\n\tint rc = 0;\n\n\tif (p_params->type == QED_FILTER_MAC) {\n\t\trc = qed_iov_vf_update_mac_shadow(p_hwfn, p_vf, p_params);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tif (p_params->type == QED_FILTER_VLAN)\n\t\trc = qed_iov_vf_update_vlan_shadow(p_hwfn, p_vf, p_params);\n\n\treturn rc;\n}\n\nstatic int qed_iov_chk_ucast(struct qed_hwfn *hwfn,\n\t\t\t     int vfid, struct qed_filter_ucast *params)\n{\n\tstruct qed_public_vf_info *vf;\n\n\tvf = qed_iov_get_public_vf_info(hwfn, vfid, true);\n\tif (!vf)\n\t\treturn -EINVAL;\n\n\t \n\tif (params->type == QED_FILTER_MAC ||\n\t    params->type == QED_FILTER_MAC_VLAN) {\n\t\tether_addr_copy(vf->mac, params->mac);\n\n\t\tif (vf->is_trusted_configured) {\n\t\t\tqed_iov_bulletin_set_mac(hwfn, vf->mac, vfid);\n\n\t\t\t \n\t\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_iov_vf_mbx_ucast_filter(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_ptt *p_ptt,\n\t\t\t\t\tstruct qed_vf_info *vf)\n{\n\tstruct qed_bulletin_content *p_bulletin = vf->bulletin.p_virt;\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tstruct vfpf_ucast_filter_tlv *req;\n\tu8 status = PFVF_STATUS_SUCCESS;\n\tstruct qed_filter_ucast params;\n\tint rc;\n\n\t \n\tmemset(&params, 0, sizeof(struct qed_filter_ucast));\n\treq = &mbx->req_virt->ucast_filter;\n\tparams.opcode = (enum qed_filter_opcode)req->opcode;\n\tparams.type = (enum qed_filter_ucast_type)req->type;\n\n\tparams.is_rx_filter = 1;\n\tparams.is_tx_filter = 1;\n\tparams.vport_to_remove_from = vf->vport_id;\n\tparams.vport_to_add_to = vf->vport_id;\n\tmemcpy(params.mac, req->mac, ETH_ALEN);\n\tparams.vlan = req->vlan;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_IOV,\n\t\t   \"VF[%d]: opcode 0x%02x type 0x%02x [%s %s] [vport 0x%02x] MAC %pM, vlan 0x%04x\\n\",\n\t\t   vf->abs_vf_id, params.opcode, params.type,\n\t\t   params.is_rx_filter ? \"RX\" : \"\",\n\t\t   params.is_tx_filter ? \"TX\" : \"\",\n\t\t   params.vport_to_add_to,\n\t\t   params.mac, params.vlan);\n\n\tif (!vf->vport_instance) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"No VPORT instance available for VF[%d], failing ucast MAC configuration\\n\",\n\t\t\t   vf->abs_vf_id);\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tgoto out;\n\t}\n\n\t \n\tif (qed_iov_vf_update_unicast_shadow(p_hwfn, vf, &params)) {\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tgoto out;\n\t}\n\n\t \n\tif ((p_bulletin->valid_bitmap & BIT(VLAN_ADDR_FORCED)) &&\n\t    (params.type == QED_FILTER_VLAN ||\n\t     params.type == QED_FILTER_MAC_VLAN)) {\n\t\t \n\t\tif (params.opcode == QED_FILTER_ADD ||\n\t\t    params.opcode == QED_FILTER_REPLACE)\n\t\t\tstatus = PFVF_STATUS_FORCED;\n\t\tgoto out;\n\t}\n\n\tif ((p_bulletin->valid_bitmap & BIT(MAC_ADDR_FORCED)) &&\n\t    (params.type == QED_FILTER_MAC ||\n\t     params.type == QED_FILTER_MAC_VLAN)) {\n\t\tif (!ether_addr_equal(p_bulletin->mac, params.mac) ||\n\t\t    (params.opcode != QED_FILTER_ADD &&\n\t\t     params.opcode != QED_FILTER_REPLACE))\n\t\t\tstatus = PFVF_STATUS_FORCED;\n\t\tgoto out;\n\t}\n\n\trc = qed_iov_chk_ucast(p_hwfn, vf->relative_vf_id, &params);\n\tif (rc) {\n\t\tstatus = PFVF_STATUS_FAILURE;\n\t\tgoto out;\n\t}\n\n\trc = qed_sp_eth_filter_ucast(p_hwfn, vf->opaque_fid, &params,\n\t\t\t\t     QED_SPQ_MODE_CB, NULL);\n\tif (rc)\n\t\tstatus = PFVF_STATUS_FAILURE;\n\nout:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_UCAST_FILTER,\n\t\t\t     sizeof(struct pfvf_def_resp_tlv), status);\n}\n\nstatic void qed_iov_vf_mbx_int_cleanup(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt,\n\t\t\t\t       struct qed_vf_info *vf)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < vf->num_sbs; i++)\n\t\tqed_int_igu_init_pure_rt_single(p_hwfn, p_ptt,\n\t\t\t\t\t\tvf->igu_sbs[i],\n\t\t\t\t\t\tvf->opaque_fid, false);\n\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_INT_CLEANUP,\n\t\t\t     sizeof(struct pfvf_def_resp_tlv),\n\t\t\t     PFVF_STATUS_SUCCESS);\n}\n\nstatic void qed_iov_vf_mbx_close(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt, struct qed_vf_info *vf)\n{\n\tu16 length = sizeof(struct pfvf_def_resp_tlv);\n\tu8 status = PFVF_STATUS_SUCCESS;\n\n\t \n\tqed_iov_vf_igu_set_int(p_hwfn, p_ptt, vf, 0);\n\n\t \n\tqed_iov_config_perm_table(p_hwfn, p_ptt, vf, 0);\n\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_CLOSE,\n\t\t\t     length, status);\n}\n\nstatic void qed_iov_vf_mbx_release(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt,\n\t\t\t\t   struct qed_vf_info *p_vf)\n{\n\tu16 length = sizeof(struct pfvf_def_resp_tlv);\n\tu8 status = PFVF_STATUS_SUCCESS;\n\tint rc = 0;\n\n\tqed_iov_vf_cleanup(p_hwfn, p_vf);\n\n\tif (p_vf->state != VF_STOPPED && p_vf->state != VF_FREE) {\n\t\t \n\t\trc = qed_sp_vf_stop(p_hwfn, p_vf->concrete_fid,\n\t\t\t\t    p_vf->opaque_fid);\n\n\t\tif (rc) {\n\t\t\tDP_ERR(p_hwfn, \"qed_sp_vf_stop returned error %d\\n\",\n\t\t\t       rc);\n\t\t\tstatus = PFVF_STATUS_FAILURE;\n\t\t}\n\n\t\tp_vf->state = VF_STOPPED;\n\t}\n\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, p_vf, CHANNEL_TLV_RELEASE,\n\t\t\t     length, status);\n}\n\nstatic void qed_iov_vf_pf_get_coalesce(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt,\n\t\t\t\t       struct qed_vf_info *p_vf)\n{\n\tstruct qed_iov_vf_mbx *mbx = &p_vf->vf_mbx;\n\tstruct pfvf_read_coal_resp_tlv *p_resp;\n\tstruct vfpf_read_coal_req_tlv *req;\n\tu8 status = PFVF_STATUS_FAILURE;\n\tstruct qed_vf_queue *p_queue;\n\tstruct qed_queue_cid *p_cid;\n\tu16 coal = 0, qid, i;\n\tbool b_is_rx;\n\tint rc = 0;\n\n\tmbx->offset = (u8 *)mbx->reply_virt;\n\treq = &mbx->req_virt->read_coal_req;\n\n\tqid = req->qid;\n\tb_is_rx = req->is_rx ? true : false;\n\n\tif (b_is_rx) {\n\t\tif (!qed_iov_validate_rxq(p_hwfn, p_vf, qid,\n\t\t\t\t\t  QED_IOV_VALIDATE_Q_ENABLE)) {\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"VF[%d]: Invalid Rx queue_id = %d\\n\",\n\t\t\t\t   p_vf->abs_vf_id, qid);\n\t\t\tgoto send_resp;\n\t\t}\n\n\t\tp_cid = qed_iov_get_vf_rx_queue_cid(&p_vf->vf_queues[qid]);\n\t\trc = qed_get_rxq_coalesce(p_hwfn, p_ptt, p_cid, &coal);\n\t\tif (rc)\n\t\t\tgoto send_resp;\n\t} else {\n\t\tif (!qed_iov_validate_txq(p_hwfn, p_vf, qid,\n\t\t\t\t\t  QED_IOV_VALIDATE_Q_ENABLE)) {\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"VF[%d]: Invalid Tx queue_id = %d\\n\",\n\t\t\t\t   p_vf->abs_vf_id, qid);\n\t\t\tgoto send_resp;\n\t\t}\n\t\tfor (i = 0; i < MAX_QUEUES_PER_QZONE; i++) {\n\t\t\tp_queue = &p_vf->vf_queues[qid];\n\t\t\tif ((!p_queue->cids[i].p_cid) ||\n\t\t\t    (!p_queue->cids[i].b_is_tx))\n\t\t\t\tcontinue;\n\n\t\t\tp_cid = p_queue->cids[i].p_cid;\n\n\t\t\trc = qed_get_txq_coalesce(p_hwfn, p_ptt, p_cid, &coal);\n\t\t\tif (rc)\n\t\t\t\tgoto send_resp;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tstatus = PFVF_STATUS_SUCCESS;\n\nsend_resp:\n\tp_resp = qed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_COALESCE_READ,\n\t\t\t     sizeof(*p_resp));\n\tp_resp->coal = coal;\n\n\tqed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_LIST_END,\n\t\t    sizeof(struct channel_list_end_tlv));\n\n\tqed_iov_send_response(p_hwfn, p_ptt, p_vf, sizeof(*p_resp), status);\n}\n\nstatic void qed_iov_vf_pf_set_coalesce(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt,\n\t\t\t\t       struct qed_vf_info *vf)\n{\n\tstruct qed_iov_vf_mbx *mbx = &vf->vf_mbx;\n\tstruct vfpf_update_coalesce *req;\n\tu8 status = PFVF_STATUS_FAILURE;\n\tstruct qed_queue_cid *p_cid;\n\tu16 rx_coal, tx_coal;\n\tint rc = 0, i;\n\tu16 qid;\n\n\treq = &mbx->req_virt->update_coalesce;\n\n\trx_coal = req->rx_coal;\n\ttx_coal = req->tx_coal;\n\tqid = req->qid;\n\n\tif (!qed_iov_validate_rxq(p_hwfn, vf, qid,\n\t\t\t\t  QED_IOV_VALIDATE_Q_ENABLE) && rx_coal) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF[%d]: Invalid Rx queue_id = %d\\n\",\n\t\t\t   vf->abs_vf_id, qid);\n\t\tgoto out;\n\t}\n\n\tif (!qed_iov_validate_txq(p_hwfn, vf, qid,\n\t\t\t\t  QED_IOV_VALIDATE_Q_ENABLE) && tx_coal) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF[%d]: Invalid Tx queue_id = %d\\n\",\n\t\t\t   vf->abs_vf_id, qid);\n\t\tgoto out;\n\t}\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_IOV,\n\t\t   \"VF[%d]: Setting coalesce for VF rx_coal = %d, tx_coal = %d at queue = %d\\n\",\n\t\t   vf->abs_vf_id, rx_coal, tx_coal, qid);\n\n\tif (rx_coal) {\n\t\tp_cid = qed_iov_get_vf_rx_queue_cid(&vf->vf_queues[qid]);\n\n\t\trc = qed_set_rxq_coalesce(p_hwfn, p_ptt, rx_coal, p_cid);\n\t\tif (rc) {\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"VF[%d]: Unable to set rx queue = %d coalesce\\n\",\n\t\t\t\t   vf->abs_vf_id, vf->vf_queues[qid].fw_rx_qid);\n\t\t\tgoto out;\n\t\t}\n\t\tvf->rx_coal = rx_coal;\n\t}\n\n\tif (tx_coal) {\n\t\tstruct qed_vf_queue *p_queue = &vf->vf_queues[qid];\n\n\t\tfor (i = 0; i < MAX_QUEUES_PER_QZONE; i++) {\n\t\t\tif (!p_queue->cids[i].p_cid)\n\t\t\t\tcontinue;\n\n\t\t\tif (!p_queue->cids[i].b_is_tx)\n\t\t\t\tcontinue;\n\n\t\t\trc = qed_set_txq_coalesce(p_hwfn, p_ptt, tx_coal,\n\t\t\t\t\t\t  p_queue->cids[i].p_cid);\n\n\t\t\tif (rc) {\n\t\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t\t   \"VF[%d]: Unable to set tx queue coalesce\\n\",\n\t\t\t\t\t   vf->abs_vf_id);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tvf->tx_coal = tx_coal;\n\t}\n\n\tstatus = PFVF_STATUS_SUCCESS;\nout:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, vf, CHANNEL_TLV_COALESCE_UPDATE,\n\t\t\t     sizeof(struct pfvf_def_resp_tlv), status);\n}\n\nstatic int\nqed_iov_vf_flr_poll_dorq(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_vf_info *p_vf, struct qed_ptt *p_ptt)\n{\n\tint cnt;\n\tu32 val;\n\n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)p_vf->concrete_fid);\n\n\tfor (cnt = 0; cnt < 50; cnt++) {\n\t\tval = qed_rd(p_hwfn, p_ptt, DORQ_REG_VF_USAGE_CNT);\n\t\tif (!val)\n\t\t\tbreak;\n\t\tmsleep(20);\n\t}\n\tqed_fid_pretend(p_hwfn, p_ptt, (u16)p_hwfn->hw_info.concrete_fid);\n\n\tif (cnt == 50) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"VF[%d] - dorq failed to cleanup [usage 0x%08x]\\n\",\n\t\t       p_vf->abs_vf_id, val);\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\n#define MAX_NUM_EXT_VOQS        (MAX_NUM_PORTS * NUM_OF_TCS)\n\nstatic int\nqed_iov_vf_flr_poll_pbf(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_vf_info *p_vf, struct qed_ptt *p_ptt)\n{\n\tu32 prod, cons[MAX_NUM_EXT_VOQS], distance[MAX_NUM_EXT_VOQS], tmp;\n\tu8 max_phys_tcs_per_port = p_hwfn->qm_info.max_phys_tcs_per_port;\n\tu8 max_ports_per_engine = p_hwfn->cdev->num_ports_in_engine;\n\tu32 prod_voq0_addr = PBF_REG_NUM_BLOCKS_ALLOCATED_PROD_VOQ0;\n\tu32 cons_voq0_addr = PBF_REG_NUM_BLOCKS_ALLOCATED_CONS_VOQ0;\n\tu8 port_id, tc, tc_id = 0, voq = 0;\n\tint cnt;\n\n\tmemset(cons, 0, MAX_NUM_EXT_VOQS * sizeof(u32));\n\tmemset(distance, 0, MAX_NUM_EXT_VOQS * sizeof(u32));\n\n\t \n\tfor (port_id = 0; port_id < max_ports_per_engine; port_id++) {\n\t\t \n\t\tfor (tc = 0; tc < max_phys_tcs_per_port + 1; tc++) {\n\t\t\ttc_id = (tc < max_phys_tcs_per_port) ? tc : PURE_LB_TC;\n\t\t\tvoq = VOQ(port_id, tc_id, max_phys_tcs_per_port);\n\t\t\tcons[voq] = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t   cons_voq0_addr + voq * 0x40);\n\t\t\tprod = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t      prod_voq0_addr + voq * 0x40);\n\t\t\tdistance[voq] = prod - cons[voq];\n\t\t}\n\t}\n\n\t \n\tport_id = 0;\n\ttc = 0;\n\tfor (cnt = 0; cnt < 50; cnt++) {\n\t\tfor (; port_id < max_ports_per_engine; port_id++) {\n\t\t\t \n\t\t\tfor (; tc < max_phys_tcs_per_port + 1; tc++) {\n\t\t\t\ttc_id = (tc < max_phys_tcs_per_port) ?\n\t\t\t\t    tc : PURE_LB_TC;\n\t\t\t\tvoq = VOQ(port_id,\n\t\t\t\t\t  tc_id, max_phys_tcs_per_port);\n\t\t\t\ttmp = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t     cons_voq0_addr + voq * 0x40);\n\t\t\t\tif (distance[voq] > tmp - cons[voq])\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (tc == max_phys_tcs_per_port + 1)\n\t\t\t\ttc = 0;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (port_id == max_ports_per_engine)\n\t\t\tbreak;\n\n\t\tmsleep(20);\n\t}\n\n\tif (cnt == 50) {\n\t\tDP_ERR(p_hwfn, \"VF[%d]: pbf poll failed on VOQ%d\\n\",\n\t\t       p_vf->abs_vf_id, (int)voq);\n\n\t\tDP_ERR(p_hwfn, \"VOQ %d has port_id as %d and tc_id as %d]\\n\",\n\t\t       (int)voq, (int)port_id, (int)tc_id);\n\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_iov_vf_flr_poll(struct qed_hwfn *p_hwfn,\n\t\t\t       struct qed_vf_info *p_vf, struct qed_ptt *p_ptt)\n{\n\tint rc;\n\n\trc = qed_iov_vf_flr_poll_dorq(p_hwfn, p_vf, p_ptt);\n\tif (rc)\n\t\treturn rc;\n\n\trc = qed_iov_vf_flr_poll_pbf(p_hwfn, p_vf, p_ptt);\n\tif (rc)\n\t\treturn rc;\n\n\treturn 0;\n}\n\nstatic int\nqed_iov_execute_vf_flr_cleanup(struct qed_hwfn *p_hwfn,\n\t\t\t       struct qed_ptt *p_ptt,\n\t\t\t       u16 rel_vf_id, u32 *ack_vfs)\n{\n\tstruct qed_vf_info *p_vf;\n\tint rc = 0;\n\n\tp_vf = qed_iov_get_vf_info(p_hwfn, rel_vf_id, false);\n\tif (!p_vf)\n\t\treturn 0;\n\n\tif (p_hwfn->pf_iov_info->pending_flr[rel_vf_id / 64] &\n\t    (1ULL << (rel_vf_id % 64))) {\n\t\tu16 vfid = p_vf->abs_vf_id;\n\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF[%d] - Handling FLR\\n\", vfid);\n\n\t\tqed_iov_vf_cleanup(p_hwfn, p_vf);\n\n\t\t \n\t\tif (!p_vf->b_init)\n\t\t\tgoto cleanup;\n\n\t\trc = qed_iov_vf_flr_poll(p_hwfn, p_vf, p_ptt);\n\t\tif (rc)\n\t\t\tgoto cleanup;\n\n\t\trc = qed_final_cleanup(p_hwfn, p_ptt, vfid, true);\n\t\tif (rc) {\n\t\t\tDP_ERR(p_hwfn, \"Failed handle FLR of VF[%d]\\n\", vfid);\n\t\t\treturn rc;\n\t\t}\n\n\t\t \n\t\tREG_WR(p_hwfn,\n\t\t       GET_GTT_REG_ADDR(GTT_BAR0_MAP_REG_USDM_RAM,\n\t\t\t\t\tUSTORM_VF_PF_CHANNEL_READY, vfid), 1);\n\n\t\t \n\t\tp_vf->state = VF_STOPPED;\n\n\t\trc = qed_iov_enable_vf_access(p_hwfn, p_ptt, p_vf);\n\t\tif (rc) {\n\t\t\tDP_ERR(p_hwfn, \"Failed to re-enable VF[%d] acces\\n\",\n\t\t\t       vfid);\n\t\t\treturn rc;\n\t\t}\ncleanup:\n\t\t \n\t\tif (p_vf->state == VF_RESET)\n\t\t\tp_vf->state = VF_STOPPED;\n\t\tack_vfs[vfid / 32] |= BIT((vfid % 32));\n\t\tp_hwfn->pf_iov_info->pending_flr[rel_vf_id / 64] &=\n\t\t    ~(1ULL << (rel_vf_id % 64));\n\t\tp_vf->vf_mbx.b_pending_msg = false;\n\t}\n\n\treturn rc;\n}\n\nstatic int\nqed_iov_vf_flr_cleanup(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 ack_vfs[VF_MAX_STATIC / 32];\n\tint rc = 0;\n\tu16 i;\n\n\tmemset(ack_vfs, 0, sizeof(u32) * (VF_MAX_STATIC / 32));\n\n\t \n\tmsleep(100);\n\n\tfor (i = 0; i < p_hwfn->cdev->p_iov_info->total_vfs; i++)\n\t\tqed_iov_execute_vf_flr_cleanup(p_hwfn, p_ptt, i, ack_vfs);\n\n\trc = qed_mcp_ack_vf_flr(p_hwfn, p_ptt, ack_vfs);\n\treturn rc;\n}\n\nbool qed_iov_mark_vf_flr(struct qed_hwfn *p_hwfn, u32 *p_disabled_vfs)\n{\n\tbool found = false;\n\tu16 i;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV, \"Marking FLR-ed VFs\\n\");\n\tfor (i = 0; i < (VF_MAX_STATIC / 32); i++)\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"[%08x,...,%08x]: %08x\\n\",\n\t\t\t   i * 32, (i + 1) * 32 - 1, p_disabled_vfs[i]);\n\n\tif (!p_hwfn->cdev->p_iov_info) {\n\t\tDP_NOTICE(p_hwfn, \"VF flr but no IOV\\n\");\n\t\treturn false;\n\t}\n\n\t \n\tfor (i = 0; i < p_hwfn->cdev->p_iov_info->total_vfs; i++) {\n\t\tstruct qed_vf_info *p_vf;\n\t\tu8 vfid;\n\n\t\tp_vf = qed_iov_get_vf_info(p_hwfn, i, false);\n\t\tif (!p_vf)\n\t\t\tcontinue;\n\n\t\tvfid = p_vf->abs_vf_id;\n\t\tif (BIT((vfid % 32)) & p_disabled_vfs[vfid / 32]) {\n\t\t\tu64 *p_flr = p_hwfn->pf_iov_info->pending_flr;\n\t\t\tu16 rel_vf_id = p_vf->relative_vf_id;\n\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t\t   \"VF[%d] [rel %d] got FLR-ed\\n\",\n\t\t\t\t   vfid, rel_vf_id);\n\n\t\t\tp_vf->state = VF_RESET;\n\n\t\t\t \n\t\t\tp_flr[rel_vf_id / 64] |= 1ULL << (rel_vf_id % 64);\n\t\t\tfound = true;\n\t\t}\n\t}\n\n\treturn found;\n}\n\nstatic int qed_iov_get_link(struct qed_hwfn *p_hwfn,\n\t\t\t    u16 vfid,\n\t\t\t    struct qed_mcp_link_params *p_params,\n\t\t\t    struct qed_mcp_link_state *p_link,\n\t\t\t    struct qed_mcp_link_capabilities *p_caps)\n{\n\tstruct qed_vf_info *p_vf = qed_iov_get_vf_info(p_hwfn,\n\t\t\t\t\t\t       vfid,\n\t\t\t\t\t\t       false);\n\tstruct qed_bulletin_content *p_bulletin;\n\n\tif (!p_vf)\n\t\treturn -EINVAL;\n\n\tp_bulletin = p_vf->bulletin.p_virt;\n\n\tif (p_params)\n\t\t__qed_vf_get_link_params(p_hwfn, p_params, p_bulletin);\n\tif (p_link)\n\t\t__qed_vf_get_link_state(p_hwfn, p_link, p_bulletin);\n\tif (p_caps)\n\t\t__qed_vf_get_link_caps(p_hwfn, p_caps, p_bulletin);\n\treturn 0;\n}\n\nstatic int\nqed_iov_vf_pf_bulletin_update_mac(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t\t  struct qed_vf_info *p_vf)\n{\n\tstruct qed_bulletin_content *p_bulletin = p_vf->bulletin.p_virt;\n\tstruct qed_iov_vf_mbx *mbx = &p_vf->vf_mbx;\n\tstruct vfpf_bulletin_update_mac_tlv *p_req;\n\tu8 status = PFVF_STATUS_SUCCESS;\n\tint rc = 0;\n\n\tif (!p_vf->p_vf_info.is_trusted_configured) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"Blocking bulletin update request from untrusted VF[%d]\\n\",\n\t\t\t   p_vf->abs_vf_id);\n\t\tstatus = PFVF_STATUS_NOT_SUPPORTED;\n\t\trc = -EINVAL;\n\t\tgoto send_status;\n\t}\n\n\tp_req = &mbx->req_virt->bulletin_update_mac;\n\tether_addr_copy(p_bulletin->mac, p_req->mac);\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t   \"Updated bulletin of VF[%d] with requested MAC[%pM]\\n\",\n\t\t   p_vf->abs_vf_id, p_req->mac);\n\nsend_status:\n\tqed_iov_prepare_resp(p_hwfn, p_ptt, p_vf,\n\t\t\t     CHANNEL_TLV_BULLETIN_UPDATE_MAC,\n\t\t\t     sizeof(struct pfvf_def_resp_tlv), status);\n\treturn rc;\n}\n\nstatic void qed_iov_process_mbx_req(struct qed_hwfn *p_hwfn,\n\t\t\t\t    struct qed_ptt *p_ptt, int vfid)\n{\n\tstruct qed_iov_vf_mbx *mbx;\n\tstruct qed_vf_info *p_vf;\n\n\tp_vf = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!p_vf)\n\t\treturn;\n\n\tmbx = &p_vf->vf_mbx;\n\n\t \n\tif (!mbx->b_pending_msg) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"VF[%02x]: Trying to process mailbox message when none is pending\\n\",\n\t\t\t  p_vf->abs_vf_id);\n\t\treturn;\n\t}\n\tmbx->b_pending_msg = false;\n\n\tmbx->first_tlv = mbx->req_virt->first_tlv;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t   \"VF[%02x]: Processing mailbox message [type %04x]\\n\",\n\t\t   p_vf->abs_vf_id, mbx->first_tlv.tl.type);\n\n\t \n\tif (qed_iov_tlv_supported(mbx->first_tlv.tl.type) &&\n\t    !p_vf->b_malicious) {\n\t\tswitch (mbx->first_tlv.tl.type) {\n\t\tcase CHANNEL_TLV_ACQUIRE:\n\t\t\tqed_iov_vf_mbx_acquire(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_VPORT_START:\n\t\t\tqed_iov_vf_mbx_start_vport(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_VPORT_TEARDOWN:\n\t\t\tqed_iov_vf_mbx_stop_vport(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_START_RXQ:\n\t\t\tqed_iov_vf_mbx_start_rxq(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_START_TXQ:\n\t\t\tqed_iov_vf_mbx_start_txq(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_STOP_RXQS:\n\t\t\tqed_iov_vf_mbx_stop_rxqs(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_STOP_TXQS:\n\t\t\tqed_iov_vf_mbx_stop_txqs(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_UPDATE_RXQ:\n\t\t\tqed_iov_vf_mbx_update_rxqs(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_VPORT_UPDATE:\n\t\t\tqed_iov_vf_mbx_vport_update(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_UCAST_FILTER:\n\t\t\tqed_iov_vf_mbx_ucast_filter(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_CLOSE:\n\t\t\tqed_iov_vf_mbx_close(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_INT_CLEANUP:\n\t\t\tqed_iov_vf_mbx_int_cleanup(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_RELEASE:\n\t\t\tqed_iov_vf_mbx_release(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_UPDATE_TUNN_PARAM:\n\t\t\tqed_iov_vf_mbx_update_tunn_param(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_COALESCE_UPDATE:\n\t\t\tqed_iov_vf_pf_set_coalesce(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_COALESCE_READ:\n\t\t\tqed_iov_vf_pf_get_coalesce(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\tcase CHANNEL_TLV_BULLETIN_UPDATE_MAC:\n\t\t\tqed_iov_vf_pf_bulletin_update_mac(p_hwfn, p_ptt, p_vf);\n\t\t\tbreak;\n\t\t}\n\t} else if (qed_iov_tlv_supported(mbx->first_tlv.tl.type)) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"VF [%02x] - considered malicious; Ignoring TLV [%04x]\\n\",\n\t\t\t   p_vf->abs_vf_id, mbx->first_tlv.tl.type);\n\n\t\tqed_iov_prepare_resp(p_hwfn, p_ptt, p_vf,\n\t\t\t\t     mbx->first_tlv.tl.type,\n\t\t\t\t     sizeof(struct pfvf_def_resp_tlv),\n\t\t\t\t     PFVF_STATUS_MALICIOUS);\n\t} else {\n\t\t \n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"VF[%02x]: unknown TLV. type %04x length %04x padding %08x reply address %llu\\n\",\n\t\t\t  p_vf->abs_vf_id,\n\t\t\t  mbx->first_tlv.tl.type,\n\t\t\t  mbx->first_tlv.tl.length,\n\t\t\t  mbx->first_tlv.padding, mbx->first_tlv.reply_address);\n\n\t\t \n\t\tif (p_vf->acquire.first_tlv.reply_address &&\n\t\t    (mbx->first_tlv.reply_address ==\n\t\t     p_vf->acquire.first_tlv.reply_address)) {\n\t\t\tqed_iov_prepare_resp(p_hwfn, p_ptt, p_vf,\n\t\t\t\t\t     mbx->first_tlv.tl.type,\n\t\t\t\t\t     sizeof(struct pfvf_def_resp_tlv),\n\t\t\t\t\t     PFVF_STATUS_NOT_SUPPORTED);\n\t\t} else {\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"VF[%02x]: Can't respond to TLV - no valid reply address\\n\",\n\t\t\t\t   p_vf->abs_vf_id);\n\t\t}\n\t}\n}\n\nstatic void qed_iov_pf_get_pending_events(struct qed_hwfn *p_hwfn, u64 *events)\n{\n\tint i;\n\n\tmemset(events, 0, sizeof(u64) * QED_VF_ARRAY_LENGTH);\n\n\tqed_for_each_vf(p_hwfn, i) {\n\t\tstruct qed_vf_info *p_vf;\n\n\t\tp_vf = &p_hwfn->pf_iov_info->vfs_array[i];\n\t\tif (p_vf->vf_mbx.b_pending_msg)\n\t\t\tevents[i / 64] |= 1ULL << (i % 64);\n\t}\n}\n\nstatic struct qed_vf_info *qed_sriov_get_vf_from_absid(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t\t       u16 abs_vfid)\n{\n\tu8 min = (u8)p_hwfn->cdev->p_iov_info->first_vf_in_pf;\n\n\tif (!_qed_iov_pf_sanity_check(p_hwfn, (int)abs_vfid - min, false)) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"Got indication for VF [abs 0x%08x] that cannot be handled by PF\\n\",\n\t\t\t   abs_vfid);\n\t\treturn NULL;\n\t}\n\n\treturn &p_hwfn->pf_iov_info->vfs_array[(u8)abs_vfid - min];\n}\n\nstatic int qed_sriov_vfpf_msg(struct qed_hwfn *p_hwfn,\n\t\t\t      u16 abs_vfid, struct regpair *vf_msg)\n{\n\tstruct qed_vf_info *p_vf = qed_sriov_get_vf_from_absid(p_hwfn,\n\t\t\t   abs_vfid);\n\n\tif (!p_vf)\n\t\treturn 0;\n\n\t \n\tp_vf->vf_mbx.pending_req = HILO_64(vf_msg->hi, vf_msg->lo);\n\n\t \n\tp_vf->vf_mbx.b_pending_msg = true;\n\tqed_schedule_iov(p_hwfn, QED_IOV_WQ_MSG_FLAG);\n\n\treturn 0;\n}\n\nvoid qed_sriov_vfpf_malicious(struct qed_hwfn *p_hwfn,\n\t\t\t      struct fw_err_data *p_data)\n{\n\tstruct qed_vf_info *p_vf;\n\n\tp_vf = qed_sriov_get_vf_from_absid(p_hwfn, qed_vf_from_entity_id\n\t\t\t\t\t   (p_data->entity_id));\n\tif (!p_vf)\n\t\treturn;\n\n\tif (!p_vf->b_malicious) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"VF [%d] - Malicious behavior [%02x]\\n\",\n\t\t\t  p_vf->abs_vf_id, p_data->err_id);\n\n\t\tp_vf->b_malicious = true;\n\t} else {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"VF [%d] - Malicious behavior [%02x]\\n\",\n\t\t\tp_vf->abs_vf_id, p_data->err_id);\n\t}\n}\n\nint qed_sriov_eqe_event(struct qed_hwfn *p_hwfn, u8 opcode, __le16 echo,\n\t\t\tunion event_ring_data *data, u8 fw_return_code)\n{\n\tswitch (opcode) {\n\tcase COMMON_EVENT_VF_PF_CHANNEL:\n\t\treturn qed_sriov_vfpf_msg(p_hwfn, le16_to_cpu(echo),\n\t\t\t\t\t  &data->vf_pf_channel.msg_addr);\n\tdefault:\n\t\tDP_INFO(p_hwfn->cdev, \"Unknown sriov eqe event 0x%02x\\n\",\n\t\t\topcode);\n\t\treturn -EINVAL;\n\t}\n}\n\nu16 qed_iov_get_next_active_vf(struct qed_hwfn *p_hwfn, u16 rel_vf_id)\n{\n\tstruct qed_hw_sriov_info *p_iov = p_hwfn->cdev->p_iov_info;\n\tu16 i;\n\n\tif (!p_iov)\n\t\tgoto out;\n\n\tfor (i = rel_vf_id; i < p_iov->total_vfs; i++)\n\t\tif (qed_iov_is_valid_vfid(p_hwfn, rel_vf_id, true, false))\n\t\t\treturn i;\n\nout:\n\treturn MAX_NUM_VFS;\n}\n\nstatic int qed_iov_copy_vf_msg(struct qed_hwfn *p_hwfn, struct qed_ptt *ptt,\n\t\t\t       int vfid)\n{\n\tstruct qed_dmae_params params;\n\tstruct qed_vf_info *vf_info;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf_info)\n\t\treturn -EINVAL;\n\n\tmemset(&params, 0, sizeof(params));\n\tSET_FIELD(params.flags, QED_DMAE_PARAMS_SRC_VF_VALID, 0x1);\n\tSET_FIELD(params.flags, QED_DMAE_PARAMS_COMPLETION_DST, 0x1);\n\tparams.src_vfid = vf_info->abs_vf_id;\n\n\tif (qed_dmae_host2host(p_hwfn, ptt,\n\t\t\t       vf_info->vf_mbx.pending_req,\n\t\t\t       vf_info->vf_mbx.req_phys,\n\t\t\t       sizeof(union vfpf_tlvs) / 4, &params)) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Failed to copy message from VF 0x%02x\\n\", vfid);\n\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_iov_bulletin_set_forced_mac(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t    u8 *mac, int vfid)\n{\n\tstruct qed_vf_info *vf_info;\n\tu64 feature;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf_info) {\n\t\tDP_NOTICE(p_hwfn->cdev,\n\t\t\t  \"Can not set forced MAC, invalid vfid [%d]\\n\", vfid);\n\t\treturn;\n\t}\n\n\tif (vf_info->b_malicious) {\n\t\tDP_NOTICE(p_hwfn->cdev,\n\t\t\t  \"Can't set forced MAC to malicious VF [%d]\\n\", vfid);\n\t\treturn;\n\t}\n\n\tif (vf_info->p_vf_info.is_trusted_configured) {\n\t\tfeature = BIT(VFPF_BULLETIN_MAC_ADDR);\n\t\t \n\t\tvf_info->bulletin.p_virt->valid_bitmap &=\n\t\t\t~BIT(MAC_ADDR_FORCED);\n\t} else {\n\t\tfeature = BIT(MAC_ADDR_FORCED);\n\t\t \n\t\tvf_info->bulletin.p_virt->valid_bitmap &=\n\t\t\t~BIT(VFPF_BULLETIN_MAC_ADDR);\n\t}\n\n\tmemcpy(vf_info->bulletin.p_virt->mac, mac, ETH_ALEN);\n\n\tvf_info->bulletin.p_virt->valid_bitmap |= feature;\n\n\tqed_iov_configure_vport_forced(p_hwfn, vf_info, feature);\n}\n\nstatic int qed_iov_bulletin_set_mac(struct qed_hwfn *p_hwfn, u8 *mac, int vfid)\n{\n\tstruct qed_vf_info *vf_info;\n\tu64 feature;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf_info) {\n\t\tDP_NOTICE(p_hwfn->cdev, \"Can not set MAC, invalid vfid [%d]\\n\",\n\t\t\t  vfid);\n\t\treturn -EINVAL;\n\t}\n\n\tif (vf_info->b_malicious) {\n\t\tDP_NOTICE(p_hwfn->cdev, \"Can't set MAC to malicious VF [%d]\\n\",\n\t\t\t  vfid);\n\t\treturn -EINVAL;\n\t}\n\n\tif (vf_info->bulletin.p_virt->valid_bitmap & BIT(MAC_ADDR_FORCED)) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Can not set MAC, Forced MAC is configured\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tfeature = BIT(VFPF_BULLETIN_MAC_ADDR);\n\tether_addr_copy(vf_info->bulletin.p_virt->mac, mac);\n\n\tvf_info->bulletin.p_virt->valid_bitmap |= feature;\n\n\tif (vf_info->p_vf_info.is_trusted_configured)\n\t\tqed_iov_configure_vport_forced(p_hwfn, vf_info, feature);\n\n\treturn 0;\n}\n\nstatic void qed_iov_bulletin_set_forced_vlan(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t     u16 pvid, int vfid)\n{\n\tstruct qed_vf_info *vf_info;\n\tu64 feature;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf_info) {\n\t\tDP_NOTICE(p_hwfn->cdev,\n\t\t\t  \"Can not set forced MAC, invalid vfid [%d]\\n\", vfid);\n\t\treturn;\n\t}\n\n\tif (vf_info->b_malicious) {\n\t\tDP_NOTICE(p_hwfn->cdev,\n\t\t\t  \"Can't set forced vlan to malicious VF [%d]\\n\", vfid);\n\t\treturn;\n\t}\n\n\tfeature = 1 << VLAN_ADDR_FORCED;\n\tvf_info->bulletin.p_virt->pvid = pvid;\n\tif (pvid)\n\t\tvf_info->bulletin.p_virt->valid_bitmap |= feature;\n\telse\n\t\tvf_info->bulletin.p_virt->valid_bitmap &= ~feature;\n\n\tqed_iov_configure_vport_forced(p_hwfn, vf_info, feature);\n}\n\nvoid qed_iov_bulletin_set_udp_ports(struct qed_hwfn *p_hwfn,\n\t\t\t\t    int vfid, u16 vxlan_port, u16 geneve_port)\n{\n\tstruct qed_vf_info *vf_info;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf_info) {\n\t\tDP_NOTICE(p_hwfn->cdev,\n\t\t\t  \"Can not set udp ports, invalid vfid [%d]\\n\", vfid);\n\t\treturn;\n\t}\n\n\tif (vf_info->b_malicious) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Can not set udp ports to malicious VF [%d]\\n\",\n\t\t\t   vfid);\n\t\treturn;\n\t}\n\n\tvf_info->bulletin.p_virt->vxlan_udp_port = vxlan_port;\n\tvf_info->bulletin.p_virt->geneve_udp_port = geneve_port;\n}\n\nstatic bool qed_iov_vf_has_vport_instance(struct qed_hwfn *p_hwfn, int vfid)\n{\n\tstruct qed_vf_info *p_vf_info;\n\n\tp_vf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!p_vf_info)\n\t\treturn false;\n\n\treturn !!p_vf_info->vport_instance;\n}\n\nstatic bool qed_iov_is_vf_stopped(struct qed_hwfn *p_hwfn, int vfid)\n{\n\tstruct qed_vf_info *p_vf_info;\n\n\tp_vf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!p_vf_info)\n\t\treturn true;\n\n\treturn p_vf_info->state == VF_STOPPED;\n}\n\nstatic bool qed_iov_spoofchk_get(struct qed_hwfn *p_hwfn, int vfid)\n{\n\tstruct qed_vf_info *vf_info;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf_info)\n\t\treturn false;\n\n\treturn vf_info->spoof_chk;\n}\n\nstatic int qed_iov_spoofchk_set(struct qed_hwfn *p_hwfn, int vfid, bool val)\n{\n\tstruct qed_vf_info *vf;\n\tint rc = -EINVAL;\n\n\tif (!qed_iov_pf_sanity_check(p_hwfn, vfid)) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"SR-IOV sanity check failed, can't set spoofchk\\n\");\n\t\tgoto out;\n\t}\n\n\tvf = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf)\n\t\tgoto out;\n\n\tif (!qed_iov_vf_has_vport_instance(p_hwfn, vfid)) {\n\t\t \n\t\tvf->req_spoofchk_val = val;\n\t\trc = 0;\n\t\tgoto out;\n\t}\n\n\trc = __qed_iov_spoofchk_set(p_hwfn, vf, val);\n\nout:\n\treturn rc;\n}\n\nstatic u8 *qed_iov_bulletin_get_mac(struct qed_hwfn *p_hwfn, u16 rel_vf_id)\n{\n\tstruct qed_vf_info *p_vf;\n\n\tp_vf = qed_iov_get_vf_info(p_hwfn, rel_vf_id, true);\n\tif (!p_vf || !p_vf->bulletin.p_virt)\n\t\treturn NULL;\n\n\tif (!(p_vf->bulletin.p_virt->valid_bitmap &\n\t      BIT(VFPF_BULLETIN_MAC_ADDR)))\n\t\treturn NULL;\n\n\treturn p_vf->bulletin.p_virt->mac;\n}\n\nstatic u8 *qed_iov_bulletin_get_forced_mac(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t   u16 rel_vf_id)\n{\n\tstruct qed_vf_info *p_vf;\n\n\tp_vf = qed_iov_get_vf_info(p_hwfn, rel_vf_id, true);\n\tif (!p_vf || !p_vf->bulletin.p_virt)\n\t\treturn NULL;\n\n\tif (!(p_vf->bulletin.p_virt->valid_bitmap & BIT(MAC_ADDR_FORCED)))\n\t\treturn NULL;\n\n\treturn p_vf->bulletin.p_virt->mac;\n}\n\nstatic u16\nqed_iov_bulletin_get_forced_vlan(struct qed_hwfn *p_hwfn, u16 rel_vf_id)\n{\n\tstruct qed_vf_info *p_vf;\n\n\tp_vf = qed_iov_get_vf_info(p_hwfn, rel_vf_id, true);\n\tif (!p_vf || !p_vf->bulletin.p_virt)\n\t\treturn 0;\n\n\tif (!(p_vf->bulletin.p_virt->valid_bitmap & BIT(VLAN_ADDR_FORCED)))\n\t\treturn 0;\n\n\treturn p_vf->bulletin.p_virt->pvid;\n}\n\nstatic int qed_iov_configure_tx_rate(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt, int vfid, int val)\n{\n\tstruct qed_vf_info *vf;\n\tu8 abs_vp_id = 0;\n\tu16 rl_id;\n\tint rc;\n\n\tvf = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf)\n\t\treturn -EINVAL;\n\n\trc = qed_fw_vport(p_hwfn, vf->vport_id, &abs_vp_id);\n\tif (rc)\n\t\treturn rc;\n\n\trl_id = abs_vp_id;\t \n\treturn qed_init_global_rl(p_hwfn, p_ptt, rl_id, (u32)val,\n\t\t\t\t  QM_RL_TYPE_NORMAL);\n}\n\nstatic int\nqed_iov_configure_min_tx_rate(struct qed_dev *cdev, int vfid, u32 rate)\n{\n\tstruct qed_vf_info *vf;\n\tu8 vport_id;\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tif (!qed_iov_pf_sanity_check(p_hwfn, vfid)) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"SR-IOV sanity check failed, can't set min rate\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tvf = qed_iov_get_vf_info(QED_LEADING_HWFN(cdev), (u16)vfid, true);\n\tif (!vf)\n\t\treturn -EINVAL;\n\n\tvport_id = vf->vport_id;\n\n\treturn qed_configure_vport_wfq(cdev, vport_id, rate);\n}\n\nstatic int qed_iov_get_vf_min_rate(struct qed_hwfn *p_hwfn, int vfid)\n{\n\tstruct qed_wfq_data *vf_vp_wfq;\n\tstruct qed_vf_info *vf_info;\n\n\tvf_info = qed_iov_get_vf_info(p_hwfn, (u16)vfid, true);\n\tif (!vf_info)\n\t\treturn 0;\n\n\tvf_vp_wfq = &p_hwfn->qm_info.wfq_data[vf_info->vport_id];\n\n\tif (vf_vp_wfq->configured)\n\t\treturn vf_vp_wfq->min_speed;\n\telse\n\t\treturn 0;\n}\n\n \nvoid qed_schedule_iov(struct qed_hwfn *hwfn, enum qed_iov_wq_flag flag)\n{\n\t \n\tsmp_mb__before_atomic();\n\tset_bit(flag, &hwfn->iov_task_flags);\n\t \n\tsmp_mb__after_atomic();\n\tDP_VERBOSE(hwfn, QED_MSG_IOV, \"Scheduling iov task [Flag: %d]\\n\", flag);\n\tqueue_delayed_work(hwfn->iov_wq, &hwfn->iov_task, 0);\n}\n\nvoid qed_vf_start_iov_wq(struct qed_dev *cdev)\n{\n\tint i;\n\n\tfor_each_hwfn(cdev, i)\n\t\tqueue_delayed_work(cdev->hwfns[i].iov_wq,\n\t\t\t\t   &cdev->hwfns[i].iov_task, 0);\n}\n\nint qed_sriov_disable(struct qed_dev *cdev, bool pci_enabled)\n{\n\tint i, j;\n\n\tfor_each_hwfn(cdev, i)\n\t\tif (cdev->hwfns[i].iov_wq)\n\t\t\tflush_workqueue(cdev->hwfns[i].iov_wq);\n\n\t \n\tqed_iov_set_vfs_to_disable(cdev, true);\n\n\tif (cdev->p_iov_info && cdev->p_iov_info->num_vfs && pci_enabled)\n\t\tpci_disable_sriov(cdev->pdev);\n\n\tif (cdev->recov_in_prog) {\n\t\tDP_VERBOSE(cdev,\n\t\t\t   QED_MSG_IOV,\n\t\t\t   \"Skip SRIOV disable operations in the device since a recovery is in progress\\n\");\n\t\tgoto out;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *hwfn = &cdev->hwfns[i];\n\t\tstruct qed_ptt *ptt = qed_ptt_acquire(hwfn);\n\n\t\t \n\t\tif (!ptt) {\n\t\t\tDP_ERR(hwfn, \"Failed to acquire ptt\\n\");\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\t \n\t\tqed_clean_wfq_db(hwfn, ptt);\n\n\t\tqed_for_each_vf(hwfn, j) {\n\t\t\tint k;\n\n\t\t\tif (!qed_iov_is_valid_vfid(hwfn, j, true, false))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tfor (k = 0; k < 100; k++) {\n\t\t\t\tif (!qed_iov_is_vf_stopped(hwfn, j))\n\t\t\t\t\tmsleep(20);\n\t\t\t\telse\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (k < 100)\n\t\t\t\tqed_iov_release_hw_for_vf(&cdev->hwfns[i],\n\t\t\t\t\t\t\t  ptt, j);\n\t\t\telse\n\t\t\t\tDP_ERR(hwfn,\n\t\t\t\t       \"Timeout waiting for VF's FLR to end\\n\");\n\t\t}\n\n\t\tqed_ptt_release(hwfn, ptt);\n\t}\nout:\n\tqed_iov_set_vfs_to_disable(cdev, false);\n\n\treturn 0;\n}\n\nstatic void qed_sriov_enable_qid_config(struct qed_hwfn *hwfn,\n\t\t\t\t\tu16 vfid,\n\t\t\t\t\tstruct qed_iov_vf_init_params *params)\n{\n\tu16 base, i;\n\n\t \n\tbase = FEAT_NUM(hwfn, QED_PF_L2_QUE) + vfid * params->num_queues;\n\n\tparams->rel_vf_id = vfid;\n\tfor (i = 0; i < params->num_queues; i++) {\n\t\tparams->req_rx_queue[i] = base + i;\n\t\tparams->req_tx_queue[i] = base + i;\n\t}\n}\n\nstatic int qed_sriov_enable(struct qed_dev *cdev, int num)\n{\n\tstruct qed_iov_vf_init_params params;\n\tstruct qed_hwfn *hwfn;\n\tstruct qed_ptt *ptt;\n\tint i, j, rc;\n\n\tif (num >= RESC_NUM(&cdev->hwfns[0], QED_VPORT)) {\n\t\tDP_NOTICE(cdev, \"Can start at most %d VFs\\n\",\n\t\t\t  RESC_NUM(&cdev->hwfns[0], QED_VPORT) - 1);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&params, 0, sizeof(params));\n\n\t \n\tfor_each_hwfn(cdev, j) {\n\t\thwfn = &cdev->hwfns[j];\n\t\tptt = qed_ptt_acquire(hwfn);\n\n\t\t \n\t\tparams.num_queues = min_t(int,\n\t\t\t\t\t  FEAT_NUM(hwfn, QED_VF_L2_QUE) / num,\n\t\t\t\t\t  16);\n\n\t\tif (!ptt) {\n\t\t\tDP_ERR(hwfn, \"Failed to acquire ptt\\n\");\n\t\t\trc = -EBUSY;\n\t\t\tgoto err;\n\t\t}\n\n\t\tfor (i = 0; i < num; i++) {\n\t\t\tif (!qed_iov_is_valid_vfid(hwfn, i, false, true))\n\t\t\t\tcontinue;\n\n\t\t\tqed_sriov_enable_qid_config(hwfn, i, &params);\n\t\t\trc = qed_iov_init_hw_for_vf(hwfn, ptt, &params);\n\t\t\tif (rc) {\n\t\t\t\tDP_ERR(cdev, \"Failed to enable VF[%d]\\n\", i);\n\t\t\t\tqed_ptt_release(hwfn, ptt);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\tqed_ptt_release(hwfn, ptt);\n\t}\n\n\t \n\trc = pci_enable_sriov(cdev->pdev, num);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed to enable sriov [%d]\\n\", rc);\n\t\tgoto err;\n\t}\n\n\thwfn = QED_LEADING_HWFN(cdev);\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt) {\n\t\tDP_ERR(hwfn, \"Failed to acquire ptt\\n\");\n\t\trc = -EBUSY;\n\t\tgoto err;\n\t}\n\n\trc = qed_mcp_ov_update_eswitch(hwfn, ptt, QED_OV_ESWITCH_VEB);\n\tif (rc)\n\t\tDP_INFO(cdev, \"Failed to update eswitch mode\\n\");\n\tqed_ptt_release(hwfn, ptt);\n\n\treturn num;\n\nerr:\n\tqed_sriov_disable(cdev, false);\n\treturn rc;\n}\n\nstatic int qed_sriov_configure(struct qed_dev *cdev, int num_vfs_param)\n{\n\tif (!IS_QED_SRIOV(cdev)) {\n\t\tDP_VERBOSE(cdev, QED_MSG_IOV, \"SR-IOV is not supported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (num_vfs_param)\n\t\treturn qed_sriov_enable(cdev, num_vfs_param);\n\telse\n\t\treturn qed_sriov_disable(cdev, true);\n}\n\nstatic int qed_sriov_pf_set_mac(struct qed_dev *cdev, u8 *mac, int vfid)\n{\n\tint i;\n\n\tif (!IS_QED_SRIOV(cdev) || !IS_PF_SRIOV_ALLOC(&cdev->hwfns[0])) {\n\t\tDP_VERBOSE(cdev, QED_MSG_IOV,\n\t\t\t   \"Cannot set a VF MAC; Sriov is not enabled\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!qed_iov_is_valid_vfid(&cdev->hwfns[0], vfid, true, true)) {\n\t\tDP_VERBOSE(cdev, QED_MSG_IOV,\n\t\t\t   \"Cannot set VF[%d] MAC (VF is not active)\\n\", vfid);\n\t\treturn -EINVAL;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *hwfn = &cdev->hwfns[i];\n\t\tstruct qed_public_vf_info *vf_info;\n\n\t\tvf_info = qed_iov_get_public_vf_info(hwfn, vfid, true);\n\t\tif (!vf_info)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (vf_info->is_trusted_configured)\n\t\t\tether_addr_copy(vf_info->mac, mac);\n\t\telse\n\t\t\tether_addr_copy(vf_info->forced_mac, mac);\n\n\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_SET_UNICAST_FILTER_FLAG);\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_sriov_pf_set_vlan(struct qed_dev *cdev, u16 vid, int vfid)\n{\n\tint i;\n\n\tif (!IS_QED_SRIOV(cdev) || !IS_PF_SRIOV_ALLOC(&cdev->hwfns[0])) {\n\t\tDP_VERBOSE(cdev, QED_MSG_IOV,\n\t\t\t   \"Cannot set a VF MAC; Sriov is not enabled\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!qed_iov_is_valid_vfid(&cdev->hwfns[0], vfid, true, true)) {\n\t\tDP_VERBOSE(cdev, QED_MSG_IOV,\n\t\t\t   \"Cannot set VF[%d] MAC (VF is not active)\\n\", vfid);\n\t\treturn -EINVAL;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *hwfn = &cdev->hwfns[i];\n\t\tstruct qed_public_vf_info *vf_info;\n\n\t\tvf_info = qed_iov_get_public_vf_info(hwfn, vfid, true);\n\t\tif (!vf_info)\n\t\t\tcontinue;\n\n\t\t \n\t\tvf_info->forced_vlan = vid;\n\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_SET_UNICAST_FILTER_FLAG);\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_get_vf_config(struct qed_dev *cdev,\n\t\t\t     int vf_id, struct ifla_vf_info *ivi)\n{\n\tstruct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_public_vf_info *vf_info;\n\tstruct qed_mcp_link_state link;\n\tu32 tx_rate;\n\tint ret;\n\n\t \n\tif (IS_VF(cdev))\n\t\treturn -EINVAL;\n\n\tif (!qed_iov_is_valid_vfid(&cdev->hwfns[0], vf_id, true, false)) {\n\t\tDP_VERBOSE(cdev, QED_MSG_IOV,\n\t\t\t   \"VF index [%d] isn't active\\n\", vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\tvf_info = qed_iov_get_public_vf_info(hwfn, vf_id, true);\n\n\tret = qed_iov_get_link(hwfn, vf_id, NULL, &link, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tivi->vf = vf_id;\n\n\tif (is_valid_ether_addr(vf_info->forced_mac))\n\t\tether_addr_copy(ivi->mac, vf_info->forced_mac);\n\telse\n\t\tether_addr_copy(ivi->mac, vf_info->mac);\n\n\tivi->vlan = vf_info->forced_vlan;\n\tivi->spoofchk = qed_iov_spoofchk_get(hwfn, vf_id);\n\tivi->linkstate = vf_info->link_state;\n\ttx_rate = vf_info->tx_rate;\n\tivi->max_tx_rate = tx_rate ? tx_rate : link.speed;\n\tivi->min_tx_rate = qed_iov_get_vf_min_rate(hwfn, vf_id);\n\tivi->trusted = vf_info->is_trusted_request;\n\n\treturn 0;\n}\n\nvoid qed_inform_vf_link_state(struct qed_hwfn *hwfn)\n{\n\tstruct qed_hwfn *lead_hwfn = QED_LEADING_HWFN(hwfn->cdev);\n\tstruct qed_mcp_link_capabilities caps;\n\tstruct qed_mcp_link_params params;\n\tstruct qed_mcp_link_state link;\n\tint i;\n\n\tif (!hwfn->pf_iov_info)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < hwfn->cdev->p_iov_info->total_vfs; i++) {\n\t\tstruct qed_public_vf_info *vf_info;\n\n\t\tvf_info = qed_iov_get_public_vf_info(hwfn, i, false);\n\t\tif (!vf_info)\n\t\t\tcontinue;\n\n\t\t \n\t\tmemcpy(&params, qed_mcp_get_link_params(lead_hwfn),\n\t\t       sizeof(params));\n\t\tmemcpy(&link, qed_mcp_get_link_state(lead_hwfn), sizeof(link));\n\t\tmemcpy(&caps, qed_mcp_get_link_capabilities(lead_hwfn),\n\t\t       sizeof(caps));\n\n\t\t \n\t\tswitch (vf_info->link_state) {\n\t\tcase IFLA_VF_LINK_STATE_DISABLE:\n\t\t\tlink.link_up = false;\n\t\t\tbreak;\n\t\tcase IFLA_VF_LINK_STATE_ENABLE:\n\t\t\tlink.link_up = true;\n\t\t\t \n\t\t\tlink.speed = (hwfn->cdev->num_hwfns > 1) ?\n\t\t\t\t     100000 : 40000;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\n\t\tif (link.link_up && vf_info->tx_rate) {\n\t\t\tstruct qed_ptt *ptt;\n\t\t\tint rate;\n\n\t\t\trate = min_t(int, vf_info->tx_rate, link.speed);\n\n\t\t\tptt = qed_ptt_acquire(hwfn);\n\t\t\tif (!ptt) {\n\t\t\t\tDP_NOTICE(hwfn, \"Failed to acquire PTT\\n\");\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (!qed_iov_configure_tx_rate(hwfn, ptt, i, rate)) {\n\t\t\t\tvf_info->tx_rate = rate;\n\t\t\t\tlink.speed = rate;\n\t\t\t}\n\n\t\t\tqed_ptt_release(hwfn, ptt);\n\t\t}\n\n\t\tqed_iov_set_link(hwfn, i, &params, &link, &caps);\n\t}\n\n\tqed_schedule_iov(hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n}\n\nstatic int qed_set_vf_link_state(struct qed_dev *cdev,\n\t\t\t\t int vf_id, int link_state)\n{\n\tint i;\n\n\t \n\tif (IS_VF(cdev))\n\t\treturn -EINVAL;\n\n\tif (!qed_iov_is_valid_vfid(&cdev->hwfns[0], vf_id, true, true)) {\n\t\tDP_VERBOSE(cdev, QED_MSG_IOV,\n\t\t\t   \"VF index [%d] isn't active\\n\", vf_id);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *hwfn = &cdev->hwfns[i];\n\t\tstruct qed_public_vf_info *vf;\n\n\t\tvf = qed_iov_get_public_vf_info(hwfn, vf_id, true);\n\t\tif (!vf)\n\t\t\tcontinue;\n\n\t\tif (vf->link_state == link_state)\n\t\t\tcontinue;\n\n\t\tvf->link_state = link_state;\n\t\tqed_inform_vf_link_state(&cdev->hwfns[i]);\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_spoof_configure(struct qed_dev *cdev, int vfid, bool val)\n{\n\tint i, rc = -EINVAL;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\trc = qed_iov_spoofchk_set(p_hwfn, vfid, val);\n\t\tif (rc)\n\t\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\nstatic int qed_configure_max_vf_rate(struct qed_dev *cdev, int vfid, int rate)\n{\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tstruct qed_public_vf_info *vf;\n\n\t\tif (!qed_iov_pf_sanity_check(p_hwfn, vfid)) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"SR-IOV sanity check failed, can't set tx rate\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvf = qed_iov_get_public_vf_info(p_hwfn, vfid, true);\n\n\t\tvf->tx_rate = rate;\n\n\t\tqed_inform_vf_link_state(p_hwfn);\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_set_vf_rate(struct qed_dev *cdev,\n\t\t\t   int vfid, u32 min_rate, u32 max_rate)\n{\n\tint rc_min = 0, rc_max = 0;\n\n\tif (max_rate)\n\t\trc_max = qed_configure_max_vf_rate(cdev, vfid, max_rate);\n\n\tif (min_rate)\n\t\trc_min = qed_iov_configure_min_tx_rate(cdev, vfid, min_rate);\n\n\tif (rc_max | rc_min)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int qed_set_vf_trust(struct qed_dev *cdev, int vfid, bool trust)\n{\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *hwfn = &cdev->hwfns[i];\n\t\tstruct qed_public_vf_info *vf;\n\n\t\tif (!qed_iov_pf_sanity_check(hwfn, vfid)) {\n\t\t\tDP_NOTICE(hwfn,\n\t\t\t\t  \"SR-IOV sanity check failed, can't set trust\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvf = qed_iov_get_public_vf_info(hwfn, vfid, true);\n\n\t\tif (vf->is_trusted_request == trust)\n\t\t\treturn 0;\n\t\tvf->is_trusted_request = trust;\n\n\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_TRUST_FLAG);\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_handle_vf_msg(struct qed_hwfn *hwfn)\n{\n\tu64 events[QED_VF_ARRAY_LENGTH];\n\tstruct qed_ptt *ptt;\n\tint i;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt) {\n\t\tDP_VERBOSE(hwfn, QED_MSG_IOV,\n\t\t\t   \"Can't acquire PTT; re-scheduling\\n\");\n\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_MSG_FLAG);\n\t\treturn;\n\t}\n\n\tqed_iov_pf_get_pending_events(hwfn, events);\n\n\tDP_VERBOSE(hwfn, QED_MSG_IOV,\n\t\t   \"Event mask of VF events: 0x%llx 0x%llx 0x%llx\\n\",\n\t\t   events[0], events[1], events[2]);\n\n\tqed_for_each_vf(hwfn, i) {\n\t\t \n\t\tif (!(events[i / 64] & (1ULL << (i % 64))))\n\t\t\tcontinue;\n\n\t\tDP_VERBOSE(hwfn, QED_MSG_IOV,\n\t\t\t   \"Handling VF message from VF 0x%02x [Abs 0x%02x]\\n\",\n\t\t\t   i, hwfn->cdev->p_iov_info->first_vf_in_pf + i);\n\n\t\t \n\t\tif (qed_iov_copy_vf_msg(hwfn, ptt, i))\n\t\t\tcontinue;\n\n\t\tqed_iov_process_mbx_req(hwfn, ptt, i);\n\t}\n\n\tqed_ptt_release(hwfn, ptt);\n}\n\nstatic bool qed_pf_validate_req_vf_mac(struct qed_hwfn *hwfn,\n\t\t\t\t       u8 *mac,\n\t\t\t\t       struct qed_public_vf_info *info)\n{\n\tif (info->is_trusted_configured) {\n\t\tif (is_valid_ether_addr(info->mac) &&\n\t\t    (!mac || !ether_addr_equal(mac, info->mac)))\n\t\t\treturn true;\n\t} else {\n\t\tif (is_valid_ether_addr(info->forced_mac) &&\n\t\t    (!mac || !ether_addr_equal(mac, info->forced_mac)))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void qed_set_bulletin_mac(struct qed_hwfn *hwfn,\n\t\t\t\t struct qed_public_vf_info *info,\n\t\t\t\t int vfid)\n{\n\tif (info->is_trusted_configured)\n\t\tqed_iov_bulletin_set_mac(hwfn, info->mac, vfid);\n\telse\n\t\tqed_iov_bulletin_set_forced_mac(hwfn, info->forced_mac, vfid);\n}\n\nstatic void qed_handle_pf_set_vf_unicast(struct qed_hwfn *hwfn)\n{\n\tint i;\n\n\tqed_for_each_vf(hwfn, i) {\n\t\tstruct qed_public_vf_info *info;\n\t\tbool update = false;\n\t\tu8 *mac;\n\n\t\tinfo = qed_iov_get_public_vf_info(hwfn, i, true);\n\t\tif (!info)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (info->is_trusted_configured)\n\t\t\tmac = qed_iov_bulletin_get_mac(hwfn, i);\n\t\telse\n\t\t\tmac = qed_iov_bulletin_get_forced_mac(hwfn, i);\n\n\t\tif (qed_pf_validate_req_vf_mac(hwfn, mac, info)) {\n\t\t\tDP_VERBOSE(hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"Handling PF setting of VF MAC to VF 0x%02x [Abs 0x%02x]\\n\",\n\t\t\t\t   i,\n\t\t\t\t   hwfn->cdev->p_iov_info->first_vf_in_pf + i);\n\n\t\t\t \n\t\t\tqed_set_bulletin_mac(hwfn, info, i);\n\t\t\tupdate = true;\n\t\t}\n\n\t\tif (qed_iov_bulletin_get_forced_vlan(hwfn, i) ^\n\t\t    info->forced_vlan) {\n\t\t\tDP_VERBOSE(hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"Handling PF setting of pvid [0x%04x] to VF 0x%02x [Abs 0x%02x]\\n\",\n\t\t\t\t   info->forced_vlan,\n\t\t\t\t   i,\n\t\t\t\t   hwfn->cdev->p_iov_info->first_vf_in_pf + i);\n\t\t\tqed_iov_bulletin_set_forced_vlan(hwfn,\n\t\t\t\t\t\t\t info->forced_vlan, i);\n\t\t\tupdate = true;\n\t\t}\n\n\t\tif (update)\n\t\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n\t}\n}\n\nstatic void qed_handle_bulletin_post(struct qed_hwfn *hwfn)\n{\n\tstruct qed_ptt *ptt;\n\tint i;\n\n\tptt = qed_ptt_acquire(hwfn);\n\tif (!ptt) {\n\t\tDP_NOTICE(hwfn, \"Failed allocating a ptt entry\\n\");\n\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n\t\treturn;\n\t}\n\n\tqed_for_each_vf(hwfn, i)\n\t\tqed_iov_post_vf_bulletin(hwfn, i, ptt);\n\n\tqed_ptt_release(hwfn, ptt);\n}\n\nstatic void qed_update_mac_for_vf_trust_change(struct qed_hwfn *hwfn, int vf_id)\n{\n\tstruct qed_public_vf_info *vf_info;\n\tstruct qed_vf_info *vf;\n\tu8 *force_mac;\n\tint i;\n\n\tvf_info = qed_iov_get_public_vf_info(hwfn, vf_id, true);\n\tvf = qed_iov_get_vf_info(hwfn, vf_id, true);\n\n\tif (!vf_info || !vf)\n\t\treturn;\n\n\t \n\tif (vf_info->is_trusted_configured &&\n\t    (vf->bulletin.p_virt->valid_bitmap & BIT(MAC_ADDR_FORCED))) {\n\t\tforce_mac = qed_iov_bulletin_get_forced_mac(hwfn, vf_id);\n\n\t\tif (force_mac) {\n\t\t\t \n\t\t\tfor (i = 0; i < QED_ETH_VF_NUM_MAC_FILTERS; i++) {\n\t\t\t\tif (ether_addr_equal(vf->shadow_config.macs[i],\n\t\t\t\t\t\t     vf_info->mac)) {\n\t\t\t\t\teth_zero_addr(vf->shadow_config.macs[i]);\n\t\t\t\t\tDP_VERBOSE(hwfn, QED_MSG_IOV,\n\t\t\t\t\t\t   \"Shadow MAC %pM removed for VF 0x%02x, VF trust mode is ON\\n\",\n\t\t\t\t\t\t    vf_info->mac, vf_id);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tether_addr_copy(vf_info->mac, force_mac);\n\t\t\teth_zero_addr(vf_info->forced_mac);\n\t\t\tvf->bulletin.p_virt->valid_bitmap &=\n\t\t\t\t\t~BIT(MAC_ADDR_FORCED);\n\t\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n\t\t}\n\t}\n\n\t \n\tif (!vf_info->is_trusted_configured) {\n\t\tu8 empty_mac[ETH_ALEN];\n\n\t\teth_zero_addr(empty_mac);\n\t\tfor (i = 0; i < QED_ETH_VF_NUM_MAC_FILTERS; i++) {\n\t\t\tif (ether_addr_equal(vf->shadow_config.macs[i],\n\t\t\t\t\t     empty_mac)) {\n\t\t\t\tether_addr_copy(vf->shadow_config.macs[i],\n\t\t\t\t\t\tvf_info->mac);\n\t\t\t\tDP_VERBOSE(hwfn, QED_MSG_IOV,\n\t\t\t\t\t   \"Shadow is updated with %pM for VF 0x%02x, VF trust mode is OFF\\n\",\n\t\t\t\t\t    vf_info->mac, vf_id);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t \n\t\tqed_iov_bulletin_set_mac(hwfn, empty_mac, vf_id);\n\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n\t}\n}\n\nstatic void qed_iov_handle_trust_change(struct qed_hwfn *hwfn)\n{\n\tstruct qed_sp_vport_update_params params;\n\tstruct qed_filter_accept_flags *flags;\n\tstruct qed_public_vf_info *vf_info;\n\tstruct qed_vf_info *vf;\n\tu8 mask;\n\tint i;\n\n\tmask = QED_ACCEPT_UCAST_UNMATCHED | QED_ACCEPT_MCAST_UNMATCHED;\n\tflags = &params.accept_flags;\n\n\tqed_for_each_vf(hwfn, i) {\n\t\t \n\t\tvf_info = qed_iov_get_public_vf_info(hwfn, i, true);\n\t\tif (vf_info->is_trusted_configured ==\n\t\t    vf_info->is_trusted_request)\n\t\t\tcontinue;\n\t\tvf_info->is_trusted_configured = vf_info->is_trusted_request;\n\n\t\t \n\t\tqed_update_mac_for_vf_trust_change(hwfn, i);\n\n\t\t \n\t\tvf = qed_iov_get_vf_info(hwfn, i, true);\n\t\tif (!vf || !vf->vport_instance)\n\t\t\tcontinue;\n\n\t\tmemset(&params, 0, sizeof(params));\n\t\tparams.opaque_fid = vf->opaque_fid;\n\t\tparams.vport_id = vf->vport_id;\n\n\t\tparams.update_ctl_frame_check = 1;\n\t\tparams.mac_chk_en = !vf_info->is_trusted_configured;\n\t\tparams.update_accept_any_vlan_flg = 0;\n\n\t\tif (vf_info->accept_any_vlan && vf_info->forced_vlan) {\n\t\t\tparams.update_accept_any_vlan_flg = 1;\n\t\t\tparams.accept_any_vlan = vf_info->accept_any_vlan;\n\t\t}\n\n\t\tif (vf_info->rx_accept_mode & mask) {\n\t\t\tflags->update_rx_mode_config = 1;\n\t\t\tflags->rx_accept_filter = vf_info->rx_accept_mode;\n\t\t}\n\n\t\tif (vf_info->tx_accept_mode & mask) {\n\t\t\tflags->update_tx_mode_config = 1;\n\t\t\tflags->tx_accept_filter = vf_info->tx_accept_mode;\n\t\t}\n\n\t\t \n\t\tif (!vf_info->is_trusted_configured) {\n\t\t\tflags->rx_accept_filter &= ~mask;\n\t\t\tflags->tx_accept_filter &= ~mask;\n\t\t\tparams.accept_any_vlan = false;\n\t\t}\n\n\t\tif (flags->update_rx_mode_config ||\n\t\t    flags->update_tx_mode_config ||\n\t\t    params.update_ctl_frame_check ||\n\t\t    params.update_accept_any_vlan_flg) {\n\t\t\tDP_VERBOSE(hwfn, QED_MSG_IOV,\n\t\t\t\t   \"vport update config for %s VF[abs 0x%x rel 0x%x]\\n\",\n\t\t\t\t   vf_info->is_trusted_configured ? \"trusted\" : \"untrusted\",\n\t\t\t\t   vf->abs_vf_id, vf->relative_vf_id);\n\t\t\tqed_sp_vport_update(hwfn, &params,\n\t\t\t\t\t    QED_SPQ_MODE_EBLOCK, NULL);\n\t\t}\n\t}\n}\n\nstatic void qed_iov_pf_task(struct work_struct *work)\n\n{\n\tstruct qed_hwfn *hwfn = container_of(work, struct qed_hwfn,\n\t\t\t\t\t     iov_task.work);\n\tint rc;\n\n\tif (test_and_clear_bit(QED_IOV_WQ_STOP_WQ_FLAG, &hwfn->iov_task_flags))\n\t\treturn;\n\n\tif (test_and_clear_bit(QED_IOV_WQ_FLR_FLAG, &hwfn->iov_task_flags)) {\n\t\tstruct qed_ptt *ptt = qed_ptt_acquire(hwfn);\n\n\t\tif (!ptt) {\n\t\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_FLR_FLAG);\n\t\t\treturn;\n\t\t}\n\n\t\trc = qed_iov_vf_flr_cleanup(hwfn, ptt);\n\t\tif (rc)\n\t\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_FLR_FLAG);\n\n\t\tqed_ptt_release(hwfn, ptt);\n\t}\n\n\tif (test_and_clear_bit(QED_IOV_WQ_MSG_FLAG, &hwfn->iov_task_flags))\n\t\tqed_handle_vf_msg(hwfn);\n\n\tif (test_and_clear_bit(QED_IOV_WQ_SET_UNICAST_FILTER_FLAG,\n\t\t\t       &hwfn->iov_task_flags))\n\t\tqed_handle_pf_set_vf_unicast(hwfn);\n\n\tif (test_and_clear_bit(QED_IOV_WQ_BULLETIN_UPDATE_FLAG,\n\t\t\t       &hwfn->iov_task_flags))\n\t\tqed_handle_bulletin_post(hwfn);\n\n\tif (test_and_clear_bit(QED_IOV_WQ_TRUST_FLAG, &hwfn->iov_task_flags))\n\t\tqed_iov_handle_trust_change(hwfn);\n}\n\nvoid qed_iov_wq_stop(struct qed_dev *cdev, bool schedule_first)\n{\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tif (!cdev->hwfns[i].iov_wq)\n\t\t\tcontinue;\n\n\t\tif (schedule_first) {\n\t\t\tqed_schedule_iov(&cdev->hwfns[i],\n\t\t\t\t\t QED_IOV_WQ_STOP_WQ_FLAG);\n\t\t\tcancel_delayed_work_sync(&cdev->hwfns[i].iov_task);\n\t\t}\n\n\t\tdestroy_workqueue(cdev->hwfns[i].iov_wq);\n\t}\n}\n\nint qed_iov_wq_start(struct qed_dev *cdev)\n{\n\tchar name[NAME_SIZE];\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\t \n\t\tif (IS_PF(p_hwfn->cdev) && !IS_PF_SRIOV(p_hwfn))\n\t\t\tcontinue;\n\n\t\tsnprintf(name, NAME_SIZE, \"iov-%02x:%02x.%02x\",\n\t\t\t cdev->pdev->bus->number,\n\t\t\t PCI_SLOT(cdev->pdev->devfn), p_hwfn->abs_pf_id);\n\n\t\tp_hwfn->iov_wq = create_singlethread_workqueue(name);\n\t\tif (!p_hwfn->iov_wq) {\n\t\t\tDP_NOTICE(p_hwfn, \"Cannot create iov workqueue\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (IS_PF(cdev))\n\t\t\tINIT_DELAYED_WORK(&p_hwfn->iov_task, qed_iov_pf_task);\n\t\telse\n\t\t\tINIT_DELAYED_WORK(&p_hwfn->iov_task, qed_iov_vf_task);\n\t}\n\n\treturn 0;\n}\n\nconst struct qed_iov_hv_ops qed_iov_ops_pass = {\n\t.configure = &qed_sriov_configure,\n\t.set_mac = &qed_sriov_pf_set_mac,\n\t.set_vlan = &qed_sriov_pf_set_vlan,\n\t.get_config = &qed_get_vf_config,\n\t.set_link_state = &qed_set_vf_link_state,\n\t.set_spoof = &qed_spoof_configure,\n\t.set_rate = &qed_set_vf_rate,\n\t.set_trust = &qed_set_vf_trust,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}