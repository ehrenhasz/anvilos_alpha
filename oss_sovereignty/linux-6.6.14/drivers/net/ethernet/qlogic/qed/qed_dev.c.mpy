{
  "module_name": "qed_dev.c",
  "hash_id": "7b4fbbb48de36532d16d84421c096061555f9275e57ba5905e093cc846c3f283",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qed/qed_dev.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <asm/byteorder.h>\n#include <linux/io.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/mutex.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/vmalloc.h>\n#include <linux/etherdevice.h>\n#include <linux/qed/qed_chain.h>\n#include <linux/qed/qed_if.h>\n#include \"qed.h\"\n#include \"qed_cxt.h\"\n#include \"qed_dcbx.h\"\n#include \"qed_dev_api.h\"\n#include \"qed_fcoe.h\"\n#include \"qed_hsi.h\"\n#include \"qed_iro_hsi.h\"\n#include \"qed_hw.h\"\n#include \"qed_init_ops.h\"\n#include \"qed_int.h\"\n#include \"qed_iscsi.h\"\n#include \"qed_ll2.h\"\n#include \"qed_mcp.h\"\n#include \"qed_ooo.h\"\n#include \"qed_reg_addr.h\"\n#include \"qed_sp.h\"\n#include \"qed_sriov.h\"\n#include \"qed_vf.h\"\n#include \"qed_rdma.h\"\n#include \"qed_nvmetcp.h\"\n\nstatic DEFINE_SPINLOCK(qm_lock);\n\n \n \nstruct qed_db_recovery_entry {\n\tstruct list_head list_entry;\n\tvoid __iomem *db_addr;\n\tvoid *db_data;\n\tenum qed_db_rec_width db_width;\n\tenum qed_db_rec_space db_space;\n\tu8 hwfn_idx;\n};\n\n \nstatic void qed_db_recovery_dp_entry(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_db_recovery_entry *db_entry,\n\t\t\t\t     char *action)\n{\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SPQ,\n\t\t   \"(%s: db_entry %p, addr %p, data %p, width %s, %s space, hwfn %d)\\n\",\n\t\t   action,\n\t\t   db_entry,\n\t\t   db_entry->db_addr,\n\t\t   db_entry->db_data,\n\t\t   db_entry->db_width == DB_REC_WIDTH_32B ? \"32b\" : \"64b\",\n\t\t   db_entry->db_space == DB_REC_USER ? \"user\" : \"kernel\",\n\t\t   db_entry->hwfn_idx);\n}\n\n \nstatic bool qed_db_rec_sanity(struct qed_dev *cdev,\n\t\t\t      void __iomem *db_addr,\n\t\t\t      enum qed_db_rec_width db_width,\n\t\t\t      void *db_data)\n{\n\tu32 width = (db_width == DB_REC_WIDTH_32B) ? 32 : 64;\n\n\t \n\tif (db_addr < cdev->doorbells ||\n\t    (u8 __iomem *)db_addr + width >\n\t    (u8 __iomem *)cdev->doorbells + cdev->db_size) {\n\t\tWARN(true,\n\t\t     \"Illegal doorbell address: %p. Legal range for doorbell addresses is [%p..%p]\\n\",\n\t\t     db_addr,\n\t\t     cdev->doorbells,\n\t\t     (u8 __iomem *)cdev->doorbells + cdev->db_size);\n\t\treturn false;\n\t}\n\n\t \n\tif (!db_data) {\n\t\tWARN(true, \"Illegal doorbell data pointer: %p\", db_data);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic struct qed_hwfn *qed_db_rec_find_hwfn(struct qed_dev *cdev,\n\t\t\t\t\t     void __iomem *db_addr)\n{\n\tstruct qed_hwfn *p_hwfn;\n\n\t \n\tif (cdev->num_hwfns > 1)\n\t\tp_hwfn = db_addr < cdev->hwfns[1].doorbells ?\n\t\t    &cdev->hwfns[0] : &cdev->hwfns[1];\n\telse\n\t\tp_hwfn = QED_LEADING_HWFN(cdev);\n\n\treturn p_hwfn;\n}\n\n \nint qed_db_recovery_add(struct qed_dev *cdev,\n\t\t\tvoid __iomem *db_addr,\n\t\t\tvoid *db_data,\n\t\t\tenum qed_db_rec_width db_width,\n\t\t\tenum qed_db_rec_space db_space)\n{\n\tstruct qed_db_recovery_entry *db_entry;\n\tstruct qed_hwfn *p_hwfn;\n\n\t \n\tif (IS_VF(cdev)) {\n\t\tDP_VERBOSE(cdev,\n\t\t\t   QED_MSG_IOV, \"db recovery - skipping VF doorbell\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tif (!qed_db_rec_sanity(cdev, db_addr, db_width, db_data))\n\t\treturn -EINVAL;\n\n\t \n\tp_hwfn = qed_db_rec_find_hwfn(cdev, db_addr);\n\n\t \n\tdb_entry = kzalloc(sizeof(*db_entry), GFP_KERNEL);\n\tif (!db_entry) {\n\t\tDP_NOTICE(cdev, \"Failed to allocate a db recovery entry\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tdb_entry->db_addr = db_addr;\n\tdb_entry->db_data = db_data;\n\tdb_entry->db_width = db_width;\n\tdb_entry->db_space = db_space;\n\tdb_entry->hwfn_idx = p_hwfn->my_id;\n\n\t \n\tqed_db_recovery_dp_entry(p_hwfn, db_entry, \"Adding\");\n\n\t \n\tspin_lock_bh(&p_hwfn->db_recovery_info.lock);\n\tlist_add_tail(&db_entry->list_entry, &p_hwfn->db_recovery_info.list);\n\tspin_unlock_bh(&p_hwfn->db_recovery_info.lock);\n\n\treturn 0;\n}\n\n \nint qed_db_recovery_del(struct qed_dev *cdev,\n\t\t\tvoid __iomem *db_addr, void *db_data)\n{\n\tstruct qed_db_recovery_entry *db_entry = NULL;\n\tstruct qed_hwfn *p_hwfn;\n\tint rc = -EINVAL;\n\n\t \n\tif (IS_VF(cdev)) {\n\t\tDP_VERBOSE(cdev,\n\t\t\t   QED_MSG_IOV, \"db recovery - skipping VF doorbell\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tp_hwfn = qed_db_rec_find_hwfn(cdev, db_addr);\n\n\t \n\tspin_lock_bh(&p_hwfn->db_recovery_info.lock);\n\tlist_for_each_entry(db_entry,\n\t\t\t    &p_hwfn->db_recovery_info.list, list_entry) {\n\t\t \n\t\tif (db_entry->db_data == db_data) {\n\t\t\tqed_db_recovery_dp_entry(p_hwfn, db_entry, \"Deleting\");\n\t\t\tlist_del(&db_entry->list_entry);\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tspin_unlock_bh(&p_hwfn->db_recovery_info.lock);\n\n\tif (rc == -EINVAL)\n\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to find element in list. Key (db_data addr) was %p. db_addr was %p\\n\",\n\t\t\t  db_data, db_addr);\n\telse\n\t\tkfree(db_entry);\n\n\treturn rc;\n}\n\n \nstatic int qed_db_recovery_setup(struct qed_hwfn *p_hwfn)\n{\n\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ, \"Setting up db recovery\\n\");\n\n\t \n\tif (!p_hwfn->cdev->db_size) {\n\t\tDP_ERR(p_hwfn->cdev, \"db_size not set\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tINIT_LIST_HEAD(&p_hwfn->db_recovery_info.list);\n\tspin_lock_init(&p_hwfn->db_recovery_info.lock);\n\tp_hwfn->db_recovery_info.db_recovery_counter = 0;\n\n\treturn 0;\n}\n\n \nstatic void qed_db_recovery_teardown(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_db_recovery_entry *db_entry = NULL;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ, \"Tearing down db recovery\\n\");\n\tif (!list_empty(&p_hwfn->db_recovery_info.list)) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_SPQ,\n\t\t\t   \"Doorbell Recovery teardown found the doorbell recovery list was not empty (Expected in disorderly driver unload (e.g. recovery) otherwise this probably means some flow forgot to db_recovery_del). Prepare to purge doorbell recovery list...\\n\");\n\t\twhile (!list_empty(&p_hwfn->db_recovery_info.list)) {\n\t\t\tdb_entry =\n\t\t\t    list_first_entry(&p_hwfn->db_recovery_info.list,\n\t\t\t\t\t     struct qed_db_recovery_entry,\n\t\t\t\t\t     list_entry);\n\t\t\tqed_db_recovery_dp_entry(p_hwfn, db_entry, \"Purging\");\n\t\t\tlist_del(&db_entry->list_entry);\n\t\t\tkfree(db_entry);\n\t\t}\n\t}\n\tp_hwfn->db_recovery_info.db_recovery_counter = 0;\n}\n\n \nvoid qed_db_recovery_dp(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_db_recovery_entry *db_entry = NULL;\n\n\tDP_NOTICE(p_hwfn,\n\t\t  \"Displaying doorbell recovery database. Counter was %d\\n\",\n\t\t  p_hwfn->db_recovery_info.db_recovery_counter);\n\n\t \n\tspin_lock_bh(&p_hwfn->db_recovery_info.lock);\n\tlist_for_each_entry(db_entry,\n\t\t\t    &p_hwfn->db_recovery_info.list, list_entry) {\n\t\tqed_db_recovery_dp_entry(p_hwfn, db_entry, \"Printing\");\n\t}\n\n\tspin_unlock_bh(&p_hwfn->db_recovery_info.lock);\n}\n\n \nstatic void qed_db_recovery_ring(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_db_recovery_entry *db_entry)\n{\n\t \n\tif (db_entry->db_width == DB_REC_WIDTH_32B) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\n\t\t\t   \"ringing doorbell address %p data %x\\n\",\n\t\t\t   db_entry->db_addr,\n\t\t\t   *(u32 *)db_entry->db_data);\n\t} else {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\n\t\t\t   \"ringing doorbell address %p data %llx\\n\",\n\t\t\t   db_entry->db_addr,\n\t\t\t   *(u64 *)(db_entry->db_data));\n\t}\n\n\t \n\tif (!qed_db_rec_sanity(p_hwfn->cdev, db_entry->db_addr,\n\t\t\t       db_entry->db_width, db_entry->db_data))\n\t\treturn;\n\n\t \n\twmb();\n\n\t \n\tif (db_entry->db_width == DB_REC_WIDTH_32B)\n\t\tDIRECT_REG_WR(db_entry->db_addr,\n\t\t\t      *(u32 *)(db_entry->db_data));\n\telse\n\t\tDIRECT_REG_WR64(db_entry->db_addr,\n\t\t\t\t*(u64 *)(db_entry->db_data));\n\n\t \n\twmb();\n}\n\n \nvoid qed_db_recovery_execute(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_db_recovery_entry *db_entry = NULL;\n\n\tDP_NOTICE(p_hwfn, \"Executing doorbell recovery. Counter was %d\\n\",\n\t\t  p_hwfn->db_recovery_info.db_recovery_counter);\n\n\t \n\tp_hwfn->db_recovery_info.db_recovery_counter++;\n\n\t \n\tspin_lock_bh(&p_hwfn->db_recovery_info.lock);\n\tlist_for_each_entry(db_entry,\n\t\t\t    &p_hwfn->db_recovery_info.list, list_entry)\n\t\tqed_db_recovery_ring(p_hwfn, db_entry);\n\tspin_unlock_bh(&p_hwfn->db_recovery_info.lock);\n}\n\n \n\n \n\nenum qed_llh_filter_type {\n\tQED_LLH_FILTER_TYPE_MAC,\n\tQED_LLH_FILTER_TYPE_PROTOCOL,\n};\n\nstruct qed_llh_mac_filter {\n\tu8 addr[ETH_ALEN];\n};\n\nstruct qed_llh_protocol_filter {\n\tenum qed_llh_prot_filter_type_t type;\n\tu16 source_port_or_eth_type;\n\tu16 dest_port;\n};\n\nunion qed_llh_filter {\n\tstruct qed_llh_mac_filter mac;\n\tstruct qed_llh_protocol_filter protocol;\n};\n\nstruct qed_llh_filter_info {\n\tbool b_enabled;\n\tu32 ref_cnt;\n\tenum qed_llh_filter_type type;\n\tunion qed_llh_filter filter;\n};\n\nstruct qed_llh_info {\n\t \n\tu8 num_ppfid;\n\n#define MAX_NUM_PPFID   8\n\tu8 ppfid_array[MAX_NUM_PPFID];\n\n\t \n\tstruct qed_llh_filter_info **pp_filters;\n};\n\nstatic void qed_llh_free(struct qed_dev *cdev)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\tu32 i;\n\n\tif (p_llh_info) {\n\t\tif (p_llh_info->pp_filters)\n\t\t\tfor (i = 0; i < p_llh_info->num_ppfid; i++)\n\t\t\t\tkfree(p_llh_info->pp_filters[i]);\n\n\t\tkfree(p_llh_info->pp_filters);\n\t}\n\n\tkfree(p_llh_info);\n\tcdev->p_llh_info = NULL;\n}\n\nstatic int qed_llh_alloc(struct qed_dev *cdev)\n{\n\tstruct qed_llh_info *p_llh_info;\n\tu32 size, i;\n\n\tp_llh_info = kzalloc(sizeof(*p_llh_info), GFP_KERNEL);\n\tif (!p_llh_info)\n\t\treturn -ENOMEM;\n\tcdev->p_llh_info = p_llh_info;\n\n\tfor (i = 0; i < MAX_NUM_PPFID; i++) {\n\t\tif (!(cdev->ppfid_bitmap & (0x1 << i)))\n\t\t\tcontinue;\n\n\t\tp_llh_info->ppfid_array[p_llh_info->num_ppfid] = i;\n\t\tDP_VERBOSE(cdev, QED_MSG_SP, \"ppfid_array[%d] = %u\\n\",\n\t\t\t   p_llh_info->num_ppfid, i);\n\t\tp_llh_info->num_ppfid++;\n\t}\n\n\tsize = p_llh_info->num_ppfid * sizeof(*p_llh_info->pp_filters);\n\tp_llh_info->pp_filters = kzalloc(size, GFP_KERNEL);\n\tif (!p_llh_info->pp_filters)\n\t\treturn -ENOMEM;\n\n\tsize = NIG_REG_LLH_FUNC_FILTER_EN_SIZE *\n\t    sizeof(**p_llh_info->pp_filters);\n\tfor (i = 0; i < p_llh_info->num_ppfid; i++) {\n\t\tp_llh_info->pp_filters[i] = kzalloc(size, GFP_KERNEL);\n\t\tif (!p_llh_info->pp_filters[i])\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_llh_shadow_sanity(struct qed_dev *cdev,\n\t\t\t\t u8 ppfid, u8 filter_idx, const char *action)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\n\tif (ppfid >= p_llh_info->num_ppfid) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"LLH shadow [%s]: using ppfid %d while only %d ppfids are available\\n\",\n\t\t\t  action, ppfid, p_llh_info->num_ppfid);\n\t\treturn -EINVAL;\n\t}\n\n\tif (filter_idx >= NIG_REG_LLH_FUNC_FILTER_EN_SIZE) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"LLH shadow [%s]: using filter_idx %d while only %d filters are available\\n\",\n\t\t\t  action, filter_idx, NIG_REG_LLH_FUNC_FILTER_EN_SIZE);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n#define QED_LLH_INVALID_FILTER_IDX      0xff\n\nstatic int\nqed_llh_shadow_search_filter(struct qed_dev *cdev,\n\t\t\t     u8 ppfid,\n\t\t\t     union qed_llh_filter *p_filter, u8 *p_filter_idx)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\tstruct qed_llh_filter_info *p_filters;\n\tint rc;\n\tu8 i;\n\n\trc = qed_llh_shadow_sanity(cdev, ppfid, 0, \"search\");\n\tif (rc)\n\t\treturn rc;\n\n\t*p_filter_idx = QED_LLH_INVALID_FILTER_IDX;\n\n\tp_filters = p_llh_info->pp_filters[ppfid];\n\tfor (i = 0; i < NIG_REG_LLH_FUNC_FILTER_EN_SIZE; i++) {\n\t\tif (!memcmp(p_filter, &p_filters[i].filter,\n\t\t\t    sizeof(*p_filter))) {\n\t\t\t*p_filter_idx = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int\nqed_llh_shadow_get_free_idx(struct qed_dev *cdev, u8 ppfid, u8 *p_filter_idx)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\tstruct qed_llh_filter_info *p_filters;\n\tint rc;\n\tu8 i;\n\n\trc = qed_llh_shadow_sanity(cdev, ppfid, 0, \"get_free_idx\");\n\tif (rc)\n\t\treturn rc;\n\n\t*p_filter_idx = QED_LLH_INVALID_FILTER_IDX;\n\n\tp_filters = p_llh_info->pp_filters[ppfid];\n\tfor (i = 0; i < NIG_REG_LLH_FUNC_FILTER_EN_SIZE; i++) {\n\t\tif (!p_filters[i].b_enabled) {\n\t\t\t*p_filter_idx = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int\n__qed_llh_shadow_add_filter(struct qed_dev *cdev,\n\t\t\t    u8 ppfid,\n\t\t\t    u8 filter_idx,\n\t\t\t    enum qed_llh_filter_type type,\n\t\t\t    union qed_llh_filter *p_filter, u32 *p_ref_cnt)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\tstruct qed_llh_filter_info *p_filters;\n\tint rc;\n\n\trc = qed_llh_shadow_sanity(cdev, ppfid, filter_idx, \"add\");\n\tif (rc)\n\t\treturn rc;\n\n\tp_filters = p_llh_info->pp_filters[ppfid];\n\tif (!p_filters[filter_idx].ref_cnt) {\n\t\tp_filters[filter_idx].b_enabled = true;\n\t\tp_filters[filter_idx].type = type;\n\t\tmemcpy(&p_filters[filter_idx].filter, p_filter,\n\t\t       sizeof(p_filters[filter_idx].filter));\n\t}\n\n\t*p_ref_cnt = ++p_filters[filter_idx].ref_cnt;\n\n\treturn 0;\n}\n\nstatic int\nqed_llh_shadow_add_filter(struct qed_dev *cdev,\n\t\t\t  u8 ppfid,\n\t\t\t  enum qed_llh_filter_type type,\n\t\t\t  union qed_llh_filter *p_filter,\n\t\t\t  u8 *p_filter_idx, u32 *p_ref_cnt)\n{\n\tint rc;\n\n\t \n\trc = qed_llh_shadow_search_filter(cdev, ppfid, p_filter, p_filter_idx);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (*p_filter_idx == QED_LLH_INVALID_FILTER_IDX) {\n\t\trc = qed_llh_shadow_get_free_idx(cdev, ppfid, p_filter_idx);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t \n\tif (*p_filter_idx == QED_LLH_INVALID_FILTER_IDX) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Failed to find an empty LLH filter to utilize [ppfid %d]\\n\",\n\t\t\t  ppfid);\n\t\treturn -EINVAL;\n\t}\n\n\treturn __qed_llh_shadow_add_filter(cdev, ppfid, *p_filter_idx, type,\n\t\t\t\t\t   p_filter, p_ref_cnt);\n}\n\nstatic int\n__qed_llh_shadow_remove_filter(struct qed_dev *cdev,\n\t\t\t       u8 ppfid, u8 filter_idx, u32 *p_ref_cnt)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\tstruct qed_llh_filter_info *p_filters;\n\tint rc;\n\n\trc = qed_llh_shadow_sanity(cdev, ppfid, filter_idx, \"remove\");\n\tif (rc)\n\t\treturn rc;\n\n\tp_filters = p_llh_info->pp_filters[ppfid];\n\tif (!p_filters[filter_idx].ref_cnt) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"LLH shadow: trying to remove a filter with ref_cnt=0\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t*p_ref_cnt = --p_filters[filter_idx].ref_cnt;\n\tif (!p_filters[filter_idx].ref_cnt)\n\t\tmemset(&p_filters[filter_idx],\n\t\t       0, sizeof(p_filters[filter_idx]));\n\n\treturn 0;\n}\n\nstatic int\nqed_llh_shadow_remove_filter(struct qed_dev *cdev,\n\t\t\t     u8 ppfid,\n\t\t\t     union qed_llh_filter *p_filter,\n\t\t\t     u8 *p_filter_idx, u32 *p_ref_cnt)\n{\n\tint rc;\n\n\trc = qed_llh_shadow_search_filter(cdev, ppfid, p_filter, p_filter_idx);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (*p_filter_idx == QED_LLH_INVALID_FILTER_IDX) {\n\t\tDP_NOTICE(cdev, \"Failed to find a filter in the LLH shadow\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn __qed_llh_shadow_remove_filter(cdev, ppfid, *p_filter_idx,\n\t\t\t\t\t      p_ref_cnt);\n}\n\nstatic int qed_llh_abs_ppfid(struct qed_dev *cdev, u8 ppfid, u8 *p_abs_ppfid)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\n\tif (ppfid >= p_llh_info->num_ppfid) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"ppfid %d is not valid, available indices are 0..%d\\n\",\n\t\t\t  ppfid, p_llh_info->num_ppfid - 1);\n\t\t*p_abs_ppfid = 0;\n\t\treturn -EINVAL;\n\t}\n\n\t*p_abs_ppfid = p_llh_info->ppfid_array[ppfid];\n\n\treturn 0;\n}\n\nstatic int\nqed_llh_set_engine_affin(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tenum qed_eng eng;\n\tu8 ppfid;\n\tint rc;\n\n\trc = qed_mcp_get_engine_config(p_hwfn, p_ptt);\n\tif (rc != 0 && rc != -EOPNOTSUPP) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to get the engine affinity configuration\\n\");\n\t\treturn rc;\n\t}\n\n\t \n\tif (QED_IS_ROCE_PERSONALITY(p_hwfn)) {\n\t\teng = cdev->fir_affin ? QED_ENG1 : QED_ENG0;\n\t\trc = qed_llh_set_roce_affinity(cdev, eng);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(cdev,\n\t\t\t\t  \"Failed to set the RoCE engine affinity\\n\");\n\t\t\treturn rc;\n\t\t}\n\n\t\tDP_VERBOSE(cdev,\n\t\t\t   QED_MSG_SP,\n\t\t\t   \"LLH: Set the engine affinity of RoCE packets as %d\\n\",\n\t\t\t   eng);\n\t}\n\n\t \n\tif (QED_IS_FCOE_PERSONALITY(p_hwfn) || QED_IS_ISCSI_PERSONALITY(p_hwfn) ||\n\t    QED_IS_NVMETCP_PERSONALITY(p_hwfn))\n\t\teng = cdev->fir_affin ? QED_ENG1 : QED_ENG0;\n\telse\t\t\t \n\t\teng = QED_BOTH_ENG;\n\n\tfor (ppfid = 0; ppfid < cdev->p_llh_info->num_ppfid; ppfid++) {\n\t\trc = qed_llh_set_ppfid_affinity(cdev, ppfid, eng);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(cdev,\n\t\t\t\t  \"Failed to set the engine affinity of ppfid %d\\n\",\n\t\t\t\t  ppfid);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\tDP_VERBOSE(cdev, QED_MSG_SP,\n\t\t   \"LLH: Set the engine affinity of non-RoCE packets as %d\\n\",\n\t\t   eng);\n\n\treturn 0;\n}\n\nstatic int qed_llh_hw_init_pf(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_ptt *p_ptt)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tu8 ppfid, abs_ppfid;\n\tint rc;\n\n\tfor (ppfid = 0; ppfid < cdev->p_llh_info->num_ppfid; ppfid++) {\n\t\tu32 addr;\n\n\t\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\taddr = NIG_REG_LLH_PPFID2PFID_TBL_0 + abs_ppfid * 0x4;\n\t\tqed_wr(p_hwfn, p_ptt, addr, p_hwfn->rel_pf_id);\n\t}\n\n\tif (test_bit(QED_MF_LLH_MAC_CLSS, &cdev->mf_bits) &&\n\t    !QED_IS_FCOE_PERSONALITY(p_hwfn)) {\n\t\trc = qed_llh_add_mac_filter(cdev, 0,\n\t\t\t\t\t    p_hwfn->hw_info.hw_mac_addr);\n\t\tif (rc)\n\t\t\tDP_NOTICE(cdev,\n\t\t\t\t  \"Failed to add an LLH filter with the primary MAC\\n\");\n\t}\n\n\tif (QED_IS_CMT(cdev)) {\n\t\trc = qed_llh_set_engine_affin(p_hwfn, p_ptt);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nu8 qed_llh_get_num_ppfid(struct qed_dev *cdev)\n{\n\treturn cdev->p_llh_info->num_ppfid;\n}\n\n#define NIG_REG_PPF_TO_ENGINE_SEL_ROCE_MASK             0x3\n#define NIG_REG_PPF_TO_ENGINE_SEL_ROCE_SHIFT            0\n#define NIG_REG_PPF_TO_ENGINE_SEL_NON_ROCE_MASK         0x3\n#define NIG_REG_PPF_TO_ENGINE_SEL_NON_ROCE_SHIFT        2\n\nint qed_llh_set_ppfid_affinity(struct qed_dev *cdev, u8 ppfid, enum qed_eng eng)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = qed_ptt_acquire(p_hwfn);\n\tu32 addr, val, eng_sel;\n\tu8 abs_ppfid;\n\tint rc = 0;\n\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\tif (!QED_IS_CMT(cdev))\n\t\tgoto out;\n\n\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\tif (rc)\n\t\tgoto out;\n\n\tswitch (eng) {\n\tcase QED_ENG0:\n\t\teng_sel = 0;\n\t\tbreak;\n\tcase QED_ENG1:\n\t\teng_sel = 1;\n\t\tbreak;\n\tcase QED_BOTH_ENG:\n\t\teng_sel = 2;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(cdev, \"Invalid affinity value for ppfid [%d]\\n\", eng);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\taddr = NIG_REG_PPF_TO_ENGINE_SEL + abs_ppfid * 0x4;\n\tval = qed_rd(p_hwfn, p_ptt, addr);\n\tSET_FIELD(val, NIG_REG_PPF_TO_ENGINE_SEL_NON_ROCE, eng_sel);\n\tqed_wr(p_hwfn, p_ptt, addr, val);\n\n\t \n\tif (!ppfid && QED_IS_IWARP_PERSONALITY(p_hwfn))\n\t\tcdev->iwarp_affin = (eng == QED_ENG1) ? 1 : 0;\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nint qed_llh_set_roce_affinity(struct qed_dev *cdev, enum qed_eng eng)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = qed_ptt_acquire(p_hwfn);\n\tu32 addr, val, eng_sel;\n\tu8 ppfid, abs_ppfid;\n\tint rc = 0;\n\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\tif (!QED_IS_CMT(cdev))\n\t\tgoto out;\n\n\tswitch (eng) {\n\tcase QED_ENG0:\n\t\teng_sel = 0;\n\t\tbreak;\n\tcase QED_ENG1:\n\t\teng_sel = 1;\n\t\tbreak;\n\tcase QED_BOTH_ENG:\n\t\teng_sel = 2;\n\t\tqed_wr(p_hwfn, p_ptt, NIG_REG_LLH_ENG_CLS_ROCE_QP_SEL,\n\t\t       0xf);   \n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(cdev, \"Invalid affinity value for RoCE [%d]\\n\", eng);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tfor (ppfid = 0; ppfid < cdev->p_llh_info->num_ppfid; ppfid++) {\n\t\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\t\tif (rc)\n\t\t\tgoto out;\n\n\t\taddr = NIG_REG_PPF_TO_ENGINE_SEL + abs_ppfid * 0x4;\n\t\tval = qed_rd(p_hwfn, p_ptt, addr);\n\t\tSET_FIELD(val, NIG_REG_PPF_TO_ENGINE_SEL_ROCE, eng_sel);\n\t\tqed_wr(p_hwfn, p_ptt, addr, val);\n\t}\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nstruct qed_llh_filter_details {\n\tu64 value;\n\tu32 mode;\n\tu32 protocol_type;\n\tu32 hdr_sel;\n\tu32 enable;\n};\n\nstatic int\nqed_llh_access_filter(struct qed_hwfn *p_hwfn,\n\t\t      struct qed_ptt *p_ptt,\n\t\t      u8 abs_ppfid,\n\t\t      u8 filter_idx,\n\t\t      struct qed_llh_filter_details *p_details)\n{\n\tstruct qed_dmae_params params = {0};\n\tu32 addr;\n\tu8 pfid;\n\tint rc;\n\n\t \n\tif (QED_IS_BB(p_hwfn->cdev))\n\t\tpfid = abs_ppfid;\n\telse\n\t\tpfid = abs_ppfid * p_hwfn->cdev->num_ports_in_engine +\n\t\t    MFW_PORT(p_hwfn);\n\n\t \n\tif (!p_details->enable) {\n\t\tqed_fid_pretend(p_hwfn, p_ptt,\n\t\t\t\tpfid << PXP_PRETEND_CONCRETE_FID_PFID_SHIFT);\n\n\t\taddr = NIG_REG_LLH_FUNC_FILTER_EN + filter_idx * 0x4;\n\t\tqed_wr(p_hwfn, p_ptt, addr, p_details->enable);\n\n\t\tqed_fid_pretend(p_hwfn, p_ptt,\n\t\t\t\tp_hwfn->rel_pf_id <<\n\t\t\t\tPXP_PRETEND_CONCRETE_FID_PFID_SHIFT);\n\t}\n\n\t \n\taddr = NIG_REG_LLH_FUNC_FILTER_VALUE + 2 * filter_idx * 0x4;\n\n\tSET_FIELD(params.flags, QED_DMAE_PARAMS_DST_PF_VALID, 0x1);\n\tparams.dst_pfid = pfid;\n\trc = qed_dmae_host2grc(p_hwfn,\n\t\t\t       p_ptt,\n\t\t\t       (u64)(uintptr_t)&p_details->value,\n\t\t\t       addr, 2  ,\n\t\t\t       &params);\n\tif (rc)\n\t\treturn rc;\n\n\tqed_fid_pretend(p_hwfn, p_ptt,\n\t\t\tpfid << PXP_PRETEND_CONCRETE_FID_PFID_SHIFT);\n\n\t \n\taddr = NIG_REG_LLH_FUNC_FILTER_MODE + filter_idx * 0x4;\n\tqed_wr(p_hwfn, p_ptt, addr, p_details->mode);\n\n\t \n\taddr = NIG_REG_LLH_FUNC_FILTER_PROTOCOL_TYPE + filter_idx * 0x4;\n\tqed_wr(p_hwfn, p_ptt, addr, p_details->protocol_type);\n\n\t \n\taddr = NIG_REG_LLH_FUNC_FILTER_HDR_SEL + filter_idx * 0x4;\n\tqed_wr(p_hwfn, p_ptt, addr, p_details->hdr_sel);\n\n\t \n\tif (p_details->enable) {\n\t\taddr = NIG_REG_LLH_FUNC_FILTER_EN + filter_idx * 0x4;\n\t\tqed_wr(p_hwfn, p_ptt, addr, p_details->enable);\n\t}\n\n\tqed_fid_pretend(p_hwfn, p_ptt,\n\t\t\tp_hwfn->rel_pf_id <<\n\t\t\tPXP_PRETEND_CONCRETE_FID_PFID_SHIFT);\n\n\treturn 0;\n}\n\nstatic int\nqed_llh_add_filter(struct qed_hwfn *p_hwfn,\n\t\t   struct qed_ptt *p_ptt,\n\t\t   u8 abs_ppfid,\n\t\t   u8 filter_idx, u8 filter_prot_type, u32 high, u32 low)\n{\n\tstruct qed_llh_filter_details filter_details;\n\n\tfilter_details.enable = 1;\n\tfilter_details.value = ((u64)high << 32) | low;\n\tfilter_details.hdr_sel = 0;\n\tfilter_details.protocol_type = filter_prot_type;\n\t \n\tfilter_details.mode = filter_prot_type ? 1 : 0;\n\n\treturn qed_llh_access_filter(p_hwfn, p_ptt, abs_ppfid, filter_idx,\n\t\t\t\t     &filter_details);\n}\n\nstatic int\nqed_llh_remove_filter(struct qed_hwfn *p_hwfn,\n\t\t      struct qed_ptt *p_ptt, u8 abs_ppfid, u8 filter_idx)\n{\n\tstruct qed_llh_filter_details filter_details = {0};\n\n\treturn qed_llh_access_filter(p_hwfn, p_ptt, abs_ppfid, filter_idx,\n\t\t\t\t     &filter_details);\n}\n\nint qed_llh_add_mac_filter(struct qed_dev *cdev,\n\t\t\t   u8 ppfid, const u8 mac_addr[ETH_ALEN])\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = qed_ptt_acquire(p_hwfn);\n\tunion qed_llh_filter filter = {};\n\tu8 filter_idx, abs_ppfid = 0;\n\tu32 high, low, ref_cnt;\n\tint rc = 0;\n\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\tif (!test_bit(QED_MF_LLH_MAC_CLSS, &cdev->mf_bits))\n\t\tgoto out;\n\n\tmemcpy(filter.mac.addr, mac_addr, ETH_ALEN);\n\trc = qed_llh_shadow_add_filter(cdev, ppfid,\n\t\t\t\t       QED_LLH_FILTER_TYPE_MAC,\n\t\t\t\t       &filter, &filter_idx, &ref_cnt);\n\tif (rc)\n\t\tgoto err;\n\n\t \n\tif (ref_cnt == 1) {\n\t\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\t\tif (rc)\n\t\t\tgoto err;\n\n\t\thigh = mac_addr[1] | (mac_addr[0] << 8);\n\t\tlow = mac_addr[5] | (mac_addr[4] << 8) | (mac_addr[3] << 16) |\n\t\t      (mac_addr[2] << 24);\n\t\trc = qed_llh_add_filter(p_hwfn, p_ptt, abs_ppfid, filter_idx,\n\t\t\t\t\t0, high, low);\n\t\tif (rc)\n\t\t\tgoto err;\n\t}\n\n\tDP_VERBOSE(cdev,\n\t\t   QED_MSG_SP,\n\t\t   \"LLH: Added MAC filter [%pM] to ppfid %hhd [abs %hhd] at idx %hhd [ref_cnt %d]\\n\",\n\t\t   mac_addr, ppfid, abs_ppfid, filter_idx, ref_cnt);\n\n\tgoto out;\n\nerr:\tDP_NOTICE(cdev,\n\t\t  \"LLH: Failed to add MAC filter [%pM] to ppfid %hhd\\n\",\n\t\t  mac_addr, ppfid);\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nstatic int\nqed_llh_protocol_filter_stringify(struct qed_dev *cdev,\n\t\t\t\t  enum qed_llh_prot_filter_type_t type,\n\t\t\t\t  u16 source_port_or_eth_type,\n\t\t\t\t  u16 dest_port, u8 *str, size_t str_len)\n{\n\tswitch (type) {\n\tcase QED_LLH_FILTER_ETHERTYPE:\n\t\tsnprintf(str, str_len, \"Ethertype 0x%04x\",\n\t\t\t source_port_or_eth_type);\n\t\tbreak;\n\tcase QED_LLH_FILTER_TCP_SRC_PORT:\n\t\tsnprintf(str, str_len, \"TCP src port 0x%04x\",\n\t\t\t source_port_or_eth_type);\n\t\tbreak;\n\tcase QED_LLH_FILTER_UDP_SRC_PORT:\n\t\tsnprintf(str, str_len, \"UDP src port 0x%04x\",\n\t\t\t source_port_or_eth_type);\n\t\tbreak;\n\tcase QED_LLH_FILTER_TCP_DEST_PORT:\n\t\tsnprintf(str, str_len, \"TCP dst port 0x%04x\", dest_port);\n\t\tbreak;\n\tcase QED_LLH_FILTER_UDP_DEST_PORT:\n\t\tsnprintf(str, str_len, \"UDP dst port 0x%04x\", dest_port);\n\t\tbreak;\n\tcase QED_LLH_FILTER_TCP_SRC_AND_DEST_PORT:\n\t\tsnprintf(str, str_len, \"TCP src/dst ports 0x%04x/0x%04x\",\n\t\t\t source_port_or_eth_type, dest_port);\n\t\tbreak;\n\tcase QED_LLH_FILTER_UDP_SRC_AND_DEST_PORT:\n\t\tsnprintf(str, str_len, \"UDP src/dst ports 0x%04x/0x%04x\",\n\t\t\t source_port_or_eth_type, dest_port);\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Non valid LLH protocol filter type %d\\n\", type);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nqed_llh_protocol_filter_to_hilo(struct qed_dev *cdev,\n\t\t\t\tenum qed_llh_prot_filter_type_t type,\n\t\t\t\tu16 source_port_or_eth_type,\n\t\t\t\tu16 dest_port, u32 *p_high, u32 *p_low)\n{\n\t*p_high = 0;\n\t*p_low = 0;\n\n\tswitch (type) {\n\tcase QED_LLH_FILTER_ETHERTYPE:\n\t\t*p_high = source_port_or_eth_type;\n\t\tbreak;\n\tcase QED_LLH_FILTER_TCP_SRC_PORT:\n\tcase QED_LLH_FILTER_UDP_SRC_PORT:\n\t\t*p_low = source_port_or_eth_type << 16;\n\t\tbreak;\n\tcase QED_LLH_FILTER_TCP_DEST_PORT:\n\tcase QED_LLH_FILTER_UDP_DEST_PORT:\n\t\t*p_low = dest_port;\n\t\tbreak;\n\tcase QED_LLH_FILTER_TCP_SRC_AND_DEST_PORT:\n\tcase QED_LLH_FILTER_UDP_SRC_AND_DEST_PORT:\n\t\t*p_low = (source_port_or_eth_type << 16) | dest_port;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Non valid LLH protocol filter type %d\\n\", type);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nint\nqed_llh_add_protocol_filter(struct qed_dev *cdev,\n\t\t\t    u8 ppfid,\n\t\t\t    enum qed_llh_prot_filter_type_t type,\n\t\t\t    u16 source_port_or_eth_type, u16 dest_port)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = qed_ptt_acquire(p_hwfn);\n\tu8 filter_idx, abs_ppfid, str[32], type_bitmap;\n\tunion qed_llh_filter filter = {};\n\tu32 high, low, ref_cnt;\n\tint rc = 0;\n\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\tif (!test_bit(QED_MF_LLH_PROTO_CLSS, &cdev->mf_bits))\n\t\tgoto out;\n\n\trc = qed_llh_protocol_filter_stringify(cdev, type,\n\t\t\t\t\t       source_port_or_eth_type,\n\t\t\t\t\t       dest_port, str, sizeof(str));\n\tif (rc)\n\t\tgoto err;\n\n\tfilter.protocol.type = type;\n\tfilter.protocol.source_port_or_eth_type = source_port_or_eth_type;\n\tfilter.protocol.dest_port = dest_port;\n\trc = qed_llh_shadow_add_filter(cdev,\n\t\t\t\t       ppfid,\n\t\t\t\t       QED_LLH_FILTER_TYPE_PROTOCOL,\n\t\t\t\t       &filter, &filter_idx, &ref_cnt);\n\tif (rc)\n\t\tgoto err;\n\n\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\tif (rc)\n\t\tgoto err;\n\n\t \n\tif (ref_cnt == 1) {\n\t\trc = qed_llh_protocol_filter_to_hilo(cdev, type,\n\t\t\t\t\t\t     source_port_or_eth_type,\n\t\t\t\t\t\t     dest_port, &high, &low);\n\t\tif (rc)\n\t\t\tgoto err;\n\n\t\ttype_bitmap = 0x1 << type;\n\t\trc = qed_llh_add_filter(p_hwfn, p_ptt, abs_ppfid,\n\t\t\t\t\tfilter_idx, type_bitmap, high, low);\n\t\tif (rc)\n\t\t\tgoto err;\n\t}\n\n\tDP_VERBOSE(cdev,\n\t\t   QED_MSG_SP,\n\t\t   \"LLH: Added protocol filter [%s] to ppfid %hhd [abs %hhd] at idx %hhd [ref_cnt %d]\\n\",\n\t\t   str, ppfid, abs_ppfid, filter_idx, ref_cnt);\n\n\tgoto out;\n\nerr:\tDP_NOTICE(p_hwfn,\n\t\t  \"LLH: Failed to add protocol filter [%s] to ppfid %hhd\\n\",\n\t\t  str, ppfid);\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nvoid qed_llh_remove_mac_filter(struct qed_dev *cdev,\n\t\t\t       u8 ppfid, u8 mac_addr[ETH_ALEN])\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = qed_ptt_acquire(p_hwfn);\n\tunion qed_llh_filter filter = {};\n\tu8 filter_idx, abs_ppfid;\n\tint rc = 0;\n\tu32 ref_cnt;\n\n\tif (!p_ptt)\n\t\treturn;\n\n\tif (!test_bit(QED_MF_LLH_MAC_CLSS, &cdev->mf_bits))\n\t\tgoto out;\n\n\tif (QED_IS_NVMETCP_PERSONALITY(p_hwfn))\n\t\treturn;\n\n\tether_addr_copy(filter.mac.addr, mac_addr);\n\trc = qed_llh_shadow_remove_filter(cdev, ppfid, &filter, &filter_idx,\n\t\t\t\t\t  &ref_cnt);\n\tif (rc)\n\t\tgoto err;\n\n\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\tif (rc)\n\t\tgoto err;\n\n\t \n\tif (!ref_cnt) {\n\t\trc = qed_llh_remove_filter(p_hwfn, p_ptt, abs_ppfid,\n\t\t\t\t\t   filter_idx);\n\t\tif (rc)\n\t\t\tgoto err;\n\t}\n\n\tDP_VERBOSE(cdev,\n\t\t   QED_MSG_SP,\n\t\t   \"LLH: Removed MAC filter [%pM] from ppfid %hhd [abs %hhd] at idx %hhd [ref_cnt %d]\\n\",\n\t\t   mac_addr, ppfid, abs_ppfid, filter_idx, ref_cnt);\n\n\tgoto out;\n\nerr:\tDP_NOTICE(cdev,\n\t\t  \"LLH: Failed to remove MAC filter [%pM] from ppfid %hhd\\n\",\n\t\t  mac_addr, ppfid);\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n}\n\nvoid qed_llh_remove_protocol_filter(struct qed_dev *cdev,\n\t\t\t\t    u8 ppfid,\n\t\t\t\t    enum qed_llh_prot_filter_type_t type,\n\t\t\t\t    u16 source_port_or_eth_type, u16 dest_port)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = qed_ptt_acquire(p_hwfn);\n\tu8 filter_idx, abs_ppfid, str[32];\n\tunion qed_llh_filter filter = {};\n\tint rc = 0;\n\tu32 ref_cnt;\n\n\tif (!p_ptt)\n\t\treturn;\n\n\tif (!test_bit(QED_MF_LLH_PROTO_CLSS, &cdev->mf_bits))\n\t\tgoto out;\n\n\trc = qed_llh_protocol_filter_stringify(cdev, type,\n\t\t\t\t\t       source_port_or_eth_type,\n\t\t\t\t\t       dest_port, str, sizeof(str));\n\tif (rc)\n\t\tgoto err;\n\n\tfilter.protocol.type = type;\n\tfilter.protocol.source_port_or_eth_type = source_port_or_eth_type;\n\tfilter.protocol.dest_port = dest_port;\n\trc = qed_llh_shadow_remove_filter(cdev, ppfid, &filter, &filter_idx,\n\t\t\t\t\t  &ref_cnt);\n\tif (rc)\n\t\tgoto err;\n\n\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\tif (rc)\n\t\tgoto err;\n\n\t \n\tif (!ref_cnt) {\n\t\trc = qed_llh_remove_filter(p_hwfn, p_ptt, abs_ppfid,\n\t\t\t\t\t   filter_idx);\n\t\tif (rc)\n\t\t\tgoto err;\n\t}\n\n\tDP_VERBOSE(cdev,\n\t\t   QED_MSG_SP,\n\t\t   \"LLH: Removed protocol filter [%s] from ppfid %hhd [abs %hhd] at idx %hhd [ref_cnt %d]\\n\",\n\t\t   str, ppfid, abs_ppfid, filter_idx, ref_cnt);\n\n\tgoto out;\n\nerr:\tDP_NOTICE(cdev,\n\t\t  \"LLH: Failed to remove protocol filter [%s] from ppfid %hhd\\n\",\n\t\t  str, ppfid);\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n}\n\n \n\n#define QED_MIN_DPIS            (4)\n#define QED_MIN_PWM_REGION      (QED_WID_SIZE * QED_MIN_DPIS)\n\nstatic u32 qed_hw_bar_size(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_ptt *p_ptt, enum BAR_ID bar_id)\n{\n\tu32 bar_reg = (bar_id == BAR_ID_0 ?\n\t\t       PGLUE_B_REG_PF_BAR0_SIZE : PGLUE_B_REG_PF_BAR1_SIZE);\n\tu32 val;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn qed_vf_hw_bar_size(p_hwfn, bar_id);\n\n\tval = qed_rd(p_hwfn, p_ptt, bar_reg);\n\tif (val)\n\t\treturn 1 << (val + 15);\n\n\t \n\tif (p_hwfn->cdev->num_hwfns > 1) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"BAR size not configured. Assuming BAR size of 256kB for GRC and 512kB for DB\\n\");\n\t\t\treturn BAR_ID_0 ? 256 * 1024 : 512 * 1024;\n\t} else {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"BAR size not configured. Assuming BAR size of 512kB for GRC and 512kB for DB\\n\");\n\t\t\treturn 512 * 1024;\n\t}\n}\n\nvoid qed_init_dp(struct qed_dev *cdev, u32 dp_module, u8 dp_level)\n{\n\tu32 i;\n\n\tcdev->dp_level = dp_level;\n\tcdev->dp_module = dp_module;\n\tfor (i = 0; i < MAX_HWFNS_PER_DEVICE; i++) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tp_hwfn->dp_level = dp_level;\n\t\tp_hwfn->dp_module = dp_module;\n\t}\n}\n\nvoid qed_init_struct(struct qed_dev *cdev)\n{\n\tu8 i;\n\n\tfor (i = 0; i < MAX_HWFNS_PER_DEVICE; i++) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tp_hwfn->cdev = cdev;\n\t\tp_hwfn->my_id = i;\n\t\tp_hwfn->b_active = false;\n\n\t\tmutex_init(&p_hwfn->dmae_info.mutex);\n\t}\n\n\t \n\tcdev->hwfns[0].b_active = true;\n\n\t \n\tcdev->cache_shift = 7;\n}\n\nstatic void qed_qm_info_free(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tkfree(qm_info->qm_pq_params);\n\tqm_info->qm_pq_params = NULL;\n\tkfree(qm_info->qm_vport_params);\n\tqm_info->qm_vport_params = NULL;\n\tkfree(qm_info->qm_port_params);\n\tqm_info->qm_port_params = NULL;\n\tkfree(qm_info->wfq_data);\n\tqm_info->wfq_data = NULL;\n}\n\nstatic void qed_dbg_user_data_free(struct qed_hwfn *p_hwfn)\n{\n\tkfree(p_hwfn->dbg_user_info);\n\tp_hwfn->dbg_user_info = NULL;\n}\n\nvoid qed_resc_free(struct qed_dev *cdev)\n{\n\tstruct qed_rdma_info *rdma_info;\n\tstruct qed_hwfn *p_hwfn;\n\tint i;\n\n\tif (IS_VF(cdev)) {\n\t\tfor_each_hwfn(cdev, i)\n\t\t\tqed_l2_free(&cdev->hwfns[i]);\n\t\treturn;\n\t}\n\n\tkfree(cdev->fw_data);\n\tcdev->fw_data = NULL;\n\n\tkfree(cdev->reset_stats);\n\tcdev->reset_stats = NULL;\n\n\tqed_llh_free(cdev);\n\n\tfor_each_hwfn(cdev, i) {\n\t\tp_hwfn = cdev->hwfns + i;\n\t\trdma_info = p_hwfn->p_rdma_info;\n\n\t\tqed_cxt_mngr_free(p_hwfn);\n\t\tqed_qm_info_free(p_hwfn);\n\t\tqed_spq_free(p_hwfn);\n\t\tqed_eq_free(p_hwfn);\n\t\tqed_consq_free(p_hwfn);\n\t\tqed_int_free(p_hwfn);\n#ifdef CONFIG_QED_LL2\n\t\tqed_ll2_free(p_hwfn);\n#endif\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_FCOE)\n\t\t\tqed_fcoe_free(p_hwfn);\n\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_ISCSI) {\n\t\t\tqed_iscsi_free(p_hwfn);\n\t\t\tqed_ooo_free(p_hwfn);\n\t\t}\n\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_NVMETCP) {\n\t\t\tqed_nvmetcp_free(p_hwfn);\n\t\t\tqed_ooo_free(p_hwfn);\n\t\t}\n\n\t\tif (QED_IS_RDMA_PERSONALITY(p_hwfn) && rdma_info) {\n\t\t\tqed_spq_unregister_async_cb(p_hwfn, rdma_info->proto);\n\t\t\tqed_rdma_info_free(p_hwfn);\n\t\t}\n\n\t\tqed_spq_unregister_async_cb(p_hwfn, PROTOCOLID_COMMON);\n\t\tqed_iov_free(p_hwfn);\n\t\tqed_l2_free(p_hwfn);\n\t\tqed_dmae_info_free(p_hwfn);\n\t\tqed_dcbx_info_free(p_hwfn);\n\t\tqed_dbg_user_data_free(p_hwfn);\n\t\tqed_fw_overlay_mem_free(p_hwfn, &p_hwfn->fw_overlay_mem);\n\n\t\t \n\t\tqed_db_recovery_teardown(p_hwfn);\n\t}\n}\n\n \n#define ACTIVE_TCS_BMAP 0x9f\n#define ACTIVE_TCS_BMAP_4PORT_K2 0xf\n\n \nstatic u32 qed_get_pq_flags(struct qed_hwfn *p_hwfn)\n{\n\tu32 flags;\n\n\t \n\tflags = PQ_FLAGS_LB;\n\n\t \n\tif (IS_QED_SRIOV(p_hwfn->cdev))\n\t\tflags |= PQ_FLAGS_VFS;\n\n\t \n\tswitch (p_hwfn->hw_info.personality) {\n\tcase QED_PCI_ETH:\n\t\tflags |= PQ_FLAGS_MCOS;\n\t\tbreak;\n\tcase QED_PCI_FCOE:\n\t\tflags |= PQ_FLAGS_OFLD;\n\t\tbreak;\n\tcase QED_PCI_ISCSI:\n\tcase QED_PCI_NVMETCP:\n\t\tflags |= PQ_FLAGS_ACK | PQ_FLAGS_OOO | PQ_FLAGS_OFLD;\n\t\tbreak;\n\tcase QED_PCI_ETH_ROCE:\n\t\tflags |= PQ_FLAGS_MCOS | PQ_FLAGS_OFLD | PQ_FLAGS_LLT;\n\t\tif (IS_QED_MULTI_TC_ROCE(p_hwfn))\n\t\t\tflags |= PQ_FLAGS_MTC;\n\t\tbreak;\n\tcase QED_PCI_ETH_IWARP:\n\t\tflags |= PQ_FLAGS_MCOS | PQ_FLAGS_ACK | PQ_FLAGS_OOO |\n\t\t    PQ_FLAGS_OFLD;\n\t\tbreak;\n\tdefault:\n\t\tDP_ERR(p_hwfn,\n\t\t       \"unknown personality %d\\n\", p_hwfn->hw_info.personality);\n\t\treturn 0;\n\t}\n\n\treturn flags;\n}\n\n \nstatic u8 qed_init_qm_get_num_tcs(struct qed_hwfn *p_hwfn)\n{\n\treturn p_hwfn->hw_info.num_hw_tc;\n}\n\nstatic u16 qed_init_qm_get_num_vfs(struct qed_hwfn *p_hwfn)\n{\n\treturn IS_QED_SRIOV(p_hwfn->cdev) ?\n\t       p_hwfn->cdev->p_iov_info->total_vfs : 0;\n}\n\nstatic u8 qed_init_qm_get_num_mtc_tcs(struct qed_hwfn *p_hwfn)\n{\n\tu32 pq_flags = qed_get_pq_flags(p_hwfn);\n\n\tif (!(PQ_FLAGS_MTC & pq_flags))\n\t\treturn 1;\n\n\treturn qed_init_qm_get_num_tcs(p_hwfn);\n}\n\n#define NUM_DEFAULT_RLS 1\n\nstatic u16 qed_init_qm_get_num_pf_rls(struct qed_hwfn *p_hwfn)\n{\n\tu16 num_pf_rls, num_vfs = qed_init_qm_get_num_vfs(p_hwfn);\n\n\t \n\tnum_pf_rls = (u16)min_t(u32, RESC_NUM(p_hwfn, QED_RL),\n\t\t\t\tRESC_NUM(p_hwfn, QED_VPORT));\n\n\t \n\tif (num_pf_rls < num_vfs + NUM_DEFAULT_RLS)\n\t\treturn 0;\n\n\t \n\tnum_pf_rls -= num_vfs + NUM_DEFAULT_RLS;\n\n\treturn num_pf_rls;\n}\n\nstatic u16 qed_init_qm_get_num_vports(struct qed_hwfn *p_hwfn)\n{\n\tu32 pq_flags = qed_get_pq_flags(p_hwfn);\n\n\t \n\treturn (!!(PQ_FLAGS_RLS & pq_flags)) *\n\t       qed_init_qm_get_num_pf_rls(p_hwfn) +\n\t       (!!(PQ_FLAGS_VFS & pq_flags)) *\n\t       qed_init_qm_get_num_vfs(p_hwfn) + 1;\n}\n\n \nstatic u16 qed_init_qm_get_num_pqs(struct qed_hwfn *p_hwfn)\n{\n\tu32 pq_flags = qed_get_pq_flags(p_hwfn);\n\n\treturn (!!(PQ_FLAGS_RLS & pq_flags)) *\n\t       qed_init_qm_get_num_pf_rls(p_hwfn) +\n\t       (!!(PQ_FLAGS_MCOS & pq_flags)) *\n\t       qed_init_qm_get_num_tcs(p_hwfn) +\n\t       (!!(PQ_FLAGS_LB & pq_flags)) + (!!(PQ_FLAGS_OOO & pq_flags)) +\n\t       (!!(PQ_FLAGS_ACK & pq_flags)) +\n\t       (!!(PQ_FLAGS_OFLD & pq_flags)) *\n\t       qed_init_qm_get_num_mtc_tcs(p_hwfn) +\n\t       (!!(PQ_FLAGS_LLT & pq_flags)) *\n\t       qed_init_qm_get_num_mtc_tcs(p_hwfn) +\n\t       (!!(PQ_FLAGS_VFS & pq_flags)) * qed_init_qm_get_num_vfs(p_hwfn);\n}\n\n \nstatic void qed_init_qm_params(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tbool four_port;\n\n\t \n\tqm_info->start_pq = (u16)RESC_START(p_hwfn, QED_PQ);\n\tqm_info->start_vport = (u8)RESC_START(p_hwfn, QED_VPORT);\n\n\t \n\tqm_info->vport_rl_en = true;\n\tqm_info->vport_wfq_en = true;\n\n\t \n\tfour_port = p_hwfn->cdev->num_ports_in_engine == MAX_NUM_PORTS_K2;\n\n\t \n\tqm_info->max_phys_tcs_per_port = four_port ? NUM_PHYS_TCS_4PORT_K2 :\n\t\t\t\t\t\t     NUM_OF_PHYS_TCS;\n\n\t \n\tif (!qm_info->ooo_tc)\n\t\tqm_info->ooo_tc = four_port ? DCBX_TCP_OOO_K2_4PORT_TC :\n\t\t\t\t\t      DCBX_TCP_OOO_TC;\n}\n\n \nstatic void qed_init_qm_vport_params(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tu8 i;\n\n\t \n\tfor (i = 0; i < qed_init_qm_get_num_vports(p_hwfn); i++)\n\t\tqm_info->qm_vport_params[i].wfq = 1;\n}\n\n \nstatic void qed_init_qm_port_params(struct qed_hwfn *p_hwfn)\n{\n\t \n\tu8 i, active_phys_tcs, num_ports = p_hwfn->cdev->num_ports_in_engine;\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\n\t \n\tactive_phys_tcs = num_ports == MAX_NUM_PORTS_K2 ?\n\t\t\t  ACTIVE_TCS_BMAP_4PORT_K2 :\n\t\t\t  ACTIVE_TCS_BMAP;\n\n\tfor (i = 0; i < num_ports; i++) {\n\t\tstruct init_qm_port_params *p_qm_port =\n\t\t    &p_hwfn->qm_info.qm_port_params[i];\n\t\tu16 pbf_max_cmd_lines;\n\n\t\tp_qm_port->active = 1;\n\t\tp_qm_port->active_phys_tcs = active_phys_tcs;\n\t\tpbf_max_cmd_lines = (u16)NUM_OF_PBF_CMD_LINES(cdev);\n\t\tp_qm_port->num_pbf_cmd_lines = pbf_max_cmd_lines / num_ports;\n\t\tp_qm_port->num_btb_blocks = NUM_OF_BTB_BLOCKS(cdev) / num_ports;\n\t}\n}\n\n \nstatic void qed_init_qm_reset_params(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tqm_info->num_pqs = 0;\n\tqm_info->num_vports = 0;\n\tqm_info->num_pf_rls = 0;\n\tqm_info->num_vf_pqs = 0;\n\tqm_info->first_vf_pq = 0;\n\tqm_info->first_mcos_pq = 0;\n\tqm_info->first_rl_pq = 0;\n}\n\nstatic void qed_init_qm_advance_vport(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tqm_info->num_vports++;\n\n\tif (qm_info->num_vports > qed_init_qm_get_num_vports(p_hwfn))\n\t\tDP_ERR(p_hwfn,\n\t\t       \"vport overflow! qm_info->num_vports %d, qm_init_get_num_vports() %d\\n\",\n\t\t       qm_info->num_vports, qed_init_qm_get_num_vports(p_hwfn));\n}\n\n \n\n \n#define PQ_INIT_SHARE_VPORT     BIT(0)\n#define PQ_INIT_PF_RL           BIT(1)\n#define PQ_INIT_VF_RL           BIT(2)\n\n \n#define PQ_INIT_DEFAULT_WRR_GROUP       1\n#define PQ_INIT_DEFAULT_TC              0\n\nvoid qed_hw_info_set_offload_tc(struct qed_hw_info *p_info, u8 tc)\n{\n\tp_info->offload_tc = tc;\n\tp_info->offload_tc_set = true;\n}\n\nstatic bool qed_is_offload_tc_set(struct qed_hwfn *p_hwfn)\n{\n\treturn p_hwfn->hw_info.offload_tc_set;\n}\n\nstatic u32 qed_get_offload_tc(struct qed_hwfn *p_hwfn)\n{\n\tif (qed_is_offload_tc_set(p_hwfn))\n\t\treturn p_hwfn->hw_info.offload_tc;\n\n\treturn PQ_INIT_DEFAULT_TC;\n}\n\nstatic void qed_init_qm_pq(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_qm_info *qm_info,\n\t\t\t   u8 tc, u32 pq_init_flags)\n{\n\tu16 pq_idx = qm_info->num_pqs, max_pq = qed_init_qm_get_num_pqs(p_hwfn);\n\n\tif (pq_idx > max_pq)\n\t\tDP_ERR(p_hwfn,\n\t\t       \"pq overflow! pq %d, max pq %d\\n\", pq_idx, max_pq);\n\n\t \n\tqm_info->qm_pq_params[pq_idx].port_id = p_hwfn->port_id;\n\tqm_info->qm_pq_params[pq_idx].vport_id = qm_info->start_vport +\n\t    qm_info->num_vports;\n\tqm_info->qm_pq_params[pq_idx].tc_id = tc;\n\tqm_info->qm_pq_params[pq_idx].wrr_group = PQ_INIT_DEFAULT_WRR_GROUP;\n\tqm_info->qm_pq_params[pq_idx].rl_valid =\n\t    (pq_init_flags & PQ_INIT_PF_RL || pq_init_flags & PQ_INIT_VF_RL);\n\n\t \n\tqm_info->num_pqs++;\n\tif (!(pq_init_flags & PQ_INIT_SHARE_VPORT))\n\t\tqm_info->num_vports++;\n\n\tif (pq_init_flags & PQ_INIT_PF_RL)\n\t\tqm_info->num_pf_rls++;\n\n\tif (qm_info->num_vports > qed_init_qm_get_num_vports(p_hwfn))\n\t\tDP_ERR(p_hwfn,\n\t\t       \"vport overflow! qm_info->num_vports %d, qm_init_get_num_vports() %d\\n\",\n\t\t       qm_info->num_vports, qed_init_qm_get_num_vports(p_hwfn));\n\n\tif (qm_info->num_pf_rls > qed_init_qm_get_num_pf_rls(p_hwfn))\n\t\tDP_ERR(p_hwfn,\n\t\t       \"rl overflow! qm_info->num_pf_rls %d, qm_init_get_num_pf_rls() %d\\n\",\n\t\t       qm_info->num_pf_rls, qed_init_qm_get_num_pf_rls(p_hwfn));\n}\n\n \nstatic u16 *qed_init_qm_get_idx_from_flags(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t   unsigned long pq_flags)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\t \n\tif (bitmap_weight(&pq_flags,\n\t\t\t  sizeof(pq_flags) * BITS_PER_BYTE) > 1) {\n\t\tDP_ERR(p_hwfn, \"requested multiple pq flags 0x%lx\\n\", pq_flags);\n\t\tgoto err;\n\t}\n\n\tif (!(qed_get_pq_flags(p_hwfn) & pq_flags)) {\n\t\tDP_ERR(p_hwfn, \"pq flag 0x%lx is not set\\n\", pq_flags);\n\t\tgoto err;\n\t}\n\n\tswitch (pq_flags) {\n\tcase PQ_FLAGS_RLS:\n\t\treturn &qm_info->first_rl_pq;\n\tcase PQ_FLAGS_MCOS:\n\t\treturn &qm_info->first_mcos_pq;\n\tcase PQ_FLAGS_LB:\n\t\treturn &qm_info->pure_lb_pq;\n\tcase PQ_FLAGS_OOO:\n\t\treturn &qm_info->ooo_pq;\n\tcase PQ_FLAGS_ACK:\n\t\treturn &qm_info->pure_ack_pq;\n\tcase PQ_FLAGS_OFLD:\n\t\treturn &qm_info->first_ofld_pq;\n\tcase PQ_FLAGS_LLT:\n\t\treturn &qm_info->first_llt_pq;\n\tcase PQ_FLAGS_VFS:\n\t\treturn &qm_info->first_vf_pq;\n\tdefault:\n\t\tgoto err;\n\t}\n\nerr:\n\treturn &qm_info->start_pq;\n}\n\n \nstatic void qed_init_qm_set_idx(struct qed_hwfn *p_hwfn,\n\t\t\t\tu32 pq_flags, u16 pq_val)\n{\n\tu16 *base_pq_idx = qed_init_qm_get_idx_from_flags(p_hwfn, pq_flags);\n\n\t*base_pq_idx = p_hwfn->qm_info.start_pq + pq_val;\n}\n\n \nu16 qed_get_cm_pq_idx(struct qed_hwfn *p_hwfn, u32 pq_flags)\n{\n\tu16 *base_pq_idx = qed_init_qm_get_idx_from_flags(p_hwfn, pq_flags);\n\n\treturn *base_pq_idx + CM_TX_PQ_BASE;\n}\n\nu16 qed_get_cm_pq_idx_mcos(struct qed_hwfn *p_hwfn, u8 tc)\n{\n\tu8 max_tc = qed_init_qm_get_num_tcs(p_hwfn);\n\n\tif (max_tc == 0) {\n\t\tDP_ERR(p_hwfn, \"pq with flag 0x%lx do not exist\\n\",\n\t\t       PQ_FLAGS_MCOS);\n\t\treturn p_hwfn->qm_info.start_pq;\n\t}\n\n\tif (tc > max_tc)\n\t\tDP_ERR(p_hwfn, \"tc %d must be smaller than %d\\n\", tc, max_tc);\n\n\treturn qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_MCOS) + (tc % max_tc);\n}\n\nu16 qed_get_cm_pq_idx_vf(struct qed_hwfn *p_hwfn, u16 vf)\n{\n\tu16 max_vf = qed_init_qm_get_num_vfs(p_hwfn);\n\n\tif (max_vf == 0) {\n\t\tDP_ERR(p_hwfn, \"pq with flag 0x%lx do not exist\\n\",\n\t\t       PQ_FLAGS_VFS);\n\t\treturn p_hwfn->qm_info.start_pq;\n\t}\n\n\tif (vf > max_vf)\n\t\tDP_ERR(p_hwfn, \"vf %d must be smaller than %d\\n\", vf, max_vf);\n\n\treturn qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_VFS) + (vf % max_vf);\n}\n\nu16 qed_get_cm_pq_idx_ofld_mtc(struct qed_hwfn *p_hwfn, u8 tc)\n{\n\tu16 first_ofld_pq, pq_offset;\n\n\tfirst_ofld_pq = qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_OFLD);\n\tpq_offset = (tc < qed_init_qm_get_num_mtc_tcs(p_hwfn)) ?\n\t\t    tc : PQ_INIT_DEFAULT_TC;\n\n\treturn first_ofld_pq + pq_offset;\n}\n\nu16 qed_get_cm_pq_idx_llt_mtc(struct qed_hwfn *p_hwfn, u8 tc)\n{\n\tu16 first_llt_pq, pq_offset;\n\n\tfirst_llt_pq = qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_LLT);\n\tpq_offset = (tc < qed_init_qm_get_num_mtc_tcs(p_hwfn)) ?\n\t\t    tc : PQ_INIT_DEFAULT_TC;\n\n\treturn first_llt_pq + pq_offset;\n}\n\n \nstatic void qed_init_qm_lb_pq(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_LB))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_LB, qm_info->num_pqs);\n\tqed_init_qm_pq(p_hwfn, qm_info, PURE_LB_TC, PQ_INIT_SHARE_VPORT);\n}\n\nstatic void qed_init_qm_ooo_pq(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_OOO))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_OOO, qm_info->num_pqs);\n\tqed_init_qm_pq(p_hwfn, qm_info, qm_info->ooo_tc, PQ_INIT_SHARE_VPORT);\n}\n\nstatic void qed_init_qm_pure_ack_pq(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_ACK))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_ACK, qm_info->num_pqs);\n\tqed_init_qm_pq(p_hwfn, qm_info, qed_get_offload_tc(p_hwfn),\n\t\t       PQ_INIT_SHARE_VPORT);\n}\n\nstatic void qed_init_qm_mtc_pqs(struct qed_hwfn *p_hwfn)\n{\n\tu8 num_tcs = qed_init_qm_get_num_mtc_tcs(p_hwfn);\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tu8 tc;\n\n\t \n\tfor (tc = 0; tc < num_tcs; tc++)\n\t\tqed_init_qm_pq(p_hwfn, qm_info,\n\t\t\t       qed_is_offload_tc_set(p_hwfn) ?\n\t\t\t       p_hwfn->hw_info.offload_tc : tc,\n\t\t\t       PQ_INIT_SHARE_VPORT);\n}\n\nstatic void qed_init_qm_offload_pq(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_OFLD))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_OFLD, qm_info->num_pqs);\n\tqed_init_qm_mtc_pqs(p_hwfn);\n}\n\nstatic void qed_init_qm_low_latency_pq(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_LLT))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_LLT, qm_info->num_pqs);\n\tqed_init_qm_mtc_pqs(p_hwfn);\n}\n\nstatic void qed_init_qm_mcos_pqs(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tu8 tc_idx;\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_MCOS))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_MCOS, qm_info->num_pqs);\n\tfor (tc_idx = 0; tc_idx < qed_init_qm_get_num_tcs(p_hwfn); tc_idx++)\n\t\tqed_init_qm_pq(p_hwfn, qm_info, tc_idx, PQ_INIT_SHARE_VPORT);\n}\n\nstatic void qed_init_qm_vf_pqs(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tu16 vf_idx, num_vfs = qed_init_qm_get_num_vfs(p_hwfn);\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_VFS))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_VFS, qm_info->num_pqs);\n\tqm_info->num_vf_pqs = num_vfs;\n\tfor (vf_idx = 0; vf_idx < num_vfs; vf_idx++)\n\t\tqed_init_qm_pq(p_hwfn,\n\t\t\t       qm_info, PQ_INIT_DEFAULT_TC, PQ_INIT_VF_RL);\n}\n\nstatic void qed_init_qm_rl_pqs(struct qed_hwfn *p_hwfn)\n{\n\tu16 pf_rls_idx, num_pf_rls = qed_init_qm_get_num_pf_rls(p_hwfn);\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\n\tif (!(qed_get_pq_flags(p_hwfn) & PQ_FLAGS_RLS))\n\t\treturn;\n\n\tqed_init_qm_set_idx(p_hwfn, PQ_FLAGS_RLS, qm_info->num_pqs);\n\tfor (pf_rls_idx = 0; pf_rls_idx < num_pf_rls; pf_rls_idx++)\n\t\tqed_init_qm_pq(p_hwfn, qm_info, qed_get_offload_tc(p_hwfn),\n\t\t\t       PQ_INIT_PF_RL);\n}\n\nstatic void qed_init_qm_pq_params(struct qed_hwfn *p_hwfn)\n{\n\t \n\tqed_init_qm_rl_pqs(p_hwfn);\n\n\t \n\tqed_init_qm_mcos_pqs(p_hwfn);\n\n\t \n\tqed_init_qm_lb_pq(p_hwfn);\n\n\t \n\tqed_init_qm_ooo_pq(p_hwfn);\n\n\t \n\tqed_init_qm_pure_ack_pq(p_hwfn);\n\n\t \n\tqed_init_qm_offload_pq(p_hwfn);\n\n\t \n\tqed_init_qm_low_latency_pq(p_hwfn);\n\n\t \n\tqed_init_qm_advance_vport(p_hwfn);\n\n\t \n\tqed_init_qm_vf_pqs(p_hwfn);\n}\n\n \nstatic int qed_init_qm_sanity(struct qed_hwfn *p_hwfn)\n{\n\tif (qed_init_qm_get_num_vports(p_hwfn) > RESC_NUM(p_hwfn, QED_VPORT)) {\n\t\tDP_ERR(p_hwfn, \"requested amount of vports exceeds resource\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (qed_init_qm_get_num_pqs(p_hwfn) <= RESC_NUM(p_hwfn, QED_PQ))\n\t\treturn 0;\n\n\tif (QED_IS_ROCE_PERSONALITY(p_hwfn)) {\n\t\tp_hwfn->hw_info.multi_tc_roce_en = false;\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"multi-tc roce was disabled to reduce requested amount of pqs\\n\");\n\t\tif (qed_init_qm_get_num_pqs(p_hwfn) <= RESC_NUM(p_hwfn, QED_PQ))\n\t\t\treturn 0;\n\t}\n\n\tDP_ERR(p_hwfn, \"requested amount of pqs exceeds resource\\n\");\n\treturn -EINVAL;\n}\n\nstatic void qed_dp_init_qm_params(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tstruct init_qm_vport_params *vport;\n\tstruct init_qm_port_params *port;\n\tstruct init_qm_pq_params *pq;\n\tint i, tc;\n\n\t \n\tDP_VERBOSE(p_hwfn,\n\t\t   NETIF_MSG_HW,\n\t\t   \"qm init top level params: start_pq %d, start_vport %d, pure_lb_pq %d, offload_pq %d, llt_pq %d, pure_ack_pq %d\\n\",\n\t\t   qm_info->start_pq,\n\t\t   qm_info->start_vport,\n\t\t   qm_info->pure_lb_pq,\n\t\t   qm_info->first_ofld_pq,\n\t\t   qm_info->first_llt_pq,\n\t\t   qm_info->pure_ack_pq);\n\tDP_VERBOSE(p_hwfn,\n\t\t   NETIF_MSG_HW,\n\t\t   \"ooo_pq %d, first_vf_pq %d, num_pqs %d, num_vf_pqs %d, num_vports %d, max_phys_tcs_per_port %d\\n\",\n\t\t   qm_info->ooo_pq,\n\t\t   qm_info->first_vf_pq,\n\t\t   qm_info->num_pqs,\n\t\t   qm_info->num_vf_pqs,\n\t\t   qm_info->num_vports, qm_info->max_phys_tcs_per_port);\n\tDP_VERBOSE(p_hwfn,\n\t\t   NETIF_MSG_HW,\n\t\t   \"pf_rl_en %d, pf_wfq_en %d, vport_rl_en %d, vport_wfq_en %d, pf_wfq %d, pf_rl %d, num_pf_rls %d, pq_flags %x\\n\",\n\t\t   qm_info->pf_rl_en,\n\t\t   qm_info->pf_wfq_en,\n\t\t   qm_info->vport_rl_en,\n\t\t   qm_info->vport_wfq_en,\n\t\t   qm_info->pf_wfq,\n\t\t   qm_info->pf_rl,\n\t\t   qm_info->num_pf_rls, qed_get_pq_flags(p_hwfn));\n\n\t \n\tfor (i = 0; i < p_hwfn->cdev->num_ports_in_engine; i++) {\n\t\tport = &(qm_info->qm_port_params[i]);\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   NETIF_MSG_HW,\n\t\t\t   \"port idx %d, active %d, active_phys_tcs %d, num_pbf_cmd_lines %d, num_btb_blocks %d, reserved %d\\n\",\n\t\t\t   i,\n\t\t\t   port->active,\n\t\t\t   port->active_phys_tcs,\n\t\t\t   port->num_pbf_cmd_lines,\n\t\t\t   port->num_btb_blocks, port->reserved);\n\t}\n\n\t \n\tfor (i = 0; i < qm_info->num_vports; i++) {\n\t\tvport = &(qm_info->qm_vport_params[i]);\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   NETIF_MSG_HW,\n\t\t\t   \"vport idx %d, wfq %d, first_tx_pq_id [ \",\n\t\t\t   qm_info->start_vport + i, vport->wfq);\n\t\tfor (tc = 0; tc < NUM_OF_TCS; tc++)\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   NETIF_MSG_HW,\n\t\t\t\t   \"%d \", vport->first_tx_pq_id[tc]);\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_HW, \"]\\n\");\n\t}\n\n\t \n\tfor (i = 0; i < qm_info->num_pqs; i++) {\n\t\tpq = &(qm_info->qm_pq_params[i]);\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   NETIF_MSG_HW,\n\t\t\t   \"pq idx %d, port %d, vport_id %d, tc %d, wrr_grp %d, rl_valid %d rl_id %d\\n\",\n\t\t\t   qm_info->start_pq + i,\n\t\t\t   pq->port_id,\n\t\t\t   pq->vport_id,\n\t\t\t   pq->tc_id, pq->wrr_group, pq->rl_valid, pq->rl_id);\n\t}\n}\n\nstatic void qed_init_qm_info(struct qed_hwfn *p_hwfn)\n{\n\t \n\tqed_init_qm_reset_params(p_hwfn);\n\n\t \n\tqed_init_qm_params(p_hwfn);\n\n\t \n\tqed_init_qm_port_params(p_hwfn);\n\n\t \n\tqed_init_qm_vport_params(p_hwfn);\n\n\t \n\tqed_init_qm_pq_params(p_hwfn);\n\n\t \n\tqed_dp_init_qm_params(p_hwfn);\n}\n\n \nint qed_qm_reconf(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tbool b_rc;\n\tint rc;\n\n\t \n\tqed_init_qm_info(p_hwfn);\n\n\t \n\tspin_lock_bh(&qm_lock);\n\tb_rc = qed_send_qm_stop_cmd(p_hwfn, p_ptt, false, true,\n\t\t\t\t    qm_info->start_pq, qm_info->num_pqs);\n\tspin_unlock_bh(&qm_lock);\n\tif (!b_rc)\n\t\treturn -EINVAL;\n\n\t \n\tqed_qm_init_pf(p_hwfn, p_ptt, false);\n\n\t \n\trc = qed_init_run(p_hwfn, p_ptt, PHASE_QM_PF, p_hwfn->rel_pf_id,\n\t\t\t  p_hwfn->hw_info.hw_mode);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tspin_lock_bh(&qm_lock);\n\tb_rc = qed_send_qm_stop_cmd(p_hwfn, p_ptt, true, true,\n\t\t\t\t    qm_info->start_pq, qm_info->num_pqs);\n\tspin_unlock_bh(&qm_lock);\n\tif (!b_rc)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int qed_alloc_qm_data(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tint rc;\n\n\trc = qed_init_qm_sanity(p_hwfn);\n\tif (rc)\n\t\tgoto alloc_err;\n\n\tqm_info->qm_pq_params = kcalloc(qed_init_qm_get_num_pqs(p_hwfn),\n\t\t\t\t\tsizeof(*qm_info->qm_pq_params),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!qm_info->qm_pq_params)\n\t\tgoto alloc_err;\n\n\tqm_info->qm_vport_params = kcalloc(qed_init_qm_get_num_vports(p_hwfn),\n\t\t\t\t\t   sizeof(*qm_info->qm_vport_params),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!qm_info->qm_vport_params)\n\t\tgoto alloc_err;\n\n\tqm_info->qm_port_params = kcalloc(p_hwfn->cdev->num_ports_in_engine,\n\t\t\t\t\t  sizeof(*qm_info->qm_port_params),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!qm_info->qm_port_params)\n\t\tgoto alloc_err;\n\n\tqm_info->wfq_data = kcalloc(qed_init_qm_get_num_vports(p_hwfn),\n\t\t\t\t    sizeof(*qm_info->wfq_data),\n\t\t\t\t    GFP_KERNEL);\n\tif (!qm_info->wfq_data)\n\t\tgoto alloc_err;\n\n\treturn 0;\n\nalloc_err:\n\tDP_NOTICE(p_hwfn, \"Failed to allocate memory for QM params\\n\");\n\tqed_qm_info_free(p_hwfn);\n\treturn -ENOMEM;\n}\n\nint qed_resc_alloc(struct qed_dev *cdev)\n{\n\tu32 rdma_tasks, excess_tasks;\n\tu32 line_count;\n\tint i, rc = 0;\n\n\tif (IS_VF(cdev)) {\n\t\tfor_each_hwfn(cdev, i) {\n\t\t\trc = qed_l2_alloc(&cdev->hwfns[i]);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t}\n\t\treturn rc;\n\t}\n\n\tcdev->fw_data = kzalloc(sizeof(*cdev->fw_data), GFP_KERNEL);\n\tif (!cdev->fw_data)\n\t\treturn -ENOMEM;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tu32 n_eqes, num_cons;\n\n\t\t \n\t\trc = qed_db_recovery_setup(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\t \n\t\trc = qed_cxt_mngr_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\t \n\t\trc = qed_cxt_set_pf_params(p_hwfn, RDMA_MAX_TIDS);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\trc = qed_alloc_qm_data(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\t \n\t\tqed_init_qm_info(p_hwfn);\n\n\t\t \n\t\trc = qed_cxt_cfg_ilt_compute(p_hwfn, &line_count);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"too many ILT lines; re-computing with less lines\\n\");\n\t\t\t \n\t\t\texcess_tasks =\n\t\t\t    qed_cxt_cfg_ilt_compute_excess(p_hwfn, line_count);\n\t\t\tif (!excess_tasks)\n\t\t\t\tgoto alloc_err;\n\n\t\t\trdma_tasks = RDMA_MAX_TIDS - excess_tasks;\n\t\t\trc = qed_cxt_set_pf_params(p_hwfn, rdma_tasks);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\n\t\t\trc = qed_cxt_cfg_ilt_compute(p_hwfn, &line_count);\n\t\t\tif (rc) {\n\t\t\t\tDP_ERR(p_hwfn,\n\t\t\t\t       \"failed ILT compute. Requested too many lines: %u\\n\",\n\t\t\t\t       line_count);\n\n\t\t\t\tgoto alloc_err;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\trc = qed_cxt_tables_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\t \n\t\trc = qed_spq_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\t \n\t\tp_hwfn->p_dpc_ptt = qed_get_reserved_ptt(p_hwfn,\n\t\t\t\t\t\t\t RESERVED_PTT_DPC);\n\n\t\trc = qed_int_alloc(p_hwfn, p_hwfn->p_main_ptt);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\trc = qed_iov_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\t \n\t\tn_eqes = qed_chain_get_capacity(&p_hwfn->p_spq->chain);\n\t\tif (QED_IS_RDMA_PERSONALITY(p_hwfn)) {\n\t\t\tu32 n_srq = qed_cxt_get_total_srq_count(p_hwfn);\n\t\t\tenum protocol_type rdma_proto;\n\n\t\t\tif (QED_IS_ROCE_PERSONALITY(p_hwfn))\n\t\t\t\trdma_proto = PROTOCOLID_ROCE;\n\t\t\telse\n\t\t\t\trdma_proto = PROTOCOLID_IWARP;\n\n\t\t\tnum_cons = qed_cxt_get_proto_cid_count(p_hwfn,\n\t\t\t\t\t\t\t       rdma_proto,\n\t\t\t\t\t\t\t       NULL) * 2;\n\t\t\t \n\t\t\tn_eqes += num_cons + 2 * MAX_NUM_VFS_BB + n_srq;\n\t\t} else if (p_hwfn->hw_info.personality == QED_PCI_ISCSI ||\n\t\t\t   p_hwfn->hw_info.personality == QED_PCI_NVMETCP) {\n\t\t\tnum_cons =\n\t\t\t    qed_cxt_get_proto_cid_count(p_hwfn,\n\t\t\t\t\t\t\tPROTOCOLID_TCP_ULP,\n\t\t\t\t\t\t\tNULL);\n\t\t\tn_eqes += 2 * num_cons;\n\t\t}\n\n\t\tif (n_eqes > 0xFFFF) {\n\t\t\tDP_ERR(p_hwfn,\n\t\t\t       \"Cannot allocate 0x%x EQ elements. The maximum of a u16 chain is 0x%x\\n\",\n\t\t\t       n_eqes, 0xFFFF);\n\t\t\tgoto alloc_no_mem;\n\t\t}\n\n\t\trc = qed_eq_alloc(p_hwfn, (u16)n_eqes);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\trc = qed_consq_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\trc = qed_l2_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n#ifdef CONFIG_QED_LL2\n\t\tif (p_hwfn->using_ll2) {\n\t\t\trc = qed_ll2_alloc(p_hwfn);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\t\t}\n#endif\n\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_FCOE) {\n\t\t\trc = qed_fcoe_alloc(p_hwfn);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\t\t}\n\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_ISCSI) {\n\t\t\trc = qed_iscsi_alloc(p_hwfn);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\t\t\trc = qed_ooo_alloc(p_hwfn);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\t\t}\n\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_NVMETCP) {\n\t\t\trc = qed_nvmetcp_alloc(p_hwfn);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\t\t\trc = qed_ooo_alloc(p_hwfn);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\t\t}\n\n\t\tif (QED_IS_RDMA_PERSONALITY(p_hwfn)) {\n\t\t\trc = qed_rdma_info_alloc(p_hwfn);\n\t\t\tif (rc)\n\t\t\t\tgoto alloc_err;\n\t\t}\n\n\t\t \n\t\trc = qed_dmae_info_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\t \n\t\trc = qed_dcbx_info_alloc(p_hwfn);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\n\t\trc = qed_dbg_alloc_user_data(p_hwfn, &p_hwfn->dbg_user_info);\n\t\tif (rc)\n\t\t\tgoto alloc_err;\n\t}\n\n\trc = qed_llh_alloc(cdev);\n\tif (rc) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Failed to allocate memory for the llh_info structure\\n\");\n\t\tgoto alloc_err;\n\t}\n\n\tcdev->reset_stats = kzalloc(sizeof(*cdev->reset_stats), GFP_KERNEL);\n\tif (!cdev->reset_stats)\n\t\tgoto alloc_no_mem;\n\n\treturn 0;\n\nalloc_no_mem:\n\trc = -ENOMEM;\nalloc_err:\n\tqed_resc_free(cdev);\n\treturn rc;\n}\n\nstatic int qed_fw_err_handler(struct qed_hwfn *p_hwfn,\n\t\t\t      u8 opcode,\n\t\t\t      u16 echo,\n\t\t\t      union event_ring_data *data, u8 fw_return_code)\n{\n\tif (fw_return_code != COMMON_ERR_CODE_ERROR)\n\t\tgoto eqe_unexpected;\n\n\tif (data->err_data.recovery_scope == ERR_SCOPE_FUNC &&\n\t    le16_to_cpu(data->err_data.entity_id) >= MAX_NUM_PFS) {\n\t\tqed_sriov_vfpf_malicious(p_hwfn, &data->err_data);\n\t\treturn 0;\n\t}\n\neqe_unexpected:\n\tDP_ERR(p_hwfn,\n\t       \"Skipping unexpected eqe 0x%02x, FW return code 0x%x, echo 0x%x\\n\",\n\t       opcode, fw_return_code, echo);\n\treturn -EINVAL;\n}\n\nstatic int qed_common_eqe_event(struct qed_hwfn *p_hwfn,\n\t\t\t\tu8 opcode,\n\t\t\t\t__le16 echo,\n\t\t\t\tunion event_ring_data *data,\n\t\t\t\tu8 fw_return_code)\n{\n\tswitch (opcode) {\n\tcase COMMON_EVENT_VF_PF_CHANNEL:\n\tcase COMMON_EVENT_VF_FLR:\n\t\treturn qed_sriov_eqe_event(p_hwfn, opcode, echo, data,\n\t\t\t\t\t   fw_return_code);\n\tcase COMMON_EVENT_FW_ERROR:\n\t\treturn qed_fw_err_handler(p_hwfn, opcode,\n\t\t\t\t\t  le16_to_cpu(echo), data,\n\t\t\t\t\t  fw_return_code);\n\tdefault:\n\t\tDP_INFO(p_hwfn->cdev, \"Unknown eqe event 0x%02x, echo 0x%x\\n\",\n\t\t\topcode, echo);\n\t\treturn -EINVAL;\n\t}\n}\n\nvoid qed_resc_setup(struct qed_dev *cdev)\n{\n\tint i;\n\n\tif (IS_VF(cdev)) {\n\t\tfor_each_hwfn(cdev, i)\n\t\t\tqed_l2_setup(&cdev->hwfns[i]);\n\t\treturn;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tqed_cxt_mngr_setup(p_hwfn);\n\t\tqed_spq_setup(p_hwfn);\n\t\tqed_eq_setup(p_hwfn);\n\t\tqed_consq_setup(p_hwfn);\n\n\t\t \n\t\tqed_mcp_read_mb(p_hwfn, p_hwfn->p_main_ptt);\n\t\tmemcpy(p_hwfn->mcp_info->mfw_mb_shadow,\n\t\t       p_hwfn->mcp_info->mfw_mb_cur,\n\t\t       p_hwfn->mcp_info->mfw_mb_length);\n\n\t\tqed_int_setup(p_hwfn, p_hwfn->p_main_ptt);\n\n\t\tqed_l2_setup(p_hwfn);\n\t\tqed_iov_setup(p_hwfn);\n\t\tqed_spq_register_async_cb(p_hwfn, PROTOCOLID_COMMON,\n\t\t\t\t\t  qed_common_eqe_event);\n#ifdef CONFIG_QED_LL2\n\t\tif (p_hwfn->using_ll2)\n\t\t\tqed_ll2_setup(p_hwfn);\n#endif\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_FCOE)\n\t\t\tqed_fcoe_setup(p_hwfn);\n\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_ISCSI) {\n\t\t\tqed_iscsi_setup(p_hwfn);\n\t\t\tqed_ooo_setup(p_hwfn);\n\t\t}\n\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_NVMETCP) {\n\t\t\tqed_nvmetcp_setup(p_hwfn);\n\t\t\tqed_ooo_setup(p_hwfn);\n\t\t}\n\t}\n}\n\n#define FINAL_CLEANUP_POLL_CNT          (100)\n#define FINAL_CLEANUP_POLL_TIME         (10)\nint qed_final_cleanup(struct qed_hwfn *p_hwfn,\n\t\t      struct qed_ptt *p_ptt, u16 id, bool is_vf)\n{\n\tu32 command = 0, addr, count = FINAL_CLEANUP_POLL_CNT;\n\tint rc = -EBUSY;\n\n\taddr = GET_GTT_REG_ADDR(GTT_BAR0_MAP_REG_USDM_RAM,\n\t\t\t\tUSTORM_FLR_FINAL_ACK, p_hwfn->rel_pf_id);\n\tif (is_vf)\n\t\tid += 0x10;\n\n\tcommand |= X_FINAL_CLEANUP_AGG_INT <<\n\t\tSDM_AGG_INT_COMP_PARAMS_AGG_INT_INDEX_SHIFT;\n\tcommand |= 1 << SDM_AGG_INT_COMP_PARAMS_AGG_VECTOR_ENABLE_SHIFT;\n\tcommand |= id << SDM_AGG_INT_COMP_PARAMS_AGG_VECTOR_BIT_SHIFT;\n\tcommand |= SDM_COMP_TYPE_AGG_INT << SDM_OP_GEN_COMP_TYPE_SHIFT;\n\n\t \n\tif (REG_RD(p_hwfn, addr)) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unexpected; Found final cleanup notification before initiating final cleanup\\n\");\n\t\tREG_WR(p_hwfn, addr, 0);\n\t}\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t   \"Sending final cleanup for PFVF[%d] [Command %08x]\\n\",\n\t\t   id, command);\n\n\tqed_wr(p_hwfn, p_ptt, XSDM_REG_OPERATION_GEN, command);\n\n\t \n\twhile (!REG_RD(p_hwfn, addr) && count--)\n\t\tmsleep(FINAL_CLEANUP_POLL_TIME);\n\n\tif (REG_RD(p_hwfn, addr))\n\t\trc = 0;\n\telse\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to receive FW final cleanup notification\\n\");\n\n\t \n\tREG_WR(p_hwfn, addr, 0);\n\n\treturn rc;\n}\n\nstatic int qed_calc_hw_mode(struct qed_hwfn *p_hwfn)\n{\n\tint hw_mode = 0;\n\n\tif (QED_IS_BB_B0(p_hwfn->cdev)) {\n\t\thw_mode |= 1 << MODE_BB;\n\t} else if (QED_IS_AH(p_hwfn->cdev)) {\n\t\thw_mode |= 1 << MODE_K2;\n\t} else {\n\t\tDP_NOTICE(p_hwfn, \"Unknown chip type %#x\\n\",\n\t\t\t  p_hwfn->cdev->type);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (p_hwfn->cdev->num_ports_in_engine) {\n\tcase 1:\n\t\thw_mode |= 1 << MODE_PORTS_PER_ENG_1;\n\t\tbreak;\n\tcase 2:\n\t\thw_mode |= 1 << MODE_PORTS_PER_ENG_2;\n\t\tbreak;\n\tcase 4:\n\t\thw_mode |= 1 << MODE_PORTS_PER_ENG_4;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"num_ports_in_engine = %d not supported\\n\",\n\t\t\t  p_hwfn->cdev->num_ports_in_engine);\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_bit(QED_MF_OVLAN_CLSS, &p_hwfn->cdev->mf_bits))\n\t\thw_mode |= 1 << MODE_MF_SD;\n\telse\n\t\thw_mode |= 1 << MODE_MF_SI;\n\n\thw_mode |= 1 << MODE_ASIC;\n\n\tif (p_hwfn->cdev->num_hwfns > 1)\n\t\thw_mode |= 1 << MODE_100G;\n\n\tp_hwfn->hw_info.hw_mode = hw_mode;\n\n\tDP_VERBOSE(p_hwfn, (NETIF_MSG_PROBE | NETIF_MSG_IFUP),\n\t\t   \"Configuring function for hw_mode: 0x%08x\\n\",\n\t\t   p_hwfn->hw_info.hw_mode);\n\n\treturn 0;\n}\n\n \nstatic void qed_init_cau_rt_data(struct qed_dev *cdev)\n{\n\tu32 offset = CAU_REG_SB_VAR_MEMORY_RT_OFFSET;\n\tint i, igu_sb_id;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tstruct qed_igu_info *p_igu_info;\n\t\tstruct qed_igu_block *p_block;\n\t\tstruct cau_sb_entry sb_entry;\n\n\t\tp_igu_info = p_hwfn->hw_info.p_igu_info;\n\n\t\tfor (igu_sb_id = 0;\n\t\t     igu_sb_id < QED_MAPPING_MEMORY_SIZE(cdev); igu_sb_id++) {\n\t\t\tp_block = &p_igu_info->entry[igu_sb_id];\n\n\t\t\tif (!p_block->is_pf)\n\t\t\t\tcontinue;\n\n\t\t\tqed_init_cau_sb_entry(p_hwfn, &sb_entry,\n\t\t\t\t\t      p_block->function_id, 0, 0);\n\t\t\tSTORE_RT_REG_AGG(p_hwfn, offset + igu_sb_id * 2,\n\t\t\t\t\t sb_entry);\n\t\t}\n\t}\n}\n\nstatic void qed_init_cache_line_size(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt)\n{\n\tu32 val, wr_mbs, cache_line_size;\n\n\tval = qed_rd(p_hwfn, p_ptt, PSWRQ2_REG_WR_MBS0);\n\tswitch (val) {\n\tcase 0:\n\t\twr_mbs = 128;\n\t\tbreak;\n\tcase 1:\n\t\twr_mbs = 256;\n\t\tbreak;\n\tcase 2:\n\t\twr_mbs = 512;\n\t\tbreak;\n\tdefault:\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Unexpected value of PSWRQ2_REG_WR_MBS0 [0x%x]. Avoid configuring PGLUE_B_REG_CACHE_LINE_SIZE.\\n\",\n\t\t\tval);\n\t\treturn;\n\t}\n\n\tcache_line_size = min_t(u32, L1_CACHE_BYTES, wr_mbs);\n\tswitch (cache_line_size) {\n\tcase 32:\n\t\tval = 0;\n\t\tbreak;\n\tcase 64:\n\t\tval = 1;\n\t\tbreak;\n\tcase 128:\n\t\tval = 2;\n\t\tbreak;\n\tcase 256:\n\t\tval = 3;\n\t\tbreak;\n\tdefault:\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Unexpected value of cache line size [0x%x]. Avoid configuring PGLUE_B_REG_CACHE_LINE_SIZE.\\n\",\n\t\t\tcache_line_size);\n\t}\n\n\tif (wr_mbs < L1_CACHE_BYTES)\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"The cache line size for padding is suboptimal for performance [OS cache line size 0x%x, wr mbs 0x%x]\\n\",\n\t\t\tL1_CACHE_BYTES, wr_mbs);\n\n\tSTORE_RT_REG(p_hwfn, PGLUE_REG_B_CACHE_LINE_SIZE_RT_OFFSET, val);\n\tif (val > 0) {\n\t\tSTORE_RT_REG(p_hwfn, PSWRQ2_REG_DRAM_ALIGN_WR_RT_OFFSET, val);\n\t\tSTORE_RT_REG(p_hwfn, PSWRQ2_REG_DRAM_ALIGN_RD_RT_OFFSET, val);\n\t}\n}\n\nstatic int qed_hw_init_common(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_ptt *p_ptt, int hw_mode)\n{\n\tstruct qed_qm_info *qm_info = &p_hwfn->qm_info;\n\tstruct qed_qm_common_rt_init_params *params;\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tu8 vf_id, max_num_vfs;\n\tu16 num_pfs, pf_id;\n\tu32 concrete_fid;\n\tint rc = 0;\n\n\tparams = kzalloc(sizeof(*params), GFP_KERNEL);\n\tif (!params) {\n\t\tDP_NOTICE(p_hwfn->cdev,\n\t\t\t  \"Failed to allocate common init params\\n\");\n\n\t\treturn -ENOMEM;\n\t}\n\n\tqed_init_cau_rt_data(cdev);\n\n\t \n\tqed_gtt_init(p_hwfn);\n\n\tif (p_hwfn->mcp_info) {\n\t\tif (p_hwfn->mcp_info->func_info.bandwidth_max)\n\t\t\tqm_info->pf_rl_en = true;\n\t\tif (p_hwfn->mcp_info->func_info.bandwidth_min)\n\t\t\tqm_info->pf_wfq_en = true;\n\t}\n\n\tparams->max_ports_per_engine = p_hwfn->cdev->num_ports_in_engine;\n\tparams->max_phys_tcs_per_port = qm_info->max_phys_tcs_per_port;\n\tparams->pf_rl_en = qm_info->pf_rl_en;\n\tparams->pf_wfq_en = qm_info->pf_wfq_en;\n\tparams->global_rl_en = qm_info->vport_rl_en;\n\tparams->vport_wfq_en = qm_info->vport_wfq_en;\n\tparams->port_params = qm_info->qm_port_params;\n\n\tqed_qm_common_rt_init(p_hwfn, params);\n\n\tqed_cxt_hw_init_common(p_hwfn);\n\n\tqed_init_cache_line_size(p_hwfn, p_ptt);\n\n\trc = qed_init_run(p_hwfn, p_ptt, PHASE_ENGINE, ANY_PHASE_ID, hw_mode);\n\tif (rc)\n\t\tgoto out;\n\n\tqed_wr(p_hwfn, p_ptt, PSWRQ2_REG_L2P_VALIDATE_VFID, 0);\n\tqed_wr(p_hwfn, p_ptt, PGLUE_B_REG_USE_CLIENTID_IN_TAG, 1);\n\n\tif (QED_IS_BB(p_hwfn->cdev)) {\n\t\tnum_pfs = NUM_OF_ENG_PFS(p_hwfn->cdev);\n\t\tfor (pf_id = 0; pf_id < num_pfs; pf_id++) {\n\t\t\tqed_fid_pretend(p_hwfn, p_ptt, pf_id);\n\t\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_ROCE, 0x0);\n\t\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_TCP, 0x0);\n\t\t}\n\t\t \n\t\tqed_fid_pretend(p_hwfn, p_ptt, p_hwfn->rel_pf_id);\n\t}\n\n\tmax_num_vfs = QED_IS_AH(cdev) ? MAX_NUM_VFS_K2 : MAX_NUM_VFS_BB;\n\tfor (vf_id = 0; vf_id < max_num_vfs; vf_id++) {\n\t\tconcrete_fid = qed_vfid_to_concrete(p_hwfn, vf_id);\n\t\tqed_fid_pretend(p_hwfn, p_ptt, (u16)concrete_fid);\n\t\tqed_wr(p_hwfn, p_ptt, CCFC_REG_STRONG_ENABLE_VF, 0x1);\n\t\tqed_wr(p_hwfn, p_ptt, CCFC_REG_WEAK_ENABLE_VF, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, TCFC_REG_STRONG_ENABLE_VF, 0x1);\n\t\tqed_wr(p_hwfn, p_ptt, TCFC_REG_WEAK_ENABLE_VF, 0x0);\n\t}\n\t \n\tqed_fid_pretend(p_hwfn, p_ptt, p_hwfn->rel_pf_id);\n\nout:\n\tkfree(params);\n\n\treturn rc;\n}\n\nstatic int\nqed_hw_init_dpi_size(struct qed_hwfn *p_hwfn,\n\t\t     struct qed_ptt *p_ptt, u32 pwm_region_size, u32 n_cpus)\n{\n\tu32 dpi_bit_shift, dpi_count, dpi_page_size;\n\tu32 min_dpis;\n\tu32 n_wids;\n\n\t \n\tn_wids = max_t(u32, QED_MIN_WIDS, n_cpus);\n\tdpi_page_size = QED_WID_SIZE * roundup_pow_of_two(n_wids);\n\tdpi_page_size = (dpi_page_size + PAGE_SIZE - 1) & ~(PAGE_SIZE - 1);\n\tdpi_bit_shift = ilog2(dpi_page_size / 4096);\n\tdpi_count = pwm_region_size / dpi_page_size;\n\n\tmin_dpis = p_hwfn->pf_params.rdma_pf_params.min_dpis;\n\tmin_dpis = max_t(u32, QED_MIN_DPIS, min_dpis);\n\n\tp_hwfn->dpi_size = dpi_page_size;\n\tp_hwfn->dpi_count = dpi_count;\n\n\tqed_wr(p_hwfn, p_ptt, DORQ_REG_PF_DPI_BIT_SHIFT, dpi_bit_shift);\n\n\tif (dpi_count < min_dpis)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nenum QED_ROCE_EDPM_MODE {\n\tQED_ROCE_EDPM_MODE_ENABLE = 0,\n\tQED_ROCE_EDPM_MODE_FORCE_ON = 1,\n\tQED_ROCE_EDPM_MODE_DISABLE = 2,\n};\n\nbool qed_edpm_enabled(struct qed_hwfn *p_hwfn)\n{\n\tif (p_hwfn->dcbx_no_edpm || p_hwfn->db_bar_no_edpm)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int\nqed_hw_init_pf_doorbell_bar(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 pwm_regsize, norm_regsize;\n\tu32 non_pwm_conn, min_addr_reg1;\n\tu32 db_bar_size, n_cpus = 1;\n\tu32 roce_edpm_mode;\n\tu32 pf_dems_shift;\n\tint rc = 0;\n\tu8 cond;\n\n\tdb_bar_size = qed_hw_bar_size(p_hwfn, p_ptt, BAR_ID_1);\n\tif (p_hwfn->cdev->num_hwfns > 1)\n\t\tdb_bar_size /= 2;\n\n\t \n\tnon_pwm_conn = qed_cxt_get_proto_cid_start(p_hwfn, PROTOCOLID_CORE) +\n\t\t       qed_cxt_get_proto_cid_count(p_hwfn, PROTOCOLID_CORE,\n\t\t\t\t\t\t   NULL) +\n\t\t       qed_cxt_get_proto_cid_count(p_hwfn, PROTOCOLID_ETH,\n\t\t\t\t\t\t   NULL);\n\tnorm_regsize = roundup(QED_PF_DEMS_SIZE * non_pwm_conn, PAGE_SIZE);\n\tmin_addr_reg1 = norm_regsize / 4096;\n\tpwm_regsize = db_bar_size - norm_regsize;\n\n\t \n\tif (db_bar_size < norm_regsize) {\n\t\tDP_ERR(p_hwfn->cdev,\n\t\t       \"Doorbell BAR size 0x%x is too small (normal region is 0x%0x )\\n\",\n\t\t       db_bar_size, norm_regsize);\n\t\treturn -EINVAL;\n\t}\n\n\tif (pwm_regsize < QED_MIN_PWM_REGION) {\n\t\tDP_ERR(p_hwfn->cdev,\n\t\t       \"PWM region size 0x%0x is too small. Should be at least 0x%0x (Doorbell BAR size is 0x%x and normal region size is 0x%0x)\\n\",\n\t\t       pwm_regsize,\n\t\t       QED_MIN_PWM_REGION, db_bar_size, norm_regsize);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\troce_edpm_mode = p_hwfn->pf_params.rdma_pf_params.roce_edpm_mode;\n\tif ((roce_edpm_mode == QED_ROCE_EDPM_MODE_ENABLE) ||\n\t    ((roce_edpm_mode == QED_ROCE_EDPM_MODE_FORCE_ON))) {\n\t\t \n\t\tn_cpus = num_present_cpus();\n\t\trc = qed_hw_init_dpi_size(p_hwfn, p_ptt, pwm_regsize, n_cpus);\n\t}\n\n\tcond = (rc && (roce_edpm_mode == QED_ROCE_EDPM_MODE_ENABLE)) ||\n\t       (roce_edpm_mode == QED_ROCE_EDPM_MODE_DISABLE);\n\tif (cond || p_hwfn->dcbx_no_edpm) {\n\t\t \n\t\tn_cpus = 1;\n\t\trc = qed_hw_init_dpi_size(p_hwfn, p_ptt, pwm_regsize, n_cpus);\n\n\t\tif (cond)\n\t\t\tqed_rdma_dpm_bar(p_hwfn, p_ptt);\n\t}\n\n\tp_hwfn->wid_count = (u16)n_cpus;\n\n\tDP_INFO(p_hwfn,\n\t\t\"doorbell bar: normal_region_size=%d, pwm_region_size=%d, dpi_size=%d, dpi_count=%d, roce_edpm=%s, page_size=%lu\\n\",\n\t\tnorm_regsize,\n\t\tpwm_regsize,\n\t\tp_hwfn->dpi_size,\n\t\tp_hwfn->dpi_count,\n\t\t(!qed_edpm_enabled(p_hwfn)) ?\n\t\t\"disabled\" : \"enabled\", PAGE_SIZE);\n\n\tif (rc) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"Failed to allocate enough DPIs. Allocated %d but the current minimum is %d.\\n\",\n\t\t       p_hwfn->dpi_count,\n\t\t       p_hwfn->pf_params.rdma_pf_params.min_dpis);\n\t\treturn -EINVAL;\n\t}\n\n\tp_hwfn->dpi_start_offset = norm_regsize;\n\n\t \n\tpf_dems_shift = ilog2(QED_PF_DEMS_SIZE / 4);\n\tqed_wr(p_hwfn, p_ptt, DORQ_REG_PF_ICID_BIT_SHIFT_NORM, pf_dems_shift);\n\tqed_wr(p_hwfn, p_ptt, DORQ_REG_PF_MIN_ADDR_REG1, min_addr_reg1);\n\n\treturn 0;\n}\n\nstatic int qed_hw_init_port(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_ptt *p_ptt, int hw_mode)\n{\n\tint rc = 0;\n\n\t \n\tif (!QED_IS_CMT(p_hwfn->cdev) || !IS_LEAD_HWFN(p_hwfn))\n\t\tSTORE_RT_REG(p_hwfn, NIG_REG_BRB_GATE_DNTFWD_PORT_RT_OFFSET, 0);\n\n\trc = qed_init_run(p_hwfn, p_ptt, PHASE_PORT, p_hwfn->port_id, hw_mode);\n\tif (rc)\n\t\treturn rc;\n\n\tqed_wr(p_hwfn, p_ptt, PGLUE_B_REG_MASTER_WRITE_PAD_ENABLE, 0);\n\n\treturn 0;\n}\n\nstatic int qed_hw_init_pf(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t  struct qed_tunnel_info *p_tunn,\n\t\t\t  int hw_mode,\n\t\t\t  bool b_hw_start,\n\t\t\t  enum qed_int_mode int_mode,\n\t\t\t  bool allow_npar_tx_switch)\n{\n\tu8 rel_pf_id = p_hwfn->rel_pf_id;\n\tint rc = 0;\n\n\tif (p_hwfn->mcp_info) {\n\t\tstruct qed_mcp_function_info *p_info;\n\n\t\tp_info = &p_hwfn->mcp_info->func_info;\n\t\tif (p_info->bandwidth_min)\n\t\t\tp_hwfn->qm_info.pf_wfq = p_info->bandwidth_min;\n\n\t\t \n\t\tp_hwfn->qm_info.pf_rl = 100000;\n\t}\n\n\tqed_cxt_hw_init_pf(p_hwfn, p_ptt);\n\n\tqed_int_igu_init_rt(p_hwfn);\n\n\t \n\tif (hw_mode & BIT(MODE_MF_SD)) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_HW, \"Configuring LLH_FUNC_TAG\\n\");\n\t\tSTORE_RT_REG(p_hwfn, NIG_REG_LLH_FUNC_TAG_EN_RT_OFFSET, 1);\n\t\tSTORE_RT_REG(p_hwfn, NIG_REG_LLH_FUNC_TAG_VALUE_RT_OFFSET,\n\t\t\t     p_hwfn->hw_info.ovlan);\n\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_HW,\n\t\t\t   \"Configuring LLH_FUNC_FILTER_HDR_SEL\\n\");\n\t\tSTORE_RT_REG(p_hwfn, NIG_REG_LLH_FUNC_FILTER_HDR_SEL_RT_OFFSET,\n\t\t\t     1);\n\t}\n\n\t \n\tif (hw_mode & BIT(MODE_MF_SI)) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_HW,\n\t\t\t   \"Configuring TAGMAC_CLS_TYPE\\n\");\n\t\tSTORE_RT_REG(p_hwfn,\n\t\t\t     NIG_REG_LLH_FUNC_TAGMAC_CLS_TYPE_RT_OFFSET, 1);\n\t}\n\n\t \n\tSTORE_RT_REG(p_hwfn, PRS_REG_SEARCH_TCP_RT_OFFSET,\n\t\t     ((p_hwfn->hw_info.personality == QED_PCI_ISCSI) ||\n\t\t\t (p_hwfn->hw_info.personality == QED_PCI_NVMETCP)) ? 1 : 0);\n\tSTORE_RT_REG(p_hwfn, PRS_REG_SEARCH_FCOE_RT_OFFSET,\n\t\t     (p_hwfn->hw_info.personality == QED_PCI_FCOE) ? 1 : 0);\n\tSTORE_RT_REG(p_hwfn, PRS_REG_SEARCH_ROCE_RT_OFFSET, 0);\n\n\t \n\trc = qed_dmae_sanity(p_hwfn, p_ptt, \"pf_phase\");\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trc = qed_init_run(p_hwfn, p_ptt, PHASE_PF, rel_pf_id, hw_mode);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trc = qed_init_run(p_hwfn, p_ptt, PHASE_QM_PF, rel_pf_id, hw_mode);\n\tif (rc)\n\t\treturn rc;\n\n\tqed_fw_overlay_init_ram(p_hwfn, p_ptt, p_hwfn->fw_overlay_mem);\n\n\t \n\tqed_int_igu_init_pure_rt(p_hwfn, p_ptt, true, true);\n\n\trc = qed_hw_init_pf_doorbell_bar(p_hwfn, p_ptt);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (IS_LEAD_HWFN(p_hwfn)) {\n\t\trc = qed_llh_hw_init_pf(p_hwfn, p_ptt);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tif (b_hw_start) {\n\t\t \n\t\tqed_int_igu_enable(p_hwfn, p_ptt, int_mode);\n\n\t\t \n\t\trc = qed_sp_pf_start(p_hwfn, p_ptt, p_tunn,\n\t\t\t\t     allow_npar_tx_switch);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn, \"Function start ramrod failed\\n\");\n\t\t\treturn rc;\n\t\t}\n\t\tif (p_hwfn->hw_info.personality == QED_PCI_FCOE) {\n\t\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_TAG1, BIT(2));\n\t\t\tqed_wr(p_hwfn, p_ptt,\n\t\t\t       PRS_REG_PKT_LEN_STAT_TAGS_NOT_COUNTED_FIRST,\n\t\t\t       0x100);\n\t\t}\n\t}\n\treturn rc;\n}\n\nint qed_pglueb_set_pfid_enable(struct qed_hwfn *p_hwfn,\n\t\t\t       struct qed_ptt *p_ptt, bool b_enable)\n{\n\tu32 delay_idx = 0, val, set_val = b_enable ? 1 : 0;\n\n\t \n\tqed_wr(p_hwfn, p_ptt, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, set_val);\n\n\t \n\tfor (delay_idx = 0; delay_idx < 20000; delay_idx++) {\n\t\tval = qed_rd(p_hwfn, p_ptt,\n\t\t\t     PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER);\n\t\tif (val == set_val)\n\t\t\tbreak;\n\n\t\tusleep_range(50, 60);\n\t}\n\n\tif (val != set_val) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"PFID_ENABLE_MASTER wasn't changed after a second\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_reset_mb_shadow(struct qed_hwfn *p_hwfn,\n\t\t\t\tstruct qed_ptt *p_main_ptt)\n{\n\t \n\tqed_mcp_read_mb(p_hwfn, p_main_ptt);\n\tmemcpy(p_hwfn->mcp_info->mfw_mb_shadow,\n\t       p_hwfn->mcp_info->mfw_mb_cur, p_hwfn->mcp_info->mfw_mb_length);\n}\n\nstatic void\nqed_fill_load_req_params(struct qed_load_req_params *p_load_req,\n\t\t\t struct qed_drv_load_params *p_drv_load)\n{\n\tmemset(p_load_req, 0, sizeof(*p_load_req));\n\n\tp_load_req->drv_role = p_drv_load->is_crash_kernel ?\n\t\t\t       QED_DRV_ROLE_KDUMP : QED_DRV_ROLE_OS;\n\tp_load_req->timeout_val = p_drv_load->mfw_timeout_val;\n\tp_load_req->avoid_eng_reset = p_drv_load->avoid_eng_reset;\n\tp_load_req->override_force_load = p_drv_load->override_force_load;\n}\n\nstatic int qed_vf_start(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_hw_init_params *p_params)\n{\n\tif (p_params->p_tunn) {\n\t\tqed_vf_set_vf_start_tunn_update_param(p_params->p_tunn);\n\t\tqed_vf_pf_tunnel_param_update(p_hwfn, p_params->p_tunn);\n\t}\n\n\tp_hwfn->b_int_enabled = true;\n\n\treturn 0;\n}\n\nstatic void qed_pglueb_clear_err(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tqed_wr(p_hwfn, p_ptt, PGLUE_B_REG_WAS_ERROR_PF_31_0_CLR,\n\t       BIT(p_hwfn->abs_pf_id));\n}\n\nint qed_hw_init(struct qed_dev *cdev, struct qed_hw_init_params *p_params)\n{\n\tstruct qed_load_req_params load_req_params;\n\tu32 load_code, resp, param, drv_mb_param;\n\tbool b_default_mtu = true;\n\tstruct qed_hwfn *p_hwfn;\n\tconst u32 *fw_overlays;\n\tu32 fw_overlays_len;\n\tu16 ether_type;\n\tint rc = 0, i;\n\n\tif ((p_params->int_mode == QED_INT_MODE_MSI) && (cdev->num_hwfns > 1)) {\n\t\tDP_NOTICE(cdev, \"MSI mode is not supported for CMT devices\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (IS_PF(cdev)) {\n\t\trc = qed_init_fw_data(cdev, p_params->bin_fw_data);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tp_hwfn = &cdev->hwfns[i];\n\n\t\t \n\t\tif (!p_hwfn->hw_info.mtu) {\n\t\t\tp_hwfn->hw_info.mtu = 1500;\n\t\t\tb_default_mtu = false;\n\t\t}\n\n\t\tif (IS_VF(cdev)) {\n\t\t\tqed_vf_start(p_hwfn, p_params);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tp_hwfn->mcp_info->mcp_handling_status = 0;\n\n\t\trc = qed_calc_hw_mode(p_hwfn);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tif (IS_PF(cdev) && (test_bit(QED_MF_8021Q_TAGGING,\n\t\t\t\t\t     &cdev->mf_bits) ||\n\t\t\t\t    test_bit(QED_MF_8021AD_TAGGING,\n\t\t\t\t\t     &cdev->mf_bits))) {\n\t\t\tif (test_bit(QED_MF_8021Q_TAGGING, &cdev->mf_bits))\n\t\t\t\tether_type = ETH_P_8021Q;\n\t\t\telse\n\t\t\t\tether_type = ETH_P_8021AD;\n\t\t\tSTORE_RT_REG(p_hwfn, PRS_REG_TAG_ETHERTYPE_0_RT_OFFSET,\n\t\t\t\t     ether_type);\n\t\t\tSTORE_RT_REG(p_hwfn, NIG_REG_TAG_ETHERTYPE_0_RT_OFFSET,\n\t\t\t\t     ether_type);\n\t\t\tSTORE_RT_REG(p_hwfn, PBF_REG_TAG_ETHERTYPE_0_RT_OFFSET,\n\t\t\t\t     ether_type);\n\t\t\tSTORE_RT_REG(p_hwfn, DORQ_REG_TAG1_ETHERTYPE_RT_OFFSET,\n\t\t\t\t     ether_type);\n\t\t}\n\n\t\tqed_fill_load_req_params(&load_req_params,\n\t\t\t\t\t p_params->p_drv_load_params);\n\t\trc = qed_mcp_load_req(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t      &load_req_params);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn, \"Failed sending a LOAD_REQ command\\n\");\n\t\t\treturn rc;\n\t\t}\n\n\t\tload_code = load_req_params.load_code;\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"Load request was sent. Load code: 0x%x\\n\",\n\t\t\t   load_code);\n\n\t\t \n\t\tcdev->recov_in_prog = false;\n\n\t\tqed_mcp_set_capabilities(p_hwfn, p_hwfn->p_main_ptt);\n\n\t\tqed_reset_mb_shadow(p_hwfn, p_hwfn->p_main_ptt);\n\n\t\t \n\t\tif (load_code != FW_MSG_CODE_DRV_LOAD_ENGINE) {\n\t\t\trc = qed_final_cleanup(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t       p_hwfn->rel_pf_id, false);\n\t\t\tif (rc) {\n\t\t\t\tqed_hw_err_notify(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t\t  QED_HW_ERR_RAMROD_FAIL,\n\t\t\t\t\t\t  \"Final cleanup failed\\n\");\n\t\t\t\tgoto load_err;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tqed_pglueb_rbc_attn_handler(p_hwfn, p_hwfn->p_main_ptt, true);\n\n\t\t \n\t\trc = qed_pglueb_set_pfid_enable(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t\ttrue);\n\t\tif (rc)\n\t\t\tgoto load_err;\n\n\t\t \n\t\tqed_pglueb_clear_err(p_hwfn, p_hwfn->p_main_ptt);\n\n\t\tfw_overlays = cdev->fw_data->fw_overlays;\n\t\tfw_overlays_len = cdev->fw_data->fw_overlays_len;\n\t\tp_hwfn->fw_overlay_mem =\n\t\t    qed_fw_overlay_mem_alloc(p_hwfn, fw_overlays,\n\t\t\t\t\t     fw_overlays_len);\n\t\tif (!p_hwfn->fw_overlay_mem) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to allocate fw overlay memory\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto load_err;\n\t\t}\n\n\t\tswitch (load_code) {\n\t\tcase FW_MSG_CODE_DRV_LOAD_ENGINE:\n\t\t\trc = qed_hw_init_common(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t\tp_hwfn->hw_info.hw_mode);\n\t\t\tif (rc)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tcase FW_MSG_CODE_DRV_LOAD_PORT:\n\t\t\trc = qed_hw_init_port(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t      p_hwfn->hw_info.hw_mode);\n\t\t\tif (rc)\n\t\t\t\tbreak;\n\n\t\t\tfallthrough;\n\t\tcase FW_MSG_CODE_DRV_LOAD_FUNCTION:\n\t\t\trc = qed_hw_init_pf(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t    p_params->p_tunn,\n\t\t\t\t\t    p_hwfn->hw_info.hw_mode,\n\t\t\t\t\t    p_params->b_hw_start,\n\t\t\t\t\t    p_params->int_mode,\n\t\t\t\t\t    p_params->allow_npar_tx_switch);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Unexpected load code [0x%08x]\", load_code);\n\t\t\trc = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"init phase failed for loadcode 0x%x (rc %d)\\n\",\n\t\t\t\t  load_code, rc);\n\t\t\tgoto load_err;\n\t\t}\n\n\t\trc = qed_mcp_load_done(p_hwfn, p_hwfn->p_main_ptt);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_DCB,\n\t\t\t   \"sending phony dcbx set command to trigger DCBx attention handling\\n\");\n\t\trc = qed_mcp_cmd(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t DRV_MSG_CODE_SET_DCBX,\n\t\t\t\t 1 << DRV_MB_PARAM_DCBX_NOTIFY_SHIFT,\n\t\t\t\t &resp, &param);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to send DCBX attention request\\n\");\n\t\t\treturn rc;\n\t\t}\n\n\t\tp_hwfn->hw_init_done = true;\n\t}\n\n\tif (IS_PF(cdev)) {\n\t\tp_hwfn = QED_LEADING_HWFN(cdev);\n\n\t\t \n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_SPQ,\n\t\t\t   \"Sending GET_OEM_UPDATES command to trigger stag/bandwidth attention handling\\n\");\n\t\tdrv_mb_param = 1 << DRV_MB_PARAM_DUMMY_OEM_UPDATES_OFFSET;\n\t\trc = qed_mcp_cmd(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t DRV_MSG_CODE_GET_OEM_UPDATES,\n\t\t\t\t drv_mb_param, &resp, &param);\n\t\tif (rc)\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to send GET_OEM_UPDATES attention request\\n\");\n\n\t\tdrv_mb_param = STORM_FW_VERSION;\n\t\trc = qed_mcp_cmd(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t DRV_MSG_CODE_OV_UPDATE_STORM_FW_VER,\n\t\t\t\t drv_mb_param, &load_code, &param);\n\t\tif (rc)\n\t\t\tDP_INFO(p_hwfn, \"Failed to update firmware version\\n\");\n\n\t\tif (!b_default_mtu) {\n\t\t\trc = qed_mcp_ov_update_mtu(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t\t   p_hwfn->hw_info.mtu);\n\t\t\tif (rc)\n\t\t\t\tDP_INFO(p_hwfn,\n\t\t\t\t\t\"Failed to update default mtu\\n\");\n\t\t}\n\n\t\trc = qed_mcp_ov_update_driver_state(p_hwfn,\n\t\t\t\t\t\t    p_hwfn->p_main_ptt,\n\t\t\t\t\t\t  QED_OV_DRIVER_STATE_DISABLED);\n\t\tif (rc)\n\t\t\tDP_INFO(p_hwfn, \"Failed to update driver state\\n\");\n\n\t\trc = qed_mcp_ov_update_eswitch(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t       QED_OV_ESWITCH_NONE);\n\t\tif (rc)\n\t\t\tDP_INFO(p_hwfn, \"Failed to update eswitch mode\\n\");\n\t}\n\n\treturn 0;\n\nload_err:\n\t \n\tqed_mcp_load_done(p_hwfn, p_hwfn->p_main_ptt);\n\treturn rc;\n}\n\n#define QED_HW_STOP_RETRY_LIMIT (10)\nstatic void qed_hw_timers_stop(struct qed_dev *cdev,\n\t\t\t       struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tint i;\n\n\t \n\tqed_wr(p_hwfn, p_ptt, TM_REG_PF_ENABLE_CONN, 0x0);\n\tqed_wr(p_hwfn, p_ptt, TM_REG_PF_ENABLE_TASK, 0x0);\n\n\tif (cdev->recov_in_prog)\n\t\treturn;\n\n\tfor (i = 0; i < QED_HW_STOP_RETRY_LIMIT; i++) {\n\t\tif ((!qed_rd(p_hwfn, p_ptt,\n\t\t\t     TM_REG_PF_SCAN_ACTIVE_CONN)) &&\n\t\t    (!qed_rd(p_hwfn, p_ptt, TM_REG_PF_SCAN_ACTIVE_TASK)))\n\t\t\tbreak;\n\n\t\t \n\t\tusleep_range(1000, 2000);\n\t}\n\n\tif (i < QED_HW_STOP_RETRY_LIMIT)\n\t\treturn;\n\n\tDP_NOTICE(p_hwfn,\n\t\t  \"Timers linear scans are not over [Connection %02x Tasks %02x]\\n\",\n\t\t  (u8)qed_rd(p_hwfn, p_ptt, TM_REG_PF_SCAN_ACTIVE_CONN),\n\t\t  (u8)qed_rd(p_hwfn, p_ptt, TM_REG_PF_SCAN_ACTIVE_TASK));\n}\n\nvoid qed_hw_timers_stop_all(struct qed_dev *cdev)\n{\n\tint j;\n\n\tfor_each_hwfn(cdev, j) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[j];\n\t\tstruct qed_ptt *p_ptt = p_hwfn->p_main_ptt;\n\n\t\tqed_hw_timers_stop(cdev, p_hwfn, p_ptt);\n\t}\n}\n\nint qed_hw_stop(struct qed_dev *cdev)\n{\n\tstruct qed_hwfn *p_hwfn;\n\tstruct qed_ptt *p_ptt;\n\tint rc, rc2 = 0;\n\tint j;\n\n\tfor_each_hwfn(cdev, j) {\n\t\tp_hwfn = &cdev->hwfns[j];\n\t\tp_ptt = p_hwfn->p_main_ptt;\n\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_IFDOWN, \"Stopping hw/fw\\n\");\n\n\t\tif (IS_VF(cdev)) {\n\t\t\tqed_vf_pf_int_cleanup(p_hwfn);\n\t\t\trc = qed_vf_pf_reset(p_hwfn);\n\t\t\tif (rc) {\n\t\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t\t  \"qed_vf_pf_reset failed. rc = %d.\\n\",\n\t\t\t\t\t  rc);\n\t\t\t\trc2 = -EINVAL;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tp_hwfn->hw_init_done = false;\n\n\t\t \n\t\tif (!cdev->recov_in_prog) {\n\t\t\trc = qed_mcp_unload_req(p_hwfn, p_ptt);\n\t\t\tif (rc) {\n\t\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t\t  \"Failed sending a UNLOAD_REQ command. rc = %d.\\n\",\n\t\t\t\t\t  rc);\n\t\t\t\trc2 = -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tqed_slowpath_irq_sync(p_hwfn);\n\n\t\t \n\t\trc = qed_sp_pf_stop(p_hwfn);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to close PF against FW [rc = %d]. Continue to stop HW to prevent illegal host access by the device.\\n\",\n\t\t\t\t  rc);\n\t\t\trc2 = -EINVAL;\n\t\t}\n\n\t\tqed_wr(p_hwfn, p_ptt,\n\t\t       NIG_REG_RX_LLH_BRB_GATE_DNTFWD_PERPF, 0x1);\n\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_TCP, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_UDP, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_FCOE, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_ROCE, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_OPENFLOW, 0x0);\n\n\t\tqed_hw_timers_stop(cdev, p_hwfn, p_ptt);\n\n\t\t \n\t\tqed_int_igu_disable_int(p_hwfn, p_ptt);\n\n\t\tqed_wr(p_hwfn, p_ptt, IGU_REG_LEADING_EDGE_LATCH, 0);\n\t\tqed_wr(p_hwfn, p_ptt, IGU_REG_TRAILING_EDGE_LATCH, 0);\n\n\t\tqed_int_igu_init_pure_rt(p_hwfn, p_ptt, false, true);\n\n\t\t \n\t\tusleep_range(1000, 2000);\n\n\t\t \n\t\tqed_wr(p_hwfn, p_ptt, DORQ_REG_PF_DB_ENABLE, 0);\n\t\tqed_wr(p_hwfn, p_ptt, QM_REG_PF_EN, 0);\n\n\t\tif (IS_LEAD_HWFN(p_hwfn) &&\n\t\t    test_bit(QED_MF_LLH_MAC_CLSS, &cdev->mf_bits) &&\n\t\t    !QED_IS_FCOE_PERSONALITY(p_hwfn))\n\t\t\tqed_llh_remove_mac_filter(cdev, 0,\n\t\t\t\t\t\t  p_hwfn->hw_info.hw_mac_addr);\n\n\t\tif (!cdev->recov_in_prog) {\n\t\t\trc = qed_mcp_unload_done(p_hwfn, p_ptt);\n\t\t\tif (rc) {\n\t\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t\t  \"Failed sending a UNLOAD_DONE command. rc = %d.\\n\",\n\t\t\t\t\t  rc);\n\t\t\t\trc2 = -EINVAL;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (IS_PF(cdev) && !cdev->recov_in_prog) {\n\t\tp_hwfn = QED_LEADING_HWFN(cdev);\n\t\tp_ptt = QED_LEADING_HWFN(cdev)->p_main_ptt;\n\n\t\t \n\t\trc = qed_pglueb_set_pfid_enable(p_hwfn, p_ptt, false);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"qed_pglueb_set_pfid_enable() failed. rc = %d.\\n\",\n\t\t\t\t  rc);\n\t\t\trc2 = -EINVAL;\n\t\t}\n\t}\n\n\treturn rc2;\n}\n\nint qed_hw_stop_fastpath(struct qed_dev *cdev)\n{\n\tint j;\n\n\tfor_each_hwfn(cdev, j) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[j];\n\t\tstruct qed_ptt *p_ptt;\n\n\t\tif (IS_VF(cdev)) {\n\t\t\tqed_vf_pf_int_cleanup(p_hwfn);\n\t\t\tcontinue;\n\t\t}\n\t\tp_ptt = qed_ptt_acquire(p_hwfn);\n\t\tif (!p_ptt)\n\t\t\treturn -EAGAIN;\n\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   NETIF_MSG_IFDOWN, \"Shutting down the fastpath\\n\");\n\n\t\tqed_wr(p_hwfn, p_ptt,\n\t\t       NIG_REG_RX_LLH_BRB_GATE_DNTFWD_PERPF, 0x1);\n\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_TCP, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_UDP, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_FCOE, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_ROCE, 0x0);\n\t\tqed_wr(p_hwfn, p_ptt, PRS_REG_SEARCH_OPENFLOW, 0x0);\n\n\t\tqed_int_igu_init_pure_rt(p_hwfn, p_ptt, false, false);\n\n\t\t \n\t\tusleep_range(1000, 2000);\n\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t}\n\n\treturn 0;\n}\n\nint qed_hw_start_fastpath(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_ptt *p_ptt;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn 0;\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\tif (p_hwfn->p_rdma_info &&\n\t    p_hwfn->p_rdma_info->active && p_hwfn->b_rdma_enabled_in_prs)\n\t\tqed_wr(p_hwfn, p_ptt, p_hwfn->rdma_prs_search_reg, 0x1);\n\n\t \n\tqed_wr(p_hwfn, p_ptt, NIG_REG_RX_LLH_BRB_GATE_DNTFWD_PERPF, 0x0);\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn 0;\n}\n\n \nstatic void qed_hw_hwfn_free(struct qed_hwfn *p_hwfn)\n{\n\tqed_ptt_pool_free(p_hwfn);\n\tkfree(p_hwfn->hw_info.p_igu_info);\n\tp_hwfn->hw_info.p_igu_info = NULL;\n}\n\n \nstatic void qed_hw_hwfn_prepare(struct qed_hwfn *p_hwfn)\n{\n\t \n\tif (QED_IS_AH(p_hwfn->cdev)) {\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_E8_F0_K2, 0);\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_EC_F0_K2, 0);\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_F0_F0_K2, 0);\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_F4_F0_K2, 0);\n\t} else {\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_88_F0_BB, 0);\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_8C_F0_BB, 0);\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_90_F0_BB, 0);\n\t\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t\t       PGLUE_B_REG_PGL_ADDR_94_F0_BB, 0);\n\t}\n\n\t \n\tqed_pglueb_clear_err(p_hwfn, p_hwfn->p_main_ptt);\n\n\t \n\tqed_wr(p_hwfn, p_hwfn->p_main_ptt,\n\t       PGLUE_B_REG_INTERNAL_PFID_ENABLE_TARGET_READ, 1);\n}\n\nstatic void get_function_id(struct qed_hwfn *p_hwfn)\n{\n\t \n\tp_hwfn->hw_info.opaque_fid = (u16)REG_RD(p_hwfn,\n\t\t\t\t\t\t PXP_PF_ME_OPAQUE_ADDR);\n\n\tp_hwfn->hw_info.concrete_fid = REG_RD(p_hwfn, PXP_PF_ME_CONCRETE_ADDR);\n\n\tp_hwfn->abs_pf_id = (p_hwfn->hw_info.concrete_fid >> 16) & 0xf;\n\tp_hwfn->rel_pf_id = GET_FIELD(p_hwfn->hw_info.concrete_fid,\n\t\t\t\t      PXP_CONCRETE_FID_PFID);\n\tp_hwfn->port_id = GET_FIELD(p_hwfn->hw_info.concrete_fid,\n\t\t\t\t    PXP_CONCRETE_FID_PORT);\n\n\tDP_VERBOSE(p_hwfn, NETIF_MSG_PROBE,\n\t\t   \"Read ME register: Concrete 0x%08x Opaque 0x%04x\\n\",\n\t\t   p_hwfn->hw_info.concrete_fid, p_hwfn->hw_info.opaque_fid);\n}\n\nstatic void qed_hw_set_feat(struct qed_hwfn *p_hwfn)\n{\n\tu32 *feat_num = p_hwfn->hw_info.feat_num;\n\tstruct qed_sb_cnt_info sb_cnt;\n\tu32 non_l2_sbs = 0;\n\n\tmemset(&sb_cnt, 0, sizeof(sb_cnt));\n\tqed_int_get_num_sbs(p_hwfn, &sb_cnt);\n\n\tif (IS_ENABLED(CONFIG_QED_RDMA) &&\n\t    QED_IS_RDMA_PERSONALITY(p_hwfn)) {\n\t\t \n\t\tfeat_num[QED_RDMA_CNQ] =\n\t\t\tmin_t(u32, sb_cnt.cnt / 2,\n\t\t\t      RESC_NUM(p_hwfn, QED_RDMA_CNQ_RAM));\n\n\t\tnon_l2_sbs = feat_num[QED_RDMA_CNQ];\n\t}\n\tif (QED_IS_L2_PERSONALITY(p_hwfn)) {\n\t\t \n\t\tfeat_num[QED_VF_L2_QUE] = min_t(u32,\n\t\t\t\t\t\tRESC_NUM(p_hwfn, QED_L2_QUEUE),\n\t\t\t\t\t\tsb_cnt.iov_cnt);\n\t\tfeat_num[QED_PF_L2_QUE] = min_t(u32,\n\t\t\t\t\t\tsb_cnt.cnt - non_l2_sbs,\n\t\t\t\t\t\tRESC_NUM(p_hwfn,\n\t\t\t\t\t\t\t QED_L2_QUEUE) -\n\t\t\t\t\t\tFEAT_NUM(p_hwfn,\n\t\t\t\t\t\t\t QED_VF_L2_QUE));\n\t}\n\n\tif (QED_IS_FCOE_PERSONALITY(p_hwfn))\n\t\tfeat_num[QED_FCOE_CQ] =  min_t(u32, sb_cnt.cnt,\n\t\t\t\t\t       RESC_NUM(p_hwfn,\n\t\t\t\t\t\t\tQED_CMDQS_CQS));\n\n\tif (QED_IS_ISCSI_PERSONALITY(p_hwfn))\n\t\tfeat_num[QED_ISCSI_CQ] = min_t(u32, sb_cnt.cnt,\n\t\t\t\t\t       RESC_NUM(p_hwfn,\n\t\t\t\t\t\t\tQED_CMDQS_CQS));\n\n\tif (QED_IS_NVMETCP_PERSONALITY(p_hwfn))\n\t\tfeat_num[QED_NVMETCP_CQ] = min_t(u32, sb_cnt.cnt,\n\t\t\t\t\t\t RESC_NUM(p_hwfn,\n\t\t\t\t\t\t\t  QED_CMDQS_CQS));\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   NETIF_MSG_PROBE,\n\t\t   \"#PF_L2_QUEUES=%d VF_L2_QUEUES=%d #ROCE_CNQ=%d FCOE_CQ=%d ISCSI_CQ=%d NVMETCP_CQ=%d #SBS=%d\\n\",\n\t\t   (int)FEAT_NUM(p_hwfn, QED_PF_L2_QUE),\n\t\t   (int)FEAT_NUM(p_hwfn, QED_VF_L2_QUE),\n\t\t   (int)FEAT_NUM(p_hwfn, QED_RDMA_CNQ),\n\t\t   (int)FEAT_NUM(p_hwfn, QED_FCOE_CQ),\n\t\t   (int)FEAT_NUM(p_hwfn, QED_ISCSI_CQ),\n\t\t   (int)FEAT_NUM(p_hwfn, QED_NVMETCP_CQ),\n\t\t   (int)sb_cnt.cnt);\n}\n\nconst char *qed_hw_get_resc_name(enum qed_resources res_id)\n{\n\tswitch (res_id) {\n\tcase QED_L2_QUEUE:\n\t\treturn \"L2_QUEUE\";\n\tcase QED_VPORT:\n\t\treturn \"VPORT\";\n\tcase QED_RSS_ENG:\n\t\treturn \"RSS_ENG\";\n\tcase QED_PQ:\n\t\treturn \"PQ\";\n\tcase QED_RL:\n\t\treturn \"RL\";\n\tcase QED_MAC:\n\t\treturn \"MAC\";\n\tcase QED_VLAN:\n\t\treturn \"VLAN\";\n\tcase QED_RDMA_CNQ_RAM:\n\t\treturn \"RDMA_CNQ_RAM\";\n\tcase QED_ILT:\n\t\treturn \"ILT\";\n\tcase QED_LL2_RAM_QUEUE:\n\t\treturn \"LL2_RAM_QUEUE\";\n\tcase QED_LL2_CTX_QUEUE:\n\t\treturn \"LL2_CTX_QUEUE\";\n\tcase QED_CMDQS_CQS:\n\t\treturn \"CMDQS_CQS\";\n\tcase QED_RDMA_STATS_QUEUE:\n\t\treturn \"RDMA_STATS_QUEUE\";\n\tcase QED_BDQ:\n\t\treturn \"BDQ\";\n\tcase QED_SB:\n\t\treturn \"SB\";\n\tdefault:\n\t\treturn \"UNKNOWN_RESOURCE\";\n\t}\n}\n\nstatic int\n__qed_hw_set_soft_resc_size(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t    enum qed_resources res_id,\n\t\t\t    u32 resc_max_val, u32 *p_mcp_resp)\n{\n\tint rc;\n\n\trc = qed_mcp_set_resc_max_val(p_hwfn, p_ptt, res_id,\n\t\t\t\t      resc_max_val, p_mcp_resp);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"MFW response failure for a max value setting of resource %d [%s]\\n\",\n\t\t\t  res_id, qed_hw_get_resc_name(res_id));\n\t\treturn rc;\n\t}\n\n\tif (*p_mcp_resp != FW_MSG_CODE_RESOURCE_ALLOC_OK)\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Failed to set the max value of resource %d [%s]. mcp_resp = 0x%08x.\\n\",\n\t\t\tres_id, qed_hw_get_resc_name(res_id), *p_mcp_resp);\n\n\treturn 0;\n}\n\nstatic u32 qed_hsi_def_val[][MAX_CHIP_IDS] = {\n\t{MAX_NUM_VFS_BB, MAX_NUM_VFS_K2},\n\t{MAX_NUM_L2_QUEUES_BB, MAX_NUM_L2_QUEUES_K2},\n\t{MAX_NUM_PORTS_BB, MAX_NUM_PORTS_K2},\n\t{MAX_SB_PER_PATH_BB, MAX_SB_PER_PATH_K2,},\n\t{MAX_NUM_PFS_BB, MAX_NUM_PFS_K2},\n\t{MAX_NUM_VPORTS_BB, MAX_NUM_VPORTS_K2},\n\t{ETH_RSS_ENGINE_NUM_BB, ETH_RSS_ENGINE_NUM_K2},\n\t{MAX_QM_TX_QUEUES_BB, MAX_QM_TX_QUEUES_K2},\n\t{PXP_NUM_ILT_RECORDS_BB, PXP_NUM_ILT_RECORDS_K2},\n\t{RDMA_NUM_STATISTIC_COUNTERS_BB, RDMA_NUM_STATISTIC_COUNTERS_K2},\n\t{MAX_QM_GLOBAL_RLS, MAX_QM_GLOBAL_RLS},\n\t{PBF_MAX_CMD_LINES, PBF_MAX_CMD_LINES},\n\t{BTB_MAX_BLOCKS_BB, BTB_MAX_BLOCKS_K2},\n};\n\nu32 qed_get_hsi_def_val(struct qed_dev *cdev, enum qed_hsi_def_type type)\n{\n\tenum chip_ids chip_id = QED_IS_BB(cdev) ? CHIP_BB : CHIP_K2;\n\n\tif (type >= QED_NUM_HSI_DEFS) {\n\t\tDP_ERR(cdev, \"Unexpected HSI definition type [%d]\\n\", type);\n\t\treturn 0;\n\t}\n\n\treturn qed_hsi_def_val[type][chip_id];\n}\n\nstatic int\nqed_hw_set_soft_resc_size(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 resc_max_val, mcp_resp;\n\tu8 res_id;\n\tint rc;\n\n\tfor (res_id = 0; res_id < QED_MAX_RESC; res_id++) {\n\t\tswitch (res_id) {\n\t\tcase QED_LL2_RAM_QUEUE:\n\t\t\tresc_max_val = MAX_NUM_LL2_RX_RAM_QUEUES;\n\t\t\tbreak;\n\t\tcase QED_LL2_CTX_QUEUE:\n\t\t\tresc_max_val = MAX_NUM_LL2_RX_CTX_QUEUES;\n\t\t\tbreak;\n\t\tcase QED_RDMA_CNQ_RAM:\n\t\t\t \n\t\t\tresc_max_val = NUM_OF_GLOBAL_QUEUES;\n\t\t\tbreak;\n\t\tcase QED_RDMA_STATS_QUEUE:\n\t\t\tresc_max_val =\n\t\t\t    NUM_OF_RDMA_STATISTIC_COUNTERS(p_hwfn->cdev);\n\t\t\tbreak;\n\t\tcase QED_BDQ:\n\t\t\tresc_max_val = BDQ_NUM_RESOURCES;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tcontinue;\n\t\t}\n\n\t\trc = __qed_hw_set_soft_resc_size(p_hwfn, p_ptt, res_id,\n\t\t\t\t\t\t resc_max_val, &mcp_resp);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\tif (mcp_resp == FW_MSG_CODE_UNSUPPORTED)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic\nint qed_hw_get_dflt_resc(struct qed_hwfn *p_hwfn,\n\t\t\t enum qed_resources res_id,\n\t\t\t u32 *p_resc_num, u32 *p_resc_start)\n{\n\tu8 num_funcs = p_hwfn->num_funcs_on_engine;\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\n\tswitch (res_id) {\n\tcase QED_L2_QUEUE:\n\t\t*p_resc_num = NUM_OF_L2_QUEUES(cdev) / num_funcs;\n\t\tbreak;\n\tcase QED_VPORT:\n\t\t*p_resc_num = NUM_OF_VPORTS(cdev) / num_funcs;\n\t\tbreak;\n\tcase QED_RSS_ENG:\n\t\t*p_resc_num = NUM_OF_RSS_ENGINES(cdev) / num_funcs;\n\t\tbreak;\n\tcase QED_PQ:\n\t\t*p_resc_num = NUM_OF_QM_TX_QUEUES(cdev) / num_funcs;\n\t\t*p_resc_num &= ~0x7;\t \n\t\tbreak;\n\tcase QED_RL:\n\t\t*p_resc_num = NUM_OF_QM_GLOBAL_RLS(cdev) / num_funcs;\n\t\tbreak;\n\tcase QED_MAC:\n\tcase QED_VLAN:\n\t\t \n\t\t*p_resc_num = ETH_NUM_MAC_FILTERS / num_funcs;\n\t\tbreak;\n\tcase QED_ILT:\n\t\t*p_resc_num = NUM_OF_PXP_ILT_RECORDS(cdev) / num_funcs;\n\t\tbreak;\n\tcase QED_LL2_RAM_QUEUE:\n\t\t*p_resc_num = MAX_NUM_LL2_RX_RAM_QUEUES / num_funcs;\n\t\tbreak;\n\tcase QED_LL2_CTX_QUEUE:\n\t\t*p_resc_num = MAX_NUM_LL2_RX_CTX_QUEUES / num_funcs;\n\t\tbreak;\n\tcase QED_RDMA_CNQ_RAM:\n\tcase QED_CMDQS_CQS:\n\t\t \n\t\t*p_resc_num = NUM_OF_GLOBAL_QUEUES / num_funcs;\n\t\tbreak;\n\tcase QED_RDMA_STATS_QUEUE:\n\t\t*p_resc_num = NUM_OF_RDMA_STATISTIC_COUNTERS(cdev) / num_funcs;\n\t\tbreak;\n\tcase QED_BDQ:\n\t\tif (p_hwfn->hw_info.personality != QED_PCI_ISCSI &&\n\t\t    p_hwfn->hw_info.personality != QED_PCI_FCOE &&\n\t\t\tp_hwfn->hw_info.personality != QED_PCI_NVMETCP)\n\t\t\t*p_resc_num = 0;\n\t\telse\n\t\t\t*p_resc_num = 1;\n\t\tbreak;\n\tcase QED_SB:\n\t\t \n\t\t*p_resc_num = 0;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (res_id) {\n\tcase QED_BDQ:\n\t\tif (!*p_resc_num)\n\t\t\t*p_resc_start = 0;\n\t\telse if (p_hwfn->cdev->num_ports_in_engine == 4)\n\t\t\t*p_resc_start = p_hwfn->port_id;\n\t\telse if (p_hwfn->hw_info.personality == QED_PCI_ISCSI ||\n\t\t\t p_hwfn->hw_info.personality == QED_PCI_NVMETCP)\n\t\t\t*p_resc_start = p_hwfn->port_id;\n\t\telse if (p_hwfn->hw_info.personality == QED_PCI_FCOE)\n\t\t\t*p_resc_start = p_hwfn->port_id + 2;\n\t\tbreak;\n\tdefault:\n\t\t*p_resc_start = *p_resc_num * p_hwfn->enabled_func_idx;\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int __qed_hw_set_resc_info(struct qed_hwfn *p_hwfn,\n\t\t\t\t  enum qed_resources res_id)\n{\n\tu32 dflt_resc_num = 0, dflt_resc_start = 0;\n\tu32 mcp_resp, *p_resc_num, *p_resc_start;\n\tint rc;\n\n\tp_resc_num = &RESC_NUM(p_hwfn, res_id);\n\tp_resc_start = &RESC_START(p_hwfn, res_id);\n\n\trc = qed_hw_get_dflt_resc(p_hwfn, res_id, &dflt_resc_num,\n\t\t\t\t  &dflt_resc_start);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"Failed to get default amount for resource %d [%s]\\n\",\n\t\t       res_id, qed_hw_get_resc_name(res_id));\n\t\treturn rc;\n\t}\n\n\trc = qed_mcp_get_resc_info(p_hwfn, p_hwfn->p_main_ptt, res_id,\n\t\t\t\t   &mcp_resp, p_resc_num, p_resc_start);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"MFW response failure for an allocation request for resource %d [%s]\\n\",\n\t\t\t  res_id, qed_hw_get_resc_name(res_id));\n\t\treturn rc;\n\t}\n\n\t \n\tif (mcp_resp != FW_MSG_CODE_RESOURCE_ALLOC_OK) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Failed to receive allocation info for resource %d [%s]. mcp_resp = 0x%x. Applying default values [%d,%d].\\n\",\n\t\t\tres_id,\n\t\t\tqed_hw_get_resc_name(res_id),\n\t\t\tmcp_resp, dflt_resc_num, dflt_resc_start);\n\t\t*p_resc_num = dflt_resc_num;\n\t\t*p_resc_start = dflt_resc_start;\n\t\tgoto out;\n\t}\n\nout:\n\t \n\tif ((res_id == QED_PQ) && ((*p_resc_num % 8) || (*p_resc_start % 8))) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"PQs need to align by 8; Number %08x --> %08x, Start %08x --> %08x\\n\",\n\t\t\t*p_resc_num,\n\t\t\t(*p_resc_num) & ~0x7,\n\t\t\t*p_resc_start, (*p_resc_start) & ~0x7);\n\t\t*p_resc_num &= ~0x7;\n\t\t*p_resc_start &= ~0x7;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_hw_set_resc_info(struct qed_hwfn *p_hwfn)\n{\n\tint rc;\n\tu8 res_id;\n\n\tfor (res_id = 0; res_id < QED_MAX_RESC; res_id++) {\n\t\trc = __qed_hw_set_resc_info(p_hwfn, res_id);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_hw_get_ppfid_bitmap(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tu8 native_ppfid_idx;\n\tint rc;\n\n\t \n\tif (QED_IS_BB(cdev))\n\t\tnative_ppfid_idx = p_hwfn->rel_pf_id;\n\telse\n\t\tnative_ppfid_idx = p_hwfn->rel_pf_id /\n\t\t    cdev->num_ports_in_engine;\n\n\trc = qed_mcp_get_ppfid_bitmap(p_hwfn, p_ptt);\n\tif (rc != 0 && rc != -EOPNOTSUPP)\n\t\treturn rc;\n\telse if (rc == -EOPNOTSUPP)\n\t\tcdev->ppfid_bitmap = 0x1 << native_ppfid_idx;\n\n\tif (!(cdev->ppfid_bitmap & (0x1 << native_ppfid_idx))) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Fix the PPFID bitmap to include the native PPFID [native_ppfid_idx %hhd, orig_bitmap 0x%hhx]\\n\",\n\t\t\tnative_ppfid_idx, cdev->ppfid_bitmap);\n\t\tcdev->ppfid_bitmap = 0x1 << native_ppfid_idx;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_hw_get_resc(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_resc_unlock_params resc_unlock_params;\n\tstruct qed_resc_lock_params resc_lock_params;\n\tbool b_ah = QED_IS_AH(p_hwfn->cdev);\n\tu8 res_id;\n\tint rc;\n\n\t \n\tqed_mcp_resc_lock_default_init(&resc_lock_params, &resc_unlock_params,\n\t\t\t\t       QED_RESC_LOCK_RESC_ALLOC, false);\n\n\trc = qed_mcp_resc_lock(p_hwfn, p_ptt, &resc_lock_params);\n\tif (rc && rc != -EINVAL) {\n\t\treturn rc;\n\t} else if (rc == -EINVAL) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Skip the max values setting of the soft resources since the resource lock is not supported by the MFW\\n\");\n\t} else if (!resc_lock_params.b_granted) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to acquire the resource lock for the resource allocation commands\\n\");\n\t\treturn -EBUSY;\n\t} else {\n\t\trc = qed_hw_set_soft_resc_size(p_hwfn, p_ptt);\n\t\tif (rc && rc != -EINVAL) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to set the max values of the soft resources\\n\");\n\t\t\tgoto unlock_and_exit;\n\t\t} else if (rc == -EINVAL) {\n\t\t\tDP_INFO(p_hwfn,\n\t\t\t\t\"Skip the max values setting of the soft resources since it is not supported by the MFW\\n\");\n\t\t\trc = qed_mcp_resc_unlock(p_hwfn, p_ptt,\n\t\t\t\t\t\t &resc_unlock_params);\n\t\t\tif (rc)\n\t\t\t\tDP_INFO(p_hwfn,\n\t\t\t\t\t\"Failed to release the resource lock for the resource allocation commands\\n\");\n\t\t}\n\t}\n\n\trc = qed_hw_set_resc_info(p_hwfn);\n\tif (rc)\n\t\tgoto unlock_and_exit;\n\n\tif (resc_lock_params.b_granted && !resc_unlock_params.b_released) {\n\t\trc = qed_mcp_resc_unlock(p_hwfn, p_ptt, &resc_unlock_params);\n\t\tif (rc)\n\t\t\tDP_INFO(p_hwfn,\n\t\t\t\t\"Failed to release the resource lock for the resource allocation commands\\n\");\n\t}\n\n\t \n\tif (IS_LEAD_HWFN(p_hwfn)) {\n\t\trc = qed_hw_get_ppfid_bitmap(p_hwfn, p_ptt);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t \n\tif ((b_ah && (RESC_END(p_hwfn, QED_ILT) > PXP_NUM_ILT_RECORDS_K2)) ||\n\t    (!b_ah && (RESC_END(p_hwfn, QED_ILT) > PXP_NUM_ILT_RECORDS_BB))) {\n\t\tDP_NOTICE(p_hwfn, \"Can't assign ILT pages [%08x,...,%08x]\\n\",\n\t\t\t  RESC_START(p_hwfn, QED_ILT),\n\t\t\t  RESC_END(p_hwfn, QED_ILT) - 1);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (qed_int_igu_reset_cam(p_hwfn, p_ptt))\n\t\treturn -EINVAL;\n\n\tqed_hw_set_feat(p_hwfn);\n\n\tfor (res_id = 0; res_id < QED_MAX_RESC; res_id++)\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_PROBE, \"%s = %d start = %d\\n\",\n\t\t\t   qed_hw_get_resc_name(res_id),\n\t\t\t   RESC_NUM(p_hwfn, res_id),\n\t\t\t   RESC_START(p_hwfn, res_id));\n\n\treturn 0;\n\nunlock_and_exit:\n\tif (resc_lock_params.b_granted && !resc_unlock_params.b_released)\n\t\tqed_mcp_resc_unlock(p_hwfn, p_ptt, &resc_unlock_params);\n\treturn rc;\n}\n\nstatic int qed_hw_get_nvm_info(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 port_cfg_addr, link_temp, nvm_cfg_addr, device_capabilities, fld;\n\tu32 nvm_cfg1_offset, mf_mode, addr, generic_cont0, core_cfg;\n\tstruct qed_mcp_link_speed_params *ext_speed;\n\tstruct qed_mcp_link_capabilities *p_caps;\n\tstruct qed_mcp_link_params *link;\n\tint i;\n\n\t \n\tnvm_cfg_addr = qed_rd(p_hwfn, p_ptt, MISC_REG_GEN_PURP_CR0);\n\n\t \n\tif (!nvm_cfg_addr) {\n\t\tDP_NOTICE(p_hwfn, \"Shared memory not initialized\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tnvm_cfg1_offset = qed_rd(p_hwfn, p_ptt, nvm_cfg_addr + 4);\n\n\taddr = MCP_REG_SCRATCH + nvm_cfg1_offset +\n\t       offsetof(struct nvm_cfg1, glob) +\n\t       offsetof(struct nvm_cfg1_glob, core_cfg);\n\n\tcore_cfg = qed_rd(p_hwfn, p_ptt, addr);\n\n\tswitch ((core_cfg & NVM_CFG1_GLOB_NETWORK_PORT_MODE_MASK) >>\n\t\tNVM_CFG1_GLOB_NETWORK_PORT_MODE_OFFSET) {\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_BB_2X40G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_2X50G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_BB_1X100G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_4X10G_F:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_BB_4X10G_E:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_BB_4X20G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_1X40G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_2X25G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_2X10G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_1X25G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_4X25G:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_AHP_2X50G_R1:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_AHP_4X50G_R1:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_AHP_1X100G_R2:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_AHP_2X100G_R2:\n\tcase NVM_CFG1_GLOB_NETWORK_PORT_MODE_AHP_1X100G_R4:\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown port mode in 0x%08x\\n\", core_cfg);\n\t\tbreak;\n\t}\n\n\t \n\tlink = &p_hwfn->mcp_info->link_input;\n\tp_caps = &p_hwfn->mcp_info->link_capabilities;\n\tport_cfg_addr = MCP_REG_SCRATCH + nvm_cfg1_offset +\n\t\t\toffsetof(struct nvm_cfg1, port[MFW_PORT(p_hwfn)]);\n\tlink_temp = qed_rd(p_hwfn, p_ptt,\n\t\t\t   port_cfg_addr +\n\t\t\t   offsetof(struct nvm_cfg1_port, speed_cap_mask));\n\tlink_temp &= NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_MASK;\n\tlink->speed.advertised_speeds = link_temp;\n\n\tp_caps->speed_capabilities = link->speed.advertised_speeds;\n\n\tlink_temp = qed_rd(p_hwfn, p_ptt,\n\t\t\t   port_cfg_addr +\n\t\t\t   offsetof(struct nvm_cfg1_port, link_settings));\n\tswitch ((link_temp & NVM_CFG1_PORT_DRV_LINK_SPEED_MASK) >>\n\t\tNVM_CFG1_PORT_DRV_LINK_SPEED_OFFSET) {\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_AUTONEG:\n\t\tlink->speed.autoneg = true;\n\t\tbreak;\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_1G:\n\t\tlink->speed.forced_speed = 1000;\n\t\tbreak;\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_10G:\n\t\tlink->speed.forced_speed = 10000;\n\t\tbreak;\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_20G:\n\t\tlink->speed.forced_speed = 20000;\n\t\tbreak;\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_25G:\n\t\tlink->speed.forced_speed = 25000;\n\t\tbreak;\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_40G:\n\t\tlink->speed.forced_speed = 40000;\n\t\tbreak;\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_50G:\n\t\tlink->speed.forced_speed = 50000;\n\t\tbreak;\n\tcase NVM_CFG1_PORT_DRV_LINK_SPEED_BB_100G:\n\t\tlink->speed.forced_speed = 100000;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown Speed in 0x%08x\\n\", link_temp);\n\t}\n\n\tp_caps->default_speed_autoneg = link->speed.autoneg;\n\n\tfld = GET_MFW_FIELD(link_temp, NVM_CFG1_PORT_DRV_FLOW_CONTROL);\n\tlink->pause.autoneg = !!(fld & NVM_CFG1_PORT_DRV_FLOW_CONTROL_AUTONEG);\n\tlink->pause.forced_rx = !!(fld & NVM_CFG1_PORT_DRV_FLOW_CONTROL_RX);\n\tlink->pause.forced_tx = !!(fld & NVM_CFG1_PORT_DRV_FLOW_CONTROL_TX);\n\tlink->loopback_mode = 0;\n\n\tif (p_hwfn->mcp_info->capabilities &\n\t    FW_MB_PARAM_FEATURE_SUPPORT_FEC_CONTROL) {\n\t\tswitch (GET_MFW_FIELD(link_temp,\n\t\t\t\t      NVM_CFG1_PORT_FEC_FORCE_MODE)) {\n\t\tcase NVM_CFG1_PORT_FEC_FORCE_MODE_NONE:\n\t\t\tp_caps->fec_default |= QED_FEC_MODE_NONE;\n\t\t\tbreak;\n\t\tcase NVM_CFG1_PORT_FEC_FORCE_MODE_FIRECODE:\n\t\t\tp_caps->fec_default |= QED_FEC_MODE_FIRECODE;\n\t\t\tbreak;\n\t\tcase NVM_CFG1_PORT_FEC_FORCE_MODE_RS:\n\t\t\tp_caps->fec_default |= QED_FEC_MODE_RS;\n\t\t\tbreak;\n\t\tcase NVM_CFG1_PORT_FEC_FORCE_MODE_AUTO:\n\t\t\tp_caps->fec_default |= QED_FEC_MODE_AUTO;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t\t   \"unknown FEC mode in 0x%08x\\n\", link_temp);\n\t\t}\n\t} else {\n\t\tp_caps->fec_default = QED_FEC_MODE_UNSUPPORTED;\n\t}\n\n\tlink->fec = p_caps->fec_default;\n\n\tif (p_hwfn->mcp_info->capabilities & FW_MB_PARAM_FEATURE_SUPPORT_EEE) {\n\t\tlink_temp = qed_rd(p_hwfn, p_ptt, port_cfg_addr +\n\t\t\t\t   offsetof(struct nvm_cfg1_port, ext_phy));\n\t\tlink_temp &= NVM_CFG1_PORT_EEE_POWER_SAVING_MODE_MASK;\n\t\tlink_temp >>= NVM_CFG1_PORT_EEE_POWER_SAVING_MODE_OFFSET;\n\t\tp_caps->default_eee = QED_MCP_EEE_ENABLED;\n\t\tlink->eee.enable = true;\n\t\tswitch (link_temp) {\n\t\tcase NVM_CFG1_PORT_EEE_POWER_SAVING_MODE_DISABLED:\n\t\t\tp_caps->default_eee = QED_MCP_EEE_DISABLED;\n\t\t\tlink->eee.enable = false;\n\t\t\tbreak;\n\t\tcase NVM_CFG1_PORT_EEE_POWER_SAVING_MODE_BALANCED:\n\t\t\tp_caps->eee_lpi_timer = EEE_TX_TIMER_USEC_BALANCED_TIME;\n\t\t\tbreak;\n\t\tcase NVM_CFG1_PORT_EEE_POWER_SAVING_MODE_AGGRESSIVE:\n\t\t\tp_caps->eee_lpi_timer =\n\t\t\t    EEE_TX_TIMER_USEC_AGGRESSIVE_TIME;\n\t\t\tbreak;\n\t\tcase NVM_CFG1_PORT_EEE_POWER_SAVING_MODE_LOW_LATENCY:\n\t\t\tp_caps->eee_lpi_timer = EEE_TX_TIMER_USEC_LATENCY_TIME;\n\t\t\tbreak;\n\t\t}\n\n\t\tlink->eee.tx_lpi_timer = p_caps->eee_lpi_timer;\n\t\tlink->eee.tx_lpi_enable = link->eee.enable;\n\t\tlink->eee.adv_caps = QED_EEE_1G_ADV | QED_EEE_10G_ADV;\n\t} else {\n\t\tp_caps->default_eee = QED_MCP_EEE_UNSUPPORTED;\n\t}\n\n\tif (p_hwfn->mcp_info->capabilities &\n\t    FW_MB_PARAM_FEATURE_SUPPORT_EXT_SPEED_FEC_CONTROL) {\n\t\text_speed = &link->ext_speed;\n\n\t\tlink_temp = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t   port_cfg_addr +\n\t\t\t\t   offsetof(struct nvm_cfg1_port,\n\t\t\t\t\t    extended_speed));\n\n\t\tfld = GET_MFW_FIELD(link_temp, NVM_CFG1_PORT_EXTENDED_SPEED);\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_AN)\n\t\t\text_speed->autoneg = true;\n\n\t\text_speed->forced_speed = 0;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_1G)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_1G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_10G)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_10G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_20G)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_20G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_25G)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_25G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_40G)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_40G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_50G_R)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_50G_R;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_50G_R2)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_50G_R2;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_100G_R2)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_100G_R2;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_100G_R4)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_100G_R4;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_EXTND_SPD_100G_P4)\n\t\t\text_speed->forced_speed |= QED_EXT_SPEED_100G_P4;\n\n\t\tfld = GET_MFW_FIELD(link_temp,\n\t\t\t\t    NVM_CFG1_PORT_EXTENDED_SPEED_CAP);\n\n\t\text_speed->advertised_speeds = 0;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_RESERVED)\n\t\t\text_speed->advertised_speeds |= QED_EXT_SPEED_MASK_RES;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_1G)\n\t\t\text_speed->advertised_speeds |= QED_EXT_SPEED_MASK_1G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_10G)\n\t\t\text_speed->advertised_speeds |= QED_EXT_SPEED_MASK_10G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_20G)\n\t\t\text_speed->advertised_speeds |= QED_EXT_SPEED_MASK_20G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_25G)\n\t\t\text_speed->advertised_speeds |= QED_EXT_SPEED_MASK_25G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_40G)\n\t\t\text_speed->advertised_speeds |= QED_EXT_SPEED_MASK_40G;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_50G_R)\n\t\t\text_speed->advertised_speeds |=\n\t\t\t\tQED_EXT_SPEED_MASK_50G_R;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_50G_R2)\n\t\t\text_speed->advertised_speeds |=\n\t\t\t\tQED_EXT_SPEED_MASK_50G_R2;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_100G_R2)\n\t\t\text_speed->advertised_speeds |=\n\t\t\t\tQED_EXT_SPEED_MASK_100G_R2;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_100G_R4)\n\t\t\text_speed->advertised_speeds |=\n\t\t\t\tQED_EXT_SPEED_MASK_100G_R4;\n\t\tif (fld & NVM_CFG1_PORT_EXTENDED_SPEED_CAP_EXTND_SPD_100G_P4)\n\t\t\text_speed->advertised_speeds |=\n\t\t\t\tQED_EXT_SPEED_MASK_100G_P4;\n\n\t\tlink_temp = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t   port_cfg_addr +\n\t\t\t\t   offsetof(struct nvm_cfg1_port,\n\t\t\t\t\t    extended_fec_mode));\n\t\tlink->ext_fec_mode = link_temp;\n\n\t\tp_caps->default_ext_speed_caps = ext_speed->advertised_speeds;\n\t\tp_caps->default_ext_speed = ext_speed->forced_speed;\n\t\tp_caps->default_ext_autoneg = ext_speed->autoneg;\n\t\tp_caps->default_ext_fec = link->ext_fec_mode;\n\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Read default extended link config: Speed 0x%08x, Adv. Speed 0x%08x, AN: 0x%02x, FEC: 0x%02x\\n\",\n\t\t\t   ext_speed->forced_speed,\n\t\t\t   ext_speed->advertised_speeds, ext_speed->autoneg,\n\t\t\t   p_caps->default_ext_fec);\n\t}\n\n\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t   \"Read default link: Speed 0x%08x, Adv. Speed 0x%08x, AN: 0x%02x, PAUSE AN: 0x%02x, EEE: 0x%02x [0x%08x usec], FEC: 0x%02x\\n\",\n\t\t   link->speed.forced_speed, link->speed.advertised_speeds,\n\t\t   link->speed.autoneg, link->pause.autoneg,\n\t\t   p_caps->default_eee, p_caps->eee_lpi_timer,\n\t\t   p_caps->fec_default);\n\n\tif (IS_LEAD_HWFN(p_hwfn)) {\n\t\tstruct qed_dev *cdev = p_hwfn->cdev;\n\n\t\t \n\t\taddr = MCP_REG_SCRATCH + nvm_cfg1_offset +\n\t\t       offsetof(struct nvm_cfg1, glob) +\n\t\t       offsetof(struct nvm_cfg1_glob, generic_cont0);\n\n\t\tgeneric_cont0 = qed_rd(p_hwfn, p_ptt, addr);\n\n\t\tmf_mode = (generic_cont0 & NVM_CFG1_GLOB_MF_MODE_MASK) >>\n\t\t\t  NVM_CFG1_GLOB_MF_MODE_OFFSET;\n\n\t\tswitch (mf_mode) {\n\t\tcase NVM_CFG1_GLOB_MF_MODE_MF_ALLOWED:\n\t\t\tcdev->mf_bits = BIT(QED_MF_OVLAN_CLSS);\n\t\t\tbreak;\n\t\tcase NVM_CFG1_GLOB_MF_MODE_UFP:\n\t\t\tcdev->mf_bits = BIT(QED_MF_OVLAN_CLSS) |\n\t\t\t\t\tBIT(QED_MF_LLH_PROTO_CLSS) |\n\t\t\t\t\tBIT(QED_MF_UFP_SPECIFIC) |\n\t\t\t\t\tBIT(QED_MF_8021Q_TAGGING) |\n\t\t\t\t\tBIT(QED_MF_DONT_ADD_VLAN0_TAG);\n\t\t\tbreak;\n\t\tcase NVM_CFG1_GLOB_MF_MODE_BD:\n\t\t\tcdev->mf_bits = BIT(QED_MF_OVLAN_CLSS) |\n\t\t\t\t\tBIT(QED_MF_LLH_PROTO_CLSS) |\n\t\t\t\t\tBIT(QED_MF_8021AD_TAGGING) |\n\t\t\t\t\tBIT(QED_MF_DONT_ADD_VLAN0_TAG);\n\t\t\tbreak;\n\t\tcase NVM_CFG1_GLOB_MF_MODE_NPAR1_0:\n\t\t\tcdev->mf_bits = BIT(QED_MF_LLH_MAC_CLSS) |\n\t\t\t\t\tBIT(QED_MF_LLH_PROTO_CLSS) |\n\t\t\t\t\tBIT(QED_MF_LL2_NON_UNICAST) |\n\t\t\t\t\tBIT(QED_MF_INTER_PF_SWITCH) |\n\t\t\t\t\tBIT(QED_MF_DISABLE_ARFS);\n\t\t\tbreak;\n\t\tcase NVM_CFG1_GLOB_MF_MODE_DEFAULT:\n\t\t\tcdev->mf_bits = BIT(QED_MF_LLH_MAC_CLSS) |\n\t\t\t\t\tBIT(QED_MF_LLH_PROTO_CLSS) |\n\t\t\t\t\tBIT(QED_MF_LL2_NON_UNICAST);\n\t\t\tif (QED_IS_BB(p_hwfn->cdev))\n\t\t\t\tcdev->mf_bits |= BIT(QED_MF_NEED_DEF_PF);\n\t\t\tbreak;\n\t\t}\n\n\t\tDP_INFO(p_hwfn, \"Multi function mode is 0x%lx\\n\",\n\t\t\tcdev->mf_bits);\n\n\t\t \n\t\tif (QED_IS_CMT(cdev))\n\t\t\tcdev->mf_bits |= BIT(QED_MF_DISABLE_ARFS);\n\t}\n\n\tDP_INFO(p_hwfn, \"Multi function mode is 0x%lx\\n\",\n\t\tp_hwfn->cdev->mf_bits);\n\n\t \n\taddr = MCP_REG_SCRATCH + nvm_cfg1_offset +\n\t\toffsetof(struct nvm_cfg1, glob) +\n\t\toffsetof(struct nvm_cfg1_glob, device_capabilities);\n\n\tdevice_capabilities = qed_rd(p_hwfn, p_ptt, addr);\n\tif (device_capabilities & NVM_CFG1_GLOB_DEVICE_CAPABILITIES_ETHERNET)\n\t\t__set_bit(QED_DEV_CAP_ETH,\n\t\t\t  &p_hwfn->hw_info.device_capabilities);\n\tif (device_capabilities & NVM_CFG1_GLOB_DEVICE_CAPABILITIES_FCOE)\n\t\t__set_bit(QED_DEV_CAP_FCOE,\n\t\t\t  &p_hwfn->hw_info.device_capabilities);\n\tif (device_capabilities & NVM_CFG1_GLOB_DEVICE_CAPABILITIES_ISCSI)\n\t\t__set_bit(QED_DEV_CAP_ISCSI,\n\t\t\t  &p_hwfn->hw_info.device_capabilities);\n\tif (device_capabilities & NVM_CFG1_GLOB_DEVICE_CAPABILITIES_ROCE)\n\t\t__set_bit(QED_DEV_CAP_ROCE,\n\t\t\t  &p_hwfn->hw_info.device_capabilities);\n\n\t \n\taddr = MCP_REG_SCRATCH + nvm_cfg1_offset +\n\t\toffsetof(struct nvm_cfg1, glob) +\n\t\toffsetof(struct nvm_cfg1_glob, serial_number);\n\n\tfor (i = 0; i < 4; i++)\n\t\tp_hwfn->hw_info.part_num[i] = qed_rd(p_hwfn, p_ptt, addr + i * 4);\n\n\treturn qed_mcp_fill_shmem_func_info(p_hwfn, p_ptt);\n}\n\nstatic void qed_get_num_funcs(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu8 num_funcs, enabled_func_idx = p_hwfn->rel_pf_id;\n\tu32 reg_function_hide, tmp, eng_mask, low_pfs_mask;\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\n\tnum_funcs = QED_IS_AH(cdev) ? MAX_NUM_PFS_K2 : MAX_NUM_PFS_BB;\n\n\t \n\treg_function_hide = qed_rd(p_hwfn, p_ptt, MISCS_REG_FUNCTION_HIDE);\n\n\tif (reg_function_hide & 0x1) {\n\t\tif (QED_IS_BB(cdev)) {\n\t\t\tif (QED_PATH_ID(p_hwfn) && cdev->num_hwfns == 1) {\n\t\t\t\tnum_funcs = 0;\n\t\t\t\teng_mask = 0xaaaa;\n\t\t\t} else {\n\t\t\t\tnum_funcs = 1;\n\t\t\t\teng_mask = 0x5554;\n\t\t\t}\n\t\t} else {\n\t\t\tnum_funcs = 1;\n\t\t\teng_mask = 0xfffe;\n\t\t}\n\n\t\t \n\t\ttmp = (reg_function_hide ^ 0xffffffff) & eng_mask;\n\t\twhile (tmp) {\n\t\t\tif (tmp & 0x1)\n\t\t\t\tnum_funcs++;\n\t\t\ttmp >>= 0x1;\n\t\t}\n\n\t\t \n\t\tlow_pfs_mask = (0x1 << p_hwfn->abs_pf_id) - 1;\n\t\ttmp = reg_function_hide & eng_mask & low_pfs_mask;\n\t\twhile (tmp) {\n\t\t\tif (tmp & 0x1)\n\t\t\t\tenabled_func_idx--;\n\t\t\ttmp >>= 0x1;\n\t\t}\n\t}\n\n\tp_hwfn->num_funcs_on_engine = num_funcs;\n\tp_hwfn->enabled_func_idx = enabled_func_idx;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   NETIF_MSG_PROBE,\n\t\t   \"PF [rel_id %d, abs_id %d] occupies index %d within the %d enabled functions on the engine\\n\",\n\t\t   p_hwfn->rel_pf_id,\n\t\t   p_hwfn->abs_pf_id,\n\t\t   p_hwfn->enabled_func_idx, p_hwfn->num_funcs_on_engine);\n}\n\nstatic void qed_hw_info_port_num(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 addr, global_offsize, global_addr, port_mode;\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\n\t \n\tif (cdev->num_hwfns > 1) {\n\t\tcdev->num_ports_in_engine = 1;\n\t\tcdev->num_ports = 1;\n\t\treturn;\n\t}\n\n\t \n\tport_mode = qed_rd(p_hwfn, p_ptt, MISC_REG_PORT_MODE);\n\tswitch (port_mode) {\n\tcase 0x0:\n\t\tcdev->num_ports_in_engine = 1;\n\t\tbreak;\n\tcase 0x1:\n\t\tcdev->num_ports_in_engine = 2;\n\t\tbreak;\n\tcase 0x2:\n\t\tcdev->num_ports_in_engine = 4;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown port mode 0x%08x\\n\", port_mode);\n\t\tcdev->num_ports_in_engine = 1;\t \n\t\tbreak;\n\t}\n\n\t \n\taddr = SECTION_OFFSIZE_ADDR(p_hwfn->mcp_info->public_base,\n\t\t\t\t    PUBLIC_GLOBAL);\n\tglobal_offsize = qed_rd(p_hwfn, p_ptt, addr);\n\tglobal_addr = SECTION_ADDR(global_offsize, 0);\n\taddr = global_addr + offsetof(struct public_global, max_ports);\n\tcdev->num_ports = (u8)qed_rd(p_hwfn, p_ptt, addr);\n}\n\nstatic void qed_get_eee_caps(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_link_capabilities *p_caps;\n\tu32 eee_status;\n\n\tp_caps = &p_hwfn->mcp_info->link_capabilities;\n\tif (p_caps->default_eee == QED_MCP_EEE_UNSUPPORTED)\n\t\treturn;\n\n\tp_caps->eee_speed_caps = 0;\n\teee_status = qed_rd(p_hwfn, p_ptt, p_hwfn->mcp_info->port_addr +\n\t\t\t    offsetof(struct public_port, eee_status));\n\teee_status = (eee_status & EEE_SUPPORTED_SPEED_MASK) >>\n\t\t\tEEE_SUPPORTED_SPEED_OFFSET;\n\n\tif (eee_status & EEE_1G_SUPPORTED)\n\t\tp_caps->eee_speed_caps |= QED_EEE_1G_ADV;\n\tif (eee_status & EEE_10G_ADV)\n\t\tp_caps->eee_speed_caps |= QED_EEE_10G_ADV;\n}\n\nstatic int\nqed_get_hw_info(struct qed_hwfn *p_hwfn,\n\t\tstruct qed_ptt *p_ptt,\n\t\tenum qed_pci_personality personality)\n{\n\tint rc;\n\n\t \n\tif (IS_LEAD_HWFN(p_hwfn)) {\n\t\trc = qed_iov_hw_info(p_hwfn);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tif (IS_LEAD_HWFN(p_hwfn))\n\t\tqed_hw_info_port_num(p_hwfn, p_ptt);\n\n\tqed_mcp_get_capabilities(p_hwfn, p_ptt);\n\n\tqed_hw_get_nvm_info(p_hwfn, p_ptt);\n\n\trc = qed_int_igu_read_cam(p_hwfn, p_ptt);\n\tif (rc)\n\t\treturn rc;\n\n\tif (qed_mcp_is_init(p_hwfn))\n\t\tether_addr_copy(p_hwfn->hw_info.hw_mac_addr,\n\t\t\t\tp_hwfn->mcp_info->func_info.mac);\n\telse\n\t\teth_random_addr(p_hwfn->hw_info.hw_mac_addr);\n\n\tif (qed_mcp_is_init(p_hwfn)) {\n\t\tif (p_hwfn->mcp_info->func_info.ovlan != QED_MCP_VLAN_UNSET)\n\t\t\tp_hwfn->hw_info.ovlan =\n\t\t\t\tp_hwfn->mcp_info->func_info.ovlan;\n\n\t\tqed_mcp_cmd_port_init(p_hwfn, p_ptt);\n\n\t\tqed_get_eee_caps(p_hwfn, p_ptt);\n\n\t\tqed_mcp_read_ufp_config(p_hwfn, p_ptt);\n\t}\n\n\tif (qed_mcp_is_init(p_hwfn)) {\n\t\tenum qed_pci_personality protocol;\n\n\t\tprotocol = p_hwfn->mcp_info->func_info.protocol;\n\t\tp_hwfn->hw_info.personality = protocol;\n\t}\n\n\tif (QED_IS_ROCE_PERSONALITY(p_hwfn))\n\t\tp_hwfn->hw_info.multi_tc_roce_en = true;\n\n\tp_hwfn->hw_info.num_hw_tc = NUM_PHYS_TCS_4PORT_K2;\n\tp_hwfn->hw_info.num_active_tc = 1;\n\n\tqed_get_num_funcs(p_hwfn, p_ptt);\n\n\tif (qed_mcp_is_init(p_hwfn))\n\t\tp_hwfn->hw_info.mtu = p_hwfn->mcp_info->func_info.mtu;\n\n\treturn qed_hw_get_resc(p_hwfn, p_ptt);\n}\n\nstatic int qed_get_dev_info(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tu16 device_id_mask;\n\tu32 tmp;\n\n\t \n\tpci_read_config_word(cdev->pdev, PCI_VENDOR_ID, &cdev->vendor_id);\n\tpci_read_config_word(cdev->pdev, PCI_DEVICE_ID, &cdev->device_id);\n\n\t \n\tdevice_id_mask = cdev->device_id & QED_DEV_ID_MASK;\n\tswitch (device_id_mask) {\n\tcase QED_DEV_ID_MASK_BB:\n\t\tcdev->type = QED_DEV_TYPE_BB;\n\t\tbreak;\n\tcase QED_DEV_ID_MASK_AH:\n\t\tcdev->type = QED_DEV_TYPE_AH;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown device id 0x%x\\n\", cdev->device_id);\n\t\treturn -EBUSY;\n\t}\n\n\tcdev->chip_num = (u16)qed_rd(p_hwfn, p_ptt, MISCS_REG_CHIP_NUM);\n\tcdev->chip_rev = (u16)qed_rd(p_hwfn, p_ptt, MISCS_REG_CHIP_REV);\n\n\tMASK_FIELD(CHIP_REV, cdev->chip_rev);\n\n\t \n\ttmp = qed_rd(p_hwfn, p_ptt, MISCS_REG_CMT_ENABLED_FOR_PAIR);\n\n\tif (tmp & (1 << p_hwfn->rel_pf_id)) {\n\t\tDP_NOTICE(cdev->hwfns, \"device in CMT mode\\n\");\n\t\tcdev->num_hwfns = 2;\n\t} else {\n\t\tcdev->num_hwfns = 1;\n\t}\n\n\tcdev->chip_bond_id = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t    MISCS_REG_CHIP_TEST_REG) >> 4;\n\tMASK_FIELD(CHIP_BOND_ID, cdev->chip_bond_id);\n\tcdev->chip_metal = (u16)qed_rd(p_hwfn, p_ptt, MISCS_REG_CHIP_METAL);\n\tMASK_FIELD(CHIP_METAL, cdev->chip_metal);\n\n\tDP_INFO(cdev->hwfns,\n\t\t\"Chip details - %s %c%d, Num: %04x Rev: %04x Bond id: %04x Metal: %04x\\n\",\n\t\tQED_IS_BB(cdev) ? \"BB\" : \"AH\",\n\t\t'A' + cdev->chip_rev,\n\t\t(int)cdev->chip_metal,\n\t\tcdev->chip_num, cdev->chip_rev,\n\t\tcdev->chip_bond_id, cdev->chip_metal);\n\n\treturn 0;\n}\n\nstatic int qed_hw_prepare_single(struct qed_hwfn *p_hwfn,\n\t\t\t\t void __iomem *p_regview,\n\t\t\t\t void __iomem *p_doorbells,\n\t\t\t\t u64 db_phys_addr,\n\t\t\t\t enum qed_pci_personality personality)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tint rc = 0;\n\n\t \n\tp_hwfn->regview = p_regview;\n\tp_hwfn->doorbells = p_doorbells;\n\tp_hwfn->db_phys_addr = db_phys_addr;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn qed_vf_hw_prepare(p_hwfn);\n\n\t \n\tif (REG_RD(p_hwfn, PXP_PF_ME_OPAQUE_ADDR) == 0xffffffff) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"Reading the ME register returns all Fs; Preventing further chip access\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tget_function_id(p_hwfn);\n\n\t \n\trc = qed_ptt_pool_alloc(p_hwfn);\n\tif (rc)\n\t\tgoto err0;\n\n\t \n\tp_hwfn->p_main_ptt = qed_get_reserved_ptt(p_hwfn, RESERVED_PTT_MAIN);\n\n\t \n\tif (!p_hwfn->my_id) {\n\t\trc = qed_get_dev_info(p_hwfn, p_hwfn->p_main_ptt);\n\t\tif (rc)\n\t\t\tgoto err1;\n\t}\n\n\tqed_hw_hwfn_prepare(p_hwfn);\n\n\t \n\trc = qed_mcp_cmd_init(p_hwfn, p_hwfn->p_main_ptt);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn, \"Failed initializing mcp command\\n\");\n\t\tgoto err1;\n\t}\n\n\t \n\trc = qed_get_hw_info(p_hwfn, p_hwfn->p_main_ptt, personality);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to get HW information\\n\");\n\t\tgoto err2;\n\t}\n\n\t \n\tif (IS_LEAD_HWFN(p_hwfn) && !cdev->recov_in_prog) {\n\t\trc = qed_mcp_initiate_pf_flr(p_hwfn, p_hwfn->p_main_ptt);\n\t\tif (rc)\n\t\t\tDP_NOTICE(p_hwfn, \"Failed to initiate PF FLR\\n\");\n\t}\n\n\t \n\tif (IS_LEAD_HWFN(p_hwfn)) {\n\t\trc = qed_mcp_nvm_info_populate(p_hwfn);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to populate nvm info shadow\\n\");\n\t\t\tgoto err2;\n\t\t}\n\t}\n\n\t \n\trc = qed_init_alloc(p_hwfn);\n\tif (rc)\n\t\tgoto err3;\n\n\treturn rc;\nerr3:\n\tif (IS_LEAD_HWFN(p_hwfn))\n\t\tqed_mcp_nvm_info_free(p_hwfn);\nerr2:\n\tif (IS_LEAD_HWFN(p_hwfn))\n\t\tqed_iov_free_hw_info(p_hwfn->cdev);\n\tqed_mcp_free(p_hwfn);\nerr1:\n\tqed_hw_hwfn_free(p_hwfn);\nerr0:\n\treturn rc;\n}\n\nint qed_hw_prepare(struct qed_dev *cdev,\n\t\t   int personality)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tint rc;\n\n\t \n\tif (IS_PF(cdev))\n\t\tqed_init_iro_array(cdev);\n\n\t \n\trc = qed_hw_prepare_single(p_hwfn,\n\t\t\t\t   cdev->regview,\n\t\t\t\t   cdev->doorbells,\n\t\t\t\t   cdev->db_phys_addr,\n\t\t\t\t   personality);\n\tif (rc)\n\t\treturn rc;\n\n\tpersonality = p_hwfn->hw_info.personality;\n\n\t \n\tif (cdev->num_hwfns > 1) {\n\t\tvoid __iomem *p_regview, *p_doorbell;\n\t\tu64 db_phys_addr;\n\t\tu32 offset;\n\n\t\t \n\t\toffset = qed_hw_bar_size(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t BAR_ID_0) / 2;\n\t\tp_regview = cdev->regview + offset;\n\n\t\toffset = qed_hw_bar_size(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t BAR_ID_1) / 2;\n\n\t\tp_doorbell = cdev->doorbells + offset;\n\n\t\tdb_phys_addr = cdev->db_phys_addr + offset;\n\n\t\t \n\t\trc = qed_hw_prepare_single(&cdev->hwfns[1], p_regview,\n\t\t\t\t\t   p_doorbell, db_phys_addr,\n\t\t\t\t\t   personality);\n\n\t\t \n\t\tif (rc) {\n\t\t\tif (IS_PF(cdev)) {\n\t\t\t\tqed_init_free(p_hwfn);\n\t\t\t\tqed_mcp_nvm_info_free(p_hwfn);\n\t\t\t\tqed_mcp_free(p_hwfn);\n\t\t\t\tqed_hw_hwfn_free(p_hwfn);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn rc;\n}\n\nvoid qed_hw_remove(struct qed_dev *cdev)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tint i;\n\n\tif (IS_PF(cdev))\n\t\tqed_mcp_ov_update_driver_state(p_hwfn, p_hwfn->p_main_ptt,\n\t\t\t\t\t       QED_OV_DRIVER_STATE_NOT_LOADED);\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tif (IS_VF(cdev)) {\n\t\t\tqed_vf_pf_release(p_hwfn);\n\t\t\tcontinue;\n\t\t}\n\n\t\tqed_init_free(p_hwfn);\n\t\tqed_hw_hwfn_free(p_hwfn);\n\t\tqed_mcp_free(p_hwfn);\n\t}\n\n\tqed_iov_free_hw_info(cdev);\n\n\tqed_mcp_nvm_info_free(p_hwfn);\n}\n\nint qed_fw_l2_queue(struct qed_hwfn *p_hwfn, u16 src_id, u16 *dst_id)\n{\n\tif (src_id >= RESC_NUM(p_hwfn, QED_L2_QUEUE)) {\n\t\tu16 min, max;\n\n\t\tmin = (u16)RESC_START(p_hwfn, QED_L2_QUEUE);\n\t\tmax = min + RESC_NUM(p_hwfn, QED_L2_QUEUE);\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"l2_queue id [%d] is not valid, available indices [%d - %d]\\n\",\n\t\t\t  src_id, min, max);\n\n\t\treturn -EINVAL;\n\t}\n\n\t*dst_id = RESC_START(p_hwfn, QED_L2_QUEUE) + src_id;\n\n\treturn 0;\n}\n\nint qed_fw_vport(struct qed_hwfn *p_hwfn, u8 src_id, u8 *dst_id)\n{\n\tif (src_id >= RESC_NUM(p_hwfn, QED_VPORT)) {\n\t\tu8 min, max;\n\n\t\tmin = (u8)RESC_START(p_hwfn, QED_VPORT);\n\t\tmax = min + RESC_NUM(p_hwfn, QED_VPORT);\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"vport id [%d] is not valid, available indices [%d - %d]\\n\",\n\t\t\t  src_id, min, max);\n\n\t\treturn -EINVAL;\n\t}\n\n\t*dst_id = RESC_START(p_hwfn, QED_VPORT) + src_id;\n\n\treturn 0;\n}\n\nint qed_fw_rss_eng(struct qed_hwfn *p_hwfn, u8 src_id, u8 *dst_id)\n{\n\tif (src_id >= RESC_NUM(p_hwfn, QED_RSS_ENG)) {\n\t\tu8 min, max;\n\n\t\tmin = (u8)RESC_START(p_hwfn, QED_RSS_ENG);\n\t\tmax = min + RESC_NUM(p_hwfn, QED_RSS_ENG);\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"rss_eng id [%d] is not valid, available indices [%d - %d]\\n\",\n\t\t\t  src_id, min, max);\n\n\t\treturn -EINVAL;\n\t}\n\n\t*dst_id = RESC_START(p_hwfn, QED_RSS_ENG) + src_id;\n\n\treturn 0;\n}\n\nstatic int qed_set_coalesce(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t\t    u32 hw_addr, void *p_eth_qzone,\n\t\t\t    size_t eth_qzone_size, u8 timeset)\n{\n\tstruct coalescing_timeset *p_coal_timeset;\n\n\tif (p_hwfn->cdev->int_coalescing_mode != QED_COAL_MODE_ENABLE) {\n\t\tDP_NOTICE(p_hwfn, \"Coalescing configuration not enabled\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tp_coal_timeset = p_eth_qzone;\n\tmemset(p_eth_qzone, 0, eth_qzone_size);\n\tSET_FIELD(p_coal_timeset->value, COALESCING_TIMESET_TIMESET, timeset);\n\tSET_FIELD(p_coal_timeset->value, COALESCING_TIMESET_VALID, 1);\n\tqed_memcpy_to(p_hwfn, p_ptt, hw_addr, p_eth_qzone, eth_qzone_size);\n\n\treturn 0;\n}\n\nint qed_set_queue_coalesce(u16 rx_coal, u16 tx_coal, void *p_handle)\n{\n\tstruct qed_queue_cid *p_cid = p_handle;\n\tstruct qed_hwfn *p_hwfn;\n\tstruct qed_ptt *p_ptt;\n\tint rc = 0;\n\n\tp_hwfn = p_cid->p_owner;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn qed_vf_pf_set_coalesce(p_hwfn, rx_coal, tx_coal, p_cid);\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\tif (rx_coal) {\n\t\trc = qed_set_rxq_coalesce(p_hwfn, p_ptt, rx_coal, p_cid);\n\t\tif (rc)\n\t\t\tgoto out;\n\t\tp_hwfn->cdev->rx_coalesce_usecs = rx_coal;\n\t}\n\n\tif (tx_coal) {\n\t\trc = qed_set_txq_coalesce(p_hwfn, p_ptt, tx_coal, p_cid);\n\t\tif (rc)\n\t\t\tgoto out;\n\t\tp_hwfn->cdev->tx_coalesce_usecs = tx_coal;\n\t}\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\treturn rc;\n}\n\nint qed_set_rxq_coalesce(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_ptt *p_ptt,\n\t\t\t u16 coalesce, struct qed_queue_cid *p_cid)\n{\n\tstruct ustorm_eth_queue_zone eth_qzone;\n\tu8 timeset, timer_res;\n\tu32 address;\n\tint rc;\n\n\t \n\tif (coalesce <= 0x7F) {\n\t\ttimer_res = 0;\n\t} else if (coalesce <= 0xFF) {\n\t\ttimer_res = 1;\n\t} else if (coalesce <= 0x1FF) {\n\t\ttimer_res = 2;\n\t} else {\n\t\tDP_ERR(p_hwfn, \"Invalid coalesce value - %d\\n\", coalesce);\n\t\treturn -EINVAL;\n\t}\n\ttimeset = (u8)(coalesce >> timer_res);\n\n\trc = qed_int_set_timer_res(p_hwfn, p_ptt, timer_res,\n\t\t\t\t   p_cid->sb_igu_id, false);\n\tif (rc)\n\t\tgoto out;\n\n\taddress = BAR0_MAP_REG_USDM_RAM +\n\t\t  USTORM_ETH_QUEUE_ZONE_GTT_OFFSET(p_cid->abs.queue_id);\n\n\trc = qed_set_coalesce(p_hwfn, p_ptt, address, &eth_qzone,\n\t\t\t      sizeof(struct ustorm_eth_queue_zone), timeset);\n\tif (rc)\n\t\tgoto out;\n\nout:\n\treturn rc;\n}\n\nint qed_set_txq_coalesce(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_ptt *p_ptt,\n\t\t\t u16 coalesce, struct qed_queue_cid *p_cid)\n{\n\tstruct xstorm_eth_queue_zone eth_qzone;\n\tu8 timeset, timer_res;\n\tu32 address;\n\tint rc;\n\n\t \n\tif (coalesce <= 0x7F) {\n\t\ttimer_res = 0;\n\t} else if (coalesce <= 0xFF) {\n\t\ttimer_res = 1;\n\t} else if (coalesce <= 0x1FF) {\n\t\ttimer_res = 2;\n\t} else {\n\t\tDP_ERR(p_hwfn, \"Invalid coalesce value - %d\\n\", coalesce);\n\t\treturn -EINVAL;\n\t}\n\ttimeset = (u8)(coalesce >> timer_res);\n\n\trc = qed_int_set_timer_res(p_hwfn, p_ptt, timer_res,\n\t\t\t\t   p_cid->sb_igu_id, true);\n\tif (rc)\n\t\tgoto out;\n\n\taddress = BAR0_MAP_REG_XSDM_RAM +\n\t\t  XSTORM_ETH_QUEUE_ZONE_GTT_OFFSET(p_cid->abs.queue_id);\n\n\trc = qed_set_coalesce(p_hwfn, p_ptt, address, &eth_qzone,\n\t\t\t      sizeof(struct xstorm_eth_queue_zone), timeset);\nout:\n\treturn rc;\n}\n\n \nstatic void qed_configure_wfq_for_all_vports(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t\t     u32 min_pf_rate)\n{\n\tstruct init_qm_vport_params *vport_params;\n\tint i;\n\n\tvport_params = p_hwfn->qm_info.qm_vport_params;\n\n\tfor (i = 0; i < p_hwfn->qm_info.num_vports; i++) {\n\t\tu32 wfq_speed = p_hwfn->qm_info.wfq_data[i].min_speed;\n\n\t\tvport_params[i].wfq = (wfq_speed * QED_WFQ_UNIT) /\n\t\t\t\t\t\tmin_pf_rate;\n\t\tqed_init_vport_wfq(p_hwfn, p_ptt,\n\t\t\t\t   vport_params[i].first_tx_pq_id,\n\t\t\t\t   vport_params[i].wfq);\n\t}\n}\n\nstatic void qed_init_wfq_default_param(struct qed_hwfn *p_hwfn,\n\t\t\t\t       u32 min_pf_rate)\n\n{\n\tint i;\n\n\tfor (i = 0; i < p_hwfn->qm_info.num_vports; i++)\n\t\tp_hwfn->qm_info.qm_vport_params[i].wfq = 1;\n}\n\nstatic void qed_disable_wfq_for_all_vports(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t   struct qed_ptt *p_ptt,\n\t\t\t\t\t   u32 min_pf_rate)\n{\n\tstruct init_qm_vport_params *vport_params;\n\tint i;\n\n\tvport_params = p_hwfn->qm_info.qm_vport_params;\n\n\tfor (i = 0; i < p_hwfn->qm_info.num_vports; i++) {\n\t\tqed_init_wfq_default_param(p_hwfn, min_pf_rate);\n\t\tqed_init_vport_wfq(p_hwfn, p_ptt,\n\t\t\t\t   vport_params[i].first_tx_pq_id,\n\t\t\t\t   vport_params[i].wfq);\n\t}\n}\n\n \nstatic int qed_init_wfq_param(struct qed_hwfn *p_hwfn,\n\t\t\t      u16 vport_id, u32 req_rate, u32 min_pf_rate)\n{\n\tu32 total_req_min_rate = 0, total_left_rate = 0, left_rate_per_vp = 0;\n\tint non_requested_count = 0, req_count = 0, i, num_vports;\n\n\tnum_vports = p_hwfn->qm_info.num_vports;\n\n\tif (num_vports < 2) {\n\t\tDP_NOTICE(p_hwfn, \"Unexpected num_vports: %d\\n\", num_vports);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tfor (i = 0; i < num_vports; i++) {\n\t\tu32 tmp_speed;\n\n\t\tif ((i != vport_id) &&\n\t\t    p_hwfn->qm_info.wfq_data[i].configured) {\n\t\t\treq_count++;\n\t\t\ttmp_speed = p_hwfn->qm_info.wfq_data[i].min_speed;\n\t\t\ttotal_req_min_rate += tmp_speed;\n\t\t}\n\t}\n\n\t \n\treq_count++;\n\ttotal_req_min_rate += req_rate;\n\tnon_requested_count = num_vports - req_count;\n\n\tif (req_rate < min_pf_rate / QED_WFQ_UNIT) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Vport [%d] - Requested rate[%d Mbps] is less than one percent of configured PF min rate[%d Mbps]\\n\",\n\t\t\t   vport_id, req_rate, min_pf_rate);\n\t\treturn -EINVAL;\n\t}\n\n\tif (num_vports > QED_WFQ_UNIT) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Number of vports is greater than %d\\n\",\n\t\t\t   QED_WFQ_UNIT);\n\t\treturn -EINVAL;\n\t}\n\n\tif (total_req_min_rate > min_pf_rate) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Total requested min rate for all vports[%d Mbps] is greater than configured PF min rate[%d Mbps]\\n\",\n\t\t\t   total_req_min_rate, min_pf_rate);\n\t\treturn -EINVAL;\n\t}\n\n\ttotal_left_rate\t= min_pf_rate - total_req_min_rate;\n\n\tleft_rate_per_vp = total_left_rate / non_requested_count;\n\tif (left_rate_per_vp <  min_pf_rate / QED_WFQ_UNIT) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Non WFQ configured vports rate [%d Mbps] is less than one percent of configured PF min rate[%d Mbps]\\n\",\n\t\t\t   left_rate_per_vp, min_pf_rate);\n\t\treturn -EINVAL;\n\t}\n\n\tp_hwfn->qm_info.wfq_data[vport_id].min_speed = req_rate;\n\tp_hwfn->qm_info.wfq_data[vport_id].configured = true;\n\n\tfor (i = 0; i < num_vports; i++) {\n\t\tif (p_hwfn->qm_info.wfq_data[i].configured)\n\t\t\tcontinue;\n\n\t\tp_hwfn->qm_info.wfq_data[i].min_speed = left_rate_per_vp;\n\t}\n\n\treturn 0;\n}\n\nstatic int __qed_configure_vport_wfq(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt, u16 vp_id, u32 rate)\n{\n\tstruct qed_mcp_link_state *p_link;\n\tint rc = 0;\n\n\tp_link = &p_hwfn->cdev->hwfns[0].mcp_info->link_output;\n\n\tif (!p_link->min_pf_rate) {\n\t\tp_hwfn->qm_info.wfq_data[vp_id].min_speed = rate;\n\t\tp_hwfn->qm_info.wfq_data[vp_id].configured = true;\n\t\treturn rc;\n\t}\n\n\trc = qed_init_wfq_param(p_hwfn, vp_id, rate, p_link->min_pf_rate);\n\n\tif (!rc)\n\t\tqed_configure_wfq_for_all_vports(p_hwfn, p_ptt,\n\t\t\t\t\t\t p_link->min_pf_rate);\n\telse\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Validation failed while configuring min rate\\n\");\n\n\treturn rc;\n}\n\nstatic int __qed_configure_vp_wfq_on_link_change(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t\t struct qed_ptt *p_ptt,\n\t\t\t\t\t\t u32 min_pf_rate)\n{\n\tbool use_wfq = false;\n\tint rc = 0;\n\tu16 i;\n\n\t \n\tfor (i = 0; i < p_hwfn->qm_info.num_vports; i++) {\n\t\tu32 rate;\n\n\t\tif (!p_hwfn->qm_info.wfq_data[i].configured)\n\t\t\tcontinue;\n\n\t\trate = p_hwfn->qm_info.wfq_data[i].min_speed;\n\t\tuse_wfq = true;\n\n\t\trc = qed_init_wfq_param(p_hwfn, i, rate, min_pf_rate);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"WFQ validation failed while configuring min rate\\n\");\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!rc && use_wfq)\n\t\tqed_configure_wfq_for_all_vports(p_hwfn, p_ptt, min_pf_rate);\n\telse\n\t\tqed_disable_wfq_for_all_vports(p_hwfn, p_ptt, min_pf_rate);\n\n\treturn rc;\n}\n\n \nint qed_configure_vport_wfq(struct qed_dev *cdev, u16 vp_id, u32 rate)\n{\n\tint i, rc = -EINVAL;\n\n\t \n\tif (cdev->num_hwfns > 1) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"WFQ configuration is not supported for this device\\n\");\n\t\treturn rc;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tstruct qed_ptt *p_ptt;\n\n\t\tp_ptt = qed_ptt_acquire(p_hwfn);\n\t\tif (!p_ptt)\n\t\t\treturn -EBUSY;\n\n\t\trc = __qed_configure_vport_wfq(p_hwfn, p_ptt, vp_id, rate);\n\n\t\tif (rc) {\n\t\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t\t\treturn rc;\n\t\t}\n\n\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t}\n\n\treturn rc;\n}\n\n \nvoid qed_configure_vp_wfq_on_link_change(struct qed_dev *cdev,\n\t\t\t\t\t struct qed_ptt *p_ptt, u32 min_pf_rate)\n{\n\tint i;\n\n\tif (cdev->num_hwfns > 1) {\n\t\tDP_VERBOSE(cdev,\n\t\t\t   NETIF_MSG_LINK,\n\t\t\t   \"WFQ configuration is not supported for this device\\n\");\n\t\treturn;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\t__qed_configure_vp_wfq_on_link_change(p_hwfn, p_ptt,\n\t\t\t\t\t\t      min_pf_rate);\n\t}\n}\n\nint __qed_configure_pf_max_bandwidth(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t     struct qed_mcp_link_state *p_link,\n\t\t\t\t     u8 max_bw)\n{\n\tint rc = 0;\n\n\tp_hwfn->mcp_info->func_info.bandwidth_max = max_bw;\n\n\tif (!p_link->line_speed && (max_bw != 100))\n\t\treturn rc;\n\n\tp_link->speed = (p_link->line_speed * max_bw) / 100;\n\tp_hwfn->qm_info.pf_rl = p_link->speed;\n\n\t \n\tif (max_bw == 100)\n\t\tp_hwfn->qm_info.pf_rl = 100000;\n\n\trc = qed_init_pf_rl(p_hwfn, p_ptt, p_hwfn->rel_pf_id,\n\t\t\t    p_hwfn->qm_info.pf_rl);\n\n\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t   \"Configured MAX bandwidth to be %08x Mb/sec\\n\",\n\t\t   p_link->speed);\n\n\treturn rc;\n}\n\n \nint qed_configure_pf_max_bandwidth(struct qed_dev *cdev, u8 max_bw)\n{\n\tint i, rc = -EINVAL;\n\n\tif (max_bw < 1 || max_bw > 100) {\n\t\tDP_NOTICE(cdev, \"PF max bw valid range is [1-100]\\n\");\n\t\treturn rc;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn\t*p_hwfn = &cdev->hwfns[i];\n\t\tstruct qed_hwfn *p_lead = QED_LEADING_HWFN(cdev);\n\t\tstruct qed_mcp_link_state *p_link;\n\t\tstruct qed_ptt *p_ptt;\n\n\t\tp_link = &p_lead->mcp_info->link_output;\n\n\t\tp_ptt = qed_ptt_acquire(p_hwfn);\n\t\tif (!p_ptt)\n\t\t\treturn -EBUSY;\n\n\t\trc = __qed_configure_pf_max_bandwidth(p_hwfn, p_ptt,\n\t\t\t\t\t\t      p_link, max_bw);\n\n\t\tqed_ptt_release(p_hwfn, p_ptt);\n\n\t\tif (rc)\n\t\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\nint __qed_configure_pf_min_bandwidth(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t     struct qed_mcp_link_state *p_link,\n\t\t\t\t     u8 min_bw)\n{\n\tint rc = 0;\n\n\tp_hwfn->mcp_info->func_info.bandwidth_min = min_bw;\n\tp_hwfn->qm_info.pf_wfq = min_bw;\n\n\tif (!p_link->line_speed)\n\t\treturn rc;\n\n\tp_link->min_pf_rate = (p_link->line_speed * min_bw) / 100;\n\n\trc = qed_init_pf_wfq(p_hwfn, p_ptt, p_hwfn->rel_pf_id, min_bw);\n\n\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t   \"Configured MIN bandwidth to be %d Mb/sec\\n\",\n\t\t   p_link->min_pf_rate);\n\n\treturn rc;\n}\n\n \nint qed_configure_pf_min_bandwidth(struct qed_dev *cdev, u8 min_bw)\n{\n\tint i, rc = -EINVAL;\n\n\tif (min_bw < 1 || min_bw > 100) {\n\t\tDP_NOTICE(cdev, \"PF min bw valid range is [1-100]\\n\");\n\t\treturn rc;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tstruct qed_hwfn *p_lead = QED_LEADING_HWFN(cdev);\n\t\tstruct qed_mcp_link_state *p_link;\n\t\tstruct qed_ptt *p_ptt;\n\n\t\tp_link = &p_lead->mcp_info->link_output;\n\n\t\tp_ptt = qed_ptt_acquire(p_hwfn);\n\t\tif (!p_ptt)\n\t\t\treturn -EBUSY;\n\n\t\trc = __qed_configure_pf_min_bandwidth(p_hwfn, p_ptt,\n\t\t\t\t\t\t      p_link, min_bw);\n\t\tif (rc) {\n\t\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t\t\treturn rc;\n\t\t}\n\n\t\tif (p_link->min_pf_rate) {\n\t\t\tu32 min_rate = p_link->min_pf_rate;\n\n\t\t\trc = __qed_configure_vp_wfq_on_link_change(p_hwfn,\n\t\t\t\t\t\t\t\t   p_ptt,\n\t\t\t\t\t\t\t\t   min_rate);\n\t\t}\n\n\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t}\n\n\treturn rc;\n}\n\nvoid qed_clean_wfq_db(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_link_state *p_link;\n\n\tp_link = &p_hwfn->mcp_info->link_output;\n\n\tif (p_link->min_pf_rate)\n\t\tqed_disable_wfq_for_all_vports(p_hwfn, p_ptt,\n\t\t\t\t\t       p_link->min_pf_rate);\n\n\tmemset(p_hwfn->qm_info.wfq_data, 0,\n\t       sizeof(*p_hwfn->qm_info.wfq_data) * p_hwfn->qm_info.num_vports);\n}\n\nint qed_device_num_ports(struct qed_dev *cdev)\n{\n\treturn cdev->num_ports;\n}\n\nvoid qed_set_fw_mac_addr(__le16 *fw_msb,\n\t\t\t __le16 *fw_mid, __le16 *fw_lsb, u8 *mac)\n{\n\t((u8 *)fw_msb)[0] = mac[1];\n\t((u8 *)fw_msb)[1] = mac[0];\n\t((u8 *)fw_mid)[0] = mac[3];\n\t((u8 *)fw_mid)[1] = mac[2];\n\t((u8 *)fw_lsb)[0] = mac[5];\n\t((u8 *)fw_lsb)[1] = mac[4];\n}\n\nstatic int qed_llh_shadow_remove_all_filters(struct qed_dev *cdev, u8 ppfid)\n{\n\tstruct qed_llh_info *p_llh_info = cdev->p_llh_info;\n\tstruct qed_llh_filter_info *p_filters;\n\tint rc;\n\n\trc = qed_llh_shadow_sanity(cdev, ppfid, 0, \"remove_all\");\n\tif (rc)\n\t\treturn rc;\n\n\tp_filters = p_llh_info->pp_filters[ppfid];\n\tmemset(p_filters, 0, NIG_REG_LLH_FUNC_FILTER_EN_SIZE *\n\t       sizeof(*p_filters));\n\n\treturn 0;\n}\n\nstatic void qed_llh_clear_ppfid_filters(struct qed_dev *cdev, u8 ppfid)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = qed_ptt_acquire(p_hwfn);\n\tu8 filter_idx, abs_ppfid;\n\tint rc = 0;\n\n\tif (!p_ptt)\n\t\treturn;\n\n\tif (!test_bit(QED_MF_LLH_PROTO_CLSS, &cdev->mf_bits) &&\n\t    !test_bit(QED_MF_LLH_MAC_CLSS, &cdev->mf_bits))\n\t\tgoto out;\n\n\trc = qed_llh_abs_ppfid(cdev, ppfid, &abs_ppfid);\n\tif (rc)\n\t\tgoto out;\n\n\trc = qed_llh_shadow_remove_all_filters(cdev, ppfid);\n\tif (rc)\n\t\tgoto out;\n\n\tfor (filter_idx = 0; filter_idx < NIG_REG_LLH_FUNC_FILTER_EN_SIZE;\n\t     filter_idx++) {\n\t\trc = qed_llh_remove_filter(p_hwfn, p_ptt,\n\t\t\t\t\t   abs_ppfid, filter_idx);\n\t\tif (rc)\n\t\t\tgoto out;\n\t}\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n}\n\nint qed_llh_add_src_tcp_port_filter(struct qed_dev *cdev, u16 src_port)\n{\n\treturn qed_llh_add_protocol_filter(cdev, 0,\n\t\t\t\t\t   QED_LLH_FILTER_TCP_SRC_PORT,\n\t\t\t\t\t   src_port, QED_LLH_DONT_CARE);\n}\n\nvoid qed_llh_remove_src_tcp_port_filter(struct qed_dev *cdev, u16 src_port)\n{\n\tqed_llh_remove_protocol_filter(cdev, 0,\n\t\t\t\t       QED_LLH_FILTER_TCP_SRC_PORT,\n\t\t\t\t       src_port, QED_LLH_DONT_CARE);\n}\n\nint qed_llh_add_dst_tcp_port_filter(struct qed_dev *cdev, u16 dest_port)\n{\n\treturn qed_llh_add_protocol_filter(cdev, 0,\n\t\t\t\t\t   QED_LLH_FILTER_TCP_DEST_PORT,\n\t\t\t\t\t   QED_LLH_DONT_CARE, dest_port);\n}\n\nvoid qed_llh_remove_dst_tcp_port_filter(struct qed_dev *cdev, u16 dest_port)\n{\n\tqed_llh_remove_protocol_filter(cdev, 0,\n\t\t\t\t       QED_LLH_FILTER_TCP_DEST_PORT,\n\t\t\t\t       QED_LLH_DONT_CARE, dest_port);\n}\n\nvoid qed_llh_clear_all_filters(struct qed_dev *cdev)\n{\n\tu8 ppfid;\n\n\tif (!test_bit(QED_MF_LLH_PROTO_CLSS, &cdev->mf_bits) &&\n\t    !test_bit(QED_MF_LLH_MAC_CLSS, &cdev->mf_bits))\n\t\treturn;\n\n\tfor (ppfid = 0; ppfid < cdev->p_llh_info->num_ppfid; ppfid++)\n\t\tqed_llh_clear_ppfid_filters(cdev, ppfid);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}