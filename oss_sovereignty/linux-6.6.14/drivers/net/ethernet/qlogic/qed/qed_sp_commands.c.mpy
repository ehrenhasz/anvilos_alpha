{
  "module_name": "qed_sp_commands.c",
  "hash_id": "6fc2034e9a3caf534fe9526565308a64a58d914d6fa0fccdc7b1a811ca4a7dfc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qed/qed_sp_commands.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <asm/byteorder.h>\n#include <linux/bitops.h>\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include \"qed.h\"\n#include <linux/qed/qed_chain.h>\n#include \"qed_cxt.h\"\n#include \"qed_dcbx.h\"\n#include \"qed_hsi.h\"\n#include \"qed_hw.h\"\n#include \"qed_int.h\"\n#include \"qed_reg_addr.h\"\n#include \"qed_sp.h\"\n#include \"qed_sriov.h\"\n\nvoid qed_sp_destroy_request(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_spq_entry *p_ent)\n{\n\t \n\tif (p_ent->queue == &p_hwfn->p_spq->unlimited_pending)\n\t\tkfree(p_ent);\n\telse\n\t\tqed_spq_return_entry(p_hwfn, p_ent);\n}\n\nint qed_sp_init_request(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_spq_entry **pp_ent,\n\t\t\tu8 cmd, u8 protocol, struct qed_sp_init_data *p_data)\n{\n\tu32 opaque_cid = p_data->opaque_fid << 16 | p_data->cid;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tint rc;\n\n\tif (!pp_ent)\n\t\treturn -ENOMEM;\n\n\trc = qed_spq_get_entry(p_hwfn, pp_ent);\n\n\tif (rc)\n\t\treturn rc;\n\n\tp_ent = *pp_ent;\n\n\tp_ent->elem.hdr.cid\t\t= cpu_to_le32(opaque_cid);\n\tp_ent->elem.hdr.cmd_id\t\t= cmd;\n\tp_ent->elem.hdr.protocol_id\t= protocol;\n\n\tp_ent->priority\t\t= QED_SPQ_PRIORITY_NORMAL;\n\tp_ent->comp_mode\t= p_data->comp_mode;\n\tp_ent->comp_done.done\t= 0;\n\n\tswitch (p_ent->comp_mode) {\n\tcase QED_SPQ_MODE_EBLOCK:\n\t\tp_ent->comp_cb.cookie = &p_ent->comp_done;\n\t\tbreak;\n\n\tcase QED_SPQ_MODE_BLOCK:\n\t\tif (!p_data->p_comp_data)\n\t\t\tgoto err;\n\n\t\tp_ent->comp_cb.cookie = p_data->p_comp_data->cookie;\n\t\tbreak;\n\n\tcase QED_SPQ_MODE_CB:\n\t\tif (!p_data->p_comp_data)\n\t\t\tp_ent->comp_cb.function = NULL;\n\t\telse\n\t\t\tp_ent->comp_cb = *p_data->p_comp_data;\n\t\tbreak;\n\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown SPQE completion mode %d\\n\",\n\t\t\t  p_ent->comp_mode);\n\t\tgoto err;\n\t}\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SPQ,\n\t\t   \"Initialized: CID %08x %s:[%02x] %s:%02x data_addr %llx comp_mode [%s]\\n\",\n\t\t   opaque_cid, qed_get_ramrod_cmd_id_str(protocol, cmd),\n\t\t   cmd, qed_get_protocol_type_str(protocol), protocol,\n\t\t   (unsigned long long)(uintptr_t)&p_ent->ramrod,\n\t\t   D_TRINE(p_ent->comp_mode, QED_SPQ_MODE_EBLOCK,\n\t\t\t   QED_SPQ_MODE_BLOCK, \"MODE_EBLOCK\", \"MODE_BLOCK\",\n\t\t\t   \"MODE_CB\"));\n\n\tmemset(&p_ent->ramrod, 0, sizeof(p_ent->ramrod));\n\n\treturn 0;\n\nerr:\n\tqed_sp_destroy_request(p_hwfn, p_ent);\n\n\treturn -EINVAL;\n}\n\nstatic enum tunnel_clss qed_tunn_clss_to_fw_clss(u8 type)\n{\n\tswitch (type) {\n\tcase QED_TUNN_CLSS_MAC_VLAN:\n\t\treturn TUNNEL_CLSS_MAC_VLAN;\n\tcase QED_TUNN_CLSS_MAC_VNI:\n\t\treturn TUNNEL_CLSS_MAC_VNI;\n\tcase QED_TUNN_CLSS_INNER_MAC_VLAN:\n\t\treturn TUNNEL_CLSS_INNER_MAC_VLAN;\n\tcase QED_TUNN_CLSS_INNER_MAC_VNI:\n\t\treturn TUNNEL_CLSS_INNER_MAC_VNI;\n\tcase QED_TUNN_CLSS_MAC_VLAN_DUAL_STAGE:\n\t\treturn TUNNEL_CLSS_MAC_VLAN_DUAL_STAGE;\n\tdefault:\n\t\treturn TUNNEL_CLSS_MAC_VLAN;\n\t}\n}\n\nstatic void\nqed_set_pf_update_tunn_mode(struct qed_tunnel_info *p_tun,\n\t\t\t    struct qed_tunnel_info *p_src, bool b_pf_start)\n{\n\tif (p_src->vxlan.b_update_mode || b_pf_start)\n\t\tp_tun->vxlan.b_mode_enabled = p_src->vxlan.b_mode_enabled;\n\n\tif (p_src->l2_gre.b_update_mode || b_pf_start)\n\t\tp_tun->l2_gre.b_mode_enabled = p_src->l2_gre.b_mode_enabled;\n\n\tif (p_src->ip_gre.b_update_mode || b_pf_start)\n\t\tp_tun->ip_gre.b_mode_enabled = p_src->ip_gre.b_mode_enabled;\n\n\tif (p_src->l2_geneve.b_update_mode || b_pf_start)\n\t\tp_tun->l2_geneve.b_mode_enabled =\n\t\t    p_src->l2_geneve.b_mode_enabled;\n\n\tif (p_src->ip_geneve.b_update_mode || b_pf_start)\n\t\tp_tun->ip_geneve.b_mode_enabled =\n\t\t    p_src->ip_geneve.b_mode_enabled;\n}\n\nstatic void qed_set_tunn_cls_info(struct qed_tunnel_info *p_tun,\n\t\t\t\t  struct qed_tunnel_info *p_src)\n{\n\tint type;\n\n\tp_tun->b_update_rx_cls = p_src->b_update_rx_cls;\n\tp_tun->b_update_tx_cls = p_src->b_update_tx_cls;\n\n\ttype = qed_tunn_clss_to_fw_clss(p_src->vxlan.tun_cls);\n\tp_tun->vxlan.tun_cls = type;\n\ttype = qed_tunn_clss_to_fw_clss(p_src->l2_gre.tun_cls);\n\tp_tun->l2_gre.tun_cls = type;\n\ttype = qed_tunn_clss_to_fw_clss(p_src->ip_gre.tun_cls);\n\tp_tun->ip_gre.tun_cls = type;\n\ttype = qed_tunn_clss_to_fw_clss(p_src->l2_geneve.tun_cls);\n\tp_tun->l2_geneve.tun_cls = type;\n\ttype = qed_tunn_clss_to_fw_clss(p_src->ip_geneve.tun_cls);\n\tp_tun->ip_geneve.tun_cls = type;\n}\n\nstatic void qed_set_tunn_ports(struct qed_tunnel_info *p_tun,\n\t\t\t       struct qed_tunnel_info *p_src)\n{\n\tp_tun->geneve_port.b_update_port = p_src->geneve_port.b_update_port;\n\tp_tun->vxlan_port.b_update_port = p_src->vxlan_port.b_update_port;\n\n\tif (p_src->geneve_port.b_update_port)\n\t\tp_tun->geneve_port.port = p_src->geneve_port.port;\n\n\tif (p_src->vxlan_port.b_update_port)\n\t\tp_tun->vxlan_port.port = p_src->vxlan_port.port;\n}\n\nstatic void\n__qed_set_ramrod_tunnel_param(u8 *p_tunn_cls,\n\t\t\t      struct qed_tunn_update_type *tun_type)\n{\n\t*p_tunn_cls = tun_type->tun_cls;\n}\n\nstatic void\nqed_set_ramrod_tunnel_param(u8 *p_tunn_cls,\n\t\t\t    struct qed_tunn_update_type *tun_type,\n\t\t\t    u8 *p_update_port,\n\t\t\t    __le16 *p_port,\n\t\t\t    struct qed_tunn_update_udp_port *p_udp_port)\n{\n\t__qed_set_ramrod_tunnel_param(p_tunn_cls, tun_type);\n\tif (p_udp_port->b_update_port) {\n\t\t*p_update_port = 1;\n\t\t*p_port = cpu_to_le16(p_udp_port->port);\n\t}\n}\n\nstatic void\nqed_tunn_set_pf_update_params(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_tunnel_info *p_src,\n\t\t\t      struct pf_update_tunnel_config *p_tunn_cfg)\n{\n\tstruct qed_tunnel_info *p_tun = &p_hwfn->cdev->tunnel;\n\n\tqed_set_pf_update_tunn_mode(p_tun, p_src, false);\n\tqed_set_tunn_cls_info(p_tun, p_src);\n\tqed_set_tunn_ports(p_tun, p_src);\n\n\tqed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_vxlan,\n\t\t\t\t    &p_tun->vxlan,\n\t\t\t\t    &p_tunn_cfg->set_vxlan_udp_port_flg,\n\t\t\t\t    &p_tunn_cfg->vxlan_udp_port,\n\t\t\t\t    &p_tun->vxlan_port);\n\n\tqed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_l2geneve,\n\t\t\t\t    &p_tun->l2_geneve,\n\t\t\t\t    &p_tunn_cfg->set_geneve_udp_port_flg,\n\t\t\t\t    &p_tunn_cfg->geneve_udp_port,\n\t\t\t\t    &p_tun->geneve_port);\n\n\t__qed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_ipgeneve,\n\t\t\t\t      &p_tun->ip_geneve);\n\n\t__qed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_l2gre,\n\t\t\t\t      &p_tun->l2_gre);\n\n\t__qed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_ipgre,\n\t\t\t\t      &p_tun->ip_gre);\n\n\tp_tunn_cfg->update_rx_pf_clss = p_tun->b_update_rx_cls;\n}\n\nstatic void qed_set_hw_tunn_mode(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt,\n\t\t\t\t struct qed_tunnel_info *p_tun)\n{\n\tqed_set_gre_enable(p_hwfn, p_ptt, p_tun->l2_gre.b_mode_enabled,\n\t\t\t   p_tun->ip_gre.b_mode_enabled);\n\tqed_set_vxlan_enable(p_hwfn, p_ptt, p_tun->vxlan.b_mode_enabled);\n\n\tqed_set_geneve_enable(p_hwfn, p_ptt, p_tun->l2_geneve.b_mode_enabled,\n\t\t\t      p_tun->ip_geneve.b_mode_enabled);\n}\n\nstatic void qed_set_hw_tunn_mode_port(struct qed_hwfn *p_hwfn,\n\t\t\t\t      struct qed_ptt *p_ptt,\n\t\t\t\t      struct qed_tunnel_info *p_tunn)\n{\n\tif (p_tunn->vxlan_port.b_update_port)\n\t\tqed_set_vxlan_dest_port(p_hwfn, p_ptt,\n\t\t\t\t\tp_tunn->vxlan_port.port);\n\n\tif (p_tunn->geneve_port.b_update_port)\n\t\tqed_set_geneve_dest_port(p_hwfn, p_ptt,\n\t\t\t\t\t p_tunn->geneve_port.port);\n\n\tqed_set_hw_tunn_mode(p_hwfn, p_ptt, p_tunn);\n}\n\nstatic void\nqed_tunn_set_pf_start_params(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_tunnel_info *p_src,\n\t\t\t     struct pf_start_tunnel_config *p_tunn_cfg)\n{\n\tstruct qed_tunnel_info *p_tun = &p_hwfn->cdev->tunnel;\n\n\tif (!p_src)\n\t\treturn;\n\n\tqed_set_pf_update_tunn_mode(p_tun, p_src, true);\n\tqed_set_tunn_cls_info(p_tun, p_src);\n\tqed_set_tunn_ports(p_tun, p_src);\n\n\tqed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_vxlan,\n\t\t\t\t    &p_tun->vxlan,\n\t\t\t\t    &p_tunn_cfg->set_vxlan_udp_port_flg,\n\t\t\t\t    &p_tunn_cfg->vxlan_udp_port,\n\t\t\t\t    &p_tun->vxlan_port);\n\n\tqed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_l2geneve,\n\t\t\t\t    &p_tun->l2_geneve,\n\t\t\t\t    &p_tunn_cfg->set_geneve_udp_port_flg,\n\t\t\t\t    &p_tunn_cfg->geneve_udp_port,\n\t\t\t\t    &p_tun->geneve_port);\n\n\t__qed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_ipgeneve,\n\t\t\t\t      &p_tun->ip_geneve);\n\n\t__qed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_l2gre,\n\t\t\t\t      &p_tun->l2_gre);\n\n\t__qed_set_ramrod_tunnel_param(&p_tunn_cfg->tunnel_clss_ipgre,\n\t\t\t\t      &p_tun->ip_gre);\n}\n\nint qed_sp_pf_start(struct qed_hwfn *p_hwfn,\n\t\t    struct qed_ptt *p_ptt,\n\t\t    struct qed_tunnel_info *p_tunn,\n\t\t    bool allow_npar_tx_switch)\n{\n\tstruct outer_tag_config_struct *outer_tag_config;\n\tstruct pf_start_ramrod_data *p_ramrod = NULL;\n\tu16 sb = qed_int_get_sp_sb_id(p_hwfn);\n\tu8 sb_index = p_hwfn->p_eq->eq_sb_index;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tu8 page_cnt, i;\n\tint rc;\n\n\t \n\tqed_eq_prod_update(p_hwfn,\n\t\t\t   qed_chain_get_prod_idx(&p_hwfn->p_eq->chain));\n\n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_PF_START,\n\t\t\t\t PROTOCOLID_COMMON, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.pf_start;\n\n\tp_ramrod->event_ring_sb_id\t= cpu_to_le16(sb);\n\tp_ramrod->event_ring_sb_index\t= sb_index;\n\tp_ramrod->path_id\t\t= QED_PATH_ID(p_hwfn);\n\tp_ramrod->dont_log_ramrods\t= 0;\n\tp_ramrod->log_type_mask\t\t= cpu_to_le16(0xf);\n\n\tif (test_bit(QED_MF_OVLAN_CLSS, &p_hwfn->cdev->mf_bits))\n\t\tp_ramrod->mf_mode = MF_OVLAN;\n\telse\n\t\tp_ramrod->mf_mode = MF_NPAR;\n\n\touter_tag_config = &p_ramrod->outer_tag_config;\n\touter_tag_config->outer_tag.tci = cpu_to_le16(p_hwfn->hw_info.ovlan);\n\n\tif (test_bit(QED_MF_8021Q_TAGGING, &p_hwfn->cdev->mf_bits)) {\n\t\touter_tag_config->outer_tag.tpid = cpu_to_le16(ETH_P_8021Q);\n\t} else if (test_bit(QED_MF_8021AD_TAGGING, &p_hwfn->cdev->mf_bits)) {\n\t\touter_tag_config->outer_tag.tpid = cpu_to_le16(ETH_P_8021AD);\n\t\touter_tag_config->enable_stag_pri_change = 1;\n\t}\n\n\touter_tag_config->pri_map_valid = 1;\n\tfor (i = 0; i < QED_MAX_PFC_PRIORITIES; i++)\n\t\touter_tag_config->inner_to_outer_pri_map[i] = i;\n\n\t \n\tif (test_bit(QED_MF_UFP_SPECIFIC, &p_hwfn->cdev->mf_bits)) {\n\t\tif (p_hwfn->ufp_info.pri_type == QED_UFP_PRI_OS)\n\t\t\touter_tag_config->enable_stag_pri_change = 1;\n\t\telse\n\t\t\touter_tag_config->enable_stag_pri_change = 0;\n\n\t\touter_tag_config->outer_tag.tci |=\n\t\t    cpu_to_le16(((u16)p_hwfn->ufp_info.tc << 13));\n\t}\n\n\t \n\tDMA_REGPAIR_LE(p_ramrod->event_ring_pbl_addr,\n\t\t       qed_chain_get_pbl_phys(&p_hwfn->p_eq->chain));\n\tpage_cnt = (u8)qed_chain_get_page_cnt(&p_hwfn->p_eq->chain);\n\tp_ramrod->event_ring_num_pages = page_cnt;\n\n\t \n\tDMA_REGPAIR_LE(p_ramrod->consolid_q_pbl_base_addr,\n\t\t       qed_chain_get_pbl_phys(&p_hwfn->p_consq->chain));\n\tpage_cnt = (u8)qed_chain_get_page_cnt(&p_hwfn->p_consq->chain);\n\tp_ramrod->consolid_q_num_pages = page_cnt;\n\n\tqed_tunn_set_pf_start_params(p_hwfn, p_tunn, &p_ramrod->tunnel_config);\n\n\tif (test_bit(QED_MF_INTER_PF_SWITCH, &p_hwfn->cdev->mf_bits))\n\t\tp_ramrod->allow_npar_tx_switching = allow_npar_tx_switch;\n\n\tswitch (p_hwfn->hw_info.personality) {\n\tcase QED_PCI_ETH:\n\t\tp_ramrod->personality = PERSONALITY_ETH;\n\t\tbreak;\n\tcase QED_PCI_FCOE:\n\t\tp_ramrod->personality = PERSONALITY_FCOE;\n\t\tbreak;\n\tcase QED_PCI_ISCSI:\n\tcase QED_PCI_NVMETCP:\n\t\tp_ramrod->personality = PERSONALITY_TCP_ULP;\n\t\tbreak;\n\tcase QED_PCI_ETH_ROCE:\n\tcase QED_PCI_ETH_IWARP:\n\t\tp_ramrod->personality = PERSONALITY_RDMA_AND_ETH;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown personality %d\\n\",\n\t\t\t  p_hwfn->hw_info.personality);\n\t\tp_ramrod->personality = PERSONALITY_ETH;\n\t}\n\n\tif (p_hwfn->cdev->p_iov_info) {\n\t\tstruct qed_hw_sriov_info *p_iov = p_hwfn->cdev->p_iov_info;\n\n\t\tp_ramrod->base_vf_id = (u8)p_iov->first_vf_in_pf;\n\t\tp_ramrod->num_vfs = (u8)p_iov->total_vfs;\n\t}\n\tp_ramrod->hsi_fp_ver.major_ver_arr[ETH_VER_KEY] = ETH_HSI_VER_MAJOR;\n\tp_ramrod->hsi_fp_ver.minor_ver_arr[ETH_VER_KEY] = ETH_HSI_VER_MINOR;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\n\t\t   \"Setting event_ring_sb [id %04x index %02x], outer_tag.tci [%d]\\n\",\n\t\t   sb, sb_index, outer_tag_config->outer_tag.tci);\n\n\trc = qed_spq_post(p_hwfn, p_ent, NULL);\n\n\tif (p_tunn)\n\t\tqed_set_hw_tunn_mode_port(p_hwfn, p_ptt,\n\t\t\t\t\t  &p_hwfn->cdev->tunnel);\n\n\treturn rc;\n}\n\nint qed_sp_pf_update(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_CB;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_PF_UPDATE, PROTOCOLID_COMMON,\n\t\t\t\t &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tqed_dcbx_set_pf_update_params(&p_hwfn->p_dcbx_info->results,\n\t\t\t\t      &p_ent->ramrod.pf_update);\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nint qed_sp_pf_update_ufp(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\tif (p_hwfn->ufp_info.pri_type == QED_UFP_PRI_UNKNOWN) {\n\t\tDP_INFO(p_hwfn, \"Invalid priority type %d\\n\",\n\t\t\tp_hwfn->ufp_info.pri_type);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_CB;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_PF_UPDATE, PROTOCOLID_COMMON,\n\t\t\t\t &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ent->ramrod.pf_update.update_enable_stag_pri_change = true;\n\tif (p_hwfn->ufp_info.pri_type == QED_UFP_PRI_OS)\n\t\tp_ent->ramrod.pf_update.enable_stag_pri_change = 1;\n\telse\n\t\tp_ent->ramrod.pf_update.enable_stag_pri_change = 0;\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\n \nint qed_sp_pf_update_tunn_cfg(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_ptt *p_ptt,\n\t\t\t      struct qed_tunnel_info *p_tunn,\n\t\t\t      enum spq_mode comp_mode,\n\t\t\t      struct qed_spq_comp_cb *p_comp_data)\n{\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn qed_vf_pf_tunnel_param_update(p_hwfn, p_tunn);\n\n\tif (!p_tunn)\n\t\treturn -EINVAL;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = comp_mode;\n\tinit_data.p_comp_data = p_comp_data;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_PF_UPDATE, PROTOCOLID_COMMON,\n\t\t\t\t &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tqed_tunn_set_pf_update_params(p_hwfn, p_tunn,\n\t\t\t\t      &p_ent->ramrod.pf_update.tunnel_config);\n\n\trc = qed_spq_post(p_hwfn, p_ent, NULL);\n\tif (rc)\n\t\treturn rc;\n\n\tqed_set_hw_tunn_mode_port(p_hwfn, p_ptt, &p_hwfn->cdev->tunnel);\n\n\treturn rc;\n}\n\nint qed_sp_pf_stop(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_PF_STOP, PROTOCOLID_COMMON,\n\t\t\t\t &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nint qed_sp_heartbeat_ramrod(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_EMPTY, PROTOCOLID_COMMON,\n\t\t\t\t &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nint qed_sp_pf_update_stag(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_CB;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t COMMON_RAMROD_PF_UPDATE, PROTOCOLID_COMMON,\n\t\t\t\t &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ent->ramrod.pf_update.update_mf_vlan_flag = true;\n\tp_ent->ramrod.pf_update.mf_vlan = cpu_to_le16(p_hwfn->hw_info.ovlan);\n\tif (test_bit(QED_MF_UFP_SPECIFIC, &p_hwfn->cdev->mf_bits))\n\t\tp_ent->ramrod.pf_update.mf_vlan |=\n\t\t\tcpu_to_le16(((u16)p_hwfn->ufp_info.tc << 13));\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}