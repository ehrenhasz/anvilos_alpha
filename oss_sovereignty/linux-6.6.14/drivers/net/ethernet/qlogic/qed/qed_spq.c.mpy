{
  "module_name": "qed_spq.c",
  "hash_id": "2abdacab5db6d21187136de3a9fc800e692bf54a9d769a99650422ec06fe7e64",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qed/qed_spq.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <asm/byteorder.h>\n#include <linux/io.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include \"qed.h\"\n#include \"qed_cxt.h\"\n#include \"qed_dev_api.h\"\n#include \"qed_hsi.h\"\n#include \"qed_iro_hsi.h\"\n#include \"qed_hw.h\"\n#include \"qed_int.h\"\n#include \"qed_iscsi.h\"\n#include \"qed_mcp.h\"\n#include \"qed_ooo.h\"\n#include \"qed_reg_addr.h\"\n#include \"qed_sp.h\"\n#include \"qed_sriov.h\"\n#include \"qed_rdma.h\"\n\n \n\n#define SPQ_HIGH_PRI_RESERVE_DEFAULT    (1)\n\n#define SPQ_BLOCK_DELAY_MAX_ITER        (10)\n#define SPQ_BLOCK_DELAY_US              (10)\n#define SPQ_BLOCK_SLEEP_MAX_ITER        (1000)\n#define SPQ_BLOCK_SLEEP_MS              (5)\n\n \nstatic void qed_spq_blocking_cb(struct qed_hwfn *p_hwfn,\n\t\t\t\tvoid *cookie,\n\t\t\t\tunion event_ring_data *data, u8 fw_return_code)\n{\n\tstruct qed_spq_comp_done *comp_done;\n\n\tcomp_done = (struct qed_spq_comp_done *)cookie;\n\n\tcomp_done->fw_return_code = fw_return_code;\n\n\t \n\tsmp_store_release(&comp_done->done, 0x1);\n}\n\nstatic int __qed_spq_block(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_spq_entry *p_ent,\n\t\t\t   u8 *p_fw_ret, bool sleep_between_iter)\n{\n\tstruct qed_spq_comp_done *comp_done;\n\tu32 iter_cnt;\n\n\tcomp_done = (struct qed_spq_comp_done *)p_ent->comp_cb.cookie;\n\titer_cnt = sleep_between_iter ? SPQ_BLOCK_SLEEP_MAX_ITER\n\t\t\t\t      : SPQ_BLOCK_DELAY_MAX_ITER;\n\n\twhile (iter_cnt--) {\n\t\t \n\t\tif (smp_load_acquire(&comp_done->done) == 1) {  \n\t\t\tif (p_fw_ret)\n\t\t\t\t*p_fw_ret = comp_done->fw_return_code;\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (sleep_between_iter)\n\t\t\tmsleep(SPQ_BLOCK_SLEEP_MS);\n\t\telse\n\t\t\tudelay(SPQ_BLOCK_DELAY_US);\n\t}\n\n\treturn -EBUSY;\n}\n\nstatic int qed_spq_block(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_spq_entry *p_ent,\n\t\t\t u8 *p_fw_ret, bool skip_quick_poll)\n{\n\tstruct qed_spq_comp_done *comp_done;\n\tstruct qed_ptt *p_ptt;\n\tint rc;\n\n\t \n\tif (!skip_quick_poll) {\n\t\trc = __qed_spq_block(p_hwfn, p_ent, p_fw_ret, false);\n\t\tif (!rc)\n\t\t\treturn 0;\n\t}\n\n\t \n\trc = __qed_spq_block(p_hwfn, p_ent, p_fw_ret, true);\n\tif (!rc)\n\t\treturn 0;\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt) {\n\t\tDP_NOTICE(p_hwfn, \"ptt, failed to acquire\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\tDP_INFO(p_hwfn, \"Ramrod is stuck, requesting MCP drain\\n\");\n\trc = qed_mcp_drain(p_hwfn, p_ptt);\n\tqed_ptt_release(p_hwfn, p_ptt);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn, \"MCP drain failed\\n\");\n\t\tgoto err;\n\t}\n\n\t \n\trc = __qed_spq_block(p_hwfn, p_ent, p_fw_ret, true);\n\tif (!rc)\n\t\treturn 0;\n\n\tcomp_done = (struct qed_spq_comp_done *)p_ent->comp_cb.cookie;\n\tif (comp_done->done == 1) {\n\t\tif (p_fw_ret)\n\t\t\t*p_fw_ret = comp_done->fw_return_code;\n\t\treturn 0;\n\t}\nerr:\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EBUSY;\n\tqed_hw_err_notify(p_hwfn, p_ptt, QED_HW_ERR_RAMROD_FAIL,\n\t\t\t  \"Ramrod is stuck [CID %08x %s:%02x %s:%02x echo %04x]\\n\",\n\t\t\t  le32_to_cpu(p_ent->elem.hdr.cid),\n\t\t\t  qed_get_ramrod_cmd_id_str(p_ent->elem.hdr.protocol_id,\n\t\t\t\t\t\t    p_ent->elem.hdr.cmd_id),\n\t\t\t  p_ent->elem.hdr.cmd_id,\n\t\t\t  qed_get_protocol_type_str(p_ent->elem.hdr.protocol_id),\n\t\t\t\t\t\t    p_ent->elem.hdr.protocol_id,\n\t\t\t  le16_to_cpu(p_ent->elem.hdr.echo));\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn -EBUSY;\n}\n\n \nstatic int qed_spq_fill_entry(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_spq_entry *p_ent)\n{\n\tp_ent->flags = 0;\n\n\tswitch (p_ent->comp_mode) {\n\tcase QED_SPQ_MODE_EBLOCK:\n\tcase QED_SPQ_MODE_BLOCK:\n\t\tp_ent->comp_cb.function = qed_spq_blocking_cb;\n\t\tbreak;\n\tcase QED_SPQ_MODE_CB:\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown SPQE completion mode %d\\n\",\n\t\t\t  p_ent->comp_mode);\n\t\treturn -EINVAL;\n\t}\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SPQ,\n\t\t   \"Ramrod hdr: [CID 0x%08x %s:0x%02x %s:0x%02x] Data ptr: [%08x:%08x] Cmpltion Mode: %s\\n\",\n\t\t   p_ent->elem.hdr.cid,\n\t\t   qed_get_ramrod_cmd_id_str(p_ent->elem.hdr.protocol_id,\n\t\t\t\t\t     p_ent->elem.hdr.cmd_id),\n\t\t   p_ent->elem.hdr.cmd_id,\n\t\t   qed_get_protocol_type_str(p_ent->elem.hdr.protocol_id),\n\t\t\t\t\t     p_ent->elem.hdr.protocol_id,\n\t\t   p_ent->elem.data_ptr.hi, p_ent->elem.data_ptr.lo,\n\t\t   D_TRINE(p_ent->comp_mode, QED_SPQ_MODE_EBLOCK,\n\t\t\t   QED_SPQ_MODE_BLOCK, \"MODE_EBLOCK\", \"MODE_BLOCK\",\n\t\t\t   \"MODE_CB\"));\n\n\treturn 0;\n}\n\n \nstatic void qed_spq_hw_initialize(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_spq *p_spq)\n{\n\tstruct core_conn_context *p_cxt;\n\tstruct qed_cxt_info cxt_info;\n\tu16 physical_q;\n\tint rc;\n\n\tcxt_info.iid = p_spq->cid;\n\n\trc = qed_cxt_get_cid_info(p_hwfn, &cxt_info);\n\n\tif (rc < 0) {\n\t\tDP_NOTICE(p_hwfn, \"Cannot find context info for cid=%d\\n\",\n\t\t\t  p_spq->cid);\n\t\treturn;\n\t}\n\n\tp_cxt = cxt_info.p_cxt;\n\n\tSET_FIELD(p_cxt->xstorm_ag_context.flags10,\n\t\t  XSTORM_CORE_CONN_AG_CTX_DQ_CF_EN, 1);\n\tSET_FIELD(p_cxt->xstorm_ag_context.flags1,\n\t\t  XSTORM_CORE_CONN_AG_CTX_DQ_CF_ACTIVE, 1);\n\tSET_FIELD(p_cxt->xstorm_ag_context.flags9,\n\t\t  XSTORM_CORE_CONN_AG_CTX_CONSOLID_PROD_CF_EN, 1);\n\n\t \n\tphysical_q = qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_LB);\n\tp_cxt->xstorm_ag_context.physical_q0 = cpu_to_le16(physical_q);\n\n\tp_cxt->xstorm_st_context.spq_base_addr.lo =\n\t\tDMA_LO_LE(p_spq->chain.p_phys_addr);\n\tp_cxt->xstorm_st_context.spq_base_addr.hi =\n\t\tDMA_HI_LE(p_spq->chain.p_phys_addr);\n}\n\nstatic int qed_spq_hw_post(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_spq *p_spq, struct qed_spq_entry *p_ent)\n{\n\tstruct qed_chain *p_chain = &p_hwfn->p_spq->chain;\n\tstruct core_db_data *p_db_data = &p_spq->db_data;\n\tu16 echo = qed_chain_get_prod_idx(p_chain);\n\tstruct slow_path_element\t*elem;\n\n\tp_ent->elem.hdr.echo\t= cpu_to_le16(echo);\n\telem = qed_chain_produce(p_chain);\n\tif (!elem) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to produce from SPQ chain\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t*elem = p_ent->elem;  \n\n\t \n\tp_db_data->spq_prod = cpu_to_le16(qed_chain_get_prod_idx(p_chain));\n\n\t \n\twmb();\n\n\tDOORBELL(p_hwfn, p_spq->db_addr_offset, *(u32 *)p_db_data);\n\n\t \n\twmb();\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\n\t\t   \"Doorbelled [0x%08x, CID 0x%08x] with Flags: %02x agg_params: %02x, prod: %04x\\n\",\n\t\t   p_spq->db_addr_offset,\n\t\t   p_spq->cid,\n\t\t   p_db_data->params,\n\t\t   p_db_data->agg_flags, qed_chain_get_prod_idx(p_chain));\n\n\treturn 0;\n}\n\n \nstatic int\nqed_async_event_completion(struct qed_hwfn *p_hwfn,\n\t\t\t   struct event_ring_entry *p_eqe)\n{\n\tqed_spq_async_comp_cb cb;\n\n\tif (!p_hwfn->p_spq)\n\t\treturn -EINVAL;\n\n\tif (p_eqe->protocol_id >= MAX_PROTOCOL_TYPE) {\n\t\tDP_ERR(p_hwfn, \"Wrong protocol: %s:%d\\n\",\n\t\t       qed_get_protocol_type_str(p_eqe->protocol_id),\n\t\t       p_eqe->protocol_id);\n\n\t\treturn -EINVAL;\n\t}\n\n\tcb = p_hwfn->p_spq->async_comp_cb[p_eqe->protocol_id];\n\tif (cb) {\n\t\treturn cb(p_hwfn, p_eqe->opcode, p_eqe->echo,\n\t\t\t  &p_eqe->data, p_eqe->fw_return_code);\n\t} else {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unknown Async completion for %s:%d\\n\",\n\t\t\t  qed_get_protocol_type_str(p_eqe->protocol_id),\n\t\t\t  p_eqe->protocol_id);\n\n\t\treturn -EINVAL;\n\t}\n}\n\nint\nqed_spq_register_async_cb(struct qed_hwfn *p_hwfn,\n\t\t\t  enum protocol_type protocol_id,\n\t\t\t  qed_spq_async_comp_cb cb)\n{\n\tif (!p_hwfn->p_spq || (protocol_id >= MAX_PROTOCOL_TYPE))\n\t\treturn -EINVAL;\n\n\tp_hwfn->p_spq->async_comp_cb[protocol_id] = cb;\n\treturn 0;\n}\n\nvoid\nqed_spq_unregister_async_cb(struct qed_hwfn *p_hwfn,\n\t\t\t    enum protocol_type protocol_id)\n{\n\tif (!p_hwfn->p_spq || (protocol_id >= MAX_PROTOCOL_TYPE))\n\t\treturn;\n\n\tp_hwfn->p_spq->async_comp_cb[protocol_id] = NULL;\n}\n\n \nvoid qed_eq_prod_update(struct qed_hwfn *p_hwfn, u16 prod)\n{\n\tu32 addr = GET_GTT_REG_ADDR(GTT_BAR0_MAP_REG_USDM_RAM,\n\t\t\t\t    USTORM_EQE_CONS, p_hwfn->rel_pf_id);\n\n\tREG_WR16(p_hwfn, addr, prod);\n}\n\nint qed_eq_completion(struct qed_hwfn *p_hwfn, void *cookie)\n{\n\tstruct qed_eq *p_eq = cookie;\n\tstruct qed_chain *p_chain = &p_eq->chain;\n\tint rc = 0;\n\n\t \n\tu16 fw_cons_idx = le16_to_cpu(*p_eq->p_fw_cons);\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ, \"fw_cons_idx %x\\n\", fw_cons_idx);\n\n\t \n\tif ((fw_cons_idx & qed_chain_get_usable_per_page(p_chain)) ==\n\t    qed_chain_get_usable_per_page(p_chain))\n\t\tfw_cons_idx += qed_chain_get_unusable_per_page(p_chain);\n\n\t \n\twhile (fw_cons_idx != qed_chain_get_cons_idx(p_chain)) {\n\t\tstruct event_ring_entry *p_eqe = qed_chain_consume(p_chain);\n\n\t\tif (!p_eqe) {\n\t\t\trc = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\n\t\t\t   \"op %x prot %x res0 %x echo %x fwret %x flags %x\\n\",\n\t\t\t   p_eqe->opcode,\n\t\t\t   p_eqe->protocol_id,\n\t\t\t   p_eqe->reserved0,\n\t\t\t   le16_to_cpu(p_eqe->echo),\n\t\t\t   p_eqe->fw_return_code,\n\t\t\t   p_eqe->flags);\n\n\t\tif (GET_FIELD(p_eqe->flags, EVENT_RING_ENTRY_ASYNC)) {\n\t\t\tif (qed_async_event_completion(p_hwfn, p_eqe))\n\t\t\t\trc = -EINVAL;\n\t\t} else if (qed_spq_completion(p_hwfn,\n\t\t\t\t\t      p_eqe->echo,\n\t\t\t\t\t      p_eqe->fw_return_code,\n\t\t\t\t\t      &p_eqe->data)) {\n\t\t\trc = -EINVAL;\n\t\t}\n\n\t\tqed_chain_recycle_consumed(p_chain);\n\t}\n\n\tqed_eq_prod_update(p_hwfn, qed_chain_get_prod_idx(p_chain));\n\n\t \n\tspin_lock_bh(&p_hwfn->p_spq->lock);\n\trc = qed_spq_pend_post(p_hwfn);\n\tspin_unlock_bh(&p_hwfn->p_spq->lock);\n\n\treturn rc;\n}\n\nint qed_eq_alloc(struct qed_hwfn *p_hwfn, u16 num_elem)\n{\n\tstruct qed_chain_init_params params = {\n\t\t.mode\t\t= QED_CHAIN_MODE_PBL,\n\t\t.intended_use\t= QED_CHAIN_USE_TO_PRODUCE,\n\t\t.cnt_type\t= QED_CHAIN_CNT_TYPE_U16,\n\t\t.num_elems\t= num_elem,\n\t\t.elem_size\t= sizeof(union event_ring_element),\n\t};\n\tstruct qed_eq *p_eq;\n\tint ret;\n\n\t \n\tp_eq = kzalloc(sizeof(*p_eq), GFP_KERNEL);\n\tif (!p_eq)\n\t\treturn -ENOMEM;\n\n\tret = qed_chain_alloc(p_hwfn->cdev, &p_eq->chain, &params);\n\tif (ret) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to allocate EQ chain\\n\");\n\t\tgoto eq_allocate_fail;\n\t}\n\n\t \n\tqed_int_register_cb(p_hwfn, qed_eq_completion,\n\t\t\t    p_eq, &p_eq->eq_sb_index, &p_eq->p_fw_cons);\n\n\tp_hwfn->p_eq = p_eq;\n\treturn 0;\n\neq_allocate_fail:\n\tkfree(p_eq);\n\n\treturn ret;\n}\n\nvoid qed_eq_setup(struct qed_hwfn *p_hwfn)\n{\n\tqed_chain_reset(&p_hwfn->p_eq->chain);\n}\n\nvoid qed_eq_free(struct qed_hwfn *p_hwfn)\n{\n\tif (!p_hwfn->p_eq)\n\t\treturn;\n\n\tqed_chain_free(p_hwfn->cdev, &p_hwfn->p_eq->chain);\n\n\tkfree(p_hwfn->p_eq);\n\tp_hwfn->p_eq = NULL;\n}\n\n \nstatic int qed_cqe_completion(struct qed_hwfn *p_hwfn,\n\t\t\t      struct eth_slow_path_rx_cqe *cqe,\n\t\t\t      enum protocol_type protocol)\n{\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn 0;\n\n\t \n\treturn qed_spq_completion(p_hwfn, cqe->echo, 0, NULL);\n}\n\nint qed_eth_cqe_completion(struct qed_hwfn *p_hwfn,\n\t\t\t   struct eth_slow_path_rx_cqe *cqe)\n{\n\tint rc;\n\n\trc = qed_cqe_completion(p_hwfn, cqe, PROTOCOLID_ETH);\n\tif (rc)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to handle RXQ CQE [cmd 0x%02x]\\n\",\n\t\t\t  cqe->ramrod_cmd_id);\n\n\treturn rc;\n}\n\n \nvoid qed_spq_setup(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq *p_spq = p_hwfn->p_spq;\n\tstruct qed_spq_entry *p_virt = NULL;\n\tstruct core_db_data *p_db_data;\n\tvoid __iomem *db_addr;\n\tdma_addr_t p_phys = 0;\n\tu32 i, capacity;\n\tint rc;\n\n\tINIT_LIST_HEAD(&p_spq->pending);\n\tINIT_LIST_HEAD(&p_spq->completion_pending);\n\tINIT_LIST_HEAD(&p_spq->free_pool);\n\tINIT_LIST_HEAD(&p_spq->unlimited_pending);\n\tspin_lock_init(&p_spq->lock);\n\n\t \n\tp_phys\t= p_spq->p_phys + offsetof(struct qed_spq_entry, ramrod);\n\tp_virt\t= p_spq->p_virt;\n\n\tcapacity = qed_chain_get_capacity(&p_spq->chain);\n\tfor (i = 0; i < capacity; i++) {\n\t\tDMA_REGPAIR_LE(p_virt->elem.data_ptr, p_phys);\n\n\t\tlist_add_tail(&p_virt->list, &p_spq->free_pool);\n\n\t\tp_virt++;\n\t\tp_phys += sizeof(struct qed_spq_entry);\n\t}\n\n\t \n\tp_spq->normal_count\t\t= 0;\n\tp_spq->comp_count\t\t= 0;\n\tp_spq->comp_sent_count\t\t= 0;\n\tp_spq->unlimited_pending_count\t= 0;\n\n\tbitmap_zero(p_spq->p_comp_bitmap, SPQ_RING_SIZE);\n\tp_spq->comp_bitmap_idx = 0;\n\n\t \n\tqed_cxt_acquire_cid(p_hwfn, PROTOCOLID_CORE, &p_spq->cid);\n\tqed_spq_hw_initialize(p_hwfn, p_spq);\n\n\t \n\tqed_chain_reset(&p_spq->chain);\n\n\t \n\tp_spq->db_addr_offset = qed_db_addr(p_spq->cid, DQ_DEMS_LEGACY);\n\tp_db_data = &p_spq->db_data;\n\tmemset(p_db_data, 0, sizeof(*p_db_data));\n\tSET_FIELD(p_db_data->params, CORE_DB_DATA_DEST, DB_DEST_XCM);\n\tSET_FIELD(p_db_data->params, CORE_DB_DATA_AGG_CMD, DB_AGG_CMD_MAX);\n\tSET_FIELD(p_db_data->params, CORE_DB_DATA_AGG_VAL_SEL,\n\t\t  DQ_XCM_CORE_SPQ_PROD_CMD);\n\tp_db_data->agg_flags = DQ_XCM_CORE_DQ_CF_CMD;\n\n\t \n\tdb_addr = (void __iomem *)((u8 __iomem *)p_hwfn->doorbells +\n\t\t\t\t   p_spq->db_addr_offset);\n\trc = qed_db_recovery_add(p_hwfn->cdev, db_addr, &p_spq->db_data,\n\t\t\t\t DB_REC_WIDTH_32B, DB_REC_KERNEL);\n\tif (rc)\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Failed to register the SPQ doorbell with the doorbell recovery mechanism\\n\");\n}\n\nint qed_spq_alloc(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_chain_init_params params = {\n\t\t.mode\t\t= QED_CHAIN_MODE_SINGLE,\n\t\t.intended_use\t= QED_CHAIN_USE_TO_PRODUCE,\n\t\t.cnt_type\t= QED_CHAIN_CNT_TYPE_U16,\n\t\t.elem_size\t= sizeof(struct slow_path_element),\n\t};\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tstruct qed_spq_entry *p_virt = NULL;\n\tstruct qed_spq *p_spq = NULL;\n\tdma_addr_t p_phys = 0;\n\tu32 capacity;\n\tint ret;\n\n\t \n\tp_spq = kzalloc(sizeof(*p_spq), GFP_KERNEL);\n\tif (!p_spq)\n\t\treturn -ENOMEM;\n\n\t \n\tret = qed_chain_alloc(cdev, &p_spq->chain, &params);\n\tif (ret) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to allocate SPQ chain\\n\");\n\t\tgoto spq_chain_alloc_fail;\n\t}\n\n\t \n\tcapacity = qed_chain_get_capacity(&p_spq->chain);\n\tret = -ENOMEM;\n\n\tp_virt = dma_alloc_coherent(&cdev->pdev->dev,\n\t\t\t\t    capacity * sizeof(struct qed_spq_entry),\n\t\t\t\t    &p_phys, GFP_KERNEL);\n\tif (!p_virt)\n\t\tgoto spq_alloc_fail;\n\n\tp_spq->p_virt = p_virt;\n\tp_spq->p_phys = p_phys;\n\tp_hwfn->p_spq = p_spq;\n\n\treturn 0;\n\nspq_alloc_fail:\n\tqed_chain_free(cdev, &p_spq->chain);\nspq_chain_alloc_fail:\n\tkfree(p_spq);\n\n\treturn ret;\n}\n\nvoid qed_spq_free(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq *p_spq = p_hwfn->p_spq;\n\tvoid __iomem *db_addr;\n\tu32 capacity;\n\n\tif (!p_spq)\n\t\treturn;\n\n\t \n\tdb_addr = (void __iomem *)((u8 __iomem *)p_hwfn->doorbells +\n\t\t\t\t   p_spq->db_addr_offset);\n\tqed_db_recovery_del(p_hwfn->cdev, db_addr, &p_spq->db_data);\n\n\tif (p_spq->p_virt) {\n\t\tcapacity = qed_chain_get_capacity(&p_spq->chain);\n\t\tdma_free_coherent(&p_hwfn->cdev->pdev->dev,\n\t\t\t\t  capacity *\n\t\t\t\t  sizeof(struct qed_spq_entry),\n\t\t\t\t  p_spq->p_virt, p_spq->p_phys);\n\t}\n\n\tqed_chain_free(p_hwfn->cdev, &p_spq->chain);\n\tkfree(p_spq);\n\tp_hwfn->p_spq = NULL;\n}\n\nint qed_spq_get_entry(struct qed_hwfn *p_hwfn, struct qed_spq_entry **pp_ent)\n{\n\tstruct qed_spq *p_spq = p_hwfn->p_spq;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tint rc = 0;\n\n\tspin_lock_bh(&p_spq->lock);\n\n\tif (list_empty(&p_spq->free_pool)) {\n\t\tp_ent = kzalloc(sizeof(*p_ent), GFP_ATOMIC);\n\t\tif (!p_ent) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to allocate an SPQ entry for a pending ramrod\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tp_ent->queue = &p_spq->unlimited_pending;\n\t} else {\n\t\tp_ent = list_first_entry(&p_spq->free_pool,\n\t\t\t\t\t struct qed_spq_entry, list);\n\t\tlist_del(&p_ent->list);\n\t\tp_ent->queue = &p_spq->pending;\n\t}\n\n\t*pp_ent = p_ent;\n\nout_unlock:\n\tspin_unlock_bh(&p_spq->lock);\n\treturn rc;\n}\n\n \nstatic void __qed_spq_return_entry(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_spq_entry *p_ent)\n{\n\tlist_add_tail(&p_ent->list, &p_hwfn->p_spq->free_pool);\n}\n\nvoid qed_spq_return_entry(struct qed_hwfn *p_hwfn, struct qed_spq_entry *p_ent)\n{\n\tspin_lock_bh(&p_hwfn->p_spq->lock);\n\t__qed_spq_return_entry(p_hwfn, p_ent);\n\tspin_unlock_bh(&p_hwfn->p_spq->lock);\n}\n\n \nstatic int qed_spq_add_entry(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_spq_entry *p_ent,\n\t\t\t     enum spq_priority priority)\n{\n\tstruct qed_spq *p_spq = p_hwfn->p_spq;\n\n\tif (p_ent->queue == &p_spq->unlimited_pending) {\n\t\tif (list_empty(&p_spq->free_pool)) {\n\t\t\tlist_add_tail(&p_ent->list, &p_spq->unlimited_pending);\n\t\t\tp_spq->unlimited_pending_count++;\n\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tstruct qed_spq_entry *p_en2;\n\n\t\t\tp_en2 = list_first_entry(&p_spq->free_pool,\n\t\t\t\t\t\t struct qed_spq_entry, list);\n\t\t\tlist_del(&p_en2->list);\n\n\t\t\t \n\t\t\tp_ent->elem.data_ptr = p_en2->elem.data_ptr;\n\n\t\t\t*p_en2 = *p_ent;\n\n\t\t\t \n\t\t\tif (p_ent->comp_mode != QED_SPQ_MODE_EBLOCK)\n\t\t\t\tkfree(p_ent);\n\t\t\telse\n\t\t\t\tp_ent->post_ent = p_en2;\n\n\t\t\tp_ent = p_en2;\n\t\t}\n\t}\n\n\t \n\tswitch (priority) {\n\tcase QED_SPQ_PRIORITY_NORMAL:\n\t\tlist_add_tail(&p_ent->list, &p_spq->pending);\n\t\tp_spq->normal_count++;\n\t\tbreak;\n\tcase QED_SPQ_PRIORITY_HIGH:\n\t\tlist_add(&p_ent->list, &p_spq->pending);\n\t\tp_spq->high_count++;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nu32 qed_spq_get_cid(struct qed_hwfn *p_hwfn)\n{\n\tif (!p_hwfn->p_spq)\n\t\treturn 0xffffffff;       \n\treturn p_hwfn->p_spq->cid;\n}\n\n \nstatic int qed_spq_post_list(struct qed_hwfn *p_hwfn,\n\t\t\t     struct list_head *head, u32 keep_reserve)\n{\n\tstruct qed_spq *p_spq = p_hwfn->p_spq;\n\tint rc;\n\n\twhile (qed_chain_get_elem_left(&p_spq->chain) > keep_reserve &&\n\t       !list_empty(head)) {\n\t\tstruct qed_spq_entry *p_ent =\n\t\t\tlist_first_entry(head, struct qed_spq_entry, list);\n\t\tlist_move_tail(&p_ent->list, &p_spq->completion_pending);\n\t\tp_spq->comp_sent_count++;\n\n\t\trc = qed_spq_hw_post(p_hwfn, p_spq, p_ent);\n\t\tif (rc) {\n\t\t\tlist_del(&p_ent->list);\n\t\t\t__qed_spq_return_entry(p_hwfn, p_ent);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint qed_spq_pend_post(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_spq *p_spq = p_hwfn->p_spq;\n\tstruct qed_spq_entry *p_ent = NULL;\n\n\twhile (!list_empty(&p_spq->free_pool)) {\n\t\tif (list_empty(&p_spq->unlimited_pending))\n\t\t\tbreak;\n\n\t\tp_ent = list_first_entry(&p_spq->unlimited_pending,\n\t\t\t\t\t struct qed_spq_entry, list);\n\t\tif (!p_ent)\n\t\t\treturn -EINVAL;\n\n\t\tlist_del(&p_ent->list);\n\n\t\tqed_spq_add_entry(p_hwfn, p_ent, p_ent->priority);\n\t}\n\n\treturn qed_spq_post_list(p_hwfn, &p_spq->pending,\n\t\t\t\t SPQ_HIGH_PRI_RESERVE_DEFAULT);\n}\n\nstatic void qed_spq_recov_set_ret_code(struct qed_spq_entry *p_ent,\n\t\t\t\t       u8 *fw_return_code)\n{\n\tif (!fw_return_code)\n\t\treturn;\n\n\tif (p_ent->elem.hdr.protocol_id == PROTOCOLID_ROCE ||\n\t    p_ent->elem.hdr.protocol_id == PROTOCOLID_IWARP)\n\t\t*fw_return_code = RDMA_RETURN_OK;\n}\n\n \nstatic void qed_spq_comp_bmap_update(struct qed_hwfn *p_hwfn, __le16 echo)\n{\n\tu16 pos = le16_to_cpu(echo) % SPQ_RING_SIZE;\n\tstruct qed_spq *p_spq = p_hwfn->p_spq;\n\n\t__set_bit(pos, p_spq->p_comp_bitmap);\n\twhile (test_bit(p_spq->comp_bitmap_idx,\n\t\t\tp_spq->p_comp_bitmap)) {\n\t\t__clear_bit(p_spq->comp_bitmap_idx,\n\t\t\t    p_spq->p_comp_bitmap);\n\t\tp_spq->comp_bitmap_idx++;\n\t\tqed_chain_return_produced(&p_spq->chain);\n\t}\n}\n\nint qed_spq_post(struct qed_hwfn *p_hwfn,\n\t\t struct qed_spq_entry *p_ent, u8 *fw_return_code)\n{\n\tint rc = 0;\n\tstruct qed_spq *p_spq = p_hwfn ? p_hwfn->p_spq : NULL;\n\tbool b_ret_ent = true;\n\tbool eblock;\n\n\tif (!p_hwfn)\n\t\treturn -EINVAL;\n\n\tif (!p_ent) {\n\t\tDP_NOTICE(p_hwfn, \"Got a NULL pointer\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (p_hwfn->cdev->recov_in_prog) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_SPQ,\n\t\t\t   \"Recovery is in progress. Skip spq post [%s:%02x %s:%02x]\\n\",\n\t\t\t   qed_get_ramrod_cmd_id_str(p_ent->elem.hdr.protocol_id,\n\t\t\t\t\t\t     p_ent->elem.hdr.cmd_id),\n\t\t\t   p_ent->elem.hdr.cmd_id,\n\t\t\t   qed_get_protocol_type_str(p_ent->elem.hdr.protocol_id),\n\t\t\t   p_ent->elem.hdr.protocol_id);\n\n\t\t \n\t\tqed_spq_recov_set_ret_code(p_ent, fw_return_code);\n\t\treturn 0;\n\t}\n\n\t \n\trc = qed_spq_fill_entry(p_hwfn, p_ent);\n\n\tspin_lock_bh(&p_spq->lock);\n\n\t \n\tif (rc)\n\t\tgoto spq_post_fail;\n\n\t \n\teblock = (p_ent->comp_mode == QED_SPQ_MODE_EBLOCK);\n\n\t \n\trc = qed_spq_add_entry(p_hwfn, p_ent, p_ent->priority);\n\tif (rc)\n\t\tgoto spq_post_fail;\n\n\trc = qed_spq_pend_post(p_hwfn);\n\tif (rc) {\n\t\t \n\t\tb_ret_ent = false;\n\t\tgoto spq_post_fail;\n\t}\n\n\tspin_unlock_bh(&p_spq->lock);\n\n\tif (eblock) {\n\t\t \n\t\trc = qed_spq_block(p_hwfn, p_ent, fw_return_code,\n\t\t\t\t   p_ent->queue == &p_spq->unlimited_pending);\n\n\t\tif (p_ent->queue == &p_spq->unlimited_pending) {\n\t\t\tstruct qed_spq_entry *p_post_ent = p_ent->post_ent;\n\n\t\t\tkfree(p_ent);\n\n\t\t\t \n\t\t\tp_ent = p_post_ent;\n\t\t}\n\n\t\tif (rc)\n\t\t\tgoto spq_post_fail2;\n\n\t\t \n\t\tqed_spq_return_entry(p_hwfn, p_ent);\n\t}\n\treturn rc;\n\nspq_post_fail2:\n\tspin_lock_bh(&p_spq->lock);\n\tlist_del(&p_ent->list);\n\tqed_spq_comp_bmap_update(p_hwfn, p_ent->elem.hdr.echo);\n\nspq_post_fail:\n\t \n\tif (b_ret_ent)\n\t\t__qed_spq_return_entry(p_hwfn, p_ent);\n\tspin_unlock_bh(&p_spq->lock);\n\n\treturn rc;\n}\n\nint qed_spq_completion(struct qed_hwfn *p_hwfn,\n\t\t       __le16 echo,\n\t\t       u8 fw_return_code,\n\t\t       union event_ring_data *p_data)\n{\n\tstruct qed_spq\t\t*p_spq;\n\tstruct qed_spq_entry\t*p_ent = NULL;\n\tstruct qed_spq_entry\t*tmp;\n\tstruct qed_spq_entry\t*found = NULL;\n\n\tif (!p_hwfn)\n\t\treturn -EINVAL;\n\n\tp_spq = p_hwfn->p_spq;\n\tif (!p_spq)\n\t\treturn -EINVAL;\n\n\tspin_lock_bh(&p_spq->lock);\n\tlist_for_each_entry_safe(p_ent, tmp, &p_spq->completion_pending, list) {\n\t\tif (p_ent->elem.hdr.echo == echo) {\n\t\t\tlist_del(&p_ent->list);\n\t\t\tqed_spq_comp_bmap_update(p_hwfn, echo);\n\t\t\tp_spq->comp_count++;\n\t\t\tfound = p_ent;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\n\t\t\t   \"Got completion for echo %04x - doesn't match echo %04x in completion pending list\\n\",\n\t\t\t   le16_to_cpu(echo),\n\t\t\t   le16_to_cpu(p_ent->elem.hdr.echo));\n\t}\n\n\t \n\tspin_unlock_bh(&p_spq->lock);\n\n\tif (!found) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to find an entry this EQE [echo %04x] completes\\n\",\n\t\t\t  le16_to_cpu(echo));\n\t\treturn -EEXIST;\n\t}\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SPQ,\n\t\t   \"Complete EQE [echo %04x]: func %p cookie %p)\\n\",\n\t\t   le16_to_cpu(echo),\n\t\t   p_ent->comp_cb.function, p_ent->comp_cb.cookie);\n\tif (found->comp_cb.function)\n\t\tfound->comp_cb.function(p_hwfn, found->comp_cb.cookie, p_data,\n\t\t\t\t\tfw_return_code);\n\telse\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_SPQ,\n\t\t\t   \"Got a completion without a callback function\\n\");\n\n\tif (found->comp_mode != QED_SPQ_MODE_EBLOCK)\n\t\t \n\t\tqed_spq_return_entry(p_hwfn, found);\n\n\treturn 0;\n}\n\n#define QED_SPQ_CONSQ_ELEM_SIZE\t\t0x80\n\nint qed_consq_alloc(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_chain_init_params params = {\n\t\t.mode\t\t= QED_CHAIN_MODE_PBL,\n\t\t.intended_use\t= QED_CHAIN_USE_TO_PRODUCE,\n\t\t.cnt_type\t= QED_CHAIN_CNT_TYPE_U16,\n\t\t.num_elems\t= QED_CHAIN_PAGE_SIZE / QED_SPQ_CONSQ_ELEM_SIZE,\n\t\t.elem_size\t= QED_SPQ_CONSQ_ELEM_SIZE,\n\t};\n\tstruct qed_consq *p_consq;\n\tint ret;\n\n\t \n\tp_consq = kzalloc(sizeof(*p_consq), GFP_KERNEL);\n\tif (!p_consq)\n\t\treturn -ENOMEM;\n\n\t \n\tret = qed_chain_alloc(p_hwfn->cdev, &p_consq->chain, &params);\n\tif (ret) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to allocate ConsQ chain\");\n\t\tgoto consq_alloc_fail;\n\t}\n\n\tp_hwfn->p_consq = p_consq;\n\n\treturn 0;\n\nconsq_alloc_fail:\n\tkfree(p_consq);\n\n\treturn ret;\n}\n\nvoid qed_consq_setup(struct qed_hwfn *p_hwfn)\n{\n\tqed_chain_reset(&p_hwfn->p_consq->chain);\n}\n\nvoid qed_consq_free(struct qed_hwfn *p_hwfn)\n{\n\tif (!p_hwfn->p_consq)\n\t\treturn;\n\n\tqed_chain_free(p_hwfn->cdev, &p_hwfn->p_consq->chain);\n\n\tkfree(p_hwfn->p_consq);\n\tp_hwfn->p_consq = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}