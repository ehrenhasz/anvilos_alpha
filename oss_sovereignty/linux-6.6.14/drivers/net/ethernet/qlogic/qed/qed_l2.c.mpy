{
  "module_name": "qed_l2.c",
  "hash_id": "3349f8ff4210d6daf3e42e6e8b4870278fa2fbb8d3f22f70f187a1737843b207",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qed/qed_l2.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <asm/byteorder.h>\n#include <asm/param.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/etherdevice.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/string.h>\n#include <linux/workqueue.h>\n#include <linux/bitops.h>\n#include <linux/bug.h>\n#include <linux/vmalloc.h>\n#include \"qed.h\"\n#include <linux/qed/qed_chain.h>\n#include \"qed_cxt.h\"\n#include \"qed_dcbx.h\"\n#include \"qed_dev_api.h\"\n#include <linux/qed/qed_eth_if.h>\n#include \"qed_hsi.h\"\n#include \"qed_iro_hsi.h\"\n#include \"qed_hw.h\"\n#include \"qed_int.h\"\n#include \"qed_l2.h\"\n#include \"qed_mcp.h\"\n#include \"qed_ptp.h\"\n#include \"qed_reg_addr.h\"\n#include \"qed_sp.h\"\n#include \"qed_sriov.h\"\n\n#define QED_MAX_SGES_NUM 16\n#define CRC32_POLY 0x1edc6f41\n\nstruct qed_l2_info {\n\tu32 queues;\n\tunsigned long **pp_qid_usage;\n\n\t \n\tstruct mutex lock;\n};\n\nint qed_l2_alloc(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_l2_info *p_l2_info;\n\tunsigned long **pp_qids;\n\tu32 i;\n\n\tif (!QED_IS_L2_PERSONALITY(p_hwfn))\n\t\treturn 0;\n\n\tp_l2_info = kzalloc(sizeof(*p_l2_info), GFP_KERNEL);\n\tif (!p_l2_info)\n\t\treturn -ENOMEM;\n\tp_hwfn->p_l2_info = p_l2_info;\n\n\tif (IS_PF(p_hwfn->cdev)) {\n\t\tp_l2_info->queues = RESC_NUM(p_hwfn, QED_L2_QUEUE);\n\t} else {\n\t\tu8 rx = 0, tx = 0;\n\n\t\tqed_vf_get_num_rxqs(p_hwfn, &rx);\n\t\tqed_vf_get_num_txqs(p_hwfn, &tx);\n\n\t\tp_l2_info->queues = max_t(u8, rx, tx);\n\t}\n\n\tpp_qids = kcalloc(p_l2_info->queues, sizeof(unsigned long *),\n\t\t\t  GFP_KERNEL);\n\tif (!pp_qids)\n\t\treturn -ENOMEM;\n\tp_l2_info->pp_qid_usage = pp_qids;\n\n\tfor (i = 0; i < p_l2_info->queues; i++) {\n\t\tpp_qids[i] = kzalloc(MAX_QUEUES_PER_QZONE / 8, GFP_KERNEL);\n\t\tif (!pp_qids[i])\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nvoid qed_l2_setup(struct qed_hwfn *p_hwfn)\n{\n\tif (!QED_IS_L2_PERSONALITY(p_hwfn))\n\t\treturn;\n\n\tmutex_init(&p_hwfn->p_l2_info->lock);\n}\n\nvoid qed_l2_free(struct qed_hwfn *p_hwfn)\n{\n\tu32 i;\n\n\tif (!QED_IS_L2_PERSONALITY(p_hwfn))\n\t\treturn;\n\n\tif (!p_hwfn->p_l2_info)\n\t\treturn;\n\n\tif (!p_hwfn->p_l2_info->pp_qid_usage)\n\t\tgoto out_l2_info;\n\n\t \n\tfor (i = 0; i < p_hwfn->p_l2_info->queues; i++) {\n\t\tif (!p_hwfn->p_l2_info->pp_qid_usage[i])\n\t\t\tbreak;\n\t\tkfree(p_hwfn->p_l2_info->pp_qid_usage[i]);\n\t}\n\n\tkfree(p_hwfn->p_l2_info->pp_qid_usage);\n\nout_l2_info:\n\tkfree(p_hwfn->p_l2_info);\n\tp_hwfn->p_l2_info = NULL;\n}\n\nstatic bool qed_eth_queue_qid_usage_add(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_queue_cid *p_cid)\n{\n\tstruct qed_l2_info *p_l2_info = p_hwfn->p_l2_info;\n\tu16 queue_id = p_cid->rel.queue_id;\n\tbool b_rc = true;\n\tu8 first;\n\n\tmutex_lock(&p_l2_info->lock);\n\n\tif (queue_id >= p_l2_info->queues) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Requested to increase usage for qzone %04x out of %08x\\n\",\n\t\t\t  queue_id, p_l2_info->queues);\n\t\tb_rc = false;\n\t\tgoto out;\n\t}\n\n\tfirst = (u8)find_first_zero_bit(p_l2_info->pp_qid_usage[queue_id],\n\t\t\t\t\tMAX_QUEUES_PER_QZONE);\n\tif (first >= MAX_QUEUES_PER_QZONE) {\n\t\tb_rc = false;\n\t\tgoto out;\n\t}\n\n\t__set_bit(first, p_l2_info->pp_qid_usage[queue_id]);\n\tp_cid->qid_usage_idx = first;\n\nout:\n\tmutex_unlock(&p_l2_info->lock);\n\treturn b_rc;\n}\n\nstatic void qed_eth_queue_qid_usage_del(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_queue_cid *p_cid)\n{\n\tmutex_lock(&p_hwfn->p_l2_info->lock);\n\n\tclear_bit(p_cid->qid_usage_idx,\n\t\t  p_hwfn->p_l2_info->pp_qid_usage[p_cid->rel.queue_id]);\n\n\tmutex_unlock(&p_hwfn->p_l2_info->lock);\n}\n\nvoid qed_eth_queue_cid_release(struct qed_hwfn *p_hwfn,\n\t\t\t       struct qed_queue_cid *p_cid)\n{\n\tbool b_legacy_vf = !!(p_cid->vf_legacy & QED_QCID_LEGACY_VF_CID);\n\n\tif (IS_PF(p_hwfn->cdev) && !b_legacy_vf)\n\t\t_qed_cxt_release_cid(p_hwfn, p_cid->cid, p_cid->vfid);\n\n\t \n\tif (p_cid->vfid == QED_QUEUE_CID_SELF)\n\t\tqed_eth_queue_qid_usage_del(p_hwfn, p_cid);\n\n\tvfree(p_cid);\n}\n\n \nstatic struct qed_queue_cid *\n_qed_eth_queue_to_cid(struct qed_hwfn *p_hwfn,\n\t\t      u16 opaque_fid,\n\t\t      u32 cid,\n\t\t      struct qed_queue_start_common_params *p_params,\n\t\t      bool b_is_rx,\n\t\t      struct qed_queue_cid_vf_params *p_vf_params)\n{\n\tstruct qed_queue_cid *p_cid;\n\tint rc;\n\n\tp_cid = vzalloc(sizeof(*p_cid));\n\tif (!p_cid)\n\t\treturn NULL;\n\n\tp_cid->opaque_fid = opaque_fid;\n\tp_cid->cid = cid;\n\tp_cid->p_owner = p_hwfn;\n\n\t \n\tp_cid->rel.vport_id = p_params->vport_id;\n\tp_cid->rel.queue_id = p_params->queue_id;\n\tp_cid->rel.stats_id = p_params->stats_id;\n\tp_cid->sb_igu_id = p_params->p_sb->igu_sb_id;\n\tp_cid->b_is_rx = b_is_rx;\n\tp_cid->sb_idx = p_params->sb_idx;\n\n\t \n\tif (p_vf_params) {\n\t\tp_cid->vfid = p_vf_params->vfid;\n\t\tp_cid->vf_qid = p_vf_params->vf_qid;\n\t\tp_cid->vf_legacy = p_vf_params->vf_legacy;\n\t} else {\n\t\tp_cid->vfid = QED_QUEUE_CID_SELF;\n\t}\n\n\t \n\tif (IS_VF(p_hwfn->cdev)) {\n\t\tp_cid->abs = p_cid->rel;\n\t\tgoto out;\n\t}\n\n\t \n\trc = qed_fw_vport(p_hwfn, p_cid->rel.vport_id, &p_cid->abs.vport_id);\n\tif (rc)\n\t\tgoto fail;\n\n\trc = qed_fw_l2_queue(p_hwfn, p_cid->rel.queue_id, &p_cid->abs.queue_id);\n\tif (rc)\n\t\tgoto fail;\n\n\t \n\tif (p_cid->vfid == QED_QUEUE_CID_SELF) {\n\t\trc = qed_fw_vport(p_hwfn, p_cid->rel.stats_id,\n\t\t\t\t  &p_cid->abs.stats_id);\n\t\tif (rc)\n\t\t\tgoto fail;\n\t} else {\n\t\tp_cid->abs.stats_id = p_cid->rel.stats_id;\n\t}\n\nout:\n\t \n\tif (!p_vf_params) {\n\t\tif (!qed_eth_queue_qid_usage_add(p_hwfn, p_cid))\n\t\t\tgoto fail;\n\t} else {\n\t\tp_cid->qid_usage_idx = p_vf_params->qid_usage_idx;\n\t}\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SP,\n\t\t   \"opaque_fid: %04x CID %08x vport %02x [%02x] qzone %04x.%02x [%04x] stats %02x [%02x] SB %04x PI %02x\\n\",\n\t\t   p_cid->opaque_fid,\n\t\t   p_cid->cid,\n\t\t   p_cid->rel.vport_id,\n\t\t   p_cid->abs.vport_id,\n\t\t   p_cid->rel.queue_id,\n\t\t   p_cid->qid_usage_idx,\n\t\t   p_cid->abs.queue_id,\n\t\t   p_cid->rel.stats_id,\n\t\t   p_cid->abs.stats_id, p_cid->sb_igu_id, p_cid->sb_idx);\n\n\treturn p_cid;\n\nfail:\n\tvfree(p_cid);\n\treturn NULL;\n}\n\nstruct qed_queue_cid *\nqed_eth_queue_to_cid(struct qed_hwfn *p_hwfn,\n\t\t     u16 opaque_fid,\n\t\t     struct qed_queue_start_common_params *p_params,\n\t\t     bool b_is_rx,\n\t\t     struct qed_queue_cid_vf_params *p_vf_params)\n{\n\tstruct qed_queue_cid *p_cid;\n\tu8 vfid = QED_CXT_PF_CID;\n\tbool b_legacy_vf = false;\n\tu32 cid = 0;\n\n\t \n\tif (p_vf_params) {\n\t\tvfid = p_vf_params->vfid;\n\n\t\tif (p_vf_params->vf_legacy & QED_QCID_LEGACY_VF_CID) {\n\t\t\tb_legacy_vf = true;\n\t\t\tcid = p_vf_params->vf_qid;\n\t\t}\n\t}\n\n\t \n\tif (IS_PF(p_hwfn->cdev) && !b_legacy_vf) {\n\t\tif (_qed_cxt_acquire_cid(p_hwfn, PROTOCOLID_ETH,\n\t\t\t\t\t &cid, vfid)) {\n\t\t\tDP_NOTICE(p_hwfn, \"Failed to acquire cid\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tp_cid = _qed_eth_queue_to_cid(p_hwfn, opaque_fid, cid,\n\t\t\t\t      p_params, b_is_rx, p_vf_params);\n\tif (!p_cid && IS_PF(p_hwfn->cdev) && !b_legacy_vf)\n\t\t_qed_cxt_release_cid(p_hwfn, cid, vfid);\n\n\treturn p_cid;\n}\n\nstatic struct qed_queue_cid *\nqed_eth_queue_to_cid_pf(struct qed_hwfn *p_hwfn,\n\t\t\tu16 opaque_fid,\n\t\t\tbool b_is_rx,\n\t\t\tstruct qed_queue_start_common_params *p_params)\n{\n\treturn qed_eth_queue_to_cid(p_hwfn, opaque_fid, p_params, b_is_rx,\n\t\t\t\t    NULL);\n}\n\nint qed_sp_eth_vport_start(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_sp_vport_start_params *p_params)\n{\n\tstruct vport_start_ramrod_data *p_ramrod = NULL;\n\tstruct eth_vport_tpa_param *tpa_param;\n\tstruct qed_spq_entry *p_ent =  NULL;\n\tstruct qed_sp_init_data init_data;\n\tu16 min_size, rx_mode = 0;\n\tu8 abs_vport_id = 0;\n\tint rc;\n\n\trc = qed_fw_vport(p_hwfn, p_params->vport_id, &abs_vport_id);\n\tif (rc)\n\t\treturn rc;\n\n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_params->opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_VPORT_START,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod\t\t= &p_ent->ramrod.vport_start;\n\tp_ramrod->vport_id\t= abs_vport_id;\n\n\tp_ramrod->mtu\t\t\t= cpu_to_le16(p_params->mtu);\n\tp_ramrod->handle_ptp_pkts\t= p_params->handle_ptp_pkts;\n\tp_ramrod->inner_vlan_removal_en\t= p_params->remove_inner_vlan;\n\tp_ramrod->drop_ttl0_en\t\t= p_params->drop_ttl0;\n\tp_ramrod->untagged\t\t= p_params->only_untagged;\n\n\tSET_FIELD(rx_mode, ETH_VPORT_RX_MODE_UCAST_DROP_ALL, 1);\n\tSET_FIELD(rx_mode, ETH_VPORT_RX_MODE_MCAST_DROP_ALL, 1);\n\n\tp_ramrod->rx_mode.state = cpu_to_le16(rx_mode);\n\n\t \n\ttpa_param = &p_ramrod->tpa_param;\n\tmemset(tpa_param, 0, sizeof(*tpa_param));\n\n\ttpa_param->max_buff_num = p_params->max_buffers_per_cqe;\n\n\tswitch (p_params->tpa_mode) {\n\tcase QED_TPA_MODE_GRO:\n\t\tmin_size = p_params->mtu / 2;\n\n\t\ttpa_param->tpa_max_aggs_num = ETH_TPA_MAX_AGGS_NUM;\n\t\ttpa_param->tpa_max_size = cpu_to_le16(U16_MAX);\n\t\ttpa_param->tpa_min_size_to_cont = cpu_to_le16(min_size);\n\t\ttpa_param->tpa_min_size_to_start = cpu_to_le16(min_size);\n\t\ttpa_param->tpa_ipv4_en_flg = 1;\n\t\ttpa_param->tpa_ipv6_en_flg = 1;\n\t\ttpa_param->tpa_pkt_split_flg = 1;\n\t\ttpa_param->tpa_gro_consistent_flg = 1;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tp_ramrod->tx_switching_en = p_params->tx_switching;\n\n\tp_ramrod->ctl_frame_mac_check_en = !!p_params->check_mac;\n\tp_ramrod->ctl_frame_ethtype_check_en = !!p_params->check_ethtype;\n\n\t \n\tp_ramrod->sw_fid = qed_concrete_to_sw_fid(p_hwfn->cdev,\n\t\t\t\t\t\t  p_params->concrete_fid);\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nstatic int qed_sp_vport_start(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_sp_vport_start_params *p_params)\n{\n\tif (IS_VF(p_hwfn->cdev)) {\n\t\treturn qed_vf_pf_vport_start(p_hwfn, p_params->vport_id,\n\t\t\t\t\t     p_params->mtu,\n\t\t\t\t\t     p_params->remove_inner_vlan,\n\t\t\t\t\t     p_params->tpa_mode,\n\t\t\t\t\t     p_params->max_buffers_per_cqe,\n\t\t\t\t\t     p_params->only_untagged);\n\t}\n\n\treturn qed_sp_eth_vport_start(p_hwfn, p_params);\n}\n\nstatic int\nqed_sp_vport_update_rss(struct qed_hwfn *p_hwfn,\n\t\t\tstruct vport_update_ramrod_data *p_ramrod,\n\t\t\tstruct qed_rss_params *p_rss)\n{\n\tstruct eth_vport_rss_config *p_config;\n\tu16 capabilities = 0;\n\tint i, table_size;\n\tint rc = 0;\n\n\tif (!p_rss) {\n\t\tp_ramrod->common.update_rss_flg = 0;\n\t\treturn rc;\n\t}\n\tp_config = &p_ramrod->rss_config;\n\n\tBUILD_BUG_ON(QED_RSS_IND_TABLE_SIZE != ETH_RSS_IND_TABLE_ENTRIES_NUM);\n\n\trc = qed_fw_rss_eng(p_hwfn, p_rss->rss_eng_id, &p_config->rss_id);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod->common.update_rss_flg = p_rss->update_rss_config;\n\tp_config->update_rss_capabilities = p_rss->update_rss_capabilities;\n\tp_config->update_rss_ind_table = p_rss->update_rss_ind_table;\n\tp_config->update_rss_key = p_rss->update_rss_key;\n\n\tp_config->rss_mode = p_rss->rss_enable ?\n\t\t\t     ETH_VPORT_RSS_MODE_REGULAR :\n\t\t\t     ETH_VPORT_RSS_MODE_DISABLED;\n\n\tSET_FIELD(capabilities,\n\t\t  ETH_VPORT_RSS_CONFIG_IPV4_CAPABILITY,\n\t\t  !!(p_rss->rss_caps & QED_RSS_IPV4));\n\tSET_FIELD(capabilities,\n\t\t  ETH_VPORT_RSS_CONFIG_IPV6_CAPABILITY,\n\t\t  !!(p_rss->rss_caps & QED_RSS_IPV6));\n\tSET_FIELD(capabilities,\n\t\t  ETH_VPORT_RSS_CONFIG_IPV4_TCP_CAPABILITY,\n\t\t  !!(p_rss->rss_caps & QED_RSS_IPV4_TCP));\n\tSET_FIELD(capabilities,\n\t\t  ETH_VPORT_RSS_CONFIG_IPV6_TCP_CAPABILITY,\n\t\t  !!(p_rss->rss_caps & QED_RSS_IPV6_TCP));\n\tSET_FIELD(capabilities,\n\t\t  ETH_VPORT_RSS_CONFIG_IPV4_UDP_CAPABILITY,\n\t\t  !!(p_rss->rss_caps & QED_RSS_IPV4_UDP));\n\tSET_FIELD(capabilities,\n\t\t  ETH_VPORT_RSS_CONFIG_IPV6_UDP_CAPABILITY,\n\t\t  !!(p_rss->rss_caps & QED_RSS_IPV6_UDP));\n\tp_config->tbl_size = p_rss->rss_table_size_log;\n\n\tp_config->capabilities = cpu_to_le16(capabilities);\n\n\tDP_VERBOSE(p_hwfn, NETIF_MSG_IFUP,\n\t\t   \"update rss flag %d, rss_mode = %d, update_caps = %d, capabilities = %d, update_ind = %d, update_rss_key = %d\\n\",\n\t\t   p_ramrod->common.update_rss_flg,\n\t\t   p_config->rss_mode,\n\t\t   p_config->update_rss_capabilities,\n\t\t   p_config->capabilities,\n\t\t   p_config->update_rss_ind_table, p_config->update_rss_key);\n\n\ttable_size = min_t(int, QED_RSS_IND_TABLE_SIZE,\n\t\t\t   1 << p_config->tbl_size);\n\tfor (i = 0; i < table_size; i++) {\n\t\tstruct qed_queue_cid *p_queue = p_rss->rss_ind_table[i];\n\n\t\tif (!p_queue)\n\t\t\treturn -EINVAL;\n\n\t\tp_config->indirection_table[i] =\n\t\t    cpu_to_le16(p_queue->abs.queue_id);\n\t}\n\n\tDP_VERBOSE(p_hwfn, NETIF_MSG_IFUP,\n\t\t   \"Configured RSS indirection table [%d entries]:\\n\",\n\t\t   table_size);\n\tfor (i = 0; i < QED_RSS_IND_TABLE_SIZE; i += 0x10) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   NETIF_MSG_IFUP,\n\t\t\t   \"%04x %04x %04x %04x %04x %04x %04x %04x %04x %04x %04x %04x %04x %04x %04x %04x\\n\",\n\t\t\t   le16_to_cpu(p_config->indirection_table[i]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 1]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 2]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 3]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 4]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 5]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 6]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 7]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 8]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 9]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 10]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 11]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 12]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 13]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 14]),\n\t\t\t   le16_to_cpu(p_config->indirection_table[i + 15]));\n\t}\n\n\tfor (i = 0; i < 10; i++)\n\t\tp_config->rss_key[i] = cpu_to_le32(p_rss->rss_key[i]);\n\n\treturn rc;\n}\n\nstatic void\nqed_sp_update_accept_mode(struct qed_hwfn *p_hwfn,\n\t\t\t  struct vport_update_ramrod_data *p_ramrod,\n\t\t\t  struct qed_filter_accept_flags accept_flags)\n{\n\tp_ramrod->common.update_rx_mode_flg =\n\t\taccept_flags.update_rx_mode_config;\n\n\tp_ramrod->common.update_tx_mode_flg =\n\t\taccept_flags.update_tx_mode_config;\n\n\t \n\tif (p_ramrod->common.update_rx_mode_flg) {\n\t\tu8 accept_filter = accept_flags.rx_accept_filter;\n\t\tu16 state = 0;\n\n\t\tSET_FIELD(state, ETH_VPORT_RX_MODE_UCAST_DROP_ALL,\n\t\t\t  !(!!(accept_filter & QED_ACCEPT_UCAST_MATCHED) ||\n\t\t\t    !!(accept_filter & QED_ACCEPT_UCAST_UNMATCHED)));\n\n\t\tSET_FIELD(state, ETH_VPORT_RX_MODE_UCAST_ACCEPT_UNMATCHED,\n\t\t\t  !!(accept_filter & QED_ACCEPT_UCAST_UNMATCHED));\n\n\t\tSET_FIELD(state, ETH_VPORT_RX_MODE_MCAST_DROP_ALL,\n\t\t\t  !(!!(accept_filter & QED_ACCEPT_MCAST_MATCHED) ||\n\t\t\t    !!(accept_filter & QED_ACCEPT_MCAST_UNMATCHED)));\n\n\t\tSET_FIELD(state, ETH_VPORT_RX_MODE_MCAST_ACCEPT_ALL,\n\t\t\t  (!!(accept_filter & QED_ACCEPT_MCAST_MATCHED) &&\n\t\t\t   !!(accept_filter & QED_ACCEPT_MCAST_UNMATCHED)));\n\n\t\tSET_FIELD(state, ETH_VPORT_RX_MODE_BCAST_ACCEPT_ALL,\n\t\t\t  !!(accept_filter & QED_ACCEPT_BCAST));\n\n\t\tSET_FIELD(state, ETH_VPORT_RX_MODE_ACCEPT_ANY_VNI,\n\t\t\t  !!(accept_filter & QED_ACCEPT_ANY_VNI));\n\n\t\tp_ramrod->rx_mode.state = cpu_to_le16(state);\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"p_ramrod->rx_mode.state = 0x%x\\n\", state);\n\t}\n\n\t \n\tif (p_ramrod->common.update_tx_mode_flg) {\n\t\tu8 accept_filter = accept_flags.tx_accept_filter;\n\t\tu16 state = 0;\n\n\t\tSET_FIELD(state, ETH_VPORT_TX_MODE_UCAST_DROP_ALL,\n\t\t\t  !!(accept_filter & QED_ACCEPT_NONE));\n\n\t\tSET_FIELD(state, ETH_VPORT_TX_MODE_MCAST_DROP_ALL,\n\t\t\t  !!(accept_filter & QED_ACCEPT_NONE));\n\n\t\tSET_FIELD(state, ETH_VPORT_TX_MODE_MCAST_ACCEPT_ALL,\n\t\t\t  (!!(accept_filter & QED_ACCEPT_MCAST_MATCHED) &&\n\t\t\t   !!(accept_filter & QED_ACCEPT_MCAST_UNMATCHED)));\n\n\t\tSET_FIELD(state, ETH_VPORT_TX_MODE_UCAST_ACCEPT_ALL,\n\t\t\t  (!!(accept_filter & QED_ACCEPT_UCAST_MATCHED) &&\n\t\t\t   !!(accept_filter & QED_ACCEPT_UCAST_UNMATCHED)));\n\n\t\tSET_FIELD(state, ETH_VPORT_TX_MODE_BCAST_ACCEPT_ALL,\n\t\t\t  !!(accept_filter & QED_ACCEPT_BCAST));\n\n\t\tp_ramrod->tx_mode.state = cpu_to_le16(state);\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"p_ramrod->tx_mode.state = 0x%x\\n\", state);\n\t}\n}\n\nstatic void\nqed_sp_vport_update_sge_tpa(struct qed_hwfn *p_hwfn,\n\t\t\t    struct vport_update_ramrod_data *p_ramrod,\n\t\t\t    const struct qed_sge_tpa_params *param)\n{\n\tstruct eth_vport_tpa_param *tpa;\n\n\tif (!param) {\n\t\tp_ramrod->common.update_tpa_param_flg = 0;\n\t\tp_ramrod->common.update_tpa_en_flg = 0;\n\t\tp_ramrod->common.update_tpa_param_flg = 0;\n\t\treturn;\n\t}\n\n\tp_ramrod->common.update_tpa_en_flg = param->update_tpa_en_flg;\n\ttpa = &p_ramrod->tpa_param;\n\ttpa->tpa_ipv4_en_flg = param->tpa_ipv4_en_flg;\n\ttpa->tpa_ipv6_en_flg = param->tpa_ipv6_en_flg;\n\ttpa->tpa_ipv4_tunn_en_flg = param->tpa_ipv4_tunn_en_flg;\n\ttpa->tpa_ipv6_tunn_en_flg = param->tpa_ipv6_tunn_en_flg;\n\n\tp_ramrod->common.update_tpa_param_flg = param->update_tpa_param_flg;\n\ttpa->max_buff_num = param->max_buffers_per_cqe;\n\ttpa->tpa_pkt_split_flg = param->tpa_pkt_split_flg;\n\ttpa->tpa_hdr_data_split_flg = param->tpa_hdr_data_split_flg;\n\ttpa->tpa_gro_consistent_flg = param->tpa_gro_consistent_flg;\n\ttpa->tpa_max_aggs_num = param->tpa_max_aggs_num;\n\ttpa->tpa_max_size = cpu_to_le16(param->tpa_max_size);\n\ttpa->tpa_min_size_to_start = cpu_to_le16(param->tpa_min_size_to_start);\n\ttpa->tpa_min_size_to_cont = cpu_to_le16(param->tpa_min_size_to_cont);\n}\n\nstatic void\nqed_sp_update_mcast_bin(struct qed_hwfn *p_hwfn,\n\t\t\tstruct vport_update_ramrod_data *p_ramrod,\n\t\t\tstruct qed_sp_vport_update_params *p_params)\n{\n\tint i;\n\n\tmemset(&p_ramrod->approx_mcast.bins, 0,\n\t       sizeof(p_ramrod->approx_mcast.bins));\n\n\tif (!p_params->update_approx_mcast_flg)\n\t\treturn;\n\n\tp_ramrod->common.update_approx_mcast_flg = 1;\n\tfor (i = 0; i < ETH_MULTICAST_MAC_BINS_IN_REGS; i++) {\n\t\tu32 *p_bins = p_params->bins;\n\n\t\tp_ramrod->approx_mcast.bins[i] = cpu_to_le32(p_bins[i]);\n\t}\n}\n\nint qed_sp_vport_update(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_sp_vport_update_params *p_params,\n\t\t\tenum spq_mode comp_mode,\n\t\t\tstruct qed_spq_comp_cb *p_comp_data)\n{\n\tstruct qed_rss_params *p_rss_params = p_params->rss_params;\n\tstruct vport_update_ramrod_data_cmn *p_cmn;\n\tstruct qed_sp_init_data init_data;\n\tstruct vport_update_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tu8 abs_vport_id = 0, val;\n\tint rc = -EINVAL;\n\n\tif (IS_VF(p_hwfn->cdev)) {\n\t\trc = qed_vf_pf_vport_update(p_hwfn, p_params);\n\t\treturn rc;\n\t}\n\n\trc = qed_fw_vport(p_hwfn, p_params->vport_id, &abs_vport_id);\n\tif (rc)\n\t\treturn rc;\n\n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_params->opaque_fid;\n\tinit_data.comp_mode = comp_mode;\n\tinit_data.p_comp_data = p_comp_data;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_VPORT_UPDATE,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tp_ramrod = &p_ent->ramrod.vport_update;\n\tp_cmn = &p_ramrod->common;\n\n\tp_cmn->vport_id = abs_vport_id;\n\tp_cmn->rx_active_flg = p_params->vport_active_rx_flg;\n\tp_cmn->update_rx_active_flg = p_params->update_vport_active_rx_flg;\n\tp_cmn->tx_active_flg = p_params->vport_active_tx_flg;\n\tp_cmn->update_tx_active_flg = p_params->update_vport_active_tx_flg;\n\tp_cmn->accept_any_vlan = p_params->accept_any_vlan;\n\tval = p_params->update_accept_any_vlan_flg;\n\tp_cmn->update_accept_any_vlan_flg = val;\n\n\tp_cmn->inner_vlan_removal_en = p_params->inner_vlan_removal_flg;\n\tval = p_params->update_inner_vlan_removal_flg;\n\tp_cmn->update_inner_vlan_removal_en_flg = val;\n\n\tp_cmn->default_vlan_en = p_params->default_vlan_enable_flg;\n\tval = p_params->update_default_vlan_enable_flg;\n\tp_cmn->update_default_vlan_en_flg = val;\n\n\tp_cmn->default_vlan = cpu_to_le16(p_params->default_vlan);\n\tp_cmn->update_default_vlan_flg = p_params->update_default_vlan_flg;\n\n\tp_cmn->silent_vlan_removal_en = p_params->silent_vlan_removal_flg;\n\n\tp_ramrod->common.tx_switching_en = p_params->tx_switching_flg;\n\tp_cmn->update_tx_switching_en_flg = p_params->update_tx_switching_flg;\n\n\tp_cmn->anti_spoofing_en = p_params->anti_spoofing_en;\n\tval = p_params->update_anti_spoofing_en_flg;\n\tp_ramrod->common.update_anti_spoofing_en_flg = val;\n\n\trc = qed_sp_vport_update_rss(p_hwfn, p_ramrod, p_rss_params);\n\tif (rc) {\n\t\tqed_sp_destroy_request(p_hwfn, p_ent);\n\t\treturn rc;\n\t}\n\n\tif (p_params->update_ctl_frame_check) {\n\t\tp_cmn->ctl_frame_mac_check_en = p_params->mac_chk_en;\n\t\tp_cmn->ctl_frame_ethtype_check_en = p_params->ethtype_chk_en;\n\t}\n\n\t \n\tqed_sp_update_mcast_bin(p_hwfn, p_ramrod, p_params);\n\n\tqed_sp_update_accept_mode(p_hwfn, p_ramrod, p_params->accept_flags);\n\tqed_sp_vport_update_sge_tpa(p_hwfn, p_ramrod, p_params->sge_tpa_params);\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nint qed_sp_vport_stop(struct qed_hwfn *p_hwfn, u16 opaque_fid, u8 vport_id)\n{\n\tstruct vport_stop_ramrod_data *p_ramrod;\n\tstruct qed_sp_init_data init_data;\n\tstruct qed_spq_entry *p_ent;\n\tu8 abs_vport_id = 0;\n\tint rc;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn qed_vf_pf_vport_stop(p_hwfn);\n\n\trc = qed_fw_vport(p_hwfn, vport_id, &abs_vport_id);\n\tif (rc)\n\t\treturn rc;\n\n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_VPORT_STOP,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.vport_stop;\n\tp_ramrod->vport_id = abs_vport_id;\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nstatic int\nqed_vf_pf_accept_flags(struct qed_hwfn *p_hwfn,\n\t\t       struct qed_filter_accept_flags *p_accept_flags)\n{\n\tstruct qed_sp_vport_update_params s_params;\n\n\tmemset(&s_params, 0, sizeof(s_params));\n\tmemcpy(&s_params.accept_flags, p_accept_flags,\n\t       sizeof(struct qed_filter_accept_flags));\n\n\treturn qed_vf_pf_vport_update(p_hwfn, &s_params);\n}\n\nstatic int qed_filter_accept_cmd(struct qed_dev *cdev,\n\t\t\t\t u8 vport,\n\t\t\t\t struct qed_filter_accept_flags accept_flags,\n\t\t\t\t u8 update_accept_any_vlan,\n\t\t\t\t u8 accept_any_vlan,\n\t\t\t\t enum spq_mode comp_mode,\n\t\t\t\t struct qed_spq_comp_cb *p_comp_data)\n{\n\tstruct qed_sp_vport_update_params vport_update_params;\n\tint i, rc;\n\n\t \n\tmemset(&vport_update_params, 0, sizeof(vport_update_params));\n\tvport_update_params.vport_id = vport;\n\tvport_update_params.accept_flags = accept_flags;\n\tvport_update_params.update_accept_any_vlan_flg = update_accept_any_vlan;\n\tvport_update_params.accept_any_vlan = accept_any_vlan;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tvport_update_params.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\n\t\tif (IS_VF(cdev)) {\n\t\t\trc = qed_vf_pf_accept_flags(p_hwfn, &accept_flags);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t\tcontinue;\n\t\t}\n\n\t\trc = qed_sp_vport_update(p_hwfn, &vport_update_params,\n\t\t\t\t\t comp_mode, p_comp_data);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Update rx_mode failed %d\\n\", rc);\n\t\t\treturn rc;\n\t\t}\n\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"Accept filter configured, flags = [Rx]%x [Tx]%x\\n\",\n\t\t\t   accept_flags.rx_accept_filter,\n\t\t\t   accept_flags.tx_accept_filter);\n\t\tif (update_accept_any_vlan)\n\t\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t\t   \"accept_any_vlan=%d configured\\n\",\n\t\t\t\t   accept_any_vlan);\n\t}\n\n\treturn 0;\n}\n\nint qed_eth_rxq_start_ramrod(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_queue_cid *p_cid,\n\t\t\t     u16 bd_max_bytes,\n\t\t\t     dma_addr_t bd_chain_phys_addr,\n\t\t\t     dma_addr_t cqe_pbl_addr, u16 cqe_pbl_size)\n{\n\tstruct rx_queue_start_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc = -EINVAL;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"opaque_fid=0x%x, cid=0x%x, rx_qzone=0x%x, vport_id=0x%x, sb_id=0x%x\\n\",\n\t\t   p_cid->opaque_fid, p_cid->cid,\n\t\t   p_cid->abs.queue_id, p_cid->abs.vport_id, p_cid->sb_igu_id);\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = p_cid->cid;\n\tinit_data.opaque_fid = p_cid->opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_RX_QUEUE_START,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.rx_queue_start;\n\n\tp_ramrod->sb_id = cpu_to_le16(p_cid->sb_igu_id);\n\tp_ramrod->sb_index = p_cid->sb_idx;\n\tp_ramrod->vport_id = p_cid->abs.vport_id;\n\tp_ramrod->stats_counter_id = p_cid->abs.stats_id;\n\tp_ramrod->rx_queue_id = cpu_to_le16(p_cid->abs.queue_id);\n\tp_ramrod->complete_cqe_flg = 0;\n\tp_ramrod->complete_event_flg = 1;\n\n\tp_ramrod->bd_max_bytes = cpu_to_le16(bd_max_bytes);\n\tDMA_REGPAIR_LE(p_ramrod->bd_base, bd_chain_phys_addr);\n\n\tp_ramrod->num_of_pbl_pages = cpu_to_le16(cqe_pbl_size);\n\tDMA_REGPAIR_LE(p_ramrod->cqe_pbl_addr, cqe_pbl_addr);\n\n\tif (p_cid->vfid != QED_QUEUE_CID_SELF) {\n\t\tbool b_legacy_vf = !!(p_cid->vf_legacy &\n\t\t\t\t      QED_QCID_LEGACY_VF_RX_PROD);\n\n\t\tp_ramrod->vf_rx_prod_index = p_cid->vf_qid;\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"Queue%s is meant for VF rxq[%02x]\\n\",\n\t\t\t   b_legacy_vf ? \" [legacy]\" : \"\", p_cid->vf_qid);\n\t\tp_ramrod->vf_rx_prod_use_zone_a = b_legacy_vf;\n\t}\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nstatic int\nqed_eth_pf_rx_queue_start(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_queue_cid *p_cid,\n\t\t\t  u16 bd_max_bytes,\n\t\t\t  dma_addr_t bd_chain_phys_addr,\n\t\t\t  dma_addr_t cqe_pbl_addr,\n\t\t\t  u16 cqe_pbl_size, void __iomem **pp_prod)\n{\n\tu32 init_prod_val = 0;\n\n\t*pp_prod = (u8 __iomem *)\n\t    p_hwfn->regview +\n\t    GET_GTT_REG_ADDR(GTT_BAR0_MAP_REG_MSDM_RAM,\n\t\t\t     MSTORM_ETH_PF_PRODS, p_cid->abs.queue_id);\n\n\t \n\t__internal_ram_wr(p_hwfn, *pp_prod, sizeof(u32),\n\t\t\t  (u32 *)(&init_prod_val));\n\n\treturn qed_eth_rxq_start_ramrod(p_hwfn, p_cid,\n\t\t\t\t\tbd_max_bytes,\n\t\t\t\t\tbd_chain_phys_addr,\n\t\t\t\t\tcqe_pbl_addr, cqe_pbl_size);\n}\n\nstatic int\nqed_eth_rx_queue_start(struct qed_hwfn *p_hwfn,\n\t\t       u16 opaque_fid,\n\t\t       struct qed_queue_start_common_params *p_params,\n\t\t       u16 bd_max_bytes,\n\t\t       dma_addr_t bd_chain_phys_addr,\n\t\t       dma_addr_t cqe_pbl_addr,\n\t\t       u16 cqe_pbl_size,\n\t\t       struct qed_rxq_start_ret_params *p_ret_params)\n{\n\tstruct qed_queue_cid *p_cid;\n\tint rc;\n\n\t \n\tp_cid = qed_eth_queue_to_cid_pf(p_hwfn, opaque_fid, true, p_params);\n\tif (!p_cid)\n\t\treturn -ENOMEM;\n\n\tif (IS_PF(p_hwfn->cdev)) {\n\t\trc = qed_eth_pf_rx_queue_start(p_hwfn, p_cid,\n\t\t\t\t\t       bd_max_bytes,\n\t\t\t\t\t       bd_chain_phys_addr,\n\t\t\t\t\t       cqe_pbl_addr, cqe_pbl_size,\n\t\t\t\t\t       &p_ret_params->p_prod);\n\t} else {\n\t\trc = qed_vf_pf_rxq_start(p_hwfn, p_cid,\n\t\t\t\t\t bd_max_bytes,\n\t\t\t\t\t bd_chain_phys_addr,\n\t\t\t\t\t cqe_pbl_addr,\n\t\t\t\t\t cqe_pbl_size, &p_ret_params->p_prod);\n\t}\n\n\t \n\tif (rc)\n\t\tqed_eth_queue_cid_release(p_hwfn, p_cid);\n\telse\n\t\tp_ret_params->p_handle = (void *)p_cid;\n\n\treturn rc;\n}\n\nint qed_sp_eth_rx_queues_update(struct qed_hwfn *p_hwfn,\n\t\t\t\tvoid **pp_rxq_handles,\n\t\t\t\tu8 num_rxqs,\n\t\t\t\tu8 complete_cqe_flg,\n\t\t\t\tu8 complete_event_flg,\n\t\t\t\tenum spq_mode comp_mode,\n\t\t\t\tstruct qed_spq_comp_cb *p_comp_data)\n{\n\tstruct rx_queue_update_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tstruct qed_queue_cid *p_cid;\n\tint rc = -EINVAL;\n\tu8 i;\n\n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.comp_mode = comp_mode;\n\tinit_data.p_comp_data = p_comp_data;\n\n\tfor (i = 0; i < num_rxqs; i++) {\n\t\tp_cid = ((struct qed_queue_cid **)pp_rxq_handles)[i];\n\n\t\t \n\t\tinit_data.cid = p_cid->cid;\n\t\tinit_data.opaque_fid = p_cid->opaque_fid;\n\n\t\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t\t ETH_RAMROD_RX_QUEUE_UPDATE,\n\t\t\t\t\t PROTOCOLID_ETH, &init_data);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tp_ramrod = &p_ent->ramrod.rx_queue_update;\n\t\tp_ramrod->vport_id = p_cid->abs.vport_id;\n\n\t\tp_ramrod->rx_queue_id = cpu_to_le16(p_cid->abs.queue_id);\n\t\tp_ramrod->complete_cqe_flg = complete_cqe_flg;\n\t\tp_ramrod->complete_event_flg = complete_event_flg;\n\n\t\trc = qed_spq_post(p_hwfn, p_ent, NULL);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\treturn rc;\n}\n\nstatic int\nqed_eth_pf_rx_queue_stop(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_queue_cid *p_cid,\n\t\t\t bool b_eq_completion_only, bool b_cqe_completion)\n{\n\tstruct rx_queue_stop_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = p_cid->cid;\n\tinit_data.opaque_fid = p_cid->opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_RX_QUEUE_STOP,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.rx_queue_stop;\n\tp_ramrod->vport_id = p_cid->abs.vport_id;\n\tp_ramrod->rx_queue_id = cpu_to_le16(p_cid->abs.queue_id);\n\n\t \n\tp_ramrod->complete_cqe_flg = ((p_cid->vfid == QED_QUEUE_CID_SELF) &&\n\t\t\t\t      !b_eq_completion_only) ||\n\t\t\t\t     b_cqe_completion;\n\tp_ramrod->complete_event_flg = (p_cid->vfid != QED_QUEUE_CID_SELF) ||\n\t\t\t\t       b_eq_completion_only;\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nint qed_eth_rx_queue_stop(struct qed_hwfn *p_hwfn,\n\t\t\t  void *p_rxq,\n\t\t\t  bool eq_completion_only, bool cqe_completion)\n{\n\tstruct qed_queue_cid *p_cid = (struct qed_queue_cid *)p_rxq;\n\tint rc = -EINVAL;\n\n\tif (IS_PF(p_hwfn->cdev))\n\t\trc = qed_eth_pf_rx_queue_stop(p_hwfn, p_cid,\n\t\t\t\t\t      eq_completion_only,\n\t\t\t\t\t      cqe_completion);\n\telse\n\t\trc = qed_vf_pf_rxq_stop(p_hwfn, p_cid, cqe_completion);\n\n\tif (!rc)\n\t\tqed_eth_queue_cid_release(p_hwfn, p_cid);\n\treturn rc;\n}\n\nint\nqed_eth_txq_start_ramrod(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_queue_cid *p_cid,\n\t\t\t dma_addr_t pbl_addr, u16 pbl_size, u16 pq_id)\n{\n\tstruct tx_queue_start_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc = -EINVAL;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = p_cid->cid;\n\tinit_data.opaque_fid = p_cid->opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_TX_QUEUE_START,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.tx_queue_start;\n\tp_ramrod->vport_id = p_cid->abs.vport_id;\n\n\tp_ramrod->sb_id = cpu_to_le16(p_cid->sb_igu_id);\n\tp_ramrod->sb_index = p_cid->sb_idx;\n\tp_ramrod->stats_counter_id = p_cid->abs.stats_id;\n\n\tp_ramrod->queue_zone_id = cpu_to_le16(p_cid->abs.queue_id);\n\tp_ramrod->same_as_last_id = cpu_to_le16(p_cid->abs.queue_id);\n\n\tp_ramrod->pbl_size = cpu_to_le16(pbl_size);\n\tDMA_REGPAIR_LE(p_ramrod->pbl_base_addr, pbl_addr);\n\n\tp_ramrod->qm_pq_id = cpu_to_le16(pq_id);\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nstatic int\nqed_eth_pf_tx_queue_start(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_queue_cid *p_cid,\n\t\t\t  u8 tc,\n\t\t\t  dma_addr_t pbl_addr,\n\t\t\t  u16 pbl_size, void __iomem **pp_doorbell)\n{\n\tint rc;\n\n\trc = qed_eth_txq_start_ramrod(p_hwfn, p_cid,\n\t\t\t\t      pbl_addr, pbl_size,\n\t\t\t\t      qed_get_cm_pq_idx_mcos(p_hwfn, tc));\n\tif (rc)\n\t\treturn rc;\n\n\t \n\t*pp_doorbell = p_hwfn->doorbells +\n\t\t       qed_db_addr(p_cid->cid, DQ_DEMS_LEGACY);\n\n\treturn 0;\n}\n\nstatic int\nqed_eth_tx_queue_start(struct qed_hwfn *p_hwfn,\n\t\t       u16 opaque_fid,\n\t\t       struct qed_queue_start_common_params *p_params,\n\t\t       u8 tc,\n\t\t       dma_addr_t pbl_addr,\n\t\t       u16 pbl_size,\n\t\t       struct qed_txq_start_ret_params *p_ret_params)\n{\n\tstruct qed_queue_cid *p_cid;\n\tint rc;\n\n\tp_cid = qed_eth_queue_to_cid_pf(p_hwfn, opaque_fid, false, p_params);\n\tif (!p_cid)\n\t\treturn -EINVAL;\n\n\tif (IS_PF(p_hwfn->cdev))\n\t\trc = qed_eth_pf_tx_queue_start(p_hwfn, p_cid, tc,\n\t\t\t\t\t       pbl_addr, pbl_size,\n\t\t\t\t\t       &p_ret_params->p_doorbell);\n\telse\n\t\trc = qed_vf_pf_txq_start(p_hwfn, p_cid,\n\t\t\t\t\t pbl_addr, pbl_size,\n\t\t\t\t\t &p_ret_params->p_doorbell);\n\n\tif (rc)\n\t\tqed_eth_queue_cid_release(p_hwfn, p_cid);\n\telse\n\t\tp_ret_params->p_handle = (void *)p_cid;\n\n\treturn rc;\n}\n\nstatic int\nqed_eth_pf_tx_queue_stop(struct qed_hwfn *p_hwfn, struct qed_queue_cid *p_cid)\n{\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tint rc;\n\n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = p_cid->cid;\n\tinit_data.opaque_fid = p_cid->opaque_fid;\n\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_TX_QUEUE_STOP,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nint qed_eth_tx_queue_stop(struct qed_hwfn *p_hwfn, void *p_handle)\n{\n\tstruct qed_queue_cid *p_cid = (struct qed_queue_cid *)p_handle;\n\tint rc;\n\n\tif (IS_PF(p_hwfn->cdev))\n\t\trc = qed_eth_pf_tx_queue_stop(p_hwfn, p_cid);\n\telse\n\t\trc = qed_vf_pf_txq_stop(p_hwfn, p_cid);\n\n\tif (!rc)\n\t\tqed_eth_queue_cid_release(p_hwfn, p_cid);\n\treturn rc;\n}\n\nstatic enum eth_filter_action qed_filter_action(enum qed_filter_opcode opcode)\n{\n\tenum eth_filter_action action = MAX_ETH_FILTER_ACTION;\n\n\tswitch (opcode) {\n\tcase QED_FILTER_ADD:\n\t\taction = ETH_FILTER_ACTION_ADD;\n\t\tbreak;\n\tcase QED_FILTER_REMOVE:\n\t\taction = ETH_FILTER_ACTION_REMOVE;\n\t\tbreak;\n\tcase QED_FILTER_FLUSH:\n\t\taction = ETH_FILTER_ACTION_REMOVE_ALL;\n\t\tbreak;\n\tdefault:\n\t\taction = MAX_ETH_FILTER_ACTION;\n\t}\n\n\treturn action;\n}\n\nstatic int\nqed_filter_ucast_common(struct qed_hwfn *p_hwfn,\n\t\t\tu16 opaque_fid,\n\t\t\tstruct qed_filter_ucast *p_filter_cmd,\n\t\t\tstruct vport_filter_update_ramrod_data **pp_ramrod,\n\t\t\tstruct qed_spq_entry **pp_ent,\n\t\t\tenum spq_mode comp_mode,\n\t\t\tstruct qed_spq_comp_cb *p_comp_data)\n{\n\tu8 vport_to_add_to = 0, vport_to_remove_from = 0;\n\tstruct vport_filter_update_ramrod_data *p_ramrod;\n\tstruct eth_filter_cmd *p_first_filter;\n\tstruct eth_filter_cmd *p_second_filter;\n\tstruct qed_sp_init_data init_data;\n\tenum eth_filter_action action;\n\tint rc;\n\n\trc = qed_fw_vport(p_hwfn, p_filter_cmd->vport_to_remove_from,\n\t\t\t  &vport_to_remove_from);\n\tif (rc)\n\t\treturn rc;\n\n\trc = qed_fw_vport(p_hwfn, p_filter_cmd->vport_to_add_to,\n\t\t\t  &vport_to_add_to);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = opaque_fid;\n\tinit_data.comp_mode = comp_mode;\n\tinit_data.p_comp_data = p_comp_data;\n\n\trc = qed_sp_init_request(p_hwfn, pp_ent,\n\t\t\t\t ETH_RAMROD_FILTERS_UPDATE,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\t*pp_ramrod = &(*pp_ent)->ramrod.vport_filter_update;\n\tp_ramrod = *pp_ramrod;\n\tp_ramrod->filter_cmd_hdr.rx = p_filter_cmd->is_rx_filter ? 1 : 0;\n\tp_ramrod->filter_cmd_hdr.tx = p_filter_cmd->is_tx_filter ? 1 : 0;\n\n\tswitch (p_filter_cmd->opcode) {\n\tcase QED_FILTER_REPLACE:\n\tcase QED_FILTER_MOVE:\n\t\tp_ramrod->filter_cmd_hdr.cmd_cnt = 2; break;\n\tdefault:\n\t\tp_ramrod->filter_cmd_hdr.cmd_cnt = 1; break;\n\t}\n\n\tp_first_filter\t= &p_ramrod->filter_cmds[0];\n\tp_second_filter = &p_ramrod->filter_cmds[1];\n\n\tswitch (p_filter_cmd->type) {\n\tcase QED_FILTER_MAC:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_MAC; break;\n\tcase QED_FILTER_VLAN:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_VLAN; break;\n\tcase QED_FILTER_MAC_VLAN:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_PAIR; break;\n\tcase QED_FILTER_INNER_MAC:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_INNER_MAC; break;\n\tcase QED_FILTER_INNER_VLAN:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_INNER_VLAN; break;\n\tcase QED_FILTER_INNER_PAIR:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_INNER_PAIR; break;\n\tcase QED_FILTER_INNER_MAC_VNI_PAIR:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_INNER_MAC_VNI_PAIR;\n\t\tbreak;\n\tcase QED_FILTER_MAC_VNI_PAIR:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_MAC_VNI_PAIR; break;\n\tcase QED_FILTER_VNI:\n\t\tp_first_filter->type = ETH_FILTER_TYPE_VNI; break;\n\t}\n\n\tif ((p_first_filter->type == ETH_FILTER_TYPE_MAC) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_PAIR) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_INNER_MAC) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_INNER_PAIR) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_INNER_MAC_VNI_PAIR) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_MAC_VNI_PAIR)) {\n\t\tqed_set_fw_mac_addr(&p_first_filter->mac_msb,\n\t\t\t\t    &p_first_filter->mac_mid,\n\t\t\t\t    &p_first_filter->mac_lsb,\n\t\t\t\t    (u8 *)p_filter_cmd->mac);\n\t}\n\n\tif ((p_first_filter->type == ETH_FILTER_TYPE_VLAN) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_PAIR) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_INNER_VLAN) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_INNER_PAIR))\n\t\tp_first_filter->vlan_id = cpu_to_le16(p_filter_cmd->vlan);\n\n\tif ((p_first_filter->type == ETH_FILTER_TYPE_INNER_MAC_VNI_PAIR) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_MAC_VNI_PAIR) ||\n\t    (p_first_filter->type == ETH_FILTER_TYPE_VNI))\n\t\tp_first_filter->vni = cpu_to_le32(p_filter_cmd->vni);\n\n\tif (p_filter_cmd->opcode == QED_FILTER_MOVE) {\n\t\tp_second_filter->type = p_first_filter->type;\n\t\tp_second_filter->mac_msb = p_first_filter->mac_msb;\n\t\tp_second_filter->mac_mid = p_first_filter->mac_mid;\n\t\tp_second_filter->mac_lsb = p_first_filter->mac_lsb;\n\t\tp_second_filter->vlan_id = p_first_filter->vlan_id;\n\t\tp_second_filter->vni = p_first_filter->vni;\n\n\t\tp_first_filter->action = ETH_FILTER_ACTION_REMOVE;\n\n\t\tp_first_filter->vport_id = vport_to_remove_from;\n\n\t\tp_second_filter->action = ETH_FILTER_ACTION_ADD;\n\t\tp_second_filter->vport_id = vport_to_add_to;\n\t} else if (p_filter_cmd->opcode == QED_FILTER_REPLACE) {\n\t\tp_first_filter->vport_id = vport_to_add_to;\n\t\tmemcpy(p_second_filter, p_first_filter,\n\t\t       sizeof(*p_second_filter));\n\t\tp_first_filter->action\t= ETH_FILTER_ACTION_REMOVE_ALL;\n\t\tp_second_filter->action = ETH_FILTER_ACTION_ADD;\n\t} else {\n\t\taction = qed_filter_action(p_filter_cmd->opcode);\n\n\t\tif (action == MAX_ETH_FILTER_ACTION) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"%d is not supported yet\\n\",\n\t\t\t\t  p_filter_cmd->opcode);\n\t\t\tqed_sp_destroy_request(p_hwfn, *pp_ent);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tp_first_filter->action = action;\n\t\tp_first_filter->vport_id = (p_filter_cmd->opcode ==\n\t\t\t\t\t    QED_FILTER_REMOVE) ?\n\t\t\t\t\t   vport_to_remove_from :\n\t\t\t\t\t   vport_to_add_to;\n\t}\n\n\treturn 0;\n}\n\nint qed_sp_eth_filter_ucast(struct qed_hwfn *p_hwfn,\n\t\t\t    u16 opaque_fid,\n\t\t\t    struct qed_filter_ucast *p_filter_cmd,\n\t\t\t    enum spq_mode comp_mode,\n\t\t\t    struct qed_spq_comp_cb *p_comp_data)\n{\n\tstruct vport_filter_update_ramrod_data\t*p_ramrod\t= NULL;\n\tstruct qed_spq_entry\t\t\t*p_ent\t\t= NULL;\n\tstruct eth_filter_cmd_header\t\t*p_header;\n\tint\t\t\t\t\trc;\n\n\trc = qed_filter_ucast_common(p_hwfn, opaque_fid, p_filter_cmd,\n\t\t\t\t     &p_ramrod, &p_ent,\n\t\t\t\t     comp_mode, p_comp_data);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"Uni. filter command failed %d\\n\", rc);\n\t\treturn rc;\n\t}\n\tp_header = &p_ramrod->filter_cmd_hdr;\n\tp_header->assert_on_error = p_filter_cmd->assert_on_error;\n\n\trc = qed_spq_post(p_hwfn, p_ent, NULL);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"Unicast filter ADD command failed %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"Unicast filter configured, opcode = %s, type = %s, cmd_cnt = %d, is_rx_filter = %d, is_tx_filter = %d\\n\",\n\t\t   (p_filter_cmd->opcode == QED_FILTER_ADD) ? \"ADD\" :\n\t\t   ((p_filter_cmd->opcode == QED_FILTER_REMOVE) ?\n\t\t   \"REMOVE\" :\n\t\t   ((p_filter_cmd->opcode == QED_FILTER_MOVE) ?\n\t\t    \"MOVE\" : \"REPLACE\")),\n\t\t   (p_filter_cmd->type == QED_FILTER_MAC) ? \"MAC\" :\n\t\t   ((p_filter_cmd->type == QED_FILTER_VLAN) ?\n\t\t    \"VLAN\" : \"MAC & VLAN\"),\n\t\t   p_ramrod->filter_cmd_hdr.cmd_cnt,\n\t\t   p_filter_cmd->is_rx_filter,\n\t\t   p_filter_cmd->is_tx_filter);\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"vport_to_add_to = %d, vport_to_remove_from = %d, mac = %2x:%2x:%2x:%2x:%2x:%2x, vlan = %d\\n\",\n\t\t   p_filter_cmd->vport_to_add_to,\n\t\t   p_filter_cmd->vport_to_remove_from,\n\t\t   p_filter_cmd->mac[0],\n\t\t   p_filter_cmd->mac[1],\n\t\t   p_filter_cmd->mac[2],\n\t\t   p_filter_cmd->mac[3],\n\t\t   p_filter_cmd->mac[4],\n\t\t   p_filter_cmd->mac[5],\n\t\t   p_filter_cmd->vlan);\n\n\treturn 0;\n}\n\n \nstatic u32 qed_calc_crc32c(u8 *crc32_packet,\n\t\t\t   u32 crc32_length, u32 crc32_seed, u8 complement)\n{\n\tu32 byte = 0, bit = 0, crc32_result = crc32_seed;\n\tu8 msb = 0, current_byte = 0;\n\n\tif ((!crc32_packet) ||\n\t    (crc32_length == 0) ||\n\t    ((crc32_length % 8) != 0))\n\t\treturn crc32_result;\n\tfor (byte = 0; byte < crc32_length; byte++) {\n\t\tcurrent_byte = crc32_packet[byte];\n\t\tfor (bit = 0; bit < 8; bit++) {\n\t\t\tmsb = (u8)(crc32_result >> 31);\n\t\t\tcrc32_result = crc32_result << 1;\n\t\t\tif (msb != (0x1 & (current_byte >> bit))) {\n\t\t\t\tcrc32_result = crc32_result ^ CRC32_POLY;\n\t\t\t\tcrc32_result |= 1;  \n\t\t\t}\n\t\t}\n\t}\n\treturn crc32_result;\n}\n\nstatic u32 qed_crc32c_le(u32 seed, u8 *mac, u32 len)\n{\n\tu32 packet_buf[2] = { 0 };\n\n\tmemcpy((u8 *)(&packet_buf[0]), &mac[0], 6);\n\treturn qed_calc_crc32c((u8 *)packet_buf, 8, seed, 0);\n}\n\nu8 qed_mcast_bin_from_mac(u8 *mac)\n{\n\tu32 crc = qed_crc32c_le(ETH_MULTICAST_BIN_FROM_MAC_SEED,\n\t\t\t\tmac, ETH_ALEN);\n\n\treturn crc & 0xff;\n}\n\nstatic int\nqed_sp_eth_filter_mcast(struct qed_hwfn *p_hwfn,\n\t\t\tu16 opaque_fid,\n\t\t\tstruct qed_filter_mcast *p_filter_cmd,\n\t\t\tenum spq_mode comp_mode,\n\t\t\tstruct qed_spq_comp_cb *p_comp_data)\n{\n\tstruct vport_update_ramrod_data *p_ramrod = NULL;\n\tu32 bins[ETH_MULTICAST_MAC_BINS_IN_REGS];\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tu8 abs_vport_id = 0;\n\tint rc, i;\n\n\tif (p_filter_cmd->opcode == QED_FILTER_ADD)\n\t\trc = qed_fw_vport(p_hwfn, p_filter_cmd->vport_to_add_to,\n\t\t\t\t  &abs_vport_id);\n\telse\n\t\trc = qed_fw_vport(p_hwfn, p_filter_cmd->vport_to_remove_from,\n\t\t\t\t  &abs_vport_id);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\tinit_data.comp_mode = comp_mode;\n\tinit_data.p_comp_data = p_comp_data;\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_VPORT_UPDATE,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"Multi-cast command failed %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\tp_ramrod = &p_ent->ramrod.vport_update;\n\tp_ramrod->common.update_approx_mcast_flg = 1;\n\n\t \n\tmemset(&p_ramrod->approx_mcast.bins, 0,\n\t       sizeof(p_ramrod->approx_mcast.bins));\n\tmemset(bins, 0, sizeof(bins));\n\t \n\tif (p_filter_cmd->opcode == QED_FILTER_ADD) {\n\t\tfor (i = 0; i < p_filter_cmd->num_mc_addrs; i++) {\n\t\t\tu32 bit, nbits;\n\n\t\t\tbit = qed_mcast_bin_from_mac(p_filter_cmd->mac[i]);\n\t\t\tnbits = sizeof(u32) * BITS_PER_BYTE;\n\t\t\tbins[bit / nbits] |= 1 << (bit % nbits);\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < ETH_MULTICAST_MAC_BINS_IN_REGS; i++) {\n\t\t\tstruct vport_update_ramrod_mcast *p_ramrod_bins;\n\n\t\t\tp_ramrod_bins = &p_ramrod->approx_mcast;\n\t\t\tp_ramrod_bins->bins[i] = cpu_to_le32(bins[i]);\n\t\t}\n\t}\n\n\tp_ramrod->common.vport_id = abs_vport_id;\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n}\n\nstatic int qed_filter_mcast_cmd(struct qed_dev *cdev,\n\t\t\t\tstruct qed_filter_mcast *p_filter_cmd,\n\t\t\t\tenum spq_mode comp_mode,\n\t\t\t\tstruct qed_spq_comp_cb *p_comp_data)\n{\n\tint rc = 0;\n\tint i;\n\n\t \n\tif ((p_filter_cmd->opcode != QED_FILTER_ADD &&\n\t     (p_filter_cmd->opcode != QED_FILTER_REMOVE)) ||\n\t    (p_filter_cmd->num_mc_addrs > QED_MAX_MC_ADDRS))\n\t\treturn -EINVAL;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tu16 opaque_fid;\n\n\t\tif (IS_VF(cdev)) {\n\t\t\tqed_vf_pf_filter_mcast(p_hwfn, p_filter_cmd);\n\t\t\tcontinue;\n\t\t}\n\n\t\topaque_fid = p_hwfn->hw_info.opaque_fid;\n\n\t\trc = qed_sp_eth_filter_mcast(p_hwfn,\n\t\t\t\t\t     opaque_fid,\n\t\t\t\t\t     p_filter_cmd,\n\t\t\t\t\t     comp_mode, p_comp_data);\n\t}\n\treturn rc;\n}\n\nstatic int qed_filter_ucast_cmd(struct qed_dev *cdev,\n\t\t\t\tstruct qed_filter_ucast *p_filter_cmd,\n\t\t\t\tenum spq_mode comp_mode,\n\t\t\t\tstruct qed_spq_comp_cb *p_comp_data)\n{\n\tint rc = 0;\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tu16 opaque_fid;\n\n\t\tif (IS_VF(cdev)) {\n\t\t\trc = qed_vf_pf_filter_ucast(p_hwfn, p_filter_cmd);\n\t\t\tcontinue;\n\t\t}\n\n\t\topaque_fid = p_hwfn->hw_info.opaque_fid;\n\n\t\trc = qed_sp_eth_filter_ucast(p_hwfn,\n\t\t\t\t\t     opaque_fid,\n\t\t\t\t\t     p_filter_cmd,\n\t\t\t\t\t     comp_mode, p_comp_data);\n\t\tif (rc)\n\t\t\tbreak;\n\t}\n\n\treturn rc;\n}\n\n \nstatic void __qed_get_vport_pstats_addrlen(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t   u32 *p_addr,\n\t\t\t\t\t   u32 *p_len, u16 statistics_bin)\n{\n\tif (IS_PF(p_hwfn->cdev)) {\n\t\t*p_addr = BAR0_MAP_REG_PSDM_RAM +\n\t\t    PSTORM_QUEUE_STAT_OFFSET(statistics_bin);\n\t\t*p_len = sizeof(struct eth_pstorm_per_queue_stat);\n\t} else {\n\t\tstruct qed_vf_iov *p_iov = p_hwfn->vf_iov_info;\n\t\tstruct pfvf_acquire_resp_tlv *p_resp = &p_iov->acquire_resp;\n\n\t\t*p_addr = p_resp->pfdev_info.stats_info.pstats.address;\n\t\t*p_len = p_resp->pfdev_info.stats_info.pstats.len;\n\t}\n}\n\nstatic noinline_for_stack void\n__qed_get_vport_pstats(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t       struct qed_eth_stats *p_stats, u16 statistics_bin)\n{\n\tstruct eth_pstorm_per_queue_stat pstats;\n\tu32 pstats_addr = 0, pstats_len = 0;\n\n\t__qed_get_vport_pstats_addrlen(p_hwfn, &pstats_addr, &pstats_len,\n\t\t\t\t       statistics_bin);\n\n\tmemset(&pstats, 0, sizeof(pstats));\n\tqed_memcpy_from(p_hwfn, p_ptt, &pstats, pstats_addr, pstats_len);\n\n\tp_stats->common.tx_ucast_bytes +=\n\t    HILO_64_REGPAIR(pstats.sent_ucast_bytes);\n\tp_stats->common.tx_mcast_bytes +=\n\t    HILO_64_REGPAIR(pstats.sent_mcast_bytes);\n\tp_stats->common.tx_bcast_bytes +=\n\t    HILO_64_REGPAIR(pstats.sent_bcast_bytes);\n\tp_stats->common.tx_ucast_pkts +=\n\t    HILO_64_REGPAIR(pstats.sent_ucast_pkts);\n\tp_stats->common.tx_mcast_pkts +=\n\t    HILO_64_REGPAIR(pstats.sent_mcast_pkts);\n\tp_stats->common.tx_bcast_pkts +=\n\t    HILO_64_REGPAIR(pstats.sent_bcast_pkts);\n\tp_stats->common.tx_err_drop_pkts +=\n\t    HILO_64_REGPAIR(pstats.error_drop_pkts);\n}\n\nstatic noinline_for_stack void\n__qed_get_vport_tstats(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t       struct qed_eth_stats *p_stats, u16 statistics_bin)\n{\n\tstruct tstorm_per_port_stat tstats;\n\tu32 tstats_addr, tstats_len;\n\n\tif (IS_PF(p_hwfn->cdev)) {\n\t\ttstats_addr = BAR0_MAP_REG_TSDM_RAM +\n\t\t    TSTORM_PORT_STAT_OFFSET(MFW_PORT(p_hwfn));\n\t\ttstats_len = sizeof(struct tstorm_per_port_stat);\n\t} else {\n\t\tstruct qed_vf_iov *p_iov = p_hwfn->vf_iov_info;\n\t\tstruct pfvf_acquire_resp_tlv *p_resp = &p_iov->acquire_resp;\n\n\t\ttstats_addr = p_resp->pfdev_info.stats_info.tstats.address;\n\t\ttstats_len = p_resp->pfdev_info.stats_info.tstats.len;\n\t}\n\n\tmemset(&tstats, 0, sizeof(tstats));\n\tqed_memcpy_from(p_hwfn, p_ptt, &tstats, tstats_addr, tstats_len);\n\n\tp_stats->common.mftag_filter_discards +=\n\t    HILO_64_REGPAIR(tstats.mftag_filter_discard);\n\tp_stats->common.mac_filter_discards +=\n\t    HILO_64_REGPAIR(tstats.eth_mac_filter_discard);\n\tp_stats->common.gft_filter_drop +=\n\t\tHILO_64_REGPAIR(tstats.eth_gft_drop_pkt);\n}\n\nstatic void __qed_get_vport_ustats_addrlen(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t   u32 *p_addr,\n\t\t\t\t\t   u32 *p_len, u16 statistics_bin)\n{\n\tif (IS_PF(p_hwfn->cdev)) {\n\t\t*p_addr = BAR0_MAP_REG_USDM_RAM +\n\t\t    USTORM_QUEUE_STAT_OFFSET(statistics_bin);\n\t\t*p_len = sizeof(struct eth_ustorm_per_queue_stat);\n\t} else {\n\t\tstruct qed_vf_iov *p_iov = p_hwfn->vf_iov_info;\n\t\tstruct pfvf_acquire_resp_tlv *p_resp = &p_iov->acquire_resp;\n\n\t\t*p_addr = p_resp->pfdev_info.stats_info.ustats.address;\n\t\t*p_len = p_resp->pfdev_info.stats_info.ustats.len;\n\t}\n}\n\nstatic noinline_for_stack\nvoid __qed_get_vport_ustats(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t\t    struct qed_eth_stats *p_stats, u16 statistics_bin)\n{\n\tstruct eth_ustorm_per_queue_stat ustats;\n\tu32 ustats_addr = 0, ustats_len = 0;\n\n\t__qed_get_vport_ustats_addrlen(p_hwfn, &ustats_addr, &ustats_len,\n\t\t\t\t       statistics_bin);\n\n\tmemset(&ustats, 0, sizeof(ustats));\n\tqed_memcpy_from(p_hwfn, p_ptt, &ustats, ustats_addr, ustats_len);\n\n\tp_stats->common.rx_ucast_bytes +=\n\t    HILO_64_REGPAIR(ustats.rcv_ucast_bytes);\n\tp_stats->common.rx_mcast_bytes +=\n\t    HILO_64_REGPAIR(ustats.rcv_mcast_bytes);\n\tp_stats->common.rx_bcast_bytes +=\n\t    HILO_64_REGPAIR(ustats.rcv_bcast_bytes);\n\tp_stats->common.rx_ucast_pkts += HILO_64_REGPAIR(ustats.rcv_ucast_pkts);\n\tp_stats->common.rx_mcast_pkts += HILO_64_REGPAIR(ustats.rcv_mcast_pkts);\n\tp_stats->common.rx_bcast_pkts += HILO_64_REGPAIR(ustats.rcv_bcast_pkts);\n}\n\nstatic void __qed_get_vport_mstats_addrlen(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t   u32 *p_addr,\n\t\t\t\t\t   u32 *p_len, u16 statistics_bin)\n{\n\tif (IS_PF(p_hwfn->cdev)) {\n\t\t*p_addr = BAR0_MAP_REG_MSDM_RAM +\n\t\t    MSTORM_QUEUE_STAT_OFFSET(statistics_bin);\n\t\t*p_len = sizeof(struct eth_mstorm_per_queue_stat);\n\t} else {\n\t\tstruct qed_vf_iov *p_iov = p_hwfn->vf_iov_info;\n\t\tstruct pfvf_acquire_resp_tlv *p_resp = &p_iov->acquire_resp;\n\n\t\t*p_addr = p_resp->pfdev_info.stats_info.mstats.address;\n\t\t*p_len = p_resp->pfdev_info.stats_info.mstats.len;\n\t}\n}\n\nstatic noinline_for_stack void\n__qed_get_vport_mstats(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t       struct qed_eth_stats *p_stats, u16 statistics_bin)\n{\n\tstruct eth_mstorm_per_queue_stat mstats;\n\tu32 mstats_addr = 0, mstats_len = 0;\n\n\t__qed_get_vport_mstats_addrlen(p_hwfn, &mstats_addr, &mstats_len,\n\t\t\t\t       statistics_bin);\n\n\tmemset(&mstats, 0, sizeof(mstats));\n\tqed_memcpy_from(p_hwfn, p_ptt, &mstats, mstats_addr, mstats_len);\n\n\tp_stats->common.no_buff_discards +=\n\t    HILO_64_REGPAIR(mstats.no_buff_discard);\n\tp_stats->common.packet_too_big_discard +=\n\t    HILO_64_REGPAIR(mstats.packet_too_big_discard);\n\tp_stats->common.ttl0_discard += HILO_64_REGPAIR(mstats.ttl0_discard);\n\tp_stats->common.tpa_coalesced_pkts +=\n\t    HILO_64_REGPAIR(mstats.tpa_coalesced_pkts);\n\tp_stats->common.tpa_coalesced_events +=\n\t    HILO_64_REGPAIR(mstats.tpa_coalesced_events);\n\tp_stats->common.tpa_aborts_num +=\n\t    HILO_64_REGPAIR(mstats.tpa_aborts_num);\n\tp_stats->common.tpa_coalesced_bytes +=\n\t    HILO_64_REGPAIR(mstats.tpa_coalesced_bytes);\n}\n\nstatic noinline_for_stack void\n__qed_get_vport_port_stats(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t\t   struct qed_eth_stats *p_stats)\n{\n\tstruct qed_eth_stats_common *p_common = &p_stats->common;\n\tstruct port_stats port_stats;\n\tint j;\n\n\tmemset(&port_stats, 0, sizeof(port_stats));\n\n\tqed_memcpy_from(p_hwfn, p_ptt, &port_stats,\n\t\t\tp_hwfn->mcp_info->port_addr +\n\t\t\toffsetof(struct public_port, stats),\n\t\t\tsizeof(port_stats));\n\n\tp_common->rx_64_byte_packets += port_stats.eth.r64;\n\tp_common->rx_65_to_127_byte_packets += port_stats.eth.r127;\n\tp_common->rx_128_to_255_byte_packets += port_stats.eth.r255;\n\tp_common->rx_256_to_511_byte_packets += port_stats.eth.r511;\n\tp_common->rx_512_to_1023_byte_packets += port_stats.eth.r1023;\n\tp_common->rx_1024_to_1518_byte_packets += port_stats.eth.r1518;\n\tp_common->rx_crc_errors += port_stats.eth.rfcs;\n\tp_common->rx_mac_crtl_frames += port_stats.eth.rxcf;\n\tp_common->rx_pause_frames += port_stats.eth.rxpf;\n\tp_common->rx_pfc_frames += port_stats.eth.rxpp;\n\tp_common->rx_align_errors += port_stats.eth.raln;\n\tp_common->rx_carrier_errors += port_stats.eth.rfcr;\n\tp_common->rx_oversize_packets += port_stats.eth.rovr;\n\tp_common->rx_jabbers += port_stats.eth.rjbr;\n\tp_common->rx_undersize_packets += port_stats.eth.rund;\n\tp_common->rx_fragments += port_stats.eth.rfrg;\n\tp_common->tx_64_byte_packets += port_stats.eth.t64;\n\tp_common->tx_65_to_127_byte_packets += port_stats.eth.t127;\n\tp_common->tx_128_to_255_byte_packets += port_stats.eth.t255;\n\tp_common->tx_256_to_511_byte_packets += port_stats.eth.t511;\n\tp_common->tx_512_to_1023_byte_packets += port_stats.eth.t1023;\n\tp_common->tx_1024_to_1518_byte_packets += port_stats.eth.t1518;\n\tp_common->tx_pause_frames += port_stats.eth.txpf;\n\tp_common->tx_pfc_frames += port_stats.eth.txpp;\n\tp_common->rx_mac_bytes += port_stats.eth.rbyte;\n\tp_common->rx_mac_uc_packets += port_stats.eth.rxuca;\n\tp_common->rx_mac_mc_packets += port_stats.eth.rxmca;\n\tp_common->rx_mac_bc_packets += port_stats.eth.rxbca;\n\tp_common->rx_mac_frames_ok += port_stats.eth.rxpok;\n\tp_common->tx_mac_bytes += port_stats.eth.tbyte;\n\tp_common->tx_mac_uc_packets += port_stats.eth.txuca;\n\tp_common->tx_mac_mc_packets += port_stats.eth.txmca;\n\tp_common->tx_mac_bc_packets += port_stats.eth.txbca;\n\tp_common->tx_mac_ctrl_frames += port_stats.eth.txcf;\n\tfor (j = 0; j < 8; j++) {\n\t\tp_common->brb_truncates += port_stats.brb.brb_truncate[j];\n\t\tp_common->brb_discards += port_stats.brb.brb_discard[j];\n\t}\n\n\tif (QED_IS_BB(p_hwfn->cdev)) {\n\t\tstruct qed_eth_stats_bb *p_bb = &p_stats->bb;\n\n\t\tp_bb->rx_1519_to_1522_byte_packets +=\n\t\t    port_stats.eth.u0.bb0.r1522;\n\t\tp_bb->rx_1519_to_2047_byte_packets +=\n\t\t    port_stats.eth.u0.bb0.r2047;\n\t\tp_bb->rx_2048_to_4095_byte_packets +=\n\t\t    port_stats.eth.u0.bb0.r4095;\n\t\tp_bb->rx_4096_to_9216_byte_packets +=\n\t\t    port_stats.eth.u0.bb0.r9216;\n\t\tp_bb->rx_9217_to_16383_byte_packets +=\n\t\t    port_stats.eth.u0.bb0.r16383;\n\t\tp_bb->tx_1519_to_2047_byte_packets +=\n\t\t    port_stats.eth.u1.bb1.t2047;\n\t\tp_bb->tx_2048_to_4095_byte_packets +=\n\t\t    port_stats.eth.u1.bb1.t4095;\n\t\tp_bb->tx_4096_to_9216_byte_packets +=\n\t\t    port_stats.eth.u1.bb1.t9216;\n\t\tp_bb->tx_9217_to_16383_byte_packets +=\n\t\t    port_stats.eth.u1.bb1.t16383;\n\t\tp_bb->tx_lpi_entry_count += port_stats.eth.u2.bb2.tlpiec;\n\t\tp_bb->tx_total_collisions += port_stats.eth.u2.bb2.tncl;\n\t} else {\n\t\tstruct qed_eth_stats_ah *p_ah = &p_stats->ah;\n\n\t\tp_ah->rx_1519_to_max_byte_packets +=\n\t\t    port_stats.eth.u0.ah0.r1519_to_max;\n\t\tp_ah->tx_1519_to_max_byte_packets =\n\t\t    port_stats.eth.u1.ah1.t1519_to_max;\n\t}\n\n\tp_common->link_change_count = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t     p_hwfn->mcp_info->port_addr +\n\t\t\t\t\t     offsetof(struct public_port,\n\t\t\t\t\t\t      link_change_count));\n}\n\nstatic void __qed_get_vport_stats(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t\t  struct qed_eth_stats *stats,\n\t\t\t\t  u16 statistics_bin, bool b_get_port_stats)\n{\n\t__qed_get_vport_mstats(p_hwfn, p_ptt, stats, statistics_bin);\n\t__qed_get_vport_ustats(p_hwfn, p_ptt, stats, statistics_bin);\n\t__qed_get_vport_tstats(p_hwfn, p_ptt, stats, statistics_bin);\n\t__qed_get_vport_pstats(p_hwfn, p_ptt, stats, statistics_bin);\n\n\tif (b_get_port_stats && p_hwfn->mcp_info)\n\t\t__qed_get_vport_port_stats(p_hwfn, p_ptt, stats);\n}\n\nstatic void _qed_get_vport_stats(struct qed_dev *cdev,\n\t\t\t\t struct qed_eth_stats *stats,\n\t\t\t\t bool is_atomic)\n{\n\tu8 fw_vport = 0;\n\tint i;\n\n\tmemset(stats, 0, sizeof(*stats));\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tstruct qed_ptt *p_ptt;\n\t\tbool b_get_port_stats;\n\n\t\tp_ptt = IS_PF(cdev) ? qed_ptt_acquire_context(p_hwfn, is_atomic)\n\t\t\t\t    : NULL;\n\t\tif (IS_PF(cdev)) {\n\t\t\t \n\t\t\tif (qed_fw_vport(p_hwfn, 0, &fw_vport)) {\n\t\t\t\tDP_ERR(p_hwfn, \"No vport available!\\n\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tif (IS_PF(cdev) && !p_ptt) {\n\t\t\tDP_ERR(p_hwfn, \"Failed to acquire ptt\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tb_get_port_stats = IS_PF(cdev) && IS_LEAD_HWFN(p_hwfn);\n\t\t__qed_get_vport_stats(p_hwfn, p_ptt, stats, fw_vport,\n\t\t\t\t      b_get_port_stats);\n\nout:\n\t\tif (IS_PF(cdev) && p_ptt)\n\t\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t}\n}\n\nvoid qed_get_vport_stats(struct qed_dev *cdev, struct qed_eth_stats *stats)\n{\n\tqed_get_vport_stats_context(cdev, stats, false);\n}\n\nvoid qed_get_vport_stats_context(struct qed_dev *cdev,\n\t\t\t\t struct qed_eth_stats *stats,\n\t\t\t\t bool is_atomic)\n{\n\tu32 i;\n\n\tif (!cdev || cdev->recov_in_prog) {\n\t\tmemset(stats, 0, sizeof(*stats));\n\t\treturn;\n\t}\n\n\t_qed_get_vport_stats(cdev, stats, is_atomic);\n\n\tif (!cdev->reset_stats)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < sizeof(struct qed_eth_stats) / sizeof(u64); i++)\n\t\t((u64 *)stats)[i] -= ((u64 *)cdev->reset_stats)[i];\n}\n\n \nvoid qed_reset_vport_stats(struct qed_dev *cdev)\n{\n\tint i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\tstruct eth_mstorm_per_queue_stat mstats;\n\t\tstruct eth_ustorm_per_queue_stat ustats;\n\t\tstruct eth_pstorm_per_queue_stat pstats;\n\t\tstruct qed_ptt *p_ptt = IS_PF(cdev) ? qed_ptt_acquire(p_hwfn)\n\t\t\t\t\t\t    : NULL;\n\t\tu32 addr = 0, len = 0;\n\n\t\tif (IS_PF(cdev) && !p_ptt) {\n\t\t\tDP_ERR(p_hwfn, \"Failed to acquire ptt\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tmemset(&mstats, 0, sizeof(mstats));\n\t\t__qed_get_vport_mstats_addrlen(p_hwfn, &addr, &len, 0);\n\t\tqed_memcpy_to(p_hwfn, p_ptt, addr, &mstats, len);\n\n\t\tmemset(&ustats, 0, sizeof(ustats));\n\t\t__qed_get_vport_ustats_addrlen(p_hwfn, &addr, &len, 0);\n\t\tqed_memcpy_to(p_hwfn, p_ptt, addr, &ustats, len);\n\n\t\tmemset(&pstats, 0, sizeof(pstats));\n\t\t__qed_get_vport_pstats_addrlen(p_hwfn, &addr, &len, 0);\n\t\tqed_memcpy_to(p_hwfn, p_ptt, addr, &pstats, len);\n\n\t\tif (IS_PF(cdev))\n\t\t\tqed_ptt_release(p_hwfn, p_ptt);\n\t}\n\n\t \n\tif (!cdev->reset_stats) {\n\t\tDP_INFO(cdev, \"Reset stats not allocated\\n\");\n\t} else {\n\t\t_qed_get_vport_stats(cdev, cdev->reset_stats, false);\n\t\tcdev->reset_stats->common.link_change_count = 0;\n\t}\n}\n\nstatic enum gft_profile_type\nqed_arfs_mode_to_hsi(enum qed_filter_config_mode mode)\n{\n\tif (mode == QED_FILTER_CONFIG_MODE_5_TUPLE)\n\t\treturn GFT_PROFILE_TYPE_4_TUPLE;\n\tif (mode == QED_FILTER_CONFIG_MODE_IP_DEST)\n\t\treturn GFT_PROFILE_TYPE_IP_DST_ADDR;\n\tif (mode == QED_FILTER_CONFIG_MODE_IP_SRC)\n\t\treturn GFT_PROFILE_TYPE_IP_SRC_ADDR;\n\treturn GFT_PROFILE_TYPE_L4_DST_PORT;\n}\n\nvoid qed_arfs_mode_configure(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t     struct qed_arfs_config_params *p_cfg_params)\n{\n\tif (test_bit(QED_MF_DISABLE_ARFS, &p_hwfn->cdev->mf_bits))\n\t\treturn;\n\n\tif (p_cfg_params->mode != QED_FILTER_CONFIG_MODE_DISABLE) {\n\t\tqed_gft_config(p_hwfn, p_ptt, p_hwfn->rel_pf_id,\n\t\t\t       p_cfg_params->tcp,\n\t\t\t       p_cfg_params->udp,\n\t\t\t       p_cfg_params->ipv4,\n\t\t\t       p_cfg_params->ipv6,\n\t\t\t       qed_arfs_mode_to_hsi(p_cfg_params->mode));\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_SP,\n\t\t\t   \"Configured Filtering: tcp = %s, udp = %s, ipv4 = %s, ipv6 =%s mode=%08x\\n\",\n\t\t\t   p_cfg_params->tcp ? \"Enable\" : \"Disable\",\n\t\t\t   p_cfg_params->udp ? \"Enable\" : \"Disable\",\n\t\t\t   p_cfg_params->ipv4 ? \"Enable\" : \"Disable\",\n\t\t\t   p_cfg_params->ipv6 ? \"Enable\" : \"Disable\",\n\t\t\t   (u32)p_cfg_params->mode);\n\t} else {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP, \"Disabled Filtering\\n\");\n\t\tqed_gft_disable(p_hwfn, p_ptt, p_hwfn->rel_pf_id);\n\t}\n}\n\nint\nqed_configure_rfs_ntuple_filter(struct qed_hwfn *p_hwfn,\n\t\t\t\tstruct qed_spq_comp_cb *p_cb,\n\t\t\t\tstruct qed_ntuple_filter_params *p_params)\n{\n\tstruct rx_update_gft_filter_ramrod_data *p_ramrod = NULL;\n\tstruct qed_spq_entry *p_ent = NULL;\n\tstruct qed_sp_init_data init_data;\n\tu16 abs_rx_q_id = 0;\n\tu8 abs_vport_id = 0;\n\tint rc = -EINVAL;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tinit_data.cid = qed_spq_get_cid(p_hwfn);\n\n\tinit_data.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\n\tif (p_cb) {\n\t\tinit_data.comp_mode = QED_SPQ_MODE_CB;\n\t\tinit_data.p_comp_data = p_cb;\n\t} else {\n\t\tinit_data.comp_mode = QED_SPQ_MODE_EBLOCK;\n\t}\n\n\trc = qed_sp_init_request(p_hwfn, &p_ent,\n\t\t\t\t ETH_RAMROD_RX_UPDATE_GFT_FILTER,\n\t\t\t\t PROTOCOLID_ETH, &init_data);\n\tif (rc)\n\t\treturn rc;\n\n\tp_ramrod = &p_ent->ramrod.rx_update_gft;\n\n\tDMA_REGPAIR_LE(p_ramrod->pkt_hdr_addr, p_params->addr);\n\tp_ramrod->pkt_hdr_length = cpu_to_le16(p_params->length);\n\n\tif (p_params->b_is_drop) {\n\t\tp_ramrod->vport_id = cpu_to_le16(ETH_GFT_TRASHCAN_VPORT);\n\t} else {\n\t\trc = qed_fw_vport(p_hwfn, p_params->vport_id, &abs_vport_id);\n\t\tif (rc)\n\t\t\tgoto err;\n\n\t\tif (p_params->qid != QED_RFS_NTUPLE_QID_RSS) {\n\t\t\trc = qed_fw_l2_queue(p_hwfn, p_params->qid,\n\t\t\t\t\t     &abs_rx_q_id);\n\t\t\tif (rc)\n\t\t\t\tgoto err;\n\n\t\t\tp_ramrod->rx_qid_valid = 1;\n\t\t\tp_ramrod->rx_qid = cpu_to_le16(abs_rx_q_id);\n\t\t}\n\n\t\tp_ramrod->vport_id = cpu_to_le16((u16)abs_vport_id);\n\t}\n\n\tp_ramrod->flow_id_valid = 0;\n\tp_ramrod->flow_id = 0;\n\tp_ramrod->filter_action = p_params->b_is_add ? GFT_ADD_FILTER\n\t    : GFT_DELETE_FILTER;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"V[%0x], Q[%04x] - %s filter from 0x%llx [length %04xb]\\n\",\n\t\t   abs_vport_id, abs_rx_q_id,\n\t\t   p_params->b_is_add ? \"Adding\" : \"Removing\",\n\t\t   (u64)p_params->addr, p_params->length);\n\n\treturn qed_spq_post(p_hwfn, p_ent, NULL);\n\nerr:\n\tqed_sp_destroy_request(p_hwfn, p_ent);\n\treturn rc;\n}\n\nint qed_get_rxq_coalesce(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_ptt *p_ptt,\n\t\t\t struct qed_queue_cid *p_cid, u16 *p_rx_coal)\n{\n\tu32 coalesce, address, is_valid;\n\tstruct cau_sb_entry sb_entry;\n\tu8 timer_res;\n\tint rc;\n\n\trc = qed_dmae_grc2host(p_hwfn, p_ptt, CAU_REG_SB_VAR_MEMORY +\n\t\t\t       p_cid->sb_igu_id * sizeof(u64),\n\t\t\t       (u64)(uintptr_t)&sb_entry, 2, NULL);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"dmae_grc2host failed %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\ttimer_res = GET_FIELD(le32_to_cpu(sb_entry.params),\n\t\t\t      CAU_SB_ENTRY_TIMER_RES0);\n\n\taddress = BAR0_MAP_REG_USDM_RAM +\n\t\t  USTORM_ETH_QUEUE_ZONE_GTT_OFFSET(p_cid->abs.queue_id);\n\tcoalesce = qed_rd(p_hwfn, p_ptt, address);\n\n\tis_valid = GET_FIELD(coalesce, COALESCING_TIMESET_VALID);\n\tif (!is_valid)\n\t\treturn -EINVAL;\n\n\tcoalesce = GET_FIELD(coalesce, COALESCING_TIMESET_TIMESET);\n\t*p_rx_coal = (u16)(coalesce << timer_res);\n\n\treturn 0;\n}\n\nint qed_get_txq_coalesce(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_ptt *p_ptt,\n\t\t\t struct qed_queue_cid *p_cid, u16 *p_tx_coal)\n{\n\tu32 coalesce, address, is_valid;\n\tstruct cau_sb_entry sb_entry;\n\tu8 timer_res;\n\tint rc;\n\n\trc = qed_dmae_grc2host(p_hwfn, p_ptt, CAU_REG_SB_VAR_MEMORY +\n\t\t\t       p_cid->sb_igu_id * sizeof(u64),\n\t\t\t       (u64)(uintptr_t)&sb_entry, 2, NULL);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"dmae_grc2host failed %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\ttimer_res = GET_FIELD(le32_to_cpu(sb_entry.params),\n\t\t\t      CAU_SB_ENTRY_TIMER_RES1);\n\n\taddress = BAR0_MAP_REG_XSDM_RAM +\n\t\t  XSTORM_ETH_QUEUE_ZONE_GTT_OFFSET(p_cid->abs.queue_id);\n\tcoalesce = qed_rd(p_hwfn, p_ptt, address);\n\n\tis_valid = GET_FIELD(coalesce, COALESCING_TIMESET_VALID);\n\tif (!is_valid)\n\t\treturn -EINVAL;\n\n\tcoalesce = GET_FIELD(coalesce, COALESCING_TIMESET_TIMESET);\n\t*p_tx_coal = (u16)(coalesce << timer_res);\n\n\treturn 0;\n}\n\nint qed_get_queue_coalesce(struct qed_hwfn *p_hwfn, u16 *p_coal, void *handle)\n{\n\tstruct qed_queue_cid *p_cid = handle;\n\tstruct qed_ptt *p_ptt;\n\tint rc = 0;\n\n\tif (IS_VF(p_hwfn->cdev)) {\n\t\trc = qed_vf_pf_get_coalesce(p_hwfn, p_coal, p_cid);\n\t\tif (rc)\n\t\t\tDP_NOTICE(p_hwfn, \"Unable to read queue coalescing\\n\");\n\n\t\treturn rc;\n\t}\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EAGAIN;\n\n\tif (p_cid->b_is_rx) {\n\t\trc = qed_get_rxq_coalesce(p_hwfn, p_ptt, p_cid, p_coal);\n\t\tif (rc)\n\t\t\tgoto out;\n\t} else {\n\t\trc = qed_get_txq_coalesce(p_hwfn, p_ptt, p_cid, p_coal);\n\t\tif (rc)\n\t\t\tgoto out;\n\t}\n\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nstatic int qed_fill_eth_dev_info(struct qed_dev *cdev,\n\t\t\t\t struct qed_dev_eth_info *info)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tint i;\n\n\tmemset(info, 0, sizeof(*info));\n\n\tif (IS_PF(cdev)) {\n\t\tint max_vf_vlan_filters = 0;\n\t\tint max_vf_mac_filters = 0;\n\n\t\tinfo->num_tc = p_hwfn->hw_info.num_hw_tc;\n\n\t\tif (cdev->int_params.out.int_mode == QED_INT_MODE_MSIX) {\n\t\t\tu16 num_queues = 0;\n\n\t\t\t \n\t\t\tfor_each_hwfn(cdev, i) {\n\t\t\t\tstruct qed_hwfn *hwfn = &cdev->hwfns[i];\n\t\t\t\tu16 l2_queues = (u16)FEAT_NUM(hwfn,\n\t\t\t\t\t\t\t      QED_PF_L2_QUE);\n\t\t\t\tu16 cids;\n\n\t\t\t\tcids = hwfn->pf_params.eth_pf_params.num_cons;\n\t\t\t\tcids /= (2 + info->num_tc);\n\t\t\t\tnum_queues += min_t(u16, l2_queues, cids);\n\t\t\t}\n\n\t\t\t \n\t\t\tif (cdev->int_params.fp_msix_cnt) {\n\t\t\t\tu8 irqs = cdev->int_params.fp_msix_cnt;\n\n\t\t\t\tinfo->num_queues = (u8)min_t(u16,\n\t\t\t\t\t\t\t     num_queues, irqs);\n\t\t\t}\n\t\t} else {\n\t\t\tinfo->num_queues = cdev->num_hwfns;\n\t\t}\n\n\t\tif (IS_QED_SRIOV(cdev)) {\n\t\t\tmax_vf_vlan_filters = cdev->p_iov_info->total_vfs *\n\t\t\t\t\t      QED_ETH_VF_NUM_VLAN_FILTERS;\n\t\t\tmax_vf_mac_filters = cdev->p_iov_info->total_vfs *\n\t\t\t\t\t     QED_ETH_VF_NUM_MAC_FILTERS;\n\t\t}\n\t\tinfo->num_vlan_filters = RESC_NUM(QED_LEADING_HWFN(cdev),\n\t\t\t\t\t\t  QED_VLAN) -\n\t\t\t\t\t max_vf_vlan_filters;\n\t\tinfo->num_mac_filters = RESC_NUM(QED_LEADING_HWFN(cdev),\n\t\t\t\t\t\t QED_MAC) -\n\t\t\t\t\tmax_vf_mac_filters;\n\n\t\tether_addr_copy(info->port_mac,\n\t\t\t\tcdev->hwfns[0].hw_info.hw_mac_addr);\n\n\t\tinfo->xdp_supported = true;\n\t} else {\n\t\tu16 total_cids = 0;\n\n\t\tinfo->num_tc = 1;\n\n\t\t \n\t\tfor_each_hwfn(cdev, i) {\n\t\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\t\t\tu8 queues, cids;\n\n\t\t\tqed_vf_get_num_cids(p_hwfn, &cids);\n\t\t\tqed_vf_get_num_rxqs(p_hwfn, &queues);\n\t\t\tinfo->num_queues += queues;\n\t\t\ttotal_cids += cids;\n\t\t}\n\n\t\t \n\t\tif (total_cids >= info->num_queues * 3)\n\t\t\tinfo->xdp_supported = true;\n\n\t\tqed_vf_get_num_vlan_filters(&cdev->hwfns[0],\n\t\t\t\t\t    (u8 *)&info->num_vlan_filters);\n\t\tqed_vf_get_num_mac_filters(&cdev->hwfns[0],\n\t\t\t\t\t   (u8 *)&info->num_mac_filters);\n\t\tqed_vf_get_port_mac(&cdev->hwfns[0], info->port_mac);\n\n\t\tinfo->is_legacy = !!cdev->hwfns[0].vf_iov_info->b_pre_fp_hsi;\n\t}\n\n\tqed_fill_dev_info(cdev, &info->common);\n\n\tif (IS_VF(cdev))\n\t\teth_zero_addr(info->common.hw_mac);\n\n\treturn 0;\n}\n\nstatic void qed_register_eth_ops(struct qed_dev *cdev,\n\t\t\t\t struct qed_eth_cb_ops *ops, void *cookie)\n{\n\tcdev->protocol_ops.eth = ops;\n\tcdev->ops_cookie = cookie;\n\n\t \n\tif (IS_VF(cdev))\n\t\tqed_vf_start_iov_wq(cdev);\n}\n\nstatic bool qed_check_mac(struct qed_dev *cdev, u8 *mac)\n{\n\tif (IS_PF(cdev))\n\t\treturn true;\n\n\treturn qed_vf_check_mac(&cdev->hwfns[0], mac);\n}\n\nstatic int qed_start_vport(struct qed_dev *cdev,\n\t\t\t   struct qed_start_vport_params *params)\n{\n\tint rc, i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_sp_vport_start_params start = { 0 };\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tstart.tpa_mode = params->gro_enable ? QED_TPA_MODE_GRO :\n\t\t\t\t\t\t\tQED_TPA_MODE_NONE;\n\t\tstart.remove_inner_vlan = params->remove_inner_vlan;\n\t\tstart.only_untagged = true;\t \n\t\tstart.drop_ttl0 = params->drop_ttl0;\n\t\tstart.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\t\tstart.concrete_fid = p_hwfn->hw_info.concrete_fid;\n\t\tstart.handle_ptp_pkts = params->handle_ptp_pkts;\n\t\tstart.vport_id = params->vport_id;\n\t\tstart.max_buffers_per_cqe = 16;\n\t\tstart.mtu = params->mtu;\n\n\t\trc = qed_sp_vport_start(p_hwfn, &start);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Failed to start VPORT\\n\");\n\t\t\treturn rc;\n\t\t}\n\n\t\trc = qed_hw_start_fastpath(p_hwfn);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Failed to start VPORT fastpath\\n\");\n\t\t\treturn rc;\n\t\t}\n\n\t\tDP_VERBOSE(cdev, (QED_MSG_SPQ | NETIF_MSG_IFUP),\n\t\t\t   \"Started V-PORT %d with MTU %d\\n\",\n\t\t\t   start.vport_id, start.mtu);\n\t}\n\n\tif (params->clear_stats)\n\t\tqed_reset_vport_stats(cdev);\n\n\treturn 0;\n}\n\nstatic int qed_stop_vport(struct qed_dev *cdev, u8 vport_id)\n{\n\tint rc, i;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\trc = qed_sp_vport_stop(p_hwfn,\n\t\t\t\t       p_hwfn->hw_info.opaque_fid, vport_id);\n\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Failed to stop VPORT\\n\");\n\t\t\treturn rc;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int qed_update_vport_rss(struct qed_dev *cdev,\n\t\t\t\tstruct qed_update_vport_rss_params *input,\n\t\t\t\tstruct qed_rss_params *rss)\n{\n\tint i, fn;\n\n\t \n\trss->update_rss_config = 1;\n\trss->rss_enable = 1;\n\trss->update_rss_capabilities = 1;\n\trss->update_rss_ind_table = 1;\n\trss->update_rss_key = 1;\n\trss->rss_caps = input->rss_caps;\n\tmemcpy(rss->rss_key, input->rss_key, QED_RSS_KEY_SIZE * sizeof(u32));\n\n\t \n\tif (cdev->num_hwfns == 1) {\n\t\tmemcpy(rss->rss_ind_table,\n\t\t       input->rss_ind_table,\n\t\t       QED_RSS_IND_TABLE_SIZE * sizeof(void *));\n\t\trss->rss_table_size_log = 7;\n\t\treturn 0;\n\t}\n\n\t \n\tmemcpy(&rss[1], &rss[0], sizeof(struct qed_rss_params));\n\n\t \n\tfor (i = 0; i < QED_RSS_IND_TABLE_SIZE; i++) {\n\t\tstruct qed_queue_cid *cid = input->rss_ind_table[i];\n\t\tstruct qed_rss_params *t_rss;\n\n\t\tif (cid->p_owner == QED_LEADING_HWFN(cdev))\n\t\t\tt_rss = &rss[0];\n\t\telse\n\t\t\tt_rss = &rss[1];\n\n\t\tt_rss->rss_ind_table[i / cdev->num_hwfns] = cid;\n\t}\n\n\t \n\tfor_each_hwfn(cdev, fn) {\n\t\tfor (i = 1; i < QED_RSS_IND_TABLE_SIZE / cdev->num_hwfns; i++) {\n\t\t\tif (rss[fn].rss_ind_table[i] !=\n\t\t\t    rss[fn].rss_ind_table[0])\n\t\t\t\tbreak;\n\t\t}\n\t\tif (i == QED_RSS_IND_TABLE_SIZE / cdev->num_hwfns) {\n\t\t\tDP_VERBOSE(cdev, NETIF_MSG_IFUP,\n\t\t\t\t   \"CMT - 1 queue per-hwfn; Disabling RSS\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\trss[fn].rss_table_size_log = 6;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_update_vport(struct qed_dev *cdev,\n\t\t\t    struct qed_update_vport_params *params)\n{\n\tstruct qed_sp_vport_update_params sp_params;\n\tstruct qed_rss_params *rss;\n\tint rc = 0, i;\n\n\tif (!cdev)\n\t\treturn -ENODEV;\n\n\trss = vzalloc(array_size(sizeof(*rss), cdev->num_hwfns));\n\tif (!rss)\n\t\treturn -ENOMEM;\n\n\tmemset(&sp_params, 0, sizeof(sp_params));\n\n\t \n\tsp_params.vport_id = params->vport_id;\n\tsp_params.update_vport_active_rx_flg = params->update_vport_active_flg;\n\tsp_params.update_vport_active_tx_flg = params->update_vport_active_flg;\n\tsp_params.vport_active_rx_flg = params->vport_active_flg;\n\tsp_params.vport_active_tx_flg = params->vport_active_flg;\n\tsp_params.update_tx_switching_flg = params->update_tx_switching_flg;\n\tsp_params.tx_switching_flg = params->tx_switching_flg;\n\tsp_params.accept_any_vlan = params->accept_any_vlan;\n\tsp_params.update_accept_any_vlan_flg =\n\t\tparams->update_accept_any_vlan_flg;\n\n\t \n\tif (params->update_rss_flg)\n\t\tif (qed_update_vport_rss(cdev, &params->rss_params, rss))\n\t\t\tparams->update_rss_flg = 0;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tif (params->update_rss_flg)\n\t\t\tsp_params.rss_params = &rss[i];\n\n\t\tsp_params.opaque_fid = p_hwfn->hw_info.opaque_fid;\n\t\trc = qed_sp_vport_update(p_hwfn, &sp_params,\n\t\t\t\t\t QED_SPQ_MODE_EBLOCK,\n\t\t\t\t\t NULL);\n\t\tif (rc) {\n\t\t\tDP_ERR(cdev, \"Failed to update VPORT\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tDP_VERBOSE(cdev, (QED_MSG_SPQ | NETIF_MSG_IFUP),\n\t\t\t   \"Updated V-PORT %d: active_flag %d [update %d]\\n\",\n\t\t\t   params->vport_id, params->vport_active_flg,\n\t\t\t   params->update_vport_active_flg);\n\t}\n\nout:\n\tvfree(rss);\n\treturn rc;\n}\n\nstatic int qed_start_rxq(struct qed_dev *cdev,\n\t\t\t u8 rss_num,\n\t\t\t struct qed_queue_start_common_params *p_params,\n\t\t\t u16 bd_max_bytes,\n\t\t\t dma_addr_t bd_chain_phys_addr,\n\t\t\t dma_addr_t cqe_pbl_addr,\n\t\t\t u16 cqe_pbl_size,\n\t\t\t struct qed_rxq_start_ret_params *ret_params)\n{\n\tstruct qed_hwfn *p_hwfn;\n\tint rc, hwfn_index;\n\n\thwfn_index = rss_num % cdev->num_hwfns;\n\tp_hwfn = &cdev->hwfns[hwfn_index];\n\n\tp_params->queue_id = p_params->queue_id / cdev->num_hwfns;\n\tp_params->stats_id = p_params->vport_id;\n\n\trc = qed_eth_rx_queue_start(p_hwfn,\n\t\t\t\t    p_hwfn->hw_info.opaque_fid,\n\t\t\t\t    p_params,\n\t\t\t\t    bd_max_bytes,\n\t\t\t\t    bd_chain_phys_addr,\n\t\t\t\t    cqe_pbl_addr, cqe_pbl_size, ret_params);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed to start RXQ#%d\\n\", p_params->queue_id);\n\t\treturn rc;\n\t}\n\n\tDP_VERBOSE(cdev, (QED_MSG_SPQ | NETIF_MSG_IFUP),\n\t\t   \"Started RX-Q %d [rss_num %d] on V-PORT %d and SB igu %d\\n\",\n\t\t   p_params->queue_id, rss_num, p_params->vport_id,\n\t\t   p_params->p_sb->igu_sb_id);\n\n\treturn 0;\n}\n\nstatic int qed_stop_rxq(struct qed_dev *cdev, u8 rss_id, void *handle)\n{\n\tint rc, hwfn_index;\n\tstruct qed_hwfn *p_hwfn;\n\n\thwfn_index = rss_id % cdev->num_hwfns;\n\tp_hwfn = &cdev->hwfns[hwfn_index];\n\n\trc = qed_eth_rx_queue_stop(p_hwfn, handle, false, false);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed to stop RXQ#%02x\\n\", rss_id);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_start_txq(struct qed_dev *cdev,\n\t\t\t u8 rss_num,\n\t\t\t struct qed_queue_start_common_params *p_params,\n\t\t\t dma_addr_t pbl_addr,\n\t\t\t u16 pbl_size,\n\t\t\t struct qed_txq_start_ret_params *ret_params)\n{\n\tstruct qed_hwfn *p_hwfn;\n\tint rc, hwfn_index;\n\n\thwfn_index = rss_num % cdev->num_hwfns;\n\tp_hwfn = &cdev->hwfns[hwfn_index];\n\tp_params->queue_id = p_params->queue_id / cdev->num_hwfns;\n\tp_params->stats_id = p_params->vport_id;\n\n\trc = qed_eth_tx_queue_start(p_hwfn,\n\t\t\t\t    p_hwfn->hw_info.opaque_fid,\n\t\t\t\t    p_params, p_params->tc,\n\t\t\t\t    pbl_addr, pbl_size, ret_params);\n\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed to start TXQ#%d\\n\", p_params->queue_id);\n\t\treturn rc;\n\t}\n\n\tDP_VERBOSE(cdev, (QED_MSG_SPQ | NETIF_MSG_IFUP),\n\t\t   \"Started TX-Q %d [rss_num %d] on V-PORT %d and SB igu %d\\n\",\n\t\t   p_params->queue_id, rss_num, p_params->vport_id,\n\t\t   p_params->p_sb->igu_sb_id);\n\n\treturn 0;\n}\n\n#define QED_HW_STOP_RETRY_LIMIT (10)\nstatic int qed_fastpath_stop(struct qed_dev *cdev)\n{\n\tint rc;\n\n\trc = qed_hw_stop_fastpath(cdev);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed to stop Fastpath\\n\");\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_stop_txq(struct qed_dev *cdev, u8 rss_id, void *handle)\n{\n\tstruct qed_hwfn *p_hwfn;\n\tint rc, hwfn_index;\n\n\thwfn_index = rss_id % cdev->num_hwfns;\n\tp_hwfn = &cdev->hwfns[hwfn_index];\n\n\trc = qed_eth_tx_queue_stop(p_hwfn, handle);\n\tif (rc) {\n\t\tDP_ERR(cdev, \"Failed to stop TXQ#%02x\\n\", rss_id);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_tunn_configure(struct qed_dev *cdev,\n\t\t\t      struct qed_tunn_params *tunn_params)\n{\n\tstruct qed_tunnel_info tunn_info;\n\tint i, rc;\n\n\tmemset(&tunn_info, 0, sizeof(tunn_info));\n\tif (tunn_params->update_vxlan_port) {\n\t\ttunn_info.vxlan_port.b_update_port = true;\n\t\ttunn_info.vxlan_port.port = tunn_params->vxlan_port;\n\t}\n\n\tif (tunn_params->update_geneve_port) {\n\t\ttunn_info.geneve_port.b_update_port = true;\n\t\ttunn_info.geneve_port.port = tunn_params->geneve_port;\n\t}\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *hwfn = &cdev->hwfns[i];\n\t\tstruct qed_ptt *p_ptt;\n\t\tstruct qed_tunnel_info *tun;\n\n\t\ttun = &hwfn->cdev->tunnel;\n\t\tif (IS_PF(cdev)) {\n\t\t\tp_ptt = qed_ptt_acquire(hwfn);\n\t\t\tif (!p_ptt)\n\t\t\t\treturn -EAGAIN;\n\t\t} else {\n\t\t\tp_ptt = NULL;\n\t\t}\n\n\t\trc = qed_sp_pf_update_tunn_cfg(hwfn, p_ptt, &tunn_info,\n\t\t\t\t\t       QED_SPQ_MODE_EBLOCK, NULL);\n\t\tif (rc) {\n\t\t\tif (IS_PF(cdev))\n\t\t\t\tqed_ptt_release(hwfn, p_ptt);\n\t\t\treturn rc;\n\t\t}\n\n\t\tif (IS_PF_SRIOV(hwfn)) {\n\t\t\tu16 vxlan_port, geneve_port;\n\t\t\tint j;\n\n\t\t\tvxlan_port = tun->vxlan_port.port;\n\t\t\tgeneve_port = tun->geneve_port.port;\n\n\t\t\tqed_for_each_vf(hwfn, j) {\n\t\t\t\tqed_iov_bulletin_set_udp_ports(hwfn, j,\n\t\t\t\t\t\t\t       vxlan_port,\n\t\t\t\t\t\t\t       geneve_port);\n\t\t\t}\n\n\t\t\tqed_schedule_iov(hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);\n\t\t}\n\t\tif (IS_PF(cdev))\n\t\t\tqed_ptt_release(hwfn, p_ptt);\n\t}\n\n\treturn 0;\n}\n\nstatic int qed_configure_filter_rx_mode(struct qed_dev *cdev,\n\t\t\t\t\tenum qed_filter_rx_mode_type type)\n{\n\tstruct qed_filter_accept_flags accept_flags;\n\n\tmemset(&accept_flags, 0, sizeof(accept_flags));\n\n\taccept_flags.update_rx_mode_config = 1;\n\taccept_flags.update_tx_mode_config = 1;\n\taccept_flags.rx_accept_filter = QED_ACCEPT_UCAST_MATCHED |\n\t\t\t\t\tQED_ACCEPT_MCAST_MATCHED |\n\t\t\t\t\tQED_ACCEPT_BCAST;\n\taccept_flags.tx_accept_filter = QED_ACCEPT_UCAST_MATCHED |\n\t\t\t\t\tQED_ACCEPT_MCAST_MATCHED |\n\t\t\t\t\tQED_ACCEPT_BCAST;\n\n\tif (type == QED_FILTER_RX_MODE_TYPE_PROMISC) {\n\t\taccept_flags.rx_accept_filter |= QED_ACCEPT_UCAST_UNMATCHED |\n\t\t\t\t\t\t QED_ACCEPT_MCAST_UNMATCHED;\n\t\taccept_flags.tx_accept_filter |= QED_ACCEPT_UCAST_UNMATCHED |\n\t\t\t\t\t\t QED_ACCEPT_MCAST_UNMATCHED;\n\t} else if (type == QED_FILTER_RX_MODE_TYPE_MULTI_PROMISC) {\n\t\taccept_flags.rx_accept_filter |= QED_ACCEPT_MCAST_UNMATCHED;\n\t\taccept_flags.tx_accept_filter |= QED_ACCEPT_MCAST_UNMATCHED;\n\t}\n\n\treturn qed_filter_accept_cmd(cdev, 0, accept_flags, false, false,\n\t\t\t\t     QED_SPQ_MODE_CB, NULL);\n}\n\nstatic int qed_configure_filter_ucast(struct qed_dev *cdev,\n\t\t\t\t      struct qed_filter_ucast_params *params)\n{\n\tstruct qed_filter_ucast ucast;\n\n\tif (!params->vlan_valid && !params->mac_valid) {\n\t\tDP_NOTICE(cdev,\n\t\t\t  \"Tried configuring a unicast filter, but both MAC and VLAN are not set\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&ucast, 0, sizeof(ucast));\n\tswitch (params->type) {\n\tcase QED_FILTER_XCAST_TYPE_ADD:\n\t\tucast.opcode = QED_FILTER_ADD;\n\t\tbreak;\n\tcase QED_FILTER_XCAST_TYPE_DEL:\n\t\tucast.opcode = QED_FILTER_REMOVE;\n\t\tbreak;\n\tcase QED_FILTER_XCAST_TYPE_REPLACE:\n\t\tucast.opcode = QED_FILTER_REPLACE;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(cdev, \"Unknown unicast filter type %d\\n\",\n\t\t\t  params->type);\n\t}\n\n\tif (params->vlan_valid && params->mac_valid) {\n\t\tucast.type = QED_FILTER_MAC_VLAN;\n\t\tether_addr_copy(ucast.mac, params->mac);\n\t\tucast.vlan = params->vlan;\n\t} else if (params->mac_valid) {\n\t\tucast.type = QED_FILTER_MAC;\n\t\tether_addr_copy(ucast.mac, params->mac);\n\t} else {\n\t\tucast.type = QED_FILTER_VLAN;\n\t\tucast.vlan = params->vlan;\n\t}\n\n\tucast.is_rx_filter = true;\n\tucast.is_tx_filter = true;\n\n\treturn qed_filter_ucast_cmd(cdev, &ucast, QED_SPQ_MODE_CB, NULL);\n}\n\nstatic int qed_configure_filter_mcast(struct qed_dev *cdev,\n\t\t\t\t      struct qed_filter_mcast_params *params)\n{\n\tstruct qed_filter_mcast mcast;\n\tint i;\n\n\tmemset(&mcast, 0, sizeof(mcast));\n\tswitch (params->type) {\n\tcase QED_FILTER_XCAST_TYPE_ADD:\n\t\tmcast.opcode = QED_FILTER_ADD;\n\t\tbreak;\n\tcase QED_FILTER_XCAST_TYPE_DEL:\n\t\tmcast.opcode = QED_FILTER_REMOVE;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(cdev, \"Unknown multicast filter type %d\\n\",\n\t\t\t  params->type);\n\t}\n\n\tmcast.num_mc_addrs = params->num;\n\tfor (i = 0; i < mcast.num_mc_addrs; i++)\n\t\tether_addr_copy(mcast.mac[i], params->mac[i]);\n\n\treturn qed_filter_mcast_cmd(cdev, &mcast, QED_SPQ_MODE_CB, NULL);\n}\n\nstatic int qed_configure_arfs_searcher(struct qed_dev *cdev,\n\t\t\t\t       enum qed_filter_config_mode mode)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_arfs_config_params arfs_config_params;\n\n\tmemset(&arfs_config_params, 0, sizeof(arfs_config_params));\n\tarfs_config_params.tcp = true;\n\tarfs_config_params.udp = true;\n\tarfs_config_params.ipv4 = true;\n\tarfs_config_params.ipv6 = true;\n\tarfs_config_params.mode = mode;\n\tqed_arfs_mode_configure(p_hwfn, p_hwfn->p_arfs_ptt,\n\t\t\t\t&arfs_config_params);\n\treturn 0;\n}\n\nstatic void\nqed_arfs_sp_response_handler(struct qed_hwfn *p_hwfn,\n\t\t\t     void *cookie,\n\t\t\t     union event_ring_data *data, u8 fw_return_code)\n{\n\tstruct qed_common_cb_ops *op = p_hwfn->cdev->protocol_ops.common;\n\tvoid *dev = p_hwfn->cdev->ops_cookie;\n\n\top->arfs_filter_op(dev, cookie, fw_return_code);\n}\n\nstatic int\nqed_ntuple_arfs_filter_config(struct qed_dev *cdev,\n\t\t\t      void *cookie,\n\t\t\t      struct qed_ntuple_filter_params *params)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_spq_comp_cb cb;\n\tint rc = -EINVAL;\n\n\tcb.function = qed_arfs_sp_response_handler;\n\tcb.cookie = cookie;\n\n\tif (params->b_is_vf) {\n\t\tif (!qed_iov_is_valid_vfid(p_hwfn, params->vf_id, false,\n\t\t\t\t\t   false)) {\n\t\t\tDP_INFO(p_hwfn, \"vfid 0x%02x is out of bounds\\n\",\n\t\t\t\tparams->vf_id);\n\t\t\treturn rc;\n\t\t}\n\n\t\tparams->vport_id = params->vf_id + 1;\n\t\tparams->qid = QED_RFS_NTUPLE_QID_RSS;\n\t}\n\n\trc = qed_configure_rfs_ntuple_filter(p_hwfn, &cb, params);\n\tif (rc)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to issue a-RFS filter configuration\\n\");\n\telse\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_DRV,\n\t\t\t   \"Successfully issued a-RFS filter configuration\\n\");\n\n\treturn rc;\n}\n\nstatic int qed_get_coalesce(struct qed_dev *cdev, u16 *coal, void *handle)\n{\n\tstruct qed_queue_cid *p_cid = handle;\n\tstruct qed_hwfn *p_hwfn;\n\tint rc;\n\n\tp_hwfn = p_cid->p_owner;\n\trc = qed_get_queue_coalesce(p_hwfn, coal, handle);\n\tif (rc)\n\t\tDP_VERBOSE(cdev, QED_MSG_DEBUG,\n\t\t\t   \"Unable to read queue coalescing\\n\");\n\n\treturn rc;\n}\n\nstatic int qed_fp_cqe_completion(struct qed_dev *dev,\n\t\t\t\t u8 rss_id, struct eth_slow_path_rx_cqe *cqe)\n{\n\treturn qed_eth_cqe_completion(&dev->hwfns[rss_id % dev->num_hwfns],\n\t\t\t\t      cqe);\n}\n\nstatic int qed_req_bulletin_update_mac(struct qed_dev *cdev, const u8 *mac)\n{\n\tint i, ret;\n\n\tif (IS_PF(cdev))\n\t\treturn 0;\n\n\tfor_each_hwfn(cdev, i) {\n\t\tstruct qed_hwfn *p_hwfn = &cdev->hwfns[i];\n\n\t\tret = qed_vf_pf_bulletin_update_mac(p_hwfn, mac);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct qed_eth_ops qed_eth_ops_pass = {\n\t.common = &qed_common_ops_pass,\n#ifdef CONFIG_QED_SRIOV\n\t.iov = &qed_iov_ops_pass,\n#endif\n#ifdef CONFIG_DCB\n\t.dcb = &qed_dcbnl_ops_pass,\n#endif\n\t.ptp = &qed_ptp_ops_pass,\n\t.fill_dev_info = &qed_fill_eth_dev_info,\n\t.register_ops = &qed_register_eth_ops,\n\t.check_mac = &qed_check_mac,\n\t.vport_start = &qed_start_vport,\n\t.vport_stop = &qed_stop_vport,\n\t.vport_update = &qed_update_vport,\n\t.q_rx_start = &qed_start_rxq,\n\t.q_rx_stop = &qed_stop_rxq,\n\t.q_tx_start = &qed_start_txq,\n\t.q_tx_stop = &qed_stop_txq,\n\t.filter_config_rx_mode = &qed_configure_filter_rx_mode,\n\t.filter_config_ucast = &qed_configure_filter_ucast,\n\t.filter_config_mcast = &qed_configure_filter_mcast,\n\t.fastpath_stop = &qed_fastpath_stop,\n\t.eth_cqe_completion = &qed_fp_cqe_completion,\n\t.get_vport_stats = &qed_get_vport_stats,\n\t.tunn_config = &qed_tunn_configure,\n\t.ntuple_filter_config = &qed_ntuple_arfs_filter_config,\n\t.configure_arfs_searcher = &qed_configure_arfs_searcher,\n\t.get_coalesce = &qed_get_coalesce,\n\t.req_bulletin_update_mac = &qed_req_bulletin_update_mac,\n};\n\nconst struct qed_eth_ops *qed_get_eth_ops(void)\n{\n\treturn &qed_eth_ops_pass;\n}\nEXPORT_SYMBOL(qed_get_eth_ops);\n\nvoid qed_put_eth_ops(void)\n{\n\t \n}\nEXPORT_SYMBOL(qed_put_eth_ops);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}