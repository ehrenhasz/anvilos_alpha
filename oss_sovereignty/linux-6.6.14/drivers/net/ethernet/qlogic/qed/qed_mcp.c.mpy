{
  "module_name": "qed_mcp.c",
  "hash_id": "c68ab57c3520e878ece65acc8a5c07ffdb2de255983760a6f821f3c4cf7dc3a1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qed/qed_mcp.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <asm/byteorder.h>\n#include <linux/delay.h>\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include <linux/etherdevice.h>\n#include \"qed.h\"\n#include \"qed_cxt.h\"\n#include \"qed_dcbx.h\"\n#include \"qed_hsi.h\"\n#include \"qed_mfw_hsi.h\"\n#include \"qed_hw.h\"\n#include \"qed_mcp.h\"\n#include \"qed_reg_addr.h\"\n#include \"qed_sriov.h\"\n\n#define GRCBASE_MCP     0xe00000\n\n#define QED_MCP_RESP_ITER_US\t10\n\n#define QED_DRV_MB_MAX_RETRIES\t(500 * 1000)\t \n#define QED_MCP_RESET_RETRIES\t(50 * 1000)\t \n\n#define DRV_INNER_WR(_p_hwfn, _p_ptt, _ptr, _offset, _val)\t     \\\n\tqed_wr(_p_hwfn, _p_ptt, (_p_hwfn->mcp_info->_ptr + (_offset)), \\\n\t       _val)\n\n#define DRV_INNER_RD(_p_hwfn, _p_ptt, _ptr, _offset) \\\n\tqed_rd(_p_hwfn, _p_ptt, (_p_hwfn->mcp_info->_ptr + (_offset)))\n\n#define DRV_MB_WR(_p_hwfn, _p_ptt, _field, _val)  \\\n\tDRV_INNER_WR(p_hwfn, _p_ptt, drv_mb_addr, \\\n\t\t     offsetof(struct public_drv_mb, _field), _val)\n\n#define DRV_MB_RD(_p_hwfn, _p_ptt, _field)\t   \\\n\tDRV_INNER_RD(_p_hwfn, _p_ptt, drv_mb_addr, \\\n\t\t     offsetof(struct public_drv_mb, _field))\n\n#define PDA_COMP (((FW_MAJOR_VERSION) + (FW_MINOR_VERSION << 8)) << \\\n\t\t  DRV_ID_PDA_COMP_VER_SHIFT)\n\n#define MCP_BYTES_PER_MBIT_SHIFT 17\n\nbool qed_mcp_is_init(struct qed_hwfn *p_hwfn)\n{\n\tif (!p_hwfn->mcp_info || !p_hwfn->mcp_info->public_base)\n\t\treturn false;\n\treturn true;\n}\n\nvoid qed_mcp_cmd_port_init(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 addr = SECTION_OFFSIZE_ADDR(p_hwfn->mcp_info->public_base,\n\t\t\t\t\tPUBLIC_PORT);\n\tu32 mfw_mb_offsize = qed_rd(p_hwfn, p_ptt, addr);\n\n\tp_hwfn->mcp_info->port_addr = SECTION_ADDR(mfw_mb_offsize,\n\t\t\t\t\t\t   MFW_PORT(p_hwfn));\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"port_addr = 0x%x, port_id 0x%02x\\n\",\n\t\t   p_hwfn->mcp_info->port_addr, MFW_PORT(p_hwfn));\n}\n\nvoid qed_mcp_read_mb(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 length = MFW_DRV_MSG_MAX_DWORDS(p_hwfn->mcp_info->mfw_mb_length);\n\tu32 tmp, i;\n\n\tif (!p_hwfn->mcp_info->public_base)\n\t\treturn;\n\n\tfor (i = 0; i < length; i++) {\n\t\ttmp = qed_rd(p_hwfn, p_ptt,\n\t\t\t     p_hwfn->mcp_info->mfw_mb_addr +\n\t\t\t     (i << 2) + sizeof(u32));\n\n\t\t \n\t\t((u32 *)p_hwfn->mcp_info->mfw_mb_cur)[i] =\n\t\t\tbe32_to_cpu((__force __be32)tmp);\n\t}\n}\n\nstruct qed_mcp_cmd_elem {\n\tstruct list_head list;\n\tstruct qed_mcp_mb_params *p_mb_params;\n\tu16 expected_seq_num;\n\tbool b_is_completed;\n};\n\n \nstatic struct qed_mcp_cmd_elem *\nqed_mcp_cmd_add_elem(struct qed_hwfn *p_hwfn,\n\t\t     struct qed_mcp_mb_params *p_mb_params,\n\t\t     u16 expected_seq_num)\n{\n\tstruct qed_mcp_cmd_elem *p_cmd_elem = NULL;\n\n\tp_cmd_elem = kzalloc(sizeof(*p_cmd_elem), GFP_ATOMIC);\n\tif (!p_cmd_elem)\n\t\tgoto out;\n\n\tp_cmd_elem->p_mb_params = p_mb_params;\n\tp_cmd_elem->expected_seq_num = expected_seq_num;\n\tlist_add(&p_cmd_elem->list, &p_hwfn->mcp_info->cmd_list);\nout:\n\treturn p_cmd_elem;\n}\n\n \nstatic void qed_mcp_cmd_del_elem(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_mcp_cmd_elem *p_cmd_elem)\n{\n\tlist_del(&p_cmd_elem->list);\n\tkfree(p_cmd_elem);\n}\n\n \nstatic struct qed_mcp_cmd_elem *qed_mcp_cmd_get_elem(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t\t     u16 seq_num)\n{\n\tstruct qed_mcp_cmd_elem *p_cmd_elem = NULL;\n\n\tlist_for_each_entry(p_cmd_elem, &p_hwfn->mcp_info->cmd_list, list) {\n\t\tif (p_cmd_elem->expected_seq_num == seq_num)\n\t\t\treturn p_cmd_elem;\n\t}\n\n\treturn NULL;\n}\n\nint qed_mcp_free(struct qed_hwfn *p_hwfn)\n{\n\tif (p_hwfn->mcp_info) {\n\t\tstruct qed_mcp_cmd_elem *p_cmd_elem = NULL, *p_tmp;\n\n\t\tkfree(p_hwfn->mcp_info->mfw_mb_cur);\n\t\tkfree(p_hwfn->mcp_info->mfw_mb_shadow);\n\n\t\tspin_lock_bh(&p_hwfn->mcp_info->cmd_lock);\n\t\tlist_for_each_entry_safe(p_cmd_elem,\n\t\t\t\t\t p_tmp,\n\t\t\t\t\t &p_hwfn->mcp_info->cmd_list, list) {\n\t\t\tqed_mcp_cmd_del_elem(p_hwfn, p_cmd_elem);\n\t\t}\n\t\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\t}\n\n\tkfree(p_hwfn->mcp_info);\n\tp_hwfn->mcp_info = NULL;\n\n\treturn 0;\n}\n\n \n#define QED_MCP_SHMEM_RDY_MAX_RETRIES\t20\n#define QED_MCP_SHMEM_RDY_ITER_MS\t50\n\nstatic int qed_load_mcp_offsets(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_info *p_info = p_hwfn->mcp_info;\n\tu8 cnt = QED_MCP_SHMEM_RDY_MAX_RETRIES;\n\tu8 msec = QED_MCP_SHMEM_RDY_ITER_MS;\n\tu32 drv_mb_offsize, mfw_mb_offsize;\n\tu32 mcp_pf_id = MCP_PF_ID(p_hwfn);\n\n\tp_info->public_base = qed_rd(p_hwfn, p_ptt, MISC_REG_SHARED_MEM_ADDR);\n\tif (!p_info->public_base) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The address of the MCP scratch-pad is not configured\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tp_info->public_base |= GRCBASE_MCP;\n\n\t \n\tmfw_mb_offsize = qed_rd(p_hwfn, p_ptt,\n\t\t\t\tSECTION_OFFSIZE_ADDR(p_info->public_base,\n\t\t\t\t\t\t     PUBLIC_MFW_MB));\n\tp_info->mfw_mb_addr = SECTION_ADDR(mfw_mb_offsize, mcp_pf_id);\n\tp_info->mfw_mb_length = (u16)qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t    p_info->mfw_mb_addr +\n\t\t\t\t\t    offsetof(struct public_mfw_mb,\n\t\t\t\t\t\t     sup_msgs));\n\n\t \n\twhile (!p_info->mfw_mb_length && --cnt) {\n\t\tmsleep(msec);\n\t\tp_info->mfw_mb_length =\n\t\t\t(u16)qed_rd(p_hwfn, p_ptt,\n\t\t\t\t    p_info->mfw_mb_addr +\n\t\t\t\t    offsetof(struct public_mfw_mb, sup_msgs));\n\t}\n\n\tif (!cnt) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to get the SHMEM ready notification after %d msec\\n\",\n\t\t\t  QED_MCP_SHMEM_RDY_MAX_RETRIES * msec);\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tdrv_mb_offsize = qed_rd(p_hwfn, p_ptt,\n\t\t\t\tSECTION_OFFSIZE_ADDR(p_info->public_base,\n\t\t\t\t\t\t     PUBLIC_DRV_MB));\n\tp_info->drv_mb_addr = SECTION_ADDR(drv_mb_offsize, mcp_pf_id);\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"drv_mb_offsiz = 0x%x, drv_mb_addr = 0x%x mcp_pf_id = 0x%x\\n\",\n\t\t   drv_mb_offsize, p_info->drv_mb_addr, mcp_pf_id);\n\n\t \n\tp_info->drv_mb_seq = DRV_MB_RD(p_hwfn, p_ptt, drv_mb_header) &\n\t\t\t     DRV_MSG_SEQ_NUMBER_MASK;\n\n\t \n\tp_info->drv_pulse_seq = DRV_MB_RD(p_hwfn, p_ptt, drv_pulse_mb) &\n\t\t\t\tDRV_PULSE_SEQ_MASK;\n\n\tp_info->mcp_hist = qed_rd(p_hwfn, p_ptt, MISCS_REG_GENERIC_POR_0);\n\n\treturn 0;\n}\n\nint qed_mcp_cmd_init(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_info *p_info;\n\tu32 size;\n\n\t \n\tp_hwfn->mcp_info = kzalloc(sizeof(*p_hwfn->mcp_info), GFP_KERNEL);\n\tif (!p_hwfn->mcp_info)\n\t\tgoto err;\n\tp_info = p_hwfn->mcp_info;\n\n\t \n\tspin_lock_init(&p_info->cmd_lock);\n\tspin_lock_init(&p_info->link_lock);\n\tspin_lock_init(&p_info->unload_lock);\n\n\tINIT_LIST_HEAD(&p_info->cmd_list);\n\n\tif (qed_load_mcp_offsets(p_hwfn, p_ptt) != 0) {\n\t\tDP_NOTICE(p_hwfn, \"MCP is not initialized\\n\");\n\t\t \n\t\treturn 0;\n\t}\n\n\tsize = MFW_DRV_MSG_MAX_DWORDS(p_info->mfw_mb_length) * sizeof(u32);\n\tp_info->mfw_mb_cur = kzalloc(size, GFP_KERNEL);\n\tp_info->mfw_mb_shadow = kzalloc(size, GFP_KERNEL);\n\tif (!p_info->mfw_mb_cur || !p_info->mfw_mb_shadow)\n\t\tgoto err;\n\n\treturn 0;\n\nerr:\n\tqed_mcp_free(p_hwfn);\n\treturn -ENOMEM;\n}\n\nstatic void qed_mcp_reread_offsets(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt)\n{\n\tu32 generic_por_0 = qed_rd(p_hwfn, p_ptt, MISCS_REG_GENERIC_POR_0);\n\n\t \n\tif (p_hwfn->mcp_info->mcp_hist != generic_por_0) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_SP,\n\t\t\t   \"Rereading MCP offsets [mcp_hist 0x%08x, generic_por_0 0x%08x]\\n\",\n\t\t\t   p_hwfn->mcp_info->mcp_hist, generic_por_0);\n\n\t\tqed_load_mcp_offsets(p_hwfn, p_ptt);\n\t\tqed_mcp_cmd_port_init(p_hwfn, p_ptt);\n\t}\n}\n\nint qed_mcp_reset(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 org_mcp_reset_seq, seq, delay = QED_MCP_RESP_ITER_US, cnt = 0;\n\tint rc = 0;\n\n\tif (p_hwfn->mcp_info->b_block_cmd) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The MFW is not responsive. Avoid sending MCP_RESET mailbox command.\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tspin_lock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\torg_mcp_reset_seq = qed_rd(p_hwfn, p_ptt, MISCS_REG_GENERIC_POR_0);\n\n\t \n\tqed_mcp_reread_offsets(p_hwfn, p_ptt);\n\tseq = ++p_hwfn->mcp_info->drv_mb_seq;\n\tDRV_MB_WR(p_hwfn, p_ptt, drv_mb_header, (DRV_MSG_CODE_MCP_RESET | seq));\n\n\tdo {\n\t\t \n\t\tudelay(delay);\n\t\t \n\t} while ((org_mcp_reset_seq == qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t      MISCS_REG_GENERIC_POR_0)) &&\n\t\t (cnt++ < QED_MCP_RESET_RETRIES));\n\n\tif (org_mcp_reset_seq !=\n\t    qed_rd(p_hwfn, p_ptt, MISCS_REG_GENERIC_POR_0)) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"MCP was reset after %d usec\\n\", cnt * delay);\n\t} else {\n\t\tDP_ERR(p_hwfn, \"Failed to reset MCP\\n\");\n\t\trc = -EAGAIN;\n\t}\n\n\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\treturn rc;\n}\n\n \nstatic bool qed_mcp_has_pending_cmd(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_mcp_cmd_elem *p_cmd_elem;\n\n\t \n\tif (!list_empty(&p_hwfn->mcp_info->cmd_list)) {\n\t\tp_cmd_elem = list_first_entry(&p_hwfn->mcp_info->cmd_list,\n\t\t\t\t\t      struct qed_mcp_cmd_elem, list);\n\t\treturn !p_cmd_elem->b_is_completed;\n\t}\n\n\treturn false;\n}\n\n \nstatic int\nqed_mcp_update_pending_cmd(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_mb_params *p_mb_params;\n\tstruct qed_mcp_cmd_elem *p_cmd_elem;\n\tu32 mcp_resp;\n\tu16 seq_num;\n\n\tmcp_resp = DRV_MB_RD(p_hwfn, p_ptt, fw_mb_header);\n\tseq_num = (u16)(mcp_resp & FW_MSG_SEQ_NUMBER_MASK);\n\n\t \n\tif (seq_num != p_hwfn->mcp_info->drv_mb_seq)\n\t\treturn -EAGAIN;\n\n\tp_cmd_elem = qed_mcp_cmd_get_elem(p_hwfn, seq_num);\n\tif (!p_cmd_elem) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"Failed to find a pending mailbox cmd that expects sequence number %d\\n\",\n\t\t       seq_num);\n\t\treturn -EINVAL;\n\t}\n\n\tp_mb_params = p_cmd_elem->p_mb_params;\n\n\t \n\tp_mb_params->mcp_resp = mcp_resp;\n\n\t \n\tp_mb_params->mcp_param = DRV_MB_RD(p_hwfn, p_ptt, fw_mb_param);\n\n\t \n\tif (p_mb_params->p_data_dst && p_mb_params->data_dst_size) {\n\t\tu32 union_data_addr = p_hwfn->mcp_info->drv_mb_addr +\n\t\t\t\t      offsetof(struct public_drv_mb,\n\t\t\t\t\t       union_data);\n\t\tqed_memcpy_from(p_hwfn, p_ptt, p_mb_params->p_data_dst,\n\t\t\t\tunion_data_addr, p_mb_params->data_dst_size);\n\t}\n\n\tp_cmd_elem->b_is_completed = true;\n\n\treturn 0;\n}\n\n \nstatic void __qed_mcp_cmd_and_union(struct qed_hwfn *p_hwfn,\n\t\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t\t    struct qed_mcp_mb_params *p_mb_params,\n\t\t\t\t    u16 seq_num)\n{\n\tunion drv_union_data union_data;\n\tu32 union_data_addr;\n\n\t \n\tunion_data_addr = p_hwfn->mcp_info->drv_mb_addr +\n\t\t\t  offsetof(struct public_drv_mb, union_data);\n\tmemset(&union_data, 0, sizeof(union_data));\n\tif (p_mb_params->p_data_src && p_mb_params->data_src_size)\n\t\tmemcpy(&union_data, p_mb_params->p_data_src,\n\t\t       p_mb_params->data_src_size);\n\tqed_memcpy_to(p_hwfn, p_ptt, union_data_addr, &union_data,\n\t\t      sizeof(union_data));\n\n\t \n\tDRV_MB_WR(p_hwfn, p_ptt, drv_mb_param, p_mb_params->param);\n\n\t \n\tDRV_MB_WR(p_hwfn, p_ptt, drv_mb_header, (p_mb_params->cmd | seq_num));\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"MFW mailbox: command 0x%08x param 0x%08x\\n\",\n\t\t   (p_mb_params->cmd | seq_num), p_mb_params->param);\n}\n\nstatic void qed_mcp_cmd_set_blocking(struct qed_hwfn *p_hwfn, bool block_cmd)\n{\n\tp_hwfn->mcp_info->b_block_cmd = block_cmd;\n\n\tDP_INFO(p_hwfn, \"%s sending of mailbox commands to the MFW\\n\",\n\t\tblock_cmd ? \"Block\" : \"Unblock\");\n}\n\nstatic void qed_mcp_print_cpu_info(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt)\n{\n\tu32 cpu_mode, cpu_state, cpu_pc_0, cpu_pc_1, cpu_pc_2;\n\tu32 delay = QED_MCP_RESP_ITER_US;\n\n\tcpu_mode = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_MODE);\n\tcpu_state = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_STATE);\n\tcpu_pc_0 = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_PROGRAM_COUNTER);\n\tudelay(delay);\n\tcpu_pc_1 = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_PROGRAM_COUNTER);\n\tudelay(delay);\n\tcpu_pc_2 = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_PROGRAM_COUNTER);\n\n\tDP_NOTICE(p_hwfn,\n\t\t  \"MCP CPU info: mode 0x%08x, state 0x%08x, pc {0x%08x, 0x%08x, 0x%08x}\\n\",\n\t\t  cpu_mode, cpu_state, cpu_pc_0, cpu_pc_1, cpu_pc_2);\n}\n\nstatic int\n_qed_mcp_cmd_and_union(struct qed_hwfn *p_hwfn,\n\t\t       struct qed_ptt *p_ptt,\n\t\t       struct qed_mcp_mb_params *p_mb_params,\n\t\t       u32 max_retries, u32 usecs)\n{\n\tu32 cnt = 0, msecs = DIV_ROUND_UP(usecs, 1000);\n\tstruct qed_mcp_cmd_elem *p_cmd_elem;\n\tu16 seq_num;\n\tint rc = 0;\n\n\t \n\tdo {\n\t\t \n\n\t\tspin_lock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\t\tif (!qed_mcp_has_pending_cmd(p_hwfn))\n\t\t\tbreak;\n\n\t\trc = qed_mcp_update_pending_cmd(p_hwfn, p_ptt);\n\t\tif (!rc)\n\t\t\tbreak;\n\t\telse if (rc != -EAGAIN)\n\t\t\tgoto err;\n\n\t\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\t\tif (QED_MB_FLAGS_IS_SET(p_mb_params, CAN_SLEEP))\n\t\t\tmsleep(msecs);\n\t\telse\n\t\t\tudelay(usecs);\n\t} while (++cnt < max_retries);\n\n\tif (cnt >= max_retries) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The MFW mailbox is occupied by an uncompleted command. Failed to send command 0x%08x [param 0x%08x].\\n\",\n\t\t\t  p_mb_params->cmd, p_mb_params->param);\n\t\treturn -EAGAIN;\n\t}\n\n\t \n\tqed_mcp_reread_offsets(p_hwfn, p_ptt);\n\tseq_num = ++p_hwfn->mcp_info->drv_mb_seq;\n\tp_cmd_elem = qed_mcp_cmd_add_elem(p_hwfn, p_mb_params, seq_num);\n\tif (!p_cmd_elem) {\n\t\trc = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t__qed_mcp_cmd_and_union(p_hwfn, p_ptt, p_mb_params, seq_num);\n\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\t \n\tdo {\n\t\t \n\n\t\tif (QED_MB_FLAGS_IS_SET(p_mb_params, CAN_SLEEP))\n\t\t\tmsleep(msecs);\n\t\telse\n\t\t\tudelay(usecs);\n\n\t\tspin_lock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\t\tif (p_cmd_elem->b_is_completed)\n\t\t\tbreak;\n\n\t\trc = qed_mcp_update_pending_cmd(p_hwfn, p_ptt);\n\t\tif (!rc)\n\t\t\tbreak;\n\t\telse if (rc != -EAGAIN)\n\t\t\tgoto err;\n\n\t\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\t} while (++cnt < max_retries);\n\n\tif (cnt >= max_retries) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The MFW failed to respond to command 0x%08x [param 0x%08x].\\n\",\n\t\t\t  p_mb_params->cmd, p_mb_params->param);\n\t\tqed_mcp_print_cpu_info(p_hwfn, p_ptt);\n\n\t\tspin_lock_bh(&p_hwfn->mcp_info->cmd_lock);\n\t\tqed_mcp_cmd_del_elem(p_hwfn, p_cmd_elem);\n\t\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\t\tif (!QED_MB_FLAGS_IS_SET(p_mb_params, AVOID_BLOCK))\n\t\t\tqed_mcp_cmd_set_blocking(p_hwfn, true);\n\n\t\tqed_hw_err_notify(p_hwfn, p_ptt,\n\t\t\t\t  QED_HW_ERR_MFW_RESP_FAIL, NULL);\n\t\treturn -EAGAIN;\n\t}\n\n\tqed_mcp_cmd_del_elem(p_hwfn, p_cmd_elem);\n\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SP,\n\t\t   \"MFW mailbox: response 0x%08x param 0x%08x [after %d.%03d ms]\\n\",\n\t\t   p_mb_params->mcp_resp,\n\t\t   p_mb_params->mcp_param,\n\t\t   (cnt * usecs) / 1000, (cnt * usecs) % 1000);\n\n\t \n\tp_mb_params->mcp_resp &= FW_MSG_CODE_MASK;\n\n\treturn 0;\n\nerr:\n\tspin_unlock_bh(&p_hwfn->mcp_info->cmd_lock);\n\treturn rc;\n}\n\nstatic int qed_mcp_cmd_and_union(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt,\n\t\t\t\t struct qed_mcp_mb_params *p_mb_params)\n{\n\tsize_t union_data_size = sizeof(union drv_union_data);\n\tu32 max_retries = QED_DRV_MB_MAX_RETRIES;\n\tu32 usecs = QED_MCP_RESP_ITER_US;\n\n\t \n\tif (!qed_mcp_is_init(p_hwfn)) {\n\t\tDP_NOTICE(p_hwfn, \"MFW is not initialized!\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\tif (p_hwfn->mcp_info->b_block_cmd) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The MFW is not responsive. Avoid sending mailbox command 0x%08x [param 0x%08x].\\n\",\n\t\t\t  p_mb_params->cmd, p_mb_params->param);\n\t\treturn -EBUSY;\n\t}\n\n\tif (p_mb_params->data_src_size > union_data_size ||\n\t    p_mb_params->data_dst_size > union_data_size) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"The provided size is larger than the union data size [src_size %u, dst_size %u, union_data_size %zu]\\n\",\n\t\t       p_mb_params->data_src_size,\n\t\t       p_mb_params->data_dst_size, union_data_size);\n\t\treturn -EINVAL;\n\t}\n\n\tif (QED_MB_FLAGS_IS_SET(p_mb_params, CAN_SLEEP)) {\n\t\tmax_retries = DIV_ROUND_UP(max_retries, 1000);\n\t\tusecs *= 1000;\n\t}\n\n\treturn _qed_mcp_cmd_and_union(p_hwfn, p_ptt, p_mb_params, max_retries,\n\t\t\t\t      usecs);\n}\n\nstatic int _qed_mcp_cmd(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_ptt *p_ptt,\n\t\t\tu32 cmd,\n\t\t\tu32 param,\n\t\t\tu32 *o_mcp_resp,\n\t\t\tu32 *o_mcp_param,\n\t\t\tbool can_sleep)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tint rc;\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = cmd;\n\tmb_params.param = param;\n\tmb_params.flags = can_sleep ? QED_MB_FLAG_CAN_SLEEP : 0;\n\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\t*o_mcp_resp = mb_params.mcp_resp;\n\t*o_mcp_param = mb_params.mcp_param;\n\n\treturn 0;\n}\n\nint qed_mcp_cmd(struct qed_hwfn *p_hwfn,\n\t\tstruct qed_ptt *p_ptt,\n\t\tu32 cmd,\n\t\tu32 param,\n\t\tu32 *o_mcp_resp,\n\t\tu32 *o_mcp_param)\n{\n\treturn (_qed_mcp_cmd(p_hwfn, p_ptt, cmd, param,\n\t\t\t     o_mcp_resp, o_mcp_param, true));\n}\n\nint qed_mcp_cmd_nosleep(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_ptt *p_ptt,\n\t\t\tu32 cmd,\n\t\t\tu32 param,\n\t\t\tu32 *o_mcp_resp,\n\t\t\tu32 *o_mcp_param)\n{\n\treturn (_qed_mcp_cmd(p_hwfn, p_ptt, cmd, param,\n\t\t\t     o_mcp_resp, o_mcp_param, false));\n}\n\nstatic int\nqed_mcp_nvm_wr_cmd(struct qed_hwfn *p_hwfn,\n\t\t   struct qed_ptt *p_ptt,\n\t\t   u32 cmd,\n\t\t   u32 param,\n\t\t   u32 *o_mcp_resp,\n\t\t   u32 *o_mcp_param, u32 i_txn_size, u32 *i_buf)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tint rc;\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = cmd;\n\tmb_params.param = param;\n\tmb_params.p_data_src = i_buf;\n\tmb_params.data_src_size = (u8)i_txn_size;\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\t*o_mcp_resp = mb_params.mcp_resp;\n\t*o_mcp_param = mb_params.mcp_param;\n\n\t \n\tp_hwfn->nvm_info.valid = false;\n\n\treturn 0;\n}\n\nint qed_mcp_nvm_rd_cmd(struct qed_hwfn *p_hwfn,\n\t\t       struct qed_ptt *p_ptt,\n\t\t       u32 cmd,\n\t\t       u32 param,\n\t\t       u32 *o_mcp_resp,\n\t\t       u32 *o_mcp_param,\n\t\t       u32 *o_txn_size, u32 *o_buf, bool b_can_sleep)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tu8 raw_data[MCP_DRV_NVM_BUF_LEN];\n\tint rc;\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = cmd;\n\tmb_params.param = param;\n\tmb_params.p_data_dst = raw_data;\n\n\t \n\tmb_params.data_dst_size = MCP_DRV_NVM_BUF_LEN;\n\tif (b_can_sleep)\n\t\tmb_params.flags = QED_MB_FLAG_CAN_SLEEP;\n\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\t*o_mcp_resp = mb_params.mcp_resp;\n\t*o_mcp_param = mb_params.mcp_param;\n\n\t*o_txn_size = *o_mcp_param;\n\tmemcpy(o_buf, raw_data, *o_txn_size);\n\n\treturn 0;\n}\n\nstatic bool\nqed_mcp_can_force_load(u8 drv_role,\n\t\t       u8 exist_drv_role,\n\t\t       enum qed_override_force_load override_force_load)\n{\n\tbool can_force_load = false;\n\n\tswitch (override_force_load) {\n\tcase QED_OVERRIDE_FORCE_LOAD_ALWAYS:\n\t\tcan_force_load = true;\n\t\tbreak;\n\tcase QED_OVERRIDE_FORCE_LOAD_NEVER:\n\t\tcan_force_load = false;\n\t\tbreak;\n\tdefault:\n\t\tcan_force_load = (drv_role == DRV_ROLE_OS &&\n\t\t\t\t  exist_drv_role == DRV_ROLE_PREBOOT) ||\n\t\t\t\t (drv_role == DRV_ROLE_KDUMP &&\n\t\t\t\t  exist_drv_role == DRV_ROLE_OS);\n\t\tbreak;\n\t}\n\n\treturn can_force_load;\n}\n\nstatic int qed_mcp_cancel_load_req(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt)\n{\n\tu32 resp = 0, param = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_CANCEL_LOAD_REQ, 0,\n\t\t\t &resp, &param);\n\tif (rc)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to send cancel load request, rc = %d\\n\", rc);\n\n\treturn rc;\n}\n\n#define BITMAP_IDX_FOR_CONFIG_QEDE\tBIT(0)\n#define BITMAP_IDX_FOR_CONFIG_QED_SRIOV\tBIT(1)\n#define BITMAP_IDX_FOR_CONFIG_QEDR\tBIT(2)\n#define BITMAP_IDX_FOR_CONFIG_QEDF\tBIT(4)\n#define BITMAP_IDX_FOR_CONFIG_QEDI\tBIT(5)\n#define BITMAP_IDX_FOR_CONFIG_QED_LL2\tBIT(6)\n\nstatic u32 qed_get_config_bitmap(void)\n{\n\tu32 config_bitmap = 0x0;\n\n\tif (IS_ENABLED(CONFIG_QEDE))\n\t\tconfig_bitmap |= BITMAP_IDX_FOR_CONFIG_QEDE;\n\n\tif (IS_ENABLED(CONFIG_QED_SRIOV))\n\t\tconfig_bitmap |= BITMAP_IDX_FOR_CONFIG_QED_SRIOV;\n\n\tif (IS_ENABLED(CONFIG_QED_RDMA))\n\t\tconfig_bitmap |= BITMAP_IDX_FOR_CONFIG_QEDR;\n\n\tif (IS_ENABLED(CONFIG_QED_FCOE))\n\t\tconfig_bitmap |= BITMAP_IDX_FOR_CONFIG_QEDF;\n\n\tif (IS_ENABLED(CONFIG_QED_ISCSI))\n\t\tconfig_bitmap |= BITMAP_IDX_FOR_CONFIG_QEDI;\n\n\tif (IS_ENABLED(CONFIG_QED_LL2))\n\t\tconfig_bitmap |= BITMAP_IDX_FOR_CONFIG_QED_LL2;\n\n\treturn config_bitmap;\n}\n\nstruct qed_load_req_in_params {\n\tu8 hsi_ver;\n#define QED_LOAD_REQ_HSI_VER_DEFAULT\t0\n#define QED_LOAD_REQ_HSI_VER_1\t\t1\n\tu32 drv_ver_0;\n\tu32 drv_ver_1;\n\tu32 fw_ver;\n\tu8 drv_role;\n\tu8 timeout_val;\n\tu8 force_cmd;\n\tbool avoid_eng_reset;\n};\n\nstruct qed_load_req_out_params {\n\tu32 load_code;\n\tu32 exist_drv_ver_0;\n\tu32 exist_drv_ver_1;\n\tu32 exist_fw_ver;\n\tu8 exist_drv_role;\n\tu8 mfw_hsi_ver;\n\tbool drv_exists;\n};\n\nstatic int\n__qed_mcp_load_req(struct qed_hwfn *p_hwfn,\n\t\t   struct qed_ptt *p_ptt,\n\t\t   struct qed_load_req_in_params *p_in_params,\n\t\t   struct qed_load_req_out_params *p_out_params)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tstruct load_req_stc load_req;\n\tstruct load_rsp_stc load_rsp;\n\tu32 hsi_ver;\n\tint rc;\n\n\tmemset(&load_req, 0, sizeof(load_req));\n\tload_req.drv_ver_0 = p_in_params->drv_ver_0;\n\tload_req.drv_ver_1 = p_in_params->drv_ver_1;\n\tload_req.fw_ver = p_in_params->fw_ver;\n\tQED_MFW_SET_FIELD(load_req.misc0, LOAD_REQ_ROLE, p_in_params->drv_role);\n\tQED_MFW_SET_FIELD(load_req.misc0, LOAD_REQ_LOCK_TO,\n\t\t\t  p_in_params->timeout_val);\n\tQED_MFW_SET_FIELD(load_req.misc0, LOAD_REQ_FORCE,\n\t\t\t  p_in_params->force_cmd);\n\tQED_MFW_SET_FIELD(load_req.misc0, LOAD_REQ_FLAGS0,\n\t\t\t  p_in_params->avoid_eng_reset);\n\n\thsi_ver = (p_in_params->hsi_ver == QED_LOAD_REQ_HSI_VER_DEFAULT) ?\n\t\t  DRV_ID_MCP_HSI_VER_CURRENT :\n\t\t  (p_in_params->hsi_ver << DRV_ID_MCP_HSI_VER_SHIFT);\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_LOAD_REQ;\n\tmb_params.param = PDA_COMP | hsi_ver | p_hwfn->cdev->drv_type;\n\tmb_params.p_data_src = &load_req;\n\tmb_params.data_src_size = sizeof(load_req);\n\tmb_params.p_data_dst = &load_rsp;\n\tmb_params.data_dst_size = sizeof(load_rsp);\n\tmb_params.flags = QED_MB_FLAG_CAN_SLEEP | QED_MB_FLAG_AVOID_BLOCK;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"Load Request: param 0x%08x [init_hw %d, drv_type %d, hsi_ver %d, pda 0x%04x]\\n\",\n\t\t   mb_params.param,\n\t\t   QED_MFW_GET_FIELD(mb_params.param, DRV_ID_DRV_INIT_HW),\n\t\t   QED_MFW_GET_FIELD(mb_params.param, DRV_ID_DRV_TYPE),\n\t\t   QED_MFW_GET_FIELD(mb_params.param, DRV_ID_MCP_HSI_VER),\n\t\t   QED_MFW_GET_FIELD(mb_params.param, DRV_ID_PDA_COMP_VER));\n\n\tif (p_in_params->hsi_ver != QED_LOAD_REQ_HSI_VER_1) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"Load Request: drv_ver 0x%08x_0x%08x, fw_ver 0x%08x, misc0 0x%08x [role %d, timeout %d, force %d, flags0 0x%x]\\n\",\n\t\t\t   load_req.drv_ver_0,\n\t\t\t   load_req.drv_ver_1,\n\t\t\t   load_req.fw_ver,\n\t\t\t   load_req.misc0,\n\t\t\t   QED_MFW_GET_FIELD(load_req.misc0, LOAD_REQ_ROLE),\n\t\t\t   QED_MFW_GET_FIELD(load_req.misc0,\n\t\t\t\t\t     LOAD_REQ_LOCK_TO),\n\t\t\t   QED_MFW_GET_FIELD(load_req.misc0, LOAD_REQ_FORCE),\n\t\t\t   QED_MFW_GET_FIELD(load_req.misc0, LOAD_REQ_FLAGS0));\n\t}\n\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to send load request, rc = %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"Load Response: resp 0x%08x\\n\", mb_params.mcp_resp);\n\tp_out_params->load_code = mb_params.mcp_resp;\n\n\tif (p_in_params->hsi_ver != QED_LOAD_REQ_HSI_VER_1 &&\n\t    p_out_params->load_code != FW_MSG_CODE_DRV_LOAD_REFUSED_HSI_1) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_SP,\n\t\t\t   \"Load Response: exist_drv_ver 0x%08x_0x%08x, exist_fw_ver 0x%08x, misc0 0x%08x [exist_role %d, mfw_hsi %d, flags0 0x%x]\\n\",\n\t\t\t   load_rsp.drv_ver_0,\n\t\t\t   load_rsp.drv_ver_1,\n\t\t\t   load_rsp.fw_ver,\n\t\t\t   load_rsp.misc0,\n\t\t\t   QED_MFW_GET_FIELD(load_rsp.misc0, LOAD_RSP_ROLE),\n\t\t\t   QED_MFW_GET_FIELD(load_rsp.misc0, LOAD_RSP_HSI),\n\t\t\t   QED_MFW_GET_FIELD(load_rsp.misc0, LOAD_RSP_FLAGS0));\n\n\t\tp_out_params->exist_drv_ver_0 = load_rsp.drv_ver_0;\n\t\tp_out_params->exist_drv_ver_1 = load_rsp.drv_ver_1;\n\t\tp_out_params->exist_fw_ver = load_rsp.fw_ver;\n\t\tp_out_params->exist_drv_role =\n\t\t    QED_MFW_GET_FIELD(load_rsp.misc0, LOAD_RSP_ROLE);\n\t\tp_out_params->mfw_hsi_ver =\n\t\t    QED_MFW_GET_FIELD(load_rsp.misc0, LOAD_RSP_HSI);\n\t\tp_out_params->drv_exists =\n\t\t    QED_MFW_GET_FIELD(load_rsp.misc0, LOAD_RSP_FLAGS0) &\n\t\t    LOAD_RSP_FLAGS0_DRV_EXISTS;\n\t}\n\n\treturn 0;\n}\n\nstatic int eocre_get_mfw_drv_role(struct qed_hwfn *p_hwfn,\n\t\t\t\t  enum qed_drv_role drv_role,\n\t\t\t\t  u8 *p_mfw_drv_role)\n{\n\tswitch (drv_role) {\n\tcase QED_DRV_ROLE_OS:\n\t\t*p_mfw_drv_role = DRV_ROLE_OS;\n\t\tbreak;\n\tcase QED_DRV_ROLE_KDUMP:\n\t\t*p_mfw_drv_role = DRV_ROLE_KDUMP;\n\t\tbreak;\n\tdefault:\n\t\tDP_ERR(p_hwfn, \"Unexpected driver role %d\\n\", drv_role);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nenum qed_load_req_force {\n\tQED_LOAD_REQ_FORCE_NONE,\n\tQED_LOAD_REQ_FORCE_PF,\n\tQED_LOAD_REQ_FORCE_ALL,\n};\n\nstatic void qed_get_mfw_force_cmd(struct qed_hwfn *p_hwfn,\n\t\t\t\t  enum qed_load_req_force force_cmd,\n\t\t\t\t  u8 *p_mfw_force_cmd)\n{\n\tswitch (force_cmd) {\n\tcase QED_LOAD_REQ_FORCE_NONE:\n\t\t*p_mfw_force_cmd = LOAD_REQ_FORCE_NONE;\n\t\tbreak;\n\tcase QED_LOAD_REQ_FORCE_PF:\n\t\t*p_mfw_force_cmd = LOAD_REQ_FORCE_PF;\n\t\tbreak;\n\tcase QED_LOAD_REQ_FORCE_ALL:\n\t\t*p_mfw_force_cmd = LOAD_REQ_FORCE_ALL;\n\t\tbreak;\n\t}\n}\n\nint qed_mcp_load_req(struct qed_hwfn *p_hwfn,\n\t\t     struct qed_ptt *p_ptt,\n\t\t     struct qed_load_req_params *p_params)\n{\n\tstruct qed_load_req_out_params out_params;\n\tstruct qed_load_req_in_params in_params;\n\tu8 mfw_drv_role, mfw_force_cmd;\n\tint rc;\n\n\tmemset(&in_params, 0, sizeof(in_params));\n\tin_params.hsi_ver = QED_LOAD_REQ_HSI_VER_DEFAULT;\n\tin_params.drv_ver_1 = qed_get_config_bitmap();\n\tin_params.fw_ver = STORM_FW_VERSION;\n\trc = eocre_get_mfw_drv_role(p_hwfn, p_params->drv_role, &mfw_drv_role);\n\tif (rc)\n\t\treturn rc;\n\n\tin_params.drv_role = mfw_drv_role;\n\tin_params.timeout_val = p_params->timeout_val;\n\tqed_get_mfw_force_cmd(p_hwfn,\n\t\t\t      QED_LOAD_REQ_FORCE_NONE, &mfw_force_cmd);\n\n\tin_params.force_cmd = mfw_force_cmd;\n\tin_params.avoid_eng_reset = p_params->avoid_eng_reset;\n\n\tmemset(&out_params, 0, sizeof(out_params));\n\trc = __qed_mcp_load_req(p_hwfn, p_ptt, &in_params, &out_params);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (out_params.load_code == FW_MSG_CODE_DRV_LOAD_REFUSED_HSI_1) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"MFW refused a load request due to HSI > 1. Resending with HSI = 1\\n\");\n\n\t\tin_params.hsi_ver = QED_LOAD_REQ_HSI_VER_1;\n\t\tmemset(&out_params, 0, sizeof(out_params));\n\t\trc = __qed_mcp_load_req(p_hwfn, p_ptt, &in_params, &out_params);\n\t\tif (rc)\n\t\t\treturn rc;\n\t} else if (out_params.load_code ==\n\t\t   FW_MSG_CODE_DRV_LOAD_REFUSED_REQUIRES_FORCE) {\n\t\tif (qed_mcp_can_force_load(in_params.drv_role,\n\t\t\t\t\t   out_params.exist_drv_role,\n\t\t\t\t\t   p_params->override_force_load)) {\n\t\t\tDP_INFO(p_hwfn,\n\t\t\t\t\"A force load is required [{role, fw_ver, drv_ver}: loading={%d, 0x%08x, x%08x_0x%08x}, existing={%d, 0x%08x, 0x%08x_0x%08x}]\\n\",\n\t\t\t\tin_params.drv_role, in_params.fw_ver,\n\t\t\t\tin_params.drv_ver_0, in_params.drv_ver_1,\n\t\t\t\tout_params.exist_drv_role,\n\t\t\t\tout_params.exist_fw_ver,\n\t\t\t\tout_params.exist_drv_ver_0,\n\t\t\t\tout_params.exist_drv_ver_1);\n\n\t\t\tqed_get_mfw_force_cmd(p_hwfn,\n\t\t\t\t\t      QED_LOAD_REQ_FORCE_ALL,\n\t\t\t\t\t      &mfw_force_cmd);\n\n\t\t\tin_params.force_cmd = mfw_force_cmd;\n\t\t\tmemset(&out_params, 0, sizeof(out_params));\n\t\t\trc = __qed_mcp_load_req(p_hwfn, p_ptt, &in_params,\n\t\t\t\t\t\t&out_params);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t} else {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"A force load is required [{role, fw_ver, drv_ver}: loading={%d, 0x%08x, x%08x_0x%08x}, existing={%d, 0x%08x, 0x%08x_0x%08x}] - Avoid\\n\",\n\t\t\t\t  in_params.drv_role, in_params.fw_ver,\n\t\t\t\t  in_params.drv_ver_0, in_params.drv_ver_1,\n\t\t\t\t  out_params.exist_drv_role,\n\t\t\t\t  out_params.exist_fw_ver,\n\t\t\t\t  out_params.exist_drv_ver_0,\n\t\t\t\t  out_params.exist_drv_ver_1);\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Avoid sending a force load request to prevent disruption of active PFs\\n\");\n\n\t\t\tqed_mcp_cancel_load_req(p_hwfn, p_ptt);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\t \n\tswitch (out_params.load_code) {\n\tcase FW_MSG_CODE_DRV_LOAD_ENGINE:\n\tcase FW_MSG_CODE_DRV_LOAD_PORT:\n\tcase FW_MSG_CODE_DRV_LOAD_FUNCTION:\n\t\tif (out_params.mfw_hsi_ver != QED_LOAD_REQ_HSI_VER_1 &&\n\t\t    out_params.drv_exists) {\n\t\t\t \n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"PF is already loaded\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unexpected refusal to load request [resp 0x%08x]. Aborting.\\n\",\n\t\t\t  out_params.load_code);\n\t\treturn -EBUSY;\n\t}\n\n\tp_params->load_code = out_params.load_code;\n\n\treturn 0;\n}\n\nint qed_mcp_load_done(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 resp = 0, param = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_LOAD_DONE, 0, &resp,\n\t\t\t &param);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to send a LOAD_DONE command, rc = %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\tif (param & FW_MB_PARAM_LOAD_DONE_DID_EFUSE_ERROR)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"warning: device configuration is not supported on this board type. The device may not function as expected.\\n\");\n\n\treturn 0;\n}\n\n#define MFW_COMPLETION_MAX_ITER 5000\n#define MFW_COMPLETION_INTERVAL_MS 1\n\nint qed_mcp_unload_req(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tu32 cnt = MFW_COMPLETION_MAX_ITER;\n\tu32 wol_param;\n\tint rc;\n\n\tswitch (p_hwfn->cdev->wol_config) {\n\tcase QED_OV_WOL_DISABLED:\n\t\twol_param = DRV_MB_PARAM_UNLOAD_WOL_DISABLED;\n\t\tbreak;\n\tcase QED_OV_WOL_ENABLED:\n\t\twol_param = DRV_MB_PARAM_UNLOAD_WOL_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unknown WoL configuration %02x\\n\",\n\t\t\t  p_hwfn->cdev->wol_config);\n\t\tfallthrough;\n\tcase QED_OV_WOL_DEFAULT:\n\t\twol_param = DRV_MB_PARAM_UNLOAD_WOL_MCP;\n\t}\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_UNLOAD_REQ;\n\tmb_params.param = wol_param;\n\tmb_params.flags = QED_MB_FLAG_CAN_SLEEP | QED_MB_FLAG_AVOID_BLOCK;\n\n\tspin_lock_bh(&p_hwfn->mcp_info->unload_lock);\n\tset_bit(QED_MCP_BYPASS_PROC_BIT,\n\t\t&p_hwfn->mcp_info->mcp_handling_status);\n\tspin_unlock_bh(&p_hwfn->mcp_info->unload_lock);\n\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\n\twhile (test_bit(QED_MCP_IN_PROCESSING_BIT,\n\t\t\t&p_hwfn->mcp_info->mcp_handling_status) && --cnt)\n\t\tmsleep(MFW_COMPLETION_INTERVAL_MS);\n\n\tif (!cnt)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to wait MFW event completion after %d msec\\n\",\n\t\t\t  MFW_COMPLETION_MAX_ITER * MFW_COMPLETION_INTERVAL_MS);\n\n\treturn rc;\n}\n\nint qed_mcp_unload_done(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tstruct mcp_mac wol_mac;\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_UNLOAD_DONE;\n\n\t \n\tif (p_hwfn->cdev->wol_config == QED_OV_WOL_ENABLED) {\n\t\tu8 *p_mac = p_hwfn->cdev->wol_mac;\n\n\t\tmemset(&wol_mac, 0, sizeof(wol_mac));\n\t\twol_mac.mac_upper = p_mac[0] << 8 | p_mac[1];\n\t\twol_mac.mac_lower = p_mac[2] << 24 | p_mac[3] << 16 |\n\t\t\t\t    p_mac[4] << 8 | p_mac[5];\n\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   (QED_MSG_SP | NETIF_MSG_IFDOWN),\n\t\t\t   \"Setting WoL MAC: %pM --> [%08x,%08x]\\n\",\n\t\t\t   p_mac, wol_mac.mac_upper, wol_mac.mac_lower);\n\n\t\tmb_params.p_data_src = &wol_mac;\n\t\tmb_params.data_src_size = sizeof(wol_mac);\n\t}\n\n\treturn qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n}\n\nstatic void qed_mcp_handle_vf_flr(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_ptt *p_ptt)\n{\n\tu32 addr = SECTION_OFFSIZE_ADDR(p_hwfn->mcp_info->public_base,\n\t\t\t\t\tPUBLIC_PATH);\n\tu32 mfw_path_offsize = qed_rd(p_hwfn, p_ptt, addr);\n\tu32 path_addr = SECTION_ADDR(mfw_path_offsize,\n\t\t\t\t     QED_PATH_ID(p_hwfn));\n\tu32 disabled_vfs[VF_MAX_STATIC / 32];\n\tint i;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SP,\n\t\t   \"Reading Disabled VF information from [offset %08x], path_addr %08x\\n\",\n\t\t   mfw_path_offsize, path_addr);\n\n\tfor (i = 0; i < (VF_MAX_STATIC / 32); i++) {\n\t\tdisabled_vfs[i] = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t path_addr +\n\t\t\t\t\t offsetof(struct public_path,\n\t\t\t\t\t\t  mcp_vf_disabled) +\n\t\t\t\t\t sizeof(u32) * i);\n\t\tDP_VERBOSE(p_hwfn, (QED_MSG_SP | QED_MSG_IOV),\n\t\t\t   \"FLR-ed VFs [%08x,...,%08x] - %08x\\n\",\n\t\t\t   i * 32, (i + 1) * 32 - 1, disabled_vfs[i]);\n\t}\n\n\tif (qed_iov_mark_vf_flr(p_hwfn, disabled_vfs))\n\t\tqed_schedule_iov(p_hwfn, QED_IOV_WQ_FLR_FLAG);\n}\n\nint qed_mcp_ack_vf_flr(struct qed_hwfn *p_hwfn,\n\t\t       struct qed_ptt *p_ptt, u32 *vfs_to_ack)\n{\n\tu32 addr = SECTION_OFFSIZE_ADDR(p_hwfn->mcp_info->public_base,\n\t\t\t\t\tPUBLIC_FUNC);\n\tu32 mfw_func_offsize = qed_rd(p_hwfn, p_ptt, addr);\n\tu32 func_addr = SECTION_ADDR(mfw_func_offsize,\n\t\t\t\t     MCP_PF_ID(p_hwfn));\n\tstruct qed_mcp_mb_params mb_params;\n\tint rc;\n\tint i;\n\n\tfor (i = 0; i < (VF_MAX_STATIC / 32); i++)\n\t\tDP_VERBOSE(p_hwfn, (QED_MSG_SP | QED_MSG_IOV),\n\t\t\t   \"Acking VFs [%08x,...,%08x] - %08x\\n\",\n\t\t\t   i * 32, (i + 1) * 32 - 1, vfs_to_ack[i]);\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_VF_DISABLED_DONE;\n\tmb_params.p_data_src = vfs_to_ack;\n\tmb_params.data_src_size = VF_MAX_STATIC / 8;\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to pass ACK for VF flr to MFW\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tfor (i = 0; i < (VF_MAX_STATIC / 32); i++)\n\t\tqed_wr(p_hwfn, p_ptt,\n\t\t       func_addr +\n\t\t       offsetof(struct public_func, drv_ack_vf_disabled) +\n\t\t       i * sizeof(u32), 0);\n\n\treturn rc;\n}\n\nstatic void qed_mcp_handle_transceiver_change(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t      struct qed_ptt *p_ptt)\n{\n\tu32 transceiver_state;\n\n\ttransceiver_state = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t   p_hwfn->mcp_info->port_addr +\n\t\t\t\t   offsetof(struct public_port,\n\t\t\t\t\t    transceiver_data));\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   (NETIF_MSG_HW | QED_MSG_SP),\n\t\t   \"Received transceiver state update [0x%08x] from mfw [Addr 0x%x]\\n\",\n\t\t   transceiver_state,\n\t\t   (u32)(p_hwfn->mcp_info->port_addr +\n\t\t\t  offsetof(struct public_port, transceiver_data)));\n\n\ttransceiver_state = GET_FIELD(transceiver_state,\n\t\t\t\t      ETH_TRANSCEIVER_STATE);\n\n\tif (transceiver_state == ETH_TRANSCEIVER_STATE_PRESENT)\n\t\tDP_NOTICE(p_hwfn, \"Transceiver is present.\\n\");\n\telse\n\t\tDP_NOTICE(p_hwfn, \"Transceiver is unplugged.\\n\");\n}\n\nstatic void qed_mcp_read_eee_config(struct qed_hwfn *p_hwfn,\n\t\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t\t    struct qed_mcp_link_state *p_link)\n{\n\tu32 eee_status, val;\n\n\tp_link->eee_adv_caps = 0;\n\tp_link->eee_lp_adv_caps = 0;\n\teee_status = qed_rd(p_hwfn,\n\t\t\t    p_ptt,\n\t\t\t    p_hwfn->mcp_info->port_addr +\n\t\t\t    offsetof(struct public_port, eee_status));\n\tp_link->eee_active = !!(eee_status & EEE_ACTIVE_BIT);\n\tval = (eee_status & EEE_LD_ADV_STATUS_MASK) >> EEE_LD_ADV_STATUS_OFFSET;\n\tif (val & EEE_1G_ADV)\n\t\tp_link->eee_adv_caps |= QED_EEE_1G_ADV;\n\tif (val & EEE_10G_ADV)\n\t\tp_link->eee_adv_caps |= QED_EEE_10G_ADV;\n\tval = (eee_status & EEE_LP_ADV_STATUS_MASK) >> EEE_LP_ADV_STATUS_OFFSET;\n\tif (val & EEE_1G_ADV)\n\t\tp_link->eee_lp_adv_caps |= QED_EEE_1G_ADV;\n\tif (val & EEE_10G_ADV)\n\t\tp_link->eee_lp_adv_caps |= QED_EEE_10G_ADV;\n}\n\nstatic u32 qed_mcp_get_shmem_func(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct qed_ptt *p_ptt,\n\t\t\t\t  struct public_func *p_data, int pfid)\n{\n\tu32 addr = SECTION_OFFSIZE_ADDR(p_hwfn->mcp_info->public_base,\n\t\t\t\t\tPUBLIC_FUNC);\n\tu32 mfw_path_offsize = qed_rd(p_hwfn, p_ptt, addr);\n\tu32 func_addr;\n\tu32 i, size;\n\n\tfunc_addr = SECTION_ADDR(mfw_path_offsize, pfid);\n\tmemset(p_data, 0, sizeof(*p_data));\n\n\tsize = min_t(u32, sizeof(*p_data), QED_SECTION_SIZE(mfw_path_offsize));\n\tfor (i = 0; i < size / sizeof(u32); i++)\n\t\t((u32 *)p_data)[i] = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t    func_addr + (i << 2));\n\treturn size;\n}\n\nstatic void qed_read_pf_bandwidth(struct qed_hwfn *p_hwfn,\n\t\t\t\t  struct public_func *p_shmem_info)\n{\n\tstruct qed_mcp_function_info *p_info;\n\n\tp_info = &p_hwfn->mcp_info->func_info;\n\n\tp_info->bandwidth_min = QED_MFW_GET_FIELD(p_shmem_info->config,\n\t\t\t\t\t\t  FUNC_MF_CFG_MIN_BW);\n\tif (p_info->bandwidth_min < 1 || p_info->bandwidth_min > 100) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"bandwidth minimum out of bounds [%02x]. Set to 1\\n\",\n\t\t\tp_info->bandwidth_min);\n\t\tp_info->bandwidth_min = 1;\n\t}\n\n\tp_info->bandwidth_max = QED_MFW_GET_FIELD(p_shmem_info->config,\n\t\t\t\t\t\t  FUNC_MF_CFG_MAX_BW);\n\tif (p_info->bandwidth_max < 1 || p_info->bandwidth_max > 100) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"bandwidth maximum out of bounds [%02x]. Set to 100\\n\",\n\t\t\tp_info->bandwidth_max);\n\t\tp_info->bandwidth_max = 100;\n\t}\n}\n\nstatic void qed_mcp_handle_link_change(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt, bool b_reset)\n{\n\tstruct qed_mcp_link_state *p_link;\n\tu8 max_bw, min_bw;\n\tu32 status = 0;\n\n\t \n\tspin_lock_bh(&p_hwfn->mcp_info->link_lock);\n\n\tp_link = &p_hwfn->mcp_info->link_output;\n\tmemset(p_link, 0, sizeof(*p_link));\n\tif (!b_reset) {\n\t\tstatus = qed_rd(p_hwfn, p_ptt,\n\t\t\t\tp_hwfn->mcp_info->port_addr +\n\t\t\t\toffsetof(struct public_port, link_status));\n\t\tDP_VERBOSE(p_hwfn, (NETIF_MSG_LINK | QED_MSG_SP),\n\t\t\t   \"Received link update [0x%08x] from mfw [Addr 0x%x]\\n\",\n\t\t\t   status,\n\t\t\t   (u32)(p_hwfn->mcp_info->port_addr +\n\t\t\t\t offsetof(struct public_port, link_status)));\n\t} else {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Resetting link indications\\n\");\n\t\tgoto out;\n\t}\n\n\tif (p_hwfn->b_drv_link_init) {\n\t\t \n\t\tif (p_hwfn->mcp_info->capabilities &\n\t\t    FW_MB_PARAM_FEATURE_SUPPORT_VLINK) {\n\t\t\tstruct public_func shmem_info;\n\n\t\t\tqed_mcp_get_shmem_func(p_hwfn, p_ptt, &shmem_info,\n\t\t\t\t\t       MCP_PF_ID(p_hwfn));\n\t\t\tp_link->link_up = !!(shmem_info.status &\n\t\t\t\t\t     FUNC_STATUS_VIRTUAL_LINK_UP);\n\t\t\tqed_read_pf_bandwidth(p_hwfn, &shmem_info);\n\t\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t\t   \"Virtual link_up = %d\\n\", p_link->link_up);\n\t\t} else {\n\t\t\tp_link->link_up = !!(status & LINK_STATUS_LINK_UP);\n\t\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t\t   \"Physical link_up = %d\\n\", p_link->link_up);\n\t\t}\n\t} else {\n\t\tp_link->link_up = false;\n\t}\n\n\tp_link->full_duplex = true;\n\tswitch ((status & LINK_STATUS_SPEED_AND_DUPLEX_MASK)) {\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_100G:\n\t\tp_link->speed = 100000;\n\t\tbreak;\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_50G:\n\t\tp_link->speed = 50000;\n\t\tbreak;\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_40G:\n\t\tp_link->speed = 40000;\n\t\tbreak;\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_25G:\n\t\tp_link->speed = 25000;\n\t\tbreak;\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_20G:\n\t\tp_link->speed = 20000;\n\t\tbreak;\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_10G:\n\t\tp_link->speed = 10000;\n\t\tbreak;\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_1000THD:\n\t\tp_link->full_duplex = false;\n\t\tfallthrough;\n\tcase LINK_STATUS_SPEED_AND_DUPLEX_1000TFD:\n\t\tp_link->speed = 1000;\n\t\tbreak;\n\tdefault:\n\t\tp_link->speed = 0;\n\t\tp_link->link_up = 0;\n\t}\n\n\tif (p_link->link_up && p_link->speed)\n\t\tp_link->line_speed = p_link->speed;\n\telse\n\t\tp_link->line_speed = 0;\n\n\tmax_bw = p_hwfn->mcp_info->func_info.bandwidth_max;\n\tmin_bw = p_hwfn->mcp_info->func_info.bandwidth_min;\n\n\t \n\t__qed_configure_pf_max_bandwidth(p_hwfn, p_ptt, p_link, max_bw);\n\n\t \n\t__qed_configure_pf_min_bandwidth(p_hwfn, p_ptt, p_link, min_bw);\n\tqed_configure_vp_wfq_on_link_change(p_hwfn->cdev, p_ptt,\n\t\t\t\t\t    p_link->min_pf_rate);\n\n\tp_link->an = !!(status & LINK_STATUS_AUTO_NEGOTIATE_ENABLED);\n\tp_link->an_complete = !!(status &\n\t\t\t\t LINK_STATUS_AUTO_NEGOTIATE_COMPLETE);\n\tp_link->parallel_detection = !!(status &\n\t\t\t\t\tLINK_STATUS_PARALLEL_DETECTION_USED);\n\tp_link->pfc_enabled = !!(status & LINK_STATUS_PFC_ENABLED);\n\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_1000TFD_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_1G_FD : 0;\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_1000THD_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_1G_HD : 0;\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_10G_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_10G : 0;\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_20G_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_20G : 0;\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_25G_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_25G : 0;\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_40G_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_40G : 0;\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_50G_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_50G : 0;\n\tp_link->partner_adv_speed |=\n\t\t(status & LINK_STATUS_LINK_PARTNER_100G_CAPABLE) ?\n\t\tQED_LINK_PARTNER_SPEED_100G : 0;\n\n\tp_link->partner_tx_flow_ctrl_en =\n\t\t!!(status & LINK_STATUS_TX_FLOW_CONTROL_ENABLED);\n\tp_link->partner_rx_flow_ctrl_en =\n\t\t!!(status & LINK_STATUS_RX_FLOW_CONTROL_ENABLED);\n\n\tswitch (status & LINK_STATUS_LINK_PARTNER_FLOW_CONTROL_MASK) {\n\tcase LINK_STATUS_LINK_PARTNER_SYMMETRIC_PAUSE:\n\t\tp_link->partner_adv_pause = QED_LINK_PARTNER_SYMMETRIC_PAUSE;\n\t\tbreak;\n\tcase LINK_STATUS_LINK_PARTNER_ASYMMETRIC_PAUSE:\n\t\tp_link->partner_adv_pause = QED_LINK_PARTNER_ASYMMETRIC_PAUSE;\n\t\tbreak;\n\tcase LINK_STATUS_LINK_PARTNER_BOTH_PAUSE:\n\t\tp_link->partner_adv_pause = QED_LINK_PARTNER_BOTH_PAUSE;\n\t\tbreak;\n\tdefault:\n\t\tp_link->partner_adv_pause = 0;\n\t}\n\n\tp_link->sfp_tx_fault = !!(status & LINK_STATUS_SFP_TX_FAULT);\n\n\tif (p_hwfn->mcp_info->capabilities & FW_MB_PARAM_FEATURE_SUPPORT_EEE)\n\t\tqed_mcp_read_eee_config(p_hwfn, p_ptt, p_link);\n\n\tif (p_hwfn->mcp_info->capabilities &\n\t    FW_MB_PARAM_FEATURE_SUPPORT_FEC_CONTROL) {\n\t\tswitch (status & LINK_STATUS_FEC_MODE_MASK) {\n\t\tcase LINK_STATUS_FEC_MODE_NONE:\n\t\t\tp_link->fec_active = QED_FEC_MODE_NONE;\n\t\t\tbreak;\n\t\tcase LINK_STATUS_FEC_MODE_FIRECODE_CL74:\n\t\t\tp_link->fec_active = QED_FEC_MODE_FIRECODE;\n\t\t\tbreak;\n\t\tcase LINK_STATUS_FEC_MODE_RS_CL91:\n\t\t\tp_link->fec_active = QED_FEC_MODE_RS;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tp_link->fec_active = QED_FEC_MODE_AUTO;\n\t\t}\n\t} else {\n\t\tp_link->fec_active = QED_FEC_MODE_UNSUPPORTED;\n\t}\n\n\tqed_link_update(p_hwfn, p_ptt);\nout:\n\tspin_unlock_bh(&p_hwfn->mcp_info->link_lock);\n}\n\nint qed_mcp_set_link(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt, bool b_up)\n{\n\tstruct qed_mcp_link_params *params = &p_hwfn->mcp_info->link_input;\n\tstruct qed_mcp_mb_params mb_params;\n\tstruct eth_phy_cfg phy_cfg;\n\tu32 cmd, fec_bit = 0;\n\tu32 val, ext_speed;\n\tint rc = 0;\n\n\t \n\tmemset(&phy_cfg, 0, sizeof(phy_cfg));\n\tcmd = b_up ? DRV_MSG_CODE_INIT_PHY : DRV_MSG_CODE_LINK_RESET;\n\tif (!params->speed.autoneg)\n\t\tphy_cfg.speed = params->speed.forced_speed;\n\tphy_cfg.pause |= (params->pause.autoneg) ? ETH_PAUSE_AUTONEG : 0;\n\tphy_cfg.pause |= (params->pause.forced_rx) ? ETH_PAUSE_RX : 0;\n\tphy_cfg.pause |= (params->pause.forced_tx) ? ETH_PAUSE_TX : 0;\n\tphy_cfg.adv_speed = params->speed.advertised_speeds;\n\tphy_cfg.loopback_mode = params->loopback_mode;\n\n\t \n\tif ((p_hwfn->mcp_info->capabilities &\n\t     FW_MB_PARAM_FEATURE_SUPPORT_EEE) && params->eee.enable) {\n\t\tphy_cfg.eee_cfg |= EEE_CFG_EEE_ENABLED;\n\t\tif (params->eee.tx_lpi_enable)\n\t\t\tphy_cfg.eee_cfg |= EEE_CFG_TX_LPI;\n\t\tif (params->eee.adv_caps & QED_EEE_1G_ADV)\n\t\t\tphy_cfg.eee_cfg |= EEE_CFG_ADV_SPEED_1G;\n\t\tif (params->eee.adv_caps & QED_EEE_10G_ADV)\n\t\t\tphy_cfg.eee_cfg |= EEE_CFG_ADV_SPEED_10G;\n\t\tphy_cfg.eee_cfg |= (params->eee.tx_lpi_timer <<\n\t\t\t\t    EEE_TX_TIMER_USEC_OFFSET) &\n\t\t\t\t   EEE_TX_TIMER_USEC_MASK;\n\t}\n\n\tif (p_hwfn->mcp_info->capabilities &\n\t    FW_MB_PARAM_FEATURE_SUPPORT_FEC_CONTROL) {\n\t\tif (params->fec & QED_FEC_MODE_NONE)\n\t\t\tfec_bit |= FEC_FORCE_MODE_NONE;\n\t\telse if (params->fec & QED_FEC_MODE_FIRECODE)\n\t\t\tfec_bit |= FEC_FORCE_MODE_FIRECODE;\n\t\telse if (params->fec & QED_FEC_MODE_RS)\n\t\t\tfec_bit |= FEC_FORCE_MODE_RS;\n\t\telse if (params->fec & QED_FEC_MODE_AUTO)\n\t\t\tfec_bit |= FEC_FORCE_MODE_AUTO;\n\n\t\tSET_MFW_FIELD(phy_cfg.fec_mode, FEC_FORCE_MODE, fec_bit);\n\t}\n\n\tif (p_hwfn->mcp_info->capabilities &\n\t    FW_MB_PARAM_FEATURE_SUPPORT_EXT_SPEED_FEC_CONTROL) {\n\t\text_speed = 0;\n\t\tif (params->ext_speed.autoneg)\n\t\t\text_speed |= ETH_EXT_SPEED_NONE;\n\n\t\tval = params->ext_speed.forced_speed;\n\t\tif (val & QED_EXT_SPEED_1G)\n\t\t\text_speed |= ETH_EXT_SPEED_1G;\n\t\tif (val & QED_EXT_SPEED_10G)\n\t\t\text_speed |= ETH_EXT_SPEED_10G;\n\t\tif (val & QED_EXT_SPEED_25G)\n\t\t\text_speed |= ETH_EXT_SPEED_25G;\n\t\tif (val & QED_EXT_SPEED_40G)\n\t\t\text_speed |= ETH_EXT_SPEED_40G;\n\t\tif (val & QED_EXT_SPEED_50G_R)\n\t\t\text_speed |= ETH_EXT_SPEED_50G_BASE_R;\n\t\tif (val & QED_EXT_SPEED_50G_R2)\n\t\t\text_speed |= ETH_EXT_SPEED_50G_BASE_R2;\n\t\tif (val & QED_EXT_SPEED_100G_R2)\n\t\t\text_speed |= ETH_EXT_SPEED_100G_BASE_R2;\n\t\tif (val & QED_EXT_SPEED_100G_R4)\n\t\t\text_speed |= ETH_EXT_SPEED_100G_BASE_R4;\n\t\tif (val & QED_EXT_SPEED_100G_P4)\n\t\t\text_speed |= ETH_EXT_SPEED_100G_BASE_P4;\n\n\t\tSET_MFW_FIELD(phy_cfg.extended_speed, ETH_EXT_SPEED,\n\t\t\t      ext_speed);\n\n\t\text_speed = 0;\n\n\t\tval = params->ext_speed.advertised_speeds;\n\t\tif (val & QED_EXT_SPEED_MASK_1G)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_1G;\n\t\tif (val & QED_EXT_SPEED_MASK_10G)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_10G;\n\t\tif (val & QED_EXT_SPEED_MASK_25G)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_25G;\n\t\tif (val & QED_EXT_SPEED_MASK_40G)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_40G;\n\t\tif (val & QED_EXT_SPEED_MASK_50G_R)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_50G_BASE_R;\n\t\tif (val & QED_EXT_SPEED_MASK_50G_R2)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_50G_BASE_R2;\n\t\tif (val & QED_EXT_SPEED_MASK_100G_R2)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_100G_BASE_R2;\n\t\tif (val & QED_EXT_SPEED_MASK_100G_R4)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_100G_BASE_R4;\n\t\tif (val & QED_EXT_SPEED_MASK_100G_P4)\n\t\t\text_speed |= ETH_EXT_ADV_SPEED_100G_BASE_P4;\n\n\t\tphy_cfg.extended_speed |= ext_speed;\n\n\t\tSET_MFW_FIELD(phy_cfg.fec_mode, FEC_EXTENDED_MODE,\n\t\t\t      params->ext_fec_mode);\n\t}\n\n\tp_hwfn->b_drv_link_init = b_up;\n\n\tif (b_up) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Configuring Link: Speed 0x%08x, Pause 0x%08x, Adv. Speed 0x%08x, Loopback 0x%08x, FEC 0x%08x, Ext. Speed 0x%08x\\n\",\n\t\t\t   phy_cfg.speed, phy_cfg.pause, phy_cfg.adv_speed,\n\t\t\t   phy_cfg.loopback_mode, phy_cfg.fec_mode,\n\t\t\t   phy_cfg.extended_speed);\n\t} else {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK, \"Resetting link\\n\");\n\t}\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = cmd;\n\tmb_params.p_data_src = &phy_cfg;\n\tmb_params.data_src_size = sizeof(phy_cfg);\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\n\t \n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"MCP response failure, aborting\\n\");\n\t\treturn rc;\n\t}\n\n\t \n\tqed_mcp_handle_link_change(p_hwfn, p_ptt, !b_up);\n\n\treturn 0;\n}\n\nu32 qed_get_process_kill_counter(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt)\n{\n\tu32 path_offsize_addr, path_offsize, path_addr, proc_kill_cnt;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn -EINVAL;\n\n\tpath_offsize_addr = SECTION_OFFSIZE_ADDR(p_hwfn->mcp_info->public_base,\n\t\t\t\t\t\t PUBLIC_PATH);\n\tpath_offsize = qed_rd(p_hwfn, p_ptt, path_offsize_addr);\n\tpath_addr = SECTION_ADDR(path_offsize, QED_PATH_ID(p_hwfn));\n\n\tproc_kill_cnt = qed_rd(p_hwfn, p_ptt,\n\t\t\t       path_addr +\n\t\t\t       offsetof(struct public_path, process_kill)) &\n\t\t\tPROCESS_KILL_COUNTER_MASK;\n\n\treturn proc_kill_cnt;\n}\n\nstatic void qed_mcp_handle_process_kill(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_ptt *p_ptt)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tu32 proc_kill_cnt;\n\n\t \n\tqed_int_igu_disable_int(p_hwfn, p_ptt);\n\n\tDP_NOTICE(p_hwfn, \"Received a process kill indication\\n\");\n\n\t \n\tif (p_hwfn != QED_LEADING_HWFN(cdev))\n\t\treturn;\n\n\tif (cdev->recov_in_prog) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Ignoring the indication since a recovery process is already in progress\\n\");\n\t\treturn;\n\t}\n\n\tcdev->recov_in_prog = true;\n\n\tproc_kill_cnt = qed_get_process_kill_counter(p_hwfn, p_ptt);\n\tDP_NOTICE(p_hwfn, \"Process kill counter: %d\\n\", proc_kill_cnt);\n\n\tqed_schedule_recovery_handler(p_hwfn);\n}\n\nstatic void qed_mcp_send_protocol_stats(struct qed_hwfn *p_hwfn,\n\t\t\t\t\tstruct qed_ptt *p_ptt,\n\t\t\t\t\tenum MFW_DRV_MSG_TYPE type)\n{\n\tenum qed_mcp_protocol_type stats_type;\n\tunion qed_mcp_protocol_stats stats;\n\tstruct qed_mcp_mb_params mb_params;\n\tu32 hsi_param;\n\n\tswitch (type) {\n\tcase MFW_DRV_MSG_GET_LAN_STATS:\n\t\tstats_type = QED_MCP_LAN_STATS;\n\t\thsi_param = DRV_MSG_CODE_STATS_TYPE_LAN;\n\t\tbreak;\n\tcase MFW_DRV_MSG_GET_FCOE_STATS:\n\t\tstats_type = QED_MCP_FCOE_STATS;\n\t\thsi_param = DRV_MSG_CODE_STATS_TYPE_FCOE;\n\t\tbreak;\n\tcase MFW_DRV_MSG_GET_ISCSI_STATS:\n\t\tstats_type = QED_MCP_ISCSI_STATS;\n\t\thsi_param = DRV_MSG_CODE_STATS_TYPE_ISCSI;\n\t\tbreak;\n\tcase MFW_DRV_MSG_GET_RDMA_STATS:\n\t\tstats_type = QED_MCP_RDMA_STATS;\n\t\thsi_param = DRV_MSG_CODE_STATS_TYPE_RDMA;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Invalid protocol type %d\\n\", type);\n\t\treturn;\n\t}\n\n\tqed_get_protocol_stats(p_hwfn->cdev, stats_type, &stats);\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_GET_STATS;\n\tmb_params.param = hsi_param;\n\tmb_params.p_data_src = &stats;\n\tmb_params.data_src_size = sizeof(stats);\n\tqed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n}\n\nstatic void qed_mcp_update_bw(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_function_info *p_info;\n\tstruct public_func shmem_info;\n\tu32 resp = 0, param = 0;\n\n\tqed_mcp_get_shmem_func(p_hwfn, p_ptt, &shmem_info, MCP_PF_ID(p_hwfn));\n\n\tqed_read_pf_bandwidth(p_hwfn, &shmem_info);\n\n\tp_info = &p_hwfn->mcp_info->func_info;\n\n\tqed_configure_pf_min_bandwidth(p_hwfn->cdev, p_info->bandwidth_min);\n\tqed_configure_pf_max_bandwidth(p_hwfn->cdev, p_info->bandwidth_max);\n\n\t \n\tqed_mcp_cmd_nosleep(p_hwfn, p_ptt, DRV_MSG_CODE_BW_UPDATE_ACK, 0, &resp,\n\t\t\t    &param);\n}\n\nstatic void qed_mcp_update_stag(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct public_func shmem_info;\n\tu32 resp = 0, param = 0;\n\n\tqed_mcp_get_shmem_func(p_hwfn, p_ptt, &shmem_info, MCP_PF_ID(p_hwfn));\n\n\tp_hwfn->mcp_info->func_info.ovlan = (u16)shmem_info.ovlan_stag &\n\t\t\t\t\t\t FUNC_MF_CFG_OV_STAG_MASK;\n\tp_hwfn->hw_info.ovlan = p_hwfn->mcp_info->func_info.ovlan;\n\tif (test_bit(QED_MF_OVLAN_CLSS, &p_hwfn->cdev->mf_bits)) {\n\t\tif (p_hwfn->hw_info.ovlan != QED_MCP_VLAN_UNSET) {\n\t\t\tqed_wr(p_hwfn, p_ptt, NIG_REG_LLH_FUNC_TAG_VALUE,\n\t\t\t       p_hwfn->hw_info.ovlan);\n\t\t\tqed_wr(p_hwfn, p_ptt, NIG_REG_LLH_FUNC_TAG_EN, 1);\n\n\t\t\t \n\t\t\tqed_wr(p_hwfn, p_ptt, DORQ_REG_TAG1_OVRD_MODE, 1);\n\t\t\tqed_wr(p_hwfn, p_ptt, DORQ_REG_PF_EXT_VID_BB_K2,\n\t\t\t       p_hwfn->hw_info.ovlan);\n\t\t} else {\n\t\t\tqed_wr(p_hwfn, p_ptt, NIG_REG_LLH_FUNC_TAG_EN, 0);\n\t\t\tqed_wr(p_hwfn, p_ptt, NIG_REG_LLH_FUNC_TAG_VALUE, 0);\n\t\t\tqed_wr(p_hwfn, p_ptt, DORQ_REG_TAG1_OVRD_MODE, 0);\n\t\t\tqed_wr(p_hwfn, p_ptt, DORQ_REG_PF_EXT_VID_BB_K2, 0);\n\t\t}\n\n\t\tqed_sp_pf_update_stag(p_hwfn);\n\t}\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP, \"ovlan = %d hw_mode = 0x%x\\n\",\n\t\t   p_hwfn->mcp_info->func_info.ovlan, p_hwfn->hw_info.hw_mode);\n\n\t \n\tqed_mcp_cmd_nosleep(p_hwfn, p_ptt, DRV_MSG_CODE_S_TAG_UPDATE_ACK, 0,\n\t\t\t    &resp, &param);\n}\n\nstatic void qed_mcp_handle_fan_failure(struct qed_hwfn *p_hwfn,\n\t\t\t\t       struct qed_ptt *p_ptt)\n{\n\t \n\tif (p_hwfn != QED_LEADING_HWFN(p_hwfn->cdev))\n\t\treturn;\n\n\tqed_hw_err_notify(p_hwfn, p_ptt, QED_HW_ERR_FAN_FAIL,\n\t\t\t  \"Fan failure was detected on the network interface card and it's going to be shut down.\\n\");\n}\n\nstruct qed_mdump_cmd_params {\n\tu32 cmd;\n\tvoid *p_data_src;\n\tu8 data_src_size;\n\tvoid *p_data_dst;\n\tu8 data_dst_size;\n\tu32 mcp_resp;\n};\n\nstatic int\nqed_mcp_mdump_cmd(struct qed_hwfn *p_hwfn,\n\t\t  struct qed_ptt *p_ptt,\n\t\t  struct qed_mdump_cmd_params *p_mdump_cmd_params)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tint rc;\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_MDUMP_CMD;\n\tmb_params.param = p_mdump_cmd_params->cmd;\n\tmb_params.p_data_src = p_mdump_cmd_params->p_data_src;\n\tmb_params.data_src_size = p_mdump_cmd_params->data_src_size;\n\tmb_params.p_data_dst = p_mdump_cmd_params->p_data_dst;\n\tmb_params.data_dst_size = p_mdump_cmd_params->data_dst_size;\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\tp_mdump_cmd_params->mcp_resp = mb_params.mcp_resp;\n\n\tif (p_mdump_cmd_params->mcp_resp == FW_MSG_CODE_MDUMP_INVALID_CMD) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"The mdump sub command is unsupported by the MFW [mdump_cmd 0x%x]\\n\",\n\t\t\tp_mdump_cmd_params->cmd);\n\t\trc = -EOPNOTSUPP;\n\t} else if (p_mdump_cmd_params->mcp_resp == FW_MSG_CODE_UNSUPPORTED) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"The mdump command is not supported by the MFW\\n\");\n\t\trc = -EOPNOTSUPP;\n\t}\n\n\treturn rc;\n}\n\nstatic int qed_mcp_mdump_ack(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mdump_cmd_params mdump_cmd_params;\n\n\tmemset(&mdump_cmd_params, 0, sizeof(mdump_cmd_params));\n\tmdump_cmd_params.cmd = DRV_MSG_CODE_MDUMP_ACK;\n\n\treturn qed_mcp_mdump_cmd(p_hwfn, p_ptt, &mdump_cmd_params);\n}\n\nint\nqed_mcp_mdump_get_retain(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_ptt *p_ptt,\n\t\t\t struct mdump_retain_data_stc *p_mdump_retain)\n{\n\tstruct qed_mdump_cmd_params mdump_cmd_params;\n\tint rc;\n\n\tmemset(&mdump_cmd_params, 0, sizeof(mdump_cmd_params));\n\tmdump_cmd_params.cmd = DRV_MSG_CODE_MDUMP_GET_RETAIN;\n\tmdump_cmd_params.p_data_dst = p_mdump_retain;\n\tmdump_cmd_params.data_dst_size = sizeof(*p_mdump_retain);\n\n\trc = qed_mcp_mdump_cmd(p_hwfn, p_ptt, &mdump_cmd_params);\n\tif (rc)\n\t\treturn rc;\n\n\tif (mdump_cmd_params.mcp_resp != FW_MSG_CODE_OK) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Failed to get the mdump retained data [mcp_resp 0x%x]\\n\",\n\t\t\tmdump_cmd_params.mcp_resp);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void qed_mcp_handle_critical_error(struct qed_hwfn *p_hwfn,\n\t\t\t\t\t  struct qed_ptt *p_ptt)\n{\n\tstruct mdump_retain_data_stc mdump_retain;\n\tint rc;\n\n\t \n\tif (p_hwfn != QED_LEADING_HWFN(p_hwfn->cdev))\n\t\treturn;\n\n\trc = qed_mcp_mdump_get_retain(p_hwfn, p_ptt, &mdump_retain);\n\tif (rc == 0 && mdump_retain.valid)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The MFW notified that a critical error occurred in the device [epoch 0x%08x, pf 0x%x, status 0x%08x]\\n\",\n\t\t\t  mdump_retain.epoch,\n\t\t\t  mdump_retain.pf, mdump_retain.status);\n\telse\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The MFW notified that a critical error occurred in the device\\n\");\n\n\tDP_NOTICE(p_hwfn,\n\t\t  \"Acknowledging the notification to not allow the MFW crash dump [driver debug data collection is preferable]\\n\");\n\tqed_mcp_mdump_ack(p_hwfn, p_ptt);\n\n\tqed_hw_err_notify(p_hwfn, p_ptt, QED_HW_ERR_HW_ATTN, NULL);\n}\n\nvoid qed_mcp_read_ufp_config(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct public_func shmem_info;\n\tu32 port_cfg, val;\n\n\tif (!test_bit(QED_MF_UFP_SPECIFIC, &p_hwfn->cdev->mf_bits))\n\t\treturn;\n\n\tmemset(&p_hwfn->ufp_info, 0, sizeof(p_hwfn->ufp_info));\n\tport_cfg = qed_rd(p_hwfn, p_ptt, p_hwfn->mcp_info->port_addr +\n\t\t\t  offsetof(struct public_port, oem_cfg_port));\n\tval = (port_cfg & OEM_CFG_CHANNEL_TYPE_MASK) >>\n\t\tOEM_CFG_CHANNEL_TYPE_OFFSET;\n\tif (val != OEM_CFG_CHANNEL_TYPE_STAGGED)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Incorrect UFP Channel type  %d port_id 0x%02x\\n\",\n\t\t\t  val, MFW_PORT(p_hwfn));\n\n\tval = (port_cfg & OEM_CFG_SCHED_TYPE_MASK) >> OEM_CFG_SCHED_TYPE_OFFSET;\n\tif (val == OEM_CFG_SCHED_TYPE_ETS) {\n\t\tp_hwfn->ufp_info.mode = QED_UFP_MODE_ETS;\n\t} else if (val == OEM_CFG_SCHED_TYPE_VNIC_BW) {\n\t\tp_hwfn->ufp_info.mode = QED_UFP_MODE_VNIC_BW;\n\t} else {\n\t\tp_hwfn->ufp_info.mode = QED_UFP_MODE_UNKNOWN;\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unknown UFP scheduling mode %d port_id 0x%02x\\n\",\n\t\t\t  val, MFW_PORT(p_hwfn));\n\t}\n\n\tqed_mcp_get_shmem_func(p_hwfn, p_ptt, &shmem_info, MCP_PF_ID(p_hwfn));\n\tval = (shmem_info.oem_cfg_func & OEM_CFG_FUNC_TC_MASK) >>\n\t\tOEM_CFG_FUNC_TC_OFFSET;\n\tp_hwfn->ufp_info.tc = (u8)val;\n\tval = (shmem_info.oem_cfg_func & OEM_CFG_FUNC_HOST_PRI_CTRL_MASK) >>\n\t\tOEM_CFG_FUNC_HOST_PRI_CTRL_OFFSET;\n\tif (val == OEM_CFG_FUNC_HOST_PRI_CTRL_VNIC) {\n\t\tp_hwfn->ufp_info.pri_type = QED_UFP_PRI_VNIC;\n\t} else if (val == OEM_CFG_FUNC_HOST_PRI_CTRL_OS) {\n\t\tp_hwfn->ufp_info.pri_type = QED_UFP_PRI_OS;\n\t} else {\n\t\tp_hwfn->ufp_info.pri_type = QED_UFP_PRI_UNKNOWN;\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unknown Host priority control %d port_id 0x%02x\\n\",\n\t\t\t  val, MFW_PORT(p_hwfn));\n\t}\n\n\tDP_NOTICE(p_hwfn,\n\t\t  \"UFP shmem config: mode = %d tc = %d pri_type = %d port_id 0x%02x\\n\",\n\t\t  p_hwfn->ufp_info.mode, p_hwfn->ufp_info.tc,\n\t\t  p_hwfn->ufp_info.pri_type, MFW_PORT(p_hwfn));\n}\n\nstatic int\nqed_mcp_handle_ufp_event(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tqed_mcp_read_ufp_config(p_hwfn, p_ptt);\n\n\tif (p_hwfn->ufp_info.mode == QED_UFP_MODE_VNIC_BW) {\n\t\tp_hwfn->qm_info.ooo_tc = p_hwfn->ufp_info.tc;\n\t\tqed_hw_info_set_offload_tc(&p_hwfn->hw_info,\n\t\t\t\t\t   p_hwfn->ufp_info.tc);\n\n\t\tqed_qm_reconf(p_hwfn, p_ptt);\n\t} else if (p_hwfn->ufp_info.mode == QED_UFP_MODE_ETS) {\n\t\t \n\t\tqed_dcbx_mib_update_event(p_hwfn, p_ptt,\n\t\t\t\t\t  QED_DCBX_OPERATIONAL_MIB);\n\t} else {\n\t\tDP_ERR(p_hwfn, \"Invalid sched type, discard the UFP config\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tqed_sp_pf_update_ufp(p_hwfn);\n\n\t \n\tqed_sp_pf_update_stag(p_hwfn);\n\n\treturn 0;\n}\n\nint qed_mcp_handle_events(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_info *info = p_hwfn->mcp_info;\n\tint rc = 0;\n\tbool found = false;\n\tu16 i;\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP, \"Received message from MFW\\n\");\n\n\t \n\tqed_mcp_read_mb(p_hwfn, p_ptt);\n\n\t \n\tfor (i = 0; i < info->mfw_mb_length; i++) {\n\t\tif (info->mfw_mb_cur[i] == info->mfw_mb_shadow[i])\n\t\t\tcontinue;\n\n\t\tfound = true;\n\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_LINK,\n\t\t\t   \"Msg [%d] - old CMD 0x%02x, new CMD 0x%02x\\n\",\n\t\t\t   i, info->mfw_mb_shadow[i], info->mfw_mb_cur[i]);\n\n\t\tspin_lock_bh(&p_hwfn->mcp_info->unload_lock);\n\t\tif (test_bit(QED_MCP_BYPASS_PROC_BIT,\n\t\t\t     &p_hwfn->mcp_info->mcp_handling_status)) {\n\t\t\tspin_unlock_bh(&p_hwfn->mcp_info->unload_lock);\n\t\t\tDP_INFO(p_hwfn,\n\t\t\t\t\"Msg [%d] is bypassed on unload flow\\n\", i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tset_bit(QED_MCP_IN_PROCESSING_BIT,\n\t\t\t&p_hwfn->mcp_info->mcp_handling_status);\n\t\tspin_unlock_bh(&p_hwfn->mcp_info->unload_lock);\n\n\t\tswitch (i) {\n\t\tcase MFW_DRV_MSG_LINK_CHANGE:\n\t\t\tqed_mcp_handle_link_change(p_hwfn, p_ptt, false);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_VF_DISABLED:\n\t\t\tqed_mcp_handle_vf_flr(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_LLDP_DATA_UPDATED:\n\t\t\tqed_dcbx_mib_update_event(p_hwfn, p_ptt,\n\t\t\t\t\t\t  QED_DCBX_REMOTE_LLDP_MIB);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_DCBX_REMOTE_MIB_UPDATED:\n\t\t\tqed_dcbx_mib_update_event(p_hwfn, p_ptt,\n\t\t\t\t\t\t  QED_DCBX_REMOTE_MIB);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_DCBX_OPERATIONAL_MIB_UPDATED:\n\t\t\tqed_dcbx_mib_update_event(p_hwfn, p_ptt,\n\t\t\t\t\t\t  QED_DCBX_OPERATIONAL_MIB);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_OEM_CFG_UPDATE:\n\t\t\tqed_mcp_handle_ufp_event(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_TRANSCEIVER_STATE_CHANGE:\n\t\t\tqed_mcp_handle_transceiver_change(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_ERROR_RECOVERY:\n\t\t\tqed_mcp_handle_process_kill(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_GET_LAN_STATS:\n\t\tcase MFW_DRV_MSG_GET_FCOE_STATS:\n\t\tcase MFW_DRV_MSG_GET_ISCSI_STATS:\n\t\tcase MFW_DRV_MSG_GET_RDMA_STATS:\n\t\t\tqed_mcp_send_protocol_stats(p_hwfn, p_ptt, i);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_BW_UPDATE:\n\t\t\tqed_mcp_update_bw(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_S_TAG_UPDATE:\n\t\t\tqed_mcp_update_stag(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_FAILURE_DETECTED:\n\t\t\tqed_mcp_handle_fan_failure(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_CRITICAL_ERROR_OCCURRED:\n\t\t\tqed_mcp_handle_critical_error(p_hwfn, p_ptt);\n\t\t\tbreak;\n\t\tcase MFW_DRV_MSG_GET_TLV_REQ:\n\t\t\tqed_mfw_tlv_req(p_hwfn);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDP_INFO(p_hwfn, \"Unimplemented MFW message %d\\n\", i);\n\t\t\trc = -EINVAL;\n\t\t}\n\n\t\tclear_bit(QED_MCP_IN_PROCESSING_BIT,\n\t\t\t  &p_hwfn->mcp_info->mcp_handling_status);\n\t}\n\n\t \n\tfor (i = 0; i < MFW_DRV_MSG_MAX_DWORDS(info->mfw_mb_length); i++) {\n\t\t__be32 val = cpu_to_be32(((u32 *)info->mfw_mb_cur)[i]);\n\n\t\t \n\t\tqed_wr(p_hwfn, p_ptt,\n\t\t       info->mfw_mb_addr + sizeof(u32) +\n\t\t       MFW_DRV_MSG_MAX_DWORDS(info->mfw_mb_length) *\n\t\t       sizeof(u32) + i * sizeof(u32),\n\t\t       (__force u32)val);\n\t}\n\n\tif (!found) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Received an MFW message indication but no new message!\\n\");\n\t\trc = -EINVAL;\n\t}\n\n\t \n\tmemcpy(info->mfw_mb_shadow, info->mfw_mb_cur, info->mfw_mb_length);\n\n\treturn rc;\n}\n\nint qed_mcp_get_mfw_ver(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_ptt *p_ptt,\n\t\t\tu32 *p_mfw_ver, u32 *p_running_bundle_id)\n{\n\tu32 global_offsize, public_base;\n\n\tif (IS_VF(p_hwfn->cdev)) {\n\t\tif (p_hwfn->vf_iov_info) {\n\t\t\tstruct pfvf_acquire_resp_tlv *p_resp;\n\n\t\t\tp_resp = &p_hwfn->vf_iov_info->acquire_resp;\n\t\t\t*p_mfw_ver = p_resp->pfdev_info.mfw_ver;\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tDP_VERBOSE(p_hwfn,\n\t\t\t\t   QED_MSG_IOV,\n\t\t\t\t   \"VF requested MFW version prior to ACQUIRE\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tpublic_base = p_hwfn->mcp_info->public_base;\n\tglobal_offsize = qed_rd(p_hwfn, p_ptt,\n\t\t\t\tSECTION_OFFSIZE_ADDR(public_base,\n\t\t\t\t\t\t     PUBLIC_GLOBAL));\n\t*p_mfw_ver =\n\t    qed_rd(p_hwfn, p_ptt,\n\t\t   SECTION_ADDR(global_offsize,\n\t\t\t\t0) + offsetof(struct public_global, mfw_ver));\n\n\tif (p_running_bundle_id) {\n\t\t*p_running_bundle_id = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t\t      SECTION_ADDR(global_offsize, 0) +\n\t\t\t\t\t      offsetof(struct public_global,\n\t\t\t\t\t\t       running_bundle_id));\n\t}\n\n\treturn 0;\n}\n\nint qed_mcp_get_mbi_ver(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_ptt *p_ptt, u32 *p_mbi_ver)\n{\n\tu32 nvm_cfg_addr, nvm_cfg1_offset, mbi_ver_addr;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn -EINVAL;\n\n\t \n\tnvm_cfg_addr = qed_rd(p_hwfn, p_ptt, MISC_REG_GEN_PURP_CR0);\n\tif (!nvm_cfg_addr) {\n\t\tDP_NOTICE(p_hwfn, \"Shared memory not initialized\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tnvm_cfg1_offset = qed_rd(p_hwfn, p_ptt, nvm_cfg_addr + 4);\n\n\tmbi_ver_addr = MCP_REG_SCRATCH + nvm_cfg1_offset +\n\t\t       offsetof(struct nvm_cfg1, glob) +\n\t\t       offsetof(struct nvm_cfg1_glob, mbi_version);\n\t*p_mbi_ver = qed_rd(p_hwfn, p_ptt,\n\t\t\t    mbi_ver_addr) &\n\t\t     (NVM_CFG1_GLOB_MBI_VERSION_0_MASK |\n\t\t      NVM_CFG1_GLOB_MBI_VERSION_1_MASK |\n\t\t      NVM_CFG1_GLOB_MBI_VERSION_2_MASK);\n\n\treturn 0;\n}\n\nint qed_mcp_get_media_type(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_ptt *p_ptt, u32 *p_media_type)\n{\n\t*p_media_type = MEDIA_UNSPECIFIED;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn -EINVAL;\n\n\tif (!qed_mcp_is_init(p_hwfn)) {\n\t\tDP_NOTICE(p_hwfn, \"MFW is not initialized!\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\tif (!p_ptt) {\n\t\t*p_media_type = MEDIA_UNSPECIFIED;\n\t\treturn -EINVAL;\n\t}\n\n\t*p_media_type = qed_rd(p_hwfn, p_ptt,\n\t\t\t       p_hwfn->mcp_info->port_addr +\n\t\t\t       offsetof(struct public_port,\n\t\t\t\t\tmedia_type));\n\n\treturn 0;\n}\n\nint qed_mcp_get_transceiver_data(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt,\n\t\t\t\t u32 *p_transceiver_state,\n\t\t\t\t u32 *p_transceiver_type)\n{\n\tu32 transceiver_info;\n\n\t*p_transceiver_type = ETH_TRANSCEIVER_TYPE_NONE;\n\t*p_transceiver_state = ETH_TRANSCEIVER_STATE_UPDATING;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn -EINVAL;\n\n\tif (!qed_mcp_is_init(p_hwfn)) {\n\t\tDP_NOTICE(p_hwfn, \"MFW is not initialized!\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\ttransceiver_info = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t  p_hwfn->mcp_info->port_addr +\n\t\t\t\t  offsetof(struct public_port,\n\t\t\t\t\t   transceiver_data));\n\n\t*p_transceiver_state = (transceiver_info &\n\t\t\t\tETH_TRANSCEIVER_STATE_MASK) >>\n\t\t\t\tETH_TRANSCEIVER_STATE_OFFSET;\n\n\tif (*p_transceiver_state == ETH_TRANSCEIVER_STATE_PRESENT)\n\t\t*p_transceiver_type = (transceiver_info &\n\t\t\t\t       ETH_TRANSCEIVER_TYPE_MASK) >>\n\t\t\t\t       ETH_TRANSCEIVER_TYPE_OFFSET;\n\telse\n\t\t*p_transceiver_type = ETH_TRANSCEIVER_TYPE_UNKNOWN;\n\n\treturn 0;\n}\n\nstatic bool qed_is_transceiver_ready(u32 transceiver_state,\n\t\t\t\t     u32 transceiver_type)\n{\n\tif ((transceiver_state & ETH_TRANSCEIVER_STATE_PRESENT) &&\n\t    ((transceiver_state & ETH_TRANSCEIVER_STATE_UPDATING) == 0x0) &&\n\t    (transceiver_type != ETH_TRANSCEIVER_TYPE_NONE))\n\t\treturn true;\n\n\treturn false;\n}\n\nint qed_mcp_trans_speed_mask(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_ptt *p_ptt, u32 *p_speed_mask)\n{\n\tu32 transceiver_type, transceiver_state;\n\tint ret;\n\n\tret = qed_mcp_get_transceiver_data(p_hwfn, p_ptt, &transceiver_state,\n\t\t\t\t\t   &transceiver_type);\n\tif (ret)\n\t\treturn ret;\n\n\tif (qed_is_transceiver_ready(transceiver_state, transceiver_type) ==\n\t\t\t\t     false)\n\t\treturn -EINVAL;\n\n\tswitch (transceiver_type) {\n\tcase ETH_TRANSCEIVER_TYPE_1G_LX:\n\tcase ETH_TRANSCEIVER_TYPE_1G_SX:\n\tcase ETH_TRANSCEIVER_TYPE_1G_PCC:\n\tcase ETH_TRANSCEIVER_TYPE_1G_ACC:\n\tcase ETH_TRANSCEIVER_TYPE_1000BASET:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_10G_SR:\n\tcase ETH_TRANSCEIVER_TYPE_10G_LR:\n\tcase ETH_TRANSCEIVER_TYPE_10G_LRM:\n\tcase ETH_TRANSCEIVER_TYPE_10G_ER:\n\tcase ETH_TRANSCEIVER_TYPE_10G_PCC:\n\tcase ETH_TRANSCEIVER_TYPE_10G_ACC:\n\tcase ETH_TRANSCEIVER_TYPE_4x10G:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_40G_LR4:\n\tcase ETH_TRANSCEIVER_TYPE_40G_SR4:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_SR:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_LR:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_100G_AOC:\n\tcase ETH_TRANSCEIVER_TYPE_100G_SR4:\n\tcase ETH_TRANSCEIVER_TYPE_100G_LR4:\n\tcase ETH_TRANSCEIVER_TYPE_100G_ER4:\n\tcase ETH_TRANSCEIVER_TYPE_100G_ACC:\n\t\t*p_speed_mask =\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_25G_SR:\n\tcase ETH_TRANSCEIVER_TYPE_25G_LR:\n\tcase ETH_TRANSCEIVER_TYPE_25G_AOC:\n\tcase ETH_TRANSCEIVER_TYPE_25G_ACC_S:\n\tcase ETH_TRANSCEIVER_TYPE_25G_ACC_M:\n\tcase ETH_TRANSCEIVER_TYPE_25G_ACC_L:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_25G_CA_N:\n\tcase ETH_TRANSCEIVER_TYPE_25G_CA_S:\n\tcase ETH_TRANSCEIVER_TYPE_25G_CA_L:\n\tcase ETH_TRANSCEIVER_TYPE_4x25G_CR:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_25G_SR:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_25G_LR:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G |\n\t\t\t\tNVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_40G_CR4:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_10G_40G_CR:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_100G_CR4:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_CR:\n\t\t*p_speed_mask =\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_50G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_20G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_SR:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_LR:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_40G_100G_AOC:\n\t\t*p_speed_mask =\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_BB_100G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_25G |\n\t\t    NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_XLPPI:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_40G;\n\t\tbreak;\n\tcase ETH_TRANSCEIVER_TYPE_10G_BASET:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_1G_10G_SR:\n\tcase ETH_TRANSCEIVER_TYPE_MULTI_RATE_1G_10G_LR:\n\t\t*p_speed_mask = NVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_10G |\n\t\t\t\tNVM_CFG1_PORT_DRV_SPEED_CAPABILITY_MASK_1G;\n\t\tbreak;\n\tdefault:\n\t\tDP_INFO(p_hwfn, \"Unknown transceiver type 0x%x\\n\",\n\t\t\ttransceiver_type);\n\t\t*p_speed_mask = 0xff;\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nint qed_mcp_get_board_config(struct qed_hwfn *p_hwfn,\n\t\t\t     struct qed_ptt *p_ptt, u32 *p_board_config)\n{\n\tu32 nvm_cfg_addr, nvm_cfg1_offset, port_cfg_addr;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn -EINVAL;\n\n\tif (!qed_mcp_is_init(p_hwfn)) {\n\t\tDP_NOTICE(p_hwfn, \"MFW is not initialized!\\n\");\n\t\treturn -EBUSY;\n\t}\n\tif (!p_ptt) {\n\t\t*p_board_config = NVM_CFG1_PORT_PORT_TYPE_UNDEFINED;\n\t\treturn -EINVAL;\n\t}\n\n\tnvm_cfg_addr = qed_rd(p_hwfn, p_ptt, MISC_REG_GEN_PURP_CR0);\n\tnvm_cfg1_offset = qed_rd(p_hwfn, p_ptt, nvm_cfg_addr + 4);\n\tport_cfg_addr = MCP_REG_SCRATCH + nvm_cfg1_offset +\n\t\t\toffsetof(struct nvm_cfg1, port[MFW_PORT(p_hwfn)]);\n\t*p_board_config = qed_rd(p_hwfn, p_ptt,\n\t\t\t\t port_cfg_addr +\n\t\t\t\t offsetof(struct nvm_cfg1_port,\n\t\t\t\t\t  board_cfg));\n\n\treturn 0;\n}\n\n \nstatic void\nqed_mcp_get_shmem_proto_legacy(struct qed_hwfn *p_hwfn,\n\t\t\t       enum qed_pci_personality *p_proto)\n{\n\t \n\tif (test_bit(QED_DEV_CAP_ROCE, &p_hwfn->hw_info.device_capabilities))\n\t\t*p_proto = QED_PCI_ETH_ROCE;\n\telse\n\t\t*p_proto = QED_PCI_ETH;\n\n\tDP_VERBOSE(p_hwfn, NETIF_MSG_IFUP,\n\t\t   \"According to Legacy capabilities, L2 personality is %08x\\n\",\n\t\t   (u32)*p_proto);\n}\n\nstatic int\nqed_mcp_get_shmem_proto_mfw(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t    enum qed_pci_personality *p_proto)\n{\n\tu32 resp = 0, param = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt,\n\t\t\t DRV_MSG_CODE_GET_PF_RDMA_PROTOCOL, 0, &resp, &param);\n\tif (rc)\n\t\treturn rc;\n\tif (resp != FW_MSG_CODE_OK) {\n\t\tDP_VERBOSE(p_hwfn, NETIF_MSG_IFUP,\n\t\t\t   \"MFW lacks support for command; Returns %08x\\n\",\n\t\t\t   resp);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (param) {\n\tcase FW_MB_PARAM_GET_PF_RDMA_NONE:\n\t\t*p_proto = QED_PCI_ETH;\n\t\tbreak;\n\tcase FW_MB_PARAM_GET_PF_RDMA_ROCE:\n\t\t*p_proto = QED_PCI_ETH_ROCE;\n\t\tbreak;\n\tcase FW_MB_PARAM_GET_PF_RDMA_IWARP:\n\t\t*p_proto = QED_PCI_ETH_IWARP;\n\t\tbreak;\n\tcase FW_MB_PARAM_GET_PF_RDMA_BOTH:\n\t\t*p_proto = QED_PCI_ETH_RDMA;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"MFW answers GET_PF_RDMA_PROTOCOL but param is %08x\\n\",\n\t\t\t  param);\n\t\treturn -EINVAL;\n\t}\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   NETIF_MSG_IFUP,\n\t\t   \"According to capabilities, L2 personality is %08x [resp %08x param %08x]\\n\",\n\t\t   (u32)*p_proto, resp, param);\n\treturn 0;\n}\n\nstatic int\nqed_mcp_get_shmem_proto(struct qed_hwfn *p_hwfn,\n\t\t\tstruct public_func *p_info,\n\t\t\tstruct qed_ptt *p_ptt,\n\t\t\tenum qed_pci_personality *p_proto)\n{\n\tint rc = 0;\n\n\tswitch (p_info->config & FUNC_MF_CFG_PROTOCOL_MASK) {\n\tcase FUNC_MF_CFG_PROTOCOL_ETHERNET:\n\t\tif (!IS_ENABLED(CONFIG_QED_RDMA))\n\t\t\t*p_proto = QED_PCI_ETH;\n\t\telse if (qed_mcp_get_shmem_proto_mfw(p_hwfn, p_ptt, p_proto))\n\t\t\tqed_mcp_get_shmem_proto_legacy(p_hwfn, p_proto);\n\t\tbreak;\n\tcase FUNC_MF_CFG_PROTOCOL_ISCSI:\n\t\t*p_proto = QED_PCI_ISCSI;\n\t\tbreak;\n\tcase FUNC_MF_CFG_PROTOCOL_FCOE:\n\t\t*p_proto = QED_PCI_FCOE;\n\t\tbreak;\n\tcase FUNC_MF_CFG_PROTOCOL_ROCE:\n\t\tDP_NOTICE(p_hwfn, \"RoCE personality is not a valid value!\\n\");\n\t\tfallthrough;\n\tdefault:\n\t\trc = -EINVAL;\n\t}\n\n\treturn rc;\n}\n\nint qed_mcp_fill_shmem_func_info(struct qed_hwfn *p_hwfn,\n\t\t\t\t struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_function_info *info;\n\tstruct public_func shmem_info;\n\n\tqed_mcp_get_shmem_func(p_hwfn, p_ptt, &shmem_info, MCP_PF_ID(p_hwfn));\n\tinfo = &p_hwfn->mcp_info->func_info;\n\n\tinfo->pause_on_host = (shmem_info.config &\n\t\t\t       FUNC_MF_CFG_PAUSE_ON_HOST_RING) ? 1 : 0;\n\n\tif (qed_mcp_get_shmem_proto(p_hwfn, &shmem_info, p_ptt,\n\t\t\t\t    &info->protocol)) {\n\t\tDP_ERR(p_hwfn, \"Unknown personality %08x\\n\",\n\t\t       (u32)(shmem_info.config & FUNC_MF_CFG_PROTOCOL_MASK));\n\t\treturn -EINVAL;\n\t}\n\n\tqed_read_pf_bandwidth(p_hwfn, &shmem_info);\n\n\tif (shmem_info.mac_upper || shmem_info.mac_lower) {\n\t\tinfo->mac[0] = (u8)(shmem_info.mac_upper >> 8);\n\t\tinfo->mac[1] = (u8)(shmem_info.mac_upper);\n\t\tinfo->mac[2] = (u8)(shmem_info.mac_lower >> 24);\n\t\tinfo->mac[3] = (u8)(shmem_info.mac_lower >> 16);\n\t\tinfo->mac[4] = (u8)(shmem_info.mac_lower >> 8);\n\t\tinfo->mac[5] = (u8)(shmem_info.mac_lower);\n\n\t\t \n\t\tmemcpy(&p_hwfn->cdev->wol_mac, info->mac, ETH_ALEN);\n\t} else {\n\t\tDP_NOTICE(p_hwfn, \"MAC is 0 in shmem\\n\");\n\t}\n\n\tinfo->wwn_port = (u64)shmem_info.fcoe_wwn_port_name_lower |\n\t\t\t (((u64)shmem_info.fcoe_wwn_port_name_upper) << 32);\n\tinfo->wwn_node = (u64)shmem_info.fcoe_wwn_node_name_lower |\n\t\t\t (((u64)shmem_info.fcoe_wwn_node_name_upper) << 32);\n\n\tinfo->ovlan = (u16)(shmem_info.ovlan_stag & FUNC_MF_CFG_OV_STAG_MASK);\n\n\tinfo->mtu = (u16)shmem_info.mtu_size;\n\n\tp_hwfn->hw_info.b_wol_support = QED_WOL_SUPPORT_NONE;\n\tp_hwfn->cdev->wol_config = (u8)QED_OV_WOL_DEFAULT;\n\tif (qed_mcp_is_init(p_hwfn)) {\n\t\tu32 resp = 0, param = 0;\n\t\tint rc;\n\n\t\trc = qed_mcp_cmd(p_hwfn, p_ptt,\n\t\t\t\t DRV_MSG_CODE_OS_WOL, 0, &resp, &param);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tif (resp == FW_MSG_CODE_OS_WOL_SUPPORTED)\n\t\t\tp_hwfn->hw_info.b_wol_support = QED_WOL_SUPPORT_PME;\n\t}\n\n\tDP_VERBOSE(p_hwfn, (QED_MSG_SP | NETIF_MSG_IFUP),\n\t\t   \"Read configuration from shmem: pause_on_host %02x protocol %02x BW [%02x - %02x] MAC %pM wwn port %llx node %llx ovlan %04x wol %02x\\n\",\n\t\tinfo->pause_on_host, info->protocol,\n\t\tinfo->bandwidth_min, info->bandwidth_max,\n\t\tinfo->mac,\n\t\tinfo->wwn_port, info->wwn_node,\n\t\tinfo->ovlan, (u8)p_hwfn->hw_info.b_wol_support);\n\n\treturn 0;\n}\n\nstruct qed_mcp_link_params\n*qed_mcp_get_link_params(struct qed_hwfn *p_hwfn)\n{\n\tif (!p_hwfn || !p_hwfn->mcp_info)\n\t\treturn NULL;\n\treturn &p_hwfn->mcp_info->link_input;\n}\n\nstruct qed_mcp_link_state\n*qed_mcp_get_link_state(struct qed_hwfn *p_hwfn)\n{\n\tif (!p_hwfn || !p_hwfn->mcp_info)\n\t\treturn NULL;\n\treturn &p_hwfn->mcp_info->link_output;\n}\n\nstruct qed_mcp_link_capabilities\n*qed_mcp_get_link_capabilities(struct qed_hwfn *p_hwfn)\n{\n\tif (!p_hwfn || !p_hwfn->mcp_info)\n\t\treturn NULL;\n\treturn &p_hwfn->mcp_info->link_capabilities;\n}\n\nint qed_mcp_drain(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 resp = 0, param = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt,\n\t\t\t DRV_MSG_CODE_NIG_DRAIN, 1000, &resp, &param);\n\n\t \n\tmsleep(1020);\n\n\treturn rc;\n}\n\nint qed_mcp_get_flash_size(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_ptt *p_ptt, u32 *p_flash_size)\n{\n\tu32 flash_size;\n\n\tif (IS_VF(p_hwfn->cdev))\n\t\treturn -EINVAL;\n\n\tflash_size = qed_rd(p_hwfn, p_ptt, MCP_REG_NVM_CFG4);\n\tflash_size = (flash_size & MCP_REG_NVM_CFG4_FLASH_SIZE) >>\n\t\t      MCP_REG_NVM_CFG4_FLASH_SIZE_SHIFT;\n\tflash_size = (1 << (flash_size + MCP_BYTES_PER_MBIT_SHIFT));\n\n\t*p_flash_size = flash_size;\n\n\treturn 0;\n}\n\nint qed_start_recovery_process(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\n\tif (cdev->recov_in_prog) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Avoid triggering a recovery since such a process is already in progress\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\tDP_NOTICE(p_hwfn, \"Triggering a recovery process\\n\");\n\tqed_wr(p_hwfn, p_ptt, MISC_REG_AEU_GENERAL_ATTN_35, 0x1);\n\n\treturn 0;\n}\n\n#define QED_RECOVERY_PROLOG_SLEEP_MS    100\n\nint qed_recovery_prolog(struct qed_dev *cdev)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt = p_hwfn->p_main_ptt;\n\tint rc;\n\n\t \n\tmsleep(QED_RECOVERY_PROLOG_SLEEP_MS);\n\n\t \n\trc = qed_pglueb_set_pfid_enable(p_hwfn, p_ptt, false);\n\tif (rc)\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"qed_pglueb_set_pfid_enable() failed. rc = %d.\\n\",\n\t\t\t  rc);\n\n\treturn rc;\n}\n\nstatic int\nqed_mcp_config_vf_msix_bb(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt, u8 vf_id, u8 num)\n{\n\tu32 resp = 0, param = 0, rc_param = 0;\n\tint rc;\n\n\t \n\tif (!IS_LEAD_HWFN(p_hwfn))\n\t\treturn 0;\n\tnum *= p_hwfn->cdev->num_hwfns;\n\n\tparam |= (vf_id << DRV_MB_PARAM_CFG_VF_MSIX_VF_ID_SHIFT) &\n\t\t DRV_MB_PARAM_CFG_VF_MSIX_VF_ID_MASK;\n\tparam |= (num << DRV_MB_PARAM_CFG_VF_MSIX_SB_NUM_SHIFT) &\n\t\t DRV_MB_PARAM_CFG_VF_MSIX_SB_NUM_MASK;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_CFG_VF_MSIX, param,\n\t\t\t &resp, &rc_param);\n\n\tif (resp != FW_MSG_CODE_DRV_CFG_VF_MSIX_DONE) {\n\t\tDP_NOTICE(p_hwfn, \"VF[%d]: MFW failed to set MSI-X\\n\", vf_id);\n\t\trc = -EINVAL;\n\t} else {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Requested 0x%02x MSI-x interrupts from VF 0x%02x\\n\",\n\t\t\t   num, vf_id);\n\t}\n\n\treturn rc;\n}\n\nstatic int\nqed_mcp_config_vf_msix_ah(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt, u8 num)\n{\n\tu32 resp = 0, param = num, rc_param = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_CFG_PF_VFS_MSIX,\n\t\t\t param, &resp, &rc_param);\n\n\tif (resp != FW_MSG_CODE_DRV_CFG_PF_VFS_MSIX_DONE) {\n\t\tDP_NOTICE(p_hwfn, \"MFW failed to set MSI-X for VFs\\n\");\n\t\trc = -EINVAL;\n\t} else {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_IOV,\n\t\t\t   \"Requested 0x%02x MSI-x interrupts for VFs\\n\", num);\n\t}\n\n\treturn rc;\n}\n\nint qed_mcp_config_vf_msix(struct qed_hwfn *p_hwfn,\n\t\t\t   struct qed_ptt *p_ptt, u8 vf_id, u8 num)\n{\n\tif (QED_IS_BB(p_hwfn->cdev))\n\t\treturn qed_mcp_config_vf_msix_bb(p_hwfn, p_ptt, vf_id, num);\n\telse\n\t\treturn qed_mcp_config_vf_msix_ah(p_hwfn, p_ptt, num);\n}\n\nint\nqed_mcp_send_drv_version(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_ptt *p_ptt,\n\t\t\t struct qed_mcp_drv_version *p_ver)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tstruct drv_version_stc drv_version;\n\t__be32 val;\n\tu32 i;\n\tint rc;\n\n\tmemset(&drv_version, 0, sizeof(drv_version));\n\tdrv_version.version = p_ver->version;\n\tfor (i = 0; i < (MCP_DRV_VER_STR_SIZE - 4) / sizeof(u32); i++) {\n\t\tval = cpu_to_be32(*((u32 *)&p_ver->name[i * sizeof(u32)]));\n\t\t*(__be32 *)&drv_version.name[i * sizeof(u32)] = val;\n\t}\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_SET_VERSION;\n\tmb_params.p_data_src = &drv_version;\n\tmb_params.data_src_size = sizeof(drv_version);\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\tDP_ERR(p_hwfn, \"MCP response failure, aborting\\n\");\n\n\treturn rc;\n}\n\n \n#define QED_MCP_HALT_SLEEP_MS\t\t10\n#define QED_MCP_HALT_MAX_RETRIES\t10\n\nint qed_mcp_halt(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 resp = 0, param = 0, cpu_state, cnt = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_MCP_HALT, 0, &resp,\n\t\t\t &param);\n\tif (rc) {\n\t\tDP_ERR(p_hwfn, \"MCP response failure, aborting\\n\");\n\t\treturn rc;\n\t}\n\n\tdo {\n\t\tmsleep(QED_MCP_HALT_SLEEP_MS);\n\t\tcpu_state = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_STATE);\n\t\tif (cpu_state & MCP_REG_CPU_STATE_SOFT_HALTED)\n\t\t\tbreak;\n\t} while (++cnt < QED_MCP_HALT_MAX_RETRIES);\n\n\tif (cnt == QED_MCP_HALT_MAX_RETRIES) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to halt the MCP [CPU_MODE = 0x%08x, CPU_STATE = 0x%08x]\\n\",\n\t\t\t  qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_MODE), cpu_state);\n\t\treturn -EBUSY;\n\t}\n\n\tqed_mcp_cmd_set_blocking(p_hwfn, true);\n\n\treturn 0;\n}\n\n#define QED_MCP_RESUME_SLEEP_MS\t10\n\nint qed_mcp_resume(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 cpu_mode, cpu_state;\n\n\tqed_wr(p_hwfn, p_ptt, MCP_REG_CPU_STATE, 0xffffffff);\n\n\tcpu_mode = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_MODE);\n\tcpu_mode &= ~MCP_REG_CPU_MODE_SOFT_HALT;\n\tqed_wr(p_hwfn, p_ptt, MCP_REG_CPU_MODE, cpu_mode);\n\tmsleep(QED_MCP_RESUME_SLEEP_MS);\n\tcpu_state = qed_rd(p_hwfn, p_ptt, MCP_REG_CPU_STATE);\n\n\tif (cpu_state & MCP_REG_CPU_STATE_SOFT_HALTED) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to resume the MCP [CPU_MODE = 0x%08x, CPU_STATE = 0x%08x]\\n\",\n\t\t\t  cpu_mode, cpu_state);\n\t\treturn -EBUSY;\n\t}\n\n\tqed_mcp_cmd_set_blocking(p_hwfn, false);\n\n\treturn 0;\n}\n\nint qed_mcp_ov_update_current_config(struct qed_hwfn *p_hwfn,\n\t\t\t\t     struct qed_ptt *p_ptt,\n\t\t\t\t     enum qed_ov_client client)\n{\n\tu32 resp = 0, param = 0;\n\tu32 drv_mb_param;\n\tint rc;\n\n\tswitch (client) {\n\tcase QED_OV_CLIENT_DRV:\n\t\tdrv_mb_param = DRV_MB_PARAM_OV_CURR_CFG_OS;\n\t\tbreak;\n\tcase QED_OV_CLIENT_USER:\n\t\tdrv_mb_param = DRV_MB_PARAM_OV_CURR_CFG_OTHER;\n\t\tbreak;\n\tcase QED_OV_CLIENT_VENDOR_SPEC:\n\t\tdrv_mb_param = DRV_MB_PARAM_OV_CURR_CFG_VENDOR_SPEC;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Invalid client type %d\\n\", client);\n\t\treturn -EINVAL;\n\t}\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_OV_UPDATE_CURR_CFG,\n\t\t\t drv_mb_param, &resp, &param);\n\tif (rc)\n\t\tDP_ERR(p_hwfn, \"MCP response failure, aborting\\n\");\n\n\treturn rc;\n}\n\nint qed_mcp_ov_update_driver_state(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt,\n\t\t\t\t   enum qed_ov_driver_state drv_state)\n{\n\tu32 resp = 0, param = 0;\n\tu32 drv_mb_param;\n\tint rc;\n\n\tswitch (drv_state) {\n\tcase QED_OV_DRIVER_STATE_NOT_LOADED:\n\t\tdrv_mb_param = DRV_MSG_CODE_OV_UPDATE_DRIVER_STATE_NOT_LOADED;\n\t\tbreak;\n\tcase QED_OV_DRIVER_STATE_DISABLED:\n\t\tdrv_mb_param = DRV_MSG_CODE_OV_UPDATE_DRIVER_STATE_DISABLED;\n\t\tbreak;\n\tcase QED_OV_DRIVER_STATE_ACTIVE:\n\t\tdrv_mb_param = DRV_MSG_CODE_OV_UPDATE_DRIVER_STATE_ACTIVE;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Invalid driver state %d\\n\", drv_state);\n\t\treturn -EINVAL;\n\t}\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_OV_UPDATE_DRIVER_STATE,\n\t\t\t drv_mb_param, &resp, &param);\n\tif (rc)\n\t\tDP_ERR(p_hwfn, \"Failed to send driver state\\n\");\n\n\treturn rc;\n}\n\nint qed_mcp_ov_update_mtu(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt, u16 mtu)\n{\n\tu32 resp = 0, param = 0;\n\tu32 drv_mb_param;\n\tint rc;\n\n\tdrv_mb_param = (u32)mtu << DRV_MB_PARAM_OV_MTU_SIZE_SHIFT;\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_OV_UPDATE_MTU,\n\t\t\t drv_mb_param, &resp, &param);\n\tif (rc)\n\t\tDP_ERR(p_hwfn, \"Failed to send mtu value, rc = %d\\n\", rc);\n\n\treturn rc;\n}\n\nint qed_mcp_ov_update_mac(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt, const u8 *mac)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tu32 mfw_mac[2];\n\tint rc;\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_SET_VMAC;\n\tmb_params.param = DRV_MSG_CODE_VMAC_TYPE_MAC <<\n\t\t\t  DRV_MSG_CODE_VMAC_TYPE_SHIFT;\n\tmb_params.param |= MCP_PF_ID(p_hwfn);\n\n\t \n\tmfw_mac[0] = mac[0] << 24 | mac[1] << 16 | mac[2] << 8 | mac[3];\n\tmfw_mac[1] = mac[4] << 24 | mac[5] << 16;\n\n\tmb_params.p_data_src = (u8 *)mfw_mac;\n\tmb_params.data_src_size = 8;\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\tDP_ERR(p_hwfn, \"Failed to send mac address, rc = %d\\n\", rc);\n\n\t \n\tmemcpy(p_hwfn->cdev->wol_mac, mac, ETH_ALEN);\n\n\treturn rc;\n}\n\nint qed_mcp_ov_update_wol(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt, enum qed_ov_wol wol)\n{\n\tu32 resp = 0, param = 0;\n\tu32 drv_mb_param;\n\tint rc;\n\n\tif (p_hwfn->hw_info.b_wol_support == QED_WOL_SUPPORT_NONE) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t\t   \"Can't change WoL configuration when WoL isn't supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (wol) {\n\tcase QED_OV_WOL_DEFAULT:\n\t\tdrv_mb_param = DRV_MB_PARAM_WOL_DEFAULT;\n\t\tbreak;\n\tcase QED_OV_WOL_DISABLED:\n\t\tdrv_mb_param = DRV_MB_PARAM_WOL_DISABLED;\n\t\tbreak;\n\tcase QED_OV_WOL_ENABLED:\n\t\tdrv_mb_param = DRV_MB_PARAM_WOL_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\tDP_ERR(p_hwfn, \"Invalid wol state %d\\n\", wol);\n\t\treturn -EINVAL;\n\t}\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_OV_UPDATE_WOL,\n\t\t\t drv_mb_param, &resp, &param);\n\tif (rc)\n\t\tDP_ERR(p_hwfn, \"Failed to send wol mode, rc = %d\\n\", rc);\n\n\t \n\tp_hwfn->cdev->wol_config = (u8)wol;\n\n\treturn rc;\n}\n\nint qed_mcp_ov_update_eswitch(struct qed_hwfn *p_hwfn,\n\t\t\t      struct qed_ptt *p_ptt,\n\t\t\t      enum qed_ov_eswitch eswitch)\n{\n\tu32 resp = 0, param = 0;\n\tu32 drv_mb_param;\n\tint rc;\n\n\tswitch (eswitch) {\n\tcase QED_OV_ESWITCH_NONE:\n\t\tdrv_mb_param = DRV_MB_PARAM_ESWITCH_MODE_NONE;\n\t\tbreak;\n\tcase QED_OV_ESWITCH_VEB:\n\t\tdrv_mb_param = DRV_MB_PARAM_ESWITCH_MODE_VEB;\n\t\tbreak;\n\tcase QED_OV_ESWITCH_VEPA:\n\t\tdrv_mb_param = DRV_MB_PARAM_ESWITCH_MODE_VEPA;\n\t\tbreak;\n\tdefault:\n\t\tDP_ERR(p_hwfn, \"Invalid eswitch mode %d\\n\", eswitch);\n\t\treturn -EINVAL;\n\t}\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_OV_UPDATE_ESWITCH_MODE,\n\t\t\t drv_mb_param, &resp, &param);\n\tif (rc)\n\t\tDP_ERR(p_hwfn, \"Failed to send eswitch mode, rc = %d\\n\", rc);\n\n\treturn rc;\n}\n\nint qed_mcp_set_led(struct qed_hwfn *p_hwfn,\n\t\t    struct qed_ptt *p_ptt, enum qed_led_mode mode)\n{\n\tu32 resp = 0, param = 0, drv_mb_param;\n\tint rc;\n\n\tswitch (mode) {\n\tcase QED_LED_MODE_ON:\n\t\tdrv_mb_param = DRV_MB_PARAM_SET_LED_MODE_ON;\n\t\tbreak;\n\tcase QED_LED_MODE_OFF:\n\t\tdrv_mb_param = DRV_MB_PARAM_SET_LED_MODE_OFF;\n\t\tbreak;\n\tcase QED_LED_MODE_RESTORE:\n\t\tdrv_mb_param = DRV_MB_PARAM_SET_LED_MODE_OPER;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Invalid LED mode %d\\n\", mode);\n\t\treturn -EINVAL;\n\t}\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_SET_LED_MODE,\n\t\t\t drv_mb_param, &resp, &param);\n\n\treturn rc;\n}\n\nint qed_mcp_mask_parities(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt, u32 mask_parities)\n{\n\tu32 resp = 0, param = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_MASK_PARITIES,\n\t\t\t mask_parities, &resp, &param);\n\n\tif (rc) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"MCP response failure for mask parities, aborting\\n\");\n\t} else if (resp != FW_MSG_CODE_OK) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"MCP did not acknowledge mask parity request. Old MFW?\\n\");\n\t\trc = -EINVAL;\n\t}\n\n\treturn rc;\n}\n\nint qed_mcp_nvm_read(struct qed_dev *cdev, u32 addr, u8 *p_buf, u32 len)\n{\n\tu32 bytes_left = len, offset = 0, bytes_to_copy, read_len = 0;\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tu32 resp = 0, resp_param = 0;\n\tstruct qed_ptt *p_ptt;\n\tint rc = 0;\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EBUSY;\n\n\twhile (bytes_left > 0) {\n\t\tbytes_to_copy = min_t(u32, bytes_left, MCP_DRV_NVM_BUF_LEN);\n\n\t\trc = qed_mcp_nvm_rd_cmd(p_hwfn, p_ptt,\n\t\t\t\t\tDRV_MSG_CODE_NVM_READ_NVRAM,\n\t\t\t\t\taddr + offset +\n\t\t\t\t\t(bytes_to_copy <<\n\t\t\t\t\t DRV_MB_PARAM_NVM_LEN_OFFSET),\n\t\t\t\t\t&resp, &resp_param,\n\t\t\t\t\t&read_len,\n\t\t\t\t\t(u32 *)(p_buf + offset), false);\n\n\t\tif (rc || (resp != FW_MSG_CODE_NVM_OK)) {\n\t\t\tDP_NOTICE(cdev, \"MCP command rc = %d\\n\", rc);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (bytes_left % 0x1000 <\n\t\t    (bytes_left - read_len) % 0x1000)\n\t\t\tusleep_range(1000, 2000);\n\n\t\toffset += read_len;\n\t\tbytes_left -= read_len;\n\t}\n\n\tcdev->mcp_nvm_resp = resp;\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nint qed_mcp_nvm_resp(struct qed_dev *cdev, u8 *p_buf)\n{\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt;\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EBUSY;\n\n\tmemcpy(p_buf, &cdev->mcp_nvm_resp, sizeof(cdev->mcp_nvm_resp));\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn 0;\n}\n\nint qed_mcp_nvm_write(struct qed_dev *cdev,\n\t\t      u32 cmd, u32 addr, u8 *p_buf, u32 len)\n{\n\tu32 buf_idx = 0, buf_size, nvm_cmd, nvm_offset, resp = 0, param;\n\tstruct qed_hwfn *p_hwfn = QED_LEADING_HWFN(cdev);\n\tstruct qed_ptt *p_ptt;\n\tint rc = -EINVAL;\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt)\n\t\treturn -EBUSY;\n\n\tswitch (cmd) {\n\tcase QED_PUT_FILE_BEGIN:\n\t\tnvm_cmd = DRV_MSG_CODE_NVM_PUT_FILE_BEGIN;\n\t\tbreak;\n\tcase QED_PUT_FILE_DATA:\n\t\tnvm_cmd = DRV_MSG_CODE_NVM_PUT_FILE_DATA;\n\t\tbreak;\n\tcase QED_NVM_WRITE_NVRAM:\n\t\tnvm_cmd = DRV_MSG_CODE_NVM_WRITE_NVRAM;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Invalid nvm write command 0x%x\\n\", cmd);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tbuf_size = min_t(u32, (len - buf_idx), MCP_DRV_NVM_BUF_LEN);\n\twhile (buf_idx < len) {\n\t\tif (cmd == QED_PUT_FILE_BEGIN)\n\t\t\tnvm_offset = addr;\n\t\telse\n\t\t\tnvm_offset = ((buf_size <<\n\t\t\t\t       DRV_MB_PARAM_NVM_LEN_OFFSET) | addr) +\n\t\t\t\t       buf_idx;\n\t\trc = qed_mcp_nvm_wr_cmd(p_hwfn, p_ptt, nvm_cmd, nvm_offset,\n\t\t\t\t\t&resp, &param, buf_size,\n\t\t\t\t\t(u32 *)&p_buf[buf_idx]);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(cdev, \"nvm write failed, rc = %d\\n\", rc);\n\t\t\tresp = FW_MSG_CODE_ERROR;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (resp != FW_MSG_CODE_OK &&\n\t\t    resp != FW_MSG_CODE_NVM_OK &&\n\t\t    resp != FW_MSG_CODE_NVM_PUT_FILE_FINISH_OK) {\n\t\t\tDP_NOTICE(cdev,\n\t\t\t\t  \"nvm write failed, resp = 0x%08x\\n\", resp);\n\t\t\trc = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (buf_idx % 0x1000 > (buf_idx + buf_size) % 0x1000)\n\t\t\tusleep_range(1000, 2000);\n\n\t\t \n\t\tif (param && cmd == QED_PUT_FILE_DATA) {\n\t\t\tbuf_idx =\n\t\t\tQED_MFW_GET_FIELD(param,\n\t\t\t\t\t  FW_MB_PARAM_NVM_PUT_FILE_REQ_OFFSET);\n\t\t\tbuf_size =\n\t\t\tQED_MFW_GET_FIELD(param,\n\t\t\t\t\t  FW_MB_PARAM_NVM_PUT_FILE_REQ_SIZE);\n\t\t} else {\n\t\t\tbuf_idx += buf_size;\n\t\t\tbuf_size = min_t(u32, (len - buf_idx),\n\t\t\t\t\t MCP_DRV_NVM_BUF_LEN);\n\t\t}\n\t}\n\n\tcdev->mcp_nvm_resp = resp;\nout:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\n\treturn rc;\n}\n\nint qed_mcp_phy_sfp_read(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t\t u32 port, u32 addr, u32 offset, u32 len, u8 *p_buf)\n{\n\tu32 bytes_left, bytes_to_copy, buf_size, nvm_offset = 0;\n\tu32 resp, param;\n\tint rc;\n\n\tnvm_offset |= (port << DRV_MB_PARAM_TRANSCEIVER_PORT_OFFSET) &\n\t\t       DRV_MB_PARAM_TRANSCEIVER_PORT_MASK;\n\tnvm_offset |= (addr << DRV_MB_PARAM_TRANSCEIVER_I2C_ADDRESS_OFFSET) &\n\t\t       DRV_MB_PARAM_TRANSCEIVER_I2C_ADDRESS_MASK;\n\n\taddr = offset;\n\toffset = 0;\n\tbytes_left = len;\n\twhile (bytes_left > 0) {\n\t\tbytes_to_copy = min_t(u32, bytes_left,\n\t\t\t\t      MAX_I2C_TRANSACTION_SIZE);\n\t\tnvm_offset &= (DRV_MB_PARAM_TRANSCEIVER_I2C_ADDRESS_MASK |\n\t\t\t       DRV_MB_PARAM_TRANSCEIVER_PORT_MASK);\n\t\tnvm_offset |= ((addr + offset) <<\n\t\t\t       DRV_MB_PARAM_TRANSCEIVER_OFFSET_OFFSET) &\n\t\t\t       DRV_MB_PARAM_TRANSCEIVER_OFFSET_MASK;\n\t\tnvm_offset |= (bytes_to_copy <<\n\t\t\t       DRV_MB_PARAM_TRANSCEIVER_SIZE_OFFSET) &\n\t\t\t       DRV_MB_PARAM_TRANSCEIVER_SIZE_MASK;\n\t\trc = qed_mcp_nvm_rd_cmd(p_hwfn, p_ptt,\n\t\t\t\t\tDRV_MSG_CODE_TRANSCEIVER_READ,\n\t\t\t\t\tnvm_offset, &resp, &param, &buf_size,\n\t\t\t\t\t(u32 *)(p_buf + offset), true);\n\t\tif (rc) {\n\t\t\tDP_NOTICE(p_hwfn,\n\t\t\t\t  \"Failed to send a transceiver read command to the MFW. rc = %d.\\n\",\n\t\t\t\t  rc);\n\t\t\treturn rc;\n\t\t}\n\n\t\tif (resp == FW_MSG_CODE_TRANSCEIVER_NOT_PRESENT)\n\t\t\treturn -ENODEV;\n\t\telse if (resp != FW_MSG_CODE_TRANSCEIVER_DIAG_OK)\n\t\t\treturn -EINVAL;\n\n\t\toffset += buf_size;\n\t\tbytes_left -= buf_size;\n\t}\n\n\treturn 0;\n}\n\nint qed_mcp_bist_register_test(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 drv_mb_param = 0, rsp, param;\n\tint rc = 0;\n\n\tdrv_mb_param = (DRV_MB_PARAM_BIST_REGISTER_TEST <<\n\t\t\tDRV_MB_PARAM_BIST_TEST_INDEX_SHIFT);\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_BIST_TEST,\n\t\t\t drv_mb_param, &rsp, &param);\n\n\tif (rc)\n\t\treturn rc;\n\n\tif (((rsp & FW_MSG_CODE_MASK) != FW_MSG_CODE_OK) ||\n\t    (param != DRV_MB_PARAM_BIST_RC_PASSED))\n\t\trc = -EAGAIN;\n\n\treturn rc;\n}\n\nint qed_mcp_bist_clock_test(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 drv_mb_param, rsp, param;\n\tint rc = 0;\n\n\tdrv_mb_param = (DRV_MB_PARAM_BIST_CLOCK_TEST <<\n\t\t\tDRV_MB_PARAM_BIST_TEST_INDEX_SHIFT);\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_BIST_TEST,\n\t\t\t drv_mb_param, &rsp, &param);\n\n\tif (rc)\n\t\treturn rc;\n\n\tif (((rsp & FW_MSG_CODE_MASK) != FW_MSG_CODE_OK) ||\n\t    (param != DRV_MB_PARAM_BIST_RC_PASSED))\n\t\trc = -EAGAIN;\n\n\treturn rc;\n}\n\nint qed_mcp_bist_nvm_get_num_images(struct qed_hwfn *p_hwfn,\n\t\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t\t    u32 *num_images)\n{\n\tu32 drv_mb_param = 0, rsp;\n\tint rc = 0;\n\n\tdrv_mb_param = (DRV_MB_PARAM_BIST_NVM_TEST_NUM_IMAGES <<\n\t\t\tDRV_MB_PARAM_BIST_TEST_INDEX_SHIFT);\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_BIST_TEST,\n\t\t\t drv_mb_param, &rsp, num_images);\n\tif (rc)\n\t\treturn rc;\n\n\tif (((rsp & FW_MSG_CODE_MASK) != FW_MSG_CODE_OK))\n\t\trc = -EINVAL;\n\n\treturn rc;\n}\n\nint qed_mcp_bist_nvm_get_image_att(struct qed_hwfn *p_hwfn,\n\t\t\t\t   struct qed_ptt *p_ptt,\n\t\t\t\t   struct bist_nvm_image_att *p_image_att,\n\t\t\t\t   u32 image_index)\n{\n\tu32 buf_size = 0, param, resp = 0, resp_param = 0;\n\tint rc;\n\n\tparam = DRV_MB_PARAM_BIST_NVM_TEST_IMAGE_BY_INDEX <<\n\t\tDRV_MB_PARAM_BIST_TEST_INDEX_SHIFT;\n\tparam |= image_index << DRV_MB_PARAM_BIST_TEST_IMAGE_INDEX_SHIFT;\n\n\trc = qed_mcp_nvm_rd_cmd(p_hwfn, p_ptt,\n\t\t\t\tDRV_MSG_CODE_BIST_TEST, param,\n\t\t\t\t&resp, &resp_param,\n\t\t\t\t&buf_size,\n\t\t\t\t(u32 *)p_image_att, false);\n\tif (rc)\n\t\treturn rc;\n\n\tif (((resp & FW_MSG_CODE_MASK) != FW_MSG_CODE_OK) ||\n\t    (p_image_att->return_code != 1))\n\t\trc = -EINVAL;\n\n\treturn rc;\n}\n\nint qed_mcp_nvm_info_populate(struct qed_hwfn *p_hwfn)\n{\n\tstruct qed_nvm_image_info nvm_info;\n\tstruct qed_ptt *p_ptt;\n\tint rc;\n\tu32 i;\n\n\tif (p_hwfn->nvm_info.valid)\n\t\treturn 0;\n\n\tp_ptt = qed_ptt_acquire(p_hwfn);\n\tif (!p_ptt) {\n\t\tDP_ERR(p_hwfn, \"failed to acquire ptt\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tnvm_info.num_images = 0;\n\trc = qed_mcp_bist_nvm_get_num_images(p_hwfn,\n\t\t\t\t\t     p_ptt, &nvm_info.num_images);\n\tif (rc == -EOPNOTSUPP) {\n\t\tDP_INFO(p_hwfn, \"DRV_MSG_CODE_BIST_TEST is not supported\\n\");\n\t\tgoto out;\n\t} else if (rc || !nvm_info.num_images) {\n\t\tDP_ERR(p_hwfn, \"Failed getting number of images\\n\");\n\t\tgoto err0;\n\t}\n\n\tnvm_info.image_att = kmalloc_array(nvm_info.num_images,\n\t\t\t\t\t   sizeof(struct bist_nvm_image_att),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!nvm_info.image_att) {\n\t\trc = -ENOMEM;\n\t\tgoto err0;\n\t}\n\n\t \n\tfor (i = 0; i < nvm_info.num_images; i++) {\n\t\trc = qed_mcp_bist_nvm_get_image_att(p_hwfn, p_ptt,\n\t\t\t\t\t\t    &nvm_info.image_att[i], i);\n\t\tif (rc) {\n\t\t\tDP_ERR(p_hwfn,\n\t\t\t       \"Failed getting image index %d attributes\\n\", i);\n\t\t\tgoto err1;\n\t\t}\n\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_SP, \"image index %d, size %x\\n\", i,\n\t\t\t   nvm_info.image_att[i].len);\n\t}\nout:\n\t \n\tif (nvm_info.num_images) {\n\t\tp_hwfn->nvm_info.num_images = nvm_info.num_images;\n\t\tkfree(p_hwfn->nvm_info.image_att);\n\t\tp_hwfn->nvm_info.image_att = nvm_info.image_att;\n\t\tp_hwfn->nvm_info.valid = true;\n\t}\n\n\tqed_ptt_release(p_hwfn, p_ptt);\n\treturn 0;\n\nerr1:\n\tkfree(nvm_info.image_att);\nerr0:\n\tqed_ptt_release(p_hwfn, p_ptt);\n\treturn rc;\n}\n\nvoid qed_mcp_nvm_info_free(struct qed_hwfn *p_hwfn)\n{\n\tkfree(p_hwfn->nvm_info.image_att);\n\tp_hwfn->nvm_info.image_att = NULL;\n\tp_hwfn->nvm_info.valid = false;\n}\n\nint\nqed_mcp_get_nvm_image_att(struct qed_hwfn *p_hwfn,\n\t\t\t  enum qed_nvm_images image_id,\n\t\t\t  struct qed_nvm_image_att *p_image_att)\n{\n\tenum nvm_image_type type;\n\tint rc;\n\tu32 i;\n\n\t \n\tswitch (image_id) {\n\tcase QED_NVM_IMAGE_ISCSI_CFG:\n\t\ttype = NVM_TYPE_ISCSI_CFG;\n\t\tbreak;\n\tcase QED_NVM_IMAGE_FCOE_CFG:\n\t\ttype = NVM_TYPE_FCOE_CFG;\n\t\tbreak;\n\tcase QED_NVM_IMAGE_MDUMP:\n\t\ttype = NVM_TYPE_MDUMP;\n\t\tbreak;\n\tcase QED_NVM_IMAGE_NVM_CFG1:\n\t\ttype = NVM_TYPE_NVM_CFG1;\n\t\tbreak;\n\tcase QED_NVM_IMAGE_DEFAULT_CFG:\n\t\ttype = NVM_TYPE_DEFAULT_CFG;\n\t\tbreak;\n\tcase QED_NVM_IMAGE_NVM_META:\n\t\ttype = NVM_TYPE_NVM_META;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn, \"Unknown request of image_id %08x\\n\",\n\t\t\t  image_id);\n\t\treturn -EINVAL;\n\t}\n\n\trc = qed_mcp_nvm_info_populate(p_hwfn);\n\tif (rc)\n\t\treturn rc;\n\n\tfor (i = 0; i < p_hwfn->nvm_info.num_images; i++)\n\t\tif (type == p_hwfn->nvm_info.image_att[i].image_type)\n\t\t\tbreak;\n\tif (i == p_hwfn->nvm_info.num_images) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_STORAGE,\n\t\t\t   \"Failed to find nvram image of type %08x\\n\",\n\t\t\t   image_id);\n\t\treturn -ENOENT;\n\t}\n\n\tp_image_att->start_addr = p_hwfn->nvm_info.image_att[i].nvm_start_addr;\n\tp_image_att->length = p_hwfn->nvm_info.image_att[i].len;\n\n\treturn 0;\n}\n\nint qed_mcp_get_nvm_image(struct qed_hwfn *p_hwfn,\n\t\t\t  enum qed_nvm_images image_id,\n\t\t\t  u8 *p_buffer, u32 buffer_len)\n{\n\tstruct qed_nvm_image_att image_att;\n\tint rc;\n\n\tmemset(p_buffer, 0, buffer_len);\n\n\trc = qed_mcp_get_nvm_image_att(p_hwfn, image_id, &image_att);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (image_att.length <= 4) {\n\t\tDP_VERBOSE(p_hwfn, QED_MSG_STORAGE,\n\t\t\t   \"Image [%d] is too small - only %d bytes\\n\",\n\t\t\t   image_id, image_att.length);\n\t\treturn -EINVAL;\n\t}\n\n\tif (image_att.length > buffer_len) {\n\t\tDP_VERBOSE(p_hwfn,\n\t\t\t   QED_MSG_STORAGE,\n\t\t\t   \"Image [%d] is too big - %08x bytes where only %08x are available\\n\",\n\t\t\t   image_id, image_att.length, buffer_len);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn qed_mcp_nvm_read(p_hwfn->cdev, image_att.start_addr,\n\t\t\t\tp_buffer, image_att.length);\n}\n\nstatic enum resource_id_enum qed_mcp_get_mfw_res_id(enum qed_resources res_id)\n{\n\tenum resource_id_enum mfw_res_id = RESOURCE_NUM_INVALID;\n\n\tswitch (res_id) {\n\tcase QED_SB:\n\t\tmfw_res_id = RESOURCE_NUM_SB_E;\n\t\tbreak;\n\tcase QED_L2_QUEUE:\n\t\tmfw_res_id = RESOURCE_NUM_L2_QUEUE_E;\n\t\tbreak;\n\tcase QED_VPORT:\n\t\tmfw_res_id = RESOURCE_NUM_VPORT_E;\n\t\tbreak;\n\tcase QED_RSS_ENG:\n\t\tmfw_res_id = RESOURCE_NUM_RSS_ENGINES_E;\n\t\tbreak;\n\tcase QED_PQ:\n\t\tmfw_res_id = RESOURCE_NUM_PQ_E;\n\t\tbreak;\n\tcase QED_RL:\n\t\tmfw_res_id = RESOURCE_NUM_RL_E;\n\t\tbreak;\n\tcase QED_MAC:\n\tcase QED_VLAN:\n\t\t \n\t\tmfw_res_id = RESOURCE_VFC_FILTER_E;\n\t\tbreak;\n\tcase QED_ILT:\n\t\tmfw_res_id = RESOURCE_ILT_E;\n\t\tbreak;\n\tcase QED_LL2_RAM_QUEUE:\n\t\tmfw_res_id = RESOURCE_LL2_QUEUE_E;\n\t\tbreak;\n\tcase QED_LL2_CTX_QUEUE:\n\t\tmfw_res_id = RESOURCE_LL2_CQS_E;\n\t\tbreak;\n\tcase QED_RDMA_CNQ_RAM:\n\tcase QED_CMDQS_CQS:\n\t\t \n\t\tmfw_res_id = RESOURCE_CQS_E;\n\t\tbreak;\n\tcase QED_RDMA_STATS_QUEUE:\n\t\tmfw_res_id = RESOURCE_RDMA_STATS_QUEUE_E;\n\t\tbreak;\n\tcase QED_BDQ:\n\t\tmfw_res_id = RESOURCE_BDQ_E;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn mfw_res_id;\n}\n\n#define QED_RESC_ALLOC_VERSION_MAJOR    2\n#define QED_RESC_ALLOC_VERSION_MINOR    0\n#define QED_RESC_ALLOC_VERSION\t\t\t\t     \\\n\t((QED_RESC_ALLOC_VERSION_MAJOR <<\t\t     \\\n\t  DRV_MB_PARAM_RESOURCE_ALLOC_VERSION_MAJOR_SHIFT) | \\\n\t (QED_RESC_ALLOC_VERSION_MINOR <<\t\t     \\\n\t  DRV_MB_PARAM_RESOURCE_ALLOC_VERSION_MINOR_SHIFT))\n\nstruct qed_resc_alloc_in_params {\n\tu32 cmd;\n\tenum qed_resources res_id;\n\tu32 resc_max_val;\n};\n\nstruct qed_resc_alloc_out_params {\n\tu32 mcp_resp;\n\tu32 mcp_param;\n\tu32 resc_num;\n\tu32 resc_start;\n\tu32 vf_resc_num;\n\tu32 vf_resc_start;\n\tu32 flags;\n};\n\nstatic int\nqed_mcp_resc_allocation_msg(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_ptt *p_ptt,\n\t\t\t    struct qed_resc_alloc_in_params *p_in_params,\n\t\t\t    struct qed_resc_alloc_out_params *p_out_params)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tstruct resource_info mfw_resc_info;\n\tint rc;\n\n\tmemset(&mfw_resc_info, 0, sizeof(mfw_resc_info));\n\n\tmfw_resc_info.res_id = qed_mcp_get_mfw_res_id(p_in_params->res_id);\n\tif (mfw_resc_info.res_id == RESOURCE_NUM_INVALID) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"Failed to match resource %d [%s] with the MFW resources\\n\",\n\t\t       p_in_params->res_id,\n\t\t       qed_hw_get_resc_name(p_in_params->res_id));\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (p_in_params->cmd) {\n\tcase DRV_MSG_SET_RESOURCE_VALUE_MSG:\n\t\tmfw_resc_info.size = p_in_params->resc_max_val;\n\t\tfallthrough;\n\tcase DRV_MSG_GET_RESOURCE_ALLOC_MSG:\n\t\tbreak;\n\tdefault:\n\t\tDP_ERR(p_hwfn, \"Unexpected resource alloc command [0x%08x]\\n\",\n\t\t       p_in_params->cmd);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = p_in_params->cmd;\n\tmb_params.param = QED_RESC_ALLOC_VERSION;\n\tmb_params.p_data_src = &mfw_resc_info;\n\tmb_params.data_src_size = sizeof(mfw_resc_info);\n\tmb_params.p_data_dst = mb_params.p_data_src;\n\tmb_params.data_dst_size = mb_params.data_src_size;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SP,\n\t\t   \"Resource message request: cmd 0x%08x, res_id %d [%s], hsi_version %d.%d, val 0x%x\\n\",\n\t\t   p_in_params->cmd,\n\t\t   p_in_params->res_id,\n\t\t   qed_hw_get_resc_name(p_in_params->res_id),\n\t\t   QED_MFW_GET_FIELD(mb_params.param,\n\t\t\t\t     DRV_MB_PARAM_RESOURCE_ALLOC_VERSION_MAJOR),\n\t\t   QED_MFW_GET_FIELD(mb_params.param,\n\t\t\t\t     DRV_MB_PARAM_RESOURCE_ALLOC_VERSION_MINOR),\n\t\t   p_in_params->resc_max_val);\n\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\tp_out_params->mcp_resp = mb_params.mcp_resp;\n\tp_out_params->mcp_param = mb_params.mcp_param;\n\tp_out_params->resc_num = mfw_resc_info.size;\n\tp_out_params->resc_start = mfw_resc_info.offset;\n\tp_out_params->vf_resc_num = mfw_resc_info.vf_size;\n\tp_out_params->vf_resc_start = mfw_resc_info.vf_offset;\n\tp_out_params->flags = mfw_resc_info.flags;\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SP,\n\t\t   \"Resource message response: mfw_hsi_version %d.%d, num 0x%x, start 0x%x, vf_num 0x%x, vf_start 0x%x, flags 0x%08x\\n\",\n\t\t   QED_MFW_GET_FIELD(p_out_params->mcp_param,\n\t\t\t\t     FW_MB_PARAM_RESOURCE_ALLOC_VERSION_MAJOR),\n\t\t   QED_MFW_GET_FIELD(p_out_params->mcp_param,\n\t\t\t\t     FW_MB_PARAM_RESOURCE_ALLOC_VERSION_MINOR),\n\t\t   p_out_params->resc_num,\n\t\t   p_out_params->resc_start,\n\t\t   p_out_params->vf_resc_num,\n\t\t   p_out_params->vf_resc_start, p_out_params->flags);\n\n\treturn 0;\n}\n\nint\nqed_mcp_set_resc_max_val(struct qed_hwfn *p_hwfn,\n\t\t\t struct qed_ptt *p_ptt,\n\t\t\t enum qed_resources res_id,\n\t\t\t u32 resc_max_val, u32 *p_mcp_resp)\n{\n\tstruct qed_resc_alloc_out_params out_params;\n\tstruct qed_resc_alloc_in_params in_params;\n\tint rc;\n\n\tmemset(&in_params, 0, sizeof(in_params));\n\tin_params.cmd = DRV_MSG_SET_RESOURCE_VALUE_MSG;\n\tin_params.res_id = res_id;\n\tin_params.resc_max_val = resc_max_val;\n\tmemset(&out_params, 0, sizeof(out_params));\n\trc = qed_mcp_resc_allocation_msg(p_hwfn, p_ptt, &in_params,\n\t\t\t\t\t &out_params);\n\tif (rc)\n\t\treturn rc;\n\n\t*p_mcp_resp = out_params.mcp_resp;\n\n\treturn 0;\n}\n\nint\nqed_mcp_get_resc_info(struct qed_hwfn *p_hwfn,\n\t\t      struct qed_ptt *p_ptt,\n\t\t      enum qed_resources res_id,\n\t\t      u32 *p_mcp_resp, u32 *p_resc_num, u32 *p_resc_start)\n{\n\tstruct qed_resc_alloc_out_params out_params;\n\tstruct qed_resc_alloc_in_params in_params;\n\tint rc;\n\n\tmemset(&in_params, 0, sizeof(in_params));\n\tin_params.cmd = DRV_MSG_GET_RESOURCE_ALLOC_MSG;\n\tin_params.res_id = res_id;\n\tmemset(&out_params, 0, sizeof(out_params));\n\trc = qed_mcp_resc_allocation_msg(p_hwfn, p_ptt, &in_params,\n\t\t\t\t\t &out_params);\n\tif (rc)\n\t\treturn rc;\n\n\t*p_mcp_resp = out_params.mcp_resp;\n\n\tif (*p_mcp_resp == FW_MSG_CODE_RESOURCE_ALLOC_OK) {\n\t\t*p_resc_num = out_params.resc_num;\n\t\t*p_resc_start = out_params.resc_start;\n\t}\n\n\treturn 0;\n}\n\nint qed_mcp_initiate_pf_flr(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 mcp_resp, mcp_param;\n\n\treturn qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_INITIATE_PF_FLR, 0,\n\t\t\t   &mcp_resp, &mcp_param);\n}\n\nstatic int qed_mcp_resource_cmd(struct qed_hwfn *p_hwfn,\n\t\t\t\tstruct qed_ptt *p_ptt,\n\t\t\t\tu32 param, u32 *p_mcp_resp, u32 *p_mcp_param)\n{\n\tint rc;\n\n\trc = qed_mcp_cmd_nosleep(p_hwfn, p_ptt, DRV_MSG_CODE_RESOURCE_CMD,\n\t\t\t\t param, p_mcp_resp, p_mcp_param);\n\tif (rc)\n\t\treturn rc;\n\n\tif (*p_mcp_resp == FW_MSG_CODE_UNSUPPORTED) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"The resource command is unsupported by the MFW\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (*p_mcp_param == RESOURCE_OPCODE_UNKNOWN_CMD) {\n\t\tu8 opcode = QED_MFW_GET_FIELD(param, RESOURCE_CMD_REQ_OPCODE);\n\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"The resource command is unknown to the MFW [param 0x%08x, opcode %d]\\n\",\n\t\t\t  param, opcode);\n\t\treturn -EINVAL;\n\t}\n\n\treturn rc;\n}\n\nstatic int\n__qed_mcp_resc_lock(struct qed_hwfn *p_hwfn,\n\t\t    struct qed_ptt *p_ptt,\n\t\t    struct qed_resc_lock_params *p_params)\n{\n\tu32 param = 0, mcp_resp, mcp_param;\n\tu8 opcode;\n\tint rc;\n\n\tswitch (p_params->timeout) {\n\tcase QED_MCP_RESC_LOCK_TO_DEFAULT:\n\t\topcode = RESOURCE_OPCODE_REQ;\n\t\tp_params->timeout = 0;\n\t\tbreak;\n\tcase QED_MCP_RESC_LOCK_TO_NONE:\n\t\topcode = RESOURCE_OPCODE_REQ_WO_AGING;\n\t\tp_params->timeout = 0;\n\t\tbreak;\n\tdefault:\n\t\topcode = RESOURCE_OPCODE_REQ_W_AGING;\n\t\tbreak;\n\t}\n\n\tQED_MFW_SET_FIELD(param, RESOURCE_CMD_REQ_RESC, p_params->resource);\n\tQED_MFW_SET_FIELD(param, RESOURCE_CMD_REQ_OPCODE, opcode);\n\tQED_MFW_SET_FIELD(param, RESOURCE_CMD_REQ_AGE, p_params->timeout);\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SP,\n\t\t   \"Resource lock request: param 0x%08x [age %d, opcode %d, resource %d]\\n\",\n\t\t   param, p_params->timeout, opcode, p_params->resource);\n\n\t \n\trc = qed_mcp_resource_cmd(p_hwfn, p_ptt, param, &mcp_resp, &mcp_param);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tp_params->owner = QED_MFW_GET_FIELD(mcp_param, RESOURCE_CMD_RSP_OWNER);\n\topcode = QED_MFW_GET_FIELD(mcp_param, RESOURCE_CMD_RSP_OPCODE);\n\n\tDP_VERBOSE(p_hwfn,\n\t\t   QED_MSG_SP,\n\t\t   \"Resource lock response: mcp_param 0x%08x [opcode %d, owner %d]\\n\",\n\t\t   mcp_param, opcode, p_params->owner);\n\n\tswitch (opcode) {\n\tcase RESOURCE_OPCODE_GNT:\n\t\tp_params->b_granted = true;\n\t\tbreak;\n\tcase RESOURCE_OPCODE_BUSY:\n\t\tp_params->b_granted = false;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unexpected opcode in resource lock response [mcp_param 0x%08x, opcode %d]\\n\",\n\t\t\t  mcp_param, opcode);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nint\nqed_mcp_resc_lock(struct qed_hwfn *p_hwfn,\n\t\t  struct qed_ptt *p_ptt, struct qed_resc_lock_params *p_params)\n{\n\tu32 retry_cnt = 0;\n\tint rc;\n\n\tdo {\n\t\t \n\t\tif (retry_cnt) {\n\t\t\tif (p_params->sleep_b4_retry) {\n\t\t\t\tu16 retry_interval_in_ms =\n\t\t\t\t    DIV_ROUND_UP(p_params->retry_interval,\n\t\t\t\t\t\t 1000);\n\n\t\t\t\tmsleep(retry_interval_in_ms);\n\t\t\t} else {\n\t\t\t\tudelay(p_params->retry_interval);\n\t\t\t}\n\t\t}\n\n\t\trc = __qed_mcp_resc_lock(p_hwfn, p_ptt, p_params);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tif (p_params->b_granted)\n\t\t\tbreak;\n\t} while (retry_cnt++ < p_params->retry_num);\n\n\treturn 0;\n}\n\nint\nqed_mcp_resc_unlock(struct qed_hwfn *p_hwfn,\n\t\t    struct qed_ptt *p_ptt,\n\t\t    struct qed_resc_unlock_params *p_params)\n{\n\tu32 param = 0, mcp_resp, mcp_param;\n\tu8 opcode;\n\tint rc;\n\n\topcode = p_params->b_force ? RESOURCE_OPCODE_FORCE_RELEASE\n\t\t\t\t   : RESOURCE_OPCODE_RELEASE;\n\tQED_MFW_SET_FIELD(param, RESOURCE_CMD_REQ_RESC, p_params->resource);\n\tQED_MFW_SET_FIELD(param, RESOURCE_CMD_REQ_OPCODE, opcode);\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"Resource unlock request: param 0x%08x [opcode %d, resource %d]\\n\",\n\t\t   param, opcode, p_params->resource);\n\n\t \n\trc = qed_mcp_resource_cmd(p_hwfn, p_ptt, param, &mcp_resp, &mcp_param);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\topcode = QED_MFW_GET_FIELD(mcp_param, RESOURCE_CMD_RSP_OPCODE);\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP,\n\t\t   \"Resource unlock response: mcp_param 0x%08x [opcode %d]\\n\",\n\t\t   mcp_param, opcode);\n\n\tswitch (opcode) {\n\tcase RESOURCE_OPCODE_RELEASED_PREVIOUS:\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"Resource unlock request for an already released resource [%d]\\n\",\n\t\t\tp_params->resource);\n\t\tfallthrough;\n\tcase RESOURCE_OPCODE_RELEASED:\n\t\tp_params->b_released = true;\n\t\tbreak;\n\tcase RESOURCE_OPCODE_WRONG_OWNER:\n\t\tp_params->b_released = false;\n\t\tbreak;\n\tdefault:\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Unexpected opcode in resource unlock response [mcp_param 0x%08x, opcode %d]\\n\",\n\t\t\t  mcp_param, opcode);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nvoid qed_mcp_resc_lock_default_init(struct qed_resc_lock_params *p_lock,\n\t\t\t\t    struct qed_resc_unlock_params *p_unlock,\n\t\t\t\t    enum qed_resc_lock\n\t\t\t\t    resource, bool b_is_permanent)\n{\n\tif (p_lock) {\n\t\tmemset(p_lock, 0, sizeof(*p_lock));\n\n\t\t \n\t\tif (b_is_permanent) {\n\t\t\tp_lock->timeout = QED_MCP_RESC_LOCK_TO_NONE;\n\t\t} else {\n\t\t\tp_lock->retry_num = QED_MCP_RESC_LOCK_RETRY_CNT_DFLT;\n\t\t\tp_lock->retry_interval =\n\t\t\t    QED_MCP_RESC_LOCK_RETRY_VAL_DFLT;\n\t\t\tp_lock->sleep_b4_retry = true;\n\t\t}\n\n\t\tp_lock->resource = resource;\n\t}\n\n\tif (p_unlock) {\n\t\tmemset(p_unlock, 0, sizeof(*p_unlock));\n\t\tp_unlock->resource = resource;\n\t}\n}\n\nbool qed_mcp_is_smart_an_supported(struct qed_hwfn *p_hwfn)\n{\n\treturn !!(p_hwfn->mcp_info->capabilities &\n\t\t  FW_MB_PARAM_FEATURE_SUPPORT_SMARTLINQ);\n}\n\nint qed_mcp_get_capabilities(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 mcp_resp;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_GET_MFW_FEATURE_SUPPORT,\n\t\t\t 0, &mcp_resp, &p_hwfn->mcp_info->capabilities);\n\tif (!rc)\n\t\tDP_VERBOSE(p_hwfn, (QED_MSG_SP | NETIF_MSG_PROBE),\n\t\t\t   \"MFW supported features: %08x\\n\",\n\t\t\t   p_hwfn->mcp_info->capabilities);\n\n\treturn rc;\n}\n\nint qed_mcp_set_capabilities(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tu32 mcp_resp, mcp_param, features;\n\n\tfeatures = DRV_MB_PARAM_FEATURE_SUPPORT_PORT_EEE |\n\t\t   DRV_MB_PARAM_FEATURE_SUPPORT_FUNC_VLINK |\n\t\t   DRV_MB_PARAM_FEATURE_SUPPORT_PORT_FEC_CONTROL;\n\n\treturn qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_FEATURE_SUPPORT,\n\t\t\t   features, &mcp_resp, &mcp_param);\n}\n\nint qed_mcp_get_engine_config(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_mb_params mb_params = {0};\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tu8 fir_valid, l2_valid;\n\tint rc;\n\n\tmb_params.cmd = DRV_MSG_CODE_GET_ENGINE_CONFIG;\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\tif (mb_params.mcp_resp == FW_MSG_CODE_UNSUPPORTED) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"The get_engine_config command is unsupported by the MFW\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tfir_valid = QED_MFW_GET_FIELD(mb_params.mcp_param,\n\t\t\t\t      FW_MB_PARAM_ENG_CFG_FIR_AFFIN_VALID);\n\tif (fir_valid)\n\t\tcdev->fir_affin =\n\t\t    QED_MFW_GET_FIELD(mb_params.mcp_param,\n\t\t\t\t      FW_MB_PARAM_ENG_CFG_FIR_AFFIN_VALUE);\n\n\tl2_valid = QED_MFW_GET_FIELD(mb_params.mcp_param,\n\t\t\t\t     FW_MB_PARAM_ENG_CFG_L2_AFFIN_VALID);\n\tif (l2_valid)\n\t\tcdev->l2_affin_hint =\n\t\t    QED_MFW_GET_FIELD(mb_params.mcp_param,\n\t\t\t\t      FW_MB_PARAM_ENG_CFG_L2_AFFIN_VALUE);\n\n\tDP_INFO(p_hwfn,\n\t\t\"Engine affinity config: FIR={valid %hhd, value %hhd}, L2_hint={valid %hhd, value %hhd}\\n\",\n\t\tfir_valid, cdev->fir_affin, l2_valid, cdev->l2_affin_hint);\n\n\treturn 0;\n}\n\nint qed_mcp_get_ppfid_bitmap(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)\n{\n\tstruct qed_mcp_mb_params mb_params = {0};\n\tstruct qed_dev *cdev = p_hwfn->cdev;\n\tint rc;\n\n\tmb_params.cmd = DRV_MSG_CODE_GET_PPFID_BITMAP;\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\tif (mb_params.mcp_resp == FW_MSG_CODE_UNSUPPORTED) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"The get_ppfid_bitmap command is unsupported by the MFW\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tcdev->ppfid_bitmap = QED_MFW_GET_FIELD(mb_params.mcp_param,\n\t\t\t\t\t       FW_MB_PARAM_PPFID_BITMAP);\n\n\tDP_VERBOSE(p_hwfn, QED_MSG_SP, \"PPFID bitmap 0x%hhx\\n\",\n\t\t   cdev->ppfid_bitmap);\n\n\treturn 0;\n}\n\nint qed_mcp_nvm_get_cfg(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t\tu16 option_id, u8 entity_id, u16 flags, u8 *p_buf,\n\t\t\tu32 *p_len)\n{\n\tu32 mb_param = 0, resp, param;\n\tint rc;\n\n\tQED_MFW_SET_FIELD(mb_param, DRV_MB_PARAM_NVM_CFG_OPTION_ID, option_id);\n\tif (flags & QED_NVM_CFG_OPTION_INIT)\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_INIT, 1);\n\tif (flags & QED_NVM_CFG_OPTION_FREE)\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_FREE, 1);\n\tif (flags & QED_NVM_CFG_OPTION_ENTITY_SEL) {\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_ENTITY_SEL, 1);\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_ENTITY_ID,\n\t\t\t\t  entity_id);\n\t}\n\n\trc = qed_mcp_nvm_rd_cmd(p_hwfn, p_ptt,\n\t\t\t\tDRV_MSG_CODE_GET_NVM_CFG_OPTION,\n\t\t\t\tmb_param, &resp, &param, p_len,\n\t\t\t\t(u32 *)p_buf, false);\n\n\treturn rc;\n}\n\nint qed_mcp_nvm_set_cfg(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,\n\t\t\tu16 option_id, u8 entity_id, u16 flags, u8 *p_buf,\n\t\t\tu32 len)\n{\n\tu32 mb_param = 0, resp, param;\n\n\tQED_MFW_SET_FIELD(mb_param, DRV_MB_PARAM_NVM_CFG_OPTION_ID, option_id);\n\tif (flags & QED_NVM_CFG_OPTION_ALL)\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_ALL, 1);\n\tif (flags & QED_NVM_CFG_OPTION_INIT)\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_INIT, 1);\n\tif (flags & QED_NVM_CFG_OPTION_COMMIT)\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_COMMIT, 1);\n\tif (flags & QED_NVM_CFG_OPTION_FREE)\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_FREE, 1);\n\tif (flags & QED_NVM_CFG_OPTION_ENTITY_SEL) {\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_ENTITY_SEL, 1);\n\t\tQED_MFW_SET_FIELD(mb_param,\n\t\t\t\t  DRV_MB_PARAM_NVM_CFG_OPTION_ENTITY_ID,\n\t\t\t\t  entity_id);\n\t}\n\n\treturn qed_mcp_nvm_wr_cmd(p_hwfn, p_ptt,\n\t\t\t\t  DRV_MSG_CODE_SET_NVM_CFG_OPTION,\n\t\t\t\t  mb_param, &resp, &param, len, (u32 *)p_buf);\n}\n\n#define QED_MCP_DBG_DATA_MAX_SIZE               MCP_DRV_NVM_BUF_LEN\n#define QED_MCP_DBG_DATA_MAX_HEADER_SIZE        sizeof(u32)\n#define QED_MCP_DBG_DATA_MAX_PAYLOAD_SIZE \\\n\t(QED_MCP_DBG_DATA_MAX_SIZE - QED_MCP_DBG_DATA_MAX_HEADER_SIZE)\n\nstatic int\n__qed_mcp_send_debug_data(struct qed_hwfn *p_hwfn,\n\t\t\t  struct qed_ptt *p_ptt, u8 *p_buf, u8 size)\n{\n\tstruct qed_mcp_mb_params mb_params;\n\tint rc;\n\n\tif (size > QED_MCP_DBG_DATA_MAX_SIZE) {\n\t\tDP_ERR(p_hwfn,\n\t\t       \"Debug data size is %d while it should not exceed %d\\n\",\n\t\t       size, QED_MCP_DBG_DATA_MAX_SIZE);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&mb_params, 0, sizeof(mb_params));\n\tmb_params.cmd = DRV_MSG_CODE_DEBUG_DATA_SEND;\n\tSET_MFW_FIELD(mb_params.param, DRV_MSG_CODE_DEBUG_DATA_SEND_SIZE, size);\n\tmb_params.p_data_src = p_buf;\n\tmb_params.data_src_size = size;\n\trc = qed_mcp_cmd_and_union(p_hwfn, p_ptt, &mb_params);\n\tif (rc)\n\t\treturn rc;\n\n\tif (mb_params.mcp_resp == FW_MSG_CODE_UNSUPPORTED) {\n\t\tDP_INFO(p_hwfn,\n\t\t\t\"The DEBUG_DATA_SEND command is unsupported by the MFW\\n\");\n\t\treturn -EOPNOTSUPP;\n\t} else if (mb_params.mcp_resp == (u32)FW_MSG_CODE_DEBUG_NOT_ENABLED) {\n\t\tDP_INFO(p_hwfn, \"The DEBUG_DATA_SEND command is not enabled\\n\");\n\t\treturn -EBUSY;\n\t} else if (mb_params.mcp_resp != (u32)FW_MSG_CODE_DEBUG_DATA_SEND_OK) {\n\t\tDP_NOTICE(p_hwfn,\n\t\t\t  \"Failed to send debug data to the MFW [resp 0x%08x]\\n\",\n\t\t\t  mb_params.mcp_resp);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nenum qed_mcp_dbg_data_type {\n\tQED_MCP_DBG_DATA_TYPE_RAW,\n};\n\n \n#define QED_MCP_DBG_DATA_HDR_SN_OFFSET  0\n#define QED_MCP_DBG_DATA_HDR_SN_MASK            0x00000fff\n#define QED_MCP_DBG_DATA_HDR_TYPE_OFFSET        12\n#define QED_MCP_DBG_DATA_HDR_TYPE_MASK  0x000ff000\n#define QED_MCP_DBG_DATA_HDR_FLAGS_OFFSET       20\n#define QED_MCP_DBG_DATA_HDR_FLAGS_MASK 0x0ff00000\n#define QED_MCP_DBG_DATA_HDR_PF_OFFSET  28\n#define QED_MCP_DBG_DATA_HDR_PF_MASK            0xf0000000\n\n#define QED_MCP_DBG_DATA_HDR_FLAGS_FIRST        0x1\n#define QED_MCP_DBG_DATA_HDR_FLAGS_LAST 0x2\n\nstatic int\nqed_mcp_send_debug_data(struct qed_hwfn *p_hwfn,\n\t\t\tstruct qed_ptt *p_ptt,\n\t\t\tenum qed_mcp_dbg_data_type type, u8 *p_buf, u32 size)\n{\n\tu8 raw_data[QED_MCP_DBG_DATA_MAX_SIZE], *p_tmp_buf = p_buf;\n\tu32 tmp_size = size, *p_header, *p_payload;\n\tu8 flags = 0;\n\tu16 seq;\n\tint rc;\n\n\tp_header = (u32 *)raw_data;\n\tp_payload = (u32 *)(raw_data + QED_MCP_DBG_DATA_MAX_HEADER_SIZE);\n\n\tseq = (u16)atomic_inc_return(&p_hwfn->mcp_info->dbg_data_seq);\n\n\t \n\tflags |= QED_MCP_DBG_DATA_HDR_FLAGS_FIRST;\n\n\t*p_header = 0;\n\tSET_MFW_FIELD(*p_header, QED_MCP_DBG_DATA_HDR_SN, seq);\n\tSET_MFW_FIELD(*p_header, QED_MCP_DBG_DATA_HDR_TYPE, type);\n\tSET_MFW_FIELD(*p_header, QED_MCP_DBG_DATA_HDR_FLAGS, flags);\n\tSET_MFW_FIELD(*p_header, QED_MCP_DBG_DATA_HDR_PF, p_hwfn->abs_pf_id);\n\n\twhile (tmp_size > QED_MCP_DBG_DATA_MAX_PAYLOAD_SIZE) {\n\t\tmemcpy(p_payload, p_tmp_buf, QED_MCP_DBG_DATA_MAX_PAYLOAD_SIZE);\n\t\trc = __qed_mcp_send_debug_data(p_hwfn, p_ptt, raw_data,\n\t\t\t\t\t       QED_MCP_DBG_DATA_MAX_SIZE);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\tif (p_tmp_buf == p_buf) {\n\t\t\tflags &= ~QED_MCP_DBG_DATA_HDR_FLAGS_FIRST;\n\t\t\tSET_MFW_FIELD(*p_header, QED_MCP_DBG_DATA_HDR_FLAGS,\n\t\t\t\t      flags);\n\t\t}\n\n\t\tp_tmp_buf += QED_MCP_DBG_DATA_MAX_PAYLOAD_SIZE;\n\t\ttmp_size -= QED_MCP_DBG_DATA_MAX_PAYLOAD_SIZE;\n\t}\n\n\t \n\tflags |= QED_MCP_DBG_DATA_HDR_FLAGS_LAST;\n\tSET_MFW_FIELD(*p_header, QED_MCP_DBG_DATA_HDR_FLAGS, flags);\n\tmemcpy(p_payload, p_tmp_buf, tmp_size);\n\n\t \n\treturn __qed_mcp_send_debug_data(p_hwfn, p_ptt, raw_data,\n\t\t\t\t\t (u8)(QED_MCP_DBG_DATA_MAX_HEADER_SIZE +\n\t\t\t\t\t tmp_size));\n}\n\nint\nqed_mcp_send_raw_debug_data(struct qed_hwfn *p_hwfn,\n\t\t\t    struct qed_ptt *p_ptt, u8 *p_buf, u32 size)\n{\n\treturn qed_mcp_send_debug_data(p_hwfn, p_ptt,\n\t\t\t\t       QED_MCP_DBG_DATA_TYPE_RAW, p_buf, size);\n}\n\nbool qed_mcp_is_esl_supported(struct qed_hwfn *p_hwfn)\n{\n\treturn !!(p_hwfn->mcp_info->capabilities &\n\t\t  FW_MB_PARAM_FEATURE_SUPPORT_ENHANCED_SYS_LCK);\n}\n\nint qed_mcp_get_esl_status(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt, bool *active)\n{\n\tu32 resp = 0, param = 0;\n\tint rc;\n\n\trc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_GET_MANAGEMENT_STATUS, 0, &resp, &param);\n\tif (rc) {\n\t\tDP_NOTICE(p_hwfn, \"Failed to send ESL command, rc = %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\t*active = !!(param & FW_MB_PARAM_MANAGEMENT_STATUS_LOCKDOWN_ENABLED);\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}