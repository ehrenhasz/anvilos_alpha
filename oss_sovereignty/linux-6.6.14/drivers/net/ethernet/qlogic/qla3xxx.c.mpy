{
  "module_name": "qla3xxx.c",
  "hash_id": "b26a8274dda66d7422c9fd12260eecfc9093f54a0f41396e40aba6deabae200a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qla3xxx.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/types.h>\n#include <linux/module.h>\n#include <linux/list.h>\n#include <linux/pci.h>\n#include <linux/dma-mapping.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/dmapool.h>\n#include <linux/mempool.h>\n#include <linux/spinlock.h>\n#include <linux/kthread.h>\n#include <linux/interrupt.h>\n#include <linux/errno.h>\n#include <linux/ioport.h>\n#include <linux/ip.h>\n#include <linux/in.h>\n#include <linux/if_arp.h>\n#include <linux/if_ether.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/skbuff.h>\n#include <linux/rtnetlink.h>\n#include <linux/if_vlan.h>\n#include <linux/delay.h>\n#include <linux/mm.h>\n#include <linux/prefetch.h>\n\n#include \"qla3xxx.h\"\n\n#define DRV_NAME\t\"qla3xxx\"\n#define DRV_STRING\t\"QLogic ISP3XXX Network Driver\"\n#define DRV_VERSION\t\"v2.03.00-k5\"\n\nstatic const char ql3xxx_driver_name[] = DRV_NAME;\nstatic const char ql3xxx_driver_version[] = DRV_VERSION;\n\n#define TIMED_OUT_MSG\t\t\t\t\t\t\t\\\n\"Timed out waiting for management port to get free before issuing command\\n\"\n\nMODULE_AUTHOR(\"QLogic Corporation\");\nMODULE_DESCRIPTION(\"QLogic ISP3XXX Network Driver \" DRV_VERSION \" \");\nMODULE_LICENSE(\"GPL\");\nMODULE_VERSION(DRV_VERSION);\n\nstatic const u32 default_msg\n    = NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_LINK\n    | NETIF_MSG_IFUP | NETIF_MSG_IFDOWN;\n\nstatic int debug = -1;\t\t \nmodule_param(debug, int, 0);\nMODULE_PARM_DESC(debug, \"Debug level (0=none,...,16=all)\");\n\nstatic int msi;\nmodule_param(msi, int, 0);\nMODULE_PARM_DESC(msi, \"Turn on Message Signaled Interrupts.\");\n\nstatic const struct pci_device_id ql3xxx_pci_tbl[] = {\n\t{PCI_DEVICE(PCI_VENDOR_ID_QLOGIC, QL3022_DEVICE_ID)},\n\t{PCI_DEVICE(PCI_VENDOR_ID_QLOGIC, QL3032_DEVICE_ID)},\n\t \n\t{0,}\n};\n\nMODULE_DEVICE_TABLE(pci, ql3xxx_pci_tbl);\n\n \nenum PHY_DEVICE_TYPE {\n   PHY_TYPE_UNKNOWN   = 0,\n   PHY_VITESSE_VSC8211,\n   PHY_AGERE_ET1011C,\n   MAX_PHY_DEV_TYPES\n};\n\nstruct PHY_DEVICE_INFO {\n\tconst enum PHY_DEVICE_TYPE\tphyDevice;\n\tconst u32\t\tphyIdOUI;\n\tconst u16\t\tphyIdModel;\n\tconst char\t\t*name;\n};\n\nstatic const struct PHY_DEVICE_INFO PHY_DEVICES[] = {\n\t{PHY_TYPE_UNKNOWN,    0x000000, 0x0, \"PHY_TYPE_UNKNOWN\"},\n\t{PHY_VITESSE_VSC8211, 0x0003f1, 0xb, \"PHY_VITESSE_VSC8211\"},\n\t{PHY_AGERE_ET1011C,   0x00a0bc, 0x1, \"PHY_AGERE_ET1011C\"},\n};\n\n\n \nstatic int ql_sem_spinlock(struct ql3_adapter *qdev,\n\t\t\t    u32 sem_mask, u32 sem_bits)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tu32 value;\n\tunsigned int seconds = 3;\n\n\tdo {\n\t\twritel((sem_mask | sem_bits),\n\t\t       &port_regs->CommonRegs.semaphoreReg);\n\t\tvalue = readl(&port_regs->CommonRegs.semaphoreReg);\n\t\tif ((value & (sem_mask >> 16)) == sem_bits)\n\t\t\treturn 0;\n\t\tmdelay(1000);\n\t} while (--seconds);\n\treturn -1;\n}\n\nstatic void ql_sem_unlock(struct ql3_adapter *qdev, u32 sem_mask)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\twritel(sem_mask, &port_regs->CommonRegs.semaphoreReg);\n\treadl(&port_regs->CommonRegs.semaphoreReg);\n}\n\nstatic int ql_sem_lock(struct ql3_adapter *qdev, u32 sem_mask, u32 sem_bits)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tu32 value;\n\n\twritel((sem_mask | sem_bits), &port_regs->CommonRegs.semaphoreReg);\n\tvalue = readl(&port_regs->CommonRegs.semaphoreReg);\n\treturn ((value & (sem_mask >> 16)) == sem_bits);\n}\n\n \nstatic int ql_wait_for_drvr_lock(struct ql3_adapter *qdev)\n{\n\tint i = 0;\n\n\tdo {\n\t\tif (ql_sem_lock(qdev,\n\t\t\t\tQL_DRVR_SEM_MASK,\n\t\t\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index)\n\t\t\t\t * 2) << 1)) {\n\t\t\tnetdev_printk(KERN_DEBUG, qdev->ndev,\n\t\t\t\t      \"driver lock acquired\\n\");\n\t\t\treturn 1;\n\t\t}\n\t\tmdelay(1000);\n\t} while (++i < 10);\n\n\tnetdev_err(qdev->ndev, \"Timed out waiting for driver lock...\\n\");\n\treturn 0;\n}\n\nstatic void ql_set_register_page(struct ql3_adapter *qdev, u32 page)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\n\twritel(((ISP_CONTROL_NP_MASK << 16) | page),\n\t\t\t&port_regs->CommonRegs.ispControlStatus);\n\treadl(&port_regs->CommonRegs.ispControlStatus);\n\tqdev->current_page = page;\n}\n\nstatic u32 ql_read_common_reg_l(struct ql3_adapter *qdev, u32 __iomem *reg)\n{\n\tu32 value;\n\tunsigned long hw_flags;\n\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\tvalue = readl(reg);\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\n\treturn value;\n}\n\nstatic u32 ql_read_common_reg(struct ql3_adapter *qdev, u32 __iomem *reg)\n{\n\treturn readl(reg);\n}\n\nstatic u32 ql_read_page0_reg_l(struct ql3_adapter *qdev, u32 __iomem *reg)\n{\n\tu32 value;\n\tunsigned long hw_flags;\n\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\n\tif (qdev->current_page != 0)\n\t\tql_set_register_page(qdev, 0);\n\tvalue = readl(reg);\n\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\treturn value;\n}\n\nstatic u32 ql_read_page0_reg(struct ql3_adapter *qdev, u32 __iomem *reg)\n{\n\tif (qdev->current_page != 0)\n\t\tql_set_register_page(qdev, 0);\n\treturn readl(reg);\n}\n\nstatic void ql_write_common_reg_l(struct ql3_adapter *qdev,\n\t\t\t\tu32 __iomem *reg, u32 value)\n{\n\tunsigned long hw_flags;\n\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\twritel(value, reg);\n\treadl(reg);\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n}\n\nstatic void ql_write_common_reg(struct ql3_adapter *qdev,\n\t\t\t\tu32 __iomem *reg, u32 value)\n{\n\twritel(value, reg);\n\treadl(reg);\n}\n\nstatic void ql_write_nvram_reg(struct ql3_adapter *qdev,\n\t\t\t\tu32 __iomem *reg, u32 value)\n{\n\twritel(value, reg);\n\treadl(reg);\n\tudelay(1);\n}\n\nstatic void ql_write_page0_reg(struct ql3_adapter *qdev,\n\t\t\t       u32 __iomem *reg, u32 value)\n{\n\tif (qdev->current_page != 0)\n\t\tql_set_register_page(qdev, 0);\n\twritel(value, reg);\n\treadl(reg);\n}\n\n \nstatic void ql_write_page1_reg(struct ql3_adapter *qdev,\n\t\t\t       u32 __iomem *reg, u32 value)\n{\n\tif (qdev->current_page != 1)\n\t\tql_set_register_page(qdev, 1);\n\twritel(value, reg);\n\treadl(reg);\n}\n\n \nstatic void ql_write_page2_reg(struct ql3_adapter *qdev,\n\t\t\t       u32 __iomem *reg, u32 value)\n{\n\tif (qdev->current_page != 2)\n\t\tql_set_register_page(qdev, 2);\n\twritel(value, reg);\n\treadl(reg);\n}\n\nstatic void ql_disable_interrupts(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\n\tql_write_common_reg_l(qdev, &port_regs->CommonRegs.ispInterruptMaskReg,\n\t\t\t    (ISP_IMR_ENABLE_INT << 16));\n\n}\n\nstatic void ql_enable_interrupts(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\n\tql_write_common_reg_l(qdev, &port_regs->CommonRegs.ispInterruptMaskReg,\n\t\t\t    ((0xff << 16) | ISP_IMR_ENABLE_INT));\n\n}\n\nstatic void ql_release_to_lrg_buf_free_list(struct ql3_adapter *qdev,\n\t\t\t\t\t    struct ql_rcv_buf_cb *lrg_buf_cb)\n{\n\tdma_addr_t map;\n\tint err;\n\tlrg_buf_cb->next = NULL;\n\n\tif (qdev->lrg_buf_free_tail == NULL) {\t \n\t\tqdev->lrg_buf_free_head = qdev->lrg_buf_free_tail = lrg_buf_cb;\n\t} else {\n\t\tqdev->lrg_buf_free_tail->next = lrg_buf_cb;\n\t\tqdev->lrg_buf_free_tail = lrg_buf_cb;\n\t}\n\n\tif (!lrg_buf_cb->skb) {\n\t\tlrg_buf_cb->skb = netdev_alloc_skb(qdev->ndev,\n\t\t\t\t\t\t   qdev->lrg_buffer_len);\n\t\tif (unlikely(!lrg_buf_cb->skb)) {\n\t\t\tqdev->lrg_buf_skb_check++;\n\t\t} else {\n\t\t\t \n\t\t\tskb_reserve(lrg_buf_cb->skb, QL_HEADER_SPACE);\n\t\t\tmap = dma_map_single(&qdev->pdev->dev,\n\t\t\t\t\t     lrg_buf_cb->skb->data,\n\t\t\t\t\t     qdev->lrg_buffer_len - QL_HEADER_SPACE,\n\t\t\t\t\t     DMA_FROM_DEVICE);\n\t\t\terr = dma_mapping_error(&qdev->pdev->dev, map);\n\t\t\tif (err) {\n\t\t\t\tnetdev_err(qdev->ndev,\n\t\t\t\t\t   \"PCI mapping failed with error: %d\\n\",\n\t\t\t\t\t   err);\n\t\t\t\tdev_kfree_skb(lrg_buf_cb->skb);\n\t\t\t\tlrg_buf_cb->skb = NULL;\n\n\t\t\t\tqdev->lrg_buf_skb_check++;\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tlrg_buf_cb->buf_phy_addr_low =\n\t\t\t    cpu_to_le32(LS_64BITS(map));\n\t\t\tlrg_buf_cb->buf_phy_addr_high =\n\t\t\t    cpu_to_le32(MS_64BITS(map));\n\t\t\tdma_unmap_addr_set(lrg_buf_cb, mapaddr, map);\n\t\t\tdma_unmap_len_set(lrg_buf_cb, maplen,\n\t\t\t\t\t  qdev->lrg_buffer_len -\n\t\t\t\t\t  QL_HEADER_SPACE);\n\t\t}\n\t}\n\n\tqdev->lrg_buf_free_count++;\n}\n\nstatic struct ql_rcv_buf_cb *ql_get_from_lrg_buf_free_list(struct ql3_adapter\n\t\t\t\t\t\t\t   *qdev)\n{\n\tstruct ql_rcv_buf_cb *lrg_buf_cb = qdev->lrg_buf_free_head;\n\n\tif (lrg_buf_cb != NULL) {\n\t\tqdev->lrg_buf_free_head = lrg_buf_cb->next;\n\t\tif (qdev->lrg_buf_free_head == NULL)\n\t\t\tqdev->lrg_buf_free_tail = NULL;\n\t\tqdev->lrg_buf_free_count--;\n\t}\n\n\treturn lrg_buf_cb;\n}\n\nstatic u32 addrBits = EEPROM_NO_ADDR_BITS;\nstatic u32 dataBits = EEPROM_NO_DATA_BITS;\n\nstatic void fm93c56a_deselect(struct ql3_adapter *qdev);\nstatic void eeprom_readword(struct ql3_adapter *qdev, u32 eepromAddr,\n\t\t\t    unsigned short *value);\n\n \nstatic void fm93c56a_select(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\t__iomem u32 *spir = &port_regs->CommonRegs.serialPortInterfaceReg;\n\n\tqdev->eeprom_cmd_data = AUBURN_EEPROM_CS_1;\n\tql_write_nvram_reg(qdev, spir, ISP_NVRAM_MASK | qdev->eeprom_cmd_data);\n}\n\n \nstatic void fm93c56a_cmd(struct ql3_adapter *qdev, u32 cmd, u32 eepromAddr)\n{\n\tint i;\n\tu32 mask;\n\tu32 dataBit;\n\tu32 previousBit;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\t__iomem u32 *spir = &port_regs->CommonRegs.serialPortInterfaceReg;\n\n\t \n\tql_write_nvram_reg(qdev, spir,\n\t\t\t   (ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t    AUBURN_EEPROM_DO_1));\n\tql_write_nvram_reg(qdev, spir,\n\t\t\t   (ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t    AUBURN_EEPROM_DO_1 | AUBURN_EEPROM_CLK_RISE));\n\tql_write_nvram_reg(qdev, spir,\n\t\t\t   (ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t    AUBURN_EEPROM_DO_1 | AUBURN_EEPROM_CLK_FALL));\n\n\tmask = 1 << (FM93C56A_CMD_BITS - 1);\n\t \n\tpreviousBit = 0xffff;\n\tfor (i = 0; i < FM93C56A_CMD_BITS; i++) {\n\t\tdataBit = (cmd & mask)\n\t\t\t? AUBURN_EEPROM_DO_1\n\t\t\t: AUBURN_EEPROM_DO_0;\n\t\tif (previousBit != dataBit) {\n\t\t\t \n\t\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t\t   (ISP_NVRAM_MASK |\n\t\t\t\t\t    qdev->eeprom_cmd_data | dataBit));\n\t\t\tpreviousBit = dataBit;\n\t\t}\n\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t   (ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t\t    dataBit | AUBURN_EEPROM_CLK_RISE));\n\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t   (ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t\t    dataBit | AUBURN_EEPROM_CLK_FALL));\n\t\tcmd = cmd << 1;\n\t}\n\n\tmask = 1 << (addrBits - 1);\n\t \n\tpreviousBit = 0xffff;\n\tfor (i = 0; i < addrBits; i++) {\n\t\tdataBit = (eepromAddr & mask) ? AUBURN_EEPROM_DO_1\n\t\t\t: AUBURN_EEPROM_DO_0;\n\t\tif (previousBit != dataBit) {\n\t\t\t \n\t\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t\t   (ISP_NVRAM_MASK |\n\t\t\t\t\t    qdev->eeprom_cmd_data | dataBit));\n\t\t\tpreviousBit = dataBit;\n\t\t}\n\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t   (ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t\t    dataBit | AUBURN_EEPROM_CLK_RISE));\n\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t   (ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t\t    dataBit | AUBURN_EEPROM_CLK_FALL));\n\t\teepromAddr = eepromAddr << 1;\n\t}\n}\n\n \nstatic void fm93c56a_deselect(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\t__iomem u32 *spir = &port_regs->CommonRegs.serialPortInterfaceReg;\n\n\tqdev->eeprom_cmd_data = AUBURN_EEPROM_CS_0;\n\tql_write_nvram_reg(qdev, spir, ISP_NVRAM_MASK | qdev->eeprom_cmd_data);\n}\n\n \nstatic void fm93c56a_datain(struct ql3_adapter *qdev, unsigned short *value)\n{\n\tint i;\n\tu32 data = 0;\n\tu32 dataBit;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\t__iomem u32 *spir = &port_regs->CommonRegs.serialPortInterfaceReg;\n\n\t \n\t \n\tfor (i = 0; i < dataBits; i++) {\n\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t   ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t\t   AUBURN_EEPROM_CLK_RISE);\n\t\tql_write_nvram_reg(qdev, spir,\n\t\t\t\t   ISP_NVRAM_MASK | qdev->eeprom_cmd_data |\n\t\t\t\t   AUBURN_EEPROM_CLK_FALL);\n\t\tdataBit = (ql_read_common_reg(qdev, spir) &\n\t\t\t   AUBURN_EEPROM_DI_1) ? 1 : 0;\n\t\tdata = (data << 1) | dataBit;\n\t}\n\t*value = (u16)data;\n}\n\n \nstatic void eeprom_readword(struct ql3_adapter *qdev,\n\t\t\t    u32 eepromAddr, unsigned short *value)\n{\n\tfm93c56a_select(qdev);\n\tfm93c56a_cmd(qdev, (int)FM93C56A_READ, eepromAddr);\n\tfm93c56a_datain(qdev, value);\n\tfm93c56a_deselect(qdev);\n}\n\nstatic void ql_set_mac_addr(struct net_device *ndev, u16 *addr)\n{\n\t__le16 buf[ETH_ALEN / 2];\n\n\tbuf[0] = cpu_to_le16(addr[0]);\n\tbuf[1] = cpu_to_le16(addr[1]);\n\tbuf[2] = cpu_to_le16(addr[2]);\n\teth_hw_addr_set(ndev, (u8 *)buf);\n}\n\nstatic int ql_get_nvram_params(struct ql3_adapter *qdev)\n{\n\tu16 *pEEPROMData;\n\tu16 checksum = 0;\n\tu32 index;\n\tunsigned long hw_flags;\n\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\n\tpEEPROMData = (u16 *)&qdev->nvram_data;\n\tqdev->eeprom_cmd_data = 0;\n\tif (ql_sem_spinlock(qdev, QL_NVRAM_SEM_MASK,\n\t\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index) *\n\t\t\t 2) << 10)) {\n\t\tpr_err(\"%s: Failed ql_sem_spinlock()\\n\", __func__);\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\t\treturn -1;\n\t}\n\n\tfor (index = 0; index < EEPROM_SIZE; index++) {\n\t\teeprom_readword(qdev, index, pEEPROMData);\n\t\tchecksum += *pEEPROMData;\n\t\tpEEPROMData++;\n\t}\n\tql_sem_unlock(qdev, QL_NVRAM_SEM_MASK);\n\n\tif (checksum != 0) {\n\t\tnetdev_err(qdev->ndev, \"checksum should be zero, is %x!!\\n\",\n\t\t\t   checksum);\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\t\treturn -1;\n\t}\n\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\treturn checksum;\n}\n\nstatic const u32 PHYAddr[2] = {\n\tPORT0_PHY_ADDRESS, PORT1_PHY_ADDRESS\n};\n\nstatic int ql_wait_for_mii_ready(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 temp;\n\tint count = 1000;\n\n\twhile (count) {\n\t\ttemp = ql_read_page0_reg(qdev, &port_regs->macMIIStatusReg);\n\t\tif (!(temp & MAC_MII_STATUS_BSY))\n\t\t\treturn 0;\n\t\tudelay(10);\n\t\tcount--;\n\t}\n\treturn -1;\n}\n\nstatic void ql_mii_enable_scan_mode(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 scanControl;\n\n\tif (qdev->numPorts > 1) {\n\t\t \n\t\tscanControl = MAC_MII_CONTROL_AS | MAC_MII_CONTROL_SC;\n\t} else {\n\t\tscanControl = MAC_MII_CONTROL_SC;\n\t}\n\n\t \n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtAddrReg,\n\t\t\t   PHYAddr[0] | MII_SCAN_REGISTER);\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtControlReg,\n\t\t\t   (scanControl) |\n\t\t\t   ((MAC_MII_CONTROL_SC | MAC_MII_CONTROL_AS) << 16));\n}\n\nstatic u8 ql_mii_disable_scan_mode(struct ql3_adapter *qdev)\n{\n\tu8 ret;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\t\t\tqdev->mem_map_registers;\n\n\t \n\tif (ql_read_page0_reg(qdev, &port_regs->macMIIMgmtControlReg) &\n\t    (MAC_MII_CONTROL_AS | MAC_MII_CONTROL_SC)) {\n\t\t \n\t\tret = 1;\n\t} else {\n\t\t \n\t\tret = 0;\n\t}\n\n\t \n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtAddrReg,\n\t\t\t   PHYAddr[0] | MII_SCAN_REGISTER);\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtControlReg,\n\t\t\t   ((MAC_MII_CONTROL_SC | MAC_MII_CONTROL_AS |\n\t\t\t     MAC_MII_CONTROL_RC) << 16));\n\n\treturn ret;\n}\n\nstatic int ql_mii_write_reg_ex(struct ql3_adapter *qdev,\n\t\t\t       u16 regAddr, u16 value, u32 phyAddr)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu8 scanWasEnabled;\n\n\tscanWasEnabled = ql_mii_disable_scan_mode(qdev);\n\n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtAddrReg,\n\t\t\t   phyAddr | regAddr);\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtDataReg, value);\n\n\t \n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\tif (scanWasEnabled)\n\t\tql_mii_enable_scan_mode(qdev);\n\n\treturn 0;\n}\n\nstatic int ql_mii_read_reg_ex(struct ql3_adapter *qdev, u16 regAddr,\n\t\t\t      u16 *value, u32 phyAddr)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu8 scanWasEnabled;\n\tu32 temp;\n\n\tscanWasEnabled = ql_mii_disable_scan_mode(qdev);\n\n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtAddrReg,\n\t\t\t   phyAddr | regAddr);\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtControlReg,\n\t\t\t   (MAC_MII_CONTROL_RC << 16));\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtControlReg,\n\t\t\t   (MAC_MII_CONTROL_RC << 16) | MAC_MII_CONTROL_RC);\n\n\t \n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\ttemp = ql_read_page0_reg(qdev, &port_regs->macMIIMgmtDataReg);\n\t*value = (u16) temp;\n\n\tif (scanWasEnabled)\n\t\tql_mii_enable_scan_mode(qdev);\n\n\treturn 0;\n}\n\nstatic int ql_mii_write_reg(struct ql3_adapter *qdev, u16 regAddr, u16 value)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\n\tql_mii_disable_scan_mode(qdev);\n\n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtAddrReg,\n\t\t\t   qdev->PHYAddr | regAddr);\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtDataReg, value);\n\n\t \n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\tql_mii_enable_scan_mode(qdev);\n\n\treturn 0;\n}\n\nstatic int ql_mii_read_reg(struct ql3_adapter *qdev, u16 regAddr, u16 *value)\n{\n\tu32 temp;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\n\tql_mii_disable_scan_mode(qdev);\n\n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtAddrReg,\n\t\t\t   qdev->PHYAddr | regAddr);\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtControlReg,\n\t\t\t   (MAC_MII_CONTROL_RC << 16));\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtControlReg,\n\t\t\t   (MAC_MII_CONTROL_RC << 16) | MAC_MII_CONTROL_RC);\n\n\t \n\tif (ql_wait_for_mii_ready(qdev)) {\n\t\tnetif_warn(qdev, link, qdev->ndev, TIMED_OUT_MSG);\n\t\treturn -1;\n\t}\n\n\ttemp = ql_read_page0_reg(qdev, &port_regs->macMIIMgmtDataReg);\n\t*value = (u16) temp;\n\n\tql_mii_enable_scan_mode(qdev);\n\n\treturn 0;\n}\n\nstatic void ql_petbi_reset(struct ql3_adapter *qdev)\n{\n\tql_mii_write_reg(qdev, PETBI_CONTROL_REG, PETBI_CTRL_SOFT_RESET);\n}\n\nstatic void ql_petbi_start_neg(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\n\t \n\tql_mii_read_reg(qdev, PETBI_TBI_CTRL, &reg);\n\treg |= PETBI_TBI_AUTO_SENSE;\n\tql_mii_write_reg(qdev, PETBI_TBI_CTRL, reg);\n\n\tql_mii_write_reg(qdev, PETBI_NEG_ADVER,\n\t\t\t PETBI_NEG_PAUSE | PETBI_NEG_DUPLEX);\n\n\tql_mii_write_reg(qdev, PETBI_CONTROL_REG,\n\t\t\t PETBI_CTRL_AUTO_NEG | PETBI_CTRL_RESTART_NEG |\n\t\t\t PETBI_CTRL_FULL_DUPLEX | PETBI_CTRL_SPEED_1000);\n\n}\n\nstatic void ql_petbi_reset_ex(struct ql3_adapter *qdev)\n{\n\tql_mii_write_reg_ex(qdev, PETBI_CONTROL_REG, PETBI_CTRL_SOFT_RESET,\n\t\t\t    PHYAddr[qdev->mac_index]);\n}\n\nstatic void ql_petbi_start_neg_ex(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\n\t \n\tql_mii_read_reg_ex(qdev, PETBI_TBI_CTRL, &reg,\n\t\t\t   PHYAddr[qdev->mac_index]);\n\treg |= PETBI_TBI_AUTO_SENSE;\n\tql_mii_write_reg_ex(qdev, PETBI_TBI_CTRL, reg,\n\t\t\t    PHYAddr[qdev->mac_index]);\n\n\tql_mii_write_reg_ex(qdev, PETBI_NEG_ADVER,\n\t\t\t    PETBI_NEG_PAUSE | PETBI_NEG_DUPLEX,\n\t\t\t    PHYAddr[qdev->mac_index]);\n\n\tql_mii_write_reg_ex(qdev, PETBI_CONTROL_REG,\n\t\t\t    PETBI_CTRL_AUTO_NEG | PETBI_CTRL_RESTART_NEG |\n\t\t\t    PETBI_CTRL_FULL_DUPLEX | PETBI_CTRL_SPEED_1000,\n\t\t\t    PHYAddr[qdev->mac_index]);\n}\n\nstatic void ql_petbi_init(struct ql3_adapter *qdev)\n{\n\tql_petbi_reset(qdev);\n\tql_petbi_start_neg(qdev);\n}\n\nstatic void ql_petbi_init_ex(struct ql3_adapter *qdev)\n{\n\tql_petbi_reset_ex(qdev);\n\tql_petbi_start_neg_ex(qdev);\n}\n\nstatic int ql_is_petbi_neg_pause(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\n\tif (ql_mii_read_reg(qdev, PETBI_NEG_PARTNER, &reg) < 0)\n\t\treturn 0;\n\n\treturn (reg & PETBI_NEG_PAUSE_MASK) == PETBI_NEG_PAUSE;\n}\n\nstatic void phyAgereSpecificInit(struct ql3_adapter *qdev, u32 miiAddr)\n{\n\tnetdev_info(qdev->ndev, \"enabling Agere specific PHY\\n\");\n\t \n\tql_mii_write_reg_ex(qdev, 0x00, 0x1940, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x12, 0x840e, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x10, 0x8805, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x11, 0xf03e, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x10, 0x8806, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x11, 0x003e, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x10, 0x8807, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x11, 0x1f00, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x10, 0x2806, miiAddr);\n\t \n\tql_mii_write_reg_ex(qdev, 0x11,\n\t\t\t    0x0020 | (PHYAddr[qdev->mac_index] >> 8), miiAddr);\n\t \n\tql_mii_write_reg(qdev, 0x12, 0x840a);\n\tql_mii_write_reg(qdev, 0x00, 0x1140);\n\tql_mii_write_reg(qdev, 0x1c, 0xfaf0);\n}\n\nstatic enum PHY_DEVICE_TYPE getPhyType(struct ql3_adapter *qdev,\n\t\t\t\t       u16 phyIdReg0, u16 phyIdReg1)\n{\n\tenum PHY_DEVICE_TYPE result = PHY_TYPE_UNKNOWN;\n\tu32   oui;\n\tu16   model;\n\tint i;\n\n\tif (phyIdReg0 == 0xffff)\n\t\treturn result;\n\n\tif (phyIdReg1 == 0xffff)\n\t\treturn result;\n\n\t \n\toui = (phyIdReg0 << 6) | ((phyIdReg1 & PHY_OUI_1_MASK) >> 10);\n\n\tmodel = (phyIdReg1 & PHY_MODEL_MASK) >> 4;\n\n\t \n\tfor (i = 0; i < MAX_PHY_DEV_TYPES; i++) {\n\t\tif ((oui == PHY_DEVICES[i].phyIdOUI) &&\n\t\t    (model == PHY_DEVICES[i].phyIdModel)) {\n\t\t\tnetdev_info(qdev->ndev, \"Phy: %s\\n\",\n\t\t\t\t    PHY_DEVICES[i].name);\n\t\t\tresult = PHY_DEVICES[i].phyDevice;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn result;\n}\n\nstatic int ql_phy_get_speed(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\n\tswitch (qdev->phyType) {\n\tcase PHY_AGERE_ET1011C: {\n\t\tif (ql_mii_read_reg(qdev, 0x1A, &reg) < 0)\n\t\t\treturn 0;\n\n\t\treg = (reg >> 8) & 3;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tif (ql_mii_read_reg(qdev, AUX_CONTROL_STATUS, &reg) < 0)\n\t\t\treturn 0;\n\n\t\treg = (((reg & 0x18) >> 3) & 3);\n\t}\n\n\tswitch (reg) {\n\tcase 2:\n\t\treturn SPEED_1000;\n\tcase 1:\n\t\treturn SPEED_100;\n\tcase 0:\n\t\treturn SPEED_10;\n\tdefault:\n\t\treturn -1;\n\t}\n}\n\nstatic int ql_is_full_dup(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\n\tswitch (qdev->phyType) {\n\tcase PHY_AGERE_ET1011C: {\n\t\tif (ql_mii_read_reg(qdev, 0x1A, &reg))\n\t\t\treturn 0;\n\n\t\treturn ((reg & 0x0080) && (reg & 0x1000)) != 0;\n\t}\n\tcase PHY_VITESSE_VSC8211:\n\tdefault: {\n\t\tif (ql_mii_read_reg(qdev, AUX_CONTROL_STATUS, &reg) < 0)\n\t\t\treturn 0;\n\t\treturn (reg & PHY_AUX_DUPLEX_STAT) != 0;\n\t}\n\t}\n}\n\nstatic int ql_is_phy_neg_pause(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\n\tif (ql_mii_read_reg(qdev, PHY_NEG_PARTNER, &reg) < 0)\n\t\treturn 0;\n\n\treturn (reg & PHY_NEG_PAUSE) != 0;\n}\n\nstatic int PHY_Setup(struct ql3_adapter *qdev)\n{\n\tu16   reg1;\n\tu16   reg2;\n\tbool  agereAddrChangeNeeded = false;\n\tu32 miiAddr = 0;\n\tint err;\n\n\t \n\terr = ql_mii_read_reg(qdev, PHY_ID_0_REG, &reg1);\n\tif (err != 0) {\n\t\tnetdev_err(qdev->ndev, \"Could not read from reg PHY_ID_0_REG\\n\");\n\t\treturn err;\n\t}\n\n\terr = ql_mii_read_reg(qdev, PHY_ID_1_REG, &reg2);\n\tif (err != 0) {\n\t\tnetdev_err(qdev->ndev, \"Could not read from reg PHY_ID_1_REG\\n\");\n\t\treturn err;\n\t}\n\n\t \n\tif ((reg1 == 0xffff) || (reg2 == 0xffff)) {\n\n\t\t \n\t\tif (qdev->mac_index == 0)\n\t\t\tmiiAddr = MII_AGERE_ADDR_1;\n\t\telse\n\t\t\tmiiAddr = MII_AGERE_ADDR_2;\n\n\t\terr = ql_mii_read_reg_ex(qdev, PHY_ID_0_REG, &reg1, miiAddr);\n\t\tif (err != 0) {\n\t\t\tnetdev_err(qdev->ndev,\n\t\t\t\t   \"Could not read from reg PHY_ID_0_REG after Agere detected\\n\");\n\t\t\treturn err;\n\t\t}\n\n\t\terr = ql_mii_read_reg_ex(qdev, PHY_ID_1_REG, &reg2, miiAddr);\n\t\tif (err != 0) {\n\t\t\tnetdev_err(qdev->ndev, \"Could not read from reg PHY_ID_1_REG after Agere detected\\n\");\n\t\t\treturn err;\n\t\t}\n\n\t\t \n\t\tagereAddrChangeNeeded = true;\n\t}\n\n\t \n\tqdev->phyType = getPhyType(qdev, reg1, reg2);\n\n\tif ((qdev->phyType == PHY_AGERE_ET1011C) && agereAddrChangeNeeded) {\n\t\t \n\t\tphyAgereSpecificInit(qdev, miiAddr);\n\t} else if (qdev->phyType == PHY_TYPE_UNKNOWN) {\n\t\tnetdev_err(qdev->ndev, \"PHY is unknown\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void ql_mac_enable(struct ql3_adapter *qdev, u32 enable)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 value;\n\n\tif (enable)\n\t\tvalue = (MAC_CONFIG_REG_PE | (MAC_CONFIG_REG_PE << 16));\n\telse\n\t\tvalue = (MAC_CONFIG_REG_PE << 16);\n\n\tif (qdev->mac_index)\n\t\tql_write_page0_reg(qdev, &port_regs->mac1ConfigReg, value);\n\telse\n\t\tql_write_page0_reg(qdev, &port_regs->mac0ConfigReg, value);\n}\n\n \nstatic void ql_mac_cfg_soft_reset(struct ql3_adapter *qdev, u32 enable)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 value;\n\n\tif (enable)\n\t\tvalue = (MAC_CONFIG_REG_SR | (MAC_CONFIG_REG_SR << 16));\n\telse\n\t\tvalue = (MAC_CONFIG_REG_SR << 16);\n\n\tif (qdev->mac_index)\n\t\tql_write_page0_reg(qdev, &port_regs->mac1ConfigReg, value);\n\telse\n\t\tql_write_page0_reg(qdev, &port_regs->mac0ConfigReg, value);\n}\n\n \nstatic void ql_mac_cfg_gig(struct ql3_adapter *qdev, u32 enable)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 value;\n\n\tif (enable)\n\t\tvalue = (MAC_CONFIG_REG_GM | (MAC_CONFIG_REG_GM << 16));\n\telse\n\t\tvalue = (MAC_CONFIG_REG_GM << 16);\n\n\tif (qdev->mac_index)\n\t\tql_write_page0_reg(qdev, &port_regs->mac1ConfigReg, value);\n\telse\n\t\tql_write_page0_reg(qdev, &port_regs->mac0ConfigReg, value);\n}\n\n \nstatic void ql_mac_cfg_full_dup(struct ql3_adapter *qdev, u32 enable)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 value;\n\n\tif (enable)\n\t\tvalue = (MAC_CONFIG_REG_FD | (MAC_CONFIG_REG_FD << 16));\n\telse\n\t\tvalue = (MAC_CONFIG_REG_FD << 16);\n\n\tif (qdev->mac_index)\n\t\tql_write_page0_reg(qdev, &port_regs->mac1ConfigReg, value);\n\telse\n\t\tql_write_page0_reg(qdev, &port_regs->mac0ConfigReg, value);\n}\n\n \nstatic void ql_mac_cfg_pause(struct ql3_adapter *qdev, u32 enable)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 value;\n\n\tif (enable)\n\t\tvalue =\n\t\t    ((MAC_CONFIG_REG_TF | MAC_CONFIG_REG_RF) |\n\t\t     ((MAC_CONFIG_REG_TF | MAC_CONFIG_REG_RF) << 16));\n\telse\n\t\tvalue = ((MAC_CONFIG_REG_TF | MAC_CONFIG_REG_RF) << 16);\n\n\tif (qdev->mac_index)\n\t\tql_write_page0_reg(qdev, &port_regs->mac1ConfigReg, value);\n\telse\n\t\tql_write_page0_reg(qdev, &port_regs->mac0ConfigReg, value);\n}\n\n \nstatic int ql_is_fiber(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 bitToCheck = 0;\n\tu32 temp;\n\n\tswitch (qdev->mac_index) {\n\tcase 0:\n\t\tbitToCheck = PORT_STATUS_SM0;\n\t\tbreak;\n\tcase 1:\n\t\tbitToCheck = PORT_STATUS_SM1;\n\t\tbreak;\n\t}\n\n\ttemp = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\treturn (temp & bitToCheck) != 0;\n}\n\nstatic int ql_is_auto_cfg(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\tql_mii_read_reg(qdev, 0x00, &reg);\n\treturn (reg & 0x1000) != 0;\n}\n\n \nstatic int ql_is_auto_neg_complete(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 bitToCheck = 0;\n\tu32 temp;\n\n\tswitch (qdev->mac_index) {\n\tcase 0:\n\t\tbitToCheck = PORT_STATUS_AC0;\n\t\tbreak;\n\tcase 1:\n\t\tbitToCheck = PORT_STATUS_AC1;\n\t\tbreak;\n\t}\n\n\ttemp = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\tif (temp & bitToCheck) {\n\t\tnetif_info(qdev, link, qdev->ndev, \"Auto-Negotiate complete\\n\");\n\t\treturn 1;\n\t}\n\tnetif_info(qdev, link, qdev->ndev, \"Auto-Negotiate incomplete\\n\");\n\treturn 0;\n}\n\n \nstatic int ql_is_neg_pause(struct ql3_adapter *qdev)\n{\n\tif (ql_is_fiber(qdev))\n\t\treturn ql_is_petbi_neg_pause(qdev);\n\telse\n\t\treturn ql_is_phy_neg_pause(qdev);\n}\n\nstatic int ql_auto_neg_error(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 bitToCheck = 0;\n\tu32 temp;\n\n\tswitch (qdev->mac_index) {\n\tcase 0:\n\t\tbitToCheck = PORT_STATUS_AE0;\n\t\tbreak;\n\tcase 1:\n\t\tbitToCheck = PORT_STATUS_AE1;\n\t\tbreak;\n\t}\n\ttemp = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\treturn (temp & bitToCheck) != 0;\n}\n\nstatic u32 ql_get_link_speed(struct ql3_adapter *qdev)\n{\n\tif (ql_is_fiber(qdev))\n\t\treturn SPEED_1000;\n\telse\n\t\treturn ql_phy_get_speed(qdev);\n}\n\nstatic int ql_is_link_full_dup(struct ql3_adapter *qdev)\n{\n\tif (ql_is_fiber(qdev))\n\t\treturn 1;\n\telse\n\t\treturn ql_is_full_dup(qdev);\n}\n\n \nstatic int ql_link_down_detect(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 bitToCheck = 0;\n\tu32 temp;\n\n\tswitch (qdev->mac_index) {\n\tcase 0:\n\t\tbitToCheck = ISP_CONTROL_LINK_DN_0;\n\t\tbreak;\n\tcase 1:\n\t\tbitToCheck = ISP_CONTROL_LINK_DN_1;\n\t\tbreak;\n\t}\n\n\ttemp =\n\t    ql_read_common_reg(qdev, &port_regs->CommonRegs.ispControlStatus);\n\treturn (temp & bitToCheck) != 0;\n}\n\n \nstatic int ql_link_down_detect_clear(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\n\tswitch (qdev->mac_index) {\n\tcase 0:\n\t\tql_write_common_reg(qdev,\n\t\t\t\t    &port_regs->CommonRegs.ispControlStatus,\n\t\t\t\t    (ISP_CONTROL_LINK_DN_0) |\n\t\t\t\t    (ISP_CONTROL_LINK_DN_0 << 16));\n\t\tbreak;\n\n\tcase 1:\n\t\tql_write_common_reg(qdev,\n\t\t\t\t    &port_regs->CommonRegs.ispControlStatus,\n\t\t\t\t    (ISP_CONTROL_LINK_DN_1) |\n\t\t\t\t    (ISP_CONTROL_LINK_DN_1 << 16));\n\t\tbreak;\n\n\tdefault:\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int ql_this_adapter_controls_port(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 bitToCheck = 0;\n\tu32 temp;\n\n\tswitch (qdev->mac_index) {\n\tcase 0:\n\t\tbitToCheck = PORT_STATUS_F1_ENABLED;\n\t\tbreak;\n\tcase 1:\n\t\tbitToCheck = PORT_STATUS_F3_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ttemp = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\tif (temp & bitToCheck) {\n\t\tnetif_printk(qdev, link, KERN_DEBUG, qdev->ndev,\n\t\t\t     \"not link master\\n\");\n\t\treturn 0;\n\t}\n\n\tnetif_printk(qdev, link, KERN_DEBUG, qdev->ndev, \"link master\\n\");\n\treturn 1;\n}\n\nstatic void ql_phy_reset_ex(struct ql3_adapter *qdev)\n{\n\tql_mii_write_reg_ex(qdev, CONTROL_REG, PHY_CTRL_SOFT_RESET,\n\t\t\t    PHYAddr[qdev->mac_index]);\n}\n\nstatic void ql_phy_start_neg_ex(struct ql3_adapter *qdev)\n{\n\tu16 reg;\n\tu16 portConfiguration;\n\n\tif (qdev->phyType == PHY_AGERE_ET1011C)\n\t\tql_mii_write_reg(qdev, 0x13, 0x0000);\n\t\t\t\t\t \n\n\tif (qdev->mac_index == 0)\n\t\tportConfiguration =\n\t\t\tqdev->nvram_data.macCfg_port0.portConfiguration;\n\telse\n\t\tportConfiguration =\n\t\t\tqdev->nvram_data.macCfg_port1.portConfiguration;\n\n\t \n\tif (portConfiguration == 0)\n\t\tportConfiguration = PORT_CONFIG_DEFAULT;\n\n\t \n\tql_mii_read_reg_ex(qdev, PHY_GIG_CONTROL, &reg,\n\t\t\t   PHYAddr[qdev->mac_index]);\n\treg &= ~PHY_GIG_ALL_PARAMS;\n\n\tif (portConfiguration & PORT_CONFIG_1000MB_SPEED) {\n\t\tif (portConfiguration & PORT_CONFIG_FULL_DUPLEX_ENABLED)\n\t\t\treg |= PHY_GIG_ADV_1000F;\n\t\telse\n\t\t\treg |= PHY_GIG_ADV_1000H;\n\t}\n\n\tql_mii_write_reg_ex(qdev, PHY_GIG_CONTROL, reg,\n\t\t\t    PHYAddr[qdev->mac_index]);\n\n\t \n\tql_mii_read_reg_ex(qdev, PHY_NEG_ADVER, &reg,\n\t\t\t   PHYAddr[qdev->mac_index]);\n\treg &= ~PHY_NEG_ALL_PARAMS;\n\n\tif (portConfiguration & PORT_CONFIG_SYM_PAUSE_ENABLED)\n\t\treg |= PHY_NEG_ASY_PAUSE | PHY_NEG_SYM_PAUSE;\n\n\tif (portConfiguration & PORT_CONFIG_FULL_DUPLEX_ENABLED) {\n\t\tif (portConfiguration & PORT_CONFIG_100MB_SPEED)\n\t\t\treg |= PHY_NEG_ADV_100F;\n\n\t\tif (portConfiguration & PORT_CONFIG_10MB_SPEED)\n\t\t\treg |= PHY_NEG_ADV_10F;\n\t}\n\n\tif (portConfiguration & PORT_CONFIG_HALF_DUPLEX_ENABLED) {\n\t\tif (portConfiguration & PORT_CONFIG_100MB_SPEED)\n\t\t\treg |= PHY_NEG_ADV_100H;\n\n\t\tif (portConfiguration & PORT_CONFIG_10MB_SPEED)\n\t\t\treg |= PHY_NEG_ADV_10H;\n\t}\n\n\tif (portConfiguration & PORT_CONFIG_1000MB_SPEED)\n\t\treg |= 1;\n\n\tql_mii_write_reg_ex(qdev, PHY_NEG_ADVER, reg,\n\t\t\t    PHYAddr[qdev->mac_index]);\n\n\tql_mii_read_reg_ex(qdev, CONTROL_REG, &reg, PHYAddr[qdev->mac_index]);\n\n\tql_mii_write_reg_ex(qdev, CONTROL_REG,\n\t\t\t    reg | PHY_CTRL_RESTART_NEG | PHY_CTRL_AUTO_NEG,\n\t\t\t    PHYAddr[qdev->mac_index]);\n}\n\nstatic void ql_phy_init_ex(struct ql3_adapter *qdev)\n{\n\tql_phy_reset_ex(qdev);\n\tPHY_Setup(qdev);\n\tql_phy_start_neg_ex(qdev);\n}\n\n \nstatic u32 ql_get_link_state(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tu32 bitToCheck = 0;\n\tu32 temp, linkState;\n\n\tswitch (qdev->mac_index) {\n\tcase 0:\n\t\tbitToCheck = PORT_STATUS_UP0;\n\t\tbreak;\n\tcase 1:\n\t\tbitToCheck = PORT_STATUS_UP1;\n\t\tbreak;\n\t}\n\n\ttemp = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\tif (temp & bitToCheck)\n\t\tlinkState = LS_UP;\n\telse\n\t\tlinkState = LS_DOWN;\n\n\treturn linkState;\n}\n\nstatic int ql_port_start(struct ql3_adapter *qdev)\n{\n\tif (ql_sem_spinlock(qdev, QL_PHY_GIO_SEM_MASK,\n\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index) *\n\t\t\t 2) << 7)) {\n\t\tnetdev_err(qdev->ndev, \"Could not get hw lock for GIO\\n\");\n\t\treturn -1;\n\t}\n\n\tif (ql_is_fiber(qdev)) {\n\t\tql_petbi_init(qdev);\n\t} else {\n\t\t \n\t\tql_phy_init_ex(qdev);\n\t}\n\n\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\treturn 0;\n}\n\nstatic int ql_finish_auto_neg(struct ql3_adapter *qdev)\n{\n\n\tif (ql_sem_spinlock(qdev, QL_PHY_GIO_SEM_MASK,\n\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index) *\n\t\t\t 2) << 7))\n\t\treturn -1;\n\n\tif (!ql_auto_neg_error(qdev)) {\n\t\tif (test_bit(QL_LINK_MASTER, &qdev->flags)) {\n\t\t\t \n\t\t\tnetif_printk(qdev, link, KERN_DEBUG, qdev->ndev,\n\t\t\t\t     \"Configuring link\\n\");\n\t\t\tql_mac_cfg_soft_reset(qdev, 1);\n\t\t\tql_mac_cfg_gig(qdev,\n\t\t\t\t       (ql_get_link_speed\n\t\t\t\t\t(qdev) ==\n\t\t\t\t\tSPEED_1000));\n\t\t\tql_mac_cfg_full_dup(qdev,\n\t\t\t\t\t    ql_is_link_full_dup\n\t\t\t\t\t    (qdev));\n\t\t\tql_mac_cfg_pause(qdev,\n\t\t\t\t\t ql_is_neg_pause\n\t\t\t\t\t (qdev));\n\t\t\tql_mac_cfg_soft_reset(qdev, 0);\n\n\t\t\t \n\t\t\tnetif_printk(qdev, link, KERN_DEBUG, qdev->ndev,\n\t\t\t\t     \"Enabling mac\\n\");\n\t\t\tql_mac_enable(qdev, 1);\n\t\t}\n\n\t\tqdev->port_link_state = LS_UP;\n\t\tnetif_start_queue(qdev->ndev);\n\t\tnetif_carrier_on(qdev->ndev);\n\t\tnetif_info(qdev, link, qdev->ndev,\n\t\t\t   \"Link is up at %d Mbps, %s duplex\\n\",\n\t\t\t   ql_get_link_speed(qdev),\n\t\t\t   ql_is_link_full_dup(qdev) ? \"full\" : \"half\");\n\n\t} else {\t \n\n\t\tif (test_bit(QL_LINK_MASTER, &qdev->flags)) {\n\t\t\tnetif_printk(qdev, link, KERN_DEBUG, qdev->ndev,\n\t\t\t\t     \"Remote error detected. Calling ql_port_start()\\n\");\n\t\t\t \n\t\t\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\t\t\tif (ql_port_start(qdev))\t \n\t\t\t\treturn -1;\n\t\t\treturn 0;\n\t\t}\n\t}\n\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\treturn 0;\n}\n\nstatic void ql_link_state_machine_work(struct work_struct *work)\n{\n\tstruct ql3_adapter *qdev =\n\t\tcontainer_of(work, struct ql3_adapter, link_state_work.work);\n\n\tu32 curr_link_state;\n\tunsigned long hw_flags;\n\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\n\tcurr_link_state = ql_get_link_state(qdev);\n\n\tif (test_bit(QL_RESET_ACTIVE, &qdev->flags)) {\n\t\tnetif_info(qdev, link, qdev->ndev,\n\t\t\t   \"Reset in progress, skip processing link state\\n\");\n\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\n\t\t \n\t\tmod_timer(&qdev->adapter_timer, jiffies + HZ * 1);\n\n\t\treturn;\n\t}\n\n\tswitch (qdev->port_link_state) {\n\tdefault:\n\t\tif (test_bit(QL_LINK_MASTER, &qdev->flags))\n\t\t\tql_port_start(qdev);\n\t\tqdev->port_link_state = LS_DOWN;\n\t\tfallthrough;\n\n\tcase LS_DOWN:\n\t\tif (curr_link_state == LS_UP) {\n\t\t\tnetif_info(qdev, link, qdev->ndev, \"Link is up\\n\");\n\t\t\tif (ql_is_auto_neg_complete(qdev))\n\t\t\t\tql_finish_auto_neg(qdev);\n\n\t\t\tif (qdev->port_link_state == LS_UP)\n\t\t\t\tql_link_down_detect_clear(qdev);\n\n\t\t\tqdev->port_link_state = LS_UP;\n\t\t}\n\t\tbreak;\n\n\tcase LS_UP:\n\t\t \n\t\tif (curr_link_state == LS_DOWN) {\n\t\t\tnetif_info(qdev, link, qdev->ndev, \"Link is down\\n\");\n\t\t\tqdev->port_link_state = LS_DOWN;\n\t\t}\n\t\tif (ql_link_down_detect(qdev))\n\t\t\tqdev->port_link_state = LS_DOWN;\n\t\tbreak;\n\t}\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\n\t \n\tmod_timer(&qdev->adapter_timer, jiffies + HZ * 1);\n}\n\n \nstatic void ql_get_phy_owner(struct ql3_adapter *qdev)\n{\n\tif (ql_this_adapter_controls_port(qdev))\n\t\tset_bit(QL_LINK_MASTER, &qdev->flags);\n\telse\n\t\tclear_bit(QL_LINK_MASTER, &qdev->flags);\n}\n\n \nstatic void ql_init_scan_mode(struct ql3_adapter *qdev)\n{\n\tql_mii_enable_scan_mode(qdev);\n\n\tif (test_bit(QL_LINK_OPTICAL, &qdev->flags)) {\n\t\tif (ql_this_adapter_controls_port(qdev))\n\t\t\tql_petbi_init_ex(qdev);\n\t} else {\n\t\tif (ql_this_adapter_controls_port(qdev))\n\t\t\tql_phy_init_ex(qdev);\n\t}\n}\n\n \nstatic int ql_mii_setup(struct ql3_adapter *qdev)\n{\n\tu32 reg;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\n\tif (ql_sem_spinlock(qdev, QL_PHY_GIO_SEM_MASK,\n\t\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index) *\n\t\t\t 2) << 7))\n\t\treturn -1;\n\n\tif (qdev->device_id == QL3032_DEVICE_ID)\n\t\tql_write_page0_reg(qdev,\n\t\t\t&port_regs->macMIIMgmtControlReg, 0x0f00000);\n\n\t \n\treg = MAC_MII_CONTROL_CLK_SEL_DIV28;\n\n\tql_write_page0_reg(qdev, &port_regs->macMIIMgmtControlReg,\n\t\t\t   reg | ((MAC_MII_CONTROL_CLK_SEL_MASK) << 16));\n\n\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\treturn 0;\n}\n\n#define SUPPORTED_OPTICAL_MODES\t(SUPPORTED_1000baseT_Full |\t\\\n\t\t\t\t SUPPORTED_FIBRE |\t\t\\\n\t\t\t\t SUPPORTED_Autoneg)\n#define SUPPORTED_TP_MODES\t(SUPPORTED_10baseT_Half |\t\\\n\t\t\t\t SUPPORTED_10baseT_Full |\t\\\n\t\t\t\t SUPPORTED_100baseT_Half |\t\\\n\t\t\t\t SUPPORTED_100baseT_Full |\t\\\n\t\t\t\t SUPPORTED_1000baseT_Half |\t\\\n\t\t\t\t SUPPORTED_1000baseT_Full |\t\\\n\t\t\t\t SUPPORTED_Autoneg |\t\t\\\n\t\t\t\t SUPPORTED_TP)\t\t\t\\\n\nstatic u32 ql_supported_modes(struct ql3_adapter *qdev)\n{\n\tif (test_bit(QL_LINK_OPTICAL, &qdev->flags))\n\t\treturn SUPPORTED_OPTICAL_MODES;\n\n\treturn SUPPORTED_TP_MODES;\n}\n\nstatic int ql_get_auto_cfg_status(struct ql3_adapter *qdev)\n{\n\tint status;\n\tunsigned long hw_flags;\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\tif (ql_sem_spinlock(qdev, QL_PHY_GIO_SEM_MASK,\n\t\t\t    (QL_RESOURCE_BITS_BASE_CODE |\n\t\t\t     (qdev->mac_index) * 2) << 7)) {\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\t\treturn 0;\n\t}\n\tstatus = ql_is_auto_cfg(qdev);\n\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\treturn status;\n}\n\nstatic u32 ql_get_speed(struct ql3_adapter *qdev)\n{\n\tu32 status;\n\tunsigned long hw_flags;\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\tif (ql_sem_spinlock(qdev, QL_PHY_GIO_SEM_MASK,\n\t\t\t    (QL_RESOURCE_BITS_BASE_CODE |\n\t\t\t     (qdev->mac_index) * 2) << 7)) {\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\t\treturn 0;\n\t}\n\tstatus = ql_get_link_speed(qdev);\n\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\treturn status;\n}\n\nstatic int ql_get_full_dup(struct ql3_adapter *qdev)\n{\n\tint status;\n\tunsigned long hw_flags;\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\tif (ql_sem_spinlock(qdev, QL_PHY_GIO_SEM_MASK,\n\t\t\t    (QL_RESOURCE_BITS_BASE_CODE |\n\t\t\t     (qdev->mac_index) * 2) << 7)) {\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\t\treturn 0;\n\t}\n\tstatus = ql_is_link_full_dup(qdev);\n\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\treturn status;\n}\n\nstatic int ql_get_link_ksettings(struct net_device *ndev,\n\t\t\t\t struct ethtool_link_ksettings *cmd)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tu32 supported, advertising;\n\n\tsupported = ql_supported_modes(qdev);\n\n\tif (test_bit(QL_LINK_OPTICAL, &qdev->flags)) {\n\t\tcmd->base.port = PORT_FIBRE;\n\t} else {\n\t\tcmd->base.port = PORT_TP;\n\t\tcmd->base.phy_address = qdev->PHYAddr;\n\t}\n\tadvertising = ql_supported_modes(qdev);\n\tcmd->base.autoneg = ql_get_auto_cfg_status(qdev);\n\tcmd->base.speed = ql_get_speed(qdev);\n\tcmd->base.duplex = ql_get_full_dup(qdev);\n\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported,\n\t\t\t\t\t\tsupported);\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.advertising,\n\t\t\t\t\t\tadvertising);\n\n\treturn 0;\n}\n\nstatic void ql_get_drvinfo(struct net_device *ndev,\n\t\t\t   struct ethtool_drvinfo *drvinfo)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tstrscpy(drvinfo->driver, ql3xxx_driver_name, sizeof(drvinfo->driver));\n\tstrscpy(drvinfo->version, ql3xxx_driver_version,\n\t\tsizeof(drvinfo->version));\n\tstrscpy(drvinfo->bus_info, pci_name(qdev->pdev),\n\t\tsizeof(drvinfo->bus_info));\n}\n\nstatic u32 ql_get_msglevel(struct net_device *ndev)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\treturn qdev->msg_enable;\n}\n\nstatic void ql_set_msglevel(struct net_device *ndev, u32 value)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tqdev->msg_enable = value;\n}\n\nstatic void ql_get_pauseparam(struct net_device *ndev,\n\t\t\t      struct ethtool_pauseparam *pause)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\n\tu32 reg;\n\tif (qdev->mac_index == 0)\n\t\treg = ql_read_page0_reg(qdev, &port_regs->mac0ConfigReg);\n\telse\n\t\treg = ql_read_page0_reg(qdev, &port_regs->mac1ConfigReg);\n\n\tpause->autoneg  = ql_get_auto_cfg_status(qdev);\n\tpause->rx_pause = (reg & MAC_CONFIG_REG_RF) >> 2;\n\tpause->tx_pause = (reg & MAC_CONFIG_REG_TF) >> 1;\n}\n\nstatic const struct ethtool_ops ql3xxx_ethtool_ops = {\n\t.get_drvinfo = ql_get_drvinfo,\n\t.get_link = ethtool_op_get_link,\n\t.get_msglevel = ql_get_msglevel,\n\t.set_msglevel = ql_set_msglevel,\n\t.get_pauseparam = ql_get_pauseparam,\n\t.get_link_ksettings = ql_get_link_ksettings,\n};\n\nstatic int ql_populate_free_queue(struct ql3_adapter *qdev)\n{\n\tstruct ql_rcv_buf_cb *lrg_buf_cb = qdev->lrg_buf_free_head;\n\tdma_addr_t map;\n\tint err;\n\n\twhile (lrg_buf_cb) {\n\t\tif (!lrg_buf_cb->skb) {\n\t\t\tlrg_buf_cb->skb =\n\t\t\t\tnetdev_alloc_skb(qdev->ndev,\n\t\t\t\t\t\t qdev->lrg_buffer_len);\n\t\t\tif (unlikely(!lrg_buf_cb->skb)) {\n\t\t\t\tnetdev_printk(KERN_DEBUG, qdev->ndev,\n\t\t\t\t\t      \"Failed netdev_alloc_skb()\\n\");\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tskb_reserve(lrg_buf_cb->skb, QL_HEADER_SPACE);\n\t\t\t\tmap = dma_map_single(&qdev->pdev->dev,\n\t\t\t\t\t\t     lrg_buf_cb->skb->data,\n\t\t\t\t\t\t     qdev->lrg_buffer_len - QL_HEADER_SPACE,\n\t\t\t\t\t\t     DMA_FROM_DEVICE);\n\n\t\t\t\terr = dma_mapping_error(&qdev->pdev->dev, map);\n\t\t\t\tif (err) {\n\t\t\t\t\tnetdev_err(qdev->ndev,\n\t\t\t\t\t\t   \"PCI mapping failed with error: %d\\n\",\n\t\t\t\t\t\t   err);\n\t\t\t\t\tdev_kfree_skb(lrg_buf_cb->skb);\n\t\t\t\t\tlrg_buf_cb->skb = NULL;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\n\t\t\t\tlrg_buf_cb->buf_phy_addr_low =\n\t\t\t\t\tcpu_to_le32(LS_64BITS(map));\n\t\t\t\tlrg_buf_cb->buf_phy_addr_high =\n\t\t\t\t\tcpu_to_le32(MS_64BITS(map));\n\t\t\t\tdma_unmap_addr_set(lrg_buf_cb, mapaddr, map);\n\t\t\t\tdma_unmap_len_set(lrg_buf_cb, maplen,\n\t\t\t\t\t\t  qdev->lrg_buffer_len -\n\t\t\t\t\t\t  QL_HEADER_SPACE);\n\t\t\t\t--qdev->lrg_buf_skb_check;\n\t\t\t\tif (!qdev->lrg_buf_skb_check)\n\t\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t\tlrg_buf_cb = lrg_buf_cb->next;\n\t}\n\treturn 0;\n}\n\n \nstatic void ql_update_small_bufq_prod_index(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\n\tif (qdev->small_buf_release_cnt >= 16) {\n\t\twhile (qdev->small_buf_release_cnt >= 16) {\n\t\t\tqdev->small_buf_q_producer_index++;\n\n\t\t\tif (qdev->small_buf_q_producer_index ==\n\t\t\t    NUM_SBUFQ_ENTRIES)\n\t\t\t\tqdev->small_buf_q_producer_index = 0;\n\t\t\tqdev->small_buf_release_cnt -= 8;\n\t\t}\n\t\twmb();\n\t\twritel_relaxed(qdev->small_buf_q_producer_index,\n\t\t\t       &port_regs->CommonRegs.rxSmallQProducerIndex);\n\t}\n}\n\n \nstatic void ql_update_lrg_bufq_prod_index(struct ql3_adapter *qdev)\n{\n\tstruct bufq_addr_element *lrg_buf_q_ele;\n\tint i;\n\tstruct ql_rcv_buf_cb *lrg_buf_cb;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\n\tif ((qdev->lrg_buf_free_count >= 8) &&\n\t    (qdev->lrg_buf_release_cnt >= 16)) {\n\n\t\tif (qdev->lrg_buf_skb_check)\n\t\t\tif (!ql_populate_free_queue(qdev))\n\t\t\t\treturn;\n\n\t\tlrg_buf_q_ele = qdev->lrg_buf_next_free;\n\n\t\twhile ((qdev->lrg_buf_release_cnt >= 16) &&\n\t\t       (qdev->lrg_buf_free_count >= 8)) {\n\n\t\t\tfor (i = 0; i < 8; i++) {\n\t\t\t\tlrg_buf_cb =\n\t\t\t\t    ql_get_from_lrg_buf_free_list(qdev);\n\t\t\t\tlrg_buf_q_ele->addr_high =\n\t\t\t\t    lrg_buf_cb->buf_phy_addr_high;\n\t\t\t\tlrg_buf_q_ele->addr_low =\n\t\t\t\t    lrg_buf_cb->buf_phy_addr_low;\n\t\t\t\tlrg_buf_q_ele++;\n\n\t\t\t\tqdev->lrg_buf_release_cnt--;\n\t\t\t}\n\n\t\t\tqdev->lrg_buf_q_producer_index++;\n\n\t\t\tif (qdev->lrg_buf_q_producer_index ==\n\t\t\t    qdev->num_lbufq_entries)\n\t\t\t\tqdev->lrg_buf_q_producer_index = 0;\n\n\t\t\tif (qdev->lrg_buf_q_producer_index ==\n\t\t\t    (qdev->num_lbufq_entries - 1)) {\n\t\t\t\tlrg_buf_q_ele = qdev->lrg_buf_q_virt_addr;\n\t\t\t}\n\t\t}\n\t\twmb();\n\t\tqdev->lrg_buf_next_free = lrg_buf_q_ele;\n\t\twritel(qdev->lrg_buf_q_producer_index,\n\t\t\t&port_regs->CommonRegs.rxLargeQProducerIndex);\n\t}\n}\n\nstatic void ql_process_mac_tx_intr(struct ql3_adapter *qdev,\n\t\t\t\t   struct ob_mac_iocb_rsp *mac_rsp)\n{\n\tstruct ql_tx_buf_cb *tx_cb;\n\tint i;\n\n\tif (mac_rsp->flags & OB_MAC_IOCB_RSP_S) {\n\t\tnetdev_warn(qdev->ndev,\n\t\t\t    \"Frame too short but it was padded and sent\\n\");\n\t}\n\n\ttx_cb = &qdev->tx_buf[mac_rsp->transaction_id];\n\n\t \n\tif (mac_rsp->flags & OB_MAC_IOCB_RSP_S) {\n\t\tnetdev_err(qdev->ndev,\n\t\t\t   \"Frame too short to be legal, frame not sent\\n\");\n\n\t\tqdev->ndev->stats.tx_errors++;\n\t\tgoto frame_not_sent;\n\t}\n\n\tif (tx_cb->seg_count == 0) {\n\t\tnetdev_err(qdev->ndev, \"tx_cb->seg_count == 0: %d\\n\",\n\t\t\t   mac_rsp->transaction_id);\n\n\t\tqdev->ndev->stats.tx_errors++;\n\t\tgoto invalid_seg_count;\n\t}\n\n\tdma_unmap_single(&qdev->pdev->dev,\n\t\t\t dma_unmap_addr(&tx_cb->map[0], mapaddr),\n\t\t\t dma_unmap_len(&tx_cb->map[0], maplen), DMA_TO_DEVICE);\n\ttx_cb->seg_count--;\n\tif (tx_cb->seg_count) {\n\t\tfor (i = 1; i < tx_cb->seg_count; i++) {\n\t\t\tdma_unmap_page(&qdev->pdev->dev,\n\t\t\t\t       dma_unmap_addr(&tx_cb->map[i], mapaddr),\n\t\t\t\t       dma_unmap_len(&tx_cb->map[i], maplen),\n\t\t\t\t       DMA_TO_DEVICE);\n\t\t}\n\t}\n\tqdev->ndev->stats.tx_packets++;\n\tqdev->ndev->stats.tx_bytes += tx_cb->skb->len;\n\nframe_not_sent:\n\tdev_kfree_skb_irq(tx_cb->skb);\n\ttx_cb->skb = NULL;\n\ninvalid_seg_count:\n\tatomic_inc(&qdev->tx_count);\n}\n\nstatic void ql_get_sbuf(struct ql3_adapter *qdev)\n{\n\tif (++qdev->small_buf_index == NUM_SMALL_BUFFERS)\n\t\tqdev->small_buf_index = 0;\n\tqdev->small_buf_release_cnt++;\n}\n\nstatic struct ql_rcv_buf_cb *ql_get_lbuf(struct ql3_adapter *qdev)\n{\n\tstruct ql_rcv_buf_cb *lrg_buf_cb = NULL;\n\tlrg_buf_cb = &qdev->lrg_buf[qdev->lrg_buf_index];\n\tqdev->lrg_buf_release_cnt++;\n\tif (++qdev->lrg_buf_index == qdev->num_large_buffers)\n\t\tqdev->lrg_buf_index = 0;\n\treturn lrg_buf_cb;\n}\n\n \nstatic void ql_process_mac_rx_intr(struct ql3_adapter *qdev,\n\t\t\t\t   struct ib_mac_iocb_rsp *ib_mac_rsp_ptr)\n{\n\tstruct ql_rcv_buf_cb *lrg_buf_cb1 = NULL;\n\tstruct ql_rcv_buf_cb *lrg_buf_cb2 = NULL;\n\tstruct sk_buff *skb;\n\tu16 length = le16_to_cpu(ib_mac_rsp_ptr->length);\n\n\t \n\tql_get_sbuf(qdev);\n\n\tif (qdev->device_id == QL3022_DEVICE_ID)\n\t\tlrg_buf_cb1 = ql_get_lbuf(qdev);\n\n\t \n\tlrg_buf_cb2 = ql_get_lbuf(qdev);\n\tskb = lrg_buf_cb2->skb;\n\n\tqdev->ndev->stats.rx_packets++;\n\tqdev->ndev->stats.rx_bytes += length;\n\n\tskb_put(skb, length);\n\tdma_unmap_single(&qdev->pdev->dev,\n\t\t\t dma_unmap_addr(lrg_buf_cb2, mapaddr),\n\t\t\t dma_unmap_len(lrg_buf_cb2, maplen), DMA_FROM_DEVICE);\n\tprefetch(skb->data);\n\tskb_checksum_none_assert(skb);\n\tskb->protocol = eth_type_trans(skb, qdev->ndev);\n\n\tnapi_gro_receive(&qdev->napi, skb);\n\tlrg_buf_cb2->skb = NULL;\n\n\tif (qdev->device_id == QL3022_DEVICE_ID)\n\t\tql_release_to_lrg_buf_free_list(qdev, lrg_buf_cb1);\n\tql_release_to_lrg_buf_free_list(qdev, lrg_buf_cb2);\n}\n\nstatic void ql_process_macip_rx_intr(struct ql3_adapter *qdev,\n\t\t\t\t     struct ib_ip_iocb_rsp *ib_ip_rsp_ptr)\n{\n\tstruct ql_rcv_buf_cb *lrg_buf_cb1 = NULL;\n\tstruct ql_rcv_buf_cb *lrg_buf_cb2 = NULL;\n\tstruct sk_buff *skb1 = NULL, *skb2;\n\tstruct net_device *ndev = qdev->ndev;\n\tu16 length = le16_to_cpu(ib_ip_rsp_ptr->length);\n\tu16 size = 0;\n\n\t \n\n\tql_get_sbuf(qdev);\n\n\tif (qdev->device_id == QL3022_DEVICE_ID) {\n\t\t \n\t\tlrg_buf_cb1 = ql_get_lbuf(qdev);\n\t\tskb1 = lrg_buf_cb1->skb;\n\t\tsize = ETH_HLEN;\n\t\tif (*((u16 *) skb1->data) != 0xFFFF)\n\t\t\tsize += VLAN_ETH_HLEN - ETH_HLEN;\n\t}\n\n\t \n\tlrg_buf_cb2 = ql_get_lbuf(qdev);\n\tskb2 = lrg_buf_cb2->skb;\n\n\tskb_put(skb2, length);\t \n\tdma_unmap_single(&qdev->pdev->dev,\n\t\t\t dma_unmap_addr(lrg_buf_cb2, mapaddr),\n\t\t\t dma_unmap_len(lrg_buf_cb2, maplen), DMA_FROM_DEVICE);\n\tprefetch(skb2->data);\n\n\tskb_checksum_none_assert(skb2);\n\tif (qdev->device_id == QL3022_DEVICE_ID) {\n\t\t \n\t\tskb_copy_from_linear_data_offset(skb1, VLAN_ID_LEN,\n\t\t\t\t\t\t skb_push(skb2, size), size);\n\t} else {\n\t\tu16 checksum = le16_to_cpu(ib_ip_rsp_ptr->checksum);\n\t\tif (checksum &\n\t\t\t(IB_IP_IOCB_RSP_3032_ICE |\n\t\t\t IB_IP_IOCB_RSP_3032_CE)) {\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"%s: Bad checksum for this %s packet, checksum = %x\\n\",\n\t\t\t\t   __func__,\n\t\t\t\t   ((checksum & IB_IP_IOCB_RSP_3032_TCP) ?\n\t\t\t\t    \"TCP\" : \"UDP\"), checksum);\n\t\t} else if ((checksum & IB_IP_IOCB_RSP_3032_TCP) ||\n\t\t\t\t(checksum & IB_IP_IOCB_RSP_3032_UDP &&\n\t\t\t\t!(checksum & IB_IP_IOCB_RSP_3032_NUC))) {\n\t\t\tskb2->ip_summed = CHECKSUM_UNNECESSARY;\n\t\t}\n\t}\n\tskb2->protocol = eth_type_trans(skb2, qdev->ndev);\n\n\tnapi_gro_receive(&qdev->napi, skb2);\n\tndev->stats.rx_packets++;\n\tndev->stats.rx_bytes += length;\n\tlrg_buf_cb2->skb = NULL;\n\n\tif (qdev->device_id == QL3022_DEVICE_ID)\n\t\tql_release_to_lrg_buf_free_list(qdev, lrg_buf_cb1);\n\tql_release_to_lrg_buf_free_list(qdev, lrg_buf_cb2);\n}\n\nstatic int ql_tx_rx_clean(struct ql3_adapter *qdev, int budget)\n{\n\tstruct net_rsp_iocb *net_rsp;\n\tstruct net_device *ndev = qdev->ndev;\n\tint work_done = 0;\n\n\t \n\twhile ((le32_to_cpu(*(qdev->prsp_producer_index)) !=\n\t\tqdev->rsp_consumer_index) && (work_done < budget)) {\n\n\t\tnet_rsp = qdev->rsp_current;\n\t\trmb();\n\t\t \n\t\tif (qdev->device_id == QL3032_DEVICE_ID)\n\t\t\tnet_rsp->opcode &= 0x7f;\n\t\tswitch (net_rsp->opcode) {\n\n\t\tcase OPCODE_OB_MAC_IOCB_FN0:\n\t\tcase OPCODE_OB_MAC_IOCB_FN2:\n\t\t\tql_process_mac_tx_intr(qdev, (struct ob_mac_iocb_rsp *)\n\t\t\t\t\t       net_rsp);\n\t\t\tbreak;\n\n\t\tcase OPCODE_IB_MAC_IOCB:\n\t\tcase OPCODE_IB_3032_MAC_IOCB:\n\t\t\tql_process_mac_rx_intr(qdev, (struct ib_mac_iocb_rsp *)\n\t\t\t\t\t       net_rsp);\n\t\t\twork_done++;\n\t\t\tbreak;\n\n\t\tcase OPCODE_IB_IP_IOCB:\n\t\tcase OPCODE_IB_3032_IP_IOCB:\n\t\t\tql_process_macip_rx_intr(qdev, (struct ib_ip_iocb_rsp *)\n\t\t\t\t\t\t net_rsp);\n\t\t\twork_done++;\n\t\t\tbreak;\n\t\tdefault: {\n\t\t\tu32 *tmp = (u32 *)net_rsp;\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"Hit default case, not handled!\\n\"\n\t\t\t\t   \"\tdropping the packet, opcode = %x\\n\"\n\t\t\t\t   \"0x%08lx 0x%08lx 0x%08lx 0x%08lx\\n\",\n\t\t\t\t   net_rsp->opcode,\n\t\t\t\t   (unsigned long int)tmp[0],\n\t\t\t\t   (unsigned long int)tmp[1],\n\t\t\t\t   (unsigned long int)tmp[2],\n\t\t\t\t   (unsigned long int)tmp[3]);\n\t\t}\n\t\t}\n\n\t\tqdev->rsp_consumer_index++;\n\n\t\tif (qdev->rsp_consumer_index == NUM_RSP_Q_ENTRIES) {\n\t\t\tqdev->rsp_consumer_index = 0;\n\t\t\tqdev->rsp_current = qdev->rsp_q_virt_addr;\n\t\t} else {\n\t\t\tqdev->rsp_current++;\n\t\t}\n\n\t}\n\n\treturn work_done;\n}\n\nstatic int ql_poll(struct napi_struct *napi, int budget)\n{\n\tstruct ql3_adapter *qdev = container_of(napi, struct ql3_adapter, napi);\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tint work_done;\n\n\twork_done = ql_tx_rx_clean(qdev, budget);\n\n\tif (work_done < budget && napi_complete_done(napi, work_done)) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&qdev->hw_lock, flags);\n\t\tql_update_small_bufq_prod_index(qdev);\n\t\tql_update_lrg_bufq_prod_index(qdev);\n\t\twritel(qdev->rsp_consumer_index,\n\t\t\t    &port_regs->CommonRegs.rspQConsumerIndex);\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, flags);\n\n\t\tql_enable_interrupts(qdev);\n\t}\n\treturn work_done;\n}\n\nstatic irqreturn_t ql3xxx_isr(int irq, void *dev_id)\n{\n\n\tstruct net_device *ndev = dev_id;\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tu32 value;\n\tint handled = 1;\n\tu32 var;\n\n\tvalue = ql_read_common_reg_l(qdev,\n\t\t\t\t     &port_regs->CommonRegs.ispControlStatus);\n\n\tif (value & (ISP_CONTROL_FE | ISP_CONTROL_RI)) {\n\t\tspin_lock(&qdev->adapter_lock);\n\t\tnetif_stop_queue(qdev->ndev);\n\t\tnetif_carrier_off(qdev->ndev);\n\t\tql_disable_interrupts(qdev);\n\t\tqdev->port_link_state = LS_DOWN;\n\t\tset_bit(QL_RESET_ACTIVE, &qdev->flags) ;\n\n\t\tif (value & ISP_CONTROL_FE) {\n\t\t\t \n\t\t\tvar =\n\t\t\t    ql_read_page0_reg_l(qdev,\n\t\t\t\t\t      &port_regs->PortFatalErrStatus);\n\t\t\tnetdev_warn(ndev,\n\t\t\t\t    \"Resetting chip. PortFatalErrStatus register = 0x%x\\n\",\n\t\t\t\t    var);\n\t\t\tset_bit(QL_RESET_START, &qdev->flags) ;\n\t\t} else {\n\t\t\t \n\t\t\tset_bit(QL_RESET_PER_SCSI, &qdev->flags) ;\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"Another function issued a reset to the chip. ISR value = %x\\n\",\n\t\t\t\t   value);\n\t\t}\n\t\tqueue_delayed_work(qdev->workqueue, &qdev->reset_work, 0);\n\t\tspin_unlock(&qdev->adapter_lock);\n\t} else if (value & ISP_IMR_DISABLE_CMPL_INT) {\n\t\tql_disable_interrupts(qdev);\n\t\tif (likely(napi_schedule_prep(&qdev->napi)))\n\t\t\t__napi_schedule(&qdev->napi);\n\t} else\n\t\treturn IRQ_NONE;\n\n\treturn IRQ_RETVAL(handled);\n}\n\n \nstatic int ql_get_seg_count(struct ql3_adapter *qdev, unsigned short frags)\n{\n\tif (qdev->device_id == QL3022_DEVICE_ID)\n\t\treturn 1;\n\n\tif (frags <= 2)\n\t\treturn frags + 1;\n\telse if (frags <= 6)\n\t\treturn frags + 2;\n\telse if (frags <= 10)\n\t\treturn frags + 3;\n\telse if (frags <= 14)\n\t\treturn frags + 4;\n\telse if (frags <= 18)\n\t\treturn frags + 5;\n\treturn -1;\n}\n\nstatic void ql_hw_csum_setup(const struct sk_buff *skb,\n\t\t\t     struct ob_mac_iocb_req *mac_iocb_ptr)\n{\n\tconst struct iphdr *ip = ip_hdr(skb);\n\n\tmac_iocb_ptr->ip_hdr_off = skb_network_offset(skb);\n\tmac_iocb_ptr->ip_hdr_len = ip->ihl;\n\n\tif (ip->protocol == IPPROTO_TCP) {\n\t\tmac_iocb_ptr->flags1 |= OB_3032MAC_IOCB_REQ_TC |\n\t\t\tOB_3032MAC_IOCB_REQ_IC;\n\t} else {\n\t\tmac_iocb_ptr->flags1 |= OB_3032MAC_IOCB_REQ_UC |\n\t\t\tOB_3032MAC_IOCB_REQ_IC;\n\t}\n\n}\n\n \nstatic int ql_send_map(struct ql3_adapter *qdev,\n\t\t\t\tstruct ob_mac_iocb_req *mac_iocb_ptr,\n\t\t\t\tstruct ql_tx_buf_cb *tx_cb,\n\t\t\t\tstruct sk_buff *skb)\n{\n\tstruct oal *oal;\n\tstruct oal_entry *oal_entry;\n\tint len = skb_headlen(skb);\n\tdma_addr_t map;\n\tint err;\n\tint completed_segs, i;\n\tint seg_cnt, seg = 0;\n\tint frag_cnt = (int)skb_shinfo(skb)->nr_frags;\n\n\tseg_cnt = tx_cb->seg_count;\n\t \n\tmap = dma_map_single(&qdev->pdev->dev, skb->data, len, DMA_TO_DEVICE);\n\n\terr = dma_mapping_error(&qdev->pdev->dev, map);\n\tif (err) {\n\t\tnetdev_err(qdev->ndev, \"PCI mapping failed with error: %d\\n\",\n\t\t\t   err);\n\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\toal_entry = (struct oal_entry *)&mac_iocb_ptr->buf_addr0_low;\n\toal_entry->dma_lo = cpu_to_le32(LS_64BITS(map));\n\toal_entry->dma_hi = cpu_to_le32(MS_64BITS(map));\n\toal_entry->len = cpu_to_le32(len);\n\tdma_unmap_addr_set(&tx_cb->map[seg], mapaddr, map);\n\tdma_unmap_len_set(&tx_cb->map[seg], maplen, len);\n\tseg++;\n\n\tif (seg_cnt == 1) {\n\t\t \n\t\toal_entry->len |= cpu_to_le32(OAL_LAST_ENTRY);\n\t\treturn NETDEV_TX_OK;\n\t}\n\toal = tx_cb->oal;\n\tfor (completed_segs = 0;\n\t     completed_segs < frag_cnt;\n\t     completed_segs++, seg++) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[completed_segs];\n\t\toal_entry++;\n\t\t \n\t\tif ((seg == 2 && seg_cnt > 3) ||\n\t\t    (seg == 7 && seg_cnt > 8) ||\n\t\t    (seg == 12 && seg_cnt > 13) ||\n\t\t    (seg == 17 && seg_cnt > 18)) {\n\t\t\tmap = dma_map_single(&qdev->pdev->dev, oal,\n\t\t\t\t\t     sizeof(struct oal),\n\t\t\t\t\t     DMA_TO_DEVICE);\n\n\t\t\terr = dma_mapping_error(&qdev->pdev->dev, map);\n\t\t\tif (err) {\n\t\t\t\tnetdev_err(qdev->ndev,\n\t\t\t\t\t   \"PCI mapping outbound address list with error: %d\\n\",\n\t\t\t\t\t   err);\n\t\t\t\tgoto map_error;\n\t\t\t}\n\n\t\t\toal_entry->dma_lo = cpu_to_le32(LS_64BITS(map));\n\t\t\toal_entry->dma_hi = cpu_to_le32(MS_64BITS(map));\n\t\t\toal_entry->len = cpu_to_le32(sizeof(struct oal) |\n\t\t\t\t\t\t     OAL_CONT_ENTRY);\n\t\t\tdma_unmap_addr_set(&tx_cb->map[seg], mapaddr, map);\n\t\t\tdma_unmap_len_set(&tx_cb->map[seg], maplen,\n\t\t\t\t\t  sizeof(struct oal));\n\t\t\toal_entry = (struct oal_entry *)oal;\n\t\t\toal++;\n\t\t\tseg++;\n\t\t}\n\n\t\tmap = skb_frag_dma_map(&qdev->pdev->dev, frag, 0, skb_frag_size(frag),\n\t\t\t\t       DMA_TO_DEVICE);\n\n\t\terr = dma_mapping_error(&qdev->pdev->dev, map);\n\t\tif (err) {\n\t\t\tnetdev_err(qdev->ndev,\n\t\t\t\t   \"PCI mapping frags failed with error: %d\\n\",\n\t\t\t\t   err);\n\t\t\tgoto map_error;\n\t\t}\n\n\t\toal_entry->dma_lo = cpu_to_le32(LS_64BITS(map));\n\t\toal_entry->dma_hi = cpu_to_le32(MS_64BITS(map));\n\t\toal_entry->len = cpu_to_le32(skb_frag_size(frag));\n\t\tdma_unmap_addr_set(&tx_cb->map[seg], mapaddr, map);\n\t\tdma_unmap_len_set(&tx_cb->map[seg], maplen, skb_frag_size(frag));\n\t\t}\n\t \n\toal_entry->len |= cpu_to_le32(OAL_LAST_ENTRY);\n\treturn NETDEV_TX_OK;\n\nmap_error:\n\t \n\n\tseg = 1;\n\toal_entry = (struct oal_entry *)&mac_iocb_ptr->buf_addr0_low;\n\toal = tx_cb->oal;\n\tfor (i = 0; i < completed_segs; i++, seg++) {\n\t\toal_entry++;\n\n\t\t \n\n\t\tif ((seg == 2 && seg_cnt > 3) ||\n\t\t    (seg == 7 && seg_cnt > 8) ||\n\t\t    (seg == 12 && seg_cnt > 13) ||\n\t\t    (seg == 17 && seg_cnt > 18)) {\n\t\t\tdma_unmap_single(&qdev->pdev->dev,\n\t\t\t\t\t dma_unmap_addr(&tx_cb->map[seg], mapaddr),\n\t\t\t\t\t dma_unmap_len(&tx_cb->map[seg], maplen),\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\toal++;\n\t\t\tseg++;\n\t\t}\n\n\t\tdma_unmap_page(&qdev->pdev->dev,\n\t\t\t       dma_unmap_addr(&tx_cb->map[seg], mapaddr),\n\t\t\t       dma_unmap_len(&tx_cb->map[seg], maplen),\n\t\t\t       DMA_TO_DEVICE);\n\t}\n\n\tdma_unmap_single(&qdev->pdev->dev,\n\t\t\t dma_unmap_addr(&tx_cb->map[0], mapaddr),\n\t\t\t dma_unmap_addr(&tx_cb->map[0], maplen),\n\t\t\t DMA_TO_DEVICE);\n\n\treturn NETDEV_TX_BUSY;\n\n}\n\n \nstatic netdev_tx_t ql3xxx_send(struct sk_buff *skb,\n\t\t\t       struct net_device *ndev)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tstruct ql_tx_buf_cb *tx_cb;\n\tu32 tot_len = skb->len;\n\tstruct ob_mac_iocb_req *mac_iocb_ptr;\n\n\tif (unlikely(atomic_read(&qdev->tx_count) < 2))\n\t\treturn NETDEV_TX_BUSY;\n\n\ttx_cb = &qdev->tx_buf[qdev->req_producer_index];\n\ttx_cb->seg_count = ql_get_seg_count(qdev,\n\t\t\t\t\t     skb_shinfo(skb)->nr_frags);\n\tif (tx_cb->seg_count == -1) {\n\t\tnetdev_err(ndev, \"%s: invalid segment count!\\n\", __func__);\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tmac_iocb_ptr = tx_cb->queue_entry;\n\tmemset((void *)mac_iocb_ptr, 0, sizeof(struct ob_mac_iocb_req));\n\tmac_iocb_ptr->opcode = qdev->mac_ob_opcode;\n\tmac_iocb_ptr->flags = OB_MAC_IOCB_REQ_X;\n\tmac_iocb_ptr->flags |= qdev->mb_bit_mask;\n\tmac_iocb_ptr->transaction_id = qdev->req_producer_index;\n\tmac_iocb_ptr->data_len = cpu_to_le16((u16) tot_len);\n\ttx_cb->skb = skb;\n\tif (qdev->device_id == QL3032_DEVICE_ID &&\n\t    skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tql_hw_csum_setup(skb, mac_iocb_ptr);\n\n\tif (ql_send_map(qdev, mac_iocb_ptr, tx_cb, skb) != NETDEV_TX_OK) {\n\t\tnetdev_err(ndev, \"%s: Could not map the segments!\\n\", __func__);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\twmb();\n\tqdev->req_producer_index++;\n\tif (qdev->req_producer_index == NUM_REQ_Q_ENTRIES)\n\t\tqdev->req_producer_index = 0;\n\twmb();\n\tql_write_common_reg_l(qdev,\n\t\t\t    &port_regs->CommonRegs.reqQProducerIndex,\n\t\t\t    qdev->req_producer_index);\n\n\tnetif_printk(qdev, tx_queued, KERN_DEBUG, ndev,\n\t\t     \"tx queued, slot %d, len %d\\n\",\n\t\t     qdev->req_producer_index, skb->len);\n\n\tatomic_dec(&qdev->tx_count);\n\treturn NETDEV_TX_OK;\n}\n\nstatic int ql_alloc_net_req_rsp_queues(struct ql3_adapter *qdev)\n{\n\tqdev->req_q_size =\n\t    (u32) (NUM_REQ_Q_ENTRIES * sizeof(struct ob_mac_iocb_req));\n\n\tqdev->rsp_q_size = NUM_RSP_Q_ENTRIES * sizeof(struct net_rsp_iocb);\n\n\t \n\twmb();\n\n\tqdev->req_q_virt_addr =\n\t    dma_alloc_coherent(&qdev->pdev->dev, (size_t)qdev->req_q_size,\n\t\t\t       &qdev->req_q_phy_addr, GFP_KERNEL);\n\n\tif ((qdev->req_q_virt_addr == NULL) ||\n\t    LS_64BITS(qdev->req_q_phy_addr) & (qdev->req_q_size - 1)) {\n\t\tnetdev_err(qdev->ndev, \"reqQ failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tqdev->rsp_q_virt_addr =\n\t    dma_alloc_coherent(&qdev->pdev->dev, (size_t)qdev->rsp_q_size,\n\t\t\t       &qdev->rsp_q_phy_addr, GFP_KERNEL);\n\n\tif ((qdev->rsp_q_virt_addr == NULL) ||\n\t    LS_64BITS(qdev->rsp_q_phy_addr) & (qdev->rsp_q_size - 1)) {\n\t\tnetdev_err(qdev->ndev, \"rspQ allocation failed\\n\");\n\t\tdma_free_coherent(&qdev->pdev->dev, (size_t)qdev->req_q_size,\n\t\t\t\t  qdev->req_q_virt_addr, qdev->req_q_phy_addr);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_bit(QL_ALLOC_REQ_RSP_Q_DONE, &qdev->flags);\n\n\treturn 0;\n}\n\nstatic void ql_free_net_req_rsp_queues(struct ql3_adapter *qdev)\n{\n\tif (!test_bit(QL_ALLOC_REQ_RSP_Q_DONE, &qdev->flags)) {\n\t\tnetdev_info(qdev->ndev, \"Already done\\n\");\n\t\treturn;\n\t}\n\n\tdma_free_coherent(&qdev->pdev->dev, qdev->req_q_size,\n\t\t\t  qdev->req_q_virt_addr, qdev->req_q_phy_addr);\n\n\tqdev->req_q_virt_addr = NULL;\n\n\tdma_free_coherent(&qdev->pdev->dev, qdev->rsp_q_size,\n\t\t\t  qdev->rsp_q_virt_addr, qdev->rsp_q_phy_addr);\n\n\tqdev->rsp_q_virt_addr = NULL;\n\n\tclear_bit(QL_ALLOC_REQ_RSP_Q_DONE, &qdev->flags);\n}\n\nstatic int ql_alloc_buffer_queues(struct ql3_adapter *qdev)\n{\n\t \n\tqdev->lrg_buf_q_size =\n\t\tqdev->num_lbufq_entries * sizeof(struct lrg_buf_q_entry);\n\tif (qdev->lrg_buf_q_size < PAGE_SIZE)\n\t\tqdev->lrg_buf_q_alloc_size = PAGE_SIZE;\n\telse\n\t\tqdev->lrg_buf_q_alloc_size = qdev->lrg_buf_q_size * 2;\n\n\tqdev->lrg_buf = kmalloc_array(qdev->num_large_buffers,\n\t\t\t\t      sizeof(struct ql_rcv_buf_cb),\n\t\t\t\t      GFP_KERNEL);\n\tif (qdev->lrg_buf == NULL)\n\t\treturn -ENOMEM;\n\n\tqdev->lrg_buf_q_alloc_virt_addr =\n\t\tdma_alloc_coherent(&qdev->pdev->dev,\n\t\t\t\t   qdev->lrg_buf_q_alloc_size,\n\t\t\t\t   &qdev->lrg_buf_q_alloc_phy_addr, GFP_KERNEL);\n\n\tif (qdev->lrg_buf_q_alloc_virt_addr == NULL) {\n\t\tnetdev_err(qdev->ndev, \"lBufQ failed\\n\");\n\t\tkfree(qdev->lrg_buf);\n\t\treturn -ENOMEM;\n\t}\n\tqdev->lrg_buf_q_virt_addr = qdev->lrg_buf_q_alloc_virt_addr;\n\tqdev->lrg_buf_q_phy_addr = qdev->lrg_buf_q_alloc_phy_addr;\n\n\t \n\tqdev->small_buf_q_size =\n\t\tNUM_SBUFQ_ENTRIES * sizeof(struct lrg_buf_q_entry);\n\tif (qdev->small_buf_q_size < PAGE_SIZE)\n\t\tqdev->small_buf_q_alloc_size = PAGE_SIZE;\n\telse\n\t\tqdev->small_buf_q_alloc_size = qdev->small_buf_q_size * 2;\n\n\tqdev->small_buf_q_alloc_virt_addr =\n\t\tdma_alloc_coherent(&qdev->pdev->dev,\n\t\t\t\t   qdev->small_buf_q_alloc_size,\n\t\t\t\t   &qdev->small_buf_q_alloc_phy_addr, GFP_KERNEL);\n\n\tif (qdev->small_buf_q_alloc_virt_addr == NULL) {\n\t\tnetdev_err(qdev->ndev, \"Small Buffer Queue allocation failed\\n\");\n\t\tdma_free_coherent(&qdev->pdev->dev,\n\t\t\t\t  qdev->lrg_buf_q_alloc_size,\n\t\t\t\t  qdev->lrg_buf_q_alloc_virt_addr,\n\t\t\t\t  qdev->lrg_buf_q_alloc_phy_addr);\n\t\tkfree(qdev->lrg_buf);\n\t\treturn -ENOMEM;\n\t}\n\n\tqdev->small_buf_q_virt_addr = qdev->small_buf_q_alloc_virt_addr;\n\tqdev->small_buf_q_phy_addr = qdev->small_buf_q_alloc_phy_addr;\n\tset_bit(QL_ALLOC_BUFQS_DONE, &qdev->flags);\n\treturn 0;\n}\n\nstatic void ql_free_buffer_queues(struct ql3_adapter *qdev)\n{\n\tif (!test_bit(QL_ALLOC_BUFQS_DONE, &qdev->flags)) {\n\t\tnetdev_info(qdev->ndev, \"Already done\\n\");\n\t\treturn;\n\t}\n\tkfree(qdev->lrg_buf);\n\tdma_free_coherent(&qdev->pdev->dev, qdev->lrg_buf_q_alloc_size,\n\t\t\t  qdev->lrg_buf_q_alloc_virt_addr,\n\t\t\t  qdev->lrg_buf_q_alloc_phy_addr);\n\n\tqdev->lrg_buf_q_virt_addr = NULL;\n\n\tdma_free_coherent(&qdev->pdev->dev, qdev->small_buf_q_alloc_size,\n\t\t\t  qdev->small_buf_q_alloc_virt_addr,\n\t\t\t  qdev->small_buf_q_alloc_phy_addr);\n\n\tqdev->small_buf_q_virt_addr = NULL;\n\n\tclear_bit(QL_ALLOC_BUFQS_DONE, &qdev->flags);\n}\n\nstatic int ql_alloc_small_buffers(struct ql3_adapter *qdev)\n{\n\tint i;\n\tstruct bufq_addr_element *small_buf_q_entry;\n\n\t \n\tqdev->small_buf_total_size =\n\t\t(QL_ADDR_ELE_PER_BUFQ_ENTRY * NUM_SBUFQ_ENTRIES *\n\t\t QL_SMALL_BUFFER_SIZE);\n\n\tqdev->small_buf_virt_addr =\n\t\tdma_alloc_coherent(&qdev->pdev->dev,\n\t\t\t\t   qdev->small_buf_total_size,\n\t\t\t\t   &qdev->small_buf_phy_addr, GFP_KERNEL);\n\n\tif (qdev->small_buf_virt_addr == NULL) {\n\t\tnetdev_err(qdev->ndev, \"Failed to get small buffer memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tqdev->small_buf_phy_addr_low = LS_64BITS(qdev->small_buf_phy_addr);\n\tqdev->small_buf_phy_addr_high = MS_64BITS(qdev->small_buf_phy_addr);\n\n\tsmall_buf_q_entry = qdev->small_buf_q_virt_addr;\n\n\t \n\tfor (i = 0; i < (QL_ADDR_ELE_PER_BUFQ_ENTRY * NUM_SBUFQ_ENTRIES); i++) {\n\t\tsmall_buf_q_entry->addr_high =\n\t\t    cpu_to_le32(qdev->small_buf_phy_addr_high);\n\t\tsmall_buf_q_entry->addr_low =\n\t\t    cpu_to_le32(qdev->small_buf_phy_addr_low +\n\t\t\t\t(i * QL_SMALL_BUFFER_SIZE));\n\t\tsmall_buf_q_entry++;\n\t}\n\tqdev->small_buf_index = 0;\n\tset_bit(QL_ALLOC_SMALL_BUF_DONE, &qdev->flags);\n\treturn 0;\n}\n\nstatic void ql_free_small_buffers(struct ql3_adapter *qdev)\n{\n\tif (!test_bit(QL_ALLOC_SMALL_BUF_DONE, &qdev->flags)) {\n\t\tnetdev_info(qdev->ndev, \"Already done\\n\");\n\t\treturn;\n\t}\n\tif (qdev->small_buf_virt_addr != NULL) {\n\t\tdma_free_coherent(&qdev->pdev->dev,\n\t\t\t\t  qdev->small_buf_total_size,\n\t\t\t\t  qdev->small_buf_virt_addr,\n\t\t\t\t  qdev->small_buf_phy_addr);\n\n\t\tqdev->small_buf_virt_addr = NULL;\n\t}\n}\n\nstatic void ql_free_large_buffers(struct ql3_adapter *qdev)\n{\n\tint i = 0;\n\tstruct ql_rcv_buf_cb *lrg_buf_cb;\n\n\tfor (i = 0; i < qdev->num_large_buffers; i++) {\n\t\tlrg_buf_cb = &qdev->lrg_buf[i];\n\t\tif (lrg_buf_cb->skb) {\n\t\t\tdev_kfree_skb(lrg_buf_cb->skb);\n\t\t\tdma_unmap_single(&qdev->pdev->dev,\n\t\t\t\t\t dma_unmap_addr(lrg_buf_cb, mapaddr),\n\t\t\t\t\t dma_unmap_len(lrg_buf_cb, maplen),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tmemset(lrg_buf_cb, 0, sizeof(struct ql_rcv_buf_cb));\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void ql_init_large_buffers(struct ql3_adapter *qdev)\n{\n\tint i;\n\tstruct ql_rcv_buf_cb *lrg_buf_cb;\n\tstruct bufq_addr_element *buf_addr_ele = qdev->lrg_buf_q_virt_addr;\n\n\tfor (i = 0; i < qdev->num_large_buffers; i++) {\n\t\tlrg_buf_cb = &qdev->lrg_buf[i];\n\t\tbuf_addr_ele->addr_high = lrg_buf_cb->buf_phy_addr_high;\n\t\tbuf_addr_ele->addr_low = lrg_buf_cb->buf_phy_addr_low;\n\t\tbuf_addr_ele++;\n\t}\n\tqdev->lrg_buf_index = 0;\n\tqdev->lrg_buf_skb_check = 0;\n}\n\nstatic int ql_alloc_large_buffers(struct ql3_adapter *qdev)\n{\n\tint i;\n\tstruct ql_rcv_buf_cb *lrg_buf_cb;\n\tstruct sk_buff *skb;\n\tdma_addr_t map;\n\tint err;\n\n\tfor (i = 0; i < qdev->num_large_buffers; i++) {\n\t\tlrg_buf_cb = &qdev->lrg_buf[i];\n\t\tmemset(lrg_buf_cb, 0, sizeof(struct ql_rcv_buf_cb));\n\n\t\tskb = netdev_alloc_skb(qdev->ndev,\n\t\t\t\t       qdev->lrg_buffer_len);\n\t\tif (unlikely(!skb)) {\n\t\t\t \n\t\t\tnetdev_err(qdev->ndev,\n\t\t\t\t   \"large buff alloc failed for %d bytes at index %d\\n\",\n\t\t\t\t   qdev->lrg_buffer_len * 2, i);\n\t\t\tql_free_large_buffers(qdev);\n\t\t\treturn -ENOMEM;\n\t\t} else {\n\t\t\tlrg_buf_cb->index = i;\n\t\t\t \n\t\t\tskb_reserve(skb, QL_HEADER_SPACE);\n\t\t\tmap = dma_map_single(&qdev->pdev->dev, skb->data,\n\t\t\t\t\t     qdev->lrg_buffer_len - QL_HEADER_SPACE,\n\t\t\t\t\t     DMA_FROM_DEVICE);\n\n\t\t\terr = dma_mapping_error(&qdev->pdev->dev, map);\n\t\t\tif (err) {\n\t\t\t\tnetdev_err(qdev->ndev,\n\t\t\t\t\t   \"PCI mapping failed with error: %d\\n\",\n\t\t\t\t\t   err);\n\t\t\t\tdev_kfree_skb_irq(skb);\n\t\t\t\tql_free_large_buffers(qdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\tlrg_buf_cb->skb = skb;\n\t\t\tdma_unmap_addr_set(lrg_buf_cb, mapaddr, map);\n\t\t\tdma_unmap_len_set(lrg_buf_cb, maplen,\n\t\t\t\t\t  qdev->lrg_buffer_len -\n\t\t\t\t\t  QL_HEADER_SPACE);\n\t\t\tlrg_buf_cb->buf_phy_addr_low =\n\t\t\t    cpu_to_le32(LS_64BITS(map));\n\t\t\tlrg_buf_cb->buf_phy_addr_high =\n\t\t\t    cpu_to_le32(MS_64BITS(map));\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void ql_free_send_free_list(struct ql3_adapter *qdev)\n{\n\tstruct ql_tx_buf_cb *tx_cb;\n\tint i;\n\n\ttx_cb = &qdev->tx_buf[0];\n\tfor (i = 0; i < NUM_REQ_Q_ENTRIES; i++) {\n\t\tkfree(tx_cb->oal);\n\t\ttx_cb->oal = NULL;\n\t\ttx_cb++;\n\t}\n}\n\nstatic int ql_create_send_free_list(struct ql3_adapter *qdev)\n{\n\tstruct ql_tx_buf_cb *tx_cb;\n\tint i;\n\tstruct ob_mac_iocb_req *req_q_curr = qdev->req_q_virt_addr;\n\n\t \n\tfor (i = 0; i < NUM_REQ_Q_ENTRIES; i++) {\n\n\t\ttx_cb = &qdev->tx_buf[i];\n\t\ttx_cb->skb = NULL;\n\t\ttx_cb->queue_entry = req_q_curr;\n\t\treq_q_curr++;\n\t\ttx_cb->oal = kmalloc(512, GFP_KERNEL);\n\t\tif (tx_cb->oal == NULL)\n\t\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic int ql_alloc_mem_resources(struct ql3_adapter *qdev)\n{\n\tif (qdev->ndev->mtu == NORMAL_MTU_SIZE) {\n\t\tqdev->num_lbufq_entries = NUM_LBUFQ_ENTRIES;\n\t\tqdev->lrg_buffer_len = NORMAL_MTU_SIZE;\n\t} else if (qdev->ndev->mtu == JUMBO_MTU_SIZE) {\n\t\t \n\t\tqdev->num_lbufq_entries = JUMBO_NUM_LBUFQ_ENTRIES;\n\t\tqdev->lrg_buffer_len = JUMBO_MTU_SIZE;\n\t} else {\n\t\tnetdev_err(qdev->ndev, \"Invalid mtu size: %d.  Only %d and %d are accepted.\\n\",\n\t\t\t   qdev->ndev->mtu, NORMAL_MTU_SIZE, JUMBO_MTU_SIZE);\n\t\treturn -ENOMEM;\n\t}\n\tqdev->num_large_buffers =\n\t\tqdev->num_lbufq_entries * QL_ADDR_ELE_PER_BUFQ_ENTRY;\n\tqdev->lrg_buffer_len += VLAN_ETH_HLEN + VLAN_ID_LEN + QL_HEADER_SPACE;\n\tqdev->max_frame_size =\n\t\t(qdev->lrg_buffer_len - QL_HEADER_SPACE) + ETHERNET_CRC_SIZE;\n\n\t \n\tqdev->shadow_reg_virt_addr =\n\t\tdma_alloc_coherent(&qdev->pdev->dev, PAGE_SIZE,\n\t\t\t\t   &qdev->shadow_reg_phy_addr, GFP_KERNEL);\n\n\tif (qdev->shadow_reg_virt_addr != NULL) {\n\t\tqdev->preq_consumer_index = qdev->shadow_reg_virt_addr;\n\t\tqdev->req_consumer_index_phy_addr_high =\n\t\t\tMS_64BITS(qdev->shadow_reg_phy_addr);\n\t\tqdev->req_consumer_index_phy_addr_low =\n\t\t\tLS_64BITS(qdev->shadow_reg_phy_addr);\n\n\t\tqdev->prsp_producer_index =\n\t\t\t(__le32 *) (((u8 *) qdev->preq_consumer_index) + 8);\n\t\tqdev->rsp_producer_index_phy_addr_high =\n\t\t\tqdev->req_consumer_index_phy_addr_high;\n\t\tqdev->rsp_producer_index_phy_addr_low =\n\t\t\tqdev->req_consumer_index_phy_addr_low + 8;\n\t} else {\n\t\tnetdev_err(qdev->ndev, \"shadowReg Alloc failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (ql_alloc_net_req_rsp_queues(qdev) != 0) {\n\t\tnetdev_err(qdev->ndev, \"ql_alloc_net_req_rsp_queues failed\\n\");\n\t\tgoto err_req_rsp;\n\t}\n\n\tif (ql_alloc_buffer_queues(qdev) != 0) {\n\t\tnetdev_err(qdev->ndev, \"ql_alloc_buffer_queues failed\\n\");\n\t\tgoto err_buffer_queues;\n\t}\n\n\tif (ql_alloc_small_buffers(qdev) != 0) {\n\t\tnetdev_err(qdev->ndev, \"ql_alloc_small_buffers failed\\n\");\n\t\tgoto err_small_buffers;\n\t}\n\n\tif (ql_alloc_large_buffers(qdev) != 0) {\n\t\tnetdev_err(qdev->ndev, \"ql_alloc_large_buffers failed\\n\");\n\t\tgoto err_small_buffers;\n\t}\n\n\t \n\tql_init_large_buffers(qdev);\n\tif (ql_create_send_free_list(qdev))\n\t\tgoto err_free_list;\n\n\tqdev->rsp_current = qdev->rsp_q_virt_addr;\n\n\treturn 0;\nerr_free_list:\n\tql_free_send_free_list(qdev);\nerr_small_buffers:\n\tql_free_buffer_queues(qdev);\nerr_buffer_queues:\n\tql_free_net_req_rsp_queues(qdev);\nerr_req_rsp:\n\tdma_free_coherent(&qdev->pdev->dev, PAGE_SIZE,\n\t\t\t  qdev->shadow_reg_virt_addr,\n\t\t\t  qdev->shadow_reg_phy_addr);\n\n\treturn -ENOMEM;\n}\n\nstatic void ql_free_mem_resources(struct ql3_adapter *qdev)\n{\n\tql_free_send_free_list(qdev);\n\tql_free_large_buffers(qdev);\n\tql_free_small_buffers(qdev);\n\tql_free_buffer_queues(qdev);\n\tql_free_net_req_rsp_queues(qdev);\n\tif (qdev->shadow_reg_virt_addr != NULL) {\n\t\tdma_free_coherent(&qdev->pdev->dev, PAGE_SIZE,\n\t\t\t\t  qdev->shadow_reg_virt_addr,\n\t\t\t\t  qdev->shadow_reg_phy_addr);\n\t\tqdev->shadow_reg_virt_addr = NULL;\n\t}\n}\n\nstatic int ql_init_misc_registers(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_local_ram_registers __iomem *local_ram =\n\t    (void __iomem *)qdev->mem_map_registers;\n\n\tif (ql_sem_spinlock(qdev, QL_DDR_RAM_SEM_MASK,\n\t\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index) *\n\t\t\t 2) << 4))\n\t\treturn -1;\n\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->bufletSize, qdev->nvram_data.bufletSize);\n\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->maxBufletCount,\n\t\t\t   qdev->nvram_data.bufletCount);\n\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->freeBufletThresholdLow,\n\t\t\t   (qdev->nvram_data.tcpWindowThreshold25 << 16) |\n\t\t\t   (qdev->nvram_data.tcpWindowThreshold0));\n\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->freeBufletThresholdHigh,\n\t\t\t   qdev->nvram_data.tcpWindowThreshold50);\n\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->ipHashTableBase,\n\t\t\t   (qdev->nvram_data.ipHashTableBaseHi << 16) |\n\t\t\t   qdev->nvram_data.ipHashTableBaseLo);\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->ipHashTableCount,\n\t\t\t   qdev->nvram_data.ipHashTableSize);\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->tcpHashTableBase,\n\t\t\t   (qdev->nvram_data.tcpHashTableBaseHi << 16) |\n\t\t\t   qdev->nvram_data.tcpHashTableBaseLo);\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->tcpHashTableCount,\n\t\t\t   qdev->nvram_data.tcpHashTableSize);\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->ncbBase,\n\t\t\t   (qdev->nvram_data.ncbTableBaseHi << 16) |\n\t\t\t   qdev->nvram_data.ncbTableBaseLo);\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->maxNcbCount,\n\t\t\t   qdev->nvram_data.ncbTableSize);\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->drbBase,\n\t\t\t   (qdev->nvram_data.drbTableBaseHi << 16) |\n\t\t\t   qdev->nvram_data.drbTableBaseLo);\n\tql_write_page2_reg(qdev,\n\t\t\t   &local_ram->maxDrbCount,\n\t\t\t   qdev->nvram_data.drbTableSize);\n\tql_sem_unlock(qdev, QL_DDR_RAM_SEM_MASK);\n\treturn 0;\n}\n\nstatic int ql_adapter_initialize(struct ql3_adapter *qdev)\n{\n\tu32 value;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\t__iomem u32 *spir = &port_regs->CommonRegs.serialPortInterfaceReg;\n\tstruct ql3xxx_host_memory_registers __iomem *hmem_regs =\n\t\t(void __iomem *)port_regs;\n\tu32 delay = 10;\n\tint status = 0;\n\n\tif (ql_mii_setup(qdev))\n\t\treturn -1;\n\n\t \n\tql_write_common_reg(qdev, spir,\n\t\t\t    (ISP_SERIAL_PORT_IF_WE |\n\t\t\t     (ISP_SERIAL_PORT_IF_WE << 16)));\n\t \n\tmdelay(100);\n\tqdev->port_link_state = LS_DOWN;\n\tnetif_carrier_off(qdev->ndev);\n\n\t \n\tql_write_common_reg(qdev, spir,\n\t\t\t    (ISP_SERIAL_PORT_IF_SDE |\n\t\t\t     (ISP_SERIAL_PORT_IF_SDE << 16)));\n\n\t \n\t*((u32 *)(qdev->preq_consumer_index)) = 0;\n\tatomic_set(&qdev->tx_count, NUM_REQ_Q_ENTRIES);\n\tqdev->req_producer_index = 0;\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->reqConsumerIndexAddrHigh,\n\t\t\t   qdev->req_consumer_index_phy_addr_high);\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->reqConsumerIndexAddrLow,\n\t\t\t   qdev->req_consumer_index_phy_addr_low);\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->reqBaseAddrHigh,\n\t\t\t   MS_64BITS(qdev->req_q_phy_addr));\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->reqBaseAddrLow,\n\t\t\t   LS_64BITS(qdev->req_q_phy_addr));\n\tql_write_page1_reg(qdev, &hmem_regs->reqLength, NUM_REQ_Q_ENTRIES);\n\n\t \n\t*((__le16 *) (qdev->prsp_producer_index)) = 0;\n\tqdev->rsp_consumer_index = 0;\n\tqdev->rsp_current = qdev->rsp_q_virt_addr;\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rspProducerIndexAddrHigh,\n\t\t\t   qdev->rsp_producer_index_phy_addr_high);\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rspProducerIndexAddrLow,\n\t\t\t   qdev->rsp_producer_index_phy_addr_low);\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rspBaseAddrHigh,\n\t\t\t   MS_64BITS(qdev->rsp_q_phy_addr));\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rspBaseAddrLow,\n\t\t\t   LS_64BITS(qdev->rsp_q_phy_addr));\n\n\tql_write_page1_reg(qdev, &hmem_regs->rspLength, NUM_RSP_Q_ENTRIES);\n\n\t \n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rxLargeQBaseAddrHigh,\n\t\t\t   MS_64BITS(qdev->lrg_buf_q_phy_addr));\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rxLargeQBaseAddrLow,\n\t\t\t   LS_64BITS(qdev->lrg_buf_q_phy_addr));\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rxLargeQLength,\n\t\t\t   qdev->num_lbufq_entries);\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rxLargeBufferLength,\n\t\t\t   qdev->lrg_buffer_len);\n\n\t \n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rxSmallQBaseAddrHigh,\n\t\t\t   MS_64BITS(qdev->small_buf_q_phy_addr));\n\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rxSmallQBaseAddrLow,\n\t\t\t   LS_64BITS(qdev->small_buf_q_phy_addr));\n\n\tql_write_page1_reg(qdev, &hmem_regs->rxSmallQLength, NUM_SBUFQ_ENTRIES);\n\tql_write_page1_reg(qdev,\n\t\t\t   &hmem_regs->rxSmallBufferLength,\n\t\t\t   QL_SMALL_BUFFER_SIZE);\n\n\tqdev->small_buf_q_producer_index = NUM_SBUFQ_ENTRIES - 1;\n\tqdev->small_buf_release_cnt = 8;\n\tqdev->lrg_buf_q_producer_index = qdev->num_lbufq_entries - 1;\n\tqdev->lrg_buf_release_cnt = 8;\n\tqdev->lrg_buf_next_free = qdev->lrg_buf_q_virt_addr;\n\tqdev->small_buf_index = 0;\n\tqdev->lrg_buf_index = 0;\n\tqdev->lrg_buf_free_count = 0;\n\tqdev->lrg_buf_free_head = NULL;\n\tqdev->lrg_buf_free_tail = NULL;\n\n\tql_write_common_reg(qdev,\n\t\t\t    &port_regs->CommonRegs.\n\t\t\t    rxSmallQProducerIndex,\n\t\t\t    qdev->small_buf_q_producer_index);\n\tql_write_common_reg(qdev,\n\t\t\t    &port_regs->CommonRegs.\n\t\t\t    rxLargeQProducerIndex,\n\t\t\t    qdev->lrg_buf_q_producer_index);\n\n\t \n\tclear_bit(QL_LINK_MASTER, &qdev->flags);\n\tvalue = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\tif ((value & PORT_STATUS_IC) == 0) {\n\n\t\t \n\t\tif (ql_init_misc_registers(qdev)) {\n\t\t\tstatus = -1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tvalue = qdev->nvram_data.tcpMaxWindowSize;\n\t\tql_write_page0_reg(qdev, &port_regs->tcpMaxWindow, value);\n\n\t\tvalue = (0xFFFF << 16) | qdev->nvram_data.extHwConfig;\n\n\t\tif (ql_sem_spinlock(qdev, QL_FLASH_SEM_MASK,\n\t\t\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index)\n\t\t\t\t * 2) << 13)) {\n\t\t\tstatus = -1;\n\t\t\tgoto out;\n\t\t}\n\t\tql_write_page0_reg(qdev, &port_regs->ExternalHWConfig, value);\n\t\tql_write_page0_reg(qdev, &port_regs->InternalChipConfig,\n\t\t\t\t   (((INTERNAL_CHIP_SD | INTERNAL_CHIP_WE) <<\n\t\t\t\t     16) | (INTERNAL_CHIP_SD |\n\t\t\t\t\t    INTERNAL_CHIP_WE)));\n\t\tql_sem_unlock(qdev, QL_FLASH_SEM_MASK);\n\t}\n\n\tif (qdev->mac_index)\n\t\tql_write_page0_reg(qdev,\n\t\t\t\t   &port_regs->mac1MaxFrameLengthReg,\n\t\t\t\t   qdev->max_frame_size);\n\telse\n\t\tql_write_page0_reg(qdev,\n\t\t\t\t\t   &port_regs->mac0MaxFrameLengthReg,\n\t\t\t\t\t   qdev->max_frame_size);\n\n\tif (ql_sem_spinlock(qdev, QL_PHY_GIO_SEM_MASK,\n\t\t\t(QL_RESOURCE_BITS_BASE_CODE | (qdev->mac_index) *\n\t\t\t 2) << 7)) {\n\t\tstatus = -1;\n\t\tgoto out;\n\t}\n\n\tPHY_Setup(qdev);\n\tql_init_scan_mode(qdev);\n\tql_get_phy_owner(qdev);\n\n\t \n\n\t \n\tql_write_page0_reg(qdev, &port_regs->macAddrIndirectPtrReg,\n\t\t\t   (MAC_ADDR_INDIRECT_PTR_REG_RP_MASK << 16));\n\tql_write_page0_reg(qdev, &port_regs->macAddrDataReg,\n\t\t\t   ((qdev->ndev->dev_addr[2] << 24)\n\t\t\t    | (qdev->ndev->dev_addr[3] << 16)\n\t\t\t    | (qdev->ndev->dev_addr[4] << 8)\n\t\t\t    | qdev->ndev->dev_addr[5]));\n\n\t \n\tql_write_page0_reg(qdev, &port_regs->macAddrIndirectPtrReg,\n\t\t\t   ((MAC_ADDR_INDIRECT_PTR_REG_RP_MASK << 16) | 1));\n\tql_write_page0_reg(qdev, &port_regs->macAddrDataReg,\n\t\t\t   ((qdev->ndev->dev_addr[0] << 8)\n\t\t\t    | qdev->ndev->dev_addr[1]));\n\n\t \n\tql_write_page0_reg(qdev, &port_regs->macAddrIndirectPtrReg,\n\t\t\t   ((MAC_ADDR_INDIRECT_PTR_REG_PE << 16) |\n\t\t\t    MAC_ADDR_INDIRECT_PTR_REG_PE));\n\n\t \n\tql_write_page0_reg(qdev, &port_regs->ipAddrIndexReg,\n\t\t\t   ((IP_ADDR_INDEX_REG_MASK << 16) |\n\t\t\t    (qdev->mac_index << 2)));\n\tql_write_page0_reg(qdev, &port_regs->ipAddrDataReg, 0);\n\n\tql_write_page0_reg(qdev, &port_regs->ipAddrIndexReg,\n\t\t\t   ((IP_ADDR_INDEX_REG_MASK << 16) |\n\t\t\t    ((qdev->mac_index << 2) + 1)));\n\tql_write_page0_reg(qdev, &port_regs->ipAddrDataReg, 0);\n\n\tql_sem_unlock(qdev, QL_PHY_GIO_SEM_MASK);\n\n\t \n\tql_write_page0_reg(qdev,\n\t\t\t   &port_regs->portControl,\n\t\t\t   ((PORT_CONTROL_CC << 16) | PORT_CONTROL_CC));\n\n\tdo {\n\t\tvalue = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\t\tif (value & PORT_STATUS_IC)\n\t\t\tbreak;\n\t\tspin_unlock_irq(&qdev->hw_lock);\n\t\tmsleep(500);\n\t\tspin_lock_irq(&qdev->hw_lock);\n\t} while (--delay);\n\n\tif (delay == 0) {\n\t\tnetdev_err(qdev->ndev, \"Hw Initialization timeout\\n\");\n\t\tstatus = -1;\n\t\tgoto out;\n\t}\n\n\t \n\tif (qdev->device_id == QL3032_DEVICE_ID) {\n\t\tvalue =\n\t\t    (QL3032_PORT_CONTROL_EF | QL3032_PORT_CONTROL_KIE |\n\t\t     QL3032_PORT_CONTROL_EIv6 | QL3032_PORT_CONTROL_EIv4 |\n\t\t\tQL3032_PORT_CONTROL_ET);\n\t\tql_write_page0_reg(qdev, &port_regs->functionControl,\n\t\t\t\t   ((value << 16) | value));\n\t} else {\n\t\tvalue =\n\t\t    (PORT_CONTROL_EF | PORT_CONTROL_ET | PORT_CONTROL_EI |\n\t\t     PORT_CONTROL_HH);\n\t\tql_write_page0_reg(qdev, &port_regs->portControl,\n\t\t\t\t   ((value << 16) | value));\n\t}\n\n\nout:\n\treturn status;\n}\n\n \nstatic int ql_adapter_reset(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tint status = 0;\n\tu16 value;\n\tint max_wait_time;\n\n\tset_bit(QL_RESET_ACTIVE, &qdev->flags);\n\tclear_bit(QL_RESET_DONE, &qdev->flags);\n\n\t \n\tnetdev_printk(KERN_DEBUG, qdev->ndev, \"Issue soft reset to chip\\n\");\n\tql_write_common_reg(qdev,\n\t\t\t    &port_regs->CommonRegs.ispControlStatus,\n\t\t\t    ((ISP_CONTROL_SR << 16) | ISP_CONTROL_SR));\n\n\t \n\tnetdev_printk(KERN_DEBUG, qdev->ndev,\n\t\t      \"Wait 10 milliseconds for reset to complete\\n\");\n\n\t \n\tmax_wait_time = 5;\n\tdo {\n\t\tvalue =\n\t\t    ql_read_common_reg(qdev,\n\t\t\t\t       &port_regs->CommonRegs.ispControlStatus);\n\t\tif ((value & ISP_CONTROL_SR) == 0)\n\t\t\tbreak;\n\n\t\tmdelay(1000);\n\t} while ((--max_wait_time));\n\n\t \n\tvalue =\n\t    ql_read_common_reg(qdev, &port_regs->CommonRegs.ispControlStatus);\n\tif (value & ISP_CONTROL_RI) {\n\t\tnetdev_printk(KERN_DEBUG, qdev->ndev,\n\t\t\t      \"clearing RI after reset\\n\");\n\t\tql_write_common_reg(qdev,\n\t\t\t\t    &port_regs->CommonRegs.\n\t\t\t\t    ispControlStatus,\n\t\t\t\t    ((ISP_CONTROL_RI << 16) | ISP_CONTROL_RI));\n\t}\n\n\tif (max_wait_time == 0) {\n\t\t \n\t\tql_write_common_reg(qdev,\n\t\t\t\t    &port_regs->CommonRegs.\n\t\t\t\t    ispControlStatus,\n\t\t\t\t    ((ISP_CONTROL_FSR << 16) |\n\t\t\t\t     ISP_CONTROL_FSR));\n\t\t \n\t\tmax_wait_time = 5;\n\t\tdo {\n\t\t\tvalue = ql_read_common_reg(qdev,\n\t\t\t\t\t\t   &port_regs->CommonRegs.\n\t\t\t\t\t\t   ispControlStatus);\n\t\t\tif ((value & ISP_CONTROL_FSR) == 0)\n\t\t\t\tbreak;\n\t\t\tmdelay(1000);\n\t\t} while ((--max_wait_time));\n\t}\n\tif (max_wait_time == 0)\n\t\tstatus = 1;\n\n\tclear_bit(QL_RESET_ACTIVE, &qdev->flags);\n\tset_bit(QL_RESET_DONE, &qdev->flags);\n\treturn status;\n}\n\nstatic void ql_set_mac_info(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tu32 value, port_status;\n\tu8 func_number;\n\n\t \n\tvalue =\n\t    ql_read_common_reg_l(qdev, &port_regs->CommonRegs.ispControlStatus);\n\tfunc_number = (u8) ((value >> 4) & OPCODE_FUNC_ID_MASK);\n\tport_status = ql_read_page0_reg(qdev, &port_regs->portStatus);\n\tswitch (value & ISP_CONTROL_FN_MASK) {\n\tcase ISP_CONTROL_FN0_NET:\n\t\tqdev->mac_index = 0;\n\t\tqdev->mac_ob_opcode = OUTBOUND_MAC_IOCB | func_number;\n\t\tqdev->mb_bit_mask = FN0_MA_BITS_MASK;\n\t\tqdev->PHYAddr = PORT0_PHY_ADDRESS;\n\t\tif (port_status & PORT_STATUS_SM0)\n\t\t\tset_bit(QL_LINK_OPTICAL, &qdev->flags);\n\t\telse\n\t\t\tclear_bit(QL_LINK_OPTICAL, &qdev->flags);\n\t\tbreak;\n\n\tcase ISP_CONTROL_FN1_NET:\n\t\tqdev->mac_index = 1;\n\t\tqdev->mac_ob_opcode = OUTBOUND_MAC_IOCB | func_number;\n\t\tqdev->mb_bit_mask = FN1_MA_BITS_MASK;\n\t\tqdev->PHYAddr = PORT1_PHY_ADDRESS;\n\t\tif (port_status & PORT_STATUS_SM1)\n\t\t\tset_bit(QL_LINK_OPTICAL, &qdev->flags);\n\t\telse\n\t\t\tclear_bit(QL_LINK_OPTICAL, &qdev->flags);\n\t\tbreak;\n\n\tcase ISP_CONTROL_FN0_SCSI:\n\tcase ISP_CONTROL_FN1_SCSI:\n\tdefault:\n\t\tnetdev_printk(KERN_DEBUG, qdev->ndev,\n\t\t\t      \"Invalid function number, ispControlStatus = 0x%x\\n\",\n\t\t\t      value);\n\t\tbreak;\n\t}\n\tqdev->numPorts = qdev->nvram_data.version_and_numPorts >> 8;\n}\n\nstatic void ql_display_dev_info(struct net_device *ndev)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tstruct pci_dev *pdev = qdev->pdev;\n\n\tnetdev_info(ndev,\n\t\t    \"%s Adapter %d RevisionID %d found %s on PCI slot %d\\n\",\n\t\t    DRV_NAME, qdev->index, qdev->chip_rev_id,\n\t\t    qdev->device_id == QL3032_DEVICE_ID ? \"QLA3032\" : \"QLA3022\",\n\t\t    qdev->pci_slot);\n\tnetdev_info(ndev, \"%s Interface\\n\",\n\t\ttest_bit(QL_LINK_OPTICAL, &qdev->flags) ? \"OPTICAL\" : \"COPPER\");\n\n\t \n\tnetdev_info(ndev, \"Bus interface is %s %s\\n\",\n\t\t    ((qdev->pci_width == 64) ? \"64-bit\" : \"32-bit\"),\n\t\t    ((qdev->pci_x) ? \"PCI-X\" : \"PCI\"));\n\n\tnetdev_info(ndev, \"mem  IO base address adjusted = 0x%p\\n\",\n\t\t    qdev->mem_map_registers);\n\tnetdev_info(ndev, \"Interrupt number = %d\\n\", pdev->irq);\n\n\tnetif_info(qdev, probe, ndev, \"MAC address %pM\\n\", ndev->dev_addr);\n}\n\nstatic int ql_adapter_down(struct ql3_adapter *qdev, int do_reset)\n{\n\tstruct net_device *ndev = qdev->ndev;\n\tint retval = 0;\n\n\tnetif_stop_queue(ndev);\n\tnetif_carrier_off(ndev);\n\n\tclear_bit(QL_ADAPTER_UP, &qdev->flags);\n\tclear_bit(QL_LINK_MASTER, &qdev->flags);\n\n\tql_disable_interrupts(qdev);\n\n\tfree_irq(qdev->pdev->irq, ndev);\n\n\tif (qdev->msi && test_bit(QL_MSI_ENABLED, &qdev->flags)) {\n\t\tnetdev_info(qdev->ndev, \"calling pci_disable_msi()\\n\");\n\t\tclear_bit(QL_MSI_ENABLED, &qdev->flags);\n\t\tpci_disable_msi(qdev->pdev);\n\t}\n\n\tdel_timer_sync(&qdev->adapter_timer);\n\n\tnapi_disable(&qdev->napi);\n\n\tif (do_reset) {\n\t\tint soft_reset;\n\t\tunsigned long hw_flags;\n\n\t\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\t\tif (ql_wait_for_drvr_lock(qdev)) {\n\t\t\tsoft_reset = ql_adapter_reset(qdev);\n\t\t\tif (soft_reset) {\n\t\t\t\tnetdev_err(ndev, \"ql_adapter_reset(%d) FAILED!\\n\",\n\t\t\t\t\t   qdev->index);\n\t\t\t}\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"Releasing driver lock via chip reset\\n\");\n\t\t} else {\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"Could not acquire driver lock to do reset!\\n\");\n\t\t\tretval = -1;\n\t\t}\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\t}\n\tql_free_mem_resources(qdev);\n\treturn retval;\n}\n\nstatic int ql_adapter_up(struct ql3_adapter *qdev)\n{\n\tstruct net_device *ndev = qdev->ndev;\n\tint err;\n\tunsigned long irq_flags = IRQF_SHARED;\n\tunsigned long hw_flags;\n\n\tif (ql_alloc_mem_resources(qdev)) {\n\t\tnetdev_err(ndev, \"Unable to  allocate buffers\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (qdev->msi) {\n\t\tif (pci_enable_msi(qdev->pdev)) {\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"User requested MSI, but MSI failed to initialize.  Continuing without MSI.\\n\");\n\t\t\tqdev->msi = 0;\n\t\t} else {\n\t\t\tnetdev_info(ndev, \"MSI Enabled...\\n\");\n\t\t\tset_bit(QL_MSI_ENABLED, &qdev->flags);\n\t\t\tirq_flags &= ~IRQF_SHARED;\n\t\t}\n\t}\n\n\terr = request_irq(qdev->pdev->irq, ql3xxx_isr,\n\t\t\t  irq_flags, ndev->name, ndev);\n\tif (err) {\n\t\tnetdev_err(ndev,\n\t\t\t   \"Failed to reserve interrupt %d - already in use\\n\",\n\t\t\t   qdev->pdev->irq);\n\t\tgoto err_irq;\n\t}\n\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\n\tif (!ql_wait_for_drvr_lock(qdev)) {\n\t\tnetdev_err(ndev, \"Could not acquire driver lock\\n\");\n\t\terr = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\n\terr = ql_adapter_initialize(qdev);\n\tif (err) {\n\t\tnetdev_err(ndev, \"Unable to initialize adapter\\n\");\n\t\tgoto err_init;\n\t}\n\tql_sem_unlock(qdev, QL_DRVR_SEM_MASK);\n\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\n\tset_bit(QL_ADAPTER_UP, &qdev->flags);\n\n\tmod_timer(&qdev->adapter_timer, jiffies + HZ * 1);\n\n\tnapi_enable(&qdev->napi);\n\tql_enable_interrupts(qdev);\n\treturn 0;\n\nerr_init:\n\tql_sem_unlock(qdev, QL_DRVR_SEM_MASK);\nerr_lock:\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\tfree_irq(qdev->pdev->irq, ndev);\nerr_irq:\n\tif (qdev->msi && test_bit(QL_MSI_ENABLED, &qdev->flags)) {\n\t\tnetdev_info(ndev, \"calling pci_disable_msi()\\n\");\n\t\tclear_bit(QL_MSI_ENABLED, &qdev->flags);\n\t\tpci_disable_msi(qdev->pdev);\n\t}\n\treturn err;\n}\n\nstatic int ql_cycle_adapter(struct ql3_adapter *qdev, int reset)\n{\n\tif (ql_adapter_down(qdev, reset) || ql_adapter_up(qdev)) {\n\t\tnetdev_err(qdev->ndev,\n\t\t\t   \"Driver up/down cycle failed, closing device\\n\");\n\t\trtnl_lock();\n\t\tdev_close(qdev->ndev);\n\t\trtnl_unlock();\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\nstatic int ql3xxx_close(struct net_device *ndev)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\n\t \n\twhile (!test_bit(QL_ADAPTER_UP, &qdev->flags))\n\t\tmsleep(50);\n\n\tql_adapter_down(qdev, QL_DO_RESET);\n\treturn 0;\n}\n\nstatic int ql3xxx_open(struct net_device *ndev)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\treturn ql_adapter_up(qdev);\n}\n\nstatic int ql3xxx_set_mac_address(struct net_device *ndev, void *p)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\t\tqdev->mem_map_registers;\n\tstruct sockaddr *addr = p;\n\tunsigned long hw_flags;\n\n\tif (netif_running(ndev))\n\t\treturn -EBUSY;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(ndev, addr->sa_data);\n\n\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\t \n\tql_write_page0_reg(qdev, &port_regs->macAddrIndirectPtrReg,\n\t\t\t   (MAC_ADDR_INDIRECT_PTR_REG_RP_MASK << 16));\n\tql_write_page0_reg(qdev, &port_regs->macAddrDataReg,\n\t\t\t   ((ndev->dev_addr[2] << 24) | (ndev->\n\t\t\t\t\t\t\t dev_addr[3] << 16) |\n\t\t\t    (ndev->dev_addr[4] << 8) | ndev->dev_addr[5]));\n\n\t \n\tql_write_page0_reg(qdev, &port_regs->macAddrIndirectPtrReg,\n\t\t\t   ((MAC_ADDR_INDIRECT_PTR_REG_RP_MASK << 16) | 1));\n\tql_write_page0_reg(qdev, &port_regs->macAddrDataReg,\n\t\t\t   ((ndev->dev_addr[0] << 8) | ndev->dev_addr[1]));\n\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\n\treturn 0;\n}\n\nstatic void ql3xxx_tx_timeout(struct net_device *ndev, unsigned int txqueue)\n{\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\n\tnetdev_err(ndev, \"Resetting...\\n\");\n\t \n\tnetif_stop_queue(ndev);\n\n\t \n\tqueue_delayed_work(qdev->workqueue, &qdev->tx_timeout_work, 0);\n}\n\nstatic void ql_reset_work(struct work_struct *work)\n{\n\tstruct ql3_adapter *qdev =\n\t\tcontainer_of(work, struct ql3_adapter, reset_work.work);\n\tstruct net_device *ndev = qdev->ndev;\n\tu32 value;\n\tstruct ql_tx_buf_cb *tx_cb;\n\tint max_wait_time, i;\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tunsigned long hw_flags;\n\n\tif (test_bit(QL_RESET_PER_SCSI, &qdev->flags) ||\n\t    test_bit(QL_RESET_START, &qdev->flags)) {\n\t\tclear_bit(QL_LINK_MASTER, &qdev->flags);\n\n\t\t \n\t\tfor (i = 0; i < NUM_REQ_Q_ENTRIES; i++) {\n\t\t\tint j;\n\t\t\ttx_cb = &qdev->tx_buf[i];\n\t\t\tif (tx_cb->skb) {\n\t\t\t\tnetdev_printk(KERN_DEBUG, ndev,\n\t\t\t\t\t      \"Freeing lost SKB\\n\");\n\t\t\t\tdma_unmap_single(&qdev->pdev->dev,\n\t\t\t\t\t\t dma_unmap_addr(&tx_cb->map[0], mapaddr),\n\t\t\t\t\t\t dma_unmap_len(&tx_cb->map[0], maplen),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\t\tfor (j = 1; j < tx_cb->seg_count; j++) {\n\t\t\t\t\tdma_unmap_page(&qdev->pdev->dev,\n\t\t\t\t\t\t       dma_unmap_addr(&tx_cb->map[j], mapaddr),\n\t\t\t\t\t\t       dma_unmap_len(&tx_cb->map[j], maplen),\n\t\t\t\t\t\t       DMA_TO_DEVICE);\n\t\t\t\t}\n\t\t\t\tdev_kfree_skb(tx_cb->skb);\n\t\t\t\ttx_cb->skb = NULL;\n\t\t\t}\n\t\t}\n\n\t\tnetdev_err(ndev, \"Clearing NRI after reset\\n\");\n\t\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\t\tql_write_common_reg(qdev,\n\t\t\t\t    &port_regs->CommonRegs.\n\t\t\t\t    ispControlStatus,\n\t\t\t\t    ((ISP_CONTROL_RI << 16) | ISP_CONTROL_RI));\n\t\t \n\t\tmax_wait_time = 10;\n\t\tdo {\n\t\t\tvalue = ql_read_common_reg(qdev,\n\t\t\t\t\t\t   &port_regs->CommonRegs.\n\n\t\t\t\t\t\t   ispControlStatus);\n\t\t\tif ((value & ISP_CONTROL_SR) == 0) {\n\t\t\t\tnetdev_printk(KERN_DEBUG, ndev,\n\t\t\t\t\t      \"reset completed\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (value & ISP_CONTROL_RI) {\n\t\t\t\tnetdev_printk(KERN_DEBUG, ndev,\n\t\t\t\t\t      \"clearing NRI after reset\\n\");\n\t\t\t\tql_write_common_reg(qdev,\n\t\t\t\t\t\t    &port_regs->\n\t\t\t\t\t\t    CommonRegs.\n\t\t\t\t\t\t    ispControlStatus,\n\t\t\t\t\t\t    ((ISP_CONTROL_RI <<\n\t\t\t\t\t\t      16) | ISP_CONTROL_RI));\n\t\t\t}\n\n\t\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\t\t\tssleep(1);\n\t\t\tspin_lock_irqsave(&qdev->hw_lock, hw_flags);\n\t\t} while (--max_wait_time);\n\t\tspin_unlock_irqrestore(&qdev->hw_lock, hw_flags);\n\n\t\tif (value & ISP_CONTROL_SR) {\n\n\t\t\t \n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"Timed out waiting for reset to complete\\n\");\n\t\t\tnetdev_err(ndev, \"Do a reset\\n\");\n\t\t\tclear_bit(QL_RESET_PER_SCSI, &qdev->flags);\n\t\t\tclear_bit(QL_RESET_START, &qdev->flags);\n\t\t\tql_cycle_adapter(qdev, QL_DO_RESET);\n\t\t\treturn;\n\t\t}\n\n\t\tclear_bit(QL_RESET_ACTIVE, &qdev->flags);\n\t\tclear_bit(QL_RESET_PER_SCSI, &qdev->flags);\n\t\tclear_bit(QL_RESET_START, &qdev->flags);\n\t\tql_cycle_adapter(qdev, QL_NO_RESET);\n\t}\n}\n\nstatic void ql_tx_timeout_work(struct work_struct *work)\n{\n\tstruct ql3_adapter *qdev =\n\t\tcontainer_of(work, struct ql3_adapter, tx_timeout_work.work);\n\n\tql_cycle_adapter(qdev, QL_DO_RESET);\n}\n\nstatic void ql_get_board_info(struct ql3_adapter *qdev)\n{\n\tstruct ql3xxx_port_registers __iomem *port_regs =\n\t\tqdev->mem_map_registers;\n\tu32 value;\n\n\tvalue = ql_read_page0_reg_l(qdev, &port_regs->portStatus);\n\n\tqdev->chip_rev_id = ((value & PORT_STATUS_REV_ID_MASK) >> 12);\n\tif (value & PORT_STATUS_64)\n\t\tqdev->pci_width = 64;\n\telse\n\t\tqdev->pci_width = 32;\n\tif (value & PORT_STATUS_X)\n\t\tqdev->pci_x = 1;\n\telse\n\t\tqdev->pci_x = 0;\n\tqdev->pci_slot = (u8) PCI_SLOT(qdev->pdev->devfn);\n}\n\nstatic void ql3xxx_timer(struct timer_list *t)\n{\n\tstruct ql3_adapter *qdev = from_timer(qdev, t, adapter_timer);\n\tqueue_delayed_work(qdev->workqueue, &qdev->link_state_work, 0);\n}\n\nstatic const struct net_device_ops ql3xxx_netdev_ops = {\n\t.ndo_open\t\t= ql3xxx_open,\n\t.ndo_start_xmit\t\t= ql3xxx_send,\n\t.ndo_stop\t\t= ql3xxx_close,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= ql3xxx_set_mac_address,\n\t.ndo_tx_timeout\t\t= ql3xxx_tx_timeout,\n};\n\nstatic int ql3xxx_probe(struct pci_dev *pdev,\n\t\t\tconst struct pci_device_id *pci_entry)\n{\n\tstruct net_device *ndev = NULL;\n\tstruct ql3_adapter *qdev = NULL;\n\tstatic int cards_found;\n\tint err;\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tpr_err(\"%s cannot enable PCI device\\n\", pci_name(pdev));\n\t\tgoto err_out;\n\t}\n\n\terr = pci_request_regions(pdev, DRV_NAME);\n\tif (err) {\n\t\tpr_err(\"%s cannot obtain PCI resources\\n\", pci_name(pdev));\n\t\tgoto err_out_disable_pdev;\n\t}\n\n\tpci_set_master(pdev);\n\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\tpr_err(\"%s no usable DMA configuration\\n\", pci_name(pdev));\n\t\tgoto err_out_free_regions;\n\t}\n\n\tndev = alloc_etherdev(sizeof(struct ql3_adapter));\n\tif (!ndev) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out_free_regions;\n\t}\n\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\n\tpci_set_drvdata(pdev, ndev);\n\n\tqdev = netdev_priv(ndev);\n\tqdev->index = cards_found;\n\tqdev->ndev = ndev;\n\tqdev->pdev = pdev;\n\tqdev->device_id = pci_entry->device;\n\tqdev->port_link_state = LS_DOWN;\n\tif (msi)\n\t\tqdev->msi = 1;\n\n\tqdev->msg_enable = netif_msg_init(debug, default_msg);\n\n\tndev->features |= NETIF_F_HIGHDMA;\n\tif (qdev->device_id == QL3032_DEVICE_ID)\n\t\tndev->features |= NETIF_F_IP_CSUM | NETIF_F_SG;\n\n\tqdev->mem_map_registers = pci_ioremap_bar(pdev, 1);\n\tif (!qdev->mem_map_registers) {\n\t\tpr_err(\"%s: cannot map device registers\\n\", pci_name(pdev));\n\t\terr = -EIO;\n\t\tgoto err_out_free_ndev;\n\t}\n\n\tspin_lock_init(&qdev->adapter_lock);\n\tspin_lock_init(&qdev->hw_lock);\n\n\t \n\tndev->netdev_ops = &ql3xxx_netdev_ops;\n\tndev->ethtool_ops = &ql3xxx_ethtool_ops;\n\tndev->watchdog_timeo = 5 * HZ;\n\n\tnetif_napi_add(ndev, &qdev->napi, ql_poll);\n\n\tndev->irq = pdev->irq;\n\n\t \n\tif (ql_get_nvram_params(qdev)) {\n\t\tpr_alert(\"%s: Adapter #%d, Invalid NVRAM parameters\\n\",\n\t\t\t __func__, qdev->index);\n\t\terr = -EIO;\n\t\tgoto err_out_iounmap;\n\t}\n\n\tql_set_mac_info(qdev);\n\n\t \n\tif (qdev->mac_index) {\n\t\tndev->mtu = qdev->nvram_data.macCfg_port1.etherMtu_mac ;\n\t\tql_set_mac_addr(ndev, qdev->nvram_data.funcCfg_fn2.macAddress);\n\t} else {\n\t\tndev->mtu = qdev->nvram_data.macCfg_port0.etherMtu_mac ;\n\t\tql_set_mac_addr(ndev, qdev->nvram_data.funcCfg_fn0.macAddress);\n\t}\n\n\tndev->tx_queue_len = NUM_REQ_Q_ENTRIES;\n\n\t \n\tql_get_board_info(qdev);\n\n\t \n\tif (qdev->pci_x)\n\t\tpci_write_config_word(pdev, (int)0x4e, (u16) 0x0036);\n\n\terr = register_netdev(ndev);\n\tif (err) {\n\t\tpr_err(\"%s: cannot register net device\\n\", pci_name(pdev));\n\t\tgoto err_out_iounmap;\n\t}\n\n\t \n\n\tnetif_carrier_off(ndev);\n\tnetif_stop_queue(ndev);\n\n\tqdev->workqueue = create_singlethread_workqueue(ndev->name);\n\tif (!qdev->workqueue) {\n\t\tunregister_netdev(ndev);\n\t\terr = -ENOMEM;\n\t\tgoto err_out_iounmap;\n\t}\n\n\tINIT_DELAYED_WORK(&qdev->reset_work, ql_reset_work);\n\tINIT_DELAYED_WORK(&qdev->tx_timeout_work, ql_tx_timeout_work);\n\tINIT_DELAYED_WORK(&qdev->link_state_work, ql_link_state_machine_work);\n\n\ttimer_setup(&qdev->adapter_timer, ql3xxx_timer, 0);\n\tqdev->adapter_timer.expires = jiffies + HZ * 2;\t \n\n\tif (!cards_found) {\n\t\tpr_alert(\"%s\\n\", DRV_STRING);\n\t\tpr_alert(\"Driver name: %s, Version: %s\\n\",\n\t\t\t DRV_NAME, DRV_VERSION);\n\t}\n\tql_display_dev_info(ndev);\n\n\tcards_found++;\n\treturn 0;\n\nerr_out_iounmap:\n\tiounmap(qdev->mem_map_registers);\nerr_out_free_ndev:\n\tfree_netdev(ndev);\nerr_out_free_regions:\n\tpci_release_regions(pdev);\nerr_out_disable_pdev:\n\tpci_disable_device(pdev);\nerr_out:\n\treturn err;\n}\n\nstatic void ql3xxx_remove(struct pci_dev *pdev)\n{\n\tstruct net_device *ndev = pci_get_drvdata(pdev);\n\tstruct ql3_adapter *qdev = netdev_priv(ndev);\n\n\tunregister_netdev(ndev);\n\n\tql_disable_interrupts(qdev);\n\n\tif (qdev->workqueue) {\n\t\tcancel_delayed_work(&qdev->reset_work);\n\t\tcancel_delayed_work(&qdev->tx_timeout_work);\n\t\tdestroy_workqueue(qdev->workqueue);\n\t\tqdev->workqueue = NULL;\n\t}\n\n\tiounmap(qdev->mem_map_registers);\n\tpci_release_regions(pdev);\n\tfree_netdev(ndev);\n}\n\nstatic struct pci_driver ql3xxx_driver = {\n\n\t.name = DRV_NAME,\n\t.id_table = ql3xxx_pci_tbl,\n\t.probe = ql3xxx_probe,\n\t.remove = ql3xxx_remove,\n};\n\nmodule_pci_driver(ql3xxx_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}