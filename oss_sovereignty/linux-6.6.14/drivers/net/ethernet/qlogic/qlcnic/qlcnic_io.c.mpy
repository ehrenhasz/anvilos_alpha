{
  "module_name": "qlcnic_io.c",
  "hash_id": "a2063362622a70501bb7dd5c4bf88c7e6fdf06f770ca21b284cac7c6a807aef7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c",
  "human_readable_source": "\n \n\n#include <linux/netdevice.h>\n#include <linux/if_vlan.h>\n#include <net/ip.h>\n#include <linux/ipv6.h>\n#include <net/checksum.h>\n#include <linux/printk.h>\n#include <linux/jiffies.h>\n\n#include \"qlcnic.h\"\n\n#define QLCNIC_TX_ETHER_PKT\t\t0x01\n#define QLCNIC_TX_TCP_PKT\t\t0x02\n#define QLCNIC_TX_UDP_PKT\t\t0x03\n#define QLCNIC_TX_IP_PKT\t\t0x04\n#define QLCNIC_TX_TCP_LSO\t\t0x05\n#define QLCNIC_TX_TCP_LSO6\t\t0x06\n#define QLCNIC_TX_ENCAP_PKT\t\t0x07\n#define QLCNIC_TX_ENCAP_LSO\t\t0x08\n#define QLCNIC_TX_TCPV6_PKT\t\t0x0b\n#define QLCNIC_TX_UDPV6_PKT\t\t0x0c\n\n#define QLCNIC_FLAGS_VLAN_TAGGED\t0x10\n#define QLCNIC_FLAGS_VLAN_OOB\t\t0x40\n\n#define qlcnic_set_tx_vlan_tci(cmd_desc, v)\t\\\n\t(cmd_desc)->vlan_TCI = cpu_to_le16(v);\n#define qlcnic_set_cmd_desc_port(cmd_desc, var)\t\\\n\t((cmd_desc)->port_ctxid |= ((var) & 0x0F))\n#define qlcnic_set_cmd_desc_ctxid(cmd_desc, var)\t\\\n\t((cmd_desc)->port_ctxid |= ((var) << 4 & 0xF0))\n\n#define qlcnic_set_tx_port(_desc, _port) \\\n\t((_desc)->port_ctxid = ((_port) & 0xf) | (((_port) << 4) & 0xf0))\n\n#define qlcnic_set_tx_flags_opcode(_desc, _flags, _opcode) \\\n\t((_desc)->flags_opcode |= \\\n\tcpu_to_le16(((_flags) & 0x7f) | (((_opcode) & 0x3f) << 7)))\n\n#define qlcnic_set_tx_frags_len(_desc, _frags, _len) \\\n\t((_desc)->nfrags__length = \\\n\tcpu_to_le32(((_frags) & 0xff) | (((_len) & 0xffffff) << 8)))\n\n \n#define STATUS_OWNER_HOST\t(0x1ULL << 56)\n#define STATUS_OWNER_PHANTOM\t(0x2ULL << 56)\n\n \n#define qlcnic_get_sts_port(sts_data)\t\\\n\t((sts_data) & 0x0F)\n#define qlcnic_get_sts_status(sts_data)\t\\\n\t(((sts_data) >> 4) & 0x0F)\n#define qlcnic_get_sts_type(sts_data)\t\\\n\t(((sts_data) >> 8) & 0x0F)\n#define qlcnic_get_sts_totallength(sts_data)\t\\\n\t(((sts_data) >> 12) & 0xFFFF)\n#define qlcnic_get_sts_refhandle(sts_data)\t\\\n\t(((sts_data) >> 28) & 0xFFFF)\n#define qlcnic_get_sts_prot(sts_data)\t\\\n\t(((sts_data) >> 44) & 0x0F)\n#define qlcnic_get_sts_pkt_offset(sts_data)\t\\\n\t(((sts_data) >> 48) & 0x1F)\n#define qlcnic_get_sts_desc_cnt(sts_data)\t\\\n\t(((sts_data) >> 53) & 0x7)\n#define qlcnic_get_sts_opcode(sts_data)\t\\\n\t(((sts_data) >> 58) & 0x03F)\n\n#define qlcnic_get_lro_sts_refhandle(sts_data) \t\\\n\t((sts_data) & 0x07FFF)\n#define qlcnic_get_lro_sts_length(sts_data)\t\\\n\t(((sts_data) >> 16) & 0x0FFFF)\n#define qlcnic_get_lro_sts_l2_hdr_offset(sts_data)\t\\\n\t(((sts_data) >> 32) & 0x0FF)\n#define qlcnic_get_lro_sts_l4_hdr_offset(sts_data)\t\\\n\t(((sts_data) >> 40) & 0x0FF)\n#define qlcnic_get_lro_sts_timestamp(sts_data)\t\\\n\t(((sts_data) >> 48) & 0x1)\n#define qlcnic_get_lro_sts_type(sts_data)\t\\\n\t(((sts_data) >> 49) & 0x7)\n#define qlcnic_get_lro_sts_push_flag(sts_data)\t\t\\\n\t(((sts_data) >> 52) & 0x1)\n#define qlcnic_get_lro_sts_seq_number(sts_data)\t\t\\\n\t((sts_data) & 0x0FFFFFFFF)\n#define qlcnic_get_lro_sts_mss(sts_data1)\t\t\\\n\t((sts_data1 >> 32) & 0x0FFFF)\n\n#define qlcnic_83xx_get_lro_sts_mss(sts) ((sts) & 0xffff)\n\n \n#define QLCNIC_SYN_OFFLOAD\t0x03\n#define QLCNIC_RXPKT_DESC  \t0x04\n#define QLCNIC_OLD_RXPKT_DESC\t0x3f\n#define QLCNIC_RESPONSE_DESC\t0x05\n#define QLCNIC_LRO_DESC  \t0x12\n\n#define QLCNIC_TCP_HDR_SIZE\t\t20\n#define QLCNIC_TCP_TS_OPTION_SIZE\t12\n#define QLCNIC_FETCH_RING_ID(handle)\t((handle) >> 63)\n#define QLCNIC_DESC_OWNER_FW\t\tcpu_to_le64(STATUS_OWNER_PHANTOM)\n\n#define QLCNIC_TCP_TS_HDR_SIZE (QLCNIC_TCP_HDR_SIZE + QLCNIC_TCP_TS_OPTION_SIZE)\n\n \n#define STATUS_CKSUM_LOOP\t0\n#define STATUS_CKSUM_OK\t\t2\n\n#define qlcnic_83xx_pktln(sts)\t\t((sts >> 32) & 0x3FFF)\n#define qlcnic_83xx_hndl(sts)\t\t((sts >> 48) & 0x7FFF)\n#define qlcnic_83xx_csum_status(sts)\t((sts >> 39) & 7)\n#define qlcnic_83xx_opcode(sts)\t((sts >> 42) & 0xF)\n#define qlcnic_83xx_vlan_tag(sts)\t(((sts) >> 48) & 0xFFFF)\n#define qlcnic_83xx_lro_pktln(sts)\t(((sts) >> 32) & 0x3FFF)\n#define qlcnic_83xx_l2_hdr_off(sts)\t(((sts) >> 16) & 0xFF)\n#define qlcnic_83xx_l4_hdr_off(sts)\t(((sts) >> 24) & 0xFF)\n#define qlcnic_83xx_pkt_cnt(sts)\t(((sts) >> 16) & 0x7)\n#define qlcnic_83xx_is_tstamp(sts)\t(((sts) >> 40) & 1)\n#define qlcnic_83xx_is_psh_bit(sts)\t(((sts) >> 41) & 1)\n#define qlcnic_83xx_is_ip_align(sts)\t(((sts) >> 46) & 1)\n#define qlcnic_83xx_has_vlan_tag(sts)\t(((sts) >> 47) & 1)\n\nstatic int qlcnic_process_rcv_ring(struct qlcnic_host_sds_ring *sds_ring,\n\t\t\t\t   int max);\n\nstatic struct sk_buff *qlcnic_process_rxbuf(struct qlcnic_adapter *,\n\t\t\t\t\t    struct qlcnic_host_rds_ring *,\n\t\t\t\t\t    u16, u16);\n\nstatic inline u8 qlcnic_mac_hash(u64 mac, u16 vlan)\n{\n\treturn (u8)((mac & 0xff) ^ ((mac >> 40) & 0xff) ^ (vlan & 0xff));\n}\n\nstatic inline u32 qlcnic_get_ref_handle(struct qlcnic_adapter *adapter,\n\t\t\t\t\tu16 handle, u8 ring_id)\n{\n\tif (qlcnic_83xx_check(adapter))\n\t\treturn handle | (ring_id << 15);\n\telse\n\t\treturn handle;\n}\n\nstatic inline int qlcnic_82xx_is_lb_pkt(u64 sts_data)\n{\n\treturn (qlcnic_get_sts_status(sts_data) == STATUS_CKSUM_LOOP) ? 1 : 0;\n}\n\nstatic void qlcnic_delete_rx_list_mac(struct qlcnic_adapter *adapter,\n\t\t\t\t      struct qlcnic_filter *fil,\n\t\t\t\t      void *addr, u16 vlan_id)\n{\n\tint ret;\n\tu8 op;\n\n\top = vlan_id ? QLCNIC_MAC_VLAN_ADD : QLCNIC_MAC_ADD;\n\tret = qlcnic_sre_macaddr_change(adapter, addr, vlan_id, op);\n\tif (ret)\n\t\treturn;\n\n\top = vlan_id ? QLCNIC_MAC_VLAN_DEL : QLCNIC_MAC_DEL;\n\tret = qlcnic_sre_macaddr_change(adapter, addr, vlan_id, op);\n\tif (!ret) {\n\t\thlist_del(&fil->fnode);\n\t\tadapter->rx_fhash.fnum--;\n\t}\n}\n\nstatic struct qlcnic_filter *qlcnic_find_mac_filter(struct hlist_head *head,\n\t\t\t\t\t\t    void *addr, u16 vlan_id)\n{\n\tstruct qlcnic_filter *tmp_fil = NULL;\n\tstruct hlist_node *n;\n\n\thlist_for_each_entry_safe(tmp_fil, n, head, fnode) {\n\t\tif (ether_addr_equal(tmp_fil->faddr, addr) &&\n\t\t    tmp_fil->vlan_id == vlan_id)\n\t\t\treturn tmp_fil;\n\t}\n\n\treturn NULL;\n}\n\nstatic void qlcnic_add_lb_filter(struct qlcnic_adapter *adapter,\n\t\t\t\t struct sk_buff *skb, int loopback_pkt, u16 vlan_id)\n{\n\tstruct ethhdr *phdr = (struct ethhdr *)(skb->data);\n\tstruct qlcnic_filter *fil, *tmp_fil;\n\tstruct hlist_head *head;\n\tunsigned long time;\n\tu64 src_addr = 0;\n\tu8 hindex, op;\n\tint ret;\n\n\tif (!qlcnic_sriov_pf_check(adapter) || (vlan_id == 0xffff))\n\t\tvlan_id = 0;\n\n\tmemcpy(&src_addr, phdr->h_source, ETH_ALEN);\n\thindex = qlcnic_mac_hash(src_addr, vlan_id) &\n\t\t (adapter->fhash.fbucket_size - 1);\n\n\tif (loopback_pkt) {\n\t\tif (adapter->rx_fhash.fnum >= adapter->rx_fhash.fmax)\n\t\t\treturn;\n\n\t\thead = &(adapter->rx_fhash.fhead[hindex]);\n\n\t\ttmp_fil = qlcnic_find_mac_filter(head, &src_addr, vlan_id);\n\t\tif (tmp_fil) {\n\t\t\ttime = tmp_fil->ftime;\n\t\t\tif (time_after(jiffies, QLCNIC_READD_AGE * HZ + time))\n\t\t\t\ttmp_fil->ftime = jiffies;\n\t\t\treturn;\n\t\t}\n\n\t\tfil = kzalloc(sizeof(struct qlcnic_filter), GFP_ATOMIC);\n\t\tif (!fil)\n\t\t\treturn;\n\n\t\tfil->ftime = jiffies;\n\t\tmemcpy(fil->faddr, &src_addr, ETH_ALEN);\n\t\tfil->vlan_id = vlan_id;\n\t\tspin_lock(&adapter->rx_mac_learn_lock);\n\t\thlist_add_head(&(fil->fnode), head);\n\t\tadapter->rx_fhash.fnum++;\n\t\tspin_unlock(&adapter->rx_mac_learn_lock);\n\t} else {\n\t\thead = &adapter->fhash.fhead[hindex];\n\n\t\tspin_lock(&adapter->mac_learn_lock);\n\n\t\ttmp_fil = qlcnic_find_mac_filter(head, &src_addr, vlan_id);\n\t\tif (tmp_fil) {\n\t\t\top = vlan_id ? QLCNIC_MAC_VLAN_DEL : QLCNIC_MAC_DEL;\n\t\t\tret = qlcnic_sre_macaddr_change(adapter,\n\t\t\t\t\t\t\t(u8 *)&src_addr,\n\t\t\t\t\t\t\tvlan_id, op);\n\t\t\tif (!ret) {\n\t\t\t\thlist_del(&tmp_fil->fnode);\n\t\t\t\tadapter->fhash.fnum--;\n\t\t\t}\n\n\t\t\tspin_unlock(&adapter->mac_learn_lock);\n\n\t\t\treturn;\n\t\t}\n\n\t\tspin_unlock(&adapter->mac_learn_lock);\n\n\t\thead = &adapter->rx_fhash.fhead[hindex];\n\n\t\tspin_lock(&adapter->rx_mac_learn_lock);\n\n\t\ttmp_fil = qlcnic_find_mac_filter(head, &src_addr, vlan_id);\n\t\tif (tmp_fil)\n\t\t\tqlcnic_delete_rx_list_mac(adapter, tmp_fil, &src_addr,\n\t\t\t\t\t\t  vlan_id);\n\n\t\tspin_unlock(&adapter->rx_mac_learn_lock);\n\t}\n}\n\nvoid qlcnic_82xx_change_filter(struct qlcnic_adapter *adapter, u64 *uaddr,\n\t\t\t       u16 vlan_id, struct qlcnic_host_tx_ring *tx_ring)\n{\n\tstruct cmd_desc_type0 *hwdesc;\n\tstruct qlcnic_nic_req *req;\n\tstruct qlcnic_mac_req *mac_req;\n\tstruct qlcnic_vlan_req *vlan_req;\n\tu32 producer;\n\tu64 word;\n\n\tproducer = tx_ring->producer;\n\thwdesc = &tx_ring->desc_head[tx_ring->producer];\n\n\treq = (struct qlcnic_nic_req *)hwdesc;\n\tmemset(req, 0, sizeof(struct qlcnic_nic_req));\n\treq->qhdr = cpu_to_le64(QLCNIC_REQUEST << 23);\n\n\tword = QLCNIC_MAC_EVENT | ((u64)(adapter->portnum) << 16);\n\treq->req_hdr = cpu_to_le64(word);\n\n\tmac_req = (struct qlcnic_mac_req *)&(req->words[0]);\n\tmac_req->op = vlan_id ? QLCNIC_MAC_VLAN_ADD : QLCNIC_MAC_ADD;\n\tmemcpy(mac_req->mac_addr, uaddr, ETH_ALEN);\n\n\tvlan_req = (struct qlcnic_vlan_req *)&req->words[1];\n\tvlan_req->vlan_id = cpu_to_le16(vlan_id);\n\n\ttx_ring->producer = get_next_index(producer, tx_ring->num_desc);\n\tsmp_mb();\n}\n\nstatic void qlcnic_send_filter(struct qlcnic_adapter *adapter,\n\t\t\t       struct cmd_desc_type0 *first_desc,\n\t\t\t       struct sk_buff *skb,\n\t\t\t       struct qlcnic_host_tx_ring *tx_ring)\n{\n\tstruct vlan_ethhdr *vh = (struct vlan_ethhdr *)(skb->data);\n\tstruct ethhdr *phdr = (struct ethhdr *)(skb->data);\n\tu16 protocol = ntohs(skb->protocol);\n\tstruct qlcnic_filter *fil, *tmp_fil;\n\tstruct hlist_head *head;\n\tstruct hlist_node *n;\n\tu64 src_addr = 0;\n\tu16 vlan_id = 0;\n\tu8 hindex, hval;\n\n\tif (ether_addr_equal(phdr->h_source, adapter->mac_addr))\n\t\treturn;\n\n\tif (adapter->flags & QLCNIC_VLAN_FILTERING) {\n\t\tif (protocol == ETH_P_8021Q) {\n\t\t\tvh = skb_vlan_eth_hdr(skb);\n\t\t\tvlan_id = ntohs(vh->h_vlan_TCI);\n\t\t} else if (skb_vlan_tag_present(skb)) {\n\t\t\tvlan_id = skb_vlan_tag_get(skb);\n\t\t}\n\t}\n\n\tmemcpy(&src_addr, phdr->h_source, ETH_ALEN);\n\thval = qlcnic_mac_hash(src_addr, vlan_id);\n\thindex = hval & (adapter->fhash.fbucket_size - 1);\n\thead = &(adapter->fhash.fhead[hindex]);\n\n\thlist_for_each_entry_safe(tmp_fil, n, head, fnode) {\n\t\tif (ether_addr_equal(tmp_fil->faddr, (u8 *)&src_addr) &&\n\t\t    tmp_fil->vlan_id == vlan_id) {\n\t\t\tif (time_is_before_jiffies(QLCNIC_READD_AGE * HZ + tmp_fil->ftime))\n\t\t\t\tqlcnic_change_filter(adapter, &src_addr,\n\t\t\t\t\t\t     vlan_id, tx_ring);\n\t\t\ttmp_fil->ftime = jiffies;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (unlikely(adapter->fhash.fnum >= adapter->fhash.fmax)) {\n\t\tadapter->stats.mac_filter_limit_overrun++;\n\t\treturn;\n\t}\n\n\tfil = kzalloc(sizeof(struct qlcnic_filter), GFP_ATOMIC);\n\tif (!fil)\n\t\treturn;\n\n\tqlcnic_change_filter(adapter, &src_addr, vlan_id, tx_ring);\n\tfil->ftime = jiffies;\n\tfil->vlan_id = vlan_id;\n\tmemcpy(fil->faddr, &src_addr, ETH_ALEN);\n\tspin_lock(&adapter->mac_learn_lock);\n\thlist_add_head(&(fil->fnode), head);\n\tadapter->fhash.fnum++;\n\tspin_unlock(&adapter->mac_learn_lock);\n}\n\n#define QLCNIC_ENCAP_VXLAN_PKT\t\tBIT_0\n#define QLCNIC_ENCAP_OUTER_L3_IP6\tBIT_1\n#define QLCNIC_ENCAP_INNER_L3_IP6\tBIT_2\n#define QLCNIC_ENCAP_INNER_L4_UDP\tBIT_3\n#define QLCNIC_ENCAP_DO_L3_CSUM\t\tBIT_4\n#define QLCNIC_ENCAP_DO_L4_CSUM\t\tBIT_5\n\nstatic int qlcnic_tx_encap_pkt(struct qlcnic_adapter *adapter,\n\t\t\t       struct cmd_desc_type0 *first_desc,\n\t\t\t       struct sk_buff *skb,\n\t\t\t       struct qlcnic_host_tx_ring *tx_ring)\n{\n\tu8 opcode = 0, inner_hdr_len = 0, outer_hdr_len = 0, total_hdr_len = 0;\n\tint copied, copy_len, descr_size;\n\tu32 producer = tx_ring->producer;\n\tstruct cmd_desc_type0 *hwdesc;\n\tu16 flags = 0, encap_descr = 0;\n\n\topcode = QLCNIC_TX_ETHER_PKT;\n\tencap_descr = QLCNIC_ENCAP_VXLAN_PKT;\n\n\tif (skb_is_gso(skb)) {\n\t\tinner_hdr_len = skb_inner_transport_header(skb) +\n\t\t\t\tinner_tcp_hdrlen(skb) -\n\t\t\t\tskb_inner_mac_header(skb);\n\n\t\t \n\t\touter_hdr_len = skb_transport_offset(skb) + 8 +\n\t\t\t\tsizeof(struct udphdr);\n\t\tfirst_desc->outer_hdr_length = outer_hdr_len;\n\t\ttotal_hdr_len = inner_hdr_len + outer_hdr_len;\n\t\tencap_descr |= QLCNIC_ENCAP_DO_L3_CSUM |\n\t\t\t       QLCNIC_ENCAP_DO_L4_CSUM;\n\t\tfirst_desc->mss = cpu_to_le16(skb_shinfo(skb)->gso_size);\n\t\tfirst_desc->hdr_length = inner_hdr_len;\n\n\t\t \n\t\tcopied = 0;\n\t\tdescr_size = (int)sizeof(struct cmd_desc_type0);\n\t\twhile (copied < total_hdr_len) {\n\t\t\tcopy_len = min(descr_size, (total_hdr_len - copied));\n\t\t\thwdesc = &tx_ring->desc_head[producer];\n\t\t\ttx_ring->cmd_buf_arr[producer].skb = NULL;\n\t\t\tskb_copy_from_linear_data_offset(skb, copied,\n\t\t\t\t\t\t\t (char *)hwdesc,\n\t\t\t\t\t\t\t copy_len);\n\t\t\tcopied += copy_len;\n\t\t\tproducer = get_next_index(producer, tx_ring->num_desc);\n\t\t}\n\n\t\ttx_ring->producer = producer;\n\n\t\t \n\t\tsmp_mb();\n\t\tadapter->stats.encap_lso_frames++;\n\n\t\topcode = QLCNIC_TX_ENCAP_LSO;\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tif (inner_ip_hdr(skb)->version == 6) {\n\t\t\tif (inner_ipv6_hdr(skb)->nexthdr == IPPROTO_UDP)\n\t\t\t\tencap_descr |= QLCNIC_ENCAP_INNER_L4_UDP;\n\t\t} else {\n\t\t\tif (inner_ip_hdr(skb)->protocol == IPPROTO_UDP)\n\t\t\t\tencap_descr |= QLCNIC_ENCAP_INNER_L4_UDP;\n\t\t}\n\n\t\tadapter->stats.encap_tx_csummed++;\n\t\topcode = QLCNIC_TX_ENCAP_PKT;\n\t}\n\n\t \n\tif (ip_hdr(skb)->version == 6)\n\t\tencap_descr |= QLCNIC_ENCAP_OUTER_L3_IP6;\n\n\t \n\tencap_descr |= (skb_network_header_len(skb) >> 2) << 6;\n\n\t \n\tencap_descr |= skb_network_offset(skb) << 10;\n\tfirst_desc->encap_descr = cpu_to_le16(encap_descr);\n\n\tfirst_desc->tcp_hdr_offset = skb_inner_transport_header(skb) -\n\t\t\t\t     skb->data;\n\tfirst_desc->ip_hdr_offset = skb_inner_network_offset(skb);\n\n\tqlcnic_set_tx_flags_opcode(first_desc, flags, opcode);\n\n\treturn 0;\n}\n\nstatic int qlcnic_tx_pkt(struct qlcnic_adapter *adapter,\n\t\t\t struct cmd_desc_type0 *first_desc, struct sk_buff *skb,\n\t\t\t struct qlcnic_host_tx_ring *tx_ring)\n{\n\tu8 l4proto, opcode = 0, hdr_len = 0, tag_vlan = 0;\n\tu16 flags = 0, vlan_tci = 0;\n\tint copied, offset, copy_len, size;\n\tstruct cmd_desc_type0 *hwdesc;\n\tstruct vlan_ethhdr *vh;\n\tu16 protocol = ntohs(skb->protocol);\n\tu32 producer = tx_ring->producer;\n\n\tif (protocol == ETH_P_8021Q) {\n\t\tvh = skb_vlan_eth_hdr(skb);\n\t\tflags = QLCNIC_FLAGS_VLAN_TAGGED;\n\t\tvlan_tci = ntohs(vh->h_vlan_TCI);\n\t\tprotocol = ntohs(vh->h_vlan_encapsulated_proto);\n\t\ttag_vlan = 1;\n\t} else if (skb_vlan_tag_present(skb)) {\n\t\tflags = QLCNIC_FLAGS_VLAN_OOB;\n\t\tvlan_tci = skb_vlan_tag_get(skb);\n\t\ttag_vlan = 1;\n\t}\n\tif (unlikely(adapter->tx_pvid)) {\n\t\tif (tag_vlan && !(adapter->flags & QLCNIC_TAGGING_ENABLED))\n\t\t\treturn -EIO;\n\t\tif (tag_vlan && (adapter->flags & QLCNIC_TAGGING_ENABLED))\n\t\t\tgoto set_flags;\n\n\t\tflags = QLCNIC_FLAGS_VLAN_OOB;\n\t\tvlan_tci = adapter->tx_pvid;\n\t}\nset_flags:\n\tqlcnic_set_tx_vlan_tci(first_desc, vlan_tci);\n\tqlcnic_set_tx_flags_opcode(first_desc, flags, opcode);\n\n\tif (*(skb->data) & BIT_0) {\n\t\tflags |= BIT_0;\n\t\tmemcpy(&first_desc->eth_addr, skb->data, ETH_ALEN);\n\t}\n\topcode = QLCNIC_TX_ETHER_PKT;\n\tif (skb_is_gso(skb)) {\n\t\thdr_len = skb_tcp_all_headers(skb);\n\t\tfirst_desc->mss = cpu_to_le16(skb_shinfo(skb)->gso_size);\n\t\tfirst_desc->hdr_length = hdr_len;\n\t\topcode = (protocol == ETH_P_IPV6) ? QLCNIC_TX_TCP_LSO6 :\n\t\t\t\t\t\t    QLCNIC_TX_TCP_LSO;\n\n\t\t \n\t\tcopied = 0;\n\t\toffset = 2;\n\n\t\tif (flags & QLCNIC_FLAGS_VLAN_OOB) {\n\t\t\tfirst_desc->hdr_length += VLAN_HLEN;\n\t\t\tfirst_desc->tcp_hdr_offset = VLAN_HLEN;\n\t\t\tfirst_desc->ip_hdr_offset = VLAN_HLEN;\n\n\t\t\t \n\t\t\tflags |= QLCNIC_FLAGS_VLAN_TAGGED;\n\n\t\t\t \n\t\t\thwdesc = &tx_ring->desc_head[producer];\n\t\t\ttx_ring->cmd_buf_arr[producer].skb = NULL;\n\n\t\t\tcopy_len = min((int)sizeof(struct cmd_desc_type0) -\n\t\t\t\t       offset, hdr_len + VLAN_HLEN);\n\n\t\t\tvh = (struct vlan_ethhdr *)((char *) hwdesc + 2);\n\t\t\tskb_copy_from_linear_data(skb, vh, 12);\n\t\t\tvh->h_vlan_proto = htons(ETH_P_8021Q);\n\t\t\tvh->h_vlan_TCI = htons(vlan_tci);\n\n\t\t\tskb_copy_from_linear_data_offset(skb, 12,\n\t\t\t\t\t\t\t (char *)vh + 16,\n\t\t\t\t\t\t\t copy_len - 16);\n\t\t\tcopied = copy_len - VLAN_HLEN;\n\t\t\toffset = 0;\n\t\t\tproducer = get_next_index(producer, tx_ring->num_desc);\n\t\t}\n\n\t\twhile (copied < hdr_len) {\n\t\t\tsize = (int)sizeof(struct cmd_desc_type0) - offset;\n\t\t\tcopy_len = min(size, (hdr_len - copied));\n\t\t\thwdesc = &tx_ring->desc_head[producer];\n\t\t\ttx_ring->cmd_buf_arr[producer].skb = NULL;\n\t\t\tskb_copy_from_linear_data_offset(skb, copied,\n\t\t\t\t\t\t\t (char *)hwdesc +\n\t\t\t\t\t\t\t offset, copy_len);\n\t\t\tcopied += copy_len;\n\t\t\toffset = 0;\n\t\t\tproducer = get_next_index(producer, tx_ring->num_desc);\n\t\t}\n\n\t\ttx_ring->producer = producer;\n\t\tsmp_mb();\n\t\tadapter->stats.lso_frames++;\n\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tif (protocol == ETH_P_IP) {\n\t\t\tl4proto = ip_hdr(skb)->protocol;\n\n\t\t\tif (l4proto == IPPROTO_TCP)\n\t\t\t\topcode = QLCNIC_TX_TCP_PKT;\n\t\t\telse if (l4proto == IPPROTO_UDP)\n\t\t\t\topcode = QLCNIC_TX_UDP_PKT;\n\t\t} else if (protocol == ETH_P_IPV6) {\n\t\t\tl4proto = ipv6_hdr(skb)->nexthdr;\n\n\t\t\tif (l4proto == IPPROTO_TCP)\n\t\t\t\topcode = QLCNIC_TX_TCPV6_PKT;\n\t\t\telse if (l4proto == IPPROTO_UDP)\n\t\t\t\topcode = QLCNIC_TX_UDPV6_PKT;\n\t\t}\n\t}\n\tfirst_desc->tcp_hdr_offset += skb_transport_offset(skb);\n\tfirst_desc->ip_hdr_offset += skb_network_offset(skb);\n\tqlcnic_set_tx_flags_opcode(first_desc, flags, opcode);\n\n\treturn 0;\n}\n\nstatic int qlcnic_map_tx_skb(struct pci_dev *pdev, struct sk_buff *skb,\n\t\t\t     struct qlcnic_cmd_buffer *pbuf)\n{\n\tstruct qlcnic_skb_frag *nf;\n\tskb_frag_t *frag;\n\tint i, nr_frags;\n\tdma_addr_t map;\n\n\tnr_frags = skb_shinfo(skb)->nr_frags;\n\tnf = &pbuf->frag_array[0];\n\n\tmap = dma_map_single(&pdev->dev, skb->data, skb_headlen(skb),\n\t\t\t     DMA_TO_DEVICE);\n\tif (dma_mapping_error(&pdev->dev, map))\n\t\tgoto out_err;\n\n\tnf->dma = map;\n\tnf->length = skb_headlen(skb);\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\tfrag = &skb_shinfo(skb)->frags[i];\n\t\tnf = &pbuf->frag_array[i+1];\n\t\tmap = skb_frag_dma_map(&pdev->dev, frag, 0, skb_frag_size(frag),\n\t\t\t\t       DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&pdev->dev, map))\n\t\t\tgoto unwind;\n\n\t\tnf->dma = map;\n\t\tnf->length = skb_frag_size(frag);\n\t}\n\n\treturn 0;\n\nunwind:\n\twhile (--i >= 0) {\n\t\tnf = &pbuf->frag_array[i+1];\n\t\tdma_unmap_page(&pdev->dev, nf->dma, nf->length, DMA_TO_DEVICE);\n\t}\n\n\tnf = &pbuf->frag_array[0];\n\tdma_unmap_single(&pdev->dev, nf->dma, skb_headlen(skb), DMA_TO_DEVICE);\n\nout_err:\n\treturn -ENOMEM;\n}\n\nstatic void qlcnic_unmap_buffers(struct pci_dev *pdev, struct sk_buff *skb,\n\t\t\t\t struct qlcnic_cmd_buffer *pbuf)\n{\n\tstruct qlcnic_skb_frag *nf = &pbuf->frag_array[0];\n\tint i, nr_frags = skb_shinfo(skb)->nr_frags;\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\tnf = &pbuf->frag_array[i+1];\n\t\tdma_unmap_page(&pdev->dev, nf->dma, nf->length, DMA_TO_DEVICE);\n\t}\n\n\tnf = &pbuf->frag_array[0];\n\tdma_unmap_single(&pdev->dev, nf->dma, skb_headlen(skb), DMA_TO_DEVICE);\n\tpbuf->skb = NULL;\n}\n\nstatic inline void qlcnic_clear_cmddesc(u64 *desc)\n{\n\tdesc[0] = 0ULL;\n\tdesc[2] = 0ULL;\n\tdesc[7] = 0ULL;\n}\n\nnetdev_tx_t qlcnic_xmit_frame(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct qlcnic_adapter *adapter = netdev_priv(netdev);\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\tstruct qlcnic_cmd_buffer *pbuf;\n\tstruct qlcnic_skb_frag *buffrag;\n\tstruct cmd_desc_type0 *hwdesc, *first_desc;\n\tstruct pci_dev *pdev;\n\tstruct ethhdr *phdr;\n\tint i, k, frag_count, delta = 0;\n\tu32 producer, num_txd;\n\tu16 protocol;\n\tbool l4_is_udp = false;\n\n\tif (!test_bit(__QLCNIC_DEV_UP, &adapter->state)) {\n\t\tnetif_tx_stop_all_queues(netdev);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tif (adapter->flags & QLCNIC_MACSPOOF) {\n\t\tphdr = (struct ethhdr *)skb->data;\n\t\tif (!ether_addr_equal(phdr->h_source, adapter->mac_addr))\n\t\t\tgoto drop_packet;\n\t}\n\n\ttx_ring = &adapter->tx_ring[skb_get_queue_mapping(skb)];\n\tnum_txd = tx_ring->num_desc;\n\n\tfrag_count = skb_shinfo(skb)->nr_frags + 1;\n\n\t \n\tif (!skb_is_gso(skb) && frag_count > QLCNIC_MAX_FRAGS_PER_TX) {\n\t\tfor (i = 0; i < (frag_count - QLCNIC_MAX_FRAGS_PER_TX); i++)\n\t\t\tdelta += skb_frag_size(&skb_shinfo(skb)->frags[i]);\n\n\t\tif (!__pskb_pull_tail(skb, delta))\n\t\t\tgoto drop_packet;\n\n\t\tfrag_count = 1 + skb_shinfo(skb)->nr_frags;\n\t}\n\n\tif (unlikely(qlcnic_tx_avail(tx_ring) <= TX_STOP_THRESH)) {\n\t\tnetif_tx_stop_queue(tx_ring->txq);\n\t\tif (qlcnic_tx_avail(tx_ring) > TX_STOP_THRESH) {\n\t\t\tnetif_tx_start_queue(tx_ring->txq);\n\t\t} else {\n\t\t\ttx_ring->tx_stats.xmit_off++;\n\t\t\treturn NETDEV_TX_BUSY;\n\t\t}\n\t}\n\n\tproducer = tx_ring->producer;\n\tpbuf = &tx_ring->cmd_buf_arr[producer];\n\tpdev = adapter->pdev;\n\tfirst_desc = &tx_ring->desc_head[producer];\n\thwdesc = &tx_ring->desc_head[producer];\n\tqlcnic_clear_cmddesc((u64 *)hwdesc);\n\n\tif (qlcnic_map_tx_skb(pdev, skb, pbuf)) {\n\t\tadapter->stats.tx_dma_map_error++;\n\t\tgoto drop_packet;\n\t}\n\n\tpbuf->skb = skb;\n\tpbuf->frag_count = frag_count;\n\n\tqlcnic_set_tx_frags_len(first_desc, frag_count, skb->len);\n\tqlcnic_set_tx_port(first_desc, adapter->portnum);\n\n\tfor (i = 0; i < frag_count; i++) {\n\t\tk = i % 4;\n\n\t\tif ((k == 0) && (i > 0)) {\n\t\t\t \n\t\t\tproducer = get_next_index(producer, num_txd);\n\t\t\thwdesc = &tx_ring->desc_head[producer];\n\t\t\tqlcnic_clear_cmddesc((u64 *)hwdesc);\n\t\t\ttx_ring->cmd_buf_arr[producer].skb = NULL;\n\t\t}\n\n\t\tbuffrag = &pbuf->frag_array[i];\n\t\thwdesc->buffer_length[k] = cpu_to_le16(buffrag->length);\n\t\tswitch (k) {\n\t\tcase 0:\n\t\t\thwdesc->addr_buffer1 = cpu_to_le64(buffrag->dma);\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\thwdesc->addr_buffer2 = cpu_to_le64(buffrag->dma);\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\thwdesc->addr_buffer3 = cpu_to_le64(buffrag->dma);\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\thwdesc->addr_buffer4 = cpu_to_le64(buffrag->dma);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\ttx_ring->producer = get_next_index(producer, num_txd);\n\tsmp_mb();\n\n\tprotocol = ntohs(skb->protocol);\n\tif (protocol == ETH_P_IP)\n\t\tl4_is_udp = ip_hdr(skb)->protocol == IPPROTO_UDP;\n\telse if (protocol == ETH_P_IPV6)\n\t\tl4_is_udp = ipv6_hdr(skb)->nexthdr == IPPROTO_UDP;\n\n\t \n\tif (!skb->encapsulation || !l4_is_udp ||\n\t    !qlcnic_encap_tx_offload(adapter)) {\n\t\tif (unlikely(qlcnic_tx_pkt(adapter, first_desc, skb,\n\t\t\t\t\t   tx_ring)))\n\t\t\tgoto unwind_buff;\n\t} else {\n\t\tif (unlikely(qlcnic_tx_encap_pkt(adapter, first_desc,\n\t\t\t\t\t\t skb, tx_ring)))\n\t\t\tgoto unwind_buff;\n\t}\n\n\tif (adapter->drv_mac_learn)\n\t\tqlcnic_send_filter(adapter, first_desc, skb, tx_ring);\n\n\ttx_ring->tx_stats.tx_bytes += skb->len;\n\ttx_ring->tx_stats.xmit_called++;\n\n\t \n\twmb();\n\tqlcnic_update_cmd_producer(tx_ring);\n\n\treturn NETDEV_TX_OK;\n\nunwind_buff:\n\tqlcnic_unmap_buffers(pdev, skb, pbuf);\ndrop_packet:\n\tadapter->stats.txdropped++;\n\tdev_kfree_skb_any(skb);\n\treturn NETDEV_TX_OK;\n}\n\nvoid qlcnic_advert_link_change(struct qlcnic_adapter *adapter, int linkup)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tif (adapter->ahw->linkup && !linkup) {\n\t\tnetdev_info(netdev, \"NIC Link is down\\n\");\n\t\tadapter->ahw->linkup = 0;\n\t\tnetif_carrier_off(netdev);\n\t} else if (!adapter->ahw->linkup && linkup) {\n\t\tadapter->ahw->linkup = 1;\n\n\t\t \n\t\tif (qlcnic_83xx_check(adapter) && adapter->ahw->lb_mode) {\n\t\t\tnetdev_info(netdev, \"NIC Link is up for loopback test\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\tnetdev_info(netdev, \"NIC Link is up\\n\");\n\t\tnetif_carrier_on(netdev);\n\t}\n}\n\nstatic int qlcnic_alloc_rx_skb(struct qlcnic_adapter *adapter,\n\t\t\t       struct qlcnic_host_rds_ring *rds_ring,\n\t\t\t       struct qlcnic_rx_buffer *buffer)\n{\n\tstruct sk_buff *skb;\n\tdma_addr_t dma;\n\tstruct pci_dev *pdev = adapter->pdev;\n\n\tskb = netdev_alloc_skb(adapter->netdev, rds_ring->skb_size);\n\tif (!skb) {\n\t\tadapter->stats.skb_alloc_failure++;\n\t\treturn -ENOMEM;\n\t}\n\n\tskb_reserve(skb, NET_IP_ALIGN);\n\tdma = dma_map_single(&pdev->dev, skb->data, rds_ring->dma_size,\n\t\t\t     DMA_FROM_DEVICE);\n\n\tif (dma_mapping_error(&pdev->dev, dma)) {\n\t\tadapter->stats.rx_dma_map_error++;\n\t\tdev_kfree_skb_any(skb);\n\t\treturn -ENOMEM;\n\t}\n\n\tbuffer->skb = skb;\n\tbuffer->dma = dma;\n\n\treturn 0;\n}\n\nstatic void qlcnic_post_rx_buffers_nodb(struct qlcnic_adapter *adapter,\n\t\t\t\t\tstruct qlcnic_host_rds_ring *rds_ring,\n\t\t\t\t\tu8 ring_id)\n{\n\tstruct rcv_desc *pdesc;\n\tstruct qlcnic_rx_buffer *buffer;\n\tint  count = 0;\n\tuint32_t producer, handle;\n\tstruct list_head *head;\n\n\tif (!spin_trylock(&rds_ring->lock))\n\t\treturn;\n\n\tproducer = rds_ring->producer;\n\thead = &rds_ring->free_list;\n\twhile (!list_empty(head)) {\n\t\tbuffer = list_entry(head->next, struct qlcnic_rx_buffer, list);\n\n\t\tif (!buffer->skb) {\n\t\t\tif (qlcnic_alloc_rx_skb(adapter, rds_ring, buffer))\n\t\t\t\tbreak;\n\t\t}\n\t\tcount++;\n\t\tlist_del(&buffer->list);\n\n\t\t \n\t\tpdesc = &rds_ring->desc_head[producer];\n\t\thandle = qlcnic_get_ref_handle(adapter,\n\t\t\t\t\t       buffer->ref_handle, ring_id);\n\t\tpdesc->reference_handle = cpu_to_le16(handle);\n\t\tpdesc->buffer_length = cpu_to_le32(rds_ring->dma_size);\n\t\tpdesc->addr_buffer = cpu_to_le64(buffer->dma);\n\t\tproducer = get_next_index(producer, rds_ring->num_desc);\n\t}\n\tif (count) {\n\t\trds_ring->producer = producer;\n\t\twritel((producer - 1) & (rds_ring->num_desc - 1),\n\t\t       rds_ring->crb_rcv_producer);\n\t}\n\tspin_unlock(&rds_ring->lock);\n}\n\nstatic int qlcnic_process_cmd_ring(struct qlcnic_adapter *adapter,\n\t\t\t\t   struct qlcnic_host_tx_ring *tx_ring,\n\t\t\t\t   int budget)\n{\n\tu32 sw_consumer, hw_consumer;\n\tint i, done, count = 0;\n\tstruct qlcnic_cmd_buffer *buffer;\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct qlcnic_skb_frag *frag;\n\n\tif (!spin_trylock(&tx_ring->tx_clean_lock))\n\t\treturn 1;\n\n\tsw_consumer = tx_ring->sw_consumer;\n\thw_consumer = le32_to_cpu(*(tx_ring->hw_consumer));\n\n\twhile (sw_consumer != hw_consumer) {\n\t\tbuffer = &tx_ring->cmd_buf_arr[sw_consumer];\n\t\tif (buffer->skb) {\n\t\t\tfrag = &buffer->frag_array[0];\n\t\t\tdma_unmap_single(&pdev->dev, frag->dma, frag->length,\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\tfrag->dma = 0ULL;\n\t\t\tfor (i = 1; i < buffer->frag_count; i++) {\n\t\t\t\tfrag++;\n\t\t\t\tdma_unmap_page(&pdev->dev, frag->dma,\n\t\t\t\t\t       frag->length, DMA_TO_DEVICE);\n\t\t\t\tfrag->dma = 0ULL;\n\t\t\t}\n\t\t\ttx_ring->tx_stats.xmit_finished++;\n\t\t\tdev_kfree_skb_any(buffer->skb);\n\t\t\tbuffer->skb = NULL;\n\t\t}\n\n\t\tsw_consumer = get_next_index(sw_consumer, tx_ring->num_desc);\n\t\tif (++count >= budget)\n\t\t\tbreak;\n\t}\n\n\ttx_ring->sw_consumer = sw_consumer;\n\n\tif (count && netif_running(netdev)) {\n\t\tsmp_mb();\n\t\tif (netif_tx_queue_stopped(tx_ring->txq) &&\n\t\t    netif_carrier_ok(netdev)) {\n\t\t\tif (qlcnic_tx_avail(tx_ring) > TX_STOP_THRESH) {\n\t\t\t\tnetif_tx_wake_queue(tx_ring->txq);\n\t\t\t\ttx_ring->tx_stats.xmit_on++;\n\t\t\t}\n\t\t}\n\t\tadapter->tx_timeo_cnt = 0;\n\t}\n\t \n\thw_consumer = le32_to_cpu(*(tx_ring->hw_consumer));\n\tdone = (sw_consumer == hw_consumer);\n\n\tspin_unlock(&tx_ring->tx_clean_lock);\n\n\treturn done;\n}\n\nstatic int qlcnic_poll(struct napi_struct *napi, int budget)\n{\n\tint tx_complete, work_done;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_adapter *adapter;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\n\tsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\n\tadapter = sds_ring->adapter;\n\ttx_ring = sds_ring->tx_ring;\n\n\ttx_complete = qlcnic_process_cmd_ring(adapter, tx_ring,\n\t\t\t\t\t      budget);\n\twork_done = qlcnic_process_rcv_ring(sds_ring, budget);\n\n\t \n\tif (!tx_complete)\n\t\twork_done = budget;\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(&sds_ring->napi, work_done);\n\t\tif (test_bit(__QLCNIC_DEV_UP, &adapter->state)) {\n\t\t\tqlcnic_enable_sds_intr(adapter, sds_ring);\n\t\t\tqlcnic_enable_tx_intr(adapter, tx_ring);\n\t\t}\n\t}\n\n\treturn work_done;\n}\n\nstatic int qlcnic_tx_poll(struct napi_struct *napi, int budget)\n{\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\tstruct qlcnic_adapter *adapter;\n\tint work_done;\n\n\ttx_ring = container_of(napi, struct qlcnic_host_tx_ring, napi);\n\tadapter = tx_ring->adapter;\n\n\twork_done = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\n\tif (work_done) {\n\t\tnapi_complete(&tx_ring->napi);\n\t\tif (test_bit(__QLCNIC_DEV_UP, &adapter->state))\n\t\t\tqlcnic_enable_tx_intr(adapter, tx_ring);\n\t} else {\n\t\t \n\t\twork_done = budget;\n\t}\n\n\treturn work_done;\n}\n\nstatic int qlcnic_rx_poll(struct napi_struct *napi, int budget)\n{\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_adapter *adapter;\n\tint work_done;\n\n\tsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\n\tadapter = sds_ring->adapter;\n\n\twork_done = qlcnic_process_rcv_ring(sds_ring, budget);\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(&sds_ring->napi, work_done);\n\t\tif (test_bit(__QLCNIC_DEV_UP, &adapter->state))\n\t\t\tqlcnic_enable_sds_intr(adapter, sds_ring);\n\t}\n\n\treturn work_done;\n}\n\nstatic void qlcnic_handle_linkevent(struct qlcnic_adapter *adapter,\n\t\t\t\t    struct qlcnic_fw_msg *msg)\n{\n\tu32 cable_OUI;\n\tu16 cable_len, link_speed;\n\tu8  link_status, module, duplex, autoneg, lb_status = 0;\n\tstruct net_device *netdev = adapter->netdev;\n\n\tadapter->ahw->has_link_events = 1;\n\n\tcable_OUI = msg->body[1] & 0xffffffff;\n\tcable_len = (msg->body[1] >> 32) & 0xffff;\n\tlink_speed = (msg->body[1] >> 48) & 0xffff;\n\n\tlink_status = msg->body[2] & 0xff;\n\tduplex = (msg->body[2] >> 16) & 0xff;\n\tautoneg = (msg->body[2] >> 24) & 0xff;\n\tlb_status = (msg->body[2] >> 32) & 0x3;\n\n\tmodule = (msg->body[2] >> 8) & 0xff;\n\tif (module == LINKEVENT_MODULE_TWINAX_UNSUPPORTED_CABLE)\n\t\tdev_info(&netdev->dev,\n\t\t\t \"unsupported cable: OUI 0x%x, length %d\\n\",\n\t\t\t cable_OUI, cable_len);\n\telse if (module == LINKEVENT_MODULE_TWINAX_UNSUPPORTED_CABLELEN)\n\t\tdev_info(&netdev->dev, \"unsupported cable length %d\\n\",\n\t\t\t cable_len);\n\n\tif (!link_status && (lb_status == QLCNIC_ILB_MODE ||\n\t    lb_status == QLCNIC_ELB_MODE))\n\t\tadapter->ahw->loopback_state |= QLCNIC_LINKEVENT;\n\n\tqlcnic_advert_link_change(adapter, link_status);\n\n\tif (duplex == LINKEVENT_FULL_DUPLEX)\n\t\tadapter->ahw->link_duplex = DUPLEX_FULL;\n\telse\n\t\tadapter->ahw->link_duplex = DUPLEX_HALF;\n\n\tadapter->ahw->module_type = module;\n\tadapter->ahw->link_autoneg = autoneg;\n\n\tif (link_status) {\n\t\tadapter->ahw->link_speed = link_speed;\n\t} else {\n\t\tadapter->ahw->link_speed = SPEED_UNKNOWN;\n\t\tadapter->ahw->link_duplex = DUPLEX_UNKNOWN;\n\t}\n}\n\nstatic void qlcnic_handle_fw_message(int desc_cnt, int index,\n\t\t\t\t     struct qlcnic_host_sds_ring *sds_ring)\n{\n\tstruct qlcnic_fw_msg msg;\n\tstruct status_desc *desc;\n\tstruct qlcnic_adapter *adapter;\n\tstruct device *dev;\n\tint i = 0, opcode, ret;\n\n\twhile (desc_cnt > 0 && i < 8) {\n\t\tdesc = &sds_ring->desc_head[index];\n\t\tmsg.words[i++] = le64_to_cpu(desc->status_desc_data[0]);\n\t\tmsg.words[i++] = le64_to_cpu(desc->status_desc_data[1]);\n\n\t\tindex = get_next_index(index, sds_ring->num_desc);\n\t\tdesc_cnt--;\n\t}\n\n\tadapter = sds_ring->adapter;\n\tdev = &adapter->pdev->dev;\n\topcode = qlcnic_get_nic_msg_opcode(msg.body[0]);\n\n\tswitch (opcode) {\n\tcase QLCNIC_C2H_OPCODE_GET_LINKEVENT_RESPONSE:\n\t\tqlcnic_handle_linkevent(adapter, &msg);\n\t\tbreak;\n\tcase QLCNIC_C2H_OPCODE_CONFIG_LOOPBACK:\n\t\tret = (u32)(msg.body[1]);\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\tadapter->ahw->loopback_state |= QLCNIC_LB_RESPONSE;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tdev_info(dev, \"loopback already in progress\\n\");\n\t\t\tadapter->ahw->diag_cnt = -EINPROGRESS;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdev_info(dev, \"loopback cable is not connected\\n\");\n\t\t\tadapter->ahw->diag_cnt = -ENODEV;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_info(dev,\n\t\t\t\t \"loopback configure request failed, err %x\\n\",\n\t\t\t\t ret);\n\t\t\tadapter->ahw->diag_cnt = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase QLCNIC_C2H_OPCODE_GET_DCB_AEN:\n\t\tqlcnic_dcb_aen_handler(adapter->dcb, (void *)&msg);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic struct sk_buff *qlcnic_process_rxbuf(struct qlcnic_adapter *adapter,\n\t\t\t\t\t    struct qlcnic_host_rds_ring *ring,\n\t\t\t\t\t    u16 index, u16 cksum)\n{\n\tstruct qlcnic_rx_buffer *buffer;\n\tstruct sk_buff *skb;\n\n\tbuffer = &ring->rx_buf_arr[index];\n\tif (unlikely(buffer->skb == NULL)) {\n\t\tWARN_ON(1);\n\t\treturn NULL;\n\t}\n\n\tdma_unmap_single(&adapter->pdev->dev, buffer->dma, ring->dma_size,\n\t\t\t DMA_FROM_DEVICE);\n\n\tskb = buffer->skb;\n\tif (likely((adapter->netdev->features & NETIF_F_RXCSUM) &&\n\t\t   (cksum == STATUS_CKSUM_OK || cksum == STATUS_CKSUM_LOOP))) {\n\t\tadapter->stats.csummed++;\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t} else {\n\t\tskb_checksum_none_assert(skb);\n\t}\n\n\n\tbuffer->skb = NULL;\n\n\treturn skb;\n}\n\nstatic inline int qlcnic_check_rx_tagging(struct qlcnic_adapter *adapter,\n\t\t\t\t\t  struct sk_buff *skb, u16 *vlan_tag)\n{\n\tstruct ethhdr *eth_hdr;\n\n\tif (!__vlan_get_tag(skb, vlan_tag)) {\n\t\teth_hdr = (struct ethhdr *)skb->data;\n\t\tmemmove(skb->data + VLAN_HLEN, eth_hdr, ETH_ALEN * 2);\n\t\tskb_pull(skb, VLAN_HLEN);\n\t}\n\tif (!adapter->rx_pvid)\n\t\treturn 0;\n\n\tif (*vlan_tag == adapter->rx_pvid) {\n\t\t \n\t\t*vlan_tag = 0xffff;\n\t\treturn 0;\n\t}\n\tif (adapter->flags & QLCNIC_TAGGING_ENABLED)\n\t\treturn 0;\n\n\treturn -EINVAL;\n}\n\nstatic struct qlcnic_rx_buffer *\nqlcnic_process_rcv(struct qlcnic_adapter *adapter,\n\t\t   struct qlcnic_host_sds_ring *sds_ring, int ring,\n\t\t   u64 sts_data0)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_rx_buffer *buffer;\n\tstruct sk_buff *skb;\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tint index, length, cksum, pkt_offset, is_lb_pkt;\n\tu16 vid = 0xffff, t_vid;\n\n\tif (unlikely(ring >= adapter->max_rds_rings))\n\t\treturn NULL;\n\n\trds_ring = &recv_ctx->rds_rings[ring];\n\n\tindex = qlcnic_get_sts_refhandle(sts_data0);\n\tif (unlikely(index >= rds_ring->num_desc))\n\t\treturn NULL;\n\n\tbuffer = &rds_ring->rx_buf_arr[index];\n\tlength = qlcnic_get_sts_totallength(sts_data0);\n\tcksum  = qlcnic_get_sts_status(sts_data0);\n\tpkt_offset = qlcnic_get_sts_pkt_offset(sts_data0);\n\n\tskb = qlcnic_process_rxbuf(adapter, rds_ring, index, cksum);\n\tif (!skb)\n\t\treturn buffer;\n\n\tif (adapter->rx_mac_learn) {\n\t\tt_vid = 0;\n\t\tis_lb_pkt = qlcnic_82xx_is_lb_pkt(sts_data0);\n\t\tqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, t_vid);\n\t}\n\n\tif (length > rds_ring->skb_size)\n\t\tskb_put(skb, rds_ring->skb_size);\n\telse\n\t\tskb_put(skb, length);\n\n\tif (pkt_offset)\n\t\tskb_pull(skb, pkt_offset);\n\n\tif (unlikely(qlcnic_check_rx_tagging(adapter, skb, &vid))) {\n\t\tadapter->stats.rxdropped++;\n\t\tdev_kfree_skb(skb);\n\t\treturn buffer;\n\t}\n\n\tskb->protocol = eth_type_trans(skb, netdev);\n\n\tif (vid != 0xffff)\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\n\n\tnapi_gro_receive(&sds_ring->napi, skb);\n\n\tadapter->stats.rx_pkts++;\n\tadapter->stats.rxbytes += length;\n\n\treturn buffer;\n}\n\n#define QLC_TCP_HDR_SIZE            20\n#define QLC_TCP_TS_OPTION_SIZE      12\n#define QLC_TCP_TS_HDR_SIZE         (QLC_TCP_HDR_SIZE + QLC_TCP_TS_OPTION_SIZE)\n\nstatic struct qlcnic_rx_buffer *\nqlcnic_process_lro(struct qlcnic_adapter *adapter,\n\t\t   int ring, u64 sts_data0, u64 sts_data1)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_rx_buffer *buffer;\n\tstruct sk_buff *skb;\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tstruct iphdr *iph;\n\tstruct ipv6hdr *ipv6h;\n\tstruct tcphdr *th;\n\tbool push, timestamp;\n\tint index, l2_hdr_offset, l4_hdr_offset, is_lb_pkt;\n\tu16 lro_length, length, data_offset, t_vid, vid = 0xffff;\n\tu32 seq_number;\n\n\tif (unlikely(ring >= adapter->max_rds_rings))\n\t\treturn NULL;\n\n\trds_ring = &recv_ctx->rds_rings[ring];\n\n\tindex = qlcnic_get_lro_sts_refhandle(sts_data0);\n\tif (unlikely(index >= rds_ring->num_desc))\n\t\treturn NULL;\n\n\tbuffer = &rds_ring->rx_buf_arr[index];\n\n\ttimestamp = qlcnic_get_lro_sts_timestamp(sts_data0);\n\tlro_length = qlcnic_get_lro_sts_length(sts_data0);\n\tl2_hdr_offset = qlcnic_get_lro_sts_l2_hdr_offset(sts_data0);\n\tl4_hdr_offset = qlcnic_get_lro_sts_l4_hdr_offset(sts_data0);\n\tpush = qlcnic_get_lro_sts_push_flag(sts_data0);\n\tseq_number = qlcnic_get_lro_sts_seq_number(sts_data1);\n\n\tskb = qlcnic_process_rxbuf(adapter, rds_ring, index, STATUS_CKSUM_OK);\n\tif (!skb)\n\t\treturn buffer;\n\n\tif (adapter->rx_mac_learn) {\n\t\tt_vid = 0;\n\t\tis_lb_pkt = qlcnic_82xx_is_lb_pkt(sts_data0);\n\t\tqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, t_vid);\n\t}\n\n\tif (timestamp)\n\t\tdata_offset = l4_hdr_offset + QLC_TCP_TS_HDR_SIZE;\n\telse\n\t\tdata_offset = l4_hdr_offset + QLC_TCP_HDR_SIZE;\n\n\tskb_put(skb, lro_length + data_offset);\n\tskb_pull(skb, l2_hdr_offset);\n\n\tif (unlikely(qlcnic_check_rx_tagging(adapter, skb, &vid))) {\n\t\tadapter->stats.rxdropped++;\n\t\tdev_kfree_skb(skb);\n\t\treturn buffer;\n\t}\n\n\tskb->protocol = eth_type_trans(skb, netdev);\n\n\tif (ntohs(skb->protocol) == ETH_P_IPV6) {\n\t\tipv6h = (struct ipv6hdr *)skb->data;\n\t\tth = (struct tcphdr *)(skb->data + sizeof(struct ipv6hdr));\n\t\tlength = (th->doff << 2) + lro_length;\n\t\tipv6h->payload_len = htons(length);\n\t} else {\n\t\tiph = (struct iphdr *)skb->data;\n\t\tth = (struct tcphdr *)(skb->data + (iph->ihl << 2));\n\t\tlength = (iph->ihl << 2) + (th->doff << 2) + lro_length;\n\t\tcsum_replace2(&iph->check, iph->tot_len, htons(length));\n\t\tiph->tot_len = htons(length);\n\t}\n\n\tth->psh = push;\n\tth->seq = htonl(seq_number);\n\tlength = skb->len;\n\n\tif (adapter->flags & QLCNIC_FW_LRO_MSS_CAP) {\n\t\tskb_shinfo(skb)->gso_size = qlcnic_get_lro_sts_mss(sts_data1);\n\t\tif (skb->protocol == htons(ETH_P_IPV6))\n\t\t\tskb_shinfo(skb)->gso_type = SKB_GSO_TCPV6;\n\t\telse\n\t\t\tskb_shinfo(skb)->gso_type = SKB_GSO_TCPV4;\n\t}\n\n\tif (vid != 0xffff)\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\n\tnetif_receive_skb(skb);\n\n\tadapter->stats.lro_pkts++;\n\tadapter->stats.lrobytes += length;\n\n\treturn buffer;\n}\n\nstatic int qlcnic_process_rcv_ring(struct qlcnic_host_sds_ring *sds_ring, int max)\n{\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tstruct qlcnic_adapter *adapter = sds_ring->adapter;\n\tstruct list_head *cur;\n\tstruct status_desc *desc;\n\tstruct qlcnic_rx_buffer *rxbuf;\n\tint opcode, desc_cnt, count = 0;\n\tu64 sts_data0, sts_data1;\n\tu8 ring;\n\tu32 consumer = sds_ring->consumer;\n\n\twhile (count < max) {\n\t\tdesc = &sds_ring->desc_head[consumer];\n\t\tsts_data0 = le64_to_cpu(desc->status_desc_data[0]);\n\n\t\tif (!(sts_data0 & STATUS_OWNER_HOST))\n\t\t\tbreak;\n\n\t\tdesc_cnt = qlcnic_get_sts_desc_cnt(sts_data0);\n\t\topcode = qlcnic_get_sts_opcode(sts_data0);\n\t\tswitch (opcode) {\n\t\tcase QLCNIC_RXPKT_DESC:\n\t\tcase QLCNIC_OLD_RXPKT_DESC:\n\t\tcase QLCNIC_SYN_OFFLOAD:\n\t\t\tring = qlcnic_get_sts_type(sts_data0);\n\t\t\trxbuf = qlcnic_process_rcv(adapter, sds_ring, ring,\n\t\t\t\t\t\t   sts_data0);\n\t\t\tbreak;\n\t\tcase QLCNIC_LRO_DESC:\n\t\t\tring = qlcnic_get_lro_sts_type(sts_data0);\n\t\t\tsts_data1 = le64_to_cpu(desc->status_desc_data[1]);\n\t\t\trxbuf = qlcnic_process_lro(adapter, ring, sts_data0,\n\t\t\t\t\t\t   sts_data1);\n\t\t\tbreak;\n\t\tcase QLCNIC_RESPONSE_DESC:\n\t\t\tqlcnic_handle_fw_message(desc_cnt, consumer, sds_ring);\n\t\t\tgoto skip;\n\t\tdefault:\n\t\t\tgoto skip;\n\t\t}\n\t\tWARN_ON(desc_cnt > 1);\n\n\t\tif (likely(rxbuf))\n\t\t\tlist_add_tail(&rxbuf->list, &sds_ring->free_list[ring]);\n\t\telse\n\t\t\tadapter->stats.null_rxbuf++;\nskip:\n\t\tfor (; desc_cnt > 0; desc_cnt--) {\n\t\t\tdesc = &sds_ring->desc_head[consumer];\n\t\t\tdesc->status_desc_data[0] = QLCNIC_DESC_OWNER_FW;\n\t\t\tconsumer = get_next_index(consumer, sds_ring->num_desc);\n\t\t}\n\t\tcount++;\n\t}\n\n\tfor (ring = 0; ring < adapter->max_rds_rings; ring++) {\n\t\trds_ring = &adapter->recv_ctx->rds_rings[ring];\n\t\tif (!list_empty(&sds_ring->free_list[ring])) {\n\t\t\tlist_for_each(cur, &sds_ring->free_list[ring]) {\n\t\t\t\trxbuf = list_entry(cur, struct qlcnic_rx_buffer,\n\t\t\t\t\t\t   list);\n\t\t\t\tqlcnic_alloc_rx_skb(adapter, rds_ring, rxbuf);\n\t\t\t}\n\t\t\tspin_lock(&rds_ring->lock);\n\t\t\tlist_splice_tail_init(&sds_ring->free_list[ring],\n\t\t\t\t\t      &rds_ring->free_list);\n\t\t\tspin_unlock(&rds_ring->lock);\n\t\t}\n\n\t\tqlcnic_post_rx_buffers_nodb(adapter, rds_ring, ring);\n\t}\n\n\tif (count) {\n\t\tsds_ring->consumer = consumer;\n\t\twritel(consumer, sds_ring->crb_sts_consumer);\n\t}\n\n\treturn count;\n}\n\nvoid qlcnic_post_rx_buffers(struct qlcnic_adapter *adapter,\n\t\t\t    struct qlcnic_host_rds_ring *rds_ring, u8 ring_id)\n{\n\tstruct rcv_desc *pdesc;\n\tstruct qlcnic_rx_buffer *buffer;\n\tint count = 0;\n\tu32 producer, handle;\n\tstruct list_head *head;\n\n\tproducer = rds_ring->producer;\n\thead = &rds_ring->free_list;\n\n\twhile (!list_empty(head)) {\n\n\t\tbuffer = list_entry(head->next, struct qlcnic_rx_buffer, list);\n\n\t\tif (!buffer->skb) {\n\t\t\tif (qlcnic_alloc_rx_skb(adapter, rds_ring, buffer))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tcount++;\n\t\tlist_del(&buffer->list);\n\n\t\t \n\t\tpdesc = &rds_ring->desc_head[producer];\n\t\tpdesc->addr_buffer = cpu_to_le64(buffer->dma);\n\t\thandle = qlcnic_get_ref_handle(adapter, buffer->ref_handle,\n\t\t\t\t\t       ring_id);\n\t\tpdesc->reference_handle = cpu_to_le16(handle);\n\t\tpdesc->buffer_length = cpu_to_le32(rds_ring->dma_size);\n\t\tproducer = get_next_index(producer, rds_ring->num_desc);\n\t}\n\n\tif (count) {\n\t\trds_ring->producer = producer;\n\t\twritel((producer-1) & (rds_ring->num_desc-1),\n\t\t       rds_ring->crb_rcv_producer);\n\t}\n}\n\nstatic void dump_skb(struct sk_buff *skb, struct qlcnic_adapter *adapter)\n{\n\tif (adapter->ahw->msg_enable & NETIF_MSG_DRV) {\n\t\tchar prefix[30];\n\n\t\tscnprintf(prefix, sizeof(prefix), \"%s: %s: \",\n\t\t\t  dev_name(&adapter->pdev->dev), __func__);\n\n\t\tprint_hex_dump_debug(prefix, DUMP_PREFIX_NONE, 16, 1,\n\t\t\t\t     skb->data, skb->len, true);\n\t}\n}\n\nstatic void qlcnic_process_rcv_diag(struct qlcnic_adapter *adapter, int ring,\n\t\t\t\t    u64 sts_data0)\n{\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct sk_buff *skb;\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tint index, length, cksum, pkt_offset;\n\n\tif (unlikely(ring >= adapter->max_rds_rings))\n\t\treturn;\n\n\trds_ring = &recv_ctx->rds_rings[ring];\n\n\tindex = qlcnic_get_sts_refhandle(sts_data0);\n\tlength = qlcnic_get_sts_totallength(sts_data0);\n\tif (unlikely(index >= rds_ring->num_desc))\n\t\treturn;\n\n\tcksum  = qlcnic_get_sts_status(sts_data0);\n\tpkt_offset = qlcnic_get_sts_pkt_offset(sts_data0);\n\n\tskb = qlcnic_process_rxbuf(adapter, rds_ring, index, cksum);\n\tif (!skb)\n\t\treturn;\n\n\tif (length > rds_ring->skb_size)\n\t\tskb_put(skb, rds_ring->skb_size);\n\telse\n\t\tskb_put(skb, length);\n\n\tif (pkt_offset)\n\t\tskb_pull(skb, pkt_offset);\n\n\tif (!qlcnic_check_loopback_buff(skb->data, adapter->mac_addr))\n\t\tadapter->ahw->diag_cnt++;\n\telse\n\t\tdump_skb(skb, adapter);\n\n\tdev_kfree_skb_any(skb);\n\tadapter->stats.rx_pkts++;\n\tadapter->stats.rxbytes += length;\n\n\treturn;\n}\n\nvoid qlcnic_82xx_process_rcv_ring_diag(struct qlcnic_host_sds_ring *sds_ring)\n{\n\tstruct qlcnic_adapter *adapter = sds_ring->adapter;\n\tstruct status_desc *desc;\n\tu64 sts_data0;\n\tint ring, opcode, desc_cnt;\n\n\tu32 consumer = sds_ring->consumer;\n\n\tdesc = &sds_ring->desc_head[consumer];\n\tsts_data0 = le64_to_cpu(desc->status_desc_data[0]);\n\n\tif (!(sts_data0 & STATUS_OWNER_HOST))\n\t\treturn;\n\n\tdesc_cnt = qlcnic_get_sts_desc_cnt(sts_data0);\n\topcode = qlcnic_get_sts_opcode(sts_data0);\n\tswitch (opcode) {\n\tcase QLCNIC_RESPONSE_DESC:\n\t\tqlcnic_handle_fw_message(desc_cnt, consumer, sds_ring);\n\t\tbreak;\n\tdefault:\n\t\tring = qlcnic_get_sts_type(sts_data0);\n\t\tqlcnic_process_rcv_diag(adapter, ring, sts_data0);\n\t\tbreak;\n\t}\n\n\tfor (; desc_cnt > 0; desc_cnt--) {\n\t\tdesc = &sds_ring->desc_head[consumer];\n\t\tdesc->status_desc_data[0] = cpu_to_le64(STATUS_OWNER_PHANTOM);\n\t\tconsumer = get_next_index(consumer, sds_ring->num_desc);\n\t}\n\n\tsds_ring->consumer = consumer;\n\twritel(consumer, sds_ring->crb_sts_consumer);\n}\n\nint qlcnic_82xx_napi_add(struct qlcnic_adapter *adapter,\n\t\t\t struct net_device *netdev)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\n\tif (qlcnic_alloc_sds_rings(recv_ctx, adapter->drv_sds_rings))\n\t\treturn -ENOMEM;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tif (qlcnic_check_multi_tx(adapter) &&\n\t\t    !adapter->ahw->diag_test) {\n\t\t\tnetif_napi_add(netdev, &sds_ring->napi,\n\t\t\t\t       qlcnic_rx_poll);\n\t\t} else {\n\t\t\tif (ring == (adapter->drv_sds_rings - 1))\n\t\t\t\tnetif_napi_add(netdev, &sds_ring->napi,\n\t\t\t\t\t       qlcnic_poll);\n\t\t\telse\n\t\t\t\tnetif_napi_add(netdev, &sds_ring->napi,\n\t\t\t\t\t       qlcnic_rx_poll);\n\t\t}\n\t}\n\n\tif (qlcnic_alloc_tx_rings(adapter, netdev)) {\n\t\tqlcnic_free_sds_rings(recv_ctx);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (qlcnic_check_multi_tx(adapter) && !adapter->ahw->diag_test) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tnetif_napi_add_tx(netdev, &tx_ring->napi,\n\t\t\t\t\t  qlcnic_tx_poll);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nvoid qlcnic_82xx_napi_del(struct qlcnic_adapter *adapter)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tnetif_napi_del(&sds_ring->napi);\n\t}\n\n\tqlcnic_free_sds_rings(adapter->recv_ctx);\n\n\tif (qlcnic_check_multi_tx(adapter) && !adapter->ahw->diag_test) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tnetif_napi_del(&tx_ring->napi);\n\t\t}\n\t}\n\n\tqlcnic_free_tx_rings(adapter);\n}\n\nvoid qlcnic_82xx_napi_enable(struct qlcnic_adapter *adapter)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\n\tif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\n\t\treturn;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tnapi_enable(&sds_ring->napi);\n\t\tqlcnic_enable_sds_intr(adapter, sds_ring);\n\t}\n\n\tif (qlcnic_check_multi_tx(adapter) &&\n\t    (adapter->flags & QLCNIC_MSIX_ENABLED) &&\n\t    !adapter->ahw->diag_test) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tnapi_enable(&tx_ring->napi);\n\t\t\tqlcnic_enable_tx_intr(adapter, tx_ring);\n\t\t}\n\t}\n}\n\nvoid qlcnic_82xx_napi_disable(struct qlcnic_adapter *adapter)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\n\tif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\n\t\treturn;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tqlcnic_disable_sds_intr(adapter, sds_ring);\n\t\tnapi_synchronize(&sds_ring->napi);\n\t\tnapi_disable(&sds_ring->napi);\n\t}\n\n\tif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\n\t    !adapter->ahw->diag_test &&\n\t    qlcnic_check_multi_tx(adapter)) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tqlcnic_disable_tx_intr(adapter, tx_ring);\n\t\t\tnapi_synchronize(&tx_ring->napi);\n\t\t\tnapi_disable(&tx_ring->napi);\n\t\t}\n\t}\n}\n\n#define QLC_83XX_NORMAL_LB_PKT\t(1ULL << 36)\n#define QLC_83XX_LRO_LB_PKT\t(1ULL << 46)\n\nstatic inline int qlcnic_83xx_is_lb_pkt(u64 sts_data, int lro_pkt)\n{\n\tif (lro_pkt)\n\t\treturn (sts_data & QLC_83XX_LRO_LB_PKT) ? 1 : 0;\n\telse\n\t\treturn (sts_data & QLC_83XX_NORMAL_LB_PKT) ? 1 : 0;\n}\n\n#define QLCNIC_ENCAP_LENGTH_MASK\t0x7f\n\nstatic inline u8 qlcnic_encap_length(u64 sts_data)\n{\n\treturn sts_data & QLCNIC_ENCAP_LENGTH_MASK;\n}\n\nstatic struct qlcnic_rx_buffer *\nqlcnic_83xx_process_rcv(struct qlcnic_adapter *adapter,\n\t\t\tstruct qlcnic_host_sds_ring *sds_ring,\n\t\t\tu8 ring, u64 sts_data[])\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_rx_buffer *buffer;\n\tstruct sk_buff *skb;\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tint index, length, cksum, is_lb_pkt;\n\tu16 vid = 0xffff;\n\tint err;\n\n\tif (unlikely(ring >= adapter->max_rds_rings))\n\t\treturn NULL;\n\n\trds_ring = &recv_ctx->rds_rings[ring];\n\n\tindex = qlcnic_83xx_hndl(sts_data[0]);\n\tif (unlikely(index >= rds_ring->num_desc))\n\t\treturn NULL;\n\n\tbuffer = &rds_ring->rx_buf_arr[index];\n\tlength = qlcnic_83xx_pktln(sts_data[0]);\n\tcksum  = qlcnic_83xx_csum_status(sts_data[1]);\n\tskb = qlcnic_process_rxbuf(adapter, rds_ring, index, cksum);\n\tif (!skb)\n\t\treturn buffer;\n\n\tif (length > rds_ring->skb_size)\n\t\tskb_put(skb, rds_ring->skb_size);\n\telse\n\t\tskb_put(skb, length);\n\n\terr = qlcnic_check_rx_tagging(adapter, skb, &vid);\n\n\tif (adapter->rx_mac_learn) {\n\t\tis_lb_pkt = qlcnic_83xx_is_lb_pkt(sts_data[1], 0);\n\t\tqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, vid);\n\t}\n\n\tif (unlikely(err)) {\n\t\tadapter->stats.rxdropped++;\n\t\tdev_kfree_skb(skb);\n\t\treturn buffer;\n\t}\n\n\tskb->protocol = eth_type_trans(skb, netdev);\n\n\tif (qlcnic_encap_length(sts_data[1]) &&\n\t    skb->ip_summed == CHECKSUM_UNNECESSARY) {\n\t\tskb->csum_level = 1;\n\t\tadapter->stats.encap_rx_csummed++;\n\t}\n\n\tif (vid != 0xffff)\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\n\n\tnapi_gro_receive(&sds_ring->napi, skb);\n\n\tadapter->stats.rx_pkts++;\n\tadapter->stats.rxbytes += length;\n\n\treturn buffer;\n}\n\nstatic struct qlcnic_rx_buffer *\nqlcnic_83xx_process_lro(struct qlcnic_adapter *adapter,\n\t\t\tu8 ring, u64 sts_data[])\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_rx_buffer *buffer;\n\tstruct sk_buff *skb;\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tstruct iphdr *iph;\n\tstruct ipv6hdr *ipv6h;\n\tstruct tcphdr *th;\n\tbool push;\n\tint l2_hdr_offset, l4_hdr_offset;\n\tint index, is_lb_pkt;\n\tu16 lro_length, length, data_offset, gso_size;\n\tu16 vid = 0xffff;\n\tint err;\n\n\tif (unlikely(ring >= adapter->max_rds_rings))\n\t\treturn NULL;\n\n\trds_ring = &recv_ctx->rds_rings[ring];\n\n\tindex = qlcnic_83xx_hndl(sts_data[0]);\n\tif (unlikely(index >= rds_ring->num_desc))\n\t\treturn NULL;\n\n\tbuffer = &rds_ring->rx_buf_arr[index];\n\n\tlro_length = qlcnic_83xx_lro_pktln(sts_data[0]);\n\tl2_hdr_offset = qlcnic_83xx_l2_hdr_off(sts_data[1]);\n\tl4_hdr_offset = qlcnic_83xx_l4_hdr_off(sts_data[1]);\n\tpush = qlcnic_83xx_is_psh_bit(sts_data[1]);\n\n\tskb = qlcnic_process_rxbuf(adapter, rds_ring, index, STATUS_CKSUM_OK);\n\tif (!skb)\n\t\treturn buffer;\n\n\tif (qlcnic_83xx_is_tstamp(sts_data[1]))\n\t\tdata_offset = l4_hdr_offset + QLCNIC_TCP_TS_HDR_SIZE;\n\telse\n\t\tdata_offset = l4_hdr_offset + QLCNIC_TCP_HDR_SIZE;\n\n\tskb_put(skb, lro_length + data_offset);\n\tskb_pull(skb, l2_hdr_offset);\n\n\terr = qlcnic_check_rx_tagging(adapter, skb, &vid);\n\n\tif (adapter->rx_mac_learn) {\n\t\tis_lb_pkt = qlcnic_83xx_is_lb_pkt(sts_data[1], 1);\n\t\tqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, vid);\n\t}\n\n\tif (unlikely(err)) {\n\t\tadapter->stats.rxdropped++;\n\t\tdev_kfree_skb(skb);\n\t\treturn buffer;\n\t}\n\n\tskb->protocol = eth_type_trans(skb, netdev);\n\tif (ntohs(skb->protocol) == ETH_P_IPV6) {\n\t\tipv6h = (struct ipv6hdr *)skb->data;\n\t\tth = (struct tcphdr *)(skb->data + sizeof(struct ipv6hdr));\n\n\t\tlength = (th->doff << 2) + lro_length;\n\t\tipv6h->payload_len = htons(length);\n\t} else {\n\t\tiph = (struct iphdr *)skb->data;\n\t\tth = (struct tcphdr *)(skb->data + (iph->ihl << 2));\n\t\tlength = (iph->ihl << 2) + (th->doff << 2) + lro_length;\n\t\tcsum_replace2(&iph->check, iph->tot_len, htons(length));\n\t\tiph->tot_len = htons(length);\n\t}\n\n\tth->psh = push;\n\tlength = skb->len;\n\n\tif (adapter->flags & QLCNIC_FW_LRO_MSS_CAP) {\n\t\tgso_size = qlcnic_83xx_get_lro_sts_mss(sts_data[0]);\n\t\tskb_shinfo(skb)->gso_size = gso_size;\n\t\tif (skb->protocol == htons(ETH_P_IPV6))\n\t\t\tskb_shinfo(skb)->gso_type = SKB_GSO_TCPV6;\n\t\telse\n\t\t\tskb_shinfo(skb)->gso_type = SKB_GSO_TCPV4;\n\t}\n\n\tif (vid != 0xffff)\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\n\n\tnetif_receive_skb(skb);\n\n\tadapter->stats.lro_pkts++;\n\tadapter->stats.lrobytes += length;\n\treturn buffer;\n}\n\nstatic int qlcnic_83xx_process_rcv_ring(struct qlcnic_host_sds_ring *sds_ring,\n\t\t\t\t\tint max)\n{\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tstruct qlcnic_adapter *adapter = sds_ring->adapter;\n\tstruct list_head *cur;\n\tstruct status_desc *desc;\n\tstruct qlcnic_rx_buffer *rxbuf = NULL;\n\tu8 ring;\n\tu64 sts_data[2];\n\tint count = 0, opcode;\n\tu32 consumer = sds_ring->consumer;\n\n\twhile (count < max) {\n\t\tdesc = &sds_ring->desc_head[consumer];\n\t\tsts_data[1] = le64_to_cpu(desc->status_desc_data[1]);\n\t\topcode = qlcnic_83xx_opcode(sts_data[1]);\n\t\tif (!opcode)\n\t\t\tbreak;\n\t\tsts_data[0] = le64_to_cpu(desc->status_desc_data[0]);\n\t\tring = QLCNIC_FETCH_RING_ID(sts_data[0]);\n\n\t\tswitch (opcode) {\n\t\tcase QLC_83XX_REG_DESC:\n\t\t\trxbuf = qlcnic_83xx_process_rcv(adapter, sds_ring,\n\t\t\t\t\t\t\tring, sts_data);\n\t\t\tbreak;\n\t\tcase QLC_83XX_LRO_DESC:\n\t\t\trxbuf = qlcnic_83xx_process_lro(adapter, ring,\n\t\t\t\t\t\t\tsts_data);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_info(&adapter->pdev->dev,\n\t\t\t\t \"Unknown opcode: 0x%x\\n\", opcode);\n\t\t\tgoto skip;\n\t\t}\n\n\t\tif (likely(rxbuf))\n\t\t\tlist_add_tail(&rxbuf->list, &sds_ring->free_list[ring]);\n\t\telse\n\t\t\tadapter->stats.null_rxbuf++;\nskip:\n\t\tdesc = &sds_ring->desc_head[consumer];\n\t\t \n\t\tdesc->status_desc_data[1] = 0;\n\t\tconsumer = get_next_index(consumer, sds_ring->num_desc);\n\t\tcount++;\n\t}\n\tfor (ring = 0; ring < adapter->max_rds_rings; ring++) {\n\t\trds_ring = &adapter->recv_ctx->rds_rings[ring];\n\t\tif (!list_empty(&sds_ring->free_list[ring])) {\n\t\t\tlist_for_each(cur, &sds_ring->free_list[ring]) {\n\t\t\t\trxbuf = list_entry(cur, struct qlcnic_rx_buffer,\n\t\t\t\t\t\t   list);\n\t\t\t\tqlcnic_alloc_rx_skb(adapter, rds_ring, rxbuf);\n\t\t\t}\n\t\t\tspin_lock(&rds_ring->lock);\n\t\t\tlist_splice_tail_init(&sds_ring->free_list[ring],\n\t\t\t\t\t      &rds_ring->free_list);\n\t\t\tspin_unlock(&rds_ring->lock);\n\t\t}\n\t\tqlcnic_post_rx_buffers_nodb(adapter, rds_ring, ring);\n\t}\n\tif (count) {\n\t\tsds_ring->consumer = consumer;\n\t\twritel(consumer, sds_ring->crb_sts_consumer);\n\t}\n\treturn count;\n}\n\nstatic int qlcnic_83xx_msix_sriov_vf_poll(struct napi_struct *napi, int budget)\n{\n\tint tx_complete;\n\tint work_done;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_adapter *adapter;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\n\tsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\n\tadapter = sds_ring->adapter;\n\t \n\ttx_ring = adapter->tx_ring;\n\n\ttx_complete = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\n\twork_done = qlcnic_83xx_process_rcv_ring(sds_ring, budget);\n\n\t \n\tif (!tx_complete)\n\t\twork_done = budget;\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(&sds_ring->napi, work_done);\n\t\tqlcnic_enable_sds_intr(adapter, sds_ring);\n\t}\n\n\treturn work_done;\n}\n\nstatic int qlcnic_83xx_poll(struct napi_struct *napi, int budget)\n{\n\tint tx_complete;\n\tint work_done;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_adapter *adapter;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\n\tsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\n\tadapter = sds_ring->adapter;\n\t \n\ttx_ring = adapter->tx_ring;\n\n\ttx_complete = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\n\twork_done = qlcnic_83xx_process_rcv_ring(sds_ring, budget);\n\n\t \n\tif (!tx_complete)\n\t\twork_done = budget;\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(&sds_ring->napi, work_done);\n\t\tqlcnic_enable_sds_intr(adapter, sds_ring);\n\t}\n\n\treturn work_done;\n}\n\nstatic int qlcnic_83xx_msix_tx_poll(struct napi_struct *napi, int budget)\n{\n\tint work_done;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\tstruct qlcnic_adapter *adapter;\n\n\ttx_ring = container_of(napi, struct qlcnic_host_tx_ring, napi);\n\tadapter = tx_ring->adapter;\n\twork_done = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\n\tif (work_done) {\n\t\tnapi_complete(&tx_ring->napi);\n\t\tif (test_bit(__QLCNIC_DEV_UP , &adapter->state))\n\t\t\tqlcnic_enable_tx_intr(adapter, tx_ring);\n\t} else {\n\t\t \n\t\twork_done = budget;\n\t}\n\n\treturn work_done;\n}\n\nstatic int qlcnic_83xx_rx_poll(struct napi_struct *napi, int budget)\n{\n\tint work_done;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_adapter *adapter;\n\n\tsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\n\tadapter = sds_ring->adapter;\n\twork_done = qlcnic_83xx_process_rcv_ring(sds_ring, budget);\n\tif (work_done < budget) {\n\t\tnapi_complete_done(&sds_ring->napi, work_done);\n\t\tif (test_bit(__QLCNIC_DEV_UP, &adapter->state))\n\t\t\tqlcnic_enable_sds_intr(adapter, sds_ring);\n\t}\n\n\treturn work_done;\n}\n\nvoid qlcnic_83xx_napi_enable(struct qlcnic_adapter *adapter)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\n\tif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\n\t\treturn;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tnapi_enable(&sds_ring->napi);\n\t\tif (adapter->flags & QLCNIC_MSIX_ENABLED)\n\t\t\tqlcnic_enable_sds_intr(adapter, sds_ring);\n\t}\n\n\tif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\n\t    !(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tnapi_enable(&tx_ring->napi);\n\t\t\tqlcnic_enable_tx_intr(adapter, tx_ring);\n\t\t}\n\t}\n}\n\nvoid qlcnic_83xx_napi_disable(struct qlcnic_adapter *adapter)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\n\tif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\n\t\treturn;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tif (adapter->flags & QLCNIC_MSIX_ENABLED)\n\t\t\tqlcnic_disable_sds_intr(adapter, sds_ring);\n\t\tnapi_synchronize(&sds_ring->napi);\n\t\tnapi_disable(&sds_ring->napi);\n\t}\n\n\tif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\n\t    !(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tqlcnic_disable_tx_intr(adapter, tx_ring);\n\t\t\tnapi_synchronize(&tx_ring->napi);\n\t\t\tnapi_disable(&tx_ring->napi);\n\t\t}\n\t}\n}\n\nint qlcnic_83xx_napi_add(struct qlcnic_adapter *adapter,\n\t\t\t struct net_device *netdev)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\n\tif (qlcnic_alloc_sds_rings(recv_ctx, adapter->drv_sds_rings))\n\t\treturn -ENOMEM;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tif (adapter->flags & QLCNIC_MSIX_ENABLED) {\n\t\t\tif (!(adapter->flags & QLCNIC_TX_INTR_SHARED))\n\t\t\t\tnetif_napi_add(netdev, &sds_ring->napi,\n\t\t\t\t\t       qlcnic_83xx_rx_poll);\n\t\t\telse\n\t\t\t\tnetif_napi_add(netdev, &sds_ring->napi,\n\t\t\t\t\t       qlcnic_83xx_msix_sriov_vf_poll);\n\n\t\t} else {\n\t\t\tnetif_napi_add(netdev, &sds_ring->napi,\n\t\t\t\t       qlcnic_83xx_poll);\n\t\t}\n\t}\n\n\tif (qlcnic_alloc_tx_rings(adapter, netdev)) {\n\t\tqlcnic_free_sds_rings(recv_ctx);\n\t\treturn -ENOMEM;\n\t}\n\n\tif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\n\t    !(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tnetif_napi_add_tx(netdev, &tx_ring->napi,\n\t\t\t\t\t  qlcnic_83xx_msix_tx_poll);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nvoid qlcnic_83xx_napi_del(struct qlcnic_adapter *adapter)\n{\n\tint ring;\n\tstruct qlcnic_host_sds_ring *sds_ring;\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct qlcnic_host_tx_ring *tx_ring;\n\n\tfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\n\t\tsds_ring = &recv_ctx->sds_rings[ring];\n\t\tnetif_napi_del(&sds_ring->napi);\n\t}\n\n\tqlcnic_free_sds_rings(adapter->recv_ctx);\n\n\tif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\n\t    !(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\n\t\tfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\n\t\t\ttx_ring = &adapter->tx_ring[ring];\n\t\t\tnetif_napi_del(&tx_ring->napi);\n\t\t}\n\t}\n\n\tqlcnic_free_tx_rings(adapter);\n}\n\nstatic void qlcnic_83xx_process_rcv_diag(struct qlcnic_adapter *adapter,\n\t\t\t\t\t int ring, u64 sts_data[])\n{\n\tstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\n\tstruct sk_buff *skb;\n\tstruct qlcnic_host_rds_ring *rds_ring;\n\tint index, length;\n\n\tif (unlikely(ring >= adapter->max_rds_rings))\n\t\treturn;\n\n\trds_ring = &recv_ctx->rds_rings[ring];\n\tindex = qlcnic_83xx_hndl(sts_data[0]);\n\tif (unlikely(index >= rds_ring->num_desc))\n\t\treturn;\n\n\tlength = qlcnic_83xx_pktln(sts_data[0]);\n\n\tskb = qlcnic_process_rxbuf(adapter, rds_ring, index, STATUS_CKSUM_OK);\n\tif (!skb)\n\t\treturn;\n\n\tif (length > rds_ring->skb_size)\n\t\tskb_put(skb, rds_ring->skb_size);\n\telse\n\t\tskb_put(skb, length);\n\n\tif (!qlcnic_check_loopback_buff(skb->data, adapter->mac_addr))\n\t\tadapter->ahw->diag_cnt++;\n\telse\n\t\tdump_skb(skb, adapter);\n\n\tdev_kfree_skb_any(skb);\n\treturn;\n}\n\nvoid qlcnic_83xx_process_rcv_ring_diag(struct qlcnic_host_sds_ring *sds_ring)\n{\n\tstruct qlcnic_adapter *adapter = sds_ring->adapter;\n\tstruct status_desc *desc;\n\tu64 sts_data[2];\n\tint ring, opcode;\n\tu32 consumer = sds_ring->consumer;\n\n\tdesc = &sds_ring->desc_head[consumer];\n\tsts_data[0] = le64_to_cpu(desc->status_desc_data[0]);\n\tsts_data[1] = le64_to_cpu(desc->status_desc_data[1]);\n\topcode = qlcnic_83xx_opcode(sts_data[1]);\n\tif (!opcode)\n\t\treturn;\n\n\tring = QLCNIC_FETCH_RING_ID(sts_data[0]);\n\tqlcnic_83xx_process_rcv_diag(adapter, ring, sts_data);\n\tdesc = &sds_ring->desc_head[consumer];\n\tdesc->status_desc_data[0] = cpu_to_le64(STATUS_OWNER_PHANTOM);\n\tconsumer = get_next_index(consumer, sds_ring->num_desc);\n\tsds_ring->consumer = consumer;\n\twritel(consumer, sds_ring->crb_sts_consumer);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}