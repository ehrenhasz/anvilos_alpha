{
  "module_name": "gve_adminq.c",
  "hash_id": "fc1984e0b1423ac953d10abb0e060766a68cb0878a67993371b0ec787540dcda",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/google/gve/gve_adminq.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <linux/pci.h>\n#include \"gve.h\"\n#include \"gve_adminq.h\"\n#include \"gve_register.h\"\n\n#define GVE_MAX_ADMINQ_RELEASE_CHECK\t500\n#define GVE_ADMINQ_SLEEP_LEN\t\t20\n#define GVE_MAX_ADMINQ_EVENT_COUNTER_CHECK\t100\n\n#define GVE_DEVICE_OPTION_ERROR_FMT \"%s option error:\\n\" \\\n\"Expected: length=%d, feature_mask=%x.\\n\" \\\n\"Actual: length=%d, feature_mask=%x.\\n\"\n\n#define GVE_DEVICE_OPTION_TOO_BIG_FMT \"Length of %s option larger than expected. Possible older version of guest driver.\\n\"\n\nstatic\nstruct gve_device_option *gve_get_next_option(struct gve_device_descriptor *descriptor,\n\t\t\t\t\t      struct gve_device_option *option)\n{\n\tvoid *option_end, *descriptor_end;\n\n\toption_end = (void *)(option + 1) + be16_to_cpu(option->option_length);\n\tdescriptor_end = (void *)descriptor + be16_to_cpu(descriptor->total_length);\n\n\treturn option_end > descriptor_end ? NULL : (struct gve_device_option *)option_end;\n}\n\nstatic\nvoid gve_parse_device_option(struct gve_priv *priv,\n\t\t\t     struct gve_device_descriptor *device_descriptor,\n\t\t\t     struct gve_device_option *option,\n\t\t\t     struct gve_device_option_gqi_rda **dev_op_gqi_rda,\n\t\t\t     struct gve_device_option_gqi_qpl **dev_op_gqi_qpl,\n\t\t\t     struct gve_device_option_dqo_rda **dev_op_dqo_rda,\n\t\t\t     struct gve_device_option_jumbo_frames **dev_op_jumbo_frames,\n\t\t\t     struct gve_device_option_dqo_qpl **dev_op_dqo_qpl)\n{\n\tu32 req_feat_mask = be32_to_cpu(option->required_features_mask);\n\tu16 option_length = be16_to_cpu(option->option_length);\n\tu16 option_id = be16_to_cpu(option->option_id);\n\n\t \n\tswitch (option_id) {\n\tcase GVE_DEV_OPT_ID_GQI_RAW_ADDRESSING:\n\t\tif (option_length != GVE_DEV_OPT_LEN_GQI_RAW_ADDRESSING ||\n\t\t    req_feat_mask != GVE_DEV_OPT_REQ_FEAT_MASK_GQI_RAW_ADDRESSING) {\n\t\t\tdev_warn(&priv->pdev->dev, GVE_DEVICE_OPTION_ERROR_FMT,\n\t\t\t\t \"Raw Addressing\",\n\t\t\t\t GVE_DEV_OPT_LEN_GQI_RAW_ADDRESSING,\n\t\t\t\t GVE_DEV_OPT_REQ_FEAT_MASK_GQI_RAW_ADDRESSING,\n\t\t\t\t option_length, req_feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tdev_info(&priv->pdev->dev,\n\t\t\t \"Gqi raw addressing device option enabled.\\n\");\n\t\tpriv->queue_format = GVE_GQI_RDA_FORMAT;\n\t\tbreak;\n\tcase GVE_DEV_OPT_ID_GQI_RDA:\n\t\tif (option_length < sizeof(**dev_op_gqi_rda) ||\n\t\t    req_feat_mask != GVE_DEV_OPT_REQ_FEAT_MASK_GQI_RDA) {\n\t\t\tdev_warn(&priv->pdev->dev, GVE_DEVICE_OPTION_ERROR_FMT,\n\t\t\t\t \"GQI RDA\", (int)sizeof(**dev_op_gqi_rda),\n\t\t\t\t GVE_DEV_OPT_REQ_FEAT_MASK_GQI_RDA,\n\t\t\t\t option_length, req_feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (option_length > sizeof(**dev_op_gqi_rda)) {\n\t\t\tdev_warn(&priv->pdev->dev,\n\t\t\t\t GVE_DEVICE_OPTION_TOO_BIG_FMT, \"GQI RDA\");\n\t\t}\n\t\t*dev_op_gqi_rda = (void *)(option + 1);\n\t\tbreak;\n\tcase GVE_DEV_OPT_ID_GQI_QPL:\n\t\tif (option_length < sizeof(**dev_op_gqi_qpl) ||\n\t\t    req_feat_mask != GVE_DEV_OPT_REQ_FEAT_MASK_GQI_QPL) {\n\t\t\tdev_warn(&priv->pdev->dev, GVE_DEVICE_OPTION_ERROR_FMT,\n\t\t\t\t \"GQI QPL\", (int)sizeof(**dev_op_gqi_qpl),\n\t\t\t\t GVE_DEV_OPT_REQ_FEAT_MASK_GQI_QPL,\n\t\t\t\t option_length, req_feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (option_length > sizeof(**dev_op_gqi_qpl)) {\n\t\t\tdev_warn(&priv->pdev->dev,\n\t\t\t\t GVE_DEVICE_OPTION_TOO_BIG_FMT, \"GQI QPL\");\n\t\t}\n\t\t*dev_op_gqi_qpl = (void *)(option + 1);\n\t\tbreak;\n\tcase GVE_DEV_OPT_ID_DQO_RDA:\n\t\tif (option_length < sizeof(**dev_op_dqo_rda) ||\n\t\t    req_feat_mask != GVE_DEV_OPT_REQ_FEAT_MASK_DQO_RDA) {\n\t\t\tdev_warn(&priv->pdev->dev, GVE_DEVICE_OPTION_ERROR_FMT,\n\t\t\t\t \"DQO RDA\", (int)sizeof(**dev_op_dqo_rda),\n\t\t\t\t GVE_DEV_OPT_REQ_FEAT_MASK_DQO_RDA,\n\t\t\t\t option_length, req_feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (option_length > sizeof(**dev_op_dqo_rda)) {\n\t\t\tdev_warn(&priv->pdev->dev,\n\t\t\t\t GVE_DEVICE_OPTION_TOO_BIG_FMT, \"DQO RDA\");\n\t\t}\n\t\t*dev_op_dqo_rda = (void *)(option + 1);\n\t\tbreak;\n\tcase GVE_DEV_OPT_ID_DQO_QPL:\n\t\tif (option_length < sizeof(**dev_op_dqo_qpl) ||\n\t\t    req_feat_mask != GVE_DEV_OPT_REQ_FEAT_MASK_DQO_QPL) {\n\t\t\tdev_warn(&priv->pdev->dev, GVE_DEVICE_OPTION_ERROR_FMT,\n\t\t\t\t \"DQO QPL\", (int)sizeof(**dev_op_dqo_qpl),\n\t\t\t\t GVE_DEV_OPT_REQ_FEAT_MASK_DQO_QPL,\n\t\t\t\t option_length, req_feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (option_length > sizeof(**dev_op_dqo_qpl)) {\n\t\t\tdev_warn(&priv->pdev->dev,\n\t\t\t\t GVE_DEVICE_OPTION_TOO_BIG_FMT, \"DQO QPL\");\n\t\t}\n\t\t*dev_op_dqo_qpl = (void *)(option + 1);\n\t\tbreak;\n\tcase GVE_DEV_OPT_ID_JUMBO_FRAMES:\n\t\tif (option_length < sizeof(**dev_op_jumbo_frames) ||\n\t\t    req_feat_mask != GVE_DEV_OPT_REQ_FEAT_MASK_JUMBO_FRAMES) {\n\t\t\tdev_warn(&priv->pdev->dev, GVE_DEVICE_OPTION_ERROR_FMT,\n\t\t\t\t \"Jumbo Frames\",\n\t\t\t\t (int)sizeof(**dev_op_jumbo_frames),\n\t\t\t\t GVE_DEV_OPT_REQ_FEAT_MASK_JUMBO_FRAMES,\n\t\t\t\t option_length, req_feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (option_length > sizeof(**dev_op_jumbo_frames)) {\n\t\t\tdev_warn(&priv->pdev->dev,\n\t\t\t\t GVE_DEVICE_OPTION_TOO_BIG_FMT,\n\t\t\t\t \"Jumbo Frames\");\n\t\t}\n\t\t*dev_op_jumbo_frames = (void *)(option + 1);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tdev_dbg(&priv->pdev->dev, \"Unrecognized device option 0x%hx not enabled.\\n\",\n\t\t\toption_id);\n\t}\n}\n\n \nstatic int\ngve_process_device_options(struct gve_priv *priv,\n\t\t\t   struct gve_device_descriptor *descriptor,\n\t\t\t   struct gve_device_option_gqi_rda **dev_op_gqi_rda,\n\t\t\t   struct gve_device_option_gqi_qpl **dev_op_gqi_qpl,\n\t\t\t   struct gve_device_option_dqo_rda **dev_op_dqo_rda,\n\t\t\t   struct gve_device_option_jumbo_frames **dev_op_jumbo_frames,\n\t\t\t   struct gve_device_option_dqo_qpl **dev_op_dqo_qpl)\n{\n\tconst int num_options = be16_to_cpu(descriptor->num_device_options);\n\tstruct gve_device_option *dev_opt;\n\tint i;\n\n\t \n\tdev_opt = (void *)(descriptor + 1);\n\tfor (i = 0; i < num_options; i++) {\n\t\tstruct gve_device_option *next_opt;\n\n\t\tnext_opt = gve_get_next_option(descriptor, dev_opt);\n\t\tif (!next_opt) {\n\t\t\tdev_err(&priv->dev->dev,\n\t\t\t\t\"options exceed device_descriptor's total length.\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tgve_parse_device_option(priv, descriptor, dev_opt,\n\t\t\t\t\tdev_op_gqi_rda, dev_op_gqi_qpl,\n\t\t\t\t\tdev_op_dqo_rda, dev_op_jumbo_frames,\n\t\t\t\t\tdev_op_dqo_qpl);\n\t\tdev_opt = next_opt;\n\t}\n\n\treturn 0;\n}\n\nint gve_adminq_alloc(struct device *dev, struct gve_priv *priv)\n{\n\tpriv->adminq = dma_alloc_coherent(dev, PAGE_SIZE,\n\t\t\t\t\t  &priv->adminq_bus_addr, GFP_KERNEL);\n\tif (unlikely(!priv->adminq))\n\t\treturn -ENOMEM;\n\n\tpriv->adminq_mask = (PAGE_SIZE / sizeof(union gve_adminq_command)) - 1;\n\tpriv->adminq_prod_cnt = 0;\n\tpriv->adminq_cmd_fail = 0;\n\tpriv->adminq_timeouts = 0;\n\tpriv->adminq_describe_device_cnt = 0;\n\tpriv->adminq_cfg_device_resources_cnt = 0;\n\tpriv->adminq_register_page_list_cnt = 0;\n\tpriv->adminq_unregister_page_list_cnt = 0;\n\tpriv->adminq_create_tx_queue_cnt = 0;\n\tpriv->adminq_create_rx_queue_cnt = 0;\n\tpriv->adminq_destroy_tx_queue_cnt = 0;\n\tpriv->adminq_destroy_rx_queue_cnt = 0;\n\tpriv->adminq_dcfg_device_resources_cnt = 0;\n\tpriv->adminq_set_driver_parameter_cnt = 0;\n\tpriv->adminq_report_stats_cnt = 0;\n\tpriv->adminq_report_link_speed_cnt = 0;\n\tpriv->adminq_get_ptype_map_cnt = 0;\n\n\t \n\tiowrite32be(priv->adminq_bus_addr / PAGE_SIZE,\n\t\t    &priv->reg_bar0->adminq_pfn);\n\n\tgve_set_admin_queue_ok(priv);\n\treturn 0;\n}\n\nvoid gve_adminq_release(struct gve_priv *priv)\n{\n\tint i = 0;\n\n\t \n\tiowrite32be(0x0, &priv->reg_bar0->adminq_pfn);\n\twhile (ioread32be(&priv->reg_bar0->adminq_pfn)) {\n\t\t \n\t\tif (i == GVE_MAX_ADMINQ_RELEASE_CHECK)\n\t\t\tWARN(1, \"Unrecoverable platform error!\");\n\t\ti++;\n\t\tmsleep(GVE_ADMINQ_SLEEP_LEN);\n\t}\n\tgve_clear_device_rings_ok(priv);\n\tgve_clear_device_resources_ok(priv);\n\tgve_clear_admin_queue_ok(priv);\n}\n\nvoid gve_adminq_free(struct device *dev, struct gve_priv *priv)\n{\n\tif (!gve_get_admin_queue_ok(priv))\n\t\treturn;\n\tgve_adminq_release(priv);\n\tdma_free_coherent(dev, PAGE_SIZE, priv->adminq, priv->adminq_bus_addr);\n\tgve_clear_admin_queue_ok(priv);\n}\n\nstatic void gve_adminq_kick_cmd(struct gve_priv *priv, u32 prod_cnt)\n{\n\tiowrite32be(prod_cnt, &priv->reg_bar0->adminq_doorbell);\n}\n\nstatic bool gve_adminq_wait_for_cmd(struct gve_priv *priv, u32 prod_cnt)\n{\n\tint i;\n\n\tfor (i = 0; i < GVE_MAX_ADMINQ_EVENT_COUNTER_CHECK; i++) {\n\t\tif (ioread32be(&priv->reg_bar0->adminq_event_counter)\n\t\t    == prod_cnt)\n\t\t\treturn true;\n\t\tmsleep(GVE_ADMINQ_SLEEP_LEN);\n\t}\n\n\treturn false;\n}\n\nstatic int gve_adminq_parse_err(struct gve_priv *priv, u32 status)\n{\n\tif (status != GVE_ADMINQ_COMMAND_PASSED &&\n\t    status != GVE_ADMINQ_COMMAND_UNSET) {\n\t\tdev_err(&priv->pdev->dev, \"AQ command failed with status %d\\n\", status);\n\t\tpriv->adminq_cmd_fail++;\n\t}\n\tswitch (status) {\n\tcase GVE_ADMINQ_COMMAND_PASSED:\n\t\treturn 0;\n\tcase GVE_ADMINQ_COMMAND_UNSET:\n\t\tdev_err(&priv->pdev->dev, \"parse_aq_err: err and status both unset, this should not be possible.\\n\");\n\t\treturn -EINVAL;\n\tcase GVE_ADMINQ_COMMAND_ERROR_ABORTED:\n\tcase GVE_ADMINQ_COMMAND_ERROR_CANCELLED:\n\tcase GVE_ADMINQ_COMMAND_ERROR_DATALOSS:\n\tcase GVE_ADMINQ_COMMAND_ERROR_FAILED_PRECONDITION:\n\tcase GVE_ADMINQ_COMMAND_ERROR_UNAVAILABLE:\n\t\treturn -EAGAIN;\n\tcase GVE_ADMINQ_COMMAND_ERROR_ALREADY_EXISTS:\n\tcase GVE_ADMINQ_COMMAND_ERROR_INTERNAL_ERROR:\n\tcase GVE_ADMINQ_COMMAND_ERROR_INVALID_ARGUMENT:\n\tcase GVE_ADMINQ_COMMAND_ERROR_NOT_FOUND:\n\tcase GVE_ADMINQ_COMMAND_ERROR_OUT_OF_RANGE:\n\tcase GVE_ADMINQ_COMMAND_ERROR_UNKNOWN_ERROR:\n\t\treturn -EINVAL;\n\tcase GVE_ADMINQ_COMMAND_ERROR_DEADLINE_EXCEEDED:\n\t\treturn -ETIME;\n\tcase GVE_ADMINQ_COMMAND_ERROR_PERMISSION_DENIED:\n\tcase GVE_ADMINQ_COMMAND_ERROR_UNAUTHENTICATED:\n\t\treturn -EACCES;\n\tcase GVE_ADMINQ_COMMAND_ERROR_RESOURCE_EXHAUSTED:\n\t\treturn -ENOMEM;\n\tcase GVE_ADMINQ_COMMAND_ERROR_UNIMPLEMENTED:\n\t\treturn -EOPNOTSUPP;\n\tdefault:\n\t\tdev_err(&priv->pdev->dev, \"parse_aq_err: unknown status code %d\\n\", status);\n\t\treturn -EINVAL;\n\t}\n}\n\n \nstatic int gve_adminq_kick_and_wait(struct gve_priv *priv)\n{\n\tint tail, head;\n\tint i;\n\n\ttail = ioread32be(&priv->reg_bar0->adminq_event_counter);\n\thead = priv->adminq_prod_cnt;\n\n\tgve_adminq_kick_cmd(priv, head);\n\tif (!gve_adminq_wait_for_cmd(priv, head)) {\n\t\tdev_err(&priv->pdev->dev, \"AQ commands timed out, need to reset AQ\\n\");\n\t\tpriv->adminq_timeouts++;\n\t\treturn -ENOTRECOVERABLE;\n\t}\n\n\tfor (i = tail; i < head; i++) {\n\t\tunion gve_adminq_command *cmd;\n\t\tu32 status, err;\n\n\t\tcmd = &priv->adminq[i & priv->adminq_mask];\n\t\tstatus = be32_to_cpu(READ_ONCE(cmd->status));\n\t\terr = gve_adminq_parse_err(priv, status);\n\t\tif (err)\n\t\t\t\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int gve_adminq_issue_cmd(struct gve_priv *priv,\n\t\t\t\tunion gve_adminq_command *cmd_orig)\n{\n\tunion gve_adminq_command *cmd;\n\tu32 opcode;\n\tu32 tail;\n\n\ttail = ioread32be(&priv->reg_bar0->adminq_event_counter);\n\n\t\n\tif (((priv->adminq_prod_cnt + 1) & priv->adminq_mask) ==\n\t    (tail & priv->adminq_mask)) {\n\t\tint err;\n\n\t\t\n\t\terr = gve_adminq_kick_and_wait(priv);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t\n\t\ttail = ioread32be(&priv->reg_bar0->adminq_event_counter);\n\t\tif (((priv->adminq_prod_cnt + 1) & priv->adminq_mask) ==\n\t\t    (tail & priv->adminq_mask)) {\n\t\t\t\n\t\t\t\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tcmd = &priv->adminq[priv->adminq_prod_cnt & priv->adminq_mask];\n\tpriv->adminq_prod_cnt++;\n\n\tmemcpy(cmd, cmd_orig, sizeof(*cmd_orig));\n\topcode = be32_to_cpu(READ_ONCE(cmd->opcode));\n\n\tswitch (opcode) {\n\tcase GVE_ADMINQ_DESCRIBE_DEVICE:\n\t\tpriv->adminq_describe_device_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_CONFIGURE_DEVICE_RESOURCES:\n\t\tpriv->adminq_cfg_device_resources_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_REGISTER_PAGE_LIST:\n\t\tpriv->adminq_register_page_list_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_UNREGISTER_PAGE_LIST:\n\t\tpriv->adminq_unregister_page_list_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_CREATE_TX_QUEUE:\n\t\tpriv->adminq_create_tx_queue_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_CREATE_RX_QUEUE:\n\t\tpriv->adminq_create_rx_queue_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_DESTROY_TX_QUEUE:\n\t\tpriv->adminq_destroy_tx_queue_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_DESTROY_RX_QUEUE:\n\t\tpriv->adminq_destroy_rx_queue_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_DECONFIGURE_DEVICE_RESOURCES:\n\t\tpriv->adminq_dcfg_device_resources_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_SET_DRIVER_PARAMETER:\n\t\tpriv->adminq_set_driver_parameter_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_REPORT_STATS:\n\t\tpriv->adminq_report_stats_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_REPORT_LINK_SPEED:\n\t\tpriv->adminq_report_link_speed_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_GET_PTYPE_MAP:\n\t\tpriv->adminq_get_ptype_map_cnt++;\n\t\tbreak;\n\tcase GVE_ADMINQ_VERIFY_DRIVER_COMPATIBILITY:\n\t\tpriv->adminq_verify_driver_compatibility_cnt++;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&priv->pdev->dev, \"unknown AQ command opcode %d\\n\", opcode);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int gve_adminq_execute_cmd(struct gve_priv *priv,\n\t\t\t\t  union gve_adminq_command *cmd_orig)\n{\n\tu32 tail, head;\n\tint err;\n\n\ttail = ioread32be(&priv->reg_bar0->adminq_event_counter);\n\thead = priv->adminq_prod_cnt;\n\tif (tail != head)\n\t\t\n\t\treturn -EINVAL;\n\n\terr = gve_adminq_issue_cmd(priv, cmd_orig);\n\tif (err)\n\t\treturn err;\n\n\treturn gve_adminq_kick_and_wait(priv);\n}\n\n \n#define GVE_NTFY_BLK_BASE_MSIX_IDX\t0\nint gve_adminq_configure_device_resources(struct gve_priv *priv,\n\t\t\t\t\t  dma_addr_t counter_array_bus_addr,\n\t\t\t\t\t  u32 num_counters,\n\t\t\t\t\t  dma_addr_t db_array_bus_addr,\n\t\t\t\t\t  u32 num_ntfy_blks)\n{\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_CONFIGURE_DEVICE_RESOURCES);\n\tcmd.configure_device_resources =\n\t\t(struct gve_adminq_configure_device_resources) {\n\t\t.counter_array = cpu_to_be64(counter_array_bus_addr),\n\t\t.num_counters = cpu_to_be32(num_counters),\n\t\t.irq_db_addr = cpu_to_be64(db_array_bus_addr),\n\t\t.num_irq_dbs = cpu_to_be32(num_ntfy_blks),\n\t\t.irq_db_stride = cpu_to_be32(sizeof(*priv->irq_db_indices)),\n\t\t.ntfy_blk_msix_base_idx =\n\t\t\t\t\tcpu_to_be32(GVE_NTFY_BLK_BASE_MSIX_IDX),\n\t\t.queue_format = priv->queue_format,\n\t};\n\n\treturn gve_adminq_execute_cmd(priv, &cmd);\n}\n\nint gve_adminq_deconfigure_device_resources(struct gve_priv *priv)\n{\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_DECONFIGURE_DEVICE_RESOURCES);\n\n\treturn gve_adminq_execute_cmd(priv, &cmd);\n}\n\nstatic int gve_adminq_create_tx_queue(struct gve_priv *priv, u32 queue_index)\n{\n\tstruct gve_tx_ring *tx = &priv->tx[queue_index];\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_CREATE_TX_QUEUE);\n\tcmd.create_tx_queue = (struct gve_adminq_create_tx_queue) {\n\t\t.queue_id = cpu_to_be32(queue_index),\n\t\t.queue_resources_addr =\n\t\t\tcpu_to_be64(tx->q_resources_bus),\n\t\t.tx_ring_addr = cpu_to_be64(tx->bus),\n\t\t.ntfy_id = cpu_to_be32(tx->ntfy_id),\n\t};\n\n\tif (gve_is_gqi(priv)) {\n\t\tu32 qpl_id = priv->queue_format == GVE_GQI_RDA_FORMAT ?\n\t\t\tGVE_RAW_ADDRESSING_QPL_ID : tx->tx_fifo.qpl->id;\n\n\t\tcmd.create_tx_queue.queue_page_list_id = cpu_to_be32(qpl_id);\n\t} else {\n\t\tu16 comp_ring_size;\n\t\tu32 qpl_id = 0;\n\n\t\tif (priv->queue_format == GVE_DQO_RDA_FORMAT) {\n\t\t\tqpl_id = GVE_RAW_ADDRESSING_QPL_ID;\n\t\t\tcomp_ring_size =\n\t\t\t\tpriv->options_dqo_rda.tx_comp_ring_entries;\n\t\t} else {\n\t\t\tqpl_id = tx->dqo.qpl->id;\n\t\t\tcomp_ring_size = priv->tx_desc_cnt;\n\t\t}\n\t\tcmd.create_tx_queue.queue_page_list_id = cpu_to_be32(qpl_id);\n\t\tcmd.create_tx_queue.tx_ring_size =\n\t\t\tcpu_to_be16(priv->tx_desc_cnt);\n\t\tcmd.create_tx_queue.tx_comp_ring_addr =\n\t\t\tcpu_to_be64(tx->complq_bus_dqo);\n\t\tcmd.create_tx_queue.tx_comp_ring_size =\n\t\t\tcpu_to_be16(comp_ring_size);\n\t}\n\n\treturn gve_adminq_issue_cmd(priv, &cmd);\n}\n\nint gve_adminq_create_tx_queues(struct gve_priv *priv, u32 start_id, u32 num_queues)\n{\n\tint err;\n\tint i;\n\n\tfor (i = start_id; i < start_id + num_queues; i++) {\n\t\terr = gve_adminq_create_tx_queue(priv, i);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn gve_adminq_kick_and_wait(priv);\n}\n\nstatic int gve_adminq_create_rx_queue(struct gve_priv *priv, u32 queue_index)\n{\n\tstruct gve_rx_ring *rx = &priv->rx[queue_index];\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_CREATE_RX_QUEUE);\n\tcmd.create_rx_queue = (struct gve_adminq_create_rx_queue) {\n\t\t.queue_id = cpu_to_be32(queue_index),\n\t\t.ntfy_id = cpu_to_be32(rx->ntfy_id),\n\t\t.queue_resources_addr = cpu_to_be64(rx->q_resources_bus),\n\t};\n\n\tif (gve_is_gqi(priv)) {\n\t\tu32 qpl_id = priv->queue_format == GVE_GQI_RDA_FORMAT ?\n\t\t\tGVE_RAW_ADDRESSING_QPL_ID : rx->data.qpl->id;\n\n\t\tcmd.create_rx_queue.rx_desc_ring_addr =\n\t\t\tcpu_to_be64(rx->desc.bus),\n\t\tcmd.create_rx_queue.rx_data_ring_addr =\n\t\t\tcpu_to_be64(rx->data.data_bus),\n\t\tcmd.create_rx_queue.index = cpu_to_be32(queue_index);\n\t\tcmd.create_rx_queue.queue_page_list_id = cpu_to_be32(qpl_id);\n\t\tcmd.create_rx_queue.packet_buffer_size = cpu_to_be16(rx->packet_buffer_size);\n\t} else {\n\t\tu16 rx_buff_ring_entries;\n\t\tu32 qpl_id = 0;\n\n\t\tif (priv->queue_format == GVE_DQO_RDA_FORMAT) {\n\t\t\tqpl_id = GVE_RAW_ADDRESSING_QPL_ID;\n\t\t\trx_buff_ring_entries =\n\t\t\t\tpriv->options_dqo_rda.rx_buff_ring_entries;\n\t\t} else {\n\t\t\tqpl_id = rx->dqo.qpl->id;\n\t\t\trx_buff_ring_entries = priv->rx_desc_cnt;\n\t\t}\n\t\tcmd.create_rx_queue.queue_page_list_id = cpu_to_be32(qpl_id);\n\t\tcmd.create_rx_queue.rx_ring_size =\n\t\t\tcpu_to_be16(priv->rx_desc_cnt);\n\t\tcmd.create_rx_queue.rx_desc_ring_addr =\n\t\t\tcpu_to_be64(rx->dqo.complq.bus);\n\t\tcmd.create_rx_queue.rx_data_ring_addr =\n\t\t\tcpu_to_be64(rx->dqo.bufq.bus);\n\t\tcmd.create_rx_queue.packet_buffer_size =\n\t\t\tcpu_to_be16(priv->data_buffer_size_dqo);\n\t\tcmd.create_rx_queue.rx_buff_ring_size =\n\t\t\tcpu_to_be16(rx_buff_ring_entries);\n\t\tcmd.create_rx_queue.enable_rsc =\n\t\t\t!!(priv->dev->features & NETIF_F_LRO);\n\t}\n\n\treturn gve_adminq_issue_cmd(priv, &cmd);\n}\n\nint gve_adminq_create_rx_queues(struct gve_priv *priv, u32 num_queues)\n{\n\tint err;\n\tint i;\n\n\tfor (i = 0; i < num_queues; i++) {\n\t\terr = gve_adminq_create_rx_queue(priv, i);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn gve_adminq_kick_and_wait(priv);\n}\n\nstatic int gve_adminq_destroy_tx_queue(struct gve_priv *priv, u32 queue_index)\n{\n\tunion gve_adminq_command cmd;\n\tint err;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_DESTROY_TX_QUEUE);\n\tcmd.destroy_tx_queue = (struct gve_adminq_destroy_tx_queue) {\n\t\t.queue_id = cpu_to_be32(queue_index),\n\t};\n\n\terr = gve_adminq_issue_cmd(priv, &cmd);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nint gve_adminq_destroy_tx_queues(struct gve_priv *priv, u32 start_id, u32 num_queues)\n{\n\tint err;\n\tint i;\n\n\tfor (i = start_id; i < start_id + num_queues; i++) {\n\t\terr = gve_adminq_destroy_tx_queue(priv, i);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn gve_adminq_kick_and_wait(priv);\n}\n\nstatic int gve_adminq_destroy_rx_queue(struct gve_priv *priv, u32 queue_index)\n{\n\tunion gve_adminq_command cmd;\n\tint err;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_DESTROY_RX_QUEUE);\n\tcmd.destroy_rx_queue = (struct gve_adminq_destroy_rx_queue) {\n\t\t.queue_id = cpu_to_be32(queue_index),\n\t};\n\n\terr = gve_adminq_issue_cmd(priv, &cmd);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nint gve_adminq_destroy_rx_queues(struct gve_priv *priv, u32 num_queues)\n{\n\tint err;\n\tint i;\n\n\tfor (i = 0; i < num_queues; i++) {\n\t\terr = gve_adminq_destroy_rx_queue(priv, i);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn gve_adminq_kick_and_wait(priv);\n}\n\nstatic int gve_set_desc_cnt(struct gve_priv *priv,\n\t\t\t    struct gve_device_descriptor *descriptor)\n{\n\tpriv->tx_desc_cnt = be16_to_cpu(descriptor->tx_queue_entries);\n\tif (priv->tx_desc_cnt * sizeof(priv->tx->desc[0]) < PAGE_SIZE) {\n\t\tdev_err(&priv->pdev->dev, \"Tx desc count %d too low\\n\",\n\t\t\tpriv->tx_desc_cnt);\n\t\treturn -EINVAL;\n\t}\n\tpriv->rx_desc_cnt = be16_to_cpu(descriptor->rx_queue_entries);\n\tif (priv->rx_desc_cnt * sizeof(priv->rx->desc.desc_ring[0])\n\t    < PAGE_SIZE) {\n\t\tdev_err(&priv->pdev->dev, \"Rx desc count %d too low\\n\",\n\t\t\tpriv->rx_desc_cnt);\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int\ngve_set_desc_cnt_dqo(struct gve_priv *priv,\n\t\t     const struct gve_device_descriptor *descriptor,\n\t\t     const struct gve_device_option_dqo_rda *dev_op_dqo_rda)\n{\n\tpriv->tx_desc_cnt = be16_to_cpu(descriptor->tx_queue_entries);\n\tpriv->rx_desc_cnt = be16_to_cpu(descriptor->rx_queue_entries);\n\n\tif (priv->queue_format == GVE_DQO_QPL_FORMAT)\n\t\treturn 0;\n\n\tpriv->options_dqo_rda.tx_comp_ring_entries =\n\t\tbe16_to_cpu(dev_op_dqo_rda->tx_comp_ring_entries);\n\tpriv->options_dqo_rda.rx_buff_ring_entries =\n\t\tbe16_to_cpu(dev_op_dqo_rda->rx_buff_ring_entries);\n\n\treturn 0;\n}\n\nstatic void gve_enable_supported_features(struct gve_priv *priv,\n\t\t\t\t\t  u32 supported_features_mask,\n\t\t\t\t\t  const struct gve_device_option_jumbo_frames\n\t\t\t\t\t  *dev_op_jumbo_frames,\n\t\t\t\t\t  const struct gve_device_option_dqo_qpl\n\t\t\t\t\t  *dev_op_dqo_qpl)\n{\n\t \n\tif (dev_op_jumbo_frames &&\n\t    (supported_features_mask & GVE_SUP_JUMBO_FRAMES_MASK)) {\n\t\tdev_info(&priv->pdev->dev,\n\t\t\t \"JUMBO FRAMES device option enabled.\\n\");\n\t\tpriv->dev->max_mtu = be16_to_cpu(dev_op_jumbo_frames->max_mtu);\n\t}\n\n\t \n\tif (dev_op_dqo_qpl) {\n\t\tpriv->tx_pages_per_qpl =\n\t\t\tbe16_to_cpu(dev_op_dqo_qpl->tx_pages_per_qpl);\n\t\tpriv->rx_pages_per_qpl =\n\t\t\tbe16_to_cpu(dev_op_dqo_qpl->rx_pages_per_qpl);\n\t\tif (priv->tx_pages_per_qpl == 0)\n\t\t\tpriv->tx_pages_per_qpl = DQO_QPL_DEFAULT_TX_PAGES;\n\t\tif (priv->rx_pages_per_qpl == 0)\n\t\t\tpriv->rx_pages_per_qpl = DQO_QPL_DEFAULT_RX_PAGES;\n\t}\n}\n\nint gve_adminq_describe_device(struct gve_priv *priv)\n{\n\tstruct gve_device_option_jumbo_frames *dev_op_jumbo_frames = NULL;\n\tstruct gve_device_option_gqi_rda *dev_op_gqi_rda = NULL;\n\tstruct gve_device_option_gqi_qpl *dev_op_gqi_qpl = NULL;\n\tstruct gve_device_option_dqo_rda *dev_op_dqo_rda = NULL;\n\tstruct gve_device_option_dqo_qpl *dev_op_dqo_qpl = NULL;\n\tstruct gve_device_descriptor *descriptor;\n\tu32 supported_features_mask = 0;\n\tunion gve_adminq_command cmd;\n\tdma_addr_t descriptor_bus;\n\tint err = 0;\n\tu8 *mac;\n\tu16 mtu;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tdescriptor = dma_alloc_coherent(&priv->pdev->dev, PAGE_SIZE,\n\t\t\t\t\t&descriptor_bus, GFP_KERNEL);\n\tif (!descriptor)\n\t\treturn -ENOMEM;\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_DESCRIBE_DEVICE);\n\tcmd.describe_device.device_descriptor_addr =\n\t\t\t\t\t\tcpu_to_be64(descriptor_bus);\n\tcmd.describe_device.device_descriptor_version =\n\t\t\tcpu_to_be32(GVE_ADMINQ_DEVICE_DESCRIPTOR_VERSION);\n\tcmd.describe_device.available_length = cpu_to_be32(PAGE_SIZE);\n\n\terr = gve_adminq_execute_cmd(priv, &cmd);\n\tif (err)\n\t\tgoto free_device_descriptor;\n\n\terr = gve_process_device_options(priv, descriptor, &dev_op_gqi_rda,\n\t\t\t\t\t &dev_op_gqi_qpl, &dev_op_dqo_rda,\n\t\t\t\t\t &dev_op_jumbo_frames,\n\t\t\t\t\t &dev_op_dqo_qpl);\n\tif (err)\n\t\tgoto free_device_descriptor;\n\n\t \n\tif (dev_op_dqo_rda) {\n\t\tpriv->queue_format = GVE_DQO_RDA_FORMAT;\n\t\tdev_info(&priv->pdev->dev,\n\t\t\t \"Driver is running with DQO RDA queue format.\\n\");\n\t\tsupported_features_mask =\n\t\t\tbe32_to_cpu(dev_op_dqo_rda->supported_features_mask);\n\t} else if (dev_op_dqo_qpl) {\n\t\tpriv->queue_format = GVE_DQO_QPL_FORMAT;\n\t\tsupported_features_mask =\n\t\t\tbe32_to_cpu(dev_op_dqo_qpl->supported_features_mask);\n\t}  else if (dev_op_gqi_rda) {\n\t\tpriv->queue_format = GVE_GQI_RDA_FORMAT;\n\t\tdev_info(&priv->pdev->dev,\n\t\t\t \"Driver is running with GQI RDA queue format.\\n\");\n\t\tsupported_features_mask =\n\t\t\tbe32_to_cpu(dev_op_gqi_rda->supported_features_mask);\n\t} else if (priv->queue_format == GVE_GQI_RDA_FORMAT) {\n\t\tdev_info(&priv->pdev->dev,\n\t\t\t \"Driver is running with GQI RDA queue format.\\n\");\n\t} else {\n\t\tpriv->queue_format = GVE_GQI_QPL_FORMAT;\n\t\tif (dev_op_gqi_qpl)\n\t\t\tsupported_features_mask =\n\t\t\t\tbe32_to_cpu(dev_op_gqi_qpl->supported_features_mask);\n\t\tdev_info(&priv->pdev->dev,\n\t\t\t \"Driver is running with GQI QPL queue format.\\n\");\n\t}\n\tif (gve_is_gqi(priv)) {\n\t\terr = gve_set_desc_cnt(priv, descriptor);\n\t} else {\n\t\t \n\t\tpriv->dev->hw_features |= NETIF_F_LRO;\n\t\terr = gve_set_desc_cnt_dqo(priv, descriptor, dev_op_dqo_rda);\n\t}\n\tif (err)\n\t\tgoto free_device_descriptor;\n\n\tpriv->max_registered_pages =\n\t\t\t\tbe64_to_cpu(descriptor->max_registered_pages);\n\tmtu = be16_to_cpu(descriptor->mtu);\n\tif (mtu < ETH_MIN_MTU) {\n\t\tdev_err(&priv->pdev->dev, \"MTU %d below minimum MTU\\n\", mtu);\n\t\terr = -EINVAL;\n\t\tgoto free_device_descriptor;\n\t}\n\tpriv->dev->max_mtu = mtu;\n\tpriv->num_event_counters = be16_to_cpu(descriptor->counters);\n\teth_hw_addr_set(priv->dev, descriptor->mac);\n\tmac = descriptor->mac;\n\tdev_info(&priv->pdev->dev, \"MAC addr: %pM\\n\", mac);\n\tpriv->tx_pages_per_qpl = be16_to_cpu(descriptor->tx_pages_per_qpl);\n\tpriv->rx_data_slot_cnt = be16_to_cpu(descriptor->rx_pages_per_qpl);\n\n\tif (gve_is_gqi(priv) && priv->rx_data_slot_cnt < priv->rx_desc_cnt) {\n\t\tdev_err(&priv->pdev->dev, \"rx_data_slot_cnt cannot be smaller than rx_desc_cnt, setting rx_desc_cnt down to %d.\\n\",\n\t\t\tpriv->rx_data_slot_cnt);\n\t\tpriv->rx_desc_cnt = priv->rx_data_slot_cnt;\n\t}\n\tpriv->default_num_queues = be16_to_cpu(descriptor->default_num_queues);\n\n\tgve_enable_supported_features(priv, supported_features_mask,\n\t\t\t\t      dev_op_jumbo_frames, dev_op_dqo_qpl);\n\nfree_device_descriptor:\n\tdma_free_coherent(&priv->pdev->dev, PAGE_SIZE, descriptor,\n\t\t\t  descriptor_bus);\n\treturn err;\n}\n\nint gve_adminq_register_page_list(struct gve_priv *priv,\n\t\t\t\t  struct gve_queue_page_list *qpl)\n{\n\tstruct device *hdev = &priv->pdev->dev;\n\tu32 num_entries = qpl->num_entries;\n\tu32 size = num_entries * sizeof(qpl->page_buses[0]);\n\tunion gve_adminq_command cmd;\n\tdma_addr_t page_list_bus;\n\t__be64 *page_list;\n\tint err;\n\tint i;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tpage_list = dma_alloc_coherent(hdev, size, &page_list_bus, GFP_KERNEL);\n\tif (!page_list)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_entries; i++)\n\t\tpage_list[i] = cpu_to_be64(qpl->page_buses[i]);\n\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_REGISTER_PAGE_LIST);\n\tcmd.reg_page_list = (struct gve_adminq_register_page_list) {\n\t\t.page_list_id = cpu_to_be32(qpl->id),\n\t\t.num_pages = cpu_to_be32(num_entries),\n\t\t.page_address_list_addr = cpu_to_be64(page_list_bus),\n\t};\n\n\terr = gve_adminq_execute_cmd(priv, &cmd);\n\tdma_free_coherent(hdev, size, page_list, page_list_bus);\n\treturn err;\n}\n\nint gve_adminq_unregister_page_list(struct gve_priv *priv, u32 page_list_id)\n{\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_UNREGISTER_PAGE_LIST);\n\tcmd.unreg_page_list = (struct gve_adminq_unregister_page_list) {\n\t\t.page_list_id = cpu_to_be32(page_list_id),\n\t};\n\n\treturn gve_adminq_execute_cmd(priv, &cmd);\n}\n\nint gve_adminq_set_mtu(struct gve_priv *priv, u64 mtu)\n{\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_SET_DRIVER_PARAMETER);\n\tcmd.set_driver_param = (struct gve_adminq_set_driver_parameter) {\n\t\t.parameter_type = cpu_to_be32(GVE_SET_PARAM_MTU),\n\t\t.parameter_value = cpu_to_be64(mtu),\n\t};\n\n\treturn gve_adminq_execute_cmd(priv, &cmd);\n}\n\nint gve_adminq_report_stats(struct gve_priv *priv, u64 stats_report_len,\n\t\t\t    dma_addr_t stats_report_addr, u64 interval)\n{\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_REPORT_STATS);\n\tcmd.report_stats = (struct gve_adminq_report_stats) {\n\t\t.stats_report_len = cpu_to_be64(stats_report_len),\n\t\t.stats_report_addr = cpu_to_be64(stats_report_addr),\n\t\t.interval = cpu_to_be64(interval),\n\t};\n\n\treturn gve_adminq_execute_cmd(priv, &cmd);\n}\n\nint gve_adminq_verify_driver_compatibility(struct gve_priv *priv,\n\t\t\t\t\t   u64 driver_info_len,\n\t\t\t\t\t   dma_addr_t driver_info_addr)\n{\n\tunion gve_adminq_command cmd;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_VERIFY_DRIVER_COMPATIBILITY);\n\tcmd.verify_driver_compatibility = (struct gve_adminq_verify_driver_compatibility) {\n\t\t.driver_info_len = cpu_to_be64(driver_info_len),\n\t\t.driver_info_addr = cpu_to_be64(driver_info_addr),\n\t};\n\n\treturn gve_adminq_execute_cmd(priv, &cmd);\n}\n\nint gve_adminq_report_link_speed(struct gve_priv *priv)\n{\n\tunion gve_adminq_command gvnic_cmd;\n\tdma_addr_t link_speed_region_bus;\n\t__be64 *link_speed_region;\n\tint err;\n\n\tlink_speed_region =\n\t\tdma_alloc_coherent(&priv->pdev->dev, sizeof(*link_speed_region),\n\t\t\t\t   &link_speed_region_bus, GFP_KERNEL);\n\n\tif (!link_speed_region)\n\t\treturn -ENOMEM;\n\n\tmemset(&gvnic_cmd, 0, sizeof(gvnic_cmd));\n\tgvnic_cmd.opcode = cpu_to_be32(GVE_ADMINQ_REPORT_LINK_SPEED);\n\tgvnic_cmd.report_link_speed.link_speed_address =\n\t\tcpu_to_be64(link_speed_region_bus);\n\n\terr = gve_adminq_execute_cmd(priv, &gvnic_cmd);\n\n\tpriv->link_speed = be64_to_cpu(*link_speed_region);\n\tdma_free_coherent(&priv->pdev->dev, sizeof(*link_speed_region), link_speed_region,\n\t\t\t  link_speed_region_bus);\n\treturn err;\n}\n\nint gve_adminq_get_ptype_map_dqo(struct gve_priv *priv,\n\t\t\t\t struct gve_ptype_lut *ptype_lut)\n{\n\tstruct gve_ptype_map *ptype_map;\n\tunion gve_adminq_command cmd;\n\tdma_addr_t ptype_map_bus;\n\tint err = 0;\n\tint i;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tptype_map = dma_alloc_coherent(&priv->pdev->dev, sizeof(*ptype_map),\n\t\t\t\t       &ptype_map_bus, GFP_KERNEL);\n\tif (!ptype_map)\n\t\treturn -ENOMEM;\n\n\tcmd.opcode = cpu_to_be32(GVE_ADMINQ_GET_PTYPE_MAP);\n\tcmd.get_ptype_map = (struct gve_adminq_get_ptype_map) {\n\t\t.ptype_map_len = cpu_to_be64(sizeof(*ptype_map)),\n\t\t.ptype_map_addr = cpu_to_be64(ptype_map_bus),\n\t};\n\n\terr = gve_adminq_execute_cmd(priv, &cmd);\n\tif (err)\n\t\tgoto err;\n\n\t \n\tfor (i = 0; i < GVE_NUM_PTYPES; i++) {\n\t\tptype_lut->ptypes[i].l3_type =\n\t\t\tptype_map->ptypes[i].l3_type;\n\t\tptype_lut->ptypes[i].l4_type =\n\t\t\tptype_map->ptypes[i].l4_type;\n\t}\nerr:\n\tdma_free_coherent(&priv->pdev->dev, sizeof(*ptype_map), ptype_map,\n\t\t\t  ptype_map_bus);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}