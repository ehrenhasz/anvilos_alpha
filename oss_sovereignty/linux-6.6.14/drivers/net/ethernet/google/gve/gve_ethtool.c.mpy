{
  "module_name": "gve_ethtool.c",
  "hash_id": "fc525a5aa0a66701c01548f8fa7f41578126400642476c3c11ac8c01774a9b61",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/google/gve/gve_ethtool.c",
  "human_readable_source": "\n \n\n#include <linux/ethtool.h>\n#include <linux/rtnetlink.h>\n#include \"gve.h\"\n#include \"gve_adminq.h\"\n#include \"gve_dqo.h\"\n\nstatic void gve_get_drvinfo(struct net_device *netdev,\n\t\t\t    struct ethtool_drvinfo *info)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\tstrscpy(info->driver, gve_driver_name, sizeof(info->driver));\n\tstrscpy(info->version, gve_version_str, sizeof(info->version));\n\tstrscpy(info->bus_info, pci_name(priv->pdev), sizeof(info->bus_info));\n}\n\nstatic void gve_set_msglevel(struct net_device *netdev, u32 value)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\tpriv->msg_enable = value;\n}\n\nstatic u32 gve_get_msglevel(struct net_device *netdev)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\treturn priv->msg_enable;\n}\n\n \nstatic const char gve_gstrings_main_stats[][ETH_GSTRING_LEN] = {\n\t\"rx_packets\", \"tx_packets\", \"rx_bytes\", \"tx_bytes\",\n\t\"rx_dropped\", \"tx_dropped\", \"tx_timeouts\",\n\t\"rx_skb_alloc_fail\", \"rx_buf_alloc_fail\", \"rx_desc_err_dropped_pkt\",\n\t\"interface_up_cnt\", \"interface_down_cnt\", \"reset_cnt\",\n\t\"page_alloc_fail\", \"dma_mapping_error\", \"stats_report_trigger_cnt\",\n};\n\nstatic const char gve_gstrings_rx_stats[][ETH_GSTRING_LEN] = {\n\t\"rx_posted_desc[%u]\", \"rx_completed_desc[%u]\", \"rx_consumed_desc[%u]\", \"rx_bytes[%u]\",\n\t\"rx_cont_packet_cnt[%u]\", \"rx_frag_flip_cnt[%u]\", \"rx_frag_copy_cnt[%u]\",\n\t\"rx_frag_alloc_cnt[%u]\",\n\t\"rx_dropped_pkt[%u]\", \"rx_copybreak_pkt[%u]\", \"rx_copied_pkt[%u]\",\n\t\"rx_queue_drop_cnt[%u]\", \"rx_no_buffers_posted[%u]\",\n\t\"rx_drops_packet_over_mru[%u]\", \"rx_drops_invalid_checksum[%u]\",\n\t\"rx_xdp_aborted[%u]\", \"rx_xdp_drop[%u]\", \"rx_xdp_pass[%u]\",\n\t\"rx_xdp_tx[%u]\", \"rx_xdp_redirect[%u]\",\n\t\"rx_xdp_tx_errors[%u]\", \"rx_xdp_redirect_errors[%u]\", \"rx_xdp_alloc_fails[%u]\",\n};\n\nstatic const char gve_gstrings_tx_stats[][ETH_GSTRING_LEN] = {\n\t\"tx_posted_desc[%u]\", \"tx_completed_desc[%u]\", \"tx_consumed_desc[%u]\", \"tx_bytes[%u]\",\n\t\"tx_wake[%u]\", \"tx_stop[%u]\", \"tx_event_counter[%u]\",\n\t\"tx_dma_mapping_error[%u]\", \"tx_xsk_wakeup[%u]\",\n\t\"tx_xsk_done[%u]\", \"tx_xsk_sent[%u]\", \"tx_xdp_xmit[%u]\", \"tx_xdp_xmit_errors[%u]\"\n};\n\nstatic const char gve_gstrings_adminq_stats[][ETH_GSTRING_LEN] = {\n\t\"adminq_prod_cnt\", \"adminq_cmd_fail\", \"adminq_timeouts\",\n\t\"adminq_describe_device_cnt\", \"adminq_cfg_device_resources_cnt\",\n\t\"adminq_register_page_list_cnt\", \"adminq_unregister_page_list_cnt\",\n\t\"adminq_create_tx_queue_cnt\", \"adminq_create_rx_queue_cnt\",\n\t\"adminq_destroy_tx_queue_cnt\", \"adminq_destroy_rx_queue_cnt\",\n\t\"adminq_dcfg_device_resources_cnt\", \"adminq_set_driver_parameter_cnt\",\n\t\"adminq_report_stats_cnt\", \"adminq_report_link_speed_cnt\"\n};\n\nstatic const char gve_gstrings_priv_flags[][ETH_GSTRING_LEN] = {\n\t\"report-stats\",\n};\n\n#define GVE_MAIN_STATS_LEN  ARRAY_SIZE(gve_gstrings_main_stats)\n#define GVE_ADMINQ_STATS_LEN  ARRAY_SIZE(gve_gstrings_adminq_stats)\n#define NUM_GVE_TX_CNTS\tARRAY_SIZE(gve_gstrings_tx_stats)\n#define NUM_GVE_RX_CNTS\tARRAY_SIZE(gve_gstrings_rx_stats)\n#define GVE_PRIV_FLAGS_STR_LEN ARRAY_SIZE(gve_gstrings_priv_flags)\n\nstatic void gve_get_strings(struct net_device *netdev, u32 stringset, u8 *data)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tchar *s = (char *)data;\n\tint num_tx_queues;\n\tint i, j;\n\n\tnum_tx_queues = gve_num_tx_queues(priv);\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tmemcpy(s, *gve_gstrings_main_stats,\n\t\t       sizeof(gve_gstrings_main_stats));\n\t\ts += sizeof(gve_gstrings_main_stats);\n\n\t\tfor (i = 0; i < priv->rx_cfg.num_queues; i++) {\n\t\t\tfor (j = 0; j < NUM_GVE_RX_CNTS; j++) {\n\t\t\t\tsnprintf(s, ETH_GSTRING_LEN,\n\t\t\t\t\t gve_gstrings_rx_stats[j], i);\n\t\t\t\ts += ETH_GSTRING_LEN;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0; i < num_tx_queues; i++) {\n\t\t\tfor (j = 0; j < NUM_GVE_TX_CNTS; j++) {\n\t\t\t\tsnprintf(s, ETH_GSTRING_LEN,\n\t\t\t\t\t gve_gstrings_tx_stats[j], i);\n\t\t\t\ts += ETH_GSTRING_LEN;\n\t\t\t}\n\t\t}\n\n\t\tmemcpy(s, *gve_gstrings_adminq_stats,\n\t\t       sizeof(gve_gstrings_adminq_stats));\n\t\ts += sizeof(gve_gstrings_adminq_stats);\n\t\tbreak;\n\n\tcase ETH_SS_PRIV_FLAGS:\n\t\tmemcpy(s, *gve_gstrings_priv_flags,\n\t\t       sizeof(gve_gstrings_priv_flags));\n\t\ts += sizeof(gve_gstrings_priv_flags);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic int gve_get_sset_count(struct net_device *netdev, int sset)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tint num_tx_queues;\n\n\tnum_tx_queues = gve_num_tx_queues(priv);\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn GVE_MAIN_STATS_LEN + GVE_ADMINQ_STATS_LEN +\n\t\t       (priv->rx_cfg.num_queues * NUM_GVE_RX_CNTS) +\n\t\t       (num_tx_queues * NUM_GVE_TX_CNTS);\n\tcase ETH_SS_PRIV_FLAGS:\n\t\treturn GVE_PRIV_FLAGS_STR_LEN;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void\ngve_get_ethtool_stats(struct net_device *netdev,\n\t\t      struct ethtool_stats *stats, u64 *data)\n{\n\tu64 tmp_rx_pkts, tmp_rx_bytes, tmp_rx_skb_alloc_fail,\n\t\ttmp_rx_buf_alloc_fail, tmp_rx_desc_err_dropped_pkt,\n\t\ttmp_tx_pkts, tmp_tx_bytes;\n\tu64 rx_buf_alloc_fail, rx_desc_err_dropped_pkt, rx_pkts,\n\t\trx_skb_alloc_fail, rx_bytes, tx_pkts, tx_bytes, tx_dropped;\n\tint stats_idx, base_stats_idx, max_stats_idx;\n\tstruct stats *report_stats;\n\tint *rx_qid_to_stats_idx;\n\tint *tx_qid_to_stats_idx;\n\tstruct gve_priv *priv;\n\tbool skip_nic_stats;\n\tunsigned int start;\n\tint num_tx_queues;\n\tint ring;\n\tint i, j;\n\n\tASSERT_RTNL();\n\n\tpriv = netdev_priv(netdev);\n\tnum_tx_queues = gve_num_tx_queues(priv);\n\treport_stats = priv->stats_report->stats;\n\trx_qid_to_stats_idx = kmalloc_array(priv->rx_cfg.num_queues,\n\t\t\t\t\t    sizeof(int), GFP_KERNEL);\n\tif (!rx_qid_to_stats_idx)\n\t\treturn;\n\ttx_qid_to_stats_idx = kmalloc_array(num_tx_queues,\n\t\t\t\t\t    sizeof(int), GFP_KERNEL);\n\tif (!tx_qid_to_stats_idx) {\n\t\tkfree(rx_qid_to_stats_idx);\n\t\treturn;\n\t}\n\tfor (rx_pkts = 0, rx_bytes = 0, rx_skb_alloc_fail = 0,\n\t     rx_buf_alloc_fail = 0, rx_desc_err_dropped_pkt = 0, ring = 0;\n\t     ring < priv->rx_cfg.num_queues; ring++) {\n\t\tif (priv->rx) {\n\t\t\tdo {\n\t\t\t\tstruct gve_rx_ring *rx = &priv->rx[ring];\n\n\t\t\t\tstart =\n\t\t\t\t  u64_stats_fetch_begin(&priv->rx[ring].statss);\n\t\t\t\ttmp_rx_pkts = rx->rpackets;\n\t\t\t\ttmp_rx_bytes = rx->rbytes;\n\t\t\t\ttmp_rx_skb_alloc_fail = rx->rx_skb_alloc_fail;\n\t\t\t\ttmp_rx_buf_alloc_fail = rx->rx_buf_alloc_fail;\n\t\t\t\ttmp_rx_desc_err_dropped_pkt =\n\t\t\t\t\trx->rx_desc_err_dropped_pkt;\n\t\t\t} while (u64_stats_fetch_retry(&priv->rx[ring].statss,\n\t\t\t\t\t\t       start));\n\t\t\trx_pkts += tmp_rx_pkts;\n\t\t\trx_bytes += tmp_rx_bytes;\n\t\t\trx_skb_alloc_fail += tmp_rx_skb_alloc_fail;\n\t\t\trx_buf_alloc_fail += tmp_rx_buf_alloc_fail;\n\t\t\trx_desc_err_dropped_pkt += tmp_rx_desc_err_dropped_pkt;\n\t\t}\n\t}\n\tfor (tx_pkts = 0, tx_bytes = 0, tx_dropped = 0, ring = 0;\n\t     ring < num_tx_queues; ring++) {\n\t\tif (priv->tx) {\n\t\t\tdo {\n\t\t\t\tstart =\n\t\t\t\t  u64_stats_fetch_begin(&priv->tx[ring].statss);\n\t\t\t\ttmp_tx_pkts = priv->tx[ring].pkt_done;\n\t\t\t\ttmp_tx_bytes = priv->tx[ring].bytes_done;\n\t\t\t} while (u64_stats_fetch_retry(&priv->tx[ring].statss,\n\t\t\t\t\t\t       start));\n\t\t\ttx_pkts += tmp_tx_pkts;\n\t\t\ttx_bytes += tmp_tx_bytes;\n\t\t\ttx_dropped += priv->tx[ring].dropped_pkt;\n\t\t}\n\t}\n\n\ti = 0;\n\tdata[i++] = rx_pkts;\n\tdata[i++] = tx_pkts;\n\tdata[i++] = rx_bytes;\n\tdata[i++] = tx_bytes;\n\t \n\tdata[i++] = rx_skb_alloc_fail + rx_buf_alloc_fail +\n\t\t    rx_desc_err_dropped_pkt;\n\tdata[i++] = tx_dropped;\n\tdata[i++] = priv->tx_timeo_cnt;\n\tdata[i++] = rx_skb_alloc_fail;\n\tdata[i++] = rx_buf_alloc_fail;\n\tdata[i++] = rx_desc_err_dropped_pkt;\n\tdata[i++] = priv->interface_up_cnt;\n\tdata[i++] = priv->interface_down_cnt;\n\tdata[i++] = priv->reset_cnt;\n\tdata[i++] = priv->page_alloc_fail;\n\tdata[i++] = priv->dma_mapping_error;\n\tdata[i++] = priv->stats_report_trigger_cnt;\n\ti = GVE_MAIN_STATS_LEN;\n\n\t \n\tbase_stats_idx = GVE_TX_STATS_REPORT_NUM * num_tx_queues +\n\t\tGVE_RX_STATS_REPORT_NUM * priv->rx_cfg.num_queues;\n\tmax_stats_idx = NIC_RX_STATS_REPORT_NUM * priv->rx_cfg.num_queues +\n\t\tbase_stats_idx;\n\t \n\tskip_nic_stats = false;\n\tfor (stats_idx = base_stats_idx; stats_idx < max_stats_idx;\n\t\tstats_idx += NIC_RX_STATS_REPORT_NUM) {\n\t\tu32 stat_name = be32_to_cpu(report_stats[stats_idx].stat_name);\n\t\tu32 queue_id = be32_to_cpu(report_stats[stats_idx].queue_id);\n\n\t\tif (stat_name == 0) {\n\t\t\t \n\t\t\tskip_nic_stats = true;\n\t\t\tbreak;\n\t\t}\n\t\trx_qid_to_stats_idx[queue_id] = stats_idx;\n\t}\n\t \n\tif (priv->rx) {\n\t\tfor (ring = 0; ring < priv->rx_cfg.num_queues; ring++) {\n\t\t\tstruct gve_rx_ring *rx = &priv->rx[ring];\n\n\t\t\tdata[i++] = rx->fill_cnt;\n\t\t\tdata[i++] = rx->cnt;\n\t\t\tdata[i++] = rx->fill_cnt - rx->cnt;\n\t\t\tdo {\n\t\t\t\tstart =\n\t\t\t\t  u64_stats_fetch_begin(&priv->rx[ring].statss);\n\t\t\t\ttmp_rx_bytes = rx->rbytes;\n\t\t\t\ttmp_rx_skb_alloc_fail = rx->rx_skb_alloc_fail;\n\t\t\t\ttmp_rx_buf_alloc_fail = rx->rx_buf_alloc_fail;\n\t\t\t\ttmp_rx_desc_err_dropped_pkt =\n\t\t\t\t\trx->rx_desc_err_dropped_pkt;\n\t\t\t} while (u64_stats_fetch_retry(&priv->rx[ring].statss,\n\t\t\t\t\t\t       start));\n\t\t\tdata[i++] = tmp_rx_bytes;\n\t\t\tdata[i++] = rx->rx_cont_packet_cnt;\n\t\t\tdata[i++] = rx->rx_frag_flip_cnt;\n\t\t\tdata[i++] = rx->rx_frag_copy_cnt;\n\t\t\tdata[i++] = rx->rx_frag_alloc_cnt;\n\t\t\t \n\t\t\tdata[i++] = tmp_rx_skb_alloc_fail +\n\t\t\t\ttmp_rx_buf_alloc_fail +\n\t\t\t\ttmp_rx_desc_err_dropped_pkt;\n\t\t\tdata[i++] = rx->rx_copybreak_pkt;\n\t\t\tdata[i++] = rx->rx_copied_pkt;\n\t\t\t \n\t\t\tif (skip_nic_stats) {\n\t\t\t\t \n\t\t\t\ti += NIC_RX_STATS_REPORT_NUM;\n\t\t\t} else {\n\t\t\t\tstats_idx = rx_qid_to_stats_idx[ring];\n\t\t\t\tfor (j = 0; j < NIC_RX_STATS_REPORT_NUM; j++) {\n\t\t\t\t\tu64 value =\n\t\t\t\t\t\tbe64_to_cpu(report_stats[stats_idx + j].value);\n\n\t\t\t\t\tdata[i++] = value;\n\t\t\t\t}\n\t\t\t}\n\t\t\t \n\t\t\tdo {\n\t\t\t\tstart =\tu64_stats_fetch_begin(&priv->rx[ring].statss);\n\t\t\t\tfor (j = 0; j < GVE_XDP_ACTIONS; j++)\n\t\t\t\t\tdata[i + j] = rx->xdp_actions[j];\n\t\t\t\tdata[i + j++] = rx->xdp_tx_errors;\n\t\t\t\tdata[i + j++] = rx->xdp_redirect_errors;\n\t\t\t\tdata[i + j++] = rx->xdp_alloc_fails;\n\t\t\t} while (u64_stats_fetch_retry(&priv->rx[ring].statss,\n\t\t\t\t\t\t       start));\n\t\t\ti += GVE_XDP_ACTIONS + 3;  \n\t\t}\n\t} else {\n\t\ti += priv->rx_cfg.num_queues * NUM_GVE_RX_CNTS;\n\t}\n\n\t \n\tbase_stats_idx = max_stats_idx;\n\tmax_stats_idx = NIC_TX_STATS_REPORT_NUM * num_tx_queues +\n\t\tmax_stats_idx;\n\t \n\tskip_nic_stats = false;\n\tfor (stats_idx = base_stats_idx; stats_idx < max_stats_idx;\n\t\tstats_idx += NIC_TX_STATS_REPORT_NUM) {\n\t\tu32 stat_name = be32_to_cpu(report_stats[stats_idx].stat_name);\n\t\tu32 queue_id = be32_to_cpu(report_stats[stats_idx].queue_id);\n\n\t\tif (stat_name == 0) {\n\t\t\t \n\t\t\tskip_nic_stats = true;\n\t\t\tbreak;\n\t\t}\n\t\ttx_qid_to_stats_idx[queue_id] = stats_idx;\n\t}\n\t \n\tif (priv->tx) {\n\t\tfor (ring = 0; ring < num_tx_queues; ring++) {\n\t\t\tstruct gve_tx_ring *tx = &priv->tx[ring];\n\n\t\t\tif (gve_is_gqi(priv)) {\n\t\t\t\tdata[i++] = tx->req;\n\t\t\t\tdata[i++] = tx->done;\n\t\t\t\tdata[i++] = tx->req - tx->done;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tdata[i++] = 0;\n\t\t\t\tdata[i++] = 0;\n\t\t\t\tdata[i++] = tx->dqo_tx.tail - tx->dqo_tx.head;\n\t\t\t}\n\t\t\tdo {\n\t\t\t\tstart =\n\t\t\t\t  u64_stats_fetch_begin(&priv->tx[ring].statss);\n\t\t\t\ttmp_tx_bytes = tx->bytes_done;\n\t\t\t} while (u64_stats_fetch_retry(&priv->tx[ring].statss,\n\t\t\t\t\t\t       start));\n\t\t\tdata[i++] = tmp_tx_bytes;\n\t\t\tdata[i++] = tx->wake_queue;\n\t\t\tdata[i++] = tx->stop_queue;\n\t\t\tdata[i++] = gve_tx_load_event_counter(priv, tx);\n\t\t\tdata[i++] = tx->dma_mapping_error;\n\t\t\t \n\t\t\tif (skip_nic_stats) {\n\t\t\t\t \n\t\t\t\ti += NIC_TX_STATS_REPORT_NUM;\n\t\t\t} else {\n\t\t\t\tstats_idx = tx_qid_to_stats_idx[ring];\n\t\t\t\tfor (j = 0; j < NIC_TX_STATS_REPORT_NUM; j++) {\n\t\t\t\t\tu64 value =\n\t\t\t\t\t\tbe64_to_cpu(report_stats[stats_idx + j].value);\n\t\t\t\t\tdata[i++] = value;\n\t\t\t\t}\n\t\t\t}\n\t\t\t \n\t\t\tdata[i++] = tx->xdp_xsk_wakeup;\n\t\t\tdata[i++] = tx->xdp_xsk_done;\n\t\t\tdo {\n\t\t\t\tstart = u64_stats_fetch_begin(&priv->tx[ring].statss);\n\t\t\t\tdata[i] = tx->xdp_xsk_sent;\n\t\t\t\tdata[i + 1] = tx->xdp_xmit;\n\t\t\t\tdata[i + 2] = tx->xdp_xmit_errors;\n\t\t\t} while (u64_stats_fetch_retry(&priv->tx[ring].statss,\n\t\t\t\t\t\t       start));\n\t\t\ti += 3;  \n\t\t}\n\t} else {\n\t\ti += num_tx_queues * NUM_GVE_TX_CNTS;\n\t}\n\n\tkfree(rx_qid_to_stats_idx);\n\tkfree(tx_qid_to_stats_idx);\n\t \n\tdata[i++] = priv->adminq_prod_cnt;\n\tdata[i++] = priv->adminq_cmd_fail;\n\tdata[i++] = priv->adminq_timeouts;\n\tdata[i++] = priv->adminq_describe_device_cnt;\n\tdata[i++] = priv->adminq_cfg_device_resources_cnt;\n\tdata[i++] = priv->adminq_register_page_list_cnt;\n\tdata[i++] = priv->adminq_unregister_page_list_cnt;\n\tdata[i++] = priv->adminq_create_tx_queue_cnt;\n\tdata[i++] = priv->adminq_create_rx_queue_cnt;\n\tdata[i++] = priv->adminq_destroy_tx_queue_cnt;\n\tdata[i++] = priv->adminq_destroy_rx_queue_cnt;\n\tdata[i++] = priv->adminq_dcfg_device_resources_cnt;\n\tdata[i++] = priv->adminq_set_driver_parameter_cnt;\n\tdata[i++] = priv->adminq_report_stats_cnt;\n\tdata[i++] = priv->adminq_report_link_speed_cnt;\n}\n\nstatic void gve_get_channels(struct net_device *netdev,\n\t\t\t     struct ethtool_channels *cmd)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\tcmd->max_rx = priv->rx_cfg.max_queues;\n\tcmd->max_tx = priv->tx_cfg.max_queues;\n\tcmd->max_other = 0;\n\tcmd->max_combined = 0;\n\tcmd->rx_count = priv->rx_cfg.num_queues;\n\tcmd->tx_count = priv->tx_cfg.num_queues;\n\tcmd->other_count = 0;\n\tcmd->combined_count = 0;\n}\n\nstatic int gve_set_channels(struct net_device *netdev,\n\t\t\t    struct ethtool_channels *cmd)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tstruct gve_queue_config new_tx_cfg = priv->tx_cfg;\n\tstruct gve_queue_config new_rx_cfg = priv->rx_cfg;\n\tstruct ethtool_channels old_settings;\n\tint new_tx = cmd->tx_count;\n\tint new_rx = cmd->rx_count;\n\n\tgve_get_channels(netdev, &old_settings);\n\n\t \n\tif (cmd->combined_count != old_settings.combined_count)\n\t\treturn -EINVAL;\n\n\tif (!new_rx || !new_tx)\n\t\treturn -EINVAL;\n\n\tif (priv->num_xdp_queues &&\n\t    (new_tx != new_rx || (2 * new_tx > priv->tx_cfg.max_queues))) {\n\t\tdev_err(&priv->pdev->dev, \"XDP load failed: The number of configured RX queues should be equal to the number of configured TX queues and the number of configured RX/TX queues should be less than or equal to half the maximum number of RX/TX queues\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!netif_carrier_ok(netdev)) {\n\t\tpriv->tx_cfg.num_queues = new_tx;\n\t\tpriv->rx_cfg.num_queues = new_rx;\n\t\treturn 0;\n\t}\n\n\tnew_tx_cfg.num_queues = new_tx;\n\tnew_rx_cfg.num_queues = new_rx;\n\n\treturn gve_adjust_queues(priv, new_rx_cfg, new_tx_cfg);\n}\n\nstatic void gve_get_ringparam(struct net_device *netdev,\n\t\t\t      struct ethtool_ringparam *cmd,\n\t\t\t      struct kernel_ethtool_ringparam *kernel_cmd,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\tcmd->rx_max_pending = priv->rx_desc_cnt;\n\tcmd->tx_max_pending = priv->tx_desc_cnt;\n\tcmd->rx_pending = priv->rx_desc_cnt;\n\tcmd->tx_pending = priv->tx_desc_cnt;\n}\n\nstatic int gve_user_reset(struct net_device *netdev, u32 *flags)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\tif (*flags == ETH_RESET_ALL) {\n\t\t*flags = 0;\n\t\treturn gve_reset(priv, true);\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int gve_get_tunable(struct net_device *netdev,\n\t\t\t   const struct ethtool_tunable *etuna, void *value)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\tswitch (etuna->id) {\n\tcase ETHTOOL_RX_COPYBREAK:\n\t\t*(u32 *)value = priv->rx_copybreak;\n\t\treturn 0;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int gve_set_tunable(struct net_device *netdev,\n\t\t\t   const struct ethtool_tunable *etuna,\n\t\t\t   const void *value)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tu32 len;\n\n\tswitch (etuna->id) {\n\tcase ETHTOOL_RX_COPYBREAK:\n\t{\n\t\tu32 max_copybreak = gve_is_gqi(priv) ?\n\t\t\t(PAGE_SIZE / 2) : priv->data_buffer_size_dqo;\n\n\t\tlen = *(u32 *)value;\n\t\tif (len > max_copybreak)\n\t\t\treturn -EINVAL;\n\t\tpriv->rx_copybreak = len;\n\t\treturn 0;\n\t}\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic u32 gve_get_priv_flags(struct net_device *netdev)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tu32 ret_flags = 0;\n\n\t \n\tif (priv->ethtool_flags & BIT(0))\n\t\tret_flags |= BIT(0);\n\treturn ret_flags;\n}\n\nstatic int gve_set_priv_flags(struct net_device *netdev, u32 flags)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tu64 ori_flags, new_flags;\n\tint num_tx_queues;\n\n\tnum_tx_queues = gve_num_tx_queues(priv);\n\tori_flags = READ_ONCE(priv->ethtool_flags);\n\tnew_flags = ori_flags;\n\n\t \n\tif (flags & BIT(0))\n\t\tnew_flags |= BIT(0);\n\telse\n\t\tnew_flags &= ~(BIT(0));\n\tpriv->ethtool_flags = new_flags;\n\t \n\tif (flags & BIT(0)) {\n\t\tmod_timer(&priv->stats_report_timer,\n\t\t\t  round_jiffies(jiffies +\n\t\t\t\t\tmsecs_to_jiffies(priv->stats_report_timer_period)));\n\t}\n\t \n\t \n\tif (!(flags & BIT(0)) && (ori_flags & BIT(0))) {\n\t\tint tx_stats_num = GVE_TX_STATS_REPORT_NUM *\n\t\t\tnum_tx_queues;\n\t\tint rx_stats_num = GVE_RX_STATS_REPORT_NUM *\n\t\t\tpriv->rx_cfg.num_queues;\n\n\t\tmemset(priv->stats_report->stats, 0, (tx_stats_num + rx_stats_num) *\n\t\t\t\t   sizeof(struct stats));\n\t\tdel_timer_sync(&priv->stats_report_timer);\n\t}\n\treturn 0;\n}\n\nstatic int gve_get_link_ksettings(struct net_device *netdev,\n\t\t\t\t  struct ethtool_link_ksettings *cmd)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tint err = 0;\n\n\tif (priv->link_speed == 0)\n\t\terr = gve_adminq_report_link_speed(priv);\n\n\tcmd->base.speed = priv->link_speed;\n\n\tcmd->base.duplex = DUPLEX_FULL;\n\n\treturn err;\n}\n\nstatic int gve_get_coalesce(struct net_device *netdev,\n\t\t\t    struct ethtool_coalesce *ec,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_ec,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\n\tif (gve_is_gqi(priv))\n\t\treturn -EOPNOTSUPP;\n\tec->tx_coalesce_usecs = priv->tx_coalesce_usecs;\n\tec->rx_coalesce_usecs = priv->rx_coalesce_usecs;\n\n\treturn 0;\n}\n\nstatic int gve_set_coalesce(struct net_device *netdev,\n\t\t\t    struct ethtool_coalesce *ec,\n\t\t\t    struct kernel_ethtool_coalesce *kernel_ec,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct gve_priv *priv = netdev_priv(netdev);\n\tu32 tx_usecs_orig = priv->tx_coalesce_usecs;\n\tu32 rx_usecs_orig = priv->rx_coalesce_usecs;\n\tint idx;\n\n\tif (gve_is_gqi(priv))\n\t\treturn -EOPNOTSUPP;\n\n\tif (ec->tx_coalesce_usecs > GVE_MAX_ITR_INTERVAL_DQO ||\n\t    ec->rx_coalesce_usecs > GVE_MAX_ITR_INTERVAL_DQO)\n\t\treturn -EINVAL;\n\tpriv->tx_coalesce_usecs = ec->tx_coalesce_usecs;\n\tpriv->rx_coalesce_usecs = ec->rx_coalesce_usecs;\n\n\tif (tx_usecs_orig != priv->tx_coalesce_usecs) {\n\t\tfor (idx = 0; idx < priv->tx_cfg.num_queues; idx++) {\n\t\t\tint ntfy_idx = gve_tx_idx_to_ntfy(priv, idx);\n\t\t\tstruct gve_notify_block *block = &priv->ntfy_blocks[ntfy_idx];\n\n\t\t\tgve_set_itr_coalesce_usecs_dqo(priv, block,\n\t\t\t\t\t\t       priv->tx_coalesce_usecs);\n\t\t}\n\t}\n\n\tif (rx_usecs_orig != priv->rx_coalesce_usecs) {\n\t\tfor (idx = 0; idx < priv->rx_cfg.num_queues; idx++) {\n\t\t\tint ntfy_idx = gve_rx_idx_to_ntfy(priv, idx);\n\t\t\tstruct gve_notify_block *block = &priv->ntfy_blocks[ntfy_idx];\n\n\t\t\tgve_set_itr_coalesce_usecs_dqo(priv, block,\n\t\t\t\t\t\t       priv->rx_coalesce_usecs);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nconst struct ethtool_ops gve_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS,\n\t.get_drvinfo = gve_get_drvinfo,\n\t.get_strings = gve_get_strings,\n\t.get_sset_count = gve_get_sset_count,\n\t.get_ethtool_stats = gve_get_ethtool_stats,\n\t.set_msglevel = gve_set_msglevel,\n\t.get_msglevel = gve_get_msglevel,\n\t.set_channels = gve_set_channels,\n\t.get_channels = gve_get_channels,\n\t.get_link = ethtool_op_get_link,\n\t.get_coalesce = gve_get_coalesce,\n\t.set_coalesce = gve_set_coalesce,\n\t.get_ringparam = gve_get_ringparam,\n\t.reset = gve_user_reset,\n\t.get_tunable = gve_get_tunable,\n\t.set_tunable = gve_set_tunable,\n\t.get_priv_flags = gve_get_priv_flags,\n\t.set_priv_flags = gve_set_priv_flags,\n\t.get_link_ksettings = gve_get_link_ksettings\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}