{
  "module_name": "cpsw_priv.c",
  "hash_id": "41a95adcb56c790981e3d9001528aef2d7c0700f0c6d585768e1f58d9a6c11cd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ti/cpsw_priv.c",
  "human_readable_source": "\n \n\n#include <linux/bpf.h>\n#include <linux/bpf_trace.h>\n#include <linux/if_ether.h>\n#include <linux/if_vlan.h>\n#include <linux/kmemleak.h>\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/net_tstamp.h>\n#include <linux/of.h>\n#include <linux/phy.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/skbuff.h>\n#include <net/page_pool/helpers.h>\n#include <net/pkt_cls.h>\n#include <net/pkt_sched.h>\n\n#include \"cpsw.h\"\n#include \"cpts.h\"\n#include \"cpsw_ale.h\"\n#include \"cpsw_priv.h\"\n#include \"cpsw_sl.h\"\n#include \"davinci_cpdma.h\"\n\n#define CPTS_N_ETX_TS 4\n\nint (*cpsw_slave_index)(struct cpsw_common *cpsw, struct cpsw_priv *priv);\n\nvoid cpsw_intr_enable(struct cpsw_common *cpsw)\n{\n\twritel_relaxed(0xFF, &cpsw->wr_regs->tx_en);\n\twritel_relaxed(0xFF, &cpsw->wr_regs->rx_en);\n\n\tcpdma_ctlr_int_ctrl(cpsw->dma, true);\n}\n\nvoid cpsw_intr_disable(struct cpsw_common *cpsw)\n{\n\twritel_relaxed(0, &cpsw->wr_regs->tx_en);\n\twritel_relaxed(0, &cpsw->wr_regs->rx_en);\n\n\tcpdma_ctlr_int_ctrl(cpsw->dma, false);\n}\n\nvoid cpsw_tx_handler(void *token, int len, int status)\n{\n\tstruct cpsw_meta_xdp\t*xmeta;\n\tstruct xdp_frame\t*xdpf;\n\tstruct net_device\t*ndev;\n\tstruct netdev_queue\t*txq;\n\tstruct sk_buff\t\t*skb;\n\tint\t\t\tch;\n\n\tif (cpsw_is_xdpf_handle(token)) {\n\t\txdpf = cpsw_handle_to_xdpf(token);\n\t\txmeta = (void *)xdpf + CPSW_XMETA_OFFSET;\n\t\tndev = xmeta->ndev;\n\t\tch = xmeta->ch;\n\t\txdp_return_frame(xdpf);\n\t} else {\n\t\tskb = token;\n\t\tndev = skb->dev;\n\t\tch = skb_get_queue_mapping(skb);\n\t\tcpts_tx_timestamp(ndev_to_cpsw(ndev)->cpts, skb);\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\t \n\ttxq = netdev_get_tx_queue(ndev, ch);\n\tif (unlikely(netif_tx_queue_stopped(txq)))\n\t\tnetif_tx_wake_queue(txq);\n\n\tndev->stats.tx_packets++;\n\tndev->stats.tx_bytes += len;\n}\n\nirqreturn_t cpsw_tx_interrupt(int irq, void *dev_id)\n{\n\tstruct cpsw_common *cpsw = dev_id;\n\n\twritel(0, &cpsw->wr_regs->tx_en);\n\tcpdma_ctlr_eoi(cpsw->dma, CPDMA_EOI_TX);\n\n\tif (cpsw->quirk_irq) {\n\t\tdisable_irq_nosync(cpsw->irqs_table[1]);\n\t\tcpsw->tx_irq_disabled = true;\n\t}\n\n\tnapi_schedule(&cpsw->napi_tx);\n\treturn IRQ_HANDLED;\n}\n\nirqreturn_t cpsw_rx_interrupt(int irq, void *dev_id)\n{\n\tstruct cpsw_common *cpsw = dev_id;\n\n\twritel(0, &cpsw->wr_regs->rx_en);\n\tcpdma_ctlr_eoi(cpsw->dma, CPDMA_EOI_RX);\n\n\tif (cpsw->quirk_irq) {\n\t\tdisable_irq_nosync(cpsw->irqs_table[0]);\n\t\tcpsw->rx_irq_disabled = true;\n\t}\n\n\tnapi_schedule(&cpsw->napi_rx);\n\treturn IRQ_HANDLED;\n}\n\nirqreturn_t cpsw_misc_interrupt(int irq, void *dev_id)\n{\n\tstruct cpsw_common *cpsw = dev_id;\n\n\twritel(0, &cpsw->wr_regs->misc_en);\n\tcpdma_ctlr_eoi(cpsw->dma, CPDMA_EOI_MISC);\n\tcpts_misc_interrupt(cpsw->cpts);\n\twritel(0x10, &cpsw->wr_regs->misc_en);\n\n\treturn IRQ_HANDLED;\n}\n\nint cpsw_tx_mq_poll(struct napi_struct *napi_tx, int budget)\n{\n\tstruct cpsw_common\t*cpsw = napi_to_cpsw(napi_tx);\n\tint\t\t\tnum_tx, cur_budget, ch;\n\tu32\t\t\tch_map;\n\tstruct cpsw_vector\t*txv;\n\n\t \n\tch_map = cpdma_ctrl_txchs_state(cpsw->dma);\n\tfor (ch = 0, num_tx = 0; ch_map & 0xff; ch_map <<= 1, ch++) {\n\t\tif (!(ch_map & 0x80))\n\t\t\tcontinue;\n\n\t\ttxv = &cpsw->txv[ch];\n\t\tif (unlikely(txv->budget > budget - num_tx))\n\t\t\tcur_budget = budget - num_tx;\n\t\telse\n\t\t\tcur_budget = txv->budget;\n\n\t\tnum_tx += cpdma_chan_process(txv->ch, cur_budget);\n\t\tif (num_tx >= budget)\n\t\t\tbreak;\n\t}\n\n\tif (num_tx < budget) {\n\t\tnapi_complete(napi_tx);\n\t\twritel(0xff, &cpsw->wr_regs->tx_en);\n\t}\n\n\treturn num_tx;\n}\n\nint cpsw_tx_poll(struct napi_struct *napi_tx, int budget)\n{\n\tstruct cpsw_common *cpsw = napi_to_cpsw(napi_tx);\n\tint num_tx;\n\n\tnum_tx = cpdma_chan_process(cpsw->txv[0].ch, budget);\n\tif (num_tx < budget) {\n\t\tnapi_complete(napi_tx);\n\t\twritel(0xff, &cpsw->wr_regs->tx_en);\n\t\tif (cpsw->tx_irq_disabled) {\n\t\t\tcpsw->tx_irq_disabled = false;\n\t\t\tenable_irq(cpsw->irqs_table[1]);\n\t\t}\n\t}\n\n\treturn num_tx;\n}\n\nint cpsw_rx_mq_poll(struct napi_struct *napi_rx, int budget)\n{\n\tstruct cpsw_common\t*cpsw = napi_to_cpsw(napi_rx);\n\tint\t\t\tnum_rx, cur_budget, ch;\n\tu32\t\t\tch_map;\n\tstruct cpsw_vector\t*rxv;\n\n\t \n\tch_map = cpdma_ctrl_rxchs_state(cpsw->dma);\n\tfor (ch = 0, num_rx = 0; ch_map; ch_map >>= 1, ch++) {\n\t\tif (!(ch_map & 0x01))\n\t\t\tcontinue;\n\n\t\trxv = &cpsw->rxv[ch];\n\t\tif (unlikely(rxv->budget > budget - num_rx))\n\t\t\tcur_budget = budget - num_rx;\n\t\telse\n\t\t\tcur_budget = rxv->budget;\n\n\t\tnum_rx += cpdma_chan_process(rxv->ch, cur_budget);\n\t\tif (num_rx >= budget)\n\t\t\tbreak;\n\t}\n\n\tif (num_rx < budget) {\n\t\tnapi_complete_done(napi_rx, num_rx);\n\t\twritel(0xff, &cpsw->wr_regs->rx_en);\n\t}\n\n\treturn num_rx;\n}\n\nint cpsw_rx_poll(struct napi_struct *napi_rx, int budget)\n{\n\tstruct cpsw_common *cpsw = napi_to_cpsw(napi_rx);\n\tint num_rx;\n\n\tnum_rx = cpdma_chan_process(cpsw->rxv[0].ch, budget);\n\tif (num_rx < budget) {\n\t\tnapi_complete_done(napi_rx, num_rx);\n\t\twritel(0xff, &cpsw->wr_regs->rx_en);\n\t\tif (cpsw->rx_irq_disabled) {\n\t\t\tcpsw->rx_irq_disabled = false;\n\t\t\tenable_irq(cpsw->irqs_table[0]);\n\t\t}\n\t}\n\n\treturn num_rx;\n}\n\nvoid cpsw_rx_vlan_encap(struct sk_buff *skb)\n{\n\tstruct cpsw_priv *priv = netdev_priv(skb->dev);\n\tu32 rx_vlan_encap_hdr = *((u32 *)skb->data);\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tu16 vtag, vid, prio, pkt_type;\n\n\t \n\tskb_pull(skb, CPSW_RX_VLAN_ENCAP_HDR_SIZE);\n\n\tpkt_type = (rx_vlan_encap_hdr >>\n\t\t    CPSW_RX_VLAN_ENCAP_HDR_PKT_TYPE_SHIFT) &\n\t\t    CPSW_RX_VLAN_ENCAP_HDR_PKT_TYPE_MSK;\n\t \n\tif (pkt_type == CPSW_RX_VLAN_ENCAP_HDR_PKT_RESERV ||\n\t    pkt_type == CPSW_RX_VLAN_ENCAP_HDR_PKT_PRIO_TAG)\n\t\treturn;\n\n\tvid = (rx_vlan_encap_hdr >>\n\t       CPSW_RX_VLAN_ENCAP_HDR_VID_SHIFT) &\n\t       VLAN_VID_MASK;\n\t \n\tif (!vid)\n\t\treturn;\n\n\t \n\tif (!cpsw_ale_get_vlan_p0_untag(cpsw->ale, vid)) {\n\t\tprio = (rx_vlan_encap_hdr >>\n\t\t\tCPSW_RX_VLAN_ENCAP_HDR_PRIO_SHIFT) &\n\t\t\tCPSW_RX_VLAN_ENCAP_HDR_PRIO_MSK;\n\n\t\tvtag = (prio << VLAN_PRIO_SHIFT) | vid;\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vtag);\n\t}\n\n\t \n\tif (pkt_type == CPSW_RX_VLAN_ENCAP_HDR_PKT_VLAN_TAG) {\n\t\tmemmove(skb->data + VLAN_HLEN, skb->data, 2 * ETH_ALEN);\n\t\tskb_pull(skb, VLAN_HLEN);\n\t}\n}\n\nvoid cpsw_set_slave_mac(struct cpsw_slave *slave, struct cpsw_priv *priv)\n{\n\tslave_write(slave, mac_hi(priv->mac_addr), SA_HI);\n\tslave_write(slave, mac_lo(priv->mac_addr), SA_LO);\n}\n\nvoid soft_reset(const char *module, void __iomem *reg)\n{\n\tunsigned long timeout = jiffies + HZ;\n\n\twritel_relaxed(1, reg);\n\tdo {\n\t\tcpu_relax();\n\t} while ((readl_relaxed(reg) & 1) && time_after(timeout, jiffies));\n\n\tWARN(readl_relaxed(reg) & 1, \"failed to soft-reset %s\\n\", module);\n}\n\nvoid cpsw_ndo_tx_timeout(struct net_device *ndev, unsigned int txqueue)\n{\n\tstruct cpsw_priv *priv = netdev_priv(ndev);\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tint ch;\n\n\tcpsw_err(priv, tx_err, \"transmit timeout, restarting dma\\n\");\n\tndev->stats.tx_errors++;\n\tcpsw_intr_disable(cpsw);\n\tfor (ch = 0; ch < cpsw->tx_ch_num; ch++) {\n\t\tcpdma_chan_stop(cpsw->txv[ch].ch);\n\t\tcpdma_chan_start(cpsw->txv[ch].ch);\n\t}\n\n\tcpsw_intr_enable(cpsw);\n\tnetif_trans_update(ndev);\n\tnetif_tx_wake_all_queues(ndev);\n}\n\nstatic int cpsw_get_common_speed(struct cpsw_common *cpsw)\n{\n\tint i, speed;\n\n\tfor (i = 0, speed = 0; i < cpsw->data.slaves; i++)\n\t\tif (cpsw->slaves[i].phy && cpsw->slaves[i].phy->link)\n\t\t\tspeed += cpsw->slaves[i].phy->speed;\n\n\treturn speed;\n}\n\nint cpsw_need_resplit(struct cpsw_common *cpsw)\n{\n\tint i, rlim_ch_num;\n\tint speed, ch_rate;\n\n\t \n\tspeed = cpsw_get_common_speed(cpsw);\n\tif (speed == cpsw->speed || !speed)\n\t\treturn 0;\n\n\tcpsw->speed = speed;\n\n\tfor (i = 0, rlim_ch_num = 0; i < cpsw->tx_ch_num; i++) {\n\t\tch_rate = cpdma_chan_get_rate(cpsw->txv[i].ch);\n\t\tif (!ch_rate)\n\t\t\tbreak;\n\n\t\trlim_ch_num++;\n\t}\n\n\t \n\tif (!rlim_ch_num || rlim_ch_num == cpsw->tx_ch_num)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nvoid cpsw_split_res(struct cpsw_common *cpsw)\n{\n\tu32 consumed_rate = 0, bigest_rate = 0;\n\tstruct cpsw_vector *txv = cpsw->txv;\n\tint i, ch_weight, rlim_ch_num = 0;\n\tint budget, bigest_rate_ch = 0;\n\tu32 ch_rate, max_rate;\n\tint ch_budget = 0;\n\n\tfor (i = 0; i < cpsw->tx_ch_num; i++) {\n\t\tch_rate = cpdma_chan_get_rate(txv[i].ch);\n\t\tif (!ch_rate)\n\t\t\tcontinue;\n\n\t\trlim_ch_num++;\n\t\tconsumed_rate += ch_rate;\n\t}\n\n\tif (cpsw->tx_ch_num == rlim_ch_num) {\n\t\tmax_rate = consumed_rate;\n\t} else if (!rlim_ch_num) {\n\t\tch_budget = NAPI_POLL_WEIGHT / cpsw->tx_ch_num;\n\t\tbigest_rate = 0;\n\t\tmax_rate = consumed_rate;\n\t} else {\n\t\tmax_rate = cpsw->speed * 1000;\n\n\t\t \n\t\tif (max_rate < consumed_rate)\n\t\t\tmax_rate *= 10;\n\n\t\tif (max_rate < consumed_rate)\n\t\t\tmax_rate *= 10;\n\n\t\tch_budget = (consumed_rate * NAPI_POLL_WEIGHT) / max_rate;\n\t\tch_budget = (NAPI_POLL_WEIGHT - ch_budget) /\n\t\t\t    (cpsw->tx_ch_num - rlim_ch_num);\n\t\tbigest_rate = (max_rate - consumed_rate) /\n\t\t\t      (cpsw->tx_ch_num - rlim_ch_num);\n\t}\n\n\t \n\tbudget = NAPI_POLL_WEIGHT;\n\tfor (i = 0; i < cpsw->tx_ch_num; i++) {\n\t\tch_rate = cpdma_chan_get_rate(txv[i].ch);\n\t\tif (ch_rate) {\n\t\t\ttxv[i].budget = (ch_rate * NAPI_POLL_WEIGHT) / max_rate;\n\t\t\tif (!txv[i].budget)\n\t\t\t\ttxv[i].budget++;\n\t\t\tif (ch_rate > bigest_rate) {\n\t\t\t\tbigest_rate_ch = i;\n\t\t\t\tbigest_rate = ch_rate;\n\t\t\t}\n\n\t\t\tch_weight = (ch_rate * 100) / max_rate;\n\t\t\tif (!ch_weight)\n\t\t\t\tch_weight++;\n\t\t\tcpdma_chan_set_weight(cpsw->txv[i].ch, ch_weight);\n\t\t} else {\n\t\t\ttxv[i].budget = ch_budget;\n\t\t\tif (!bigest_rate_ch)\n\t\t\t\tbigest_rate_ch = i;\n\t\t\tcpdma_chan_set_weight(cpsw->txv[i].ch, 0);\n\t\t}\n\n\t\tbudget -= txv[i].budget;\n\t}\n\n\tif (budget)\n\t\ttxv[bigest_rate_ch].budget += budget;\n\n\t \n\tbudget = NAPI_POLL_WEIGHT;\n\tch_budget = budget / cpsw->rx_ch_num;\n\tfor (i = 0; i < cpsw->rx_ch_num; i++) {\n\t\tcpsw->rxv[i].budget = ch_budget;\n\t\tbudget -= ch_budget;\n\t}\n\n\tif (budget)\n\t\tcpsw->rxv[0].budget += budget;\n}\n\nint cpsw_init_common(struct cpsw_common *cpsw, void __iomem *ss_regs,\n\t\t     int ale_ageout, phys_addr_t desc_mem_phys,\n\t\t     int descs_pool_size)\n{\n\tu32 slave_offset, sliver_offset, slave_size;\n\tstruct cpsw_ale_params ale_params;\n\tstruct cpsw_platform_data *data;\n\tstruct cpdma_params dma_params;\n\tstruct device *dev = cpsw->dev;\n\tstruct device_node *cpts_node;\n\tvoid __iomem *cpts_regs;\n\tint ret = 0, i;\n\n\tdata = &cpsw->data;\n\tcpsw->rx_ch_num = 1;\n\tcpsw->tx_ch_num = 1;\n\n\tcpsw->version = readl(&cpsw->regs->id_ver);\n\n\tmemset(&dma_params, 0, sizeof(dma_params));\n\tmemset(&ale_params, 0, sizeof(ale_params));\n\n\tswitch (cpsw->version) {\n\tcase CPSW_VERSION_1:\n\t\tcpsw->host_port_regs = ss_regs + CPSW1_HOST_PORT_OFFSET;\n\t\tcpts_regs\t     = ss_regs + CPSW1_CPTS_OFFSET;\n\t\tcpsw->hw_stats\t     = ss_regs + CPSW1_HW_STATS;\n\t\tdma_params.dmaregs   = ss_regs + CPSW1_CPDMA_OFFSET;\n\t\tdma_params.txhdp     = ss_regs + CPSW1_STATERAM_OFFSET;\n\t\tale_params.ale_regs  = ss_regs + CPSW1_ALE_OFFSET;\n\t\tslave_offset         = CPSW1_SLAVE_OFFSET;\n\t\tslave_size           = CPSW1_SLAVE_SIZE;\n\t\tsliver_offset        = CPSW1_SLIVER_OFFSET;\n\t\tdma_params.desc_mem_phys = 0;\n\t\tbreak;\n\tcase CPSW_VERSION_2:\n\tcase CPSW_VERSION_3:\n\tcase CPSW_VERSION_4:\n\t\tcpsw->host_port_regs = ss_regs + CPSW2_HOST_PORT_OFFSET;\n\t\tcpts_regs\t     = ss_regs + CPSW2_CPTS_OFFSET;\n\t\tcpsw->hw_stats\t     = ss_regs + CPSW2_HW_STATS;\n\t\tdma_params.dmaregs   = ss_regs + CPSW2_CPDMA_OFFSET;\n\t\tdma_params.txhdp     = ss_regs + CPSW2_STATERAM_OFFSET;\n\t\tale_params.ale_regs  = ss_regs + CPSW2_ALE_OFFSET;\n\t\tslave_offset         = CPSW2_SLAVE_OFFSET;\n\t\tslave_size           = CPSW2_SLAVE_SIZE;\n\t\tsliver_offset        = CPSW2_SLIVER_OFFSET;\n\t\tdma_params.desc_mem_phys = desc_mem_phys;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(dev, \"unknown version 0x%08x\\n\", cpsw->version);\n\t\treturn -ENODEV;\n\t}\n\n\tfor (i = 0; i < cpsw->data.slaves; i++) {\n\t\tstruct cpsw_slave *slave = &cpsw->slaves[i];\n\t\tvoid __iomem\t\t*regs = cpsw->regs;\n\n\t\tslave->slave_num = i;\n\t\tslave->data\t= &cpsw->data.slave_data[i];\n\t\tslave->regs\t= regs + slave_offset;\n\t\tslave->port_vlan = slave->data->dual_emac_res_vlan;\n\t\tslave->mac_sl = cpsw_sl_get(\"cpsw\", dev, regs + sliver_offset);\n\t\tif (IS_ERR(slave->mac_sl))\n\t\t\treturn PTR_ERR(slave->mac_sl);\n\n\t\tslave_offset  += slave_size;\n\t\tsliver_offset += SLIVER_SIZE;\n\t}\n\n\tale_params.dev\t\t\t= dev;\n\tale_params.ale_ageout\t\t= ale_ageout;\n\tale_params.ale_ports\t\t= CPSW_ALE_PORTS_NUM;\n\tale_params.dev_id\t\t= \"cpsw\";\n\tale_params.bus_freq\t\t= cpsw->bus_freq_mhz * 1000000;\n\n\tcpsw->ale = cpsw_ale_create(&ale_params);\n\tif (IS_ERR(cpsw->ale)) {\n\t\tdev_err(dev, \"error initializing ale engine\\n\");\n\t\treturn PTR_ERR(cpsw->ale);\n\t}\n\n\tdma_params.dev\t\t= dev;\n\tdma_params.rxthresh\t= dma_params.dmaregs + CPDMA_RXTHRESH;\n\tdma_params.rxfree\t= dma_params.dmaregs + CPDMA_RXFREE;\n\tdma_params.rxhdp\t= dma_params.txhdp + CPDMA_RXHDP;\n\tdma_params.txcp\t\t= dma_params.txhdp + CPDMA_TXCP;\n\tdma_params.rxcp\t\t= dma_params.txhdp + CPDMA_RXCP;\n\n\tdma_params.num_chan\t\t= data->channels;\n\tdma_params.has_soft_reset\t= true;\n\tdma_params.min_packet_size\t= CPSW_MIN_PACKET_SIZE;\n\tdma_params.desc_mem_size\t= data->bd_ram_size;\n\tdma_params.desc_align\t\t= 16;\n\tdma_params.has_ext_regs\t\t= true;\n\tdma_params.desc_hw_addr         = dma_params.desc_mem_phys;\n\tdma_params.bus_freq_mhz\t\t= cpsw->bus_freq_mhz;\n\tdma_params.descs_pool_size\t= descs_pool_size;\n\n\tcpsw->dma = cpdma_ctlr_create(&dma_params);\n\tif (!cpsw->dma) {\n\t\tdev_err(dev, \"error initializing dma\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tcpts_node = of_get_child_by_name(cpsw->dev->of_node, \"cpts\");\n\tif (!cpts_node)\n\t\tcpts_node = cpsw->dev->of_node;\n\n\tcpsw->cpts = cpts_create(cpsw->dev, cpts_regs, cpts_node,\n\t\t\t\t CPTS_N_ETX_TS);\n\tif (IS_ERR(cpsw->cpts)) {\n\t\tret = PTR_ERR(cpsw->cpts);\n\t\tcpdma_ctlr_destroy(cpsw->dma);\n\t}\n\tof_node_put(cpts_node);\n\n\treturn ret;\n}\n\n#if IS_ENABLED(CONFIG_TI_CPTS)\n\nstatic void cpsw_hwtstamp_v1(struct cpsw_priv *priv)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_slave *slave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\tu32 ts_en, seq_id;\n\n\tif (!priv->tx_ts_enabled && !priv->rx_ts_enabled) {\n\t\tslave_write(slave, 0, CPSW1_TS_CTL);\n\t\treturn;\n\t}\n\n\tseq_id = (30 << CPSW_V1_SEQ_ID_OFS_SHIFT) | ETH_P_1588;\n\tts_en = EVENT_MSG_BITS << CPSW_V1_MSG_TYPE_OFS;\n\n\tif (priv->tx_ts_enabled)\n\t\tts_en |= CPSW_V1_TS_TX_EN;\n\n\tif (priv->rx_ts_enabled)\n\t\tts_en |= CPSW_V1_TS_RX_EN;\n\n\tslave_write(slave, ts_en, CPSW1_TS_CTL);\n\tslave_write(slave, seq_id, CPSW1_TS_SEQ_LTYPE);\n}\n\nstatic void cpsw_hwtstamp_v2(struct cpsw_priv *priv)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_slave *slave;\n\tu32 ctrl, mtype;\n\n\tslave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\n\tctrl = slave_read(slave, CPSW2_CONTROL);\n\tswitch (cpsw->version) {\n\tcase CPSW_VERSION_2:\n\t\tctrl &= ~CTRL_V2_ALL_TS_MASK;\n\n\t\tif (priv->tx_ts_enabled)\n\t\t\tctrl |= CTRL_V2_TX_TS_BITS;\n\n\t\tif (priv->rx_ts_enabled)\n\t\t\tctrl |= CTRL_V2_RX_TS_BITS;\n\t\tbreak;\n\tcase CPSW_VERSION_3:\n\tdefault:\n\t\tctrl &= ~CTRL_V3_ALL_TS_MASK;\n\n\t\tif (priv->tx_ts_enabled)\n\t\t\tctrl |= CTRL_V3_TX_TS_BITS;\n\n\t\tif (priv->rx_ts_enabled)\n\t\t\tctrl |= CTRL_V3_RX_TS_BITS;\n\t\tbreak;\n\t}\n\n\tmtype = (30 << TS_SEQ_ID_OFFSET_SHIFT) | EVENT_MSG_BITS;\n\n\tslave_write(slave, mtype, CPSW2_TS_SEQ_MTYPE);\n\tslave_write(slave, ctrl, CPSW2_CONTROL);\n\twritel_relaxed(ETH_P_1588, &cpsw->regs->ts_ltype);\n\twritel_relaxed(ETH_P_8021Q, &cpsw->regs->vlan_ltype);\n}\n\nstatic int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr)\n{\n\tstruct cpsw_priv *priv = netdev_priv(dev);\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct hwtstamp_config cfg;\n\n\tif (cpsw->version != CPSW_VERSION_1 &&\n\t    cpsw->version != CPSW_VERSION_2 &&\n\t    cpsw->version != CPSW_VERSION_3)\n\t\treturn -EOPNOTSUPP;\n\n\tif (copy_from_user(&cfg, ifr->ifr_data, sizeof(cfg)))\n\t\treturn -EFAULT;\n\n\tif (cfg.tx_type != HWTSTAMP_TX_OFF && cfg.tx_type != HWTSTAMP_TX_ON)\n\t\treturn -ERANGE;\n\n\tswitch (cfg.rx_filter) {\n\tcase HWTSTAMP_FILTER_NONE:\n\t\tpriv->rx_ts_enabled = 0;\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_ALL:\n\tcase HWTSTAMP_FILTER_NTP_ALL:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:\n\t\treturn -ERANGE;\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:\n\tcase HWTSTAMP_FILTER_PTP_V2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:\n\t\tpriv->rx_ts_enabled = HWTSTAMP_FILTER_PTP_V2_EVENT;\n\t\tcfg.rx_filter = HWTSTAMP_FILTER_PTP_V2_EVENT;\n\t\tbreak;\n\tdefault:\n\t\treturn -ERANGE;\n\t}\n\n\tpriv->tx_ts_enabled = cfg.tx_type == HWTSTAMP_TX_ON;\n\n\tswitch (cpsw->version) {\n\tcase CPSW_VERSION_1:\n\t\tcpsw_hwtstamp_v1(priv);\n\t\tbreak;\n\tcase CPSW_VERSION_2:\n\tcase CPSW_VERSION_3:\n\t\tcpsw_hwtstamp_v2(priv);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t}\n\n\treturn copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;\n}\n\nstatic int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr)\n{\n\tstruct cpsw_common *cpsw = ndev_to_cpsw(dev);\n\tstruct cpsw_priv *priv = netdev_priv(dev);\n\tstruct hwtstamp_config cfg;\n\n\tif (cpsw->version != CPSW_VERSION_1 &&\n\t    cpsw->version != CPSW_VERSION_2 &&\n\t    cpsw->version != CPSW_VERSION_3)\n\t\treturn -EOPNOTSUPP;\n\n\tcfg.flags = 0;\n\tcfg.tx_type = priv->tx_ts_enabled ? HWTSTAMP_TX_ON : HWTSTAMP_TX_OFF;\n\tcfg.rx_filter = priv->rx_ts_enabled;\n\n\treturn copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;\n}\n#else\nstatic int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr)\n{\n\treturn -EOPNOTSUPP;\n}\n\nstatic int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr)\n{\n\treturn -EOPNOTSUPP;\n}\n#endif  \n\nint cpsw_ndo_ioctl(struct net_device *dev, struct ifreq *req, int cmd)\n{\n\tstruct cpsw_priv *priv = netdev_priv(dev);\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tint slave_no = cpsw_slave_index(cpsw, priv);\n\tstruct phy_device *phy;\n\n\tif (!netif_running(dev))\n\t\treturn -EINVAL;\n\n\tphy = cpsw->slaves[slave_no].phy;\n\n\tif (!phy_has_hwtstamp(phy)) {\n\t\tswitch (cmd) {\n\t\tcase SIOCSHWTSTAMP:\n\t\t\treturn cpsw_hwtstamp_set(dev, req);\n\t\tcase SIOCGHWTSTAMP:\n\t\t\treturn cpsw_hwtstamp_get(dev, req);\n\t\t}\n\t}\n\n\tif (phy)\n\t\treturn phy_mii_ioctl(phy, req, cmd);\n\n\treturn -EOPNOTSUPP;\n}\n\nint cpsw_ndo_set_tx_maxrate(struct net_device *ndev, int queue, u32 rate)\n{\n\tstruct cpsw_priv *priv = netdev_priv(ndev);\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_slave *slave;\n\tu32 min_rate;\n\tu32 ch_rate;\n\tint i, ret;\n\n\tch_rate = netdev_get_tx_queue(ndev, queue)->tx_maxrate;\n\tif (ch_rate == rate)\n\t\treturn 0;\n\n\tch_rate = rate * 1000;\n\tmin_rate = cpdma_chan_get_min_rate(cpsw->dma);\n\tif ((ch_rate < min_rate && ch_rate)) {\n\t\tdev_err(priv->dev, \"The channel rate cannot be less than %dMbps\",\n\t\t\tmin_rate);\n\t\treturn -EINVAL;\n\t}\n\n\tif (rate > cpsw->speed) {\n\t\tdev_err(priv->dev, \"The channel rate cannot be more than 2Gbps\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = pm_runtime_resume_and_get(cpsw->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = cpdma_chan_set_rate(cpsw->txv[queue].ch, ch_rate);\n\tpm_runtime_put(cpsw->dev);\n\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tfor (i = 0; i < cpsw->data.slaves; i++) {\n\t\tslave = &cpsw->slaves[i];\n\t\tif (!slave->ndev)\n\t\t\tcontinue;\n\n\t\tnetdev_get_tx_queue(slave->ndev, queue)->tx_maxrate = rate;\n\t}\n\n\tcpsw_split_res(cpsw);\n\treturn ret;\n}\n\nstatic int cpsw_tc_to_fifo(int tc, int num_tc)\n{\n\tif (tc == num_tc - 1)\n\t\treturn 0;\n\n\treturn CPSW_FIFO_SHAPERS_NUM - tc;\n}\n\nbool cpsw_shp_is_off(struct cpsw_priv *priv)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_slave *slave;\n\tu32 shift, mask, val;\n\n\tval = readl_relaxed(&cpsw->regs->ptype);\n\n\tslave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\tshift = CPSW_FIFO_SHAPE_EN_SHIFT + 3 * slave->slave_num;\n\tmask = 7 << shift;\n\tval = val & mask;\n\n\treturn !val;\n}\n\nstatic void cpsw_fifo_shp_on(struct cpsw_priv *priv, int fifo, int on)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_slave *slave;\n\tu32 shift, mask, val;\n\n\tval = readl_relaxed(&cpsw->regs->ptype);\n\n\tslave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\tshift = CPSW_FIFO_SHAPE_EN_SHIFT + 3 * slave->slave_num;\n\tmask = (1 << --fifo) << shift;\n\tval = on ? val | mask : val & ~mask;\n\n\twritel_relaxed(val, &cpsw->regs->ptype);\n}\n\nstatic int cpsw_set_fifo_bw(struct cpsw_priv *priv, int fifo, int bw)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tu32 val = 0, send_pct, shift;\n\tstruct cpsw_slave *slave;\n\tint pct = 0, i;\n\n\tif (bw > priv->shp_cfg_speed * 1000)\n\t\tgoto err;\n\n\t \n\tslave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\tsend_pct = slave_read(slave, SEND_PERCENT);\n\tfor (i = CPSW_FIFO_SHAPERS_NUM; i > 0; i--) {\n\t\tif (!bw) {\n\t\t\tif (i >= fifo || !priv->fifo_bw[i])\n\t\t\t\tcontinue;\n\n\t\t\tdev_warn(priv->dev, \"Prev FIFO%d is shaped\", i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!priv->fifo_bw[i] && i > fifo) {\n\t\t\tdev_err(priv->dev, \"Upper FIFO%d is not shaped\", i);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tshift = (i - 1) * 8;\n\t\tif (i == fifo) {\n\t\t\tsend_pct &= ~(CPSW_PCT_MASK << shift);\n\t\t\tval = DIV_ROUND_UP(bw, priv->shp_cfg_speed * 10);\n\t\t\tif (!val)\n\t\t\t\tval = 1;\n\n\t\t\tsend_pct |= val << shift;\n\t\t\tpct += val;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (priv->fifo_bw[i])\n\t\t\tpct += (send_pct >> shift) & CPSW_PCT_MASK;\n\t}\n\n\tif (pct >= 100)\n\t\tgoto err;\n\n\tslave_write(slave, send_pct, SEND_PERCENT);\n\tpriv->fifo_bw[fifo] = bw;\n\n\tdev_warn(priv->dev, \"set FIFO%d bw = %d\\n\", fifo,\n\t\t DIV_ROUND_CLOSEST(val * priv->shp_cfg_speed, 100));\n\n\treturn 0;\nerr:\n\tdev_err(priv->dev, \"Bandwidth doesn't fit in tc configuration\");\n\treturn -EINVAL;\n}\n\nstatic int cpsw_set_fifo_rlimit(struct cpsw_priv *priv, int fifo, int bw)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_slave *slave;\n\tu32 tx_in_ctl_rg, val;\n\tint ret;\n\n\tret = cpsw_set_fifo_bw(priv, fifo, bw);\n\tif (ret)\n\t\treturn ret;\n\n\tslave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\ttx_in_ctl_rg = cpsw->version == CPSW_VERSION_1 ?\n\t\t       CPSW1_TX_IN_CTL : CPSW2_TX_IN_CTL;\n\n\tif (!bw)\n\t\tcpsw_fifo_shp_on(priv, fifo, bw);\n\n\tval = slave_read(slave, tx_in_ctl_rg);\n\tif (cpsw_shp_is_off(priv)) {\n\t\t \n\t\tval &= ~(0xf << CPSW_FIFO_RATE_EN_SHIFT);\n\n\t\t \n\t\tval &= ~(3 << CPSW_FIFO_QUEUE_TYPE_SHIFT);\n\n\t\t \n\t\tif (bw)\n\t\t\tval |= 2 << CPSW_FIFO_QUEUE_TYPE_SHIFT;\n\t\telse\n\t\t\tpriv->shp_cfg_speed = 0;\n\t}\n\n\t \n\tif (bw)\n\t\tval |= BIT(fifo + CPSW_FIFO_RATE_EN_SHIFT);\n\telse\n\t\tval &= ~BIT(fifo + CPSW_FIFO_RATE_EN_SHIFT);\n\tslave_write(slave, val, tx_in_ctl_rg);\n\n\t \n\tcpsw_fifo_shp_on(priv, fifo, bw);\n\treturn 0;\n}\n\n \nstatic int cpsw_set_cbs(struct net_device *ndev,\n\t\t\tstruct tc_cbs_qopt_offload *qopt)\n{\n\tstruct cpsw_priv *priv = netdev_priv(ndev);\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_slave *slave;\n\tint prev_speed = 0;\n\tint tc, ret, fifo;\n\tu32 bw = 0;\n\n\ttc = netdev_txq_to_tc(priv->ndev, qopt->queue);\n\n\t \n\tfifo = cpsw_tc_to_fifo(tc, ndev->num_tc);\n\tif (!fifo) {\n\t\tdev_err(priv->dev, \"Last tc%d can't be rate limited\", tc);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!qopt->enable && !priv->fifo_bw[fifo])\n\t\treturn 0;\n\n\t \n\tslave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\tif (slave->phy && slave->phy->link) {\n\t\tif (priv->shp_cfg_speed &&\n\t\t    priv->shp_cfg_speed != slave->phy->speed)\n\t\t\tprev_speed = priv->shp_cfg_speed;\n\n\t\tpriv->shp_cfg_speed = slave->phy->speed;\n\t}\n\n\tif (!priv->shp_cfg_speed) {\n\t\tdev_err(priv->dev, \"Link speed is not known\");\n\t\treturn -1;\n\t}\n\n\tret = pm_runtime_resume_and_get(cpsw->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbw = qopt->enable ? qopt->idleslope : 0;\n\tret = cpsw_set_fifo_rlimit(priv, fifo, bw);\n\tif (ret) {\n\t\tpriv->shp_cfg_speed = prev_speed;\n\t\tprev_speed = 0;\n\t}\n\n\tif (bw && prev_speed)\n\t\tdev_warn(priv->dev,\n\t\t\t \"Speed was changed, CBS shaper speeds are changed!\");\n\n\tpm_runtime_put_sync(cpsw->dev);\n\treturn ret;\n}\n\nstatic int cpsw_set_mqprio(struct net_device *ndev, void *type_data)\n{\n\tstruct tc_mqprio_qopt_offload *mqprio = type_data;\n\tstruct cpsw_priv *priv = netdev_priv(ndev);\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tint fifo, num_tc, count, offset;\n\tstruct cpsw_slave *slave;\n\tu32 tx_prio_map = 0;\n\tint i, tc, ret;\n\n\tnum_tc = mqprio->qopt.num_tc;\n\tif (num_tc > CPSW_TC_NUM)\n\t\treturn -EINVAL;\n\n\tif (mqprio->mode != TC_MQPRIO_MODE_DCB)\n\t\treturn -EINVAL;\n\n\tret = pm_runtime_resume_and_get(cpsw->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (num_tc) {\n\t\tfor (i = 0; i < 8; i++) {\n\t\t\ttc = mqprio->qopt.prio_tc_map[i];\n\t\t\tfifo = cpsw_tc_to_fifo(tc, num_tc);\n\t\t\ttx_prio_map |= fifo << (4 * i);\n\t\t}\n\n\t\tnetdev_set_num_tc(ndev, num_tc);\n\t\tfor (i = 0; i < num_tc; i++) {\n\t\t\tcount = mqprio->qopt.count[i];\n\t\t\toffset = mqprio->qopt.offset[i];\n\t\t\tnetdev_set_tc_queue(ndev, i, count, offset);\n\t\t}\n\t}\n\n\tif (!mqprio->qopt.hw) {\n\t\t \n\t\tnetdev_reset_tc(ndev);\n\t\ttx_prio_map = TX_PRIORITY_MAPPING;\n\t}\n\n\tpriv->mqprio_hw = mqprio->qopt.hw;\n\n\toffset = cpsw->version == CPSW_VERSION_1 ?\n\t\t CPSW1_TX_PRI_MAP : CPSW2_TX_PRI_MAP;\n\n\tslave = &cpsw->slaves[cpsw_slave_index(cpsw, priv)];\n\tslave_write(slave, tx_prio_map, offset);\n\n\tpm_runtime_put_sync(cpsw->dev);\n\n\treturn 0;\n}\n\nstatic int cpsw_qos_setup_tc_block(struct net_device *ndev, struct flow_block_offload *f);\n\nint cpsw_ndo_setup_tc(struct net_device *ndev, enum tc_setup_type type,\n\t\t      void *type_data)\n{\n\tswitch (type) {\n\tcase TC_SETUP_QDISC_CBS:\n\t\treturn cpsw_set_cbs(ndev, type_data);\n\n\tcase TC_SETUP_QDISC_MQPRIO:\n\t\treturn cpsw_set_mqprio(ndev, type_data);\n\n\tcase TC_SETUP_BLOCK:\n\t\treturn cpsw_qos_setup_tc_block(ndev, type_data);\n\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nvoid cpsw_cbs_resume(struct cpsw_slave *slave, struct cpsw_priv *priv)\n{\n\tint fifo, bw;\n\n\tfor (fifo = CPSW_FIFO_SHAPERS_NUM; fifo > 0; fifo--) {\n\t\tbw = priv->fifo_bw[fifo];\n\t\tif (!bw)\n\t\t\tcontinue;\n\n\t\tcpsw_set_fifo_rlimit(priv, fifo, bw);\n\t}\n}\n\nvoid cpsw_mqprio_resume(struct cpsw_slave *slave, struct cpsw_priv *priv)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tu32 tx_prio_map = 0;\n\tint i, tc, fifo;\n\tu32 tx_prio_rg;\n\n\tif (!priv->mqprio_hw)\n\t\treturn;\n\n\tfor (i = 0; i < 8; i++) {\n\t\ttc = netdev_get_prio_tc_map(priv->ndev, i);\n\t\tfifo = CPSW_FIFO_SHAPERS_NUM - tc;\n\t\ttx_prio_map |= fifo << (4 * i);\n\t}\n\n\ttx_prio_rg = cpsw->version == CPSW_VERSION_1 ?\n\t\t     CPSW1_TX_PRI_MAP : CPSW2_TX_PRI_MAP;\n\n\tslave_write(slave, tx_prio_map, tx_prio_rg);\n}\n\nint cpsw_fill_rx_channels(struct cpsw_priv *priv)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_meta_xdp *xmeta;\n\tstruct page_pool *pool;\n\tstruct page *page;\n\tint ch_buf_num;\n\tint ch, i, ret;\n\tdma_addr_t dma;\n\n\tfor (ch = 0; ch < cpsw->rx_ch_num; ch++) {\n\t\tpool = cpsw->page_pool[ch];\n\t\tch_buf_num = cpdma_chan_get_rx_buf_num(cpsw->rxv[ch].ch);\n\t\tfor (i = 0; i < ch_buf_num; i++) {\n\t\t\tpage = page_pool_dev_alloc_pages(pool);\n\t\t\tif (!page) {\n\t\t\t\tcpsw_err(priv, ifup, \"allocate rx page err\\n\");\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\txmeta = page_address(page) + CPSW_XMETA_OFFSET;\n\t\t\txmeta->ndev = priv->ndev;\n\t\t\txmeta->ch = ch;\n\n\t\t\tdma = page_pool_get_dma_addr(page) + CPSW_HEADROOM_NA;\n\t\t\tret = cpdma_chan_idle_submit_mapped(cpsw->rxv[ch].ch,\n\t\t\t\t\t\t\t    page, dma,\n\t\t\t\t\t\t\t    cpsw->rx_packet_max,\n\t\t\t\t\t\t\t    0);\n\t\t\tif (ret < 0) {\n\t\t\t\tcpsw_err(priv, ifup,\n\t\t\t\t\t \"cannot submit page to channel %d rx, error %d\\n\",\n\t\t\t\t\t ch, ret);\n\t\t\t\tpage_pool_recycle_direct(pool, page);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\tcpsw_info(priv, ifup, \"ch %d rx, submitted %d descriptors\\n\",\n\t\t\t  ch, ch_buf_num);\n\t}\n\n\treturn 0;\n}\n\nstatic struct page_pool *cpsw_create_page_pool(struct cpsw_common *cpsw,\n\t\t\t\t\t       int size)\n{\n\tstruct page_pool_params pp_params = {};\n\tstruct page_pool *pool;\n\n\tpp_params.order = 0;\n\tpp_params.flags = PP_FLAG_DMA_MAP;\n\tpp_params.pool_size = size;\n\tpp_params.nid = NUMA_NO_NODE;\n\tpp_params.dma_dir = DMA_BIDIRECTIONAL;\n\tpp_params.dev = cpsw->dev;\n\n\tpool = page_pool_create(&pp_params);\n\tif (IS_ERR(pool))\n\t\tdev_err(cpsw->dev, \"cannot create rx page pool\\n\");\n\n\treturn pool;\n}\n\nstatic int cpsw_create_rx_pool(struct cpsw_common *cpsw, int ch)\n{\n\tstruct page_pool *pool;\n\tint ret = 0, pool_size;\n\n\tpool_size = cpdma_chan_get_rx_buf_num(cpsw->rxv[ch].ch);\n\tpool = cpsw_create_page_pool(cpsw, pool_size);\n\tif (IS_ERR(pool))\n\t\tret = PTR_ERR(pool);\n\telse\n\t\tcpsw->page_pool[ch] = pool;\n\n\treturn ret;\n}\n\nstatic int cpsw_ndev_create_xdp_rxq(struct cpsw_priv *priv, int ch)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct xdp_rxq_info *rxq;\n\tstruct page_pool *pool;\n\tint ret;\n\n\tpool = cpsw->page_pool[ch];\n\trxq = &priv->xdp_rxq[ch];\n\n\tret = xdp_rxq_info_reg(rxq, priv->ndev, ch, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tret = xdp_rxq_info_reg_mem_model(rxq, MEM_TYPE_PAGE_POOL, pool);\n\tif (ret)\n\t\txdp_rxq_info_unreg(rxq);\n\n\treturn ret;\n}\n\nstatic void cpsw_ndev_destroy_xdp_rxq(struct cpsw_priv *priv, int ch)\n{\n\tstruct xdp_rxq_info *rxq = &priv->xdp_rxq[ch];\n\n\tif (!xdp_rxq_info_is_reg(rxq))\n\t\treturn;\n\n\txdp_rxq_info_unreg(rxq);\n}\n\nvoid cpsw_destroy_xdp_rxqs(struct cpsw_common *cpsw)\n{\n\tstruct net_device *ndev;\n\tint i, ch;\n\n\tfor (ch = 0; ch < cpsw->rx_ch_num; ch++) {\n\t\tfor (i = 0; i < cpsw->data.slaves; i++) {\n\t\t\tndev = cpsw->slaves[i].ndev;\n\t\t\tif (!ndev)\n\t\t\t\tcontinue;\n\n\t\t\tcpsw_ndev_destroy_xdp_rxq(netdev_priv(ndev), ch);\n\t\t}\n\n\t\tpage_pool_destroy(cpsw->page_pool[ch]);\n\t\tcpsw->page_pool[ch] = NULL;\n\t}\n}\n\nint cpsw_create_xdp_rxqs(struct cpsw_common *cpsw)\n{\n\tstruct net_device *ndev;\n\tint i, ch, ret;\n\n\tfor (ch = 0; ch < cpsw->rx_ch_num; ch++) {\n\t\tret = cpsw_create_rx_pool(cpsw, ch);\n\t\tif (ret)\n\t\t\tgoto err_cleanup;\n\n\t\t \n\t\tfor (i = 0; i < cpsw->data.slaves; i++) {\n\t\t\tndev = cpsw->slaves[i].ndev;\n\t\t\tif (!ndev)\n\t\t\t\tcontinue;\n\n\t\t\tret = cpsw_ndev_create_xdp_rxq(netdev_priv(ndev), ch);\n\t\t\tif (ret)\n\t\t\t\tgoto err_cleanup;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_cleanup:\n\tcpsw_destroy_xdp_rxqs(cpsw);\n\n\treturn ret;\n}\n\nstatic int cpsw_xdp_prog_setup(struct cpsw_priv *priv, struct netdev_bpf *bpf)\n{\n\tstruct bpf_prog *prog = bpf->prog;\n\n\tif (!priv->xdpi.prog && !prog)\n\t\treturn 0;\n\n\tWRITE_ONCE(priv->xdp_prog, prog);\n\n\txdp_attachment_setup(&priv->xdpi, bpf);\n\n\treturn 0;\n}\n\nint cpsw_ndo_bpf(struct net_device *ndev, struct netdev_bpf *bpf)\n{\n\tstruct cpsw_priv *priv = netdev_priv(ndev);\n\n\tswitch (bpf->command) {\n\tcase XDP_SETUP_PROG:\n\t\treturn cpsw_xdp_prog_setup(priv, bpf);\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint cpsw_xdp_tx_frame(struct cpsw_priv *priv, struct xdp_frame *xdpf,\n\t\t      struct page *page, int port)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct cpsw_meta_xdp *xmeta;\n\tstruct cpdma_chan *txch;\n\tdma_addr_t dma;\n\tint ret;\n\n\txmeta = (void *)xdpf + CPSW_XMETA_OFFSET;\n\txmeta->ndev = priv->ndev;\n\txmeta->ch = 0;\n\ttxch = cpsw->txv[0].ch;\n\n\tif (page) {\n\t\tdma = page_pool_get_dma_addr(page);\n\t\tdma += xdpf->headroom + sizeof(struct xdp_frame);\n\t\tret = cpdma_chan_submit_mapped(txch, cpsw_xdpf_to_handle(xdpf),\n\t\t\t\t\t       dma, xdpf->len, port);\n\t} else {\n\t\tif (sizeof(*xmeta) > xdpf->headroom)\n\t\t\treturn -EINVAL;\n\n\t\tret = cpdma_chan_submit(txch, cpsw_xdpf_to_handle(xdpf),\n\t\t\t\t\txdpf->data, xdpf->len, port);\n\t}\n\n\tif (ret)\n\t\tpriv->ndev->stats.tx_dropped++;\n\n\treturn ret;\n}\n\nint cpsw_run_xdp(struct cpsw_priv *priv, int ch, struct xdp_buff *xdp,\n\t\t struct page *page, int port, int *len)\n{\n\tstruct cpsw_common *cpsw = priv->cpsw;\n\tstruct net_device *ndev = priv->ndev;\n\tint ret = CPSW_XDP_CONSUMED;\n\tstruct xdp_frame *xdpf;\n\tstruct bpf_prog *prog;\n\tu32 act;\n\n\tprog = READ_ONCE(priv->xdp_prog);\n\tif (!prog)\n\t\treturn CPSW_XDP_PASS;\n\n\tact = bpf_prog_run_xdp(prog, xdp);\n\t \n\t*len = xdp->data_end - xdp->data;\n\n\tswitch (act) {\n\tcase XDP_PASS:\n\t\tret = CPSW_XDP_PASS;\n\t\tgoto out;\n\tcase XDP_TX:\n\t\txdpf = xdp_convert_buff_to_frame(xdp);\n\t\tif (unlikely(!xdpf))\n\t\t\tgoto drop;\n\n\t\tif (cpsw_xdp_tx_frame(priv, xdpf, page, port))\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\tbreak;\n\tcase XDP_REDIRECT:\n\t\tif (xdp_do_redirect(ndev, xdp, prog))\n\t\t\tgoto drop;\n\n\t\t \n\t\txdp_do_flush_map();\n\t\tbreak;\n\tdefault:\n\t\tbpf_warn_invalid_xdp_action(ndev, prog, act);\n\t\tfallthrough;\n\tcase XDP_ABORTED:\n\t\ttrace_xdp_exception(ndev, prog, act);\n\t\tfallthrough;\t \n\tcase XDP_DROP:\n\t\tndev->stats.rx_bytes += *len;\n\t\tndev->stats.rx_packets++;\n\t\tgoto drop;\n\t}\n\n\tndev->stats.rx_bytes += *len;\n\tndev->stats.rx_packets++;\nout:\n\treturn ret;\ndrop:\n\tpage_pool_recycle_direct(cpsw->page_pool[ch], page);\n\treturn ret;\n}\n\nstatic int cpsw_qos_clsflower_add_policer(struct cpsw_priv *priv,\n\t\t\t\t\t  struct netlink_ext_ack *extack,\n\t\t\t\t\t  struct flow_cls_offload *cls,\n\t\t\t\t\t  u64 rate_pkt_ps)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(cls);\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tstatic const u8 mc_mac[] = {0x01, 0x00, 0x00, 0x00, 0x00, 0x00};\n\tstruct flow_match_eth_addrs match;\n\tu32 port_id;\n\tint ret;\n\n\tif (dissector->used_keys &\n\t    ~(BIT_ULL(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ETH_ADDRS))) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Unsupported keys used\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Not matching on eth address\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tflow_rule_match_eth_addrs(rule, &match);\n\n\tif (!is_zero_ether_addr(match.mask->src)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Matching on source MAC not supported\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tport_id = cpsw_slave_index(priv->cpsw, priv) + 1;\n\n\tif (is_broadcast_ether_addr(match.key->dst) &&\n\t    is_broadcast_ether_addr(match.mask->dst)) {\n\t\tret = cpsw_ale_rx_ratelimit_bc(priv->cpsw->ale, port_id, rate_pkt_ps);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tpriv->ale_bc_ratelimit.cookie = cls->cookie;\n\t\tpriv->ale_bc_ratelimit.rate_packet_ps = rate_pkt_ps;\n\t} else if (ether_addr_equal_unaligned(match.key->dst, mc_mac) &&\n\t\t   ether_addr_equal_unaligned(match.mask->dst, mc_mac)) {\n\t\tret = cpsw_ale_rx_ratelimit_mc(priv->cpsw->ale, port_id, rate_pkt_ps);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tpriv->ale_mc_ratelimit.cookie = cls->cookie;\n\t\tpriv->ale_mc_ratelimit.rate_packet_ps = rate_pkt_ps;\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Not supported matching key\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int cpsw_qos_clsflower_policer_validate(const struct flow_action *action,\n\t\t\t\t\t       const struct flow_action_entry *act,\n\t\t\t\t\t       struct netlink_ext_ack *extack)\n{\n\tif (act->police.exceed.act_id != FLOW_ACTION_DROP) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when exceed action is not drop\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id != FLOW_ACTION_PIPE &&\n\t    act->police.notexceed.act_id != FLOW_ACTION_ACCEPT) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is not pipe or ok\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id == FLOW_ACTION_ACCEPT &&\n\t    !flow_action_is_last_entry(action, act)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is ok, but action is not last\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.rate_bytes_ps || act->police.peakrate_bytes_ps ||\n\t    act->police.avrate || act->police.overhead) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when bytes per second/peakrate/avrate/overhead is configured\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int cpsw_qos_configure_clsflower(struct cpsw_priv *priv, struct flow_cls_offload *cls)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(cls);\n\tstruct netlink_ext_ack *extack = cls->common.extack;\n\tconst struct flow_action_entry *act;\n\tint i, ret;\n\n\tflow_action_for_each(i, act, &rule->action) {\n\t\tswitch (act->id) {\n\t\tcase FLOW_ACTION_POLICE:\n\t\t\tret = cpsw_qos_clsflower_policer_validate(&rule->action, act, extack);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\treturn cpsw_qos_clsflower_add_policer(priv, extack, cls,\n\t\t\t\t\t\t\t      act->police.rate_pkt_ps);\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG_MOD(extack, \"Action not supported\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\treturn -EOPNOTSUPP;\n}\n\nstatic int cpsw_qos_delete_clsflower(struct cpsw_priv *priv, struct flow_cls_offload *cls)\n{\n\tu32 port_id = cpsw_slave_index(priv->cpsw, priv) + 1;\n\n\tif (cls->cookie == priv->ale_bc_ratelimit.cookie) {\n\t\tpriv->ale_bc_ratelimit.cookie = 0;\n\t\tpriv->ale_bc_ratelimit.rate_packet_ps = 0;\n\t\tcpsw_ale_rx_ratelimit_bc(priv->cpsw->ale, port_id, 0);\n\t}\n\n\tif (cls->cookie == priv->ale_mc_ratelimit.cookie) {\n\t\tpriv->ale_mc_ratelimit.cookie = 0;\n\t\tpriv->ale_mc_ratelimit.rate_packet_ps = 0;\n\t\tcpsw_ale_rx_ratelimit_mc(priv->cpsw->ale, port_id, 0);\n\t}\n\n\treturn 0;\n}\n\nstatic int cpsw_qos_setup_tc_clsflower(struct cpsw_priv *priv, struct flow_cls_offload *cls_flower)\n{\n\tswitch (cls_flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn cpsw_qos_configure_clsflower(priv, cls_flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn cpsw_qos_delete_clsflower(priv, cls_flower);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int cpsw_qos_setup_tc_block_cb(enum tc_setup_type type, void *type_data, void *cb_priv)\n{\n\tstruct cpsw_priv *priv = cb_priv;\n\tint ret;\n\n\tif (!tc_cls_can_offload_and_chain0(priv->ndev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tret = pm_runtime_get_sync(priv->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_noidle(priv->dev);\n\t\treturn ret;\n\t}\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\tret = cpsw_qos_setup_tc_clsflower(priv, type_data);\n\t\tbreak;\n\tdefault:\n\t\tret = -EOPNOTSUPP;\n\t}\n\n\tpm_runtime_put(priv->dev);\n\treturn ret;\n}\n\nstatic LIST_HEAD(cpsw_qos_block_cb_list);\n\nstatic int cpsw_qos_setup_tc_block(struct net_device *ndev, struct flow_block_offload *f)\n{\n\tstruct cpsw_priv *priv = netdev_priv(ndev);\n\n\treturn flow_block_cb_setup_simple(f, &cpsw_qos_block_cb_list,\n\t\t\t\t\t  cpsw_qos_setup_tc_block_cb,\n\t\t\t\t\t  priv, priv, true);\n}\n\nvoid cpsw_qos_clsflower_resume(struct cpsw_priv *priv)\n{\n\tu32 port_id = cpsw_slave_index(priv->cpsw, priv) + 1;\n\n\tif (priv->ale_bc_ratelimit.cookie)\n\t\tcpsw_ale_rx_ratelimit_bc(priv->cpsw->ale, port_id,\n\t\t\t\t\t priv->ale_bc_ratelimit.rate_packet_ps);\n\n\tif (priv->ale_mc_ratelimit.cookie)\n\t\tcpsw_ale_rx_ratelimit_mc(priv->cpsw->ale, port_id,\n\t\t\t\t\t priv->ale_mc_ratelimit.rate_packet_ps);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}