{
  "module_name": "am65-cpsw-qos.c",
  "hash_id": "ff5280949b2bb90e86eb5865d758e7e674f1befb7206f8be389bd498f9351e4b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ti/am65-cpsw-qos.c",
  "human_readable_source": "\n \n\n#include <linux/pm_runtime.h>\n#include <linux/time.h>\n#include <net/pkt_cls.h>\n\n#include \"am65-cpsw-nuss.h\"\n#include \"am65-cpsw-qos.h\"\n#include \"am65-cpts.h\"\n#include \"cpsw_ale.h\"\n\n#define AM65_CPSW_REG_CTL\t\t\t0x004\n#define AM65_CPSW_PN_REG_CTL\t\t\t0x004\n#define AM65_CPSW_PN_REG_FIFO_STATUS\t\t0x050\n#define AM65_CPSW_PN_REG_EST_CTL\t\t0x060\n#define AM65_CPSW_PN_REG_PRI_CIR(pri)\t\t(0x140 + 4 * (pri))\n\n \n#define AM65_CPSW_CTL_EST_EN\t\t\tBIT(18)\n\n \n#define AM65_CPSW_PN_CTL_EST_PORT_EN\t\tBIT(17)\n\n \n#define AM65_CPSW_PN_EST_ONEBUF\t\t\tBIT(0)\n#define AM65_CPSW_PN_EST_BUFSEL\t\t\tBIT(1)\n#define AM65_CPSW_PN_EST_TS_EN\t\t\tBIT(2)\n#define AM65_CPSW_PN_EST_TS_FIRST\t\tBIT(3)\n#define AM65_CPSW_PN_EST_ONEPRI\t\t\tBIT(4)\n#define AM65_CPSW_PN_EST_TS_PRI_MSK\t\tGENMASK(7, 5)\n\n \n#define AM65_CPSW_PN_FST_TX_PRI_ACTIVE_MSK\tGENMASK(7, 0)\n#define AM65_CPSW_PN_FST_TX_E_MAC_ALLOW_MSK\tGENMASK(15, 8)\n#define AM65_CPSW_PN_FST_EST_CNT_ERR\t\tBIT(16)\n#define AM65_CPSW_PN_FST_EST_ADD_ERR\t\tBIT(17)\n#define AM65_CPSW_PN_FST_EST_BUFACT\t\tBIT(18)\n\n \n#define AM65_CPSW_FETCH_RAM_CMD_NUM\t\t0x80\n#define AM65_CPSW_FETCH_CNT_MSK\t\t\tGENMASK(21, 8)\n#define AM65_CPSW_FETCH_CNT_MAX\t\t\t(AM65_CPSW_FETCH_CNT_MSK >> 8)\n#define AM65_CPSW_FETCH_CNT_OFFSET\t\t8\n#define AM65_CPSW_FETCH_ALLOW_MSK\t\tGENMASK(7, 0)\n#define AM65_CPSW_FETCH_ALLOW_MAX\t\tAM65_CPSW_FETCH_ALLOW_MSK\n\nenum timer_act {\n\tTACT_PROG,\t\t \n\tTACT_NEED_STOP,\t\t \n\tTACT_SKIP_PROG,\t\t \n};\n\nstatic int am65_cpsw_port_est_enabled(struct am65_cpsw_port *port)\n{\n\treturn port->qos.est_oper || port->qos.est_admin;\n}\n\nstatic void am65_cpsw_est_enable(struct am65_cpsw_common *common, int enable)\n{\n\tu32 val;\n\n\tval = readl(common->cpsw_base + AM65_CPSW_REG_CTL);\n\n\tif (enable)\n\t\tval |= AM65_CPSW_CTL_EST_EN;\n\telse\n\t\tval &= ~AM65_CPSW_CTL_EST_EN;\n\n\twritel(val, common->cpsw_base + AM65_CPSW_REG_CTL);\n\tcommon->est_enabled = enable;\n}\n\nstatic void am65_cpsw_port_est_enable(struct am65_cpsw_port *port, int enable)\n{\n\tu32 val;\n\n\tval = readl(port->port_base + AM65_CPSW_PN_REG_CTL);\n\tif (enable)\n\t\tval |= AM65_CPSW_PN_CTL_EST_PORT_EN;\n\telse\n\t\tval &= ~AM65_CPSW_PN_CTL_EST_PORT_EN;\n\n\twritel(val, port->port_base + AM65_CPSW_PN_REG_CTL);\n}\n\n \nstatic void am65_cpsw_port_est_assign_buf_num(struct net_device *ndev,\n\t\t\t\t\t      int buf_num)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tu32 val;\n\n\tval = readl(port->port_base + AM65_CPSW_PN_REG_EST_CTL);\n\tif (buf_num)\n\t\tval |= AM65_CPSW_PN_EST_BUFSEL;\n\telse\n\t\tval &= ~AM65_CPSW_PN_EST_BUFSEL;\n\n\twritel(val, port->port_base + AM65_CPSW_PN_REG_EST_CTL);\n}\n\n \nstatic int am65_cpsw_port_est_is_swapped(struct net_device *ndev, int *oper,\n\t\t\t\t\t int *admin)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tu32 val;\n\n\tval = readl(port->port_base + AM65_CPSW_PN_REG_FIFO_STATUS);\n\t*oper = !!(val & AM65_CPSW_PN_FST_EST_BUFACT);\n\n\tval = readl(port->port_base + AM65_CPSW_PN_REG_EST_CTL);\n\t*admin = !!(val & AM65_CPSW_PN_EST_BUFSEL);\n\n\treturn *admin == *oper;\n}\n\n \nstatic int am65_cpsw_port_est_get_free_buf_num(struct net_device *ndev)\n{\n\tint oper, admin;\n\tint roll = 2;\n\n\twhile (roll--) {\n\t\tif (am65_cpsw_port_est_is_swapped(ndev, &oper, &admin))\n\t\t\treturn !oper;\n\n\t\t \n\t\tam65_cpsw_port_est_assign_buf_num(ndev, oper);\n\n\t\tdev_info(&ndev->dev,\n\t\t\t \"Prev. EST admin cycle is in transit %d -> %d\\n\",\n\t\t\t oper, admin);\n\t}\n\n\treturn admin;\n}\n\nstatic void am65_cpsw_admin_to_oper(struct net_device *ndev)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\n\tdevm_kfree(&ndev->dev, port->qos.est_oper);\n\n\tport->qos.est_oper = port->qos.est_admin;\n\tport->qos.est_admin = NULL;\n}\n\nstatic void am65_cpsw_port_est_get_buf_num(struct net_device *ndev,\n\t\t\t\t\t   struct am65_cpsw_est *est_new)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tu32 val;\n\n\tval = readl(port->port_base + AM65_CPSW_PN_REG_EST_CTL);\n\tval &= ~AM65_CPSW_PN_EST_ONEBUF;\n\twritel(val, port->port_base + AM65_CPSW_PN_REG_EST_CTL);\n\n\test_new->buf = am65_cpsw_port_est_get_free_buf_num(ndev);\n\n\t \n\tif (port->qos.est_oper && port->qos.est_admin &&\n\t    est_new->buf == port->qos.est_oper->buf)\n\t\tam65_cpsw_admin_to_oper(ndev);\n}\n\nstatic void am65_cpsw_est_set(struct net_device *ndev, int enable)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tstruct am65_cpsw_common *common = port->common;\n\tint common_enable = 0;\n\tint i;\n\n\tam65_cpsw_port_est_enable(port, enable);\n\n\tfor (i = 0; i < common->port_num; i++)\n\t\tcommon_enable |= am65_cpsw_port_est_enabled(&common->ports[i]);\n\n\tcommon_enable |= enable;\n\tam65_cpsw_est_enable(common, common_enable);\n}\n\n \nstatic void am65_cpsw_est_update_state(struct net_device *ndev)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tint oper, admin;\n\n\tif (!port->qos.est_admin)\n\t\treturn;\n\n\tif (!am65_cpsw_port_est_is_swapped(ndev, &oper, &admin))\n\t\treturn;\n\n\tam65_cpsw_admin_to_oper(ndev);\n}\n\n \nstatic int am65_est_cmd_ns_to_cnt(u64 ns, int link_speed)\n{\n\tu64 temp;\n\n\ttemp = ns * link_speed;\n\tif (link_speed < SPEED_1000)\n\t\ttemp <<= 1;\n\n\treturn DIV_ROUND_UP(temp, 8 * 1000);\n}\n\nstatic void __iomem *am65_cpsw_est_set_sched_cmds(void __iomem *addr,\n\t\t\t\t\t\t  int fetch_cnt,\n\t\t\t\t\t\t  int fetch_allow)\n{\n\tu32 prio_mask, cmd_fetch_cnt, cmd;\n\n\tdo {\n\t\tif (fetch_cnt > AM65_CPSW_FETCH_CNT_MAX) {\n\t\t\tfetch_cnt -= AM65_CPSW_FETCH_CNT_MAX;\n\t\t\tcmd_fetch_cnt = AM65_CPSW_FETCH_CNT_MAX;\n\t\t} else {\n\t\t\tcmd_fetch_cnt = fetch_cnt;\n\t\t\t \n\t\t\tif (cmd_fetch_cnt && cmd_fetch_cnt < 16)\n\t\t\t\tcmd_fetch_cnt = 16;\n\n\t\t\tfetch_cnt = 0;\n\t\t}\n\n\t\tprio_mask = fetch_allow & AM65_CPSW_FETCH_ALLOW_MSK;\n\t\tcmd = (cmd_fetch_cnt << AM65_CPSW_FETCH_CNT_OFFSET) | prio_mask;\n\n\t\twritel(cmd, addr);\n\t\taddr += 4;\n\t} while (fetch_cnt);\n\n\treturn addr;\n}\n\nstatic int am65_cpsw_est_calc_cmd_num(struct net_device *ndev,\n\t\t\t\t      struct tc_taprio_qopt_offload *taprio,\n\t\t\t\t      int link_speed)\n{\n\tint i, cmd_cnt, cmd_sum = 0;\n\tu32 fetch_cnt;\n\n\tfor (i = 0; i < taprio->num_entries; i++) {\n\t\tif (taprio->entries[i].command != TC_TAPRIO_CMD_SET_GATES) {\n\t\t\tdev_err(&ndev->dev, \"Only SET command is supported\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tfetch_cnt = am65_est_cmd_ns_to_cnt(taprio->entries[i].interval,\n\t\t\t\t\t\t   link_speed);\n\n\t\tcmd_cnt = DIV_ROUND_UP(fetch_cnt, AM65_CPSW_FETCH_CNT_MAX);\n\t\tif (!cmd_cnt)\n\t\t\tcmd_cnt++;\n\n\t\tcmd_sum += cmd_cnt;\n\n\t\tif (!fetch_cnt)\n\t\t\tbreak;\n\t}\n\n\treturn cmd_sum;\n}\n\nstatic int am65_cpsw_est_check_scheds(struct net_device *ndev,\n\t\t\t\t      struct am65_cpsw_est *est_new)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tint cmd_num;\n\n\tcmd_num = am65_cpsw_est_calc_cmd_num(ndev, &est_new->taprio,\n\t\t\t\t\t     port->qos.link_speed);\n\tif (cmd_num < 0)\n\t\treturn cmd_num;\n\n\tif (cmd_num > AM65_CPSW_FETCH_RAM_CMD_NUM / 2) {\n\t\tdev_err(&ndev->dev, \"No fetch RAM\");\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void am65_cpsw_est_set_sched_list(struct net_device *ndev,\n\t\t\t\t\t struct am65_cpsw_est *est_new)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tu32 fetch_cnt, fetch_allow, all_fetch_allow = 0;\n\tvoid __iomem *ram_addr, *max_ram_addr;\n\tstruct tc_taprio_sched_entry *entry;\n\tint i, ram_size;\n\n\tram_addr = port->fetch_ram_base;\n\tram_size = AM65_CPSW_FETCH_RAM_CMD_NUM * 2;\n\tram_addr += est_new->buf * ram_size;\n\n\tmax_ram_addr = ram_size + ram_addr;\n\tfor (i = 0; i < est_new->taprio.num_entries; i++) {\n\t\tentry = &est_new->taprio.entries[i];\n\n\t\tfetch_cnt = am65_est_cmd_ns_to_cnt(entry->interval,\n\t\t\t\t\t\t   port->qos.link_speed);\n\t\tfetch_allow = entry->gate_mask;\n\t\tif (fetch_allow > AM65_CPSW_FETCH_ALLOW_MAX)\n\t\t\tdev_dbg(&ndev->dev, \"fetch_allow > 8 bits: %d\\n\",\n\t\t\t\tfetch_allow);\n\n\t\tram_addr = am65_cpsw_est_set_sched_cmds(ram_addr, fetch_cnt,\n\t\t\t\t\t\t\tfetch_allow);\n\n\t\tif (!fetch_cnt && i < est_new->taprio.num_entries - 1) {\n\t\t\tdev_info(&ndev->dev,\n\t\t\t\t \"next scheds after %d have no impact\", i + 1);\n\t\t\tbreak;\n\t\t}\n\n\t\tall_fetch_allow |= fetch_allow;\n\t}\n\n\t \n\tif (ram_addr < max_ram_addr)\n\t\twritel(~all_fetch_allow & AM65_CPSW_FETCH_ALLOW_MSK, ram_addr);\n}\n\n \nstatic int am65_cpsw_timer_set(struct net_device *ndev,\n\t\t\t       struct am65_cpsw_est *est_new)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tstruct am65_cpsw_common *common = port->common;\n\tstruct am65_cpts *cpts = common->cpts;\n\tstruct am65_cpts_estf_cfg cfg;\n\n\tcfg.ns_period = est_new->taprio.cycle_time;\n\tcfg.ns_start = est_new->taprio.base_time;\n\n\treturn am65_cpts_estf_enable(cpts, port->port_id - 1, &cfg);\n}\n\nstatic void am65_cpsw_timer_stop(struct net_device *ndev)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tstruct am65_cpts *cpts = port->common->cpts;\n\n\tam65_cpts_estf_disable(cpts, port->port_id - 1);\n}\n\nstatic enum timer_act am65_cpsw_timer_act(struct net_device *ndev,\n\t\t\t\t\t  struct am65_cpsw_est *est_new)\n{\n\tstruct tc_taprio_qopt_offload *taprio_oper, *taprio_new;\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tstruct am65_cpts *cpts = port->common->cpts;\n\tu64 cur_time;\n\ts64 diff;\n\n\tif (!port->qos.est_oper)\n\t\treturn TACT_PROG;\n\n\ttaprio_new = &est_new->taprio;\n\ttaprio_oper = &port->qos.est_oper->taprio;\n\n\tif (taprio_new->cycle_time != taprio_oper->cycle_time)\n\t\treturn TACT_NEED_STOP;\n\n\t \n\tif (!taprio_new->base_time && taprio_oper)\n\t\ttaprio_new->base_time = taprio_oper->base_time;\n\n\tif (taprio_new->base_time == taprio_oper->base_time)\n\t\treturn TACT_SKIP_PROG;\n\n\t \n\tdiff = taprio_new->base_time - taprio_oper->base_time;\n\tdiff = diff < 0 ? -diff : diff;\n\tif (diff % taprio_new->cycle_time)\n\t\treturn TACT_NEED_STOP;\n\n\tcur_time = am65_cpts_ns_gettime(cpts);\n\tif (taprio_new->base_time <= cur_time + taprio_new->cycle_time)\n\t\treturn TACT_SKIP_PROG;\n\n\t \n\treturn TACT_NEED_STOP;\n}\n\nstatic void am65_cpsw_stop_est(struct net_device *ndev)\n{\n\tam65_cpsw_est_set(ndev, 0);\n\tam65_cpsw_timer_stop(ndev);\n}\n\nstatic void am65_cpsw_purge_est(struct net_device *ndev)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\n\tam65_cpsw_stop_est(ndev);\n\n\tdevm_kfree(&ndev->dev, port->qos.est_admin);\n\tdevm_kfree(&ndev->dev, port->qos.est_oper);\n\n\tport->qos.est_oper = NULL;\n\tport->qos.est_admin = NULL;\n}\n\nstatic int am65_cpsw_configure_taprio(struct net_device *ndev,\n\t\t\t\t      struct am65_cpsw_est *est_new)\n{\n\tstruct am65_cpsw_common *common = am65_ndev_to_common(ndev);\n\tstruct am65_cpts *cpts = common->cpts;\n\tint ret = 0, tact = TACT_PROG;\n\n\tam65_cpsw_est_update_state(ndev);\n\n\tif (est_new->taprio.cmd == TAPRIO_CMD_DESTROY) {\n\t\tam65_cpsw_stop_est(ndev);\n\t\treturn ret;\n\t}\n\n\tret = am65_cpsw_est_check_scheds(ndev, est_new);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttact = am65_cpsw_timer_act(ndev, est_new);\n\tif (tact == TACT_NEED_STOP) {\n\t\tdev_err(&ndev->dev,\n\t\t\t\"Can't toggle estf timer, stop taprio first\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (tact == TACT_PROG)\n\t\tam65_cpsw_timer_stop(ndev);\n\n\tif (!est_new->taprio.base_time)\n\t\test_new->taprio.base_time = am65_cpts_ns_gettime(cpts);\n\n\tam65_cpsw_port_est_get_buf_num(ndev, est_new);\n\tam65_cpsw_est_set_sched_list(ndev, est_new);\n\tam65_cpsw_port_est_assign_buf_num(ndev, est_new->buf);\n\n\tam65_cpsw_est_set(ndev, est_new->taprio.cmd == TAPRIO_CMD_REPLACE);\n\n\tif (tact == TACT_PROG) {\n\t\tret = am65_cpsw_timer_set(ndev, est_new);\n\t\tif (ret) {\n\t\t\tdev_err(&ndev->dev, \"Failed to set cycle time\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic void am65_cpsw_cp_taprio(struct tc_taprio_qopt_offload *from,\n\t\t\t\tstruct tc_taprio_qopt_offload *to)\n{\n\tint i;\n\n\t*to = *from;\n\tfor (i = 0; i < from->num_entries; i++)\n\t\tto->entries[i] = from->entries[i];\n}\n\nstatic int am65_cpsw_set_taprio(struct net_device *ndev, void *type_data)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tstruct tc_taprio_qopt_offload *taprio = type_data;\n\tstruct am65_cpsw_est *est_new;\n\tint ret = 0;\n\n\tif (taprio->cycle_time_extension) {\n\t\tdev_err(&ndev->dev, \"Failed to set cycle time extension\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\test_new = devm_kzalloc(&ndev->dev,\n\t\t\t       struct_size(est_new, taprio.entries, taprio->num_entries),\n\t\t\t       GFP_KERNEL);\n\tif (!est_new)\n\t\treturn -ENOMEM;\n\n\tam65_cpsw_cp_taprio(taprio, &est_new->taprio);\n\tret = am65_cpsw_configure_taprio(ndev, est_new);\n\tif (!ret) {\n\t\tif (taprio->cmd == TAPRIO_CMD_REPLACE) {\n\t\t\tdevm_kfree(&ndev->dev, port->qos.est_admin);\n\n\t\t\tport->qos.est_admin = est_new;\n\t\t} else {\n\t\t\tdevm_kfree(&ndev->dev, est_new);\n\t\t\tam65_cpsw_purge_est(ndev);\n\t\t}\n\t} else {\n\t\tdevm_kfree(&ndev->dev, est_new);\n\t}\n\n\treturn ret;\n}\n\nstatic void am65_cpsw_est_link_up(struct net_device *ndev, int link_speed)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tktime_t cur_time;\n\ts64 delta;\n\n\tport->qos.link_speed = link_speed;\n\tif (!am65_cpsw_port_est_enabled(port))\n\t\treturn;\n\n\tif (port->qos.link_down_time) {\n\t\tcur_time = ktime_get();\n\t\tdelta = ktime_us_delta(cur_time, port->qos.link_down_time);\n\t\tif (delta > USEC_PER_SEC) {\n\t\t\tdev_err(&ndev->dev,\n\t\t\t\t\"Link has been lost too long, stopping TAS\");\n\t\t\tgoto purge_est;\n\t\t}\n\t}\n\n\treturn;\n\npurge_est:\n\tam65_cpsw_purge_est(ndev);\n}\n\nstatic int am65_cpsw_setup_taprio(struct net_device *ndev, void *type_data)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tstruct tc_taprio_qopt_offload *taprio = type_data;\n\tstruct am65_cpsw_common *common = port->common;\n\n\tif (taprio->cmd != TAPRIO_CMD_REPLACE &&\n\t    taprio->cmd != TAPRIO_CMD_DESTROY)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!IS_ENABLED(CONFIG_TI_AM65_CPSW_TAS))\n\t\treturn -ENODEV;\n\n\tif (!netif_running(ndev)) {\n\t\tdev_err(&ndev->dev, \"interface is down, link speed unknown\\n\");\n\t\treturn -ENETDOWN;\n\t}\n\n\tif (common->pf_p0_rx_ptype_rrobin) {\n\t\tdev_err(&ndev->dev,\n\t\t\t\"p0-rx-ptype-rrobin flag conflicts with taprio qdisc\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (port->qos.link_speed == SPEED_UNKNOWN)\n\t\treturn -ENOLINK;\n\n\treturn am65_cpsw_set_taprio(ndev, type_data);\n}\n\nstatic int am65_cpsw_tc_query_caps(struct net_device *ndev, void *type_data)\n{\n\tstruct tc_query_caps_base *base = type_data;\n\n\tswitch (base->type) {\n\tcase TC_SETUP_QDISC_TAPRIO: {\n\t\tstruct tc_taprio_caps *caps = base->caps;\n\n\t\tif (!IS_ENABLED(CONFIG_TI_AM65_CPSW_TAS))\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tcaps->gate_mask_per_txq = true;\n\n\t\treturn 0;\n\t}\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int am65_cpsw_qos_clsflower_add_policer(struct am65_cpsw_port *port,\n\t\t\t\t\t       struct netlink_ext_ack *extack,\n\t\t\t\t\t       struct flow_cls_offload *cls,\n\t\t\t\t\t       u64 rate_pkt_ps)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(cls);\n\tstruct flow_dissector *dissector = rule->match.dissector;\n\tstatic const u8 mc_mac[] = {0x01, 0x00, 0x00, 0x00, 0x00, 0x00};\n\tstruct am65_cpsw_qos *qos = &port->qos;\n\tstruct flow_match_eth_addrs match;\n\tint ret;\n\n\tif (dissector->used_keys &\n\t    ~(BIT_ULL(FLOW_DISSECTOR_KEY_BASIC) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_CONTROL) |\n\t      BIT_ULL(FLOW_DISSECTOR_KEY_ETH_ADDRS))) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Unsupported keys used\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Not matching on eth address\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tflow_rule_match_eth_addrs(rule, &match);\n\n\tif (!is_zero_ether_addr(match.mask->src)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Matching on source MAC not supported\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (is_broadcast_ether_addr(match.key->dst) &&\n\t    is_broadcast_ether_addr(match.mask->dst)) {\n\t\tret = cpsw_ale_rx_ratelimit_bc(port->common->ale, port->port_id, rate_pkt_ps);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tqos->ale_bc_ratelimit.cookie = cls->cookie;\n\t\tqos->ale_bc_ratelimit.rate_packet_ps = rate_pkt_ps;\n\t} else if (ether_addr_equal_unaligned(match.key->dst, mc_mac) &&\n\t\t   ether_addr_equal_unaligned(match.mask->dst, mc_mac)) {\n\t\tret = cpsw_ale_rx_ratelimit_mc(port->common->ale, port->port_id, rate_pkt_ps);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tqos->ale_mc_ratelimit.cookie = cls->cookie;\n\t\tqos->ale_mc_ratelimit.rate_packet_ps = rate_pkt_ps;\n\t} else {\n\t\tNL_SET_ERR_MSG_MOD(extack, \"Not supported matching key\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int am65_cpsw_qos_clsflower_policer_validate(const struct flow_action *action,\n\t\t\t\t\t\t    const struct flow_action_entry *act,\n\t\t\t\t\t\t    struct netlink_ext_ack *extack)\n{\n\tif (act->police.exceed.act_id != FLOW_ACTION_DROP) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when exceed action is not drop\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id != FLOW_ACTION_PIPE &&\n\t    act->police.notexceed.act_id != FLOW_ACTION_ACCEPT) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is not pipe or ok\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.notexceed.act_id == FLOW_ACTION_ACCEPT &&\n\t    !flow_action_is_last_entry(action, act)) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when conform action is ok, but action is not last\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (act->police.rate_bytes_ps || act->police.peakrate_bytes_ps ||\n\t    act->police.avrate || act->police.overhead) {\n\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t   \"Offload not supported when bytes per second/peakrate/avrate/overhead is configured\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn 0;\n}\n\nstatic int am65_cpsw_qos_configure_clsflower(struct am65_cpsw_port *port,\n\t\t\t\t\t     struct flow_cls_offload *cls)\n{\n\tstruct flow_rule *rule = flow_cls_offload_flow_rule(cls);\n\tstruct netlink_ext_ack *extack = cls->common.extack;\n\tconst struct flow_action_entry *act;\n\tint i, ret;\n\n\tflow_action_for_each(i, act, &rule->action) {\n\t\tswitch (act->id) {\n\t\tcase FLOW_ACTION_POLICE:\n\t\t\tret = am65_cpsw_qos_clsflower_policer_validate(&rule->action, act, extack);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\treturn am65_cpsw_qos_clsflower_add_policer(port, extack, cls,\n\t\t\t\t\t\t\t\t   act->police.rate_pkt_ps);\n\t\tdefault:\n\t\t\tNL_SET_ERR_MSG_MOD(extack,\n\t\t\t\t\t   \"Action not supported\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t}\n\treturn -EOPNOTSUPP;\n}\n\nstatic int am65_cpsw_qos_delete_clsflower(struct am65_cpsw_port *port, struct flow_cls_offload *cls)\n{\n\tstruct am65_cpsw_qos *qos = &port->qos;\n\n\tif (cls->cookie == qos->ale_bc_ratelimit.cookie) {\n\t\tqos->ale_bc_ratelimit.cookie = 0;\n\t\tqos->ale_bc_ratelimit.rate_packet_ps = 0;\n\t\tcpsw_ale_rx_ratelimit_bc(port->common->ale, port->port_id, 0);\n\t}\n\n\tif (cls->cookie == qos->ale_mc_ratelimit.cookie) {\n\t\tqos->ale_mc_ratelimit.cookie = 0;\n\t\tqos->ale_mc_ratelimit.rate_packet_ps = 0;\n\t\tcpsw_ale_rx_ratelimit_mc(port->common->ale, port->port_id, 0);\n\t}\n\n\treturn 0;\n}\n\nstatic int am65_cpsw_qos_setup_tc_clsflower(struct am65_cpsw_port *port,\n\t\t\t\t\t    struct flow_cls_offload *cls_flower)\n{\n\tswitch (cls_flower->command) {\n\tcase FLOW_CLS_REPLACE:\n\t\treturn am65_cpsw_qos_configure_clsflower(port, cls_flower);\n\tcase FLOW_CLS_DESTROY:\n\t\treturn am65_cpsw_qos_delete_clsflower(port, cls_flower);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int am65_cpsw_qos_setup_tc_block_cb(enum tc_setup_type type, void *type_data, void *cb_priv)\n{\n\tstruct am65_cpsw_port *port = cb_priv;\n\n\tif (!tc_cls_can_offload_and_chain0(port->ndev, type_data))\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (type) {\n\tcase TC_SETUP_CLSFLOWER:\n\t\treturn am65_cpsw_qos_setup_tc_clsflower(port, type_data);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic LIST_HEAD(am65_cpsw_qos_block_cb_list);\n\nstatic int am65_cpsw_qos_setup_tc_block(struct net_device *ndev, struct flow_block_offload *f)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\n\treturn flow_block_cb_setup_simple(f, &am65_cpsw_qos_block_cb_list,\n\t\t\t\t\t  am65_cpsw_qos_setup_tc_block_cb,\n\t\t\t\t\t  port, port, true);\n}\n\nint am65_cpsw_qos_ndo_setup_tc(struct net_device *ndev, enum tc_setup_type type,\n\t\t\t       void *type_data)\n{\n\tswitch (type) {\n\tcase TC_QUERY_CAPS:\n\t\treturn am65_cpsw_tc_query_caps(ndev, type_data);\n\tcase TC_SETUP_QDISC_TAPRIO:\n\t\treturn am65_cpsw_setup_taprio(ndev, type_data);\n\tcase TC_SETUP_BLOCK:\n\t\treturn am65_cpsw_qos_setup_tc_block(ndev, type_data);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nvoid am65_cpsw_qos_link_up(struct net_device *ndev, int link_speed)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\n\tif (!IS_ENABLED(CONFIG_TI_AM65_CPSW_TAS))\n\t\treturn;\n\n\tam65_cpsw_est_link_up(ndev, link_speed);\n\tport->qos.link_down_time = 0;\n}\n\nvoid am65_cpsw_qos_link_down(struct net_device *ndev)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\n\tif (!IS_ENABLED(CONFIG_TI_AM65_CPSW_TAS))\n\t\treturn;\n\n\tif (!port->qos.link_down_time)\n\t\tport->qos.link_down_time = ktime_get();\n\n\tport->qos.link_speed = SPEED_UNKNOWN;\n}\n\nstatic u32\nam65_cpsw_qos_tx_rate_calc(u32 rate_mbps, unsigned long bus_freq)\n{\n\tu32 ir;\n\n\tbus_freq /= 1000000;\n\tir = DIV_ROUND_UP(((u64)rate_mbps * 32768),  bus_freq);\n\treturn ir;\n}\n\nstatic void\nam65_cpsw_qos_tx_p0_rate_apply(struct am65_cpsw_common *common,\n\t\t\t       int tx_ch, u32 rate_mbps)\n{\n\tstruct am65_cpsw_host *host = am65_common_get_host(common);\n\tu32 ch_cir;\n\tint i;\n\n\tch_cir = am65_cpsw_qos_tx_rate_calc(rate_mbps, common->bus_freq);\n\twritel(ch_cir, host->port_base + AM65_CPSW_PN_REG_PRI_CIR(tx_ch));\n\n\t \n\tfor (i = 0; i < common->port_num; i++) {\n\t\tstruct net_device *ndev = common->ports[i].ndev;\n\n\t\tif (!ndev)\n\t\t\tcontinue;\n\t\tnetdev_get_tx_queue(ndev, tx_ch)->tx_maxrate = rate_mbps;\n\t}\n}\n\nint am65_cpsw_qos_ndo_tx_p0_set_maxrate(struct net_device *ndev,\n\t\t\t\t\tint queue, u32 rate_mbps)\n{\n\tstruct am65_cpsw_port *port = am65_ndev_to_port(ndev);\n\tstruct am65_cpsw_common *common = port->common;\n\tstruct am65_cpsw_tx_chn *tx_chn;\n\tu32 ch_rate, tx_ch_rate_msk_new;\n\tu32 ch_msk = 0;\n\tint ret;\n\n\tdev_dbg(common->dev, \"apply TX%d rate limiting %uMbps tx_rate_msk%x\\n\",\n\t\tqueue, rate_mbps, common->tx_ch_rate_msk);\n\n\tif (common->pf_p0_rx_ptype_rrobin) {\n\t\tdev_err(common->dev, \"TX Rate Limiting failed - rrobin mode\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tch_rate = netdev_get_tx_queue(ndev, queue)->tx_maxrate;\n\tif (ch_rate == rate_mbps)\n\t\treturn 0;\n\n\tret = pm_runtime_get_sync(common->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_noidle(common->dev);\n\t\treturn ret;\n\t}\n\tret = 0;\n\n\ttx_ch_rate_msk_new = common->tx_ch_rate_msk;\n\tif (rate_mbps && !(tx_ch_rate_msk_new & BIT(queue))) {\n\t\ttx_ch_rate_msk_new |= BIT(queue);\n\t\tch_msk = GENMASK(common->tx_ch_num - 1, queue);\n\t\tch_msk = tx_ch_rate_msk_new ^ ch_msk;\n\t} else if (!rate_mbps) {\n\t\ttx_ch_rate_msk_new &= ~BIT(queue);\n\t\tch_msk = queue ? GENMASK(queue - 1, 0) : 0;\n\t\tch_msk = tx_ch_rate_msk_new & ch_msk;\n\t}\n\n\tif (ch_msk) {\n\t\tdev_err(common->dev, \"TX rate limiting has to be enabled sequentially hi->lo tx_rate_msk:%x tx_rate_msk_new:%x\\n\",\n\t\t\tcommon->tx_ch_rate_msk, tx_ch_rate_msk_new);\n\t\tret = -EINVAL;\n\t\tgoto exit_put;\n\t}\n\n\ttx_chn = &common->tx_chns[queue];\n\ttx_chn->rate_mbps = rate_mbps;\n\tcommon->tx_ch_rate_msk = tx_ch_rate_msk_new;\n\n\tif (!common->usage_count)\n\t\t \n\t\tgoto exit_put;\n\n\tam65_cpsw_qos_tx_p0_rate_apply(common, queue, rate_mbps);\n\nexit_put:\n\tpm_runtime_put(common->dev);\n\treturn ret;\n}\n\nvoid am65_cpsw_qos_tx_p0_rate_init(struct am65_cpsw_common *common)\n{\n\tstruct am65_cpsw_host *host = am65_common_get_host(common);\n\tint tx_ch;\n\n\tfor (tx_ch = 0; tx_ch < common->tx_ch_num; tx_ch++) {\n\t\tstruct am65_cpsw_tx_chn *tx_chn = &common->tx_chns[tx_ch];\n\t\tu32 ch_cir;\n\n\t\tif (!tx_chn->rate_mbps)\n\t\t\tcontinue;\n\n\t\tch_cir = am65_cpsw_qos_tx_rate_calc(tx_chn->rate_mbps,\n\t\t\t\t\t\t    common->bus_freq);\n\t\twritel(ch_cir,\n\t\t       host->port_base + AM65_CPSW_PN_REG_PRI_CIR(tx_ch));\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}