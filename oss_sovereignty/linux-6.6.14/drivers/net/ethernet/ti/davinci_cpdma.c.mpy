{
  "module_name": "davinci_cpdma.c",
  "hash_id": "d884dfcaa04dbdc5ed677c94b34fa81f78e4d544b5dee3d49f8f23736d4eb283",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ti/davinci_cpdma.c",
  "human_readable_source": "\n \n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/device.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/dma-mapping.h>\n#include <linux/io.h>\n#include <linux/delay.h>\n#include <linux/genalloc.h>\n#include \"davinci_cpdma.h\"\n\n \n#define CPDMA_TXIDVER\t\t0x00\n#define CPDMA_TXCONTROL\t\t0x04\n#define CPDMA_TXTEARDOWN\t0x08\n#define CPDMA_RXIDVER\t\t0x10\n#define CPDMA_RXCONTROL\t\t0x14\n#define CPDMA_SOFTRESET\t\t0x1c\n#define CPDMA_RXTEARDOWN\t0x18\n#define CPDMA_TX_PRI0_RATE\t0x30\n#define CPDMA_TXINTSTATRAW\t0x80\n#define CPDMA_TXINTSTATMASKED\t0x84\n#define CPDMA_TXINTMASKSET\t0x88\n#define CPDMA_TXINTMASKCLEAR\t0x8c\n#define CPDMA_MACINVECTOR\t0x90\n#define CPDMA_MACEOIVECTOR\t0x94\n#define CPDMA_RXINTSTATRAW\t0xa0\n#define CPDMA_RXINTSTATMASKED\t0xa4\n#define CPDMA_RXINTMASKSET\t0xa8\n#define CPDMA_RXINTMASKCLEAR\t0xac\n#define CPDMA_DMAINTSTATRAW\t0xb0\n#define CPDMA_DMAINTSTATMASKED\t0xb4\n#define CPDMA_DMAINTMASKSET\t0xb8\n#define CPDMA_DMAINTMASKCLEAR\t0xbc\n#define CPDMA_DMAINT_HOSTERR\tBIT(1)\n\n \n#define CPDMA_DMACONTROL\t0x20\n#define CPDMA_DMASTATUS\t\t0x24\n#define CPDMA_RXBUFFOFS\t\t0x28\n#define CPDMA_EM_CONTROL\t0x2c\n\n \n#define CPDMA_DESC_SOP\t\tBIT(31)\n#define CPDMA_DESC_EOP\t\tBIT(30)\n#define CPDMA_DESC_OWNER\tBIT(29)\n#define CPDMA_DESC_EOQ\t\tBIT(28)\n#define CPDMA_DESC_TD_COMPLETE\tBIT(27)\n#define CPDMA_DESC_PASS_CRC\tBIT(26)\n#define CPDMA_DESC_TO_PORT_EN\tBIT(20)\n#define CPDMA_TO_PORT_SHIFT\t16\n#define CPDMA_DESC_PORT_MASK\t(BIT(18) | BIT(17) | BIT(16))\n#define CPDMA_DESC_CRC_LEN\t4\n\n#define CPDMA_TEARDOWN_VALUE\t0xfffffffc\n\n#define CPDMA_MAX_RLIM_CNT\t16384\n\nstruct cpdma_desc {\n\t \n\tu32\t\t\thw_next;\n\tu32\t\t\thw_buffer;\n\tu32\t\t\thw_len;\n\tu32\t\t\thw_mode;\n\t \n\tvoid\t\t\t*sw_token;\n\tu32\t\t\tsw_buffer;\n\tu32\t\t\tsw_len;\n};\n\nstruct cpdma_desc_pool {\n\tphys_addr_t\t\tphys;\n\tdma_addr_t\t\thw_addr;\n\tvoid __iomem\t\t*iomap;\t\t \n\tvoid\t\t\t*cpumap;\t \n\tint\t\t\tdesc_size, mem_size;\n\tint\t\t\tnum_desc;\n\tstruct device\t\t*dev;\n\tstruct gen_pool\t\t*gen_pool;\n};\n\nenum cpdma_state {\n\tCPDMA_STATE_IDLE,\n\tCPDMA_STATE_ACTIVE,\n\tCPDMA_STATE_TEARDOWN,\n};\n\nstruct cpdma_ctlr {\n\tenum cpdma_state\tstate;\n\tstruct cpdma_params\tparams;\n\tstruct device\t\t*dev;\n\tstruct cpdma_desc_pool\t*pool;\n\tspinlock_t\t\tlock;\n\tstruct cpdma_chan\t*channels[2 * CPDMA_MAX_CHANNELS];\n\tint chan_num;\n\tint\t\t\tnum_rx_desc;  \n\tint\t\t\tnum_tx_desc;  \n};\n\nstruct cpdma_chan {\n\tstruct cpdma_desc __iomem\t*head, *tail;\n\tvoid __iomem\t\t\t*hdp, *cp, *rxfree;\n\tenum cpdma_state\t\tstate;\n\tstruct cpdma_ctlr\t\t*ctlr;\n\tint\t\t\t\tchan_num;\n\tspinlock_t\t\t\tlock;\n\tint\t\t\t\tcount;\n\tu32\t\t\t\tdesc_num;\n\tu32\t\t\t\tmask;\n\tcpdma_handler_fn\t\thandler;\n\tenum dma_data_direction\t\tdir;\n\tstruct cpdma_chan_stats\t\tstats;\n\t \n\tint\tint_set, int_clear, td;\n\tint\t\t\t\tweight;\n\tu32\t\t\t\trate_factor;\n\tu32\t\t\t\trate;\n};\n\nstruct cpdma_control_info {\n\tu32\t\treg;\n\tu32\t\tshift, mask;\n\tint\t\taccess;\n#define ACCESS_RO\tBIT(0)\n#define ACCESS_WO\tBIT(1)\n#define ACCESS_RW\t(ACCESS_RO | ACCESS_WO)\n};\n\nstruct submit_info {\n\tstruct cpdma_chan *chan;\n\tint directed;\n\tvoid *token;\n\tvoid *data_virt;\n\tdma_addr_t data_dma;\n\tint len;\n};\n\nstatic struct cpdma_control_info controls[] = {\n\t[CPDMA_TX_RLIM]\t\t  = {CPDMA_DMACONTROL,\t8,  0xffff, ACCESS_RW},\n\t[CPDMA_CMD_IDLE]\t  = {CPDMA_DMACONTROL,\t3,  1,      ACCESS_WO},\n\t[CPDMA_COPY_ERROR_FRAMES] = {CPDMA_DMACONTROL,\t4,  1,      ACCESS_RW},\n\t[CPDMA_RX_OFF_LEN_UPDATE] = {CPDMA_DMACONTROL,\t2,  1,      ACCESS_RW},\n\t[CPDMA_RX_OWNERSHIP_FLIP] = {CPDMA_DMACONTROL,\t1,  1,      ACCESS_RW},\n\t[CPDMA_TX_PRIO_FIXED]\t  = {CPDMA_DMACONTROL,\t0,  1,      ACCESS_RW},\n\t[CPDMA_STAT_IDLE]\t  = {CPDMA_DMASTATUS,\t31, 1,      ACCESS_RO},\n\t[CPDMA_STAT_TX_ERR_CODE]  = {CPDMA_DMASTATUS,\t20, 0xf,    ACCESS_RW},\n\t[CPDMA_STAT_TX_ERR_CHAN]  = {CPDMA_DMASTATUS,\t16, 0x7,    ACCESS_RW},\n\t[CPDMA_STAT_RX_ERR_CODE]  = {CPDMA_DMASTATUS,\t12, 0xf,    ACCESS_RW},\n\t[CPDMA_STAT_RX_ERR_CHAN]  = {CPDMA_DMASTATUS,\t8,  0x7,    ACCESS_RW},\n\t[CPDMA_RX_BUFFER_OFFSET]  = {CPDMA_RXBUFFOFS,\t0,  0xffff, ACCESS_RW},\n};\n\n#define tx_chan_num(chan)\t(chan)\n#define rx_chan_num(chan)\t((chan) + CPDMA_MAX_CHANNELS)\n#define is_rx_chan(chan)\t((chan)->chan_num >= CPDMA_MAX_CHANNELS)\n#define is_tx_chan(chan)\t(!is_rx_chan(chan))\n#define __chan_linear(chan_num)\t((chan_num) & (CPDMA_MAX_CHANNELS - 1))\n#define chan_linear(chan)\t__chan_linear((chan)->chan_num)\n\n \n#define dmaregs\t\tparams.dmaregs\n#define num_chan\tparams.num_chan\n\n \n#define dma_reg_read(ctlr, ofs)\t\treadl((ctlr)->dmaregs + (ofs))\n#define chan_read(chan, fld)\t\treadl((chan)->fld)\n#define desc_read(desc, fld)\t\treadl(&(desc)->fld)\n#define dma_reg_write(ctlr, ofs, v)\twritel(v, (ctlr)->dmaregs + (ofs))\n#define chan_write(chan, fld, v)\twritel(v, (chan)->fld)\n#define desc_write(desc, fld, v)\twritel((u32)(v), &(desc)->fld)\n\n#define cpdma_desc_to_port(chan, mode, directed)\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif (!is_rx_chan(chan) && ((directed == 1) ||\t\t\\\n\t\t\t\t\t  (directed == 2)))\t\t\\\n\t\t\tmode |= (CPDMA_DESC_TO_PORT_EN |\t\t\\\n\t\t\t\t (directed << CPDMA_TO_PORT_SHIFT));\t\\\n\t} while (0)\n\n#define CPDMA_DMA_EXT_MAP\t\tBIT(16)\n\nstatic void cpdma_desc_pool_destroy(struct cpdma_ctlr *ctlr)\n{\n\tstruct cpdma_desc_pool *pool = ctlr->pool;\n\n\tif (!pool)\n\t\treturn;\n\n\tWARN(gen_pool_size(pool->gen_pool) != gen_pool_avail(pool->gen_pool),\n\t     \"cpdma_desc_pool size %zd != avail %zd\",\n\t     gen_pool_size(pool->gen_pool),\n\t     gen_pool_avail(pool->gen_pool));\n\tif (pool->cpumap)\n\t\tdma_free_coherent(ctlr->dev, pool->mem_size, pool->cpumap,\n\t\t\t\t  pool->phys);\n}\n\n \nstatic int cpdma_desc_pool_create(struct cpdma_ctlr *ctlr)\n{\n\tstruct cpdma_params *cpdma_params = &ctlr->params;\n\tstruct cpdma_desc_pool *pool;\n\tint ret = -ENOMEM;\n\n\tpool = devm_kzalloc(ctlr->dev, sizeof(*pool), GFP_KERNEL);\n\tif (!pool)\n\t\tgoto gen_pool_create_fail;\n\tctlr->pool = pool;\n\n\tpool->mem_size\t= cpdma_params->desc_mem_size;\n\tpool->desc_size\t= ALIGN(sizeof(struct cpdma_desc),\n\t\t\t\tcpdma_params->desc_align);\n\tpool->num_desc\t= pool->mem_size / pool->desc_size;\n\n\tif (cpdma_params->descs_pool_size) {\n\t\t \n\t\tpool->num_desc = cpdma_params->descs_pool_size;\n\t\tpool->mem_size = pool->desc_size * pool->num_desc;\n\t\tif (pool->mem_size > cpdma_params->desc_mem_size)\n\t\t\tcpdma_params->desc_mem_phys = 0;\n\t}\n\n\tpool->gen_pool = devm_gen_pool_create(ctlr->dev, ilog2(pool->desc_size),\n\t\t\t\t\t      -1, \"cpdma\");\n\tif (IS_ERR(pool->gen_pool)) {\n\t\tret = PTR_ERR(pool->gen_pool);\n\t\tdev_err(ctlr->dev, \"pool create failed %d\\n\", ret);\n\t\tgoto gen_pool_create_fail;\n\t}\n\n\tif (cpdma_params->desc_mem_phys) {\n\t\tpool->phys  = cpdma_params->desc_mem_phys;\n\t\tpool->iomap = devm_ioremap(ctlr->dev, pool->phys,\n\t\t\t\t\t   pool->mem_size);\n\t\tpool->hw_addr = cpdma_params->desc_hw_addr;\n\t} else {\n\t\tpool->cpumap = dma_alloc_coherent(ctlr->dev,  pool->mem_size,\n\t\t\t\t\t\t  &pool->hw_addr, GFP_KERNEL);\n\t\tpool->iomap = (void __iomem __force *)pool->cpumap;\n\t\tpool->phys = pool->hw_addr;  \n\t}\n\n\tif (!pool->iomap)\n\t\tgoto gen_pool_create_fail;\n\n\tret = gen_pool_add_virt(pool->gen_pool, (unsigned long)pool->iomap,\n\t\t\t\tpool->phys, pool->mem_size, -1);\n\tif (ret < 0) {\n\t\tdev_err(ctlr->dev, \"pool add failed %d\\n\", ret);\n\t\tgoto gen_pool_add_virt_fail;\n\t}\n\n\treturn 0;\n\ngen_pool_add_virt_fail:\n\tcpdma_desc_pool_destroy(ctlr);\ngen_pool_create_fail:\n\tctlr->pool = NULL;\n\treturn ret;\n}\n\nstatic inline dma_addr_t desc_phys(struct cpdma_desc_pool *pool,\n\t\t  struct cpdma_desc __iomem *desc)\n{\n\tif (!desc)\n\t\treturn 0;\n\treturn pool->hw_addr + (__force long)desc - (__force long)pool->iomap;\n}\n\nstatic inline struct cpdma_desc __iomem *\ndesc_from_phys(struct cpdma_desc_pool *pool, dma_addr_t dma)\n{\n\treturn dma ? pool->iomap + dma - pool->hw_addr : NULL;\n}\n\nstatic struct cpdma_desc __iomem *\ncpdma_desc_alloc(struct cpdma_desc_pool *pool)\n{\n\treturn (struct cpdma_desc __iomem *)\n\t\tgen_pool_alloc(pool->gen_pool, pool->desc_size);\n}\n\nstatic void cpdma_desc_free(struct cpdma_desc_pool *pool,\n\t\t\t    struct cpdma_desc __iomem *desc, int num_desc)\n{\n\tgen_pool_free(pool->gen_pool, (unsigned long)desc, pool->desc_size);\n}\n\nstatic int _cpdma_control_set(struct cpdma_ctlr *ctlr, int control, int value)\n{\n\tstruct cpdma_control_info *info = &controls[control];\n\tu32 val;\n\n\tif (!ctlr->params.has_ext_regs)\n\t\treturn -ENOTSUPP;\n\n\tif (ctlr->state != CPDMA_STATE_ACTIVE)\n\t\treturn -EINVAL;\n\n\tif (control < 0 || control >= ARRAY_SIZE(controls))\n\t\treturn -ENOENT;\n\n\tif ((info->access & ACCESS_WO) != ACCESS_WO)\n\t\treturn -EPERM;\n\n\tval  = dma_reg_read(ctlr, info->reg);\n\tval &= ~(info->mask << info->shift);\n\tval |= (value & info->mask) << info->shift;\n\tdma_reg_write(ctlr, info->reg, val);\n\n\treturn 0;\n}\n\nstatic int _cpdma_control_get(struct cpdma_ctlr *ctlr, int control)\n{\n\tstruct cpdma_control_info *info = &controls[control];\n\tint ret;\n\n\tif (!ctlr->params.has_ext_regs)\n\t\treturn -ENOTSUPP;\n\n\tif (ctlr->state != CPDMA_STATE_ACTIVE)\n\t\treturn -EINVAL;\n\n\tif (control < 0 || control >= ARRAY_SIZE(controls))\n\t\treturn -ENOENT;\n\n\tif ((info->access & ACCESS_RO) != ACCESS_RO)\n\t\treturn -EPERM;\n\n\tret = (dma_reg_read(ctlr, info->reg) >> info->shift) & info->mask;\n\treturn ret;\n}\n\n \nstatic int cpdma_chan_set_chan_shaper(struct cpdma_chan *chan)\n{\n\tstruct cpdma_ctlr *ctlr = chan->ctlr;\n\tu32 rate_reg;\n\tu32 rmask;\n\tint ret;\n\n\tif (!chan->rate)\n\t\treturn 0;\n\n\trate_reg = CPDMA_TX_PRI0_RATE + 4 * chan->chan_num;\n\tdma_reg_write(ctlr, rate_reg, chan->rate_factor);\n\n\trmask = _cpdma_control_get(ctlr, CPDMA_TX_RLIM);\n\trmask |= chan->mask;\n\n\tret = _cpdma_control_set(ctlr, CPDMA_TX_RLIM, rmask);\n\treturn ret;\n}\n\nstatic int cpdma_chan_on(struct cpdma_chan *chan)\n{\n\tstruct cpdma_ctlr *ctlr = chan->ctlr;\n\tstruct cpdma_desc_pool\t*pool = ctlr->pool;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->state != CPDMA_STATE_IDLE) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EBUSY;\n\t}\n\tif (ctlr->state != CPDMA_STATE_ACTIVE) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\tdma_reg_write(ctlr, chan->int_set, chan->mask);\n\tchan->state = CPDMA_STATE_ACTIVE;\n\tif (chan->head) {\n\t\tchan_write(chan, hdp, desc_phys(pool, chan->head));\n\t\tif (chan->rxfree)\n\t\t\tchan_write(chan, rxfree, chan->count);\n\t}\n\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn 0;\n}\n\n \nstatic int cpdma_chan_fit_rate(struct cpdma_chan *ch, u32 rate,\n\t\t\t       u32 *rmask, int *prio_mode)\n{\n\tstruct cpdma_ctlr *ctlr = ch->ctlr;\n\tstruct cpdma_chan *chan;\n\tu32 old_rate = ch->rate;\n\tu32 new_rmask = 0;\n\tint rlim = 0;\n\tint i;\n\n\tfor (i = tx_chan_num(0); i < tx_chan_num(CPDMA_MAX_CHANNELS); i++) {\n\t\tchan = ctlr->channels[i];\n\t\tif (!chan)\n\t\t\tcontinue;\n\n\t\tif (chan == ch)\n\t\t\tchan->rate = rate;\n\n\t\tif (chan->rate) {\n\t\t\trlim = 1;\n\t\t\tnew_rmask |= chan->mask;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (rlim)\n\t\t\tgoto err;\n\t}\n\n\t*rmask = new_rmask;\n\t*prio_mode = rlim;\n\treturn 0;\n\nerr:\n\tch->rate = old_rate;\n\tdev_err(ctlr->dev, \"Upper cpdma ch%d is not rate limited\\n\",\n\t\tchan->chan_num);\n\treturn -EINVAL;\n}\n\nstatic u32 cpdma_chan_set_factors(struct cpdma_ctlr *ctlr,\n\t\t\t\t  struct cpdma_chan *ch)\n{\n\tu32 delta = UINT_MAX, prev_delta = UINT_MAX, best_delta = UINT_MAX;\n\tu32 best_send_cnt = 0, best_idle_cnt = 0;\n\tu32 new_rate, best_rate = 0, rate_reg;\n\tu64 send_cnt, idle_cnt;\n\tu32 min_send_cnt, freq;\n\tu64 divident, divisor;\n\n\tif (!ch->rate) {\n\t\tch->rate_factor = 0;\n\t\tgoto set_factor;\n\t}\n\n\tfreq = ctlr->params.bus_freq_mhz * 1000 * 32;\n\tif (!freq) {\n\t\tdev_err(ctlr->dev, \"The bus frequency is not set\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmin_send_cnt = freq - ch->rate;\n\tsend_cnt = DIV_ROUND_UP(min_send_cnt, ch->rate);\n\twhile (send_cnt <= CPDMA_MAX_RLIM_CNT) {\n\t\tdivident = ch->rate * send_cnt;\n\t\tdivisor = min_send_cnt;\n\t\tidle_cnt = DIV_ROUND_CLOSEST_ULL(divident, divisor);\n\n\t\tdivident = freq * idle_cnt;\n\t\tdivisor = idle_cnt + send_cnt;\n\t\tnew_rate = DIV_ROUND_CLOSEST_ULL(divident, divisor);\n\n\t\tdelta = new_rate >= ch->rate ? new_rate - ch->rate : delta;\n\t\tif (delta < best_delta) {\n\t\t\tbest_delta = delta;\n\t\t\tbest_send_cnt = send_cnt;\n\t\t\tbest_idle_cnt = idle_cnt;\n\t\t\tbest_rate = new_rate;\n\n\t\t\tif (!delta)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (prev_delta >= delta) {\n\t\t\tprev_delta = delta;\n\t\t\tsend_cnt++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tidle_cnt++;\n\t\tdivident = freq * idle_cnt;\n\t\tsend_cnt = DIV_ROUND_CLOSEST_ULL(divident, ch->rate);\n\t\tsend_cnt -= idle_cnt;\n\t\tprev_delta = UINT_MAX;\n\t}\n\n\tch->rate = best_rate;\n\tch->rate_factor = best_send_cnt | (best_idle_cnt << 16);\n\nset_factor:\n\trate_reg = CPDMA_TX_PRI0_RATE + 4 * ch->chan_num;\n\tdma_reg_write(ctlr, rate_reg, ch->rate_factor);\n\treturn 0;\n}\n\nstruct cpdma_ctlr *cpdma_ctlr_create(struct cpdma_params *params)\n{\n\tstruct cpdma_ctlr *ctlr;\n\n\tctlr = devm_kzalloc(params->dev, sizeof(*ctlr), GFP_KERNEL);\n\tif (!ctlr)\n\t\treturn NULL;\n\n\tctlr->state = CPDMA_STATE_IDLE;\n\tctlr->params = *params;\n\tctlr->dev = params->dev;\n\tctlr->chan_num = 0;\n\tspin_lock_init(&ctlr->lock);\n\n\tif (cpdma_desc_pool_create(ctlr))\n\t\treturn NULL;\n\t \n\tctlr->num_tx_desc = ctlr->pool->num_desc / 2;\n\tctlr->num_rx_desc = ctlr->pool->num_desc - ctlr->num_tx_desc;\n\n\tif (WARN_ON(ctlr->num_chan > CPDMA_MAX_CHANNELS))\n\t\tctlr->num_chan = CPDMA_MAX_CHANNELS;\n\treturn ctlr;\n}\n\nint cpdma_ctlr_start(struct cpdma_ctlr *ctlr)\n{\n\tstruct cpdma_chan *chan;\n\tunsigned long flags;\n\tint i, prio_mode;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tif (ctlr->state != CPDMA_STATE_IDLE) {\n\t\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\t\treturn -EBUSY;\n\t}\n\n\tif (ctlr->params.has_soft_reset) {\n\t\tunsigned timeout = 10 * 100;\n\n\t\tdma_reg_write(ctlr, CPDMA_SOFTRESET, 1);\n\t\twhile (timeout) {\n\t\t\tif (dma_reg_read(ctlr, CPDMA_SOFTRESET) == 0)\n\t\t\t\tbreak;\n\t\t\tudelay(10);\n\t\t\ttimeout--;\n\t\t}\n\t\tWARN_ON(!timeout);\n\t}\n\n\tfor (i = 0; i < ctlr->num_chan; i++) {\n\t\twritel(0, ctlr->params.txhdp + 4 * i);\n\t\twritel(0, ctlr->params.rxhdp + 4 * i);\n\t\twritel(0, ctlr->params.txcp + 4 * i);\n\t\twritel(0, ctlr->params.rxcp + 4 * i);\n\t}\n\n\tdma_reg_write(ctlr, CPDMA_RXINTMASKCLEAR, 0xffffffff);\n\tdma_reg_write(ctlr, CPDMA_TXINTMASKCLEAR, 0xffffffff);\n\n\tdma_reg_write(ctlr, CPDMA_TXCONTROL, 1);\n\tdma_reg_write(ctlr, CPDMA_RXCONTROL, 1);\n\n\tctlr->state = CPDMA_STATE_ACTIVE;\n\n\tprio_mode = 0;\n\tfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\n\t\tchan = ctlr->channels[i];\n\t\tif (chan) {\n\t\t\tcpdma_chan_set_chan_shaper(chan);\n\t\t\tcpdma_chan_on(chan);\n\n\t\t\t \n\t\t\tif (is_tx_chan(chan) && !chan->rate)\n\t\t\t\tprio_mode = 1;\n\t\t}\n\t}\n\n\t_cpdma_control_set(ctlr, CPDMA_TX_PRIO_FIXED, prio_mode);\n\t_cpdma_control_set(ctlr, CPDMA_RX_BUFFER_OFFSET, 0);\n\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn 0;\n}\n\nint cpdma_ctlr_stop(struct cpdma_ctlr *ctlr)\n{\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tif (ctlr->state != CPDMA_STATE_ACTIVE) {\n\t\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tctlr->state = CPDMA_STATE_TEARDOWN;\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\n\tfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\n\t\tif (ctlr->channels[i])\n\t\t\tcpdma_chan_stop(ctlr->channels[i]);\n\t}\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tdma_reg_write(ctlr, CPDMA_RXINTMASKCLEAR, 0xffffffff);\n\tdma_reg_write(ctlr, CPDMA_TXINTMASKCLEAR, 0xffffffff);\n\n\tdma_reg_write(ctlr, CPDMA_TXCONTROL, 0);\n\tdma_reg_write(ctlr, CPDMA_RXCONTROL, 0);\n\n\tctlr->state = CPDMA_STATE_IDLE;\n\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn 0;\n}\n\nint cpdma_ctlr_destroy(struct cpdma_ctlr *ctlr)\n{\n\tint ret = 0, i;\n\n\tif (!ctlr)\n\t\treturn -EINVAL;\n\n\tif (ctlr->state != CPDMA_STATE_IDLE)\n\t\tcpdma_ctlr_stop(ctlr);\n\n\tfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++)\n\t\tcpdma_chan_destroy(ctlr->channels[i]);\n\n\tcpdma_desc_pool_destroy(ctlr);\n\treturn ret;\n}\n\nint cpdma_ctlr_int_ctrl(struct cpdma_ctlr *ctlr, bool enable)\n{\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tif (ctlr->state != CPDMA_STATE_ACTIVE) {\n\t\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\n\t\tif (ctlr->channels[i])\n\t\t\tcpdma_chan_int_ctrl(ctlr->channels[i], enable);\n\t}\n\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn 0;\n}\n\nvoid cpdma_ctlr_eoi(struct cpdma_ctlr *ctlr, u32 value)\n{\n\tdma_reg_write(ctlr, CPDMA_MACEOIVECTOR, value);\n}\n\nu32 cpdma_ctrl_rxchs_state(struct cpdma_ctlr *ctlr)\n{\n\treturn dma_reg_read(ctlr, CPDMA_RXINTSTATMASKED);\n}\n\nu32 cpdma_ctrl_txchs_state(struct cpdma_ctlr *ctlr)\n{\n\treturn dma_reg_read(ctlr, CPDMA_TXINTSTATMASKED);\n}\n\nstatic void cpdma_chan_set_descs(struct cpdma_ctlr *ctlr,\n\t\t\t\t int rx, int desc_num,\n\t\t\t\t int per_ch_desc)\n{\n\tstruct cpdma_chan *chan, *most_chan = NULL;\n\tint desc_cnt = desc_num;\n\tint most_dnum = 0;\n\tint min, max, i;\n\n\tif (!desc_num)\n\t\treturn;\n\n\tif (rx) {\n\t\tmin = rx_chan_num(0);\n\t\tmax = rx_chan_num(CPDMA_MAX_CHANNELS);\n\t} else {\n\t\tmin = tx_chan_num(0);\n\t\tmax = tx_chan_num(CPDMA_MAX_CHANNELS);\n\t}\n\n\tfor (i = min; i < max; i++) {\n\t\tchan = ctlr->channels[i];\n\t\tif (!chan)\n\t\t\tcontinue;\n\n\t\tif (chan->weight)\n\t\t\tchan->desc_num = (chan->weight * desc_num) / 100;\n\t\telse\n\t\t\tchan->desc_num = per_ch_desc;\n\n\t\tdesc_cnt -= chan->desc_num;\n\n\t\tif (most_dnum < chan->desc_num) {\n\t\t\tmost_dnum = chan->desc_num;\n\t\t\tmost_chan = chan;\n\t\t}\n\t}\n\t \n\tif (most_chan)\n\t\tmost_chan->desc_num += desc_cnt;\n}\n\n \nstatic int cpdma_chan_split_pool(struct cpdma_ctlr *ctlr)\n{\n\tint tx_per_ch_desc = 0, rx_per_ch_desc = 0;\n\tint free_rx_num = 0, free_tx_num = 0;\n\tint rx_weight = 0, tx_weight = 0;\n\tint tx_desc_num, rx_desc_num;\n\tstruct cpdma_chan *chan;\n\tint i;\n\n\tif (!ctlr->chan_num)\n\t\treturn 0;\n\n\tfor (i = 0; i < ARRAY_SIZE(ctlr->channels); i++) {\n\t\tchan = ctlr->channels[i];\n\t\tif (!chan)\n\t\t\tcontinue;\n\n\t\tif (is_rx_chan(chan)) {\n\t\t\tif (!chan->weight)\n\t\t\t\tfree_rx_num++;\n\t\t\trx_weight += chan->weight;\n\t\t} else {\n\t\t\tif (!chan->weight)\n\t\t\t\tfree_tx_num++;\n\t\t\ttx_weight += chan->weight;\n\t\t}\n\t}\n\n\tif (rx_weight > 100 || tx_weight > 100)\n\t\treturn -EINVAL;\n\n\ttx_desc_num = ctlr->num_tx_desc;\n\trx_desc_num = ctlr->num_rx_desc;\n\n\tif (free_tx_num) {\n\t\ttx_per_ch_desc = tx_desc_num - (tx_weight * tx_desc_num) / 100;\n\t\ttx_per_ch_desc /= free_tx_num;\n\t}\n\tif (free_rx_num) {\n\t\trx_per_ch_desc = rx_desc_num - (rx_weight * rx_desc_num) / 100;\n\t\trx_per_ch_desc /= free_rx_num;\n\t}\n\n\tcpdma_chan_set_descs(ctlr, 0, tx_desc_num, tx_per_ch_desc);\n\tcpdma_chan_set_descs(ctlr, 1, rx_desc_num, rx_per_ch_desc);\n\n\treturn 0;\n}\n\n\n \nint cpdma_chan_set_weight(struct cpdma_chan *ch, int weight)\n{\n\tstruct cpdma_ctlr *ctlr = ch->ctlr;\n\tunsigned long flags, ch_flags;\n\tint ret;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tspin_lock_irqsave(&ch->lock, ch_flags);\n\tif (ch->weight == weight) {\n\t\tspin_unlock_irqrestore(&ch->lock, ch_flags);\n\t\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\t\treturn 0;\n\t}\n\tch->weight = weight;\n\tspin_unlock_irqrestore(&ch->lock, ch_flags);\n\n\t \n\tret = cpdma_chan_split_pool(ctlr);\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn ret;\n}\n\n \nu32 cpdma_chan_get_min_rate(struct cpdma_ctlr *ctlr)\n{\n\tunsigned int divident, divisor;\n\n\tdivident = ctlr->params.bus_freq_mhz * 32 * 1000;\n\tdivisor = 1 + CPDMA_MAX_RLIM_CNT;\n\n\treturn DIV_ROUND_UP(divident, divisor);\n}\n\n \nint cpdma_chan_set_rate(struct cpdma_chan *ch, u32 rate)\n{\n\tunsigned long flags, ch_flags;\n\tstruct cpdma_ctlr *ctlr;\n\tint ret, prio_mode;\n\tu32 rmask;\n\n\tif (!ch || !is_tx_chan(ch))\n\t\treturn -EINVAL;\n\n\tif (ch->rate == rate)\n\t\treturn rate;\n\n\tctlr = ch->ctlr;\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tspin_lock_irqsave(&ch->lock, ch_flags);\n\n\tret = cpdma_chan_fit_rate(ch, rate, &rmask, &prio_mode);\n\tif (ret)\n\t\tgoto err;\n\n\tret = cpdma_chan_set_factors(ctlr, ch);\n\tif (ret)\n\t\tgoto err;\n\n\tspin_unlock_irqrestore(&ch->lock, ch_flags);\n\n\t \n\t_cpdma_control_set(ctlr, CPDMA_TX_RLIM, rmask);\n\t_cpdma_control_set(ctlr, CPDMA_TX_PRIO_FIXED, prio_mode);\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn ret;\n\nerr:\n\tspin_unlock_irqrestore(&ch->lock, ch_flags);\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn ret;\n}\n\nu32 cpdma_chan_get_rate(struct cpdma_chan *ch)\n{\n\tunsigned long flags;\n\tu32 rate;\n\n\tspin_lock_irqsave(&ch->lock, flags);\n\trate = ch->rate;\n\tspin_unlock_irqrestore(&ch->lock, flags);\n\n\treturn rate;\n}\n\nstruct cpdma_chan *cpdma_chan_create(struct cpdma_ctlr *ctlr, int chan_num,\n\t\t\t\t     cpdma_handler_fn handler, int rx_type)\n{\n\tint offset = chan_num * 4;\n\tstruct cpdma_chan *chan;\n\tunsigned long flags;\n\n\tchan_num = rx_type ? rx_chan_num(chan_num) : tx_chan_num(chan_num);\n\n\tif (__chan_linear(chan_num) >= ctlr->num_chan)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tchan = devm_kzalloc(ctlr->dev, sizeof(*chan), GFP_KERNEL);\n\tif (!chan)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tif (ctlr->channels[chan_num]) {\n\t\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\t\tdevm_kfree(ctlr->dev, chan);\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\n\tchan->ctlr\t= ctlr;\n\tchan->state\t= CPDMA_STATE_IDLE;\n\tchan->chan_num\t= chan_num;\n\tchan->handler\t= handler;\n\tchan->rate\t= 0;\n\tchan->weight\t= 0;\n\n\tif (is_rx_chan(chan)) {\n\t\tchan->hdp\t= ctlr->params.rxhdp + offset;\n\t\tchan->cp\t= ctlr->params.rxcp + offset;\n\t\tchan->rxfree\t= ctlr->params.rxfree + offset;\n\t\tchan->int_set\t= CPDMA_RXINTMASKSET;\n\t\tchan->int_clear\t= CPDMA_RXINTMASKCLEAR;\n\t\tchan->td\t= CPDMA_RXTEARDOWN;\n\t\tchan->dir\t= DMA_FROM_DEVICE;\n\t} else {\n\t\tchan->hdp\t= ctlr->params.txhdp + offset;\n\t\tchan->cp\t= ctlr->params.txcp + offset;\n\t\tchan->int_set\t= CPDMA_TXINTMASKSET;\n\t\tchan->int_clear\t= CPDMA_TXINTMASKCLEAR;\n\t\tchan->td\t= CPDMA_TXTEARDOWN;\n\t\tchan->dir\t= DMA_TO_DEVICE;\n\t}\n\tchan->mask = BIT(chan_linear(chan));\n\n\tspin_lock_init(&chan->lock);\n\n\tctlr->channels[chan_num] = chan;\n\tctlr->chan_num++;\n\n\tcpdma_chan_split_pool(ctlr);\n\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn chan;\n}\n\nint cpdma_chan_get_rx_buf_num(struct cpdma_chan *chan)\n{\n\tunsigned long flags;\n\tint desc_num;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tdesc_num = chan->desc_num;\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\n\treturn desc_num;\n}\n\nint cpdma_chan_destroy(struct cpdma_chan *chan)\n{\n\tstruct cpdma_ctlr *ctlr;\n\tunsigned long flags;\n\n\tif (!chan)\n\t\treturn -EINVAL;\n\tctlr = chan->ctlr;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tif (chan->state != CPDMA_STATE_IDLE)\n\t\tcpdma_chan_stop(chan);\n\tctlr->channels[chan->chan_num] = NULL;\n\tctlr->chan_num--;\n\tdevm_kfree(ctlr->dev, chan);\n\tcpdma_chan_split_pool(ctlr);\n\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\treturn 0;\n}\n\nint cpdma_chan_get_stats(struct cpdma_chan *chan,\n\t\t\t struct cpdma_chan_stats *stats)\n{\n\tunsigned long flags;\n\tif (!chan)\n\t\treturn -EINVAL;\n\tspin_lock_irqsave(&chan->lock, flags);\n\tmemcpy(stats, &chan->stats, sizeof(*stats));\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn 0;\n}\n\nstatic void __cpdma_chan_submit(struct cpdma_chan *chan,\n\t\t\t\tstruct cpdma_desc __iomem *desc)\n{\n\tstruct cpdma_ctlr\t\t*ctlr = chan->ctlr;\n\tstruct cpdma_desc __iomem\t*prev = chan->tail;\n\tstruct cpdma_desc_pool\t\t*pool = ctlr->pool;\n\tdma_addr_t\t\t\tdesc_dma;\n\tu32\t\t\t\tmode;\n\n\tdesc_dma = desc_phys(pool, desc);\n\n\t \n\tif (!chan->head) {\n\t\tchan->stats.head_enqueue++;\n\t\tchan->head = desc;\n\t\tchan->tail = desc;\n\t\tif (chan->state == CPDMA_STATE_ACTIVE)\n\t\t\tchan_write(chan, hdp, desc_dma);\n\t\treturn;\n\t}\n\n\t \n\tdesc_write(prev, hw_next, desc_dma);\n\tchan->tail = desc;\n\tchan->stats.tail_enqueue++;\n\n\t \n\tmode = desc_read(prev, hw_mode);\n\tif (((mode & (CPDMA_DESC_EOQ | CPDMA_DESC_OWNER)) == CPDMA_DESC_EOQ) &&\n\t    (chan->state == CPDMA_STATE_ACTIVE)) {\n\t\tdesc_write(prev, hw_mode, mode & ~CPDMA_DESC_EOQ);\n\t\tchan_write(chan, hdp, desc_dma);\n\t\tchan->stats.misqueued++;\n\t}\n}\n\nstatic int cpdma_chan_submit_si(struct submit_info *si)\n{\n\tstruct cpdma_chan\t\t*chan = si->chan;\n\tstruct cpdma_ctlr\t\t*ctlr = chan->ctlr;\n\tint\t\t\t\tlen = si->len;\n\tstruct cpdma_desc __iomem\t*desc;\n\tdma_addr_t\t\t\tbuffer;\n\tu32\t\t\t\tmode;\n\tint\t\t\t\tret;\n\n\tif (chan->count >= chan->desc_num)\t{\n\t\tchan->stats.desc_alloc_fail++;\n\t\treturn -ENOMEM;\n\t}\n\n\tdesc = cpdma_desc_alloc(ctlr->pool);\n\tif (!desc) {\n\t\tchan->stats.desc_alloc_fail++;\n\t\treturn -ENOMEM;\n\t}\n\n\tif (len < ctlr->params.min_packet_size) {\n\t\tlen = ctlr->params.min_packet_size;\n\t\tchan->stats.runt_transmit_buff++;\n\t}\n\n\tmode = CPDMA_DESC_OWNER | CPDMA_DESC_SOP | CPDMA_DESC_EOP;\n\tcpdma_desc_to_port(chan, mode, si->directed);\n\n\tif (si->data_dma) {\n\t\tbuffer = si->data_dma;\n\t\tdma_sync_single_for_device(ctlr->dev, buffer, len, chan->dir);\n\t} else {\n\t\tbuffer = dma_map_single(ctlr->dev, si->data_virt, len, chan->dir);\n\t\tret = dma_mapping_error(ctlr->dev, buffer);\n\t\tif (ret) {\n\t\t\tcpdma_desc_free(ctlr->pool, desc, 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t \n\twritel_relaxed(0, &desc->hw_next);\n\twritel_relaxed(buffer, &desc->hw_buffer);\n\twritel_relaxed(len, &desc->hw_len);\n\twritel_relaxed(mode | len, &desc->hw_mode);\n\twritel_relaxed((uintptr_t)si->token, &desc->sw_token);\n\twritel_relaxed(buffer, &desc->sw_buffer);\n\twritel_relaxed(si->data_dma ? len | CPDMA_DMA_EXT_MAP : len,\n\t\t       &desc->sw_len);\n\tdesc_read(desc, sw_len);\n\n\t__cpdma_chan_submit(chan, desc);\n\n\tif (chan->state == CPDMA_STATE_ACTIVE && chan->rxfree)\n\t\tchan_write(chan, rxfree, 1);\n\n\tchan->count++;\n\treturn 0;\n}\n\nint cpdma_chan_idle_submit(struct cpdma_chan *chan, void *token, void *data,\n\t\t\t   int len, int directed)\n{\n\tstruct submit_info si;\n\tunsigned long flags;\n\tint ret;\n\n\tsi.chan = chan;\n\tsi.token = token;\n\tsi.data_virt = data;\n\tsi.data_dma = 0;\n\tsi.len = len;\n\tsi.directed = directed;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->state == CPDMA_STATE_TEARDOWN) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tret = cpdma_chan_submit_si(&si);\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn ret;\n}\n\nint cpdma_chan_idle_submit_mapped(struct cpdma_chan *chan, void *token,\n\t\t\t\t  dma_addr_t data, int len, int directed)\n{\n\tstruct submit_info si;\n\tunsigned long flags;\n\tint ret;\n\n\tsi.chan = chan;\n\tsi.token = token;\n\tsi.data_virt = NULL;\n\tsi.data_dma = data;\n\tsi.len = len;\n\tsi.directed = directed;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->state == CPDMA_STATE_TEARDOWN) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tret = cpdma_chan_submit_si(&si);\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn ret;\n}\n\nint cpdma_chan_submit(struct cpdma_chan *chan, void *token, void *data,\n\t\t      int len, int directed)\n{\n\tstruct submit_info si;\n\tunsigned long flags;\n\tint ret;\n\n\tsi.chan = chan;\n\tsi.token = token;\n\tsi.data_virt = data;\n\tsi.data_dma = 0;\n\tsi.len = len;\n\tsi.directed = directed;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->state != CPDMA_STATE_ACTIVE) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tret = cpdma_chan_submit_si(&si);\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn ret;\n}\n\nint cpdma_chan_submit_mapped(struct cpdma_chan *chan, void *token,\n\t\t\t     dma_addr_t data, int len, int directed)\n{\n\tstruct submit_info si;\n\tunsigned long flags;\n\tint ret;\n\n\tsi.chan = chan;\n\tsi.token = token;\n\tsi.data_virt = NULL;\n\tsi.data_dma = data;\n\tsi.len = len;\n\tsi.directed = directed;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->state != CPDMA_STATE_ACTIVE) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tret = cpdma_chan_submit_si(&si);\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn ret;\n}\n\nbool cpdma_check_free_tx_desc(struct cpdma_chan *chan)\n{\n\tstruct cpdma_ctlr\t*ctlr = chan->ctlr;\n\tstruct cpdma_desc_pool\t*pool = ctlr->pool;\n\tbool\t\t\tfree_tx_desc;\n\tunsigned long\t\tflags;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tfree_tx_desc = (chan->count < chan->desc_num) &&\n\t\t\t gen_pool_avail(pool->gen_pool);\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn free_tx_desc;\n}\n\nstatic void __cpdma_chan_free(struct cpdma_chan *chan,\n\t\t\t      struct cpdma_desc __iomem *desc,\n\t\t\t      int outlen, int status)\n{\n\tstruct cpdma_ctlr\t\t*ctlr = chan->ctlr;\n\tstruct cpdma_desc_pool\t\t*pool = ctlr->pool;\n\tdma_addr_t\t\t\tbuff_dma;\n\tint\t\t\t\toriglen;\n\tuintptr_t\t\t\ttoken;\n\n\ttoken      = desc_read(desc, sw_token);\n\toriglen    = desc_read(desc, sw_len);\n\n\tbuff_dma   = desc_read(desc, sw_buffer);\n\tif (origlen & CPDMA_DMA_EXT_MAP) {\n\t\toriglen &= ~CPDMA_DMA_EXT_MAP;\n\t\tdma_sync_single_for_cpu(ctlr->dev, buff_dma, origlen,\n\t\t\t\t\tchan->dir);\n\t} else {\n\t\tdma_unmap_single(ctlr->dev, buff_dma, origlen, chan->dir);\n\t}\n\n\tcpdma_desc_free(pool, desc, 1);\n\t(*chan->handler)((void *)token, outlen, status);\n}\n\nstatic int __cpdma_chan_process(struct cpdma_chan *chan)\n{\n\tstruct cpdma_ctlr\t\t*ctlr = chan->ctlr;\n\tstruct cpdma_desc __iomem\t*desc;\n\tint\t\t\t\tstatus, outlen;\n\tint\t\t\t\tcb_status = 0;\n\tstruct cpdma_desc_pool\t\t*pool = ctlr->pool;\n\tdma_addr_t\t\t\tdesc_dma;\n\tunsigned long\t\t\tflags;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\n\tdesc = chan->head;\n\tif (!desc) {\n\t\tchan->stats.empty_dequeue++;\n\t\tstatus = -ENOENT;\n\t\tgoto unlock_ret;\n\t}\n\tdesc_dma = desc_phys(pool, desc);\n\n\tstatus\t= desc_read(desc, hw_mode);\n\toutlen\t= status & 0x7ff;\n\tif (status & CPDMA_DESC_OWNER) {\n\t\tchan->stats.busy_dequeue++;\n\t\tstatus = -EBUSY;\n\t\tgoto unlock_ret;\n\t}\n\n\tif (status & CPDMA_DESC_PASS_CRC)\n\t\toutlen -= CPDMA_DESC_CRC_LEN;\n\n\tstatus\t= status & (CPDMA_DESC_EOQ | CPDMA_DESC_TD_COMPLETE |\n\t\t\t    CPDMA_DESC_PORT_MASK | CPDMA_RX_VLAN_ENCAP);\n\n\tchan->head = desc_from_phys(pool, desc_read(desc, hw_next));\n\tchan_write(chan, cp, desc_dma);\n\tchan->count--;\n\tchan->stats.good_dequeue++;\n\n\tif ((status & CPDMA_DESC_EOQ) && chan->head) {\n\t\tchan->stats.requeue++;\n\t\tchan_write(chan, hdp, desc_phys(pool, chan->head));\n\t}\n\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\tif (unlikely(status & CPDMA_DESC_TD_COMPLETE))\n\t\tcb_status = -ENOSYS;\n\telse\n\t\tcb_status = status;\n\n\t__cpdma_chan_free(chan, desc, outlen, cb_status);\n\treturn status;\n\nunlock_ret:\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn status;\n}\n\nint cpdma_chan_process(struct cpdma_chan *chan, int quota)\n{\n\tint used = 0, ret = 0;\n\n\tif (chan->state != CPDMA_STATE_ACTIVE)\n\t\treturn -EINVAL;\n\n\twhile (used < quota) {\n\t\tret = __cpdma_chan_process(chan);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t\tused++;\n\t}\n\treturn used;\n}\n\nint cpdma_chan_start(struct cpdma_chan *chan)\n{\n\tstruct cpdma_ctlr *ctlr = chan->ctlr;\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tret = cpdma_chan_set_chan_shaper(chan);\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\tif (ret)\n\t\treturn ret;\n\n\tret = cpdma_chan_on(chan);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nint cpdma_chan_stop(struct cpdma_chan *chan)\n{\n\tstruct cpdma_ctlr\t*ctlr = chan->ctlr;\n\tstruct cpdma_desc_pool\t*pool = ctlr->pool;\n\tunsigned long\t\tflags;\n\tint\t\t\tret;\n\tunsigned\t\ttimeout;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->state == CPDMA_STATE_TEARDOWN) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tchan->state = CPDMA_STATE_TEARDOWN;\n\tdma_reg_write(ctlr, chan->int_clear, chan->mask);\n\n\t \n\tdma_reg_write(ctlr, chan->td, chan_linear(chan));\n\n\t \n\ttimeout = 100 * 100;  \n\twhile (timeout) {\n\t\tu32 cp = chan_read(chan, cp);\n\t\tif ((cp & CPDMA_TEARDOWN_VALUE) == CPDMA_TEARDOWN_VALUE)\n\t\t\tbreak;\n\t\tudelay(10);\n\t\ttimeout--;\n\t}\n\tWARN_ON(!timeout);\n\tchan_write(chan, cp, CPDMA_TEARDOWN_VALUE);\n\n\t \n\tspin_unlock_irqrestore(&chan->lock, flags);\n\tdo {\n\t\tret = __cpdma_chan_process(chan);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t} while ((ret & CPDMA_DESC_TD_COMPLETE) == 0);\n\tspin_lock_irqsave(&chan->lock, flags);\n\n\t \n\twhile (chan->head) {\n\t\tstruct cpdma_desc __iomem *desc = chan->head;\n\t\tdma_addr_t next_dma;\n\n\t\tnext_dma = desc_read(desc, hw_next);\n\t\tchan->head = desc_from_phys(pool, next_dma);\n\t\tchan->count--;\n\t\tchan->stats.teardown_dequeue++;\n\n\t\t \n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\t__cpdma_chan_free(chan, desc, 0, -ENOSYS);\n\t\tspin_lock_irqsave(&chan->lock, flags);\n\t}\n\n\tchan->state = CPDMA_STATE_IDLE;\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\treturn 0;\n}\n\nint cpdma_chan_int_ctrl(struct cpdma_chan *chan, bool enable)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (chan->state != CPDMA_STATE_ACTIVE) {\n\t\tspin_unlock_irqrestore(&chan->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\tdma_reg_write(chan->ctlr, enable ? chan->int_set : chan->int_clear,\n\t\t      chan->mask);\n\tspin_unlock_irqrestore(&chan->lock, flags);\n\n\treturn 0;\n}\n\nint cpdma_control_get(struct cpdma_ctlr *ctlr, int control)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tret = _cpdma_control_get(ctlr, control);\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\n\treturn ret;\n}\n\nint cpdma_control_set(struct cpdma_ctlr *ctlr, int control, int value)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\tret = _cpdma_control_set(ctlr, control, value);\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\n\treturn ret;\n}\n\nint cpdma_get_num_rx_descs(struct cpdma_ctlr *ctlr)\n{\n\treturn ctlr->num_rx_desc;\n}\n\nint cpdma_get_num_tx_descs(struct cpdma_ctlr *ctlr)\n{\n\treturn ctlr->num_tx_desc;\n}\n\nint cpdma_set_num_rx_descs(struct cpdma_ctlr *ctlr, int num_rx_desc)\n{\n\tunsigned long flags;\n\tint temp, ret;\n\n\tspin_lock_irqsave(&ctlr->lock, flags);\n\n\ttemp = ctlr->num_rx_desc;\n\tctlr->num_rx_desc = num_rx_desc;\n\tctlr->num_tx_desc = ctlr->pool->num_desc - ctlr->num_rx_desc;\n\tret = cpdma_chan_split_pool(ctlr);\n\tif (ret) {\n\t\tctlr->num_rx_desc = temp;\n\t\tctlr->num_tx_desc = ctlr->pool->num_desc - ctlr->num_rx_desc;\n\t}\n\n\tspin_unlock_irqrestore(&ctlr->lock, flags);\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}