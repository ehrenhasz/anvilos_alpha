{
  "module_name": "ionic_lif.c",
  "hash_id": "4459918c0baf82a20b70bed53014669d5dc7e41331e25746e9ab336293c79832",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/pensando/ionic/ionic_lif.c",
  "human_readable_source": "\n \n\n#include <linux/ethtool.h>\n#include <linux/printk.h>\n#include <linux/dynamic_debug.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/if_vlan.h>\n#include <linux/rtnetlink.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/cpumask.h>\n#include <linux/crash_dump.h>\n#include <linux/vmalloc.h>\n\n#include \"ionic.h\"\n#include \"ionic_bus.h\"\n#include \"ionic_dev.h\"\n#include \"ionic_lif.h\"\n#include \"ionic_txrx.h\"\n#include \"ionic_ethtool.h\"\n#include \"ionic_debugfs.h\"\n\n \nstatic const u8 ionic_qtype_versions[IONIC_QTYPE_MAX] = {\n\t[IONIC_QTYPE_ADMINQ]  = 0,    \n\t[IONIC_QTYPE_NOTIFYQ] = 0,    \n\t[IONIC_QTYPE_RXQ]     = 2,    \n\t[IONIC_QTYPE_TXQ]     = 3,    \n};\n\nstatic void ionic_link_status_check(struct ionic_lif *lif);\nstatic void ionic_lif_handle_fw_down(struct ionic_lif *lif);\nstatic void ionic_lif_handle_fw_up(struct ionic_lif *lif);\nstatic void ionic_lif_set_netdev_info(struct ionic_lif *lif);\n\nstatic void ionic_txrx_deinit(struct ionic_lif *lif);\nstatic int ionic_txrx_init(struct ionic_lif *lif);\nstatic int ionic_start_queues(struct ionic_lif *lif);\nstatic void ionic_stop_queues(struct ionic_lif *lif);\nstatic void ionic_lif_queue_identify(struct ionic_lif *lif);\n\nstatic void ionic_dim_work(struct work_struct *work)\n{\n\tstruct dim *dim = container_of(work, struct dim, work);\n\tstruct ionic_intr_info *intr;\n\tstruct dim_cq_moder cur_moder;\n\tstruct ionic_qcq *qcq;\n\tstruct ionic_lif *lif;\n\tu32 new_coal;\n\n\tcur_moder = net_dim_get_rx_moderation(dim->mode, dim->profile_ix);\n\tqcq = container_of(dim, struct ionic_qcq, dim);\n\tlif = qcq->q.lif;\n\tnew_coal = ionic_coal_usec_to_hw(lif->ionic, cur_moder.usec);\n\tnew_coal = new_coal ? new_coal : 1;\n\n\tintr = &qcq->intr;\n\tif (intr->dim_coal_hw != new_coal) {\n\t\tintr->dim_coal_hw = new_coal;\n\n\t\tionic_intr_coal_init(lif->ionic->idev.intr_ctrl,\n\t\t\t\t     intr->index, intr->dim_coal_hw);\n\t}\n\n\tdim->state = DIM_START_MEASURE;\n}\n\nstatic void ionic_lif_deferred_work(struct work_struct *work)\n{\n\tstruct ionic_lif *lif = container_of(work, struct ionic_lif, deferred.work);\n\tstruct ionic_deferred *def = &lif->deferred;\n\tstruct ionic_deferred_work *w = NULL;\n\n\tdo {\n\t\tspin_lock_bh(&def->lock);\n\t\tif (!list_empty(&def->list)) {\n\t\t\tw = list_first_entry(&def->list,\n\t\t\t\t\t     struct ionic_deferred_work, list);\n\t\t\tlist_del(&w->list);\n\t\t}\n\t\tspin_unlock_bh(&def->lock);\n\n\t\tif (!w)\n\t\t\tbreak;\n\n\t\tswitch (w->type) {\n\t\tcase IONIC_DW_TYPE_RX_MODE:\n\t\t\tionic_lif_rx_mode(lif);\n\t\t\tbreak;\n\t\tcase IONIC_DW_TYPE_LINK_STATUS:\n\t\t\tionic_link_status_check(lif);\n\t\t\tbreak;\n\t\tcase IONIC_DW_TYPE_LIF_RESET:\n\t\t\tif (w->fw_status) {\n\t\t\t\tionic_lif_handle_fw_up(lif);\n\t\t\t} else {\n\t\t\t\tionic_lif_handle_fw_down(lif);\n\n\t\t\t\t \n\t\t\t\tmod_timer(&lif->ionic->watchdog_timer, jiffies + 1);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tkfree(w);\n\t\tw = NULL;\n\t} while (true);\n}\n\nvoid ionic_lif_deferred_enqueue(struct ionic_deferred *def,\n\t\t\t\tstruct ionic_deferred_work *work)\n{\n\tspin_lock_bh(&def->lock);\n\tlist_add_tail(&work->list, &def->list);\n\tspin_unlock_bh(&def->lock);\n\tschedule_work(&def->work);\n}\n\nstatic void ionic_link_status_check(struct ionic_lif *lif)\n{\n\tstruct net_device *netdev = lif->netdev;\n\tu16 link_status;\n\tbool link_up;\n\n\tif (!test_bit(IONIC_LIF_F_LINK_CHECK_REQUESTED, lif->state))\n\t\treturn;\n\n\t \n\tif (test_bit(IONIC_LIF_F_BROKEN, lif->state)) {\n\t\tclear_bit(IONIC_LIF_F_LINK_CHECK_REQUESTED, lif->state);\n\t\treturn;\n\t}\n\n\tlink_status = le16_to_cpu(lif->info->status.link_status);\n\tlink_up = link_status == IONIC_PORT_OPER_STATUS_UP;\n\n\tif (link_up) {\n\t\tint err = 0;\n\n\t\tif (netdev->flags & IFF_UP && netif_running(netdev)) {\n\t\t\tmutex_lock(&lif->queue_lock);\n\t\t\terr = ionic_start_queues(lif);\n\t\t\tif (err && err != -EBUSY) {\n\t\t\t\tnetdev_err(netdev,\n\t\t\t\t\t   \"Failed to start queues: %d\\n\", err);\n\t\t\t\tset_bit(IONIC_LIF_F_BROKEN, lif->state);\n\t\t\t\tnetif_carrier_off(lif->netdev);\n\t\t\t}\n\t\t\tmutex_unlock(&lif->queue_lock);\n\t\t}\n\n\t\tif (!err && !netif_carrier_ok(netdev)) {\n\t\t\tionic_port_identify(lif->ionic);\n\t\t\tnetdev_info(netdev, \"Link up - %d Gbps\\n\",\n\t\t\t\t    le32_to_cpu(lif->info->status.link_speed) / 1000);\n\t\t\tnetif_carrier_on(netdev);\n\t\t}\n\t} else {\n\t\tif (netif_carrier_ok(netdev)) {\n\t\t\tlif->link_down_count++;\n\t\t\tnetdev_info(netdev, \"Link down\\n\");\n\t\t\tnetif_carrier_off(netdev);\n\t\t}\n\n\t\tif (netdev->flags & IFF_UP && netif_running(netdev)) {\n\t\t\tmutex_lock(&lif->queue_lock);\n\t\t\tionic_stop_queues(lif);\n\t\t\tmutex_unlock(&lif->queue_lock);\n\t\t}\n\t}\n\n\tclear_bit(IONIC_LIF_F_LINK_CHECK_REQUESTED, lif->state);\n}\n\nvoid ionic_link_status_check_request(struct ionic_lif *lif, bool can_sleep)\n{\n\tstruct ionic_deferred_work *work;\n\n\t \n\tif (test_and_set_bit(IONIC_LIF_F_LINK_CHECK_REQUESTED, lif->state))\n\t\treturn;\n\n\tif (!can_sleep) {\n\t\twork = kzalloc(sizeof(*work), GFP_ATOMIC);\n\t\tif (!work) {\n\t\t\tclear_bit(IONIC_LIF_F_LINK_CHECK_REQUESTED, lif->state);\n\t\t\treturn;\n\t\t}\n\n\t\twork->type = IONIC_DW_TYPE_LINK_STATUS;\n\t\tionic_lif_deferred_enqueue(&lif->deferred, work);\n\t} else {\n\t\tionic_link_status_check(lif);\n\t}\n}\n\nstatic void ionic_napi_deadline(struct timer_list *timer)\n{\n\tstruct ionic_qcq *qcq = container_of(timer, struct ionic_qcq, napi_deadline);\n\n\tnapi_schedule(&qcq->napi);\n}\n\nstatic irqreturn_t ionic_isr(int irq, void *data)\n{\n\tstruct napi_struct *napi = data;\n\n\tnapi_schedule_irqoff(napi);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int ionic_request_irq(struct ionic_lif *lif, struct ionic_qcq *qcq)\n{\n\tstruct ionic_intr_info *intr = &qcq->intr;\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_queue *q = &qcq->q;\n\tconst char *name;\n\n\tif (lif->registered)\n\t\tname = lif->netdev->name;\n\telse\n\t\tname = dev_name(dev);\n\n\tsnprintf(intr->name, sizeof(intr->name),\n\t\t \"%s-%s-%s\", IONIC_DRV_NAME, name, q->name);\n\n\treturn devm_request_irq(dev, intr->vector, ionic_isr,\n\t\t\t\t0, intr->name, &qcq->napi);\n}\n\nstatic int ionic_intr_alloc(struct ionic_lif *lif, struct ionic_intr_info *intr)\n{\n\tstruct ionic *ionic = lif->ionic;\n\tint index;\n\n\tindex = find_first_zero_bit(ionic->intrs, ionic->nintrs);\n\tif (index == ionic->nintrs) {\n\t\tnetdev_warn(lif->netdev, \"%s: no intr, index=%d nintrs=%d\\n\",\n\t\t\t    __func__, index, ionic->nintrs);\n\t\treturn -ENOSPC;\n\t}\n\n\tset_bit(index, ionic->intrs);\n\tionic_intr_init(&ionic->idev, intr, index);\n\n\treturn 0;\n}\n\nstatic void ionic_intr_free(struct ionic *ionic, int index)\n{\n\tif (index != IONIC_INTR_INDEX_NOT_ASSIGNED && index < ionic->nintrs)\n\t\tclear_bit(index, ionic->intrs);\n}\n\nstatic int ionic_qcq_enable(struct ionic_qcq *qcq)\n{\n\tstruct ionic_queue *q = &qcq->q;\n\tstruct ionic_lif *lif = q->lif;\n\tstruct ionic_dev *idev;\n\tstruct device *dev;\n\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.q_control = {\n\t\t\t.opcode = IONIC_CMD_Q_CONTROL,\n\t\t\t.lif_index = cpu_to_le16(lif->index),\n\t\t\t.type = q->type,\n\t\t\t.index = cpu_to_le32(q->index),\n\t\t\t.oper = IONIC_Q_ENABLE,\n\t\t},\n\t};\n\tint ret;\n\n\tidev = &lif->ionic->idev;\n\tdev = lif->ionic->dev;\n\n\tdev_dbg(dev, \"q_enable.index %d q_enable.qtype %d\\n\",\n\t\tctx.cmd.q_control.index, ctx.cmd.q_control.type);\n\n\tif (qcq->flags & IONIC_QCQ_F_INTR)\n\t\tionic_intr_clean(idev->intr_ctrl, qcq->intr.index);\n\n\tret = ionic_adminq_post_wait(lif, &ctx);\n\tif (ret)\n\t\treturn ret;\n\n\tif (qcq->napi.poll)\n\t\tnapi_enable(&qcq->napi);\n\n\tif (qcq->flags & IONIC_QCQ_F_INTR) {\n\t\tirq_set_affinity_hint(qcq->intr.vector,\n\t\t\t\t      &qcq->intr.affinity_mask);\n\t\tionic_intr_mask(idev->intr_ctrl, qcq->intr.index,\n\t\t\t\tIONIC_INTR_MASK_CLEAR);\n\t}\n\n\treturn 0;\n}\n\nstatic int ionic_qcq_disable(struct ionic_lif *lif, struct ionic_qcq *qcq, int fw_err)\n{\n\tstruct ionic_queue *q;\n\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.q_control = {\n\t\t\t.opcode = IONIC_CMD_Q_CONTROL,\n\t\t\t.oper = IONIC_Q_DISABLE,\n\t\t},\n\t};\n\n\tif (!qcq) {\n\t\tnetdev_err(lif->netdev, \"%s: bad qcq\\n\", __func__);\n\t\treturn -ENXIO;\n\t}\n\n\tq = &qcq->q;\n\n\tif (qcq->flags & IONIC_QCQ_F_INTR) {\n\t\tstruct ionic_dev *idev = &lif->ionic->idev;\n\n\t\tcancel_work_sync(&qcq->dim.work);\n\t\tionic_intr_mask(idev->intr_ctrl, qcq->intr.index,\n\t\t\t\tIONIC_INTR_MASK_SET);\n\t\tsynchronize_irq(qcq->intr.vector);\n\t\tirq_set_affinity_hint(qcq->intr.vector, NULL);\n\t\tnapi_disable(&qcq->napi);\n\t\tdel_timer_sync(&qcq->napi_deadline);\n\t}\n\n\t \n\tif (fw_err == -ETIMEDOUT || fw_err == -ENXIO)\n\t\treturn fw_err;\n\n\tctx.cmd.q_control.lif_index = cpu_to_le16(lif->index);\n\tctx.cmd.q_control.type = q->type;\n\tctx.cmd.q_control.index = cpu_to_le32(q->index);\n\tdev_dbg(lif->ionic->dev, \"q_disable.index %d q_disable.qtype %d\\n\",\n\t\tctx.cmd.q_control.index, ctx.cmd.q_control.type);\n\n\treturn ionic_adminq_post_wait(lif, &ctx);\n}\n\nstatic void ionic_lif_qcq_deinit(struct ionic_lif *lif, struct ionic_qcq *qcq)\n{\n\tstruct ionic_dev *idev = &lif->ionic->idev;\n\n\tif (!qcq)\n\t\treturn;\n\n\tif (!(qcq->flags & IONIC_QCQ_F_INITED))\n\t\treturn;\n\n\tif (qcq->flags & IONIC_QCQ_F_INTR) {\n\t\tionic_intr_mask(idev->intr_ctrl, qcq->intr.index,\n\t\t\t\tIONIC_INTR_MASK_SET);\n\t\tnetif_napi_del(&qcq->napi);\n\t}\n\n\tqcq->flags &= ~IONIC_QCQ_F_INITED;\n}\n\nstatic void ionic_qcq_intr_free(struct ionic_lif *lif, struct ionic_qcq *qcq)\n{\n\tif (!(qcq->flags & IONIC_QCQ_F_INTR) || qcq->intr.vector == 0)\n\t\treturn;\n\n\tirq_set_affinity_hint(qcq->intr.vector, NULL);\n\tdevm_free_irq(lif->ionic->dev, qcq->intr.vector, &qcq->napi);\n\tqcq->intr.vector = 0;\n\tionic_intr_free(lif->ionic, qcq->intr.index);\n\tqcq->intr.index = IONIC_INTR_INDEX_NOT_ASSIGNED;\n}\n\nstatic void ionic_qcq_free(struct ionic_lif *lif, struct ionic_qcq *qcq)\n{\n\tstruct device *dev = lif->ionic->dev;\n\n\tif (!qcq)\n\t\treturn;\n\n\tionic_debugfs_del_qcq(qcq);\n\n\tif (qcq->q_base) {\n\t\tdma_free_coherent(dev, qcq->q_size, qcq->q_base, qcq->q_base_pa);\n\t\tqcq->q_base = NULL;\n\t\tqcq->q_base_pa = 0;\n\t}\n\n\tif (qcq->cmb_q_base) {\n\t\tiounmap(qcq->cmb_q_base);\n\t\tionic_put_cmb(lif, qcq->cmb_pgid, qcq->cmb_order);\n\t\tqcq->cmb_pgid = 0;\n\t\tqcq->cmb_order = 0;\n\t\tqcq->cmb_q_base = NULL;\n\t\tqcq->cmb_q_base_pa = 0;\n\t}\n\n\tif (qcq->cq_base) {\n\t\tdma_free_coherent(dev, qcq->cq_size, qcq->cq_base, qcq->cq_base_pa);\n\t\tqcq->cq_base = NULL;\n\t\tqcq->cq_base_pa = 0;\n\t}\n\n\tif (qcq->sg_base) {\n\t\tdma_free_coherent(dev, qcq->sg_size, qcq->sg_base, qcq->sg_base_pa);\n\t\tqcq->sg_base = NULL;\n\t\tqcq->sg_base_pa = 0;\n\t}\n\n\tionic_qcq_intr_free(lif, qcq);\n\n\tif (qcq->cq.info) {\n\t\tvfree(qcq->cq.info);\n\t\tqcq->cq.info = NULL;\n\t}\n\tif (qcq->q.info) {\n\t\tvfree(qcq->q.info);\n\t\tqcq->q.info = NULL;\n\t}\n}\n\nvoid ionic_qcqs_free(struct ionic_lif *lif)\n{\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_qcq *adminqcq;\n\tunsigned long irqflags;\n\n\tif (lif->notifyqcq) {\n\t\tionic_qcq_free(lif, lif->notifyqcq);\n\t\tdevm_kfree(dev, lif->notifyqcq);\n\t\tlif->notifyqcq = NULL;\n\t}\n\n\tif (lif->adminqcq) {\n\t\tspin_lock_irqsave(&lif->adminq_lock, irqflags);\n\t\tadminqcq = READ_ONCE(lif->adminqcq);\n\t\tlif->adminqcq = NULL;\n\t\tspin_unlock_irqrestore(&lif->adminq_lock, irqflags);\n\t\tif (adminqcq) {\n\t\t\tionic_qcq_free(lif, adminqcq);\n\t\t\tdevm_kfree(dev, adminqcq);\n\t\t}\n\t}\n\n\tif (lif->rxqcqs) {\n\t\tdevm_kfree(dev, lif->rxqstats);\n\t\tlif->rxqstats = NULL;\n\t\tdevm_kfree(dev, lif->rxqcqs);\n\t\tlif->rxqcqs = NULL;\n\t}\n\n\tif (lif->txqcqs) {\n\t\tdevm_kfree(dev, lif->txqstats);\n\t\tlif->txqstats = NULL;\n\t\tdevm_kfree(dev, lif->txqcqs);\n\t\tlif->txqcqs = NULL;\n\t}\n}\n\nstatic void ionic_link_qcq_interrupts(struct ionic_qcq *src_qcq,\n\t\t\t\t      struct ionic_qcq *n_qcq)\n{\n\tn_qcq->intr.vector = src_qcq->intr.vector;\n\tn_qcq->intr.index = src_qcq->intr.index;\n\tn_qcq->napi_qcq = src_qcq->napi_qcq;\n}\n\nstatic int ionic_alloc_qcq_interrupt(struct ionic_lif *lif, struct ionic_qcq *qcq)\n{\n\tint err;\n\n\tif (!(qcq->flags & IONIC_QCQ_F_INTR)) {\n\t\tqcq->intr.index = IONIC_INTR_INDEX_NOT_ASSIGNED;\n\t\treturn 0;\n\t}\n\n\terr = ionic_intr_alloc(lif, &qcq->intr);\n\tif (err) {\n\t\tnetdev_warn(lif->netdev, \"no intr for %s: %d\\n\",\n\t\t\t    qcq->q.name, err);\n\t\tgoto err_out;\n\t}\n\n\terr = ionic_bus_get_irq(lif->ionic, qcq->intr.index);\n\tif (err < 0) {\n\t\tnetdev_warn(lif->netdev, \"no vector for %s: %d\\n\",\n\t\t\t    qcq->q.name, err);\n\t\tgoto err_out_free_intr;\n\t}\n\tqcq->intr.vector = err;\n\tionic_intr_mask_assert(lif->ionic->idev.intr_ctrl, qcq->intr.index,\n\t\t\t       IONIC_INTR_MASK_SET);\n\n\terr = ionic_request_irq(lif, qcq);\n\tif (err) {\n\t\tnetdev_warn(lif->netdev, \"irq request failed %d\\n\", err);\n\t\tgoto err_out_free_intr;\n\t}\n\n\t \n\tqcq->intr.cpu = cpumask_local_spread(qcq->intr.index,\n\t\t\t\t\t     dev_to_node(lif->ionic->dev));\n\tif (qcq->intr.cpu != -1)\n\t\tcpumask_set_cpu(qcq->intr.cpu, &qcq->intr.affinity_mask);\n\n\tnetdev_dbg(lif->netdev, \"%s: Interrupt index %d\\n\", qcq->q.name, qcq->intr.index);\n\treturn 0;\n\nerr_out_free_intr:\n\tionic_intr_free(lif->ionic, qcq->intr.index);\nerr_out:\n\treturn err;\n}\n\nstatic int ionic_qcq_alloc(struct ionic_lif *lif, unsigned int type,\n\t\t\t   unsigned int index,\n\t\t\t   const char *name, unsigned int flags,\n\t\t\t   unsigned int num_descs, unsigned int desc_size,\n\t\t\t   unsigned int cq_desc_size,\n\t\t\t   unsigned int sg_desc_size,\n\t\t\t   unsigned int pid, struct ionic_qcq **qcq)\n{\n\tstruct ionic_dev *idev = &lif->ionic->idev;\n\tstruct device *dev = lif->ionic->dev;\n\tvoid *q_base, *cq_base, *sg_base;\n\tdma_addr_t cq_base_pa = 0;\n\tdma_addr_t sg_base_pa = 0;\n\tdma_addr_t q_base_pa = 0;\n\tstruct ionic_qcq *new;\n\tint err;\n\n\t*qcq = NULL;\n\n\tnew = devm_kzalloc(dev, sizeof(*new), GFP_KERNEL);\n\tif (!new) {\n\t\tnetdev_err(lif->netdev, \"Cannot allocate queue structure\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tnew->q.dev = dev;\n\tnew->flags = flags;\n\n\tnew->q.info = vcalloc(num_descs, sizeof(*new->q.info));\n\tif (!new->q.info) {\n\t\tnetdev_err(lif->netdev, \"Cannot allocate queue info\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_out_free_qcq;\n\t}\n\n\tnew->q.type = type;\n\tnew->q.max_sg_elems = lif->qtype_info[type].max_sg_elems;\n\n\terr = ionic_q_init(lif, idev, &new->q, index, name, num_descs,\n\t\t\t   desc_size, sg_desc_size, pid);\n\tif (err) {\n\t\tnetdev_err(lif->netdev, \"Cannot initialize queue\\n\");\n\t\tgoto err_out_free_q_info;\n\t}\n\n\terr = ionic_alloc_qcq_interrupt(lif, new);\n\tif (err)\n\t\tgoto err_out;\n\n\tnew->cq.info = vcalloc(num_descs, sizeof(*new->cq.info));\n\tif (!new->cq.info) {\n\t\tnetdev_err(lif->netdev, \"Cannot allocate completion queue info\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_out_free_irq;\n\t}\n\n\terr = ionic_cq_init(lif, &new->cq, &new->intr, num_descs, cq_desc_size);\n\tif (err) {\n\t\tnetdev_err(lif->netdev, \"Cannot initialize completion queue\\n\");\n\t\tgoto err_out_free_cq_info;\n\t}\n\n\tif (flags & IONIC_QCQ_F_NOTIFYQ) {\n\t\tint q_size;\n\n\t\t \n\t\tq_size = ALIGN(num_descs * desc_size, PAGE_SIZE);\n\t\tnew->q_size = PAGE_SIZE + q_size +\n\t\t\t      ALIGN(num_descs * cq_desc_size, PAGE_SIZE);\n\t\tnew->q_base = dma_alloc_coherent(dev, new->q_size,\n\t\t\t\t\t\t &new->q_base_pa, GFP_KERNEL);\n\t\tif (!new->q_base) {\n\t\t\tnetdev_err(lif->netdev, \"Cannot allocate qcq DMA memory\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out_free_cq_info;\n\t\t}\n\t\tq_base = PTR_ALIGN(new->q_base, PAGE_SIZE);\n\t\tq_base_pa = ALIGN(new->q_base_pa, PAGE_SIZE);\n\t\tionic_q_map(&new->q, q_base, q_base_pa);\n\n\t\tcq_base = PTR_ALIGN(q_base + q_size, PAGE_SIZE);\n\t\tcq_base_pa = ALIGN(new->q_base_pa + q_size, PAGE_SIZE);\n\t\tionic_cq_map(&new->cq, cq_base, cq_base_pa);\n\t\tionic_cq_bind(&new->cq, &new->q);\n\t} else {\n\t\t \n\t\tnew->q_size = PAGE_SIZE + (num_descs * desc_size);\n\t\tnew->q_base = dma_alloc_coherent(dev, new->q_size, &new->q_base_pa,\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (!new->q_base) {\n\t\t\tnetdev_err(lif->netdev, \"Cannot allocate queue DMA memory\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out_free_cq_info;\n\t\t}\n\t\tq_base = PTR_ALIGN(new->q_base, PAGE_SIZE);\n\t\tq_base_pa = ALIGN(new->q_base_pa, PAGE_SIZE);\n\t\tionic_q_map(&new->q, q_base, q_base_pa);\n\n\t\tif (flags & IONIC_QCQ_F_CMB_RINGS) {\n\t\t\t \n\t\t\tnew->cmb_q_size = num_descs * desc_size;\n\t\t\tnew->cmb_order = order_base_2(new->cmb_q_size / PAGE_SIZE);\n\n\t\t\terr = ionic_get_cmb(lif, &new->cmb_pgid, &new->cmb_q_base_pa,\n\t\t\t\t\t    new->cmb_order);\n\t\t\tif (err) {\n\t\t\t\tnetdev_err(lif->netdev,\n\t\t\t\t\t   \"Cannot allocate queue order %d from cmb: err %d\\n\",\n\t\t\t\t\t   new->cmb_order, err);\n\t\t\t\tgoto err_out_free_q;\n\t\t\t}\n\n\t\t\tnew->cmb_q_base = ioremap_wc(new->cmb_q_base_pa, new->cmb_q_size);\n\t\t\tif (!new->cmb_q_base) {\n\t\t\t\tnetdev_err(lif->netdev, \"Cannot map queue from cmb\\n\");\n\t\t\t\tionic_put_cmb(lif, new->cmb_pgid, new->cmb_order);\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto err_out_free_q;\n\t\t\t}\n\n\t\t\tnew->cmb_q_base_pa -= idev->phy_cmb_pages;\n\t\t\tionic_q_cmb_map(&new->q, new->cmb_q_base, new->cmb_q_base_pa);\n\t\t}\n\n\t\t \n\t\tnew->cq_size = PAGE_SIZE + (num_descs * cq_desc_size);\n\t\tnew->cq_base = dma_alloc_coherent(dev, new->cq_size, &new->cq_base_pa,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!new->cq_base) {\n\t\t\tnetdev_err(lif->netdev, \"Cannot allocate cq DMA memory\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out_free_q;\n\t\t}\n\t\tcq_base = PTR_ALIGN(new->cq_base, PAGE_SIZE);\n\t\tcq_base_pa = ALIGN(new->cq_base_pa, PAGE_SIZE);\n\t\tionic_cq_map(&new->cq, cq_base, cq_base_pa);\n\t\tionic_cq_bind(&new->cq, &new->q);\n\t}\n\n\tif (flags & IONIC_QCQ_F_SG) {\n\t\tnew->sg_size = PAGE_SIZE + (num_descs * sg_desc_size);\n\t\tnew->sg_base = dma_alloc_coherent(dev, new->sg_size, &new->sg_base_pa,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!new->sg_base) {\n\t\t\tnetdev_err(lif->netdev, \"Cannot allocate sg DMA memory\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out_free_cq;\n\t\t}\n\t\tsg_base = PTR_ALIGN(new->sg_base, PAGE_SIZE);\n\t\tsg_base_pa = ALIGN(new->sg_base_pa, PAGE_SIZE);\n\t\tionic_q_sg_map(&new->q, sg_base, sg_base_pa);\n\t}\n\n\tINIT_WORK(&new->dim.work, ionic_dim_work);\n\tnew->dim.mode = DIM_CQ_PERIOD_MODE_START_FROM_EQE;\n\n\t*qcq = new;\n\n\treturn 0;\n\nerr_out_free_cq:\n\tdma_free_coherent(dev, new->cq_size, new->cq_base, new->cq_base_pa);\nerr_out_free_q:\n\tif (new->cmb_q_base) {\n\t\tiounmap(new->cmb_q_base);\n\t\tionic_put_cmb(lif, new->cmb_pgid, new->cmb_order);\n\t}\n\tdma_free_coherent(dev, new->q_size, new->q_base, new->q_base_pa);\nerr_out_free_cq_info:\n\tvfree(new->cq.info);\nerr_out_free_irq:\n\tif (flags & IONIC_QCQ_F_INTR) {\n\t\tdevm_free_irq(dev, new->intr.vector, &new->napi);\n\t\tionic_intr_free(lif->ionic, new->intr.index);\n\t}\nerr_out_free_q_info:\n\tvfree(new->q.info);\nerr_out_free_qcq:\n\tdevm_kfree(dev, new);\nerr_out:\n\tdev_err(dev, \"qcq alloc of %s%d failed %d\\n\", name, index, err);\n\treturn err;\n}\n\nstatic int ionic_qcqs_alloc(struct ionic_lif *lif)\n{\n\tstruct device *dev = lif->ionic->dev;\n\tunsigned int flags;\n\tint err;\n\n\tflags = IONIC_QCQ_F_INTR;\n\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_ADMINQ, 0, \"admin\", flags,\n\t\t\t      IONIC_ADMINQ_LENGTH,\n\t\t\t      sizeof(struct ionic_admin_cmd),\n\t\t\t      sizeof(struct ionic_admin_comp),\n\t\t\t      0, lif->kern_pid, &lif->adminqcq);\n\tif (err)\n\t\treturn err;\n\tionic_debugfs_add_qcq(lif, lif->adminqcq);\n\n\tif (lif->ionic->nnqs_per_lif) {\n\t\tflags = IONIC_QCQ_F_NOTIFYQ;\n\t\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_NOTIFYQ, 0, \"notifyq\",\n\t\t\t\t      flags, IONIC_NOTIFYQ_LENGTH,\n\t\t\t\t      sizeof(struct ionic_notifyq_cmd),\n\t\t\t\t      sizeof(union ionic_notifyq_comp),\n\t\t\t\t      0, lif->kern_pid, &lif->notifyqcq);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t\tionic_debugfs_add_qcq(lif, lif->notifyqcq);\n\n\t\t \n\t\tionic_link_qcq_interrupts(lif->adminqcq, lif->notifyqcq);\n\t}\n\n\terr = -ENOMEM;\n\tlif->txqcqs = devm_kcalloc(dev, lif->ionic->ntxqs_per_lif,\n\t\t\t\t   sizeof(*lif->txqcqs), GFP_KERNEL);\n\tif (!lif->txqcqs)\n\t\tgoto err_out;\n\tlif->rxqcqs = devm_kcalloc(dev, lif->ionic->nrxqs_per_lif,\n\t\t\t\t   sizeof(*lif->rxqcqs), GFP_KERNEL);\n\tif (!lif->rxqcqs)\n\t\tgoto err_out;\n\n\tlif->txqstats = devm_kcalloc(dev, lif->ionic->ntxqs_per_lif + 1,\n\t\t\t\t     sizeof(*lif->txqstats), GFP_KERNEL);\n\tif (!lif->txqstats)\n\t\tgoto err_out;\n\tlif->rxqstats = devm_kcalloc(dev, lif->ionic->nrxqs_per_lif + 1,\n\t\t\t\t     sizeof(*lif->rxqstats), GFP_KERNEL);\n\tif (!lif->rxqstats)\n\t\tgoto err_out;\n\n\treturn 0;\n\nerr_out:\n\tionic_qcqs_free(lif);\n\treturn err;\n}\n\nstatic void ionic_qcq_sanitize(struct ionic_qcq *qcq)\n{\n\tqcq->q.tail_idx = 0;\n\tqcq->q.head_idx = 0;\n\tqcq->cq.tail_idx = 0;\n\tqcq->cq.done_color = 1;\n\tmemset(qcq->q_base, 0, qcq->q_size);\n\tif (qcq->cmb_q_base)\n\t\tmemset_io(qcq->cmb_q_base, 0, qcq->cmb_q_size);\n\tmemset(qcq->cq_base, 0, qcq->cq_size);\n\tmemset(qcq->sg_base, 0, qcq->sg_size);\n}\n\nstatic int ionic_lif_txq_init(struct ionic_lif *lif, struct ionic_qcq *qcq)\n{\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_queue *q = &qcq->q;\n\tstruct ionic_cq *cq = &qcq->cq;\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.q_init = {\n\t\t\t.opcode = IONIC_CMD_Q_INIT,\n\t\t\t.lif_index = cpu_to_le16(lif->index),\n\t\t\t.type = q->type,\n\t\t\t.ver = lif->qtype_info[q->type].version,\n\t\t\t.index = cpu_to_le32(q->index),\n\t\t\t.flags = cpu_to_le16(IONIC_QINIT_F_IRQ |\n\t\t\t\t\t     IONIC_QINIT_F_SG),\n\t\t\t.intr_index = cpu_to_le16(qcq->intr.index),\n\t\t\t.pid = cpu_to_le16(q->pid),\n\t\t\t.ring_size = ilog2(q->num_descs),\n\t\t\t.ring_base = cpu_to_le64(q->base_pa),\n\t\t\t.cq_ring_base = cpu_to_le64(cq->base_pa),\n\t\t\t.sg_ring_base = cpu_to_le64(q->sg_base_pa),\n\t\t\t.features = cpu_to_le64(q->features),\n\t\t},\n\t};\n\tint err;\n\n\tif (qcq->flags & IONIC_QCQ_F_CMB_RINGS) {\n\t\tctx.cmd.q_init.flags |= cpu_to_le16(IONIC_QINIT_F_CMB);\n\t\tctx.cmd.q_init.ring_base = cpu_to_le64(qcq->cmb_q_base_pa);\n\t}\n\n\tdev_dbg(dev, \"txq_init.pid %d\\n\", ctx.cmd.q_init.pid);\n\tdev_dbg(dev, \"txq_init.index %d\\n\", ctx.cmd.q_init.index);\n\tdev_dbg(dev, \"txq_init.ring_base 0x%llx\\n\", ctx.cmd.q_init.ring_base);\n\tdev_dbg(dev, \"txq_init.ring_size %d\\n\", ctx.cmd.q_init.ring_size);\n\tdev_dbg(dev, \"txq_init.cq_ring_base 0x%llx\\n\", ctx.cmd.q_init.cq_ring_base);\n\tdev_dbg(dev, \"txq_init.sg_ring_base 0x%llx\\n\", ctx.cmd.q_init.sg_ring_base);\n\tdev_dbg(dev, \"txq_init.flags 0x%x\\n\", ctx.cmd.q_init.flags);\n\tdev_dbg(dev, \"txq_init.ver %d\\n\", ctx.cmd.q_init.ver);\n\tdev_dbg(dev, \"txq_init.intr_index %d\\n\", ctx.cmd.q_init.intr_index);\n\n\tionic_qcq_sanitize(qcq);\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\treturn err;\n\n\tq->hw_type = ctx.comp.q_init.hw_type;\n\tq->hw_index = le32_to_cpu(ctx.comp.q_init.hw_index);\n\tq->dbval = IONIC_DBELL_QID(q->hw_index);\n\n\tdev_dbg(dev, \"txq->hw_type %d\\n\", q->hw_type);\n\tdev_dbg(dev, \"txq->hw_index %d\\n\", q->hw_index);\n\n\tq->dbell_deadline = IONIC_TX_DOORBELL_DEADLINE;\n\tq->dbell_jiffies = jiffies;\n\n\tif (test_bit(IONIC_LIF_F_SPLIT_INTR, lif->state)) {\n\t\tnetif_napi_add(lif->netdev, &qcq->napi, ionic_tx_napi);\n\t\tqcq->napi_qcq = qcq;\n\t\ttimer_setup(&qcq->napi_deadline, ionic_napi_deadline, 0);\n\t}\n\n\tqcq->flags |= IONIC_QCQ_F_INITED;\n\n\treturn 0;\n}\n\nstatic int ionic_lif_rxq_init(struct ionic_lif *lif, struct ionic_qcq *qcq)\n{\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_queue *q = &qcq->q;\n\tstruct ionic_cq *cq = &qcq->cq;\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.q_init = {\n\t\t\t.opcode = IONIC_CMD_Q_INIT,\n\t\t\t.lif_index = cpu_to_le16(lif->index),\n\t\t\t.type = q->type,\n\t\t\t.ver = lif->qtype_info[q->type].version,\n\t\t\t.index = cpu_to_le32(q->index),\n\t\t\t.flags = cpu_to_le16(IONIC_QINIT_F_IRQ |\n\t\t\t\t\t     IONIC_QINIT_F_SG),\n\t\t\t.intr_index = cpu_to_le16(cq->bound_intr->index),\n\t\t\t.pid = cpu_to_le16(q->pid),\n\t\t\t.ring_size = ilog2(q->num_descs),\n\t\t\t.ring_base = cpu_to_le64(q->base_pa),\n\t\t\t.cq_ring_base = cpu_to_le64(cq->base_pa),\n\t\t\t.sg_ring_base = cpu_to_le64(q->sg_base_pa),\n\t\t\t.features = cpu_to_le64(q->features),\n\t\t},\n\t};\n\tint err;\n\n\tif (qcq->flags & IONIC_QCQ_F_CMB_RINGS) {\n\t\tctx.cmd.q_init.flags |= cpu_to_le16(IONIC_QINIT_F_CMB);\n\t\tctx.cmd.q_init.ring_base = cpu_to_le64(qcq->cmb_q_base_pa);\n\t}\n\n\tdev_dbg(dev, \"rxq_init.pid %d\\n\", ctx.cmd.q_init.pid);\n\tdev_dbg(dev, \"rxq_init.index %d\\n\", ctx.cmd.q_init.index);\n\tdev_dbg(dev, \"rxq_init.ring_base 0x%llx\\n\", ctx.cmd.q_init.ring_base);\n\tdev_dbg(dev, \"rxq_init.ring_size %d\\n\", ctx.cmd.q_init.ring_size);\n\tdev_dbg(dev, \"rxq_init.flags 0x%x\\n\", ctx.cmd.q_init.flags);\n\tdev_dbg(dev, \"rxq_init.ver %d\\n\", ctx.cmd.q_init.ver);\n\tdev_dbg(dev, \"rxq_init.intr_index %d\\n\", ctx.cmd.q_init.intr_index);\n\n\tionic_qcq_sanitize(qcq);\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\treturn err;\n\n\tq->hw_type = ctx.comp.q_init.hw_type;\n\tq->hw_index = le32_to_cpu(ctx.comp.q_init.hw_index);\n\tq->dbval = IONIC_DBELL_QID(q->hw_index);\n\n\tdev_dbg(dev, \"rxq->hw_type %d\\n\", q->hw_type);\n\tdev_dbg(dev, \"rxq->hw_index %d\\n\", q->hw_index);\n\n\tq->dbell_deadline = IONIC_RX_MIN_DOORBELL_DEADLINE;\n\tq->dbell_jiffies = jiffies;\n\n\tif (test_bit(IONIC_LIF_F_SPLIT_INTR, lif->state))\n\t\tnetif_napi_add(lif->netdev, &qcq->napi, ionic_rx_napi);\n\telse\n\t\tnetif_napi_add(lif->netdev, &qcq->napi, ionic_txrx_napi);\n\n\tqcq->napi_qcq = qcq;\n\ttimer_setup(&qcq->napi_deadline, ionic_napi_deadline, 0);\n\n\tqcq->flags |= IONIC_QCQ_F_INITED;\n\n\treturn 0;\n}\n\nint ionic_lif_create_hwstamp_txq(struct ionic_lif *lif)\n{\n\tunsigned int num_desc, desc_sz, comp_sz, sg_desc_sz;\n\tunsigned int txq_i, flags;\n\tstruct ionic_qcq *txq;\n\tu64 features;\n\tint err;\n\n\tif (lif->hwstamp_txq)\n\t\treturn 0;\n\n\tfeatures = IONIC_Q_F_2X_CQ_DESC | IONIC_TXQ_F_HWSTAMP;\n\n\tnum_desc = IONIC_MIN_TXRX_DESC;\n\tdesc_sz = sizeof(struct ionic_txq_desc);\n\tcomp_sz = 2 * sizeof(struct ionic_txq_comp);\n\n\tif (lif->qtype_info[IONIC_QTYPE_TXQ].version >= 1 &&\n\t    lif->qtype_info[IONIC_QTYPE_TXQ].sg_desc_sz == sizeof(struct ionic_txq_sg_desc_v1))\n\t\tsg_desc_sz = sizeof(struct ionic_txq_sg_desc_v1);\n\telse\n\t\tsg_desc_sz = sizeof(struct ionic_txq_sg_desc);\n\n\ttxq_i = lif->ionic->ntxqs_per_lif;\n\tflags = IONIC_QCQ_F_TX_STATS | IONIC_QCQ_F_SG;\n\n\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_TXQ, txq_i, \"hwstamp_tx\", flags,\n\t\t\t      num_desc, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t      lif->kern_pid, &txq);\n\tif (err)\n\t\tgoto err_qcq_alloc;\n\n\ttxq->q.features = features;\n\n\tionic_link_qcq_interrupts(lif->adminqcq, txq);\n\tionic_debugfs_add_qcq(lif, txq);\n\n\tlif->hwstamp_txq = txq;\n\n\tif (netif_running(lif->netdev)) {\n\t\terr = ionic_lif_txq_init(lif, txq);\n\t\tif (err)\n\t\t\tgoto err_qcq_init;\n\n\t\tif (test_bit(IONIC_LIF_F_UP, lif->state)) {\n\t\t\terr = ionic_qcq_enable(txq);\n\t\t\tif (err)\n\t\t\t\tgoto err_qcq_enable;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_qcq_enable:\n\tionic_lif_qcq_deinit(lif, txq);\nerr_qcq_init:\n\tlif->hwstamp_txq = NULL;\n\tionic_debugfs_del_qcq(txq);\n\tionic_qcq_free(lif, txq);\n\tdevm_kfree(lif->ionic->dev, txq);\nerr_qcq_alloc:\n\treturn err;\n}\n\nint ionic_lif_create_hwstamp_rxq(struct ionic_lif *lif)\n{\n\tunsigned int num_desc, desc_sz, comp_sz, sg_desc_sz;\n\tunsigned int rxq_i, flags;\n\tstruct ionic_qcq *rxq;\n\tu64 features;\n\tint err;\n\n\tif (lif->hwstamp_rxq)\n\t\treturn 0;\n\n\tfeatures = IONIC_Q_F_2X_CQ_DESC | IONIC_RXQ_F_HWSTAMP;\n\n\tnum_desc = IONIC_MIN_TXRX_DESC;\n\tdesc_sz = sizeof(struct ionic_rxq_desc);\n\tcomp_sz = 2 * sizeof(struct ionic_rxq_comp);\n\tsg_desc_sz = sizeof(struct ionic_rxq_sg_desc);\n\n\trxq_i = lif->ionic->nrxqs_per_lif;\n\tflags = IONIC_QCQ_F_RX_STATS | IONIC_QCQ_F_SG;\n\n\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_RXQ, rxq_i, \"hwstamp_rx\", flags,\n\t\t\t      num_desc, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t      lif->kern_pid, &rxq);\n\tif (err)\n\t\tgoto err_qcq_alloc;\n\n\trxq->q.features = features;\n\n\tionic_link_qcq_interrupts(lif->adminqcq, rxq);\n\tionic_debugfs_add_qcq(lif, rxq);\n\n\tlif->hwstamp_rxq = rxq;\n\n\tif (netif_running(lif->netdev)) {\n\t\terr = ionic_lif_rxq_init(lif, rxq);\n\t\tif (err)\n\t\t\tgoto err_qcq_init;\n\n\t\tif (test_bit(IONIC_LIF_F_UP, lif->state)) {\n\t\t\tionic_rx_fill(&rxq->q);\n\t\t\terr = ionic_qcq_enable(rxq);\n\t\t\tif (err)\n\t\t\t\tgoto err_qcq_enable;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_qcq_enable:\n\tionic_lif_qcq_deinit(lif, rxq);\nerr_qcq_init:\n\tlif->hwstamp_rxq = NULL;\n\tionic_debugfs_del_qcq(rxq);\n\tionic_qcq_free(lif, rxq);\n\tdevm_kfree(lif->ionic->dev, rxq);\nerr_qcq_alloc:\n\treturn err;\n}\n\nint ionic_lif_config_hwstamp_rxq_all(struct ionic_lif *lif, bool rx_all)\n{\n\tstruct ionic_queue_params qparam;\n\n\tionic_init_queue_params(lif, &qparam);\n\n\tif (rx_all)\n\t\tqparam.rxq_features = IONIC_Q_F_2X_CQ_DESC | IONIC_RXQ_F_HWSTAMP;\n\telse\n\t\tqparam.rxq_features = 0;\n\n\t \n\tif (!netif_running(lif->netdev)) {\n\t\tlif->rxq_features = qparam.rxq_features;\n\t\treturn 0;\n\t}\n\n\treturn ionic_reconfigure_queues(lif, &qparam);\n}\n\nint ionic_lif_set_hwstamp_txmode(struct ionic_lif *lif, u16 txstamp_mode)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_setattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_SETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_TXSTAMP,\n\t\t\t.txstamp_mode = cpu_to_le16(txstamp_mode),\n\t\t},\n\t};\n\n\treturn ionic_adminq_post_wait(lif, &ctx);\n}\n\nstatic void ionic_lif_del_hwstamp_rxfilt(struct ionic_lif *lif)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.rx_filter_del = {\n\t\t\t.opcode = IONIC_CMD_RX_FILTER_DEL,\n\t\t\t.lif_index = cpu_to_le16(lif->index),\n\t\t},\n\t};\n\tstruct ionic_rx_filter *f;\n\tu32 filter_id;\n\tint err;\n\n\tspin_lock_bh(&lif->rx_filters.lock);\n\n\tf = ionic_rx_filter_rxsteer(lif);\n\tif (!f) {\n\t\tspin_unlock_bh(&lif->rx_filters.lock);\n\t\treturn;\n\t}\n\n\tfilter_id = f->filter_id;\n\tionic_rx_filter_free(lif, f);\n\n\tspin_unlock_bh(&lif->rx_filters.lock);\n\n\tnetdev_dbg(lif->netdev, \"rx_filter del RXSTEER (id %d)\\n\", filter_id);\n\n\tctx.cmd.rx_filter_del.filter_id = cpu_to_le32(filter_id);\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err && err != -EEXIST)\n\t\tnetdev_dbg(lif->netdev, \"failed to delete rx_filter RXSTEER (id %d)\\n\", filter_id);\n}\n\nstatic int ionic_lif_add_hwstamp_rxfilt(struct ionic_lif *lif, u64 pkt_class)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.rx_filter_add = {\n\t\t\t.opcode = IONIC_CMD_RX_FILTER_ADD,\n\t\t\t.lif_index = cpu_to_le16(lif->index),\n\t\t\t.match = cpu_to_le16(IONIC_RX_FILTER_STEER_PKTCLASS),\n\t\t\t.pkt_class = cpu_to_le64(pkt_class),\n\t\t},\n\t};\n\tu8 qtype;\n\tu32 qid;\n\tint err;\n\n\tif (!lif->hwstamp_rxq)\n\t\treturn -EINVAL;\n\n\tqtype = lif->hwstamp_rxq->q.type;\n\tctx.cmd.rx_filter_add.qtype = qtype;\n\n\tqid = lif->hwstamp_rxq->q.index;\n\tctx.cmd.rx_filter_add.qid = cpu_to_le32(qid);\n\n\tnetdev_dbg(lif->netdev, \"rx_filter add RXSTEER\\n\");\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err && err != -EEXIST)\n\t\treturn err;\n\n\tspin_lock_bh(&lif->rx_filters.lock);\n\terr = ionic_rx_filter_save(lif, 0, qid, 0, &ctx, IONIC_FILTER_STATE_SYNCED);\n\tspin_unlock_bh(&lif->rx_filters.lock);\n\n\treturn err;\n}\n\nint ionic_lif_set_hwstamp_rxfilt(struct ionic_lif *lif, u64 pkt_class)\n{\n\tionic_lif_del_hwstamp_rxfilt(lif);\n\n\tif (!pkt_class)\n\t\treturn 0;\n\n\treturn ionic_lif_add_hwstamp_rxfilt(lif, pkt_class);\n}\n\nstatic bool ionic_notifyq_service(struct ionic_cq *cq,\n\t\t\t\t  struct ionic_cq_info *cq_info)\n{\n\tunion ionic_notifyq_comp *comp = cq_info->cq_desc;\n\tstruct ionic_deferred_work *work;\n\tstruct net_device *netdev;\n\tstruct ionic_queue *q;\n\tstruct ionic_lif *lif;\n\tu64 eid;\n\n\tq = cq->bound_q;\n\tlif = q->info[0].cb_arg;\n\tnetdev = lif->netdev;\n\teid = le64_to_cpu(comp->event.eid);\n\n\t \n\tif ((s64)(eid - lif->last_eid) <= 0)\n\t\treturn false;\n\n\tlif->last_eid = eid;\n\n\tdev_dbg(lif->ionic->dev, \"notifyq event:\\n\");\n\tdynamic_hex_dump(\"event \", DUMP_PREFIX_OFFSET, 16, 1,\n\t\t\t comp, sizeof(*comp), true);\n\n\tswitch (le16_to_cpu(comp->event.ecode)) {\n\tcase IONIC_EVENT_LINK_CHANGE:\n\t\tionic_link_status_check_request(lif, CAN_NOT_SLEEP);\n\t\tbreak;\n\tcase IONIC_EVENT_RESET:\n\t\tif (lif->ionic->idev.fw_status_ready &&\n\t\t    !test_bit(IONIC_LIF_F_FW_RESET, lif->state) &&\n\t\t    !test_and_set_bit(IONIC_LIF_F_FW_STOPPING, lif->state)) {\n\t\t\twork = kzalloc(sizeof(*work), GFP_ATOMIC);\n\t\t\tif (!work) {\n\t\t\t\tnetdev_err(lif->netdev, \"Reset event dropped\\n\");\n\t\t\t\tclear_bit(IONIC_LIF_F_FW_STOPPING, lif->state);\n\t\t\t} else {\n\t\t\t\twork->type = IONIC_DW_TYPE_LIF_RESET;\n\t\t\t\tionic_lif_deferred_enqueue(&lif->deferred, work);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tnetdev_warn(netdev, \"Notifyq event ecode=%d eid=%lld\\n\",\n\t\t\t    comp->event.ecode, eid);\n\t\tbreak;\n\t}\n\n\treturn true;\n}\n\nstatic bool ionic_adminq_service(struct ionic_cq *cq,\n\t\t\t\t struct ionic_cq_info *cq_info)\n{\n\tstruct ionic_admin_comp *comp = cq_info->cq_desc;\n\n\tif (!color_match(comp->color, cq->done_color))\n\t\treturn false;\n\n\tionic_q_service(cq->bound_q, cq_info, le16_to_cpu(comp->comp_index));\n\n\treturn true;\n}\n\nstatic int ionic_adminq_napi(struct napi_struct *napi, int budget)\n{\n\tstruct ionic_intr_info *intr = napi_to_cq(napi)->bound_intr;\n\tstruct ionic_lif *lif = napi_to_cq(napi)->lif;\n\tstruct ionic_dev *idev = &lif->ionic->idev;\n\tunsigned long irqflags;\n\tunsigned int flags = 0;\n\tbool resched = false;\n\tint rx_work = 0;\n\tint tx_work = 0;\n\tint n_work = 0;\n\tint a_work = 0;\n\tint work_done;\n\tint credits;\n\n\tif (lif->notifyqcq && lif->notifyqcq->flags & IONIC_QCQ_F_INITED)\n\t\tn_work = ionic_cq_service(&lif->notifyqcq->cq, budget,\n\t\t\t\t\t  ionic_notifyq_service, NULL, NULL);\n\n\tspin_lock_irqsave(&lif->adminq_lock, irqflags);\n\tif (lif->adminqcq && lif->adminqcq->flags & IONIC_QCQ_F_INITED)\n\t\ta_work = ionic_cq_service(&lif->adminqcq->cq, budget,\n\t\t\t\t\t  ionic_adminq_service, NULL, NULL);\n\tspin_unlock_irqrestore(&lif->adminq_lock, irqflags);\n\n\tif (lif->hwstamp_rxq)\n\t\trx_work = ionic_cq_service(&lif->hwstamp_rxq->cq, budget,\n\t\t\t\t\t   ionic_rx_service, NULL, NULL);\n\n\tif (lif->hwstamp_txq)\n\t\ttx_work = ionic_cq_service(&lif->hwstamp_txq->cq, budget,\n\t\t\t\t\t   ionic_tx_service, NULL, NULL);\n\n\twork_done = max(max(n_work, a_work), max(rx_work, tx_work));\n\tif (work_done < budget && napi_complete_done(napi, work_done)) {\n\t\tflags |= IONIC_INTR_CRED_UNMASK;\n\t\tintr->rearm_count++;\n\t}\n\n\tif (work_done || flags) {\n\t\tflags |= IONIC_INTR_CRED_RESET_COALESCE;\n\t\tcredits = n_work + a_work + rx_work + tx_work;\n\t\tionic_intr_credits(idev->intr_ctrl, intr->index, credits, flags);\n\t}\n\n\tif (!a_work && ionic_adminq_poke_doorbell(&lif->adminqcq->q))\n\t\tresched = true;\n\tif (lif->hwstamp_rxq && !rx_work && ionic_rxq_poke_doorbell(&lif->hwstamp_rxq->q))\n\t\tresched = true;\n\tif (lif->hwstamp_txq && !tx_work && ionic_txq_poke_doorbell(&lif->hwstamp_txq->q))\n\t\tresched = true;\n\tif (resched)\n\t\tmod_timer(&lif->adminqcq->napi_deadline,\n\t\t\t  jiffies + IONIC_NAPI_DEADLINE);\n\n\treturn work_done;\n}\n\nvoid ionic_get_stats64(struct net_device *netdev,\n\t\t       struct rtnl_link_stats64 *ns)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic_lif_stats *ls;\n\n\tmemset(ns, 0, sizeof(*ns));\n\tls = &lif->info->stats;\n\n\tns->rx_packets = le64_to_cpu(ls->rx_ucast_packets) +\n\t\t\t le64_to_cpu(ls->rx_mcast_packets) +\n\t\t\t le64_to_cpu(ls->rx_bcast_packets);\n\n\tns->tx_packets = le64_to_cpu(ls->tx_ucast_packets) +\n\t\t\t le64_to_cpu(ls->tx_mcast_packets) +\n\t\t\t le64_to_cpu(ls->tx_bcast_packets);\n\n\tns->rx_bytes = le64_to_cpu(ls->rx_ucast_bytes) +\n\t\t       le64_to_cpu(ls->rx_mcast_bytes) +\n\t\t       le64_to_cpu(ls->rx_bcast_bytes);\n\n\tns->tx_bytes = le64_to_cpu(ls->tx_ucast_bytes) +\n\t\t       le64_to_cpu(ls->tx_mcast_bytes) +\n\t\t       le64_to_cpu(ls->tx_bcast_bytes);\n\n\tns->rx_dropped = le64_to_cpu(ls->rx_ucast_drop_packets) +\n\t\t\t le64_to_cpu(ls->rx_mcast_drop_packets) +\n\t\t\t le64_to_cpu(ls->rx_bcast_drop_packets);\n\n\tns->tx_dropped = le64_to_cpu(ls->tx_ucast_drop_packets) +\n\t\t\t le64_to_cpu(ls->tx_mcast_drop_packets) +\n\t\t\t le64_to_cpu(ls->tx_bcast_drop_packets);\n\n\tns->multicast = le64_to_cpu(ls->rx_mcast_packets);\n\n\tns->rx_over_errors = le64_to_cpu(ls->rx_queue_empty);\n\n\tns->rx_missed_errors = le64_to_cpu(ls->rx_dma_error) +\n\t\t\t       le64_to_cpu(ls->rx_queue_disabled) +\n\t\t\t       le64_to_cpu(ls->rx_desc_fetch_error) +\n\t\t\t       le64_to_cpu(ls->rx_desc_data_error);\n\n\tns->tx_aborted_errors = le64_to_cpu(ls->tx_dma_error) +\n\t\t\t\tle64_to_cpu(ls->tx_queue_disabled) +\n\t\t\t\tle64_to_cpu(ls->tx_desc_fetch_error) +\n\t\t\t\tle64_to_cpu(ls->tx_desc_data_error);\n\n\tns->rx_errors = ns->rx_over_errors +\n\t\t\tns->rx_missed_errors;\n\n\tns->tx_errors = ns->tx_aborted_errors;\n}\n\nstatic int ionic_addr_add(struct net_device *netdev, const u8 *addr)\n{\n\treturn ionic_lif_list_addr(netdev_priv(netdev), addr, ADD_ADDR);\n}\n\nstatic int ionic_addr_del(struct net_device *netdev, const u8 *addr)\n{\n\t \n\tif (ether_addr_equal(addr, netdev->dev_addr))\n\t\treturn 0;\n\n\treturn ionic_lif_list_addr(netdev_priv(netdev), addr, DEL_ADDR);\n}\n\nvoid ionic_lif_rx_mode(struct ionic_lif *lif)\n{\n\tstruct net_device *netdev = lif->netdev;\n\tunsigned int nfilters;\n\tunsigned int nd_flags;\n\tchar buf[128];\n\tu16 rx_mode;\n\tint i;\n#define REMAIN(__x) (sizeof(buf) - (__x))\n\n\tmutex_lock(&lif->config_lock);\n\n\t \n\tnd_flags = netdev->flags;\n\n\trx_mode = IONIC_RX_MODE_F_UNICAST;\n\trx_mode |= (nd_flags & IFF_MULTICAST) ? IONIC_RX_MODE_F_MULTICAST : 0;\n\trx_mode |= (nd_flags & IFF_BROADCAST) ? IONIC_RX_MODE_F_BROADCAST : 0;\n\trx_mode |= (nd_flags & IFF_PROMISC) ? IONIC_RX_MODE_F_PROMISC : 0;\n\trx_mode |= (nd_flags & IFF_ALLMULTI) ? IONIC_RX_MODE_F_ALLMULTI : 0;\n\n\t \n\tionic_rx_filter_sync(lif);\n\n\t \n\tnfilters = le32_to_cpu(lif->identity->eth.max_ucast_filters);\n\n\tif (((lif->nucast + lif->nmcast) >= nfilters) ||\n\t    (lif->max_vlans && lif->nvlans >= lif->max_vlans)) {\n\t\trx_mode |= IONIC_RX_MODE_F_PROMISC;\n\t\trx_mode |= IONIC_RX_MODE_F_ALLMULTI;\n\t} else {\n\t\tif (!(nd_flags & IFF_PROMISC))\n\t\t\trx_mode &= ~IONIC_RX_MODE_F_PROMISC;\n\t\tif (!(nd_flags & IFF_ALLMULTI))\n\t\t\trx_mode &= ~IONIC_RX_MODE_F_ALLMULTI;\n\t}\n\n\ti = scnprintf(buf, sizeof(buf), \"rx_mode 0x%04x -> 0x%04x:\",\n\t\t      lif->rx_mode, rx_mode);\n\tif (rx_mode & IONIC_RX_MODE_F_UNICAST)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" RX_MODE_F_UNICAST\");\n\tif (rx_mode & IONIC_RX_MODE_F_MULTICAST)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" RX_MODE_F_MULTICAST\");\n\tif (rx_mode & IONIC_RX_MODE_F_BROADCAST)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" RX_MODE_F_BROADCAST\");\n\tif (rx_mode & IONIC_RX_MODE_F_PROMISC)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" RX_MODE_F_PROMISC\");\n\tif (rx_mode & IONIC_RX_MODE_F_ALLMULTI)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" RX_MODE_F_ALLMULTI\");\n\tif (rx_mode & IONIC_RX_MODE_F_RDMA_SNIFFER)\n\t\ti += scnprintf(&buf[i], REMAIN(i), \" RX_MODE_F_RDMA_SNIFFER\");\n\tnetdev_dbg(netdev, \"lif%d %s\\n\", lif->index, buf);\n\n\tif (lif->rx_mode != rx_mode) {\n\t\tstruct ionic_admin_ctx ctx = {\n\t\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t\t.cmd.rx_mode_set = {\n\t\t\t\t.opcode = IONIC_CMD_RX_MODE_SET,\n\t\t\t\t.lif_index = cpu_to_le16(lif->index),\n\t\t\t},\n\t\t};\n\t\tint err;\n\n\t\tctx.cmd.rx_mode_set.rx_mode = cpu_to_le16(rx_mode);\n\t\terr = ionic_adminq_post_wait(lif, &ctx);\n\t\tif (err)\n\t\t\tnetdev_warn(netdev, \"set rx_mode 0x%04x failed: %d\\n\",\n\t\t\t\t    rx_mode, err);\n\t\telse\n\t\t\tlif->rx_mode = rx_mode;\n\t}\n\n\tmutex_unlock(&lif->config_lock);\n}\n\nstatic void ionic_ndo_set_rx_mode(struct net_device *netdev)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic_deferred_work *work;\n\n\t \n\t__dev_uc_sync(netdev, ionic_addr_add, ionic_addr_del);\n\t__dev_mc_sync(netdev, ionic_addr_add, ionic_addr_del);\n\n\t \n\twork = kzalloc(sizeof(*work), GFP_ATOMIC);\n\tif (!work) {\n\t\tnetdev_err(lif->netdev, \"rxmode change dropped\\n\");\n\t\treturn;\n\t}\n\twork->type = IONIC_DW_TYPE_RX_MODE;\n\tnetdev_dbg(lif->netdev, \"deferred: rx_mode\\n\");\n\tionic_lif_deferred_enqueue(&lif->deferred, work);\n}\n\nstatic __le64 ionic_netdev_features_to_nic(netdev_features_t features)\n{\n\tu64 wanted = 0;\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_TX)\n\t\twanted |= IONIC_ETH_HW_VLAN_TX_TAG;\n\tif (features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\twanted |= IONIC_ETH_HW_VLAN_RX_STRIP;\n\tif (features & NETIF_F_HW_VLAN_CTAG_FILTER)\n\t\twanted |= IONIC_ETH_HW_VLAN_RX_FILTER;\n\tif (features & NETIF_F_RXHASH)\n\t\twanted |= IONIC_ETH_HW_RX_HASH;\n\tif (features & NETIF_F_RXCSUM)\n\t\twanted |= IONIC_ETH_HW_RX_CSUM;\n\tif (features & NETIF_F_SG)\n\t\twanted |= IONIC_ETH_HW_TX_SG;\n\tif (features & NETIF_F_HW_CSUM)\n\t\twanted |= IONIC_ETH_HW_TX_CSUM;\n\tif (features & NETIF_F_TSO)\n\t\twanted |= IONIC_ETH_HW_TSO;\n\tif (features & NETIF_F_TSO6)\n\t\twanted |= IONIC_ETH_HW_TSO_IPV6;\n\tif (features & NETIF_F_TSO_ECN)\n\t\twanted |= IONIC_ETH_HW_TSO_ECN;\n\tif (features & NETIF_F_GSO_GRE)\n\t\twanted |= IONIC_ETH_HW_TSO_GRE;\n\tif (features & NETIF_F_GSO_GRE_CSUM)\n\t\twanted |= IONIC_ETH_HW_TSO_GRE_CSUM;\n\tif (features & NETIF_F_GSO_IPXIP4)\n\t\twanted |= IONIC_ETH_HW_TSO_IPXIP4;\n\tif (features & NETIF_F_GSO_IPXIP6)\n\t\twanted |= IONIC_ETH_HW_TSO_IPXIP6;\n\tif (features & NETIF_F_GSO_UDP_TUNNEL)\n\t\twanted |= IONIC_ETH_HW_TSO_UDP;\n\tif (features & NETIF_F_GSO_UDP_TUNNEL_CSUM)\n\t\twanted |= IONIC_ETH_HW_TSO_UDP_CSUM;\n\n\treturn cpu_to_le64(wanted);\n}\n\nstatic int ionic_set_nic_features(struct ionic_lif *lif,\n\t\t\t\t  netdev_features_t features)\n{\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_setattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_SETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_FEATURES,\n\t\t},\n\t};\n\tu64 vlan_flags = IONIC_ETH_HW_VLAN_TX_TAG |\n\t\t\t IONIC_ETH_HW_VLAN_RX_STRIP |\n\t\t\t IONIC_ETH_HW_VLAN_RX_FILTER;\n\tu64 old_hw_features;\n\tint err;\n\n\tctx.cmd.lif_setattr.features = ionic_netdev_features_to_nic(features);\n\n\tif (lif->phc)\n\t\tctx.cmd.lif_setattr.features |= cpu_to_le64(IONIC_ETH_HW_TIMESTAMP);\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\treturn err;\n\n\told_hw_features = lif->hw_features;\n\tlif->hw_features = le64_to_cpu(ctx.cmd.lif_setattr.features &\n\t\t\t\t       ctx.comp.lif_setattr.features);\n\n\tif ((old_hw_features ^ lif->hw_features) & IONIC_ETH_HW_RX_HASH)\n\t\tionic_lif_rss_config(lif, lif->rss_types, NULL, NULL);\n\n\tif ((vlan_flags & le64_to_cpu(ctx.cmd.lif_setattr.features)) &&\n\t    !(vlan_flags & le64_to_cpu(ctx.comp.lif_setattr.features)))\n\t\tdev_info_once(lif->ionic->dev, \"NIC is not supporting vlan offload, likely in SmartNIC mode\\n\");\n\n\tif (lif->hw_features & IONIC_ETH_HW_VLAN_TX_TAG)\n\t\tdev_dbg(dev, \"feature ETH_HW_VLAN_TX_TAG\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_VLAN_RX_STRIP)\n\t\tdev_dbg(dev, \"feature ETH_HW_VLAN_RX_STRIP\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_VLAN_RX_FILTER)\n\t\tdev_dbg(dev, \"feature ETH_HW_VLAN_RX_FILTER\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_RX_HASH)\n\t\tdev_dbg(dev, \"feature ETH_HW_RX_HASH\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TX_SG)\n\t\tdev_dbg(dev, \"feature ETH_HW_TX_SG\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TX_CSUM)\n\t\tdev_dbg(dev, \"feature ETH_HW_TX_CSUM\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_RX_CSUM)\n\t\tdev_dbg(dev, \"feature ETH_HW_RX_CSUM\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_IPV6)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_IPV6\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_ECN)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_ECN\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_GRE)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_GRE\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_GRE_CSUM)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_GRE_CSUM\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_IPXIP4)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_IPXIP4\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_IPXIP6)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_IPXIP6\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_UDP)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_UDP\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_UDP_CSUM)\n\t\tdev_dbg(dev, \"feature ETH_HW_TSO_UDP_CSUM\\n\");\n\tif (lif->hw_features & IONIC_ETH_HW_TIMESTAMP)\n\t\tdev_dbg(dev, \"feature ETH_HW_TIMESTAMP\\n\");\n\n\treturn 0;\n}\n\nstatic int ionic_init_nic_features(struct ionic_lif *lif)\n{\n\tstruct net_device *netdev = lif->netdev;\n\tnetdev_features_t features;\n\tint err;\n\n\t \n\tfeatures = NETIF_F_HW_VLAN_CTAG_TX |\n\t\t   NETIF_F_HW_VLAN_CTAG_RX |\n\t\t   NETIF_F_HW_VLAN_CTAG_FILTER |\n\t\t   NETIF_F_SG |\n\t\t   NETIF_F_HW_CSUM |\n\t\t   NETIF_F_RXCSUM |\n\t\t   NETIF_F_TSO |\n\t\t   NETIF_F_TSO6 |\n\t\t   NETIF_F_TSO_ECN |\n\t\t   NETIF_F_GSO_GRE |\n\t\t   NETIF_F_GSO_GRE_CSUM |\n\t\t   NETIF_F_GSO_IPXIP4 |\n\t\t   NETIF_F_GSO_IPXIP6 |\n\t\t   NETIF_F_GSO_UDP_TUNNEL |\n\t\t   NETIF_F_GSO_UDP_TUNNEL_CSUM;\n\n\tif (lif->nxqs > 1)\n\t\tfeatures |= NETIF_F_RXHASH;\n\n\terr = ionic_set_nic_features(lif, features);\n\tif (err)\n\t\treturn err;\n\n\t \n\tnetdev->features |= NETIF_F_HIGHDMA;\n\n\tif (lif->hw_features & IONIC_ETH_HW_VLAN_TX_TAG)\n\t\tnetdev->hw_features |= NETIF_F_HW_VLAN_CTAG_TX;\n\tif (lif->hw_features & IONIC_ETH_HW_VLAN_RX_STRIP)\n\t\tnetdev->hw_features |= NETIF_F_HW_VLAN_CTAG_RX;\n\tif (lif->hw_features & IONIC_ETH_HW_VLAN_RX_FILTER)\n\t\tnetdev->hw_features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\tif (lif->hw_features & IONIC_ETH_HW_RX_HASH)\n\t\tnetdev->hw_features |= NETIF_F_RXHASH;\n\tif (lif->hw_features & IONIC_ETH_HW_TX_SG)\n\t\tnetdev->hw_features |= NETIF_F_SG;\n\n\tif (lif->hw_features & IONIC_ETH_HW_TX_CSUM)\n\t\tnetdev->hw_enc_features |= NETIF_F_HW_CSUM;\n\tif (lif->hw_features & IONIC_ETH_HW_RX_CSUM)\n\t\tnetdev->hw_enc_features |= NETIF_F_RXCSUM;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO)\n\t\tnetdev->hw_enc_features |= NETIF_F_TSO;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_IPV6)\n\t\tnetdev->hw_enc_features |= NETIF_F_TSO6;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_ECN)\n\t\tnetdev->hw_enc_features |= NETIF_F_TSO_ECN;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_GRE)\n\t\tnetdev->hw_enc_features |= NETIF_F_GSO_GRE;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_GRE_CSUM)\n\t\tnetdev->hw_enc_features |= NETIF_F_GSO_GRE_CSUM;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_IPXIP4)\n\t\tnetdev->hw_enc_features |= NETIF_F_GSO_IPXIP4;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_IPXIP6)\n\t\tnetdev->hw_enc_features |= NETIF_F_GSO_IPXIP6;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_UDP)\n\t\tnetdev->hw_enc_features |= NETIF_F_GSO_UDP_TUNNEL;\n\tif (lif->hw_features & IONIC_ETH_HW_TSO_UDP_CSUM)\n\t\tnetdev->hw_enc_features |= NETIF_F_GSO_UDP_TUNNEL_CSUM;\n\n\tnetdev->hw_features |= netdev->hw_enc_features;\n\tnetdev->features |= netdev->hw_features;\n\tnetdev->vlan_features |= netdev->features & ~NETIF_F_VLAN_FEATURES;\n\n\tnetdev->priv_flags |= IFF_UNICAST_FLT |\n\t\t\t      IFF_LIVE_ADDR_CHANGE;\n\n\treturn 0;\n}\n\nstatic int ionic_set_features(struct net_device *netdev,\n\t\t\t      netdev_features_t features)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tint err;\n\n\tnetdev_dbg(netdev, \"%s: lif->features=0x%08llx new_features=0x%08llx\\n\",\n\t\t   __func__, (u64)lif->netdev->features, (u64)features);\n\n\terr = ionic_set_nic_features(lif, features);\n\n\treturn err;\n}\n\nstatic int ionic_set_attr_mac(struct ionic_lif *lif, u8 *mac)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_setattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_SETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_MAC,\n\t\t},\n\t};\n\n\tether_addr_copy(ctx.cmd.lif_setattr.mac, mac);\n\treturn ionic_adminq_post_wait(lif, &ctx);\n}\n\nstatic int ionic_get_attr_mac(struct ionic_lif *lif, u8 *mac_addr)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_getattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_GETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_MAC,\n\t\t},\n\t};\n\tint err;\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\treturn err;\n\n\tether_addr_copy(mac_addr, ctx.comp.lif_getattr.mac);\n\treturn 0;\n}\n\nstatic int ionic_program_mac(struct ionic_lif *lif, u8 *mac)\n{\n\tu8  get_mac[ETH_ALEN];\n\tint err;\n\n\terr = ionic_set_attr_mac(lif, mac);\n\tif (err)\n\t\treturn err;\n\n\terr = ionic_get_attr_mac(lif, get_mac);\n\tif (err)\n\t\treturn err;\n\n\t \n\tif (!ether_addr_equal(get_mac, mac))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic int ionic_set_mac_address(struct net_device *netdev, void *sa)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct sockaddr *addr = sa;\n\tu8 *mac;\n\tint err;\n\n\tmac = (u8 *)addr->sa_data;\n\tif (ether_addr_equal(netdev->dev_addr, mac))\n\t\treturn 0;\n\n\terr = ionic_program_mac(lif, mac);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (err > 0)\n\t\tnetdev_dbg(netdev, \"%s: SET and GET ATTR Mac are not equal-due to old FW running\\n\",\n\t\t\t   __func__);\n\n\terr = eth_prepare_mac_addr_change(netdev, addr);\n\tif (err)\n\t\treturn err;\n\n\tif (!is_zero_ether_addr(netdev->dev_addr)) {\n\t\tnetdev_info(netdev, \"deleting mac addr %pM\\n\",\n\t\t\t    netdev->dev_addr);\n\t\tionic_lif_addr_del(netdev_priv(netdev), netdev->dev_addr);\n\t}\n\n\teth_commit_mac_addr_change(netdev, addr);\n\tnetdev_info(netdev, \"updating mac addr %pM\\n\", mac);\n\n\treturn ionic_lif_addr_add(netdev_priv(netdev), mac);\n}\n\nvoid ionic_stop_queues_reconfig(struct ionic_lif *lif)\n{\n\t \n\tnetif_device_detach(lif->netdev);\n\tionic_stop_queues(lif);\n\tionic_txrx_deinit(lif);\n}\n\nstatic int ionic_start_queues_reconfig(struct ionic_lif *lif)\n{\n\tint err;\n\n\t \n\n\t \n\terr = ionic_txrx_init(lif);\n\tionic_link_status_check_request(lif, CAN_NOT_SLEEP);\n\tnetif_device_attach(lif->netdev);\n\n\treturn err;\n}\n\nstatic int ionic_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_setattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_SETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_MTU,\n\t\t\t.mtu = cpu_to_le32(new_mtu),\n\t\t},\n\t};\n\tint err;\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\treturn err;\n\n\t \n\tif (!netif_running(netdev)) {\n\t\tnetdev->mtu = new_mtu;\n\t\treturn 0;\n\t}\n\n\tmutex_lock(&lif->queue_lock);\n\tionic_stop_queues_reconfig(lif);\n\tnetdev->mtu = new_mtu;\n\terr = ionic_start_queues_reconfig(lif);\n\tmutex_unlock(&lif->queue_lock);\n\n\treturn err;\n}\n\nstatic void ionic_tx_timeout_work(struct work_struct *ws)\n{\n\tstruct ionic_lif *lif = container_of(ws, struct ionic_lif, tx_timeout_work);\n\tint err;\n\n\tif (test_bit(IONIC_LIF_F_FW_RESET, lif->state))\n\t\treturn;\n\n\t \n\tif (!netif_running(lif->netdev))\n\t\treturn;\n\n\tmutex_lock(&lif->queue_lock);\n\tionic_stop_queues_reconfig(lif);\n\terr = ionic_start_queues_reconfig(lif);\n\tmutex_unlock(&lif->queue_lock);\n\n\tif (err)\n\t\tdev_err(lif->ionic->dev, \"%s: Restarting queues failed\\n\", __func__);\n}\n\nstatic void ionic_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\n\tnetdev_info(lif->netdev, \"Tx Timeout triggered - txq %d\\n\", txqueue);\n\tschedule_work(&lif->tx_timeout_work);\n}\n\nstatic int ionic_vlan_rx_add_vid(struct net_device *netdev, __be16 proto,\n\t\t\t\t u16 vid)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tint err;\n\n\terr = ionic_lif_vlan_add(lif, vid);\n\tif (err)\n\t\treturn err;\n\n\tionic_lif_rx_mode(lif);\n\n\treturn 0;\n}\n\nstatic int ionic_vlan_rx_kill_vid(struct net_device *netdev, __be16 proto,\n\t\t\t\t  u16 vid)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tint err;\n\n\terr = ionic_lif_vlan_del(lif, vid);\n\tif (err)\n\t\treturn err;\n\n\tionic_lif_rx_mode(lif);\n\n\treturn 0;\n}\n\nint ionic_lif_rss_config(struct ionic_lif *lif, const u16 types,\n\t\t\t const u8 *key, const u32 *indir)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_setattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_SETATTR,\n\t\t\t.attr = IONIC_LIF_ATTR_RSS,\n\t\t\t.rss.addr = cpu_to_le64(lif->rss_ind_tbl_pa),\n\t\t},\n\t};\n\tunsigned int i, tbl_sz;\n\n\tif (lif->hw_features & IONIC_ETH_HW_RX_HASH) {\n\t\tlif->rss_types = types;\n\t\tctx.cmd.lif_setattr.rss.types = cpu_to_le16(types);\n\t}\n\n\tif (key)\n\t\tmemcpy(lif->rss_hash_key, key, IONIC_RSS_HASH_KEY_SIZE);\n\n\tif (indir) {\n\t\ttbl_sz = le16_to_cpu(lif->ionic->ident.lif.eth.rss_ind_tbl_sz);\n\t\tfor (i = 0; i < tbl_sz; i++)\n\t\t\tlif->rss_ind_tbl[i] = indir[i];\n\t}\n\n\tmemcpy(ctx.cmd.lif_setattr.rss.key, lif->rss_hash_key,\n\t       IONIC_RSS_HASH_KEY_SIZE);\n\n\treturn ionic_adminq_post_wait(lif, &ctx);\n}\n\nstatic int ionic_lif_rss_init(struct ionic_lif *lif)\n{\n\tunsigned int tbl_sz;\n\tunsigned int i;\n\n\tlif->rss_types = IONIC_RSS_TYPE_IPV4     |\n\t\t\t IONIC_RSS_TYPE_IPV4_TCP |\n\t\t\t IONIC_RSS_TYPE_IPV4_UDP |\n\t\t\t IONIC_RSS_TYPE_IPV6     |\n\t\t\t IONIC_RSS_TYPE_IPV6_TCP |\n\t\t\t IONIC_RSS_TYPE_IPV6_UDP;\n\n\t \n\ttbl_sz = le16_to_cpu(lif->ionic->ident.lif.eth.rss_ind_tbl_sz);\n\tfor (i = 0; i < tbl_sz; i++)\n\t\tlif->rss_ind_tbl[i] = ethtool_rxfh_indir_default(i, lif->nxqs);\n\n\treturn ionic_lif_rss_config(lif, lif->rss_types, NULL, NULL);\n}\n\nstatic void ionic_lif_rss_deinit(struct ionic_lif *lif)\n{\n\tint tbl_sz;\n\n\ttbl_sz = le16_to_cpu(lif->ionic->ident.lif.eth.rss_ind_tbl_sz);\n\tmemset(lif->rss_ind_tbl, 0, tbl_sz);\n\tmemset(lif->rss_hash_key, 0, IONIC_RSS_HASH_KEY_SIZE);\n\n\tionic_lif_rss_config(lif, 0x0, NULL, NULL);\n}\n\nstatic void ionic_lif_quiesce(struct ionic_lif *lif)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_setattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_SETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_STATE,\n\t\t\t.state = IONIC_LIF_QUIESCE,\n\t\t},\n\t};\n\tint err;\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\tnetdev_dbg(lif->netdev, \"lif quiesce failed %d\\n\", err);\n}\n\nstatic void ionic_txrx_disable(struct ionic_lif *lif)\n{\n\tunsigned int i;\n\tint err = 0;\n\n\tif (lif->txqcqs) {\n\t\tfor (i = 0; i < lif->nxqs; i++)\n\t\t\terr = ionic_qcq_disable(lif, lif->txqcqs[i], err);\n\t}\n\n\tif (lif->hwstamp_txq)\n\t\terr = ionic_qcq_disable(lif, lif->hwstamp_txq, err);\n\n\tif (lif->rxqcqs) {\n\t\tfor (i = 0; i < lif->nxqs; i++)\n\t\t\terr = ionic_qcq_disable(lif, lif->rxqcqs[i], err);\n\t}\n\n\tif (lif->hwstamp_rxq)\n\t\terr = ionic_qcq_disable(lif, lif->hwstamp_rxq, err);\n\n\tionic_lif_quiesce(lif);\n}\n\nstatic void ionic_txrx_deinit(struct ionic_lif *lif)\n{\n\tunsigned int i;\n\n\tif (lif->txqcqs) {\n\t\tfor (i = 0; i < lif->nxqs && lif->txqcqs[i]; i++) {\n\t\t\tionic_lif_qcq_deinit(lif, lif->txqcqs[i]);\n\t\t\tionic_tx_flush(&lif->txqcqs[i]->cq);\n\t\t\tionic_tx_empty(&lif->txqcqs[i]->q);\n\t\t}\n\t}\n\n\tif (lif->rxqcqs) {\n\t\tfor (i = 0; i < lif->nxqs && lif->rxqcqs[i]; i++) {\n\t\t\tionic_lif_qcq_deinit(lif, lif->rxqcqs[i]);\n\t\t\tionic_rx_empty(&lif->rxqcqs[i]->q);\n\t\t}\n\t}\n\tlif->rx_mode = 0;\n\n\tif (lif->hwstamp_txq) {\n\t\tionic_lif_qcq_deinit(lif, lif->hwstamp_txq);\n\t\tionic_tx_flush(&lif->hwstamp_txq->cq);\n\t\tionic_tx_empty(&lif->hwstamp_txq->q);\n\t}\n\n\tif (lif->hwstamp_rxq) {\n\t\tionic_lif_qcq_deinit(lif, lif->hwstamp_rxq);\n\t\tionic_rx_empty(&lif->hwstamp_rxq->q);\n\t}\n}\n\nvoid ionic_txrx_free(struct ionic_lif *lif)\n{\n\tunsigned int i;\n\n\tif (lif->txqcqs) {\n\t\tfor (i = 0; i < lif->ionic->ntxqs_per_lif && lif->txqcqs[i]; i++) {\n\t\t\tionic_qcq_free(lif, lif->txqcqs[i]);\n\t\t\tdevm_kfree(lif->ionic->dev, lif->txqcqs[i]);\n\t\t\tlif->txqcqs[i] = NULL;\n\t\t}\n\t}\n\n\tif (lif->rxqcqs) {\n\t\tfor (i = 0; i < lif->ionic->nrxqs_per_lif && lif->rxqcqs[i]; i++) {\n\t\t\tionic_qcq_free(lif, lif->rxqcqs[i]);\n\t\t\tdevm_kfree(lif->ionic->dev, lif->rxqcqs[i]);\n\t\t\tlif->rxqcqs[i] = NULL;\n\t\t}\n\t}\n\n\tif (lif->hwstamp_txq) {\n\t\tionic_qcq_free(lif, lif->hwstamp_txq);\n\t\tdevm_kfree(lif->ionic->dev, lif->hwstamp_txq);\n\t\tlif->hwstamp_txq = NULL;\n\t}\n\n\tif (lif->hwstamp_rxq) {\n\t\tionic_qcq_free(lif, lif->hwstamp_rxq);\n\t\tdevm_kfree(lif->ionic->dev, lif->hwstamp_rxq);\n\t\tlif->hwstamp_rxq = NULL;\n\t}\n}\n\nstatic int ionic_txrx_alloc(struct ionic_lif *lif)\n{\n\tunsigned int comp_sz, desc_sz, num_desc, sg_desc_sz;\n\tunsigned int flags, i;\n\tint err = 0;\n\n\tnum_desc = lif->ntxq_descs;\n\tdesc_sz = sizeof(struct ionic_txq_desc);\n\tcomp_sz = sizeof(struct ionic_txq_comp);\n\n\tif (lif->qtype_info[IONIC_QTYPE_TXQ].version >= 1 &&\n\t    lif->qtype_info[IONIC_QTYPE_TXQ].sg_desc_sz ==\n\t\t\t\t\t  sizeof(struct ionic_txq_sg_desc_v1))\n\t\tsg_desc_sz = sizeof(struct ionic_txq_sg_desc_v1);\n\telse\n\t\tsg_desc_sz = sizeof(struct ionic_txq_sg_desc);\n\n\tflags = IONIC_QCQ_F_TX_STATS | IONIC_QCQ_F_SG;\n\n\tif (test_bit(IONIC_LIF_F_CMB_TX_RINGS, lif->state))\n\t\tflags |= IONIC_QCQ_F_CMB_RINGS;\n\n\tif (test_bit(IONIC_LIF_F_SPLIT_INTR, lif->state))\n\t\tflags |= IONIC_QCQ_F_INTR;\n\n\tfor (i = 0; i < lif->nxqs; i++) {\n\t\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_TXQ, i, \"tx\", flags,\n\t\t\t\t      num_desc, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t\t      lif->kern_pid, &lif->txqcqs[i]);\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\tif (flags & IONIC_QCQ_F_INTR) {\n\t\t\tionic_intr_coal_init(lif->ionic->idev.intr_ctrl,\n\t\t\t\t\t     lif->txqcqs[i]->intr.index,\n\t\t\t\t\t     lif->tx_coalesce_hw);\n\t\t\tif (test_bit(IONIC_LIF_F_TX_DIM_INTR, lif->state))\n\t\t\t\tlif->txqcqs[i]->intr.dim_coal_hw = lif->tx_coalesce_hw;\n\t\t}\n\n\t\tionic_debugfs_add_qcq(lif, lif->txqcqs[i]);\n\t}\n\n\tflags = IONIC_QCQ_F_RX_STATS | IONIC_QCQ_F_SG | IONIC_QCQ_F_INTR;\n\n\tif (test_bit(IONIC_LIF_F_CMB_RX_RINGS, lif->state))\n\t\tflags |= IONIC_QCQ_F_CMB_RINGS;\n\n\tnum_desc = lif->nrxq_descs;\n\tdesc_sz = sizeof(struct ionic_rxq_desc);\n\tcomp_sz = sizeof(struct ionic_rxq_comp);\n\tsg_desc_sz = sizeof(struct ionic_rxq_sg_desc);\n\n\tif (lif->rxq_features & IONIC_Q_F_2X_CQ_DESC)\n\t\tcomp_sz *= 2;\n\n\tfor (i = 0; i < lif->nxqs; i++) {\n\t\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_RXQ, i, \"rx\", flags,\n\t\t\t\t      num_desc, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t\t      lif->kern_pid, &lif->rxqcqs[i]);\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\tlif->rxqcqs[i]->q.features = lif->rxq_features;\n\n\t\tionic_intr_coal_init(lif->ionic->idev.intr_ctrl,\n\t\t\t\t     lif->rxqcqs[i]->intr.index,\n\t\t\t\t     lif->rx_coalesce_hw);\n\t\tif (test_bit(IONIC_LIF_F_RX_DIM_INTR, lif->state))\n\t\t\tlif->rxqcqs[i]->intr.dim_coal_hw = lif->rx_coalesce_hw;\n\n\t\tif (!test_bit(IONIC_LIF_F_SPLIT_INTR, lif->state))\n\t\t\tionic_link_qcq_interrupts(lif->rxqcqs[i],\n\t\t\t\t\t\t  lif->txqcqs[i]);\n\n\t\tionic_debugfs_add_qcq(lif, lif->rxqcqs[i]);\n\t}\n\n\treturn 0;\n\nerr_out:\n\tionic_txrx_free(lif);\n\n\treturn err;\n}\n\nstatic int ionic_txrx_init(struct ionic_lif *lif)\n{\n\tunsigned int i;\n\tint err;\n\n\tfor (i = 0; i < lif->nxqs; i++) {\n\t\terr = ionic_lif_txq_init(lif, lif->txqcqs[i]);\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\terr = ionic_lif_rxq_init(lif, lif->rxqcqs[i]);\n\t\tif (err) {\n\t\t\tionic_lif_qcq_deinit(lif, lif->txqcqs[i]);\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tif (lif->netdev->features & NETIF_F_RXHASH)\n\t\tionic_lif_rss_init(lif);\n\n\tionic_lif_rx_mode(lif);\n\n\treturn 0;\n\nerr_out:\n\twhile (i--) {\n\t\tionic_lif_qcq_deinit(lif, lif->txqcqs[i]);\n\t\tionic_lif_qcq_deinit(lif, lif->rxqcqs[i]);\n\t}\n\n\treturn err;\n}\n\nstatic int ionic_txrx_enable(struct ionic_lif *lif)\n{\n\tint derr = 0;\n\tint i, err;\n\n\tfor (i = 0; i < lif->nxqs; i++) {\n\t\tif (!(lif->rxqcqs[i] && lif->txqcqs[i])) {\n\t\t\tdev_err(lif->ionic->dev, \"%s: bad qcq %d\\n\", __func__, i);\n\t\t\terr = -ENXIO;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tionic_rx_fill(&lif->rxqcqs[i]->q);\n\t\terr = ionic_qcq_enable(lif->rxqcqs[i]);\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\terr = ionic_qcq_enable(lif->txqcqs[i]);\n\t\tif (err) {\n\t\t\tderr = ionic_qcq_disable(lif, lif->rxqcqs[i], err);\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tif (lif->hwstamp_rxq) {\n\t\tionic_rx_fill(&lif->hwstamp_rxq->q);\n\t\terr = ionic_qcq_enable(lif->hwstamp_rxq);\n\t\tif (err)\n\t\t\tgoto err_out_hwstamp_rx;\n\t}\n\n\tif (lif->hwstamp_txq) {\n\t\terr = ionic_qcq_enable(lif->hwstamp_txq);\n\t\tif (err)\n\t\t\tgoto err_out_hwstamp_tx;\n\t}\n\n\treturn 0;\n\nerr_out_hwstamp_tx:\n\tif (lif->hwstamp_rxq)\n\t\tderr = ionic_qcq_disable(lif, lif->hwstamp_rxq, derr);\nerr_out_hwstamp_rx:\n\ti = lif->nxqs;\nerr_out:\n\twhile (i--) {\n\t\tderr = ionic_qcq_disable(lif, lif->txqcqs[i], derr);\n\t\tderr = ionic_qcq_disable(lif, lif->rxqcqs[i], derr);\n\t}\n\n\treturn err;\n}\n\nstatic int ionic_start_queues(struct ionic_lif *lif)\n{\n\tint err;\n\n\tif (test_bit(IONIC_LIF_F_BROKEN, lif->state))\n\t\treturn -EIO;\n\n\tif (test_bit(IONIC_LIF_F_FW_RESET, lif->state))\n\t\treturn -EBUSY;\n\n\tif (test_and_set_bit(IONIC_LIF_F_UP, lif->state))\n\t\treturn 0;\n\n\terr = ionic_txrx_enable(lif);\n\tif (err) {\n\t\tclear_bit(IONIC_LIF_F_UP, lif->state);\n\t\treturn err;\n\t}\n\tnetif_tx_wake_all_queues(lif->netdev);\n\n\treturn 0;\n}\n\nstatic int ionic_open(struct net_device *netdev)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tint err;\n\n\t \n\tif (test_and_clear_bit(IONIC_LIF_F_BROKEN, lif->state))\n\t\tnetdev_info(netdev, \"clearing broken state\\n\");\n\n\tmutex_lock(&lif->queue_lock);\n\n\terr = ionic_txrx_alloc(lif);\n\tif (err)\n\t\tgoto err_unlock;\n\n\terr = ionic_txrx_init(lif);\n\tif (err)\n\t\tgoto err_txrx_free;\n\n\terr = netif_set_real_num_tx_queues(netdev, lif->nxqs);\n\tif (err)\n\t\tgoto err_txrx_deinit;\n\n\terr = netif_set_real_num_rx_queues(netdev, lif->nxqs);\n\tif (err)\n\t\tgoto err_txrx_deinit;\n\n\t \n\tif (netif_carrier_ok(netdev)) {\n\t\terr = ionic_start_queues(lif);\n\t\tif (err)\n\t\t\tgoto err_txrx_deinit;\n\t}\n\n\t \n\tionic_lif_hwstamp_recreate_queues(lif);\n\n\tmutex_unlock(&lif->queue_lock);\n\n\treturn 0;\n\nerr_txrx_deinit:\n\tionic_txrx_deinit(lif);\nerr_txrx_free:\n\tionic_txrx_free(lif);\nerr_unlock:\n\tmutex_unlock(&lif->queue_lock);\n\treturn err;\n}\n\nstatic void ionic_stop_queues(struct ionic_lif *lif)\n{\n\tif (!test_and_clear_bit(IONIC_LIF_F_UP, lif->state))\n\t\treturn;\n\n\tnetif_tx_disable(lif->netdev);\n\tionic_txrx_disable(lif);\n}\n\nstatic int ionic_stop(struct net_device *netdev)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\n\tif (test_bit(IONIC_LIF_F_FW_RESET, lif->state))\n\t\treturn 0;\n\n\tmutex_lock(&lif->queue_lock);\n\tionic_stop_queues(lif);\n\tionic_txrx_deinit(lif);\n\tionic_txrx_free(lif);\n\tmutex_unlock(&lif->queue_lock);\n\n\treturn 0;\n}\n\nstatic int ionic_eth_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\n\tswitch (cmd) {\n\tcase SIOCSHWTSTAMP:\n\t\treturn ionic_lif_hwstamp_set(lif, ifr);\n\tcase SIOCGHWTSTAMP:\n\t\treturn ionic_lif_hwstamp_get(lif, ifr);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int ionic_get_fw_vf_config(struct ionic *ionic, int vf, struct ionic_vf *vfdata)\n{\n\tstruct ionic_vf_getattr_comp comp = { 0 };\n\tint err;\n\tu8 attr;\n\n\tattr = IONIC_VF_ATTR_VLAN;\n\terr = ionic_dev_cmd_vf_getattr(ionic, vf, attr, &comp);\n\tif (err && comp.status != IONIC_RC_ENOSUPP)\n\t\tgoto err_out;\n\tif (!err)\n\t\tvfdata->vlanid = comp.vlanid;\n\n\tattr = IONIC_VF_ATTR_SPOOFCHK;\n\terr = ionic_dev_cmd_vf_getattr(ionic, vf, attr, &comp);\n\tif (err && comp.status != IONIC_RC_ENOSUPP)\n\t\tgoto err_out;\n\tif (!err)\n\t\tvfdata->spoofchk = comp.spoofchk;\n\n\tattr = IONIC_VF_ATTR_LINKSTATE;\n\terr = ionic_dev_cmd_vf_getattr(ionic, vf, attr, &comp);\n\tif (err && comp.status != IONIC_RC_ENOSUPP)\n\t\tgoto err_out;\n\tif (!err) {\n\t\tswitch (comp.linkstate) {\n\t\tcase IONIC_VF_LINK_STATUS_UP:\n\t\t\tvfdata->linkstate = IFLA_VF_LINK_STATE_ENABLE;\n\t\t\tbreak;\n\t\tcase IONIC_VF_LINK_STATUS_DOWN:\n\t\t\tvfdata->linkstate = IFLA_VF_LINK_STATE_DISABLE;\n\t\t\tbreak;\n\t\tcase IONIC_VF_LINK_STATUS_AUTO:\n\t\t\tvfdata->linkstate = IFLA_VF_LINK_STATE_AUTO;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_warn(ionic->dev, \"Unexpected link state %u\\n\", comp.linkstate);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tattr = IONIC_VF_ATTR_RATE;\n\terr = ionic_dev_cmd_vf_getattr(ionic, vf, attr, &comp);\n\tif (err && comp.status != IONIC_RC_ENOSUPP)\n\t\tgoto err_out;\n\tif (!err)\n\t\tvfdata->maxrate = comp.maxrate;\n\n\tattr = IONIC_VF_ATTR_TRUST;\n\terr = ionic_dev_cmd_vf_getattr(ionic, vf, attr, &comp);\n\tif (err && comp.status != IONIC_RC_ENOSUPP)\n\t\tgoto err_out;\n\tif (!err)\n\t\tvfdata->trusted = comp.trust;\n\n\tattr = IONIC_VF_ATTR_MAC;\n\terr = ionic_dev_cmd_vf_getattr(ionic, vf, attr, &comp);\n\tif (err && comp.status != IONIC_RC_ENOSUPP)\n\t\tgoto err_out;\n\tif (!err)\n\t\tether_addr_copy(vfdata->macaddr, comp.macaddr);\n\nerr_out:\n\tif (err)\n\t\tdev_err(ionic->dev, \"Failed to get %s for VF %d\\n\",\n\t\t\tionic_vf_attr_to_str(attr), vf);\n\n\treturn err;\n}\n\nstatic int ionic_get_vf_config(struct net_device *netdev,\n\t\t\t       int vf, struct ifla_vf_info *ivf)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tstruct ionic_vf vfdata = { 0 };\n\tint ret = 0;\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_read(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tivf->vf = vf;\n\t\tivf->qos = 0;\n\n\t\tret = ionic_get_fw_vf_config(ionic, vf, &vfdata);\n\t\tif (!ret) {\n\t\t\tivf->vlan         = le16_to_cpu(vfdata.vlanid);\n\t\t\tivf->spoofchk     = vfdata.spoofchk;\n\t\t\tivf->linkstate    = vfdata.linkstate;\n\t\t\tivf->max_tx_rate  = le32_to_cpu(vfdata.maxrate);\n\t\t\tivf->trusted      = vfdata.trusted;\n\t\t\tether_addr_copy(ivf->mac, vfdata.macaddr);\n\t\t}\n\t}\n\n\tup_read(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic int ionic_get_vf_stats(struct net_device *netdev, int vf,\n\t\t\t      struct ifla_vf_stats *vf_stats)\n{\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tstruct ionic_lif_stats *vs;\n\tint ret = 0;\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_read(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tmemset(vf_stats, 0, sizeof(*vf_stats));\n\t\tvs = &ionic->vfs[vf].stats;\n\n\t\tvf_stats->rx_packets = le64_to_cpu(vs->rx_ucast_packets);\n\t\tvf_stats->tx_packets = le64_to_cpu(vs->tx_ucast_packets);\n\t\tvf_stats->rx_bytes   = le64_to_cpu(vs->rx_ucast_bytes);\n\t\tvf_stats->tx_bytes   = le64_to_cpu(vs->tx_ucast_bytes);\n\t\tvf_stats->broadcast  = le64_to_cpu(vs->rx_bcast_packets);\n\t\tvf_stats->multicast  = le64_to_cpu(vs->rx_mcast_packets);\n\t\tvf_stats->rx_dropped = le64_to_cpu(vs->rx_ucast_drop_packets) +\n\t\t\t\t       le64_to_cpu(vs->rx_mcast_drop_packets) +\n\t\t\t\t       le64_to_cpu(vs->rx_bcast_drop_packets);\n\t\tvf_stats->tx_dropped = le64_to_cpu(vs->tx_ucast_drop_packets) +\n\t\t\t\t       le64_to_cpu(vs->tx_mcast_drop_packets) +\n\t\t\t\t       le64_to_cpu(vs->tx_bcast_drop_packets);\n\t}\n\n\tup_read(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic int ionic_set_vf_mac(struct net_device *netdev, int vf, u8 *mac)\n{\n\tstruct ionic_vf_setattr_cmd vfc = { .attr = IONIC_VF_ATTR_MAC };\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tint ret;\n\n\tif (!(is_zero_ether_addr(mac) || is_valid_ether_addr(mac)))\n\t\treturn -EINVAL;\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_write(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tether_addr_copy(vfc.macaddr, mac);\n\t\tdev_dbg(ionic->dev, \"%s: vf %d macaddr %pM\\n\",\n\t\t\t__func__, vf, vfc.macaddr);\n\n\t\tret = ionic_set_vf_config(ionic, vf, &vfc);\n\t\tif (!ret)\n\t\t\tether_addr_copy(ionic->vfs[vf].macaddr, mac);\n\t}\n\n\tup_write(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic int ionic_set_vf_vlan(struct net_device *netdev, int vf, u16 vlan,\n\t\t\t     u8 qos, __be16 proto)\n{\n\tstruct ionic_vf_setattr_cmd vfc = { .attr = IONIC_VF_ATTR_VLAN };\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tint ret;\n\n\t \n\tif (qos)\n\t\treturn -EINVAL;\n\n\tif (vlan > 4095)\n\t\treturn -EINVAL;\n\n\tif (proto != htons(ETH_P_8021Q))\n\t\treturn -EPROTONOSUPPORT;\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_write(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tvfc.vlanid = cpu_to_le16(vlan);\n\t\tdev_dbg(ionic->dev, \"%s: vf %d vlan %d\\n\",\n\t\t\t__func__, vf, le16_to_cpu(vfc.vlanid));\n\n\t\tret = ionic_set_vf_config(ionic, vf, &vfc);\n\t\tif (!ret)\n\t\t\tionic->vfs[vf].vlanid = cpu_to_le16(vlan);\n\t}\n\n\tup_write(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic int ionic_set_vf_rate(struct net_device *netdev, int vf,\n\t\t\t     int tx_min, int tx_max)\n{\n\tstruct ionic_vf_setattr_cmd vfc = { .attr = IONIC_VF_ATTR_RATE };\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tint ret;\n\n\t \n\tif (tx_min)\n\t\treturn -EINVAL;\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_write(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tvfc.maxrate = cpu_to_le32(tx_max);\n\t\tdev_dbg(ionic->dev, \"%s: vf %d maxrate %d\\n\",\n\t\t\t__func__, vf, le32_to_cpu(vfc.maxrate));\n\n\t\tret = ionic_set_vf_config(ionic, vf, &vfc);\n\t\tif (!ret)\n\t\t\tionic->vfs[vf].maxrate = cpu_to_le32(tx_max);\n\t}\n\n\tup_write(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic int ionic_set_vf_spoofchk(struct net_device *netdev, int vf, bool set)\n{\n\tstruct ionic_vf_setattr_cmd vfc = { .attr = IONIC_VF_ATTR_SPOOFCHK };\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tint ret;\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_write(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tvfc.spoofchk = set;\n\t\tdev_dbg(ionic->dev, \"%s: vf %d spoof %d\\n\",\n\t\t\t__func__, vf, vfc.spoofchk);\n\n\t\tret = ionic_set_vf_config(ionic, vf, &vfc);\n\t\tif (!ret)\n\t\t\tionic->vfs[vf].spoofchk = set;\n\t}\n\n\tup_write(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic int ionic_set_vf_trust(struct net_device *netdev, int vf, bool set)\n{\n\tstruct ionic_vf_setattr_cmd vfc = { .attr = IONIC_VF_ATTR_TRUST };\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tint ret;\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_write(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tvfc.trust = set;\n\t\tdev_dbg(ionic->dev, \"%s: vf %d trust %d\\n\",\n\t\t\t__func__, vf, vfc.trust);\n\n\t\tret = ionic_set_vf_config(ionic, vf, &vfc);\n\t\tif (!ret)\n\t\t\tionic->vfs[vf].trusted = set;\n\t}\n\n\tup_write(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic int ionic_set_vf_link_state(struct net_device *netdev, int vf, int set)\n{\n\tstruct ionic_vf_setattr_cmd vfc = { .attr = IONIC_VF_ATTR_LINKSTATE };\n\tstruct ionic_lif *lif = netdev_priv(netdev);\n\tstruct ionic *ionic = lif->ionic;\n\tu8 vfls;\n\tint ret;\n\n\tswitch (set) {\n\tcase IFLA_VF_LINK_STATE_ENABLE:\n\t\tvfls = IONIC_VF_LINK_STATUS_UP;\n\t\tbreak;\n\tcase IFLA_VF_LINK_STATE_DISABLE:\n\t\tvfls = IONIC_VF_LINK_STATUS_DOWN;\n\t\tbreak;\n\tcase IFLA_VF_LINK_STATE_AUTO:\n\t\tvfls = IONIC_VF_LINK_STATUS_AUTO;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (!netif_device_present(netdev))\n\t\treturn -EBUSY;\n\n\tdown_write(&ionic->vf_op_lock);\n\n\tif (vf >= pci_num_vf(ionic->pdev) || !ionic->vfs) {\n\t\tret = -EINVAL;\n\t} else {\n\t\tvfc.linkstate = vfls;\n\t\tdev_dbg(ionic->dev, \"%s: vf %d linkstate %d\\n\",\n\t\t\t__func__, vf, vfc.linkstate);\n\n\t\tret = ionic_set_vf_config(ionic, vf, &vfc);\n\t\tif (!ret)\n\t\t\tionic->vfs[vf].linkstate = set;\n\t}\n\n\tup_write(&ionic->vf_op_lock);\n\treturn ret;\n}\n\nstatic void ionic_vf_attr_replay(struct ionic_lif *lif)\n{\n\tstruct ionic_vf_setattr_cmd vfc = { };\n\tstruct ionic *ionic = lif->ionic;\n\tstruct ionic_vf *v;\n\tint i;\n\n\tif (!ionic->vfs)\n\t\treturn;\n\n\tdown_read(&ionic->vf_op_lock);\n\n\tfor (i = 0; i < ionic->num_vfs; i++) {\n\t\tv = &ionic->vfs[i];\n\n\t\tif (v->stats_pa) {\n\t\t\tvfc.attr = IONIC_VF_ATTR_STATSADDR;\n\t\t\tvfc.stats_pa = cpu_to_le64(v->stats_pa);\n\t\t\tionic_set_vf_config(ionic, i, &vfc);\n\t\t\tvfc.stats_pa = 0;\n\t\t}\n\n\t\tif (!is_zero_ether_addr(v->macaddr)) {\n\t\t\tvfc.attr = IONIC_VF_ATTR_MAC;\n\t\t\tether_addr_copy(vfc.macaddr, v->macaddr);\n\t\t\tionic_set_vf_config(ionic, i, &vfc);\n\t\t\teth_zero_addr(vfc.macaddr);\n\t\t}\n\n\t\tif (v->vlanid) {\n\t\t\tvfc.attr = IONIC_VF_ATTR_VLAN;\n\t\t\tvfc.vlanid = v->vlanid;\n\t\t\tionic_set_vf_config(ionic, i, &vfc);\n\t\t\tvfc.vlanid = 0;\n\t\t}\n\n\t\tif (v->maxrate) {\n\t\t\tvfc.attr = IONIC_VF_ATTR_RATE;\n\t\t\tvfc.maxrate = v->maxrate;\n\t\t\tionic_set_vf_config(ionic, i, &vfc);\n\t\t\tvfc.maxrate = 0;\n\t\t}\n\n\t\tif (v->spoofchk) {\n\t\t\tvfc.attr = IONIC_VF_ATTR_SPOOFCHK;\n\t\t\tvfc.spoofchk = v->spoofchk;\n\t\t\tionic_set_vf_config(ionic, i, &vfc);\n\t\t\tvfc.spoofchk = 0;\n\t\t}\n\n\t\tif (v->trusted) {\n\t\t\tvfc.attr = IONIC_VF_ATTR_TRUST;\n\t\t\tvfc.trust = v->trusted;\n\t\t\tionic_set_vf_config(ionic, i, &vfc);\n\t\t\tvfc.trust = 0;\n\t\t}\n\n\t\tif (v->linkstate) {\n\t\t\tvfc.attr = IONIC_VF_ATTR_LINKSTATE;\n\t\t\tvfc.linkstate = v->linkstate;\n\t\t\tionic_set_vf_config(ionic, i, &vfc);\n\t\t\tvfc.linkstate = 0;\n\t\t}\n\t}\n\n\tup_read(&ionic->vf_op_lock);\n\n\tionic_vf_start(ionic);\n}\n\nstatic const struct net_device_ops ionic_netdev_ops = {\n\t.ndo_open               = ionic_open,\n\t.ndo_stop               = ionic_stop,\n\t.ndo_eth_ioctl\t\t= ionic_eth_ioctl,\n\t.ndo_start_xmit\t\t= ionic_start_xmit,\n\t.ndo_get_stats64\t= ionic_get_stats64,\n\t.ndo_set_rx_mode\t= ionic_ndo_set_rx_mode,\n\t.ndo_set_features\t= ionic_set_features,\n\t.ndo_set_mac_address\t= ionic_set_mac_address,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_tx_timeout         = ionic_tx_timeout,\n\t.ndo_change_mtu         = ionic_change_mtu,\n\t.ndo_vlan_rx_add_vid    = ionic_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid   = ionic_vlan_rx_kill_vid,\n\t.ndo_set_vf_vlan\t= ionic_set_vf_vlan,\n\t.ndo_set_vf_trust\t= ionic_set_vf_trust,\n\t.ndo_set_vf_mac\t\t= ionic_set_vf_mac,\n\t.ndo_set_vf_rate\t= ionic_set_vf_rate,\n\t.ndo_set_vf_spoofchk\t= ionic_set_vf_spoofchk,\n\t.ndo_get_vf_config\t= ionic_get_vf_config,\n\t.ndo_set_vf_link_state\t= ionic_set_vf_link_state,\n\t.ndo_get_vf_stats       = ionic_get_vf_stats,\n};\n\nstatic int ionic_cmb_reconfig(struct ionic_lif *lif,\n\t\t\t      struct ionic_queue_params *qparam)\n{\n\tstruct ionic_queue_params start_qparams;\n\tint err = 0;\n\n\t \n\n\t \n\tionic_init_queue_params(lif, &start_qparams);\n\n\t \n\tionic_stop_queues_reconfig(lif);\n\tionic_txrx_free(lif);\n\n\t \n\tionic_set_queue_params(lif, qparam);\n\n\tif (netif_running(lif->netdev)) {\n\t\t \n\t\terr = ionic_txrx_alloc(lif);\n\t\tif (err) {\n\t\t\tdev_warn(lif->ionic->dev,\n\t\t\t\t \"CMB reconfig failed, restoring values: %d\\n\", err);\n\n\t\t\t \n\t\t\tionic_set_queue_params(lif, &start_qparams);\n\t\t\terr = ionic_txrx_alloc(lif);\n\t\t\tif (err) {\n\t\t\t\tdev_err(lif->ionic->dev,\n\t\t\t\t\t\"CMB restore failed: %d\\n\", err);\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t}\n\n\t\terr = ionic_start_queues_reconfig(lif);\n\t\tif (err) {\n\t\t\tdev_err(lif->ionic->dev,\n\t\t\t\t\"CMB reconfig failed: %d\\n\", err);\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\nerr_out:\n\t \n\tnetif_device_attach(lif->netdev);\n\n\treturn err;\n}\n\nstatic void ionic_swap_queues(struct ionic_qcq *a, struct ionic_qcq *b)\n{\n\t \n\tswap(a->q.features,   b->q.features);\n\tswap(a->q.num_descs,  b->q.num_descs);\n\tswap(a->q.desc_size,  b->q.desc_size);\n\tswap(a->q.base,       b->q.base);\n\tswap(a->q.base_pa,    b->q.base_pa);\n\tswap(a->q.info,       b->q.info);\n\tswap(a->q_base,       b->q_base);\n\tswap(a->q_base_pa,    b->q_base_pa);\n\tswap(a->q_size,       b->q_size);\n\n\tswap(a->q.sg_desc_size, b->q.sg_desc_size);\n\tswap(a->q.sg_base,    b->q.sg_base);\n\tswap(a->q.sg_base_pa, b->q.sg_base_pa);\n\tswap(a->sg_base,      b->sg_base);\n\tswap(a->sg_base_pa,   b->sg_base_pa);\n\tswap(a->sg_size,      b->sg_size);\n\n\tswap(a->cq.num_descs, b->cq.num_descs);\n\tswap(a->cq.desc_size, b->cq.desc_size);\n\tswap(a->cq.base,      b->cq.base);\n\tswap(a->cq.base_pa,   b->cq.base_pa);\n\tswap(a->cq.info,      b->cq.info);\n\tswap(a->cq_base,      b->cq_base);\n\tswap(a->cq_base_pa,   b->cq_base_pa);\n\tswap(a->cq_size,      b->cq_size);\n\n\tionic_debugfs_del_qcq(a);\n\tionic_debugfs_add_qcq(a->q.lif, a);\n}\n\nint ionic_reconfigure_queues(struct ionic_lif *lif,\n\t\t\t     struct ionic_queue_params *qparam)\n{\n\tunsigned int comp_sz, desc_sz, num_desc, sg_desc_sz;\n\tstruct ionic_qcq **tx_qcqs = NULL;\n\tstruct ionic_qcq **rx_qcqs = NULL;\n\tunsigned int flags, i;\n\tint err = 0;\n\n\t \n\tif ((test_bit(IONIC_LIF_F_CMB_TX_RINGS, lif->state) && qparam->cmb_tx) ||\n\t    (test_bit(IONIC_LIF_F_CMB_RX_RINGS, lif->state) && qparam->cmb_rx))\n\t\treturn ionic_cmb_reconfig(lif, qparam);\n\n\t \n\tif (qparam->nxqs != lif->nxqs || qparam->ntxq_descs != lif->ntxq_descs) {\n\t\ttx_qcqs = devm_kcalloc(lif->ionic->dev, lif->ionic->ntxqs_per_lif,\n\t\t\t\t       sizeof(struct ionic_qcq *), GFP_KERNEL);\n\t\tif (!tx_qcqs) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\tif (qparam->nxqs != lif->nxqs ||\n\t    qparam->nrxq_descs != lif->nrxq_descs ||\n\t    qparam->rxq_features != lif->rxq_features) {\n\t\trx_qcqs = devm_kcalloc(lif->ionic->dev, lif->ionic->nrxqs_per_lif,\n\t\t\t\t       sizeof(struct ionic_qcq *), GFP_KERNEL);\n\t\tif (!rx_qcqs) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\t \n\tif (tx_qcqs) {\n\t\tnum_desc = qparam->ntxq_descs;\n\t\tdesc_sz = sizeof(struct ionic_txq_desc);\n\t\tcomp_sz = sizeof(struct ionic_txq_comp);\n\n\t\tif (lif->qtype_info[IONIC_QTYPE_TXQ].version >= 1 &&\n\t\t    lif->qtype_info[IONIC_QTYPE_TXQ].sg_desc_sz ==\n\t\t    sizeof(struct ionic_txq_sg_desc_v1))\n\t\t\tsg_desc_sz = sizeof(struct ionic_txq_sg_desc_v1);\n\t\telse\n\t\t\tsg_desc_sz = sizeof(struct ionic_txq_sg_desc);\n\n\t\tfor (i = 0; i < qparam->nxqs; i++) {\n\t\t\t \n\t\t\tif (!lif->txqcqs[i]) {\n\t\t\t\tflags = IONIC_QCQ_F_TX_STATS | IONIC_QCQ_F_SG;\n\t\t\t\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_TXQ, i, \"tx\", flags,\n\t\t\t\t\t\t      4, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t\t\t\t      lif->kern_pid, &lif->txqcqs[i]);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\tflags = lif->txqcqs[i]->flags & ~IONIC_QCQ_F_INTR;\n\t\t\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_TXQ, i, \"tx\", flags,\n\t\t\t\t\t      num_desc, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t\t\t      lif->kern_pid, &tx_qcqs[i]);\n\t\t\tif (err)\n\t\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tif (rx_qcqs) {\n\t\tnum_desc = qparam->nrxq_descs;\n\t\tdesc_sz = sizeof(struct ionic_rxq_desc);\n\t\tcomp_sz = sizeof(struct ionic_rxq_comp);\n\t\tsg_desc_sz = sizeof(struct ionic_rxq_sg_desc);\n\n\t\tif (qparam->rxq_features & IONIC_Q_F_2X_CQ_DESC)\n\t\t\tcomp_sz *= 2;\n\n\t\tfor (i = 0; i < qparam->nxqs; i++) {\n\t\t\t \n\t\t\tif (!lif->rxqcqs[i]) {\n\t\t\t\tflags = IONIC_QCQ_F_RX_STATS | IONIC_QCQ_F_SG;\n\t\t\t\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_RXQ, i, \"rx\", flags,\n\t\t\t\t\t\t      4, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t\t\t\t      lif->kern_pid, &lif->rxqcqs[i]);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\tflags = lif->rxqcqs[i]->flags & ~IONIC_QCQ_F_INTR;\n\t\t\terr = ionic_qcq_alloc(lif, IONIC_QTYPE_RXQ, i, \"rx\", flags,\n\t\t\t\t\t      num_desc, desc_sz, comp_sz, sg_desc_sz,\n\t\t\t\t\t      lif->kern_pid, &rx_qcqs[i]);\n\t\t\tif (err)\n\t\t\t\tgoto err_out;\n\n\t\t\trx_qcqs[i]->q.features = qparam->rxq_features;\n\t\t}\n\t}\n\n\t \n\tionic_stop_queues_reconfig(lif);\n\n\tif (qparam->nxqs != lif->nxqs) {\n\t\terr = netif_set_real_num_tx_queues(lif->netdev, qparam->nxqs);\n\t\tif (err)\n\t\t\tgoto err_out_reinit_unlock;\n\t\terr = netif_set_real_num_rx_queues(lif->netdev, qparam->nxqs);\n\t\tif (err) {\n\t\t\tnetif_set_real_num_tx_queues(lif->netdev, lif->nxqs);\n\t\t\tgoto err_out_reinit_unlock;\n\t\t}\n\t}\n\n\t \n\tif (tx_qcqs) {\n\t\tlif->ntxq_descs = qparam->ntxq_descs;\n\t\tfor (i = 0; i < qparam->nxqs; i++)\n\t\t\tionic_swap_queues(lif->txqcqs[i], tx_qcqs[i]);\n\t}\n\n\tif (rx_qcqs) {\n\t\tlif->nrxq_descs = qparam->nrxq_descs;\n\t\tfor (i = 0; i < qparam->nxqs; i++)\n\t\t\tionic_swap_queues(lif->rxqcqs[i], rx_qcqs[i]);\n\t}\n\n\t \n\tif (qparam->intr_split != test_bit(IONIC_LIF_F_SPLIT_INTR, lif->state) ||\n\t    qparam->nxqs != lif->nxqs) {\n\t\tif (qparam->intr_split) {\n\t\t\tset_bit(IONIC_LIF_F_SPLIT_INTR, lif->state);\n\t\t} else {\n\t\t\tclear_bit(IONIC_LIF_F_SPLIT_INTR, lif->state);\n\t\t\tlif->tx_coalesce_usecs = lif->rx_coalesce_usecs;\n\t\t\tlif->tx_coalesce_hw = lif->rx_coalesce_hw;\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < lif->ionic->ntxqs_per_lif; i++) {\n\t\t\tif (lif->txqcqs[i])\n\t\t\t\tionic_qcq_intr_free(lif, lif->txqcqs[i]);\n\t\t\tif (lif->rxqcqs[i])\n\t\t\t\tionic_qcq_intr_free(lif, lif->rxqcqs[i]);\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < qparam->nxqs; i++) {\n\t\t\tlif->rxqcqs[i]->flags |= IONIC_QCQ_F_INTR;\n\t\t\terr = ionic_alloc_qcq_interrupt(lif, lif->rxqcqs[i]);\n\t\t\tionic_intr_coal_init(lif->ionic->idev.intr_ctrl,\n\t\t\t\t\t     lif->rxqcqs[i]->intr.index,\n\t\t\t\t\t     lif->rx_coalesce_hw);\n\n\t\t\tif (qparam->intr_split) {\n\t\t\t\tlif->txqcqs[i]->flags |= IONIC_QCQ_F_INTR;\n\t\t\t\terr = ionic_alloc_qcq_interrupt(lif, lif->txqcqs[i]);\n\t\t\t\tionic_intr_coal_init(lif->ionic->idev.intr_ctrl,\n\t\t\t\t\t\t     lif->txqcqs[i]->intr.index,\n\t\t\t\t\t\t     lif->tx_coalesce_hw);\n\t\t\t\tif (test_bit(IONIC_LIF_F_TX_DIM_INTR, lif->state))\n\t\t\t\t\tlif->txqcqs[i]->intr.dim_coal_hw = lif->tx_coalesce_hw;\n\t\t\t} else {\n\t\t\t\tlif->txqcqs[i]->flags &= ~IONIC_QCQ_F_INTR;\n\t\t\t\tionic_link_qcq_interrupts(lif->rxqcqs[i], lif->txqcqs[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (tx_qcqs) {\n\t\tfor (i = 0; i < qparam->nxqs; i++) {\n\t\t\tionic_debugfs_del_qcq(lif->txqcqs[i]);\n\t\t\tionic_debugfs_add_qcq(lif, lif->txqcqs[i]);\n\t\t}\n\t}\n\n\tif (rx_qcqs) {\n\t\tfor (i = 0; i < qparam->nxqs; i++) {\n\t\t\tionic_debugfs_del_qcq(lif->rxqcqs[i]);\n\t\t\tionic_debugfs_add_qcq(lif, lif->rxqcqs[i]);\n\t\t}\n\t}\n\n\tswap(lif->nxqs, qparam->nxqs);\n\tswap(lif->rxq_features, qparam->rxq_features);\n\nerr_out_reinit_unlock:\n\t \n\tif (err)\n\t\tionic_start_queues_reconfig(lif);\n\telse\n\t\terr = ionic_start_queues_reconfig(lif);\n\nerr_out:\n\t \n\tfor (i = 0; i < qparam->nxqs; i++) {\n\t\tif (tx_qcqs && tx_qcqs[i]) {\n\t\t\ttx_qcqs[i]->flags &= ~IONIC_QCQ_F_INTR;\n\t\t\tionic_qcq_free(lif, tx_qcqs[i]);\n\t\t\tdevm_kfree(lif->ionic->dev, tx_qcqs[i]);\n\t\t\ttx_qcqs[i] = NULL;\n\t\t}\n\t\tif (rx_qcqs && rx_qcqs[i]) {\n\t\t\trx_qcqs[i]->flags &= ~IONIC_QCQ_F_INTR;\n\t\t\tionic_qcq_free(lif, rx_qcqs[i]);\n\t\t\tdevm_kfree(lif->ionic->dev, rx_qcqs[i]);\n\t\t\trx_qcqs[i] = NULL;\n\t\t}\n\t}\n\n\t \n\tif (rx_qcqs) {\n\t\tdevm_kfree(lif->ionic->dev, rx_qcqs);\n\t\trx_qcqs = NULL;\n\t}\n\tif (tx_qcqs) {\n\t\tdevm_kfree(lif->ionic->dev, tx_qcqs);\n\t\ttx_qcqs = NULL;\n\t}\n\n\t \n\tfor (i = lif->nxqs; i < lif->ionic->ntxqs_per_lif; i++) {\n\t\tif (lif->txqcqs && lif->txqcqs[i]) {\n\t\t\tlif->txqcqs[i]->flags &= ~IONIC_QCQ_F_INTR;\n\t\t\tionic_qcq_free(lif, lif->txqcqs[i]);\n\t\t}\n\n\t\tif (lif->rxqcqs && lif->rxqcqs[i]) {\n\t\t\tlif->rxqcqs[i]->flags &= ~IONIC_QCQ_F_INTR;\n\t\t\tionic_qcq_free(lif, lif->rxqcqs[i]);\n\t\t}\n\t}\n\n\tif (err)\n\t\tnetdev_info(lif->netdev, \"%s: failed %d\\n\", __func__, err);\n\n\treturn err;\n}\n\nint ionic_lif_alloc(struct ionic *ionic)\n{\n\tstruct device *dev = ionic->dev;\n\tunion ionic_lif_identity *lid;\n\tstruct net_device *netdev;\n\tstruct ionic_lif *lif;\n\tint tbl_sz;\n\tint err;\n\n\tlid = kzalloc(sizeof(*lid), GFP_KERNEL);\n\tif (!lid)\n\t\treturn -ENOMEM;\n\n\tnetdev = alloc_etherdev_mqs(sizeof(*lif),\n\t\t\t\t    ionic->ntxqs_per_lif, ionic->ntxqs_per_lif);\n\tif (!netdev) {\n\t\tdev_err(dev, \"Cannot allocate netdev, aborting\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_out_free_lid;\n\t}\n\n\tSET_NETDEV_DEV(netdev, dev);\n\n\tlif = netdev_priv(netdev);\n\tlif->netdev = netdev;\n\tionic->lif = lif;\n\tnetdev->netdev_ops = &ionic_netdev_ops;\n\tionic_ethtool_set_ops(netdev);\n\n\tnetdev->watchdog_timeo = 2 * HZ;\n\tnetif_carrier_off(netdev);\n\n\tlif->identity = lid;\n\tlif->lif_type = IONIC_LIF_TYPE_CLASSIC;\n\terr = ionic_lif_identify(ionic, lif->lif_type, lif->identity);\n\tif (err) {\n\t\tdev_err(ionic->dev, \"Cannot identify type %d: %d\\n\",\n\t\t\tlif->lif_type, err);\n\t\tgoto err_out_free_netdev;\n\t}\n\tlif->netdev->min_mtu = max_t(unsigned int, ETH_MIN_MTU,\n\t\t\t\t     le32_to_cpu(lif->identity->eth.min_frame_size));\n\tlif->netdev->max_mtu =\n\t\tle32_to_cpu(lif->identity->eth.max_frame_size) - ETH_HLEN - VLAN_HLEN;\n\n\tlif->neqs = ionic->neqs_per_lif;\n\tlif->nxqs = ionic->ntxqs_per_lif;\n\n\tlif->ionic = ionic;\n\tlif->index = 0;\n\n\tif (is_kdump_kernel()) {\n\t\tlif->ntxq_descs = IONIC_MIN_TXRX_DESC;\n\t\tlif->nrxq_descs = IONIC_MIN_TXRX_DESC;\n\t} else {\n\t\tlif->ntxq_descs = IONIC_DEF_TXRX_DESC;\n\t\tlif->nrxq_descs = IONIC_DEF_TXRX_DESC;\n\t}\n\n\t \n\tlif->rx_coalesce_usecs = IONIC_ITR_COAL_USEC_DEFAULT;\n\tlif->rx_coalesce_hw = ionic_coal_usec_to_hw(lif->ionic,\n\t\t\t\t\t\t    lif->rx_coalesce_usecs);\n\tlif->tx_coalesce_usecs = lif->rx_coalesce_usecs;\n\tlif->tx_coalesce_hw = lif->rx_coalesce_hw;\n\tset_bit(IONIC_LIF_F_RX_DIM_INTR, lif->state);\n\tset_bit(IONIC_LIF_F_TX_DIM_INTR, lif->state);\n\n\tsnprintf(lif->name, sizeof(lif->name), \"lif%u\", lif->index);\n\n\tmutex_init(&lif->queue_lock);\n\tmutex_init(&lif->config_lock);\n\n\tspin_lock_init(&lif->adminq_lock);\n\n\tspin_lock_init(&lif->deferred.lock);\n\tINIT_LIST_HEAD(&lif->deferred.list);\n\tINIT_WORK(&lif->deferred.work, ionic_lif_deferred_work);\n\n\t \n\tlif->info_sz = ALIGN(sizeof(*lif->info), PAGE_SIZE);\n\tlif->info = dma_alloc_coherent(dev, lif->info_sz,\n\t\t\t\t       &lif->info_pa, GFP_KERNEL);\n\tif (!lif->info) {\n\t\tdev_err(dev, \"Failed to allocate lif info, aborting\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_out_free_mutex;\n\t}\n\n\tionic_debugfs_add_lif(lif);\n\n\t \n\tionic_lif_queue_identify(lif);\n\terr = ionic_qcqs_alloc(lif);\n\tif (err)\n\t\tgoto err_out_free_lif_info;\n\n\t \n\ttbl_sz = le16_to_cpu(lif->ionic->ident.lif.eth.rss_ind_tbl_sz);\n\tlif->rss_ind_tbl_sz = sizeof(*lif->rss_ind_tbl) * tbl_sz;\n\tlif->rss_ind_tbl = dma_alloc_coherent(dev, lif->rss_ind_tbl_sz,\n\t\t\t\t\t      &lif->rss_ind_tbl_pa,\n\t\t\t\t\t      GFP_KERNEL);\n\n\tif (!lif->rss_ind_tbl) {\n\t\terr = -ENOMEM;\n\t\tdev_err(dev, \"Failed to allocate rss indirection table, aborting\\n\");\n\t\tgoto err_out_free_qcqs;\n\t}\n\tnetdev_rss_key_fill(lif->rss_hash_key, IONIC_RSS_HASH_KEY_SIZE);\n\n\tionic_lif_alloc_phc(lif);\n\n\treturn 0;\n\nerr_out_free_qcqs:\n\tionic_qcqs_free(lif);\nerr_out_free_lif_info:\n\tdma_free_coherent(dev, lif->info_sz, lif->info, lif->info_pa);\n\tlif->info = NULL;\n\tlif->info_pa = 0;\nerr_out_free_mutex:\n\tmutex_destroy(&lif->config_lock);\n\tmutex_destroy(&lif->queue_lock);\nerr_out_free_netdev:\n\tfree_netdev(lif->netdev);\n\tlif = NULL;\nerr_out_free_lid:\n\tkfree(lid);\n\n\treturn err;\n}\n\nstatic void ionic_lif_reset(struct ionic_lif *lif)\n{\n\tstruct ionic_dev *idev = &lif->ionic->idev;\n\n\tmutex_lock(&lif->ionic->dev_cmd_lock);\n\tionic_dev_cmd_lif_reset(idev, lif->index);\n\tionic_dev_cmd_wait(lif->ionic, DEVCMD_TIMEOUT);\n\tmutex_unlock(&lif->ionic->dev_cmd_lock);\n}\n\nstatic void ionic_lif_handle_fw_down(struct ionic_lif *lif)\n{\n\tstruct ionic *ionic = lif->ionic;\n\n\tif (test_and_set_bit(IONIC_LIF_F_FW_RESET, lif->state))\n\t\treturn;\n\n\tdev_info(ionic->dev, \"FW Down: Stopping LIFs\\n\");\n\n\tnetif_device_detach(lif->netdev);\n\n\tmutex_lock(&lif->queue_lock);\n\tif (test_bit(IONIC_LIF_F_UP, lif->state)) {\n\t\tdev_info(ionic->dev, \"Surprise FW stop, stopping queues\\n\");\n\t\tionic_stop_queues(lif);\n\t}\n\n\tif (netif_running(lif->netdev)) {\n\t\tionic_txrx_deinit(lif);\n\t\tionic_txrx_free(lif);\n\t}\n\tionic_lif_deinit(lif);\n\tionic_reset(ionic);\n\tionic_qcqs_free(lif);\n\n\tmutex_unlock(&lif->queue_lock);\n\n\tclear_bit(IONIC_LIF_F_FW_STOPPING, lif->state);\n\tdev_info(ionic->dev, \"FW Down: LIFs stopped\\n\");\n}\n\nint ionic_restart_lif(struct ionic_lif *lif)\n{\n\tstruct ionic *ionic = lif->ionic;\n\tint err;\n\n\tmutex_lock(&lif->queue_lock);\n\n\tif (test_and_clear_bit(IONIC_LIF_F_BROKEN, lif->state))\n\t\tdev_info(ionic->dev, \"FW Up: clearing broken state\\n\");\n\n\terr = ionic_qcqs_alloc(lif);\n\tif (err)\n\t\tgoto err_unlock;\n\n\terr = ionic_lif_init(lif);\n\tif (err)\n\t\tgoto err_qcqs_free;\n\n\tionic_vf_attr_replay(lif);\n\n\tif (lif->registered)\n\t\tionic_lif_set_netdev_info(lif);\n\n\tionic_rx_filter_replay(lif);\n\n\tif (netif_running(lif->netdev)) {\n\t\terr = ionic_txrx_alloc(lif);\n\t\tif (err)\n\t\t\tgoto err_lifs_deinit;\n\n\t\terr = ionic_txrx_init(lif);\n\t\tif (err)\n\t\t\tgoto err_txrx_free;\n\t}\n\n\tmutex_unlock(&lif->queue_lock);\n\n\tclear_bit(IONIC_LIF_F_FW_RESET, lif->state);\n\tionic_link_status_check_request(lif, CAN_SLEEP);\n\tnetif_device_attach(lif->netdev);\n\n\treturn 0;\n\nerr_txrx_free:\n\tionic_txrx_free(lif);\nerr_lifs_deinit:\n\tionic_lif_deinit(lif);\nerr_qcqs_free:\n\tionic_qcqs_free(lif);\nerr_unlock:\n\tmutex_unlock(&lif->queue_lock);\n\n\treturn err;\n}\n\nstatic void ionic_lif_handle_fw_up(struct ionic_lif *lif)\n{\n\tstruct ionic *ionic = lif->ionic;\n\tint err;\n\n\tif (!test_bit(IONIC_LIF_F_FW_RESET, lif->state))\n\t\treturn;\n\n\tdev_info(ionic->dev, \"FW Up: restarting LIFs\\n\");\n\n\t \n\tionic_init_devinfo(ionic);\n\terr = ionic_identify(ionic);\n\tif (err)\n\t\tgoto err_out;\n\terr = ionic_port_identify(ionic);\n\tif (err)\n\t\tgoto err_out;\n\terr = ionic_port_init(ionic);\n\tif (err)\n\t\tgoto err_out;\n\n\terr = ionic_restart_lif(lif);\n\tif (err)\n\t\tgoto err_out;\n\n\tdev_info(ionic->dev, \"FW Up: LIFs restarted\\n\");\n\n\t \n\tionic_lif_hwstamp_replay(lif);\n\n\treturn;\n\nerr_out:\n\tdev_err(ionic->dev, \"FW Up: LIFs restart failed - err %d\\n\", err);\n}\n\nvoid ionic_lif_free(struct ionic_lif *lif)\n{\n\tstruct device *dev = lif->ionic->dev;\n\n\tionic_lif_free_phc(lif);\n\n\t \n\tdma_free_coherent(dev, lif->rss_ind_tbl_sz, lif->rss_ind_tbl,\n\t\t\t  lif->rss_ind_tbl_pa);\n\tlif->rss_ind_tbl = NULL;\n\tlif->rss_ind_tbl_pa = 0;\n\n\t \n\tionic_qcqs_free(lif);\n\tif (!test_bit(IONIC_LIF_F_FW_RESET, lif->state))\n\t\tionic_lif_reset(lif);\n\n\t \n\tkfree(lif->identity);\n\tdma_free_coherent(dev, lif->info_sz, lif->info, lif->info_pa);\n\tlif->info = NULL;\n\tlif->info_pa = 0;\n\n\t \n\tionic_bus_unmap_dbpage(lif->ionic, lif->kern_dbpage);\n\tlif->kern_dbpage = NULL;\n\n\tmutex_destroy(&lif->config_lock);\n\tmutex_destroy(&lif->queue_lock);\n\n\t \n\tionic_debugfs_del_lif(lif);\n\tfree_netdev(lif->netdev);\n}\n\nvoid ionic_lif_deinit(struct ionic_lif *lif)\n{\n\tif (!test_and_clear_bit(IONIC_LIF_F_INITED, lif->state))\n\t\treturn;\n\n\tif (!test_bit(IONIC_LIF_F_FW_RESET, lif->state)) {\n\t\tcancel_work_sync(&lif->deferred.work);\n\t\tcancel_work_sync(&lif->tx_timeout_work);\n\t\tionic_rx_filters_deinit(lif);\n\t\tif (lif->netdev->features & NETIF_F_RXHASH)\n\t\t\tionic_lif_rss_deinit(lif);\n\t}\n\n\tnapi_disable(&lif->adminqcq->napi);\n\tionic_lif_qcq_deinit(lif, lif->notifyqcq);\n\tionic_lif_qcq_deinit(lif, lif->adminqcq);\n\n\tionic_lif_reset(lif);\n}\n\nstatic int ionic_lif_adminq_init(struct ionic_lif *lif)\n{\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_q_init_comp comp;\n\tstruct ionic_dev *idev;\n\tstruct ionic_qcq *qcq;\n\tstruct ionic_queue *q;\n\tint err;\n\n\tidev = &lif->ionic->idev;\n\tqcq = lif->adminqcq;\n\tq = &qcq->q;\n\n\tmutex_lock(&lif->ionic->dev_cmd_lock);\n\tionic_dev_cmd_adminq_init(idev, qcq, lif->index, qcq->intr.index);\n\terr = ionic_dev_cmd_wait(lif->ionic, DEVCMD_TIMEOUT);\n\tionic_dev_cmd_comp(idev, (union ionic_dev_cmd_comp *)&comp);\n\tmutex_unlock(&lif->ionic->dev_cmd_lock);\n\tif (err) {\n\t\tnetdev_err(lif->netdev, \"adminq init failed %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tq->hw_type = comp.hw_type;\n\tq->hw_index = le32_to_cpu(comp.hw_index);\n\tq->dbval = IONIC_DBELL_QID(q->hw_index);\n\n\tdev_dbg(dev, \"adminq->hw_type %d\\n\", q->hw_type);\n\tdev_dbg(dev, \"adminq->hw_index %d\\n\", q->hw_index);\n\n\tq->dbell_deadline = IONIC_ADMIN_DOORBELL_DEADLINE;\n\tq->dbell_jiffies = jiffies;\n\n\tnetif_napi_add(lif->netdev, &qcq->napi, ionic_adminq_napi);\n\n\tqcq->napi_qcq = qcq;\n\ttimer_setup(&qcq->napi_deadline, ionic_napi_deadline, 0);\n\n\tnapi_enable(&qcq->napi);\n\n\tif (qcq->flags & IONIC_QCQ_F_INTR)\n\t\tionic_intr_mask(idev->intr_ctrl, qcq->intr.index,\n\t\t\t\tIONIC_INTR_MASK_CLEAR);\n\n\tqcq->flags |= IONIC_QCQ_F_INITED;\n\n\treturn 0;\n}\n\nstatic int ionic_lif_notifyq_init(struct ionic_lif *lif)\n{\n\tstruct ionic_qcq *qcq = lif->notifyqcq;\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_queue *q = &qcq->q;\n\tint err;\n\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.q_init = {\n\t\t\t.opcode = IONIC_CMD_Q_INIT,\n\t\t\t.lif_index = cpu_to_le16(lif->index),\n\t\t\t.type = q->type,\n\t\t\t.ver = lif->qtype_info[q->type].version,\n\t\t\t.index = cpu_to_le32(q->index),\n\t\t\t.flags = cpu_to_le16(IONIC_QINIT_F_IRQ |\n\t\t\t\t\t     IONIC_QINIT_F_ENA),\n\t\t\t.intr_index = cpu_to_le16(lif->adminqcq->intr.index),\n\t\t\t.pid = cpu_to_le16(q->pid),\n\t\t\t.ring_size = ilog2(q->num_descs),\n\t\t\t.ring_base = cpu_to_le64(q->base_pa),\n\t\t}\n\t};\n\n\tdev_dbg(dev, \"notifyq_init.pid %d\\n\", ctx.cmd.q_init.pid);\n\tdev_dbg(dev, \"notifyq_init.index %d\\n\", ctx.cmd.q_init.index);\n\tdev_dbg(dev, \"notifyq_init.ring_base 0x%llx\\n\", ctx.cmd.q_init.ring_base);\n\tdev_dbg(dev, \"notifyq_init.ring_size %d\\n\", ctx.cmd.q_init.ring_size);\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\treturn err;\n\n\tlif->last_eid = 0;\n\tq->hw_type = ctx.comp.q_init.hw_type;\n\tq->hw_index = le32_to_cpu(ctx.comp.q_init.hw_index);\n\tq->dbval = IONIC_DBELL_QID(q->hw_index);\n\n\tdev_dbg(dev, \"notifyq->hw_type %d\\n\", q->hw_type);\n\tdev_dbg(dev, \"notifyq->hw_index %d\\n\", q->hw_index);\n\n\t \n\tq->info[0].cb_arg = lif;\n\n\tqcq->flags |= IONIC_QCQ_F_INITED;\n\n\treturn 0;\n}\n\nstatic int ionic_station_set(struct ionic_lif *lif)\n{\n\tstruct net_device *netdev = lif->netdev;\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_getattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_GETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_MAC,\n\t\t},\n\t};\n\tu8 mac_address[ETH_ALEN];\n\tstruct sockaddr addr;\n\tint err;\n\n\terr = ionic_adminq_post_wait(lif, &ctx);\n\tif (err)\n\t\treturn err;\n\tnetdev_dbg(lif->netdev, \"found initial MAC addr %pM\\n\",\n\t\t   ctx.comp.lif_getattr.mac);\n\tether_addr_copy(mac_address, ctx.comp.lif_getattr.mac);\n\n\tif (is_zero_ether_addr(mac_address)) {\n\t\teth_hw_addr_random(netdev);\n\t\tnetdev_dbg(netdev, \"Random Mac generated: %pM\\n\", netdev->dev_addr);\n\t\tether_addr_copy(mac_address, netdev->dev_addr);\n\n\t\terr = ionic_program_mac(lif, mac_address);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (err > 0) {\n\t\t\tnetdev_dbg(netdev, \"%s:SET/GET ATTR Mac are not same-due to old FW running\\n\",\n\t\t\t\t   __func__);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (!is_zero_ether_addr(netdev->dev_addr)) {\n\t\t \n\t\tif (!ether_addr_equal(mac_address, netdev->dev_addr))\n\t\t\tionic_lif_addr_add(lif, netdev->dev_addr);\n\t} else {\n\t\t \n\t\tether_addr_copy(addr.sa_data, mac_address);\n\t\taddr.sa_family = AF_INET;\n\t\terr = eth_prepare_mac_addr_change(netdev, &addr);\n\t\tif (err) {\n\t\t\tnetdev_warn(lif->netdev, \"ignoring bad MAC addr from NIC %pM - err %d\\n\",\n\t\t\t\t    addr.sa_data, err);\n\t\t\treturn 0;\n\t\t}\n\n\t\teth_commit_mac_addr_change(netdev, &addr);\n\t}\n\n\tnetdev_dbg(lif->netdev, \"adding station MAC addr %pM\\n\",\n\t\t   netdev->dev_addr);\n\tionic_lif_addr_add(lif, netdev->dev_addr);\n\n\treturn 0;\n}\n\nint ionic_lif_init(struct ionic_lif *lif)\n{\n\tstruct ionic_dev *idev = &lif->ionic->idev;\n\tstruct device *dev = lif->ionic->dev;\n\tstruct ionic_lif_init_comp comp;\n\tint dbpage_num;\n\tint err;\n\n\tmutex_lock(&lif->ionic->dev_cmd_lock);\n\tionic_dev_cmd_lif_init(idev, lif->index, lif->info_pa);\n\terr = ionic_dev_cmd_wait(lif->ionic, DEVCMD_TIMEOUT);\n\tionic_dev_cmd_comp(idev, (union ionic_dev_cmd_comp *)&comp);\n\tmutex_unlock(&lif->ionic->dev_cmd_lock);\n\tif (err)\n\t\treturn err;\n\n\tlif->hw_index = le16_to_cpu(comp.hw_index);\n\n\t \n\tlif->dbid_count = le32_to_cpu(lif->ionic->ident.dev.ndbpgs_per_lif);\n\tif (!lif->dbid_count) {\n\t\tdev_err(dev, \"No doorbell pages, aborting\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tlif->kern_pid = 0;\n\tdbpage_num = ionic_db_page_num(lif, lif->kern_pid);\n\tlif->kern_dbpage = ionic_bus_map_dbpage(lif->ionic, dbpage_num);\n\tif (!lif->kern_dbpage) {\n\t\tdev_err(dev, \"Cannot map dbpage, aborting\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\terr = ionic_lif_adminq_init(lif);\n\tif (err)\n\t\tgoto err_out_adminq_deinit;\n\n\tif (lif->ionic->nnqs_per_lif) {\n\t\terr = ionic_lif_notifyq_init(lif);\n\t\tif (err)\n\t\t\tgoto err_out_notifyq_deinit;\n\t}\n\n\terr = ionic_init_nic_features(lif);\n\tif (err)\n\t\tgoto err_out_notifyq_deinit;\n\n\tif (!test_bit(IONIC_LIF_F_FW_RESET, lif->state)) {\n\t\terr = ionic_rx_filters_init(lif);\n\t\tif (err)\n\t\t\tgoto err_out_notifyq_deinit;\n\t}\n\n\terr = ionic_station_set(lif);\n\tif (err)\n\t\tgoto err_out_notifyq_deinit;\n\n\tlif->rx_copybreak = IONIC_RX_COPYBREAK_DEFAULT;\n\n\tset_bit(IONIC_LIF_F_INITED, lif->state);\n\n\tINIT_WORK(&lif->tx_timeout_work, ionic_tx_timeout_work);\n\n\treturn 0;\n\nerr_out_notifyq_deinit:\n\tnapi_disable(&lif->adminqcq->napi);\n\tionic_lif_qcq_deinit(lif, lif->notifyqcq);\nerr_out_adminq_deinit:\n\tionic_lif_qcq_deinit(lif, lif->adminqcq);\n\tionic_lif_reset(lif);\n\tionic_bus_unmap_dbpage(lif->ionic, lif->kern_dbpage);\n\tlif->kern_dbpage = NULL;\n\n\treturn err;\n}\n\nstatic void ionic_lif_notify_work(struct work_struct *ws)\n{\n}\n\nstatic void ionic_lif_set_netdev_info(struct ionic_lif *lif)\n{\n\tstruct ionic_admin_ctx ctx = {\n\t\t.work = COMPLETION_INITIALIZER_ONSTACK(ctx.work),\n\t\t.cmd.lif_setattr = {\n\t\t\t.opcode = IONIC_CMD_LIF_SETATTR,\n\t\t\t.index = cpu_to_le16(lif->index),\n\t\t\t.attr = IONIC_LIF_ATTR_NAME,\n\t\t},\n\t};\n\n\tstrscpy(ctx.cmd.lif_setattr.name, lif->netdev->name,\n\t\tsizeof(ctx.cmd.lif_setattr.name));\n\n\tionic_adminq_post_wait(lif, &ctx);\n}\n\nstatic struct ionic_lif *ionic_netdev_lif(struct net_device *netdev)\n{\n\tif (!netdev || netdev->netdev_ops->ndo_start_xmit != ionic_start_xmit)\n\t\treturn NULL;\n\n\treturn netdev_priv(netdev);\n}\n\nstatic int ionic_lif_notify(struct notifier_block *nb,\n\t\t\t    unsigned long event, void *info)\n{\n\tstruct net_device *ndev = netdev_notifier_info_to_dev(info);\n\tstruct ionic *ionic = container_of(nb, struct ionic, nb);\n\tstruct ionic_lif *lif = ionic_netdev_lif(ndev);\n\n\tif (!lif || lif->ionic != ionic)\n\t\treturn NOTIFY_DONE;\n\n\tswitch (event) {\n\tcase NETDEV_CHANGENAME:\n\t\tionic_lif_set_netdev_info(lif);\n\t\tbreak;\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\nint ionic_lif_register(struct ionic_lif *lif)\n{\n\tint err;\n\n\tionic_lif_register_phc(lif);\n\n\tINIT_WORK(&lif->ionic->nb_work, ionic_lif_notify_work);\n\n\tlif->ionic->nb.notifier_call = ionic_lif_notify;\n\n\terr = register_netdevice_notifier(&lif->ionic->nb);\n\tif (err)\n\t\tlif->ionic->nb.notifier_call = NULL;\n\n\t \n\terr = register_netdev(lif->netdev);\n\tif (err) {\n\t\tdev_err(lif->ionic->dev, \"Cannot register net device, aborting\\n\");\n\t\tionic_lif_unregister_phc(lif);\n\t\treturn err;\n\t}\n\n\tionic_link_status_check_request(lif, CAN_SLEEP);\n\tlif->registered = true;\n\tionic_lif_set_netdev_info(lif);\n\n\treturn 0;\n}\n\nvoid ionic_lif_unregister(struct ionic_lif *lif)\n{\n\tif (lif->ionic->nb.notifier_call) {\n\t\tunregister_netdevice_notifier(&lif->ionic->nb);\n\t\tcancel_work_sync(&lif->ionic->nb_work);\n\t\tlif->ionic->nb.notifier_call = NULL;\n\t}\n\n\tif (lif->netdev->reg_state == NETREG_REGISTERED)\n\t\tunregister_netdev(lif->netdev);\n\n\tionic_lif_unregister_phc(lif);\n\n\tlif->registered = false;\n}\n\nstatic void ionic_lif_queue_identify(struct ionic_lif *lif)\n{\n\tunion ionic_q_identity __iomem *q_ident;\n\tstruct ionic *ionic = lif->ionic;\n\tstruct ionic_dev *idev;\n\tint qtype;\n\tint err;\n\n\tidev = &lif->ionic->idev;\n\tq_ident = (union ionic_q_identity __iomem *)&idev->dev_cmd_regs->data;\n\n\tfor (qtype = 0; qtype < ARRAY_SIZE(ionic_qtype_versions); qtype++) {\n\t\tstruct ionic_qtype_info *qti = &lif->qtype_info[qtype];\n\n\t\t \n\t\tswitch (qtype) {\n\t\tcase IONIC_QTYPE_ADMINQ:\n\t\tcase IONIC_QTYPE_NOTIFYQ:\n\t\tcase IONIC_QTYPE_RXQ:\n\t\tcase IONIC_QTYPE_TXQ:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tcontinue;\n\t\t}\n\n\t\tmemset(qti, 0, sizeof(*qti));\n\n\t\tmutex_lock(&ionic->dev_cmd_lock);\n\t\tionic_dev_cmd_queue_identify(idev, lif->lif_type, qtype,\n\t\t\t\t\t     ionic_qtype_versions[qtype]);\n\t\terr = ionic_dev_cmd_wait(ionic, DEVCMD_TIMEOUT);\n\t\tif (!err) {\n\t\t\tqti->version   = readb(&q_ident->version);\n\t\t\tqti->supported = readb(&q_ident->supported);\n\t\t\tqti->features  = readq(&q_ident->features);\n\t\t\tqti->desc_sz   = readw(&q_ident->desc_sz);\n\t\t\tqti->comp_sz   = readw(&q_ident->comp_sz);\n\t\t\tqti->sg_desc_sz   = readw(&q_ident->sg_desc_sz);\n\t\t\tqti->max_sg_elems = readw(&q_ident->max_sg_elems);\n\t\t\tqti->sg_desc_stride = readw(&q_ident->sg_desc_stride);\n\t\t}\n\t\tmutex_unlock(&ionic->dev_cmd_lock);\n\n\t\tif (err == -EINVAL) {\n\t\t\tdev_err(ionic->dev, \"qtype %d not supported\\n\", qtype);\n\t\t\tcontinue;\n\t\t} else if (err == -EIO) {\n\t\t\tdev_err(ionic->dev, \"q_ident failed, not supported on older FW\\n\");\n\t\t\treturn;\n\t\t} else if (err) {\n\t\t\tdev_err(ionic->dev, \"q_ident failed, qtype %d: %d\\n\",\n\t\t\t\tqtype, err);\n\t\t\treturn;\n\t\t}\n\n\t\tdev_dbg(ionic->dev, \" qtype[%d].version = %d\\n\",\n\t\t\tqtype, qti->version);\n\t\tdev_dbg(ionic->dev, \" qtype[%d].supported = 0x%02x\\n\",\n\t\t\tqtype, qti->supported);\n\t\tdev_dbg(ionic->dev, \" qtype[%d].features = 0x%04llx\\n\",\n\t\t\tqtype, qti->features);\n\t\tdev_dbg(ionic->dev, \" qtype[%d].desc_sz = %d\\n\",\n\t\t\tqtype, qti->desc_sz);\n\t\tdev_dbg(ionic->dev, \" qtype[%d].comp_sz = %d\\n\",\n\t\t\tqtype, qti->comp_sz);\n\t\tdev_dbg(ionic->dev, \" qtype[%d].sg_desc_sz = %d\\n\",\n\t\t\tqtype, qti->sg_desc_sz);\n\t\tdev_dbg(ionic->dev, \" qtype[%d].max_sg_elems = %d\\n\",\n\t\t\tqtype, qti->max_sg_elems);\n\t\tdev_dbg(ionic->dev, \" qtype[%d].sg_desc_stride = %d\\n\",\n\t\t\tqtype, qti->sg_desc_stride);\n\t}\n}\n\nint ionic_lif_identify(struct ionic *ionic, u8 lif_type,\n\t\t       union ionic_lif_identity *lid)\n{\n\tstruct ionic_dev *idev = &ionic->idev;\n\tsize_t sz;\n\tint err;\n\n\tsz = min(sizeof(*lid), sizeof(idev->dev_cmd_regs->data));\n\n\tmutex_lock(&ionic->dev_cmd_lock);\n\tionic_dev_cmd_lif_identify(idev, lif_type, IONIC_IDENTITY_VERSION_1);\n\terr = ionic_dev_cmd_wait(ionic, DEVCMD_TIMEOUT);\n\tmemcpy_fromio(lid, &idev->dev_cmd_regs->data, sz);\n\tmutex_unlock(&ionic->dev_cmd_lock);\n\tif (err)\n\t\treturn (err);\n\n\tdev_dbg(ionic->dev, \"capabilities 0x%llx\\n\",\n\t\tle64_to_cpu(lid->capabilities));\n\n\tdev_dbg(ionic->dev, \"eth.max_ucast_filters %d\\n\",\n\t\tle32_to_cpu(lid->eth.max_ucast_filters));\n\tdev_dbg(ionic->dev, \"eth.max_mcast_filters %d\\n\",\n\t\tle32_to_cpu(lid->eth.max_mcast_filters));\n\tdev_dbg(ionic->dev, \"eth.features 0x%llx\\n\",\n\t\tle64_to_cpu(lid->eth.config.features));\n\tdev_dbg(ionic->dev, \"eth.queue_count[IONIC_QTYPE_ADMINQ] %d\\n\",\n\t\tle32_to_cpu(lid->eth.config.queue_count[IONIC_QTYPE_ADMINQ]));\n\tdev_dbg(ionic->dev, \"eth.queue_count[IONIC_QTYPE_NOTIFYQ] %d\\n\",\n\t\tle32_to_cpu(lid->eth.config.queue_count[IONIC_QTYPE_NOTIFYQ]));\n\tdev_dbg(ionic->dev, \"eth.queue_count[IONIC_QTYPE_RXQ] %d\\n\",\n\t\tle32_to_cpu(lid->eth.config.queue_count[IONIC_QTYPE_RXQ]));\n\tdev_dbg(ionic->dev, \"eth.queue_count[IONIC_QTYPE_TXQ] %d\\n\",\n\t\tle32_to_cpu(lid->eth.config.queue_count[IONIC_QTYPE_TXQ]));\n\tdev_dbg(ionic->dev, \"eth.config.name %s\\n\", lid->eth.config.name);\n\tdev_dbg(ionic->dev, \"eth.config.mac %pM\\n\", lid->eth.config.mac);\n\tdev_dbg(ionic->dev, \"eth.config.mtu %d\\n\",\n\t\tle32_to_cpu(lid->eth.config.mtu));\n\n\treturn 0;\n}\n\nint ionic_lif_size(struct ionic *ionic)\n{\n\tstruct ionic_identity *ident = &ionic->ident;\n\tunsigned int nintrs, dev_nintrs;\n\tunion ionic_lif_config *lc;\n\tunsigned int ntxqs_per_lif;\n\tunsigned int nrxqs_per_lif;\n\tunsigned int neqs_per_lif;\n\tunsigned int nnqs_per_lif;\n\tunsigned int nxqs, neqs;\n\tunsigned int min_intrs;\n\tint err;\n\n\t \n\tlc = &ident->lif.eth.config;\n\tdev_nintrs = le32_to_cpu(ident->dev.nintrs);\n\tneqs_per_lif = le32_to_cpu(ident->lif.rdma.eq_qtype.qid_count);\n\tnnqs_per_lif = le32_to_cpu(lc->queue_count[IONIC_QTYPE_NOTIFYQ]);\n\tntxqs_per_lif = le32_to_cpu(lc->queue_count[IONIC_QTYPE_TXQ]);\n\tnrxqs_per_lif = le32_to_cpu(lc->queue_count[IONIC_QTYPE_RXQ]);\n\n\t \n\tif (is_kdump_kernel()) {\n\t\tdev_nintrs = 2;\n\t\tneqs_per_lif = 0;\n\t\tnnqs_per_lif = 0;\n\t\tntxqs_per_lif = 1;\n\t\tnrxqs_per_lif = 1;\n\t}\n\n\t \n\tif (lc->features & cpu_to_le64(IONIC_ETH_HW_TIMESTAMP)) {\n\t\tif (ntxqs_per_lif <= 1 || nrxqs_per_lif <= 1) {\n\t\t\tlc->features &= cpu_to_le64(~IONIC_ETH_HW_TIMESTAMP);\n\t\t} else {\n\t\t\tntxqs_per_lif -= 1;\n\t\t\tnrxqs_per_lif -= 1;\n\t\t}\n\t}\n\n\tnxqs = min(ntxqs_per_lif, nrxqs_per_lif);\n\tnxqs = min(nxqs, num_online_cpus());\n\tneqs = min(neqs_per_lif, num_online_cpus());\n\ntry_again:\n\t \n\tnintrs = 1 + nxqs + neqs;\n\tmin_intrs = 2;   \n\n\tif (nintrs > dev_nintrs)\n\t\tgoto try_fewer;\n\n\terr = ionic_bus_alloc_irq_vectors(ionic, nintrs);\n\tif (err < 0 && err != -ENOSPC) {\n\t\tdev_err(ionic->dev, \"Can't get intrs from OS: %d\\n\", err);\n\t\treturn err;\n\t}\n\tif (err == -ENOSPC)\n\t\tgoto try_fewer;\n\n\tif (err != nintrs) {\n\t\tionic_bus_free_irq_vectors(ionic);\n\t\tgoto try_fewer;\n\t}\n\n\tionic->nnqs_per_lif = nnqs_per_lif;\n\tionic->neqs_per_lif = neqs;\n\tionic->ntxqs_per_lif = nxqs;\n\tionic->nrxqs_per_lif = nxqs;\n\tionic->nintrs = nintrs;\n\n\tionic_debugfs_add_sizes(ionic);\n\n\treturn 0;\n\ntry_fewer:\n\tif (nnqs_per_lif > 1) {\n\t\tnnqs_per_lif >>= 1;\n\t\tgoto try_again;\n\t}\n\tif (neqs > 1) {\n\t\tneqs >>= 1;\n\t\tgoto try_again;\n\t}\n\tif (nxqs > 1) {\n\t\tnxqs >>= 1;\n\t\tgoto try_again;\n\t}\n\tdev_err(ionic->dev, \"Can't get minimum %d intrs from OS\\n\", min_intrs);\n\treturn -ENOSPC;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}