{
  "module_name": "bnx2x_main.c",
  "hash_id": "30d61a45e6b02c82032c3804215b44139974840d7814a14209f2a6fdd45ea842",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/broadcom/bnx2x/bnx2x_main.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/kernel.h>\n#include <linux/device.h>   \n#include <linux/timer.h>\n#include <linux/errno.h>\n#include <linux/ioport.h>\n#include <linux/slab.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/init.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/dma-mapping.h>\n#include <linux/bitops.h>\n#include <linux/irq.h>\n#include <linux/delay.h>\n#include <asm/byteorder.h>\n#include <linux/time.h>\n#include <linux/ethtool.h>\n#include <linux/mii.h>\n#include <linux/if_vlan.h>\n#include <linux/crash_dump.h>\n#include <net/ip.h>\n#include <net/ipv6.h>\n#include <net/tcp.h>\n#include <net/vxlan.h>\n#include <net/checksum.h>\n#include <net/ip6_checksum.h>\n#include <linux/workqueue.h>\n#include <linux/crc32.h>\n#include <linux/crc32c.h>\n#include <linux/prefetch.h>\n#include <linux/zlib.h>\n#include <linux/io.h>\n#include <linux/semaphore.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include \"bnx2x.h\"\n#include \"bnx2x_init.h\"\n#include \"bnx2x_init_ops.h\"\n#include \"bnx2x_cmn.h\"\n#include \"bnx2x_vfpf.h\"\n#include \"bnx2x_dcb.h\"\n#include \"bnx2x_sp.h\"\n#include <linux/firmware.h>\n#include \"bnx2x_fw_file_hdr.h\"\n \n#define FW_FILE_VERSION\t\t\t\t\t\\\n\t__stringify(BCM_5710_FW_MAJOR_VERSION) \".\"\t\\\n\t__stringify(BCM_5710_FW_MINOR_VERSION) \".\"\t\\\n\t__stringify(BCM_5710_FW_REVISION_VERSION) \".\"\t\\\n\t__stringify(BCM_5710_FW_ENGINEERING_VERSION)\n\n#define FW_FILE_VERSION_V15\t\t\t\t\\\n\t__stringify(BCM_5710_FW_MAJOR_VERSION) \".\"      \\\n\t__stringify(BCM_5710_FW_MINOR_VERSION) \".\"\t\\\n\t__stringify(BCM_5710_FW_REVISION_VERSION_V15) \".\"\t\\\n\t__stringify(BCM_5710_FW_ENGINEERING_VERSION)\n\n#define FW_FILE_NAME_E1\t\t\"bnx2x/bnx2x-e1-\" FW_FILE_VERSION \".fw\"\n#define FW_FILE_NAME_E1H\t\"bnx2x/bnx2x-e1h-\" FW_FILE_VERSION \".fw\"\n#define FW_FILE_NAME_E2\t\t\"bnx2x/bnx2x-e2-\" FW_FILE_VERSION \".fw\"\n#define FW_FILE_NAME_E1_V15\t\"bnx2x/bnx2x-e1-\" FW_FILE_VERSION_V15 \".fw\"\n#define FW_FILE_NAME_E1H_V15\t\"bnx2x/bnx2x-e1h-\" FW_FILE_VERSION_V15 \".fw\"\n#define FW_FILE_NAME_E2_V15\t\"bnx2x/bnx2x-e2-\" FW_FILE_VERSION_V15 \".fw\"\n\n \n#define TX_TIMEOUT\t\t(5*HZ)\n\nMODULE_AUTHOR(\"Eliezer Tamir\");\nMODULE_DESCRIPTION(\"QLogic \"\n\t\t   \"BCM57710/57711/57711E/\"\n\t\t   \"57712/57712_MF/57800/57800_MF/57810/57810_MF/\"\n\t\t   \"57840/57840_MF Driver\");\nMODULE_LICENSE(\"GPL\");\nMODULE_FIRMWARE(FW_FILE_NAME_E1);\nMODULE_FIRMWARE(FW_FILE_NAME_E1H);\nMODULE_FIRMWARE(FW_FILE_NAME_E2);\nMODULE_FIRMWARE(FW_FILE_NAME_E1_V15);\nMODULE_FIRMWARE(FW_FILE_NAME_E1H_V15);\nMODULE_FIRMWARE(FW_FILE_NAME_E2_V15);\n\nint bnx2x_num_queues;\nmodule_param_named(num_queues, bnx2x_num_queues, int, 0444);\nMODULE_PARM_DESC(num_queues,\n\t\t \" Set number of queues (default is as a number of CPUs)\");\n\nstatic int disable_tpa;\nmodule_param(disable_tpa, int, 0444);\nMODULE_PARM_DESC(disable_tpa, \" Disable the TPA (LRO) feature\");\n\nstatic int int_mode;\nmodule_param(int_mode, int, 0444);\nMODULE_PARM_DESC(int_mode, \" Force interrupt mode other than MSI-X \"\n\t\t\t\t\"(1 INT#x; 2 MSI)\");\n\nstatic int dropless_fc;\nmodule_param(dropless_fc, int, 0444);\nMODULE_PARM_DESC(dropless_fc, \" Pause on exhausted host ring\");\n\nstatic int mrrs = -1;\nmodule_param(mrrs, int, 0444);\nMODULE_PARM_DESC(mrrs, \" Force Max Read Req Size (0..3) (for debug)\");\n\nstatic int debug;\nmodule_param(debug, int, 0444);\nMODULE_PARM_DESC(debug, \" Default debug msglevel\");\n\nstatic struct workqueue_struct *bnx2x_wq;\nstruct workqueue_struct *bnx2x_iov_wq;\n\nstruct bnx2x_mac_vals {\n\tu32 xmac_addr;\n\tu32 xmac_val;\n\tu32 emac_addr;\n\tu32 emac_val;\n\tu32 umac_addr[2];\n\tu32 umac_val[2];\n\tu32 bmac_addr;\n\tu32 bmac_val[2];\n};\n\nenum bnx2x_board_type {\n\tBCM57710 = 0,\n\tBCM57711,\n\tBCM57711E,\n\tBCM57712,\n\tBCM57712_MF,\n\tBCM57712_VF,\n\tBCM57800,\n\tBCM57800_MF,\n\tBCM57800_VF,\n\tBCM57810,\n\tBCM57810_MF,\n\tBCM57810_VF,\n\tBCM57840_4_10,\n\tBCM57840_2_20,\n\tBCM57840_MF,\n\tBCM57840_VF,\n\tBCM57811,\n\tBCM57811_MF,\n\tBCM57840_O,\n\tBCM57840_MFO,\n\tBCM57811_VF\n};\n\n \nstatic struct {\n\tchar *name;\n} board_info[] = {\n\t[BCM57710]\t= { \"QLogic BCM57710 10 Gigabit PCIe [Everest]\" },\n\t[BCM57711]\t= { \"QLogic BCM57711 10 Gigabit PCIe\" },\n\t[BCM57711E]\t= { \"QLogic BCM57711E 10 Gigabit PCIe\" },\n\t[BCM57712]\t= { \"QLogic BCM57712 10 Gigabit Ethernet\" },\n\t[BCM57712_MF]\t= { \"QLogic BCM57712 10 Gigabit Ethernet Multi Function\" },\n\t[BCM57712_VF]\t= { \"QLogic BCM57712 10 Gigabit Ethernet Virtual Function\" },\n\t[BCM57800]\t= { \"QLogic BCM57800 10 Gigabit Ethernet\" },\n\t[BCM57800_MF]\t= { \"QLogic BCM57800 10 Gigabit Ethernet Multi Function\" },\n\t[BCM57800_VF]\t= { \"QLogic BCM57800 10 Gigabit Ethernet Virtual Function\" },\n\t[BCM57810]\t= { \"QLogic BCM57810 10 Gigabit Ethernet\" },\n\t[BCM57810_MF]\t= { \"QLogic BCM57810 10 Gigabit Ethernet Multi Function\" },\n\t[BCM57810_VF]\t= { \"QLogic BCM57810 10 Gigabit Ethernet Virtual Function\" },\n\t[BCM57840_4_10]\t= { \"QLogic BCM57840 10 Gigabit Ethernet\" },\n\t[BCM57840_2_20]\t= { \"QLogic BCM57840 20 Gigabit Ethernet\" },\n\t[BCM57840_MF]\t= { \"QLogic BCM57840 10/20 Gigabit Ethernet Multi Function\" },\n\t[BCM57840_VF]\t= { \"QLogic BCM57840 10/20 Gigabit Ethernet Virtual Function\" },\n\t[BCM57811]\t= { \"QLogic BCM57811 10 Gigabit Ethernet\" },\n\t[BCM57811_MF]\t= { \"QLogic BCM57811 10 Gigabit Ethernet Multi Function\" },\n\t[BCM57840_O]\t= { \"QLogic BCM57840 10/20 Gigabit Ethernet\" },\n\t[BCM57840_MFO]\t= { \"QLogic BCM57840 10/20 Gigabit Ethernet Multi Function\" },\n\t[BCM57811_VF]\t= { \"QLogic BCM57840 10/20 Gigabit Ethernet Virtual Function\" }\n};\n\n#ifndef PCI_DEVICE_ID_NX2_57710\n#define PCI_DEVICE_ID_NX2_57710\t\tCHIP_NUM_57710\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57711\n#define PCI_DEVICE_ID_NX2_57711\t\tCHIP_NUM_57711\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57711E\n#define PCI_DEVICE_ID_NX2_57711E\tCHIP_NUM_57711E\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57712\n#define PCI_DEVICE_ID_NX2_57712\t\tCHIP_NUM_57712\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57712_MF\n#define PCI_DEVICE_ID_NX2_57712_MF\tCHIP_NUM_57712_MF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57712_VF\n#define PCI_DEVICE_ID_NX2_57712_VF\tCHIP_NUM_57712_VF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57800\n#define PCI_DEVICE_ID_NX2_57800\t\tCHIP_NUM_57800\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57800_MF\n#define PCI_DEVICE_ID_NX2_57800_MF\tCHIP_NUM_57800_MF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57800_VF\n#define PCI_DEVICE_ID_NX2_57800_VF\tCHIP_NUM_57800_VF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57810\n#define PCI_DEVICE_ID_NX2_57810\t\tCHIP_NUM_57810\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57810_MF\n#define PCI_DEVICE_ID_NX2_57810_MF\tCHIP_NUM_57810_MF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57840_O\n#define PCI_DEVICE_ID_NX2_57840_O\tCHIP_NUM_57840_OBSOLETE\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57810_VF\n#define PCI_DEVICE_ID_NX2_57810_VF\tCHIP_NUM_57810_VF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57840_4_10\n#define PCI_DEVICE_ID_NX2_57840_4_10\tCHIP_NUM_57840_4_10\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57840_2_20\n#define PCI_DEVICE_ID_NX2_57840_2_20\tCHIP_NUM_57840_2_20\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57840_MFO\n#define PCI_DEVICE_ID_NX2_57840_MFO\tCHIP_NUM_57840_MF_OBSOLETE\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57840_MF\n#define PCI_DEVICE_ID_NX2_57840_MF\tCHIP_NUM_57840_MF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57840_VF\n#define PCI_DEVICE_ID_NX2_57840_VF\tCHIP_NUM_57840_VF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57811\n#define PCI_DEVICE_ID_NX2_57811\t\tCHIP_NUM_57811\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57811_MF\n#define PCI_DEVICE_ID_NX2_57811_MF\tCHIP_NUM_57811_MF\n#endif\n#ifndef PCI_DEVICE_ID_NX2_57811_VF\n#define PCI_DEVICE_ID_NX2_57811_VF\tCHIP_NUM_57811_VF\n#endif\n\nstatic const struct pci_device_id bnx2x_pci_tbl[] = {\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57710), BCM57710 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57711), BCM57711 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57711E), BCM57711E },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57712), BCM57712 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57712_MF), BCM57712_MF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57712_VF), BCM57712_VF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57800), BCM57800 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57800_MF), BCM57800_MF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57800_VF), BCM57800_VF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57810), BCM57810 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57810_MF), BCM57810_MF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57840_O), BCM57840_O },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57840_4_10), BCM57840_4_10 },\n\t{ PCI_VDEVICE(QLOGIC,\tPCI_DEVICE_ID_NX2_57840_4_10), BCM57840_4_10 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57840_2_20), BCM57840_2_20 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57810_VF), BCM57810_VF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57840_MFO), BCM57840_MFO },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57840_MF), BCM57840_MF },\n\t{ PCI_VDEVICE(QLOGIC,\tPCI_DEVICE_ID_NX2_57840_MF), BCM57840_MF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57840_VF), BCM57840_VF },\n\t{ PCI_VDEVICE(QLOGIC,\tPCI_DEVICE_ID_NX2_57840_VF), BCM57840_VF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57811), BCM57811 },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57811_MF), BCM57811_MF },\n\t{ PCI_VDEVICE(BROADCOM, PCI_DEVICE_ID_NX2_57811_VF), BCM57811_VF },\n\t{ 0 }\n};\n\nMODULE_DEVICE_TABLE(pci, bnx2x_pci_tbl);\n\nconst u32 dmae_reg_go_c[] = {\n\tDMAE_REG_GO_C0, DMAE_REG_GO_C1, DMAE_REG_GO_C2, DMAE_REG_GO_C3,\n\tDMAE_REG_GO_C4, DMAE_REG_GO_C5, DMAE_REG_GO_C6, DMAE_REG_GO_C7,\n\tDMAE_REG_GO_C8, DMAE_REG_GO_C9, DMAE_REG_GO_C10, DMAE_REG_GO_C11,\n\tDMAE_REG_GO_C12, DMAE_REG_GO_C13, DMAE_REG_GO_C14, DMAE_REG_GO_C15\n};\n\n \n#define BNX2X_PREV_WAIT_NEEDED 1\nstatic DEFINE_SEMAPHORE(bnx2x_prev_sem, 1);\nstatic LIST_HEAD(bnx2x_prev_list);\n\n \nstatic struct cnic_eth_dev *bnx2x_cnic_probe(struct net_device *dev);\nstatic u32 bnx2x_rx_ustorm_prods_offset(struct bnx2x_fastpath *fp);\nstatic int bnx2x_set_storm_rx_mode(struct bnx2x *bp);\n\n \n\nstatic int bnx2x_hwtstamp_ioctl(struct bnx2x *bp, struct ifreq *ifr);\n\nstatic void __storm_memset_dma_mapping(struct bnx2x *bp,\n\t\t\t\t       u32 addr, dma_addr_t mapping)\n{\n\tREG_WR(bp,  addr, U64_LO(mapping));\n\tREG_WR(bp,  addr + 4, U64_HI(mapping));\n}\n\nstatic void storm_memset_spq_addr(struct bnx2x *bp,\n\t\t\t\t  dma_addr_t mapping, u16 abs_fid)\n{\n\tu32 addr = XSEM_REG_FAST_MEMORY +\n\t\t\tXSTORM_SPQ_PAGE_BASE_OFFSET(abs_fid);\n\n\t__storm_memset_dma_mapping(bp, addr, mapping);\n}\n\nstatic void storm_memset_vf_to_pf(struct bnx2x *bp, u16 abs_fid,\n\t\t\t\t  u16 pf_id)\n{\n\tREG_WR8(bp, BAR_XSTRORM_INTMEM + XSTORM_VF_TO_PF_OFFSET(abs_fid),\n\t\tpf_id);\n\tREG_WR8(bp, BAR_CSTRORM_INTMEM + CSTORM_VF_TO_PF_OFFSET(abs_fid),\n\t\tpf_id);\n\tREG_WR8(bp, BAR_TSTRORM_INTMEM + TSTORM_VF_TO_PF_OFFSET(abs_fid),\n\t\tpf_id);\n\tREG_WR8(bp, BAR_USTRORM_INTMEM + USTORM_VF_TO_PF_OFFSET(abs_fid),\n\t\tpf_id);\n}\n\nstatic void storm_memset_func_en(struct bnx2x *bp, u16 abs_fid,\n\t\t\t\t u8 enable)\n{\n\tREG_WR8(bp, BAR_XSTRORM_INTMEM + XSTORM_FUNC_EN_OFFSET(abs_fid),\n\t\tenable);\n\tREG_WR8(bp, BAR_CSTRORM_INTMEM + CSTORM_FUNC_EN_OFFSET(abs_fid),\n\t\tenable);\n\tREG_WR8(bp, BAR_TSTRORM_INTMEM + TSTORM_FUNC_EN_OFFSET(abs_fid),\n\t\tenable);\n\tREG_WR8(bp, BAR_USTRORM_INTMEM + USTORM_FUNC_EN_OFFSET(abs_fid),\n\t\tenable);\n}\n\nstatic void storm_memset_eq_data(struct bnx2x *bp,\n\t\t\t\t struct event_ring_data *eq_data,\n\t\t\t\tu16 pfid)\n{\n\tsize_t size = sizeof(struct event_ring_data);\n\n\tu32 addr = BAR_CSTRORM_INTMEM + CSTORM_EVENT_RING_DATA_OFFSET(pfid);\n\n\t__storm_memset_struct(bp, addr, size, (u32 *)eq_data);\n}\n\nstatic void storm_memset_eq_prod(struct bnx2x *bp, u16 eq_prod,\n\t\t\t\t u16 pfid)\n{\n\tu32 addr = BAR_CSTRORM_INTMEM + CSTORM_EVENT_RING_PROD_OFFSET(pfid);\n\tREG_WR16(bp, addr, eq_prod);\n}\n\n \nstatic void bnx2x_reg_wr_ind(struct bnx2x *bp, u32 addr, u32 val)\n{\n\tpci_write_config_dword(bp->pdev, PCICFG_GRC_ADDRESS, addr);\n\tpci_write_config_dword(bp->pdev, PCICFG_GRC_DATA, val);\n\tpci_write_config_dword(bp->pdev, PCICFG_GRC_ADDRESS,\n\t\t\t       PCICFG_VENDOR_ID_OFFSET);\n}\n\nstatic u32 bnx2x_reg_rd_ind(struct bnx2x *bp, u32 addr)\n{\n\tu32 val;\n\n\tpci_write_config_dword(bp->pdev, PCICFG_GRC_ADDRESS, addr);\n\tpci_read_config_dword(bp->pdev, PCICFG_GRC_DATA, &val);\n\tpci_write_config_dword(bp->pdev, PCICFG_GRC_ADDRESS,\n\t\t\t       PCICFG_VENDOR_ID_OFFSET);\n\n\treturn val;\n}\n\n#define DMAE_DP_SRC_GRC\t\t\"grc src_addr [%08x]\"\n#define DMAE_DP_SRC_PCI\t\t\"pci src_addr [%x:%08x]\"\n#define DMAE_DP_DST_GRC\t\t\"grc dst_addr [%08x]\"\n#define DMAE_DP_DST_PCI\t\t\"pci dst_addr [%x:%08x]\"\n#define DMAE_DP_DST_NONE\t\"dst_addr [none]\"\n\nstatic void bnx2x_dp_dmae(struct bnx2x *bp,\n\t\t\t  struct dmae_command *dmae, int msglvl)\n{\n\tu32 src_type = dmae->opcode & DMAE_COMMAND_SRC;\n\tint i;\n\n\tswitch (dmae->opcode & DMAE_COMMAND_DST) {\n\tcase DMAE_CMD_DST_PCI:\n\t\tif (src_type == DMAE_CMD_SRC_PCI)\n\t\t\tDP(msglvl, \"DMAE: opcode 0x%08x\\n\"\n\t\t\t   \"src [%x:%08x], len [%d*4], dst [%x:%08x]\\n\"\n\t\t\t   \"comp_addr [%x:%08x], comp_val 0x%08x\\n\",\n\t\t\t   dmae->opcode, dmae->src_addr_hi, dmae->src_addr_lo,\n\t\t\t   dmae->len, dmae->dst_addr_hi, dmae->dst_addr_lo,\n\t\t\t   dmae->comp_addr_hi, dmae->comp_addr_lo,\n\t\t\t   dmae->comp_val);\n\t\telse\n\t\t\tDP(msglvl, \"DMAE: opcode 0x%08x\\n\"\n\t\t\t   \"src [%08x], len [%d*4], dst [%x:%08x]\\n\"\n\t\t\t   \"comp_addr [%x:%08x], comp_val 0x%08x\\n\",\n\t\t\t   dmae->opcode, dmae->src_addr_lo >> 2,\n\t\t\t   dmae->len, dmae->dst_addr_hi, dmae->dst_addr_lo,\n\t\t\t   dmae->comp_addr_hi, dmae->comp_addr_lo,\n\t\t\t   dmae->comp_val);\n\t\tbreak;\n\tcase DMAE_CMD_DST_GRC:\n\t\tif (src_type == DMAE_CMD_SRC_PCI)\n\t\t\tDP(msglvl, \"DMAE: opcode 0x%08x\\n\"\n\t\t\t   \"src [%x:%08x], len [%d*4], dst_addr [%08x]\\n\"\n\t\t\t   \"comp_addr [%x:%08x], comp_val 0x%08x\\n\",\n\t\t\t   dmae->opcode, dmae->src_addr_hi, dmae->src_addr_lo,\n\t\t\t   dmae->len, dmae->dst_addr_lo >> 2,\n\t\t\t   dmae->comp_addr_hi, dmae->comp_addr_lo,\n\t\t\t   dmae->comp_val);\n\t\telse\n\t\t\tDP(msglvl, \"DMAE: opcode 0x%08x\\n\"\n\t\t\t   \"src [%08x], len [%d*4], dst [%08x]\\n\"\n\t\t\t   \"comp_addr [%x:%08x], comp_val 0x%08x\\n\",\n\t\t\t   dmae->opcode, dmae->src_addr_lo >> 2,\n\t\t\t   dmae->len, dmae->dst_addr_lo >> 2,\n\t\t\t   dmae->comp_addr_hi, dmae->comp_addr_lo,\n\t\t\t   dmae->comp_val);\n\t\tbreak;\n\tdefault:\n\t\tif (src_type == DMAE_CMD_SRC_PCI)\n\t\t\tDP(msglvl, \"DMAE: opcode 0x%08x\\n\"\n\t\t\t   \"src_addr [%x:%08x]  len [%d * 4]  dst_addr [none]\\n\"\n\t\t\t   \"comp_addr [%x:%08x]  comp_val 0x%08x\\n\",\n\t\t\t   dmae->opcode, dmae->src_addr_hi, dmae->src_addr_lo,\n\t\t\t   dmae->len, dmae->comp_addr_hi, dmae->comp_addr_lo,\n\t\t\t   dmae->comp_val);\n\t\telse\n\t\t\tDP(msglvl, \"DMAE: opcode 0x%08x\\n\"\n\t\t\t   \"src_addr [%08x]  len [%d * 4]  dst_addr [none]\\n\"\n\t\t\t   \"comp_addr [%x:%08x]  comp_val 0x%08x\\n\",\n\t\t\t   dmae->opcode, dmae->src_addr_lo >> 2,\n\t\t\t   dmae->len, dmae->comp_addr_hi, dmae->comp_addr_lo,\n\t\t\t   dmae->comp_val);\n\t\tbreak;\n\t}\n\n\tfor (i = 0; i < (sizeof(struct dmae_command)/4); i++)\n\t\tDP(msglvl, \"DMAE RAW [%02d]: 0x%08x\\n\",\n\t\t   i, *(((u32 *)dmae) + i));\n}\n\n \nvoid bnx2x_post_dmae(struct bnx2x *bp, struct dmae_command *dmae, int idx)\n{\n\tu32 cmd_offset;\n\tint i;\n\n\tcmd_offset = (DMAE_REG_CMD_MEM + sizeof(struct dmae_command) * idx);\n\tfor (i = 0; i < (sizeof(struct dmae_command)/4); i++) {\n\t\tREG_WR(bp, cmd_offset + i*4, *(((u32 *)dmae) + i));\n\t}\n\tREG_WR(bp, dmae_reg_go_c[idx], 1);\n}\n\nu32 bnx2x_dmae_opcode_add_comp(u32 opcode, u8 comp_type)\n{\n\treturn opcode | ((comp_type << DMAE_COMMAND_C_DST_SHIFT) |\n\t\t\t   DMAE_CMD_C_ENABLE);\n}\n\nu32 bnx2x_dmae_opcode_clr_src_reset(u32 opcode)\n{\n\treturn opcode & ~DMAE_CMD_SRC_RESET;\n}\n\nu32 bnx2x_dmae_opcode(struct bnx2x *bp, u8 src_type, u8 dst_type,\n\t\t\t     bool with_comp, u8 comp_type)\n{\n\tu32 opcode = 0;\n\n\topcode |= ((src_type << DMAE_COMMAND_SRC_SHIFT) |\n\t\t   (dst_type << DMAE_COMMAND_DST_SHIFT));\n\n\topcode |= (DMAE_CMD_SRC_RESET | DMAE_CMD_DST_RESET);\n\n\topcode |= (BP_PORT(bp) ? DMAE_CMD_PORT_1 : DMAE_CMD_PORT_0);\n\topcode |= ((BP_VN(bp) << DMAE_CMD_E1HVN_SHIFT) |\n\t\t   (BP_VN(bp) << DMAE_COMMAND_DST_VN_SHIFT));\n\topcode |= (DMAE_COM_SET_ERR << DMAE_COMMAND_ERR_POLICY_SHIFT);\n\n#ifdef __BIG_ENDIAN\n\topcode |= DMAE_CMD_ENDIANITY_B_DW_SWAP;\n#else\n\topcode |= DMAE_CMD_ENDIANITY_DW_SWAP;\n#endif\n\tif (with_comp)\n\t\topcode = bnx2x_dmae_opcode_add_comp(opcode, comp_type);\n\treturn opcode;\n}\n\nvoid bnx2x_prep_dmae_with_comp(struct bnx2x *bp,\n\t\t\t\t      struct dmae_command *dmae,\n\t\t\t\t      u8 src_type, u8 dst_type)\n{\n\tmemset(dmae, 0, sizeof(struct dmae_command));\n\n\t \n\tdmae->opcode = bnx2x_dmae_opcode(bp, src_type, dst_type,\n\t\t\t\t\t true, DMAE_COMP_PCI);\n\n\t \n\tdmae->comp_addr_lo = U64_LO(bnx2x_sp_mapping(bp, wb_comp));\n\tdmae->comp_addr_hi = U64_HI(bnx2x_sp_mapping(bp, wb_comp));\n\tdmae->comp_val = DMAE_COMP_VAL;\n}\n\n \nint bnx2x_issue_dmae_with_comp(struct bnx2x *bp, struct dmae_command *dmae,\n\t\t\t       u32 *comp)\n{\n\tint cnt = CHIP_REV_IS_SLOW(bp) ? (400000) : 4000;\n\tint rc = 0;\n\n\tbnx2x_dp_dmae(bp, dmae, BNX2X_MSG_DMAE);\n\n\t \n\n\tspin_lock_bh(&bp->dmae_lock);\n\n\t \n\t*comp = 0;\n\n\t \n\tbnx2x_post_dmae(bp, dmae, INIT_DMAE_C(bp));\n\n\t \n\tudelay(5);\n\twhile ((*comp & ~DMAE_PCI_ERR_FLAG) != DMAE_COMP_VAL) {\n\n\t\tif (!cnt ||\n\t\t    (bp->recovery_state != BNX2X_RECOVERY_DONE &&\n\t\t     bp->recovery_state != BNX2X_RECOVERY_NIC_LOADING)) {\n\t\t\tBNX2X_ERR(\"DMAE timeout!\\n\");\n\t\t\trc = DMAE_TIMEOUT;\n\t\t\tgoto unlock;\n\t\t}\n\t\tcnt--;\n\t\tudelay(50);\n\t}\n\tif (*comp & DMAE_PCI_ERR_FLAG) {\n\t\tBNX2X_ERR(\"DMAE PCI error!\\n\");\n\t\trc = DMAE_PCI_ERROR;\n\t}\n\nunlock:\n\n\tspin_unlock_bh(&bp->dmae_lock);\n\n\treturn rc;\n}\n\nvoid bnx2x_write_dmae(struct bnx2x *bp, dma_addr_t dma_addr, u32 dst_addr,\n\t\t      u32 len32)\n{\n\tint rc;\n\tstruct dmae_command dmae;\n\n\tif (!bp->dmae_ready) {\n\t\tu32 *data = bnx2x_sp(bp, wb_data[0]);\n\n\t\tif (CHIP_IS_E1(bp))\n\t\t\tbnx2x_init_ind_wr(bp, dst_addr, data, len32);\n\t\telse\n\t\t\tbnx2x_init_str_wr(bp, dst_addr, data, len32);\n\t\treturn;\n\t}\n\n\t \n\tbnx2x_prep_dmae_with_comp(bp, &dmae, DMAE_SRC_PCI, DMAE_DST_GRC);\n\n\t \n\tdmae.src_addr_lo = U64_LO(dma_addr);\n\tdmae.src_addr_hi = U64_HI(dma_addr);\n\tdmae.dst_addr_lo = dst_addr >> 2;\n\tdmae.dst_addr_hi = 0;\n\tdmae.len = len32;\n\n\t \n\trc = bnx2x_issue_dmae_with_comp(bp, &dmae, bnx2x_sp(bp, wb_comp));\n\tif (rc) {\n\t\tBNX2X_ERR(\"DMAE returned failure %d\\n\", rc);\n#ifdef BNX2X_STOP_ON_ERROR\n\t\tbnx2x_panic();\n#endif\n\t}\n}\n\nvoid bnx2x_read_dmae(struct bnx2x *bp, u32 src_addr, u32 len32)\n{\n\tint rc;\n\tstruct dmae_command dmae;\n\n\tif (!bp->dmae_ready) {\n\t\tu32 *data = bnx2x_sp(bp, wb_data[0]);\n\t\tint i;\n\n\t\tif (CHIP_IS_E1(bp))\n\t\t\tfor (i = 0; i < len32; i++)\n\t\t\t\tdata[i] = bnx2x_reg_rd_ind(bp, src_addr + i*4);\n\t\telse\n\t\t\tfor (i = 0; i < len32; i++)\n\t\t\t\tdata[i] = REG_RD(bp, src_addr + i*4);\n\n\t\treturn;\n\t}\n\n\t \n\tbnx2x_prep_dmae_with_comp(bp, &dmae, DMAE_SRC_GRC, DMAE_DST_PCI);\n\n\t \n\tdmae.src_addr_lo = src_addr >> 2;\n\tdmae.src_addr_hi = 0;\n\tdmae.dst_addr_lo = U64_LO(bnx2x_sp_mapping(bp, wb_data));\n\tdmae.dst_addr_hi = U64_HI(bnx2x_sp_mapping(bp, wb_data));\n\tdmae.len = len32;\n\n\t \n\trc = bnx2x_issue_dmae_with_comp(bp, &dmae, bnx2x_sp(bp, wb_comp));\n\tif (rc) {\n\t\tBNX2X_ERR(\"DMAE returned failure %d\\n\", rc);\n#ifdef BNX2X_STOP_ON_ERROR\n\t\tbnx2x_panic();\n#endif\n\t}\n}\n\nstatic void bnx2x_write_dmae_phys_len(struct bnx2x *bp, dma_addr_t phys_addr,\n\t\t\t\t      u32 addr, u32 len)\n{\n\tint dmae_wr_max = DMAE_LEN32_WR_MAX(bp);\n\tint offset = 0;\n\n\twhile (len > dmae_wr_max) {\n\t\tbnx2x_write_dmae(bp, phys_addr + offset,\n\t\t\t\t addr + offset, dmae_wr_max);\n\t\toffset += dmae_wr_max * 4;\n\t\tlen -= dmae_wr_max;\n\t}\n\n\tbnx2x_write_dmae(bp, phys_addr + offset, addr + offset, len);\n}\n\nenum storms {\n\t   XSTORM,\n\t   TSTORM,\n\t   CSTORM,\n\t   USTORM,\n\t   MAX_STORMS\n};\n\n#define STORMS_NUM 4\n#define REGS_IN_ENTRY 4\n\nstatic inline int bnx2x_get_assert_list_entry(struct bnx2x *bp,\n\t\t\t\t\t      enum storms storm,\n\t\t\t\t\t      int entry)\n{\n\tswitch (storm) {\n\tcase XSTORM:\n\t\treturn XSTORM_ASSERT_LIST_OFFSET(entry);\n\tcase TSTORM:\n\t\treturn TSTORM_ASSERT_LIST_OFFSET(entry);\n\tcase CSTORM:\n\t\treturn CSTORM_ASSERT_LIST_OFFSET(entry);\n\tcase USTORM:\n\t\treturn USTORM_ASSERT_LIST_OFFSET(entry);\n\tcase MAX_STORMS:\n\tdefault:\n\t\tBNX2X_ERR(\"unknown storm\\n\");\n\t}\n\treturn -EINVAL;\n}\n\nstatic int bnx2x_mc_assert(struct bnx2x *bp)\n{\n\tchar last_idx;\n\tint i, j, rc = 0;\n\tenum storms storm;\n\tu32 regs[REGS_IN_ENTRY];\n\tu32 bar_storm_intmem[STORMS_NUM] = {\n\t\tBAR_XSTRORM_INTMEM,\n\t\tBAR_TSTRORM_INTMEM,\n\t\tBAR_CSTRORM_INTMEM,\n\t\tBAR_USTRORM_INTMEM\n\t};\n\tu32 storm_assert_list_index[STORMS_NUM] = {\n\t\tXSTORM_ASSERT_LIST_INDEX_OFFSET,\n\t\tTSTORM_ASSERT_LIST_INDEX_OFFSET,\n\t\tCSTORM_ASSERT_LIST_INDEX_OFFSET,\n\t\tUSTORM_ASSERT_LIST_INDEX_OFFSET\n\t};\n\tchar *storms_string[STORMS_NUM] = {\n\t\t\"XSTORM\",\n\t\t\"TSTORM\",\n\t\t\"CSTORM\",\n\t\t\"USTORM\"\n\t};\n\n\tfor (storm = XSTORM; storm < MAX_STORMS; storm++) {\n\t\tlast_idx = REG_RD8(bp, bar_storm_intmem[storm] +\n\t\t\t\t   storm_assert_list_index[storm]);\n\t\tif (last_idx)\n\t\t\tBNX2X_ERR(\"%s_ASSERT_LIST_INDEX 0x%x\\n\",\n\t\t\t\t  storms_string[storm], last_idx);\n\n\t\t \n\t\tfor (i = 0; i < STROM_ASSERT_ARRAY_SIZE; i++) {\n\t\t\t \n\t\t\tfor (j = 0; j < REGS_IN_ENTRY; j++)\n\t\t\t\tregs[j] = REG_RD(bp, bar_storm_intmem[storm] +\n\t\t\t\t\t  bnx2x_get_assert_list_entry(bp,\n\t\t\t\t\t\t\t\t      storm,\n\t\t\t\t\t\t\t\t      i) +\n\t\t\t\t\t  sizeof(u32) * j);\n\n\t\t\t \n\t\t\tif (regs[0] != COMMON_ASM_INVALID_ASSERT_OPCODE) {\n\t\t\t\tBNX2X_ERR(\"%s_ASSERT_INDEX 0x%x = 0x%08x 0x%08x 0x%08x 0x%08x\\n\",\n\t\t\t\t\t  storms_string[storm], i, regs[3],\n\t\t\t\t\t  regs[2], regs[1], regs[0]);\n\t\t\t\trc++;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tBNX2X_ERR(\"Chip Revision: %s, FW Version: %d_%d_%d\\n\",\n\t\t  CHIP_IS_E1(bp) ? \"everest1\" :\n\t\t  CHIP_IS_E1H(bp) ? \"everest1h\" :\n\t\t  CHIP_IS_E2(bp) ? \"everest2\" : \"everest3\",\n\t\t  bp->fw_major, bp->fw_minor, bp->fw_rev);\n\n\treturn rc;\n}\n\n#define MCPR_TRACE_BUFFER_SIZE\t(0x800)\n#define SCRATCH_BUFFER_SIZE(bp)\t\\\n\t(CHIP_IS_E1(bp) ? 0x10000 : (CHIP_IS_E1H(bp) ? 0x20000 : 0x28000))\n\nvoid bnx2x_fw_dump_lvl(struct bnx2x *bp, const char *lvl)\n{\n\tu32 addr, val;\n\tu32 mark, offset;\n\t__be32 data[9];\n\tint word;\n\tu32 trace_shmem_base;\n\tif (BP_NOMCP(bp)) {\n\t\tBNX2X_ERR(\"NO MCP - can not dump\\n\");\n\t\treturn;\n\t}\n\tnetdev_printk(lvl, bp->dev, \"bc %d.%d.%d\\n\",\n\t\t(bp->common.bc_ver & 0xff0000) >> 16,\n\t\t(bp->common.bc_ver & 0xff00) >> 8,\n\t\t(bp->common.bc_ver & 0xff));\n\n\tif (pci_channel_offline(bp->pdev)) {\n\t\tBNX2X_ERR(\"Cannot dump MCP info while in PCI error\\n\");\n\t\treturn;\n\t}\n\n\tval = REG_RD(bp, MCP_REG_MCPR_CPU_PROGRAM_COUNTER);\n\tif (val == REG_RD(bp, MCP_REG_MCPR_CPU_PROGRAM_COUNTER))\n\t\tBNX2X_ERR(\"%s\" \"MCP PC at 0x%x\\n\", lvl, val);\n\n\tif (BP_PATH(bp) == 0)\n\t\ttrace_shmem_base = bp->common.shmem_base;\n\telse\n\t\ttrace_shmem_base = SHMEM2_RD(bp, other_shmem_base_addr);\n\n\t \n\tif (trace_shmem_base < MCPR_SCRATCH_BASE(bp) + MCPR_TRACE_BUFFER_SIZE ||\n\t    trace_shmem_base >= MCPR_SCRATCH_BASE(bp) +\n\t\t\t\tSCRATCH_BUFFER_SIZE(bp)) {\n\t\tBNX2X_ERR(\"Unable to dump trace buffer (mark %x)\\n\",\n\t\t\t  trace_shmem_base);\n\t\treturn;\n\t}\n\n\taddr = trace_shmem_base - MCPR_TRACE_BUFFER_SIZE;\n\n\t \n\tmark = REG_RD(bp, addr);\n\tif (mark != MFW_TRACE_SIGNATURE) {\n\t\tBNX2X_ERR(\"Trace buffer signature is missing.\");\n\t\treturn ;\n\t}\n\n\t \n\taddr += 4;\n\tmark = REG_RD(bp, addr);\n\tmark = MCPR_SCRATCH_BASE(bp) + ((mark + 0x3) & ~0x3) - 0x08000000;\n\tif (mark >= trace_shmem_base || mark < addr + 4) {\n\t\tBNX2X_ERR(\"Mark doesn't fall inside Trace Buffer\\n\");\n\t\treturn;\n\t}\n\tprintk(\"%s\" \"begin fw dump (mark 0x%x)\\n\", lvl, mark);\n\n\tprintk(\"%s\", lvl);\n\n\t \n\tfor (offset = mark; offset < trace_shmem_base; offset += 0x8*4) {\n\t\tfor (word = 0; word < 8; word++)\n\t\t\tdata[word] = htonl(REG_RD(bp, offset + 4*word));\n\t\tdata[8] = 0x0;\n\t\tpr_cont(\"%s\", (char *)data);\n\t}\n\n\t \n\tfor (offset = addr + 4; offset <= mark; offset += 0x8*4) {\n\t\tfor (word = 0; word < 8; word++)\n\t\t\tdata[word] = htonl(REG_RD(bp, offset + 4*word));\n\t\tdata[8] = 0x0;\n\t\tpr_cont(\"%s\", (char *)data);\n\t}\n\tprintk(\"%s\" \"end of fw dump\\n\", lvl);\n}\n\nstatic void bnx2x_fw_dump(struct bnx2x *bp)\n{\n\tbnx2x_fw_dump_lvl(bp, KERN_ERR);\n}\n\nstatic void bnx2x_hc_int_disable(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tu32 addr = port ? HC_REG_CONFIG_1 : HC_REG_CONFIG_0;\n\tu32 val = REG_RD(bp, addr);\n\n\t \n\tif (CHIP_IS_E1(bp)) {\n\t\t \n\t\tREG_WR(bp, HC_REG_INT_MASK + port*4, 0);\n\n\t\tval &= ~(HC_CONFIG_0_REG_SINGLE_ISR_EN_0 |\n\t\t\t HC_CONFIG_0_REG_INT_LINE_EN_0 |\n\t\t\t HC_CONFIG_0_REG_ATTN_BIT_EN_0);\n\t} else\n\t\tval &= ~(HC_CONFIG_0_REG_SINGLE_ISR_EN_0 |\n\t\t\t HC_CONFIG_0_REG_MSI_MSIX_INT_EN_0 |\n\t\t\t HC_CONFIG_0_REG_INT_LINE_EN_0 |\n\t\t\t HC_CONFIG_0_REG_ATTN_BIT_EN_0);\n\n\tDP(NETIF_MSG_IFDOWN,\n\t   \"write %x to HC %d (addr 0x%x)\\n\",\n\t   val, port, addr);\n\n\tREG_WR(bp, addr, val);\n\tif (REG_RD(bp, addr) != val)\n\t\tBNX2X_ERR(\"BUG! Proper val not read from IGU!\\n\");\n}\n\nstatic void bnx2x_igu_int_disable(struct bnx2x *bp)\n{\n\tu32 val = REG_RD(bp, IGU_REG_PF_CONFIGURATION);\n\n\tval &= ~(IGU_PF_CONF_MSI_MSIX_EN |\n\t\t IGU_PF_CONF_INT_LINE_EN |\n\t\t IGU_PF_CONF_ATTN_BIT_EN);\n\n\tDP(NETIF_MSG_IFDOWN, \"write %x to IGU\\n\", val);\n\n\tREG_WR(bp, IGU_REG_PF_CONFIGURATION, val);\n\tif (REG_RD(bp, IGU_REG_PF_CONFIGURATION) != val)\n\t\tBNX2X_ERR(\"BUG! Proper val not read from IGU!\\n\");\n}\n\nstatic void bnx2x_int_disable(struct bnx2x *bp)\n{\n\tif (bp->common.int_block == INT_BLOCK_HC)\n\t\tbnx2x_hc_int_disable(bp);\n\telse\n\t\tbnx2x_igu_int_disable(bp);\n}\n\nvoid bnx2x_panic_dump(struct bnx2x *bp, bool disable_int)\n{\n\tint i;\n\tu16 j;\n\tstruct hc_sp_status_block_data sp_sb_data;\n\tint func = BP_FUNC(bp);\n#ifdef BNX2X_STOP_ON_ERROR\n\tu16 start = 0, end = 0;\n\tu8 cos;\n#endif\n\tif (IS_PF(bp) && disable_int)\n\t\tbnx2x_int_disable(bp);\n\n\tbp->stats_state = STATS_STATE_DISABLED;\n\tbp->eth_stats.unrecoverable_error++;\n\tDP(BNX2X_MSG_STATS, \"stats_state - DISABLED\\n\");\n\n\tBNX2X_ERR(\"begin crash dump -----------------\\n\");\n\n\t \n\t \n\tif (IS_PF(bp)) {\n\t\tstruct host_sp_status_block *def_sb = bp->def_status_blk;\n\t\tint data_size, cstorm_offset;\n\n\t\tBNX2X_ERR(\"def_idx(0x%x)  def_att_idx(0x%x)  attn_state(0x%x)  spq_prod_idx(0x%x) next_stats_cnt(0x%x)\\n\",\n\t\t\t  bp->def_idx, bp->def_att_idx, bp->attn_state,\n\t\t\t  bp->spq_prod_idx, bp->stats_counter);\n\t\tBNX2X_ERR(\"DSB: attn bits(0x%x)  ack(0x%x)  id(0x%x)  idx(0x%x)\\n\",\n\t\t\t  def_sb->atten_status_block.attn_bits,\n\t\t\t  def_sb->atten_status_block.attn_bits_ack,\n\t\t\t  def_sb->atten_status_block.status_block_id,\n\t\t\t  def_sb->atten_status_block.attn_bits_index);\n\t\tBNX2X_ERR(\"     def (\");\n\t\tfor (i = 0; i < HC_SP_SB_MAX_INDICES; i++)\n\t\t\tpr_cont(\"0x%x%s\",\n\t\t\t\tdef_sb->sp_sb.index_values[i],\n\t\t\t\t(i == HC_SP_SB_MAX_INDICES - 1) ? \")  \" : \" \");\n\n\t\tdata_size = sizeof(struct hc_sp_status_block_data) /\n\t\t\t    sizeof(u32);\n\t\tcstorm_offset = CSTORM_SP_STATUS_BLOCK_DATA_OFFSET(func);\n\t\tfor (i = 0; i < data_size; i++)\n\t\t\t*((u32 *)&sp_sb_data + i) =\n\t\t\t\tREG_RD(bp, BAR_CSTRORM_INTMEM + cstorm_offset +\n\t\t\t\t\t   i * sizeof(u32));\n\n\t\tpr_cont(\"igu_sb_id(0x%x)  igu_seg_id(0x%x) pf_id(0x%x)  vnic_id(0x%x)  vf_id(0x%x)  vf_valid (0x%x) state(0x%x)\\n\",\n\t\t\tsp_sb_data.igu_sb_id,\n\t\t\tsp_sb_data.igu_seg_id,\n\t\t\tsp_sb_data.p_func.pf_id,\n\t\t\tsp_sb_data.p_func.vnic_id,\n\t\t\tsp_sb_data.p_func.vf_id,\n\t\t\tsp_sb_data.p_func.vf_valid,\n\t\t\tsp_sb_data.state);\n\t}\n\n\tfor_each_eth_queue(bp, i) {\n\t\tstruct bnx2x_fastpath *fp = &bp->fp[i];\n\t\tint loop;\n\t\tstruct hc_status_block_data_e2 sb_data_e2;\n\t\tstruct hc_status_block_data_e1x sb_data_e1x;\n\t\tstruct hc_status_block_sm  *hc_sm_p =\n\t\t\tCHIP_IS_E1x(bp) ?\n\t\t\tsb_data_e1x.common.state_machine :\n\t\t\tsb_data_e2.common.state_machine;\n\t\tstruct hc_index_data *hc_index_p =\n\t\t\tCHIP_IS_E1x(bp) ?\n\t\t\tsb_data_e1x.index_data :\n\t\t\tsb_data_e2.index_data;\n\t\tu8 data_size, cos;\n\t\tu32 *sb_data_p;\n\t\tstruct bnx2x_fp_txdata txdata;\n\n\t\tif (!bp->fp)\n\t\t\tbreak;\n\n\t\tif (!fp->rx_cons_sb)\n\t\t\tcontinue;\n\n\t\t \n\t\tBNX2X_ERR(\"fp%d: rx_bd_prod(0x%x)  rx_bd_cons(0x%x)  rx_comp_prod(0x%x)  rx_comp_cons(0x%x)  *rx_cons_sb(0x%x)\\n\",\n\t\t\t  i, fp->rx_bd_prod, fp->rx_bd_cons,\n\t\t\t  fp->rx_comp_prod,\n\t\t\t  fp->rx_comp_cons, le16_to_cpu(*fp->rx_cons_sb));\n\t\tBNX2X_ERR(\"     rx_sge_prod(0x%x)  last_max_sge(0x%x)  fp_hc_idx(0x%x)\\n\",\n\t\t\t  fp->rx_sge_prod, fp->last_max_sge,\n\t\t\t  le16_to_cpu(fp->fp_hc_idx));\n\n\t\t \n\t\tfor_each_cos_in_tx_queue(fp, cos)\n\t\t{\n\t\t\tif (!fp->txdata_ptr[cos])\n\t\t\t\tbreak;\n\n\t\t\ttxdata = *fp->txdata_ptr[cos];\n\n\t\t\tif (!txdata.tx_cons_sb)\n\t\t\t\tcontinue;\n\n\t\t\tBNX2X_ERR(\"fp%d: tx_pkt_prod(0x%x)  tx_pkt_cons(0x%x)  tx_bd_prod(0x%x)  tx_bd_cons(0x%x)  *tx_cons_sb(0x%x)\\n\",\n\t\t\t\t  i, txdata.tx_pkt_prod,\n\t\t\t\t  txdata.tx_pkt_cons, txdata.tx_bd_prod,\n\t\t\t\t  txdata.tx_bd_cons,\n\t\t\t\t  le16_to_cpu(*txdata.tx_cons_sb));\n\t\t}\n\n\t\tloop = CHIP_IS_E1x(bp) ?\n\t\t\tHC_SB_MAX_INDICES_E1X : HC_SB_MAX_INDICES_E2;\n\n\t\t \n\n\t\tif (IS_FCOE_FP(fp))\n\t\t\tcontinue;\n\n\t\tBNX2X_ERR(\"     run indexes (\");\n\t\tfor (j = 0; j < HC_SB_MAX_SM; j++)\n\t\t\tpr_cont(\"0x%x%s\",\n\t\t\t       fp->sb_running_index[j],\n\t\t\t       (j == HC_SB_MAX_SM - 1) ? \")\" : \" \");\n\n\t\tBNX2X_ERR(\"     indexes (\");\n\t\tfor (j = 0; j < loop; j++)\n\t\t\tpr_cont(\"0x%x%s\",\n\t\t\t       fp->sb_index_values[j],\n\t\t\t       (j == loop - 1) ? \")\" : \" \");\n\n\t\t \n\t\tif (IS_VF(bp))\n\t\t\tcontinue;\n\n\t\t \n\t\tdata_size = CHIP_IS_E1x(bp) ?\n\t\t\tsizeof(struct hc_status_block_data_e1x) :\n\t\t\tsizeof(struct hc_status_block_data_e2);\n\t\tdata_size /= sizeof(u32);\n\t\tsb_data_p = CHIP_IS_E1x(bp) ?\n\t\t\t(u32 *)&sb_data_e1x :\n\t\t\t(u32 *)&sb_data_e2;\n\t\t \n\t\tfor (j = 0; j < data_size; j++)\n\t\t\t*(sb_data_p + j) = REG_RD(bp, BAR_CSTRORM_INTMEM +\n\t\t\t\tCSTORM_STATUS_BLOCK_DATA_OFFSET(fp->fw_sb_id) +\n\t\t\t\tj * sizeof(u32));\n\n\t\tif (!CHIP_IS_E1x(bp)) {\n\t\t\tpr_cont(\"pf_id(0x%x)  vf_id(0x%x)  vf_valid(0x%x) vnic_id(0x%x)  same_igu_sb_1b(0x%x) state(0x%x)\\n\",\n\t\t\t\tsb_data_e2.common.p_func.pf_id,\n\t\t\t\tsb_data_e2.common.p_func.vf_id,\n\t\t\t\tsb_data_e2.common.p_func.vf_valid,\n\t\t\t\tsb_data_e2.common.p_func.vnic_id,\n\t\t\t\tsb_data_e2.common.same_igu_sb_1b,\n\t\t\t\tsb_data_e2.common.state);\n\t\t} else {\n\t\t\tpr_cont(\"pf_id(0x%x)  vf_id(0x%x)  vf_valid(0x%x) vnic_id(0x%x)  same_igu_sb_1b(0x%x) state(0x%x)\\n\",\n\t\t\t\tsb_data_e1x.common.p_func.pf_id,\n\t\t\t\tsb_data_e1x.common.p_func.vf_id,\n\t\t\t\tsb_data_e1x.common.p_func.vf_valid,\n\t\t\t\tsb_data_e1x.common.p_func.vnic_id,\n\t\t\t\tsb_data_e1x.common.same_igu_sb_1b,\n\t\t\t\tsb_data_e1x.common.state);\n\t\t}\n\n\t\t \n\t\tfor (j = 0; j < HC_SB_MAX_SM; j++) {\n\t\t\tpr_cont(\"SM[%d] __flags (0x%x) igu_sb_id (0x%x)  igu_seg_id(0x%x) time_to_expire (0x%x) timer_value(0x%x)\\n\",\n\t\t\t\tj, hc_sm_p[j].__flags,\n\t\t\t\thc_sm_p[j].igu_sb_id,\n\t\t\t\thc_sm_p[j].igu_seg_id,\n\t\t\t\thc_sm_p[j].time_to_expire,\n\t\t\t\thc_sm_p[j].timer_value);\n\t\t}\n\n\t\t \n\t\tfor (j = 0; j < loop; j++) {\n\t\t\tpr_cont(\"INDEX[%d] flags (0x%x) timeout (0x%x)\\n\", j,\n\t\t\t       hc_index_p[j].flags,\n\t\t\t       hc_index_p[j].timeout);\n\t\t}\n\t}\n\n#ifdef BNX2X_STOP_ON_ERROR\n\tif (IS_PF(bp)) {\n\t\t \n\t\tBNX2X_ERR(\"eq cons %x prod %x\\n\", bp->eq_cons, bp->eq_prod);\n\t\tfor (i = 0; i < NUM_EQ_DESC; i++) {\n\t\t\tu32 *data = (u32 *)&bp->eq_ring[i].message.data;\n\n\t\t\tBNX2X_ERR(\"event queue [%d]: header: opcode %d, error %d\\n\",\n\t\t\t\t  i, bp->eq_ring[i].message.opcode,\n\t\t\t\t  bp->eq_ring[i].message.error);\n\t\t\tBNX2X_ERR(\"data: %x %x %x\\n\",\n\t\t\t\t  data[0], data[1], data[2]);\n\t\t}\n\t}\n\n\t \n\t \n\tfor_each_valid_rx_queue(bp, i) {\n\t\tstruct bnx2x_fastpath *fp = &bp->fp[i];\n\n\t\tif (!bp->fp)\n\t\t\tbreak;\n\n\t\tif (!fp->rx_cons_sb)\n\t\t\tcontinue;\n\n\t\tstart = RX_BD(le16_to_cpu(*fp->rx_cons_sb) - 10);\n\t\tend = RX_BD(le16_to_cpu(*fp->rx_cons_sb) + 503);\n\t\tfor (j = start; j != end; j = RX_BD(j + 1)) {\n\t\t\tu32 *rx_bd = (u32 *)&fp->rx_desc_ring[j];\n\t\t\tstruct sw_rx_bd *sw_bd = &fp->rx_buf_ring[j];\n\n\t\t\tBNX2X_ERR(\"fp%d: rx_bd[%x]=[%x:%x]  sw_bd=[%p]\\n\",\n\t\t\t\t  i, j, rx_bd[1], rx_bd[0], sw_bd->data);\n\t\t}\n\n\t\tstart = RX_SGE(fp->rx_sge_prod);\n\t\tend = RX_SGE(fp->last_max_sge);\n\t\tfor (j = start; j != end; j = RX_SGE(j + 1)) {\n\t\t\tu32 *rx_sge = (u32 *)&fp->rx_sge_ring[j];\n\t\t\tstruct sw_rx_page *sw_page = &fp->rx_page_ring[j];\n\n\t\t\tBNX2X_ERR(\"fp%d: rx_sge[%x]=[%x:%x]  sw_page=[%p]\\n\",\n\t\t\t\t  i, j, rx_sge[1], rx_sge[0], sw_page->page);\n\t\t}\n\n\t\tstart = RCQ_BD(fp->rx_comp_cons - 10);\n\t\tend = RCQ_BD(fp->rx_comp_cons + 503);\n\t\tfor (j = start; j != end; j = RCQ_BD(j + 1)) {\n\t\t\tu32 *cqe = (u32 *)&fp->rx_comp_ring[j];\n\n\t\t\tBNX2X_ERR(\"fp%d: cqe[%x]=[%x:%x:%x:%x]\\n\",\n\t\t\t\t  i, j, cqe[0], cqe[1], cqe[2], cqe[3]);\n\t\t}\n\t}\n\n\t \n\tfor_each_valid_tx_queue(bp, i) {\n\t\tstruct bnx2x_fastpath *fp = &bp->fp[i];\n\n\t\tif (!bp->fp)\n\t\t\tbreak;\n\n\t\tfor_each_cos_in_tx_queue(fp, cos) {\n\t\t\tstruct bnx2x_fp_txdata *txdata = fp->txdata_ptr[cos];\n\n\t\t\tif (!fp->txdata_ptr[cos])\n\t\t\t\tbreak;\n\n\t\t\tif (!txdata->tx_cons_sb)\n\t\t\t\tcontinue;\n\n\t\t\tstart = TX_BD(le16_to_cpu(*txdata->tx_cons_sb) - 10);\n\t\t\tend = TX_BD(le16_to_cpu(*txdata->tx_cons_sb) + 245);\n\t\t\tfor (j = start; j != end; j = TX_BD(j + 1)) {\n\t\t\t\tstruct sw_tx_bd *sw_bd =\n\t\t\t\t\t&txdata->tx_buf_ring[j];\n\n\t\t\t\tBNX2X_ERR(\"fp%d: txdata %d, packet[%x]=[%p,%x]\\n\",\n\t\t\t\t\t  i, cos, j, sw_bd->skb,\n\t\t\t\t\t  sw_bd->first_bd);\n\t\t\t}\n\n\t\t\tstart = TX_BD(txdata->tx_bd_cons - 10);\n\t\t\tend = TX_BD(txdata->tx_bd_cons + 254);\n\t\t\tfor (j = start; j != end; j = TX_BD(j + 1)) {\n\t\t\t\tu32 *tx_bd = (u32 *)&txdata->tx_desc_ring[j];\n\n\t\t\t\tBNX2X_ERR(\"fp%d: txdata %d, tx_bd[%x]=[%x:%x:%x:%x]\\n\",\n\t\t\t\t\t  i, cos, j, tx_bd[0], tx_bd[1],\n\t\t\t\t\t  tx_bd[2], tx_bd[3]);\n\t\t\t}\n\t\t}\n\t}\n#endif\n\tif (IS_PF(bp)) {\n\t\tint tmp_msg_en = bp->msg_enable;\n\n\t\tbnx2x_fw_dump(bp);\n\t\tbp->msg_enable |= NETIF_MSG_HW;\n\t\tBNX2X_ERR(\"Idle check (1st round) ----------\\n\");\n\t\tbnx2x_idle_chk(bp);\n\t\tBNX2X_ERR(\"Idle check (2nd round) ----------\\n\");\n\t\tbnx2x_idle_chk(bp);\n\t\tbp->msg_enable = tmp_msg_en;\n\t\tbnx2x_mc_assert(bp);\n\t}\n\n\tBNX2X_ERR(\"end crash dump -----------------\\n\");\n}\n\n \n#define FLR_WAIT_USEC\t\t10000\t \n#define FLR_WAIT_INTERVAL\t50\t \n#define\tFLR_POLL_CNT\t\t(FLR_WAIT_USEC/FLR_WAIT_INTERVAL)  \n\nstruct pbf_pN_buf_regs {\n\tint pN;\n\tu32 init_crd;\n\tu32 crd;\n\tu32 crd_freed;\n};\n\nstruct pbf_pN_cmd_regs {\n\tint pN;\n\tu32 lines_occup;\n\tu32 lines_freed;\n};\n\nstatic void bnx2x_pbf_pN_buf_flushed(struct bnx2x *bp,\n\t\t\t\t     struct pbf_pN_buf_regs *regs,\n\t\t\t\t     u32 poll_count)\n{\n\tu32 init_crd, crd, crd_start, crd_freed, crd_freed_start;\n\tu32 cur_cnt = poll_count;\n\n\tcrd_freed = crd_freed_start = REG_RD(bp, regs->crd_freed);\n\tcrd = crd_start = REG_RD(bp, regs->crd);\n\tinit_crd = REG_RD(bp, regs->init_crd);\n\n\tDP(BNX2X_MSG_SP, \"INIT CREDIT[%d] : %x\\n\", regs->pN, init_crd);\n\tDP(BNX2X_MSG_SP, \"CREDIT[%d]      : s:%x\\n\", regs->pN, crd);\n\tDP(BNX2X_MSG_SP, \"CREDIT_FREED[%d]: s:%x\\n\", regs->pN, crd_freed);\n\n\twhile ((crd != init_crd) && ((u32)SUB_S32(crd_freed, crd_freed_start) <\n\t       (init_crd - crd_start))) {\n\t\tif (cur_cnt--) {\n\t\t\tudelay(FLR_WAIT_INTERVAL);\n\t\t\tcrd = REG_RD(bp, regs->crd);\n\t\t\tcrd_freed = REG_RD(bp, regs->crd_freed);\n\t\t} else {\n\t\t\tDP(BNX2X_MSG_SP, \"PBF tx buffer[%d] timed out\\n\",\n\t\t\t   regs->pN);\n\t\t\tDP(BNX2X_MSG_SP, \"CREDIT[%d]      : c:%x\\n\",\n\t\t\t   regs->pN, crd);\n\t\t\tDP(BNX2X_MSG_SP, \"CREDIT_FREED[%d]: c:%x\\n\",\n\t\t\t   regs->pN, crd_freed);\n\t\t\tbreak;\n\t\t}\n\t}\n\tDP(BNX2X_MSG_SP, \"Waited %d*%d usec for PBF tx buffer[%d]\\n\",\n\t   poll_count-cur_cnt, FLR_WAIT_INTERVAL, regs->pN);\n}\n\nstatic void bnx2x_pbf_pN_cmd_flushed(struct bnx2x *bp,\n\t\t\t\t     struct pbf_pN_cmd_regs *regs,\n\t\t\t\t     u32 poll_count)\n{\n\tu32 occup, to_free, freed, freed_start;\n\tu32 cur_cnt = poll_count;\n\n\toccup = to_free = REG_RD(bp, regs->lines_occup);\n\tfreed = freed_start = REG_RD(bp, regs->lines_freed);\n\n\tDP(BNX2X_MSG_SP, \"OCCUPANCY[%d]   : s:%x\\n\", regs->pN, occup);\n\tDP(BNX2X_MSG_SP, \"LINES_FREED[%d] : s:%x\\n\", regs->pN, freed);\n\n\twhile (occup && ((u32)SUB_S32(freed, freed_start) < to_free)) {\n\t\tif (cur_cnt--) {\n\t\t\tudelay(FLR_WAIT_INTERVAL);\n\t\t\toccup = REG_RD(bp, regs->lines_occup);\n\t\t\tfreed = REG_RD(bp, regs->lines_freed);\n\t\t} else {\n\t\t\tDP(BNX2X_MSG_SP, \"PBF cmd queue[%d] timed out\\n\",\n\t\t\t   regs->pN);\n\t\t\tDP(BNX2X_MSG_SP, \"OCCUPANCY[%d]   : s:%x\\n\",\n\t\t\t   regs->pN, occup);\n\t\t\tDP(BNX2X_MSG_SP, \"LINES_FREED[%d] : s:%x\\n\",\n\t\t\t   regs->pN, freed);\n\t\t\tbreak;\n\t\t}\n\t}\n\tDP(BNX2X_MSG_SP, \"Waited %d*%d usec for PBF cmd queue[%d]\\n\",\n\t   poll_count-cur_cnt, FLR_WAIT_INTERVAL, regs->pN);\n}\n\nstatic u32 bnx2x_flr_clnup_reg_poll(struct bnx2x *bp, u32 reg,\n\t\t\t\t    u32 expected, u32 poll_count)\n{\n\tu32 cur_cnt = poll_count;\n\tu32 val;\n\n\twhile ((val = REG_RD(bp, reg)) != expected && cur_cnt--)\n\t\tudelay(FLR_WAIT_INTERVAL);\n\n\treturn val;\n}\n\nint bnx2x_flr_clnup_poll_hw_counter(struct bnx2x *bp, u32 reg,\n\t\t\t\t    char *msg, u32 poll_cnt)\n{\n\tu32 val = bnx2x_flr_clnup_reg_poll(bp, reg, 0, poll_cnt);\n\tif (val != 0) {\n\t\tBNX2X_ERR(\"%s usage count=%d\\n\", msg, val);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nu32 bnx2x_flr_clnup_poll_count(struct bnx2x *bp)\n{\n\t \n\tif (CHIP_REV_IS_EMUL(bp))\n\t\treturn FLR_POLL_CNT * 2000;\n\n\tif (CHIP_REV_IS_FPGA(bp))\n\t\treturn FLR_POLL_CNT * 120;\n\n\treturn FLR_POLL_CNT;\n}\n\nvoid bnx2x_tx_hw_flushed(struct bnx2x *bp, u32 poll_count)\n{\n\tstruct pbf_pN_cmd_regs cmd_regs[] = {\n\t\t{0, (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_TQ_OCCUPANCY_Q0 :\n\t\t\tPBF_REG_P0_TQ_OCCUPANCY,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_TQ_LINES_FREED_CNT_Q0 :\n\t\t\tPBF_REG_P0_TQ_LINES_FREED_CNT},\n\t\t{1, (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_TQ_OCCUPANCY_Q1 :\n\t\t\tPBF_REG_P1_TQ_OCCUPANCY,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_TQ_LINES_FREED_CNT_Q1 :\n\t\t\tPBF_REG_P1_TQ_LINES_FREED_CNT},\n\t\t{4, (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_TQ_OCCUPANCY_LB_Q :\n\t\t\tPBF_REG_P4_TQ_OCCUPANCY,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_TQ_LINES_FREED_CNT_LB_Q :\n\t\t\tPBF_REG_P4_TQ_LINES_FREED_CNT}\n\t};\n\n\tstruct pbf_pN_buf_regs buf_regs[] = {\n\t\t{0, (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_INIT_CRD_Q0 :\n\t\t\tPBF_REG_P0_INIT_CRD ,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_CREDIT_Q0 :\n\t\t\tPBF_REG_P0_CREDIT,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_INTERNAL_CRD_FREED_CNT_Q0 :\n\t\t\tPBF_REG_P0_INTERNAL_CRD_FREED_CNT},\n\t\t{1, (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_INIT_CRD_Q1 :\n\t\t\tPBF_REG_P1_INIT_CRD,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_CREDIT_Q1 :\n\t\t\tPBF_REG_P1_CREDIT,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_INTERNAL_CRD_FREED_CNT_Q1 :\n\t\t\tPBF_REG_P1_INTERNAL_CRD_FREED_CNT},\n\t\t{4, (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_INIT_CRD_LB_Q :\n\t\t\tPBF_REG_P4_INIT_CRD,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_CREDIT_LB_Q :\n\t\t\tPBF_REG_P4_CREDIT,\n\t\t    (CHIP_IS_E3B0(bp)) ?\n\t\t\tPBF_REG_INTERNAL_CRD_FREED_CNT_LB_Q :\n\t\t\tPBF_REG_P4_INTERNAL_CRD_FREED_CNT},\n\t};\n\n\tint i;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(cmd_regs); i++)\n\t\tbnx2x_pbf_pN_cmd_flushed(bp, &cmd_regs[i], poll_count);\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(buf_regs); i++)\n\t\tbnx2x_pbf_pN_buf_flushed(bp, &buf_regs[i], poll_count);\n}\n\n#define OP_GEN_PARAM(param) \\\n\t(((param) << SDM_OP_GEN_COMP_PARAM_SHIFT) & SDM_OP_GEN_COMP_PARAM)\n\n#define OP_GEN_TYPE(type) \\\n\t(((type) << SDM_OP_GEN_COMP_TYPE_SHIFT) & SDM_OP_GEN_COMP_TYPE)\n\n#define OP_GEN_AGG_VECT(index) \\\n\t(((index) << SDM_OP_GEN_AGG_VECT_IDX_SHIFT) & SDM_OP_GEN_AGG_VECT_IDX)\n\nint bnx2x_send_final_clnup(struct bnx2x *bp, u8 clnup_func, u32 poll_cnt)\n{\n\tu32 op_gen_command = 0;\n\tu32 comp_addr = BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_FINAL_CLEANUP_COMPLETE_OFFSET(clnup_func);\n\n\tif (REG_RD(bp, comp_addr)) {\n\t\tBNX2X_ERR(\"Cleanup complete was not 0 before sending\\n\");\n\t\treturn 1;\n\t}\n\n\top_gen_command |= OP_GEN_PARAM(XSTORM_AGG_INT_FINAL_CLEANUP_INDEX);\n\top_gen_command |= OP_GEN_TYPE(XSTORM_AGG_INT_FINAL_CLEANUP_COMP_TYPE);\n\top_gen_command |= OP_GEN_AGG_VECT(clnup_func);\n\top_gen_command |= 1 << SDM_OP_GEN_AGG_VECT_IDX_VALID_SHIFT;\n\n\tDP(BNX2X_MSG_SP, \"sending FW Final cleanup\\n\");\n\tREG_WR(bp, XSDM_REG_OPERATION_GEN, op_gen_command);\n\n\tif (bnx2x_flr_clnup_reg_poll(bp, comp_addr, 1, poll_cnt) != 1) {\n\t\tBNX2X_ERR(\"FW final cleanup did not succeed\\n\");\n\t\tDP(BNX2X_MSG_SP, \"At timeout completion address contained %x\\n\",\n\t\t   (REG_RD(bp, comp_addr)));\n\t\tbnx2x_panic();\n\t\treturn 1;\n\t}\n\t \n\tREG_WR(bp, comp_addr, 0);\n\n\treturn 0;\n}\n\nu8 bnx2x_is_pcie_pending(struct pci_dev *dev)\n{\n\tu16 status;\n\n\tpcie_capability_read_word(dev, PCI_EXP_DEVSTA, &status);\n\treturn status & PCI_EXP_DEVSTA_TRPND;\n}\n\n \nstatic int bnx2x_poll_hw_usage_counters(struct bnx2x *bp, u32 poll_cnt)\n{\n\t \n\tif (bnx2x_flr_clnup_poll_hw_counter(bp,\n\t\t\tCFC_REG_NUM_LCIDS_INSIDE_PF,\n\t\t\t\"CFC PF usage counter timed out\",\n\t\t\tpoll_cnt))\n\t\treturn 1;\n\n\t \n\tif (bnx2x_flr_clnup_poll_hw_counter(bp,\n\t\t\tDORQ_REG_PF_USAGE_CNT,\n\t\t\t\"DQ PF usage counter timed out\",\n\t\t\tpoll_cnt))\n\t\treturn 1;\n\n\t \n\tif (bnx2x_flr_clnup_poll_hw_counter(bp,\n\t\t\tQM_REG_PF_USG_CNT_0 + 4*BP_FUNC(bp),\n\t\t\t\"QM PF usage counter timed out\",\n\t\t\tpoll_cnt))\n\t\treturn 1;\n\n\t \n\tif (bnx2x_flr_clnup_poll_hw_counter(bp,\n\t\t\tTM_REG_LIN0_VNIC_UC + 4*BP_PORT(bp),\n\t\t\t\"Timers VNIC usage counter timed out\",\n\t\t\tpoll_cnt))\n\t\treturn 1;\n\tif (bnx2x_flr_clnup_poll_hw_counter(bp,\n\t\t\tTM_REG_LIN0_NUM_SCANS + 4*BP_PORT(bp),\n\t\t\t\"Timers NUM_SCANS usage counter timed out\",\n\t\t\tpoll_cnt))\n\t\treturn 1;\n\n\t \n\tif (bnx2x_flr_clnup_poll_hw_counter(bp,\n\t\t\tdmae_reg_go_c[INIT_DMAE_C(bp)],\n\t\t\t\"DMAE command register timed out\",\n\t\t\tpoll_cnt))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic void bnx2x_hw_enable_status(struct bnx2x *bp)\n{\n\tu32 val;\n\n\tval = REG_RD(bp, CFC_REG_WEAK_ENABLE_PF);\n\tDP(BNX2X_MSG_SP, \"CFC_REG_WEAK_ENABLE_PF is 0x%x\\n\", val);\n\n\tval = REG_RD(bp, PBF_REG_DISABLE_PF);\n\tDP(BNX2X_MSG_SP, \"PBF_REG_DISABLE_PF is 0x%x\\n\", val);\n\n\tval = REG_RD(bp, IGU_REG_PCI_PF_MSI_EN);\n\tDP(BNX2X_MSG_SP, \"IGU_REG_PCI_PF_MSI_EN is 0x%x\\n\", val);\n\n\tval = REG_RD(bp, IGU_REG_PCI_PF_MSIX_EN);\n\tDP(BNX2X_MSG_SP, \"IGU_REG_PCI_PF_MSIX_EN is 0x%x\\n\", val);\n\n\tval = REG_RD(bp, IGU_REG_PCI_PF_MSIX_FUNC_MASK);\n\tDP(BNX2X_MSG_SP, \"IGU_REG_PCI_PF_MSIX_FUNC_MASK is 0x%x\\n\", val);\n\n\tval = REG_RD(bp, PGLUE_B_REG_SHADOW_BME_PF_7_0_CLR);\n\tDP(BNX2X_MSG_SP, \"PGLUE_B_REG_SHADOW_BME_PF_7_0_CLR is 0x%x\\n\", val);\n\n\tval = REG_RD(bp, PGLUE_B_REG_FLR_REQUEST_PF_7_0_CLR);\n\tDP(BNX2X_MSG_SP, \"PGLUE_B_REG_FLR_REQUEST_PF_7_0_CLR is 0x%x\\n\", val);\n\n\tval = REG_RD(bp, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER);\n\tDP(BNX2X_MSG_SP, \"PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER is 0x%x\\n\",\n\t   val);\n}\n\nstatic int bnx2x_pf_flr_clnup(struct bnx2x *bp)\n{\n\tu32 poll_cnt = bnx2x_flr_clnup_poll_count(bp);\n\n\tDP(BNX2X_MSG_SP, \"Cleanup after FLR PF[%d]\\n\", BP_ABS_FUNC(bp));\n\n\t \n\tREG_WR(bp, PGLUE_B_REG_INTERNAL_PFID_ENABLE_TARGET_READ, 1);\n\n\t \n\tDP(BNX2X_MSG_SP, \"Polling usage counters\\n\");\n\tif (bnx2x_poll_hw_usage_counters(bp, poll_cnt))\n\t\treturn -EBUSY;\n\n\t \n\n\t \n\tif (bnx2x_send_final_clnup(bp, (u8)BP_FUNC(bp), poll_cnt))\n\t\treturn -EBUSY;\n\n\t \n\n\t \n\tbnx2x_tx_hw_flushed(bp, poll_cnt);\n\n\t \n\tmsleep(100);\n\n\t \n\tif (bnx2x_is_pcie_pending(bp->pdev))\n\t\tBNX2X_ERR(\"PCIE Transactions still pending\\n\");\n\n\t \n\tbnx2x_hw_enable_status(bp);\n\n\t \n\tREG_WR(bp, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, 1);\n\n\treturn 0;\n}\n\nstatic void bnx2x_hc_int_enable(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tu32 addr = port ? HC_REG_CONFIG_1 : HC_REG_CONFIG_0;\n\tu32 val = REG_RD(bp, addr);\n\tbool msix = (bp->flags & USING_MSIX_FLAG) ? true : false;\n\tbool single_msix = (bp->flags & USING_SINGLE_MSIX_FLAG) ? true : false;\n\tbool msi = (bp->flags & USING_MSI_FLAG) ? true : false;\n\n\tif (msix) {\n\t\tval &= ~(HC_CONFIG_0_REG_SINGLE_ISR_EN_0 |\n\t\t\t HC_CONFIG_0_REG_INT_LINE_EN_0);\n\t\tval |= (HC_CONFIG_0_REG_MSI_MSIX_INT_EN_0 |\n\t\t\tHC_CONFIG_0_REG_ATTN_BIT_EN_0);\n\t\tif (single_msix)\n\t\t\tval |= HC_CONFIG_0_REG_SINGLE_ISR_EN_0;\n\t} else if (msi) {\n\t\tval &= ~HC_CONFIG_0_REG_INT_LINE_EN_0;\n\t\tval |= (HC_CONFIG_0_REG_SINGLE_ISR_EN_0 |\n\t\t\tHC_CONFIG_0_REG_MSI_MSIX_INT_EN_0 |\n\t\t\tHC_CONFIG_0_REG_ATTN_BIT_EN_0);\n\t} else {\n\t\tval |= (HC_CONFIG_0_REG_SINGLE_ISR_EN_0 |\n\t\t\tHC_CONFIG_0_REG_MSI_MSIX_INT_EN_0 |\n\t\t\tHC_CONFIG_0_REG_INT_LINE_EN_0 |\n\t\t\tHC_CONFIG_0_REG_ATTN_BIT_EN_0);\n\n\t\tif (!CHIP_IS_E1(bp)) {\n\t\t\tDP(NETIF_MSG_IFUP,\n\t\t\t   \"write %x to HC %d (addr 0x%x)\\n\", val, port, addr);\n\n\t\t\tREG_WR(bp, addr, val);\n\n\t\t\tval &= ~HC_CONFIG_0_REG_MSI_MSIX_INT_EN_0;\n\t\t}\n\t}\n\n\tif (CHIP_IS_E1(bp))\n\t\tREG_WR(bp, HC_REG_INT_MASK + port*4, 0x1FFFF);\n\n\tDP(NETIF_MSG_IFUP,\n\t   \"write %x to HC %d (addr 0x%x) mode %s\\n\", val, port, addr,\n\t   (msix ? \"MSI-X\" : (msi ? \"MSI\" : \"INTx\")));\n\n\tREG_WR(bp, addr, val);\n\t \n\tbarrier();\n\n\tif (!CHIP_IS_E1(bp)) {\n\t\t \n\t\tif (IS_MF(bp)) {\n\t\t\tval = (0xee0f | (1 << (BP_VN(bp) + 4)));\n\t\t\tif (bp->port.pmf)\n\t\t\t\t \n\t\t\t\tval |= 0x1100;\n\t\t} else\n\t\t\tval = 0xffff;\n\n\t\tREG_WR(bp, HC_REG_TRAILING_EDGE_0 + port*8, val);\n\t\tREG_WR(bp, HC_REG_LEADING_EDGE_0 + port*8, val);\n\t}\n}\n\nstatic void bnx2x_igu_int_enable(struct bnx2x *bp)\n{\n\tu32 val;\n\tbool msix = (bp->flags & USING_MSIX_FLAG) ? true : false;\n\tbool single_msix = (bp->flags & USING_SINGLE_MSIX_FLAG) ? true : false;\n\tbool msi = (bp->flags & USING_MSI_FLAG) ? true : false;\n\n\tval = REG_RD(bp, IGU_REG_PF_CONFIGURATION);\n\n\tif (msix) {\n\t\tval &= ~(IGU_PF_CONF_INT_LINE_EN |\n\t\t\t IGU_PF_CONF_SINGLE_ISR_EN);\n\t\tval |= (IGU_PF_CONF_MSI_MSIX_EN |\n\t\t\tIGU_PF_CONF_ATTN_BIT_EN);\n\n\t\tif (single_msix)\n\t\t\tval |= IGU_PF_CONF_SINGLE_ISR_EN;\n\t} else if (msi) {\n\t\tval &= ~IGU_PF_CONF_INT_LINE_EN;\n\t\tval |= (IGU_PF_CONF_MSI_MSIX_EN |\n\t\t\tIGU_PF_CONF_ATTN_BIT_EN |\n\t\t\tIGU_PF_CONF_SINGLE_ISR_EN);\n\t} else {\n\t\tval &= ~IGU_PF_CONF_MSI_MSIX_EN;\n\t\tval |= (IGU_PF_CONF_INT_LINE_EN |\n\t\t\tIGU_PF_CONF_ATTN_BIT_EN |\n\t\t\tIGU_PF_CONF_SINGLE_ISR_EN);\n\t}\n\n\t \n\tif ((!msix) || single_msix) {\n\t\tREG_WR(bp, IGU_REG_PF_CONFIGURATION, val);\n\t\tbnx2x_ack_int(bp);\n\t}\n\n\tval |= IGU_PF_CONF_FUNC_EN;\n\n\tDP(NETIF_MSG_IFUP, \"write 0x%x to IGU  mode %s\\n\",\n\t   val, (msix ? \"MSI-X\" : (msi ? \"MSI\" : \"INTx\")));\n\n\tREG_WR(bp, IGU_REG_PF_CONFIGURATION, val);\n\n\tif (val & IGU_PF_CONF_INT_LINE_EN)\n\t\tpci_intx(bp->pdev, true);\n\n\tbarrier();\n\n\t \n\tif (IS_MF(bp)) {\n\t\tval = (0xee0f | (1 << (BP_VN(bp) + 4)));\n\t\tif (bp->port.pmf)\n\t\t\t \n\t\t\tval |= 0x1100;\n\t} else\n\t\tval = 0xffff;\n\n\tREG_WR(bp, IGU_REG_TRAILING_EDGE_LATCH, val);\n\tREG_WR(bp, IGU_REG_LEADING_EDGE_LATCH, val);\n}\n\nvoid bnx2x_int_enable(struct bnx2x *bp)\n{\n\tif (bp->common.int_block == INT_BLOCK_HC)\n\t\tbnx2x_hc_int_enable(bp);\n\telse\n\t\tbnx2x_igu_int_enable(bp);\n}\n\nvoid bnx2x_int_disable_sync(struct bnx2x *bp, int disable_hw)\n{\n\tint msix = (bp->flags & USING_MSIX_FLAG) ? 1 : 0;\n\tint i, offset;\n\n\tif (disable_hw)\n\t\t \n\t\tbnx2x_int_disable(bp);\n\n\t \n\tif (msix) {\n\t\tsynchronize_irq(bp->msix_table[0].vector);\n\t\toffset = 1;\n\t\tif (CNIC_SUPPORT(bp))\n\t\t\toffset++;\n\t\tfor_each_eth_queue(bp, i)\n\t\t\tsynchronize_irq(bp->msix_table[offset++].vector);\n\t} else\n\t\tsynchronize_irq(bp->pdev->irq);\n\n\t \n\tcancel_delayed_work(&bp->sp_task);\n\tcancel_delayed_work(&bp->period_task);\n\tflush_workqueue(bnx2x_wq);\n}\n\n \n\n \n\n \nstatic bool bnx2x_trylock_hw_lock(struct bnx2x *bp, u32 resource)\n{\n\tu32 lock_status;\n\tu32 resource_bit = (1 << resource);\n\tint func = BP_FUNC(bp);\n\tu32 hw_lock_control_reg;\n\n\tDP(NETIF_MSG_HW | NETIF_MSG_IFUP,\n\t   \"Trying to take a lock on resource %d\\n\", resource);\n\n\t \n\tif (resource > HW_LOCK_MAX_RESOURCE_VALUE) {\n\t\tDP(NETIF_MSG_HW | NETIF_MSG_IFUP,\n\t\t   \"resource(0x%x) > HW_LOCK_MAX_RESOURCE_VALUE(0x%x)\\n\",\n\t\t   resource, HW_LOCK_MAX_RESOURCE_VALUE);\n\t\treturn false;\n\t}\n\n\tif (func <= 5)\n\t\thw_lock_control_reg = (MISC_REG_DRIVER_CONTROL_1 + func*8);\n\telse\n\t\thw_lock_control_reg =\n\t\t\t\t(MISC_REG_DRIVER_CONTROL_7 + (func - 6)*8);\n\n\t \n\tREG_WR(bp, hw_lock_control_reg + 4, resource_bit);\n\tlock_status = REG_RD(bp, hw_lock_control_reg);\n\tif (lock_status & resource_bit)\n\t\treturn true;\n\n\tDP(NETIF_MSG_HW | NETIF_MSG_IFUP,\n\t   \"Failed to get a lock on resource %d\\n\", resource);\n\treturn false;\n}\n\n \nstatic int bnx2x_get_leader_lock_resource(struct bnx2x *bp)\n{\n\tif (BP_PATH(bp))\n\t\treturn HW_LOCK_RESOURCE_RECOVERY_LEADER_1;\n\telse\n\t\treturn HW_LOCK_RESOURCE_RECOVERY_LEADER_0;\n}\n\n \nstatic bool bnx2x_trylock_leader_lock(struct bnx2x *bp)\n{\n\treturn bnx2x_trylock_hw_lock(bp, bnx2x_get_leader_lock_resource(bp));\n}\n\nstatic void bnx2x_cnic_cfc_comp(struct bnx2x *bp, int cid, u8 err);\n\n \nstatic int bnx2x_schedule_sp_task(struct bnx2x *bp)\n{\n\t \n\tatomic_set(&bp->interrupt_occurred, 1);\n\n\t \n\tsmp_wmb();\n\n\t \n\treturn queue_delayed_work(bnx2x_wq, &bp->sp_task, 0);\n}\n\nvoid bnx2x_sp_event(struct bnx2x_fastpath *fp, union eth_rx_cqe *rr_cqe)\n{\n\tstruct bnx2x *bp = fp->bp;\n\tint cid = SW_CID(rr_cqe->ramrod_cqe.conn_and_cmd_data);\n\tint command = CQE_CMD(rr_cqe->ramrod_cqe.conn_and_cmd_data);\n\tenum bnx2x_queue_cmd drv_cmd = BNX2X_Q_CMD_MAX;\n\tstruct bnx2x_queue_sp_obj *q_obj = &bnx2x_sp_obj(bp, fp).q_obj;\n\n\tDP(BNX2X_MSG_SP,\n\t   \"fp %d  cid %d  got ramrod #%d  state is %x  type is %d\\n\",\n\t   fp->index, cid, command, bp->state,\n\t   rr_cqe->ramrod_cqe.ramrod_type);\n\n\t \n\tif (cid >= BNX2X_FIRST_VF_CID  &&\n\t    cid < BNX2X_FIRST_VF_CID + BNX2X_VF_CIDS)\n\t\tbnx2x_iov_set_queue_sp_obj(bp, cid, &q_obj);\n\n\tswitch (command) {\n\tcase (RAMROD_CMD_ID_ETH_CLIENT_UPDATE):\n\t\tDP(BNX2X_MSG_SP, \"got UPDATE ramrod. CID %d\\n\", cid);\n\t\tdrv_cmd = BNX2X_Q_CMD_UPDATE;\n\t\tbreak;\n\n\tcase (RAMROD_CMD_ID_ETH_CLIENT_SETUP):\n\t\tDP(BNX2X_MSG_SP, \"got MULTI[%d] setup ramrod\\n\", cid);\n\t\tdrv_cmd = BNX2X_Q_CMD_SETUP;\n\t\tbreak;\n\n\tcase (RAMROD_CMD_ID_ETH_TX_QUEUE_SETUP):\n\t\tDP(BNX2X_MSG_SP, \"got MULTI[%d] tx-only setup ramrod\\n\", cid);\n\t\tdrv_cmd = BNX2X_Q_CMD_SETUP_TX_ONLY;\n\t\tbreak;\n\n\tcase (RAMROD_CMD_ID_ETH_HALT):\n\t\tDP(BNX2X_MSG_SP, \"got MULTI[%d] halt ramrod\\n\", cid);\n\t\tdrv_cmd = BNX2X_Q_CMD_HALT;\n\t\tbreak;\n\n\tcase (RAMROD_CMD_ID_ETH_TERMINATE):\n\t\tDP(BNX2X_MSG_SP, \"got MULTI[%d] terminate ramrod\\n\", cid);\n\t\tdrv_cmd = BNX2X_Q_CMD_TERMINATE;\n\t\tbreak;\n\n\tcase (RAMROD_CMD_ID_ETH_EMPTY):\n\t\tDP(BNX2X_MSG_SP, \"got MULTI[%d] empty ramrod\\n\", cid);\n\t\tdrv_cmd = BNX2X_Q_CMD_EMPTY;\n\t\tbreak;\n\n\tcase (RAMROD_CMD_ID_ETH_TPA_UPDATE):\n\t\tDP(BNX2X_MSG_SP, \"got tpa update ramrod CID=%d\\n\", cid);\n\t\tdrv_cmd = BNX2X_Q_CMD_UPDATE_TPA;\n\t\tbreak;\n\n\tdefault:\n\t\tBNX2X_ERR(\"unexpected MC reply (%d) on fp[%d]\\n\",\n\t\t\t  command, fp->index);\n\t\treturn;\n\t}\n\n\tif ((drv_cmd != BNX2X_Q_CMD_MAX) &&\n\t    q_obj->complete_cmd(bp, q_obj, drv_cmd))\n\t\t \n#ifdef BNX2X_STOP_ON_ERROR\n\t\tbnx2x_panic();\n#else\n\t\treturn;\n#endif\n\n\tsmp_mb__before_atomic();\n\tatomic_inc(&bp->cq_spq_left);\n\t \n\tsmp_mb__after_atomic();\n\n\tDP(BNX2X_MSG_SP, \"bp->cq_spq_left %x\\n\", atomic_read(&bp->cq_spq_left));\n\n\tif ((drv_cmd == BNX2X_Q_CMD_UPDATE) && (IS_FCOE_FP(fp)) &&\n\t    (!!test_bit(BNX2X_AFEX_FCOE_Q_UPDATE_PENDING, &bp->sp_state))) {\n\t\t \n\t\tsmp_mb__before_atomic();\n\t\tset_bit(BNX2X_AFEX_PENDING_VIFSET_MCP_ACK, &bp->sp_state);\n\t\twmb();\n\t\tclear_bit(BNX2X_AFEX_FCOE_Q_UPDATE_PENDING, &bp->sp_state);\n\t\tsmp_mb__after_atomic();\n\n\t\t \n\t\tbnx2x_schedule_sp_task(bp);\n\t}\n\n\treturn;\n}\n\nirqreturn_t bnx2x_interrupt(int irq, void *dev_instance)\n{\n\tstruct bnx2x *bp = netdev_priv(dev_instance);\n\tu16 status = bnx2x_ack_int(bp);\n\tu16 mask;\n\tint i;\n\tu8 cos;\n\n\t \n\tif (unlikely(status == 0)) {\n\t\tDP(NETIF_MSG_INTR, \"not our interrupt!\\n\");\n\t\treturn IRQ_NONE;\n\t}\n\tDP(NETIF_MSG_INTR, \"got an interrupt  status 0x%x\\n\", status);\n\n#ifdef BNX2X_STOP_ON_ERROR\n\tif (unlikely(bp->panic))\n\t\treturn IRQ_HANDLED;\n#endif\n\n\tfor_each_eth_queue(bp, i) {\n\t\tstruct bnx2x_fastpath *fp = &bp->fp[i];\n\n\t\tmask = 0x2 << (fp->index + CNIC_SUPPORT(bp));\n\t\tif (status & mask) {\n\t\t\t \n\t\t\tfor_each_cos_in_tx_queue(fp, cos)\n\t\t\t\tprefetch(fp->txdata_ptr[cos]->tx_cons_sb);\n\t\t\tprefetch(&fp->sb_running_index[SM_RX_ID]);\n\t\t\tnapi_schedule_irqoff(&bnx2x_fp(bp, fp->index, napi));\n\t\t\tstatus &= ~mask;\n\t\t}\n\t}\n\n\tif (CNIC_SUPPORT(bp)) {\n\t\tmask = 0x2;\n\t\tif (status & (mask | 0x1)) {\n\t\t\tstruct cnic_ops *c_ops = NULL;\n\n\t\t\trcu_read_lock();\n\t\t\tc_ops = rcu_dereference(bp->cnic_ops);\n\t\t\tif (c_ops && (bp->cnic_eth_dev.drv_state &\n\t\t\t\t      CNIC_DRV_STATE_HANDLES_IRQ))\n\t\t\t\tc_ops->cnic_handler(bp->cnic_data, NULL);\n\t\t\trcu_read_unlock();\n\n\t\t\tstatus &= ~mask;\n\t\t}\n\t}\n\n\tif (unlikely(status & 0x1)) {\n\n\t\t \n\t\tbnx2x_schedule_sp_task(bp);\n\n\t\tstatus &= ~0x1;\n\t\tif (!status)\n\t\t\treturn IRQ_HANDLED;\n\t}\n\n\tif (unlikely(status))\n\t\tDP(NETIF_MSG_INTR, \"got an unknown interrupt! (status 0x%x)\\n\",\n\t\t   status);\n\n\treturn IRQ_HANDLED;\n}\n\n \n\n \n\nint bnx2x_acquire_hw_lock(struct bnx2x *bp, u32 resource)\n{\n\tu32 lock_status;\n\tu32 resource_bit = (1 << resource);\n\tint func = BP_FUNC(bp);\n\tu32 hw_lock_control_reg;\n\tint cnt;\n\n\t \n\tif (resource > HW_LOCK_MAX_RESOURCE_VALUE) {\n\t\tBNX2X_ERR(\"resource(0x%x) > HW_LOCK_MAX_RESOURCE_VALUE(0x%x)\\n\",\n\t\t   resource, HW_LOCK_MAX_RESOURCE_VALUE);\n\t\treturn -EINVAL;\n\t}\n\n\tif (func <= 5) {\n\t\thw_lock_control_reg = (MISC_REG_DRIVER_CONTROL_1 + func*8);\n\t} else {\n\t\thw_lock_control_reg =\n\t\t\t\t(MISC_REG_DRIVER_CONTROL_7 + (func - 6)*8);\n\t}\n\n\t \n\tlock_status = REG_RD(bp, hw_lock_control_reg);\n\tif (lock_status & resource_bit) {\n\t\tBNX2X_ERR(\"lock_status 0x%x  resource_bit 0x%x\\n\",\n\t\t   lock_status, resource_bit);\n\t\treturn -EEXIST;\n\t}\n\n\t \n\tfor (cnt = 0; cnt < 1000; cnt++) {\n\t\t \n\t\tREG_WR(bp, hw_lock_control_reg + 4, resource_bit);\n\t\tlock_status = REG_RD(bp, hw_lock_control_reg);\n\t\tif (lock_status & resource_bit)\n\t\t\treturn 0;\n\n\t\tusleep_range(5000, 10000);\n\t}\n\tBNX2X_ERR(\"Timeout\\n\");\n\treturn -EAGAIN;\n}\n\nint bnx2x_release_leader_lock(struct bnx2x *bp)\n{\n\treturn bnx2x_release_hw_lock(bp, bnx2x_get_leader_lock_resource(bp));\n}\n\nint bnx2x_release_hw_lock(struct bnx2x *bp, u32 resource)\n{\n\tu32 lock_status;\n\tu32 resource_bit = (1 << resource);\n\tint func = BP_FUNC(bp);\n\tu32 hw_lock_control_reg;\n\n\t \n\tif (resource > HW_LOCK_MAX_RESOURCE_VALUE) {\n\t\tBNX2X_ERR(\"resource(0x%x) > HW_LOCK_MAX_RESOURCE_VALUE(0x%x)\\n\",\n\t\t   resource, HW_LOCK_MAX_RESOURCE_VALUE);\n\t\treturn -EINVAL;\n\t}\n\n\tif (func <= 5) {\n\t\thw_lock_control_reg = (MISC_REG_DRIVER_CONTROL_1 + func*8);\n\t} else {\n\t\thw_lock_control_reg =\n\t\t\t\t(MISC_REG_DRIVER_CONTROL_7 + (func - 6)*8);\n\t}\n\n\t \n\tlock_status = REG_RD(bp, hw_lock_control_reg);\n\tif (!(lock_status & resource_bit)) {\n\t\tBNX2X_ERR(\"lock_status 0x%x resource_bit 0x%x. Unlock was called but lock wasn't taken!\\n\",\n\t\t\t  lock_status, resource_bit);\n\t\treturn -EFAULT;\n\t}\n\n\tREG_WR(bp, hw_lock_control_reg, resource_bit);\n\treturn 0;\n}\n\nint bnx2x_get_gpio(struct bnx2x *bp, int gpio_num, u8 port)\n{\n\t \n\tint gpio_port = (REG_RD(bp, NIG_REG_PORT_SWAP) &&\n\t\t\t REG_RD(bp, NIG_REG_STRAP_OVERRIDE)) ^ port;\n\tint gpio_shift = gpio_num +\n\t\t\t(gpio_port ? MISC_REGISTERS_GPIO_PORT_SHIFT : 0);\n\tu32 gpio_mask = (1 << gpio_shift);\n\tu32 gpio_reg;\n\tint value;\n\n\tif (gpio_num > MISC_REGISTERS_GPIO_3) {\n\t\tBNX2X_ERR(\"Invalid GPIO %d\\n\", gpio_num);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tgpio_reg = REG_RD(bp, MISC_REG_GPIO);\n\n\t \n\tif ((gpio_reg & gpio_mask) == gpio_mask)\n\t\tvalue = 1;\n\telse\n\t\tvalue = 0;\n\n\treturn value;\n}\n\nint bnx2x_set_gpio(struct bnx2x *bp, int gpio_num, u32 mode, u8 port)\n{\n\t \n\tint gpio_port = (REG_RD(bp, NIG_REG_PORT_SWAP) &&\n\t\t\t REG_RD(bp, NIG_REG_STRAP_OVERRIDE)) ^ port;\n\tint gpio_shift = gpio_num +\n\t\t\t(gpio_port ? MISC_REGISTERS_GPIO_PORT_SHIFT : 0);\n\tu32 gpio_mask = (1 << gpio_shift);\n\tu32 gpio_reg;\n\n\tif (gpio_num > MISC_REGISTERS_GPIO_3) {\n\t\tBNX2X_ERR(\"Invalid GPIO %d\\n\", gpio_num);\n\t\treturn -EINVAL;\n\t}\n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_GPIO);\n\t \n\tgpio_reg = (REG_RD(bp, MISC_REG_GPIO) & MISC_REGISTERS_GPIO_FLOAT);\n\n\tswitch (mode) {\n\tcase MISC_REGISTERS_GPIO_OUTPUT_LOW:\n\t\tDP(NETIF_MSG_LINK,\n\t\t   \"Set GPIO %d (shift %d) -> output low\\n\",\n\t\t   gpio_num, gpio_shift);\n\t\t \n\t\tgpio_reg &= ~(gpio_mask << MISC_REGISTERS_GPIO_FLOAT_POS);\n\t\tgpio_reg |=  (gpio_mask << MISC_REGISTERS_GPIO_CLR_POS);\n\t\tbreak;\n\n\tcase MISC_REGISTERS_GPIO_OUTPUT_HIGH:\n\t\tDP(NETIF_MSG_LINK,\n\t\t   \"Set GPIO %d (shift %d) -> output high\\n\",\n\t\t   gpio_num, gpio_shift);\n\t\t \n\t\tgpio_reg &= ~(gpio_mask << MISC_REGISTERS_GPIO_FLOAT_POS);\n\t\tgpio_reg |=  (gpio_mask << MISC_REGISTERS_GPIO_SET_POS);\n\t\tbreak;\n\n\tcase MISC_REGISTERS_GPIO_INPUT_HI_Z:\n\t\tDP(NETIF_MSG_LINK,\n\t\t   \"Set GPIO %d (shift %d) -> input\\n\",\n\t\t   gpio_num, gpio_shift);\n\t\t \n\t\tgpio_reg |= (gpio_mask << MISC_REGISTERS_GPIO_FLOAT_POS);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tREG_WR(bp, MISC_REG_GPIO, gpio_reg);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_GPIO);\n\n\treturn 0;\n}\n\nint bnx2x_set_mult_gpio(struct bnx2x *bp, u8 pins, u32 mode)\n{\n\tu32 gpio_reg = 0;\n\tint rc = 0;\n\n\t \n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_GPIO);\n\t \n\tgpio_reg = REG_RD(bp, MISC_REG_GPIO);\n\tgpio_reg &= ~(pins << MISC_REGISTERS_GPIO_FLOAT_POS);\n\tgpio_reg &= ~(pins << MISC_REGISTERS_GPIO_CLR_POS);\n\tgpio_reg &= ~(pins << MISC_REGISTERS_GPIO_SET_POS);\n\n\tswitch (mode) {\n\tcase MISC_REGISTERS_GPIO_OUTPUT_LOW:\n\t\tDP(NETIF_MSG_LINK, \"Set GPIO 0x%x -> output low\\n\", pins);\n\t\t \n\t\tgpio_reg |= (pins << MISC_REGISTERS_GPIO_CLR_POS);\n\t\tbreak;\n\n\tcase MISC_REGISTERS_GPIO_OUTPUT_HIGH:\n\t\tDP(NETIF_MSG_LINK, \"Set GPIO 0x%x -> output high\\n\", pins);\n\t\t \n\t\tgpio_reg |= (pins << MISC_REGISTERS_GPIO_SET_POS);\n\t\tbreak;\n\n\tcase MISC_REGISTERS_GPIO_INPUT_HI_Z:\n\t\tDP(NETIF_MSG_LINK, \"Set GPIO 0x%x -> input\\n\", pins);\n\t\t \n\t\tgpio_reg |= (pins << MISC_REGISTERS_GPIO_FLOAT_POS);\n\t\tbreak;\n\n\tdefault:\n\t\tBNX2X_ERR(\"Invalid GPIO mode assignment %d\\n\", mode);\n\t\trc = -EINVAL;\n\t\tbreak;\n\t}\n\n\tif (rc == 0)\n\t\tREG_WR(bp, MISC_REG_GPIO, gpio_reg);\n\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_GPIO);\n\n\treturn rc;\n}\n\nint bnx2x_set_gpio_int(struct bnx2x *bp, int gpio_num, u32 mode, u8 port)\n{\n\t \n\tint gpio_port = (REG_RD(bp, NIG_REG_PORT_SWAP) &&\n\t\t\t REG_RD(bp, NIG_REG_STRAP_OVERRIDE)) ^ port;\n\tint gpio_shift = gpio_num +\n\t\t\t(gpio_port ? MISC_REGISTERS_GPIO_PORT_SHIFT : 0);\n\tu32 gpio_mask = (1 << gpio_shift);\n\tu32 gpio_reg;\n\n\tif (gpio_num > MISC_REGISTERS_GPIO_3) {\n\t\tBNX2X_ERR(\"Invalid GPIO %d\\n\", gpio_num);\n\t\treturn -EINVAL;\n\t}\n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_GPIO);\n\t \n\tgpio_reg = REG_RD(bp, MISC_REG_GPIO_INT);\n\n\tswitch (mode) {\n\tcase MISC_REGISTERS_GPIO_INT_OUTPUT_CLR:\n\t\tDP(NETIF_MSG_LINK,\n\t\t   \"Clear GPIO INT %d (shift %d) -> output low\\n\",\n\t\t   gpio_num, gpio_shift);\n\t\t \n\t\tgpio_reg &= ~(gpio_mask << MISC_REGISTERS_GPIO_INT_SET_POS);\n\t\tgpio_reg |=  (gpio_mask << MISC_REGISTERS_GPIO_INT_CLR_POS);\n\t\tbreak;\n\n\tcase MISC_REGISTERS_GPIO_INT_OUTPUT_SET:\n\t\tDP(NETIF_MSG_LINK,\n\t\t   \"Set GPIO INT %d (shift %d) -> output high\\n\",\n\t\t   gpio_num, gpio_shift);\n\t\t \n\t\tgpio_reg &= ~(gpio_mask << MISC_REGISTERS_GPIO_INT_CLR_POS);\n\t\tgpio_reg |=  (gpio_mask << MISC_REGISTERS_GPIO_INT_SET_POS);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tREG_WR(bp, MISC_REG_GPIO_INT, gpio_reg);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_GPIO);\n\n\treturn 0;\n}\n\nstatic int bnx2x_set_spio(struct bnx2x *bp, int spio, u32 mode)\n{\n\tu32 spio_reg;\n\n\t \n\tif ((spio != MISC_SPIO_SPIO4) && (spio != MISC_SPIO_SPIO5)) {\n\t\tBNX2X_ERR(\"Invalid SPIO 0x%x\\n\", spio);\n\t\treturn -EINVAL;\n\t}\n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_SPIO);\n\t \n\tspio_reg = (REG_RD(bp, MISC_REG_SPIO) & MISC_SPIO_FLOAT);\n\n\tswitch (mode) {\n\tcase MISC_SPIO_OUTPUT_LOW:\n\t\tDP(NETIF_MSG_HW, \"Set SPIO 0x%x -> output low\\n\", spio);\n\t\t \n\t\tspio_reg &= ~(spio << MISC_SPIO_FLOAT_POS);\n\t\tspio_reg |=  (spio << MISC_SPIO_CLR_POS);\n\t\tbreak;\n\n\tcase MISC_SPIO_OUTPUT_HIGH:\n\t\tDP(NETIF_MSG_HW, \"Set SPIO 0x%x -> output high\\n\", spio);\n\t\t \n\t\tspio_reg &= ~(spio << MISC_SPIO_FLOAT_POS);\n\t\tspio_reg |=  (spio << MISC_SPIO_SET_POS);\n\t\tbreak;\n\n\tcase MISC_SPIO_INPUT_HI_Z:\n\t\tDP(NETIF_MSG_HW, \"Set SPIO 0x%x -> input\\n\", spio);\n\t\t \n\t\tspio_reg |= (spio << MISC_SPIO_FLOAT_POS);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tREG_WR(bp, MISC_REG_SPIO, spio_reg);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_SPIO);\n\n\treturn 0;\n}\n\nvoid bnx2x_calc_fc_adv(struct bnx2x *bp)\n{\n\tu8 cfg_idx = bnx2x_get_link_cfg_idx(bp);\n\n\tbp->port.advertising[cfg_idx] &= ~(ADVERTISED_Asym_Pause |\n\t\t\t\t\t   ADVERTISED_Pause);\n\tswitch (bp->link_vars.ieee_fc &\n\t\tMDIO_COMBO_IEEE0_AUTO_NEG_ADV_PAUSE_MASK) {\n\tcase MDIO_COMBO_IEEE0_AUTO_NEG_ADV_PAUSE_BOTH:\n\t\tbp->port.advertising[cfg_idx] |= (ADVERTISED_Asym_Pause |\n\t\t\t\t\t\t  ADVERTISED_Pause);\n\t\tbreak;\n\n\tcase MDIO_COMBO_IEEE0_AUTO_NEG_ADV_PAUSE_ASYMMETRIC:\n\t\tbp->port.advertising[cfg_idx] |= ADVERTISED_Asym_Pause;\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void bnx2x_set_requested_fc(struct bnx2x *bp)\n{\n\t \n\tif (CHIP_IS_E1x(bp) && (bp->dev->mtu > 5000))\n\t\tbp->link_params.req_fc_auto_adv = BNX2X_FLOW_CTRL_TX;\n\telse\n\t\tbp->link_params.req_fc_auto_adv = BNX2X_FLOW_CTRL_BOTH;\n}\n\nstatic void bnx2x_init_dropless_fc(struct bnx2x *bp)\n{\n\tu32 pause_enabled = 0;\n\n\tif (!CHIP_IS_E1(bp) && bp->dropless_fc && bp->link_vars.link_up) {\n\t\tif (bp->link_vars.flow_ctrl & BNX2X_FLOW_CTRL_TX)\n\t\t\tpause_enabled = 1;\n\n\t\tREG_WR(bp, BAR_USTRORM_INTMEM +\n\t\t\t   USTORM_ETH_PAUSE_ENABLED_OFFSET(BP_PORT(bp)),\n\t\t       pause_enabled);\n\t}\n\n\tDP(NETIF_MSG_IFUP | NETIF_MSG_LINK, \"dropless_fc is %s\\n\",\n\t   pause_enabled ? \"enabled\" : \"disabled\");\n}\n\nint bnx2x_initial_phy_init(struct bnx2x *bp, int load_mode)\n{\n\tint rc, cfx_idx = bnx2x_get_link_cfg_idx(bp);\n\tu16 req_line_speed = bp->link_params.req_line_speed[cfx_idx];\n\n\tif (!BP_NOMCP(bp)) {\n\t\tbnx2x_set_requested_fc(bp);\n\t\tbnx2x_acquire_phy_lock(bp);\n\n\t\tif (load_mode == LOAD_DIAG) {\n\t\t\tstruct link_params *lp = &bp->link_params;\n\t\t\tlp->loopback_mode = LOOPBACK_XGXS;\n\t\t\t \n\t\t\tif (lp->req_line_speed[cfx_idx] < SPEED_20000) {\n\t\t\t\tif (lp->speed_cap_mask[cfx_idx] &\n\t\t\t\t    PORT_HW_CFG_SPEED_CAPABILITY_D0_20G)\n\t\t\t\t\tlp->req_line_speed[cfx_idx] =\n\t\t\t\t\tSPEED_20000;\n\t\t\t\telse if (lp->speed_cap_mask[cfx_idx] &\n\t\t\t\t\t    PORT_HW_CFG_SPEED_CAPABILITY_D0_10G)\n\t\t\t\t\t\tlp->req_line_speed[cfx_idx] =\n\t\t\t\t\t\tSPEED_10000;\n\t\t\t\telse\n\t\t\t\t\tlp->req_line_speed[cfx_idx] =\n\t\t\t\t\tSPEED_1000;\n\t\t\t}\n\t\t}\n\n\t\tif (load_mode == LOAD_LOOPBACK_EXT) {\n\t\t\tstruct link_params *lp = &bp->link_params;\n\t\t\tlp->loopback_mode = LOOPBACK_EXT;\n\t\t}\n\n\t\trc = bnx2x_phy_init(&bp->link_params, &bp->link_vars);\n\n\t\tbnx2x_release_phy_lock(bp);\n\n\t\tbnx2x_init_dropless_fc(bp);\n\n\t\tbnx2x_calc_fc_adv(bp);\n\n\t\tif (bp->link_vars.link_up) {\n\t\t\tbnx2x_stats_handle(bp, STATS_EVENT_LINK_UP);\n\t\t\tbnx2x_link_report(bp);\n\t\t}\n\t\tqueue_delayed_work(bnx2x_wq, &bp->period_task, 0);\n\t\tbp->link_params.req_line_speed[cfx_idx] = req_line_speed;\n\t\treturn rc;\n\t}\n\tBNX2X_ERR(\"Bootcode is missing - can not initialize link\\n\");\n\treturn -EINVAL;\n}\n\nvoid bnx2x_link_set(struct bnx2x *bp)\n{\n\tif (!BP_NOMCP(bp)) {\n\t\tbnx2x_acquire_phy_lock(bp);\n\t\tbnx2x_phy_init(&bp->link_params, &bp->link_vars);\n\t\tbnx2x_release_phy_lock(bp);\n\n\t\tbnx2x_init_dropless_fc(bp);\n\n\t\tbnx2x_calc_fc_adv(bp);\n\t} else\n\t\tBNX2X_ERR(\"Bootcode is missing - can not set link\\n\");\n}\n\nstatic void bnx2x__link_reset(struct bnx2x *bp)\n{\n\tif (!BP_NOMCP(bp)) {\n\t\tbnx2x_acquire_phy_lock(bp);\n\t\tbnx2x_lfa_reset(&bp->link_params, &bp->link_vars);\n\t\tbnx2x_release_phy_lock(bp);\n\t} else\n\t\tBNX2X_ERR(\"Bootcode is missing - can not reset link\\n\");\n}\n\nvoid bnx2x_force_link_reset(struct bnx2x *bp)\n{\n\tbnx2x_acquire_phy_lock(bp);\n\tbnx2x_link_reset(&bp->link_params, &bp->link_vars, 1);\n\tbnx2x_release_phy_lock(bp);\n}\n\nu8 bnx2x_link_test(struct bnx2x *bp, u8 is_serdes)\n{\n\tu8 rc = 0;\n\n\tif (!BP_NOMCP(bp)) {\n\t\tbnx2x_acquire_phy_lock(bp);\n\t\trc = bnx2x_test_link(&bp->link_params, &bp->link_vars,\n\t\t\t\t     is_serdes);\n\t\tbnx2x_release_phy_lock(bp);\n\t} else\n\t\tBNX2X_ERR(\"Bootcode is missing - can not test link\\n\");\n\n\treturn rc;\n}\n\n \nstatic void bnx2x_calc_vn_min(struct bnx2x *bp,\n\t\t\t\t      struct cmng_init_input *input)\n{\n\tint all_zero = 1;\n\tint vn;\n\n\tfor (vn = VN_0; vn < BP_MAX_VN_NUM(bp); vn++) {\n\t\tu32 vn_cfg = bp->mf_config[vn];\n\t\tu32 vn_min_rate = ((vn_cfg & FUNC_MF_CFG_MIN_BW_MASK) >>\n\t\t\t\t   FUNC_MF_CFG_MIN_BW_SHIFT) * 100;\n\n\t\t \n\t\tif (vn_cfg & FUNC_MF_CFG_FUNC_HIDE)\n\t\t\tvn_min_rate = 0;\n\t\t \n\t\telse if (!vn_min_rate)\n\t\t\tvn_min_rate = DEF_MIN_RATE;\n\t\telse\n\t\t\tall_zero = 0;\n\n\t\tinput->vnic_min_rate[vn] = vn_min_rate;\n\t}\n\n\t \n\tif (BNX2X_IS_ETS_ENABLED(bp)) {\n\t\tinput->flags.cmng_enables &=\n\t\t\t\t\t~CMNG_FLAGS_PER_PORT_FAIRNESS_VN;\n\t\tDP(NETIF_MSG_IFUP, \"Fairness will be disabled due to ETS\\n\");\n\t} else if (all_zero) {\n\t\tinput->flags.cmng_enables &=\n\t\t\t\t\t~CMNG_FLAGS_PER_PORT_FAIRNESS_VN;\n\t\tDP(NETIF_MSG_IFUP,\n\t\t   \"All MIN values are zeroes fairness will be disabled\\n\");\n\t} else\n\t\tinput->flags.cmng_enables |=\n\t\t\t\t\tCMNG_FLAGS_PER_PORT_FAIRNESS_VN;\n}\n\nstatic void bnx2x_calc_vn_max(struct bnx2x *bp, int vn,\n\t\t\t\t    struct cmng_init_input *input)\n{\n\tu16 vn_max_rate;\n\tu32 vn_cfg = bp->mf_config[vn];\n\n\tif (vn_cfg & FUNC_MF_CFG_FUNC_HIDE)\n\t\tvn_max_rate = 0;\n\telse {\n\t\tu32 maxCfg = bnx2x_extract_max_cfg(bp, vn_cfg);\n\n\t\tif (IS_MF_PERCENT_BW(bp)) {\n\t\t\t \n\t\t\tvn_max_rate = (bp->link_vars.line_speed * maxCfg) / 100;\n\t\t} else  \n\t\t\t \n\t\t\tvn_max_rate = maxCfg * 100;\n\t}\n\n\tDP(NETIF_MSG_IFUP, \"vn %d: vn_max_rate %d\\n\", vn, vn_max_rate);\n\n\tinput->vnic_max_rate[vn] = vn_max_rate;\n}\n\nstatic int bnx2x_get_cmng_fns_mode(struct bnx2x *bp)\n{\n\tif (CHIP_REV_IS_SLOW(bp))\n\t\treturn CMNG_FNS_NONE;\n\tif (IS_MF(bp))\n\t\treturn CMNG_FNS_MINMAX;\n\n\treturn CMNG_FNS_NONE;\n}\n\nvoid bnx2x_read_mf_cfg(struct bnx2x *bp)\n{\n\tint vn, n = (CHIP_MODE_IS_4_PORT(bp) ? 2 : 1);\n\n\tif (BP_NOMCP(bp))\n\t\treturn;  \n\n\t \n\tfor (vn = VN_0; vn < BP_MAX_VN_NUM(bp); vn++) {\n\t\tint  func = n * (2 * vn + BP_PORT(bp)) + BP_PATH(bp);\n\n\t\tif (func >= E1H_FUNC_MAX)\n\t\t\tbreak;\n\n\t\tbp->mf_config[vn] =\n\t\t\tMF_CFG_RD(bp, func_mf_config[func].config);\n\t}\n\tif (bp->mf_config[BP_VN(bp)] & FUNC_MF_CFG_FUNC_DISABLED) {\n\t\tDP(NETIF_MSG_IFUP, \"mf_cfg function disabled\\n\");\n\t\tbp->flags |= MF_FUNC_DIS;\n\t} else {\n\t\tDP(NETIF_MSG_IFUP, \"mf_cfg function enabled\\n\");\n\t\tbp->flags &= ~MF_FUNC_DIS;\n\t}\n}\n\nstatic void bnx2x_cmng_fns_init(struct bnx2x *bp, u8 read_cfg, u8 cmng_type)\n{\n\tstruct cmng_init_input input;\n\tmemset(&input, 0, sizeof(struct cmng_init_input));\n\n\tinput.port_rate = bp->link_vars.line_speed;\n\n\tif (cmng_type == CMNG_FNS_MINMAX && input.port_rate) {\n\t\tint vn;\n\n\t\t \n\t\tif (read_cfg)\n\t\t\tbnx2x_read_mf_cfg(bp);\n\n\t\t \n\t\tbnx2x_calc_vn_min(bp, &input);\n\n\t\t \n\t\tif (bp->port.pmf)\n\t\t\tfor (vn = VN_0; vn < BP_MAX_VN_NUM(bp); vn++)\n\t\t\t\tbnx2x_calc_vn_max(bp, vn, &input);\n\n\t\t \n\t\tinput.flags.cmng_enables |=\n\t\t\t\t\tCMNG_FLAGS_PER_PORT_RATE_SHAPING_VN;\n\n\t\tbnx2x_init_cmng(&input, &bp->cmng);\n\t\treturn;\n\t}\n\n\t \n\tDP(NETIF_MSG_IFUP,\n\t   \"rate shaping and fairness are disabled\\n\");\n}\n\nstatic void storm_memset_cmng(struct bnx2x *bp,\n\t\t\t      struct cmng_init *cmng,\n\t\t\t      u8 port)\n{\n\tint vn;\n\tsize_t size = sizeof(struct cmng_struct_per_port);\n\n\tu32 addr = BAR_XSTRORM_INTMEM +\n\t\t\tXSTORM_CMNG_PER_PORT_VARS_OFFSET(port);\n\n\t__storm_memset_struct(bp, addr, size, (u32 *)&cmng->port);\n\n\tfor (vn = VN_0; vn < BP_MAX_VN_NUM(bp); vn++) {\n\t\tint func = func_by_vn(bp, vn);\n\n\t\taddr = BAR_XSTRORM_INTMEM +\n\t\t       XSTORM_RATE_SHAPING_PER_VN_VARS_OFFSET(func);\n\t\tsize = sizeof(struct rate_shaping_vars_per_vn);\n\t\t__storm_memset_struct(bp, addr, size,\n\t\t\t\t      (u32 *)&cmng->vnic.vnic_max_rate[vn]);\n\n\t\taddr = BAR_XSTRORM_INTMEM +\n\t\t       XSTORM_FAIRNESS_PER_VN_VARS_OFFSET(func);\n\t\tsize = sizeof(struct fairness_vars_per_vn);\n\t\t__storm_memset_struct(bp, addr, size,\n\t\t\t\t      (u32 *)&cmng->vnic.vnic_min_rate[vn]);\n\t}\n}\n\n \nvoid bnx2x_set_local_cmng(struct bnx2x *bp)\n{\n\tint cmng_fns = bnx2x_get_cmng_fns_mode(bp);\n\n\tif (cmng_fns != CMNG_FNS_NONE) {\n\t\tbnx2x_cmng_fns_init(bp, false, cmng_fns);\n\t\tstorm_memset_cmng(bp, &bp->cmng, BP_PORT(bp));\n\t} else {\n\t\t \n\t\tDP(NETIF_MSG_IFUP,\n\t\t   \"single function mode without fairness\\n\");\n\t}\n}\n\n \nstatic void bnx2x_link_attn(struct bnx2x *bp)\n{\n\t \n\tbnx2x_stats_handle(bp, STATS_EVENT_STOP);\n\n\tbnx2x_link_update(&bp->link_params, &bp->link_vars);\n\n\tbnx2x_init_dropless_fc(bp);\n\n\tif (bp->link_vars.link_up) {\n\n\t\tif (bp->link_vars.mac_type != MAC_TYPE_EMAC) {\n\t\t\tstruct host_port_stats *pstats;\n\n\t\t\tpstats = bnx2x_sp(bp, port_stats);\n\t\t\t \n\t\t\tmemset(&(pstats->mac_stx[0]), 0,\n\t\t\t       sizeof(struct mac_stx));\n\t\t}\n\t\tif (bp->state == BNX2X_STATE_OPEN)\n\t\t\tbnx2x_stats_handle(bp, STATS_EVENT_LINK_UP);\n\t}\n\n\tif (bp->link_vars.link_up && bp->link_vars.line_speed)\n\t\tbnx2x_set_local_cmng(bp);\n\n\t__bnx2x_link_report(bp);\n\n\tif (IS_MF(bp))\n\t\tbnx2x_link_sync_notify(bp);\n}\n\nvoid bnx2x__link_status_update(struct bnx2x *bp)\n{\n\tif (bp->state != BNX2X_STATE_OPEN)\n\t\treturn;\n\n\t \n\tif (IS_PF(bp)) {\n\t\tbnx2x_dcbx_pmf_update(bp);\n\t\tbnx2x_link_status_update(&bp->link_params, &bp->link_vars);\n\t\tif (bp->link_vars.link_up)\n\t\t\tbnx2x_stats_handle(bp, STATS_EVENT_LINK_UP);\n\t\telse\n\t\t\tbnx2x_stats_handle(bp, STATS_EVENT_STOP);\n\t\t\t \n\t\tbnx2x_link_report(bp);\n\n\t} else {  \n\t\tbp->port.supported[0] |= (SUPPORTED_10baseT_Half |\n\t\t\t\t\t  SUPPORTED_10baseT_Full |\n\t\t\t\t\t  SUPPORTED_100baseT_Half |\n\t\t\t\t\t  SUPPORTED_100baseT_Full |\n\t\t\t\t\t  SUPPORTED_1000baseT_Full |\n\t\t\t\t\t  SUPPORTED_2500baseX_Full |\n\t\t\t\t\t  SUPPORTED_10000baseT_Full |\n\t\t\t\t\t  SUPPORTED_TP |\n\t\t\t\t\t  SUPPORTED_FIBRE |\n\t\t\t\t\t  SUPPORTED_Autoneg |\n\t\t\t\t\t  SUPPORTED_Pause |\n\t\t\t\t\t  SUPPORTED_Asym_Pause);\n\t\tbp->port.advertising[0] = bp->port.supported[0];\n\n\t\tbp->link_params.bp = bp;\n\t\tbp->link_params.port = BP_PORT(bp);\n\t\tbp->link_params.req_duplex[0] = DUPLEX_FULL;\n\t\tbp->link_params.req_flow_ctrl[0] = BNX2X_FLOW_CTRL_NONE;\n\t\tbp->link_params.req_line_speed[0] = SPEED_10000;\n\t\tbp->link_params.speed_cap_mask[0] = 0x7f0000;\n\t\tbp->link_params.switch_cfg = SWITCH_CFG_10G;\n\t\tbp->link_vars.mac_type = MAC_TYPE_BMAC;\n\t\tbp->link_vars.line_speed = SPEED_10000;\n\t\tbp->link_vars.link_status =\n\t\t\t(LINK_STATUS_LINK_UP |\n\t\t\t LINK_STATUS_SPEED_AND_DUPLEX_10GTFD);\n\t\tbp->link_vars.link_up = 1;\n\t\tbp->link_vars.duplex = DUPLEX_FULL;\n\t\tbp->link_vars.flow_ctrl = BNX2X_FLOW_CTRL_NONE;\n\t\t__bnx2x_link_report(bp);\n\n\t\tbnx2x_sample_bulletin(bp);\n\n\t\t \n\t\tbnx2x_stats_handle(bp, STATS_EVENT_LINK_UP);\n\t}\n}\n\nstatic int bnx2x_afex_func_update(struct bnx2x *bp, u16 vifid,\n\t\t\t\t  u16 vlan_val, u8 allowed_prio)\n{\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\tstruct bnx2x_func_afex_update_params *f_update_params =\n\t\t&func_params.params.afex_update;\n\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_AFEX_UPDATE;\n\n\t \n\n\tf_update_params->vif_id = vifid;\n\tf_update_params->afex_default_vlan = vlan_val;\n\tf_update_params->allowed_priorities = allowed_prio;\n\n\t \n\tif (bnx2x_func_state_change(bp, &func_params) < 0)\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_AFEX_VIFSET_ACK, 0);\n\n\treturn 0;\n}\n\nstatic int bnx2x_afex_handle_vif_list_cmd(struct bnx2x *bp, u8 cmd_type,\n\t\t\t\t\t  u16 vif_index, u8 func_bit_map)\n{\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\tstruct bnx2x_func_afex_viflists_params *update_params =\n\t\t&func_params.params.afex_viflists;\n\tint rc;\n\tu32 drv_msg_code;\n\n\t \n\tif ((cmd_type != VIF_LIST_RULE_GET) && (cmd_type != VIF_LIST_RULE_SET))\n\t\tBNX2X_ERR(\"BUG! afex_handle_vif_list_cmd invalid type 0x%x\\n\",\n\t\t\t  cmd_type);\n\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_AFEX_VIFLISTS;\n\n\t \n\tupdate_params->afex_vif_list_command = cmd_type;\n\tupdate_params->vif_list_index = vif_index;\n\tupdate_params->func_bit_map =\n\t\t(cmd_type == VIF_LIST_RULE_GET) ? 0 : func_bit_map;\n\tupdate_params->func_to_clear = 0;\n\tdrv_msg_code =\n\t\t(cmd_type == VIF_LIST_RULE_GET) ?\n\t\tDRV_MSG_CODE_AFEX_LISTGET_ACK :\n\t\tDRV_MSG_CODE_AFEX_LISTSET_ACK;\n\n\t \n\trc = bnx2x_func_state_change(bp, &func_params);\n\tif (rc < 0)\n\t\tbnx2x_fw_command(bp, drv_msg_code, 0);\n\n\treturn 0;\n}\n\nstatic void bnx2x_handle_afex_cmd(struct bnx2x *bp, u32 cmd)\n{\n\tstruct afex_stats afex_stats;\n\tu32 func = BP_ABS_FUNC(bp);\n\tu32 mf_config;\n\tu16 vlan_val;\n\tu32 vlan_prio;\n\tu16 vif_id;\n\tu8 allowed_prio;\n\tu8 vlan_mode;\n\tu32 addr_to_write, vifid, addrs, stats_type, i;\n\n\tif (cmd & DRV_STATUS_AFEX_LISTGET_REQ) {\n\t\tvifid = SHMEM2_RD(bp, afex_param1_to_driver[BP_FW_MB_IDX(bp)]);\n\t\tDP(BNX2X_MSG_MCP,\n\t\t   \"afex: got MCP req LISTGET_REQ for vifid 0x%x\\n\", vifid);\n\t\tbnx2x_afex_handle_vif_list_cmd(bp, VIF_LIST_RULE_GET, vifid, 0);\n\t}\n\n\tif (cmd & DRV_STATUS_AFEX_LISTSET_REQ) {\n\t\tvifid = SHMEM2_RD(bp, afex_param1_to_driver[BP_FW_MB_IDX(bp)]);\n\t\taddrs = SHMEM2_RD(bp, afex_param2_to_driver[BP_FW_MB_IDX(bp)]);\n\t\tDP(BNX2X_MSG_MCP,\n\t\t   \"afex: got MCP req LISTSET_REQ for vifid 0x%x addrs 0x%x\\n\",\n\t\t   vifid, addrs);\n\t\tbnx2x_afex_handle_vif_list_cmd(bp, VIF_LIST_RULE_SET, vifid,\n\t\t\t\t\t       addrs);\n\t}\n\n\tif (cmd & DRV_STATUS_AFEX_STATSGET_REQ) {\n\t\taddr_to_write = SHMEM2_RD(bp,\n\t\t\tafex_scratchpad_addr_to_write[BP_FW_MB_IDX(bp)]);\n\t\tstats_type = SHMEM2_RD(bp,\n\t\t\tafex_param1_to_driver[BP_FW_MB_IDX(bp)]);\n\n\t\tDP(BNX2X_MSG_MCP,\n\t\t   \"afex: got MCP req STATSGET_REQ, write to addr 0x%x\\n\",\n\t\t   addr_to_write);\n\n\t\tbnx2x_afex_collect_stats(bp, (void *)&afex_stats, stats_type);\n\n\t\t \n\t\tfor (i = 0; i < (sizeof(struct afex_stats)/sizeof(u32)); i++)\n\t\t\tREG_WR(bp, addr_to_write + i*sizeof(u32),\n\t\t\t       *(((u32 *)(&afex_stats))+i));\n\n\t\t \n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_AFEX_STATSGET_ACK, 0);\n\t}\n\n\tif (cmd & DRV_STATUS_AFEX_VIFSET_REQ) {\n\t\tmf_config = MF_CFG_RD(bp, func_mf_config[func].config);\n\t\tbp->mf_config[BP_VN(bp)] = mf_config;\n\t\tDP(BNX2X_MSG_MCP,\n\t\t   \"afex: got MCP req VIFSET_REQ, mf_config 0x%x\\n\",\n\t\t   mf_config);\n\n\t\t \n\t\tif (!(mf_config & FUNC_MF_CFG_FUNC_DISABLED)) {\n\t\t\t \n\t\t\tstruct cmng_init_input cmng_input;\n\t\t\tstruct rate_shaping_vars_per_vn m_rs_vn;\n\t\t\tsize_t size = sizeof(struct rate_shaping_vars_per_vn);\n\t\t\tu32 addr = BAR_XSTRORM_INTMEM +\n\t\t\t    XSTORM_RATE_SHAPING_PER_VN_VARS_OFFSET(BP_FUNC(bp));\n\n\t\t\tbp->mf_config[BP_VN(bp)] = mf_config;\n\n\t\t\tbnx2x_calc_vn_max(bp, BP_VN(bp), &cmng_input);\n\t\t\tm_rs_vn.vn_counter.rate =\n\t\t\t\tcmng_input.vnic_max_rate[BP_VN(bp)];\n\t\t\tm_rs_vn.vn_counter.quota =\n\t\t\t\t(m_rs_vn.vn_counter.rate *\n\t\t\t\t RS_PERIODIC_TIMEOUT_USEC) / 8;\n\n\t\t\t__storm_memset_struct(bp, addr, size, (u32 *)&m_rs_vn);\n\n\t\t\t \n\t\t\tvif_id =\n\t\t\t\t(MF_CFG_RD(bp, func_mf_config[func].e1hov_tag) &\n\t\t\t\t FUNC_MF_CFG_E1HOV_TAG_MASK) >>\n\t\t\t\tFUNC_MF_CFG_E1HOV_TAG_SHIFT;\n\t\t\tvlan_val =\n\t\t\t\t(MF_CFG_RD(bp, func_mf_config[func].e1hov_tag) &\n\t\t\t\t FUNC_MF_CFG_AFEX_VLAN_MASK) >>\n\t\t\t\tFUNC_MF_CFG_AFEX_VLAN_SHIFT;\n\t\t\tvlan_prio = (mf_config &\n\t\t\t\t     FUNC_MF_CFG_TRANSMIT_PRIORITY_MASK) >>\n\t\t\t\t    FUNC_MF_CFG_TRANSMIT_PRIORITY_SHIFT;\n\t\t\tvlan_val |= (vlan_prio << VLAN_PRIO_SHIFT);\n\t\t\tvlan_mode =\n\t\t\t\t(MF_CFG_RD(bp,\n\t\t\t\t\t   func_mf_config[func].afex_config) &\n\t\t\t\t FUNC_MF_CFG_AFEX_VLAN_MODE_MASK) >>\n\t\t\t\tFUNC_MF_CFG_AFEX_VLAN_MODE_SHIFT;\n\t\t\tallowed_prio =\n\t\t\t\t(MF_CFG_RD(bp,\n\t\t\t\t\t   func_mf_config[func].afex_config) &\n\t\t\t\t FUNC_MF_CFG_AFEX_COS_FILTER_MASK) >>\n\t\t\t\tFUNC_MF_CFG_AFEX_COS_FILTER_SHIFT;\n\n\t\t\t \n\t\t\tif (bnx2x_afex_func_update(bp, vif_id, vlan_val,\n\t\t\t\t\t\t   allowed_prio))\n\t\t\t\treturn;\n\n\t\t\tbp->afex_def_vlan_tag = vlan_val;\n\t\t\tbp->afex_vlan_mode = vlan_mode;\n\t\t} else {\n\t\t\t \n\t\t\tbnx2x_link_report(bp);\n\n\t\t\t \n\t\t\tbnx2x_afex_func_update(bp, 0xFFFF, 0, 0);\n\n\t\t\t \n\t\t\tbp->afex_def_vlan_tag = -1;\n\t\t}\n\t}\n}\n\nstatic void bnx2x_handle_update_svid_cmd(struct bnx2x *bp)\n{\n\tstruct bnx2x_func_switch_update_params *switch_update_params;\n\tstruct bnx2x_func_state_params func_params;\n\n\tmemset(&func_params, 0, sizeof(struct bnx2x_func_state_params));\n\tswitch_update_params = &func_params.params.switch_update;\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_SWITCH_UPDATE;\n\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &func_params.ramrod_flags);\n\t__set_bit(RAMROD_RETRY, &func_params.ramrod_flags);\n\n\tif (IS_MF_UFP(bp) || IS_MF_BD(bp)) {\n\t\tint func = BP_ABS_FUNC(bp);\n\t\tu32 val;\n\n\t\t \n\t\tval = MF_CFG_RD(bp, func_mf_config[func].e1hov_tag) &\n\t\t\t\tFUNC_MF_CFG_E1HOV_TAG_MASK;\n\t\tif (val != FUNC_MF_CFG_E1HOV_TAG_DEFAULT) {\n\t\t\tbp->mf_ov = val;\n\t\t} else {\n\t\t\tBNX2X_ERR(\"Got an SVID event, but no tag is configured in shmem\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\t \n\t\tREG_WR(bp, NIG_REG_LLH0_FUNC_VLAN_ID + BP_PORT(bp) * 8,\n\t\t       bp->mf_ov);\n\n\t\t \n\t\t__set_bit(BNX2X_F_UPDATE_SD_VLAN_TAG_CHNG,\n\t\t\t  &switch_update_params->changes);\n\t\tswitch_update_params->vlan = bp->mf_ov;\n\n\t\tif (bnx2x_func_state_change(bp, &func_params) < 0) {\n\t\t\tBNX2X_ERR(\"Failed to configure FW of S-tag Change to %02x\\n\",\n\t\t\t\t  bp->mf_ov);\n\t\t\tgoto fail;\n\t\t} else {\n\t\t\tDP(BNX2X_MSG_MCP, \"Configured S-tag %02x\\n\",\n\t\t\t   bp->mf_ov);\n\t\t}\n\t} else {\n\t\tgoto fail;\n\t}\n\n\tbnx2x_fw_command(bp, DRV_MSG_CODE_OEM_UPDATE_SVID_OK, 0);\n\treturn;\nfail:\n\tbnx2x_fw_command(bp, DRV_MSG_CODE_OEM_UPDATE_SVID_FAILURE, 0);\n}\n\nstatic void bnx2x_pmf_update(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tu32 val;\n\n\tbp->port.pmf = 1;\n\tDP(BNX2X_MSG_MCP, \"pmf %d\\n\", bp->port.pmf);\n\n\t \n\tsmp_mb();\n\n\t \n\tqueue_delayed_work(bnx2x_wq, &bp->period_task, 0);\n\n\tbnx2x_dcbx_pmf_update(bp);\n\n\t \n\tval = (0xff0f | (1 << (BP_VN(bp) + 4)));\n\tif (bp->common.int_block == INT_BLOCK_HC) {\n\t\tREG_WR(bp, HC_REG_TRAILING_EDGE_0 + port*8, val);\n\t\tREG_WR(bp, HC_REG_LEADING_EDGE_0 + port*8, val);\n\t} else if (!CHIP_IS_E1x(bp)) {\n\t\tREG_WR(bp, IGU_REG_TRAILING_EDGE_LATCH, val);\n\t\tREG_WR(bp, IGU_REG_LEADING_EDGE_LATCH, val);\n\t}\n\n\tbnx2x_stats_handle(bp, STATS_EVENT_PMF);\n}\n\n \n\n \n\n \n\n \nu32 bnx2x_fw_command(struct bnx2x *bp, u32 command, u32 param)\n{\n\tint mb_idx = BP_FW_MB_IDX(bp);\n\tu32 seq;\n\tu32 rc = 0;\n\tu32 cnt = 1;\n\tu8 delay = CHIP_REV_IS_SLOW(bp) ? 100 : 10;\n\n\tmutex_lock(&bp->fw_mb_mutex);\n\tseq = ++bp->fw_seq;\n\tSHMEM_WR(bp, func_mb[mb_idx].drv_mb_param, param);\n\tSHMEM_WR(bp, func_mb[mb_idx].drv_mb_header, (command | seq));\n\n\tDP(BNX2X_MSG_MCP, \"wrote command (%x) to FW MB param 0x%08x\\n\",\n\t\t\t(command | seq), param);\n\n\tdo {\n\t\t \n\t\tmsleep(delay);\n\n\t\trc = SHMEM_RD(bp, func_mb[mb_idx].fw_mb_header);\n\n\t\t \n\t} while ((seq != (rc & FW_MSG_SEQ_NUMBER_MASK)) && (cnt++ < 500));\n\n\tDP(BNX2X_MSG_MCP, \"[after %d ms] read (%x) seq is (%x) from FW MB\\n\",\n\t   cnt*delay, rc, seq);\n\n\t \n\tif (seq == (rc & FW_MSG_SEQ_NUMBER_MASK))\n\t\trc &= FW_MSG_CODE_MASK;\n\telse {\n\t\t \n\t\tBNX2X_ERR(\"FW failed to respond!\\n\");\n\t\tbnx2x_fw_dump(bp);\n\t\trc = 0;\n\t}\n\tmutex_unlock(&bp->fw_mb_mutex);\n\n\treturn rc;\n}\n\nstatic void storm_memset_func_cfg(struct bnx2x *bp,\n\t\t\t\t struct tstorm_eth_function_common_config *tcfg,\n\t\t\t\t u16 abs_fid)\n{\n\tsize_t size = sizeof(struct tstorm_eth_function_common_config);\n\n\tu32 addr = BAR_TSTRORM_INTMEM +\n\t\t\tTSTORM_FUNCTION_COMMON_CONFIG_OFFSET(abs_fid);\n\n\t__storm_memset_struct(bp, addr, size, (u32 *)tcfg);\n}\n\nvoid bnx2x_func_init(struct bnx2x *bp, struct bnx2x_func_init_params *p)\n{\n\tif (CHIP_IS_E1x(bp)) {\n\t\tstruct tstorm_eth_function_common_config tcfg = {0};\n\n\t\tstorm_memset_func_cfg(bp, &tcfg, p->func_id);\n\t}\n\n\t \n\tstorm_memset_vf_to_pf(bp, p->func_id, p->pf_id);\n\tstorm_memset_func_en(bp, p->func_id, 1);\n\n\t \n\tif (p->spq_active) {\n\t\tstorm_memset_spq_addr(bp, p->spq_map, p->func_id);\n\t\tREG_WR(bp, XSEM_REG_FAST_MEMORY +\n\t\t       XSTORM_SPQ_PROD_OFFSET(p->func_id), p->spq_prod);\n\t}\n}\n\n \nstatic unsigned long bnx2x_get_common_flags(struct bnx2x *bp,\n\t\t\t\t\t    struct bnx2x_fastpath *fp,\n\t\t\t\t\t    bool zero_stats)\n{\n\tunsigned long flags = 0;\n\n\t \n\t__set_bit(BNX2X_Q_FLG_ACTIVE, &flags);\n\n\t \n\n\t__set_bit(BNX2X_Q_FLG_STATS, &flags);\n\tif (zero_stats)\n\t\t__set_bit(BNX2X_Q_FLG_ZERO_STATS, &flags);\n\n\tif (bp->flags & TX_SWITCHING)\n\t\t__set_bit(BNX2X_Q_FLG_TX_SWITCH, &flags);\n\n\t__set_bit(BNX2X_Q_FLG_PCSUM_ON_PKT, &flags);\n\t__set_bit(BNX2X_Q_FLG_TUN_INC_INNER_IP_ID, &flags);\n\n#ifdef BNX2X_STOP_ON_ERROR\n\t__set_bit(BNX2X_Q_FLG_TX_SEC, &flags);\n#endif\n\n\treturn flags;\n}\n\nstatic unsigned long bnx2x_get_q_flags(struct bnx2x *bp,\n\t\t\t\t       struct bnx2x_fastpath *fp,\n\t\t\t\t       bool leading)\n{\n\tunsigned long flags = 0;\n\n\t \n\tif (IS_MF_SD(bp))\n\t\t__set_bit(BNX2X_Q_FLG_OV, &flags);\n\n\tif (IS_FCOE_FP(fp)) {\n\t\t__set_bit(BNX2X_Q_FLG_FCOE, &flags);\n\t\t \n\t\t__set_bit(BNX2X_Q_FLG_FORCE_DEFAULT_PRI, &flags);\n\t}\n\n\tif (fp->mode != TPA_MODE_DISABLED) {\n\t\t__set_bit(BNX2X_Q_FLG_TPA, &flags);\n\t\t__set_bit(BNX2X_Q_FLG_TPA_IPV6, &flags);\n\t\tif (fp->mode == TPA_MODE_GRO)\n\t\t\t__set_bit(BNX2X_Q_FLG_TPA_GRO, &flags);\n\t}\n\n\tif (leading) {\n\t\t__set_bit(BNX2X_Q_FLG_LEADING_RSS, &flags);\n\t\t__set_bit(BNX2X_Q_FLG_MCAST, &flags);\n\t}\n\n\t \n\t__set_bit(BNX2X_Q_FLG_VLAN, &flags);\n\n\t \n\tif (IS_MF_AFEX(bp))\n\t\t__set_bit(BNX2X_Q_FLG_SILENT_VLAN_REM, &flags);\n\n\treturn flags | bnx2x_get_common_flags(bp, fp, true);\n}\n\nstatic void bnx2x_pf_q_prep_general(struct bnx2x *bp,\n\tstruct bnx2x_fastpath *fp, struct bnx2x_general_setup_params *gen_init,\n\tu8 cos)\n{\n\tgen_init->stat_id = bnx2x_stats_id(fp);\n\tgen_init->spcl_id = fp->cl_id;\n\n\t \n\tif (IS_FCOE_FP(fp))\n\t\tgen_init->mtu = BNX2X_FCOE_MINI_JUMBO_MTU;\n\telse\n\t\tgen_init->mtu = bp->dev->mtu;\n\n\tgen_init->cos = cos;\n\n\tgen_init->fp_hsi = ETH_FP_HSI_VERSION;\n}\n\nstatic void bnx2x_pf_rx_q_prep(struct bnx2x *bp,\n\tstruct bnx2x_fastpath *fp, struct rxq_pause_params *pause,\n\tstruct bnx2x_rxq_setup_params *rxq_init)\n{\n\tu8 max_sge = 0;\n\tu16 sge_sz = 0;\n\tu16 tpa_agg_size = 0;\n\n\tif (fp->mode != TPA_MODE_DISABLED) {\n\t\tpause->sge_th_lo = SGE_TH_LO(bp);\n\t\tpause->sge_th_hi = SGE_TH_HI(bp);\n\n\t\t \n\t\tWARN_ON(bp->dropless_fc &&\n\t\t\t\tpause->sge_th_hi + FW_PREFETCH_CNT >\n\t\t\t\tMAX_RX_SGE_CNT * NUM_RX_SGE_PAGES);\n\n\t\ttpa_agg_size = TPA_AGG_SIZE;\n\t\tmax_sge = SGE_PAGE_ALIGN(bp->dev->mtu) >>\n\t\t\tSGE_PAGE_SHIFT;\n\t\tmax_sge = ((max_sge + PAGES_PER_SGE - 1) &\n\t\t\t  (~(PAGES_PER_SGE-1))) >> PAGES_PER_SGE_SHIFT;\n\t\tsge_sz = (u16)min_t(u32, SGE_PAGES, 0xffff);\n\t}\n\n\t \n\tif (!CHIP_IS_E1(bp)) {\n\t\tpause->bd_th_lo = BD_TH_LO(bp);\n\t\tpause->bd_th_hi = BD_TH_HI(bp);\n\n\t\tpause->rcq_th_lo = RCQ_TH_LO(bp);\n\t\tpause->rcq_th_hi = RCQ_TH_HI(bp);\n\t\t \n\t\tWARN_ON(bp->dropless_fc &&\n\t\t\t\tpause->bd_th_hi + FW_PREFETCH_CNT >\n\t\t\t\tbp->rx_ring_size);\n\t\tWARN_ON(bp->dropless_fc &&\n\t\t\t\tpause->rcq_th_hi + FW_PREFETCH_CNT >\n\t\t\t\tNUM_RCQ_RINGS * MAX_RCQ_DESC_CNT);\n\n\t\tpause->pri_map = 1;\n\t}\n\n\t \n\trxq_init->dscr_map = fp->rx_desc_mapping;\n\trxq_init->sge_map = fp->rx_sge_mapping;\n\trxq_init->rcq_map = fp->rx_comp_mapping;\n\trxq_init->rcq_np_map = fp->rx_comp_mapping + BCM_PAGE_SIZE;\n\n\t \n\trxq_init->buf_sz = fp->rx_buf_size - BNX2X_FW_RX_ALIGN_START -\n\t\t\t   BNX2X_FW_RX_ALIGN_END - IP_HEADER_ALIGNMENT_PADDING;\n\n\trxq_init->cl_qzone_id = fp->cl_qzone_id;\n\trxq_init->tpa_agg_sz = tpa_agg_size;\n\trxq_init->sge_buf_sz = sge_sz;\n\trxq_init->max_sges_pkt = max_sge;\n\trxq_init->rss_engine_id = BP_FUNC(bp);\n\trxq_init->mcast_engine_id = BP_FUNC(bp);\n\n\t \n\trxq_init->max_tpa_queues = MAX_AGG_QS(bp);\n\n\trxq_init->cache_line_log = BNX2X_RX_ALIGN_SHIFT;\n\trxq_init->fw_sb_id = fp->fw_sb_id;\n\n\tif (IS_FCOE_FP(fp))\n\t\trxq_init->sb_cq_index = HC_SP_INDEX_ETH_FCOE_RX_CQ_CONS;\n\telse\n\t\trxq_init->sb_cq_index = HC_INDEX_ETH_RX_CQ_CONS;\n\t \n\tif (IS_MF_AFEX(bp)) {\n\t\trxq_init->silent_removal_value = bp->afex_def_vlan_tag;\n\t\trxq_init->silent_removal_mask = VLAN_VID_MASK;\n\t}\n}\n\nstatic void bnx2x_pf_tx_q_prep(struct bnx2x *bp,\n\tstruct bnx2x_fastpath *fp, struct bnx2x_txq_setup_params *txq_init,\n\tu8 cos)\n{\n\ttxq_init->dscr_map = fp->txdata_ptr[cos]->tx_desc_mapping;\n\ttxq_init->sb_cq_index = HC_INDEX_ETH_FIRST_TX_CQ_CONS + cos;\n\ttxq_init->traffic_type = LLFC_TRAFFIC_TYPE_NW;\n\ttxq_init->fw_sb_id = fp->fw_sb_id;\n\n\t \n\ttxq_init->tss_leading_cl_id = bnx2x_fp(bp, 0, cl_id);\n\n\tif (IS_FCOE_FP(fp)) {\n\t\ttxq_init->sb_cq_index = HC_SP_INDEX_ETH_FCOE_TX_CQ_CONS;\n\t\ttxq_init->traffic_type = LLFC_TRAFFIC_TYPE_FCOE;\n\t}\n}\n\nstatic void bnx2x_pf_init(struct bnx2x *bp)\n{\n\tstruct bnx2x_func_init_params func_init = {0};\n\tstruct event_ring_data eq_data = { {0} };\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\t \n\t\t \n\t\tREG_WR(bp, IGU_REG_STATISTIC_NUM_MESSAGE_SENT +\n\t\t\t   BNX2X_IGU_STAS_MSG_VF_CNT*4 +\n\t\t\t   (CHIP_MODE_IS_4_PORT(bp) ?\n\t\t\t\tBP_FUNC(bp) : BP_VN(bp))*4, 0);\n\t\t \n\t\tREG_WR(bp, IGU_REG_STATISTIC_NUM_MESSAGE_SENT +\n\t\t\t   BNX2X_IGU_STAS_MSG_VF_CNT*4 +\n\t\t\t   BNX2X_IGU_STAS_MSG_PF_CNT*4 +\n\t\t\t   (CHIP_MODE_IS_4_PORT(bp) ?\n\t\t\t\tBP_FUNC(bp) : BP_VN(bp))*4, 0);\n\t}\n\n\tfunc_init.spq_active = true;\n\tfunc_init.pf_id = BP_FUNC(bp);\n\tfunc_init.func_id = BP_FUNC(bp);\n\tfunc_init.spq_map = bp->spq_mapping;\n\tfunc_init.spq_prod = bp->spq_prod_idx;\n\n\tbnx2x_func_init(bp, &func_init);\n\n\tmemset(&(bp->cmng), 0, sizeof(struct cmng_struct_per_port));\n\n\t \n\tbp->link_vars.line_speed = SPEED_10000;\n\tbnx2x_cmng_fns_init(bp, true, bnx2x_get_cmng_fns_mode(bp));\n\n\t \n\tif (bp->port.pmf)\n\t\tstorm_memset_cmng(bp, &bp->cmng, BP_PORT(bp));\n\n\t \n\teq_data.base_addr.hi = U64_HI(bp->eq_mapping);\n\teq_data.base_addr.lo = U64_LO(bp->eq_mapping);\n\teq_data.producer = bp->eq_prod;\n\teq_data.index_id = HC_SP_INDEX_EQ_CONS;\n\teq_data.sb_id = DEF_SB_ID;\n\tstorm_memset_eq_data(bp, &eq_data, BP_FUNC(bp));\n}\n\nstatic void bnx2x_e1h_disable(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\n\tbnx2x_tx_disable(bp);\n\n\tREG_WR(bp, NIG_REG_LLH0_FUNC_EN + port*8, 0);\n}\n\nstatic void bnx2x_e1h_enable(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\n\tif (!(IS_MF_UFP(bp) && BNX2X_IS_MF_SD_PROTOCOL_FCOE(bp)))\n\t\tREG_WR(bp, NIG_REG_LLH0_FUNC_EN + port * 8, 1);\n\n\t \n\tnetif_tx_wake_all_queues(bp->dev);\n\n\t \n}\n\n#define DRV_INFO_ETH_STAT_NUM_MACS_REQUIRED 3\n\nstatic void bnx2x_drv_info_ether_stat(struct bnx2x *bp)\n{\n\tstruct eth_stats_info *ether_stat =\n\t\t&bp->slowpath->drv_info_to_mcp.ether_stat;\n\tstruct bnx2x_vlan_mac_obj *mac_obj =\n\t\t&bp->sp_objs->mac_obj;\n\tint i;\n\n\tstrscpy(ether_stat->version, DRV_MODULE_VERSION,\n\t\tETH_STAT_INFO_VERSION_LEN);\n\n\t \n\tfor (i = 0; i < DRV_INFO_ETH_STAT_NUM_MACS_REQUIRED; i++)\n\t\tmemset(ether_stat->mac_local + i, 0,\n\t\t       sizeof(ether_stat->mac_local[0]));\n\tmac_obj->get_n_elements(bp, &bp->sp_objs[0].mac_obj,\n\t\t\t\tDRV_INFO_ETH_STAT_NUM_MACS_REQUIRED,\n\t\t\t\tether_stat->mac_local + MAC_PAD, MAC_PAD,\n\t\t\t\tETH_ALEN);\n\tether_stat->mtu_size = bp->dev->mtu;\n\tif (bp->dev->features & NETIF_F_RXCSUM)\n\t\tether_stat->feature_flags |= FEATURE_ETH_CHKSUM_OFFLOAD_MASK;\n\tif (bp->dev->features & NETIF_F_TSO)\n\t\tether_stat->feature_flags |= FEATURE_ETH_LSO_MASK;\n\tether_stat->feature_flags |= bp->common.boot_mode;\n\n\tether_stat->promiscuous_mode = (bp->dev->flags & IFF_PROMISC) ? 1 : 0;\n\n\tether_stat->txq_size = bp->tx_ring_size;\n\tether_stat->rxq_size = bp->rx_ring_size;\n\n#ifdef CONFIG_BNX2X_SRIOV\n\tether_stat->vf_cnt = IS_SRIOV(bp) ? bp->vfdb->sriov.nr_virtfn : 0;\n#endif\n}\n\nstatic void bnx2x_drv_info_fcoe_stat(struct bnx2x *bp)\n{\n\tstruct bnx2x_dcbx_app_params *app = &bp->dcbx_port_params.app;\n\tstruct fcoe_stats_info *fcoe_stat =\n\t\t&bp->slowpath->drv_info_to_mcp.fcoe_stat;\n\n\tif (!CNIC_LOADED(bp))\n\t\treturn;\n\n\tmemcpy(fcoe_stat->mac_local + MAC_PAD, bp->fip_mac, ETH_ALEN);\n\n\tfcoe_stat->qos_priority =\n\t\tapp->traffic_type_priority[LLFC_TRAFFIC_TYPE_FCOE];\n\n\t \n\tif (!NO_FCOE(bp)) {\n\t\tstruct tstorm_per_queue_stats *fcoe_q_tstorm_stats =\n\t\t\t&bp->fw_stats_data->queue_stats[FCOE_IDX(bp)].\n\t\t\ttstorm_queue_statistics;\n\n\t\tstruct xstorm_per_queue_stats *fcoe_q_xstorm_stats =\n\t\t\t&bp->fw_stats_data->queue_stats[FCOE_IDX(bp)].\n\t\t\txstorm_queue_statistics;\n\n\t\tstruct fcoe_statistics_params *fw_fcoe_stat =\n\t\t\t&bp->fw_stats_data->fcoe;\n\n\t\tADD_64_LE(fcoe_stat->rx_bytes_hi, LE32_0,\n\t\t\t  fcoe_stat->rx_bytes_lo,\n\t\t\t  fw_fcoe_stat->rx_stat0.fcoe_rx_byte_cnt);\n\n\t\tADD_64_LE(fcoe_stat->rx_bytes_hi,\n\t\t\t  fcoe_q_tstorm_stats->rcv_ucast_bytes.hi,\n\t\t\t  fcoe_stat->rx_bytes_lo,\n\t\t\t  fcoe_q_tstorm_stats->rcv_ucast_bytes.lo);\n\n\t\tADD_64_LE(fcoe_stat->rx_bytes_hi,\n\t\t\t  fcoe_q_tstorm_stats->rcv_bcast_bytes.hi,\n\t\t\t  fcoe_stat->rx_bytes_lo,\n\t\t\t  fcoe_q_tstorm_stats->rcv_bcast_bytes.lo);\n\n\t\tADD_64_LE(fcoe_stat->rx_bytes_hi,\n\t\t\t  fcoe_q_tstorm_stats->rcv_mcast_bytes.hi,\n\t\t\t  fcoe_stat->rx_bytes_lo,\n\t\t\t  fcoe_q_tstorm_stats->rcv_mcast_bytes.lo);\n\n\t\tADD_64_LE(fcoe_stat->rx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->rx_frames_lo,\n\t\t\t  fw_fcoe_stat->rx_stat0.fcoe_rx_pkt_cnt);\n\n\t\tADD_64_LE(fcoe_stat->rx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->rx_frames_lo,\n\t\t\t  fcoe_q_tstorm_stats->rcv_ucast_pkts);\n\n\t\tADD_64_LE(fcoe_stat->rx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->rx_frames_lo,\n\t\t\t  fcoe_q_tstorm_stats->rcv_bcast_pkts);\n\n\t\tADD_64_LE(fcoe_stat->rx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->rx_frames_lo,\n\t\t\t  fcoe_q_tstorm_stats->rcv_mcast_pkts);\n\n\t\tADD_64_LE(fcoe_stat->tx_bytes_hi, LE32_0,\n\t\t\t  fcoe_stat->tx_bytes_lo,\n\t\t\t  fw_fcoe_stat->tx_stat.fcoe_tx_byte_cnt);\n\n\t\tADD_64_LE(fcoe_stat->tx_bytes_hi,\n\t\t\t  fcoe_q_xstorm_stats->ucast_bytes_sent.hi,\n\t\t\t  fcoe_stat->tx_bytes_lo,\n\t\t\t  fcoe_q_xstorm_stats->ucast_bytes_sent.lo);\n\n\t\tADD_64_LE(fcoe_stat->tx_bytes_hi,\n\t\t\t  fcoe_q_xstorm_stats->bcast_bytes_sent.hi,\n\t\t\t  fcoe_stat->tx_bytes_lo,\n\t\t\t  fcoe_q_xstorm_stats->bcast_bytes_sent.lo);\n\n\t\tADD_64_LE(fcoe_stat->tx_bytes_hi,\n\t\t\t  fcoe_q_xstorm_stats->mcast_bytes_sent.hi,\n\t\t\t  fcoe_stat->tx_bytes_lo,\n\t\t\t  fcoe_q_xstorm_stats->mcast_bytes_sent.lo);\n\n\t\tADD_64_LE(fcoe_stat->tx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->tx_frames_lo,\n\t\t\t  fw_fcoe_stat->tx_stat.fcoe_tx_pkt_cnt);\n\n\t\tADD_64_LE(fcoe_stat->tx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->tx_frames_lo,\n\t\t\t  fcoe_q_xstorm_stats->ucast_pkts_sent);\n\n\t\tADD_64_LE(fcoe_stat->tx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->tx_frames_lo,\n\t\t\t  fcoe_q_xstorm_stats->bcast_pkts_sent);\n\n\t\tADD_64_LE(fcoe_stat->tx_frames_hi, LE32_0,\n\t\t\t  fcoe_stat->tx_frames_lo,\n\t\t\t  fcoe_q_xstorm_stats->mcast_pkts_sent);\n\t}\n\n\t \n\tbnx2x_cnic_notify(bp, CNIC_CTL_FCOE_STATS_GET_CMD);\n}\n\nstatic void bnx2x_drv_info_iscsi_stat(struct bnx2x *bp)\n{\n\tstruct bnx2x_dcbx_app_params *app = &bp->dcbx_port_params.app;\n\tstruct iscsi_stats_info *iscsi_stat =\n\t\t&bp->slowpath->drv_info_to_mcp.iscsi_stat;\n\n\tif (!CNIC_LOADED(bp))\n\t\treturn;\n\n\tmemcpy(iscsi_stat->mac_local + MAC_PAD, bp->cnic_eth_dev.iscsi_mac,\n\t       ETH_ALEN);\n\n\tiscsi_stat->qos_priority =\n\t\tapp->traffic_type_priority[LLFC_TRAFFIC_TYPE_ISCSI];\n\n\t \n\tbnx2x_cnic_notify(bp, CNIC_CTL_ISCSI_STATS_GET_CMD);\n}\n\n \nstatic void bnx2x_config_mf_bw(struct bnx2x *bp)\n{\n\t \n\tif (!IS_MF(bp)) {\n\t\tDP(BNX2X_MSG_MCP,\n\t\t   \"Ignoring MF BW config in single function mode\\n\");\n\t\treturn;\n\t}\n\n\tif (bp->link_vars.link_up) {\n\t\tbnx2x_cmng_fns_init(bp, true, CMNG_FNS_MINMAX);\n\t\tbnx2x_link_sync_notify(bp);\n\t}\n\tstorm_memset_cmng(bp, &bp->cmng, BP_PORT(bp));\n}\n\nstatic void bnx2x_set_mf_bw(struct bnx2x *bp)\n{\n\tbnx2x_config_mf_bw(bp);\n\tbnx2x_fw_command(bp, DRV_MSG_CODE_SET_MF_BW_ACK, 0);\n}\n\nstatic void bnx2x_handle_eee_event(struct bnx2x *bp)\n{\n\tDP(BNX2X_MSG_MCP, \"EEE - LLDP event\\n\");\n\tbnx2x_fw_command(bp, DRV_MSG_CODE_EEE_RESULTS_ACK, 0);\n}\n\n#define BNX2X_UPDATE_DRV_INFO_IND_LENGTH\t(20)\n#define BNX2X_UPDATE_DRV_INFO_IND_COUNT\t\t(25)\n\nstatic void bnx2x_handle_drv_info_req(struct bnx2x *bp)\n{\n\tenum drv_info_opcode op_code;\n\tu32 drv_info_ctl = SHMEM2_RD(bp, drv_info_control);\n\tbool release = false;\n\tint wait;\n\n\t \n\tif ((drv_info_ctl & DRV_INFO_CONTROL_VER_MASK) != DRV_INFO_CUR_VER) {\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_DRV_INFO_NACK, 0);\n\t\treturn;\n\t}\n\n\top_code = (drv_info_ctl & DRV_INFO_CONTROL_OP_CODE_MASK) >>\n\t\t  DRV_INFO_CONTROL_OP_CODE_SHIFT;\n\n\t \n\tmutex_lock(&bp->drv_info_mutex);\n\n\tmemset(&bp->slowpath->drv_info_to_mcp, 0,\n\t       sizeof(union drv_info_to_mcp));\n\n\tswitch (op_code) {\n\tcase ETH_STATS_OPCODE:\n\t\tbnx2x_drv_info_ether_stat(bp);\n\t\tbreak;\n\tcase FCOE_STATS_OPCODE:\n\t\tbnx2x_drv_info_fcoe_stat(bp);\n\t\tbreak;\n\tcase ISCSI_STATS_OPCODE:\n\t\tbnx2x_drv_info_iscsi_stat(bp);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_DRV_INFO_NACK, 0);\n\t\tgoto out;\n\t}\n\n\t \n\tSHMEM2_WR(bp, drv_info_host_addr_lo,\n\t\tU64_LO(bnx2x_sp_mapping(bp, drv_info_to_mcp)));\n\tSHMEM2_WR(bp, drv_info_host_addr_hi,\n\t\tU64_HI(bnx2x_sp_mapping(bp, drv_info_to_mcp)));\n\n\tbnx2x_fw_command(bp, DRV_MSG_CODE_DRV_INFO_ACK, 0);\n\n\t \n\tif (!SHMEM2_HAS(bp, mfw_drv_indication)) {\n\t\tDP(BNX2X_MSG_MCP, \"Management does not support indication\\n\");\n\t} else if (!bp->drv_info_mng_owner) {\n\t\tu32 bit = MFW_DRV_IND_READ_DONE_OFFSET((BP_ABS_FUNC(bp) >> 1));\n\n\t\tfor (wait = 0; wait < BNX2X_UPDATE_DRV_INFO_IND_COUNT; wait++) {\n\t\t\tu32 indication = SHMEM2_RD(bp, mfw_drv_indication);\n\n\t\t\t \n\t\t\tif (indication & bit) {\n\t\t\t\tSHMEM2_WR(bp, mfw_drv_indication,\n\t\t\t\t\t  indication & ~bit);\n\t\t\t\trelease = true;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tmsleep(BNX2X_UPDATE_DRV_INFO_IND_LENGTH);\n\t\t}\n\t}\n\tif (!release) {\n\t\tDP(BNX2X_MSG_MCP, \"Management did not release indication\\n\");\n\t\tbp->drv_info_mng_owner = true;\n\t}\n\nout:\n\tmutex_unlock(&bp->drv_info_mutex);\n}\n\nstatic u32 bnx2x_update_mng_version_utility(u8 *version, bool bnx2x_format)\n{\n\tu8 vals[4];\n\tint i = 0;\n\n\tif (bnx2x_format) {\n\t\ti = sscanf(version, \"1.%c%hhd.%hhd.%hhd\",\n\t\t\t   &vals[0], &vals[1], &vals[2], &vals[3]);\n\t\tif (i > 0)\n\t\t\tvals[0] -= '0';\n\t} else {\n\t\ti = sscanf(version, \"%hhd.%hhd.%hhd.%hhd\",\n\t\t\t   &vals[0], &vals[1], &vals[2], &vals[3]);\n\t}\n\n\twhile (i < 4)\n\t\tvals[i++] = 0;\n\n\treturn (vals[0] << 24) | (vals[1] << 16) | (vals[2] << 8) | vals[3];\n}\n\nvoid bnx2x_update_mng_version(struct bnx2x *bp)\n{\n\tu32 iscsiver = DRV_VER_NOT_LOADED;\n\tu32 fcoever = DRV_VER_NOT_LOADED;\n\tu32 ethver = DRV_VER_NOT_LOADED;\n\tint idx = BP_FW_MB_IDX(bp);\n\tu8 *version;\n\n\tif (!SHMEM2_HAS(bp, func_os_drv_ver))\n\t\treturn;\n\n\tmutex_lock(&bp->drv_info_mutex);\n\t \n\tif (bp->drv_info_mng_owner)\n\t\tgoto out;\n\n\tif (bp->state != BNX2X_STATE_OPEN)\n\t\tgoto out;\n\n\t \n\tethver = bnx2x_update_mng_version_utility(DRV_MODULE_VERSION, true);\n\tif (!CNIC_LOADED(bp))\n\t\tgoto out;\n\n\t \n\tmemset(&bp->slowpath->drv_info_to_mcp, 0,\n\t       sizeof(union drv_info_to_mcp));\n\tbnx2x_drv_info_iscsi_stat(bp);\n\tversion = bp->slowpath->drv_info_to_mcp.iscsi_stat.version;\n\tiscsiver = bnx2x_update_mng_version_utility(version, false);\n\n\tmemset(&bp->slowpath->drv_info_to_mcp, 0,\n\t       sizeof(union drv_info_to_mcp));\n\tbnx2x_drv_info_fcoe_stat(bp);\n\tversion = bp->slowpath->drv_info_to_mcp.fcoe_stat.version;\n\tfcoever = bnx2x_update_mng_version_utility(version, false);\n\nout:\n\tSHMEM2_WR(bp, func_os_drv_ver[idx].versions[DRV_PERS_ETHERNET], ethver);\n\tSHMEM2_WR(bp, func_os_drv_ver[idx].versions[DRV_PERS_ISCSI], iscsiver);\n\tSHMEM2_WR(bp, func_os_drv_ver[idx].versions[DRV_PERS_FCOE], fcoever);\n\n\tmutex_unlock(&bp->drv_info_mutex);\n\n\tDP(BNX2X_MSG_MCP, \"Setting driver version: ETH [%08x] iSCSI [%08x] FCoE [%08x]\\n\",\n\t   ethver, iscsiver, fcoever);\n}\n\nvoid bnx2x_update_mfw_dump(struct bnx2x *bp)\n{\n\tu32 drv_ver;\n\tu32 valid_dump;\n\n\tif (!SHMEM2_HAS(bp, drv_info))\n\t\treturn;\n\n\t \n\tSHMEM2_WR(bp, drv_info.epoc, (u32)ktime_get_real_seconds());\n\n\tdrv_ver = bnx2x_update_mng_version_utility(DRV_MODULE_VERSION, true);\n\tSHMEM2_WR(bp, drv_info.drv_ver, drv_ver);\n\n\tSHMEM2_WR(bp, drv_info.fw_ver, REG_RD(bp, XSEM_REG_PRAM));\n\n\t \n\tvalid_dump = SHMEM2_RD(bp, drv_info.valid_dump);\n\n\tif (valid_dump & FIRST_DUMP_VALID)\n\t\tDP(NETIF_MSG_IFUP, \"A valid On-Chip MFW dump found on 1st partition\\n\");\n\n\tif (valid_dump & SECOND_DUMP_VALID)\n\t\tDP(NETIF_MSG_IFUP, \"A valid On-Chip MFW dump found on 2nd partition\\n\");\n}\n\nstatic void bnx2x_oem_event(struct bnx2x *bp, u32 event)\n{\n\tu32 cmd_ok, cmd_fail;\n\n\t \n\tif (event & DRV_STATUS_DCC_EVENT_MASK &&\n\t    event & DRV_STATUS_OEM_EVENT_MASK) {\n\t\tBNX2X_ERR(\"Received simultaneous events %08x\\n\", event);\n\t\treturn;\n\t}\n\n\tif (event & DRV_STATUS_DCC_EVENT_MASK) {\n\t\tcmd_fail = DRV_MSG_CODE_DCC_FAILURE;\n\t\tcmd_ok = DRV_MSG_CODE_DCC_OK;\n\t} else   {\n\t\tcmd_fail = DRV_MSG_CODE_OEM_FAILURE;\n\t\tcmd_ok = DRV_MSG_CODE_OEM_OK;\n\t}\n\n\tDP(BNX2X_MSG_MCP, \"oem_event 0x%x\\n\", event);\n\n\tif (event & (DRV_STATUS_DCC_DISABLE_ENABLE_PF |\n\t\t     DRV_STATUS_OEM_DISABLE_ENABLE_PF)) {\n\t\t \n\t\tif (bp->mf_config[BP_VN(bp)] & FUNC_MF_CFG_FUNC_DISABLED) {\n\t\t\tDP(BNX2X_MSG_MCP, \"mf_cfg function disabled\\n\");\n\t\t\tbp->flags |= MF_FUNC_DIS;\n\n\t\t\tbnx2x_e1h_disable(bp);\n\t\t} else {\n\t\t\tDP(BNX2X_MSG_MCP, \"mf_cfg function enabled\\n\");\n\t\t\tbp->flags &= ~MF_FUNC_DIS;\n\n\t\t\tbnx2x_e1h_enable(bp);\n\t\t}\n\t\tevent &= ~(DRV_STATUS_DCC_DISABLE_ENABLE_PF |\n\t\t\t   DRV_STATUS_OEM_DISABLE_ENABLE_PF);\n\t}\n\n\tif (event & (DRV_STATUS_DCC_BANDWIDTH_ALLOCATION |\n\t\t     DRV_STATUS_OEM_BANDWIDTH_ALLOCATION)) {\n\t\tbnx2x_config_mf_bw(bp);\n\t\tevent &= ~(DRV_STATUS_DCC_BANDWIDTH_ALLOCATION |\n\t\t\t   DRV_STATUS_OEM_BANDWIDTH_ALLOCATION);\n\t}\n\n\t \n\tif (event)\n\t\tbnx2x_fw_command(bp, cmd_fail, 0);\n\telse\n\t\tbnx2x_fw_command(bp, cmd_ok, 0);\n}\n\n \nstatic struct eth_spe *bnx2x_sp_get_next(struct bnx2x *bp)\n{\n\tstruct eth_spe *next_spe = bp->spq_prod_bd;\n\n\tif (bp->spq_prod_bd == bp->spq_last_bd) {\n\t\tbp->spq_prod_bd = bp->spq;\n\t\tbp->spq_prod_idx = 0;\n\t\tDP(BNX2X_MSG_SP, \"end of spq\\n\");\n\t} else {\n\t\tbp->spq_prod_bd++;\n\t\tbp->spq_prod_idx++;\n\t}\n\treturn next_spe;\n}\n\n \nstatic void bnx2x_sp_prod_update(struct bnx2x *bp)\n{\n\tint func = BP_FUNC(bp);\n\n\t \n\tmb();\n\n\tREG_WR16_RELAXED(bp, BAR_XSTRORM_INTMEM + XSTORM_SPQ_PROD_OFFSET(func),\n\t\t\t bp->spq_prod_idx);\n}\n\n \nstatic bool bnx2x_is_contextless_ramrod(int cmd, int cmd_type)\n{\n\tif ((cmd_type == NONE_CONNECTION_TYPE) ||\n\t    (cmd == RAMROD_CMD_ID_ETH_FORWARD_SETUP) ||\n\t    (cmd == RAMROD_CMD_ID_ETH_CLASSIFICATION_RULES) ||\n\t    (cmd == RAMROD_CMD_ID_ETH_FILTER_RULES) ||\n\t    (cmd == RAMROD_CMD_ID_ETH_MULTICAST_RULES) ||\n\t    (cmd == RAMROD_CMD_ID_ETH_SET_MAC) ||\n\t    (cmd == RAMROD_CMD_ID_ETH_RSS_UPDATE))\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\n \nint bnx2x_sp_post(struct bnx2x *bp, int command, int cid,\n\t\t  u32 data_hi, u32 data_lo, int cmd_type)\n{\n\tstruct eth_spe *spe;\n\tu16 type;\n\tbool common = bnx2x_is_contextless_ramrod(command, cmd_type);\n\n#ifdef BNX2X_STOP_ON_ERROR\n\tif (unlikely(bp->panic)) {\n\t\tBNX2X_ERR(\"Can't post SP when there is panic\\n\");\n\t\treturn -EIO;\n\t}\n#endif\n\n\tspin_lock_bh(&bp->spq_lock);\n\n\tif (common) {\n\t\tif (!atomic_read(&bp->eq_spq_left)) {\n\t\t\tBNX2X_ERR(\"BUG! EQ ring full!\\n\");\n\t\t\tspin_unlock_bh(&bp->spq_lock);\n\t\t\tbnx2x_panic();\n\t\t\treturn -EBUSY;\n\t\t}\n\t} else if (!atomic_read(&bp->cq_spq_left)) {\n\t\t\tBNX2X_ERR(\"BUG! SPQ ring full!\\n\");\n\t\t\tspin_unlock_bh(&bp->spq_lock);\n\t\t\tbnx2x_panic();\n\t\t\treturn -EBUSY;\n\t}\n\n\tspe = bnx2x_sp_get_next(bp);\n\n\t \n\tspe->hdr.conn_and_cmd_data =\n\t\t\tcpu_to_le32((command << SPE_HDR_CMD_ID_SHIFT) |\n\t\t\t\t    HW_CID(bp, cid));\n\n\t \n\tif (!(cmd_type & SPE_HDR_FUNCTION_ID)) {\n\t\ttype = (cmd_type << SPE_HDR_CONN_TYPE_SHIFT) &\n\t\t\tSPE_HDR_CONN_TYPE;\n\t\ttype |= ((BP_FUNC(bp) << SPE_HDR_FUNCTION_ID_SHIFT) &\n\t\t\t SPE_HDR_FUNCTION_ID);\n\t} else {\n\t\ttype = cmd_type;\n\t}\n\n\tspe->hdr.type = cpu_to_le16(type);\n\n\tspe->data.update_data_addr.hi = cpu_to_le32(data_hi);\n\tspe->data.update_data_addr.lo = cpu_to_le32(data_lo);\n\n\t \n\tif (common)\n\t\tatomic_dec(&bp->eq_spq_left);\n\telse\n\t\tatomic_dec(&bp->cq_spq_left);\n\n\tDP(BNX2X_MSG_SP,\n\t   \"SPQE[%x] (%x:%x)  (cmd, common?) (%d,%d)  hw_cid %x  data (%x:%x) type(0x%x) left (CQ, EQ) (%x,%x)\\n\",\n\t   bp->spq_prod_idx, (u32)U64_HI(bp->spq_mapping),\n\t   (u32)(U64_LO(bp->spq_mapping) +\n\t   (void *)bp->spq_prod_bd - (void *)bp->spq), command, common,\n\t   HW_CID(bp, cid), data_hi, data_lo, type,\n\t   atomic_read(&bp->cq_spq_left), atomic_read(&bp->eq_spq_left));\n\n\tbnx2x_sp_prod_update(bp);\n\tspin_unlock_bh(&bp->spq_lock);\n\treturn 0;\n}\n\n \nstatic int bnx2x_acquire_alr(struct bnx2x *bp)\n{\n\tu32 j, val;\n\tint rc = 0;\n\n\tmight_sleep();\n\tfor (j = 0; j < 1000; j++) {\n\t\tREG_WR(bp, MCP_REG_MCPR_ACCESS_LOCK, MCPR_ACCESS_LOCK_LOCK);\n\t\tval = REG_RD(bp, MCP_REG_MCPR_ACCESS_LOCK);\n\t\tif (val & MCPR_ACCESS_LOCK_LOCK)\n\t\t\tbreak;\n\n\t\tusleep_range(5000, 10000);\n\t}\n\tif (!(val & MCPR_ACCESS_LOCK_LOCK)) {\n\t\tBNX2X_ERR(\"Cannot acquire MCP access lock register\\n\");\n\t\trc = -EBUSY;\n\t}\n\n\treturn rc;\n}\n\n \nstatic void bnx2x_release_alr(struct bnx2x *bp)\n{\n\tREG_WR(bp, MCP_REG_MCPR_ACCESS_LOCK, 0);\n}\n\n#define BNX2X_DEF_SB_ATT_IDX\t0x0001\n#define BNX2X_DEF_SB_IDX\t0x0002\n\nstatic u16 bnx2x_update_dsb_idx(struct bnx2x *bp)\n{\n\tstruct host_sp_status_block *def_sb = bp->def_status_blk;\n\tu16 rc = 0;\n\n\tbarrier();  \n\tif (bp->def_att_idx != def_sb->atten_status_block.attn_bits_index) {\n\t\tbp->def_att_idx = def_sb->atten_status_block.attn_bits_index;\n\t\trc |= BNX2X_DEF_SB_ATT_IDX;\n\t}\n\n\tif (bp->def_idx != def_sb->sp_sb.running_index) {\n\t\tbp->def_idx = def_sb->sp_sb.running_index;\n\t\trc |= BNX2X_DEF_SB_IDX;\n\t}\n\n\t \n\tbarrier();\n\treturn rc;\n}\n\n \n\nstatic void bnx2x_attn_int_asserted(struct bnx2x *bp, u32 asserted)\n{\n\tint port = BP_PORT(bp);\n\tu32 aeu_addr = port ? MISC_REG_AEU_MASK_ATTN_FUNC_1 :\n\t\t\t      MISC_REG_AEU_MASK_ATTN_FUNC_0;\n\tu32 nig_int_mask_addr = port ? NIG_REG_MASK_INTERRUPT_PORT1 :\n\t\t\t\t       NIG_REG_MASK_INTERRUPT_PORT0;\n\tu32 aeu_mask;\n\tu32 nig_mask = 0;\n\tu32 reg_addr;\n\n\tif (bp->attn_state & asserted)\n\t\tBNX2X_ERR(\"IGU ERROR\\n\");\n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_PORT0_ATT_MASK + port);\n\taeu_mask = REG_RD(bp, aeu_addr);\n\n\tDP(NETIF_MSG_HW, \"aeu_mask %x  newly asserted %x\\n\",\n\t   aeu_mask, asserted);\n\taeu_mask &= ~(asserted & 0x3ff);\n\tDP(NETIF_MSG_HW, \"new mask %x\\n\", aeu_mask);\n\n\tREG_WR(bp, aeu_addr, aeu_mask);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_PORT0_ATT_MASK + port);\n\n\tDP(NETIF_MSG_HW, \"attn_state %x\\n\", bp->attn_state);\n\tbp->attn_state |= asserted;\n\tDP(NETIF_MSG_HW, \"new state %x\\n\", bp->attn_state);\n\n\tif (asserted & ATTN_HARD_WIRED_MASK) {\n\t\tif (asserted & ATTN_NIG_FOR_FUNC) {\n\n\t\t\tbnx2x_acquire_phy_lock(bp);\n\n\t\t\t \n\t\t\tnig_mask = REG_RD(bp, nig_int_mask_addr);\n\n\t\t\t \n\t\t\tif (nig_mask) {\n\t\t\t\tREG_WR(bp, nig_int_mask_addr, 0);\n\n\t\t\t\tbnx2x_link_attn(bp);\n\t\t\t}\n\n\t\t\t \n\t\t}\n\t\tif (asserted & ATTN_SW_TIMER_4_FUNC)\n\t\t\tDP(NETIF_MSG_HW, \"ATTN_SW_TIMER_4_FUNC!\\n\");\n\n\t\tif (asserted & GPIO_2_FUNC)\n\t\t\tDP(NETIF_MSG_HW, \"GPIO_2_FUNC!\\n\");\n\n\t\tif (asserted & GPIO_3_FUNC)\n\t\t\tDP(NETIF_MSG_HW, \"GPIO_3_FUNC!\\n\");\n\n\t\tif (asserted & GPIO_4_FUNC)\n\t\t\tDP(NETIF_MSG_HW, \"GPIO_4_FUNC!\\n\");\n\n\t\tif (port == 0) {\n\t\t\tif (asserted & ATTN_GENERAL_ATTN_1) {\n\t\t\t\tDP(NETIF_MSG_HW, \"ATTN_GENERAL_ATTN_1!\\n\");\n\t\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_1, 0x0);\n\t\t\t}\n\t\t\tif (asserted & ATTN_GENERAL_ATTN_2) {\n\t\t\t\tDP(NETIF_MSG_HW, \"ATTN_GENERAL_ATTN_2!\\n\");\n\t\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_2, 0x0);\n\t\t\t}\n\t\t\tif (asserted & ATTN_GENERAL_ATTN_3) {\n\t\t\t\tDP(NETIF_MSG_HW, \"ATTN_GENERAL_ATTN_3!\\n\");\n\t\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_3, 0x0);\n\t\t\t}\n\t\t} else {\n\t\t\tif (asserted & ATTN_GENERAL_ATTN_4) {\n\t\t\t\tDP(NETIF_MSG_HW, \"ATTN_GENERAL_ATTN_4!\\n\");\n\t\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_4, 0x0);\n\t\t\t}\n\t\t\tif (asserted & ATTN_GENERAL_ATTN_5) {\n\t\t\t\tDP(NETIF_MSG_HW, \"ATTN_GENERAL_ATTN_5!\\n\");\n\t\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_5, 0x0);\n\t\t\t}\n\t\t\tif (asserted & ATTN_GENERAL_ATTN_6) {\n\t\t\t\tDP(NETIF_MSG_HW, \"ATTN_GENERAL_ATTN_6!\\n\");\n\t\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_6, 0x0);\n\t\t\t}\n\t\t}\n\n\t}  \n\n\tif (bp->common.int_block == INT_BLOCK_HC)\n\t\treg_addr = (HC_REG_COMMAND_REG + port*32 +\n\t\t\t    COMMAND_REG_ATTN_BITS_SET);\n\telse\n\t\treg_addr = (BAR_IGU_INTMEM + IGU_CMD_ATTN_BIT_SET_UPPER*8);\n\n\tDP(NETIF_MSG_HW, \"about to mask 0x%08x at %s addr 0x%x\\n\", asserted,\n\t   (bp->common.int_block == INT_BLOCK_HC) ? \"HC\" : \"IGU\", reg_addr);\n\tREG_WR(bp, reg_addr, asserted);\n\n\t \n\tif (asserted & ATTN_NIG_FOR_FUNC) {\n\t\t \n\t\tif (bp->common.int_block != INT_BLOCK_HC) {\n\t\t\tu32 cnt = 0, igu_acked;\n\t\t\tdo {\n\t\t\t\tigu_acked = REG_RD(bp,\n\t\t\t\t\t\t   IGU_REG_ATTENTION_ACK_BITS);\n\t\t\t} while (((igu_acked & ATTN_NIG_FOR_FUNC) == 0) &&\n\t\t\t\t (++cnt < MAX_IGU_ATTN_ACK_TO));\n\t\t\tif (!igu_acked)\n\t\t\t\tDP(NETIF_MSG_HW,\n\t\t\t\t   \"Failed to verify IGU ack on time\\n\");\n\t\t\tbarrier();\n\t\t}\n\t\tREG_WR(bp, nig_int_mask_addr, nig_mask);\n\t\tbnx2x_release_phy_lock(bp);\n\t}\n}\n\nstatic void bnx2x_fan_failure(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tu32 ext_phy_config;\n\t \n\text_phy_config =\n\t\tSHMEM_RD(bp,\n\t\t\t dev_info.port_hw_config[port].external_phy_config);\n\n\text_phy_config &= ~PORT_HW_CFG_XGXS_EXT_PHY_TYPE_MASK;\n\text_phy_config |= PORT_HW_CFG_XGXS_EXT_PHY_TYPE_FAILURE;\n\tSHMEM_WR(bp, dev_info.port_hw_config[port].external_phy_config,\n\t\t ext_phy_config);\n\n\t \n\tnetdev_err(bp->dev, \"Fan Failure on Network Controller has caused the driver to shutdown the card to prevent permanent damage.\\n\"\n\t\t\t    \"Please contact OEM Support for assistance\\n\");\n\n\t \n\tbnx2x_schedule_sp_rtnl(bp, BNX2X_SP_RTNL_FAN_FAILURE, 0);\n}\n\nstatic void bnx2x_attn_int_deasserted0(struct bnx2x *bp, u32 attn)\n{\n\tint port = BP_PORT(bp);\n\tint reg_offset;\n\tu32 val;\n\n\treg_offset = (port ? MISC_REG_AEU_ENABLE1_FUNC_1_OUT_0 :\n\t\t\t     MISC_REG_AEU_ENABLE1_FUNC_0_OUT_0);\n\n\tif (attn & AEU_INPUTS_ATTN_BITS_SPIO5) {\n\n\t\tval = REG_RD(bp, reg_offset);\n\t\tval &= ~AEU_INPUTS_ATTN_BITS_SPIO5;\n\t\tREG_WR(bp, reg_offset, val);\n\n\t\tBNX2X_ERR(\"SPIO5 hw attention\\n\");\n\n\t\t \n\t\tbnx2x_hw_reset_phy(&bp->link_params);\n\t\tbnx2x_fan_failure(bp);\n\t}\n\n\tif ((attn & bp->link_vars.aeu_int_mask) && bp->port.pmf) {\n\t\tbnx2x_acquire_phy_lock(bp);\n\t\tbnx2x_handle_module_detect_int(&bp->link_params);\n\t\tbnx2x_release_phy_lock(bp);\n\t}\n\n\tif (attn & HW_INTERRUPT_ASSERT_SET_0) {\n\n\t\tval = REG_RD(bp, reg_offset);\n\t\tval &= ~(attn & HW_INTERRUPT_ASSERT_SET_0);\n\t\tREG_WR(bp, reg_offset, val);\n\n\t\tBNX2X_ERR(\"FATAL HW block attention set0 0x%x\\n\",\n\t\t\t  (u32)(attn & HW_INTERRUPT_ASSERT_SET_0));\n\t\tbnx2x_panic();\n\t}\n}\n\nstatic void bnx2x_attn_int_deasserted1(struct bnx2x *bp, u32 attn)\n{\n\tu32 val;\n\n\tif (attn & AEU_INPUTS_ATTN_BITS_DOORBELLQ_HW_INTERRUPT) {\n\n\t\tval = REG_RD(bp, DORQ_REG_DORQ_INT_STS_CLR);\n\t\tBNX2X_ERR(\"DB hw attention 0x%x\\n\", val);\n\t\t \n\t\tif (val & 0x2)\n\t\t\tBNX2X_ERR(\"FATAL error from DORQ\\n\");\n\t}\n\n\tif (attn & HW_INTERRUPT_ASSERT_SET_1) {\n\n\t\tint port = BP_PORT(bp);\n\t\tint reg_offset;\n\n\t\treg_offset = (port ? MISC_REG_AEU_ENABLE1_FUNC_1_OUT_1 :\n\t\t\t\t     MISC_REG_AEU_ENABLE1_FUNC_0_OUT_1);\n\n\t\tval = REG_RD(bp, reg_offset);\n\t\tval &= ~(attn & HW_INTERRUPT_ASSERT_SET_1);\n\t\tREG_WR(bp, reg_offset, val);\n\n\t\tBNX2X_ERR(\"FATAL HW block attention set1 0x%x\\n\",\n\t\t\t  (u32)(attn & HW_INTERRUPT_ASSERT_SET_1));\n\t\tbnx2x_panic();\n\t}\n}\n\nstatic void bnx2x_attn_int_deasserted2(struct bnx2x *bp, u32 attn)\n{\n\tu32 val;\n\n\tif (attn & AEU_INPUTS_ATTN_BITS_CFC_HW_INTERRUPT) {\n\n\t\tval = REG_RD(bp, CFC_REG_CFC_INT_STS_CLR);\n\t\tBNX2X_ERR(\"CFC hw attention 0x%x\\n\", val);\n\t\t \n\t\tif (val & 0x2)\n\t\t\tBNX2X_ERR(\"FATAL error from CFC\\n\");\n\t}\n\n\tif (attn & AEU_INPUTS_ATTN_BITS_PXP_HW_INTERRUPT) {\n\t\tval = REG_RD(bp, PXP_REG_PXP_INT_STS_CLR_0);\n\t\tBNX2X_ERR(\"PXP hw attention-0 0x%x\\n\", val);\n\t\t \n\t\tif (val & 0x18000)\n\t\t\tBNX2X_ERR(\"FATAL error from PXP\\n\");\n\n\t\tif (!CHIP_IS_E1x(bp)) {\n\t\t\tval = REG_RD(bp, PXP_REG_PXP_INT_STS_CLR_1);\n\t\t\tBNX2X_ERR(\"PXP hw attention-1 0x%x\\n\", val);\n\t\t}\n\t}\n\n\tif (attn & HW_INTERRUPT_ASSERT_SET_2) {\n\n\t\tint port = BP_PORT(bp);\n\t\tint reg_offset;\n\n\t\treg_offset = (port ? MISC_REG_AEU_ENABLE1_FUNC_1_OUT_2 :\n\t\t\t\t     MISC_REG_AEU_ENABLE1_FUNC_0_OUT_2);\n\n\t\tval = REG_RD(bp, reg_offset);\n\t\tval &= ~(attn & HW_INTERRUPT_ASSERT_SET_2);\n\t\tREG_WR(bp, reg_offset, val);\n\n\t\tBNX2X_ERR(\"FATAL HW block attention set2 0x%x\\n\",\n\t\t\t  (u32)(attn & HW_INTERRUPT_ASSERT_SET_2));\n\t\tbnx2x_panic();\n\t}\n}\n\nstatic void bnx2x_attn_int_deasserted3(struct bnx2x *bp, u32 attn)\n{\n\tu32 val;\n\n\tif (attn & EVEREST_GEN_ATTN_IN_USE_MASK) {\n\n\t\tif (attn & BNX2X_PMF_LINK_ASSERT) {\n\t\t\tint func = BP_FUNC(bp);\n\n\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_12 + func*4, 0);\n\t\t\tbnx2x_read_mf_cfg(bp);\n\t\t\tbp->mf_config[BP_VN(bp)] = MF_CFG_RD(bp,\n\t\t\t\t\tfunc_mf_config[BP_ABS_FUNC(bp)].config);\n\t\t\tval = SHMEM_RD(bp,\n\t\t\t\t       func_mb[BP_FW_MB_IDX(bp)].drv_status);\n\n\t\t\tif (val & (DRV_STATUS_DCC_EVENT_MASK |\n\t\t\t\t   DRV_STATUS_OEM_EVENT_MASK))\n\t\t\t\tbnx2x_oem_event(bp,\n\t\t\t\t\t(val & (DRV_STATUS_DCC_EVENT_MASK |\n\t\t\t\t\t\tDRV_STATUS_OEM_EVENT_MASK)));\n\n\t\t\tif (val & DRV_STATUS_SET_MF_BW)\n\t\t\t\tbnx2x_set_mf_bw(bp);\n\n\t\t\tif (val & DRV_STATUS_DRV_INFO_REQ)\n\t\t\t\tbnx2x_handle_drv_info_req(bp);\n\n\t\t\tif (val & DRV_STATUS_VF_DISABLED)\n\t\t\t\tbnx2x_schedule_iov_task(bp,\n\t\t\t\t\t\t\tBNX2X_IOV_HANDLE_FLR);\n\n\t\t\tif ((bp->port.pmf == 0) && (val & DRV_STATUS_PMF))\n\t\t\t\tbnx2x_pmf_update(bp);\n\n\t\t\tif (bp->port.pmf &&\n\t\t\t    (val & DRV_STATUS_DCBX_NEGOTIATION_RESULTS) &&\n\t\t\t\tbp->dcbx_enabled > 0)\n\t\t\t\t \n\t\t\t\tbnx2x_dcbx_set_params(bp,\n\t\t\t\t\tBNX2X_DCBX_STATE_NEG_RECEIVED);\n\t\t\tif (val & DRV_STATUS_AFEX_EVENT_MASK)\n\t\t\t\tbnx2x_handle_afex_cmd(bp,\n\t\t\t\t\tval & DRV_STATUS_AFEX_EVENT_MASK);\n\t\t\tif (val & DRV_STATUS_EEE_NEGOTIATION_RESULTS)\n\t\t\t\tbnx2x_handle_eee_event(bp);\n\n\t\t\tif (val & DRV_STATUS_OEM_UPDATE_SVID)\n\t\t\t\tbnx2x_schedule_sp_rtnl(bp,\n\t\t\t\t\tBNX2X_SP_RTNL_UPDATE_SVID, 0);\n\n\t\t\tif (bp->link_vars.periodic_flags &\n\t\t\t    PERIODIC_FLAGS_LINK_EVENT) {\n\t\t\t\t \n\t\t\t\tbnx2x_acquire_phy_lock(bp);\n\t\t\t\tbp->link_vars.periodic_flags &=\n\t\t\t\t\t~PERIODIC_FLAGS_LINK_EVENT;\n\t\t\t\tbnx2x_release_phy_lock(bp);\n\t\t\t\tif (IS_MF(bp))\n\t\t\t\t\tbnx2x_link_sync_notify(bp);\n\t\t\t\tbnx2x_link_report(bp);\n\t\t\t}\n\t\t\t \n\t\t\tbnx2x__link_status_update(bp);\n\t\t} else if (attn & BNX2X_MC_ASSERT_BITS) {\n\n\t\t\tBNX2X_ERR(\"MC assert!\\n\");\n\t\t\tbnx2x_mc_assert(bp);\n\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_10, 0);\n\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_9, 0);\n\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_8, 0);\n\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_7, 0);\n\t\t\tbnx2x_panic();\n\n\t\t} else if (attn & BNX2X_MCP_ASSERT) {\n\n\t\t\tBNX2X_ERR(\"MCP assert!\\n\");\n\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_11, 0);\n\t\t\tbnx2x_fw_dump(bp);\n\n\t\t} else\n\t\t\tBNX2X_ERR(\"Unknown HW assert! (attn 0x%x)\\n\", attn);\n\t}\n\n\tif (attn & EVEREST_LATCHED_ATTN_IN_USE_MASK) {\n\t\tBNX2X_ERR(\"LATCHED attention 0x%08x (masked)\\n\", attn);\n\t\tif (attn & BNX2X_GRC_TIMEOUT) {\n\t\t\tval = CHIP_IS_E1(bp) ? 0 :\n\t\t\t\t\tREG_RD(bp, MISC_REG_GRC_TIMEOUT_ATTN);\n\t\t\tBNX2X_ERR(\"GRC time-out 0x%08x\\n\", val);\n\t\t}\n\t\tif (attn & BNX2X_GRC_RSV) {\n\t\t\tval = CHIP_IS_E1(bp) ? 0 :\n\t\t\t\t\tREG_RD(bp, MISC_REG_GRC_RSV_ATTN);\n\t\t\tBNX2X_ERR(\"GRC reserved 0x%08x\\n\", val);\n\t\t}\n\t\tREG_WR(bp, MISC_REG_AEU_CLR_LATCH_SIGNAL, 0x7ff);\n\t}\n}\n\n \n#define BNX2X_RECOVERY_GLOB_REG\t\tMISC_REG_GENERIC_POR_1\n\n#define BNX2X_PATH0_LOAD_CNT_MASK\t0x000000ff\n#define BNX2X_PATH0_LOAD_CNT_SHIFT\t0\n#define BNX2X_PATH1_LOAD_CNT_MASK\t0x0000ff00\n#define BNX2X_PATH1_LOAD_CNT_SHIFT\t8\n#define BNX2X_PATH0_RST_IN_PROG_BIT\t0x00010000\n#define BNX2X_PATH1_RST_IN_PROG_BIT\t0x00020000\n#define BNX2X_GLOBAL_RESET_BIT\t\t0x00040000\n\n \nvoid bnx2x_set_reset_global(struct bnx2x *bp)\n{\n\tu32 val;\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n\tval = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\tREG_WR(bp, BNX2X_RECOVERY_GLOB_REG, val | BNX2X_GLOBAL_RESET_BIT);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n}\n\n \nstatic void bnx2x_clear_reset_global(struct bnx2x *bp)\n{\n\tu32 val;\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n\tval = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\tREG_WR(bp, BNX2X_RECOVERY_GLOB_REG, val & (~BNX2X_GLOBAL_RESET_BIT));\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n}\n\n \nstatic bool bnx2x_reset_is_global(struct bnx2x *bp)\n{\n\tu32 val = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\n\tDP(NETIF_MSG_HW, \"GEN_REG_VAL=0x%08x\\n\", val);\n\treturn (val & BNX2X_GLOBAL_RESET_BIT) ? true : false;\n}\n\n \nstatic void bnx2x_set_reset_done(struct bnx2x *bp)\n{\n\tu32 val;\n\tu32 bit = BP_PATH(bp) ?\n\t\tBNX2X_PATH1_RST_IN_PROG_BIT : BNX2X_PATH0_RST_IN_PROG_BIT;\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n\tval = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\n\t \n\tval &= ~bit;\n\tREG_WR(bp, BNX2X_RECOVERY_GLOB_REG, val);\n\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n}\n\n \nvoid bnx2x_set_reset_in_progress(struct bnx2x *bp)\n{\n\tu32 val;\n\tu32 bit = BP_PATH(bp) ?\n\t\tBNX2X_PATH1_RST_IN_PROG_BIT : BNX2X_PATH0_RST_IN_PROG_BIT;\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n\tval = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\n\t \n\tval |= bit;\n\tREG_WR(bp, BNX2X_RECOVERY_GLOB_REG, val);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n}\n\n \nbool bnx2x_reset_is_done(struct bnx2x *bp, int engine)\n{\n\tu32 val = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\tu32 bit = engine ?\n\t\tBNX2X_PATH1_RST_IN_PROG_BIT : BNX2X_PATH0_RST_IN_PROG_BIT;\n\n\t \n\treturn (val & bit) ? false : true;\n}\n\n \nvoid bnx2x_set_pf_load(struct bnx2x *bp)\n{\n\tu32 val1, val;\n\tu32 mask = BP_PATH(bp) ? BNX2X_PATH1_LOAD_CNT_MASK :\n\t\t\t     BNX2X_PATH0_LOAD_CNT_MASK;\n\tu32 shift = BP_PATH(bp) ? BNX2X_PATH1_LOAD_CNT_SHIFT :\n\t\t\t     BNX2X_PATH0_LOAD_CNT_SHIFT;\n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n\tval = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\n\tDP(NETIF_MSG_IFUP, \"Old GEN_REG_VAL=0x%08x\\n\", val);\n\n\t \n\tval1 = (val & mask) >> shift;\n\n\t \n\tval1 |= (1 << bp->pf_num);\n\n\t \n\tval &= ~mask;\n\n\t \n\tval |= ((val1 << shift) & mask);\n\n\tREG_WR(bp, BNX2X_RECOVERY_GLOB_REG, val);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n}\n\n \nbool bnx2x_clear_pf_load(struct bnx2x *bp)\n{\n\tu32 val1, val;\n\tu32 mask = BP_PATH(bp) ? BNX2X_PATH1_LOAD_CNT_MASK :\n\t\t\t     BNX2X_PATH0_LOAD_CNT_MASK;\n\tu32 shift = BP_PATH(bp) ? BNX2X_PATH1_LOAD_CNT_SHIFT :\n\t\t\t     BNX2X_PATH0_LOAD_CNT_SHIFT;\n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n\tval = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\tDP(NETIF_MSG_IFDOWN, \"Old GEN_REG_VAL=0x%08x\\n\", val);\n\n\t \n\tval1 = (val & mask) >> shift;\n\n\t \n\tval1 &= ~(1 << bp->pf_num);\n\n\t \n\tval &= ~mask;\n\n\t \n\tval |= ((val1 << shift) & mask);\n\n\tREG_WR(bp, BNX2X_RECOVERY_GLOB_REG, val);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RECOVERY_REG);\n\treturn val1 != 0;\n}\n\n \nstatic bool bnx2x_get_load_status(struct bnx2x *bp, int engine)\n{\n\tu32 mask = (engine ? BNX2X_PATH1_LOAD_CNT_MASK :\n\t\t\t     BNX2X_PATH0_LOAD_CNT_MASK);\n\tu32 shift = (engine ? BNX2X_PATH1_LOAD_CNT_SHIFT :\n\t\t\t     BNX2X_PATH0_LOAD_CNT_SHIFT);\n\tu32 val = REG_RD(bp, BNX2X_RECOVERY_GLOB_REG);\n\n\tDP(NETIF_MSG_HW | NETIF_MSG_IFUP, \"GLOB_REG=0x%08x\\n\", val);\n\n\tval = (val & mask) >> shift;\n\n\tDP(NETIF_MSG_HW | NETIF_MSG_IFUP, \"load mask for engine %d = 0x%x\\n\",\n\t   engine, val);\n\n\treturn val != 0;\n}\n\nstatic void _print_parity(struct bnx2x *bp, u32 reg)\n{\n\tpr_cont(\" [0x%08x] \", REG_RD(bp, reg));\n}\n\nstatic void _print_next_block(int idx, const char *blk)\n{\n\tpr_cont(\"%s%s\", idx ? \", \" : \"\", blk);\n}\n\nstatic bool bnx2x_check_blocks_with_parity0(struct bnx2x *bp, u32 sig,\n\t\t\t\t\t    int *par_num, bool print)\n{\n\tu32 cur_bit;\n\tbool res;\n\tint i;\n\n\tres = false;\n\n\tfor (i = 0; sig; i++) {\n\t\tcur_bit = (0x1UL << i);\n\t\tif (sig & cur_bit) {\n\t\t\tres |= true;  \n\n\t\t\tif (print) {\n\t\t\t\tswitch (cur_bit) {\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_BRB_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"BRB\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      BRB1_REG_BRB1_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_PARSER_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"PARSER\");\n\t\t\t\t\t_print_parity(bp, PRS_REG_PRS_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_TSDM_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"TSDM\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      TSDM_REG_TSDM_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_SEARCHER_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"SEARCHER\");\n\t\t\t\t\t_print_parity(bp, SRC_REG_SRC_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_TCM_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"TCM\");\n\t\t\t\t\t_print_parity(bp, TCM_REG_TCM_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_TSEMI_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"TSEMI\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      TSEM_REG_TSEM_PRTY_STS_0);\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      TSEM_REG_TSEM_PRTY_STS_1);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_PBCLIENT_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"XPB\");\n\t\t\t\t\t_print_parity(bp, GRCBASE_XPB +\n\t\t\t\t\t\t\t  PB_REG_PB_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\tsig &= ~cur_bit;\n\t\t}\n\t}\n\n\treturn res;\n}\n\nstatic bool bnx2x_check_blocks_with_parity1(struct bnx2x *bp, u32 sig,\n\t\t\t\t\t    int *par_num, bool *global,\n\t\t\t\t\t    bool print)\n{\n\tu32 cur_bit;\n\tbool res;\n\tint i;\n\n\tres = false;\n\n\tfor (i = 0; sig; i++) {\n\t\tcur_bit = (0x1UL << i);\n\t\tif (sig & cur_bit) {\n\t\t\tres |= true;  \n\t\t\tswitch (cur_bit) {\n\t\t\tcase AEU_INPUTS_ATTN_BITS_PBF_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"PBF\");\n\t\t\t\t\t_print_parity(bp, PBF_REG_PBF_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_QM_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"QM\");\n\t\t\t\t\t_print_parity(bp, QM_REG_QM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_TIMERS_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"TM\");\n\t\t\t\t\t_print_parity(bp, TM_REG_TM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_XSDM_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"XSDM\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      XSDM_REG_XSDM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_XCM_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"XCM\");\n\t\t\t\t\t_print_parity(bp, XCM_REG_XCM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_XSEMI_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"XSEMI\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      XSEM_REG_XSEM_PRTY_STS_0);\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      XSEM_REG_XSEM_PRTY_STS_1);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_DOORBELLQ_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"DOORBELLQ\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      DORQ_REG_DORQ_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_NIG_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"NIG\");\n\t\t\t\t\tif (CHIP_IS_E1x(bp)) {\n\t\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t\tNIG_REG_NIG_PRTY_STS);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t\tNIG_REG_NIG_PRTY_STS_0);\n\t\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t\tNIG_REG_NIG_PRTY_STS_1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_VAUX_PCI_CORE_PARITY_ERROR:\n\t\t\t\tif (print)\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"VAUX PCI CORE\");\n\t\t\t\t*global = true;\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_DEBUG_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"DEBUG\");\n\t\t\t\t\t_print_parity(bp, DBG_REG_DBG_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_USDM_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"USDM\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      USDM_REG_USDM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_UCM_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"UCM\");\n\t\t\t\t\t_print_parity(bp, UCM_REG_UCM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_USEMI_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"USEMI\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      USEM_REG_USEM_PRTY_STS_0);\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      USEM_REG_USEM_PRTY_STS_1);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_UPB_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"UPB\");\n\t\t\t\t\t_print_parity(bp, GRCBASE_UPB +\n\t\t\t\t\t\t\t  PB_REG_PB_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_CSDM_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"CSDM\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      CSDM_REG_CSDM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_CCM_PARITY_ERROR:\n\t\t\t\tif (print) {\n\t\t\t\t\t_print_next_block((*par_num)++, \"CCM\");\n\t\t\t\t\t_print_parity(bp, CCM_REG_CCM_PRTY_STS);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tsig &= ~cur_bit;\n\t\t}\n\t}\n\n\treturn res;\n}\n\nstatic bool bnx2x_check_blocks_with_parity2(struct bnx2x *bp, u32 sig,\n\t\t\t\t\t    int *par_num, bool print)\n{\n\tu32 cur_bit;\n\tbool res;\n\tint i;\n\n\tres = false;\n\n\tfor (i = 0; sig; i++) {\n\t\tcur_bit = (0x1UL << i);\n\t\tif (sig & cur_bit) {\n\t\t\tres = true;  \n\t\t\tif (print) {\n\t\t\t\tswitch (cur_bit) {\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_CSEMI_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"CSEMI\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      CSEM_REG_CSEM_PRTY_STS_0);\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      CSEM_REG_CSEM_PRTY_STS_1);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_PXP_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"PXP\");\n\t\t\t\t\t_print_parity(bp, PXP_REG_PXP_PRTY_STS);\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      PXP2_REG_PXP2_PRTY_STS_0);\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      PXP2_REG_PXP2_PRTY_STS_1);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_IN_ATTN_BITS_PXPPCICLOCKCLIENT_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"PXPPCICLOCKCLIENT\");\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_CFC_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"CFC\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      CFC_REG_CFC_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_CDU_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"CDU\");\n\t\t\t\t\t_print_parity(bp, CDU_REG_CDU_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_DMAE_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"DMAE\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      DMAE_REG_DMAE_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_IGU_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"IGU\");\n\t\t\t\t\tif (CHIP_IS_E1x(bp))\n\t\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t\tHC_REG_HC_PRTY_STS);\n\t\t\t\t\telse\n\t\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t\tIGU_REG_IGU_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_MISC_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"MISC\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      MISC_REG_MISC_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\tsig &= ~cur_bit;\n\t\t}\n\t}\n\n\treturn res;\n}\n\nstatic bool bnx2x_check_blocks_with_parity3(struct bnx2x *bp, u32 sig,\n\t\t\t\t\t    int *par_num, bool *global,\n\t\t\t\t\t    bool print)\n{\n\tbool res = false;\n\tu32 cur_bit;\n\tint i;\n\n\tfor (i = 0; sig; i++) {\n\t\tcur_bit = (0x1UL << i);\n\t\tif (sig & cur_bit) {\n\t\t\tswitch (cur_bit) {\n\t\t\tcase AEU_INPUTS_ATTN_BITS_MCP_LATCHED_ROM_PARITY:\n\t\t\t\tif (print)\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"MCP ROM\");\n\t\t\t\t*global = true;\n\t\t\t\tres = true;\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_MCP_LATCHED_UMP_RX_PARITY:\n\t\t\t\tif (print)\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"MCP UMP RX\");\n\t\t\t\t*global = true;\n\t\t\t\tres = true;\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_MCP_LATCHED_UMP_TX_PARITY:\n\t\t\t\tif (print)\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"MCP UMP TX\");\n\t\t\t\t*global = true;\n\t\t\t\tres = true;\n\t\t\t\tbreak;\n\t\t\tcase AEU_INPUTS_ATTN_BITS_MCP_LATCHED_SCPAD_PARITY:\n\t\t\t\t(*par_num)++;\n\t\t\t\t \n\t\t\t\tREG_WR(bp, MISC_REG_AEU_CLR_LATCH_SIGNAL,\n\t\t\t\t       1UL << 10);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tsig &= ~cur_bit;\n\t\t}\n\t}\n\n\treturn res;\n}\n\nstatic bool bnx2x_check_blocks_with_parity4(struct bnx2x *bp, u32 sig,\n\t\t\t\t\t    int *par_num, bool print)\n{\n\tu32 cur_bit;\n\tbool res;\n\tint i;\n\n\tres = false;\n\n\tfor (i = 0; sig; i++) {\n\t\tcur_bit = (0x1UL << i);\n\t\tif (sig & cur_bit) {\n\t\t\tres = true;  \n\t\t\tif (print) {\n\t\t\t\tswitch (cur_bit) {\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_PGLUE_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++,\n\t\t\t\t\t\t\t  \"PGLUE_B\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      PGLUE_B_REG_PGLUE_B_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\tcase AEU_INPUTS_ATTN_BITS_ATC_PARITY_ERROR:\n\t\t\t\t\t_print_next_block((*par_num)++, \"ATC\");\n\t\t\t\t\t_print_parity(bp,\n\t\t\t\t\t\t      ATC_REG_ATC_PRTY_STS);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t \n\t\t\tsig &= ~cur_bit;\n\t\t}\n\t}\n\n\treturn res;\n}\n\nstatic bool bnx2x_parity_attn(struct bnx2x *bp, bool *global, bool print,\n\t\t\t      u32 *sig)\n{\n\tbool res = false;\n\n\tif ((sig[0] & HW_PRTY_ASSERT_SET_0) ||\n\t    (sig[1] & HW_PRTY_ASSERT_SET_1) ||\n\t    (sig[2] & HW_PRTY_ASSERT_SET_2) ||\n\t    (sig[3] & HW_PRTY_ASSERT_SET_3) ||\n\t    (sig[4] & HW_PRTY_ASSERT_SET_4)) {\n\t\tint par_num = 0;\n\n\t\tDP(NETIF_MSG_HW, \"Was parity error: HW block parity attention:\\n\"\n\t\t\t\t \"[0]:0x%08x [1]:0x%08x [2]:0x%08x [3]:0x%08x [4]:0x%08x\\n\",\n\t\t\t  sig[0] & HW_PRTY_ASSERT_SET_0,\n\t\t\t  sig[1] & HW_PRTY_ASSERT_SET_1,\n\t\t\t  sig[2] & HW_PRTY_ASSERT_SET_2,\n\t\t\t  sig[3] & HW_PRTY_ASSERT_SET_3,\n\t\t\t  sig[4] & HW_PRTY_ASSERT_SET_4);\n\t\tif (print) {\n\t\t\tif (((sig[0] & HW_PRTY_ASSERT_SET_0) ||\n\t\t\t     (sig[1] & HW_PRTY_ASSERT_SET_1) ||\n\t\t\t     (sig[2] & HW_PRTY_ASSERT_SET_2) ||\n\t\t\t     (sig[4] & HW_PRTY_ASSERT_SET_4)) ||\n\t\t\t     (sig[3] & HW_PRTY_ASSERT_SET_3_WITHOUT_SCPAD)) {\n\t\t\t\tnetdev_err(bp->dev,\n\t\t\t\t\t   \"Parity errors detected in blocks: \");\n\t\t\t} else {\n\t\t\t\tprint = false;\n\t\t\t}\n\t\t}\n\t\tres |= bnx2x_check_blocks_with_parity0(bp,\n\t\t\tsig[0] & HW_PRTY_ASSERT_SET_0, &par_num, print);\n\t\tres |= bnx2x_check_blocks_with_parity1(bp,\n\t\t\tsig[1] & HW_PRTY_ASSERT_SET_1, &par_num, global, print);\n\t\tres |= bnx2x_check_blocks_with_parity2(bp,\n\t\t\tsig[2] & HW_PRTY_ASSERT_SET_2, &par_num, print);\n\t\tres |= bnx2x_check_blocks_with_parity3(bp,\n\t\t\tsig[3] & HW_PRTY_ASSERT_SET_3, &par_num, global, print);\n\t\tres |= bnx2x_check_blocks_with_parity4(bp,\n\t\t\tsig[4] & HW_PRTY_ASSERT_SET_4, &par_num, print);\n\n\t\tif (print)\n\t\t\tpr_cont(\"\\n\");\n\t}\n\n\treturn res;\n}\n\n \nbool bnx2x_chk_parity_attn(struct bnx2x *bp, bool *global, bool print)\n{\n\tstruct attn_route attn = { {0} };\n\tint port = BP_PORT(bp);\n\n\tattn.sig[0] = REG_RD(bp,\n\t\tMISC_REG_AEU_AFTER_INVERT_1_FUNC_0 +\n\t\t\t     port*4);\n\tattn.sig[1] = REG_RD(bp,\n\t\tMISC_REG_AEU_AFTER_INVERT_2_FUNC_0 +\n\t\t\t     port*4);\n\tattn.sig[2] = REG_RD(bp,\n\t\tMISC_REG_AEU_AFTER_INVERT_3_FUNC_0 +\n\t\t\t     port*4);\n\tattn.sig[3] = REG_RD(bp,\n\t\tMISC_REG_AEU_AFTER_INVERT_4_FUNC_0 +\n\t\t\t     port*4);\n\t \n\tattn.sig[3] &= ((REG_RD(bp,\n\t\t\t\t!port ? MISC_REG_AEU_ENABLE4_FUNC_0_OUT_0\n\t\t\t\t      : MISC_REG_AEU_ENABLE4_FUNC_1_OUT_0) &\n\t\t\t MISC_AEU_ENABLE_MCP_PRTY_BITS) |\n\t\t\t~MISC_AEU_ENABLE_MCP_PRTY_BITS);\n\n\tif (!CHIP_IS_E1x(bp))\n\t\tattn.sig[4] = REG_RD(bp,\n\t\t\tMISC_REG_AEU_AFTER_INVERT_5_FUNC_0 +\n\t\t\t\t     port*4);\n\n\treturn bnx2x_parity_attn(bp, global, print, attn.sig);\n}\n\nstatic void bnx2x_attn_int_deasserted4(struct bnx2x *bp, u32 attn)\n{\n\tu32 val;\n\tif (attn & AEU_INPUTS_ATTN_BITS_PGLUE_HW_INTERRUPT) {\n\n\t\tval = REG_RD(bp, PGLUE_B_REG_PGLUE_B_INT_STS_CLR);\n\t\tBNX2X_ERR(\"PGLUE hw attention 0x%x\\n\", val);\n\t\tif (val & PGLUE_B_PGLUE_B_INT_STS_REG_ADDRESS_ERROR)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_ADDRESS_ERROR\\n\");\n\t\tif (val & PGLUE_B_PGLUE_B_INT_STS_REG_INCORRECT_RCV_BEHAVIOR)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_INCORRECT_RCV_BEHAVIOR\\n\");\n\t\tif (val & PGLUE_B_PGLUE_B_INT_STS_REG_WAS_ERROR_ATTN)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_WAS_ERROR_ATTN\\n\");\n\t\tif (val & PGLUE_B_PGLUE_B_INT_STS_REG_VF_LENGTH_VIOLATION_ATTN)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_VF_LENGTH_VIOLATION_ATTN\\n\");\n\t\tif (val &\n\t\t    PGLUE_B_PGLUE_B_INT_STS_REG_VF_GRC_SPACE_VIOLATION_ATTN)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_VF_GRC_SPACE_VIOLATION_ATTN\\n\");\n\t\tif (val &\n\t\t    PGLUE_B_PGLUE_B_INT_STS_REG_VF_MSIX_BAR_VIOLATION_ATTN)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_VF_MSIX_BAR_VIOLATION_ATTN\\n\");\n\t\tif (val & PGLUE_B_PGLUE_B_INT_STS_REG_TCPL_ERROR_ATTN)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_TCPL_ERROR_ATTN\\n\");\n\t\tif (val & PGLUE_B_PGLUE_B_INT_STS_REG_TCPL_IN_TWO_RCBS_ATTN)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_TCPL_IN_TWO_RCBS_ATTN\\n\");\n\t\tif (val & PGLUE_B_PGLUE_B_INT_STS_REG_CSSNOOP_FIFO_OVERFLOW)\n\t\t\tBNX2X_ERR(\"PGLUE_B_PGLUE_B_INT_STS_REG_CSSNOOP_FIFO_OVERFLOW\\n\");\n\t}\n\tif (attn & AEU_INPUTS_ATTN_BITS_ATC_HW_INTERRUPT) {\n\t\tval = REG_RD(bp, ATC_REG_ATC_INT_STS_CLR);\n\t\tBNX2X_ERR(\"ATC hw attention 0x%x\\n\", val);\n\t\tif (val & ATC_ATC_INT_STS_REG_ADDRESS_ERROR)\n\t\t\tBNX2X_ERR(\"ATC_ATC_INT_STS_REG_ADDRESS_ERROR\\n\");\n\t\tif (val & ATC_ATC_INT_STS_REG_ATC_TCPL_TO_NOT_PEND)\n\t\t\tBNX2X_ERR(\"ATC_ATC_INT_STS_REG_ATC_TCPL_TO_NOT_PEND\\n\");\n\t\tif (val & ATC_ATC_INT_STS_REG_ATC_GPA_MULTIPLE_HITS)\n\t\t\tBNX2X_ERR(\"ATC_ATC_INT_STS_REG_ATC_GPA_MULTIPLE_HITS\\n\");\n\t\tif (val & ATC_ATC_INT_STS_REG_ATC_RCPL_TO_EMPTY_CNT)\n\t\t\tBNX2X_ERR(\"ATC_ATC_INT_STS_REG_ATC_RCPL_TO_EMPTY_CNT\\n\");\n\t\tif (val & ATC_ATC_INT_STS_REG_ATC_TCPL_ERROR)\n\t\t\tBNX2X_ERR(\"ATC_ATC_INT_STS_REG_ATC_TCPL_ERROR\\n\");\n\t\tif (val & ATC_ATC_INT_STS_REG_ATC_IREQ_LESS_THAN_STU)\n\t\t\tBNX2X_ERR(\"ATC_ATC_INT_STS_REG_ATC_IREQ_LESS_THAN_STU\\n\");\n\t}\n\n\tif (attn & (AEU_INPUTS_ATTN_BITS_PGLUE_PARITY_ERROR |\n\t\t    AEU_INPUTS_ATTN_BITS_ATC_PARITY_ERROR)) {\n\t\tBNX2X_ERR(\"FATAL parity attention set4 0x%x\\n\",\n\t\t(u32)(attn & (AEU_INPUTS_ATTN_BITS_PGLUE_PARITY_ERROR |\n\t\t    AEU_INPUTS_ATTN_BITS_ATC_PARITY_ERROR)));\n\t}\n}\n\nstatic void bnx2x_attn_int_deasserted(struct bnx2x *bp, u32 deasserted)\n{\n\tstruct attn_route attn, *group_mask;\n\tint port = BP_PORT(bp);\n\tint index;\n\tu32 reg_addr;\n\tu32 val;\n\tu32 aeu_mask;\n\tbool global = false;\n\n\t \n\tbnx2x_acquire_alr(bp);\n\n\tif (bnx2x_chk_parity_attn(bp, &global, true)) {\n#ifndef BNX2X_STOP_ON_ERROR\n\t\tbp->recovery_state = BNX2X_RECOVERY_INIT;\n\t\tschedule_delayed_work(&bp->sp_rtnl_task, 0);\n\t\t \n\t\tbnx2x_int_disable(bp);\n\t\t \n#else\n\t\tbnx2x_panic();\n#endif\n\t\tbnx2x_release_alr(bp);\n\t\treturn;\n\t}\n\n\tattn.sig[0] = REG_RD(bp, MISC_REG_AEU_AFTER_INVERT_1_FUNC_0 + port*4);\n\tattn.sig[1] = REG_RD(bp, MISC_REG_AEU_AFTER_INVERT_2_FUNC_0 + port*4);\n\tattn.sig[2] = REG_RD(bp, MISC_REG_AEU_AFTER_INVERT_3_FUNC_0 + port*4);\n\tattn.sig[3] = REG_RD(bp, MISC_REG_AEU_AFTER_INVERT_4_FUNC_0 + port*4);\n\tif (!CHIP_IS_E1x(bp))\n\t\tattn.sig[4] =\n\t\t      REG_RD(bp, MISC_REG_AEU_AFTER_INVERT_5_FUNC_0 + port*4);\n\telse\n\t\tattn.sig[4] = 0;\n\n\tDP(NETIF_MSG_HW, \"attn: %08x %08x %08x %08x %08x\\n\",\n\t   attn.sig[0], attn.sig[1], attn.sig[2], attn.sig[3], attn.sig[4]);\n\n\tfor (index = 0; index < MAX_DYNAMIC_ATTN_GRPS; index++) {\n\t\tif (deasserted & (1 << index)) {\n\t\t\tgroup_mask = &bp->attn_group[index];\n\n\t\t\tDP(NETIF_MSG_HW, \"group[%d]: %08x %08x %08x %08x %08x\\n\",\n\t\t\t   index,\n\t\t\t   group_mask->sig[0], group_mask->sig[1],\n\t\t\t   group_mask->sig[2], group_mask->sig[3],\n\t\t\t   group_mask->sig[4]);\n\n\t\t\tbnx2x_attn_int_deasserted4(bp,\n\t\t\t\t\tattn.sig[4] & group_mask->sig[4]);\n\t\t\tbnx2x_attn_int_deasserted3(bp,\n\t\t\t\t\tattn.sig[3] & group_mask->sig[3]);\n\t\t\tbnx2x_attn_int_deasserted1(bp,\n\t\t\t\t\tattn.sig[1] & group_mask->sig[1]);\n\t\t\tbnx2x_attn_int_deasserted2(bp,\n\t\t\t\t\tattn.sig[2] & group_mask->sig[2]);\n\t\t\tbnx2x_attn_int_deasserted0(bp,\n\t\t\t\t\tattn.sig[0] & group_mask->sig[0]);\n\t\t}\n\t}\n\n\tbnx2x_release_alr(bp);\n\n\tif (bp->common.int_block == INT_BLOCK_HC)\n\t\treg_addr = (HC_REG_COMMAND_REG + port*32 +\n\t\t\t    COMMAND_REG_ATTN_BITS_CLR);\n\telse\n\t\treg_addr = (BAR_IGU_INTMEM + IGU_CMD_ATTN_BIT_CLR_UPPER*8);\n\n\tval = ~deasserted;\n\tDP(NETIF_MSG_HW, \"about to mask 0x%08x at %s addr 0x%x\\n\", val,\n\t   (bp->common.int_block == INT_BLOCK_HC) ? \"HC\" : \"IGU\", reg_addr);\n\tREG_WR(bp, reg_addr, val);\n\n\tif (~bp->attn_state & deasserted)\n\t\tBNX2X_ERR(\"IGU ERROR\\n\");\n\n\treg_addr = port ? MISC_REG_AEU_MASK_ATTN_FUNC_1 :\n\t\t\t  MISC_REG_AEU_MASK_ATTN_FUNC_0;\n\n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_PORT0_ATT_MASK + port);\n\taeu_mask = REG_RD(bp, reg_addr);\n\n\tDP(NETIF_MSG_HW, \"aeu_mask %x  newly deasserted %x\\n\",\n\t   aeu_mask, deasserted);\n\taeu_mask |= (deasserted & 0x3ff);\n\tDP(NETIF_MSG_HW, \"new mask %x\\n\", aeu_mask);\n\n\tREG_WR(bp, reg_addr, aeu_mask);\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_PORT0_ATT_MASK + port);\n\n\tDP(NETIF_MSG_HW, \"attn_state %x\\n\", bp->attn_state);\n\tbp->attn_state &= ~deasserted;\n\tDP(NETIF_MSG_HW, \"new state %x\\n\", bp->attn_state);\n}\n\nstatic void bnx2x_attn_int(struct bnx2x *bp)\n{\n\t \n\tu32 attn_bits = le32_to_cpu(bp->def_status_blk->atten_status_block.\n\t\t\t\t\t\t\t\tattn_bits);\n\tu32 attn_ack = le32_to_cpu(bp->def_status_blk->atten_status_block.\n\t\t\t\t\t\t\t\tattn_bits_ack);\n\tu32 attn_state = bp->attn_state;\n\n\t \n\tu32 asserted   =  attn_bits & ~attn_ack & ~attn_state;\n\tu32 deasserted = ~attn_bits &  attn_ack &  attn_state;\n\n\tDP(NETIF_MSG_HW,\n\t   \"attn_bits %x  attn_ack %x  asserted %x  deasserted %x\\n\",\n\t   attn_bits, attn_ack, asserted, deasserted);\n\n\tif (~(attn_bits ^ attn_ack) & (attn_bits ^ attn_state))\n\t\tBNX2X_ERR(\"BAD attention state\\n\");\n\n\t \n\tif (asserted)\n\t\tbnx2x_attn_int_asserted(bp, asserted);\n\n\tif (deasserted)\n\t\tbnx2x_attn_int_deasserted(bp, deasserted);\n}\n\nvoid bnx2x_igu_ack_sb(struct bnx2x *bp, u8 igu_sb_id, u8 segment,\n\t\t      u16 index, u8 op, u8 update)\n{\n\tu32 igu_addr = bp->igu_base_addr;\n\tigu_addr += (IGU_CMD_INT_ACK_BASE + igu_sb_id)*8;\n\tbnx2x_igu_ack_sb_gen(bp, igu_sb_id, segment, index, op, update,\n\t\t\t     igu_addr);\n}\n\nstatic void bnx2x_update_eq_prod(struct bnx2x *bp, u16 prod)\n{\n\t \n\tstorm_memset_eq_prod(bp, prod, BP_FUNC(bp));\n}\n\nstatic int  bnx2x_cnic_handle_cfc_del(struct bnx2x *bp, u32 cid,\n\t\t\t\t      union event_ring_elem *elem)\n{\n\tu8 err = elem->message.error;\n\n\tif (!bp->cnic_eth_dev.starting_cid  ||\n\t    (cid < bp->cnic_eth_dev.starting_cid &&\n\t    cid != bp->cnic_eth_dev.iscsi_l2_cid))\n\t\treturn 1;\n\n\tDP(BNX2X_MSG_SP, \"got delete ramrod for CNIC CID %d\\n\", cid);\n\n\tif (unlikely(err)) {\n\n\t\tBNX2X_ERR(\"got delete ramrod for CNIC CID %d with error!\\n\",\n\t\t\t  cid);\n\t\tbnx2x_panic_dump(bp, false);\n\t}\n\tbnx2x_cnic_cfc_comp(bp, cid, err);\n\treturn 0;\n}\n\nstatic void bnx2x_handle_mcast_eqe(struct bnx2x *bp)\n{\n\tstruct bnx2x_mcast_ramrod_params rparam;\n\tint rc;\n\n\tmemset(&rparam, 0, sizeof(rparam));\n\n\trparam.mcast_obj = &bp->mcast_obj;\n\n\tnetif_addr_lock_bh(bp->dev);\n\n\t \n\tbp->mcast_obj.raw.clear_pending(&bp->mcast_obj.raw);\n\n\t \n\tif (bp->mcast_obj.check_pending(&bp->mcast_obj)) {\n\t\trc = bnx2x_config_mcast(bp, &rparam, BNX2X_MCAST_CMD_CONT);\n\t\tif (rc < 0)\n\t\t\tBNX2X_ERR(\"Failed to send pending mcast commands: %d\\n\",\n\t\t\t\t  rc);\n\t}\n\n\tnetif_addr_unlock_bh(bp->dev);\n}\n\nstatic void bnx2x_handle_classification_eqe(struct bnx2x *bp,\n\t\t\t\t\t    union event_ring_elem *elem)\n{\n\tunsigned long ramrod_flags = 0;\n\tint rc = 0;\n\tu32 echo = le32_to_cpu(elem->message.data.eth_event.echo);\n\tu32 cid = echo & BNX2X_SWCID_MASK;\n\tstruct bnx2x_vlan_mac_obj *vlan_mac_obj;\n\n\t \n\t__set_bit(RAMROD_CONT, &ramrod_flags);\n\n\tswitch (echo >> BNX2X_SWCID_SHIFT) {\n\tcase BNX2X_FILTER_MAC_PENDING:\n\t\tDP(BNX2X_MSG_SP, \"Got SETUP_MAC completions\\n\");\n\t\tif (CNIC_LOADED(bp) && (cid == BNX2X_ISCSI_ETH_CID(bp)))\n\t\t\tvlan_mac_obj = &bp->iscsi_l2_mac_obj;\n\t\telse\n\t\t\tvlan_mac_obj = &bp->sp_objs[cid].mac_obj;\n\n\t\tbreak;\n\tcase BNX2X_FILTER_VLAN_PENDING:\n\t\tDP(BNX2X_MSG_SP, \"Got SETUP_VLAN completions\\n\");\n\t\tvlan_mac_obj = &bp->sp_objs[cid].vlan_obj;\n\t\tbreak;\n\tcase BNX2X_FILTER_MCAST_PENDING:\n\t\tDP(BNX2X_MSG_SP, \"Got SETUP_MCAST completions\\n\");\n\t\t \n\t\tbnx2x_handle_mcast_eqe(bp);\n\t\treturn;\n\tdefault:\n\t\tBNX2X_ERR(\"Unsupported classification command: 0x%x\\n\", echo);\n\t\treturn;\n\t}\n\n\trc = vlan_mac_obj->complete(bp, vlan_mac_obj, elem, &ramrod_flags);\n\n\tif (rc < 0)\n\t\tBNX2X_ERR(\"Failed to schedule new commands: %d\\n\", rc);\n\telse if (rc > 0)\n\t\tDP(BNX2X_MSG_SP, \"Scheduled next pending commands...\\n\");\n}\n\nstatic void bnx2x_set_iscsi_eth_rx_mode(struct bnx2x *bp, bool start);\n\nstatic void bnx2x_handle_rx_mode_eqe(struct bnx2x *bp)\n{\n\tnetif_addr_lock_bh(bp->dev);\n\n\tclear_bit(BNX2X_FILTER_RX_MODE_PENDING, &bp->sp_state);\n\n\t \n\tif (test_and_clear_bit(BNX2X_FILTER_RX_MODE_SCHED, &bp->sp_state))\n\t\tbnx2x_set_storm_rx_mode(bp);\n\telse if (test_and_clear_bit(BNX2X_FILTER_ISCSI_ETH_START_SCHED,\n\t\t\t\t    &bp->sp_state))\n\t\tbnx2x_set_iscsi_eth_rx_mode(bp, true);\n\telse if (test_and_clear_bit(BNX2X_FILTER_ISCSI_ETH_STOP_SCHED,\n\t\t\t\t    &bp->sp_state))\n\t\tbnx2x_set_iscsi_eth_rx_mode(bp, false);\n\n\tnetif_addr_unlock_bh(bp->dev);\n}\n\nstatic void bnx2x_after_afex_vif_lists(struct bnx2x *bp,\n\t\t\t\t\t      union event_ring_elem *elem)\n{\n\tif (elem->message.data.vif_list_event.echo == VIF_LIST_RULE_GET) {\n\t\tDP(BNX2X_MSG_SP,\n\t\t   \"afex: ramrod completed VIF LIST_GET, addrs 0x%x\\n\",\n\t\t   elem->message.data.vif_list_event.func_bit_map);\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_AFEX_LISTGET_ACK,\n\t\t\telem->message.data.vif_list_event.func_bit_map);\n\t} else if (elem->message.data.vif_list_event.echo ==\n\t\t   VIF_LIST_RULE_SET) {\n\t\tDP(BNX2X_MSG_SP, \"afex: ramrod completed VIF LIST_SET\\n\");\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_AFEX_LISTSET_ACK, 0);\n\t}\n}\n\n \nstatic void bnx2x_after_function_update(struct bnx2x *bp)\n{\n\tint q, rc;\n\tstruct bnx2x_fastpath *fp;\n\tstruct bnx2x_queue_state_params queue_params = {NULL};\n\tstruct bnx2x_queue_update_params *q_update_params =\n\t\t&queue_params.params.update;\n\n\t \n\tqueue_params.cmd = BNX2X_Q_CMD_UPDATE;\n\n\t \n\t__set_bit(BNX2X_Q_UPDATE_SILENT_VLAN_REM_CHNG,\n\t\t  &q_update_params->update_flags);\n\t__set_bit(BNX2X_Q_UPDATE_SILENT_VLAN_REM,\n\t\t  &q_update_params->update_flags);\n\t__set_bit(RAMROD_COMP_WAIT, &queue_params.ramrod_flags);\n\n\t \n\tif (bp->afex_vlan_mode == FUNC_MF_CFG_AFEX_VLAN_ACCESS_MODE) {\n\t\tq_update_params->silent_removal_value = 0;\n\t\tq_update_params->silent_removal_mask = 0;\n\t} else {\n\t\tq_update_params->silent_removal_value =\n\t\t\t(bp->afex_def_vlan_tag & VLAN_VID_MASK);\n\t\tq_update_params->silent_removal_mask = VLAN_VID_MASK;\n\t}\n\n\tfor_each_eth_queue(bp, q) {\n\t\t \n\t\tfp = &bp->fp[q];\n\t\tqueue_params.q_obj = &bnx2x_sp_obj(bp, fp).q_obj;\n\n\t\t \n\t\trc = bnx2x_queue_state_change(bp, &queue_params);\n\t\tif (rc < 0)\n\t\t\tBNX2X_ERR(\"Failed to config silent vlan rem for Q %d\\n\",\n\t\t\t\t  q);\n\t}\n\n\tif (!NO_FCOE(bp) && CNIC_ENABLED(bp)) {\n\t\tfp = &bp->fp[FCOE_IDX(bp)];\n\t\tqueue_params.q_obj = &bnx2x_sp_obj(bp, fp).q_obj;\n\n\t\t \n\t\t__clear_bit(RAMROD_COMP_WAIT, &queue_params.ramrod_flags);\n\n\t\t \n\t\tsmp_mb__before_atomic();\n\t\tset_bit(BNX2X_AFEX_FCOE_Q_UPDATE_PENDING, &bp->sp_state);\n\t\tsmp_mb__after_atomic();\n\n\t\t \n\t\trc = bnx2x_queue_state_change(bp, &queue_params);\n\t\tif (rc < 0)\n\t\t\tBNX2X_ERR(\"Failed to config silent vlan rem for Q %d\\n\",\n\t\t\t\t  q);\n\t} else {\n\t\t \n\t\tbnx2x_link_report(bp);\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_AFEX_VIFSET_ACK, 0);\n\t}\n}\n\nstatic struct bnx2x_queue_sp_obj *bnx2x_cid_to_q_obj(\n\tstruct bnx2x *bp, u32 cid)\n{\n\tDP(BNX2X_MSG_SP, \"retrieving fp from cid %d\\n\", cid);\n\n\tif (CNIC_LOADED(bp) && (cid == BNX2X_FCOE_ETH_CID(bp)))\n\t\treturn &bnx2x_fcoe_sp_obj(bp, q_obj);\n\telse\n\t\treturn &bp->sp_objs[CID_TO_FP(cid, bp)].q_obj;\n}\n\nstatic void bnx2x_eq_int(struct bnx2x *bp)\n{\n\tu16 hw_cons, sw_cons, sw_prod;\n\tunion event_ring_elem *elem;\n\tu8 echo;\n\tu32 cid;\n\tu8 opcode;\n\tint rc, spqe_cnt = 0;\n\tstruct bnx2x_queue_sp_obj *q_obj;\n\tstruct bnx2x_func_sp_obj *f_obj = &bp->func_obj;\n\tstruct bnx2x_raw_obj *rss_raw = &bp->rss_conf_obj.raw;\n\n\thw_cons = le16_to_cpu(*bp->eq_cons_sb);\n\n\t \n\tif ((hw_cons & EQ_DESC_MAX_PAGE) == EQ_DESC_MAX_PAGE)\n\t\thw_cons++;\n\n\t \n\tsw_cons = bp->eq_cons;\n\tsw_prod = bp->eq_prod;\n\n\tDP(BNX2X_MSG_SP, \"EQ:  hw_cons %u  sw_cons %u bp->eq_spq_left %x\\n\",\n\t\t\thw_cons, sw_cons, atomic_read(&bp->eq_spq_left));\n\n\tfor (; sw_cons != hw_cons;\n\t      sw_prod = NEXT_EQ_IDX(sw_prod), sw_cons = NEXT_EQ_IDX(sw_cons)) {\n\n\t\telem = &bp->eq_ring[EQ_DESC(sw_cons)];\n\n\t\trc = bnx2x_iov_eq_sp_event(bp, elem);\n\t\tif (!rc) {\n\t\t\tDP(BNX2X_MSG_IOV, \"bnx2x_iov_eq_sp_event returned %d\\n\",\n\t\t\t   rc);\n\t\t\tgoto next_spqe;\n\t\t}\n\n\t\topcode = elem->message.opcode;\n\n\t\t \n\t\tswitch (opcode) {\n\t\tcase EVENT_RING_OPCODE_VF_PF_CHANNEL:\n\t\t\tbnx2x_vf_mbx_schedule(bp,\n\t\t\t\t\t      &elem->message.data.vf_pf_event);\n\t\t\tcontinue;\n\n\t\tcase EVENT_RING_OPCODE_STAT_QUERY:\n\t\t\tDP_AND((BNX2X_MSG_SP | BNX2X_MSG_STATS),\n\t\t\t       \"got statistics comp event %d\\n\",\n\t\t\t       bp->stats_comp++);\n\t\t\t \n\t\t\tgoto next_spqe;\n\n\t\tcase EVENT_RING_OPCODE_CFC_DEL:\n\t\t\t \n\t\t\t \n\n\t\t\t \n\t\t\tcid = SW_CID(elem->message.data.cfc_del_event.cid);\n\n\t\t\tDP(BNX2X_MSG_SP,\n\t\t\t   \"got delete ramrod for MULTI[%d]\\n\", cid);\n\n\t\t\tif (CNIC_LOADED(bp) &&\n\t\t\t    !bnx2x_cnic_handle_cfc_del(bp, cid, elem))\n\t\t\t\tgoto next_spqe;\n\n\t\t\tq_obj = bnx2x_cid_to_q_obj(bp, cid);\n\n\t\t\tif (q_obj->complete_cmd(bp, q_obj, BNX2X_Q_CMD_CFC_DEL))\n\t\t\t\tbreak;\n\n\t\t\tgoto next_spqe;\n\n\t\tcase EVENT_RING_OPCODE_STOP_TRAFFIC:\n\t\t\tDP(BNX2X_MSG_SP | BNX2X_MSG_DCB, \"got STOP TRAFFIC\\n\");\n\t\t\tbnx2x_dcbx_set_params(bp, BNX2X_DCBX_STATE_TX_PAUSED);\n\t\t\tif (f_obj->complete_cmd(bp, f_obj,\n\t\t\t\t\t\tBNX2X_F_CMD_TX_STOP))\n\t\t\t\tbreak;\n\t\t\tgoto next_spqe;\n\n\t\tcase EVENT_RING_OPCODE_START_TRAFFIC:\n\t\t\tDP(BNX2X_MSG_SP | BNX2X_MSG_DCB, \"got START TRAFFIC\\n\");\n\t\t\tbnx2x_dcbx_set_params(bp, BNX2X_DCBX_STATE_TX_RELEASED);\n\t\t\tif (f_obj->complete_cmd(bp, f_obj,\n\t\t\t\t\t\tBNX2X_F_CMD_TX_START))\n\t\t\t\tbreak;\n\t\t\tgoto next_spqe;\n\n\t\tcase EVENT_RING_OPCODE_FUNCTION_UPDATE:\n\t\t\techo = elem->message.data.function_update_event.echo;\n\t\t\tif (echo == SWITCH_UPDATE) {\n\t\t\t\tDP(BNX2X_MSG_SP | NETIF_MSG_IFUP,\n\t\t\t\t   \"got FUNC_SWITCH_UPDATE ramrod\\n\");\n\t\t\t\tif (f_obj->complete_cmd(\n\t\t\t\t\tbp, f_obj, BNX2X_F_CMD_SWITCH_UPDATE))\n\t\t\t\t\tbreak;\n\n\t\t\t} else {\n\t\t\t\tint cmd = BNX2X_SP_RTNL_AFEX_F_UPDATE;\n\n\t\t\t\tDP(BNX2X_MSG_SP | BNX2X_MSG_MCP,\n\t\t\t\t   \"AFEX: ramrod completed FUNCTION_UPDATE\\n\");\n\t\t\t\tf_obj->complete_cmd(bp, f_obj,\n\t\t\t\t\t\t    BNX2X_F_CMD_AFEX_UPDATE);\n\n\t\t\t\t \n\t\t\t\tbnx2x_schedule_sp_rtnl(bp, cmd, 0);\n\t\t\t}\n\n\t\t\tgoto next_spqe;\n\n\t\tcase EVENT_RING_OPCODE_AFEX_VIF_LISTS:\n\t\t\tf_obj->complete_cmd(bp, f_obj,\n\t\t\t\t\t    BNX2X_F_CMD_AFEX_VIFLISTS);\n\t\t\tbnx2x_after_afex_vif_lists(bp, elem);\n\t\t\tgoto next_spqe;\n\t\tcase EVENT_RING_OPCODE_FUNCTION_START:\n\t\t\tDP(BNX2X_MSG_SP | NETIF_MSG_IFUP,\n\t\t\t   \"got FUNC_START ramrod\\n\");\n\t\t\tif (f_obj->complete_cmd(bp, f_obj, BNX2X_F_CMD_START))\n\t\t\t\tbreak;\n\n\t\t\tgoto next_spqe;\n\n\t\tcase EVENT_RING_OPCODE_FUNCTION_STOP:\n\t\t\tDP(BNX2X_MSG_SP | NETIF_MSG_IFUP,\n\t\t\t   \"got FUNC_STOP ramrod\\n\");\n\t\t\tif (f_obj->complete_cmd(bp, f_obj, BNX2X_F_CMD_STOP))\n\t\t\t\tbreak;\n\n\t\t\tgoto next_spqe;\n\n\t\tcase EVENT_RING_OPCODE_SET_TIMESYNC:\n\t\t\tDP(BNX2X_MSG_SP | BNX2X_MSG_PTP,\n\t\t\t   \"got set_timesync ramrod completion\\n\");\n\t\t\tif (f_obj->complete_cmd(bp, f_obj,\n\t\t\t\t\t\tBNX2X_F_CMD_SET_TIMESYNC))\n\t\t\t\tbreak;\n\t\t\tgoto next_spqe;\n\t\t}\n\n\t\tswitch (opcode | bp->state) {\n\t\tcase (EVENT_RING_OPCODE_RSS_UPDATE_RULES |\n\t\t      BNX2X_STATE_OPEN):\n\t\tcase (EVENT_RING_OPCODE_RSS_UPDATE_RULES |\n\t\t      BNX2X_STATE_OPENING_WAIT4_PORT):\n\t\tcase (EVENT_RING_OPCODE_RSS_UPDATE_RULES |\n\t\t      BNX2X_STATE_CLOSING_WAIT4_HALT):\n\t\t\tDP(BNX2X_MSG_SP, \"got RSS_UPDATE ramrod. CID %d\\n\",\n\t\t\t   SW_CID(elem->message.data.eth_event.echo));\n\t\t\trss_raw->clear_pending(rss_raw);\n\t\t\tbreak;\n\n\t\tcase (EVENT_RING_OPCODE_SET_MAC | BNX2X_STATE_OPEN):\n\t\tcase (EVENT_RING_OPCODE_SET_MAC | BNX2X_STATE_DIAG):\n\t\tcase (EVENT_RING_OPCODE_SET_MAC |\n\t\t      BNX2X_STATE_CLOSING_WAIT4_HALT):\n\t\tcase (EVENT_RING_OPCODE_CLASSIFICATION_RULES |\n\t\t      BNX2X_STATE_OPEN):\n\t\tcase (EVENT_RING_OPCODE_CLASSIFICATION_RULES |\n\t\t      BNX2X_STATE_DIAG):\n\t\tcase (EVENT_RING_OPCODE_CLASSIFICATION_RULES |\n\t\t      BNX2X_STATE_CLOSING_WAIT4_HALT):\n\t\t\tDP(BNX2X_MSG_SP, \"got (un)set vlan/mac ramrod\\n\");\n\t\t\tbnx2x_handle_classification_eqe(bp, elem);\n\t\t\tbreak;\n\n\t\tcase (EVENT_RING_OPCODE_MULTICAST_RULES |\n\t\t      BNX2X_STATE_OPEN):\n\t\tcase (EVENT_RING_OPCODE_MULTICAST_RULES |\n\t\t      BNX2X_STATE_DIAG):\n\t\tcase (EVENT_RING_OPCODE_MULTICAST_RULES |\n\t\t      BNX2X_STATE_CLOSING_WAIT4_HALT):\n\t\t\tDP(BNX2X_MSG_SP, \"got mcast ramrod\\n\");\n\t\t\tbnx2x_handle_mcast_eqe(bp);\n\t\t\tbreak;\n\n\t\tcase (EVENT_RING_OPCODE_FILTERS_RULES |\n\t\t      BNX2X_STATE_OPEN):\n\t\tcase (EVENT_RING_OPCODE_FILTERS_RULES |\n\t\t      BNX2X_STATE_DIAG):\n\t\tcase (EVENT_RING_OPCODE_FILTERS_RULES |\n\t\t      BNX2X_STATE_CLOSING_WAIT4_HALT):\n\t\t\tDP(BNX2X_MSG_SP, \"got rx_mode ramrod\\n\");\n\t\t\tbnx2x_handle_rx_mode_eqe(bp);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tBNX2X_ERR(\"Unknown EQ event %d, bp->state 0x%x\\n\",\n\t\t\t\t  elem->message.opcode, bp->state);\n\t\t}\nnext_spqe:\n\t\tspqe_cnt++;\n\t}  \n\n\tsmp_mb__before_atomic();\n\tatomic_add(spqe_cnt, &bp->eq_spq_left);\n\n\tbp->eq_cons = sw_cons;\n\tbp->eq_prod = sw_prod;\n\t \n\tsmp_wmb();\n\n\t \n\tbnx2x_update_eq_prod(bp, bp->eq_prod);\n}\n\nstatic void bnx2x_sp_task(struct work_struct *work)\n{\n\tstruct bnx2x *bp = container_of(work, struct bnx2x, sp_task.work);\n\n\tDP(BNX2X_MSG_SP, \"sp task invoked\\n\");\n\n\t \n\tsmp_rmb();\n\tif (atomic_read(&bp->interrupt_occurred)) {\n\n\t\t \n\t\tu16 status = bnx2x_update_dsb_idx(bp);\n\n\t\tDP(BNX2X_MSG_SP, \"status %x\\n\", status);\n\t\tDP(BNX2X_MSG_SP, \"setting interrupt_occurred to 0\\n\");\n\t\tatomic_set(&bp->interrupt_occurred, 0);\n\n\t\t \n\t\tif (status & BNX2X_DEF_SB_ATT_IDX) {\n\t\t\tbnx2x_attn_int(bp);\n\t\t\tstatus &= ~BNX2X_DEF_SB_ATT_IDX;\n\t\t}\n\n\t\t \n\t\tif (status & BNX2X_DEF_SB_IDX) {\n\t\t\tstruct bnx2x_fastpath *fp = bnx2x_fcoe_fp(bp);\n\n\t\t\tif (FCOE_INIT(bp) &&\n\t\t\t    (bnx2x_has_rx_work(fp) || bnx2x_has_tx_work(fp))) {\n\t\t\t\t \n\t\t\t\tlocal_bh_disable();\n\t\t\t\tnapi_schedule(&bnx2x_fcoe(bp, napi));\n\t\t\t\tlocal_bh_enable();\n\t\t\t}\n\n\t\t\t \n\t\t\tbnx2x_eq_int(bp);\n\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id, USTORM_ID,\n\t\t\t\t     le16_to_cpu(bp->def_idx), IGU_INT_NOP, 1);\n\n\t\t\tstatus &= ~BNX2X_DEF_SB_IDX;\n\t\t}\n\n\t\t \n\t\tif (unlikely(status))\n\t\t\tDP(BNX2X_MSG_SP,\n\t\t\t   \"got an unknown interrupt! (status 0x%x)\\n\", status);\n\n\t\t \n\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id, ATTENTION_ID,\n\t\t\t     le16_to_cpu(bp->def_att_idx), IGU_INT_ENABLE, 1);\n\t}\n\n\t \n\tif (test_and_clear_bit(BNX2X_AFEX_PENDING_VIFSET_MCP_ACK,\n\t\t\t       &bp->sp_state)) {\n\t\tbnx2x_link_report(bp);\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_AFEX_VIFSET_ACK, 0);\n\t}\n}\n\nirqreturn_t bnx2x_msix_sp_int(int irq, void *dev_instance)\n{\n\tstruct net_device *dev = dev_instance;\n\tstruct bnx2x *bp = netdev_priv(dev);\n\n\tbnx2x_ack_sb(bp, bp->igu_dsb_id, USTORM_ID, 0,\n\t\t     IGU_INT_DISABLE, 0);\n\n#ifdef BNX2X_STOP_ON_ERROR\n\tif (unlikely(bp->panic))\n\t\treturn IRQ_HANDLED;\n#endif\n\n\tif (CNIC_LOADED(bp)) {\n\t\tstruct cnic_ops *c_ops;\n\n\t\trcu_read_lock();\n\t\tc_ops = rcu_dereference(bp->cnic_ops);\n\t\tif (c_ops)\n\t\t\tc_ops->cnic_handler(bp->cnic_data, NULL);\n\t\trcu_read_unlock();\n\t}\n\n\t \n\tbnx2x_schedule_sp_task(bp);\n\n\treturn IRQ_HANDLED;\n}\n\n \n\nvoid bnx2x_drv_pulse(struct bnx2x *bp)\n{\n\tSHMEM_WR(bp, func_mb[BP_FW_MB_IDX(bp)].drv_pulse_mb,\n\t\t bp->fw_drv_pulse_wr_seq);\n}\n\nstatic void bnx2x_timer(struct timer_list *t)\n{\n\tstruct bnx2x *bp = from_timer(bp, t, timer);\n\n\tif (!netif_running(bp->dev))\n\t\treturn;\n\n\tif (IS_PF(bp) &&\n\t    !BP_NOMCP(bp)) {\n\t\tint mb_idx = BP_FW_MB_IDX(bp);\n\t\tu16 drv_pulse;\n\t\tu16 mcp_pulse;\n\n\t\t++bp->fw_drv_pulse_wr_seq;\n\t\tbp->fw_drv_pulse_wr_seq &= DRV_PULSE_SEQ_MASK;\n\t\tdrv_pulse = bp->fw_drv_pulse_wr_seq;\n\t\tbnx2x_drv_pulse(bp);\n\n\t\tmcp_pulse = (SHMEM_RD(bp, func_mb[mb_idx].mcp_pulse_mb) &\n\t\t\t     MCP_PULSE_SEQ_MASK);\n\t\t \n\t\tif (((drv_pulse - mcp_pulse) & MCP_PULSE_SEQ_MASK) > 5)\n\t\t\tBNX2X_ERR(\"MFW seems hanged: drv_pulse (0x%x) != mcp_pulse (0x%x)\\n\",\n\t\t\t\t  drv_pulse, mcp_pulse);\n\t}\n\n\tif (bp->state == BNX2X_STATE_OPEN)\n\t\tbnx2x_stats_handle(bp, STATS_EVENT_UPDATE);\n\n\t \n\tif (IS_VF(bp))\n\t\tbnx2x_timer_sriov(bp);\n\n\tmod_timer(&bp->timer, jiffies + bp->current_interval);\n}\n\n \n\n \n\n \n\nstatic void bnx2x_fill(struct bnx2x *bp, u32 addr, int fill, u32 len)\n{\n\tu32 i;\n\tif (!(len%4) && !(addr%4))\n\t\tfor (i = 0; i < len; i += 4)\n\t\t\tREG_WR(bp, addr + i, fill);\n\telse\n\t\tfor (i = 0; i < len; i++)\n\t\t\tREG_WR8(bp, addr + i, fill);\n}\n\n \nstatic void bnx2x_wr_fp_sb_data(struct bnx2x *bp,\n\t\t\t\tint fw_sb_id,\n\t\t\t\tu32 *sb_data_p,\n\t\t\t\tu32 data_size)\n{\n\tint index;\n\tfor (index = 0; index < data_size; index++)\n\t\tREG_WR(bp, BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_STATUS_BLOCK_DATA_OFFSET(fw_sb_id) +\n\t\t\tsizeof(u32)*index,\n\t\t\t*(sb_data_p + index));\n}\n\nstatic void bnx2x_zero_fp_sb(struct bnx2x *bp, int fw_sb_id)\n{\n\tu32 *sb_data_p;\n\tu32 data_size = 0;\n\tstruct hc_status_block_data_e2 sb_data_e2;\n\tstruct hc_status_block_data_e1x sb_data_e1x;\n\n\t \n\tif (!CHIP_IS_E1x(bp)) {\n\t\tmemset(&sb_data_e2, 0, sizeof(struct hc_status_block_data_e2));\n\t\tsb_data_e2.common.state = SB_DISABLED;\n\t\tsb_data_e2.common.p_func.vf_valid = false;\n\t\tsb_data_p = (u32 *)&sb_data_e2;\n\t\tdata_size = sizeof(struct hc_status_block_data_e2)/sizeof(u32);\n\t} else {\n\t\tmemset(&sb_data_e1x, 0,\n\t\t       sizeof(struct hc_status_block_data_e1x));\n\t\tsb_data_e1x.common.state = SB_DISABLED;\n\t\tsb_data_e1x.common.p_func.vf_valid = false;\n\t\tsb_data_p = (u32 *)&sb_data_e1x;\n\t\tdata_size = sizeof(struct hc_status_block_data_e1x)/sizeof(u32);\n\t}\n\tbnx2x_wr_fp_sb_data(bp, fw_sb_id, sb_data_p, data_size);\n\n\tbnx2x_fill(bp, BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_STATUS_BLOCK_OFFSET(fw_sb_id), 0,\n\t\t\tCSTORM_STATUS_BLOCK_SIZE);\n\tbnx2x_fill(bp, BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_SYNC_BLOCK_OFFSET(fw_sb_id), 0,\n\t\t\tCSTORM_SYNC_BLOCK_SIZE);\n}\n\n \nstatic void bnx2x_wr_sp_sb_data(struct bnx2x *bp,\n\t\tstruct hc_sp_status_block_data *sp_sb_data)\n{\n\tint func = BP_FUNC(bp);\n\tint i;\n\tfor (i = 0; i < sizeof(struct hc_sp_status_block_data)/sizeof(u32); i++)\n\t\tREG_WR(bp, BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_SP_STATUS_BLOCK_DATA_OFFSET(func) +\n\t\t\ti*sizeof(u32),\n\t\t\t*((u32 *)sp_sb_data + i));\n}\n\nstatic void bnx2x_zero_sp_sb(struct bnx2x *bp)\n{\n\tint func = BP_FUNC(bp);\n\tstruct hc_sp_status_block_data sp_sb_data;\n\tmemset(&sp_sb_data, 0, sizeof(struct hc_sp_status_block_data));\n\n\tsp_sb_data.state = SB_DISABLED;\n\tsp_sb_data.p_func.vf_valid = false;\n\n\tbnx2x_wr_sp_sb_data(bp, &sp_sb_data);\n\n\tbnx2x_fill(bp, BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_SP_STATUS_BLOCK_OFFSET(func), 0,\n\t\t\tCSTORM_SP_STATUS_BLOCK_SIZE);\n\tbnx2x_fill(bp, BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_SP_SYNC_BLOCK_OFFSET(func), 0,\n\t\t\tCSTORM_SP_SYNC_BLOCK_SIZE);\n}\n\nstatic void bnx2x_setup_ndsb_state_machine(struct hc_status_block_sm *hc_sm,\n\t\t\t\t\t   int igu_sb_id, int igu_seg_id)\n{\n\thc_sm->igu_sb_id = igu_sb_id;\n\thc_sm->igu_seg_id = igu_seg_id;\n\thc_sm->timer_value = 0xFF;\n\thc_sm->time_to_expire = 0xFFFFFFFF;\n}\n\n \nstatic void bnx2x_map_sb_state_machines(struct hc_index_data *index_data)\n{\n\t \n\t \n\tindex_data[HC_INDEX_ETH_RX_CQ_CONS].flags &= ~HC_INDEX_DATA_SM_ID;\n\n\t \n\tindex_data[HC_INDEX_OOO_TX_CQ_CONS].flags &= ~HC_INDEX_DATA_SM_ID;\n\tindex_data[HC_INDEX_ETH_TX_CQ_CONS_COS0].flags &= ~HC_INDEX_DATA_SM_ID;\n\tindex_data[HC_INDEX_ETH_TX_CQ_CONS_COS1].flags &= ~HC_INDEX_DATA_SM_ID;\n\tindex_data[HC_INDEX_ETH_TX_CQ_CONS_COS2].flags &= ~HC_INDEX_DATA_SM_ID;\n\n\t \n\t \n\tindex_data[HC_INDEX_ETH_RX_CQ_CONS].flags |=\n\t\tSM_RX_ID << HC_INDEX_DATA_SM_ID_SHIFT;\n\n\t \n\tindex_data[HC_INDEX_OOO_TX_CQ_CONS].flags |=\n\t\tSM_TX_ID << HC_INDEX_DATA_SM_ID_SHIFT;\n\tindex_data[HC_INDEX_ETH_TX_CQ_CONS_COS0].flags |=\n\t\tSM_TX_ID << HC_INDEX_DATA_SM_ID_SHIFT;\n\tindex_data[HC_INDEX_ETH_TX_CQ_CONS_COS1].flags |=\n\t\tSM_TX_ID << HC_INDEX_DATA_SM_ID_SHIFT;\n\tindex_data[HC_INDEX_ETH_TX_CQ_CONS_COS2].flags |=\n\t\tSM_TX_ID << HC_INDEX_DATA_SM_ID_SHIFT;\n}\n\nvoid bnx2x_init_sb(struct bnx2x *bp, dma_addr_t mapping, int vfid,\n\t\t\t  u8 vf_valid, int fw_sb_id, int igu_sb_id)\n{\n\tint igu_seg_id;\n\n\tstruct hc_status_block_data_e2 sb_data_e2;\n\tstruct hc_status_block_data_e1x sb_data_e1x;\n\tstruct hc_status_block_sm  *hc_sm_p;\n\tint data_size;\n\tu32 *sb_data_p;\n\n\tif (CHIP_INT_MODE_IS_BC(bp))\n\t\tigu_seg_id = HC_SEG_ACCESS_NORM;\n\telse\n\t\tigu_seg_id = IGU_SEG_ACCESS_NORM;\n\n\tbnx2x_zero_fp_sb(bp, fw_sb_id);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tmemset(&sb_data_e2, 0, sizeof(struct hc_status_block_data_e2));\n\t\tsb_data_e2.common.state = SB_ENABLED;\n\t\tsb_data_e2.common.p_func.pf_id = BP_FUNC(bp);\n\t\tsb_data_e2.common.p_func.vf_id = vfid;\n\t\tsb_data_e2.common.p_func.vf_valid = vf_valid;\n\t\tsb_data_e2.common.p_func.vnic_id = BP_VN(bp);\n\t\tsb_data_e2.common.same_igu_sb_1b = true;\n\t\tsb_data_e2.common.host_sb_addr.hi = U64_HI(mapping);\n\t\tsb_data_e2.common.host_sb_addr.lo = U64_LO(mapping);\n\t\thc_sm_p = sb_data_e2.common.state_machine;\n\t\tsb_data_p = (u32 *)&sb_data_e2;\n\t\tdata_size = sizeof(struct hc_status_block_data_e2)/sizeof(u32);\n\t\tbnx2x_map_sb_state_machines(sb_data_e2.index_data);\n\t} else {\n\t\tmemset(&sb_data_e1x, 0,\n\t\t       sizeof(struct hc_status_block_data_e1x));\n\t\tsb_data_e1x.common.state = SB_ENABLED;\n\t\tsb_data_e1x.common.p_func.pf_id = BP_FUNC(bp);\n\t\tsb_data_e1x.common.p_func.vf_id = 0xff;\n\t\tsb_data_e1x.common.p_func.vf_valid = false;\n\t\tsb_data_e1x.common.p_func.vnic_id = BP_VN(bp);\n\t\tsb_data_e1x.common.same_igu_sb_1b = true;\n\t\tsb_data_e1x.common.host_sb_addr.hi = U64_HI(mapping);\n\t\tsb_data_e1x.common.host_sb_addr.lo = U64_LO(mapping);\n\t\thc_sm_p = sb_data_e1x.common.state_machine;\n\t\tsb_data_p = (u32 *)&sb_data_e1x;\n\t\tdata_size = sizeof(struct hc_status_block_data_e1x)/sizeof(u32);\n\t\tbnx2x_map_sb_state_machines(sb_data_e1x.index_data);\n\t}\n\n\tbnx2x_setup_ndsb_state_machine(&hc_sm_p[SM_RX_ID],\n\t\t\t\t       igu_sb_id, igu_seg_id);\n\tbnx2x_setup_ndsb_state_machine(&hc_sm_p[SM_TX_ID],\n\t\t\t\t       igu_sb_id, igu_seg_id);\n\n\tDP(NETIF_MSG_IFUP, \"Init FW SB %d\\n\", fw_sb_id);\n\n\t \n\tbnx2x_wr_fp_sb_data(bp, fw_sb_id, sb_data_p, data_size);\n}\n\nstatic void bnx2x_update_coalesce_sb(struct bnx2x *bp, u8 fw_sb_id,\n\t\t\t\t     u16 tx_usec, u16 rx_usec)\n{\n\tbnx2x_update_coalesce_sb_index(bp, fw_sb_id, HC_INDEX_ETH_RX_CQ_CONS,\n\t\t\t\t    false, rx_usec);\n\tbnx2x_update_coalesce_sb_index(bp, fw_sb_id,\n\t\t\t\t       HC_INDEX_ETH_TX_CQ_CONS_COS0, false,\n\t\t\t\t       tx_usec);\n\tbnx2x_update_coalesce_sb_index(bp, fw_sb_id,\n\t\t\t\t       HC_INDEX_ETH_TX_CQ_CONS_COS1, false,\n\t\t\t\t       tx_usec);\n\tbnx2x_update_coalesce_sb_index(bp, fw_sb_id,\n\t\t\t\t       HC_INDEX_ETH_TX_CQ_CONS_COS2, false,\n\t\t\t\t       tx_usec);\n}\n\nstatic void bnx2x_init_def_sb(struct bnx2x *bp)\n{\n\tstruct host_sp_status_block *def_sb = bp->def_status_blk;\n\tdma_addr_t mapping = bp->def_status_blk_mapping;\n\tint igu_sp_sb_index;\n\tint igu_seg_id;\n\tint port = BP_PORT(bp);\n\tint func = BP_FUNC(bp);\n\tint reg_offset, reg_offset_en5;\n\tu64 section;\n\tint index;\n\tstruct hc_sp_status_block_data sp_sb_data;\n\tmemset(&sp_sb_data, 0, sizeof(struct hc_sp_status_block_data));\n\n\tif (CHIP_INT_MODE_IS_BC(bp)) {\n\t\tigu_sp_sb_index = DEF_SB_IGU_ID;\n\t\tigu_seg_id = HC_SEG_ACCESS_DEF;\n\t} else {\n\t\tigu_sp_sb_index = bp->igu_dsb_id;\n\t\tigu_seg_id = IGU_SEG_ACCESS_DEF;\n\t}\n\n\t \n\tsection = ((u64)mapping) + offsetof(struct host_sp_status_block,\n\t\t\t\t\t    atten_status_block);\n\tdef_sb->atten_status_block.status_block_id = igu_sp_sb_index;\n\n\tbp->attn_state = 0;\n\n\treg_offset = (port ? MISC_REG_AEU_ENABLE1_FUNC_1_OUT_0 :\n\t\t\t     MISC_REG_AEU_ENABLE1_FUNC_0_OUT_0);\n\treg_offset_en5 = (port ? MISC_REG_AEU_ENABLE5_FUNC_1_OUT_0 :\n\t\t\t\t MISC_REG_AEU_ENABLE5_FUNC_0_OUT_0);\n\tfor (index = 0; index < MAX_DYNAMIC_ATTN_GRPS; index++) {\n\t\tint sindex;\n\t\t \n\t\tfor (sindex = 0; sindex < 4; sindex++)\n\t\t\tbp->attn_group[index].sig[sindex] =\n\t\t\t   REG_RD(bp, reg_offset + sindex*0x4 + 0x10*index);\n\n\t\tif (!CHIP_IS_E1x(bp))\n\t\t\t \n\t\t\tbp->attn_group[index].sig[4] = REG_RD(bp,\n\t\t\t\t\treg_offset_en5 + 0x4*index);\n\t\telse\n\t\t\tbp->attn_group[index].sig[4] = 0;\n\t}\n\n\tif (bp->common.int_block == INT_BLOCK_HC) {\n\t\treg_offset = (port ? HC_REG_ATTN_MSG1_ADDR_L :\n\t\t\t\t     HC_REG_ATTN_MSG0_ADDR_L);\n\n\t\tREG_WR(bp, reg_offset, U64_LO(section));\n\t\tREG_WR(bp, reg_offset + 4, U64_HI(section));\n\t} else if (!CHIP_IS_E1x(bp)) {\n\t\tREG_WR(bp, IGU_REG_ATTN_MSG_ADDR_L, U64_LO(section));\n\t\tREG_WR(bp, IGU_REG_ATTN_MSG_ADDR_H, U64_HI(section));\n\t}\n\n\tsection = ((u64)mapping) + offsetof(struct host_sp_status_block,\n\t\t\t\t\t    sp_sb);\n\n\tbnx2x_zero_sp_sb(bp);\n\n\t \n\tsp_sb_data.state\t\t= SB_ENABLED;\n\tsp_sb_data.host_sb_addr.lo\t= U64_LO(section);\n\tsp_sb_data.host_sb_addr.hi\t= U64_HI(section);\n\tsp_sb_data.igu_sb_id\t\t= igu_sp_sb_index;\n\tsp_sb_data.igu_seg_id\t\t= igu_seg_id;\n\tsp_sb_data.p_func.pf_id\t\t= func;\n\tsp_sb_data.p_func.vnic_id\t= BP_VN(bp);\n\tsp_sb_data.p_func.vf_id\t\t= 0xff;\n\n\tbnx2x_wr_sp_sb_data(bp, &sp_sb_data);\n\n\tbnx2x_ack_sb(bp, bp->igu_dsb_id, USTORM_ID, 0, IGU_INT_ENABLE, 0);\n}\n\nvoid bnx2x_update_coalesce(struct bnx2x *bp)\n{\n\tint i;\n\n\tfor_each_eth_queue(bp, i)\n\t\tbnx2x_update_coalesce_sb(bp, bp->fp[i].fw_sb_id,\n\t\t\t\t\t bp->tx_ticks, bp->rx_ticks);\n}\n\nstatic void bnx2x_init_sp_ring(struct bnx2x *bp)\n{\n\tspin_lock_init(&bp->spq_lock);\n\tatomic_set(&bp->cq_spq_left, MAX_SPQ_PENDING);\n\n\tbp->spq_prod_idx = 0;\n\tbp->dsb_sp_prod = BNX2X_SP_DSB_INDEX;\n\tbp->spq_prod_bd = bp->spq;\n\tbp->spq_last_bd = bp->spq_prod_bd + MAX_SP_DESC_CNT;\n}\n\nstatic void bnx2x_init_eq_ring(struct bnx2x *bp)\n{\n\tint i;\n\tfor (i = 1; i <= NUM_EQ_PAGES; i++) {\n\t\tunion event_ring_elem *elem =\n\t\t\t&bp->eq_ring[EQ_DESC_CNT_PAGE * i - 1];\n\n\t\telem->next_page.addr.hi =\n\t\t\tcpu_to_le32(U64_HI(bp->eq_mapping +\n\t\t\t\t   BCM_PAGE_SIZE * (i % NUM_EQ_PAGES)));\n\t\telem->next_page.addr.lo =\n\t\t\tcpu_to_le32(U64_LO(bp->eq_mapping +\n\t\t\t\t   BCM_PAGE_SIZE*(i % NUM_EQ_PAGES)));\n\t}\n\tbp->eq_cons = 0;\n\tbp->eq_prod = NUM_EQ_DESC;\n\tbp->eq_cons_sb = BNX2X_EQ_INDEX;\n\t \n\tatomic_set(&bp->eq_spq_left,\n\t\tmin_t(int, MAX_SP_DESC_CNT - MAX_SPQ_PENDING, NUM_EQ_DESC) - 1);\n}\n\n \nstatic int bnx2x_set_q_rx_mode(struct bnx2x *bp, u8 cl_id,\n\t\t\t       unsigned long rx_mode_flags,\n\t\t\t       unsigned long rx_accept_flags,\n\t\t\t       unsigned long tx_accept_flags,\n\t\t\t       unsigned long ramrod_flags)\n{\n\tstruct bnx2x_rx_mode_ramrod_params ramrod_param;\n\tint rc;\n\n\tmemset(&ramrod_param, 0, sizeof(ramrod_param));\n\n\t \n\tramrod_param.cid = 0;\n\tramrod_param.cl_id = cl_id;\n\tramrod_param.rx_mode_obj = &bp->rx_mode_obj;\n\tramrod_param.func_id = BP_FUNC(bp);\n\n\tramrod_param.pstate = &bp->sp_state;\n\tramrod_param.state = BNX2X_FILTER_RX_MODE_PENDING;\n\n\tramrod_param.rdata = bnx2x_sp(bp, rx_mode_rdata);\n\tramrod_param.rdata_mapping = bnx2x_sp_mapping(bp, rx_mode_rdata);\n\n\tset_bit(BNX2X_FILTER_RX_MODE_PENDING, &bp->sp_state);\n\n\tramrod_param.ramrod_flags = ramrod_flags;\n\tramrod_param.rx_mode_flags = rx_mode_flags;\n\n\tramrod_param.rx_accept_flags = rx_accept_flags;\n\tramrod_param.tx_accept_flags = tx_accept_flags;\n\n\trc = bnx2x_config_rx_mode(bp, &ramrod_param);\n\tif (rc < 0) {\n\t\tBNX2X_ERR(\"Set rx_mode %d failed\\n\", bp->rx_mode);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int bnx2x_fill_accept_flags(struct bnx2x *bp, u32 rx_mode,\n\t\t\t\t   unsigned long *rx_accept_flags,\n\t\t\t\t   unsigned long *tx_accept_flags)\n{\n\t \n\t*rx_accept_flags = 0;\n\t*tx_accept_flags = 0;\n\n\tswitch (rx_mode) {\n\tcase BNX2X_RX_MODE_NONE:\n\t\t \n\t\tbreak;\n\tcase BNX2X_RX_MODE_NORMAL:\n\t\t__set_bit(BNX2X_ACCEPT_UNICAST, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_MULTICAST, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_BROADCAST, rx_accept_flags);\n\n\t\t \n\t\t__set_bit(BNX2X_ACCEPT_UNICAST, tx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_MULTICAST, tx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_BROADCAST, tx_accept_flags);\n\n\t\tif (bp->accept_any_vlan) {\n\t\t\t__set_bit(BNX2X_ACCEPT_ANY_VLAN, rx_accept_flags);\n\t\t\t__set_bit(BNX2X_ACCEPT_ANY_VLAN, tx_accept_flags);\n\t\t}\n\n\t\tbreak;\n\tcase BNX2X_RX_MODE_ALLMULTI:\n\t\t__set_bit(BNX2X_ACCEPT_UNICAST, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_ALL_MULTICAST, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_BROADCAST, rx_accept_flags);\n\n\t\t \n\t\t__set_bit(BNX2X_ACCEPT_UNICAST, tx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_ALL_MULTICAST, tx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_BROADCAST, tx_accept_flags);\n\n\t\tif (bp->accept_any_vlan) {\n\t\t\t__set_bit(BNX2X_ACCEPT_ANY_VLAN, rx_accept_flags);\n\t\t\t__set_bit(BNX2X_ACCEPT_ANY_VLAN, tx_accept_flags);\n\t\t}\n\n\t\tbreak;\n\tcase BNX2X_RX_MODE_PROMISC:\n\t\t \n\t\t__set_bit(BNX2X_ACCEPT_UNMATCHED, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_UNICAST, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_ALL_MULTICAST, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_BROADCAST, rx_accept_flags);\n\n\t\t \n\t\t__set_bit(BNX2X_ACCEPT_ALL_MULTICAST, tx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_BROADCAST, tx_accept_flags);\n\n\t\tif (IS_MF_SI(bp))\n\t\t\t__set_bit(BNX2X_ACCEPT_ALL_UNICAST, tx_accept_flags);\n\t\telse\n\t\t\t__set_bit(BNX2X_ACCEPT_UNICAST, tx_accept_flags);\n\n\t\t__set_bit(BNX2X_ACCEPT_ANY_VLAN, rx_accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_ANY_VLAN, tx_accept_flags);\n\n\t\tbreak;\n\tdefault:\n\t\tBNX2X_ERR(\"Unknown rx_mode: %d\\n\", rx_mode);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int bnx2x_set_storm_rx_mode(struct bnx2x *bp)\n{\n\tunsigned long rx_mode_flags = 0, ramrod_flags = 0;\n\tunsigned long rx_accept_flags = 0, tx_accept_flags = 0;\n\tint rc;\n\n\tif (!NO_FCOE(bp))\n\t\t \n\t\t__set_bit(BNX2X_RX_MODE_FCOE_ETH, &rx_mode_flags);\n\n\trc = bnx2x_fill_accept_flags(bp, bp->rx_mode, &rx_accept_flags,\n\t\t\t\t     &tx_accept_flags);\n\tif (rc)\n\t\treturn rc;\n\n\t__set_bit(RAMROD_RX, &ramrod_flags);\n\t__set_bit(RAMROD_TX, &ramrod_flags);\n\n\treturn bnx2x_set_q_rx_mode(bp, bp->fp->cl_id, rx_mode_flags,\n\t\t\t\t   rx_accept_flags, tx_accept_flags,\n\t\t\t\t   ramrod_flags);\n}\n\nstatic void bnx2x_init_internal_common(struct bnx2x *bp)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < (USTORM_AGG_DATA_SIZE >> 2); i++)\n\t\tREG_WR(bp, BAR_USTRORM_INTMEM +\n\t\t       USTORM_AGG_DATA_OFFSET + i * 4, 0);\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tREG_WR8(bp, BAR_CSTRORM_INTMEM + CSTORM_IGU_MODE_OFFSET,\n\t\t\tCHIP_INT_MODE_IS_BC(bp) ?\n\t\t\tHC_IGU_BC_MODE : HC_IGU_NBC_MODE);\n\t}\n}\n\nstatic void bnx2x_init_internal(struct bnx2x *bp, u32 load_code)\n{\n\tswitch (load_code) {\n\tcase FW_MSG_CODE_DRV_LOAD_COMMON:\n\tcase FW_MSG_CODE_DRV_LOAD_COMMON_CHIP:\n\t\tbnx2x_init_internal_common(bp);\n\t\tfallthrough;\n\n\tcase FW_MSG_CODE_DRV_LOAD_PORT:\n\t\t \n\t\tfallthrough;\n\n\tcase FW_MSG_CODE_DRV_LOAD_FUNCTION:\n\t\t \n\t\tbreak;\n\n\tdefault:\n\t\tBNX2X_ERR(\"Unknown load_code (0x%x) from MCP\\n\", load_code);\n\t\tbreak;\n\t}\n}\n\nstatic inline u8 bnx2x_fp_igu_sb_id(struct bnx2x_fastpath *fp)\n{\n\treturn fp->bp->igu_base_sb + fp->index + CNIC_SUPPORT(fp->bp);\n}\n\nstatic inline u8 bnx2x_fp_fw_sb_id(struct bnx2x_fastpath *fp)\n{\n\treturn fp->bp->base_fw_ndsb + fp->index + CNIC_SUPPORT(fp->bp);\n}\n\nstatic u8 bnx2x_fp_cl_id(struct bnx2x_fastpath *fp)\n{\n\tif (CHIP_IS_E1x(fp->bp))\n\t\treturn BP_L_ID(fp->bp) + fp->index;\n\telse\t \n\t\treturn bnx2x_fp_igu_sb_id(fp);\n}\n\nstatic void bnx2x_init_eth_fp(struct bnx2x *bp, int fp_idx)\n{\n\tstruct bnx2x_fastpath *fp = &bp->fp[fp_idx];\n\tu8 cos;\n\tunsigned long q_type = 0;\n\tu32 cids[BNX2X_MULTI_TX_COS] = { 0 };\n\tfp->rx_queue = fp_idx;\n\tfp->cid = fp_idx;\n\tfp->cl_id = bnx2x_fp_cl_id(fp);\n\tfp->fw_sb_id = bnx2x_fp_fw_sb_id(fp);\n\tfp->igu_sb_id = bnx2x_fp_igu_sb_id(fp);\n\t \n\tfp->cl_qzone_id  = bnx2x_fp_qzone_id(fp);\n\n\t \n\tfp->ustorm_rx_prods_offset = bnx2x_rx_ustorm_prods_offset(fp);\n\n\t \n\tfp->rx_cons_sb = BNX2X_RX_SB_INDEX;\n\n\t \n\t__set_bit(BNX2X_Q_TYPE_HAS_RX, &q_type);\n\t__set_bit(BNX2X_Q_TYPE_HAS_TX, &q_type);\n\n\tBUG_ON(fp->max_cos > BNX2X_MULTI_TX_COS);\n\n\t \n\tfor_each_cos_in_tx_queue(fp, cos) {\n\t\tbnx2x_init_txdata(bp, fp->txdata_ptr[cos],\n\t\t\t\t  CID_COS_TO_TX_ONLY_CID(fp->cid, cos, bp),\n\t\t\t\t  FP_COS_TO_TXQ(fp, cos, bp),\n\t\t\t\t  BNX2X_TX_SB_INDEX_BASE + cos, fp);\n\t\tcids[cos] = fp->txdata_ptr[cos]->cid;\n\t}\n\n\t \n\tif (IS_VF(bp))\n\t\treturn;\n\n\tbnx2x_init_sb(bp, fp->status_blk_mapping, BNX2X_VF_ID_INVALID, false,\n\t\t      fp->fw_sb_id, fp->igu_sb_id);\n\tbnx2x_update_fpsb_idx(fp);\n\tbnx2x_init_queue_obj(bp, &bnx2x_sp_obj(bp, fp).q_obj, fp->cl_id, cids,\n\t\t\t     fp->max_cos, BP_FUNC(bp), bnx2x_sp(bp, q_rdata),\n\t\t\t     bnx2x_sp_mapping(bp, q_rdata), q_type);\n\n\t \n\tbnx2x_init_vlan_mac_fp_objs(fp, BNX2X_OBJ_TYPE_RX_TX);\n\n\tDP(NETIF_MSG_IFUP,\n\t   \"queue[%d]:  bnx2x_init_sb(%p,%p)  cl_id %d  fw_sb %d  igu_sb %d\\n\",\n\t   fp_idx, bp, fp->status_blk.e2_sb, fp->cl_id, fp->fw_sb_id,\n\t   fp->igu_sb_id);\n}\n\nstatic void bnx2x_init_tx_ring_one(struct bnx2x_fp_txdata *txdata)\n{\n\tint i;\n\n\tfor (i = 1; i <= NUM_TX_RINGS; i++) {\n\t\tstruct eth_tx_next_bd *tx_next_bd =\n\t\t\t&txdata->tx_desc_ring[TX_DESC_CNT * i - 1].next_bd;\n\n\t\ttx_next_bd->addr_hi =\n\t\t\tcpu_to_le32(U64_HI(txdata->tx_desc_mapping +\n\t\t\t\t    BCM_PAGE_SIZE*(i % NUM_TX_RINGS)));\n\t\ttx_next_bd->addr_lo =\n\t\t\tcpu_to_le32(U64_LO(txdata->tx_desc_mapping +\n\t\t\t\t    BCM_PAGE_SIZE*(i % NUM_TX_RINGS)));\n\t}\n\n\t*txdata->tx_cons_sb = cpu_to_le16(0);\n\n\tSET_FLAG(txdata->tx_db.data.header.header, DOORBELL_HDR_DB_TYPE, 1);\n\ttxdata->tx_db.data.zero_fill1 = 0;\n\ttxdata->tx_db.data.prod = 0;\n\n\ttxdata->tx_pkt_prod = 0;\n\ttxdata->tx_pkt_cons = 0;\n\ttxdata->tx_bd_prod = 0;\n\ttxdata->tx_bd_cons = 0;\n\ttxdata->tx_pkt = 0;\n}\n\nstatic void bnx2x_init_tx_rings_cnic(struct bnx2x *bp)\n{\n\tint i;\n\n\tfor_each_tx_queue_cnic(bp, i)\n\t\tbnx2x_init_tx_ring_one(bp->fp[i].txdata_ptr[0]);\n}\n\nstatic void bnx2x_init_tx_rings(struct bnx2x *bp)\n{\n\tint i;\n\tu8 cos;\n\n\tfor_each_eth_queue(bp, i)\n\t\tfor_each_cos_in_tx_queue(&bp->fp[i], cos)\n\t\t\tbnx2x_init_tx_ring_one(bp->fp[i].txdata_ptr[cos]);\n}\n\nstatic void bnx2x_init_fcoe_fp(struct bnx2x *bp)\n{\n\tstruct bnx2x_fastpath *fp = bnx2x_fcoe_fp(bp);\n\tunsigned long q_type = 0;\n\n\tbnx2x_fcoe(bp, rx_queue) = BNX2X_NUM_ETH_QUEUES(bp);\n\tbnx2x_fcoe(bp, cl_id) = bnx2x_cnic_eth_cl_id(bp,\n\t\t\t\t\t\t     BNX2X_FCOE_ETH_CL_ID_IDX);\n\tbnx2x_fcoe(bp, cid) = BNX2X_FCOE_ETH_CID(bp);\n\tbnx2x_fcoe(bp, fw_sb_id) = DEF_SB_ID;\n\tbnx2x_fcoe(bp, igu_sb_id) = bp->igu_dsb_id;\n\tbnx2x_fcoe(bp, rx_cons_sb) = BNX2X_FCOE_L2_RX_INDEX;\n\tbnx2x_init_txdata(bp, bnx2x_fcoe(bp, txdata_ptr[0]),\n\t\t\t  fp->cid, FCOE_TXQ_IDX(bp), BNX2X_FCOE_L2_TX_INDEX,\n\t\t\t  fp);\n\n\tDP(NETIF_MSG_IFUP, \"created fcoe tx data (fp index %d)\\n\", fp->index);\n\n\t \n\tbnx2x_fcoe(bp, cl_qzone_id) = bnx2x_fp_qzone_id(fp);\n\t \n\tbnx2x_fcoe(bp, ustorm_rx_prods_offset) =\n\t\tbnx2x_rx_ustorm_prods_offset(fp);\n\n\t \n\t__set_bit(BNX2X_Q_TYPE_HAS_RX, &q_type);\n\t__set_bit(BNX2X_Q_TYPE_HAS_TX, &q_type);\n\n\t \n\tBUG_ON(fp->max_cos != 1);\n\n\tbnx2x_init_queue_obj(bp, &bnx2x_sp_obj(bp, fp).q_obj, fp->cl_id,\n\t\t\t     &fp->cid, 1, BP_FUNC(bp), bnx2x_sp(bp, q_rdata),\n\t\t\t     bnx2x_sp_mapping(bp, q_rdata), q_type);\n\n\tDP(NETIF_MSG_IFUP,\n\t   \"queue[%d]: bnx2x_init_sb(%p,%p) cl_id %d fw_sb %d igu_sb %d\\n\",\n\t   fp->index, bp, fp->status_blk.e2_sb, fp->cl_id, fp->fw_sb_id,\n\t   fp->igu_sb_id);\n}\n\nvoid bnx2x_nic_init_cnic(struct bnx2x *bp)\n{\n\tif (!NO_FCOE(bp))\n\t\tbnx2x_init_fcoe_fp(bp);\n\n\tbnx2x_init_sb(bp, bp->cnic_sb_mapping,\n\t\t      BNX2X_VF_ID_INVALID, false,\n\t\t      bnx2x_cnic_fw_sb_id(bp), bnx2x_cnic_igu_sb_id(bp));\n\n\t \n\trmb();\n\tbnx2x_init_rx_rings_cnic(bp);\n\tbnx2x_init_tx_rings_cnic(bp);\n\n\t \n\tmb();\n}\n\nvoid bnx2x_pre_irq_nic_init(struct bnx2x *bp)\n{\n\tint i;\n\n\t \n\tfor_each_eth_queue(bp, i)\n\t\tbnx2x_init_eth_fp(bp, i);\n\n\t \n\trmb();\n\tbnx2x_init_rx_rings(bp);\n\tbnx2x_init_tx_rings(bp);\n\n\tif (IS_PF(bp)) {\n\t\t \n\t\tbnx2x_init_mod_abs_int(bp, &bp->link_vars, bp->common.chip_id,\n\t\t\t\t       bp->common.shmem_base,\n\t\t\t\t       bp->common.shmem2_base, BP_PORT(bp));\n\n\t\t \n\t\tbnx2x_init_def_sb(bp);\n\t\tbnx2x_update_dsb_idx(bp);\n\t\tbnx2x_init_sp_ring(bp);\n\t} else {\n\t\tbnx2x_memset_stats(bp);\n\t}\n}\n\nvoid bnx2x_post_irq_nic_init(struct bnx2x *bp, u32 load_code)\n{\n\tbnx2x_init_eq_ring(bp);\n\tbnx2x_init_internal(bp, load_code);\n\tbnx2x_pf_init(bp);\n\tbnx2x_stats_init(bp);\n\n\t \n\tmb();\n\n\tbnx2x_int_enable(bp);\n\n\t \n\tbnx2x_attn_int_deasserted0(bp,\n\t\tREG_RD(bp, MISC_REG_AEU_AFTER_INVERT_1_FUNC_0 + BP_PORT(bp)*4) &\n\t\t\t\t   AEU_INPUTS_ATTN_BITS_SPIO5);\n}\n\n \nstatic int bnx2x_gunzip_init(struct bnx2x *bp)\n{\n\tbp->gunzip_buf = dma_alloc_coherent(&bp->pdev->dev, FW_BUF_SIZE,\n\t\t\t\t\t    &bp->gunzip_mapping, GFP_KERNEL);\n\tif (bp->gunzip_buf  == NULL)\n\t\tgoto gunzip_nomem1;\n\n\tbp->strm = kmalloc(sizeof(*bp->strm), GFP_KERNEL);\n\tif (bp->strm  == NULL)\n\t\tgoto gunzip_nomem2;\n\n\tbp->strm->workspace = vmalloc(zlib_inflate_workspacesize());\n\tif (bp->strm->workspace == NULL)\n\t\tgoto gunzip_nomem3;\n\n\treturn 0;\n\ngunzip_nomem3:\n\tkfree(bp->strm);\n\tbp->strm = NULL;\n\ngunzip_nomem2:\n\tdma_free_coherent(&bp->pdev->dev, FW_BUF_SIZE, bp->gunzip_buf,\n\t\t\t  bp->gunzip_mapping);\n\tbp->gunzip_buf = NULL;\n\ngunzip_nomem1:\n\tBNX2X_ERR(\"Cannot allocate firmware buffer for un-compression\\n\");\n\treturn -ENOMEM;\n}\n\nstatic void bnx2x_gunzip_end(struct bnx2x *bp)\n{\n\tif (bp->strm) {\n\t\tvfree(bp->strm->workspace);\n\t\tkfree(bp->strm);\n\t\tbp->strm = NULL;\n\t}\n\n\tif (bp->gunzip_buf) {\n\t\tdma_free_coherent(&bp->pdev->dev, FW_BUF_SIZE, bp->gunzip_buf,\n\t\t\t\t  bp->gunzip_mapping);\n\t\tbp->gunzip_buf = NULL;\n\t}\n}\n\nstatic int bnx2x_gunzip(struct bnx2x *bp, const u8 *zbuf, int len)\n{\n\tint n, rc;\n\n\t \n\tif ((zbuf[0] != 0x1f) || (zbuf[1] != 0x8b) || (zbuf[2] != Z_DEFLATED)) {\n\t\tBNX2X_ERR(\"Bad gzip header\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tn = 10;\n\n#define FNAME\t\t\t\t0x8\n\n\tif (zbuf[3] & FNAME)\n\t\twhile ((zbuf[n++] != 0) && (n < len));\n\n\tbp->strm->next_in = (typeof(bp->strm->next_in))zbuf + n;\n\tbp->strm->avail_in = len - n;\n\tbp->strm->next_out = bp->gunzip_buf;\n\tbp->strm->avail_out = FW_BUF_SIZE;\n\n\trc = zlib_inflateInit2(bp->strm, -MAX_WBITS);\n\tif (rc != Z_OK)\n\t\treturn rc;\n\n\trc = zlib_inflate(bp->strm, Z_FINISH);\n\tif ((rc != Z_OK) && (rc != Z_STREAM_END))\n\t\tnetdev_err(bp->dev, \"Firmware decompression error: %s\\n\",\n\t\t\t   bp->strm->msg);\n\n\tbp->gunzip_outlen = (FW_BUF_SIZE - bp->strm->avail_out);\n\tif (bp->gunzip_outlen & 0x3)\n\t\tnetdev_err(bp->dev,\n\t\t\t   \"Firmware decompression error: gunzip_outlen (%d) not aligned\\n\",\n\t\t\t\tbp->gunzip_outlen);\n\tbp->gunzip_outlen >>= 2;\n\n\tzlib_inflateEnd(bp->strm);\n\n\tif (rc == Z_STREAM_END)\n\t\treturn 0;\n\n\treturn rc;\n}\n\n \n\n \n\n \nstatic void bnx2x_lb_pckt(struct bnx2x *bp)\n{\n\tu32 wb_write[3];\n\n\t \n\twb_write[0] = 0x55555555;\n\twb_write[1] = 0x55555555;\n\twb_write[2] = 0x20;\t\t \n\tREG_WR_DMAE(bp, NIG_REG_DEBUG_PACKET_LB, wb_write, 3);\n\n\t \n\twb_write[0] = 0x09000000;\n\twb_write[1] = 0x55555555;\n\twb_write[2] = 0x10;\t\t \n\tREG_WR_DMAE(bp, NIG_REG_DEBUG_PACKET_LB, wb_write, 3);\n}\n\n \nstatic int bnx2x_int_mem_test(struct bnx2x *bp)\n{\n\tint factor;\n\tint count, i;\n\tu32 val = 0;\n\n\tif (CHIP_REV_IS_FPGA(bp))\n\t\tfactor = 120;\n\telse if (CHIP_REV_IS_EMUL(bp))\n\t\tfactor = 200;\n\telse\n\t\tfactor = 1;\n\n\t \n\tREG_WR(bp, TSDM_REG_ENABLE_IN1, 0x0);\n\tREG_WR(bp, TCM_REG_PRS_IFEN, 0x0);\n\tREG_WR(bp, CFC_REG_DEBUG0, 0x1);\n\tREG_WR(bp, NIG_REG_PRS_REQ_IN_EN, 0x0);\n\n\t \n\tREG_WR(bp, PRS_REG_CFC_SEARCH_INITIAL_CREDIT, 0x0);\n\n\t \n\tbnx2x_lb_pckt(bp);\n\n\t \n\t \n\tcount = 1000 * factor;\n\twhile (count) {\n\n\t\tbnx2x_read_dmae(bp, NIG_REG_STAT2_BRB_OCTET, 2);\n\t\tval = *bnx2x_sp(bp, wb_data[0]);\n\t\tif (val == 0x10)\n\t\t\tbreak;\n\n\t\tusleep_range(10000, 20000);\n\t\tcount--;\n\t}\n\tif (val != 0x10) {\n\t\tBNX2X_ERR(\"NIG timeout  val = 0x%x\\n\", val);\n\t\treturn -1;\n\t}\n\n\t \n\tcount = 1000 * factor;\n\twhile (count) {\n\t\tval = REG_RD(bp, PRS_REG_NUM_OF_PACKETS);\n\t\tif (val == 1)\n\t\t\tbreak;\n\n\t\tusleep_range(10000, 20000);\n\t\tcount--;\n\t}\n\tif (val != 0x1) {\n\t\tBNX2X_ERR(\"PRS timeout val = 0x%x\\n\", val);\n\t\treturn -2;\n\t}\n\n\t \n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_CLEAR, 0x03);\n\tmsleep(50);\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_SET, 0x03);\n\tmsleep(50);\n\tbnx2x_init_block(bp, BLOCK_BRB1, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_PRS, PHASE_COMMON);\n\n\tDP(NETIF_MSG_HW, \"part2\\n\");\n\n\t \n\tREG_WR(bp, TSDM_REG_ENABLE_IN1, 0x0);\n\tREG_WR(bp, TCM_REG_PRS_IFEN, 0x0);\n\tREG_WR(bp, CFC_REG_DEBUG0, 0x1);\n\tREG_WR(bp, NIG_REG_PRS_REQ_IN_EN, 0x0);\n\n\t \n\tREG_WR(bp, PRS_REG_CFC_SEARCH_INITIAL_CREDIT, 0x0);\n\n\t \n\tfor (i = 0; i < 10; i++)\n\t\tbnx2x_lb_pckt(bp);\n\n\t \n\tcount = 1000 * factor;\n\twhile (count) {\n\n\t\tbnx2x_read_dmae(bp, NIG_REG_STAT2_BRB_OCTET, 2);\n\t\tval = *bnx2x_sp(bp, wb_data[0]);\n\t\tif (val == 0xb0)\n\t\t\tbreak;\n\n\t\tusleep_range(10000, 20000);\n\t\tcount--;\n\t}\n\tif (val != 0xb0) {\n\t\tBNX2X_ERR(\"NIG timeout  val = 0x%x\\n\", val);\n\t\treturn -3;\n\t}\n\n\t \n\tval = REG_RD(bp, PRS_REG_NUM_OF_PACKETS);\n\tif (val != 2)\n\t\tBNX2X_ERR(\"PRS timeout  val = 0x%x\\n\", val);\n\n\t \n\tREG_WR(bp, PRS_REG_CFC_SEARCH_INITIAL_CREDIT, 0x1);\n\n\t \n\tmsleep(10 * factor);\n\t \n\tval = REG_RD(bp, PRS_REG_NUM_OF_PACKETS);\n\tif (val != 3)\n\t\tBNX2X_ERR(\"PRS timeout  val = 0x%x\\n\", val);\n\n\t \n\tfor (i = 0; i < 11; i++)\n\t\tREG_RD(bp, NIG_REG_INGRESS_EOP_LB_FIFO);\n\tval = REG_RD(bp, NIG_REG_INGRESS_EOP_LB_EMPTY);\n\tif (val != 1) {\n\t\tBNX2X_ERR(\"clear of NIG failed\\n\");\n\t\treturn -4;\n\t}\n\n\t \n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_CLEAR, 0x03);\n\tmsleep(50);\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_SET, 0x03);\n\tmsleep(50);\n\tbnx2x_init_block(bp, BLOCK_BRB1, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_PRS, PHASE_COMMON);\n\tif (!CNIC_SUPPORT(bp))\n\t\t \n\t\tREG_WR(bp, PRS_REG_NIC_MODE, 1);\n\n\t \n\tREG_WR(bp, TSDM_REG_ENABLE_IN1, 0x7fffffff);\n\tREG_WR(bp, TCM_REG_PRS_IFEN, 0x1);\n\tREG_WR(bp, CFC_REG_DEBUG0, 0x0);\n\tREG_WR(bp, NIG_REG_PRS_REQ_IN_EN, 0x1);\n\n\tDP(NETIF_MSG_HW, \"done\\n\");\n\n\treturn 0;  \n}\n\nstatic void bnx2x_enable_blocks_attention(struct bnx2x *bp)\n{\n\tu32 val;\n\n\tREG_WR(bp, PXP_REG_PXP_INT_MASK_0, 0);\n\tif (!CHIP_IS_E1x(bp))\n\t\tREG_WR(bp, PXP_REG_PXP_INT_MASK_1, 0x40);\n\telse\n\t\tREG_WR(bp, PXP_REG_PXP_INT_MASK_1, 0);\n\tREG_WR(bp, DORQ_REG_DORQ_INT_MASK, 0);\n\tREG_WR(bp, CFC_REG_CFC_INT_MASK, 0);\n\t \n\tREG_WR(bp, BRB1_REG_BRB1_INT_MASK, 0xFC00);\n\tREG_WR(bp, QM_REG_QM_INT_MASK, 0);\n\tREG_WR(bp, TM_REG_TM_INT_MASK, 0);\n\tREG_WR(bp, XSDM_REG_XSDM_INT_MASK_0, 0);\n\tREG_WR(bp, XSDM_REG_XSDM_INT_MASK_1, 0);\n\tREG_WR(bp, XCM_REG_XCM_INT_MASK, 0);\n \n \n\tREG_WR(bp, USDM_REG_USDM_INT_MASK_0, 0);\n\tREG_WR(bp, USDM_REG_USDM_INT_MASK_1, 0);\n\tREG_WR(bp, UCM_REG_UCM_INT_MASK, 0);\n \n \n\tREG_WR(bp, GRCBASE_UPB + PB_REG_PB_INT_MASK, 0);\n\tREG_WR(bp, CSDM_REG_CSDM_INT_MASK_0, 0);\n\tREG_WR(bp, CSDM_REG_CSDM_INT_MASK_1, 0);\n\tREG_WR(bp, CCM_REG_CCM_INT_MASK, 0);\n \n \n\n\tval = PXP2_PXP2_INT_MASK_0_REG_PGL_CPL_AFT  |\n\t\tPXP2_PXP2_INT_MASK_0_REG_PGL_CPL_OF |\n\t\tPXP2_PXP2_INT_MASK_0_REG_PGL_PCIE_ATTN;\n\tif (!CHIP_IS_E1x(bp))\n\t\tval |= PXP2_PXP2_INT_MASK_0_REG_PGL_READ_BLOCKED |\n\t\t\tPXP2_PXP2_INT_MASK_0_REG_PGL_WRITE_BLOCKED;\n\tREG_WR(bp, PXP2_REG_PXP2_INT_MASK_0, val);\n\n\tREG_WR(bp, TSDM_REG_TSDM_INT_MASK_0, 0);\n\tREG_WR(bp, TSDM_REG_TSDM_INT_MASK_1, 0);\n\tREG_WR(bp, TCM_REG_TCM_INT_MASK, 0);\n \n\n\tif (!CHIP_IS_E1x(bp))\n\t\t \n\t\tREG_WR(bp, TSEM_REG_TSEM_INT_MASK_1, 0x07ff);\n\n\tREG_WR(bp, CDU_REG_CDU_INT_MASK, 0);\n\tREG_WR(bp, DMAE_REG_DMAE_INT_MASK, 0);\n \n\tREG_WR(bp, PBF_REG_PBF_INT_MASK, 0x18);\t\t \n}\n\nstatic void bnx2x_reset_common(struct bnx2x *bp)\n{\n\tu32 val = 0x1400;\n\n\t \n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_CLEAR,\n\t       0xd3ffff7f);\n\n\tif (CHIP_IS_E3(bp)) {\n\t\tval |= MISC_REGISTERS_RESET_REG_2_MSTAT0;\n\t\tval |= MISC_REGISTERS_RESET_REG_2_MSTAT1;\n\t}\n\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_2_CLEAR, val);\n}\n\nstatic void bnx2x_setup_dmae(struct bnx2x *bp)\n{\n\tbp->dmae_ready = 0;\n\tspin_lock_init(&bp->dmae_lock);\n}\n\nstatic void bnx2x_init_pxp(struct bnx2x *bp)\n{\n\tu16 devctl;\n\tint r_order, w_order;\n\n\tpcie_capability_read_word(bp->pdev, PCI_EXP_DEVCTL, &devctl);\n\tDP(NETIF_MSG_HW, \"read 0x%x from devctl\\n\", devctl);\n\tw_order = ((devctl & PCI_EXP_DEVCTL_PAYLOAD) >> 5);\n\tif (bp->mrrs == -1)\n\t\tr_order = ((devctl & PCI_EXP_DEVCTL_READRQ) >> 12);\n\telse {\n\t\tDP(NETIF_MSG_HW, \"force read order to %d\\n\", bp->mrrs);\n\t\tr_order = bp->mrrs;\n\t}\n\n\tbnx2x_init_pxp_arb(bp, r_order, w_order);\n}\n\nstatic void bnx2x_setup_fan_failure_detection(struct bnx2x *bp)\n{\n\tint is_required;\n\tu32 val;\n\tint port;\n\n\tif (BP_NOMCP(bp))\n\t\treturn;\n\n\tis_required = 0;\n\tval = SHMEM_RD(bp, dev_info.shared_hw_config.config2) &\n\t      SHARED_HW_CFG_FAN_FAILURE_MASK;\n\n\tif (val == SHARED_HW_CFG_FAN_FAILURE_ENABLED)\n\t\tis_required = 1;\n\n\t \n\telse if (val == SHARED_HW_CFG_FAN_FAILURE_PHY_TYPE)\n\t\tfor (port = PORT_0; port < PORT_MAX; port++) {\n\t\t\tis_required |=\n\t\t\t\tbnx2x_fan_failure_det_req(\n\t\t\t\t\tbp,\n\t\t\t\t\tbp->common.shmem_base,\n\t\t\t\t\tbp->common.shmem2_base,\n\t\t\t\t\tport);\n\t\t}\n\n\tDP(NETIF_MSG_HW, \"fan detection setting: %d\\n\", is_required);\n\n\tif (is_required == 0)\n\t\treturn;\n\n\t \n\tbnx2x_set_spio(bp, MISC_SPIO_SPIO5, MISC_SPIO_INPUT_HI_Z);\n\n\t \n\tval = REG_RD(bp, MISC_REG_SPIO_INT);\n\tval |= (MISC_SPIO_SPIO5 << MISC_SPIO_INT_OLD_SET_POS);\n\tREG_WR(bp, MISC_REG_SPIO_INT, val);\n\n\t \n\tval = REG_RD(bp, MISC_REG_SPIO_EVENT_EN);\n\tval |= MISC_SPIO_SPIO5;\n\tREG_WR(bp, MISC_REG_SPIO_EVENT_EN, val);\n}\n\nvoid bnx2x_pf_disable(struct bnx2x *bp)\n{\n\tu32 val = REG_RD(bp, IGU_REG_PF_CONFIGURATION);\n\tval &= ~IGU_PF_CONF_FUNC_EN;\n\n\tREG_WR(bp, IGU_REG_PF_CONFIGURATION, val);\n\tREG_WR(bp, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, 0);\n\tREG_WR(bp, CFC_REG_WEAK_ENABLE_PF, 0);\n}\n\nstatic void bnx2x__common_init_phy(struct bnx2x *bp)\n{\n\tu32 shmem_base[2], shmem2_base[2];\n\t \n\tif (SHMEM2_RD(bp, size) >\n\t    (u32)offsetof(struct shmem2_region, lfa_host_addr[BP_PORT(bp)]))\n\t\treturn;\n\tshmem_base[0] =  bp->common.shmem_base;\n\tshmem2_base[0] = bp->common.shmem2_base;\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tshmem_base[1] =\n\t\t\tSHMEM2_RD(bp, other_shmem_base_addr);\n\t\tshmem2_base[1] =\n\t\t\tSHMEM2_RD(bp, other_shmem2_base_addr);\n\t}\n\tbnx2x_acquire_phy_lock(bp);\n\tbnx2x_common_init_phy(bp, shmem_base, shmem2_base,\n\t\t\t      bp->common.chip_id);\n\tbnx2x_release_phy_lock(bp);\n}\n\nstatic void bnx2x_config_endianity(struct bnx2x *bp, u32 val)\n{\n\tREG_WR(bp, PXP2_REG_RQ_QM_ENDIAN_M, val);\n\tREG_WR(bp, PXP2_REG_RQ_TM_ENDIAN_M, val);\n\tREG_WR(bp, PXP2_REG_RQ_SRC_ENDIAN_M, val);\n\tREG_WR(bp, PXP2_REG_RQ_CDU_ENDIAN_M, val);\n\tREG_WR(bp, PXP2_REG_RQ_DBG_ENDIAN_M, val);\n\n\t \n\tREG_WR(bp, PXP2_REG_RQ_HC_ENDIAN_M, 0);\n\n\tREG_WR(bp, PXP2_REG_RD_QM_SWAP_MODE, val);\n\tREG_WR(bp, PXP2_REG_RD_TM_SWAP_MODE, val);\n\tREG_WR(bp, PXP2_REG_RD_SRC_SWAP_MODE, val);\n\tREG_WR(bp, PXP2_REG_RD_CDURD_SWAP_MODE, val);\n}\n\nstatic void bnx2x_set_endianity(struct bnx2x *bp)\n{\n#ifdef __BIG_ENDIAN\n\tbnx2x_config_endianity(bp, 1);\n#else\n\tbnx2x_config_endianity(bp, 0);\n#endif\n}\n\nstatic void bnx2x_reset_endianity(struct bnx2x *bp)\n{\n\tbnx2x_config_endianity(bp, 0);\n}\n\n \nstatic int bnx2x_init_hw_common(struct bnx2x *bp)\n{\n\tu32 val;\n\n\tDP(NETIF_MSG_HW, \"starting common init  func %d\\n\", BP_ABS_FUNC(bp));\n\n\t \n\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RESET);\n\n\tbnx2x_reset_common(bp);\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_SET, 0xffffffff);\n\n\tval = 0xfffc;\n\tif (CHIP_IS_E3(bp)) {\n\t\tval |= MISC_REGISTERS_RESET_REG_2_MSTAT0;\n\t\tval |= MISC_REGISTERS_RESET_REG_2_MSTAT1;\n\t}\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_2_SET, val);\n\n\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RESET);\n\n\tbnx2x_init_block(bp, BLOCK_MISC, PHASE_COMMON);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tu8 abs_func_id;\n\n\t\t \n\t\tfor (abs_func_id = BP_PATH(bp);\n\t\t     abs_func_id < E2_FUNC_MAX*2; abs_func_id += 2) {\n\t\t\tif (abs_func_id == BP_ABS_FUNC(bp)) {\n\t\t\t\tREG_WR(bp,\n\t\t\t\t    PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER,\n\t\t\t\t    1);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tbnx2x_pretend_func(bp, abs_func_id);\n\t\t\t \n\t\t\tbnx2x_pf_disable(bp);\n\t\t\tbnx2x_pretend_func(bp, BP_ABS_FUNC(bp));\n\t\t}\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_PXP, PHASE_COMMON);\n\tif (CHIP_IS_E1(bp)) {\n\t\t \n\t\tREG_WR(bp, PXP_REG_PXP_INT_MASK_0, 0);\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_PXP2, PHASE_COMMON);\n\tbnx2x_init_pxp(bp);\n\tbnx2x_set_endianity(bp);\n\tbnx2x_ilt_init_page_size(bp, INITOP_SET);\n\n\tif (CHIP_REV_IS_FPGA(bp) && CHIP_IS_E1H(bp))\n\t\tREG_WR(bp, PXP2_REG_PGL_TAGS_LIMIT, 0x1);\n\n\t \n\tmsleep(100);\n\t \n\tval = REG_RD(bp, PXP2_REG_RQ_CFG_DONE);\n\tif (val != 1) {\n\t\tBNX2X_ERR(\"PXP2 CFG failed\\n\");\n\t\treturn -EBUSY;\n\t}\n\tval = REG_RD(bp, PXP2_REG_RD_INIT_DONE);\n\tif (val != 1) {\n\t\tBNX2X_ERR(\"PXP2 RD_INIT failed\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tif (!CHIP_IS_E1x(bp)) {\n \n\t\tstruct ilt_client_info ilt_cli;\n\t\tstruct bnx2x_ilt ilt;\n\t\tmemset(&ilt_cli, 0, sizeof(struct ilt_client_info));\n\t\tmemset(&ilt, 0, sizeof(struct bnx2x_ilt));\n\n\t\t \n\t\tilt_cli.start = 0;\n\t\tilt_cli.end = ILT_NUM_PAGE_ENTRIES - 1;\n\t\tilt_cli.client_num = ILT_CLIENT_TM;\n\n\t\t \n\t\tbnx2x_pretend_func(bp, (BP_PATH(bp) + 6));\n\t\tbnx2x_ilt_client_init_op_ilt(bp, &ilt, &ilt_cli, INITOP_CLEAR);\n\t\tbnx2x_pretend_func(bp, BP_ABS_FUNC(bp));\n\n\t\tREG_WR(bp, PXP2_REG_RQ_DRAM_ALIGN, BNX2X_PXP_DRAM_ALIGN);\n\t\tREG_WR(bp, PXP2_REG_RQ_DRAM_ALIGN_RD, BNX2X_PXP_DRAM_ALIGN);\n\t\tREG_WR(bp, PXP2_REG_RQ_DRAM_ALIGN_SEL, 1);\n\t}\n\n\tREG_WR(bp, PXP2_REG_RQ_DISABLE_INPUTS, 0);\n\tREG_WR(bp, PXP2_REG_RD_DISABLE_INPUTS, 0);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tint factor = CHIP_REV_IS_EMUL(bp) ? 1000 :\n\t\t\t\t(CHIP_REV_IS_FPGA(bp) ? 400 : 0);\n\t\tbnx2x_init_block(bp, BLOCK_PGLUE_B, PHASE_COMMON);\n\n\t\tbnx2x_init_block(bp, BLOCK_ATC, PHASE_COMMON);\n\n\t\t \n\t\tdo {\n\t\t\tmsleep(200);\n\t\t\tval = REG_RD(bp, ATC_REG_ATC_INIT_DONE);\n\t\t} while (factor-- && (val != 1));\n\n\t\tif (val != 1) {\n\t\t\tBNX2X_ERR(\"ATC_INIT failed\\n\");\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_DMAE, PHASE_COMMON);\n\n\tbnx2x_iov_init_dmae(bp);\n\n\t \n\tbp->dmae_ready = 1;\n\tbnx2x_init_fill(bp, TSEM_REG_PRAM, 0, 8, 1);\n\n\tbnx2x_init_block(bp, BLOCK_TCM, PHASE_COMMON);\n\n\tbnx2x_init_block(bp, BLOCK_UCM, PHASE_COMMON);\n\n\tbnx2x_init_block(bp, BLOCK_CCM, PHASE_COMMON);\n\n\tbnx2x_init_block(bp, BLOCK_XCM, PHASE_COMMON);\n\n\tbnx2x_read_dmae(bp, XSEM_REG_PASSIVE_BUFFER, 3);\n\tbnx2x_read_dmae(bp, CSEM_REG_PASSIVE_BUFFER, 3);\n\tbnx2x_read_dmae(bp, TSEM_REG_PASSIVE_BUFFER, 3);\n\tbnx2x_read_dmae(bp, USEM_REG_PASSIVE_BUFFER, 3);\n\n\tbnx2x_init_block(bp, BLOCK_QM, PHASE_COMMON);\n\n\t \n\tbnx2x_qm_init_ptr_table(bp, bp->qm_cid_count, INITOP_SET);\n\n\t \n\tREG_WR(bp, QM_REG_SOFT_RESET, 1);\n\tREG_WR(bp, QM_REG_SOFT_RESET, 0);\n\n\tif (CNIC_SUPPORT(bp))\n\t\tbnx2x_init_block(bp, BLOCK_TM, PHASE_COMMON);\n\n\tbnx2x_init_block(bp, BLOCK_DORQ, PHASE_COMMON);\n\n\tif (!CHIP_REV_IS_SLOW(bp))\n\t\t \n\t\tREG_WR(bp, DORQ_REG_DORQ_INT_MASK, 0);\n\n\tbnx2x_init_block(bp, BLOCK_BRB1, PHASE_COMMON);\n\n\tbnx2x_init_block(bp, BLOCK_PRS, PHASE_COMMON);\n\tREG_WR(bp, PRS_REG_A_PRSU_20, 0xf);\n\n\tif (!CHIP_IS_E1(bp))\n\t\tREG_WR(bp, PRS_REG_E1HOV_MODE, bp->path_has_ovlan);\n\n\tif (!CHIP_IS_E1x(bp) && !CHIP_IS_E3B0(bp)) {\n\t\tif (IS_MF_AFEX(bp)) {\n\t\t\t \n\t\t\tREG_WR(bp, PRS_REG_HDRS_AFTER_BASIC, 0xE);\n\t\t\tREG_WR(bp, PRS_REG_MUST_HAVE_HDRS, 0xA);\n\t\t\tREG_WR(bp, PRS_REG_HDRS_AFTER_TAG_0, 0x6);\n\t\t\tREG_WR(bp, PRS_REG_TAG_ETHERTYPE_0, 0x8926);\n\t\t\tREG_WR(bp, PRS_REG_TAG_LEN_0, 0x4);\n\t\t} else {\n\t\t\t \n\t\t\tREG_WR(bp, PRS_REG_HDRS_AFTER_BASIC,\n\t\t\t       bp->path_has_ovlan ? 7 : 6);\n\t\t}\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_TSDM, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_CSDM, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_USDM, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_XSDM, PHASE_COMMON);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\t \n\t\tREG_WR(bp, TSEM_REG_FAST_MEMORY + VFC_REG_MEMORIES_RST,\n\t\t\t   VFC_MEMORIES_RST_REG_CAM_RST |\n\t\t\t   VFC_MEMORIES_RST_REG_RAM_RST);\n\t\tREG_WR(bp, XSEM_REG_FAST_MEMORY + VFC_REG_MEMORIES_RST,\n\t\t\t   VFC_MEMORIES_RST_REG_CAM_RST |\n\t\t\t   VFC_MEMORIES_RST_REG_RAM_RST);\n\n\t\tmsleep(20);\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_TSEM, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_USEM, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_CSEM, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_XSEM, PHASE_COMMON);\n\n\t \n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_CLEAR,\n\t       0x80000000);\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_SET,\n\t       0x80000000);\n\n\tbnx2x_init_block(bp, BLOCK_UPB, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_XPB, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_PBF, PHASE_COMMON);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tif (IS_MF_AFEX(bp)) {\n\t\t\t \n\t\t\tREG_WR(bp, PBF_REG_HDRS_AFTER_BASIC, 0xE);\n\t\t\tREG_WR(bp, PBF_REG_MUST_HAVE_HDRS, 0xA);\n\t\t\tREG_WR(bp, PBF_REG_HDRS_AFTER_TAG_0, 0x6);\n\t\t\tREG_WR(bp, PBF_REG_TAG_ETHERTYPE_0, 0x8926);\n\t\t\tREG_WR(bp, PBF_REG_TAG_LEN_0, 0x4);\n\t\t} else {\n\t\t\tREG_WR(bp, PBF_REG_HDRS_AFTER_BASIC,\n\t\t\t       bp->path_has_ovlan ? 7 : 6);\n\t\t}\n\t}\n\n\tREG_WR(bp, SRC_REG_SOFT_RST, 1);\n\n\tbnx2x_init_block(bp, BLOCK_SRC, PHASE_COMMON);\n\n\tif (CNIC_SUPPORT(bp)) {\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_0, 0x63285672);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_1, 0x24b8f2cc);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_2, 0x223aef9b);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_3, 0x26001e3a);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_4, 0x7ae91116);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_5, 0x5ce5230b);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_6, 0x298d8adf);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_7, 0x6eb0ff09);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_8, 0x1830f82f);\n\t\tREG_WR(bp, SRC_REG_KEYSEARCH_9, 0x01e46be7);\n\t}\n\tREG_WR(bp, SRC_REG_SOFT_RST, 0);\n\n\tif (sizeof(union cdu_context) != 1024)\n\t\t \n\t\tdev_alert(&bp->pdev->dev,\n\t\t\t  \"please adjust the size of cdu_context(%ld)\\n\",\n\t\t\t  (long)sizeof(union cdu_context));\n\n\tbnx2x_init_block(bp, BLOCK_CDU, PHASE_COMMON);\n\tval = (4 << 24) + (0 << 12) + 1024;\n\tREG_WR(bp, CDU_REG_CDU_GLOBAL_PARAMS, val);\n\n\tbnx2x_init_block(bp, BLOCK_CFC, PHASE_COMMON);\n\tREG_WR(bp, CFC_REG_INIT_REG, 0x7FF);\n\t \n\tREG_WR(bp, CFC_REG_CFC_INT_MASK, 0);\n\n\t \n\tREG_WR(bp, CFC_REG_DEBUG0, 0x20020000);\n\n\tbnx2x_init_block(bp, BLOCK_HC, PHASE_COMMON);\n\n\tif (!CHIP_IS_E1x(bp) && BP_NOMCP(bp))\n\t\tREG_WR(bp, IGU_REG_RESET_MEMORIES, 0x36);\n\n\tbnx2x_init_block(bp, BLOCK_IGU, PHASE_COMMON);\n\tbnx2x_init_block(bp, BLOCK_MISC_AEU, PHASE_COMMON);\n\n\t \n\tREG_WR(bp, 0x2814, 0xffffffff);\n\tREG_WR(bp, 0x3820, 0xffffffff);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tREG_WR(bp, PCICFG_OFFSET + PXPCS_TL_CONTROL_5,\n\t\t\t   (PXPCS_TL_CONTROL_5_ERR_UNSPPORT1 |\n\t\t\t\tPXPCS_TL_CONTROL_5_ERR_UNSPPORT));\n\t\tREG_WR(bp, PCICFG_OFFSET + PXPCS_TL_FUNC345_STAT,\n\t\t\t   (PXPCS_TL_FUNC345_STAT_ERR_UNSPPORT4 |\n\t\t\t\tPXPCS_TL_FUNC345_STAT_ERR_UNSPPORT3 |\n\t\t\t\tPXPCS_TL_FUNC345_STAT_ERR_UNSPPORT2));\n\t\tREG_WR(bp, PCICFG_OFFSET + PXPCS_TL_FUNC678_STAT,\n\t\t\t   (PXPCS_TL_FUNC678_STAT_ERR_UNSPPORT7 |\n\t\t\t\tPXPCS_TL_FUNC678_STAT_ERR_UNSPPORT6 |\n\t\t\t\tPXPCS_TL_FUNC678_STAT_ERR_UNSPPORT5));\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_NIG, PHASE_COMMON);\n\tif (!CHIP_IS_E1(bp)) {\n\t\t \n\t\tif (!CHIP_IS_E3(bp))\n\t\t\tREG_WR(bp, NIG_REG_LLH_MF_MODE, IS_MF(bp));\n\t}\n\tif (CHIP_IS_E1H(bp))\n\t\t \n\t\tREG_WR(bp, NIG_REG_LLH_E1HOV_MODE, IS_MF_SD(bp));\n\n\tif (CHIP_REV_IS_SLOW(bp))\n\t\tmsleep(200);\n\n\t \n\tval = reg_poll(bp, CFC_REG_LL_INIT_DONE, 1, 100, 10);\n\tif (val != 1) {\n\t\tBNX2X_ERR(\"CFC LL_INIT failed\\n\");\n\t\treturn -EBUSY;\n\t}\n\tval = reg_poll(bp, CFC_REG_AC_INIT_DONE, 1, 100, 10);\n\tif (val != 1) {\n\t\tBNX2X_ERR(\"CFC AC_INIT failed\\n\");\n\t\treturn -EBUSY;\n\t}\n\tval = reg_poll(bp, CFC_REG_CAM_INIT_DONE, 1, 100, 10);\n\tif (val != 1) {\n\t\tBNX2X_ERR(\"CFC CAM_INIT failed\\n\");\n\t\treturn -EBUSY;\n\t}\n\tREG_WR(bp, CFC_REG_DEBUG0, 0);\n\n\tif (CHIP_IS_E1(bp)) {\n\t\t \n\t\tbnx2x_read_dmae(bp, NIG_REG_STAT2_BRB_OCTET, 2);\n\t\tval = *bnx2x_sp(bp, wb_data[0]);\n\n\t\t \n\t\tif ((val == 0) && bnx2x_int_mem_test(bp)) {\n\t\t\tBNX2X_ERR(\"internal mem self test failed\\n\");\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\tbnx2x_setup_fan_failure_detection(bp);\n\n\t \n\tREG_RD(bp, PXP2_REG_PXP2_INT_STS_CLR_0);\n\n\tbnx2x_enable_blocks_attention(bp);\n\tbnx2x_enable_blocks_parity(bp);\n\n\tif (!BP_NOMCP(bp)) {\n\t\tif (CHIP_IS_E1x(bp))\n\t\t\tbnx2x__common_init_phy(bp);\n\t} else\n\t\tBNX2X_ERR(\"Bootcode is missing - can not initialize link\\n\");\n\n\tif (SHMEM2_HAS(bp, netproc_fw_ver))\n\t\tSHMEM2_WR(bp, netproc_fw_ver, REG_RD(bp, XSEM_REG_PRAM));\n\n\treturn 0;\n}\n\n \nstatic int bnx2x_init_hw_common_chip(struct bnx2x *bp)\n{\n\tint rc = bnx2x_init_hw_common(bp);\n\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (!BP_NOMCP(bp))\n\t\tbnx2x__common_init_phy(bp);\n\n\treturn 0;\n}\n\nstatic int bnx2x_init_hw_port(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tint init_phase = port ? PHASE_PORT1 : PHASE_PORT0;\n\tu32 low, high;\n\tu32 val, reg;\n\n\tDP(NETIF_MSG_HW, \"starting port init  port %d\\n\", port);\n\n\tREG_WR(bp, NIG_REG_MASK_INTERRUPT_PORT0 + port*4, 0);\n\n\tbnx2x_init_block(bp, BLOCK_MISC, init_phase);\n\tbnx2x_init_block(bp, BLOCK_PXP, init_phase);\n\tbnx2x_init_block(bp, BLOCK_PXP2, init_phase);\n\n\t \n\tif (!CHIP_IS_E1x(bp))\n\t\tREG_WR(bp, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, 1);\n\n\tbnx2x_init_block(bp, BLOCK_ATC, init_phase);\n\tbnx2x_init_block(bp, BLOCK_DMAE, init_phase);\n\tbnx2x_init_block(bp, BLOCK_PGLUE_B, init_phase);\n\tbnx2x_init_block(bp, BLOCK_QM, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_TCM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_UCM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_CCM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XCM, init_phase);\n\n\t \n\tbnx2x_qm_init_cid_count(bp, bp->qm_cid_count, INITOP_SET);\n\n\tif (CNIC_SUPPORT(bp)) {\n\t\tbnx2x_init_block(bp, BLOCK_TM, init_phase);\n\t\tREG_WR(bp, TM_REG_LIN0_SCAN_TIME + port*4, 20);\n\t\tREG_WR(bp, TM_REG_LIN0_MAX_ACTIVE_CID + port*4, 31);\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_DORQ, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_BRB1, init_phase);\n\n\tif (CHIP_IS_E1(bp) || CHIP_IS_E1H(bp)) {\n\n\t\tif (IS_MF(bp))\n\t\t\tlow = ((bp->flags & ONE_PORT_FLAG) ? 160 : 246);\n\t\telse if (bp->dev->mtu > 4096) {\n\t\t\tif (bp->flags & ONE_PORT_FLAG)\n\t\t\t\tlow = 160;\n\t\t\telse {\n\t\t\t\tval = bp->dev->mtu;\n\t\t\t\t \n\t\t\t\tlow = 96 + (val/64) +\n\t\t\t\t\t\t((val % 64) ? 1 : 0);\n\t\t\t}\n\t\t} else\n\t\t\tlow = ((bp->flags & ONE_PORT_FLAG) ? 80 : 160);\n\t\thigh = low + 56;\t \n\t\tREG_WR(bp, BRB1_REG_PAUSE_LOW_THRESHOLD_0 + port*4, low);\n\t\tREG_WR(bp, BRB1_REG_PAUSE_HIGH_THRESHOLD_0 + port*4, high);\n\t}\n\n\tif (CHIP_MODE_IS_4_PORT(bp))\n\t\tREG_WR(bp, (BP_PORT(bp) ?\n\t\t\t    BRB1_REG_MAC_GUARANTIED_1 :\n\t\t\t    BRB1_REG_MAC_GUARANTIED_0), 40);\n\n\tbnx2x_init_block(bp, BLOCK_PRS, init_phase);\n\tif (CHIP_IS_E3B0(bp)) {\n\t\tif (IS_MF_AFEX(bp)) {\n\t\t\t \n\t\t\tREG_WR(bp, BP_PORT(bp) ?\n\t\t\t       PRS_REG_HDRS_AFTER_BASIC_PORT_1 :\n\t\t\t       PRS_REG_HDRS_AFTER_BASIC_PORT_0, 0xE);\n\t\t\tREG_WR(bp, BP_PORT(bp) ?\n\t\t\t       PRS_REG_HDRS_AFTER_TAG_0_PORT_1 :\n\t\t\t       PRS_REG_HDRS_AFTER_TAG_0_PORT_0, 0x6);\n\t\t\tREG_WR(bp, BP_PORT(bp) ?\n\t\t\t       PRS_REG_MUST_HAVE_HDRS_PORT_1 :\n\t\t\t       PRS_REG_MUST_HAVE_HDRS_PORT_0, 0xA);\n\t\t} else {\n\t\t\t \n\t\t\tREG_WR(bp, BP_PORT(bp) ?\n\t\t\t       PRS_REG_HDRS_AFTER_BASIC_PORT_1 :\n\t\t\t       PRS_REG_HDRS_AFTER_BASIC_PORT_0,\n\t\t\t       (bp->path_has_ovlan ? 7 : 6));\n\t\t}\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_TSDM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_CSDM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_USDM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XSDM, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_TSEM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_USEM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_CSEM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XSEM, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_UPB, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XPB, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_PBF, init_phase);\n\n\tif (CHIP_IS_E1x(bp)) {\n\t\t \n\t\tREG_WR(bp, PBF_REG_P0_PAUSE_ENABLE + port*4, 0);\n\n\t\t \n\t\tREG_WR(bp, PBF_REG_P0_ARB_THRSH + port*4, (9040/16));\n\t\t \n\t\tREG_WR(bp, PBF_REG_P0_INIT_CRD + port*4, (9040/16) + 553 - 22);\n\n\t\t \n\t\tREG_WR(bp, PBF_REG_INIT_P0 + port*4, 1);\n\t\tudelay(50);\n\t\tREG_WR(bp, PBF_REG_INIT_P0 + port*4, 0);\n\t}\n\n\tif (CNIC_SUPPORT(bp))\n\t\tbnx2x_init_block(bp, BLOCK_SRC, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_CDU, init_phase);\n\tbnx2x_init_block(bp, BLOCK_CFC, init_phase);\n\n\tif (CHIP_IS_E1(bp)) {\n\t\tREG_WR(bp, HC_REG_LEADING_EDGE_0 + port*8, 0);\n\t\tREG_WR(bp, HC_REG_TRAILING_EDGE_0 + port*8, 0);\n\t}\n\tbnx2x_init_block(bp, BLOCK_HC, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_IGU, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_MISC_AEU, init_phase);\n\t \n\tval = IS_MF(bp) ? 0xF7 : 0x7;\n\t \n\tval |= CHIP_IS_E1(bp) ? 0 : 0x10;\n\tREG_WR(bp, MISC_REG_AEU_MASK_ATTN_FUNC_0 + port*4, val);\n\n\t \n\treg = port ? MISC_REG_AEU_ENABLE4_NIG_1 : MISC_REG_AEU_ENABLE4_NIG_0;\n\tREG_WR(bp, reg,\n\t       REG_RD(bp, reg) &\n\t       ~AEU_INPUTS_ATTN_BITS_MCP_LATCHED_SCPAD_PARITY);\n\n\treg = port ? MISC_REG_AEU_ENABLE4_PXP_1 : MISC_REG_AEU_ENABLE4_PXP_0;\n\tREG_WR(bp, reg,\n\t       REG_RD(bp, reg) &\n\t       ~AEU_INPUTS_ATTN_BITS_MCP_LATCHED_SCPAD_PARITY);\n\n\tbnx2x_init_block(bp, BLOCK_NIG, init_phase);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\t \n\t\tif (IS_MF_AFEX(bp))\n\t\t\tREG_WR(bp, BP_PORT(bp) ?\n\t\t\t       NIG_REG_P1_HDRS_AFTER_BASIC :\n\t\t\t       NIG_REG_P0_HDRS_AFTER_BASIC, 0xE);\n\t\telse\n\t\t\tREG_WR(bp, BP_PORT(bp) ?\n\t\t\t       NIG_REG_P1_HDRS_AFTER_BASIC :\n\t\t\t       NIG_REG_P0_HDRS_AFTER_BASIC,\n\t\t\t       IS_MF_SD(bp) ? 7 : 6);\n\n\t\tif (CHIP_IS_E3(bp))\n\t\t\tREG_WR(bp, BP_PORT(bp) ?\n\t\t\t\t   NIG_REG_LLH1_MF_MODE :\n\t\t\t\t   NIG_REG_LLH_MF_MODE, IS_MF(bp));\n\t}\n\tif (!CHIP_IS_E3(bp))\n\t\tREG_WR(bp, NIG_REG_XGXS_SERDES0_MODE_SEL + port*4, 1);\n\n\tif (!CHIP_IS_E1(bp)) {\n\t\t \n\t\tREG_WR(bp, NIG_REG_LLH0_BRB1_DRV_MASK_MF + port*4,\n\t\t       (IS_MF_SD(bp) ? 0x1 : 0x2));\n\n\t\tif (!CHIP_IS_E1x(bp)) {\n\t\t\tval = 0;\n\t\t\tswitch (bp->mf_mode) {\n\t\t\tcase MULTI_FUNCTION_SD:\n\t\t\t\tval = 1;\n\t\t\t\tbreak;\n\t\t\tcase MULTI_FUNCTION_SI:\n\t\t\tcase MULTI_FUNCTION_AFEX:\n\t\t\t\tval = 2;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tREG_WR(bp, (BP_PORT(bp) ? NIG_REG_LLH1_CLS_TYPE :\n\t\t\t\t\t\t  NIG_REG_LLH0_CLS_TYPE), val);\n\t\t}\n\t\t{\n\t\t\tREG_WR(bp, NIG_REG_LLFC_ENABLE_0 + port*4, 0);\n\t\t\tREG_WR(bp, NIG_REG_LLFC_OUT_EN_0 + port*4, 0);\n\t\t\tREG_WR(bp, NIG_REG_PAUSE_ENABLE_0 + port*4, 1);\n\t\t}\n\t}\n\n\t \n\tval = REG_RD(bp, MISC_REG_SPIO_EVENT_EN);\n\tif (val & MISC_SPIO_SPIO5) {\n\t\tu32 reg_addr = (port ? MISC_REG_AEU_ENABLE1_FUNC_1_OUT_0 :\n\t\t\t\t       MISC_REG_AEU_ENABLE1_FUNC_0_OUT_0);\n\t\tval = REG_RD(bp, reg_addr);\n\t\tval |= AEU_INPUTS_ATTN_BITS_SPIO5;\n\t\tREG_WR(bp, reg_addr, val);\n\t}\n\n\tif (CHIP_IS_E3B0(bp))\n\t\tbp->flags |= PTP_SUPPORTED;\n\n\treturn 0;\n}\n\nstatic void bnx2x_ilt_wr(struct bnx2x *bp, u32 index, dma_addr_t addr)\n{\n\tint reg;\n\tu32 wb_write[2];\n\n\tif (CHIP_IS_E1(bp))\n\t\treg = PXP2_REG_RQ_ONCHIP_AT + index*8;\n\telse\n\t\treg = PXP2_REG_RQ_ONCHIP_AT_B0 + index*8;\n\n\twb_write[0] = ONCHIP_ADDR1(addr);\n\twb_write[1] = ONCHIP_ADDR2(addr);\n\tREG_WR_DMAE(bp, reg, wb_write, 2);\n}\n\nvoid bnx2x_igu_clear_sb_gen(struct bnx2x *bp, u8 func, u8 idu_sb_id, bool is_pf)\n{\n\tu32 data, ctl, cnt = 100;\n\tu32 igu_addr_data = IGU_REG_COMMAND_REG_32LSB_DATA;\n\tu32 igu_addr_ctl = IGU_REG_COMMAND_REG_CTRL;\n\tu32 igu_addr_ack = IGU_REG_CSTORM_TYPE_0_SB_CLEANUP + (idu_sb_id/32)*4;\n\tu32 sb_bit =  1 << (idu_sb_id%32);\n\tu32 func_encode = func | (is_pf ? 1 : 0) << IGU_FID_ENCODE_IS_PF_SHIFT;\n\tu32 addr_encode = IGU_CMD_E2_PROD_UPD_BASE + idu_sb_id;\n\n\t \n\tif (CHIP_INT_MODE_IS_BC(bp))\n\t\treturn;\n\n\tdata = (IGU_USE_REGISTER_cstorm_type_0_sb_cleanup\n\t\t\t<< IGU_REGULAR_CLEANUP_TYPE_SHIFT)\t|\n\t\tIGU_REGULAR_CLEANUP_SET\t\t\t\t|\n\t\tIGU_REGULAR_BCLEANUP;\n\n\tctl = addr_encode << IGU_CTRL_REG_ADDRESS_SHIFT\t\t|\n\t      func_encode << IGU_CTRL_REG_FID_SHIFT\t\t|\n\t      IGU_CTRL_CMD_TYPE_WR << IGU_CTRL_REG_TYPE_SHIFT;\n\n\tDP(NETIF_MSG_HW, \"write 0x%08x to IGU(via GRC) addr 0x%x\\n\",\n\t\t\t data, igu_addr_data);\n\tREG_WR(bp, igu_addr_data, data);\n\tbarrier();\n\tDP(NETIF_MSG_HW, \"write 0x%08x to IGU(via GRC) addr 0x%x\\n\",\n\t\t\t  ctl, igu_addr_ctl);\n\tREG_WR(bp, igu_addr_ctl, ctl);\n\tbarrier();\n\n\t \n\twhile (!(REG_RD(bp, igu_addr_ack) & sb_bit) && --cnt)\n\t\tmsleep(20);\n\n\tif (!(REG_RD(bp, igu_addr_ack) & sb_bit)) {\n\t\tDP(NETIF_MSG_HW,\n\t\t   \"Unable to finish IGU cleanup: idu_sb_id %d offset %d bit %d (cnt %d)\\n\",\n\t\t\t  idu_sb_id, idu_sb_id/32, idu_sb_id%32, cnt);\n\t}\n}\n\nstatic void bnx2x_igu_clear_sb(struct bnx2x *bp, u8 idu_sb_id)\n{\n\tbnx2x_igu_clear_sb_gen(bp, BP_FUNC(bp), idu_sb_id, true  );\n}\n\nstatic void bnx2x_clear_func_ilt(struct bnx2x *bp, u32 func)\n{\n\tu32 i, base = FUNC_ILT_BASE(func);\n\tfor (i = base; i < base + ILT_PER_FUNC; i++)\n\t\tbnx2x_ilt_wr(bp, i, 0);\n}\n\nstatic void bnx2x_init_searcher(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tbnx2x_src_init_t2(bp, bp->t2, bp->t2_mapping, SRC_CONN_NUM);\n\t \n\tREG_WR(bp, SRC_REG_NUMBER_HASH_BITS0 + port*4, SRC_HASH_BITS);\n}\n\nstatic inline int bnx2x_func_switch_update(struct bnx2x *bp, int suspend)\n{\n\tint rc;\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\tstruct bnx2x_func_switch_update_params *switch_update_params =\n\t\t&func_params.params.switch_update;\n\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &func_params.ramrod_flags);\n\t__set_bit(RAMROD_RETRY, &func_params.ramrod_flags);\n\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_SWITCH_UPDATE;\n\n\t \n\t__set_bit(BNX2X_F_UPDATE_TX_SWITCH_SUSPEND_CHNG,\n\t\t  &switch_update_params->changes);\n\tif (suspend)\n\t\t__set_bit(BNX2X_F_UPDATE_TX_SWITCH_SUSPEND,\n\t\t\t  &switch_update_params->changes);\n\n\trc = bnx2x_func_state_change(bp, &func_params);\n\n\treturn rc;\n}\n\nstatic int bnx2x_reset_nic_mode(struct bnx2x *bp)\n{\n\tint rc, i, port = BP_PORT(bp);\n\tint vlan_en = 0, mac_en[NUM_MACS];\n\n\t \n\tif (bp->mf_mode == SINGLE_FUNCTION) {\n\t\tbnx2x_set_rx_filter(&bp->link_params, 0);\n\t} else {\n\t\tvlan_en = REG_RD(bp, port ? NIG_REG_LLH1_FUNC_EN :\n\t\t\t\t   NIG_REG_LLH0_FUNC_EN);\n\t\tREG_WR(bp, port ? NIG_REG_LLH1_FUNC_EN :\n\t\t\t  NIG_REG_LLH0_FUNC_EN, 0);\n\t\tfor (i = 0; i < NUM_MACS; i++) {\n\t\t\tmac_en[i] = REG_RD(bp, port ?\n\t\t\t\t\t     (NIG_REG_LLH1_FUNC_MEM_ENABLE +\n\t\t\t\t\t      4 * i) :\n\t\t\t\t\t     (NIG_REG_LLH0_FUNC_MEM_ENABLE +\n\t\t\t\t\t      4 * i));\n\t\t\tREG_WR(bp, port ? (NIG_REG_LLH1_FUNC_MEM_ENABLE +\n\t\t\t\t\t      4 * i) :\n\t\t\t\t  (NIG_REG_LLH0_FUNC_MEM_ENABLE + 4 * i), 0);\n\t\t}\n\t}\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P0_TX_MNG_HOST_ENABLE :\n\t       NIG_REG_P1_TX_MNG_HOST_ENABLE, 0);\n\n\t \n\trc = bnx2x_func_switch_update(bp, 1);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Can't suspend tx-switching!\\n\");\n\t\treturn rc;\n\t}\n\n\t \n\tREG_WR(bp, PRS_REG_NIC_MODE, 0);\n\n\t \n\tif (bp->mf_mode == SINGLE_FUNCTION) {\n\t\tbnx2x_set_rx_filter(&bp->link_params, 1);\n\t} else {\n\t\tREG_WR(bp, port ? NIG_REG_LLH1_FUNC_EN :\n\t\t\t  NIG_REG_LLH0_FUNC_EN, vlan_en);\n\t\tfor (i = 0; i < NUM_MACS; i++) {\n\t\t\tREG_WR(bp, port ? (NIG_REG_LLH1_FUNC_MEM_ENABLE +\n\t\t\t\t\t      4 * i) :\n\t\t\t\t  (NIG_REG_LLH0_FUNC_MEM_ENABLE + 4 * i),\n\t\t\t\t  mac_en[i]);\n\t\t}\n\t}\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P0_TX_MNG_HOST_ENABLE :\n\t       NIG_REG_P1_TX_MNG_HOST_ENABLE, 1);\n\n\t \n\trc = bnx2x_func_switch_update(bp, 0);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Can't resume tx-switching!\\n\");\n\t\treturn rc;\n\t}\n\n\tDP(NETIF_MSG_IFUP, \"NIC MODE disabled\\n\");\n\treturn 0;\n}\n\nint bnx2x_init_hw_func_cnic(struct bnx2x *bp)\n{\n\tint rc;\n\n\tbnx2x_ilt_init_op_cnic(bp, INITOP_SET);\n\n\tif (CONFIGURE_NIC_MODE(bp)) {\n\t\t \n\t\tbnx2x_init_searcher(bp);\n\n\t\t \n\t\trc = bnx2x_reset_nic_mode(bp);\n\t\tif (rc)\n\t\t\tBNX2X_ERR(\"Can't change NIC mode!\\n\");\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void bnx2x_clean_pglue_errors(struct bnx2x *bp)\n{\n\tif (!CHIP_IS_E1x(bp))\n\t\tREG_WR(bp, PGLUE_B_REG_WAS_ERROR_PF_7_0_CLR,\n\t\t       1 << BP_ABS_FUNC(bp));\n}\n\nstatic int bnx2x_init_hw_func(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tint func = BP_FUNC(bp);\n\tint init_phase = PHASE_PF0 + func;\n\tstruct bnx2x_ilt *ilt = BP_ILT(bp);\n\tu16 cdu_ilt_start;\n\tu32 addr, val;\n\tu32 main_mem_base, main_mem_size, main_mem_prty_clr;\n\tint i, main_mem_width, rc;\n\n\tDP(NETIF_MSG_HW, \"starting func init  func %d\\n\", func);\n\n\t \n\tif (!CHIP_IS_E1x(bp)) {\n\t\trc = bnx2x_pf_flr_clnup(bp);\n\t\tif (rc) {\n\t\t\tbnx2x_fw_dump(bp);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\t \n\tif (bp->common.int_block == INT_BLOCK_HC) {\n\t\taddr = (port ? HC_REG_CONFIG_1 : HC_REG_CONFIG_0);\n\t\tval = REG_RD(bp, addr);\n\t\tval |= HC_CONFIG_0_REG_MSI_ATTN_EN_0;\n\t\tREG_WR(bp, addr, val);\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_PXP, init_phase);\n\tbnx2x_init_block(bp, BLOCK_PXP2, init_phase);\n\n\tilt = BP_ILT(bp);\n\tcdu_ilt_start = ilt->clients[ILT_CLIENT_CDU].start;\n\n\tif (IS_SRIOV(bp))\n\t\tcdu_ilt_start += BNX2X_FIRST_VF_CID/ILT_PAGE_CIDS;\n\tcdu_ilt_start = bnx2x_iov_init_ilt(bp, cdu_ilt_start);\n\n\t \n\tcdu_ilt_start = ilt->clients[ILT_CLIENT_CDU].start;\n\tfor (i = 0; i < L2_ILT_LINES(bp); i++) {\n\t\tilt->lines[cdu_ilt_start + i].page = bp->context[i].vcxt;\n\t\tilt->lines[cdu_ilt_start + i].page_mapping =\n\t\t\tbp->context[i].cxt_mapping;\n\t\tilt->lines[cdu_ilt_start + i].size = bp->context[i].size;\n\t}\n\n\tbnx2x_ilt_init_op(bp, INITOP_SET);\n\n\tif (!CONFIGURE_NIC_MODE(bp)) {\n\t\tbnx2x_init_searcher(bp);\n\t\tREG_WR(bp, PRS_REG_NIC_MODE, 0);\n\t\tDP(NETIF_MSG_IFUP, \"NIC MODE disabled\\n\");\n\t} else {\n\t\t \n\t\tREG_WR(bp, PRS_REG_NIC_MODE, 1);\n\t\tDP(NETIF_MSG_IFUP, \"NIC MODE configured\\n\");\n\t}\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tu32 pf_conf = IGU_PF_CONF_FUNC_EN;\n\n\t\t \n\t\tif (!(bp->flags & USING_MSIX_FLAG))\n\t\t\tpf_conf |= IGU_PF_CONF_SINGLE_ISR_EN;\n\t\t \n\t\tmsleep(20);\n\t\t \n\t\tREG_WR(bp, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, 1);\n\t\t \n\t\tREG_WR(bp, IGU_REG_PF_CONFIGURATION, pf_conf);\n\t}\n\n\tbp->dmae_ready = 1;\n\n\tbnx2x_init_block(bp, BLOCK_PGLUE_B, init_phase);\n\n\tbnx2x_clean_pglue_errors(bp);\n\n\tbnx2x_init_block(bp, BLOCK_ATC, init_phase);\n\tbnx2x_init_block(bp, BLOCK_DMAE, init_phase);\n\tbnx2x_init_block(bp, BLOCK_NIG, init_phase);\n\tbnx2x_init_block(bp, BLOCK_SRC, init_phase);\n\tbnx2x_init_block(bp, BLOCK_MISC, init_phase);\n\tbnx2x_init_block(bp, BLOCK_TCM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_UCM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_CCM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XCM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_TSEM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_USEM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_CSEM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XSEM, init_phase);\n\n\tif (!CHIP_IS_E1x(bp))\n\t\tREG_WR(bp, QM_REG_PF_EN, 1);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tREG_WR(bp, TSEM_REG_VFPF_ERR_NUM, BNX2X_MAX_NUM_OF_VFS + func);\n\t\tREG_WR(bp, USEM_REG_VFPF_ERR_NUM, BNX2X_MAX_NUM_OF_VFS + func);\n\t\tREG_WR(bp, CSEM_REG_VFPF_ERR_NUM, BNX2X_MAX_NUM_OF_VFS + func);\n\t\tREG_WR(bp, XSEM_REG_VFPF_ERR_NUM, BNX2X_MAX_NUM_OF_VFS + func);\n\t}\n\tbnx2x_init_block(bp, BLOCK_QM, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_TM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_DORQ, init_phase);\n\tREG_WR(bp, DORQ_REG_MODE_ACT, 1);  \n\n\tbnx2x_iov_init_dq(bp);\n\n\tbnx2x_init_block(bp, BLOCK_BRB1, init_phase);\n\tbnx2x_init_block(bp, BLOCK_PRS, init_phase);\n\tbnx2x_init_block(bp, BLOCK_TSDM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_CSDM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_USDM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XSDM, init_phase);\n\tbnx2x_init_block(bp, BLOCK_UPB, init_phase);\n\tbnx2x_init_block(bp, BLOCK_XPB, init_phase);\n\tbnx2x_init_block(bp, BLOCK_PBF, init_phase);\n\tif (!CHIP_IS_E1x(bp))\n\t\tREG_WR(bp, PBF_REG_DISABLE_PF, 0);\n\n\tbnx2x_init_block(bp, BLOCK_CDU, init_phase);\n\n\tbnx2x_init_block(bp, BLOCK_CFC, init_phase);\n\n\tif (!CHIP_IS_E1x(bp))\n\t\tREG_WR(bp, CFC_REG_WEAK_ENABLE_PF, 1);\n\n\tif (IS_MF(bp)) {\n\t\tif (!(IS_MF_UFP(bp) && BNX2X_IS_MF_SD_PROTOCOL_FCOE(bp))) {\n\t\t\tREG_WR(bp, NIG_REG_LLH0_FUNC_EN + port * 8, 1);\n\t\t\tREG_WR(bp, NIG_REG_LLH0_FUNC_VLAN_ID + port * 8,\n\t\t\t       bp->mf_ov);\n\t\t}\n\t}\n\n\tbnx2x_init_block(bp, BLOCK_MISC_AEU, init_phase);\n\n\t \n\tif (bp->common.int_block == INT_BLOCK_HC) {\n\t\tif (CHIP_IS_E1H(bp)) {\n\t\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_12 + func*4, 0);\n\n\t\t\tREG_WR(bp, HC_REG_LEADING_EDGE_0 + port*8, 0);\n\t\t\tREG_WR(bp, HC_REG_TRAILING_EDGE_0 + port*8, 0);\n\t\t}\n\t\tbnx2x_init_block(bp, BLOCK_HC, init_phase);\n\n\t} else {\n\t\tint num_segs, sb_idx, prod_offset;\n\n\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_12 + func*4, 0);\n\n\t\tif (!CHIP_IS_E1x(bp)) {\n\t\t\tREG_WR(bp, IGU_REG_LEADING_EDGE_LATCH, 0);\n\t\t\tREG_WR(bp, IGU_REG_TRAILING_EDGE_LATCH, 0);\n\t\t}\n\n\t\tbnx2x_init_block(bp, BLOCK_IGU, init_phase);\n\n\t\tif (!CHIP_IS_E1x(bp)) {\n\t\t\tint dsb_idx = 0;\n\t\t\t \n\t\t\t \n\t\t\tnum_segs = CHIP_INT_MODE_IS_BC(bp) ?\n\t\t\t\tIGU_BC_NDSB_NUM_SEGS : IGU_NORM_NDSB_NUM_SEGS;\n\t\t\tfor (sb_idx = 0; sb_idx < bp->igu_sb_cnt; sb_idx++) {\n\t\t\t\tprod_offset = (bp->igu_base_sb + sb_idx) *\n\t\t\t\t\tnum_segs;\n\n\t\t\t\tfor (i = 0; i < num_segs; i++) {\n\t\t\t\t\taddr = IGU_REG_PROD_CONS_MEMORY +\n\t\t\t\t\t\t\t(prod_offset + i) * 4;\n\t\t\t\t\tREG_WR(bp, addr, 0);\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_base_sb + sb_idx,\n\t\t\t\t\t     USTORM_ID, 0, IGU_INT_NOP, 1);\n\t\t\t\tbnx2x_igu_clear_sb(bp,\n\t\t\t\t\t\t   bp->igu_base_sb + sb_idx);\n\t\t\t}\n\n\t\t\t \n\t\t\tnum_segs = CHIP_INT_MODE_IS_BC(bp) ?\n\t\t\t\tIGU_BC_DSB_NUM_SEGS : IGU_NORM_DSB_NUM_SEGS;\n\n\t\t\tif (CHIP_MODE_IS_4_PORT(bp))\n\t\t\t\tdsb_idx = BP_FUNC(bp);\n\t\t\telse\n\t\t\t\tdsb_idx = BP_VN(bp);\n\n\t\t\tprod_offset = (CHIP_INT_MODE_IS_BC(bp) ?\n\t\t\t\t       IGU_BC_BASE_DSB_PROD + dsb_idx :\n\t\t\t\t       IGU_NORM_BASE_DSB_PROD + dsb_idx);\n\n\t\t\t \n\t\t\tfor (i = 0; i < (num_segs * E1HVN_MAX);\n\t\t\t     i += E1HVN_MAX) {\n\t\t\t\taddr = IGU_REG_PROD_CONS_MEMORY +\n\t\t\t\t\t\t\t(prod_offset + i)*4;\n\t\t\t\tREG_WR(bp, addr, 0);\n\t\t\t}\n\t\t\t \n\t\t\tif (CHIP_INT_MODE_IS_BC(bp)) {\n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id,\n\t\t\t\t\t     USTORM_ID, 0, IGU_INT_NOP, 1);\n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id,\n\t\t\t\t\t     CSTORM_ID, 0, IGU_INT_NOP, 1);\n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id,\n\t\t\t\t\t     XSTORM_ID, 0, IGU_INT_NOP, 1);\n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id,\n\t\t\t\t\t     TSTORM_ID, 0, IGU_INT_NOP, 1);\n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id,\n\t\t\t\t\t     ATTENTION_ID, 0, IGU_INT_NOP, 1);\n\t\t\t} else {\n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id,\n\t\t\t\t\t     USTORM_ID, 0, IGU_INT_NOP, 1);\n\t\t\t\tbnx2x_ack_sb(bp, bp->igu_dsb_id,\n\t\t\t\t\t     ATTENTION_ID, 0, IGU_INT_NOP, 1);\n\t\t\t}\n\t\t\tbnx2x_igu_clear_sb(bp, bp->igu_dsb_id);\n\n\t\t\t \n\t\t\tREG_WR(bp, IGU_REG_SB_INT_BEFORE_MASK_LSB, 0);\n\t\t\tREG_WR(bp, IGU_REG_SB_INT_BEFORE_MASK_MSB, 0);\n\t\t\tREG_WR(bp, IGU_REG_SB_MASK_LSB, 0);\n\t\t\tREG_WR(bp, IGU_REG_SB_MASK_MSB, 0);\n\t\t\tREG_WR(bp, IGU_REG_PBA_STATUS_LSB, 0);\n\t\t\tREG_WR(bp, IGU_REG_PBA_STATUS_MSB, 0);\n\t\t}\n\t}\n\n\t \n\tREG_WR(bp, 0x2114, 0xffffffff);\n\tREG_WR(bp, 0x2120, 0xffffffff);\n\n\tif (CHIP_IS_E1x(bp)) {\n\t\tmain_mem_size = HC_REG_MAIN_MEMORY_SIZE / 2;  \n\t\tmain_mem_base = HC_REG_MAIN_MEMORY +\n\t\t\t\tBP_PORT(bp) * (main_mem_size * 4);\n\t\tmain_mem_prty_clr = HC_REG_HC_PRTY_STS_CLR;\n\t\tmain_mem_width = 8;\n\n\t\tval = REG_RD(bp, main_mem_prty_clr);\n\t\tif (val)\n\t\t\tDP(NETIF_MSG_HW,\n\t\t\t   \"Hmmm... Parity errors in HC block during function init (0x%x)!\\n\",\n\t\t\t   val);\n\n\t\t \n\t\tfor (i = main_mem_base;\n\t\t     i < main_mem_base + main_mem_size * 4;\n\t\t     i += main_mem_width) {\n\t\t\tbnx2x_read_dmae(bp, i, main_mem_width / 4);\n\t\t\tbnx2x_write_dmae(bp, bnx2x_sp_mapping(bp, wb_data),\n\t\t\t\t\t i, main_mem_width / 4);\n\t\t}\n\t\t \n\t\tREG_RD(bp, main_mem_prty_clr);\n\t}\n\n#ifdef BNX2X_STOP_ON_ERROR\n\t \n\tREG_WR8(bp, BAR_USTRORM_INTMEM +\n\t       USTORM_RECORD_SLOW_PATH_OFFSET(BP_FUNC(bp)), 1);\n\tREG_WR8(bp, BAR_TSTRORM_INTMEM +\n\t       TSTORM_RECORD_SLOW_PATH_OFFSET(BP_FUNC(bp)), 1);\n\tREG_WR8(bp, BAR_CSTRORM_INTMEM +\n\t       CSTORM_RECORD_SLOW_PATH_OFFSET(BP_FUNC(bp)), 1);\n\tREG_WR8(bp, BAR_XSTRORM_INTMEM +\n\t       XSTORM_RECORD_SLOW_PATH_OFFSET(BP_FUNC(bp)), 1);\n#endif\n\n\tbnx2x_phy_probe(&bp->link_params);\n\n\treturn 0;\n}\n\nvoid bnx2x_free_mem_cnic(struct bnx2x *bp)\n{\n\tbnx2x_ilt_mem_op_cnic(bp, ILT_MEMOP_FREE);\n\n\tif (!CHIP_IS_E1x(bp))\n\t\tBNX2X_PCI_FREE(bp->cnic_sb.e2_sb, bp->cnic_sb_mapping,\n\t\t\t       sizeof(struct host_hc_status_block_e2));\n\telse\n\t\tBNX2X_PCI_FREE(bp->cnic_sb.e1x_sb, bp->cnic_sb_mapping,\n\t\t\t       sizeof(struct host_hc_status_block_e1x));\n\n\tBNX2X_PCI_FREE(bp->t2, bp->t2_mapping, SRC_T2_SZ);\n}\n\nvoid bnx2x_free_mem(struct bnx2x *bp)\n{\n\tint i;\n\n\tBNX2X_PCI_FREE(bp->fw_stats, bp->fw_stats_mapping,\n\t\t       bp->fw_stats_data_sz + bp->fw_stats_req_sz);\n\n\tif (IS_VF(bp))\n\t\treturn;\n\n\tBNX2X_PCI_FREE(bp->def_status_blk, bp->def_status_blk_mapping,\n\t\t       sizeof(struct host_sp_status_block));\n\n\tBNX2X_PCI_FREE(bp->slowpath, bp->slowpath_mapping,\n\t\t       sizeof(struct bnx2x_slowpath));\n\n\tfor (i = 0; i < L2_ILT_LINES(bp); i++)\n\t\tBNX2X_PCI_FREE(bp->context[i].vcxt, bp->context[i].cxt_mapping,\n\t\t\t       bp->context[i].size);\n\tbnx2x_ilt_mem_op(bp, ILT_MEMOP_FREE);\n\n\tBNX2X_FREE(bp->ilt->lines);\n\n\tBNX2X_PCI_FREE(bp->spq, bp->spq_mapping, BCM_PAGE_SIZE);\n\n\tBNX2X_PCI_FREE(bp->eq_ring, bp->eq_mapping,\n\t\t       BCM_PAGE_SIZE * NUM_EQ_PAGES);\n\n\tBNX2X_PCI_FREE(bp->t2, bp->t2_mapping, SRC_T2_SZ);\n\n\tbnx2x_iov_free_mem(bp);\n}\n\nint bnx2x_alloc_mem_cnic(struct bnx2x *bp)\n{\n\tif (!CHIP_IS_E1x(bp)) {\n\t\t \n\t\tbp->cnic_sb.e2_sb = BNX2X_PCI_ALLOC(&bp->cnic_sb_mapping,\n\t\t\t\t\t\t    sizeof(struct host_hc_status_block_e2));\n\t\tif (!bp->cnic_sb.e2_sb)\n\t\t\tgoto alloc_mem_err;\n\t} else {\n\t\tbp->cnic_sb.e1x_sb = BNX2X_PCI_ALLOC(&bp->cnic_sb_mapping,\n\t\t\t\t\t\t     sizeof(struct host_hc_status_block_e1x));\n\t\tif (!bp->cnic_sb.e1x_sb)\n\t\t\tgoto alloc_mem_err;\n\t}\n\n\tif (CONFIGURE_NIC_MODE(bp) && !bp->t2) {\n\t\t \n\t\tbp->t2 = BNX2X_PCI_ALLOC(&bp->t2_mapping, SRC_T2_SZ);\n\t\tif (!bp->t2)\n\t\t\tgoto alloc_mem_err;\n\t}\n\n\t \n\tbp->cnic_eth_dev.addr_drv_info_to_mcp =\n\t\t&bp->slowpath->drv_info_to_mcp;\n\n\tif (bnx2x_ilt_mem_op_cnic(bp, ILT_MEMOP_ALLOC))\n\t\tgoto alloc_mem_err;\n\n\treturn 0;\n\nalloc_mem_err:\n\tbnx2x_free_mem_cnic(bp);\n\tBNX2X_ERR(\"Can't allocate memory\\n\");\n\treturn -ENOMEM;\n}\n\nint bnx2x_alloc_mem(struct bnx2x *bp)\n{\n\tint i, allocated, context_size;\n\n\tif (!CONFIGURE_NIC_MODE(bp) && !bp->t2) {\n\t\t \n\t\tbp->t2 = BNX2X_PCI_ALLOC(&bp->t2_mapping, SRC_T2_SZ);\n\t\tif (!bp->t2)\n\t\t\tgoto alloc_mem_err;\n\t}\n\n\tbp->def_status_blk = BNX2X_PCI_ALLOC(&bp->def_status_blk_mapping,\n\t\t\t\t\t     sizeof(struct host_sp_status_block));\n\tif (!bp->def_status_blk)\n\t\tgoto alloc_mem_err;\n\n\tbp->slowpath = BNX2X_PCI_ALLOC(&bp->slowpath_mapping,\n\t\t\t\t       sizeof(struct bnx2x_slowpath));\n\tif (!bp->slowpath)\n\t\tgoto alloc_mem_err;\n\n\t \n\tcontext_size = sizeof(union cdu_context) * BNX2X_L2_CID_COUNT(bp);\n\n\tfor (i = 0, allocated = 0; allocated < context_size; i++) {\n\t\tbp->context[i].size = min(CDU_ILT_PAGE_SZ,\n\t\t\t\t\t  (context_size - allocated));\n\t\tbp->context[i].vcxt = BNX2X_PCI_ALLOC(&bp->context[i].cxt_mapping,\n\t\t\t\t\t\t      bp->context[i].size);\n\t\tif (!bp->context[i].vcxt)\n\t\t\tgoto alloc_mem_err;\n\t\tallocated += bp->context[i].size;\n\t}\n\tbp->ilt->lines = kcalloc(ILT_MAX_LINES, sizeof(struct ilt_line),\n\t\t\t\t GFP_KERNEL);\n\tif (!bp->ilt->lines)\n\t\tgoto alloc_mem_err;\n\n\tif (bnx2x_ilt_mem_op(bp, ILT_MEMOP_ALLOC))\n\t\tgoto alloc_mem_err;\n\n\tif (bnx2x_iov_alloc_mem(bp))\n\t\tgoto alloc_mem_err;\n\n\t \n\tbp->spq = BNX2X_PCI_ALLOC(&bp->spq_mapping, BCM_PAGE_SIZE);\n\tif (!bp->spq)\n\t\tgoto alloc_mem_err;\n\n\t \n\tbp->eq_ring = BNX2X_PCI_ALLOC(&bp->eq_mapping,\n\t\t\t\t      BCM_PAGE_SIZE * NUM_EQ_PAGES);\n\tif (!bp->eq_ring)\n\t\tgoto alloc_mem_err;\n\n\treturn 0;\n\nalloc_mem_err:\n\tbnx2x_free_mem(bp);\n\tBNX2X_ERR(\"Can't allocate memory\\n\");\n\treturn -ENOMEM;\n}\n\n \n\nint bnx2x_set_mac_one(struct bnx2x *bp, const u8 *mac,\n\t\t      struct bnx2x_vlan_mac_obj *obj, bool set,\n\t\t      int mac_type, unsigned long *ramrod_flags)\n{\n\tint rc;\n\tstruct bnx2x_vlan_mac_ramrod_params ramrod_param;\n\n\tmemset(&ramrod_param, 0, sizeof(ramrod_param));\n\n\t \n\tramrod_param.vlan_mac_obj = obj;\n\tramrod_param.ramrod_flags = *ramrod_flags;\n\n\t \n\tif (!test_bit(RAMROD_CONT, ramrod_flags)) {\n\t\tmemcpy(ramrod_param.user_req.u.mac.mac, mac, ETH_ALEN);\n\n\t\t__set_bit(mac_type, &ramrod_param.user_req.vlan_mac_flags);\n\n\t\t \n\t\tif (set)\n\t\t\tramrod_param.user_req.cmd = BNX2X_VLAN_MAC_ADD;\n\t\telse\n\t\t\tramrod_param.user_req.cmd = BNX2X_VLAN_MAC_DEL;\n\t}\n\n\trc = bnx2x_config_vlan_mac(bp, &ramrod_param);\n\n\tif (rc == -EEXIST) {\n\t\tDP(BNX2X_MSG_SP, \"Failed to schedule ADD operations: %d\\n\", rc);\n\t\t \n\t\trc = 0;\n\t} else if (rc < 0)\n\t\tBNX2X_ERR(\"%s MAC failed\\n\", (set ? \"Set\" : \"Del\"));\n\n\treturn rc;\n}\n\nint bnx2x_set_vlan_one(struct bnx2x *bp, u16 vlan,\n\t\t       struct bnx2x_vlan_mac_obj *obj, bool set,\n\t\t       unsigned long *ramrod_flags)\n{\n\tint rc;\n\tstruct bnx2x_vlan_mac_ramrod_params ramrod_param;\n\n\tmemset(&ramrod_param, 0, sizeof(ramrod_param));\n\n\t \n\tramrod_param.vlan_mac_obj = obj;\n\tramrod_param.ramrod_flags = *ramrod_flags;\n\n\t \n\tif (!test_bit(RAMROD_CONT, ramrod_flags)) {\n\t\tramrod_param.user_req.u.vlan.vlan = vlan;\n\t\t__set_bit(BNX2X_VLAN, &ramrod_param.user_req.vlan_mac_flags);\n\t\t \n\t\tif (set)\n\t\t\tramrod_param.user_req.cmd = BNX2X_VLAN_MAC_ADD;\n\t\telse\n\t\t\tramrod_param.user_req.cmd = BNX2X_VLAN_MAC_DEL;\n\t}\n\n\trc = bnx2x_config_vlan_mac(bp, &ramrod_param);\n\n\tif (rc == -EEXIST) {\n\t\t \n\t\tDP(BNX2X_MSG_SP, \"Failed to schedule ADD operations: %d\\n\", rc);\n\t\trc = 0;\n\t} else if (rc < 0) {\n\t\tBNX2X_ERR(\"%s VLAN failed\\n\", (set ? \"Set\" : \"Del\"));\n\t}\n\n\treturn rc;\n}\n\nvoid bnx2x_clear_vlan_info(struct bnx2x *bp)\n{\n\tstruct bnx2x_vlan_entry *vlan;\n\n\t \n\tlist_for_each_entry(vlan, &bp->vlan_reg, link)\n\t\tvlan->hw = false;\n\n\tbp->vlan_cnt = 0;\n}\n\nstatic int bnx2x_del_all_vlans(struct bnx2x *bp)\n{\n\tstruct bnx2x_vlan_mac_obj *vlan_obj = &bp->sp_objs[0].vlan_obj;\n\tunsigned long ramrod_flags = 0, vlan_flags = 0;\n\tint rc;\n\n\t__set_bit(RAMROD_COMP_WAIT, &ramrod_flags);\n\t__set_bit(BNX2X_VLAN, &vlan_flags);\n\trc = vlan_obj->delete_all(bp, vlan_obj, &vlan_flags, &ramrod_flags);\n\tif (rc)\n\t\treturn rc;\n\n\tbnx2x_clear_vlan_info(bp);\n\n\treturn 0;\n}\n\nint bnx2x_del_all_macs(struct bnx2x *bp,\n\t\t       struct bnx2x_vlan_mac_obj *mac_obj,\n\t\t       int mac_type, bool wait_for_comp)\n{\n\tint rc;\n\tunsigned long ramrod_flags = 0, vlan_mac_flags = 0;\n\n\t \n\tif (wait_for_comp)\n\t\t__set_bit(RAMROD_COMP_WAIT, &ramrod_flags);\n\n\t \n\t__set_bit(mac_type, &vlan_mac_flags);\n\n\trc = mac_obj->delete_all(bp, mac_obj, &vlan_mac_flags, &ramrod_flags);\n\tif (rc < 0)\n\t\tBNX2X_ERR(\"Failed to delete MACs: %d\\n\", rc);\n\n\treturn rc;\n}\n\nint bnx2x_set_eth_mac(struct bnx2x *bp, bool set)\n{\n\tif (IS_PF(bp)) {\n\t\tunsigned long ramrod_flags = 0;\n\n\t\tDP(NETIF_MSG_IFUP, \"Adding Eth MAC\\n\");\n\t\t__set_bit(RAMROD_COMP_WAIT, &ramrod_flags);\n\t\treturn bnx2x_set_mac_one(bp, bp->dev->dev_addr,\n\t\t\t\t\t &bp->sp_objs->mac_obj, set,\n\t\t\t\t\t BNX2X_ETH_MAC, &ramrod_flags);\n\t} else {  \n\t\treturn bnx2x_vfpf_config_mac(bp, bp->dev->dev_addr,\n\t\t\t\t\t     bp->fp->index, set);\n\t}\n}\n\nint bnx2x_setup_leading(struct bnx2x *bp)\n{\n\tif (IS_PF(bp))\n\t\treturn bnx2x_setup_queue(bp, &bp->fp[0], true);\n\telse  \n\t\treturn bnx2x_vfpf_setup_q(bp, &bp->fp[0], true);\n}\n\n \nint bnx2x_set_int_mode(struct bnx2x *bp)\n{\n\tint rc = 0;\n\n\tif (IS_VF(bp) && int_mode != BNX2X_INT_MODE_MSIX) {\n\t\tBNX2X_ERR(\"VF not loaded since interrupt mode not msix\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (int_mode) {\n\tcase BNX2X_INT_MODE_MSIX:\n\t\t \n\t\trc = bnx2x_enable_msix(bp);\n\n\t\t \n\t\tif (!rc)\n\t\t\treturn 0;\n\n\t\t \n\t\tif (rc && IS_VF(bp))\n\t\t\treturn rc;\n\n\t\t \n\t\tBNX2X_DEV_INFO(\"Failed to enable multiple MSI-X (%d), set number of queues to %d\\n\",\n\t\t\t       bp->num_queues,\n\t\t\t       1 + bp->num_cnic_queues);\n\n\t\tfallthrough;\n\tcase BNX2X_INT_MODE_MSI:\n\t\tbnx2x_enable_msi(bp);\n\n\t\tfallthrough;\n\tcase BNX2X_INT_MODE_INTX:\n\t\tbp->num_ethernet_queues = 1;\n\t\tbp->num_queues = bp->num_ethernet_queues + bp->num_cnic_queues;\n\t\tBNX2X_DEV_INFO(\"set number of queues to 1\\n\");\n\t\tbreak;\n\tdefault:\n\t\tBNX2X_DEV_INFO(\"unknown value in int_mode module parameter\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n \nstatic inline u16 bnx2x_cid_ilt_lines(struct bnx2x *bp)\n{\n\tif (IS_SRIOV(bp))\n\t\treturn (BNX2X_FIRST_VF_CID + BNX2X_VF_CIDS)/ILT_PAGE_CIDS;\n\treturn L2_ILT_LINES(bp);\n}\n\nvoid bnx2x_ilt_set_info(struct bnx2x *bp)\n{\n\tstruct ilt_client_info *ilt_client;\n\tstruct bnx2x_ilt *ilt = BP_ILT(bp);\n\tu16 line = 0;\n\n\tilt->start_line = FUNC_ILT_BASE(BP_FUNC(bp));\n\tDP(BNX2X_MSG_SP, \"ilt starts at line %d\\n\", ilt->start_line);\n\n\t \n\tilt_client = &ilt->clients[ILT_CLIENT_CDU];\n\tilt_client->client_num = ILT_CLIENT_CDU;\n\tilt_client->page_size = CDU_ILT_PAGE_SZ;\n\tilt_client->flags = ILT_CLIENT_SKIP_MEM;\n\tilt_client->start = line;\n\tline += bnx2x_cid_ilt_lines(bp);\n\n\tif (CNIC_SUPPORT(bp))\n\t\tline += CNIC_ILT_LINES;\n\tilt_client->end = line - 1;\n\n\tDP(NETIF_MSG_IFUP, \"ilt client[CDU]: start %d, end %d, psz 0x%x, flags 0x%x, hw psz %d\\n\",\n\t   ilt_client->start,\n\t   ilt_client->end,\n\t   ilt_client->page_size,\n\t   ilt_client->flags,\n\t   ilog2(ilt_client->page_size >> 12));\n\n\t \n\tif (QM_INIT(bp->qm_cid_count)) {\n\t\tilt_client = &ilt->clients[ILT_CLIENT_QM];\n\t\tilt_client->client_num = ILT_CLIENT_QM;\n\t\tilt_client->page_size = QM_ILT_PAGE_SZ;\n\t\tilt_client->flags = 0;\n\t\tilt_client->start = line;\n\n\t\t \n\t\tline += DIV_ROUND_UP(bp->qm_cid_count * QM_QUEUES_PER_FUNC * 4,\n\t\t\t\t\t\t\t QM_ILT_PAGE_SZ);\n\n\t\tilt_client->end = line - 1;\n\n\t\tDP(NETIF_MSG_IFUP,\n\t\t   \"ilt client[QM]: start %d, end %d, psz 0x%x, flags 0x%x, hw psz %d\\n\",\n\t\t   ilt_client->start,\n\t\t   ilt_client->end,\n\t\t   ilt_client->page_size,\n\t\t   ilt_client->flags,\n\t\t   ilog2(ilt_client->page_size >> 12));\n\t}\n\n\tif (CNIC_SUPPORT(bp)) {\n\t\t \n\t\tilt_client = &ilt->clients[ILT_CLIENT_SRC];\n\t\tilt_client->client_num = ILT_CLIENT_SRC;\n\t\tilt_client->page_size = SRC_ILT_PAGE_SZ;\n\t\tilt_client->flags = 0;\n\t\tilt_client->start = line;\n\t\tline += SRC_ILT_LINES;\n\t\tilt_client->end = line - 1;\n\n\t\tDP(NETIF_MSG_IFUP,\n\t\t   \"ilt client[SRC]: start %d, end %d, psz 0x%x, flags 0x%x, hw psz %d\\n\",\n\t\t   ilt_client->start,\n\t\t   ilt_client->end,\n\t\t   ilt_client->page_size,\n\t\t   ilt_client->flags,\n\t\t   ilog2(ilt_client->page_size >> 12));\n\n\t\t \n\t\tilt_client = &ilt->clients[ILT_CLIENT_TM];\n\t\tilt_client->client_num = ILT_CLIENT_TM;\n\t\tilt_client->page_size = TM_ILT_PAGE_SZ;\n\t\tilt_client->flags = 0;\n\t\tilt_client->start = line;\n\t\tline += TM_ILT_LINES;\n\t\tilt_client->end = line - 1;\n\n\t\tDP(NETIF_MSG_IFUP,\n\t\t   \"ilt client[TM]: start %d, end %d, psz 0x%x, flags 0x%x, hw psz %d\\n\",\n\t\t   ilt_client->start,\n\t\t   ilt_client->end,\n\t\t   ilt_client->page_size,\n\t\t   ilt_client->flags,\n\t\t   ilog2(ilt_client->page_size >> 12));\n\t}\n\n\tBUG_ON(line > ILT_MAX_LINES);\n}\n\n \nstatic void bnx2x_pf_q_prep_init(struct bnx2x *bp,\n\tstruct bnx2x_fastpath *fp, struct bnx2x_queue_init_params *init_params)\n{\n\tu8 cos;\n\tint cxt_index, cxt_offset;\n\n\t \n\tif (!IS_FCOE_FP(fp)) {\n\t\t__set_bit(BNX2X_Q_FLG_HC, &init_params->rx.flags);\n\t\t__set_bit(BNX2X_Q_FLG_HC, &init_params->tx.flags);\n\n\t\t \n\t\t__set_bit(BNX2X_Q_FLG_HC_EN, &init_params->rx.flags);\n\t\t__set_bit(BNX2X_Q_FLG_HC_EN, &init_params->tx.flags);\n\n\t\t \n\t\tinit_params->rx.hc_rate = bp->rx_ticks ?\n\t\t\t(1000000 / bp->rx_ticks) : 0;\n\t\tinit_params->tx.hc_rate = bp->tx_ticks ?\n\t\t\t(1000000 / bp->tx_ticks) : 0;\n\n\t\t \n\t\tinit_params->rx.fw_sb_id = init_params->tx.fw_sb_id =\n\t\t\tfp->fw_sb_id;\n\n\t\t \n\t\tinit_params->rx.sb_cq_index = HC_INDEX_ETH_RX_CQ_CONS;\n\t\tinit_params->tx.sb_cq_index = HC_INDEX_ETH_FIRST_TX_CQ_CONS;\n\t}\n\n\t \n\tinit_params->max_cos = fp->max_cos;\n\n\tDP(NETIF_MSG_IFUP, \"fp: %d setting queue params max cos to: %d\\n\",\n\t    fp->index, init_params->max_cos);\n\n\t \n\tfor (cos = FIRST_TX_COS_INDEX; cos < init_params->max_cos; cos++) {\n\t\tcxt_index = fp->txdata_ptr[cos]->cid / ILT_PAGE_CIDS;\n\t\tcxt_offset = fp->txdata_ptr[cos]->cid - (cxt_index *\n\t\t\t\tILT_PAGE_CIDS);\n\t\tinit_params->cxts[cos] =\n\t\t\t&bp->context[cxt_index].vcxt[cxt_offset].eth;\n\t}\n}\n\nstatic int bnx2x_setup_tx_only(struct bnx2x *bp, struct bnx2x_fastpath *fp,\n\t\t\tstruct bnx2x_queue_state_params *q_params,\n\t\t\tstruct bnx2x_queue_setup_tx_only_params *tx_only_params,\n\t\t\tint tx_index, bool leading)\n{\n\tmemset(tx_only_params, 0, sizeof(*tx_only_params));\n\n\t \n\tq_params->cmd = BNX2X_Q_CMD_SETUP_TX_ONLY;\n\n\t \n\ttx_only_params->flags = bnx2x_get_common_flags(bp, fp, false);\n\n\t \n\ttx_only_params->cid_index = tx_index;\n\n\t \n\tbnx2x_pf_q_prep_general(bp, fp, &tx_only_params->gen_params, tx_index);\n\n\t \n\tbnx2x_pf_tx_q_prep(bp, fp, &tx_only_params->txq_params, tx_index);\n\n\tDP(NETIF_MSG_IFUP,\n\t   \"preparing to send tx-only ramrod for connection: cos %d, primary cid %d, cid %d, client id %d, sp-client id %d, flags %lx\\n\",\n\t   tx_index, q_params->q_obj->cids[FIRST_TX_COS_INDEX],\n\t   q_params->q_obj->cids[tx_index], q_params->q_obj->cl_id,\n\t   tx_only_params->gen_params.spcl_id, tx_only_params->flags);\n\n\t \n\treturn bnx2x_queue_state_change(bp, q_params);\n}\n\n \n\nint bnx2x_setup_queue(struct bnx2x *bp, struct bnx2x_fastpath *fp,\n\t\t       bool leading)\n{\n\tstruct bnx2x_queue_state_params q_params = {NULL};\n\tstruct bnx2x_queue_setup_params *setup_params =\n\t\t\t\t\t\t&q_params.params.setup;\n\tstruct bnx2x_queue_setup_tx_only_params *tx_only_params =\n\t\t\t\t\t\t&q_params.params.tx_only;\n\tint rc;\n\tu8 tx_index;\n\n\tDP(NETIF_MSG_IFUP, \"setting up queue %d\\n\", fp->index);\n\n\t \n\tif (!IS_FCOE_FP(fp))\n\t\tbnx2x_ack_sb(bp, fp->igu_sb_id, USTORM_ID, 0,\n\t\t\t     IGU_INT_ENABLE, 0);\n\n\tq_params.q_obj = &bnx2x_sp_obj(bp, fp).q_obj;\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &q_params.ramrod_flags);\n\n\t \n\tbnx2x_pf_q_prep_init(bp, fp, &q_params.params.init);\n\n\t \n\tq_params.cmd = BNX2X_Q_CMD_INIT;\n\n\t \n\trc = bnx2x_queue_state_change(bp, &q_params);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Queue(%d) INIT failed\\n\", fp->index);\n\t\treturn rc;\n\t}\n\n\tDP(NETIF_MSG_IFUP, \"init complete\\n\");\n\n\t \n\tmemset(setup_params, 0, sizeof(*setup_params));\n\n\t \n\tsetup_params->flags = bnx2x_get_q_flags(bp, fp, leading);\n\n\t \n\tbnx2x_pf_q_prep_general(bp, fp, &setup_params->gen_params,\n\t\t\t\tFIRST_TX_COS_INDEX);\n\n\tbnx2x_pf_rx_q_prep(bp, fp, &setup_params->pause_params,\n\t\t\t    &setup_params->rxq_params);\n\n\tbnx2x_pf_tx_q_prep(bp, fp, &setup_params->txq_params,\n\t\t\t   FIRST_TX_COS_INDEX);\n\n\t \n\tq_params.cmd = BNX2X_Q_CMD_SETUP;\n\n\tif (IS_FCOE_FP(fp))\n\t\tbp->fcoe_init = true;\n\n\t \n\trc = bnx2x_queue_state_change(bp, &q_params);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Queue(%d) SETUP failed\\n\", fp->index);\n\t\treturn rc;\n\t}\n\n\t \n\tfor (tx_index = FIRST_TX_ONLY_COS_INDEX;\n\t      tx_index < fp->max_cos;\n\t      tx_index++) {\n\n\t\t \n\t\trc = bnx2x_setup_tx_only(bp, fp, &q_params,\n\t\t\t\t\t  tx_only_params, tx_index, leading);\n\t\tif (rc) {\n\t\t\tBNX2X_ERR(\"Queue(%d.%d) TX_ONLY_SETUP failed\\n\",\n\t\t\t\t  fp->index, tx_index);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\treturn rc;\n}\n\nstatic int bnx2x_stop_queue(struct bnx2x *bp, int index)\n{\n\tstruct bnx2x_fastpath *fp = &bp->fp[index];\n\tstruct bnx2x_fp_txdata *txdata;\n\tstruct bnx2x_queue_state_params q_params = {NULL};\n\tint rc, tx_index;\n\n\tDP(NETIF_MSG_IFDOWN, \"stopping queue %d cid %d\\n\", index, fp->cid);\n\n\tq_params.q_obj = &bnx2x_sp_obj(bp, fp).q_obj;\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &q_params.ramrod_flags);\n\n\t \n\tfor (tx_index = FIRST_TX_ONLY_COS_INDEX;\n\t     tx_index < fp->max_cos;\n\t     tx_index++){\n\n\t\t \n\t\ttxdata = fp->txdata_ptr[tx_index];\n\n\t\tDP(NETIF_MSG_IFDOWN, \"stopping tx-only queue %d\\n\",\n\t\t\t\t\t\t\ttxdata->txq_index);\n\n\t\t \n\t\tq_params.cmd = BNX2X_Q_CMD_TERMINATE;\n\t\tmemset(&q_params.params.terminate, 0,\n\t\t       sizeof(q_params.params.terminate));\n\t\tq_params.params.terminate.cid_index = tx_index;\n\n\t\trc = bnx2x_queue_state_change(bp, &q_params);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\tq_params.cmd = BNX2X_Q_CMD_CFC_DEL;\n\t\tmemset(&q_params.params.cfc_del, 0,\n\t\t       sizeof(q_params.params.cfc_del));\n\t\tq_params.params.cfc_del.cid_index = tx_index;\n\t\trc = bnx2x_queue_state_change(bp, &q_params);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\t \n\t \n\tq_params.cmd = BNX2X_Q_CMD_HALT;\n\trc = bnx2x_queue_state_change(bp, &q_params);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tq_params.cmd = BNX2X_Q_CMD_TERMINATE;\n\tmemset(&q_params.params.terminate, 0,\n\t       sizeof(q_params.params.terminate));\n\tq_params.params.terminate.cid_index = FIRST_TX_COS_INDEX;\n\trc = bnx2x_queue_state_change(bp, &q_params);\n\tif (rc)\n\t\treturn rc;\n\t \n\tq_params.cmd = BNX2X_Q_CMD_CFC_DEL;\n\tmemset(&q_params.params.cfc_del, 0,\n\t       sizeof(q_params.params.cfc_del));\n\tq_params.params.cfc_del.cid_index = FIRST_TX_COS_INDEX;\n\treturn bnx2x_queue_state_change(bp, &q_params);\n}\n\nstatic void bnx2x_reset_func(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tint func = BP_FUNC(bp);\n\tint i;\n\n\t \n\tREG_WR8(bp, BAR_XSTRORM_INTMEM + XSTORM_FUNC_EN_OFFSET(func), 0);\n\tREG_WR8(bp, BAR_CSTRORM_INTMEM + CSTORM_FUNC_EN_OFFSET(func), 0);\n\tREG_WR8(bp, BAR_TSTRORM_INTMEM + TSTORM_FUNC_EN_OFFSET(func), 0);\n\tREG_WR8(bp, BAR_USTRORM_INTMEM + USTORM_FUNC_EN_OFFSET(func), 0);\n\n\t \n\tfor_each_eth_queue(bp, i) {\n\t\tstruct bnx2x_fastpath *fp = &bp->fp[i];\n\t\tREG_WR8(bp, BAR_CSTRORM_INTMEM +\n\t\t\t   CSTORM_STATUS_BLOCK_DATA_STATE_OFFSET(fp->fw_sb_id),\n\t\t\t   SB_DISABLED);\n\t}\n\n\tif (CNIC_LOADED(bp))\n\t\t \n\t\tREG_WR8(bp, BAR_CSTRORM_INTMEM +\n\t\t\tCSTORM_STATUS_BLOCK_DATA_STATE_OFFSET\n\t\t\t(bnx2x_cnic_fw_sb_id(bp)), SB_DISABLED);\n\n\t \n\tREG_WR8(bp, BAR_CSTRORM_INTMEM +\n\t\tCSTORM_SP_STATUS_BLOCK_DATA_STATE_OFFSET(func),\n\t\tSB_DISABLED);\n\n\tfor (i = 0; i < XSTORM_SPQ_DATA_SIZE / 4; i++)\n\t\tREG_WR(bp, BAR_XSTRORM_INTMEM + XSTORM_SPQ_DATA_OFFSET(func),\n\t\t       0);\n\n\t \n\tif (bp->common.int_block == INT_BLOCK_HC) {\n\t\tREG_WR(bp, HC_REG_LEADING_EDGE_0 + port*8, 0);\n\t\tREG_WR(bp, HC_REG_TRAILING_EDGE_0 + port*8, 0);\n\t} else {\n\t\tREG_WR(bp, IGU_REG_LEADING_EDGE_LATCH, 0);\n\t\tREG_WR(bp, IGU_REG_TRAILING_EDGE_LATCH, 0);\n\t}\n\n\tif (CNIC_LOADED(bp)) {\n\t\t \n\t\tREG_WR(bp, TM_REG_EN_LINEAR0_TIMER + port*4, 0);\n\t\t \n\t\tfor (i = 0; i < 200; i++) {\n\t\t\tusleep_range(10000, 20000);\n\t\t\tif (!REG_RD(bp, TM_REG_LIN0_SCAN_ON + port*4))\n\t\t\t\tbreak;\n\t\t}\n\t}\n\t \n\tbnx2x_clear_func_ilt(bp, func);\n\n\t \n\tif (!CHIP_IS_E1x(bp) && BP_VN(bp) == 3) {\n\t\tstruct ilt_client_info ilt_cli;\n\t\t \n\t\tmemset(&ilt_cli, 0, sizeof(struct ilt_client_info));\n\t\tilt_cli.start = 0;\n\t\tilt_cli.end = ILT_NUM_PAGE_ENTRIES - 1;\n\t\tilt_cli.client_num = ILT_CLIENT_TM;\n\n\t\tbnx2x_ilt_boundry_init_op(bp, &ilt_cli, 0, INITOP_CLEAR);\n\t}\n\n\t \n\tif (!CHIP_IS_E1x(bp))\n\t\tbnx2x_pf_disable(bp);\n\n\tbp->dmae_ready = 0;\n}\n\nstatic void bnx2x_reset_port(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tu32 val;\n\n\t \n\tbnx2x__link_reset(bp);\n\n\tREG_WR(bp, NIG_REG_MASK_INTERRUPT_PORT0 + port*4, 0);\n\n\t \n\tREG_WR(bp, NIG_REG_LLH0_BRB1_DRV_MASK + port*4, 0x0);\n\t \n\tREG_WR(bp, (port ? NIG_REG_LLH1_BRB1_NOT_MCP :\n\t\t\t   NIG_REG_LLH0_BRB1_NOT_MCP), 0x0);\n\n\t \n\tREG_WR(bp, MISC_REG_AEU_MASK_ATTN_FUNC_0 + port*4, 0);\n\n\tmsleep(100);\n\t \n\tval = REG_RD(bp, BRB1_REG_PORT_NUM_OCC_BLOCKS_0 + port*4);\n\tif (val)\n\t\tDP(NETIF_MSG_IFDOWN,\n\t\t   \"BRB1 is not empty  %d blocks are occupied\\n\", val);\n\n\t \n}\n\nstatic int bnx2x_reset_hw(struct bnx2x *bp, u32 load_code)\n{\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &func_params.ramrod_flags);\n\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_HW_RESET;\n\n\tfunc_params.params.hw_init.load_phase = load_code;\n\n\treturn bnx2x_func_state_change(bp, &func_params);\n}\n\nstatic int bnx2x_func_stop(struct bnx2x *bp)\n{\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\tint rc;\n\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &func_params.ramrod_flags);\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_STOP;\n\n\t \n\trc = bnx2x_func_state_change(bp, &func_params);\n\tif (rc) {\n#ifdef BNX2X_STOP_ON_ERROR\n\t\treturn rc;\n#else\n\t\tBNX2X_ERR(\"FUNC_STOP ramrod failed. Running a dry transaction\\n\");\n\t\t__set_bit(RAMROD_DRV_CLR_ONLY, &func_params.ramrod_flags);\n\t\treturn bnx2x_func_state_change(bp, &func_params);\n#endif\n\t}\n\n\treturn 0;\n}\n\n \nu32 bnx2x_send_unload_req(struct bnx2x *bp, int unload_mode)\n{\n\tu32 reset_code = 0;\n\tint port = BP_PORT(bp);\n\n\t \n\tif (unload_mode == UNLOAD_NORMAL)\n\t\treset_code = DRV_MSG_CODE_UNLOAD_REQ_WOL_DIS;\n\n\telse if (bp->flags & NO_WOL_FLAG)\n\t\treset_code = DRV_MSG_CODE_UNLOAD_REQ_WOL_MCP;\n\n\telse if (bp->wol) {\n\t\tu32 emac_base = port ? GRCBASE_EMAC1 : GRCBASE_EMAC0;\n\t\tconst u8 *mac_addr = bp->dev->dev_addr;\n\t\tstruct pci_dev *pdev = bp->pdev;\n\t\tu32 val;\n\t\tu16 pmc;\n\n\t\t \n\t\tu8 entry = (BP_VN(bp) + 1)*8;\n\n\t\tval = (mac_addr[0] << 8) | mac_addr[1];\n\t\tEMAC_WR(bp, EMAC_REG_EMAC_MAC_MATCH + entry, val);\n\n\t\tval = (mac_addr[2] << 24) | (mac_addr[3] << 16) |\n\t\t      (mac_addr[4] << 8) | mac_addr[5];\n\t\tEMAC_WR(bp, EMAC_REG_EMAC_MAC_MATCH + entry + 4, val);\n\n\t\t \n\t\tpci_read_config_word(pdev, pdev->pm_cap + PCI_PM_CTRL, &pmc);\n\t\tpmc |= PCI_PM_CTRL_PME_ENABLE | PCI_PM_CTRL_PME_STATUS;\n\t\tpci_write_config_word(pdev, pdev->pm_cap + PCI_PM_CTRL, pmc);\n\n\t\treset_code = DRV_MSG_CODE_UNLOAD_REQ_WOL_EN;\n\n\t} else\n\t\treset_code = DRV_MSG_CODE_UNLOAD_REQ_WOL_DIS;\n\n\t \n\tif (!BP_NOMCP(bp))\n\t\treset_code = bnx2x_fw_command(bp, reset_code, 0);\n\telse {\n\t\tint path = BP_PATH(bp);\n\n\t\tDP(NETIF_MSG_IFDOWN, \"NO MCP - load counts[%d]      %d, %d, %d\\n\",\n\t\t   path, bnx2x_load_count[path][0], bnx2x_load_count[path][1],\n\t\t   bnx2x_load_count[path][2]);\n\t\tbnx2x_load_count[path][0]--;\n\t\tbnx2x_load_count[path][1 + port]--;\n\t\tDP(NETIF_MSG_IFDOWN, \"NO MCP - new load counts[%d]  %d, %d, %d\\n\",\n\t\t   path, bnx2x_load_count[path][0], bnx2x_load_count[path][1],\n\t\t   bnx2x_load_count[path][2]);\n\t\tif (bnx2x_load_count[path][0] == 0)\n\t\t\treset_code = FW_MSG_CODE_DRV_UNLOAD_COMMON;\n\t\telse if (bnx2x_load_count[path][1 + port] == 0)\n\t\t\treset_code = FW_MSG_CODE_DRV_UNLOAD_PORT;\n\t\telse\n\t\t\treset_code = FW_MSG_CODE_DRV_UNLOAD_FUNCTION;\n\t}\n\n\treturn reset_code;\n}\n\n \nvoid bnx2x_send_unload_done(struct bnx2x *bp, bool keep_link)\n{\n\tu32 reset_param = keep_link ? DRV_MSG_CODE_UNLOAD_SKIP_LINK_RESET : 0;\n\n\t \n\tif (!BP_NOMCP(bp))\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_UNLOAD_DONE, reset_param);\n}\n\nstatic int bnx2x_func_wait_started(struct bnx2x *bp)\n{\n\tint tout = 50;\n\tint msix = (bp->flags & USING_MSIX_FLAG) ? 1 : 0;\n\n\tif (!bp->port.pmf)\n\t\treturn 0;\n\n\t \n\n\t \n\tif (msix)\n\t\tsynchronize_irq(bp->msix_table[0].vector);\n\telse\n\t\tsynchronize_irq(bp->pdev->irq);\n\n\tflush_workqueue(bnx2x_wq);\n\tflush_workqueue(bnx2x_iov_wq);\n\n\twhile (bnx2x_func_get_state(bp, &bp->func_obj) !=\n\t\t\t\tBNX2X_F_STATE_STARTED && tout--)\n\t\tmsleep(20);\n\n\tif (bnx2x_func_get_state(bp, &bp->func_obj) !=\n\t\t\t\t\t\tBNX2X_F_STATE_STARTED) {\n#ifdef BNX2X_STOP_ON_ERROR\n\t\tBNX2X_ERR(\"Wrong function state\\n\");\n\t\treturn -EBUSY;\n#else\n\t\t \n\t\tstruct bnx2x_func_state_params func_params = {NULL};\n\n\t\tDP(NETIF_MSG_IFDOWN,\n\t\t   \"Hmmm... Unexpected function state! Forcing STARTED-->TX_STOPPED-->STARTED\\n\");\n\n\t\tfunc_params.f_obj = &bp->func_obj;\n\t\t__set_bit(RAMROD_DRV_CLR_ONLY,\n\t\t\t\t\t&func_params.ramrod_flags);\n\n\t\t \n\t\tfunc_params.cmd = BNX2X_F_CMD_TX_STOP;\n\t\tbnx2x_func_state_change(bp, &func_params);\n\n\t\t \n\t\tfunc_params.cmd = BNX2X_F_CMD_TX_START;\n\t\treturn bnx2x_func_state_change(bp, &func_params);\n#endif\n\t}\n\n\treturn 0;\n}\n\nstatic void bnx2x_disable_ptp(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_TO_HOST :\n\t       NIG_REG_P0_LLH_PTP_TO_HOST, 0x0);\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_PARAM_MASK :\n\t       NIG_REG_P0_LLH_PTP_PARAM_MASK, 0x7FF);\n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_RULE_MASK :\n\t       NIG_REG_P0_LLH_PTP_RULE_MASK, 0x3FFF);\n\tREG_WR(bp, port ? NIG_REG_P1_TLLH_PTP_PARAM_MASK :\n\t       NIG_REG_P0_TLLH_PTP_PARAM_MASK, 0x7FF);\n\tREG_WR(bp, port ? NIG_REG_P1_TLLH_PTP_RULE_MASK :\n\t       NIG_REG_P0_TLLH_PTP_RULE_MASK, 0x3FFF);\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_PTP_EN :\n\t       NIG_REG_P0_PTP_EN, 0x0);\n}\n\n \nstatic void bnx2x_stop_ptp(struct bnx2x *bp)\n{\n\t \n\tcancel_work_sync(&bp->ptp_task);\n\n\tif (bp->ptp_tx_skb) {\n\t\tdev_kfree_skb_any(bp->ptp_tx_skb);\n\t\tbp->ptp_tx_skb = NULL;\n\t}\n\n\t \n\tbnx2x_disable_ptp(bp);\n\n\tDP(BNX2X_MSG_PTP, \"PTP stop ended successfully\\n\");\n}\n\nvoid bnx2x_chip_cleanup(struct bnx2x *bp, int unload_mode, bool keep_link)\n{\n\tint port = BP_PORT(bp);\n\tint i, rc = 0;\n\tu8 cos;\n\tstruct bnx2x_mcast_ramrod_params rparam = {NULL};\n\tu32 reset_code;\n\n\t \n\tfor_each_tx_queue(bp, i) {\n\t\tstruct bnx2x_fastpath *fp = &bp->fp[i];\n\n\t\tfor_each_cos_in_tx_queue(fp, cos)\n\t\t\trc = bnx2x_clean_tx_queue(bp, fp->txdata_ptr[cos]);\n#ifdef BNX2X_STOP_ON_ERROR\n\t\tif (rc)\n\t\t\treturn;\n#endif\n\t}\n\n\t \n\tusleep_range(1000, 2000);\n\n\t \n\trc = bnx2x_del_all_macs(bp, &bp->sp_objs[0].mac_obj, BNX2X_ETH_MAC,\n\t\t\t\tfalse);\n\tif (rc < 0)\n\t\tBNX2X_ERR(\"Failed to delete all ETH macs: %d\\n\", rc);\n\n\t \n\trc = bnx2x_del_all_macs(bp, &bp->sp_objs[0].mac_obj, BNX2X_UC_LIST_MAC,\n\t\t\t\ttrue);\n\tif (rc < 0)\n\t\tBNX2X_ERR(\"Failed to schedule DEL commands for UC MACs list: %d\\n\",\n\t\t\t  rc);\n\n\t \n\tif (!CHIP_IS_E1x(bp)) {\n\t\t \n\t\trc = bnx2x_del_all_vlans(bp);\n\t\tif (rc < 0)\n\t\t\tBNX2X_ERR(\"Failed to delete all VLANs\\n\");\n\t}\n\n\t \n\tif (!CHIP_IS_E1(bp))\n\t\tREG_WR(bp, NIG_REG_LLH0_FUNC_EN + port*8, 0);\n\n\t \n\tnetif_addr_lock_bh(bp->dev);\n\t \n\tif (test_bit(BNX2X_FILTER_RX_MODE_PENDING, &bp->sp_state))\n\t\tset_bit(BNX2X_FILTER_RX_MODE_SCHED, &bp->sp_state);\n\telse if (bp->slowpath)\n\t\tbnx2x_set_storm_rx_mode(bp);\n\n\t \n\trparam.mcast_obj = &bp->mcast_obj;\n\trc = bnx2x_config_mcast(bp, &rparam, BNX2X_MCAST_CMD_DEL);\n\tif (rc < 0)\n\t\tBNX2X_ERR(\"Failed to send DEL multicast command: %d\\n\", rc);\n\n\tnetif_addr_unlock_bh(bp->dev);\n\n\tbnx2x_iov_chip_cleanup(bp);\n\n\t \n\treset_code = bnx2x_send_unload_req(bp, unload_mode);\n\n\t \n\trc = bnx2x_func_wait_started(bp);\n\tif (rc) {\n\t\tBNX2X_ERR(\"bnx2x_func_wait_started failed\\n\");\n#ifdef BNX2X_STOP_ON_ERROR\n\t\treturn;\n#endif\n\t}\n\n\t \n\tfor_each_eth_queue(bp, i)\n\t\tif (bnx2x_stop_queue(bp, i))\n#ifdef BNX2X_STOP_ON_ERROR\n\t\t\treturn;\n#else\n\t\t\tgoto unload_error;\n#endif\n\n\tif (CNIC_LOADED(bp)) {\n\t\tfor_each_cnic_queue(bp, i)\n\t\t\tif (bnx2x_stop_queue(bp, i))\n#ifdef BNX2X_STOP_ON_ERROR\n\t\t\t\treturn;\n#else\n\t\t\t\tgoto unload_error;\n#endif\n\t}\n\n\t \n\tif (!bnx2x_wait_sp_comp(bp, ~0x0UL))\n\t\tBNX2X_ERR(\"Hmmm... Common slow path ramrods got stuck!\\n\");\n\n#ifndef BNX2X_STOP_ON_ERROR\nunload_error:\n#endif\n\trc = bnx2x_func_stop(bp);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Function stop failed!\\n\");\n#ifdef BNX2X_STOP_ON_ERROR\n\t\treturn;\n#endif\n\t}\n\n\t \n\tif (bp->flags & PTP_SUPPORTED) {\n\t\tbnx2x_stop_ptp(bp);\n\t\tif (bp->ptp_clock) {\n\t\t\tptp_clock_unregister(bp->ptp_clock);\n\t\t\tbp->ptp_clock = NULL;\n\t\t}\n\t}\n\n\tif (!bp->nic_stopped) {\n\t\t \n\t\tbnx2x_netif_stop(bp, 1);\n\t\t \n\t\tbnx2x_del_all_napi(bp);\n\t\tif (CNIC_LOADED(bp))\n\t\t\tbnx2x_del_all_napi_cnic(bp);\n\n\t\t \n\t\tbnx2x_free_irq(bp);\n\t\tbp->nic_stopped = true;\n\t}\n\n\t \n\tif (!pci_channel_offline(bp->pdev)) {\n\t\trc = bnx2x_reset_hw(bp, reset_code);\n\t\tif (rc)\n\t\t\tBNX2X_ERR(\"HW_RESET failed\\n\");\n\t}\n\n\t \n\tbnx2x_send_unload_done(bp, keep_link);\n}\n\nvoid bnx2x_disable_close_the_gate(struct bnx2x *bp)\n{\n\tu32 val;\n\n\tDP(NETIF_MSG_IFDOWN, \"Disabling \\\"close the gates\\\"\\n\");\n\n\tif (CHIP_IS_E1(bp)) {\n\t\tint port = BP_PORT(bp);\n\t\tu32 addr = port ? MISC_REG_AEU_MASK_ATTN_FUNC_1 :\n\t\t\tMISC_REG_AEU_MASK_ATTN_FUNC_0;\n\n\t\tval = REG_RD(bp, addr);\n\t\tval &= ~(0x300);\n\t\tREG_WR(bp, addr, val);\n\t} else {\n\t\tval = REG_RD(bp, MISC_REG_AEU_GENERAL_MASK);\n\t\tval &= ~(MISC_AEU_GENERAL_MASK_REG_AEU_PXP_CLOSE_MASK |\n\t\t\t MISC_AEU_GENERAL_MASK_REG_AEU_NIG_CLOSE_MASK);\n\t\tREG_WR(bp, MISC_REG_AEU_GENERAL_MASK, val);\n\t}\n}\n\n \nstatic void bnx2x_set_234_gates(struct bnx2x *bp, bool close)\n{\n\tu32 val;\n\n\t \n\tif (!CHIP_IS_E1(bp)) {\n\t\t \n\t\tREG_WR(bp, PXP_REG_HST_DISCARD_DOORBELLS, !!close);\n\t\t \n\t\tREG_WR(bp, PXP_REG_HST_DISCARD_INTERNAL_WRITES, !!close);\n\t}\n\n\t \n\tif (CHIP_IS_E1x(bp)) {\n\t\t \n\t\tval = REG_RD(bp, HC_REG_CONFIG_1);\n\t\tREG_WR(bp, HC_REG_CONFIG_1,\n\t\t       (!close) ? (val | HC_CONFIG_1_REG_BLOCK_DISABLE_1) :\n\t\t       (val & ~(u32)HC_CONFIG_1_REG_BLOCK_DISABLE_1));\n\n\t\tval = REG_RD(bp, HC_REG_CONFIG_0);\n\t\tREG_WR(bp, HC_REG_CONFIG_0,\n\t\t       (!close) ? (val | HC_CONFIG_0_REG_BLOCK_DISABLE_0) :\n\t\t       (val & ~(u32)HC_CONFIG_0_REG_BLOCK_DISABLE_0));\n\t} else {\n\t\t \n\t\tval = REG_RD(bp, IGU_REG_BLOCK_CONFIGURATION);\n\n\t\tREG_WR(bp, IGU_REG_BLOCK_CONFIGURATION,\n\t\t       (!close) ?\n\t\t       (val | IGU_BLOCK_CONFIGURATION_REG_BLOCK_ENABLE) :\n\t\t       (val & ~(u32)IGU_BLOCK_CONFIGURATION_REG_BLOCK_ENABLE));\n\t}\n\n\tDP(NETIF_MSG_HW | NETIF_MSG_IFUP, \"%s gates #2, #3 and #4\\n\",\n\t\tclose ? \"closing\" : \"opening\");\n}\n\n#define SHARED_MF_CLP_MAGIC  0x80000000  \n\nstatic void bnx2x_clp_reset_prep(struct bnx2x *bp, u32 *magic_val)\n{\n\t \n\tu32 val = MF_CFG_RD(bp, shared_mf_config.clp_mb);\n\t*magic_val = val & SHARED_MF_CLP_MAGIC;\n\tMF_CFG_WR(bp, shared_mf_config.clp_mb, val | SHARED_MF_CLP_MAGIC);\n}\n\n \nstatic void bnx2x_clp_reset_done(struct bnx2x *bp, u32 magic_val)\n{\n\t \n\tu32 val = MF_CFG_RD(bp, shared_mf_config.clp_mb);\n\tMF_CFG_WR(bp, shared_mf_config.clp_mb,\n\t\t(val & (~SHARED_MF_CLP_MAGIC)) | magic_val);\n}\n\n \nstatic void bnx2x_reset_mcp_prep(struct bnx2x *bp, u32 *magic_val)\n{\n\tu32 shmem;\n\tu32 validity_offset;\n\n\tDP(NETIF_MSG_HW | NETIF_MSG_IFUP, \"Starting\\n\");\n\n\t \n\tif (!CHIP_IS_E1(bp))\n\t\tbnx2x_clp_reset_prep(bp, magic_val);\n\n\t \n\tshmem = REG_RD(bp, MISC_REG_SHARED_MEM_ADDR);\n\tvalidity_offset =\n\t\toffsetof(struct shmem_region, validity_map[BP_PORT(bp)]);\n\n\t \n\tif (shmem > 0)\n\t\tREG_WR(bp, shmem + validity_offset, 0);\n}\n\n#define MCP_TIMEOUT      5000    \n#define MCP_ONE_TIMEOUT  100     \n\n \nstatic void bnx2x_mcp_wait_one(struct bnx2x *bp)\n{\n\t \n\tif (CHIP_REV_IS_SLOW(bp))\n\t\tmsleep(MCP_ONE_TIMEOUT*10);\n\telse\n\t\tmsleep(MCP_ONE_TIMEOUT);\n}\n\n \nstatic int bnx2x_init_shmem(struct bnx2x *bp)\n{\n\tint cnt = 0;\n\tu32 val = 0;\n\n\tdo {\n\t\tbp->common.shmem_base = REG_RD(bp, MISC_REG_SHARED_MEM_ADDR);\n\n\t\t \n\t\tif (bp->common.shmem_base == 0xFFFFFFFF) {\n\t\t\tbp->flags |= NO_MCP_FLAG;\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tif (bp->common.shmem_base) {\n\t\t\tval = SHMEM_RD(bp, validity_map[BP_PORT(bp)]);\n\t\t\tif (val & SHR_MEM_VALIDITY_MB)\n\t\t\t\treturn 0;\n\t\t}\n\n\t\tbnx2x_mcp_wait_one(bp);\n\n\t} while (cnt++ < (MCP_TIMEOUT / MCP_ONE_TIMEOUT));\n\n\tBNX2X_ERR(\"BAD MCP validity signature\\n\");\n\n\treturn -ENODEV;\n}\n\nstatic int bnx2x_reset_mcp_comp(struct bnx2x *bp, u32 magic_val)\n{\n\tint rc = bnx2x_init_shmem(bp);\n\n\t \n\tif (!CHIP_IS_E1(bp))\n\t\tbnx2x_clp_reset_done(bp, magic_val);\n\n\treturn rc;\n}\n\nstatic void bnx2x_pxp_prep(struct bnx2x *bp)\n{\n\tif (!CHIP_IS_E1(bp)) {\n\t\tREG_WR(bp, PXP2_REG_RD_START_INIT, 0);\n\t\tREG_WR(bp, PXP2_REG_RQ_RBC_DONE, 0);\n\t}\n}\n\n \nstatic void bnx2x_process_kill_chip_reset(struct bnx2x *bp, bool global)\n{\n\tu32 not_reset_mask1, reset_mask1, not_reset_mask2, reset_mask2;\n\tu32 global_bits2, stay_reset2;\n\n\t \n\tglobal_bits2 =\n\t\tMISC_REGISTERS_RESET_REG_2_RST_MCP_N_RESET_CMN_CPU |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_MCP_N_RESET_CMN_CORE;\n\n\t \n\tnot_reset_mask1 =\n\t\tMISC_REGISTERS_RESET_REG_1_RST_HC |\n\t\tMISC_REGISTERS_RESET_REG_1_RST_PXPV |\n\t\tMISC_REGISTERS_RESET_REG_1_RST_PXP;\n\n\tnot_reset_mask2 =\n\t\tMISC_REGISTERS_RESET_REG_2_RST_PCI_MDIO |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_EMAC0_HARD_CORE |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_EMAC1_HARD_CORE |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_MISC_CORE |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_RBCN |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_GRC  |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_MCP_N_RESET_REG_HARD_CORE |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_MCP_N_HARD_CORE_RST_B |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_ATC |\n\t\tMISC_REGISTERS_RESET_REG_2_PGLC |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_BMAC0 |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_BMAC1 |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_EMAC0 |\n\t\tMISC_REGISTERS_RESET_REG_2_RST_EMAC1 |\n\t\tMISC_REGISTERS_RESET_REG_2_UMAC0 |\n\t\tMISC_REGISTERS_RESET_REG_2_UMAC1;\n\n\t \n\tstay_reset2 =\n\t\tMISC_REGISTERS_RESET_REG_2_XMAC |\n\t\tMISC_REGISTERS_RESET_REG_2_XMAC_SOFT;\n\n\t \n\treset_mask1 = 0xffffffff;\n\n\tif (CHIP_IS_E1(bp))\n\t\treset_mask2 = 0xffff;\n\telse if (CHIP_IS_E1H(bp))\n\t\treset_mask2 = 0x1ffff;\n\telse if (CHIP_IS_E2(bp))\n\t\treset_mask2 = 0xfffff;\n\telse  \n\t\treset_mask2 = 0x3ffffff;\n\n\t \n\tif (!global)\n\t\treset_mask2 &= ~global_bits2;\n\n\t \n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_2_CLEAR,\n\t       reset_mask2 & (~not_reset_mask2));\n\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_CLEAR,\n\t       reset_mask1 & (~not_reset_mask1));\n\n\tbarrier();\n\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_2_SET,\n\t       reset_mask2 & (~stay_reset2));\n\n\tbarrier();\n\n\tREG_WR(bp, GRCBASE_MISC + MISC_REGISTERS_RESET_REG_1_SET, reset_mask1);\n}\n\n \nstatic int bnx2x_er_poll_igu_vq(struct bnx2x *bp)\n{\n\tu32 cnt = 1000;\n\tu32 pend_bits = 0;\n\n\tdo {\n\t\tpend_bits  = REG_RD(bp, IGU_REG_PENDING_BITS_STATUS);\n\n\t\tif (pend_bits == 0)\n\t\t\tbreak;\n\n\t\tusleep_range(1000, 2000);\n\t} while (cnt-- > 0);\n\n\tif (cnt <= 0) {\n\t\tBNX2X_ERR(\"Still pending IGU requests pend_bits=%x!\\n\",\n\t\t\t  pend_bits);\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\nstatic int bnx2x_process_kill(struct bnx2x *bp, bool global)\n{\n\tint cnt = 1000;\n\tu32 val = 0;\n\tu32 sr_cnt, blk_cnt, port_is_idle_0, port_is_idle_1, pgl_exp_rom2;\n\tu32 tags_63_32 = 0;\n\n\t \n\tdo {\n\t\tsr_cnt  = REG_RD(bp, PXP2_REG_RD_SR_CNT);\n\t\tblk_cnt = REG_RD(bp, PXP2_REG_RD_BLK_CNT);\n\t\tport_is_idle_0 = REG_RD(bp, PXP2_REG_RD_PORT_IS_IDLE_0);\n\t\tport_is_idle_1 = REG_RD(bp, PXP2_REG_RD_PORT_IS_IDLE_1);\n\t\tpgl_exp_rom2 = REG_RD(bp, PXP2_REG_PGL_EXP_ROM2);\n\t\tif (CHIP_IS_E3(bp))\n\t\t\ttags_63_32 = REG_RD(bp, PGLUE_B_REG_TAGS_63_32);\n\n\t\tif ((sr_cnt == 0x7e) && (blk_cnt == 0xa0) &&\n\t\t    ((port_is_idle_0 & 0x1) == 0x1) &&\n\t\t    ((port_is_idle_1 & 0x1) == 0x1) &&\n\t\t    (pgl_exp_rom2 == 0xffffffff) &&\n\t\t    (!CHIP_IS_E3(bp) || (tags_63_32 == 0xffffffff)))\n\t\t\tbreak;\n\t\tusleep_range(1000, 2000);\n\t} while (cnt-- > 0);\n\n\tif (cnt <= 0) {\n\t\tBNX2X_ERR(\"Tetris buffer didn't get empty or there are still outstanding read requests after 1s!\\n\");\n\t\tBNX2X_ERR(\"sr_cnt=0x%08x, blk_cnt=0x%08x, port_is_idle_0=0x%08x, port_is_idle_1=0x%08x, pgl_exp_rom2=0x%08x\\n\",\n\t\t\t  sr_cnt, blk_cnt, port_is_idle_0, port_is_idle_1,\n\t\t\t  pgl_exp_rom2);\n\t\treturn -EAGAIN;\n\t}\n\n\tbarrier();\n\n\t \n\tbnx2x_set_234_gates(bp, true);\n\n\t \n\tif (!CHIP_IS_E1x(bp) && bnx2x_er_poll_igu_vq(bp))\n\t\treturn -EAGAIN;\n\n\t \n\n\t \n\tREG_WR(bp, MISC_REG_UNPREPARED, 0);\n\tbarrier();\n\n\t \n\tusleep_range(1000, 2000);\n\n\t \n\t \n\tif (global)\n\t\tbnx2x_reset_mcp_prep(bp, &val);\n\n\t \n\tbnx2x_pxp_prep(bp);\n\tbarrier();\n\n\t \n\tbnx2x_process_kill_chip_reset(bp, global);\n\tbarrier();\n\n\t \n\tif (!CHIP_IS_E1x(bp))\n\t\tREG_WR(bp, PGLUE_B_REG_LATCHED_ERRORS_CLR, 0x7f);\n\n\t \n\t \n\tif (global && bnx2x_reset_mcp_comp(bp, val))\n\t\treturn -EAGAIN;\n\n\t \n\n\t \n\tbnx2x_set_234_gates(bp, false);\n\n\t \n\n\treturn 0;\n}\n\nstatic int bnx2x_leader_reset(struct bnx2x *bp)\n{\n\tint rc = 0;\n\tbool global = bnx2x_reset_is_global(bp);\n\tu32 load_code;\n\n\t \n\tif (!global && !BP_NOMCP(bp)) {\n\t\tload_code = bnx2x_fw_command(bp, DRV_MSG_CODE_LOAD_REQ,\n\t\t\t\t\t     DRV_MSG_CODE_LOAD_REQ_WITH_LFA);\n\t\tif (!load_code) {\n\t\t\tBNX2X_ERR(\"MCP response failure, aborting\\n\");\n\t\t\trc = -EAGAIN;\n\t\t\tgoto exit_leader_reset;\n\t\t}\n\t\tif ((load_code != FW_MSG_CODE_DRV_LOAD_COMMON_CHIP) &&\n\t\t    (load_code != FW_MSG_CODE_DRV_LOAD_COMMON)) {\n\t\t\tBNX2X_ERR(\"MCP unexpected resp, aborting\\n\");\n\t\t\trc = -EAGAIN;\n\t\t\tgoto exit_leader_reset2;\n\t\t}\n\t\tload_code = bnx2x_fw_command(bp, DRV_MSG_CODE_LOAD_DONE, 0);\n\t\tif (!load_code) {\n\t\t\tBNX2X_ERR(\"MCP response failure, aborting\\n\");\n\t\t\trc = -EAGAIN;\n\t\t\tgoto exit_leader_reset2;\n\t\t}\n\t}\n\n\t \n\tif (bnx2x_process_kill(bp, global)) {\n\t\tBNX2X_ERR(\"Something bad had happen on engine %d! Aii!\\n\",\n\t\t\t  BP_PATH(bp));\n\t\trc = -EAGAIN;\n\t\tgoto exit_leader_reset2;\n\t}\n\n\t \n\tbnx2x_set_reset_done(bp);\n\tif (global)\n\t\tbnx2x_clear_reset_global(bp);\n\nexit_leader_reset2:\n\t \n\tif (!global && !BP_NOMCP(bp)) {\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_UNLOAD_REQ_WOL_MCP, 0);\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_UNLOAD_DONE, 0);\n\t}\nexit_leader_reset:\n\tbp->is_leader = 0;\n\tbnx2x_release_leader_lock(bp);\n\tsmp_mb();\n\treturn rc;\n}\n\nstatic void bnx2x_recovery_failed(struct bnx2x *bp)\n{\n\tnetdev_err(bp->dev, \"Recovery has failed. Power cycle is needed.\\n\");\n\n\t \n\tnetif_device_detach(bp->dev);\n\n\t \n\tbnx2x_set_reset_in_progress(bp);\n\n\t \n\tbnx2x_set_power_state(bp, PCI_D3hot);\n\n\tbp->recovery_state = BNX2X_RECOVERY_FAILED;\n\n\tsmp_mb();\n}\n\n \nstatic void bnx2x_parity_recover(struct bnx2x *bp)\n{\n\tu32 error_recovered, error_unrecovered;\n\tbool is_parity, global = false;\n#ifdef CONFIG_BNX2X_SRIOV\n\tint vf_idx;\n\n\tfor (vf_idx = 0; vf_idx < bp->requested_nr_virtfn; vf_idx++) {\n\t\tstruct bnx2x_virtf *vf = BP_VF(bp, vf_idx);\n\n\t\tif (vf)\n\t\t\tvf->state = VF_LOST;\n\t}\n#endif\n\tDP(NETIF_MSG_HW, \"Handling parity\\n\");\n\twhile (1) {\n\t\tswitch (bp->recovery_state) {\n\t\tcase BNX2X_RECOVERY_INIT:\n\t\t\tDP(NETIF_MSG_HW, \"State is BNX2X_RECOVERY_INIT\\n\");\n\t\t\tis_parity = bnx2x_chk_parity_attn(bp, &global, false);\n\t\t\tWARN_ON(!is_parity);\n\n\t\t\t \n\t\t\tif (bnx2x_trylock_leader_lock(bp)) {\n\t\t\t\tbnx2x_set_reset_in_progress(bp);\n\t\t\t\t \n\n\t\t\t\tif (global)\n\t\t\t\t\tbnx2x_set_reset_global(bp);\n\n\t\t\t\tbp->is_leader = 1;\n\t\t\t}\n\n\t\t\t \n\t\t\t \n\t\t\tif (bnx2x_nic_unload(bp, UNLOAD_RECOVERY, false))\n\t\t\t\treturn;\n\n\t\t\tbp->recovery_state = BNX2X_RECOVERY_WAIT;\n\n\t\t\t \n\t\t\tsmp_mb();\n\t\t\tbreak;\n\n\t\tcase BNX2X_RECOVERY_WAIT:\n\t\t\tDP(NETIF_MSG_HW, \"State is BNX2X_RECOVERY_WAIT\\n\");\n\t\t\tif (bp->is_leader) {\n\t\t\t\tint other_engine = BP_PATH(bp) ? 0 : 1;\n\t\t\t\tbool other_load_status =\n\t\t\t\t\tbnx2x_get_load_status(bp, other_engine);\n\t\t\t\tbool load_status =\n\t\t\t\t\tbnx2x_get_load_status(bp, BP_PATH(bp));\n\t\t\t\tglobal = bnx2x_reset_is_global(bp);\n\n\t\t\t\t \n\t\t\t\tif (load_status ||\n\t\t\t\t    (global && other_load_status)) {\n\t\t\t\t\t \n\t\t\t\t\tschedule_delayed_work(&bp->sp_rtnl_task,\n\t\t\t\t\t\t\t\tHZ/10);\n\t\t\t\t\treturn;\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tif (bnx2x_leader_reset(bp)) {\n\t\t\t\t\t\tbnx2x_recovery_failed(bp);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\t \n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {  \n\t\t\t\tif (!bnx2x_reset_is_done(bp, BP_PATH(bp))) {\n\t\t\t\t\t \n\t\t\t\t\tif (bnx2x_trylock_leader_lock(bp)) {\n\t\t\t\t\t\t \n\t\t\t\t\t\tbp->is_leader = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\n\t\t\t\t\tschedule_delayed_work(&bp->sp_rtnl_task,\n\t\t\t\t\t\t\t\tHZ/10);\n\t\t\t\t\treturn;\n\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tif (bnx2x_reset_is_global(bp)) {\n\t\t\t\t\t\tschedule_delayed_work(\n\t\t\t\t\t\t\t&bp->sp_rtnl_task,\n\t\t\t\t\t\t\tHZ/10);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\terror_recovered =\n\t\t\t\t\t  bp->eth_stats.recoverable_error;\n\t\t\t\t\terror_unrecovered =\n\t\t\t\t\t  bp->eth_stats.unrecoverable_error;\n\t\t\t\t\tbp->recovery_state =\n\t\t\t\t\t\tBNX2X_RECOVERY_NIC_LOADING;\n\t\t\t\t\tif (bnx2x_nic_load(bp, LOAD_NORMAL)) {\n\t\t\t\t\t\terror_unrecovered++;\n\t\t\t\t\t\tnetdev_err(bp->dev,\n\t\t\t\t\t\t\t   \"Recovery failed. Power cycle needed\\n\");\n\t\t\t\t\t\t \n\t\t\t\t\t\tnetif_device_detach(bp->dev);\n\t\t\t\t\t\t \n\t\t\t\t\t\tbnx2x_set_power_state(\n\t\t\t\t\t\t\tbp, PCI_D3hot);\n\t\t\t\t\t\tsmp_mb();\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbp->recovery_state =\n\t\t\t\t\t\t\tBNX2X_RECOVERY_DONE;\n\t\t\t\t\t\terror_recovered++;\n\t\t\t\t\t\tsmp_mb();\n\t\t\t\t\t}\n\t\t\t\t\tbp->eth_stats.recoverable_error =\n\t\t\t\t\t\terror_recovered;\n\t\t\t\t\tbp->eth_stats.unrecoverable_error =\n\t\t\t\t\t\terror_unrecovered;\n\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic int bnx2x_udp_port_update(struct bnx2x *bp)\n{\n\tstruct bnx2x_func_switch_update_params *switch_update_params;\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\tu16 vxlan_port = 0, geneve_port = 0;\n\tint rc;\n\n\tswitch_update_params = &func_params.params.switch_update;\n\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &func_params.ramrod_flags);\n\t__set_bit(RAMROD_RETRY, &func_params.ramrod_flags);\n\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_SWITCH_UPDATE;\n\n\t \n\t__set_bit(BNX2X_F_UPDATE_TUNNEL_CFG_CHNG,\n\t\t  &switch_update_params->changes);\n\n\tif (bp->udp_tunnel_ports[BNX2X_UDP_PORT_GENEVE]) {\n\t\tgeneve_port = bp->udp_tunnel_ports[BNX2X_UDP_PORT_GENEVE];\n\t\tswitch_update_params->geneve_dst_port = geneve_port;\n\t}\n\n\tif (bp->udp_tunnel_ports[BNX2X_UDP_PORT_VXLAN]) {\n\t\tvxlan_port = bp->udp_tunnel_ports[BNX2X_UDP_PORT_VXLAN];\n\t\tswitch_update_params->vxlan_dst_port = vxlan_port;\n\t}\n\n\t \n\t__set_bit(BNX2X_F_UPDATE_TUNNEL_INNER_RSS,\n\t\t  &switch_update_params->changes);\n\n\trc = bnx2x_func_state_change(bp, &func_params);\n\tif (rc)\n\t\tBNX2X_ERR(\"failed to set UDP dst port to %04x %04x (rc = 0x%x)\\n\",\n\t\t\t  vxlan_port, geneve_port, rc);\n\telse\n\t\tDP(BNX2X_MSG_SP,\n\t\t   \"Configured UDP ports: Vxlan [%04x] Geneve [%04x]\\n\",\n\t\t   vxlan_port, geneve_port);\n\n\treturn rc;\n}\n\nstatic int bnx2x_udp_tunnel_sync(struct net_device *netdev, unsigned int table)\n{\n\tstruct bnx2x *bp = netdev_priv(netdev);\n\tstruct udp_tunnel_info ti;\n\n\tudp_tunnel_nic_get_port(netdev, table, 0, &ti);\n\tbp->udp_tunnel_ports[table] = be16_to_cpu(ti.port);\n\n\treturn bnx2x_udp_port_update(bp);\n}\n\nstatic const struct udp_tunnel_nic_info bnx2x_udp_tunnels = {\n\t.sync_table\t= bnx2x_udp_tunnel_sync,\n\t.flags\t\t= UDP_TUNNEL_NIC_INFO_MAY_SLEEP |\n\t\t\t  UDP_TUNNEL_NIC_INFO_OPEN_ONLY,\n\t.tables\t\t= {\n\t\t{ .n_entries = 1, .tunnel_types = UDP_TUNNEL_TYPE_VXLAN,  },\n\t\t{ .n_entries = 1, .tunnel_types = UDP_TUNNEL_TYPE_GENEVE, },\n\t},\n};\n\nstatic int bnx2x_close(struct net_device *dev);\n\n \nstatic void bnx2x_sp_rtnl_task(struct work_struct *work)\n{\n\tstruct bnx2x *bp = container_of(work, struct bnx2x, sp_rtnl_task.work);\n\n\trtnl_lock();\n\n\tif (!netif_running(bp->dev)) {\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n\n\tif (unlikely(bp->recovery_state != BNX2X_RECOVERY_DONE)) {\n#ifdef BNX2X_STOP_ON_ERROR\n\t\tBNX2X_ERR(\"recovery flow called but STOP_ON_ERROR defined so reset not done to allow debug dump,\\n\"\n\t\t\t  \"you will need to reboot when done\\n\");\n\t\tgoto sp_rtnl_not_reset;\n#endif\n\t\t \n\t\tbp->sp_rtnl_state = 0;\n\t\tsmp_mb();\n\n\t\tbnx2x_parity_recover(bp);\n\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_TX_TIMEOUT, &bp->sp_rtnl_state)) {\n#ifdef BNX2X_STOP_ON_ERROR\n\t\tBNX2X_ERR(\"recovery flow called but STOP_ON_ERROR defined so reset not done to allow debug dump,\\n\"\n\t\t\t  \"you will need to reboot when done\\n\");\n\t\tgoto sp_rtnl_not_reset;\n#endif\n\n\t\t \n\t\tbp->sp_rtnl_state = 0;\n\t\tsmp_mb();\n\n\t\t \n\t\tbp->link_vars.link_up = 0;\n\t\tbp->force_link_down = true;\n\t\tnetif_carrier_off(bp->dev);\n\t\tBNX2X_ERR(\"Indicating link is down due to Tx-timeout\\n\");\n\n\t\tbnx2x_nic_unload(bp, UNLOAD_NORMAL, true);\n\t\t \n\t\tif (bnx2x_nic_load(bp, LOAD_NORMAL) == -ENOMEM) {\n\t\t\tbnx2x_nic_unload(bp, UNLOAD_NORMAL, true);\n\t\t\tif (bnx2x_nic_load(bp, LOAD_NORMAL))\n\t\t\t\tBNX2X_ERR(\"Open the NIC fails again!\\n\");\n\t\t}\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n#ifdef BNX2X_STOP_ON_ERROR\nsp_rtnl_not_reset:\n#endif\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_SETUP_TC, &bp->sp_rtnl_state))\n\t\tbnx2x_setup_tc(bp->dev, bp->dcbx_port_params.ets.num_of_cos);\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_AFEX_F_UPDATE, &bp->sp_rtnl_state))\n\t\tbnx2x_after_function_update(bp);\n\t \n\tif (test_and_clear_bit(BNX2X_SP_RTNL_FAN_FAILURE, &bp->sp_rtnl_state)) {\n\t\tDP(NETIF_MSG_HW, \"fan failure detected. Unloading driver\\n\");\n\t\tnetif_device_detach(bp->dev);\n\t\tbnx2x_close(bp->dev);\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_VFPF_MCAST, &bp->sp_rtnl_state)) {\n\t\tDP(BNX2X_MSG_SP,\n\t\t   \"sending set mcast vf pf channel message from rtnl sp-task\\n\");\n\t\tbnx2x_vfpf_set_mcast(bp->dev);\n\t}\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_VFPF_CHANNEL_DOWN,\n\t\t\t       &bp->sp_rtnl_state)){\n\t\tif (netif_carrier_ok(bp->dev)) {\n\t\t\tbnx2x_tx_disable(bp);\n\t\t\tBNX2X_ERR(\"PF indicated channel is not servicable anymore. This means this VF device is no longer operational\\n\");\n\t\t}\n\t}\n\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_RX_MODE, &bp->sp_rtnl_state)) {\n\t\tDP(BNX2X_MSG_SP, \"Handling Rx Mode setting\\n\");\n\t\tbnx2x_set_rx_mode_inner(bp);\n\t}\n\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_HYPERVISOR_VLAN,\n\t\t\t       &bp->sp_rtnl_state))\n\t\tbnx2x_pf_set_vfs_vlan(bp);\n\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_TX_STOP, &bp->sp_rtnl_state)) {\n\t\tbnx2x_dcbx_stop_hw_tx(bp);\n\t\tbnx2x_dcbx_resume_hw_tx(bp);\n\t}\n\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_GET_DRV_VERSION,\n\t\t\t       &bp->sp_rtnl_state))\n\t\tbnx2x_update_mng_version(bp);\n\n\tif (test_and_clear_bit(BNX2X_SP_RTNL_UPDATE_SVID, &bp->sp_rtnl_state))\n\t\tbnx2x_handle_update_svid_cmd(bp);\n\n\t \n\trtnl_unlock();\n\n\t \n\tif (IS_SRIOV(bp) && test_and_clear_bit(BNX2X_SP_RTNL_ENABLE_SRIOV,\n\t\t\t\t\t       &bp->sp_rtnl_state)) {\n\t\tbnx2x_disable_sriov(bp);\n\t\tbnx2x_enable_sriov(bp);\n\t}\n}\n\nstatic void bnx2x_period_task(struct work_struct *work)\n{\n\tstruct bnx2x *bp = container_of(work, struct bnx2x, period_task.work);\n\n\tif (!netif_running(bp->dev))\n\t\tgoto period_task_exit;\n\n\tif (CHIP_REV_IS_SLOW(bp)) {\n\t\tBNX2X_ERR(\"period task called on emulation, ignoring\\n\");\n\t\tgoto period_task_exit;\n\t}\n\n\tbnx2x_acquire_phy_lock(bp);\n\t \n\tsmp_mb();\n\tif (bp->port.pmf) {\n\t\tbnx2x_period_func(&bp->link_params, &bp->link_vars);\n\n\t\t \n\t\tqueue_delayed_work(bnx2x_wq, &bp->period_task, 1*HZ);\n\t}\n\n\tbnx2x_release_phy_lock(bp);\nperiod_task_exit:\n\treturn;\n}\n\n \n\nstatic u32 bnx2x_get_pretend_reg(struct bnx2x *bp)\n{\n\tu32 base = PXP2_REG_PGL_PRETEND_FUNC_F0;\n\tu32 stride = PXP2_REG_PGL_PRETEND_FUNC_F1 - base;\n\treturn base + (BP_ABS_FUNC(bp)) * stride;\n}\n\nstatic bool bnx2x_prev_unload_close_umac(struct bnx2x *bp,\n\t\t\t\t\t u8 port, u32 reset_reg,\n\t\t\t\t\t struct bnx2x_mac_vals *vals)\n{\n\tu32 mask = MISC_REGISTERS_RESET_REG_2_UMAC0 << port;\n\tu32 base_addr;\n\n\tif (!(mask & reset_reg))\n\t\treturn false;\n\n\tBNX2X_DEV_INFO(\"Disable umac Rx %02x\\n\", port);\n\tbase_addr = port ? GRCBASE_UMAC1 : GRCBASE_UMAC0;\n\tvals->umac_addr[port] = base_addr + UMAC_REG_COMMAND_CONFIG;\n\tvals->umac_val[port] = REG_RD(bp, vals->umac_addr[port]);\n\tREG_WR(bp, vals->umac_addr[port], 0);\n\n\treturn true;\n}\n\nstatic void bnx2x_prev_unload_close_mac(struct bnx2x *bp,\n\t\t\t\t\tstruct bnx2x_mac_vals *vals)\n{\n\tu32 val, base_addr, offset, mask, reset_reg;\n\tbool mac_stopped = false;\n\tu8 port = BP_PORT(bp);\n\n\t \n\tmemset(vals, 0, sizeof(*vals));\n\n\treset_reg = REG_RD(bp, MISC_REG_RESET_REG_2);\n\n\tif (!CHIP_IS_E3(bp)) {\n\t\tval = REG_RD(bp, NIG_REG_BMAC0_REGS_OUT_EN + port * 4);\n\t\tmask = MISC_REGISTERS_RESET_REG_2_RST_BMAC0 << port;\n\t\tif ((mask & reset_reg) && val) {\n\t\t\tu32 wb_data[2];\n\t\t\tBNX2X_DEV_INFO(\"Disable bmac Rx\\n\");\n\t\t\tbase_addr = BP_PORT(bp) ? NIG_REG_INGRESS_BMAC1_MEM\n\t\t\t\t\t\t: NIG_REG_INGRESS_BMAC0_MEM;\n\t\t\toffset = CHIP_IS_E2(bp) ? BIGMAC2_REGISTER_BMAC_CONTROL\n\t\t\t\t\t\t: BIGMAC_REGISTER_BMAC_CONTROL;\n\n\t\t\t \n\t\t\twb_data[0] = REG_RD(bp, base_addr + offset);\n\t\t\twb_data[1] = REG_RD(bp, base_addr + offset + 0x4);\n\t\t\tvals->bmac_addr = base_addr + offset;\n\t\t\tvals->bmac_val[0] = wb_data[0];\n\t\t\tvals->bmac_val[1] = wb_data[1];\n\t\t\twb_data[0] &= ~BMAC_CONTROL_RX_ENABLE;\n\t\t\tREG_WR(bp, vals->bmac_addr, wb_data[0]);\n\t\t\tREG_WR(bp, vals->bmac_addr + 0x4, wb_data[1]);\n\t\t}\n\t\tBNX2X_DEV_INFO(\"Disable emac Rx\\n\");\n\t\tvals->emac_addr = NIG_REG_NIG_EMAC0_EN + BP_PORT(bp)*4;\n\t\tvals->emac_val = REG_RD(bp, vals->emac_addr);\n\t\tREG_WR(bp, vals->emac_addr, 0);\n\t\tmac_stopped = true;\n\t} else {\n\t\tif (reset_reg & MISC_REGISTERS_RESET_REG_2_XMAC) {\n\t\t\tBNX2X_DEV_INFO(\"Disable xmac Rx\\n\");\n\t\t\tbase_addr = BP_PORT(bp) ? GRCBASE_XMAC1 : GRCBASE_XMAC0;\n\t\t\tval = REG_RD(bp, base_addr + XMAC_REG_PFC_CTRL_HI);\n\t\t\tREG_WR(bp, base_addr + XMAC_REG_PFC_CTRL_HI,\n\t\t\t       val & ~(1 << 1));\n\t\t\tREG_WR(bp, base_addr + XMAC_REG_PFC_CTRL_HI,\n\t\t\t       val | (1 << 1));\n\t\t\tvals->xmac_addr = base_addr + XMAC_REG_CTRL;\n\t\t\tvals->xmac_val = REG_RD(bp, vals->xmac_addr);\n\t\t\tREG_WR(bp, vals->xmac_addr, 0);\n\t\t\tmac_stopped = true;\n\t\t}\n\n\t\tmac_stopped |= bnx2x_prev_unload_close_umac(bp, 0,\n\t\t\t\t\t\t\t    reset_reg, vals);\n\t\tmac_stopped |= bnx2x_prev_unload_close_umac(bp, 1,\n\t\t\t\t\t\t\t    reset_reg, vals);\n\t}\n\n\tif (mac_stopped)\n\t\tmsleep(20);\n}\n\n#define BNX2X_PREV_UNDI_PROD_ADDR(p) (BAR_TSTRORM_INTMEM + 0x1508 + ((p) << 4))\n#define BNX2X_PREV_UNDI_PROD_ADDR_H(f) (BAR_TSTRORM_INTMEM + \\\n\t\t\t\t\t0x1848 + ((f) << 4))\n#define BNX2X_PREV_UNDI_RCQ(val)\t((val) & 0xffff)\n#define BNX2X_PREV_UNDI_BD(val)\t\t((val) >> 16 & 0xffff)\n#define BNX2X_PREV_UNDI_PROD(rcq, bd)\t((bd) << 16 | (rcq))\n\n#define BCM_5710_UNDI_FW_MF_MAJOR\t(0x07)\n#define BCM_5710_UNDI_FW_MF_MINOR\t(0x08)\n#define BCM_5710_UNDI_FW_MF_VERS\t(0x05)\n\nstatic bool bnx2x_prev_is_after_undi(struct bnx2x *bp)\n{\n\t \n\tif (!(REG_RD(bp, MISC_REG_RESET_REG_1) &\n\t    MISC_REGISTERS_RESET_REG_1_RST_DORQ))\n\t\treturn false;\n\n\tif (REG_RD(bp, DORQ_REG_NORM_CID_OFST) == 0x7) {\n\t\tBNX2X_DEV_INFO(\"UNDI previously loaded\\n\");\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void bnx2x_prev_unload_undi_inc(struct bnx2x *bp, u8 inc)\n{\n\tu16 rcq, bd;\n\tu32 addr, tmp_reg;\n\n\tif (BP_FUNC(bp) < 2)\n\t\taddr = BNX2X_PREV_UNDI_PROD_ADDR(BP_PORT(bp));\n\telse\n\t\taddr = BNX2X_PREV_UNDI_PROD_ADDR_H(BP_FUNC(bp) - 2);\n\n\ttmp_reg = REG_RD(bp, addr);\n\trcq = BNX2X_PREV_UNDI_RCQ(tmp_reg) + inc;\n\tbd = BNX2X_PREV_UNDI_BD(tmp_reg) + inc;\n\n\ttmp_reg = BNX2X_PREV_UNDI_PROD(rcq, bd);\n\tREG_WR(bp, addr, tmp_reg);\n\n\tBNX2X_DEV_INFO(\"UNDI producer [%d/%d][%08x] rings bd -> 0x%04x, rcq -> 0x%04x\\n\",\n\t\t       BP_PORT(bp), BP_FUNC(bp), addr, bd, rcq);\n}\n\nstatic int bnx2x_prev_mcp_done(struct bnx2x *bp)\n{\n\tu32 rc = bnx2x_fw_command(bp, DRV_MSG_CODE_UNLOAD_DONE,\n\t\t\t\t  DRV_MSG_CODE_UNLOAD_SKIP_LINK_RESET);\n\tif (!rc) {\n\t\tBNX2X_ERR(\"MCP response failure, aborting\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\nstatic struct bnx2x_prev_path_list *\n\t\tbnx2x_prev_path_get_entry(struct bnx2x *bp)\n{\n\tstruct bnx2x_prev_path_list *tmp_list;\n\n\tlist_for_each_entry(tmp_list, &bnx2x_prev_list, list)\n\t\tif (PCI_SLOT(bp->pdev->devfn) == tmp_list->slot &&\n\t\t    bp->pdev->bus->number == tmp_list->bus &&\n\t\t    BP_PATH(bp) == tmp_list->path)\n\t\t\treturn tmp_list;\n\n\treturn NULL;\n}\n\nstatic int bnx2x_prev_path_mark_eeh(struct bnx2x *bp)\n{\n\tstruct bnx2x_prev_path_list *tmp_list;\n\tint rc;\n\n\trc = down_interruptible(&bnx2x_prev_sem);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Received %d when tried to take lock\\n\", rc);\n\t\treturn rc;\n\t}\n\n\ttmp_list = bnx2x_prev_path_get_entry(bp);\n\tif (tmp_list) {\n\t\ttmp_list->aer = 1;\n\t\trc = 0;\n\t} else {\n\t\tBNX2X_ERR(\"path %d: Entry does not exist for eeh; Flow occurs before initial insmod is over ?\\n\",\n\t\t\t  BP_PATH(bp));\n\t}\n\n\tup(&bnx2x_prev_sem);\n\n\treturn rc;\n}\n\nstatic bool bnx2x_prev_is_path_marked(struct bnx2x *bp)\n{\n\tstruct bnx2x_prev_path_list *tmp_list;\n\tbool rc = false;\n\n\tif (down_trylock(&bnx2x_prev_sem))\n\t\treturn false;\n\n\ttmp_list = bnx2x_prev_path_get_entry(bp);\n\tif (tmp_list) {\n\t\tif (tmp_list->aer) {\n\t\t\tDP(NETIF_MSG_HW, \"Path %d was marked by AER\\n\",\n\t\t\t   BP_PATH(bp));\n\t\t} else {\n\t\t\trc = true;\n\t\t\tBNX2X_DEV_INFO(\"Path %d was already cleaned from previous drivers\\n\",\n\t\t\t\t       BP_PATH(bp));\n\t\t}\n\t}\n\n\tup(&bnx2x_prev_sem);\n\n\treturn rc;\n}\n\nbool bnx2x_port_after_undi(struct bnx2x *bp)\n{\n\tstruct bnx2x_prev_path_list *entry;\n\tbool val;\n\n\tdown(&bnx2x_prev_sem);\n\n\tentry = bnx2x_prev_path_get_entry(bp);\n\tval = !!(entry && (entry->undi & (1 << BP_PORT(bp))));\n\n\tup(&bnx2x_prev_sem);\n\n\treturn val;\n}\n\nstatic int bnx2x_prev_mark_path(struct bnx2x *bp, bool after_undi)\n{\n\tstruct bnx2x_prev_path_list *tmp_list;\n\tint rc;\n\n\trc = down_interruptible(&bnx2x_prev_sem);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Received %d when tried to take lock\\n\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\ttmp_list = bnx2x_prev_path_get_entry(bp);\n\tif (tmp_list) {\n\t\tif (!tmp_list->aer) {\n\t\t\tBNX2X_ERR(\"Re-Marking the path.\\n\");\n\t\t} else {\n\t\t\tDP(NETIF_MSG_HW, \"Removing AER indication from path %d\\n\",\n\t\t\t   BP_PATH(bp));\n\t\t\ttmp_list->aer = 0;\n\t\t}\n\t\tup(&bnx2x_prev_sem);\n\t\treturn 0;\n\t}\n\tup(&bnx2x_prev_sem);\n\n\t \n\ttmp_list = kmalloc(sizeof(struct bnx2x_prev_path_list), GFP_KERNEL);\n\tif (!tmp_list) {\n\t\tBNX2X_ERR(\"Failed to allocate 'bnx2x_prev_path_list'\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\ttmp_list->bus = bp->pdev->bus->number;\n\ttmp_list->slot = PCI_SLOT(bp->pdev->devfn);\n\ttmp_list->path = BP_PATH(bp);\n\ttmp_list->aer = 0;\n\ttmp_list->undi = after_undi ? (1 << BP_PORT(bp)) : 0;\n\n\trc = down_interruptible(&bnx2x_prev_sem);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Received %d when tried to take lock\\n\", rc);\n\t\tkfree(tmp_list);\n\t} else {\n\t\tDP(NETIF_MSG_HW, \"Marked path [%d] - finished previous unload\\n\",\n\t\t   BP_PATH(bp));\n\t\tlist_add(&tmp_list->list, &bnx2x_prev_list);\n\t\tup(&bnx2x_prev_sem);\n\t}\n\n\treturn rc;\n}\n\nstatic int bnx2x_do_flr(struct bnx2x *bp)\n{\n\tstruct pci_dev *dev = bp->pdev;\n\n\tif (CHIP_IS_E1x(bp)) {\n\t\tBNX2X_DEV_INFO(\"FLR not supported in E1/E1H\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (bp->common.bc_ver < REQ_BC_VER_4_INITIATE_FLR) {\n\t\tBNX2X_ERR(\"FLR not supported by BC_VER: 0x%x\\n\",\n\t\t\t  bp->common.bc_ver);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!pci_wait_for_pending_transaction(dev))\n\t\tdev_err(&dev->dev, \"transaction is not cleared; proceeding with reset anyway\\n\");\n\n\tBNX2X_DEV_INFO(\"Initiating FLR\\n\");\n\tbnx2x_fw_command(bp, DRV_MSG_CODE_INITIATE_FLR, 0);\n\n\treturn 0;\n}\n\nstatic int bnx2x_prev_unload_uncommon(struct bnx2x *bp)\n{\n\tint rc;\n\n\tBNX2X_DEV_INFO(\"Uncommon unload Flow\\n\");\n\n\t \n\tif (bnx2x_prev_is_path_marked(bp))\n\t\treturn bnx2x_prev_mcp_done(bp);\n\n\tBNX2X_DEV_INFO(\"Path is unmarked\\n\");\n\n\t \n\tif (bnx2x_prev_is_after_undi(bp))\n\t\tgoto out;\n\n\t \n\trc = bnx2x_compare_fw_ver(bp, FW_MSG_CODE_DRV_LOAD_FUNCTION, false);\n\n\tif (!rc) {\n\t\t \n\t\tBNX2X_DEV_INFO(\"FW version matches our own. Attempting FLR\\n\");\n\t\trc = bnx2x_do_flr(bp);\n\t}\n\n\tif (!rc) {\n\t\t \n\t\tBNX2X_DEV_INFO(\"FLR successful\\n\");\n\t\treturn 0;\n\t}\n\n\tBNX2X_DEV_INFO(\"Could not FLR\\n\");\n\nout:\n\t \n\trc = bnx2x_prev_mcp_done(bp);\n\tif (!rc)\n\t\trc = BNX2X_PREV_WAIT_NEEDED;\n\n\treturn rc;\n}\n\nstatic int bnx2x_prev_unload_common(struct bnx2x *bp)\n{\n\tu32 reset_reg, tmp_reg = 0, rc;\n\tbool prev_undi = false;\n\tstruct bnx2x_mac_vals mac_vals;\n\n\t \n\tBNX2X_DEV_INFO(\"Common unload Flow\\n\");\n\n\tmemset(&mac_vals, 0, sizeof(mac_vals));\n\n\tif (bnx2x_prev_is_path_marked(bp))\n\t\treturn bnx2x_prev_mcp_done(bp);\n\n\treset_reg = REG_RD(bp, MISC_REG_RESET_REG_1);\n\n\t \n\tif (reset_reg & MISC_REGISTERS_RESET_REG_1_RST_BRB1) {\n\t\tu32 timer_count = 1000;\n\n\t\t \n\t\tbnx2x_prev_unload_close_mac(bp, &mac_vals);\n\n\t\t \n\t\tbnx2x_set_rx_filter(&bp->link_params, 0);\n\t\tbp->link_params.port ^= 1;\n\t\tbnx2x_set_rx_filter(&bp->link_params, 0);\n\t\tbp->link_params.port ^= 1;\n\n\t\t \n\t\tif (bnx2x_prev_is_after_undi(bp)) {\n\t\t\tprev_undi = true;\n\t\t\t \n\t\t\tREG_WR(bp, DORQ_REG_NORM_CID_OFST, 0);\n\t\t\t \n\t\t\tREG_RD(bp, NIG_REG_NIG_INT_STS_CLR_0);\n\t\t}\n\t\tif (!CHIP_IS_E1x(bp))\n\t\t\t \n\t\t\tREG_WR(bp, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, 0);\n\n\t\t \n\t\ttmp_reg = REG_RD(bp, BRB1_REG_NUM_OF_FULL_BLOCKS);\n\t\twhile (timer_count) {\n\t\t\tu32 prev_brb = tmp_reg;\n\n\t\t\ttmp_reg = REG_RD(bp, BRB1_REG_NUM_OF_FULL_BLOCKS);\n\t\t\tif (!tmp_reg)\n\t\t\t\tbreak;\n\n\t\t\tBNX2X_DEV_INFO(\"BRB still has 0x%08x\\n\", tmp_reg);\n\n\t\t\t \n\t\t\tif (prev_brb > tmp_reg)\n\t\t\t\ttimer_count = 1000;\n\t\t\telse\n\t\t\t\ttimer_count--;\n\n\t\t\t \n\t\t\tif (prev_undi)\n\t\t\t\tbnx2x_prev_unload_undi_inc(bp, 1);\n\n\t\t\tudelay(10);\n\t\t}\n\n\t\tif (!timer_count)\n\t\t\tBNX2X_ERR(\"Failed to empty BRB, hope for the best\\n\");\n\t}\n\n\t \n\tbnx2x_reset_common(bp);\n\n\tif (mac_vals.xmac_addr)\n\t\tREG_WR(bp, mac_vals.xmac_addr, mac_vals.xmac_val);\n\tif (mac_vals.umac_addr[0])\n\t\tREG_WR(bp, mac_vals.umac_addr[0], mac_vals.umac_val[0]);\n\tif (mac_vals.umac_addr[1])\n\t\tREG_WR(bp, mac_vals.umac_addr[1], mac_vals.umac_val[1]);\n\tif (mac_vals.emac_addr)\n\t\tREG_WR(bp, mac_vals.emac_addr, mac_vals.emac_val);\n\tif (mac_vals.bmac_addr) {\n\t\tREG_WR(bp, mac_vals.bmac_addr, mac_vals.bmac_val[0]);\n\t\tREG_WR(bp, mac_vals.bmac_addr + 4, mac_vals.bmac_val[1]);\n\t}\n\n\trc = bnx2x_prev_mark_path(bp, prev_undi);\n\tif (rc) {\n\t\tbnx2x_prev_mcp_done(bp);\n\t\treturn rc;\n\t}\n\n\treturn bnx2x_prev_mcp_done(bp);\n}\n\nstatic int bnx2x_prev_unload(struct bnx2x *bp)\n{\n\tint time_counter = 10;\n\tu32 rc, fw, hw_lock_reg, hw_lock_val;\n\tBNX2X_DEV_INFO(\"Entering Previous Unload Flow\\n\");\n\n\t \n\tbnx2x_clean_pglue_errors(bp);\n\n\t \n\thw_lock_reg = (BP_FUNC(bp) <= 5) ?\n\t\t      (MISC_REG_DRIVER_CONTROL_1 + BP_FUNC(bp) * 8) :\n\t\t      (MISC_REG_DRIVER_CONTROL_7 + (BP_FUNC(bp) - 6) * 8);\n\n\thw_lock_val = REG_RD(bp, hw_lock_reg);\n\tif (hw_lock_val) {\n\t\tif (hw_lock_val & HW_LOCK_RESOURCE_NVRAM) {\n\t\t\tBNX2X_DEV_INFO(\"Release Previously held NVRAM lock\\n\");\n\t\t\tREG_WR(bp, MCP_REG_MCPR_NVM_SW_ARB,\n\t\t\t       (MCPR_NVM_SW_ARB_ARB_REQ_CLR1 << BP_PORT(bp)));\n\t\t}\n\n\t\tBNX2X_DEV_INFO(\"Release Previously held hw lock\\n\");\n\t\tREG_WR(bp, hw_lock_reg, 0xffffffff);\n\t} else\n\t\tBNX2X_DEV_INFO(\"No need to release hw/nvram locks\\n\");\n\n\tif (MCPR_ACCESS_LOCK_LOCK & REG_RD(bp, MCP_REG_MCPR_ACCESS_LOCK)) {\n\t\tBNX2X_DEV_INFO(\"Release previously held alr\\n\");\n\t\tbnx2x_release_alr(bp);\n\t}\n\n\tdo {\n\t\tint aer = 0;\n\t\t \n\t\tfw = bnx2x_fw_command(bp, DRV_MSG_CODE_UNLOAD_REQ_WOL_DIS, 0);\n\t\tif (!fw) {\n\t\t\tBNX2X_ERR(\"MCP response failure, aborting\\n\");\n\t\t\trc = -EBUSY;\n\t\t\tbreak;\n\t\t}\n\n\t\trc = down_interruptible(&bnx2x_prev_sem);\n\t\tif (rc) {\n\t\t\tBNX2X_ERR(\"Cannot check for AER; Received %d when tried to take lock\\n\",\n\t\t\t\t  rc);\n\t\t} else {\n\t\t\t \n\t\t\taer = !!(bnx2x_prev_path_get_entry(bp) &&\n\t\t\t\t bnx2x_prev_path_get_entry(bp)->aer);\n\t\t\tup(&bnx2x_prev_sem);\n\t\t}\n\n\t\tif (fw == FW_MSG_CODE_DRV_UNLOAD_COMMON || aer) {\n\t\t\trc = bnx2x_prev_unload_common(bp);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\trc = bnx2x_prev_unload_uncommon(bp);\n\t\tif (rc != BNX2X_PREV_WAIT_NEEDED)\n\t\t\tbreak;\n\n\t\tmsleep(20);\n\t} while (--time_counter);\n\n\tif (!time_counter || rc) {\n\t\tBNX2X_DEV_INFO(\"Unloading previous driver did not occur, Possibly due to MF UNDI\\n\");\n\t\trc = -EPROBE_DEFER;\n\t}\n\n\t \n\tif (bnx2x_port_after_undi(bp))\n\t\tbp->link_params.feature_config_flags |=\n\t\t\tFEATURE_CONFIG_BOOT_FROM_SAN;\n\n\tBNX2X_DEV_INFO(\"Finished Previous Unload Flow [%d]\\n\", rc);\n\n\treturn rc;\n}\n\nstatic void bnx2x_get_common_hwinfo(struct bnx2x *bp)\n{\n\tu32 val, val2, val3, val4, id, boot_mode;\n\tu16 pmc;\n\n\t \n\t \n\tval = REG_RD(bp, MISC_REG_CHIP_NUM);\n\tid = ((val & 0xffff) << 16);\n\tval = REG_RD(bp, MISC_REG_CHIP_REV);\n\tid |= ((val & 0xf) << 12);\n\n\t \n\tval = REG_RD(bp, PCICFG_OFFSET + PCI_ID_VAL3);\n\tid |= (((val >> 24) & 0xf) << 4);\n\tval = REG_RD(bp, MISC_REG_BOND_ID);\n\tid |= (val & 0xf);\n\tbp->common.chip_id = id;\n\n\t \n\tif (REG_RD(bp, MISC_REG_CHIP_TYPE) & MISC_REG_CHIP_TYPE_57811_MASK) {\n\t\tif (CHIP_IS_57810(bp))\n\t\t\tbp->common.chip_id = (CHIP_NUM_57811 << 16) |\n\t\t\t\t(bp->common.chip_id & 0x0000FFFF);\n\t\telse if (CHIP_IS_57810_MF(bp))\n\t\t\tbp->common.chip_id = (CHIP_NUM_57811_MF << 16) |\n\t\t\t\t(bp->common.chip_id & 0x0000FFFF);\n\t\tbp->common.chip_id |= 0x1;\n\t}\n\n\t \n\tbp->db_size = (1 << BNX2X_DB_SHIFT);\n\n\tif (!CHIP_IS_E1x(bp)) {\n\t\tval = REG_RD(bp, MISC_REG_PORT4MODE_EN_OVWR);\n\t\tif ((val & 1) == 0)\n\t\t\tval = REG_RD(bp, MISC_REG_PORT4MODE_EN);\n\t\telse\n\t\t\tval = (val >> 1) & 1;\n\t\tBNX2X_DEV_INFO(\"chip is in %s\\n\", val ? \"4_PORT_MODE\" :\n\t\t\t\t\t\t       \"2_PORT_MODE\");\n\t\tbp->common.chip_port_mode = val ? CHIP_4_PORT_MODE :\n\t\t\t\t\t\t CHIP_2_PORT_MODE;\n\n\t\tif (CHIP_MODE_IS_4_PORT(bp))\n\t\t\tbp->pfid = (bp->pf_num >> 1);\t \n\t\telse\n\t\t\tbp->pfid = (bp->pf_num & 0x6);\t \n\t} else {\n\t\tbp->common.chip_port_mode = CHIP_PORT_MODE_NONE;  \n\t\tbp->pfid = bp->pf_num;\t\t\t \n\t}\n\n\tBNX2X_DEV_INFO(\"pf_id: %x\", bp->pfid);\n\n\tbp->link_params.chip_id = bp->common.chip_id;\n\tBNX2X_DEV_INFO(\"chip ID is 0x%x\\n\", id);\n\n\tval = (REG_RD(bp, 0x2874) & 0x55);\n\tif ((bp->common.chip_id & 0x1) ||\n\t    (CHIP_IS_E1(bp) && val) || (CHIP_IS_E1H(bp) && (val == 0x55))) {\n\t\tbp->flags |= ONE_PORT_FLAG;\n\t\tBNX2X_DEV_INFO(\"single port device\\n\");\n\t}\n\n\tval = REG_RD(bp, MCP_REG_MCPR_NVM_CFG4);\n\tbp->common.flash_size = (BNX2X_NVRAM_1MB_SIZE <<\n\t\t\t\t (val & MCPR_NVM_CFG4_FLASH_SIZE));\n\tBNX2X_DEV_INFO(\"flash_size 0x%x (%d)\\n\",\n\t\t       bp->common.flash_size, bp->common.flash_size);\n\n\tbnx2x_init_shmem(bp);\n\n\tbp->common.shmem2_base = REG_RD(bp, (BP_PATH(bp) ?\n\t\t\t\t\tMISC_REG_GENERIC_CR_1 :\n\t\t\t\t\tMISC_REG_GENERIC_CR_0));\n\n\tbp->link_params.shmem_base = bp->common.shmem_base;\n\tbp->link_params.shmem2_base = bp->common.shmem2_base;\n\tif (SHMEM2_RD(bp, size) >\n\t    (u32)offsetof(struct shmem2_region, lfa_host_addr[BP_PORT(bp)]))\n\t\tbp->link_params.lfa_base =\n\t\tREG_RD(bp, bp->common.shmem2_base +\n\t\t       (u32)offsetof(struct shmem2_region,\n\t\t\t\t     lfa_host_addr[BP_PORT(bp)]));\n\telse\n\t\tbp->link_params.lfa_base = 0;\n\tBNX2X_DEV_INFO(\"shmem offset 0x%x  shmem2 offset 0x%x\\n\",\n\t\t       bp->common.shmem_base, bp->common.shmem2_base);\n\n\tif (!bp->common.shmem_base) {\n\t\tBNX2X_DEV_INFO(\"MCP not active\\n\");\n\t\tbp->flags |= NO_MCP_FLAG;\n\t\treturn;\n\t}\n\n\tbp->common.hw_config = SHMEM_RD(bp, dev_info.shared_hw_config.config);\n\tBNX2X_DEV_INFO(\"hw_config 0x%08x\\n\", bp->common.hw_config);\n\n\tbp->link_params.hw_led_mode = ((bp->common.hw_config &\n\t\t\t\t\tSHARED_HW_CFG_LED_MODE_MASK) >>\n\t\t\t\t       SHARED_HW_CFG_LED_MODE_SHIFT);\n\n\tbp->link_params.feature_config_flags = 0;\n\tval = SHMEM_RD(bp, dev_info.shared_feature_config.config);\n\tif (val & SHARED_FEAT_CFG_OVERRIDE_PREEMPHASIS_CFG_ENABLED)\n\t\tbp->link_params.feature_config_flags |=\n\t\t\t\tFEATURE_CONFIG_OVERRIDE_PREEMPHASIS_ENABLED;\n\telse\n\t\tbp->link_params.feature_config_flags &=\n\t\t\t\t~FEATURE_CONFIG_OVERRIDE_PREEMPHASIS_ENABLED;\n\n\tval = SHMEM_RD(bp, dev_info.bc_rev) >> 8;\n\tbp->common.bc_ver = val;\n\tBNX2X_DEV_INFO(\"bc_ver %X\\n\", val);\n\tif (val < BNX2X_BC_VER) {\n\t\t \n\t\tBNX2X_ERR(\"This driver needs bc_ver %X but found %X, please upgrade BC\\n\",\n\t\t\t  BNX2X_BC_VER, val);\n\t}\n\tbp->link_params.feature_config_flags |=\n\t\t\t\t(val >= REQ_BC_VER_4_VRFY_FIRST_PHY_OPT_MDL) ?\n\t\t\t\tFEATURE_CONFIG_BC_SUPPORTS_OPT_MDL_VRFY : 0;\n\n\tbp->link_params.feature_config_flags |=\n\t\t(val >= REQ_BC_VER_4_VRFY_SPECIFIC_PHY_OPT_MDL) ?\n\t\tFEATURE_CONFIG_BC_SUPPORTS_DUAL_PHY_OPT_MDL_VRFY : 0;\n\tbp->link_params.feature_config_flags |=\n\t\t(val >= REQ_BC_VER_4_VRFY_AFEX_SUPPORTED) ?\n\t\tFEATURE_CONFIG_BC_SUPPORTS_AFEX : 0;\n\tbp->link_params.feature_config_flags |=\n\t\t(val >= REQ_BC_VER_4_SFP_TX_DISABLE_SUPPORTED) ?\n\t\tFEATURE_CONFIG_BC_SUPPORTS_SFP_TX_DISABLED : 0;\n\n\tbp->link_params.feature_config_flags |=\n\t\t(val >= REQ_BC_VER_4_MT_SUPPORTED) ?\n\t\tFEATURE_CONFIG_MT_SUPPORT : 0;\n\n\tbp->flags |= (val >= REQ_BC_VER_4_PFC_STATS_SUPPORTED) ?\n\t\t\tBC_SUPPORTS_PFC_STATS : 0;\n\n\tbp->flags |= (val >= REQ_BC_VER_4_FCOE_FEATURES) ?\n\t\t\tBC_SUPPORTS_FCOE_FEATURES : 0;\n\n\tbp->flags |= (val >= REQ_BC_VER_4_DCBX_ADMIN_MSG_NON_PMF) ?\n\t\t\tBC_SUPPORTS_DCBX_MSG_NON_PMF : 0;\n\n\tbp->flags |= (val >= REQ_BC_VER_4_RMMOD_CMD) ?\n\t\t\tBC_SUPPORTS_RMMOD_CMD : 0;\n\n\tboot_mode = SHMEM_RD(bp,\n\t\t\tdev_info.port_feature_config[BP_PORT(bp)].mba_config) &\n\t\t\tPORT_FEATURE_MBA_BOOT_AGENT_TYPE_MASK;\n\tswitch (boot_mode) {\n\tcase PORT_FEATURE_MBA_BOOT_AGENT_TYPE_PXE:\n\t\tbp->common.boot_mode = FEATURE_ETH_BOOTMODE_PXE;\n\t\tbreak;\n\tcase PORT_FEATURE_MBA_BOOT_AGENT_TYPE_ISCSIB:\n\t\tbp->common.boot_mode = FEATURE_ETH_BOOTMODE_ISCSI;\n\t\tbreak;\n\tcase PORT_FEATURE_MBA_BOOT_AGENT_TYPE_FCOE_BOOT:\n\t\tbp->common.boot_mode = FEATURE_ETH_BOOTMODE_FCOE;\n\t\tbreak;\n\tcase PORT_FEATURE_MBA_BOOT_AGENT_TYPE_NONE:\n\t\tbp->common.boot_mode = FEATURE_ETH_BOOTMODE_NONE;\n\t\tbreak;\n\t}\n\n\tpci_read_config_word(bp->pdev, bp->pdev->pm_cap + PCI_PM_PMC, &pmc);\n\tbp->flags |= (pmc & PCI_PM_CAP_PME_D3cold) ? 0 : NO_WOL_FLAG;\n\n\tBNX2X_DEV_INFO(\"%sWoL capable\\n\",\n\t\t       (bp->flags & NO_WOL_FLAG) ? \"not \" : \"\");\n\n\tval = SHMEM_RD(bp, dev_info.shared_hw_config.part_num);\n\tval2 = SHMEM_RD(bp, dev_info.shared_hw_config.part_num[4]);\n\tval3 = SHMEM_RD(bp, dev_info.shared_hw_config.part_num[8]);\n\tval4 = SHMEM_RD(bp, dev_info.shared_hw_config.part_num[12]);\n\n\tdev_info(&bp->pdev->dev, \"part number %X-%X-%X-%X\\n\",\n\t\t val, val2, val3, val4);\n}\n\n#define IGU_FID(val)\tGET_FIELD((val), IGU_REG_MAPPING_MEMORY_FID)\n#define IGU_VEC(val)\tGET_FIELD((val), IGU_REG_MAPPING_MEMORY_VECTOR)\n\nstatic int bnx2x_get_igu_cam_info(struct bnx2x *bp)\n{\n\tint pfid = BP_FUNC(bp);\n\tint igu_sb_id;\n\tu32 val;\n\tu8 fid, igu_sb_cnt = 0;\n\n\tbp->igu_base_sb = 0xff;\n\tif (CHIP_INT_MODE_IS_BC(bp)) {\n\t\tint vn = BP_VN(bp);\n\t\tigu_sb_cnt = bp->igu_sb_cnt;\n\t\tbp->igu_base_sb = (CHIP_MODE_IS_4_PORT(bp) ? pfid : vn) *\n\t\t\tFP_SB_MAX_E1x;\n\n\t\tbp->igu_dsb_id =  E1HVN_MAX * FP_SB_MAX_E1x +\n\t\t\t(CHIP_MODE_IS_4_PORT(bp) ? pfid : vn);\n\n\t\treturn 0;\n\t}\n\n\t \n\tfor (igu_sb_id = 0; igu_sb_id < IGU_REG_MAPPING_MEMORY_SIZE;\n\t     igu_sb_id++) {\n\t\tval = REG_RD(bp, IGU_REG_MAPPING_MEMORY + igu_sb_id * 4);\n\t\tif (!(val & IGU_REG_MAPPING_MEMORY_VALID))\n\t\t\tcontinue;\n\t\tfid = IGU_FID(val);\n\t\tif ((fid & IGU_FID_ENCODE_IS_PF)) {\n\t\t\tif ((fid & IGU_FID_PF_NUM_MASK) != pfid)\n\t\t\t\tcontinue;\n\t\t\tif (IGU_VEC(val) == 0)\n\t\t\t\t \n\t\t\t\tbp->igu_dsb_id = igu_sb_id;\n\t\t\telse {\n\t\t\t\tif (bp->igu_base_sb == 0xff)\n\t\t\t\t\tbp->igu_base_sb = igu_sb_id;\n\t\t\t\tigu_sb_cnt++;\n\t\t\t}\n\t\t}\n\t}\n\n#ifdef CONFIG_PCI_MSI\n\t \n\tbp->igu_sb_cnt = min_t(int, bp->igu_sb_cnt, igu_sb_cnt);\n#endif\n\n\tif (igu_sb_cnt == 0) {\n\t\tBNX2X_ERR(\"CAM configuration error\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void bnx2x_link_settings_supported(struct bnx2x *bp, u32 switch_cfg)\n{\n\tint cfg_size = 0, idx, port = BP_PORT(bp);\n\n\t \n\tbp->port.supported[0] = 0;\n\tbp->port.supported[1] = 0;\n\tswitch (bp->link_params.num_phys) {\n\tcase 1:\n\t\tbp->port.supported[0] = bp->link_params.phy[INT_PHY].supported;\n\t\tcfg_size = 1;\n\t\tbreak;\n\tcase 2:\n\t\tbp->port.supported[0] = bp->link_params.phy[EXT_PHY1].supported;\n\t\tcfg_size = 1;\n\t\tbreak;\n\tcase 3:\n\t\tif (bp->link_params.multi_phy_config &\n\t\t    PORT_HW_CFG_PHY_SWAPPED_ENABLED) {\n\t\t\tbp->port.supported[1] =\n\t\t\t\tbp->link_params.phy[EXT_PHY1].supported;\n\t\t\tbp->port.supported[0] =\n\t\t\t\tbp->link_params.phy[EXT_PHY2].supported;\n\t\t} else {\n\t\t\tbp->port.supported[0] =\n\t\t\t\tbp->link_params.phy[EXT_PHY1].supported;\n\t\t\tbp->port.supported[1] =\n\t\t\t\tbp->link_params.phy[EXT_PHY2].supported;\n\t\t}\n\t\tcfg_size = 2;\n\t\tbreak;\n\t}\n\n\tif (!(bp->port.supported[0] || bp->port.supported[1])) {\n\t\tBNX2X_ERR(\"NVRAM config error. BAD phy config. PHY1 config 0x%x, PHY2 config 0x%x\\n\",\n\t\t\t   SHMEM_RD(bp,\n\t\t\t   dev_info.port_hw_config[port].external_phy_config),\n\t\t\t   SHMEM_RD(bp,\n\t\t\t   dev_info.port_hw_config[port].external_phy_config2));\n\t\treturn;\n\t}\n\n\tif (CHIP_IS_E3(bp))\n\t\tbp->port.phy_addr = REG_RD(bp, MISC_REG_WC0_CTRL_PHY_ADDR);\n\telse {\n\t\tswitch (switch_cfg) {\n\t\tcase SWITCH_CFG_1G:\n\t\t\tbp->port.phy_addr = REG_RD(\n\t\t\t\tbp, NIG_REG_SERDES0_CTRL_PHY_ADDR + port*0x10);\n\t\t\tbreak;\n\t\tcase SWITCH_CFG_10G:\n\t\t\tbp->port.phy_addr = REG_RD(\n\t\t\t\tbp, NIG_REG_XGXS0_CTRL_PHY_ADDR + port*0x18);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBNX2X_ERR(\"BAD switch_cfg link_config 0x%x\\n\",\n\t\t\t\t  bp->port.link_config[0]);\n\t\t\treturn;\n\t\t}\n\t}\n\tBNX2X_DEV_INFO(\"phy_addr 0x%x\\n\", bp->port.phy_addr);\n\t \n\tfor (idx = 0; idx < cfg_size; idx++) {\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_10M_HALF))\n\t\t\tbp->port.supported[idx] &= ~SUPPORTED_10baseT_Half;\n\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_10M_FULL))\n\t\t\tbp->port.supported[idx] &= ~SUPPORTED_10baseT_Full;\n\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_100M_HALF))\n\t\t\tbp->port.supported[idx] &= ~SUPPORTED_100baseT_Half;\n\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_100M_FULL))\n\t\t\tbp->port.supported[idx] &= ~SUPPORTED_100baseT_Full;\n\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_1G))\n\t\t\tbp->port.supported[idx] &= ~(SUPPORTED_1000baseT_Half |\n\t\t\t\t\t\t     SUPPORTED_1000baseT_Full);\n\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_2_5G))\n\t\t\tbp->port.supported[idx] &= ~SUPPORTED_2500baseX_Full;\n\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_10G))\n\t\t\tbp->port.supported[idx] &= ~SUPPORTED_10000baseT_Full;\n\n\t\tif (!(bp->link_params.speed_cap_mask[idx] &\n\t\t\t\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_20G))\n\t\t\tbp->port.supported[idx] &= ~SUPPORTED_20000baseKR2_Full;\n\t}\n\n\tBNX2X_DEV_INFO(\"supported 0x%x 0x%x\\n\", bp->port.supported[0],\n\t\t       bp->port.supported[1]);\n}\n\nstatic void bnx2x_link_settings_requested(struct bnx2x *bp)\n{\n\tu32 link_config, idx, cfg_size = 0;\n\tbp->port.advertising[0] = 0;\n\tbp->port.advertising[1] = 0;\n\tswitch (bp->link_params.num_phys) {\n\tcase 1:\n\tcase 2:\n\t\tcfg_size = 1;\n\t\tbreak;\n\tcase 3:\n\t\tcfg_size = 2;\n\t\tbreak;\n\t}\n\tfor (idx = 0; idx < cfg_size; idx++) {\n\t\tbp->link_params.req_duplex[idx] = DUPLEX_FULL;\n\t\tlink_config = bp->port.link_config[idx];\n\t\tswitch (link_config & PORT_FEATURE_LINK_SPEED_MASK) {\n\t\tcase PORT_FEATURE_LINK_SPEED_AUTO:\n\t\t\tif (bp->port.supported[idx] & SUPPORTED_Autoneg) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_AUTO_NEG;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\tbp->port.supported[idx];\n\t\t\t\tif (bp->link_params.phy[EXT_PHY1].type ==\n\t\t\t\t    PORT_HW_CFG_XGXS_EXT_PHY_TYPE_BCM84833)\n\t\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(SUPPORTED_100baseT_Half |\n\t\t\t\t\t SUPPORTED_100baseT_Full);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_10000;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_10000baseT_Full |\n\t\t\t\t\t ADVERTISED_FIBRE);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PORT_FEATURE_LINK_SPEED_10M_FULL:\n\t\t\tif (bp->port.supported[idx] & SUPPORTED_10baseT_Full) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_10;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_10baseT_Full |\n\t\t\t\t\t ADVERTISED_TP);\n\t\t\t} else {\n\t\t\t\tBNX2X_ERR(\"NVRAM config error. Invalid link_config 0x%x  speed_cap_mask 0x%x\\n\",\n\t\t\t\t\t    link_config,\n\t\t\t\t    bp->link_params.speed_cap_mask[idx]);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PORT_FEATURE_LINK_SPEED_10M_HALF:\n\t\t\tif (bp->port.supported[idx] & SUPPORTED_10baseT_Half) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_10;\n\t\t\t\tbp->link_params.req_duplex[idx] =\n\t\t\t\t\tDUPLEX_HALF;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_10baseT_Half |\n\t\t\t\t\t ADVERTISED_TP);\n\t\t\t} else {\n\t\t\t\tBNX2X_ERR(\"NVRAM config error. Invalid link_config 0x%x  speed_cap_mask 0x%x\\n\",\n\t\t\t\t\t    link_config,\n\t\t\t\t\t  bp->link_params.speed_cap_mask[idx]);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PORT_FEATURE_LINK_SPEED_100M_FULL:\n\t\t\tif (bp->port.supported[idx] &\n\t\t\t    SUPPORTED_100baseT_Full) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_100;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_100baseT_Full |\n\t\t\t\t\t ADVERTISED_TP);\n\t\t\t} else {\n\t\t\t\tBNX2X_ERR(\"NVRAM config error. Invalid link_config 0x%x  speed_cap_mask 0x%x\\n\",\n\t\t\t\t\t    link_config,\n\t\t\t\t\t  bp->link_params.speed_cap_mask[idx]);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PORT_FEATURE_LINK_SPEED_100M_HALF:\n\t\t\tif (bp->port.supported[idx] &\n\t\t\t    SUPPORTED_100baseT_Half) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\t\t\t\tSPEED_100;\n\t\t\t\tbp->link_params.req_duplex[idx] =\n\t\t\t\t\t\t\t\tDUPLEX_HALF;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_100baseT_Half |\n\t\t\t\t\t ADVERTISED_TP);\n\t\t\t} else {\n\t\t\t\tBNX2X_ERR(\"NVRAM config error. Invalid link_config 0x%x  speed_cap_mask 0x%x\\n\",\n\t\t\t\t    link_config,\n\t\t\t\t    bp->link_params.speed_cap_mask[idx]);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PORT_FEATURE_LINK_SPEED_1G:\n\t\t\tif (bp->port.supported[idx] &\n\t\t\t    SUPPORTED_1000baseT_Full) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_1000;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_1000baseT_Full |\n\t\t\t\t\t ADVERTISED_TP);\n\t\t\t} else if (bp->port.supported[idx] &\n\t\t\t\t   SUPPORTED_1000baseKX_Full) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_1000;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\tADVERTISED_1000baseKX_Full;\n\t\t\t} else {\n\t\t\t\tBNX2X_ERR(\"NVRAM config error. Invalid link_config 0x%x  speed_cap_mask 0x%x\\n\",\n\t\t\t\t    link_config,\n\t\t\t\t    bp->link_params.speed_cap_mask[idx]);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PORT_FEATURE_LINK_SPEED_2_5G:\n\t\t\tif (bp->port.supported[idx] &\n\t\t\t    SUPPORTED_2500baseX_Full) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_2500;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_2500baseX_Full |\n\t\t\t\t\t\tADVERTISED_TP);\n\t\t\t} else {\n\t\t\t\tBNX2X_ERR(\"NVRAM config error. Invalid link_config 0x%x  speed_cap_mask 0x%x\\n\",\n\t\t\t\t    link_config,\n\t\t\t\t    bp->link_params.speed_cap_mask[idx]);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PORT_FEATURE_LINK_SPEED_10G_CX4:\n\t\t\tif (bp->port.supported[idx] &\n\t\t\t    SUPPORTED_10000baseT_Full) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_10000;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_10000baseT_Full |\n\t\t\t\t\t\tADVERTISED_FIBRE);\n\t\t\t} else if (bp->port.supported[idx] &\n\t\t\t\t   SUPPORTED_10000baseKR_Full) {\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\tSPEED_10000;\n\t\t\t\tbp->port.advertising[idx] |=\n\t\t\t\t\t(ADVERTISED_10000baseKR_Full |\n\t\t\t\t\t\tADVERTISED_FIBRE);\n\t\t\t} else {\n\t\t\t\tBNX2X_ERR(\"NVRAM config error. Invalid link_config 0x%x  speed_cap_mask 0x%x\\n\",\n\t\t\t\t    link_config,\n\t\t\t\t    bp->link_params.speed_cap_mask[idx]);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase PORT_FEATURE_LINK_SPEED_20G:\n\t\t\tbp->link_params.req_line_speed[idx] = SPEED_20000;\n\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBNX2X_ERR(\"NVRAM config error. BAD link speed link_config 0x%x\\n\",\n\t\t\t\t  link_config);\n\t\t\t\tbp->link_params.req_line_speed[idx] =\n\t\t\t\t\t\t\tSPEED_AUTO_NEG;\n\t\t\t\tbp->port.advertising[idx] =\n\t\t\t\t\t\tbp->port.supported[idx];\n\t\t\tbreak;\n\t\t}\n\n\t\tbp->link_params.req_flow_ctrl[idx] = (link_config &\n\t\t\t\t\t PORT_FEATURE_FLOW_CONTROL_MASK);\n\t\tif (bp->link_params.req_flow_ctrl[idx] ==\n\t\t    BNX2X_FLOW_CTRL_AUTO) {\n\t\t\tif (!(bp->port.supported[idx] & SUPPORTED_Autoneg))\n\t\t\t\tbp->link_params.req_flow_ctrl[idx] =\n\t\t\t\t\t\t\tBNX2X_FLOW_CTRL_NONE;\n\t\t\telse\n\t\t\t\tbnx2x_set_requested_fc(bp);\n\t\t}\n\n\t\tBNX2X_DEV_INFO(\"req_line_speed %d  req_duplex %d req_flow_ctrl 0x%x advertising 0x%x\\n\",\n\t\t\t       bp->link_params.req_line_speed[idx],\n\t\t\t       bp->link_params.req_duplex[idx],\n\t\t\t       bp->link_params.req_flow_ctrl[idx],\n\t\t\t       bp->port.advertising[idx]);\n\t}\n}\n\nstatic void bnx2x_set_mac_buf(u8 *mac_buf, u32 mac_lo, u16 mac_hi)\n{\n\t__be16 mac_hi_be = cpu_to_be16(mac_hi);\n\t__be32 mac_lo_be = cpu_to_be32(mac_lo);\n\tmemcpy(mac_buf, &mac_hi_be, sizeof(mac_hi_be));\n\tmemcpy(mac_buf + sizeof(mac_hi_be), &mac_lo_be, sizeof(mac_lo_be));\n}\n\nstatic void bnx2x_get_port_hwinfo(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tu32 config;\n\tu32 ext_phy_type, ext_phy_config, eee_mode;\n\n\tbp->link_params.bp = bp;\n\tbp->link_params.port = port;\n\n\tbp->link_params.lane_config =\n\t\tSHMEM_RD(bp, dev_info.port_hw_config[port].lane_config);\n\n\tbp->link_params.speed_cap_mask[0] =\n\t\tSHMEM_RD(bp,\n\t\t\t dev_info.port_hw_config[port].speed_capability_mask) &\n\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_MASK;\n\tbp->link_params.speed_cap_mask[1] =\n\t\tSHMEM_RD(bp,\n\t\t\t dev_info.port_hw_config[port].speed_capability_mask2) &\n\t\tPORT_HW_CFG_SPEED_CAPABILITY_D0_MASK;\n\tbp->port.link_config[0] =\n\t\tSHMEM_RD(bp, dev_info.port_feature_config[port].link_config);\n\n\tbp->port.link_config[1] =\n\t\tSHMEM_RD(bp, dev_info.port_feature_config[port].link_config2);\n\n\tbp->link_params.multi_phy_config =\n\t\tSHMEM_RD(bp, dev_info.port_hw_config[port].multi_phy_config);\n\t \n\tconfig = SHMEM_RD(bp, dev_info.port_feature_config[port].config);\n\tbp->wol = (!(bp->flags & NO_WOL_FLAG) &&\n\t\t   (config & PORT_FEATURE_WOL_ENABLED));\n\n\tif ((config & PORT_FEAT_CFG_STORAGE_PERSONALITY_MASK) ==\n\t    PORT_FEAT_CFG_STORAGE_PERSONALITY_FCOE && !IS_MF(bp))\n\t\tbp->flags |= NO_ISCSI_FLAG;\n\tif ((config & PORT_FEAT_CFG_STORAGE_PERSONALITY_MASK) ==\n\t    PORT_FEAT_CFG_STORAGE_PERSONALITY_ISCSI && !(IS_MF(bp)))\n\t\tbp->flags |= NO_FCOE_FLAG;\n\n\tBNX2X_DEV_INFO(\"lane_config 0x%08x  speed_cap_mask0 0x%08x  link_config0 0x%08x\\n\",\n\t\t       bp->link_params.lane_config,\n\t\t       bp->link_params.speed_cap_mask[0],\n\t\t       bp->port.link_config[0]);\n\n\tbp->link_params.switch_cfg = (bp->port.link_config[0] &\n\t\t\t\t      PORT_FEATURE_CONNECTED_SWITCH_MASK);\n\tbnx2x_phy_probe(&bp->link_params);\n\tbnx2x_link_settings_supported(bp, bp->link_params.switch_cfg);\n\n\tbnx2x_link_settings_requested(bp);\n\n\t \n\text_phy_config =\n\t\tSHMEM_RD(bp,\n\t\t\t dev_info.port_hw_config[port].external_phy_config);\n\text_phy_type = XGXS_EXT_PHY_TYPE(ext_phy_config);\n\tif (ext_phy_type == PORT_HW_CFG_XGXS_EXT_PHY_TYPE_DIRECT)\n\t\tbp->mdio.prtad = bp->port.phy_addr;\n\n\telse if ((ext_phy_type != PORT_HW_CFG_XGXS_EXT_PHY_TYPE_FAILURE) &&\n\t\t (ext_phy_type != PORT_HW_CFG_XGXS_EXT_PHY_TYPE_NOT_CONN))\n\t\tbp->mdio.prtad =\n\t\t\tXGXS_EXT_PHY_ADDR(ext_phy_config);\n\n\t \n\teee_mode = (((SHMEM_RD(bp, dev_info.\n\t\t      port_feature_config[port].eee_power_mode)) &\n\t\t     PORT_FEAT_CFG_EEE_POWER_MODE_MASK) >>\n\t\t    PORT_FEAT_CFG_EEE_POWER_MODE_SHIFT);\n\tif (eee_mode != PORT_FEAT_CFG_EEE_POWER_MODE_DISABLED) {\n\t\tbp->link_params.eee_mode = EEE_MODE_ADV_LPI |\n\t\t\t\t\t   EEE_MODE_ENABLE_LPI |\n\t\t\t\t\t   EEE_MODE_OUTPUT_TIME;\n\t} else {\n\t\tbp->link_params.eee_mode = 0;\n\t}\n}\n\nvoid bnx2x_get_iscsi_info(struct bnx2x *bp)\n{\n\tu32 no_flags = NO_ISCSI_FLAG;\n\tint port = BP_PORT(bp);\n\tu32 max_iscsi_conn = FW_ENCODE_32BIT_PATTERN ^ SHMEM_RD(bp,\n\t\t\t\tdrv_lic_key[port].max_iscsi_conn);\n\n\tif (!CNIC_SUPPORT(bp)) {\n\t\tbp->flags |= no_flags;\n\t\treturn;\n\t}\n\n\t \n\tbp->cnic_eth_dev.max_iscsi_conn =\n\t\t(max_iscsi_conn & BNX2X_MAX_ISCSI_INIT_CONN_MASK) >>\n\t\tBNX2X_MAX_ISCSI_INIT_CONN_SHIFT;\n\n\tBNX2X_DEV_INFO(\"max_iscsi_conn 0x%x\\n\",\n\t\t       bp->cnic_eth_dev.max_iscsi_conn);\n\n\t \n\tif (!bp->cnic_eth_dev.max_iscsi_conn)\n\t\tbp->flags |= no_flags;\n}\n\nstatic void bnx2x_get_ext_wwn_info(struct bnx2x *bp, int func)\n{\n\t \n\tbp->cnic_eth_dev.fcoe_wwn_port_name_hi =\n\t\tMF_CFG_RD(bp, func_ext_config[func].fcoe_wwn_port_name_upper);\n\tbp->cnic_eth_dev.fcoe_wwn_port_name_lo =\n\t\tMF_CFG_RD(bp, func_ext_config[func].fcoe_wwn_port_name_lower);\n\n\t \n\tbp->cnic_eth_dev.fcoe_wwn_node_name_hi =\n\t\tMF_CFG_RD(bp, func_ext_config[func].fcoe_wwn_node_name_upper);\n\tbp->cnic_eth_dev.fcoe_wwn_node_name_lo =\n\t\tMF_CFG_RD(bp, func_ext_config[func].fcoe_wwn_node_name_lower);\n}\n\nstatic int bnx2x_shared_fcoe_funcs(struct bnx2x *bp)\n{\n\tu8 count = 0;\n\n\tif (IS_MF(bp)) {\n\t\tu8 fid;\n\n\t\t \n\t\tfor (fid = BP_PATH(bp); fid < E2_FUNC_MAX * 2; fid += 2) {\n\t\t\tif (IS_MF_SD(bp)) {\n\t\t\t\tu32 cfg = MF_CFG_RD(bp,\n\t\t\t\t\t\t    func_mf_config[fid].config);\n\n\t\t\t\tif (!(cfg & FUNC_MF_CFG_FUNC_HIDE) &&\n\t\t\t\t    ((cfg & FUNC_MF_CFG_PROTOCOL_MASK) ==\n\t\t\t\t\t    FUNC_MF_CFG_PROTOCOL_FCOE))\n\t\t\t\t\tcount++;\n\t\t\t} else {\n\t\t\t\tu32 cfg = MF_CFG_RD(bp,\n\t\t\t\t\t\t    func_ext_config[fid].\n\t\t\t\t\t\t\t\t      func_cfg);\n\n\t\t\t\tif ((cfg & MACP_FUNC_CFG_FLAGS_ENABLED) &&\n\t\t\t\t    (cfg & MACP_FUNC_CFG_FLAGS_FCOE_OFFLOAD))\n\t\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t} else {  \n\t\tint port, port_cnt = CHIP_MODE_IS_4_PORT(bp) ? 2 : 1;\n\n\t\tfor (port = 0; port < port_cnt; port++) {\n\t\t\tu32 lic = SHMEM_RD(bp,\n\t\t\t\t\t   drv_lic_key[port].max_fcoe_conn) ^\n\t\t\t\t  FW_ENCODE_32BIT_PATTERN;\n\t\t\tif (lic)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}\n\nstatic void bnx2x_get_fcoe_info(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tint func = BP_ABS_FUNC(bp);\n\tu32 max_fcoe_conn = FW_ENCODE_32BIT_PATTERN ^ SHMEM_RD(bp,\n\t\t\t\tdrv_lic_key[port].max_fcoe_conn);\n\tu8 num_fcoe_func = bnx2x_shared_fcoe_funcs(bp);\n\n\tif (!CNIC_SUPPORT(bp)) {\n\t\tbp->flags |= NO_FCOE_FLAG;\n\t\treturn;\n\t}\n\n\t \n\tbp->cnic_eth_dev.max_fcoe_conn =\n\t\t(max_fcoe_conn & BNX2X_MAX_FCOE_INIT_CONN_MASK) >>\n\t\tBNX2X_MAX_FCOE_INIT_CONN_SHIFT;\n\n\t \n\tbp->cnic_eth_dev.max_fcoe_exchanges = MAX_NUM_FCOE_TASKS_PER_ENGINE;\n\n\t \n\tif (num_fcoe_func)\n\t\tbp->cnic_eth_dev.max_fcoe_exchanges /= num_fcoe_func;\n\n\t \n\tif (!IS_MF(bp)) {\n\t\t \n\t\tbp->cnic_eth_dev.fcoe_wwn_port_name_hi =\n\t\t\tSHMEM_RD(bp,\n\t\t\t\t dev_info.port_hw_config[port].\n\t\t\t\t fcoe_wwn_port_name_upper);\n\t\tbp->cnic_eth_dev.fcoe_wwn_port_name_lo =\n\t\t\tSHMEM_RD(bp,\n\t\t\t\t dev_info.port_hw_config[port].\n\t\t\t\t fcoe_wwn_port_name_lower);\n\n\t\t \n\t\tbp->cnic_eth_dev.fcoe_wwn_node_name_hi =\n\t\t\tSHMEM_RD(bp,\n\t\t\t\t dev_info.port_hw_config[port].\n\t\t\t\t fcoe_wwn_node_name_upper);\n\t\tbp->cnic_eth_dev.fcoe_wwn_node_name_lo =\n\t\t\tSHMEM_RD(bp,\n\t\t\t\t dev_info.port_hw_config[port].\n\t\t\t\t fcoe_wwn_node_name_lower);\n\t} else if (!IS_MF_SD(bp)) {\n\t\t \n\t\tif (BNX2X_HAS_MF_EXT_PROTOCOL_FCOE(bp))\n\t\t\tbnx2x_get_ext_wwn_info(bp, func);\n\t} else {\n\t\tif (BNX2X_IS_MF_SD_PROTOCOL_FCOE(bp) && !CHIP_IS_E1x(bp))\n\t\t\tbnx2x_get_ext_wwn_info(bp, func);\n\t}\n\n\tBNX2X_DEV_INFO(\"max_fcoe_conn 0x%x\\n\", bp->cnic_eth_dev.max_fcoe_conn);\n\n\t \n\tif (!bp->cnic_eth_dev.max_fcoe_conn) {\n\t\tbp->flags |= NO_FCOE_FLAG;\n\t\teth_zero_addr(bp->fip_mac);\n\t}\n}\n\nstatic void bnx2x_get_cnic_info(struct bnx2x *bp)\n{\n\t \n\tbnx2x_get_iscsi_info(bp);\n\tbnx2x_get_fcoe_info(bp);\n}\n\nstatic void bnx2x_get_cnic_mac_hwinfo(struct bnx2x *bp)\n{\n\tu32 val, val2;\n\tint func = BP_ABS_FUNC(bp);\n\tint port = BP_PORT(bp);\n\tu8 *iscsi_mac = bp->cnic_eth_dev.iscsi_mac;\n\tu8 *fip_mac = bp->fip_mac;\n\n\tif (IS_MF(bp)) {\n\t\t \n\t\tif (!IS_MF_SD(bp)) {\n\t\t\tu32 cfg = MF_CFG_RD(bp, func_ext_config[func].func_cfg);\n\t\t\tif (cfg & MACP_FUNC_CFG_FLAGS_ISCSI_OFFLOAD) {\n\t\t\t\tval2 = MF_CFG_RD(bp, func_ext_config[func].\n\t\t\t\t\t\t iscsi_mac_addr_upper);\n\t\t\t\tval = MF_CFG_RD(bp, func_ext_config[func].\n\t\t\t\t\t\tiscsi_mac_addr_lower);\n\t\t\t\tbnx2x_set_mac_buf(iscsi_mac, val, val2);\n\t\t\t\tBNX2X_DEV_INFO\n\t\t\t\t\t(\"Read iSCSI MAC: %pM\\n\", iscsi_mac);\n\t\t\t} else {\n\t\t\t\tbp->flags |= NO_ISCSI_OOO_FLAG | NO_ISCSI_FLAG;\n\t\t\t}\n\n\t\t\tif (cfg & MACP_FUNC_CFG_FLAGS_FCOE_OFFLOAD) {\n\t\t\t\tval2 = MF_CFG_RD(bp, func_ext_config[func].\n\t\t\t\t\t\t fcoe_mac_addr_upper);\n\t\t\t\tval = MF_CFG_RD(bp, func_ext_config[func].\n\t\t\t\t\t\tfcoe_mac_addr_lower);\n\t\t\t\tbnx2x_set_mac_buf(fip_mac, val, val2);\n\t\t\t\tBNX2X_DEV_INFO\n\t\t\t\t\t(\"Read FCoE L2 MAC: %pM\\n\", fip_mac);\n\t\t\t} else {\n\t\t\t\tbp->flags |= NO_FCOE_FLAG;\n\t\t\t}\n\n\t\t\tbp->mf_ext_config = cfg;\n\n\t\t} else {  \n\t\t\tif (BNX2X_IS_MF_SD_PROTOCOL_ISCSI(bp)) {\n\t\t\t\t \n\t\t\t\tmemcpy(iscsi_mac, bp->dev->dev_addr, ETH_ALEN);\n\n\t\t\t\tBNX2X_DEV_INFO(\"SD ISCSI MODE\\n\");\n\t\t\t\tBNX2X_DEV_INFO\n\t\t\t\t\t(\"Read iSCSI MAC: %pM\\n\", iscsi_mac);\n\t\t\t} else if (BNX2X_IS_MF_SD_PROTOCOL_FCOE(bp)) {\n\t\t\t\t \n\t\t\t\tmemcpy(fip_mac, bp->dev->dev_addr, ETH_ALEN);\n\t\t\t\tBNX2X_DEV_INFO(\"SD FCoE MODE\\n\");\n\t\t\t\tBNX2X_DEV_INFO\n\t\t\t\t\t(\"Read FIP MAC: %pM\\n\", fip_mac);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (IS_MF_FCOE_AFEX(bp))\n\t\t\teth_hw_addr_set(bp->dev, fip_mac);\n\t} else {\n\t\tval2 = SHMEM_RD(bp, dev_info.port_hw_config[port].\n\t\t\t\tiscsi_mac_upper);\n\t\tval = SHMEM_RD(bp, dev_info.port_hw_config[port].\n\t\t\t       iscsi_mac_lower);\n\t\tbnx2x_set_mac_buf(iscsi_mac, val, val2);\n\n\t\tval2 = SHMEM_RD(bp, dev_info.port_hw_config[port].\n\t\t\t\tfcoe_fip_mac_upper);\n\t\tval = SHMEM_RD(bp, dev_info.port_hw_config[port].\n\t\t\t       fcoe_fip_mac_lower);\n\t\tbnx2x_set_mac_buf(fip_mac, val, val2);\n\t}\n\n\t \n\tif (!is_valid_ether_addr(iscsi_mac)) {\n\t\tbp->flags |= NO_ISCSI_OOO_FLAG | NO_ISCSI_FLAG;\n\t\teth_zero_addr(iscsi_mac);\n\t}\n\n\t \n\tif (!is_valid_ether_addr(fip_mac)) {\n\t\tbp->flags |= NO_FCOE_FLAG;\n\t\teth_zero_addr(bp->fip_mac);\n\t}\n}\n\nstatic void bnx2x_get_mac_hwinfo(struct bnx2x *bp)\n{\n\tu32 val, val2;\n\tint func = BP_ABS_FUNC(bp);\n\tint port = BP_PORT(bp);\n\tu8 addr[ETH_ALEN] = {};\n\n\t \n\teth_hw_addr_set(bp->dev, addr);\n\n\tif (BP_NOMCP(bp)) {\n\t\tBNX2X_ERROR(\"warning: random MAC workaround active\\n\");\n\t\teth_hw_addr_random(bp->dev);\n\t} else if (IS_MF(bp)) {\n\t\tval2 = MF_CFG_RD(bp, func_mf_config[func].mac_upper);\n\t\tval = MF_CFG_RD(bp, func_mf_config[func].mac_lower);\n\t\tif ((val2 != FUNC_MF_CFG_UPPERMAC_DEFAULT) &&\n\t\t    (val != FUNC_MF_CFG_LOWERMAC_DEFAULT)) {\n\t\t\tbnx2x_set_mac_buf(addr, val, val2);\n\t\t\teth_hw_addr_set(bp->dev, addr);\n\t\t}\n\n\t\tif (CNIC_SUPPORT(bp))\n\t\t\tbnx2x_get_cnic_mac_hwinfo(bp);\n\t} else {\n\t\t \n\t\tval2 = SHMEM_RD(bp, dev_info.port_hw_config[port].mac_upper);\n\t\tval = SHMEM_RD(bp, dev_info.port_hw_config[port].mac_lower);\n\t\tbnx2x_set_mac_buf(addr, val, val2);\n\t\teth_hw_addr_set(bp->dev, addr);\n\n\t\tif (CNIC_SUPPORT(bp))\n\t\t\tbnx2x_get_cnic_mac_hwinfo(bp);\n\t}\n\n\tif (!BP_NOMCP(bp)) {\n\t\t \n\t\tval2 = SHMEM_RD(bp, dev_info.port_hw_config[port].mac_upper);\n\t\tval = SHMEM_RD(bp, dev_info.port_hw_config[port].mac_lower);\n\t\tbnx2x_set_mac_buf(bp->phys_port_id, val, val2);\n\t\tbp->flags |= HAS_PHYS_PORT_ID;\n\t}\n\n\tmemcpy(bp->link_params.mac_addr, bp->dev->dev_addr, ETH_ALEN);\n\n\tif (!is_valid_ether_addr(bp->dev->dev_addr))\n\t\tdev_err(&bp->pdev->dev,\n\t\t\t\"bad Ethernet MAC address configuration: %pM\\n\"\n\t\t\t\"change it manually before bringing up the appropriate network interface\\n\",\n\t\t\tbp->dev->dev_addr);\n}\n\nstatic bool bnx2x_get_dropless_info(struct bnx2x *bp)\n{\n\tint tmp;\n\tu32 cfg;\n\n\tif (IS_VF(bp))\n\t\treturn false;\n\n\tif (IS_MF(bp) && !CHIP_IS_E1x(bp)) {\n\t\t \n\t\ttmp = BP_ABS_FUNC(bp);\n\t\tcfg = MF_CFG_RD(bp, func_ext_config[tmp].func_cfg);\n\t\tcfg = !!(cfg & MACP_FUNC_CFG_PAUSE_ON_HOST_RING);\n\t} else {\n\t\t \n\t\ttmp = BP_PORT(bp);\n\t\tcfg = SHMEM_RD(bp,\n\t\t\t       dev_info.port_hw_config[tmp].generic_features);\n\t\tcfg = !!(cfg & PORT_HW_CFG_PAUSE_ON_HOST_RING_ENABLED);\n\t}\n\treturn cfg;\n}\n\nstatic void validate_set_si_mode(struct bnx2x *bp)\n{\n\tu8 func = BP_ABS_FUNC(bp);\n\tu32 val;\n\n\tval = MF_CFG_RD(bp, func_mf_config[func].mac_upper);\n\n\t \n\tif (val != 0xffff) {\n\t\tbp->mf_mode = MULTI_FUNCTION_SI;\n\t\tbp->mf_config[BP_VN(bp)] =\n\t\t\tMF_CFG_RD(bp, func_mf_config[func].config);\n\t} else\n\t\tBNX2X_DEV_INFO(\"illegal MAC address for SI\\n\");\n}\n\nstatic int bnx2x_get_hwinfo(struct bnx2x *bp)\n{\n\tint  func = BP_ABS_FUNC(bp);\n\tint vn;\n\tu32 val = 0, val2 = 0;\n\tint rc = 0;\n\n\t \n\tif (REG_RD(bp, MISC_REG_CHIP_NUM) == 0xffffffff) {\n\t\tdev_err(&bp->pdev->dev,\n\t\t\t\"Chip read returns all Fs. Preventing probe from continuing\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tbnx2x_get_common_hwinfo(bp);\n\n\t \n\tif (CHIP_IS_E1x(bp)) {\n\t\tbp->common.int_block = INT_BLOCK_HC;\n\n\t\tbp->igu_dsb_id = DEF_SB_IGU_ID;\n\t\tbp->igu_base_sb = 0;\n\t} else {\n\t\tbp->common.int_block = INT_BLOCK_IGU;\n\n\t\t \n\t\tbnx2x_acquire_hw_lock(bp, HW_LOCK_RESOURCE_RESET);\n\n\t\tval = REG_RD(bp, IGU_REG_BLOCK_CONFIGURATION);\n\n\t\tif (val & IGU_BLOCK_CONFIGURATION_REG_BACKWARD_COMP_EN) {\n\t\t\tint tout = 5000;\n\n\t\t\tBNX2X_DEV_INFO(\"FORCING Normal Mode\\n\");\n\n\t\t\tval &= ~(IGU_BLOCK_CONFIGURATION_REG_BACKWARD_COMP_EN);\n\t\t\tREG_WR(bp, IGU_REG_BLOCK_CONFIGURATION, val);\n\t\t\tREG_WR(bp, IGU_REG_RESET_MEMORIES, 0x7f);\n\n\t\t\twhile (tout && REG_RD(bp, IGU_REG_RESET_MEMORIES)) {\n\t\t\t\ttout--;\n\t\t\t\tusleep_range(1000, 2000);\n\t\t\t}\n\n\t\t\tif (REG_RD(bp, IGU_REG_RESET_MEMORIES)) {\n\t\t\t\tdev_err(&bp->pdev->dev,\n\t\t\t\t\t\"FORCING Normal Mode failed!!!\\n\");\n\t\t\t\tbnx2x_release_hw_lock(bp,\n\t\t\t\t\t\t      HW_LOCK_RESOURCE_RESET);\n\t\t\t\treturn -EPERM;\n\t\t\t}\n\t\t}\n\n\t\tif (val & IGU_BLOCK_CONFIGURATION_REG_BACKWARD_COMP_EN) {\n\t\t\tBNX2X_DEV_INFO(\"IGU Backward Compatible Mode\\n\");\n\t\t\tbp->common.int_block |= INT_BLOCK_MODE_BW_COMP;\n\t\t} else\n\t\t\tBNX2X_DEV_INFO(\"IGU Normal Mode\\n\");\n\n\t\trc = bnx2x_get_igu_cam_info(bp);\n\t\tbnx2x_release_hw_lock(bp, HW_LOCK_RESOURCE_RESET);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t \n\tif (CHIP_IS_E1x(bp))\n\t\tbp->base_fw_ndsb = BP_PORT(bp) * FP_SB_MAX_E1x + BP_L_ID(bp);\n\telse  \n\t\tbp->base_fw_ndsb = bp->igu_base_sb;\n\n\tBNX2X_DEV_INFO(\"igu_dsb_id %d  igu_base_sb %d  igu_sb_cnt %d\\n\"\n\t\t       \"base_fw_ndsb %d\\n\", bp->igu_dsb_id, bp->igu_base_sb,\n\t\t       bp->igu_sb_cnt, bp->base_fw_ndsb);\n\n\t \n\tbp->mf_ov = 0;\n\tbp->mf_mode = 0;\n\tbp->mf_sub_mode = 0;\n\tvn = BP_VN(bp);\n\n\tif (!CHIP_IS_E1(bp) && !BP_NOMCP(bp)) {\n\t\tBNX2X_DEV_INFO(\"shmem2base 0x%x, size %d, mfcfg offset %d\\n\",\n\t\t\t       bp->common.shmem2_base, SHMEM2_RD(bp, size),\n\t\t\t      (u32)offsetof(struct shmem2_region, mf_cfg_addr));\n\n\t\tif (SHMEM2_HAS(bp, mf_cfg_addr))\n\t\t\tbp->common.mf_cfg_base = SHMEM2_RD(bp, mf_cfg_addr);\n\t\telse\n\t\t\tbp->common.mf_cfg_base = bp->common.shmem_base +\n\t\t\t\toffsetof(struct shmem_region, func_mb) +\n\t\t\t\tE1H_FUNC_MAX * sizeof(struct drv_func_mb);\n\t\t \n\t\tif (bp->common.mf_cfg_base != SHMEM_MF_CFG_ADDR_NONE) {\n\t\t\t \n\t\t\tval = SHMEM_RD(bp,\n\t\t\t\t       dev_info.shared_feature_config.config);\n\t\t\tval &= SHARED_FEAT_CFG_FORCE_SF_MODE_MASK;\n\n\t\t\tswitch (val) {\n\t\t\tcase SHARED_FEAT_CFG_FORCE_SF_MODE_SWITCH_INDEPT:\n\t\t\t\tvalidate_set_si_mode(bp);\n\t\t\t\tbreak;\n\t\t\tcase SHARED_FEAT_CFG_FORCE_SF_MODE_AFEX_MODE:\n\t\t\t\tif ((!CHIP_IS_E1x(bp)) &&\n\t\t\t\t    (MF_CFG_RD(bp, func_mf_config[func].\n\t\t\t\t\t       mac_upper) != 0xffff) &&\n\t\t\t\t    (SHMEM2_HAS(bp,\n\t\t\t\t\t\tafex_driver_support))) {\n\t\t\t\t\tbp->mf_mode = MULTI_FUNCTION_AFEX;\n\t\t\t\t\tbp->mf_config[vn] = MF_CFG_RD(bp,\n\t\t\t\t\t\tfunc_mf_config[func].config);\n\t\t\t\t} else {\n\t\t\t\t\tBNX2X_DEV_INFO(\"can not configure afex mode\\n\");\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase SHARED_FEAT_CFG_FORCE_SF_MODE_MF_ALLOWED:\n\t\t\t\t \n\t\t\t\tval = MF_CFG_RD(bp,\n\t\t\t\t\tfunc_mf_config[FUNC_0].e1hov_tag);\n\t\t\t\tval &= FUNC_MF_CFG_E1HOV_TAG_MASK;\n\n\t\t\t\tif (val != FUNC_MF_CFG_E1HOV_TAG_DEFAULT) {\n\t\t\t\t\tbp->mf_mode = MULTI_FUNCTION_SD;\n\t\t\t\t\tbp->mf_config[vn] = MF_CFG_RD(bp,\n\t\t\t\t\t\tfunc_mf_config[func].config);\n\t\t\t\t} else\n\t\t\t\t\tBNX2X_DEV_INFO(\"illegal OV for SD\\n\");\n\t\t\t\tbreak;\n\t\t\tcase SHARED_FEAT_CFG_FORCE_SF_MODE_BD_MODE:\n\t\t\t\tbp->mf_mode = MULTI_FUNCTION_SD;\n\t\t\t\tbp->mf_sub_mode = SUB_MF_MODE_BD;\n\t\t\t\tbp->mf_config[vn] =\n\t\t\t\t\tMF_CFG_RD(bp,\n\t\t\t\t\t\t  func_mf_config[func].config);\n\n\t\t\t\tif (SHMEM2_HAS(bp, mtu_size)) {\n\t\t\t\t\tint mtu_idx = BP_FW_MB_IDX(bp);\n\t\t\t\t\tu16 mtu_size;\n\t\t\t\t\tu32 mtu;\n\n\t\t\t\t\tmtu = SHMEM2_RD(bp, mtu_size[mtu_idx]);\n\t\t\t\t\tmtu_size = (u16)mtu;\n\t\t\t\t\tDP(NETIF_MSG_IFUP, \"Read MTU size %04x [%08x]\\n\",\n\t\t\t\t\t   mtu_size, mtu);\n\n\t\t\t\t\t \n\t\t\t\t\tif ((mtu_size >= ETH_MIN_PACKET_SIZE) &&\n\t\t\t\t\t    (mtu_size <=\n\t\t\t\t\t     ETH_MAX_JUMBO_PACKET_SIZE))\n\t\t\t\t\t\tbp->dev->mtu = mtu_size;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase SHARED_FEAT_CFG_FORCE_SF_MODE_UFP_MODE:\n\t\t\t\tbp->mf_mode = MULTI_FUNCTION_SD;\n\t\t\t\tbp->mf_sub_mode = SUB_MF_MODE_UFP;\n\t\t\t\tbp->mf_config[vn] =\n\t\t\t\t\tMF_CFG_RD(bp,\n\t\t\t\t\t\t  func_mf_config[func].config);\n\t\t\t\tbreak;\n\t\t\tcase SHARED_FEAT_CFG_FORCE_SF_MODE_FORCED_SF:\n\t\t\t\tbp->mf_config[vn] = 0;\n\t\t\t\tbreak;\n\t\t\tcase SHARED_FEAT_CFG_FORCE_SF_MODE_EXTENDED_MODE:\n\t\t\t\tval2 = SHMEM_RD(bp,\n\t\t\t\t\tdev_info.shared_hw_config.config_3);\n\t\t\t\tval2 &= SHARED_HW_CFG_EXTENDED_MF_MODE_MASK;\n\t\t\t\tswitch (val2) {\n\t\t\t\tcase SHARED_HW_CFG_EXTENDED_MF_MODE_NPAR1_DOT_5:\n\t\t\t\t\tvalidate_set_si_mode(bp);\n\t\t\t\t\tbp->mf_sub_mode =\n\t\t\t\t\t\t\tSUB_MF_MODE_NPAR1_DOT_5;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t \n\t\t\t\t\tbp->mf_config[vn] = 0;\n\t\t\t\t\tBNX2X_DEV_INFO(\"unknown extended MF mode 0x%x\\n\",\n\t\t\t\t\t\t       val);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t \n\t\t\t\tbp->mf_config[vn] = 0;\n\t\t\t\tBNX2X_DEV_INFO(\"unknown MF mode 0x%x\\n\", val);\n\t\t\t}\n\t\t}\n\n\t\tBNX2X_DEV_INFO(\"%s function mode\\n\",\n\t\t\t       IS_MF(bp) ? \"multi\" : \"single\");\n\n\t\tswitch (bp->mf_mode) {\n\t\tcase MULTI_FUNCTION_SD:\n\t\t\tval = MF_CFG_RD(bp, func_mf_config[func].e1hov_tag) &\n\t\t\t      FUNC_MF_CFG_E1HOV_TAG_MASK;\n\t\t\tif (val != FUNC_MF_CFG_E1HOV_TAG_DEFAULT) {\n\t\t\t\tbp->mf_ov = val;\n\t\t\t\tbp->path_has_ovlan = true;\n\n\t\t\t\tBNX2X_DEV_INFO(\"MF OV for func %d is %d (0x%04x)\\n\",\n\t\t\t\t\t       func, bp->mf_ov, bp->mf_ov);\n\t\t\t} else if ((bp->mf_sub_mode == SUB_MF_MODE_UFP) ||\n\t\t\t\t   (bp->mf_sub_mode == SUB_MF_MODE_BD)) {\n\t\t\t\tdev_err(&bp->pdev->dev,\n\t\t\t\t\t\"Unexpected - no valid MF OV for func %d in UFP/BD mode\\n\",\n\t\t\t\t\tfunc);\n\t\t\t\tbp->path_has_ovlan = true;\n\t\t\t} else {\n\t\t\t\tdev_err(&bp->pdev->dev,\n\t\t\t\t\t\"No valid MF OV for func %d, aborting\\n\",\n\t\t\t\t\tfunc);\n\t\t\t\treturn -EPERM;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase MULTI_FUNCTION_AFEX:\n\t\t\tBNX2X_DEV_INFO(\"func %d is in MF afex mode\\n\", func);\n\t\t\tbreak;\n\t\tcase MULTI_FUNCTION_SI:\n\t\t\tBNX2X_DEV_INFO(\"func %d is in MF switch-independent mode\\n\",\n\t\t\t\t       func);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (vn) {\n\t\t\t\tdev_err(&bp->pdev->dev,\n\t\t\t\t\t\"VN %d is in a single function mode, aborting\\n\",\n\t\t\t\t\tvn);\n\t\t\t\treturn -EPERM;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (CHIP_MODE_IS_4_PORT(bp) &&\n\t\t    !bp->path_has_ovlan &&\n\t\t    !IS_MF(bp) &&\n\t\t    bp->common.mf_cfg_base != SHMEM_MF_CFG_ADDR_NONE) {\n\t\t\tu8 other_port = !BP_PORT(bp);\n\t\t\tu8 other_func = BP_PATH(bp) + 2*other_port;\n\t\t\tval = MF_CFG_RD(bp,\n\t\t\t\t\tfunc_mf_config[other_func].e1hov_tag);\n\t\t\tif (val != FUNC_MF_CFG_E1HOV_TAG_DEFAULT)\n\t\t\t\tbp->path_has_ovlan = true;\n\t\t}\n\t}\n\n\t \n\tif (CHIP_IS_E1H(bp) && IS_MF(bp))\n\t\tbp->igu_sb_cnt = min_t(u8, bp->igu_sb_cnt, E1H_MAX_MF_SB_COUNT);\n\n\t \n\tbnx2x_get_port_hwinfo(bp);\n\n\t \n\tbnx2x_get_mac_hwinfo(bp);\n\n\tbnx2x_get_cnic_info(bp);\n\n\treturn rc;\n}\n\nstatic void bnx2x_read_fwinfo(struct bnx2x *bp)\n{\n\tchar str_id[VENDOR_ID_LEN + 1];\n\tunsigned int vpd_len, kw_len;\n\tu8 *vpd_data;\n\tint rodi;\n\n\tmemset(bp->fw_ver, 0, sizeof(bp->fw_ver));\n\n\tvpd_data = pci_vpd_alloc(bp->pdev, &vpd_len);\n\tif (IS_ERR(vpd_data))\n\t\treturn;\n\n\trodi = pci_vpd_find_ro_info_keyword(vpd_data, vpd_len,\n\t\t\t\t\t    PCI_VPD_RO_KEYWORD_MFR_ID, &kw_len);\n\tif (rodi < 0 || kw_len != VENDOR_ID_LEN)\n\t\tgoto out_not_found;\n\n\t \n\tsnprintf(str_id, VENDOR_ID_LEN + 1, \"%04x\", PCI_VENDOR_ID_DELL);\n\tif (!strncasecmp(str_id, &vpd_data[rodi], VENDOR_ID_LEN)) {\n\t\trodi = pci_vpd_find_ro_info_keyword(vpd_data, vpd_len,\n\t\t\t\t\t\t    PCI_VPD_RO_KEYWORD_VENDOR0,\n\t\t\t\t\t\t    &kw_len);\n\t\tif (rodi >= 0 && kw_len < sizeof(bp->fw_ver)) {\n\t\t\tmemcpy(bp->fw_ver, &vpd_data[rodi], kw_len);\n\t\t\tbp->fw_ver[kw_len] = ' ';\n\t\t}\n\t}\nout_not_found:\n\tkfree(vpd_data);\n}\n\nstatic void bnx2x_set_modes_bitmap(struct bnx2x *bp)\n{\n\tu32 flags = 0;\n\n\tif (CHIP_REV_IS_FPGA(bp))\n\t\tSET_FLAGS(flags, MODE_FPGA);\n\telse if (CHIP_REV_IS_EMUL(bp))\n\t\tSET_FLAGS(flags, MODE_EMUL);\n\telse\n\t\tSET_FLAGS(flags, MODE_ASIC);\n\n\tif (CHIP_MODE_IS_4_PORT(bp))\n\t\tSET_FLAGS(flags, MODE_PORT4);\n\telse\n\t\tSET_FLAGS(flags, MODE_PORT2);\n\n\tif (CHIP_IS_E2(bp))\n\t\tSET_FLAGS(flags, MODE_E2);\n\telse if (CHIP_IS_E3(bp)) {\n\t\tSET_FLAGS(flags, MODE_E3);\n\t\tif (CHIP_REV(bp) == CHIP_REV_Ax)\n\t\t\tSET_FLAGS(flags, MODE_E3_A0);\n\t\telse  \n\t\t\tSET_FLAGS(flags, MODE_E3_B0 | MODE_COS3);\n\t}\n\n\tif (IS_MF(bp)) {\n\t\tSET_FLAGS(flags, MODE_MF);\n\t\tswitch (bp->mf_mode) {\n\t\tcase MULTI_FUNCTION_SD:\n\t\t\tSET_FLAGS(flags, MODE_MF_SD);\n\t\t\tbreak;\n\t\tcase MULTI_FUNCTION_SI:\n\t\t\tSET_FLAGS(flags, MODE_MF_SI);\n\t\t\tbreak;\n\t\tcase MULTI_FUNCTION_AFEX:\n\t\t\tSET_FLAGS(flags, MODE_MF_AFEX);\n\t\t\tbreak;\n\t\t}\n\t} else\n\t\tSET_FLAGS(flags, MODE_SF);\n\n#if defined(__LITTLE_ENDIAN)\n\tSET_FLAGS(flags, MODE_LITTLE_ENDIAN);\n#else  \n\tSET_FLAGS(flags, MODE_BIG_ENDIAN);\n#endif\n\tINIT_MODE_FLAGS(bp) = flags;\n}\n\nstatic int bnx2x_init_bp(struct bnx2x *bp)\n{\n\tint func;\n\tint rc;\n\n\tmutex_init(&bp->port.phy_mutex);\n\tmutex_init(&bp->fw_mb_mutex);\n\tmutex_init(&bp->drv_info_mutex);\n\tsema_init(&bp->stats_lock, 1);\n\tbp->drv_info_mng_owner = false;\n\tINIT_LIST_HEAD(&bp->vlan_reg);\n\n\tINIT_DELAYED_WORK(&bp->sp_task, bnx2x_sp_task);\n\tINIT_DELAYED_WORK(&bp->sp_rtnl_task, bnx2x_sp_rtnl_task);\n\tINIT_DELAYED_WORK(&bp->period_task, bnx2x_period_task);\n\tINIT_DELAYED_WORK(&bp->iov_task, bnx2x_iov_task);\n\tif (IS_PF(bp)) {\n\t\trc = bnx2x_get_hwinfo(bp);\n\t\tif (rc)\n\t\t\treturn rc;\n\t} else {\n\t\tstatic const u8 zero_addr[ETH_ALEN] = {};\n\n\t\teth_hw_addr_set(bp->dev, zero_addr);\n\t}\n\n\tbnx2x_set_modes_bitmap(bp);\n\n\trc = bnx2x_alloc_mem_bp(bp);\n\tif (rc)\n\t\treturn rc;\n\n\tbnx2x_read_fwinfo(bp);\n\n\tfunc = BP_FUNC(bp);\n\n\t \n\tif (IS_PF(bp) && !BP_NOMCP(bp)) {\n\t\t \n\t\tbp->fw_seq =\n\t\t\tSHMEM_RD(bp, func_mb[BP_FW_MB_IDX(bp)].drv_mb_header) &\n\t\t\t\t\t\t\tDRV_MSG_SEQ_NUMBER_MASK;\n\t\tBNX2X_DEV_INFO(\"fw_seq 0x%08x\\n\", bp->fw_seq);\n\n\t\trc = bnx2x_prev_unload(bp);\n\t\tif (rc) {\n\t\t\tbnx2x_free_mem_bp(bp);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\tif (CHIP_REV_IS_FPGA(bp))\n\t\tdev_err(&bp->pdev->dev, \"FPGA detected\\n\");\n\n\tif (BP_NOMCP(bp) && (func == 0))\n\t\tdev_err(&bp->pdev->dev, \"MCP disabled, must load devices in order!\\n\");\n\n\tbp->disable_tpa = disable_tpa;\n\tbp->disable_tpa |= !!IS_MF_STORAGE_ONLY(bp);\n\t \n\tbp->disable_tpa |= is_kdump_kernel();\n\n\t \n\tif (bp->disable_tpa) {\n\t\tbp->dev->hw_features &= ~(NETIF_F_LRO | NETIF_F_GRO_HW);\n\t\tbp->dev->features &= ~(NETIF_F_LRO | NETIF_F_GRO_HW);\n\t}\n\n\tif (CHIP_IS_E1(bp))\n\t\tbp->dropless_fc = false;\n\telse\n\t\tbp->dropless_fc = dropless_fc | bnx2x_get_dropless_info(bp);\n\n\tbp->mrrs = mrrs;\n\n\tbp->tx_ring_size = IS_MF_STORAGE_ONLY(bp) ? 0 : MAX_TX_AVAIL;\n\tif (IS_VF(bp))\n\t\tbp->rx_ring_size = MAX_RX_AVAIL;\n\n\t \n\tbp->tx_ticks = (50 / BNX2X_BTR) * BNX2X_BTR;\n\tbp->rx_ticks = (25 / BNX2X_BTR) * BNX2X_BTR;\n\n\tbp->current_interval = CHIP_REV_IS_SLOW(bp) ? 5*HZ : HZ;\n\n\ttimer_setup(&bp->timer, bnx2x_timer, 0);\n\tbp->timer.expires = jiffies + bp->current_interval;\n\n\tif (SHMEM2_HAS(bp, dcbx_lldp_params_offset) &&\n\t    SHMEM2_HAS(bp, dcbx_lldp_dcbx_stat_offset) &&\n\t    SHMEM2_HAS(bp, dcbx_en) &&\n\t    SHMEM2_RD(bp, dcbx_lldp_params_offset) &&\n\t    SHMEM2_RD(bp, dcbx_lldp_dcbx_stat_offset) &&\n\t    SHMEM2_RD(bp, dcbx_en[BP_PORT(bp)])) {\n\t\tbnx2x_dcbx_set_state(bp, true, BNX2X_DCBX_ENABLED_ON_NEG_ON);\n\t\tbnx2x_dcbx_init_params(bp);\n\t} else {\n\t\tbnx2x_dcbx_set_state(bp, false, BNX2X_DCBX_ENABLED_OFF);\n\t}\n\n\tif (CHIP_IS_E1x(bp))\n\t\tbp->cnic_base_cl_id = FP_SB_MAX_E1x;\n\telse\n\t\tbp->cnic_base_cl_id = FP_SB_MAX_E2;\n\n\t \n\tif (IS_VF(bp))\n\t\tbp->max_cos = 1;\n\telse if (CHIP_IS_E1x(bp))\n\t\tbp->max_cos = BNX2X_MULTI_TX_COS_E1X;\n\telse if (CHIP_IS_E2(bp) || CHIP_IS_E3A0(bp))\n\t\tbp->max_cos = BNX2X_MULTI_TX_COS_E2_E3A0;\n\telse if (CHIP_IS_E3B0(bp))\n\t\tbp->max_cos = BNX2X_MULTI_TX_COS_E3B0;\n\telse\n\t\tBNX2X_ERR(\"unknown chip %x revision %x\\n\",\n\t\t\t  CHIP_NUM(bp), CHIP_REV(bp));\n\tBNX2X_DEV_INFO(\"set bp->max_cos to %d\\n\", bp->max_cos);\n\n\t \n\tif (IS_VF(bp))\n\t\tbp->min_msix_vec_cnt = 1;\n\telse if (CNIC_SUPPORT(bp))\n\t\tbp->min_msix_vec_cnt = 3;\n\telse  \n\t\tbp->min_msix_vec_cnt = 2;\n\tBNX2X_DEV_INFO(\"bp->min_msix_vec_cnt %d\", bp->min_msix_vec_cnt);\n\n\tbp->dump_preset_idx = 1;\n\n\treturn rc;\n}\n\n \n\n \n\n \nstatic int bnx2x_open(struct net_device *dev)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tint rc;\n\n\tbp->stats_init = true;\n\n\tnetif_carrier_off(dev);\n\n\tbnx2x_set_power_state(bp, PCI_D0);\n\n\t \n\tif (IS_PF(bp)) {\n\t\tint other_engine = BP_PATH(bp) ? 0 : 1;\n\t\tbool other_load_status, load_status;\n\t\tbool global = false;\n\n\t\tother_load_status = bnx2x_get_load_status(bp, other_engine);\n\t\tload_status = bnx2x_get_load_status(bp, BP_PATH(bp));\n\t\tif (!bnx2x_reset_is_done(bp, BP_PATH(bp)) ||\n\t\t    bnx2x_chk_parity_attn(bp, &global, true)) {\n\t\t\tdo {\n\t\t\t\t \n\t\t\t\tif (global)\n\t\t\t\t\tbnx2x_set_reset_global(bp);\n\n\t\t\t\t \n\t\t\t\tif ((!load_status &&\n\t\t\t\t     (!global || !other_load_status)) &&\n\t\t\t\t      bnx2x_trylock_leader_lock(bp) &&\n\t\t\t\t      !bnx2x_leader_reset(bp)) {\n\t\t\t\t\tnetdev_info(bp->dev,\n\t\t\t\t\t\t    \"Recovered in open\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tbnx2x_set_power_state(bp, PCI_D3hot);\n\t\t\t\tbp->recovery_state = BNX2X_RECOVERY_FAILED;\n\n\t\t\t\tBNX2X_ERR(\"Recovery flow hasn't been properly completed yet. Try again later.\\n\"\n\t\t\t\t\t  \"If you still see this message after a few retries then power cycle is required.\\n\");\n\n\t\t\t\treturn -EAGAIN;\n\t\t\t} while (0);\n\t\t}\n\t}\n\n\tbp->recovery_state = BNX2X_RECOVERY_DONE;\n\trc = bnx2x_nic_load(bp, LOAD_OPEN);\n\tif (rc)\n\t\treturn rc;\n\n\treturn 0;\n}\n\n \nstatic int bnx2x_close(struct net_device *dev)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\n\t \n\tbnx2x_nic_unload(bp, UNLOAD_CLOSE, false);\n\n\treturn 0;\n}\n\nstruct bnx2x_mcast_list_elem_group\n{\n\tstruct list_head mcast_group_link;\n\tstruct bnx2x_mcast_list_elem mcast_elems[];\n};\n\n#define MCAST_ELEMS_PER_PG \\\n\t((PAGE_SIZE - sizeof(struct bnx2x_mcast_list_elem_group)) / \\\n\tsizeof(struct bnx2x_mcast_list_elem))\n\nstatic void bnx2x_free_mcast_macs_list(struct list_head *mcast_group_list)\n{\n\tstruct bnx2x_mcast_list_elem_group *current_mcast_group;\n\n\twhile (!list_empty(mcast_group_list)) {\n\t\tcurrent_mcast_group = list_first_entry(mcast_group_list,\n\t\t\t\t      struct bnx2x_mcast_list_elem_group,\n\t\t\t\t      mcast_group_link);\n\t\tlist_del(&current_mcast_group->mcast_group_link);\n\t\tfree_page((unsigned long)current_mcast_group);\n\t}\n}\n\nstatic int bnx2x_init_mcast_macs_list(struct bnx2x *bp,\n\t\t\t\t      struct bnx2x_mcast_ramrod_params *p,\n\t\t\t\t      struct list_head *mcast_group_list)\n{\n\tstruct bnx2x_mcast_list_elem *mc_mac;\n\tstruct netdev_hw_addr *ha;\n\tstruct bnx2x_mcast_list_elem_group *current_mcast_group = NULL;\n\tint mc_count = netdev_mc_count(bp->dev);\n\tint offset = 0;\n\n\tINIT_LIST_HEAD(&p->mcast_list);\n\tnetdev_for_each_mc_addr(ha, bp->dev) {\n\t\tif (!offset) {\n\t\t\tcurrent_mcast_group =\n\t\t\t\t(struct bnx2x_mcast_list_elem_group *)\n\t\t\t\t__get_free_page(GFP_ATOMIC);\n\t\t\tif (!current_mcast_group) {\n\t\t\t\tbnx2x_free_mcast_macs_list(mcast_group_list);\n\t\t\t\tBNX2X_ERR(\"Failed to allocate mc MAC list\\n\");\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tlist_add(&current_mcast_group->mcast_group_link,\n\t\t\t\t mcast_group_list);\n\t\t}\n\t\tmc_mac = &current_mcast_group->mcast_elems[offset];\n\t\tmc_mac->mac = bnx2x_mc_addr(ha);\n\t\tlist_add_tail(&mc_mac->link, &p->mcast_list);\n\t\toffset++;\n\t\tif (offset == MCAST_ELEMS_PER_PG)\n\t\t\toffset = 0;\n\t}\n\tp->mcast_list_len = mc_count;\n\treturn 0;\n}\n\n \nstatic int bnx2x_set_uc_list(struct bnx2x *bp)\n{\n\tint rc;\n\tstruct net_device *dev = bp->dev;\n\tstruct netdev_hw_addr *ha;\n\tstruct bnx2x_vlan_mac_obj *mac_obj = &bp->sp_objs->mac_obj;\n\tunsigned long ramrod_flags = 0;\n\n\t \n\trc = bnx2x_del_all_macs(bp, mac_obj, BNX2X_UC_LIST_MAC, false);\n\tif (rc < 0) {\n\t\tBNX2X_ERR(\"Failed to schedule DELETE operations: %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\tnetdev_for_each_uc_addr(ha, dev) {\n\t\trc = bnx2x_set_mac_one(bp, bnx2x_uc_addr(ha), mac_obj, true,\n\t\t\t\t       BNX2X_UC_LIST_MAC, &ramrod_flags);\n\t\tif (rc == -EEXIST) {\n\t\t\tDP(BNX2X_MSG_SP,\n\t\t\t   \"Failed to schedule ADD operations: %d\\n\", rc);\n\t\t\t \n\t\t\trc = 0;\n\n\t\t} else if (rc < 0) {\n\n\t\t\tBNX2X_ERR(\"Failed to schedule ADD operations: %d\\n\",\n\t\t\t\t  rc);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\t \n\t__set_bit(RAMROD_CONT, &ramrod_flags);\n\treturn bnx2x_set_mac_one(bp, NULL, mac_obj, false  ,\n\t\t\t\t BNX2X_UC_LIST_MAC, &ramrod_flags);\n}\n\nstatic int bnx2x_set_mc_list_e1x(struct bnx2x *bp)\n{\n\tLIST_HEAD(mcast_group_list);\n\tstruct net_device *dev = bp->dev;\n\tstruct bnx2x_mcast_ramrod_params rparam = {NULL};\n\tint rc = 0;\n\n\trparam.mcast_obj = &bp->mcast_obj;\n\n\t \n\trc = bnx2x_config_mcast(bp, &rparam, BNX2X_MCAST_CMD_DEL);\n\tif (rc < 0) {\n\t\tBNX2X_ERR(\"Failed to clear multicast configuration: %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\tif (netdev_mc_count(dev)) {\n\t\trc = bnx2x_init_mcast_macs_list(bp, &rparam, &mcast_group_list);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\trc = bnx2x_config_mcast(bp, &rparam,\n\t\t\t\t\tBNX2X_MCAST_CMD_ADD);\n\t\tif (rc < 0)\n\t\t\tBNX2X_ERR(\"Failed to set a new multicast configuration: %d\\n\",\n\t\t\t\t  rc);\n\n\t\tbnx2x_free_mcast_macs_list(&mcast_group_list);\n\t}\n\n\treturn rc;\n}\n\nstatic int bnx2x_set_mc_list(struct bnx2x *bp)\n{\n\tLIST_HEAD(mcast_group_list);\n\tstruct bnx2x_mcast_ramrod_params rparam = {NULL};\n\tstruct net_device *dev = bp->dev;\n\tint rc = 0;\n\n\t \n\tif (CHIP_IS_E1x(bp))\n\t\treturn bnx2x_set_mc_list_e1x(bp);\n\n\trparam.mcast_obj = &bp->mcast_obj;\n\n\tif (netdev_mc_count(dev)) {\n\t\trc = bnx2x_init_mcast_macs_list(bp, &rparam, &mcast_group_list);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\trc = bnx2x_config_mcast(bp, &rparam,\n\t\t\t\t\tBNX2X_MCAST_CMD_SET);\n\t\tif (rc < 0)\n\t\t\tBNX2X_ERR(\"Failed to set a new multicast configuration: %d\\n\",\n\t\t\t\t  rc);\n\n\t\tbnx2x_free_mcast_macs_list(&mcast_group_list);\n\t} else {\n\t\t \n\t\trc = bnx2x_config_mcast(bp, &rparam, BNX2X_MCAST_CMD_DEL);\n\t\tif (rc < 0)\n\t\t\tBNX2X_ERR(\"Failed to clear multicast configuration %d\\n\",\n\t\t\t\t  rc);\n\t}\n\n\treturn rc;\n}\n\n \nstatic void bnx2x_set_rx_mode(struct net_device *dev)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\n\tif (bp->state != BNX2X_STATE_OPEN) {\n\t\tDP(NETIF_MSG_IFUP, \"state is %x, returning\\n\", bp->state);\n\t\treturn;\n\t} else {\n\t\t \n\t\tbnx2x_schedule_sp_rtnl(bp, BNX2X_SP_RTNL_RX_MODE,\n\t\t\t\t       NETIF_MSG_IFUP);\n\t}\n}\n\nvoid bnx2x_set_rx_mode_inner(struct bnx2x *bp)\n{\n\tu32 rx_mode = BNX2X_RX_MODE_NORMAL;\n\n\tDP(NETIF_MSG_IFUP, \"dev->flags = %x\\n\", bp->dev->flags);\n\n\tnetif_addr_lock_bh(bp->dev);\n\n\tif (bp->dev->flags & IFF_PROMISC) {\n\t\trx_mode = BNX2X_RX_MODE_PROMISC;\n\t} else if ((bp->dev->flags & IFF_ALLMULTI) ||\n\t\t   ((netdev_mc_count(bp->dev) > BNX2X_MAX_MULTICAST) &&\n\t\t    CHIP_IS_E1(bp))) {\n\t\trx_mode = BNX2X_RX_MODE_ALLMULTI;\n\t} else {\n\t\tif (IS_PF(bp)) {\n\t\t\t \n\t\t\tif (bnx2x_set_mc_list(bp) < 0)\n\t\t\t\trx_mode = BNX2X_RX_MODE_ALLMULTI;\n\n\t\t\t \n\t\t\tnetif_addr_unlock_bh(bp->dev);\n\t\t\tif (bnx2x_set_uc_list(bp) < 0)\n\t\t\t\trx_mode = BNX2X_RX_MODE_PROMISC;\n\t\t\tnetif_addr_lock_bh(bp->dev);\n\t\t} else {\n\t\t\t \n\t\t\tbnx2x_schedule_sp_rtnl(bp,\n\t\t\t\t\t       BNX2X_SP_RTNL_VFPF_MCAST, 0);\n\t\t}\n\t}\n\n\tbp->rx_mode = rx_mode;\n\t \n\tif (IS_MF_ISCSI_ONLY(bp))\n\t\tbp->rx_mode = BNX2X_RX_MODE_NONE;\n\n\t \n\tif (test_bit(BNX2X_FILTER_RX_MODE_PENDING, &bp->sp_state)) {\n\t\tset_bit(BNX2X_FILTER_RX_MODE_SCHED, &bp->sp_state);\n\t\tnetif_addr_unlock_bh(bp->dev);\n\t\treturn;\n\t}\n\n\tif (IS_PF(bp)) {\n\t\tbnx2x_set_storm_rx_mode(bp);\n\t\tnetif_addr_unlock_bh(bp->dev);\n\t} else {\n\t\t \n\t\tnetif_addr_unlock_bh(bp->dev);\n\t\tbnx2x_vfpf_storm_rx_mode(bp);\n\t}\n}\n\n \nstatic int bnx2x_mdio_read(struct net_device *netdev, int prtad,\n\t\t\t   int devad, u16 addr)\n{\n\tstruct bnx2x *bp = netdev_priv(netdev);\n\tu16 value;\n\tint rc;\n\n\tDP(NETIF_MSG_LINK, \"mdio_read: prtad 0x%x, devad 0x%x, addr 0x%x\\n\",\n\t   prtad, devad, addr);\n\n\t \n\tdevad = (devad == MDIO_DEVAD_NONE) ? DEFAULT_PHY_DEV_ADDR : devad;\n\n\tbnx2x_acquire_phy_lock(bp);\n\trc = bnx2x_phy_read(&bp->link_params, prtad, devad, addr, &value);\n\tbnx2x_release_phy_lock(bp);\n\tDP(NETIF_MSG_LINK, \"mdio_read_val 0x%x rc = 0x%x\\n\", value, rc);\n\n\tif (!rc)\n\t\trc = value;\n\treturn rc;\n}\n\n \nstatic int bnx2x_mdio_write(struct net_device *netdev, int prtad, int devad,\n\t\t\t    u16 addr, u16 value)\n{\n\tstruct bnx2x *bp = netdev_priv(netdev);\n\tint rc;\n\n\tDP(NETIF_MSG_LINK,\n\t   \"mdio_write: prtad 0x%x, devad 0x%x, addr 0x%x, value 0x%x\\n\",\n\t   prtad, devad, addr, value);\n\n\t \n\tdevad = (devad == MDIO_DEVAD_NONE) ? DEFAULT_PHY_DEV_ADDR : devad;\n\n\tbnx2x_acquire_phy_lock(bp);\n\trc = bnx2x_phy_write(&bp->link_params, prtad, devad, addr, value);\n\tbnx2x_release_phy_lock(bp);\n\treturn rc;\n}\n\n \nstatic int bnx2x_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tstruct mii_ioctl_data *mdio = if_mii(ifr);\n\n\tif (!netif_running(dev))\n\t\treturn -EAGAIN;\n\n\tswitch (cmd) {\n\tcase SIOCSHWTSTAMP:\n\t\treturn bnx2x_hwtstamp_ioctl(bp, ifr);\n\tdefault:\n\t\tDP(NETIF_MSG_LINK, \"ioctl: phy id 0x%x, reg 0x%x, val_in 0x%x\\n\",\n\t\t   mdio->phy_id, mdio->reg_num, mdio->val_in);\n\t\treturn mdio_mii_ioctl(&bp->mdio, mdio, cmd);\n\t}\n}\n\nstatic int bnx2x_validate_addr(struct net_device *dev)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\n\t \n\tif (IS_VF(bp))\n\t\tbnx2x_sample_bulletin(bp);\n\n\tif (!is_valid_ether_addr(dev->dev_addr)) {\n\t\tBNX2X_ERR(\"Non-valid Ethernet address\\n\");\n\t\treturn -EADDRNOTAVAIL;\n\t}\n\treturn 0;\n}\n\nstatic int bnx2x_get_phys_port_id(struct net_device *netdev,\n\t\t\t\t  struct netdev_phys_item_id *ppid)\n{\n\tstruct bnx2x *bp = netdev_priv(netdev);\n\n\tif (!(bp->flags & HAS_PHYS_PORT_ID))\n\t\treturn -EOPNOTSUPP;\n\n\tppid->id_len = sizeof(bp->phys_port_id);\n\tmemcpy(ppid->id, bp->phys_port_id, ppid->id_len);\n\n\treturn 0;\n}\n\nstatic netdev_features_t bnx2x_features_check(struct sk_buff *skb,\n\t\t\t\t\t      struct net_device *dev,\n\t\t\t\t\t      netdev_features_t features)\n{\n\t \n\tif (unlikely(skb_is_gso(skb) &&\n\t\t     (skb_shinfo(skb)->gso_size > 9000) &&\n\t\t     !skb_gso_validate_mac_len(skb, 9700)))\n\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\n\tfeatures = vlan_features_check(skb, features);\n\treturn vxlan_features_check(skb, features);\n}\n\nstatic int __bnx2x_vlan_configure_vid(struct bnx2x *bp, u16 vid, bool add)\n{\n\tint rc;\n\n\tif (IS_PF(bp)) {\n\t\tunsigned long ramrod_flags = 0;\n\n\t\t__set_bit(RAMROD_COMP_WAIT, &ramrod_flags);\n\t\trc = bnx2x_set_vlan_one(bp, vid, &bp->sp_objs->vlan_obj,\n\t\t\t\t\tadd, &ramrod_flags);\n\t} else {\n\t\trc = bnx2x_vfpf_update_vlan(bp, vid, bp->fp->index, add);\n\t}\n\n\treturn rc;\n}\n\nstatic int bnx2x_vlan_configure_vid_list(struct bnx2x *bp)\n{\n\tstruct bnx2x_vlan_entry *vlan;\n\tint rc = 0;\n\n\t \n\tlist_for_each_entry(vlan, &bp->vlan_reg, link) {\n\t\tif (vlan->hw)\n\t\t\tcontinue;\n\n\t\tif (bp->vlan_cnt >= bp->vlan_credit)\n\t\t\treturn -ENOBUFS;\n\n\t\trc = __bnx2x_vlan_configure_vid(bp, vlan->vid, true);\n\t\tif (rc) {\n\t\t\tBNX2X_ERR(\"Unable to config VLAN %d\\n\", vlan->vid);\n\t\t\treturn rc;\n\t\t}\n\n\t\tDP(NETIF_MSG_IFUP, \"HW configured for VLAN %d\\n\", vlan->vid);\n\t\tvlan->hw = true;\n\t\tbp->vlan_cnt++;\n\t}\n\n\treturn 0;\n}\n\nstatic void bnx2x_vlan_configure(struct bnx2x *bp, bool set_rx_mode)\n{\n\tbool need_accept_any_vlan;\n\n\tneed_accept_any_vlan = !!bnx2x_vlan_configure_vid_list(bp);\n\n\tif (bp->accept_any_vlan != need_accept_any_vlan) {\n\t\tbp->accept_any_vlan = need_accept_any_vlan;\n\t\tDP(NETIF_MSG_IFUP, \"Accept all VLAN %s\\n\",\n\t\t   bp->accept_any_vlan ? \"raised\" : \"cleared\");\n\t\tif (set_rx_mode) {\n\t\t\tif (IS_PF(bp))\n\t\t\t\tbnx2x_set_rx_mode_inner(bp);\n\t\t\telse\n\t\t\t\tbnx2x_vfpf_storm_rx_mode(bp);\n\t\t}\n\t}\n}\n\nint bnx2x_vlan_reconfigure_vid(struct bnx2x *bp)\n{\n\t \n\tbnx2x_vlan_configure(bp, false);\n\n\treturn 0;\n}\n\nstatic int bnx2x_vlan_rx_add_vid(struct net_device *dev, __be16 proto, u16 vid)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tstruct bnx2x_vlan_entry *vlan;\n\n\tDP(NETIF_MSG_IFUP, \"Adding VLAN %d\\n\", vid);\n\n\tvlan = kmalloc(sizeof(*vlan), GFP_KERNEL);\n\tif (!vlan)\n\t\treturn -ENOMEM;\n\n\tvlan->vid = vid;\n\tvlan->hw = false;\n\tlist_add_tail(&vlan->link, &bp->vlan_reg);\n\n\tif (netif_running(dev))\n\t\tbnx2x_vlan_configure(bp, true);\n\n\treturn 0;\n}\n\nstatic int bnx2x_vlan_rx_kill_vid(struct net_device *dev, __be16 proto, u16 vid)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tstruct bnx2x_vlan_entry *vlan;\n\tbool found = false;\n\tint rc = 0;\n\n\tDP(NETIF_MSG_IFUP, \"Removing VLAN %d\\n\", vid);\n\n\tlist_for_each_entry(vlan, &bp->vlan_reg, link)\n\t\tif (vlan->vid == vid) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\n\tif (!found) {\n\t\tBNX2X_ERR(\"Unable to kill VLAN %d - not found\\n\", vid);\n\t\treturn -EINVAL;\n\t}\n\n\tif (netif_running(dev) && vlan->hw) {\n\t\trc = __bnx2x_vlan_configure_vid(bp, vid, false);\n\t\tDP(NETIF_MSG_IFUP, \"HW deconfigured for VLAN %d\\n\", vid);\n\t\tbp->vlan_cnt--;\n\t}\n\n\tlist_del(&vlan->link);\n\tkfree(vlan);\n\n\tif (netif_running(dev))\n\t\tbnx2x_vlan_configure(bp, true);\n\n\tDP(NETIF_MSG_IFUP, \"Removing VLAN result %d\\n\", rc);\n\n\treturn rc;\n}\n\nstatic const struct net_device_ops bnx2x_netdev_ops = {\n\t.ndo_open\t\t= bnx2x_open,\n\t.ndo_stop\t\t= bnx2x_close,\n\t.ndo_start_xmit\t\t= bnx2x_start_xmit,\n\t.ndo_select_queue\t= bnx2x_select_queue,\n\t.ndo_set_rx_mode\t= bnx2x_set_rx_mode,\n\t.ndo_set_mac_address\t= bnx2x_change_mac_addr,\n\t.ndo_validate_addr\t= bnx2x_validate_addr,\n\t.ndo_eth_ioctl\t\t= bnx2x_ioctl,\n\t.ndo_change_mtu\t\t= bnx2x_change_mtu,\n\t.ndo_fix_features\t= bnx2x_fix_features,\n\t.ndo_set_features\t= bnx2x_set_features,\n\t.ndo_tx_timeout\t\t= bnx2x_tx_timeout,\n\t.ndo_vlan_rx_add_vid\t= bnx2x_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= bnx2x_vlan_rx_kill_vid,\n\t.ndo_setup_tc\t\t= __bnx2x_setup_tc,\n#ifdef CONFIG_BNX2X_SRIOV\n\t.ndo_set_vf_mac\t\t= bnx2x_set_vf_mac,\n\t.ndo_set_vf_vlan\t= bnx2x_set_vf_vlan,\n\t.ndo_get_vf_config\t= bnx2x_get_vf_config,\n\t.ndo_set_vf_spoofchk\t= bnx2x_set_vf_spoofchk,\n#endif\n#ifdef NETDEV_FCOE_WWNN\n\t.ndo_fcoe_get_wwn\t= bnx2x_fcoe_get_wwn,\n#endif\n\n\t.ndo_get_phys_port_id\t= bnx2x_get_phys_port_id,\n\t.ndo_set_vf_link_state\t= bnx2x_set_vf_link_state,\n\t.ndo_features_check\t= bnx2x_features_check,\n};\n\nstatic int bnx2x_init_dev(struct bnx2x *bp, struct pci_dev *pdev,\n\t\t\t  struct net_device *dev, unsigned long board_type)\n{\n\tint rc;\n\tu32 pci_cfg_dword;\n\tbool chip_is_e1x = (board_type == BCM57710 ||\n\t\t\t    board_type == BCM57711 ||\n\t\t\t    board_type == BCM57711E);\n\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\tbp->dev = dev;\n\tbp->pdev = pdev;\n\n\trc = pci_enable_device(pdev);\n\tif (rc) {\n\t\tdev_err(&bp->pdev->dev,\n\t\t\t\"Cannot enable PCI device, aborting\\n\");\n\t\tgoto err_out;\n\t}\n\n\tif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\n\t\tdev_err(&bp->pdev->dev,\n\t\t\t\"Cannot find PCI device base address, aborting\\n\");\n\t\trc = -ENODEV;\n\t\tgoto err_out_disable;\n\t}\n\n\tif (IS_PF(bp) && !(pci_resource_flags(pdev, 2) & IORESOURCE_MEM)) {\n\t\tdev_err(&bp->pdev->dev, \"Cannot find second PCI device base address, aborting\\n\");\n\t\trc = -ENODEV;\n\t\tgoto err_out_disable;\n\t}\n\n\tpci_read_config_dword(pdev, PCICFG_REVISION_ID_OFFSET, &pci_cfg_dword);\n\tif ((pci_cfg_dword & PCICFG_REVESION_ID_MASK) ==\n\t    PCICFG_REVESION_ID_ERROR_VAL) {\n\t\tpr_err(\"PCI device error, probably due to fan failure, aborting\\n\");\n\t\trc = -ENODEV;\n\t\tgoto err_out_disable;\n\t}\n\n\tif (atomic_read(&pdev->enable_cnt) == 1) {\n\t\trc = pci_request_regions(pdev, DRV_MODULE_NAME);\n\t\tif (rc) {\n\t\t\tdev_err(&bp->pdev->dev,\n\t\t\t\t\"Cannot obtain PCI resources, aborting\\n\");\n\t\t\tgoto err_out_disable;\n\t\t}\n\n\t\tpci_set_master(pdev);\n\t\tpci_save_state(pdev);\n\t}\n\n\tif (IS_PF(bp)) {\n\t\tif (!pdev->pm_cap) {\n\t\t\tdev_err(&bp->pdev->dev,\n\t\t\t\t\"Cannot find power management capability, aborting\\n\");\n\t\t\trc = -EIO;\n\t\t\tgoto err_out_release;\n\t\t}\n\t}\n\n\tif (!pci_is_pcie(pdev)) {\n\t\tdev_err(&bp->pdev->dev, \"Not PCI Express, aborting\\n\");\n\t\trc = -EIO;\n\t\tgoto err_out_release;\n\t}\n\n\trc = dma_set_mask_and_coherent(&bp->pdev->dev, DMA_BIT_MASK(64));\n\tif (rc) {\n\t\tdev_err(&bp->pdev->dev, \"System does not support DMA, aborting\\n\");\n\t\tgoto err_out_release;\n\t}\n\n\tdev->mem_start = pci_resource_start(pdev, 0);\n\tdev->base_addr = dev->mem_start;\n\tdev->mem_end = pci_resource_end(pdev, 0);\n\n\tdev->irq = pdev->irq;\n\n\tbp->regview = pci_ioremap_bar(pdev, 0);\n\tif (!bp->regview) {\n\t\tdev_err(&bp->pdev->dev,\n\t\t\t\"Cannot map register space, aborting\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err_out_release;\n\t}\n\n\t \n\tif (chip_is_e1x) {\n\t\tbp->pf_num = PCI_FUNC(pdev->devfn);\n\t} else {\n\t\t \n\t\tpci_read_config_dword(bp->pdev,\n\t\t\t\t      PCICFG_ME_REGISTER, &pci_cfg_dword);\n\t\tbp->pf_num = (u8)((pci_cfg_dword & ME_REG_ABS_PF_NUM) >>\n\t\t\t\t  ME_REG_ABS_PF_NUM_SHIFT);\n\t}\n\tBNX2X_DEV_INFO(\"me reg PF num: %d\\n\", bp->pf_num);\n\n\t \n\tpci_write_config_dword(bp->pdev, PCICFG_GRC_ADDRESS,\n\t\t\t       PCICFG_VENDOR_ID_OFFSET);\n\n\t \n\tpdev->needs_freset = 1;\n\n\t \n\tif (IS_PF(bp)) {\n\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_88_F0, 0);\n\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_8C_F0, 0);\n\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_90_F0, 0);\n\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_94_F0, 0);\n\n\t\tif (chip_is_e1x) {\n\t\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_88_F1, 0);\n\t\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_8C_F1, 0);\n\t\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_90_F1, 0);\n\t\t\tREG_WR(bp, PXP2_REG_PGL_ADDR_94_F1, 0);\n\t\t}\n\n\t\t \n\t\tif (!chip_is_e1x)\n\t\t\tREG_WR(bp,\n\t\t\t       PGLUE_B_REG_INTERNAL_PFID_ENABLE_TARGET_READ, 1);\n\t}\n\n\tdev->watchdog_timeo = TX_TIMEOUT;\n\n\tdev->netdev_ops = &bnx2x_netdev_ops;\n\tbnx2x_set_ethtool_ops(bp, dev);\n\n\tdev->priv_flags |= IFF_UNICAST_FLT;\n\n\tdev->hw_features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |\n\t\tNETIF_F_TSO | NETIF_F_TSO_ECN | NETIF_F_TSO6 |\n\t\tNETIF_F_RXCSUM | NETIF_F_LRO | NETIF_F_GRO | NETIF_F_GRO_HW |\n\t\tNETIF_F_RXHASH | NETIF_F_HW_VLAN_CTAG_TX;\n\tif (!chip_is_e1x) {\n\t\tdev->hw_features |= NETIF_F_GSO_GRE | NETIF_F_GSO_GRE_CSUM |\n\t\t\t\t    NETIF_F_GSO_IPXIP4 |\n\t\t\t\t    NETIF_F_GSO_UDP_TUNNEL |\n\t\t\t\t    NETIF_F_GSO_UDP_TUNNEL_CSUM |\n\t\t\t\t    NETIF_F_GSO_PARTIAL;\n\n\t\tdev->hw_enc_features =\n\t\t\tNETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_SG |\n\t\t\tNETIF_F_TSO | NETIF_F_TSO_ECN | NETIF_F_TSO6 |\n\t\t\tNETIF_F_GSO_IPXIP4 |\n\t\t\tNETIF_F_GSO_GRE | NETIF_F_GSO_GRE_CSUM |\n\t\t\tNETIF_F_GSO_UDP_TUNNEL | NETIF_F_GSO_UDP_TUNNEL_CSUM |\n\t\t\tNETIF_F_GSO_PARTIAL;\n\n\t\tdev->gso_partial_features = NETIF_F_GSO_GRE_CSUM |\n\t\t\t\t\t    NETIF_F_GSO_UDP_TUNNEL_CSUM;\n\n\t\tif (IS_PF(bp))\n\t\t\tdev->udp_tunnel_nic_info = &bnx2x_udp_tunnels;\n\t}\n\n\tdev->vlan_features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |\n\t\tNETIF_F_TSO | NETIF_F_TSO_ECN | NETIF_F_TSO6 | NETIF_F_HIGHDMA;\n\n\tif (IS_PF(bp)) {\n\t\tif (chip_is_e1x)\n\t\t\tbp->accept_any_vlan = true;\n\t\telse\n\t\t\tdev->hw_features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\t}\n\t \n\n\tdev->features |= dev->hw_features | NETIF_F_HW_VLAN_CTAG_RX;\n\tdev->features |= NETIF_F_HIGHDMA;\n\tif (dev->features & NETIF_F_LRO)\n\t\tdev->features &= ~NETIF_F_GRO_HW;\n\n\t \n\tdev->hw_features |= NETIF_F_LOOPBACK;\n\n#ifdef BCM_DCBNL\n\tdev->dcbnl_ops = &bnx2x_dcbnl_ops;\n#endif\n\n\t \n\tdev->min_mtu = ETH_MIN_PACKET_SIZE;\n\tdev->max_mtu = ETH_MAX_JUMBO_PACKET_SIZE;\n\n\t \n\tbp->mdio.prtad = MDIO_PRTAD_NONE;\n\tbp->mdio.mmds = 0;\n\tbp->mdio.mode_support = MDIO_SUPPORTS_C45 | MDIO_EMULATE_C22;\n\tbp->mdio.dev = dev;\n\tbp->mdio.mdio_read = bnx2x_mdio_read;\n\tbp->mdio.mdio_write = bnx2x_mdio_write;\n\n\treturn 0;\n\nerr_out_release:\n\tif (atomic_read(&pdev->enable_cnt) == 1)\n\t\tpci_release_regions(pdev);\n\nerr_out_disable:\n\tpci_disable_device(pdev);\n\nerr_out:\n\treturn rc;\n}\n\nstatic int bnx2x_check_firmware(struct bnx2x *bp)\n{\n\tconst struct firmware *firmware = bp->firmware;\n\tstruct bnx2x_fw_file_hdr *fw_hdr;\n\tstruct bnx2x_fw_file_section *sections;\n\tu32 offset, len, num_ops;\n\t__be16 *ops_offsets;\n\tint i;\n\tconst u8 *fw_ver;\n\n\tif (firmware->size < sizeof(struct bnx2x_fw_file_hdr)) {\n\t\tBNX2X_ERR(\"Wrong FW size\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tfw_hdr = (struct bnx2x_fw_file_hdr *)firmware->data;\n\tsections = (struct bnx2x_fw_file_section *)fw_hdr;\n\n\t \n\tfor (i = 0; i < sizeof(*fw_hdr) / sizeof(*sections); i++) {\n\t\toffset = be32_to_cpu(sections[i].offset);\n\t\tlen = be32_to_cpu(sections[i].len);\n\t\tif (offset + len > firmware->size) {\n\t\t\tBNX2X_ERR(\"Section %d length is out of bounds\\n\", i);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t \n\toffset = be32_to_cpu(fw_hdr->init_ops_offsets.offset);\n\tops_offsets = (__force __be16 *)(firmware->data + offset);\n\tnum_ops = be32_to_cpu(fw_hdr->init_ops.len) / sizeof(struct raw_op);\n\n\tfor (i = 0; i < be32_to_cpu(fw_hdr->init_ops_offsets.len) / 2; i++) {\n\t\tif (be16_to_cpu(ops_offsets[i]) > num_ops) {\n\t\t\tBNX2X_ERR(\"Section offset %d is out of bounds\\n\", i);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t \n\toffset = be32_to_cpu(fw_hdr->fw_version.offset);\n\tfw_ver = firmware->data + offset;\n\tif (fw_ver[0] != bp->fw_major || fw_ver[1] != bp->fw_minor ||\n\t    fw_ver[2] != bp->fw_rev || fw_ver[3] != bp->fw_eng) {\n\t\tBNX2X_ERR(\"Bad FW version:%d.%d.%d.%d. Should be %d.%d.%d.%d\\n\",\n\t\t\t  fw_ver[0], fw_ver[1], fw_ver[2], fw_ver[3],\n\t\t\t  bp->fw_major, bp->fw_minor, bp->fw_rev, bp->fw_eng);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void be32_to_cpu_n(const u8 *_source, u8 *_target, u32 n)\n{\n\tconst __be32 *source = (const __be32 *)_source;\n\tu32 *target = (u32 *)_target;\n\tu32 i;\n\n\tfor (i = 0; i < n/4; i++)\n\t\ttarget[i] = be32_to_cpu(source[i]);\n}\n\n \nstatic void bnx2x_prep_ops(const u8 *_source, u8 *_target, u32 n)\n{\n\tconst __be32 *source = (const __be32 *)_source;\n\tstruct raw_op *target = (struct raw_op *)_target;\n\tu32 i, j, tmp;\n\n\tfor (i = 0, j = 0; i < n/8; i++, j += 2) {\n\t\ttmp = be32_to_cpu(source[j]);\n\t\ttarget[i].op = (tmp >> 24) & 0xff;\n\t\ttarget[i].offset = tmp & 0xffffff;\n\t\ttarget[i].raw_data = be32_to_cpu(source[j + 1]);\n\t}\n}\n\n \nstatic void bnx2x_prep_iro(const u8 *_source, u8 *_target, u32 n)\n{\n\tconst __be32 *source = (const __be32 *)_source;\n\tstruct iro *target = (struct iro *)_target;\n\tu32 i, j, tmp;\n\n\tfor (i = 0, j = 0; i < n/sizeof(struct iro); i++) {\n\t\ttarget[i].base = be32_to_cpu(source[j]);\n\t\tj++;\n\t\ttmp = be32_to_cpu(source[j]);\n\t\ttarget[i].m1 = (tmp >> 16) & 0xffff;\n\t\ttarget[i].m2 = tmp & 0xffff;\n\t\tj++;\n\t\ttmp = be32_to_cpu(source[j]);\n\t\ttarget[i].m3 = (tmp >> 16) & 0xffff;\n\t\ttarget[i].size = tmp & 0xffff;\n\t\tj++;\n\t}\n}\n\nstatic void be16_to_cpu_n(const u8 *_source, u8 *_target, u32 n)\n{\n\tconst __be16 *source = (const __be16 *)_source;\n\tu16 *target = (u16 *)_target;\n\tu32 i;\n\n\tfor (i = 0; i < n/2; i++)\n\t\ttarget[i] = be16_to_cpu(source[i]);\n}\n\n#define BNX2X_ALLOC_AND_SET(arr, lbl, func)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tu32 len = be32_to_cpu(fw_hdr->arr.len);\t\t\t\t\\\n\tbp->arr = kmalloc(len, GFP_KERNEL);\t\t\t\t\\\n\tif (!bp->arr)\t\t\t\t\t\t\t\\\n\t\tgoto lbl;\t\t\t\t\t\t\\\n\tfunc(bp->firmware->data + be32_to_cpu(fw_hdr->arr.offset),\t\\\n\t     (u8 *)bp->arr, len);\t\t\t\t\t\\\n} while (0)\n\nstatic int bnx2x_init_firmware(struct bnx2x *bp)\n{\n\tconst char *fw_file_name, *fw_file_name_v15;\n\tstruct bnx2x_fw_file_hdr *fw_hdr;\n\tint rc;\n\n\tif (bp->firmware)\n\t\treturn 0;\n\n\tif (CHIP_IS_E1(bp)) {\n\t\tfw_file_name = FW_FILE_NAME_E1;\n\t\tfw_file_name_v15 = FW_FILE_NAME_E1_V15;\n\t} else if (CHIP_IS_E1H(bp)) {\n\t\tfw_file_name = FW_FILE_NAME_E1H;\n\t\tfw_file_name_v15 = FW_FILE_NAME_E1H_V15;\n\t} else if (!CHIP_IS_E1x(bp)) {\n\t\tfw_file_name = FW_FILE_NAME_E2;\n\t\tfw_file_name_v15 = FW_FILE_NAME_E2_V15;\n\t} else {\n\t\tBNX2X_ERR(\"Unsupported chip revision\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tBNX2X_DEV_INFO(\"Loading %s\\n\", fw_file_name);\n\n\trc = request_firmware(&bp->firmware, fw_file_name, &bp->pdev->dev);\n\tif (rc) {\n\t\tBNX2X_DEV_INFO(\"Trying to load older fw %s\\n\", fw_file_name_v15);\n\n\t\t \n\t\trc = request_firmware(&bp->firmware, fw_file_name_v15, &bp->pdev->dev);\n\n\t\tif (rc)\n\t\t\tgoto request_firmware_exit;\n\n\t\tbp->fw_rev = BCM_5710_FW_REVISION_VERSION_V15;\n\t} else {\n\t\tbp->fw_cap |= FW_CAP_INVALIDATE_VF_FP_HSI;\n\t\tbp->fw_rev = BCM_5710_FW_REVISION_VERSION;\n\t}\n\n\tbp->fw_major = BCM_5710_FW_MAJOR_VERSION;\n\tbp->fw_minor = BCM_5710_FW_MINOR_VERSION;\n\tbp->fw_eng = BCM_5710_FW_ENGINEERING_VERSION;\n\n\trc = bnx2x_check_firmware(bp);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Corrupt firmware file %s\\n\", fw_file_name);\n\t\tgoto request_firmware_exit;\n\t}\n\n\tfw_hdr = (struct bnx2x_fw_file_hdr *)bp->firmware->data;\n\n\t \n\t \n\trc = -ENOMEM;\n\tBNX2X_ALLOC_AND_SET(init_data, request_firmware_exit, be32_to_cpu_n);\n\n\t \n\tBNX2X_ALLOC_AND_SET(init_ops, init_ops_alloc_err, bnx2x_prep_ops);\n\n\t \n\tBNX2X_ALLOC_AND_SET(init_ops_offsets, init_offsets_alloc_err,\n\t\t\t    be16_to_cpu_n);\n\n\t \n\tINIT_TSEM_INT_TABLE_DATA(bp) = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->tsem_int_table_data.offset);\n\tINIT_TSEM_PRAM_DATA(bp)      = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->tsem_pram_data.offset);\n\tINIT_USEM_INT_TABLE_DATA(bp) = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->usem_int_table_data.offset);\n\tINIT_USEM_PRAM_DATA(bp)      = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->usem_pram_data.offset);\n\tINIT_XSEM_INT_TABLE_DATA(bp) = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->xsem_int_table_data.offset);\n\tINIT_XSEM_PRAM_DATA(bp)      = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->xsem_pram_data.offset);\n\tINIT_CSEM_INT_TABLE_DATA(bp) = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->csem_int_table_data.offset);\n\tINIT_CSEM_PRAM_DATA(bp)      = bp->firmware->data +\n\t\t\tbe32_to_cpu(fw_hdr->csem_pram_data.offset);\n\t \n\tBNX2X_ALLOC_AND_SET(iro_arr, iro_alloc_err, bnx2x_prep_iro);\n\n\treturn 0;\n\niro_alloc_err:\n\tkfree(bp->init_ops_offsets);\ninit_offsets_alloc_err:\n\tkfree(bp->init_ops);\ninit_ops_alloc_err:\n\tkfree(bp->init_data);\nrequest_firmware_exit:\n\trelease_firmware(bp->firmware);\n\tbp->firmware = NULL;\n\n\treturn rc;\n}\n\nstatic void bnx2x_release_firmware(struct bnx2x *bp)\n{\n\tkfree(bp->init_ops_offsets);\n\tkfree(bp->init_ops);\n\tkfree(bp->init_data);\n\trelease_firmware(bp->firmware);\n\tbp->firmware = NULL;\n}\n\nstatic struct bnx2x_func_sp_drv_ops bnx2x_func_sp_drv = {\n\t.init_hw_cmn_chip = bnx2x_init_hw_common_chip,\n\t.init_hw_cmn      = bnx2x_init_hw_common,\n\t.init_hw_port     = bnx2x_init_hw_port,\n\t.init_hw_func     = bnx2x_init_hw_func,\n\n\t.reset_hw_cmn     = bnx2x_reset_common,\n\t.reset_hw_port    = bnx2x_reset_port,\n\t.reset_hw_func    = bnx2x_reset_func,\n\n\t.gunzip_init      = bnx2x_gunzip_init,\n\t.gunzip_end       = bnx2x_gunzip_end,\n\n\t.init_fw          = bnx2x_init_firmware,\n\t.release_fw       = bnx2x_release_firmware,\n};\n\nvoid bnx2x__init_func_obj(struct bnx2x *bp)\n{\n\t \n\tbnx2x_setup_dmae(bp);\n\n\tbnx2x_init_func_obj(bp, &bp->func_obj,\n\t\t\t    bnx2x_sp(bp, func_rdata),\n\t\t\t    bnx2x_sp_mapping(bp, func_rdata),\n\t\t\t    bnx2x_sp(bp, func_afex_rdata),\n\t\t\t    bnx2x_sp_mapping(bp, func_afex_rdata),\n\t\t\t    &bnx2x_func_sp_drv);\n}\n\n \nstatic int bnx2x_set_qm_cid_count(struct bnx2x *bp)\n{\n\tint cid_count = BNX2X_L2_MAX_CID(bp);\n\n\tif (IS_SRIOV(bp))\n\t\tcid_count += BNX2X_VF_CIDS;\n\n\tif (CNIC_SUPPORT(bp))\n\t\tcid_count += CNIC_CID_MAX;\n\n\treturn roundup(cid_count, QM_CID_ROUND);\n}\n\n \nstatic int bnx2x_get_num_non_def_sbs(struct pci_dev *pdev, int cnic_cnt)\n{\n\tint index;\n\tu16 control = 0;\n\n\t \n\tif (!pdev->msix_cap) {\n\t\tdev_info(&pdev->dev, \"no msix capability found\\n\");\n\t\treturn 1 + cnic_cnt;\n\t}\n\tdev_info(&pdev->dev, \"msix capability found\\n\");\n\n\t \n\tpci_read_config_word(pdev, pdev->msix_cap + PCI_MSIX_FLAGS, &control);\n\n\tindex = control & PCI_MSIX_FLAGS_QSIZE;\n\n\treturn index;\n}\n\nstatic int set_max_cos_est(int chip_id)\n{\n\tswitch (chip_id) {\n\tcase BCM57710:\n\tcase BCM57711:\n\tcase BCM57711E:\n\t\treturn BNX2X_MULTI_TX_COS_E1X;\n\tcase BCM57712:\n\tcase BCM57712_MF:\n\t\treturn BNX2X_MULTI_TX_COS_E2_E3A0;\n\tcase BCM57800:\n\tcase BCM57800_MF:\n\tcase BCM57810:\n\tcase BCM57810_MF:\n\tcase BCM57840_4_10:\n\tcase BCM57840_2_20:\n\tcase BCM57840_O:\n\tcase BCM57840_MFO:\n\tcase BCM57840_MF:\n\tcase BCM57811:\n\tcase BCM57811_MF:\n\t\treturn BNX2X_MULTI_TX_COS_E3B0;\n\tcase BCM57712_VF:\n\tcase BCM57800_VF:\n\tcase BCM57810_VF:\n\tcase BCM57840_VF:\n\tcase BCM57811_VF:\n\t\treturn 1;\n\tdefault:\n\t\tpr_err(\"Unknown board_type (%d), aborting\\n\", chip_id);\n\t\treturn -ENODEV;\n\t}\n}\n\nstatic int set_is_vf(int chip_id)\n{\n\tswitch (chip_id) {\n\tcase BCM57712_VF:\n\tcase BCM57800_VF:\n\tcase BCM57810_VF:\n\tcase BCM57840_VF:\n\tcase BCM57811_VF:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \n#define tsgen_ctrl 0x0\n#define tsgen_freecount 0x10\n#define tsgen_synctime_t0 0x20\n#define tsgen_offset_t0 0x28\n#define tsgen_drift_t0 0x30\n#define tsgen_synctime_t1 0x58\n#define tsgen_offset_t1 0x60\n#define tsgen_drift_t1 0x68\n\n \nstatic int bnx2x_send_update_drift_ramrod(struct bnx2x *bp, int drift_dir,\n\t\t\t\t\t  int best_val, int best_period)\n{\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\tstruct bnx2x_func_set_timesync_params *set_timesync_params =\n\t\t&func_params.params.set_timesync;\n\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &func_params.ramrod_flags);\n\t__set_bit(RAMROD_RETRY, &func_params.ramrod_flags);\n\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_SET_TIMESYNC;\n\n\t \n\tset_timesync_params->drift_adjust_cmd = TS_DRIFT_ADJUST_SET;\n\tset_timesync_params->offset_cmd = TS_OFFSET_KEEP;\n\tset_timesync_params->add_sub_drift_adjust_value =\n\t\tdrift_dir ? TS_ADD_VALUE : TS_SUB_VALUE;\n\tset_timesync_params->drift_adjust_value = best_val;\n\tset_timesync_params->drift_adjust_period = best_period;\n\n\treturn bnx2x_func_state_change(bp, &func_params);\n}\n\nstatic int bnx2x_ptp_adjfine(struct ptp_clock_info *ptp, long scaled_ppm)\n{\n\tstruct bnx2x *bp = container_of(ptp, struct bnx2x, ptp_clock_info);\n\tint rc;\n\tint drift_dir = 1;\n\tint val, period, period1, period2, dif, dif1, dif2;\n\tint best_dif = BNX2X_MAX_PHC_DRIFT, best_period = 0, best_val = 0;\n\ts32 ppb = scaled_ppm_to_ppb(scaled_ppm);\n\n\tDP(BNX2X_MSG_PTP, \"PTP adjfine called, ppb = %d\\n\", ppb);\n\n\tif (!netif_running(bp->dev)) {\n\t\tDP(BNX2X_MSG_PTP,\n\t\t   \"PTP adjfine called while the interface is down\\n\");\n\t\treturn -ENETDOWN;\n\t}\n\n\tif (ppb < 0) {\n\t\tppb = -ppb;\n\t\tdrift_dir = 0;\n\t}\n\n\tif (ppb == 0) {\n\t\tbest_val = 1;\n\t\tbest_period = 0x1FFFFFF;\n\t} else if (ppb >= BNX2X_MAX_PHC_DRIFT) {\n\t\tbest_val = 31;\n\t\tbest_period = 1;\n\t} else {\n\t\t \n\t\tfor (val = 0; val <= 31; val++) {\n\t\t\tif ((val & 0x7) == 0)\n\t\t\t\tcontinue;\n\t\t\tperiod1 = val * 1000000 / ppb;\n\t\t\tperiod2 = period1 + 1;\n\t\t\tif (period1 != 0)\n\t\t\t\tdif1 = ppb - (val * 1000000 / period1);\n\t\t\telse\n\t\t\t\tdif1 = BNX2X_MAX_PHC_DRIFT;\n\t\t\tif (dif1 < 0)\n\t\t\t\tdif1 = -dif1;\n\t\t\tdif2 = ppb - (val * 1000000 / period2);\n\t\t\tif (dif2 < 0)\n\t\t\t\tdif2 = -dif2;\n\t\t\tdif = (dif1 < dif2) ? dif1 : dif2;\n\t\t\tperiod = (dif1 < dif2) ? period1 : period2;\n\t\t\tif (dif < best_dif) {\n\t\t\t\tbest_dif = dif;\n\t\t\t\tbest_val = val;\n\t\t\t\tbest_period = period;\n\t\t\t}\n\t\t}\n\t}\n\n\trc = bnx2x_send_update_drift_ramrod(bp, drift_dir, best_val,\n\t\t\t\t\t    best_period);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Failed to set drift\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tDP(BNX2X_MSG_PTP, \"Configured val = %d, period = %d\\n\", best_val,\n\t   best_period);\n\n\treturn 0;\n}\n\nstatic int bnx2x_ptp_adjtime(struct ptp_clock_info *ptp, s64 delta)\n{\n\tstruct bnx2x *bp = container_of(ptp, struct bnx2x, ptp_clock_info);\n\n\tif (!netif_running(bp->dev)) {\n\t\tDP(BNX2X_MSG_PTP,\n\t\t   \"PTP adjtime called while the interface is down\\n\");\n\t\treturn -ENETDOWN;\n\t}\n\n\tDP(BNX2X_MSG_PTP, \"PTP adjtime called, delta = %llx\\n\", delta);\n\n\ttimecounter_adjtime(&bp->timecounter, delta);\n\n\treturn 0;\n}\n\nstatic int bnx2x_ptp_gettime(struct ptp_clock_info *ptp, struct timespec64 *ts)\n{\n\tstruct bnx2x *bp = container_of(ptp, struct bnx2x, ptp_clock_info);\n\tu64 ns;\n\n\tif (!netif_running(bp->dev)) {\n\t\tDP(BNX2X_MSG_PTP,\n\t\t   \"PTP gettime called while the interface is down\\n\");\n\t\treturn -ENETDOWN;\n\t}\n\n\tns = timecounter_read(&bp->timecounter);\n\n\tDP(BNX2X_MSG_PTP, \"PTP gettime called, ns = %llu\\n\", ns);\n\n\t*ts = ns_to_timespec64(ns);\n\n\treturn 0;\n}\n\nstatic int bnx2x_ptp_settime(struct ptp_clock_info *ptp,\n\t\t\t     const struct timespec64 *ts)\n{\n\tstruct bnx2x *bp = container_of(ptp, struct bnx2x, ptp_clock_info);\n\tu64 ns;\n\n\tif (!netif_running(bp->dev)) {\n\t\tDP(BNX2X_MSG_PTP,\n\t\t   \"PTP settime called while the interface is down\\n\");\n\t\treturn -ENETDOWN;\n\t}\n\n\tns = timespec64_to_ns(ts);\n\n\tDP(BNX2X_MSG_PTP, \"PTP settime called, ns = %llu\\n\", ns);\n\n\t \n\ttimecounter_init(&bp->timecounter, &bp->cyclecounter, ns);\n\n\treturn 0;\n}\n\n \nstatic int bnx2x_ptp_enable(struct ptp_clock_info *ptp,\n\t\t\t    struct ptp_clock_request *rq, int on)\n{\n\tstruct bnx2x *bp = container_of(ptp, struct bnx2x, ptp_clock_info);\n\n\tBNX2X_ERR(\"PHC ancillary features are not supported\\n\");\n\treturn -ENOTSUPP;\n}\n\nvoid bnx2x_register_phc(struct bnx2x *bp)\n{\n\t \n\tbp->ptp_clock_info.owner = THIS_MODULE;\n\tsnprintf(bp->ptp_clock_info.name, 16, \"%s\", bp->dev->name);\n\tbp->ptp_clock_info.max_adj = BNX2X_MAX_PHC_DRIFT;  \n\tbp->ptp_clock_info.n_alarm = 0;\n\tbp->ptp_clock_info.n_ext_ts = 0;\n\tbp->ptp_clock_info.n_per_out = 0;\n\tbp->ptp_clock_info.pps = 0;\n\tbp->ptp_clock_info.adjfine = bnx2x_ptp_adjfine;\n\tbp->ptp_clock_info.adjtime = bnx2x_ptp_adjtime;\n\tbp->ptp_clock_info.gettime64 = bnx2x_ptp_gettime;\n\tbp->ptp_clock_info.settime64 = bnx2x_ptp_settime;\n\tbp->ptp_clock_info.enable = bnx2x_ptp_enable;\n\n\tbp->ptp_clock = ptp_clock_register(&bp->ptp_clock_info, &bp->pdev->dev);\n\tif (IS_ERR(bp->ptp_clock)) {\n\t\tbp->ptp_clock = NULL;\n\t\tBNX2X_ERR(\"PTP clock registration failed\\n\");\n\t}\n}\n\nstatic int bnx2x_init_one(struct pci_dev *pdev,\n\t\t\t\t    const struct pci_device_id *ent)\n{\n\tstruct net_device *dev = NULL;\n\tstruct bnx2x *bp;\n\tint rc, max_non_def_sbs;\n\tint rx_count, tx_count, rss_count, doorbell_size;\n\tint max_cos_est;\n\tbool is_vf;\n\tint cnic_cnt;\n\n\t \n\tif (is_kdump_kernel()) {\n\t\tktime_t now = ktime_get_boottime();\n\t\tktime_t fw_ready_time = ktime_set(5, 0);\n\n\t\tif (ktime_before(now, fw_ready_time))\n\t\t\tmsleep(ktime_ms_delta(fw_ready_time, now));\n\t}\n\n\t \n\tmax_cos_est = set_max_cos_est(ent->driver_data);\n\tif (max_cos_est < 0)\n\t\treturn max_cos_est;\n\tis_vf = set_is_vf(ent->driver_data);\n\tcnic_cnt = is_vf ? 0 : 1;\n\n\tmax_non_def_sbs = bnx2x_get_num_non_def_sbs(pdev, cnic_cnt);\n\n\t \n\tmax_non_def_sbs += is_vf ? 1 : 0;\n\n\t \n\trss_count = max_non_def_sbs - cnic_cnt;\n\n\tif (rss_count < 1)\n\t\treturn -EINVAL;\n\n\t \n\trx_count = rss_count + cnic_cnt;\n\n\t \n\ttx_count = rss_count * max_cos_est + cnic_cnt;\n\n\t \n\tdev = alloc_etherdev_mqs(sizeof(*bp), tx_count, rx_count);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tbp = netdev_priv(dev);\n\n\tbp->flags = 0;\n\tif (is_vf)\n\t\tbp->flags |= IS_VF_FLAG;\n\n\tbp->igu_sb_cnt = max_non_def_sbs;\n\tbp->igu_base_addr = IS_VF(bp) ? PXP_VF_ADDR_IGU_START : BAR_IGU_INTMEM;\n\tbp->msg_enable = debug;\n\tbp->cnic_support = cnic_cnt;\n\tbp->cnic_probe = bnx2x_cnic_probe;\n\n\tpci_set_drvdata(pdev, dev);\n\n\trc = bnx2x_init_dev(bp, pdev, dev, ent->driver_data);\n\tif (rc < 0) {\n\t\tfree_netdev(dev);\n\t\treturn rc;\n\t}\n\n\tBNX2X_DEV_INFO(\"This is a %s function\\n\",\n\t\t       IS_PF(bp) ? \"physical\" : \"virtual\");\n\tBNX2X_DEV_INFO(\"Cnic support is %s\\n\", CNIC_SUPPORT(bp) ? \"on\" : \"off\");\n\tBNX2X_DEV_INFO(\"Max num of status blocks %d\\n\", max_non_def_sbs);\n\tBNX2X_DEV_INFO(\"Allocated netdev with %d tx and %d rx queues\\n\",\n\t\t       tx_count, rx_count);\n\n\trc = bnx2x_init_bp(bp);\n\tif (rc)\n\t\tgoto init_one_exit;\n\n\t \n\tif (IS_VF(bp)) {\n\t\tbp->doorbells = bnx2x_vf_doorbells(bp);\n\t\trc = bnx2x_vf_pci_alloc(bp);\n\t\tif (rc)\n\t\t\tgoto init_one_freemem;\n\t} else {\n\t\tdoorbell_size = BNX2X_L2_MAX_CID(bp) * (1 << BNX2X_DB_SHIFT);\n\t\tif (doorbell_size > pci_resource_len(pdev, 2)) {\n\t\t\tdev_err(&bp->pdev->dev,\n\t\t\t\t\"Cannot map doorbells, bar size too small, aborting\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto init_one_freemem;\n\t\t}\n\t\tbp->doorbells = ioremap(pci_resource_start(pdev, 2),\n\t\t\t\t\t\tdoorbell_size);\n\t}\n\tif (!bp->doorbells) {\n\t\tdev_err(&bp->pdev->dev,\n\t\t\t\"Cannot map doorbell space, aborting\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto init_one_freemem;\n\t}\n\n\tif (IS_VF(bp)) {\n\t\trc = bnx2x_vfpf_acquire(bp, tx_count, rx_count);\n\t\tif (rc)\n\t\t\tgoto init_one_freemem;\n\n#ifdef CONFIG_BNX2X_SRIOV\n\t\t \n\t\tif (bp->acquire_resp.pfdev_info.pf_cap & PFVF_CAP_VLAN_FILTER) {\n\t\t\tdev->hw_features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\t\t\tdev->features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\t\t}\n#endif\n\t}\n\n\t \n\trc = bnx2x_iov_init_one(bp, int_mode, BNX2X_MAX_NUM_OF_VFS);\n\tif (rc)\n\t\tgoto init_one_freemem;\n\n\t \n\tbp->qm_cid_count = bnx2x_set_qm_cid_count(bp);\n\tBNX2X_DEV_INFO(\"qm_cid_count %d\\n\", bp->qm_cid_count);\n\n\t \n\tif (CHIP_IS_E1x(bp))\n\t\tbp->flags |= NO_FCOE_FLAG;\n\n\t \n\tbnx2x_set_num_queues(bp);\n\n\t \n\trc = bnx2x_set_int_mode(bp);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Cannot set interrupts\\n\");\n\t\tgoto init_one_freemem;\n\t}\n\tBNX2X_DEV_INFO(\"set interrupts successfully\\n\");\n\n\t \n\trc = register_netdev(dev);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Cannot register net device\\n\");\n\t\tgoto init_one_freemem;\n\t}\n\tBNX2X_DEV_INFO(\"device name after netdev register %s\\n\", dev->name);\n\n\tif (!NO_FCOE(bp)) {\n\t\t \n\t\trtnl_lock();\n\t\tdev_addr_add(bp->dev, bp->fip_mac, NETDEV_HW_ADDR_T_SAN);\n\t\trtnl_unlock();\n\t}\n\tBNX2X_DEV_INFO(\n\t       \"%s (%c%d) PCI-E found at mem %lx, IRQ %d, node addr %pM\\n\",\n\t       board_info[ent->driver_data].name,\n\t       (CHIP_REV(bp) >> 12) + 'A', (CHIP_METAL(bp) >> 4),\n\t       dev->base_addr, bp->pdev->irq, dev->dev_addr);\n\tpcie_print_link_status(bp->pdev);\n\n\tif (!IS_MF_SD_STORAGE_PERSONALITY_ONLY(bp))\n\t\tbnx2x_set_os_driver_state(bp, OS_DRIVER_STATE_DISABLED);\n\n\treturn 0;\n\ninit_one_freemem:\n\tbnx2x_free_mem_bp(bp);\n\ninit_one_exit:\n\tif (bp->regview)\n\t\tiounmap(bp->regview);\n\n\tif (IS_PF(bp) && bp->doorbells)\n\t\tiounmap(bp->doorbells);\n\n\tfree_netdev(dev);\n\n\tif (atomic_read(&pdev->enable_cnt) == 1)\n\t\tpci_release_regions(pdev);\n\n\tpci_disable_device(pdev);\n\n\treturn rc;\n}\n\nstatic void __bnx2x_remove(struct pci_dev *pdev,\n\t\t\t   struct net_device *dev,\n\t\t\t   struct bnx2x *bp,\n\t\t\t   bool remove_netdev)\n{\n\t \n\tif (!NO_FCOE(bp)) {\n\t\trtnl_lock();\n\t\tdev_addr_del(bp->dev, bp->fip_mac, NETDEV_HW_ADDR_T_SAN);\n\t\trtnl_unlock();\n\t}\n\n#ifdef BCM_DCBNL\n\t \n\tbnx2x_dcbnl_update_applist(bp, true);\n#endif\n\n\tif (IS_PF(bp) &&\n\t    !BP_NOMCP(bp) &&\n\t    (bp->flags & BC_SUPPORTS_RMMOD_CMD))\n\t\tbnx2x_fw_command(bp, DRV_MSG_CODE_RMMOD, 0);\n\n\t \n\tif (remove_netdev) {\n\t\tunregister_netdev(dev);\n\t} else {\n\t\trtnl_lock();\n\t\tdev_close(dev);\n\t\trtnl_unlock();\n\t}\n\n\tbnx2x_iov_remove_one(bp);\n\n\t \n\tif (IS_PF(bp)) {\n\t\tbnx2x_set_power_state(bp, PCI_D0);\n\t\tbnx2x_set_os_driver_state(bp, OS_DRIVER_STATE_NOT_LOADED);\n\n\t\t \n\t\tbnx2x_reset_endianity(bp);\n\t}\n\n\t \n\tbnx2x_disable_msi(bp);\n\n\t \n\tif (IS_PF(bp))\n\t\tbnx2x_set_power_state(bp, PCI_D3hot);\n\n\t \n\tcancel_delayed_work_sync(&bp->sp_rtnl_task);\n\n\t \n\tif (IS_VF(bp))\n\t\tbnx2x_vfpf_release(bp);\n\n\t \n\tif (system_state == SYSTEM_POWER_OFF) {\n\t\tpci_wake_from_d3(pdev, bp->wol);\n\t\tpci_set_power_state(pdev, PCI_D3hot);\n\t}\n\n\tif (remove_netdev) {\n\t\tif (bp->regview)\n\t\t\tiounmap(bp->regview);\n\n\t\t \n\t\tif (IS_PF(bp)) {\n\t\t\tif (bp->doorbells)\n\t\t\t\tiounmap(bp->doorbells);\n\n\t\t\tbnx2x_release_firmware(bp);\n\t\t} else {\n\t\t\tbnx2x_vf_pci_dealloc(bp);\n\t\t}\n\t\tbnx2x_free_mem_bp(bp);\n\n\t\tfree_netdev(dev);\n\n\t\tif (atomic_read(&pdev->enable_cnt) == 1)\n\t\t\tpci_release_regions(pdev);\n\n\t\tpci_disable_device(pdev);\n\t}\n}\n\nstatic void bnx2x_remove_one(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct bnx2x *bp;\n\n\tif (!dev) {\n\t\tdev_err(&pdev->dev, \"BAD net device from bnx2x_init_one\\n\");\n\t\treturn;\n\t}\n\tbp = netdev_priv(dev);\n\n\t__bnx2x_remove(pdev, dev, bp, true);\n}\n\nstatic int bnx2x_eeh_nic_unload(struct bnx2x *bp)\n{\n\tbp->state = BNX2X_STATE_CLOSING_WAIT4_HALT;\n\n\tbp->rx_mode = BNX2X_RX_MODE_NONE;\n\n\tif (CNIC_LOADED(bp))\n\t\tbnx2x_cnic_notify(bp, CNIC_CTL_STOP_CMD);\n\n\t \n\tbnx2x_tx_disable(bp);\n\tnetdev_reset_tc(bp->dev);\n\n\tdel_timer_sync(&bp->timer);\n\tcancel_delayed_work_sync(&bp->sp_task);\n\tcancel_delayed_work_sync(&bp->period_task);\n\n\tif (!down_timeout(&bp->stats_lock, HZ / 10)) {\n\t\tbp->stats_state = STATS_STATE_DISABLED;\n\t\tup(&bp->stats_lock);\n\t}\n\n\tbnx2x_save_statistics(bp);\n\n\tnetif_carrier_off(bp->dev);\n\n\treturn 0;\n}\n\n \nstatic pci_ers_result_t bnx2x_io_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\tpci_channel_state_t state)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct bnx2x *bp = netdev_priv(dev);\n\n\trtnl_lock();\n\n\tBNX2X_ERR(\"IO error detected\\n\");\n\n\tnetif_device_detach(dev);\n\n\tif (state == pci_channel_io_perm_failure) {\n\t\trtnl_unlock();\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tif (netif_running(dev))\n\t\tbnx2x_eeh_nic_unload(bp);\n\n\tbnx2x_prev_path_mark_eeh(bp);\n\n\tpci_disable_device(pdev);\n\n\trtnl_unlock();\n\n\t \n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\n \nstatic pci_ers_result_t bnx2x_io_slot_reset(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tint i;\n\n\trtnl_lock();\n\tBNX2X_ERR(\"IO slot reset initializing...\\n\");\n\tif (pci_enable_device(pdev)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Cannot re-enable PCI device after reset\\n\");\n\t\trtnl_unlock();\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\n\tpci_set_master(pdev);\n\tpci_restore_state(pdev);\n\tpci_save_state(pdev);\n\n\tif (netif_running(dev))\n\t\tbnx2x_set_power_state(bp, PCI_D0);\n\n\tif (netif_running(dev)) {\n\t\tBNX2X_ERR(\"IO slot reset --> driver unload\\n\");\n\n\t\t \n\t\tif (bnx2x_init_shmem(bp)) {\n\t\t\trtnl_unlock();\n\t\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t\t}\n\n\t\tif (IS_PF(bp) && SHMEM2_HAS(bp, drv_capabilities_flag)) {\n\t\t\tu32 v;\n\n\t\t\tv = SHMEM2_RD(bp,\n\t\t\t\t      drv_capabilities_flag[BP_FW_MB_IDX(bp)]);\n\t\t\tSHMEM2_WR(bp, drv_capabilities_flag[BP_FW_MB_IDX(bp)],\n\t\t\t\t  v & ~DRV_FLAGS_CAPABILITIES_LOADED_L2);\n\t\t}\n\t\tbnx2x_drain_tx_queues(bp);\n\t\tbnx2x_send_unload_req(bp, UNLOAD_RECOVERY);\n\t\tif (!bp->nic_stopped) {\n\t\t\tbnx2x_netif_stop(bp, 1);\n\t\t\tbnx2x_del_all_napi(bp);\n\n\t\t\tif (CNIC_LOADED(bp))\n\t\t\t\tbnx2x_del_all_napi_cnic(bp);\n\n\t\t\tbnx2x_free_irq(bp);\n\t\t\tbp->nic_stopped = true;\n\t\t}\n\n\t\t \n\t\tbnx2x_send_unload_done(bp, true);\n\n\t\tbp->sp_state = 0;\n\t\tbp->port.pmf = 0;\n\n\t\tbnx2x_prev_unload(bp);\n\n\t\t \n\t\tbnx2x_squeeze_objects(bp);\n\t\tbnx2x_free_skbs(bp);\n\t\tfor_each_rx_queue(bp, i)\n\t\t\tbnx2x_free_rx_sge_range(bp, bp->fp + i, NUM_RX_SGE);\n\t\tbnx2x_free_fp_mem(bp);\n\t\tbnx2x_free_mem(bp);\n\n\t\tbp->state = BNX2X_STATE_CLOSED;\n\t}\n\n\trtnl_unlock();\n\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\n \nstatic void bnx2x_io_resume(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct bnx2x *bp = netdev_priv(dev);\n\n\tif (bp->recovery_state != BNX2X_RECOVERY_DONE) {\n\t\tnetdev_err(bp->dev, \"Handling parity error recovery. Try again later\\n\");\n\t\treturn;\n\t}\n\n\trtnl_lock();\n\n\tbp->fw_seq = SHMEM_RD(bp, func_mb[BP_FW_MB_IDX(bp)].drv_mb_header) &\n\t\t\t\t\t\t\tDRV_MSG_SEQ_NUMBER_MASK;\n\n\tif (netif_running(dev)) {\n\t\tif (bnx2x_nic_load(bp, LOAD_NORMAL)) {\n\t\t\tnetdev_err(bp->dev, \"Error during driver initialization, try unloading/reloading the driver\\n\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tnetif_device_attach(dev);\n\ndone:\n\trtnl_unlock();\n}\n\nstatic const struct pci_error_handlers bnx2x_err_handler = {\n\t.error_detected = bnx2x_io_error_detected,\n\t.slot_reset     = bnx2x_io_slot_reset,\n\t.resume         = bnx2x_io_resume,\n};\n\nstatic void bnx2x_shutdown(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct bnx2x *bp;\n\n\tif (!dev)\n\t\treturn;\n\n\tbp = netdev_priv(dev);\n\tif (!bp)\n\t\treturn;\n\n\trtnl_lock();\n\tnetif_device_detach(dev);\n\trtnl_unlock();\n\n\t \n\t__bnx2x_remove(pdev, dev, bp, false);\n}\n\nstatic struct pci_driver bnx2x_pci_driver = {\n\t.name        = DRV_MODULE_NAME,\n\t.id_table    = bnx2x_pci_tbl,\n\t.probe       = bnx2x_init_one,\n\t.remove      = bnx2x_remove_one,\n\t.driver.pm   = &bnx2x_pm_ops,\n\t.err_handler = &bnx2x_err_handler,\n#ifdef CONFIG_BNX2X_SRIOV\n\t.sriov_configure = bnx2x_sriov_configure,\n#endif\n\t.shutdown    = bnx2x_shutdown,\n};\n\nstatic int __init bnx2x_init(void)\n{\n\tint ret;\n\n\tbnx2x_wq = create_singlethread_workqueue(\"bnx2x\");\n\tif (bnx2x_wq == NULL) {\n\t\tpr_err(\"Cannot create workqueue\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tbnx2x_iov_wq = create_singlethread_workqueue(\"bnx2x_iov\");\n\tif (!bnx2x_iov_wq) {\n\t\tpr_err(\"Cannot create iov workqueue\\n\");\n\t\tdestroy_workqueue(bnx2x_wq);\n\t\treturn -ENOMEM;\n\t}\n\n\tret = pci_register_driver(&bnx2x_pci_driver);\n\tif (ret) {\n\t\tpr_err(\"Cannot register driver\\n\");\n\t\tdestroy_workqueue(bnx2x_wq);\n\t\tdestroy_workqueue(bnx2x_iov_wq);\n\t}\n\treturn ret;\n}\n\nstatic void __exit bnx2x_cleanup(void)\n{\n\tstruct list_head *pos, *q;\n\n\tpci_unregister_driver(&bnx2x_pci_driver);\n\n\tdestroy_workqueue(bnx2x_wq);\n\tdestroy_workqueue(bnx2x_iov_wq);\n\n\t \n\tlist_for_each_safe(pos, q, &bnx2x_prev_list) {\n\t\tstruct bnx2x_prev_path_list *tmp =\n\t\t\tlist_entry(pos, struct bnx2x_prev_path_list, list);\n\t\tlist_del(pos);\n\t\tkfree(tmp);\n\t}\n}\n\nvoid bnx2x_notify_link_changed(struct bnx2x *bp)\n{\n\tREG_WR(bp, MISC_REG_AEU_GENERAL_ATTN_12 + BP_FUNC(bp)*sizeof(u32), 1);\n}\n\nmodule_init(bnx2x_init);\nmodule_exit(bnx2x_cleanup);\n\n \nstatic int bnx2x_set_iscsi_eth_mac_addr(struct bnx2x *bp)\n{\n\tunsigned long ramrod_flags = 0;\n\n\t__set_bit(RAMROD_COMP_WAIT, &ramrod_flags);\n\treturn bnx2x_set_mac_one(bp, bp->cnic_eth_dev.iscsi_mac,\n\t\t\t\t &bp->iscsi_l2_mac_obj, true,\n\t\t\t\t BNX2X_ISCSI_ETH_MAC, &ramrod_flags);\n}\n\n \nstatic void bnx2x_cnic_sp_post(struct bnx2x *bp, int count)\n{\n\tstruct eth_spe *spe;\n\tint cxt_index, cxt_offset;\n\n#ifdef BNX2X_STOP_ON_ERROR\n\tif (unlikely(bp->panic))\n\t\treturn;\n#endif\n\n\tspin_lock_bh(&bp->spq_lock);\n\tBUG_ON(bp->cnic_spq_pending < count);\n\tbp->cnic_spq_pending -= count;\n\n\tfor (; bp->cnic_kwq_pending; bp->cnic_kwq_pending--) {\n\t\tu16 type =  (le16_to_cpu(bp->cnic_kwq_cons->hdr.type)\n\t\t\t\t& SPE_HDR_CONN_TYPE) >>\n\t\t\t\tSPE_HDR_CONN_TYPE_SHIFT;\n\t\tu8 cmd = (le32_to_cpu(bp->cnic_kwq_cons->hdr.conn_and_cmd_data)\n\t\t\t\t>> SPE_HDR_CMD_ID_SHIFT) & 0xff;\n\n\t\t \n\t\tif (type == ETH_CONNECTION_TYPE) {\n\t\t\tif (cmd == RAMROD_CMD_ID_ETH_CLIENT_SETUP) {\n\t\t\t\tcxt_index = BNX2X_ISCSI_ETH_CID(bp) /\n\t\t\t\t\tILT_PAGE_CIDS;\n\t\t\t\tcxt_offset = BNX2X_ISCSI_ETH_CID(bp) -\n\t\t\t\t\t(cxt_index * ILT_PAGE_CIDS);\n\t\t\t\tbnx2x_set_ctx_validation(bp,\n\t\t\t\t\t&bp->context[cxt_index].\n\t\t\t\t\t\t\t vcxt[cxt_offset].eth,\n\t\t\t\t\tBNX2X_ISCSI_ETH_CID(bp));\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (type == ETH_CONNECTION_TYPE) {\n\t\t\tif (!atomic_read(&bp->cq_spq_left))\n\t\t\t\tbreak;\n\t\t\telse\n\t\t\t\tatomic_dec(&bp->cq_spq_left);\n\t\t} else if (type == NONE_CONNECTION_TYPE) {\n\t\t\tif (!atomic_read(&bp->eq_spq_left))\n\t\t\t\tbreak;\n\t\t\telse\n\t\t\t\tatomic_dec(&bp->eq_spq_left);\n\t\t} else if ((type == ISCSI_CONNECTION_TYPE) ||\n\t\t\t   (type == FCOE_CONNECTION_TYPE)) {\n\t\t\tif (bp->cnic_spq_pending >=\n\t\t\t    bp->cnic_eth_dev.max_kwqe_pending)\n\t\t\t\tbreak;\n\t\t\telse\n\t\t\t\tbp->cnic_spq_pending++;\n\t\t} else {\n\t\t\tBNX2X_ERR(\"Unknown SPE type: %d\\n\", type);\n\t\t\tbnx2x_panic();\n\t\t\tbreak;\n\t\t}\n\n\t\tspe = bnx2x_sp_get_next(bp);\n\t\t*spe = *bp->cnic_kwq_cons;\n\n\t\tDP(BNX2X_MSG_SP, \"pending on SPQ %d, on KWQ %d count %d\\n\",\n\t\t   bp->cnic_spq_pending, bp->cnic_kwq_pending, count);\n\n\t\tif (bp->cnic_kwq_cons == bp->cnic_kwq_last)\n\t\t\tbp->cnic_kwq_cons = bp->cnic_kwq;\n\t\telse\n\t\t\tbp->cnic_kwq_cons++;\n\t}\n\tbnx2x_sp_prod_update(bp);\n\tspin_unlock_bh(&bp->spq_lock);\n}\n\nstatic int bnx2x_cnic_sp_queue(struct net_device *dev,\n\t\t\t       struct kwqe_16 *kwqes[], u32 count)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tint i;\n\n#ifdef BNX2X_STOP_ON_ERROR\n\tif (unlikely(bp->panic)) {\n\t\tBNX2X_ERR(\"Can't post to SP queue while panic\\n\");\n\t\treturn -EIO;\n\t}\n#endif\n\n\tif ((bp->recovery_state != BNX2X_RECOVERY_DONE) &&\n\t    (bp->recovery_state != BNX2X_RECOVERY_NIC_LOADING)) {\n\t\tBNX2X_ERR(\"Handling parity error recovery. Try again later\\n\");\n\t\treturn -EAGAIN;\n\t}\n\n\tspin_lock_bh(&bp->spq_lock);\n\n\tfor (i = 0; i < count; i++) {\n\t\tstruct eth_spe *spe = (struct eth_spe *)kwqes[i];\n\n\t\tif (bp->cnic_kwq_pending == MAX_SP_DESC_CNT)\n\t\t\tbreak;\n\n\t\t*bp->cnic_kwq_prod = *spe;\n\n\t\tbp->cnic_kwq_pending++;\n\n\t\tDP(BNX2X_MSG_SP, \"L5 SPQE %x %x %x:%x pos %d\\n\",\n\t\t   spe->hdr.conn_and_cmd_data, spe->hdr.type,\n\t\t   spe->data.update_data_addr.hi,\n\t\t   spe->data.update_data_addr.lo,\n\t\t   bp->cnic_kwq_pending);\n\n\t\tif (bp->cnic_kwq_prod == bp->cnic_kwq_last)\n\t\t\tbp->cnic_kwq_prod = bp->cnic_kwq;\n\t\telse\n\t\t\tbp->cnic_kwq_prod++;\n\t}\n\n\tspin_unlock_bh(&bp->spq_lock);\n\n\tif (bp->cnic_spq_pending < bp->cnic_eth_dev.max_kwqe_pending)\n\t\tbnx2x_cnic_sp_post(bp, 0);\n\n\treturn i;\n}\n\nstatic int bnx2x_cnic_ctl_send(struct bnx2x *bp, struct cnic_ctl_info *ctl)\n{\n\tstruct cnic_ops *c_ops;\n\tint rc = 0;\n\n\tmutex_lock(&bp->cnic_mutex);\n\tc_ops = rcu_dereference_protected(bp->cnic_ops,\n\t\t\t\t\t  lockdep_is_held(&bp->cnic_mutex));\n\tif (c_ops)\n\t\trc = c_ops->cnic_ctl(bp->cnic_data, ctl);\n\tmutex_unlock(&bp->cnic_mutex);\n\n\treturn rc;\n}\n\nstatic int bnx2x_cnic_ctl_send_bh(struct bnx2x *bp, struct cnic_ctl_info *ctl)\n{\n\tstruct cnic_ops *c_ops;\n\tint rc = 0;\n\n\trcu_read_lock();\n\tc_ops = rcu_dereference(bp->cnic_ops);\n\tif (c_ops)\n\t\trc = c_ops->cnic_ctl(bp->cnic_data, ctl);\n\trcu_read_unlock();\n\n\treturn rc;\n}\n\n \nint bnx2x_cnic_notify(struct bnx2x *bp, int cmd)\n{\n\tstruct cnic_ctl_info ctl = {0};\n\n\tctl.cmd = cmd;\n\n\treturn bnx2x_cnic_ctl_send(bp, &ctl);\n}\n\nstatic void bnx2x_cnic_cfc_comp(struct bnx2x *bp, int cid, u8 err)\n{\n\tstruct cnic_ctl_info ctl = {0};\n\n\t \n\tctl.cmd = CNIC_CTL_COMPLETION_CMD;\n\tctl.data.comp.cid = cid;\n\tctl.data.comp.error = err;\n\n\tbnx2x_cnic_ctl_send_bh(bp, &ctl);\n\tbnx2x_cnic_sp_post(bp, 0);\n}\n\n \nstatic void bnx2x_set_iscsi_eth_rx_mode(struct bnx2x *bp, bool start)\n{\n\tunsigned long accept_flags = 0, ramrod_flags = 0;\n\tu8 cl_id = bnx2x_cnic_eth_cl_id(bp, BNX2X_ISCSI_ETH_CL_ID_IDX);\n\tint sched_state = BNX2X_FILTER_ISCSI_ETH_STOP_SCHED;\n\n\tif (start) {\n\t\t \n\t\t__set_bit(BNX2X_ACCEPT_UNICAST, &accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_ALL_MULTICAST, &accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_BROADCAST, &accept_flags);\n\t\t__set_bit(BNX2X_ACCEPT_ANY_VLAN, &accept_flags);\n\n\t\t \n\t\tclear_bit(BNX2X_FILTER_ISCSI_ETH_STOP_SCHED, &bp->sp_state);\n\n\t\tsched_state = BNX2X_FILTER_ISCSI_ETH_START_SCHED;\n\t} else\n\t\t \n\t\tclear_bit(BNX2X_FILTER_ISCSI_ETH_START_SCHED, &bp->sp_state);\n\n\tif (test_bit(BNX2X_FILTER_RX_MODE_PENDING, &bp->sp_state))\n\t\tset_bit(sched_state, &bp->sp_state);\n\telse {\n\t\t__set_bit(RAMROD_RX, &ramrod_flags);\n\t\tbnx2x_set_q_rx_mode(bp, cl_id, 0, accept_flags, 0,\n\t\t\t\t    ramrod_flags);\n\t}\n}\n\nstatic int bnx2x_drv_ctl(struct net_device *dev, struct drv_ctl_info *ctl)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tint rc = 0;\n\n\tswitch (ctl->cmd) {\n\tcase DRV_CTL_CTXTBL_WR_CMD: {\n\t\tu32 index = ctl->data.io.offset;\n\t\tdma_addr_t addr = ctl->data.io.dma_addr;\n\n\t\tbnx2x_ilt_wr(bp, index, addr);\n\t\tbreak;\n\t}\n\n\tcase DRV_CTL_RET_L5_SPQ_CREDIT_CMD: {\n\t\tint count = ctl->data.credit.credit_count;\n\n\t\tbnx2x_cnic_sp_post(bp, count);\n\t\tbreak;\n\t}\n\n\t \n\tcase DRV_CTL_START_L2_CMD: {\n\t\tstruct cnic_eth_dev *cp = &bp->cnic_eth_dev;\n\t\tunsigned long sp_bits = 0;\n\n\t\t \n\t\tbnx2x_init_mac_obj(bp, &bp->iscsi_l2_mac_obj,\n\t\t\t\t   cp->iscsi_l2_client_id,\n\t\t\t\t   cp->iscsi_l2_cid, BP_FUNC(bp),\n\t\t\t\t   bnx2x_sp(bp, mac_rdata),\n\t\t\t\t   bnx2x_sp_mapping(bp, mac_rdata),\n\t\t\t\t   BNX2X_FILTER_MAC_PENDING,\n\t\t\t\t   &bp->sp_state, BNX2X_OBJ_TYPE_RX,\n\t\t\t\t   &bp->macs_pool);\n\n\t\t \n\t\trc = bnx2x_set_iscsi_eth_mac_addr(bp);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tbarrier();\n\n\t\t \n\n\t\tnetif_addr_lock_bh(dev);\n\t\tbnx2x_set_iscsi_eth_rx_mode(bp, true);\n\t\tnetif_addr_unlock_bh(dev);\n\n\t\t \n\t\t__set_bit(BNX2X_FILTER_RX_MODE_PENDING, &sp_bits);\n\t\t__set_bit(BNX2X_FILTER_ISCSI_ETH_START_SCHED, &sp_bits);\n\n\t\tif (!bnx2x_wait_sp_comp(bp, sp_bits))\n\t\t\tBNX2X_ERR(\"rx_mode completion timed out!\\n\");\n\n\t\tbreak;\n\t}\n\n\t \n\tcase DRV_CTL_STOP_L2_CMD: {\n\t\tunsigned long sp_bits = 0;\n\n\t\t \n\t\tnetif_addr_lock_bh(dev);\n\t\tbnx2x_set_iscsi_eth_rx_mode(bp, false);\n\t\tnetif_addr_unlock_bh(dev);\n\n\t\t \n\t\t__set_bit(BNX2X_FILTER_RX_MODE_PENDING, &sp_bits);\n\t\t__set_bit(BNX2X_FILTER_ISCSI_ETH_STOP_SCHED, &sp_bits);\n\n\t\tif (!bnx2x_wait_sp_comp(bp, sp_bits))\n\t\t\tBNX2X_ERR(\"rx_mode completion timed out!\\n\");\n\n\t\tbarrier();\n\n\t\t \n\t\trc = bnx2x_del_all_macs(bp, &bp->iscsi_l2_mac_obj,\n\t\t\t\t\tBNX2X_ISCSI_ETH_MAC, true);\n\t\tbreak;\n\t}\n\tcase DRV_CTL_RET_L2_SPQ_CREDIT_CMD: {\n\t\tint count = ctl->data.credit.credit_count;\n\n\t\tsmp_mb__before_atomic();\n\t\tatomic_add(count, &bp->cq_spq_left);\n\t\tsmp_mb__after_atomic();\n\t\tbreak;\n\t}\n\tcase DRV_CTL_ULP_REGISTER_CMD: {\n\t\tint ulp_type = ctl->data.register_data.ulp_type;\n\n\t\tif (CHIP_IS_E3(bp)) {\n\t\t\tint idx = BP_FW_MB_IDX(bp);\n\t\t\tu32 cap = SHMEM2_RD(bp, drv_capabilities_flag[idx]);\n\t\t\tint path = BP_PATH(bp);\n\t\t\tint port = BP_PORT(bp);\n\t\t\tint i;\n\t\t\tu32 scratch_offset;\n\t\t\tu32 *host_addr;\n\n\t\t\t \n\t\t\tif (ulp_type == CNIC_ULP_ISCSI)\n\t\t\t\tcap |= DRV_FLAGS_CAPABILITIES_LOADED_ISCSI;\n\t\t\telse if (ulp_type == CNIC_ULP_FCOE)\n\t\t\t\tcap |= DRV_FLAGS_CAPABILITIES_LOADED_FCOE;\n\t\t\tSHMEM2_WR(bp, drv_capabilities_flag[idx], cap);\n\n\t\t\tif ((ulp_type != CNIC_ULP_FCOE) ||\n\t\t\t    (!SHMEM2_HAS(bp, ncsi_oem_data_addr)) ||\n\t\t\t    (!(bp->flags &  BC_SUPPORTS_FCOE_FEATURES)))\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tscratch_offset = SHMEM2_RD(bp, ncsi_oem_data_addr);\n\t\t\tif (!scratch_offset)\n\t\t\t\tbreak;\n\t\t\tscratch_offset += offsetof(struct glob_ncsi_oem_data,\n\t\t\t\t\t\t   fcoe_features[path][port]);\n\t\t\thost_addr = (u32 *) &(ctl->data.register_data.\n\t\t\t\t\t      fcoe_features);\n\t\t\tfor (i = 0; i < sizeof(struct fcoe_capabilities);\n\t\t\t     i += 4)\n\t\t\t\tREG_WR(bp, scratch_offset + i,\n\t\t\t\t       *(host_addr + i/4));\n\t\t}\n\t\tbnx2x_schedule_sp_rtnl(bp, BNX2X_SP_RTNL_GET_DRV_VERSION, 0);\n\t\tbreak;\n\t}\n\n\tcase DRV_CTL_ULP_UNREGISTER_CMD: {\n\t\tint ulp_type = ctl->data.ulp_type;\n\n\t\tif (CHIP_IS_E3(bp)) {\n\t\t\tint idx = BP_FW_MB_IDX(bp);\n\t\t\tu32 cap;\n\n\t\t\tcap = SHMEM2_RD(bp, drv_capabilities_flag[idx]);\n\t\t\tif (ulp_type == CNIC_ULP_ISCSI)\n\t\t\t\tcap &= ~DRV_FLAGS_CAPABILITIES_LOADED_ISCSI;\n\t\t\telse if (ulp_type == CNIC_ULP_FCOE)\n\t\t\t\tcap &= ~DRV_FLAGS_CAPABILITIES_LOADED_FCOE;\n\t\t\tSHMEM2_WR(bp, drv_capabilities_flag[idx], cap);\n\t\t}\n\t\tbnx2x_schedule_sp_rtnl(bp, BNX2X_SP_RTNL_GET_DRV_VERSION, 0);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tBNX2X_ERR(\"unknown command %x\\n\", ctl->cmd);\n\t\trc = -EINVAL;\n\t}\n\n\t \n\tif (IS_MF_SD_STORAGE_PERSONALITY_ONLY(bp)) {\n\t\tswitch (ctl->drv_state) {\n\t\tcase DRV_NOP:\n\t\t\tbreak;\n\t\tcase DRV_ACTIVE:\n\t\t\tbnx2x_set_os_driver_state(bp,\n\t\t\t\t\t\t  OS_DRIVER_STATE_ACTIVE);\n\t\t\tbreak;\n\t\tcase DRV_INACTIVE:\n\t\t\tbnx2x_set_os_driver_state(bp,\n\t\t\t\t\t\t  OS_DRIVER_STATE_DISABLED);\n\t\t\tbreak;\n\t\tcase DRV_UNLOADED:\n\t\t\tbnx2x_set_os_driver_state(bp,\n\t\t\t\t\t\t  OS_DRIVER_STATE_NOT_LOADED);\n\t\t\tbreak;\n\t\tdefault:\n\t\tBNX2X_ERR(\"Unknown cnic driver state: %d\\n\", ctl->drv_state);\n\t\t}\n\t}\n\n\treturn rc;\n}\n\nstatic int bnx2x_get_fc_npiv(struct net_device *dev,\n\t\t\t     struct cnic_fc_npiv_tbl *cnic_tbl)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tstruct bdn_fc_npiv_tbl *tbl = NULL;\n\tu32 offset, entries;\n\tint rc = -EINVAL;\n\tint i;\n\n\tif (!SHMEM2_HAS(bp, fc_npiv_nvram_tbl_addr[0]))\n\t\tgoto out;\n\n\tDP(BNX2X_MSG_MCP, \"About to read the FC-NPIV table\\n\");\n\n\ttbl = kmalloc(sizeof(*tbl), GFP_KERNEL);\n\tif (!tbl) {\n\t\tBNX2X_ERR(\"Failed to allocate fc_npiv table\\n\");\n\t\tgoto out;\n\t}\n\n\toffset = SHMEM2_RD(bp, fc_npiv_nvram_tbl_addr[BP_PORT(bp)]);\n\tif (!offset) {\n\t\tDP(BNX2X_MSG_MCP, \"No FC-NPIV in NVRAM\\n\");\n\t\tgoto out;\n\t}\n\tDP(BNX2X_MSG_MCP, \"Offset of FC-NPIV in NVRAM: %08x\\n\", offset);\n\n\t \n\tif (bnx2x_nvram_read(bp, offset, (u8 *)tbl, sizeof(*tbl))) {\n\t\tBNX2X_ERR(\"Failed to read FC-NPIV table\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\tentries = tbl->fc_npiv_cfg.num_of_npiv;\n\tentries = (__force u32)be32_to_cpu((__force __be32)entries);\n\ttbl->fc_npiv_cfg.num_of_npiv = entries;\n\n\tif (!tbl->fc_npiv_cfg.num_of_npiv) {\n\t\tDP(BNX2X_MSG_MCP,\n\t\t   \"No FC-NPIV table [valid, simply not present]\\n\");\n\t\tgoto out;\n\t} else if (tbl->fc_npiv_cfg.num_of_npiv > MAX_NUMBER_NPIV) {\n\t\tBNX2X_ERR(\"FC-NPIV table with bad length 0x%08x\\n\",\n\t\t\t  tbl->fc_npiv_cfg.num_of_npiv);\n\t\tgoto out;\n\t} else {\n\t\tDP(BNX2X_MSG_MCP, \"Read 0x%08x entries from NVRAM\\n\",\n\t\t   tbl->fc_npiv_cfg.num_of_npiv);\n\t}\n\n\t \n\tcnic_tbl->count = tbl->fc_npiv_cfg.num_of_npiv;\n\tfor (i = 0; i < cnic_tbl->count; i++) {\n\t\tmemcpy(cnic_tbl->wwpn[i], tbl->settings[i].npiv_wwpn, 8);\n\t\tmemcpy(cnic_tbl->wwnn[i], tbl->settings[i].npiv_wwnn, 8);\n\t}\n\n\trc = 0;\nout:\n\tkfree(tbl);\n\treturn rc;\n}\n\nvoid bnx2x_setup_cnic_irq_info(struct bnx2x *bp)\n{\n\tstruct cnic_eth_dev *cp = &bp->cnic_eth_dev;\n\n\tif (bp->flags & USING_MSIX_FLAG) {\n\t\tcp->drv_state |= CNIC_DRV_STATE_USING_MSIX;\n\t\tcp->irq_arr[0].irq_flags |= CNIC_IRQ_FL_MSIX;\n\t\tcp->irq_arr[0].vector = bp->msix_table[1].vector;\n\t} else {\n\t\tcp->drv_state &= ~CNIC_DRV_STATE_USING_MSIX;\n\t\tcp->irq_arr[0].irq_flags &= ~CNIC_IRQ_FL_MSIX;\n\t}\n\tif (!CHIP_IS_E1x(bp))\n\t\tcp->irq_arr[0].status_blk = (void *)bp->cnic_sb.e2_sb;\n\telse\n\t\tcp->irq_arr[0].status_blk = (void *)bp->cnic_sb.e1x_sb;\n\n\tcp->irq_arr[0].status_blk_num =  bnx2x_cnic_fw_sb_id(bp);\n\tcp->irq_arr[0].status_blk_num2 = bnx2x_cnic_igu_sb_id(bp);\n\tcp->irq_arr[1].status_blk = bp->def_status_blk;\n\tcp->irq_arr[1].status_blk_num = DEF_SB_ID;\n\tcp->irq_arr[1].status_blk_num2 = DEF_SB_IGU_ID;\n\n\tcp->num_irq = 2;\n}\n\nvoid bnx2x_setup_cnic_info(struct bnx2x *bp)\n{\n\tstruct cnic_eth_dev *cp = &bp->cnic_eth_dev;\n\n\tcp->ctx_tbl_offset = FUNC_ILT_BASE(BP_FUNC(bp)) +\n\t\t\t     bnx2x_cid_ilt_lines(bp);\n\tcp->starting_cid = bnx2x_cid_ilt_lines(bp) * ILT_PAGE_CIDS;\n\tcp->fcoe_init_cid = BNX2X_FCOE_ETH_CID(bp);\n\tcp->iscsi_l2_cid = BNX2X_ISCSI_ETH_CID(bp);\n\n\tDP(NETIF_MSG_IFUP, \"BNX2X_1st_NON_L2_ETH_CID(bp) %x, cp->starting_cid %x, cp->fcoe_init_cid %x, cp->iscsi_l2_cid %x\\n\",\n\t   BNX2X_1st_NON_L2_ETH_CID(bp), cp->starting_cid, cp->fcoe_init_cid,\n\t   cp->iscsi_l2_cid);\n\n\tif (NO_ISCSI_OOO(bp))\n\t\tcp->drv_state |= CNIC_DRV_STATE_NO_ISCSI_OOO;\n}\n\nstatic int bnx2x_register_cnic(struct net_device *dev, struct cnic_ops *ops,\n\t\t\t       void *data)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tstruct cnic_eth_dev *cp = &bp->cnic_eth_dev;\n\tint rc;\n\n\tDP(NETIF_MSG_IFUP, \"Register_cnic called\\n\");\n\n\tif (ops == NULL) {\n\t\tBNX2X_ERR(\"NULL ops received\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!CNIC_SUPPORT(bp)) {\n\t\tBNX2X_ERR(\"Can't register CNIC when not supported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!CNIC_LOADED(bp)) {\n\t\trc = bnx2x_load_cnic(bp);\n\t\tif (rc) {\n\t\t\tBNX2X_ERR(\"CNIC-related load failed\\n\");\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\tbp->cnic_enabled = true;\n\n\tbp->cnic_kwq = kzalloc(PAGE_SIZE, GFP_KERNEL);\n\tif (!bp->cnic_kwq)\n\t\treturn -ENOMEM;\n\n\tbp->cnic_kwq_cons = bp->cnic_kwq;\n\tbp->cnic_kwq_prod = bp->cnic_kwq;\n\tbp->cnic_kwq_last = bp->cnic_kwq + MAX_SP_DESC_CNT;\n\n\tbp->cnic_spq_pending = 0;\n\tbp->cnic_kwq_pending = 0;\n\n\tbp->cnic_data = data;\n\n\tcp->num_irq = 0;\n\tcp->drv_state |= CNIC_DRV_STATE_REGD;\n\tcp->iro_arr = bp->iro_arr;\n\n\tbnx2x_setup_cnic_irq_info(bp);\n\n\trcu_assign_pointer(bp->cnic_ops, ops);\n\n\t \n\tbnx2x_schedule_sp_rtnl(bp, BNX2X_SP_RTNL_GET_DRV_VERSION, 0);\n\n\treturn 0;\n}\n\nstatic int bnx2x_unregister_cnic(struct net_device *dev)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tstruct cnic_eth_dev *cp = &bp->cnic_eth_dev;\n\n\tmutex_lock(&bp->cnic_mutex);\n\tcp->drv_state = 0;\n\tRCU_INIT_POINTER(bp->cnic_ops, NULL);\n\tmutex_unlock(&bp->cnic_mutex);\n\tsynchronize_rcu();\n\tbp->cnic_enabled = false;\n\tkfree(bp->cnic_kwq);\n\tbp->cnic_kwq = NULL;\n\n\treturn 0;\n}\n\nstatic struct cnic_eth_dev *bnx2x_cnic_probe(struct net_device *dev)\n{\n\tstruct bnx2x *bp = netdev_priv(dev);\n\tstruct cnic_eth_dev *cp = &bp->cnic_eth_dev;\n\n\t \n\tif (NO_ISCSI(bp) && NO_FCOE(bp))\n\t\treturn NULL;\n\n\tcp->drv_owner = THIS_MODULE;\n\tcp->chip_id = CHIP_ID(bp);\n\tcp->pdev = bp->pdev;\n\tcp->io_base = bp->regview;\n\tcp->io_base2 = bp->doorbells;\n\tcp->max_kwqe_pending = 8;\n\tcp->ctx_blk_size = CDU_ILT_PAGE_SZ;\n\tcp->ctx_tbl_offset = FUNC_ILT_BASE(BP_FUNC(bp)) +\n\t\t\t     bnx2x_cid_ilt_lines(bp);\n\tcp->ctx_tbl_len = CNIC_ILT_LINES;\n\tcp->starting_cid = bnx2x_cid_ilt_lines(bp) * ILT_PAGE_CIDS;\n\tcp->drv_submit_kwqes_16 = bnx2x_cnic_sp_queue;\n\tcp->drv_ctl = bnx2x_drv_ctl;\n\tcp->drv_get_fc_npiv_tbl = bnx2x_get_fc_npiv;\n\tcp->drv_register_cnic = bnx2x_register_cnic;\n\tcp->drv_unregister_cnic = bnx2x_unregister_cnic;\n\tcp->fcoe_init_cid = BNX2X_FCOE_ETH_CID(bp);\n\tcp->iscsi_l2_client_id =\n\t\tbnx2x_cnic_eth_cl_id(bp, BNX2X_ISCSI_ETH_CL_ID_IDX);\n\tcp->iscsi_l2_cid = BNX2X_ISCSI_ETH_CID(bp);\n\n\tif (NO_ISCSI_OOO(bp))\n\t\tcp->drv_state |= CNIC_DRV_STATE_NO_ISCSI_OOO;\n\n\tif (NO_ISCSI(bp))\n\t\tcp->drv_state |= CNIC_DRV_STATE_NO_ISCSI;\n\n\tif (NO_FCOE(bp))\n\t\tcp->drv_state |= CNIC_DRV_STATE_NO_FCOE;\n\n\tBNX2X_DEV_INFO(\n\t\t\"page_size %d, tbl_offset %d, tbl_lines %d, starting cid %d\\n\",\n\t   cp->ctx_blk_size,\n\t   cp->ctx_tbl_offset,\n\t   cp->ctx_tbl_len,\n\t   cp->starting_cid);\n\treturn cp;\n}\n\nstatic u32 bnx2x_rx_ustorm_prods_offset(struct bnx2x_fastpath *fp)\n{\n\tstruct bnx2x *bp = fp->bp;\n\tu32 offset = BAR_USTRORM_INTMEM;\n\n\tif (IS_VF(bp))\n\t\treturn bnx2x_vf_ustorm_prods_offset(bp, fp);\n\telse if (!CHIP_IS_E1x(bp))\n\t\toffset += USTORM_RX_PRODS_E2_OFFSET(fp->cl_qzone_id);\n\telse\n\t\toffset += USTORM_RX_PRODS_E1X_OFFSET(BP_PORT(bp), fp->cl_id);\n\n\treturn offset;\n}\n\n \nint bnx2x_pretend_func(struct bnx2x *bp, u16 pretend_func_val)\n{\n\tu32 pretend_reg;\n\n\tif (CHIP_IS_E1H(bp) && pretend_func_val >= E1H_FUNC_MAX)\n\t\treturn -1;\n\n\t \n\tpretend_reg = bnx2x_get_pretend_reg(bp);\n\tREG_WR(bp, pretend_reg, pretend_func_val);\n\tREG_RD(bp, pretend_reg);\n\treturn 0;\n}\n\nstatic void bnx2x_ptp_task(struct work_struct *work)\n{\n\tstruct bnx2x *bp = container_of(work, struct bnx2x, ptp_task);\n\tint port = BP_PORT(bp);\n\tu32 val_seq;\n\tu64 timestamp, ns;\n\tstruct skb_shared_hwtstamps shhwtstamps;\n\tbool bail = true;\n\tint i;\n\n\t \n\tfor (i = 0; i < 10; i++) {\n\t\t \n\t\tval_seq = REG_RD(bp, port ? NIG_REG_P1_TLLH_PTP_BUF_SEQID :\n\t\t\t\t NIG_REG_P0_TLLH_PTP_BUF_SEQID);\n\t\tif (val_seq & 0x10000) {\n\t\t\tbail = false;\n\t\t\tbreak;\n\t\t}\n\t\tmsleep(1 << i);\n\t}\n\n\tif (!bail) {\n\t\t \n\t\ttimestamp = REG_RD(bp, port ? NIG_REG_P1_TLLH_PTP_BUF_TS_MSB :\n\t\t\t\t   NIG_REG_P0_TLLH_PTP_BUF_TS_MSB);\n\t\ttimestamp <<= 32;\n\t\ttimestamp |= REG_RD(bp, port ? NIG_REG_P1_TLLH_PTP_BUF_TS_LSB :\n\t\t\t\t    NIG_REG_P0_TLLH_PTP_BUF_TS_LSB);\n\t\t \n\t\tREG_WR(bp, port ? NIG_REG_P1_TLLH_PTP_BUF_SEQID :\n\t\t       NIG_REG_P0_TLLH_PTP_BUF_SEQID, 0x10000);\n\t\tns = timecounter_cyc2time(&bp->timecounter, timestamp);\n\n\t\tmemset(&shhwtstamps, 0, sizeof(shhwtstamps));\n\t\tshhwtstamps.hwtstamp = ns_to_ktime(ns);\n\t\tskb_tstamp_tx(bp->ptp_tx_skb, &shhwtstamps);\n\n\t\tDP(BNX2X_MSG_PTP, \"Tx timestamp, timestamp cycles = %llu, ns = %llu\\n\",\n\t\t   timestamp, ns);\n\t} else {\n\t\tDP(BNX2X_MSG_PTP,\n\t\t   \"Tx timestamp is not recorded (register read=%u)\\n\",\n\t\t   val_seq);\n\t\tbp->eth_stats.ptp_skip_tx_ts++;\n\t}\n\n\tdev_kfree_skb_any(bp->ptp_tx_skb);\n\tbp->ptp_tx_skb = NULL;\n}\n\nvoid bnx2x_set_rx_ts(struct bnx2x *bp, struct sk_buff *skb)\n{\n\tint port = BP_PORT(bp);\n\tu64 timestamp, ns;\n\n\ttimestamp = REG_RD(bp, port ? NIG_REG_P1_LLH_PTP_HOST_BUF_TS_MSB :\n\t\t\t    NIG_REG_P0_LLH_PTP_HOST_BUF_TS_MSB);\n\ttimestamp <<= 32;\n\ttimestamp |= REG_RD(bp, port ? NIG_REG_P1_LLH_PTP_HOST_BUF_TS_LSB :\n\t\t\t    NIG_REG_P0_LLH_PTP_HOST_BUF_TS_LSB);\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_HOST_BUF_SEQID :\n\t       NIG_REG_P0_LLH_PTP_HOST_BUF_SEQID, 0x10000);\n\n\tns = timecounter_cyc2time(&bp->timecounter, timestamp);\n\n\tskb_hwtstamps(skb)->hwtstamp = ns_to_ktime(ns);\n\n\tDP(BNX2X_MSG_PTP, \"Rx timestamp, timestamp cycles = %llu, ns = %llu\\n\",\n\t   timestamp, ns);\n}\n\n \nstatic u64 bnx2x_cyclecounter_read(const struct cyclecounter *cc)\n{\n\tstruct bnx2x *bp = container_of(cc, struct bnx2x, cyclecounter);\n\tint port = BP_PORT(bp);\n\tu32 wb_data[2];\n\tu64 phc_cycles;\n\n\tREG_RD_DMAE(bp, port ? NIG_REG_TIMESYNC_GEN_REG + tsgen_synctime_t1 :\n\t\t    NIG_REG_TIMESYNC_GEN_REG + tsgen_synctime_t0, wb_data, 2);\n\tphc_cycles = wb_data[1];\n\tphc_cycles = (phc_cycles << 32) + wb_data[0];\n\n\tDP(BNX2X_MSG_PTP, \"PHC read cycles = %llu\\n\", phc_cycles);\n\n\treturn phc_cycles;\n}\n\nstatic void bnx2x_init_cyclecounter(struct bnx2x *bp)\n{\n\tmemset(&bp->cyclecounter, 0, sizeof(bp->cyclecounter));\n\tbp->cyclecounter.read = bnx2x_cyclecounter_read;\n\tbp->cyclecounter.mask = CYCLECOUNTER_MASK(64);\n\tbp->cyclecounter.shift = 0;\n\tbp->cyclecounter.mult = 1;\n}\n\nstatic int bnx2x_send_reset_timesync_ramrod(struct bnx2x *bp)\n{\n\tstruct bnx2x_func_state_params func_params = {NULL};\n\tstruct bnx2x_func_set_timesync_params *set_timesync_params =\n\t\t&func_params.params.set_timesync;\n\n\t \n\t__set_bit(RAMROD_COMP_WAIT, &func_params.ramrod_flags);\n\t__set_bit(RAMROD_RETRY, &func_params.ramrod_flags);\n\n\tfunc_params.f_obj = &bp->func_obj;\n\tfunc_params.cmd = BNX2X_F_CMD_SET_TIMESYNC;\n\n\t \n\tset_timesync_params->drift_adjust_cmd = TS_DRIFT_ADJUST_RESET;\n\tset_timesync_params->offset_cmd = TS_OFFSET_KEEP;\n\n\treturn bnx2x_func_state_change(bp, &func_params);\n}\n\nstatic int bnx2x_enable_ptp_packets(struct bnx2x *bp)\n{\n\tstruct bnx2x_queue_state_params q_params;\n\tint rc, i;\n\n\t \n\tmemset(&q_params, 0, sizeof(q_params));\n\t__set_bit(RAMROD_COMP_WAIT, &q_params.ramrod_flags);\n\tq_params.cmd = BNX2X_Q_CMD_UPDATE;\n\t__set_bit(BNX2X_Q_UPDATE_PTP_PKTS_CHNG,\n\t\t  &q_params.params.update.update_flags);\n\t__set_bit(BNX2X_Q_UPDATE_PTP_PKTS,\n\t\t  &q_params.params.update.update_flags);\n\n\t \n\tfor_each_eth_queue(bp, i) {\n\t\tstruct bnx2x_fastpath *fp = &bp->fp[i];\n\n\t\t \n\t\tq_params.q_obj = &bnx2x_sp_obj(bp, fp).q_obj;\n\n\t\t \n\t\trc = bnx2x_queue_state_change(bp, &q_params);\n\t\tif (rc) {\n\t\t\tBNX2X_ERR(\"Failed to enable PTP packets\\n\");\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n#define BNX2X_P2P_DETECT_PARAM_MASK 0x5F5\n#define BNX2X_P2P_DETECT_RULE_MASK 0x3DBB\n#define BNX2X_PTP_TX_ON_PARAM_MASK (BNX2X_P2P_DETECT_PARAM_MASK & 0x6AA)\n#define BNX2X_PTP_TX_ON_RULE_MASK (BNX2X_P2P_DETECT_RULE_MASK & 0x3EEE)\n#define BNX2X_PTP_V1_L4_PARAM_MASK (BNX2X_P2P_DETECT_PARAM_MASK & 0x7EE)\n#define BNX2X_PTP_V1_L4_RULE_MASK (BNX2X_P2P_DETECT_RULE_MASK & 0x3FFE)\n#define BNX2X_PTP_V2_L4_PARAM_MASK (BNX2X_P2P_DETECT_PARAM_MASK & 0x7EA)\n#define BNX2X_PTP_V2_L4_RULE_MASK (BNX2X_P2P_DETECT_RULE_MASK & 0x3FEE)\n#define BNX2X_PTP_V2_L2_PARAM_MASK (BNX2X_P2P_DETECT_PARAM_MASK & 0x6BF)\n#define BNX2X_PTP_V2_L2_RULE_MASK (BNX2X_P2P_DETECT_RULE_MASK & 0x3EFF)\n#define BNX2X_PTP_V2_PARAM_MASK (BNX2X_P2P_DETECT_PARAM_MASK & 0x6AA)\n#define BNX2X_PTP_V2_RULE_MASK (BNX2X_P2P_DETECT_RULE_MASK & 0x3EEE)\n\nint bnx2x_configure_ptp_filters(struct bnx2x *bp)\n{\n\tint port = BP_PORT(bp);\n\tu32 param, rule;\n\tint rc;\n\n\tif (!bp->hwtstamp_ioctl_called)\n\t\treturn 0;\n\n\tparam = port ? NIG_REG_P1_TLLH_PTP_PARAM_MASK :\n\t\tNIG_REG_P0_TLLH_PTP_PARAM_MASK;\n\trule = port ? NIG_REG_P1_TLLH_PTP_RULE_MASK :\n\t\tNIG_REG_P0_TLLH_PTP_RULE_MASK;\n\tswitch (bp->tx_type) {\n\tcase HWTSTAMP_TX_ON:\n\t\tbp->flags |= TX_TIMESTAMPING_EN;\n\t\tREG_WR(bp, param, BNX2X_PTP_TX_ON_PARAM_MASK);\n\t\tREG_WR(bp, rule, BNX2X_PTP_TX_ON_RULE_MASK);\n\t\tbreak;\n\tcase HWTSTAMP_TX_ONESTEP_SYNC:\n\tcase HWTSTAMP_TX_ONESTEP_P2P:\n\t\tBNX2X_ERR(\"One-step timestamping is not supported\\n\");\n\t\treturn -ERANGE;\n\t}\n\n\tparam = port ? NIG_REG_P1_LLH_PTP_PARAM_MASK :\n\t\tNIG_REG_P0_LLH_PTP_PARAM_MASK;\n\trule = port ? NIG_REG_P1_LLH_PTP_RULE_MASK :\n\t\tNIG_REG_P0_LLH_PTP_RULE_MASK;\n\tswitch (bp->rx_filter) {\n\tcase HWTSTAMP_FILTER_NONE:\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_ALL:\n\tcase HWTSTAMP_FILTER_SOME:\n\tcase HWTSTAMP_FILTER_NTP_ALL:\n\t\tbp->rx_filter = HWTSTAMP_FILTER_NONE;\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:\n\t\tbp->rx_filter = HWTSTAMP_FILTER_PTP_V1_L4_EVENT;\n\t\t \n\t\tREG_WR(bp, param, BNX2X_PTP_V1_L4_PARAM_MASK);\n\t\tREG_WR(bp, rule, BNX2X_PTP_V1_L4_RULE_MASK);\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:\n\t\tbp->rx_filter = HWTSTAMP_FILTER_PTP_V2_L4_EVENT;\n\t\t \n\t\tREG_WR(bp, param, BNX2X_PTP_V2_L4_PARAM_MASK);\n\t\tREG_WR(bp, rule, BNX2X_PTP_V2_L4_RULE_MASK);\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:\n\t\tbp->rx_filter = HWTSTAMP_FILTER_PTP_V2_L2_EVENT;\n\t\t \n\t\tREG_WR(bp, param, BNX2X_PTP_V2_L2_PARAM_MASK);\n\t\tREG_WR(bp, rule, BNX2X_PTP_V2_L2_RULE_MASK);\n\n\t\tbreak;\n\tcase HWTSTAMP_FILTER_PTP_V2_EVENT:\n\tcase HWTSTAMP_FILTER_PTP_V2_SYNC:\n\tcase HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:\n\t\tbp->rx_filter = HWTSTAMP_FILTER_PTP_V2_EVENT;\n\t\t \n\t\tREG_WR(bp, param, BNX2X_PTP_V2_PARAM_MASK);\n\t\tREG_WR(bp, rule, BNX2X_PTP_V2_RULE_MASK);\n\t\tbreak;\n\t}\n\n\t \n\trc = bnx2x_enable_ptp_packets(bp);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_TO_HOST :\n\t       NIG_REG_P0_LLH_PTP_TO_HOST, 0x1);\n\n\treturn 0;\n}\n\nstatic int bnx2x_hwtstamp_ioctl(struct bnx2x *bp, struct ifreq *ifr)\n{\n\tstruct hwtstamp_config config;\n\tint rc;\n\n\tDP(BNX2X_MSG_PTP, \"HWTSTAMP IOCTL called\\n\");\n\n\tif (copy_from_user(&config, ifr->ifr_data, sizeof(config)))\n\t\treturn -EFAULT;\n\n\tDP(BNX2X_MSG_PTP, \"Requested tx_type: %d, requested rx_filters = %d\\n\",\n\t   config.tx_type, config.rx_filter);\n\n\tbp->hwtstamp_ioctl_called = true;\n\tbp->tx_type = config.tx_type;\n\tbp->rx_filter = config.rx_filter;\n\n\trc = bnx2x_configure_ptp_filters(bp);\n\tif (rc)\n\t\treturn rc;\n\n\tconfig.rx_filter = bp->rx_filter;\n\n\treturn copy_to_user(ifr->ifr_data, &config, sizeof(config)) ?\n\t\t-EFAULT : 0;\n}\n\n \nstatic int bnx2x_configure_ptp(struct bnx2x *bp)\n{\n\tint rc, port = BP_PORT(bp);\n\tu32 wb_data[2];\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_PARAM_MASK :\n\t       NIG_REG_P0_LLH_PTP_PARAM_MASK, 0x7FF);\n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_RULE_MASK :\n\t       NIG_REG_P0_LLH_PTP_RULE_MASK, 0x3FFF);\n\tREG_WR(bp, port ? NIG_REG_P1_TLLH_PTP_PARAM_MASK :\n\t       NIG_REG_P0_TLLH_PTP_PARAM_MASK, 0x7FF);\n\tREG_WR(bp, port ? NIG_REG_P1_TLLH_PTP_RULE_MASK :\n\t       NIG_REG_P0_TLLH_PTP_RULE_MASK, 0x3FFF);\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_TO_HOST :\n\t       NIG_REG_P0_LLH_PTP_TO_HOST, 0x0);\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_PTP_EN :\n\t       NIG_REG_P0_PTP_EN, 0x3F);\n\n\t \n\twb_data[0] = 0;\n\twb_data[1] = 0;\n\tREG_WR_DMAE(bp, NIG_REG_TIMESYNC_GEN_REG + tsgen_ctrl, wb_data, 2);\n\n\t \n\trc = bnx2x_send_reset_timesync_ramrod(bp);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Failed to reset PHC drift register\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\t \n\tREG_WR(bp, port ? NIG_REG_P1_LLH_PTP_HOST_BUF_SEQID :\n\t       NIG_REG_P0_LLH_PTP_HOST_BUF_SEQID, 0x10000);\n\tREG_WR(bp, port ? NIG_REG_P1_TLLH_PTP_BUF_SEQID :\n\t       NIG_REG_P0_TLLH_PTP_BUF_SEQID, 0x10000);\n\n\treturn 0;\n}\n\n \nvoid bnx2x_init_ptp(struct bnx2x *bp)\n{\n\tint rc;\n\n\t \n\trc = bnx2x_configure_ptp(bp);\n\tif (rc) {\n\t\tBNX2X_ERR(\"Stopping PTP initialization\\n\");\n\t\treturn;\n\t}\n\n\t \n\tINIT_WORK(&bp->ptp_task, bnx2x_ptp_task);\n\n\t \n\tif (!bp->timecounter_init_done) {\n\t\tbnx2x_init_cyclecounter(bp);\n\t\ttimecounter_init(&bp->timecounter, &bp->cyclecounter,\n\t\t\t\t ktime_to_ns(ktime_get_real()));\n\t\tbp->timecounter_init_done = true;\n\t}\n\n\tDP(BNX2X_MSG_PTP, \"PTP initialization ended successfully\\n\");\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}