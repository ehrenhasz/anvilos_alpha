{
  "module_name": "bcm63xx_enet.c",
  "hash_id": "51d4511a723a823a8ce8add9d28d2e497c2047da677a2e88da49437c8fdef260",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/broadcom/bcm63xx_enet.c",
  "human_readable_source": "\n \n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/clk.h>\n#include <linux/etherdevice.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/ethtool.h>\n#include <linux/crc32.h>\n#include <linux/err.h>\n#include <linux/dma-mapping.h>\n#include <linux/platform_device.h>\n#include <linux/if_vlan.h>\n\n#include <bcm63xx_dev_enet.h>\n#include \"bcm63xx_enet.h\"\n\nstatic char bcm_enet_driver_name[] = \"bcm63xx_enet\";\n\nstatic int copybreak __read_mostly = 128;\nmodule_param(copybreak, int, 0);\nMODULE_PARM_DESC(copybreak, \"Receive copy threshold\");\n\n \nstatic void __iomem *bcm_enet_shared_base[3];\n\n \nstatic inline u32 enet_readl(struct bcm_enet_priv *priv, u32 off)\n{\n\treturn bcm_readl(priv->base + off);\n}\n\nstatic inline void enet_writel(struct bcm_enet_priv *priv,\n\t\t\t       u32 val, u32 off)\n{\n\tbcm_writel(val, priv->base + off);\n}\n\n \nstatic inline u32 enetsw_readl(struct bcm_enet_priv *priv, u32 off)\n{\n\treturn bcm_readl(priv->base + off);\n}\n\nstatic inline void enetsw_writel(struct bcm_enet_priv *priv,\n\t\t\t\t u32 val, u32 off)\n{\n\tbcm_writel(val, priv->base + off);\n}\n\nstatic inline u16 enetsw_readw(struct bcm_enet_priv *priv, u32 off)\n{\n\treturn bcm_readw(priv->base + off);\n}\n\nstatic inline void enetsw_writew(struct bcm_enet_priv *priv,\n\t\t\t\t u16 val, u32 off)\n{\n\tbcm_writew(val, priv->base + off);\n}\n\nstatic inline u8 enetsw_readb(struct bcm_enet_priv *priv, u32 off)\n{\n\treturn bcm_readb(priv->base + off);\n}\n\nstatic inline void enetsw_writeb(struct bcm_enet_priv *priv,\n\t\t\t\t u8 val, u32 off)\n{\n\tbcm_writeb(val, priv->base + off);\n}\n\n\n \nstatic inline u32 enet_dma_readl(struct bcm_enet_priv *priv, u32 off)\n{\n\treturn bcm_readl(bcm_enet_shared_base[0] + off);\n}\n\nstatic inline void enet_dma_writel(struct bcm_enet_priv *priv,\n\t\t\t\t       u32 val, u32 off)\n{\n\tbcm_writel(val, bcm_enet_shared_base[0] + off);\n}\n\nstatic inline u32 enet_dmac_readl(struct bcm_enet_priv *priv, u32 off, int chan)\n{\n\treturn bcm_readl(bcm_enet_shared_base[1] +\n\t\tbcm63xx_enetdmacreg(off) + chan * priv->dma_chan_width);\n}\n\nstatic inline void enet_dmac_writel(struct bcm_enet_priv *priv,\n\t\t\t\t       u32 val, u32 off, int chan)\n{\n\tbcm_writel(val, bcm_enet_shared_base[1] +\n\t\tbcm63xx_enetdmacreg(off) + chan * priv->dma_chan_width);\n}\n\nstatic inline u32 enet_dmas_readl(struct bcm_enet_priv *priv, u32 off, int chan)\n{\n\treturn bcm_readl(bcm_enet_shared_base[2] + off + chan * priv->dma_chan_width);\n}\n\nstatic inline void enet_dmas_writel(struct bcm_enet_priv *priv,\n\t\t\t\t       u32 val, u32 off, int chan)\n{\n\tbcm_writel(val, bcm_enet_shared_base[2] + off + chan * priv->dma_chan_width);\n}\n\n \nstatic int do_mdio_op(struct bcm_enet_priv *priv, unsigned int data)\n{\n\tint limit;\n\n\t \n\tenet_writel(priv, ENET_IR_MII, ENET_IR_REG);\n\n\tenet_writel(priv, data, ENET_MIIDATA_REG);\n\twmb();\n\n\t \n\tlimit = 1000;\n\tdo {\n\t\tif (enet_readl(priv, ENET_IR_REG) & ENET_IR_MII)\n\t\t\tbreak;\n\t\tudelay(1);\n\t} while (limit-- > 0);\n\n\treturn (limit < 0) ? 1 : 0;\n}\n\n \nstatic int bcm_enet_mdio_read(struct bcm_enet_priv *priv, int mii_id,\n\t\t\t      int regnum)\n{\n\tu32 tmp, val;\n\n\ttmp = regnum << ENET_MIIDATA_REG_SHIFT;\n\ttmp |= 0x2 << ENET_MIIDATA_TA_SHIFT;\n\ttmp |= mii_id << ENET_MIIDATA_PHYID_SHIFT;\n\ttmp |= ENET_MIIDATA_OP_READ_MASK;\n\n\tif (do_mdio_op(priv, tmp))\n\t\treturn -1;\n\n\tval = enet_readl(priv, ENET_MIIDATA_REG);\n\tval &= 0xffff;\n\treturn val;\n}\n\n \nstatic int bcm_enet_mdio_write(struct bcm_enet_priv *priv, int mii_id,\n\t\t\t       int regnum, u16 value)\n{\n\tu32 tmp;\n\n\ttmp = (value & 0xffff) << ENET_MIIDATA_DATA_SHIFT;\n\ttmp |= 0x2 << ENET_MIIDATA_TA_SHIFT;\n\ttmp |= regnum << ENET_MIIDATA_REG_SHIFT;\n\ttmp |= mii_id << ENET_MIIDATA_PHYID_SHIFT;\n\ttmp |= ENET_MIIDATA_OP_WRITE_MASK;\n\n\t(void)do_mdio_op(priv, tmp);\n\treturn 0;\n}\n\n \nstatic int bcm_enet_mdio_read_phylib(struct mii_bus *bus, int mii_id,\n\t\t\t\t     int regnum)\n{\n\treturn bcm_enet_mdio_read(bus->priv, mii_id, regnum);\n}\n\n \nstatic int bcm_enet_mdio_write_phylib(struct mii_bus *bus, int mii_id,\n\t\t\t\t      int regnum, u16 value)\n{\n\treturn bcm_enet_mdio_write(bus->priv, mii_id, regnum, value);\n}\n\n \nstatic int bcm_enet_mdio_read_mii(struct net_device *dev, int mii_id,\n\t\t\t\t  int regnum)\n{\n\treturn bcm_enet_mdio_read(netdev_priv(dev), mii_id, regnum);\n}\n\n \nstatic void bcm_enet_mdio_write_mii(struct net_device *dev, int mii_id,\n\t\t\t\t    int regnum, int value)\n{\n\tbcm_enet_mdio_write(netdev_priv(dev), mii_id, regnum, value);\n}\n\n \nstatic int bcm_enet_refill_rx(struct net_device *dev, bool napi_mode)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\n\twhile (priv->rx_desc_count < priv->rx_ring_size) {\n\t\tstruct bcm_enet_desc *desc;\n\t\tint desc_idx;\n\t\tu32 len_stat;\n\n\t\tdesc_idx = priv->rx_dirty_desc;\n\t\tdesc = &priv->rx_desc_cpu[desc_idx];\n\n\t\tif (!priv->rx_buf[desc_idx]) {\n\t\t\tvoid *buf;\n\n\t\t\tif (likely(napi_mode))\n\t\t\t\tbuf = napi_alloc_frag(priv->rx_frag_size);\n\t\t\telse\n\t\t\t\tbuf = netdev_alloc_frag(priv->rx_frag_size);\n\t\t\tif (unlikely(!buf))\n\t\t\t\tbreak;\n\t\t\tpriv->rx_buf[desc_idx] = buf;\n\t\t\tdesc->address = dma_map_single(&priv->pdev->dev,\n\t\t\t\t\t\t       buf + priv->rx_buf_offset,\n\t\t\t\t\t\t       priv->rx_buf_size,\n\t\t\t\t\t\t       DMA_FROM_DEVICE);\n\t\t}\n\n\t\tlen_stat = priv->rx_buf_size << DMADESC_LENGTH_SHIFT;\n\t\tlen_stat |= DMADESC_OWNER_MASK;\n\t\tif (priv->rx_dirty_desc == priv->rx_ring_size - 1) {\n\t\t\tlen_stat |= (DMADESC_WRAP_MASK >> priv->dma_desc_shift);\n\t\t\tpriv->rx_dirty_desc = 0;\n\t\t} else {\n\t\t\tpriv->rx_dirty_desc++;\n\t\t}\n\t\twmb();\n\t\tdesc->len_stat = len_stat;\n\n\t\tpriv->rx_desc_count++;\n\n\t\t \n\t\tif (priv->dma_has_sram)\n\t\t\tenet_dma_writel(priv, 1, ENETDMA_BUFALLOC_REG(priv->rx_chan));\n\t\telse\n\t\t\tenet_dmac_writel(priv, 1, ENETDMAC_BUFALLOC, priv->rx_chan);\n\t}\n\n\t \n\tif (priv->rx_desc_count == 0 && netif_running(dev)) {\n\t\tdev_warn(&priv->pdev->dev, \"unable to refill rx ring\\n\");\n\t\tpriv->rx_timeout.expires = jiffies + HZ;\n\t\tadd_timer(&priv->rx_timeout);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void bcm_enet_refill_rx_timer(struct timer_list *t)\n{\n\tstruct bcm_enet_priv *priv = from_timer(priv, t, rx_timeout);\n\tstruct net_device *dev = priv->net_dev;\n\n\tspin_lock(&priv->rx_lock);\n\tbcm_enet_refill_rx(dev, false);\n\tspin_unlock(&priv->rx_lock);\n}\n\n \nstatic int bcm_enet_receive_queue(struct net_device *dev, int budget)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct list_head rx_list;\n\tstruct device *kdev;\n\tint processed;\n\n\tpriv = netdev_priv(dev);\n\tINIT_LIST_HEAD(&rx_list);\n\tkdev = &priv->pdev->dev;\n\tprocessed = 0;\n\n\t \n\tif (budget > priv->rx_desc_count)\n\t\tbudget = priv->rx_desc_count;\n\n\tdo {\n\t\tstruct bcm_enet_desc *desc;\n\t\tstruct sk_buff *skb;\n\t\tint desc_idx;\n\t\tu32 len_stat;\n\t\tunsigned int len;\n\t\tvoid *buf;\n\n\t\tdesc_idx = priv->rx_curr_desc;\n\t\tdesc = &priv->rx_desc_cpu[desc_idx];\n\n\t\t \n\t\trmb();\n\n\t\tlen_stat = desc->len_stat;\n\n\t\t \n\t\tif (len_stat & DMADESC_OWNER_MASK)\n\t\t\tbreak;\n\n\t\tprocessed++;\n\t\tpriv->rx_curr_desc++;\n\t\tif (priv->rx_curr_desc == priv->rx_ring_size)\n\t\t\tpriv->rx_curr_desc = 0;\n\n\t\t \n\t\tif ((len_stat & (DMADESC_ESOP_MASK >> priv->dma_desc_shift)) !=\n\t\t\t(DMADESC_ESOP_MASK >> priv->dma_desc_shift)) {\n\t\t\tdev->stats.rx_dropped++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (!priv->enet_is_sw &&\n\t\t    unlikely(len_stat & DMADESC_ERR_MASK)) {\n\t\t\tdev->stats.rx_errors++;\n\n\t\t\tif (len_stat & DMADESC_OVSIZE_MASK)\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\tif (len_stat & DMADESC_CRC_MASK)\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tif (len_stat & DMADESC_UNDER_MASK)\n\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\tif (len_stat & DMADESC_OV_MASK)\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tbuf = priv->rx_buf[desc_idx];\n\t\tlen = (len_stat & DMADESC_LENGTH_MASK) >> DMADESC_LENGTH_SHIFT;\n\t\t \n\t\tlen -= 4;\n\n\t\tif (len < copybreak) {\n\t\t\tskb = napi_alloc_skb(&priv->napi, len);\n\t\t\tif (unlikely(!skb)) {\n\t\t\t\t \n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tdma_sync_single_for_cpu(kdev, desc->address,\n\t\t\t\t\t\tlen, DMA_FROM_DEVICE);\n\t\t\tmemcpy(skb->data, buf + priv->rx_buf_offset, len);\n\t\t\tdma_sync_single_for_device(kdev, desc->address,\n\t\t\t\t\t\t   len, DMA_FROM_DEVICE);\n\t\t} else {\n\t\t\tdma_unmap_single(kdev, desc->address,\n\t\t\t\t\t priv->rx_buf_size, DMA_FROM_DEVICE);\n\t\t\tpriv->rx_buf[desc_idx] = NULL;\n\n\t\t\tskb = napi_build_skb(buf, priv->rx_frag_size);\n\t\t\tif (unlikely(!skb)) {\n\t\t\t\tskb_free_frag(buf);\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tskb_reserve(skb, priv->rx_buf_offset);\n\t\t}\n\n\t\tskb_put(skb, len);\n\t\tskb->protocol = eth_type_trans(skb, dev);\n\t\tdev->stats.rx_packets++;\n\t\tdev->stats.rx_bytes += len;\n\t\tlist_add_tail(&skb->list, &rx_list);\n\n\t} while (processed < budget);\n\n\tnetif_receive_skb_list(&rx_list);\n\tpriv->rx_desc_count -= processed;\n\n\tif (processed || !priv->rx_desc_count) {\n\t\tbcm_enet_refill_rx(dev, true);\n\n\t\t \n\t\tenet_dmac_writel(priv, priv->dma_chan_en_mask,\n\t\t\t\t\t ENETDMAC_CHANCFG, priv->rx_chan);\n\t}\n\n\treturn processed;\n}\n\n\n \nstatic int bcm_enet_tx_reclaim(struct net_device *dev, int force, int budget)\n{\n\tstruct bcm_enet_priv *priv;\n\tunsigned int bytes;\n\tint released;\n\n\tpriv = netdev_priv(dev);\n\tbytes = 0;\n\treleased = 0;\n\n\twhile (priv->tx_desc_count < priv->tx_ring_size) {\n\t\tstruct bcm_enet_desc *desc;\n\t\tstruct sk_buff *skb;\n\n\t\t \n\t\tspin_lock(&priv->tx_lock);\n\n\t\tdesc = &priv->tx_desc_cpu[priv->tx_dirty_desc];\n\n\t\tif (!force && (desc->len_stat & DMADESC_OWNER_MASK)) {\n\t\t\tspin_unlock(&priv->tx_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\trmb();\n\n\t\tskb = priv->tx_skb[priv->tx_dirty_desc];\n\t\tpriv->tx_skb[priv->tx_dirty_desc] = NULL;\n\t\tdma_unmap_single(&priv->pdev->dev, desc->address, skb->len,\n\t\t\t\t DMA_TO_DEVICE);\n\n\t\tpriv->tx_dirty_desc++;\n\t\tif (priv->tx_dirty_desc == priv->tx_ring_size)\n\t\t\tpriv->tx_dirty_desc = 0;\n\t\tpriv->tx_desc_count++;\n\n\t\tspin_unlock(&priv->tx_lock);\n\n\t\tif (desc->len_stat & DMADESC_UNDER_MASK)\n\t\t\tdev->stats.tx_errors++;\n\n\t\tbytes += skb->len;\n\t\tnapi_consume_skb(skb, budget);\n\t\treleased++;\n\t}\n\n\tnetdev_completed_queue(dev, released, bytes);\n\n\tif (netif_queue_stopped(dev) && released)\n\t\tnetif_wake_queue(dev);\n\n\treturn released;\n}\n\n \nstatic int bcm_enet_poll(struct napi_struct *napi, int budget)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct net_device *dev;\n\tint rx_work_done;\n\n\tpriv = container_of(napi, struct bcm_enet_priv, napi);\n\tdev = priv->net_dev;\n\n\t \n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IR, priv->rx_chan);\n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IR, priv->tx_chan);\n\n\t \n\tbcm_enet_tx_reclaim(dev, 0, budget);\n\n\tspin_lock(&priv->rx_lock);\n\trx_work_done = bcm_enet_receive_queue(dev, budget);\n\tspin_unlock(&priv->rx_lock);\n\n\tif (rx_work_done >= budget) {\n\t\t \n\t\treturn rx_work_done;\n\t}\n\n\t \n\tnapi_complete_done(napi, rx_work_done);\n\n\t \n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IRMASK, priv->tx_chan);\n\n\treturn rx_work_done;\n}\n\n \nstatic irqreturn_t bcm_enet_isr_mac(int irq, void *dev_id)\n{\n\tstruct net_device *dev;\n\tstruct bcm_enet_priv *priv;\n\tu32 stat;\n\n\tdev = dev_id;\n\tpriv = netdev_priv(dev);\n\n\tstat = enet_readl(priv, ENET_IR_REG);\n\tif (!(stat & ENET_IR_MIB))\n\t\treturn IRQ_NONE;\n\n\t \n\tenet_writel(priv, ENET_IR_MIB, ENET_IR_REG);\n\tenet_writel(priv, 0, ENET_IRMASK_REG);\n\n\t \n\tschedule_work(&priv->mib_update_task);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t bcm_enet_isr_dma(int irq, void *dev_id)\n{\n\tstruct net_device *dev;\n\tstruct bcm_enet_priv *priv;\n\n\tdev = dev_id;\n\tpriv = netdev_priv(dev);\n\n\t \n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->tx_chan);\n\n\tnapi_schedule(&priv->napi);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic netdev_tx_t\nbcm_enet_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct bcm_enet_desc *desc;\n\tu32 len_stat;\n\tnetdev_tx_t ret;\n\n\tpriv = netdev_priv(dev);\n\n\t \n\tspin_lock(&priv->tx_lock);\n\n\t \n\tif (unlikely(!priv->tx_desc_count)) {\n\t\tnetif_stop_queue(dev);\n\t\tdev_err(&priv->pdev->dev, \"xmit called with no tx desc \"\n\t\t\t\"available?\\n\");\n\t\tret = NETDEV_TX_BUSY;\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (priv->enet_is_sw && skb->len < 64) {\n\t\tint needed = 64 - skb->len;\n\t\tchar *data;\n\n\t\tif (unlikely(skb_tailroom(skb) < needed)) {\n\t\t\tstruct sk_buff *nskb;\n\n\t\t\tnskb = skb_copy_expand(skb, 0, needed, GFP_ATOMIC);\n\t\t\tif (!nskb) {\n\t\t\t\tret = NETDEV_TX_BUSY;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t\tdev_kfree_skb(skb);\n\t\t\tskb = nskb;\n\t\t}\n\t\tdata = skb_put_zero(skb, needed);\n\t}\n\n\t \n\tdesc = &priv->tx_desc_cpu[priv->tx_curr_desc];\n\tpriv->tx_skb[priv->tx_curr_desc] = skb;\n\n\t \n\tdesc->address = dma_map_single(&priv->pdev->dev, skb->data, skb->len,\n\t\t\t\t       DMA_TO_DEVICE);\n\n\tlen_stat = (skb->len << DMADESC_LENGTH_SHIFT) & DMADESC_LENGTH_MASK;\n\tlen_stat |= (DMADESC_ESOP_MASK >> priv->dma_desc_shift) |\n\t\tDMADESC_APPEND_CRC |\n\t\tDMADESC_OWNER_MASK;\n\n\tpriv->tx_curr_desc++;\n\tif (priv->tx_curr_desc == priv->tx_ring_size) {\n\t\tpriv->tx_curr_desc = 0;\n\t\tlen_stat |= (DMADESC_WRAP_MASK >> priv->dma_desc_shift);\n\t}\n\tpriv->tx_desc_count--;\n\n\t \n\twmb();\n\tdesc->len_stat = len_stat;\n\twmb();\n\n\tnetdev_sent_queue(dev, skb->len);\n\n\t \n\tif (!netdev_xmit_more() || !priv->tx_desc_count)\n\t\tenet_dmac_writel(priv, priv->dma_chan_en_mask,\n\t\t\t\t ENETDMAC_CHANCFG, priv->tx_chan);\n\n\t \n\tif (!priv->tx_desc_count)\n\t\tnetif_stop_queue(dev);\n\n\tdev->stats.tx_bytes += skb->len;\n\tdev->stats.tx_packets++;\n\tret = NETDEV_TX_OK;\n\nout_unlock:\n\tspin_unlock(&priv->tx_lock);\n\treturn ret;\n}\n\n \nstatic int bcm_enet_set_mac_address(struct net_device *dev, void *p)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct sockaddr *addr = p;\n\tu32 val;\n\n\tpriv = netdev_priv(dev);\n\teth_hw_addr_set(dev, addr->sa_data);\n\n\t \n\tval = (dev->dev_addr[2] << 24) | (dev->dev_addr[3] << 16) |\n\t\t(dev->dev_addr[4] << 8) | dev->dev_addr[5];\n\tenet_writel(priv, val, ENET_PML_REG(0));\n\n\tval = (dev->dev_addr[0] << 8 | dev->dev_addr[1]);\n\tval |= ENET_PMH_DATAVALID_MASK;\n\tenet_writel(priv, val, ENET_PMH_REG(0));\n\n\treturn 0;\n}\n\n \nstatic void bcm_enet_set_multicast_list(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct netdev_hw_addr *ha;\n\tu32 val;\n\tint i;\n\n\tpriv = netdev_priv(dev);\n\n\tval = enet_readl(priv, ENET_RXCFG_REG);\n\n\tif (dev->flags & IFF_PROMISC)\n\t\tval |= ENET_RXCFG_PROMISC_MASK;\n\telse\n\t\tval &= ~ENET_RXCFG_PROMISC_MASK;\n\n\t \n\tif ((dev->flags & IFF_ALLMULTI) || netdev_mc_count(dev) > 3)\n\t\tval |= ENET_RXCFG_ALLMCAST_MASK;\n\telse\n\t\tval &= ~ENET_RXCFG_ALLMCAST_MASK;\n\n\t \n\tif (val & ENET_RXCFG_ALLMCAST_MASK) {\n\t\tenet_writel(priv, val, ENET_RXCFG_REG);\n\t\treturn;\n\t}\n\n\ti = 0;\n\tnetdev_for_each_mc_addr(ha, dev) {\n\t\tu8 *dmi_addr;\n\t\tu32 tmp;\n\n\t\tif (i == 3)\n\t\t\tbreak;\n\t\t \n\t\tdmi_addr = ha->addr;\n\t\ttmp = (dmi_addr[2] << 24) | (dmi_addr[3] << 16) |\n\t\t\t(dmi_addr[4] << 8) | dmi_addr[5];\n\t\tenet_writel(priv, tmp, ENET_PML_REG(i + 1));\n\n\t\ttmp = (dmi_addr[0] << 8 | dmi_addr[1]);\n\t\ttmp |= ENET_PMH_DATAVALID_MASK;\n\t\tenet_writel(priv, tmp, ENET_PMH_REG(i++ + 1));\n\t}\n\n\tfor (; i < 3; i++) {\n\t\tenet_writel(priv, 0, ENET_PML_REG(i + 1));\n\t\tenet_writel(priv, 0, ENET_PMH_REG(i + 1));\n\t}\n\n\tenet_writel(priv, val, ENET_RXCFG_REG);\n}\n\n \nstatic void bcm_enet_set_duplex(struct bcm_enet_priv *priv, int fullduplex)\n{\n\tu32 val;\n\n\tval = enet_readl(priv, ENET_TXCTL_REG);\n\tif (fullduplex)\n\t\tval |= ENET_TXCTL_FD_MASK;\n\telse\n\t\tval &= ~ENET_TXCTL_FD_MASK;\n\tenet_writel(priv, val, ENET_TXCTL_REG);\n}\n\n \nstatic void bcm_enet_set_flow(struct bcm_enet_priv *priv, int rx_en, int tx_en)\n{\n\tu32 val;\n\n\t \n\tval = enet_readl(priv, ENET_RXCFG_REG);\n\tif (rx_en)\n\t\tval |= ENET_RXCFG_ENFLOW_MASK;\n\telse\n\t\tval &= ~ENET_RXCFG_ENFLOW_MASK;\n\tenet_writel(priv, val, ENET_RXCFG_REG);\n\n\tif (!priv->dma_has_sram)\n\t\treturn;\n\n\t \n\tval = enet_dma_readl(priv, ENETDMA_CFG_REG);\n\tif (tx_en)\n\t\tval |= ENETDMA_CFG_FLOWCH_MASK(priv->rx_chan);\n\telse\n\t\tval &= ~ENETDMA_CFG_FLOWCH_MASK(priv->rx_chan);\n\tenet_dma_writel(priv, val, ENETDMA_CFG_REG);\n}\n\n \nstatic void bcm_enet_adjust_phy_link(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct phy_device *phydev;\n\tint status_changed;\n\n\tpriv = netdev_priv(dev);\n\tphydev = dev->phydev;\n\tstatus_changed = 0;\n\n\tif (priv->old_link != phydev->link) {\n\t\tstatus_changed = 1;\n\t\tpriv->old_link = phydev->link;\n\t}\n\n\t \n\tif (phydev->link && phydev->duplex != priv->old_duplex) {\n\t\tbcm_enet_set_duplex(priv,\n\t\t\t\t    (phydev->duplex == DUPLEX_FULL) ? 1 : 0);\n\t\tstatus_changed = 1;\n\t\tpriv->old_duplex = phydev->duplex;\n\t}\n\n\t \n\tif (phydev->link && phydev->pause != priv->old_pause) {\n\t\tint rx_pause_en, tx_pause_en;\n\n\t\tif (phydev->pause) {\n\t\t\t \n\t\t\trx_pause_en = 1;\n\t\t\ttx_pause_en = 1;\n\t\t} else if (!priv->pause_auto) {\n\t\t\t \n\t\t\trx_pause_en = priv->pause_rx;\n\t\t\ttx_pause_en = priv->pause_tx;\n\t\t} else {\n\t\t\trx_pause_en = 0;\n\t\t\ttx_pause_en = 0;\n\t\t}\n\n\t\tbcm_enet_set_flow(priv, rx_pause_en, tx_pause_en);\n\t\tstatus_changed = 1;\n\t\tpriv->old_pause = phydev->pause;\n\t}\n\n\tif (status_changed) {\n\t\tpr_info(\"%s: link %s\", dev->name, phydev->link ?\n\t\t\t\"UP\" : \"DOWN\");\n\t\tif (phydev->link)\n\t\t\tpr_cont(\" - %d/%s - flow control %s\", phydev->speed,\n\t\t\t       DUPLEX_FULL == phydev->duplex ? \"full\" : \"half\",\n\t\t\t       phydev->pause == 1 ? \"rx&tx\" : \"off\");\n\n\t\tpr_cont(\"\\n\");\n\t}\n}\n\n \nstatic void bcm_enet_adjust_link(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\tbcm_enet_set_duplex(priv, priv->force_duplex_full);\n\tbcm_enet_set_flow(priv, priv->pause_rx, priv->pause_tx);\n\tnetif_carrier_on(dev);\n\n\tpr_info(\"%s: link forced UP - %d/%s - flow control %s/%s\\n\",\n\t\tdev->name,\n\t\tpriv->force_speed_100 ? 100 : 10,\n\t\tpriv->force_duplex_full ? \"full\" : \"half\",\n\t\tpriv->pause_rx ? \"rx\" : \"off\",\n\t\tpriv->pause_tx ? \"tx\" : \"off\");\n}\n\nstatic void bcm_enet_free_rx_buf_ring(struct device *kdev, struct bcm_enet_priv *priv)\n{\n\tint i;\n\n\tfor (i = 0; i < priv->rx_ring_size; i++) {\n\t\tstruct bcm_enet_desc *desc;\n\n\t\tif (!priv->rx_buf[i])\n\t\t\tcontinue;\n\n\t\tdesc = &priv->rx_desc_cpu[i];\n\t\tdma_unmap_single(kdev, desc->address, priv->rx_buf_size,\n\t\t\t\t DMA_FROM_DEVICE);\n\t\tskb_free_frag(priv->rx_buf[i]);\n\t}\n\tkfree(priv->rx_buf);\n}\n\n \nstatic int bcm_enet_open(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct sockaddr addr;\n\tstruct device *kdev;\n\tstruct phy_device *phydev;\n\tint i, ret;\n\tunsigned int size;\n\tchar phy_id[MII_BUS_ID_SIZE + 3];\n\tvoid *p;\n\tu32 val;\n\n\tpriv = netdev_priv(dev);\n\tkdev = &priv->pdev->dev;\n\n\tif (priv->has_phy) {\n\t\t \n\t\tsnprintf(phy_id, sizeof(phy_id), PHY_ID_FMT,\n\t\t\t priv->mii_bus->id, priv->phy_id);\n\n\t\tphydev = phy_connect(dev, phy_id, bcm_enet_adjust_phy_link,\n\t\t\t\t     PHY_INTERFACE_MODE_MII);\n\n\t\tif (IS_ERR(phydev)) {\n\t\t\tdev_err(kdev, \"could not attach to PHY\\n\");\n\t\t\treturn PTR_ERR(phydev);\n\t\t}\n\n\t\t \n\t\tphy_support_sym_pause(phydev);\n\t\tphy_set_max_speed(phydev, SPEED_100);\n\t\tphy_set_sym_pause(phydev, priv->pause_rx, priv->pause_rx,\n\t\t\t\t  priv->pause_auto);\n\n\t\tphy_attached_info(phydev);\n\n\t\tpriv->old_link = 0;\n\t\tpriv->old_duplex = -1;\n\t\tpriv->old_pause = -1;\n\t} else {\n\t\tphydev = NULL;\n\t}\n\n\t \n\tenet_writel(priv, 0, ENET_IRMASK_REG);\n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->tx_chan);\n\n\tret = request_irq(dev->irq, bcm_enet_isr_mac, 0, dev->name, dev);\n\tif (ret)\n\t\tgoto out_phy_disconnect;\n\n\tret = request_irq(priv->irq_rx, bcm_enet_isr_dma, 0,\n\t\t\t  dev->name, dev);\n\tif (ret)\n\t\tgoto out_freeirq;\n\n\tret = request_irq(priv->irq_tx, bcm_enet_isr_dma,\n\t\t\t  0, dev->name, dev);\n\tif (ret)\n\t\tgoto out_freeirq_rx;\n\n\t \n\tfor (i = 0; i < 4; i++) {\n\t\tenet_writel(priv, 0, ENET_PML_REG(i));\n\t\tenet_writel(priv, 0, ENET_PMH_REG(i));\n\t}\n\n\t \n\tmemcpy(addr.sa_data, dev->dev_addr, ETH_ALEN);\n\tbcm_enet_set_mac_address(dev, &addr);\n\n\t \n\tsize = priv->rx_ring_size * sizeof(struct bcm_enet_desc);\n\tp = dma_alloc_coherent(kdev, size, &priv->rx_desc_dma, GFP_KERNEL);\n\tif (!p) {\n\t\tret = -ENOMEM;\n\t\tgoto out_freeirq_tx;\n\t}\n\n\tpriv->rx_desc_alloc_size = size;\n\tpriv->rx_desc_cpu = p;\n\n\t \n\tsize = priv->tx_ring_size * sizeof(struct bcm_enet_desc);\n\tp = dma_alloc_coherent(kdev, size, &priv->tx_desc_dma, GFP_KERNEL);\n\tif (!p) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free_rx_ring;\n\t}\n\n\tpriv->tx_desc_alloc_size = size;\n\tpriv->tx_desc_cpu = p;\n\n\tpriv->tx_skb = kcalloc(priv->tx_ring_size, sizeof(struct sk_buff *),\n\t\t\t       GFP_KERNEL);\n\tif (!priv->tx_skb) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free_tx_ring;\n\t}\n\n\tpriv->tx_desc_count = priv->tx_ring_size;\n\tpriv->tx_dirty_desc = 0;\n\tpriv->tx_curr_desc = 0;\n\tspin_lock_init(&priv->tx_lock);\n\n\t \n\tpriv->rx_buf = kcalloc(priv->rx_ring_size, sizeof(void *),\n\t\t\t       GFP_KERNEL);\n\tif (!priv->rx_buf) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free_tx_skb;\n\t}\n\n\tpriv->rx_desc_count = 0;\n\tpriv->rx_dirty_desc = 0;\n\tpriv->rx_curr_desc = 0;\n\n\t \n\tif (priv->dma_has_sram)\n\t\tenet_dma_writel(priv, ENETDMA_BUFALLOC_FORCE_MASK | 0,\n\t\t\t\tENETDMA_BUFALLOC_REG(priv->rx_chan));\n\telse\n\t\tenet_dmac_writel(priv, ENETDMA_BUFALLOC_FORCE_MASK | 0,\n\t\t\t\tENETDMAC_BUFALLOC, priv->rx_chan);\n\n\tif (bcm_enet_refill_rx(dev, false)) {\n\t\tdev_err(kdev, \"cannot allocate rx buffer queue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t \n\tif (priv->dma_has_sram) {\n\t\tenet_dmas_writel(priv, priv->rx_desc_dma,\n\t\t\t\t ENETDMAS_RSTART_REG, priv->rx_chan);\n\t\tenet_dmas_writel(priv, priv->tx_desc_dma,\n\t\t\t ENETDMAS_RSTART_REG, priv->tx_chan);\n\t} else {\n\t\tenet_dmac_writel(priv, priv->rx_desc_dma,\n\t\t\t\tENETDMAC_RSTART, priv->rx_chan);\n\t\tenet_dmac_writel(priv, priv->tx_desc_dma,\n\t\t\t\tENETDMAC_RSTART, priv->tx_chan);\n\t}\n\n\t \n\tif (priv->dma_has_sram) {\n\t\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM2_REG, priv->rx_chan);\n\t\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM2_REG, priv->tx_chan);\n\t\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM3_REG, priv->rx_chan);\n\t\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM3_REG, priv->tx_chan);\n\t\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM4_REG, priv->rx_chan);\n\t\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM4_REG, priv->tx_chan);\n\t} else {\n\t\tenet_dmac_writel(priv, 0, ENETDMAC_FC, priv->rx_chan);\n\t\tenet_dmac_writel(priv, 0, ENETDMAC_FC, priv->tx_chan);\n\t}\n\n\t \n\tenet_writel(priv, priv->hw_mtu, ENET_RXMAXLEN_REG);\n\tenet_writel(priv, priv->hw_mtu, ENET_TXMAXLEN_REG);\n\n\t \n\tenet_dmac_writel(priv, priv->dma_maxburst,\n\t\t\t ENETDMAC_MAXBURST, priv->rx_chan);\n\tenet_dmac_writel(priv, priv->dma_maxburst,\n\t\t\t ENETDMAC_MAXBURST, priv->tx_chan);\n\n\t \n\tenet_writel(priv, BCMENET_TX_FIFO_TRESH, ENET_TXWMARK_REG);\n\n\t \n\tif (priv->dma_has_sram) {\n\t\tval = priv->rx_ring_size / 3;\n\t\tenet_dma_writel(priv, val, ENETDMA_FLOWCL_REG(priv->rx_chan));\n\t\tval = (priv->rx_ring_size * 2) / 3;\n\t\tenet_dma_writel(priv, val, ENETDMA_FLOWCH_REG(priv->rx_chan));\n\t} else {\n\t\tenet_dmac_writel(priv, 5, ENETDMAC_FC, priv->rx_chan);\n\t\tenet_dmac_writel(priv, priv->rx_ring_size, ENETDMAC_LEN, priv->rx_chan);\n\t\tenet_dmac_writel(priv, priv->tx_ring_size, ENETDMAC_LEN, priv->tx_chan);\n\t}\n\n\t \n\twmb();\n\tval = enet_readl(priv, ENET_CTL_REG);\n\tval |= ENET_CTL_ENABLE_MASK;\n\tenet_writel(priv, val, ENET_CTL_REG);\n\tif (priv->dma_has_sram)\n\t\tenet_dma_writel(priv, ENETDMA_CFG_EN_MASK, ENETDMA_CFG_REG);\n\tenet_dmac_writel(priv, priv->dma_chan_en_mask,\n\t\t\t ENETDMAC_CHANCFG, priv->rx_chan);\n\n\t \n\tenet_writel(priv, ENET_IR_MIB, ENET_IR_REG);\n\tenet_writel(priv, ENET_IR_MIB, ENET_IRMASK_REG);\n\n\t \n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IR, priv->rx_chan);\n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IR, priv->tx_chan);\n\n\t \n\tnapi_enable(&priv->napi);\n\n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, priv->dma_chan_int_mask,\n\t\t\t ENETDMAC_IRMASK, priv->tx_chan);\n\n\tif (phydev)\n\t\tphy_start(phydev);\n\telse\n\t\tbcm_enet_adjust_link(dev);\n\n\tnetif_start_queue(dev);\n\treturn 0;\n\nout:\n\tbcm_enet_free_rx_buf_ring(kdev, priv);\n\nout_free_tx_skb:\n\tkfree(priv->tx_skb);\n\nout_free_tx_ring:\n\tdma_free_coherent(kdev, priv->tx_desc_alloc_size,\n\t\t\t  priv->tx_desc_cpu, priv->tx_desc_dma);\n\nout_free_rx_ring:\n\tdma_free_coherent(kdev, priv->rx_desc_alloc_size,\n\t\t\t  priv->rx_desc_cpu, priv->rx_desc_dma);\n\nout_freeirq_tx:\n\tfree_irq(priv->irq_tx, dev);\n\nout_freeirq_rx:\n\tfree_irq(priv->irq_rx, dev);\n\nout_freeirq:\n\tfree_irq(dev->irq, dev);\n\nout_phy_disconnect:\n\tif (phydev)\n\t\tphy_disconnect(phydev);\n\n\treturn ret;\n}\n\n \nstatic void bcm_enet_disable_mac(struct bcm_enet_priv *priv)\n{\n\tint limit;\n\tu32 val;\n\n\tval = enet_readl(priv, ENET_CTL_REG);\n\tval |= ENET_CTL_DISABLE_MASK;\n\tenet_writel(priv, val, ENET_CTL_REG);\n\n\tlimit = 1000;\n\tdo {\n\t\tu32 val;\n\n\t\tval = enet_readl(priv, ENET_CTL_REG);\n\t\tif (!(val & ENET_CTL_DISABLE_MASK))\n\t\t\tbreak;\n\t\tudelay(1);\n\t} while (limit--);\n}\n\n \nstatic void bcm_enet_disable_dma(struct bcm_enet_priv *priv, int chan)\n{\n\tint limit;\n\n\tenet_dmac_writel(priv, 0, ENETDMAC_CHANCFG, chan);\n\n\tlimit = 1000;\n\tdo {\n\t\tu32 val;\n\n\t\tval = enet_dmac_readl(priv, ENETDMAC_CHANCFG, chan);\n\t\tif (!(val & ENETDMAC_CHANCFG_EN_MASK))\n\t\t\tbreak;\n\t\tudelay(1);\n\t} while (limit--);\n}\n\n \nstatic int bcm_enet_stop(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct device *kdev;\n\n\tpriv = netdev_priv(dev);\n\tkdev = &priv->pdev->dev;\n\n\tnetif_stop_queue(dev);\n\tnapi_disable(&priv->napi);\n\tif (priv->has_phy)\n\t\tphy_stop(dev->phydev);\n\tdel_timer_sync(&priv->rx_timeout);\n\n\t \n\tenet_writel(priv, 0, ENET_IRMASK_REG);\n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->tx_chan);\n\n\t \n\tcancel_work_sync(&priv->mib_update_task);\n\n\t \n\tbcm_enet_disable_dma(priv, priv->tx_chan);\n\tbcm_enet_disable_dma(priv, priv->rx_chan);\n\tbcm_enet_disable_mac(priv);\n\n\t \n\tbcm_enet_tx_reclaim(dev, 1, 0);\n\n\t \n\tbcm_enet_free_rx_buf_ring(kdev, priv);\n\n\t \n\tkfree(priv->tx_skb);\n\tdma_free_coherent(kdev, priv->rx_desc_alloc_size,\n\t\t\t  priv->rx_desc_cpu, priv->rx_desc_dma);\n\tdma_free_coherent(kdev, priv->tx_desc_alloc_size,\n\t\t\t  priv->tx_desc_cpu, priv->tx_desc_dma);\n\tfree_irq(priv->irq_tx, dev);\n\tfree_irq(priv->irq_rx, dev);\n\tfree_irq(dev->irq, dev);\n\n\t \n\tif (priv->has_phy)\n\t\tphy_disconnect(dev->phydev);\n\n\t \n\tnetdev_reset_queue(dev);\n\n\treturn 0;\n}\n\n \nstruct bcm_enet_stats {\n\tchar stat_string[ETH_GSTRING_LEN];\n\tint sizeof_stat;\n\tint stat_offset;\n\tint mib_reg;\n};\n\n#define GEN_STAT(m) sizeof(((struct bcm_enet_priv *)0)->m),\t\t\\\n\t\t     offsetof(struct bcm_enet_priv, m)\n#define DEV_STAT(m) sizeof(((struct net_device_stats *)0)->m),\t\t\\\n\t\t     offsetof(struct net_device_stats, m)\n\nstatic const struct bcm_enet_stats bcm_enet_gstrings_stats[] = {\n\t{ \"rx_packets\", DEV_STAT(rx_packets), -1 },\n\t{ \"tx_packets\",\tDEV_STAT(tx_packets), -1 },\n\t{ \"rx_bytes\", DEV_STAT(rx_bytes), -1 },\n\t{ \"tx_bytes\", DEV_STAT(tx_bytes), -1 },\n\t{ \"rx_errors\", DEV_STAT(rx_errors), -1 },\n\t{ \"tx_errors\", DEV_STAT(tx_errors), -1 },\n\t{ \"rx_dropped\",\tDEV_STAT(rx_dropped), -1 },\n\t{ \"tx_dropped\",\tDEV_STAT(tx_dropped), -1 },\n\n\t{ \"rx_good_octets\", GEN_STAT(mib.rx_gd_octets), ETH_MIB_RX_GD_OCTETS},\n\t{ \"rx_good_pkts\", GEN_STAT(mib.rx_gd_pkts), ETH_MIB_RX_GD_PKTS },\n\t{ \"rx_broadcast\", GEN_STAT(mib.rx_brdcast), ETH_MIB_RX_BRDCAST },\n\t{ \"rx_multicast\", GEN_STAT(mib.rx_mult), ETH_MIB_RX_MULT },\n\t{ \"rx_64_octets\", GEN_STAT(mib.rx_64), ETH_MIB_RX_64 },\n\t{ \"rx_65_127_oct\", GEN_STAT(mib.rx_65_127), ETH_MIB_RX_65_127 },\n\t{ \"rx_128_255_oct\", GEN_STAT(mib.rx_128_255), ETH_MIB_RX_128_255 },\n\t{ \"rx_256_511_oct\", GEN_STAT(mib.rx_256_511), ETH_MIB_RX_256_511 },\n\t{ \"rx_512_1023_oct\", GEN_STAT(mib.rx_512_1023), ETH_MIB_RX_512_1023 },\n\t{ \"rx_1024_max_oct\", GEN_STAT(mib.rx_1024_max), ETH_MIB_RX_1024_MAX },\n\t{ \"rx_jabber\", GEN_STAT(mib.rx_jab), ETH_MIB_RX_JAB },\n\t{ \"rx_oversize\", GEN_STAT(mib.rx_ovr), ETH_MIB_RX_OVR },\n\t{ \"rx_fragment\", GEN_STAT(mib.rx_frag), ETH_MIB_RX_FRAG },\n\t{ \"rx_dropped\",\tGEN_STAT(mib.rx_drop), ETH_MIB_RX_DROP },\n\t{ \"rx_crc_align\", GEN_STAT(mib.rx_crc_align), ETH_MIB_RX_CRC_ALIGN },\n\t{ \"rx_undersize\", GEN_STAT(mib.rx_und), ETH_MIB_RX_UND },\n\t{ \"rx_crc\", GEN_STAT(mib.rx_crc), ETH_MIB_RX_CRC },\n\t{ \"rx_align\", GEN_STAT(mib.rx_align), ETH_MIB_RX_ALIGN },\n\t{ \"rx_symbol_error\", GEN_STAT(mib.rx_sym), ETH_MIB_RX_SYM },\n\t{ \"rx_pause\", GEN_STAT(mib.rx_pause), ETH_MIB_RX_PAUSE },\n\t{ \"rx_control\", GEN_STAT(mib.rx_cntrl), ETH_MIB_RX_CNTRL },\n\n\t{ \"tx_good_octets\", GEN_STAT(mib.tx_gd_octets), ETH_MIB_TX_GD_OCTETS },\n\t{ \"tx_good_pkts\", GEN_STAT(mib.tx_gd_pkts), ETH_MIB_TX_GD_PKTS },\n\t{ \"tx_broadcast\", GEN_STAT(mib.tx_brdcast), ETH_MIB_TX_BRDCAST },\n\t{ \"tx_multicast\", GEN_STAT(mib.tx_mult), ETH_MIB_TX_MULT },\n\t{ \"tx_64_oct\", GEN_STAT(mib.tx_64), ETH_MIB_TX_64 },\n\t{ \"tx_65_127_oct\", GEN_STAT(mib.tx_65_127), ETH_MIB_TX_65_127 },\n\t{ \"tx_128_255_oct\", GEN_STAT(mib.tx_128_255), ETH_MIB_TX_128_255 },\n\t{ \"tx_256_511_oct\", GEN_STAT(mib.tx_256_511), ETH_MIB_TX_256_511 },\n\t{ \"tx_512_1023_oct\", GEN_STAT(mib.tx_512_1023), ETH_MIB_TX_512_1023},\n\t{ \"tx_1024_max_oct\", GEN_STAT(mib.tx_1024_max), ETH_MIB_TX_1024_MAX },\n\t{ \"tx_jabber\", GEN_STAT(mib.tx_jab), ETH_MIB_TX_JAB },\n\t{ \"tx_oversize\", GEN_STAT(mib.tx_ovr), ETH_MIB_TX_OVR },\n\t{ \"tx_fragment\", GEN_STAT(mib.tx_frag), ETH_MIB_TX_FRAG },\n\t{ \"tx_underrun\", GEN_STAT(mib.tx_underrun), ETH_MIB_TX_UNDERRUN },\n\t{ \"tx_collisions\", GEN_STAT(mib.tx_col), ETH_MIB_TX_COL },\n\t{ \"tx_single_collision\", GEN_STAT(mib.tx_1_col), ETH_MIB_TX_1_COL },\n\t{ \"tx_multiple_collision\", GEN_STAT(mib.tx_m_col), ETH_MIB_TX_M_COL },\n\t{ \"tx_excess_collision\", GEN_STAT(mib.tx_ex_col), ETH_MIB_TX_EX_COL },\n\t{ \"tx_late_collision\", GEN_STAT(mib.tx_late), ETH_MIB_TX_LATE },\n\t{ \"tx_deferred\", GEN_STAT(mib.tx_def), ETH_MIB_TX_DEF },\n\t{ \"tx_carrier_sense\", GEN_STAT(mib.tx_crs), ETH_MIB_TX_CRS },\n\t{ \"tx_pause\", GEN_STAT(mib.tx_pause), ETH_MIB_TX_PAUSE },\n\n};\n\n#define BCM_ENET_STATS_LEN\tARRAY_SIZE(bcm_enet_gstrings_stats)\n\nstatic const u32 unused_mib_regs[] = {\n\tETH_MIB_TX_ALL_OCTETS,\n\tETH_MIB_TX_ALL_PKTS,\n\tETH_MIB_RX_ALL_OCTETS,\n\tETH_MIB_RX_ALL_PKTS,\n};\n\n\nstatic void bcm_enet_get_drvinfo(struct net_device *netdev,\n\t\t\t\t struct ethtool_drvinfo *drvinfo)\n{\n\tstrscpy(drvinfo->driver, bcm_enet_driver_name, sizeof(drvinfo->driver));\n\tstrscpy(drvinfo->bus_info, \"bcm63xx\", sizeof(drvinfo->bus_info));\n}\n\nstatic int bcm_enet_get_sset_count(struct net_device *netdev,\n\t\t\t\t\tint string_set)\n{\n\tswitch (string_set) {\n\tcase ETH_SS_STATS:\n\t\treturn BCM_ENET_STATS_LEN;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void bcm_enet_get_strings(struct net_device *netdev,\n\t\t\t\t u32 stringset, u8 *data)\n{\n\tint i;\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tfor (i = 0; i < BCM_ENET_STATS_LEN; i++) {\n\t\t\tmemcpy(data + i * ETH_GSTRING_LEN,\n\t\t\t       bcm_enet_gstrings_stats[i].stat_string,\n\t\t\t       ETH_GSTRING_LEN);\n\t\t}\n\t\tbreak;\n\t}\n}\n\nstatic void update_mib_counters(struct bcm_enet_priv *priv)\n{\n\tint i;\n\n\tfor (i = 0; i < BCM_ENET_STATS_LEN; i++) {\n\t\tconst struct bcm_enet_stats *s;\n\t\tu32 val;\n\t\tchar *p;\n\n\t\ts = &bcm_enet_gstrings_stats[i];\n\t\tif (s->mib_reg == -1)\n\t\t\tcontinue;\n\n\t\tval = enet_readl(priv, ENET_MIB_REG(s->mib_reg));\n\t\tp = (char *)priv + s->stat_offset;\n\n\t\tif (s->sizeof_stat == sizeof(u64))\n\t\t\t*(u64 *)p += val;\n\t\telse\n\t\t\t*(u32 *)p += val;\n\t}\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(unused_mib_regs); i++)\n\t\t(void)enet_readl(priv, ENET_MIB_REG(unused_mib_regs[i]));\n}\n\nstatic void bcm_enet_update_mib_counters_defer(struct work_struct *t)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = container_of(t, struct bcm_enet_priv, mib_update_task);\n\tmutex_lock(&priv->mib_update_lock);\n\tupdate_mib_counters(priv);\n\tmutex_unlock(&priv->mib_update_lock);\n\n\t \n\tif (netif_running(priv->net_dev))\n\t\tenet_writel(priv, ENET_IR_MIB, ENET_IRMASK_REG);\n}\n\nstatic void bcm_enet_get_ethtool_stats(struct net_device *netdev,\n\t\t\t\t       struct ethtool_stats *stats,\n\t\t\t\t       u64 *data)\n{\n\tstruct bcm_enet_priv *priv;\n\tint i;\n\n\tpriv = netdev_priv(netdev);\n\n\tmutex_lock(&priv->mib_update_lock);\n\tupdate_mib_counters(priv);\n\n\tfor (i = 0; i < BCM_ENET_STATS_LEN; i++) {\n\t\tconst struct bcm_enet_stats *s;\n\t\tchar *p;\n\n\t\ts = &bcm_enet_gstrings_stats[i];\n\t\tif (s->mib_reg == -1)\n\t\t\tp = (char *)&netdev->stats;\n\t\telse\n\t\t\tp = (char *)priv;\n\t\tp += s->stat_offset;\n\t\tdata[i] = (s->sizeof_stat == sizeof(u64)) ?\n\t\t\t*(u64 *)p : *(u32 *)p;\n\t}\n\tmutex_unlock(&priv->mib_update_lock);\n}\n\nstatic int bcm_enet_nway_reset(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\tif (priv->has_phy)\n\t\treturn phy_ethtool_nway_reset(dev);\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int bcm_enet_get_link_ksettings(struct net_device *dev,\n\t\t\t\t       struct ethtool_link_ksettings *cmd)\n{\n\tstruct bcm_enet_priv *priv;\n\tu32 supported, advertising;\n\n\tpriv = netdev_priv(dev);\n\n\tif (priv->has_phy) {\n\t\tif (!dev->phydev)\n\t\t\treturn -ENODEV;\n\n\t\tphy_ethtool_ksettings_get(dev->phydev, cmd);\n\n\t\treturn 0;\n\t} else {\n\t\tcmd->base.autoneg = 0;\n\t\tcmd->base.speed = (priv->force_speed_100) ?\n\t\t\tSPEED_100 : SPEED_10;\n\t\tcmd->base.duplex = (priv->force_duplex_full) ?\n\t\t\tDUPLEX_FULL : DUPLEX_HALF;\n\t\tsupported = ADVERTISED_10baseT_Half |\n\t\t\tADVERTISED_10baseT_Full |\n\t\t\tADVERTISED_100baseT_Half |\n\t\t\tADVERTISED_100baseT_Full;\n\t\tadvertising = 0;\n\t\tethtool_convert_legacy_u32_to_link_mode(\n\t\t\tcmd->link_modes.supported, supported);\n\t\tethtool_convert_legacy_u32_to_link_mode(\n\t\t\tcmd->link_modes.advertising, advertising);\n\t\tcmd->base.port = PORT_MII;\n\t}\n\treturn 0;\n}\n\nstatic int bcm_enet_set_link_ksettings(struct net_device *dev,\n\t\t\t\t       const struct ethtool_link_ksettings *cmd)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\tif (priv->has_phy) {\n\t\tif (!dev->phydev)\n\t\t\treturn -ENODEV;\n\t\treturn phy_ethtool_ksettings_set(dev->phydev, cmd);\n\t} else {\n\n\t\tif (cmd->base.autoneg ||\n\t\t    (cmd->base.speed != SPEED_100 &&\n\t\t     cmd->base.speed != SPEED_10) ||\n\t\t    cmd->base.port != PORT_MII)\n\t\t\treturn -EINVAL;\n\n\t\tpriv->force_speed_100 =\n\t\t\t(cmd->base.speed == SPEED_100) ? 1 : 0;\n\t\tpriv->force_duplex_full =\n\t\t\t(cmd->base.duplex == DUPLEX_FULL) ? 1 : 0;\n\n\t\tif (netif_running(dev))\n\t\t\tbcm_enet_adjust_link(dev);\n\t\treturn 0;\n\t}\n}\n\nstatic void\nbcm_enet_get_ringparam(struct net_device *dev,\n\t\t       struct ethtool_ringparam *ering,\n\t\t       struct kernel_ethtool_ringparam *kernel_ering,\n\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\n\t \n\tering->rx_max_pending = 8192;\n\tering->tx_max_pending = 8192;\n\tering->rx_pending = priv->rx_ring_size;\n\tering->tx_pending = priv->tx_ring_size;\n}\n\nstatic int bcm_enet_set_ringparam(struct net_device *dev,\n\t\t\t\t  struct ethtool_ringparam *ering,\n\t\t\t\t  struct kernel_ethtool_ringparam *kernel_ering,\n\t\t\t\t  struct netlink_ext_ack *extack)\n{\n\tstruct bcm_enet_priv *priv;\n\tint was_running;\n\n\tpriv = netdev_priv(dev);\n\n\twas_running = 0;\n\tif (netif_running(dev)) {\n\t\tbcm_enet_stop(dev);\n\t\twas_running = 1;\n\t}\n\n\tpriv->rx_ring_size = ering->rx_pending;\n\tpriv->tx_ring_size = ering->tx_pending;\n\n\tif (was_running) {\n\t\tint err;\n\n\t\terr = bcm_enet_open(dev);\n\t\tif (err)\n\t\t\tdev_close(dev);\n\t\telse\n\t\t\tbcm_enet_set_multicast_list(dev);\n\t}\n\treturn 0;\n}\n\nstatic void bcm_enet_get_pauseparam(struct net_device *dev,\n\t\t\t\t    struct ethtool_pauseparam *ecmd)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\tecmd->autoneg = priv->pause_auto;\n\tecmd->rx_pause = priv->pause_rx;\n\tecmd->tx_pause = priv->pause_tx;\n}\n\nstatic int bcm_enet_set_pauseparam(struct net_device *dev,\n\t\t\t\t   struct ethtool_pauseparam *ecmd)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\n\tif (priv->has_phy) {\n\t\tif (ecmd->autoneg && (ecmd->rx_pause != ecmd->tx_pause)) {\n\t\t\t \n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\t \n\t\tif (ecmd->autoneg)\n\t\t\treturn -EINVAL;\n\t}\n\n\tpriv->pause_auto = ecmd->autoneg;\n\tpriv->pause_rx = ecmd->rx_pause;\n\tpriv->pause_tx = ecmd->tx_pause;\n\n\treturn 0;\n}\n\nstatic const struct ethtool_ops bcm_enet_ethtool_ops = {\n\t.get_strings\t\t= bcm_enet_get_strings,\n\t.get_sset_count\t\t= bcm_enet_get_sset_count,\n\t.get_ethtool_stats      = bcm_enet_get_ethtool_stats,\n\t.nway_reset\t\t= bcm_enet_nway_reset,\n\t.get_drvinfo\t\t= bcm_enet_get_drvinfo,\n\t.get_link\t\t= ethtool_op_get_link,\n\t.get_ringparam\t\t= bcm_enet_get_ringparam,\n\t.set_ringparam\t\t= bcm_enet_set_ringparam,\n\t.get_pauseparam\t\t= bcm_enet_get_pauseparam,\n\t.set_pauseparam\t\t= bcm_enet_set_pauseparam,\n\t.get_link_ksettings\t= bcm_enet_get_link_ksettings,\n\t.set_link_ksettings\t= bcm_enet_set_link_ksettings,\n};\n\nstatic int bcm_enet_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\tif (priv->has_phy) {\n\t\tif (!dev->phydev)\n\t\t\treturn -ENODEV;\n\t\treturn phy_mii_ioctl(dev->phydev, rq, cmd);\n\t} else {\n\t\tstruct mii_if_info mii;\n\n\t\tmii.dev = dev;\n\t\tmii.mdio_read = bcm_enet_mdio_read_mii;\n\t\tmii.mdio_write = bcm_enet_mdio_write_mii;\n\t\tmii.phy_id = 0;\n\t\tmii.phy_id_mask = 0x3f;\n\t\tmii.reg_num_mask = 0x1f;\n\t\treturn generic_mii_ioctl(&mii, if_mii(rq), cmd, NULL);\n\t}\n}\n\n \nstatic int bcm_enet_change_mtu(struct net_device *dev, int new_mtu)\n{\n\tstruct bcm_enet_priv *priv = netdev_priv(dev);\n\tint actual_mtu = new_mtu;\n\n\tif (netif_running(dev))\n\t\treturn -EBUSY;\n\n\t \n\tactual_mtu += VLAN_ETH_HLEN;\n\n\t \n\tpriv->hw_mtu = actual_mtu;\n\n\t \n\tpriv->rx_buf_size = ALIGN(actual_mtu + ETH_FCS_LEN,\n\t\t\t\t  priv->dma_maxburst * 4);\n\n\tpriv->rx_frag_size = SKB_DATA_ALIGN(priv->rx_buf_offset + priv->rx_buf_size) +\n\t\t\t\t\t    SKB_DATA_ALIGN(sizeof(struct skb_shared_info));\n\n\tdev->mtu = new_mtu;\n\treturn 0;\n}\n\n \nstatic void bcm_enet_hw_preinit(struct bcm_enet_priv *priv)\n{\n\tu32 val;\n\tint limit;\n\n\t \n\tbcm_enet_disable_mac(priv);\n\n\t \n\tval = ENET_CTL_SRESET_MASK;\n\tenet_writel(priv, val, ENET_CTL_REG);\n\twmb();\n\n\tlimit = 1000;\n\tdo {\n\t\tval = enet_readl(priv, ENET_CTL_REG);\n\t\tif (!(val & ENET_CTL_SRESET_MASK))\n\t\t\tbreak;\n\t\tudelay(1);\n\t} while (limit--);\n\n\t \n\tval = enet_readl(priv, ENET_CTL_REG);\n\tif (priv->use_external_mii)\n\t\tval |= ENET_CTL_EPHYSEL_MASK;\n\telse\n\t\tval &= ~ENET_CTL_EPHYSEL_MASK;\n\tenet_writel(priv, val, ENET_CTL_REG);\n\n\t \n\tenet_writel(priv, (0x1f << ENET_MIISC_MDCFREQDIV_SHIFT) |\n\t\t    ENET_MIISC_PREAMBLEEN_MASK, ENET_MIISC_REG);\n\n\t \n\tval = enet_readl(priv, ENET_MIBCTL_REG);\n\tval |= ENET_MIBCTL_RDCLEAR_MASK;\n\tenet_writel(priv, val, ENET_MIBCTL_REG);\n}\n\nstatic const struct net_device_ops bcm_enet_ops = {\n\t.ndo_open\t\t= bcm_enet_open,\n\t.ndo_stop\t\t= bcm_enet_stop,\n\t.ndo_start_xmit\t\t= bcm_enet_start_xmit,\n\t.ndo_set_mac_address\t= bcm_enet_set_mac_address,\n\t.ndo_set_rx_mode\t= bcm_enet_set_multicast_list,\n\t.ndo_eth_ioctl\t\t= bcm_enet_ioctl,\n\t.ndo_change_mtu\t\t= bcm_enet_change_mtu,\n};\n\n \nstatic int bcm_enet_probe(struct platform_device *pdev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct net_device *dev;\n\tstruct bcm63xx_enet_platform_data *pd;\n\tint irq, irq_rx, irq_tx;\n\tstruct mii_bus *bus;\n\tint i, ret;\n\n\tif (!bcm_enet_shared_base[0])\n\t\treturn -EPROBE_DEFER;\n\n\tirq = platform_get_irq(pdev, 0);\n\tirq_rx = platform_get_irq(pdev, 1);\n\tirq_tx = platform_get_irq(pdev, 2);\n\tif (irq < 0 || irq_rx < 0 || irq_tx < 0)\n\t\treturn -ENODEV;\n\n\tdev = alloc_etherdev(sizeof(*priv));\n\tif (!dev)\n\t\treturn -ENOMEM;\n\tpriv = netdev_priv(dev);\n\n\tpriv->enet_is_sw = false;\n\tpriv->dma_maxburst = BCMENET_DMA_MAXBURST;\n\tpriv->rx_buf_offset = NET_SKB_PAD;\n\n\tret = bcm_enet_change_mtu(dev, dev->mtu);\n\tif (ret)\n\t\tgoto out;\n\n\tpriv->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(priv->base)) {\n\t\tret = PTR_ERR(priv->base);\n\t\tgoto out;\n\t}\n\n\tdev->irq = priv->irq = irq;\n\tpriv->irq_rx = irq_rx;\n\tpriv->irq_tx = irq_tx;\n\n\tpriv->mac_clk = devm_clk_get(&pdev->dev, \"enet\");\n\tif (IS_ERR(priv->mac_clk)) {\n\t\tret = PTR_ERR(priv->mac_clk);\n\t\tgoto out;\n\t}\n\tret = clk_prepare_enable(priv->mac_clk);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tpriv->rx_ring_size = BCMENET_DEF_RX_DESC;\n\tpriv->tx_ring_size = BCMENET_DEF_TX_DESC;\n\n\tpd = dev_get_platdata(&pdev->dev);\n\tif (pd) {\n\t\teth_hw_addr_set(dev, pd->mac_addr);\n\t\tpriv->has_phy = pd->has_phy;\n\t\tpriv->phy_id = pd->phy_id;\n\t\tpriv->has_phy_interrupt = pd->has_phy_interrupt;\n\t\tpriv->phy_interrupt = pd->phy_interrupt;\n\t\tpriv->use_external_mii = !pd->use_internal_phy;\n\t\tpriv->pause_auto = pd->pause_auto;\n\t\tpriv->pause_rx = pd->pause_rx;\n\t\tpriv->pause_tx = pd->pause_tx;\n\t\tpriv->force_duplex_full = pd->force_duplex_full;\n\t\tpriv->force_speed_100 = pd->force_speed_100;\n\t\tpriv->dma_chan_en_mask = pd->dma_chan_en_mask;\n\t\tpriv->dma_chan_int_mask = pd->dma_chan_int_mask;\n\t\tpriv->dma_chan_width = pd->dma_chan_width;\n\t\tpriv->dma_has_sram = pd->dma_has_sram;\n\t\tpriv->dma_desc_shift = pd->dma_desc_shift;\n\t\tpriv->rx_chan = pd->rx_chan;\n\t\tpriv->tx_chan = pd->tx_chan;\n\t}\n\n\tif (priv->has_phy && !priv->use_external_mii) {\n\t\t \n\t\tpriv->phy_clk = devm_clk_get(&pdev->dev, \"ephy\");\n\t\tif (IS_ERR(priv->phy_clk)) {\n\t\t\tret = PTR_ERR(priv->phy_clk);\n\t\t\tpriv->phy_clk = NULL;\n\t\t\tgoto out_disable_clk_mac;\n\t\t}\n\t\tret = clk_prepare_enable(priv->phy_clk);\n\t\tif (ret)\n\t\t\tgoto out_disable_clk_mac;\n\t}\n\n\t \n\tbcm_enet_hw_preinit(priv);\n\n\t \n\tif (priv->has_phy) {\n\n\t\tpriv->mii_bus = mdiobus_alloc();\n\t\tif (!priv->mii_bus) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_uninit_hw;\n\t\t}\n\n\t\tbus = priv->mii_bus;\n\t\tbus->name = \"bcm63xx_enet MII bus\";\n\t\tbus->parent = &pdev->dev;\n\t\tbus->priv = priv;\n\t\tbus->read = bcm_enet_mdio_read_phylib;\n\t\tbus->write = bcm_enet_mdio_write_phylib;\n\t\tsprintf(bus->id, \"%s-%d\", pdev->name, pdev->id);\n\n\t\t \n\t\tbus->phy_mask = ~(1 << priv->phy_id);\n\n\t\tif (priv->has_phy_interrupt)\n\t\t\tbus->irq[priv->phy_id] = priv->phy_interrupt;\n\n\t\tret = mdiobus_register(bus);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"unable to register mdio bus\\n\");\n\t\t\tgoto out_free_mdio;\n\t\t}\n\t} else {\n\n\t\t \n\t\tif (pd && pd->mii_config &&\n\t\t    pd->mii_config(dev, 1, bcm_enet_mdio_read_mii,\n\t\t\t\t   bcm_enet_mdio_write_mii)) {\n\t\t\tdev_err(&pdev->dev, \"unable to configure mdio bus\\n\");\n\t\t\tgoto out_uninit_hw;\n\t\t}\n\t}\n\n\tspin_lock_init(&priv->rx_lock);\n\n\t \n\ttimer_setup(&priv->rx_timeout, bcm_enet_refill_rx_timer, 0);\n\n\t \n\tmutex_init(&priv->mib_update_lock);\n\tINIT_WORK(&priv->mib_update_task, bcm_enet_update_mib_counters_defer);\n\n\t \n\tfor (i = 0; i < ENET_MIB_REG_COUNT; i++)\n\t\tenet_writel(priv, 0, ENET_MIB_REG(i));\n\n\t \n\tdev->netdev_ops = &bcm_enet_ops;\n\tnetif_napi_add_weight(dev, &priv->napi, bcm_enet_poll, 16);\n\n\tdev->ethtool_ops = &bcm_enet_ethtool_ops;\n\t \n\tdev->min_mtu = ETH_ZLEN - ETH_HLEN;\n\tdev->max_mtu = BCMENET_MAX_MTU - VLAN_ETH_HLEN;\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\tret = register_netdev(dev);\n\tif (ret)\n\t\tgoto out_unregister_mdio;\n\n\tnetif_carrier_off(dev);\n\tplatform_set_drvdata(pdev, dev);\n\tpriv->pdev = pdev;\n\tpriv->net_dev = dev;\n\n\treturn 0;\n\nout_unregister_mdio:\n\tif (priv->mii_bus)\n\t\tmdiobus_unregister(priv->mii_bus);\n\nout_free_mdio:\n\tif (priv->mii_bus)\n\t\tmdiobus_free(priv->mii_bus);\n\nout_uninit_hw:\n\t \n\tenet_writel(priv, 0, ENET_MIISC_REG);\n\tclk_disable_unprepare(priv->phy_clk);\n\nout_disable_clk_mac:\n\tclk_disable_unprepare(priv->mac_clk);\nout:\n\tfree_netdev(dev);\n\treturn ret;\n}\n\n\n \nstatic int bcm_enet_remove(struct platform_device *pdev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct net_device *dev;\n\n\t \n\tdev = platform_get_drvdata(pdev);\n\tpriv = netdev_priv(dev);\n\tunregister_netdev(dev);\n\n\t \n\tenet_writel(priv, 0, ENET_MIISC_REG);\n\n\tif (priv->has_phy) {\n\t\tmdiobus_unregister(priv->mii_bus);\n\t\tmdiobus_free(priv->mii_bus);\n\t} else {\n\t\tstruct bcm63xx_enet_platform_data *pd;\n\n\t\tpd = dev_get_platdata(&pdev->dev);\n\t\tif (pd && pd->mii_config)\n\t\t\tpd->mii_config(dev, 0, bcm_enet_mdio_read_mii,\n\t\t\t\t       bcm_enet_mdio_write_mii);\n\t}\n\n\t \n\tclk_disable_unprepare(priv->phy_clk);\n\tclk_disable_unprepare(priv->mac_clk);\n\n\tfree_netdev(dev);\n\treturn 0;\n}\n\nstatic struct platform_driver bcm63xx_enet_driver = {\n\t.probe\t= bcm_enet_probe,\n\t.remove\t= bcm_enet_remove,\n\t.driver\t= {\n\t\t.name\t= \"bcm63xx_enet\",\n\t},\n};\n\n \nstatic int bcmenet_sw_mdio_read(struct bcm_enet_priv *priv,\n\t\t\t\tint ext, int phy_id, int location)\n{\n\tu32 reg;\n\tint ret;\n\n\tspin_lock_bh(&priv->enetsw_mdio_lock);\n\tenetsw_writel(priv, 0, ENETSW_MDIOC_REG);\n\n\treg = ENETSW_MDIOC_RD_MASK |\n\t\t(phy_id << ENETSW_MDIOC_PHYID_SHIFT) |\n\t\t(location << ENETSW_MDIOC_REG_SHIFT);\n\n\tif (ext)\n\t\treg |= ENETSW_MDIOC_EXT_MASK;\n\n\tenetsw_writel(priv, reg, ENETSW_MDIOC_REG);\n\tudelay(50);\n\tret = enetsw_readw(priv, ENETSW_MDIOD_REG);\n\tspin_unlock_bh(&priv->enetsw_mdio_lock);\n\treturn ret;\n}\n\nstatic void bcmenet_sw_mdio_write(struct bcm_enet_priv *priv,\n\t\t\t\t int ext, int phy_id, int location,\n\t\t\t\t uint16_t data)\n{\n\tu32 reg;\n\n\tspin_lock_bh(&priv->enetsw_mdio_lock);\n\tenetsw_writel(priv, 0, ENETSW_MDIOC_REG);\n\n\treg = ENETSW_MDIOC_WR_MASK |\n\t\t(phy_id << ENETSW_MDIOC_PHYID_SHIFT) |\n\t\t(location << ENETSW_MDIOC_REG_SHIFT);\n\n\tif (ext)\n\t\treg |= ENETSW_MDIOC_EXT_MASK;\n\n\treg |= data;\n\n\tenetsw_writel(priv, reg, ENETSW_MDIOC_REG);\n\tudelay(50);\n\tspin_unlock_bh(&priv->enetsw_mdio_lock);\n}\n\nstatic inline int bcm_enet_port_is_rgmii(int portid)\n{\n\treturn portid >= ENETSW_RGMII_PORT0;\n}\n\n \nstatic void swphy_poll_timer(struct timer_list *t)\n{\n\tstruct bcm_enet_priv *priv = from_timer(priv, t, swphy_poll);\n\tunsigned int i;\n\n\tfor (i = 0; i < priv->num_ports; i++) {\n\t\tstruct bcm63xx_enetsw_port *port;\n\t\tint val, j, up, advertise, lpa, speed, duplex, media;\n\t\tint external_phy = bcm_enet_port_is_rgmii(i);\n\t\tu8 override;\n\n\t\tport = &priv->used_ports[i];\n\t\tif (!port->used)\n\t\t\tcontinue;\n\n\t\tif (port->bypass_link)\n\t\t\tcontinue;\n\n\t\t \n\t\tfor (j = 0; j < 2; j++)\n\t\t\tval = bcmenet_sw_mdio_read(priv, external_phy,\n\t\t\t\t\t\t   port->phy_id, MII_BMSR);\n\n\t\tif (val == 0xffff)\n\t\t\tcontinue;\n\n\t\tup = (val & BMSR_LSTATUS) ? 1 : 0;\n\t\tif (!(up ^ priv->sw_port_link[i]))\n\t\t\tcontinue;\n\n\t\tpriv->sw_port_link[i] = up;\n\n\t\t \n\t\tif (!up) {\n\t\t\tdev_info(&priv->pdev->dev, \"link DOWN on %s\\n\",\n\t\t\t\t port->name);\n\t\t\tenetsw_writeb(priv, ENETSW_PORTOV_ENABLE_MASK,\n\t\t\t\t      ENETSW_PORTOV_REG(i));\n\t\t\tenetsw_writeb(priv, ENETSW_PTCTRL_RXDIS_MASK |\n\t\t\t\t      ENETSW_PTCTRL_TXDIS_MASK,\n\t\t\t\t      ENETSW_PTCTRL_REG(i));\n\t\t\tcontinue;\n\t\t}\n\n\t\tadvertise = bcmenet_sw_mdio_read(priv, external_phy,\n\t\t\t\t\t\t port->phy_id, MII_ADVERTISE);\n\n\t\tlpa = bcmenet_sw_mdio_read(priv, external_phy, port->phy_id,\n\t\t\t\t\t   MII_LPA);\n\n\t\t \n\t\tmedia = mii_nway_result(lpa & advertise);\n\t\tduplex = (media & ADVERTISE_FULL) ? 1 : 0;\n\n\t\tif (media & (ADVERTISE_100FULL | ADVERTISE_100HALF))\n\t\t\tspeed = 100;\n\t\telse\n\t\t\tspeed = 10;\n\n\t\tif (val & BMSR_ESTATEN) {\n\t\t\tadvertise = bcmenet_sw_mdio_read(priv, external_phy,\n\t\t\t\t\t\tport->phy_id, MII_CTRL1000);\n\n\t\t\tlpa = bcmenet_sw_mdio_read(priv, external_phy,\n\t\t\t\t\t\tport->phy_id, MII_STAT1000);\n\n\t\t\tif (advertise & (ADVERTISE_1000FULL | ADVERTISE_1000HALF)\n\t\t\t\t\t&& lpa & (LPA_1000FULL | LPA_1000HALF)) {\n\t\t\t\tspeed = 1000;\n\t\t\t\tduplex = (lpa & LPA_1000FULL);\n\t\t\t}\n\t\t}\n\n\t\tdev_info(&priv->pdev->dev,\n\t\t\t \"link UP on %s, %dMbps, %s-duplex\\n\",\n\t\t\t port->name, speed, duplex ? \"full\" : \"half\");\n\n\t\toverride = ENETSW_PORTOV_ENABLE_MASK |\n\t\t\tENETSW_PORTOV_LINKUP_MASK;\n\n\t\tif (speed == 1000)\n\t\t\toverride |= ENETSW_IMPOV_1000_MASK;\n\t\telse if (speed == 100)\n\t\t\toverride |= ENETSW_IMPOV_100_MASK;\n\t\tif (duplex)\n\t\t\toverride |= ENETSW_IMPOV_FDX_MASK;\n\n\t\tenetsw_writeb(priv, override, ENETSW_PORTOV_REG(i));\n\t\tenetsw_writeb(priv, 0, ENETSW_PTCTRL_REG(i));\n\t}\n\n\tpriv->swphy_poll.expires = jiffies + HZ;\n\tadd_timer(&priv->swphy_poll);\n}\n\n \nstatic int bcm_enetsw_open(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct device *kdev;\n\tint i, ret;\n\tunsigned int size;\n\tvoid *p;\n\tu32 val;\n\n\tpriv = netdev_priv(dev);\n\tkdev = &priv->pdev->dev;\n\n\t \n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->tx_chan);\n\n\tret = request_irq(priv->irq_rx, bcm_enet_isr_dma,\n\t\t\t  0, dev->name, dev);\n\tif (ret)\n\t\tgoto out_freeirq;\n\n\tif (priv->irq_tx != -1) {\n\t\tret = request_irq(priv->irq_tx, bcm_enet_isr_dma,\n\t\t\t\t  0, dev->name, dev);\n\t\tif (ret)\n\t\t\tgoto out_freeirq_rx;\n\t}\n\n\t \n\tsize = priv->rx_ring_size * sizeof(struct bcm_enet_desc);\n\tp = dma_alloc_coherent(kdev, size, &priv->rx_desc_dma, GFP_KERNEL);\n\tif (!p) {\n\t\tdev_err(kdev, \"cannot allocate rx ring %u\\n\", size);\n\t\tret = -ENOMEM;\n\t\tgoto out_freeirq_tx;\n\t}\n\n\tpriv->rx_desc_alloc_size = size;\n\tpriv->rx_desc_cpu = p;\n\n\t \n\tsize = priv->tx_ring_size * sizeof(struct bcm_enet_desc);\n\tp = dma_alloc_coherent(kdev, size, &priv->tx_desc_dma, GFP_KERNEL);\n\tif (!p) {\n\t\tdev_err(kdev, \"cannot allocate tx ring\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_free_rx_ring;\n\t}\n\n\tpriv->tx_desc_alloc_size = size;\n\tpriv->tx_desc_cpu = p;\n\n\tpriv->tx_skb = kcalloc(priv->tx_ring_size, sizeof(struct sk_buff *),\n\t\t\t       GFP_KERNEL);\n\tif (!priv->tx_skb) {\n\t\tdev_err(kdev, \"cannot allocate tx skb queue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_free_tx_ring;\n\t}\n\n\tpriv->tx_desc_count = priv->tx_ring_size;\n\tpriv->tx_dirty_desc = 0;\n\tpriv->tx_curr_desc = 0;\n\tspin_lock_init(&priv->tx_lock);\n\n\t \n\tpriv->rx_buf = kcalloc(priv->rx_ring_size, sizeof(void *),\n\t\t\t       GFP_KERNEL);\n\tif (!priv->rx_buf) {\n\t\tdev_err(kdev, \"cannot allocate rx buffer queue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_free_tx_skb;\n\t}\n\n\tpriv->rx_desc_count = 0;\n\tpriv->rx_dirty_desc = 0;\n\tpriv->rx_curr_desc = 0;\n\n\t \n\tfor (i = 0; i < priv->num_ports; i++) {\n\t\tenetsw_writeb(priv, ENETSW_PORTOV_ENABLE_MASK,\n\t\t\t      ENETSW_PORTOV_REG(i));\n\t\tenetsw_writeb(priv, ENETSW_PTCTRL_RXDIS_MASK |\n\t\t\t      ENETSW_PTCTRL_TXDIS_MASK,\n\t\t\t      ENETSW_PTCTRL_REG(i));\n\n\t\tpriv->sw_port_link[i] = 0;\n\t}\n\n\t \n\tval = enetsw_readb(priv, ENETSW_GMCR_REG);\n\tval |= ENETSW_GMCR_RST_MIB_MASK;\n\tenetsw_writeb(priv, val, ENETSW_GMCR_REG);\n\tmdelay(1);\n\tval &= ~ENETSW_GMCR_RST_MIB_MASK;\n\tenetsw_writeb(priv, val, ENETSW_GMCR_REG);\n\tmdelay(1);\n\n\t \n\tval = enetsw_readb(priv, ENETSW_IMPOV_REG);\n\tval |= ENETSW_IMPOV_FORCE_MASK | ENETSW_IMPOV_LINKUP_MASK;\n\tenetsw_writeb(priv, val, ENETSW_IMPOV_REG);\n\n\t \n\tval = enetsw_readb(priv, ENETSW_SWMODE_REG);\n\tval |= ENETSW_SWMODE_FWD_EN_MASK;\n\tenetsw_writeb(priv, val, ENETSW_SWMODE_REG);\n\n\t \n\tenetsw_writel(priv, 0x1ff, ENETSW_JMBCTL_PORT_REG);\n\tenetsw_writew(priv, 9728, ENETSW_JMBCTL_MAXSIZE_REG);\n\n\t \n\tenet_dma_writel(priv, ENETDMA_BUFALLOC_FORCE_MASK | 0,\n\t\t\tENETDMA_BUFALLOC_REG(priv->rx_chan));\n\n\tif (bcm_enet_refill_rx(dev, false)) {\n\t\tdev_err(kdev, \"cannot allocate rx buffer queue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t \n\tenet_dmas_writel(priv, priv->rx_desc_dma,\n\t\t\t ENETDMAS_RSTART_REG, priv->rx_chan);\n\tenet_dmas_writel(priv, priv->tx_desc_dma,\n\t\t\t ENETDMAS_RSTART_REG, priv->tx_chan);\n\n\t \n\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM2_REG, priv->rx_chan);\n\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM2_REG, priv->tx_chan);\n\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM3_REG, priv->rx_chan);\n\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM3_REG, priv->tx_chan);\n\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM4_REG, priv->rx_chan);\n\tenet_dmas_writel(priv, 0, ENETDMAS_SRAM4_REG, priv->tx_chan);\n\n\t \n\tenet_dmac_writel(priv, priv->dma_maxburst,\n\t\t\t ENETDMAC_MAXBURST, priv->rx_chan);\n\tenet_dmac_writel(priv, priv->dma_maxburst,\n\t\t\t ENETDMAC_MAXBURST, priv->tx_chan);\n\n\t \n\tval = priv->rx_ring_size / 3;\n\tenet_dma_writel(priv, val, ENETDMA_FLOWCL_REG(priv->rx_chan));\n\tval = (priv->rx_ring_size * 2) / 3;\n\tenet_dma_writel(priv, val, ENETDMA_FLOWCH_REG(priv->rx_chan));\n\n\t \n\twmb();\n\tenet_dma_writel(priv, ENETDMA_CFG_EN_MASK, ENETDMA_CFG_REG);\n\tenet_dmac_writel(priv, ENETDMAC_CHANCFG_EN_MASK,\n\t\t\t ENETDMAC_CHANCFG, priv->rx_chan);\n\n\t \n\tenet_dmac_writel(priv, ENETDMAC_IR_PKTDONE_MASK,\n\t\t\t ENETDMAC_IR, priv->rx_chan);\n\tenet_dmac_writel(priv, ENETDMAC_IR_PKTDONE_MASK,\n\t\t\t ENETDMAC_IR, priv->tx_chan);\n\n\t \n\tnapi_enable(&priv->napi);\n\n\tenet_dmac_writel(priv, ENETDMAC_IR_PKTDONE_MASK,\n\t\t\t ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, ENETDMAC_IR_PKTDONE_MASK,\n\t\t\t ENETDMAC_IRMASK, priv->tx_chan);\n\n\tnetif_carrier_on(dev);\n\tnetif_start_queue(dev);\n\n\t \n\tfor (i = 0; i < priv->num_ports; i++) {\n\t\tstruct bcm63xx_enetsw_port *port;\n\t\tu8 override;\n\t\tport = &priv->used_ports[i];\n\t\tif (!port->used)\n\t\t\tcontinue;\n\n\t\tif (!port->bypass_link)\n\t\t\tcontinue;\n\n\t\toverride = ENETSW_PORTOV_ENABLE_MASK |\n\t\t\tENETSW_PORTOV_LINKUP_MASK;\n\n\t\tswitch (port->force_speed) {\n\t\tcase 1000:\n\t\t\toverride |= ENETSW_IMPOV_1000_MASK;\n\t\t\tbreak;\n\t\tcase 100:\n\t\t\toverride |= ENETSW_IMPOV_100_MASK;\n\t\t\tbreak;\n\t\tcase 10:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_warn(\"invalid forced speed on port %s: assume 10\\n\",\n\t\t\t       port->name);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (port->force_duplex_full)\n\t\t\toverride |= ENETSW_IMPOV_FDX_MASK;\n\n\n\t\tenetsw_writeb(priv, override, ENETSW_PORTOV_REG(i));\n\t\tenetsw_writeb(priv, 0, ENETSW_PTCTRL_REG(i));\n\t}\n\n\t \n\ttimer_setup(&priv->swphy_poll, swphy_poll_timer, 0);\n\tmod_timer(&priv->swphy_poll, jiffies);\n\treturn 0;\n\nout:\n\tbcm_enet_free_rx_buf_ring(kdev, priv);\n\nout_free_tx_skb:\n\tkfree(priv->tx_skb);\n\nout_free_tx_ring:\n\tdma_free_coherent(kdev, priv->tx_desc_alloc_size,\n\t\t\t  priv->tx_desc_cpu, priv->tx_desc_dma);\n\nout_free_rx_ring:\n\tdma_free_coherent(kdev, priv->rx_desc_alloc_size,\n\t\t\t  priv->rx_desc_cpu, priv->rx_desc_dma);\n\nout_freeirq_tx:\n\tif (priv->irq_tx != -1)\n\t\tfree_irq(priv->irq_tx, dev);\n\nout_freeirq_rx:\n\tfree_irq(priv->irq_rx, dev);\n\nout_freeirq:\n\treturn ret;\n}\n\n \nstatic int bcm_enetsw_stop(struct net_device *dev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct device *kdev;\n\n\tpriv = netdev_priv(dev);\n\tkdev = &priv->pdev->dev;\n\n\tdel_timer_sync(&priv->swphy_poll);\n\tnetif_stop_queue(dev);\n\tnapi_disable(&priv->napi);\n\tdel_timer_sync(&priv->rx_timeout);\n\n\t \n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->rx_chan);\n\tenet_dmac_writel(priv, 0, ENETDMAC_IRMASK, priv->tx_chan);\n\n\t \n\tbcm_enet_disable_dma(priv, priv->tx_chan);\n\tbcm_enet_disable_dma(priv, priv->rx_chan);\n\n\t \n\tbcm_enet_tx_reclaim(dev, 1, 0);\n\n\t \n\tbcm_enet_free_rx_buf_ring(kdev, priv);\n\n\t \n\tkfree(priv->tx_skb);\n\tdma_free_coherent(kdev, priv->rx_desc_alloc_size,\n\t\t\t  priv->rx_desc_cpu, priv->rx_desc_dma);\n\tdma_free_coherent(kdev, priv->tx_desc_alloc_size,\n\t\t\t  priv->tx_desc_cpu, priv->tx_desc_dma);\n\tif (priv->irq_tx != -1)\n\t\tfree_irq(priv->irq_tx, dev);\n\tfree_irq(priv->irq_rx, dev);\n\n\t \n\tnetdev_reset_queue(dev);\n\n\treturn 0;\n}\n\n \nstatic int bcm_enetsw_phy_is_external(struct bcm_enet_priv *priv, int phy_id)\n{\n\tint i;\n\n\tfor (i = 0; i < priv->num_ports; ++i) {\n\t\tif (!priv->used_ports[i].used)\n\t\t\tcontinue;\n\t\tif (priv->used_ports[i].phy_id == phy_id)\n\t\t\treturn bcm_enet_port_is_rgmii(i);\n\t}\n\n\tprintk_once(KERN_WARNING  \"bcm63xx_enet: could not find a used port with phy_id %i, assuming phy is external\\n\",\n\t\t    phy_id);\n\treturn 1;\n}\n\n \nstatic int bcm_enetsw_mii_mdio_read(struct net_device *dev, int phy_id,\n\t\t\t\t    int location)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\treturn bcmenet_sw_mdio_read(priv,\n\t\t\t\t    bcm_enetsw_phy_is_external(priv, phy_id),\n\t\t\t\t    phy_id, location);\n}\n\n \nstatic void bcm_enetsw_mii_mdio_write(struct net_device *dev, int phy_id,\n\t\t\t\t      int location,\n\t\t\t\t      int val)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\tbcmenet_sw_mdio_write(priv, bcm_enetsw_phy_is_external(priv, phy_id),\n\t\t\t      phy_id, location, val);\n}\n\nstatic int bcm_enetsw_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tstruct mii_if_info mii;\n\n\tmii.dev = dev;\n\tmii.mdio_read = bcm_enetsw_mii_mdio_read;\n\tmii.mdio_write = bcm_enetsw_mii_mdio_write;\n\tmii.phy_id = 0;\n\tmii.phy_id_mask = 0x3f;\n\tmii.reg_num_mask = 0x1f;\n\treturn generic_mii_ioctl(&mii, if_mii(rq), cmd, NULL);\n\n}\n\nstatic const struct net_device_ops bcm_enetsw_ops = {\n\t.ndo_open\t\t= bcm_enetsw_open,\n\t.ndo_stop\t\t= bcm_enetsw_stop,\n\t.ndo_start_xmit\t\t= bcm_enet_start_xmit,\n\t.ndo_change_mtu\t\t= bcm_enet_change_mtu,\n\t.ndo_eth_ioctl\t\t= bcm_enetsw_ioctl,\n};\n\n\nstatic const struct bcm_enet_stats bcm_enetsw_gstrings_stats[] = {\n\t{ \"rx_packets\", DEV_STAT(rx_packets), -1 },\n\t{ \"tx_packets\",\tDEV_STAT(tx_packets), -1 },\n\t{ \"rx_bytes\", DEV_STAT(rx_bytes), -1 },\n\t{ \"tx_bytes\", DEV_STAT(tx_bytes), -1 },\n\t{ \"rx_errors\", DEV_STAT(rx_errors), -1 },\n\t{ \"tx_errors\", DEV_STAT(tx_errors), -1 },\n\t{ \"rx_dropped\",\tDEV_STAT(rx_dropped), -1 },\n\t{ \"tx_dropped\",\tDEV_STAT(tx_dropped), -1 },\n\n\t{ \"tx_good_octets\", GEN_STAT(mib.tx_gd_octets), ETHSW_MIB_RX_GD_OCT },\n\t{ \"tx_unicast\", GEN_STAT(mib.tx_unicast), ETHSW_MIB_RX_BRDCAST },\n\t{ \"tx_broadcast\", GEN_STAT(mib.tx_brdcast), ETHSW_MIB_RX_BRDCAST },\n\t{ \"tx_multicast\", GEN_STAT(mib.tx_mult), ETHSW_MIB_RX_MULT },\n\t{ \"tx_64_octets\", GEN_STAT(mib.tx_64), ETHSW_MIB_RX_64 },\n\t{ \"tx_65_127_oct\", GEN_STAT(mib.tx_65_127), ETHSW_MIB_RX_65_127 },\n\t{ \"tx_128_255_oct\", GEN_STAT(mib.tx_128_255), ETHSW_MIB_RX_128_255 },\n\t{ \"tx_256_511_oct\", GEN_STAT(mib.tx_256_511), ETHSW_MIB_RX_256_511 },\n\t{ \"tx_512_1023_oct\", GEN_STAT(mib.tx_512_1023), ETHSW_MIB_RX_512_1023},\n\t{ \"tx_1024_1522_oct\", GEN_STAT(mib.tx_1024_max),\n\t  ETHSW_MIB_RX_1024_1522 },\n\t{ \"tx_1523_2047_oct\", GEN_STAT(mib.tx_1523_2047),\n\t  ETHSW_MIB_RX_1523_2047 },\n\t{ \"tx_2048_4095_oct\", GEN_STAT(mib.tx_2048_4095),\n\t  ETHSW_MIB_RX_2048_4095 },\n\t{ \"tx_4096_8191_oct\", GEN_STAT(mib.tx_4096_8191),\n\t  ETHSW_MIB_RX_4096_8191 },\n\t{ \"tx_8192_9728_oct\", GEN_STAT(mib.tx_8192_9728),\n\t  ETHSW_MIB_RX_8192_9728 },\n\t{ \"tx_oversize\", GEN_STAT(mib.tx_ovr), ETHSW_MIB_RX_OVR },\n\t{ \"tx_oversize_drop\", GEN_STAT(mib.tx_ovr), ETHSW_MIB_RX_OVR_DISC },\n\t{ \"tx_dropped\",\tGEN_STAT(mib.tx_drop), ETHSW_MIB_RX_DROP },\n\t{ \"tx_undersize\", GEN_STAT(mib.tx_underrun), ETHSW_MIB_RX_UND },\n\t{ \"tx_pause\", GEN_STAT(mib.tx_pause), ETHSW_MIB_RX_PAUSE },\n\n\t{ \"rx_good_octets\", GEN_STAT(mib.rx_gd_octets), ETHSW_MIB_TX_ALL_OCT },\n\t{ \"rx_broadcast\", GEN_STAT(mib.rx_brdcast), ETHSW_MIB_TX_BRDCAST },\n\t{ \"rx_multicast\", GEN_STAT(mib.rx_mult), ETHSW_MIB_TX_MULT },\n\t{ \"rx_unicast\", GEN_STAT(mib.rx_unicast), ETHSW_MIB_TX_MULT },\n\t{ \"rx_pause\", GEN_STAT(mib.rx_pause), ETHSW_MIB_TX_PAUSE },\n\t{ \"rx_dropped\", GEN_STAT(mib.rx_drop), ETHSW_MIB_TX_DROP_PKTS },\n\n};\n\n#define BCM_ENETSW_STATS_LEN\t\\\n\t(sizeof(bcm_enetsw_gstrings_stats) / sizeof(struct bcm_enet_stats))\n\nstatic void bcm_enetsw_get_strings(struct net_device *netdev,\n\t\t\t\t   u32 stringset, u8 *data)\n{\n\tint i;\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tfor (i = 0; i < BCM_ENETSW_STATS_LEN; i++) {\n\t\t\tmemcpy(data + i * ETH_GSTRING_LEN,\n\t\t\t       bcm_enetsw_gstrings_stats[i].stat_string,\n\t\t\t       ETH_GSTRING_LEN);\n\t\t}\n\t\tbreak;\n\t}\n}\n\nstatic int bcm_enetsw_get_sset_count(struct net_device *netdev,\n\t\t\t\t     int string_set)\n{\n\tswitch (string_set) {\n\tcase ETH_SS_STATS:\n\t\treturn BCM_ENETSW_STATS_LEN;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void bcm_enetsw_get_drvinfo(struct net_device *netdev,\n\t\t\t\t   struct ethtool_drvinfo *drvinfo)\n{\n\tstrncpy(drvinfo->driver, bcm_enet_driver_name, sizeof(drvinfo->driver));\n\tstrncpy(drvinfo->bus_info, \"bcm63xx\", sizeof(drvinfo->bus_info));\n}\n\nstatic void bcm_enetsw_get_ethtool_stats(struct net_device *netdev,\n\t\t\t\t\t struct ethtool_stats *stats,\n\t\t\t\t\t u64 *data)\n{\n\tstruct bcm_enet_priv *priv;\n\tint i;\n\n\tpriv = netdev_priv(netdev);\n\n\tfor (i = 0; i < BCM_ENETSW_STATS_LEN; i++) {\n\t\tconst struct bcm_enet_stats *s;\n\t\tu32 lo, hi;\n\t\tchar *p;\n\t\tint reg;\n\n\t\ts = &bcm_enetsw_gstrings_stats[i];\n\n\t\treg = s->mib_reg;\n\t\tif (reg == -1)\n\t\t\tcontinue;\n\n\t\tlo = enetsw_readl(priv, ENETSW_MIB_REG(reg));\n\t\tp = (char *)priv + s->stat_offset;\n\n\t\tif (s->sizeof_stat == sizeof(u64)) {\n\t\t\thi = enetsw_readl(priv, ENETSW_MIB_REG(reg + 1));\n\t\t\t*(u64 *)p = ((u64)hi << 32 | lo);\n\t\t} else {\n\t\t\t*(u32 *)p = lo;\n\t\t}\n\t}\n\n\tfor (i = 0; i < BCM_ENETSW_STATS_LEN; i++) {\n\t\tconst struct bcm_enet_stats *s;\n\t\tchar *p;\n\n\t\ts = &bcm_enetsw_gstrings_stats[i];\n\n\t\tif (s->mib_reg == -1)\n\t\t\tp = (char *)&netdev->stats + s->stat_offset;\n\t\telse\n\t\t\tp = (char *)priv + s->stat_offset;\n\n\t\tdata[i] = (s->sizeof_stat == sizeof(u64)) ?\n\t\t\t*(u64 *)p : *(u32 *)p;\n\t}\n}\n\nstatic void\nbcm_enetsw_get_ringparam(struct net_device *dev,\n\t\t\t struct ethtool_ringparam *ering,\n\t\t\t struct kernel_ethtool_ringparam *kernel_ering,\n\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct bcm_enet_priv *priv;\n\n\tpriv = netdev_priv(dev);\n\n\t \n\tering->rx_max_pending = 8192;\n\tering->tx_max_pending = 8192;\n\tering->rx_mini_max_pending = 0;\n\tering->rx_jumbo_max_pending = 0;\n\tering->rx_pending = priv->rx_ring_size;\n\tering->tx_pending = priv->tx_ring_size;\n}\n\nstatic int\nbcm_enetsw_set_ringparam(struct net_device *dev,\n\t\t\t struct ethtool_ringparam *ering,\n\t\t\t struct kernel_ethtool_ringparam *kernel_ering,\n\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct bcm_enet_priv *priv;\n\tint was_running;\n\n\tpriv = netdev_priv(dev);\n\n\twas_running = 0;\n\tif (netif_running(dev)) {\n\t\tbcm_enetsw_stop(dev);\n\t\twas_running = 1;\n\t}\n\n\tpriv->rx_ring_size = ering->rx_pending;\n\tpriv->tx_ring_size = ering->tx_pending;\n\n\tif (was_running) {\n\t\tint err;\n\n\t\terr = bcm_enetsw_open(dev);\n\t\tif (err)\n\t\t\tdev_close(dev);\n\t}\n\treturn 0;\n}\n\nstatic const struct ethtool_ops bcm_enetsw_ethtool_ops = {\n\t.get_strings\t\t= bcm_enetsw_get_strings,\n\t.get_sset_count\t\t= bcm_enetsw_get_sset_count,\n\t.get_ethtool_stats      = bcm_enetsw_get_ethtool_stats,\n\t.get_drvinfo\t\t= bcm_enetsw_get_drvinfo,\n\t.get_ringparam\t\t= bcm_enetsw_get_ringparam,\n\t.set_ringparam\t\t= bcm_enetsw_set_ringparam,\n};\n\n \nstatic int bcm_enetsw_probe(struct platform_device *pdev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct net_device *dev;\n\tstruct bcm63xx_enetsw_platform_data *pd;\n\tstruct resource *res_mem;\n\tint ret, irq_rx, irq_tx;\n\n\tif (!bcm_enet_shared_base[0])\n\t\treturn -EPROBE_DEFER;\n\n\tres_mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tirq_rx = platform_get_irq(pdev, 0);\n\tirq_tx = platform_get_irq(pdev, 1);\n\tif (!res_mem || irq_rx < 0)\n\t\treturn -ENODEV;\n\n\tdev = alloc_etherdev(sizeof(*priv));\n\tif (!dev)\n\t\treturn -ENOMEM;\n\tpriv = netdev_priv(dev);\n\n\t \n\tpriv->enet_is_sw = true;\n\tpriv->irq_rx = irq_rx;\n\tpriv->irq_tx = irq_tx;\n\tpriv->rx_ring_size = BCMENET_DEF_RX_DESC;\n\tpriv->tx_ring_size = BCMENET_DEF_TX_DESC;\n\tpriv->dma_maxburst = BCMENETSW_DMA_MAXBURST;\n\tpriv->rx_buf_offset = NET_SKB_PAD + NET_IP_ALIGN;\n\n\tpd = dev_get_platdata(&pdev->dev);\n\tif (pd) {\n\t\teth_hw_addr_set(dev, pd->mac_addr);\n\t\tmemcpy(priv->used_ports, pd->used_ports,\n\t\t       sizeof(pd->used_ports));\n\t\tpriv->num_ports = pd->num_ports;\n\t\tpriv->dma_has_sram = pd->dma_has_sram;\n\t\tpriv->dma_chan_en_mask = pd->dma_chan_en_mask;\n\t\tpriv->dma_chan_int_mask = pd->dma_chan_int_mask;\n\t\tpriv->dma_chan_width = pd->dma_chan_width;\n\t}\n\n\tret = bcm_enet_change_mtu(dev, dev->mtu);\n\tif (ret)\n\t\tgoto out;\n\n\tpriv->base = devm_ioremap_resource(&pdev->dev, res_mem);\n\tif (IS_ERR(priv->base)) {\n\t\tret = PTR_ERR(priv->base);\n\t\tgoto out;\n\t}\n\n\tpriv->mac_clk = devm_clk_get(&pdev->dev, \"enetsw\");\n\tif (IS_ERR(priv->mac_clk)) {\n\t\tret = PTR_ERR(priv->mac_clk);\n\t\tgoto out;\n\t}\n\tret = clk_prepare_enable(priv->mac_clk);\n\tif (ret)\n\t\tgoto out;\n\n\tpriv->rx_chan = 0;\n\tpriv->tx_chan = 1;\n\tspin_lock_init(&priv->rx_lock);\n\n\t \n\ttimer_setup(&priv->rx_timeout, bcm_enet_refill_rx_timer, 0);\n\n\t \n\tdev->netdev_ops = &bcm_enetsw_ops;\n\tnetif_napi_add_weight(dev, &priv->napi, bcm_enet_poll, 16);\n\tdev->ethtool_ops = &bcm_enetsw_ethtool_ops;\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\tspin_lock_init(&priv->enetsw_mdio_lock);\n\n\tret = register_netdev(dev);\n\tif (ret)\n\t\tgoto out_disable_clk;\n\n\tnetif_carrier_off(dev);\n\tplatform_set_drvdata(pdev, dev);\n\tpriv->pdev = pdev;\n\tpriv->net_dev = dev;\n\n\treturn 0;\n\nout_disable_clk:\n\tclk_disable_unprepare(priv->mac_clk);\nout:\n\tfree_netdev(dev);\n\treturn ret;\n}\n\n\n \nstatic int bcm_enetsw_remove(struct platform_device *pdev)\n{\n\tstruct bcm_enet_priv *priv;\n\tstruct net_device *dev;\n\n\t \n\tdev = platform_get_drvdata(pdev);\n\tpriv = netdev_priv(dev);\n\tunregister_netdev(dev);\n\n\tclk_disable_unprepare(priv->mac_clk);\n\n\tfree_netdev(dev);\n\treturn 0;\n}\n\nstatic struct platform_driver bcm63xx_enetsw_driver = {\n\t.probe\t= bcm_enetsw_probe,\n\t.remove\t= bcm_enetsw_remove,\n\t.driver\t= {\n\t\t.name\t= \"bcm63xx_enetsw\",\n\t},\n};\n\n \nstatic int bcm_enet_shared_probe(struct platform_device *pdev)\n{\n\tvoid __iomem *p[3];\n\tunsigned int i;\n\n\tmemset(bcm_enet_shared_base, 0, sizeof(bcm_enet_shared_base));\n\n\tfor (i = 0; i < 3; i++) {\n\t\tp[i] = devm_platform_ioremap_resource(pdev, i);\n\t\tif (IS_ERR(p[i]))\n\t\t\treturn PTR_ERR(p[i]);\n\t}\n\n\tmemcpy(bcm_enet_shared_base, p, sizeof(bcm_enet_shared_base));\n\n\treturn 0;\n}\n\n \nstruct platform_driver bcm63xx_enet_shared_driver = {\n\t.probe\t= bcm_enet_shared_probe,\n\t.driver\t= {\n\t\t.name\t= \"bcm63xx_enet_shared\",\n\t},\n};\n\nstatic struct platform_driver * const drivers[] = {\n\t&bcm63xx_enet_shared_driver,\n\t&bcm63xx_enet_driver,\n\t&bcm63xx_enetsw_driver,\n};\n\n \nstatic int __init bcm_enet_init(void)\n{\n\treturn platform_register_drivers(drivers, ARRAY_SIZE(drivers));\n}\n\nstatic void __exit bcm_enet_exit(void)\n{\n\tplatform_unregister_drivers(drivers, ARRAY_SIZE(drivers));\n}\n\n\nmodule_init(bcm_enet_init);\nmodule_exit(bcm_enet_exit);\n\nMODULE_DESCRIPTION(\"BCM63xx internal ethernet mac driver\");\nMODULE_AUTHOR(\"Maxime Bizon <mbizon@freebox.fr>\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}