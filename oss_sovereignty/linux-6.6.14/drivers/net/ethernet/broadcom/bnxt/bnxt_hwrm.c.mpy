{
  "module_name": "bnxt_hwrm.c",
  "hash_id": "714e7414b93bb6c9f0cedd495d7145b76b6d4e39f8755046ca603eae1fb9e32a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/broadcom/bnxt/bnxt_hwrm.c",
  "human_readable_source": " \n\n#include <asm/byteorder.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/errno.h>\n#include <linux/ethtool.h>\n#include <linux/if_ether.h>\n#include <linux/io.h>\n#include <linux/irq.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/netdevice.h>\n#include <linux/pci.h>\n#include <linux/skbuff.h>\n\n#include \"bnxt_hsi.h\"\n#include \"bnxt.h\"\n#include \"bnxt_hwrm.h\"\n\nstatic u64 hwrm_calc_sentinel(struct bnxt_hwrm_ctx *ctx, u16 req_type)\n{\n\treturn (((uintptr_t)ctx) + req_type) ^ BNXT_HWRM_SENTINEL;\n}\n\n \nint __hwrm_req_init(struct bnxt *bp, void **req, u16 req_type, u32 req_len)\n{\n\tstruct bnxt_hwrm_ctx *ctx;\n\tdma_addr_t dma_handle;\n\tu8 *req_addr;\n\n\tif (req_len > BNXT_HWRM_CTX_OFFSET)\n\t\treturn -E2BIG;\n\n\treq_addr = dma_pool_alloc(bp->hwrm_dma_pool, GFP_KERNEL | __GFP_ZERO,\n\t\t\t\t  &dma_handle);\n\tif (!req_addr)\n\t\treturn -ENOMEM;\n\n\tctx = (struct bnxt_hwrm_ctx *)(req_addr + BNXT_HWRM_CTX_OFFSET);\n\t \n\tctx->sentinel = hwrm_calc_sentinel(ctx, req_type);\n\tctx->req_len = req_len;\n\tctx->req = (struct input *)req_addr;\n\tctx->resp = (struct output *)(req_addr + BNXT_HWRM_RESP_OFFSET);\n\tctx->dma_handle = dma_handle;\n\tctx->flags = 0;  \n\tctx->timeout = bp->hwrm_cmd_timeout ?: DFLT_HWRM_CMD_TIMEOUT;\n\tctx->allocated = BNXT_HWRM_DMA_SIZE - BNXT_HWRM_CTX_OFFSET;\n\tctx->gfp = GFP_KERNEL;\n\tctx->slice_addr = NULL;\n\n\t \n\tctx->req->req_type = cpu_to_le16(req_type);\n\tctx->req->resp_addr = cpu_to_le64(dma_handle + BNXT_HWRM_RESP_OFFSET);\n\tctx->req->cmpl_ring = cpu_to_le16(BNXT_HWRM_NO_CMPL_RING);\n\tctx->req->target_id = cpu_to_le16(BNXT_HWRM_TARGET);\n\t*req = ctx->req;\n\n\treturn 0;\n}\n\nstatic struct bnxt_hwrm_ctx *__hwrm_ctx(struct bnxt *bp, u8 *req_addr)\n{\n\tvoid *ctx_addr = req_addr + BNXT_HWRM_CTX_OFFSET;\n\tstruct input *req = (struct input *)req_addr;\n\tstruct bnxt_hwrm_ctx *ctx = ctx_addr;\n\tu64 sentinel;\n\n\tif (!req) {\n\t\t \n\t\tnetdev_err(bp->dev, \"null HWRM request\");\n\t\tdump_stack();\n\t\treturn NULL;\n\t}\n\n\t \n\tsentinel = hwrm_calc_sentinel(ctx, le16_to_cpu(req->req_type));\n\tif (ctx->sentinel != sentinel) {\n\t\t \n\t\tnetdev_err(bp->dev, \"HWRM sentinel mismatch, req_type = %u\\n\",\n\t\t\t   (u32)le16_to_cpu(req->req_type));\n\t\tdump_stack();\n\t\treturn NULL;\n\t}\n\n\treturn ctx;\n}\n\n \nvoid hwrm_req_timeout(struct bnxt *bp, void *req, unsigned int timeout)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\n\tif (ctx)\n\t\tctx->timeout = timeout;\n}\n\n \nvoid hwrm_req_alloc_flags(struct bnxt *bp, void *req, gfp_t gfp)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\n\tif (ctx)\n\t\tctx->gfp = gfp;\n}\n\n \nint hwrm_req_replace(struct bnxt *bp, void *req, void *new_req, u32 len)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\tstruct input *internal_req = req;\n\tu16 req_type;\n\n\tif (!ctx)\n\t\treturn -EINVAL;\n\n\tif (len > BNXT_HWRM_CTX_OFFSET)\n\t\treturn -E2BIG;\n\n\t \n\tctx->allocated = BNXT_HWRM_DMA_SIZE - BNXT_HWRM_CTX_OFFSET;\n\tif (ctx->slice_addr) {\n\t\tdma_free_coherent(&bp->pdev->dev, ctx->slice_size,\n\t\t\t\t  ctx->slice_addr, ctx->slice_handle);\n\t\tctx->slice_addr = NULL;\n\t}\n\tctx->gfp = GFP_KERNEL;\n\n\tif ((bp->fw_cap & BNXT_FW_CAP_SHORT_CMD) || len > BNXT_HWRM_MAX_REQ_LEN) {\n\t\tmemcpy(internal_req, new_req, len);\n\t} else {\n\t\tinternal_req->req_type = ((struct input *)new_req)->req_type;\n\t\tctx->req = new_req;\n\t}\n\n\tctx->req_len = len;\n\tctx->req->resp_addr = cpu_to_le64(ctx->dma_handle +\n\t\t\t\t\t  BNXT_HWRM_RESP_OFFSET);\n\n\t \n\treq_type = le16_to_cpu(internal_req->req_type);\n\tctx->sentinel = hwrm_calc_sentinel(ctx, req_type);\n\n\treturn 0;\n}\n\n \nvoid hwrm_req_flags(struct bnxt *bp, void *req, enum bnxt_hwrm_ctx_flags flags)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\n\tif (ctx)\n\t\tctx->flags |= (flags & HWRM_API_FLAGS);\n}\n\n \nvoid *hwrm_req_hold(struct bnxt *bp, void *req)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\tstruct input *input = (struct input *)req;\n\n\tif (!ctx)\n\t\treturn NULL;\n\n\tif (ctx->flags & BNXT_HWRM_INTERNAL_CTX_OWNED) {\n\t\t \n\t\tnetdev_err(bp->dev, \"HWRM context already owned, req_type = %u\\n\",\n\t\t\t   (u32)le16_to_cpu(input->req_type));\n\t\tdump_stack();\n\t\treturn NULL;\n\t}\n\n\tctx->flags |= BNXT_HWRM_INTERNAL_CTX_OWNED;\n\treturn ((u8 *)req) + BNXT_HWRM_RESP_OFFSET;\n}\n\nstatic void __hwrm_ctx_drop(struct bnxt *bp, struct bnxt_hwrm_ctx *ctx)\n{\n\tvoid *addr = ((u8 *)ctx) - BNXT_HWRM_CTX_OFFSET;\n\tdma_addr_t dma_handle = ctx->dma_handle;  \n\n\t \n\tif (ctx->slice_addr)\n\t\tdma_free_coherent(&bp->pdev->dev, ctx->slice_size,\n\t\t\t\t  ctx->slice_addr, ctx->slice_handle);\n\n\t \n\tmemset(ctx, 0, sizeof(struct bnxt_hwrm_ctx));\n\n\t \n\tif (dma_handle)\n\t\tdma_pool_free(bp->hwrm_dma_pool, addr, dma_handle);\n}\n\n \nvoid hwrm_req_drop(struct bnxt *bp, void *req)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\n\tif (ctx)\n\t\t__hwrm_ctx_drop(bp, ctx);\n}\n\nstatic int __hwrm_to_stderr(u32 hwrm_err)\n{\n\tswitch (hwrm_err) {\n\tcase HWRM_ERR_CODE_SUCCESS:\n\t\treturn 0;\n\tcase HWRM_ERR_CODE_RESOURCE_LOCKED:\n\t\treturn -EROFS;\n\tcase HWRM_ERR_CODE_RESOURCE_ACCESS_DENIED:\n\t\treturn -EACCES;\n\tcase HWRM_ERR_CODE_RESOURCE_ALLOC_ERROR:\n\t\treturn -ENOSPC;\n\tcase HWRM_ERR_CODE_INVALID_PARAMS:\n\tcase HWRM_ERR_CODE_INVALID_FLAGS:\n\tcase HWRM_ERR_CODE_INVALID_ENABLES:\n\tcase HWRM_ERR_CODE_UNSUPPORTED_TLV:\n\tcase HWRM_ERR_CODE_UNSUPPORTED_OPTION_ERR:\n\t\treturn -EINVAL;\n\tcase HWRM_ERR_CODE_NO_BUFFER:\n\t\treturn -ENOMEM;\n\tcase HWRM_ERR_CODE_HOT_RESET_PROGRESS:\n\tcase HWRM_ERR_CODE_BUSY:\n\t\treturn -EAGAIN;\n\tcase HWRM_ERR_CODE_CMD_NOT_SUPPORTED:\n\t\treturn -EOPNOTSUPP;\n\tcase HWRM_ERR_CODE_PF_UNAVAILABLE:\n\t\treturn -ENODEV;\n\tdefault:\n\t\treturn -EIO;\n\t}\n}\n\nstatic struct bnxt_hwrm_wait_token *\n__hwrm_acquire_token(struct bnxt *bp, enum bnxt_hwrm_chnl dst)\n{\n\tstruct bnxt_hwrm_wait_token *token;\n\n\ttoken = kzalloc(sizeof(*token), GFP_KERNEL);\n\tif (!token)\n\t\treturn NULL;\n\n\tmutex_lock(&bp->hwrm_cmd_lock);\n\n\ttoken->dst = dst;\n\ttoken->state = BNXT_HWRM_PENDING;\n\tif (dst == BNXT_HWRM_CHNL_CHIMP) {\n\t\ttoken->seq_id = bp->hwrm_cmd_seq++;\n\t\thlist_add_head_rcu(&token->node, &bp->hwrm_pending_list);\n\t} else {\n\t\ttoken->seq_id = bp->hwrm_cmd_kong_seq++;\n\t}\n\n\treturn token;\n}\n\nstatic void\n__hwrm_release_token(struct bnxt *bp, struct bnxt_hwrm_wait_token *token)\n{\n\tif (token->dst == BNXT_HWRM_CHNL_CHIMP) {\n\t\thlist_del_rcu(&token->node);\n\t\tkfree_rcu(token, rcu);\n\t} else {\n\t\tkfree(token);\n\t}\n\tmutex_unlock(&bp->hwrm_cmd_lock);\n}\n\nvoid\nhwrm_update_token(struct bnxt *bp, u16 seq_id, enum bnxt_hwrm_wait_state state)\n{\n\tstruct bnxt_hwrm_wait_token *token;\n\n\trcu_read_lock();\n\thlist_for_each_entry_rcu(token, &bp->hwrm_pending_list, node) {\n\t\tif (token->seq_id == seq_id) {\n\t\t\tWRITE_ONCE(token->state, state);\n\t\t\trcu_read_unlock();\n\t\t\treturn;\n\t\t}\n\t}\n\trcu_read_unlock();\n\tnetdev_err(bp->dev, \"Invalid hwrm seq id %d\\n\", seq_id);\n}\n\nstatic void hwrm_req_dbg(struct bnxt *bp, struct input *req)\n{\n\tu32 ring = le16_to_cpu(req->cmpl_ring);\n\tu32 type = le16_to_cpu(req->req_type);\n\tu32 tgt = le16_to_cpu(req->target_id);\n\tu32 seq = le16_to_cpu(req->seq_id);\n\tchar opt[32] = \"\\n\";\n\n\tif (unlikely(ring != (u16)BNXT_HWRM_NO_CMPL_RING))\n\t\tsnprintf(opt, 16, \" ring %d\\n\", ring);\n\n\tif (unlikely(tgt != BNXT_HWRM_TARGET))\n\t\tsnprintf(opt + strlen(opt) - 1, 16, \" tgt 0x%x\\n\", tgt);\n\n\tnetdev_dbg(bp->dev, \"sent hwrm req_type 0x%x seq id 0x%x%s\",\n\t\t   type, seq, opt);\n}\n\n#define hwrm_err(bp, ctx, fmt, ...)\t\t\t\t       \\\n\tdo {\t\t\t\t\t\t\t       \\\n\t\tif ((ctx)->flags & BNXT_HWRM_CTX_SILENT)\t       \\\n\t\t\tnetdev_dbg((bp)->dev, fmt, __VA_ARGS__);       \\\n\t\telse\t\t\t\t\t\t       \\\n\t\t\tnetdev_err((bp)->dev, fmt, __VA_ARGS__);       \\\n\t} while (0)\n\nstatic bool hwrm_wait_must_abort(struct bnxt *bp, u32 req_type, u32 *fw_status)\n{\n\tif (req_type == HWRM_VER_GET)\n\t\treturn false;\n\n\tif (!bp->fw_health || !bp->fw_health->status_reliable)\n\t\treturn false;\n\n\t*fw_status = bnxt_fw_health_readl(bp, BNXT_FW_HEALTH_REG);\n\treturn *fw_status && !BNXT_FW_IS_HEALTHY(*fw_status);\n}\n\nstatic int __hwrm_send(struct bnxt *bp, struct bnxt_hwrm_ctx *ctx)\n{\n\tu32 doorbell_offset = BNXT_GRCPF_REG_CHIMP_COMM_TRIGGER;\n\tenum bnxt_hwrm_chnl dst = BNXT_HWRM_CHNL_CHIMP;\n\tu32 bar_offset = BNXT_GRCPF_REG_CHIMP_COMM;\n\tstruct bnxt_hwrm_wait_token *token = NULL;\n\tstruct hwrm_short_input short_input = {0};\n\tu16 max_req_len = BNXT_HWRM_MAX_REQ_LEN;\n\tunsigned int i, timeout, tmo_count;\n\tu32 *data = (u32 *)ctx->req;\n\tu32 msg_len = ctx->req_len;\n\tu32 req_type, sts;\n\tint rc = -EBUSY;\n\tu16 len = 0;\n\tu8 *valid;\n\n\tif (ctx->flags & BNXT_HWRM_INTERNAL_RESP_DIRTY)\n\t\tmemset(ctx->resp, 0, PAGE_SIZE);\n\n\treq_type = le16_to_cpu(ctx->req->req_type);\n\tif (BNXT_NO_FW_ACCESS(bp) &&\n\t    (req_type != HWRM_FUNC_RESET && req_type != HWRM_VER_GET)) {\n\t\tnetdev_dbg(bp->dev, \"hwrm req_type 0x%x skipped, FW channel down\\n\",\n\t\t\t   req_type);\n\t\tgoto exit;\n\t}\n\n\tif (msg_len > BNXT_HWRM_MAX_REQ_LEN &&\n\t    msg_len > bp->hwrm_max_ext_req_len) {\n\t\trc = -E2BIG;\n\t\tgoto exit;\n\t}\n\n\tif (bnxt_kong_hwrm_message(bp, ctx->req)) {\n\t\tdst = BNXT_HWRM_CHNL_KONG;\n\t\tbar_offset = BNXT_GRCPF_REG_KONG_COMM;\n\t\tdoorbell_offset = BNXT_GRCPF_REG_KONG_COMM_TRIGGER;\n\t\tif (le16_to_cpu(ctx->req->cmpl_ring) != INVALID_HW_RING_ID) {\n\t\t\tnetdev_err(bp->dev, \"Ring completions not supported for KONG commands, req_type = %d\\n\",\n\t\t\t\t   req_type);\n\t\t\trc = -EINVAL;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\ttoken = __hwrm_acquire_token(bp, dst);\n\tif (!token) {\n\t\trc = -ENOMEM;\n\t\tgoto exit;\n\t}\n\tctx->req->seq_id = cpu_to_le16(token->seq_id);\n\n\tif ((bp->fw_cap & BNXT_FW_CAP_SHORT_CMD) ||\n\t    msg_len > BNXT_HWRM_MAX_REQ_LEN) {\n\t\tshort_input.req_type = ctx->req->req_type;\n\t\tshort_input.signature =\n\t\t\t\tcpu_to_le16(SHORT_REQ_SIGNATURE_SHORT_CMD);\n\t\tshort_input.size = cpu_to_le16(msg_len);\n\t\tshort_input.req_addr = cpu_to_le64(ctx->dma_handle);\n\n\t\tdata = (u32 *)&short_input;\n\t\tmsg_len = sizeof(short_input);\n\n\t\tmax_req_len = BNXT_HWRM_SHORT_REQ_LEN;\n\t}\n\n\t \n\twmb();\n\n\t \n\t__iowrite32_copy(bp->bar0 + bar_offset, data, msg_len / 4);\n\n\tfor (i = msg_len; i < max_req_len; i += 4)\n\t\twritel(0, bp->bar0 + bar_offset + i);\n\n\t \n\twritel(1, bp->bar0 + doorbell_offset);\n\n\thwrm_req_dbg(bp, ctx->req);\n\n\tif (!pci_is_enabled(bp->pdev)) {\n\t\trc = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\t \n\ttimeout = min(ctx->timeout, bp->hwrm_cmd_max_timeout ?: HWRM_CMD_MAX_TIMEOUT);\n\t \n\ttimeout *= 1000;\n\n\ti = 0;\n\t \n\ttmo_count = HWRM_SHORT_TIMEOUT_COUNTER;\n\ttimeout = timeout - HWRM_SHORT_MIN_TIMEOUT * HWRM_SHORT_TIMEOUT_COUNTER;\n\ttmo_count += DIV_ROUND_UP(timeout, HWRM_MIN_TIMEOUT);\n\n\tif (le16_to_cpu(ctx->req->cmpl_ring) != INVALID_HW_RING_ID) {\n\t\t \n\t\twhile (READ_ONCE(token->state) < BNXT_HWRM_COMPLETE &&\n\t\t       i++ < tmo_count) {\n\t\t\t \n\t\t\tif (test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state))\n\t\t\t\tgoto exit;\n\t\t\t \n\t\t\tif (i < HWRM_SHORT_TIMEOUT_COUNTER) {\n\t\t\t\tusleep_range(HWRM_SHORT_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_SHORT_MAX_TIMEOUT);\n\t\t\t} else {\n\t\t\t\tif (hwrm_wait_must_abort(bp, req_type, &sts)) {\n\t\t\t\t\thwrm_err(bp, ctx, \"Resp cmpl intr abandoning msg: 0x%x due to firmware status: 0x%x\\n\",\n\t\t\t\t\t\t req_type, sts);\n\t\t\t\t\tgoto exit;\n\t\t\t\t}\n\t\t\t\tusleep_range(HWRM_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_MAX_TIMEOUT);\n\t\t\t}\n\t\t}\n\n\t\tif (READ_ONCE(token->state) != BNXT_HWRM_COMPLETE) {\n\t\t\thwrm_err(bp, ctx, \"Resp cmpl intr err msg: 0x%x\\n\",\n\t\t\t\t req_type);\n\t\t\tgoto exit;\n\t\t}\n\t\tlen = le16_to_cpu(READ_ONCE(ctx->resp->resp_len));\n\t\tvalid = ((u8 *)ctx->resp) + len - 1;\n\t} else {\n\t\t__le16 seen_out_of_seq = ctx->req->seq_id;  \n\t\tint j;\n\n\t\t \n\t\tfor (i = 0; i < tmo_count; i++) {\n\t\t\t \n\t\t\tif (test_bit(BNXT_STATE_FW_FATAL_COND, &bp->state))\n\t\t\t\tgoto exit;\n\n\t\t\tif (token &&\n\t\t\t    READ_ONCE(token->state) == BNXT_HWRM_DEFERRED) {\n\t\t\t\t__hwrm_release_token(bp, token);\n\t\t\t\ttoken = NULL;\n\t\t\t}\n\n\t\t\tlen = le16_to_cpu(READ_ONCE(ctx->resp->resp_len));\n\t\t\tif (len) {\n\t\t\t\t__le16 resp_seq = READ_ONCE(ctx->resp->seq_id);\n\n\t\t\t\tif (resp_seq == ctx->req->seq_id)\n\t\t\t\t\tbreak;\n\t\t\t\tif (resp_seq != seen_out_of_seq) {\n\t\t\t\t\tnetdev_warn(bp->dev, \"Discarding out of seq response: 0x%x for msg {0x%x 0x%x}\\n\",\n\t\t\t\t\t\t    le16_to_cpu(resp_seq),\n\t\t\t\t\t\t    req_type,\n\t\t\t\t\t\t    le16_to_cpu(ctx->req->seq_id));\n\t\t\t\t\tseen_out_of_seq = resp_seq;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\tif (i < HWRM_SHORT_TIMEOUT_COUNTER) {\n\t\t\t\tusleep_range(HWRM_SHORT_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_SHORT_MAX_TIMEOUT);\n\t\t\t} else {\n\t\t\t\tif (hwrm_wait_must_abort(bp, req_type, &sts)) {\n\t\t\t\t\thwrm_err(bp, ctx, \"Abandoning msg {0x%x 0x%x} len: %d due to firmware status: 0x%x\\n\",\n\t\t\t\t\t\t req_type,\n\t\t\t\t\t\t le16_to_cpu(ctx->req->seq_id),\n\t\t\t\t\t\t len, sts);\n\t\t\t\t\tgoto exit;\n\t\t\t\t}\n\t\t\t\tusleep_range(HWRM_MIN_TIMEOUT,\n\t\t\t\t\t     HWRM_MAX_TIMEOUT);\n\t\t\t}\n\t\t}\n\n\t\tif (i >= tmo_count) {\n\t\t\thwrm_err(bp, ctx, \"Error (timeout: %u) msg {0x%x 0x%x} len:%d\\n\",\n\t\t\t\t hwrm_total_timeout(i), req_type,\n\t\t\t\t le16_to_cpu(ctx->req->seq_id), len);\n\t\t\tgoto exit;\n\t\t}\n\n\t\t \n\t\tvalid = ((u8 *)ctx->resp) + len - 1;\n\t\tfor (j = 0; j < HWRM_VALID_BIT_DELAY_USEC; ) {\n\t\t\t \n\t\t\tdma_rmb();\n\t\t\tif (*valid)\n\t\t\t\tbreak;\n\t\t\tif (j < 10) {\n\t\t\t\tudelay(1);\n\t\t\t\tj++;\n\t\t\t} else {\n\t\t\t\tusleep_range(20, 30);\n\t\t\t\tj += 20;\n\t\t\t}\n\t\t}\n\n\t\tif (j >= HWRM_VALID_BIT_DELAY_USEC) {\n\t\t\thwrm_err(bp, ctx, \"Error (timeout: %u) msg {0x%x 0x%x} len:%d v:%d\\n\",\n\t\t\t\t hwrm_total_timeout(i) + j, req_type,\n\t\t\t\t le16_to_cpu(ctx->req->seq_id), len, *valid);\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\t \n\t*valid = 0;\n\trc = le16_to_cpu(ctx->resp->error_code);\n\tif (rc == HWRM_ERR_CODE_BUSY && !(ctx->flags & BNXT_HWRM_CTX_SILENT))\n\t\tnetdev_warn(bp->dev, \"FW returned busy, hwrm req_type 0x%x\\n\",\n\t\t\t    req_type);\n\telse if (rc && rc != HWRM_ERR_CODE_PF_UNAVAILABLE)\n\t\thwrm_err(bp, ctx, \"hwrm req_type 0x%x seq id 0x%x error 0x%x\\n\",\n\t\t\t req_type, token->seq_id, rc);\n\trc = __hwrm_to_stderr(rc);\nexit:\n\tif (token)\n\t\t__hwrm_release_token(bp, token);\n\tif (ctx->flags & BNXT_HWRM_INTERNAL_CTX_OWNED)\n\t\tctx->flags |= BNXT_HWRM_INTERNAL_RESP_DIRTY;\n\telse\n\t\t__hwrm_ctx_drop(bp, ctx);\n\treturn rc;\n}\n\n \nint hwrm_req_send(struct bnxt *bp, void *req)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\n\tif (!ctx)\n\t\treturn -EINVAL;\n\n\treturn __hwrm_send(bp, ctx);\n}\n\n \nint hwrm_req_send_silent(struct bnxt *bp, void *req)\n{\n\thwrm_req_flags(bp, req, BNXT_HWRM_CTX_SILENT);\n\treturn hwrm_req_send(bp, req);\n}\n\n \nvoid *\nhwrm_req_dma_slice(struct bnxt *bp, void *req, u32 size, dma_addr_t *dma_handle)\n{\n\tstruct bnxt_hwrm_ctx *ctx = __hwrm_ctx(bp, req);\n\tu8 *end = ((u8 *)req) + BNXT_HWRM_DMA_SIZE;\n\tstruct input *input = req;\n\tu8 *addr, *req_addr = req;\n\tu32 max_offset, offset;\n\n\tif (!ctx)\n\t\treturn NULL;\n\n\tmax_offset = BNXT_HWRM_DMA_SIZE - ctx->allocated;\n\toffset = max_offset - size;\n\toffset = ALIGN_DOWN(offset, BNXT_HWRM_DMA_ALIGN);\n\taddr = req_addr + offset;\n\n\tif (addr < req_addr + max_offset && req_addr + ctx->req_len <= addr) {\n\t\tctx->allocated = end - addr;\n\t\t*dma_handle = ctx->dma_handle + offset;\n\t\treturn addr;\n\t}\n\n\t \n\tif (ctx->slice_addr) {\n\t\t \n\t\tnetdev_err(bp->dev, \"HWRM refusing to reallocate DMA slice, req_type = %u\\n\",\n\t\t\t   (u32)le16_to_cpu(input->req_type));\n\t\tdump_stack();\n\t\treturn NULL;\n\t}\n\n\taddr = dma_alloc_coherent(&bp->pdev->dev, size, dma_handle, ctx->gfp);\n\n\tif (!addr)\n\t\treturn NULL;\n\n\tctx->slice_addr = addr;\n\tctx->slice_size = size;\n\tctx->slice_handle = *dma_handle;\n\n\treturn addr;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}