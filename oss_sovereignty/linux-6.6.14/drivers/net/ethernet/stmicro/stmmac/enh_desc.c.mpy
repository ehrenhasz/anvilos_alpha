{
  "module_name": "enh_desc.c",
  "hash_id": "d6cee708fc721203986e93a6cc6a4224821043d92fdeaf2f1d6eaca99c2f8b86",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/stmicro/stmmac/enh_desc.c",
  "human_readable_source": "\n \n\n#include <linux/stmmac.h>\n#include \"common.h\"\n#include \"descs_com.h\"\n\nstatic int enh_desc_get_tx_status(struct stmmac_extra_stats *x,\n\t\t\t\t  struct dma_desc *p, void __iomem *ioaddr)\n{\n\tunsigned int tdes0 = le32_to_cpu(p->des0);\n\tint ret = tx_done;\n\n\t \n\tif (unlikely(tdes0 & ETDES0_OWN))\n\t\treturn tx_dma_own;\n\n\t \n\tif (likely(!(tdes0 & ETDES0_LAST_SEGMENT)))\n\t\treturn tx_not_ls;\n\n\tif (unlikely(tdes0 & ETDES0_ERROR_SUMMARY)) {\n\t\tif (unlikely(tdes0 & ETDES0_JABBER_TIMEOUT))\n\t\t\tx->tx_jabber++;\n\n\t\tif (unlikely(tdes0 & ETDES0_FRAME_FLUSHED)) {\n\t\t\tx->tx_frame_flushed++;\n\t\t\tdwmac_dma_flush_tx_fifo(ioaddr);\n\t\t}\n\n\t\tif (unlikely(tdes0 & ETDES0_LOSS_CARRIER)) {\n\t\t\tx->tx_losscarrier++;\n\t\t}\n\t\tif (unlikely(tdes0 & ETDES0_NO_CARRIER)) {\n\t\t\tx->tx_carrier++;\n\t\t}\n\t\tif (unlikely((tdes0 & ETDES0_LATE_COLLISION) ||\n\t\t\t     (tdes0 & ETDES0_EXCESSIVE_COLLISIONS)))\n\t\t\tx->tx_collision +=\n\t\t\t\t(tdes0 & ETDES0_COLLISION_COUNT_MASK) >> 3;\n\n\t\tif (unlikely(tdes0 & ETDES0_EXCESSIVE_DEFERRAL))\n\t\t\tx->tx_deferred++;\n\n\t\tif (unlikely(tdes0 & ETDES0_UNDERFLOW_ERROR)) {\n\t\t\tdwmac_dma_flush_tx_fifo(ioaddr);\n\t\t\tx->tx_underflow++;\n\t\t}\n\n\t\tif (unlikely(tdes0 & ETDES0_IP_HEADER_ERROR))\n\t\t\tx->tx_ip_header_error++;\n\n\t\tif (unlikely(tdes0 & ETDES0_PAYLOAD_ERROR)) {\n\t\t\tx->tx_payload_error++;\n\t\t\tdwmac_dma_flush_tx_fifo(ioaddr);\n\t\t}\n\n\t\tret = tx_err;\n\t}\n\n\tif (unlikely(tdes0 & ETDES0_DEFERRED))\n\t\tx->tx_deferred++;\n\n#ifdef STMMAC_VLAN_TAG_USED\n\tif (tdes0 & ETDES0_VLAN_FRAME)\n\t\tx->tx_vlan++;\n#endif\n\n\treturn ret;\n}\n\nstatic int enh_desc_get_tx_len(struct dma_desc *p)\n{\n\treturn (le32_to_cpu(p->des1) & ETDES1_BUFFER1_SIZE_MASK);\n}\n\nstatic int enh_desc_coe_rdes0(int ipc_err, int type, int payload_err)\n{\n\tint ret = good_frame;\n\tu32 status = (type << 2 | ipc_err << 1 | payload_err) & 0x7;\n\n\t \n\tif (status == 0x0)\n\t\tret = llc_snap;\n\telse if (status == 0x4)\n\t\tret = good_frame;\n\telse if (status == 0x5)\n\t\tret = csum_none;\n\telse if (status == 0x6)\n\t\tret = csum_none;\n\telse if (status == 0x7)\n\t\tret = csum_none;\n\telse if (status == 0x1)\n\t\tret = discard_frame;\n\telse if (status == 0x3)\n\t\tret = discard_frame;\n\treturn ret;\n}\n\nstatic void enh_desc_get_ext_status(struct stmmac_extra_stats *x,\n\t\t\t\t    struct dma_extended_desc *p)\n{\n\tunsigned int rdes0 = le32_to_cpu(p->basic.des0);\n\tunsigned int rdes4 = le32_to_cpu(p->des4);\n\n\tif (unlikely(rdes0 & ERDES0_RX_MAC_ADDR)) {\n\t\tint message_type = (rdes4 & ERDES4_MSG_TYPE_MASK) >> 8;\n\n\t\tif (rdes4 & ERDES4_IP_HDR_ERR)\n\t\t\tx->ip_hdr_err++;\n\t\tif (rdes4 & ERDES4_IP_PAYLOAD_ERR)\n\t\t\tx->ip_payload_err++;\n\t\tif (rdes4 & ERDES4_IP_CSUM_BYPASSED)\n\t\t\tx->ip_csum_bypassed++;\n\t\tif (rdes4 & ERDES4_IPV4_PKT_RCVD)\n\t\t\tx->ipv4_pkt_rcvd++;\n\t\tif (rdes4 & ERDES4_IPV6_PKT_RCVD)\n\t\t\tx->ipv6_pkt_rcvd++;\n\n\t\tif (message_type == RDES_EXT_NO_PTP)\n\t\t\tx->no_ptp_rx_msg_type_ext++;\n\t\telse if (message_type == RDES_EXT_SYNC)\n\t\t\tx->ptp_rx_msg_type_sync++;\n\t\telse if (message_type == RDES_EXT_FOLLOW_UP)\n\t\t\tx->ptp_rx_msg_type_follow_up++;\n\t\telse if (message_type == RDES_EXT_DELAY_REQ)\n\t\t\tx->ptp_rx_msg_type_delay_req++;\n\t\telse if (message_type == RDES_EXT_DELAY_RESP)\n\t\t\tx->ptp_rx_msg_type_delay_resp++;\n\t\telse if (message_type == RDES_EXT_PDELAY_REQ)\n\t\t\tx->ptp_rx_msg_type_pdelay_req++;\n\t\telse if (message_type == RDES_EXT_PDELAY_RESP)\n\t\t\tx->ptp_rx_msg_type_pdelay_resp++;\n\t\telse if (message_type == RDES_EXT_PDELAY_FOLLOW_UP)\n\t\t\tx->ptp_rx_msg_type_pdelay_follow_up++;\n\t\telse if (message_type == RDES_PTP_ANNOUNCE)\n\t\t\tx->ptp_rx_msg_type_announce++;\n\t\telse if (message_type == RDES_PTP_MANAGEMENT)\n\t\t\tx->ptp_rx_msg_type_management++;\n\t\telse if (message_type == RDES_PTP_PKT_RESERVED_TYPE)\n\t\t\tx->ptp_rx_msg_pkt_reserved_type++;\n\n\t\tif (rdes4 & ERDES4_PTP_FRAME_TYPE)\n\t\t\tx->ptp_frame_type++;\n\t\tif (rdes4 & ERDES4_PTP_VER)\n\t\t\tx->ptp_ver++;\n\t\tif (rdes4 & ERDES4_TIMESTAMP_DROPPED)\n\t\t\tx->timestamp_dropped++;\n\t\tif (rdes4 & ERDES4_AV_PKT_RCVD)\n\t\t\tx->av_pkt_rcvd++;\n\t\tif (rdes4 & ERDES4_AV_TAGGED_PKT_RCVD)\n\t\t\tx->av_tagged_pkt_rcvd++;\n\t\tif ((rdes4 & ERDES4_VLAN_TAG_PRI_VAL_MASK) >> 18)\n\t\t\tx->vlan_tag_priority_val++;\n\t\tif (rdes4 & ERDES4_L3_FILTER_MATCH)\n\t\t\tx->l3_filter_match++;\n\t\tif (rdes4 & ERDES4_L4_FILTER_MATCH)\n\t\t\tx->l4_filter_match++;\n\t\tif ((rdes4 & ERDES4_L3_L4_FILT_NO_MATCH_MASK) >> 26)\n\t\t\tx->l3_l4_filter_no_match++;\n\t}\n}\n\nstatic int enh_desc_get_rx_status(struct stmmac_extra_stats *x,\n\t\t\t\t  struct dma_desc *p)\n{\n\tunsigned int rdes0 = le32_to_cpu(p->des0);\n\tint ret = good_frame;\n\n\tif (unlikely(rdes0 & RDES0_OWN))\n\t\treturn dma_own;\n\n\tif (unlikely(!(rdes0 & RDES0_LAST_DESCRIPTOR))) {\n\t\tx->rx_length++;\n\t\treturn discard_frame;\n\t}\n\n\tif (unlikely(rdes0 & RDES0_ERROR_SUMMARY)) {\n\t\tif (unlikely(rdes0 & RDES0_DESCRIPTOR_ERROR)) {\n\t\t\tx->rx_desc++;\n\t\t\tx->rx_length++;\n\t\t}\n\t\tif (unlikely(rdes0 & RDES0_OVERFLOW_ERROR))\n\t\t\tx->rx_gmac_overflow++;\n\n\t\tif (unlikely(rdes0 & RDES0_IPC_CSUM_ERROR))\n\t\t\tpr_err(\"\\tIPC Csum Error/Giant frame\\n\");\n\n\t\tif (unlikely(rdes0 & RDES0_COLLISION))\n\t\t\tx->rx_collision++;\n\t\tif (unlikely(rdes0 & RDES0_RECEIVE_WATCHDOG))\n\t\t\tx->rx_watchdog++;\n\n\t\tif (unlikely(rdes0 & RDES0_MII_ERROR))\t \n\t\t\tx->rx_mii++;\n\n\t\tif (unlikely(rdes0 & RDES0_CRC_ERROR)) {\n\t\t\tx->rx_crc_errors++;\n\t\t}\n\t\tret = discard_frame;\n\t}\n\n\t \n\tif (likely(ret == good_frame))\n\t\tret = enh_desc_coe_rdes0(!!(rdes0 & RDES0_IPC_CSUM_ERROR),\n\t\t\t\t\t !!(rdes0 & RDES0_FRAME_TYPE),\n\t\t\t\t\t !!(rdes0 & ERDES0_RX_MAC_ADDR));\n\n\tif (unlikely(rdes0 & RDES0_DRIBBLING))\n\t\tx->dribbling_bit++;\n\n\tif (unlikely(rdes0 & RDES0_SA_FILTER_FAIL)) {\n\t\tx->sa_rx_filter_fail++;\n\t\tret = discard_frame;\n\t}\n\tif (unlikely(rdes0 & RDES0_DA_FILTER_FAIL)) {\n\t\tx->da_rx_filter_fail++;\n\t\tret = discard_frame;\n\t}\n\tif (unlikely(rdes0 & RDES0_LENGTH_ERROR)) {\n\t\tx->rx_length++;\n\t\tret = discard_frame;\n\t}\n#ifdef STMMAC_VLAN_TAG_USED\n\tif (rdes0 & RDES0_VLAN_TAG)\n\t\tx->rx_vlan++;\n#endif\n\n\treturn ret;\n}\n\nstatic void enh_desc_init_rx_desc(struct dma_desc *p, int disable_rx_ic,\n\t\t\t\t  int mode, int end, int bfsize)\n{\n\tint bfsize1;\n\n\tp->des0 |= cpu_to_le32(RDES0_OWN);\n\n\tbfsize1 = min(bfsize, BUF_SIZE_8KiB);\n\tp->des1 |= cpu_to_le32(bfsize1 & ERDES1_BUFFER1_SIZE_MASK);\n\n\tif (mode == STMMAC_CHAIN_MODE)\n\t\tehn_desc_rx_set_on_chain(p);\n\telse\n\t\tehn_desc_rx_set_on_ring(p, end, bfsize);\n\n\tif (disable_rx_ic)\n\t\tp->des1 |= cpu_to_le32(ERDES1_DISABLE_IC);\n}\n\nstatic void enh_desc_init_tx_desc(struct dma_desc *p, int mode, int end)\n{\n\tp->des0 &= cpu_to_le32(~ETDES0_OWN);\n\tif (mode == STMMAC_CHAIN_MODE)\n\t\tenh_desc_end_tx_desc_on_chain(p);\n\telse\n\t\tenh_desc_end_tx_desc_on_ring(p, end);\n}\n\nstatic int enh_desc_get_tx_owner(struct dma_desc *p)\n{\n\treturn (le32_to_cpu(p->des0) & ETDES0_OWN) >> 31;\n}\n\nstatic void enh_desc_set_tx_owner(struct dma_desc *p)\n{\n\tp->des0 |= cpu_to_le32(ETDES0_OWN);\n}\n\nstatic void enh_desc_set_rx_owner(struct dma_desc *p, int disable_rx_ic)\n{\n\tp->des0 |= cpu_to_le32(RDES0_OWN);\n}\n\nstatic int enh_desc_get_tx_ls(struct dma_desc *p)\n{\n\treturn (le32_to_cpu(p->des0) & ETDES0_LAST_SEGMENT) >> 29;\n}\n\nstatic void enh_desc_release_tx_desc(struct dma_desc *p, int mode)\n{\n\tint ter = (le32_to_cpu(p->des0) & ETDES0_END_RING) >> 21;\n\n\tmemset(p, 0, offsetof(struct dma_desc, des2));\n\tif (mode == STMMAC_CHAIN_MODE)\n\t\tenh_desc_end_tx_desc_on_chain(p);\n\telse\n\t\tenh_desc_end_tx_desc_on_ring(p, ter);\n}\n\nstatic void enh_desc_prepare_tx_desc(struct dma_desc *p, int is_fs, int len,\n\t\t\t\t     bool csum_flag, int mode, bool tx_own,\n\t\t\t\t     bool ls, unsigned int tot_pkt_len)\n{\n\tunsigned int tdes0 = le32_to_cpu(p->des0);\n\n\tif (mode == STMMAC_CHAIN_MODE)\n\t\tenh_set_tx_desc_len_on_chain(p, len);\n\telse\n\t\tenh_set_tx_desc_len_on_ring(p, len);\n\n\tif (is_fs)\n\t\ttdes0 |= ETDES0_FIRST_SEGMENT;\n\telse\n\t\ttdes0 &= ~ETDES0_FIRST_SEGMENT;\n\n\tif (likely(csum_flag))\n\t\ttdes0 |= (TX_CIC_FULL << ETDES0_CHECKSUM_INSERTION_SHIFT);\n\telse\n\t\ttdes0 &= ~(TX_CIC_FULL << ETDES0_CHECKSUM_INSERTION_SHIFT);\n\n\tif (ls)\n\t\ttdes0 |= ETDES0_LAST_SEGMENT;\n\n\t \n\tif (tx_own)\n\t\ttdes0 |= ETDES0_OWN;\n\n\tif (is_fs && tx_own)\n\t\t \n\t\tdma_wmb();\n\n\tp->des0 = cpu_to_le32(tdes0);\n}\n\nstatic void enh_desc_set_tx_ic(struct dma_desc *p)\n{\n\tp->des0 |= cpu_to_le32(ETDES0_INTERRUPT);\n}\n\nstatic int enh_desc_get_rx_frame_len(struct dma_desc *p, int rx_coe_type)\n{\n\tunsigned int csum = 0;\n\t \n\tif (rx_coe_type == STMMAC_RX_COE_TYPE1)\n\t\tcsum = 2;\n\n\treturn (((le32_to_cpu(p->des0) & RDES0_FRAME_LEN_MASK)\n\t\t\t\t>> RDES0_FRAME_LEN_SHIFT) - csum);\n}\n\nstatic void enh_desc_enable_tx_timestamp(struct dma_desc *p)\n{\n\tp->des0 |= cpu_to_le32(ETDES0_TIME_STAMP_ENABLE);\n}\n\nstatic int enh_desc_get_tx_timestamp_status(struct dma_desc *p)\n{\n\treturn (le32_to_cpu(p->des0) & ETDES0_TIME_STAMP_STATUS) >> 17;\n}\n\nstatic void enh_desc_get_timestamp(void *desc, u32 ats, u64 *ts)\n{\n\tu64 ns;\n\n\tif (ats) {\n\t\tstruct dma_extended_desc *p = (struct dma_extended_desc *)desc;\n\t\tns = le32_to_cpu(p->des6);\n\t\t \n\t\tns += le32_to_cpu(p->des7) * 1000000000ULL;\n\t} else {\n\t\tstruct dma_desc *p = (struct dma_desc *)desc;\n\t\tns = le32_to_cpu(p->des2);\n\t\tns += le32_to_cpu(p->des3) * 1000000000ULL;\n\t}\n\n\t*ts = ns;\n}\n\nstatic int enh_desc_get_rx_timestamp_status(void *desc, void *next_desc,\n\t\t\t\t\t    u32 ats)\n{\n\tif (ats) {\n\t\tstruct dma_extended_desc *p = (struct dma_extended_desc *)desc;\n\t\treturn (le32_to_cpu(p->basic.des0) & RDES0_IPC_CSUM_ERROR) >> 7;\n\t} else {\n\t\tstruct dma_desc *p = (struct dma_desc *)desc;\n\t\tif ((le32_to_cpu(p->des2) == 0xffffffff) &&\n\t\t    (le32_to_cpu(p->des3) == 0xffffffff))\n\t\t\t \n\t\t\treturn 0;\n\t\telse\n\t\t\treturn 1;\n\t}\n}\n\nstatic void enh_desc_display_ring(void *head, unsigned int size, bool rx,\n\t\t\t\t  dma_addr_t dma_rx_phy, unsigned int desc_size)\n{\n\tstruct dma_extended_desc *ep = (struct dma_extended_desc *)head;\n\tdma_addr_t dma_addr;\n\tint i;\n\n\tpr_info(\"Extended %s descriptor ring:\\n\", rx ? \"RX\" : \"TX\");\n\n\tfor (i = 0; i < size; i++) {\n\t\tu64 x;\n\t\tdma_addr = dma_rx_phy + i * sizeof(*ep);\n\n\t\tx = *(u64 *)ep;\n\t\tpr_info(\"%03d [%pad]: 0x%x 0x%x 0x%x 0x%x\\n\",\n\t\t\ti, &dma_addr,\n\t\t\t(unsigned int)x, (unsigned int)(x >> 32),\n\t\t\tep->basic.des2, ep->basic.des3);\n\t\tep++;\n\t}\n\tpr_info(\"\\n\");\n}\n\nstatic void enh_desc_set_addr(struct dma_desc *p, dma_addr_t addr)\n{\n\tp->des2 = cpu_to_le32(addr);\n}\n\nstatic void enh_desc_clear(struct dma_desc *p)\n{\n\tp->des2 = 0;\n}\n\nconst struct stmmac_desc_ops enh_desc_ops = {\n\t.tx_status = enh_desc_get_tx_status,\n\t.rx_status = enh_desc_get_rx_status,\n\t.get_tx_len = enh_desc_get_tx_len,\n\t.init_rx_desc = enh_desc_init_rx_desc,\n\t.init_tx_desc = enh_desc_init_tx_desc,\n\t.get_tx_owner = enh_desc_get_tx_owner,\n\t.release_tx_desc = enh_desc_release_tx_desc,\n\t.prepare_tx_desc = enh_desc_prepare_tx_desc,\n\t.set_tx_ic = enh_desc_set_tx_ic,\n\t.get_tx_ls = enh_desc_get_tx_ls,\n\t.set_tx_owner = enh_desc_set_tx_owner,\n\t.set_rx_owner = enh_desc_set_rx_owner,\n\t.get_rx_frame_len = enh_desc_get_rx_frame_len,\n\t.rx_extended_status = enh_desc_get_ext_status,\n\t.enable_tx_timestamp = enh_desc_enable_tx_timestamp,\n\t.get_tx_timestamp_status = enh_desc_get_tx_timestamp_status,\n\t.get_timestamp = enh_desc_get_timestamp,\n\t.get_rx_timestamp_status = enh_desc_get_rx_timestamp_status,\n\t.display_ring = enh_desc_display_ring,\n\t.set_addr = enh_desc_set_addr,\n\t.clear = enh_desc_clear,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}