{
  "module_name": "ehea_qmr.h",
  "hash_id": "f148719e443f07875ad45aa26b634d9cfd3ceae5ba9650879c189f8dd56569ab",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ibm/ehea/ehea_qmr.h",
  "human_readable_source": " \n \n\n#ifndef __EHEA_QMR_H__\n#define __EHEA_QMR_H__\n\n#include <linux/prefetch.h>\n#include \"ehea.h\"\n#include \"ehea_hw.h\"\n\n \n\n#define EHEA_PAGESHIFT         12\n#define EHEA_PAGESIZE          (1UL << EHEA_PAGESHIFT)\n#define EHEA_SECTSIZE          (1UL << 24)\n#define EHEA_PAGES_PER_SECTION (EHEA_SECTSIZE >> EHEA_PAGESHIFT)\n#define EHEA_HUGEPAGESHIFT     34\n#define EHEA_HUGEPAGE_SIZE     (1UL << EHEA_HUGEPAGESHIFT)\n#define EHEA_HUGEPAGE_PFN_MASK ((EHEA_HUGEPAGE_SIZE - 1) >> PAGE_SHIFT)\n\n#if ((1UL << SECTION_SIZE_BITS) < EHEA_SECTSIZE)\n#error eHEA module cannot work if kernel sectionsize < ehea sectionsize\n#endif\n\n \n\n \n#define EHEA_WR_ID_COUNT   EHEA_BMASK_IBM(0, 19)\n#define EHEA_WR_ID_TYPE    EHEA_BMASK_IBM(20, 23)\n#define EHEA_SWQE2_TYPE    0x1\n#define EHEA_SWQE3_TYPE    0x2\n#define EHEA_RWQE2_TYPE    0x3\n#define EHEA_RWQE3_TYPE    0x4\n#define EHEA_WR_ID_INDEX   EHEA_BMASK_IBM(24, 47)\n#define EHEA_WR_ID_REFILL  EHEA_BMASK_IBM(48, 63)\n\nstruct ehea_vsgentry {\n\tu64 vaddr;\n\tu32 l_key;\n\tu32 len;\n};\n\n \n#define EHEA_MAX_WQE_SG_ENTRIES  \t252\n#define SWQE2_MAX_IMM            \t(0xD0 - 0x30)\n#define SWQE3_MAX_IMM            \t224\n\n \n#define EHEA_SWQE_CRC                   0x8000\n#define EHEA_SWQE_IP_CHECKSUM           0x4000\n#define EHEA_SWQE_TCP_CHECKSUM          0x2000\n#define EHEA_SWQE_TSO                   0x1000\n#define EHEA_SWQE_SIGNALLED_COMPLETION  0x0800\n#define EHEA_SWQE_VLAN_INSERT           0x0400\n#define EHEA_SWQE_IMM_DATA_PRESENT      0x0200\n#define EHEA_SWQE_DESCRIPTORS_PRESENT   0x0100\n#define EHEA_SWQE_WRAP_CTL_REC          0x0080\n#define EHEA_SWQE_WRAP_CTL_FORCE        0x0040\n#define EHEA_SWQE_BIND                  0x0020\n#define EHEA_SWQE_PURGE                 0x0010\n\n \n#define SWQE_HEADER_SIZE\t\t32\n\nstruct ehea_swqe {\n\tu64 wr_id;\n\tu16 tx_control;\n\tu16 vlan_tag;\n\tu8 reserved1;\n\tu8 ip_start;\n\tu8 ip_end;\n\tu8 immediate_data_length;\n\tu8 tcp_offset;\n\tu8 reserved2;\n\tu16 reserved2b;\n\tu8 wrap_tag;\n\tu8 descriptors;\t\t \n\tu16 reserved3;\n\tu16 reserved4;\n\tu16 mss;\n\tu32 reserved5;\n\tunion {\n\t\t \n\t\tstruct {\n\t\t\tstruct ehea_vsgentry sg_list[EHEA_MAX_WQE_SG_ENTRIES];\n\t\t} no_immediate_data;\n\n\t\t \n\t\tstruct {\n\t\t\tstruct ehea_vsgentry sg_entry;\n\t\t\t \n\t\t\tu8 immediate_data[SWQE2_MAX_IMM];\n\t\t\t \n\t\t\tstruct ehea_vsgentry sg_list[EHEA_MAX_WQE_SG_ENTRIES-1];\n\t\t} immdata_desc __packed;\n\n\t\t \n\t\tstruct {\n\t\t\tu8 immediate_data[SWQE3_MAX_IMM];\n\t\t} immdata_nodesc;\n\t} u;\n};\n\nstruct ehea_rwqe {\n\tu64 wr_id;\t\t \n\tu8 reserved1[5];\n\tu8 data_segments;\n\tu16 reserved2;\n\tu64 reserved3;\n\tu64 reserved4;\n\tstruct ehea_vsgentry sg_list[EHEA_MAX_WQE_SG_ENTRIES];\n};\n\n#define EHEA_CQE_VLAN_TAG_XTRACT   0x0400\n\n#define EHEA_CQE_TYPE_RQ           0x60\n#define EHEA_CQE_STAT_ERR_MASK     0x700F\n#define EHEA_CQE_STAT_FAT_ERR_MASK 0xF\n#define EHEA_CQE_BLIND_CKSUM       0x8000\n#define EHEA_CQE_STAT_ERR_TCP      0x4000\n#define EHEA_CQE_STAT_ERR_IP       0x2000\n#define EHEA_CQE_STAT_ERR_CRC      0x1000\n\n \n#define EHEA_CQE_STAT_RESET_MASK   0x0002\n\nstruct ehea_cqe {\n\tu64 wr_id;\t\t \n\tu8 type;\n\tu8 valid;\n\tu16 status;\n\tu16 reserved1;\n\tu16 num_bytes_transfered;\n\tu16 vlan_tag;\n\tu16 inet_checksum_value;\n\tu8 reserved2;\n\tu8 header_length;\n\tu16 reserved3;\n\tu16 page_offset;\n\tu16 wqe_count;\n\tu32 qp_token;\n\tu32 timestamp;\n\tu32 reserved4;\n\tu64 reserved5[3];\n};\n\n#define EHEA_EQE_VALID           EHEA_BMASK_IBM(0, 0)\n#define EHEA_EQE_IS_CQE          EHEA_BMASK_IBM(1, 1)\n#define EHEA_EQE_IDENTIFIER      EHEA_BMASK_IBM(2, 7)\n#define EHEA_EQE_QP_CQ_NUMBER    EHEA_BMASK_IBM(8, 31)\n#define EHEA_EQE_QP_TOKEN        EHEA_BMASK_IBM(32, 63)\n#define EHEA_EQE_CQ_TOKEN        EHEA_BMASK_IBM(32, 63)\n#define EHEA_EQE_KEY             EHEA_BMASK_IBM(32, 63)\n#define EHEA_EQE_PORT_NUMBER     EHEA_BMASK_IBM(56, 63)\n#define EHEA_EQE_EQ_NUMBER       EHEA_BMASK_IBM(48, 63)\n#define EHEA_EQE_SM_ID           EHEA_BMASK_IBM(48, 63)\n#define EHEA_EQE_SM_MECH_NUMBER  EHEA_BMASK_IBM(48, 55)\n#define EHEA_EQE_SM_PORT_NUMBER  EHEA_BMASK_IBM(56, 63)\n\n#define EHEA_AER_RESTYPE_QP  0x8\n#define EHEA_AER_RESTYPE_CQ  0x4\n#define EHEA_AER_RESTYPE_EQ  0x3\n\n \n#define EHEA_AER_RESET_MASK   0xFFFFFFFFFEFFFFFFULL\n#define EHEA_AERR_RESET_MASK  0xFFFFFFFFFFFFFFFFULL\n\nstruct ehea_eqe {\n\tu64 entry;\n};\n\n#define ERROR_DATA_LENGTH  EHEA_BMASK_IBM(52, 63)\n#define ERROR_DATA_TYPE    EHEA_BMASK_IBM(0, 7)\n\nstatic inline void *hw_qeit_calc(struct hw_queue *queue, u64 q_offset)\n{\n\tstruct ehea_page *current_page;\n\n\tif (q_offset >= queue->queue_length)\n\t\tq_offset -= queue->queue_length;\n\tcurrent_page = (queue->queue_pages)[q_offset >> EHEA_PAGESHIFT];\n\treturn &current_page->entries[q_offset & (EHEA_PAGESIZE - 1)];\n}\n\nstatic inline void *hw_qeit_get(struct hw_queue *queue)\n{\n\treturn hw_qeit_calc(queue, queue->current_q_offset);\n}\n\nstatic inline void hw_qeit_inc(struct hw_queue *queue)\n{\n\tqueue->current_q_offset += queue->qe_size;\n\tif (queue->current_q_offset >= queue->queue_length) {\n\t\tqueue->current_q_offset = 0;\n\t\t \n\t\tqueue->toggle_state = (~queue->toggle_state) & 1;\n\t}\n}\n\nstatic inline void *hw_qeit_get_inc(struct hw_queue *queue)\n{\n\tvoid *retvalue = hw_qeit_get(queue);\n\thw_qeit_inc(queue);\n\treturn retvalue;\n}\n\nstatic inline void *hw_qeit_get_inc_valid(struct hw_queue *queue)\n{\n\tstruct ehea_cqe *retvalue = hw_qeit_get(queue);\n\tu8 valid = retvalue->valid;\n\tvoid *pref;\n\n\tif ((valid >> 7) == (queue->toggle_state & 1)) {\n\t\t \n\t\thw_qeit_inc(queue);\n\t\tpref = hw_qeit_calc(queue, queue->current_q_offset);\n\t\tprefetch(pref);\n\t\tprefetch(pref + 128);\n\t} else\n\t\tretvalue = NULL;\n\treturn retvalue;\n}\n\nstatic inline void *hw_qeit_get_valid(struct hw_queue *queue)\n{\n\tstruct ehea_cqe *retvalue = hw_qeit_get(queue);\n\tvoid *pref;\n\tu8 valid;\n\n\tpref = hw_qeit_calc(queue, queue->current_q_offset);\n\tprefetch(pref);\n\tprefetch(pref + 128);\n\tprefetch(pref + 256);\n\tvalid = retvalue->valid;\n\tif (!((valid >> 7) == (queue->toggle_state & 1)))\n\t\tretvalue = NULL;\n\treturn retvalue;\n}\n\nstatic inline void *hw_qeit_reset(struct hw_queue *queue)\n{\n\tqueue->current_q_offset = 0;\n\treturn hw_qeit_get(queue);\n}\n\nstatic inline void *hw_qeit_eq_get_inc(struct hw_queue *queue)\n{\n\tu64 last_entry_in_q = queue->queue_length - queue->qe_size;\n\tvoid *retvalue;\n\n\tretvalue = hw_qeit_get(queue);\n\tqueue->current_q_offset += queue->qe_size;\n\tif (queue->current_q_offset > last_entry_in_q) {\n\t\tqueue->current_q_offset = 0;\n\t\tqueue->toggle_state = (~queue->toggle_state) & 1;\n\t}\n\treturn retvalue;\n}\n\nstatic inline void *hw_eqit_eq_get_inc_valid(struct hw_queue *queue)\n{\n\tvoid *retvalue = hw_qeit_get(queue);\n\tu32 qe = *(u8 *)retvalue;\n\tif ((qe >> 7) == (queue->toggle_state & 1))\n\t\thw_qeit_eq_get_inc(queue);\n\telse\n\t\tretvalue = NULL;\n\treturn retvalue;\n}\n\nstatic inline struct ehea_rwqe *ehea_get_next_rwqe(struct ehea_qp *qp,\n\t\t\t\t\t\t   int rq_nr)\n{\n\tstruct hw_queue *queue;\n\n\tif (rq_nr == 1)\n\t\tqueue = &qp->hw_rqueue1;\n\telse if (rq_nr == 2)\n\t\tqueue = &qp->hw_rqueue2;\n\telse\n\t\tqueue = &qp->hw_rqueue3;\n\n\treturn hw_qeit_get_inc(queue);\n}\n\nstatic inline struct ehea_swqe *ehea_get_swqe(struct ehea_qp *my_qp,\n\t\t\t\t\t      int *wqe_index)\n{\n\tstruct hw_queue *queue = &my_qp->hw_squeue;\n\tstruct ehea_swqe *wqe_p;\n\n\t*wqe_index = (queue->current_q_offset) >> (7 + EHEA_SG_SQ);\n\twqe_p = hw_qeit_get_inc(&my_qp->hw_squeue);\n\n\treturn wqe_p;\n}\n\nstatic inline void ehea_post_swqe(struct ehea_qp *my_qp, struct ehea_swqe *swqe)\n{\n\tiosync();\n\tehea_update_sqa(my_qp, 1);\n}\n\nstatic inline struct ehea_cqe *ehea_poll_rq1(struct ehea_qp *qp, int *wqe_index)\n{\n\tstruct hw_queue *queue = &qp->hw_rqueue1;\n\n\t*wqe_index = (queue->current_q_offset) >> (7 + EHEA_SG_RQ1);\n\treturn hw_qeit_get_valid(queue);\n}\n\nstatic inline void ehea_inc_cq(struct ehea_cq *cq)\n{\n\thw_qeit_inc(&cq->hw_queue);\n}\n\nstatic inline void ehea_inc_rq1(struct ehea_qp *qp)\n{\n\thw_qeit_inc(&qp->hw_rqueue1);\n}\n\nstatic inline struct ehea_cqe *ehea_poll_cq(struct ehea_cq *my_cq)\n{\n\treturn hw_qeit_get_valid(&my_cq->hw_queue);\n}\n\n#define EHEA_CQ_REGISTER_ORIG 0\n#define EHEA_EQ_REGISTER_ORIG 0\n\nenum ehea_eq_type {\n\tEHEA_EQ = 0,\t\t \n\tEHEA_NEQ\t\t \n};\n\nstruct ehea_eq *ehea_create_eq(struct ehea_adapter *adapter,\n\t\t\t       enum ehea_eq_type type,\n\t\t\t       const u32 length, const u8 eqe_gen);\n\nint ehea_destroy_eq(struct ehea_eq *eq);\n\nstruct ehea_eqe *ehea_poll_eq(struct ehea_eq *eq);\n\nstruct ehea_cq *ehea_create_cq(struct ehea_adapter *adapter, int cqe,\n\t\t\t       u64 eq_handle, u32 cq_token);\n\nint ehea_destroy_cq(struct ehea_cq *cq);\n\nstruct ehea_qp *ehea_create_qp(struct ehea_adapter *adapter, u32 pd,\n\t\t\t       struct ehea_qp_init_attr *init_attr);\n\nint ehea_destroy_qp(struct ehea_qp *qp);\n\nint ehea_reg_kernel_mr(struct ehea_adapter *adapter, struct ehea_mr *mr);\n\nint ehea_gen_smr(struct ehea_adapter *adapter, struct ehea_mr *old_mr,\n\t\t struct ehea_mr *shared_mr);\n\nint ehea_rem_mr(struct ehea_mr *mr);\n\nu64 ehea_error_data(struct ehea_adapter *adapter, u64 res_handle,\n\t\t    u64 *aer, u64 *aerr);\n\nint ehea_add_sect_bmap(unsigned long pfn, unsigned long nr_pages);\nint ehea_rem_sect_bmap(unsigned long pfn, unsigned long nr_pages);\nint ehea_create_busmap(void);\nvoid ehea_destroy_busmap(void);\nu64 ehea_map_vaddr(void *caddr);\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}