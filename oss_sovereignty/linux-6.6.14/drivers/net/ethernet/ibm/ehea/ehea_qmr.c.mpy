{
  "module_name": "ehea_qmr.c",
  "hash_id": "c705217db6a8f7401bc6b8b3efff5176dfe969ebd8ff7d7d4160e36aadadfe84",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ibm/ehea/ehea_qmr.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include \"ehea.h\"\n#include \"ehea_phyp.h\"\n#include \"ehea_qmr.h\"\n\nstatic struct ehea_bmap *ehea_bmap;\n\nstatic void *hw_qpageit_get_inc(struct hw_queue *queue)\n{\n\tvoid *retvalue = hw_qeit_get(queue);\n\n\tqueue->current_q_offset += queue->pagesize;\n\tif (queue->current_q_offset > queue->queue_length) {\n\t\tqueue->current_q_offset -= queue->pagesize;\n\t\tretvalue = NULL;\n\t} else if (((u64) retvalue) & (EHEA_PAGESIZE-1)) {\n\t\tpr_err(\"not on pageboundary\\n\");\n\t\tretvalue = NULL;\n\t}\n\treturn retvalue;\n}\n\nstatic int hw_queue_ctor(struct hw_queue *queue, const u32 nr_of_pages,\n\t\t\t  const u32 pagesize, const u32 qe_size)\n{\n\tint pages_per_kpage = PAGE_SIZE / pagesize;\n\tint i, k;\n\n\tif ((pagesize > PAGE_SIZE) || (!pages_per_kpage)) {\n\t\tpr_err(\"pagesize conflict! kernel pagesize=%d, ehea pagesize=%d\\n\",\n\t\t       (int)PAGE_SIZE, (int)pagesize);\n\t\treturn -EINVAL;\n\t}\n\n\tqueue->queue_length = nr_of_pages * pagesize;\n\tqueue->queue_pages = kmalloc_array(nr_of_pages, sizeof(void *),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!queue->queue_pages)\n\t\treturn -ENOMEM;\n\n\t \n\ti = 0;\n\twhile (i < nr_of_pages) {\n\t\tu8 *kpage = (u8 *)get_zeroed_page(GFP_KERNEL);\n\t\tif (!kpage)\n\t\t\tgoto out_nomem;\n\t\tfor (k = 0; k < pages_per_kpage && i < nr_of_pages; k++) {\n\t\t\t(queue->queue_pages)[i] = (struct ehea_page *)kpage;\n\t\t\tkpage += pagesize;\n\t\t\ti++;\n\t\t}\n\t}\n\n\tqueue->current_q_offset = 0;\n\tqueue->qe_size = qe_size;\n\tqueue->pagesize = pagesize;\n\tqueue->toggle_state = 1;\n\n\treturn 0;\nout_nomem:\n\tfor (i = 0; i < nr_of_pages; i += pages_per_kpage) {\n\t\tif (!(queue->queue_pages)[i])\n\t\t\tbreak;\n\t\tfree_page((unsigned long)(queue->queue_pages)[i]);\n\t}\n\treturn -ENOMEM;\n}\n\nstatic void hw_queue_dtor(struct hw_queue *queue)\n{\n\tint pages_per_kpage;\n\tint i, nr_pages;\n\n\tif (!queue || !queue->queue_pages)\n\t\treturn;\n\n\tpages_per_kpage = PAGE_SIZE / queue->pagesize;\n\n\tnr_pages = queue->queue_length / queue->pagesize;\n\n\tfor (i = 0; i < nr_pages; i += pages_per_kpage)\n\t\tfree_page((unsigned long)(queue->queue_pages)[i]);\n\n\tkfree(queue->queue_pages);\n}\n\nstruct ehea_cq *ehea_create_cq(struct ehea_adapter *adapter,\n\t\t\t       int nr_of_cqe, u64 eq_handle, u32 cq_token)\n{\n\tstruct ehea_cq *cq;\n\tu64 hret, rpage;\n\tu32 counter;\n\tint ret;\n\tvoid *vpage;\n\n\tcq = kzalloc(sizeof(*cq), GFP_KERNEL);\n\tif (!cq)\n\t\tgoto out_nomem;\n\n\tcq->attr.max_nr_of_cqes = nr_of_cqe;\n\tcq->attr.cq_token = cq_token;\n\tcq->attr.eq_handle = eq_handle;\n\n\tcq->adapter = adapter;\n\n\thret = ehea_h_alloc_resource_cq(adapter->handle, &cq->attr,\n\t\t\t\t\t&cq->fw_handle, &cq->epas);\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"alloc_resource_cq failed\\n\");\n\t\tgoto out_freemem;\n\t}\n\n\tret = hw_queue_ctor(&cq->hw_queue, cq->attr.nr_pages,\n\t\t\t    EHEA_PAGESIZE, sizeof(struct ehea_cqe));\n\tif (ret)\n\t\tgoto out_freeres;\n\n\tfor (counter = 0; counter < cq->attr.nr_pages; counter++) {\n\t\tvpage = hw_qpageit_get_inc(&cq->hw_queue);\n\t\tif (!vpage) {\n\t\t\tpr_err(\"hw_qpageit_get_inc failed\\n\");\n\t\t\tgoto out_kill_hwq;\n\t\t}\n\n\t\trpage = __pa(vpage);\n\t\thret = ehea_h_register_rpage(adapter->handle,\n\t\t\t\t\t     0, EHEA_CQ_REGISTER_ORIG,\n\t\t\t\t\t     cq->fw_handle, rpage, 1);\n\t\tif (hret < H_SUCCESS) {\n\t\t\tpr_err(\"register_rpage_cq failed ehea_cq=%p hret=%llx counter=%i act_pages=%i\\n\",\n\t\t\t       cq, hret, counter, cq->attr.nr_pages);\n\t\t\tgoto out_kill_hwq;\n\t\t}\n\n\t\tif (counter == (cq->attr.nr_pages - 1)) {\n\t\t\tvpage = hw_qpageit_get_inc(&cq->hw_queue);\n\n\t\t\tif ((hret != H_SUCCESS) || (vpage)) {\n\t\t\t\tpr_err(\"registration of pages not complete hret=%llx\\n\",\n\t\t\t\t       hret);\n\t\t\t\tgoto out_kill_hwq;\n\t\t\t}\n\t\t} else {\n\t\t\tif (hret != H_PAGE_REGISTERED) {\n\t\t\t\tpr_err(\"CQ: registration of page failed hret=%llx\\n\",\n\t\t\t\t       hret);\n\t\t\t\tgoto out_kill_hwq;\n\t\t\t}\n\t\t}\n\t}\n\n\thw_qeit_reset(&cq->hw_queue);\n\tehea_reset_cq_ep(cq);\n\tehea_reset_cq_n1(cq);\n\n\treturn cq;\n\nout_kill_hwq:\n\thw_queue_dtor(&cq->hw_queue);\n\nout_freeres:\n\tehea_h_free_resource(adapter->handle, cq->fw_handle, FORCE_FREE);\n\nout_freemem:\n\tkfree(cq);\n\nout_nomem:\n\treturn NULL;\n}\n\nstatic u64 ehea_destroy_cq_res(struct ehea_cq *cq, u64 force)\n{\n\tu64 hret;\n\tu64 adapter_handle = cq->adapter->handle;\n\n\t \n\thret = ehea_h_free_resource(adapter_handle, cq->fw_handle, force);\n\tif (hret != H_SUCCESS)\n\t\treturn hret;\n\n\thw_queue_dtor(&cq->hw_queue);\n\tkfree(cq);\n\n\treturn hret;\n}\n\nint ehea_destroy_cq(struct ehea_cq *cq)\n{\n\tu64 hret, aer, aerr;\n\tif (!cq)\n\t\treturn 0;\n\n\thcp_epas_dtor(&cq->epas);\n\thret = ehea_destroy_cq_res(cq, NORMAL_FREE);\n\tif (hret == H_R_STATE) {\n\t\tehea_error_data(cq->adapter, cq->fw_handle, &aer, &aerr);\n\t\thret = ehea_destroy_cq_res(cq, FORCE_FREE);\n\t}\n\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"destroy CQ failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstruct ehea_eq *ehea_create_eq(struct ehea_adapter *adapter,\n\t\t\t       const enum ehea_eq_type type,\n\t\t\t       const u32 max_nr_of_eqes, const u8 eqe_gen)\n{\n\tint ret, i;\n\tu64 hret, rpage;\n\tvoid *vpage;\n\tstruct ehea_eq *eq;\n\n\teq = kzalloc(sizeof(*eq), GFP_KERNEL);\n\tif (!eq)\n\t\treturn NULL;\n\n\teq->adapter = adapter;\n\teq->attr.type = type;\n\teq->attr.max_nr_of_eqes = max_nr_of_eqes;\n\teq->attr.eqe_gen = eqe_gen;\n\tspin_lock_init(&eq->spinlock);\n\n\thret = ehea_h_alloc_resource_eq(adapter->handle,\n\t\t\t\t\t&eq->attr, &eq->fw_handle);\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"alloc_resource_eq failed\\n\");\n\t\tgoto out_freemem;\n\t}\n\n\tret = hw_queue_ctor(&eq->hw_queue, eq->attr.nr_pages,\n\t\t\t    EHEA_PAGESIZE, sizeof(struct ehea_eqe));\n\tif (ret) {\n\t\tpr_err(\"can't allocate eq pages\\n\");\n\t\tgoto out_freeres;\n\t}\n\n\tfor (i = 0; i < eq->attr.nr_pages; i++) {\n\t\tvpage = hw_qpageit_get_inc(&eq->hw_queue);\n\t\tif (!vpage) {\n\t\t\tpr_err(\"hw_qpageit_get_inc failed\\n\");\n\t\t\thret = H_RESOURCE;\n\t\t\tgoto out_kill_hwq;\n\t\t}\n\n\t\trpage = __pa(vpage);\n\n\t\thret = ehea_h_register_rpage(adapter->handle, 0,\n\t\t\t\t\t     EHEA_EQ_REGISTER_ORIG,\n\t\t\t\t\t     eq->fw_handle, rpage, 1);\n\n\t\tif (i == (eq->attr.nr_pages - 1)) {\n\t\t\t \n\t\t\tvpage = hw_qpageit_get_inc(&eq->hw_queue);\n\t\t\tif ((hret != H_SUCCESS) || (vpage))\n\t\t\t\tgoto out_kill_hwq;\n\n\t\t} else {\n\t\t\tif (hret != H_PAGE_REGISTERED)\n\t\t\t\tgoto out_kill_hwq;\n\n\t\t}\n\t}\n\n\thw_qeit_reset(&eq->hw_queue);\n\treturn eq;\n\nout_kill_hwq:\n\thw_queue_dtor(&eq->hw_queue);\n\nout_freeres:\n\tehea_h_free_resource(adapter->handle, eq->fw_handle, FORCE_FREE);\n\nout_freemem:\n\tkfree(eq);\n\treturn NULL;\n}\n\nstruct ehea_eqe *ehea_poll_eq(struct ehea_eq *eq)\n{\n\tstruct ehea_eqe *eqe;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&eq->spinlock, flags);\n\teqe = hw_eqit_eq_get_inc_valid(&eq->hw_queue);\n\tspin_unlock_irqrestore(&eq->spinlock, flags);\n\n\treturn eqe;\n}\n\nstatic u64 ehea_destroy_eq_res(struct ehea_eq *eq, u64 force)\n{\n\tu64 hret;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&eq->spinlock, flags);\n\n\thret = ehea_h_free_resource(eq->adapter->handle, eq->fw_handle, force);\n\tspin_unlock_irqrestore(&eq->spinlock, flags);\n\n\tif (hret != H_SUCCESS)\n\t\treturn hret;\n\n\thw_queue_dtor(&eq->hw_queue);\n\tkfree(eq);\n\n\treturn hret;\n}\n\nint ehea_destroy_eq(struct ehea_eq *eq)\n{\n\tu64 hret, aer, aerr;\n\tif (!eq)\n\t\treturn 0;\n\n\thcp_epas_dtor(&eq->epas);\n\n\thret = ehea_destroy_eq_res(eq, NORMAL_FREE);\n\tif (hret == H_R_STATE) {\n\t\tehea_error_data(eq->adapter, eq->fw_handle, &aer, &aerr);\n\t\thret = ehea_destroy_eq_res(eq, FORCE_FREE);\n\t}\n\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"destroy EQ failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int ehea_qp_alloc_register(struct ehea_qp *qp, struct hw_queue *hw_queue,\n\t\t\t   int nr_pages, int wqe_size, int act_nr_sges,\n\t\t\t   struct ehea_adapter *adapter, int h_call_q_selector)\n{\n\tu64 hret, rpage;\n\tint ret, cnt;\n\tvoid *vpage;\n\n\tret = hw_queue_ctor(hw_queue, nr_pages, EHEA_PAGESIZE, wqe_size);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (cnt = 0; cnt < nr_pages; cnt++) {\n\t\tvpage = hw_qpageit_get_inc(hw_queue);\n\t\tif (!vpage) {\n\t\t\tpr_err(\"hw_qpageit_get_inc failed\\n\");\n\t\t\tgoto out_kill_hwq;\n\t\t}\n\t\trpage = __pa(vpage);\n\t\thret = ehea_h_register_rpage(adapter->handle,\n\t\t\t\t\t     0, h_call_q_selector,\n\t\t\t\t\t     qp->fw_handle, rpage, 1);\n\t\tif (hret < H_SUCCESS) {\n\t\t\tpr_err(\"register_rpage_qp failed\\n\");\n\t\t\tgoto out_kill_hwq;\n\t\t}\n\t}\n\thw_qeit_reset(hw_queue);\n\treturn 0;\n\nout_kill_hwq:\n\thw_queue_dtor(hw_queue);\n\treturn -EIO;\n}\n\nstatic inline u32 map_wqe_size(u8 wqe_enc_size)\n{\n\treturn 128 << wqe_enc_size;\n}\n\nstruct ehea_qp *ehea_create_qp(struct ehea_adapter *adapter,\n\t\t\t       u32 pd, struct ehea_qp_init_attr *init_attr)\n{\n\tint ret;\n\tu64 hret;\n\tstruct ehea_qp *qp;\n\tu32 wqe_size_in_bytes_sq, wqe_size_in_bytes_rq1;\n\tu32 wqe_size_in_bytes_rq2, wqe_size_in_bytes_rq3;\n\n\n\tqp = kzalloc(sizeof(*qp), GFP_KERNEL);\n\tif (!qp)\n\t\treturn NULL;\n\n\tqp->adapter = adapter;\n\n\thret = ehea_h_alloc_resource_qp(adapter->handle, init_attr, pd,\n\t\t\t\t\t&qp->fw_handle, &qp->epas);\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"ehea_h_alloc_resource_qp failed\\n\");\n\t\tgoto out_freemem;\n\t}\n\n\twqe_size_in_bytes_sq = map_wqe_size(init_attr->act_wqe_size_enc_sq);\n\twqe_size_in_bytes_rq1 = map_wqe_size(init_attr->act_wqe_size_enc_rq1);\n\twqe_size_in_bytes_rq2 = map_wqe_size(init_attr->act_wqe_size_enc_rq2);\n\twqe_size_in_bytes_rq3 = map_wqe_size(init_attr->act_wqe_size_enc_rq3);\n\n\tret = ehea_qp_alloc_register(qp, &qp->hw_squeue, init_attr->nr_sq_pages,\n\t\t\t\t     wqe_size_in_bytes_sq,\n\t\t\t\t     init_attr->act_wqe_size_enc_sq, adapter,\n\t\t\t\t     0);\n\tif (ret) {\n\t\tpr_err(\"can't register for sq ret=%x\\n\", ret);\n\t\tgoto out_freeres;\n\t}\n\n\tret = ehea_qp_alloc_register(qp, &qp->hw_rqueue1,\n\t\t\t\t     init_attr->nr_rq1_pages,\n\t\t\t\t     wqe_size_in_bytes_rq1,\n\t\t\t\t     init_attr->act_wqe_size_enc_rq1,\n\t\t\t\t     adapter, 1);\n\tif (ret) {\n\t\tpr_err(\"can't register for rq1 ret=%x\\n\", ret);\n\t\tgoto out_kill_hwsq;\n\t}\n\n\tif (init_attr->rq_count > 1) {\n\t\tret = ehea_qp_alloc_register(qp, &qp->hw_rqueue2,\n\t\t\t\t\t     init_attr->nr_rq2_pages,\n\t\t\t\t\t     wqe_size_in_bytes_rq2,\n\t\t\t\t\t     init_attr->act_wqe_size_enc_rq2,\n\t\t\t\t\t     adapter, 2);\n\t\tif (ret) {\n\t\t\tpr_err(\"can't register for rq2 ret=%x\\n\", ret);\n\t\t\tgoto out_kill_hwr1q;\n\t\t}\n\t}\n\n\tif (init_attr->rq_count > 2) {\n\t\tret = ehea_qp_alloc_register(qp, &qp->hw_rqueue3,\n\t\t\t\t\t     init_attr->nr_rq3_pages,\n\t\t\t\t\t     wqe_size_in_bytes_rq3,\n\t\t\t\t\t     init_attr->act_wqe_size_enc_rq3,\n\t\t\t\t\t     adapter, 3);\n\t\tif (ret) {\n\t\t\tpr_err(\"can't register for rq3 ret=%x\\n\", ret);\n\t\t\tgoto out_kill_hwr2q;\n\t\t}\n\t}\n\n\tqp->init_attr = *init_attr;\n\n\treturn qp;\n\nout_kill_hwr2q:\n\thw_queue_dtor(&qp->hw_rqueue2);\n\nout_kill_hwr1q:\n\thw_queue_dtor(&qp->hw_rqueue1);\n\nout_kill_hwsq:\n\thw_queue_dtor(&qp->hw_squeue);\n\nout_freeres:\n\tehea_h_disable_and_get_hea(adapter->handle, qp->fw_handle);\n\tehea_h_free_resource(adapter->handle, qp->fw_handle, FORCE_FREE);\n\nout_freemem:\n\tkfree(qp);\n\treturn NULL;\n}\n\nstatic u64 ehea_destroy_qp_res(struct ehea_qp *qp, u64 force)\n{\n\tu64 hret;\n\tstruct ehea_qp_init_attr *qp_attr = &qp->init_attr;\n\n\n\tehea_h_disable_and_get_hea(qp->adapter->handle, qp->fw_handle);\n\thret = ehea_h_free_resource(qp->adapter->handle, qp->fw_handle, force);\n\tif (hret != H_SUCCESS)\n\t\treturn hret;\n\n\thw_queue_dtor(&qp->hw_squeue);\n\thw_queue_dtor(&qp->hw_rqueue1);\n\n\tif (qp_attr->rq_count > 1)\n\t\thw_queue_dtor(&qp->hw_rqueue2);\n\tif (qp_attr->rq_count > 2)\n\t\thw_queue_dtor(&qp->hw_rqueue3);\n\tkfree(qp);\n\n\treturn hret;\n}\n\nint ehea_destroy_qp(struct ehea_qp *qp)\n{\n\tu64 hret, aer, aerr;\n\tif (!qp)\n\t\treturn 0;\n\n\thcp_epas_dtor(&qp->epas);\n\n\thret = ehea_destroy_qp_res(qp, NORMAL_FREE);\n\tif (hret == H_R_STATE) {\n\t\tehea_error_data(qp->adapter, qp->fw_handle, &aer, &aerr);\n\t\thret = ehea_destroy_qp_res(qp, FORCE_FREE);\n\t}\n\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"destroy QP failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic inline int ehea_calc_index(unsigned long i, unsigned long s)\n{\n\treturn (i >> s) & EHEA_INDEX_MASK;\n}\n\nstatic inline int ehea_init_top_bmap(struct ehea_top_bmap *ehea_top_bmap,\n\t\t\t\t     int dir)\n{\n\tif (!ehea_top_bmap->dir[dir]) {\n\t\tehea_top_bmap->dir[dir] =\n\t\t\tkzalloc(sizeof(struct ehea_dir_bmap), GFP_KERNEL);\n\t\tif (!ehea_top_bmap->dir[dir])\n\t\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic inline int ehea_init_bmap(struct ehea_bmap *ehea_bmap, int top, int dir)\n{\n\tif (!ehea_bmap->top[top]) {\n\t\tehea_bmap->top[top] =\n\t\t\tkzalloc(sizeof(struct ehea_top_bmap), GFP_KERNEL);\n\t\tif (!ehea_bmap->top[top])\n\t\t\treturn -ENOMEM;\n\t}\n\treturn ehea_init_top_bmap(ehea_bmap->top[top], dir);\n}\n\nstatic DEFINE_MUTEX(ehea_busmap_mutex);\nstatic unsigned long ehea_mr_len;\n\n#define EHEA_BUSMAP_ADD_SECT 1\n#define EHEA_BUSMAP_REM_SECT 0\n\nstatic void ehea_rebuild_busmap(void)\n{\n\tu64 vaddr = EHEA_BUSMAP_START;\n\tint top, dir, idx;\n\n\tfor (top = 0; top < EHEA_MAP_ENTRIES; top++) {\n\t\tstruct ehea_top_bmap *ehea_top;\n\t\tint valid_dir_entries = 0;\n\n\t\tif (!ehea_bmap->top[top])\n\t\t\tcontinue;\n\t\tehea_top = ehea_bmap->top[top];\n\t\tfor (dir = 0; dir < EHEA_MAP_ENTRIES; dir++) {\n\t\t\tstruct ehea_dir_bmap *ehea_dir;\n\t\t\tint valid_entries = 0;\n\n\t\t\tif (!ehea_top->dir[dir])\n\t\t\t\tcontinue;\n\t\t\tvalid_dir_entries++;\n\t\t\tehea_dir = ehea_top->dir[dir];\n\t\t\tfor (idx = 0; idx < EHEA_MAP_ENTRIES; idx++) {\n\t\t\t\tif (!ehea_dir->ent[idx])\n\t\t\t\t\tcontinue;\n\t\t\t\tvalid_entries++;\n\t\t\t\tehea_dir->ent[idx] = vaddr;\n\t\t\t\tvaddr += EHEA_SECTSIZE;\n\t\t\t}\n\t\t\tif (!valid_entries) {\n\t\t\t\tehea_top->dir[dir] = NULL;\n\t\t\t\tkfree(ehea_dir);\n\t\t\t}\n\t\t}\n\t\tif (!valid_dir_entries) {\n\t\t\tehea_bmap->top[top] = NULL;\n\t\t\tkfree(ehea_top);\n\t\t}\n\t}\n}\n\nstatic int ehea_update_busmap(unsigned long pfn, unsigned long nr_pages, int add)\n{\n\tunsigned long i, start_section, end_section;\n\n\tif (!nr_pages)\n\t\treturn 0;\n\n\tif (!ehea_bmap) {\n\t\tehea_bmap = kzalloc(sizeof(struct ehea_bmap), GFP_KERNEL);\n\t\tif (!ehea_bmap)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tstart_section = (pfn * PAGE_SIZE) / EHEA_SECTSIZE;\n\tend_section = start_section + ((nr_pages * PAGE_SIZE) / EHEA_SECTSIZE);\n\t \n\tfor (i = start_section; i < end_section; i++) {\n\t\tu64 flag;\n\t\tint top = ehea_calc_index(i, EHEA_TOP_INDEX_SHIFT);\n\t\tint dir = ehea_calc_index(i, EHEA_DIR_INDEX_SHIFT);\n\t\tint idx = i & EHEA_INDEX_MASK;\n\n\t\tif (add) {\n\t\t\tint ret = ehea_init_bmap(ehea_bmap, top, dir);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tflag = 1;  \n\t\t\tehea_mr_len += EHEA_SECTSIZE;\n\t\t} else {\n\t\t\tif (!ehea_bmap->top[top])\n\t\t\t\tcontinue;\n\t\t\tif (!ehea_bmap->top[top]->dir[dir])\n\t\t\t\tcontinue;\n\t\t\tflag = 0;  \n\t\t\tehea_mr_len -= EHEA_SECTSIZE;\n\t\t}\n\n\t\tehea_bmap->top[top]->dir[dir]->ent[idx] = flag;\n\t}\n\tehea_rebuild_busmap();  \n\treturn 0;\n}\n\nint ehea_add_sect_bmap(unsigned long pfn, unsigned long nr_pages)\n{\n\tint ret;\n\n\tmutex_lock(&ehea_busmap_mutex);\n\tret = ehea_update_busmap(pfn, nr_pages, EHEA_BUSMAP_ADD_SECT);\n\tmutex_unlock(&ehea_busmap_mutex);\n\treturn ret;\n}\n\nint ehea_rem_sect_bmap(unsigned long pfn, unsigned long nr_pages)\n{\n\tint ret;\n\n\tmutex_lock(&ehea_busmap_mutex);\n\tret = ehea_update_busmap(pfn, nr_pages, EHEA_BUSMAP_REM_SECT);\n\tmutex_unlock(&ehea_busmap_mutex);\n\treturn ret;\n}\n\nstatic int ehea_is_hugepage(unsigned long pfn)\n{\n\tif (pfn & EHEA_HUGEPAGE_PFN_MASK)\n\t\treturn 0;\n\n\tif (page_shift(pfn_to_page(pfn)) != EHEA_HUGEPAGESHIFT)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic int ehea_create_busmap_callback(unsigned long initial_pfn,\n\t\t\t\t       unsigned long total_nr_pages, void *arg)\n{\n\tint ret;\n\tunsigned long pfn, start_pfn, end_pfn, nr_pages;\n\n\tif ((total_nr_pages * PAGE_SIZE) < EHEA_HUGEPAGE_SIZE)\n\t\treturn ehea_update_busmap(initial_pfn, total_nr_pages,\n\t\t\t\t\t  EHEA_BUSMAP_ADD_SECT);\n\n\t \n\tstart_pfn = initial_pfn;\n\tend_pfn = initial_pfn + total_nr_pages;\n\tpfn = start_pfn;\n\n\twhile (pfn < end_pfn) {\n\t\tif (ehea_is_hugepage(pfn)) {\n\t\t\t \n\t\t\tnr_pages = pfn - start_pfn;\n\t\t\tret = ehea_update_busmap(start_pfn, nr_pages,\n\t\t\t\t\t\t EHEA_BUSMAP_ADD_SECT);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\t \n\t\t\tpfn += (EHEA_HUGEPAGE_SIZE / PAGE_SIZE);\n\t\t\tstart_pfn = pfn;\n\t\t} else\n\t\t\tpfn += (EHEA_SECTSIZE / PAGE_SIZE);\n\t}\n\n\t \n\tnr_pages = pfn - start_pfn;\n\treturn ehea_update_busmap(start_pfn, nr_pages, EHEA_BUSMAP_ADD_SECT);\n}\n\nint ehea_create_busmap(void)\n{\n\tint ret;\n\n\tmutex_lock(&ehea_busmap_mutex);\n\tehea_mr_len = 0;\n\tret = walk_system_ram_range(0, 1ULL << MAX_PHYSMEM_BITS, NULL,\n\t\t\t\t   ehea_create_busmap_callback);\n\tmutex_unlock(&ehea_busmap_mutex);\n\treturn ret;\n}\n\nvoid ehea_destroy_busmap(void)\n{\n\tint top, dir;\n\tmutex_lock(&ehea_busmap_mutex);\n\tif (!ehea_bmap)\n\t\tgoto out_destroy;\n\n\tfor (top = 0; top < EHEA_MAP_ENTRIES; top++) {\n\t\tif (!ehea_bmap->top[top])\n\t\t\tcontinue;\n\n\t\tfor (dir = 0; dir < EHEA_MAP_ENTRIES; dir++) {\n\t\t\tif (!ehea_bmap->top[top]->dir[dir])\n\t\t\t\tcontinue;\n\n\t\t\tkfree(ehea_bmap->top[top]->dir[dir]);\n\t\t}\n\n\t\tkfree(ehea_bmap->top[top]);\n\t}\n\n\tkfree(ehea_bmap);\n\tehea_bmap = NULL;\nout_destroy:\n\tmutex_unlock(&ehea_busmap_mutex);\n}\n\nu64 ehea_map_vaddr(void *caddr)\n{\n\tint top, dir, idx;\n\tunsigned long index, offset;\n\n\tif (!ehea_bmap)\n\t\treturn EHEA_INVAL_ADDR;\n\n\tindex = __pa(caddr) >> SECTION_SIZE_BITS;\n\ttop = (index >> EHEA_TOP_INDEX_SHIFT) & EHEA_INDEX_MASK;\n\tif (!ehea_bmap->top[top])\n\t\treturn EHEA_INVAL_ADDR;\n\n\tdir = (index >> EHEA_DIR_INDEX_SHIFT) & EHEA_INDEX_MASK;\n\tif (!ehea_bmap->top[top]->dir[dir])\n\t\treturn EHEA_INVAL_ADDR;\n\n\tidx = index & EHEA_INDEX_MASK;\n\tif (!ehea_bmap->top[top]->dir[dir]->ent[idx])\n\t\treturn EHEA_INVAL_ADDR;\n\n\toffset = (unsigned long)caddr & (EHEA_SECTSIZE - 1);\n\treturn ehea_bmap->top[top]->dir[dir]->ent[idx] | offset;\n}\n\nstatic inline void *ehea_calc_sectbase(int top, int dir, int idx)\n{\n\tunsigned long ret = idx;\n\tret |= dir << EHEA_DIR_INDEX_SHIFT;\n\tret |= top << EHEA_TOP_INDEX_SHIFT;\n\treturn __va(ret << SECTION_SIZE_BITS);\n}\n\nstatic u64 ehea_reg_mr_section(int top, int dir, int idx, u64 *pt,\n\t\t\t       struct ehea_adapter *adapter,\n\t\t\t       struct ehea_mr *mr)\n{\n\tvoid *pg;\n\tu64 j, m, hret;\n\tunsigned long k = 0;\n\tu64 pt_abs = __pa(pt);\n\n\tvoid *sectbase = ehea_calc_sectbase(top, dir, idx);\n\n\tfor (j = 0; j < (EHEA_PAGES_PER_SECTION / EHEA_MAX_RPAGE); j++) {\n\n\t\tfor (m = 0; m < EHEA_MAX_RPAGE; m++) {\n\t\t\tpg = sectbase + ((k++) * EHEA_PAGESIZE);\n\t\t\tpt[m] = __pa(pg);\n\t\t}\n\t\thret = ehea_h_register_rpage_mr(adapter->handle, mr->handle, 0,\n\t\t\t\t\t\t0, pt_abs, EHEA_MAX_RPAGE);\n\n\t\tif ((hret != H_SUCCESS) &&\n\t\t    (hret != H_PAGE_REGISTERED)) {\n\t\t\tehea_h_free_resource(adapter->handle, mr->handle,\n\t\t\t\t\t     FORCE_FREE);\n\t\t\tpr_err(\"register_rpage_mr failed\\n\");\n\t\t\treturn hret;\n\t\t}\n\t}\n\treturn hret;\n}\n\nstatic u64 ehea_reg_mr_sections(int top, int dir, u64 *pt,\n\t\t\t\tstruct ehea_adapter *adapter,\n\t\t\t\tstruct ehea_mr *mr)\n{\n\tu64 hret = H_SUCCESS;\n\tint idx;\n\n\tfor (idx = 0; idx < EHEA_MAP_ENTRIES; idx++) {\n\t\tif (!ehea_bmap->top[top]->dir[dir]->ent[idx])\n\t\t\tcontinue;\n\n\t\thret = ehea_reg_mr_section(top, dir, idx, pt, adapter, mr);\n\t\tif ((hret != H_SUCCESS) && (hret != H_PAGE_REGISTERED))\n\t\t\treturn hret;\n\t}\n\treturn hret;\n}\n\nstatic u64 ehea_reg_mr_dir_sections(int top, u64 *pt,\n\t\t\t\t    struct ehea_adapter *adapter,\n\t\t\t\t    struct ehea_mr *mr)\n{\n\tu64 hret = H_SUCCESS;\n\tint dir;\n\n\tfor (dir = 0; dir < EHEA_MAP_ENTRIES; dir++) {\n\t\tif (!ehea_bmap->top[top]->dir[dir])\n\t\t\tcontinue;\n\n\t\thret = ehea_reg_mr_sections(top, dir, pt, adapter, mr);\n\t\tif ((hret != H_SUCCESS) && (hret != H_PAGE_REGISTERED))\n\t\t\treturn hret;\n\t}\n\treturn hret;\n}\n\nint ehea_reg_kernel_mr(struct ehea_adapter *adapter, struct ehea_mr *mr)\n{\n\tint ret;\n\tu64 *pt;\n\tu64 hret;\n\tu32 acc_ctrl = EHEA_MR_ACC_CTRL;\n\n\tunsigned long top;\n\n\tpt = (void *)get_zeroed_page(GFP_KERNEL);\n\tif (!pt) {\n\t\tpr_err(\"no mem\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\thret = ehea_h_alloc_resource_mr(adapter->handle, EHEA_BUSMAP_START,\n\t\t\t\t\tehea_mr_len, acc_ctrl, adapter->pd,\n\t\t\t\t\t&mr->handle, &mr->lkey);\n\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"alloc_resource_mr failed\\n\");\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tif (!ehea_bmap) {\n\t\tehea_h_free_resource(adapter->handle, mr->handle, FORCE_FREE);\n\t\tpr_err(\"no busmap available\\n\");\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tfor (top = 0; top < EHEA_MAP_ENTRIES; top++) {\n\t\tif (!ehea_bmap->top[top])\n\t\t\tcontinue;\n\n\t\thret = ehea_reg_mr_dir_sections(top, pt, adapter, mr);\n\t\tif((hret != H_PAGE_REGISTERED) && (hret != H_SUCCESS))\n\t\t\tbreak;\n\t}\n\n\tif (hret != H_SUCCESS) {\n\t\tehea_h_free_resource(adapter->handle, mr->handle, FORCE_FREE);\n\t\tpr_err(\"registering mr failed\\n\");\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tmr->vaddr = EHEA_BUSMAP_START;\n\tmr->adapter = adapter;\n\tret = 0;\nout:\n\tfree_page((unsigned long)pt);\n\treturn ret;\n}\n\nint ehea_rem_mr(struct ehea_mr *mr)\n{\n\tu64 hret;\n\n\tif (!mr || !mr->adapter)\n\t\treturn -EINVAL;\n\n\thret = ehea_h_free_resource(mr->adapter->handle, mr->handle,\n\t\t\t\t    FORCE_FREE);\n\tif (hret != H_SUCCESS) {\n\t\tpr_err(\"destroy MR failed\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nint ehea_gen_smr(struct ehea_adapter *adapter, struct ehea_mr *old_mr,\n\t\t struct ehea_mr *shared_mr)\n{\n\tu64 hret;\n\n\thret = ehea_h_register_smr(adapter->handle, old_mr->handle,\n\t\t\t\t   old_mr->vaddr, EHEA_MR_ACC_CTRL,\n\t\t\t\t   adapter->pd, shared_mr);\n\tif (hret != H_SUCCESS)\n\t\treturn -EIO;\n\n\tshared_mr->adapter = adapter;\n\n\treturn 0;\n}\n\nstatic void print_error_data(u64 *data)\n{\n\tint length;\n\tu64 type = EHEA_BMASK_GET(ERROR_DATA_TYPE, data[2]);\n\tu64 resource = data[1];\n\n\tlength = EHEA_BMASK_GET(ERROR_DATA_LENGTH, data[0]);\n\n\tif (length > EHEA_PAGESIZE)\n\t\tlength = EHEA_PAGESIZE;\n\n\tif (type == EHEA_AER_RESTYPE_QP)\n\t\tpr_err(\"QP (resource=%llX) state: AER=0x%llX, AERR=0x%llX, port=%llX\\n\",\n\t\t       resource, data[6], data[12], data[22]);\n\telse if (type == EHEA_AER_RESTYPE_CQ)\n\t\tpr_err(\"CQ (resource=%llX) state: AER=0x%llX\\n\",\n\t\t       resource, data[6]);\n\telse if (type == EHEA_AER_RESTYPE_EQ)\n\t\tpr_err(\"EQ (resource=%llX) state: AER=0x%llX\\n\",\n\t\t       resource, data[6]);\n\n\tehea_dump(data, length, \"error data\");\n}\n\nu64 ehea_error_data(struct ehea_adapter *adapter, u64 res_handle,\n\t\t    u64 *aer, u64 *aerr)\n{\n\tunsigned long ret;\n\tu64 *rblock;\n\tu64 type = 0;\n\n\trblock = (void *)get_zeroed_page(GFP_KERNEL);\n\tif (!rblock) {\n\t\tpr_err(\"Cannot allocate rblock memory\\n\");\n\t\tgoto out;\n\t}\n\n\tret = ehea_h_error_data(adapter->handle, res_handle, rblock);\n\n\tif (ret == H_SUCCESS) {\n\t\ttype = EHEA_BMASK_GET(ERROR_DATA_TYPE, rblock[2]);\n\t\t*aer = rblock[6];\n\t\t*aerr = rblock[12];\n\t\tprint_error_data(rblock);\n\t} else if (ret == H_R_STATE) {\n\t\tpr_err(\"No error data available: %llX\\n\", res_handle);\n\t} else\n\t\tpr_err(\"Error data could not be fetched: %llX\\n\", res_handle);\n\n\tfree_page((unsigned long)rblock);\nout:\n\treturn type;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}