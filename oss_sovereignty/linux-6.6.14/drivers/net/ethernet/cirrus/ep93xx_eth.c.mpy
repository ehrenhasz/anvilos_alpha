{
  "module_name": "ep93xx_eth.c",
  "hash_id": "b1ab628c532e99a57fd390af7afcb5099abd1ad9a04cbba4e048a5a8cbb4b100",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/cirrus/ep93xx_eth.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \":%s: \" fmt, __func__\n\n#include <linux/dma-mapping.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/netdevice.h>\n#include <linux/mii.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/interrupt.h>\n#include <linux/moduleparam.h>\n#include <linux/platform_device.h>\n#include <linux/delay.h>\n#include <linux/io.h>\n#include <linux/slab.h>\n\n#include <linux/platform_data/eth-ep93xx.h>\n\n#define DRV_MODULE_NAME\t\t\"ep93xx-eth\"\n\n#define RX_QUEUE_ENTRIES\t64\n#define TX_QUEUE_ENTRIES\t8\n\n#define MAX_PKT_SIZE\t\t2044\n#define PKT_BUF_SIZE\t\t2048\n\n#define REG_RXCTL\t\t0x0000\n#define  REG_RXCTL_DEFAULT\t0x00073800\n#define REG_TXCTL\t\t0x0004\n#define  REG_TXCTL_ENABLE\t0x00000001\n#define REG_MIICMD\t\t0x0010\n#define  REG_MIICMD_READ\t0x00008000\n#define  REG_MIICMD_WRITE\t0x00004000\n#define REG_MIIDATA\t\t0x0014\n#define REG_MIISTS\t\t0x0018\n#define  REG_MIISTS_BUSY\t0x00000001\n#define REG_SELFCTL\t\t0x0020\n#define  REG_SELFCTL_RESET\t0x00000001\n#define REG_INTEN\t\t0x0024\n#define  REG_INTEN_TX\t\t0x00000008\n#define  REG_INTEN_RX\t\t0x00000007\n#define REG_INTSTSP\t\t0x0028\n#define  REG_INTSTS_TX\t\t0x00000008\n#define  REG_INTSTS_RX\t\t0x00000004\n#define REG_INTSTSC\t\t0x002c\n#define REG_AFP\t\t\t0x004c\n#define REG_INDAD0\t\t0x0050\n#define REG_INDAD1\t\t0x0051\n#define REG_INDAD2\t\t0x0052\n#define REG_INDAD3\t\t0x0053\n#define REG_INDAD4\t\t0x0054\n#define REG_INDAD5\t\t0x0055\n#define REG_GIINTMSK\t\t0x0064\n#define  REG_GIINTMSK_ENABLE\t0x00008000\n#define REG_BMCTL\t\t0x0080\n#define  REG_BMCTL_ENABLE_TX\t0x00000100\n#define  REG_BMCTL_ENABLE_RX\t0x00000001\n#define REG_BMSTS\t\t0x0084\n#define  REG_BMSTS_RX_ACTIVE\t0x00000008\n#define REG_RXDQBADD\t\t0x0090\n#define REG_RXDQBLEN\t\t0x0094\n#define REG_RXDCURADD\t\t0x0098\n#define REG_RXDENQ\t\t0x009c\n#define REG_RXSTSQBADD\t\t0x00a0\n#define REG_RXSTSQBLEN\t\t0x00a4\n#define REG_RXSTSQCURADD\t0x00a8\n#define REG_RXSTSENQ\t\t0x00ac\n#define REG_TXDQBADD\t\t0x00b0\n#define REG_TXDQBLEN\t\t0x00b4\n#define REG_TXDQCURADD\t\t0x00b8\n#define REG_TXDENQ\t\t0x00bc\n#define REG_TXSTSQBADD\t\t0x00c0\n#define REG_TXSTSQBLEN\t\t0x00c4\n#define REG_TXSTSQCURADD\t0x00c8\n#define REG_MAXFRMLEN\t\t0x00e8\n\nstruct ep93xx_rdesc\n{\n\tu32\tbuf_addr;\n\tu32\trdesc1;\n};\n\n#define RDESC1_NSOF\t\t0x80000000\n#define RDESC1_BUFFER_INDEX\t0x7fff0000\n#define RDESC1_BUFFER_LENGTH\t0x0000ffff\n\nstruct ep93xx_rstat\n{\n\tu32\trstat0;\n\tu32\trstat1;\n};\n\n#define RSTAT0_RFP\t\t0x80000000\n#define RSTAT0_RWE\t\t0x40000000\n#define RSTAT0_EOF\t\t0x20000000\n#define RSTAT0_EOB\t\t0x10000000\n#define RSTAT0_AM\t\t0x00c00000\n#define RSTAT0_RX_ERR\t\t0x00200000\n#define RSTAT0_OE\t\t0x00100000\n#define RSTAT0_FE\t\t0x00080000\n#define RSTAT0_RUNT\t\t0x00040000\n#define RSTAT0_EDATA\t\t0x00020000\n#define RSTAT0_CRCE\t\t0x00010000\n#define RSTAT0_CRCI\t\t0x00008000\n#define RSTAT0_HTI\t\t0x00003f00\n#define RSTAT1_RFP\t\t0x80000000\n#define RSTAT1_BUFFER_INDEX\t0x7fff0000\n#define RSTAT1_FRAME_LENGTH\t0x0000ffff\n\nstruct ep93xx_tdesc\n{\n\tu32\tbuf_addr;\n\tu32\ttdesc1;\n};\n\n#define TDESC1_EOF\t\t0x80000000\n#define TDESC1_BUFFER_INDEX\t0x7fff0000\n#define TDESC1_BUFFER_ABORT\t0x00008000\n#define TDESC1_BUFFER_LENGTH\t0x00000fff\n\nstruct ep93xx_tstat\n{\n\tu32\ttstat0;\n};\n\n#define TSTAT0_TXFP\t\t0x80000000\n#define TSTAT0_TXWE\t\t0x40000000\n#define TSTAT0_FA\t\t0x20000000\n#define TSTAT0_LCRS\t\t0x10000000\n#define TSTAT0_OW\t\t0x04000000\n#define TSTAT0_TXU\t\t0x02000000\n#define TSTAT0_ECOLL\t\t0x01000000\n#define TSTAT0_NCOLL\t\t0x001f0000\n#define TSTAT0_BUFFER_INDEX\t0x00007fff\n\nstruct ep93xx_descs\n{\n\tstruct ep93xx_rdesc\trdesc[RX_QUEUE_ENTRIES];\n\tstruct ep93xx_tdesc\ttdesc[TX_QUEUE_ENTRIES];\n\tstruct ep93xx_rstat\trstat[RX_QUEUE_ENTRIES];\n\tstruct ep93xx_tstat\ttstat[TX_QUEUE_ENTRIES];\n};\n\nstruct ep93xx_priv\n{\n\tstruct resource\t\t*res;\n\tvoid __iomem\t\t*base_addr;\n\tint\t\t\tirq;\n\n\tstruct ep93xx_descs\t*descs;\n\tdma_addr_t\t\tdescs_dma_addr;\n\n\tvoid\t\t\t*rx_buf[RX_QUEUE_ENTRIES];\n\tvoid\t\t\t*tx_buf[TX_QUEUE_ENTRIES];\n\n\tspinlock_t\t\trx_lock;\n\tunsigned int\t\trx_pointer;\n\tunsigned int\t\ttx_clean_pointer;\n\tunsigned int\t\ttx_pointer;\n\tspinlock_t\t\ttx_pending_lock;\n\tunsigned int\t\ttx_pending;\n\n\tstruct net_device\t*dev;\n\tstruct napi_struct\tnapi;\n\n\tstruct mii_if_info\tmii;\n\tu8\t\t\tmdc_divisor;\n};\n\n#define rdb(ep, off)\t\t__raw_readb((ep)->base_addr + (off))\n#define rdw(ep, off)\t\t__raw_readw((ep)->base_addr + (off))\n#define rdl(ep, off)\t\t__raw_readl((ep)->base_addr + (off))\n#define wrb(ep, off, val)\t__raw_writeb((val), (ep)->base_addr + (off))\n#define wrw(ep, off, val)\t__raw_writew((val), (ep)->base_addr + (off))\n#define wrl(ep, off, val)\t__raw_writel((val), (ep)->base_addr + (off))\n\nstatic int ep93xx_mdio_read(struct net_device *dev, int phy_id, int reg)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tint data;\n\tint i;\n\n\twrl(ep, REG_MIICMD, REG_MIICMD_READ | (phy_id << 5) | reg);\n\n\tfor (i = 0; i < 10; i++) {\n\t\tif ((rdl(ep, REG_MIISTS) & REG_MIISTS_BUSY) == 0)\n\t\t\tbreak;\n\t\tmsleep(1);\n\t}\n\n\tif (i == 10) {\n\t\tpr_info(\"mdio read timed out\\n\");\n\t\tdata = 0xffff;\n\t} else {\n\t\tdata = rdl(ep, REG_MIIDATA);\n\t}\n\n\treturn data;\n}\n\nstatic void ep93xx_mdio_write(struct net_device *dev, int phy_id, int reg, int data)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tint i;\n\n\twrl(ep, REG_MIIDATA, data);\n\twrl(ep, REG_MIICMD, REG_MIICMD_WRITE | (phy_id << 5) | reg);\n\n\tfor (i = 0; i < 10; i++) {\n\t\tif ((rdl(ep, REG_MIISTS) & REG_MIISTS_BUSY) == 0)\n\t\t\tbreak;\n\t\tmsleep(1);\n\t}\n\n\tif (i == 10)\n\t\tpr_info(\"mdio write timed out\\n\");\n}\n\nstatic int ep93xx_rx(struct net_device *dev, int budget)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tint processed = 0;\n\n\twhile (processed < budget) {\n\t\tint entry;\n\t\tstruct ep93xx_rstat *rstat;\n\t\tu32 rstat0;\n\t\tu32 rstat1;\n\t\tint length;\n\t\tstruct sk_buff *skb;\n\n\t\tentry = ep->rx_pointer;\n\t\trstat = ep->descs->rstat + entry;\n\n\t\trstat0 = rstat->rstat0;\n\t\trstat1 = rstat->rstat1;\n\t\tif (!(rstat0 & RSTAT0_RFP) || !(rstat1 & RSTAT1_RFP))\n\t\t\tbreak;\n\n\t\trstat->rstat0 = 0;\n\t\trstat->rstat1 = 0;\n\n\t\tif (!(rstat0 & RSTAT0_EOF))\n\t\t\tpr_crit(\"not end-of-frame %.8x %.8x\\n\", rstat0, rstat1);\n\t\tif (!(rstat0 & RSTAT0_EOB))\n\t\t\tpr_crit(\"not end-of-buffer %.8x %.8x\\n\", rstat0, rstat1);\n\t\tif ((rstat1 & RSTAT1_BUFFER_INDEX) >> 16 != entry)\n\t\t\tpr_crit(\"entry mismatch %.8x %.8x\\n\", rstat0, rstat1);\n\n\t\tif (!(rstat0 & RSTAT0_RWE)) {\n\t\t\tdev->stats.rx_errors++;\n\t\t\tif (rstat0 & RSTAT0_OE)\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\tif (rstat0 & RSTAT0_FE)\n\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\tif (rstat0 & (RSTAT0_RUNT | RSTAT0_EDATA))\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\tif (rstat0 & RSTAT0_CRCE)\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tgoto err;\n\t\t}\n\n\t\tlength = rstat1 & RSTAT1_FRAME_LENGTH;\n\t\tif (length > MAX_PKT_SIZE) {\n\t\t\tpr_notice(\"invalid length %.8x %.8x\\n\", rstat0, rstat1);\n\t\t\tgoto err;\n\t\t}\n\n\t\t \n\t\tif (rstat0 & RSTAT0_CRCI)\n\t\t\tlength -= 4;\n\n\t\tskb = netdev_alloc_skb(dev, length + 2);\n\t\tif (likely(skb != NULL)) {\n\t\t\tstruct ep93xx_rdesc *rxd = &ep->descs->rdesc[entry];\n\t\t\tskb_reserve(skb, 2);\n\t\t\tdma_sync_single_for_cpu(dev->dev.parent, rxd->buf_addr,\n\t\t\t\t\t\tlength, DMA_FROM_DEVICE);\n\t\t\tskb_copy_to_linear_data(skb, ep->rx_buf[entry], length);\n\t\t\tdma_sync_single_for_device(dev->dev.parent,\n\t\t\t\t\t\t   rxd->buf_addr, length,\n\t\t\t\t\t\t   DMA_FROM_DEVICE);\n\t\t\tskb_put(skb, length);\n\t\t\tskb->protocol = eth_type_trans(skb, dev);\n\n\t\t\tnapi_gro_receive(&ep->napi, skb);\n\n\t\t\tdev->stats.rx_packets++;\n\t\t\tdev->stats.rx_bytes += length;\n\t\t} else {\n\t\t\tdev->stats.rx_dropped++;\n\t\t}\n\nerr:\n\t\tep->rx_pointer = (entry + 1) & (RX_QUEUE_ENTRIES - 1);\n\t\tprocessed++;\n\t}\n\n\treturn processed;\n}\n\nstatic int ep93xx_poll(struct napi_struct *napi, int budget)\n{\n\tstruct ep93xx_priv *ep = container_of(napi, struct ep93xx_priv, napi);\n\tstruct net_device *dev = ep->dev;\n\tint rx;\n\n\trx = ep93xx_rx(dev, budget);\n\tif (rx < budget && napi_complete_done(napi, rx)) {\n\t\tspin_lock_irq(&ep->rx_lock);\n\t\twrl(ep, REG_INTEN, REG_INTEN_TX | REG_INTEN_RX);\n\t\tspin_unlock_irq(&ep->rx_lock);\n\t}\n\n\tif (rx) {\n\t\twrw(ep, REG_RXDENQ, rx);\n\t\twrw(ep, REG_RXSTSENQ, rx);\n\t}\n\n\treturn rx;\n}\n\nstatic netdev_tx_t ep93xx_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tstruct ep93xx_tdesc *txd;\n\tint entry;\n\n\tif (unlikely(skb->len > MAX_PKT_SIZE)) {\n\t\tdev->stats.tx_dropped++;\n\t\tdev_kfree_skb(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tentry = ep->tx_pointer;\n\tep->tx_pointer = (ep->tx_pointer + 1) & (TX_QUEUE_ENTRIES - 1);\n\n\ttxd = &ep->descs->tdesc[entry];\n\n\ttxd->tdesc1 = TDESC1_EOF | (entry << 16) | (skb->len & 0xfff);\n\tdma_sync_single_for_cpu(dev->dev.parent, txd->buf_addr, skb->len,\n\t\t\t\tDMA_TO_DEVICE);\n\tskb_copy_and_csum_dev(skb, ep->tx_buf[entry]);\n\tdma_sync_single_for_device(dev->dev.parent, txd->buf_addr, skb->len,\n\t\t\t\t   DMA_TO_DEVICE);\n\tdev_kfree_skb(skb);\n\n\tspin_lock_irq(&ep->tx_pending_lock);\n\tep->tx_pending++;\n\tif (ep->tx_pending == TX_QUEUE_ENTRIES)\n\t\tnetif_stop_queue(dev);\n\tspin_unlock_irq(&ep->tx_pending_lock);\n\n\twrl(ep, REG_TXDENQ, 1);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void ep93xx_tx_complete(struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tint wake;\n\n\twake = 0;\n\n\tspin_lock(&ep->tx_pending_lock);\n\twhile (1) {\n\t\tint entry;\n\t\tstruct ep93xx_tstat *tstat;\n\t\tu32 tstat0;\n\n\t\tentry = ep->tx_clean_pointer;\n\t\ttstat = ep->descs->tstat + entry;\n\n\t\ttstat0 = tstat->tstat0;\n\t\tif (!(tstat0 & TSTAT0_TXFP))\n\t\t\tbreak;\n\n\t\ttstat->tstat0 = 0;\n\n\t\tif (tstat0 & TSTAT0_FA)\n\t\t\tpr_crit(\"frame aborted %.8x\\n\", tstat0);\n\t\tif ((tstat0 & TSTAT0_BUFFER_INDEX) != entry)\n\t\t\tpr_crit(\"entry mismatch %.8x\\n\", tstat0);\n\n\t\tif (tstat0 & TSTAT0_TXWE) {\n\t\t\tint length = ep->descs->tdesc[entry].tdesc1 & 0xfff;\n\n\t\t\tdev->stats.tx_packets++;\n\t\t\tdev->stats.tx_bytes += length;\n\t\t} else {\n\t\t\tdev->stats.tx_errors++;\n\t\t}\n\n\t\tif (tstat0 & TSTAT0_OW)\n\t\t\tdev->stats.tx_window_errors++;\n\t\tif (tstat0 & TSTAT0_TXU)\n\t\t\tdev->stats.tx_fifo_errors++;\n\t\tdev->stats.collisions += (tstat0 >> 16) & 0x1f;\n\n\t\tep->tx_clean_pointer = (entry + 1) & (TX_QUEUE_ENTRIES - 1);\n\t\tif (ep->tx_pending == TX_QUEUE_ENTRIES)\n\t\t\twake = 1;\n\t\tep->tx_pending--;\n\t}\n\tspin_unlock(&ep->tx_pending_lock);\n\n\tif (wake)\n\t\tnetif_wake_queue(dev);\n}\n\nstatic irqreturn_t ep93xx_irq(int irq, void *dev_id)\n{\n\tstruct net_device *dev = dev_id;\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tu32 status;\n\n\tstatus = rdl(ep, REG_INTSTSC);\n\tif (status == 0)\n\t\treturn IRQ_NONE;\n\n\tif (status & REG_INTSTS_RX) {\n\t\tspin_lock(&ep->rx_lock);\n\t\tif (likely(napi_schedule_prep(&ep->napi))) {\n\t\t\twrl(ep, REG_INTEN, REG_INTEN_TX);\n\t\t\t__napi_schedule(&ep->napi);\n\t\t}\n\t\tspin_unlock(&ep->rx_lock);\n\t}\n\n\tif (status & REG_INTSTS_TX)\n\t\tep93xx_tx_complete(dev);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void ep93xx_free_buffers(struct ep93xx_priv *ep)\n{\n\tstruct device *dev = ep->dev->dev.parent;\n\tint i;\n\n\tif (!ep->descs)\n\t\treturn;\n\n\tfor (i = 0; i < RX_QUEUE_ENTRIES; i++) {\n\t\tdma_addr_t d;\n\n\t\td = ep->descs->rdesc[i].buf_addr;\n\t\tif (d)\n\t\t\tdma_unmap_single(dev, d, PKT_BUF_SIZE, DMA_FROM_DEVICE);\n\n\t\tkfree(ep->rx_buf[i]);\n\t}\n\n\tfor (i = 0; i < TX_QUEUE_ENTRIES; i++) {\n\t\tdma_addr_t d;\n\n\t\td = ep->descs->tdesc[i].buf_addr;\n\t\tif (d)\n\t\t\tdma_unmap_single(dev, d, PKT_BUF_SIZE, DMA_TO_DEVICE);\n\n\t\tkfree(ep->tx_buf[i]);\n\t}\n\n\tdma_free_coherent(dev, sizeof(struct ep93xx_descs), ep->descs,\n\t\t\t\t\t\t\tep->descs_dma_addr);\n\tep->descs = NULL;\n}\n\nstatic int ep93xx_alloc_buffers(struct ep93xx_priv *ep)\n{\n\tstruct device *dev = ep->dev->dev.parent;\n\tint i;\n\n\tep->descs = dma_alloc_coherent(dev, sizeof(struct ep93xx_descs),\n\t\t\t\t&ep->descs_dma_addr, GFP_KERNEL);\n\tif (ep->descs == NULL)\n\t\treturn 1;\n\n\tfor (i = 0; i < RX_QUEUE_ENTRIES; i++) {\n\t\tvoid *buf;\n\t\tdma_addr_t d;\n\n\t\tbuf = kmalloc(PKT_BUF_SIZE, GFP_KERNEL);\n\t\tif (buf == NULL)\n\t\t\tgoto err;\n\n\t\td = dma_map_single(dev, buf, PKT_BUF_SIZE, DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(dev, d)) {\n\t\t\tkfree(buf);\n\t\t\tgoto err;\n\t\t}\n\n\t\tep->rx_buf[i] = buf;\n\t\tep->descs->rdesc[i].buf_addr = d;\n\t\tep->descs->rdesc[i].rdesc1 = (i << 16) | PKT_BUF_SIZE;\n\t}\n\n\tfor (i = 0; i < TX_QUEUE_ENTRIES; i++) {\n\t\tvoid *buf;\n\t\tdma_addr_t d;\n\n\t\tbuf = kmalloc(PKT_BUF_SIZE, GFP_KERNEL);\n\t\tif (buf == NULL)\n\t\t\tgoto err;\n\n\t\td = dma_map_single(dev, buf, PKT_BUF_SIZE, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(dev, d)) {\n\t\t\tkfree(buf);\n\t\t\tgoto err;\n\t\t}\n\n\t\tep->tx_buf[i] = buf;\n\t\tep->descs->tdesc[i].buf_addr = d;\n\t}\n\n\treturn 0;\n\nerr:\n\tep93xx_free_buffers(ep);\n\treturn 1;\n}\n\nstatic int ep93xx_start_hw(struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tunsigned long addr;\n\tint i;\n\n\twrl(ep, REG_SELFCTL, REG_SELFCTL_RESET);\n\tfor (i = 0; i < 10; i++) {\n\t\tif ((rdl(ep, REG_SELFCTL) & REG_SELFCTL_RESET) == 0)\n\t\t\tbreak;\n\t\tmsleep(1);\n\t}\n\n\tif (i == 10) {\n\t\tpr_crit(\"hw failed to reset\\n\");\n\t\treturn 1;\n\t}\n\n\twrl(ep, REG_SELFCTL, ((ep->mdc_divisor - 1) << 9));\n\n\t \n\tif ((ep93xx_mdio_read(dev, ep->mii.phy_id, MII_BMSR) & 0x0040) != 0)\n\t\twrl(ep, REG_SELFCTL, ((ep->mdc_divisor - 1) << 9) | (1 << 8));\n\n\t \n\taddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, rdesc);\n\twrl(ep, REG_RXDQBADD, addr);\n\twrl(ep, REG_RXDCURADD, addr);\n\twrw(ep, REG_RXDQBLEN, RX_QUEUE_ENTRIES * sizeof(struct ep93xx_rdesc));\n\n\t \n\taddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, rstat);\n\twrl(ep, REG_RXSTSQBADD, addr);\n\twrl(ep, REG_RXSTSQCURADD, addr);\n\twrw(ep, REG_RXSTSQBLEN, RX_QUEUE_ENTRIES * sizeof(struct ep93xx_rstat));\n\n\t \n\taddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, tdesc);\n\twrl(ep, REG_TXDQBADD, addr);\n\twrl(ep, REG_TXDQCURADD, addr);\n\twrw(ep, REG_TXDQBLEN, TX_QUEUE_ENTRIES * sizeof(struct ep93xx_tdesc));\n\n\t \n\taddr = ep->descs_dma_addr + offsetof(struct ep93xx_descs, tstat);\n\twrl(ep, REG_TXSTSQBADD, addr);\n\twrl(ep, REG_TXSTSQCURADD, addr);\n\twrw(ep, REG_TXSTSQBLEN, TX_QUEUE_ENTRIES * sizeof(struct ep93xx_tstat));\n\n\twrl(ep, REG_BMCTL, REG_BMCTL_ENABLE_TX | REG_BMCTL_ENABLE_RX);\n\twrl(ep, REG_INTEN, REG_INTEN_TX | REG_INTEN_RX);\n\twrl(ep, REG_GIINTMSK, 0);\n\n\tfor (i = 0; i < 10; i++) {\n\t\tif ((rdl(ep, REG_BMSTS) & REG_BMSTS_RX_ACTIVE) != 0)\n\t\t\tbreak;\n\t\tmsleep(1);\n\t}\n\n\tif (i == 10) {\n\t\tpr_crit(\"hw failed to start\\n\");\n\t\treturn 1;\n\t}\n\n\twrl(ep, REG_RXDENQ, RX_QUEUE_ENTRIES);\n\twrl(ep, REG_RXSTSENQ, RX_QUEUE_ENTRIES);\n\n\twrb(ep, REG_INDAD0, dev->dev_addr[0]);\n\twrb(ep, REG_INDAD1, dev->dev_addr[1]);\n\twrb(ep, REG_INDAD2, dev->dev_addr[2]);\n\twrb(ep, REG_INDAD3, dev->dev_addr[3]);\n\twrb(ep, REG_INDAD4, dev->dev_addr[4]);\n\twrb(ep, REG_INDAD5, dev->dev_addr[5]);\n\twrl(ep, REG_AFP, 0);\n\n\twrl(ep, REG_MAXFRMLEN, (MAX_PKT_SIZE << 16) | MAX_PKT_SIZE);\n\n\twrl(ep, REG_RXCTL, REG_RXCTL_DEFAULT);\n\twrl(ep, REG_TXCTL, REG_TXCTL_ENABLE);\n\n\treturn 0;\n}\n\nstatic void ep93xx_stop_hw(struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tint i;\n\n\twrl(ep, REG_SELFCTL, REG_SELFCTL_RESET);\n\tfor (i = 0; i < 10; i++) {\n\t\tif ((rdl(ep, REG_SELFCTL) & REG_SELFCTL_RESET) == 0)\n\t\t\tbreak;\n\t\tmsleep(1);\n\t}\n\n\tif (i == 10)\n\t\tpr_crit(\"hw failed to reset\\n\");\n}\n\nstatic int ep93xx_open(struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tint err;\n\n\tif (ep93xx_alloc_buffers(ep))\n\t\treturn -ENOMEM;\n\n\tnapi_enable(&ep->napi);\n\n\tif (ep93xx_start_hw(dev)) {\n\t\tnapi_disable(&ep->napi);\n\t\tep93xx_free_buffers(ep);\n\t\treturn -EIO;\n\t}\n\n\tspin_lock_init(&ep->rx_lock);\n\tep->rx_pointer = 0;\n\tep->tx_clean_pointer = 0;\n\tep->tx_pointer = 0;\n\tspin_lock_init(&ep->tx_pending_lock);\n\tep->tx_pending = 0;\n\n\terr = request_irq(ep->irq, ep93xx_irq, IRQF_SHARED, dev->name, dev);\n\tif (err) {\n\t\tnapi_disable(&ep->napi);\n\t\tep93xx_stop_hw(dev);\n\t\tep93xx_free_buffers(ep);\n\t\treturn err;\n\t}\n\n\twrl(ep, REG_GIINTMSK, REG_GIINTMSK_ENABLE);\n\n\tnetif_start_queue(dev);\n\n\treturn 0;\n}\n\nstatic int ep93xx_close(struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\n\tnapi_disable(&ep->napi);\n\tnetif_stop_queue(dev);\n\n\twrl(ep, REG_GIINTMSK, 0);\n\tfree_irq(ep->irq, dev);\n\tep93xx_stop_hw(dev);\n\tep93xx_free_buffers(ep);\n\n\treturn 0;\n}\n\nstatic int ep93xx_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\tstruct mii_ioctl_data *data = if_mii(ifr);\n\n\treturn generic_mii_ioctl(&ep->mii, data, cmd, NULL);\n}\n\nstatic void ep93xx_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\n{\n\tstrscpy(info->driver, DRV_MODULE_NAME, sizeof(info->driver));\n}\n\nstatic int ep93xx_get_link_ksettings(struct net_device *dev,\n\t\t\t\t     struct ethtool_link_ksettings *cmd)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\n\tmii_ethtool_get_link_ksettings(&ep->mii, cmd);\n\n\treturn 0;\n}\n\nstatic int ep93xx_set_link_ksettings(struct net_device *dev,\n\t\t\t\t     const struct ethtool_link_ksettings *cmd)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\treturn mii_ethtool_set_link_ksettings(&ep->mii, cmd);\n}\n\nstatic int ep93xx_nway_reset(struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\treturn mii_nway_restart(&ep->mii);\n}\n\nstatic u32 ep93xx_get_link(struct net_device *dev)\n{\n\tstruct ep93xx_priv *ep = netdev_priv(dev);\n\treturn mii_link_ok(&ep->mii);\n}\n\nstatic const struct ethtool_ops ep93xx_ethtool_ops = {\n\t.get_drvinfo\t\t= ep93xx_get_drvinfo,\n\t.nway_reset\t\t= ep93xx_nway_reset,\n\t.get_link\t\t= ep93xx_get_link,\n\t.get_link_ksettings\t= ep93xx_get_link_ksettings,\n\t.set_link_ksettings\t= ep93xx_set_link_ksettings,\n};\n\nstatic const struct net_device_ops ep93xx_netdev_ops = {\n\t.ndo_open\t\t= ep93xx_open,\n\t.ndo_stop\t\t= ep93xx_close,\n\t.ndo_start_xmit\t\t= ep93xx_xmit,\n\t.ndo_eth_ioctl\t\t= ep93xx_ioctl,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n};\n\nstatic struct net_device *ep93xx_dev_alloc(struct ep93xx_eth_data *data)\n{\n\tstruct net_device *dev;\n\n\tdev = alloc_etherdev(sizeof(struct ep93xx_priv));\n\tif (dev == NULL)\n\t\treturn NULL;\n\n\teth_hw_addr_set(dev, data->dev_addr);\n\n\tdev->ethtool_ops = &ep93xx_ethtool_ops;\n\tdev->netdev_ops = &ep93xx_netdev_ops;\n\n\tdev->features |= NETIF_F_SG | NETIF_F_HW_CSUM;\n\n\treturn dev;\n}\n\n\nstatic int ep93xx_eth_remove(struct platform_device *pdev)\n{\n\tstruct net_device *dev;\n\tstruct ep93xx_priv *ep;\n\tstruct resource *mem;\n\n\tdev = platform_get_drvdata(pdev);\n\tif (dev == NULL)\n\t\treturn 0;\n\n\tep = netdev_priv(dev);\n\n\t \n\tunregister_netdev(dev);\n\tep93xx_free_buffers(ep);\n\n\tif (ep->base_addr != NULL)\n\t\tiounmap(ep->base_addr);\n\n\tif (ep->res != NULL) {\n\t\tmem = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\t\trelease_mem_region(mem->start, resource_size(mem));\n\t}\n\n\tfree_netdev(dev);\n\n\treturn 0;\n}\n\nstatic int ep93xx_eth_probe(struct platform_device *pdev)\n{\n\tstruct ep93xx_eth_data *data;\n\tstruct net_device *dev;\n\tstruct ep93xx_priv *ep;\n\tstruct resource *mem;\n\tint irq;\n\tint err;\n\n\tif (pdev == NULL)\n\t\treturn -ENODEV;\n\tdata = dev_get_platdata(&pdev->dev);\n\n\tmem = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tirq = platform_get_irq(pdev, 0);\n\tif (!mem || irq < 0)\n\t\treturn -ENXIO;\n\n\tdev = ep93xx_dev_alloc(data);\n\tif (dev == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\tep = netdev_priv(dev);\n\tep->dev = dev;\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\tnetif_napi_add(dev, &ep->napi, ep93xx_poll);\n\n\tplatform_set_drvdata(pdev, dev);\n\n\tep->res = request_mem_region(mem->start, resource_size(mem),\n\t\t\t\t     dev_name(&pdev->dev));\n\tif (ep->res == NULL) {\n\t\tdev_err(&pdev->dev, \"Could not reserve memory region\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tep->base_addr = ioremap(mem->start, resource_size(mem));\n\tif (ep->base_addr == NULL) {\n\t\tdev_err(&pdev->dev, \"Failed to ioremap ethernet registers\\n\");\n\t\terr = -EIO;\n\t\tgoto err_out;\n\t}\n\tep->irq = irq;\n\n\tep->mii.phy_id = data->phy_id;\n\tep->mii.phy_id_mask = 0x1f;\n\tep->mii.reg_num_mask = 0x1f;\n\tep->mii.dev = dev;\n\tep->mii.mdio_read = ep93xx_mdio_read;\n\tep->mii.mdio_write = ep93xx_mdio_write;\n\tep->mdc_divisor = 40;\t \n\n\tif (is_zero_ether_addr(dev->dev_addr))\n\t\teth_hw_addr_random(dev);\n\n\terr = register_netdev(dev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to register netdev\\n\");\n\t\tgoto err_out;\n\t}\n\n\tprintk(KERN_INFO \"%s: ep93xx on-chip ethernet, IRQ %d, %pM\\n\",\n\t\t\tdev->name, ep->irq, dev->dev_addr);\n\n\treturn 0;\n\nerr_out:\n\tep93xx_eth_remove(pdev);\n\treturn err;\n}\n\n\nstatic struct platform_driver ep93xx_eth_driver = {\n\t.probe\t\t= ep93xx_eth_probe,\n\t.remove\t\t= ep93xx_eth_remove,\n\t.driver\t\t= {\n\t\t.name\t= \"ep93xx-eth\",\n\t},\n};\n\nmodule_platform_driver(ep93xx_eth_driver);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"platform:ep93xx-eth\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}