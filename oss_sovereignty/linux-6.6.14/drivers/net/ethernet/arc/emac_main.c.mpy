{
  "module_name": "emac_main.c",
  "hash_id": "29e10cebca79d53eadc8b694a414d851ad37215ca462ed50c8f62ec5dbc6448a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/arc/emac_main.c",
  "human_readable_source": "\n \n\n#include <linux/crc32.h>\n#include <linux/etherdevice.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n\n#include \"emac.h\"\n\nstatic void arc_emac_restart(struct net_device *ndev);\n\n \nstatic inline int arc_emac_tx_avail(struct arc_emac_priv *priv)\n{\n\treturn (priv->txbd_dirty + TX_BD_NUM - priv->txbd_curr - 1) % TX_BD_NUM;\n}\n\n \nstatic void arc_emac_adjust_link(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct phy_device *phy_dev = ndev->phydev;\n\tunsigned int reg, state_changed = 0;\n\n\tif (priv->link != phy_dev->link) {\n\t\tpriv->link = phy_dev->link;\n\t\tstate_changed = 1;\n\t}\n\n\tif (priv->speed != phy_dev->speed) {\n\t\tpriv->speed = phy_dev->speed;\n\t\tstate_changed = 1;\n\t\tif (priv->set_mac_speed)\n\t\t\tpriv->set_mac_speed(priv, priv->speed);\n\t}\n\n\tif (priv->duplex != phy_dev->duplex) {\n\t\treg = arc_reg_get(priv, R_CTRL);\n\n\t\tif (phy_dev->duplex == DUPLEX_FULL)\n\t\t\treg |= ENFL_MASK;\n\t\telse\n\t\t\treg &= ~ENFL_MASK;\n\n\t\tarc_reg_set(priv, R_CTRL, reg);\n\t\tpriv->duplex = phy_dev->duplex;\n\t\tstate_changed = 1;\n\t}\n\n\tif (state_changed)\n\t\tphy_print_status(phy_dev);\n}\n\n \nstatic void arc_emac_get_drvinfo(struct net_device *ndev,\n\t\t\t\t struct ethtool_drvinfo *info)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\n\tstrscpy(info->driver, priv->drv_name, sizeof(info->driver));\n}\n\nstatic const struct ethtool_ops arc_emac_ethtool_ops = {\n\t.get_drvinfo\t= arc_emac_get_drvinfo,\n\t.get_link\t= ethtool_op_get_link,\n\t.get_link_ksettings = phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings = phy_ethtool_set_link_ksettings,\n};\n\n#define FIRST_OR_LAST_MASK\t(FIRST_MASK | LAST_MASK)\n\n \nstatic void arc_emac_tx_clean(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct net_device_stats *stats = &ndev->stats;\n\tunsigned int i;\n\n\tfor (i = 0; i < TX_BD_NUM; i++) {\n\t\tunsigned int *txbd_dirty = &priv->txbd_dirty;\n\t\tstruct arc_emac_bd *txbd = &priv->txbd[*txbd_dirty];\n\t\tstruct buffer_state *tx_buff = &priv->tx_buff[*txbd_dirty];\n\t\tstruct sk_buff *skb = tx_buff->skb;\n\t\tunsigned int info = le32_to_cpu(txbd->info);\n\n\t\tif ((info & FOR_EMAC) || !txbd->data || !skb)\n\t\t\tbreak;\n\n\t\tif (unlikely(info & (DROP | DEFR | LTCL | UFLO))) {\n\t\t\tstats->tx_errors++;\n\t\t\tstats->tx_dropped++;\n\n\t\t\tif (info & DEFR)\n\t\t\t\tstats->tx_carrier_errors++;\n\n\t\t\tif (info & LTCL)\n\t\t\t\tstats->collisions++;\n\n\t\t\tif (info & UFLO)\n\t\t\t\tstats->tx_fifo_errors++;\n\t\t} else if (likely(info & FIRST_OR_LAST_MASK)) {\n\t\t\tstats->tx_packets++;\n\t\t\tstats->tx_bytes += skb->len;\n\t\t}\n\n\t\tdma_unmap_single(&ndev->dev, dma_unmap_addr(tx_buff, addr),\n\t\t\t\t dma_unmap_len(tx_buff, len), DMA_TO_DEVICE);\n\n\t\t \n\t\tdev_consume_skb_irq(skb);\n\n\t\ttxbd->data = 0;\n\t\ttxbd->info = 0;\n\t\ttx_buff->skb = NULL;\n\n\t\t*txbd_dirty = (*txbd_dirty + 1) % TX_BD_NUM;\n\t}\n\n\t \n\tsmp_mb();\n\n\tif (netif_queue_stopped(ndev) && arc_emac_tx_avail(priv))\n\t\tnetif_wake_queue(ndev);\n}\n\n \nstatic int arc_emac_rx(struct net_device *ndev, int budget)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tunsigned int work_done;\n\n\tfor (work_done = 0; work_done < budget; work_done++) {\n\t\tunsigned int *last_rx_bd = &priv->last_rx_bd;\n\t\tstruct net_device_stats *stats = &ndev->stats;\n\t\tstruct buffer_state *rx_buff = &priv->rx_buff[*last_rx_bd];\n\t\tstruct arc_emac_bd *rxbd = &priv->rxbd[*last_rx_bd];\n\t\tunsigned int pktlen, info = le32_to_cpu(rxbd->info);\n\t\tstruct sk_buff *skb;\n\t\tdma_addr_t addr;\n\n\t\tif (unlikely((info & OWN_MASK) == FOR_EMAC))\n\t\t\tbreak;\n\n\t\t \n\t\t*last_rx_bd = (*last_rx_bd + 1) % RX_BD_NUM;\n\n\t\tif (unlikely((info & FIRST_OR_LAST_MASK) !=\n\t\t\t     FIRST_OR_LAST_MASK)) {\n\t\t\t \n\t\t\tif (net_ratelimit())\n\t\t\t\tnetdev_err(ndev, \"incomplete packet received\\n\");\n\n\t\t\t \n\t\t\trxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\n\t\t\tstats->rx_errors++;\n\t\t\tstats->rx_length_errors++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tskb = netdev_alloc_skb_ip_align(ndev, EMAC_BUFFER_SIZE);\n\t\tif (unlikely(!skb)) {\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetdev_err(ndev, \"cannot allocate skb\\n\");\n\t\t\t \n\t\t\trxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\n\t\t\tstats->rx_errors++;\n\t\t\tstats->rx_dropped++;\n\t\t\tcontinue;\n\t\t}\n\n\t\taddr = dma_map_single(&ndev->dev, (void *)skb->data,\n\t\t\t\t      EMAC_BUFFER_SIZE, DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(&ndev->dev, addr)) {\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetdev_err(ndev, \"cannot map dma buffer\\n\");\n\t\t\tdev_kfree_skb(skb);\n\t\t\t \n\t\t\trxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\n\t\t\tstats->rx_errors++;\n\t\t\tstats->rx_dropped++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tdma_unmap_single(&ndev->dev, dma_unmap_addr(rx_buff, addr),\n\t\t\t\t dma_unmap_len(rx_buff, len), DMA_FROM_DEVICE);\n\n\t\tpktlen = info & LEN_MASK;\n\t\tstats->rx_packets++;\n\t\tstats->rx_bytes += pktlen;\n\t\tskb_put(rx_buff->skb, pktlen);\n\t\trx_buff->skb->dev = ndev;\n\t\trx_buff->skb->protocol = eth_type_trans(rx_buff->skb, ndev);\n\n\t\tnetif_receive_skb(rx_buff->skb);\n\n\t\trx_buff->skb = skb;\n\t\tdma_unmap_addr_set(rx_buff, addr, addr);\n\t\tdma_unmap_len_set(rx_buff, len, EMAC_BUFFER_SIZE);\n\n\t\trxbd->data = cpu_to_le32(addr);\n\n\t\t \n\t\twmb();\n\n\t\t \n\t\trxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\n\t}\n\n\treturn work_done;\n}\n\n \nstatic void arc_emac_rx_miss_handle(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct net_device_stats *stats = &ndev->stats;\n\tunsigned int miss;\n\n\tmiss = arc_reg_get(priv, R_MISS);\n\tif (miss) {\n\t\tstats->rx_errors += miss;\n\t\tstats->rx_missed_errors += miss;\n\t\tpriv->rx_missed_errors += miss;\n\t}\n}\n\n \nstatic void arc_emac_rx_stall_check(struct net_device *ndev,\n\t\t\t\t    int budget, unsigned int work_done)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct arc_emac_bd *rxbd;\n\n\tif (work_done)\n\t\tpriv->rx_missed_errors = 0;\n\n\tif (priv->rx_missed_errors && budget) {\n\t\trxbd = &priv->rxbd[priv->last_rx_bd];\n\t\tif (le32_to_cpu(rxbd->info) & FOR_EMAC) {\n\t\t\tarc_emac_restart(ndev);\n\t\t\tpriv->rx_missed_errors = 0;\n\t\t}\n\t}\n}\n\n \nstatic int arc_emac_poll(struct napi_struct *napi, int budget)\n{\n\tstruct net_device *ndev = napi->dev;\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tunsigned int work_done;\n\n\tarc_emac_tx_clean(ndev);\n\tarc_emac_rx_miss_handle(ndev);\n\n\twork_done = arc_emac_rx(ndev, budget);\n\tif (work_done < budget) {\n\t\tnapi_complete_done(napi, work_done);\n\t\tarc_reg_or(priv, R_ENABLE, RXINT_MASK | TXINT_MASK);\n\t}\n\n\tarc_emac_rx_stall_check(ndev, budget, work_done);\n\n\treturn work_done;\n}\n\n \nstatic irqreturn_t arc_emac_intr(int irq, void *dev_instance)\n{\n\tstruct net_device *ndev = dev_instance;\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct net_device_stats *stats = &ndev->stats;\n\tunsigned int status;\n\n\tstatus = arc_reg_get(priv, R_STATUS);\n\tstatus &= ~MDIO_MASK;\n\n\t \n\tarc_reg_set(priv, R_STATUS, status);\n\n\tif (status & (RXINT_MASK | TXINT_MASK)) {\n\t\tif (likely(napi_schedule_prep(&priv->napi))) {\n\t\t\tarc_reg_clr(priv, R_ENABLE, RXINT_MASK | TXINT_MASK);\n\t\t\t__napi_schedule(&priv->napi);\n\t\t}\n\t}\n\n\tif (status & ERR_MASK) {\n\t\t \n\n\t\tif (status & MSER_MASK) {\n\t\t\tstats->rx_missed_errors += 0x100;\n\t\t\tstats->rx_errors += 0x100;\n\t\t\tpriv->rx_missed_errors += 0x100;\n\t\t\tnapi_schedule(&priv->napi);\n\t\t}\n\n\t\tif (status & RXCR_MASK) {\n\t\t\tstats->rx_crc_errors += 0x100;\n\t\t\tstats->rx_errors += 0x100;\n\t\t}\n\n\t\tif (status & RXFR_MASK) {\n\t\t\tstats->rx_frame_errors += 0x100;\n\t\t\tstats->rx_errors += 0x100;\n\t\t}\n\n\t\tif (status & RXFL_MASK) {\n\t\t\tstats->rx_over_errors += 0x100;\n\t\t\tstats->rx_errors += 0x100;\n\t\t}\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void arc_emac_poll_controller(struct net_device *dev)\n{\n\tdisable_irq(dev->irq);\n\tarc_emac_intr(dev->irq, dev);\n\tenable_irq(dev->irq);\n}\n#endif\n\n \nstatic int arc_emac_open(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct phy_device *phy_dev = ndev->phydev;\n\tint i;\n\n\tphy_dev->autoneg = AUTONEG_ENABLE;\n\tphy_dev->speed = 0;\n\tphy_dev->duplex = 0;\n\tlinkmode_and(phy_dev->advertising, phy_dev->advertising,\n\t\t     phy_dev->supported);\n\n\tpriv->last_rx_bd = 0;\n\n\t \n\tfor (i = 0; i < RX_BD_NUM; i++) {\n\t\tdma_addr_t addr;\n\t\tunsigned int *last_rx_bd = &priv->last_rx_bd;\n\t\tstruct arc_emac_bd *rxbd = &priv->rxbd[*last_rx_bd];\n\t\tstruct buffer_state *rx_buff = &priv->rx_buff[*last_rx_bd];\n\n\t\trx_buff->skb = netdev_alloc_skb_ip_align(ndev,\n\t\t\t\t\t\t\t EMAC_BUFFER_SIZE);\n\t\tif (unlikely(!rx_buff->skb))\n\t\t\treturn -ENOMEM;\n\n\t\taddr = dma_map_single(&ndev->dev, (void *)rx_buff->skb->data,\n\t\t\t\t      EMAC_BUFFER_SIZE, DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(&ndev->dev, addr)) {\n\t\t\tnetdev_err(ndev, \"cannot dma map\\n\");\n\t\t\tdev_kfree_skb(rx_buff->skb);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tdma_unmap_addr_set(rx_buff, addr, addr);\n\t\tdma_unmap_len_set(rx_buff, len, EMAC_BUFFER_SIZE);\n\n\t\trxbd->data = cpu_to_le32(addr);\n\n\t\t \n\t\twmb();\n\n\t\t \n\t\trxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\n\n\t\t*last_rx_bd = (*last_rx_bd + 1) % RX_BD_NUM;\n\t}\n\n\tpriv->txbd_curr = 0;\n\tpriv->txbd_dirty = 0;\n\n\t \n\tmemset(priv->txbd, 0, TX_RING_SZ);\n\n\t \n\tarc_reg_set(priv, R_LAFL, 0);\n\tarc_reg_set(priv, R_LAFH, 0);\n\n\t \n\tarc_reg_set(priv, R_RX_RING, (unsigned int)priv->rxbd_dma);\n\tarc_reg_set(priv, R_TX_RING, (unsigned int)priv->txbd_dma);\n\n\t \n\tarc_reg_set(priv, R_ENABLE, RXINT_MASK | TXINT_MASK | ERR_MASK);\n\n\t \n\tarc_reg_set(priv, R_CTRL,\n\t\t    (RX_BD_NUM << 24) |\t \n\t\t    (TX_BD_NUM << 16) |\t \n\t\t    TXRN_MASK | RXRN_MASK);\n\n\tnapi_enable(&priv->napi);\n\n\t \n\tarc_reg_or(priv, R_CTRL, EN_MASK);\n\n\tphy_start(ndev->phydev);\n\n\tnetif_start_queue(ndev);\n\n\treturn 0;\n}\n\n \nstatic void arc_emac_set_rx_mode(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\n\tif (ndev->flags & IFF_PROMISC) {\n\t\tarc_reg_or(priv, R_CTRL, PROM_MASK);\n\t} else {\n\t\tarc_reg_clr(priv, R_CTRL, PROM_MASK);\n\n\t\tif (ndev->flags & IFF_ALLMULTI) {\n\t\t\tarc_reg_set(priv, R_LAFL, ~0);\n\t\t\tarc_reg_set(priv, R_LAFH, ~0);\n\t\t} else if (ndev->flags & IFF_MULTICAST) {\n\t\t\tstruct netdev_hw_addr *ha;\n\t\t\tunsigned int filter[2] = { 0, 0 };\n\t\t\tint bit;\n\n\t\t\tnetdev_for_each_mc_addr(ha, ndev) {\n\t\t\t\tbit = ether_crc_le(ETH_ALEN, ha->addr) >> 26;\n\t\t\t\tfilter[bit >> 5] |= 1 << (bit & 31);\n\t\t\t}\n\n\t\t\tarc_reg_set(priv, R_LAFL, filter[0]);\n\t\t\tarc_reg_set(priv, R_LAFH, filter[1]);\n\t\t} else {\n\t\t\tarc_reg_set(priv, R_LAFL, 0);\n\t\t\tarc_reg_set(priv, R_LAFH, 0);\n\t\t}\n\t}\n}\n\n \nstatic void arc_free_tx_queue(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tunsigned int i;\n\n\tfor (i = 0; i < TX_BD_NUM; i++) {\n\t\tstruct arc_emac_bd *txbd = &priv->txbd[i];\n\t\tstruct buffer_state *tx_buff = &priv->tx_buff[i];\n\n\t\tif (tx_buff->skb) {\n\t\t\tdma_unmap_single(&ndev->dev,\n\t\t\t\t\t dma_unmap_addr(tx_buff, addr),\n\t\t\t\t\t dma_unmap_len(tx_buff, len),\n\t\t\t\t\t DMA_TO_DEVICE);\n\n\t\t\t \n\t\t\tdev_kfree_skb_irq(tx_buff->skb);\n\t\t}\n\n\t\ttxbd->info = 0;\n\t\ttxbd->data = 0;\n\t\ttx_buff->skb = NULL;\n\t}\n}\n\n \nstatic void arc_free_rx_queue(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tunsigned int i;\n\n\tfor (i = 0; i < RX_BD_NUM; i++) {\n\t\tstruct arc_emac_bd *rxbd = &priv->rxbd[i];\n\t\tstruct buffer_state *rx_buff = &priv->rx_buff[i];\n\n\t\tif (rx_buff->skb) {\n\t\t\tdma_unmap_single(&ndev->dev,\n\t\t\t\t\t dma_unmap_addr(rx_buff, addr),\n\t\t\t\t\t dma_unmap_len(rx_buff, len),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\n\t\t\t \n\t\t\tdev_kfree_skb_irq(rx_buff->skb);\n\t\t}\n\n\t\trxbd->info = 0;\n\t\trxbd->data = 0;\n\t\trx_buff->skb = NULL;\n\t}\n}\n\n \nstatic int arc_emac_stop(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\n\tnapi_disable(&priv->napi);\n\tnetif_stop_queue(ndev);\n\n\tphy_stop(ndev->phydev);\n\n\t \n\tarc_reg_clr(priv, R_ENABLE, RXINT_MASK | TXINT_MASK | ERR_MASK);\n\n\t \n\tarc_reg_clr(priv, R_CTRL, EN_MASK);\n\n\t \n\tarc_free_tx_queue(ndev);\n\tarc_free_rx_queue(ndev);\n\n\treturn 0;\n}\n\n \nstatic struct net_device_stats *arc_emac_stats(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct net_device_stats *stats = &ndev->stats;\n\tunsigned long miss, rxerr;\n\tu8 rxcrc, rxfram, rxoflow;\n\n\trxerr = arc_reg_get(priv, R_RXERR);\n\tmiss = arc_reg_get(priv, R_MISS);\n\n\trxcrc = rxerr;\n\trxfram = rxerr >> 8;\n\trxoflow = rxerr >> 16;\n\n\tstats->rx_errors += miss;\n\tstats->rx_errors += rxcrc + rxfram + rxoflow;\n\n\tstats->rx_over_errors += rxoflow;\n\tstats->rx_frame_errors += rxfram;\n\tstats->rx_crc_errors += rxcrc;\n\tstats->rx_missed_errors += miss;\n\n\treturn stats;\n}\n\n \nstatic netdev_tx_t arc_emac_tx(struct sk_buff *skb, struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tunsigned int len, *txbd_curr = &priv->txbd_curr;\n\tstruct net_device_stats *stats = &ndev->stats;\n\t__le32 *info = &priv->txbd[*txbd_curr].info;\n\tdma_addr_t addr;\n\n\tif (skb_padto(skb, ETH_ZLEN))\n\t\treturn NETDEV_TX_OK;\n\n\tlen = max_t(unsigned int, ETH_ZLEN, skb->len);\n\n\tif (unlikely(!arc_emac_tx_avail(priv))) {\n\t\tnetif_stop_queue(ndev);\n\t\tnetdev_err(ndev, \"BUG! Tx Ring full when queue awake!\\n\");\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\taddr = dma_map_single(&ndev->dev, (void *)skb->data, len,\n\t\t\t      DMA_TO_DEVICE);\n\n\tif (unlikely(dma_mapping_error(&ndev->dev, addr))) {\n\t\tstats->tx_dropped++;\n\t\tstats->tx_errors++;\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\tdma_unmap_addr_set(&priv->tx_buff[*txbd_curr], addr, addr);\n\tdma_unmap_len_set(&priv->tx_buff[*txbd_curr], len, len);\n\n\tpriv->txbd[*txbd_curr].data = cpu_to_le32(addr);\n\n\t \n\twmb();\n\n\tskb_tx_timestamp(skb);\n\n\t*info = cpu_to_le32(FOR_EMAC | FIRST_OR_LAST_MASK | len);\n\n\t \n\twmb();\n\n\tpriv->tx_buff[*txbd_curr].skb = skb;\n\n\t \n\t*txbd_curr = (*txbd_curr + 1) % TX_BD_NUM;\n\n\t \n\tsmp_mb();\n\n\tif (!arc_emac_tx_avail(priv)) {\n\t\tnetif_stop_queue(ndev);\n\t\t \n\t\tsmp_mb();\n\t\tif (arc_emac_tx_avail(priv))\n\t\t\tnetif_start_queue(ndev);\n\t}\n\n\tarc_reg_set(priv, R_STATUS, TXPL_MASK);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void arc_emac_set_address_internal(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tunsigned int addr_low, addr_hi;\n\n\taddr_low = le32_to_cpu(*(__le32 *)&ndev->dev_addr[0]);\n\taddr_hi = le16_to_cpu(*(__le16 *)&ndev->dev_addr[4]);\n\n\tarc_reg_set(priv, R_ADDRL, addr_low);\n\tarc_reg_set(priv, R_ADDRH, addr_hi);\n}\n\n \nstatic int arc_emac_set_address(struct net_device *ndev, void *p)\n{\n\tstruct sockaddr *addr = p;\n\n\tif (netif_running(ndev))\n\t\treturn -EBUSY;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(ndev, addr->sa_data);\n\n\tarc_emac_set_address_internal(ndev);\n\n\treturn 0;\n}\n\n \nstatic void arc_emac_restart(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\tstruct net_device_stats *stats = &ndev->stats;\n\tint i;\n\n\tif (net_ratelimit())\n\t\tnetdev_warn(ndev, \"restarting stalled EMAC\\n\");\n\n\tnetif_stop_queue(ndev);\n\n\t \n\tarc_reg_clr(priv, R_ENABLE, RXINT_MASK | TXINT_MASK | ERR_MASK);\n\n\t \n\tarc_reg_clr(priv, R_CTRL, EN_MASK);\n\n\t \n\tarc_free_tx_queue(ndev);\n\n\t \n\tpriv->txbd_curr = 0;\n\tpriv->txbd_dirty = 0;\n\tmemset(priv->txbd, 0, TX_RING_SZ);\n\n\tfor (i = 0; i < RX_BD_NUM; i++) {\n\t\tstruct arc_emac_bd *rxbd = &priv->rxbd[i];\n\t\tunsigned int info = le32_to_cpu(rxbd->info);\n\n\t\tif (!(info & FOR_EMAC)) {\n\t\t\tstats->rx_errors++;\n\t\t\tstats->rx_dropped++;\n\t\t}\n\t\t \n\t\trxbd->info = cpu_to_le32(FOR_EMAC | EMAC_BUFFER_SIZE);\n\t}\n\tpriv->last_rx_bd = 0;\n\n\t \n\twmb();\n\n\t \n\tarc_reg_set(priv, R_ENABLE, RXINT_MASK | TXINT_MASK | ERR_MASK);\n\n\t \n\tarc_reg_or(priv, R_CTRL, EN_MASK);\n\n\tnetif_start_queue(ndev);\n}\n\nstatic const struct net_device_ops arc_emac_netdev_ops = {\n\t.ndo_open\t\t= arc_emac_open,\n\t.ndo_stop\t\t= arc_emac_stop,\n\t.ndo_start_xmit\t\t= arc_emac_tx,\n\t.ndo_set_mac_address\t= arc_emac_set_address,\n\t.ndo_get_stats\t\t= arc_emac_stats,\n\t.ndo_set_rx_mode\t= arc_emac_set_rx_mode,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl_running,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= arc_emac_poll_controller,\n#endif\n};\n\nint arc_emac_probe(struct net_device *ndev, int interface)\n{\n\tstruct device *dev = ndev->dev.parent;\n\tstruct resource res_regs;\n\tstruct device_node *phy_node;\n\tstruct phy_device *phydev = NULL;\n\tstruct arc_emac_priv *priv;\n\tunsigned int id, clock_frequency, irq;\n\tint err;\n\n\t \n\tphy_node = of_parse_phandle(dev->of_node, \"phy\", 0);\n\tif (!phy_node) {\n\t\tdev_err(dev, \"failed to retrieve phy description from device tree\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\t \n\terr = of_address_to_resource(dev->of_node, 0, &res_regs);\n\tif (err) {\n\t\tdev_err(dev, \"failed to retrieve registers base from device tree\\n\");\n\t\terr = -ENODEV;\n\t\tgoto out_put_node;\n\t}\n\n\t \n\tirq = irq_of_parse_and_map(dev->of_node, 0);\n\tif (!irq) {\n\t\tdev_err(dev, \"failed to retrieve <irq> value from device tree\\n\");\n\t\terr = -ENODEV;\n\t\tgoto out_put_node;\n\t}\n\n\tndev->netdev_ops = &arc_emac_netdev_ops;\n\tndev->ethtool_ops = &arc_emac_ethtool_ops;\n\tndev->watchdog_timeo = TX_TIMEOUT;\n\n\tpriv = netdev_priv(ndev);\n\tpriv->dev = dev;\n\n\tpriv->regs = devm_ioremap_resource(dev, &res_regs);\n\tif (IS_ERR(priv->regs)) {\n\t\terr = PTR_ERR(priv->regs);\n\t\tgoto out_put_node;\n\t}\n\n\tdev_dbg(dev, \"Registers base address is 0x%p\\n\", priv->regs);\n\n\tif (priv->clk) {\n\t\terr = clk_prepare_enable(priv->clk);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"failed to enable clock\\n\");\n\t\t\tgoto out_put_node;\n\t\t}\n\n\t\tclock_frequency = clk_get_rate(priv->clk);\n\t} else {\n\t\t \n\t\tif (of_property_read_u32(dev->of_node, \"clock-frequency\",\n\t\t\t\t\t &clock_frequency)) {\n\t\t\tdev_err(dev, \"failed to retrieve <clock-frequency> from device tree\\n\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_put_node;\n\t\t}\n\t}\n\n\tid = arc_reg_get(priv, R_ID);\n\n\t \n\tif (!(id == 0x0005fd02 || id == 0x0007fd02)) {\n\t\tdev_err(dev, \"ARC EMAC not detected, id=0x%x\\n\", id);\n\t\terr = -ENODEV;\n\t\tgoto out_clken;\n\t}\n\tdev_info(dev, \"ARC EMAC detected with id: 0x%x\\n\", id);\n\n\t \n\tarc_reg_set(priv, R_POLLRATE, clock_frequency / 1000000);\n\n\tndev->irq = irq;\n\tdev_info(dev, \"IRQ is %d\\n\", ndev->irq);\n\n\t \n\terr = devm_request_irq(dev, ndev->irq, arc_emac_intr, 0,\n\t\t\t       ndev->name, ndev);\n\tif (err) {\n\t\tdev_err(dev, \"could not allocate IRQ\\n\");\n\t\tgoto out_clken;\n\t}\n\n\t \n\terr = of_get_ethdev_address(dev->of_node, ndev);\n\tif (err)\n\t\teth_hw_addr_random(ndev);\n\n\tarc_emac_set_address_internal(ndev);\n\tdev_info(dev, \"MAC address is now %pM\\n\", ndev->dev_addr);\n\n\t \n\tpriv->rxbd = dmam_alloc_coherent(dev, RX_RING_SZ + TX_RING_SZ,\n\t\t\t\t\t &priv->rxbd_dma, GFP_KERNEL);\n\n\tif (!priv->rxbd) {\n\t\tdev_err(dev, \"failed to allocate data buffers\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto out_clken;\n\t}\n\n\tpriv->txbd = priv->rxbd + RX_BD_NUM;\n\n\tpriv->txbd_dma = priv->rxbd_dma + RX_RING_SZ;\n\tdev_dbg(dev, \"EMAC Device addr: Rx Ring [0x%x], Tx Ring[%x]\\n\",\n\t\t(unsigned int)priv->rxbd_dma, (unsigned int)priv->txbd_dma);\n\n\terr = arc_mdio_probe(priv);\n\tif (err) {\n\t\tdev_err(dev, \"failed to probe MII bus\\n\");\n\t\tgoto out_clken;\n\t}\n\n\tphydev = of_phy_connect(ndev, phy_node, arc_emac_adjust_link, 0,\n\t\t\t\tinterface);\n\tif (!phydev) {\n\t\tdev_err(dev, \"of_phy_connect() failed\\n\");\n\t\terr = -ENODEV;\n\t\tgoto out_mdio;\n\t}\n\n\tdev_info(dev, \"connected to %s phy with id 0x%x\\n\",\n\t\t phydev->drv->name, phydev->phy_id);\n\n\tnetif_napi_add_weight(ndev, &priv->napi, arc_emac_poll,\n\t\t\t      ARC_EMAC_NAPI_WEIGHT);\n\n\terr = register_netdev(ndev);\n\tif (err) {\n\t\tdev_err(dev, \"failed to register network device\\n\");\n\t\tgoto out_netif_api;\n\t}\n\n\tof_node_put(phy_node);\n\treturn 0;\n\nout_netif_api:\n\tnetif_napi_del(&priv->napi);\n\tphy_disconnect(phydev);\nout_mdio:\n\tarc_mdio_remove(priv);\nout_clken:\n\tif (priv->clk)\n\t\tclk_disable_unprepare(priv->clk);\nout_put_node:\n\tof_node_put(phy_node);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(arc_emac_probe);\n\nvoid arc_emac_remove(struct net_device *ndev)\n{\n\tstruct arc_emac_priv *priv = netdev_priv(ndev);\n\n\tphy_disconnect(ndev->phydev);\n\tarc_mdio_remove(priv);\n\tunregister_netdev(ndev);\n\tnetif_napi_del(&priv->napi);\n\n\tif (!IS_ERR(priv->clk))\n\t\tclk_disable_unprepare(priv->clk);\n}\nEXPORT_SYMBOL_GPL(arc_emac_remove);\n\nMODULE_AUTHOR(\"Alexey Brodkin <abrodkin@synopsys.com>\");\nMODULE_DESCRIPTION(\"ARC EMAC driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}