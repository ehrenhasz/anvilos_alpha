{
  "module_name": "lib82596.c",
  "hash_id": "185023bfbfef13d54e3957b0ee28015ddca08f67dd9a4c2db69e198557196008",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/i825xx/lib82596.c",
  "human_readable_source": "\n \n\n \n \n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/errno.h>\n#include <linux/ioport.h>\n#include <linux/interrupt.h>\n#include <linux/delay.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/types.h>\n#include <linux/bitops.h>\n#include <linux/dma-mapping.h>\n#include <linux/io.h>\n#include <linux/irq.h>\n#include <linux/gfp.h>\n\n \n\n#define DEB_INIT\t0x0001\n#define DEB_PROBE\t0x0002\n#define DEB_SERIOUS\t0x0004\n#define DEB_ERRORS\t0x0008\n#define DEB_MULTI\t0x0010\n#define DEB_TDR\t\t0x0020\n#define DEB_OPEN\t0x0040\n#define DEB_RESET\t0x0080\n#define DEB_ADDCMD\t0x0100\n#define DEB_STATUS\t0x0200\n#define DEB_STARTTX\t0x0400\n#define DEB_RXADDR\t0x0800\n#define DEB_TXADDR\t0x1000\n#define DEB_RXFRAME\t0x2000\n#define DEB_INTS\t0x4000\n#define DEB_STRUCT\t0x8000\n#define DEB_ANY\t\t0xffff\n\n\n#define DEB(x, y)\tif (i596_debug & (x)) { y; }\n\n\n \n#define PORT_RESET\t\t0x00\t \n#define PORT_SELFTEST\t\t0x01\t \n#define PORT_ALTSCP\t\t0x02\t \n#define PORT_ALTDUMP\t\t0x03\t \n\nstatic int i596_debug = (DEB_SERIOUS|DEB_PROBE);\n\n \nstatic int rx_copybreak = 100;\n\n#define PKT_BUF_SZ\t1536\n#define MAX_MC_CNT\t64\n\n#define ISCP_BUSY\t0x0001\n\n#define I596_NULL ((u32)0xffffffff)\n\n#define CMD_EOL\t\t0x8000\t \n#define CMD_SUSP\t0x4000\t \n#define CMD_INTR\t0x2000\t \n\n#define CMD_FLEX\t0x0008\t \n\nenum commands {\n\tCmdNOp = 0, CmdSASetup = 1, CmdConfigure = 2, CmdMulticastList = 3,\n\tCmdTx = 4, CmdTDR = 5, CmdDump = 6, CmdDiagnose = 7\n};\n\n#define STAT_C\t\t0x8000\t \n#define STAT_B\t\t0x4000\t \n#define STAT_OK\t\t0x2000\t \n#define STAT_A\t\t0x1000\t \n\n#define\t CUC_START\t0x0100\n#define\t CUC_RESUME\t0x0200\n#define\t CUC_SUSPEND    0x0300\n#define\t CUC_ABORT\t0x0400\n#define\t RX_START\t0x0010\n#define\t RX_RESUME\t0x0020\n#define\t RX_SUSPEND\t0x0030\n#define\t RX_ABORT\t0x0040\n\n#define TX_TIMEOUT\t(HZ/20)\n\n\nstruct i596_reg {\n\tunsigned short porthi;\n\tunsigned short portlo;\n\tu32            ca;\n};\n\n#define EOF\t\t0x8000\n#define SIZE_MASK\t0x3fff\n\nstruct i596_tbd {\n\tunsigned short size;\n\tunsigned short pad;\n\tu32            next;\n\tu32            data;\n\tu32 cache_pad[5];\t\t \n};\n\n \n\nstruct i596_cmd {\n\tstruct i596_cmd *v_next;\t \n\tunsigned short status;\n\tunsigned short command;\n\tu32            b_next;\t \n};\n\nstruct tx_cmd {\n\tstruct i596_cmd cmd;\n\tu32            tbd;\n\tunsigned short size;\n\tunsigned short pad;\n\tstruct sk_buff *skb;\t\t \n\tdma_addr_t dma_addr;\n#ifdef __LP64__\n\tu32 cache_pad[6];\t\t \n#else\n\tu32 cache_pad[1];\t\t \n#endif\n};\n\nstruct tdr_cmd {\n\tstruct i596_cmd cmd;\n\tunsigned short status;\n\tunsigned short pad;\n};\n\nstruct mc_cmd {\n\tstruct i596_cmd cmd;\n\tshort mc_cnt;\n\tchar mc_addrs[MAX_MC_CNT*6];\n};\n\nstruct sa_cmd {\n\tstruct i596_cmd cmd;\n\tchar eth_addr[8];\n};\n\nstruct cf_cmd {\n\tstruct i596_cmd cmd;\n\tchar i596_config[16];\n};\n\nstruct i596_rfd {\n\tunsigned short stat;\n\tunsigned short cmd;\n\tu32            b_next;\t \n\tu32            rbd;\n\tunsigned short count;\n\tunsigned short size;\n\tstruct i596_rfd *v_next;\t \n\tstruct i596_rfd *v_prev;\n#ifndef __LP64__\n\tu32 cache_pad[2];\t\t \n#endif\n};\n\nstruct i596_rbd {\n\t \n\tunsigned short count;\n\tunsigned short zero1;\n\tu32            b_next;\n\tu32            b_data;\t\t \n\tunsigned short size;\n\tunsigned short zero2;\n\t \n\tstruct sk_buff *skb;\n\tstruct i596_rbd *v_next;\n\tu32            b_addr;\t\t \n\tunsigned char *v_data;\t\t \n\t\t\t\t\t \n#ifdef __LP64__\n    u32 cache_pad[4];\n#endif\n};\n\n \n\n#define TX_RING_SIZE 32\n#define RX_RING_SIZE 16\n\nstruct i596_scb {\n\tunsigned short status;\n\tunsigned short command;\n\tu32           cmd;\n\tu32           rfd;\n\tu32           crc_err;\n\tu32           align_err;\n\tu32           resource_err;\n\tu32           over_err;\n\tu32           rcvdt_err;\n\tu32           short_err;\n\tunsigned short t_on;\n\tunsigned short t_off;\n};\n\nstruct i596_iscp {\n\tu32 stat;\n\tu32 scb;\n};\n\nstruct i596_scp {\n\tu32 sysbus;\n\tu32 pad;\n\tu32 iscp;\n};\n\nstruct i596_dma {\n\tstruct i596_scp scp\t\t        __attribute__((aligned(32)));\n\tvolatile struct i596_iscp iscp\t\t__attribute__((aligned(32)));\n\tvolatile struct i596_scb scb\t\t__attribute__((aligned(32)));\n\tstruct sa_cmd sa_cmd\t\t\t__attribute__((aligned(32)));\n\tstruct cf_cmd cf_cmd\t\t\t__attribute__((aligned(32)));\n\tstruct tdr_cmd tdr_cmd\t\t\t__attribute__((aligned(32)));\n\tstruct mc_cmd mc_cmd\t\t\t__attribute__((aligned(32)));\n\tstruct i596_rfd rfds[RX_RING_SIZE]\t__attribute__((aligned(32)));\n\tstruct i596_rbd rbds[RX_RING_SIZE]\t__attribute__((aligned(32)));\n\tstruct tx_cmd tx_cmds[TX_RING_SIZE]\t__attribute__((aligned(32)));\n\tstruct i596_tbd tbds[TX_RING_SIZE]\t__attribute__((aligned(32)));\n};\n\nstruct i596_private {\n\tstruct i596_dma *dma;\n\tu32    stat;\n\tint last_restart;\n\tstruct i596_rfd *rfd_head;\n\tstruct i596_rbd *rbd_head;\n\tstruct i596_cmd *cmd_tail;\n\tstruct i596_cmd *cmd_head;\n\tint cmd_backlog;\n\tu32    last_cmd;\n\tint next_tx_cmd;\n\tint options;\n\tspinlock_t lock;        \n\tdma_addr_t dma_addr;\n\tvoid __iomem *mpu_port;\n\tvoid __iomem *ca;\n};\n\nstatic const char init_setup[] =\n{\n\t0x8E,\t\t \n\t0xC8,\t\t \n\t0x80,\t\t \n\t0x2E,\t\t \n\t0x00,\t\t \n\t0x60,\t\t \n\t0x00,\t\t \n\t0xf2,\t\t \n\t0x00,\t\t \n\t0x00,\t\t \n\t0x40,\t\t \n\t0xff,\n\t0x00,\n\t0x7f   };\n\nstatic int i596_open(struct net_device *dev);\nstatic netdev_tx_t i596_start_xmit(struct sk_buff *skb, struct net_device *dev);\nstatic irqreturn_t i596_interrupt(int irq, void *dev_id);\nstatic int i596_close(struct net_device *dev);\nstatic void i596_add_cmd(struct net_device *dev, struct i596_cmd *cmd);\nstatic void i596_tx_timeout (struct net_device *dev, unsigned int txqueue);\nstatic void print_eth(unsigned char *buf, char *str);\nstatic void set_multicast_list(struct net_device *dev);\nstatic inline void ca(struct net_device *dev);\nstatic void mpu_port(struct net_device *dev, int c, dma_addr_t x);\n\nstatic int rx_ring_size = RX_RING_SIZE;\nstatic int ticks_limit = 100;\nstatic int max_cmd_backlog = TX_RING_SIZE-1;\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void i596_poll_controller(struct net_device *dev);\n#endif\n\nstatic inline dma_addr_t virt_to_dma(struct i596_private *lp, volatile void *v)\n{\n\treturn lp->dma_addr + ((unsigned long)v - (unsigned long)lp->dma);\n}\n\n#ifdef NONCOHERENT_DMA\nstatic inline void dma_sync_dev(struct net_device *ndev, volatile void *addr,\n\t\tsize_t len)\n{\n\tdma_sync_single_for_device(ndev->dev.parent,\n\t\t\tvirt_to_dma(netdev_priv(ndev), addr), len,\n\t\t\tDMA_BIDIRECTIONAL);\n}\n\nstatic inline void dma_sync_cpu(struct net_device *ndev, volatile void *addr,\n\t\tsize_t len)\n{\n\tdma_sync_single_for_cpu(ndev->dev.parent,\n\t\t\tvirt_to_dma(netdev_priv(ndev), addr), len,\n\t\t\tDMA_BIDIRECTIONAL);\n}\n#else\nstatic inline void dma_sync_dev(struct net_device *ndev, volatile void *addr,\n\t\tsize_t len)\n{\n}\nstatic inline void dma_sync_cpu(struct net_device *ndev, volatile void *addr,\n\t\tsize_t len)\n{\n}\n#endif  \n\nstatic inline int wait_istat(struct net_device *dev, struct i596_dma *dma, int delcnt, char *str)\n{\n\tdma_sync_cpu(dev, &(dma->iscp), sizeof(struct i596_iscp));\n\twhile (--delcnt && dma->iscp.stat) {\n\t\tudelay(10);\n\t\tdma_sync_cpu(dev, &(dma->iscp), sizeof(struct i596_iscp));\n\t}\n\tif (!delcnt) {\n\t\tprintk(KERN_ERR \"%s: %s, iscp.stat %04x, didn't clear\\n\",\n\t\t     dev->name, str, SWAP16(dma->iscp.stat));\n\t\treturn -1;\n\t} else\n\t\treturn 0;\n}\n\n\nstatic inline int wait_cmd(struct net_device *dev, struct i596_dma *dma, int delcnt, char *str)\n{\n\tdma_sync_cpu(dev, &(dma->scb), sizeof(struct i596_scb));\n\twhile (--delcnt && dma->scb.command) {\n\t\tudelay(10);\n\t\tdma_sync_cpu(dev, &(dma->scb), sizeof(struct i596_scb));\n\t}\n\tif (!delcnt) {\n\t\tprintk(KERN_ERR \"%s: %s, status %4.4x, cmd %4.4x.\\n\",\n\t\t       dev->name, str,\n\t\t       SWAP16(dma->scb.status),\n\t\t       SWAP16(dma->scb.command));\n\t\treturn -1;\n\t} else\n\t\treturn 0;\n}\n\n\nstatic void i596_display_data(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_dma *dma = lp->dma;\n\tstruct i596_cmd *cmd;\n\tstruct i596_rfd *rfd;\n\tstruct i596_rbd *rbd;\n\n\tprintk(KERN_DEBUG \"lp and scp at %p, .sysbus = %08x, .iscp = %08x\\n\",\n\t       &dma->scp, dma->scp.sysbus, SWAP32(dma->scp.iscp));\n\tprintk(KERN_DEBUG \"iscp at %p, iscp.stat = %08x, .scb = %08x\\n\",\n\t       &dma->iscp, SWAP32(dma->iscp.stat), SWAP32(dma->iscp.scb));\n\tprintk(KERN_DEBUG \"scb at %p, scb.status = %04x, .command = %04x,\"\n\t\t\" .cmd = %08x, .rfd = %08x\\n\",\n\t       &dma->scb, SWAP16(dma->scb.status), SWAP16(dma->scb.command),\n\t\tSWAP16(dma->scb.cmd), SWAP32(dma->scb.rfd));\n\tprintk(KERN_DEBUG \"   errors: crc %x, align %x, resource %x,\"\n\t       \" over %x, rcvdt %x, short %x\\n\",\n\t       SWAP32(dma->scb.crc_err), SWAP32(dma->scb.align_err),\n\t       SWAP32(dma->scb.resource_err), SWAP32(dma->scb.over_err),\n\t       SWAP32(dma->scb.rcvdt_err), SWAP32(dma->scb.short_err));\n\tcmd = lp->cmd_head;\n\twhile (cmd != NULL) {\n\t\tprintk(KERN_DEBUG\n\t\t       \"cmd at %p, .status = %04x, .command = %04x,\"\n\t\t       \" .b_next = %08x\\n\",\n\t\t       cmd, SWAP16(cmd->status), SWAP16(cmd->command),\n\t\t       SWAP32(cmd->b_next));\n\t\tcmd = cmd->v_next;\n\t}\n\trfd = lp->rfd_head;\n\tprintk(KERN_DEBUG \"rfd_head = %p\\n\", rfd);\n\tdo {\n\t\tprintk(KERN_DEBUG\n\t\t       \"   %p .stat %04x, .cmd %04x, b_next %08x, rbd %08x,\"\n\t\t       \" count %04x\\n\",\n\t\t       rfd, SWAP16(rfd->stat), SWAP16(rfd->cmd),\n\t\t       SWAP32(rfd->b_next), SWAP32(rfd->rbd),\n\t\t       SWAP16(rfd->count));\n\t\trfd = rfd->v_next;\n\t} while (rfd != lp->rfd_head);\n\trbd = lp->rbd_head;\n\tprintk(KERN_DEBUG \"rbd_head = %p\\n\", rbd);\n\tdo {\n\t\tprintk(KERN_DEBUG\n\t\t       \"   %p .count %04x, b_next %08x, b_data %08x,\"\n\t\t       \" size %04x\\n\",\n\t\t\trbd, SWAP16(rbd->count), SWAP32(rbd->b_next),\n\t\t       SWAP32(rbd->b_data), SWAP16(rbd->size));\n\t\trbd = rbd->v_next;\n\t} while (rbd != lp->rbd_head);\n\tdma_sync_cpu(dev, dma, sizeof(struct i596_dma));\n}\n\nstatic inline int init_rx_bufs(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_dma *dma = lp->dma;\n\tint i;\n\tstruct i596_rfd *rfd;\n\tstruct i596_rbd *rbd;\n\n\t \n\n\tfor (i = 0, rbd = dma->rbds; i < rx_ring_size; i++, rbd++) {\n\t\tdma_addr_t dma_addr;\n\t\tstruct sk_buff *skb;\n\n\t\tskb = netdev_alloc_skb_ip_align(dev, PKT_BUF_SZ);\n\t\tif (skb == NULL)\n\t\t\treturn -1;\n\t\tdma_addr = dma_map_single(dev->dev.parent, skb->data,\n\t\t\t\t\t  PKT_BUF_SZ, DMA_FROM_DEVICE);\n\t\trbd->v_next = rbd+1;\n\t\trbd->b_next = SWAP32(virt_to_dma(lp, rbd+1));\n\t\trbd->b_addr = SWAP32(virt_to_dma(lp, rbd));\n\t\trbd->skb = skb;\n\t\trbd->v_data = skb->data;\n\t\trbd->b_data = SWAP32(dma_addr);\n\t\trbd->size = SWAP16(PKT_BUF_SZ);\n\t}\n\tlp->rbd_head = dma->rbds;\n\trbd = dma->rbds + rx_ring_size - 1;\n\trbd->v_next = dma->rbds;\n\trbd->b_next = SWAP32(virt_to_dma(lp, dma->rbds));\n\n\t \n\n\tfor (i = 0, rfd = dma->rfds; i < rx_ring_size; i++, rfd++) {\n\t\trfd->rbd = I596_NULL;\n\t\trfd->v_next = rfd+1;\n\t\trfd->v_prev = rfd-1;\n\t\trfd->b_next = SWAP32(virt_to_dma(lp, rfd+1));\n\t\trfd->cmd = SWAP16(CMD_FLEX);\n\t}\n\tlp->rfd_head = dma->rfds;\n\tdma->scb.rfd = SWAP32(virt_to_dma(lp, dma->rfds));\n\trfd = dma->rfds;\n\trfd->rbd = SWAP32(virt_to_dma(lp, lp->rbd_head));\n\trfd->v_prev = dma->rfds + rx_ring_size - 1;\n\trfd = dma->rfds + rx_ring_size - 1;\n\trfd->v_next = dma->rfds;\n\trfd->b_next = SWAP32(virt_to_dma(lp, dma->rfds));\n\trfd->cmd = SWAP16(CMD_EOL|CMD_FLEX);\n\n\tdma_sync_dev(dev, dma, sizeof(struct i596_dma));\n\treturn 0;\n}\n\nstatic inline void remove_rx_bufs(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_rbd *rbd;\n\tint i;\n\n\tfor (i = 0, rbd = lp->dma->rbds; i < rx_ring_size; i++, rbd++) {\n\t\tif (rbd->skb == NULL)\n\t\t\tbreak;\n\t\tdma_unmap_single(dev->dev.parent,\n\t\t\t\t (dma_addr_t)SWAP32(rbd->b_data),\n\t\t\t\t PKT_BUF_SZ, DMA_FROM_DEVICE);\n\t\tdev_kfree_skb(rbd->skb);\n\t}\n}\n\n\nstatic void rebuild_rx_bufs(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_dma *dma = lp->dma;\n\tint i;\n\n\t \n\n\tfor (i = 0; i < rx_ring_size; i++) {\n\t\tdma->rfds[i].rbd = I596_NULL;\n\t\tdma->rfds[i].cmd = SWAP16(CMD_FLEX);\n\t}\n\tdma->rfds[rx_ring_size-1].cmd = SWAP16(CMD_EOL|CMD_FLEX);\n\tlp->rfd_head = dma->rfds;\n\tdma->scb.rfd = SWAP32(virt_to_dma(lp, dma->rfds));\n\tlp->rbd_head = dma->rbds;\n\tdma->rfds[0].rbd = SWAP32(virt_to_dma(lp, dma->rbds));\n\n\tdma_sync_dev(dev, dma, sizeof(struct i596_dma));\n}\n\n\nstatic int init_i596_mem(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_dma *dma = lp->dma;\n\tunsigned long flags;\n\n\tmpu_port(dev, PORT_RESET, 0);\n\tudelay(100);\t\t\t \n\n\t \n\n\tlp->last_cmd = jiffies;\n\n\tdma->scp.sysbus = SYSBUS;\n\tdma->scp.iscp = SWAP32(virt_to_dma(lp, &(dma->iscp)));\n\tdma->iscp.scb = SWAP32(virt_to_dma(lp, &(dma->scb)));\n\tdma->iscp.stat = SWAP32(ISCP_BUSY);\n\tlp->cmd_backlog = 0;\n\n\tlp->cmd_head = NULL;\n\tdma->scb.cmd = I596_NULL;\n\n\tDEB(DEB_INIT, printk(KERN_DEBUG \"%s: starting i82596.\\n\", dev->name));\n\n\tdma_sync_dev(dev, &(dma->scp), sizeof(struct i596_scp));\n\tdma_sync_dev(dev, &(dma->iscp), sizeof(struct i596_iscp));\n\tdma_sync_dev(dev, &(dma->scb), sizeof(struct i596_scb));\n\n\tmpu_port(dev, PORT_ALTSCP, virt_to_dma(lp, &dma->scp));\n\tca(dev);\n\tif (wait_istat(dev, dma, 1000, \"initialization timed out\"))\n\t\tgoto failed;\n\tDEB(DEB_INIT, printk(KERN_DEBUG\n\t\t\t     \"%s: i82596 initialization successful\\n\",\n\t\t\t     dev->name));\n\n\tif (request_irq(dev->irq, i596_interrupt, 0, \"i82596\", dev)) {\n\t\tprintk(KERN_ERR \"%s: IRQ %d not free\\n\", dev->name, dev->irq);\n\t\tgoto failed;\n\t}\n\n\t \n\trebuild_rx_bufs(dev);\n\n\tdma->scb.command = 0;\n\tdma_sync_dev(dev, &(dma->scb), sizeof(struct i596_scb));\n\n\tDEB(DEB_INIT, printk(KERN_DEBUG\n\t\t\t     \"%s: queuing CmdConfigure\\n\", dev->name));\n\tmemcpy(dma->cf_cmd.i596_config, init_setup, 14);\n\tdma->cf_cmd.cmd.command = SWAP16(CmdConfigure);\n\tdma_sync_dev(dev, &(dma->cf_cmd), sizeof(struct cf_cmd));\n\ti596_add_cmd(dev, &dma->cf_cmd.cmd);\n\n\tDEB(DEB_INIT, printk(KERN_DEBUG \"%s: queuing CmdSASetup\\n\", dev->name));\n\tmemcpy(dma->sa_cmd.eth_addr, dev->dev_addr, ETH_ALEN);\n\tdma->sa_cmd.cmd.command = SWAP16(CmdSASetup);\n\tdma_sync_dev(dev, &(dma->sa_cmd), sizeof(struct sa_cmd));\n\ti596_add_cmd(dev, &dma->sa_cmd.cmd);\n\n\tDEB(DEB_INIT, printk(KERN_DEBUG \"%s: queuing CmdTDR\\n\", dev->name));\n\tdma->tdr_cmd.cmd.command = SWAP16(CmdTDR);\n\tdma_sync_dev(dev, &(dma->tdr_cmd), sizeof(struct tdr_cmd));\n\ti596_add_cmd(dev, &dma->tdr_cmd.cmd);\n\n\tspin_lock_irqsave (&lp->lock, flags);\n\n\tif (wait_cmd(dev, dma, 1000, \"timed out waiting to issue RX_START\")) {\n\t\tspin_unlock_irqrestore (&lp->lock, flags);\n\t\tgoto failed_free_irq;\n\t}\n\tDEB(DEB_INIT, printk(KERN_DEBUG \"%s: Issuing RX_START\\n\", dev->name));\n\tdma->scb.command = SWAP16(RX_START);\n\tdma->scb.rfd = SWAP32(virt_to_dma(lp, dma->rfds));\n\tdma_sync_dev(dev, &(dma->scb), sizeof(struct i596_scb));\n\n\tca(dev);\n\n\tspin_unlock_irqrestore (&lp->lock, flags);\n\tif (wait_cmd(dev, dma, 1000, \"RX_START not processed\"))\n\t\tgoto failed_free_irq;\n\tDEB(DEB_INIT, printk(KERN_DEBUG\n\t\t\t     \"%s: Receive unit started OK\\n\", dev->name));\n\treturn 0;\n\nfailed_free_irq:\n\tfree_irq(dev->irq, dev);\nfailed:\n\tprintk(KERN_ERR \"%s: Failed to initialise 82596\\n\", dev->name);\n\tmpu_port(dev, PORT_RESET, 0);\n\treturn -1;\n}\n\n\nstatic inline int i596_rx(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_rfd *rfd;\n\tstruct i596_rbd *rbd;\n\tint frames = 0;\n\n\tDEB(DEB_RXFRAME, printk(KERN_DEBUG\n\t\t\t\t\"i596_rx(), rfd_head %p, rbd_head %p\\n\",\n\t\t\t\tlp->rfd_head, lp->rbd_head));\n\n\n\trfd = lp->rfd_head;\t\t \n\n\tdma_sync_cpu(dev, rfd, sizeof(struct i596_rfd));\n\twhile (rfd->stat & SWAP16(STAT_C)) {\t \n\t\tif (rfd->rbd == I596_NULL)\n\t\t\trbd = NULL;\n\t\telse if (rfd->rbd == lp->rbd_head->b_addr) {\n\t\t\trbd = lp->rbd_head;\n\t\t\tdma_sync_cpu(dev, rbd, sizeof(struct i596_rbd));\n\t\t} else {\n\t\t\tprintk(KERN_ERR \"%s: rbd chain broken!\\n\", dev->name);\n\t\t\t \n\t\t\trbd = NULL;\n\t\t}\n\t\tDEB(DEB_RXFRAME, printk(KERN_DEBUG\n\t\t\t\t      \"  rfd %p, rfd.rbd %08x, rfd.stat %04x\\n\",\n\t\t\t\t      rfd, rfd->rbd, rfd->stat));\n\n\t\tif (rbd != NULL && (rfd->stat & SWAP16(STAT_OK))) {\n\t\t\t \n\t\t\tint pkt_len = SWAP16(rbd->count) & 0x3fff;\n\t\t\tstruct sk_buff *skb = rbd->skb;\n\t\t\tint rx_in_place = 0;\n\n\t\t\tDEB(DEB_RXADDR, print_eth(rbd->v_data, \"received\"));\n\t\t\tframes++;\n\n\t\t\t \n\n\t\t\tif (pkt_len > rx_copybreak) {\n\t\t\t\tstruct sk_buff *newskb;\n\t\t\t\tdma_addr_t dma_addr;\n\n\t\t\t\tdma_unmap_single(dev->dev.parent,\n\t\t\t\t\t\t (dma_addr_t)SWAP32(rbd->b_data),\n\t\t\t\t\t\t PKT_BUF_SZ, DMA_FROM_DEVICE);\n\t\t\t\t \n\t\t\t\tnewskb = netdev_alloc_skb_ip_align(dev,\n\t\t\t\t\t\t\t\t   PKT_BUF_SZ);\n\t\t\t\tif (newskb == NULL) {\n\t\t\t\t\tskb = NULL;\t \n\t\t\t\t\tgoto memory_squeeze;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tskb_put(skb, pkt_len);\n\t\t\t\trx_in_place = 1;\n\t\t\t\trbd->skb = newskb;\n\t\t\t\tdma_addr = dma_map_single(dev->dev.parent,\n\t\t\t\t\t\t\t  newskb->data,\n\t\t\t\t\t\t\t  PKT_BUF_SZ,\n\t\t\t\t\t\t\t  DMA_FROM_DEVICE);\n\t\t\t\trbd->v_data = newskb->data;\n\t\t\t\trbd->b_data = SWAP32(dma_addr);\n\t\t\t\tdma_sync_dev(dev, rbd, sizeof(struct i596_rbd));\n\t\t\t} else {\n\t\t\t\tskb = netdev_alloc_skb_ip_align(dev, pkt_len);\n\t\t\t}\nmemory_squeeze:\n\t\t\tif (skb == NULL) {\n\t\t\t\t \n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t} else {\n\t\t\t\tif (!rx_in_place) {\n\t\t\t\t\t \n\t\t\t\t\tdma_sync_single_for_cpu(dev->dev.parent,\n\t\t\t\t\t\t\t\t(dma_addr_t)SWAP32(rbd->b_data),\n\t\t\t\t\t\t\t\tPKT_BUF_SZ, DMA_FROM_DEVICE);\n\t\t\t\t\tskb_put_data(skb, rbd->v_data,\n\t\t\t\t\t\t     pkt_len);\n\t\t\t\t\tdma_sync_single_for_device(dev->dev.parent,\n\t\t\t\t\t\t\t\t   (dma_addr_t)SWAP32(rbd->b_data),\n\t\t\t\t\t\t\t\t   PKT_BUF_SZ, DMA_FROM_DEVICE);\n\t\t\t\t}\n\t\t\t\tskb->len = pkt_len;\n\t\t\t\tskb->protocol = eth_type_trans(skb, dev);\n\t\t\t\tnetif_rx(skb);\n\t\t\t\tdev->stats.rx_packets++;\n\t\t\t\tdev->stats.rx_bytes += pkt_len;\n\t\t\t}\n\t\t} else {\n\t\t\tDEB(DEB_ERRORS, printk(KERN_DEBUG\n\t\t\t\t\t       \"%s: Error, rfd.stat = 0x%04x\\n\",\n\t\t\t\t\t       dev->name, rfd->stat));\n\t\t\tdev->stats.rx_errors++;\n\t\t\tif (rfd->stat & SWAP16(0x0100))\n\t\t\t\tdev->stats.collisions++;\n\t\t\tif (rfd->stat & SWAP16(0x8000))\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\tif (rfd->stat & SWAP16(0x0001))\n\t\t\t\tdev->stats.rx_over_errors++;\n\t\t\tif (rfd->stat & SWAP16(0x0002))\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\tif (rfd->stat & SWAP16(0x0004))\n\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\tif (rfd->stat & SWAP16(0x0008))\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tif (rfd->stat & SWAP16(0x0010))\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t}\n\n\t\t \n\n\t\tif (rbd != NULL && (rbd->count & SWAP16(0x4000))) {\n\t\t\trbd->count = 0;\n\t\t\tlp->rbd_head = rbd->v_next;\n\t\t\tdma_sync_dev(dev, rbd, sizeof(struct i596_rbd));\n\t\t}\n\n\t\t \n\n\t\trfd->rbd = I596_NULL;\n\t\trfd->stat = 0;\n\t\trfd->cmd = SWAP16(CMD_EOL|CMD_FLEX);\n\t\trfd->count = 0;\n\n\t\t \n\n\t\tlp->dma->scb.rfd = rfd->b_next;\n\t\tlp->rfd_head = rfd->v_next;\n\t\tdma_sync_dev(dev, rfd, sizeof(struct i596_rfd));\n\n\t\t \n\n\t\trfd->v_prev->cmd = SWAP16(CMD_FLEX);\n\t\tdma_sync_dev(dev, rfd->v_prev, sizeof(struct i596_rfd));\n\t\trfd = lp->rfd_head;\n\t\tdma_sync_cpu(dev, rfd, sizeof(struct i596_rfd));\n\t}\n\n\tDEB(DEB_RXFRAME, printk(KERN_DEBUG \"frames %d\\n\", frames));\n\n\treturn 0;\n}\n\n\nstatic inline void i596_cleanup_cmd(struct net_device *dev, struct i596_private *lp)\n{\n\tstruct i596_cmd *ptr;\n\n\twhile (lp->cmd_head != NULL) {\n\t\tptr = lp->cmd_head;\n\t\tlp->cmd_head = ptr->v_next;\n\t\tlp->cmd_backlog--;\n\n\t\tswitch (SWAP16(ptr->command) & 0x7) {\n\t\tcase CmdTx:\n\t\t\t{\n\t\t\t\tstruct tx_cmd *tx_cmd = (struct tx_cmd *) ptr;\n\t\t\t\tstruct sk_buff *skb = tx_cmd->skb;\n\t\t\t\tdma_unmap_single(dev->dev.parent,\n\t\t\t\t\t\t tx_cmd->dma_addr,\n\t\t\t\t\t\t skb->len, DMA_TO_DEVICE);\n\n\t\t\t\tdev_kfree_skb(skb);\n\n\t\t\t\tdev->stats.tx_errors++;\n\t\t\t\tdev->stats.tx_aborted_errors++;\n\n\t\t\t\tptr->v_next = NULL;\n\t\t\t\tptr->b_next = I596_NULL;\n\t\t\t\ttx_cmd->cmd.command = 0;   \n\t\t\t\tbreak;\n\t\t\t}\n\t\tdefault:\n\t\t\tptr->v_next = NULL;\n\t\t\tptr->b_next = I596_NULL;\n\t\t}\n\t\tdma_sync_dev(dev, ptr, sizeof(struct i596_cmd));\n\t}\n\n\twait_cmd(dev, lp->dma, 100, \"i596_cleanup_cmd timed out\");\n\tlp->dma->scb.cmd = I596_NULL;\n\tdma_sync_dev(dev, &(lp->dma->scb), sizeof(struct i596_scb));\n}\n\n\nstatic inline void i596_reset(struct net_device *dev, struct i596_private *lp)\n{\n\tunsigned long flags;\n\n\tDEB(DEB_RESET, printk(KERN_DEBUG \"i596_reset\\n\"));\n\n\tspin_lock_irqsave (&lp->lock, flags);\n\n\twait_cmd(dev, lp->dma, 100, \"i596_reset timed out\");\n\n\tnetif_stop_queue(dev);\n\n\t \n\tlp->dma->scb.command = SWAP16(CUC_ABORT | RX_ABORT);\n\tdma_sync_dev(dev, &(lp->dma->scb), sizeof(struct i596_scb));\n\tca(dev);\n\n\t \n\twait_cmd(dev, lp->dma, 1000, \"i596_reset 2 timed out\");\n\tspin_unlock_irqrestore (&lp->lock, flags);\n\n\ti596_cleanup_cmd(dev, lp);\n\ti596_rx(dev);\n\n\tnetif_start_queue(dev);\n\tinit_i596_mem(dev);\n}\n\n\nstatic void i596_add_cmd(struct net_device *dev, struct i596_cmd *cmd)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_dma *dma = lp->dma;\n\tunsigned long flags;\n\n\tDEB(DEB_ADDCMD, printk(KERN_DEBUG \"i596_add_cmd cmd_head %p\\n\",\n\t\t\t       lp->cmd_head));\n\n\tcmd->status = 0;\n\tcmd->command |= SWAP16(CMD_EOL | CMD_INTR);\n\tcmd->v_next = NULL;\n\tcmd->b_next = I596_NULL;\n\tdma_sync_dev(dev, cmd, sizeof(struct i596_cmd));\n\n\tspin_lock_irqsave (&lp->lock, flags);\n\n\tif (lp->cmd_head != NULL) {\n\t\tlp->cmd_tail->v_next = cmd;\n\t\tlp->cmd_tail->b_next = SWAP32(virt_to_dma(lp, &cmd->status));\n\t\tdma_sync_dev(dev, lp->cmd_tail, sizeof(struct i596_cmd));\n\t} else {\n\t\tlp->cmd_head = cmd;\n\t\twait_cmd(dev, dma, 100, \"i596_add_cmd timed out\");\n\t\tdma->scb.cmd = SWAP32(virt_to_dma(lp, &cmd->status));\n\t\tdma->scb.command = SWAP16(CUC_START);\n\t\tdma_sync_dev(dev, &(dma->scb), sizeof(struct i596_scb));\n\t\tca(dev);\n\t}\n\tlp->cmd_tail = cmd;\n\tlp->cmd_backlog++;\n\n\tspin_unlock_irqrestore (&lp->lock, flags);\n\n\tif (lp->cmd_backlog > max_cmd_backlog) {\n\t\tunsigned long tickssofar = jiffies - lp->last_cmd;\n\n\t\tif (tickssofar < ticks_limit)\n\t\t\treturn;\n\n\t\tprintk(KERN_ERR\n\t\t       \"%s: command unit timed out, status resetting.\\n\",\n\t\t       dev->name);\n#if 1\n\t\ti596_reset(dev, lp);\n#endif\n\t}\n}\n\nstatic int i596_open(struct net_device *dev)\n{\n\tDEB(DEB_OPEN, printk(KERN_DEBUG\n\t\t\t     \"%s: i596_open() irq %d.\\n\", dev->name, dev->irq));\n\n\tif (init_rx_bufs(dev)) {\n\t\tprintk(KERN_ERR \"%s: Failed to init rx bufs\\n\", dev->name);\n\t\treturn -EAGAIN;\n\t}\n\tif (init_i596_mem(dev)) {\n\t\tprintk(KERN_ERR \"%s: Failed to init memory\\n\", dev->name);\n\t\tgoto out_remove_rx_bufs;\n\t}\n\tnetif_start_queue(dev);\n\n\treturn 0;\n\nout_remove_rx_bufs:\n\tremove_rx_bufs(dev);\n\treturn -EAGAIN;\n}\n\nstatic void i596_tx_timeout (struct net_device *dev, unsigned int txqueue)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\n\t \n\tDEB(DEB_ERRORS, printk(KERN_DEBUG\n\t\t\t       \"%s: transmit timed out, status resetting.\\n\",\n\t\t\t       dev->name));\n\n\tdev->stats.tx_errors++;\n\n\t \n\tif (lp->last_restart == dev->stats.tx_packets) {\n\t\tDEB(DEB_ERRORS, printk(KERN_DEBUG \"Resetting board.\\n\"));\n\t\t \n\t\ti596_reset (dev, lp);\n\t} else {\n\t\t \n\t\tDEB(DEB_ERRORS, printk(KERN_DEBUG \"Kicking board.\\n\"));\n\t\tlp->dma->scb.command = SWAP16(CUC_START | RX_START);\n\t\tdma_sync_dev(dev, &(lp->dma->scb), sizeof(struct i596_scb));\n\t\tca (dev);\n\t\tlp->last_restart = dev->stats.tx_packets;\n\t}\n\n\tnetif_trans_update(dev);  \n\tnetif_wake_queue (dev);\n}\n\n\nstatic netdev_tx_t i596_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct tx_cmd *tx_cmd;\n\tstruct i596_tbd *tbd;\n\tshort length = skb->len;\n\n\tDEB(DEB_STARTTX, printk(KERN_DEBUG\n\t\t\t\t\"%s: i596_start_xmit(%x,%p) called\\n\",\n\t\t\t\tdev->name, skb->len, skb->data));\n\n\tif (length < ETH_ZLEN) {\n\t\tif (skb_padto(skb, ETH_ZLEN))\n\t\t\treturn NETDEV_TX_OK;\n\t\tlength = ETH_ZLEN;\n\t}\n\n\tnetif_stop_queue(dev);\n\n\ttx_cmd = lp->dma->tx_cmds + lp->next_tx_cmd;\n\ttbd = lp->dma->tbds + lp->next_tx_cmd;\n\n\tif (tx_cmd->cmd.command) {\n\t\tDEB(DEB_ERRORS, printk(KERN_DEBUG\n\t\t\t\t       \"%s: xmit ring full, dropping packet.\\n\",\n\t\t\t\t       dev->name));\n\t\tdev->stats.tx_dropped++;\n\n\t\tdev_kfree_skb_any(skb);\n\t} else {\n\t\tif (++lp->next_tx_cmd == TX_RING_SIZE)\n\t\t\tlp->next_tx_cmd = 0;\n\t\ttx_cmd->tbd = SWAP32(virt_to_dma(lp, tbd));\n\t\ttbd->next = I596_NULL;\n\n\t\ttx_cmd->cmd.command = SWAP16(CMD_FLEX | CmdTx);\n\t\ttx_cmd->skb = skb;\n\n\t\ttx_cmd->pad = 0;\n\t\ttx_cmd->size = 0;\n\t\ttbd->pad = 0;\n\t\ttbd->size = SWAP16(EOF | length);\n\n\t\ttx_cmd->dma_addr = dma_map_single(dev->dev.parent, skb->data,\n\t\t\t\t\t\t  skb->len, DMA_TO_DEVICE);\n\t\ttbd->data = SWAP32(tx_cmd->dma_addr);\n\n\t\tDEB(DEB_TXADDR, print_eth(skb->data, \"tx-queued\"));\n\t\tdma_sync_dev(dev, tx_cmd, sizeof(struct tx_cmd));\n\t\tdma_sync_dev(dev, tbd, sizeof(struct i596_tbd));\n\t\ti596_add_cmd(dev, &tx_cmd->cmd);\n\n\t\tdev->stats.tx_packets++;\n\t\tdev->stats.tx_bytes += length;\n\t}\n\n\tnetif_start_queue(dev);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void print_eth(unsigned char *add, char *str)\n{\n\tprintk(KERN_DEBUG \"i596 0x%p, %pM --> %pM %02X%02X, %s\\n\",\n\t       add, add + 6, add, add[12], add[13], str);\n}\nstatic const struct net_device_ops i596_netdev_ops = {\n\t.ndo_open\t\t= i596_open,\n\t.ndo_stop\t\t= i596_close,\n\t.ndo_start_xmit\t\t= i596_start_xmit,\n\t.ndo_set_rx_mode\t= set_multicast_list,\n\t.ndo_tx_timeout\t\t= i596_tx_timeout,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= i596_poll_controller,\n#endif\n};\n\nstatic int i82596_probe(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tint ret;\n\n\t \n\tBUILD_BUG_ON(sizeof(struct i596_rfd) != 32);\n\tBUILD_BUG_ON(sizeof(struct i596_rbd) &  31);\n\tBUILD_BUG_ON(sizeof(struct tx_cmd)   &  31);\n\tBUILD_BUG_ON(sizeof(struct i596_tbd) != 32);\n#ifndef __LP64__\n\tBUILD_BUG_ON(sizeof(struct i596_dma) > 4096);\n#endif\n\n\tif (!dev->base_addr || !dev->irq)\n\t\treturn -ENODEV;\n\n\tdev->netdev_ops = &i596_netdev_ops;\n\tdev->watchdog_timeo = TX_TIMEOUT;\n\n\tmemset(lp->dma, 0, sizeof(struct i596_dma));\n\tlp->dma->scb.command = 0;\n\tlp->dma->scb.cmd = I596_NULL;\n\tlp->dma->scb.rfd = I596_NULL;\n\tspin_lock_init(&lp->lock);\n\n\tdma_sync_dev(dev, lp->dma, sizeof(struct i596_dma));\n\n\tret = register_netdev(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tDEB(DEB_PROBE, printk(KERN_INFO \"%s: 82596 at %#3lx, %pM IRQ %d.\\n\",\n\t\t\t      dev->name, dev->base_addr, dev->dev_addr,\n\t\t\t      dev->irq));\n\tDEB(DEB_INIT, printk(KERN_INFO\n\t\t\t     \"%s: dma at 0x%p (%d bytes), lp->scb at 0x%p\\n\",\n\t\t\t     dev->name, lp->dma, (int)sizeof(struct i596_dma),\n\t\t\t     &lp->dma->scb));\n\n\treturn 0;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void i596_poll_controller(struct net_device *dev)\n{\n\tdisable_irq(dev->irq);\n\ti596_interrupt(dev->irq, dev);\n\tenable_irq(dev->irq);\n}\n#endif\n\nstatic irqreturn_t i596_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *dev = dev_id;\n\tstruct i596_private *lp;\n\tstruct i596_dma *dma;\n\tunsigned short status, ack_cmd = 0;\n\n\tlp = netdev_priv(dev);\n\tdma = lp->dma;\n\n\tspin_lock (&lp->lock);\n\n\twait_cmd(dev, dma, 100, \"i596 interrupt, timeout\");\n\tstatus = SWAP16(dma->scb.status);\n\n\tDEB(DEB_INTS, printk(KERN_DEBUG\n\t\t\t     \"%s: i596 interrupt, IRQ %d, status %4.4x.\\n\",\n\t\t\tdev->name, dev->irq, status));\n\n\tack_cmd = status & 0xf000;\n\n\tif (!ack_cmd) {\n\t\tDEB(DEB_ERRORS, printk(KERN_DEBUG\n\t\t\t\t       \"%s: interrupt with no events\\n\",\n\t\t\t\t       dev->name));\n\t\tspin_unlock (&lp->lock);\n\t\treturn IRQ_NONE;\n\t}\n\n\tif ((status & 0x8000) || (status & 0x2000)) {\n\t\tstruct i596_cmd *ptr;\n\n\t\tif ((status & 0x8000))\n\t\t\tDEB(DEB_INTS,\n\t\t\t    printk(KERN_DEBUG\n\t\t\t\t   \"%s: i596 interrupt completed command.\\n\",\n\t\t\t\t   dev->name));\n\t\tif ((status & 0x2000))\n\t\t\tDEB(DEB_INTS,\n\t\t\t    printk(KERN_DEBUG\n\t\t\t\t   \"%s: i596 interrupt command unit inactive %x.\\n\",\n\t\t\t\t   dev->name, status & 0x0700));\n\n\t\twhile (lp->cmd_head != NULL) {\n\t\t\tdma_sync_cpu(dev, lp->cmd_head, sizeof(struct i596_cmd));\n\t\t\tif (!(lp->cmd_head->status & SWAP16(STAT_C)))\n\t\t\t\tbreak;\n\n\t\t\tptr = lp->cmd_head;\n\n\t\t\tDEB(DEB_STATUS,\n\t\t\t    printk(KERN_DEBUG\n\t\t\t\t   \"cmd_head->status = %04x, ->command = %04x\\n\",\n\t\t\t\t   SWAP16(lp->cmd_head->status),\n\t\t\t\t   SWAP16(lp->cmd_head->command)));\n\t\t\tlp->cmd_head = ptr->v_next;\n\t\t\tlp->cmd_backlog--;\n\n\t\t\tswitch (SWAP16(ptr->command) & 0x7) {\n\t\t\tcase CmdTx:\n\t\t\t    {\n\t\t\t\tstruct tx_cmd *tx_cmd = (struct tx_cmd *) ptr;\n\t\t\t\tstruct sk_buff *skb = tx_cmd->skb;\n\n\t\t\t\tif (ptr->status & SWAP16(STAT_OK)) {\n\t\t\t\t\tDEB(DEB_TXADDR,\n\t\t\t\t\t    print_eth(skb->data, \"tx-done\"));\n\t\t\t\t} else {\n\t\t\t\t\tdev->stats.tx_errors++;\n\t\t\t\t\tif (ptr->status & SWAP16(0x0020))\n\t\t\t\t\t\tdev->stats.collisions++;\n\t\t\t\t\tif (!(ptr->status & SWAP16(0x0040)))\n\t\t\t\t\t\tdev->stats.tx_heartbeat_errors++;\n\t\t\t\t\tif (ptr->status & SWAP16(0x0400))\n\t\t\t\t\t\tdev->stats.tx_carrier_errors++;\n\t\t\t\t\tif (ptr->status & SWAP16(0x0800))\n\t\t\t\t\t\tdev->stats.collisions++;\n\t\t\t\t\tif (ptr->status & SWAP16(0x1000))\n\t\t\t\t\t\tdev->stats.tx_aborted_errors++;\n\t\t\t\t}\n\t\t\t\tdma_unmap_single(dev->dev.parent,\n\t\t\t\t\t\t tx_cmd->dma_addr,\n\t\t\t\t\t\t skb->len, DMA_TO_DEVICE);\n\t\t\t\tdev_consume_skb_irq(skb);\n\n\t\t\t\ttx_cmd->cmd.command = 0;  \n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\tcase CmdTDR:\n\t\t\t    {\n\t\t\t\tunsigned short status = SWAP16(((struct tdr_cmd *)ptr)->status);\n\n\t\t\t\tif (status & 0x8000) {\n\t\t\t\t\tDEB(DEB_ANY,\n\t\t\t\t\t    printk(KERN_DEBUG \"%s: link ok.\\n\",\n\t\t\t\t\t\t   dev->name));\n\t\t\t\t} else {\n\t\t\t\t\tif (status & 0x4000)\n\t\t\t\t\t\tprintk(KERN_ERR\n\t\t\t\t\t\t       \"%s: Transceiver problem.\\n\",\n\t\t\t\t\t\t       dev->name);\n\t\t\t\t\tif (status & 0x2000)\n\t\t\t\t\t\tprintk(KERN_ERR\n\t\t\t\t\t\t       \"%s: Termination problem.\\n\",\n\t\t\t\t\t\t       dev->name);\n\t\t\t\t\tif (status & 0x1000)\n\t\t\t\t\t\tprintk(KERN_ERR\n\t\t\t\t\t\t       \"%s: Short circuit.\\n\",\n\t\t\t\t\t\t       dev->name);\n\n\t\t\t\t\tDEB(DEB_TDR,\n\t\t\t\t\t    printk(KERN_DEBUG \"%s: Time %d.\\n\",\n\t\t\t\t\t\t   dev->name, status & 0x07ff));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t    }\n\t\t\tcase CmdConfigure:\n\t\t\t\t \n\t\t\t\tptr->command = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tptr->v_next = NULL;\n\t\t\tptr->b_next = I596_NULL;\n\t\t\tdma_sync_dev(dev, ptr, sizeof(struct i596_cmd));\n\t\t\tlp->last_cmd = jiffies;\n\t\t}\n\n\t\t \n\t\tptr = lp->cmd_head;\n\t\twhile ((ptr != NULL) && (ptr != lp->cmd_tail)) {\n\t\t\tstruct i596_cmd *prev = ptr;\n\n\t\t\tptr->command &= SWAP16(0x1fff);\n\t\t\tptr = ptr->v_next;\n\t\t\tdma_sync_dev(dev, prev, sizeof(struct i596_cmd));\n\t\t}\n\n\t\tif (lp->cmd_head != NULL)\n\t\t\tack_cmd |= CUC_START;\n\t\tdma->scb.cmd = SWAP32(virt_to_dma(lp, &lp->cmd_head->status));\n\t\tdma_sync_dev(dev, &dma->scb, sizeof(struct i596_scb));\n\t}\n\tif ((status & 0x1000) || (status & 0x4000)) {\n\t\tif ((status & 0x4000))\n\t\t\tDEB(DEB_INTS,\n\t\t\t    printk(KERN_DEBUG\n\t\t\t\t   \"%s: i596 interrupt received a frame.\\n\",\n\t\t\t\t   dev->name));\n\t\ti596_rx(dev);\n\t\t \n\t\tif (status & 0x1000) {\n\t\t\tif (netif_running(dev)) {\n\t\t\t\tDEB(DEB_ERRORS,\n\t\t\t\t    printk(KERN_DEBUG\n\t\t\t\t\t   \"%s: i596 interrupt receive unit inactive, status 0x%x\\n\",\n\t\t\t\t\t   dev->name, status));\n\t\t\t\tack_cmd |= RX_START;\n\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\t\trebuild_rx_bufs(dev);\n\t\t\t}\n\t\t}\n\t}\n\twait_cmd(dev, dma, 100, \"i596 interrupt, timeout\");\n\tdma->scb.command = SWAP16(ack_cmd);\n\tdma_sync_dev(dev, &dma->scb, sizeof(struct i596_scb));\n\n\t \n\n\tca(dev);\n\n\twait_cmd(dev, dma, 100, \"i596 interrupt, exit timeout\");\n\tDEB(DEB_INTS, printk(KERN_DEBUG \"%s: exiting interrupt.\\n\", dev->name));\n\n\tspin_unlock (&lp->lock);\n\treturn IRQ_HANDLED;\n}\n\nstatic int i596_close(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tunsigned long flags;\n\n\tnetif_stop_queue(dev);\n\n\tDEB(DEB_INIT,\n\t    printk(KERN_DEBUG\n\t\t   \"%s: Shutting down ethercard, status was %4.4x.\\n\",\n\t\t   dev->name, SWAP16(lp->dma->scb.status)));\n\n\tspin_lock_irqsave(&lp->lock, flags);\n\n\twait_cmd(dev, lp->dma, 100, \"close1 timed out\");\n\tlp->dma->scb.command = SWAP16(CUC_ABORT | RX_ABORT);\n\tdma_sync_dev(dev, &lp->dma->scb, sizeof(struct i596_scb));\n\n\tca(dev);\n\n\twait_cmd(dev, lp->dma, 100, \"close2 timed out\");\n\tspin_unlock_irqrestore(&lp->lock, flags);\n\tDEB(DEB_STRUCT, i596_display_data(dev));\n\ti596_cleanup_cmd(dev, lp);\n\n\tfree_irq(dev->irq, dev);\n\tremove_rx_bufs(dev);\n\n\treturn 0;\n}\n\n \n\nstatic void set_multicast_list(struct net_device *dev)\n{\n\tstruct i596_private *lp = netdev_priv(dev);\n\tstruct i596_dma *dma = lp->dma;\n\tint config = 0, cnt;\n\n\tDEB(DEB_MULTI,\n\t    printk(KERN_DEBUG\n\t\t   \"%s: set multicast list, %d entries, promisc %s, allmulti %s\\n\",\n\t\t   dev->name, netdev_mc_count(dev),\n\t\t   dev->flags & IFF_PROMISC ? \"ON\" : \"OFF\",\n\t\t   dev->flags & IFF_ALLMULTI ? \"ON\" : \"OFF\"));\n\n\tif ((dev->flags & IFF_PROMISC) &&\n\t    !(dma->cf_cmd.i596_config[8] & 0x01)) {\n\t\tdma->cf_cmd.i596_config[8] |= 0x01;\n\t\tconfig = 1;\n\t}\n\tif (!(dev->flags & IFF_PROMISC) &&\n\t    (dma->cf_cmd.i596_config[8] & 0x01)) {\n\t\tdma->cf_cmd.i596_config[8] &= ~0x01;\n\t\tconfig = 1;\n\t}\n\tif ((dev->flags & IFF_ALLMULTI) &&\n\t    (dma->cf_cmd.i596_config[11] & 0x20)) {\n\t\tdma->cf_cmd.i596_config[11] &= ~0x20;\n\t\tconfig = 1;\n\t}\n\tif (!(dev->flags & IFF_ALLMULTI) &&\n\t    !(dma->cf_cmd.i596_config[11] & 0x20)) {\n\t\tdma->cf_cmd.i596_config[11] |= 0x20;\n\t\tconfig = 1;\n\t}\n\tif (config) {\n\t\tif (dma->cf_cmd.cmd.command)\n\t\t\tprintk(KERN_INFO\n\t\t\t       \"%s: config change request already queued\\n\",\n\t\t\t       dev->name);\n\t\telse {\n\t\t\tdma->cf_cmd.cmd.command = SWAP16(CmdConfigure);\n\t\t\tdma_sync_dev(dev, &dma->cf_cmd, sizeof(struct cf_cmd));\n\t\t\ti596_add_cmd(dev, &dma->cf_cmd.cmd);\n\t\t}\n\t}\n\n\tcnt = netdev_mc_count(dev);\n\tif (cnt > MAX_MC_CNT) {\n\t\tcnt = MAX_MC_CNT;\n\t\tprintk(KERN_NOTICE \"%s: Only %d multicast addresses supported\",\n\t\t\tdev->name, cnt);\n\t}\n\n\tif (!netdev_mc_empty(dev)) {\n\t\tstruct netdev_hw_addr *ha;\n\t\tunsigned char *cp;\n\t\tstruct mc_cmd *cmd;\n\n\t\tcmd = &dma->mc_cmd;\n\t\tcmd->cmd.command = SWAP16(CmdMulticastList);\n\t\tcmd->mc_cnt = SWAP16(netdev_mc_count(dev) * 6);\n\t\tcp = cmd->mc_addrs;\n\t\tnetdev_for_each_mc_addr(ha, dev) {\n\t\t\tif (!cnt--)\n\t\t\t\tbreak;\n\t\t\tmemcpy(cp, ha->addr, ETH_ALEN);\n\t\t\tif (i596_debug > 1)\n\t\t\t\tDEB(DEB_MULTI,\n\t\t\t\t    printk(KERN_DEBUG\n\t\t\t\t\t   \"%s: Adding address %pM\\n\",\n\t\t\t\t\t   dev->name, cp));\n\t\t\tcp += ETH_ALEN;\n\t\t}\n\t\tdma_sync_dev(dev, &dma->mc_cmd, sizeof(struct mc_cmd));\n\t\ti596_add_cmd(dev, &cmd->cmd);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}