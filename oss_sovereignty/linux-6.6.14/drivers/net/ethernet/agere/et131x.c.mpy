{
  "module_name": "et131x.c",
  "hash_id": "54a08e53dab9fcc250e3a2a5938f5b220cb6ecef931e3392c7b6d908bfcb2b8f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/agere/et131x.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/pci.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\n#include <linux/sched.h>\n#include <linux/ptrace.h>\n#include <linux/slab.h>\n#include <linux/ctype.h>\n#include <linux/string.h>\n#include <linux/timer.h>\n#include <linux/interrupt.h>\n#include <linux/in.h>\n#include <linux/delay.h>\n#include <linux/bitops.h>\n#include <linux/io.h>\n\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/if_arp.h>\n#include <linux/ioport.h>\n#include <linux/crc32.h>\n#include <linux/random.h>\n#include <linux/phy.h>\n\n#include \"et131x.h\"\n\nMODULE_AUTHOR(\"Victor Soriano <vjsoriano@agere.com>\");\nMODULE_AUTHOR(\"Mark Einon <mark.einon@gmail.com>\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_DESCRIPTION(\"10/100/1000 Base-T Ethernet Driver for the ET1310 by Agere Systems\");\n\n \n#define MAX_NUM_REGISTER_POLLS          1000\n#define MAX_NUM_WRITE_RETRIES           2\n\n \n#define COUNTER_WRAP_16_BIT 0x10000\n#define COUNTER_WRAP_12_BIT 0x1000\n\n \n#define INTERNAL_MEM_SIZE       0x400\t \n#define INTERNAL_MEM_RX_OFFSET  0x1FF\t \n\n \n \n#define INT_MASK_DISABLE            0xffffffff\n\n \n#define INT_MASK_ENABLE             0xfffebf17\n#define INT_MASK_ENABLE_NO_FLOW     0xfffebfd7\n\n \n \n#define NIC_MIN_PACKET_SIZE\t60\n\n \n#define NIC_MAX_MCAST_LIST\t128\n\n \n#define ET131X_PACKET_TYPE_DIRECTED\t\t0x0001\n#define ET131X_PACKET_TYPE_MULTICAST\t\t0x0002\n#define ET131X_PACKET_TYPE_BROADCAST\t\t0x0004\n#define ET131X_PACKET_TYPE_PROMISCUOUS\t\t0x0008\n#define ET131X_PACKET_TYPE_ALL_MULTICAST\t0x0010\n\n \n#define ET131X_TX_TIMEOUT\t(1 * HZ)\n#define NIC_SEND_HANG_THRESHOLD\t0\n\n \n#define FMP_ADAPTER_INTERRUPT_IN_USE\t0x00000008\n\n \n#define FMP_ADAPTER_LOWER_POWER\t\t0x00200000\n\n#define FMP_ADAPTER_NON_RECOVER_ERROR\t0x00800000\n#define FMP_ADAPTER_HARDWARE_ERROR\t0x04000000\n\n#define FMP_ADAPTER_FAIL_SEND_MASK\t0x3ff00000\n\n \n#define ET1310_PCI_MAC_ADDRESS\t\t0xA4\n#define ET1310_PCI_EEPROM_STATUS\t0xB2\n#define ET1310_PCI_ACK_NACK\t\t0xC0\n#define ET1310_PCI_REPLAY\t\t0xC2\n#define ET1310_PCI_L0L1LATENCY\t\t0xCF\n\n \n#define ET131X_PCI_DEVICE_ID_GIG\t0xED00\t \n#define ET131X_PCI_DEVICE_ID_FAST\t0xED01\t \n\n \n#define NANO_IN_A_MICRO\t1000\n\n#define PARM_RX_NUM_BUFS_DEF    4\n#define PARM_RX_TIME_INT_DEF    10\n#define PARM_RX_MEM_END_DEF     0x2bc\n#define PARM_TX_TIME_INT_DEF    40\n#define PARM_TX_NUM_BUFS_DEF    4\n#define PARM_DMA_CACHE_DEF      0\n\n \n#define FBR_CHUNKS\t\t32\n#define MAX_DESC_PER_RING_RX\t1024\n\n \n#define RFD_LOW_WATER_MARK\t40\n#define NIC_DEFAULT_NUM_RFD\t1024\n#define NUM_FBRS\t\t2\n\n#define MAX_PACKETS_HANDLED\t256\n#define ET131X_MIN_MTU\t\t64\n#define ET131X_MAX_MTU\t\t9216\n\n#define ALCATEL_MULTICAST_PKT\t0x01000000\n#define ALCATEL_BROADCAST_PKT\t0x02000000\n\n \nstruct fbr_desc {\n\tu32 addr_lo;\n\tu32 addr_hi;\n\tu32 word2;\t\t \n};\n\n \nstruct pkt_stat_desc {\n\tu32 word0;\n\tu32 word1;\n};\n\n \n\n \n\n \n\n \nstruct rx_status_block {\n\tu32 word0;\n\tu32 word1;\n};\n\n \nstruct fbr_lookup {\n\tvoid\t\t*virt[MAX_DESC_PER_RING_RX];\n\tu32\t\t bus_high[MAX_DESC_PER_RING_RX];\n\tu32\t\t bus_low[MAX_DESC_PER_RING_RX];\n\tvoid\t\t*ring_virtaddr;\n\tdma_addr_t\t ring_physaddr;\n\tvoid\t\t*mem_virtaddrs[MAX_DESC_PER_RING_RX / FBR_CHUNKS];\n\tdma_addr_t\t mem_physaddrs[MAX_DESC_PER_RING_RX / FBR_CHUNKS];\n\tu32\t\t local_full;\n\tu32\t\t num_entries;\n\tdma_addr_t\t buffsize;\n};\n\n \nstruct rx_ring {\n\tstruct fbr_lookup *fbr[NUM_FBRS];\n\tvoid *ps_ring_virtaddr;\n\tdma_addr_t ps_ring_physaddr;\n\tu32 local_psr_full;\n\tu32 psr_entries;\n\n\tstruct rx_status_block *rx_status_block;\n\tdma_addr_t rx_status_bus;\n\n\tstruct list_head recv_list;\n\tu32 num_ready_recv;\n\n\tu32 num_rfd;\n\n\tbool unfinished_receives;\n};\n\n \n \n#define TXDESC_FLAG_LASTPKT\t\t0x0001\n#define TXDESC_FLAG_FIRSTPKT\t\t0x0002\n#define TXDESC_FLAG_INTPROC\t\t0x0004\n\n \nstruct tx_desc {\n\tu32 addr_hi;\n\tu32 addr_lo;\n\tu32 len_vlan;\t \n\tu32 flags;\t \n};\n\n \n\n \nstruct tcb {\n\tstruct tcb *next;\t \n\tu32 count;\t\t \n\tu32 stale;\t\t \n\tstruct sk_buff *skb;\t \n\tu32 index;\t\t \n\tu32 index_start;\n};\n\n \nstruct tx_ring {\n\t \n\tstruct tcb *tcb_ring;\n\n\t \n\tstruct tcb *tcb_qhead;\n\tstruct tcb *tcb_qtail;\n\n\t \n\tstruct tcb *send_head;\n\tstruct tcb *send_tail;\n\tint used;\n\n\t \n\tstruct tx_desc *tx_desc_ring;\n\tdma_addr_t tx_desc_ring_pa;\n\n\t \n\tu32 send_idx;\n\n\t \n\tu32 *tx_status;\n\tdma_addr_t tx_status_pa;\n\n\t \n\tint since_irq;\n};\n\n \n#define NUM_DESC_PER_RING_TX         512     \n#define NUM_TCB                      64\n\n \n#define TX_ERROR_PERIOD             1000\n\n#define LO_MARK_PERCENT_FOR_PSR     15\n#define LO_MARK_PERCENT_FOR_RX      15\n\n \nstruct rfd {\n\tstruct list_head list_node;\n\tstruct sk_buff *skb;\n\tu32 len;\t \n\tu16 bufferindex;\n\tu8 ringindex;\n};\n\n \n#define FLOW_BOTH\t0\n#define FLOW_TXONLY\t1\n#define FLOW_RXONLY\t2\n#define FLOW_NONE\t3\n\n \nstruct ce_stats {\n\tu32\t\tmulticast_pkts_rcvd;\n\tu32\t\trcvd_pkts_dropped;\n\n\tu32\t\ttx_underflows;\n\tu32\t\ttx_collisions;\n\tu32\t\ttx_excessive_collisions;\n\tu32\t\ttx_first_collisions;\n\tu32\t\ttx_late_collisions;\n\tu32\t\ttx_max_pkt_errs;\n\tu32\t\ttx_deferred;\n\n\tu32\t\trx_overflows;\n\tu32\t\trx_length_errs;\n\tu32\t\trx_align_errs;\n\tu32\t\trx_crc_errs;\n\tu32\t\trx_code_violations;\n\tu32\t\trx_other_errs;\n\n\tu32\t\tinterrupt_status;\n};\n\n \nstruct et131x_adapter {\n\tstruct net_device *netdev;\n\tstruct pci_dev *pdev;\n\tstruct mii_bus *mii_bus;\n\tstruct napi_struct napi;\n\n\t \n\tu32 flags;\n\n\t \n\tint link;\n\n\t \n\tu8 rom_addr[ETH_ALEN];\n\tu8 addr[ETH_ALEN];\n\tbool has_eeprom;\n\tu8 eeprom_data[2];\n\n\tspinlock_t tcb_send_qlock;  \n\tspinlock_t tcb_ready_qlock;  \n\tspinlock_t rcv_lock;  \n\n\t \n\tu32 packet_filter;\n\n\t \n\tu32 multicast_addr_count;\n\tu8 multicast_list[NIC_MAX_MCAST_LIST][ETH_ALEN];\n\n\t \n\tstruct address_map __iomem *regs;\n\n\t \n\tu8 wanted_flow;\t\t \n\tu32 registry_jumbo_packet;\t \n\n\t \n\tu8 flow;\t\t \n\n\t \n\tstruct timer_list error_timer;\n\n\t \n\tu8 boot_coma;\n\n\t \n\tstruct tx_ring tx_ring;\n\n\t \n\tstruct rx_ring rx_ring;\n\n\tstruct ce_stats stats;\n};\n\nstatic int eeprom_wait_ready(struct pci_dev *pdev, u32 *status)\n{\n\tu32 reg;\n\tint i;\n\n\t \n\tfor (i = 0; i < MAX_NUM_REGISTER_POLLS; i++) {\n\t\tif (pci_read_config_dword(pdev, LBCIF_DWORD1_GROUP, &reg))\n\t\t\treturn -EIO;\n\n\t\t \n\t\tif ((reg & 0x3000) == 0x3000) {\n\t\t\tif (status)\n\t\t\t\t*status = reg;\n\t\t\treturn reg & 0xFF;\n\t\t}\n\t}\n\treturn -ETIMEDOUT;\n}\n\nstatic int eeprom_write(struct et131x_adapter *adapter, u32 addr, u8 data)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tint index = 0;\n\tint retries;\n\tint err = 0;\n\tint writeok = 0;\n\tu32 status;\n\tu32 val = 0;\n\n\t \n\terr = eeprom_wait_ready(pdev, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\t  \n\tif (pci_write_config_byte(pdev, LBCIF_CONTROL_REGISTER,\n\t\t\t\t  LBCIF_CONTROL_LBCIF_ENABLE |\n\t\t\t\t\tLBCIF_CONTROL_I2C_WRITE))\n\t\treturn -EIO;\n\n\t \n\tfor (retries = 0; retries < MAX_NUM_WRITE_RETRIES; retries++) {\n\t\tif (pci_write_config_dword(pdev, LBCIF_ADDRESS_REGISTER, addr))\n\t\t\tbreak;\n\t\t \n\t\tif (pci_write_config_byte(pdev, LBCIF_DATA_REGISTER, data))\n\t\t\tbreak;\n\t\t \n\t\terr = eeprom_wait_ready(pdev, &status);\n\t\tif (err < 0)\n\t\t\treturn 0;\n\n\t\t \n\t\tif ((status & LBCIF_STATUS_GENERAL_ERROR) &&\n\t\t    adapter->pdev->revision == 0)\n\t\t\tbreak;\n\n\t\t \n\t\tif (status & LBCIF_STATUS_ACK_ERROR) {\n\t\t\t \n\t\t\tudelay(10);\n\t\t\tcontinue;\n\t\t}\n\n\t\twriteok = 1;\n\t\tbreak;\n\t}\n\n\tudelay(10);\n\n\twhile (1) {\n\t\tif (pci_write_config_byte(pdev, LBCIF_CONTROL_REGISTER,\n\t\t\t\t\t  LBCIF_CONTROL_LBCIF_ENABLE))\n\t\t\twriteok = 0;\n\n\t\t \n\t\tdo {\n\t\t\tpci_write_config_dword(pdev,\n\t\t\t\t\t       LBCIF_ADDRESS_REGISTER,\n\t\t\t\t\t       addr);\n\t\t\tdo {\n\t\t\t\tpci_read_config_dword(pdev,\n\t\t\t\t\t\t      LBCIF_DATA_REGISTER,\n\t\t\t\t\t\t      &val);\n\t\t\t} while ((val & 0x00010000) == 0);\n\t\t} while (val & 0x00040000);\n\n\t\tif ((val & 0xFF00) != 0xC000 || index == 10000)\n\t\t\tbreak;\n\t\tindex++;\n\t}\n\treturn writeok ? 0 : -EIO;\n}\n\nstatic int eeprom_read(struct et131x_adapter *adapter, u32 addr, u8 *pdata)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tint err;\n\tu32 status;\n\n\t \n\terr = eeprom_wait_ready(pdev, NULL);\n\tif (err < 0)\n\t\treturn err;\n\t \n\tif (pci_write_config_byte(pdev, LBCIF_CONTROL_REGISTER,\n\t\t\t\t  LBCIF_CONTROL_LBCIF_ENABLE))\n\t\treturn -EIO;\n\t \n\tif (pci_write_config_dword(pdev, LBCIF_ADDRESS_REGISTER, addr))\n\t\treturn -EIO;\n\t \n\terr = eeprom_wait_ready(pdev, &status);\n\tif (err < 0)\n\t\treturn err;\n\t \n\t*pdata = err;\n\n\treturn (status & LBCIF_STATUS_ACK_ERROR) ? -EIO : 0;\n}\n\nstatic int et131x_init_eeprom(struct et131x_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tu8 eestatus;\n\n\tpci_read_config_byte(pdev, ET1310_PCI_EEPROM_STATUS, &eestatus);\n\n\t \n\tif (pci_read_config_byte(pdev, ET1310_PCI_EEPROM_STATUS, &eestatus)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Could not read PCI config space for EEPROM Status\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (eestatus & 0x4C) {\n\t\tint write_failed = 0;\n\n\t\tif (pdev->revision == 0x01) {\n\t\t\tint\ti;\n\t\t\tstatic const u8 eedata[4] = { 0xFE, 0x13, 0x10, 0xFF };\n\n\t\t\t \n\t\t\tfor (i = 0; i < 3; i++)\n\t\t\t\tif (eeprom_write(adapter, i, eedata[i]) < 0)\n\t\t\t\t\twrite_failed = 1;\n\t\t}\n\t\tif (pdev->revision  != 0x01 || write_failed) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Fatal EEPROM Status Error - 0x%04x\\n\",\n\t\t\t\teestatus);\n\n\t\t\t \n\t\t\tadapter->has_eeprom = false;\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\tadapter->has_eeprom = true;\n\n\t \n\teeprom_read(adapter, 0x70, &adapter->eeprom_data[0]);\n\teeprom_read(adapter, 0x71, &adapter->eeprom_data[1]);\n\n\tif (adapter->eeprom_data[0] != 0xcd)\n\t\t \n\t\tadapter->eeprom_data[1] = 0x00;\n\n\treturn 0;\n}\n\nstatic void et131x_rx_dma_enable(struct et131x_adapter *adapter)\n{\n\t \n\tu32 csr =  ET_RXDMA_CSR_FBR1_ENABLE;\n\tstruct rx_ring *rx_ring = &adapter->rx_ring;\n\n\tif (rx_ring->fbr[1]->buffsize == 4096)\n\t\tcsr |= ET_RXDMA_CSR_FBR1_SIZE_LO;\n\telse if (rx_ring->fbr[1]->buffsize == 8192)\n\t\tcsr |= ET_RXDMA_CSR_FBR1_SIZE_HI;\n\telse if (rx_ring->fbr[1]->buffsize == 16384)\n\t\tcsr |= ET_RXDMA_CSR_FBR1_SIZE_LO | ET_RXDMA_CSR_FBR1_SIZE_HI;\n\n\tcsr |= ET_RXDMA_CSR_FBR0_ENABLE;\n\tif (rx_ring->fbr[0]->buffsize == 256)\n\t\tcsr |= ET_RXDMA_CSR_FBR0_SIZE_LO;\n\telse if (rx_ring->fbr[0]->buffsize == 512)\n\t\tcsr |= ET_RXDMA_CSR_FBR0_SIZE_HI;\n\telse if (rx_ring->fbr[0]->buffsize == 1024)\n\t\tcsr |= ET_RXDMA_CSR_FBR0_SIZE_LO | ET_RXDMA_CSR_FBR0_SIZE_HI;\n\twritel(csr, &adapter->regs->rxdma.csr);\n\n\tcsr = readl(&adapter->regs->rxdma.csr);\n\tif (csr & ET_RXDMA_CSR_HALT_STATUS) {\n\t\tudelay(5);\n\t\tcsr = readl(&adapter->regs->rxdma.csr);\n\t\tif (csr & ET_RXDMA_CSR_HALT_STATUS) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"RX Dma failed to exit halt state. CSR 0x%08x\\n\",\n\t\t\t\tcsr);\n\t\t}\n\t}\n}\n\nstatic void et131x_rx_dma_disable(struct et131x_adapter *adapter)\n{\n\tu32 csr;\n\t \n\twritel(ET_RXDMA_CSR_HALT | ET_RXDMA_CSR_FBR1_ENABLE,\n\t       &adapter->regs->rxdma.csr);\n\tcsr = readl(&adapter->regs->rxdma.csr);\n\tif (!(csr & ET_RXDMA_CSR_HALT_STATUS)) {\n\t\tudelay(5);\n\t\tcsr = readl(&adapter->regs->rxdma.csr);\n\t\tif (!(csr & ET_RXDMA_CSR_HALT_STATUS))\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"RX Dma failed to enter halt state. CSR 0x%08x\\n\",\n\t\t\t\tcsr);\n\t}\n}\n\nstatic void et131x_tx_dma_enable(struct et131x_adapter *adapter)\n{\n\t \n\twritel(ET_TXDMA_SNGL_EPKT | (PARM_DMA_CACHE_DEF << ET_TXDMA_CACHE_SHIFT),\n\t       &adapter->regs->txdma.csr);\n}\n\nstatic inline void add_10bit(u32 *v, int n)\n{\n\t*v = INDEX10(*v + n) | (*v & ET_DMA10_WRAP);\n}\n\nstatic inline void add_12bit(u32 *v, int n)\n{\n\t*v = INDEX12(*v + n) | (*v & ET_DMA12_WRAP);\n}\n\nstatic void et1310_config_mac_regs1(struct et131x_adapter *adapter)\n{\n\tstruct mac_regs __iomem *macregs = &adapter->regs->mac;\n\tu32 station1;\n\tu32 station2;\n\tu32 ipg;\n\n\t \n\twritel(ET_MAC_CFG1_SOFT_RESET | ET_MAC_CFG1_SIM_RESET  |\n\t       ET_MAC_CFG1_RESET_RXMC | ET_MAC_CFG1_RESET_TXMC |\n\t       ET_MAC_CFG1_RESET_RXFUNC | ET_MAC_CFG1_RESET_TXFUNC,\n\t       &macregs->cfg1);\n\n\t \n\tipg = 0x38005860;\t\t \n\tipg |= 0x50 << 8;\t\t \n\twritel(ipg, &macregs->ipg);\n\n\t \n\t \n\twritel(0x00A1F037, &macregs->hfdp);\n\n\t \n\twritel(0, &macregs->if_ctrl);\n\n\twritel(ET_MAC_MIIMGMT_CLK_RST, &macregs->mii_mgmt_cfg);\n\n\t \n\tstation2 = (adapter->addr[1] << ET_MAC_STATION_ADDR2_OC2_SHIFT) |\n\t\t   (adapter->addr[0] << ET_MAC_STATION_ADDR2_OC1_SHIFT);\n\tstation1 = (adapter->addr[5] << ET_MAC_STATION_ADDR1_OC6_SHIFT) |\n\t\t   (adapter->addr[4] << ET_MAC_STATION_ADDR1_OC5_SHIFT) |\n\t\t   (adapter->addr[3] << ET_MAC_STATION_ADDR1_OC4_SHIFT) |\n\t\t    adapter->addr[2];\n\twritel(station1, &macregs->station_addr_1);\n\twritel(station2, &macregs->station_addr_2);\n\n\t \n\twritel(adapter->registry_jumbo_packet + 4, &macregs->max_fm_len);\n\n\t \n\twritel(0, &macregs->cfg1);\n}\n\nstatic void et1310_config_mac_regs2(struct et131x_adapter *adapter)\n{\n\tint32_t delay = 0;\n\tstruct mac_regs __iomem *mac = &adapter->regs->mac;\n\tstruct phy_device *phydev = adapter->netdev->phydev;\n\tu32 cfg1;\n\tu32 cfg2;\n\tu32 ifctrl;\n\tu32 ctl;\n\n\tctl = readl(&adapter->regs->txmac.ctl);\n\tcfg1 = readl(&mac->cfg1);\n\tcfg2 = readl(&mac->cfg2);\n\tifctrl = readl(&mac->if_ctrl);\n\n\t \n\tcfg2 &= ~ET_MAC_CFG2_IFMODE_MASK;\n\tif (phydev->speed == SPEED_1000) {\n\t\tcfg2 |= ET_MAC_CFG2_IFMODE_1000;\n\t\tifctrl &= ~ET_MAC_IFCTRL_PHYMODE;\n\t} else {\n\t\tcfg2 |= ET_MAC_CFG2_IFMODE_100;\n\t\tifctrl |= ET_MAC_IFCTRL_PHYMODE;\n\t}\n\n\tcfg1 |= ET_MAC_CFG1_RX_ENABLE | ET_MAC_CFG1_TX_ENABLE |\n\t\t\t\t\t\t\tET_MAC_CFG1_TX_FLOW;\n\n\tcfg1 &= ~(ET_MAC_CFG1_LOOPBACK | ET_MAC_CFG1_RX_FLOW);\n\tif (adapter->flow == FLOW_RXONLY || adapter->flow == FLOW_BOTH)\n\t\tcfg1 |= ET_MAC_CFG1_RX_FLOW;\n\twritel(cfg1, &mac->cfg1);\n\n\t \n\t \n\tcfg2 |= 0x7 << ET_MAC_CFG2_PREAMBLE_SHIFT;\n\tcfg2 |= ET_MAC_CFG2_IFMODE_LEN_CHECK;\n\tcfg2 |= ET_MAC_CFG2_IFMODE_PAD_CRC;\n\tcfg2 |=\tET_MAC_CFG2_IFMODE_CRC_ENABLE;\n\tcfg2 &= ~ET_MAC_CFG2_IFMODE_HUGE_FRAME;\n\tcfg2 &= ~ET_MAC_CFG2_IFMODE_FULL_DPLX;\n\n\tif (phydev->duplex == DUPLEX_FULL)\n\t\tcfg2 |= ET_MAC_CFG2_IFMODE_FULL_DPLX;\n\n\tifctrl &= ~ET_MAC_IFCTRL_GHDMODE;\n\tif (phydev->duplex == DUPLEX_HALF)\n\t\tifctrl |= ET_MAC_IFCTRL_GHDMODE;\n\n\twritel(ifctrl, &mac->if_ctrl);\n\twritel(cfg2, &mac->cfg2);\n\n\tdo {\n\t\tudelay(10);\n\t\tdelay++;\n\t\tcfg1 = readl(&mac->cfg1);\n\t} while ((cfg1 & ET_MAC_CFG1_WAIT) != ET_MAC_CFG1_WAIT && delay < 100);\n\n\tif (delay == 100) {\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"Syncd bits did not respond correctly cfg1 word 0x%08x\\n\",\n\t\t\t cfg1);\n\t}\n\n\tctl |= ET_TX_CTRL_TXMAC_ENABLE | ET_TX_CTRL_FC_DISABLE;\n\twritel(ctl, &adapter->regs->txmac.ctl);\n\n\tif (adapter->flags & FMP_ADAPTER_LOWER_POWER) {\n\t\tet131x_rx_dma_enable(adapter);\n\t\tet131x_tx_dma_enable(adapter);\n\t}\n}\n\nstatic int et1310_in_phy_coma(struct et131x_adapter *adapter)\n{\n\tu32 pmcsr = readl(&adapter->regs->global.pm_csr);\n\n\treturn ET_PM_PHY_SW_COMA & pmcsr ? 1 : 0;\n}\n\nstatic void et1310_setup_device_for_multicast(struct et131x_adapter *adapter)\n{\n\tstruct rxmac_regs __iomem *rxmac = &adapter->regs->rxmac;\n\tu32 hash1 = 0;\n\tu32 hash2 = 0;\n\tu32 hash3 = 0;\n\tu32 hash4 = 0;\n\n\t \n\tif (adapter->packet_filter & ET131X_PACKET_TYPE_MULTICAST) {\n\t\tint i;\n\n\t\t \n\t\tfor (i = 0; i < adapter->multicast_addr_count; i++) {\n\t\t\tu32 result;\n\n\t\t\tresult = ether_crc(6, adapter->multicast_list[i]);\n\n\t\t\tresult = (result & 0x3F800000) >> 23;\n\n\t\t\tif (result < 32) {\n\t\t\t\thash1 |= (1 << result);\n\t\t\t} else if ((31 < result) && (result < 64)) {\n\t\t\t\tresult -= 32;\n\t\t\t\thash2 |= (1 << result);\n\t\t\t} else if ((63 < result) && (result < 96)) {\n\t\t\t\tresult -= 64;\n\t\t\t\thash3 |= (1 << result);\n\t\t\t} else {\n\t\t\t\tresult -= 96;\n\t\t\t\thash4 |= (1 << result);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (!et1310_in_phy_coma(adapter)) {\n\t\twritel(hash1, &rxmac->multi_hash1);\n\t\twritel(hash2, &rxmac->multi_hash2);\n\t\twritel(hash3, &rxmac->multi_hash3);\n\t\twritel(hash4, &rxmac->multi_hash4);\n\t}\n}\n\nstatic void et1310_setup_device_for_unicast(struct et131x_adapter *adapter)\n{\n\tstruct rxmac_regs __iomem *rxmac = &adapter->regs->rxmac;\n\tu32 uni_pf1;\n\tu32 uni_pf2;\n\tu32 uni_pf3;\n\n\t \n\tuni_pf3 = (adapter->addr[0] << ET_RX_UNI_PF_ADDR2_1_SHIFT) |\n\t\t  (adapter->addr[1] << ET_RX_UNI_PF_ADDR2_2_SHIFT) |\n\t\t  (adapter->addr[0] << ET_RX_UNI_PF_ADDR1_1_SHIFT) |\n\t\t   adapter->addr[1];\n\n\tuni_pf2 = (adapter->addr[2] << ET_RX_UNI_PF_ADDR2_3_SHIFT) |\n\t\t  (adapter->addr[3] << ET_RX_UNI_PF_ADDR2_4_SHIFT) |\n\t\t  (adapter->addr[4] << ET_RX_UNI_PF_ADDR2_5_SHIFT) |\n\t\t   adapter->addr[5];\n\n\tuni_pf1 = (adapter->addr[2] << ET_RX_UNI_PF_ADDR1_3_SHIFT) |\n\t\t  (adapter->addr[3] << ET_RX_UNI_PF_ADDR1_4_SHIFT) |\n\t\t  (adapter->addr[4] << ET_RX_UNI_PF_ADDR1_5_SHIFT) |\n\t\t   adapter->addr[5];\n\n\tif (!et1310_in_phy_coma(adapter)) {\n\t\twritel(uni_pf1, &rxmac->uni_pf_addr1);\n\t\twritel(uni_pf2, &rxmac->uni_pf_addr2);\n\t\twritel(uni_pf3, &rxmac->uni_pf_addr3);\n\t}\n}\n\nstatic void et1310_config_rxmac_regs(struct et131x_adapter *adapter)\n{\n\tstruct rxmac_regs __iomem *rxmac = &adapter->regs->rxmac;\n\tstruct phy_device *phydev = adapter->netdev->phydev;\n\tu32 sa_lo;\n\tu32 sa_hi = 0;\n\tu32 pf_ctrl = 0;\n\tu32 __iomem *wolw;\n\n\t \n\twritel(0x8, &rxmac->ctrl);\n\n\t \n\twritel(0, &rxmac->crc0);\n\twritel(0, &rxmac->crc12);\n\twritel(0, &rxmac->crc34);\n\n\t \n\tfor (wolw = &rxmac->mask0_word0; wolw <= &rxmac->mask4_word3; wolw++)\n\t\twritel(0, wolw);\n\n\t \n\tsa_lo = (adapter->addr[2] << ET_RX_WOL_LO_SA3_SHIFT) |\n\t\t(adapter->addr[3] << ET_RX_WOL_LO_SA4_SHIFT) |\n\t\t(adapter->addr[4] << ET_RX_WOL_LO_SA5_SHIFT) |\n\t\t adapter->addr[5];\n\twritel(sa_lo, &rxmac->sa_lo);\n\n\tsa_hi = (u32)(adapter->addr[0] << ET_RX_WOL_HI_SA1_SHIFT) |\n\t\t       adapter->addr[1];\n\twritel(sa_hi, &rxmac->sa_hi);\n\n\t \n\twritel(0, &rxmac->pf_ctrl);\n\n\t \n\tif (adapter->packet_filter & ET131X_PACKET_TYPE_DIRECTED) {\n\t\tet1310_setup_device_for_unicast(adapter);\n\t\tpf_ctrl |= ET_RX_PFCTRL_UNICST_FILTER_ENABLE;\n\t} else {\n\t\twritel(0, &rxmac->uni_pf_addr1);\n\t\twritel(0, &rxmac->uni_pf_addr2);\n\t\twritel(0, &rxmac->uni_pf_addr3);\n\t}\n\n\t \n\tif (!(adapter->packet_filter & ET131X_PACKET_TYPE_ALL_MULTICAST)) {\n\t\tpf_ctrl |= ET_RX_PFCTRL_MLTCST_FILTER_ENABLE;\n\t\tet1310_setup_device_for_multicast(adapter);\n\t}\n\n\t \n\tpf_ctrl |= (NIC_MIN_PACKET_SIZE + 4) << ET_RX_PFCTRL_MIN_PKT_SZ_SHIFT;\n\tpf_ctrl |= ET_RX_PFCTRL_FRAG_FILTER_ENABLE;\n\n\tif (adapter->registry_jumbo_packet > 8192)\n\t\t \n\t\twritel(0x41, &rxmac->mcif_ctrl_max_seg);\n\telse\n\t\twritel(0, &rxmac->mcif_ctrl_max_seg);\n\n\twritel(0, &rxmac->mcif_water_mark);\n\twritel(0, &rxmac->mif_ctrl);\n\twritel(0, &rxmac->space_avail);\n\n\t \n\tif (phydev && phydev->speed == SPEED_100)\n\t\twritel(0x30038, &rxmac->mif_ctrl);\n\telse\n\t\twritel(0x30030, &rxmac->mif_ctrl);\n\n\t \n\twritel(pf_ctrl, &rxmac->pf_ctrl);\n\twritel(ET_RX_CTRL_RXMAC_ENABLE | ET_RX_CTRL_WOL_DISABLE, &rxmac->ctrl);\n}\n\nstatic void et1310_config_txmac_regs(struct et131x_adapter *adapter)\n{\n\tstruct txmac_regs __iomem *txmac = &adapter->regs->txmac;\n\n\t \n\tif (adapter->flow == FLOW_NONE)\n\t\twritel(0, &txmac->cf_param);\n\telse\n\t\twritel(0x40, &txmac->cf_param);\n}\n\nstatic void et1310_config_macstat_regs(struct et131x_adapter *adapter)\n{\n\tstruct macstat_regs __iomem *macstat = &adapter->regs->macstat;\n\tu32 __iomem *reg;\n\n\t \n\tfor (reg = &macstat->txrx_0_64_byte_frames;\n\t     reg <= &macstat->carry_reg2; reg++)\n\t\twritel(0, reg);\n\n\t \n\twritel(0xFFFFBE32, &macstat->carry_reg1_mask);\n\twritel(0xFFFE7E8B, &macstat->carry_reg2_mask);\n}\n\nstatic int et131x_phy_mii_read(struct et131x_adapter *adapter, u8 addr,\n\t\t\t       u8 reg, u16 *value)\n{\n\tstruct mac_regs __iomem *mac = &adapter->regs->mac;\n\tint status = 0;\n\tu32 delay = 0;\n\tu32 mii_addr;\n\tu32 mii_cmd;\n\tu32 mii_indicator;\n\n\t \n\tmii_addr = readl(&mac->mii_mgmt_addr);\n\tmii_cmd = readl(&mac->mii_mgmt_cmd);\n\n\t \n\twritel(0, &mac->mii_mgmt_cmd);\n\n\t \n\twritel(ET_MAC_MII_ADDR(addr, reg), &mac->mii_mgmt_addr);\n\n\twritel(0x1, &mac->mii_mgmt_cmd);\n\n\tdo {\n\t\tudelay(50);\n\t\tdelay++;\n\t\tmii_indicator = readl(&mac->mii_mgmt_indicator);\n\t} while ((mii_indicator & ET_MAC_MGMT_WAIT) && delay < 50);\n\n\t \n\tif (delay == 50) {\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"reg 0x%08x could not be read\\n\", reg);\n\t\tdev_warn(&adapter->pdev->dev, \"status is  0x%08x\\n\",\n\t\t\t mii_indicator);\n\n\t\tstatus = -EIO;\n\t\tgoto out;\n\t}\n\n\t \n\t*value = readl(&mac->mii_mgmt_stat) & ET_MAC_MIIMGMT_STAT_PHYCRTL_MASK;\n\nout:\n\t \n\twritel(0, &mac->mii_mgmt_cmd);\n\n\t \n\twritel(mii_addr, &mac->mii_mgmt_addr);\n\twritel(mii_cmd, &mac->mii_mgmt_cmd);\n\n\treturn status;\n}\n\nstatic int et131x_mii_read(struct et131x_adapter *adapter, u8 reg, u16 *value)\n{\n\tstruct phy_device *phydev = adapter->netdev->phydev;\n\n\tif (!phydev)\n\t\treturn -EIO;\n\n\treturn et131x_phy_mii_read(adapter, phydev->mdio.addr, reg, value);\n}\n\nstatic int et131x_mii_write(struct et131x_adapter *adapter, u8 addr, u8 reg,\n\t\t\t    u16 value)\n{\n\tstruct mac_regs __iomem *mac = &adapter->regs->mac;\n\tint status = 0;\n\tu32 delay = 0;\n\tu32 mii_addr;\n\tu32 mii_cmd;\n\tu32 mii_indicator;\n\n\t \n\tmii_addr = readl(&mac->mii_mgmt_addr);\n\tmii_cmd = readl(&mac->mii_mgmt_cmd);\n\n\t \n\twritel(0, &mac->mii_mgmt_cmd);\n\n\t \n\twritel(ET_MAC_MII_ADDR(addr, reg), &mac->mii_mgmt_addr);\n\n\t \n\twritel(value, &mac->mii_mgmt_ctrl);\n\n\tdo {\n\t\tudelay(50);\n\t\tdelay++;\n\t\tmii_indicator = readl(&mac->mii_mgmt_indicator);\n\t} while ((mii_indicator & ET_MAC_MGMT_BUSY) && delay < 100);\n\n\t \n\tif (delay == 100) {\n\t\tu16 tmp;\n\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"reg 0x%08x could not be written\", reg);\n\t\tdev_warn(&adapter->pdev->dev, \"status is  0x%08x\\n\",\n\t\t\t mii_indicator);\n\t\tdev_warn(&adapter->pdev->dev, \"command is  0x%08x\\n\",\n\t\t\t readl(&mac->mii_mgmt_cmd));\n\n\t\tet131x_mii_read(adapter, reg, &tmp);\n\n\t\tstatus = -EIO;\n\t}\n\t \n\twritel(0, &mac->mii_mgmt_cmd);\n\n\t \n\twritel(mii_addr, &mac->mii_mgmt_addr);\n\twritel(mii_cmd, &mac->mii_mgmt_cmd);\n\n\treturn status;\n}\n\nstatic void et1310_phy_read_mii_bit(struct et131x_adapter *adapter,\n\t\t\t\t    u16 regnum,\n\t\t\t\t    u16 bitnum,\n\t\t\t\t    u8 *value)\n{\n\tu16 reg;\n\tu16 mask = 1 << bitnum;\n\n\tet131x_mii_read(adapter, regnum, &reg);\n\n\t*value = (reg & mask) >> bitnum;\n}\n\nstatic void et1310_config_flow_control(struct et131x_adapter *adapter)\n{\n\tstruct phy_device *phydev = adapter->netdev->phydev;\n\n\tif (phydev->duplex == DUPLEX_HALF) {\n\t\tadapter->flow = FLOW_NONE;\n\t} else {\n\t\tchar remote_pause, remote_async_pause;\n\n\t\tet1310_phy_read_mii_bit(adapter, 5, 10, &remote_pause);\n\t\tet1310_phy_read_mii_bit(adapter, 5, 11, &remote_async_pause);\n\n\t\tif (remote_pause && remote_async_pause) {\n\t\t\tadapter->flow = adapter->wanted_flow;\n\t\t} else if (remote_pause && !remote_async_pause) {\n\t\t\tif (adapter->wanted_flow == FLOW_BOTH)\n\t\t\t\tadapter->flow = FLOW_BOTH;\n\t\t\telse\n\t\t\t\tadapter->flow = FLOW_NONE;\n\t\t} else if (!remote_pause && !remote_async_pause) {\n\t\t\tadapter->flow = FLOW_NONE;\n\t\t} else {\n\t\t\tif (adapter->wanted_flow == FLOW_BOTH)\n\t\t\t\tadapter->flow = FLOW_RXONLY;\n\t\t\telse\n\t\t\t\tadapter->flow = FLOW_NONE;\n\t\t}\n\t}\n}\n\n \nstatic void et1310_update_macstat_host_counters(struct et131x_adapter *adapter)\n{\n\tstruct ce_stats *stats = &adapter->stats;\n\tstruct macstat_regs __iomem *macstat =\n\t\t&adapter->regs->macstat;\n\n\tstats->tx_collisions\t       += readl(&macstat->tx_total_collisions);\n\tstats->tx_first_collisions     += readl(&macstat->tx_single_collisions);\n\tstats->tx_deferred\t       += readl(&macstat->tx_deferred);\n\tstats->tx_excessive_collisions +=\n\t\t\t\treadl(&macstat->tx_multiple_collisions);\n\tstats->tx_late_collisions      += readl(&macstat->tx_late_collisions);\n\tstats->tx_underflows\t       += readl(&macstat->tx_undersize_frames);\n\tstats->tx_max_pkt_errs\t       += readl(&macstat->tx_oversize_frames);\n\n\tstats->rx_align_errs        += readl(&macstat->rx_align_errs);\n\tstats->rx_crc_errs          += readl(&macstat->rx_code_errs);\n\tstats->rcvd_pkts_dropped    += readl(&macstat->rx_drops);\n\tstats->rx_overflows         += readl(&macstat->rx_oversize_packets);\n\tstats->rx_code_violations   += readl(&macstat->rx_fcs_errs);\n\tstats->rx_length_errs       += readl(&macstat->rx_frame_len_errs);\n\tstats->rx_other_errs        += readl(&macstat->rx_fragment_packets);\n}\n\n \nstatic void et1310_handle_macstat_interrupt(struct et131x_adapter *adapter)\n{\n\tu32 carry_reg1;\n\tu32 carry_reg2;\n\n\t \n\tcarry_reg1 = readl(&adapter->regs->macstat.carry_reg1);\n\tcarry_reg2 = readl(&adapter->regs->macstat.carry_reg2);\n\n\twritel(carry_reg1, &adapter->regs->macstat.carry_reg1);\n\twritel(carry_reg2, &adapter->regs->macstat.carry_reg2);\n\n\t \n\tif (carry_reg1 & (1 << 14))\n\t\tadapter->stats.rx_code_violations\t+= COUNTER_WRAP_16_BIT;\n\tif (carry_reg1 & (1 << 8))\n\t\tadapter->stats.rx_align_errs\t+= COUNTER_WRAP_12_BIT;\n\tif (carry_reg1 & (1 << 7))\n\t\tadapter->stats.rx_length_errs\t+= COUNTER_WRAP_16_BIT;\n\tif (carry_reg1 & (1 << 2))\n\t\tadapter->stats.rx_other_errs\t+= COUNTER_WRAP_16_BIT;\n\tif (carry_reg1 & (1 << 6))\n\t\tadapter->stats.rx_crc_errs\t+= COUNTER_WRAP_16_BIT;\n\tif (carry_reg1 & (1 << 3))\n\t\tadapter->stats.rx_overflows\t+= COUNTER_WRAP_16_BIT;\n\tif (carry_reg1 & (1 << 0))\n\t\tadapter->stats.rcvd_pkts_dropped\t+= COUNTER_WRAP_16_BIT;\n\tif (carry_reg2 & (1 << 16))\n\t\tadapter->stats.tx_max_pkt_errs\t+= COUNTER_WRAP_12_BIT;\n\tif (carry_reg2 & (1 << 15))\n\t\tadapter->stats.tx_underflows\t+= COUNTER_WRAP_12_BIT;\n\tif (carry_reg2 & (1 << 6))\n\t\tadapter->stats.tx_first_collisions += COUNTER_WRAP_12_BIT;\n\tif (carry_reg2 & (1 << 8))\n\t\tadapter->stats.tx_deferred\t+= COUNTER_WRAP_12_BIT;\n\tif (carry_reg2 & (1 << 5))\n\t\tadapter->stats.tx_excessive_collisions += COUNTER_WRAP_12_BIT;\n\tif (carry_reg2 & (1 << 4))\n\t\tadapter->stats.tx_late_collisions\t+= COUNTER_WRAP_12_BIT;\n\tif (carry_reg2 & (1 << 2))\n\t\tadapter->stats.tx_collisions\t+= COUNTER_WRAP_12_BIT;\n}\n\nstatic int et131x_mdio_read(struct mii_bus *bus, int phy_addr, int reg)\n{\n\tstruct net_device *netdev = bus->priv;\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tu16 value;\n\tint ret;\n\n\tret = et131x_phy_mii_read(adapter, phy_addr, reg, &value);\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn value;\n}\n\nstatic int et131x_mdio_write(struct mii_bus *bus, int phy_addr,\n\t\t\t     int reg, u16 value)\n{\n\tstruct net_device *netdev = bus->priv;\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\n\treturn et131x_mii_write(adapter, phy_addr, reg, value);\n}\n\n \nstatic void et1310_phy_power_switch(struct et131x_adapter *adapter, bool down)\n{\n\tu16 data;\n\tstruct  phy_device *phydev = adapter->netdev->phydev;\n\n\tet131x_mii_read(adapter, MII_BMCR, &data);\n\tdata &= ~BMCR_PDOWN;\n\tif (down)\n\t\tdata |= BMCR_PDOWN;\n\tet131x_mii_write(adapter, phydev->mdio.addr, MII_BMCR, data);\n}\n\n \nstatic void et131x_xcvr_init(struct et131x_adapter *adapter)\n{\n\tu16 lcr2;\n\tstruct  phy_device *phydev = adapter->netdev->phydev;\n\n\t \n\tif ((adapter->eeprom_data[1] & 0x4) == 0) {\n\t\tet131x_mii_read(adapter, PHY_LED_2, &lcr2);\n\n\t\tlcr2 &= (ET_LED2_LED_100TX | ET_LED2_LED_1000T);\n\t\tlcr2 |= (LED_VAL_LINKON_ACTIVE << LED_LINK_SHIFT);\n\n\t\tif ((adapter->eeprom_data[1] & 0x8) == 0)\n\t\t\tlcr2 |= (LED_VAL_1000BT_100BTX << LED_TXRX_SHIFT);\n\t\telse\n\t\t\tlcr2 |= (LED_VAL_LINKON << LED_TXRX_SHIFT);\n\n\t\tet131x_mii_write(adapter, phydev->mdio.addr, PHY_LED_2, lcr2);\n\t}\n}\n\n \nstatic void et131x_configure_global_regs(struct et131x_adapter *adapter)\n{\n\tstruct global_regs __iomem *regs = &adapter->regs->global;\n\n\twritel(0, &regs->rxq_start_addr);\n\twritel(INTERNAL_MEM_SIZE - 1, &regs->txq_end_addr);\n\n\tif (adapter->registry_jumbo_packet < 2048) {\n\t\t \n\t\twritel(PARM_RX_MEM_END_DEF, &regs->rxq_end_addr);\n\t\twritel(PARM_RX_MEM_END_DEF + 1, &regs->txq_start_addr);\n\t} else if (adapter->registry_jumbo_packet < 8192) {\n\t\t \n\t\twritel(INTERNAL_MEM_RX_OFFSET, &regs->rxq_end_addr);\n\t\twritel(INTERNAL_MEM_RX_OFFSET + 1, &regs->txq_start_addr);\n\t} else {\n\t\t \n\t\twritel(0x01b3, &regs->rxq_end_addr);\n\t\twritel(0x01b4, &regs->txq_start_addr);\n\t}\n\n\t \n\twritel(0, &regs->loopback);\n\n\twritel(0, &regs->msi_config);\n\n\t \n\twritel(0, &regs->watchdog_timer);\n}\n\n \nstatic void et131x_config_rx_dma_regs(struct et131x_adapter *adapter)\n{\n\tstruct rxdma_regs __iomem *rx_dma = &adapter->regs->rxdma;\n\tstruct rx_ring *rx_local = &adapter->rx_ring;\n\tstruct fbr_desc *fbr_entry;\n\tu32 entry;\n\tu32 psr_num_des;\n\tunsigned long flags;\n\tu8 id;\n\n\tet131x_rx_dma_disable(adapter);\n\n\t \n\twritel(upper_32_bits(rx_local->rx_status_bus), &rx_dma->dma_wb_base_hi);\n\twritel(lower_32_bits(rx_local->rx_status_bus), &rx_dma->dma_wb_base_lo);\n\n\tmemset(rx_local->rx_status_block, 0, sizeof(struct rx_status_block));\n\n\t \n\twritel(upper_32_bits(rx_local->ps_ring_physaddr), &rx_dma->psr_base_hi);\n\twritel(lower_32_bits(rx_local->ps_ring_physaddr), &rx_dma->psr_base_lo);\n\twritel(rx_local->psr_entries - 1, &rx_dma->psr_num_des);\n\twritel(0, &rx_dma->psr_full_offset);\n\n\tpsr_num_des = readl(&rx_dma->psr_num_des) & ET_RXDMA_PSR_NUM_DES_MASK;\n\twritel((psr_num_des * LO_MARK_PERCENT_FOR_PSR) / 100,\n\t       &rx_dma->psr_min_des);\n\n\tspin_lock_irqsave(&adapter->rcv_lock, flags);\n\n\t \n\trx_local->local_psr_full = 0;\n\n\tfor (id = 0; id < NUM_FBRS; id++) {\n\t\tu32 __iomem *num_des;\n\t\tu32 __iomem *full_offset;\n\t\tu32 __iomem *min_des;\n\t\tu32 __iomem *base_hi;\n\t\tu32 __iomem *base_lo;\n\t\tstruct fbr_lookup *fbr = rx_local->fbr[id];\n\n\t\tif (id == 0) {\n\t\t\tnum_des = &rx_dma->fbr0_num_des;\n\t\t\tfull_offset = &rx_dma->fbr0_full_offset;\n\t\t\tmin_des = &rx_dma->fbr0_min_des;\n\t\t\tbase_hi = &rx_dma->fbr0_base_hi;\n\t\t\tbase_lo = &rx_dma->fbr0_base_lo;\n\t\t} else {\n\t\t\tnum_des = &rx_dma->fbr1_num_des;\n\t\t\tfull_offset = &rx_dma->fbr1_full_offset;\n\t\t\tmin_des = &rx_dma->fbr1_min_des;\n\t\t\tbase_hi = &rx_dma->fbr1_base_hi;\n\t\t\tbase_lo = &rx_dma->fbr1_base_lo;\n\t\t}\n\n\t\t \n\t\tfbr_entry = fbr->ring_virtaddr;\n\t\tfor (entry = 0; entry < fbr->num_entries; entry++) {\n\t\t\tfbr_entry->addr_hi = fbr->bus_high[entry];\n\t\t\tfbr_entry->addr_lo = fbr->bus_low[entry];\n\t\t\tfbr_entry->word2 = entry;\n\t\t\tfbr_entry++;\n\t\t}\n\n\t\t \n\t\twritel(upper_32_bits(fbr->ring_physaddr), base_hi);\n\t\twritel(lower_32_bits(fbr->ring_physaddr), base_lo);\n\t\twritel(fbr->num_entries - 1, num_des);\n\t\twritel(ET_DMA10_WRAP, full_offset);\n\n\t\t \n\t\tfbr->local_full = ET_DMA10_WRAP;\n\t\twritel(((fbr->num_entries * LO_MARK_PERCENT_FOR_RX) / 100) - 1,\n\t\t       min_des);\n\t}\n\n\t \n\twritel(PARM_RX_NUM_BUFS_DEF, &rx_dma->num_pkt_done);\n\n\t \n\twritel(PARM_RX_TIME_INT_DEF, &rx_dma->max_pkt_time);\n\n\tspin_unlock_irqrestore(&adapter->rcv_lock, flags);\n}\n\n \nstatic void et131x_config_tx_dma_regs(struct et131x_adapter *adapter)\n{\n\tstruct txdma_regs __iomem *txdma = &adapter->regs->txdma;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\t \n\twritel(upper_32_bits(tx_ring->tx_desc_ring_pa), &txdma->pr_base_hi);\n\twritel(lower_32_bits(tx_ring->tx_desc_ring_pa), &txdma->pr_base_lo);\n\n\t \n\twritel(NUM_DESC_PER_RING_TX - 1, &txdma->pr_num_des);\n\n\t \n\twritel(upper_32_bits(tx_ring->tx_status_pa), &txdma->dma_wb_base_hi);\n\twritel(lower_32_bits(tx_ring->tx_status_pa), &txdma->dma_wb_base_lo);\n\n\t*tx_ring->tx_status = 0;\n\n\twritel(0, &txdma->service_request);\n\ttx_ring->send_idx = 0;\n}\n\n \nstatic void et131x_adapter_setup(struct et131x_adapter *adapter)\n{\n\tet131x_configure_global_regs(adapter);\n\tet1310_config_mac_regs1(adapter);\n\n\t \n\t \n\twritel(ET_MMC_ENABLE, &adapter->regs->mmc.mmc_ctrl);\n\n\tet1310_config_rxmac_regs(adapter);\n\tet1310_config_txmac_regs(adapter);\n\n\tet131x_config_rx_dma_regs(adapter);\n\tet131x_config_tx_dma_regs(adapter);\n\n\tet1310_config_macstat_regs(adapter);\n\n\tet1310_phy_power_switch(adapter, 0);\n\tet131x_xcvr_init(adapter);\n}\n\n \nstatic void et131x_soft_reset(struct et131x_adapter *adapter)\n{\n\tu32 reg;\n\n\t \n\treg = ET_MAC_CFG1_SOFT_RESET | ET_MAC_CFG1_SIM_RESET |\n\t      ET_MAC_CFG1_RESET_RXMC | ET_MAC_CFG1_RESET_TXMC |\n\t      ET_MAC_CFG1_RESET_RXFUNC | ET_MAC_CFG1_RESET_TXFUNC;\n\twritel(reg, &adapter->regs->mac.cfg1);\n\n\treg = ET_RESET_ALL;\n\twritel(reg, &adapter->regs->global.sw_reset);\n\n\treg = ET_MAC_CFG1_RESET_RXMC | ET_MAC_CFG1_RESET_TXMC |\n\t      ET_MAC_CFG1_RESET_RXFUNC | ET_MAC_CFG1_RESET_TXFUNC;\n\twritel(reg, &adapter->regs->mac.cfg1);\n\twritel(0, &adapter->regs->mac.cfg1);\n}\n\nstatic void et131x_enable_interrupts(struct et131x_adapter *adapter)\n{\n\tu32 mask;\n\n\tif (adapter->flow == FLOW_TXONLY || adapter->flow == FLOW_BOTH)\n\t\tmask = INT_MASK_ENABLE;\n\telse\n\t\tmask = INT_MASK_ENABLE_NO_FLOW;\n\n\twritel(mask, &adapter->regs->global.int_mask);\n}\n\nstatic void et131x_disable_interrupts(struct et131x_adapter *adapter)\n{\n\twritel(INT_MASK_DISABLE, &adapter->regs->global.int_mask);\n}\n\nstatic void et131x_tx_dma_disable(struct et131x_adapter *adapter)\n{\n\t \n\twritel(ET_TXDMA_CSR_HALT | ET_TXDMA_SNGL_EPKT,\n\t       &adapter->regs->txdma.csr);\n}\n\nstatic void et131x_enable_txrx(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\n\tet131x_rx_dma_enable(adapter);\n\tet131x_tx_dma_enable(adapter);\n\n\tif (adapter->flags & FMP_ADAPTER_INTERRUPT_IN_USE)\n\t\tet131x_enable_interrupts(adapter);\n\n\tnetif_start_queue(netdev);\n}\n\nstatic void et131x_disable_txrx(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\n\tnetif_stop_queue(netdev);\n\n\tet131x_rx_dma_disable(adapter);\n\tet131x_tx_dma_disable(adapter);\n\n\tet131x_disable_interrupts(adapter);\n}\n\nstatic void et131x_init_send(struct et131x_adapter *adapter)\n{\n\tint i;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\tstruct tcb *tcb = tx_ring->tcb_ring;\n\n\ttx_ring->tcb_qhead = tcb;\n\n\tmemset(tcb, 0, sizeof(struct tcb) * NUM_TCB);\n\n\tfor (i = 0; i < NUM_TCB; i++) {\n\t\ttcb->next = tcb + 1;\n\t\ttcb++;\n\t}\n\n\ttcb--;\n\ttx_ring->tcb_qtail = tcb;\n\ttcb->next = NULL;\n\t \n\ttx_ring->send_head = NULL;\n\ttx_ring->send_tail = NULL;\n}\n\n \nstatic void et1310_enable_phy_coma(struct et131x_adapter *adapter)\n{\n\tu32 pmcsr = readl(&adapter->regs->global.pm_csr);\n\n\t \n\tadapter->flags |= FMP_ADAPTER_LOWER_POWER;\n\n\t \n\tet131x_disable_txrx(adapter->netdev);\n\n\t \n\tpmcsr &= ~ET_PMCSR_INIT;\n\twritel(pmcsr, &adapter->regs->global.pm_csr);\n\n\t \n\tpmcsr |= ET_PM_PHY_SW_COMA;\n\twritel(pmcsr, &adapter->regs->global.pm_csr);\n}\n\nstatic void et1310_disable_phy_coma(struct et131x_adapter *adapter)\n{\n\tu32 pmcsr;\n\n\tpmcsr = readl(&adapter->regs->global.pm_csr);\n\n\t \n\tpmcsr |= ET_PMCSR_INIT;\n\tpmcsr &= ~ET_PM_PHY_SW_COMA;\n\twritel(pmcsr, &adapter->regs->global.pm_csr);\n\n\t \n\n\t \n\tet131x_init_send(adapter);\n\n\t \n\tet131x_soft_reset(adapter);\n\n\tet131x_adapter_setup(adapter);\n\n\t \n\tadapter->flags &= ~FMP_ADAPTER_LOWER_POWER;\n\n\tet131x_enable_txrx(adapter->netdev);\n}\n\nstatic inline u32 bump_free_buff_ring(u32 *free_buff_ring, u32 limit)\n{\n\tu32 tmp_free_buff_ring = *free_buff_ring;\n\n\ttmp_free_buff_ring++;\n\t \n\tif ((tmp_free_buff_ring & ET_DMA10_MASK) > limit) {\n\t\ttmp_free_buff_ring &= ~ET_DMA10_MASK;\n\t\ttmp_free_buff_ring ^= ET_DMA10_WRAP;\n\t}\n\t \n\ttmp_free_buff_ring &= (ET_DMA10_MASK | ET_DMA10_WRAP);\n\t*free_buff_ring = tmp_free_buff_ring;\n\treturn tmp_free_buff_ring;\n}\n\n \nstatic int et131x_rx_dma_memory_alloc(struct et131x_adapter *adapter)\n{\n\tu8 id;\n\tu32 i, j;\n\tu32 bufsize;\n\tu32 psr_size;\n\tu32 fbr_chunksize;\n\tstruct rx_ring *rx_ring = &adapter->rx_ring;\n\tstruct fbr_lookup *fbr;\n\n\t \n\trx_ring->fbr[0] = kzalloc(sizeof(*fbr), GFP_KERNEL);\n\tif (rx_ring->fbr[0] == NULL)\n\t\treturn -ENOMEM;\n\trx_ring->fbr[1] = kzalloc(sizeof(*fbr), GFP_KERNEL);\n\tif (rx_ring->fbr[1] == NULL)\n\t\treturn -ENOMEM;\n\n\t \n\tif (adapter->registry_jumbo_packet < 2048) {\n\t\trx_ring->fbr[0]->buffsize = 256;\n\t\trx_ring->fbr[0]->num_entries = 512;\n\t\trx_ring->fbr[1]->buffsize = 2048;\n\t\trx_ring->fbr[1]->num_entries = 512;\n\t} else if (adapter->registry_jumbo_packet < 4096) {\n\t\trx_ring->fbr[0]->buffsize = 512;\n\t\trx_ring->fbr[0]->num_entries = 1024;\n\t\trx_ring->fbr[1]->buffsize = 4096;\n\t\trx_ring->fbr[1]->num_entries = 512;\n\t} else {\n\t\trx_ring->fbr[0]->buffsize = 1024;\n\t\trx_ring->fbr[0]->num_entries = 768;\n\t\trx_ring->fbr[1]->buffsize = 16384;\n\t\trx_ring->fbr[1]->num_entries = 128;\n\t}\n\n\trx_ring->psr_entries = rx_ring->fbr[0]->num_entries +\n\t\t\t       rx_ring->fbr[1]->num_entries;\n\n\tfor (id = 0; id < NUM_FBRS; id++) {\n\t\tfbr = rx_ring->fbr[id];\n\t\t \n\t\tbufsize = sizeof(struct fbr_desc) * fbr->num_entries;\n\t\tfbr->ring_virtaddr = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t\t\tbufsize,\n\t\t\t\t\t\t\t&fbr->ring_physaddr,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (!fbr->ring_virtaddr) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Cannot alloc memory for Free Buffer Ring %d\\n\",\n\t\t\t\tid);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (id = 0; id < NUM_FBRS; id++) {\n\t\tfbr = rx_ring->fbr[id];\n\t\tfbr_chunksize = (FBR_CHUNKS * fbr->buffsize);\n\n\t\tfor (i = 0; i < fbr->num_entries / FBR_CHUNKS; i++) {\n\t\t\tdma_addr_t fbr_physaddr;\n\n\t\t\tfbr->mem_virtaddrs[i] = dma_alloc_coherent(\n\t\t\t\t\t&adapter->pdev->dev, fbr_chunksize,\n\t\t\t\t\t&fbr->mem_physaddrs[i],\n\t\t\t\t\tGFP_KERNEL);\n\n\t\t\tif (!fbr->mem_virtaddrs[i]) {\n\t\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\t\"Could not alloc memory\\n\");\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\t \n\t\t\tfbr_physaddr = fbr->mem_physaddrs[i];\n\n\t\t\tfor (j = 0; j < FBR_CHUNKS; j++) {\n\t\t\t\tu32 k = (i * FBR_CHUNKS) + j;\n\n\t\t\t\t \n\t\t\t\tfbr->virt[k] = (u8 *)fbr->mem_virtaddrs[i] +\n\t\t\t\t\t\t   (j * fbr->buffsize);\n\n\t\t\t\t \n\t\t\t\tfbr->bus_high[k] = upper_32_bits(fbr_physaddr);\n\t\t\t\tfbr->bus_low[k] = lower_32_bits(fbr_physaddr);\n\t\t\t\tfbr_physaddr += fbr->buffsize;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tpsr_size = sizeof(struct pkt_stat_desc) * rx_ring->psr_entries;\n\n\trx_ring->ps_ring_virtaddr = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t\t  psr_size,\n\t\t\t\t\t\t  &rx_ring->ps_ring_physaddr,\n\t\t\t\t\t\t  GFP_KERNEL);\n\n\tif (!rx_ring->ps_ring_virtaddr) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot alloc memory for Packet Status Ring\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\trx_ring->rx_status_block = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t    sizeof(struct rx_status_block),\n\t\t\t\t\t    &rx_ring->rx_status_bus,\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!rx_ring->rx_status_block) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot alloc memory for Status Block\\n\");\n\t\treturn -ENOMEM;\n\t}\n\trx_ring->num_rfd = NIC_DEFAULT_NUM_RFD;\n\n\t \n\tINIT_LIST_HEAD(&rx_ring->recv_list);\n\treturn 0;\n}\n\nstatic void et131x_rx_dma_memory_free(struct et131x_adapter *adapter)\n{\n\tu8 id;\n\tu32 ii;\n\tu32 bufsize;\n\tu32 psr_size;\n\tstruct rfd *rfd;\n\tstruct rx_ring *rx_ring = &adapter->rx_ring;\n\tstruct fbr_lookup *fbr;\n\n\t \n\tWARN_ON(rx_ring->num_ready_recv != rx_ring->num_rfd);\n\n\twhile (!list_empty(&rx_ring->recv_list)) {\n\t\trfd = list_entry(rx_ring->recv_list.next,\n\t\t\t\t struct rfd, list_node);\n\n\t\tlist_del(&rfd->list_node);\n\t\trfd->skb = NULL;\n\t\tkfree(rfd);\n\t}\n\n\t \n\tfor (id = 0; id < NUM_FBRS; id++) {\n\t\tfbr = rx_ring->fbr[id];\n\n\t\tif (!fbr || !fbr->ring_virtaddr)\n\t\t\tcontinue;\n\n\t\t \n\t\tfor (ii = 0; ii < fbr->num_entries / FBR_CHUNKS; ii++) {\n\t\t\tif (fbr->mem_virtaddrs[ii]) {\n\t\t\t\tbufsize = fbr->buffsize * FBR_CHUNKS;\n\n\t\t\t\tdma_free_coherent(&adapter->pdev->dev,\n\t\t\t\t\t\t  bufsize,\n\t\t\t\t\t\t  fbr->mem_virtaddrs[ii],\n\t\t\t\t\t\t  fbr->mem_physaddrs[ii]);\n\n\t\t\t\tfbr->mem_virtaddrs[ii] = NULL;\n\t\t\t}\n\t\t}\n\n\t\tbufsize = sizeof(struct fbr_desc) * fbr->num_entries;\n\n\t\tdma_free_coherent(&adapter->pdev->dev,\n\t\t\t\t  bufsize,\n\t\t\t\t  fbr->ring_virtaddr,\n\t\t\t\t  fbr->ring_physaddr);\n\n\t\tfbr->ring_virtaddr = NULL;\n\t}\n\n\t \n\tif (rx_ring->ps_ring_virtaddr) {\n\t\tpsr_size = sizeof(struct pkt_stat_desc) * rx_ring->psr_entries;\n\n\t\tdma_free_coherent(&adapter->pdev->dev, psr_size,\n\t\t\t\t  rx_ring->ps_ring_virtaddr,\n\t\t\t\t  rx_ring->ps_ring_physaddr);\n\n\t\trx_ring->ps_ring_virtaddr = NULL;\n\t}\n\n\t \n\tif (rx_ring->rx_status_block) {\n\t\tdma_free_coherent(&adapter->pdev->dev,\n\t\t\t\t  sizeof(struct rx_status_block),\n\t\t\t\t  rx_ring->rx_status_block,\n\t\t\t\t  rx_ring->rx_status_bus);\n\t\trx_ring->rx_status_block = NULL;\n\t}\n\n\t \n\tkfree(rx_ring->fbr[0]);\n\tkfree(rx_ring->fbr[1]);\n\n\t \n\trx_ring->num_ready_recv = 0;\n}\n\n \nstatic int et131x_init_recv(struct et131x_adapter *adapter)\n{\n\tstruct rfd *rfd;\n\tu32 rfdct;\n\tstruct rx_ring *rx_ring = &adapter->rx_ring;\n\n\t \n\tfor (rfdct = 0; rfdct < rx_ring->num_rfd; rfdct++) {\n\t\trfd = kzalloc(sizeof(*rfd), GFP_ATOMIC | GFP_DMA);\n\t\tif (!rfd)\n\t\t\treturn -ENOMEM;\n\n\t\trfd->skb = NULL;\n\n\t\t \n\t\tlist_add_tail(&rfd->list_node, &rx_ring->recv_list);\n\n\t\t \n\t\trx_ring->num_ready_recv++;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void et131x_set_rx_dma_timer(struct et131x_adapter *adapter)\n{\n\tstruct phy_device *phydev = adapter->netdev->phydev;\n\n\t \n\tif ((phydev->speed == SPEED_100) || (phydev->speed == SPEED_10)) {\n\t\twritel(0, &adapter->regs->rxdma.max_pkt_time);\n\t\twritel(1, &adapter->regs->rxdma.num_pkt_done);\n\t}\n}\n\n \nstatic void nic_return_rfd(struct et131x_adapter *adapter, struct rfd *rfd)\n{\n\tstruct rx_ring *rx_local = &adapter->rx_ring;\n\tstruct rxdma_regs __iomem *rx_dma = &adapter->regs->rxdma;\n\tu16 buff_index = rfd->bufferindex;\n\tu8 ring_index = rfd->ringindex;\n\tunsigned long flags;\n\tstruct fbr_lookup *fbr = rx_local->fbr[ring_index];\n\n\t \n\tif (buff_index < fbr->num_entries) {\n\t\tu32 free_buff_ring;\n\t\tu32 __iomem *offset;\n\t\tstruct fbr_desc *next;\n\n\t\tif (ring_index == 0)\n\t\t\toffset = &rx_dma->fbr0_full_offset;\n\t\telse\n\t\t\toffset = &rx_dma->fbr1_full_offset;\n\n\t\tnext = (struct fbr_desc *)(fbr->ring_virtaddr) +\n\t\t       INDEX10(fbr->local_full);\n\n\t\t \n\t\tnext->addr_hi = fbr->bus_high[buff_index];\n\t\tnext->addr_lo = fbr->bus_low[buff_index];\n\t\tnext->word2 = buff_index;\n\n\t\tfree_buff_ring = bump_free_buff_ring(&fbr->local_full,\n\t\t\t\t\t\t     fbr->num_entries - 1);\n\t\twritel(free_buff_ring, offset);\n\t} else {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"%s illegal Buffer Index returned\\n\", __func__);\n\t}\n\n\t \n\tspin_lock_irqsave(&adapter->rcv_lock, flags);\n\tlist_add_tail(&rfd->list_node, &rx_local->recv_list);\n\trx_local->num_ready_recv++;\n\tspin_unlock_irqrestore(&adapter->rcv_lock, flags);\n\n\tWARN_ON(rx_local->num_ready_recv > rx_local->num_rfd);\n}\n\n \nstatic struct rfd *nic_rx_pkts(struct et131x_adapter *adapter)\n{\n\tstruct rx_ring *rx_local = &adapter->rx_ring;\n\tstruct rx_status_block *status;\n\tstruct pkt_stat_desc *psr;\n\tstruct rfd *rfd;\n\tunsigned long flags;\n\tstruct list_head *element;\n\tu8 ring_index;\n\tu16 buff_index;\n\tu32 len;\n\tu32 word0;\n\tu32 word1;\n\tstruct sk_buff *skb;\n\tstruct fbr_lookup *fbr;\n\n\t \n\tstatus = rx_local->rx_status_block;\n\tword1 = status->word1 >> 16;\n\n\t \n\tif ((word1 & 0x1FFF) == (rx_local->local_psr_full & 0x1FFF))\n\t\treturn NULL;  \n\n\t \n\tpsr = (struct pkt_stat_desc *)(rx_local->ps_ring_virtaddr) +\n\t\t\t(rx_local->local_psr_full & 0xFFF);\n\n\t \n\tlen = psr->word1 & 0xFFFF;\n\tring_index = (psr->word1 >> 26) & 0x03;\n\tfbr = rx_local->fbr[ring_index];\n\tbuff_index = (psr->word1 >> 16) & 0x3FF;\n\tword0 = psr->word0;\n\n\t \n\t \n\tadd_12bit(&rx_local->local_psr_full, 1);\n\tif ((rx_local->local_psr_full & 0xFFF) > rx_local->psr_entries - 1) {\n\t\t \n\t\trx_local->local_psr_full &=  ~0xFFF;\n\t\trx_local->local_psr_full ^= 0x1000;\n\t}\n\n\twritel(rx_local->local_psr_full, &adapter->regs->rxdma.psr_full_offset);\n\n\tif (ring_index > 1 || buff_index > fbr->num_entries - 1) {\n\t\t \n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"NICRxPkts PSR Entry %d indicates length of %d and/or bad bi(%d)\\n\",\n\t\t\trx_local->local_psr_full & 0xFFF, len, buff_index);\n\t\treturn NULL;\n\t}\n\n\t \n\tspin_lock_irqsave(&adapter->rcv_lock, flags);\n\n\telement = rx_local->recv_list.next;\n\trfd = list_entry(element, struct rfd, list_node);\n\n\tif (!rfd) {\n\t\tspin_unlock_irqrestore(&adapter->rcv_lock, flags);\n\t\treturn NULL;\n\t}\n\n\tlist_del(&rfd->list_node);\n\trx_local->num_ready_recv--;\n\n\tspin_unlock_irqrestore(&adapter->rcv_lock, flags);\n\n\trfd->bufferindex = buff_index;\n\trfd->ringindex = ring_index;\n\n\t \n\tif (len < (NIC_MIN_PACKET_SIZE + 4)) {\n\t\tadapter->stats.rx_other_errs++;\n\t\trfd->len = 0;\n\t\tgoto out;\n\t}\n\n\tif ((word0 & ALCATEL_MULTICAST_PKT) && !(word0 & ALCATEL_BROADCAST_PKT))\n\t\tadapter->stats.multicast_pkts_rcvd++;\n\n\trfd->len = len;\n\n\tskb = dev_alloc_skb(rfd->len + 2);\n\tif (!skb)\n\t\treturn NULL;\n\n\tadapter->netdev->stats.rx_bytes += rfd->len;\n\n\tskb_put_data(skb, fbr->virt[buff_index], rfd->len);\n\n\tskb->protocol = eth_type_trans(skb, adapter->netdev);\n\tskb->ip_summed = CHECKSUM_NONE;\n\tnetif_receive_skb(skb);\n\nout:\n\tnic_return_rfd(adapter, rfd);\n\treturn rfd;\n}\n\nstatic int et131x_handle_recv_pkts(struct et131x_adapter *adapter, int budget)\n{\n\tstruct rfd *rfd = NULL;\n\tint count = 0;\n\tint limit = budget;\n\tbool done = true;\n\tstruct rx_ring *rx_ring = &adapter->rx_ring;\n\n\tif (budget > MAX_PACKETS_HANDLED)\n\t\tlimit = MAX_PACKETS_HANDLED;\n\n\t \n\twhile (count < limit) {\n\t\tif (list_empty(&rx_ring->recv_list)) {\n\t\t\tWARN_ON(rx_ring->num_ready_recv != 0);\n\t\t\tdone = false;\n\t\t\tbreak;\n\t\t}\n\n\t\trfd = nic_rx_pkts(adapter);\n\n\t\tif (rfd == NULL)\n\t\t\tbreak;\n\n\t\t \n\t\tif (!adapter->packet_filter ||\n\t\t    !netif_carrier_ok(adapter->netdev) ||\n\t\t    rfd->len == 0)\n\t\t\tcontinue;\n\n\t\tadapter->netdev->stats.rx_packets++;\n\n\t\tif (rx_ring->num_ready_recv < RFD_LOW_WATER_MARK)\n\t\t\tdev_warn(&adapter->pdev->dev, \"RFD's are running out\\n\");\n\n\t\tcount++;\n\t}\n\n\tif (count == limit || !done) {\n\t\trx_ring->unfinished_receives = true;\n\t\twritel(PARM_TX_TIME_INT_DEF * NANO_IN_A_MICRO,\n\t\t       &adapter->regs->global.watchdog_timer);\n\t} else {\n\t\t \n\t\trx_ring->unfinished_receives = false;\n\t}\n\n\treturn count;\n}\n\n \nstatic int et131x_tx_dma_memory_alloc(struct et131x_adapter *adapter)\n{\n\tint desc_size = 0;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\t \n\ttx_ring->tcb_ring = kcalloc(NUM_TCB, sizeof(struct tcb),\n\t\t\t\t    GFP_KERNEL | GFP_DMA);\n\tif (!tx_ring->tcb_ring)\n\t\treturn -ENOMEM;\n\n\tdesc_size = (sizeof(struct tx_desc) * NUM_DESC_PER_RING_TX);\n\ttx_ring->tx_desc_ring = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t\t   desc_size,\n\t\t\t\t\t\t   &tx_ring->tx_desc_ring_pa,\n\t\t\t\t\t\t   GFP_KERNEL);\n\tif (!tx_ring->tx_desc_ring) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot alloc memory for Tx Ring\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\ttx_ring->tx_status = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t\t    sizeof(u32),\n\t\t\t\t\t\t    &tx_ring->tx_status_pa,\n\t\t\t\t\t\t    GFP_KERNEL);\n\tif (!tx_ring->tx_status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot alloc memory for Tx status block\\n\");\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nstatic void et131x_tx_dma_memory_free(struct et131x_adapter *adapter)\n{\n\tint desc_size = 0;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\tif (tx_ring->tx_desc_ring) {\n\t\t \n\t\tdesc_size = (sizeof(struct tx_desc) * NUM_DESC_PER_RING_TX);\n\t\tdma_free_coherent(&adapter->pdev->dev,\n\t\t\t\t  desc_size,\n\t\t\t\t  tx_ring->tx_desc_ring,\n\t\t\t\t  tx_ring->tx_desc_ring_pa);\n\t\ttx_ring->tx_desc_ring = NULL;\n\t}\n\n\t \n\tif (tx_ring->tx_status) {\n\t\tdma_free_coherent(&adapter->pdev->dev,\n\t\t\t\t  sizeof(u32),\n\t\t\t\t  tx_ring->tx_status,\n\t\t\t\t  tx_ring->tx_status_pa);\n\n\t\ttx_ring->tx_status = NULL;\n\t}\n\t \n\tkfree(tx_ring->tcb_ring);\n}\n\n#define MAX_TX_DESC_PER_PKT 24\n\n \nstatic int nic_send_packet(struct et131x_adapter *adapter, struct tcb *tcb)\n{\n\tu32 i;\n\tstruct tx_desc desc[MAX_TX_DESC_PER_PKT];\n\tu32 frag = 0;\n\tu32 thiscopy, remainder;\n\tstruct sk_buff *skb = tcb->skb;\n\tu32 nr_frags = skb_shinfo(skb)->nr_frags + 1;\n\tskb_frag_t *frags = &skb_shinfo(skb)->frags[0];\n\tstruct phy_device *phydev = adapter->netdev->phydev;\n\tdma_addr_t dma_addr;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\t \n\n\tmemset(desc, 0, sizeof(struct tx_desc) * (nr_frags + 1));\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\t \n\t\tif (i == 0) {\n\t\t\t \n\t\t\tif (skb_headlen(skb) <= 1514) {\n\t\t\t\t \n\t\t\t\tdesc[frag].len_vlan = skb_headlen(skb);\n\t\t\t\tdma_addr = dma_map_single(&adapter->pdev->dev,\n\t\t\t\t\t\t\t  skb->data,\n\t\t\t\t\t\t\t  skb_headlen(skb),\n\t\t\t\t\t\t\t  DMA_TO_DEVICE);\n\t\t\t\tdesc[frag].addr_lo = lower_32_bits(dma_addr);\n\t\t\t\tdesc[frag].addr_hi = upper_32_bits(dma_addr);\n\t\t\t\tfrag++;\n\t\t\t} else {\n\t\t\t\tdesc[frag].len_vlan = skb_headlen(skb) / 2;\n\t\t\t\tdma_addr = dma_map_single(&adapter->pdev->dev,\n\t\t\t\t\t\t\t  skb->data,\n\t\t\t\t\t\t\t  skb_headlen(skb) / 2,\n\t\t\t\t\t\t\t  DMA_TO_DEVICE);\n\t\t\t\tdesc[frag].addr_lo = lower_32_bits(dma_addr);\n\t\t\t\tdesc[frag].addr_hi = upper_32_bits(dma_addr);\n\t\t\t\tfrag++;\n\n\t\t\t\tdesc[frag].len_vlan = skb_headlen(skb) / 2;\n\t\t\t\tdma_addr = dma_map_single(&adapter->pdev->dev,\n\t\t\t\t\t\t\t  skb->data +\n\t\t\t\t\t\t\t  skb_headlen(skb) / 2,\n\t\t\t\t\t\t\t  skb_headlen(skb) / 2,\n\t\t\t\t\t\t\t  DMA_TO_DEVICE);\n\t\t\t\tdesc[frag].addr_lo = lower_32_bits(dma_addr);\n\t\t\t\tdesc[frag].addr_hi = upper_32_bits(dma_addr);\n\t\t\t\tfrag++;\n\t\t\t}\n\t\t} else {\n\t\t\tdesc[frag].len_vlan = skb_frag_size(&frags[i - 1]);\n\t\t\tdma_addr = skb_frag_dma_map(&adapter->pdev->dev,\n\t\t\t\t\t\t    &frags[i - 1],\n\t\t\t\t\t\t    0,\n\t\t\t\t\t\t    desc[frag].len_vlan,\n\t\t\t\t\t\t    DMA_TO_DEVICE);\n\t\t\tdesc[frag].addr_lo = lower_32_bits(dma_addr);\n\t\t\tdesc[frag].addr_hi = upper_32_bits(dma_addr);\n\t\t\tfrag++;\n\t\t}\n\t}\n\n\tif (phydev && phydev->speed == SPEED_1000) {\n\t\tif (++tx_ring->since_irq == PARM_TX_NUM_BUFS_DEF) {\n\t\t\t \n\t\t\tdesc[frag - 1].flags =\n\t\t\t\t    TXDESC_FLAG_INTPROC | TXDESC_FLAG_LASTPKT;\n\t\t\ttx_ring->since_irq = 0;\n\t\t} else {  \n\t\t\tdesc[frag - 1].flags = TXDESC_FLAG_LASTPKT;\n\t\t}\n\t} else {\n\t\tdesc[frag - 1].flags =\n\t\t\t\t    TXDESC_FLAG_INTPROC | TXDESC_FLAG_LASTPKT;\n\t}\n\n\tdesc[0].flags |= TXDESC_FLAG_FIRSTPKT;\n\n\ttcb->index_start = tx_ring->send_idx;\n\ttcb->stale = 0;\n\n\tthiscopy = NUM_DESC_PER_RING_TX - INDEX10(tx_ring->send_idx);\n\n\tif (thiscopy >= frag) {\n\t\tremainder = 0;\n\t\tthiscopy = frag;\n\t} else {\n\t\tremainder = frag - thiscopy;\n\t}\n\n\tmemcpy(tx_ring->tx_desc_ring + INDEX10(tx_ring->send_idx),\n\t       desc,\n\t       sizeof(struct tx_desc) * thiscopy);\n\n\tadd_10bit(&tx_ring->send_idx, thiscopy);\n\n\tif (INDEX10(tx_ring->send_idx) == 0 ||\n\t    INDEX10(tx_ring->send_idx) == NUM_DESC_PER_RING_TX) {\n\t\ttx_ring->send_idx &= ~ET_DMA10_MASK;\n\t\ttx_ring->send_idx ^= ET_DMA10_WRAP;\n\t}\n\n\tif (remainder) {\n\t\tmemcpy(tx_ring->tx_desc_ring,\n\t\t       desc + thiscopy,\n\t\t       sizeof(struct tx_desc) * remainder);\n\n\t\tadd_10bit(&tx_ring->send_idx, remainder);\n\t}\n\n\tif (INDEX10(tx_ring->send_idx) == 0) {\n\t\tif (tx_ring->send_idx)\n\t\t\ttcb->index = NUM_DESC_PER_RING_TX - 1;\n\t\telse\n\t\t\ttcb->index = ET_DMA10_WRAP|(NUM_DESC_PER_RING_TX - 1);\n\t} else {\n\t\ttcb->index = tx_ring->send_idx - 1;\n\t}\n\n\tspin_lock(&adapter->tcb_send_qlock);\n\n\tif (tx_ring->send_tail)\n\t\ttx_ring->send_tail->next = tcb;\n\telse\n\t\ttx_ring->send_head = tcb;\n\n\ttx_ring->send_tail = tcb;\n\n\tWARN_ON(tcb->next != NULL);\n\n\ttx_ring->used++;\n\n\tspin_unlock(&adapter->tcb_send_qlock);\n\n\t \n\twritel(tx_ring->send_idx, &adapter->regs->txdma.service_request);\n\n\t \n\tif (phydev && phydev->speed == SPEED_1000) {\n\t\twritel(PARM_TX_TIME_INT_DEF * NANO_IN_A_MICRO,\n\t\t       &adapter->regs->global.watchdog_timer);\n\t}\n\treturn 0;\n}\n\nstatic int send_packet(struct sk_buff *skb, struct et131x_adapter *adapter)\n{\n\tint status;\n\tstruct tcb *tcb;\n\tunsigned long flags;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\t \n\tif (skb->len < ETH_HLEN)\n\t\treturn -EIO;\n\n\tspin_lock_irqsave(&adapter->tcb_ready_qlock, flags);\n\n\ttcb = tx_ring->tcb_qhead;\n\n\tif (tcb == NULL) {\n\t\tspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\n\t\treturn -ENOMEM;\n\t}\n\n\ttx_ring->tcb_qhead = tcb->next;\n\n\tif (tx_ring->tcb_qhead == NULL)\n\t\ttx_ring->tcb_qtail = NULL;\n\n\tspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\n\n\ttcb->skb = skb;\n\ttcb->next = NULL;\n\n\tstatus = nic_send_packet(adapter, tcb);\n\n\tif (status != 0) {\n\t\tspin_lock_irqsave(&adapter->tcb_ready_qlock, flags);\n\n\t\tif (tx_ring->tcb_qtail)\n\t\t\ttx_ring->tcb_qtail->next = tcb;\n\t\telse\n\t\t\t \n\t\t\ttx_ring->tcb_qhead = tcb;\n\n\t\ttx_ring->tcb_qtail = tcb;\n\t\tspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\n\t\treturn status;\n\t}\n\tWARN_ON(tx_ring->used > NUM_TCB);\n\treturn 0;\n}\n\n \nstatic inline void free_send_packet(struct et131x_adapter *adapter,\n\t\t\t\t    struct tcb *tcb)\n{\n\tunsigned long flags;\n\tstruct tx_desc *desc = NULL;\n\tstruct net_device_stats *stats = &adapter->netdev->stats;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\tu64  dma_addr;\n\n\tif (tcb->skb) {\n\t\tstats->tx_bytes += tcb->skb->len;\n\n\t\t \n\t\tdo {\n\t\t\tdesc = tx_ring->tx_desc_ring +\n\t\t\t       INDEX10(tcb->index_start);\n\n\t\t\tdma_addr = desc->addr_lo;\n\t\t\tdma_addr |= (u64)desc->addr_hi << 32;\n\n\t\t\tdma_unmap_single(&adapter->pdev->dev,\n\t\t\t\t\t dma_addr,\n\t\t\t\t\t desc->len_vlan, DMA_TO_DEVICE);\n\n\t\t\tadd_10bit(&tcb->index_start, 1);\n\t\t\tif (INDEX10(tcb->index_start) >=\n\t\t\t\t\t\t\tNUM_DESC_PER_RING_TX) {\n\t\t\t\ttcb->index_start &= ~ET_DMA10_MASK;\n\t\t\t\ttcb->index_start ^= ET_DMA10_WRAP;\n\t\t\t}\n\t\t} while (desc != tx_ring->tx_desc_ring + INDEX10(tcb->index));\n\n\t\tdev_kfree_skb_any(tcb->skb);\n\t}\n\n\tmemset(tcb, 0, sizeof(struct tcb));\n\n\t \n\tspin_lock_irqsave(&adapter->tcb_ready_qlock, flags);\n\n\tstats->tx_packets++;\n\n\tif (tx_ring->tcb_qtail)\n\t\ttx_ring->tcb_qtail->next = tcb;\n\telse  \n\t\ttx_ring->tcb_qhead = tcb;\n\n\ttx_ring->tcb_qtail = tcb;\n\n\tspin_unlock_irqrestore(&adapter->tcb_ready_qlock, flags);\n\tWARN_ON(tx_ring->used < 0);\n}\n\n \nstatic void et131x_free_busy_send_packets(struct et131x_adapter *adapter)\n{\n\tstruct tcb *tcb;\n\tunsigned long flags;\n\tu32 freed = 0;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\t \n\tspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\n\n\ttcb = tx_ring->send_head;\n\n\twhile (tcb != NULL && freed < NUM_TCB) {\n\t\tstruct tcb *next = tcb->next;\n\n\t\ttx_ring->send_head = next;\n\n\t\tif (next == NULL)\n\t\t\ttx_ring->send_tail = NULL;\n\n\t\ttx_ring->used--;\n\n\t\tspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\n\n\t\tfreed++;\n\t\tfree_send_packet(adapter, tcb);\n\n\t\tspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\n\n\t\ttcb = tx_ring->send_head;\n\t}\n\n\tWARN_ON(freed == NUM_TCB);\n\n\tspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\n\n\ttx_ring->used = 0;\n}\n\n \nstatic void et131x_handle_send_pkts(struct et131x_adapter *adapter)\n{\n\tunsigned long flags;\n\tu32 serviced;\n\tstruct tcb *tcb;\n\tu32 index;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\tserviced = readl(&adapter->regs->txdma.new_service_complete);\n\tindex = INDEX10(serviced);\n\n\t \n\tspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\n\n\ttcb = tx_ring->send_head;\n\n\twhile (tcb &&\n\t       ((serviced ^ tcb->index) & ET_DMA10_WRAP) &&\n\t       index < INDEX10(tcb->index)) {\n\t\ttx_ring->used--;\n\t\ttx_ring->send_head = tcb->next;\n\t\tif (tcb->next == NULL)\n\t\t\ttx_ring->send_tail = NULL;\n\n\t\tspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\n\t\tfree_send_packet(adapter, tcb);\n\t\tspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\n\n\t\t \n\t\ttcb = tx_ring->send_head;\n\t}\n\twhile (tcb &&\n\t       !((serviced ^ tcb->index) & ET_DMA10_WRAP) &&\n\t       index > (tcb->index & ET_DMA10_MASK)) {\n\t\ttx_ring->used--;\n\t\ttx_ring->send_head = tcb->next;\n\t\tif (tcb->next == NULL)\n\t\t\ttx_ring->send_tail = NULL;\n\n\t\tspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\n\t\tfree_send_packet(adapter, tcb);\n\t\tspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\n\n\t\t \n\t\ttcb = tx_ring->send_head;\n\t}\n\n\t \n\tif (tx_ring->used <= NUM_TCB / 3)\n\t\tnetif_wake_queue(adapter->netdev);\n\n\tspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\n}\n\nstatic int et131x_get_regs_len(struct net_device *netdev)\n{\n#define ET131X_REGS_LEN 256\n\treturn ET131X_REGS_LEN * sizeof(u32);\n}\n\nstatic void et131x_get_regs(struct net_device *netdev,\n\t\t\t    struct ethtool_regs *regs, void *regs_data)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct address_map __iomem *aregs = adapter->regs;\n\tu32 *regs_buff = regs_data;\n\tu32 num = 0;\n\tu16 tmp;\n\n\tmemset(regs_data, 0, et131x_get_regs_len(netdev));\n\n\tregs->version = (1 << 24) | (adapter->pdev->revision << 16) |\n\t\t\tadapter->pdev->device;\n\n\t \n\tet131x_mii_read(adapter, MII_BMCR, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_BMSR, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_PHYSID1, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_PHYSID2, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_ADVERTISE, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_LPA, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_EXPANSION, &tmp);\n\tregs_buff[num++] = tmp;\n\t \n\tet131x_mii_read(adapter, 0x07, &tmp);\n\tregs_buff[num++] = tmp;\n\t \n\tet131x_mii_read(adapter, 0x08, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_CTRL1000, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_STAT1000, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, 0x0b, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, 0x0c, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_MMD_CTRL, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_MMD_DATA, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, MII_ESTATUS, &tmp);\n\tregs_buff[num++] = tmp;\n\n\tet131x_mii_read(adapter, PHY_INDEX_REG, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_DATA_REG, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_MPHY_CONTROL_REG, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_LOOPBACK_CONTROL, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_LOOPBACK_CONTROL + 1, &tmp);\n\tregs_buff[num++] = tmp;\n\n\tet131x_mii_read(adapter, PHY_REGISTER_MGMT_CONTROL, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_CONFIG, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_PHY_CONTROL, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_INTERRUPT_MASK, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_INTERRUPT_STATUS, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_PHY_STATUS, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_LED_1, &tmp);\n\tregs_buff[num++] = tmp;\n\tet131x_mii_read(adapter, PHY_LED_2, &tmp);\n\tregs_buff[num++] = tmp;\n\n\t \n\tregs_buff[num++] = readl(&aregs->global.txq_start_addr);\n\tregs_buff[num++] = readl(&aregs->global.txq_end_addr);\n\tregs_buff[num++] = readl(&aregs->global.rxq_start_addr);\n\tregs_buff[num++] = readl(&aregs->global.rxq_end_addr);\n\tregs_buff[num++] = readl(&aregs->global.pm_csr);\n\tregs_buff[num++] = adapter->stats.interrupt_status;\n\tregs_buff[num++] = readl(&aregs->global.int_mask);\n\tregs_buff[num++] = readl(&aregs->global.int_alias_clr_en);\n\tregs_buff[num++] = readl(&aregs->global.int_status_alias);\n\tregs_buff[num++] = readl(&aregs->global.sw_reset);\n\tregs_buff[num++] = readl(&aregs->global.slv_timer);\n\tregs_buff[num++] = readl(&aregs->global.msi_config);\n\tregs_buff[num++] = readl(&aregs->global.loopback);\n\tregs_buff[num++] = readl(&aregs->global.watchdog_timer);\n\n\t \n\tregs_buff[num++] = readl(&aregs->txdma.csr);\n\tregs_buff[num++] = readl(&aregs->txdma.pr_base_hi);\n\tregs_buff[num++] = readl(&aregs->txdma.pr_base_lo);\n\tregs_buff[num++] = readl(&aregs->txdma.pr_num_des);\n\tregs_buff[num++] = readl(&aregs->txdma.txq_wr_addr);\n\tregs_buff[num++] = readl(&aregs->txdma.txq_wr_addr_ext);\n\tregs_buff[num++] = readl(&aregs->txdma.txq_rd_addr);\n\tregs_buff[num++] = readl(&aregs->txdma.dma_wb_base_hi);\n\tregs_buff[num++] = readl(&aregs->txdma.dma_wb_base_lo);\n\tregs_buff[num++] = readl(&aregs->txdma.service_request);\n\tregs_buff[num++] = readl(&aregs->txdma.service_complete);\n\tregs_buff[num++] = readl(&aregs->txdma.cache_rd_index);\n\tregs_buff[num++] = readl(&aregs->txdma.cache_wr_index);\n\tregs_buff[num++] = readl(&aregs->txdma.tx_dma_error);\n\tregs_buff[num++] = readl(&aregs->txdma.desc_abort_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.payload_abort_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.writeback_abort_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.desc_timeout_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.payload_timeout_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.writeback_timeout_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.desc_error_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.payload_error_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.writeback_error_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.dropped_tlp_cnt);\n\tregs_buff[num++] = readl(&aregs->txdma.new_service_complete);\n\tregs_buff[num++] = readl(&aregs->txdma.ethernet_packet_cnt);\n\n\t \n\tregs_buff[num++] = readl(&aregs->rxdma.csr);\n\tregs_buff[num++] = readl(&aregs->rxdma.dma_wb_base_hi);\n\tregs_buff[num++] = readl(&aregs->rxdma.dma_wb_base_lo);\n\tregs_buff[num++] = readl(&aregs->rxdma.num_pkt_done);\n\tregs_buff[num++] = readl(&aregs->rxdma.max_pkt_time);\n\tregs_buff[num++] = readl(&aregs->rxdma.rxq_rd_addr);\n\tregs_buff[num++] = readl(&aregs->rxdma.rxq_rd_addr_ext);\n\tregs_buff[num++] = readl(&aregs->rxdma.rxq_wr_addr);\n\tregs_buff[num++] = readl(&aregs->rxdma.psr_base_hi);\n\tregs_buff[num++] = readl(&aregs->rxdma.psr_base_lo);\n\tregs_buff[num++] = readl(&aregs->rxdma.psr_num_des);\n\tregs_buff[num++] = readl(&aregs->rxdma.psr_avail_offset);\n\tregs_buff[num++] = readl(&aregs->rxdma.psr_full_offset);\n\tregs_buff[num++] = readl(&aregs->rxdma.psr_access_index);\n\tregs_buff[num++] = readl(&aregs->rxdma.psr_min_des);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr0_base_lo);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr0_base_hi);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr0_num_des);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr0_avail_offset);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr0_full_offset);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr0_rd_index);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr0_min_des);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr1_base_lo);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr1_base_hi);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr1_num_des);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr1_avail_offset);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr1_full_offset);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr1_rd_index);\n\tregs_buff[num++] = readl(&aregs->rxdma.fbr1_min_des);\n}\n\nstatic void et131x_get_drvinfo(struct net_device *netdev,\n\t\t\t       struct ethtool_drvinfo *info)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\n\tstrscpy(info->driver, DRIVER_NAME, sizeof(info->driver));\n\tstrscpy(info->bus_info, pci_name(adapter->pdev),\n\t\tsizeof(info->bus_info));\n}\n\nstatic const struct ethtool_ops et131x_ethtool_ops = {\n\t.get_drvinfo\t= et131x_get_drvinfo,\n\t.get_regs_len\t= et131x_get_regs_len,\n\t.get_regs\t= et131x_get_regs,\n\t.get_link\t= ethtool_op_get_link,\n\t.get_link_ksettings = phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings = phy_ethtool_set_link_ksettings,\n};\n\n \nstatic void et131x_hwaddr_init(struct et131x_adapter *adapter)\n{\n\t \n\tif (is_zero_ether_addr(adapter->rom_addr)) {\n\t\t \n\t\tget_random_bytes(&adapter->addr[5], 1);\n\t\t \n\t\tether_addr_copy(adapter->rom_addr, adapter->addr);\n\t} else {\n\t\t \n\t\tether_addr_copy(adapter->addr, adapter->rom_addr);\n\t}\n}\n\nstatic int et131x_pci_init(struct et131x_adapter *adapter,\n\t\t\t   struct pci_dev *pdev)\n{\n\tu16 max_payload;\n\tint i, rc;\n\n\trc = et131x_init_eeprom(adapter);\n\tif (rc < 0)\n\t\tgoto out;\n\n\tif (!pci_is_pcie(pdev)) {\n\t\tdev_err(&pdev->dev, \"Missing PCIe capabilities\\n\");\n\t\tgoto err_out;\n\t}\n\n\t \n\tmax_payload = pdev->pcie_mpss;\n\n\tif (max_payload < 2) {\n\t\tstatic const u16 acknak[2] = { 0x76, 0xD0 };\n\t\tstatic const u16 replay[2] = { 0x1E0, 0x2ED };\n\n\t\tif (pci_write_config_word(pdev, ET1310_PCI_ACK_NACK,\n\t\t\t\t\t  acknak[max_payload])) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Could not write PCI config space for ACK/NAK\\n\");\n\t\t\tgoto err_out;\n\t\t}\n\t\tif (pci_write_config_word(pdev, ET1310_PCI_REPLAY,\n\t\t\t\t\t  replay[max_payload])) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Could not write PCI config space for Replay Timer\\n\");\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\t \n\tif (pci_write_config_byte(pdev, ET1310_PCI_L0L1LATENCY, 0x11)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Could not write PCI config space for Latency Timers\\n\");\n\t\tgoto err_out;\n\t}\n\n\t \n\tif (pcie_set_readrq(pdev, 2048)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Couldn't change PCI config space for Max read size\\n\");\n\t\tgoto err_out;\n\t}\n\n\t \n\tif (!adapter->has_eeprom) {\n\t\tet131x_hwaddr_init(adapter);\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < ETH_ALEN; i++) {\n\t\tif (pci_read_config_byte(pdev, ET1310_PCI_MAC_ADDRESS + i,\n\t\t\t\t\t adapter->rom_addr + i)) {\n\t\t\tdev_err(&pdev->dev, \"Could not read PCI config space for MAC address\\n\");\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\tether_addr_copy(adapter->addr, adapter->rom_addr);\nout:\n\treturn rc;\nerr_out:\n\trc = -EIO;\n\tgoto out;\n}\n\n \nstatic void et131x_error_timer_handler(struct timer_list *t)\n{\n\tstruct et131x_adapter *adapter = from_timer(adapter, t, error_timer);\n\tstruct phy_device *phydev = adapter->netdev->phydev;\n\n\tif (et1310_in_phy_coma(adapter)) {\n\t\t \n\t\tet1310_disable_phy_coma(adapter);\n\t\tadapter->boot_coma = 20;\n\t} else {\n\t\tet1310_update_macstat_host_counters(adapter);\n\t}\n\n\tif (!phydev->link && adapter->boot_coma < 11)\n\t\tadapter->boot_coma++;\n\n\tif (adapter->boot_coma == 10) {\n\t\tif (!phydev->link) {\n\t\t\tif (!et1310_in_phy_coma(adapter)) {\n\t\t\t\t \n\t\t\t\tet131x_enable_interrupts(adapter);\n\t\t\t\tet1310_enable_phy_coma(adapter);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tmod_timer(&adapter->error_timer, jiffies +\n\t\t  msecs_to_jiffies(TX_ERROR_PERIOD));\n}\n\nstatic void et131x_adapter_memory_free(struct et131x_adapter *adapter)\n{\n\tet131x_tx_dma_memory_free(adapter);\n\tet131x_rx_dma_memory_free(adapter);\n}\n\nstatic int et131x_adapter_memory_alloc(struct et131x_adapter *adapter)\n{\n\tint status;\n\n\tstatus = et131x_tx_dma_memory_alloc(adapter);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"et131x_tx_dma_memory_alloc FAILED\\n\");\n\t\tet131x_tx_dma_memory_free(adapter);\n\t\treturn status;\n\t}\n\n\tstatus = et131x_rx_dma_memory_alloc(adapter);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"et131x_rx_dma_memory_alloc FAILED\\n\");\n\t\tet131x_adapter_memory_free(adapter);\n\t\treturn status;\n\t}\n\n\tstatus = et131x_init_recv(adapter);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev, \"et131x_init_recv FAILED\\n\");\n\t\tet131x_adapter_memory_free(adapter);\n\t}\n\treturn status;\n}\n\nstatic void et131x_adjust_link(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct  phy_device *phydev = netdev->phydev;\n\n\tif (!phydev)\n\t\treturn;\n\tif (phydev->link == adapter->link)\n\t\treturn;\n\n\t \n\tif (et1310_in_phy_coma(adapter))\n\t\tet1310_disable_phy_coma(adapter);\n\n\tadapter->link = phydev->link;\n\tphy_print_status(phydev);\n\n\tif (phydev->link) {\n\t\tadapter->boot_coma = 20;\n\t\tif (phydev->speed == SPEED_10) {\n\t\t\tu16 register18;\n\n\t\t\tet131x_mii_read(adapter, PHY_MPHY_CONTROL_REG,\n\t\t\t\t\t&register18);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_MPHY_CONTROL_REG,\n\t\t\t\t\t register18 | 0x4);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_INDEX_REG, register18 | 0x8402);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_DATA_REG, register18 | 511);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_MPHY_CONTROL_REG, register18);\n\t\t}\n\n\t\tet1310_config_flow_control(adapter);\n\n\t\tif (phydev->speed == SPEED_1000 &&\n\t\t    adapter->registry_jumbo_packet > 2048) {\n\t\t\tu16 reg;\n\n\t\t\tet131x_mii_read(adapter, PHY_CONFIG, &reg);\n\t\t\treg &= ~ET_PHY_CONFIG_TX_FIFO_DEPTH;\n\t\t\treg |= ET_PHY_CONFIG_FIFO_DEPTH_32;\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_CONFIG, reg);\n\t\t}\n\n\t\tet131x_set_rx_dma_timer(adapter);\n\t\tet1310_config_mac_regs2(adapter);\n\t} else {\n\t\tadapter->boot_coma = 0;\n\n\t\tif (phydev->speed == SPEED_10) {\n\t\t\tu16 register18;\n\n\t\t\tet131x_mii_read(adapter, PHY_MPHY_CONTROL_REG,\n\t\t\t\t\t&register18);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_MPHY_CONTROL_REG,\n\t\t\t\t\t register18 | 0x4);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_INDEX_REG, register18 | 0x8402);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_DATA_REG, register18 | 511);\n\t\t\tet131x_mii_write(adapter, phydev->mdio.addr,\n\t\t\t\t\t PHY_MPHY_CONTROL_REG, register18);\n\t\t}\n\n\t\tet131x_free_busy_send_packets(adapter);\n\t\tet131x_init_send(adapter);\n\n\t\t \n\t\tet131x_soft_reset(adapter);\n\n\t\tet131x_adapter_setup(adapter);\n\n\t\tet131x_disable_txrx(netdev);\n\t\tet131x_enable_txrx(netdev);\n\t}\n}\n\nstatic int et131x_mii_probe(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct  phy_device *phydev = NULL;\n\n\tphydev = phy_find_first(adapter->mii_bus);\n\tif (!phydev) {\n\t\tdev_err(&adapter->pdev->dev, \"no PHY found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tphydev = phy_connect(netdev, phydev_name(phydev),\n\t\t\t     &et131x_adjust_link, PHY_INTERFACE_MODE_MII);\n\n\tif (IS_ERR(phydev)) {\n\t\tdev_err(&adapter->pdev->dev, \"Could not attach to PHY\\n\");\n\t\treturn PTR_ERR(phydev);\n\t}\n\n\tphy_set_max_speed(phydev, SPEED_100);\n\n\tif (adapter->pdev->device != ET131X_PCI_DEVICE_ID_FAST)\n\t\tphy_set_max_speed(phydev, SPEED_1000);\n\n\tphydev->autoneg = AUTONEG_ENABLE;\n\n\tphy_attached_info(phydev);\n\n\treturn 0;\n}\n\nstatic struct et131x_adapter *et131x_adapter_init(struct net_device *netdev,\n\t\t\t\t\t\t  struct pci_dev *pdev)\n{\n\tstatic const u8 default_mac[] = { 0x00, 0x05, 0x3d, 0x00, 0x02, 0x00 };\n\n\tstruct et131x_adapter *adapter;\n\n\tadapter = netdev_priv(netdev);\n\tadapter->pdev = pci_dev_get(pdev);\n\tadapter->netdev = netdev;\n\n\tspin_lock_init(&adapter->tcb_send_qlock);\n\tspin_lock_init(&adapter->tcb_ready_qlock);\n\tspin_lock_init(&adapter->rcv_lock);\n\n\tadapter->registry_jumbo_packet = 1514;\t \n\n\tether_addr_copy(adapter->addr, default_mac);\n\n\treturn adapter;\n}\n\nstatic void et131x_pci_remove(struct pci_dev *pdev)\n{\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\n\tunregister_netdev(netdev);\n\tnetif_napi_del(&adapter->napi);\n\tphy_disconnect(netdev->phydev);\n\tmdiobus_unregister(adapter->mii_bus);\n\tmdiobus_free(adapter->mii_bus);\n\n\tet131x_adapter_memory_free(adapter);\n\tiounmap(adapter->regs);\n\tpci_dev_put(pdev);\n\n\tfree_netdev(netdev);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n}\n\nstatic void et131x_up(struct net_device *netdev)\n{\n\tet131x_enable_txrx(netdev);\n\tphy_start(netdev->phydev);\n}\n\nstatic void et131x_down(struct net_device *netdev)\n{\n\t \n\tnetif_trans_update(netdev);\n\n\tphy_stop(netdev->phydev);\n\tet131x_disable_txrx(netdev);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int et131x_suspend(struct device *dev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev);\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\n\tif (netif_running(netdev)) {\n\t\tnetif_device_detach(netdev);\n\t\tet131x_down(netdev);\n\t\tpci_save_state(pdev);\n\t}\n\n\treturn 0;\n}\n\nstatic int et131x_resume(struct device *dev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev);\n\tstruct net_device *netdev = pci_get_drvdata(pdev);\n\n\tif (netif_running(netdev)) {\n\t\tpci_restore_state(pdev);\n\t\tet131x_up(netdev);\n\t\tnetif_device_attach(netdev);\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic SIMPLE_DEV_PM_OPS(et131x_pm_ops, et131x_suspend, et131x_resume);\n\nstatic irqreturn_t et131x_isr(int irq, void *dev_id)\n{\n\tbool handled = true;\n\tbool enable_interrupts = true;\n\tstruct net_device *netdev = dev_id;\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct address_map __iomem *iomem = adapter->regs;\n\tstruct rx_ring *rx_ring = &adapter->rx_ring;\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\tu32 status;\n\n\tif (!netif_device_present(netdev)) {\n\t\thandled = false;\n\t\tenable_interrupts = false;\n\t\tgoto out;\n\t}\n\n\tet131x_disable_interrupts(adapter);\n\n\tstatus = readl(&adapter->regs->global.int_status);\n\n\tif (adapter->flow == FLOW_TXONLY || adapter->flow == FLOW_BOTH)\n\t\tstatus &= ~INT_MASK_ENABLE;\n\telse\n\t\tstatus &= ~INT_MASK_ENABLE_NO_FLOW;\n\n\t \n\tif (!status) {\n\t\thandled = false;\n\t\tet131x_enable_interrupts(adapter);\n\t\tgoto out;\n\t}\n\n\t \n\tif (status & ET_INTR_WATCHDOG) {\n\t\tstruct tcb *tcb = tx_ring->send_head;\n\n\t\tif (tcb)\n\t\t\tif (++tcb->stale > 1)\n\t\t\t\tstatus |= ET_INTR_TXDMA_ISR;\n\n\t\tif (rx_ring->unfinished_receives)\n\t\t\tstatus |= ET_INTR_RXDMA_XFR_DONE;\n\t\telse if (tcb == NULL)\n\t\t\twritel(0, &adapter->regs->global.watchdog_timer);\n\n\t\tstatus &= ~ET_INTR_WATCHDOG;\n\t}\n\n\tif (status & (ET_INTR_RXDMA_XFR_DONE | ET_INTR_TXDMA_ISR)) {\n\t\tenable_interrupts = false;\n\t\tnapi_schedule(&adapter->napi);\n\t}\n\n\tstatus &= ~(ET_INTR_TXDMA_ISR | ET_INTR_RXDMA_XFR_DONE);\n\n\tif (!status)\n\t\tgoto out;\n\n\tif (status & ET_INTR_TXDMA_ERR) {\n\t\t \n\t\tu32 txdma_err = readl(&iomem->txdma.tx_dma_error);\n\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"TXDMA_ERR interrupt, error = %d\\n\",\n\t\t\t txdma_err);\n\t}\n\n\tif (status & (ET_INTR_RXDMA_FB_R0_LOW | ET_INTR_RXDMA_FB_R1_LOW)) {\n\t\t \n\n\t\t \n\t\tif (adapter->flow == FLOW_TXONLY || adapter->flow == FLOW_BOTH) {\n\t\t\t \n\t\t\tif (!et1310_in_phy_coma(adapter))\n\t\t\t\twritel(3, &iomem->txmac.bp_ctrl);\n\t\t}\n\t}\n\n\t \n\tif (status & ET_INTR_RXDMA_STAT_LOW) {\n\t\t \n\t}\n\n\tif (status & ET_INTR_RXDMA_ERR) {\n\t\t \n\t\t \n\n\t\tdev_warn(&adapter->pdev->dev, \"RxDMA_ERR interrupt, error %x\\n\",\n\t\t\t readl(&iomem->txmac.tx_test));\n\t}\n\n\t \n\tif (status & ET_INTR_WOL) {\n\t\t \n\t\tdev_err(&adapter->pdev->dev, \"WAKE_ON_LAN interrupt\\n\");\n\t}\n\n\tif (status & ET_INTR_TXMAC) {\n\t\tu32 err = readl(&iomem->txmac.err);\n\n\t\t \n\t\tdev_warn(&adapter->pdev->dev, \"TXMAC interrupt, error 0x%08x\\n\",\n\t\t\t err);\n\n\t\t \n\t}\n\n\tif (status & ET_INTR_RXMAC) {\n\t\t \n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"RXMAC interrupt, error 0x%08x.  Requesting reset\\n\",\n\t\t\t readl(&iomem->rxmac.err_reg));\n\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"Enable 0x%08x, Diag 0x%08x\\n\",\n\t\t\t readl(&iomem->rxmac.ctrl),\n\t\t\t readl(&iomem->rxmac.rxq_diag));\n\n\t\t \n\t}\n\n\tif (status & ET_INTR_MAC_STAT) {\n\t\t \n\t\tet1310_handle_macstat_interrupt(adapter);\n\t}\n\n\tif (status & ET_INTR_SLV_TIMEOUT) {\n\t\t \n\t}\n\nout:\n\tif (enable_interrupts)\n\t\tet131x_enable_interrupts(adapter);\n\n\treturn IRQ_RETVAL(handled);\n}\n\nstatic int et131x_poll(struct napi_struct *napi, int budget)\n{\n\tstruct et131x_adapter *adapter =\n\t\tcontainer_of(napi, struct et131x_adapter, napi);\n\tint work_done = et131x_handle_recv_pkts(adapter, budget);\n\n\tet131x_handle_send_pkts(adapter);\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(&adapter->napi, work_done);\n\t\tet131x_enable_interrupts(adapter);\n\t}\n\n\treturn work_done;\n}\n\n \nstatic struct net_device_stats *et131x_stats(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct net_device_stats *stats = &adapter->netdev->stats;\n\tstruct ce_stats *devstat = &adapter->stats;\n\n\tstats->rx_errors = devstat->rx_length_errs +\n\t\t\t   devstat->rx_align_errs +\n\t\t\t   devstat->rx_crc_errs +\n\t\t\t   devstat->rx_code_violations +\n\t\t\t   devstat->rx_other_errs;\n\tstats->tx_errors = devstat->tx_max_pkt_errs;\n\tstats->multicast = devstat->multicast_pkts_rcvd;\n\tstats->collisions = devstat->tx_collisions;\n\n\tstats->rx_length_errors = devstat->rx_length_errs;\n\tstats->rx_over_errors = devstat->rx_overflows;\n\tstats->rx_crc_errors = devstat->rx_crc_errs;\n\tstats->rx_dropped = devstat->rcvd_pkts_dropped;\n\n\t \n\t \n\t \n\t \n\n\t \n\t \n\t \n\t \n\t \n\treturn stats;\n}\n\nstatic int et131x_open(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct pci_dev *pdev = adapter->pdev;\n\tunsigned int irq = pdev->irq;\n\tint result;\n\n\t \n\ttimer_setup(&adapter->error_timer, et131x_error_timer_handler, 0);\n\tadapter->error_timer.expires = jiffies +\n\t\tmsecs_to_jiffies(TX_ERROR_PERIOD);\n\tadd_timer(&adapter->error_timer);\n\n\tresult = request_irq(irq, et131x_isr,\n\t\t\t     IRQF_SHARED, netdev->name, netdev);\n\tif (result) {\n\t\tdev_err(&pdev->dev, \"could not register IRQ %d\\n\", irq);\n\t\treturn result;\n\t}\n\n\tadapter->flags |= FMP_ADAPTER_INTERRUPT_IN_USE;\n\n\tnapi_enable(&adapter->napi);\n\n\tet131x_up(netdev);\n\n\treturn result;\n}\n\nstatic int et131x_close(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\n\tet131x_down(netdev);\n\tnapi_disable(&adapter->napi);\n\n\tadapter->flags &= ~FMP_ADAPTER_INTERRUPT_IN_USE;\n\tfree_irq(adapter->pdev->irq, netdev);\n\n\t \n\treturn del_timer_sync(&adapter->error_timer);\n}\n\n \nstatic int et131x_set_packet_filter(struct et131x_adapter *adapter)\n{\n\tint filter = adapter->packet_filter;\n\tu32 ctrl;\n\tu32 pf_ctrl;\n\n\tctrl = readl(&adapter->regs->rxmac.ctrl);\n\tpf_ctrl = readl(&adapter->regs->rxmac.pf_ctrl);\n\n\t \n\tctrl |= 0x04;\n\n\t \n\tif ((filter & ET131X_PACKET_TYPE_PROMISCUOUS) || filter == 0)\n\t\tpf_ctrl &= ~7;\t \n\telse {\n\t\t \n\t\tif (filter & ET131X_PACKET_TYPE_ALL_MULTICAST)\n\t\t\tpf_ctrl &= ~2;\t \n\t\telse {\n\t\t\tet1310_setup_device_for_multicast(adapter);\n\t\t\tpf_ctrl |= 2;\n\t\t\tctrl &= ~0x04;\n\t\t}\n\n\t\t \n\t\tif (filter & ET131X_PACKET_TYPE_DIRECTED) {\n\t\t\tet1310_setup_device_for_unicast(adapter);\n\t\t\tpf_ctrl |= 4;\n\t\t\tctrl &= ~0x04;\n\t\t}\n\n\t\t \n\t\tif (filter & ET131X_PACKET_TYPE_BROADCAST) {\n\t\t\tpf_ctrl |= 1;\t \n\t\t\tctrl &= ~0x04;\n\t\t} else {\n\t\t\tpf_ctrl &= ~1;\n\t\t}\n\n\t\t \n\t\twritel(pf_ctrl, &adapter->regs->rxmac.pf_ctrl);\n\t\twritel(ctrl, &adapter->regs->rxmac.ctrl);\n\t}\n\treturn 0;\n}\n\nstatic void et131x_multicast(struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tint packet_filter;\n\tstruct netdev_hw_addr *ha;\n\tint i;\n\n\t \n\tpacket_filter = adapter->packet_filter;\n\n\t \n\tpacket_filter &= ~ET131X_PACKET_TYPE_MULTICAST;\n\n\t \n\tif (netdev->flags & IFF_PROMISC)\n\t\tadapter->packet_filter |= ET131X_PACKET_TYPE_PROMISCUOUS;\n\telse\n\t\tadapter->packet_filter &= ~ET131X_PACKET_TYPE_PROMISCUOUS;\n\n\tif ((netdev->flags & IFF_ALLMULTI) ||\n\t    (netdev_mc_count(netdev) > NIC_MAX_MCAST_LIST))\n\t\tadapter->packet_filter |= ET131X_PACKET_TYPE_ALL_MULTICAST;\n\n\tif (netdev_mc_count(netdev) < 1) {\n\t\tadapter->packet_filter &= ~ET131X_PACKET_TYPE_ALL_MULTICAST;\n\t\tadapter->packet_filter &= ~ET131X_PACKET_TYPE_MULTICAST;\n\t} else {\n\t\tadapter->packet_filter |= ET131X_PACKET_TYPE_MULTICAST;\n\t}\n\n\t \n\ti = 0;\n\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\tif (i == NIC_MAX_MCAST_LIST)\n\t\t\tbreak;\n\t\tether_addr_copy(adapter->multicast_list[i++], ha->addr);\n\t}\n\tadapter->multicast_addr_count = i;\n\n\t \n\tif (packet_filter != adapter->packet_filter)\n\t\tet131x_set_packet_filter(adapter);\n}\n\nstatic netdev_tx_t et131x_tx(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\n\t \n\tif (unlikely(skb_shinfo(skb)->nr_frags > MAX_TX_DESC_PER_PKT - 2)) {\n\t\tif (skb_linearize(skb))\n\t\t\tgoto drop_err;\n\t}\n\t \n\tif (tx_ring->used >= NUM_TCB - 1 && !netif_queue_stopped(netdev))\n\t\tnetif_stop_queue(netdev);\n\n\t \n\tnetif_trans_update(netdev);\n\n\t \n\tif (tx_ring->used >= NUM_TCB)\n\t\tgoto drop_err;\n\n\tif ((adapter->flags & FMP_ADAPTER_FAIL_SEND_MASK) ||\n\t    !netif_carrier_ok(netdev))\n\t\tgoto drop_err;\n\n\tif (send_packet(skb, adapter))\n\t\tgoto drop_err;\n\n\treturn NETDEV_TX_OK;\n\ndrop_err:\n\tdev_kfree_skb_any(skb);\n\tadapter->netdev->stats.tx_dropped++;\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic void et131x_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\tstruct tx_ring *tx_ring = &adapter->tx_ring;\n\tstruct tcb *tcb;\n\tunsigned long flags;\n\n\t \n\tif (!(adapter->flags & FMP_ADAPTER_INTERRUPT_IN_USE))\n\t\treturn;\n\n\t \n\tif (adapter->flags & FMP_ADAPTER_NON_RECOVER_ERROR)\n\t\treturn;\n\n\t \n\tif (adapter->flags & FMP_ADAPTER_HARDWARE_ERROR) {\n\t\tdev_err(&adapter->pdev->dev, \"hardware error - reset\\n\");\n\t\treturn;\n\t}\n\n\t \n\tspin_lock_irqsave(&adapter->tcb_send_qlock, flags);\n\ttcb = tx_ring->send_head;\n\tspin_unlock_irqrestore(&adapter->tcb_send_qlock, flags);\n\n\tif (tcb) {\n\t\ttcb->count++;\n\n\t\tif (tcb->count > NIC_SEND_HANG_THRESHOLD) {\n\t\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t\t \"Send stuck - reset. tcb->WrIndex %x\\n\",\n\t\t\t\t tcb->index);\n\n\t\t\tadapter->netdev->stats.tx_errors++;\n\n\t\t\t \n\t\t\tet131x_disable_txrx(netdev);\n\t\t\tet131x_enable_txrx(netdev);\n\t\t}\n\t}\n}\n\nstatic int et131x_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tint result = 0;\n\tstruct et131x_adapter *adapter = netdev_priv(netdev);\n\n\tet131x_disable_txrx(netdev);\n\n\tnetdev->mtu = new_mtu;\n\n\tet131x_adapter_memory_free(adapter);\n\n\t \n\tadapter->registry_jumbo_packet = new_mtu + 14;\n\tet131x_soft_reset(adapter);\n\n\tresult = et131x_adapter_memory_alloc(adapter);\n\tif (result != 0) {\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"Change MTU failed; couldn't re-alloc DMA memory\\n\");\n\t\treturn result;\n\t}\n\n\tet131x_init_send(adapter);\n\tet131x_hwaddr_init(adapter);\n\teth_hw_addr_set(netdev, adapter->addr);\n\n\t \n\tet131x_adapter_setup(adapter);\n\tet131x_enable_txrx(netdev);\n\n\treturn result;\n}\n\nstatic const struct net_device_ops et131x_netdev_ops = {\n\t.ndo_open\t\t= et131x_open,\n\t.ndo_stop\t\t= et131x_close,\n\t.ndo_start_xmit\t\t= et131x_tx,\n\t.ndo_set_rx_mode\t= et131x_multicast,\n\t.ndo_tx_timeout\t\t= et131x_tx_timeout,\n\t.ndo_change_mtu\t\t= et131x_change_mtu,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_get_stats\t\t= et131x_stats,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl,\n};\n\nstatic int et131x_pci_setup(struct pci_dev *pdev,\n\t\t\t    const struct pci_device_id *ent)\n{\n\tstruct net_device *netdev;\n\tstruct et131x_adapter *adapter;\n\tint rc;\n\n\trc = pci_enable_device(pdev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"pci_enable_device() failed\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\tif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\n\t\tdev_err(&pdev->dev, \"Can't find PCI device's base address\\n\");\n\t\trc = -ENODEV;\n\t\tgoto err_disable;\n\t}\n\n\trc = pci_request_regions(pdev, DRIVER_NAME);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Can't get PCI resources\\n\");\n\t\tgoto err_disable;\n\t}\n\n\tpci_set_master(pdev);\n\n\t \n\trc = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"No usable DMA addressing method\\n\");\n\t\tgoto err_release_res;\n\t}\n\n\tnetdev = alloc_etherdev(sizeof(struct et131x_adapter));\n\tif (!netdev) {\n\t\tdev_err(&pdev->dev, \"Couldn't alloc netdev struct\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err_release_res;\n\t}\n\n\tnetdev->watchdog_timeo = ET131X_TX_TIMEOUT;\n\tnetdev->netdev_ops     = &et131x_netdev_ops;\n\tnetdev->min_mtu        = ET131X_MIN_MTU;\n\tnetdev->max_mtu        = ET131X_MAX_MTU;\n\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\tnetdev->ethtool_ops = &et131x_ethtool_ops;\n\n\tadapter = et131x_adapter_init(netdev, pdev);\n\n\trc = et131x_pci_init(adapter, pdev);\n\tif (rc < 0)\n\t\tgoto err_free_dev;\n\n\t \n\tadapter->regs = pci_ioremap_bar(pdev, 0);\n\tif (!adapter->regs) {\n\t\tdev_err(&pdev->dev, \"Cannot map device registers\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto err_free_dev;\n\t}\n\n\t \n\twritel(ET_PMCSR_INIT,  &adapter->regs->global.pm_csr);\n\n\tet131x_soft_reset(adapter);\n\tet131x_disable_interrupts(adapter);\n\n\trc = et131x_adapter_memory_alloc(adapter);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Could not alloc adapter memory (DMA)\\n\");\n\t\tgoto err_iounmap;\n\t}\n\n\tet131x_init_send(adapter);\n\n\tnetif_napi_add(netdev, &adapter->napi, et131x_poll);\n\n\teth_hw_addr_set(netdev, adapter->addr);\n\n\trc = -ENOMEM;\n\n\tadapter->mii_bus = mdiobus_alloc();\n\tif (!adapter->mii_bus) {\n\t\tdev_err(&pdev->dev, \"Alloc of mii_bus struct failed\\n\");\n\t\tgoto err_mem_free;\n\t}\n\n\tadapter->mii_bus->name = \"et131x_eth_mii\";\n\tsnprintf(adapter->mii_bus->id, MII_BUS_ID_SIZE, \"%x\", pci_dev_id(adapter->pdev));\n\tadapter->mii_bus->priv = netdev;\n\tadapter->mii_bus->read = et131x_mdio_read;\n\tadapter->mii_bus->write = et131x_mdio_write;\n\n\trc = mdiobus_register(adapter->mii_bus);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"failed to register MII bus\\n\");\n\t\tgoto err_mdio_free;\n\t}\n\n\trc = et131x_mii_probe(netdev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"failed to probe MII bus\\n\");\n\t\tgoto err_mdio_unregister;\n\t}\n\n\tet131x_adapter_setup(adapter);\n\n\t \n\tadapter->boot_coma = 0;\n\tet1310_disable_phy_coma(adapter);\n\n\t \n\n\trc = register_netdev(netdev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"register_netdev() failed\\n\");\n\t\tgoto err_phy_disconnect;\n\t}\n\n\t \n\tpci_set_drvdata(pdev, netdev);\nout:\n\treturn rc;\n\nerr_phy_disconnect:\n\tphy_disconnect(netdev->phydev);\nerr_mdio_unregister:\n\tmdiobus_unregister(adapter->mii_bus);\nerr_mdio_free:\n\tmdiobus_free(adapter->mii_bus);\nerr_mem_free:\n\tet131x_adapter_memory_free(adapter);\nerr_iounmap:\n\tiounmap(adapter->regs);\nerr_free_dev:\n\tpci_dev_put(pdev);\n\tfree_netdev(netdev);\nerr_release_res:\n\tpci_release_regions(pdev);\nerr_disable:\n\tpci_disable_device(pdev);\n\tgoto out;\n}\n\nstatic const struct pci_device_id et131x_pci_table[] = {\n\t{ PCI_VDEVICE(ATT, ET131X_PCI_DEVICE_ID_GIG), 0UL},\n\t{ PCI_VDEVICE(ATT, ET131X_PCI_DEVICE_ID_FAST), 0UL},\n\t{ 0,}\n};\nMODULE_DEVICE_TABLE(pci, et131x_pci_table);\n\nstatic struct pci_driver et131x_driver = {\n\t.name\t\t= DRIVER_NAME,\n\t.id_table\t= et131x_pci_table,\n\t.probe\t\t= et131x_pci_setup,\n\t.remove\t\t= et131x_pci_remove,\n\t.driver.pm\t= &et131x_pm_ops,\n};\n\nmodule_pci_driver(et131x_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}