{
  "module_name": "hclge_tm.c",
  "hash_id": "99e9e58a58f66b4b15a71872ab43e6b33984c3d11c6ebbf5b8e2ec6d72b4dcfc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_tm.c",
  "human_readable_source": "\n\n\n#include <linux/etherdevice.h>\n\n#include \"hclge_cmd.h\"\n#include \"hclge_main.h\"\n#include \"hclge_tm.h\"\n\nenum hclge_shaper_level {\n\tHCLGE_SHAPER_LVL_PRI\t= 0,\n\tHCLGE_SHAPER_LVL_PG\t= 1,\n\tHCLGE_SHAPER_LVL_PORT\t= 2,\n\tHCLGE_SHAPER_LVL_QSET\t= 3,\n\tHCLGE_SHAPER_LVL_CNT\t= 4,\n\tHCLGE_SHAPER_LVL_VF\t= 0,\n\tHCLGE_SHAPER_LVL_PF\t= 1,\n};\n\n#define HCLGE_TM_PFC_PKT_GET_CMD_NUM\t3\n#define HCLGE_TM_PFC_NUM_GET_PER_CMD\t3\n\n#define HCLGE_SHAPER_BS_U_DEF\t5\n#define HCLGE_SHAPER_BS_S_DEF\t20\n\n \nstatic int hclge_shaper_para_calc(u32 ir, u8 shaper_level,\n\t\t\t\t  struct hclge_shaper_ir_para *ir_para,\n\t\t\t\t  u32 max_tm_rate)\n{\n#define DEFAULT_SHAPER_IR_B\t126\n#define DIVISOR_CLK\t\t(1000 * 8)\n#define DEFAULT_DIVISOR_IR_B\t(DEFAULT_SHAPER_IR_B * DIVISOR_CLK)\n\n\tstatic const u16 tick_array[HCLGE_SHAPER_LVL_CNT] = {\n\t\t6 * 256,         \n\t\t6 * 32,          \n\t\t6 * 8,           \n\t\t6 * 256          \n\t};\n\tu8 ir_u_calc = 0;\n\tu8 ir_s_calc = 0;\n\tu32 ir_calc;\n\tu32 tick;\n\n\t \n\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT ||\n\t    ir > max_tm_rate)\n\t\treturn -EINVAL;\n\n\ttick = tick_array[shaper_level];\n\n\t \n\tir_calc = (DEFAULT_DIVISOR_IR_B + (tick >> 1) - 1) / tick;\n\n\tif (ir_calc == ir) {\n\t\tir_para->ir_b = DEFAULT_SHAPER_IR_B;\n\t\tir_para->ir_u = 0;\n\t\tir_para->ir_s = 0;\n\n\t\treturn 0;\n\t} else if (ir_calc > ir) {\n\t\t \n\t\twhile (ir_calc >= ir && ir) {\n\t\t\tir_s_calc++;\n\t\t\tir_calc = DEFAULT_DIVISOR_IR_B /\n\t\t\t\t  (tick * (1 << ir_s_calc));\n\t\t}\n\n\t\tir_para->ir_b = (ir * tick * (1 << ir_s_calc) +\n\t\t\t\t(DIVISOR_CLK >> 1)) / DIVISOR_CLK;\n\t} else {\n\t\t \n\t\tu32 numerator;\n\n\t\twhile (ir_calc < ir) {\n\t\t\tir_u_calc++;\n\t\t\tnumerator = DEFAULT_DIVISOR_IR_B * (1 << ir_u_calc);\n\t\t\tir_calc = (numerator + (tick >> 1)) / tick;\n\t\t}\n\n\t\tif (ir_calc == ir) {\n\t\t\tir_para->ir_b = DEFAULT_SHAPER_IR_B;\n\t\t} else {\n\t\t\tu32 denominator = DIVISOR_CLK * (1 << --ir_u_calc);\n\t\t\tir_para->ir_b = (ir * tick + (denominator >> 1)) /\n\t\t\t\t\tdenominator;\n\t\t}\n\t}\n\n\tir_para->ir_u = ir_u_calc;\n\tir_para->ir_s = ir_s_calc;\n\n\treturn 0;\n}\n\nstatic const u16 hclge_pfc_tx_stats_offset[] = {\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri0_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri1_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri2_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri3_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri4_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri5_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri6_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_tx_pfc_pri7_pkt_num)\n};\n\nstatic const u16 hclge_pfc_rx_stats_offset[] = {\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri0_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri1_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri2_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri3_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri4_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri5_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri6_pkt_num),\n\tHCLGE_MAC_STATS_FIELD_OFF(mac_rx_pfc_pri7_pkt_num)\n};\n\nstatic void hclge_pfc_stats_get(struct hclge_dev *hdev, bool tx, u64 *stats)\n{\n\tconst u16 *offset;\n\tint i;\n\n\tif (tx)\n\t\toffset = hclge_pfc_tx_stats_offset;\n\telse\n\t\toffset = hclge_pfc_rx_stats_offset;\n\n\tfor (i = 0; i < HCLGE_MAX_TC_NUM; i++)\n\t\tstats[i] = HCLGE_STATS_READ(&hdev->mac_stats, offset[i]);\n}\n\nvoid hclge_pfc_rx_stats_get(struct hclge_dev *hdev, u64 *stats)\n{\n\thclge_pfc_stats_get(hdev, false, stats);\n}\n\nvoid hclge_pfc_tx_stats_get(struct hclge_dev *hdev, u64 *stats)\n{\n\thclge_pfc_stats_get(hdev, true, stats);\n}\n\nint hclge_mac_pause_en_cfg(struct hclge_dev *hdev, bool tx, bool rx)\n{\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_CFG_MAC_PAUSE_EN, false);\n\n\tdesc.data[0] = cpu_to_le32((tx ? HCLGE_TX_MAC_PAUSE_EN_MSK : 0) |\n\t\t(rx ? HCLGE_RX_MAC_PAUSE_EN_MSK : 0));\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nint hclge_pfc_pause_en_cfg(struct hclge_dev *hdev, u8 tx_rx_bitmap,\n\t\t\t   u8 pfc_bitmap)\n{\n\tstruct hclge_desc desc;\n\tstruct hclge_pfc_en_cmd *pfc = (struct hclge_pfc_en_cmd *)desc.data;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_CFG_PFC_PAUSE_EN, false);\n\n\tpfc->tx_rx_en_bitmap = tx_rx_bitmap;\n\tpfc->pri_en_bitmap = pfc_bitmap;\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_pause_param_cfg(struct hclge_dev *hdev, const u8 *addr,\n\t\t\t\t u8 pause_trans_gap, u16 pause_trans_time)\n{\n\tstruct hclge_cfg_pause_param_cmd *pause_param;\n\tstruct hclge_desc desc;\n\n\tpause_param = (struct hclge_cfg_pause_param_cmd *)desc.data;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_CFG_MAC_PARA, false);\n\n\tether_addr_copy(pause_param->mac_addr, addr);\n\tether_addr_copy(pause_param->mac_addr_extra, addr);\n\tpause_param->pause_trans_gap = pause_trans_gap;\n\tpause_param->pause_trans_time = cpu_to_le16(pause_trans_time);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nint hclge_pause_addr_cfg(struct hclge_dev *hdev, const u8 *mac_addr)\n{\n\tstruct hclge_cfg_pause_param_cmd *pause_param;\n\tstruct hclge_desc desc;\n\tu16 trans_time;\n\tu8 trans_gap;\n\tint ret;\n\n\tpause_param = (struct hclge_cfg_pause_param_cmd *)desc.data;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_CFG_MAC_PARA, true);\n\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret)\n\t\treturn ret;\n\n\ttrans_gap = pause_param->pause_trans_gap;\n\ttrans_time = le16_to_cpu(pause_param->pause_trans_time);\n\n\treturn hclge_pause_param_cfg(hdev, mac_addr, trans_gap, trans_time);\n}\n\nstatic int hclge_fill_pri_array(struct hclge_dev *hdev, u8 *pri, u8 pri_id)\n{\n\tu8 tc;\n\n\ttc = hdev->tm_info.prio_tc[pri_id];\n\n\tif (tc >= hdev->tm_info.num_tc)\n\t\treturn -EINVAL;\n\n\t \n\tpri[pri_id >> 1] |= tc << ((pri_id & 1) * 4);\n\n\treturn 0;\n}\n\nint hclge_up_to_tc_map(struct hclge_dev *hdev)\n{\n\tstruct hclge_desc desc;\n\tu8 *pri = (u8 *)desc.data;\n\tu8 pri_id;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_PRI_TO_TC_MAPPING, false);\n\n\tfor (pri_id = 0; pri_id < HNAE3_MAX_USER_PRIO; pri_id++) {\n\t\tret = hclge_fill_pri_array(hdev, pri, pri_id);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic void hclge_dscp_to_prio_map_init(struct hclge_dev *hdev)\n{\n\tu8 i;\n\n\thdev->vport[0].nic.kinfo.tc_map_mode = HNAE3_TC_MAP_MODE_PRIO;\n\thdev->vport[0].nic.kinfo.dscp_app_cnt = 0;\n\tfor (i = 0; i < HNAE3_MAX_DSCP; i++)\n\t\thdev->vport[0].nic.kinfo.dscp_prio[i] = HNAE3_PRIO_ID_INVALID;\n}\n\nint hclge_dscp_to_tc_map(struct hclge_dev *hdev)\n{\n\tstruct hclge_desc desc[HCLGE_DSCP_MAP_TC_BD_NUM];\n\tu8 *req0 = (u8 *)desc[0].data;\n\tu8 *req1 = (u8 *)desc[1].data;\n\tu8 pri_id, tc_id, i, j;\n\n\thclge_cmd_setup_basic_desc(&desc[0], HCLGE_OPC_QOS_MAP, false);\n\tdesc[0].flag |= cpu_to_le16(HCLGE_COMM_CMD_FLAG_NEXT);\n\thclge_cmd_setup_basic_desc(&desc[1], HCLGE_OPC_QOS_MAP, false);\n\n\t \n\tfor (i = 0; i < HNAE3_MAX_DSCP / HCLGE_DSCP_MAP_TC_BD_NUM; i++) {\n\t\tpri_id = hdev->vport[0].nic.kinfo.dscp_prio[i];\n\t\tpri_id = pri_id == HNAE3_PRIO_ID_INVALID ? 0 : pri_id;\n\t\ttc_id = hdev->tm_info.prio_tc[pri_id];\n\t\t \n\t\treq0[i >> 1] |= tc_id << HCLGE_DSCP_TC_SHIFT(i);\n\n\t\tj = i + HNAE3_MAX_DSCP / HCLGE_DSCP_MAP_TC_BD_NUM;\n\t\tpri_id = hdev->vport[0].nic.kinfo.dscp_prio[j];\n\t\tpri_id = pri_id == HNAE3_PRIO_ID_INVALID ? 0 : pri_id;\n\t\ttc_id = hdev->tm_info.prio_tc[pri_id];\n\t\treq1[i >> 1] |= tc_id << HCLGE_DSCP_TC_SHIFT(i);\n\t}\n\n\treturn hclge_cmd_send(&hdev->hw, desc, HCLGE_DSCP_MAP_TC_BD_NUM);\n}\n\nstatic int hclge_tm_pg_to_pri_map_cfg(struct hclge_dev *hdev,\n\t\t\t\t      u8 pg_id, u8 pri_bit_map)\n{\n\tstruct hclge_pg_to_pri_link_cmd *map;\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PG_TO_PRI_LINK, false);\n\n\tmap = (struct hclge_pg_to_pri_link_cmd *)desc.data;\n\n\tmap->pg_id = pg_id;\n\tmap->pri_bit_map = pri_bit_map;\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_qs_to_pri_map_cfg(struct hclge_dev *hdev, u16 qs_id, u8 pri,\n\t\t\t\t      bool link_vld)\n{\n\tstruct hclge_qs_to_pri_link_cmd *map;\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_QS_TO_PRI_LINK, false);\n\n\tmap = (struct hclge_qs_to_pri_link_cmd *)desc.data;\n\n\tmap->qs_id = cpu_to_le16(qs_id);\n\tmap->priority = pri;\n\tmap->link_vld = link_vld ? HCLGE_TM_QS_PRI_LINK_VLD_MSK : 0;\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_q_to_qs_map_cfg(struct hclge_dev *hdev,\n\t\t\t\t    u16 q_id, u16 qs_id)\n{\n\tstruct hclge_nq_to_qs_link_cmd *map;\n\tstruct hclge_desc desc;\n\tu16 qs_id_l;\n\tu16 qs_id_h;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_NQ_TO_QS_LINK, false);\n\n\tmap = (struct hclge_nq_to_qs_link_cmd *)desc.data;\n\n\tmap->nq_id = cpu_to_le16(q_id);\n\n\t \n\tqs_id_l = hnae3_get_field(qs_id, HCLGE_TM_QS_ID_L_MSK,\n\t\t\t\t  HCLGE_TM_QS_ID_L_S);\n\tqs_id_h = hnae3_get_field(qs_id, HCLGE_TM_QS_ID_H_MSK,\n\t\t\t\t  HCLGE_TM_QS_ID_H_S);\n\thnae3_set_field(qs_id, HCLGE_TM_QS_ID_L_MSK, HCLGE_TM_QS_ID_L_S,\n\t\t\tqs_id_l);\n\thnae3_set_field(qs_id, HCLGE_TM_QS_ID_H_EXT_MSK, HCLGE_TM_QS_ID_H_EXT_S,\n\t\t\tqs_id_h);\n\tmap->qset_id = cpu_to_le16(qs_id | HCLGE_TM_Q_QS_LINK_VLD_MSK);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_pg_weight_cfg(struct hclge_dev *hdev, u8 pg_id,\n\t\t\t\t  u8 dwrr)\n{\n\tstruct hclge_pg_weight_cmd *weight;\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PG_WEIGHT, false);\n\n\tweight = (struct hclge_pg_weight_cmd *)desc.data;\n\n\tweight->pg_id = pg_id;\n\tweight->dwrr = dwrr;\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_pri_weight_cfg(struct hclge_dev *hdev, u8 pri_id,\n\t\t\t\t   u8 dwrr)\n{\n\tstruct hclge_priority_weight_cmd *weight;\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PRI_WEIGHT, false);\n\n\tweight = (struct hclge_priority_weight_cmd *)desc.data;\n\n\tweight->pri_id = pri_id;\n\tweight->dwrr = dwrr;\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_qs_weight_cfg(struct hclge_dev *hdev, u16 qs_id,\n\t\t\t\t  u8 dwrr)\n{\n\tstruct hclge_qs_weight_cmd *weight;\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_QS_WEIGHT, false);\n\n\tweight = (struct hclge_qs_weight_cmd *)desc.data;\n\n\tweight->qs_id = cpu_to_le16(qs_id);\n\tweight->dwrr = dwrr;\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic u32 hclge_tm_get_shapping_para(u8 ir_b, u8 ir_u, u8 ir_s,\n\t\t\t\t      u8 bs_b, u8 bs_s)\n{\n\tu32 shapping_para = 0;\n\n\thclge_tm_set_field(shapping_para, IR_B, ir_b);\n\thclge_tm_set_field(shapping_para, IR_U, ir_u);\n\thclge_tm_set_field(shapping_para, IR_S, ir_s);\n\thclge_tm_set_field(shapping_para, BS_B, bs_b);\n\thclge_tm_set_field(shapping_para, BS_S, bs_s);\n\n\treturn shapping_para;\n}\n\nstatic int hclge_tm_pg_shapping_cfg(struct hclge_dev *hdev,\n\t\t\t\t    enum hclge_shap_bucket bucket, u8 pg_id,\n\t\t\t\t    u32 shapping_para, u32 rate)\n{\n\tstruct hclge_pg_shapping_cmd *shap_cfg_cmd;\n\tenum hclge_opcode_type opcode;\n\tstruct hclge_desc desc;\n\n\topcode = bucket ? HCLGE_OPC_TM_PG_P_SHAPPING :\n\t\t HCLGE_OPC_TM_PG_C_SHAPPING;\n\thclge_cmd_setup_basic_desc(&desc, opcode, false);\n\n\tshap_cfg_cmd = (struct hclge_pg_shapping_cmd *)desc.data;\n\n\tshap_cfg_cmd->pg_id = pg_id;\n\n\tshap_cfg_cmd->pg_shapping_para = cpu_to_le32(shapping_para);\n\n\thnae3_set_bit(shap_cfg_cmd->flag, HCLGE_TM_RATE_VLD, 1);\n\n\tshap_cfg_cmd->pg_rate = cpu_to_le32(rate);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nint hclge_tm_port_shaper_cfg(struct hclge_dev *hdev)\n{\n\tstruct hclge_port_shapping_cmd *shap_cfg_cmd;\n\tstruct hclge_shaper_ir_para ir_para;\n\tstruct hclge_desc desc;\n\tu32 shapping_para;\n\tint ret;\n\n\tret = hclge_shaper_para_calc(hdev->hw.mac.speed, HCLGE_SHAPER_LVL_PORT,\n\t\t\t\t     &ir_para,\n\t\t\t\t     hdev->ae_dev->dev_specs.max_tm_rate);\n\tif (ret)\n\t\treturn ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PORT_SHAPPING, false);\n\tshap_cfg_cmd = (struct hclge_port_shapping_cmd *)desc.data;\n\n\tshapping_para = hclge_tm_get_shapping_para(ir_para.ir_b, ir_para.ir_u,\n\t\t\t\t\t\t   ir_para.ir_s,\n\t\t\t\t\t\t   HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t   HCLGE_SHAPER_BS_S_DEF);\n\n\tshap_cfg_cmd->port_shapping_para = cpu_to_le32(shapping_para);\n\n\thnae3_set_bit(shap_cfg_cmd->flag, HCLGE_TM_RATE_VLD, 1);\n\n\tshap_cfg_cmd->port_rate = cpu_to_le32(hdev->hw.mac.speed);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_pri_shapping_cfg(struct hclge_dev *hdev,\n\t\t\t\t     enum hclge_shap_bucket bucket, u8 pri_id,\n\t\t\t\t     u32 shapping_para, u32 rate)\n{\n\tstruct hclge_pri_shapping_cmd *shap_cfg_cmd;\n\tenum hclge_opcode_type opcode;\n\tstruct hclge_desc desc;\n\n\topcode = bucket ? HCLGE_OPC_TM_PRI_P_SHAPPING :\n\t\t HCLGE_OPC_TM_PRI_C_SHAPPING;\n\n\thclge_cmd_setup_basic_desc(&desc, opcode, false);\n\n\tshap_cfg_cmd = (struct hclge_pri_shapping_cmd *)desc.data;\n\n\tshap_cfg_cmd->pri_id = pri_id;\n\n\tshap_cfg_cmd->pri_shapping_para = cpu_to_le32(shapping_para);\n\n\thnae3_set_bit(shap_cfg_cmd->flag, HCLGE_TM_RATE_VLD, 1);\n\n\tshap_cfg_cmd->pri_rate = cpu_to_le32(rate);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_pg_schd_mode_cfg(struct hclge_dev *hdev, u8 pg_id)\n{\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PG_SCH_MODE_CFG, false);\n\n\tif (hdev->tm_info.pg_info[pg_id].pg_sch_mode == HCLGE_SCH_MODE_DWRR)\n\t\tdesc.data[1] = cpu_to_le32(HCLGE_TM_TX_SCHD_DWRR_MSK);\n\telse\n\t\tdesc.data[1] = 0;\n\n\tdesc.data[0] = cpu_to_le32(pg_id);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_pri_schd_mode_cfg(struct hclge_dev *hdev, u8 pri_id)\n{\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PRI_SCH_MODE_CFG, false);\n\n\tif (hdev->tm_info.tc_info[pri_id].tc_sch_mode == HCLGE_SCH_MODE_DWRR)\n\t\tdesc.data[1] = cpu_to_le32(HCLGE_TM_TX_SCHD_DWRR_MSK);\n\telse\n\t\tdesc.data[1] = 0;\n\n\tdesc.data[0] = cpu_to_le32(pri_id);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_qs_schd_mode_cfg(struct hclge_dev *hdev, u16 qs_id, u8 mode)\n{\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_QS_SCH_MODE_CFG, false);\n\n\tif (mode == HCLGE_SCH_MODE_DWRR)\n\t\tdesc.data[1] = cpu_to_le32(HCLGE_TM_TX_SCHD_DWRR_MSK);\n\telse\n\t\tdesc.data[1] = 0;\n\n\tdesc.data[0] = cpu_to_le32(qs_id);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_qs_bp_cfg(struct hclge_dev *hdev, u8 tc, u8 grp_id,\n\t\t\t      u32 bit_map)\n{\n\tstruct hclge_bp_to_qs_map_cmd *bp_to_qs_map_cmd;\n\tstruct hclge_desc desc;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_BP_TO_QSET_MAPPING,\n\t\t\t\t   false);\n\n\tbp_to_qs_map_cmd = (struct hclge_bp_to_qs_map_cmd *)desc.data;\n\n\tbp_to_qs_map_cmd->tc_id = tc;\n\tbp_to_qs_map_cmd->qs_group_id = grp_id;\n\tbp_to_qs_map_cmd->qs_bit_map = cpu_to_le32(bit_map);\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nint hclge_tm_qs_shaper_cfg(struct hclge_vport *vport, int max_tx_rate)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_qs_shapping_cmd *shap_cfg_cmd;\n\tstruct hclge_shaper_ir_para ir_para;\n\tstruct hclge_dev *hdev = vport->back;\n\tstruct hclge_desc desc;\n\tu32 shaper_para;\n\tint ret, i;\n\n\tif (!max_tx_rate)\n\t\tmax_tx_rate = hdev->ae_dev->dev_specs.max_tm_rate;\n\n\tret = hclge_shaper_para_calc(max_tx_rate, HCLGE_SHAPER_LVL_QSET,\n\t\t\t\t     &ir_para,\n\t\t\t\t     hdev->ae_dev->dev_specs.max_tm_rate);\n\tif (ret)\n\t\treturn ret;\n\n\tshaper_para = hclge_tm_get_shapping_para(ir_para.ir_b, ir_para.ir_u,\n\t\t\t\t\t\t ir_para.ir_s,\n\t\t\t\t\t\t HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t HCLGE_SHAPER_BS_S_DEF);\n\n\tfor (i = 0; i < kinfo->tc_info.num_tc; i++) {\n\t\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_QCN_SHAPPING_CFG,\n\t\t\t\t\t   false);\n\n\t\tshap_cfg_cmd = (struct hclge_qs_shapping_cmd *)desc.data;\n\t\tshap_cfg_cmd->qs_id = cpu_to_le16(vport->qs_offset + i);\n\t\tshap_cfg_cmd->qs_shapping_para = cpu_to_le32(shaper_para);\n\n\t\thnae3_set_bit(shap_cfg_cmd->flag, HCLGE_TM_RATE_VLD, 1);\n\t\tshap_cfg_cmd->qs_rate = cpu_to_le32(max_tx_rate);\n\n\t\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\t\tif (ret) {\n\t\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\t\"vport%u, qs%u failed to set tx_rate:%d, ret=%d\\n\",\n\t\t\t\tvport->vport_id, shap_cfg_cmd->qs_id,\n\t\t\t\tmax_tx_rate, ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic u16 hclge_vport_get_max_rss_size(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hnae3_tc_info *tc_info = &kinfo->tc_info;\n\tstruct hclge_dev *hdev = vport->back;\n\tu16 max_rss_size = 0;\n\tint i;\n\n\tif (!tc_info->mqprio_active)\n\t\treturn vport->alloc_tqps / tc_info->num_tc;\n\n\tfor (i = 0; i < HNAE3_MAX_TC; i++) {\n\t\tif (!(hdev->hw_tc_map & BIT(i)) || i >= tc_info->num_tc)\n\t\t\tcontinue;\n\t\tif (max_rss_size < tc_info->tqp_count[i])\n\t\t\tmax_rss_size = tc_info->tqp_count[i];\n\t}\n\n\treturn max_rss_size;\n}\n\nstatic u16 hclge_vport_get_tqp_num(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hnae3_tc_info *tc_info = &kinfo->tc_info;\n\tstruct hclge_dev *hdev = vport->back;\n\tint sum = 0;\n\tint i;\n\n\tif (!tc_info->mqprio_active)\n\t\treturn kinfo->rss_size * tc_info->num_tc;\n\n\tfor (i = 0; i < HNAE3_MAX_TC; i++) {\n\t\tif (hdev->hw_tc_map & BIT(i) && i < tc_info->num_tc)\n\t\t\tsum += tc_info->tqp_count[i];\n\t}\n\n\treturn sum;\n}\n\nstatic void hclge_tm_update_kinfo_rss_size(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_dev *hdev = vport->back;\n\tu16 vport_max_rss_size;\n\tu16 max_rss_size;\n\n\t \n\tif (vport->vport_id) {\n\t\tkinfo->tc_info.max_tc = 1;\n\t\tkinfo->tc_info.num_tc = 1;\n\t\tvport->qs_offset = HNAE3_MAX_TC +\n\t\t\t\t   vport->vport_id - HCLGE_VF_VPORT_START_NUM;\n\t\tvport_max_rss_size = hdev->vf_rss_size_max;\n\t} else {\n\t\tkinfo->tc_info.max_tc = hdev->tc_max;\n\t\tkinfo->tc_info.num_tc =\n\t\t\tmin_t(u16, vport->alloc_tqps, hdev->tm_info.num_tc);\n\t\tvport->qs_offset = 0;\n\t\tvport_max_rss_size = hdev->pf_rss_size_max;\n\t}\n\n\tmax_rss_size = min_t(u16, vport_max_rss_size,\n\t\t\t     hclge_vport_get_max_rss_size(vport));\n\n\t \n\tif (kinfo->req_rss_size != kinfo->rss_size && kinfo->req_rss_size &&\n\t    kinfo->req_rss_size <= max_rss_size) {\n\t\tdev_info(&hdev->pdev->dev, \"rss changes from %u to %u\\n\",\n\t\t\t kinfo->rss_size, kinfo->req_rss_size);\n\t\tkinfo->rss_size = kinfo->req_rss_size;\n\t} else if (kinfo->rss_size > max_rss_size ||\n\t\t   (!kinfo->req_rss_size && kinfo->rss_size < max_rss_size)) {\n\t\t \n\t\tkinfo->rss_size = max_rss_size;\n\t}\n}\n\nstatic void hclge_tm_vport_tc_info_update(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_dev *hdev = vport->back;\n\tu8 i;\n\n\thclge_tm_update_kinfo_rss_size(vport);\n\tkinfo->num_tqps = hclge_vport_get_tqp_num(vport);\n\tvport->dwrr = 100;   \n\tvport->bw_limit = hdev->tm_info.pg_info[0].bw_limit;\n\n\tif (vport->vport_id == PF_VPORT_ID)\n\t\thdev->rss_cfg.rss_size = kinfo->rss_size;\n\n\t \n\tif (kinfo->tc_info.mqprio_active)\n\t\treturn;\n\n\tfor (i = 0; i < HNAE3_MAX_TC; i++) {\n\t\tif (hdev->hw_tc_map & BIT(i) && i < kinfo->tc_info.num_tc) {\n\t\t\tkinfo->tc_info.tqp_offset[i] = i * kinfo->rss_size;\n\t\t\tkinfo->tc_info.tqp_count[i] = kinfo->rss_size;\n\t\t} else {\n\t\t\t \n\t\t\tkinfo->tc_info.tqp_offset[i] = 0;\n\t\t\tkinfo->tc_info.tqp_count[i] = 1;\n\t\t}\n\t}\n\n\tmemcpy(kinfo->tc_info.prio_tc, hdev->tm_info.prio_tc,\n\t       sizeof_field(struct hnae3_tc_info, prio_tc));\n}\n\nstatic void hclge_tm_vport_info_update(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tu32 i;\n\n\tfor (i = 0; i < hdev->num_alloc_vport; i++) {\n\t\thclge_tm_vport_tc_info_update(vport);\n\n\t\tvport++;\n\t}\n}\n\nstatic void hclge_tm_tc_info_init(struct hclge_dev *hdev)\n{\n\tu8 i, tc_sch_mode;\n\tu32 bw_limit;\n\n\tfor (i = 0; i < hdev->tc_max; i++) {\n\t\tif (i < hdev->tm_info.num_tc) {\n\t\t\ttc_sch_mode = HCLGE_SCH_MODE_DWRR;\n\t\t\tbw_limit = hdev->tm_info.pg_info[0].bw_limit;\n\t\t} else {\n\t\t\ttc_sch_mode = HCLGE_SCH_MODE_SP;\n\t\t\tbw_limit = 0;\n\t\t}\n\n\t\thdev->tm_info.tc_info[i].tc_id = i;\n\t\thdev->tm_info.tc_info[i].tc_sch_mode = tc_sch_mode;\n\t\thdev->tm_info.tc_info[i].pgid = 0;\n\t\thdev->tm_info.tc_info[i].bw_limit = bw_limit;\n\t}\n\n\tfor (i = 0; i < HNAE3_MAX_USER_PRIO; i++)\n\t\thdev->tm_info.prio_tc[i] =\n\t\t\t(i >= hdev->tm_info.num_tc) ? 0 : i;\n}\n\nstatic void hclge_tm_pg_info_init(struct hclge_dev *hdev)\n{\n#define BW_PERCENT\t100\n#define DEFAULT_BW_WEIGHT\t1\n\n\tu8 i;\n\n\tfor (i = 0; i < hdev->tm_info.num_pg; i++) {\n\t\tint k;\n\n\t\thdev->tm_info.pg_dwrr[i] = i ? 0 : BW_PERCENT;\n\n\t\thdev->tm_info.pg_info[i].pg_id = i;\n\t\thdev->tm_info.pg_info[i].pg_sch_mode = HCLGE_SCH_MODE_DWRR;\n\n\t\thdev->tm_info.pg_info[i].bw_limit =\n\t\t\t\t\thdev->ae_dev->dev_specs.max_tm_rate;\n\n\t\tif (i != 0)\n\t\t\tcontinue;\n\n\t\thdev->tm_info.pg_info[i].tc_bit_map = hdev->hw_tc_map;\n\t\tfor (k = 0; k < hdev->tm_info.num_tc; k++)\n\t\t\thdev->tm_info.pg_info[i].tc_dwrr[k] = BW_PERCENT;\n\t\tfor (; k < HNAE3_MAX_TC; k++)\n\t\t\thdev->tm_info.pg_info[i].tc_dwrr[k] = DEFAULT_BW_WEIGHT;\n\t}\n}\n\nstatic void hclge_update_fc_mode_by_dcb_flag(struct hclge_dev *hdev)\n{\n\tif (hdev->tm_info.num_tc == 1 && !hdev->tm_info.pfc_en) {\n\t\tif (hdev->fc_mode_last_time == HCLGE_FC_PFC)\n\t\t\tdev_warn(&hdev->pdev->dev,\n\t\t\t\t \"Only 1 tc used, but last mode is FC_PFC\\n\");\n\n\t\thdev->tm_info.fc_mode = hdev->fc_mode_last_time;\n\t} else if (hdev->tm_info.fc_mode != HCLGE_FC_PFC) {\n\t\t \n\t\thdev->fc_mode_last_time = hdev->tm_info.fc_mode;\n\t\thdev->tm_info.fc_mode = HCLGE_FC_PFC;\n\t}\n}\n\nstatic void hclge_update_fc_mode(struct hclge_dev *hdev)\n{\n\tif (!hdev->tm_info.pfc_en) {\n\t\thdev->tm_info.fc_mode = hdev->fc_mode_last_time;\n\t\treturn;\n\t}\n\n\tif (hdev->tm_info.fc_mode != HCLGE_FC_PFC) {\n\t\thdev->fc_mode_last_time = hdev->tm_info.fc_mode;\n\t\thdev->tm_info.fc_mode = HCLGE_FC_PFC;\n\t}\n}\n\nvoid hclge_tm_pfc_info_update(struct hclge_dev *hdev)\n{\n\tif (hdev->ae_dev->dev_version >= HNAE3_DEVICE_VERSION_V3)\n\t\thclge_update_fc_mode(hdev);\n\telse\n\t\thclge_update_fc_mode_by_dcb_flag(hdev);\n}\n\nstatic void hclge_tm_schd_info_init(struct hclge_dev *hdev)\n{\n\thclge_tm_pg_info_init(hdev);\n\n\thclge_tm_tc_info_init(hdev);\n\n\thclge_tm_vport_info_update(hdev);\n\n\thclge_tm_pfc_info_update(hdev);\n}\n\nstatic int hclge_tm_pg_to_pri_map(struct hclge_dev *hdev)\n{\n\tint ret;\n\tu32 i;\n\n\tif (hdev->tx_sch_mode != HCLGE_FLAG_TC_BASE_SCH_MODE)\n\t\treturn 0;\n\n\tfor (i = 0; i < hdev->tm_info.num_pg; i++) {\n\t\t \n\t\tret = hclge_tm_pg_to_pri_map_cfg(\n\t\t\thdev, i, hdev->tm_info.pg_info[i].tc_bit_map);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pg_shaper_cfg(struct hclge_dev *hdev)\n{\n\tu32 max_tm_rate = hdev->ae_dev->dev_specs.max_tm_rate;\n\tstruct hclge_shaper_ir_para ir_para;\n\tu32 shaper_para;\n\tint ret;\n\tu32 i;\n\n\t \n\tif (hdev->tx_sch_mode != HCLGE_FLAG_TC_BASE_SCH_MODE)\n\t\treturn 0;\n\n\t \n\tfor (i = 0; i < hdev->tm_info.num_pg; i++) {\n\t\tu32 rate = hdev->tm_info.pg_info[i].bw_limit;\n\n\t\t \n\t\tret = hclge_shaper_para_calc(rate, HCLGE_SHAPER_LVL_PG,\n\t\t\t\t\t     &ir_para, max_tm_rate);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tshaper_para = hclge_tm_get_shapping_para(0, 0, 0,\n\t\t\t\t\t\t\t HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t\t HCLGE_SHAPER_BS_S_DEF);\n\t\tret = hclge_tm_pg_shapping_cfg(hdev,\n\t\t\t\t\t       HCLGE_TM_SHAP_C_BUCKET, i,\n\t\t\t\t\t       shaper_para, rate);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tshaper_para = hclge_tm_get_shapping_para(ir_para.ir_b,\n\t\t\t\t\t\t\t ir_para.ir_u,\n\t\t\t\t\t\t\t ir_para.ir_s,\n\t\t\t\t\t\t\t HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t\t HCLGE_SHAPER_BS_S_DEF);\n\t\tret = hclge_tm_pg_shapping_cfg(hdev,\n\t\t\t\t\t       HCLGE_TM_SHAP_P_BUCKET, i,\n\t\t\t\t\t       shaper_para, rate);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pg_dwrr_cfg(struct hclge_dev *hdev)\n{\n\tint ret;\n\tu32 i;\n\n\t \n\tif (hdev->tx_sch_mode != HCLGE_FLAG_TC_BASE_SCH_MODE)\n\t\treturn 0;\n\n\t \n\tfor (i = 0; i < hdev->tm_info.num_pg; i++) {\n\t\t \n\t\tret = hclge_tm_pg_weight_cfg(hdev, i, hdev->tm_info.pg_dwrr[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_vport_q_to_qs_map(struct hclge_dev *hdev,\n\t\t\t\t   struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hnae3_tc_info *tc_info = &kinfo->tc_info;\n\tstruct hnae3_queue **tqp = kinfo->tqp;\n\tu32 i, j;\n\tint ret;\n\n\tfor (i = 0; i < tc_info->num_tc; i++) {\n\t\tfor (j = 0; j < tc_info->tqp_count[i]; j++) {\n\t\t\tstruct hnae3_queue *q = tqp[tc_info->tqp_offset[i] + j];\n\n\t\t\tret = hclge_tm_q_to_qs_map_cfg(hdev,\n\t\t\t\t\t\t       hclge_get_queue_id(q),\n\t\t\t\t\t\t       vport->qs_offset + i);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_q_qs_cfg_tc_base(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tu16 i, k;\n\tint ret;\n\n\t \n\tfor (k = 0; k < hdev->num_alloc_vport; k++) {\n\t\tstruct hnae3_knic_private_info *kinfo = &vport[k].nic.kinfo;\n\n\t\tfor (i = 0; i < kinfo->tc_info.max_tc; i++) {\n\t\t\tu8 pri = i < kinfo->tc_info.num_tc ? i : 0;\n\t\t\tbool link_vld = i < kinfo->tc_info.num_tc;\n\n\t\t\tret = hclge_tm_qs_to_pri_map_cfg(hdev,\n\t\t\t\t\t\t\t vport[k].qs_offset + i,\n\t\t\t\t\t\t\t pri, link_vld);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_q_qs_cfg_vnet_base(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tu16 i, k;\n\tint ret;\n\n\t \n\tfor (k = 0; k < hdev->num_alloc_vport; k++)\n\t\tfor (i = 0; i < HNAE3_MAX_TC; i++) {\n\t\t\tret = hclge_tm_qs_to_pri_map_cfg(hdev,\n\t\t\t\t\t\t\t vport[k].qs_offset + i,\n\t\t\t\t\t\t\t k, true);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_q_qs_cfg(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tint ret;\n\tu32 i;\n\n\tif (hdev->tx_sch_mode == HCLGE_FLAG_TC_BASE_SCH_MODE)\n\t\tret = hclge_tm_pri_q_qs_cfg_tc_base(hdev);\n\telse if (hdev->tx_sch_mode == HCLGE_FLAG_VNET_BASE_SCH_MODE)\n\t\tret = hclge_tm_pri_q_qs_cfg_vnet_base(hdev);\n\telse\n\t\treturn -EINVAL;\n\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tfor (i = 0; i < hdev->num_alloc_vport; i++) {\n\t\tret = hclge_vport_q_to_qs_map(hdev, vport);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tvport++;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_tc_base_shaper_cfg(struct hclge_dev *hdev)\n{\n\tu32 max_tm_rate = hdev->ae_dev->dev_specs.max_tm_rate;\n\tstruct hclge_shaper_ir_para ir_para;\n\tu32 shaper_para_c, shaper_para_p;\n\tint ret;\n\tu32 i;\n\n\tfor (i = 0; i < hdev->tc_max; i++) {\n\t\tu32 rate = hdev->tm_info.tc_info[i].bw_limit;\n\n\t\tif (rate) {\n\t\t\tret = hclge_shaper_para_calc(rate, HCLGE_SHAPER_LVL_PRI,\n\t\t\t\t\t\t     &ir_para, max_tm_rate);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tshaper_para_c = hclge_tm_get_shapping_para(0, 0, 0,\n\t\t\t\t\t\t\t\t   HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t\t\t   HCLGE_SHAPER_BS_S_DEF);\n\t\t\tshaper_para_p = hclge_tm_get_shapping_para(ir_para.ir_b,\n\t\t\t\t\t\t\t\t   ir_para.ir_u,\n\t\t\t\t\t\t\t\t   ir_para.ir_s,\n\t\t\t\t\t\t\t\t   HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t\t\t   HCLGE_SHAPER_BS_S_DEF);\n\t\t} else {\n\t\t\tshaper_para_c = 0;\n\t\t\tshaper_para_p = 0;\n\t\t}\n\n\t\tret = hclge_tm_pri_shapping_cfg(hdev, HCLGE_TM_SHAP_C_BUCKET, i,\n\t\t\t\t\t\tshaper_para_c, rate);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = hclge_tm_pri_shapping_cfg(hdev, HCLGE_TM_SHAP_P_BUCKET, i,\n\t\t\t\t\t\tshaper_para_p, rate);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_vnet_base_shaper_pri_cfg(struct hclge_vport *vport)\n{\n\tstruct hclge_dev *hdev = vport->back;\n\tstruct hclge_shaper_ir_para ir_para;\n\tu32 shaper_para;\n\tint ret;\n\n\tret = hclge_shaper_para_calc(vport->bw_limit, HCLGE_SHAPER_LVL_VF,\n\t\t\t\t     &ir_para,\n\t\t\t\t     hdev->ae_dev->dev_specs.max_tm_rate);\n\tif (ret)\n\t\treturn ret;\n\n\tshaper_para = hclge_tm_get_shapping_para(0, 0, 0,\n\t\t\t\t\t\t HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t HCLGE_SHAPER_BS_S_DEF);\n\tret = hclge_tm_pri_shapping_cfg(hdev, HCLGE_TM_SHAP_C_BUCKET,\n\t\t\t\t\tvport->vport_id, shaper_para,\n\t\t\t\t\tvport->bw_limit);\n\tif (ret)\n\t\treturn ret;\n\n\tshaper_para = hclge_tm_get_shapping_para(ir_para.ir_b, ir_para.ir_u,\n\t\t\t\t\t\t ir_para.ir_s,\n\t\t\t\t\t\t HCLGE_SHAPER_BS_U_DEF,\n\t\t\t\t\t\t HCLGE_SHAPER_BS_S_DEF);\n\tret = hclge_tm_pri_shapping_cfg(hdev, HCLGE_TM_SHAP_P_BUCKET,\n\t\t\t\t\tvport->vport_id, shaper_para,\n\t\t\t\t\tvport->bw_limit);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_vnet_base_shaper_qs_cfg(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_dev *hdev = vport->back;\n\tu32 max_tm_rate = hdev->ae_dev->dev_specs.max_tm_rate;\n\tstruct hclge_shaper_ir_para ir_para;\n\tu32 i;\n\tint ret;\n\n\tfor (i = 0; i < kinfo->tc_info.num_tc; i++) {\n\t\tret = hclge_shaper_para_calc(hdev->tm_info.tc_info[i].bw_limit,\n\t\t\t\t\t     HCLGE_SHAPER_LVL_QSET,\n\t\t\t\t\t     &ir_para, max_tm_rate);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_vnet_base_shaper_cfg(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tint ret;\n\tu32 i;\n\n\t \n\tfor (i = 0; i < hdev->num_alloc_vport; i++) {\n\t\tret = hclge_tm_pri_vnet_base_shaper_pri_cfg(vport);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = hclge_tm_pri_vnet_base_shaper_qs_cfg(vport);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tvport++;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_shaper_cfg(struct hclge_dev *hdev)\n{\n\tint ret;\n\n\tif (hdev->tx_sch_mode == HCLGE_FLAG_TC_BASE_SCH_MODE) {\n\t\tret = hclge_tm_pri_tc_base_shaper_cfg(hdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tret = hclge_tm_pri_vnet_base_shaper_cfg(hdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_tc_base_dwrr_cfg(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tstruct hclge_pg_info *pg_info;\n\tu8 dwrr;\n\tint ret;\n\tu32 i, k;\n\n\tfor (i = 0; i < hdev->tc_max; i++) {\n\t\tpg_info =\n\t\t\t&hdev->tm_info.pg_info[hdev->tm_info.tc_info[i].pgid];\n\t\tdwrr = pg_info->tc_dwrr[i];\n\n\t\tret = hclge_tm_pri_weight_cfg(hdev, i, dwrr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tfor (k = 0; k < hdev->num_alloc_vport; k++) {\n\t\t\tstruct hnae3_knic_private_info *kinfo = &vport[k].nic.kinfo;\n\n\t\t\tif (i >= kinfo->tc_info.max_tc)\n\t\t\t\tcontinue;\n\n\t\t\tdwrr = i < kinfo->tc_info.num_tc ? vport[k].dwrr : 0;\n\t\t\tret = hclge_tm_qs_weight_cfg(\n\t\t\t\thdev, vport[k].qs_offset + i,\n\t\t\t\tdwrr);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_ets_tc_dwrr_cfg(struct hclge_dev *hdev)\n{\n#define DEFAULT_TC_OFFSET\t14\n\n\tstruct hclge_ets_tc_weight_cmd *ets_weight;\n\tstruct hclge_desc desc;\n\tunsigned int i;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_ETS_TC_WEIGHT, false);\n\tets_weight = (struct hclge_ets_tc_weight_cmd *)desc.data;\n\n\tfor (i = 0; i < HNAE3_MAX_TC; i++) {\n\t\tstruct hclge_pg_info *pg_info;\n\n\t\tpg_info = &hdev->tm_info.pg_info[hdev->tm_info.tc_info[i].pgid];\n\t\tets_weight->tc_weight[i] = pg_info->tc_dwrr[i];\n\t}\n\n\tets_weight->weight_offset = DEFAULT_TC_OFFSET;\n\n\treturn hclge_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclge_tm_pri_vnet_base_dwrr_pri_cfg(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_dev *hdev = vport->back;\n\tint ret;\n\tu8 i;\n\n\t \n\tret = hclge_tm_pri_weight_cfg(hdev, vport->vport_id, vport->dwrr);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tfor (i = 0; i < kinfo->tc_info.num_tc; i++) {\n\t\tret = hclge_tm_qs_weight_cfg(\n\t\t\thdev, vport->qs_offset + i,\n\t\t\thdev->tm_info.pg_info[0].tc_dwrr[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_vnet_base_dwrr_cfg(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tint ret;\n\tu32 i;\n\n\tfor (i = 0; i < hdev->num_alloc_vport; i++) {\n\t\tret = hclge_tm_pri_vnet_base_dwrr_pri_cfg(vport);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tvport++;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_pri_dwrr_cfg(struct hclge_dev *hdev)\n{\n\tint ret;\n\n\tif (hdev->tx_sch_mode == HCLGE_FLAG_TC_BASE_SCH_MODE) {\n\t\tret = hclge_tm_pri_tc_base_dwrr_cfg(hdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!hnae3_dev_dcb_supported(hdev))\n\t\t\treturn 0;\n\n\t\tret = hclge_tm_ets_tc_dwrr_cfg(hdev);\n\t\tif (ret == -EOPNOTSUPP) {\n\t\t\tdev_warn(&hdev->pdev->dev,\n\t\t\t\t \"fw %08x doesn't support ets tc weight cmd\\n\",\n\t\t\t\t hdev->fw_version);\n\t\t\tret = 0;\n\t\t}\n\n\t\treturn ret;\n\t} else {\n\t\tret = hclge_tm_pri_vnet_base_dwrr_cfg(hdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_map_cfg(struct hclge_dev *hdev)\n{\n\tint ret;\n\n\tret = hclge_up_to_tc_map(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tif (hdev->vport[0].nic.kinfo.tc_map_mode == HNAE3_TC_MAP_MODE_DSCP) {\n\t\tret = hclge_dscp_to_tc_map(hdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = hclge_tm_pg_to_pri_map(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn hclge_tm_pri_q_qs_cfg(hdev);\n}\n\nstatic int hclge_tm_shaper_cfg(struct hclge_dev *hdev)\n{\n\tint ret;\n\n\tret = hclge_tm_port_shaper_cfg(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = hclge_tm_pg_shaper_cfg(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn hclge_tm_pri_shaper_cfg(hdev);\n}\n\nint hclge_tm_dwrr_cfg(struct hclge_dev *hdev)\n{\n\tint ret;\n\n\tret = hclge_tm_pg_dwrr_cfg(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn hclge_tm_pri_dwrr_cfg(hdev);\n}\n\nstatic int hclge_tm_lvl2_schd_mode_cfg(struct hclge_dev *hdev)\n{\n\tint ret;\n\tu8 i;\n\n\t \n\tif (hdev->tx_sch_mode == HCLGE_FLAG_VNET_BASE_SCH_MODE)\n\t\treturn 0;\n\n\tfor (i = 0; i < hdev->tm_info.num_pg; i++) {\n\t\tret = hclge_tm_pg_schd_mode_cfg(hdev, i);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_schd_mode_tc_base_cfg(struct hclge_dev *hdev, u8 pri_id)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tint ret;\n\tu8 mode;\n\tu16 i;\n\n\tret = hclge_tm_pri_schd_mode_cfg(hdev, pri_id);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < hdev->num_alloc_vport; i++) {\n\t\tstruct hnae3_knic_private_info *kinfo = &vport[i].nic.kinfo;\n\n\t\tif (pri_id >= kinfo->tc_info.max_tc)\n\t\t\tcontinue;\n\n\t\tmode = pri_id < kinfo->tc_info.num_tc ? HCLGE_SCH_MODE_DWRR :\n\t\t       HCLGE_SCH_MODE_SP;\n\t\tret = hclge_tm_qs_schd_mode_cfg(hdev,\n\t\t\t\t\t\tvport[i].qs_offset + pri_id,\n\t\t\t\t\t\tmode);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_schd_mode_vnet_base_cfg(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_dev *hdev = vport->back;\n\tint ret;\n\tu8 i;\n\n\tif (vport->vport_id >= HNAE3_MAX_TC)\n\t\treturn -EINVAL;\n\n\tret = hclge_tm_pri_schd_mode_cfg(hdev, vport->vport_id);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < kinfo->tc_info.num_tc; i++) {\n\t\tu8 sch_mode = hdev->tm_info.tc_info[i].tc_sch_mode;\n\n\t\tret = hclge_tm_qs_schd_mode_cfg(hdev, vport->qs_offset + i,\n\t\t\t\t\t\tsch_mode);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_lvl34_schd_mode_cfg(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tint ret;\n\tu8 i;\n\n\tif (hdev->tx_sch_mode == HCLGE_FLAG_TC_BASE_SCH_MODE) {\n\t\tfor (i = 0; i < hdev->tc_max; i++) {\n\t\t\tret = hclge_tm_schd_mode_tc_base_cfg(hdev, i);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < hdev->num_alloc_vport; i++) {\n\t\t\tret = hclge_tm_schd_mode_vnet_base_cfg(vport);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tvport++;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int hclge_tm_schd_mode_hw(struct hclge_dev *hdev)\n{\n\tint ret;\n\n\tret = hclge_tm_lvl2_schd_mode_cfg(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn hclge_tm_lvl34_schd_mode_cfg(hdev);\n}\n\nint hclge_tm_schd_setup_hw(struct hclge_dev *hdev)\n{\n\tint ret;\n\n\t \n\tret = hclge_tm_map_cfg(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = hclge_tm_shaper_cfg(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = hclge_tm_dwrr_cfg(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = hclge_tm_schd_mode_hw(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn hclge_tm_flush_cfg(hdev, false);\n}\n\nstatic int hclge_pause_param_setup_hw(struct hclge_dev *hdev)\n{\n\tstruct hclge_mac *mac = &hdev->hw.mac;\n\n\treturn hclge_pause_param_cfg(hdev, mac->mac_addr,\n\t\t\t\t     HCLGE_DEFAULT_PAUSE_TRANS_GAP,\n\t\t\t\t     HCLGE_DEFAULT_PAUSE_TRANS_TIME);\n}\n\nstatic int hclge_pfc_setup_hw(struct hclge_dev *hdev)\n{\n\tu8 enable_bitmap = 0;\n\n\tif (hdev->tm_info.fc_mode == HCLGE_FC_PFC)\n\t\tenable_bitmap = HCLGE_TX_MAC_PAUSE_EN_MSK |\n\t\t\t\tHCLGE_RX_MAC_PAUSE_EN_MSK;\n\n\treturn hclge_pfc_pause_en_cfg(hdev, enable_bitmap,\n\t\t\t\t      hdev->tm_info.pfc_en);\n}\n\n \nstatic int hclge_bp_setup_hw(struct hclge_dev *hdev, u8 tc)\n{\n\tu16 grp_id_shift = HCLGE_BP_GRP_ID_S;\n\tu16 grp_id_mask = HCLGE_BP_GRP_ID_M;\n\tu8 grp_num = HCLGE_BP_GRP_NUM;\n\tint i;\n\n\tif (hdev->num_tqps > HCLGE_TQP_MAX_SIZE_DEV_V2) {\n\t\tgrp_num = HCLGE_BP_EXT_GRP_NUM;\n\t\tgrp_id_mask = HCLGE_BP_EXT_GRP_ID_M;\n\t\tgrp_id_shift = HCLGE_BP_EXT_GRP_ID_S;\n\t}\n\n\tfor (i = 0; i < grp_num; i++) {\n\t\tu32 qs_bitmap = 0;\n\t\tint k, ret;\n\n\t\tfor (k = 0; k < hdev->num_alloc_vport; k++) {\n\t\t\tstruct hclge_vport *vport = &hdev->vport[k];\n\t\t\tu16 qs_id = vport->qs_offset + tc;\n\t\t\tu8 grp, sub_grp;\n\n\t\t\tgrp = hnae3_get_field(qs_id, grp_id_mask, grp_id_shift);\n\t\t\tsub_grp = hnae3_get_field(qs_id, HCLGE_BP_SUB_GRP_ID_M,\n\t\t\t\t\t\t  HCLGE_BP_SUB_GRP_ID_S);\n\t\t\tif (i == grp)\n\t\t\t\tqs_bitmap |= (1 << sub_grp);\n\t\t}\n\n\t\tret = hclge_tm_qs_bp_cfg(hdev, tc, i, qs_bitmap);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint hclge_mac_pause_setup_hw(struct hclge_dev *hdev)\n{\n\tbool tx_en, rx_en;\n\n\tswitch (hdev->tm_info.fc_mode) {\n\tcase HCLGE_FC_NONE:\n\t\ttx_en = false;\n\t\trx_en = false;\n\t\tbreak;\n\tcase HCLGE_FC_RX_PAUSE:\n\t\ttx_en = false;\n\t\trx_en = true;\n\t\tbreak;\n\tcase HCLGE_FC_TX_PAUSE:\n\t\ttx_en = true;\n\t\trx_en = false;\n\t\tbreak;\n\tcase HCLGE_FC_FULL:\n\t\ttx_en = true;\n\t\trx_en = true;\n\t\tbreak;\n\tcase HCLGE_FC_PFC:\n\t\ttx_en = false;\n\t\trx_en = false;\n\t\tbreak;\n\tdefault:\n\t\ttx_en = true;\n\t\trx_en = true;\n\t}\n\n\treturn hclge_mac_pause_en_cfg(hdev, tx_en, rx_en);\n}\n\nstatic int hclge_tm_bp_setup(struct hclge_dev *hdev)\n{\n\tint ret;\n\tint i;\n\n\tfor (i = 0; i < hdev->tm_info.num_tc; i++) {\n\t\tret = hclge_bp_setup_hw(hdev, i);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint hclge_pause_setup_hw(struct hclge_dev *hdev, bool init)\n{\n\tint ret;\n\n\tret = hclge_pause_param_setup_hw(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = hclge_mac_pause_setup_hw(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (!hnae3_dev_dcb_supported(hdev))\n\t\treturn 0;\n\n\t \n\tret = hclge_pfc_setup_hw(hdev);\n\tif (init && ret == -EOPNOTSUPP)\n\t\tdev_warn(&hdev->pdev->dev, \"GE MAC does not support pfc\\n\");\n\telse if (ret) {\n\t\tdev_err(&hdev->pdev->dev, \"config pfc failed! ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\treturn hclge_tm_bp_setup(hdev);\n}\n\nvoid hclge_tm_prio_tc_info_update(struct hclge_dev *hdev, u8 *prio_tc)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tstruct hnae3_knic_private_info *kinfo;\n\tu32 i, k;\n\n\tfor (i = 0; i < HNAE3_MAX_USER_PRIO; i++) {\n\t\thdev->tm_info.prio_tc[i] = prio_tc[i];\n\n\t\tfor (k = 0;  k < hdev->num_alloc_vport; k++) {\n\t\t\tkinfo = &vport[k].nic.kinfo;\n\t\t\tkinfo->tc_info.prio_tc[i] = prio_tc[i];\n\t\t}\n\t}\n}\n\nvoid hclge_tm_schd_info_update(struct hclge_dev *hdev, u8 num_tc)\n{\n\tu8 bit_map = 0;\n\tu8 i;\n\n\thdev->tm_info.num_tc = num_tc;\n\n\tfor (i = 0; i < hdev->tm_info.num_tc; i++)\n\t\tbit_map |= BIT(i);\n\n\tif (!bit_map) {\n\t\tbit_map = 1;\n\t\thdev->tm_info.num_tc = 1;\n\t}\n\n\thdev->hw_tc_map = bit_map;\n\n\thclge_tm_schd_info_init(hdev);\n}\n\nint hclge_tm_init_hw(struct hclge_dev *hdev, bool init)\n{\n\tint ret;\n\n\tif ((hdev->tx_sch_mode != HCLGE_FLAG_TC_BASE_SCH_MODE) &&\n\t    (hdev->tx_sch_mode != HCLGE_FLAG_VNET_BASE_SCH_MODE))\n\t\treturn -ENOTSUPP;\n\n\tret = hclge_tm_schd_setup_hw(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = hclge_pause_setup_hw(hdev, init);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nint hclge_tm_schd_init(struct hclge_dev *hdev)\n{\n\t \n\thdev->tm_info.fc_mode = HCLGE_FC_FULL;\n\thdev->fc_mode_last_time = hdev->tm_info.fc_mode;\n\n\tif (hdev->tx_sch_mode != HCLGE_FLAG_TC_BASE_SCH_MODE &&\n\t    hdev->tm_info.num_pg != 1)\n\t\treturn -EINVAL;\n\n\thclge_tm_schd_info_init(hdev);\n\thclge_dscp_to_prio_map_init(hdev);\n\n\treturn hclge_tm_init_hw(hdev, true);\n}\n\nint hclge_tm_vport_map_update(struct hclge_dev *hdev)\n{\n\tstruct hclge_vport *vport = hdev->vport;\n\tint ret;\n\n\thclge_tm_vport_tc_info_update(vport);\n\n\tret = hclge_vport_q_to_qs_map(hdev, vport);\n\tif (ret)\n\t\treturn ret;\n\n\tif (hdev->tm_info.num_tc == 1 && !hdev->tm_info.pfc_en)\n\t\treturn 0;\n\n\treturn hclge_tm_bp_setup(hdev);\n}\n\nint hclge_tm_get_qset_num(struct hclge_dev *hdev, u16 *qset_num)\n{\n\tstruct hclge_tm_nodes_cmd *nodes;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\tif (hdev->ae_dev->dev_version <= HNAE3_DEVICE_VERSION_V2) {\n\t\t \n\t\t*qset_num = HCLGE_TM_PF_MAX_QSET_NUM + pci_num_vf(hdev->pdev);\n\t\treturn 0;\n\t}\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_NODES, true);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get qset num, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tnodes = (struct hclge_tm_nodes_cmd *)desc.data;\n\t*qset_num = le16_to_cpu(nodes->qset_num);\n\treturn 0;\n}\n\nint hclge_tm_get_pri_num(struct hclge_dev *hdev, u8 *pri_num)\n{\n\tstruct hclge_tm_nodes_cmd *nodes;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\tif (hdev->ae_dev->dev_version <= HNAE3_DEVICE_VERSION_V2) {\n\t\t*pri_num = HCLGE_TM_PF_MAX_PRI_NUM;\n\t\treturn 0;\n\t}\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_NODES, true);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get pri num, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tnodes = (struct hclge_tm_nodes_cmd *)desc.data;\n\t*pri_num = nodes->pri_num;\n\treturn 0;\n}\n\nint hclge_tm_get_qset_map_pri(struct hclge_dev *hdev, u16 qset_id, u8 *priority,\n\t\t\t      u8 *link_vld)\n{\n\tstruct hclge_qs_to_pri_link_cmd *map;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_QS_TO_PRI_LINK, true);\n\tmap = (struct hclge_qs_to_pri_link_cmd *)desc.data;\n\tmap->qs_id = cpu_to_le16(qset_id);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get qset map priority, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*priority = map->priority;\n\t*link_vld = map->link_vld;\n\treturn 0;\n}\n\nint hclge_tm_get_qset_sch_mode(struct hclge_dev *hdev, u16 qset_id, u8 *mode)\n{\n\tstruct hclge_qs_sch_mode_cfg_cmd *qs_sch_mode;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_QS_SCH_MODE_CFG, true);\n\tqs_sch_mode = (struct hclge_qs_sch_mode_cfg_cmd *)desc.data;\n\tqs_sch_mode->qs_id = cpu_to_le16(qset_id);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get qset sch mode, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*mode = qs_sch_mode->sch_mode;\n\treturn 0;\n}\n\nint hclge_tm_get_qset_weight(struct hclge_dev *hdev, u16 qset_id, u8 *weight)\n{\n\tstruct hclge_qs_weight_cmd *qs_weight;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_QS_WEIGHT, true);\n\tqs_weight = (struct hclge_qs_weight_cmd *)desc.data;\n\tqs_weight->qs_id = cpu_to_le16(qset_id);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get qset weight, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*weight = qs_weight->dwrr;\n\treturn 0;\n}\n\nint hclge_tm_get_qset_shaper(struct hclge_dev *hdev, u16 qset_id,\n\t\t\t     struct hclge_tm_shaper_para *para)\n{\n\tstruct hclge_qs_shapping_cmd *shap_cfg_cmd;\n\tstruct hclge_desc desc;\n\tu32 shapping_para;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_QCN_SHAPPING_CFG, true);\n\tshap_cfg_cmd = (struct hclge_qs_shapping_cmd *)desc.data;\n\tshap_cfg_cmd->qs_id = cpu_to_le16(qset_id);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get qset %u shaper, ret = %d\\n\", qset_id,\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tshapping_para = le32_to_cpu(shap_cfg_cmd->qs_shapping_para);\n\tpara->ir_b = hclge_tm_get_field(shapping_para, IR_B);\n\tpara->ir_u = hclge_tm_get_field(shapping_para, IR_U);\n\tpara->ir_s = hclge_tm_get_field(shapping_para, IR_S);\n\tpara->bs_b = hclge_tm_get_field(shapping_para, BS_B);\n\tpara->bs_s = hclge_tm_get_field(shapping_para, BS_S);\n\tpara->flag = shap_cfg_cmd->flag;\n\tpara->rate = le32_to_cpu(shap_cfg_cmd->qs_rate);\n\treturn 0;\n}\n\nint hclge_tm_get_pri_sch_mode(struct hclge_dev *hdev, u8 pri_id, u8 *mode)\n{\n\tstruct hclge_pri_sch_mode_cfg_cmd *pri_sch_mode;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PRI_SCH_MODE_CFG, true);\n\tpri_sch_mode = (struct hclge_pri_sch_mode_cfg_cmd *)desc.data;\n\tpri_sch_mode->pri_id = pri_id;\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get priority sch mode, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*mode = pri_sch_mode->sch_mode;\n\treturn 0;\n}\n\nint hclge_tm_get_pri_weight(struct hclge_dev *hdev, u8 pri_id, u8 *weight)\n{\n\tstruct hclge_priority_weight_cmd *priority_weight;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PRI_WEIGHT, true);\n\tpriority_weight = (struct hclge_priority_weight_cmd *)desc.data;\n\tpriority_weight->pri_id = pri_id;\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get priority weight, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*weight = priority_weight->dwrr;\n\treturn 0;\n}\n\nint hclge_tm_get_pri_shaper(struct hclge_dev *hdev, u8 pri_id,\n\t\t\t    enum hclge_opcode_type cmd,\n\t\t\t    struct hclge_tm_shaper_para *para)\n{\n\tstruct hclge_pri_shapping_cmd *shap_cfg_cmd;\n\tstruct hclge_desc desc;\n\tu32 shapping_para;\n\tint ret;\n\n\tif (cmd != HCLGE_OPC_TM_PRI_C_SHAPPING &&\n\t    cmd != HCLGE_OPC_TM_PRI_P_SHAPPING)\n\t\treturn -EINVAL;\n\n\thclge_cmd_setup_basic_desc(&desc, cmd, true);\n\tshap_cfg_cmd = (struct hclge_pri_shapping_cmd *)desc.data;\n\tshap_cfg_cmd->pri_id = pri_id;\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get priority shaper(%#x), ret = %d\\n\",\n\t\t\tcmd, ret);\n\t\treturn ret;\n\t}\n\n\tshapping_para = le32_to_cpu(shap_cfg_cmd->pri_shapping_para);\n\tpara->ir_b = hclge_tm_get_field(shapping_para, IR_B);\n\tpara->ir_u = hclge_tm_get_field(shapping_para, IR_U);\n\tpara->ir_s = hclge_tm_get_field(shapping_para, IR_S);\n\tpara->bs_b = hclge_tm_get_field(shapping_para, BS_B);\n\tpara->bs_s = hclge_tm_get_field(shapping_para, BS_S);\n\tpara->flag = shap_cfg_cmd->flag;\n\tpara->rate = le32_to_cpu(shap_cfg_cmd->pri_rate);\n\treturn 0;\n}\n\nint hclge_tm_get_q_to_qs_map(struct hclge_dev *hdev, u16 q_id, u16 *qset_id)\n{\n\tstruct hclge_nq_to_qs_link_cmd *map;\n\tstruct hclge_desc desc;\n\tu16 qs_id_l;\n\tu16 qs_id_h;\n\tint ret;\n\n\tmap = (struct hclge_nq_to_qs_link_cmd *)desc.data;\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_NQ_TO_QS_LINK, true);\n\tmap->nq_id = cpu_to_le16(q_id);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get queue to qset map, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\t*qset_id = le16_to_cpu(map->qset_id);\n\n\t \n\tqs_id_l = hnae3_get_field(*qset_id, HCLGE_TM_QS_ID_L_MSK,\n\t\t\t\t  HCLGE_TM_QS_ID_L_S);\n\tqs_id_h = hnae3_get_field(*qset_id, HCLGE_TM_QS_ID_H_EXT_MSK,\n\t\t\t\t  HCLGE_TM_QS_ID_H_EXT_S);\n\t*qset_id = 0;\n\thnae3_set_field(*qset_id, HCLGE_TM_QS_ID_L_MSK, HCLGE_TM_QS_ID_L_S,\n\t\t\tqs_id_l);\n\thnae3_set_field(*qset_id, HCLGE_TM_QS_ID_H_MSK, HCLGE_TM_QS_ID_H_S,\n\t\t\tqs_id_h);\n\treturn 0;\n}\n\nint hclge_tm_get_q_to_tc(struct hclge_dev *hdev, u16 q_id, u8 *tc_id)\n{\n#define HCLGE_TM_TC_MASK\t\t0x7\n\n\tstruct hclge_tqp_tx_queue_tc_cmd *tc;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\ttc = (struct hclge_tqp_tx_queue_tc_cmd *)desc.data;\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TQP_TX_QUEUE_TC, true);\n\ttc->queue_id = cpu_to_le16(q_id);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get queue to tc map, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*tc_id = tc->tc_id & HCLGE_TM_TC_MASK;\n\treturn 0;\n}\n\nint hclge_tm_get_pg_to_pri_map(struct hclge_dev *hdev, u8 pg_id,\n\t\t\t       u8 *pri_bit_map)\n{\n\tstruct hclge_pg_to_pri_link_cmd *map;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PG_TO_PRI_LINK, true);\n\tmap = (struct hclge_pg_to_pri_link_cmd *)desc.data;\n\tmap->pg_id = pg_id;\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get pg to pri map, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*pri_bit_map = map->pri_bit_map;\n\treturn 0;\n}\n\nint hclge_tm_get_pg_weight(struct hclge_dev *hdev, u8 pg_id, u8 *weight)\n{\n\tstruct hclge_pg_weight_cmd *pg_weight_cmd;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PG_WEIGHT, true);\n\tpg_weight_cmd = (struct hclge_pg_weight_cmd *)desc.data;\n\tpg_weight_cmd->pg_id = pg_id;\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get pg weight, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*weight = pg_weight_cmd->dwrr;\n\treturn 0;\n}\n\nint hclge_tm_get_pg_sch_mode(struct hclge_dev *hdev, u8 pg_id, u8 *mode)\n{\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PG_SCH_MODE_CFG, true);\n\tdesc.data[0] = cpu_to_le32(pg_id);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get pg sch mode, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t*mode = (u8)le32_to_cpu(desc.data[1]);\n\treturn 0;\n}\n\nint hclge_tm_get_pg_shaper(struct hclge_dev *hdev, u8 pg_id,\n\t\t\t   enum hclge_opcode_type cmd,\n\t\t\t   struct hclge_tm_shaper_para *para)\n{\n\tstruct hclge_pg_shapping_cmd *shap_cfg_cmd;\n\tstruct hclge_desc desc;\n\tu32 shapping_para;\n\tint ret;\n\n\tif (cmd != HCLGE_OPC_TM_PG_C_SHAPPING &&\n\t    cmd != HCLGE_OPC_TM_PG_P_SHAPPING)\n\t\treturn -EINVAL;\n\n\thclge_cmd_setup_basic_desc(&desc, cmd, true);\n\tshap_cfg_cmd = (struct hclge_pg_shapping_cmd *)desc.data;\n\tshap_cfg_cmd->pg_id = pg_id;\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get pg shaper(%#x), ret = %d\\n\",\n\t\t\tcmd, ret);\n\t\treturn ret;\n\t}\n\n\tshapping_para = le32_to_cpu(shap_cfg_cmd->pg_shapping_para);\n\tpara->ir_b = hclge_tm_get_field(shapping_para, IR_B);\n\tpara->ir_u = hclge_tm_get_field(shapping_para, IR_U);\n\tpara->ir_s = hclge_tm_get_field(shapping_para, IR_S);\n\tpara->bs_b = hclge_tm_get_field(shapping_para, BS_B);\n\tpara->bs_s = hclge_tm_get_field(shapping_para, BS_S);\n\tpara->flag = shap_cfg_cmd->flag;\n\tpara->rate = le32_to_cpu(shap_cfg_cmd->pg_rate);\n\treturn 0;\n}\n\nint hclge_tm_get_port_shaper(struct hclge_dev *hdev,\n\t\t\t     struct hclge_tm_shaper_para *para)\n{\n\tstruct hclge_port_shapping_cmd *port_shap_cfg_cmd;\n\tstruct hclge_desc desc;\n\tu32 shapping_para;\n\tint ret;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_PORT_SHAPPING, true);\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get port shaper, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tport_shap_cfg_cmd = (struct hclge_port_shapping_cmd *)desc.data;\n\tshapping_para = le32_to_cpu(port_shap_cfg_cmd->port_shapping_para);\n\tpara->ir_b = hclge_tm_get_field(shapping_para, IR_B);\n\tpara->ir_u = hclge_tm_get_field(shapping_para, IR_U);\n\tpara->ir_s = hclge_tm_get_field(shapping_para, IR_S);\n\tpara->bs_b = hclge_tm_get_field(shapping_para, BS_B);\n\tpara->bs_s = hclge_tm_get_field(shapping_para, BS_S);\n\tpara->flag = port_shap_cfg_cmd->flag;\n\tpara->rate = le32_to_cpu(port_shap_cfg_cmd->port_rate);\n\n\treturn 0;\n}\n\nint hclge_tm_flush_cfg(struct hclge_dev *hdev, bool enable)\n{\n\tstruct hclge_desc desc;\n\tint ret;\n\n\tif (!hnae3_ae_dev_tm_flush_supported(hdev))\n\t\treturn 0;\n\n\thclge_cmd_setup_basic_desc(&desc, HCLGE_OPC_TM_FLUSH, false);\n\n\tdesc.data[0] = cpu_to_le32(enable ? HCLGE_TM_FLUSH_EN_MSK : 0);\n\n\tret = hclge_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to config tm flush, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (enable)\n\t\tmsleep(HCLGE_TM_FLUSH_TIME_MS);\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}