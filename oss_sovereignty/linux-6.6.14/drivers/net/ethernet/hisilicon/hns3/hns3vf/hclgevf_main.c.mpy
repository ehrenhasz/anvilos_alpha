{
  "module_name": "hclgevf_main.c",
  "hash_id": "8a01a600712f90f2ab99166a7619b93ffccae6c947bcc480742688334cf71d3a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c",
  "human_readable_source": "\n\n\n#include <linux/etherdevice.h>\n#include <linux/iopoll.h>\n#include <net/rtnetlink.h>\n#include \"hclgevf_cmd.h\"\n#include \"hclgevf_main.h\"\n#include \"hclgevf_regs.h\"\n#include \"hclge_mbx.h\"\n#include \"hnae3.h\"\n#include \"hclgevf_devlink.h\"\n#include \"hclge_comm_rss.h\"\n\n#define HCLGEVF_NAME\t\"hclgevf\"\n\n#define HCLGEVF_RESET_MAX_FAIL_CNT\t5\n\nstatic int hclgevf_reset_hdev(struct hclgevf_dev *hdev);\nstatic void hclgevf_task_schedule(struct hclgevf_dev *hdev,\n\t\t\t\t  unsigned long delay);\n\nstatic struct hnae3_ae_algo ae_algovf;\n\nstatic struct workqueue_struct *hclgevf_wq;\n\nstatic const struct pci_device_id ae_algovf_pci_tbl[] = {\n\t{PCI_VDEVICE(HUAWEI, HNAE3_DEV_ID_VF), 0},\n\t{PCI_VDEVICE(HUAWEI, HNAE3_DEV_ID_RDMA_DCB_PFC_VF),\n\t HNAE3_DEV_SUPPORT_ROCE_DCB_BITS},\n\t \n\t{0, }\n};\n\nMODULE_DEVICE_TABLE(pci, ae_algovf_pci_tbl);\n\n \nint hclgevf_cmd_send(struct hclgevf_hw *hw, struct hclge_desc *desc, int num)\n{\n\treturn hclge_comm_cmd_send(&hw->hw, desc, num);\n}\n\nvoid hclgevf_arq_init(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_comm_cmq *cmdq = &hdev->hw.hw.cmq;\n\n\tspin_lock(&cmdq->crq.lock);\n\t \n\thdev->arq.hdev = hdev;\n\thdev->arq.head = 0;\n\thdev->arq.tail = 0;\n\tatomic_set(&hdev->arq.count, 0);\n\tspin_unlock(&cmdq->crq.lock);\n}\n\nstruct hclgevf_dev *hclgevf_ae_get_hdev(struct hnae3_handle *handle)\n{\n\tif (!handle->client)\n\t\treturn container_of(handle, struct hclgevf_dev, nic);\n\telse if (handle->client->type == HNAE3_CLIENT_ROCE)\n\t\treturn container_of(handle, struct hclgevf_dev, roce);\n\telse\n\t\treturn container_of(handle, struct hclgevf_dev, nic);\n}\n\nstatic void hclgevf_update_stats(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tint status;\n\n\tstatus = hclge_comm_tqps_update_stats(handle, &hdev->hw.hw);\n\tif (status)\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF update of TQPS stats fail, status = %d.\\n\",\n\t\t\tstatus);\n}\n\nstatic int hclgevf_get_sset_count(struct hnae3_handle *handle, int strset)\n{\n\tif (strset == ETH_SS_TEST)\n\t\treturn -EOPNOTSUPP;\n\telse if (strset == ETH_SS_STATS)\n\t\treturn hclge_comm_tqps_get_sset_count(handle);\n\n\treturn 0;\n}\n\nstatic void hclgevf_get_strings(struct hnae3_handle *handle, u32 strset,\n\t\t\t\tu8 *data)\n{\n\tu8 *p = (char *)data;\n\n\tif (strset == ETH_SS_STATS)\n\t\tp = hclge_comm_tqps_get_strings(handle, p);\n}\n\nstatic void hclgevf_get_stats(struct hnae3_handle *handle, u64 *data)\n{\n\thclge_comm_tqps_get_stats(handle, data);\n}\n\nstatic void hclgevf_build_send_msg(struct hclge_vf_to_pf_msg *msg, u8 code,\n\t\t\t\t   u8 subcode)\n{\n\tif (msg) {\n\t\tmemset(msg, 0, sizeof(struct hclge_vf_to_pf_msg));\n\t\tmsg->code = code;\n\t\tmsg->subcode = subcode;\n\t}\n}\n\nstatic int hclgevf_get_basic_info(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_ae_dev *ae_dev = hdev->ae_dev;\n\tu8 resp_msg[HCLGE_MBX_MAX_RESP_DATA_SIZE];\n\tstruct hclge_basic_info *basic_info;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tunsigned long caps;\n\tint status;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_BASIC_INFO, 0);\n\tstatus = hclgevf_send_mbx_msg(hdev, &send_msg, true, resp_msg,\n\t\t\t\t      sizeof(resp_msg));\n\tif (status) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to get basic info from pf, ret = %d\", status);\n\t\treturn status;\n\t}\n\n\tbasic_info = (struct hclge_basic_info *)resp_msg;\n\n\thdev->hw_tc_map = basic_info->hw_tc_map;\n\thdev->mbx_api_version = le16_to_cpu(basic_info->mbx_api_version);\n\tcaps = le32_to_cpu(basic_info->pf_caps);\n\tif (test_bit(HNAE3_PF_SUPPORT_VLAN_FLTR_MDF_B, &caps))\n\t\tset_bit(HNAE3_DEV_SUPPORT_VLAN_FLTR_MDF_B, ae_dev->caps);\n\n\treturn 0;\n}\n\nstatic int hclgevf_get_port_base_vlan_filter_state(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_handle *nic = &hdev->nic;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu8 resp_msg;\n\tint ret;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_VLAN,\n\t\t\t       HCLGE_MBX_GET_PORT_BASE_VLAN_STATE);\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, &resp_msg,\n\t\t\t\t   sizeof(u8));\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF request to get port based vlan state failed %d\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tnic->port_base_vlan_state = resp_msg;\n\n\treturn 0;\n}\n\nstatic int hclgevf_get_queue_info(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_TQPS_RSS_INFO_LEN\t6\n\n\tstruct hclge_mbx_vf_queue_info *queue_info;\n\tu8 resp_msg[HCLGEVF_TQPS_RSS_INFO_LEN];\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tint status;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_QINFO, 0);\n\tstatus = hclgevf_send_mbx_msg(hdev, &send_msg, true, resp_msg,\n\t\t\t\t      HCLGEVF_TQPS_RSS_INFO_LEN);\n\tif (status) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF request to get tqp info from PF failed %d\",\n\t\t\tstatus);\n\t\treturn status;\n\t}\n\n\tqueue_info = (struct hclge_mbx_vf_queue_info *)resp_msg;\n\thdev->num_tqps = le16_to_cpu(queue_info->num_tqps);\n\thdev->rss_size_max = le16_to_cpu(queue_info->rss_size);\n\thdev->rx_buf_len = le16_to_cpu(queue_info->rx_buf_len);\n\n\treturn 0;\n}\n\nstatic int hclgevf_get_queue_depth(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_TQPS_DEPTH_INFO_LEN\t4\n\n\tstruct hclge_mbx_vf_queue_depth *queue_depth;\n\tu8 resp_msg[HCLGEVF_TQPS_DEPTH_INFO_LEN];\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tint ret;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_QDEPTH, 0);\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, resp_msg,\n\t\t\t\t   HCLGEVF_TQPS_DEPTH_INFO_LEN);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF request to get tqp depth info from PF failed %d\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\tqueue_depth = (struct hclge_mbx_vf_queue_depth *)resp_msg;\n\thdev->num_tx_desc = le16_to_cpu(queue_depth->num_tx_desc);\n\thdev->num_rx_desc = le16_to_cpu(queue_depth->num_rx_desc);\n\n\treturn 0;\n}\n\nstatic u16 hclgevf_get_qid_global(struct hnae3_handle *handle, u16 queue_id)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu16 qid_in_pf = 0;\n\tu8 resp_data[2];\n\tint ret;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_QID_IN_PF, 0);\n\t*(__le16 *)send_msg.data = cpu_to_le16(queue_id);\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, resp_data,\n\t\t\t\t   sizeof(resp_data));\n\tif (!ret)\n\t\tqid_in_pf = le16_to_cpu(*(__le16 *)resp_data);\n\n\treturn qid_in_pf;\n}\n\nstatic int hclgevf_get_pf_media_type(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu8 resp_msg[2];\n\tint ret;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_MEDIA_TYPE, 0);\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, resp_msg,\n\t\t\t\t   sizeof(resp_msg));\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF request to get the pf port media type failed %d\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\thdev->hw.mac.media_type = resp_msg[0];\n\thdev->hw.mac.module_type = resp_msg[1];\n\n\treturn 0;\n}\n\nstatic int hclgevf_alloc_tqps(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_ae_dev *ae_dev = pci_get_drvdata(hdev->pdev);\n\tstruct hclge_comm_tqp *tqp;\n\tint i;\n\n\thdev->htqp = devm_kcalloc(&hdev->pdev->dev, hdev->num_tqps,\n\t\t\t\t  sizeof(struct hclge_comm_tqp), GFP_KERNEL);\n\tif (!hdev->htqp)\n\t\treturn -ENOMEM;\n\n\ttqp = hdev->htqp;\n\n\tfor (i = 0; i < hdev->num_tqps; i++) {\n\t\ttqp->dev = &hdev->pdev->dev;\n\t\ttqp->index = i;\n\n\t\ttqp->q.ae_algo = &ae_algovf;\n\t\ttqp->q.buf_size = hdev->rx_buf_len;\n\t\ttqp->q.tx_desc_num = hdev->num_tx_desc;\n\t\ttqp->q.rx_desc_num = hdev->num_rx_desc;\n\n\t\t \n\t\tif (i < HCLGEVF_TQP_MAX_SIZE_DEV_V2)\n\t\t\ttqp->q.io_base = hdev->hw.hw.io_base +\n\t\t\t\t\t HCLGEVF_TQP_REG_OFFSET +\n\t\t\t\t\t i * HCLGEVF_TQP_REG_SIZE;\n\t\telse\n\t\t\ttqp->q.io_base = hdev->hw.hw.io_base +\n\t\t\t\t\t HCLGEVF_TQP_REG_OFFSET +\n\t\t\t\t\t HCLGEVF_TQP_EXT_REG_OFFSET +\n\t\t\t\t\t (i - HCLGEVF_TQP_MAX_SIZE_DEV_V2) *\n\t\t\t\t\t HCLGEVF_TQP_REG_SIZE;\n\n\t\t \n\t\tif (test_bit(HNAE3_DEV_SUPPORT_TX_PUSH_B, ae_dev->caps))\n\t\t\ttqp->q.mem_base = hdev->hw.hw.mem_base +\n\t\t\t\t\t  HCLGEVF_TQP_MEM_OFFSET(hdev, i);\n\n\t\ttqp++;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclgevf_knic_setup(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_handle *nic = &hdev->nic;\n\tstruct hnae3_knic_private_info *kinfo;\n\tu16 new_tqps = hdev->num_tqps;\n\tunsigned int i;\n\tu8 num_tc = 0;\n\n\tkinfo = &nic->kinfo;\n\tkinfo->num_tx_desc = hdev->num_tx_desc;\n\tkinfo->num_rx_desc = hdev->num_rx_desc;\n\tkinfo->rx_buf_len = hdev->rx_buf_len;\n\tfor (i = 0; i < HCLGE_COMM_MAX_TC_NUM; i++)\n\t\tif (hdev->hw_tc_map & BIT(i))\n\t\t\tnum_tc++;\n\n\tnum_tc = num_tc ? num_tc : 1;\n\tkinfo->tc_info.num_tc = num_tc;\n\tkinfo->rss_size = min_t(u16, hdev->rss_size_max, new_tqps / num_tc);\n\tnew_tqps = kinfo->rss_size * num_tc;\n\tkinfo->num_tqps = min(new_tqps, hdev->num_tqps);\n\n\tkinfo->tqp = devm_kcalloc(&hdev->pdev->dev, kinfo->num_tqps,\n\t\t\t\t  sizeof(struct hnae3_queue *), GFP_KERNEL);\n\tif (!kinfo->tqp)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < kinfo->num_tqps; i++) {\n\t\thdev->htqp[i].q.handle = &hdev->nic;\n\t\thdev->htqp[i].q.tqp_index = i;\n\t\tkinfo->tqp[i] = &hdev->htqp[i].q;\n\t}\n\n\t \n\tkinfo->num_tqps = min_t(u16, hdev->num_nic_msix - 1, kinfo->num_tqps);\n\tkinfo->rss_size = min_t(u16, kinfo->num_tqps / num_tc,\n\t\t\t\tkinfo->rss_size);\n\n\treturn 0;\n}\n\nstatic void hclgevf_request_link_info(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tint status;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_LINK_STATUS, 0);\n\tstatus = hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n\tif (status)\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF failed to fetch link status(%d) from PF\", status);\n}\n\nvoid hclgevf_update_link_status(struct hclgevf_dev *hdev, int link_state)\n{\n\tstruct hnae3_handle *rhandle = &hdev->roce;\n\tstruct hnae3_handle *handle = &hdev->nic;\n\tstruct hnae3_client *rclient;\n\tstruct hnae3_client *client;\n\n\tif (test_and_set_bit(HCLGEVF_STATE_LINK_UPDATING, &hdev->state))\n\t\treturn;\n\n\tclient = handle->client;\n\trclient = hdev->roce_client;\n\n\tlink_state =\n\t\ttest_bit(HCLGEVF_STATE_DOWN, &hdev->state) ? 0 : link_state;\n\tif (link_state != hdev->hw.mac.link) {\n\t\thdev->hw.mac.link = link_state;\n\t\tclient->ops->link_status_change(handle, !!link_state);\n\t\tif (rclient && rclient->ops->link_status_change)\n\t\t\trclient->ops->link_status_change(rhandle, !!link_state);\n\t}\n\n\tclear_bit(HCLGEVF_STATE_LINK_UPDATING, &hdev->state);\n}\n\nstatic void hclgevf_update_link_mode(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_ADVERTISING\t0\n#define HCLGEVF_SUPPORTED\t1\n\n\tstruct hclge_vf_to_pf_msg send_msg;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_LINK_MODE, 0);\n\tsend_msg.data[0] = HCLGEVF_ADVERTISING;\n\thclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n\tsend_msg.data[0] = HCLGEVF_SUPPORTED;\n\thclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n}\n\nstatic int hclgevf_set_handle_info(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_handle *nic = &hdev->nic;\n\tint ret;\n\n\tnic->ae_algo = &ae_algovf;\n\tnic->pdev = hdev->pdev;\n\tnic->numa_node_mask = hdev->numa_node_mask;\n\tnic->flags |= HNAE3_SUPPORT_VF;\n\tnic->kinfo.io_base = hdev->hw.hw.io_base;\n\n\tret = hclgevf_knic_setup(hdev);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev, \"VF knic setup failed %d\\n\",\n\t\t\tret);\n\treturn ret;\n}\n\nstatic void hclgevf_free_vector(struct hclgevf_dev *hdev, int vector_id)\n{\n\tif (hdev->vector_status[vector_id] == HCLGEVF_INVALID_VPORT) {\n\t\tdev_warn(&hdev->pdev->dev,\n\t\t\t \"vector(vector_id %d) has been freed.\\n\", vector_id);\n\t\treturn;\n\t}\n\n\thdev->vector_status[vector_id] = HCLGEVF_INVALID_VPORT;\n\thdev->num_msi_left += 1;\n\thdev->num_msi_used -= 1;\n}\n\nstatic int hclgevf_get_vector(struct hnae3_handle *handle, u16 vector_num,\n\t\t\t      struct hnae3_vector_info *vector_info)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hnae3_vector_info *vector = vector_info;\n\tint alloc = 0;\n\tint i, j;\n\n\tvector_num = min_t(u16, hdev->num_nic_msix - 1, vector_num);\n\tvector_num = min(hdev->num_msi_left, vector_num);\n\n\tfor (j = 0; j < vector_num; j++) {\n\t\tfor (i = HCLGEVF_MISC_VECTOR_NUM + 1; i < hdev->num_msi; i++) {\n\t\t\tif (hdev->vector_status[i] == HCLGEVF_INVALID_VPORT) {\n\t\t\t\tvector->vector = pci_irq_vector(hdev->pdev, i);\n\t\t\t\tvector->io_addr = hdev->hw.hw.io_base +\n\t\t\t\t\tHCLGEVF_VECTOR_REG_BASE +\n\t\t\t\t\t(i - 1) * HCLGEVF_VECTOR_REG_OFFSET;\n\t\t\t\thdev->vector_status[i] = 0;\n\t\t\t\thdev->vector_irq[i] = vector->vector;\n\n\t\t\t\tvector++;\n\t\t\t\talloc++;\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\thdev->num_msi_left -= alloc;\n\thdev->num_msi_used += alloc;\n\n\treturn alloc;\n}\n\nstatic int hclgevf_get_vector_index(struct hclgevf_dev *hdev, int vector)\n{\n\tint i;\n\n\tfor (i = 0; i < hdev->num_msi; i++)\n\t\tif (vector == hdev->vector_irq[i])\n\t\t\treturn i;\n\n\treturn -EINVAL;\n}\n\n \nstatic int hclgevf_get_rss_hash_key(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_RSS_MBX_RESP_LEN\t8\n\tstruct hclge_comm_rss_cfg *rss_cfg = &hdev->rss_cfg;\n\tu8 resp_msg[HCLGEVF_RSS_MBX_RESP_LEN];\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu16 msg_num, hash_key_index;\n\tu8 index;\n\tint ret;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_RSS_KEY, 0);\n\tmsg_num = (HCLGE_COMM_RSS_KEY_SIZE + HCLGEVF_RSS_MBX_RESP_LEN - 1) /\n\t\t\tHCLGEVF_RSS_MBX_RESP_LEN;\n\tfor (index = 0; index < msg_num; index++) {\n\t\tsend_msg.data[0] = index;\n\t\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, resp_msg,\n\t\t\t\t\t   HCLGEVF_RSS_MBX_RESP_LEN);\n\t\tif (ret) {\n\t\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\t\"VF get rss hash key from PF failed, ret=%d\",\n\t\t\t\tret);\n\t\t\treturn ret;\n\t\t}\n\n\t\thash_key_index = HCLGEVF_RSS_MBX_RESP_LEN * index;\n\t\tif (index == msg_num - 1)\n\t\t\tmemcpy(&rss_cfg->rss_hash_key[hash_key_index],\n\t\t\t       &resp_msg[0],\n\t\t\t       HCLGE_COMM_RSS_KEY_SIZE - hash_key_index);\n\t\telse\n\t\t\tmemcpy(&rss_cfg->rss_hash_key[hash_key_index],\n\t\t\t       &resp_msg[0], HCLGEVF_RSS_MBX_RESP_LEN);\n\t}\n\n\treturn 0;\n}\n\nstatic int hclgevf_get_rss(struct hnae3_handle *handle, u32 *indir, u8 *key,\n\t\t\t   u8 *hfunc)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_comm_rss_cfg *rss_cfg = &hdev->rss_cfg;\n\tint ret;\n\n\tif (hdev->ae_dev->dev_version >= HNAE3_DEVICE_VERSION_V2) {\n\t\thclge_comm_get_rss_hash_info(rss_cfg, key, hfunc);\n\t} else {\n\t\tif (hfunc)\n\t\t\t*hfunc = ETH_RSS_HASH_TOP;\n\t\tif (key) {\n\t\t\tret = hclgevf_get_rss_hash_key(hdev);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tmemcpy(key, rss_cfg->rss_hash_key,\n\t\t\t       HCLGE_COMM_RSS_KEY_SIZE);\n\t\t}\n\t}\n\n\thclge_comm_get_rss_indir_tbl(rss_cfg, indir,\n\t\t\t\t     hdev->ae_dev->dev_specs.rss_ind_tbl_size);\n\n\treturn 0;\n}\n\nstatic int hclgevf_set_rss(struct hnae3_handle *handle, const u32 *indir,\n\t\t\t   const u8 *key, const u8 hfunc)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_comm_rss_cfg *rss_cfg = &hdev->rss_cfg;\n\tint ret, i;\n\n\tif (hdev->ae_dev->dev_version >= HNAE3_DEVICE_VERSION_V2) {\n\t\tret = hclge_comm_set_rss_hash_key(rss_cfg, &hdev->hw.hw, key,\n\t\t\t\t\t\t  hfunc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t \n\tfor (i = 0; i < hdev->ae_dev->dev_specs.rss_ind_tbl_size; i++)\n\t\trss_cfg->rss_indirection_tbl[i] = indir[i];\n\n\t \n\treturn hclge_comm_set_rss_indir_table(hdev->ae_dev, &hdev->hw.hw,\n\t\t\t\t\t      rss_cfg->rss_indirection_tbl);\n}\n\nstatic int hclgevf_set_rss_tuple(struct hnae3_handle *handle,\n\t\t\t\t struct ethtool_rxnfc *nfc)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tint ret;\n\n\tif (hdev->ae_dev->dev_version < HNAE3_DEVICE_VERSION_V2)\n\t\treturn -EOPNOTSUPP;\n\n\tret = hclge_comm_set_rss_tuple(hdev->ae_dev, &hdev->hw.hw,\n\t\t\t\t       &hdev->rss_cfg, nfc);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\"failed to set rss tuple, ret = %d.\\n\", ret);\n\n\treturn ret;\n}\n\nstatic int hclgevf_get_rss_tuple(struct hnae3_handle *handle,\n\t\t\t\t struct ethtool_rxnfc *nfc)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tu8 tuple_sets;\n\tint ret;\n\n\tif (hdev->ae_dev->dev_version < HNAE3_DEVICE_VERSION_V2)\n\t\treturn -EOPNOTSUPP;\n\n\tnfc->data = 0;\n\n\tret = hclge_comm_get_rss_tuple(&hdev->rss_cfg, nfc->flow_type,\n\t\t\t\t       &tuple_sets);\n\tif (ret || !tuple_sets)\n\t\treturn ret;\n\n\tnfc->data = hclge_comm_convert_rss_tuple(tuple_sets);\n\n\treturn 0;\n}\n\nstatic int hclgevf_get_tc_size(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_comm_rss_cfg *rss_cfg = &hdev->rss_cfg;\n\n\treturn rss_cfg->rss_size;\n}\n\nstatic int hclgevf_bind_ring_to_vector(struct hnae3_handle *handle, bool en,\n\t\t\t\t       int vector_id,\n\t\t\t\t       struct hnae3_ring_chain_node *ring_chain)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tstruct hnae3_ring_chain_node *node;\n\tint status;\n\tint i = 0;\n\n\tmemset(&send_msg, 0, sizeof(send_msg));\n\tsend_msg.code = en ? HCLGE_MBX_MAP_RING_TO_VECTOR :\n\t\tHCLGE_MBX_UNMAP_RING_TO_VECTOR;\n\tsend_msg.vector_id = vector_id;\n\n\tfor (node = ring_chain; node; node = node->next) {\n\t\tsend_msg.param[i].ring_type =\n\t\t\t\thnae3_get_bit(node->flag, HNAE3_RING_TYPE_B);\n\n\t\tsend_msg.param[i].tqp_index = node->tqp_index;\n\t\tsend_msg.param[i].int_gl_index =\n\t\t\t\t\thnae3_get_field(node->int_gl_idx,\n\t\t\t\t\t\t\tHNAE3_RING_GL_IDX_M,\n\t\t\t\t\t\t\tHNAE3_RING_GL_IDX_S);\n\n\t\ti++;\n\t\tif (i == HCLGE_MBX_MAX_RING_CHAIN_PARAM_NUM || !node->next) {\n\t\t\tsend_msg.ring_num = i;\n\n\t\t\tstatus = hclgevf_send_mbx_msg(hdev, &send_msg, false,\n\t\t\t\t\t\t      NULL, 0);\n\t\t\tif (status) {\n\t\t\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\t\t\"Map TQP fail, status is %d.\\n\",\n\t\t\t\t\tstatus);\n\t\t\t\treturn status;\n\t\t\t}\n\t\t\ti = 0;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int hclgevf_map_ring_to_vector(struct hnae3_handle *handle, int vector,\n\t\t\t\t      struct hnae3_ring_chain_node *ring_chain)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tint vector_id;\n\n\tvector_id = hclgevf_get_vector_index(hdev, vector);\n\tif (vector_id < 0) {\n\t\tdev_err(&handle->pdev->dev,\n\t\t\t\"Get vector index fail. ret =%d\\n\", vector_id);\n\t\treturn vector_id;\n\t}\n\n\treturn hclgevf_bind_ring_to_vector(handle, true, vector_id, ring_chain);\n}\n\nstatic int hclgevf_unmap_ring_from_vector(\n\t\t\t\tstruct hnae3_handle *handle,\n\t\t\t\tint vector,\n\t\t\t\tstruct hnae3_ring_chain_node *ring_chain)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tint ret, vector_id;\n\n\tif (test_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state))\n\t\treturn 0;\n\n\tvector_id = hclgevf_get_vector_index(hdev, vector);\n\tif (vector_id < 0) {\n\t\tdev_err(&handle->pdev->dev,\n\t\t\t\"Get vector index fail. ret =%d\\n\", vector_id);\n\t\treturn vector_id;\n\t}\n\n\tret = hclgevf_bind_ring_to_vector(handle, false, vector_id, ring_chain);\n\tif (ret)\n\t\tdev_err(&handle->pdev->dev,\n\t\t\t\"Unmap ring from vector fail. vector=%d, ret =%d\\n\",\n\t\t\tvector_id,\n\t\t\tret);\n\n\treturn ret;\n}\n\nstatic int hclgevf_put_vector(struct hnae3_handle *handle, int vector)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tint vector_id;\n\n\tvector_id = hclgevf_get_vector_index(hdev, vector);\n\tif (vector_id < 0) {\n\t\tdev_err(&handle->pdev->dev,\n\t\t\t\"hclgevf_put_vector get vector index fail. ret =%d\\n\",\n\t\t\tvector_id);\n\t\treturn vector_id;\n\t}\n\n\thclgevf_free_vector(hdev, vector_id);\n\n\treturn 0;\n}\n\nstatic int hclgevf_cmd_set_promisc_mode(struct hclgevf_dev *hdev,\n\t\t\t\t\tbool en_uc_pmc, bool en_mc_pmc,\n\t\t\t\t\tbool en_bc_pmc)\n{\n\tstruct hnae3_handle *handle = &hdev->nic;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tint ret;\n\n\tmemset(&send_msg, 0, sizeof(send_msg));\n\tsend_msg.code = HCLGE_MBX_SET_PROMISC_MODE;\n\tsend_msg.en_bc = en_bc_pmc ? 1 : 0;\n\tsend_msg.en_uc = en_uc_pmc ? 1 : 0;\n\tsend_msg.en_mc = en_mc_pmc ? 1 : 0;\n\tsend_msg.en_limit_promisc = test_bit(HNAE3_PFLAG_LIMIT_PROMISC,\n\t\t\t\t\t     &handle->priv_flags) ? 1 : 0;\n\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"Set promisc mode fail, status is %d.\\n\", ret);\n\n\treturn ret;\n}\n\nstatic int hclgevf_set_promisc_mode(struct hnae3_handle *handle, bool en_uc_pmc,\n\t\t\t\t    bool en_mc_pmc)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tbool en_bc_pmc;\n\n\ten_bc_pmc = hdev->ae_dev->dev_version >= HNAE3_DEVICE_VERSION_V2;\n\n\treturn hclgevf_cmd_set_promisc_mode(hdev, en_uc_pmc, en_mc_pmc,\n\t\t\t\t\t    en_bc_pmc);\n}\n\nstatic void hclgevf_request_update_promisc_mode(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\tset_bit(HCLGEVF_STATE_PROMISC_CHANGED, &hdev->state);\n\thclgevf_task_schedule(hdev, 0);\n}\n\nstatic void hclgevf_sync_promisc_mode(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_handle *handle = &hdev->nic;\n\tbool en_uc_pmc = handle->netdev_flags & HNAE3_UPE;\n\tbool en_mc_pmc = handle->netdev_flags & HNAE3_MPE;\n\tint ret;\n\n\tif (test_bit(HCLGEVF_STATE_PROMISC_CHANGED, &hdev->state)) {\n\t\tret = hclgevf_set_promisc_mode(handle, en_uc_pmc, en_mc_pmc);\n\t\tif (!ret)\n\t\t\tclear_bit(HCLGEVF_STATE_PROMISC_CHANGED, &hdev->state);\n\t}\n}\n\nstatic int hclgevf_tqp_enable_cmd_send(struct hclgevf_dev *hdev, u16 tqp_id,\n\t\t\t\t       u16 stream_id, bool enable)\n{\n\tstruct hclgevf_cfg_com_tqp_queue_cmd *req;\n\tstruct hclge_desc desc;\n\n\treq = (struct hclgevf_cfg_com_tqp_queue_cmd *)desc.data;\n\n\thclgevf_cmd_setup_basic_desc(&desc, HCLGE_OPC_CFG_COM_TQP_QUEUE, false);\n\treq->tqp_id = cpu_to_le16(tqp_id & HCLGEVF_RING_ID_MASK);\n\treq->stream_id = cpu_to_le16(stream_id);\n\tif (enable)\n\t\treq->enable |= 1U << HCLGEVF_TQP_ENABLE_B;\n\n\treturn hclgevf_cmd_send(&hdev->hw, &desc, 1);\n}\n\nstatic int hclgevf_tqp_enable(struct hnae3_handle *handle, bool enable)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tint ret;\n\tu16 i;\n\n\tfor (i = 0; i < handle->kinfo.num_tqps; i++) {\n\t\tret = hclgevf_tqp_enable_cmd_send(hdev, i, 0, enable);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclgevf_get_host_mac_addr(struct hclgevf_dev *hdev, u8 *p)\n{\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu8 host_mac[ETH_ALEN];\n\tint status;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_GET_MAC_ADDR, 0);\n\tstatus = hclgevf_send_mbx_msg(hdev, &send_msg, true, host_mac,\n\t\t\t\t      ETH_ALEN);\n\tif (status) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"fail to get VF MAC from host %d\", status);\n\t\treturn status;\n\t}\n\n\tether_addr_copy(p, host_mac);\n\n\treturn 0;\n}\n\nstatic void hclgevf_get_mac_addr(struct hnae3_handle *handle, u8 *p)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tu8 host_mac_addr[ETH_ALEN];\n\n\tif (hclgevf_get_host_mac_addr(hdev, host_mac_addr))\n\t\treturn;\n\n\thdev->has_pf_mac = !is_zero_ether_addr(host_mac_addr);\n\tif (hdev->has_pf_mac)\n\t\tether_addr_copy(p, host_mac_addr);\n\telse\n\t\tether_addr_copy(p, hdev->hw.mac.mac_addr);\n}\n\nstatic int hclgevf_set_mac_addr(struct hnae3_handle *handle, const void *p,\n\t\t\t\tbool is_first)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tu8 *old_mac_addr = (u8 *)hdev->hw.mac.mac_addr;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu8 *new_mac_addr = (u8 *)p;\n\tint status;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_UNICAST, 0);\n\tsend_msg.subcode = HCLGE_MBX_MAC_VLAN_UC_MODIFY;\n\tether_addr_copy(send_msg.data, new_mac_addr);\n\tif (is_first && !hdev->has_pf_mac)\n\t\teth_zero_addr(&send_msg.data[ETH_ALEN]);\n\telse\n\t\tether_addr_copy(&send_msg.data[ETH_ALEN], old_mac_addr);\n\tstatus = hclgevf_send_mbx_msg(hdev, &send_msg, true, NULL, 0);\n\tif (!status)\n\t\tether_addr_copy(hdev->hw.mac.mac_addr, new_mac_addr);\n\n\treturn status;\n}\n\nstatic struct hclgevf_mac_addr_node *\nhclgevf_find_mac_node(struct list_head *list, const u8 *mac_addr)\n{\n\tstruct hclgevf_mac_addr_node *mac_node, *tmp;\n\n\tlist_for_each_entry_safe(mac_node, tmp, list, node)\n\t\tif (ether_addr_equal(mac_addr, mac_node->mac_addr))\n\t\t\treturn mac_node;\n\n\treturn NULL;\n}\n\nstatic void hclgevf_update_mac_node(struct hclgevf_mac_addr_node *mac_node,\n\t\t\t\t    enum HCLGEVF_MAC_NODE_STATE state)\n{\n\tswitch (state) {\n\t \n\tcase HCLGEVF_MAC_TO_ADD:\n\t\tif (mac_node->state == HCLGEVF_MAC_TO_DEL)\n\t\t\tmac_node->state = HCLGEVF_MAC_ACTIVE;\n\t\tbreak;\n\t \n\tcase HCLGEVF_MAC_TO_DEL:\n\t\tif (mac_node->state == HCLGEVF_MAC_TO_ADD) {\n\t\t\tlist_del(&mac_node->node);\n\t\t\tkfree(mac_node);\n\t\t} else {\n\t\t\tmac_node->state = HCLGEVF_MAC_TO_DEL;\n\t\t}\n\t\tbreak;\n\t \n\tcase HCLGEVF_MAC_ACTIVE:\n\t\tif (mac_node->state == HCLGEVF_MAC_TO_ADD)\n\t\t\tmac_node->state = HCLGEVF_MAC_ACTIVE;\n\t\tbreak;\n\t}\n}\n\nstatic int hclgevf_update_mac_list(struct hnae3_handle *handle,\n\t\t\t\t   enum HCLGEVF_MAC_NODE_STATE state,\n\t\t\t\t   enum HCLGEVF_MAC_ADDR_TYPE mac_type,\n\t\t\t\t   const unsigned char *addr)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclgevf_mac_addr_node *mac_node;\n\tstruct list_head *list;\n\n\tlist = (mac_type == HCLGEVF_MAC_ADDR_UC) ?\n\t       &hdev->mac_table.uc_mac_list : &hdev->mac_table.mc_mac_list;\n\n\tspin_lock_bh(&hdev->mac_table.mac_list_lock);\n\n\t \n\tmac_node = hclgevf_find_mac_node(list, addr);\n\tif (mac_node) {\n\t\thclgevf_update_mac_node(mac_node, state);\n\t\tspin_unlock_bh(&hdev->mac_table.mac_list_lock);\n\t\treturn 0;\n\t}\n\t \n\tif (state == HCLGEVF_MAC_TO_DEL) {\n\t\tspin_unlock_bh(&hdev->mac_table.mac_list_lock);\n\t\treturn -ENOENT;\n\t}\n\n\tmac_node = kzalloc(sizeof(*mac_node), GFP_ATOMIC);\n\tif (!mac_node) {\n\t\tspin_unlock_bh(&hdev->mac_table.mac_list_lock);\n\t\treturn -ENOMEM;\n\t}\n\n\tmac_node->state = state;\n\tether_addr_copy(mac_node->mac_addr, addr);\n\tlist_add_tail(&mac_node->node, list);\n\n\tspin_unlock_bh(&hdev->mac_table.mac_list_lock);\n\treturn 0;\n}\n\nstatic int hclgevf_add_uc_addr(struct hnae3_handle *handle,\n\t\t\t       const unsigned char *addr)\n{\n\treturn hclgevf_update_mac_list(handle, HCLGEVF_MAC_TO_ADD,\n\t\t\t\t       HCLGEVF_MAC_ADDR_UC, addr);\n}\n\nstatic int hclgevf_rm_uc_addr(struct hnae3_handle *handle,\n\t\t\t      const unsigned char *addr)\n{\n\treturn hclgevf_update_mac_list(handle, HCLGEVF_MAC_TO_DEL,\n\t\t\t\t       HCLGEVF_MAC_ADDR_UC, addr);\n}\n\nstatic int hclgevf_add_mc_addr(struct hnae3_handle *handle,\n\t\t\t       const unsigned char *addr)\n{\n\treturn hclgevf_update_mac_list(handle, HCLGEVF_MAC_TO_ADD,\n\t\t\t\t       HCLGEVF_MAC_ADDR_MC, addr);\n}\n\nstatic int hclgevf_rm_mc_addr(struct hnae3_handle *handle,\n\t\t\t      const unsigned char *addr)\n{\n\treturn hclgevf_update_mac_list(handle, HCLGEVF_MAC_TO_DEL,\n\t\t\t\t       HCLGEVF_MAC_ADDR_MC, addr);\n}\n\nstatic int hclgevf_add_del_mac_addr(struct hclgevf_dev *hdev,\n\t\t\t\t    struct hclgevf_mac_addr_node *mac_node,\n\t\t\t\t    enum HCLGEVF_MAC_ADDR_TYPE mac_type)\n{\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu8 code, subcode;\n\n\tif (mac_type == HCLGEVF_MAC_ADDR_UC) {\n\t\tcode = HCLGE_MBX_SET_UNICAST;\n\t\tif (mac_node->state == HCLGEVF_MAC_TO_ADD)\n\t\t\tsubcode = HCLGE_MBX_MAC_VLAN_UC_ADD;\n\t\telse\n\t\t\tsubcode = HCLGE_MBX_MAC_VLAN_UC_REMOVE;\n\t} else {\n\t\tcode = HCLGE_MBX_SET_MULTICAST;\n\t\tif (mac_node->state == HCLGEVF_MAC_TO_ADD)\n\t\t\tsubcode = HCLGE_MBX_MAC_VLAN_MC_ADD;\n\t\telse\n\t\t\tsubcode = HCLGE_MBX_MAC_VLAN_MC_REMOVE;\n\t}\n\n\thclgevf_build_send_msg(&send_msg, code, subcode);\n\tether_addr_copy(send_msg.data, mac_node->mac_addr);\n\treturn hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n}\n\nstatic void hclgevf_config_mac_list(struct hclgevf_dev *hdev,\n\t\t\t\t    struct list_head *list,\n\t\t\t\t    enum HCLGEVF_MAC_ADDR_TYPE mac_type)\n{\n\tchar format_mac_addr[HNAE3_FORMAT_MAC_ADDR_LEN];\n\tstruct hclgevf_mac_addr_node *mac_node, *tmp;\n\tint ret;\n\n\tlist_for_each_entry_safe(mac_node, tmp, list, node) {\n\t\tret = hclgevf_add_del_mac_addr(hdev, mac_node, mac_type);\n\t\tif  (ret) {\n\t\t\thnae3_format_mac_addr(format_mac_addr,\n\t\t\t\t\t      mac_node->mac_addr);\n\t\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\t\"failed to configure mac %s, state = %d, ret = %d\\n\",\n\t\t\t\tformat_mac_addr, mac_node->state, ret);\n\t\t\treturn;\n\t\t}\n\t\tif (mac_node->state == HCLGEVF_MAC_TO_ADD) {\n\t\t\tmac_node->state = HCLGEVF_MAC_ACTIVE;\n\t\t} else {\n\t\t\tlist_del(&mac_node->node);\n\t\t\tkfree(mac_node);\n\t\t}\n\t}\n}\n\nstatic void hclgevf_sync_from_add_list(struct list_head *add_list,\n\t\t\t\t       struct list_head *mac_list)\n{\n\tstruct hclgevf_mac_addr_node *mac_node, *tmp, *new_node;\n\n\tlist_for_each_entry_safe(mac_node, tmp, add_list, node) {\n\t\t \n\t\tnew_node = hclgevf_find_mac_node(mac_list, mac_node->mac_addr);\n\t\tif (new_node) {\n\t\t\thclgevf_update_mac_node(new_node, mac_node->state);\n\t\t\tlist_del(&mac_node->node);\n\t\t\tkfree(mac_node);\n\t\t} else if (mac_node->state == HCLGEVF_MAC_ACTIVE) {\n\t\t\tmac_node->state = HCLGEVF_MAC_TO_DEL;\n\t\t\tlist_move_tail(&mac_node->node, mac_list);\n\t\t} else {\n\t\t\tlist_del(&mac_node->node);\n\t\t\tkfree(mac_node);\n\t\t}\n\t}\n}\n\nstatic void hclgevf_sync_from_del_list(struct list_head *del_list,\n\t\t\t\t       struct list_head *mac_list)\n{\n\tstruct hclgevf_mac_addr_node *mac_node, *tmp, *new_node;\n\n\tlist_for_each_entry_safe(mac_node, tmp, del_list, node) {\n\t\tnew_node = hclgevf_find_mac_node(mac_list, mac_node->mac_addr);\n\t\tif (new_node) {\n\t\t\t \n\t\t\tnew_node->state = HCLGEVF_MAC_ACTIVE;\n\t\t\tlist_del(&mac_node->node);\n\t\t\tkfree(mac_node);\n\t\t} else {\n\t\t\tlist_move_tail(&mac_node->node, mac_list);\n\t\t}\n\t}\n}\n\nstatic void hclgevf_clear_list(struct list_head *list)\n{\n\tstruct hclgevf_mac_addr_node *mac_node, *tmp;\n\n\tlist_for_each_entry_safe(mac_node, tmp, list, node) {\n\t\tlist_del(&mac_node->node);\n\t\tkfree(mac_node);\n\t}\n}\n\nstatic void hclgevf_sync_mac_list(struct hclgevf_dev *hdev,\n\t\t\t\t  enum HCLGEVF_MAC_ADDR_TYPE mac_type)\n{\n\tstruct hclgevf_mac_addr_node *mac_node, *tmp, *new_node;\n\tstruct list_head tmp_add_list, tmp_del_list;\n\tstruct list_head *list;\n\n\tINIT_LIST_HEAD(&tmp_add_list);\n\tINIT_LIST_HEAD(&tmp_del_list);\n\n\t \n\tlist = (mac_type == HCLGEVF_MAC_ADDR_UC) ?\n\t\t&hdev->mac_table.uc_mac_list : &hdev->mac_table.mc_mac_list;\n\n\tspin_lock_bh(&hdev->mac_table.mac_list_lock);\n\n\tlist_for_each_entry_safe(mac_node, tmp, list, node) {\n\t\tswitch (mac_node->state) {\n\t\tcase HCLGEVF_MAC_TO_DEL:\n\t\t\tlist_move_tail(&mac_node->node, &tmp_del_list);\n\t\t\tbreak;\n\t\tcase HCLGEVF_MAC_TO_ADD:\n\t\t\tnew_node = kzalloc(sizeof(*new_node), GFP_ATOMIC);\n\t\t\tif (!new_node)\n\t\t\t\tgoto stop_traverse;\n\n\t\t\tether_addr_copy(new_node->mac_addr, mac_node->mac_addr);\n\t\t\tnew_node->state = mac_node->state;\n\t\t\tlist_add_tail(&new_node->node, &tmp_add_list);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\nstop_traverse:\n\tspin_unlock_bh(&hdev->mac_table.mac_list_lock);\n\n\t \n\thclgevf_config_mac_list(hdev, &tmp_del_list, mac_type);\n\thclgevf_config_mac_list(hdev, &tmp_add_list, mac_type);\n\n\t \n\tspin_lock_bh(&hdev->mac_table.mac_list_lock);\n\n\thclgevf_sync_from_del_list(&tmp_del_list, list);\n\thclgevf_sync_from_add_list(&tmp_add_list, list);\n\n\tspin_unlock_bh(&hdev->mac_table.mac_list_lock);\n}\n\nstatic void hclgevf_sync_mac_table(struct hclgevf_dev *hdev)\n{\n\thclgevf_sync_mac_list(hdev, HCLGEVF_MAC_ADDR_UC);\n\thclgevf_sync_mac_list(hdev, HCLGEVF_MAC_ADDR_MC);\n}\n\nstatic void hclgevf_uninit_mac_list(struct hclgevf_dev *hdev)\n{\n\tspin_lock_bh(&hdev->mac_table.mac_list_lock);\n\n\thclgevf_clear_list(&hdev->mac_table.uc_mac_list);\n\thclgevf_clear_list(&hdev->mac_table.mc_mac_list);\n\n\tspin_unlock_bh(&hdev->mac_table.mac_list_lock);\n}\n\nstatic int hclgevf_enable_vlan_filter(struct hnae3_handle *handle, bool enable)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hnae3_ae_dev *ae_dev = hdev->ae_dev;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\n\tif (!test_bit(HNAE3_DEV_SUPPORT_VLAN_FLTR_MDF_B, ae_dev->caps))\n\t\treturn -EOPNOTSUPP;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_VLAN,\n\t\t\t       HCLGE_MBX_ENABLE_VLAN_FILTER);\n\tsend_msg.data[0] = enable ? 1 : 0;\n\n\treturn hclgevf_send_mbx_msg(hdev, &send_msg, true, NULL, 0);\n}\n\nstatic int hclgevf_set_vlan_filter(struct hnae3_handle *handle,\n\t\t\t\t   __be16 proto, u16 vlan_id,\n\t\t\t\t   bool is_kill)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_mbx_vlan_filter *vlan_filter;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tint ret;\n\n\tif (vlan_id > HCLGEVF_MAX_VLAN_ID)\n\t\treturn -EINVAL;\n\n\tif (proto != htons(ETH_P_8021Q))\n\t\treturn -EPROTONOSUPPORT;\n\n\t \n\tif ((test_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state) ||\n\t     test_bit(HCLGEVF_STATE_RST_FAIL, &hdev->state)) && is_kill) {\n\t\tset_bit(vlan_id, hdev->vlan_del_fail_bmap);\n\t\treturn -EBUSY;\n\t} else if (!is_kill && test_bit(vlan_id, hdev->vlan_del_fail_bmap)) {\n\t\tclear_bit(vlan_id, hdev->vlan_del_fail_bmap);\n\t}\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_VLAN,\n\t\t\t       HCLGE_MBX_VLAN_FILTER);\n\tvlan_filter = (struct hclge_mbx_vlan_filter *)send_msg.data;\n\tvlan_filter->is_kill = is_kill;\n\tvlan_filter->vlan_id = cpu_to_le16(vlan_id);\n\tvlan_filter->proto = cpu_to_le16(be16_to_cpu(proto));\n\n\t \n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, NULL, 0);\n\tif (is_kill && ret)\n\t\tset_bit(vlan_id, hdev->vlan_del_fail_bmap);\n\n\treturn ret;\n}\n\nstatic void hclgevf_sync_vlan_filter(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_MAX_SYNC_COUNT\t60\n\tstruct hnae3_handle *handle = &hdev->nic;\n\tint ret, sync_cnt = 0;\n\tu16 vlan_id;\n\n\tif (bitmap_empty(hdev->vlan_del_fail_bmap, VLAN_N_VID))\n\t\treturn;\n\n\trtnl_lock();\n\tvlan_id = find_first_bit(hdev->vlan_del_fail_bmap, VLAN_N_VID);\n\twhile (vlan_id != VLAN_N_VID) {\n\t\tret = hclgevf_set_vlan_filter(handle, htons(ETH_P_8021Q),\n\t\t\t\t\t      vlan_id, true);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tclear_bit(vlan_id, hdev->vlan_del_fail_bmap);\n\t\tsync_cnt++;\n\t\tif (sync_cnt >= HCLGEVF_MAX_SYNC_COUNT)\n\t\t\tbreak;\n\n\t\tvlan_id = find_first_bit(hdev->vlan_del_fail_bmap, VLAN_N_VID);\n\t}\n\trtnl_unlock();\n}\n\nstatic int hclgevf_en_hw_strip_rxvtag(struct hnae3_handle *handle, bool enable)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_vf_to_pf_msg send_msg;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_VLAN,\n\t\t\t       HCLGE_MBX_VLAN_RX_OFF_CFG);\n\tsend_msg.data[0] = enable ? 1 : 0;\n\treturn hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n}\n\nstatic int hclgevf_reset_tqp(struct hnae3_handle *handle)\n{\n#define HCLGEVF_RESET_ALL_QUEUE_DONE\t1U\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tu8 return_status = 0;\n\tint ret;\n\tu16 i;\n\n\t \n\tret = hclgevf_tqp_enable(handle, false);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev, \"failed to disable tqp, ret = %d\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_QUEUE_RESET, 0);\n\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, &return_status,\n\t\t\t\t   sizeof(return_status));\n\tif (ret || return_status == HCLGEVF_RESET_ALL_QUEUE_DONE)\n\t\treturn ret;\n\n\tfor (i = 1; i < handle->kinfo.num_tqps; i++) {\n\t\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_QUEUE_RESET, 0);\n\t\t*(__le16 *)send_msg.data = cpu_to_le16(i);\n\t\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, NULL, 0);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclgevf_set_mtu(struct hnae3_handle *handle, int new_mtu)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_mbx_mtu_info *mtu_info;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_MTU, 0);\n\tmtu_info = (struct hclge_mbx_mtu_info *)send_msg.data;\n\tmtu_info->mtu = cpu_to_le32(new_mtu);\n\n\treturn hclgevf_send_mbx_msg(hdev, &send_msg, true, NULL, 0);\n}\n\nstatic int hclgevf_notify_client(struct hclgevf_dev *hdev,\n\t\t\t\t enum hnae3_reset_notify_type type)\n{\n\tstruct hnae3_client *client = hdev->nic_client;\n\tstruct hnae3_handle *handle = &hdev->nic;\n\tint ret;\n\n\tif (!test_bit(HCLGEVF_STATE_NIC_REGISTERED, &hdev->state) ||\n\t    !client)\n\t\treturn 0;\n\n\tif (!client->ops->reset_notify)\n\t\treturn -EOPNOTSUPP;\n\n\tret = client->ops->reset_notify(handle, type);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev, \"notify nic client failed %d(%d)\\n\",\n\t\t\ttype, ret);\n\n\treturn ret;\n}\n\nstatic int hclgevf_notify_roce_client(struct hclgevf_dev *hdev,\n\t\t\t\t      enum hnae3_reset_notify_type type)\n{\n\tstruct hnae3_client *client = hdev->roce_client;\n\tstruct hnae3_handle *handle = &hdev->roce;\n\tint ret;\n\n\tif (!test_bit(HCLGEVF_STATE_ROCE_REGISTERED, &hdev->state) || !client)\n\t\treturn 0;\n\n\tif (!client->ops->reset_notify)\n\t\treturn -EOPNOTSUPP;\n\n\tret = client->ops->reset_notify(handle, type);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev, \"notify roce client failed %d(%d)\",\n\t\t\ttype, ret);\n\treturn ret;\n}\n\nstatic int hclgevf_reset_wait(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_RESET_WAIT_US\t20000\n#define HCLGEVF_RESET_WAIT_CNT\t2000\n#define HCLGEVF_RESET_WAIT_TIMEOUT_US\t\\\n\t(HCLGEVF_RESET_WAIT_US * HCLGEVF_RESET_WAIT_CNT)\n\n\tu32 val;\n\tint ret;\n\n\tif (hdev->reset_type == HNAE3_VF_RESET)\n\t\tret = readl_poll_timeout(hdev->hw.hw.io_base +\n\t\t\t\t\t HCLGEVF_VF_RST_ING, val,\n\t\t\t\t\t !(val & HCLGEVF_VF_RST_ING_BIT),\n\t\t\t\t\t HCLGEVF_RESET_WAIT_US,\n\t\t\t\t\t HCLGEVF_RESET_WAIT_TIMEOUT_US);\n\telse\n\t\tret = readl_poll_timeout(hdev->hw.hw.io_base +\n\t\t\t\t\t HCLGEVF_RST_ING, val,\n\t\t\t\t\t !(val & HCLGEVF_RST_ING_BITS),\n\t\t\t\t\t HCLGEVF_RESET_WAIT_US,\n\t\t\t\t\t HCLGEVF_RESET_WAIT_TIMEOUT_US);\n\n\t \n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"couldn't get reset done status from h/w, timeout!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tif (hdev->reset_type == HNAE3_VF_FULL_RESET)\n\t\tmsleep(5000);\n\telse\n\t\tmsleep(500);\n\n\treturn 0;\n}\n\nstatic void hclgevf_reset_handshake(struct hclgevf_dev *hdev, bool enable)\n{\n\tu32 reg_val;\n\n\treg_val = hclgevf_read_dev(&hdev->hw, HCLGE_COMM_NIC_CSQ_DEPTH_REG);\n\tif (enable)\n\t\treg_val |= HCLGEVF_NIC_SW_RST_RDY;\n\telse\n\t\treg_val &= ~HCLGEVF_NIC_SW_RST_RDY;\n\n\thclgevf_write_dev(&hdev->hw, HCLGE_COMM_NIC_CSQ_DEPTH_REG,\n\t\t\t  reg_val);\n}\n\nstatic int hclgevf_reset_stack(struct hclgevf_dev *hdev)\n{\n\tint ret;\n\n\t \n\tret = hclgevf_notify_client(hdev, HNAE3_UNINIT_CLIENT);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = hclgevf_reset_hdev(hdev);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"hclge device re-init failed, VF is disabled!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = hclgevf_notify_client(hdev, HNAE3_INIT_CLIENT);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\thclgevf_reset_handshake(hdev, false);\n\n\t \n\treturn hclgevf_notify_client(hdev, HNAE3_UP_CLIENT);\n}\n\nstatic int hclgevf_reset_prepare_wait(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_RESET_SYNC_TIME 100\n\n\tif (hdev->reset_type == HNAE3_VF_FUNC_RESET) {\n\t\tstruct hclge_vf_to_pf_msg send_msg;\n\t\tint ret;\n\n\t\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_RESET, 0);\n\t\tret = hclgevf_send_mbx_msg(hdev, &send_msg, true, NULL, 0);\n\t\tif (ret) {\n\t\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\t\"failed to assert VF reset, ret = %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t\thdev->rst_stats.vf_func_rst_cnt++;\n\t}\n\n\tset_bit(HCLGE_COMM_STATE_CMD_DISABLE, &hdev->hw.hw.comm_state);\n\t \n\tmsleep(HCLGEVF_RESET_SYNC_TIME);\n\thclgevf_reset_handshake(hdev, true);\n\tdev_info(&hdev->pdev->dev, \"prepare reset(%d) wait done\\n\",\n\t\t hdev->reset_type);\n\n\treturn 0;\n}\n\nstatic void hclgevf_dump_rst_info(struct hclgevf_dev *hdev)\n{\n\tdev_info(&hdev->pdev->dev, \"VF function reset count: %u\\n\",\n\t\t hdev->rst_stats.vf_func_rst_cnt);\n\tdev_info(&hdev->pdev->dev, \"FLR reset count: %u\\n\",\n\t\t hdev->rst_stats.flr_rst_cnt);\n\tdev_info(&hdev->pdev->dev, \"VF reset count: %u\\n\",\n\t\t hdev->rst_stats.vf_rst_cnt);\n\tdev_info(&hdev->pdev->dev, \"reset done count: %u\\n\",\n\t\t hdev->rst_stats.rst_done_cnt);\n\tdev_info(&hdev->pdev->dev, \"HW reset done count: %u\\n\",\n\t\t hdev->rst_stats.hw_rst_done_cnt);\n\tdev_info(&hdev->pdev->dev, \"reset count: %u\\n\",\n\t\t hdev->rst_stats.rst_cnt);\n\tdev_info(&hdev->pdev->dev, \"reset fail count: %u\\n\",\n\t\t hdev->rst_stats.rst_fail_cnt);\n\tdev_info(&hdev->pdev->dev, \"vector0 interrupt enable status: 0x%x\\n\",\n\t\t hclgevf_read_dev(&hdev->hw, HCLGEVF_MISC_VECTOR_REG_BASE));\n\tdev_info(&hdev->pdev->dev, \"vector0 interrupt status: 0x%x\\n\",\n\t\t hclgevf_read_dev(&hdev->hw, HCLGE_COMM_VECTOR0_CMDQ_STATE_REG));\n\tdev_info(&hdev->pdev->dev, \"handshake status: 0x%x\\n\",\n\t\t hclgevf_read_dev(&hdev->hw, HCLGE_COMM_NIC_CSQ_DEPTH_REG));\n\tdev_info(&hdev->pdev->dev, \"function reset status: 0x%x\\n\",\n\t\t hclgevf_read_dev(&hdev->hw, HCLGEVF_RST_ING));\n\tdev_info(&hdev->pdev->dev, \"hdev state: 0x%lx\\n\", hdev->state);\n}\n\nstatic void hclgevf_reset_err_handle(struct hclgevf_dev *hdev)\n{\n\t \n\thclgevf_reset_handshake(hdev, true);\n\thdev->rst_stats.rst_fail_cnt++;\n\tdev_err(&hdev->pdev->dev, \"failed to reset VF(%u)\\n\",\n\t\thdev->rst_stats.rst_fail_cnt);\n\n\tif (hdev->rst_stats.rst_fail_cnt < HCLGEVF_RESET_MAX_FAIL_CNT)\n\t\tset_bit(hdev->reset_type, &hdev->reset_pending);\n\n\tif (hclgevf_is_reset_pending(hdev)) {\n\t\tset_bit(HCLGEVF_RESET_PENDING, &hdev->reset_state);\n\t\thclgevf_reset_task_schedule(hdev);\n\t} else {\n\t\tset_bit(HCLGEVF_STATE_RST_FAIL, &hdev->state);\n\t\thclgevf_dump_rst_info(hdev);\n\t}\n}\n\nstatic int hclgevf_reset_prepare(struct hclgevf_dev *hdev)\n{\n\tint ret;\n\n\thdev->rst_stats.rst_cnt++;\n\n\t \n\tret = hclgevf_notify_roce_client(hdev, HNAE3_DOWN_CLIENT);\n\tif (ret)\n\t\treturn ret;\n\n\trtnl_lock();\n\t \n\tret = hclgevf_notify_client(hdev, HNAE3_DOWN_CLIENT);\n\trtnl_unlock();\n\tif (ret)\n\t\treturn ret;\n\n\treturn hclgevf_reset_prepare_wait(hdev);\n}\n\nstatic int hclgevf_reset_rebuild(struct hclgevf_dev *hdev)\n{\n\tint ret;\n\n\thdev->rst_stats.hw_rst_done_cnt++;\n\tret = hclgevf_notify_roce_client(hdev, HNAE3_UNINIT_CLIENT);\n\tif (ret)\n\t\treturn ret;\n\n\trtnl_lock();\n\t \n\tret = hclgevf_reset_stack(hdev);\n\trtnl_unlock();\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev, \"failed to reset VF stack\\n\");\n\t\treturn ret;\n\t}\n\n\tret = hclgevf_notify_roce_client(hdev, HNAE3_INIT_CLIENT);\n\t \n\tif (ret &&\n\t    hdev->rst_stats.rst_fail_cnt < HCLGEVF_RESET_MAX_FAIL_CNT - 1)\n\t\treturn ret;\n\n\tret = hclgevf_notify_roce_client(hdev, HNAE3_UP_CLIENT);\n\tif (ret)\n\t\treturn ret;\n\n\thdev->last_reset_time = jiffies;\n\thdev->rst_stats.rst_done_cnt++;\n\thdev->rst_stats.rst_fail_cnt = 0;\n\tclear_bit(HCLGEVF_STATE_RST_FAIL, &hdev->state);\n\n\treturn 0;\n}\n\nstatic void hclgevf_reset(struct hclgevf_dev *hdev)\n{\n\tif (hclgevf_reset_prepare(hdev))\n\t\tgoto err_reset;\n\n\t \n\tif (hclgevf_reset_wait(hdev)) {\n\t\t \n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to fetch H/W reset completion status\\n\");\n\t\tgoto err_reset;\n\t}\n\n\tif (hclgevf_reset_rebuild(hdev))\n\t\tgoto err_reset;\n\n\treturn;\n\nerr_reset:\n\thclgevf_reset_err_handle(hdev);\n}\n\nstatic enum hnae3_reset_type hclgevf_get_reset_level(unsigned long *addr)\n{\n\tenum hnae3_reset_type rst_level = HNAE3_NONE_RESET;\n\n\t \n\tif (test_bit(HNAE3_VF_RESET, addr)) {\n\t\trst_level = HNAE3_VF_RESET;\n\t\tclear_bit(HNAE3_VF_RESET, addr);\n\t\tclear_bit(HNAE3_VF_PF_FUNC_RESET, addr);\n\t\tclear_bit(HNAE3_VF_FUNC_RESET, addr);\n\t} else if (test_bit(HNAE3_VF_FULL_RESET, addr)) {\n\t\trst_level = HNAE3_VF_FULL_RESET;\n\t\tclear_bit(HNAE3_VF_FULL_RESET, addr);\n\t\tclear_bit(HNAE3_VF_FUNC_RESET, addr);\n\t} else if (test_bit(HNAE3_VF_PF_FUNC_RESET, addr)) {\n\t\trst_level = HNAE3_VF_PF_FUNC_RESET;\n\t\tclear_bit(HNAE3_VF_PF_FUNC_RESET, addr);\n\t\tclear_bit(HNAE3_VF_FUNC_RESET, addr);\n\t} else if (test_bit(HNAE3_VF_FUNC_RESET, addr)) {\n\t\trst_level = HNAE3_VF_FUNC_RESET;\n\t\tclear_bit(HNAE3_VF_FUNC_RESET, addr);\n\t} else if (test_bit(HNAE3_FLR_RESET, addr)) {\n\t\trst_level = HNAE3_FLR_RESET;\n\t\tclear_bit(HNAE3_FLR_RESET, addr);\n\t}\n\n\treturn rst_level;\n}\n\nstatic void hclgevf_reset_event(struct pci_dev *pdev,\n\t\t\t\tstruct hnae3_handle *handle)\n{\n\tstruct hnae3_ae_dev *ae_dev = pci_get_drvdata(pdev);\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\n\tdev_info(&hdev->pdev->dev, \"received reset request from VF enet\\n\");\n\n\tif (hdev->default_reset_request)\n\t\thdev->reset_level =\n\t\t\thclgevf_get_reset_level(&hdev->default_reset_request);\n\telse\n\t\thdev->reset_level = HNAE3_VF_FUNC_RESET;\n\n\t \n\tset_bit(HCLGEVF_RESET_REQUESTED, &hdev->reset_state);\n\thclgevf_reset_task_schedule(hdev);\n\n\thdev->last_reset_time = jiffies;\n}\n\nstatic void hclgevf_set_def_reset_request(struct hnae3_ae_dev *ae_dev,\n\t\t\t\t\t  enum hnae3_reset_type rst_type)\n{\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\n\tset_bit(rst_type, &hdev->default_reset_request);\n}\n\nstatic void hclgevf_enable_vector(struct hclgevf_misc_vector *vector, bool en)\n{\n\twritel(en ? 1 : 0, vector->addr);\n}\n\nstatic void hclgevf_reset_prepare_general(struct hnae3_ae_dev *ae_dev,\n\t\t\t\t\t  enum hnae3_reset_type rst_type)\n{\n#define HCLGEVF_RESET_RETRY_WAIT_MS\t500\n#define HCLGEVF_RESET_RETRY_CNT\t\t5\n\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\tint retry_cnt = 0;\n\tint ret;\n\n\twhile (retry_cnt++ < HCLGEVF_RESET_RETRY_CNT) {\n\t\tdown(&hdev->reset_sem);\n\t\tset_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state);\n\t\thdev->reset_type = rst_type;\n\t\tret = hclgevf_reset_prepare(hdev);\n\t\tif (!ret && !hdev->reset_pending)\n\t\t\tbreak;\n\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to prepare to reset, ret=%d, reset_pending:0x%lx, retry_cnt:%d\\n\",\n\t\t\tret, hdev->reset_pending, retry_cnt);\n\t\tclear_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state);\n\t\tup(&hdev->reset_sem);\n\t\tmsleep(HCLGEVF_RESET_RETRY_WAIT_MS);\n\t}\n\n\t \n\thclgevf_enable_vector(&hdev->misc_vector, false);\n\n\tif (hdev->reset_type == HNAE3_FLR_RESET)\n\t\thdev->rst_stats.flr_rst_cnt++;\n}\n\nstatic void hclgevf_reset_done(struct hnae3_ae_dev *ae_dev)\n{\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\tint ret;\n\n\thclgevf_enable_vector(&hdev->misc_vector, true);\n\n\tret = hclgevf_reset_rebuild(hdev);\n\tif (ret)\n\t\tdev_warn(&hdev->pdev->dev, \"fail to rebuild, ret=%d\\n\",\n\t\t\t ret);\n\n\thdev->reset_type = HNAE3_NONE_RESET;\n\tclear_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state);\n\tup(&hdev->reset_sem);\n}\n\nstatic u32 hclgevf_get_fw_version(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\treturn hdev->fw_version;\n}\n\nstatic void hclgevf_get_misc_vector(struct hclgevf_dev *hdev)\n{\n\tstruct hclgevf_misc_vector *vector = &hdev->misc_vector;\n\n\tvector->vector_irq = pci_irq_vector(hdev->pdev,\n\t\t\t\t\t    HCLGEVF_MISC_VECTOR_NUM);\n\tvector->addr = hdev->hw.hw.io_base + HCLGEVF_MISC_VECTOR_REG_BASE;\n\t \n\thdev->vector_status[HCLGEVF_MISC_VECTOR_NUM] = 0;\n\thdev->vector_irq[HCLGEVF_MISC_VECTOR_NUM] = vector->vector_irq;\n\n\thdev->num_msi_left -= 1;\n\thdev->num_msi_used += 1;\n}\n\nvoid hclgevf_reset_task_schedule(struct hclgevf_dev *hdev)\n{\n\tif (!test_bit(HCLGEVF_STATE_REMOVING, &hdev->state) &&\n\t    test_bit(HCLGEVF_STATE_SERVICE_INITED, &hdev->state) &&\n\t    !test_and_set_bit(HCLGEVF_STATE_RST_SERVICE_SCHED,\n\t\t\t      &hdev->state))\n\t\tmod_delayed_work(hclgevf_wq, &hdev->service_task, 0);\n}\n\nvoid hclgevf_mbx_task_schedule(struct hclgevf_dev *hdev)\n{\n\tif (!test_bit(HCLGEVF_STATE_REMOVING, &hdev->state) &&\n\t    !test_and_set_bit(HCLGEVF_STATE_MBX_SERVICE_SCHED,\n\t\t\t      &hdev->state))\n\t\tmod_delayed_work(hclgevf_wq, &hdev->service_task, 0);\n}\n\nstatic void hclgevf_task_schedule(struct hclgevf_dev *hdev,\n\t\t\t\t  unsigned long delay)\n{\n\tif (!test_bit(HCLGEVF_STATE_REMOVING, &hdev->state) &&\n\t    !test_bit(HCLGEVF_STATE_RST_FAIL, &hdev->state))\n\t\tmod_delayed_work(hclgevf_wq, &hdev->service_task, delay);\n}\n\nstatic void hclgevf_reset_service_task(struct hclgevf_dev *hdev)\n{\n#define\tHCLGEVF_MAX_RESET_ATTEMPTS_CNT\t3\n\n\tif (!test_and_clear_bit(HCLGEVF_STATE_RST_SERVICE_SCHED, &hdev->state))\n\t\treturn;\n\n\tdown(&hdev->reset_sem);\n\tset_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state);\n\n\tif (test_and_clear_bit(HCLGEVF_RESET_PENDING,\n\t\t\t       &hdev->reset_state)) {\n\t\t \n\t\thdev->reset_attempts = 0;\n\n\t\thdev->last_reset_time = jiffies;\n\t\thdev->reset_type =\n\t\t\thclgevf_get_reset_level(&hdev->reset_pending);\n\t\tif (hdev->reset_type != HNAE3_NONE_RESET)\n\t\t\thclgevf_reset(hdev);\n\t} else if (test_and_clear_bit(HCLGEVF_RESET_REQUESTED,\n\t\t\t\t      &hdev->reset_state)) {\n\t\t \n\t\tif (hdev->reset_attempts > HCLGEVF_MAX_RESET_ATTEMPTS_CNT) {\n\t\t\t \n\t\t\tset_bit(HNAE3_VF_FULL_RESET, &hdev->reset_pending);\n\n\t\t\t \n\t\t\tset_bit(HCLGEVF_RESET_PENDING, &hdev->reset_state);\n\t\t} else {\n\t\t\thdev->reset_attempts++;\n\n\t\t\tset_bit(hdev->reset_level, &hdev->reset_pending);\n\t\t\tset_bit(HCLGEVF_RESET_PENDING, &hdev->reset_state);\n\t\t}\n\t\thclgevf_reset_task_schedule(hdev);\n\t}\n\n\thdev->reset_type = HNAE3_NONE_RESET;\n\tclear_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state);\n\tup(&hdev->reset_sem);\n}\n\nstatic void hclgevf_mailbox_service_task(struct hclgevf_dev *hdev)\n{\n\tif (!test_and_clear_bit(HCLGEVF_STATE_MBX_SERVICE_SCHED, &hdev->state))\n\t\treturn;\n\n\tif (test_and_set_bit(HCLGEVF_STATE_MBX_HANDLING, &hdev->state))\n\t\treturn;\n\n\thclgevf_mbx_async_handler(hdev);\n\n\tclear_bit(HCLGEVF_STATE_MBX_HANDLING, &hdev->state);\n}\n\nstatic void hclgevf_keep_alive(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tint ret;\n\n\tif (test_bit(HCLGE_COMM_STATE_CMD_DISABLE, &hdev->hw.hw.comm_state))\n\t\treturn;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_KEEP_ALIVE, 0);\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF sends keep alive cmd failed(=%d)\\n\", ret);\n}\n\nstatic void hclgevf_periodic_service_task(struct hclgevf_dev *hdev)\n{\n\tunsigned long delta = round_jiffies_relative(HZ);\n\tstruct hnae3_handle *handle = &hdev->nic;\n\n\tif (test_bit(HCLGEVF_STATE_RST_FAIL, &hdev->state) ||\n\t    test_bit(HCLGE_COMM_STATE_CMD_DISABLE, &hdev->hw.hw.comm_state))\n\t\treturn;\n\n\tif (time_is_after_jiffies(hdev->last_serv_processed + HZ)) {\n\t\tdelta = jiffies - hdev->last_serv_processed;\n\n\t\tif (delta < round_jiffies_relative(HZ)) {\n\t\t\tdelta = round_jiffies_relative(HZ) - delta;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\thdev->serv_processed_cnt++;\n\tif (!(hdev->serv_processed_cnt % HCLGEVF_KEEP_ALIVE_TASK_INTERVAL))\n\t\thclgevf_keep_alive(hdev);\n\n\tif (test_bit(HCLGEVF_STATE_DOWN, &hdev->state)) {\n\t\thdev->last_serv_processed = jiffies;\n\t\tgoto out;\n\t}\n\n\tif (!(hdev->serv_processed_cnt % HCLGEVF_STATS_TIMER_INTERVAL))\n\t\thclge_comm_tqps_update_stats(handle, &hdev->hw.hw);\n\n\t \n\tif (!test_bit(HCLGEVF_STATE_PF_PUSH_LINK_STATUS, &hdev->state))\n\t\thclgevf_request_link_info(hdev);\n\n\thclgevf_update_link_mode(hdev);\n\n\thclgevf_sync_vlan_filter(hdev);\n\n\thclgevf_sync_mac_table(hdev);\n\n\thclgevf_sync_promisc_mode(hdev);\n\n\thdev->last_serv_processed = jiffies;\n\nout:\n\thclgevf_task_schedule(hdev, delta);\n}\n\nstatic void hclgevf_service_task(struct work_struct *work)\n{\n\tstruct hclgevf_dev *hdev = container_of(work, struct hclgevf_dev,\n\t\t\t\t\t\tservice_task.work);\n\n\thclgevf_reset_service_task(hdev);\n\thclgevf_mailbox_service_task(hdev);\n\thclgevf_periodic_service_task(hdev);\n\n\t \n\thclgevf_reset_service_task(hdev);\n\thclgevf_mailbox_service_task(hdev);\n}\n\nstatic void hclgevf_clear_event_cause(struct hclgevf_dev *hdev, u32 regclr)\n{\n\thclgevf_write_dev(&hdev->hw, HCLGE_COMM_VECTOR0_CMDQ_SRC_REG, regclr);\n}\n\nstatic enum hclgevf_evt_cause hclgevf_check_evt_cause(struct hclgevf_dev *hdev,\n\t\t\t\t\t\t      u32 *clearval)\n{\n\tu32 val, cmdq_stat_reg, rst_ing_reg;\n\n\t \n\tcmdq_stat_reg = hclgevf_read_dev(&hdev->hw,\n\t\t\t\t\t HCLGE_COMM_VECTOR0_CMDQ_STATE_REG);\n\tif (BIT(HCLGEVF_VECTOR0_RST_INT_B) & cmdq_stat_reg) {\n\t\trst_ing_reg = hclgevf_read_dev(&hdev->hw, HCLGEVF_RST_ING);\n\t\tdev_info(&hdev->pdev->dev,\n\t\t\t \"receive reset interrupt 0x%x!\\n\", rst_ing_reg);\n\t\tset_bit(HNAE3_VF_RESET, &hdev->reset_pending);\n\t\tset_bit(HCLGEVF_RESET_PENDING, &hdev->reset_state);\n\t\tset_bit(HCLGE_COMM_STATE_CMD_DISABLE, &hdev->hw.hw.comm_state);\n\t\t*clearval = ~(1U << HCLGEVF_VECTOR0_RST_INT_B);\n\t\thdev->rst_stats.vf_rst_cnt++;\n\t\t \n\t\tval = hclgevf_read_dev(&hdev->hw, HCLGEVF_VF_RST_ING);\n\t\thclgevf_write_dev(&hdev->hw, HCLGEVF_VF_RST_ING,\n\t\t\t\t  val | HCLGEVF_VF_RST_ING_BIT);\n\t\treturn HCLGEVF_VECTOR0_EVENT_RST;\n\t}\n\n\t \n\tif (BIT(HCLGEVF_VECTOR0_RX_CMDQ_INT_B) & cmdq_stat_reg) {\n\t\t \n\t\tif (hdev->ae_dev->dev_version >= HNAE3_DEVICE_VERSION_V2)\n\t\t\t*clearval = ~(1U << HCLGEVF_VECTOR0_RX_CMDQ_INT_B);\n\t\telse\n\t\t\t*clearval = cmdq_stat_reg &\n\t\t\t\t    ~BIT(HCLGEVF_VECTOR0_RX_CMDQ_INT_B);\n\n\t\treturn HCLGEVF_VECTOR0_EVENT_MBX;\n\t}\n\n\t \n\tdev_info(&hdev->pdev->dev,\n\t\t \"vector 0 interrupt from unknown source, cmdq_src = %#x\\n\",\n\t\t cmdq_stat_reg);\n\n\treturn HCLGEVF_VECTOR0_EVENT_OTHER;\n}\n\nstatic void hclgevf_reset_timer(struct timer_list *t)\n{\n\tstruct hclgevf_dev *hdev = from_timer(hdev, t, reset_timer);\n\n\thclgevf_clear_event_cause(hdev, HCLGEVF_VECTOR0_EVENT_RST);\n\thclgevf_reset_task_schedule(hdev);\n}\n\nstatic irqreturn_t hclgevf_misc_irq_handle(int irq, void *data)\n{\n#define HCLGEVF_RESET_DELAY\t5\n\n\tenum hclgevf_evt_cause event_cause;\n\tstruct hclgevf_dev *hdev = data;\n\tu32 clearval;\n\n\thclgevf_enable_vector(&hdev->misc_vector, false);\n\tevent_cause = hclgevf_check_evt_cause(hdev, &clearval);\n\tif (event_cause != HCLGEVF_VECTOR0_EVENT_OTHER)\n\t\thclgevf_clear_event_cause(hdev, clearval);\n\n\tswitch (event_cause) {\n\tcase HCLGEVF_VECTOR0_EVENT_RST:\n\t\tmod_timer(&hdev->reset_timer,\n\t\t\t  jiffies + msecs_to_jiffies(HCLGEVF_RESET_DELAY));\n\t\tbreak;\n\tcase HCLGEVF_VECTOR0_EVENT_MBX:\n\t\thclgevf_mbx_handler(hdev);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\thclgevf_enable_vector(&hdev->misc_vector, true);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int hclgevf_configure(struct hclgevf_dev *hdev)\n{\n\tint ret;\n\n\thdev->gro_en = true;\n\n\tret = hclgevf_get_basic_info(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = hclgevf_get_port_base_vlan_filter_state(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = hclgevf_get_queue_info(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = hclgevf_get_queue_depth(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn hclgevf_get_pf_media_type(hdev);\n}\n\nstatic int hclgevf_alloc_hdev(struct hnae3_ae_dev *ae_dev)\n{\n\tstruct pci_dev *pdev = ae_dev->pdev;\n\tstruct hclgevf_dev *hdev;\n\n\thdev = devm_kzalloc(&pdev->dev, sizeof(*hdev), GFP_KERNEL);\n\tif (!hdev)\n\t\treturn -ENOMEM;\n\n\thdev->pdev = pdev;\n\thdev->ae_dev = ae_dev;\n\tae_dev->priv = hdev;\n\n\treturn 0;\n}\n\nstatic int hclgevf_init_roce_base_info(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_handle *roce = &hdev->roce;\n\tstruct hnae3_handle *nic = &hdev->nic;\n\n\troce->rinfo.num_vectors = hdev->num_roce_msix;\n\n\tif (hdev->num_msi_left < roce->rinfo.num_vectors ||\n\t    hdev->num_msi_left == 0)\n\t\treturn -EINVAL;\n\n\troce->rinfo.base_vector = hdev->roce_base_msix_offset;\n\n\troce->rinfo.netdev = nic->kinfo.netdev;\n\troce->rinfo.roce_io_base = hdev->hw.hw.io_base;\n\troce->rinfo.roce_mem_base = hdev->hw.hw.mem_base;\n\n\troce->pdev = nic->pdev;\n\troce->ae_algo = nic->ae_algo;\n\troce->numa_node_mask = nic->numa_node_mask;\n\n\treturn 0;\n}\n\nstatic int hclgevf_config_gro(struct hclgevf_dev *hdev)\n{\n\tstruct hclgevf_cfg_gro_status_cmd *req;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\tif (!hnae3_ae_dev_gro_supported(hdev->ae_dev))\n\t\treturn 0;\n\n\thclgevf_cmd_setup_basic_desc(&desc, HCLGE_OPC_GRO_GENERIC_CONFIG,\n\t\t\t\t     false);\n\treq = (struct hclgevf_cfg_gro_status_cmd *)desc.data;\n\n\treq->gro_en = hdev->gro_en ? 1 : 0;\n\n\tret = hclgevf_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"VF GRO hardware config cmd failed, ret = %d.\\n\", ret);\n\n\treturn ret;\n}\n\nstatic int hclgevf_rss_init_hw(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_comm_rss_cfg *rss_cfg = &hdev->rss_cfg;\n\tu16 tc_offset[HCLGE_COMM_MAX_TC_NUM];\n\tu16 tc_valid[HCLGE_COMM_MAX_TC_NUM];\n\tu16 tc_size[HCLGE_COMM_MAX_TC_NUM];\n\tint ret;\n\n\tif (hdev->ae_dev->dev_version >= HNAE3_DEVICE_VERSION_V2) {\n\t\tret = hclge_comm_set_rss_algo_key(&hdev->hw.hw,\n\t\t\t\t\t\t  rss_cfg->rss_algo,\n\t\t\t\t\t\t  rss_cfg->rss_hash_key);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = hclge_comm_set_rss_input_tuple(&hdev->hw.hw, rss_cfg);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = hclge_comm_set_rss_indir_table(hdev->ae_dev, &hdev->hw.hw,\n\t\t\t\t\t     rss_cfg->rss_indirection_tbl);\n\tif (ret)\n\t\treturn ret;\n\n\thclge_comm_get_rss_tc_info(rss_cfg->rss_size, hdev->hw_tc_map,\n\t\t\t\t   tc_offset, tc_valid, tc_size);\n\n\treturn hclge_comm_set_rss_tc_mode(&hdev->hw.hw, tc_offset,\n\t\t\t\t\t  tc_valid, tc_size);\n}\n\nstatic int hclgevf_init_vlan_config(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_handle *nic = &hdev->nic;\n\tint ret;\n\n\tret = hclgevf_en_hw_strip_rxvtag(nic, true);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed to enable rx vlan offload, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treturn hclgevf_set_vlan_filter(&hdev->nic, htons(ETH_P_8021Q), 0,\n\t\t\t\t       false);\n}\n\nstatic void hclgevf_flush_link_update(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_FLUSH_LINK_TIMEOUT\t100000\n\n\tunsigned long last = hdev->serv_processed_cnt;\n\tint i = 0;\n\n\twhile (test_bit(HCLGEVF_STATE_LINK_UPDATING, &hdev->state) &&\n\t       i++ < HCLGEVF_FLUSH_LINK_TIMEOUT &&\n\t       last == hdev->serv_processed_cnt)\n\t\tusleep_range(1, 1);\n}\n\nstatic void hclgevf_set_timer_task(struct hnae3_handle *handle, bool enable)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\tif (enable) {\n\t\thclgevf_task_schedule(hdev, 0);\n\t} else {\n\t\tset_bit(HCLGEVF_STATE_DOWN, &hdev->state);\n\n\t\t \n\t\tsmp_mb__before_atomic();\n\t\thclgevf_flush_link_update(hdev);\n\t}\n}\n\nstatic int hclgevf_ae_start(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\tclear_bit(HCLGEVF_STATE_DOWN, &hdev->state);\n\tclear_bit(HCLGEVF_STATE_PF_PUSH_LINK_STATUS, &hdev->state);\n\n\thclge_comm_reset_tqp_stats(handle);\n\n\thclgevf_request_link_info(hdev);\n\n\thclgevf_update_link_mode(hdev);\n\n\treturn 0;\n}\n\nstatic void hclgevf_ae_stop(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\tset_bit(HCLGEVF_STATE_DOWN, &hdev->state);\n\n\tif (hdev->reset_type != HNAE3_VF_RESET)\n\t\thclgevf_reset_tqp(handle);\n\n\thclge_comm_reset_tqp_stats(handle);\n\thclgevf_update_link_status(hdev, 0);\n}\n\nstatic int hclgevf_set_alive(struct hnae3_handle *handle, bool alive)\n{\n#define HCLGEVF_STATE_ALIVE\t1\n#define HCLGEVF_STATE_NOT_ALIVE\t0\n\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hclge_vf_to_pf_msg send_msg;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_ALIVE, 0);\n\tsend_msg.data[0] = alive ? HCLGEVF_STATE_ALIVE :\n\t\t\t\tHCLGEVF_STATE_NOT_ALIVE;\n\treturn hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n}\n\nstatic int hclgevf_client_start(struct hnae3_handle *handle)\n{\n\treturn hclgevf_set_alive(handle, true);\n}\n\nstatic void hclgevf_client_stop(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tint ret;\n\n\tret = hclgevf_set_alive(handle, false);\n\tif (ret)\n\t\tdev_warn(&hdev->pdev->dev,\n\t\t\t \"%s failed %d\\n\", __func__, ret);\n}\n\nstatic void hclgevf_state_init(struct hclgevf_dev *hdev)\n{\n\tclear_bit(HCLGEVF_STATE_MBX_SERVICE_SCHED, &hdev->state);\n\tclear_bit(HCLGEVF_STATE_MBX_HANDLING, &hdev->state);\n\tclear_bit(HCLGEVF_STATE_RST_FAIL, &hdev->state);\n\n\tINIT_DELAYED_WORK(&hdev->service_task, hclgevf_service_task);\n\n\tmutex_init(&hdev->mbx_resp.mbx_mutex);\n\tsema_init(&hdev->reset_sem, 1);\n\n\tspin_lock_init(&hdev->mac_table.mac_list_lock);\n\tINIT_LIST_HEAD(&hdev->mac_table.uc_mac_list);\n\tINIT_LIST_HEAD(&hdev->mac_table.mc_mac_list);\n\n\t \n\tset_bit(HCLGEVF_STATE_DOWN, &hdev->state);\n}\n\nstatic void hclgevf_state_uninit(struct hclgevf_dev *hdev)\n{\n\tset_bit(HCLGEVF_STATE_DOWN, &hdev->state);\n\tset_bit(HCLGEVF_STATE_REMOVING, &hdev->state);\n\n\tif (hdev->service_task.work.func)\n\t\tcancel_delayed_work_sync(&hdev->service_task);\n\n\tmutex_destroy(&hdev->mbx_resp.mbx_mutex);\n}\n\nstatic int hclgevf_init_msi(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\tint vectors;\n\tint i;\n\n\tif (hnae3_dev_roce_supported(hdev))\n\t\tvectors = pci_alloc_irq_vectors(pdev,\n\t\t\t\t\t\thdev->roce_base_msix_offset + 1,\n\t\t\t\t\t\thdev->num_msi,\n\t\t\t\t\t\tPCI_IRQ_MSIX);\n\telse\n\t\tvectors = pci_alloc_irq_vectors(pdev, HNAE3_MIN_VECTOR_NUM,\n\t\t\t\t\t\thdev->num_msi,\n\t\t\t\t\t\tPCI_IRQ_MSI | PCI_IRQ_MSIX);\n\n\tif (vectors < 0) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"failed(%d) to allocate MSI/MSI-X vectors\\n\",\n\t\t\tvectors);\n\t\treturn vectors;\n\t}\n\tif (vectors < hdev->num_msi)\n\t\tdev_warn(&hdev->pdev->dev,\n\t\t\t \"requested %u MSI/MSI-X, but allocated %d MSI/MSI-X\\n\",\n\t\t\t hdev->num_msi, vectors);\n\n\thdev->num_msi = vectors;\n\thdev->num_msi_left = vectors;\n\n\thdev->vector_status = devm_kcalloc(&pdev->dev, hdev->num_msi,\n\t\t\t\t\t   sizeof(u16), GFP_KERNEL);\n\tif (!hdev->vector_status) {\n\t\tpci_free_irq_vectors(pdev);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < hdev->num_msi; i++)\n\t\thdev->vector_status[i] = HCLGEVF_INVALID_VPORT;\n\n\thdev->vector_irq = devm_kcalloc(&pdev->dev, hdev->num_msi,\n\t\t\t\t\tsizeof(int), GFP_KERNEL);\n\tif (!hdev->vector_irq) {\n\t\tdevm_kfree(&pdev->dev, hdev->vector_status);\n\t\tpci_free_irq_vectors(pdev);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void hclgevf_uninit_msi(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\n\tdevm_kfree(&pdev->dev, hdev->vector_status);\n\tdevm_kfree(&pdev->dev, hdev->vector_irq);\n\tpci_free_irq_vectors(pdev);\n}\n\nstatic int hclgevf_misc_irq_init(struct hclgevf_dev *hdev)\n{\n\tint ret;\n\n\thclgevf_get_misc_vector(hdev);\n\n\tsnprintf(hdev->misc_vector.name, HNAE3_INT_NAME_LEN, \"%s-misc-%s\",\n\t\t HCLGEVF_NAME, pci_name(hdev->pdev));\n\tret = request_irq(hdev->misc_vector.vector_irq, hclgevf_misc_irq_handle,\n\t\t\t  0, hdev->misc_vector.name, hdev);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev, \"VF failed to request misc irq(%d)\\n\",\n\t\t\thdev->misc_vector.vector_irq);\n\t\treturn ret;\n\t}\n\n\thclgevf_clear_event_cause(hdev, 0);\n\n\t \n\thclgevf_enable_vector(&hdev->misc_vector, true);\n\n\treturn ret;\n}\n\nstatic void hclgevf_misc_irq_uninit(struct hclgevf_dev *hdev)\n{\n\t \n\thclgevf_enable_vector(&hdev->misc_vector, false);\n\tsynchronize_irq(hdev->misc_vector.vector_irq);\n\tfree_irq(hdev->misc_vector.vector_irq, hdev);\n\thclgevf_free_vector(hdev, 0);\n}\n\nstatic void hclgevf_info_show(struct hclgevf_dev *hdev)\n{\n\tstruct device *dev = &hdev->pdev->dev;\n\n\tdev_info(dev, \"VF info begin:\\n\");\n\n\tdev_info(dev, \"Task queue pairs numbers: %u\\n\", hdev->num_tqps);\n\tdev_info(dev, \"Desc num per TX queue: %u\\n\", hdev->num_tx_desc);\n\tdev_info(dev, \"Desc num per RX queue: %u\\n\", hdev->num_rx_desc);\n\tdev_info(dev, \"Numbers of vports: %u\\n\", hdev->num_alloc_vport);\n\tdev_info(dev, \"HW tc map: 0x%x\\n\", hdev->hw_tc_map);\n\tdev_info(dev, \"PF media type of this VF: %u\\n\",\n\t\t hdev->hw.mac.media_type);\n\n\tdev_info(dev, \"VF info end.\\n\");\n}\n\nstatic int hclgevf_init_nic_client_instance(struct hnae3_ae_dev *ae_dev,\n\t\t\t\t\t    struct hnae3_client *client)\n{\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\tint rst_cnt = hdev->rst_stats.rst_cnt;\n\tint ret;\n\n\tret = client->ops->init_instance(&hdev->nic);\n\tif (ret)\n\t\treturn ret;\n\n\tset_bit(HCLGEVF_STATE_NIC_REGISTERED, &hdev->state);\n\tif (test_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state) ||\n\t    rst_cnt != hdev->rst_stats.rst_cnt) {\n\t\tclear_bit(HCLGEVF_STATE_NIC_REGISTERED, &hdev->state);\n\n\t\tclient->ops->uninit_instance(&hdev->nic, 0);\n\t\treturn -EBUSY;\n\t}\n\n\thnae3_set_client_init_flag(client, ae_dev, 1);\n\n\tif (netif_msg_drv(&hdev->nic))\n\t\thclgevf_info_show(hdev);\n\n\treturn 0;\n}\n\nstatic int hclgevf_init_roce_client_instance(struct hnae3_ae_dev *ae_dev,\n\t\t\t\t\t     struct hnae3_client *client)\n{\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\tint ret;\n\n\tif (!hnae3_dev_roce_supported(hdev) || !hdev->roce_client ||\n\t    !hdev->nic_client)\n\t\treturn 0;\n\n\tret = hclgevf_init_roce_base_info(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = client->ops->init_instance(&hdev->roce);\n\tif (ret)\n\t\treturn ret;\n\n\tset_bit(HCLGEVF_STATE_ROCE_REGISTERED, &hdev->state);\n\thnae3_set_client_init_flag(client, ae_dev, 1);\n\n\treturn 0;\n}\n\nstatic int hclgevf_init_client_instance(struct hnae3_client *client,\n\t\t\t\t\tstruct hnae3_ae_dev *ae_dev)\n{\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\tint ret;\n\n\tswitch (client->type) {\n\tcase HNAE3_CLIENT_KNIC:\n\t\thdev->nic_client = client;\n\t\thdev->nic.client = client;\n\n\t\tret = hclgevf_init_nic_client_instance(ae_dev, client);\n\t\tif (ret)\n\t\t\tgoto clear_nic;\n\n\t\tret = hclgevf_init_roce_client_instance(ae_dev,\n\t\t\t\t\t\t\thdev->roce_client);\n\t\tif (ret)\n\t\t\tgoto clear_roce;\n\n\t\tbreak;\n\tcase HNAE3_CLIENT_ROCE:\n\t\tif (hnae3_dev_roce_supported(hdev)) {\n\t\t\thdev->roce_client = client;\n\t\t\thdev->roce.client = client;\n\t\t}\n\n\t\tret = hclgevf_init_roce_client_instance(ae_dev, client);\n\t\tif (ret)\n\t\t\tgoto clear_roce;\n\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n\nclear_nic:\n\thdev->nic_client = NULL;\n\thdev->nic.client = NULL;\n\treturn ret;\nclear_roce:\n\thdev->roce_client = NULL;\n\thdev->roce.client = NULL;\n\treturn ret;\n}\n\nstatic void hclgevf_uninit_client_instance(struct hnae3_client *client,\n\t\t\t\t\t   struct hnae3_ae_dev *ae_dev)\n{\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\n\t \n\tif (hdev->roce_client) {\n\t\twhile (test_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state))\n\t\t\tmsleep(HCLGEVF_WAIT_RESET_DONE);\n\t\tclear_bit(HCLGEVF_STATE_ROCE_REGISTERED, &hdev->state);\n\n\t\thdev->roce_client->ops->uninit_instance(&hdev->roce, 0);\n\t\thdev->roce_client = NULL;\n\t\thdev->roce.client = NULL;\n\t}\n\n\t \n\tif (client->ops->uninit_instance && hdev->nic_client &&\n\t    client->type != HNAE3_CLIENT_ROCE) {\n\t\twhile (test_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state))\n\t\t\tmsleep(HCLGEVF_WAIT_RESET_DONE);\n\t\tclear_bit(HCLGEVF_STATE_NIC_REGISTERED, &hdev->state);\n\n\t\tclient->ops->uninit_instance(&hdev->nic, 0);\n\t\thdev->nic_client = NULL;\n\t\thdev->nic.client = NULL;\n\t}\n}\n\nstatic int hclgevf_dev_mem_map(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\tstruct hclgevf_hw *hw = &hdev->hw;\n\n\t \n\tif (!(pci_select_bars(pdev, IORESOURCE_MEM) & BIT(HCLGEVF_MEM_BAR)))\n\t\treturn 0;\n\n\thw->hw.mem_base =\n\t\tdevm_ioremap_wc(&pdev->dev,\n\t\t\t\tpci_resource_start(pdev, HCLGEVF_MEM_BAR),\n\t\t\t\tpci_resource_len(pdev, HCLGEVF_MEM_BAR));\n\tif (!hw->hw.mem_base) {\n\t\tdev_err(&pdev->dev, \"failed to map device memory\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nstatic int hclgevf_pci_init(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\tstruct hclgevf_hw *hw;\n\tint ret;\n\n\tret = pci_enable_device(pdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to enable PCI device\\n\");\n\t\treturn ret;\n\t}\n\n\tret = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"can't set consistent PCI DMA, exiting\");\n\t\tgoto err_disable_device;\n\t}\n\n\tret = pci_request_regions(pdev, HCLGEVF_DRIVER_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"PCI request regions failed %d\\n\", ret);\n\t\tgoto err_disable_device;\n\t}\n\n\tpci_set_master(pdev);\n\thw = &hdev->hw;\n\thw->hw.io_base = pci_iomap(pdev, 2, 0);\n\tif (!hw->hw.io_base) {\n\t\tdev_err(&pdev->dev, \"can't map configuration register space\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_release_regions;\n\t}\n\n\tret = hclgevf_dev_mem_map(hdev);\n\tif (ret)\n\t\tgoto err_unmap_io_base;\n\n\treturn 0;\n\nerr_unmap_io_base:\n\tpci_iounmap(pdev, hdev->hw.hw.io_base);\nerr_release_regions:\n\tpci_release_regions(pdev);\nerr_disable_device:\n\tpci_disable_device(pdev);\n\n\treturn ret;\n}\n\nstatic void hclgevf_pci_uninit(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\n\tif (hdev->hw.hw.mem_base)\n\t\tdevm_iounmap(&pdev->dev, hdev->hw.hw.mem_base);\n\n\tpci_iounmap(pdev, hdev->hw.hw.io_base);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n}\n\nstatic int hclgevf_query_vf_resource(struct hclgevf_dev *hdev)\n{\n\tstruct hclgevf_query_res_cmd *req;\n\tstruct hclge_desc desc;\n\tint ret;\n\n\thclgevf_cmd_setup_basic_desc(&desc, HCLGE_OPC_QUERY_VF_RSRC, true);\n\tret = hclgevf_cmd_send(&hdev->hw, &desc, 1);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"query vf resource failed, ret = %d.\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treq = (struct hclgevf_query_res_cmd *)desc.data;\n\n\tif (hnae3_dev_roce_supported(hdev)) {\n\t\thdev->roce_base_msix_offset =\n\t\thnae3_get_field(le16_to_cpu(req->msixcap_localid_ba_rocee),\n\t\t\t\tHCLGEVF_MSIX_OFT_ROCEE_M,\n\t\t\t\tHCLGEVF_MSIX_OFT_ROCEE_S);\n\t\thdev->num_roce_msix =\n\t\thnae3_get_field(le16_to_cpu(req->vf_intr_vector_number),\n\t\t\t\tHCLGEVF_VEC_NUM_M, HCLGEVF_VEC_NUM_S);\n\n\t\t \n\t\thdev->num_nic_msix = hdev->num_roce_msix;\n\n\t\t \n\t\thdev->num_msi = hdev->num_roce_msix +\n\t\t\t\thdev->roce_base_msix_offset;\n\t} else {\n\t\thdev->num_msi =\n\t\thnae3_get_field(le16_to_cpu(req->vf_intr_vector_number),\n\t\t\t\tHCLGEVF_VEC_NUM_M, HCLGEVF_VEC_NUM_S);\n\n\t\thdev->num_nic_msix = hdev->num_msi;\n\t}\n\n\tif (hdev->num_nic_msix < HNAE3_MIN_VECTOR_NUM) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"Just %u msi resources, not enough for vf(min:2).\\n\",\n\t\t\thdev->num_nic_msix);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void hclgevf_set_default_dev_specs(struct hclgevf_dev *hdev)\n{\n#define HCLGEVF_MAX_NON_TSO_BD_NUM\t\t\t8U\n\n\tstruct hnae3_ae_dev *ae_dev = pci_get_drvdata(hdev->pdev);\n\n\tae_dev->dev_specs.max_non_tso_bd_num =\n\t\t\t\t\tHCLGEVF_MAX_NON_TSO_BD_NUM;\n\tae_dev->dev_specs.rss_ind_tbl_size = HCLGEVF_RSS_IND_TBL_SIZE;\n\tae_dev->dev_specs.rss_key_size = HCLGE_COMM_RSS_KEY_SIZE;\n\tae_dev->dev_specs.max_int_gl = HCLGEVF_DEF_MAX_INT_GL;\n\tae_dev->dev_specs.max_frm_size = HCLGEVF_MAC_MAX_FRAME;\n}\n\nstatic void hclgevf_parse_dev_specs(struct hclgevf_dev *hdev,\n\t\t\t\t    struct hclge_desc *desc)\n{\n\tstruct hnae3_ae_dev *ae_dev = pci_get_drvdata(hdev->pdev);\n\tstruct hclgevf_dev_specs_0_cmd *req0;\n\tstruct hclgevf_dev_specs_1_cmd *req1;\n\n\treq0 = (struct hclgevf_dev_specs_0_cmd *)desc[0].data;\n\treq1 = (struct hclgevf_dev_specs_1_cmd *)desc[1].data;\n\n\tae_dev->dev_specs.max_non_tso_bd_num = req0->max_non_tso_bd_num;\n\tae_dev->dev_specs.rss_ind_tbl_size =\n\t\t\t\t\tle16_to_cpu(req0->rss_ind_tbl_size);\n\tae_dev->dev_specs.int_ql_max = le16_to_cpu(req0->int_ql_max);\n\tae_dev->dev_specs.rss_key_size = le16_to_cpu(req0->rss_key_size);\n\tae_dev->dev_specs.max_int_gl = le16_to_cpu(req1->max_int_gl);\n\tae_dev->dev_specs.max_frm_size = le16_to_cpu(req1->max_frm_size);\n}\n\nstatic void hclgevf_check_dev_specs(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_dev_specs *dev_specs = &hdev->ae_dev->dev_specs;\n\n\tif (!dev_specs->max_non_tso_bd_num)\n\t\tdev_specs->max_non_tso_bd_num = HCLGEVF_MAX_NON_TSO_BD_NUM;\n\tif (!dev_specs->rss_ind_tbl_size)\n\t\tdev_specs->rss_ind_tbl_size = HCLGEVF_RSS_IND_TBL_SIZE;\n\tif (!dev_specs->rss_key_size)\n\t\tdev_specs->rss_key_size = HCLGE_COMM_RSS_KEY_SIZE;\n\tif (!dev_specs->max_int_gl)\n\t\tdev_specs->max_int_gl = HCLGEVF_DEF_MAX_INT_GL;\n\tif (!dev_specs->max_frm_size)\n\t\tdev_specs->max_frm_size = HCLGEVF_MAC_MAX_FRAME;\n}\n\nstatic int hclgevf_query_dev_specs(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_desc desc[HCLGEVF_QUERY_DEV_SPECS_BD_NUM];\n\tint ret;\n\tint i;\n\n\t \n\tif (hdev->ae_dev->dev_version < HNAE3_DEVICE_VERSION_V3) {\n\t\thclgevf_set_default_dev_specs(hdev);\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < HCLGEVF_QUERY_DEV_SPECS_BD_NUM - 1; i++) {\n\t\thclgevf_cmd_setup_basic_desc(&desc[i],\n\t\t\t\t\t     HCLGE_OPC_QUERY_DEV_SPECS, true);\n\t\tdesc[i].flag |= cpu_to_le16(HCLGE_COMM_CMD_FLAG_NEXT);\n\t}\n\thclgevf_cmd_setup_basic_desc(&desc[i], HCLGE_OPC_QUERY_DEV_SPECS, true);\n\n\tret = hclgevf_cmd_send(&hdev->hw, desc, HCLGEVF_QUERY_DEV_SPECS_BD_NUM);\n\tif (ret)\n\t\treturn ret;\n\n\thclgevf_parse_dev_specs(hdev, desc);\n\thclgevf_check_dev_specs(hdev);\n\n\treturn 0;\n}\n\nstatic int hclgevf_pci_reset(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\tint ret = 0;\n\n\tif ((hdev->reset_type == HNAE3_VF_FULL_RESET ||\n\t     hdev->reset_type == HNAE3_FLR_RESET) &&\n\t    test_bit(HCLGEVF_STATE_IRQ_INITED, &hdev->state)) {\n\t\thclgevf_misc_irq_uninit(hdev);\n\t\thclgevf_uninit_msi(hdev);\n\t\tclear_bit(HCLGEVF_STATE_IRQ_INITED, &hdev->state);\n\t}\n\n\tif (!test_bit(HCLGEVF_STATE_IRQ_INITED, &hdev->state)) {\n\t\tpci_set_master(pdev);\n\t\tret = hclgevf_init_msi(hdev);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"failed(%d) to init MSI/MSI-X\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = hclgevf_misc_irq_init(hdev);\n\t\tif (ret) {\n\t\t\thclgevf_uninit_msi(hdev);\n\t\t\tdev_err(&pdev->dev, \"failed(%d) to init Misc IRQ(vector0)\\n\",\n\t\t\t\tret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tset_bit(HCLGEVF_STATE_IRQ_INITED, &hdev->state);\n\t}\n\n\treturn ret;\n}\n\nstatic int hclgevf_clear_vport_list(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_vf_to_pf_msg send_msg;\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_HANDLE_VF_TBL,\n\t\t\t       HCLGE_MBX_VPORT_LIST_CLEAR);\n\treturn hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n}\n\nstatic void hclgevf_init_rxd_adv_layout(struct hclgevf_dev *hdev)\n{\n\tif (hnae3_ae_dev_rxd_adv_layout_supported(hdev->ae_dev))\n\t\thclgevf_write_dev(&hdev->hw, HCLGEVF_RXD_ADV_LAYOUT_EN_REG, 1);\n}\n\nstatic void hclgevf_uninit_rxd_adv_layout(struct hclgevf_dev *hdev)\n{\n\tif (hnae3_ae_dev_rxd_adv_layout_supported(hdev->ae_dev))\n\t\thclgevf_write_dev(&hdev->hw, HCLGEVF_RXD_ADV_LAYOUT_EN_REG, 0);\n}\n\nstatic int hclgevf_reset_hdev(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\tint ret;\n\n\tret = hclgevf_pci_reset(hdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pci reset failed %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\thclgevf_arq_init(hdev);\n\tret = hclge_comm_cmd_init(hdev->ae_dev, &hdev->hw.hw,\n\t\t\t\t  &hdev->fw_version, false,\n\t\t\t\t  hdev->reset_pending);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"cmd failed %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = hclgevf_rss_init_hw(hdev);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed(%d) to initialize RSS\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = hclgevf_config_gro(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = hclgevf_init_vlan_config(hdev);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed(%d) to initialize VLAN config\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tret = hclgevf_get_port_base_vlan_filter_state(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tset_bit(HCLGEVF_STATE_PROMISC_CHANGED, &hdev->state);\n\n\thclgevf_init_rxd_adv_layout(hdev);\n\n\tdev_info(&hdev->pdev->dev, \"Reset done\\n\");\n\n\treturn 0;\n}\n\nstatic int hclgevf_init_hdev(struct hclgevf_dev *hdev)\n{\n\tstruct pci_dev *pdev = hdev->pdev;\n\tint ret;\n\n\tret = hclgevf_pci_init(hdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = hclgevf_devlink_init(hdev);\n\tif (ret)\n\t\tgoto err_devlink_init;\n\n\tret = hclge_comm_cmd_queue_init(hdev->pdev, &hdev->hw.hw);\n\tif (ret)\n\t\tgoto err_cmd_queue_init;\n\n\thclgevf_arq_init(hdev);\n\tret = hclge_comm_cmd_init(hdev->ae_dev, &hdev->hw.hw,\n\t\t\t\t  &hdev->fw_version, false,\n\t\t\t\t  hdev->reset_pending);\n\tif (ret)\n\t\tgoto err_cmd_init;\n\n\t \n\tret = hclgevf_query_vf_resource(hdev);\n\tif (ret)\n\t\tgoto err_cmd_init;\n\n\tret = hclgevf_query_dev_specs(hdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"failed to query dev specifications, ret = %d\\n\", ret);\n\t\tgoto err_cmd_init;\n\t}\n\n\tret = hclgevf_init_msi(hdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed(%d) to init MSI/MSI-X\\n\", ret);\n\t\tgoto err_cmd_init;\n\t}\n\n\thclgevf_state_init(hdev);\n\thdev->reset_level = HNAE3_VF_FUNC_RESET;\n\thdev->reset_type = HNAE3_NONE_RESET;\n\n\tret = hclgevf_misc_irq_init(hdev);\n\tif (ret)\n\t\tgoto err_misc_irq_init;\n\n\tset_bit(HCLGEVF_STATE_IRQ_INITED, &hdev->state);\n\n\tret = hclgevf_configure(hdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed(%d) to fetch configuration\\n\", ret);\n\t\tgoto err_config;\n\t}\n\n\tret = hclgevf_alloc_tqps(hdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed(%d) to allocate TQPs\\n\", ret);\n\t\tgoto err_config;\n\t}\n\n\tret = hclgevf_set_handle_info(hdev);\n\tif (ret)\n\t\tgoto err_config;\n\n\tret = hclgevf_config_gro(hdev);\n\tif (ret)\n\t\tgoto err_config;\n\n\t \n\tret = hclge_comm_rss_init_cfg(&hdev->nic, hdev->ae_dev,\n\t\t\t\t      &hdev->rss_cfg);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to init rss cfg, ret = %d\\n\", ret);\n\t\tgoto err_config;\n\t}\n\n\tret = hclgevf_rss_init_hw(hdev);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed(%d) to initialize RSS\\n\", ret);\n\t\tgoto err_config;\n\t}\n\n\t \n\tret = hclgevf_clear_vport_list(hdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"failed to clear tbl list configuration, ret = %d.\\n\",\n\t\t\tret);\n\t\tgoto err_config;\n\t}\n\n\tret = hclgevf_init_vlan_config(hdev);\n\tif (ret) {\n\t\tdev_err(&hdev->pdev->dev,\n\t\t\t\"failed(%d) to initialize VLAN config\\n\", ret);\n\t\tgoto err_config;\n\t}\n\n\thclgevf_init_rxd_adv_layout(hdev);\n\n\tset_bit(HCLGEVF_STATE_SERVICE_INITED, &hdev->state);\n\n\thdev->last_reset_time = jiffies;\n\tdev_info(&hdev->pdev->dev, \"finished initializing %s driver\\n\",\n\t\t HCLGEVF_DRIVER_NAME);\n\n\thclgevf_task_schedule(hdev, round_jiffies_relative(HZ));\n\ttimer_setup(&hdev->reset_timer, hclgevf_reset_timer, 0);\n\n\treturn 0;\n\nerr_config:\n\thclgevf_misc_irq_uninit(hdev);\nerr_misc_irq_init:\n\thclgevf_state_uninit(hdev);\n\thclgevf_uninit_msi(hdev);\nerr_cmd_init:\n\thclge_comm_cmd_uninit(hdev->ae_dev, &hdev->hw.hw);\nerr_cmd_queue_init:\n\thclgevf_devlink_uninit(hdev);\nerr_devlink_init:\n\thclgevf_pci_uninit(hdev);\n\tclear_bit(HCLGEVF_STATE_IRQ_INITED, &hdev->state);\n\treturn ret;\n}\n\nstatic void hclgevf_uninit_hdev(struct hclgevf_dev *hdev)\n{\n\tstruct hclge_vf_to_pf_msg send_msg;\n\n\thclgevf_state_uninit(hdev);\n\thclgevf_uninit_rxd_adv_layout(hdev);\n\n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_VF_UNINIT, 0);\n\thclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n\n\tif (test_bit(HCLGEVF_STATE_IRQ_INITED, &hdev->state)) {\n\t\thclgevf_misc_irq_uninit(hdev);\n\t\thclgevf_uninit_msi(hdev);\n\t}\n\n\thclge_comm_cmd_uninit(hdev->ae_dev, &hdev->hw.hw);\n\thclgevf_devlink_uninit(hdev);\n\thclgevf_pci_uninit(hdev);\n\thclgevf_uninit_mac_list(hdev);\n}\n\nstatic int hclgevf_init_ae_dev(struct hnae3_ae_dev *ae_dev)\n{\n\tstruct pci_dev *pdev = ae_dev->pdev;\n\tint ret;\n\n\tret = hclgevf_alloc_hdev(ae_dev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"hclge device allocation failed\\n\");\n\t\treturn ret;\n\t}\n\n\tret = hclgevf_init_hdev(ae_dev->priv);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"hclge device initialization failed\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void hclgevf_uninit_ae_dev(struct hnae3_ae_dev *ae_dev)\n{\n\tstruct hclgevf_dev *hdev = ae_dev->priv;\n\n\thclgevf_uninit_hdev(hdev);\n\tae_dev->priv = NULL;\n}\n\nstatic u32 hclgevf_get_max_channels(struct hclgevf_dev *hdev)\n{\n\tstruct hnae3_handle *nic = &hdev->nic;\n\tstruct hnae3_knic_private_info *kinfo = &nic->kinfo;\n\n\treturn min_t(u32, hdev->rss_size_max,\n\t\t     hdev->num_tqps / kinfo->tc_info.num_tc);\n}\n\n \nstatic void hclgevf_get_channels(struct hnae3_handle *handle,\n\t\t\t\t struct ethtool_channels *ch)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\tch->max_combined = hclgevf_get_max_channels(hdev);\n\tch->other_count = 0;\n\tch->max_other = 0;\n\tch->combined_count = handle->kinfo.rss_size;\n}\n\nstatic void hclgevf_get_tqps_and_rss_info(struct hnae3_handle *handle,\n\t\t\t\t\t  u16 *alloc_tqps, u16 *max_rss_size)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\t*alloc_tqps = hdev->num_tqps;\n\t*max_rss_size = hdev->rss_size_max;\n}\n\nstatic void hclgevf_update_rss_size(struct hnae3_handle *handle,\n\t\t\t\t    u32 new_tqps_num)\n{\n\tstruct hnae3_knic_private_info *kinfo = &handle->kinfo;\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tu16 max_rss_size;\n\n\tkinfo->req_rss_size = new_tqps_num;\n\n\tmax_rss_size = min_t(u16, hdev->rss_size_max,\n\t\t\t     hdev->num_tqps / kinfo->tc_info.num_tc);\n\n\t \n\tif (kinfo->req_rss_size != kinfo->rss_size && kinfo->req_rss_size &&\n\t    kinfo->req_rss_size <= max_rss_size)\n\t\tkinfo->rss_size = kinfo->req_rss_size;\n\telse if (kinfo->rss_size > max_rss_size ||\n\t\t (!kinfo->req_rss_size && kinfo->rss_size < max_rss_size))\n\t\tkinfo->rss_size = max_rss_size;\n\n\tkinfo->num_tqps = kinfo->tc_info.num_tc * kinfo->rss_size;\n}\n\nstatic int hclgevf_set_channels(struct hnae3_handle *handle, u32 new_tqps_num,\n\t\t\t\tbool rxfh_configured)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tstruct hnae3_knic_private_info *kinfo = &handle->kinfo;\n\tu16 tc_offset[HCLGE_COMM_MAX_TC_NUM];\n\tu16 tc_valid[HCLGE_COMM_MAX_TC_NUM];\n\tu16 tc_size[HCLGE_COMM_MAX_TC_NUM];\n\tu16 cur_rss_size = kinfo->rss_size;\n\tu16 cur_tqps = kinfo->num_tqps;\n\tu32 *rss_indir;\n\tunsigned int i;\n\tint ret;\n\n\thclgevf_update_rss_size(handle, new_tqps_num);\n\n\thclge_comm_get_rss_tc_info(kinfo->rss_size, hdev->hw_tc_map,\n\t\t\t\t   tc_offset, tc_valid, tc_size);\n\tret = hclge_comm_set_rss_tc_mode(&hdev->hw.hw, tc_offset,\n\t\t\t\t\t tc_valid, tc_size);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (rxfh_configured)\n\t\tgoto out;\n\n\t \n\trss_indir = kcalloc(hdev->ae_dev->dev_specs.rss_ind_tbl_size,\n\t\t\t    sizeof(u32), GFP_KERNEL);\n\tif (!rss_indir)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < hdev->ae_dev->dev_specs.rss_ind_tbl_size; i++)\n\t\trss_indir[i] = i % kinfo->rss_size;\n\n\thdev->rss_cfg.rss_size = kinfo->rss_size;\n\n\tret = hclgevf_set_rss(handle, rss_indir, NULL, 0);\n\tif (ret)\n\t\tdev_err(&hdev->pdev->dev, \"set rss indir table fail, ret=%d\\n\",\n\t\t\tret);\n\n\tkfree(rss_indir);\n\nout:\n\tif (!ret)\n\t\tdev_info(&hdev->pdev->dev,\n\t\t\t \"Channels changed, rss_size from %u to %u, tqps from %u to %u\",\n\t\t\t cur_rss_size, kinfo->rss_size,\n\t\t\t cur_tqps, kinfo->rss_size * kinfo->tc_info.num_tc);\n\n\treturn ret;\n}\n\nstatic int hclgevf_get_status(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\treturn hdev->hw.mac.link;\n}\n\nstatic void hclgevf_get_ksettings_an_result(struct hnae3_handle *handle,\n\t\t\t\t\t    u8 *auto_neg, u32 *speed,\n\t\t\t\t\t    u8 *duplex, u32 *lane_num)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\tif (speed)\n\t\t*speed = hdev->hw.mac.speed;\n\tif (duplex)\n\t\t*duplex = hdev->hw.mac.duplex;\n\tif (auto_neg)\n\t\t*auto_neg = AUTONEG_DISABLE;\n}\n\nvoid hclgevf_update_speed_duplex(struct hclgevf_dev *hdev, u32 speed,\n\t\t\t\t u8 duplex)\n{\n\thdev->hw.mac.speed = speed;\n\thdev->hw.mac.duplex = duplex;\n}\n\nstatic int hclgevf_gro_en(struct hnae3_handle *handle, bool enable)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\tbool gro_en_old = hdev->gro_en;\n\tint ret;\n\n\thdev->gro_en = enable;\n\tret = hclgevf_config_gro(hdev);\n\tif (ret)\n\t\thdev->gro_en = gro_en_old;\n\n\treturn ret;\n}\n\nstatic void hclgevf_get_media_type(struct hnae3_handle *handle, u8 *media_type,\n\t\t\t\t   u8 *module_type)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\tif (media_type)\n\t\t*media_type = hdev->hw.mac.media_type;\n\n\tif (module_type)\n\t\t*module_type = hdev->hw.mac.module_type;\n}\n\nstatic bool hclgevf_get_hw_reset_stat(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\treturn !!hclgevf_read_dev(&hdev->hw, HCLGEVF_RST_ING);\n}\n\nstatic bool hclgevf_get_cmdq_stat(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\treturn test_bit(HCLGE_COMM_STATE_CMD_DISABLE, &hdev->hw.hw.comm_state);\n}\n\nstatic bool hclgevf_ae_dev_resetting(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\treturn test_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state);\n}\n\nstatic unsigned long hclgevf_ae_dev_reset_cnt(struct hnae3_handle *handle)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\treturn hdev->rst_stats.hw_rst_done_cnt;\n}\n\nstatic void hclgevf_get_link_mode(struct hnae3_handle *handle,\n\t\t\t\t  unsigned long *supported,\n\t\t\t\t  unsigned long *advertising)\n{\n\tstruct hclgevf_dev *hdev = hclgevf_ae_get_hdev(handle);\n\n\t*supported = hdev->hw.mac.supported;\n\t*advertising = hdev->hw.mac.advertising;\n}\n\nvoid hclgevf_update_port_base_vlan_info(struct hclgevf_dev *hdev, u16 state,\n\t\t\t\tstruct hclge_mbx_port_base_vlan *port_base_vlan)\n{\n\tstruct hnae3_handle *nic = &hdev->nic;\n\tstruct hclge_vf_to_pf_msg send_msg;\n\tint ret;\n\n\trtnl_lock();\n\n\tif (test_bit(HCLGEVF_STATE_RST_HANDLING, &hdev->state) ||\n\t    test_bit(HCLGEVF_STATE_RST_FAIL, &hdev->state)) {\n\t\tdev_warn(&hdev->pdev->dev,\n\t\t\t \"is resetting when updating port based vlan info\\n\");\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n\n\tret = hclgevf_notify_client(hdev, HNAE3_DOWN_CLIENT);\n\tif (ret) {\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n\n\t \n\thclgevf_build_send_msg(&send_msg, HCLGE_MBX_SET_VLAN,\n\t\t\t       HCLGE_MBX_PORT_BASE_VLAN_CFG);\n\tmemcpy(send_msg.data, port_base_vlan, sizeof(*port_base_vlan));\n\tret = hclgevf_send_mbx_msg(hdev, &send_msg, false, NULL, 0);\n\tif (!ret) {\n\t\tif (state == HNAE3_PORT_BASE_VLAN_DISABLE)\n\t\t\tnic->port_base_vlan_state = state;\n\t\telse\n\t\t\tnic->port_base_vlan_state = HNAE3_PORT_BASE_VLAN_ENABLE;\n\t}\n\n\thclgevf_notify_client(hdev, HNAE3_UP_CLIENT);\n\trtnl_unlock();\n}\n\nstatic const struct hnae3_ae_ops hclgevf_ops = {\n\t.init_ae_dev = hclgevf_init_ae_dev,\n\t.uninit_ae_dev = hclgevf_uninit_ae_dev,\n\t.reset_prepare = hclgevf_reset_prepare_general,\n\t.reset_done = hclgevf_reset_done,\n\t.init_client_instance = hclgevf_init_client_instance,\n\t.uninit_client_instance = hclgevf_uninit_client_instance,\n\t.start = hclgevf_ae_start,\n\t.stop = hclgevf_ae_stop,\n\t.client_start = hclgevf_client_start,\n\t.client_stop = hclgevf_client_stop,\n\t.map_ring_to_vector = hclgevf_map_ring_to_vector,\n\t.unmap_ring_from_vector = hclgevf_unmap_ring_from_vector,\n\t.get_vector = hclgevf_get_vector,\n\t.put_vector = hclgevf_put_vector,\n\t.reset_queue = hclgevf_reset_tqp,\n\t.get_mac_addr = hclgevf_get_mac_addr,\n\t.set_mac_addr = hclgevf_set_mac_addr,\n\t.add_uc_addr = hclgevf_add_uc_addr,\n\t.rm_uc_addr = hclgevf_rm_uc_addr,\n\t.add_mc_addr = hclgevf_add_mc_addr,\n\t.rm_mc_addr = hclgevf_rm_mc_addr,\n\t.get_stats = hclgevf_get_stats,\n\t.update_stats = hclgevf_update_stats,\n\t.get_strings = hclgevf_get_strings,\n\t.get_sset_count = hclgevf_get_sset_count,\n\t.get_rss_key_size = hclge_comm_get_rss_key_size,\n\t.get_rss = hclgevf_get_rss,\n\t.set_rss = hclgevf_set_rss,\n\t.get_rss_tuple = hclgevf_get_rss_tuple,\n\t.set_rss_tuple = hclgevf_set_rss_tuple,\n\t.get_tc_size = hclgevf_get_tc_size,\n\t.get_fw_version = hclgevf_get_fw_version,\n\t.set_vlan_filter = hclgevf_set_vlan_filter,\n\t.enable_vlan_filter = hclgevf_enable_vlan_filter,\n\t.enable_hw_strip_rxvtag = hclgevf_en_hw_strip_rxvtag,\n\t.reset_event = hclgevf_reset_event,\n\t.set_default_reset_request = hclgevf_set_def_reset_request,\n\t.set_channels = hclgevf_set_channels,\n\t.get_channels = hclgevf_get_channels,\n\t.get_tqps_and_rss_info = hclgevf_get_tqps_and_rss_info,\n\t.get_regs_len = hclgevf_get_regs_len,\n\t.get_regs = hclgevf_get_regs,\n\t.get_status = hclgevf_get_status,\n\t.get_ksettings_an_result = hclgevf_get_ksettings_an_result,\n\t.get_media_type = hclgevf_get_media_type,\n\t.get_hw_reset_stat = hclgevf_get_hw_reset_stat,\n\t.ae_dev_resetting = hclgevf_ae_dev_resetting,\n\t.ae_dev_reset_cnt = hclgevf_ae_dev_reset_cnt,\n\t.set_gro_en = hclgevf_gro_en,\n\t.set_mtu = hclgevf_set_mtu,\n\t.get_global_queue_id = hclgevf_get_qid_global,\n\t.set_timer_task = hclgevf_set_timer_task,\n\t.get_link_mode = hclgevf_get_link_mode,\n\t.set_promisc_mode = hclgevf_set_promisc_mode,\n\t.request_update_promisc_mode = hclgevf_request_update_promisc_mode,\n\t.get_cmdq_stat = hclgevf_get_cmdq_stat,\n};\n\nstatic struct hnae3_ae_algo ae_algovf = {\n\t.ops = &hclgevf_ops,\n\t.pdev_id_table = ae_algovf_pci_tbl,\n};\n\nstatic int __init hclgevf_init(void)\n{\n\tpr_info(\"%s is initializing\\n\", HCLGEVF_NAME);\n\n\thclgevf_wq = alloc_workqueue(\"%s\", WQ_UNBOUND, 0, HCLGEVF_NAME);\n\tif (!hclgevf_wq) {\n\t\tpr_err(\"%s: failed to create workqueue\\n\", HCLGEVF_NAME);\n\t\treturn -ENOMEM;\n\t}\n\n\thnae3_register_ae_algo(&ae_algovf);\n\n\treturn 0;\n}\n\nstatic void __exit hclgevf_exit(void)\n{\n\thnae3_unregister_ae_algo(&ae_algovf);\n\tdestroy_workqueue(hclgevf_wq);\n}\nmodule_init(hclgevf_init);\nmodule_exit(hclgevf_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Huawei Tech. Co., Ltd.\");\nMODULE_DESCRIPTION(\"HCLGEVF Driver\");\nMODULE_VERSION(HCLGEVF_MOD_VERSION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}