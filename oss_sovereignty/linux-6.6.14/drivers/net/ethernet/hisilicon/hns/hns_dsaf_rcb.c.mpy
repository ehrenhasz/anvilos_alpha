{
  "module_name": "hns_dsaf_rcb.c",
  "hash_id": "3fe59f2d87f1d41de804efb697ec02f459be7d192b046e5bae8d759941d50c09",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/hisilicon/hns/hns_dsaf_rcb.c",
  "human_readable_source": "\n \n\n#include <linux/cdev.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <asm/cacheflush.h>\n#include <linux/platform_device.h>\n#include <linux/spinlock.h>\n\n#include \"hns_dsaf_main.h\"\n#include \"hns_dsaf_ppe.h\"\n#include \"hns_dsaf_rcb.h\"\n\n#define RCB_COMMON_REG_OFFSET 0x80000\n#define TX_RING 0\n#define RX_RING 1\n\n#define RCB_RESET_WAIT_TIMES 30\n#define RCB_RESET_TRY_TIMES 10\n\n \n#define RCB_DEFAULT_BUFFER_SIZE 2048\n\n \nvoid hns_rcb_wait_fbd_clean(struct hnae_queue **qs, int q_num, u32 flag)\n{\n\tint i, wait_cnt;\n\tu32 fbd_num;\n\n\tfor (wait_cnt = i = 0; i < q_num; wait_cnt++) {\n\t\tusleep_range(200, 300);\n\t\tfbd_num = 0;\n\t\tif (flag & RCB_INT_FLAG_TX)\n\t\t\tfbd_num += dsaf_read_dev(qs[i],\n\t\t\t\t\t\t RCB_RING_TX_RING_FBDNUM_REG);\n\t\tif (flag & RCB_INT_FLAG_RX)\n\t\t\tfbd_num += dsaf_read_dev(qs[i],\n\t\t\t\t\t\t RCB_RING_RX_RING_FBDNUM_REG);\n\t\tif (!fbd_num)\n\t\t\ti++;\n\t\tif (wait_cnt >= 10000)\n\t\t\tbreak;\n\t}\n\n\tif (i < q_num)\n\t\tdev_err(qs[i]->handle->owner_dev,\n\t\t\t\"queue(%d) wait fbd(%d) clean fail!!\\n\", i, fbd_num);\n}\n\nint hns_rcb_wait_tx_ring_clean(struct hnae_queue *qs)\n{\n\tu32 head, tail;\n\tint wait_cnt;\n\n\ttail = dsaf_read_dev(&qs->tx_ring, RCB_REG_TAIL);\n\twait_cnt = 0;\n\twhile (wait_cnt++ < HNS_MAX_WAIT_CNT) {\n\t\thead = dsaf_read_dev(&qs->tx_ring, RCB_REG_HEAD);\n\t\tif (tail == head)\n\t\t\tbreak;\n\n\t\tusleep_range(100, 200);\n\t}\n\n\tif (wait_cnt >= HNS_MAX_WAIT_CNT) {\n\t\tdev_err(qs->dev->dev, \"rcb wait timeout, head not equal to tail.\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\n \nvoid hns_rcb_reset_ring_hw(struct hnae_queue *q)\n{\n\tu32 wait_cnt;\n\tu32 try_cnt = 0;\n\tu32 could_ret;\n\n\tu32 tx_fbd_num;\n\n\twhile (try_cnt++ < RCB_RESET_TRY_TIMES) {\n\t\tusleep_range(100, 200);\n\t\ttx_fbd_num = dsaf_read_dev(q, RCB_RING_TX_RING_FBDNUM_REG);\n\t\tif (tx_fbd_num)\n\t\t\tcontinue;\n\n\t\tdsaf_write_dev(q, RCB_RING_PREFETCH_EN_REG, 0);\n\n\t\tdsaf_write_dev(q, RCB_RING_T0_BE_RST, 1);\n\n\t\tmsleep(20);\n\t\tcould_ret = dsaf_read_dev(q, RCB_RING_COULD_BE_RST);\n\n\t\twait_cnt = 0;\n\t\twhile (!could_ret && (wait_cnt < RCB_RESET_WAIT_TIMES)) {\n\t\t\tdsaf_write_dev(q, RCB_RING_T0_BE_RST, 0);\n\n\t\t\tdsaf_write_dev(q, RCB_RING_T0_BE_RST, 1);\n\n\t\t\tmsleep(20);\n\t\t\tcould_ret = dsaf_read_dev(q, RCB_RING_COULD_BE_RST);\n\n\t\t\twait_cnt++;\n\t\t}\n\n\t\tdsaf_write_dev(q, RCB_RING_T0_BE_RST, 0);\n\n\t\tif (could_ret)\n\t\t\tbreak;\n\t}\n\n\tif (try_cnt >= RCB_RESET_TRY_TIMES)\n\t\tdev_err(q->dev->dev, \"port%d reset ring fail\\n\",\n\t\t\thns_ae_get_vf_cb(q->handle)->port_index);\n}\n\n \nvoid hns_rcb_int_ctrl_hw(struct hnae_queue *q, u32 flag, u32 mask)\n{\n\tu32 int_mask_en = !!mask;\n\n\tif (flag & RCB_INT_FLAG_TX) {\n\t\tdsaf_write_dev(q, RCB_RING_INTMSK_TXWL_REG, int_mask_en);\n\t\tdsaf_write_dev(q, RCB_RING_INTMSK_TX_OVERTIME_REG,\n\t\t\t       int_mask_en);\n\t}\n\n\tif (flag & RCB_INT_FLAG_RX) {\n\t\tdsaf_write_dev(q, RCB_RING_INTMSK_RXWL_REG, int_mask_en);\n\t\tdsaf_write_dev(q, RCB_RING_INTMSK_RX_OVERTIME_REG,\n\t\t\t       int_mask_en);\n\t}\n}\n\nvoid hns_rcb_int_clr_hw(struct hnae_queue *q, u32 flag)\n{\n\tif (flag & RCB_INT_FLAG_TX) {\n\t\tdsaf_write_dev(q, RCB_RING_INTSTS_TX_RING_REG, 1);\n\t\tdsaf_write_dev(q, RCB_RING_INTSTS_TX_OVERTIME_REG, 1);\n\t}\n\n\tif (flag & RCB_INT_FLAG_RX) {\n\t\tdsaf_write_dev(q, RCB_RING_INTSTS_RX_RING_REG, 1);\n\t\tdsaf_write_dev(q, RCB_RING_INTSTS_RX_OVERTIME_REG, 1);\n\t}\n}\n\nvoid hns_rcbv2_int_ctrl_hw(struct hnae_queue *q, u32 flag, u32 mask)\n{\n\tu32 int_mask_en = !!mask;\n\n\tif (flag & RCB_INT_FLAG_TX)\n\t\tdsaf_write_dev(q, RCB_RING_INTMSK_TXWL_REG, int_mask_en);\n\n\tif (flag & RCB_INT_FLAG_RX)\n\t\tdsaf_write_dev(q, RCB_RING_INTMSK_RXWL_REG, int_mask_en);\n}\n\nvoid hns_rcbv2_int_clr_hw(struct hnae_queue *q, u32 flag)\n{\n\tif (flag & RCB_INT_FLAG_TX)\n\t\tdsaf_write_dev(q, RCBV2_TX_RING_INT_STS_REG, 1);\n\n\tif (flag & RCB_INT_FLAG_RX)\n\t\tdsaf_write_dev(q, RCBV2_RX_RING_INT_STS_REG, 1);\n}\n\n \nvoid hns_rcb_ring_enable_hw(struct hnae_queue *q, u32 val)\n{\n\tdsaf_write_dev(q, RCB_RING_PREFETCH_EN_REG, !!val);\n}\n\nvoid hns_rcb_start(struct hnae_queue *q, u32 val)\n{\n\thns_rcb_ring_enable_hw(q, val);\n}\n\n \nvoid hns_rcb_common_init_commit_hw(struct rcb_common_cb *rcb_common)\n{\n\twmb();\t \n\tdsaf_write_dev(rcb_common, RCB_COM_CFG_SYS_FSH_REG, 1);\n\twmb();\t \n}\n\n \nvoid hns_rcb_set_tx_ring_bs(struct hnae_queue *q, u32 buf_size)\n{\n\tu32 bd_size_type = hns_rcb_buf_size2type(buf_size);\n\n\tdsaf_write_dev(q, RCB_RING_TX_RING_BD_LEN_REG,\n\t\t       bd_size_type);\n}\n\n \nvoid hns_rcb_set_rx_ring_bs(struct hnae_queue *q, u32 buf_size)\n{\n\tu32 bd_size_type = hns_rcb_buf_size2type(buf_size);\n\n\tdsaf_write_dev(q, RCB_RING_RX_RING_BD_LEN_REG,\n\t\t       bd_size_type);\n}\n\n \nstatic void hns_rcb_ring_init(struct ring_pair_cb *ring_pair, int ring_type)\n{\n\tstruct hnae_queue *q = &ring_pair->q;\n\tstruct hnae_ring *ring =\n\t\t(ring_type == RX_RING) ? &q->rx_ring : &q->tx_ring;\n\tdma_addr_t dma = ring->desc_dma_addr;\n\n\tif (ring_type == RX_RING) {\n\t\tdsaf_write_dev(q, RCB_RING_RX_RING_BASEADDR_L_REG,\n\t\t\t       (u32)dma);\n\t\tdsaf_write_dev(q, RCB_RING_RX_RING_BASEADDR_H_REG,\n\t\t\t       (u32)((dma >> 31) >> 1));\n\n\t\thns_rcb_set_rx_ring_bs(q, ring->buf_size);\n\n\t\tdsaf_write_dev(q, RCB_RING_RX_RING_BD_NUM_REG,\n\t\t\t       ring_pair->port_id_in_comm);\n\t\tdsaf_write_dev(q, RCB_RING_RX_RING_PKTLINE_REG,\n\t\t\t       ring_pair->port_id_in_comm);\n\t} else {\n\t\tdsaf_write_dev(q, RCB_RING_TX_RING_BASEADDR_L_REG,\n\t\t\t       (u32)dma);\n\t\tdsaf_write_dev(q, RCB_RING_TX_RING_BASEADDR_H_REG,\n\t\t\t       (u32)((dma >> 31) >> 1));\n\n\t\thns_rcb_set_tx_ring_bs(q, ring->buf_size);\n\n\t\tdsaf_write_dev(q, RCB_RING_TX_RING_BD_NUM_REG,\n\t\t\t       ring_pair->port_id_in_comm);\n\t\tdsaf_write_dev(q, RCB_RING_TX_RING_PKTLINE_REG,\n\t\t\tring_pair->port_id_in_comm + HNS_RCB_TX_PKTLINE_OFFSET);\n\t}\n}\n\n \nvoid hns_rcb_init_hw(struct ring_pair_cb *ring)\n{\n\thns_rcb_ring_init(ring, RX_RING);\n\thns_rcb_ring_init(ring, TX_RING);\n}\n\n \nstatic void hns_rcb_set_port_desc_cnt(struct rcb_common_cb *rcb_common,\n\t\t\t\t      u32 port_idx, u32 desc_cnt)\n{\n\tdsaf_write_dev(rcb_common, RCB_CFG_BD_NUM_REG + port_idx * 4,\n\t\t       desc_cnt);\n}\n\nstatic void hns_rcb_set_port_timeout(\n\tstruct rcb_common_cb *rcb_common, u32 port_idx, u32 timeout)\n{\n\tif (AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver)) {\n\t\tdsaf_write_dev(rcb_common, RCB_CFG_OVERTIME_REG,\n\t\t\t       timeout * HNS_RCB_CLK_FREQ_MHZ);\n\t} else if (!HNS_DSAF_IS_DEBUG(rcb_common->dsaf_dev)) {\n\t\tif (timeout > HNS_RCB_DEF_GAP_TIME_USECS)\n\t\t\tdsaf_write_dev(rcb_common,\n\t\t\t\t       RCB_PORT_INT_GAPTIME_REG + port_idx * 4,\n\t\t\t\t       HNS_RCB_DEF_GAP_TIME_USECS);\n\t\telse\n\t\t\tdsaf_write_dev(rcb_common,\n\t\t\t\t       RCB_PORT_INT_GAPTIME_REG + port_idx * 4,\n\t\t\t\t       timeout);\n\n\t\tdsaf_write_dev(rcb_common,\n\t\t\t       RCB_PORT_CFG_OVERTIME_REG + port_idx * 4,\n\t\t\t       timeout);\n\t} else {\n\t\tdsaf_write_dev(rcb_common,\n\t\t\t       RCB_PORT_CFG_OVERTIME_REG + port_idx * 4,\n\t\t\t       timeout);\n\t}\n}\n\nstatic int hns_rcb_common_get_port_num(struct rcb_common_cb *rcb_common)\n{\n\tif (!HNS_DSAF_IS_DEBUG(rcb_common->dsaf_dev))\n\t\treturn HNS_RCB_SERVICE_NW_ENGINE_NUM;\n\telse\n\t\treturn HNS_RCB_DEBUG_NW_ENGINE_NUM;\n}\n\n \nstatic void hns_rcb_comm_exc_irq_en(\n\t\t\tstruct rcb_common_cb *rcb_common, int en)\n{\n\tu32 clr_vlue = 0xfffffffful;\n\tu32 msk_vlue = en ? 0 : 0xfffffffful;\n\n\t \n\tdsaf_write_dev(rcb_common, RCB_COM_INTSTS_ECC_ERR_REG, clr_vlue);\n\n\tdsaf_write_dev(rcb_common, RCB_COM_SF_CFG_RING_STS, clr_vlue);\n\n\tdsaf_write_dev(rcb_common, RCB_COM_SF_CFG_BD_RINT_STS, clr_vlue);\n\n\tdsaf_write_dev(rcb_common, RCB_COM_RINT_TX_PKT_REG, clr_vlue);\n\tdsaf_write_dev(rcb_common, RCB_COM_AXI_ERR_STS, clr_vlue);\n\n\t \n\tdsaf_write_dev(rcb_common, RCB_COM_INTMASK_ECC_ERR_REG, msk_vlue);\n\n\tdsaf_write_dev(rcb_common, RCB_COM_SF_CFG_INTMASK_RING, msk_vlue);\n\n\t \n\tdsaf_write_dev(rcb_common, RCB_COM_SF_CFG_INTMASK_BD, msk_vlue | 2);\n\n\tdsaf_write_dev(rcb_common, RCB_COM_INTMSK_TX_PKT_REG, msk_vlue);\n\tdsaf_write_dev(rcb_common, RCB_COM_AXI_WR_ERR_INTMASK, msk_vlue);\n}\n\n \nint hns_rcb_common_init_hw(struct rcb_common_cb *rcb_common)\n{\n\tu32 reg_val;\n\tint i;\n\tint port_num = hns_rcb_common_get_port_num(rcb_common);\n\n\thns_rcb_comm_exc_irq_en(rcb_common, 0);\n\n\treg_val = dsaf_read_dev(rcb_common, RCB_COM_CFG_INIT_FLAG_REG);\n\tif (0x1 != (reg_val & 0x1)) {\n\t\tdev_err(rcb_common->dsaf_dev->dev,\n\t\t\t\"RCB_COM_CFG_INIT_FLAG_REG reg = 0x%x\\n\", reg_val);\n\t\treturn -EBUSY;\n\t}\n\n\tfor (i = 0; i < port_num; i++) {\n\t\thns_rcb_set_port_desc_cnt(rcb_common, i, rcb_common->desc_num);\n\t\thns_rcb_set_rx_coalesced_frames(\n\t\t\trcb_common, i, HNS_RCB_DEF_RX_COALESCED_FRAMES);\n\t\tif (!AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver) &&\n\t\t    !HNS_DSAF_IS_DEBUG(rcb_common->dsaf_dev))\n\t\t\thns_rcb_set_tx_coalesced_frames(\n\t\t\t\trcb_common, i, HNS_RCB_DEF_TX_COALESCED_FRAMES);\n\t\thns_rcb_set_port_timeout(\n\t\t\trcb_common, i, HNS_RCB_DEF_COALESCED_USECS);\n\t}\n\n\tdsaf_write_dev(rcb_common, RCB_COM_CFG_ENDIAN_REG,\n\t\t       HNS_RCB_COMMON_ENDIAN);\n\n\tif (AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver)) {\n\t\tdsaf_write_dev(rcb_common, RCB_COM_CFG_FNA_REG, 0x0);\n\t\tdsaf_write_dev(rcb_common, RCB_COM_CFG_FA_REG, 0x1);\n\t} else {\n\t\tdsaf_set_dev_bit(rcb_common, RCBV2_COM_CFG_USER_REG,\n\t\t\t\t RCB_COM_CFG_FNA_B, false);\n\t\tdsaf_set_dev_bit(rcb_common, RCBV2_COM_CFG_USER_REG,\n\t\t\t\t RCB_COM_CFG_FA_B, true);\n\t\tdsaf_set_dev_bit(rcb_common, RCBV2_COM_CFG_TSO_MODE_REG,\n\t\t\t\t RCB_COM_TSO_MODE_B, HNS_TSO_MODE_8BD_32K);\n\t}\n\n\treturn 0;\n}\n\nint hns_rcb_buf_size2type(u32 buf_size)\n{\n\tint bd_size_type;\n\n\tswitch (buf_size) {\n\tcase 512:\n\t\tbd_size_type = HNS_BD_SIZE_512_TYPE;\n\t\tbreak;\n\tcase 1024:\n\t\tbd_size_type = HNS_BD_SIZE_1024_TYPE;\n\t\tbreak;\n\tcase 2048:\n\t\tbd_size_type = HNS_BD_SIZE_2048_TYPE;\n\t\tbreak;\n\tcase 4096:\n\t\tbd_size_type = HNS_BD_SIZE_4096_TYPE;\n\t\tbreak;\n\tdefault:\n\t\tbd_size_type = -EINVAL;\n\t}\n\n\treturn bd_size_type;\n}\n\nstatic void hns_rcb_ring_get_cfg(struct hnae_queue *q, int ring_type)\n{\n\tstruct hnae_ring *ring;\n\tstruct rcb_common_cb *rcb_common;\n\tstruct ring_pair_cb *ring_pair_cb;\n\tu16 desc_num, mdnum_ppkt;\n\tbool irq_idx, is_ver1;\n\n\tring_pair_cb = container_of(q, struct ring_pair_cb, q);\n\tis_ver1 = AE_IS_VER1(ring_pair_cb->rcb_common->dsaf_dev->dsaf_ver);\n\tif (ring_type == RX_RING) {\n\t\tring = &q->rx_ring;\n\t\tring->io_base = ring_pair_cb->q.io_base;\n\t\tirq_idx = HNS_RCB_IRQ_IDX_RX;\n\t\tmdnum_ppkt = HNS_RCB_RING_MAX_BD_PER_PKT;\n\t} else {\n\t\tring = &q->tx_ring;\n\t\tring->io_base = ring_pair_cb->q.io_base +\n\t\t\tHNS_RCB_TX_REG_OFFSET;\n\t\tirq_idx = HNS_RCB_IRQ_IDX_TX;\n\t\tmdnum_ppkt = is_ver1 ? HNS_RCB_RING_MAX_TXBD_PER_PKT :\n\t\t\t\t HNS_RCBV2_RING_MAX_TXBD_PER_PKT;\n\t}\n\n\trcb_common = ring_pair_cb->rcb_common;\n\tdesc_num = rcb_common->dsaf_dev->desc_num;\n\n\tring->desc = NULL;\n\tring->desc_cb = NULL;\n\n\tring->irq = ring_pair_cb->virq[irq_idx];\n\tring->desc_dma_addr = 0;\n\n\tring->buf_size = RCB_DEFAULT_BUFFER_SIZE;\n\tring->desc_num = desc_num;\n\tring->max_desc_num_per_pkt = mdnum_ppkt;\n\tring->max_raw_data_sz_per_desc = HNS_RCB_MAX_PKT_SIZE;\n\tring->max_pkt_size = HNS_RCB_MAX_PKT_SIZE;\n\tring->next_to_use = 0;\n\tring->next_to_clean = 0;\n}\n\nstatic void hns_rcb_ring_pair_get_cfg(struct ring_pair_cb *ring_pair_cb)\n{\n\tring_pair_cb->q.handle = NULL;\n\n\thns_rcb_ring_get_cfg(&ring_pair_cb->q, RX_RING);\n\thns_rcb_ring_get_cfg(&ring_pair_cb->q, TX_RING);\n}\n\nstatic int hns_rcb_get_port_in_comm(\n\tstruct rcb_common_cb *rcb_common, int ring_idx)\n{\n\treturn ring_idx / (rcb_common->max_q_per_vf * rcb_common->max_vfn);\n}\n\n#define SERVICE_RING_IRQ_IDX(v1) \\\n\t((v1) ? HNS_SERVICE_RING_IRQ_IDX : HNSV2_SERVICE_RING_IRQ_IDX)\nstatic int hns_rcb_get_base_irq_idx(struct rcb_common_cb *rcb_common)\n{\n\tbool is_ver1 = AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver);\n\n\tif (!HNS_DSAF_IS_DEBUG(rcb_common->dsaf_dev))\n\t\treturn SERVICE_RING_IRQ_IDX(is_ver1);\n\telse\n\t\treturn  HNS_DEBUG_RING_IRQ_IDX;\n}\n\n#define RCB_COMM_BASE_TO_RING_BASE(base, ringid)\\\n\t((base) + 0x10000 + HNS_RCB_REG_OFFSET * (ringid))\n \nint hns_rcb_get_cfg(struct rcb_common_cb *rcb_common)\n{\n\tstruct ring_pair_cb *ring_pair_cb;\n\tu32 i;\n\tu32 ring_num = rcb_common->ring_num;\n\tint base_irq_idx = hns_rcb_get_base_irq_idx(rcb_common);\n\tstruct platform_device *pdev =\n\t\tto_platform_device(rcb_common->dsaf_dev->dev);\n\tbool is_ver1 = AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver);\n\n\tfor (i = 0; i < ring_num; i++) {\n\t\tring_pair_cb = &rcb_common->ring_pair_cb[i];\n\t\tring_pair_cb->rcb_common = rcb_common;\n\t\tring_pair_cb->dev = rcb_common->dsaf_dev->dev;\n\t\tring_pair_cb->index = i;\n\t\tring_pair_cb->q.io_base =\n\t\t\tRCB_COMM_BASE_TO_RING_BASE(rcb_common->io_base, i);\n\t\tring_pair_cb->port_id_in_comm =\n\t\t\thns_rcb_get_port_in_comm(rcb_common, i);\n\t\tring_pair_cb->virq[HNS_RCB_IRQ_IDX_TX] =\n\t\tis_ver1 ? platform_get_irq(pdev, base_irq_idx + i * 2) :\n\t\t\t  platform_get_irq(pdev, base_irq_idx + i * 3 + 1);\n\t\tring_pair_cb->virq[HNS_RCB_IRQ_IDX_RX] =\n\t\tis_ver1 ? platform_get_irq(pdev, base_irq_idx + i * 2 + 1) :\n\t\t\t  platform_get_irq(pdev, base_irq_idx + i * 3);\n\t\tif ((ring_pair_cb->virq[HNS_RCB_IRQ_IDX_TX] == -EPROBE_DEFER) ||\n\t\t    (ring_pair_cb->virq[HNS_RCB_IRQ_IDX_RX] == -EPROBE_DEFER))\n\t\t\treturn -EPROBE_DEFER;\n\n\t\tring_pair_cb->q.phy_base =\n\t\t\tRCB_COMM_BASE_TO_RING_BASE(rcb_common->phy_base, i);\n\t\thns_rcb_ring_pair_get_cfg(ring_pair_cb);\n\t}\n\n\treturn 0;\n}\n\n \nu32 hns_rcb_get_rx_coalesced_frames(\n\tstruct rcb_common_cb *rcb_common, u32 port_idx)\n{\n\treturn dsaf_read_dev(rcb_common, RCB_CFG_PKTLINE_REG + port_idx * 4);\n}\n\n \nu32 hns_rcb_get_tx_coalesced_frames(\n\tstruct rcb_common_cb *rcb_common, u32 port_idx)\n{\n\tu64 reg;\n\n\treg = RCB_CFG_PKTLINE_REG + (port_idx + HNS_RCB_TX_PKTLINE_OFFSET) * 4;\n\treturn dsaf_read_dev(rcb_common, reg);\n}\n\n \nu32 hns_rcb_get_coalesce_usecs(\n\tstruct rcb_common_cb *rcb_common, u32 port_idx)\n{\n\tif (AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver))\n\t\treturn dsaf_read_dev(rcb_common, RCB_CFG_OVERTIME_REG) /\n\t\t       HNS_RCB_CLK_FREQ_MHZ;\n\telse\n\t\treturn dsaf_read_dev(rcb_common,\n\t\t\t\t     RCB_PORT_CFG_OVERTIME_REG + port_idx * 4);\n}\n\n \nint hns_rcb_set_coalesce_usecs(\n\tstruct rcb_common_cb *rcb_common, u32 port_idx, u32 timeout)\n{\n\tu32 old_timeout = hns_rcb_get_coalesce_usecs(rcb_common, port_idx);\n\n\tif (timeout == old_timeout)\n\t\treturn 0;\n\n\tif (AE_IS_VER1(rcb_common->dsaf_dev->dsaf_ver)) {\n\t\tif (!HNS_DSAF_IS_DEBUG(rcb_common->dsaf_dev)) {\n\t\t\tdev_err(rcb_common->dsaf_dev->dev,\n\t\t\t\t\"error: not support coalesce_usecs setting!\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tif (timeout > HNS_RCB_MAX_COALESCED_USECS || timeout == 0) {\n\t\tdev_err(rcb_common->dsaf_dev->dev,\n\t\t\t\"error: coalesce_usecs setting supports 1~1023us\\n\");\n\t\treturn -EINVAL;\n\t}\n\thns_rcb_set_port_timeout(rcb_common, port_idx, timeout);\n\treturn 0;\n}\n\n \nint hns_rcb_set_tx_coalesced_frames(\n\tstruct rcb_common_cb *rcb_common, u32 port_idx, u32 coalesced_frames)\n{\n\tu32 old_waterline =\n\t\thns_rcb_get_tx_coalesced_frames(rcb_common, port_idx);\n\tu64 reg;\n\n\tif (coalesced_frames == old_waterline)\n\t\treturn 0;\n\n\tif (coalesced_frames != 1) {\n\t\tdev_err(rcb_common->dsaf_dev->dev,\n\t\t\t\"error: not support tx coalesce_frames setting!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treg = RCB_CFG_PKTLINE_REG + (port_idx + HNS_RCB_TX_PKTLINE_OFFSET) * 4;\n\tdsaf_write_dev(rcb_common, reg,\tcoalesced_frames);\n\treturn 0;\n}\n\n \nint hns_rcb_set_rx_coalesced_frames(\n\tstruct rcb_common_cb *rcb_common, u32 port_idx, u32 coalesced_frames)\n{\n\tu32 old_waterline =\n\t\thns_rcb_get_rx_coalesced_frames(rcb_common, port_idx);\n\n\tif (coalesced_frames == old_waterline)\n\t\treturn 0;\n\n\tif (coalesced_frames >= rcb_common->desc_num ||\n\t    coalesced_frames > HNS_RCB_MAX_COALESCED_FRAMES ||\n\t    coalesced_frames < HNS_RCB_MIN_COALESCED_FRAMES) {\n\t\tdev_err(rcb_common->dsaf_dev->dev,\n\t\t\t\"error: not support coalesce_frames setting!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdsaf_write_dev(rcb_common, RCB_CFG_PKTLINE_REG + port_idx * 4,\n\t\t       coalesced_frames);\n\treturn 0;\n}\n\n \nvoid hns_rcb_get_queue_mode(enum dsaf_mode dsaf_mode, u16 *max_vfn,\n\t\t\t    u16 *max_q_per_vf)\n{\n\tswitch (dsaf_mode) {\n\tcase DSAF_MODE_DISABLE_6PORT_0VM:\n\t\t*max_vfn = 1;\n\t\t*max_q_per_vf = 16;\n\t\tbreak;\n\tcase DSAF_MODE_DISABLE_FIX:\n\tcase DSAF_MODE_DISABLE_SP:\n\t\t*max_vfn = 1;\n\t\t*max_q_per_vf = 1;\n\t\tbreak;\n\tcase DSAF_MODE_DISABLE_2PORT_64VM:\n\t\t*max_vfn = 64;\n\t\t*max_q_per_vf = 1;\n\t\tbreak;\n\tcase DSAF_MODE_DISABLE_6PORT_16VM:\n\t\t*max_vfn = 16;\n\t\t*max_q_per_vf = 1;\n\t\tbreak;\n\tdefault:\n\t\t*max_vfn = 1;\n\t\t*max_q_per_vf = 16;\n\t\tbreak;\n\t}\n}\n\nstatic int hns_rcb_get_ring_num(struct dsaf_device *dsaf_dev)\n{\n\tswitch (dsaf_dev->dsaf_mode) {\n\tcase DSAF_MODE_ENABLE_FIX:\n\tcase DSAF_MODE_DISABLE_SP:\n\t\treturn 1;\n\n\tcase DSAF_MODE_DISABLE_FIX:\n\t\treturn 6;\n\n\tcase DSAF_MODE_ENABLE_0VM:\n\t\treturn 32;\n\n\tcase DSAF_MODE_DISABLE_6PORT_0VM:\n\tcase DSAF_MODE_ENABLE_16VM:\n\tcase DSAF_MODE_DISABLE_6PORT_2VM:\n\tcase DSAF_MODE_DISABLE_6PORT_16VM:\n\tcase DSAF_MODE_DISABLE_6PORT_4VM:\n\tcase DSAF_MODE_ENABLE_8VM:\n\t\treturn 96;\n\n\tcase DSAF_MODE_DISABLE_2PORT_16VM:\n\tcase DSAF_MODE_DISABLE_2PORT_8VM:\n\tcase DSAF_MODE_ENABLE_32VM:\n\tcase DSAF_MODE_DISABLE_2PORT_64VM:\n\tcase DSAF_MODE_ENABLE_128VM:\n\t\treturn 128;\n\n\tdefault:\n\t\tdev_warn(dsaf_dev->dev,\n\t\t\t \"get ring num fail,use default!dsaf_mode=%d\\n\",\n\t\t\t dsaf_dev->dsaf_mode);\n\t\treturn 128;\n\t}\n}\n\nstatic u8 __iomem *hns_rcb_common_get_vaddr(struct rcb_common_cb *rcb_common)\n{\n\tstruct dsaf_device *dsaf_dev = rcb_common->dsaf_dev;\n\n\treturn dsaf_dev->ppe_base + RCB_COMMON_REG_OFFSET;\n}\n\nstatic phys_addr_t hns_rcb_common_get_paddr(struct rcb_common_cb *rcb_common)\n{\n\tstruct dsaf_device *dsaf_dev = rcb_common->dsaf_dev;\n\n\treturn dsaf_dev->ppe_paddr + RCB_COMMON_REG_OFFSET;\n}\n\nint hns_rcb_common_get_cfg(struct dsaf_device *dsaf_dev,\n\t\t\t   int comm_index)\n{\n\tstruct rcb_common_cb *rcb_common;\n\tenum dsaf_mode dsaf_mode = dsaf_dev->dsaf_mode;\n\tu16 max_vfn;\n\tu16 max_q_per_vf;\n\tint ring_num = hns_rcb_get_ring_num(dsaf_dev);\n\n\trcb_common =\n\t\tdevm_kzalloc(dsaf_dev->dev,\n\t\t\t     struct_size(rcb_common, ring_pair_cb, ring_num),\n\t\t\t     GFP_KERNEL);\n\tif (!rcb_common) {\n\t\tdev_err(dsaf_dev->dev, \"rcb common devm_kzalloc fail!\\n\");\n\t\treturn -ENOMEM;\n\t}\n\trcb_common->comm_index = comm_index;\n\trcb_common->ring_num = ring_num;\n\trcb_common->dsaf_dev = dsaf_dev;\n\n\trcb_common->desc_num = dsaf_dev->desc_num;\n\n\thns_rcb_get_queue_mode(dsaf_mode, &max_vfn, &max_q_per_vf);\n\trcb_common->max_vfn = max_vfn;\n\trcb_common->max_q_per_vf = max_q_per_vf;\n\n\trcb_common->io_base = hns_rcb_common_get_vaddr(rcb_common);\n\trcb_common->phy_base = hns_rcb_common_get_paddr(rcb_common);\n\n\tdsaf_dev->rcb_common[comm_index] = rcb_common;\n\treturn 0;\n}\n\nvoid hns_rcb_common_free_cfg(struct dsaf_device *dsaf_dev,\n\t\t\t     u32 comm_index)\n{\n\tdsaf_dev->rcb_common[comm_index] = NULL;\n}\n\nvoid hns_rcb_update_stats(struct hnae_queue *queue)\n{\n\tstruct ring_pair_cb *ring =\n\t\tcontainer_of(queue, struct ring_pair_cb, q);\n\tstruct dsaf_device *dsaf_dev = ring->rcb_common->dsaf_dev;\n\tstruct ppe_common_cb *ppe_common\n\t\t= dsaf_dev->ppe_common[ring->rcb_common->comm_index];\n\tstruct hns_ring_hw_stats *hw_stats = &ring->hw_stats;\n\n\thw_stats->rx_pkts += dsaf_read_dev(queue,\n\t\t\t RCB_RING_RX_RING_PKTNUM_RECORD_REG);\n\tdsaf_write_dev(queue, RCB_RING_RX_RING_PKTNUM_RECORD_REG, 0x1);\n\n\thw_stats->ppe_rx_ok_pkts += dsaf_read_dev(ppe_common,\n\t\t\t PPE_COM_HIS_RX_PKT_QID_OK_CNT_REG + 4 * ring->index);\n\thw_stats->ppe_rx_drop_pkts += dsaf_read_dev(ppe_common,\n\t\t\t PPE_COM_HIS_RX_PKT_QID_DROP_CNT_REG + 4 * ring->index);\n\n\thw_stats->tx_pkts += dsaf_read_dev(queue,\n\t\t\t RCB_RING_TX_RING_PKTNUM_RECORD_REG);\n\tdsaf_write_dev(queue, RCB_RING_TX_RING_PKTNUM_RECORD_REG, 0x1);\n\n\thw_stats->ppe_tx_ok_pkts += dsaf_read_dev(ppe_common,\n\t\t\t PPE_COM_HIS_TX_PKT_QID_OK_CNT_REG + 4 * ring->index);\n\thw_stats->ppe_tx_drop_pkts += dsaf_read_dev(ppe_common,\n\t\t\t PPE_COM_HIS_TX_PKT_QID_ERR_CNT_REG + 4 * ring->index);\n}\n\n \nvoid hns_rcb_get_stats(struct hnae_queue *queue, u64 *data)\n{\n\tu64 *regs_buff = data;\n\tstruct ring_pair_cb *ring =\n\t\tcontainer_of(queue, struct ring_pair_cb, q);\n\tstruct hns_ring_hw_stats *hw_stats = &ring->hw_stats;\n\n\tregs_buff[0] = hw_stats->tx_pkts;\n\tregs_buff[1] = hw_stats->ppe_tx_ok_pkts;\n\tregs_buff[2] = hw_stats->ppe_tx_drop_pkts;\n\tregs_buff[3] =\n\t\tdsaf_read_dev(queue, RCB_RING_TX_RING_FBDNUM_REG);\n\n\tregs_buff[4] = queue->tx_ring.stats.tx_pkts;\n\tregs_buff[5] = queue->tx_ring.stats.tx_bytes;\n\tregs_buff[6] = queue->tx_ring.stats.tx_err_cnt;\n\tregs_buff[7] = queue->tx_ring.stats.io_err_cnt;\n\tregs_buff[8] = queue->tx_ring.stats.sw_err_cnt;\n\tregs_buff[9] = queue->tx_ring.stats.seg_pkt_cnt;\n\tregs_buff[10] = queue->tx_ring.stats.restart_queue;\n\tregs_buff[11] = queue->tx_ring.stats.tx_busy;\n\n\tregs_buff[12] = hw_stats->rx_pkts;\n\tregs_buff[13] = hw_stats->ppe_rx_ok_pkts;\n\tregs_buff[14] = hw_stats->ppe_rx_drop_pkts;\n\tregs_buff[15] =\n\t\tdsaf_read_dev(queue, RCB_RING_RX_RING_FBDNUM_REG);\n\n\tregs_buff[16] = queue->rx_ring.stats.rx_pkts;\n\tregs_buff[17] = queue->rx_ring.stats.rx_bytes;\n\tregs_buff[18] = queue->rx_ring.stats.rx_err_cnt;\n\tregs_buff[19] = queue->rx_ring.stats.io_err_cnt;\n\tregs_buff[20] = queue->rx_ring.stats.sw_err_cnt;\n\tregs_buff[21] = queue->rx_ring.stats.seg_pkt_cnt;\n\tregs_buff[22] = queue->rx_ring.stats.reuse_pg_cnt;\n\tregs_buff[23] = queue->rx_ring.stats.err_pkt_len;\n\tregs_buff[24] = queue->rx_ring.stats.non_vld_descs;\n\tregs_buff[25] = queue->rx_ring.stats.err_bd_num;\n\tregs_buff[26] = queue->rx_ring.stats.l2_err;\n\tregs_buff[27] = queue->rx_ring.stats.l3l4_csum_err;\n}\n\n \nint hns_rcb_get_ring_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn HNS_RING_STATIC_REG_NUM;\n\n\treturn 0;\n}\n\n \nint hns_rcb_get_common_regs_count(void)\n{\n\treturn HNS_RCB_COMMON_DUMP_REG_NUM;\n}\n\n \nint hns_rcb_get_ring_regs_count(void)\n{\n\treturn HNS_RCB_RING_DUMP_REG_NUM;\n}\n\n \nvoid hns_rcb_get_strings(int stringset, u8 *data, int index)\n{\n\tu8 *buff = data;\n\n\tif (stringset != ETH_SS_STATS)\n\t\treturn;\n\n\tethtool_sprintf(&buff, \"tx_ring%d_rcb_pkt_num\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_ppe_tx_pkt_num\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_ppe_drop_pkt_num\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_fbd_num\", index);\n\n\tethtool_sprintf(&buff, \"tx_ring%d_pkt_num\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_bytes\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_err_cnt\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_io_err\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_sw_err\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_seg_pkt\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_restart_queue\", index);\n\tethtool_sprintf(&buff, \"tx_ring%d_tx_busy\", index);\n\n\tethtool_sprintf(&buff, \"rx_ring%d_rcb_pkt_num\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_ppe_pkt_num\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_ppe_drop_pkt_num\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_fbd_num\", index);\n\n\tethtool_sprintf(&buff, \"rx_ring%d_pkt_num\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_bytes\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_err_cnt\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_io_err\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_sw_err\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_seg_pkt\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_reuse_pg\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_len_err\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_non_vld_desc_err\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_bd_num_err\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_l2_err\", index);\n\tethtool_sprintf(&buff, \"rx_ring%d_l3l4csum_err\", index);\n}\n\nvoid hns_rcb_get_common_regs(struct rcb_common_cb *rcb_com, void *data)\n{\n\tu32 *regs = data;\n\tbool is_ver1 = AE_IS_VER1(rcb_com->dsaf_dev->dsaf_ver);\n\tbool is_dbg = HNS_DSAF_IS_DEBUG(rcb_com->dsaf_dev);\n\tu32 reg_tmp;\n\tu32 reg_num_tmp;\n\tu32 i;\n\n\t \n\tregs[0] = dsaf_read_dev(rcb_com, RCB_COM_CFG_ENDIAN_REG);\n\tregs[1] = dsaf_read_dev(rcb_com, RCB_COM_CFG_SYS_FSH_REG);\n\tregs[2] = dsaf_read_dev(rcb_com, RCB_COM_CFG_INIT_FLAG_REG);\n\n\tregs[3] = dsaf_read_dev(rcb_com, RCB_COM_CFG_PKT_REG);\n\tregs[4] = dsaf_read_dev(rcb_com, RCB_COM_CFG_RINVLD_REG);\n\tregs[5] = dsaf_read_dev(rcb_com, RCB_COM_CFG_FNA_REG);\n\tregs[6] = dsaf_read_dev(rcb_com, RCB_COM_CFG_FA_REG);\n\tregs[7] = dsaf_read_dev(rcb_com, RCB_COM_CFG_PKT_TC_BP_REG);\n\tregs[8] = dsaf_read_dev(rcb_com, RCB_COM_CFG_PPE_TNL_CLKEN_REG);\n\n\tregs[9] = dsaf_read_dev(rcb_com, RCB_COM_INTMSK_TX_PKT_REG);\n\tregs[10] = dsaf_read_dev(rcb_com, RCB_COM_RINT_TX_PKT_REG);\n\tregs[11] = dsaf_read_dev(rcb_com, RCB_COM_INTMASK_ECC_ERR_REG);\n\tregs[12] = dsaf_read_dev(rcb_com, RCB_COM_INTSTS_ECC_ERR_REG);\n\tregs[13] = dsaf_read_dev(rcb_com, RCB_COM_EBD_SRAM_ERR_REG);\n\tregs[14] = dsaf_read_dev(rcb_com, RCB_COM_RXRING_ERR_REG);\n\tregs[15] = dsaf_read_dev(rcb_com, RCB_COM_TXRING_ERR_REG);\n\tregs[16] = dsaf_read_dev(rcb_com, RCB_COM_TX_FBD_ERR_REG);\n\tregs[17] = dsaf_read_dev(rcb_com, RCB_SRAM_ECC_CHK_EN_REG);\n\tregs[18] = dsaf_read_dev(rcb_com, RCB_SRAM_ECC_CHK0_REG);\n\tregs[19] = dsaf_read_dev(rcb_com, RCB_SRAM_ECC_CHK1_REG);\n\tregs[20] = dsaf_read_dev(rcb_com, RCB_SRAM_ECC_CHK2_REG);\n\tregs[21] = dsaf_read_dev(rcb_com, RCB_SRAM_ECC_CHK3_REG);\n\tregs[22] = dsaf_read_dev(rcb_com, RCB_SRAM_ECC_CHK4_REG);\n\tregs[23] = dsaf_read_dev(rcb_com, RCB_SRAM_ECC_CHK5_REG);\n\tregs[24] = dsaf_read_dev(rcb_com, RCB_ECC_ERR_ADDR0_REG);\n\tregs[25] = dsaf_read_dev(rcb_com, RCB_ECC_ERR_ADDR3_REG);\n\tregs[26] = dsaf_read_dev(rcb_com, RCB_ECC_ERR_ADDR4_REG);\n\tregs[27] = dsaf_read_dev(rcb_com, RCB_ECC_ERR_ADDR5_REG);\n\n\tregs[28] = dsaf_read_dev(rcb_com, RCB_COM_SF_CFG_INTMASK_RING);\n\tregs[29] = dsaf_read_dev(rcb_com, RCB_COM_SF_CFG_RING_STS);\n\tregs[30] = dsaf_read_dev(rcb_com, RCB_COM_SF_CFG_RING);\n\tregs[31] = dsaf_read_dev(rcb_com, RCB_COM_SF_CFG_INTMASK_BD);\n\tregs[32] = dsaf_read_dev(rcb_com, RCB_COM_SF_CFG_BD_RINT_STS);\n\tregs[33] = dsaf_read_dev(rcb_com, RCB_COM_RCB_RD_BD_BUSY);\n\tregs[34] = dsaf_read_dev(rcb_com, RCB_COM_RCB_FBD_CRT_EN);\n\tregs[35] = dsaf_read_dev(rcb_com, RCB_COM_AXI_WR_ERR_INTMASK);\n\tregs[36] = dsaf_read_dev(rcb_com, RCB_COM_AXI_ERR_STS);\n\tregs[37] = dsaf_read_dev(rcb_com, RCB_COM_CHK_TX_FBD_NUM_REG);\n\n\t \n\tfor (i = 0; i < 16; i++) {  \n\t\tregs[38 + i]\n\t\t\t= dsaf_read_dev(rcb_com, RCB_CFG_BD_NUM_REG + 4 * i);\n\t\tregs[54 + i]\n\t\t\t= dsaf_read_dev(rcb_com, RCB_CFG_PKTLINE_REG + 4 * i);\n\t}\n\n\treg_tmp = is_ver1 ? RCB_CFG_OVERTIME_REG : RCB_PORT_CFG_OVERTIME_REG;\n\treg_num_tmp = (is_ver1 || is_dbg) ? 1 : 6;\n\tfor (i = 0; i < reg_num_tmp; i++)\n\t\tregs[70 + i] = dsaf_read_dev(rcb_com, reg_tmp);\n\n\tregs[76] = dsaf_read_dev(rcb_com, RCB_CFG_PKTLINE_INT_NUM_REG);\n\tregs[77] = dsaf_read_dev(rcb_com, RCB_CFG_OVERTIME_INT_NUM_REG);\n\n\t \n\tfor (i = 78; i < 80; i++)\n\t\tregs[i] = 0xcccccccc;\n}\n\nvoid hns_rcb_get_ring_regs(struct hnae_queue *queue, void *data)\n{\n\tu32 *regs = data;\n\tstruct ring_pair_cb *ring_pair\n\t\t= container_of(queue, struct ring_pair_cb, q);\n\tu32 i;\n\n\t \n\tregs[0] = dsaf_read_dev(queue, RCB_RING_RX_RING_BASEADDR_L_REG);\n\tregs[1] = dsaf_read_dev(queue, RCB_RING_RX_RING_BASEADDR_H_REG);\n\tregs[2] = dsaf_read_dev(queue, RCB_RING_RX_RING_BD_NUM_REG);\n\tregs[3] = dsaf_read_dev(queue, RCB_RING_RX_RING_BD_LEN_REG);\n\tregs[4] = dsaf_read_dev(queue, RCB_RING_RX_RING_PKTLINE_REG);\n\tregs[5] = dsaf_read_dev(queue, RCB_RING_RX_RING_TAIL_REG);\n\tregs[6] = dsaf_read_dev(queue, RCB_RING_RX_RING_HEAD_REG);\n\tregs[7] = dsaf_read_dev(queue, RCB_RING_RX_RING_FBDNUM_REG);\n\tregs[8] = dsaf_read_dev(queue, RCB_RING_RX_RING_PKTNUM_RECORD_REG);\n\n\tregs[9] = dsaf_read_dev(queue, RCB_RING_TX_RING_BASEADDR_L_REG);\n\tregs[10] = dsaf_read_dev(queue, RCB_RING_TX_RING_BASEADDR_H_REG);\n\tregs[11] = dsaf_read_dev(queue, RCB_RING_TX_RING_BD_NUM_REG);\n\tregs[12] = dsaf_read_dev(queue, RCB_RING_TX_RING_BD_LEN_REG);\n\tregs[13] = dsaf_read_dev(queue, RCB_RING_TX_RING_PKTLINE_REG);\n\tregs[15] = dsaf_read_dev(queue, RCB_RING_TX_RING_TAIL_REG);\n\tregs[16] = dsaf_read_dev(queue, RCB_RING_TX_RING_HEAD_REG);\n\tregs[17] = dsaf_read_dev(queue, RCB_RING_TX_RING_FBDNUM_REG);\n\tregs[18] = dsaf_read_dev(queue, RCB_RING_TX_RING_OFFSET_REG);\n\tregs[19] = dsaf_read_dev(queue, RCB_RING_TX_RING_PKTNUM_RECORD_REG);\n\n\tregs[20] = dsaf_read_dev(queue, RCB_RING_PREFETCH_EN_REG);\n\tregs[21] = dsaf_read_dev(queue, RCB_RING_CFG_VF_NUM_REG);\n\tregs[22] = dsaf_read_dev(queue, RCB_RING_ASID_REG);\n\tregs[23] = dsaf_read_dev(queue, RCB_RING_RX_VM_REG);\n\tregs[24] = dsaf_read_dev(queue, RCB_RING_T0_BE_RST);\n\tregs[25] = dsaf_read_dev(queue, RCB_RING_COULD_BE_RST);\n\tregs[26] = dsaf_read_dev(queue, RCB_RING_WRR_WEIGHT_REG);\n\n\tregs[27] = dsaf_read_dev(queue, RCB_RING_INTMSK_RXWL_REG);\n\tregs[28] = dsaf_read_dev(queue, RCB_RING_INTSTS_RX_RING_REG);\n\tregs[29] = dsaf_read_dev(queue, RCB_RING_INTMSK_TXWL_REG);\n\tregs[30] = dsaf_read_dev(queue, RCB_RING_INTSTS_TX_RING_REG);\n\tregs[31] = dsaf_read_dev(queue, RCB_RING_INTMSK_RX_OVERTIME_REG);\n\tregs[32] = dsaf_read_dev(queue, RCB_RING_INTSTS_RX_OVERTIME_REG);\n\tregs[33] = dsaf_read_dev(queue, RCB_RING_INTMSK_TX_OVERTIME_REG);\n\tregs[34] = dsaf_read_dev(queue, RCB_RING_INTSTS_TX_OVERTIME_REG);\n\n\t \n\tfor (i = 35; i < 40; i++)\n\t\tregs[i] = 0xcccccc00 + ring_pair->index;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}