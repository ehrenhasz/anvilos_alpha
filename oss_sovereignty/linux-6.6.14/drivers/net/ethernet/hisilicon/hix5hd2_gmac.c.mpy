{
  "module_name": "hix5hd2_gmac.c",
  "hash_id": "497147fdbd43dc2ea208a6796e30514f7990a28223379b3b4576e4c54620aafe",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/hisilicon/hix5hd2_gmac.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/etherdevice.h>\n#include <linux/platform_device.h>\n#include <linux/of_device.h>\n#include <linux/of_net.h>\n#include <linux/of_mdio.h>\n#include <linux/reset.h>\n#include <linux/clk.h>\n#include <linux/circ_buf.h>\n\n#define STATION_ADDR_LOW\t\t0x0000\n#define STATION_ADDR_HIGH\t\t0x0004\n#define MAC_DUPLEX_HALF_CTRL\t\t0x0008\n#define MAX_FRM_SIZE\t\t\t0x003c\n#define PORT_MODE\t\t\t0x0040\n#define PORT_EN\t\t\t\t0x0044\n#define BITS_TX_EN\t\t\tBIT(2)\n#define BITS_RX_EN\t\t\tBIT(1)\n#define REC_FILT_CONTROL\t\t0x0064\n#define BIT_CRC_ERR_PASS\t\tBIT(5)\n#define BIT_PAUSE_FRM_PASS\t\tBIT(4)\n#define BIT_VLAN_DROP_EN\t\tBIT(3)\n#define BIT_BC_DROP_EN\t\t\tBIT(2)\n#define BIT_MC_MATCH_EN\t\t\tBIT(1)\n#define BIT_UC_MATCH_EN\t\t\tBIT(0)\n#define PORT_MC_ADDR_LOW\t\t0x0068\n#define PORT_MC_ADDR_HIGH\t\t0x006C\n#define CF_CRC_STRIP\t\t\t0x01b0\n#define MODE_CHANGE_EN\t\t\t0x01b4\n#define BIT_MODE_CHANGE_EN\t\tBIT(0)\n#define COL_SLOT_TIME\t\t\t0x01c0\n#define RECV_CONTROL\t\t\t0x01e0\n#define BIT_STRIP_PAD_EN\t\tBIT(3)\n#define BIT_RUNT_PKT_EN\t\t\tBIT(4)\n#define CONTROL_WORD\t\t\t0x0214\n#define MDIO_SINGLE_CMD\t\t\t0x03c0\n#define MDIO_SINGLE_DATA\t\t0x03c4\n#define MDIO_CTRL\t\t\t0x03cc\n#define MDIO_RDATA_STATUS\t\t0x03d0\n\n#define MDIO_START\t\t\tBIT(20)\n#define MDIO_R_VALID\t\t\tBIT(0)\n#define MDIO_READ\t\t\t(BIT(17) | MDIO_START)\n#define MDIO_WRITE\t\t\t(BIT(16) | MDIO_START)\n\n#define RX_FQ_START_ADDR\t\t0x0500\n#define RX_FQ_DEPTH\t\t\t0x0504\n#define RX_FQ_WR_ADDR\t\t\t0x0508\n#define RX_FQ_RD_ADDR\t\t\t0x050c\n#define RX_FQ_VLDDESC_CNT\t\t0x0510\n#define RX_FQ_ALEMPTY_TH\t\t0x0514\n#define RX_FQ_REG_EN\t\t\t0x0518\n#define BITS_RX_FQ_START_ADDR_EN\tBIT(2)\n#define BITS_RX_FQ_DEPTH_EN\t\tBIT(1)\n#define BITS_RX_FQ_RD_ADDR_EN\t\tBIT(0)\n#define RX_FQ_ALFULL_TH\t\t\t0x051c\n#define RX_BQ_START_ADDR\t\t0x0520\n#define RX_BQ_DEPTH\t\t\t0x0524\n#define RX_BQ_WR_ADDR\t\t\t0x0528\n#define RX_BQ_RD_ADDR\t\t\t0x052c\n#define RX_BQ_FREE_DESC_CNT\t\t0x0530\n#define RX_BQ_ALEMPTY_TH\t\t0x0534\n#define RX_BQ_REG_EN\t\t\t0x0538\n#define BITS_RX_BQ_START_ADDR_EN\tBIT(2)\n#define BITS_RX_BQ_DEPTH_EN\t\tBIT(1)\n#define BITS_RX_BQ_WR_ADDR_EN\t\tBIT(0)\n#define RX_BQ_ALFULL_TH\t\t\t0x053c\n#define TX_BQ_START_ADDR\t\t0x0580\n#define TX_BQ_DEPTH\t\t\t0x0584\n#define TX_BQ_WR_ADDR\t\t\t0x0588\n#define TX_BQ_RD_ADDR\t\t\t0x058c\n#define TX_BQ_VLDDESC_CNT\t\t0x0590\n#define TX_BQ_ALEMPTY_TH\t\t0x0594\n#define TX_BQ_REG_EN\t\t\t0x0598\n#define BITS_TX_BQ_START_ADDR_EN\tBIT(2)\n#define BITS_TX_BQ_DEPTH_EN\t\tBIT(1)\n#define BITS_TX_BQ_RD_ADDR_EN\t\tBIT(0)\n#define TX_BQ_ALFULL_TH\t\t\t0x059c\n#define TX_RQ_START_ADDR\t\t0x05a0\n#define TX_RQ_DEPTH\t\t\t0x05a4\n#define TX_RQ_WR_ADDR\t\t\t0x05a8\n#define TX_RQ_RD_ADDR\t\t\t0x05ac\n#define TX_RQ_FREE_DESC_CNT\t\t0x05b0\n#define TX_RQ_ALEMPTY_TH\t\t0x05b4\n#define TX_RQ_REG_EN\t\t\t0x05b8\n#define BITS_TX_RQ_START_ADDR_EN\tBIT(2)\n#define BITS_TX_RQ_DEPTH_EN\t\tBIT(1)\n#define BITS_TX_RQ_WR_ADDR_EN\t\tBIT(0)\n#define TX_RQ_ALFULL_TH\t\t\t0x05bc\n#define RAW_PMU_INT\t\t\t0x05c0\n#define ENA_PMU_INT\t\t\t0x05c4\n#define STATUS_PMU_INT\t\t\t0x05c8\n#define MAC_FIFO_ERR_IN\t\t\tBIT(30)\n#define TX_RQ_IN_TIMEOUT_INT\t\tBIT(29)\n#define RX_BQ_IN_TIMEOUT_INT\t\tBIT(28)\n#define TXOUTCFF_FULL_INT\t\tBIT(27)\n#define TXOUTCFF_EMPTY_INT\t\tBIT(26)\n#define TXCFF_FULL_INT\t\t\tBIT(25)\n#define TXCFF_EMPTY_INT\t\t\tBIT(24)\n#define RXOUTCFF_FULL_INT\t\tBIT(23)\n#define RXOUTCFF_EMPTY_INT\t\tBIT(22)\n#define RXCFF_FULL_INT\t\t\tBIT(21)\n#define RXCFF_EMPTY_INT\t\t\tBIT(20)\n#define TX_RQ_IN_INT\t\t\tBIT(19)\n#define TX_BQ_OUT_INT\t\t\tBIT(18)\n#define RX_BQ_IN_INT\t\t\tBIT(17)\n#define RX_FQ_OUT_INT\t\t\tBIT(16)\n#define TX_RQ_EMPTY_INT\t\t\tBIT(15)\n#define TX_RQ_FULL_INT\t\t\tBIT(14)\n#define TX_RQ_ALEMPTY_INT\t\tBIT(13)\n#define TX_RQ_ALFULL_INT\t\tBIT(12)\n#define TX_BQ_EMPTY_INT\t\t\tBIT(11)\n#define TX_BQ_FULL_INT\t\t\tBIT(10)\n#define TX_BQ_ALEMPTY_INT\t\tBIT(9)\n#define TX_BQ_ALFULL_INT\t\tBIT(8)\n#define RX_BQ_EMPTY_INT\t\t\tBIT(7)\n#define RX_BQ_FULL_INT\t\t\tBIT(6)\n#define RX_BQ_ALEMPTY_INT\t\tBIT(5)\n#define RX_BQ_ALFULL_INT\t\tBIT(4)\n#define RX_FQ_EMPTY_INT\t\t\tBIT(3)\n#define RX_FQ_FULL_INT\t\t\tBIT(2)\n#define RX_FQ_ALEMPTY_INT\t\tBIT(1)\n#define RX_FQ_ALFULL_INT\t\tBIT(0)\n\n#define DEF_INT_MASK\t\t\t(RX_BQ_IN_INT | RX_BQ_IN_TIMEOUT_INT | \\\n\t\t\t\t\tTX_RQ_IN_INT | TX_RQ_IN_TIMEOUT_INT)\n\n#define DESC_WR_RD_ENA\t\t\t0x05cc\n#define IN_QUEUE_TH\t\t\t0x05d8\n#define OUT_QUEUE_TH\t\t\t0x05dc\n#define QUEUE_TX_BQ_SHIFT\t\t16\n#define RX_BQ_IN_TIMEOUT_TH\t\t0x05e0\n#define TX_RQ_IN_TIMEOUT_TH\t\t0x05e4\n#define STOP_CMD\t\t\t0x05e8\n#define BITS_TX_STOP\t\t\tBIT(1)\n#define BITS_RX_STOP\t\t\tBIT(0)\n#define FLUSH_CMD\t\t\t0x05eC\n#define BITS_TX_FLUSH_CMD\t\tBIT(5)\n#define BITS_RX_FLUSH_CMD\t\tBIT(4)\n#define BITS_TX_FLUSH_FLAG_DOWN\t\tBIT(3)\n#define BITS_TX_FLUSH_FLAG_UP\t\tBIT(2)\n#define BITS_RX_FLUSH_FLAG_DOWN\t\tBIT(1)\n#define BITS_RX_FLUSH_FLAG_UP\t\tBIT(0)\n#define RX_CFF_NUM_REG\t\t\t0x05f0\n#define PMU_FSM_REG\t\t\t0x05f8\n#define RX_FIFO_PKT_IN_NUM\t\t0x05fc\n#define RX_FIFO_PKT_OUT_NUM\t\t0x0600\n\n#define RGMII_SPEED_1000\t\t0x2c\n#define RGMII_SPEED_100\t\t\t0x2f\n#define RGMII_SPEED_10\t\t\t0x2d\n#define MII_SPEED_100\t\t\t0x0f\n#define MII_SPEED_10\t\t\t0x0d\n#define GMAC_SPEED_1000\t\t\t0x05\n#define GMAC_SPEED_100\t\t\t0x01\n#define GMAC_SPEED_10\t\t\t0x00\n#define GMAC_FULL_DUPLEX\t\tBIT(4)\n\n#define RX_BQ_INT_THRESHOLD\t\t0x01\n#define TX_RQ_INT_THRESHOLD\t\t0x01\n#define RX_BQ_IN_TIMEOUT\t\t0x10000\n#define TX_RQ_IN_TIMEOUT\t\t0x50000\n\n#define MAC_MAX_FRAME_SIZE\t\t1600\n#define DESC_SIZE\t\t\t32\n#define RX_DESC_NUM\t\t\t1024\n#define TX_DESC_NUM\t\t\t1024\n\n#define DESC_VLD_FREE\t\t\t0\n#define DESC_VLD_BUSY\t\t\t0x80000000\n#define DESC_FL_MID\t\t\t0\n#define DESC_FL_LAST\t\t\t0x20000000\n#define DESC_FL_FIRST\t\t\t0x40000000\n#define DESC_FL_FULL\t\t\t0x60000000\n#define DESC_DATA_LEN_OFF\t\t16\n#define DESC_BUFF_LEN_OFF\t\t0\n#define DESC_DATA_MASK\t\t\t0x7ff\n#define DESC_SG\t\t\t\tBIT(30)\n#define DESC_FRAGS_NUM_OFF\t\t11\n\n \n#define dma_ring_incr(n, s)\t\t(((n) + 1) & ((s) - 1))\n#define dma_cnt(n)\t\t\t((n) >> 5)\n#define dma_byte(n)\t\t\t((n) << 5)\n\n#define HW_CAP_TSO\t\t\tBIT(0)\n#define GEMAC_V1\t\t\t0\n#define GEMAC_V2\t\t\t(GEMAC_V1 | HW_CAP_TSO)\n#define HAS_CAP_TSO(hw_cap)\t\t((hw_cap) & HW_CAP_TSO)\n\n#define PHY_RESET_DELAYS_PROPERTY\t\"hisilicon,phy-reset-delays-us\"\n\nenum phy_reset_delays {\n\tPRE_DELAY,\n\tPULSE,\n\tPOST_DELAY,\n\tDELAYS_NUM,\n};\n\nstruct hix5hd2_desc {\n\t__le32 buff_addr;\n\t__le32 cmd;\n} __aligned(32);\n\nstruct hix5hd2_desc_sw {\n\tstruct hix5hd2_desc *desc;\n\tdma_addr_t\tphys_addr;\n\tunsigned int\tcount;\n\tunsigned int\tsize;\n};\n\nstruct hix5hd2_sg_desc_ring {\n\tstruct sg_desc *desc;\n\tdma_addr_t phys_addr;\n};\n\nstruct frags_info {\n\t__le32 addr;\n\t__le32 size;\n};\n\n \n#define SG_MAX_SKB_FRAGS\t17\nstruct sg_desc {\n\t__le32 total_len;\n\t__le32 resvd0;\n\t__le32 linear_addr;\n\t__le32 linear_len;\n\t \n\tstruct frags_info frags[SG_MAX_SKB_FRAGS + 1];\n};\n\n#define QUEUE_NUMS\t4\nstruct hix5hd2_priv {\n\tstruct hix5hd2_desc_sw pool[QUEUE_NUMS];\n#define rx_fq\t\tpool[0]\n#define rx_bq\t\tpool[1]\n#define tx_bq\t\tpool[2]\n#define tx_rq\t\tpool[3]\n\tstruct hix5hd2_sg_desc_ring tx_ring;\n\n\tvoid __iomem *base;\n\tvoid __iomem *ctrl_base;\n\n\tstruct sk_buff *tx_skb[TX_DESC_NUM];\n\tstruct sk_buff *rx_skb[RX_DESC_NUM];\n\n\tstruct device *dev;\n\tstruct net_device *netdev;\n\n\tstruct device_node *phy_node;\n\tphy_interface_t\tphy_mode;\n\n\tunsigned long hw_cap;\n\tunsigned int speed;\n\tunsigned int duplex;\n\n\tstruct clk *mac_core_clk;\n\tstruct clk *mac_ifc_clk;\n\tstruct reset_control *mac_core_rst;\n\tstruct reset_control *mac_ifc_rst;\n\tstruct reset_control *phy_rst;\n\tu32 phy_reset_delays[DELAYS_NUM];\n\tstruct mii_bus *bus;\n\tstruct napi_struct napi;\n\tstruct work_struct tx_timeout_task;\n};\n\nstatic inline void hix5hd2_mac_interface_reset(struct hix5hd2_priv *priv)\n{\n\tif (!priv->mac_ifc_rst)\n\t\treturn;\n\n\treset_control_assert(priv->mac_ifc_rst);\n\treset_control_deassert(priv->mac_ifc_rst);\n}\n\nstatic void hix5hd2_config_port(struct net_device *dev, u32 speed, u32 duplex)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tu32 val;\n\n\tpriv->speed = speed;\n\tpriv->duplex = duplex;\n\n\tswitch (priv->phy_mode) {\n\tcase PHY_INTERFACE_MODE_RGMII:\n\t\tif (speed == SPEED_1000)\n\t\t\tval = RGMII_SPEED_1000;\n\t\telse if (speed == SPEED_100)\n\t\t\tval = RGMII_SPEED_100;\n\t\telse\n\t\t\tval = RGMII_SPEED_10;\n\t\tbreak;\n\tcase PHY_INTERFACE_MODE_MII:\n\t\tif (speed == SPEED_100)\n\t\t\tval = MII_SPEED_100;\n\t\telse\n\t\t\tval = MII_SPEED_10;\n\t\tbreak;\n\tdefault:\n\t\tnetdev_warn(dev, \"not supported mode\\n\");\n\t\tval = MII_SPEED_10;\n\t\tbreak;\n\t}\n\n\tif (duplex)\n\t\tval |= GMAC_FULL_DUPLEX;\n\twritel_relaxed(val, priv->ctrl_base);\n\thix5hd2_mac_interface_reset(priv);\n\n\twritel_relaxed(BIT_MODE_CHANGE_EN, priv->base + MODE_CHANGE_EN);\n\tif (speed == SPEED_1000)\n\t\tval = GMAC_SPEED_1000;\n\telse if (speed == SPEED_100)\n\t\tval = GMAC_SPEED_100;\n\telse\n\t\tval = GMAC_SPEED_10;\n\twritel_relaxed(val, priv->base + PORT_MODE);\n\twritel_relaxed(0, priv->base + MODE_CHANGE_EN);\n\twritel_relaxed(duplex, priv->base + MAC_DUPLEX_HALF_CTRL);\n}\n\nstatic void hix5hd2_set_desc_depth(struct hix5hd2_priv *priv, int rx, int tx)\n{\n\twritel_relaxed(BITS_RX_FQ_DEPTH_EN, priv->base + RX_FQ_REG_EN);\n\twritel_relaxed(rx << 3, priv->base + RX_FQ_DEPTH);\n\twritel_relaxed(0, priv->base + RX_FQ_REG_EN);\n\n\twritel_relaxed(BITS_RX_BQ_DEPTH_EN, priv->base + RX_BQ_REG_EN);\n\twritel_relaxed(rx << 3, priv->base + RX_BQ_DEPTH);\n\twritel_relaxed(0, priv->base + RX_BQ_REG_EN);\n\n\twritel_relaxed(BITS_TX_BQ_DEPTH_EN, priv->base + TX_BQ_REG_EN);\n\twritel_relaxed(tx << 3, priv->base + TX_BQ_DEPTH);\n\twritel_relaxed(0, priv->base + TX_BQ_REG_EN);\n\n\twritel_relaxed(BITS_TX_RQ_DEPTH_EN, priv->base + TX_RQ_REG_EN);\n\twritel_relaxed(tx << 3, priv->base + TX_RQ_DEPTH);\n\twritel_relaxed(0, priv->base + TX_RQ_REG_EN);\n}\n\nstatic void hix5hd2_set_rx_fq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\n{\n\twritel_relaxed(BITS_RX_FQ_START_ADDR_EN, priv->base + RX_FQ_REG_EN);\n\twritel_relaxed(phy_addr, priv->base + RX_FQ_START_ADDR);\n\twritel_relaxed(0, priv->base + RX_FQ_REG_EN);\n}\n\nstatic void hix5hd2_set_rx_bq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\n{\n\twritel_relaxed(BITS_RX_BQ_START_ADDR_EN, priv->base + RX_BQ_REG_EN);\n\twritel_relaxed(phy_addr, priv->base + RX_BQ_START_ADDR);\n\twritel_relaxed(0, priv->base + RX_BQ_REG_EN);\n}\n\nstatic void hix5hd2_set_tx_bq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\n{\n\twritel_relaxed(BITS_TX_BQ_START_ADDR_EN, priv->base + TX_BQ_REG_EN);\n\twritel_relaxed(phy_addr, priv->base + TX_BQ_START_ADDR);\n\twritel_relaxed(0, priv->base + TX_BQ_REG_EN);\n}\n\nstatic void hix5hd2_set_tx_rq(struct hix5hd2_priv *priv, dma_addr_t phy_addr)\n{\n\twritel_relaxed(BITS_TX_RQ_START_ADDR_EN, priv->base + TX_RQ_REG_EN);\n\twritel_relaxed(phy_addr, priv->base + TX_RQ_START_ADDR);\n\twritel_relaxed(0, priv->base + TX_RQ_REG_EN);\n}\n\nstatic void hix5hd2_set_desc_addr(struct hix5hd2_priv *priv)\n{\n\thix5hd2_set_rx_fq(priv, priv->rx_fq.phys_addr);\n\thix5hd2_set_rx_bq(priv, priv->rx_bq.phys_addr);\n\thix5hd2_set_tx_rq(priv, priv->tx_rq.phys_addr);\n\thix5hd2_set_tx_bq(priv, priv->tx_bq.phys_addr);\n}\n\nstatic void hix5hd2_hw_init(struct hix5hd2_priv *priv)\n{\n\tu32 val;\n\n\t \n\twritel_relaxed(0, priv->base + ENA_PMU_INT);\n\twritel_relaxed(~0, priv->base + RAW_PMU_INT);\n\n\twritel_relaxed(BIT_CRC_ERR_PASS, priv->base + REC_FILT_CONTROL);\n\twritel_relaxed(MAC_MAX_FRAME_SIZE, priv->base + CONTROL_WORD);\n\twritel_relaxed(0, priv->base + COL_SLOT_TIME);\n\n\tval = RX_BQ_INT_THRESHOLD | TX_RQ_INT_THRESHOLD << QUEUE_TX_BQ_SHIFT;\n\twritel_relaxed(val, priv->base + IN_QUEUE_TH);\n\n\twritel_relaxed(RX_BQ_IN_TIMEOUT, priv->base + RX_BQ_IN_TIMEOUT_TH);\n\twritel_relaxed(TX_RQ_IN_TIMEOUT, priv->base + TX_RQ_IN_TIMEOUT_TH);\n\n\thix5hd2_set_desc_depth(priv, RX_DESC_NUM, TX_DESC_NUM);\n\thix5hd2_set_desc_addr(priv);\n}\n\nstatic void hix5hd2_irq_enable(struct hix5hd2_priv *priv)\n{\n\twritel_relaxed(DEF_INT_MASK, priv->base + ENA_PMU_INT);\n}\n\nstatic void hix5hd2_irq_disable(struct hix5hd2_priv *priv)\n{\n\twritel_relaxed(0, priv->base + ENA_PMU_INT);\n}\n\nstatic void hix5hd2_port_enable(struct hix5hd2_priv *priv)\n{\n\twritel_relaxed(0xf, priv->base + DESC_WR_RD_ENA);\n\twritel_relaxed(BITS_RX_EN | BITS_TX_EN, priv->base + PORT_EN);\n}\n\nstatic void hix5hd2_port_disable(struct hix5hd2_priv *priv)\n{\n\twritel_relaxed(~(u32)(BITS_RX_EN | BITS_TX_EN), priv->base + PORT_EN);\n\twritel_relaxed(0, priv->base + DESC_WR_RD_ENA);\n}\n\nstatic void hix5hd2_hw_set_mac_addr(struct net_device *dev)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tconst unsigned char *mac = dev->dev_addr;\n\tu32 val;\n\n\tval = mac[1] | (mac[0] << 8);\n\twritel_relaxed(val, priv->base + STATION_ADDR_HIGH);\n\n\tval = mac[5] | (mac[4] << 8) | (mac[3] << 16) | (mac[2] << 24);\n\twritel_relaxed(val, priv->base + STATION_ADDR_LOW);\n}\n\nstatic int hix5hd2_net_set_mac_address(struct net_device *dev, void *p)\n{\n\tint ret;\n\n\tret = eth_mac_addr(dev, p);\n\tif (!ret)\n\t\thix5hd2_hw_set_mac_addr(dev);\n\n\treturn ret;\n}\n\nstatic void hix5hd2_adjust_link(struct net_device *dev)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tstruct phy_device *phy = dev->phydev;\n\n\tif ((priv->speed != phy->speed) || (priv->duplex != phy->duplex)) {\n\t\thix5hd2_config_port(dev, phy->speed, phy->duplex);\n\t\tphy_print_status(phy);\n\t}\n}\n\nstatic void hix5hd2_rx_refill(struct hix5hd2_priv *priv)\n{\n\tstruct hix5hd2_desc *desc;\n\tstruct sk_buff *skb;\n\tu32 start, end, num, pos, i;\n\tu32 len = MAC_MAX_FRAME_SIZE;\n\tdma_addr_t addr;\n\n\t \n\tstart = dma_cnt(readl_relaxed(priv->base + RX_FQ_WR_ADDR));\n\t \n\tend = dma_cnt(readl_relaxed(priv->base + RX_FQ_RD_ADDR));\n\tnum = CIRC_SPACE(start, end, RX_DESC_NUM);\n\n\tfor (i = 0, pos = start; i < num; i++) {\n\t\tif (priv->rx_skb[pos]) {\n\t\t\tbreak;\n\t\t} else {\n\t\t\tskb = netdev_alloc_skb_ip_align(priv->netdev, len);\n\t\t\tif (unlikely(skb == NULL))\n\t\t\t\tbreak;\n\t\t}\n\n\t\taddr = dma_map_single(priv->dev, skb->data, len, DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(priv->dev, addr)) {\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tbreak;\n\t\t}\n\n\t\tdesc = priv->rx_fq.desc + pos;\n\t\tdesc->buff_addr = cpu_to_le32(addr);\n\t\tpriv->rx_skb[pos] = skb;\n\t\tdesc->cmd = cpu_to_le32(DESC_VLD_FREE |\n\t\t\t\t\t(len - 1) << DESC_BUFF_LEN_OFF);\n\t\tpos = dma_ring_incr(pos, RX_DESC_NUM);\n\t}\n\n\t \n\twmb();\n\n\tif (pos != start)\n\t\twritel_relaxed(dma_byte(pos), priv->base + RX_FQ_WR_ADDR);\n}\n\nstatic int hix5hd2_rx(struct net_device *dev, int limit)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tstruct sk_buff *skb;\n\tstruct hix5hd2_desc *desc;\n\tdma_addr_t addr;\n\tu32 start, end, num, pos, i, len;\n\n\t \n\tstart = dma_cnt(readl_relaxed(priv->base + RX_BQ_RD_ADDR));\n\t \n\tend = dma_cnt(readl_relaxed(priv->base + RX_BQ_WR_ADDR));\n\tnum = CIRC_CNT(end, start, RX_DESC_NUM);\n\tif (num > limit)\n\t\tnum = limit;\n\n\t \n\trmb();\n\tfor (i = 0, pos = start; i < num; i++) {\n\t\tskb = priv->rx_skb[pos];\n\t\tif (unlikely(!skb)) {\n\t\t\tnetdev_err(dev, \"inconsistent rx_skb\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tpriv->rx_skb[pos] = NULL;\n\n\t\tdesc = priv->rx_bq.desc + pos;\n\t\tlen = (le32_to_cpu(desc->cmd) >> DESC_DATA_LEN_OFF) &\n\t\t       DESC_DATA_MASK;\n\t\taddr = le32_to_cpu(desc->buff_addr);\n\t\tdma_unmap_single(priv->dev, addr, MAC_MAX_FRAME_SIZE,\n\t\t\t\t DMA_FROM_DEVICE);\n\n\t\tskb_put(skb, len);\n\t\tif (skb->len > MAC_MAX_FRAME_SIZE) {\n\t\t\tnetdev_err(dev, \"rcv len err, len = %d\\n\", skb->len);\n\t\t\tdev->stats.rx_errors++;\n\t\t\tdev->stats.rx_length_errors++;\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tgoto next;\n\t\t}\n\n\t\tskb->protocol = eth_type_trans(skb, dev);\n\t\tnapi_gro_receive(&priv->napi, skb);\n\t\tdev->stats.rx_packets++;\n\t\tdev->stats.rx_bytes += len;\nnext:\n\t\tpos = dma_ring_incr(pos, RX_DESC_NUM);\n\t}\n\n\tif (pos != start)\n\t\twritel_relaxed(dma_byte(pos), priv->base + RX_BQ_RD_ADDR);\n\n\thix5hd2_rx_refill(priv);\n\n\treturn num;\n}\n\nstatic void hix5hd2_clean_sg_desc(struct hix5hd2_priv *priv,\n\t\t\t\t  struct sk_buff *skb, u32 pos)\n{\n\tstruct sg_desc *desc;\n\tdma_addr_t addr;\n\tu32 len;\n\tint i;\n\n\tdesc = priv->tx_ring.desc + pos;\n\n\taddr = le32_to_cpu(desc->linear_addr);\n\tlen = le32_to_cpu(desc->linear_len);\n\tdma_unmap_single(priv->dev, addr, len, DMA_TO_DEVICE);\n\n\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\taddr = le32_to_cpu(desc->frags[i].addr);\n\t\tlen = le32_to_cpu(desc->frags[i].size);\n\t\tdma_unmap_page(priv->dev, addr, len, DMA_TO_DEVICE);\n\t}\n}\n\nstatic void hix5hd2_xmit_reclaim(struct net_device *dev)\n{\n\tstruct sk_buff *skb;\n\tstruct hix5hd2_desc *desc;\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tunsigned int bytes_compl = 0, pkts_compl = 0;\n\tu32 start, end, num, pos, i;\n\tdma_addr_t addr;\n\n\tnetif_tx_lock(dev);\n\n\t \n\tstart = dma_cnt(readl_relaxed(priv->base + TX_RQ_RD_ADDR));\n\t \n\tend = dma_cnt(readl_relaxed(priv->base + TX_RQ_WR_ADDR));\n\tnum = CIRC_CNT(end, start, TX_DESC_NUM);\n\n\tfor (i = 0, pos = start; i < num; i++) {\n\t\tskb = priv->tx_skb[pos];\n\t\tif (unlikely(!skb)) {\n\t\t\tnetdev_err(dev, \"inconsistent tx_skb\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tpkts_compl++;\n\t\tbytes_compl += skb->len;\n\t\tdesc = priv->tx_rq.desc + pos;\n\n\t\tif (skb_shinfo(skb)->nr_frags) {\n\t\t\thix5hd2_clean_sg_desc(priv, skb, pos);\n\t\t} else {\n\t\t\taddr = le32_to_cpu(desc->buff_addr);\n\t\t\tdma_unmap_single(priv->dev, addr, skb->len,\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\t}\n\n\t\tpriv->tx_skb[pos] = NULL;\n\t\tdev_consume_skb_any(skb);\n\t\tpos = dma_ring_incr(pos, TX_DESC_NUM);\n\t}\n\n\tif (pos != start)\n\t\twritel_relaxed(dma_byte(pos), priv->base + TX_RQ_RD_ADDR);\n\n\tnetif_tx_unlock(dev);\n\n\tif (pkts_compl || bytes_compl)\n\t\tnetdev_completed_queue(dev, pkts_compl, bytes_compl);\n\n\tif (unlikely(netif_queue_stopped(priv->netdev)) && pkts_compl)\n\t\tnetif_wake_queue(priv->netdev);\n}\n\nstatic int hix5hd2_poll(struct napi_struct *napi, int budget)\n{\n\tstruct hix5hd2_priv *priv = container_of(napi,\n\t\t\t\tstruct hix5hd2_priv, napi);\n\tstruct net_device *dev = priv->netdev;\n\tint work_done = 0, task = budget;\n\tint ints, num;\n\n\tdo {\n\t\thix5hd2_xmit_reclaim(dev);\n\t\tnum = hix5hd2_rx(dev, task);\n\t\twork_done += num;\n\t\ttask -= num;\n\t\tif ((work_done >= budget) || (num == 0))\n\t\t\tbreak;\n\n\t\tints = readl_relaxed(priv->base + RAW_PMU_INT);\n\t\twritel_relaxed(ints, priv->base + RAW_PMU_INT);\n\t} while (ints & DEF_INT_MASK);\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(napi, work_done);\n\t\thix5hd2_irq_enable(priv);\n\t}\n\n\treturn work_done;\n}\n\nstatic irqreturn_t hix5hd2_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *dev = (struct net_device *)dev_id;\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tint ints = readl_relaxed(priv->base + RAW_PMU_INT);\n\n\twritel_relaxed(ints, priv->base + RAW_PMU_INT);\n\tif (likely(ints & DEF_INT_MASK)) {\n\t\thix5hd2_irq_disable(priv);\n\t\tnapi_schedule(&priv->napi);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic u32 hix5hd2_get_desc_cmd(struct sk_buff *skb, unsigned long hw_cap)\n{\n\tu32 cmd = 0;\n\n\tif (HAS_CAP_TSO(hw_cap)) {\n\t\tif (skb_shinfo(skb)->nr_frags)\n\t\t\tcmd |= DESC_SG;\n\t\tcmd |= skb_shinfo(skb)->nr_frags << DESC_FRAGS_NUM_OFF;\n\t} else {\n\t\tcmd |= DESC_FL_FULL |\n\t\t\t((skb->len & DESC_DATA_MASK) << DESC_BUFF_LEN_OFF);\n\t}\n\n\tcmd |= (skb->len & DESC_DATA_MASK) << DESC_DATA_LEN_OFF;\n\tcmd |= DESC_VLD_BUSY;\n\n\treturn cmd;\n}\n\nstatic int hix5hd2_fill_sg_desc(struct hix5hd2_priv *priv,\n\t\t\t\tstruct sk_buff *skb, u32 pos)\n{\n\tstruct sg_desc *desc;\n\tdma_addr_t addr;\n\tint ret;\n\tint i;\n\n\tdesc = priv->tx_ring.desc + pos;\n\n\tdesc->total_len = cpu_to_le32(skb->len);\n\taddr = dma_map_single(priv->dev, skb->data, skb_headlen(skb),\n\t\t\t      DMA_TO_DEVICE);\n\tif (unlikely(dma_mapping_error(priv->dev, addr)))\n\t\treturn -EINVAL;\n\tdesc->linear_addr = cpu_to_le32(addr);\n\tdesc->linear_len = cpu_to_le32(skb_headlen(skb));\n\n\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\t\tint len = skb_frag_size(frag);\n\n\t\taddr = skb_frag_dma_map(priv->dev, frag, 0, len, DMA_TO_DEVICE);\n\t\tret = dma_mapping_error(priv->dev, addr);\n\t\tif (unlikely(ret))\n\t\t\treturn -EINVAL;\n\t\tdesc->frags[i].addr = cpu_to_le32(addr);\n\t\tdesc->frags[i].size = cpu_to_le32(len);\n\t}\n\n\treturn 0;\n}\n\nstatic netdev_tx_t hix5hd2_net_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tstruct hix5hd2_desc *desc;\n\tdma_addr_t addr;\n\tu32 pos;\n\tu32 cmd;\n\tint ret;\n\n\t \n\tpos = dma_cnt(readl_relaxed(priv->base + TX_BQ_WR_ADDR));\n\tif (unlikely(priv->tx_skb[pos])) {\n\t\tdev->stats.tx_dropped++;\n\t\tdev->stats.tx_fifo_errors++;\n\t\tnetif_stop_queue(dev);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tdesc = priv->tx_bq.desc + pos;\n\n\tcmd = hix5hd2_get_desc_cmd(skb, priv->hw_cap);\n\tdesc->cmd = cpu_to_le32(cmd);\n\n\tif (skb_shinfo(skb)->nr_frags) {\n\t\tret = hix5hd2_fill_sg_desc(priv, skb, pos);\n\t\tif (unlikely(ret)) {\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tdev->stats.tx_dropped++;\n\t\t\treturn NETDEV_TX_OK;\n\t\t}\n\t\taddr = priv->tx_ring.phys_addr + pos * sizeof(struct sg_desc);\n\t} else {\n\t\taddr = dma_map_single(priv->dev, skb->data, skb->len,\n\t\t\t\t      DMA_TO_DEVICE);\n\t\tif (unlikely(dma_mapping_error(priv->dev, addr))) {\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tdev->stats.tx_dropped++;\n\t\t\treturn NETDEV_TX_OK;\n\t\t}\n\t}\n\tdesc->buff_addr = cpu_to_le32(addr);\n\n\tpriv->tx_skb[pos] = skb;\n\n\t \n\twmb();\n\n\tpos = dma_ring_incr(pos, TX_DESC_NUM);\n\twritel_relaxed(dma_byte(pos), priv->base + TX_BQ_WR_ADDR);\n\n\tnetif_trans_update(dev);\n\tdev->stats.tx_packets++;\n\tdev->stats.tx_bytes += skb->len;\n\tnetdev_sent_queue(dev, skb->len);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void hix5hd2_free_dma_desc_rings(struct hix5hd2_priv *priv)\n{\n\tstruct hix5hd2_desc *desc;\n\tdma_addr_t addr;\n\tint i;\n\n\tfor (i = 0; i < RX_DESC_NUM; i++) {\n\t\tstruct sk_buff *skb = priv->rx_skb[i];\n\t\tif (skb == NULL)\n\t\t\tcontinue;\n\n\t\tdesc = priv->rx_fq.desc + i;\n\t\taddr = le32_to_cpu(desc->buff_addr);\n\t\tdma_unmap_single(priv->dev, addr,\n\t\t\t\t MAC_MAX_FRAME_SIZE, DMA_FROM_DEVICE);\n\t\tdev_kfree_skb_any(skb);\n\t\tpriv->rx_skb[i] = NULL;\n\t}\n\n\tfor (i = 0; i < TX_DESC_NUM; i++) {\n\t\tstruct sk_buff *skb = priv->tx_skb[i];\n\t\tif (skb == NULL)\n\t\t\tcontinue;\n\n\t\tdesc = priv->tx_rq.desc + i;\n\t\taddr = le32_to_cpu(desc->buff_addr);\n\t\tdma_unmap_single(priv->dev, addr, skb->len, DMA_TO_DEVICE);\n\t\tdev_kfree_skb_any(skb);\n\t\tpriv->tx_skb[i] = NULL;\n\t}\n}\n\nstatic int hix5hd2_net_open(struct net_device *dev)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\tstruct phy_device *phy;\n\tint ret;\n\n\tret = clk_prepare_enable(priv->mac_core_clk);\n\tif (ret < 0) {\n\t\tnetdev_err(dev, \"failed to enable mac core clk %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = clk_prepare_enable(priv->mac_ifc_clk);\n\tif (ret < 0) {\n\t\tclk_disable_unprepare(priv->mac_core_clk);\n\t\tnetdev_err(dev, \"failed to enable mac ifc clk %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tphy = of_phy_connect(dev, priv->phy_node,\n\t\t\t     &hix5hd2_adjust_link, 0, priv->phy_mode);\n\tif (!phy) {\n\t\tclk_disable_unprepare(priv->mac_ifc_clk);\n\t\tclk_disable_unprepare(priv->mac_core_clk);\n\t\treturn -ENODEV;\n\t}\n\n\tphy_start(phy);\n\thix5hd2_hw_init(priv);\n\thix5hd2_rx_refill(priv);\n\n\tnetdev_reset_queue(dev);\n\tnetif_start_queue(dev);\n\tnapi_enable(&priv->napi);\n\n\thix5hd2_port_enable(priv);\n\thix5hd2_irq_enable(priv);\n\n\treturn 0;\n}\n\nstatic int hix5hd2_net_close(struct net_device *dev)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\n\thix5hd2_port_disable(priv);\n\thix5hd2_irq_disable(priv);\n\tnapi_disable(&priv->napi);\n\tnetif_stop_queue(dev);\n\thix5hd2_free_dma_desc_rings(priv);\n\n\tif (dev->phydev) {\n\t\tphy_stop(dev->phydev);\n\t\tphy_disconnect(dev->phydev);\n\t}\n\n\tclk_disable_unprepare(priv->mac_ifc_clk);\n\tclk_disable_unprepare(priv->mac_core_clk);\n\n\treturn 0;\n}\n\nstatic void hix5hd2_tx_timeout_task(struct work_struct *work)\n{\n\tstruct hix5hd2_priv *priv;\n\n\tpriv = container_of(work, struct hix5hd2_priv, tx_timeout_task);\n\thix5hd2_net_close(priv->netdev);\n\thix5hd2_net_open(priv->netdev);\n}\n\nstatic void hix5hd2_net_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct hix5hd2_priv *priv = netdev_priv(dev);\n\n\tschedule_work(&priv->tx_timeout_task);\n}\n\nstatic const struct net_device_ops hix5hd2_netdev_ops = {\n\t.ndo_open\t\t= hix5hd2_net_open,\n\t.ndo_stop\t\t= hix5hd2_net_close,\n\t.ndo_start_xmit\t\t= hix5hd2_net_xmit,\n\t.ndo_tx_timeout\t\t= hix5hd2_net_timeout,\n\t.ndo_set_mac_address\t= hix5hd2_net_set_mac_address,\n};\n\nstatic const struct ethtool_ops hix5hd2_ethtools_ops = {\n\t.get_link\t\t= ethtool_op_get_link,\n\t.get_link_ksettings     = phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings     = phy_ethtool_set_link_ksettings,\n};\n\nstatic int hix5hd2_mdio_wait_ready(struct mii_bus *bus)\n{\n\tstruct hix5hd2_priv *priv = bus->priv;\n\tvoid __iomem *base = priv->base;\n\tint i, timeout = 10000;\n\n\tfor (i = 0; readl_relaxed(base + MDIO_SINGLE_CMD) & MDIO_START; i++) {\n\t\tif (i == timeout)\n\t\t\treturn -ETIMEDOUT;\n\t\tusleep_range(10, 20);\n\t}\n\n\treturn 0;\n}\n\nstatic int hix5hd2_mdio_read(struct mii_bus *bus, int phy, int reg)\n{\n\tstruct hix5hd2_priv *priv = bus->priv;\n\tvoid __iomem *base = priv->base;\n\tint val, ret;\n\n\tret = hix5hd2_mdio_wait_ready(bus);\n\tif (ret < 0)\n\t\tgoto out;\n\n\twritel_relaxed(MDIO_READ | phy << 8 | reg, base + MDIO_SINGLE_CMD);\n\tret = hix5hd2_mdio_wait_ready(bus);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tval = readl_relaxed(base + MDIO_RDATA_STATUS);\n\tif (val & MDIO_R_VALID) {\n\t\tdev_err(bus->parent, \"SMI bus read not valid\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tval = readl_relaxed(priv->base + MDIO_SINGLE_DATA);\n\tret = (val >> 16) & 0xFFFF;\nout:\n\treturn ret;\n}\n\nstatic int hix5hd2_mdio_write(struct mii_bus *bus, int phy, int reg, u16 val)\n{\n\tstruct hix5hd2_priv *priv = bus->priv;\n\tvoid __iomem *base = priv->base;\n\tint ret;\n\n\tret = hix5hd2_mdio_wait_ready(bus);\n\tif (ret < 0)\n\t\tgoto out;\n\n\twritel_relaxed(val, base + MDIO_SINGLE_DATA);\n\twritel_relaxed(MDIO_WRITE | phy << 8 | reg, base + MDIO_SINGLE_CMD);\n\tret = hix5hd2_mdio_wait_ready(bus);\nout:\n\treturn ret;\n}\n\nstatic void hix5hd2_destroy_hw_desc_queue(struct hix5hd2_priv *priv)\n{\n\tint i;\n\n\tfor (i = 0; i < QUEUE_NUMS; i++) {\n\t\tif (priv->pool[i].desc) {\n\t\t\tdma_free_coherent(priv->dev, priv->pool[i].size,\n\t\t\t\t\t  priv->pool[i].desc,\n\t\t\t\t\t  priv->pool[i].phys_addr);\n\t\t\tpriv->pool[i].desc = NULL;\n\t\t}\n\t}\n}\n\nstatic int hix5hd2_init_hw_desc_queue(struct hix5hd2_priv *priv)\n{\n\tstruct device *dev = priv->dev;\n\tstruct hix5hd2_desc *virt_addr;\n\tdma_addr_t phys_addr;\n\tint size, i;\n\n\tpriv->rx_fq.count = RX_DESC_NUM;\n\tpriv->rx_bq.count = RX_DESC_NUM;\n\tpriv->tx_bq.count = TX_DESC_NUM;\n\tpriv->tx_rq.count = TX_DESC_NUM;\n\n\tfor (i = 0; i < QUEUE_NUMS; i++) {\n\t\tsize = priv->pool[i].count * sizeof(struct hix5hd2_desc);\n\t\tvirt_addr = dma_alloc_coherent(dev, size, &phys_addr,\n\t\t\t\t\t       GFP_KERNEL);\n\t\tif (virt_addr == NULL)\n\t\t\tgoto error_free_pool;\n\n\t\tpriv->pool[i].size = size;\n\t\tpriv->pool[i].desc = virt_addr;\n\t\tpriv->pool[i].phys_addr = phys_addr;\n\t}\n\treturn 0;\n\nerror_free_pool:\n\thix5hd2_destroy_hw_desc_queue(priv);\n\n\treturn -ENOMEM;\n}\n\nstatic int hix5hd2_init_sg_desc_queue(struct hix5hd2_priv *priv)\n{\n\tstruct sg_desc *desc;\n\tdma_addr_t phys_addr;\n\n\tdesc = dma_alloc_coherent(priv->dev,\n\t\t\t\t  TX_DESC_NUM * sizeof(struct sg_desc),\n\t\t\t\t  &phys_addr, GFP_KERNEL);\n\tif (!desc)\n\t\treturn -ENOMEM;\n\n\tpriv->tx_ring.desc = desc;\n\tpriv->tx_ring.phys_addr = phys_addr;\n\n\treturn 0;\n}\n\nstatic void hix5hd2_destroy_sg_desc_queue(struct hix5hd2_priv *priv)\n{\n\tif (priv->tx_ring.desc) {\n\t\tdma_free_coherent(priv->dev,\n\t\t\t\t  TX_DESC_NUM * sizeof(struct sg_desc),\n\t\t\t\t  priv->tx_ring.desc, priv->tx_ring.phys_addr);\n\t\tpriv->tx_ring.desc = NULL;\n\t}\n}\n\nstatic inline void hix5hd2_mac_core_reset(struct hix5hd2_priv *priv)\n{\n\tif (!priv->mac_core_rst)\n\t\treturn;\n\n\treset_control_assert(priv->mac_core_rst);\n\treset_control_deassert(priv->mac_core_rst);\n}\n\nstatic void hix5hd2_sleep_us(u32 time_us)\n{\n\tu32 time_ms;\n\n\tif (!time_us)\n\t\treturn;\n\n\ttime_ms = DIV_ROUND_UP(time_us, 1000);\n\tif (time_ms < 20)\n\t\tusleep_range(time_us, time_us + 500);\n\telse\n\t\tmsleep(time_ms);\n}\n\nstatic void hix5hd2_phy_reset(struct hix5hd2_priv *priv)\n{\n\t \n\treset_control_deassert(priv->phy_rst);\n\thix5hd2_sleep_us(priv->phy_reset_delays[PRE_DELAY]);\n\n\treset_control_assert(priv->phy_rst);\n\t \n\thix5hd2_sleep_us(priv->phy_reset_delays[PULSE]);\n\treset_control_deassert(priv->phy_rst);\n\t \n\thix5hd2_sleep_us(priv->phy_reset_delays[POST_DELAY]);\n}\n\nstatic const struct of_device_id hix5hd2_of_match[];\n\nstatic int hix5hd2_dev_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *node = dev->of_node;\n\tconst struct of_device_id *of_id = NULL;\n\tstruct net_device *ndev;\n\tstruct hix5hd2_priv *priv;\n\tstruct mii_bus *bus;\n\tint ret;\n\n\tndev = alloc_etherdev(sizeof(struct hix5hd2_priv));\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, ndev);\n\n\tpriv = netdev_priv(ndev);\n\tpriv->dev = dev;\n\tpriv->netdev = ndev;\n\n\tof_id = of_match_device(hix5hd2_of_match, dev);\n\tif (!of_id) {\n\t\tret = -EINVAL;\n\t\tgoto out_free_netdev;\n\t}\n\tpriv->hw_cap = (unsigned long)of_id->data;\n\n\tpriv->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(priv->base)) {\n\t\tret = PTR_ERR(priv->base);\n\t\tgoto out_free_netdev;\n\t}\n\n\tpriv->ctrl_base = devm_platform_ioremap_resource(pdev, 1);\n\tif (IS_ERR(priv->ctrl_base)) {\n\t\tret = PTR_ERR(priv->ctrl_base);\n\t\tgoto out_free_netdev;\n\t}\n\n\tpriv->mac_core_clk = devm_clk_get(&pdev->dev, \"mac_core\");\n\tif (IS_ERR(priv->mac_core_clk)) {\n\t\tnetdev_err(ndev, \"failed to get mac core clk\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_free_netdev;\n\t}\n\n\tret = clk_prepare_enable(priv->mac_core_clk);\n\tif (ret < 0) {\n\t\tnetdev_err(ndev, \"failed to enable mac core clk %d\\n\", ret);\n\t\tgoto out_free_netdev;\n\t}\n\n\tpriv->mac_ifc_clk = devm_clk_get(&pdev->dev, \"mac_ifc\");\n\tif (IS_ERR(priv->mac_ifc_clk))\n\t\tpriv->mac_ifc_clk = NULL;\n\n\tret = clk_prepare_enable(priv->mac_ifc_clk);\n\tif (ret < 0) {\n\t\tnetdev_err(ndev, \"failed to enable mac ifc clk %d\\n\", ret);\n\t\tgoto out_disable_mac_core_clk;\n\t}\n\n\tpriv->mac_core_rst = devm_reset_control_get(dev, \"mac_core\");\n\tif (IS_ERR(priv->mac_core_rst))\n\t\tpriv->mac_core_rst = NULL;\n\thix5hd2_mac_core_reset(priv);\n\n\tpriv->mac_ifc_rst = devm_reset_control_get(dev, \"mac_ifc\");\n\tif (IS_ERR(priv->mac_ifc_rst))\n\t\tpriv->mac_ifc_rst = NULL;\n\n\tpriv->phy_rst = devm_reset_control_get(dev, \"phy\");\n\tif (IS_ERR(priv->phy_rst)) {\n\t\tpriv->phy_rst = NULL;\n\t} else {\n\t\tret = of_property_read_u32_array(node,\n\t\t\t\t\t\t PHY_RESET_DELAYS_PROPERTY,\n\t\t\t\t\t\t priv->phy_reset_delays,\n\t\t\t\t\t\t DELAYS_NUM);\n\t\tif (ret)\n\t\t\tgoto out_disable_clk;\n\t\thix5hd2_phy_reset(priv);\n\t}\n\n\tbus = mdiobus_alloc();\n\tif (bus == NULL) {\n\t\tret = -ENOMEM;\n\t\tgoto out_disable_clk;\n\t}\n\n\tbus->priv = priv;\n\tbus->name = \"hix5hd2_mii_bus\";\n\tbus->read = hix5hd2_mdio_read;\n\tbus->write = hix5hd2_mdio_write;\n\tbus->parent = &pdev->dev;\n\tsnprintf(bus->id, MII_BUS_ID_SIZE, \"%s-mii\", dev_name(&pdev->dev));\n\tpriv->bus = bus;\n\n\tret = of_mdiobus_register(bus, node);\n\tif (ret)\n\t\tgoto err_free_mdio;\n\n\tret = of_get_phy_mode(node, &priv->phy_mode);\n\tif (ret) {\n\t\tnetdev_err(ndev, \"not find phy-mode\\n\");\n\t\tgoto err_mdiobus;\n\t}\n\n\tpriv->phy_node = of_parse_phandle(node, \"phy-handle\", 0);\n\tif (!priv->phy_node) {\n\t\tnetdev_err(ndev, \"not find phy-handle\\n\");\n\t\tret = -EINVAL;\n\t\tgoto err_mdiobus;\n\t}\n\n\tndev->irq = platform_get_irq(pdev, 0);\n\tif (ndev->irq < 0) {\n\t\tret = ndev->irq;\n\t\tgoto out_phy_node;\n\t}\n\n\tret = devm_request_irq(dev, ndev->irq, hix5hd2_interrupt,\n\t\t\t       0, pdev->name, ndev);\n\tif (ret) {\n\t\tnetdev_err(ndev, \"devm_request_irq failed\\n\");\n\t\tgoto out_phy_node;\n\t}\n\n\tret = of_get_ethdev_address(node, ndev);\n\tif (ret) {\n\t\teth_hw_addr_random(ndev);\n\t\tnetdev_warn(ndev, \"using random MAC address %pM\\n\",\n\t\t\t    ndev->dev_addr);\n\t}\n\n\tINIT_WORK(&priv->tx_timeout_task, hix5hd2_tx_timeout_task);\n\tndev->watchdog_timeo = 6 * HZ;\n\tndev->priv_flags |= IFF_UNICAST_FLT;\n\tndev->netdev_ops = &hix5hd2_netdev_ops;\n\tndev->ethtool_ops = &hix5hd2_ethtools_ops;\n\tSET_NETDEV_DEV(ndev, dev);\n\n\tif (HAS_CAP_TSO(priv->hw_cap))\n\t\tndev->hw_features |= NETIF_F_SG;\n\n\tndev->features |= ndev->hw_features | NETIF_F_HIGHDMA;\n\tndev->vlan_features |= ndev->features;\n\n\tret = hix5hd2_init_hw_desc_queue(priv);\n\tif (ret)\n\t\tgoto out_phy_node;\n\n\tnetif_napi_add(ndev, &priv->napi, hix5hd2_poll);\n\n\tif (HAS_CAP_TSO(priv->hw_cap)) {\n\t\tret = hix5hd2_init_sg_desc_queue(priv);\n\t\tif (ret)\n\t\t\tgoto out_destroy_queue;\n\t}\n\n\tret = register_netdev(priv->netdev);\n\tif (ret) {\n\t\tnetdev_err(ndev, \"register_netdev failed!\");\n\t\tgoto out_destroy_queue;\n\t}\n\n\tclk_disable_unprepare(priv->mac_ifc_clk);\n\tclk_disable_unprepare(priv->mac_core_clk);\n\n\treturn ret;\n\nout_destroy_queue:\n\tif (HAS_CAP_TSO(priv->hw_cap))\n\t\thix5hd2_destroy_sg_desc_queue(priv);\n\tnetif_napi_del(&priv->napi);\n\thix5hd2_destroy_hw_desc_queue(priv);\nout_phy_node:\n\tof_node_put(priv->phy_node);\nerr_mdiobus:\n\tmdiobus_unregister(bus);\nerr_free_mdio:\n\tmdiobus_free(bus);\nout_disable_clk:\n\tclk_disable_unprepare(priv->mac_ifc_clk);\nout_disable_mac_core_clk:\n\tclk_disable_unprepare(priv->mac_core_clk);\nout_free_netdev:\n\tfree_netdev(ndev);\n\n\treturn ret;\n}\n\nstatic int hix5hd2_dev_remove(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct hix5hd2_priv *priv = netdev_priv(ndev);\n\n\tnetif_napi_del(&priv->napi);\n\tunregister_netdev(ndev);\n\tmdiobus_unregister(priv->bus);\n\tmdiobus_free(priv->bus);\n\n\tif (HAS_CAP_TSO(priv->hw_cap))\n\t\thix5hd2_destroy_sg_desc_queue(priv);\n\thix5hd2_destroy_hw_desc_queue(priv);\n\tof_node_put(priv->phy_node);\n\tcancel_work_sync(&priv->tx_timeout_task);\n\tfree_netdev(ndev);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id hix5hd2_of_match[] = {\n\t{ .compatible = \"hisilicon,hisi-gmac-v1\", .data = (void *)GEMAC_V1 },\n\t{ .compatible = \"hisilicon,hisi-gmac-v2\", .data = (void *)GEMAC_V2 },\n\t{ .compatible = \"hisilicon,hix5hd2-gmac\", .data = (void *)GEMAC_V1 },\n\t{ .compatible = \"hisilicon,hi3798cv200-gmac\", .data = (void *)GEMAC_V2 },\n\t{ .compatible = \"hisilicon,hi3516a-gmac\", .data = (void *)GEMAC_V2 },\n\t{},\n};\n\nMODULE_DEVICE_TABLE(of, hix5hd2_of_match);\n\nstatic struct platform_driver hix5hd2_dev_driver = {\n\t.driver = {\n\t\t.name = \"hisi-gmac\",\n\t\t.of_match_table = hix5hd2_of_match,\n\t},\n\t.probe = hix5hd2_dev_probe,\n\t.remove = hix5hd2_dev_remove,\n};\n\nmodule_platform_driver(hix5hd2_dev_driver);\n\nMODULE_DESCRIPTION(\"HISILICON Gigabit Ethernet MAC driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS(\"platform:hisi-gmac\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}