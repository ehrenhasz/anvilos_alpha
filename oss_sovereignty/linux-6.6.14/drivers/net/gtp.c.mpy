{
  "module_name": "gtp.c",
  "hash_id": "adf1548b6512ff06c6089dbb7b2ff0f4a1c578b2202a0ffb17ca691433b9b0b3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/gtp.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/skbuff.h>\n#include <linux/udp.h>\n#include <linux/rculist.h>\n#include <linux/jhash.h>\n#include <linux/if_tunnel.h>\n#include <linux/net.h>\n#include <linux/file.h>\n#include <linux/gtp.h>\n\n#include <net/net_namespace.h>\n#include <net/protocol.h>\n#include <net/ip.h>\n#include <net/udp.h>\n#include <net/udp_tunnel.h>\n#include <net/icmp.h>\n#include <net/xfrm.h>\n#include <net/genetlink.h>\n#include <net/netns/generic.h>\n#include <net/gtp.h>\n\n \nstruct pdp_ctx {\n\tstruct hlist_node\thlist_tid;\n\tstruct hlist_node\thlist_addr;\n\n\tunion {\n\t\tstruct {\n\t\t\tu64\ttid;\n\t\t\tu16\tflow;\n\t\t} v0;\n\t\tstruct {\n\t\t\tu32\ti_tei;\n\t\t\tu32\to_tei;\n\t\t} v1;\n\t} u;\n\tu8\t\t\tgtp_version;\n\tu16\t\t\taf;\n\n\tstruct in_addr\t\tms_addr_ip4;\n\tstruct in_addr\t\tpeer_addr_ip4;\n\n\tstruct sock\t\t*sk;\n\tstruct net_device       *dev;\n\n\tatomic_t\t\ttx_seq;\n\tstruct rcu_head\t\trcu_head;\n};\n\n \nstruct gtp_dev {\n\tstruct list_head\tlist;\n\n\tstruct sock\t\t*sk0;\n\tstruct sock\t\t*sk1u;\n\tu8\t\t\tsk_created;\n\n\tstruct net_device\t*dev;\n\tstruct net\t\t*net;\n\n\tunsigned int\t\trole;\n\tunsigned int\t\thash_size;\n\tstruct hlist_head\t*tid_hash;\n\tstruct hlist_head\t*addr_hash;\n\n\tu8\t\t\trestart_count;\n};\n\nstruct echo_info {\n\tstruct in_addr\t\tms_addr_ip4;\n\tstruct in_addr\t\tpeer_addr_ip4;\n\tu8\t\t\tgtp_version;\n};\n\nstatic unsigned int gtp_net_id __read_mostly;\n\nstruct gtp_net {\n\tstruct list_head gtp_dev_list;\n};\n\nstatic u32 gtp_h_initval;\n\nstatic struct genl_family gtp_genl_family;\n\nenum gtp_multicast_groups {\n\tGTP_GENL_MCGRP,\n};\n\nstatic const struct genl_multicast_group gtp_genl_mcgrps[] = {\n\t[GTP_GENL_MCGRP] = { .name = GTP_GENL_MCGRP_NAME },\n};\n\nstatic void pdp_context_delete(struct pdp_ctx *pctx);\n\nstatic inline u32 gtp0_hashfn(u64 tid)\n{\n\tu32 *tid32 = (u32 *) &tid;\n\treturn jhash_2words(tid32[0], tid32[1], gtp_h_initval);\n}\n\nstatic inline u32 gtp1u_hashfn(u32 tid)\n{\n\treturn jhash_1word(tid, gtp_h_initval);\n}\n\nstatic inline u32 ipv4_hashfn(__be32 ip)\n{\n\treturn jhash_1word((__force u32)ip, gtp_h_initval);\n}\n\n \nstatic struct pdp_ctx *gtp0_pdp_find(struct gtp_dev *gtp, u64 tid)\n{\n\tstruct hlist_head *head;\n\tstruct pdp_ctx *pdp;\n\n\thead = &gtp->tid_hash[gtp0_hashfn(tid) % gtp->hash_size];\n\n\thlist_for_each_entry_rcu(pdp, head, hlist_tid) {\n\t\tif (pdp->gtp_version == GTP_V0 &&\n\t\t    pdp->u.v0.tid == tid)\n\t\t\treturn pdp;\n\t}\n\treturn NULL;\n}\n\n \nstatic struct pdp_ctx *gtp1_pdp_find(struct gtp_dev *gtp, u32 tid)\n{\n\tstruct hlist_head *head;\n\tstruct pdp_ctx *pdp;\n\n\thead = &gtp->tid_hash[gtp1u_hashfn(tid) % gtp->hash_size];\n\n\thlist_for_each_entry_rcu(pdp, head, hlist_tid) {\n\t\tif (pdp->gtp_version == GTP_V1 &&\n\t\t    pdp->u.v1.i_tei == tid)\n\t\t\treturn pdp;\n\t}\n\treturn NULL;\n}\n\n \nstatic struct pdp_ctx *ipv4_pdp_find(struct gtp_dev *gtp, __be32 ms_addr)\n{\n\tstruct hlist_head *head;\n\tstruct pdp_ctx *pdp;\n\n\thead = &gtp->addr_hash[ipv4_hashfn(ms_addr) % gtp->hash_size];\n\n\thlist_for_each_entry_rcu(pdp, head, hlist_addr) {\n\t\tif (pdp->af == AF_INET &&\n\t\t    pdp->ms_addr_ip4.s_addr == ms_addr)\n\t\t\treturn pdp;\n\t}\n\n\treturn NULL;\n}\n\nstatic bool gtp_check_ms_ipv4(struct sk_buff *skb, struct pdp_ctx *pctx,\n\t\t\t\t  unsigned int hdrlen, unsigned int role)\n{\n\tstruct iphdr *iph;\n\n\tif (!pskb_may_pull(skb, hdrlen + sizeof(struct iphdr)))\n\t\treturn false;\n\n\tiph = (struct iphdr *)(skb->data + hdrlen);\n\n\tif (role == GTP_ROLE_SGSN)\n\t\treturn iph->daddr == pctx->ms_addr_ip4.s_addr;\n\telse\n\t\treturn iph->saddr == pctx->ms_addr_ip4.s_addr;\n}\n\n \nstatic bool gtp_check_ms(struct sk_buff *skb, struct pdp_ctx *pctx,\n\t\t\t     unsigned int hdrlen, unsigned int role)\n{\n\tswitch (ntohs(skb->protocol)) {\n\tcase ETH_P_IP:\n\t\treturn gtp_check_ms_ipv4(skb, pctx, hdrlen, role);\n\t}\n\treturn false;\n}\n\nstatic int gtp_rx(struct pdp_ctx *pctx, struct sk_buff *skb,\n\t\t\tunsigned int hdrlen, unsigned int role)\n{\n\tif (!gtp_check_ms(skb, pctx, hdrlen, role)) {\n\t\tnetdev_dbg(pctx->dev, \"No PDP ctx for this MS\\n\");\n\t\treturn 1;\n\t}\n\n\t \n\tif (iptunnel_pull_header(skb, hdrlen, skb->protocol,\n\t\t\t !net_eq(sock_net(pctx->sk), dev_net(pctx->dev)))) {\n\t\tpctx->dev->stats.rx_length_errors++;\n\t\tgoto err;\n\t}\n\n\tnetdev_dbg(pctx->dev, \"forwarding packet from GGSN to uplink\\n\");\n\n\t \n\tskb_reset_network_header(skb);\n\tskb_reset_mac_header(skb);\n\n\tskb->dev = pctx->dev;\n\n\tdev_sw_netstats_rx_add(pctx->dev, skb->len);\n\n\t__netif_rx(skb);\n\treturn 0;\n\nerr:\n\tpctx->dev->stats.rx_dropped++;\n\treturn -1;\n}\n\nstatic struct rtable *ip4_route_output_gtp(struct flowi4 *fl4,\n\t\t\t\t\t   const struct sock *sk,\n\t\t\t\t\t   __be32 daddr, __be32 saddr)\n{\n\tmemset(fl4, 0, sizeof(*fl4));\n\tfl4->flowi4_oif\t\t= sk->sk_bound_dev_if;\n\tfl4->daddr\t\t= daddr;\n\tfl4->saddr\t\t= saddr;\n\tfl4->flowi4_tos\t\t= ip_sock_rt_tos(sk);\n\tfl4->flowi4_scope\t= ip_sock_rt_scope(sk);\n\tfl4->flowi4_proto\t= sk->sk_protocol;\n\n\treturn ip_route_output_key(sock_net(sk), fl4);\n}\n\n \nstatic bool gtp0_validate_echo_hdr(struct gtp0_header *gtp0)\n{\n\treturn !(gtp0->tid || (gtp0->flags ^ 0x1e) ||\n\t\tgtp0->number != 0xff || gtp0->flow);\n}\n\n \nstatic void gtp0_build_echo_msg(struct gtp0_header *hdr, __u8 msg_type)\n{\n\tint len_pkt, len_hdr;\n\n\thdr->flags = 0x1e;  \n\thdr->type = msg_type;\n\t \n\thdr->flow = 0;\n\thdr->tid = 0;\n\thdr->number = 0xff;\n\thdr->spare[0] = 0xff;\n\thdr->spare[1] = 0xff;\n\thdr->spare[2] = 0xff;\n\n\tlen_pkt = sizeof(struct gtp0_packet);\n\tlen_hdr = sizeof(struct gtp0_header);\n\n\tif (msg_type == GTP_ECHO_RSP)\n\t\thdr->length = htons(len_pkt - len_hdr);\n\telse\n\t\thdr->length = 0;\n}\n\nstatic int gtp0_send_echo_resp(struct gtp_dev *gtp, struct sk_buff *skb)\n{\n\tstruct gtp0_packet *gtp_pkt;\n\tstruct gtp0_header *gtp0;\n\tstruct rtable *rt;\n\tstruct flowi4 fl4;\n\tstruct iphdr *iph;\n\t__be16 seq;\n\n\tgtp0 = (struct gtp0_header *)(skb->data + sizeof(struct udphdr));\n\n\tif (!gtp0_validate_echo_hdr(gtp0))\n\t\treturn -1;\n\n\tseq = gtp0->seq;\n\n\t \n\tskb_pull_data(skb, sizeof(struct gtp0_header) + sizeof(struct udphdr));\n\n\tgtp_pkt = skb_push(skb, sizeof(struct gtp0_packet));\n\tmemset(gtp_pkt, 0, sizeof(struct gtp0_packet));\n\n\tgtp0_build_echo_msg(&gtp_pkt->gtp0_h, GTP_ECHO_RSP);\n\n\t \n\tgtp_pkt->gtp0_h.seq = seq;\n\n\tgtp_pkt->ie.tag = GTPIE_RECOVERY;\n\tgtp_pkt->ie.val = gtp->restart_count;\n\n\tiph = ip_hdr(skb);\n\n\t \n\trt = ip4_route_output_gtp(&fl4, gtp->sk0, iph->saddr, iph->daddr);\n\tif (IS_ERR(rt)) {\n\t\tnetdev_dbg(gtp->dev, \"no route for echo response from %pI4\\n\",\n\t\t\t   &iph->saddr);\n\t\treturn -1;\n\t}\n\n\tudp_tunnel_xmit_skb(rt, gtp->sk0, skb,\n\t\t\t    fl4.saddr, fl4.daddr,\n\t\t\t    iph->tos,\n\t\t\t    ip4_dst_hoplimit(&rt->dst),\n\t\t\t    0,\n\t\t\t    htons(GTP0_PORT), htons(GTP0_PORT),\n\t\t\t    !net_eq(sock_net(gtp->sk1u),\n\t\t\t\t    dev_net(gtp->dev)),\n\t\t\t    false);\n\treturn 0;\n}\n\nstatic int gtp_genl_fill_echo(struct sk_buff *skb, u32 snd_portid, u32 snd_seq,\n\t\t\t      int flags, u32 type, struct echo_info echo)\n{\n\tvoid *genlh;\n\n\tgenlh = genlmsg_put(skb, snd_portid, snd_seq, &gtp_genl_family, flags,\n\t\t\t    type);\n\tif (!genlh)\n\t\tgoto failure;\n\n\tif (nla_put_u32(skb, GTPA_VERSION, echo.gtp_version) ||\n\t    nla_put_be32(skb, GTPA_PEER_ADDRESS, echo.peer_addr_ip4.s_addr) ||\n\t    nla_put_be32(skb, GTPA_MS_ADDRESS, echo.ms_addr_ip4.s_addr))\n\t\tgoto failure;\n\n\tgenlmsg_end(skb, genlh);\n\treturn 0;\n\nfailure:\n\tgenlmsg_cancel(skb, genlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int gtp0_handle_echo_resp(struct gtp_dev *gtp, struct sk_buff *skb)\n{\n\tstruct gtp0_header *gtp0;\n\tstruct echo_info echo;\n\tstruct sk_buff *msg;\n\tstruct iphdr *iph;\n\tint ret;\n\n\tgtp0 = (struct gtp0_header *)(skb->data + sizeof(struct udphdr));\n\n\tif (!gtp0_validate_echo_hdr(gtp0))\n\t\treturn -1;\n\n\tiph = ip_hdr(skb);\n\techo.ms_addr_ip4.s_addr = iph->daddr;\n\techo.peer_addr_ip4.s_addr = iph->saddr;\n\techo.gtp_version = GTP_V0;\n\n\tmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_ATOMIC);\n\tif (!msg)\n\t\treturn -ENOMEM;\n\n\tret = gtp_genl_fill_echo(msg, 0, 0, 0, GTP_CMD_ECHOREQ, echo);\n\tif (ret < 0) {\n\t\tnlmsg_free(msg);\n\t\treturn ret;\n\t}\n\n\treturn genlmsg_multicast_netns(&gtp_genl_family, dev_net(gtp->dev),\n\t\t\t\t       msg, 0, GTP_GENL_MCGRP, GFP_ATOMIC);\n}\n\n \nstatic int gtp0_udp_encap_recv(struct gtp_dev *gtp, struct sk_buff *skb)\n{\n\tunsigned int hdrlen = sizeof(struct udphdr) +\n\t\t\t      sizeof(struct gtp0_header);\n\tstruct gtp0_header *gtp0;\n\tstruct pdp_ctx *pctx;\n\n\tif (!pskb_may_pull(skb, hdrlen))\n\t\treturn -1;\n\n\tgtp0 = (struct gtp0_header *)(skb->data + sizeof(struct udphdr));\n\n\tif ((gtp0->flags >> 5) != GTP_V0)\n\t\treturn 1;\n\n\t \n\tif (gtp0->type == GTP_ECHO_REQ && gtp->sk_created)\n\t\treturn gtp0_send_echo_resp(gtp, skb);\n\n\tif (gtp0->type == GTP_ECHO_RSP && gtp->sk_created)\n\t\treturn gtp0_handle_echo_resp(gtp, skb);\n\n\tif (gtp0->type != GTP_TPDU)\n\t\treturn 1;\n\n\tpctx = gtp0_pdp_find(gtp, be64_to_cpu(gtp0->tid));\n\tif (!pctx) {\n\t\tnetdev_dbg(gtp->dev, \"No PDP ctx to decap skb=%p\\n\", skb);\n\t\treturn 1;\n\t}\n\n\treturn gtp_rx(pctx, skb, hdrlen, gtp->role);\n}\n\n \nstatic void gtp1u_build_echo_msg(struct gtp1_header_long *hdr, __u8 msg_type)\n{\n\tint len_pkt, len_hdr;\n\n\t \n\thdr->flags = 0x32;  \n\thdr->type = msg_type;\n\t \n\thdr->tid = 0;\n\n\t \n\n\tlen_hdr = sizeof(struct gtp1_header);\n\n\tif (msg_type == GTP_ECHO_RSP) {\n\t\tlen_pkt = sizeof(struct gtp1u_packet);\n\t\thdr->length = htons(len_pkt - len_hdr);\n\t} else {\n\t\t \n\t\tlen_pkt = sizeof(struct gtp1_header_long);\n\t\thdr->length = htons(len_pkt - len_hdr);\n\t}\n}\n\nstatic int gtp1u_send_echo_resp(struct gtp_dev *gtp, struct sk_buff *skb)\n{\n\tstruct gtp1_header_long *gtp1u;\n\tstruct gtp1u_packet *gtp_pkt;\n\tstruct rtable *rt;\n\tstruct flowi4 fl4;\n\tstruct iphdr *iph;\n\n\tgtp1u = (struct gtp1_header_long *)(skb->data + sizeof(struct udphdr));\n\n\t \n\tif (!(gtp1u->flags & GTP1_F_SEQ) || gtp1u->tid)\n\t\treturn -1;\n\n\t \n\tskb_pull_data(skb,\n\t\t      sizeof(struct gtp1_header_long) + sizeof(struct udphdr));\n\n\tgtp_pkt = skb_push(skb, sizeof(struct gtp1u_packet));\n\tmemset(gtp_pkt, 0, sizeof(struct gtp1u_packet));\n\n\tgtp1u_build_echo_msg(&gtp_pkt->gtp1u_h, GTP_ECHO_RSP);\n\n\t \n\tgtp_pkt->ie.tag = GTPIE_RECOVERY;\n\tgtp_pkt->ie.val = 0;\n\n\tiph = ip_hdr(skb);\n\n\t \n\trt = ip4_route_output_gtp(&fl4, gtp->sk1u, iph->saddr, iph->daddr);\n\tif (IS_ERR(rt)) {\n\t\tnetdev_dbg(gtp->dev, \"no route for echo response from %pI4\\n\",\n\t\t\t   &iph->saddr);\n\t\treturn -1;\n\t}\n\n\tudp_tunnel_xmit_skb(rt, gtp->sk1u, skb,\n\t\t\t    fl4.saddr, fl4.daddr,\n\t\t\t    iph->tos,\n\t\t\t    ip4_dst_hoplimit(&rt->dst),\n\t\t\t    0,\n\t\t\t    htons(GTP1U_PORT), htons(GTP1U_PORT),\n\t\t\t    !net_eq(sock_net(gtp->sk1u),\n\t\t\t\t    dev_net(gtp->dev)),\n\t\t\t    false);\n\treturn 0;\n}\n\nstatic int gtp1u_handle_echo_resp(struct gtp_dev *gtp, struct sk_buff *skb)\n{\n\tstruct gtp1_header_long *gtp1u;\n\tstruct echo_info echo;\n\tstruct sk_buff *msg;\n\tstruct iphdr *iph;\n\tint ret;\n\n\tgtp1u = (struct gtp1_header_long *)(skb->data + sizeof(struct udphdr));\n\n\t \n\tif (!(gtp1u->flags & GTP1_F_SEQ) || gtp1u->tid)\n\t\treturn -1;\n\n\tiph = ip_hdr(skb);\n\techo.ms_addr_ip4.s_addr = iph->daddr;\n\techo.peer_addr_ip4.s_addr = iph->saddr;\n\techo.gtp_version = GTP_V1;\n\n\tmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_ATOMIC);\n\tif (!msg)\n\t\treturn -ENOMEM;\n\n\tret = gtp_genl_fill_echo(msg, 0, 0, 0, GTP_CMD_ECHOREQ, echo);\n\tif (ret < 0) {\n\t\tnlmsg_free(msg);\n\t\treturn ret;\n\t}\n\n\treturn genlmsg_multicast_netns(&gtp_genl_family, dev_net(gtp->dev),\n\t\t\t\t       msg, 0, GTP_GENL_MCGRP, GFP_ATOMIC);\n}\n\nstatic int gtp1u_udp_encap_recv(struct gtp_dev *gtp, struct sk_buff *skb)\n{\n\tunsigned int hdrlen = sizeof(struct udphdr) +\n\t\t\t      sizeof(struct gtp1_header);\n\tstruct gtp1_header *gtp1;\n\tstruct pdp_ctx *pctx;\n\n\tif (!pskb_may_pull(skb, hdrlen))\n\t\treturn -1;\n\n\tgtp1 = (struct gtp1_header *)(skb->data + sizeof(struct udphdr));\n\n\tif ((gtp1->flags >> 5) != GTP_V1)\n\t\treturn 1;\n\n\t \n\tif (gtp1->type == GTP_ECHO_REQ && gtp->sk_created)\n\t\treturn gtp1u_send_echo_resp(gtp, skb);\n\n\tif (gtp1->type == GTP_ECHO_RSP && gtp->sk_created)\n\t\treturn gtp1u_handle_echo_resp(gtp, skb);\n\n\tif (gtp1->type != GTP_TPDU)\n\t\treturn 1;\n\n\t \n\tif (gtp1->flags & GTP1_F_MASK)\n\t\thdrlen += 4;\n\n\t \n\tif (!pskb_may_pull(skb, hdrlen))\n\t\treturn -1;\n\n\tgtp1 = (struct gtp1_header *)(skb->data + sizeof(struct udphdr));\n\n\tpctx = gtp1_pdp_find(gtp, ntohl(gtp1->tid));\n\tif (!pctx) {\n\t\tnetdev_dbg(gtp->dev, \"No PDP ctx to decap skb=%p\\n\", skb);\n\t\treturn 1;\n\t}\n\n\treturn gtp_rx(pctx, skb, hdrlen, gtp->role);\n}\n\nstatic void __gtp_encap_destroy(struct sock *sk)\n{\n\tstruct gtp_dev *gtp;\n\n\tlock_sock(sk);\n\tgtp = sk->sk_user_data;\n\tif (gtp) {\n\t\tif (gtp->sk0 == sk)\n\t\t\tgtp->sk0 = NULL;\n\t\telse\n\t\t\tgtp->sk1u = NULL;\n\t\tWRITE_ONCE(udp_sk(sk)->encap_type, 0);\n\t\trcu_assign_sk_user_data(sk, NULL);\n\t\trelease_sock(sk);\n\t\tsock_put(sk);\n\t\treturn;\n\t}\n\trelease_sock(sk);\n}\n\nstatic void gtp_encap_destroy(struct sock *sk)\n{\n\trtnl_lock();\n\t__gtp_encap_destroy(sk);\n\trtnl_unlock();\n}\n\nstatic void gtp_encap_disable_sock(struct sock *sk)\n{\n\tif (!sk)\n\t\treturn;\n\n\t__gtp_encap_destroy(sk);\n}\n\nstatic void gtp_encap_disable(struct gtp_dev *gtp)\n{\n\tif (gtp->sk_created) {\n\t\tudp_tunnel_sock_release(gtp->sk0->sk_socket);\n\t\tudp_tunnel_sock_release(gtp->sk1u->sk_socket);\n\t\tgtp->sk_created = false;\n\t\tgtp->sk0 = NULL;\n\t\tgtp->sk1u = NULL;\n\t} else {\n\t\tgtp_encap_disable_sock(gtp->sk0);\n\t\tgtp_encap_disable_sock(gtp->sk1u);\n\t}\n}\n\n \nstatic int gtp_encap_recv(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct gtp_dev *gtp;\n\tint ret = 0;\n\n\tgtp = rcu_dereference_sk_user_data(sk);\n\tif (!gtp)\n\t\treturn 1;\n\n\tnetdev_dbg(gtp->dev, \"encap_recv sk=%p\\n\", sk);\n\n\tswitch (READ_ONCE(udp_sk(sk)->encap_type)) {\n\tcase UDP_ENCAP_GTP0:\n\t\tnetdev_dbg(gtp->dev, \"received GTP0 packet\\n\");\n\t\tret = gtp0_udp_encap_recv(gtp, skb);\n\t\tbreak;\n\tcase UDP_ENCAP_GTP1U:\n\t\tnetdev_dbg(gtp->dev, \"received GTP1U packet\\n\");\n\t\tret = gtp1u_udp_encap_recv(gtp, skb);\n\t\tbreak;\n\tdefault:\n\t\tret = -1;  \n\t}\n\n\tswitch (ret) {\n\tcase 1:\n\t\tnetdev_dbg(gtp->dev, \"pass up to the process\\n\");\n\t\tbreak;\n\tcase 0:\n\t\tbreak;\n\tcase -1:\n\t\tnetdev_dbg(gtp->dev, \"GTP packet has been dropped\\n\");\n\t\tkfree_skb(skb);\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int gtp_dev_init(struct net_device *dev)\n{\n\tstruct gtp_dev *gtp = netdev_priv(dev);\n\n\tgtp->dev = dev;\n\n\tdev->tstats = netdev_alloc_pcpu_stats(struct pcpu_sw_netstats);\n\tif (!dev->tstats)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void gtp_dev_uninit(struct net_device *dev)\n{\n\tstruct gtp_dev *gtp = netdev_priv(dev);\n\n\tgtp_encap_disable(gtp);\n\tfree_percpu(dev->tstats);\n}\n\nstatic inline void gtp0_push_header(struct sk_buff *skb, struct pdp_ctx *pctx)\n{\n\tint payload_len = skb->len;\n\tstruct gtp0_header *gtp0;\n\n\tgtp0 = skb_push(skb, sizeof(*gtp0));\n\n\tgtp0->flags\t= 0x1e;  \n\tgtp0->type\t= GTP_TPDU;\n\tgtp0->length\t= htons(payload_len);\n\tgtp0->seq\t= htons((atomic_inc_return(&pctx->tx_seq) - 1) % 0xffff);\n\tgtp0->flow\t= htons(pctx->u.v0.flow);\n\tgtp0->number\t= 0xff;\n\tgtp0->spare[0]\t= gtp0->spare[1] = gtp0->spare[2] = 0xff;\n\tgtp0->tid\t= cpu_to_be64(pctx->u.v0.tid);\n}\n\nstatic inline void gtp1_push_header(struct sk_buff *skb, struct pdp_ctx *pctx)\n{\n\tint payload_len = skb->len;\n\tstruct gtp1_header *gtp1;\n\n\tgtp1 = skb_push(skb, sizeof(*gtp1));\n\n\t \n\tgtp1->flags\t= 0x30;  \n\tgtp1->type\t= GTP_TPDU;\n\tgtp1->length\t= htons(payload_len);\n\tgtp1->tid\t= htonl(pctx->u.v1.o_tei);\n\n\t \n}\n\nstruct gtp_pktinfo {\n\tstruct sock\t\t*sk;\n\tstruct iphdr\t\t*iph;\n\tstruct flowi4\t\tfl4;\n\tstruct rtable\t\t*rt;\n\tstruct pdp_ctx\t\t*pctx;\n\tstruct net_device\t*dev;\n\t__be16\t\t\tgtph_port;\n};\n\nstatic void gtp_push_header(struct sk_buff *skb, struct gtp_pktinfo *pktinfo)\n{\n\tswitch (pktinfo->pctx->gtp_version) {\n\tcase GTP_V0:\n\t\tpktinfo->gtph_port = htons(GTP0_PORT);\n\t\tgtp0_push_header(skb, pktinfo->pctx);\n\t\tbreak;\n\tcase GTP_V1:\n\t\tpktinfo->gtph_port = htons(GTP1U_PORT);\n\t\tgtp1_push_header(skb, pktinfo->pctx);\n\t\tbreak;\n\t}\n}\n\nstatic inline void gtp_set_pktinfo_ipv4(struct gtp_pktinfo *pktinfo,\n\t\t\t\t\tstruct sock *sk, struct iphdr *iph,\n\t\t\t\t\tstruct pdp_ctx *pctx, struct rtable *rt,\n\t\t\t\t\tstruct flowi4 *fl4,\n\t\t\t\t\tstruct net_device *dev)\n{\n\tpktinfo->sk\t= sk;\n\tpktinfo->iph\t= iph;\n\tpktinfo->pctx\t= pctx;\n\tpktinfo->rt\t= rt;\n\tpktinfo->fl4\t= *fl4;\n\tpktinfo->dev\t= dev;\n}\n\nstatic int gtp_build_skb_ip4(struct sk_buff *skb, struct net_device *dev,\n\t\t\t     struct gtp_pktinfo *pktinfo)\n{\n\tstruct gtp_dev *gtp = netdev_priv(dev);\n\tstruct pdp_ctx *pctx;\n\tstruct rtable *rt;\n\tstruct flowi4 fl4;\n\tstruct iphdr *iph;\n\t__be16 df;\n\tint mtu;\n\n\t \n\tiph = ip_hdr(skb);\n\tif (gtp->role == GTP_ROLE_SGSN)\n\t\tpctx = ipv4_pdp_find(gtp, iph->saddr);\n\telse\n\t\tpctx = ipv4_pdp_find(gtp, iph->daddr);\n\n\tif (!pctx) {\n\t\tnetdev_dbg(dev, \"no PDP ctx found for %pI4, skip\\n\",\n\t\t\t   &iph->daddr);\n\t\treturn -ENOENT;\n\t}\n\tnetdev_dbg(dev, \"found PDP context %p\\n\", pctx);\n\n\trt = ip4_route_output_gtp(&fl4, pctx->sk, pctx->peer_addr_ip4.s_addr,\n\t\t\t\t  inet_sk(pctx->sk)->inet_saddr);\n\tif (IS_ERR(rt)) {\n\t\tnetdev_dbg(dev, \"no route to SSGN %pI4\\n\",\n\t\t\t   &pctx->peer_addr_ip4.s_addr);\n\t\tdev->stats.tx_carrier_errors++;\n\t\tgoto err;\n\t}\n\n\tif (rt->dst.dev == dev) {\n\t\tnetdev_dbg(dev, \"circular route to SSGN %pI4\\n\",\n\t\t\t   &pctx->peer_addr_ip4.s_addr);\n\t\tdev->stats.collisions++;\n\t\tgoto err_rt;\n\t}\n\n\t \n\tdf = iph->frag_off;\n\tif (df) {\n\t\tmtu = dst_mtu(&rt->dst) - dev->hard_header_len -\n\t\t\tsizeof(struct iphdr) - sizeof(struct udphdr);\n\t\tswitch (pctx->gtp_version) {\n\t\tcase GTP_V0:\n\t\t\tmtu -= sizeof(struct gtp0_header);\n\t\t\tbreak;\n\t\tcase GTP_V1:\n\t\t\tmtu -= sizeof(struct gtp1_header);\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tmtu = dst_mtu(&rt->dst);\n\t}\n\n\tskb_dst_update_pmtu_no_confirm(skb, mtu);\n\n\tif (iph->frag_off & htons(IP_DF) &&\n\t    ((!skb_is_gso(skb) && skb->len > mtu) ||\n\t     (skb_is_gso(skb) && !skb_gso_validate_network_len(skb, mtu)))) {\n\t\tnetdev_dbg(dev, \"packet too big, fragmentation needed\\n\");\n\t\ticmp_ndo_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,\n\t\t\t      htonl(mtu));\n\t\tgoto err_rt;\n\t}\n\n\tgtp_set_pktinfo_ipv4(pktinfo, pctx->sk, iph, pctx, rt, &fl4, dev);\n\tgtp_push_header(skb, pktinfo);\n\n\treturn 0;\nerr_rt:\n\tip_rt_put(rt);\nerr:\n\treturn -EBADMSG;\n}\n\nstatic netdev_tx_t gtp_dev_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tunsigned int proto = ntohs(skb->protocol);\n\tstruct gtp_pktinfo pktinfo;\n\tint err;\n\n\t \n\tif (skb_cow_head(skb, dev->needed_headroom))\n\t\tgoto tx_err;\n\n\tskb_reset_inner_headers(skb);\n\n\t \n\trcu_read_lock();\n\tswitch (proto) {\n\tcase ETH_P_IP:\n\t\terr = gtp_build_skb_ip4(skb, dev, &pktinfo);\n\t\tbreak;\n\tdefault:\n\t\terr = -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\tif (err < 0)\n\t\tgoto tx_err;\n\n\tswitch (proto) {\n\tcase ETH_P_IP:\n\t\tnetdev_dbg(pktinfo.dev, \"gtp -> IP src: %pI4 dst: %pI4\\n\",\n\t\t\t   &pktinfo.iph->saddr, &pktinfo.iph->daddr);\n\t\tudp_tunnel_xmit_skb(pktinfo.rt, pktinfo.sk, skb,\n\t\t\t\t    pktinfo.fl4.saddr, pktinfo.fl4.daddr,\n\t\t\t\t    pktinfo.iph->tos,\n\t\t\t\t    ip4_dst_hoplimit(&pktinfo.rt->dst),\n\t\t\t\t    0,\n\t\t\t\t    pktinfo.gtph_port, pktinfo.gtph_port,\n\t\t\t\t    !net_eq(sock_net(pktinfo.pctx->sk),\n\t\t\t\t\t    dev_net(dev)),\n\t\t\t\t    false);\n\t\tbreak;\n\t}\n\n\treturn NETDEV_TX_OK;\ntx_err:\n\tdev->stats.tx_errors++;\n\tdev_kfree_skb(skb);\n\treturn NETDEV_TX_OK;\n}\n\nstatic const struct net_device_ops gtp_netdev_ops = {\n\t.ndo_init\t\t= gtp_dev_init,\n\t.ndo_uninit\t\t= gtp_dev_uninit,\n\t.ndo_start_xmit\t\t= gtp_dev_xmit,\n\t.ndo_get_stats64\t= dev_get_tstats64,\n};\n\nstatic const struct device_type gtp_type = {\n\t.name = \"gtp\",\n};\n\nstatic void gtp_link_setup(struct net_device *dev)\n{\n\tunsigned int max_gtp_header_len = sizeof(struct iphdr) +\n\t\t\t\t\t  sizeof(struct udphdr) +\n\t\t\t\t\t  sizeof(struct gtp0_header);\n\n\tdev->netdev_ops\t\t= &gtp_netdev_ops;\n\tdev->needs_free_netdev\t= true;\n\tSET_NETDEV_DEVTYPE(dev, &gtp_type);\n\n\tdev->hard_header_len = 0;\n\tdev->addr_len = 0;\n\tdev->mtu = ETH_DATA_LEN - max_gtp_header_len;\n\n\t \n\tdev->type = ARPHRD_NONE;\n\tdev->flags = IFF_POINTOPOINT | IFF_NOARP | IFF_MULTICAST;\n\n\tdev->priv_flags\t|= IFF_NO_QUEUE;\n\tdev->features\t|= NETIF_F_LLTX;\n\tnetif_keep_dst(dev);\n\n\tdev->needed_headroom\t= LL_MAX_HEADER + max_gtp_header_len;\n}\n\nstatic int gtp_hashtable_new(struct gtp_dev *gtp, int hsize);\nstatic int gtp_encap_enable(struct gtp_dev *gtp, struct nlattr *data[]);\n\nstatic void gtp_destructor(struct net_device *dev)\n{\n\tstruct gtp_dev *gtp = netdev_priv(dev);\n\n\tkfree(gtp->addr_hash);\n\tkfree(gtp->tid_hash);\n}\n\nstatic struct sock *gtp_create_sock(int type, struct gtp_dev *gtp)\n{\n\tstruct udp_tunnel_sock_cfg tuncfg = {};\n\tstruct udp_port_cfg udp_conf = {\n\t\t.local_ip.s_addr\t= htonl(INADDR_ANY),\n\t\t.family\t\t\t= AF_INET,\n\t};\n\tstruct net *net = gtp->net;\n\tstruct socket *sock;\n\tint err;\n\n\tif (type == UDP_ENCAP_GTP0)\n\t\tudp_conf.local_udp_port = htons(GTP0_PORT);\n\telse if (type == UDP_ENCAP_GTP1U)\n\t\tudp_conf.local_udp_port = htons(GTP1U_PORT);\n\telse\n\t\treturn ERR_PTR(-EINVAL);\n\n\terr = udp_sock_create(net, &udp_conf, &sock);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\ttuncfg.sk_user_data = gtp;\n\ttuncfg.encap_type = type;\n\ttuncfg.encap_rcv = gtp_encap_recv;\n\ttuncfg.encap_destroy = NULL;\n\n\tsetup_udp_tunnel_sock(net, sock, &tuncfg);\n\n\treturn sock->sk;\n}\n\nstatic int gtp_create_sockets(struct gtp_dev *gtp, struct nlattr *data[])\n{\n\tstruct sock *sk1u = NULL;\n\tstruct sock *sk0 = NULL;\n\n\tsk0 = gtp_create_sock(UDP_ENCAP_GTP0, gtp);\n\tif (IS_ERR(sk0))\n\t\treturn PTR_ERR(sk0);\n\n\tsk1u = gtp_create_sock(UDP_ENCAP_GTP1U, gtp);\n\tif (IS_ERR(sk1u)) {\n\t\tudp_tunnel_sock_release(sk0->sk_socket);\n\t\treturn PTR_ERR(sk1u);\n\t}\n\n\tgtp->sk_created = true;\n\tgtp->sk0 = sk0;\n\tgtp->sk1u = sk1u;\n\n\treturn 0;\n}\n\nstatic int gtp_newlink(struct net *src_net, struct net_device *dev,\n\t\t       struct nlattr *tb[], struct nlattr *data[],\n\t\t       struct netlink_ext_ack *extack)\n{\n\tunsigned int role = GTP_ROLE_GGSN;\n\tstruct gtp_dev *gtp;\n\tstruct gtp_net *gn;\n\tint hashsize, err;\n\n\tgtp = netdev_priv(dev);\n\n\tif (!data[IFLA_GTP_PDP_HASHSIZE]) {\n\t\thashsize = 1024;\n\t} else {\n\t\thashsize = nla_get_u32(data[IFLA_GTP_PDP_HASHSIZE]);\n\t\tif (!hashsize)\n\t\t\thashsize = 1024;\n\t}\n\n\tif (data[IFLA_GTP_ROLE]) {\n\t\trole = nla_get_u32(data[IFLA_GTP_ROLE]);\n\t\tif (role > GTP_ROLE_SGSN)\n\t\t\treturn -EINVAL;\n\t}\n\tgtp->role = role;\n\n\tif (!data[IFLA_GTP_RESTART_COUNT])\n\t\tgtp->restart_count = 0;\n\telse\n\t\tgtp->restart_count = nla_get_u8(data[IFLA_GTP_RESTART_COUNT]);\n\n\tgtp->net = src_net;\n\n\terr = gtp_hashtable_new(gtp, hashsize);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (data[IFLA_GTP_CREATE_SOCKETS])\n\t\terr = gtp_create_sockets(gtp, data);\n\telse\n\t\terr = gtp_encap_enable(gtp, data);\n\tif (err < 0)\n\t\tgoto out_hashtable;\n\n\terr = register_netdevice(dev);\n\tif (err < 0) {\n\t\tnetdev_dbg(dev, \"failed to register new netdev %d\\n\", err);\n\t\tgoto out_encap;\n\t}\n\n\tgn = net_generic(dev_net(dev), gtp_net_id);\n\tlist_add_rcu(&gtp->list, &gn->gtp_dev_list);\n\tdev->priv_destructor = gtp_destructor;\n\n\tnetdev_dbg(dev, \"registered new GTP interface\\n\");\n\n\treturn 0;\n\nout_encap:\n\tgtp_encap_disable(gtp);\nout_hashtable:\n\tkfree(gtp->addr_hash);\n\tkfree(gtp->tid_hash);\n\treturn err;\n}\n\nstatic void gtp_dellink(struct net_device *dev, struct list_head *head)\n{\n\tstruct gtp_dev *gtp = netdev_priv(dev);\n\tstruct pdp_ctx *pctx;\n\tint i;\n\n\tfor (i = 0; i < gtp->hash_size; i++)\n\t\thlist_for_each_entry_rcu(pctx, &gtp->tid_hash[i], hlist_tid)\n\t\t\tpdp_context_delete(pctx);\n\n\tlist_del_rcu(&gtp->list);\n\tunregister_netdevice_queue(dev, head);\n}\n\nstatic const struct nla_policy gtp_policy[IFLA_GTP_MAX + 1] = {\n\t[IFLA_GTP_FD0]\t\t\t= { .type = NLA_U32 },\n\t[IFLA_GTP_FD1]\t\t\t= { .type = NLA_U32 },\n\t[IFLA_GTP_PDP_HASHSIZE]\t\t= { .type = NLA_U32 },\n\t[IFLA_GTP_ROLE]\t\t\t= { .type = NLA_U32 },\n\t[IFLA_GTP_CREATE_SOCKETS]\t= { .type = NLA_U8 },\n\t[IFLA_GTP_RESTART_COUNT]\t= { .type = NLA_U8 },\n};\n\nstatic int gtp_validate(struct nlattr *tb[], struct nlattr *data[],\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tif (!data)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic size_t gtp_get_size(const struct net_device *dev)\n{\n\treturn nla_total_size(sizeof(__u32)) +  \n\t\tnla_total_size(sizeof(__u32)) +  \n\t\tnla_total_size(sizeof(__u8));  \n}\n\nstatic int gtp_fill_info(struct sk_buff *skb, const struct net_device *dev)\n{\n\tstruct gtp_dev *gtp = netdev_priv(dev);\n\n\tif (nla_put_u32(skb, IFLA_GTP_PDP_HASHSIZE, gtp->hash_size))\n\t\tgoto nla_put_failure;\n\tif (nla_put_u32(skb, IFLA_GTP_ROLE, gtp->role))\n\t\tgoto nla_put_failure;\n\tif (nla_put_u8(skb, IFLA_GTP_RESTART_COUNT, gtp->restart_count))\n\t\tgoto nla_put_failure;\n\n\treturn 0;\n\nnla_put_failure:\n\treturn -EMSGSIZE;\n}\n\nstatic struct rtnl_link_ops gtp_link_ops __read_mostly = {\n\t.kind\t\t= \"gtp\",\n\t.maxtype\t= IFLA_GTP_MAX,\n\t.policy\t\t= gtp_policy,\n\t.priv_size\t= sizeof(struct gtp_dev),\n\t.setup\t\t= gtp_link_setup,\n\t.validate\t= gtp_validate,\n\t.newlink\t= gtp_newlink,\n\t.dellink\t= gtp_dellink,\n\t.get_size\t= gtp_get_size,\n\t.fill_info\t= gtp_fill_info,\n};\n\nstatic int gtp_hashtable_new(struct gtp_dev *gtp, int hsize)\n{\n\tint i;\n\n\tgtp->addr_hash = kmalloc_array(hsize, sizeof(struct hlist_head),\n\t\t\t\t       GFP_KERNEL | __GFP_NOWARN);\n\tif (gtp->addr_hash == NULL)\n\t\treturn -ENOMEM;\n\n\tgtp->tid_hash = kmalloc_array(hsize, sizeof(struct hlist_head),\n\t\t\t\t      GFP_KERNEL | __GFP_NOWARN);\n\tif (gtp->tid_hash == NULL)\n\t\tgoto err1;\n\n\tgtp->hash_size = hsize;\n\n\tfor (i = 0; i < hsize; i++) {\n\t\tINIT_HLIST_HEAD(&gtp->addr_hash[i]);\n\t\tINIT_HLIST_HEAD(&gtp->tid_hash[i]);\n\t}\n\treturn 0;\nerr1:\n\tkfree(gtp->addr_hash);\n\treturn -ENOMEM;\n}\n\nstatic struct sock *gtp_encap_enable_socket(int fd, int type,\n\t\t\t\t\t    struct gtp_dev *gtp)\n{\n\tstruct udp_tunnel_sock_cfg tuncfg = {NULL};\n\tstruct socket *sock;\n\tstruct sock *sk;\n\tint err;\n\n\tpr_debug(\"enable gtp on %d, %d\\n\", fd, type);\n\n\tsock = sockfd_lookup(fd, &err);\n\tif (!sock) {\n\t\tpr_debug(\"gtp socket fd=%d not found\\n\", fd);\n\t\treturn NULL;\n\t}\n\n\tsk = sock->sk;\n\tif (sk->sk_protocol != IPPROTO_UDP ||\n\t    sk->sk_type != SOCK_DGRAM ||\n\t    (sk->sk_family != AF_INET && sk->sk_family != AF_INET6)) {\n\t\tpr_debug(\"socket fd=%d not UDP\\n\", fd);\n\t\tsk = ERR_PTR(-EINVAL);\n\t\tgoto out_sock;\n\t}\n\n\tlock_sock(sk);\n\tif (sk->sk_user_data) {\n\t\tsk = ERR_PTR(-EBUSY);\n\t\tgoto out_rel_sock;\n\t}\n\n\tsock_hold(sk);\n\n\ttuncfg.sk_user_data = gtp;\n\ttuncfg.encap_type = type;\n\ttuncfg.encap_rcv = gtp_encap_recv;\n\ttuncfg.encap_destroy = gtp_encap_destroy;\n\n\tsetup_udp_tunnel_sock(sock_net(sock->sk), sock, &tuncfg);\n\nout_rel_sock:\n\trelease_sock(sock->sk);\nout_sock:\n\tsockfd_put(sock);\n\treturn sk;\n}\n\nstatic int gtp_encap_enable(struct gtp_dev *gtp, struct nlattr *data[])\n{\n\tstruct sock *sk1u = NULL;\n\tstruct sock *sk0 = NULL;\n\n\tif (!data[IFLA_GTP_FD0] && !data[IFLA_GTP_FD1])\n\t\treturn -EINVAL;\n\n\tif (data[IFLA_GTP_FD0]) {\n\t\tu32 fd0 = nla_get_u32(data[IFLA_GTP_FD0]);\n\n\t\tsk0 = gtp_encap_enable_socket(fd0, UDP_ENCAP_GTP0, gtp);\n\t\tif (IS_ERR(sk0))\n\t\t\treturn PTR_ERR(sk0);\n\t}\n\n\tif (data[IFLA_GTP_FD1]) {\n\t\tu32 fd1 = nla_get_u32(data[IFLA_GTP_FD1]);\n\n\t\tsk1u = gtp_encap_enable_socket(fd1, UDP_ENCAP_GTP1U, gtp);\n\t\tif (IS_ERR(sk1u)) {\n\t\t\tgtp_encap_disable_sock(sk0);\n\t\t\treturn PTR_ERR(sk1u);\n\t\t}\n\t}\n\n\tgtp->sk0 = sk0;\n\tgtp->sk1u = sk1u;\n\n\treturn 0;\n}\n\nstatic struct gtp_dev *gtp_find_dev(struct net *src_net, struct nlattr *nla[])\n{\n\tstruct gtp_dev *gtp = NULL;\n\tstruct net_device *dev;\n\tstruct net *net;\n\n\t \n\tif (nla[GTPA_NET_NS_FD])\n\t\tnet = get_net_ns_by_fd(nla_get_u32(nla[GTPA_NET_NS_FD]));\n\telse\n\t\tnet = get_net(src_net);\n\n\tif (IS_ERR(net))\n\t\treturn NULL;\n\n\t \n\tdev = dev_get_by_index_rcu(net, nla_get_u32(nla[GTPA_LINK]));\n\tif (dev && dev->netdev_ops == &gtp_netdev_ops)\n\t\tgtp = netdev_priv(dev);\n\n\tput_net(net);\n\treturn gtp;\n}\n\nstatic void ipv4_pdp_fill(struct pdp_ctx *pctx, struct genl_info *info)\n{\n\tpctx->gtp_version = nla_get_u32(info->attrs[GTPA_VERSION]);\n\tpctx->af = AF_INET;\n\tpctx->peer_addr_ip4.s_addr =\n\t\tnla_get_be32(info->attrs[GTPA_PEER_ADDRESS]);\n\tpctx->ms_addr_ip4.s_addr =\n\t\tnla_get_be32(info->attrs[GTPA_MS_ADDRESS]);\n\n\tswitch (pctx->gtp_version) {\n\tcase GTP_V0:\n\t\t \n\t\tpctx->u.v0.tid = nla_get_u64(info->attrs[GTPA_TID]);\n\t\tpctx->u.v0.flow = nla_get_u16(info->attrs[GTPA_FLOW]);\n\t\tbreak;\n\tcase GTP_V1:\n\t\tpctx->u.v1.i_tei = nla_get_u32(info->attrs[GTPA_I_TEI]);\n\t\tpctx->u.v1.o_tei = nla_get_u32(info->attrs[GTPA_O_TEI]);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic struct pdp_ctx *gtp_pdp_add(struct gtp_dev *gtp, struct sock *sk,\n\t\t\t\t   struct genl_info *info)\n{\n\tstruct pdp_ctx *pctx, *pctx_tid = NULL;\n\tstruct net_device *dev = gtp->dev;\n\tu32 hash_ms, hash_tid = 0;\n\tunsigned int version;\n\tbool found = false;\n\t__be32 ms_addr;\n\n\tms_addr = nla_get_be32(info->attrs[GTPA_MS_ADDRESS]);\n\thash_ms = ipv4_hashfn(ms_addr) % gtp->hash_size;\n\tversion = nla_get_u32(info->attrs[GTPA_VERSION]);\n\n\tpctx = ipv4_pdp_find(gtp, ms_addr);\n\tif (pctx)\n\t\tfound = true;\n\tif (version == GTP_V0)\n\t\tpctx_tid = gtp0_pdp_find(gtp,\n\t\t\t\t\t nla_get_u64(info->attrs[GTPA_TID]));\n\telse if (version == GTP_V1)\n\t\tpctx_tid = gtp1_pdp_find(gtp,\n\t\t\t\t\t nla_get_u32(info->attrs[GTPA_I_TEI]));\n\tif (pctx_tid)\n\t\tfound = true;\n\n\tif (found) {\n\t\tif (info->nlhdr->nlmsg_flags & NLM_F_EXCL)\n\t\t\treturn ERR_PTR(-EEXIST);\n\t\tif (info->nlhdr->nlmsg_flags & NLM_F_REPLACE)\n\t\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\t\tif (pctx && pctx_tid)\n\t\t\treturn ERR_PTR(-EEXIST);\n\t\tif (!pctx)\n\t\t\tpctx = pctx_tid;\n\n\t\tipv4_pdp_fill(pctx, info);\n\n\t\tif (pctx->gtp_version == GTP_V0)\n\t\t\tnetdev_dbg(dev, \"GTPv0-U: update tunnel id = %llx (pdp %p)\\n\",\n\t\t\t\t   pctx->u.v0.tid, pctx);\n\t\telse if (pctx->gtp_version == GTP_V1)\n\t\t\tnetdev_dbg(dev, \"GTPv1-U: update tunnel id = %x/%x (pdp %p)\\n\",\n\t\t\t\t   pctx->u.v1.i_tei, pctx->u.v1.o_tei, pctx);\n\n\t\treturn pctx;\n\n\t}\n\n\tpctx = kmalloc(sizeof(*pctx), GFP_ATOMIC);\n\tif (pctx == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tsock_hold(sk);\n\tpctx->sk = sk;\n\tpctx->dev = gtp->dev;\n\tipv4_pdp_fill(pctx, info);\n\tatomic_set(&pctx->tx_seq, 0);\n\n\tswitch (pctx->gtp_version) {\n\tcase GTP_V0:\n\t\t \n\t\thash_tid = gtp0_hashfn(pctx->u.v0.tid) % gtp->hash_size;\n\t\tbreak;\n\tcase GTP_V1:\n\t\thash_tid = gtp1u_hashfn(pctx->u.v1.i_tei) % gtp->hash_size;\n\t\tbreak;\n\t}\n\n\thlist_add_head_rcu(&pctx->hlist_addr, &gtp->addr_hash[hash_ms]);\n\thlist_add_head_rcu(&pctx->hlist_tid, &gtp->tid_hash[hash_tid]);\n\n\tswitch (pctx->gtp_version) {\n\tcase GTP_V0:\n\t\tnetdev_dbg(dev, \"GTPv0-U: new PDP ctx id=%llx ssgn=%pI4 ms=%pI4 (pdp=%p)\\n\",\n\t\t\t   pctx->u.v0.tid, &pctx->peer_addr_ip4,\n\t\t\t   &pctx->ms_addr_ip4, pctx);\n\t\tbreak;\n\tcase GTP_V1:\n\t\tnetdev_dbg(dev, \"GTPv1-U: new PDP ctx id=%x/%x ssgn=%pI4 ms=%pI4 (pdp=%p)\\n\",\n\t\t\t   pctx->u.v1.i_tei, pctx->u.v1.o_tei,\n\t\t\t   &pctx->peer_addr_ip4, &pctx->ms_addr_ip4, pctx);\n\t\tbreak;\n\t}\n\n\treturn pctx;\n}\n\nstatic void pdp_context_free(struct rcu_head *head)\n{\n\tstruct pdp_ctx *pctx = container_of(head, struct pdp_ctx, rcu_head);\n\n\tsock_put(pctx->sk);\n\tkfree(pctx);\n}\n\nstatic void pdp_context_delete(struct pdp_ctx *pctx)\n{\n\thlist_del_rcu(&pctx->hlist_tid);\n\thlist_del_rcu(&pctx->hlist_addr);\n\tcall_rcu(&pctx->rcu_head, pdp_context_free);\n}\n\nstatic int gtp_tunnel_notify(struct pdp_ctx *pctx, u8 cmd, gfp_t allocation);\n\nstatic int gtp_genl_new_pdp(struct sk_buff *skb, struct genl_info *info)\n{\n\tunsigned int version;\n\tstruct pdp_ctx *pctx;\n\tstruct gtp_dev *gtp;\n\tstruct sock *sk;\n\tint err;\n\n\tif (!info->attrs[GTPA_VERSION] ||\n\t    !info->attrs[GTPA_LINK] ||\n\t    !info->attrs[GTPA_PEER_ADDRESS] ||\n\t    !info->attrs[GTPA_MS_ADDRESS])\n\t\treturn -EINVAL;\n\n\tversion = nla_get_u32(info->attrs[GTPA_VERSION]);\n\n\tswitch (version) {\n\tcase GTP_V0:\n\t\tif (!info->attrs[GTPA_TID] ||\n\t\t    !info->attrs[GTPA_FLOW])\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase GTP_V1:\n\t\tif (!info->attrs[GTPA_I_TEI] ||\n\t\t    !info->attrs[GTPA_O_TEI])\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\trtnl_lock();\n\n\tgtp = gtp_find_dev(sock_net(skb->sk), info->attrs);\n\tif (!gtp) {\n\t\terr = -ENODEV;\n\t\tgoto out_unlock;\n\t}\n\n\tif (version == GTP_V0)\n\t\tsk = gtp->sk0;\n\telse if (version == GTP_V1)\n\t\tsk = gtp->sk1u;\n\telse\n\t\tsk = NULL;\n\n\tif (!sk) {\n\t\terr = -ENODEV;\n\t\tgoto out_unlock;\n\t}\n\n\tpctx = gtp_pdp_add(gtp, sk, info);\n\tif (IS_ERR(pctx)) {\n\t\terr = PTR_ERR(pctx);\n\t} else {\n\t\tgtp_tunnel_notify(pctx, GTP_CMD_NEWPDP, GFP_KERNEL);\n\t\terr = 0;\n\t}\n\nout_unlock:\n\trtnl_unlock();\n\treturn err;\n}\n\nstatic struct pdp_ctx *gtp_find_pdp_by_link(struct net *net,\n\t\t\t\t\t    struct nlattr *nla[])\n{\n\tstruct gtp_dev *gtp;\n\n\tgtp = gtp_find_dev(net, nla);\n\tif (!gtp)\n\t\treturn ERR_PTR(-ENODEV);\n\n\tif (nla[GTPA_MS_ADDRESS]) {\n\t\t__be32 ip = nla_get_be32(nla[GTPA_MS_ADDRESS]);\n\n\t\treturn ipv4_pdp_find(gtp, ip);\n\t} else if (nla[GTPA_VERSION]) {\n\t\tu32 gtp_version = nla_get_u32(nla[GTPA_VERSION]);\n\n\t\tif (gtp_version == GTP_V0 && nla[GTPA_TID])\n\t\t\treturn gtp0_pdp_find(gtp, nla_get_u64(nla[GTPA_TID]));\n\t\telse if (gtp_version == GTP_V1 && nla[GTPA_I_TEI])\n\t\t\treturn gtp1_pdp_find(gtp, nla_get_u32(nla[GTPA_I_TEI]));\n\t}\n\n\treturn ERR_PTR(-EINVAL);\n}\n\nstatic struct pdp_ctx *gtp_find_pdp(struct net *net, struct nlattr *nla[])\n{\n\tstruct pdp_ctx *pctx;\n\n\tif (nla[GTPA_LINK])\n\t\tpctx = gtp_find_pdp_by_link(net, nla);\n\telse\n\t\tpctx = ERR_PTR(-EINVAL);\n\n\tif (!pctx)\n\t\tpctx = ERR_PTR(-ENOENT);\n\n\treturn pctx;\n}\n\nstatic int gtp_genl_del_pdp(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct pdp_ctx *pctx;\n\tint err = 0;\n\n\tif (!info->attrs[GTPA_VERSION])\n\t\treturn -EINVAL;\n\n\trcu_read_lock();\n\n\tpctx = gtp_find_pdp(sock_net(skb->sk), info->attrs);\n\tif (IS_ERR(pctx)) {\n\t\terr = PTR_ERR(pctx);\n\t\tgoto out_unlock;\n\t}\n\n\tif (pctx->gtp_version == GTP_V0)\n\t\tnetdev_dbg(pctx->dev, \"GTPv0-U: deleting tunnel id = %llx (pdp %p)\\n\",\n\t\t\t   pctx->u.v0.tid, pctx);\n\telse if (pctx->gtp_version == GTP_V1)\n\t\tnetdev_dbg(pctx->dev, \"GTPv1-U: deleting tunnel id = %x/%x (pdp %p)\\n\",\n\t\t\t   pctx->u.v1.i_tei, pctx->u.v1.o_tei, pctx);\n\n\tgtp_tunnel_notify(pctx, GTP_CMD_DELPDP, GFP_ATOMIC);\n\tpdp_context_delete(pctx);\n\nout_unlock:\n\trcu_read_unlock();\n\treturn err;\n}\n\nstatic int gtp_genl_fill_info(struct sk_buff *skb, u32 snd_portid, u32 snd_seq,\n\t\t\t      int flags, u32 type, struct pdp_ctx *pctx)\n{\n\tvoid *genlh;\n\n\tgenlh = genlmsg_put(skb, snd_portid, snd_seq, &gtp_genl_family, flags,\n\t\t\t    type);\n\tif (genlh == NULL)\n\t\tgoto nlmsg_failure;\n\n\tif (nla_put_u32(skb, GTPA_VERSION, pctx->gtp_version) ||\n\t    nla_put_u32(skb, GTPA_LINK, pctx->dev->ifindex) ||\n\t    nla_put_be32(skb, GTPA_PEER_ADDRESS, pctx->peer_addr_ip4.s_addr) ||\n\t    nla_put_be32(skb, GTPA_MS_ADDRESS, pctx->ms_addr_ip4.s_addr))\n\t\tgoto nla_put_failure;\n\n\tswitch (pctx->gtp_version) {\n\tcase GTP_V0:\n\t\tif (nla_put_u64_64bit(skb, GTPA_TID, pctx->u.v0.tid, GTPA_PAD) ||\n\t\t    nla_put_u16(skb, GTPA_FLOW, pctx->u.v0.flow))\n\t\t\tgoto nla_put_failure;\n\t\tbreak;\n\tcase GTP_V1:\n\t\tif (nla_put_u32(skb, GTPA_I_TEI, pctx->u.v1.i_tei) ||\n\t\t    nla_put_u32(skb, GTPA_O_TEI, pctx->u.v1.o_tei))\n\t\t\tgoto nla_put_failure;\n\t\tbreak;\n\t}\n\tgenlmsg_end(skb, genlh);\n\treturn 0;\n\nnlmsg_failure:\nnla_put_failure:\n\tgenlmsg_cancel(skb, genlh);\n\treturn -EMSGSIZE;\n}\n\nstatic int gtp_tunnel_notify(struct pdp_ctx *pctx, u8 cmd, gfp_t allocation)\n{\n\tstruct sk_buff *msg;\n\tint ret;\n\n\tmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, allocation);\n\tif (!msg)\n\t\treturn -ENOMEM;\n\n\tret = gtp_genl_fill_info(msg, 0, 0, 0, cmd, pctx);\n\tif (ret < 0) {\n\t\tnlmsg_free(msg);\n\t\treturn ret;\n\t}\n\n\tret = genlmsg_multicast_netns(&gtp_genl_family, dev_net(pctx->dev), msg,\n\t\t\t\t      0, GTP_GENL_MCGRP, GFP_ATOMIC);\n\treturn ret;\n}\n\nstatic int gtp_genl_get_pdp(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct pdp_ctx *pctx = NULL;\n\tstruct sk_buff *skb2;\n\tint err;\n\n\tif (!info->attrs[GTPA_VERSION])\n\t\treturn -EINVAL;\n\n\trcu_read_lock();\n\n\tpctx = gtp_find_pdp(sock_net(skb->sk), info->attrs);\n\tif (IS_ERR(pctx)) {\n\t\terr = PTR_ERR(pctx);\n\t\tgoto err_unlock;\n\t}\n\n\tskb2 = genlmsg_new(NLMSG_GOODSIZE, GFP_ATOMIC);\n\tif (skb2 == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto err_unlock;\n\t}\n\n\terr = gtp_genl_fill_info(skb2, NETLINK_CB(skb).portid, info->snd_seq,\n\t\t\t\t 0, info->nlhdr->nlmsg_type, pctx);\n\tif (err < 0)\n\t\tgoto err_unlock_free;\n\n\trcu_read_unlock();\n\treturn genlmsg_unicast(genl_info_net(info), skb2, info->snd_portid);\n\nerr_unlock_free:\n\tkfree_skb(skb2);\nerr_unlock:\n\trcu_read_unlock();\n\treturn err;\n}\n\nstatic int gtp_genl_dump_pdp(struct sk_buff *skb,\n\t\t\t\tstruct netlink_callback *cb)\n{\n\tstruct gtp_dev *last_gtp = (struct gtp_dev *)cb->args[2], *gtp;\n\tint i, j, bucket = cb->args[0], skip = cb->args[1];\n\tstruct net *net = sock_net(skb->sk);\n\tstruct pdp_ctx *pctx;\n\tstruct gtp_net *gn;\n\n\tgn = net_generic(net, gtp_net_id);\n\n\tif (cb->args[4])\n\t\treturn 0;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(gtp, &gn->gtp_dev_list, list) {\n\t\tif (last_gtp && last_gtp != gtp)\n\t\t\tcontinue;\n\t\telse\n\t\t\tlast_gtp = NULL;\n\n\t\tfor (i = bucket; i < gtp->hash_size; i++) {\n\t\t\tj = 0;\n\t\t\thlist_for_each_entry_rcu(pctx, &gtp->tid_hash[i],\n\t\t\t\t\t\t hlist_tid) {\n\t\t\t\tif (j >= skip &&\n\t\t\t\t    gtp_genl_fill_info(skb,\n\t\t\t\t\t    NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t    cb->nlh->nlmsg_seq,\n\t\t\t\t\t    NLM_F_MULTI,\n\t\t\t\t\t    cb->nlh->nlmsg_type, pctx)) {\n\t\t\t\t\tcb->args[0] = i;\n\t\t\t\t\tcb->args[1] = j;\n\t\t\t\t\tcb->args[2] = (unsigned long)gtp;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tj++;\n\t\t\t}\n\t\t\tskip = 0;\n\t\t}\n\t\tbucket = 0;\n\t}\n\tcb->args[4] = 1;\nout:\n\trcu_read_unlock();\n\treturn skb->len;\n}\n\nstatic int gtp_genl_send_echo_req(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *skb_to_send;\n\t__be32 src_ip, dst_ip;\n\tunsigned int version;\n\tstruct gtp_dev *gtp;\n\tstruct flowi4 fl4;\n\tstruct rtable *rt;\n\tstruct sock *sk;\n\t__be16 port;\n\tint len;\n\n\tif (!info->attrs[GTPA_VERSION] ||\n\t    !info->attrs[GTPA_LINK] ||\n\t    !info->attrs[GTPA_PEER_ADDRESS] ||\n\t    !info->attrs[GTPA_MS_ADDRESS])\n\t\treturn -EINVAL;\n\n\tversion = nla_get_u32(info->attrs[GTPA_VERSION]);\n\tdst_ip = nla_get_be32(info->attrs[GTPA_PEER_ADDRESS]);\n\tsrc_ip = nla_get_be32(info->attrs[GTPA_MS_ADDRESS]);\n\n\tgtp = gtp_find_dev(sock_net(skb->sk), info->attrs);\n\tif (!gtp)\n\t\treturn -ENODEV;\n\n\tif (!gtp->sk_created)\n\t\treturn -EOPNOTSUPP;\n\tif (!(gtp->dev->flags & IFF_UP))\n\t\treturn -ENETDOWN;\n\n\tif (version == GTP_V0) {\n\t\tstruct gtp0_header *gtp0_h;\n\n\t\tlen = LL_RESERVED_SPACE(gtp->dev) + sizeof(struct gtp0_header) +\n\t\t\tsizeof(struct iphdr) + sizeof(struct udphdr);\n\n\t\tskb_to_send = netdev_alloc_skb_ip_align(gtp->dev, len);\n\t\tif (!skb_to_send)\n\t\t\treturn -ENOMEM;\n\n\t\tsk = gtp->sk0;\n\t\tport = htons(GTP0_PORT);\n\n\t\tgtp0_h = skb_push(skb_to_send, sizeof(struct gtp0_header));\n\t\tmemset(gtp0_h, 0, sizeof(struct gtp0_header));\n\t\tgtp0_build_echo_msg(gtp0_h, GTP_ECHO_REQ);\n\t} else if (version == GTP_V1) {\n\t\tstruct gtp1_header_long *gtp1u_h;\n\n\t\tlen = LL_RESERVED_SPACE(gtp->dev) +\n\t\t\tsizeof(struct gtp1_header_long) +\n\t\t\tsizeof(struct iphdr) + sizeof(struct udphdr);\n\n\t\tskb_to_send = netdev_alloc_skb_ip_align(gtp->dev, len);\n\t\tif (!skb_to_send)\n\t\t\treturn -ENOMEM;\n\n\t\tsk = gtp->sk1u;\n\t\tport = htons(GTP1U_PORT);\n\n\t\tgtp1u_h = skb_push(skb_to_send,\n\t\t\t\t   sizeof(struct gtp1_header_long));\n\t\tmemset(gtp1u_h, 0, sizeof(struct gtp1_header_long));\n\t\tgtp1u_build_echo_msg(gtp1u_h, GTP_ECHO_REQ);\n\t} else {\n\t\treturn -ENODEV;\n\t}\n\n\trt = ip4_route_output_gtp(&fl4, sk, dst_ip, src_ip);\n\tif (IS_ERR(rt)) {\n\t\tnetdev_dbg(gtp->dev, \"no route for echo request to %pI4\\n\",\n\t\t\t   &dst_ip);\n\t\tkfree_skb(skb_to_send);\n\t\treturn -ENODEV;\n\t}\n\n\tudp_tunnel_xmit_skb(rt, sk, skb_to_send,\n\t\t\t    fl4.saddr, fl4.daddr,\n\t\t\t    fl4.flowi4_tos,\n\t\t\t    ip4_dst_hoplimit(&rt->dst),\n\t\t\t    0,\n\t\t\t    port, port,\n\t\t\t    !net_eq(sock_net(sk),\n\t\t\t\t    dev_net(gtp->dev)),\n\t\t\t    false);\n\treturn 0;\n}\n\nstatic const struct nla_policy gtp_genl_policy[GTPA_MAX + 1] = {\n\t[GTPA_LINK]\t\t= { .type = NLA_U32, },\n\t[GTPA_VERSION]\t\t= { .type = NLA_U32, },\n\t[GTPA_TID]\t\t= { .type = NLA_U64, },\n\t[GTPA_PEER_ADDRESS]\t= { .type = NLA_U32, },\n\t[GTPA_MS_ADDRESS]\t= { .type = NLA_U32, },\n\t[GTPA_FLOW]\t\t= { .type = NLA_U16, },\n\t[GTPA_NET_NS_FD]\t= { .type = NLA_U32, },\n\t[GTPA_I_TEI]\t\t= { .type = NLA_U32, },\n\t[GTPA_O_TEI]\t\t= { .type = NLA_U32, },\n};\n\nstatic const struct genl_small_ops gtp_genl_ops[] = {\n\t{\n\t\t.cmd = GTP_CMD_NEWPDP,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = gtp_genl_new_pdp,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n\t{\n\t\t.cmd = GTP_CMD_DELPDP,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = gtp_genl_del_pdp,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n\t{\n\t\t.cmd = GTP_CMD_GETPDP,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = gtp_genl_get_pdp,\n\t\t.dumpit = gtp_genl_dump_pdp,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n\t{\n\t\t.cmd = GTP_CMD_ECHOREQ,\n\t\t.validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,\n\t\t.doit = gtp_genl_send_echo_req,\n\t\t.flags = GENL_ADMIN_PERM,\n\t},\n};\n\nstatic struct genl_family gtp_genl_family __ro_after_init = {\n\t.name\t\t= \"gtp\",\n\t.version\t= 0,\n\t.hdrsize\t= 0,\n\t.maxattr\t= GTPA_MAX,\n\t.policy = gtp_genl_policy,\n\t.netnsok\t= true,\n\t.module\t\t= THIS_MODULE,\n\t.small_ops\t= gtp_genl_ops,\n\t.n_small_ops\t= ARRAY_SIZE(gtp_genl_ops),\n\t.resv_start_op\t= GTP_CMD_ECHOREQ + 1,\n\t.mcgrps\t\t= gtp_genl_mcgrps,\n\t.n_mcgrps\t= ARRAY_SIZE(gtp_genl_mcgrps),\n};\n\nstatic int __net_init gtp_net_init(struct net *net)\n{\n\tstruct gtp_net *gn = net_generic(net, gtp_net_id);\n\n\tINIT_LIST_HEAD(&gn->gtp_dev_list);\n\treturn 0;\n}\n\nstatic void __net_exit gtp_net_exit(struct net *net)\n{\n\tstruct gtp_net *gn = net_generic(net, gtp_net_id);\n\tstruct gtp_dev *gtp;\n\tLIST_HEAD(list);\n\n\trtnl_lock();\n\tlist_for_each_entry(gtp, &gn->gtp_dev_list, list)\n\t\tgtp_dellink(gtp->dev, &list);\n\n\tunregister_netdevice_many(&list);\n\trtnl_unlock();\n}\n\nstatic struct pernet_operations gtp_net_ops = {\n\t.init\t= gtp_net_init,\n\t.exit\t= gtp_net_exit,\n\t.id\t= &gtp_net_id,\n\t.size\t= sizeof(struct gtp_net),\n};\n\nstatic int __init gtp_init(void)\n{\n\tint err;\n\n\tget_random_bytes(&gtp_h_initval, sizeof(gtp_h_initval));\n\n\terr = rtnl_link_register(&gtp_link_ops);\n\tif (err < 0)\n\t\tgoto error_out;\n\n\terr = genl_register_family(&gtp_genl_family);\n\tif (err < 0)\n\t\tgoto unreg_rtnl_link;\n\n\terr = register_pernet_subsys(&gtp_net_ops);\n\tif (err < 0)\n\t\tgoto unreg_genl_family;\n\n\tpr_info(\"GTP module loaded (pdp ctx size %zd bytes)\\n\",\n\t\tsizeof(struct pdp_ctx));\n\treturn 0;\n\nunreg_genl_family:\n\tgenl_unregister_family(&gtp_genl_family);\nunreg_rtnl_link:\n\trtnl_link_unregister(&gtp_link_ops);\nerror_out:\n\tpr_err(\"error loading GTP module loaded\\n\");\n\treturn err;\n}\nlate_initcall(gtp_init);\n\nstatic void __exit gtp_fini(void)\n{\n\tgenl_unregister_family(&gtp_genl_family);\n\trtnl_link_unregister(&gtp_link_ops);\n\tunregister_pernet_subsys(&gtp_net_ops);\n\n\tpr_info(\"GTP module unloaded\\n\");\n}\nmodule_exit(gtp_fini);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Harald Welte <hwelte@sysmocom.de>\");\nMODULE_DESCRIPTION(\"Interface driver for GTP encapsulated traffic\");\nMODULE_ALIAS_RTNL_LINK(\"gtp\");\nMODULE_ALIAS_GENL_FAMILY(\"gtp\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}