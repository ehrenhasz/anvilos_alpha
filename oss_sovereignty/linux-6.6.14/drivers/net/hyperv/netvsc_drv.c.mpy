{
  "module_name": "netvsc_drv.c",
  "hash_id": "5f8601a6b387483d78aca7095988c0162fa6ab925d156b968c26ef2cce6b402b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/hyperv/netvsc_drv.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/init.h>\n#include <linux/atomic.h>\n#include <linux/ethtool.h>\n#include <linux/module.h>\n#include <linux/highmem.h>\n#include <linux/device.h>\n#include <linux/io.h>\n#include <linux/delay.h>\n#include <linux/netdevice.h>\n#include <linux/inetdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/pci.h>\n#include <linux/skbuff.h>\n#include <linux/if_vlan.h>\n#include <linux/in.h>\n#include <linux/slab.h>\n#include <linux/rtnetlink.h>\n#include <linux/netpoll.h>\n#include <linux/bpf.h>\n\n#include <net/arp.h>\n#include <net/route.h>\n#include <net/sock.h>\n#include <net/pkt_sched.h>\n#include <net/checksum.h>\n#include <net/ip6_checksum.h>\n\n#include \"hyperv_net.h\"\n\n#define RING_SIZE_MIN\t64\n\n#define LINKCHANGE_INT (2 * HZ)\n#define VF_TAKEOVER_INT (HZ / 10)\n\nstatic unsigned int ring_size __ro_after_init = 128;\nmodule_param(ring_size, uint, 0444);\nMODULE_PARM_DESC(ring_size, \"Ring buffer size (# of pages)\");\nunsigned int netvsc_ring_bytes __ro_after_init;\n\nstatic const u32 default_msg = NETIF_MSG_DRV | NETIF_MSG_PROBE |\n\t\t\t\tNETIF_MSG_LINK | NETIF_MSG_IFUP |\n\t\t\t\tNETIF_MSG_IFDOWN | NETIF_MSG_RX_ERR |\n\t\t\t\tNETIF_MSG_TX_ERR;\n\nstatic int debug = -1;\nmodule_param(debug, int, 0444);\nMODULE_PARM_DESC(debug, \"Debug level (0=none,...,16=all)\");\n\nstatic LIST_HEAD(netvsc_dev_list);\n\nstatic void netvsc_change_rx_flags(struct net_device *net, int change)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tstruct net_device *vf_netdev = rtnl_dereference(ndev_ctx->vf_netdev);\n\tint inc;\n\n\tif (!vf_netdev)\n\t\treturn;\n\n\tif (change & IFF_PROMISC) {\n\t\tinc = (net->flags & IFF_PROMISC) ? 1 : -1;\n\t\tdev_set_promiscuity(vf_netdev, inc);\n\t}\n\n\tif (change & IFF_ALLMULTI) {\n\t\tinc = (net->flags & IFF_ALLMULTI) ? 1 : -1;\n\t\tdev_set_allmulti(vf_netdev, inc);\n\t}\n}\n\nstatic void netvsc_set_rx_mode(struct net_device *net)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tstruct net_device *vf_netdev;\n\tstruct netvsc_device *nvdev;\n\n\trcu_read_lock();\n\tvf_netdev = rcu_dereference(ndev_ctx->vf_netdev);\n\tif (vf_netdev) {\n\t\tdev_uc_sync(vf_netdev, net);\n\t\tdev_mc_sync(vf_netdev, net);\n\t}\n\n\tnvdev = rcu_dereference(ndev_ctx->nvdev);\n\tif (nvdev)\n\t\trndis_filter_update(nvdev);\n\trcu_read_unlock();\n}\n\nstatic void netvsc_tx_enable(struct netvsc_device *nvscdev,\n\t\t\t     struct net_device *ndev)\n{\n\tnvscdev->tx_disable = false;\n\tvirt_wmb();  \n\n\tnetif_tx_wake_all_queues(ndev);\n}\n\nstatic int netvsc_open(struct net_device *net)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tstruct net_device *vf_netdev = rtnl_dereference(ndev_ctx->vf_netdev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndev_ctx->nvdev);\n\tstruct rndis_device *rdev;\n\tint ret = 0;\n\n\tnetif_carrier_off(net);\n\n\t \n\tret = rndis_filter_open(nvdev);\n\tif (ret != 0) {\n\t\tnetdev_err(net, \"unable to open device (ret %d).\\n\", ret);\n\t\treturn ret;\n\t}\n\n\trdev = nvdev->extension;\n\tif (!rdev->link_state) {\n\t\tnetif_carrier_on(net);\n\t\tnetvsc_tx_enable(nvdev, net);\n\t}\n\n\tif (vf_netdev) {\n\t\t \n\t\tret = dev_open(vf_netdev, NULL);\n\t\tif (ret)\n\t\t\tnetdev_warn(net,\n\t\t\t\t    \"unable to open slave: %s: %d\\n\",\n\t\t\t\t    vf_netdev->name, ret);\n\t}\n\treturn 0;\n}\n\nstatic int netvsc_wait_until_empty(struct netvsc_device *nvdev)\n{\n\tunsigned int retry = 0;\n\tint i;\n\n\t \n\tfor (;;) {\n\t\tu32 aread = 0;\n\n\t\tfor (i = 0; i < nvdev->num_chn; i++) {\n\t\t\tstruct vmbus_channel *chn\n\t\t\t\t= nvdev->chan_table[i].channel;\n\n\t\t\tif (!chn)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tnapi_synchronize(&nvdev->chan_table[i].napi);\n\n\t\t\taread = hv_get_bytes_to_read(&chn->inbound);\n\t\t\tif (aread)\n\t\t\t\tbreak;\n\n\t\t\taread = hv_get_bytes_to_read(&chn->outbound);\n\t\t\tif (aread)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (aread == 0)\n\t\t\treturn 0;\n\n\t\tif (++retry > RETRY_MAX)\n\t\t\treturn -ETIMEDOUT;\n\n\t\tusleep_range(RETRY_US_LO, RETRY_US_HI);\n\t}\n}\n\nstatic void netvsc_tx_disable(struct netvsc_device *nvscdev,\n\t\t\t      struct net_device *ndev)\n{\n\tif (nvscdev) {\n\t\tnvscdev->tx_disable = true;\n\t\tvirt_wmb();  \n\t}\n\n\tnetif_tx_disable(ndev);\n}\n\nstatic int netvsc_close(struct net_device *net)\n{\n\tstruct net_device_context *net_device_ctx = netdev_priv(net);\n\tstruct net_device *vf_netdev\n\t\t= rtnl_dereference(net_device_ctx->vf_netdev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(net_device_ctx->nvdev);\n\tint ret;\n\n\tnetvsc_tx_disable(nvdev, net);\n\n\t \n\tif (!nvdev)\n\t\treturn 0;\n\n\tret = rndis_filter_close(nvdev);\n\tif (ret != 0) {\n\t\tnetdev_err(net, \"unable to close device (ret %d).\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = netvsc_wait_until_empty(nvdev);\n\tif (ret)\n\t\tnetdev_err(net, \"Ring buffer not empty after closing rndis\\n\");\n\n\tif (vf_netdev)\n\t\tdev_close(vf_netdev);\n\n\treturn ret;\n}\n\nstatic inline void *init_ppi_data(struct rndis_message *msg,\n\t\t\t\t  u32 ppi_size, u32 pkt_type)\n{\n\tstruct rndis_packet *rndis_pkt = &msg->msg.pkt;\n\tstruct rndis_per_packet_info *ppi;\n\n\trndis_pkt->data_offset += ppi_size;\n\tppi = (void *)rndis_pkt + rndis_pkt->per_pkt_info_offset\n\t\t+ rndis_pkt->per_pkt_info_len;\n\n\tppi->size = ppi_size;\n\tppi->type = pkt_type;\n\tppi->internal = 0;\n\tppi->ppi_offset = sizeof(struct rndis_per_packet_info);\n\n\trndis_pkt->per_pkt_info_len += ppi_size;\n\n\treturn ppi + 1;\n}\n\nstatic inline int netvsc_get_tx_queue(struct net_device *ndev,\n\t\t\t\t      struct sk_buff *skb, int old_idx)\n{\n\tconst struct net_device_context *ndc = netdev_priv(ndev);\n\tstruct sock *sk = skb->sk;\n\tint q_idx;\n\n\tq_idx = ndc->tx_table[netvsc_get_hash(skb, ndc) &\n\t\t\t      (VRSS_SEND_TAB_SIZE - 1)];\n\n\t \n\tif (q_idx != old_idx &&\n\t    sk && sk_fullsock(sk) && rcu_access_pointer(sk->sk_dst_cache))\n\t\tsk_tx_queue_set(sk, q_idx);\n\n\treturn q_idx;\n}\n\n \nstatic u16 netvsc_pick_tx(struct net_device *ndev, struct sk_buff *skb)\n{\n\tint q_idx = sk_tx_queue_get(skb->sk);\n\n\tif (q_idx < 0 || skb->ooo_okay || q_idx >= ndev->real_num_tx_queues) {\n\t\t \n\t\tif (skb_rx_queue_recorded(skb))\n\t\t\tq_idx = skb_get_rx_queue(skb);\n\t\telse\n\t\t\tq_idx = netvsc_get_tx_queue(ndev, skb, q_idx);\n\t}\n\n\treturn q_idx;\n}\n\nstatic u16 netvsc_select_queue(struct net_device *ndev, struct sk_buff *skb,\n\t\t\t       struct net_device *sb_dev)\n{\n\tstruct net_device_context *ndc = netdev_priv(ndev);\n\tstruct net_device *vf_netdev;\n\tu16 txq;\n\n\trcu_read_lock();\n\tvf_netdev = rcu_dereference(ndc->vf_netdev);\n\tif (vf_netdev) {\n\t\tconst struct net_device_ops *vf_ops = vf_netdev->netdev_ops;\n\n\t\tif (vf_ops->ndo_select_queue)\n\t\t\ttxq = vf_ops->ndo_select_queue(vf_netdev, skb, sb_dev);\n\t\telse\n\t\t\ttxq = netdev_pick_tx(vf_netdev, skb, NULL);\n\n\t\t \n\t\tqdisc_skb_cb(skb)->slave_dev_queue_mapping = txq;\n\t} else {\n\t\ttxq = netvsc_pick_tx(ndev, skb);\n\t}\n\trcu_read_unlock();\n\n\twhile (txq >= ndev->real_num_tx_queues)\n\t\ttxq -= ndev->real_num_tx_queues;\n\n\treturn txq;\n}\n\nstatic u32 fill_pg_buf(unsigned long hvpfn, u32 offset, u32 len,\n\t\t       struct hv_page_buffer *pb)\n{\n\tint j = 0;\n\n\thvpfn += offset >> HV_HYP_PAGE_SHIFT;\n\toffset = offset & ~HV_HYP_PAGE_MASK;\n\n\twhile (len > 0) {\n\t\tunsigned long bytes;\n\n\t\tbytes = HV_HYP_PAGE_SIZE - offset;\n\t\tif (bytes > len)\n\t\t\tbytes = len;\n\t\tpb[j].pfn = hvpfn;\n\t\tpb[j].offset = offset;\n\t\tpb[j].len = bytes;\n\n\t\toffset += bytes;\n\t\tlen -= bytes;\n\n\t\tif (offset == HV_HYP_PAGE_SIZE && len) {\n\t\t\thvpfn++;\n\t\t\toffset = 0;\n\t\t\tj++;\n\t\t}\n\t}\n\n\treturn j + 1;\n}\n\nstatic u32 init_page_array(void *hdr, u32 len, struct sk_buff *skb,\n\t\t\t   struct hv_netvsc_packet *packet,\n\t\t\t   struct hv_page_buffer *pb)\n{\n\tu32 slots_used = 0;\n\tchar *data = skb->data;\n\tint frags = skb_shinfo(skb)->nr_frags;\n\tint i;\n\n\t \n\tslots_used += fill_pg_buf(virt_to_hvpfn(hdr),\n\t\t\t\t  offset_in_hvpage(hdr),\n\t\t\t\t  len,\n\t\t\t\t  &pb[slots_used]);\n\n\tpacket->rmsg_size = len;\n\tpacket->rmsg_pgcnt = slots_used;\n\n\tslots_used += fill_pg_buf(virt_to_hvpfn(data),\n\t\t\t\t  offset_in_hvpage(data),\n\t\t\t\t  skb_headlen(skb),\n\t\t\t\t  &pb[slots_used]);\n\n\tfor (i = 0; i < frags; i++) {\n\t\tskb_frag_t *frag = skb_shinfo(skb)->frags + i;\n\n\t\tslots_used += fill_pg_buf(page_to_hvpfn(skb_frag_page(frag)),\n\t\t\t\t\t  skb_frag_off(frag),\n\t\t\t\t\t  skb_frag_size(frag),\n\t\t\t\t\t  &pb[slots_used]);\n\t}\n\treturn slots_used;\n}\n\nstatic int count_skb_frag_slots(struct sk_buff *skb)\n{\n\tint i, frags = skb_shinfo(skb)->nr_frags;\n\tint pages = 0;\n\n\tfor (i = 0; i < frags; i++) {\n\t\tskb_frag_t *frag = skb_shinfo(skb)->frags + i;\n\t\tunsigned long size = skb_frag_size(frag);\n\t\tunsigned long offset = skb_frag_off(frag);\n\n\t\t \n\t\toffset &= ~HV_HYP_PAGE_MASK;\n\t\tpages += HVPFN_UP(offset + size);\n\t}\n\treturn pages;\n}\n\nstatic int netvsc_get_slots(struct sk_buff *skb)\n{\n\tchar *data = skb->data;\n\tunsigned int offset = offset_in_hvpage(data);\n\tunsigned int len = skb_headlen(skb);\n\tint slots;\n\tint frag_slots;\n\n\tslots = DIV_ROUND_UP(offset + len, HV_HYP_PAGE_SIZE);\n\tfrag_slots = count_skb_frag_slots(skb);\n\treturn slots + frag_slots;\n}\n\nstatic u32 net_checksum_info(struct sk_buff *skb)\n{\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\tstruct iphdr *ip = ip_hdr(skb);\n\n\t\tif (ip->protocol == IPPROTO_TCP)\n\t\t\treturn TRANSPORT_INFO_IPV4_TCP;\n\t\telse if (ip->protocol == IPPROTO_UDP)\n\t\t\treturn TRANSPORT_INFO_IPV4_UDP;\n\t} else {\n\t\tstruct ipv6hdr *ip6 = ipv6_hdr(skb);\n\n\t\tif (ip6->nexthdr == IPPROTO_TCP)\n\t\t\treturn TRANSPORT_INFO_IPV6_TCP;\n\t\telse if (ip6->nexthdr == IPPROTO_UDP)\n\t\t\treturn TRANSPORT_INFO_IPV6_UDP;\n\t}\n\n\treturn TRANSPORT_INFO_NOT_IP;\n}\n\n \nstatic int netvsc_vf_xmit(struct net_device *net, struct net_device *vf_netdev,\n\t\t\t  struct sk_buff *skb)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tunsigned int len = skb->len;\n\tint rc;\n\n\tskb->dev = vf_netdev;\n\tskb_record_rx_queue(skb, qdisc_skb_cb(skb)->slave_dev_queue_mapping);\n\n\trc = dev_queue_xmit(skb);\n\tif (likely(rc == NET_XMIT_SUCCESS || rc == NET_XMIT_CN)) {\n\t\tstruct netvsc_vf_pcpu_stats *pcpu_stats\n\t\t\t= this_cpu_ptr(ndev_ctx->vf_stats);\n\n\t\tu64_stats_update_begin(&pcpu_stats->syncp);\n\t\tpcpu_stats->tx_packets++;\n\t\tpcpu_stats->tx_bytes += len;\n\t\tu64_stats_update_end(&pcpu_stats->syncp);\n\t} else {\n\t\tthis_cpu_inc(ndev_ctx->vf_stats->tx_dropped);\n\t}\n\n\treturn rc;\n}\n\nstatic int netvsc_xmit(struct sk_buff *skb, struct net_device *net, bool xdp_tx)\n{\n\tstruct net_device_context *net_device_ctx = netdev_priv(net);\n\tstruct hv_netvsc_packet *packet = NULL;\n\tint ret;\n\tunsigned int num_data_pgs;\n\tstruct rndis_message *rndis_msg;\n\tstruct net_device *vf_netdev;\n\tu32 rndis_msg_size;\n\tu32 hash;\n\tstruct hv_page_buffer pb[MAX_PAGE_BUFFER_COUNT];\n\n\t \n\tvf_netdev = rcu_dereference_bh(net_device_ctx->vf_netdev);\n\tif (vf_netdev && netif_running(vf_netdev) &&\n\t    netif_carrier_ok(vf_netdev) && !netpoll_tx_running(net) &&\n\t    net_device_ctx->data_path_is_vf)\n\t\treturn netvsc_vf_xmit(net, vf_netdev, skb);\n\n\t \n\n\tnum_data_pgs = netvsc_get_slots(skb) + 2;\n\n\tif (unlikely(num_data_pgs > MAX_PAGE_BUFFER_COUNT)) {\n\t\t++net_device_ctx->eth_stats.tx_scattered;\n\n\t\tif (skb_linearize(skb))\n\t\t\tgoto no_memory;\n\n\t\tnum_data_pgs = netvsc_get_slots(skb) + 2;\n\t\tif (num_data_pgs > MAX_PAGE_BUFFER_COUNT) {\n\t\t\t++net_device_ctx->eth_stats.tx_too_big;\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\t \n\tret = skb_cow_head(skb, RNDIS_AND_PPI_SIZE);\n\tif (ret)\n\t\tgoto no_memory;\n\n\t \n\tBUILD_BUG_ON(sizeof(struct hv_netvsc_packet) >\n\t\t\tsizeof_field(struct sk_buff, cb));\n\tpacket = (struct hv_netvsc_packet *)skb->cb;\n\n\tpacket->q_idx = skb_get_queue_mapping(skb);\n\n\tpacket->total_data_buflen = skb->len;\n\tpacket->total_bytes = skb->len;\n\tpacket->total_packets = 1;\n\n\trndis_msg = (struct rndis_message *)skb->head;\n\n\t \n\trndis_msg->ndis_msg_type = RNDIS_MSG_PACKET;\n\trndis_msg->msg_len = packet->total_data_buflen;\n\n\trndis_msg->msg.pkt = (struct rndis_packet) {\n\t\t.data_offset = sizeof(struct rndis_packet),\n\t\t.data_len = packet->total_data_buflen,\n\t\t.per_pkt_info_offset = sizeof(struct rndis_packet),\n\t};\n\n\trndis_msg_size = RNDIS_MESSAGE_SIZE(struct rndis_packet);\n\n\thash = skb_get_hash_raw(skb);\n\tif (hash != 0 && net->real_num_tx_queues > 1) {\n\t\tu32 *hash_info;\n\n\t\trndis_msg_size += NDIS_HASH_PPI_SIZE;\n\t\thash_info = init_ppi_data(rndis_msg, NDIS_HASH_PPI_SIZE,\n\t\t\t\t\t  NBL_HASH_VALUE);\n\t\t*hash_info = hash;\n\t}\n\n\t \n\tif (skb->protocol == htons(ETH_P_8021Q)) {\n\t\tu16 vlan_tci;\n\n\t\tskb_reset_mac_header(skb);\n\t\tif (eth_type_vlan(eth_hdr(skb)->h_proto)) {\n\t\t\tif (unlikely(__skb_vlan_pop(skb, &vlan_tci) != 0)) {\n\t\t\t\t++net_device_ctx->eth_stats.vlan_error;\n\t\t\t\tgoto drop;\n\t\t\t}\n\n\t\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tci);\n\t\t\t \n\t\t\tpacket->total_data_buflen -= VLAN_HLEN;\n\t\t\tpacket->total_bytes -= VLAN_HLEN;\n\t\t\trndis_msg->msg_len = packet->total_data_buflen;\n\t\t\trndis_msg->msg.pkt.data_len = packet->total_data_buflen;\n\t\t}\n\t}\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\tstruct ndis_pkt_8021q_info *vlan;\n\n\t\trndis_msg_size += NDIS_VLAN_PPI_SIZE;\n\t\tvlan = init_ppi_data(rndis_msg, NDIS_VLAN_PPI_SIZE,\n\t\t\t\t     IEEE_8021Q_INFO);\n\n\t\tvlan->value = 0;\n\t\tvlan->vlanid = skb_vlan_tag_get_id(skb);\n\t\tvlan->cfi = skb_vlan_tag_get_cfi(skb);\n\t\tvlan->pri = skb_vlan_tag_get_prio(skb);\n\t}\n\n\tif (skb_is_gso(skb)) {\n\t\tstruct ndis_tcp_lso_info *lso_info;\n\n\t\trndis_msg_size += NDIS_LSO_PPI_SIZE;\n\t\tlso_info = init_ppi_data(rndis_msg, NDIS_LSO_PPI_SIZE,\n\t\t\t\t\t TCP_LARGESEND_PKTINFO);\n\n\t\tlso_info->value = 0;\n\t\tlso_info->lso_v2_transmit.type = NDIS_TCP_LARGE_SEND_OFFLOAD_V2_TYPE;\n\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\tlso_info->lso_v2_transmit.ip_version =\n\t\t\t\tNDIS_TCP_LARGE_SEND_OFFLOAD_IPV4;\n\t\t\tip_hdr(skb)->tot_len = 0;\n\t\t\tip_hdr(skb)->check = 0;\n\t\t\ttcp_hdr(skb)->check =\n\t\t\t\t~csum_tcpudp_magic(ip_hdr(skb)->saddr,\n\t\t\t\t\t\t   ip_hdr(skb)->daddr, 0, IPPROTO_TCP, 0);\n\t\t} else {\n\t\t\tlso_info->lso_v2_transmit.ip_version =\n\t\t\t\tNDIS_TCP_LARGE_SEND_OFFLOAD_IPV6;\n\t\t\ttcp_v6_gso_csum_prep(skb);\n\t\t}\n\t\tlso_info->lso_v2_transmit.tcp_header_offset = skb_transport_offset(skb);\n\t\tlso_info->lso_v2_transmit.mss = skb_shinfo(skb)->gso_size;\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tif (net_checksum_info(skb) & net_device_ctx->tx_checksum_mask) {\n\t\t\tstruct ndis_tcp_ip_checksum_info *csum_info;\n\n\t\t\trndis_msg_size += NDIS_CSUM_PPI_SIZE;\n\t\t\tcsum_info = init_ppi_data(rndis_msg, NDIS_CSUM_PPI_SIZE,\n\t\t\t\t\t\t  TCPIP_CHKSUM_PKTINFO);\n\n\t\t\tcsum_info->value = 0;\n\t\t\tcsum_info->transmit.tcp_header_offset = skb_transport_offset(skb);\n\n\t\t\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\t\t\tcsum_info->transmit.is_ipv4 = 1;\n\n\t\t\t\tif (ip_hdr(skb)->protocol == IPPROTO_TCP)\n\t\t\t\t\tcsum_info->transmit.tcp_checksum = 1;\n\t\t\t\telse\n\t\t\t\t\tcsum_info->transmit.udp_checksum = 1;\n\t\t\t} else {\n\t\t\t\tcsum_info->transmit.is_ipv6 = 1;\n\n\t\t\t\tif (ipv6_hdr(skb)->nexthdr == IPPROTO_TCP)\n\t\t\t\t\tcsum_info->transmit.tcp_checksum = 1;\n\t\t\t\telse\n\t\t\t\t\tcsum_info->transmit.udp_checksum = 1;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tif (skb_checksum_help(skb))\n\t\t\t\tgoto drop;\n\t\t}\n\t}\n\n\t \n\trndis_msg->msg_len += rndis_msg_size;\n\tpacket->total_data_buflen = rndis_msg->msg_len;\n\tpacket->page_buf_cnt = init_page_array(rndis_msg, rndis_msg_size,\n\t\t\t\t\t       skb, packet, pb);\n\n\t \n\tskb_tx_timestamp(skb);\n\n\tret = netvsc_send(net, packet, rndis_msg, pb, skb, xdp_tx);\n\tif (likely(ret == 0))\n\t\treturn NETDEV_TX_OK;\n\n\tif (ret == -EAGAIN) {\n\t\t++net_device_ctx->eth_stats.tx_busy;\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\tif (ret == -ENOSPC)\n\t\t++net_device_ctx->eth_stats.tx_no_space;\n\ndrop:\n\tdev_kfree_skb_any(skb);\n\tnet->stats.tx_dropped++;\n\n\treturn NETDEV_TX_OK;\n\nno_memory:\n\t++net_device_ctx->eth_stats.tx_no_memory;\n\tgoto drop;\n}\n\nstatic netdev_tx_t netvsc_start_xmit(struct sk_buff *skb,\n\t\t\t\t     struct net_device *ndev)\n{\n\treturn netvsc_xmit(skb, ndev, false);\n}\n\n \nvoid netvsc_linkstatus_callback(struct net_device *net,\n\t\t\t\tstruct rndis_message *resp,\n\t\t\t\tvoid *data, u32 data_buflen)\n{\n\tstruct rndis_indicate_status *indicate = &resp->msg.indicate_status;\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tstruct netvsc_reconfig *event;\n\tunsigned long flags;\n\n\t \n\tif (resp->msg_len - RNDIS_HEADER_SIZE < sizeof(struct rndis_indicate_status)) {\n\t\tnetdev_err(net, \"invalid rndis_indicate_status packet, len: %u\\n\",\n\t\t\t   resp->msg_len);\n\t\treturn;\n\t}\n\n\t \n\tmemcpy(indicate, data + RNDIS_HEADER_SIZE, sizeof(*indicate));\n\n\t \n\tif (indicate->status == RNDIS_STATUS_LINK_SPEED_CHANGE) {\n\t\tu32 speed;\n\n\t\t \n\t\tif (indicate->status_buflen < sizeof(speed) ||\n\t\t    indicate->status_buf_offset < sizeof(*indicate) ||\n\t\t    data_buflen - RNDIS_HEADER_SIZE < indicate->status_buf_offset ||\n\t\t    data_buflen - RNDIS_HEADER_SIZE - indicate->status_buf_offset\n\t\t\t\t< indicate->status_buflen) {\n\t\t\tnetdev_err(net, \"invalid rndis_indicate_status packet\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\tspeed = *(u32 *)(data + RNDIS_HEADER_SIZE + indicate->status_buf_offset) / 10000;\n\t\tndev_ctx->speed = speed;\n\t\treturn;\n\t}\n\n\t \n\tif (indicate->status != RNDIS_STATUS_NETWORK_CHANGE &&\n\t    indicate->status != RNDIS_STATUS_MEDIA_CONNECT &&\n\t    indicate->status != RNDIS_STATUS_MEDIA_DISCONNECT)\n\t\treturn;\n\n\tif (net->reg_state != NETREG_REGISTERED)\n\t\treturn;\n\n\tevent = kzalloc(sizeof(*event), GFP_ATOMIC);\n\tif (!event)\n\t\treturn;\n\tevent->event = indicate->status;\n\n\tspin_lock_irqsave(&ndev_ctx->lock, flags);\n\tlist_add_tail(&event->list, &ndev_ctx->reconfig_events);\n\tspin_unlock_irqrestore(&ndev_ctx->lock, flags);\n\n\tschedule_delayed_work(&ndev_ctx->dwork, 0);\n}\n\n \nvoid netvsc_xdp_xmit(struct sk_buff *skb, struct net_device *ndev)\n{\n\tint rc;\n\n\tskb->queue_mapping = skb_get_rx_queue(skb);\n\t__skb_push(skb, ETH_HLEN);\n\n\trc = netvsc_xmit(skb, ndev, true);\n\n\tif (dev_xmit_complete(rc))\n\t\treturn;\n\n\tdev_kfree_skb_any(skb);\n\tndev->stats.tx_dropped++;\n}\n\nstatic void netvsc_comp_ipcsum(struct sk_buff *skb)\n{\n\tstruct iphdr *iph = (struct iphdr *)skb->data;\n\n\tiph->check = 0;\n\tiph->check = ip_fast_csum(iph, iph->ihl);\n}\n\nstatic struct sk_buff *netvsc_alloc_recv_skb(struct net_device *net,\n\t\t\t\t\t     struct netvsc_channel *nvchan,\n\t\t\t\t\t     struct xdp_buff *xdp)\n{\n\tstruct napi_struct *napi = &nvchan->napi;\n\tconst struct ndis_pkt_8021q_info *vlan = &nvchan->rsc.vlan;\n\tconst struct ndis_tcp_ip_checksum_info *csum_info =\n\t\t\t\t\t\t&nvchan->rsc.csum_info;\n\tconst u32 *hash_info = &nvchan->rsc.hash_info;\n\tu8 ppi_flags = nvchan->rsc.ppi_flags;\n\tstruct sk_buff *skb;\n\tvoid *xbuf = xdp->data_hard_start;\n\tint i;\n\n\tif (xbuf) {\n\t\tunsigned int hdroom = xdp->data - xdp->data_hard_start;\n\t\tunsigned int xlen = xdp->data_end - xdp->data;\n\t\tunsigned int frag_size = xdp->frame_sz;\n\n\t\tskb = build_skb(xbuf, frag_size);\n\n\t\tif (!skb) {\n\t\t\t__free_page(virt_to_page(xbuf));\n\t\t\treturn NULL;\n\t\t}\n\n\t\tskb_reserve(skb, hdroom);\n\t\tskb_put(skb, xlen);\n\t\tskb->dev = napi->dev;\n\t} else {\n\t\tskb = napi_alloc_skb(napi, nvchan->rsc.pktlen);\n\n\t\tif (!skb)\n\t\t\treturn NULL;\n\n\t\t \n\t\tfor (i = 0; i < nvchan->rsc.cnt; i++)\n\t\t\tskb_put_data(skb, nvchan->rsc.data[i],\n\t\t\t\t     nvchan->rsc.len[i]);\n\t}\n\n\tskb->protocol = eth_type_trans(skb, net);\n\n\t \n\tskb_checksum_none_assert(skb);\n\n\t \n\tif ((ppi_flags & NVSC_RSC_CSUM_INFO) && csum_info->receive.ip_checksum_value_invalid &&\n\t    csum_info->receive.ip_checksum_succeeded &&\n\t    skb->protocol == htons(ETH_P_IP)) {\n\t\t \n\t\tif (skb_headlen(skb) < sizeof(struct iphdr)) {\n\t\t\tkfree_skb(skb);\n\t\t\treturn NULL;\n\t\t}\n\t\tnetvsc_comp_ipcsum(skb);\n\t}\n\n\t \n\tif ((ppi_flags & NVSC_RSC_CSUM_INFO) && (net->features & NETIF_F_RXCSUM)) {\n\t\tif (csum_info->receive.tcp_checksum_succeeded ||\n\t\t    csum_info->receive.udp_checksum_succeeded)\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t}\n\n\tif ((ppi_flags & NVSC_RSC_HASH_INFO) && (net->features & NETIF_F_RXHASH))\n\t\tskb_set_hash(skb, *hash_info, PKT_HASH_TYPE_L4);\n\n\tif (ppi_flags & NVSC_RSC_VLAN) {\n\t\tu16 vlan_tci = vlan->vlanid | (vlan->pri << VLAN_PRIO_SHIFT) |\n\t\t\t(vlan->cfi ? VLAN_CFI_MASK : 0);\n\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),\n\t\t\t\t       vlan_tci);\n\t}\n\n\treturn skb;\n}\n\n \nint netvsc_recv_callback(struct net_device *net,\n\t\t\t struct netvsc_device *net_device,\n\t\t\t struct netvsc_channel *nvchan)\n{\n\tstruct net_device_context *net_device_ctx = netdev_priv(net);\n\tstruct vmbus_channel *channel = nvchan->channel;\n\tu16 q_idx = channel->offermsg.offer.sub_channel_index;\n\tstruct sk_buff *skb;\n\tstruct netvsc_stats_rx *rx_stats = &nvchan->rx_stats;\n\tstruct xdp_buff xdp;\n\tu32 act;\n\n\tif (net->reg_state != NETREG_REGISTERED)\n\t\treturn NVSP_STAT_FAIL;\n\n\tact = netvsc_run_xdp(net, nvchan, &xdp);\n\n\tif (act == XDP_REDIRECT)\n\t\treturn NVSP_STAT_SUCCESS;\n\n\tif (act != XDP_PASS && act != XDP_TX) {\n\t\tu64_stats_update_begin(&rx_stats->syncp);\n\t\trx_stats->xdp_drop++;\n\t\tu64_stats_update_end(&rx_stats->syncp);\n\n\t\treturn NVSP_STAT_SUCCESS;  \n\t}\n\n\t \n\tskb = netvsc_alloc_recv_skb(net, nvchan, &xdp);\n\n\tif (unlikely(!skb)) {\n\t\t++net_device_ctx->eth_stats.rx_no_memory;\n\t\treturn NVSP_STAT_FAIL;\n\t}\n\n\tskb_record_rx_queue(skb, q_idx);\n\n\t \n\tu64_stats_update_begin(&rx_stats->syncp);\n\tif (act == XDP_TX)\n\t\trx_stats->xdp_tx++;\n\n\trx_stats->packets++;\n\trx_stats->bytes += nvchan->rsc.pktlen;\n\n\tif (skb->pkt_type == PACKET_BROADCAST)\n\t\t++rx_stats->broadcast;\n\telse if (skb->pkt_type == PACKET_MULTICAST)\n\t\t++rx_stats->multicast;\n\tu64_stats_update_end(&rx_stats->syncp);\n\n\tif (act == XDP_TX) {\n\t\tnetvsc_xdp_xmit(skb, net);\n\t\treturn NVSP_STAT_SUCCESS;\n\t}\n\n\tnapi_gro_receive(&nvchan->napi, skb);\n\treturn NVSP_STAT_SUCCESS;\n}\n\nstatic void netvsc_get_drvinfo(struct net_device *net,\n\t\t\t       struct ethtool_drvinfo *info)\n{\n\tstrscpy(info->driver, KBUILD_MODNAME, sizeof(info->driver));\n\tstrscpy(info->fw_version, \"N/A\", sizeof(info->fw_version));\n}\n\nstatic void netvsc_get_channels(struct net_device *net,\n\t\t\t\tstruct ethtool_channels *channel)\n{\n\tstruct net_device_context *net_device_ctx = netdev_priv(net);\n\tstruct netvsc_device *nvdev = rtnl_dereference(net_device_ctx->nvdev);\n\n\tif (nvdev) {\n\t\tchannel->max_combined\t= nvdev->max_chn;\n\t\tchannel->combined_count = nvdev->num_chn;\n\t}\n}\n\n \nstatic\nstruct netvsc_device_info *netvsc_devinfo_get(struct netvsc_device *nvdev)\n{\n\tstruct netvsc_device_info *dev_info;\n\tstruct bpf_prog *prog;\n\n\tdev_info = kzalloc(sizeof(*dev_info), GFP_ATOMIC);\n\n\tif (!dev_info)\n\t\treturn NULL;\n\n\tif (nvdev) {\n\t\tASSERT_RTNL();\n\n\t\tdev_info->num_chn = nvdev->num_chn;\n\t\tdev_info->send_sections = nvdev->send_section_cnt;\n\t\tdev_info->send_section_size = nvdev->send_section_size;\n\t\tdev_info->recv_sections = nvdev->recv_section_cnt;\n\t\tdev_info->recv_section_size = nvdev->recv_section_size;\n\n\t\tmemcpy(dev_info->rss_key, nvdev->extension->rss_key,\n\t\t       NETVSC_HASH_KEYLEN);\n\n\t\tprog = netvsc_xdp_get(nvdev);\n\t\tif (prog) {\n\t\t\tbpf_prog_inc(prog);\n\t\t\tdev_info->bprog = prog;\n\t\t}\n\t} else {\n\t\tdev_info->num_chn = VRSS_CHANNEL_DEFAULT;\n\t\tdev_info->send_sections = NETVSC_DEFAULT_TX;\n\t\tdev_info->send_section_size = NETVSC_SEND_SECTION_SIZE;\n\t\tdev_info->recv_sections = NETVSC_DEFAULT_RX;\n\t\tdev_info->recv_section_size = NETVSC_RECV_SECTION_SIZE;\n\t}\n\n\treturn dev_info;\n}\n\n \nstatic void netvsc_devinfo_put(struct netvsc_device_info *dev_info)\n{\n\tif (dev_info->bprog) {\n\t\tASSERT_RTNL();\n\t\tbpf_prog_put(dev_info->bprog);\n\t}\n\n\tkfree(dev_info);\n}\n\nstatic int netvsc_detach(struct net_device *ndev,\n\t\t\t struct netvsc_device *nvdev)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(ndev);\n\tstruct hv_device *hdev = ndev_ctx->device_ctx;\n\tint ret;\n\n\t \n\tif (cancel_work_sync(&nvdev->subchan_work))\n\t\tnvdev->num_chn = 1;\n\n\tnetvsc_xdp_set(ndev, NULL, NULL, nvdev);\n\n\t \n\tif (netif_running(ndev)) {\n\t\tnetvsc_tx_disable(nvdev, ndev);\n\n\t\tret = rndis_filter_close(nvdev);\n\t\tif (ret) {\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"unable to close device (ret %d).\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = netvsc_wait_until_empty(nvdev);\n\t\tif (ret) {\n\t\t\tnetdev_err(ndev,\n\t\t\t\t   \"Ring buffer not empty after closing rndis\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tnetif_device_detach(ndev);\n\n\trndis_filter_device_remove(hdev, nvdev);\n\n\treturn 0;\n}\n\nstatic int netvsc_attach(struct net_device *ndev,\n\t\t\t struct netvsc_device_info *dev_info)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(ndev);\n\tstruct hv_device *hdev = ndev_ctx->device_ctx;\n\tstruct netvsc_device *nvdev;\n\tstruct rndis_device *rdev;\n\tstruct bpf_prog *prog;\n\tint ret = 0;\n\n\tnvdev = rndis_filter_device_add(hdev, dev_info);\n\tif (IS_ERR(nvdev))\n\t\treturn PTR_ERR(nvdev);\n\n\tif (nvdev->num_chn > 1) {\n\t\tret = rndis_set_subchannel(ndev, nvdev, dev_info);\n\n\t\t \n\t\tif (ret) {\n\t\t\tnvdev->max_chn = 1;\n\t\t\tnvdev->num_chn = 1;\n\t\t}\n\t}\n\n\tprog = dev_info->bprog;\n\tif (prog) {\n\t\tbpf_prog_inc(prog);\n\t\tret = netvsc_xdp_set(ndev, prog, NULL, nvdev);\n\t\tif (ret) {\n\t\t\tbpf_prog_put(prog);\n\t\t\tgoto err1;\n\t\t}\n\t}\n\n\t \n\tnvdev->tx_disable = false;\n\tnetif_device_attach(ndev);\n\n\t \n\tnetif_carrier_off(ndev);\n\n\tif (netif_running(ndev)) {\n\t\tret = rndis_filter_open(nvdev);\n\t\tif (ret)\n\t\t\tgoto err2;\n\n\t\trdev = nvdev->extension;\n\t\tif (!rdev->link_state)\n\t\t\tnetif_carrier_on(ndev);\n\t}\n\n\treturn 0;\n\nerr2:\n\tnetif_device_detach(ndev);\n\nerr1:\n\trndis_filter_device_remove(hdev, nvdev);\n\n\treturn ret;\n}\n\nstatic int netvsc_set_channels(struct net_device *net,\n\t\t\t       struct ethtool_channels *channels)\n{\n\tstruct net_device_context *net_device_ctx = netdev_priv(net);\n\tstruct netvsc_device *nvdev = rtnl_dereference(net_device_ctx->nvdev);\n\tunsigned int orig, count = channels->combined_count;\n\tstruct netvsc_device_info *device_info;\n\tint ret;\n\n\t \n\tif (count == 0 ||\n\t    channels->rx_count || channels->tx_count || channels->other_count)\n\t\treturn -EINVAL;\n\n\tif (!nvdev || nvdev->destroy)\n\t\treturn -ENODEV;\n\n\tif (nvdev->nvsp_version < NVSP_PROTOCOL_VERSION_5)\n\t\treturn -EINVAL;\n\n\tif (count > nvdev->max_chn)\n\t\treturn -EINVAL;\n\n\torig = nvdev->num_chn;\n\n\tdevice_info = netvsc_devinfo_get(nvdev);\n\n\tif (!device_info)\n\t\treturn -ENOMEM;\n\n\tdevice_info->num_chn = count;\n\n\tret = netvsc_detach(net, nvdev);\n\tif (ret)\n\t\tgoto out;\n\n\tret = netvsc_attach(net, device_info);\n\tif (ret) {\n\t\tdevice_info->num_chn = orig;\n\t\tif (netvsc_attach(net, device_info))\n\t\t\tnetdev_err(net, \"restoring channel setting failed\\n\");\n\t}\n\nout:\n\tnetvsc_devinfo_put(device_info);\n\treturn ret;\n}\n\nstatic void netvsc_init_settings(struct net_device *dev)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\n\tndc->l4_hash = HV_DEFAULT_L4HASH;\n\n\tndc->speed = SPEED_UNKNOWN;\n\tndc->duplex = DUPLEX_FULL;\n\n\tdev->features = NETIF_F_LRO;\n}\n\nstatic int netvsc_get_link_ksettings(struct net_device *dev,\n\t\t\t\t     struct ethtool_link_ksettings *cmd)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct net_device *vf_netdev;\n\n\tvf_netdev = rtnl_dereference(ndc->vf_netdev);\n\n\tif (vf_netdev)\n\t\treturn __ethtool_get_link_ksettings(vf_netdev, cmd);\n\n\tcmd->base.speed = ndc->speed;\n\tcmd->base.duplex = ndc->duplex;\n\tcmd->base.port = PORT_OTHER;\n\n\treturn 0;\n}\n\nstatic int netvsc_set_link_ksettings(struct net_device *dev,\n\t\t\t\t     const struct ethtool_link_ksettings *cmd)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct net_device *vf_netdev = rtnl_dereference(ndc->vf_netdev);\n\n\tif (vf_netdev) {\n\t\tif (!vf_netdev->ethtool_ops->set_link_ksettings)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\treturn vf_netdev->ethtool_ops->set_link_ksettings(vf_netdev,\n\t\t\t\t\t\t\t\t  cmd);\n\t}\n\n\treturn ethtool_virtdev_set_link_ksettings(dev, cmd,\n\t\t\t\t\t\t  &ndc->speed, &ndc->duplex);\n}\n\nstatic int netvsc_change_mtu(struct net_device *ndev, int mtu)\n{\n\tstruct net_device_context *ndevctx = netdev_priv(ndev);\n\tstruct net_device *vf_netdev = rtnl_dereference(ndevctx->vf_netdev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);\n\tint orig_mtu = ndev->mtu;\n\tstruct netvsc_device_info *device_info;\n\tint ret = 0;\n\n\tif (!nvdev || nvdev->destroy)\n\t\treturn -ENODEV;\n\n\tdevice_info = netvsc_devinfo_get(nvdev);\n\n\tif (!device_info)\n\t\treturn -ENOMEM;\n\n\t \n\tif (vf_netdev) {\n\t\tret = dev_set_mtu(vf_netdev, mtu);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tret = netvsc_detach(ndev, nvdev);\n\tif (ret)\n\t\tgoto rollback_vf;\n\n\tndev->mtu = mtu;\n\n\tret = netvsc_attach(ndev, device_info);\n\tif (!ret)\n\t\tgoto out;\n\n\t \n\tndev->mtu = orig_mtu;\n\n\tif (netvsc_attach(ndev, device_info))\n\t\tnetdev_err(ndev, \"restoring mtu failed\\n\");\nrollback_vf:\n\tif (vf_netdev)\n\t\tdev_set_mtu(vf_netdev, orig_mtu);\n\nout:\n\tnetvsc_devinfo_put(device_info);\n\treturn ret;\n}\n\nstatic void netvsc_get_vf_stats(struct net_device *net,\n\t\t\t\tstruct netvsc_vf_pcpu_stats *tot)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tint i;\n\n\tmemset(tot, 0, sizeof(*tot));\n\n\tfor_each_possible_cpu(i) {\n\t\tconst struct netvsc_vf_pcpu_stats *stats\n\t\t\t= per_cpu_ptr(ndev_ctx->vf_stats, i);\n\t\tu64 rx_packets, rx_bytes, tx_packets, tx_bytes;\n\t\tunsigned int start;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&stats->syncp);\n\t\t\trx_packets = stats->rx_packets;\n\t\t\ttx_packets = stats->tx_packets;\n\t\t\trx_bytes = stats->rx_bytes;\n\t\t\ttx_bytes = stats->tx_bytes;\n\t\t} while (u64_stats_fetch_retry(&stats->syncp, start));\n\n\t\ttot->rx_packets += rx_packets;\n\t\ttot->tx_packets += tx_packets;\n\t\ttot->rx_bytes   += rx_bytes;\n\t\ttot->tx_bytes   += tx_bytes;\n\t\ttot->tx_dropped += stats->tx_dropped;\n\t}\n}\n\nstatic void netvsc_get_pcpu_stats(struct net_device *net,\n\t\t\t\t  struct netvsc_ethtool_pcpu_stats *pcpu_tot)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tstruct netvsc_device *nvdev = rcu_dereference_rtnl(ndev_ctx->nvdev);\n\tint i;\n\n\t \n\tfor_each_possible_cpu(i) {\n\t\tconst struct netvsc_vf_pcpu_stats *stats =\n\t\t\tper_cpu_ptr(ndev_ctx->vf_stats, i);\n\t\tstruct netvsc_ethtool_pcpu_stats *this_tot = &pcpu_tot[i];\n\t\tunsigned int start;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&stats->syncp);\n\t\t\tthis_tot->vf_rx_packets = stats->rx_packets;\n\t\t\tthis_tot->vf_tx_packets = stats->tx_packets;\n\t\t\tthis_tot->vf_rx_bytes = stats->rx_bytes;\n\t\t\tthis_tot->vf_tx_bytes = stats->tx_bytes;\n\t\t} while (u64_stats_fetch_retry(&stats->syncp, start));\n\t\tthis_tot->rx_packets = this_tot->vf_rx_packets;\n\t\tthis_tot->tx_packets = this_tot->vf_tx_packets;\n\t\tthis_tot->rx_bytes   = this_tot->vf_rx_bytes;\n\t\tthis_tot->tx_bytes   = this_tot->vf_tx_bytes;\n\t}\n\n\t \n\tfor (i = 0; i < nvdev->num_chn; i++) {\n\t\tconst struct netvsc_channel *nvchan = &nvdev->chan_table[i];\n\t\tconst struct netvsc_stats_tx *tx_stats;\n\t\tconst struct netvsc_stats_rx *rx_stats;\n\t\tstruct netvsc_ethtool_pcpu_stats *this_tot =\n\t\t\t&pcpu_tot[nvchan->channel->target_cpu];\n\t\tu64 packets, bytes;\n\t\tunsigned int start;\n\n\t\ttx_stats = &nvchan->tx_stats;\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&tx_stats->syncp);\n\t\t\tpackets = tx_stats->packets;\n\t\t\tbytes = tx_stats->bytes;\n\t\t} while (u64_stats_fetch_retry(&tx_stats->syncp, start));\n\n\t\tthis_tot->tx_bytes\t+= bytes;\n\t\tthis_tot->tx_packets\t+= packets;\n\n\t\trx_stats = &nvchan->rx_stats;\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&rx_stats->syncp);\n\t\t\tpackets = rx_stats->packets;\n\t\t\tbytes = rx_stats->bytes;\n\t\t} while (u64_stats_fetch_retry(&rx_stats->syncp, start));\n\n\t\tthis_tot->rx_bytes\t+= bytes;\n\t\tthis_tot->rx_packets\t+= packets;\n\t}\n}\n\nstatic void netvsc_get_stats64(struct net_device *net,\n\t\t\t       struct rtnl_link_stats64 *t)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(net);\n\tstruct netvsc_device *nvdev;\n\tstruct netvsc_vf_pcpu_stats vf_tot;\n\tint i;\n\n\trcu_read_lock();\n\n\tnvdev = rcu_dereference(ndev_ctx->nvdev);\n\tif (!nvdev)\n\t\tgoto out;\n\n\tnetdev_stats_to_stats64(t, &net->stats);\n\n\tnetvsc_get_vf_stats(net, &vf_tot);\n\tt->rx_packets += vf_tot.rx_packets;\n\tt->tx_packets += vf_tot.tx_packets;\n\tt->rx_bytes   += vf_tot.rx_bytes;\n\tt->tx_bytes   += vf_tot.tx_bytes;\n\tt->tx_dropped += vf_tot.tx_dropped;\n\n\tfor (i = 0; i < nvdev->num_chn; i++) {\n\t\tconst struct netvsc_channel *nvchan = &nvdev->chan_table[i];\n\t\tconst struct netvsc_stats_tx *tx_stats;\n\t\tconst struct netvsc_stats_rx *rx_stats;\n\t\tu64 packets, bytes, multicast;\n\t\tunsigned int start;\n\n\t\ttx_stats = &nvchan->tx_stats;\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&tx_stats->syncp);\n\t\t\tpackets = tx_stats->packets;\n\t\t\tbytes = tx_stats->bytes;\n\t\t} while (u64_stats_fetch_retry(&tx_stats->syncp, start));\n\n\t\tt->tx_bytes\t+= bytes;\n\t\tt->tx_packets\t+= packets;\n\n\t\trx_stats = &nvchan->rx_stats;\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&rx_stats->syncp);\n\t\t\tpackets = rx_stats->packets;\n\t\t\tbytes = rx_stats->bytes;\n\t\t\tmulticast = rx_stats->multicast + rx_stats->broadcast;\n\t\t} while (u64_stats_fetch_retry(&rx_stats->syncp, start));\n\n\t\tt->rx_bytes\t+= bytes;\n\t\tt->rx_packets\t+= packets;\n\t\tt->multicast\t+= multicast;\n\t}\nout:\n\trcu_read_unlock();\n}\n\nstatic int netvsc_set_mac_addr(struct net_device *ndev, void *p)\n{\n\tstruct net_device_context *ndc = netdev_priv(ndev);\n\tstruct net_device *vf_netdev = rtnl_dereference(ndc->vf_netdev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndc->nvdev);\n\tstruct sockaddr *addr = p;\n\tint err;\n\n\terr = eth_prepare_mac_addr_change(ndev, p);\n\tif (err)\n\t\treturn err;\n\n\tif (!nvdev)\n\t\treturn -ENODEV;\n\n\tif (vf_netdev) {\n\t\terr = dev_set_mac_address(vf_netdev, addr, NULL);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = rndis_filter_set_device_mac(nvdev, addr->sa_data);\n\tif (!err) {\n\t\teth_commit_mac_addr_change(ndev, p);\n\t} else if (vf_netdev) {\n\t\t \n\t\tmemcpy(addr->sa_data, ndev->dev_addr, ETH_ALEN);\n\t\tdev_set_mac_address(vf_netdev, addr, NULL);\n\t}\n\n\treturn err;\n}\n\nstatic const struct {\n\tchar name[ETH_GSTRING_LEN];\n\tu16 offset;\n} netvsc_stats[] = {\n\t{ \"tx_scattered\", offsetof(struct netvsc_ethtool_stats, tx_scattered) },\n\t{ \"tx_no_memory\", offsetof(struct netvsc_ethtool_stats, tx_no_memory) },\n\t{ \"tx_no_space\",  offsetof(struct netvsc_ethtool_stats, tx_no_space) },\n\t{ \"tx_too_big\",\t  offsetof(struct netvsc_ethtool_stats, tx_too_big) },\n\t{ \"tx_busy\",\t  offsetof(struct netvsc_ethtool_stats, tx_busy) },\n\t{ \"tx_send_full\", offsetof(struct netvsc_ethtool_stats, tx_send_full) },\n\t{ \"rx_comp_busy\", offsetof(struct netvsc_ethtool_stats, rx_comp_busy) },\n\t{ \"rx_no_memory\", offsetof(struct netvsc_ethtool_stats, rx_no_memory) },\n\t{ \"stop_queue\", offsetof(struct netvsc_ethtool_stats, stop_queue) },\n\t{ \"wake_queue\", offsetof(struct netvsc_ethtool_stats, wake_queue) },\n\t{ \"vlan_error\", offsetof(struct netvsc_ethtool_stats, vlan_error) },\n}, pcpu_stats[] = {\n\t{ \"cpu%u_rx_packets\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, rx_packets) },\n\t{ \"cpu%u_rx_bytes\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, rx_bytes) },\n\t{ \"cpu%u_tx_packets\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, tx_packets) },\n\t{ \"cpu%u_tx_bytes\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, tx_bytes) },\n\t{ \"cpu%u_vf_rx_packets\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, vf_rx_packets) },\n\t{ \"cpu%u_vf_rx_bytes\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, vf_rx_bytes) },\n\t{ \"cpu%u_vf_tx_packets\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, vf_tx_packets) },\n\t{ \"cpu%u_vf_tx_bytes\",\n\t\toffsetof(struct netvsc_ethtool_pcpu_stats, vf_tx_bytes) },\n}, vf_stats[] = {\n\t{ \"vf_rx_packets\", offsetof(struct netvsc_vf_pcpu_stats, rx_packets) },\n\t{ \"vf_rx_bytes\",   offsetof(struct netvsc_vf_pcpu_stats, rx_bytes) },\n\t{ \"vf_tx_packets\", offsetof(struct netvsc_vf_pcpu_stats, tx_packets) },\n\t{ \"vf_tx_bytes\",   offsetof(struct netvsc_vf_pcpu_stats, tx_bytes) },\n\t{ \"vf_tx_dropped\", offsetof(struct netvsc_vf_pcpu_stats, tx_dropped) },\n};\n\n#define NETVSC_GLOBAL_STATS_LEN\tARRAY_SIZE(netvsc_stats)\n#define NETVSC_VF_STATS_LEN\tARRAY_SIZE(vf_stats)\n\n \n#define NETVSC_PCPU_STATS_LEN (num_present_cpus() * ARRAY_SIZE(pcpu_stats))\n\n \n#define NETVSC_QUEUE_STATS_LEN(dev) ((dev)->num_chn * 8)\n\nstatic int netvsc_get_sset_count(struct net_device *dev, int string_set)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndc->nvdev);\n\n\tif (!nvdev)\n\t\treturn -ENODEV;\n\n\tswitch (string_set) {\n\tcase ETH_SS_STATS:\n\t\treturn NETVSC_GLOBAL_STATS_LEN\n\t\t\t+ NETVSC_VF_STATS_LEN\n\t\t\t+ NETVSC_QUEUE_STATS_LEN(nvdev)\n\t\t\t+ NETVSC_PCPU_STATS_LEN;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void netvsc_get_ethtool_stats(struct net_device *dev,\n\t\t\t\t     struct ethtool_stats *stats, u64 *data)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndc->nvdev);\n\tconst void *nds = &ndc->eth_stats;\n\tconst struct netvsc_stats_tx *tx_stats;\n\tconst struct netvsc_stats_rx *rx_stats;\n\tstruct netvsc_vf_pcpu_stats sum;\n\tstruct netvsc_ethtool_pcpu_stats *pcpu_sum;\n\tunsigned int start;\n\tu64 packets, bytes;\n\tu64 xdp_drop;\n\tu64 xdp_redirect;\n\tu64 xdp_tx;\n\tu64 xdp_xmit;\n\tint i, j, cpu;\n\n\tif (!nvdev)\n\t\treturn;\n\n\tfor (i = 0; i < NETVSC_GLOBAL_STATS_LEN; i++)\n\t\tdata[i] = *(unsigned long *)(nds + netvsc_stats[i].offset);\n\n\tnetvsc_get_vf_stats(dev, &sum);\n\tfor (j = 0; j < NETVSC_VF_STATS_LEN; j++)\n\t\tdata[i++] = *(u64 *)((void *)&sum + vf_stats[j].offset);\n\n\tfor (j = 0; j < nvdev->num_chn; j++) {\n\t\ttx_stats = &nvdev->chan_table[j].tx_stats;\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&tx_stats->syncp);\n\t\t\tpackets = tx_stats->packets;\n\t\t\tbytes = tx_stats->bytes;\n\t\t\txdp_xmit = tx_stats->xdp_xmit;\n\t\t} while (u64_stats_fetch_retry(&tx_stats->syncp, start));\n\t\tdata[i++] = packets;\n\t\tdata[i++] = bytes;\n\t\tdata[i++] = xdp_xmit;\n\n\t\trx_stats = &nvdev->chan_table[j].rx_stats;\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&rx_stats->syncp);\n\t\t\tpackets = rx_stats->packets;\n\t\t\tbytes = rx_stats->bytes;\n\t\t\txdp_drop = rx_stats->xdp_drop;\n\t\t\txdp_redirect = rx_stats->xdp_redirect;\n\t\t\txdp_tx = rx_stats->xdp_tx;\n\t\t} while (u64_stats_fetch_retry(&rx_stats->syncp, start));\n\t\tdata[i++] = packets;\n\t\tdata[i++] = bytes;\n\t\tdata[i++] = xdp_drop;\n\t\tdata[i++] = xdp_redirect;\n\t\tdata[i++] = xdp_tx;\n\t}\n\n\tpcpu_sum = kvmalloc_array(num_possible_cpus(),\n\t\t\t\t  sizeof(struct netvsc_ethtool_pcpu_stats),\n\t\t\t\t  GFP_KERNEL);\n\tif (!pcpu_sum)\n\t\treturn;\n\n\tnetvsc_get_pcpu_stats(dev, pcpu_sum);\n\tfor_each_present_cpu(cpu) {\n\t\tstruct netvsc_ethtool_pcpu_stats *this_sum = &pcpu_sum[cpu];\n\n\t\tfor (j = 0; j < ARRAY_SIZE(pcpu_stats); j++)\n\t\t\tdata[i++] = *(u64 *)((void *)this_sum\n\t\t\t\t\t     + pcpu_stats[j].offset);\n\t}\n\tkvfree(pcpu_sum);\n}\n\nstatic void netvsc_get_strings(struct net_device *dev, u32 stringset, u8 *data)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndc->nvdev);\n\tu8 *p = data;\n\tint i, cpu;\n\n\tif (!nvdev)\n\t\treturn;\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tfor (i = 0; i < ARRAY_SIZE(netvsc_stats); i++)\n\t\t\tethtool_sprintf(&p, netvsc_stats[i].name);\n\n\t\tfor (i = 0; i < ARRAY_SIZE(vf_stats); i++)\n\t\t\tethtool_sprintf(&p, vf_stats[i].name);\n\n\t\tfor (i = 0; i < nvdev->num_chn; i++) {\n\t\t\tethtool_sprintf(&p, \"tx_queue_%u_packets\", i);\n\t\t\tethtool_sprintf(&p, \"tx_queue_%u_bytes\", i);\n\t\t\tethtool_sprintf(&p, \"tx_queue_%u_xdp_xmit\", i);\n\t\t\tethtool_sprintf(&p, \"rx_queue_%u_packets\", i);\n\t\t\tethtool_sprintf(&p, \"rx_queue_%u_bytes\", i);\n\t\t\tethtool_sprintf(&p, \"rx_queue_%u_xdp_drop\", i);\n\t\t\tethtool_sprintf(&p, \"rx_queue_%u_xdp_redirect\", i);\n\t\t\tethtool_sprintf(&p, \"rx_queue_%u_xdp_tx\", i);\n\t\t}\n\n\t\tfor_each_present_cpu(cpu) {\n\t\t\tfor (i = 0; i < ARRAY_SIZE(pcpu_stats); i++)\n\t\t\t\tethtool_sprintf(&p, pcpu_stats[i].name, cpu);\n\t\t}\n\n\t\tbreak;\n\t}\n}\n\nstatic int\nnetvsc_get_rss_hash_opts(struct net_device_context *ndc,\n\t\t\t struct ethtool_rxnfc *info)\n{\n\tconst u32 l4_flag = RXH_L4_B_0_1 | RXH_L4_B_2_3;\n\n\tinfo->data = RXH_IP_SRC | RXH_IP_DST;\n\n\tswitch (info->flow_type) {\n\tcase TCP_V4_FLOW:\n\t\tif (ndc->l4_hash & HV_TCP4_L4HASH)\n\t\t\tinfo->data |= l4_flag;\n\n\t\tbreak;\n\n\tcase TCP_V6_FLOW:\n\t\tif (ndc->l4_hash & HV_TCP6_L4HASH)\n\t\t\tinfo->data |= l4_flag;\n\n\t\tbreak;\n\n\tcase UDP_V4_FLOW:\n\t\tif (ndc->l4_hash & HV_UDP4_L4HASH)\n\t\t\tinfo->data |= l4_flag;\n\n\t\tbreak;\n\n\tcase UDP_V6_FLOW:\n\t\tif (ndc->l4_hash & HV_UDP6_L4HASH)\n\t\t\tinfo->data |= l4_flag;\n\n\t\tbreak;\n\n\tcase IPV4_FLOW:\n\tcase IPV6_FLOW:\n\t\tbreak;\n\tdefault:\n\t\tinfo->data = 0;\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nnetvsc_get_rxnfc(struct net_device *dev, struct ethtool_rxnfc *info,\n\t\t u32 *rules)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndc->nvdev);\n\n\tif (!nvdev)\n\t\treturn -ENODEV;\n\n\tswitch (info->cmd) {\n\tcase ETHTOOL_GRXRINGS:\n\t\tinfo->data = nvdev->num_chn;\n\t\treturn 0;\n\n\tcase ETHTOOL_GRXFH:\n\t\treturn netvsc_get_rss_hash_opts(ndc, info);\n\t}\n\treturn -EOPNOTSUPP;\n}\n\nstatic int netvsc_set_rss_hash_opts(struct net_device_context *ndc,\n\t\t\t\t    struct ethtool_rxnfc *info)\n{\n\tif (info->data == (RXH_IP_SRC | RXH_IP_DST |\n\t\t\t   RXH_L4_B_0_1 | RXH_L4_B_2_3)) {\n\t\tswitch (info->flow_type) {\n\t\tcase TCP_V4_FLOW:\n\t\t\tndc->l4_hash |= HV_TCP4_L4HASH;\n\t\t\tbreak;\n\n\t\tcase TCP_V6_FLOW:\n\t\t\tndc->l4_hash |= HV_TCP6_L4HASH;\n\t\t\tbreak;\n\n\t\tcase UDP_V4_FLOW:\n\t\t\tndc->l4_hash |= HV_UDP4_L4HASH;\n\t\t\tbreak;\n\n\t\tcase UDP_V6_FLOW:\n\t\t\tndc->l4_hash |= HV_UDP6_L4HASH;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tif (info->data == (RXH_IP_SRC | RXH_IP_DST)) {\n\t\tswitch (info->flow_type) {\n\t\tcase TCP_V4_FLOW:\n\t\t\tndc->l4_hash &= ~HV_TCP4_L4HASH;\n\t\t\tbreak;\n\n\t\tcase TCP_V6_FLOW:\n\t\t\tndc->l4_hash &= ~HV_TCP6_L4HASH;\n\t\t\tbreak;\n\n\t\tcase UDP_V4_FLOW:\n\t\t\tndc->l4_hash &= ~HV_UDP4_L4HASH;\n\t\t\tbreak;\n\n\t\tcase UDP_V6_FLOW:\n\t\t\tndc->l4_hash &= ~HV_UDP6_L4HASH;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int\nnetvsc_set_rxnfc(struct net_device *ndev, struct ethtool_rxnfc *info)\n{\n\tstruct net_device_context *ndc = netdev_priv(ndev);\n\n\tif (info->cmd == ETHTOOL_SRXFH)\n\t\treturn netvsc_set_rss_hash_opts(ndc, info);\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic u32 netvsc_get_rxfh_key_size(struct net_device *dev)\n{\n\treturn NETVSC_HASH_KEYLEN;\n}\n\nstatic u32 netvsc_rss_indir_size(struct net_device *dev)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\n\treturn ndc->rx_table_sz;\n}\n\nstatic int netvsc_get_rxfh(struct net_device *dev, u32 *indir, u8 *key,\n\t\t\t   u8 *hfunc)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct netvsc_device *ndev = rtnl_dereference(ndc->nvdev);\n\tstruct rndis_device *rndis_dev;\n\tint i;\n\n\tif (!ndev)\n\t\treturn -ENODEV;\n\n\tif (hfunc)\n\t\t*hfunc = ETH_RSS_HASH_TOP;\t \n\n\trndis_dev = ndev->extension;\n\tif (indir) {\n\t\tfor (i = 0; i < ndc->rx_table_sz; i++)\n\t\t\tindir[i] = ndc->rx_table[i];\n\t}\n\n\tif (key)\n\t\tmemcpy(key, rndis_dev->rss_key, NETVSC_HASH_KEYLEN);\n\n\treturn 0;\n}\n\nstatic int netvsc_set_rxfh(struct net_device *dev, const u32 *indir,\n\t\t\t   const u8 *key, const u8 hfunc)\n{\n\tstruct net_device_context *ndc = netdev_priv(dev);\n\tstruct netvsc_device *ndev = rtnl_dereference(ndc->nvdev);\n\tstruct rndis_device *rndis_dev;\n\tint i;\n\n\tif (!ndev)\n\t\treturn -ENODEV;\n\n\tif (hfunc != ETH_RSS_HASH_NO_CHANGE && hfunc != ETH_RSS_HASH_TOP)\n\t\treturn -EOPNOTSUPP;\n\n\trndis_dev = ndev->extension;\n\tif (indir) {\n\t\tfor (i = 0; i < ndc->rx_table_sz; i++)\n\t\t\tif (indir[i] >= ndev->num_chn)\n\t\t\t\treturn -EINVAL;\n\n\t\tfor (i = 0; i < ndc->rx_table_sz; i++)\n\t\t\tndc->rx_table[i] = indir[i];\n\t}\n\n\tif (!key) {\n\t\tif (!indir)\n\t\t\treturn 0;\n\n\t\tkey = rndis_dev->rss_key;\n\t}\n\n\treturn rndis_filter_set_rss_param(rndis_dev, key);\n}\n\n \nstatic void __netvsc_get_ringparam(struct netvsc_device *nvdev,\n\t\t\t\t   struct ethtool_ringparam *ring)\n{\n\tu32 max_buf_size;\n\n\tring->rx_pending = nvdev->recv_section_cnt;\n\tring->tx_pending = nvdev->send_section_cnt;\n\n\tif (nvdev->nvsp_version <= NVSP_PROTOCOL_VERSION_2)\n\t\tmax_buf_size = NETVSC_RECEIVE_BUFFER_SIZE_LEGACY;\n\telse\n\t\tmax_buf_size = NETVSC_RECEIVE_BUFFER_SIZE;\n\n\tring->rx_max_pending = max_buf_size / nvdev->recv_section_size;\n\tring->tx_max_pending = NETVSC_SEND_BUFFER_SIZE\n\t\t/ nvdev->send_section_size;\n}\n\nstatic void netvsc_get_ringparam(struct net_device *ndev,\n\t\t\t\t struct ethtool_ringparam *ring,\n\t\t\t\t struct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct net_device_context *ndevctx = netdev_priv(ndev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);\n\n\tif (!nvdev)\n\t\treturn;\n\n\t__netvsc_get_ringparam(nvdev, ring);\n}\n\nstatic int netvsc_set_ringparam(struct net_device *ndev,\n\t\t\t\tstruct ethtool_ringparam *ring,\n\t\t\t\tstruct kernel_ethtool_ringparam *kernel_ring,\n\t\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct net_device_context *ndevctx = netdev_priv(ndev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);\n\tstruct netvsc_device_info *device_info;\n\tstruct ethtool_ringparam orig;\n\tu32 new_tx, new_rx;\n\tint ret = 0;\n\n\tif (!nvdev || nvdev->destroy)\n\t\treturn -ENODEV;\n\n\tmemset(&orig, 0, sizeof(orig));\n\t__netvsc_get_ringparam(nvdev, &orig);\n\n\tnew_tx = clamp_t(u32, ring->tx_pending,\n\t\t\t NETVSC_MIN_TX_SECTIONS, orig.tx_max_pending);\n\tnew_rx = clamp_t(u32, ring->rx_pending,\n\t\t\t NETVSC_MIN_RX_SECTIONS, orig.rx_max_pending);\n\n\tif (new_tx == orig.tx_pending &&\n\t    new_rx == orig.rx_pending)\n\t\treturn 0;\t  \n\n\tdevice_info = netvsc_devinfo_get(nvdev);\n\n\tif (!device_info)\n\t\treturn -ENOMEM;\n\n\tdevice_info->send_sections = new_tx;\n\tdevice_info->recv_sections = new_rx;\n\n\tret = netvsc_detach(ndev, nvdev);\n\tif (ret)\n\t\tgoto out;\n\n\tret = netvsc_attach(ndev, device_info);\n\tif (ret) {\n\t\tdevice_info->send_sections = orig.tx_pending;\n\t\tdevice_info->recv_sections = orig.rx_pending;\n\n\t\tif (netvsc_attach(ndev, device_info))\n\t\t\tnetdev_err(ndev, \"restoring ringparam failed\");\n\t}\n\nout:\n\tnetvsc_devinfo_put(device_info);\n\treturn ret;\n}\n\nstatic netdev_features_t netvsc_fix_features(struct net_device *ndev,\n\t\t\t\t\t     netdev_features_t features)\n{\n\tstruct net_device_context *ndevctx = netdev_priv(ndev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);\n\n\tif (!nvdev || nvdev->destroy)\n\t\treturn features;\n\n\tif ((features & NETIF_F_LRO) && netvsc_xdp_get(nvdev)) {\n\t\tfeatures ^= NETIF_F_LRO;\n\t\tnetdev_info(ndev, \"Skip LRO - unsupported with XDP\\n\");\n\t}\n\n\treturn features;\n}\n\nstatic int netvsc_set_features(struct net_device *ndev,\n\t\t\t       netdev_features_t features)\n{\n\tnetdev_features_t change = features ^ ndev->features;\n\tstruct net_device_context *ndevctx = netdev_priv(ndev);\n\tstruct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);\n\tstruct net_device *vf_netdev = rtnl_dereference(ndevctx->vf_netdev);\n\tstruct ndis_offload_params offloads;\n\tint ret = 0;\n\n\tif (!nvdev || nvdev->destroy)\n\t\treturn -ENODEV;\n\n\tif (!(change & NETIF_F_LRO))\n\t\tgoto syncvf;\n\n\tmemset(&offloads, 0, sizeof(struct ndis_offload_params));\n\n\tif (features & NETIF_F_LRO) {\n\t\toffloads.rsc_ip_v4 = NDIS_OFFLOAD_PARAMETERS_RSC_ENABLED;\n\t\toffloads.rsc_ip_v6 = NDIS_OFFLOAD_PARAMETERS_RSC_ENABLED;\n\t} else {\n\t\toffloads.rsc_ip_v4 = NDIS_OFFLOAD_PARAMETERS_RSC_DISABLED;\n\t\toffloads.rsc_ip_v6 = NDIS_OFFLOAD_PARAMETERS_RSC_DISABLED;\n\t}\n\n\tret = rndis_filter_set_offload_params(ndev, nvdev, &offloads);\n\n\tif (ret) {\n\t\tfeatures ^= NETIF_F_LRO;\n\t\tndev->features = features;\n\t}\n\nsyncvf:\n\tif (!vf_netdev)\n\t\treturn ret;\n\n\tvf_netdev->wanted_features = features;\n\tnetdev_update_features(vf_netdev);\n\n\treturn ret;\n}\n\nstatic int netvsc_get_regs_len(struct net_device *netdev)\n{\n\treturn VRSS_SEND_TAB_SIZE * sizeof(u32);\n}\n\nstatic void netvsc_get_regs(struct net_device *netdev,\n\t\t\t    struct ethtool_regs *regs, void *p)\n{\n\tstruct net_device_context *ndc = netdev_priv(netdev);\n\tu32 *regs_buff = p;\n\n\t \n\tregs->version = 1;\n\n\tmemcpy(regs_buff, ndc->tx_table, VRSS_SEND_TAB_SIZE * sizeof(u32));\n}\n\nstatic u32 netvsc_get_msglevel(struct net_device *ndev)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(ndev);\n\n\treturn ndev_ctx->msg_enable;\n}\n\nstatic void netvsc_set_msglevel(struct net_device *ndev, u32 val)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(ndev);\n\n\tndev_ctx->msg_enable = val;\n}\n\nstatic const struct ethtool_ops ethtool_ops = {\n\t.get_drvinfo\t= netvsc_get_drvinfo,\n\t.get_regs_len\t= netvsc_get_regs_len,\n\t.get_regs\t= netvsc_get_regs,\n\t.get_msglevel\t= netvsc_get_msglevel,\n\t.set_msglevel\t= netvsc_set_msglevel,\n\t.get_link\t= ethtool_op_get_link,\n\t.get_ethtool_stats = netvsc_get_ethtool_stats,\n\t.get_sset_count = netvsc_get_sset_count,\n\t.get_strings\t= netvsc_get_strings,\n\t.get_channels   = netvsc_get_channels,\n\t.set_channels   = netvsc_set_channels,\n\t.get_ts_info\t= ethtool_op_get_ts_info,\n\t.get_rxnfc\t= netvsc_get_rxnfc,\n\t.set_rxnfc\t= netvsc_set_rxnfc,\n\t.get_rxfh_key_size = netvsc_get_rxfh_key_size,\n\t.get_rxfh_indir_size = netvsc_rss_indir_size,\n\t.get_rxfh\t= netvsc_get_rxfh,\n\t.set_rxfh\t= netvsc_set_rxfh,\n\t.get_link_ksettings = netvsc_get_link_ksettings,\n\t.set_link_ksettings = netvsc_set_link_ksettings,\n\t.get_ringparam\t= netvsc_get_ringparam,\n\t.set_ringparam\t= netvsc_set_ringparam,\n};\n\nstatic const struct net_device_ops device_ops = {\n\t.ndo_open =\t\t\tnetvsc_open,\n\t.ndo_stop =\t\t\tnetvsc_close,\n\t.ndo_start_xmit =\t\tnetvsc_start_xmit,\n\t.ndo_change_rx_flags =\t\tnetvsc_change_rx_flags,\n\t.ndo_set_rx_mode =\t\tnetvsc_set_rx_mode,\n\t.ndo_fix_features =\t\tnetvsc_fix_features,\n\t.ndo_set_features =\t\tnetvsc_set_features,\n\t.ndo_change_mtu =\t\tnetvsc_change_mtu,\n\t.ndo_validate_addr =\t\teth_validate_addr,\n\t.ndo_set_mac_address =\t\tnetvsc_set_mac_addr,\n\t.ndo_select_queue =\t\tnetvsc_select_queue,\n\t.ndo_get_stats64 =\t\tnetvsc_get_stats64,\n\t.ndo_bpf =\t\t\tnetvsc_bpf,\n\t.ndo_xdp_xmit =\t\t\tnetvsc_ndoxdp_xmit,\n};\n\n \nstatic void netvsc_link_change(struct work_struct *w)\n{\n\tstruct net_device_context *ndev_ctx =\n\t\tcontainer_of(w, struct net_device_context, dwork.work);\n\tstruct hv_device *device_obj = ndev_ctx->device_ctx;\n\tstruct net_device *net = hv_get_drvdata(device_obj);\n\tunsigned long flags, next_reconfig, delay;\n\tstruct netvsc_reconfig *event = NULL;\n\tstruct netvsc_device *net_device;\n\tstruct rndis_device *rdev;\n\tbool reschedule = false;\n\n\t \n\tif (!rtnl_trylock()) {\n\t\tschedule_delayed_work(&ndev_ctx->dwork, LINKCHANGE_INT);\n\t\treturn;\n\t}\n\n\tnet_device = rtnl_dereference(ndev_ctx->nvdev);\n\tif (!net_device)\n\t\tgoto out_unlock;\n\n\trdev = net_device->extension;\n\n\tnext_reconfig = ndev_ctx->last_reconfig + LINKCHANGE_INT;\n\tif (time_is_after_jiffies(next_reconfig)) {\n\t\t \n\t\tdelay = next_reconfig - jiffies;\n\t\tdelay = delay < LINKCHANGE_INT ? delay : LINKCHANGE_INT;\n\t\tschedule_delayed_work(&ndev_ctx->dwork, delay);\n\t\tgoto out_unlock;\n\t}\n\tndev_ctx->last_reconfig = jiffies;\n\n\tspin_lock_irqsave(&ndev_ctx->lock, flags);\n\tif (!list_empty(&ndev_ctx->reconfig_events)) {\n\t\tevent = list_first_entry(&ndev_ctx->reconfig_events,\n\t\t\t\t\t struct netvsc_reconfig, list);\n\t\tlist_del(&event->list);\n\t\treschedule = !list_empty(&ndev_ctx->reconfig_events);\n\t}\n\tspin_unlock_irqrestore(&ndev_ctx->lock, flags);\n\n\tif (!event)\n\t\tgoto out_unlock;\n\n\tswitch (event->event) {\n\t\t \n\tcase RNDIS_STATUS_MEDIA_CONNECT:\n\t\tif (rdev->link_state) {\n\t\t\trdev->link_state = false;\n\t\t\tnetif_carrier_on(net);\n\t\t\tnetvsc_tx_enable(net_device, net);\n\t\t} else {\n\t\t\t__netdev_notify_peers(net);\n\t\t}\n\t\tkfree(event);\n\t\tbreak;\n\tcase RNDIS_STATUS_MEDIA_DISCONNECT:\n\t\tif (!rdev->link_state) {\n\t\t\trdev->link_state = true;\n\t\t\tnetif_carrier_off(net);\n\t\t\tnetvsc_tx_disable(net_device, net);\n\t\t}\n\t\tkfree(event);\n\t\tbreak;\n\tcase RNDIS_STATUS_NETWORK_CHANGE:\n\t\t \n\t\tif (!rdev->link_state) {\n\t\t\trdev->link_state = true;\n\t\t\tnetif_carrier_off(net);\n\t\t\tnetvsc_tx_disable(net_device, net);\n\t\t\tevent->event = RNDIS_STATUS_MEDIA_CONNECT;\n\t\t\tspin_lock_irqsave(&ndev_ctx->lock, flags);\n\t\t\tlist_add(&event->list, &ndev_ctx->reconfig_events);\n\t\t\tspin_unlock_irqrestore(&ndev_ctx->lock, flags);\n\t\t\treschedule = true;\n\t\t}\n\t\tbreak;\n\t}\n\n\trtnl_unlock();\n\n\t \n\tif (reschedule)\n\t\tschedule_delayed_work(&ndev_ctx->dwork, LINKCHANGE_INT);\n\n\treturn;\n\nout_unlock:\n\trtnl_unlock();\n}\n\nstatic struct net_device *get_netvsc_byref(struct net_device *vf_netdev)\n{\n\tstruct net_device_context *net_device_ctx;\n\tstruct net_device *dev;\n\n\tdev = netdev_master_upper_dev_get(vf_netdev);\n\tif (!dev || dev->netdev_ops != &device_ops)\n\t\treturn NULL;\t \n\n\tnet_device_ctx = netdev_priv(dev);\n\tif (!rtnl_dereference(net_device_ctx->nvdev))\n\t\treturn NULL;\t \n\n\treturn dev;\n}\n\n \nstatic rx_handler_result_t netvsc_vf_handle_frame(struct sk_buff **pskb)\n{\n\tstruct sk_buff *skb = *pskb;\n\tstruct net_device *ndev = rcu_dereference(skb->dev->rx_handler_data);\n\tstruct net_device_context *ndev_ctx = netdev_priv(ndev);\n\tstruct netvsc_vf_pcpu_stats *pcpu_stats\n\t\t = this_cpu_ptr(ndev_ctx->vf_stats);\n\n\tskb = skb_share_check(skb, GFP_ATOMIC);\n\tif (unlikely(!skb))\n\t\treturn RX_HANDLER_CONSUMED;\n\n\t*pskb = skb;\n\n\tskb->dev = ndev;\n\n\tu64_stats_update_begin(&pcpu_stats->syncp);\n\tpcpu_stats->rx_packets++;\n\tpcpu_stats->rx_bytes += skb->len;\n\tu64_stats_update_end(&pcpu_stats->syncp);\n\n\treturn RX_HANDLER_ANOTHER;\n}\n\nstatic int netvsc_vf_join(struct net_device *vf_netdev,\n\t\t\t  struct net_device *ndev)\n{\n\tstruct net_device_context *ndev_ctx = netdev_priv(ndev);\n\tint ret;\n\n\tret = netdev_rx_handler_register(vf_netdev,\n\t\t\t\t\t netvsc_vf_handle_frame, ndev);\n\tif (ret != 0) {\n\t\tnetdev_err(vf_netdev,\n\t\t\t   \"can not register netvsc VF receive handler (err = %d)\\n\",\n\t\t\t   ret);\n\t\tgoto rx_handler_failed;\n\t}\n\n\tret = netdev_master_upper_dev_link(vf_netdev, ndev,\n\t\t\t\t\t   NULL, NULL, NULL);\n\tif (ret != 0) {\n\t\tnetdev_err(vf_netdev,\n\t\t\t   \"can not set master device %s (err = %d)\\n\",\n\t\t\t   ndev->name, ret);\n\t\tgoto upper_link_failed;\n\t}\n\n\tschedule_delayed_work(&ndev_ctx->vf_takeover, VF_TAKEOVER_INT);\n\n\tcall_netdevice_notifiers(NETDEV_JOIN, vf_netdev);\n\n\tnetdev_info(vf_netdev, \"joined to %s\\n\", ndev->name);\n\treturn 0;\n\nupper_link_failed:\n\tnetdev_rx_handler_unregister(vf_netdev);\nrx_handler_failed:\n\treturn ret;\n}\n\nstatic void __netvsc_vf_setup(struct net_device *ndev,\n\t\t\t      struct net_device *vf_netdev)\n{\n\tint ret;\n\n\t \n\tret = dev_set_mtu(vf_netdev, ndev->mtu);\n\tif (ret)\n\t\tnetdev_warn(vf_netdev,\n\t\t\t    \"unable to change mtu to %u\\n\", ndev->mtu);\n\n\t \n\tdev_change_flags(vf_netdev, ndev->flags | IFF_SLAVE, NULL);\n\n\t \n\tnetif_addr_lock_bh(ndev);\n\tdev_uc_sync(vf_netdev, ndev);\n\tdev_mc_sync(vf_netdev, ndev);\n\tnetif_addr_unlock_bh(ndev);\n\n\tif (netif_running(ndev)) {\n\t\tret = dev_open(vf_netdev, NULL);\n\t\tif (ret)\n\t\t\tnetdev_warn(vf_netdev,\n\t\t\t\t    \"unable to open: %d\\n\", ret);\n\t}\n}\n\n \nstatic void netvsc_vf_setup(struct work_struct *w)\n{\n\tstruct net_device_context *ndev_ctx\n\t\t= container_of(w, struct net_device_context, vf_takeover.work);\n\tstruct net_device *ndev = hv_get_drvdata(ndev_ctx->device_ctx);\n\tstruct net_device *vf_netdev;\n\n\tif (!rtnl_trylock()) {\n\t\tschedule_delayed_work(&ndev_ctx->vf_takeover, 0);\n\t\treturn;\n\t}\n\n\tvf_netdev = rtnl_dereference(ndev_ctx->vf_netdev);\n\tif (vf_netdev)\n\t\t__netvsc_vf_setup(ndev, vf_netdev);\n\n\trtnl_unlock();\n}\n\n \nstatic struct net_device *get_netvsc_byslot(const struct net_device *vf_netdev)\n{\n\tstruct device *parent = vf_netdev->dev.parent;\n\tstruct net_device_context *ndev_ctx;\n\tstruct net_device *ndev;\n\tstruct pci_dev *pdev;\n\tu32 serial;\n\n\tif (!parent || !dev_is_pci(parent))\n\t\treturn NULL;  \n\n\tpdev = to_pci_dev(parent);\n\tif (!pdev->slot) {\n\t\tnetdev_notice(vf_netdev, \"no PCI slot information\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (kstrtou32(pci_slot_name(pdev->slot), 10, &serial)) {\n\t\tnetdev_notice(vf_netdev, \"Invalid vf serial:%s\\n\",\n\t\t\t      pci_slot_name(pdev->slot));\n\t\treturn NULL;\n\t}\n\n\tlist_for_each_entry(ndev_ctx, &netvsc_dev_list, list) {\n\t\tif (!ndev_ctx->vf_alloc)\n\t\t\tcontinue;\n\n\t\tif (ndev_ctx->vf_serial != serial)\n\t\t\tcontinue;\n\n\t\tndev = hv_get_drvdata(ndev_ctx->device_ctx);\n\t\tif (ndev->addr_len != vf_netdev->addr_len ||\n\t\t    memcmp(ndev->perm_addr, vf_netdev->perm_addr,\n\t\t\t   ndev->addr_len) != 0)\n\t\t\tcontinue;\n\n\t\treturn ndev;\n\n\t}\n\n\t \n\tlist_for_each_entry(ndev_ctx, &netvsc_dev_list, list) {\n\t\tndev = hv_get_drvdata(ndev_ctx->device_ctx);\n\t\tif (ether_addr_equal(vf_netdev->perm_addr, ndev->perm_addr) ||\n\t\t    ether_addr_equal(vf_netdev->dev_addr, ndev->perm_addr))\n\t\t\treturn ndev;\n\t}\n\n\tnetdev_notice(vf_netdev,\n\t\t      \"no netdev found for vf serial:%u\\n\", serial);\n\treturn NULL;\n}\n\nstatic int netvsc_prepare_bonding(struct net_device *vf_netdev)\n{\n\tstruct net_device *ndev;\n\n\tndev = get_netvsc_byslot(vf_netdev);\n\tif (!ndev)\n\t\treturn NOTIFY_DONE;\n\n\t \n\tvf_netdev->flags |= IFF_SLAVE;\n\treturn NOTIFY_DONE;\n}\n\nstatic int netvsc_register_vf(struct net_device *vf_netdev)\n{\n\tstruct net_device_context *net_device_ctx;\n\tstruct netvsc_device *netvsc_dev;\n\tstruct bpf_prog *prog;\n\tstruct net_device *ndev;\n\tint ret;\n\n\tif (vf_netdev->addr_len != ETH_ALEN)\n\t\treturn NOTIFY_DONE;\n\n\tndev = get_netvsc_byslot(vf_netdev);\n\tif (!ndev)\n\t\treturn NOTIFY_DONE;\n\n\tnet_device_ctx = netdev_priv(ndev);\n\tnetvsc_dev = rtnl_dereference(net_device_ctx->nvdev);\n\tif (!netvsc_dev || rtnl_dereference(net_device_ctx->vf_netdev))\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif (!net_eq(dev_net(ndev), dev_net(vf_netdev))) {\n\t\tret = dev_change_net_namespace(vf_netdev,\n\t\t\t\t\t       dev_net(ndev), \"eth%d\");\n\t\tif (ret)\n\t\t\tnetdev_err(vf_netdev,\n\t\t\t\t   \"could not move to same namespace as %s: %d\\n\",\n\t\t\t\t   ndev->name, ret);\n\t\telse\n\t\t\tnetdev_info(vf_netdev,\n\t\t\t\t    \"VF moved to namespace with: %s\\n\",\n\t\t\t\t    ndev->name);\n\t\treturn NOTIFY_DONE;\n\t}\n\n\tnetdev_info(ndev, \"VF registering: %s\\n\", vf_netdev->name);\n\n\tif (netvsc_vf_join(vf_netdev, ndev) != 0)\n\t\treturn NOTIFY_DONE;\n\n\tdev_hold(vf_netdev);\n\trcu_assign_pointer(net_device_ctx->vf_netdev, vf_netdev);\n\n\tif (ndev->needed_headroom < vf_netdev->needed_headroom)\n\t\tndev->needed_headroom = vf_netdev->needed_headroom;\n\n\tvf_netdev->wanted_features = ndev->features;\n\tnetdev_update_features(vf_netdev);\n\n\tprog = netvsc_xdp_get(netvsc_dev);\n\tnetvsc_vf_setxdp(vf_netdev, prog);\n\n\treturn NOTIFY_OK;\n}\n\n \nstatic int netvsc_vf_changed(struct net_device *vf_netdev, unsigned long event)\n{\n\tstruct net_device_context *net_device_ctx;\n\tstruct netvsc_device *netvsc_dev;\n\tstruct net_device *ndev;\n\tbool vf_is_up = false;\n\tint ret;\n\n\tif (event != NETDEV_GOING_DOWN)\n\t\tvf_is_up = netif_running(vf_netdev);\n\n\tndev = get_netvsc_byref(vf_netdev);\n\tif (!ndev)\n\t\treturn NOTIFY_DONE;\n\n\tnet_device_ctx = netdev_priv(ndev);\n\tnetvsc_dev = rtnl_dereference(net_device_ctx->nvdev);\n\tif (!netvsc_dev)\n\t\treturn NOTIFY_DONE;\n\n\tif (net_device_ctx->data_path_is_vf == vf_is_up)\n\t\treturn NOTIFY_OK;\n\n\tif (vf_is_up && !net_device_ctx->vf_alloc) {\n\t\tnetdev_info(ndev, \"Waiting for the VF association from host\\n\");\n\t\twait_for_completion(&net_device_ctx->vf_add);\n\t}\n\n\tret = netvsc_switch_datapath(ndev, vf_is_up);\n\n\tif (ret) {\n\t\tnetdev_err(ndev,\n\t\t\t   \"Data path failed to switch %s VF: %s, err: %d\\n\",\n\t\t\t   vf_is_up ? \"to\" : \"from\", vf_netdev->name, ret);\n\t\treturn NOTIFY_DONE;\n\t} else {\n\t\tnetdev_info(ndev, \"Data path switched %s VF: %s\\n\",\n\t\t\t    vf_is_up ? \"to\" : \"from\", vf_netdev->name);\n\t}\n\n\treturn NOTIFY_OK;\n}\n\nstatic int netvsc_unregister_vf(struct net_device *vf_netdev)\n{\n\tstruct net_device *ndev;\n\tstruct net_device_context *net_device_ctx;\n\n\tndev = get_netvsc_byref(vf_netdev);\n\tif (!ndev)\n\t\treturn NOTIFY_DONE;\n\n\tnet_device_ctx = netdev_priv(ndev);\n\tcancel_delayed_work_sync(&net_device_ctx->vf_takeover);\n\n\tnetdev_info(ndev, \"VF unregistering: %s\\n\", vf_netdev->name);\n\n\tnetvsc_vf_setxdp(vf_netdev, NULL);\n\n\treinit_completion(&net_device_ctx->vf_add);\n\tnetdev_rx_handler_unregister(vf_netdev);\n\tnetdev_upper_dev_unlink(vf_netdev, ndev);\n\tRCU_INIT_POINTER(net_device_ctx->vf_netdev, NULL);\n\tdev_put(vf_netdev);\n\n\tndev->needed_headroom = RNDIS_AND_PPI_SIZE;\n\n\treturn NOTIFY_OK;\n}\n\nstatic int netvsc_probe(struct hv_device *dev,\n\t\t\tconst struct hv_vmbus_device_id *dev_id)\n{\n\tstruct net_device *net = NULL;\n\tstruct net_device_context *net_device_ctx;\n\tstruct netvsc_device_info *device_info = NULL;\n\tstruct netvsc_device *nvdev;\n\tint ret = -ENOMEM;\n\n\tnet = alloc_etherdev_mq(sizeof(struct net_device_context),\n\t\t\t\tVRSS_CHANNEL_MAX);\n\tif (!net)\n\t\tgoto no_net;\n\n\tnetif_carrier_off(net);\n\n\tnetvsc_init_settings(net);\n\n\tnet_device_ctx = netdev_priv(net);\n\tnet_device_ctx->device_ctx = dev;\n\tnet_device_ctx->msg_enable = netif_msg_init(debug, default_msg);\n\tif (netif_msg_probe(net_device_ctx))\n\t\tnetdev_dbg(net, \"netvsc msg_enable: %d\\n\",\n\t\t\t   net_device_ctx->msg_enable);\n\n\thv_set_drvdata(dev, net);\n\n\tINIT_DELAYED_WORK(&net_device_ctx->dwork, netvsc_link_change);\n\n\tinit_completion(&net_device_ctx->vf_add);\n\tspin_lock_init(&net_device_ctx->lock);\n\tINIT_LIST_HEAD(&net_device_ctx->reconfig_events);\n\tINIT_DELAYED_WORK(&net_device_ctx->vf_takeover, netvsc_vf_setup);\n\n\tnet_device_ctx->vf_stats\n\t\t= netdev_alloc_pcpu_stats(struct netvsc_vf_pcpu_stats);\n\tif (!net_device_ctx->vf_stats)\n\t\tgoto no_stats;\n\n\tnet->netdev_ops = &device_ops;\n\tnet->ethtool_ops = &ethtool_ops;\n\tSET_NETDEV_DEV(net, &dev->device);\n\tdma_set_min_align_mask(&dev->device, HV_HYP_PAGE_SIZE - 1);\n\n\t \n\tnet->needed_headroom = RNDIS_AND_PPI_SIZE;\n\n\t \n\tnetif_set_real_num_tx_queues(net, 1);\n\tnetif_set_real_num_rx_queues(net, 1);\n\n\t \n\tdevice_info = netvsc_devinfo_get(NULL);\n\n\tif (!device_info) {\n\t\tret = -ENOMEM;\n\t\tgoto devinfo_failed;\n\t}\n\n\t \n\trtnl_lock();\n\n\tnvdev = rndis_filter_device_add(dev, device_info);\n\tif (IS_ERR(nvdev)) {\n\t\tret = PTR_ERR(nvdev);\n\t\tnetdev_err(net, \"unable to add netvsc device (ret %d)\\n\", ret);\n\t\tgoto rndis_failed;\n\t}\n\n\teth_hw_addr_set(net, device_info->mac_adr);\n\n\tif (nvdev->num_chn > 1)\n\t\tschedule_work(&nvdev->subchan_work);\n\n\t \n\tnet->features = net->hw_features |\n\t\tNETIF_F_HIGHDMA | NETIF_F_HW_VLAN_CTAG_TX |\n\t\tNETIF_F_HW_VLAN_CTAG_RX;\n\tnet->vlan_features = net->features;\n\n\tnetdev_lockdep_set_classes(net);\n\n\tnet->xdp_features = NETDEV_XDP_ACT_BASIC | NETDEV_XDP_ACT_REDIRECT |\n\t\t\t    NETDEV_XDP_ACT_NDO_XMIT;\n\n\t \n\tnet->min_mtu = NETVSC_MTU_MIN;\n\tif (nvdev->nvsp_version >= NVSP_PROTOCOL_VERSION_2)\n\t\tnet->max_mtu = NETVSC_MTU - ETH_HLEN;\n\telse\n\t\tnet->max_mtu = ETH_DATA_LEN;\n\n\tnvdev->tx_disable = false;\n\n\tret = register_netdevice(net);\n\tif (ret != 0) {\n\t\tpr_err(\"Unable to register netdev.\\n\");\n\t\tgoto register_failed;\n\t}\n\n\tlist_add(&net_device_ctx->list, &netvsc_dev_list);\n\trtnl_unlock();\n\n\tnetvsc_devinfo_put(device_info);\n\treturn 0;\n\nregister_failed:\n\trndis_filter_device_remove(dev, nvdev);\nrndis_failed:\n\trtnl_unlock();\n\tnetvsc_devinfo_put(device_info);\ndevinfo_failed:\n\tfree_percpu(net_device_ctx->vf_stats);\nno_stats:\n\thv_set_drvdata(dev, NULL);\n\tfree_netdev(net);\nno_net:\n\treturn ret;\n}\n\nstatic void netvsc_remove(struct hv_device *dev)\n{\n\tstruct net_device_context *ndev_ctx;\n\tstruct net_device *vf_netdev, *net;\n\tstruct netvsc_device *nvdev;\n\n\tnet = hv_get_drvdata(dev);\n\tif (net == NULL) {\n\t\tdev_err(&dev->device, \"No net device to remove\\n\");\n\t\treturn;\n\t}\n\n\tndev_ctx = netdev_priv(net);\n\n\tcancel_delayed_work_sync(&ndev_ctx->dwork);\n\n\trtnl_lock();\n\tnvdev = rtnl_dereference(ndev_ctx->nvdev);\n\tif (nvdev) {\n\t\tcancel_work_sync(&nvdev->subchan_work);\n\t\tnetvsc_xdp_set(net, NULL, NULL, nvdev);\n\t}\n\n\t \n\tvf_netdev = rtnl_dereference(ndev_ctx->vf_netdev);\n\tif (vf_netdev)\n\t\tnetvsc_unregister_vf(vf_netdev);\n\n\tif (nvdev)\n\t\trndis_filter_device_remove(dev, nvdev);\n\n\tunregister_netdevice(net);\n\tlist_del(&ndev_ctx->list);\n\n\trtnl_unlock();\n\n\thv_set_drvdata(dev, NULL);\n\n\tfree_percpu(ndev_ctx->vf_stats);\n\tfree_netdev(net);\n}\n\nstatic int netvsc_suspend(struct hv_device *dev)\n{\n\tstruct net_device_context *ndev_ctx;\n\tstruct netvsc_device *nvdev;\n\tstruct net_device *net;\n\tint ret;\n\n\tnet = hv_get_drvdata(dev);\n\n\tndev_ctx = netdev_priv(net);\n\tcancel_delayed_work_sync(&ndev_ctx->dwork);\n\n\trtnl_lock();\n\n\tnvdev = rtnl_dereference(ndev_ctx->nvdev);\n\tif (nvdev == NULL) {\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\t \n\tndev_ctx->saved_netvsc_dev_info = netvsc_devinfo_get(nvdev);\n\tif (!ndev_ctx->saved_netvsc_dev_info) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tret = netvsc_detach(net, nvdev);\nout:\n\trtnl_unlock();\n\n\treturn ret;\n}\n\nstatic int netvsc_resume(struct hv_device *dev)\n{\n\tstruct net_device *net = hv_get_drvdata(dev);\n\tstruct net_device_context *net_device_ctx;\n\tstruct netvsc_device_info *device_info;\n\tint ret;\n\n\trtnl_lock();\n\n\tnet_device_ctx = netdev_priv(net);\n\n\t \n\tnet_device_ctx->data_path_is_vf = false;\n\tdevice_info = net_device_ctx->saved_netvsc_dev_info;\n\n\tret = netvsc_attach(net, device_info);\n\n\tnetvsc_devinfo_put(device_info);\n\tnet_device_ctx->saved_netvsc_dev_info = NULL;\n\n\trtnl_unlock();\n\n\treturn ret;\n}\nstatic const struct hv_vmbus_device_id id_table[] = {\n\t \n\t{ HV_NIC_GUID, },\n\t{ },\n};\n\nMODULE_DEVICE_TABLE(vmbus, id_table);\n\n \nstatic struct  hv_driver netvsc_drv = {\n\t.name = KBUILD_MODNAME,\n\t.id_table = id_table,\n\t.probe = netvsc_probe,\n\t.remove = netvsc_remove,\n\t.suspend = netvsc_suspend,\n\t.resume = netvsc_resume,\n\t.driver = {\n\t\t.probe_type = PROBE_FORCE_SYNCHRONOUS,\n\t},\n};\n\n \nstatic int netvsc_netdev_event(struct notifier_block *this,\n\t\t\t       unsigned long event, void *ptr)\n{\n\tstruct net_device *event_dev = netdev_notifier_info_to_dev(ptr);\n\n\t \n\tif (event_dev->netdev_ops == &device_ops)\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif (event_dev->type != ARPHRD_ETHER)\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif (is_vlan_dev(event_dev))\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif (netif_is_bond_master(event_dev))\n\t\treturn NOTIFY_DONE;\n\n\tswitch (event) {\n\tcase NETDEV_POST_INIT:\n\t\treturn netvsc_prepare_bonding(event_dev);\n\tcase NETDEV_REGISTER:\n\t\treturn netvsc_register_vf(event_dev);\n\tcase NETDEV_UNREGISTER:\n\t\treturn netvsc_unregister_vf(event_dev);\n\tcase NETDEV_UP:\n\tcase NETDEV_DOWN:\n\tcase NETDEV_CHANGE:\n\tcase NETDEV_GOING_DOWN:\n\t\treturn netvsc_vf_changed(event_dev, event);\n\tdefault:\n\t\treturn NOTIFY_DONE;\n\t}\n}\n\nstatic struct notifier_block netvsc_netdev_notifier = {\n\t.notifier_call = netvsc_netdev_event,\n};\n\nstatic void __exit netvsc_drv_exit(void)\n{\n\tunregister_netdevice_notifier(&netvsc_netdev_notifier);\n\tvmbus_driver_unregister(&netvsc_drv);\n}\n\nstatic int __init netvsc_drv_init(void)\n{\n\tint ret;\n\n\tif (ring_size < RING_SIZE_MIN) {\n\t\tring_size = RING_SIZE_MIN;\n\t\tpr_info(\"Increased ring_size to %u (min allowed)\\n\",\n\t\t\tring_size);\n\t}\n\tnetvsc_ring_bytes = ring_size * PAGE_SIZE;\n\n\tregister_netdevice_notifier(&netvsc_netdev_notifier);\n\n\tret = vmbus_driver_register(&netvsc_drv);\n\tif (ret)\n\t\tgoto err_vmbus_reg;\n\n\treturn 0;\n\nerr_vmbus_reg:\n\tunregister_netdevice_notifier(&netvsc_netdev_notifier);\n\treturn ret;\n}\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Microsoft Hyper-V network driver\");\n\nmodule_init(netvsc_drv_init);\nmodule_exit(netvsc_drv_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}