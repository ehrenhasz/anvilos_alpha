{
  "module_name": "ethernet-tx.c",
  "hash_id": "ec7b25fad8618fc1d70e1c83fa31699be322af80e60b5038b754c3f1b19c79fb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/staging/octeon/ethernet-tx.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ip.h>\n#include <linux/ratelimit.h>\n#include <linux/string.h>\n#include <linux/interrupt.h>\n#include <net/dst.h>\n#ifdef CONFIG_XFRM\n#include <linux/xfrm.h>\n#include <net/xfrm.h>\n#endif  \n\n#include <linux/atomic.h>\n#include <net/sch_generic.h>\n\n#include \"octeon-ethernet.h\"\n#include \"ethernet-defines.h\"\n#include \"ethernet-tx.h\"\n#include \"ethernet-util.h\"\n\n#define CVM_OCT_SKB_CB(skb)\t((u64 *)((skb)->cb))\n\n \n#ifndef GET_SKBUFF_QOS\n#define GET_SKBUFF_QOS(skb) 0\n#endif\n\nstatic void cvm_oct_tx_do_cleanup(unsigned long arg);\nstatic DECLARE_TASKLET_OLD(cvm_oct_tx_cleanup_tasklet, cvm_oct_tx_do_cleanup);\n\n \n#define MAX_SKB_TO_FREE (MAX_OUT_QUEUE_DEPTH * 2)\n\nstatic inline int cvm_oct_adjust_skb_to_free(int skb_to_free, int fau)\n{\n\tint undo;\n\n\tundo = skb_to_free > 0 ? MAX_SKB_TO_FREE : skb_to_free +\n\t\t\t\t\t\t   MAX_SKB_TO_FREE;\n\tif (undo > 0)\n\t\tcvmx_fau_atomic_add32(fau, -undo);\n\tskb_to_free = -skb_to_free > MAX_SKB_TO_FREE ? MAX_SKB_TO_FREE :\n\t\t\t\t\t\t       -skb_to_free;\n\treturn skb_to_free;\n}\n\nstatic void cvm_oct_kick_tx_poll_watchdog(void)\n{\n\tunion cvmx_ciu_timx ciu_timx;\n\n\tciu_timx.u64 = 0;\n\tciu_timx.s.one_shot = 1;\n\tciu_timx.s.len = cvm_oct_tx_poll_interval;\n\tcvmx_write_csr(CVMX_CIU_TIMX(1), ciu_timx.u64);\n}\n\nstatic void cvm_oct_free_tx_skbs(struct net_device *dev)\n{\n\tint skb_to_free;\n\tint qos, queues_per_port;\n\tint total_remaining = 0;\n\tunsigned long flags;\n\tstruct octeon_ethernet *priv = netdev_priv(dev);\n\n\tqueues_per_port = cvmx_pko_get_num_queues(priv->port);\n\t \n\tfor (qos = 0; qos < queues_per_port; qos++) {\n\t\tif (skb_queue_len(&priv->tx_free_list[qos]) == 0)\n\t\t\tcontinue;\n\t\tskb_to_free = cvmx_fau_fetch_and_add32(priv->fau + qos * 4,\n\t\t\t\t\t\t       MAX_SKB_TO_FREE);\n\t\tskb_to_free = cvm_oct_adjust_skb_to_free(skb_to_free,\n\t\t\t\t\t\t\t priv->fau + qos * 4);\n\t\tif (skb_to_free > 0) {\n\t\t\tstruct sk_buff *to_free_list = NULL;\n\n\t\t\tspin_lock_irqsave(&priv->tx_free_list[qos].lock, flags);\n\t\t\twhile (skb_to_free > 0) {\n\t\t\t\tstruct sk_buff *t;\n\n\t\t\t\tt = __skb_dequeue(&priv->tx_free_list[qos]);\n\t\t\t\tt->next = to_free_list;\n\t\t\t\tto_free_list = t;\n\t\t\t\tskb_to_free--;\n\t\t\t}\n\t\t\tspin_unlock_irqrestore(&priv->tx_free_list[qos].lock,\n\t\t\t\t\t       flags);\n\t\t\t \n\t\t\twhile (to_free_list) {\n\t\t\t\tstruct sk_buff *t = to_free_list;\n\n\t\t\t\tto_free_list = to_free_list->next;\n\t\t\t\tdev_kfree_skb_any(t);\n\t\t\t}\n\t\t}\n\t\ttotal_remaining += skb_queue_len(&priv->tx_free_list[qos]);\n\t}\n\tif (total_remaining < MAX_OUT_QUEUE_DEPTH && netif_queue_stopped(dev))\n\t\tnetif_wake_queue(dev);\n\tif (total_remaining)\n\t\tcvm_oct_kick_tx_poll_watchdog();\n}\n\n \nnetdev_tx_t cvm_oct_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tunion cvmx_pko_command_word0 pko_command;\n\tunion cvmx_buf_ptr hw_buffer;\n\tu64 old_scratch;\n\tu64 old_scratch2;\n\tint qos;\n\tint i;\n\tenum {QUEUE_CORE, QUEUE_HW, QUEUE_DROP} queue_type;\n\tstruct octeon_ethernet *priv = netdev_priv(dev);\n\tstruct sk_buff *to_free_list;\n\tint skb_to_free;\n\tint buffers_to_free;\n\tu32 total_to_clean;\n\tunsigned long flags;\n#if REUSE_SKBUFFS_WITHOUT_FREE\n\tunsigned char *fpa_head;\n#endif\n\n\t \n\tprefetch(priv);\n\n\t \n\tif ((CVMX_PKO_QUEUES_PER_PORT_INTERFACE0 > 1) ||\n\t    (CVMX_PKO_QUEUES_PER_PORT_INTERFACE1 > 1)) {\n\t\tqos = GET_SKBUFF_QOS(skb);\n\t\tif (qos <= 0)\n\t\t\tqos = 0;\n\t\telse if (qos >= cvmx_pko_get_num_queues(priv->port))\n\t\t\tqos = 0;\n\t} else {\n\t\tqos = 0;\n\t}\n\n\tif (USE_ASYNC_IOBDMA) {\n\t\t \n\t\tCVMX_SYNCIOBDMA;\n\t\told_scratch = cvmx_scratch_read64(CVMX_SCR_SCRATCH);\n\t\told_scratch2 = cvmx_scratch_read64(CVMX_SCR_SCRATCH + 8);\n\n\t\t \n\t\tcvmx_fau_async_fetch_and_add32(CVMX_SCR_SCRATCH + 8,\n\t\t\t\t\t       FAU_NUM_PACKET_BUFFERS_TO_FREE,\n\t\t\t\t\t       0);\n\t\tcvmx_fau_async_fetch_and_add32(CVMX_SCR_SCRATCH,\n\t\t\t\t\t       priv->fau + qos * 4,\n\t\t\t\t\t       MAX_SKB_TO_FREE);\n\t}\n\n\t \n\tif (unlikely(skb_shinfo(skb)->nr_frags > 5)) {\n\t\tif (unlikely(__skb_linearize(skb))) {\n\t\t\tqueue_type = QUEUE_DROP;\n\t\t\tif (USE_ASYNC_IOBDMA) {\n\t\t\t\t \n\t\t\t\tCVMX_SYNCIOBDMA;\n\t\t\t\tskb_to_free =\n\t\t\t\t\tcvmx_scratch_read64(CVMX_SCR_SCRATCH);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tskb_to_free =\n\t\t\t\t     cvmx_fau_fetch_and_add32(priv->fau +\n\t\t\t\t\t\t\t      qos * 4,\n\t\t\t\t\t\t\t      MAX_SKB_TO_FREE);\n\t\t\t}\n\t\t\tskb_to_free = cvm_oct_adjust_skb_to_free(skb_to_free,\n\t\t\t\t\t\t\t\t priv->fau +\n\t\t\t\t\t\t\t\t qos * 4);\n\t\t\tspin_lock_irqsave(&priv->tx_free_list[qos].lock, flags);\n\t\t\tgoto skip_xmit;\n\t\t}\n\t}\n\n\t \n\tif ((skb->len < 64) && OCTEON_IS_MODEL(OCTEON_CN3XXX)) {\n\t\tunion cvmx_gmxx_prtx_cfg gmx_prt_cfg;\n\t\tint interface = INTERFACE(priv->port);\n\t\tint index = INDEX(priv->port);\n\n\t\tif (interface < 2) {\n\t\t\t \n\t\t\tgmx_prt_cfg.u64 =\n\t\t\t    cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));\n\t\t\tif (gmx_prt_cfg.s.duplex == 0) {\n\t\t\t\tint add_bytes = 64 - skb->len;\n\n\t\t\t\tif ((skb_tail_pointer(skb) + add_bytes) <=\n\t\t\t\t    skb_end_pointer(skb))\n\t\t\t\t\t__skb_put_zero(skb, add_bytes);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tpko_command.u64 = 0;\n#ifdef __LITTLE_ENDIAN\n\tpko_command.s.le = 1;\n#endif\n\tpko_command.s.n2 = 1;\t \n\tpko_command.s.segs = 1;\n\tpko_command.s.total_bytes = skb->len;\n\tpko_command.s.size0 = CVMX_FAU_OP_SIZE_32;\n\tpko_command.s.subone0 = 1;\n\n\tpko_command.s.dontfree = 1;\n\n\t \n\thw_buffer.u64 = 0;\n\tif (skb_shinfo(skb)->nr_frags == 0) {\n\t\thw_buffer.s.addr = XKPHYS_TO_PHYS((uintptr_t)skb->data);\n\t\thw_buffer.s.pool = 0;\n\t\thw_buffer.s.size = skb->len;\n\t} else {\n\t\thw_buffer.s.addr = XKPHYS_TO_PHYS((uintptr_t)skb->data);\n\t\thw_buffer.s.pool = 0;\n\t\thw_buffer.s.size = skb_headlen(skb);\n\t\tCVM_OCT_SKB_CB(skb)[0] = hw_buffer.u64;\n\t\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\t\tskb_frag_t *fs = skb_shinfo(skb)->frags + i;\n\n\t\t\thw_buffer.s.addr =\n\t\t\t\tXKPHYS_TO_PHYS((uintptr_t)skb_frag_address(fs));\n\t\t\thw_buffer.s.size = skb_frag_size(fs);\n\t\t\tCVM_OCT_SKB_CB(skb)[i + 1] = hw_buffer.u64;\n\t\t}\n\t\thw_buffer.s.addr =\n\t\t\tXKPHYS_TO_PHYS((uintptr_t)CVM_OCT_SKB_CB(skb));\n\t\thw_buffer.s.size = skb_shinfo(skb)->nr_frags + 1;\n\t\tpko_command.s.segs = skb_shinfo(skb)->nr_frags + 1;\n\t\tpko_command.s.gather = 1;\n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\n\t \n#if REUSE_SKBUFFS_WITHOUT_FREE\n\tfpa_head = skb->head + 256 - ((unsigned long)skb->head & 0x7f);\n\tif (unlikely(skb->data < fpa_head)) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\tif (unlikely\n\t    ((skb_end_pointer(skb) - fpa_head) < CVMX_FPA_PACKET_POOL_SIZE)) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\tif (unlikely(skb_shared(skb))) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\tif (unlikely(skb_cloned(skb))) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\tif (unlikely(skb_header_cloned(skb))) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\tif (unlikely(skb->destructor)) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\tif (unlikely(skb_shinfo(skb)->nr_frags)) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\tif (unlikely\n\t    (skb->truesize !=\n\t     sizeof(*skb) + skb_end_offset(skb))) {\n\t\t \n\t\tgoto dont_put_skbuff_in_hw;\n\t}\n\n\t \n\tpko_command.s.dontfree = 0;\n\n\thw_buffer.s.back = ((unsigned long)skb->data >> 7) -\n\t\t\t   ((unsigned long)fpa_head >> 7);\n\n\t*(struct sk_buff **)(fpa_head - sizeof(void *)) = skb;\n\n\t \n\tdst_release(skb_dst(skb));\n\tskb_dst_set(skb, NULL);\n\tskb_ext_reset(skb);\n\tnf_reset_ct(skb);\n\tskb_reset_redirect(skb);\n\n#ifdef CONFIG_NET_SCHED\n\tskb->tc_index = 0;\n#endif  \n#endif  \n\ndont_put_skbuff_in_hw:\n\n\t \n\tif ((skb->protocol == htons(ETH_P_IP)) &&\n\t    (ip_hdr(skb)->version == 4) &&\n\t    (ip_hdr(skb)->ihl == 5) &&\n\t    ((ip_hdr(skb)->frag_off == 0) ||\n\t     (ip_hdr(skb)->frag_off == htons(1 << 14))) &&\n\t    ((ip_hdr(skb)->protocol == IPPROTO_TCP) ||\n\t     (ip_hdr(skb)->protocol == IPPROTO_UDP))) {\n\t\t \n\t\tpko_command.s.ipoffp1 = skb_network_offset(skb) + 1;\n\t}\n\n\tif (USE_ASYNC_IOBDMA) {\n\t\t \n\t\tCVMX_SYNCIOBDMA;\n\t\tskb_to_free = cvmx_scratch_read64(CVMX_SCR_SCRATCH);\n\t\tbuffers_to_free = cvmx_scratch_read64(CVMX_SCR_SCRATCH + 8);\n\t} else {\n\t\t \n\t\tskb_to_free = cvmx_fau_fetch_and_add32(priv->fau + qos * 4,\n\t\t\t\t\t\t       MAX_SKB_TO_FREE);\n\t\tbuffers_to_free =\n\t\t    cvmx_fau_fetch_and_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);\n\t}\n\n\tskb_to_free = cvm_oct_adjust_skb_to_free(skb_to_free,\n\t\t\t\t\t\t priv->fau + qos * 4);\n\n\t \n\tif ((buffers_to_free < -100) && !pko_command.s.dontfree)\n\t\tpko_command.s.dontfree = 1;\n\n\tif (pko_command.s.dontfree) {\n\t\tqueue_type = QUEUE_CORE;\n\t\tpko_command.s.reg0 = priv->fau + qos * 4;\n\t} else {\n\t\tqueue_type = QUEUE_HW;\n\t}\n\tif (USE_ASYNC_IOBDMA)\n\t\tcvmx_fau_async_fetch_and_add32(CVMX_SCR_SCRATCH,\n\t\t\t\t\t       FAU_TOTAL_TX_TO_CLEAN, 1);\n\n\tspin_lock_irqsave(&priv->tx_free_list[qos].lock, flags);\n\n\t \n\tif (unlikely(skb_queue_len(&priv->tx_free_list[qos]) >=\n\t\t     MAX_OUT_QUEUE_DEPTH)) {\n\t\tif (dev->tx_queue_len != 0) {\n\t\t\t \n\t\t\tspin_unlock_irqrestore(&priv->tx_free_list[qos].lock,\n\t\t\t\t\t       flags);\n\t\t\tnetif_stop_queue(dev);\n\t\t\tspin_lock_irqsave(&priv->tx_free_list[qos].lock,\n\t\t\t\t\t  flags);\n\t\t} else {\n\t\t\t \n\t\t\tqueue_type = QUEUE_DROP;\n\t\t\tgoto skip_xmit;\n\t\t}\n\t}\n\n\tcvmx_pko_send_packet_prepare(priv->port, priv->queue + qos,\n\t\t\t\t     CVMX_PKO_LOCK_NONE);\n\n\t \n\tif (unlikely(cvmx_pko_send_packet_finish(priv->port,\n\t\t\t\t\t\t priv->queue + qos,\n\t\t\t\t\t\t pko_command, hw_buffer,\n\t\t\t\t\t\t CVMX_PKO_LOCK_NONE))) {\n\t\tprintk_ratelimited(\"%s: Failed to send the packet\\n\",\n\t\t\t\t   dev->name);\n\t\tqueue_type = QUEUE_DROP;\n\t}\nskip_xmit:\n\tto_free_list = NULL;\n\n\tswitch (queue_type) {\n\tcase QUEUE_DROP:\n\t\tskb->next = to_free_list;\n\t\tto_free_list = skb;\n\t\tdev->stats.tx_dropped++;\n\t\tbreak;\n\tcase QUEUE_HW:\n\t\tcvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, -1);\n\t\tbreak;\n\tcase QUEUE_CORE:\n\t\t__skb_queue_tail(&priv->tx_free_list[qos], skb);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\twhile (skb_to_free > 0) {\n\t\tstruct sk_buff *t = __skb_dequeue(&priv->tx_free_list[qos]);\n\n\t\tt->next = to_free_list;\n\t\tto_free_list = t;\n\t\tskb_to_free--;\n\t}\n\n\tspin_unlock_irqrestore(&priv->tx_free_list[qos].lock, flags);\n\n\t \n\twhile (to_free_list) {\n\t\tstruct sk_buff *t = to_free_list;\n\n\t\tto_free_list = to_free_list->next;\n\t\tdev_kfree_skb_any(t);\n\t}\n\n\tif (USE_ASYNC_IOBDMA) {\n\t\tCVMX_SYNCIOBDMA;\n\t\ttotal_to_clean = cvmx_scratch_read64(CVMX_SCR_SCRATCH);\n\t\t \n\t\tcvmx_scratch_write64(CVMX_SCR_SCRATCH, old_scratch);\n\t\tcvmx_scratch_write64(CVMX_SCR_SCRATCH + 8, old_scratch2);\n\t} else {\n\t\ttotal_to_clean =\n\t\t\tcvmx_fau_fetch_and_add32(FAU_TOTAL_TX_TO_CLEAN, 1);\n\t}\n\n\tif (total_to_clean & 0x3ff) {\n\t\t \n\t\ttasklet_schedule(&cvm_oct_tx_cleanup_tasklet);\n\t}\n\n\tcvm_oct_kick_tx_poll_watchdog();\n\n\treturn NETDEV_TX_OK;\n}\n\n \nnetdev_tx_t cvm_oct_xmit_pow(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct octeon_ethernet *priv = netdev_priv(dev);\n\tvoid *packet_buffer;\n\tvoid *copy_location;\n\n\t \n\tstruct cvmx_wqe *work = cvmx_fpa_alloc(CVMX_FPA_WQE_POOL);\n\n\tif (unlikely(!work)) {\n\t\tprintk_ratelimited(\"%s: Failed to allocate a work queue entry\\n\",\n\t\t\t\t   dev->name);\n\t\tdev->stats.tx_dropped++;\n\t\tdev_kfree_skb_any(skb);\n\t\treturn 0;\n\t}\n\n\t \n\tpacket_buffer = cvmx_fpa_alloc(CVMX_FPA_PACKET_POOL);\n\tif (unlikely(!packet_buffer)) {\n\t\tprintk_ratelimited(\"%s: Failed to allocate a packet buffer\\n\",\n\t\t\t\t   dev->name);\n\t\tcvmx_fpa_free(work, CVMX_FPA_WQE_POOL, 1);\n\t\tdev->stats.tx_dropped++;\n\t\tdev_kfree_skb_any(skb);\n\t\treturn 0;\n\t}\n\n\t \n\tcopy_location = packet_buffer + sizeof(u64);\n\tcopy_location += ((CVMX_HELPER_FIRST_MBUFF_SKIP + 7) & 0xfff8) + 6;\n\n\t \n\tmemcpy(copy_location, skb->data, skb->len);\n\n\t \n\tif (!OCTEON_IS_MODEL(OCTEON_CN68XX))\n\t\twork->word0.pip.cn38xx.hw_chksum = skb->csum;\n\twork->word1.len = skb->len;\n\tcvmx_wqe_set_port(work, priv->port);\n\tcvmx_wqe_set_qos(work, priv->port & 0x7);\n\tcvmx_wqe_set_grp(work, pow_send_group);\n\twork->word1.tag_type = CVMX_HELPER_INPUT_TAG_TYPE;\n\twork->word1.tag = pow_send_group;\t \n\t \n\twork->word2.u64 = 0;\n\twork->word2.s.bufs = 1;\n\twork->packet_ptr.u64 = 0;\n\twork->packet_ptr.s.addr = cvmx_ptr_to_phys(copy_location);\n\twork->packet_ptr.s.pool = CVMX_FPA_PACKET_POOL;\n\twork->packet_ptr.s.size = CVMX_FPA_PACKET_POOL_SIZE;\n\twork->packet_ptr.s.back = (copy_location - packet_buffer) >> 7;\n\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\twork->word2.s.ip_offset = 14;\n#if 0\n\t\twork->word2.s.vlan_valid = 0;\t \n\t\twork->word2.s.vlan_cfi = 0;\t \n\t\twork->word2.s.vlan_id = 0;\t \n\t\twork->word2.s.dec_ipcomp = 0;\t \n#endif\n\t\twork->word2.s.tcp_or_udp =\n\t\t    (ip_hdr(skb)->protocol == IPPROTO_TCP) ||\n\t\t    (ip_hdr(skb)->protocol == IPPROTO_UDP);\n#if 0\n\t\t \n\t\twork->word2.s.dec_ipsec = 0;\n\t\t \n\t\twork->word2.s.is_v6 = 0;\n\t\t \n\t\twork->word2.s.software = 0;\n\t\t \n\t\twork->word2.s.L4_error = 0;\n#endif\n\t\twork->word2.s.is_frag = !((ip_hdr(skb)->frag_off == 0) ||\n\t\t\t\t\t  (ip_hdr(skb)->frag_off ==\n\t\t\t\t\t      cpu_to_be16(1 << 14)));\n#if 0\n\t\t \n\t\twork->word2.s.IP_exc = 0;\n#endif\n\t\twork->word2.s.is_bcast = (skb->pkt_type == PACKET_BROADCAST);\n\t\twork->word2.s.is_mcast = (skb->pkt_type == PACKET_MULTICAST);\n#if 0\n\t\t \n\t\twork->word2.s.not_IP = 0;\n\t\t \n\t\twork->word2.s.rcv_error = 0;\n\t\t \n\t\twork->word2.s.err_code = 0;\n#endif\n\n\t\t \n\t\tmemcpy(work->packet_data, skb->data + 10,\n\t\t       sizeof(work->packet_data));\n\t} else {\n#if 0\n\t\twork->word2.snoip.vlan_valid = 0;\t \n\t\twork->word2.snoip.vlan_cfi = 0;\t \n\t\twork->word2.snoip.vlan_id = 0;\t \n\t\twork->word2.snoip.software = 0;\t \n#endif\n\t\twork->word2.snoip.is_rarp = skb->protocol == htons(ETH_P_RARP);\n\t\twork->word2.snoip.is_arp = skb->protocol == htons(ETH_P_ARP);\n\t\twork->word2.snoip.is_bcast =\n\t\t    (skb->pkt_type == PACKET_BROADCAST);\n\t\twork->word2.snoip.is_mcast =\n\t\t    (skb->pkt_type == PACKET_MULTICAST);\n\t\twork->word2.snoip.not_IP = 1;\t \n#if 0\n\t\t \n\t\twork->word2.snoip.rcv_error = 0;\n\t\t \n\t\twork->word2.snoip.err_code = 0;\n#endif\n\t\tmemcpy(work->packet_data, skb->data, sizeof(work->packet_data));\n\t}\n\n\t \n\tcvmx_pow_work_submit(work, work->word1.tag, work->word1.tag_type,\n\t\t\t     cvmx_wqe_get_qos(work), cvmx_wqe_get_grp(work));\n\tdev->stats.tx_packets++;\n\tdev->stats.tx_bytes += skb->len;\n\tdev_consume_skb_any(skb);\n\treturn 0;\n}\n\n \nvoid cvm_oct_tx_shutdown_dev(struct net_device *dev)\n{\n\tstruct octeon_ethernet *priv = netdev_priv(dev);\n\tunsigned long flags;\n\tint qos;\n\n\tfor (qos = 0; qos < 16; qos++) {\n\t\tspin_lock_irqsave(&priv->tx_free_list[qos].lock, flags);\n\t\twhile (skb_queue_len(&priv->tx_free_list[qos]))\n\t\t\tdev_kfree_skb_any(__skb_dequeue\n\t\t\t\t\t  (&priv->tx_free_list[qos]));\n\t\tspin_unlock_irqrestore(&priv->tx_free_list[qos].lock, flags);\n\t}\n}\n\nstatic void cvm_oct_tx_do_cleanup(unsigned long arg)\n{\n\tint port;\n\n\tfor (port = 0; port < TOTAL_NUMBER_OF_PORTS; port++) {\n\t\tif (cvm_oct_device[port]) {\n\t\t\tstruct net_device *dev = cvm_oct_device[port];\n\n\t\t\tcvm_oct_free_tx_skbs(dev);\n\t\t}\n\t}\n}\n\nstatic irqreturn_t cvm_oct_tx_cleanup_watchdog(int cpl, void *dev_id)\n{\n\t \n\tcvmx_write_csr(CVMX_CIU_TIMX(1), 0);\n\t \n\ttasklet_schedule(&cvm_oct_tx_cleanup_tasklet);\n\treturn IRQ_HANDLED;\n}\n\nvoid cvm_oct_tx_initialize(void)\n{\n\tint i;\n\n\t \n\tcvmx_write_csr(CVMX_CIU_TIMX(1), 0);\n\t \n\ti = request_irq(OCTEON_IRQ_TIMER1,\n\t\t\tcvm_oct_tx_cleanup_watchdog, 0,\n\t\t\t\"Ethernet\", cvm_oct_device);\n\n\tif (i)\n\t\tpanic(\"Could not acquire Ethernet IRQ %d\\n\", OCTEON_IRQ_TIMER1);\n}\n\nvoid cvm_oct_tx_shutdown(void)\n{\n\t \n\tfree_irq(OCTEON_IRQ_TIMER1, cvm_oct_device);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}