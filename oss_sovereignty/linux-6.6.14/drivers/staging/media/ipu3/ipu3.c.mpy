{
  "module_name": "ipu3.c",
  "hash_id": "879025e84c59702ec35e0814a5f044a07a3e2cc173ee77be40575bd170265ad4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/staging/media/ipu3/ipu3.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/pm_runtime.h>\n\n#include \"ipu3.h\"\n#include \"ipu3-dmamap.h\"\n#include \"ipu3-mmu.h\"\n\n#define IMGU_PCI_ID\t\t\t0x1919\n#define IMGU_PCI_BAR\t\t\t0\n#define IMGU_DMA_MASK\t\t\tDMA_BIT_MASK(39)\n#define IMGU_MAX_QUEUE_DEPTH\t\t(2 + 2)\n\n \n#define CSS_QUEUE_IN_BUF_SIZE\t\t0\n#define CSS_QUEUE_PARAMS_BUF_SIZE\t0\n#define CSS_QUEUE_OUT_BUF_SIZE\t\t(4160 * 3120 * 12 / 8)\n#define CSS_QUEUE_VF_BUF_SIZE\t\t(1920 * 1080 * 12 / 8)\n#define CSS_QUEUE_STAT_3A_BUF_SIZE\tsizeof(struct ipu3_uapi_stats_3a)\n\nstatic const size_t css_queue_buf_size_map[IPU3_CSS_QUEUES] = {\n\t[IPU3_CSS_QUEUE_IN] = CSS_QUEUE_IN_BUF_SIZE,\n\t[IPU3_CSS_QUEUE_PARAMS] = CSS_QUEUE_PARAMS_BUF_SIZE,\n\t[IPU3_CSS_QUEUE_OUT] = CSS_QUEUE_OUT_BUF_SIZE,\n\t[IPU3_CSS_QUEUE_VF] = CSS_QUEUE_VF_BUF_SIZE,\n\t[IPU3_CSS_QUEUE_STAT_3A] = CSS_QUEUE_STAT_3A_BUF_SIZE,\n};\n\nstatic const struct imgu_node_mapping imgu_node_map[IMGU_NODE_NUM] = {\n\t[IMGU_NODE_IN] = {IPU3_CSS_QUEUE_IN, \"input\"},\n\t[IMGU_NODE_PARAMS] = {IPU3_CSS_QUEUE_PARAMS, \"parameters\"},\n\t[IMGU_NODE_OUT] = {IPU3_CSS_QUEUE_OUT, \"output\"},\n\t[IMGU_NODE_VF] = {IPU3_CSS_QUEUE_VF, \"viewfinder\"},\n\t[IMGU_NODE_STAT_3A] = {IPU3_CSS_QUEUE_STAT_3A, \"3a stat\"},\n};\n\nunsigned int imgu_node_to_queue(unsigned int node)\n{\n\treturn imgu_node_map[node].css_queue;\n}\n\nunsigned int imgu_map_node(struct imgu_device *imgu, unsigned int css_queue)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < IMGU_NODE_NUM; i++)\n\t\tif (imgu_node_map[i].css_queue == css_queue)\n\t\t\tbreak;\n\n\treturn i;\n}\n\n \n\nstatic void imgu_dummybufs_cleanup(struct imgu_device *imgu, unsigned int pipe)\n{\n\tunsigned int i;\n\tstruct imgu_media_pipe *imgu_pipe = &imgu->imgu_pipe[pipe];\n\n\tfor (i = 0; i < IPU3_CSS_QUEUES; i++)\n\t\timgu_dmamap_free(imgu,\n\t\t\t\t &imgu_pipe->queues[i].dmap);\n}\n\nstatic int imgu_dummybufs_preallocate(struct imgu_device *imgu,\n\t\t\t\t      unsigned int pipe)\n{\n\tunsigned int i;\n\tsize_t size;\n\tstruct imgu_media_pipe *imgu_pipe = &imgu->imgu_pipe[pipe];\n\n\tfor (i = 0; i < IPU3_CSS_QUEUES; i++) {\n\t\tsize = css_queue_buf_size_map[i];\n\t\t \n\t\tif (i == IMGU_QUEUE_MASTER || size == 0)\n\t\t\tcontinue;\n\n\t\tif (!imgu_dmamap_alloc(imgu,\n\t\t\t\t       &imgu_pipe->queues[i].dmap, size)) {\n\t\t\timgu_dummybufs_cleanup(imgu, pipe);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int imgu_dummybufs_init(struct imgu_device *imgu, unsigned int pipe)\n{\n\tconst struct v4l2_pix_format_mplane *mpix;\n\tconst struct v4l2_meta_format\t*meta;\n\tunsigned int i, k, node;\n\tsize_t size;\n\tstruct imgu_media_pipe *imgu_pipe = &imgu->imgu_pipe[pipe];\n\n\t \n\tfor (i = 0; i < IPU3_CSS_QUEUES; i++) {\n\t\tnode = imgu_map_node(imgu, i);\n\t\tif (!imgu_pipe->queue_enabled[node] || i == IMGU_QUEUE_MASTER)\n\t\t\tcontinue;\n\n\t\tif (!imgu_pipe->nodes[IMGU_NODE_VF].enabled &&\n\t\t    i == IPU3_CSS_QUEUE_VF)\n\t\t\t \n\t\t\tcontinue;\n\n\t\tmeta = &imgu_pipe->nodes[node].vdev_fmt.fmt.meta;\n\t\tmpix = &imgu_pipe->nodes[node].vdev_fmt.fmt.pix_mp;\n\n\t\tif (node == IMGU_NODE_STAT_3A || node == IMGU_NODE_PARAMS)\n\t\t\tsize = meta->buffersize;\n\t\telse\n\t\t\tsize = mpix->plane_fmt[0].sizeimage;\n\n\t\tif (imgu_css_dma_buffer_resize(imgu,\n\t\t\t\t\t       &imgu_pipe->queues[i].dmap,\n\t\t\t\t\t       size)) {\n\t\t\timgu_dummybufs_cleanup(imgu, pipe);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tfor (k = 0; k < IMGU_MAX_QUEUE_DEPTH; k++)\n\t\t\timgu_css_buf_init(&imgu_pipe->queues[i].dummybufs[k], i,\n\t\t\t\t\t  imgu_pipe->queues[i].dmap.daddr);\n\t}\n\n\treturn 0;\n}\n\n \nstatic struct imgu_css_buffer *imgu_dummybufs_get(struct imgu_device *imgu,\n\t\t\t\t\t\t   int queue, unsigned int pipe)\n{\n\tunsigned int i;\n\tstruct imgu_media_pipe *imgu_pipe = &imgu->imgu_pipe[pipe];\n\n\t \n\tif (queue == IPU3_CSS_QUEUE_IN)\n\t\treturn NULL;\n\n\tif (WARN_ON(!imgu_pipe->queues[queue].dmap.vaddr))\n\t\t \n\t\treturn NULL;\n\n\tfor (i = 0; i < IMGU_MAX_QUEUE_DEPTH; i++)\n\t\tif (imgu_css_buf_state(&imgu_pipe->queues[queue].dummybufs[i]) !=\n\t\t\tIPU3_CSS_BUFFER_QUEUED)\n\t\t\tbreak;\n\n\tif (i == IMGU_MAX_QUEUE_DEPTH)\n\t\treturn NULL;\n\n\timgu_css_buf_init(&imgu_pipe->queues[queue].dummybufs[i], queue,\n\t\t\t  imgu_pipe->queues[queue].dmap.daddr);\n\n\treturn &imgu_pipe->queues[queue].dummybufs[i];\n}\n\n \nstatic bool imgu_dummybufs_check(struct imgu_device *imgu,\n\t\t\t\t struct imgu_css_buffer *buf,\n\t\t\t\t unsigned int pipe)\n{\n\tunsigned int i;\n\tstruct imgu_media_pipe *imgu_pipe = &imgu->imgu_pipe[pipe];\n\n\tfor (i = 0; i < IMGU_MAX_QUEUE_DEPTH; i++)\n\t\tif (buf == &imgu_pipe->queues[buf->queue].dummybufs[i])\n\t\t\tbreak;\n\n\treturn i < IMGU_MAX_QUEUE_DEPTH;\n}\n\nstatic void imgu_buffer_done(struct imgu_device *imgu, struct vb2_buffer *vb,\n\t\t\t     enum vb2_buffer_state state)\n{\n\tmutex_lock(&imgu->lock);\n\timgu_v4l2_buffer_done(vb, state);\n\tmutex_unlock(&imgu->lock);\n}\n\nstatic struct imgu_css_buffer *imgu_queue_getbuf(struct imgu_device *imgu,\n\t\t\t\t\t\t unsigned int node,\n\t\t\t\t\t\t unsigned int pipe)\n{\n\tstruct imgu_buffer *buf;\n\tstruct imgu_media_pipe *imgu_pipe = &imgu->imgu_pipe[pipe];\n\n\tif (WARN_ON(node >= IMGU_NODE_NUM))\n\t\treturn NULL;\n\n\t \n\tlist_for_each_entry(buf, &imgu_pipe->nodes[node].buffers, vid_buf.list) {\n\t\tif (imgu_css_buf_state(&buf->css_buf) == IPU3_CSS_BUFFER_NEW)\n\t\t\treturn &buf->css_buf;\n\t}\n\n\t \n\treturn imgu_dummybufs_get(imgu, imgu_node_map[node].css_queue, pipe);\n}\n\n \nint imgu_queue_buffers(struct imgu_device *imgu, bool initial, unsigned int pipe)\n{\n\tunsigned int node;\n\tint r = 0;\n\tstruct imgu_media_pipe *imgu_pipe = &imgu->imgu_pipe[pipe];\n\n\tif (!imgu_css_is_streaming(&imgu->css))\n\t\treturn 0;\n\n\tdev_dbg(&imgu->pci_dev->dev, \"Queue buffers to pipe %d\", pipe);\n\tmutex_lock(&imgu->lock);\n\n\tif (!imgu_css_pipe_queue_empty(&imgu->css, pipe)) {\n\t\tmutex_unlock(&imgu->lock);\n\t\treturn 0;\n\t}\n\n\t \n\tfor (node = IMGU_NODE_NUM - 1;\n\t     imgu_queue_getbuf(imgu, IMGU_NODE_IN, pipe);\n\t     node = node ? node - 1 : IMGU_NODE_NUM - 1) {\n\t\tif (node == IMGU_NODE_VF &&\n\t\t    !imgu_pipe->nodes[IMGU_NODE_VF].enabled) {\n\t\t\tdev_warn(&imgu->pci_dev->dev,\n\t\t\t\t \"Vf not enabled, ignore queue\");\n\t\t\tcontinue;\n\t\t} else if (node == IMGU_NODE_PARAMS &&\n\t\t\t   imgu_pipe->nodes[node].enabled) {\n\t\t\tstruct vb2_buffer *vb;\n\t\t\tstruct imgu_vb2_buffer *ivb;\n\n\t\t\t \n\t\t\tif (list_empty(&imgu_pipe->nodes[node].buffers))\n\t\t\t\tcontinue;\n\n\t\t\tivb = list_first_entry(&imgu_pipe->nodes[node].buffers,\n\t\t\t\t\t       struct imgu_vb2_buffer, list);\n\t\t\tlist_del(&ivb->list);\n\t\t\tvb = &ivb->vbb.vb2_buf;\n\t\t\tr = imgu_css_set_parameters(&imgu->css, pipe,\n\t\t\t\t\t\t    vb2_plane_vaddr(vb, 0));\n\t\t\tif (r) {\n\t\t\t\tvb2_buffer_done(vb, VB2_BUF_STATE_ERROR);\n\t\t\t\tdev_warn(&imgu->pci_dev->dev,\n\t\t\t\t\t \"set parameters failed.\");\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tvb2_buffer_done(vb, VB2_BUF_STATE_DONE);\n\t\t\tdev_dbg(&imgu->pci_dev->dev,\n\t\t\t\t\"queue user parameters %d to css.\", vb->index);\n\t\t} else if (imgu_pipe->queue_enabled[node]) {\n\t\t\tstruct imgu_css_buffer *buf =\n\t\t\t\timgu_queue_getbuf(imgu, node, pipe);\n\t\t\tstruct imgu_buffer *ibuf = NULL;\n\t\t\tbool dummy;\n\n\t\t\tif (!buf)\n\t\t\t\tbreak;\n\n\t\t\tr = imgu_css_buf_queue(&imgu->css, pipe, buf);\n\t\t\tif (r)\n\t\t\t\tbreak;\n\t\t\tdummy = imgu_dummybufs_check(imgu, buf, pipe);\n\t\t\tif (!dummy)\n\t\t\t\tibuf = container_of(buf, struct imgu_buffer,\n\t\t\t\t\t\t    css_buf);\n\t\t\tdev_dbg(&imgu->pci_dev->dev,\n\t\t\t\t\"queue %s %s buffer %u to css da: 0x%08x\\n\",\n\t\t\t\tdummy ? \"dummy\" : \"user\",\n\t\t\t\timgu_node_map[node].name,\n\t\t\t\tdummy ? 0 : ibuf->vid_buf.vbb.vb2_buf.index,\n\t\t\t\t(u32)buf->daddr);\n\t\t}\n\t}\n\tmutex_unlock(&imgu->lock);\n\n\tif (r && r != -EBUSY)\n\t\tgoto failed;\n\n\treturn 0;\n\nfailed:\n\t \n\tdev_err(&imgu->pci_dev->dev,\n\t\t\"failed to queue buffer to CSS on queue %i (%d)\\n\",\n\t\tnode, r);\n\n\tif (initial)\n\t\t \n\t\treturn r;\n\n\tfor (node = 0; node < IMGU_NODE_NUM; node++) {\n\t\tstruct imgu_buffer *buf, *buf0;\n\n\t\tif (!imgu_pipe->queue_enabled[node])\n\t\t\tcontinue;\t \n\n\t\tmutex_lock(&imgu->lock);\n\t\tlist_for_each_entry_safe(buf, buf0,\n\t\t\t\t\t &imgu_pipe->nodes[node].buffers,\n\t\t\t\t\t vid_buf.list) {\n\t\t\tif (imgu_css_buf_state(&buf->css_buf) ==\n\t\t\t    IPU3_CSS_BUFFER_QUEUED)\n\t\t\t\tcontinue;\t \n\n\t\t\timgu_v4l2_buffer_done(&buf->vid_buf.vbb.vb2_buf,\n\t\t\t\t\t      VB2_BUF_STATE_ERROR);\n\t\t}\n\t\tmutex_unlock(&imgu->lock);\n\t}\n\n\treturn r;\n}\n\nstatic int imgu_powerup(struct imgu_device *imgu)\n{\n\tint r;\n\tunsigned int pipe;\n\tunsigned int freq = 200;\n\tstruct v4l2_mbus_framefmt *fmt;\n\n\t \n\tfor_each_set_bit(pipe, imgu->css.enabled_pipes, IMGU_MAX_PIPE_NUM) {\n\t\tfmt = &imgu->imgu_pipe[pipe].nodes[IMGU_NODE_IN].pad_fmt;\n\t\tdev_dbg(&imgu->pci_dev->dev, \"pipe %u input format = %ux%u\",\n\t\t\tpipe, fmt->width, fmt->height);\n\t\tif ((fmt->width * fmt->height) >= (2048 * 1152))\n\t\t\tfreq = 450;\n\t}\n\n\tr = imgu_css_set_powerup(&imgu->pci_dev->dev, imgu->base, freq);\n\tif (r)\n\t\treturn r;\n\n\timgu_mmu_resume(imgu->mmu);\n\treturn 0;\n}\n\nstatic void imgu_powerdown(struct imgu_device *imgu)\n{\n\timgu_mmu_suspend(imgu->mmu);\n\timgu_css_set_powerdown(&imgu->pci_dev->dev, imgu->base);\n}\n\nint imgu_s_stream(struct imgu_device *imgu, int enable)\n{\n\tstruct device *dev = &imgu->pci_dev->dev;\n\tint r, pipe;\n\n\tif (!enable) {\n\t\t \n\t\tdev_dbg(dev, \"stream off\\n\");\n\t\t \n\t\tatomic_set(&imgu->qbuf_barrier, 1);\n\t\timgu_css_stop_streaming(&imgu->css);\n\t\tsynchronize_irq(imgu->pci_dev->irq);\n\t\tatomic_set(&imgu->qbuf_barrier, 0);\n\t\timgu_powerdown(imgu);\n\t\tpm_runtime_put(&imgu->pci_dev->dev);\n\n\t\treturn 0;\n\t}\n\n\t \n\tr = pm_runtime_resume_and_get(dev);\n\tif (r < 0) {\n\t\tdev_err(dev, \"failed to set imgu power\\n\");\n\t\treturn r;\n\t}\n\n\tr = imgu_powerup(imgu);\n\tif (r) {\n\t\tdev_err(dev, \"failed to power up imgu\\n\");\n\t\tpm_runtime_put(dev);\n\t\treturn r;\n\t}\n\n\t \n\tr = imgu_css_start_streaming(&imgu->css);\n\tif (r) {\n\t\tdev_err(dev, \"failed to start css streaming (%d)\", r);\n\t\tgoto fail_start_streaming;\n\t}\n\n\tfor_each_set_bit(pipe, imgu->css.enabled_pipes, IMGU_MAX_PIPE_NUM) {\n\t\t \n\t\tr = imgu_dummybufs_init(imgu, pipe);\n\t\tif (r) {\n\t\t\tdev_err(dev, \"failed to initialize dummy buffers (%d)\", r);\n\t\t\tgoto fail_dummybufs;\n\t\t}\n\n\t\t \n\t\tr = imgu_queue_buffers(imgu, true, pipe);\n\t\tif (r) {\n\t\t\tdev_err(dev, \"failed to queue initial buffers (%d)\", r);\n\t\t\tgoto fail_queueing;\n\t\t}\n\t}\n\n\treturn 0;\nfail_queueing:\n\tfor_each_set_bit(pipe, imgu->css.enabled_pipes, IMGU_MAX_PIPE_NUM)\n\t\timgu_dummybufs_cleanup(imgu, pipe);\nfail_dummybufs:\n\timgu_css_stop_streaming(&imgu->css);\nfail_start_streaming:\n\tpm_runtime_put(dev);\n\n\treturn r;\n}\n\nstatic void imgu_video_nodes_exit(struct imgu_device *imgu)\n{\n\tint i;\n\n\tfor (i = 0; i < IMGU_MAX_PIPE_NUM; i++)\n\t\timgu_dummybufs_cleanup(imgu, i);\n\n\timgu_v4l2_unregister(imgu);\n}\n\nstatic int imgu_video_nodes_init(struct imgu_device *imgu)\n{\n\tstruct v4l2_pix_format_mplane *fmts[IPU3_CSS_QUEUES] = { NULL };\n\tstruct v4l2_rect *rects[IPU3_CSS_RECTS] = { NULL };\n\tstruct imgu_media_pipe *imgu_pipe;\n\tunsigned int i, j;\n\tint r;\n\n\timgu->buf_struct_size = sizeof(struct imgu_buffer);\n\n\tfor (j = 0; j < IMGU_MAX_PIPE_NUM; j++) {\n\t\timgu_pipe = &imgu->imgu_pipe[j];\n\n\t\tfor (i = 0; i < IMGU_NODE_NUM; i++) {\n\t\t\timgu_pipe->nodes[i].name = imgu_node_map[i].name;\n\t\t\timgu_pipe->nodes[i].output = i < IMGU_QUEUE_FIRST_INPUT;\n\t\t\timgu_pipe->nodes[i].enabled = false;\n\n\t\t\tif (i != IMGU_NODE_PARAMS && i != IMGU_NODE_STAT_3A)\n\t\t\t\tfmts[imgu_node_map[i].css_queue] =\n\t\t\t\t\t&imgu_pipe->nodes[i].vdev_fmt.fmt.pix_mp;\n\t\t\tatomic_set(&imgu_pipe->nodes[i].sequence, 0);\n\t\t}\n\t}\n\n\tr = imgu_v4l2_register(imgu);\n\tif (r)\n\t\treturn r;\n\n\t \n\tfor (j = 0; j < IMGU_MAX_PIPE_NUM; j++) {\n\t\timgu_pipe = &imgu->imgu_pipe[j];\n\n\t\trects[IPU3_CSS_RECT_EFFECTIVE] = &imgu_pipe->imgu_sd.rect.eff;\n\t\trects[IPU3_CSS_RECT_BDS] = &imgu_pipe->imgu_sd.rect.bds;\n\t\timgu_css_fmt_set(&imgu->css, fmts, rects, j);\n\n\t\t \n\t\tr = imgu_dummybufs_preallocate(imgu, j);\n\t\tif (r) {\n\t\t\tdev_err(&imgu->pci_dev->dev,\n\t\t\t\t\"failed to pre-allocate dummy buffers (%d)\", r);\n\t\t\tgoto out_cleanup;\n\t\t}\n\t}\n\n\treturn 0;\n\nout_cleanup:\n\timgu_video_nodes_exit(imgu);\n\n\treturn r;\n}\n\n \n\nstatic irqreturn_t imgu_isr_threaded(int irq, void *imgu_ptr)\n{\n\tstruct imgu_device *imgu = imgu_ptr;\n\tstruct imgu_media_pipe *imgu_pipe;\n\tint p;\n\n\t \n\tdo {\n\t\tu64 ns = ktime_get_ns();\n\t\tstruct imgu_css_buffer *b;\n\t\tstruct imgu_buffer *buf = NULL;\n\t\tunsigned int node, pipe;\n\t\tbool dummy;\n\n\t\tdo {\n\t\t\tmutex_lock(&imgu->lock);\n\t\t\tb = imgu_css_buf_dequeue(&imgu->css);\n\t\t\tmutex_unlock(&imgu->lock);\n\t\t} while (PTR_ERR(b) == -EAGAIN);\n\n\t\tif (IS_ERR(b)) {\n\t\t\tif (PTR_ERR(b) != -EBUSY)\t \n\t\t\t\tdev_err(&imgu->pci_dev->dev,\n\t\t\t\t\t\"failed to dequeue buffers (%ld)\\n\",\n\t\t\t\t\tPTR_ERR(b));\n\t\t\tbreak;\n\t\t}\n\n\t\tnode = imgu_map_node(imgu, b->queue);\n\t\tpipe = b->pipe;\n\t\tdummy = imgu_dummybufs_check(imgu, b, pipe);\n\t\tif (!dummy)\n\t\t\tbuf = container_of(b, struct imgu_buffer, css_buf);\n\t\tdev_dbg(&imgu->pci_dev->dev,\n\t\t\t\"dequeue %s %s buffer %d daddr 0x%x from css\\n\",\n\t\t\tdummy ? \"dummy\" : \"user\",\n\t\t\timgu_node_map[node].name,\n\t\t\tdummy ? 0 : buf->vid_buf.vbb.vb2_buf.index,\n\t\t\t(u32)b->daddr);\n\n\t\tif (dummy)\n\t\t\t \n\t\t\tcontinue;\n\n\t\t \n\t\timgu_pipe = &imgu->imgu_pipe[pipe];\n\t\tif (!imgu_pipe->nodes[node].output) {\n\t\t\tbuf->vid_buf.vbb.vb2_buf.timestamp = ns;\n\t\t\tbuf->vid_buf.vbb.field = V4L2_FIELD_NONE;\n\t\t\tbuf->vid_buf.vbb.sequence =\n\t\t\t\tatomic_inc_return(\n\t\t\t\t&imgu_pipe->nodes[node].sequence);\n\t\t\tdev_dbg(&imgu->pci_dev->dev, \"vb2 buffer sequence %d\",\n\t\t\t\tbuf->vid_buf.vbb.sequence);\n\t\t}\n\t\timgu_buffer_done(imgu, &buf->vid_buf.vbb.vb2_buf,\n\t\t\t\t imgu_css_buf_state(&buf->css_buf) ==\n\t\t\t\t\t\t    IPU3_CSS_BUFFER_DONE ?\n\t\t\t\t\t\t    VB2_BUF_STATE_DONE :\n\t\t\t\t\t\t    VB2_BUF_STATE_ERROR);\n\t\tmutex_lock(&imgu->lock);\n\t\tif (imgu_css_queue_empty(&imgu->css))\n\t\t\twake_up_all(&imgu->buf_drain_wq);\n\t\tmutex_unlock(&imgu->lock);\n\t} while (1);\n\n\t \n\tif (!atomic_read(&imgu->qbuf_barrier))\n\t\tfor_each_set_bit(p, imgu->css.enabled_pipes, IMGU_MAX_PIPE_NUM)\n\t\t\timgu_queue_buffers(imgu, false, p);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t imgu_isr(int irq, void *imgu_ptr)\n{\n\tstruct imgu_device *imgu = imgu_ptr;\n\n\t \n\tif (imgu_css_irq_ack(&imgu->css) < 0)\n\t\treturn IRQ_NONE;\n\n\treturn IRQ_WAKE_THREAD;\n}\n\nstatic int imgu_pci_config_setup(struct pci_dev *dev)\n{\n\tu16 pci_command;\n\tint r = pci_enable_msi(dev);\n\n\tif (r) {\n\t\tdev_err(&dev->dev, \"failed to enable MSI (%d)\\n\", r);\n\t\treturn r;\n\t}\n\n\tpci_read_config_word(dev, PCI_COMMAND, &pci_command);\n\tpci_command |= PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER |\n\t\t\tPCI_COMMAND_INTX_DISABLE;\n\tpci_write_config_word(dev, PCI_COMMAND, pci_command);\n\n\treturn 0;\n}\n\nstatic int imgu_pci_probe(struct pci_dev *pci_dev,\n\t\t\t  const struct pci_device_id *id)\n{\n\tstruct imgu_device *imgu;\n\tphys_addr_t phys;\n\tunsigned long phys_len;\n\tvoid __iomem *const *iomap;\n\tint r;\n\n\timgu = devm_kzalloc(&pci_dev->dev, sizeof(*imgu), GFP_KERNEL);\n\tif (!imgu)\n\t\treturn -ENOMEM;\n\n\timgu->pci_dev = pci_dev;\n\n\tr = pcim_enable_device(pci_dev);\n\tif (r) {\n\t\tdev_err(&pci_dev->dev, \"failed to enable device (%d)\\n\", r);\n\t\treturn r;\n\t}\n\n\tdev_info(&pci_dev->dev, \"device 0x%x (rev: 0x%x)\\n\",\n\t\t pci_dev->device, pci_dev->revision);\n\n\tphys = pci_resource_start(pci_dev, IMGU_PCI_BAR);\n\tphys_len = pci_resource_len(pci_dev, IMGU_PCI_BAR);\n\n\tr = pcim_iomap_regions(pci_dev, 1 << IMGU_PCI_BAR, pci_name(pci_dev));\n\tif (r) {\n\t\tdev_err(&pci_dev->dev, \"failed to remap I/O memory (%d)\\n\", r);\n\t\treturn r;\n\t}\n\tdev_info(&pci_dev->dev, \"physical base address %pap, %lu bytes\\n\",\n\t\t &phys, phys_len);\n\n\tiomap = pcim_iomap_table(pci_dev);\n\tif (!iomap) {\n\t\tdev_err(&pci_dev->dev, \"failed to iomap table\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\timgu->base = iomap[IMGU_PCI_BAR];\n\n\tpci_set_drvdata(pci_dev, imgu);\n\n\tpci_set_master(pci_dev);\n\n\tr = dma_coerce_mask_and_coherent(&pci_dev->dev, IMGU_DMA_MASK);\n\tif (r) {\n\t\tdev_err(&pci_dev->dev, \"failed to set DMA mask (%d)\\n\", r);\n\t\treturn -ENODEV;\n\t}\n\n\tr = imgu_pci_config_setup(pci_dev);\n\tif (r)\n\t\treturn r;\n\n\tmutex_init(&imgu->lock);\n\tmutex_init(&imgu->streaming_lock);\n\tatomic_set(&imgu->qbuf_barrier, 0);\n\tinit_waitqueue_head(&imgu->buf_drain_wq);\n\n\tr = imgu_css_set_powerup(&pci_dev->dev, imgu->base, 200);\n\tif (r) {\n\t\tdev_err(&pci_dev->dev,\n\t\t\t\"failed to power up CSS (%d)\\n\", r);\n\t\tgoto out_mutex_destroy;\n\t}\n\n\timgu->mmu = imgu_mmu_init(&pci_dev->dev, imgu->base);\n\tif (IS_ERR(imgu->mmu)) {\n\t\tr = PTR_ERR(imgu->mmu);\n\t\tdev_err(&pci_dev->dev, \"failed to initialize MMU (%d)\\n\", r);\n\t\tgoto out_css_powerdown;\n\t}\n\n\tr = imgu_dmamap_init(imgu);\n\tif (r) {\n\t\tdev_err(&pci_dev->dev,\n\t\t\t\"failed to initialize DMA mapping (%d)\\n\", r);\n\t\tgoto out_mmu_exit;\n\t}\n\n\t \n\tr = imgu_css_init(&pci_dev->dev, &imgu->css, imgu->base, phys_len);\n\tif (r) {\n\t\tdev_err(&pci_dev->dev, \"failed to initialize CSS (%d)\\n\", r);\n\t\tgoto out_dmamap_exit;\n\t}\n\n\t \n\tr = imgu_video_nodes_init(imgu);\n\tif (r) {\n\t\tdev_err(&pci_dev->dev, \"failed to create V4L2 devices (%d)\\n\",\n\t\t\tr);\n\t\tgoto out_css_cleanup;\n\t}\n\n\tr = devm_request_threaded_irq(&pci_dev->dev, pci_dev->irq,\n\t\t\t\t      imgu_isr, imgu_isr_threaded,\n\t\t\t\t      IRQF_SHARED, IMGU_NAME, imgu);\n\tif (r) {\n\t\tdev_err(&pci_dev->dev, \"failed to request IRQ (%d)\\n\", r);\n\t\tgoto out_video_exit;\n\t}\n\n\tpm_runtime_put_noidle(&pci_dev->dev);\n\tpm_runtime_allow(&pci_dev->dev);\n\n\treturn 0;\n\nout_video_exit:\n\timgu_video_nodes_exit(imgu);\nout_css_cleanup:\n\timgu_css_cleanup(&imgu->css);\nout_dmamap_exit:\n\timgu_dmamap_exit(imgu);\nout_mmu_exit:\n\timgu_mmu_exit(imgu->mmu);\nout_css_powerdown:\n\timgu_css_set_powerdown(&pci_dev->dev, imgu->base);\nout_mutex_destroy:\n\tmutex_destroy(&imgu->streaming_lock);\n\tmutex_destroy(&imgu->lock);\n\n\treturn r;\n}\n\nstatic void imgu_pci_remove(struct pci_dev *pci_dev)\n{\n\tstruct imgu_device *imgu = pci_get_drvdata(pci_dev);\n\n\tpm_runtime_forbid(&pci_dev->dev);\n\tpm_runtime_get_noresume(&pci_dev->dev);\n\n\timgu_video_nodes_exit(imgu);\n\timgu_css_cleanup(&imgu->css);\n\timgu_css_set_powerdown(&pci_dev->dev, imgu->base);\n\timgu_dmamap_exit(imgu);\n\timgu_mmu_exit(imgu->mmu);\n\tmutex_destroy(&imgu->streaming_lock);\n\tmutex_destroy(&imgu->lock);\n}\n\nstatic int __maybe_unused imgu_suspend(struct device *dev)\n{\n\tstruct pci_dev *pci_dev = to_pci_dev(dev);\n\tstruct imgu_device *imgu = pci_get_drvdata(pci_dev);\n\n\tdev_dbg(dev, \"enter %s\\n\", __func__);\n\timgu->suspend_in_stream = imgu_css_is_streaming(&imgu->css);\n\tif (!imgu->suspend_in_stream)\n\t\tgoto out;\n\t \n\tatomic_set(&imgu->qbuf_barrier, 1);\n\t \n\tsynchronize_irq(pci_dev->irq);\n\t \n\tif (!wait_event_timeout(imgu->buf_drain_wq,\n\t    imgu_css_queue_empty(&imgu->css), msecs_to_jiffies(1000)))\n\t\tdev_err(dev, \"wait buffer drain timeout.\\n\");\n\n\timgu_css_stop_streaming(&imgu->css);\n\tatomic_set(&imgu->qbuf_barrier, 0);\n\timgu_powerdown(imgu);\n\tpm_runtime_force_suspend(dev);\nout:\n\tdev_dbg(dev, \"leave %s\\n\", __func__);\n\treturn 0;\n}\n\nstatic int __maybe_unused imgu_resume(struct device *dev)\n{\n\tstruct imgu_device *imgu = dev_get_drvdata(dev);\n\tint r = 0;\n\tunsigned int pipe;\n\n\tdev_dbg(dev, \"enter %s\\n\", __func__);\n\n\tif (!imgu->suspend_in_stream)\n\t\tgoto out;\n\n\tpm_runtime_force_resume(dev);\n\n\tr = imgu_powerup(imgu);\n\tif (r) {\n\t\tdev_err(dev, \"failed to power up imgu\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\tr = imgu_css_start_streaming(&imgu->css);\n\tif (r) {\n\t\tdev_err(dev, \"failed to resume css streaming (%d)\", r);\n\t\tgoto out;\n\t}\n\n\tfor_each_set_bit(pipe, imgu->css.enabled_pipes, IMGU_MAX_PIPE_NUM) {\n\t\tr = imgu_queue_buffers(imgu, true, pipe);\n\t\tif (r)\n\t\t\tdev_err(dev, \"failed to queue buffers to pipe %d (%d)\",\n\t\t\t\tpipe, r);\n\t}\n\nout:\n\tdev_dbg(dev, \"leave %s\\n\", __func__);\n\n\treturn r;\n}\n\n \nstatic __maybe_unused int imgu_rpm_dummy_cb(struct device *dev)\n{\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops imgu_pm_ops = {\n\tSET_RUNTIME_PM_OPS(&imgu_rpm_dummy_cb, &imgu_rpm_dummy_cb, NULL)\n\tSET_SYSTEM_SLEEP_PM_OPS(&imgu_suspend, &imgu_resume)\n};\n\nstatic const struct pci_device_id imgu_pci_tbl[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, IMGU_PCI_ID) },\n\t{ 0, }\n};\n\nMODULE_DEVICE_TABLE(pci, imgu_pci_tbl);\n\nstatic struct pci_driver imgu_pci_driver = {\n\t.name = IMGU_NAME,\n\t.id_table = imgu_pci_tbl,\n\t.probe = imgu_pci_probe,\n\t.remove = imgu_pci_remove,\n\t.driver = {\n\t\t.pm = &imgu_pm_ops,\n\t},\n};\n\nmodule_pci_driver(imgu_pci_driver);\n\nMODULE_AUTHOR(\"Tuukka Toivonen <tuukka.toivonen@intel.com>\");\nMODULE_AUTHOR(\"Tianshu Qiu <tian.shu.qiu@intel.com>\");\nMODULE_AUTHOR(\"Jian Xu Zheng <jian.xu.zheng@intel.com>\");\nMODULE_AUTHOR(\"Yuning Pu <yuning.pu@intel.com>\");\nMODULE_AUTHOR(\"Yong Zhi <yong.zhi@intel.com>\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"Intel ipu3_imgu PCI driver\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}