{
  "module_name": "cpuidle-riscv-sbi.c",
  "hash_id": "3118355c8bd7b143651c2efcfc76c1cf74c8fdaa971accea5141df04d2532d5a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cpuidle/cpuidle-riscv-sbi.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"cpuidle-riscv-sbi: \" fmt\n\n#include <linux/cpuhotplug.h>\n#include <linux/cpuidle.h>\n#include <linux/cpumask.h>\n#include <linux/cpu_pm.h>\n#include <linux/cpu_cooling.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/slab.h>\n#include <linux/platform_device.h>\n#include <linux/pm_domain.h>\n#include <linux/pm_runtime.h>\n#include <asm/cpuidle.h>\n#include <asm/sbi.h>\n#include <asm/smp.h>\n#include <asm/suspend.h>\n\n#include \"dt_idle_states.h\"\n#include \"dt_idle_genpd.h\"\n\nstruct sbi_cpuidle_data {\n\tu32 *states;\n\tstruct device *dev;\n};\n\nstruct sbi_domain_state {\n\tbool available;\n\tu32 state;\n};\n\nstatic DEFINE_PER_CPU_READ_MOSTLY(struct sbi_cpuidle_data, sbi_cpuidle_data);\nstatic DEFINE_PER_CPU(struct sbi_domain_state, domain_state);\nstatic bool sbi_cpuidle_use_osi;\nstatic bool sbi_cpuidle_use_cpuhp;\nstatic bool sbi_cpuidle_pd_allow_domain_state;\n\nstatic inline void sbi_set_domain_state(u32 state)\n{\n\tstruct sbi_domain_state *data = this_cpu_ptr(&domain_state);\n\n\tdata->available = true;\n\tdata->state = state;\n}\n\nstatic inline u32 sbi_get_domain_state(void)\n{\n\tstruct sbi_domain_state *data = this_cpu_ptr(&domain_state);\n\n\treturn data->state;\n}\n\nstatic inline void sbi_clear_domain_state(void)\n{\n\tstruct sbi_domain_state *data = this_cpu_ptr(&domain_state);\n\n\tdata->available = false;\n}\n\nstatic inline bool sbi_is_domain_state_available(void)\n{\n\tstruct sbi_domain_state *data = this_cpu_ptr(&domain_state);\n\n\treturn data->available;\n}\n\nstatic int sbi_suspend_finisher(unsigned long suspend_type,\n\t\t\t\tunsigned long resume_addr,\n\t\t\t\tunsigned long opaque)\n{\n\tstruct sbiret ret;\n\n\tret = sbi_ecall(SBI_EXT_HSM, SBI_EXT_HSM_HART_SUSPEND,\n\t\t\tsuspend_type, resume_addr, opaque, 0, 0, 0);\n\n\treturn (ret.error) ? sbi_err_map_linux_errno(ret.error) : 0;\n}\n\nstatic int sbi_suspend(u32 state)\n{\n\tif (state & SBI_HSM_SUSP_NON_RET_BIT)\n\t\treturn cpu_suspend(state, sbi_suspend_finisher);\n\telse\n\t\treturn sbi_suspend_finisher(state, 0, 0);\n}\n\nstatic __cpuidle int sbi_cpuidle_enter_state(struct cpuidle_device *dev,\n\t\t\t\t\t     struct cpuidle_driver *drv, int idx)\n{\n\tu32 *states = __this_cpu_read(sbi_cpuidle_data.states);\n\tu32 state = states[idx];\n\n\tif (state & SBI_HSM_SUSP_NON_RET_BIT)\n\t\treturn CPU_PM_CPU_IDLE_ENTER_PARAM(sbi_suspend, idx, state);\n\telse\n\t\treturn CPU_PM_CPU_IDLE_ENTER_RETENTION_PARAM(sbi_suspend,\n\t\t\t\t\t\t\t     idx, state);\n}\n\nstatic __cpuidle int __sbi_enter_domain_idle_state(struct cpuidle_device *dev,\n\t\t\t\t\t\t   struct cpuidle_driver *drv, int idx,\n\t\t\t\t\t\t   bool s2idle)\n{\n\tstruct sbi_cpuidle_data *data = this_cpu_ptr(&sbi_cpuidle_data);\n\tu32 *states = data->states;\n\tstruct device *pd_dev = data->dev;\n\tu32 state;\n\tint ret;\n\n\tret = cpu_pm_enter();\n\tif (ret)\n\t\treturn -1;\n\n\t \n\tif (s2idle)\n\t\tdev_pm_genpd_suspend(pd_dev);\n\telse\n\t\tpm_runtime_put_sync_suspend(pd_dev);\n\n\tct_cpuidle_enter();\n\n\tif (sbi_is_domain_state_available())\n\t\tstate = sbi_get_domain_state();\n\telse\n\t\tstate = states[idx];\n\n\tret = sbi_suspend(state) ? -1 : idx;\n\n\tct_cpuidle_exit();\n\n\tif (s2idle)\n\t\tdev_pm_genpd_resume(pd_dev);\n\telse\n\t\tpm_runtime_get_sync(pd_dev);\n\n\tcpu_pm_exit();\n\n\t \n\tsbi_clear_domain_state();\n\treturn ret;\n}\n\nstatic int sbi_enter_domain_idle_state(struct cpuidle_device *dev,\n\t\t\t\t       struct cpuidle_driver *drv, int idx)\n{\n\treturn __sbi_enter_domain_idle_state(dev, drv, idx, false);\n}\n\nstatic int sbi_enter_s2idle_domain_idle_state(struct cpuidle_device *dev,\n\t\t\t\t\t      struct cpuidle_driver *drv,\n\t\t\t\t\t      int idx)\n{\n\treturn __sbi_enter_domain_idle_state(dev, drv, idx, true);\n}\n\nstatic int sbi_cpuidle_cpuhp_up(unsigned int cpu)\n{\n\tstruct device *pd_dev = __this_cpu_read(sbi_cpuidle_data.dev);\n\n\tif (pd_dev)\n\t\tpm_runtime_get_sync(pd_dev);\n\n\treturn 0;\n}\n\nstatic int sbi_cpuidle_cpuhp_down(unsigned int cpu)\n{\n\tstruct device *pd_dev = __this_cpu_read(sbi_cpuidle_data.dev);\n\n\tif (pd_dev) {\n\t\tpm_runtime_put_sync(pd_dev);\n\t\t \n\t\tsbi_clear_domain_state();\n\t}\n\n\treturn 0;\n}\n\nstatic void sbi_idle_init_cpuhp(void)\n{\n\tint err;\n\n\tif (!sbi_cpuidle_use_cpuhp)\n\t\treturn;\n\n\terr = cpuhp_setup_state_nocalls(CPUHP_AP_CPU_PM_STARTING,\n\t\t\t\t\t\"cpuidle/sbi:online\",\n\t\t\t\t\tsbi_cpuidle_cpuhp_up,\n\t\t\t\t\tsbi_cpuidle_cpuhp_down);\n\tif (err)\n\t\tpr_warn(\"Failed %d while setup cpuhp state\\n\", err);\n}\n\nstatic const struct of_device_id sbi_cpuidle_state_match[] = {\n\t{ .compatible = \"riscv,idle-state\",\n\t  .data = sbi_cpuidle_enter_state },\n\t{ },\n};\n\nstatic bool sbi_suspend_state_is_valid(u32 state)\n{\n\tif (state > SBI_HSM_SUSPEND_RET_DEFAULT &&\n\t    state < SBI_HSM_SUSPEND_RET_PLATFORM)\n\t\treturn false;\n\tif (state > SBI_HSM_SUSPEND_NON_RET_DEFAULT &&\n\t    state < SBI_HSM_SUSPEND_NON_RET_PLATFORM)\n\t\treturn false;\n\treturn true;\n}\n\nstatic int sbi_dt_parse_state_node(struct device_node *np, u32 *state)\n{\n\tint err = of_property_read_u32(np, \"riscv,sbi-suspend-param\", state);\n\n\tif (err) {\n\t\tpr_warn(\"%pOF missing riscv,sbi-suspend-param property\\n\", np);\n\t\treturn err;\n\t}\n\n\tif (!sbi_suspend_state_is_valid(*state)) {\n\t\tpr_warn(\"Invalid SBI suspend state %#x\\n\", *state);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int sbi_dt_cpu_init_topology(struct cpuidle_driver *drv,\n\t\t\t\t     struct sbi_cpuidle_data *data,\n\t\t\t\t     unsigned int state_count, int cpu)\n{\n\t \n\tif (!sbi_cpuidle_use_osi)\n\t\treturn 0;\n\n\tdata->dev = dt_idle_attach_cpu(cpu, \"sbi\");\n\tif (IS_ERR_OR_NULL(data->dev))\n\t\treturn PTR_ERR_OR_ZERO(data->dev);\n\n\t \n\tdrv->states[state_count - 1].flags |= CPUIDLE_FLAG_RCU_IDLE;\n\tdrv->states[state_count - 1].enter = sbi_enter_domain_idle_state;\n\tdrv->states[state_count - 1].enter_s2idle =\n\t\t\t\t\tsbi_enter_s2idle_domain_idle_state;\n\tsbi_cpuidle_use_cpuhp = true;\n\n\treturn 0;\n}\n\nstatic int sbi_cpuidle_dt_init_states(struct device *dev,\n\t\t\t\t\tstruct cpuidle_driver *drv,\n\t\t\t\t\tunsigned int cpu,\n\t\t\t\t\tunsigned int state_count)\n{\n\tstruct sbi_cpuidle_data *data = per_cpu_ptr(&sbi_cpuidle_data, cpu);\n\tstruct device_node *state_node;\n\tstruct device_node *cpu_node;\n\tu32 *states;\n\tint i, ret;\n\n\tcpu_node = of_cpu_device_node_get(cpu);\n\tif (!cpu_node)\n\t\treturn -ENODEV;\n\n\tstates = devm_kcalloc(dev, state_count, sizeof(*states), GFP_KERNEL);\n\tif (!states) {\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\t \n\tfor (i = 1; i < state_count; i++) {\n\t\tstate_node = of_get_cpu_state_node(cpu_node, i - 1);\n\t\tif (!state_node)\n\t\t\tbreak;\n\n\t\tret = sbi_dt_parse_state_node(state_node, &states[i]);\n\t\tof_node_put(state_node);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tpr_debug(\"sbi-state %#x index %d\\n\", states[i], i);\n\t}\n\tif (i != state_count) {\n\t\tret = -ENODEV;\n\t\tgoto fail;\n\t}\n\n\t \n\tret = sbi_dt_cpu_init_topology(drv, data, state_count, cpu);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tdata->states = states;\n\nfail:\n\tof_node_put(cpu_node);\n\n\treturn ret;\n}\n\nstatic void sbi_cpuidle_deinit_cpu(int cpu)\n{\n\tstruct sbi_cpuidle_data *data = per_cpu_ptr(&sbi_cpuidle_data, cpu);\n\n\tdt_idle_detach_cpu(data->dev);\n\tsbi_cpuidle_use_cpuhp = false;\n}\n\nstatic int sbi_cpuidle_init_cpu(struct device *dev, int cpu)\n{\n\tstruct cpuidle_driver *drv;\n\tunsigned int state_count = 0;\n\tint ret = 0;\n\n\tdrv = devm_kzalloc(dev, sizeof(*drv), GFP_KERNEL);\n\tif (!drv)\n\t\treturn -ENOMEM;\n\n\tdrv->name = \"sbi_cpuidle\";\n\tdrv->owner = THIS_MODULE;\n\tdrv->cpumask = (struct cpumask *)cpumask_of(cpu);\n\n\t \n\tdrv->states[0].enter = sbi_cpuidle_enter_state;\n\tdrv->states[0].exit_latency = 1;\n\tdrv->states[0].target_residency = 1;\n\tdrv->states[0].power_usage = UINT_MAX;\n\tstrcpy(drv->states[0].name, \"WFI\");\n\tstrcpy(drv->states[0].desc, \"RISC-V WFI\");\n\n\t \n\tret = dt_init_idle_driver(drv, sbi_cpuidle_state_match, 1);\n\tif (ret <= 0) {\n\t\tpr_debug(\"HART%ld: failed to parse DT idle states\\n\",\n\t\t\t cpuid_to_hartid_map(cpu));\n\t\treturn ret ? : -ENODEV;\n\t}\n\tstate_count = ret + 1;  \n\n\t \n\tret = sbi_cpuidle_dt_init_states(dev, drv, cpu, state_count);\n\tif (ret) {\n\t\tpr_err(\"HART%ld: failed to init idle states\\n\",\n\t\t       cpuid_to_hartid_map(cpu));\n\t\treturn ret;\n\t}\n\n\tret = cpuidle_register(drv, NULL);\n\tif (ret)\n\t\tgoto deinit;\n\n\tcpuidle_cooling_register(drv);\n\n\treturn 0;\ndeinit:\n\tsbi_cpuidle_deinit_cpu(cpu);\n\treturn ret;\n}\n\nstatic void sbi_cpuidle_domain_sync_state(struct device *dev)\n{\n\t \n\tsbi_cpuidle_pd_allow_domain_state = true;\n}\n\n#ifdef CONFIG_DT_IDLE_GENPD\n\nstatic int sbi_cpuidle_pd_power_off(struct generic_pm_domain *pd)\n{\n\tstruct genpd_power_state *state = &pd->states[pd->state_idx];\n\tu32 *pd_state;\n\n\tif (!state->data)\n\t\treturn 0;\n\n\tif (!sbi_cpuidle_pd_allow_domain_state)\n\t\treturn -EBUSY;\n\n\t \n\tpd_state = state->data;\n\tsbi_set_domain_state(*pd_state);\n\n\treturn 0;\n}\n\nstruct sbi_pd_provider {\n\tstruct list_head link;\n\tstruct device_node *node;\n};\n\nstatic LIST_HEAD(sbi_pd_providers);\n\nstatic int sbi_pd_init(struct device_node *np)\n{\n\tstruct generic_pm_domain *pd;\n\tstruct sbi_pd_provider *pd_provider;\n\tstruct dev_power_governor *pd_gov;\n\tint ret = -ENOMEM;\n\n\tpd = dt_idle_pd_alloc(np, sbi_dt_parse_state_node);\n\tif (!pd)\n\t\tgoto out;\n\n\tpd_provider = kzalloc(sizeof(*pd_provider), GFP_KERNEL);\n\tif (!pd_provider)\n\t\tgoto free_pd;\n\n\tpd->flags |= GENPD_FLAG_IRQ_SAFE | GENPD_FLAG_CPU_DOMAIN;\n\n\t \n\tif (sbi_cpuidle_use_osi)\n\t\tpd->power_off = sbi_cpuidle_pd_power_off;\n\telse\n\t\tpd->flags |= GENPD_FLAG_ALWAYS_ON;\n\n\t \n\tpd_gov = pd->states ? &pm_domain_cpu_gov : NULL;\n\n\tret = pm_genpd_init(pd, pd_gov, false);\n\tif (ret)\n\t\tgoto free_pd_prov;\n\n\tret = of_genpd_add_provider_simple(np, pd);\n\tif (ret)\n\t\tgoto remove_pd;\n\n\tpd_provider->node = of_node_get(np);\n\tlist_add(&pd_provider->link, &sbi_pd_providers);\n\n\tpr_debug(\"init PM domain %s\\n\", pd->name);\n\treturn 0;\n\nremove_pd:\n\tpm_genpd_remove(pd);\nfree_pd_prov:\n\tkfree(pd_provider);\nfree_pd:\n\tdt_idle_pd_free(pd);\nout:\n\tpr_err(\"failed to init PM domain ret=%d %pOF\\n\", ret, np);\n\treturn ret;\n}\n\nstatic void sbi_pd_remove(void)\n{\n\tstruct sbi_pd_provider *pd_provider, *it;\n\tstruct generic_pm_domain *genpd;\n\n\tlist_for_each_entry_safe(pd_provider, it, &sbi_pd_providers, link) {\n\t\tof_genpd_del_provider(pd_provider->node);\n\n\t\tgenpd = of_genpd_remove_last(pd_provider->node);\n\t\tif (!IS_ERR(genpd))\n\t\t\tkfree(genpd);\n\n\t\tof_node_put(pd_provider->node);\n\t\tlist_del(&pd_provider->link);\n\t\tkfree(pd_provider);\n\t}\n}\n\nstatic int sbi_genpd_probe(struct device_node *np)\n{\n\tstruct device_node *node;\n\tint ret = 0, pd_count = 0;\n\n\tif (!np)\n\t\treturn -ENODEV;\n\n\t \n\tfor_each_child_of_node(np, node) {\n\t\tif (!of_property_present(node, \"#power-domain-cells\"))\n\t\t\tcontinue;\n\n\t\tret = sbi_pd_init(node);\n\t\tif (ret)\n\t\t\tgoto put_node;\n\n\t\tpd_count++;\n\t}\n\n\t \n\tif (!pd_count)\n\t\tgoto no_pd;\n\n\t \n\tret = dt_idle_pd_init_topology(np);\n\tif (ret)\n\t\tgoto remove_pd;\n\n\treturn 0;\n\nput_node:\n\tof_node_put(node);\nremove_pd:\n\tsbi_pd_remove();\n\tpr_err(\"failed to create CPU PM domains ret=%d\\n\", ret);\nno_pd:\n\treturn ret;\n}\n\n#else\n\nstatic inline int sbi_genpd_probe(struct device_node *np)\n{\n\treturn 0;\n}\n\n#endif\n\nstatic int sbi_cpuidle_probe(struct platform_device *pdev)\n{\n\tint cpu, ret;\n\tstruct cpuidle_driver *drv;\n\tstruct cpuidle_device *dev;\n\tstruct device_node *np, *pds_node;\n\n\t \n\tsbi_cpuidle_use_osi = true;\n\tfor_each_possible_cpu(cpu) {\n\t\tnp = of_cpu_device_node_get(cpu);\n\t\tif (np &&\n\t\t    of_property_present(np, \"power-domains\") &&\n\t\t    of_property_present(np, \"power-domain-names\")) {\n\t\t\tcontinue;\n\t\t} else {\n\t\t\tsbi_cpuidle_use_osi = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tpds_node = of_find_node_by_path(\"/cpus/power-domains\");\n\tif (pds_node) {\n\t\tret = sbi_genpd_probe(pds_node);\n\t\tof_node_put(pds_node);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t \n\tfor_each_possible_cpu(cpu) {\n\t\tret = sbi_cpuidle_init_cpu(&pdev->dev, cpu);\n\t\tif (ret) {\n\t\t\tpr_debug(\"HART%ld: idle driver init failed\\n\",\n\t\t\t\t cpuid_to_hartid_map(cpu));\n\t\t\tgoto out_fail;\n\t\t}\n\t}\n\n\t \n\tsbi_idle_init_cpuhp();\n\n\tpr_info(\"idle driver registered for all CPUs\\n\");\n\n\treturn 0;\n\nout_fail:\n\twhile (--cpu >= 0) {\n\t\tdev = per_cpu(cpuidle_devices, cpu);\n\t\tdrv = cpuidle_get_cpu_driver(dev);\n\t\tcpuidle_unregister(drv);\n\t\tsbi_cpuidle_deinit_cpu(cpu);\n\t}\n\n\treturn ret;\n}\n\nstatic struct platform_driver sbi_cpuidle_driver = {\n\t.probe = sbi_cpuidle_probe,\n\t.driver = {\n\t\t.name = \"sbi-cpuidle\",\n\t\t.sync_state = sbi_cpuidle_domain_sync_state,\n\t},\n};\n\nstatic int __init sbi_cpuidle_init(void)\n{\n\tint ret;\n\tstruct platform_device *pdev;\n\n\t \n\tif ((sbi_spec_version < sbi_mk_version(0, 3)) ||\n\t    !sbi_probe_extension(SBI_EXT_HSM)) {\n\t\tpr_info(\"HSM suspend not available\\n\");\n\t\treturn 0;\n\t}\n\n\tret = platform_driver_register(&sbi_cpuidle_driver);\n\tif (ret)\n\t\treturn ret;\n\n\tpdev = platform_device_register_simple(\"sbi-cpuidle\",\n\t\t\t\t\t\t-1, NULL, 0);\n\tif (IS_ERR(pdev)) {\n\t\tplatform_driver_unregister(&sbi_cpuidle_driver);\n\t\treturn PTR_ERR(pdev);\n\t}\n\n\treturn 0;\n}\ndevice_initcall(sbi_cpuidle_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}