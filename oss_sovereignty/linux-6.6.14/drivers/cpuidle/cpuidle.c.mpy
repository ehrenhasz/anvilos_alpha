{
  "module_name": "cpuidle.c",
  "hash_id": "91c91bfb431bc840a40e5f03ca316be0448998571672b8f90cf87c0697c731b4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cpuidle/cpuidle.c",
  "human_readable_source": " \n\n#include \"linux/percpu-defs.h\"\n#include <linux/clockchips.h>\n#include <linux/kernel.h>\n#include <linux/mutex.h>\n#include <linux/sched.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/idle.h>\n#include <linux/notifier.h>\n#include <linux/pm_qos.h>\n#include <linux/cpu.h>\n#include <linux/cpuidle.h>\n#include <linux/ktime.h>\n#include <linux/hrtimer.h>\n#include <linux/module.h>\n#include <linux/suspend.h>\n#include <linux/tick.h>\n#include <linux/mmu_context.h>\n#include <linux/context_tracking.h>\n#include <trace/events/power.h>\n\n#include \"cpuidle.h\"\n\nDEFINE_PER_CPU(struct cpuidle_device *, cpuidle_devices);\nDEFINE_PER_CPU(struct cpuidle_device, cpuidle_dev);\n\nDEFINE_MUTEX(cpuidle_lock);\nLIST_HEAD(cpuidle_detected_devices);\n\nstatic int enabled_devices;\nstatic int off __read_mostly;\nstatic int initialized __read_mostly;\n\nint cpuidle_disabled(void)\n{\n\treturn off;\n}\nvoid disable_cpuidle(void)\n{\n\toff = 1;\n}\n\nbool cpuidle_not_available(struct cpuidle_driver *drv,\n\t\t\t   struct cpuidle_device *dev)\n{\n\treturn off || !initialized || !drv || !dev || !dev->enabled;\n}\n\n \nint cpuidle_play_dead(void)\n{\n\tstruct cpuidle_device *dev = __this_cpu_read(cpuidle_devices);\n\tstruct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);\n\tint i;\n\n\tif (!drv)\n\t\treturn -ENODEV;\n\n\t \n\tfor (i = drv->state_count - 1; i >= 0; i--)\n\t\tif (drv->states[i].enter_dead)\n\t\t\treturn drv->states[i].enter_dead(dev, i);\n\n\treturn -ENODEV;\n}\n\nstatic int find_deepest_state(struct cpuidle_driver *drv,\n\t\t\t      struct cpuidle_device *dev,\n\t\t\t      u64 max_latency_ns,\n\t\t\t      unsigned int forbidden_flags,\n\t\t\t      bool s2idle)\n{\n\tu64 latency_req = 0;\n\tint i, ret = 0;\n\n\tfor (i = 1; i < drv->state_count; i++) {\n\t\tstruct cpuidle_state *s = &drv->states[i];\n\n\t\tif (dev->states_usage[i].disable ||\n\t\t    s->exit_latency_ns <= latency_req ||\n\t\t    s->exit_latency_ns > max_latency_ns ||\n\t\t    (s->flags & forbidden_flags) ||\n\t\t    (s2idle && !s->enter_s2idle))\n\t\t\tcontinue;\n\n\t\tlatency_req = s->exit_latency_ns;\n\t\tret = i;\n\t}\n\treturn ret;\n}\n\n \nvoid cpuidle_use_deepest_state(u64 latency_limit_ns)\n{\n\tstruct cpuidle_device *dev;\n\n\tpreempt_disable();\n\tdev = cpuidle_get_device();\n\tif (dev)\n\t\tdev->forced_idle_latency_limit_ns = latency_limit_ns;\n\tpreempt_enable();\n}\n\n \nint cpuidle_find_deepest_state(struct cpuidle_driver *drv,\n\t\t\t       struct cpuidle_device *dev,\n\t\t\t       u64 latency_limit_ns)\n{\n\treturn find_deepest_state(drv, dev, latency_limit_ns, 0, false);\n}\n\n#ifdef CONFIG_SUSPEND\nstatic noinstr void enter_s2idle_proper(struct cpuidle_driver *drv,\n\t\t\t\t\t struct cpuidle_device *dev, int index)\n{\n\tstruct cpuidle_state *target_state = &drv->states[index];\n\tktime_t time_start, time_end;\n\n\tinstrumentation_begin();\n\n\ttime_start = ns_to_ktime(local_clock_noinstr());\n\n\ttick_freeze();\n\t \n\tstop_critical_timings();\n\tif (!(target_state->flags & CPUIDLE_FLAG_RCU_IDLE)) {\n\t\tct_cpuidle_enter();\n\t\t \n\t\tinstrumentation_begin();\n\t}\n\ttarget_state->enter_s2idle(dev, drv, index);\n\tif (WARN_ON_ONCE(!irqs_disabled()))\n\t\traw_local_irq_disable();\n\tif (!(target_state->flags & CPUIDLE_FLAG_RCU_IDLE)) {\n\t\tinstrumentation_end();\n\t\tct_cpuidle_exit();\n\t}\n\ttick_unfreeze();\n\tstart_critical_timings();\n\n\ttime_end = ns_to_ktime(local_clock_noinstr());\n\n\tdev->states_usage[index].s2idle_time += ktime_us_delta(time_end, time_start);\n\tdev->states_usage[index].s2idle_usage++;\n\tinstrumentation_end();\n}\n\n \nint cpuidle_enter_s2idle(struct cpuidle_driver *drv, struct cpuidle_device *dev)\n{\n\tint index;\n\n\t \n\tindex = find_deepest_state(drv, dev, U64_MAX, 0, true);\n\tif (index > 0) {\n\t\tenter_s2idle_proper(drv, dev, index);\n\t\tlocal_irq_enable();\n\t}\n\treturn index;\n}\n#endif  \n\n \nnoinstr int cpuidle_enter_state(struct cpuidle_device *dev,\n\t\t\t\t struct cpuidle_driver *drv,\n\t\t\t\t int index)\n{\n\tint entered_state;\n\n\tstruct cpuidle_state *target_state = &drv->states[index];\n\tbool broadcast = !!(target_state->flags & CPUIDLE_FLAG_TIMER_STOP);\n\tktime_t time_start, time_end;\n\n\tinstrumentation_begin();\n\n\t \n\tif (broadcast && tick_broadcast_enter()) {\n\t\tindex = find_deepest_state(drv, dev, target_state->exit_latency_ns,\n\t\t\t\t\t   CPUIDLE_FLAG_TIMER_STOP, false);\n\t\tif (index < 0) {\n\t\t\tdefault_idle_call();\n\t\t\treturn -EBUSY;\n\t\t}\n\t\ttarget_state = &drv->states[index];\n\t\tbroadcast = false;\n\t}\n\n\tif (target_state->flags & CPUIDLE_FLAG_TLB_FLUSHED)\n\t\tleave_mm(dev->cpu);\n\n\t \n\tsched_idle_set_state(target_state);\n\n\ttrace_cpu_idle(index, dev->cpu);\n\ttime_start = ns_to_ktime(local_clock_noinstr());\n\n\tstop_critical_timings();\n\tif (!(target_state->flags & CPUIDLE_FLAG_RCU_IDLE)) {\n\t\tct_cpuidle_enter();\n\t\t \n\t\tinstrumentation_begin();\n\t}\n\n\t \n\tentered_state = target_state->enter(dev, drv, index);\n\n\tif (WARN_ONCE(!irqs_disabled(), \"%ps leaked IRQ state\", target_state->enter))\n\t\traw_local_irq_disable();\n\n\tif (!(target_state->flags & CPUIDLE_FLAG_RCU_IDLE)) {\n\t\tinstrumentation_end();\n\t\tct_cpuidle_exit();\n\t}\n\tstart_critical_timings();\n\n\tsched_clock_idle_wakeup_event();\n\ttime_end = ns_to_ktime(local_clock_noinstr());\n\ttrace_cpu_idle(PWR_EVENT_EXIT, dev->cpu);\n\n\t \n\tsched_idle_set_state(NULL);\n\n\tif (broadcast)\n\t\ttick_broadcast_exit();\n\n\tif (!cpuidle_state_is_coupled(drv, index))\n\t\tlocal_irq_enable();\n\n\tif (entered_state >= 0) {\n\t\ts64 diff, delay = drv->states[entered_state].exit_latency_ns;\n\t\tint i;\n\n\t\t \n\t\tdiff = ktime_sub(time_end, time_start);\n\n\t\tdev->last_residency_ns = diff;\n\t\tdev->states_usage[entered_state].time_ns += diff;\n\t\tdev->states_usage[entered_state].usage++;\n\n\t\tif (diff < drv->states[entered_state].target_residency_ns) {\n\t\t\tfor (i = entered_state - 1; i >= 0; i--) {\n\t\t\t\tif (dev->states_usage[i].disable)\n\t\t\t\t\tcontinue;\n\n\t\t\t\t \n\t\t\t\tdev->states_usage[entered_state].above++;\n\t\t\t\ttrace_cpu_idle_miss(dev->cpu, entered_state, false);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (diff > delay) {\n\t\t\tfor (i = entered_state + 1; i < drv->state_count; i++) {\n\t\t\t\tif (dev->states_usage[i].disable)\n\t\t\t\t\tcontinue;\n\n\t\t\t\t \n\t\t\t\tif (diff - delay >= drv->states[i].target_residency_ns) {\n\t\t\t\t\tdev->states_usage[entered_state].below++;\n\t\t\t\t\ttrace_cpu_idle_miss(dev->cpu, entered_state, true);\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdev->last_residency_ns = 0;\n\t\tdev->states_usage[index].rejected++;\n\t}\n\n\tinstrumentation_end();\n\n\treturn entered_state;\n}\n\n \nint cpuidle_select(struct cpuidle_driver *drv, struct cpuidle_device *dev,\n\t\t   bool *stop_tick)\n{\n\treturn cpuidle_curr_governor->select(drv, dev, stop_tick);\n}\n\n \nint cpuidle_enter(struct cpuidle_driver *drv, struct cpuidle_device *dev,\n\t\t  int index)\n{\n\tint ret = 0;\n\n\t \n\tWRITE_ONCE(dev->next_hrtimer, tick_nohz_get_next_hrtimer());\n\n\tif (cpuidle_state_is_coupled(drv, index))\n\t\tret = cpuidle_enter_state_coupled(dev, drv, index);\n\telse\n\t\tret = cpuidle_enter_state(dev, drv, index);\n\n\tWRITE_ONCE(dev->next_hrtimer, 0);\n\treturn ret;\n}\n\n \nvoid cpuidle_reflect(struct cpuidle_device *dev, int index)\n{\n\tif (cpuidle_curr_governor->reflect && index >= 0)\n\t\tcpuidle_curr_governor->reflect(dev, index);\n}\n\n \n#define CPUIDLE_POLL_MIN 10000\n#define CPUIDLE_POLL_MAX (TICK_NSEC / 16)\n\n \n__cpuidle u64 cpuidle_poll_time(struct cpuidle_driver *drv,\n\t\t      struct cpuidle_device *dev)\n{\n\tint i;\n\tu64 limit_ns;\n\n\tBUILD_BUG_ON(CPUIDLE_POLL_MIN > CPUIDLE_POLL_MAX);\n\n\tif (dev->poll_limit_ns)\n\t\treturn dev->poll_limit_ns;\n\n\tlimit_ns = CPUIDLE_POLL_MAX;\n\tfor (i = 1; i < drv->state_count; i++) {\n\t\tu64 state_limit;\n\n\t\tif (dev->states_usage[i].disable)\n\t\t\tcontinue;\n\n\t\tstate_limit = drv->states[i].target_residency_ns;\n\t\tif (state_limit < CPUIDLE_POLL_MIN)\n\t\t\tcontinue;\n\n\t\tlimit_ns = min_t(u64, state_limit, CPUIDLE_POLL_MAX);\n\t\tbreak;\n\t}\n\n\tdev->poll_limit_ns = limit_ns;\n\n\treturn dev->poll_limit_ns;\n}\n\n \nvoid cpuidle_install_idle_handler(void)\n{\n\tif (enabled_devices) {\n\t\t \n\t\tsmp_wmb();\n\t\tinitialized = 1;\n\t}\n}\n\n \nvoid cpuidle_uninstall_idle_handler(void)\n{\n\tif (enabled_devices) {\n\t\tinitialized = 0;\n\t\twake_up_all_idle_cpus();\n\t}\n\n\t \n\tsynchronize_rcu();\n}\n\n \nvoid cpuidle_pause_and_lock(void)\n{\n\tmutex_lock(&cpuidle_lock);\n\tcpuidle_uninstall_idle_handler();\n}\n\nEXPORT_SYMBOL_GPL(cpuidle_pause_and_lock);\n\n \nvoid cpuidle_resume_and_unlock(void)\n{\n\tcpuidle_install_idle_handler();\n\tmutex_unlock(&cpuidle_lock);\n}\n\nEXPORT_SYMBOL_GPL(cpuidle_resume_and_unlock);\n\n \nvoid cpuidle_pause(void)\n{\n\tmutex_lock(&cpuidle_lock);\n\tcpuidle_uninstall_idle_handler();\n\tmutex_unlock(&cpuidle_lock);\n}\n\n \nvoid cpuidle_resume(void)\n{\n\tmutex_lock(&cpuidle_lock);\n\tcpuidle_install_idle_handler();\n\tmutex_unlock(&cpuidle_lock);\n}\n\n \nint cpuidle_enable_device(struct cpuidle_device *dev)\n{\n\tint ret;\n\tstruct cpuidle_driver *drv;\n\n\tif (!dev)\n\t\treturn -EINVAL;\n\n\tif (dev->enabled)\n\t\treturn 0;\n\n\tif (!cpuidle_curr_governor)\n\t\treturn -EIO;\n\n\tdrv = cpuidle_get_cpu_driver(dev);\n\n\tif (!drv)\n\t\treturn -EIO;\n\n\tif (!dev->registered)\n\t\treturn -EINVAL;\n\n\tret = cpuidle_add_device_sysfs(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tif (cpuidle_curr_governor->enable) {\n\t\tret = cpuidle_curr_governor->enable(drv, dev);\n\t\tif (ret)\n\t\t\tgoto fail_sysfs;\n\t}\n\n\tsmp_wmb();\n\n\tdev->enabled = 1;\n\n\tenabled_devices++;\n\treturn 0;\n\nfail_sysfs:\n\tcpuidle_remove_device_sysfs(dev);\n\n\treturn ret;\n}\n\nEXPORT_SYMBOL_GPL(cpuidle_enable_device);\n\n \nvoid cpuidle_disable_device(struct cpuidle_device *dev)\n{\n\tstruct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);\n\n\tif (!dev || !dev->enabled)\n\t\treturn;\n\n\tif (!drv || !cpuidle_curr_governor)\n\t\treturn;\n\n\tdev->enabled = 0;\n\n\tif (cpuidle_curr_governor->disable)\n\t\tcpuidle_curr_governor->disable(drv, dev);\n\n\tcpuidle_remove_device_sysfs(dev);\n\tenabled_devices--;\n}\n\nEXPORT_SYMBOL_GPL(cpuidle_disable_device);\n\nstatic void __cpuidle_unregister_device(struct cpuidle_device *dev)\n{\n\tstruct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);\n\n\tlist_del(&dev->device_list);\n\tper_cpu(cpuidle_devices, dev->cpu) = NULL;\n\tmodule_put(drv->owner);\n\n\tdev->registered = 0;\n}\n\nstatic void __cpuidle_device_init(struct cpuidle_device *dev)\n{\n\tmemset(dev->states_usage, 0, sizeof(dev->states_usage));\n\tdev->last_residency_ns = 0;\n\tdev->next_hrtimer = 0;\n}\n\n \nstatic int __cpuidle_register_device(struct cpuidle_device *dev)\n{\n\tstruct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);\n\tint i, ret;\n\n\tif (!try_module_get(drv->owner))\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < drv->state_count; i++) {\n\t\tif (drv->states[i].flags & CPUIDLE_FLAG_UNUSABLE)\n\t\t\tdev->states_usage[i].disable |= CPUIDLE_STATE_DISABLED_BY_DRIVER;\n\n\t\tif (drv->states[i].flags & CPUIDLE_FLAG_OFF)\n\t\t\tdev->states_usage[i].disable |= CPUIDLE_STATE_DISABLED_BY_USER;\n\t}\n\n\tper_cpu(cpuidle_devices, dev->cpu) = dev;\n\tlist_add(&dev->device_list, &cpuidle_detected_devices);\n\n\tret = cpuidle_coupled_register_device(dev);\n\tif (ret)\n\t\t__cpuidle_unregister_device(dev);\n\telse\n\t\tdev->registered = 1;\n\n\treturn ret;\n}\n\n \nint cpuidle_register_device(struct cpuidle_device *dev)\n{\n\tint ret = -EBUSY;\n\n\tif (!dev)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&cpuidle_lock);\n\n\tif (dev->registered)\n\t\tgoto out_unlock;\n\n\t__cpuidle_device_init(dev);\n\n\tret = __cpuidle_register_device(dev);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tret = cpuidle_add_sysfs(dev);\n\tif (ret)\n\t\tgoto out_unregister;\n\n\tret = cpuidle_enable_device(dev);\n\tif (ret)\n\t\tgoto out_sysfs;\n\n\tcpuidle_install_idle_handler();\n\nout_unlock:\n\tmutex_unlock(&cpuidle_lock);\n\n\treturn ret;\n\nout_sysfs:\n\tcpuidle_remove_sysfs(dev);\nout_unregister:\n\t__cpuidle_unregister_device(dev);\n\tgoto out_unlock;\n}\n\nEXPORT_SYMBOL_GPL(cpuidle_register_device);\n\n \nvoid cpuidle_unregister_device(struct cpuidle_device *dev)\n{\n\tif (!dev || dev->registered == 0)\n\t\treturn;\n\n\tcpuidle_pause_and_lock();\n\n\tcpuidle_disable_device(dev);\n\n\tcpuidle_remove_sysfs(dev);\n\n\t__cpuidle_unregister_device(dev);\n\n\tcpuidle_coupled_unregister_device(dev);\n\n\tcpuidle_resume_and_unlock();\n}\n\nEXPORT_SYMBOL_GPL(cpuidle_unregister_device);\n\n \nvoid cpuidle_unregister(struct cpuidle_driver *drv)\n{\n\tint cpu;\n\tstruct cpuidle_device *device;\n\n\tfor_each_cpu(cpu, drv->cpumask) {\n\t\tdevice = &per_cpu(cpuidle_dev, cpu);\n\t\tcpuidle_unregister_device(device);\n\t}\n\n\tcpuidle_unregister_driver(drv);\n}\nEXPORT_SYMBOL_GPL(cpuidle_unregister);\n\n \nint cpuidle_register(struct cpuidle_driver *drv,\n\t\t     const struct cpumask *const coupled_cpus)\n{\n\tint ret, cpu;\n\tstruct cpuidle_device *device;\n\n\tret = cpuidle_register_driver(drv);\n\tif (ret) {\n\t\tpr_err(\"failed to register cpuidle driver\\n\");\n\t\treturn ret;\n\t}\n\n\tfor_each_cpu(cpu, drv->cpumask) {\n\t\tdevice = &per_cpu(cpuidle_dev, cpu);\n\t\tdevice->cpu = cpu;\n\n#ifdef CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED\n\t\t \n\t\tif (coupled_cpus)\n\t\t\tdevice->coupled_cpus = *coupled_cpus;\n#endif\n\t\tret = cpuidle_register_device(device);\n\t\tif (!ret)\n\t\t\tcontinue;\n\n\t\tpr_err(\"Failed to register cpuidle device for cpu%d\\n\", cpu);\n\n\t\tcpuidle_unregister(drv);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(cpuidle_register);\n\n \nstatic int __init cpuidle_init(void)\n{\n\tif (cpuidle_disabled())\n\t\treturn -ENODEV;\n\n\treturn cpuidle_add_interface();\n}\n\nmodule_param(off, int, 0444);\nmodule_param_string(governor, param_governor, CPUIDLE_NAME_LEN, 0444);\ncore_initcall(cpuidle_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}