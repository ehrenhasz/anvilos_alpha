{
  "module_name": "osl.c",
  "hash_id": "c1020a98ac612f771c7c56508d32769b022106883bf06de9ed8732b84288da29",
  "original_prompt": "Ingested from linux-6.6.14/drivers/acpi/osl.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"ACPI: OSL: \" fmt\n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/lockdep.h>\n#include <linux/pci.h>\n#include <linux/interrupt.h>\n#include <linux/kmod.h>\n#include <linux/delay.h>\n#include <linux/workqueue.h>\n#include <linux/nmi.h>\n#include <linux/acpi.h>\n#include <linux/efi.h>\n#include <linux/ioport.h>\n#include <linux/list.h>\n#include <linux/jiffies.h>\n#include <linux/semaphore.h>\n#include <linux/security.h>\n\n#include <asm/io.h>\n#include <linux/uaccess.h>\n#include <linux/io-64-nonatomic-lo-hi.h>\n\n#include \"acpica/accommon.h\"\n#include \"internal.h\"\n\n \n#define _COMPONENT\t\tACPI_OS_SERVICES\nACPI_MODULE_NAME(\"osl\");\n\nstruct acpi_os_dpc {\n\tacpi_osd_exec_callback function;\n\tvoid *context;\n\tstruct work_struct work;\n};\n\n#ifdef ENABLE_DEBUGGER\n#include <linux/kdb.h>\n\n \nint acpi_in_debugger;\nEXPORT_SYMBOL(acpi_in_debugger);\n#endif\t\t\t\t \n\nstatic int (*__acpi_os_prepare_sleep)(u8 sleep_state, u32 pm1a_ctrl,\n\t\t\t\t      u32 pm1b_ctrl);\nstatic int (*__acpi_os_prepare_extended_sleep)(u8 sleep_state, u32 val_a,\n\t\t\t\t      u32 val_b);\n\nstatic acpi_osd_handler acpi_irq_handler;\nstatic void *acpi_irq_context;\nstatic struct workqueue_struct *kacpid_wq;\nstatic struct workqueue_struct *kacpi_notify_wq;\nstatic struct workqueue_struct *kacpi_hotplug_wq;\nstatic bool acpi_os_initialized;\nunsigned int acpi_sci_irq = INVALID_ACPI_IRQ;\nbool acpi_permanent_mmap = false;\n\n \nstruct acpi_ioremap {\n\tstruct list_head list;\n\tvoid __iomem *virt;\n\tacpi_physical_address phys;\n\tacpi_size size;\n\tunion {\n\t\tunsigned long refcount;\n\t\tstruct rcu_work rwork;\n\t} track;\n};\n\nstatic LIST_HEAD(acpi_ioremaps);\nstatic DEFINE_MUTEX(acpi_ioremap_lock);\n#define acpi_ioremap_lock_held() lock_is_held(&acpi_ioremap_lock.dep_map)\n\nstatic void __init acpi_request_region (struct acpi_generic_address *gas,\n\tunsigned int length, char *desc)\n{\n\tu64 addr;\n\n\t \n\tmemcpy(&addr, &gas->address, sizeof(addr));\n\tif (!addr || !length)\n\t\treturn;\n\n\t \n\tif (gas->space_id == ACPI_ADR_SPACE_SYSTEM_IO)\n\t\trequest_region(addr, length, desc);\n\telse if (gas->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)\n\t\trequest_mem_region(addr, length, desc);\n}\n\nstatic int __init acpi_reserve_resources(void)\n{\n\tacpi_request_region(&acpi_gbl_FADT.xpm1a_event_block, acpi_gbl_FADT.pm1_event_length,\n\t\t\"ACPI PM1a_EVT_BLK\");\n\n\tacpi_request_region(&acpi_gbl_FADT.xpm1b_event_block, acpi_gbl_FADT.pm1_event_length,\n\t\t\"ACPI PM1b_EVT_BLK\");\n\n\tacpi_request_region(&acpi_gbl_FADT.xpm1a_control_block, acpi_gbl_FADT.pm1_control_length,\n\t\t\"ACPI PM1a_CNT_BLK\");\n\n\tacpi_request_region(&acpi_gbl_FADT.xpm1b_control_block, acpi_gbl_FADT.pm1_control_length,\n\t\t\"ACPI PM1b_CNT_BLK\");\n\n\tif (acpi_gbl_FADT.pm_timer_length == 4)\n\t\tacpi_request_region(&acpi_gbl_FADT.xpm_timer_block, 4, \"ACPI PM_TMR\");\n\n\tacpi_request_region(&acpi_gbl_FADT.xpm2_control_block, acpi_gbl_FADT.pm2_control_length,\n\t\t\"ACPI PM2_CNT_BLK\");\n\n\t \n\n\tif (!(acpi_gbl_FADT.gpe0_block_length & 0x1))\n\t\tacpi_request_region(&acpi_gbl_FADT.xgpe0_block,\n\t\t\t       acpi_gbl_FADT.gpe0_block_length, \"ACPI GPE0_BLK\");\n\n\tif (!(acpi_gbl_FADT.gpe1_block_length & 0x1))\n\t\tacpi_request_region(&acpi_gbl_FADT.xgpe1_block,\n\t\t\t       acpi_gbl_FADT.gpe1_block_length, \"ACPI GPE1_BLK\");\n\n\treturn 0;\n}\nfs_initcall_sync(acpi_reserve_resources);\n\nvoid acpi_os_printf(const char *fmt, ...)\n{\n\tva_list args;\n\tva_start(args, fmt);\n\tacpi_os_vprintf(fmt, args);\n\tva_end(args);\n}\nEXPORT_SYMBOL(acpi_os_printf);\n\nvoid acpi_os_vprintf(const char *fmt, va_list args)\n{\n\tstatic char buffer[512];\n\n\tvsprintf(buffer, fmt, args);\n\n#ifdef ENABLE_DEBUGGER\n\tif (acpi_in_debugger) {\n\t\tkdb_printf(\"%s\", buffer);\n\t} else {\n\t\tif (printk_get_level(buffer))\n\t\t\tprintk(\"%s\", buffer);\n\t\telse\n\t\t\tprintk(KERN_CONT \"%s\", buffer);\n\t}\n#else\n\tif (acpi_debugger_write_log(buffer) < 0) {\n\t\tif (printk_get_level(buffer))\n\t\t\tprintk(\"%s\", buffer);\n\t\telse\n\t\t\tprintk(KERN_CONT \"%s\", buffer);\n\t}\n#endif\n}\n\n#ifdef CONFIG_KEXEC\nstatic unsigned long acpi_rsdp;\nstatic int __init setup_acpi_rsdp(char *arg)\n{\n\treturn kstrtoul(arg, 16, &acpi_rsdp);\n}\nearly_param(\"acpi_rsdp\", setup_acpi_rsdp);\n#endif\n\nacpi_physical_address __init acpi_os_get_root_pointer(void)\n{\n\tacpi_physical_address pa;\n\n#ifdef CONFIG_KEXEC\n\t \n\tif (acpi_rsdp && !security_locked_down(LOCKDOWN_ACPI_TABLES)) {\n\t\tacpi_arch_set_root_pointer(acpi_rsdp);\n\t\treturn acpi_rsdp;\n\t}\n#endif\n\tpa = acpi_arch_get_root_pointer();\n\tif (pa)\n\t\treturn pa;\n\n\tif (efi_enabled(EFI_CONFIG_TABLES)) {\n\t\tif (efi.acpi20 != EFI_INVALID_TABLE_ADDR)\n\t\t\treturn efi.acpi20;\n\t\tif (efi.acpi != EFI_INVALID_TABLE_ADDR)\n\t\t\treturn efi.acpi;\n\t\tpr_err(\"System description tables not found\\n\");\n\t} else if (IS_ENABLED(CONFIG_ACPI_LEGACY_TABLES_LOOKUP)) {\n\t\tacpi_find_root_pointer(&pa);\n\t}\n\n\treturn pa;\n}\n\n \nstatic struct acpi_ioremap *\nacpi_map_lookup(acpi_physical_address phys, acpi_size size)\n{\n\tstruct acpi_ioremap *map;\n\n\tlist_for_each_entry_rcu(map, &acpi_ioremaps, list, acpi_ioremap_lock_held())\n\t\tif (map->phys <= phys &&\n\t\t    phys + size <= map->phys + map->size)\n\t\t\treturn map;\n\n\treturn NULL;\n}\n\n \nstatic void __iomem *\nacpi_map_vaddr_lookup(acpi_physical_address phys, unsigned int size)\n{\n\tstruct acpi_ioremap *map;\n\n\tmap = acpi_map_lookup(phys, size);\n\tif (map)\n\t\treturn map->virt + (phys - map->phys);\n\n\treturn NULL;\n}\n\nvoid __iomem *acpi_os_get_iomem(acpi_physical_address phys, unsigned int size)\n{\n\tstruct acpi_ioremap *map;\n\tvoid __iomem *virt = NULL;\n\n\tmutex_lock(&acpi_ioremap_lock);\n\tmap = acpi_map_lookup(phys, size);\n\tif (map) {\n\t\tvirt = map->virt + (phys - map->phys);\n\t\tmap->track.refcount++;\n\t}\n\tmutex_unlock(&acpi_ioremap_lock);\n\treturn virt;\n}\nEXPORT_SYMBOL_GPL(acpi_os_get_iomem);\n\n \nstatic struct acpi_ioremap *\nacpi_map_lookup_virt(void __iomem *virt, acpi_size size)\n{\n\tstruct acpi_ioremap *map;\n\n\tlist_for_each_entry_rcu(map, &acpi_ioremaps, list, acpi_ioremap_lock_held())\n\t\tif (map->virt <= virt &&\n\t\t    virt + size <= map->virt + map->size)\n\t\t\treturn map;\n\n\treturn NULL;\n}\n\n#if defined(CONFIG_IA64) || defined(CONFIG_ARM64) || defined(CONFIG_RISCV)\n \n#define should_use_kmap(pfn)   0\n#else\n#define should_use_kmap(pfn)   page_is_ram(pfn)\n#endif\n\nstatic void __iomem *acpi_map(acpi_physical_address pg_off, unsigned long pg_sz)\n{\n\tunsigned long pfn;\n\n\tpfn = pg_off >> PAGE_SHIFT;\n\tif (should_use_kmap(pfn)) {\n\t\tif (pg_sz > PAGE_SIZE)\n\t\t\treturn NULL;\n\t\treturn (void __iomem __force *)kmap(pfn_to_page(pfn));\n\t} else\n\t\treturn acpi_os_ioremap(pg_off, pg_sz);\n}\n\nstatic void acpi_unmap(acpi_physical_address pg_off, void __iomem *vaddr)\n{\n\tunsigned long pfn;\n\n\tpfn = pg_off >> PAGE_SHIFT;\n\tif (should_use_kmap(pfn))\n\t\tkunmap(pfn_to_page(pfn));\n\telse\n\t\tiounmap(vaddr);\n}\n\n \nvoid __iomem __ref\n*acpi_os_map_iomem(acpi_physical_address phys, acpi_size size)\n{\n\tstruct acpi_ioremap *map;\n\tvoid __iomem *virt;\n\tacpi_physical_address pg_off;\n\tacpi_size pg_sz;\n\n\tif (phys > ULONG_MAX) {\n\t\tpr_err(\"Cannot map memory that high: 0x%llx\\n\", phys);\n\t\treturn NULL;\n\t}\n\n\tif (!acpi_permanent_mmap)\n\t\treturn __acpi_map_table((unsigned long)phys, size);\n\n\tmutex_lock(&acpi_ioremap_lock);\n\t \n\tmap = acpi_map_lookup(phys, size);\n\tif (map) {\n\t\tmap->track.refcount++;\n\t\tgoto out;\n\t}\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (!map) {\n\t\tmutex_unlock(&acpi_ioremap_lock);\n\t\treturn NULL;\n\t}\n\n\tpg_off = round_down(phys, PAGE_SIZE);\n\tpg_sz = round_up(phys + size, PAGE_SIZE) - pg_off;\n\tvirt = acpi_map(phys, size);\n\tif (!virt) {\n\t\tmutex_unlock(&acpi_ioremap_lock);\n\t\tkfree(map);\n\t\treturn NULL;\n\t}\n\n\tINIT_LIST_HEAD(&map->list);\n\tmap->virt = (void __iomem __force *)((unsigned long)virt & PAGE_MASK);\n\tmap->phys = pg_off;\n\tmap->size = pg_sz;\n\tmap->track.refcount = 1;\n\n\tlist_add_tail_rcu(&map->list, &acpi_ioremaps);\n\nout:\n\tmutex_unlock(&acpi_ioremap_lock);\n\treturn map->virt + (phys - map->phys);\n}\nEXPORT_SYMBOL_GPL(acpi_os_map_iomem);\n\nvoid *__ref acpi_os_map_memory(acpi_physical_address phys, acpi_size size)\n{\n\treturn (void *)acpi_os_map_iomem(phys, size);\n}\nEXPORT_SYMBOL_GPL(acpi_os_map_memory);\n\nstatic void acpi_os_map_remove(struct work_struct *work)\n{\n\tstruct acpi_ioremap *map = container_of(to_rcu_work(work),\n\t\t\t\t\t\tstruct acpi_ioremap,\n\t\t\t\t\t\ttrack.rwork);\n\n\tacpi_unmap(map->phys, map->virt);\n\tkfree(map);\n}\n\n \nstatic void acpi_os_drop_map_ref(struct acpi_ioremap *map)\n{\n\tif (--map->track.refcount)\n\t\treturn;\n\n\tlist_del_rcu(&map->list);\n\n\tINIT_RCU_WORK(&map->track.rwork, acpi_os_map_remove);\n\tqueue_rcu_work(system_wq, &map->track.rwork);\n}\n\n \nvoid __ref acpi_os_unmap_iomem(void __iomem *virt, acpi_size size)\n{\n\tstruct acpi_ioremap *map;\n\n\tif (!acpi_permanent_mmap) {\n\t\t__acpi_unmap_table(virt, size);\n\t\treturn;\n\t}\n\n\tmutex_lock(&acpi_ioremap_lock);\n\n\tmap = acpi_map_lookup_virt(virt, size);\n\tif (!map) {\n\t\tmutex_unlock(&acpi_ioremap_lock);\n\t\tWARN(true, \"ACPI: %s: bad address %p\\n\", __func__, virt);\n\t\treturn;\n\t}\n\tacpi_os_drop_map_ref(map);\n\n\tmutex_unlock(&acpi_ioremap_lock);\n}\nEXPORT_SYMBOL_GPL(acpi_os_unmap_iomem);\n\n \nvoid __ref acpi_os_unmap_memory(void *virt, acpi_size size)\n{\n\tacpi_os_unmap_iomem((void __iomem *)virt, size);\n}\nEXPORT_SYMBOL_GPL(acpi_os_unmap_memory);\n\nvoid __iomem *acpi_os_map_generic_address(struct acpi_generic_address *gas)\n{\n\tu64 addr;\n\n\tif (gas->space_id != ACPI_ADR_SPACE_SYSTEM_MEMORY)\n\t\treturn NULL;\n\n\t \n\tmemcpy(&addr, &gas->address, sizeof(addr));\n\tif (!addr || !gas->bit_width)\n\t\treturn NULL;\n\n\treturn acpi_os_map_iomem(addr, gas->bit_width / 8);\n}\nEXPORT_SYMBOL(acpi_os_map_generic_address);\n\nvoid acpi_os_unmap_generic_address(struct acpi_generic_address *gas)\n{\n\tu64 addr;\n\tstruct acpi_ioremap *map;\n\n\tif (gas->space_id != ACPI_ADR_SPACE_SYSTEM_MEMORY)\n\t\treturn;\n\n\t \n\tmemcpy(&addr, &gas->address, sizeof(addr));\n\tif (!addr || !gas->bit_width)\n\t\treturn;\n\n\tmutex_lock(&acpi_ioremap_lock);\n\n\tmap = acpi_map_lookup(addr, gas->bit_width / 8);\n\tif (!map) {\n\t\tmutex_unlock(&acpi_ioremap_lock);\n\t\treturn;\n\t}\n\tacpi_os_drop_map_ref(map);\n\n\tmutex_unlock(&acpi_ioremap_lock);\n}\nEXPORT_SYMBOL(acpi_os_unmap_generic_address);\n\n#ifdef ACPI_FUTURE_USAGE\nacpi_status\nacpi_os_get_physical_address(void *virt, acpi_physical_address * phys)\n{\n\tif (!phys || !virt)\n\t\treturn AE_BAD_PARAMETER;\n\n\t*phys = virt_to_phys(virt);\n\n\treturn AE_OK;\n}\n#endif\n\n#ifdef CONFIG_ACPI_REV_OVERRIDE_POSSIBLE\nstatic bool acpi_rev_override;\n\nint __init acpi_rev_override_setup(char *str)\n{\n\tacpi_rev_override = true;\n\treturn 1;\n}\n__setup(\"acpi_rev_override\", acpi_rev_override_setup);\n#else\n#define acpi_rev_override\tfalse\n#endif\n\n#define ACPI_MAX_OVERRIDE_LEN 100\n\nstatic char acpi_os_name[ACPI_MAX_OVERRIDE_LEN];\n\nacpi_status\nacpi_os_predefined_override(const struct acpi_predefined_names *init_val,\n\t\t\t    acpi_string *new_val)\n{\n\tif (!init_val || !new_val)\n\t\treturn AE_BAD_PARAMETER;\n\n\t*new_val = NULL;\n\tif (!memcmp(init_val->name, \"_OS_\", 4) && strlen(acpi_os_name)) {\n\t\tpr_info(\"Overriding _OS definition to '%s'\\n\", acpi_os_name);\n\t\t*new_val = acpi_os_name;\n\t}\n\n\tif (!memcmp(init_val->name, \"_REV\", 4) && acpi_rev_override) {\n\t\tpr_info(\"Overriding _REV return value to 5\\n\");\n\t\t*new_val = (char *)5;\n\t}\n\n\treturn AE_OK;\n}\n\nstatic irqreturn_t acpi_irq(int irq, void *dev_id)\n{\n\tu32 handled;\n\n\thandled = (*acpi_irq_handler) (acpi_irq_context);\n\n\tif (handled) {\n\t\tacpi_irq_handled++;\n\t\treturn IRQ_HANDLED;\n\t} else {\n\t\tacpi_irq_not_handled++;\n\t\treturn IRQ_NONE;\n\t}\n}\n\nacpi_status\nacpi_os_install_interrupt_handler(u32 gsi, acpi_osd_handler handler,\n\t\t\t\t  void *context)\n{\n\tunsigned int irq;\n\n\tacpi_irq_stats_init();\n\n\t \n\tif (gsi != acpi_gbl_FADT.sci_interrupt)\n\t\treturn AE_BAD_PARAMETER;\n\n\tif (acpi_irq_handler)\n\t\treturn AE_ALREADY_ACQUIRED;\n\n\tif (acpi_gsi_to_irq(gsi, &irq) < 0) {\n\t\tpr_err(\"SCI (ACPI GSI %d) not registered\\n\", gsi);\n\t\treturn AE_OK;\n\t}\n\n\tacpi_irq_handler = handler;\n\tacpi_irq_context = context;\n\tif (request_irq(irq, acpi_irq, IRQF_SHARED, \"acpi\", acpi_irq)) {\n\t\tpr_err(\"SCI (IRQ%d) allocation failed\\n\", irq);\n\t\tacpi_irq_handler = NULL;\n\t\treturn AE_NOT_ACQUIRED;\n\t}\n\tacpi_sci_irq = irq;\n\n\treturn AE_OK;\n}\n\nacpi_status acpi_os_remove_interrupt_handler(u32 gsi, acpi_osd_handler handler)\n{\n\tif (gsi != acpi_gbl_FADT.sci_interrupt || !acpi_sci_irq_valid())\n\t\treturn AE_BAD_PARAMETER;\n\n\tfree_irq(acpi_sci_irq, acpi_irq);\n\tacpi_irq_handler = NULL;\n\tacpi_sci_irq = INVALID_ACPI_IRQ;\n\n\treturn AE_OK;\n}\n\n \n\nvoid acpi_os_sleep(u64 ms)\n{\n\tmsleep(ms);\n}\n\nvoid acpi_os_stall(u32 us)\n{\n\twhile (us) {\n\t\tu32 delay = 1000;\n\n\t\tif (delay > us)\n\t\t\tdelay = us;\n\t\tudelay(delay);\n\t\ttouch_nmi_watchdog();\n\t\tus -= delay;\n\t}\n}\n\n \nu64 acpi_os_get_timer(void)\n{\n\treturn (get_jiffies_64() - INITIAL_JIFFIES) *\n\t\t(ACPI_100NSEC_PER_SEC / HZ);\n}\n\nacpi_status acpi_os_read_port(acpi_io_address port, u32 *value, u32 width)\n{\n\tu32 dummy;\n\n\tif (value)\n\t\t*value = 0;\n\telse\n\t\tvalue = &dummy;\n\n\tif (width <= 8) {\n\t\t*value = inb(port);\n\t} else if (width <= 16) {\n\t\t*value = inw(port);\n\t} else if (width <= 32) {\n\t\t*value = inl(port);\n\t} else {\n\t\tpr_debug(\"%s: Access width %d not supported\\n\", __func__, width);\n\t\treturn AE_BAD_PARAMETER;\n\t}\n\n\treturn AE_OK;\n}\n\nEXPORT_SYMBOL(acpi_os_read_port);\n\nacpi_status acpi_os_write_port(acpi_io_address port, u32 value, u32 width)\n{\n\tif (width <= 8) {\n\t\toutb(value, port);\n\t} else if (width <= 16) {\n\t\toutw(value, port);\n\t} else if (width <= 32) {\n\t\toutl(value, port);\n\t} else {\n\t\tpr_debug(\"%s: Access width %d not supported\\n\", __func__, width);\n\t\treturn AE_BAD_PARAMETER;\n\t}\n\n\treturn AE_OK;\n}\n\nEXPORT_SYMBOL(acpi_os_write_port);\n\nint acpi_os_read_iomem(void __iomem *virt_addr, u64 *value, u32 width)\n{\n\n\tswitch (width) {\n\tcase 8:\n\t\t*(u8 *) value = readb(virt_addr);\n\t\tbreak;\n\tcase 16:\n\t\t*(u16 *) value = readw(virt_addr);\n\t\tbreak;\n\tcase 32:\n\t\t*(u32 *) value = readl(virt_addr);\n\t\tbreak;\n\tcase 64:\n\t\t*(u64 *) value = readq(virt_addr);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nacpi_status\nacpi_os_read_memory(acpi_physical_address phys_addr, u64 *value, u32 width)\n{\n\tvoid __iomem *virt_addr;\n\tunsigned int size = width / 8;\n\tbool unmap = false;\n\tu64 dummy;\n\tint error;\n\n\trcu_read_lock();\n\tvirt_addr = acpi_map_vaddr_lookup(phys_addr, size);\n\tif (!virt_addr) {\n\t\trcu_read_unlock();\n\t\tvirt_addr = acpi_os_ioremap(phys_addr, size);\n\t\tif (!virt_addr)\n\t\t\treturn AE_BAD_ADDRESS;\n\t\tunmap = true;\n\t}\n\n\tif (!value)\n\t\tvalue = &dummy;\n\n\terror = acpi_os_read_iomem(virt_addr, value, width);\n\tBUG_ON(error);\n\n\tif (unmap)\n\t\tiounmap(virt_addr);\n\telse\n\t\trcu_read_unlock();\n\n\treturn AE_OK;\n}\n\nacpi_status\nacpi_os_write_memory(acpi_physical_address phys_addr, u64 value, u32 width)\n{\n\tvoid __iomem *virt_addr;\n\tunsigned int size = width / 8;\n\tbool unmap = false;\n\n\trcu_read_lock();\n\tvirt_addr = acpi_map_vaddr_lookup(phys_addr, size);\n\tif (!virt_addr) {\n\t\trcu_read_unlock();\n\t\tvirt_addr = acpi_os_ioremap(phys_addr, size);\n\t\tif (!virt_addr)\n\t\t\treturn AE_BAD_ADDRESS;\n\t\tunmap = true;\n\t}\n\n\tswitch (width) {\n\tcase 8:\n\t\twriteb(value, virt_addr);\n\t\tbreak;\n\tcase 16:\n\t\twritew(value, virt_addr);\n\t\tbreak;\n\tcase 32:\n\t\twritel(value, virt_addr);\n\t\tbreak;\n\tcase 64:\n\t\twriteq(value, virt_addr);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tif (unmap)\n\t\tiounmap(virt_addr);\n\telse\n\t\trcu_read_unlock();\n\n\treturn AE_OK;\n}\n\n#ifdef CONFIG_PCI\nacpi_status\nacpi_os_read_pci_configuration(struct acpi_pci_id * pci_id, u32 reg,\n\t\t\t       u64 *value, u32 width)\n{\n\tint result, size;\n\tu32 value32;\n\n\tif (!value)\n\t\treturn AE_BAD_PARAMETER;\n\n\tswitch (width) {\n\tcase 8:\n\t\tsize = 1;\n\t\tbreak;\n\tcase 16:\n\t\tsize = 2;\n\t\tbreak;\n\tcase 32:\n\t\tsize = 4;\n\t\tbreak;\n\tdefault:\n\t\treturn AE_ERROR;\n\t}\n\n\tresult = raw_pci_read(pci_id->segment, pci_id->bus,\n\t\t\t\tPCI_DEVFN(pci_id->device, pci_id->function),\n\t\t\t\treg, size, &value32);\n\t*value = value32;\n\n\treturn (result ? AE_ERROR : AE_OK);\n}\n\nacpi_status\nacpi_os_write_pci_configuration(struct acpi_pci_id * pci_id, u32 reg,\n\t\t\t\tu64 value, u32 width)\n{\n\tint result, size;\n\n\tswitch (width) {\n\tcase 8:\n\t\tsize = 1;\n\t\tbreak;\n\tcase 16:\n\t\tsize = 2;\n\t\tbreak;\n\tcase 32:\n\t\tsize = 4;\n\t\tbreak;\n\tdefault:\n\t\treturn AE_ERROR;\n\t}\n\n\tresult = raw_pci_write(pci_id->segment, pci_id->bus,\n\t\t\t\tPCI_DEVFN(pci_id->device, pci_id->function),\n\t\t\t\treg, size, value);\n\n\treturn (result ? AE_ERROR : AE_OK);\n}\n#endif\n\nstatic void acpi_os_execute_deferred(struct work_struct *work)\n{\n\tstruct acpi_os_dpc *dpc = container_of(work, struct acpi_os_dpc, work);\n\n\tdpc->function(dpc->context);\n\tkfree(dpc);\n}\n\n#ifdef CONFIG_ACPI_DEBUGGER\nstatic struct acpi_debugger acpi_debugger;\nstatic bool acpi_debugger_initialized;\n\nint acpi_register_debugger(struct module *owner,\n\t\t\t   const struct acpi_debugger_ops *ops)\n{\n\tint ret = 0;\n\n\tmutex_lock(&acpi_debugger.lock);\n\tif (acpi_debugger.ops) {\n\t\tret = -EBUSY;\n\t\tgoto err_lock;\n\t}\n\n\tacpi_debugger.owner = owner;\n\tacpi_debugger.ops = ops;\n\nerr_lock:\n\tmutex_unlock(&acpi_debugger.lock);\n\treturn ret;\n}\nEXPORT_SYMBOL(acpi_register_debugger);\n\nvoid acpi_unregister_debugger(const struct acpi_debugger_ops *ops)\n{\n\tmutex_lock(&acpi_debugger.lock);\n\tif (ops == acpi_debugger.ops) {\n\t\tacpi_debugger.ops = NULL;\n\t\tacpi_debugger.owner = NULL;\n\t}\n\tmutex_unlock(&acpi_debugger.lock);\n}\nEXPORT_SYMBOL(acpi_unregister_debugger);\n\nint acpi_debugger_create_thread(acpi_osd_exec_callback function, void *context)\n{\n\tint ret;\n\tint (*func)(acpi_osd_exec_callback, void *);\n\tstruct module *owner;\n\n\tif (!acpi_debugger_initialized)\n\t\treturn -ENODEV;\n\tmutex_lock(&acpi_debugger.lock);\n\tif (!acpi_debugger.ops) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tif (!try_module_get(acpi_debugger.owner)) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tfunc = acpi_debugger.ops->create_thread;\n\towner = acpi_debugger.owner;\n\tmutex_unlock(&acpi_debugger.lock);\n\n\tret = func(function, context);\n\n\tmutex_lock(&acpi_debugger.lock);\n\tmodule_put(owner);\nerr_lock:\n\tmutex_unlock(&acpi_debugger.lock);\n\treturn ret;\n}\n\nssize_t acpi_debugger_write_log(const char *msg)\n{\n\tssize_t ret;\n\tssize_t (*func)(const char *);\n\tstruct module *owner;\n\n\tif (!acpi_debugger_initialized)\n\t\treturn -ENODEV;\n\tmutex_lock(&acpi_debugger.lock);\n\tif (!acpi_debugger.ops) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tif (!try_module_get(acpi_debugger.owner)) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tfunc = acpi_debugger.ops->write_log;\n\towner = acpi_debugger.owner;\n\tmutex_unlock(&acpi_debugger.lock);\n\n\tret = func(msg);\n\n\tmutex_lock(&acpi_debugger.lock);\n\tmodule_put(owner);\nerr_lock:\n\tmutex_unlock(&acpi_debugger.lock);\n\treturn ret;\n}\n\nssize_t acpi_debugger_read_cmd(char *buffer, size_t buffer_length)\n{\n\tssize_t ret;\n\tssize_t (*func)(char *, size_t);\n\tstruct module *owner;\n\n\tif (!acpi_debugger_initialized)\n\t\treturn -ENODEV;\n\tmutex_lock(&acpi_debugger.lock);\n\tif (!acpi_debugger.ops) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tif (!try_module_get(acpi_debugger.owner)) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tfunc = acpi_debugger.ops->read_cmd;\n\towner = acpi_debugger.owner;\n\tmutex_unlock(&acpi_debugger.lock);\n\n\tret = func(buffer, buffer_length);\n\n\tmutex_lock(&acpi_debugger.lock);\n\tmodule_put(owner);\nerr_lock:\n\tmutex_unlock(&acpi_debugger.lock);\n\treturn ret;\n}\n\nint acpi_debugger_wait_command_ready(void)\n{\n\tint ret;\n\tint (*func)(bool, char *, size_t);\n\tstruct module *owner;\n\n\tif (!acpi_debugger_initialized)\n\t\treturn -ENODEV;\n\tmutex_lock(&acpi_debugger.lock);\n\tif (!acpi_debugger.ops) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tif (!try_module_get(acpi_debugger.owner)) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tfunc = acpi_debugger.ops->wait_command_ready;\n\towner = acpi_debugger.owner;\n\tmutex_unlock(&acpi_debugger.lock);\n\n\tret = func(acpi_gbl_method_executing,\n\t\t   acpi_gbl_db_line_buf, ACPI_DB_LINE_BUFFER_SIZE);\n\n\tmutex_lock(&acpi_debugger.lock);\n\tmodule_put(owner);\nerr_lock:\n\tmutex_unlock(&acpi_debugger.lock);\n\treturn ret;\n}\n\nint acpi_debugger_notify_command_complete(void)\n{\n\tint ret;\n\tint (*func)(void);\n\tstruct module *owner;\n\n\tif (!acpi_debugger_initialized)\n\t\treturn -ENODEV;\n\tmutex_lock(&acpi_debugger.lock);\n\tif (!acpi_debugger.ops) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tif (!try_module_get(acpi_debugger.owner)) {\n\t\tret = -ENODEV;\n\t\tgoto err_lock;\n\t}\n\tfunc = acpi_debugger.ops->notify_command_complete;\n\towner = acpi_debugger.owner;\n\tmutex_unlock(&acpi_debugger.lock);\n\n\tret = func();\n\n\tmutex_lock(&acpi_debugger.lock);\n\tmodule_put(owner);\nerr_lock:\n\tmutex_unlock(&acpi_debugger.lock);\n\treturn ret;\n}\n\nint __init acpi_debugger_init(void)\n{\n\tmutex_init(&acpi_debugger.lock);\n\tacpi_debugger_initialized = true;\n\treturn 0;\n}\n#endif\n\n \n\nacpi_status acpi_os_execute(acpi_execute_type type,\n\t\t\t    acpi_osd_exec_callback function, void *context)\n{\n\tacpi_status status = AE_OK;\n\tstruct acpi_os_dpc *dpc;\n\tstruct workqueue_struct *queue;\n\tint ret;\n\tACPI_DEBUG_PRINT((ACPI_DB_EXEC,\n\t\t\t  \"Scheduling function [%p(%p)] for deferred execution.\\n\",\n\t\t\t  function, context));\n\n\tif (type == OSL_DEBUGGER_MAIN_THREAD) {\n\t\tret = acpi_debugger_create_thread(function, context);\n\t\tif (ret) {\n\t\t\tpr_err(\"Kernel thread creation failed\\n\");\n\t\t\tstatus = AE_ERROR;\n\t\t}\n\t\tgoto out_thread;\n\t}\n\n\t \n\n\tdpc = kzalloc(sizeof(struct acpi_os_dpc), GFP_ATOMIC);\n\tif (!dpc)\n\t\treturn AE_NO_MEMORY;\n\n\tdpc->function = function;\n\tdpc->context = context;\n\n\t \n\tif (type == OSL_NOTIFY_HANDLER) {\n\t\tqueue = kacpi_notify_wq;\n\t\tINIT_WORK(&dpc->work, acpi_os_execute_deferred);\n\t} else if (type == OSL_GPE_HANDLER) {\n\t\tqueue = kacpid_wq;\n\t\tINIT_WORK(&dpc->work, acpi_os_execute_deferred);\n\t} else {\n\t\tpr_err(\"Unsupported os_execute type %d.\\n\", type);\n\t\tstatus = AE_ERROR;\n\t}\n\n\tif (ACPI_FAILURE(status))\n\t\tgoto err_workqueue;\n\n\t \n\tret = queue_work_on(0, queue, &dpc->work);\n\tif (!ret) {\n\t\tpr_err(\"Unable to queue work\\n\");\n\t\tstatus = AE_ERROR;\n\t}\nerr_workqueue:\n\tif (ACPI_FAILURE(status))\n\t\tkfree(dpc);\nout_thread:\n\treturn status;\n}\nEXPORT_SYMBOL(acpi_os_execute);\n\nvoid acpi_os_wait_events_complete(void)\n{\n\t \n\tif (acpi_sci_irq_valid())\n\t\tsynchronize_hardirq(acpi_sci_irq);\n\tflush_workqueue(kacpid_wq);\n\tflush_workqueue(kacpi_notify_wq);\n}\nEXPORT_SYMBOL(acpi_os_wait_events_complete);\n\nstruct acpi_hp_work {\n\tstruct work_struct work;\n\tstruct acpi_device *adev;\n\tu32 src;\n};\n\nstatic void acpi_hotplug_work_fn(struct work_struct *work)\n{\n\tstruct acpi_hp_work *hpw = container_of(work, struct acpi_hp_work, work);\n\n\tacpi_os_wait_events_complete();\n\tacpi_device_hotplug(hpw->adev, hpw->src);\n\tkfree(hpw);\n}\n\nacpi_status acpi_hotplug_schedule(struct acpi_device *adev, u32 src)\n{\n\tstruct acpi_hp_work *hpw;\n\n\tacpi_handle_debug(adev->handle,\n\t\t\t  \"Scheduling hotplug event %u for deferred handling\\n\",\n\t\t\t   src);\n\n\thpw = kmalloc(sizeof(*hpw), GFP_KERNEL);\n\tif (!hpw)\n\t\treturn AE_NO_MEMORY;\n\n\tINIT_WORK(&hpw->work, acpi_hotplug_work_fn);\n\thpw->adev = adev;\n\thpw->src = src;\n\t \n\tif (!queue_work(kacpi_hotplug_wq, &hpw->work)) {\n\t\tkfree(hpw);\n\t\treturn AE_ERROR;\n\t}\n\treturn AE_OK;\n}\n\nbool acpi_queue_hotplug_work(struct work_struct *work)\n{\n\treturn queue_work(kacpi_hotplug_wq, work);\n}\n\nacpi_status\nacpi_os_create_semaphore(u32 max_units, u32 initial_units, acpi_handle * handle)\n{\n\tstruct semaphore *sem = NULL;\n\n\tsem = acpi_os_allocate_zeroed(sizeof(struct semaphore));\n\tif (!sem)\n\t\treturn AE_NO_MEMORY;\n\n\tsema_init(sem, initial_units);\n\n\t*handle = (acpi_handle *) sem;\n\n\tACPI_DEBUG_PRINT((ACPI_DB_MUTEX, \"Creating semaphore[%p|%d].\\n\",\n\t\t\t  *handle, initial_units));\n\n\treturn AE_OK;\n}\n\n \n\nacpi_status acpi_os_delete_semaphore(acpi_handle handle)\n{\n\tstruct semaphore *sem = (struct semaphore *)handle;\n\n\tif (!sem)\n\t\treturn AE_BAD_PARAMETER;\n\n\tACPI_DEBUG_PRINT((ACPI_DB_MUTEX, \"Deleting semaphore[%p].\\n\", handle));\n\n\tBUG_ON(!list_empty(&sem->wait_list));\n\tkfree(sem);\n\tsem = NULL;\n\n\treturn AE_OK;\n}\n\n \nacpi_status acpi_os_wait_semaphore(acpi_handle handle, u32 units, u16 timeout)\n{\n\tacpi_status status = AE_OK;\n\tstruct semaphore *sem = (struct semaphore *)handle;\n\tlong jiffies;\n\tint ret = 0;\n\n\tif (!acpi_os_initialized)\n\t\treturn AE_OK;\n\n\tif (!sem || (units < 1))\n\t\treturn AE_BAD_PARAMETER;\n\n\tif (units > 1)\n\t\treturn AE_SUPPORT;\n\n\tACPI_DEBUG_PRINT((ACPI_DB_MUTEX, \"Waiting for semaphore[%p|%d|%d]\\n\",\n\t\t\t  handle, units, timeout));\n\n\tif (timeout == ACPI_WAIT_FOREVER)\n\t\tjiffies = MAX_SCHEDULE_TIMEOUT;\n\telse\n\t\tjiffies = msecs_to_jiffies(timeout);\n\n\tret = down_timeout(sem, jiffies);\n\tif (ret)\n\t\tstatus = AE_TIME;\n\n\tif (ACPI_FAILURE(status)) {\n\t\tACPI_DEBUG_PRINT((ACPI_DB_MUTEX,\n\t\t\t\t  \"Failed to acquire semaphore[%p|%d|%d], %s\",\n\t\t\t\t  handle, units, timeout,\n\t\t\t\t  acpi_format_exception(status)));\n\t} else {\n\t\tACPI_DEBUG_PRINT((ACPI_DB_MUTEX,\n\t\t\t\t  \"Acquired semaphore[%p|%d|%d]\", handle,\n\t\t\t\t  units, timeout));\n\t}\n\n\treturn status;\n}\n\n \nacpi_status acpi_os_signal_semaphore(acpi_handle handle, u32 units)\n{\n\tstruct semaphore *sem = (struct semaphore *)handle;\n\n\tif (!acpi_os_initialized)\n\t\treturn AE_OK;\n\n\tif (!sem || (units < 1))\n\t\treturn AE_BAD_PARAMETER;\n\n\tif (units > 1)\n\t\treturn AE_SUPPORT;\n\n\tACPI_DEBUG_PRINT((ACPI_DB_MUTEX, \"Signaling semaphore[%p|%d]\\n\", handle,\n\t\t\t  units));\n\n\tup(sem);\n\n\treturn AE_OK;\n}\n\nacpi_status acpi_os_get_line(char *buffer, u32 buffer_length, u32 *bytes_read)\n{\n#ifdef ENABLE_DEBUGGER\n\tif (acpi_in_debugger) {\n\t\tu32 chars;\n\n\t\tkdb_read(buffer, buffer_length);\n\n\t\t \n\t\tchars = strlen(buffer) - 1;\n\t\tbuffer[chars] = '\\0';\n\t}\n#else\n\tint ret;\n\n\tret = acpi_debugger_read_cmd(buffer, buffer_length);\n\tif (ret < 0)\n\t\treturn AE_ERROR;\n\tif (bytes_read)\n\t\t*bytes_read = ret;\n#endif\n\n\treturn AE_OK;\n}\nEXPORT_SYMBOL(acpi_os_get_line);\n\nacpi_status acpi_os_wait_command_ready(void)\n{\n\tint ret;\n\n\tret = acpi_debugger_wait_command_ready();\n\tif (ret < 0)\n\t\treturn AE_ERROR;\n\treturn AE_OK;\n}\n\nacpi_status acpi_os_notify_command_complete(void)\n{\n\tint ret;\n\n\tret = acpi_debugger_notify_command_complete();\n\tif (ret < 0)\n\t\treturn AE_ERROR;\n\treturn AE_OK;\n}\n\nacpi_status acpi_os_signal(u32 function, void *info)\n{\n\tswitch (function) {\n\tcase ACPI_SIGNAL_FATAL:\n\t\tpr_err(\"Fatal opcode executed\\n\");\n\t\tbreak;\n\tcase ACPI_SIGNAL_BREAKPOINT:\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn AE_OK;\n}\n\nstatic int __init acpi_os_name_setup(char *str)\n{\n\tchar *p = acpi_os_name;\n\tint count = ACPI_MAX_OVERRIDE_LEN - 1;\n\n\tif (!str || !*str)\n\t\treturn 0;\n\n\tfor (; count-- && *str; str++) {\n\t\tif (isalnum(*str) || *str == ' ' || *str == ':')\n\t\t\t*p++ = *str;\n\t\telse if (*str == '\\'' || *str == '\"')\n\t\t\tcontinue;\n\t\telse\n\t\t\tbreak;\n\t}\n\t*p = 0;\n\n\treturn 1;\n\n}\n\n__setup(\"acpi_os_name=\", acpi_os_name_setup);\n\n \nstatic int __init acpi_no_auto_serialize_setup(char *str)\n{\n\tacpi_gbl_auto_serialize_methods = FALSE;\n\tpr_info(\"Auto-serialization disabled\\n\");\n\n\treturn 1;\n}\n\n__setup(\"acpi_no_auto_serialize\", acpi_no_auto_serialize_setup);\n\n \n#define ENFORCE_RESOURCES_STRICT 2\n#define ENFORCE_RESOURCES_LAX    1\n#define ENFORCE_RESOURCES_NO     0\n\nstatic unsigned int acpi_enforce_resources = ENFORCE_RESOURCES_STRICT;\n\nstatic int __init acpi_enforce_resources_setup(char *str)\n{\n\tif (str == NULL || *str == '\\0')\n\t\treturn 0;\n\n\tif (!strcmp(\"strict\", str))\n\t\tacpi_enforce_resources = ENFORCE_RESOURCES_STRICT;\n\telse if (!strcmp(\"lax\", str))\n\t\tacpi_enforce_resources = ENFORCE_RESOURCES_LAX;\n\telse if (!strcmp(\"no\", str))\n\t\tacpi_enforce_resources = ENFORCE_RESOURCES_NO;\n\n\treturn 1;\n}\n\n__setup(\"acpi_enforce_resources=\", acpi_enforce_resources_setup);\n\n \nint acpi_check_resource_conflict(const struct resource *res)\n{\n\tacpi_adr_space_type space_id;\n\n\tif (acpi_enforce_resources == ENFORCE_RESOURCES_NO)\n\t\treturn 0;\n\n\tif (res->flags & IORESOURCE_IO)\n\t\tspace_id = ACPI_ADR_SPACE_SYSTEM_IO;\n\telse if (res->flags & IORESOURCE_MEM)\n\t\tspace_id = ACPI_ADR_SPACE_SYSTEM_MEMORY;\n\telse\n\t\treturn 0;\n\n\tif (!acpi_check_address_range(space_id, res->start, resource_size(res), 1))\n\t\treturn 0;\n\n\tpr_info(\"Resource conflict; ACPI support missing from driver?\\n\");\n\n\tif (acpi_enforce_resources == ENFORCE_RESOURCES_STRICT)\n\t\treturn -EBUSY;\n\n\tif (acpi_enforce_resources == ENFORCE_RESOURCES_LAX)\n\t\tpr_notice(\"Resource conflict: System may be unstable or behave erratically\\n\");\n\n\treturn 0;\n}\nEXPORT_SYMBOL(acpi_check_resource_conflict);\n\nint acpi_check_region(resource_size_t start, resource_size_t n,\n\t\t      const char *name)\n{\n\tstruct resource res = DEFINE_RES_IO_NAMED(start, n, name);\n\n\treturn acpi_check_resource_conflict(&res);\n}\nEXPORT_SYMBOL(acpi_check_region);\n\n \nint acpi_resources_are_enforced(void)\n{\n\treturn acpi_enforce_resources == ENFORCE_RESOURCES_STRICT;\n}\nEXPORT_SYMBOL(acpi_resources_are_enforced);\n\n \nvoid acpi_os_delete_lock(acpi_spinlock handle)\n{\n\tACPI_FREE(handle);\n}\n\n \n\nacpi_cpu_flags acpi_os_acquire_lock(acpi_spinlock lockp)\n\t__acquires(lockp)\n{\n\tacpi_cpu_flags flags;\n\tspin_lock_irqsave(lockp, flags);\n\treturn flags;\n}\n\n \n\nvoid acpi_os_release_lock(acpi_spinlock lockp, acpi_cpu_flags flags)\n\t__releases(lockp)\n{\n\tspin_unlock_irqrestore(lockp, flags);\n}\n\n#ifndef ACPI_USE_LOCAL_CACHE\n\n \n\nacpi_status\nacpi_os_create_cache(char *name, u16 size, u16 depth, acpi_cache_t ** cache)\n{\n\t*cache = kmem_cache_create(name, size, 0, 0, NULL);\n\tif (*cache == NULL)\n\t\treturn AE_ERROR;\n\telse\n\t\treturn AE_OK;\n}\n\n \n\nacpi_status acpi_os_purge_cache(acpi_cache_t * cache)\n{\n\tkmem_cache_shrink(cache);\n\treturn (AE_OK);\n}\n\n \n\nacpi_status acpi_os_delete_cache(acpi_cache_t * cache)\n{\n\tkmem_cache_destroy(cache);\n\treturn (AE_OK);\n}\n\n \n\nacpi_status acpi_os_release_object(acpi_cache_t * cache, void *object)\n{\n\tkmem_cache_free(cache, object);\n\treturn (AE_OK);\n}\n#endif\n\nstatic int __init acpi_no_static_ssdt_setup(char *s)\n{\n\tacpi_gbl_disable_ssdt_table_install = TRUE;\n\tpr_info(\"Static SSDT installation disabled\\n\");\n\n\treturn 0;\n}\n\nearly_param(\"acpi_no_static_ssdt\", acpi_no_static_ssdt_setup);\n\nstatic int __init acpi_disable_return_repair(char *s)\n{\n\tpr_notice(\"Predefined validation mechanism disabled\\n\");\n\tacpi_gbl_disable_auto_repair = TRUE;\n\n\treturn 1;\n}\n\n__setup(\"acpica_no_return_repair\", acpi_disable_return_repair);\n\nacpi_status __init acpi_os_initialize(void)\n{\n\tacpi_os_map_generic_address(&acpi_gbl_FADT.xpm1a_event_block);\n\tacpi_os_map_generic_address(&acpi_gbl_FADT.xpm1b_event_block);\n\n\tacpi_gbl_xgpe0_block_logical_address =\n\t\t(unsigned long)acpi_os_map_generic_address(&acpi_gbl_FADT.xgpe0_block);\n\tacpi_gbl_xgpe1_block_logical_address =\n\t\t(unsigned long)acpi_os_map_generic_address(&acpi_gbl_FADT.xgpe1_block);\n\n\tif (acpi_gbl_FADT.flags & ACPI_FADT_RESET_REGISTER) {\n\t\t \n\t\tvoid *rv;\n\n\t\trv = acpi_os_map_generic_address(&acpi_gbl_FADT.reset_register);\n\t\tpr_debug(\"%s: Reset register mapping %s\\n\", __func__,\n\t\t\t rv ? \"successful\" : \"failed\");\n\t}\n\tacpi_os_initialized = true;\n\n\treturn AE_OK;\n}\n\nacpi_status __init acpi_os_initialize1(void)\n{\n\tkacpid_wq = alloc_workqueue(\"kacpid\", 0, 1);\n\tkacpi_notify_wq = alloc_workqueue(\"kacpi_notify\", 0, 1);\n\tkacpi_hotplug_wq = alloc_ordered_workqueue(\"kacpi_hotplug\", 0);\n\tBUG_ON(!kacpid_wq);\n\tBUG_ON(!kacpi_notify_wq);\n\tBUG_ON(!kacpi_hotplug_wq);\n\tacpi_osi_init();\n\treturn AE_OK;\n}\n\nacpi_status acpi_os_terminate(void)\n{\n\tif (acpi_irq_handler) {\n\t\tacpi_os_remove_interrupt_handler(acpi_gbl_FADT.sci_interrupt,\n\t\t\t\t\t\t acpi_irq_handler);\n\t}\n\n\tacpi_os_unmap_generic_address(&acpi_gbl_FADT.xgpe1_block);\n\tacpi_os_unmap_generic_address(&acpi_gbl_FADT.xgpe0_block);\n\tacpi_gbl_xgpe0_block_logical_address = 0UL;\n\tacpi_gbl_xgpe1_block_logical_address = 0UL;\n\n\tacpi_os_unmap_generic_address(&acpi_gbl_FADT.xpm1b_event_block);\n\tacpi_os_unmap_generic_address(&acpi_gbl_FADT.xpm1a_event_block);\n\n\tif (acpi_gbl_FADT.flags & ACPI_FADT_RESET_REGISTER)\n\t\tacpi_os_unmap_generic_address(&acpi_gbl_FADT.reset_register);\n\n\tdestroy_workqueue(kacpid_wq);\n\tdestroy_workqueue(kacpi_notify_wq);\n\tdestroy_workqueue(kacpi_hotplug_wq);\n\n\treturn AE_OK;\n}\n\nacpi_status acpi_os_prepare_sleep(u8 sleep_state, u32 pm1a_control,\n\t\t\t\t  u32 pm1b_control)\n{\n\tint rc = 0;\n\tif (__acpi_os_prepare_sleep)\n\t\trc = __acpi_os_prepare_sleep(sleep_state,\n\t\t\t\t\t     pm1a_control, pm1b_control);\n\tif (rc < 0)\n\t\treturn AE_ERROR;\n\telse if (rc > 0)\n\t\treturn AE_CTRL_TERMINATE;\n\n\treturn AE_OK;\n}\n\nvoid acpi_os_set_prepare_sleep(int (*func)(u8 sleep_state,\n\t\t\t       u32 pm1a_ctrl, u32 pm1b_ctrl))\n{\n\t__acpi_os_prepare_sleep = func;\n}\n\n#if (ACPI_REDUCED_HARDWARE)\nacpi_status acpi_os_prepare_extended_sleep(u8 sleep_state, u32 val_a,\n\t\t\t\t  u32 val_b)\n{\n\tint rc = 0;\n\tif (__acpi_os_prepare_extended_sleep)\n\t\trc = __acpi_os_prepare_extended_sleep(sleep_state,\n\t\t\t\t\t     val_a, val_b);\n\tif (rc < 0)\n\t\treturn AE_ERROR;\n\telse if (rc > 0)\n\t\treturn AE_CTRL_TERMINATE;\n\n\treturn AE_OK;\n}\n#else\nacpi_status acpi_os_prepare_extended_sleep(u8 sleep_state, u32 val_a,\n\t\t\t\t  u32 val_b)\n{\n\treturn AE_OK;\n}\n#endif\n\nvoid acpi_os_set_prepare_extended_sleep(int (*func)(u8 sleep_state,\n\t\t\t       u32 val_a, u32 val_b))\n{\n\t__acpi_os_prepare_extended_sleep = func;\n}\n\nacpi_status acpi_os_enter_sleep(u8 sleep_state,\n\t\t\t\tu32 reg_a_value, u32 reg_b_value)\n{\n\tacpi_status status;\n\n\tif (acpi_gbl_reduced_hardware)\n\t\tstatus = acpi_os_prepare_extended_sleep(sleep_state,\n\t\t\t\t\t\t\treg_a_value,\n\t\t\t\t\t\t\treg_b_value);\n\telse\n\t\tstatus = acpi_os_prepare_sleep(sleep_state,\n\t\t\t\t\t       reg_a_value, reg_b_value);\n\treturn status;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}