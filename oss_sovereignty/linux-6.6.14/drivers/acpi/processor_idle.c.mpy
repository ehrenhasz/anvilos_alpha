{
  "module_name": "processor_idle.c",
  "hash_id": "c56dd24f91378cac53dc01340aafda69e2f336e6796b99a365d46140c597034f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/acpi/processor_idle.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) \"ACPI: \" fmt\n\n#include <linux/module.h>\n#include <linux/acpi.h>\n#include <linux/dmi.h>\n#include <linux/sched.h>        \n#include <linux/sort.h>\n#include <linux/tick.h>\n#include <linux/cpuidle.h>\n#include <linux/cpu.h>\n#include <linux/minmax.h>\n#include <linux/perf_event.h>\n#include <acpi/processor.h>\n#include <linux/context_tracking.h>\n\n \n#ifdef CONFIG_X86\n#include <asm/apic.h>\n#include <asm/cpu.h>\n#endif\n\n#define ACPI_IDLE_STATE_START\t(IS_ENABLED(CONFIG_ARCH_HAS_CPU_RELAX) ? 1 : 0)\n\nstatic unsigned int max_cstate __read_mostly = ACPI_PROCESSOR_MAX_POWER;\nmodule_param(max_cstate, uint, 0400);\nstatic bool nocst __read_mostly;\nmodule_param(nocst, bool, 0400);\nstatic bool bm_check_disable __read_mostly;\nmodule_param(bm_check_disable, bool, 0400);\n\nstatic unsigned int latency_factor __read_mostly = 2;\nmodule_param(latency_factor, uint, 0644);\n\nstatic DEFINE_PER_CPU(struct cpuidle_device *, acpi_cpuidle_device);\n\nstruct cpuidle_driver acpi_idle_driver = {\n\t.name =\t\t\"acpi_idle\",\n\t.owner =\tTHIS_MODULE,\n};\n\n#ifdef CONFIG_ACPI_PROCESSOR_CSTATE\nstatic\nDEFINE_PER_CPU(struct acpi_processor_cx * [CPUIDLE_STATE_MAX], acpi_cstate);\n\nstatic int disabled_by_idle_boot_param(void)\n{\n\treturn boot_option_idle_override == IDLE_POLL ||\n\t\tboot_option_idle_override == IDLE_HALT;\n}\n\n \nstatic int set_max_cstate(const struct dmi_system_id *id)\n{\n\tif (max_cstate > ACPI_PROCESSOR_MAX_POWER)\n\t\treturn 0;\n\n\tpr_notice(\"%s detected - limiting to C%ld max_cstate.\"\n\t\t  \" Override with \\\"processor.max_cstate=%d\\\"\\n\", id->ident,\n\t\t  (long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);\n\n\tmax_cstate = (long)id->driver_data;\n\n\treturn 0;\n}\n\nstatic const struct dmi_system_id processor_power_dmi_table[] = {\n\t{ set_max_cstate, \"Clevo 5600D\", {\n\t  DMI_MATCH(DMI_BIOS_VENDOR,\"Phoenix Technologies LTD\"),\n\t  DMI_MATCH(DMI_BIOS_VERSION,\"SHE845M0.86C.0013.D.0302131307\")},\n\t (void *)2},\n\t{ set_max_cstate, \"Pavilion zv5000\", {\n\t  DMI_MATCH(DMI_SYS_VENDOR, \"Hewlett-Packard\"),\n\t  DMI_MATCH(DMI_PRODUCT_NAME,\"Pavilion zv5000 (DS502A#ABA)\")},\n\t (void *)1},\n\t{ set_max_cstate, \"Asus L8400B\", {\n\t  DMI_MATCH(DMI_SYS_VENDOR, \"ASUSTeK Computer Inc.\"),\n\t  DMI_MATCH(DMI_PRODUCT_NAME,\"L8400B series Notebook PC\")},\n\t (void *)1},\n\t{},\n};\n\n\n \nstatic void __cpuidle acpi_safe_halt(void)\n{\n\tif (!tif_need_resched()) {\n\t\traw_safe_halt();\n\t\traw_local_irq_disable();\n\t}\n}\n\n#ifdef ARCH_APICTIMER_STOPS_ON_C3\n\n \nstatic void lapic_timer_check_state(int state, struct acpi_processor *pr,\n\t\t\t\t   struct acpi_processor_cx *cx)\n{\n\tstruct acpi_processor_power *pwr = &pr->power;\n\tu8 type = local_apic_timer_c2_ok ? ACPI_STATE_C3 : ACPI_STATE_C2;\n\n\tif (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))\n\t\treturn;\n\n\tif (boot_cpu_has_bug(X86_BUG_AMD_APIC_C1E))\n\t\ttype = ACPI_STATE_C1;\n\n\t \n\tif (pwr->timer_broadcast_on_state < state)\n\t\treturn;\n\n\tif (cx->type >= type)\n\t\tpr->power.timer_broadcast_on_state = state;\n}\n\nstatic void __lapic_timer_propagate_broadcast(void *arg)\n{\n\tstruct acpi_processor *pr = arg;\n\n\tif (pr->power.timer_broadcast_on_state < INT_MAX)\n\t\ttick_broadcast_enable();\n\telse\n\t\ttick_broadcast_disable();\n}\n\nstatic void lapic_timer_propagate_broadcast(struct acpi_processor *pr)\n{\n\tsmp_call_function_single(pr->id, __lapic_timer_propagate_broadcast,\n\t\t\t\t (void *)pr, 1);\n}\n\n \nstatic bool lapic_timer_needs_broadcast(struct acpi_processor *pr,\n\t\t\t\t\tstruct acpi_processor_cx *cx)\n{\n\treturn cx - pr->power.states >= pr->power.timer_broadcast_on_state;\n}\n\n#else\n\nstatic void lapic_timer_check_state(int state, struct acpi_processor *pr,\n\t\t\t\t   struct acpi_processor_cx *cstate) { }\nstatic void lapic_timer_propagate_broadcast(struct acpi_processor *pr) { }\n\nstatic bool lapic_timer_needs_broadcast(struct acpi_processor *pr,\n\t\t\t\t\tstruct acpi_processor_cx *cx)\n{\n\treturn false;\n}\n\n#endif\n\n#if defined(CONFIG_X86)\nstatic void tsc_check_state(int state)\n{\n\tswitch (boot_cpu_data.x86_vendor) {\n\tcase X86_VENDOR_HYGON:\n\tcase X86_VENDOR_AMD:\n\tcase X86_VENDOR_INTEL:\n\tcase X86_VENDOR_CENTAUR:\n\tcase X86_VENDOR_ZHAOXIN:\n\t\t \n\t\tif (boot_cpu_has(X86_FEATURE_NONSTOP_TSC))\n\t\t\treturn;\n\t\tfallthrough;\n\tdefault:\n\t\t \n\t\tif (state > ACPI_STATE_C1)\n\t\t\tmark_tsc_unstable(\"TSC halts in idle\");\n\t}\n}\n#else\nstatic void tsc_check_state(int state) { return; }\n#endif\n\nstatic int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)\n{\n\n\tif (!pr->pblk)\n\t\treturn -ENODEV;\n\n\t \n\tpr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;\n\tpr->power.states[ACPI_STATE_C3].type = ACPI_STATE_C3;\n\n#ifndef CONFIG_HOTPLUG_CPU\n\t \n\tif ((num_online_cpus() > 1) &&\n\t    !(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))\n\t\treturn -ENODEV;\n#endif\n\n\t \n\tpr->power.states[ACPI_STATE_C2].address = pr->pblk + 4;\n\tpr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;\n\n\t \n\tpr->power.states[ACPI_STATE_C2].latency = acpi_gbl_FADT.c2_latency;\n\tpr->power.states[ACPI_STATE_C3].latency = acpi_gbl_FADT.c3_latency;\n\n\t \n\tif (acpi_gbl_FADT.c2_latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {\n\t\tacpi_handle_debug(pr->handle, \"C2 latency too large [%d]\\n\",\n\t\t\t\t  acpi_gbl_FADT.c2_latency);\n\t\t \n\t\tpr->power.states[ACPI_STATE_C2].address = 0;\n\t}\n\n\t \n\tif (acpi_gbl_FADT.c3_latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {\n\t\tacpi_handle_debug(pr->handle, \"C3 latency too large [%d]\\n\",\n\t\t\t\t  acpi_gbl_FADT.c3_latency);\n\t\t \n\t\tpr->power.states[ACPI_STATE_C3].address = 0;\n\t}\n\n\tacpi_handle_debug(pr->handle, \"lvl2[0x%08x] lvl3[0x%08x]\\n\",\n\t\t\t  pr->power.states[ACPI_STATE_C2].address,\n\t\t\t  pr->power.states[ACPI_STATE_C3].address);\n\n\tsnprintf(pr->power.states[ACPI_STATE_C2].desc,\n\t\t\t ACPI_CX_DESC_LEN, \"ACPI P_LVL2 IOPORT 0x%x\",\n\t\t\t pr->power.states[ACPI_STATE_C2].address);\n\tsnprintf(pr->power.states[ACPI_STATE_C3].desc,\n\t\t\t ACPI_CX_DESC_LEN, \"ACPI P_LVL3 IOPORT 0x%x\",\n\t\t\t pr->power.states[ACPI_STATE_C3].address);\n\n\treturn 0;\n}\n\nstatic int acpi_processor_get_power_info_default(struct acpi_processor *pr)\n{\n\tif (!pr->power.states[ACPI_STATE_C1].valid) {\n\t\t \n\t\t \n\t\tpr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;\n\t\tpr->power.states[ACPI_STATE_C1].valid = 1;\n\t\tpr->power.states[ACPI_STATE_C1].entry_method = ACPI_CSTATE_HALT;\n\n\t\tsnprintf(pr->power.states[ACPI_STATE_C1].desc,\n\t\t\t ACPI_CX_DESC_LEN, \"ACPI HLT\");\n\t}\n\t \n\tpr->power.states[ACPI_STATE_C0].valid = 1;\n\treturn 0;\n}\n\nstatic int acpi_processor_get_power_info_cst(struct acpi_processor *pr)\n{\n\tint ret;\n\n\tif (nocst)\n\t\treturn -ENODEV;\n\n\tret = acpi_processor_evaluate_cst(pr->handle, pr->id, &pr->power);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!pr->power.count)\n\t\treturn -EFAULT;\n\n\tpr->flags.has_cst = 1;\n\treturn 0;\n}\n\nstatic void acpi_processor_power_verify_c3(struct acpi_processor *pr,\n\t\t\t\t\t   struct acpi_processor_cx *cx)\n{\n\tstatic int bm_check_flag = -1;\n\tstatic int bm_control_flag = -1;\n\n\n\tif (!cx->address)\n\t\treturn;\n\n\t \n\tif (errata.piix4.fdma) {\n\t\tacpi_handle_debug(pr->handle,\n\t\t\t\t  \"C3 not supported on PIIX4 with Type-F DMA\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (bm_check_flag == -1) {\n\t\t \n\t\tacpi_processor_power_init_bm_check(&(pr->flags), pr->id);\n\t\tbm_check_flag = pr->flags.bm_check;\n\t\tbm_control_flag = pr->flags.bm_control;\n\t} else {\n\t\tpr->flags.bm_check = bm_check_flag;\n\t\tpr->flags.bm_control = bm_control_flag;\n\t}\n\n\tif (pr->flags.bm_check) {\n\t\tif (!pr->flags.bm_control) {\n\t\t\tif (pr->flags.has_cst != 1) {\n\t\t\t\t \n\t\t\t\tacpi_handle_debug(pr->handle,\n\t\t\t\t\t\t  \"C3 support requires BM control\\n\");\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tacpi_handle_debug(pr->handle,\n\t\t\t\t\t\t  \"C3 support without BM control\\n\");\n\t\t\t}\n\t\t}\n\t} else {\n\t\t \n\t\tif (!(acpi_gbl_FADT.flags & ACPI_FADT_WBINVD)) {\n\t\t\tacpi_handle_debug(pr->handle,\n\t\t\t\t\t  \"Cache invalidation should work properly\"\n\t\t\t\t\t  \" for C3 to be enabled on SMP systems\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tcx->valid = 1;\n\n\t \n\tacpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, 1);\n}\n\nstatic int acpi_cst_latency_cmp(const void *a, const void *b)\n{\n\tconst struct acpi_processor_cx *x = a, *y = b;\n\n\tif (!(x->valid && y->valid))\n\t\treturn 0;\n\tif (x->latency > y->latency)\n\t\treturn 1;\n\tif (x->latency < y->latency)\n\t\treturn -1;\n\treturn 0;\n}\nstatic void acpi_cst_latency_swap(void *a, void *b, int n)\n{\n\tstruct acpi_processor_cx *x = a, *y = b;\n\n\tif (!(x->valid && y->valid))\n\t\treturn;\n\tswap(x->latency, y->latency);\n}\n\nstatic int acpi_processor_power_verify(struct acpi_processor *pr)\n{\n\tunsigned int i;\n\tunsigned int working = 0;\n\tunsigned int last_latency = 0;\n\tunsigned int last_type = 0;\n\tbool buggy_latency = false;\n\n\tpr->power.timer_broadcast_on_state = INT_MAX;\n\n\tfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\n\t\tstruct acpi_processor_cx *cx = &pr->power.states[i];\n\n\t\tswitch (cx->type) {\n\t\tcase ACPI_STATE_C1:\n\t\t\tcx->valid = 1;\n\t\t\tbreak;\n\n\t\tcase ACPI_STATE_C2:\n\t\t\tif (!cx->address)\n\t\t\t\tbreak;\n\t\t\tcx->valid = 1;\n\t\t\tbreak;\n\n\t\tcase ACPI_STATE_C3:\n\t\t\tacpi_processor_power_verify_c3(pr, cx);\n\t\t\tbreak;\n\t\t}\n\t\tif (!cx->valid)\n\t\t\tcontinue;\n\t\tif (cx->type >= last_type && cx->latency < last_latency)\n\t\t\tbuggy_latency = true;\n\t\tlast_latency = cx->latency;\n\t\tlast_type = cx->type;\n\n\t\tlapic_timer_check_state(i, pr, cx);\n\t\ttsc_check_state(cx->type);\n\t\tworking++;\n\t}\n\n\tif (buggy_latency) {\n\t\tpr_notice(\"FW issue: working around C-state latencies out of order\\n\");\n\t\tsort(&pr->power.states[1], max_cstate,\n\t\t     sizeof(struct acpi_processor_cx),\n\t\t     acpi_cst_latency_cmp,\n\t\t     acpi_cst_latency_swap);\n\t}\n\n\tlapic_timer_propagate_broadcast(pr);\n\n\treturn working;\n}\n\nstatic int acpi_processor_get_cstate_info(struct acpi_processor *pr)\n{\n\tunsigned int i;\n\tint result;\n\n\n\t \n\n\t \n\tmemset(pr->power.states, 0, sizeof(pr->power.states));\n\n\tresult = acpi_processor_get_power_info_cst(pr);\n\tif (result == -ENODEV)\n\t\tresult = acpi_processor_get_power_info_fadt(pr);\n\n\tif (result)\n\t\treturn result;\n\n\tacpi_processor_get_power_info_default(pr);\n\n\tpr->power.count = acpi_processor_power_verify(pr);\n\n\t \n\tfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {\n\t\tif (pr->power.states[i].valid) {\n\t\t\tpr->power.count = i;\n\t\t\tpr->flags.power = 1;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int acpi_idle_bm_check(void)\n{\n\tu32 bm_status = 0;\n\n\tif (bm_check_disable)\n\t\treturn 0;\n\n\tacpi_read_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);\n\tif (bm_status)\n\t\tacpi_write_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);\n\t \n\telse if (errata.piix4.bmisx) {\n\t\tif ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)\n\t\t    || (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))\n\t\t\tbm_status = 1;\n\t}\n\treturn bm_status;\n}\n\nstatic __cpuidle void io_idle(unsigned long addr)\n{\n\t \n\tinb(addr);\n\n#ifdef\tCONFIG_X86\n\t \n\tif (boot_cpu_has(X86_FEATURE_HYPERVISOR))\n\t\treturn;\n\t \n\tif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\n\t\treturn;\n#endif\n\t \n\tinl(acpi_gbl_FADT.xpm_timer_block.address);\n}\n\n \nstatic void __cpuidle acpi_idle_do_entry(struct acpi_processor_cx *cx)\n{\n\tperf_lopwr_cb(true);\n\n\tif (cx->entry_method == ACPI_CSTATE_FFH) {\n\t\t \n\t\tacpi_processor_ffh_cstate_enter(cx);\n\t} else if (cx->entry_method == ACPI_CSTATE_HALT) {\n\t\tacpi_safe_halt();\n\t} else {\n\t\tio_idle(cx->address);\n\t}\n\n\tperf_lopwr_cb(false);\n}\n\n \nstatic int acpi_idle_play_dead(struct cpuidle_device *dev, int index)\n{\n\tstruct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);\n\n\tACPI_FLUSH_CPU_CACHE();\n\n\twhile (1) {\n\n\t\tif (cx->entry_method == ACPI_CSTATE_HALT)\n\t\t\traw_safe_halt();\n\t\telse if (cx->entry_method == ACPI_CSTATE_SYSTEMIO) {\n\t\t\tio_idle(cx->address);\n\t\t} else\n\t\t\treturn -ENODEV;\n\t}\n\n\t \n\treturn 0;\n}\n\nstatic __always_inline bool acpi_idle_fallback_to_c1(struct acpi_processor *pr)\n{\n\treturn IS_ENABLED(CONFIG_HOTPLUG_CPU) && !pr->flags.has_cst &&\n\t\t!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED);\n}\n\nstatic int c3_cpu_count;\nstatic DEFINE_RAW_SPINLOCK(c3_lock);\n\n \nstatic int __cpuidle acpi_idle_enter_bm(struct cpuidle_driver *drv,\n\t\t\t       struct acpi_processor *pr,\n\t\t\t       struct acpi_processor_cx *cx,\n\t\t\t       int index)\n{\n\tstatic struct acpi_processor_cx safe_cx = {\n\t\t.entry_method = ACPI_CSTATE_HALT,\n\t};\n\n\t \n\tbool dis_bm = pr->flags.bm_control;\n\n\tinstrumentation_begin();\n\n\t \n\tif (!cx->bm_sts_skip && acpi_idle_bm_check()) {\n\t\tdis_bm = false;\n\t\tindex = drv->safe_state_index;\n\t\tif (index >= 0) {\n\t\t\tcx = this_cpu_read(acpi_cstate[index]);\n\t\t} else {\n\t\t\tcx = &safe_cx;\n\t\t\tindex = -EBUSY;\n\t\t}\n\t}\n\n\tif (dis_bm) {\n\t\traw_spin_lock(&c3_lock);\n\t\tc3_cpu_count++;\n\t\t \n\t\tif (c3_cpu_count == num_online_cpus())\n\t\t\tacpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 1);\n\t\traw_spin_unlock(&c3_lock);\n\t}\n\n\tct_cpuidle_enter();\n\n\tacpi_idle_do_entry(cx);\n\n\tct_cpuidle_exit();\n\n\t \n\tif (dis_bm) {\n\t\traw_spin_lock(&c3_lock);\n\t\tacpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 0);\n\t\tc3_cpu_count--;\n\t\traw_spin_unlock(&c3_lock);\n\t}\n\n\tinstrumentation_end();\n\n\treturn index;\n}\n\nstatic int __cpuidle acpi_idle_enter(struct cpuidle_device *dev,\n\t\t\t   struct cpuidle_driver *drv, int index)\n{\n\tstruct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);\n\tstruct acpi_processor *pr;\n\n\tpr = __this_cpu_read(processors);\n\tif (unlikely(!pr))\n\t\treturn -EINVAL;\n\n\tif (cx->type != ACPI_STATE_C1) {\n\t\tif (cx->type == ACPI_STATE_C3 && pr->flags.bm_check)\n\t\t\treturn acpi_idle_enter_bm(drv, pr, cx, index);\n\n\t\t \n\t\tif (acpi_idle_fallback_to_c1(pr) && num_online_cpus() > 1) {\n\t\t\tindex = ACPI_IDLE_STATE_START;\n\t\t\tcx = per_cpu(acpi_cstate[index], dev->cpu);\n\t\t}\n\t}\n\n\tif (cx->type == ACPI_STATE_C3)\n\t\tACPI_FLUSH_CPU_CACHE();\n\n\tacpi_idle_do_entry(cx);\n\n\treturn index;\n}\n\nstatic int __cpuidle acpi_idle_enter_s2idle(struct cpuidle_device *dev,\n\t\t\t\t  struct cpuidle_driver *drv, int index)\n{\n\tstruct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);\n\n\tif (cx->type == ACPI_STATE_C3) {\n\t\tstruct acpi_processor *pr = __this_cpu_read(processors);\n\n\t\tif (unlikely(!pr))\n\t\t\treturn 0;\n\n\t\tif (pr->flags.bm_check) {\n\t\t\tu8 bm_sts_skip = cx->bm_sts_skip;\n\n\t\t\t \n\t\t\tcx->bm_sts_skip = 1;\n\t\t\tacpi_idle_enter_bm(drv, pr, cx, index);\n\t\t\tcx->bm_sts_skip = bm_sts_skip;\n\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tACPI_FLUSH_CPU_CACHE();\n\t\t}\n\t}\n\tacpi_idle_do_entry(cx);\n\n\treturn 0;\n}\n\nstatic int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,\n\t\t\t\t\t   struct cpuidle_device *dev)\n{\n\tint i, count = ACPI_IDLE_STATE_START;\n\tstruct acpi_processor_cx *cx;\n\tstruct cpuidle_state *state;\n\n\tif (max_cstate == 0)\n\t\tmax_cstate = 1;\n\n\tfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\n\t\tstate = &acpi_idle_driver.states[count];\n\t\tcx = &pr->power.states[i];\n\n\t\tif (!cx->valid)\n\t\t\tcontinue;\n\n\t\tper_cpu(acpi_cstate[count], dev->cpu) = cx;\n\n\t\tif (lapic_timer_needs_broadcast(pr, cx))\n\t\t\tstate->flags |= CPUIDLE_FLAG_TIMER_STOP;\n\n\t\tif (cx->type == ACPI_STATE_C3) {\n\t\t\tstate->flags |= CPUIDLE_FLAG_TLB_FLUSHED;\n\t\t\tif (pr->flags.bm_check)\n\t\t\t\tstate->flags |= CPUIDLE_FLAG_RCU_IDLE;\n\t\t}\n\n\t\tcount++;\n\t\tif (count == CPUIDLE_STATE_MAX)\n\t\t\tbreak;\n\t}\n\n\tif (!count)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int acpi_processor_setup_cstates(struct acpi_processor *pr)\n{\n\tint i, count;\n\tstruct acpi_processor_cx *cx;\n\tstruct cpuidle_state *state;\n\tstruct cpuidle_driver *drv = &acpi_idle_driver;\n\n\tif (max_cstate == 0)\n\t\tmax_cstate = 1;\n\n\tif (IS_ENABLED(CONFIG_ARCH_HAS_CPU_RELAX)) {\n\t\tcpuidle_poll_state_init(drv);\n\t\tcount = 1;\n\t} else {\n\t\tcount = 0;\n\t}\n\n\tfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\n\t\tcx = &pr->power.states[i];\n\n\t\tif (!cx->valid)\n\t\t\tcontinue;\n\n\t\tstate = &drv->states[count];\n\t\tsnprintf(state->name, CPUIDLE_NAME_LEN, \"C%d\", i);\n\t\tstrscpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);\n\t\tstate->exit_latency = cx->latency;\n\t\tstate->target_residency = cx->latency * latency_factor;\n\t\tstate->enter = acpi_idle_enter;\n\n\t\tstate->flags = 0;\n\t\tif (cx->type == ACPI_STATE_C1 || cx->type == ACPI_STATE_C2 ||\n\t\t    cx->type == ACPI_STATE_C3) {\n\t\t\tstate->enter_dead = acpi_idle_play_dead;\n\t\t\tif (cx->type != ACPI_STATE_C3)\n\t\t\t\tdrv->safe_state_index = count;\n\t\t}\n\t\t \n\t\tif (cx->type != ACPI_STATE_C1 && !acpi_idle_fallback_to_c1(pr))\n\t\t\tstate->enter_s2idle = acpi_idle_enter_s2idle;\n\n\t\tcount++;\n\t\tif (count == CPUIDLE_STATE_MAX)\n\t\t\tbreak;\n\t}\n\n\tdrv->state_count = count;\n\n\tif (!count)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic inline void acpi_processor_cstate_first_run_checks(void)\n{\n\tstatic int first_run;\n\n\tif (first_run)\n\t\treturn;\n\tdmi_check_system(processor_power_dmi_table);\n\tmax_cstate = acpi_processor_cstate_check(max_cstate);\n\tif (max_cstate < ACPI_C_STATES_MAX)\n\t\tpr_notice(\"processor limited to max C-state %d\\n\", max_cstate);\n\n\tfirst_run++;\n\n\tif (nocst)\n\t\treturn;\n\n\tacpi_processor_claim_cst_control();\n}\n#else\n\nstatic inline int disabled_by_idle_boot_param(void) { return 0; }\nstatic inline void acpi_processor_cstate_first_run_checks(void) { }\nstatic int acpi_processor_get_cstate_info(struct acpi_processor *pr)\n{\n\treturn -ENODEV;\n}\n\nstatic int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,\n\t\t\t\t\t   struct cpuidle_device *dev)\n{\n\treturn -EINVAL;\n}\n\nstatic int acpi_processor_setup_cstates(struct acpi_processor *pr)\n{\n\treturn -EINVAL;\n}\n\n#endif  \n\nstruct acpi_lpi_states_array {\n\tunsigned int size;\n\tunsigned int composite_states_size;\n\tstruct acpi_lpi_state *entries;\n\tstruct acpi_lpi_state *composite_states[ACPI_PROCESSOR_MAX_POWER];\n};\n\nstatic int obj_get_integer(union acpi_object *obj, u32 *value)\n{\n\tif (obj->type != ACPI_TYPE_INTEGER)\n\t\treturn -EINVAL;\n\n\t*value = obj->integer.value;\n\treturn 0;\n}\n\nstatic int acpi_processor_evaluate_lpi(acpi_handle handle,\n\t\t\t\t       struct acpi_lpi_states_array *info)\n{\n\tacpi_status status;\n\tint ret = 0;\n\tint pkg_count, state_idx = 1, loop;\n\tstruct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };\n\tunion acpi_object *lpi_data;\n\tstruct acpi_lpi_state *lpi_state;\n\n\tstatus = acpi_evaluate_object(handle, \"_LPI\", NULL, &buffer);\n\tif (ACPI_FAILURE(status)) {\n\t\tacpi_handle_debug(handle, \"No _LPI, giving up\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tlpi_data = buffer.pointer;\n\n\t \n\tif (!lpi_data || lpi_data->type != ACPI_TYPE_PACKAGE ||\n\t    lpi_data->package.count < 4) {\n\t\tpr_debug(\"not enough elements in _LPI\\n\");\n\t\tret = -ENODATA;\n\t\tgoto end;\n\t}\n\n\tpkg_count = lpi_data->package.elements[2].integer.value;\n\n\t \n\tif (pkg_count < 1 || pkg_count != lpi_data->package.count - 3) {\n\t\tpr_debug(\"count given by _LPI is not valid\\n\");\n\t\tret = -ENODATA;\n\t\tgoto end;\n\t}\n\n\tlpi_state = kcalloc(pkg_count, sizeof(*lpi_state), GFP_KERNEL);\n\tif (!lpi_state) {\n\t\tret = -ENOMEM;\n\t\tgoto end;\n\t}\n\n\tinfo->size = pkg_count;\n\tinfo->entries = lpi_state;\n\n\t \n\tfor (loop = 3; state_idx <= pkg_count; loop++, state_idx++, lpi_state++) {\n\t\tunion acpi_object *element, *pkg_elem, *obj;\n\n\t\telement = &lpi_data->package.elements[loop];\n\t\tif (element->type != ACPI_TYPE_PACKAGE || element->package.count < 7)\n\t\t\tcontinue;\n\n\t\tpkg_elem = element->package.elements;\n\n\t\tobj = pkg_elem + 6;\n\t\tif (obj->type == ACPI_TYPE_BUFFER) {\n\t\t\tstruct acpi_power_register *reg;\n\n\t\t\treg = (struct acpi_power_register *)obj->buffer.pointer;\n\t\t\tif (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO &&\n\t\t\t    reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE)\n\t\t\t\tcontinue;\n\n\t\t\tlpi_state->address = reg->address;\n\t\t\tlpi_state->entry_method =\n\t\t\t\treg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE ?\n\t\t\t\tACPI_CSTATE_FFH : ACPI_CSTATE_SYSTEMIO;\n\t\t} else if (obj->type == ACPI_TYPE_INTEGER) {\n\t\t\tlpi_state->entry_method = ACPI_CSTATE_INTEGER;\n\t\t\tlpi_state->address = obj->integer.value;\n\t\t} else {\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\n\t\tobj = pkg_elem + 9;\n\t\tif (obj->type == ACPI_TYPE_STRING)\n\t\t\tstrscpy(lpi_state->desc, obj->string.pointer,\n\t\t\t\tACPI_CX_DESC_LEN);\n\n\t\tlpi_state->index = state_idx;\n\t\tif (obj_get_integer(pkg_elem + 0, &lpi_state->min_residency)) {\n\t\t\tpr_debug(\"No min. residency found, assuming 10 us\\n\");\n\t\t\tlpi_state->min_residency = 10;\n\t\t}\n\n\t\tif (obj_get_integer(pkg_elem + 1, &lpi_state->wake_latency)) {\n\t\t\tpr_debug(\"No wakeup residency found, assuming 10 us\\n\");\n\t\t\tlpi_state->wake_latency = 10;\n\t\t}\n\n\t\tif (obj_get_integer(pkg_elem + 2, &lpi_state->flags))\n\t\t\tlpi_state->flags = 0;\n\n\t\tif (obj_get_integer(pkg_elem + 3, &lpi_state->arch_flags))\n\t\t\tlpi_state->arch_flags = 0;\n\n\t\tif (obj_get_integer(pkg_elem + 4, &lpi_state->res_cnt_freq))\n\t\t\tlpi_state->res_cnt_freq = 1;\n\n\t\tif (obj_get_integer(pkg_elem + 5, &lpi_state->enable_parent_state))\n\t\t\tlpi_state->enable_parent_state = 0;\n\t}\n\n\tacpi_handle_debug(handle, \"Found %d power states\\n\", state_idx);\nend:\n\tkfree(buffer.pointer);\n\treturn ret;\n}\n\n \nstatic int flat_state_cnt;\n\n \nstatic bool combine_lpi_states(struct acpi_lpi_state *local,\n\t\t\t       struct acpi_lpi_state *parent,\n\t\t\t       struct acpi_lpi_state *result)\n{\n\tif (parent->entry_method == ACPI_CSTATE_INTEGER) {\n\t\tif (!parent->address)  \n\t\t\treturn false;\n\t\tresult->address = local->address + parent->address;\n\t} else {\n\t\tresult->address = parent->address;\n\t}\n\n\tresult->min_residency = max(local->min_residency, parent->min_residency);\n\tresult->wake_latency = local->wake_latency + parent->wake_latency;\n\tresult->enable_parent_state = parent->enable_parent_state;\n\tresult->entry_method = local->entry_method;\n\n\tresult->flags = parent->flags;\n\tresult->arch_flags = parent->arch_flags;\n\tresult->index = parent->index;\n\n\tstrscpy(result->desc, local->desc, ACPI_CX_DESC_LEN);\n\tstrlcat(result->desc, \"+\", ACPI_CX_DESC_LEN);\n\tstrlcat(result->desc, parent->desc, ACPI_CX_DESC_LEN);\n\treturn true;\n}\n\n#define ACPI_LPI_STATE_FLAGS_ENABLED\t\t\tBIT(0)\n\nstatic void stash_composite_state(struct acpi_lpi_states_array *curr_level,\n\t\t\t\t  struct acpi_lpi_state *t)\n{\n\tcurr_level->composite_states[curr_level->composite_states_size++] = t;\n}\n\nstatic int flatten_lpi_states(struct acpi_processor *pr,\n\t\t\t      struct acpi_lpi_states_array *curr_level,\n\t\t\t      struct acpi_lpi_states_array *prev_level)\n{\n\tint i, j, state_count = curr_level->size;\n\tstruct acpi_lpi_state *p, *t = curr_level->entries;\n\n\tcurr_level->composite_states_size = 0;\n\tfor (j = 0; j < state_count; j++, t++) {\n\t\tstruct acpi_lpi_state *flpi;\n\n\t\tif (!(t->flags & ACPI_LPI_STATE_FLAGS_ENABLED))\n\t\t\tcontinue;\n\n\t\tif (flat_state_cnt >= ACPI_PROCESSOR_MAX_POWER) {\n\t\t\tpr_warn(\"Limiting number of LPI states to max (%d)\\n\",\n\t\t\t\tACPI_PROCESSOR_MAX_POWER);\n\t\t\tpr_warn(\"Please increase ACPI_PROCESSOR_MAX_POWER if needed.\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tflpi = &pr->power.lpi_states[flat_state_cnt];\n\n\t\tif (!prev_level) {  \n\t\t\tmemcpy(flpi, t, sizeof(*t));\n\t\t\tstash_composite_state(curr_level, flpi);\n\t\t\tflat_state_cnt++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor (i = 0; i < prev_level->composite_states_size; i++) {\n\t\t\tp = prev_level->composite_states[i];\n\t\t\tif (t->index <= p->enable_parent_state &&\n\t\t\t    combine_lpi_states(p, t, flpi)) {\n\t\t\t\tstash_composite_state(curr_level, flpi);\n\t\t\t\tflat_state_cnt++;\n\t\t\t\tflpi++;\n\t\t\t}\n\t\t}\n\t}\n\n\tkfree(curr_level->entries);\n\treturn 0;\n}\n\nint __weak acpi_processor_ffh_lpi_probe(unsigned int cpu)\n{\n\treturn -EOPNOTSUPP;\n}\n\nstatic int acpi_processor_get_lpi_info(struct acpi_processor *pr)\n{\n\tint ret, i;\n\tacpi_status status;\n\tacpi_handle handle = pr->handle, pr_ahandle;\n\tstruct acpi_device *d = NULL;\n\tstruct acpi_lpi_states_array info[2], *tmp, *prev, *curr;\n\n\t \n\tret = acpi_processor_ffh_lpi_probe(pr->id);\n\tif (ret == -EOPNOTSUPP)\n\t\treturn ret;\n\n\tif (!osc_pc_lpi_support_confirmed)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!acpi_has_method(handle, \"_LPI\"))\n\t\treturn -EINVAL;\n\n\tflat_state_cnt = 0;\n\tprev = &info[0];\n\tcurr = &info[1];\n\thandle = pr->handle;\n\tret = acpi_processor_evaluate_lpi(handle, prev);\n\tif (ret)\n\t\treturn ret;\n\tflatten_lpi_states(pr, prev, NULL);\n\n\tstatus = acpi_get_parent(handle, &pr_ahandle);\n\twhile (ACPI_SUCCESS(status)) {\n\t\td = acpi_fetch_acpi_dev(pr_ahandle);\n\t\tif (!d)\n\t\t\tbreak;\n\n\t\thandle = pr_ahandle;\n\n\t\tif (strcmp(acpi_device_hid(d), ACPI_PROCESSOR_CONTAINER_HID))\n\t\t\tbreak;\n\n\t\t \n\t\tif (!acpi_has_method(handle, \"_LPI\"))\n\t\t\tbreak;\n\n\t\tret = acpi_processor_evaluate_lpi(handle, curr);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\t \n\t\tflatten_lpi_states(pr, curr, prev);\n\n\t\ttmp = prev, prev = curr, curr = tmp;\n\n\t\tstatus = acpi_get_parent(handle, &pr_ahandle);\n\t}\n\n\tpr->power.count = flat_state_cnt;\n\t \n\tfor (i = 0; i < pr->power.count; i++)\n\t\tpr->power.lpi_states[i].index = i;\n\n\t \n\tpr->flags.has_lpi = 1;\n\tpr->flags.power = 1;\n\n\treturn 0;\n}\n\nint __weak acpi_processor_ffh_lpi_enter(struct acpi_lpi_state *lpi)\n{\n\treturn -ENODEV;\n}\n\n \nstatic int acpi_idle_lpi_enter(struct cpuidle_device *dev,\n\t\t\t       struct cpuidle_driver *drv, int index)\n{\n\tstruct acpi_processor *pr;\n\tstruct acpi_lpi_state *lpi;\n\n\tpr = __this_cpu_read(processors);\n\n\tif (unlikely(!pr))\n\t\treturn -EINVAL;\n\n\tlpi = &pr->power.lpi_states[index];\n\tif (lpi->entry_method == ACPI_CSTATE_FFH)\n\t\treturn acpi_processor_ffh_lpi_enter(lpi);\n\n\treturn -EINVAL;\n}\n\nstatic int acpi_processor_setup_lpi_states(struct acpi_processor *pr)\n{\n\tint i;\n\tstruct acpi_lpi_state *lpi;\n\tstruct cpuidle_state *state;\n\tstruct cpuidle_driver *drv = &acpi_idle_driver;\n\n\tif (!pr->flags.has_lpi)\n\t\treturn -EOPNOTSUPP;\n\n\tfor (i = 0; i < pr->power.count && i < CPUIDLE_STATE_MAX; i++) {\n\t\tlpi = &pr->power.lpi_states[i];\n\n\t\tstate = &drv->states[i];\n\t\tsnprintf(state->name, CPUIDLE_NAME_LEN, \"LPI-%d\", i);\n\t\tstrscpy(state->desc, lpi->desc, CPUIDLE_DESC_LEN);\n\t\tstate->exit_latency = lpi->wake_latency;\n\t\tstate->target_residency = lpi->min_residency;\n\t\tstate->flags |= arch_get_idle_state_flags(lpi->arch_flags);\n\t\tif (i != 0 && lpi->entry_method == ACPI_CSTATE_FFH)\n\t\t\tstate->flags |= CPUIDLE_FLAG_RCU_IDLE;\n\t\tstate->enter = acpi_idle_lpi_enter;\n\t\tdrv->safe_state_index = i;\n\t}\n\n\tdrv->state_count = i;\n\n\treturn 0;\n}\n\n \nstatic int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)\n{\n\tint i;\n\tstruct cpuidle_driver *drv = &acpi_idle_driver;\n\n\tif (!pr->flags.power_setup_done || !pr->flags.power)\n\t\treturn -EINVAL;\n\n\tdrv->safe_state_index = -1;\n\tfor (i = ACPI_IDLE_STATE_START; i < CPUIDLE_STATE_MAX; i++) {\n\t\tdrv->states[i].name[0] = '\\0';\n\t\tdrv->states[i].desc[0] = '\\0';\n\t}\n\n\tif (pr->flags.has_lpi)\n\t\treturn acpi_processor_setup_lpi_states(pr);\n\n\treturn acpi_processor_setup_cstates(pr);\n}\n\n \nstatic int acpi_processor_setup_cpuidle_dev(struct acpi_processor *pr,\n\t\t\t\t\t    struct cpuidle_device *dev)\n{\n\tif (!pr->flags.power_setup_done || !pr->flags.power || !dev)\n\t\treturn -EINVAL;\n\n\tdev->cpu = pr->id;\n\tif (pr->flags.has_lpi)\n\t\treturn acpi_processor_ffh_lpi_probe(pr->id);\n\n\treturn acpi_processor_setup_cpuidle_cx(pr, dev);\n}\n\nstatic int acpi_processor_get_power_info(struct acpi_processor *pr)\n{\n\tint ret;\n\n\tret = acpi_processor_get_lpi_info(pr);\n\tif (ret)\n\t\tret = acpi_processor_get_cstate_info(pr);\n\n\treturn ret;\n}\n\nint acpi_processor_hotplug(struct acpi_processor *pr)\n{\n\tint ret = 0;\n\tstruct cpuidle_device *dev;\n\n\tif (disabled_by_idle_boot_param())\n\t\treturn 0;\n\n\tif (!pr->flags.power_setup_done)\n\t\treturn -ENODEV;\n\n\tdev = per_cpu(acpi_cpuidle_device, pr->id);\n\tcpuidle_pause_and_lock();\n\tcpuidle_disable_device(dev);\n\tret = acpi_processor_get_power_info(pr);\n\tif (!ret && pr->flags.power) {\n\t\tacpi_processor_setup_cpuidle_dev(pr, dev);\n\t\tret = cpuidle_enable_device(dev);\n\t}\n\tcpuidle_resume_and_unlock();\n\n\treturn ret;\n}\n\nint acpi_processor_power_state_has_changed(struct acpi_processor *pr)\n{\n\tint cpu;\n\tstruct acpi_processor *_pr;\n\tstruct cpuidle_device *dev;\n\n\tif (disabled_by_idle_boot_param())\n\t\treturn 0;\n\n\tif (!pr->flags.power_setup_done)\n\t\treturn -ENODEV;\n\n\t \n\n\tif (pr->id == 0 && cpuidle_get_driver() == &acpi_idle_driver) {\n\n\t\t \n\t\tcpus_read_lock();\n\t\tcpuidle_pause_and_lock();\n\n\t\t \n\t\tfor_each_online_cpu(cpu) {\n\t\t\t_pr = per_cpu(processors, cpu);\n\t\t\tif (!_pr || !_pr->flags.power_setup_done)\n\t\t\t\tcontinue;\n\t\t\tdev = per_cpu(acpi_cpuidle_device, cpu);\n\t\t\tcpuidle_disable_device(dev);\n\t\t}\n\n\t\t \n\t\tacpi_processor_get_power_info(pr);\n\t\tacpi_processor_setup_cpuidle_states(pr);\n\n\t\t \n\t\tfor_each_online_cpu(cpu) {\n\t\t\t_pr = per_cpu(processors, cpu);\n\t\t\tif (!_pr || !_pr->flags.power_setup_done)\n\t\t\t\tcontinue;\n\t\t\tacpi_processor_get_power_info(_pr);\n\t\t\tif (_pr->flags.power) {\n\t\t\t\tdev = per_cpu(acpi_cpuidle_device, cpu);\n\t\t\t\tacpi_processor_setup_cpuidle_dev(_pr, dev);\n\t\t\t\tcpuidle_enable_device(dev);\n\t\t\t}\n\t\t}\n\t\tcpuidle_resume_and_unlock();\n\t\tcpus_read_unlock();\n\t}\n\n\treturn 0;\n}\n\nstatic int acpi_processor_registered;\n\nint acpi_processor_power_init(struct acpi_processor *pr)\n{\n\tint retval;\n\tstruct cpuidle_device *dev;\n\n\tif (disabled_by_idle_boot_param())\n\t\treturn 0;\n\n\tacpi_processor_cstate_first_run_checks();\n\n\tif (!acpi_processor_get_power_info(pr))\n\t\tpr->flags.power_setup_done = 1;\n\n\t \n\tif (pr->flags.power) {\n\t\t \n\t\tif (!acpi_processor_registered) {\n\t\t\tacpi_processor_setup_cpuidle_states(pr);\n\t\t\tretval = cpuidle_register_driver(&acpi_idle_driver);\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t\tpr_debug(\"%s registered with cpuidle\\n\",\n\t\t\t\t acpi_idle_driver.name);\n\t\t}\n\n\t\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\t\tif (!dev)\n\t\t\treturn -ENOMEM;\n\t\tper_cpu(acpi_cpuidle_device, pr->id) = dev;\n\n\t\tacpi_processor_setup_cpuidle_dev(pr, dev);\n\n\t\t \n\t\tretval = cpuidle_register_device(dev);\n\t\tif (retval) {\n\t\t\tif (acpi_processor_registered == 0)\n\t\t\t\tcpuidle_unregister_driver(&acpi_idle_driver);\n\t\t\treturn retval;\n\t\t}\n\t\tacpi_processor_registered++;\n\t}\n\treturn 0;\n}\n\nint acpi_processor_power_exit(struct acpi_processor *pr)\n{\n\tstruct cpuidle_device *dev = per_cpu(acpi_cpuidle_device, pr->id);\n\n\tif (disabled_by_idle_boot_param())\n\t\treturn 0;\n\n\tif (pr->flags.power) {\n\t\tcpuidle_unregister_device(dev);\n\t\tacpi_processor_registered--;\n\t\tif (acpi_processor_registered == 0)\n\t\t\tcpuidle_unregister_driver(&acpi_idle_driver);\n\t}\n\n\tpr->flags.power_setup_done = 0;\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}