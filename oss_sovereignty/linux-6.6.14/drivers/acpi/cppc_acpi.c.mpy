{
  "module_name": "cppc_acpi.c",
  "hash_id": "2e3adebf0191a5c9585f365390806807b725651e019c055686d56e35abef9a71",
  "original_prompt": "Ingested from linux-6.6.14/drivers/acpi/cppc_acpi.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"ACPI CPPC: \" fmt\n\n#include <linux/delay.h>\n#include <linux/iopoll.h>\n#include <linux/ktime.h>\n#include <linux/rwsem.h>\n#include <linux/wait.h>\n#include <linux/topology.h>\n\n#include <acpi/cppc_acpi.h>\n\nstruct cppc_pcc_data {\n\tstruct pcc_mbox_chan *pcc_channel;\n\tvoid __iomem *pcc_comm_addr;\n\tbool pcc_channel_acquired;\n\tunsigned int deadline_us;\n\tunsigned int pcc_mpar, pcc_mrtt, pcc_nominal;\n\n\tbool pending_pcc_write_cmd;\t \n\tbool platform_owns_pcc;\t\t \n\tunsigned int pcc_write_cnt;\t \n\n\t \n\tstruct rw_semaphore pcc_lock;\n\n\t \n\twait_queue_head_t pcc_write_wait_q;\n\tktime_t last_cmd_cmpl_time;\n\tktime_t last_mpar_reset;\n\tint mpar_count;\n\tint refcount;\n};\n\n \nstatic struct cppc_pcc_data *pcc_data[MAX_PCC_SUBSPACES];\n \nstatic DEFINE_PER_CPU(int, cpu_pcc_subspace_idx);\n\n \nstatic DEFINE_PER_CPU(struct cpc_desc *, cpc_desc_ptr);\n\n \n#define GET_PCC_VADDR(offs, pcc_ss_id) (pcc_data[pcc_ss_id]->pcc_comm_addr + \\\n\t\t\t\t\t\t0x8 + (offs))\n\n \n#define CPC_IN_PCC(cpc) ((cpc)->type == ACPI_TYPE_BUFFER &&\t\t\\\n\t\t\t\t(cpc)->cpc_entry.reg.space_id ==\t\\\n\t\t\t\tACPI_ADR_SPACE_PLATFORM_COMM)\n\n \n#define CPC_IN_SYSTEM_MEMORY(cpc) ((cpc)->type == ACPI_TYPE_BUFFER &&\t\\\n\t\t\t\t(cpc)->cpc_entry.reg.space_id ==\t\\\n\t\t\t\tACPI_ADR_SPACE_SYSTEM_MEMORY)\n\n \n#define CPC_IN_SYSTEM_IO(cpc) ((cpc)->type == ACPI_TYPE_BUFFER &&\t\\\n\t\t\t\t(cpc)->cpc_entry.reg.space_id ==\t\\\n\t\t\t\tACPI_ADR_SPACE_SYSTEM_IO)\n\n \n#define IS_NULL_REG(reg) ((reg)->space_id ==  ACPI_ADR_SPACE_SYSTEM_MEMORY && \\\n\t\t\t\t(reg)->address == 0 &&\t\t\t\\\n\t\t\t\t(reg)->bit_width == 0 &&\t\t\\\n\t\t\t\t(reg)->bit_offset == 0 &&\t\t\\\n\t\t\t\t(reg)->access_width == 0)\n\n \n#define CPC_SUPPORTED(cpc) ((cpc)->type == ACPI_TYPE_INTEGER ?\t\t\\\n\t\t\t\t!!(cpc)->cpc_entry.int_value :\t\t\\\n\t\t\t\t!IS_NULL_REG(&(cpc)->cpc_entry.reg))\n \n#define NUM_RETRIES 500ULL\n\n#define OVER_16BTS_MASK ~0xFFFFULL\n\n#define define_one_cppc_ro(_name)\t\t\\\nstatic struct kobj_attribute _name =\t\t\\\n__ATTR(_name, 0444, show_##_name, NULL)\n\n#define to_cpc_desc(a) container_of(a, struct cpc_desc, kobj)\n\n#define show_cppc_data(access_fn, struct_name, member_name)\t\t\\\n\tstatic ssize_t show_##member_name(struct kobject *kobj,\t\t\\\n\t\t\t\tstruct kobj_attribute *attr, char *buf)\t\\\n\t{\t\t\t\t\t\t\t\t\\\n\t\tstruct cpc_desc *cpc_ptr = to_cpc_desc(kobj);\t\t\\\n\t\tstruct struct_name st_name = {0};\t\t\t\\\n\t\tint ret;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\tret = access_fn(cpc_ptr->cpu_id, &st_name);\t\t\\\n\t\tif (ret)\t\t\t\t\t\t\\\n\t\t\treturn ret;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\treturn sysfs_emit(buf, \"%llu\\n\",\t\t\\\n\t\t\t\t(u64)st_name.member_name);\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tdefine_one_cppc_ro(member_name)\n\nshow_cppc_data(cppc_get_perf_caps, cppc_perf_caps, highest_perf);\nshow_cppc_data(cppc_get_perf_caps, cppc_perf_caps, lowest_perf);\nshow_cppc_data(cppc_get_perf_caps, cppc_perf_caps, nominal_perf);\nshow_cppc_data(cppc_get_perf_caps, cppc_perf_caps, lowest_nonlinear_perf);\nshow_cppc_data(cppc_get_perf_caps, cppc_perf_caps, lowest_freq);\nshow_cppc_data(cppc_get_perf_caps, cppc_perf_caps, nominal_freq);\n\nshow_cppc_data(cppc_get_perf_ctrs, cppc_perf_fb_ctrs, reference_perf);\nshow_cppc_data(cppc_get_perf_ctrs, cppc_perf_fb_ctrs, wraparound_time);\n\nstatic ssize_t show_feedback_ctrs(struct kobject *kobj,\n\t\tstruct kobj_attribute *attr, char *buf)\n{\n\tstruct cpc_desc *cpc_ptr = to_cpc_desc(kobj);\n\tstruct cppc_perf_fb_ctrs fb_ctrs = {0};\n\tint ret;\n\n\tret = cppc_get_perf_ctrs(cpc_ptr->cpu_id, &fb_ctrs);\n\tif (ret)\n\t\treturn ret;\n\n\treturn sysfs_emit(buf, \"ref:%llu del:%llu\\n\",\n\t\t\tfb_ctrs.reference, fb_ctrs.delivered);\n}\ndefine_one_cppc_ro(feedback_ctrs);\n\nstatic struct attribute *cppc_attrs[] = {\n\t&feedback_ctrs.attr,\n\t&reference_perf.attr,\n\t&wraparound_time.attr,\n\t&highest_perf.attr,\n\t&lowest_perf.attr,\n\t&lowest_nonlinear_perf.attr,\n\t&nominal_perf.attr,\n\t&nominal_freq.attr,\n\t&lowest_freq.attr,\n\tNULL\n};\nATTRIBUTE_GROUPS(cppc);\n\nstatic const struct kobj_type cppc_ktype = {\n\t.sysfs_ops = &kobj_sysfs_ops,\n\t.default_groups = cppc_groups,\n};\n\nstatic int check_pcc_chan(int pcc_ss_id, bool chk_err_bit)\n{\n\tint ret, status;\n\tstruct cppc_pcc_data *pcc_ss_data = pcc_data[pcc_ss_id];\n\tstruct acpi_pcct_shared_memory __iomem *generic_comm_base =\n\t\tpcc_ss_data->pcc_comm_addr;\n\n\tif (!pcc_ss_data->platform_owns_pcc)\n\t\treturn 0;\n\n\t \n\tret = readw_relaxed_poll_timeout(&generic_comm_base->status, status,\n\t\t\t\t\tstatus & PCC_CMD_COMPLETE_MASK, 3,\n\t\t\t\t\tpcc_ss_data->deadline_us);\n\n\tif (likely(!ret)) {\n\t\tpcc_ss_data->platform_owns_pcc = false;\n\t\tif (chk_err_bit && (status & PCC_ERROR_MASK))\n\t\t\tret = -EIO;\n\t}\n\n\tif (unlikely(ret))\n\t\tpr_err(\"PCC check channel failed for ss: %d. ret=%d\\n\",\n\t\t       pcc_ss_id, ret);\n\n\treturn ret;\n}\n\n \nstatic int send_pcc_cmd(int pcc_ss_id, u16 cmd)\n{\n\tint ret = -EIO, i;\n\tstruct cppc_pcc_data *pcc_ss_data = pcc_data[pcc_ss_id];\n\tstruct acpi_pcct_shared_memory __iomem *generic_comm_base =\n\t\tpcc_ss_data->pcc_comm_addr;\n\tunsigned int time_delta;\n\n\t \n\tif (cmd == CMD_READ) {\n\t\t \n\t\tif (pcc_ss_data->pending_pcc_write_cmd)\n\t\t\tsend_pcc_cmd(pcc_ss_id, CMD_WRITE);\n\n\t\tret = check_pcc_chan(pcc_ss_id, false);\n\t\tif (ret)\n\t\t\tgoto end;\n\t} else  \n\t\tpcc_ss_data->pending_pcc_write_cmd = FALSE;\n\n\t \n\tif (pcc_ss_data->pcc_mrtt) {\n\t\ttime_delta = ktime_us_delta(ktime_get(),\n\t\t\t\t\t    pcc_ss_data->last_cmd_cmpl_time);\n\t\tif (pcc_ss_data->pcc_mrtt > time_delta)\n\t\t\tudelay(pcc_ss_data->pcc_mrtt - time_delta);\n\t}\n\n\t \n\tif (pcc_ss_data->pcc_mpar) {\n\t\tif (pcc_ss_data->mpar_count == 0) {\n\t\t\ttime_delta = ktime_ms_delta(ktime_get(),\n\t\t\t\t\t\t    pcc_ss_data->last_mpar_reset);\n\t\t\tif ((time_delta < 60 * MSEC_PER_SEC) && pcc_ss_data->last_mpar_reset) {\n\t\t\t\tpr_debug(\"PCC cmd for subspace %d not sent due to MPAR limit\",\n\t\t\t\t\t pcc_ss_id);\n\t\t\t\tret = -EIO;\n\t\t\t\tgoto end;\n\t\t\t}\n\t\t\tpcc_ss_data->last_mpar_reset = ktime_get();\n\t\t\tpcc_ss_data->mpar_count = pcc_ss_data->pcc_mpar;\n\t\t}\n\t\tpcc_ss_data->mpar_count--;\n\t}\n\n\t \n\twritew_relaxed(cmd, &generic_comm_base->command);\n\n\t \n\twritew_relaxed(0, &generic_comm_base->status);\n\n\tpcc_ss_data->platform_owns_pcc = true;\n\n\t \n\tret = mbox_send_message(pcc_ss_data->pcc_channel->mchan, &cmd);\n\tif (ret < 0) {\n\t\tpr_err(\"Err sending PCC mbox message. ss: %d cmd:%d, ret:%d\\n\",\n\t\t       pcc_ss_id, cmd, ret);\n\t\tgoto end;\n\t}\n\n\t \n\tret = check_pcc_chan(pcc_ss_id, true);\n\n\tif (pcc_ss_data->pcc_mrtt)\n\t\tpcc_ss_data->last_cmd_cmpl_time = ktime_get();\n\n\tif (pcc_ss_data->pcc_channel->mchan->mbox->txdone_irq)\n\t\tmbox_chan_txdone(pcc_ss_data->pcc_channel->mchan, ret);\n\telse\n\t\tmbox_client_txdone(pcc_ss_data->pcc_channel->mchan, ret);\n\nend:\n\tif (cmd == CMD_WRITE) {\n\t\tif (unlikely(ret)) {\n\t\t\tfor_each_possible_cpu(i) {\n\t\t\t\tstruct cpc_desc *desc = per_cpu(cpc_desc_ptr, i);\n\n\t\t\t\tif (!desc)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (desc->write_cmd_id == pcc_ss_data->pcc_write_cnt)\n\t\t\t\t\tdesc->write_cmd_status = ret;\n\t\t\t}\n\t\t}\n\t\tpcc_ss_data->pcc_write_cnt++;\n\t\twake_up_all(&pcc_ss_data->pcc_write_wait_q);\n\t}\n\n\treturn ret;\n}\n\nstatic void cppc_chan_tx_done(struct mbox_client *cl, void *msg, int ret)\n{\n\tif (ret < 0)\n\t\tpr_debug(\"TX did not complete: CMD sent:%x, ret:%d\\n\",\n\t\t\t\t*(u16 *)msg, ret);\n\telse\n\t\tpr_debug(\"TX completed. CMD sent:%x, ret:%d\\n\",\n\t\t\t\t*(u16 *)msg, ret);\n}\n\nstatic struct mbox_client cppc_mbox_cl = {\n\t.tx_done = cppc_chan_tx_done,\n\t.knows_txdone = true,\n};\n\nstatic int acpi_get_psd(struct cpc_desc *cpc_ptr, acpi_handle handle)\n{\n\tint result = -EFAULT;\n\tacpi_status status = AE_OK;\n\tstruct acpi_buffer buffer = {ACPI_ALLOCATE_BUFFER, NULL};\n\tstruct acpi_buffer format = {sizeof(\"NNNNN\"), \"NNNNN\"};\n\tstruct acpi_buffer state = {0, NULL};\n\tunion acpi_object  *psd = NULL;\n\tstruct acpi_psd_package *pdomain;\n\n\tstatus = acpi_evaluate_object_typed(handle, \"_PSD\", NULL,\n\t\t\t\t\t    &buffer, ACPI_TYPE_PACKAGE);\n\tif (status == AE_NOT_FOUND)\t \n\t\treturn 0;\n\tif (ACPI_FAILURE(status))\n\t\treturn -ENODEV;\n\n\tpsd = buffer.pointer;\n\tif (!psd || psd->package.count != 1) {\n\t\tpr_debug(\"Invalid _PSD data\\n\");\n\t\tgoto end;\n\t}\n\n\tpdomain = &(cpc_ptr->domain_info);\n\n\tstate.length = sizeof(struct acpi_psd_package);\n\tstate.pointer = pdomain;\n\n\tstatus = acpi_extract_package(&(psd->package.elements[0]),\n\t\t&format, &state);\n\tif (ACPI_FAILURE(status)) {\n\t\tpr_debug(\"Invalid _PSD data for CPU:%d\\n\", cpc_ptr->cpu_id);\n\t\tgoto end;\n\t}\n\n\tif (pdomain->num_entries != ACPI_PSD_REV0_ENTRIES) {\n\t\tpr_debug(\"Unknown _PSD:num_entries for CPU:%d\\n\", cpc_ptr->cpu_id);\n\t\tgoto end;\n\t}\n\n\tif (pdomain->revision != ACPI_PSD_REV0_REVISION) {\n\t\tpr_debug(\"Unknown _PSD:revision for CPU: %d\\n\", cpc_ptr->cpu_id);\n\t\tgoto end;\n\t}\n\n\tif (pdomain->coord_type != DOMAIN_COORD_TYPE_SW_ALL &&\n\t    pdomain->coord_type != DOMAIN_COORD_TYPE_SW_ANY &&\n\t    pdomain->coord_type != DOMAIN_COORD_TYPE_HW_ALL) {\n\t\tpr_debug(\"Invalid _PSD:coord_type for CPU:%d\\n\", cpc_ptr->cpu_id);\n\t\tgoto end;\n\t}\n\n\tresult = 0;\nend:\n\tkfree(buffer.pointer);\n\treturn result;\n}\n\nbool acpi_cpc_valid(void)\n{\n\tstruct cpc_desc *cpc_ptr;\n\tint cpu;\n\n\tif (acpi_disabled)\n\t\treturn false;\n\n\tfor_each_present_cpu(cpu) {\n\t\tcpc_ptr = per_cpu(cpc_desc_ptr, cpu);\n\t\tif (!cpc_ptr)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(acpi_cpc_valid);\n\nbool cppc_allow_fast_switch(void)\n{\n\tstruct cpc_register_resource *desired_reg;\n\tstruct cpc_desc *cpc_ptr;\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tcpc_ptr = per_cpu(cpc_desc_ptr, cpu);\n\t\tdesired_reg = &cpc_ptr->cpc_regs[DESIRED_PERF];\n\t\tif (!CPC_IN_SYSTEM_MEMORY(desired_reg) &&\n\t\t\t\t!CPC_IN_SYSTEM_IO(desired_reg))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(cppc_allow_fast_switch);\n\n \nint acpi_get_psd_map(unsigned int cpu, struct cppc_cpudata *cpu_data)\n{\n\tstruct cpc_desc *cpc_ptr, *match_cpc_ptr;\n\tstruct acpi_psd_package *match_pdomain;\n\tstruct acpi_psd_package *pdomain;\n\tint count_target, i;\n\n\t \n\tcpc_ptr = per_cpu(cpc_desc_ptr, cpu);\n\tif (!cpc_ptr)\n\t\treturn -EFAULT;\n\n\tpdomain = &(cpc_ptr->domain_info);\n\tcpumask_set_cpu(cpu, cpu_data->shared_cpu_map);\n\tif (pdomain->num_processors <= 1)\n\t\treturn 0;\n\n\t \n\tcount_target = pdomain->num_processors;\n\tif (pdomain->coord_type == DOMAIN_COORD_TYPE_SW_ALL)\n\t\tcpu_data->shared_type = CPUFREQ_SHARED_TYPE_ALL;\n\telse if (pdomain->coord_type == DOMAIN_COORD_TYPE_HW_ALL)\n\t\tcpu_data->shared_type = CPUFREQ_SHARED_TYPE_HW;\n\telse if (pdomain->coord_type == DOMAIN_COORD_TYPE_SW_ANY)\n\t\tcpu_data->shared_type = CPUFREQ_SHARED_TYPE_ANY;\n\n\tfor_each_possible_cpu(i) {\n\t\tif (i == cpu)\n\t\t\tcontinue;\n\n\t\tmatch_cpc_ptr = per_cpu(cpc_desc_ptr, i);\n\t\tif (!match_cpc_ptr)\n\t\t\tgoto err_fault;\n\n\t\tmatch_pdomain = &(match_cpc_ptr->domain_info);\n\t\tif (match_pdomain->domain != pdomain->domain)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (match_pdomain->num_processors != count_target)\n\t\t\tgoto err_fault;\n\n\t\tif (pdomain->coord_type != match_pdomain->coord_type)\n\t\t\tgoto err_fault;\n\n\t\tcpumask_set_cpu(i, cpu_data->shared_cpu_map);\n\t}\n\n\treturn 0;\n\nerr_fault:\n\t \n\tcpumask_clear(cpu_data->shared_cpu_map);\n\tcpumask_set_cpu(cpu, cpu_data->shared_cpu_map);\n\tcpu_data->shared_type = CPUFREQ_SHARED_TYPE_NONE;\n\n\treturn -EFAULT;\n}\nEXPORT_SYMBOL_GPL(acpi_get_psd_map);\n\nstatic int register_pcc_channel(int pcc_ss_idx)\n{\n\tstruct pcc_mbox_chan *pcc_chan;\n\tu64 usecs_lat;\n\n\tif (pcc_ss_idx >= 0) {\n\t\tpcc_chan = pcc_mbox_request_channel(&cppc_mbox_cl, pcc_ss_idx);\n\n\t\tif (IS_ERR(pcc_chan)) {\n\t\t\tpr_err(\"Failed to find PCC channel for subspace %d\\n\",\n\t\t\t       pcc_ss_idx);\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tpcc_data[pcc_ss_idx]->pcc_channel = pcc_chan;\n\t\t \n\t\tusecs_lat = NUM_RETRIES * pcc_chan->latency;\n\t\tpcc_data[pcc_ss_idx]->deadline_us = usecs_lat;\n\t\tpcc_data[pcc_ss_idx]->pcc_mrtt = pcc_chan->min_turnaround_time;\n\t\tpcc_data[pcc_ss_idx]->pcc_mpar = pcc_chan->max_access_rate;\n\t\tpcc_data[pcc_ss_idx]->pcc_nominal = pcc_chan->latency;\n\n\t\tpcc_data[pcc_ss_idx]->pcc_comm_addr =\n\t\t\tacpi_os_ioremap(pcc_chan->shmem_base_addr,\n\t\t\t\t\tpcc_chan->shmem_size);\n\t\tif (!pcc_data[pcc_ss_idx]->pcc_comm_addr) {\n\t\t\tpr_err(\"Failed to ioremap PCC comm region mem for %d\\n\",\n\t\t\t       pcc_ss_idx);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tpcc_data[pcc_ss_idx]->pcc_channel_acquired = true;\n\t}\n\n\treturn 0;\n}\n\n \nbool __weak cpc_ffh_supported(void)\n{\n\treturn false;\n}\n\n \nbool __weak cpc_supported_by_cpu(void)\n{\n\treturn false;\n}\n\n \nstatic int pcc_data_alloc(int pcc_ss_id)\n{\n\tif (pcc_ss_id < 0 || pcc_ss_id >= MAX_PCC_SUBSPACES)\n\t\treturn -EINVAL;\n\n\tif (pcc_data[pcc_ss_id]) {\n\t\tpcc_data[pcc_ss_id]->refcount++;\n\t} else {\n\t\tpcc_data[pcc_ss_id] = kzalloc(sizeof(struct cppc_pcc_data),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!pcc_data[pcc_ss_id])\n\t\t\treturn -ENOMEM;\n\t\tpcc_data[pcc_ss_id]->refcount++;\n\t}\n\n\treturn 0;\n}\n\n \n\n#ifndef arch_init_invariance_cppc\nstatic inline void arch_init_invariance_cppc(void) { }\n#endif\n\n \nint acpi_cppc_processor_probe(struct acpi_processor *pr)\n{\n\tstruct acpi_buffer output = {ACPI_ALLOCATE_BUFFER, NULL};\n\tunion acpi_object *out_obj, *cpc_obj;\n\tstruct cpc_desc *cpc_ptr;\n\tstruct cpc_reg *gas_t;\n\tstruct device *cpu_dev;\n\tacpi_handle handle = pr->handle;\n\tunsigned int num_ent, i, cpc_rev;\n\tint pcc_subspace_id = -1;\n\tacpi_status status;\n\tint ret = -ENODATA;\n\n\tif (!osc_sb_cppc2_support_acked) {\n\t\tpr_debug(\"CPPC v2 _OSC not acked\\n\");\n\t\tif (!cpc_supported_by_cpu())\n\t\t\treturn -ENODEV;\n\t}\n\n\t \n\tstatus = acpi_evaluate_object_typed(handle, \"_CPC\", NULL, &output,\n\t\t\tACPI_TYPE_PACKAGE);\n\tif (ACPI_FAILURE(status)) {\n\t\tret = -ENODEV;\n\t\tgoto out_buf_free;\n\t}\n\n\tout_obj = (union acpi_object *) output.pointer;\n\n\tcpc_ptr = kzalloc(sizeof(struct cpc_desc), GFP_KERNEL);\n\tif (!cpc_ptr) {\n\t\tret = -ENOMEM;\n\t\tgoto out_buf_free;\n\t}\n\n\t \n\tcpc_obj = &out_obj->package.elements[0];\n\tif (cpc_obj->type == ACPI_TYPE_INTEGER)\t{\n\t\tnum_ent = cpc_obj->integer.value;\n\t\tif (num_ent <= 1) {\n\t\t\tpr_debug(\"Unexpected _CPC NumEntries value (%d) for CPU:%d\\n\",\n\t\t\t\t num_ent, pr->id);\n\t\t\tgoto out_free;\n\t\t}\n\t} else {\n\t\tpr_debug(\"Unexpected _CPC NumEntries entry type (%d) for CPU:%d\\n\",\n\t\t\t cpc_obj->type, pr->id);\n\t\tgoto out_free;\n\t}\n\n\t \n\tcpc_obj = &out_obj->package.elements[1];\n\tif (cpc_obj->type == ACPI_TYPE_INTEGER)\t{\n\t\tcpc_rev = cpc_obj->integer.value;\n\t} else {\n\t\tpr_debug(\"Unexpected _CPC Revision entry type (%d) for CPU:%d\\n\",\n\t\t\t cpc_obj->type, pr->id);\n\t\tgoto out_free;\n\t}\n\n\tif (cpc_rev < CPPC_V2_REV) {\n\t\tpr_debug(\"Unsupported _CPC Revision (%d) for CPU:%d\\n\", cpc_rev,\n\t\t\t pr->id);\n\t\tgoto out_free;\n\t}\n\n\t \n\tif ((cpc_rev == CPPC_V2_REV && num_ent != CPPC_V2_NUM_ENT) ||\n\t    (cpc_rev == CPPC_V3_REV && num_ent != CPPC_V3_NUM_ENT) ||\n\t    (cpc_rev > CPPC_V3_REV && num_ent <= CPPC_V3_NUM_ENT)) {\n\t\tpr_debug(\"Unexpected number of _CPC return package entries (%d) for CPU:%d\\n\",\n\t\t\t num_ent, pr->id);\n\t\tgoto out_free;\n\t}\n\tif (cpc_rev > CPPC_V3_REV) {\n\t\tnum_ent = CPPC_V3_NUM_ENT;\n\t\tcpc_rev = CPPC_V3_REV;\n\t}\n\n\tcpc_ptr->num_entries = num_ent;\n\tcpc_ptr->version = cpc_rev;\n\n\t \n\tfor (i = 2; i < num_ent; i++) {\n\t\tcpc_obj = &out_obj->package.elements[i];\n\n\t\tif (cpc_obj->type == ACPI_TYPE_INTEGER)\t{\n\t\t\tcpc_ptr->cpc_regs[i-2].type = ACPI_TYPE_INTEGER;\n\t\t\tcpc_ptr->cpc_regs[i-2].cpc_entry.int_value = cpc_obj->integer.value;\n\t\t} else if (cpc_obj->type == ACPI_TYPE_BUFFER) {\n\t\t\tgas_t = (struct cpc_reg *)\n\t\t\t\tcpc_obj->buffer.pointer;\n\n\t\t\t \n\t\t\tif (gas_t->space_id == ACPI_ADR_SPACE_PLATFORM_COMM) {\n\t\t\t\tif (pcc_subspace_id < 0) {\n\t\t\t\t\tpcc_subspace_id = gas_t->access_width;\n\t\t\t\t\tif (pcc_data_alloc(pcc_subspace_id))\n\t\t\t\t\t\tgoto out_free;\n\t\t\t\t} else if (pcc_subspace_id != gas_t->access_width) {\n\t\t\t\t\tpr_debug(\"Mismatched PCC ids in _CPC for CPU:%d\\n\",\n\t\t\t\t\t\t pr->id);\n\t\t\t\t\tgoto out_free;\n\t\t\t\t}\n\t\t\t} else if (gas_t->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY) {\n\t\t\t\tif (gas_t->address) {\n\t\t\t\t\tvoid __iomem *addr;\n\n\t\t\t\t\tif (!osc_cpc_flexible_adr_space_confirmed) {\n\t\t\t\t\t\tpr_debug(\"Flexible address space capability not supported\\n\");\n\t\t\t\t\t\tif (!cpc_supported_by_cpu())\n\t\t\t\t\t\t\tgoto out_free;\n\t\t\t\t\t}\n\n\t\t\t\t\taddr = ioremap(gas_t->address, gas_t->bit_width/8);\n\t\t\t\t\tif (!addr)\n\t\t\t\t\t\tgoto out_free;\n\t\t\t\t\tcpc_ptr->cpc_regs[i-2].sys_mem_vaddr = addr;\n\t\t\t\t}\n\t\t\t} else if (gas_t->space_id == ACPI_ADR_SPACE_SYSTEM_IO) {\n\t\t\t\tif (gas_t->access_width < 1 || gas_t->access_width > 3) {\n\t\t\t\t\t \n\t\t\t\t\tpr_debug(\"Invalid access width %d for SystemIO register in _CPC\\n\",\n\t\t\t\t\t\t gas_t->access_width);\n\t\t\t\t\tgoto out_free;\n\t\t\t\t}\n\t\t\t\tif (gas_t->address & OVER_16BTS_MASK) {\n\t\t\t\t\t \n\t\t\t\t\tpr_debug(\"Invalid IO port %llu for SystemIO register in _CPC\\n\",\n\t\t\t\t\t\t gas_t->address);\n\t\t\t\t\tgoto out_free;\n\t\t\t\t}\n\t\t\t\tif (!osc_cpc_flexible_adr_space_confirmed) {\n\t\t\t\t\tpr_debug(\"Flexible address space capability not supported\\n\");\n\t\t\t\t\tif (!cpc_supported_by_cpu())\n\t\t\t\t\t\tgoto out_free;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (gas_t->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE || !cpc_ffh_supported()) {\n\t\t\t\t\t \n\t\t\t\t\tpr_debug(\"Unsupported register type (%d) in _CPC\\n\",\n\t\t\t\t\t\t gas_t->space_id);\n\t\t\t\t\tgoto out_free;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcpc_ptr->cpc_regs[i-2].type = ACPI_TYPE_BUFFER;\n\t\t\tmemcpy(&cpc_ptr->cpc_regs[i-2].cpc_entry.reg, gas_t, sizeof(*gas_t));\n\t\t} else {\n\t\t\tpr_debug(\"Invalid entry type (%d) in _CPC for CPU:%d\\n\",\n\t\t\t\t i, pr->id);\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\tper_cpu(cpu_pcc_subspace_idx, pr->id) = pcc_subspace_id;\n\n\t \n\tfor (i = num_ent - 2; i < MAX_CPC_REG_ENT; i++) {\n\t\tcpc_ptr->cpc_regs[i].type = ACPI_TYPE_INTEGER;\n\t\tcpc_ptr->cpc_regs[i].cpc_entry.int_value = 0;\n\t}\n\n\n\t \n\tcpc_ptr->cpu_id = pr->id;\n\n\t \n\tret = acpi_get_psd(cpc_ptr, handle);\n\tif (ret)\n\t\tgoto out_free;\n\n\t \n\tif (pcc_subspace_id >= 0 && !pcc_data[pcc_subspace_id]->pcc_channel_acquired) {\n\t\tret = register_pcc_channel(pcc_subspace_id);\n\t\tif (ret)\n\t\t\tgoto out_free;\n\n\t\tinit_rwsem(&pcc_data[pcc_subspace_id]->pcc_lock);\n\t\tinit_waitqueue_head(&pcc_data[pcc_subspace_id]->pcc_write_wait_q);\n\t}\n\n\t \n\tpr_debug(\"Parsed CPC struct for CPU: %d\\n\", pr->id);\n\n\t \n\tcpu_dev = get_cpu_device(pr->id);\n\tif (!cpu_dev) {\n\t\tret = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\t \n\tper_cpu(cpc_desc_ptr, pr->id) = cpc_ptr;\n\n\tret = kobject_init_and_add(&cpc_ptr->kobj, &cppc_ktype, &cpu_dev->kobj,\n\t\t\t\"acpi_cppc\");\n\tif (ret) {\n\t\tper_cpu(cpc_desc_ptr, pr->id) = NULL;\n\t\tkobject_put(&cpc_ptr->kobj);\n\t\tgoto out_free;\n\t}\n\n\tarch_init_invariance_cppc();\n\n\tkfree(output.pointer);\n\treturn 0;\n\nout_free:\n\t \n\tfor (i = 2; i < cpc_ptr->num_entries; i++) {\n\t\tvoid __iomem *addr = cpc_ptr->cpc_regs[i-2].sys_mem_vaddr;\n\n\t\tif (addr)\n\t\t\tiounmap(addr);\n\t}\n\tkfree(cpc_ptr);\n\nout_buf_free:\n\tkfree(output.pointer);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(acpi_cppc_processor_probe);\n\n \nvoid acpi_cppc_processor_exit(struct acpi_processor *pr)\n{\n\tstruct cpc_desc *cpc_ptr;\n\tunsigned int i;\n\tvoid __iomem *addr;\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, pr->id);\n\n\tif (pcc_ss_id >= 0 && pcc_data[pcc_ss_id]) {\n\t\tif (pcc_data[pcc_ss_id]->pcc_channel_acquired) {\n\t\t\tpcc_data[pcc_ss_id]->refcount--;\n\t\t\tif (!pcc_data[pcc_ss_id]->refcount) {\n\t\t\t\tpcc_mbox_free_channel(pcc_data[pcc_ss_id]->pcc_channel);\n\t\t\t\tkfree(pcc_data[pcc_ss_id]);\n\t\t\t\tpcc_data[pcc_ss_id] = NULL;\n\t\t\t}\n\t\t}\n\t}\n\n\tcpc_ptr = per_cpu(cpc_desc_ptr, pr->id);\n\tif (!cpc_ptr)\n\t\treturn;\n\n\t \n\tfor (i = 2; i < cpc_ptr->num_entries; i++) {\n\t\taddr = cpc_ptr->cpc_regs[i-2].sys_mem_vaddr;\n\t\tif (addr)\n\t\t\tiounmap(addr);\n\t}\n\n\tkobject_put(&cpc_ptr->kobj);\n\tkfree(cpc_ptr);\n}\nEXPORT_SYMBOL_GPL(acpi_cppc_processor_exit);\n\n \nint __weak cpc_read_ffh(int cpunum, struct cpc_reg *reg, u64 *val)\n{\n\treturn -ENOTSUPP;\n}\n\n \nint __weak cpc_write_ffh(int cpunum, struct cpc_reg *reg, u64 val)\n{\n\treturn -ENOTSUPP;\n}\n\n \n\nstatic int cpc_read(int cpu, struct cpc_register_resource *reg_res, u64 *val)\n{\n\tvoid __iomem *vaddr = NULL;\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpu);\n\tstruct cpc_reg *reg = &reg_res->cpc_entry.reg;\n\n\tif (reg_res->type == ACPI_TYPE_INTEGER) {\n\t\t*val = reg_res->cpc_entry.int_value;\n\t\treturn 0;\n\t}\n\n\t*val = 0;\n\n\tif (reg->space_id == ACPI_ADR_SPACE_SYSTEM_IO) {\n\t\tu32 width = 8 << (reg->access_width - 1);\n\t\tu32 val_u32;\n\t\tacpi_status status;\n\n\t\tstatus = acpi_os_read_port((acpi_io_address)reg->address,\n\t\t\t\t\t   &val_u32, width);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\tpr_debug(\"Error: Failed to read SystemIO port %llx\\n\",\n\t\t\t\t reg->address);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\t*val = val_u32;\n\t\treturn 0;\n\t} else if (reg->space_id == ACPI_ADR_SPACE_PLATFORM_COMM && pcc_ss_id >= 0)\n\t\tvaddr = GET_PCC_VADDR(reg->address, pcc_ss_id);\n\telse if (reg->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)\n\t\tvaddr = reg_res->sys_mem_vaddr;\n\telse if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE)\n\t\treturn cpc_read_ffh(cpu, reg, val);\n\telse\n\t\treturn acpi_os_read_memory((acpi_physical_address)reg->address,\n\t\t\t\tval, reg->bit_width);\n\n\tswitch (reg->bit_width) {\n\tcase 8:\n\t\t*val = readb_relaxed(vaddr);\n\t\tbreak;\n\tcase 16:\n\t\t*val = readw_relaxed(vaddr);\n\t\tbreak;\n\tcase 32:\n\t\t*val = readl_relaxed(vaddr);\n\t\tbreak;\n\tcase 64:\n\t\t*val = readq_relaxed(vaddr);\n\t\tbreak;\n\tdefault:\n\t\tpr_debug(\"Error: Cannot read %u bit width from PCC for ss: %d\\n\",\n\t\t\t reg->bit_width, pcc_ss_id);\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nstatic int cpc_write(int cpu, struct cpc_register_resource *reg_res, u64 val)\n{\n\tint ret_val = 0;\n\tvoid __iomem *vaddr = NULL;\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpu);\n\tstruct cpc_reg *reg = &reg_res->cpc_entry.reg;\n\n\tif (reg->space_id == ACPI_ADR_SPACE_SYSTEM_IO) {\n\t\tu32 width = 8 << (reg->access_width - 1);\n\t\tacpi_status status;\n\n\t\tstatus = acpi_os_write_port((acpi_io_address)reg->address,\n\t\t\t\t\t    (u32)val, width);\n\t\tif (ACPI_FAILURE(status)) {\n\t\t\tpr_debug(\"Error: Failed to write SystemIO port %llx\\n\",\n\t\t\t\t reg->address);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\treturn 0;\n\t} else if (reg->space_id == ACPI_ADR_SPACE_PLATFORM_COMM && pcc_ss_id >= 0)\n\t\tvaddr = GET_PCC_VADDR(reg->address, pcc_ss_id);\n\telse if (reg->space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)\n\t\tvaddr = reg_res->sys_mem_vaddr;\n\telse if (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE)\n\t\treturn cpc_write_ffh(cpu, reg, val);\n\telse\n\t\treturn acpi_os_write_memory((acpi_physical_address)reg->address,\n\t\t\t\tval, reg->bit_width);\n\n\tswitch (reg->bit_width) {\n\tcase 8:\n\t\twriteb_relaxed(val, vaddr);\n\t\tbreak;\n\tcase 16:\n\t\twritew_relaxed(val, vaddr);\n\t\tbreak;\n\tcase 32:\n\t\twritel_relaxed(val, vaddr);\n\t\tbreak;\n\tcase 64:\n\t\twriteq_relaxed(val, vaddr);\n\t\tbreak;\n\tdefault:\n\t\tpr_debug(\"Error: Cannot write %u bit width to PCC for ss: %d\\n\",\n\t\t\t reg->bit_width, pcc_ss_id);\n\t\tret_val = -EFAULT;\n\t\tbreak;\n\t}\n\n\treturn ret_val;\n}\n\nstatic int cppc_get_perf(int cpunum, enum cppc_regs reg_idx, u64 *perf)\n{\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpunum);\n\tstruct cpc_register_resource *reg;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpunum);\n\t\treturn -ENODEV;\n\t}\n\n\treg = &cpc_desc->cpc_regs[reg_idx];\n\n\tif (CPC_IN_PCC(reg)) {\n\t\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpunum);\n\t\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\t\tint ret = 0;\n\n\t\tif (pcc_ss_id < 0)\n\t\t\treturn -EIO;\n\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\n\t\tdown_write(&pcc_ss_data->pcc_lock);\n\n\t\tif (send_pcc_cmd(pcc_ss_id, CMD_READ) >= 0)\n\t\t\tcpc_read(cpunum, reg, perf);\n\t\telse\n\t\t\tret = -EIO;\n\n\t\tup_write(&pcc_ss_data->pcc_lock);\n\n\t\treturn ret;\n\t}\n\n\tcpc_read(cpunum, reg, perf);\n\n\treturn 0;\n}\n\n \nint cppc_get_desired_perf(int cpunum, u64 *desired_perf)\n{\n\treturn cppc_get_perf(cpunum, DESIRED_PERF, desired_perf);\n}\nEXPORT_SYMBOL_GPL(cppc_get_desired_perf);\n\n \nint cppc_get_nominal_perf(int cpunum, u64 *nominal_perf)\n{\n\treturn cppc_get_perf(cpunum, NOMINAL_PERF, nominal_perf);\n}\n\n \nint cppc_get_epp_perf(int cpunum, u64 *epp_perf)\n{\n\treturn cppc_get_perf(cpunum, ENERGY_PERF, epp_perf);\n}\nEXPORT_SYMBOL_GPL(cppc_get_epp_perf);\n\n \nint cppc_get_perf_caps(int cpunum, struct cppc_perf_caps *perf_caps)\n{\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpunum);\n\tstruct cpc_register_resource *highest_reg, *lowest_reg,\n\t\t*lowest_non_linear_reg, *nominal_reg, *guaranteed_reg,\n\t\t*low_freq_reg = NULL, *nom_freq_reg = NULL;\n\tu64 high, low, guaranteed, nom, min_nonlinear, low_f = 0, nom_f = 0;\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpunum);\n\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\tint ret = 0, regs_in_pcc = 0;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpunum);\n\t\treturn -ENODEV;\n\t}\n\n\thighest_reg = &cpc_desc->cpc_regs[HIGHEST_PERF];\n\tlowest_reg = &cpc_desc->cpc_regs[LOWEST_PERF];\n\tlowest_non_linear_reg = &cpc_desc->cpc_regs[LOW_NON_LINEAR_PERF];\n\tnominal_reg = &cpc_desc->cpc_regs[NOMINAL_PERF];\n\tlow_freq_reg = &cpc_desc->cpc_regs[LOWEST_FREQ];\n\tnom_freq_reg = &cpc_desc->cpc_regs[NOMINAL_FREQ];\n\tguaranteed_reg = &cpc_desc->cpc_regs[GUARANTEED_PERF];\n\n\t \n\tif (CPC_IN_PCC(highest_reg) || CPC_IN_PCC(lowest_reg) ||\n\t\tCPC_IN_PCC(lowest_non_linear_reg) || CPC_IN_PCC(nominal_reg) ||\n\t\tCPC_IN_PCC(low_freq_reg) || CPC_IN_PCC(nom_freq_reg)) {\n\t\tif (pcc_ss_id < 0) {\n\t\t\tpr_debug(\"Invalid pcc_ss_id\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\t\tregs_in_pcc = 1;\n\t\tdown_write(&pcc_ss_data->pcc_lock);\n\t\t \n\t\tif (send_pcc_cmd(pcc_ss_id, CMD_READ) < 0) {\n\t\t\tret = -EIO;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\tcpc_read(cpunum, highest_reg, &high);\n\tperf_caps->highest_perf = high;\n\n\tcpc_read(cpunum, lowest_reg, &low);\n\tperf_caps->lowest_perf = low;\n\n\tcpc_read(cpunum, nominal_reg, &nom);\n\tperf_caps->nominal_perf = nom;\n\n\tif (guaranteed_reg->type != ACPI_TYPE_BUFFER  ||\n\t    IS_NULL_REG(&guaranteed_reg->cpc_entry.reg)) {\n\t\tperf_caps->guaranteed_perf = 0;\n\t} else {\n\t\tcpc_read(cpunum, guaranteed_reg, &guaranteed);\n\t\tperf_caps->guaranteed_perf = guaranteed;\n\t}\n\n\tcpc_read(cpunum, lowest_non_linear_reg, &min_nonlinear);\n\tperf_caps->lowest_nonlinear_perf = min_nonlinear;\n\n\tif (!high || !low || !nom || !min_nonlinear)\n\t\tret = -EFAULT;\n\n\t \n\tif (CPC_SUPPORTED(low_freq_reg))\n\t\tcpc_read(cpunum, low_freq_reg, &low_f);\n\n\tif (CPC_SUPPORTED(nom_freq_reg))\n\t\tcpc_read(cpunum, nom_freq_reg, &nom_f);\n\n\tperf_caps->lowest_freq = low_f;\n\tperf_caps->nominal_freq = nom_f;\n\n\nout_err:\n\tif (regs_in_pcc)\n\t\tup_write(&pcc_ss_data->pcc_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(cppc_get_perf_caps);\n\n \nbool cppc_perf_ctrs_in_pcc(void)\n{\n\tint cpu;\n\n\tfor_each_present_cpu(cpu) {\n\t\tstruct cpc_register_resource *ref_perf_reg;\n\t\tstruct cpc_desc *cpc_desc;\n\n\t\tcpc_desc = per_cpu(cpc_desc_ptr, cpu);\n\n\t\tif (CPC_IN_PCC(&cpc_desc->cpc_regs[DELIVERED_CTR]) ||\n\t\t    CPC_IN_PCC(&cpc_desc->cpc_regs[REFERENCE_CTR]) ||\n\t\t    CPC_IN_PCC(&cpc_desc->cpc_regs[CTR_WRAP_TIME]))\n\t\t\treturn true;\n\n\n\t\tref_perf_reg = &cpc_desc->cpc_regs[REFERENCE_PERF];\n\n\t\t \n\t\tif (!CPC_SUPPORTED(ref_perf_reg))\n\t\t\tref_perf_reg = &cpc_desc->cpc_regs[NOMINAL_PERF];\n\n\t\tif (CPC_IN_PCC(ref_perf_reg))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\nEXPORT_SYMBOL_GPL(cppc_perf_ctrs_in_pcc);\n\n \nint cppc_get_perf_ctrs(int cpunum, struct cppc_perf_fb_ctrs *perf_fb_ctrs)\n{\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpunum);\n\tstruct cpc_register_resource *delivered_reg, *reference_reg,\n\t\t*ref_perf_reg, *ctr_wrap_reg;\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpunum);\n\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\tu64 delivered, reference, ref_perf, ctr_wrap_time;\n\tint ret = 0, regs_in_pcc = 0;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpunum);\n\t\treturn -ENODEV;\n\t}\n\n\tdelivered_reg = &cpc_desc->cpc_regs[DELIVERED_CTR];\n\treference_reg = &cpc_desc->cpc_regs[REFERENCE_CTR];\n\tref_perf_reg = &cpc_desc->cpc_regs[REFERENCE_PERF];\n\tctr_wrap_reg = &cpc_desc->cpc_regs[CTR_WRAP_TIME];\n\n\t \n\tif (!CPC_SUPPORTED(ref_perf_reg))\n\t\tref_perf_reg = &cpc_desc->cpc_regs[NOMINAL_PERF];\n\n\t \n\tif (CPC_IN_PCC(delivered_reg) || CPC_IN_PCC(reference_reg) ||\n\t\tCPC_IN_PCC(ctr_wrap_reg) || CPC_IN_PCC(ref_perf_reg)) {\n\t\tif (pcc_ss_id < 0) {\n\t\t\tpr_debug(\"Invalid pcc_ss_id\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\t\tdown_write(&pcc_ss_data->pcc_lock);\n\t\tregs_in_pcc = 1;\n\t\t \n\t\tif (send_pcc_cmd(pcc_ss_id, CMD_READ) < 0) {\n\t\t\tret = -EIO;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\tcpc_read(cpunum, delivered_reg, &delivered);\n\tcpc_read(cpunum, reference_reg, &reference);\n\tcpc_read(cpunum, ref_perf_reg, &ref_perf);\n\n\t \n\tctr_wrap_time = (u64)(~((u64)0));\n\tif (CPC_SUPPORTED(ctr_wrap_reg))\n\t\tcpc_read(cpunum, ctr_wrap_reg, &ctr_wrap_time);\n\n\tif (!delivered || !reference ||\t!ref_perf) {\n\t\tret = -EFAULT;\n\t\tgoto out_err;\n\t}\n\n\tperf_fb_ctrs->delivered = delivered;\n\tperf_fb_ctrs->reference = reference;\n\tperf_fb_ctrs->reference_perf = ref_perf;\n\tperf_fb_ctrs->wraparound_time = ctr_wrap_time;\nout_err:\n\tif (regs_in_pcc)\n\t\tup_write(&pcc_ss_data->pcc_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(cppc_get_perf_ctrs);\n\n \nint cppc_set_epp_perf(int cpu, struct cppc_perf_ctrls *perf_ctrls, bool enable)\n{\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpu);\n\tstruct cpc_register_resource *epp_set_reg;\n\tstruct cpc_register_resource *auto_sel_reg;\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpu);\n\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\tint ret;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpu);\n\t\treturn -ENODEV;\n\t}\n\n\tauto_sel_reg = &cpc_desc->cpc_regs[AUTO_SEL_ENABLE];\n\tepp_set_reg = &cpc_desc->cpc_regs[ENERGY_PERF];\n\n\tif (CPC_IN_PCC(epp_set_reg) || CPC_IN_PCC(auto_sel_reg)) {\n\t\tif (pcc_ss_id < 0) {\n\t\t\tpr_debug(\"Invalid pcc_ss_id for CPU:%d\\n\", cpu);\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tif (CPC_SUPPORTED(auto_sel_reg)) {\n\t\t\tret = cpc_write(cpu, auto_sel_reg, enable);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tif (CPC_SUPPORTED(epp_set_reg)) {\n\t\t\tret = cpc_write(cpu, epp_set_reg, perf_ctrls->energy_perf);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\n\t\tdown_write(&pcc_ss_data->pcc_lock);\n\t\t \n\t\tret = send_pcc_cmd(pcc_ss_id, CMD_WRITE);\n\t\tup_write(&pcc_ss_data->pcc_lock);\n\t} else {\n\t\tret = -ENOTSUPP;\n\t\tpr_debug(\"_CPC in PCC is not supported\\n\");\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(cppc_set_epp_perf);\n\n \nint cppc_get_auto_sel_caps(int cpunum, struct cppc_perf_caps *perf_caps)\n{\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpunum);\n\tstruct cpc_register_resource *auto_sel_reg;\n\tu64  auto_sel;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpunum);\n\t\treturn -ENODEV;\n\t}\n\n\tauto_sel_reg = &cpc_desc->cpc_regs[AUTO_SEL_ENABLE];\n\n\tif (!CPC_SUPPORTED(auto_sel_reg))\n\t\tpr_warn_once(\"Autonomous mode is not unsupported!\\n\");\n\n\tif (CPC_IN_PCC(auto_sel_reg)) {\n\t\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpunum);\n\t\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\t\tint ret = 0;\n\n\t\tif (pcc_ss_id < 0)\n\t\t\treturn -ENODEV;\n\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\n\t\tdown_write(&pcc_ss_data->pcc_lock);\n\n\t\tif (send_pcc_cmd(pcc_ss_id, CMD_READ) >= 0) {\n\t\t\tcpc_read(cpunum, auto_sel_reg, &auto_sel);\n\t\t\tperf_caps->auto_sel = (bool)auto_sel;\n\t\t} else {\n\t\t\tret = -EIO;\n\t\t}\n\n\t\tup_write(&pcc_ss_data->pcc_lock);\n\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(cppc_get_auto_sel_caps);\n\n \nint cppc_set_auto_sel(int cpu, bool enable)\n{\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpu);\n\tstruct cpc_register_resource *auto_sel_reg;\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpu);\n\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\tint ret = -EINVAL;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpu);\n\t\treturn -ENODEV;\n\t}\n\n\tauto_sel_reg = &cpc_desc->cpc_regs[AUTO_SEL_ENABLE];\n\n\tif (CPC_IN_PCC(auto_sel_reg)) {\n\t\tif (pcc_ss_id < 0) {\n\t\t\tpr_debug(\"Invalid pcc_ss_id\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tif (CPC_SUPPORTED(auto_sel_reg)) {\n\t\t\tret = cpc_write(cpu, auto_sel_reg, enable);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\n\t\tdown_write(&pcc_ss_data->pcc_lock);\n\t\t \n\t\tret = send_pcc_cmd(pcc_ss_id, CMD_WRITE);\n\t\tup_write(&pcc_ss_data->pcc_lock);\n\t} else {\n\t\tret = -ENOTSUPP;\n\t\tpr_debug(\"_CPC in PCC is not supported\\n\");\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(cppc_set_auto_sel);\n\n \nint cppc_set_enable(int cpu, bool enable)\n{\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpu);\n\tstruct cpc_register_resource *enable_reg;\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpu);\n\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\tint ret = -EINVAL;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpu);\n\t\treturn -EINVAL;\n\t}\n\n\tenable_reg = &cpc_desc->cpc_regs[ENABLE];\n\n\tif (CPC_IN_PCC(enable_reg)) {\n\n\t\tif (pcc_ss_id < 0)\n\t\t\treturn -EIO;\n\n\t\tret = cpc_write(cpu, enable_reg, enable);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\n\t\tdown_write(&pcc_ss_data->pcc_lock);\n\t\t \n\t\tret = send_pcc_cmd(pcc_ss_id, CMD_WRITE);\n\t\tup_write(&pcc_ss_data->pcc_lock);\n\t\treturn ret;\n\t}\n\n\treturn cpc_write(cpu, enable_reg, enable);\n}\nEXPORT_SYMBOL_GPL(cppc_set_enable);\n\n \nint cppc_set_perf(int cpu, struct cppc_perf_ctrls *perf_ctrls)\n{\n\tstruct cpc_desc *cpc_desc = per_cpu(cpc_desc_ptr, cpu);\n\tstruct cpc_register_resource *desired_reg, *min_perf_reg, *max_perf_reg;\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpu);\n\tstruct cppc_pcc_data *pcc_ss_data = NULL;\n\tint ret = 0;\n\n\tif (!cpc_desc) {\n\t\tpr_debug(\"No CPC descriptor for CPU:%d\\n\", cpu);\n\t\treturn -ENODEV;\n\t}\n\n\tdesired_reg = &cpc_desc->cpc_regs[DESIRED_PERF];\n\tmin_perf_reg = &cpc_desc->cpc_regs[MIN_PERF];\n\tmax_perf_reg = &cpc_desc->cpc_regs[MAX_PERF];\n\n\t \n\tif (CPC_IN_PCC(desired_reg) || CPC_IN_PCC(min_perf_reg) || CPC_IN_PCC(max_perf_reg)) {\n\t\tif (pcc_ss_id < 0) {\n\t\t\tpr_debug(\"Invalid pcc_ss_id\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tpcc_ss_data = pcc_data[pcc_ss_id];\n\t\tdown_read(&pcc_ss_data->pcc_lock);  \n\t\tif (pcc_ss_data->platform_owns_pcc) {\n\t\t\tret = check_pcc_chan(pcc_ss_id, false);\n\t\t\tif (ret) {\n\t\t\t\tup_read(&pcc_ss_data->pcc_lock);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t\t \n\t\tpcc_ss_data->pending_pcc_write_cmd = true;\n\t\tcpc_desc->write_cmd_id = pcc_ss_data->pcc_write_cnt;\n\t\tcpc_desc->write_cmd_status = 0;\n\t}\n\n\tcpc_write(cpu, desired_reg, perf_ctrls->desired_perf);\n\n\t \n\tif (perf_ctrls->min_perf)\n\t\tcpc_write(cpu, min_perf_reg, perf_ctrls->min_perf);\n\tif (perf_ctrls->max_perf)\n\t\tcpc_write(cpu, max_perf_reg, perf_ctrls->max_perf);\n\n\tif (CPC_IN_PCC(desired_reg) || CPC_IN_PCC(min_perf_reg) || CPC_IN_PCC(max_perf_reg))\n\t\tup_read(&pcc_ss_data->pcc_lock);\t \n\t \n\tif (CPC_IN_PCC(desired_reg) || CPC_IN_PCC(min_perf_reg) || CPC_IN_PCC(max_perf_reg)) {\n\t\tif (down_write_trylock(&pcc_ss_data->pcc_lock)) { \n\t\t\t \n\t\t\tif (pcc_ss_data->pending_pcc_write_cmd)\n\t\t\t\tsend_pcc_cmd(pcc_ss_id, CMD_WRITE);\n\t\t\tup_write(&pcc_ss_data->pcc_lock);\t \n\t\t} else\n\t\t\t \n\t\t\twait_event(pcc_ss_data->pcc_write_wait_q,\n\t\t\t\t   cpc_desc->write_cmd_id != pcc_ss_data->pcc_write_cnt);\n\n\t\t \n\t\tret = cpc_desc->write_cmd_status;\n\t}\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(cppc_set_perf);\n\n \nunsigned int cppc_get_transition_latency(int cpu_num)\n{\n\t \n\tunsigned int latency_ns = 0;\n\tstruct cpc_desc *cpc_desc;\n\tstruct cpc_register_resource *desired_reg;\n\tint pcc_ss_id = per_cpu(cpu_pcc_subspace_idx, cpu_num);\n\tstruct cppc_pcc_data *pcc_ss_data;\n\n\tcpc_desc = per_cpu(cpc_desc_ptr, cpu_num);\n\tif (!cpc_desc)\n\t\treturn CPUFREQ_ETERNAL;\n\n\tdesired_reg = &cpc_desc->cpc_regs[DESIRED_PERF];\n\tif (CPC_IN_SYSTEM_MEMORY(desired_reg) || CPC_IN_SYSTEM_IO(desired_reg))\n\t\treturn 0;\n\telse if (!CPC_IN_PCC(desired_reg))\n\t\treturn CPUFREQ_ETERNAL;\n\n\tif (pcc_ss_id < 0)\n\t\treturn CPUFREQ_ETERNAL;\n\n\tpcc_ss_data = pcc_data[pcc_ss_id];\n\tif (pcc_ss_data->pcc_mpar)\n\t\tlatency_ns = 60 * (1000 * 1000 * 1000 / pcc_ss_data->pcc_mpar);\n\n\tlatency_ns = max(latency_ns, pcc_ss_data->pcc_nominal * 1000);\n\tlatency_ns = max(latency_ns, pcc_ss_data->pcc_mrtt * 1000);\n\n\treturn latency_ns;\n}\nEXPORT_SYMBOL_GPL(cppc_get_transition_latency);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}