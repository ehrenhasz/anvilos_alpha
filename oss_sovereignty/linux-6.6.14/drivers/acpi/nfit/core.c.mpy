{
  "module_name": "core.c",
  "hash_id": "a8cef988a064d0bdd4a550ac3183e936b60e66fc7658bf6dfdf2a5aa35e2f96e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/acpi/nfit/core.c",
  "human_readable_source": "\n \n#include <linux/list_sort.h>\n#include <linux/libnvdimm.h>\n#include <linux/module.h>\n#include <linux/nospec.h>\n#include <linux/mutex.h>\n#include <linux/ndctl.h>\n#include <linux/sysfs.h>\n#include <linux/delay.h>\n#include <linux/list.h>\n#include <linux/acpi.h>\n#include <linux/sort.h>\n#include <linux/io.h>\n#include <linux/nd.h>\n#include <asm/cacheflush.h>\n#include <acpi/nfit.h>\n#include \"intel.h\"\n#include \"nfit.h\"\n\n \n#include <linux/io-64-nonatomic-hi-lo.h>\n\nstatic bool force_enable_dimms;\nmodule_param(force_enable_dimms, bool, S_IRUGO|S_IWUSR);\nMODULE_PARM_DESC(force_enable_dimms, \"Ignore _STA (ACPI DIMM device) status\");\n\nstatic bool disable_vendor_specific;\nmodule_param(disable_vendor_specific, bool, S_IRUGO);\nMODULE_PARM_DESC(disable_vendor_specific,\n\t\t\"Limit commands to the publicly specified set\");\n\nstatic unsigned long override_dsm_mask;\nmodule_param(override_dsm_mask, ulong, S_IRUGO);\nMODULE_PARM_DESC(override_dsm_mask, \"Bitmask of allowed NVDIMM DSM functions\");\n\nstatic int default_dsm_family = -1;\nmodule_param(default_dsm_family, int, S_IRUGO);\nMODULE_PARM_DESC(default_dsm_family,\n\t\t\"Try this DSM type first when identifying NVDIMM family\");\n\nstatic bool no_init_ars;\nmodule_param(no_init_ars, bool, 0644);\nMODULE_PARM_DESC(no_init_ars, \"Skip ARS run at nfit init time\");\n\nstatic bool force_labels;\nmodule_param(force_labels, bool, 0444);\nMODULE_PARM_DESC(force_labels, \"Opt-in to labels despite missing methods\");\n\nLIST_HEAD(acpi_descs);\nDEFINE_MUTEX(acpi_desc_lock);\n\nstatic struct workqueue_struct *nfit_wq;\n\nstruct nfit_table_prev {\n\tstruct list_head spas;\n\tstruct list_head memdevs;\n\tstruct list_head dcrs;\n\tstruct list_head bdws;\n\tstruct list_head idts;\n\tstruct list_head flushes;\n};\n\nstatic guid_t nfit_uuid[NFIT_UUID_MAX];\n\nconst guid_t *to_nfit_uuid(enum nfit_uuids id)\n{\n\treturn &nfit_uuid[id];\n}\nEXPORT_SYMBOL(to_nfit_uuid);\n\nstatic const guid_t *to_nfit_bus_uuid(int family)\n{\n\tif (WARN_ONCE(family == NVDIMM_BUS_FAMILY_NFIT,\n\t\t\t\"only secondary bus families can be translated\\n\"))\n\t\treturn NULL;\n\t \n\treturn to_nfit_uuid(family + NVDIMM_FAMILY_MAX);\n}\n\nstatic struct acpi_device *to_acpi_dev(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\n\t \n\tif (!nd_desc->provider_name\n\t\t\t|| strcmp(nd_desc->provider_name, \"ACPI.NFIT\") != 0)\n\t\treturn NULL;\n\n\treturn to_acpi_device(acpi_desc->dev);\n}\n\nstatic int xlat_bus_status(void *buf, unsigned int cmd, u32 status)\n{\n\tstruct nd_cmd_clear_error *clear_err;\n\tstruct nd_cmd_ars_status *ars_status;\n\tu16 flags;\n\n\tswitch (cmd) {\n\tcase ND_CMD_ARS_CAP:\n\t\tif ((status & 0xffff) == NFIT_ARS_CAP_NONE)\n\t\t\treturn -ENOTTY;\n\n\t\t \n\t\tif (status & 0xffff)\n\t\t\treturn -EIO;\n\n\t\t \n\t\tflags = ND_ARS_PERSISTENT | ND_ARS_VOLATILE;\n\t\tif ((status >> 16 & flags) == 0)\n\t\t\treturn -ENOTTY;\n\t\treturn 0;\n\tcase ND_CMD_ARS_START:\n\t\t \n\t\tif ((status & 0xffff) == NFIT_ARS_START_BUSY)\n\t\t\treturn -EBUSY;\n\n\t\t \n\t\tif (status & 0xffff)\n\t\t\treturn -EIO;\n\t\treturn 0;\n\tcase ND_CMD_ARS_STATUS:\n\t\tars_status = buf;\n\t\t \n\t\tif (status & 0xffff)\n\t\t\treturn -EIO;\n\t\t \n\t\tif (status == NFIT_ARS_STATUS_DONE)\n\t\t\treturn 0;\n\n\t\t \n\t\tif (status == NFIT_ARS_STATUS_BUSY)\n\t\t\treturn -EBUSY;\n\n\t\t \n\t\tif (status == NFIT_ARS_STATUS_NONE)\n\t\t\treturn -EAGAIN;\n\n\t\t \n\t\tif (status == NFIT_ARS_STATUS_INTR) {\n\t\t\tif (ars_status->out_length >= 40 && (ars_status->flags\n\t\t\t\t\t\t& NFIT_ARS_F_OVERFLOW))\n\t\t\t\treturn -ENOSPC;\n\t\t\treturn 0;\n\t\t}\n\n\t\t \n\t\tif (status >> 16)\n\t\t\treturn -EIO;\n\t\treturn 0;\n\tcase ND_CMD_CLEAR_ERROR:\n\t\tclear_err = buf;\n\t\tif (status & 0xffff)\n\t\t\treturn -EIO;\n\t\tif (!clear_err->cleared)\n\t\t\treturn -EIO;\n\t\tif (clear_err->length > clear_err->cleared)\n\t\t\treturn clear_err->cleared;\n\t\treturn 0;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tif (status)\n\t\treturn -EIO;\n\treturn 0;\n}\n\n#define ACPI_LABELS_LOCKED 3\n\nstatic int xlat_nvdimm_status(struct nvdimm *nvdimm, void *buf, unsigned int cmd,\n\t\tu32 status)\n{\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\tswitch (cmd) {\n\tcase ND_CMD_GET_CONFIG_SIZE:\n\t\t \n\t\tif (test_bit(NFIT_MEM_LSR, &nfit_mem->flags))\n\t\t\tbreak;\n\n\t\tif (status >> 16 & ND_CONFIG_LOCKED)\n\t\t\treturn -EACCES;\n\t\tbreak;\n\tcase ND_CMD_GET_CONFIG_DATA:\n\t\tif (test_bit(NFIT_MEM_LSR, &nfit_mem->flags)\n\t\t\t\t&& status == ACPI_LABELS_LOCKED)\n\t\t\treturn -EACCES;\n\t\tbreak;\n\tcase ND_CMD_SET_CONFIG_DATA:\n\t\tif (test_bit(NFIT_MEM_LSW, &nfit_mem->flags)\n\t\t\t\t&& status == ACPI_LABELS_LOCKED)\n\t\t\treturn -EACCES;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tif (status)\n\t\treturn -EIO;\n\treturn 0;\n}\n\nstatic int xlat_status(struct nvdimm *nvdimm, void *buf, unsigned int cmd,\n\t\tu32 status)\n{\n\tif (!nvdimm)\n\t\treturn xlat_bus_status(buf, cmd, status);\n\treturn xlat_nvdimm_status(nvdimm, buf, cmd, status);\n}\n\n \nstatic union acpi_object *pkg_to_buf(union acpi_object *pkg)\n{\n\tint i;\n\tvoid *dst;\n\tsize_t size = 0;\n\tunion acpi_object *buf = NULL;\n\n\tif (pkg->type != ACPI_TYPE_PACKAGE) {\n\t\tWARN_ONCE(1, \"BIOS bug, unexpected element type: %d\\n\",\n\t\t\t\tpkg->type);\n\t\tgoto err;\n\t}\n\n\tfor (i = 0; i < pkg->package.count; i++) {\n\t\tunion acpi_object *obj = &pkg->package.elements[i];\n\n\t\tif (obj->type == ACPI_TYPE_INTEGER)\n\t\t\tsize += 4;\n\t\telse if (obj->type == ACPI_TYPE_BUFFER)\n\t\t\tsize += obj->buffer.length;\n\t\telse {\n\t\t\tWARN_ONCE(1, \"BIOS bug, unexpected element type: %d\\n\",\n\t\t\t\t\tobj->type);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tbuf = ACPI_ALLOCATE(sizeof(*buf) + size);\n\tif (!buf)\n\t\tgoto err;\n\n\tdst = buf + 1;\n\tbuf->type = ACPI_TYPE_BUFFER;\n\tbuf->buffer.length = size;\n\tbuf->buffer.pointer = dst;\n\tfor (i = 0; i < pkg->package.count; i++) {\n\t\tunion acpi_object *obj = &pkg->package.elements[i];\n\n\t\tif (obj->type == ACPI_TYPE_INTEGER) {\n\t\t\tmemcpy(dst, &obj->integer.value, 4);\n\t\t\tdst += 4;\n\t\t} else if (obj->type == ACPI_TYPE_BUFFER) {\n\t\t\tmemcpy(dst, obj->buffer.pointer, obj->buffer.length);\n\t\t\tdst += obj->buffer.length;\n\t\t}\n\t}\nerr:\n\tACPI_FREE(pkg);\n\treturn buf;\n}\n\nstatic union acpi_object *int_to_buf(union acpi_object *integer)\n{\n\tunion acpi_object *buf = NULL;\n\tvoid *dst = NULL;\n\n\tif (integer->type != ACPI_TYPE_INTEGER) {\n\t\tWARN_ONCE(1, \"BIOS bug, unexpected element type: %d\\n\",\n\t\t\t\tinteger->type);\n\t\tgoto err;\n\t}\n\n\tbuf = ACPI_ALLOCATE(sizeof(*buf) + 4);\n\tif (!buf)\n\t\tgoto err;\n\n\tdst = buf + 1;\n\tbuf->type = ACPI_TYPE_BUFFER;\n\tbuf->buffer.length = 4;\n\tbuf->buffer.pointer = dst;\n\tmemcpy(dst, &integer->integer.value, 4);\nerr:\n\tACPI_FREE(integer);\n\treturn buf;\n}\n\nstatic union acpi_object *acpi_label_write(acpi_handle handle, u32 offset,\n\t\tu32 len, void *data)\n{\n\tacpi_status rc;\n\tstruct acpi_buffer buf = { ACPI_ALLOCATE_BUFFER, NULL };\n\tstruct acpi_object_list input = {\n\t\t.count = 3,\n\t\t.pointer = (union acpi_object []) {\n\t\t\t[0] = {\n\t\t\t\t.integer.type = ACPI_TYPE_INTEGER,\n\t\t\t\t.integer.value = offset,\n\t\t\t},\n\t\t\t[1] = {\n\t\t\t\t.integer.type = ACPI_TYPE_INTEGER,\n\t\t\t\t.integer.value = len,\n\t\t\t},\n\t\t\t[2] = {\n\t\t\t\t.buffer.type = ACPI_TYPE_BUFFER,\n\t\t\t\t.buffer.pointer = data,\n\t\t\t\t.buffer.length = len,\n\t\t\t},\n\t\t},\n\t};\n\n\trc = acpi_evaluate_object(handle, \"_LSW\", &input, &buf);\n\tif (ACPI_FAILURE(rc))\n\t\treturn NULL;\n\treturn int_to_buf(buf.pointer);\n}\n\nstatic union acpi_object *acpi_label_read(acpi_handle handle, u32 offset,\n\t\tu32 len)\n{\n\tacpi_status rc;\n\tstruct acpi_buffer buf = { ACPI_ALLOCATE_BUFFER, NULL };\n\tstruct acpi_object_list input = {\n\t\t.count = 2,\n\t\t.pointer = (union acpi_object []) {\n\t\t\t[0] = {\n\t\t\t\t.integer.type = ACPI_TYPE_INTEGER,\n\t\t\t\t.integer.value = offset,\n\t\t\t},\n\t\t\t[1] = {\n\t\t\t\t.integer.type = ACPI_TYPE_INTEGER,\n\t\t\t\t.integer.value = len,\n\t\t\t},\n\t\t},\n\t};\n\n\trc = acpi_evaluate_object(handle, \"_LSR\", &input, &buf);\n\tif (ACPI_FAILURE(rc))\n\t\treturn NULL;\n\treturn pkg_to_buf(buf.pointer);\n}\n\nstatic union acpi_object *acpi_label_info(acpi_handle handle)\n{\n\tacpi_status rc;\n\tstruct acpi_buffer buf = { ACPI_ALLOCATE_BUFFER, NULL };\n\n\trc = acpi_evaluate_object(handle, \"_LSI\", NULL, &buf);\n\tif (ACPI_FAILURE(rc))\n\t\treturn NULL;\n\treturn pkg_to_buf(buf.pointer);\n}\n\nstatic u8 nfit_dsm_revid(unsigned family, unsigned func)\n{\n\tstatic const u8 revid_table[NVDIMM_FAMILY_MAX+1][NVDIMM_CMD_MAX+1] = {\n\t\t[NVDIMM_FAMILY_INTEL] = {\n\t\t\t[NVDIMM_INTEL_GET_MODES ...\n\t\t\t\tNVDIMM_INTEL_FW_ACTIVATE_ARM] = 2,\n\t\t},\n\t};\n\tu8 id;\n\n\tif (family > NVDIMM_FAMILY_MAX)\n\t\treturn 0;\n\tif (func > NVDIMM_CMD_MAX)\n\t\treturn 0;\n\tid = revid_table[family][func];\n\tif (id == 0)\n\t\treturn 1;  \n\treturn id;\n}\n\nstatic bool payload_dumpable(struct nvdimm *nvdimm, unsigned int func)\n{\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\tif (nfit_mem && nfit_mem->family == NVDIMM_FAMILY_INTEL\n\t\t\t&& func >= NVDIMM_INTEL_GET_SECURITY_STATE\n\t\t\t&& func <= NVDIMM_INTEL_MASTER_SECURE_ERASE)\n\t\treturn IS_ENABLED(CONFIG_NFIT_SECURITY_DEBUG);\n\treturn true;\n}\n\nstatic int cmd_to_func(struct nfit_mem *nfit_mem, unsigned int cmd,\n\t\tstruct nd_cmd_pkg *call_pkg, int *family)\n{\n\tif (call_pkg) {\n\t\tint i;\n\n\t\tif (nfit_mem && nfit_mem->family != call_pkg->nd_family)\n\t\t\treturn -ENOTTY;\n\n\t\tfor (i = 0; i < ARRAY_SIZE(call_pkg->nd_reserved2); i++)\n\t\t\tif (call_pkg->nd_reserved2[i])\n\t\t\t\treturn -EINVAL;\n\t\t*family = call_pkg->nd_family;\n\t\treturn call_pkg->nd_command;\n\t}\n\n\t \n\tif (!nfit_mem)\n\t\treturn cmd;\n\n\t \n\tif (nfit_mem->family == NVDIMM_FAMILY_INTEL)\n\t\treturn cmd;\n\n\t \n\treturn 0;\n}\n\nint acpi_nfit_ctl(struct nvdimm_bus_descriptor *nd_desc, struct nvdimm *nvdimm,\n\t\tunsigned int cmd, void *buf, unsigned int buf_len, int *cmd_rc)\n{\n\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\tunion acpi_object in_obj, in_buf, *out_obj;\n\tconst struct nd_cmd_desc *desc = NULL;\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nd_cmd_pkg *call_pkg = NULL;\n\tconst char *cmd_name, *dimm_name;\n\tunsigned long cmd_mask, dsm_mask;\n\tu32 offset, fw_status = 0;\n\tacpi_handle handle;\n\tconst guid_t *guid;\n\tint func, rc, i;\n\tint family = 0;\n\n\tif (cmd_rc)\n\t\t*cmd_rc = -EINVAL;\n\n\tif (cmd == ND_CMD_CALL)\n\t\tcall_pkg = buf;\n\tfunc = cmd_to_func(nfit_mem, cmd, call_pkg, &family);\n\tif (func < 0)\n\t\treturn func;\n\n\tif (nvdimm) {\n\t\tstruct acpi_device *adev = nfit_mem->adev;\n\n\t\tif (!adev)\n\t\t\treturn -ENOTTY;\n\n\t\tdimm_name = nvdimm_name(nvdimm);\n\t\tcmd_name = nvdimm_cmd_name(cmd);\n\t\tcmd_mask = nvdimm_cmd_mask(nvdimm);\n\t\tdsm_mask = nfit_mem->dsm_mask;\n\t\tdesc = nd_cmd_dimm_desc(cmd);\n\t\tguid = to_nfit_uuid(nfit_mem->family);\n\t\thandle = adev->handle;\n\t} else {\n\t\tstruct acpi_device *adev = to_acpi_dev(acpi_desc);\n\n\t\tcmd_name = nvdimm_bus_cmd_name(cmd);\n\t\tcmd_mask = nd_desc->cmd_mask;\n\t\tif (cmd == ND_CMD_CALL && call_pkg->nd_family) {\n\t\t\tfamily = call_pkg->nd_family;\n\t\t\tif (family > NVDIMM_BUS_FAMILY_MAX ||\n\t\t\t    !test_bit(family, &nd_desc->bus_family_mask))\n\t\t\t\treturn -EINVAL;\n\t\t\tfamily = array_index_nospec(family,\n\t\t\t\t\t\t    NVDIMM_BUS_FAMILY_MAX + 1);\n\t\t\tdsm_mask = acpi_desc->family_dsm_mask[family];\n\t\t\tguid = to_nfit_bus_uuid(family);\n\t\t} else {\n\t\t\tdsm_mask = acpi_desc->bus_dsm_mask;\n\t\t\tguid = to_nfit_uuid(NFIT_DEV_BUS);\n\t\t}\n\t\tdesc = nd_cmd_bus_desc(cmd);\n\t\thandle = adev->handle;\n\t\tdimm_name = \"bus\";\n\t}\n\n\tif (!desc || (cmd && (desc->out_num + desc->in_num == 0)))\n\t\treturn -ENOTTY;\n\n\t \n\tif (cmd == ND_CMD_CALL &&\n\t    (func > NVDIMM_CMD_MAX || !test_bit(func, &dsm_mask)))\n\t\treturn -ENOTTY;\n\telse if (!test_bit(cmd, &cmd_mask))\n\t\treturn -ENOTTY;\n\n\tin_obj.type = ACPI_TYPE_PACKAGE;\n\tin_obj.package.count = 1;\n\tin_obj.package.elements = &in_buf;\n\tin_buf.type = ACPI_TYPE_BUFFER;\n\tin_buf.buffer.pointer = buf;\n\tin_buf.buffer.length = 0;\n\n\t \n\tfor (i = 0; i < desc->in_num; i++)\n\t\tin_buf.buffer.length += nd_cmd_in_size(nvdimm, cmd, desc,\n\t\t\t\ti, buf);\n\n\tif (call_pkg) {\n\t\t \n\t\tin_buf.buffer.pointer = (void *) &call_pkg->nd_payload;\n\t\tin_buf.buffer.length = call_pkg->nd_size_in;\n\t}\n\n\tdev_dbg(dev, \"%s cmd: %d: family: %d func: %d input length: %d\\n\",\n\t\tdimm_name, cmd, family, func, in_buf.buffer.length);\n\tif (payload_dumpable(nvdimm, func))\n\t\tprint_hex_dump_debug(\"nvdimm in  \", DUMP_PREFIX_OFFSET, 4, 4,\n\t\t\t\tin_buf.buffer.pointer,\n\t\t\t\tmin_t(u32, 256, in_buf.buffer.length), true);\n\n\t \n\tif (nvdimm && cmd == ND_CMD_GET_CONFIG_SIZE\n\t\t\t&& test_bit(NFIT_MEM_LSR, &nfit_mem->flags))\n\t\tout_obj = acpi_label_info(handle);\n\telse if (nvdimm && cmd == ND_CMD_GET_CONFIG_DATA\n\t\t\t&& test_bit(NFIT_MEM_LSR, &nfit_mem->flags)) {\n\t\tstruct nd_cmd_get_config_data_hdr *p = buf;\n\n\t\tout_obj = acpi_label_read(handle, p->in_offset, p->in_length);\n\t} else if (nvdimm && cmd == ND_CMD_SET_CONFIG_DATA\n\t\t\t&& test_bit(NFIT_MEM_LSW, &nfit_mem->flags)) {\n\t\tstruct nd_cmd_set_config_hdr *p = buf;\n\n\t\tout_obj = acpi_label_write(handle, p->in_offset, p->in_length,\n\t\t\t\tp->in_buf);\n\t} else {\n\t\tu8 revid;\n\n\t\tif (nvdimm)\n\t\t\trevid = nfit_dsm_revid(nfit_mem->family, func);\n\t\telse\n\t\t\trevid = 1;\n\t\tout_obj = acpi_evaluate_dsm(handle, guid, revid, func, &in_obj);\n\t}\n\n\tif (!out_obj) {\n\t\tdev_dbg(dev, \"%s _DSM failed cmd: %s\\n\", dimm_name, cmd_name);\n\t\treturn -EINVAL;\n\t}\n\n\tif (out_obj->type != ACPI_TYPE_BUFFER) {\n\t\tdev_dbg(dev, \"%s unexpected output object type cmd: %s type: %d\\n\",\n\t\t\t\tdimm_name, cmd_name, out_obj->type);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tdev_dbg(dev, \"%s cmd: %s output length: %d\\n\", dimm_name,\n\t\t\tcmd_name, out_obj->buffer.length);\n\tprint_hex_dump_debug(cmd_name, DUMP_PREFIX_OFFSET, 4, 4,\n\t\t\tout_obj->buffer.pointer,\n\t\t\tmin_t(u32, 128, out_obj->buffer.length), true);\n\n\tif (call_pkg) {\n\t\tcall_pkg->nd_fw_size = out_obj->buffer.length;\n\t\tmemcpy(call_pkg->nd_payload + call_pkg->nd_size_in,\n\t\t\tout_obj->buffer.pointer,\n\t\t\tmin(call_pkg->nd_fw_size, call_pkg->nd_size_out));\n\n\t\tACPI_FREE(out_obj);\n\t\t \n\t\tif (cmd_rc)\n\t\t\t*cmd_rc = 0;\n\t\treturn 0;\n\t}\n\n\tfor (i = 0, offset = 0; i < desc->out_num; i++) {\n\t\tu32 out_size = nd_cmd_out_size(nvdimm, cmd, desc, i, buf,\n\t\t\t\t(u32 *) out_obj->buffer.pointer,\n\t\t\t\tout_obj->buffer.length - offset);\n\n\t\tif (offset + out_size > out_obj->buffer.length) {\n\t\t\tdev_dbg(dev, \"%s output object underflow cmd: %s field: %d\\n\",\n\t\t\t\t\tdimm_name, cmd_name, i);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (in_buf.buffer.length + offset + out_size > buf_len) {\n\t\t\tdev_dbg(dev, \"%s output overrun cmd: %s field: %d\\n\",\n\t\t\t\t\tdimm_name, cmd_name, i);\n\t\t\trc = -ENXIO;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(buf + in_buf.buffer.length + offset,\n\t\t\t\tout_obj->buffer.pointer + offset, out_size);\n\t\toffset += out_size;\n\t}\n\n\t \n\tif (i >= 1 && ((!nvdimm && cmd >= ND_CMD_ARS_CAP\n\t\t\t\t\t&& cmd <= ND_CMD_CLEAR_ERROR)\n\t\t\t\t|| (nvdimm && cmd >= ND_CMD_SMART\n\t\t\t\t\t&& cmd <= ND_CMD_VENDOR)))\n\t\tfw_status = *(u32 *) out_obj->buffer.pointer;\n\n\tif (offset + in_buf.buffer.length < buf_len) {\n\t\tif (i >= 1) {\n\t\t\t \n\t\t\trc = buf_len - offset - in_buf.buffer.length;\n\t\t\tif (cmd_rc)\n\t\t\t\t*cmd_rc = xlat_status(nvdimm, buf, cmd,\n\t\t\t\t\t\tfw_status);\n\t\t} else {\n\t\t\tdev_err(dev, \"%s:%s underrun cmd: %s buf_len: %d out_len: %d\\n\",\n\t\t\t\t\t__func__, dimm_name, cmd_name, buf_len,\n\t\t\t\t\toffset);\n\t\t\trc = -ENXIO;\n\t\t}\n\t} else {\n\t\trc = 0;\n\t\tif (cmd_rc)\n\t\t\t*cmd_rc = xlat_status(nvdimm, buf, cmd, fw_status);\n\t}\n\n out:\n\tACPI_FREE(out_obj);\n\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(acpi_nfit_ctl);\n\nstatic const char *spa_type_name(u16 type)\n{\n\tstatic const char *to_name[] = {\n\t\t[NFIT_SPA_VOLATILE] = \"volatile\",\n\t\t[NFIT_SPA_PM] = \"pmem\",\n\t\t[NFIT_SPA_DCR] = \"dimm-control-region\",\n\t\t[NFIT_SPA_BDW] = \"block-data-window\",\n\t\t[NFIT_SPA_VDISK] = \"volatile-disk\",\n\t\t[NFIT_SPA_VCD] = \"volatile-cd\",\n\t\t[NFIT_SPA_PDISK] = \"persistent-disk\",\n\t\t[NFIT_SPA_PCD] = \"persistent-cd\",\n\n\t};\n\n\tif (type > NFIT_SPA_PCD)\n\t\treturn \"unknown\";\n\n\treturn to_name[type];\n}\n\nint nfit_spa_type(struct acpi_nfit_system_address *spa)\n{\n\tguid_t guid;\n\tint i;\n\n\timport_guid(&guid, spa->range_guid);\n\tfor (i = 0; i < NFIT_UUID_MAX; i++)\n\t\tif (guid_equal(to_nfit_uuid(i), &guid))\n\t\t\treturn i;\n\treturn -1;\n}\n\nstatic size_t sizeof_spa(struct acpi_nfit_system_address *spa)\n{\n\tif (spa->flags & ACPI_NFIT_LOCATION_COOKIE_VALID)\n\t\treturn sizeof(*spa);\n\treturn sizeof(*spa) - 8;\n}\n\nstatic bool add_spa(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev,\n\t\tstruct acpi_nfit_system_address *spa)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_spa *nfit_spa;\n\n\tif (spa->header.length != sizeof_spa(spa))\n\t\treturn false;\n\n\tlist_for_each_entry(nfit_spa, &prev->spas, list) {\n\t\tif (memcmp(nfit_spa->spa, spa, sizeof_spa(spa)) == 0) {\n\t\t\tlist_move_tail(&nfit_spa->list, &acpi_desc->spas);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tnfit_spa = devm_kzalloc(dev, sizeof(*nfit_spa) + sizeof_spa(spa),\n\t\t\tGFP_KERNEL);\n\tif (!nfit_spa)\n\t\treturn false;\n\tINIT_LIST_HEAD(&nfit_spa->list);\n\tmemcpy(nfit_spa->spa, spa, sizeof_spa(spa));\n\tlist_add_tail(&nfit_spa->list, &acpi_desc->spas);\n\tdev_dbg(dev, \"spa index: %d type: %s\\n\",\n\t\t\tspa->range_index,\n\t\t\tspa_type_name(nfit_spa_type(spa)));\n\treturn true;\n}\n\nstatic bool add_memdev(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev,\n\t\tstruct acpi_nfit_memory_map *memdev)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_memdev *nfit_memdev;\n\n\tif (memdev->header.length != sizeof(*memdev))\n\t\treturn false;\n\n\tlist_for_each_entry(nfit_memdev, &prev->memdevs, list)\n\t\tif (memcmp(nfit_memdev->memdev, memdev, sizeof(*memdev)) == 0) {\n\t\t\tlist_move_tail(&nfit_memdev->list, &acpi_desc->memdevs);\n\t\t\treturn true;\n\t\t}\n\n\tnfit_memdev = devm_kzalloc(dev, sizeof(*nfit_memdev) + sizeof(*memdev),\n\t\t\tGFP_KERNEL);\n\tif (!nfit_memdev)\n\t\treturn false;\n\tINIT_LIST_HEAD(&nfit_memdev->list);\n\tmemcpy(nfit_memdev->memdev, memdev, sizeof(*memdev));\n\tlist_add_tail(&nfit_memdev->list, &acpi_desc->memdevs);\n\tdev_dbg(dev, \"memdev handle: %#x spa: %d dcr: %d flags: %#x\\n\",\n\t\t\tmemdev->device_handle, memdev->range_index,\n\t\t\tmemdev->region_index, memdev->flags);\n\treturn true;\n}\n\nint nfit_get_smbios_id(u32 device_handle, u16 *flags)\n{\n\tstruct acpi_nfit_memory_map *memdev;\n\tstruct acpi_nfit_desc *acpi_desc;\n\tstruct nfit_mem *nfit_mem;\n\tu16 physical_id;\n\n\tmutex_lock(&acpi_desc_lock);\n\tlist_for_each_entry(acpi_desc, &acpi_descs, list) {\n\t\tmutex_lock(&acpi_desc->init_mutex);\n\t\tlist_for_each_entry(nfit_mem, &acpi_desc->dimms, list) {\n\t\t\tmemdev = __to_nfit_memdev(nfit_mem);\n\t\t\tif (memdev->device_handle == device_handle) {\n\t\t\t\t*flags = memdev->flags;\n\t\t\t\tphysical_id = memdev->physical_id;\n\t\t\t\tmutex_unlock(&acpi_desc->init_mutex);\n\t\t\t\tmutex_unlock(&acpi_desc_lock);\n\t\t\t\treturn physical_id;\n\t\t\t}\n\t\t}\n\t\tmutex_unlock(&acpi_desc->init_mutex);\n\t}\n\tmutex_unlock(&acpi_desc_lock);\n\n\treturn -ENODEV;\n}\nEXPORT_SYMBOL_GPL(nfit_get_smbios_id);\n\n \nstatic size_t sizeof_dcr(struct acpi_nfit_control_region *dcr)\n{\n\tif (dcr->header.length < offsetof(struct acpi_nfit_control_region,\n\t\t\t\twindow_size))\n\t\treturn 0;\n\tif (dcr->windows)\n\t\treturn sizeof(*dcr);\n\treturn offsetof(struct acpi_nfit_control_region, window_size);\n}\n\nstatic bool add_dcr(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev,\n\t\tstruct acpi_nfit_control_region *dcr)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_dcr *nfit_dcr;\n\n\tif (!sizeof_dcr(dcr))\n\t\treturn false;\n\n\tlist_for_each_entry(nfit_dcr, &prev->dcrs, list)\n\t\tif (memcmp(nfit_dcr->dcr, dcr, sizeof_dcr(dcr)) == 0) {\n\t\t\tlist_move_tail(&nfit_dcr->list, &acpi_desc->dcrs);\n\t\t\treturn true;\n\t\t}\n\n\tnfit_dcr = devm_kzalloc(dev, sizeof(*nfit_dcr) + sizeof(*dcr),\n\t\t\tGFP_KERNEL);\n\tif (!nfit_dcr)\n\t\treturn false;\n\tINIT_LIST_HEAD(&nfit_dcr->list);\n\tmemcpy(nfit_dcr->dcr, dcr, sizeof_dcr(dcr));\n\tlist_add_tail(&nfit_dcr->list, &acpi_desc->dcrs);\n\tdev_dbg(dev, \"dcr index: %d windows: %d\\n\",\n\t\t\tdcr->region_index, dcr->windows);\n\treturn true;\n}\n\nstatic bool add_bdw(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev,\n\t\tstruct acpi_nfit_data_region *bdw)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_bdw *nfit_bdw;\n\n\tif (bdw->header.length != sizeof(*bdw))\n\t\treturn false;\n\tlist_for_each_entry(nfit_bdw, &prev->bdws, list)\n\t\tif (memcmp(nfit_bdw->bdw, bdw, sizeof(*bdw)) == 0) {\n\t\t\tlist_move_tail(&nfit_bdw->list, &acpi_desc->bdws);\n\t\t\treturn true;\n\t\t}\n\n\tnfit_bdw = devm_kzalloc(dev, sizeof(*nfit_bdw) + sizeof(*bdw),\n\t\t\tGFP_KERNEL);\n\tif (!nfit_bdw)\n\t\treturn false;\n\tINIT_LIST_HEAD(&nfit_bdw->list);\n\tmemcpy(nfit_bdw->bdw, bdw, sizeof(*bdw));\n\tlist_add_tail(&nfit_bdw->list, &acpi_desc->bdws);\n\tdev_dbg(dev, \"bdw dcr: %d windows: %d\\n\",\n\t\t\tbdw->region_index, bdw->windows);\n\treturn true;\n}\n\nstatic size_t sizeof_idt(struct acpi_nfit_interleave *idt)\n{\n\tif (idt->header.length < sizeof(*idt))\n\t\treturn 0;\n\treturn sizeof(*idt) + sizeof(u32) * idt->line_count;\n}\n\nstatic bool add_idt(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev,\n\t\tstruct acpi_nfit_interleave *idt)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_idt *nfit_idt;\n\n\tif (!sizeof_idt(idt))\n\t\treturn false;\n\n\tlist_for_each_entry(nfit_idt, &prev->idts, list) {\n\t\tif (sizeof_idt(nfit_idt->idt) != sizeof_idt(idt))\n\t\t\tcontinue;\n\n\t\tif (memcmp(nfit_idt->idt, idt, sizeof_idt(idt)) == 0) {\n\t\t\tlist_move_tail(&nfit_idt->list, &acpi_desc->idts);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tnfit_idt = devm_kzalloc(dev, sizeof(*nfit_idt) + sizeof_idt(idt),\n\t\t\tGFP_KERNEL);\n\tif (!nfit_idt)\n\t\treturn false;\n\tINIT_LIST_HEAD(&nfit_idt->list);\n\tmemcpy(nfit_idt->idt, idt, sizeof_idt(idt));\n\tlist_add_tail(&nfit_idt->list, &acpi_desc->idts);\n\tdev_dbg(dev, \"idt index: %d num_lines: %d\\n\",\n\t\t\tidt->interleave_index, idt->line_count);\n\treturn true;\n}\n\nstatic size_t sizeof_flush(struct acpi_nfit_flush_address *flush)\n{\n\tif (flush->header.length < sizeof(*flush))\n\t\treturn 0;\n\treturn struct_size(flush, hint_address, flush->hint_count);\n}\n\nstatic bool add_flush(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev,\n\t\tstruct acpi_nfit_flush_address *flush)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_flush *nfit_flush;\n\n\tif (!sizeof_flush(flush))\n\t\treturn false;\n\n\tlist_for_each_entry(nfit_flush, &prev->flushes, list) {\n\t\tif (sizeof_flush(nfit_flush->flush) != sizeof_flush(flush))\n\t\t\tcontinue;\n\n\t\tif (memcmp(nfit_flush->flush, flush,\n\t\t\t\t\tsizeof_flush(flush)) == 0) {\n\t\t\tlist_move_tail(&nfit_flush->list, &acpi_desc->flushes);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tnfit_flush = devm_kzalloc(dev, sizeof(*nfit_flush)\n\t\t\t+ sizeof_flush(flush), GFP_KERNEL);\n\tif (!nfit_flush)\n\t\treturn false;\n\tINIT_LIST_HEAD(&nfit_flush->list);\n\tmemcpy(nfit_flush->flush, flush, sizeof_flush(flush));\n\tlist_add_tail(&nfit_flush->list, &acpi_desc->flushes);\n\tdev_dbg(dev, \"nfit_flush handle: %d hint_count: %d\\n\",\n\t\t\tflush->device_handle, flush->hint_count);\n\treturn true;\n}\n\nstatic bool add_platform_cap(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct acpi_nfit_capabilities *pcap)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tu32 mask;\n\n\tmask = (1 << (pcap->highest_capability + 1)) - 1;\n\tacpi_desc->platform_cap = pcap->capabilities & mask;\n\tdev_dbg(dev, \"cap: %#x\\n\", acpi_desc->platform_cap);\n\treturn true;\n}\n\nstatic void *add_table(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev, void *table, const void *end)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct acpi_nfit_header *hdr;\n\tvoid *err = ERR_PTR(-ENOMEM);\n\n\tif (table >= end)\n\t\treturn NULL;\n\n\thdr = table;\n\tif (!hdr->length) {\n\t\tdev_warn(dev, \"found a zero length table '%d' parsing nfit\\n\",\n\t\t\thdr->type);\n\t\treturn NULL;\n\t}\n\n\tswitch (hdr->type) {\n\tcase ACPI_NFIT_TYPE_SYSTEM_ADDRESS:\n\t\tif (!add_spa(acpi_desc, prev, table))\n\t\t\treturn err;\n\t\tbreak;\n\tcase ACPI_NFIT_TYPE_MEMORY_MAP:\n\t\tif (!add_memdev(acpi_desc, prev, table))\n\t\t\treturn err;\n\t\tbreak;\n\tcase ACPI_NFIT_TYPE_CONTROL_REGION:\n\t\tif (!add_dcr(acpi_desc, prev, table))\n\t\t\treturn err;\n\t\tbreak;\n\tcase ACPI_NFIT_TYPE_DATA_REGION:\n\t\tif (!add_bdw(acpi_desc, prev, table))\n\t\t\treturn err;\n\t\tbreak;\n\tcase ACPI_NFIT_TYPE_INTERLEAVE:\n\t\tif (!add_idt(acpi_desc, prev, table))\n\t\t\treturn err;\n\t\tbreak;\n\tcase ACPI_NFIT_TYPE_FLUSH_ADDRESS:\n\t\tif (!add_flush(acpi_desc, prev, table))\n\t\t\treturn err;\n\t\tbreak;\n\tcase ACPI_NFIT_TYPE_SMBIOS:\n\t\tdev_dbg(dev, \"smbios\\n\");\n\t\tbreak;\n\tcase ACPI_NFIT_TYPE_CAPABILITIES:\n\t\tif (!add_platform_cap(acpi_desc, table))\n\t\t\treturn err;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(dev, \"unknown table '%d' parsing nfit\\n\", hdr->type);\n\t\tbreak;\n\t}\n\n\treturn table + hdr->length;\n}\n\nstatic int __nfit_mem_init(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct acpi_nfit_system_address *spa)\n{\n\tstruct nfit_mem *nfit_mem, *found;\n\tstruct nfit_memdev *nfit_memdev;\n\tint type = spa ? nfit_spa_type(spa) : 0;\n\n\tswitch (type) {\n\tcase NFIT_SPA_DCR:\n\tcase NFIT_SPA_PM:\n\t\tbreak;\n\tdefault:\n\t\tif (spa)\n\t\t\treturn 0;\n\t}\n\n\t \n\tlist_for_each_entry(nfit_memdev, &acpi_desc->memdevs, list) {\n\t\tstruct nfit_flush *nfit_flush;\n\t\tstruct nfit_dcr *nfit_dcr;\n\t\tu32 device_handle;\n\t\tu16 dcr;\n\n\t\tif (spa && nfit_memdev->memdev->range_index != spa->range_index)\n\t\t\tcontinue;\n\t\tif (!spa && nfit_memdev->memdev->range_index)\n\t\t\tcontinue;\n\t\tfound = NULL;\n\t\tdcr = nfit_memdev->memdev->region_index;\n\t\tdevice_handle = nfit_memdev->memdev->device_handle;\n\t\tlist_for_each_entry(nfit_mem, &acpi_desc->dimms, list)\n\t\t\tif (__to_nfit_memdev(nfit_mem)->device_handle\n\t\t\t\t\t== device_handle) {\n\t\t\t\tfound = nfit_mem;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tif (found)\n\t\t\tnfit_mem = found;\n\t\telse {\n\t\t\tnfit_mem = devm_kzalloc(acpi_desc->dev,\n\t\t\t\t\tsizeof(*nfit_mem), GFP_KERNEL);\n\t\t\tif (!nfit_mem)\n\t\t\t\treturn -ENOMEM;\n\t\t\tINIT_LIST_HEAD(&nfit_mem->list);\n\t\t\tnfit_mem->acpi_desc = acpi_desc;\n\t\t\tlist_add(&nfit_mem->list, &acpi_desc->dimms);\n\t\t}\n\n\t\tlist_for_each_entry(nfit_dcr, &acpi_desc->dcrs, list) {\n\t\t\tif (nfit_dcr->dcr->region_index != dcr)\n\t\t\t\tcontinue;\n\t\t\t \n\t\t\tif (!nfit_mem->dcr)\n\t\t\t\tnfit_mem->dcr = nfit_dcr->dcr;\n\t\t\telse if (nfit_mem->dcr->windows == 0\n\t\t\t\t\t&& nfit_dcr->dcr->windows)\n\t\t\t\tnfit_mem->dcr = nfit_dcr->dcr;\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_for_each_entry(nfit_flush, &acpi_desc->flushes, list) {\n\t\t\tstruct acpi_nfit_flush_address *flush;\n\t\t\tu16 i;\n\n\t\t\tif (nfit_flush->flush->device_handle != device_handle)\n\t\t\t\tcontinue;\n\t\t\tnfit_mem->nfit_flush = nfit_flush;\n\t\t\tflush = nfit_flush->flush;\n\t\t\tnfit_mem->flush_wpq = devm_kcalloc(acpi_desc->dev,\n\t\t\t\t\tflush->hint_count,\n\t\t\t\t\tsizeof(struct resource),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!nfit_mem->flush_wpq)\n\t\t\t\treturn -ENOMEM;\n\t\t\tfor (i = 0; i < flush->hint_count; i++) {\n\t\t\t\tstruct resource *res = &nfit_mem->flush_wpq[i];\n\n\t\t\t\tres->start = flush->hint_address[i];\n\t\t\t\tres->end = res->start + 8 - 1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (dcr && !nfit_mem->dcr) {\n\t\t\tdev_err(acpi_desc->dev, \"SPA %d missing DCR %d\\n\",\n\t\t\t\t\tspa->range_index, dcr);\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tif (type == NFIT_SPA_DCR) {\n\t\t\tstruct nfit_idt *nfit_idt;\n\t\t\tu16 idt_idx;\n\n\t\t\t \n\t\t\tnfit_mem->spa_dcr = spa;\n\t\t\tnfit_mem->memdev_dcr = nfit_memdev->memdev;\n\t\t\tidt_idx = nfit_memdev->memdev->interleave_index;\n\t\t\tlist_for_each_entry(nfit_idt, &acpi_desc->idts, list) {\n\t\t\t\tif (nfit_idt->idt->interleave_index != idt_idx)\n\t\t\t\t\tcontinue;\n\t\t\t\tnfit_mem->idt_dcr = nfit_idt->idt;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (type == NFIT_SPA_PM) {\n\t\t\t \n\t\t\tnfit_mem->memdev_pmem = nfit_memdev->memdev;\n\t\t} else\n\t\t\tnfit_mem->memdev_dcr = nfit_memdev->memdev;\n\t}\n\n\treturn 0;\n}\n\nstatic int nfit_mem_cmp(void *priv, const struct list_head *_a,\n\t\tconst struct list_head *_b)\n{\n\tstruct nfit_mem *a = container_of(_a, typeof(*a), list);\n\tstruct nfit_mem *b = container_of(_b, typeof(*b), list);\n\tu32 handleA, handleB;\n\n\thandleA = __to_nfit_memdev(a)->device_handle;\n\thandleB = __to_nfit_memdev(b)->device_handle;\n\tif (handleA < handleB)\n\t\treturn -1;\n\telse if (handleA > handleB)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic int nfit_mem_init(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nfit_spa *nfit_spa;\n\tint rc;\n\n\n\t \n\tlist_for_each_entry(nfit_spa, &acpi_desc->spas, list) {\n\t\trc = __nfit_mem_init(acpi_desc, nfit_spa->spa);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\t \n\trc = __nfit_mem_init(acpi_desc, NULL);\n\tif (rc)\n\t\treturn rc;\n\n\tlist_sort(NULL, &acpi_desc->dimms, nfit_mem_cmp);\n\n\treturn 0;\n}\n\nstatic ssize_t bus_dsm_mask_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm_bus *nvdimm_bus = to_nvdimm_bus(dev);\n\tstruct nvdimm_bus_descriptor *nd_desc = to_nd_desc(nvdimm_bus);\n\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\n\treturn sprintf(buf, \"%#lx\\n\", acpi_desc->bus_dsm_mask);\n}\nstatic struct device_attribute dev_attr_bus_dsm_mask =\n\t\t__ATTR(dsm_mask, 0444, bus_dsm_mask_show, NULL);\n\nstatic ssize_t revision_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm_bus *nvdimm_bus = to_nvdimm_bus(dev);\n\tstruct nvdimm_bus_descriptor *nd_desc = to_nd_desc(nvdimm_bus);\n\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\n\treturn sprintf(buf, \"%d\\n\", acpi_desc->acpi_header.revision);\n}\nstatic DEVICE_ATTR_RO(revision);\n\nstatic ssize_t hw_error_scrub_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm_bus *nvdimm_bus = to_nvdimm_bus(dev);\n\tstruct nvdimm_bus_descriptor *nd_desc = to_nd_desc(nvdimm_bus);\n\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\n\treturn sprintf(buf, \"%d\\n\", acpi_desc->scrub_mode);\n}\n\n \nstatic ssize_t hw_error_scrub_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t size)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc;\n\tssize_t rc;\n\tlong val;\n\n\trc = kstrtol(buf, 0, &val);\n\tif (rc)\n\t\treturn rc;\n\n\tdevice_lock(dev);\n\tnd_desc = dev_get_drvdata(dev);\n\tif (nd_desc) {\n\t\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\n\t\tswitch (val) {\n\t\tcase HW_ERROR_SCRUB_ON:\n\t\t\tacpi_desc->scrub_mode = HW_ERROR_SCRUB_ON;\n\t\t\tbreak;\n\t\tcase HW_ERROR_SCRUB_OFF:\n\t\t\tacpi_desc->scrub_mode = HW_ERROR_SCRUB_OFF;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\trc = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\tdevice_unlock(dev);\n\tif (rc)\n\t\treturn rc;\n\treturn size;\n}\nstatic DEVICE_ATTR_RW(hw_error_scrub);\n\n \nstatic ssize_t scrub_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc;\n\tstruct acpi_nfit_desc *acpi_desc;\n\tssize_t rc = -ENXIO;\n\tbool busy;\n\n\tdevice_lock(dev);\n\tnd_desc = dev_get_drvdata(dev);\n\tif (!nd_desc) {\n\t\tdevice_unlock(dev);\n\t\treturn rc;\n\t}\n\tacpi_desc = to_acpi_desc(nd_desc);\n\n\tmutex_lock(&acpi_desc->init_mutex);\n\tbusy = test_bit(ARS_BUSY, &acpi_desc->scrub_flags)\n\t\t&& !test_bit(ARS_CANCEL, &acpi_desc->scrub_flags);\n\trc = sprintf(buf, \"%d%s\", acpi_desc->scrub_count, busy ? \"+\\n\" : \"\\n\");\n\t \n\tif (busy && capable(CAP_SYS_RAWIO) && !test_and_set_bit(ARS_POLL,\n\t\t\t\t&acpi_desc->scrub_flags)) {\n\t\tacpi_desc->scrub_tmo = 1;\n\t\tmod_delayed_work(nfit_wq, &acpi_desc->dwork, HZ);\n\t}\n\n\tmutex_unlock(&acpi_desc->init_mutex);\n\tdevice_unlock(dev);\n\treturn rc;\n}\n\nstatic ssize_t scrub_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t size)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc;\n\tssize_t rc;\n\tlong val;\n\n\trc = kstrtol(buf, 0, &val);\n\tif (rc)\n\t\treturn rc;\n\tif (val != 1)\n\t\treturn -EINVAL;\n\n\tdevice_lock(dev);\n\tnd_desc = dev_get_drvdata(dev);\n\tif (nd_desc) {\n\t\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\n\t\trc = acpi_nfit_ars_rescan(acpi_desc, ARS_REQ_LONG);\n\t}\n\tdevice_unlock(dev);\n\tif (rc)\n\t\treturn rc;\n\treturn size;\n}\nstatic DEVICE_ATTR_RW(scrub);\n\nstatic bool ars_supported(struct nvdimm_bus *nvdimm_bus)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = to_nd_desc(nvdimm_bus);\n\tconst unsigned long mask = 1 << ND_CMD_ARS_CAP | 1 << ND_CMD_ARS_START\n\t\t| 1 << ND_CMD_ARS_STATUS;\n\n\treturn (nd_desc->cmd_mask & mask) == mask;\n}\n\nstatic umode_t nfit_visible(struct kobject *kobj, struct attribute *a, int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct nvdimm_bus *nvdimm_bus = to_nvdimm_bus(dev);\n\n\tif (a == &dev_attr_scrub.attr)\n\t\treturn ars_supported(nvdimm_bus) ? a->mode : 0;\n\n\tif (a == &dev_attr_firmware_activate_noidle.attr)\n\t\treturn intel_fwa_supported(nvdimm_bus) ? a->mode : 0;\n\n\treturn a->mode;\n}\n\nstatic struct attribute *acpi_nfit_attributes[] = {\n\t&dev_attr_revision.attr,\n\t&dev_attr_scrub.attr,\n\t&dev_attr_hw_error_scrub.attr,\n\t&dev_attr_bus_dsm_mask.attr,\n\t&dev_attr_firmware_activate_noidle.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group acpi_nfit_attribute_group = {\n\t.name = \"nfit\",\n\t.attrs = acpi_nfit_attributes,\n\t.is_visible = nfit_visible,\n};\n\nstatic const struct attribute_group *acpi_nfit_attribute_groups[] = {\n\t&acpi_nfit_attribute_group,\n\tNULL,\n};\n\nstatic struct acpi_nfit_memory_map *to_nfit_memdev(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\treturn __to_nfit_memdev(nfit_mem);\n}\n\nstatic struct acpi_nfit_control_region *to_nfit_dcr(struct device *dev)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\treturn nfit_mem->dcr;\n}\n\nstatic ssize_t handle_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_memory_map *memdev = to_nfit_memdev(dev);\n\n\treturn sprintf(buf, \"%#x\\n\", memdev->device_handle);\n}\nstatic DEVICE_ATTR_RO(handle);\n\nstatic ssize_t phys_id_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_memory_map *memdev = to_nfit_memdev(dev);\n\n\treturn sprintf(buf, \"%#x\\n\", memdev->physical_id);\n}\nstatic DEVICE_ATTR_RO(phys_id);\n\nstatic ssize_t vendor_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%04x\\n\", be16_to_cpu(dcr->vendor_id));\n}\nstatic DEVICE_ATTR_RO(vendor);\n\nstatic ssize_t rev_id_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%04x\\n\", be16_to_cpu(dcr->revision_id));\n}\nstatic DEVICE_ATTR_RO(rev_id);\n\nstatic ssize_t device_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%04x\\n\", be16_to_cpu(dcr->device_id));\n}\nstatic DEVICE_ATTR_RO(device);\n\nstatic ssize_t subsystem_vendor_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%04x\\n\", be16_to_cpu(dcr->subsystem_vendor_id));\n}\nstatic DEVICE_ATTR_RO(subsystem_vendor);\n\nstatic ssize_t subsystem_rev_id_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%04x\\n\",\n\t\t\tbe16_to_cpu(dcr->subsystem_revision_id));\n}\nstatic DEVICE_ATTR_RO(subsystem_rev_id);\n\nstatic ssize_t subsystem_device_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%04x\\n\", be16_to_cpu(dcr->subsystem_device_id));\n}\nstatic DEVICE_ATTR_RO(subsystem_device);\n\nstatic int num_nvdimm_formats(struct nvdimm *nvdimm)\n{\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\tint formats = 0;\n\n\tif (nfit_mem->memdev_pmem)\n\t\tformats++;\n\treturn formats;\n}\n\nstatic ssize_t format_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%04x\\n\", le16_to_cpu(dcr->code));\n}\nstatic DEVICE_ATTR_RO(format);\n\nstatic ssize_t format1_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tu32 handle;\n\tssize_t rc = -ENXIO;\n\tstruct nfit_mem *nfit_mem;\n\tstruct nfit_memdev *nfit_memdev;\n\tstruct acpi_nfit_desc *acpi_desc;\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\tnfit_mem = nvdimm_provider_data(nvdimm);\n\tacpi_desc = nfit_mem->acpi_desc;\n\thandle = to_nfit_memdev(dev)->device_handle;\n\n\t \n\tmutex_lock(&acpi_desc->init_mutex);\n\tlist_for_each_entry(nfit_memdev, &acpi_desc->memdevs, list) {\n\t\tstruct acpi_nfit_memory_map *memdev = nfit_memdev->memdev;\n\t\tstruct nfit_dcr *nfit_dcr;\n\n\t\tif (memdev->device_handle != handle)\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry(nfit_dcr, &acpi_desc->dcrs, list) {\n\t\t\tif (nfit_dcr->dcr->region_index != memdev->region_index)\n\t\t\t\tcontinue;\n\t\t\tif (nfit_dcr->dcr->code == dcr->code)\n\t\t\t\tcontinue;\n\t\t\trc = sprintf(buf, \"0x%04x\\n\",\n\t\t\t\t\tle16_to_cpu(nfit_dcr->dcr->code));\n\t\t\tbreak;\n\t\t}\n\t\tif (rc != -ENXIO)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(&acpi_desc->init_mutex);\n\treturn rc;\n}\nstatic DEVICE_ATTR_RO(format1);\n\nstatic ssize_t formats_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\n\treturn sprintf(buf, \"%d\\n\", num_nvdimm_formats(nvdimm));\n}\nstatic DEVICE_ATTR_RO(formats);\n\nstatic ssize_t serial_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct acpi_nfit_control_region *dcr = to_nfit_dcr(dev);\n\n\treturn sprintf(buf, \"0x%08x\\n\", be32_to_cpu(dcr->serial_number));\n}\nstatic DEVICE_ATTR_RO(serial);\n\nstatic ssize_t family_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\tif (nfit_mem->family < 0)\n\t\treturn -ENXIO;\n\treturn sprintf(buf, \"%d\\n\", nfit_mem->family);\n}\nstatic DEVICE_ATTR_RO(family);\n\nstatic ssize_t dsm_mask_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\tif (nfit_mem->family < 0)\n\t\treturn -ENXIO;\n\treturn sprintf(buf, \"%#lx\\n\", nfit_mem->dsm_mask);\n}\nstatic DEVICE_ATTR_RO(dsm_mask);\n\nstatic ssize_t flags_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\tu16 flags = __to_nfit_memdev(nfit_mem)->flags;\n\n\tif (test_bit(NFIT_MEM_DIRTY, &nfit_mem->flags))\n\t\tflags |= ACPI_NFIT_MEM_FLUSH_FAILED;\n\n\treturn sprintf(buf, \"%s%s%s%s%s%s%s\\n\",\n\t\tflags & ACPI_NFIT_MEM_SAVE_FAILED ? \"save_fail \" : \"\",\n\t\tflags & ACPI_NFIT_MEM_RESTORE_FAILED ? \"restore_fail \" : \"\",\n\t\tflags & ACPI_NFIT_MEM_FLUSH_FAILED ? \"flush_fail \" : \"\",\n\t\tflags & ACPI_NFIT_MEM_NOT_ARMED ? \"not_armed \" : \"\",\n\t\tflags & ACPI_NFIT_MEM_HEALTH_OBSERVED ? \"smart_event \" : \"\",\n\t\tflags & ACPI_NFIT_MEM_MAP_FAILED ? \"map_fail \" : \"\",\n\t\tflags & ACPI_NFIT_MEM_HEALTH_ENABLED ? \"smart_notify \" : \"\");\n}\nstatic DEVICE_ATTR_RO(flags);\n\nstatic ssize_t id_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\treturn sprintf(buf, \"%s\\n\", nfit_mem->id);\n}\nstatic DEVICE_ATTR_RO(id);\n\nstatic ssize_t dirty_shutdown_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\treturn sprintf(buf, \"%d\\n\", nfit_mem->dirty_shutdown);\n}\nstatic DEVICE_ATTR_RO(dirty_shutdown);\n\nstatic struct attribute *acpi_nfit_dimm_attributes[] = {\n\t&dev_attr_handle.attr,\n\t&dev_attr_phys_id.attr,\n\t&dev_attr_vendor.attr,\n\t&dev_attr_device.attr,\n\t&dev_attr_rev_id.attr,\n\t&dev_attr_subsystem_vendor.attr,\n\t&dev_attr_subsystem_device.attr,\n\t&dev_attr_subsystem_rev_id.attr,\n\t&dev_attr_format.attr,\n\t&dev_attr_formats.attr,\n\t&dev_attr_format1.attr,\n\t&dev_attr_serial.attr,\n\t&dev_attr_flags.attr,\n\t&dev_attr_id.attr,\n\t&dev_attr_family.attr,\n\t&dev_attr_dsm_mask.attr,\n\t&dev_attr_dirty_shutdown.attr,\n\tNULL,\n};\n\nstatic umode_t acpi_nfit_dimm_attr_visible(struct kobject *kobj,\n\t\tstruct attribute *a, int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct nvdimm *nvdimm = to_nvdimm(dev);\n\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\n\tif (!to_nfit_dcr(dev)) {\n\t\t \n\t\tif (a == &dev_attr_handle.attr || a == &dev_attr_phys_id.attr\n\t\t\t\t|| a == &dev_attr_flags.attr\n\t\t\t\t|| a == &dev_attr_family.attr\n\t\t\t\t|| a == &dev_attr_dsm_mask.attr)\n\t\t\treturn a->mode;\n\t\treturn 0;\n\t}\n\n\tif (a == &dev_attr_format1.attr && num_nvdimm_formats(nvdimm) <= 1)\n\t\treturn 0;\n\n\tif (!test_bit(NFIT_MEM_DIRTY_COUNT, &nfit_mem->flags)\n\t\t\t&& a == &dev_attr_dirty_shutdown.attr)\n\t\treturn 0;\n\n\treturn a->mode;\n}\n\nstatic const struct attribute_group acpi_nfit_dimm_attribute_group = {\n\t.name = \"nfit\",\n\t.attrs = acpi_nfit_dimm_attributes,\n\t.is_visible = acpi_nfit_dimm_attr_visible,\n};\n\nstatic const struct attribute_group *acpi_nfit_dimm_attribute_groups[] = {\n\t&acpi_nfit_dimm_attribute_group,\n\tNULL,\n};\n\nstatic struct nvdimm *acpi_nfit_dimm_by_handle(struct acpi_nfit_desc *acpi_desc,\n\t\tu32 device_handle)\n{\n\tstruct nfit_mem *nfit_mem;\n\n\tlist_for_each_entry(nfit_mem, &acpi_desc->dimms, list)\n\t\tif (__to_nfit_memdev(nfit_mem)->device_handle == device_handle)\n\t\t\treturn nfit_mem->nvdimm;\n\n\treturn NULL;\n}\n\nvoid __acpi_nvdimm_notify(struct device *dev, u32 event)\n{\n\tstruct nfit_mem *nfit_mem;\n\tstruct acpi_nfit_desc *acpi_desc;\n\n\tdev_dbg(dev->parent, \"%s: event: %d\\n\", dev_name(dev),\n\t\t\tevent);\n\n\tif (event != NFIT_NOTIFY_DIMM_HEALTH) {\n\t\tdev_dbg(dev->parent, \"%s: unknown event: %d\\n\", dev_name(dev),\n\t\t\t\tevent);\n\t\treturn;\n\t}\n\n\tacpi_desc = dev_get_drvdata(dev->parent);\n\tif (!acpi_desc)\n\t\treturn;\n\n\t \n\tnfit_mem = dev_get_drvdata(dev);\n\tif (nfit_mem && nfit_mem->flags_attr)\n\t\tsysfs_notify_dirent(nfit_mem->flags_attr);\n}\nEXPORT_SYMBOL_GPL(__acpi_nvdimm_notify);\n\nstatic void acpi_nvdimm_notify(acpi_handle handle, u32 event, void *data)\n{\n\tstruct acpi_device *adev = data;\n\tstruct device *dev = &adev->dev;\n\n\tdevice_lock(dev->parent);\n\t__acpi_nvdimm_notify(dev, event);\n\tdevice_unlock(dev->parent);\n}\n\nstatic bool acpi_nvdimm_has_method(struct acpi_device *adev, char *method)\n{\n\tacpi_handle handle;\n\tacpi_status status;\n\n\tstatus = acpi_get_handle(adev->handle, method, &handle);\n\n\tif (ACPI_SUCCESS(status))\n\t\treturn true;\n\treturn false;\n}\n\n__weak void nfit_intel_shutdown_status(struct nfit_mem *nfit_mem)\n{\n\tstruct device *dev = &nfit_mem->adev->dev;\n\tstruct nd_intel_smart smart = { 0 };\n\tunion acpi_object in_buf = {\n\t\t.buffer.type = ACPI_TYPE_BUFFER,\n\t\t.buffer.length = 0,\n\t};\n\tunion acpi_object in_obj = {\n\t\t.package.type = ACPI_TYPE_PACKAGE,\n\t\t.package.count = 1,\n\t\t.package.elements = &in_buf,\n\t};\n\tconst u8 func = ND_INTEL_SMART;\n\tconst guid_t *guid = to_nfit_uuid(nfit_mem->family);\n\tu8 revid = nfit_dsm_revid(nfit_mem->family, func);\n\tstruct acpi_device *adev = nfit_mem->adev;\n\tacpi_handle handle = adev->handle;\n\tunion acpi_object *out_obj;\n\n\tif ((nfit_mem->dsm_mask & (1 << func)) == 0)\n\t\treturn;\n\n\tout_obj = acpi_evaluate_dsm(handle, guid, revid, func, &in_obj);\n\tif (!out_obj || out_obj->type != ACPI_TYPE_BUFFER\n\t\t\t|| out_obj->buffer.length < sizeof(smart)) {\n\t\tdev_dbg(dev->parent, \"%s: failed to retrieve initial health\\n\",\n\t\t\t\tdev_name(dev));\n\t\tACPI_FREE(out_obj);\n\t\treturn;\n\t}\n\tmemcpy(&smart, out_obj->buffer.pointer, sizeof(smart));\n\tACPI_FREE(out_obj);\n\n\tif (smart.flags & ND_INTEL_SMART_SHUTDOWN_VALID) {\n\t\tif (smart.shutdown_state)\n\t\t\tset_bit(NFIT_MEM_DIRTY, &nfit_mem->flags);\n\t}\n\n\tif (smart.flags & ND_INTEL_SMART_SHUTDOWN_COUNT_VALID) {\n\t\tset_bit(NFIT_MEM_DIRTY_COUNT, &nfit_mem->flags);\n\t\tnfit_mem->dirty_shutdown = smart.shutdown_count;\n\t}\n}\n\nstatic void populate_shutdown_status(struct nfit_mem *nfit_mem)\n{\n\t \n\tif (nfit_mem->family == NVDIMM_FAMILY_INTEL)\n\t\tnfit_intel_shutdown_status(nfit_mem);\n}\n\nstatic int acpi_nfit_add_dimm(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_mem *nfit_mem, u32 device_handle)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\tstruct acpi_device *adev, *adev_dimm;\n\tstruct device *dev = acpi_desc->dev;\n\tunsigned long dsm_mask, label_mask;\n\tconst guid_t *guid;\n\tint i;\n\tint family = -1;\n\tstruct acpi_nfit_control_region *dcr = nfit_mem->dcr;\n\n\t \n\tnfit_mem->dsm_mask = acpi_desc->dimm_cmd_force_en;\n\tnfit_mem->family = NVDIMM_FAMILY_INTEL;\n\tset_bit(NVDIMM_FAMILY_INTEL, &nd_desc->dimm_family_mask);\n\n\tif (dcr->valid_fields & ACPI_NFIT_CONTROL_MFG_INFO_VALID)\n\t\tsprintf(nfit_mem->id, \"%04x-%02x-%04x-%08x\",\n\t\t\t\tbe16_to_cpu(dcr->vendor_id),\n\t\t\t\tdcr->manufacturing_location,\n\t\t\t\tbe16_to_cpu(dcr->manufacturing_date),\n\t\t\t\tbe32_to_cpu(dcr->serial_number));\n\telse\n\t\tsprintf(nfit_mem->id, \"%04x-%08x\",\n\t\t\t\tbe16_to_cpu(dcr->vendor_id),\n\t\t\t\tbe32_to_cpu(dcr->serial_number));\n\n\tadev = to_acpi_dev(acpi_desc);\n\tif (!adev) {\n\t\t \n\t\tpopulate_shutdown_status(nfit_mem);\n\t\treturn 0;\n\t}\n\n\tadev_dimm = acpi_find_child_device(adev, device_handle, false);\n\tnfit_mem->adev = adev_dimm;\n\tif (!adev_dimm) {\n\t\tdev_err(dev, \"no ACPI.NFIT device with _ADR %#x, disabling...\\n\",\n\t\t\t\tdevice_handle);\n\t\treturn force_enable_dimms ? 0 : -ENODEV;\n\t}\n\n\tif (ACPI_FAILURE(acpi_install_notify_handler(adev_dimm->handle,\n\t\tACPI_DEVICE_NOTIFY, acpi_nvdimm_notify, adev_dimm))) {\n\t\tdev_err(dev, \"%s: notification registration failed\\n\",\n\t\t\t\tdev_name(&adev_dimm->dev));\n\t\treturn -ENXIO;\n\t}\n\t \n\tdev_set_drvdata(&adev_dimm->dev, nfit_mem);\n\n\t \n\tclear_bit(NVDIMM_FAMILY_INTEL, &nd_desc->dimm_family_mask);\n\tfor (i = 0; i <= NVDIMM_FAMILY_MAX; i++)\n\t\tif (acpi_check_dsm(adev_dimm->handle, to_nfit_uuid(i), 1, 1)) {\n\t\t\tset_bit(i, &nd_desc->dimm_family_mask);\n\t\t\tif (family < 0 || i == default_dsm_family)\n\t\t\t\tfamily = i;\n\t\t}\n\n\t \n\tnfit_mem->family = family;\n\tif (override_dsm_mask && !disable_vendor_specific)\n\t\tdsm_mask = override_dsm_mask;\n\telse if (nfit_mem->family == NVDIMM_FAMILY_INTEL) {\n\t\tdsm_mask = NVDIMM_INTEL_CMDMASK;\n\t\tif (disable_vendor_specific)\n\t\t\tdsm_mask &= ~(1 << ND_CMD_VENDOR);\n\t} else if (nfit_mem->family == NVDIMM_FAMILY_HPE1) {\n\t\tdsm_mask = 0x1c3c76;\n\t} else if (nfit_mem->family == NVDIMM_FAMILY_HPE2) {\n\t\tdsm_mask = 0x1fe;\n\t\tif (disable_vendor_specific)\n\t\t\tdsm_mask &= ~(1 << 8);\n\t} else if (nfit_mem->family == NVDIMM_FAMILY_MSFT) {\n\t\tdsm_mask = 0xffffffff;\n\t} else if (nfit_mem->family == NVDIMM_FAMILY_HYPERV) {\n\t\tdsm_mask = 0x1f;\n\t} else {\n\t\tdev_dbg(dev, \"unknown dimm command family\\n\");\n\t\tnfit_mem->family = -1;\n\t\t \n\t\treturn 0;\n\t}\n\n\t \n\tdsm_mask &= ~1UL;\n\n\tguid = to_nfit_uuid(nfit_mem->family);\n\tfor_each_set_bit(i, &dsm_mask, BITS_PER_LONG)\n\t\tif (acpi_check_dsm(adev_dimm->handle, guid,\n\t\t\t\t\tnfit_dsm_revid(nfit_mem->family, i),\n\t\t\t\t\t1ULL << i))\n\t\t\tset_bit(i, &nfit_mem->dsm_mask);\n\n\t \n\tlabel_mask = 1 << ND_CMD_GET_CONFIG_SIZE | 1 << ND_CMD_GET_CONFIG_DATA\n\t\t| 1 << ND_CMD_SET_CONFIG_DATA;\n\tif (family == NVDIMM_FAMILY_INTEL\n\t\t\t&& (dsm_mask & label_mask) == label_mask)\n\t\t ;\n\telse {\n\t\tif (acpi_nvdimm_has_method(adev_dimm, \"_LSI\")\n\t\t\t\t&& acpi_nvdimm_has_method(adev_dimm, \"_LSR\")) {\n\t\t\tdev_dbg(dev, \"%s: has _LSR\\n\", dev_name(&adev_dimm->dev));\n\t\t\tset_bit(NFIT_MEM_LSR, &nfit_mem->flags);\n\t\t}\n\n\t\tif (test_bit(NFIT_MEM_LSR, &nfit_mem->flags)\n\t\t\t\t&& acpi_nvdimm_has_method(adev_dimm, \"_LSW\")) {\n\t\t\tdev_dbg(dev, \"%s: has _LSW\\n\", dev_name(&adev_dimm->dev));\n\t\t\tset_bit(NFIT_MEM_LSW, &nfit_mem->flags);\n\t\t}\n\n\t\t \n\t\tif (!test_bit(NFIT_MEM_LSW, &nfit_mem->flags)\n\t\t\t\t&& !force_labels) {\n\t\t\tdev_dbg(dev, \"%s: No _LSW, disable labels\\n\",\n\t\t\t\t\tdev_name(&adev_dimm->dev));\n\t\t\tclear_bit(NFIT_MEM_LSR, &nfit_mem->flags);\n\t\t} else\n\t\t\tdev_dbg(dev, \"%s: Force enable labels\\n\",\n\t\t\t\t\tdev_name(&adev_dimm->dev));\n\t}\n\n\tpopulate_shutdown_status(nfit_mem);\n\n\treturn 0;\n}\n\nstatic void shutdown_dimm_notify(void *data)\n{\n\tstruct acpi_nfit_desc *acpi_desc = data;\n\tstruct nfit_mem *nfit_mem;\n\n\tmutex_lock(&acpi_desc->init_mutex);\n\t \n\tlist_for_each_entry(nfit_mem, &acpi_desc->dimms, list) {\n\t\tstruct acpi_device *adev_dimm = nfit_mem->adev;\n\n\t\tif (nfit_mem->flags_attr) {\n\t\t\tsysfs_put(nfit_mem->flags_attr);\n\t\t\tnfit_mem->flags_attr = NULL;\n\t\t}\n\t\tif (adev_dimm) {\n\t\t\tacpi_remove_notify_handler(adev_dimm->handle,\n\t\t\t\t\tACPI_DEVICE_NOTIFY, acpi_nvdimm_notify);\n\t\t\tdev_set_drvdata(&adev_dimm->dev, NULL);\n\t\t}\n\t}\n\tmutex_unlock(&acpi_desc->init_mutex);\n}\n\nstatic const struct nvdimm_security_ops *acpi_nfit_get_security_ops(int family)\n{\n\tswitch (family) {\n\tcase NVDIMM_FAMILY_INTEL:\n\t\treturn intel_security_ops;\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic const struct nvdimm_fw_ops *acpi_nfit_get_fw_ops(\n\t\tstruct nfit_mem *nfit_mem)\n{\n\tunsigned long mask;\n\tstruct acpi_nfit_desc *acpi_desc = nfit_mem->acpi_desc;\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\n\tif (!nd_desc->fw_ops)\n\t\treturn NULL;\n\n\tif (nfit_mem->family != NVDIMM_FAMILY_INTEL)\n\t\treturn NULL;\n\n\tmask = nfit_mem->dsm_mask & NVDIMM_INTEL_FW_ACTIVATE_CMDMASK;\n\tif (mask != NVDIMM_INTEL_FW_ACTIVATE_CMDMASK)\n\t\treturn NULL;\n\n\treturn intel_fw_ops;\n}\n\nstatic int acpi_nfit_register_dimms(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nfit_mem *nfit_mem;\n\tint dimm_count = 0, rc;\n\tstruct nvdimm *nvdimm;\n\n\tlist_for_each_entry(nfit_mem, &acpi_desc->dimms, list) {\n\t\tstruct acpi_nfit_flush_address *flush;\n\t\tunsigned long flags = 0, cmd_mask;\n\t\tstruct nfit_memdev *nfit_memdev;\n\t\tu32 device_handle;\n\t\tu16 mem_flags;\n\n\t\tdevice_handle = __to_nfit_memdev(nfit_mem)->device_handle;\n\t\tnvdimm = acpi_nfit_dimm_by_handle(acpi_desc, device_handle);\n\t\tif (nvdimm) {\n\t\t\tdimm_count++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tlist_for_each_entry(nfit_memdev, &acpi_desc->memdevs, list) {\n\t\t\tstruct acpi_nfit_memory_map *dimm_memdev;\n\n\t\t\tdimm_memdev = __to_nfit_memdev(nfit_mem);\n\t\t\tif (dimm_memdev->device_handle\n\t\t\t\t\t!= nfit_memdev->memdev->device_handle)\n\t\t\t\tcontinue;\n\t\t\tdimm_memdev->flags |= nfit_memdev->memdev->flags;\n\t\t}\n\n\t\tmem_flags = __to_nfit_memdev(nfit_mem)->flags;\n\t\tif (mem_flags & ACPI_NFIT_MEM_NOT_ARMED)\n\t\t\tset_bit(NDD_UNARMED, &flags);\n\n\t\trc = acpi_nfit_add_dimm(acpi_desc, nfit_mem, device_handle);\n\t\tif (rc)\n\t\t\tcontinue;\n\n\t\t \n\t\tcmd_mask = 1UL << ND_CMD_CALL;\n\t\tif (nfit_mem->family == NVDIMM_FAMILY_INTEL) {\n\t\t\t \n\t\t\tcmd_mask |= nfit_mem->dsm_mask & NVDIMM_STANDARD_CMDMASK;\n\t\t}\n\n\t\tif (test_bit(NFIT_MEM_LSR, &nfit_mem->flags)) {\n\t\t\tset_bit(ND_CMD_GET_CONFIG_SIZE, &cmd_mask);\n\t\t\tset_bit(ND_CMD_GET_CONFIG_DATA, &cmd_mask);\n\t\t}\n\t\tif (test_bit(NFIT_MEM_LSW, &nfit_mem->flags))\n\t\t\tset_bit(ND_CMD_SET_CONFIG_DATA, &cmd_mask);\n\n\t\tflush = nfit_mem->nfit_flush ? nfit_mem->nfit_flush->flush\n\t\t\t: NULL;\n\t\tnvdimm = __nvdimm_create(acpi_desc->nvdimm_bus, nfit_mem,\n\t\t\t\tacpi_nfit_dimm_attribute_groups,\n\t\t\t\tflags, cmd_mask, flush ? flush->hint_count : 0,\n\t\t\t\tnfit_mem->flush_wpq, &nfit_mem->id[0],\n\t\t\t\tacpi_nfit_get_security_ops(nfit_mem->family),\n\t\t\t\tacpi_nfit_get_fw_ops(nfit_mem));\n\t\tif (!nvdimm)\n\t\t\treturn -ENOMEM;\n\n\t\tnfit_mem->nvdimm = nvdimm;\n\t\tdimm_count++;\n\n\t\tif ((mem_flags & ACPI_NFIT_MEM_FAILED_MASK) == 0)\n\t\t\tcontinue;\n\n\t\tdev_err(acpi_desc->dev, \"Error found in NVDIMM %s flags:%s%s%s%s%s\\n\",\n\t\t\t\tnvdimm_name(nvdimm),\n\t\t  mem_flags & ACPI_NFIT_MEM_SAVE_FAILED ? \" save_fail\" : \"\",\n\t\t  mem_flags & ACPI_NFIT_MEM_RESTORE_FAILED ? \" restore_fail\":\"\",\n\t\t  mem_flags & ACPI_NFIT_MEM_FLUSH_FAILED ? \" flush_fail\" : \"\",\n\t\t  mem_flags & ACPI_NFIT_MEM_NOT_ARMED ? \" not_armed\" : \"\",\n\t\t  mem_flags & ACPI_NFIT_MEM_MAP_FAILED ? \" map_fail\" : \"\");\n\n\t}\n\n\trc = nvdimm_bus_check_dimm_count(acpi_desc->nvdimm_bus, dimm_count);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tlist_for_each_entry(nfit_mem, &acpi_desc->dimms, list) {\n\t\tstruct kernfs_node *nfit_kernfs;\n\n\t\tnvdimm = nfit_mem->nvdimm;\n\t\tif (!nvdimm)\n\t\t\tcontinue;\n\n\t\tnfit_kernfs = sysfs_get_dirent(nvdimm_kobj(nvdimm)->sd, \"nfit\");\n\t\tif (nfit_kernfs)\n\t\t\tnfit_mem->flags_attr = sysfs_get_dirent(nfit_kernfs,\n\t\t\t\t\t\"flags\");\n\t\tsysfs_put(nfit_kernfs);\n\t\tif (!nfit_mem->flags_attr)\n\t\t\tdev_warn(acpi_desc->dev, \"%s: notifications disabled\\n\",\n\t\t\t\t\tnvdimm_name(nvdimm));\n\t}\n\n\treturn devm_add_action_or_reset(acpi_desc->dev, shutdown_dimm_notify,\n\t\t\tacpi_desc);\n}\n\n \nenum nfit_aux_cmds {\n\tNFIT_CMD_TRANSLATE_SPA = 5,\n\tNFIT_CMD_ARS_INJECT_SET = 7,\n\tNFIT_CMD_ARS_INJECT_CLEAR = 8,\n\tNFIT_CMD_ARS_INJECT_GET = 9,\n};\n\nstatic void acpi_nfit_init_dsms(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\tconst guid_t *guid = to_nfit_uuid(NFIT_DEV_BUS);\n\tunsigned long dsm_mask, *mask;\n\tstruct acpi_device *adev;\n\tint i;\n\n\tset_bit(ND_CMD_CALL, &nd_desc->cmd_mask);\n\tset_bit(NVDIMM_BUS_FAMILY_NFIT, &nd_desc->bus_family_mask);\n\n\t \n\tif (acpi_desc->bus_cmd_force_en) {\n\t\tnd_desc->cmd_mask = acpi_desc->bus_cmd_force_en;\n\t\tmask = &nd_desc->bus_family_mask;\n\t\tif (acpi_desc->family_dsm_mask[NVDIMM_BUS_FAMILY_INTEL]) {\n\t\t\tset_bit(NVDIMM_BUS_FAMILY_INTEL, mask);\n\t\t\tnd_desc->fw_ops = intel_bus_fw_ops;\n\t\t}\n\t}\n\n\tadev = to_acpi_dev(acpi_desc);\n\tif (!adev)\n\t\treturn;\n\n\tfor (i = ND_CMD_ARS_CAP; i <= ND_CMD_CLEAR_ERROR; i++)\n\t\tif (acpi_check_dsm(adev->handle, guid, 1, 1ULL << i))\n\t\t\tset_bit(i, &nd_desc->cmd_mask);\n\n\tdsm_mask =\n\t\t(1 << ND_CMD_ARS_CAP) |\n\t\t(1 << ND_CMD_ARS_START) |\n\t\t(1 << ND_CMD_ARS_STATUS) |\n\t\t(1 << ND_CMD_CLEAR_ERROR) |\n\t\t(1 << NFIT_CMD_TRANSLATE_SPA) |\n\t\t(1 << NFIT_CMD_ARS_INJECT_SET) |\n\t\t(1 << NFIT_CMD_ARS_INJECT_CLEAR) |\n\t\t(1 << NFIT_CMD_ARS_INJECT_GET);\n\tfor_each_set_bit(i, &dsm_mask, BITS_PER_LONG)\n\t\tif (acpi_check_dsm(adev->handle, guid, 1, 1ULL << i))\n\t\t\tset_bit(i, &acpi_desc->bus_dsm_mask);\n\n\t \n\tdsm_mask = NVDIMM_BUS_INTEL_FW_ACTIVATE_CMDMASK;\n\tguid = to_nfit_bus_uuid(NVDIMM_BUS_FAMILY_INTEL);\n\tmask = &acpi_desc->family_dsm_mask[NVDIMM_BUS_FAMILY_INTEL];\n\tfor_each_set_bit(i, &dsm_mask, BITS_PER_LONG)\n\t\tif (acpi_check_dsm(adev->handle, guid, 1, 1ULL << i))\n\t\t\tset_bit(i, mask);\n\n\tif (*mask == dsm_mask) {\n\t\tset_bit(NVDIMM_BUS_FAMILY_INTEL, &nd_desc->bus_family_mask);\n\t\tnd_desc->fw_ops = intel_bus_fw_ops;\n\t}\n}\n\nstatic ssize_t range_index_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct nd_region *nd_region = to_nd_region(dev);\n\tstruct nfit_spa *nfit_spa = nd_region_provider_data(nd_region);\n\n\treturn sprintf(buf, \"%d\\n\", nfit_spa->spa->range_index);\n}\nstatic DEVICE_ATTR_RO(range_index);\n\nstatic struct attribute *acpi_nfit_region_attributes[] = {\n\t&dev_attr_range_index.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group acpi_nfit_region_attribute_group = {\n\t.name = \"nfit\",\n\t.attrs = acpi_nfit_region_attributes,\n};\n\nstatic const struct attribute_group *acpi_nfit_region_attribute_groups[] = {\n\t&acpi_nfit_region_attribute_group,\n\tNULL,\n};\n\n \nstruct nfit_set_info {\n\tu64 region_offset;\n\tu32 serial_number;\n\tu32 pad;\n};\n\nstruct nfit_set_info2 {\n\tu64 region_offset;\n\tu32 serial_number;\n\tu16 vendor_id;\n\tu16 manufacturing_date;\n\tu8 manufacturing_location;\n\tu8 reserved[31];\n};\n\nstatic int cmp_map_compat(const void *m0, const void *m1)\n{\n\tconst struct nfit_set_info *map0 = m0;\n\tconst struct nfit_set_info *map1 = m1;\n\n\treturn memcmp(&map0->region_offset, &map1->region_offset,\n\t\t\tsizeof(u64));\n}\n\nstatic int cmp_map(const void *m0, const void *m1)\n{\n\tconst struct nfit_set_info *map0 = m0;\n\tconst struct nfit_set_info *map1 = m1;\n\n\tif (map0->region_offset < map1->region_offset)\n\t\treturn -1;\n\telse if (map0->region_offset > map1->region_offset)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic int cmp_map2(const void *m0, const void *m1)\n{\n\tconst struct nfit_set_info2 *map0 = m0;\n\tconst struct nfit_set_info2 *map1 = m1;\n\n\tif (map0->region_offset < map1->region_offset)\n\t\treturn -1;\n\telse if (map0->region_offset > map1->region_offset)\n\t\treturn 1;\n\treturn 0;\n}\n\n \nstatic struct acpi_nfit_memory_map *memdev_from_spa(\n\t\tstruct acpi_nfit_desc *acpi_desc, u16 range_index, int n)\n{\n\tstruct nfit_memdev *nfit_memdev;\n\n\tlist_for_each_entry(nfit_memdev, &acpi_desc->memdevs, list)\n\t\tif (nfit_memdev->memdev->range_index == range_index)\n\t\t\tif (n-- == 0)\n\t\t\t\treturn nfit_memdev->memdev;\n\treturn NULL;\n}\n\nstatic int acpi_nfit_init_interleave_set(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nd_region_desc *ndr_desc,\n\t\tstruct acpi_nfit_system_address *spa)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nd_interleave_set *nd_set;\n\tu16 nr = ndr_desc->num_mappings;\n\tstruct nfit_set_info2 *info2;\n\tstruct nfit_set_info *info;\n\tint i;\n\n\tnd_set = devm_kzalloc(dev, sizeof(*nd_set), GFP_KERNEL);\n\tif (!nd_set)\n\t\treturn -ENOMEM;\n\timport_guid(&nd_set->type_guid, spa->range_guid);\n\n\tinfo = devm_kcalloc(dev, nr, sizeof(*info), GFP_KERNEL);\n\tif (!info)\n\t\treturn -ENOMEM;\n\n\tinfo2 = devm_kcalloc(dev, nr, sizeof(*info2), GFP_KERNEL);\n\tif (!info2)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tstruct nd_mapping_desc *mapping = &ndr_desc->mapping[i];\n\t\tstruct nvdimm *nvdimm = mapping->nvdimm;\n\t\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\t\tstruct nfit_set_info *map = &info[i];\n\t\tstruct nfit_set_info2 *map2 = &info2[i];\n\t\tstruct acpi_nfit_memory_map *memdev =\n\t\t\tmemdev_from_spa(acpi_desc, spa->range_index, i);\n\t\tstruct acpi_nfit_control_region *dcr = nfit_mem->dcr;\n\n\t\tif (!memdev || !nfit_mem->dcr) {\n\t\t\tdev_err(dev, \"%s: failed to find DCR\\n\", __func__);\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tmap->region_offset = memdev->region_offset;\n\t\tmap->serial_number = dcr->serial_number;\n\n\t\tmap2->region_offset = memdev->region_offset;\n\t\tmap2->serial_number = dcr->serial_number;\n\t\tmap2->vendor_id = dcr->vendor_id;\n\t\tmap2->manufacturing_date = dcr->manufacturing_date;\n\t\tmap2->manufacturing_location = dcr->manufacturing_location;\n\t}\n\n\t \n\tsort(info, nr, sizeof(*info), cmp_map, NULL);\n\tnd_set->cookie1 = nd_fletcher64(info, sizeof(*info) * nr, 0);\n\n\t \n\tsort(info2, nr, sizeof(*info2), cmp_map2, NULL);\n\tnd_set->cookie2 = nd_fletcher64(info2, sizeof(*info2) * nr, 0);\n\n\t \n\tsort(info, nr, sizeof(*info), cmp_map_compat, NULL);\n\tnd_set->altcookie = nd_fletcher64(info, sizeof(*info) * nr, 0);\n\n\t \n\tfor (i = 0; i < nr; i++) {\n\t\tstruct nfit_set_info2 *map2 = &info2[i];\n\t\tint j;\n\n\t\tfor (j = 0; j < nr; j++) {\n\t\t\tstruct nd_mapping_desc *mapping = &ndr_desc->mapping[j];\n\t\t\tstruct nvdimm *nvdimm = mapping->nvdimm;\n\t\t\tstruct nfit_mem *nfit_mem = nvdimm_provider_data(nvdimm);\n\t\t\tstruct acpi_nfit_control_region *dcr = nfit_mem->dcr;\n\n\t\t\tif (map2->serial_number == dcr->serial_number &&\n\t\t\t    map2->vendor_id == dcr->vendor_id &&\n\t\t\t    map2->manufacturing_date == dcr->manufacturing_date &&\n\t\t\t    map2->manufacturing_location\n\t\t\t\t    == dcr->manufacturing_location) {\n\t\t\t\tmapping->position = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tndr_desc->nd_set = nd_set;\n\tdevm_kfree(dev, info);\n\tdevm_kfree(dev, info2);\n\n\treturn 0;\n}\n\nstatic int ars_get_cap(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nd_cmd_ars_cap *cmd, struct nfit_spa *nfit_spa)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\tstruct acpi_nfit_system_address *spa = nfit_spa->spa;\n\tint cmd_rc, rc;\n\n\tcmd->address = spa->address;\n\tcmd->length = spa->length;\n\trc = nd_desc->ndctl(nd_desc, NULL, ND_CMD_ARS_CAP, cmd,\n\t\t\tsizeof(*cmd), &cmd_rc);\n\tif (rc < 0)\n\t\treturn rc;\n\treturn cmd_rc;\n}\n\nstatic int ars_start(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_spa *nfit_spa, enum nfit_ars_state req_type)\n{\n\tint rc;\n\tint cmd_rc;\n\tstruct nd_cmd_ars_start ars_start;\n\tstruct acpi_nfit_system_address *spa = nfit_spa->spa;\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\n\tmemset(&ars_start, 0, sizeof(ars_start));\n\tars_start.address = spa->address;\n\tars_start.length = spa->length;\n\tif (req_type == ARS_REQ_SHORT)\n\t\tars_start.flags = ND_ARS_RETURN_PREV_DATA;\n\tif (nfit_spa_type(spa) == NFIT_SPA_PM)\n\t\tars_start.type = ND_ARS_PERSISTENT;\n\telse if (nfit_spa_type(spa) == NFIT_SPA_VOLATILE)\n\t\tars_start.type = ND_ARS_VOLATILE;\n\telse\n\t\treturn -ENOTTY;\n\n\trc = nd_desc->ndctl(nd_desc, NULL, ND_CMD_ARS_START, &ars_start,\n\t\t\tsizeof(ars_start), &cmd_rc);\n\n\tif (rc < 0)\n\t\treturn rc;\n\tif (cmd_rc < 0)\n\t\treturn cmd_rc;\n\tset_bit(ARS_VALID, &acpi_desc->scrub_flags);\n\treturn 0;\n}\n\nstatic int ars_continue(struct acpi_nfit_desc *acpi_desc)\n{\n\tint rc, cmd_rc;\n\tstruct nd_cmd_ars_start ars_start;\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\tstruct nd_cmd_ars_status *ars_status = acpi_desc->ars_status;\n\n\tars_start = (struct nd_cmd_ars_start) {\n\t\t.address = ars_status->restart_address,\n\t\t.length = ars_status->restart_length,\n\t\t.type = ars_status->type,\n\t};\n\trc = nd_desc->ndctl(nd_desc, NULL, ND_CMD_ARS_START, &ars_start,\n\t\t\tsizeof(ars_start), &cmd_rc);\n\tif (rc < 0)\n\t\treturn rc;\n\treturn cmd_rc;\n}\n\nstatic int ars_get_status(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc = &acpi_desc->nd_desc;\n\tstruct nd_cmd_ars_status *ars_status = acpi_desc->ars_status;\n\tint rc, cmd_rc;\n\n\trc = nd_desc->ndctl(nd_desc, NULL, ND_CMD_ARS_STATUS, ars_status,\n\t\t\tacpi_desc->max_ars, &cmd_rc);\n\tif (rc < 0)\n\t\treturn rc;\n\treturn cmd_rc;\n}\n\nstatic void ars_complete(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_spa *nfit_spa)\n{\n\tstruct nd_cmd_ars_status *ars_status = acpi_desc->ars_status;\n\tstruct acpi_nfit_system_address *spa = nfit_spa->spa;\n\tstruct nd_region *nd_region = nfit_spa->nd_region;\n\tstruct device *dev;\n\n\tlockdep_assert_held(&acpi_desc->init_mutex);\n\t \n\tif (acpi_desc->scrub_spa != nfit_spa)\n\t\treturn;\n\n\tif ((ars_status->address >= spa->address && ars_status->address\n\t\t\t\t< spa->address + spa->length)\n\t\t\t|| (ars_status->address < spa->address)) {\n\t\t \n\t\tif (ars_status->address + ars_status->length\n\t\t\t\t>= spa->address + spa->length)\n\t\t\t\t ;\n\t\telse\n\t\t\treturn;\n\t} else\n\t\treturn;\n\n\tacpi_desc->scrub_spa = NULL;\n\tif (nd_region) {\n\t\tdev = nd_region_dev(nd_region);\n\t\tnvdimm_region_notify(nd_region, NVDIMM_REVALIDATE_POISON);\n\t} else\n\t\tdev = acpi_desc->dev;\n\tdev_dbg(dev, \"ARS: range %d complete\\n\", spa->range_index);\n}\n\nstatic int ars_status_process_records(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nvdimm_bus *nvdimm_bus = acpi_desc->nvdimm_bus;\n\tstruct nd_cmd_ars_status *ars_status = acpi_desc->ars_status;\n\tint rc;\n\tu32 i;\n\n\t \n\tif (ars_status->out_length < 44)\n\t\treturn 0;\n\n\t \n\tif (!test_and_clear_bit(ARS_VALID, &acpi_desc->scrub_flags)) {\n\t\tdev_dbg(acpi_desc->dev, \"skip %d stale records\\n\",\n\t\t\t\tars_status->num_records);\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < ars_status->num_records; i++) {\n\t\t \n\t\tif (ars_status->out_length\n\t\t\t\t< 44 + sizeof(struct nd_ars_record) * (i + 1))\n\t\t\tbreak;\n\t\trc = nvdimm_bus_add_badrange(nvdimm_bus,\n\t\t\t\tars_status->records[i].err_address,\n\t\t\t\tars_status->records[i].length);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\tif (i < ars_status->num_records)\n\t\tdev_warn(acpi_desc->dev, \"detected truncated ars results\\n\");\n\n\treturn 0;\n}\n\nstatic void acpi_nfit_remove_resource(void *data)\n{\n\tstruct resource *res = data;\n\n\tremove_resource(res);\n}\n\nstatic int acpi_nfit_insert_resource(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nd_region_desc *ndr_desc)\n{\n\tstruct resource *res, *nd_res = ndr_desc->res;\n\tint is_pmem, ret;\n\n\t \n\tis_pmem = region_intersects(nd_res->start, resource_size(nd_res),\n\t\t\t\tIORESOURCE_MEM, IORES_DESC_PERSISTENT_MEMORY);\n\tif (is_pmem == REGION_INTERSECTS)\n\t\treturn 0;\n\n\tres = devm_kzalloc(acpi_desc->dev, sizeof(*res), GFP_KERNEL);\n\tif (!res)\n\t\treturn -ENOMEM;\n\n\tres->name = \"Persistent Memory\";\n\tres->start = nd_res->start;\n\tres->end = nd_res->end;\n\tres->flags = IORESOURCE_MEM;\n\tres->desc = IORES_DESC_PERSISTENT_MEMORY;\n\n\tret = insert_resource(&iomem_resource, res);\n\tif (ret)\n\t\treturn ret;\n\n\tret = devm_add_action_or_reset(acpi_desc->dev,\n\t\t\t\t\tacpi_nfit_remove_resource,\n\t\t\t\t\tres);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int acpi_nfit_init_mapping(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nd_mapping_desc *mapping, struct nd_region_desc *ndr_desc,\n\t\tstruct acpi_nfit_memory_map *memdev,\n\t\tstruct nfit_spa *nfit_spa)\n{\n\tstruct nvdimm *nvdimm = acpi_nfit_dimm_by_handle(acpi_desc,\n\t\t\tmemdev->device_handle);\n\tstruct acpi_nfit_system_address *spa = nfit_spa->spa;\n\n\tif (!nvdimm) {\n\t\tdev_err(acpi_desc->dev, \"spa%d dimm: %#x not found\\n\",\n\t\t\t\tspa->range_index, memdev->device_handle);\n\t\treturn -ENODEV;\n\t}\n\n\tmapping->nvdimm = nvdimm;\n\tswitch (nfit_spa_type(spa)) {\n\tcase NFIT_SPA_PM:\n\tcase NFIT_SPA_VOLATILE:\n\t\tmapping->start = memdev->address;\n\t\tmapping->size = memdev->region_size;\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic bool nfit_spa_is_virtual(struct acpi_nfit_system_address *spa)\n{\n\treturn (nfit_spa_type(spa) == NFIT_SPA_VDISK ||\n\t\tnfit_spa_type(spa) == NFIT_SPA_VCD   ||\n\t\tnfit_spa_type(spa) == NFIT_SPA_PDISK ||\n\t\tnfit_spa_type(spa) == NFIT_SPA_PCD);\n}\n\nstatic bool nfit_spa_is_volatile(struct acpi_nfit_system_address *spa)\n{\n\treturn (nfit_spa_type(spa) == NFIT_SPA_VDISK ||\n\t\tnfit_spa_type(spa) == NFIT_SPA_VCD   ||\n\t\tnfit_spa_type(spa) == NFIT_SPA_VOLATILE);\n}\n\nstatic int acpi_nfit_register_region(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_spa *nfit_spa)\n{\n\tstatic struct nd_mapping_desc mappings[ND_MAX_MAPPINGS];\n\tstruct acpi_nfit_system_address *spa = nfit_spa->spa;\n\tstruct nd_region_desc *ndr_desc, _ndr_desc;\n\tstruct nfit_memdev *nfit_memdev;\n\tstruct nvdimm_bus *nvdimm_bus;\n\tstruct resource res;\n\tint count = 0, rc;\n\n\tif (nfit_spa->nd_region)\n\t\treturn 0;\n\n\tif (spa->range_index == 0 && !nfit_spa_is_virtual(spa)) {\n\t\tdev_dbg(acpi_desc->dev, \"detected invalid spa index\\n\");\n\t\treturn 0;\n\t}\n\n\tmemset(&res, 0, sizeof(res));\n\tmemset(&mappings, 0, sizeof(mappings));\n\tmemset(&_ndr_desc, 0, sizeof(_ndr_desc));\n\tres.start = spa->address;\n\tres.end = res.start + spa->length - 1;\n\tndr_desc = &_ndr_desc;\n\tndr_desc->res = &res;\n\tndr_desc->provider_data = nfit_spa;\n\tndr_desc->attr_groups = acpi_nfit_region_attribute_groups;\n\tif (spa->flags & ACPI_NFIT_PROXIMITY_VALID) {\n\t\tndr_desc->numa_node = pxm_to_online_node(spa->proximity_domain);\n\t\tndr_desc->target_node = pxm_to_node(spa->proximity_domain);\n\t} else {\n\t\tndr_desc->numa_node = NUMA_NO_NODE;\n\t\tndr_desc->target_node = NUMA_NO_NODE;\n\t}\n\n\t \n\tif (ndr_desc->numa_node == NUMA_NO_NODE) {\n\t\tndr_desc->numa_node = memory_add_physaddr_to_nid(spa->address);\n\t\tdev_info(acpi_desc->dev, \"changing numa node from %d to %d for nfit region [%pa-%pa]\",\n\t\t\tNUMA_NO_NODE, ndr_desc->numa_node, &res.start, &res.end);\n\t}\n\tif (ndr_desc->target_node == NUMA_NO_NODE) {\n\t\tndr_desc->target_node = phys_to_target_node(spa->address);\n\t\tdev_info(acpi_desc->dev, \"changing target node from %d to %d for nfit region [%pa-%pa]\",\n\t\t\tNUMA_NO_NODE, ndr_desc->numa_node, &res.start, &res.end);\n\t}\n\n\t \n\tif (acpi_desc->platform_cap & ACPI_NFIT_CAPABILITY_CACHE_FLUSH)\n\t\tset_bit(ND_REGION_PERSIST_CACHE, &ndr_desc->flags);\n\telse if (acpi_desc->platform_cap & ACPI_NFIT_CAPABILITY_MEM_FLUSH)\n\t\tset_bit(ND_REGION_PERSIST_MEMCTRL, &ndr_desc->flags);\n\n\tlist_for_each_entry(nfit_memdev, &acpi_desc->memdevs, list) {\n\t\tstruct acpi_nfit_memory_map *memdev = nfit_memdev->memdev;\n\t\tstruct nd_mapping_desc *mapping;\n\n\t\t \n\t\tif (memdev->range_index == 0 || spa->range_index == 0)\n\t\t\tcontinue;\n\t\tif (memdev->range_index != spa->range_index)\n\t\t\tcontinue;\n\t\tif (count >= ND_MAX_MAPPINGS) {\n\t\t\tdev_err(acpi_desc->dev, \"spa%d exceeds max mappings %d\\n\",\n\t\t\t\t\tspa->range_index, ND_MAX_MAPPINGS);\n\t\t\treturn -ENXIO;\n\t\t}\n\t\tmapping = &mappings[count++];\n\t\trc = acpi_nfit_init_mapping(acpi_desc, mapping, ndr_desc,\n\t\t\t\tmemdev, nfit_spa);\n\t\tif (rc)\n\t\t\tgoto out;\n\t}\n\n\tndr_desc->mapping = mappings;\n\tndr_desc->num_mappings = count;\n\trc = acpi_nfit_init_interleave_set(acpi_desc, ndr_desc, spa);\n\tif (rc)\n\t\tgoto out;\n\n\tnvdimm_bus = acpi_desc->nvdimm_bus;\n\tif (nfit_spa_type(spa) == NFIT_SPA_PM) {\n\t\trc = acpi_nfit_insert_resource(acpi_desc, ndr_desc);\n\t\tif (rc) {\n\t\t\tdev_warn(acpi_desc->dev,\n\t\t\t\t\"failed to insert pmem resource to iomem: %d\\n\",\n\t\t\t\trc);\n\t\t\tgoto out;\n\t\t}\n\n\t\tnfit_spa->nd_region = nvdimm_pmem_region_create(nvdimm_bus,\n\t\t\t\tndr_desc);\n\t\tif (!nfit_spa->nd_region)\n\t\t\trc = -ENOMEM;\n\t} else if (nfit_spa_is_volatile(spa)) {\n\t\tnfit_spa->nd_region = nvdimm_volatile_region_create(nvdimm_bus,\n\t\t\t\tndr_desc);\n\t\tif (!nfit_spa->nd_region)\n\t\t\trc = -ENOMEM;\n\t} else if (nfit_spa_is_virtual(spa)) {\n\t\tnfit_spa->nd_region = nvdimm_pmem_region_create(nvdimm_bus,\n\t\t\t\tndr_desc);\n\t\tif (!nfit_spa->nd_region)\n\t\t\trc = -ENOMEM;\n\t}\n\n out:\n\tif (rc)\n\t\tdev_err(acpi_desc->dev, \"failed to register spa range %d\\n\",\n\t\t\t\tnfit_spa->spa->range_index);\n\treturn rc;\n}\n\nstatic int ars_status_alloc(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nd_cmd_ars_status *ars_status;\n\n\tif (acpi_desc->ars_status) {\n\t\tmemset(acpi_desc->ars_status, 0, acpi_desc->max_ars);\n\t\treturn 0;\n\t}\n\n\tars_status = devm_kzalloc(dev, acpi_desc->max_ars, GFP_KERNEL);\n\tif (!ars_status)\n\t\treturn -ENOMEM;\n\tacpi_desc->ars_status = ars_status;\n\treturn 0;\n}\n\nstatic int acpi_nfit_query_poison(struct acpi_nfit_desc *acpi_desc)\n{\n\tint rc;\n\n\tif (ars_status_alloc(acpi_desc))\n\t\treturn -ENOMEM;\n\n\trc = ars_get_status(acpi_desc);\n\n\tif (rc < 0 && rc != -ENOSPC)\n\t\treturn rc;\n\n\tif (ars_status_process_records(acpi_desc))\n\t\tdev_err(acpi_desc->dev, \"Failed to process ARS records\\n\");\n\n\treturn rc;\n}\n\nstatic int ars_register(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_spa *nfit_spa)\n{\n\tint rc;\n\n\tif (test_bit(ARS_FAILED, &nfit_spa->ars_state))\n\t\treturn acpi_nfit_register_region(acpi_desc, nfit_spa);\n\n\tset_bit(ARS_REQ_SHORT, &nfit_spa->ars_state);\n\tif (!no_init_ars)\n\t\tset_bit(ARS_REQ_LONG, &nfit_spa->ars_state);\n\n\tswitch (acpi_nfit_query_poison(acpi_desc)) {\n\tcase 0:\n\tcase -ENOSPC:\n\tcase -EAGAIN:\n\t\trc = ars_start(acpi_desc, nfit_spa, ARS_REQ_SHORT);\n\t\t \n\t\tif (rc == -EBUSY)\n\t\t\tbreak;\n\t\tif (rc) {\n\t\t\tset_bit(ARS_FAILED, &nfit_spa->ars_state);\n\t\t\tbreak;\n\t\t}\n\t\tclear_bit(ARS_REQ_SHORT, &nfit_spa->ars_state);\n\t\trc = acpi_nfit_query_poison(acpi_desc);\n\t\tif (rc)\n\t\t\tbreak;\n\t\tacpi_desc->scrub_spa = nfit_spa;\n\t\tars_complete(acpi_desc, nfit_spa);\n\t\t \n\t\tacpi_desc->scrub_spa = NULL;\n\t\tbreak;\n\tcase -EBUSY:\n\tcase -ENOMEM:\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tset_bit(ARS_FAILED, &nfit_spa->ars_state);\n\t\tbreak;\n\t}\n\n\treturn acpi_nfit_register_region(acpi_desc, nfit_spa);\n}\n\nstatic void ars_complete_all(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nfit_spa *nfit_spa;\n\n\tlist_for_each_entry(nfit_spa, &acpi_desc->spas, list) {\n\t\tif (test_bit(ARS_FAILED, &nfit_spa->ars_state))\n\t\t\tcontinue;\n\t\tars_complete(acpi_desc, nfit_spa);\n\t}\n}\n\nstatic unsigned int __acpi_nfit_scrub(struct acpi_nfit_desc *acpi_desc,\n\t\tint query_rc)\n{\n\tunsigned int tmo = acpi_desc->scrub_tmo;\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_spa *nfit_spa;\n\n\tlockdep_assert_held(&acpi_desc->init_mutex);\n\n\tif (test_bit(ARS_CANCEL, &acpi_desc->scrub_flags))\n\t\treturn 0;\n\n\tif (query_rc == -EBUSY) {\n\t\tdev_dbg(dev, \"ARS: ARS busy\\n\");\n\t\treturn min(30U * 60U, tmo * 2);\n\t}\n\tif (query_rc == -ENOSPC) {\n\t\tdev_dbg(dev, \"ARS: ARS continue\\n\");\n\t\tars_continue(acpi_desc);\n\t\treturn 1;\n\t}\n\tif (query_rc && query_rc != -EAGAIN) {\n\t\tunsigned long long addr, end;\n\n\t\taddr = acpi_desc->ars_status->address;\n\t\tend = addr + acpi_desc->ars_status->length;\n\t\tdev_dbg(dev, \"ARS: %llx-%llx failed (%d)\\n\", addr, end,\n\t\t\t\tquery_rc);\n\t}\n\n\tars_complete_all(acpi_desc);\n\tlist_for_each_entry(nfit_spa, &acpi_desc->spas, list) {\n\t\tenum nfit_ars_state req_type;\n\t\tint rc;\n\n\t\tif (test_bit(ARS_FAILED, &nfit_spa->ars_state))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (test_bit(ARS_REQ_SHORT, &nfit_spa->ars_state))\n\t\t\treq_type = ARS_REQ_SHORT;\n\t\telse if (test_bit(ARS_REQ_LONG, &nfit_spa->ars_state))\n\t\t\treq_type = ARS_REQ_LONG;\n\t\telse\n\t\t\tcontinue;\n\t\trc = ars_start(acpi_desc, nfit_spa, req_type);\n\n\t\tdev = nd_region_dev(nfit_spa->nd_region);\n\t\tdev_dbg(dev, \"ARS: range %d ARS start %s (%d)\\n\",\n\t\t\t\tnfit_spa->spa->range_index,\n\t\t\t\treq_type == ARS_REQ_SHORT ? \"short\" : \"long\",\n\t\t\t\trc);\n\t\t \n\t\tif (rc == -EBUSY)\n\t\t\treturn 1;\n\t\tif (rc == 0) {\n\t\t\tdev_WARN_ONCE(dev, acpi_desc->scrub_spa,\n\t\t\t\t\t\"scrub start while range %d active\\n\",\n\t\t\t\t\tacpi_desc->scrub_spa->spa->range_index);\n\t\t\tclear_bit(req_type, &nfit_spa->ars_state);\n\t\t\tacpi_desc->scrub_spa = nfit_spa;\n\t\t\t \n\t\t\tlist_move_tail(&nfit_spa->list, &acpi_desc->spas);\n\t\t\treturn 1;\n\t\t}\n\n\t\tdev_err(dev, \"ARS: range %d ARS failed (%d)\\n\",\n\t\t\t\tnfit_spa->spa->range_index, rc);\n\t\tset_bit(ARS_FAILED, &nfit_spa->ars_state);\n\t}\n\treturn 0;\n}\n\nstatic void __sched_ars(struct acpi_nfit_desc *acpi_desc, unsigned int tmo)\n{\n\tlockdep_assert_held(&acpi_desc->init_mutex);\n\n\tset_bit(ARS_BUSY, &acpi_desc->scrub_flags);\n\t \n\tif (tmo)\n\t\tacpi_desc->scrub_tmo = tmo;\n\tqueue_delayed_work(nfit_wq, &acpi_desc->dwork, tmo * HZ);\n}\n\nstatic void sched_ars(struct acpi_nfit_desc *acpi_desc)\n{\n\t__sched_ars(acpi_desc, 0);\n}\n\nstatic void notify_ars_done(struct acpi_nfit_desc *acpi_desc)\n{\n\tlockdep_assert_held(&acpi_desc->init_mutex);\n\n\tclear_bit(ARS_BUSY, &acpi_desc->scrub_flags);\n\tacpi_desc->scrub_count++;\n\tif (acpi_desc->scrub_count_state)\n\t\tsysfs_notify_dirent(acpi_desc->scrub_count_state);\n}\n\nstatic void acpi_nfit_scrub(struct work_struct *work)\n{\n\tstruct acpi_nfit_desc *acpi_desc;\n\tunsigned int tmo;\n\tint query_rc;\n\n\tacpi_desc = container_of(work, typeof(*acpi_desc), dwork.work);\n\tmutex_lock(&acpi_desc->init_mutex);\n\tquery_rc = acpi_nfit_query_poison(acpi_desc);\n\ttmo = __acpi_nfit_scrub(acpi_desc, query_rc);\n\tif (tmo)\n\t\t__sched_ars(acpi_desc, tmo);\n\telse\n\t\tnotify_ars_done(acpi_desc);\n\tmemset(acpi_desc->ars_status, 0, acpi_desc->max_ars);\n\tclear_bit(ARS_POLL, &acpi_desc->scrub_flags);\n\tmutex_unlock(&acpi_desc->init_mutex);\n}\n\nstatic void acpi_nfit_init_ars(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_spa *nfit_spa)\n{\n\tint type = nfit_spa_type(nfit_spa->spa);\n\tstruct nd_cmd_ars_cap ars_cap;\n\tint rc;\n\n\tset_bit(ARS_FAILED, &nfit_spa->ars_state);\n\tmemset(&ars_cap, 0, sizeof(ars_cap));\n\trc = ars_get_cap(acpi_desc, &ars_cap, nfit_spa);\n\tif (rc < 0)\n\t\treturn;\n\t \n\tif (type == NFIT_SPA_VOLATILE && ((ars_cap.status >> 16)\n\t\t\t\t& ND_ARS_VOLATILE) == 0)\n\t\treturn;\n\tif (type == NFIT_SPA_PM && ((ars_cap.status >> 16)\n\t\t\t\t& ND_ARS_PERSISTENT) == 0)\n\t\treturn;\n\n\tnfit_spa->max_ars = ars_cap.max_ars_out;\n\tnfit_spa->clear_err_unit = ars_cap.clear_err_unit;\n\tacpi_desc->max_ars = max(nfit_spa->max_ars, acpi_desc->max_ars);\n\tclear_bit(ARS_FAILED, &nfit_spa->ars_state);\n}\n\nstatic int acpi_nfit_register_regions(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct nfit_spa *nfit_spa;\n\tint rc, do_sched_ars = 0;\n\n\tset_bit(ARS_VALID, &acpi_desc->scrub_flags);\n\tlist_for_each_entry(nfit_spa, &acpi_desc->spas, list) {\n\t\tswitch (nfit_spa_type(nfit_spa->spa)) {\n\t\tcase NFIT_SPA_VOLATILE:\n\t\tcase NFIT_SPA_PM:\n\t\t\tacpi_nfit_init_ars(acpi_desc, nfit_spa);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tlist_for_each_entry(nfit_spa, &acpi_desc->spas, list) {\n\t\tswitch (nfit_spa_type(nfit_spa->spa)) {\n\t\tcase NFIT_SPA_VOLATILE:\n\t\tcase NFIT_SPA_PM:\n\t\t\t \n\t\t\trc = ars_register(acpi_desc, nfit_spa);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\n\t\t\t \n\t\t\tif (!test_bit(ARS_FAILED, &nfit_spa->ars_state))\n\t\t\t\tdo_sched_ars++;\n\t\t\tbreak;\n\t\tcase NFIT_SPA_BDW:\n\t\t\t \n\t\t\tbreak;\n\t\tcase NFIT_SPA_DCR:\n\t\tcase NFIT_SPA_VDISK:\n\t\tcase NFIT_SPA_VCD:\n\t\tcase NFIT_SPA_PDISK:\n\t\tcase NFIT_SPA_PCD:\n\t\t\t \n\t\t\trc = acpi_nfit_register_region(acpi_desc, nfit_spa);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (do_sched_ars)\n\t\tsched_ars(acpi_desc);\n\treturn 0;\n}\n\nstatic int acpi_nfit_check_deletions(struct acpi_nfit_desc *acpi_desc,\n\t\tstruct nfit_table_prev *prev)\n{\n\tstruct device *dev = acpi_desc->dev;\n\n\tif (!list_empty(&prev->spas) ||\n\t\t\t!list_empty(&prev->memdevs) ||\n\t\t\t!list_empty(&prev->dcrs) ||\n\t\t\t!list_empty(&prev->bdws) ||\n\t\t\t!list_empty(&prev->idts) ||\n\t\t\t!list_empty(&prev->flushes)) {\n\t\tdev_err(dev, \"new nfit deletes entries (unsupported)\\n\");\n\t\treturn -ENXIO;\n\t}\n\treturn 0;\n}\n\nstatic int acpi_nfit_desc_init_scrub_attr(struct acpi_nfit_desc *acpi_desc)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct kernfs_node *nfit;\n\tstruct device *bus_dev;\n\n\tif (!ars_supported(acpi_desc->nvdimm_bus))\n\t\treturn 0;\n\n\tbus_dev = to_nvdimm_bus_dev(acpi_desc->nvdimm_bus);\n\tnfit = sysfs_get_dirent(bus_dev->kobj.sd, \"nfit\");\n\tif (!nfit) {\n\t\tdev_err(dev, \"sysfs_get_dirent 'nfit' failed\\n\");\n\t\treturn -ENODEV;\n\t}\n\tacpi_desc->scrub_count_state = sysfs_get_dirent(nfit, \"scrub\");\n\tsysfs_put(nfit);\n\tif (!acpi_desc->scrub_count_state) {\n\t\tdev_err(dev, \"sysfs_get_dirent 'scrub' failed\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n\nstatic void acpi_nfit_unregister(void *data)\n{\n\tstruct acpi_nfit_desc *acpi_desc = data;\n\n\tnvdimm_bus_unregister(acpi_desc->nvdimm_bus);\n}\n\nint acpi_nfit_init(struct acpi_nfit_desc *acpi_desc, void *data, acpi_size sz)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tstruct nfit_table_prev prev;\n\tconst void *end;\n\tint rc;\n\n\tif (!acpi_desc->nvdimm_bus) {\n\t\tacpi_nfit_init_dsms(acpi_desc);\n\n\t\tacpi_desc->nvdimm_bus = nvdimm_bus_register(dev,\n\t\t\t\t&acpi_desc->nd_desc);\n\t\tif (!acpi_desc->nvdimm_bus)\n\t\t\treturn -ENOMEM;\n\n\t\trc = devm_add_action_or_reset(dev, acpi_nfit_unregister,\n\t\t\t\tacpi_desc);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\trc = acpi_nfit_desc_init_scrub_attr(acpi_desc);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\tmutex_lock(&acpi_desc_lock);\n\t\tlist_add_tail(&acpi_desc->list, &acpi_descs);\n\t\tmutex_unlock(&acpi_desc_lock);\n\t}\n\n\tmutex_lock(&acpi_desc->init_mutex);\n\n\tINIT_LIST_HEAD(&prev.spas);\n\tINIT_LIST_HEAD(&prev.memdevs);\n\tINIT_LIST_HEAD(&prev.dcrs);\n\tINIT_LIST_HEAD(&prev.bdws);\n\tINIT_LIST_HEAD(&prev.idts);\n\tINIT_LIST_HEAD(&prev.flushes);\n\n\tlist_cut_position(&prev.spas, &acpi_desc->spas,\n\t\t\t\tacpi_desc->spas.prev);\n\tlist_cut_position(&prev.memdevs, &acpi_desc->memdevs,\n\t\t\t\tacpi_desc->memdevs.prev);\n\tlist_cut_position(&prev.dcrs, &acpi_desc->dcrs,\n\t\t\t\tacpi_desc->dcrs.prev);\n\tlist_cut_position(&prev.bdws, &acpi_desc->bdws,\n\t\t\t\tacpi_desc->bdws.prev);\n\tlist_cut_position(&prev.idts, &acpi_desc->idts,\n\t\t\t\tacpi_desc->idts.prev);\n\tlist_cut_position(&prev.flushes, &acpi_desc->flushes,\n\t\t\t\tacpi_desc->flushes.prev);\n\n\tend = data + sz;\n\twhile (!IS_ERR_OR_NULL(data))\n\t\tdata = add_table(acpi_desc, &prev, data, end);\n\n\tif (IS_ERR(data)) {\n\t\tdev_dbg(dev, \"nfit table parsing error: %ld\\n\",\tPTR_ERR(data));\n\t\trc = PTR_ERR(data);\n\t\tgoto out_unlock;\n\t}\n\n\trc = acpi_nfit_check_deletions(acpi_desc, &prev);\n\tif (rc)\n\t\tgoto out_unlock;\n\n\trc = nfit_mem_init(acpi_desc);\n\tif (rc)\n\t\tgoto out_unlock;\n\n\trc = acpi_nfit_register_dimms(acpi_desc);\n\tif (rc)\n\t\tgoto out_unlock;\n\n\trc = acpi_nfit_register_regions(acpi_desc);\n\n out_unlock:\n\tmutex_unlock(&acpi_desc->init_mutex);\n\treturn rc;\n}\nEXPORT_SYMBOL_GPL(acpi_nfit_init);\n\nstatic int acpi_nfit_flush_probe(struct nvdimm_bus_descriptor *nd_desc)\n{\n\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\tstruct device *dev = acpi_desc->dev;\n\n\t \n\tdevice_lock(dev);\n\tdevice_unlock(dev);\n\n\t \n\tmutex_lock(&acpi_desc->init_mutex);\n\tmutex_unlock(&acpi_desc->init_mutex);\n\n\treturn 0;\n}\n\nstatic int __acpi_nfit_clear_to_send(struct nvdimm_bus_descriptor *nd_desc,\n\t\tstruct nvdimm *nvdimm, unsigned int cmd)\n{\n\tstruct acpi_nfit_desc *acpi_desc = to_acpi_desc(nd_desc);\n\n\tif (nvdimm)\n\t\treturn 0;\n\tif (cmd != ND_CMD_ARS_START)\n\t\treturn 0;\n\n\t \n\tif (work_busy(&acpi_desc->dwork.work))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\n \nstatic int acpi_nfit_clear_to_send(struct nvdimm_bus_descriptor *nd_desc,\n\t\tstruct nvdimm *nvdimm, unsigned int cmd, void *buf)\n{\n\tstruct nd_cmd_pkg *call_pkg = buf;\n\tunsigned int func;\n\n\tif (nvdimm && cmd == ND_CMD_CALL &&\n\t\t\tcall_pkg->nd_family == NVDIMM_FAMILY_INTEL) {\n\t\tfunc = call_pkg->nd_command;\n\t\tif (func > NVDIMM_CMD_MAX ||\n\t\t    (1 << func) & NVDIMM_INTEL_DENY_CMDMASK)\n\t\t\treturn -EOPNOTSUPP;\n\t}\n\n\t \n\tif (!nvdimm && cmd == ND_CMD_CALL &&\n\t\t\tcall_pkg->nd_family != NVDIMM_BUS_FAMILY_NFIT)\n\t\treturn -EOPNOTSUPP;\n\n\treturn __acpi_nfit_clear_to_send(nd_desc, nvdimm, cmd);\n}\n\nint acpi_nfit_ars_rescan(struct acpi_nfit_desc *acpi_desc,\n\t\tenum nfit_ars_state req_type)\n{\n\tstruct device *dev = acpi_desc->dev;\n\tint scheduled = 0, busy = 0;\n\tstruct nfit_spa *nfit_spa;\n\n\tmutex_lock(&acpi_desc->init_mutex);\n\tif (test_bit(ARS_CANCEL, &acpi_desc->scrub_flags)) {\n\t\tmutex_unlock(&acpi_desc->init_mutex);\n\t\treturn 0;\n\t}\n\n\tlist_for_each_entry(nfit_spa, &acpi_desc->spas, list) {\n\t\tint type = nfit_spa_type(nfit_spa->spa);\n\n\t\tif (type != NFIT_SPA_PM && type != NFIT_SPA_VOLATILE)\n\t\t\tcontinue;\n\t\tif (test_bit(ARS_FAILED, &nfit_spa->ars_state))\n\t\t\tcontinue;\n\n\t\tif (test_and_set_bit(req_type, &nfit_spa->ars_state))\n\t\t\tbusy++;\n\t\telse\n\t\t\tscheduled++;\n\t}\n\tif (scheduled) {\n\t\tsched_ars(acpi_desc);\n\t\tdev_dbg(dev, \"ars_scan triggered\\n\");\n\t}\n\tmutex_unlock(&acpi_desc->init_mutex);\n\n\tif (scheduled)\n\t\treturn 0;\n\tif (busy)\n\t\treturn -EBUSY;\n\treturn -ENOTTY;\n}\n\nvoid acpi_nfit_desc_init(struct acpi_nfit_desc *acpi_desc, struct device *dev)\n{\n\tstruct nvdimm_bus_descriptor *nd_desc;\n\n\tdev_set_drvdata(dev, acpi_desc);\n\tacpi_desc->dev = dev;\n\tnd_desc = &acpi_desc->nd_desc;\n\tnd_desc->provider_name = \"ACPI.NFIT\";\n\tnd_desc->module = THIS_MODULE;\n\tnd_desc->ndctl = acpi_nfit_ctl;\n\tnd_desc->flush_probe = acpi_nfit_flush_probe;\n\tnd_desc->clear_to_send = acpi_nfit_clear_to_send;\n\tnd_desc->attr_groups = acpi_nfit_attribute_groups;\n\n\tINIT_LIST_HEAD(&acpi_desc->spas);\n\tINIT_LIST_HEAD(&acpi_desc->dcrs);\n\tINIT_LIST_HEAD(&acpi_desc->bdws);\n\tINIT_LIST_HEAD(&acpi_desc->idts);\n\tINIT_LIST_HEAD(&acpi_desc->flushes);\n\tINIT_LIST_HEAD(&acpi_desc->memdevs);\n\tINIT_LIST_HEAD(&acpi_desc->dimms);\n\tINIT_LIST_HEAD(&acpi_desc->list);\n\tmutex_init(&acpi_desc->init_mutex);\n\tacpi_desc->scrub_tmo = 1;\n\tINIT_DELAYED_WORK(&acpi_desc->dwork, acpi_nfit_scrub);\n}\nEXPORT_SYMBOL_GPL(acpi_nfit_desc_init);\n\nstatic void acpi_nfit_put_table(void *table)\n{\n\tacpi_put_table(table);\n}\n\nstatic void acpi_nfit_notify(acpi_handle handle, u32 event, void *data)\n{\n\tstruct acpi_device *adev = data;\n\n\tdevice_lock(&adev->dev);\n\t__acpi_nfit_notify(&adev->dev, handle, event);\n\tdevice_unlock(&adev->dev);\n}\n\nstatic void acpi_nfit_remove_notify_handler(void *data)\n{\n\tstruct acpi_device *adev = data;\n\n\tacpi_dev_remove_notify_handler(adev, ACPI_DEVICE_NOTIFY,\n\t\t\t\t       acpi_nfit_notify);\n}\n\nvoid acpi_nfit_shutdown(void *data)\n{\n\tstruct acpi_nfit_desc *acpi_desc = data;\n\tstruct device *bus_dev = to_nvdimm_bus_dev(acpi_desc->nvdimm_bus);\n\n\t \n\tmutex_lock(&acpi_desc_lock);\n\tlist_del(&acpi_desc->list);\n\tmutex_unlock(&acpi_desc_lock);\n\n\tmutex_lock(&acpi_desc->init_mutex);\n\tset_bit(ARS_CANCEL, &acpi_desc->scrub_flags);\n\tmutex_unlock(&acpi_desc->init_mutex);\n\tcancel_delayed_work_sync(&acpi_desc->dwork);\n\n\t \n\tdevice_lock(bus_dev);\n\tdevice_unlock(bus_dev);\n\n\tflush_workqueue(nfit_wq);\n}\nEXPORT_SYMBOL_GPL(acpi_nfit_shutdown);\n\nstatic int acpi_nfit_add(struct acpi_device *adev)\n{\n\tstruct acpi_buffer buf = { ACPI_ALLOCATE_BUFFER, NULL };\n\tstruct acpi_nfit_desc *acpi_desc;\n\tstruct device *dev = &adev->dev;\n\tstruct acpi_table_header *tbl;\n\tacpi_status status = AE_OK;\n\tacpi_size sz;\n\tint rc = 0;\n\n\trc = acpi_dev_install_notify_handler(adev, ACPI_DEVICE_NOTIFY,\n\t\t\t\t\t     acpi_nfit_notify);\n\tif (rc)\n\t\treturn rc;\n\n\trc = devm_add_action_or_reset(dev, acpi_nfit_remove_notify_handler,\n\t\t\t\t\tadev);\n\tif (rc)\n\t\treturn rc;\n\n\tstatus = acpi_get_table(ACPI_SIG_NFIT, 0, &tbl);\n\tif (ACPI_FAILURE(status)) {\n\t\t \n\t\tdev_dbg(dev, \"failed to find NFIT at startup\\n\");\n\t\treturn 0;\n\t}\n\n\trc = devm_add_action_or_reset(dev, acpi_nfit_put_table, tbl);\n\tif (rc)\n\t\treturn rc;\n\tsz = tbl->length;\n\n\tacpi_desc = devm_kzalloc(dev, sizeof(*acpi_desc), GFP_KERNEL);\n\tif (!acpi_desc)\n\t\treturn -ENOMEM;\n\tacpi_nfit_desc_init(acpi_desc, &adev->dev);\n\n\t \n\tacpi_desc->acpi_header = *tbl;\n\n\t \n\tstatus = acpi_evaluate_object(adev->handle, \"_FIT\", NULL, &buf);\n\tif (ACPI_SUCCESS(status) && buf.length > 0) {\n\t\tunion acpi_object *obj = buf.pointer;\n\n\t\tif (obj->type == ACPI_TYPE_BUFFER)\n\t\t\trc = acpi_nfit_init(acpi_desc, obj->buffer.pointer,\n\t\t\t\t\tobj->buffer.length);\n\t\telse\n\t\t\tdev_dbg(dev, \"invalid type %d, ignoring _FIT\\n\",\n\t\t\t\t(int) obj->type);\n\t\tkfree(buf.pointer);\n\t} else\n\t\t \n\t\trc = acpi_nfit_init(acpi_desc, (void *) tbl\n\t\t\t\t+ sizeof(struct acpi_table_nfit),\n\t\t\t\tsz - sizeof(struct acpi_table_nfit));\n\n\tif (rc)\n\t\treturn rc;\n\n\treturn devm_add_action_or_reset(dev, acpi_nfit_shutdown, acpi_desc);\n}\n\nstatic void acpi_nfit_update_notify(struct device *dev, acpi_handle handle)\n{\n\tstruct acpi_nfit_desc *acpi_desc = dev_get_drvdata(dev);\n\tstruct acpi_buffer buf = { ACPI_ALLOCATE_BUFFER, NULL };\n\tunion acpi_object *obj;\n\tacpi_status status;\n\tint ret;\n\n\tif (!dev->driver) {\n\t\t \n\t\tdev_dbg(dev, \"no driver found for dev\\n\");\n\t\treturn;\n\t}\n\n\tif (!acpi_desc) {\n\t\tacpi_desc = devm_kzalloc(dev, sizeof(*acpi_desc), GFP_KERNEL);\n\t\tif (!acpi_desc)\n\t\t\treturn;\n\t\tacpi_nfit_desc_init(acpi_desc, dev);\n\t} else {\n\t\t \n\t\tflush_workqueue(nfit_wq);\n\t}\n\n\t \n\tstatus = acpi_evaluate_object(handle, \"_FIT\", NULL, &buf);\n\tif (ACPI_FAILURE(status)) {\n\t\tdev_err(dev, \"failed to evaluate _FIT\\n\");\n\t\treturn;\n\t}\n\n\tobj = buf.pointer;\n\tif (obj->type == ACPI_TYPE_BUFFER) {\n\t\tret = acpi_nfit_init(acpi_desc, obj->buffer.pointer,\n\t\t\t\tobj->buffer.length);\n\t\tif (ret)\n\t\t\tdev_err(dev, \"failed to merge updated NFIT\\n\");\n\t} else\n\t\tdev_err(dev, \"Invalid _FIT\\n\");\n\tkfree(buf.pointer);\n}\n\nstatic void acpi_nfit_uc_error_notify(struct device *dev, acpi_handle handle)\n{\n\tstruct acpi_nfit_desc *acpi_desc = dev_get_drvdata(dev);\n\n\tif (acpi_desc->scrub_mode == HW_ERROR_SCRUB_ON)\n\t\tacpi_nfit_ars_rescan(acpi_desc, ARS_REQ_LONG);\n\telse\n\t\tacpi_nfit_ars_rescan(acpi_desc, ARS_REQ_SHORT);\n}\n\nvoid __acpi_nfit_notify(struct device *dev, acpi_handle handle, u32 event)\n{\n\tdev_dbg(dev, \"event: 0x%x\\n\", event);\n\n\tswitch (event) {\n\tcase NFIT_NOTIFY_UPDATE:\n\t\treturn acpi_nfit_update_notify(dev, handle);\n\tcase NFIT_NOTIFY_UC_MEMORY_ERROR:\n\t\treturn acpi_nfit_uc_error_notify(dev, handle);\n\tdefault:\n\t\treturn;\n\t}\n}\nEXPORT_SYMBOL_GPL(__acpi_nfit_notify);\n\nstatic const struct acpi_device_id acpi_nfit_ids[] = {\n\t{ \"ACPI0012\", 0 },\n\t{ \"\", 0 },\n};\nMODULE_DEVICE_TABLE(acpi, acpi_nfit_ids);\n\nstatic struct acpi_driver acpi_nfit_driver = {\n\t.name = KBUILD_MODNAME,\n\t.ids = acpi_nfit_ids,\n\t.ops = {\n\t\t.add = acpi_nfit_add,\n\t},\n};\n\nstatic __init int nfit_init(void)\n{\n\tint ret;\n\n\tBUILD_BUG_ON(sizeof(struct acpi_table_nfit) != 40);\n\tBUILD_BUG_ON(sizeof(struct acpi_nfit_system_address) != 64);\n\tBUILD_BUG_ON(sizeof(struct acpi_nfit_memory_map) != 48);\n\tBUILD_BUG_ON(sizeof(struct acpi_nfit_interleave) != 16);\n\tBUILD_BUG_ON(sizeof(struct acpi_nfit_smbios) != 8);\n\tBUILD_BUG_ON(sizeof(struct acpi_nfit_control_region) != 80);\n\tBUILD_BUG_ON(sizeof(struct acpi_nfit_data_region) != 40);\n\tBUILD_BUG_ON(sizeof(struct acpi_nfit_capabilities) != 16);\n\n\tguid_parse(UUID_VOLATILE_MEMORY, &nfit_uuid[NFIT_SPA_VOLATILE]);\n\tguid_parse(UUID_PERSISTENT_MEMORY, &nfit_uuid[NFIT_SPA_PM]);\n\tguid_parse(UUID_CONTROL_REGION, &nfit_uuid[NFIT_SPA_DCR]);\n\tguid_parse(UUID_DATA_REGION, &nfit_uuid[NFIT_SPA_BDW]);\n\tguid_parse(UUID_VOLATILE_VIRTUAL_DISK, &nfit_uuid[NFIT_SPA_VDISK]);\n\tguid_parse(UUID_VOLATILE_VIRTUAL_CD, &nfit_uuid[NFIT_SPA_VCD]);\n\tguid_parse(UUID_PERSISTENT_VIRTUAL_DISK, &nfit_uuid[NFIT_SPA_PDISK]);\n\tguid_parse(UUID_PERSISTENT_VIRTUAL_CD, &nfit_uuid[NFIT_SPA_PCD]);\n\tguid_parse(UUID_NFIT_BUS, &nfit_uuid[NFIT_DEV_BUS]);\n\tguid_parse(UUID_NFIT_DIMM, &nfit_uuid[NFIT_DEV_DIMM]);\n\tguid_parse(UUID_NFIT_DIMM_N_HPE1, &nfit_uuid[NFIT_DEV_DIMM_N_HPE1]);\n\tguid_parse(UUID_NFIT_DIMM_N_HPE2, &nfit_uuid[NFIT_DEV_DIMM_N_HPE2]);\n\tguid_parse(UUID_NFIT_DIMM_N_MSFT, &nfit_uuid[NFIT_DEV_DIMM_N_MSFT]);\n\tguid_parse(UUID_NFIT_DIMM_N_HYPERV, &nfit_uuid[NFIT_DEV_DIMM_N_HYPERV]);\n\tguid_parse(UUID_INTEL_BUS, &nfit_uuid[NFIT_BUS_INTEL]);\n\n\tnfit_wq = create_singlethread_workqueue(\"nfit\");\n\tif (!nfit_wq)\n\t\treturn -ENOMEM;\n\n\tnfit_mce_register();\n\tret = acpi_bus_register_driver(&acpi_nfit_driver);\n\tif (ret) {\n\t\tnfit_mce_unregister();\n\t\tdestroy_workqueue(nfit_wq);\n\t}\n\n\treturn ret;\n\n}\n\nstatic __exit void nfit_exit(void)\n{\n\tnfit_mce_unregister();\n\tacpi_bus_unregister_driver(&acpi_nfit_driver);\n\tdestroy_workqueue(nfit_wq);\n\tWARN_ON(!list_empty(&acpi_descs));\n}\n\nmodule_init(nfit_init);\nmodule_exit(nfit_exit);\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Intel Corporation\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}