{
  "module_name": "ghes.c",
  "hash_id": "6c20ae06e09bb353d847523602daffc6d660550733de6c7db16af86bf8d7f9e2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/acpi/apei/ghes.c",
  "human_readable_source": "\n \n\n#include <linux/arm_sdei.h>\n#include <linux/kernel.h>\n#include <linux/moduleparam.h>\n#include <linux/init.h>\n#include <linux/acpi.h>\n#include <linux/io.h>\n#include <linux/interrupt.h>\n#include <linux/timer.h>\n#include <linux/cper.h>\n#include <linux/platform_device.h>\n#include <linux/mutex.h>\n#include <linux/ratelimit.h>\n#include <linux/vmalloc.h>\n#include <linux/irq_work.h>\n#include <linux/llist.h>\n#include <linux/genalloc.h>\n#include <linux/pci.h>\n#include <linux/pfn.h>\n#include <linux/aer.h>\n#include <linux/nmi.h>\n#include <linux/sched/clock.h>\n#include <linux/uuid.h>\n#include <linux/ras.h>\n#include <linux/task_work.h>\n\n#include <acpi/actbl1.h>\n#include <acpi/ghes.h>\n#include <acpi/apei.h>\n#include <asm/fixmap.h>\n#include <asm/tlbflush.h>\n#include <ras/ras_event.h>\n\n#include \"apei-internal.h\"\n\n#define GHES_PFX\t\"GHES: \"\n\n#define GHES_ESTATUS_MAX_SIZE\t\t65536\n#define GHES_ESOURCE_PREALLOC_MAX_SIZE\t65536\n\n#define GHES_ESTATUS_POOL_MIN_ALLOC_ORDER 3\n\n \n#define GHES_ESTATUS_CACHE_AVG_SIZE\t512\n\n#define GHES_ESTATUS_CACHES_SIZE\t4\n\n#define GHES_ESTATUS_IN_CACHE_MAX_NSEC\t10000000000ULL\n \n#define GHES_ESTATUS_CACHE_ALLOCED_MAX\t(GHES_ESTATUS_CACHES_SIZE * 3 / 2)\n\n#define GHES_ESTATUS_CACHE_LEN(estatus_len)\t\t\t\\\n\t(sizeof(struct ghes_estatus_cache) + (estatus_len))\n#define GHES_ESTATUS_FROM_CACHE(estatus_cache)\t\t\t\\\n\t((struct acpi_hest_generic_status *)\t\t\t\t\\\n\t ((struct ghes_estatus_cache *)(estatus_cache) + 1))\n\n#define GHES_ESTATUS_NODE_LEN(estatus_len)\t\t\t\\\n\t(sizeof(struct ghes_estatus_node) + (estatus_len))\n#define GHES_ESTATUS_FROM_NODE(estatus_node)\t\t\t\\\n\t((struct acpi_hest_generic_status *)\t\t\t\t\\\n\t ((struct ghes_estatus_node *)(estatus_node) + 1))\n\n#define GHES_VENDOR_ENTRY_LEN(gdata_len)                               \\\n\t(sizeof(struct ghes_vendor_record_entry) + (gdata_len))\n#define GHES_GDATA_FROM_VENDOR_ENTRY(vendor_entry)                     \\\n\t((struct acpi_hest_generic_data *)                              \\\n\t((struct ghes_vendor_record_entry *)(vendor_entry) + 1))\n\n \n#ifndef CONFIG_ARM_SDE_INTERFACE\n#define FIX_APEI_GHES_SDEI_NORMAL\t__end_of_fixed_addresses\n#define FIX_APEI_GHES_SDEI_CRITICAL\t__end_of_fixed_addresses\n#endif\n\nstatic ATOMIC_NOTIFIER_HEAD(ghes_report_chain);\n\nstatic inline bool is_hest_type_generic_v2(struct ghes *ghes)\n{\n\treturn ghes->generic->header.type == ACPI_HEST_TYPE_GENERIC_ERROR_V2;\n}\n\n \nbool ghes_disable;\nmodule_param_named(disable, ghes_disable, bool, 0);\n\n \nstatic bool ghes_edac_force_enable;\nmodule_param_named(edac_force_enable, ghes_edac_force_enable, bool, 0);\n\n \nstatic LIST_HEAD(ghes_hed);\nstatic DEFINE_MUTEX(ghes_list_mutex);\n\n \nstatic LIST_HEAD(ghes_devs);\nstatic DEFINE_MUTEX(ghes_devs_mutex);\n\n \nstatic DEFINE_SPINLOCK(ghes_notify_lock_irq);\n\nstruct ghes_vendor_record_entry {\n\tstruct work_struct work;\n\tint error_severity;\n\tchar vendor_record[];\n};\n\nstatic struct gen_pool *ghes_estatus_pool;\n\nstatic struct ghes_estatus_cache __rcu *ghes_estatus_caches[GHES_ESTATUS_CACHES_SIZE];\nstatic atomic_t ghes_estatus_cache_alloced;\n\nstatic int ghes_panic_timeout __read_mostly = 30;\n\nstatic void __iomem *ghes_map(u64 pfn, enum fixed_addresses fixmap_idx)\n{\n\tphys_addr_t paddr;\n\tpgprot_t prot;\n\n\tpaddr = PFN_PHYS(pfn);\n\tprot = arch_apei_get_mem_attribute(paddr);\n\t__set_fixmap(fixmap_idx, paddr, prot);\n\n\treturn (void __iomem *) __fix_to_virt(fixmap_idx);\n}\n\nstatic void ghes_unmap(void __iomem *vaddr, enum fixed_addresses fixmap_idx)\n{\n\tint _idx = virt_to_fix((unsigned long)vaddr);\n\n\tWARN_ON_ONCE(fixmap_idx != _idx);\n\tclear_fixmap(fixmap_idx);\n}\n\nint ghes_estatus_pool_init(unsigned int num_ghes)\n{\n\tunsigned long addr, len;\n\tint rc;\n\n\tghes_estatus_pool = gen_pool_create(GHES_ESTATUS_POOL_MIN_ALLOC_ORDER, -1);\n\tif (!ghes_estatus_pool)\n\t\treturn -ENOMEM;\n\n\tlen = GHES_ESTATUS_CACHE_AVG_SIZE * GHES_ESTATUS_CACHE_ALLOCED_MAX;\n\tlen += (num_ghes * GHES_ESOURCE_PREALLOC_MAX_SIZE);\n\n\taddr = (unsigned long)vmalloc(PAGE_ALIGN(len));\n\tif (!addr)\n\t\tgoto err_pool_alloc;\n\n\trc = gen_pool_add(ghes_estatus_pool, addr, PAGE_ALIGN(len), -1);\n\tif (rc)\n\t\tgoto err_pool_add;\n\n\treturn 0;\n\nerr_pool_add:\n\tvfree((void *)addr);\n\nerr_pool_alloc:\n\tgen_pool_destroy(ghes_estatus_pool);\n\n\treturn -ENOMEM;\n}\n\n \nvoid ghes_estatus_pool_region_free(unsigned long addr, u32 size)\n{\n\tgen_pool_free(ghes_estatus_pool, addr, size);\n}\nEXPORT_SYMBOL_GPL(ghes_estatus_pool_region_free);\n\nstatic int map_gen_v2(struct ghes *ghes)\n{\n\treturn apei_map_generic_address(&ghes->generic_v2->read_ack_register);\n}\n\nstatic void unmap_gen_v2(struct ghes *ghes)\n{\n\tapei_unmap_generic_address(&ghes->generic_v2->read_ack_register);\n}\n\nstatic void ghes_ack_error(struct acpi_hest_generic_v2 *gv2)\n{\n\tint rc;\n\tu64 val = 0;\n\n\trc = apei_read(&val, &gv2->read_ack_register);\n\tif (rc)\n\t\treturn;\n\n\tval &= gv2->read_ack_preserve << gv2->read_ack_register.bit_offset;\n\tval |= gv2->read_ack_write    << gv2->read_ack_register.bit_offset;\n\n\tapei_write(val, &gv2->read_ack_register);\n}\n\nstatic struct ghes *ghes_new(struct acpi_hest_generic *generic)\n{\n\tstruct ghes *ghes;\n\tunsigned int error_block_length;\n\tint rc;\n\n\tghes = kzalloc(sizeof(*ghes), GFP_KERNEL);\n\tif (!ghes)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tghes->generic = generic;\n\tif (is_hest_type_generic_v2(ghes)) {\n\t\trc = map_gen_v2(ghes);\n\t\tif (rc)\n\t\t\tgoto err_free;\n\t}\n\n\trc = apei_map_generic_address(&generic->error_status_address);\n\tif (rc)\n\t\tgoto err_unmap_read_ack_addr;\n\terror_block_length = generic->error_block_length;\n\tif (error_block_length > GHES_ESTATUS_MAX_SIZE) {\n\t\tpr_warn(FW_WARN GHES_PFX\n\t\t\t\"Error status block length is too long: %u for \"\n\t\t\t\"generic hardware error source: %d.\\n\",\n\t\t\terror_block_length, generic->header.source_id);\n\t\terror_block_length = GHES_ESTATUS_MAX_SIZE;\n\t}\n\tghes->estatus = kmalloc(error_block_length, GFP_KERNEL);\n\tif (!ghes->estatus) {\n\t\trc = -ENOMEM;\n\t\tgoto err_unmap_status_addr;\n\t}\n\n\treturn ghes;\n\nerr_unmap_status_addr:\n\tapei_unmap_generic_address(&generic->error_status_address);\nerr_unmap_read_ack_addr:\n\tif (is_hest_type_generic_v2(ghes))\n\t\tunmap_gen_v2(ghes);\nerr_free:\n\tkfree(ghes);\n\treturn ERR_PTR(rc);\n}\n\nstatic void ghes_fini(struct ghes *ghes)\n{\n\tkfree(ghes->estatus);\n\tapei_unmap_generic_address(&ghes->generic->error_status_address);\n\tif (is_hest_type_generic_v2(ghes))\n\t\tunmap_gen_v2(ghes);\n}\n\nstatic inline int ghes_severity(int severity)\n{\n\tswitch (severity) {\n\tcase CPER_SEV_INFORMATIONAL:\n\t\treturn GHES_SEV_NO;\n\tcase CPER_SEV_CORRECTED:\n\t\treturn GHES_SEV_CORRECTED;\n\tcase CPER_SEV_RECOVERABLE:\n\t\treturn GHES_SEV_RECOVERABLE;\n\tcase CPER_SEV_FATAL:\n\t\treturn GHES_SEV_PANIC;\n\tdefault:\n\t\t \n\t\treturn GHES_SEV_PANIC;\n\t}\n}\n\nstatic void ghes_copy_tofrom_phys(void *buffer, u64 paddr, u32 len,\n\t\t\t\t  int from_phys,\n\t\t\t\t  enum fixed_addresses fixmap_idx)\n{\n\tvoid __iomem *vaddr;\n\tu64 offset;\n\tu32 trunk;\n\n\twhile (len > 0) {\n\t\toffset = paddr - (paddr & PAGE_MASK);\n\t\tvaddr = ghes_map(PHYS_PFN(paddr), fixmap_idx);\n\t\ttrunk = PAGE_SIZE - offset;\n\t\ttrunk = min(trunk, len);\n\t\tif (from_phys)\n\t\t\tmemcpy_fromio(buffer, vaddr + offset, trunk);\n\t\telse\n\t\t\tmemcpy_toio(vaddr + offset, buffer, trunk);\n\t\tlen -= trunk;\n\t\tpaddr += trunk;\n\t\tbuffer += trunk;\n\t\tghes_unmap(vaddr, fixmap_idx);\n\t}\n}\n\n \nstatic int __ghes_check_estatus(struct ghes *ghes,\n\t\t\t\tstruct acpi_hest_generic_status *estatus)\n{\n\tu32 len = cper_estatus_len(estatus);\n\n\tif (len < sizeof(*estatus)) {\n\t\tpr_warn_ratelimited(FW_WARN GHES_PFX \"Truncated error status block!\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (len > ghes->generic->error_block_length) {\n\t\tpr_warn_ratelimited(FW_WARN GHES_PFX \"Invalid error status block length!\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (cper_estatus_check_header(estatus)) {\n\t\tpr_warn_ratelimited(FW_WARN GHES_PFX \"Invalid CPER header!\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int __ghes_peek_estatus(struct ghes *ghes,\n\t\t\t       struct acpi_hest_generic_status *estatus,\n\t\t\t       u64 *buf_paddr, enum fixed_addresses fixmap_idx)\n{\n\tstruct acpi_hest_generic *g = ghes->generic;\n\tint rc;\n\n\trc = apei_read(buf_paddr, &g->error_status_address);\n\tif (rc) {\n\t\t*buf_paddr = 0;\n\t\tpr_warn_ratelimited(FW_WARN GHES_PFX\n\"Failed to read error status block address for hardware error source: %d.\\n\",\n\t\t\t\t   g->header.source_id);\n\t\treturn -EIO;\n\t}\n\tif (!*buf_paddr)\n\t\treturn -ENOENT;\n\n\tghes_copy_tofrom_phys(estatus, *buf_paddr, sizeof(*estatus), 1,\n\t\t\t      fixmap_idx);\n\tif (!estatus->block_status) {\n\t\t*buf_paddr = 0;\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\nstatic int __ghes_read_estatus(struct acpi_hest_generic_status *estatus,\n\t\t\t       u64 buf_paddr, enum fixed_addresses fixmap_idx,\n\t\t\t       size_t buf_len)\n{\n\tghes_copy_tofrom_phys(estatus, buf_paddr, buf_len, 1, fixmap_idx);\n\tif (cper_estatus_check(estatus)) {\n\t\tpr_warn_ratelimited(FW_WARN GHES_PFX\n\t\t\t\t    \"Failed to read error status block!\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic int ghes_read_estatus(struct ghes *ghes,\n\t\t\t     struct acpi_hest_generic_status *estatus,\n\t\t\t     u64 *buf_paddr, enum fixed_addresses fixmap_idx)\n{\n\tint rc;\n\n\trc = __ghes_peek_estatus(ghes, estatus, buf_paddr, fixmap_idx);\n\tif (rc)\n\t\treturn rc;\n\n\trc = __ghes_check_estatus(ghes, estatus);\n\tif (rc)\n\t\treturn rc;\n\n\treturn __ghes_read_estatus(estatus, *buf_paddr, fixmap_idx,\n\t\t\t\t   cper_estatus_len(estatus));\n}\n\nstatic void ghes_clear_estatus(struct ghes *ghes,\n\t\t\t       struct acpi_hest_generic_status *estatus,\n\t\t\t       u64 buf_paddr, enum fixed_addresses fixmap_idx)\n{\n\testatus->block_status = 0;\n\n\tif (!buf_paddr)\n\t\treturn;\n\n\tghes_copy_tofrom_phys(estatus, buf_paddr,\n\t\t\t      sizeof(estatus->block_status), 0,\n\t\t\t      fixmap_idx);\n\n\t \n\tif (is_hest_type_generic_v2(ghes))\n\t\tghes_ack_error(ghes->generic_v2);\n}\n\n \nstatic void ghes_kick_task_work(struct callback_head *head)\n{\n\tstruct acpi_hest_generic_status *estatus;\n\tstruct ghes_estatus_node *estatus_node;\n\tu32 node_len;\n\n\testatus_node = container_of(head, struct ghes_estatus_node, task_work);\n\tif (IS_ENABLED(CONFIG_ACPI_APEI_MEMORY_FAILURE))\n\t\tmemory_failure_queue_kick(estatus_node->task_work_cpu);\n\n\testatus = GHES_ESTATUS_FROM_NODE(estatus_node);\n\tnode_len = GHES_ESTATUS_NODE_LEN(cper_estatus_len(estatus));\n\tgen_pool_free(ghes_estatus_pool, (unsigned long)estatus_node, node_len);\n}\n\nstatic bool ghes_do_memory_failure(u64 physical_addr, int flags)\n{\n\tunsigned long pfn;\n\n\tif (!IS_ENABLED(CONFIG_ACPI_APEI_MEMORY_FAILURE))\n\t\treturn false;\n\n\tpfn = PHYS_PFN(physical_addr);\n\tif (!pfn_valid(pfn) && !arch_is_platform_page(physical_addr)) {\n\t\tpr_warn_ratelimited(FW_WARN GHES_PFX\n\t\t\"Invalid address in generic error data: %#llx\\n\",\n\t\tphysical_addr);\n\t\treturn false;\n\t}\n\n\tmemory_failure_queue(pfn, flags);\n\treturn true;\n}\n\nstatic bool ghes_handle_memory_failure(struct acpi_hest_generic_data *gdata,\n\t\t\t\t       int sev)\n{\n\tint flags = -1;\n\tint sec_sev = ghes_severity(gdata->error_severity);\n\tstruct cper_sec_mem_err *mem_err = acpi_hest_get_payload(gdata);\n\n\tif (!(mem_err->validation_bits & CPER_MEM_VALID_PA))\n\t\treturn false;\n\n\t \n\tif (sec_sev == GHES_SEV_CORRECTED &&\n\t    (gdata->flags & CPER_SEC_ERROR_THRESHOLD_EXCEEDED))\n\t\tflags = MF_SOFT_OFFLINE;\n\tif (sev == GHES_SEV_RECOVERABLE && sec_sev == GHES_SEV_RECOVERABLE)\n\t\tflags = 0;\n\n\tif (flags != -1)\n\t\treturn ghes_do_memory_failure(mem_err->physical_addr, flags);\n\n\treturn false;\n}\n\nstatic bool ghes_handle_arm_hw_error(struct acpi_hest_generic_data *gdata, int sev)\n{\n\tstruct cper_sec_proc_arm *err = acpi_hest_get_payload(gdata);\n\tbool queued = false;\n\tint sec_sev, i;\n\tchar *p;\n\n\tlog_arm_hw_error(err);\n\n\tsec_sev = ghes_severity(gdata->error_severity);\n\tif (sev != GHES_SEV_RECOVERABLE || sec_sev != GHES_SEV_RECOVERABLE)\n\t\treturn false;\n\n\tp = (char *)(err + 1);\n\tfor (i = 0; i < err->err_info_num; i++) {\n\t\tstruct cper_arm_err_info *err_info = (struct cper_arm_err_info *)p;\n\t\tbool is_cache = (err_info->type == CPER_ARM_CACHE_ERROR);\n\t\tbool has_pa = (err_info->validation_bits & CPER_ARM_INFO_VALID_PHYSICAL_ADDR);\n\t\tconst char *error_type = \"unknown error\";\n\n\t\t \n\t\tif (is_cache && has_pa) {\n\t\t\tqueued = ghes_do_memory_failure(err_info->physical_fault_addr, 0);\n\t\t\tp += err_info->length;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (err_info->type < ARRAY_SIZE(cper_proc_error_type_strs))\n\t\t\terror_type = cper_proc_error_type_strs[err_info->type];\n\n\t\tpr_warn_ratelimited(FW_WARN GHES_PFX\n\t\t\t\t    \"Unhandled processor error type: %s\\n\",\n\t\t\t\t    error_type);\n\t\tp += err_info->length;\n\t}\n\n\treturn queued;\n}\n\n \nstatic void ghes_handle_aer(struct acpi_hest_generic_data *gdata)\n{\n#ifdef CONFIG_ACPI_APEI_PCIEAER\n\tstruct cper_sec_pcie *pcie_err = acpi_hest_get_payload(gdata);\n\n\tif (pcie_err->validation_bits & CPER_PCIE_VALID_DEVICE_ID &&\n\t    pcie_err->validation_bits & CPER_PCIE_VALID_AER_INFO) {\n\t\tunsigned int devfn;\n\t\tint aer_severity;\n\t\tu8 *aer_info;\n\n\t\tdevfn = PCI_DEVFN(pcie_err->device_id.device,\n\t\t\t\t  pcie_err->device_id.function);\n\t\taer_severity = cper_severity_to_aer(gdata->error_severity);\n\n\t\t \n\t\tif (gdata->flags & CPER_SEC_RESET)\n\t\t\taer_severity = AER_FATAL;\n\n\t\taer_info = (void *)gen_pool_alloc(ghes_estatus_pool,\n\t\t\t\t\t\t  sizeof(struct aer_capability_regs));\n\t\tif (!aer_info)\n\t\t\treturn;\n\t\tmemcpy(aer_info, pcie_err->aer_info, sizeof(struct aer_capability_regs));\n\n\t\taer_recover_queue(pcie_err->device_id.segment,\n\t\t\t\t  pcie_err->device_id.bus,\n\t\t\t\t  devfn, aer_severity,\n\t\t\t\t  (struct aer_capability_regs *)\n\t\t\t\t  aer_info);\n\t}\n#endif\n}\n\nstatic BLOCKING_NOTIFIER_HEAD(vendor_record_notify_list);\n\nint ghes_register_vendor_record_notifier(struct notifier_block *nb)\n{\n\treturn blocking_notifier_chain_register(&vendor_record_notify_list, nb);\n}\nEXPORT_SYMBOL_GPL(ghes_register_vendor_record_notifier);\n\nvoid ghes_unregister_vendor_record_notifier(struct notifier_block *nb)\n{\n\tblocking_notifier_chain_unregister(&vendor_record_notify_list, nb);\n}\nEXPORT_SYMBOL_GPL(ghes_unregister_vendor_record_notifier);\n\nstatic void ghes_vendor_record_work_func(struct work_struct *work)\n{\n\tstruct ghes_vendor_record_entry *entry;\n\tstruct acpi_hest_generic_data *gdata;\n\tu32 len;\n\n\tentry = container_of(work, struct ghes_vendor_record_entry, work);\n\tgdata = GHES_GDATA_FROM_VENDOR_ENTRY(entry);\n\n\tblocking_notifier_call_chain(&vendor_record_notify_list,\n\t\t\t\t     entry->error_severity, gdata);\n\n\tlen = GHES_VENDOR_ENTRY_LEN(acpi_hest_get_record_size(gdata));\n\tgen_pool_free(ghes_estatus_pool, (unsigned long)entry, len);\n}\n\nstatic void ghes_defer_non_standard_event(struct acpi_hest_generic_data *gdata,\n\t\t\t\t\t  int sev)\n{\n\tstruct acpi_hest_generic_data *copied_gdata;\n\tstruct ghes_vendor_record_entry *entry;\n\tu32 len;\n\n\tlen = GHES_VENDOR_ENTRY_LEN(acpi_hest_get_record_size(gdata));\n\tentry = (void *)gen_pool_alloc(ghes_estatus_pool, len);\n\tif (!entry)\n\t\treturn;\n\n\tcopied_gdata = GHES_GDATA_FROM_VENDOR_ENTRY(entry);\n\tmemcpy(copied_gdata, gdata, acpi_hest_get_record_size(gdata));\n\tentry->error_severity = sev;\n\n\tINIT_WORK(&entry->work, ghes_vendor_record_work_func);\n\tschedule_work(&entry->work);\n}\n\nstatic bool ghes_do_proc(struct ghes *ghes,\n\t\t\t const struct acpi_hest_generic_status *estatus)\n{\n\tint sev, sec_sev;\n\tstruct acpi_hest_generic_data *gdata;\n\tguid_t *sec_type;\n\tconst guid_t *fru_id = &guid_null;\n\tchar *fru_text = \"\";\n\tbool queued = false;\n\n\tsev = ghes_severity(estatus->error_severity);\n\tapei_estatus_for_each_section(estatus, gdata) {\n\t\tsec_type = (guid_t *)gdata->section_type;\n\t\tsec_sev = ghes_severity(gdata->error_severity);\n\t\tif (gdata->validation_bits & CPER_SEC_VALID_FRU_ID)\n\t\t\tfru_id = (guid_t *)gdata->fru_id;\n\n\t\tif (gdata->validation_bits & CPER_SEC_VALID_FRU_TEXT)\n\t\t\tfru_text = gdata->fru_text;\n\n\t\tif (guid_equal(sec_type, &CPER_SEC_PLATFORM_MEM)) {\n\t\t\tstruct cper_sec_mem_err *mem_err = acpi_hest_get_payload(gdata);\n\n\t\t\tatomic_notifier_call_chain(&ghes_report_chain, sev, mem_err);\n\n\t\t\tarch_apei_report_mem_error(sev, mem_err);\n\t\t\tqueued = ghes_handle_memory_failure(gdata, sev);\n\t\t}\n\t\telse if (guid_equal(sec_type, &CPER_SEC_PCIE)) {\n\t\t\tghes_handle_aer(gdata);\n\t\t}\n\t\telse if (guid_equal(sec_type, &CPER_SEC_PROC_ARM)) {\n\t\t\tqueued = ghes_handle_arm_hw_error(gdata, sev);\n\t\t} else {\n\t\t\tvoid *err = acpi_hest_get_payload(gdata);\n\n\t\t\tghes_defer_non_standard_event(gdata, sev);\n\t\t\tlog_non_standard_event(sec_type, fru_id, fru_text,\n\t\t\t\t\t       sec_sev, err,\n\t\t\t\t\t       gdata->error_data_length);\n\t\t}\n\t}\n\n\treturn queued;\n}\n\nstatic void __ghes_print_estatus(const char *pfx,\n\t\t\t\t const struct acpi_hest_generic *generic,\n\t\t\t\t const struct acpi_hest_generic_status *estatus)\n{\n\tstatic atomic_t seqno;\n\tunsigned int curr_seqno;\n\tchar pfx_seq[64];\n\n\tif (pfx == NULL) {\n\t\tif (ghes_severity(estatus->error_severity) <=\n\t\t    GHES_SEV_CORRECTED)\n\t\t\tpfx = KERN_WARNING;\n\t\telse\n\t\t\tpfx = KERN_ERR;\n\t}\n\tcurr_seqno = atomic_inc_return(&seqno);\n\tsnprintf(pfx_seq, sizeof(pfx_seq), \"%s{%u}\" HW_ERR, pfx, curr_seqno);\n\tprintk(\"%s\"\"Hardware error from APEI Generic Hardware Error Source: %d\\n\",\n\t       pfx_seq, generic->header.source_id);\n\tcper_estatus_print(pfx_seq, estatus);\n}\n\nstatic int ghes_print_estatus(const char *pfx,\n\t\t\t      const struct acpi_hest_generic *generic,\n\t\t\t      const struct acpi_hest_generic_status *estatus)\n{\n\t \n\tstatic DEFINE_RATELIMIT_STATE(ratelimit_corrected, 5*HZ, 2);\n\tstatic DEFINE_RATELIMIT_STATE(ratelimit_uncorrected, 5*HZ, 2);\n\tstruct ratelimit_state *ratelimit;\n\n\tif (ghes_severity(estatus->error_severity) <= GHES_SEV_CORRECTED)\n\t\tratelimit = &ratelimit_corrected;\n\telse\n\t\tratelimit = &ratelimit_uncorrected;\n\tif (__ratelimit(ratelimit)) {\n\t\t__ghes_print_estatus(pfx, generic, estatus);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nstatic int ghes_estatus_cached(struct acpi_hest_generic_status *estatus)\n{\n\tu32 len;\n\tint i, cached = 0;\n\tunsigned long long now;\n\tstruct ghes_estatus_cache *cache;\n\tstruct acpi_hest_generic_status *cache_estatus;\n\n\tlen = cper_estatus_len(estatus);\n\trcu_read_lock();\n\tfor (i = 0; i < GHES_ESTATUS_CACHES_SIZE; i++) {\n\t\tcache = rcu_dereference(ghes_estatus_caches[i]);\n\t\tif (cache == NULL)\n\t\t\tcontinue;\n\t\tif (len != cache->estatus_len)\n\t\t\tcontinue;\n\t\tcache_estatus = GHES_ESTATUS_FROM_CACHE(cache);\n\t\tif (memcmp(estatus, cache_estatus, len))\n\t\t\tcontinue;\n\t\tatomic_inc(&cache->count);\n\t\tnow = sched_clock();\n\t\tif (now - cache->time_in < GHES_ESTATUS_IN_CACHE_MAX_NSEC)\n\t\t\tcached = 1;\n\t\tbreak;\n\t}\n\trcu_read_unlock();\n\treturn cached;\n}\n\nstatic struct ghes_estatus_cache *ghes_estatus_cache_alloc(\n\tstruct acpi_hest_generic *generic,\n\tstruct acpi_hest_generic_status *estatus)\n{\n\tint alloced;\n\tu32 len, cache_len;\n\tstruct ghes_estatus_cache *cache;\n\tstruct acpi_hest_generic_status *cache_estatus;\n\n\talloced = atomic_add_return(1, &ghes_estatus_cache_alloced);\n\tif (alloced > GHES_ESTATUS_CACHE_ALLOCED_MAX) {\n\t\tatomic_dec(&ghes_estatus_cache_alloced);\n\t\treturn NULL;\n\t}\n\tlen = cper_estatus_len(estatus);\n\tcache_len = GHES_ESTATUS_CACHE_LEN(len);\n\tcache = (void *)gen_pool_alloc(ghes_estatus_pool, cache_len);\n\tif (!cache) {\n\t\tatomic_dec(&ghes_estatus_cache_alloced);\n\t\treturn NULL;\n\t}\n\tcache_estatus = GHES_ESTATUS_FROM_CACHE(cache);\n\tmemcpy(cache_estatus, estatus, len);\n\tcache->estatus_len = len;\n\tatomic_set(&cache->count, 0);\n\tcache->generic = generic;\n\tcache->time_in = sched_clock();\n\treturn cache;\n}\n\nstatic void ghes_estatus_cache_rcu_free(struct rcu_head *head)\n{\n\tstruct ghes_estatus_cache *cache;\n\tu32 len;\n\n\tcache = container_of(head, struct ghes_estatus_cache, rcu);\n\tlen = cper_estatus_len(GHES_ESTATUS_FROM_CACHE(cache));\n\tlen = GHES_ESTATUS_CACHE_LEN(len);\n\tgen_pool_free(ghes_estatus_pool, (unsigned long)cache, len);\n\tatomic_dec(&ghes_estatus_cache_alloced);\n}\n\nstatic void\nghes_estatus_cache_add(struct acpi_hest_generic *generic,\n\t\t       struct acpi_hest_generic_status *estatus)\n{\n\tunsigned long long now, duration, period, max_period = 0;\n\tstruct ghes_estatus_cache *cache, *new_cache;\n\tstruct ghes_estatus_cache __rcu *victim;\n\tint i, slot = -1, count;\n\n\tnew_cache = ghes_estatus_cache_alloc(generic, estatus);\n\tif (!new_cache)\n\t\treturn;\n\n\trcu_read_lock();\n\tnow = sched_clock();\n\tfor (i = 0; i < GHES_ESTATUS_CACHES_SIZE; i++) {\n\t\tcache = rcu_dereference(ghes_estatus_caches[i]);\n\t\tif (cache == NULL) {\n\t\t\tslot = i;\n\t\t\tbreak;\n\t\t}\n\t\tduration = now - cache->time_in;\n\t\tif (duration >= GHES_ESTATUS_IN_CACHE_MAX_NSEC) {\n\t\t\tslot = i;\n\t\t\tbreak;\n\t\t}\n\t\tcount = atomic_read(&cache->count);\n\t\tperiod = duration;\n\t\tdo_div(period, (count + 1));\n\t\tif (period > max_period) {\n\t\t\tmax_period = period;\n\t\t\tslot = i;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tif (slot != -1) {\n\t\t \n\t\tvictim = xchg_release(&ghes_estatus_caches[slot],\n\t\t\t\t      RCU_INITIALIZER(new_cache));\n\n\t\t \n\t\tif (victim)\n\t\t\tcall_rcu(&unrcu_pointer(victim)->rcu,\n\t\t\t\t ghes_estatus_cache_rcu_free);\n\t}\n}\n\nstatic void __ghes_panic(struct ghes *ghes,\n\t\t\t struct acpi_hest_generic_status *estatus,\n\t\t\t u64 buf_paddr, enum fixed_addresses fixmap_idx)\n{\n\t__ghes_print_estatus(KERN_EMERG, ghes->generic, estatus);\n\n\tghes_clear_estatus(ghes, estatus, buf_paddr, fixmap_idx);\n\n\t \n\tif (!panic_timeout)\n\t\tpanic_timeout = ghes_panic_timeout;\n\tpanic(\"Fatal hardware error!\");\n}\n\nstatic int ghes_proc(struct ghes *ghes)\n{\n\tstruct acpi_hest_generic_status *estatus = ghes->estatus;\n\tu64 buf_paddr;\n\tint rc;\n\n\trc = ghes_read_estatus(ghes, estatus, &buf_paddr, FIX_APEI_GHES_IRQ);\n\tif (rc)\n\t\tgoto out;\n\n\tif (ghes_severity(estatus->error_severity) >= GHES_SEV_PANIC)\n\t\t__ghes_panic(ghes, estatus, buf_paddr, FIX_APEI_GHES_IRQ);\n\n\tif (!ghes_estatus_cached(estatus)) {\n\t\tif (ghes_print_estatus(NULL, ghes->generic, estatus))\n\t\t\tghes_estatus_cache_add(ghes->generic, estatus);\n\t}\n\tghes_do_proc(ghes, estatus);\n\nout:\n\tghes_clear_estatus(ghes, estatus, buf_paddr, FIX_APEI_GHES_IRQ);\n\n\treturn rc;\n}\n\nstatic void ghes_add_timer(struct ghes *ghes)\n{\n\tstruct acpi_hest_generic *g = ghes->generic;\n\tunsigned long expire;\n\n\tif (!g->notify.poll_interval) {\n\t\tpr_warn(FW_WARN GHES_PFX \"Poll interval is 0 for generic hardware error source: %d, disabled.\\n\",\n\t\t\tg->header.source_id);\n\t\treturn;\n\t}\n\texpire = jiffies + msecs_to_jiffies(g->notify.poll_interval);\n\tghes->timer.expires = round_jiffies_relative(expire);\n\tadd_timer(&ghes->timer);\n}\n\nstatic void ghes_poll_func(struct timer_list *t)\n{\n\tstruct ghes *ghes = from_timer(ghes, t, timer);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ghes_notify_lock_irq, flags);\n\tghes_proc(ghes);\n\tspin_unlock_irqrestore(&ghes_notify_lock_irq, flags);\n\tif (!(ghes->flags & GHES_EXITING))\n\t\tghes_add_timer(ghes);\n}\n\nstatic irqreturn_t ghes_irq_func(int irq, void *data)\n{\n\tstruct ghes *ghes = data;\n\tunsigned long flags;\n\tint rc;\n\n\tspin_lock_irqsave(&ghes_notify_lock_irq, flags);\n\trc = ghes_proc(ghes);\n\tspin_unlock_irqrestore(&ghes_notify_lock_irq, flags);\n\tif (rc)\n\t\treturn IRQ_NONE;\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int ghes_notify_hed(struct notifier_block *this, unsigned long event,\n\t\t\t   void *data)\n{\n\tstruct ghes *ghes;\n\tunsigned long flags;\n\tint ret = NOTIFY_DONE;\n\n\tspin_lock_irqsave(&ghes_notify_lock_irq, flags);\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ghes, &ghes_hed, list) {\n\t\tif (!ghes_proc(ghes))\n\t\t\tret = NOTIFY_OK;\n\t}\n\trcu_read_unlock();\n\tspin_unlock_irqrestore(&ghes_notify_lock_irq, flags);\n\n\treturn ret;\n}\n\nstatic struct notifier_block ghes_notifier_hed = {\n\t.notifier_call = ghes_notify_hed,\n};\n\n \nstatic struct llist_head ghes_estatus_llist;\nstatic struct irq_work ghes_proc_irq_work;\n\nstatic void ghes_proc_in_irq(struct irq_work *irq_work)\n{\n\tstruct llist_node *llnode, *next;\n\tstruct ghes_estatus_node *estatus_node;\n\tstruct acpi_hest_generic *generic;\n\tstruct acpi_hest_generic_status *estatus;\n\tbool task_work_pending;\n\tu32 len, node_len;\n\tint ret;\n\n\tllnode = llist_del_all(&ghes_estatus_llist);\n\t \n\tllnode = llist_reverse_order(llnode);\n\twhile (llnode) {\n\t\tnext = llnode->next;\n\t\testatus_node = llist_entry(llnode, struct ghes_estatus_node,\n\t\t\t\t\t   llnode);\n\t\testatus = GHES_ESTATUS_FROM_NODE(estatus_node);\n\t\tlen = cper_estatus_len(estatus);\n\t\tnode_len = GHES_ESTATUS_NODE_LEN(len);\n\t\ttask_work_pending = ghes_do_proc(estatus_node->ghes, estatus);\n\t\tif (!ghes_estatus_cached(estatus)) {\n\t\t\tgeneric = estatus_node->generic;\n\t\t\tif (ghes_print_estatus(NULL, generic, estatus))\n\t\t\t\tghes_estatus_cache_add(generic, estatus);\n\t\t}\n\n\t\tif (task_work_pending && current->mm) {\n\t\t\testatus_node->task_work.func = ghes_kick_task_work;\n\t\t\testatus_node->task_work_cpu = smp_processor_id();\n\t\t\tret = task_work_add(current, &estatus_node->task_work,\n\t\t\t\t\t    TWA_RESUME);\n\t\t\tif (ret)\n\t\t\t\testatus_node->task_work.func = NULL;\n\t\t}\n\n\t\tif (!estatus_node->task_work.func)\n\t\t\tgen_pool_free(ghes_estatus_pool,\n\t\t\t\t      (unsigned long)estatus_node, node_len);\n\n\t\tllnode = next;\n\t}\n}\n\nstatic void ghes_print_queued_estatus(void)\n{\n\tstruct llist_node *llnode;\n\tstruct ghes_estatus_node *estatus_node;\n\tstruct acpi_hest_generic *generic;\n\tstruct acpi_hest_generic_status *estatus;\n\n\tllnode = llist_del_all(&ghes_estatus_llist);\n\t \n\tllnode = llist_reverse_order(llnode);\n\twhile (llnode) {\n\t\testatus_node = llist_entry(llnode, struct ghes_estatus_node,\n\t\t\t\t\t   llnode);\n\t\testatus = GHES_ESTATUS_FROM_NODE(estatus_node);\n\t\tgeneric = estatus_node->generic;\n\t\tghes_print_estatus(NULL, generic, estatus);\n\t\tllnode = llnode->next;\n\t}\n}\n\nstatic int ghes_in_nmi_queue_one_entry(struct ghes *ghes,\n\t\t\t\t       enum fixed_addresses fixmap_idx)\n{\n\tstruct acpi_hest_generic_status *estatus, tmp_header;\n\tstruct ghes_estatus_node *estatus_node;\n\tu32 len, node_len;\n\tu64 buf_paddr;\n\tint sev, rc;\n\n\tif (!IS_ENABLED(CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG))\n\t\treturn -EOPNOTSUPP;\n\n\trc = __ghes_peek_estatus(ghes, &tmp_header, &buf_paddr, fixmap_idx);\n\tif (rc) {\n\t\tghes_clear_estatus(ghes, &tmp_header, buf_paddr, fixmap_idx);\n\t\treturn rc;\n\t}\n\n\trc = __ghes_check_estatus(ghes, &tmp_header);\n\tif (rc) {\n\t\tghes_clear_estatus(ghes, &tmp_header, buf_paddr, fixmap_idx);\n\t\treturn rc;\n\t}\n\n\tlen = cper_estatus_len(&tmp_header);\n\tnode_len = GHES_ESTATUS_NODE_LEN(len);\n\testatus_node = (void *)gen_pool_alloc(ghes_estatus_pool, node_len);\n\tif (!estatus_node)\n\t\treturn -ENOMEM;\n\n\testatus_node->ghes = ghes;\n\testatus_node->generic = ghes->generic;\n\testatus_node->task_work.func = NULL;\n\testatus = GHES_ESTATUS_FROM_NODE(estatus_node);\n\n\tif (__ghes_read_estatus(estatus, buf_paddr, fixmap_idx, len)) {\n\t\tghes_clear_estatus(ghes, estatus, buf_paddr, fixmap_idx);\n\t\trc = -ENOENT;\n\t\tgoto no_work;\n\t}\n\n\tsev = ghes_severity(estatus->error_severity);\n\tif (sev >= GHES_SEV_PANIC) {\n\t\tghes_print_queued_estatus();\n\t\t__ghes_panic(ghes, estatus, buf_paddr, fixmap_idx);\n\t}\n\n\tghes_clear_estatus(ghes, &tmp_header, buf_paddr, fixmap_idx);\n\n\t \n\tif (ghes_estatus_cached(estatus))\n\t\tgoto no_work;\n\n\tllist_add(&estatus_node->llnode, &ghes_estatus_llist);\n\n\treturn rc;\n\nno_work:\n\tgen_pool_free(ghes_estatus_pool, (unsigned long)estatus_node,\n\t\t      node_len);\n\n\treturn rc;\n}\n\nstatic int ghes_in_nmi_spool_from_list(struct list_head *rcu_list,\n\t\t\t\t       enum fixed_addresses fixmap_idx)\n{\n\tint ret = -ENOENT;\n\tstruct ghes *ghes;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(ghes, rcu_list, list) {\n\t\tif (!ghes_in_nmi_queue_one_entry(ghes, fixmap_idx))\n\t\t\tret = 0;\n\t}\n\trcu_read_unlock();\n\n\tif (IS_ENABLED(CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG) && !ret)\n\t\tirq_work_queue(&ghes_proc_irq_work);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_ACPI_APEI_SEA\nstatic LIST_HEAD(ghes_sea);\n\n \nint ghes_notify_sea(void)\n{\n\tstatic DEFINE_RAW_SPINLOCK(ghes_notify_lock_sea);\n\tint rv;\n\n\traw_spin_lock(&ghes_notify_lock_sea);\n\trv = ghes_in_nmi_spool_from_list(&ghes_sea, FIX_APEI_GHES_SEA);\n\traw_spin_unlock(&ghes_notify_lock_sea);\n\n\treturn rv;\n}\n\nstatic void ghes_sea_add(struct ghes *ghes)\n{\n\tmutex_lock(&ghes_list_mutex);\n\tlist_add_rcu(&ghes->list, &ghes_sea);\n\tmutex_unlock(&ghes_list_mutex);\n}\n\nstatic void ghes_sea_remove(struct ghes *ghes)\n{\n\tmutex_lock(&ghes_list_mutex);\n\tlist_del_rcu(&ghes->list);\n\tmutex_unlock(&ghes_list_mutex);\n\tsynchronize_rcu();\n}\n#else  \nstatic inline void ghes_sea_add(struct ghes *ghes) { }\nstatic inline void ghes_sea_remove(struct ghes *ghes) { }\n#endif  \n\n#ifdef CONFIG_HAVE_ACPI_APEI_NMI\n \nstatic atomic_t ghes_in_nmi = ATOMIC_INIT(0);\n\nstatic LIST_HEAD(ghes_nmi);\n\nstatic int ghes_notify_nmi(unsigned int cmd, struct pt_regs *regs)\n{\n\tstatic DEFINE_RAW_SPINLOCK(ghes_notify_lock_nmi);\n\tint ret = NMI_DONE;\n\n\tif (!atomic_add_unless(&ghes_in_nmi, 1, 1))\n\t\treturn ret;\n\n\traw_spin_lock(&ghes_notify_lock_nmi);\n\tif (!ghes_in_nmi_spool_from_list(&ghes_nmi, FIX_APEI_GHES_NMI))\n\t\tret = NMI_HANDLED;\n\traw_spin_unlock(&ghes_notify_lock_nmi);\n\n\tatomic_dec(&ghes_in_nmi);\n\treturn ret;\n}\n\nstatic void ghes_nmi_add(struct ghes *ghes)\n{\n\tmutex_lock(&ghes_list_mutex);\n\tif (list_empty(&ghes_nmi))\n\t\tregister_nmi_handler(NMI_LOCAL, ghes_notify_nmi, 0, \"ghes\");\n\tlist_add_rcu(&ghes->list, &ghes_nmi);\n\tmutex_unlock(&ghes_list_mutex);\n}\n\nstatic void ghes_nmi_remove(struct ghes *ghes)\n{\n\tmutex_lock(&ghes_list_mutex);\n\tlist_del_rcu(&ghes->list);\n\tif (list_empty(&ghes_nmi))\n\t\tunregister_nmi_handler(NMI_LOCAL, \"ghes\");\n\tmutex_unlock(&ghes_list_mutex);\n\t \n\tsynchronize_rcu();\n}\n#else  \nstatic inline void ghes_nmi_add(struct ghes *ghes) { }\nstatic inline void ghes_nmi_remove(struct ghes *ghes) { }\n#endif  \n\nstatic void ghes_nmi_init_cxt(void)\n{\n\tinit_irq_work(&ghes_proc_irq_work, ghes_proc_in_irq);\n}\n\nstatic int __ghes_sdei_callback(struct ghes *ghes,\n\t\t\t\tenum fixed_addresses fixmap_idx)\n{\n\tif (!ghes_in_nmi_queue_one_entry(ghes, fixmap_idx)) {\n\t\tirq_work_queue(&ghes_proc_irq_work);\n\n\t\treturn 0;\n\t}\n\n\treturn -ENOENT;\n}\n\nstatic int ghes_sdei_normal_callback(u32 event_num, struct pt_regs *regs,\n\t\t\t\t      void *arg)\n{\n\tstatic DEFINE_RAW_SPINLOCK(ghes_notify_lock_sdei_normal);\n\tstruct ghes *ghes = arg;\n\tint err;\n\n\traw_spin_lock(&ghes_notify_lock_sdei_normal);\n\terr = __ghes_sdei_callback(ghes, FIX_APEI_GHES_SDEI_NORMAL);\n\traw_spin_unlock(&ghes_notify_lock_sdei_normal);\n\n\treturn err;\n}\n\nstatic int ghes_sdei_critical_callback(u32 event_num, struct pt_regs *regs,\n\t\t\t\t       void *arg)\n{\n\tstatic DEFINE_RAW_SPINLOCK(ghes_notify_lock_sdei_critical);\n\tstruct ghes *ghes = arg;\n\tint err;\n\n\traw_spin_lock(&ghes_notify_lock_sdei_critical);\n\terr = __ghes_sdei_callback(ghes, FIX_APEI_GHES_SDEI_CRITICAL);\n\traw_spin_unlock(&ghes_notify_lock_sdei_critical);\n\n\treturn err;\n}\n\nstatic int apei_sdei_register_ghes(struct ghes *ghes)\n{\n\tif (!IS_ENABLED(CONFIG_ARM_SDE_INTERFACE))\n\t\treturn -EOPNOTSUPP;\n\n\treturn sdei_register_ghes(ghes, ghes_sdei_normal_callback,\n\t\t\t\t ghes_sdei_critical_callback);\n}\n\nstatic int apei_sdei_unregister_ghes(struct ghes *ghes)\n{\n\tif (!IS_ENABLED(CONFIG_ARM_SDE_INTERFACE))\n\t\treturn -EOPNOTSUPP;\n\n\treturn sdei_unregister_ghes(ghes);\n}\n\nstatic int ghes_probe(struct platform_device *ghes_dev)\n{\n\tstruct acpi_hest_generic *generic;\n\tstruct ghes *ghes = NULL;\n\tunsigned long flags;\n\n\tint rc = -EINVAL;\n\n\tgeneric = *(struct acpi_hest_generic **)ghes_dev->dev.platform_data;\n\tif (!generic->enabled)\n\t\treturn -ENODEV;\n\n\tswitch (generic->notify.type) {\n\tcase ACPI_HEST_NOTIFY_POLLED:\n\tcase ACPI_HEST_NOTIFY_EXTERNAL:\n\tcase ACPI_HEST_NOTIFY_SCI:\n\tcase ACPI_HEST_NOTIFY_GSIV:\n\tcase ACPI_HEST_NOTIFY_GPIO:\n\t\tbreak;\n\n\tcase ACPI_HEST_NOTIFY_SEA:\n\t\tif (!IS_ENABLED(CONFIG_ACPI_APEI_SEA)) {\n\t\t\tpr_warn(GHES_PFX \"Generic hardware error source: %d notified via SEA is not supported\\n\",\n\t\t\t\tgeneric->header.source_id);\n\t\t\trc = -ENOTSUPP;\n\t\t\tgoto err;\n\t\t}\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_NMI:\n\t\tif (!IS_ENABLED(CONFIG_HAVE_ACPI_APEI_NMI)) {\n\t\t\tpr_warn(GHES_PFX \"Generic hardware error source: %d notified via NMI interrupt is not supported!\\n\",\n\t\t\t\tgeneric->header.source_id);\n\t\t\tgoto err;\n\t\t}\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_SOFTWARE_DELEGATED:\n\t\tif (!IS_ENABLED(CONFIG_ARM_SDE_INTERFACE)) {\n\t\t\tpr_warn(GHES_PFX \"Generic hardware error source: %d notified via SDE Interface is not supported!\\n\",\n\t\t\t\tgeneric->header.source_id);\n\t\t\tgoto err;\n\t\t}\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_LOCAL:\n\t\tpr_warn(GHES_PFX \"Generic hardware error source: %d notified via local interrupt is not supported!\\n\",\n\t\t\tgeneric->header.source_id);\n\t\tgoto err;\n\tdefault:\n\t\tpr_warn(FW_WARN GHES_PFX \"Unknown notification type: %u for generic hardware error source: %d\\n\",\n\t\t\tgeneric->notify.type, generic->header.source_id);\n\t\tgoto err;\n\t}\n\n\trc = -EIO;\n\tif (generic->error_block_length <\n\t    sizeof(struct acpi_hest_generic_status)) {\n\t\tpr_warn(FW_BUG GHES_PFX \"Invalid error block length: %u for generic hardware error source: %d\\n\",\n\t\t\tgeneric->error_block_length, generic->header.source_id);\n\t\tgoto err;\n\t}\n\tghes = ghes_new(generic);\n\tif (IS_ERR(ghes)) {\n\t\trc = PTR_ERR(ghes);\n\t\tghes = NULL;\n\t\tgoto err;\n\t}\n\n\tswitch (generic->notify.type) {\n\tcase ACPI_HEST_NOTIFY_POLLED:\n\t\ttimer_setup(&ghes->timer, ghes_poll_func, 0);\n\t\tghes_add_timer(ghes);\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_EXTERNAL:\n\t\t \n\t\trc = acpi_gsi_to_irq(generic->notify.vector, &ghes->irq);\n\t\tif (rc) {\n\t\t\tpr_err(GHES_PFX \"Failed to map GSI to IRQ for generic hardware error source: %d\\n\",\n\t\t\t       generic->header.source_id);\n\t\t\tgoto err;\n\t\t}\n\t\trc = request_irq(ghes->irq, ghes_irq_func, IRQF_SHARED,\n\t\t\t\t \"GHES IRQ\", ghes);\n\t\tif (rc) {\n\t\t\tpr_err(GHES_PFX \"Failed to register IRQ for generic hardware error source: %d\\n\",\n\t\t\t       generic->header.source_id);\n\t\t\tgoto err;\n\t\t}\n\t\tbreak;\n\n\tcase ACPI_HEST_NOTIFY_SCI:\n\tcase ACPI_HEST_NOTIFY_GSIV:\n\tcase ACPI_HEST_NOTIFY_GPIO:\n\t\tmutex_lock(&ghes_list_mutex);\n\t\tif (list_empty(&ghes_hed))\n\t\t\tregister_acpi_hed_notifier(&ghes_notifier_hed);\n\t\tlist_add_rcu(&ghes->list, &ghes_hed);\n\t\tmutex_unlock(&ghes_list_mutex);\n\t\tbreak;\n\n\tcase ACPI_HEST_NOTIFY_SEA:\n\t\tghes_sea_add(ghes);\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_NMI:\n\t\tghes_nmi_add(ghes);\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_SOFTWARE_DELEGATED:\n\t\trc = apei_sdei_register_ghes(ghes);\n\t\tif (rc)\n\t\t\tgoto err;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tplatform_set_drvdata(ghes_dev, ghes);\n\n\tghes->dev = &ghes_dev->dev;\n\n\tmutex_lock(&ghes_devs_mutex);\n\tlist_add_tail(&ghes->elist, &ghes_devs);\n\tmutex_unlock(&ghes_devs_mutex);\n\n\t \n\tspin_lock_irqsave(&ghes_notify_lock_irq, flags);\n\tghes_proc(ghes);\n\tspin_unlock_irqrestore(&ghes_notify_lock_irq, flags);\n\n\treturn 0;\n\nerr:\n\tif (ghes) {\n\t\tghes_fini(ghes);\n\t\tkfree(ghes);\n\t}\n\treturn rc;\n}\n\nstatic int ghes_remove(struct platform_device *ghes_dev)\n{\n\tint rc;\n\tstruct ghes *ghes;\n\tstruct acpi_hest_generic *generic;\n\n\tghes = platform_get_drvdata(ghes_dev);\n\tgeneric = ghes->generic;\n\n\tghes->flags |= GHES_EXITING;\n\tswitch (generic->notify.type) {\n\tcase ACPI_HEST_NOTIFY_POLLED:\n\t\ttimer_shutdown_sync(&ghes->timer);\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_EXTERNAL:\n\t\tfree_irq(ghes->irq, ghes);\n\t\tbreak;\n\n\tcase ACPI_HEST_NOTIFY_SCI:\n\tcase ACPI_HEST_NOTIFY_GSIV:\n\tcase ACPI_HEST_NOTIFY_GPIO:\n\t\tmutex_lock(&ghes_list_mutex);\n\t\tlist_del_rcu(&ghes->list);\n\t\tif (list_empty(&ghes_hed))\n\t\t\tunregister_acpi_hed_notifier(&ghes_notifier_hed);\n\t\tmutex_unlock(&ghes_list_mutex);\n\t\tsynchronize_rcu();\n\t\tbreak;\n\n\tcase ACPI_HEST_NOTIFY_SEA:\n\t\tghes_sea_remove(ghes);\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_NMI:\n\t\tghes_nmi_remove(ghes);\n\t\tbreak;\n\tcase ACPI_HEST_NOTIFY_SOFTWARE_DELEGATED:\n\t\trc = apei_sdei_unregister_ghes(ghes);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t\tbreak;\n\t}\n\n\tghes_fini(ghes);\n\n\tmutex_lock(&ghes_devs_mutex);\n\tlist_del(&ghes->elist);\n\tmutex_unlock(&ghes_devs_mutex);\n\n\tkfree(ghes);\n\n\treturn 0;\n}\n\nstatic struct platform_driver ghes_platform_driver = {\n\t.driver\t\t= {\n\t\t.name\t= \"GHES\",\n\t},\n\t.probe\t\t= ghes_probe,\n\t.remove\t\t= ghes_remove,\n};\n\nvoid __init acpi_ghes_init(void)\n{\n\tint rc;\n\n\tsdei_init();\n\n\tif (acpi_disabled)\n\t\treturn;\n\n\tswitch (hest_disable) {\n\tcase HEST_NOT_FOUND:\n\t\treturn;\n\tcase HEST_DISABLED:\n\t\tpr_info(GHES_PFX \"HEST is not enabled!\\n\");\n\t\treturn;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (ghes_disable) {\n\t\tpr_info(GHES_PFX \"GHES is not enabled!\\n\");\n\t\treturn;\n\t}\n\n\tghes_nmi_init_cxt();\n\n\trc = platform_driver_register(&ghes_platform_driver);\n\tif (rc)\n\t\treturn;\n\n\trc = apei_osc_setup();\n\tif (rc == 0 && osc_sb_apei_support_acked)\n\t\tpr_info(GHES_PFX \"APEI firmware first mode is enabled by APEI bit and WHEA _OSC.\\n\");\n\telse if (rc == 0 && !osc_sb_apei_support_acked)\n\t\tpr_info(GHES_PFX \"APEI firmware first mode is enabled by WHEA _OSC.\\n\");\n\telse if (rc && osc_sb_apei_support_acked)\n\t\tpr_info(GHES_PFX \"APEI firmware first mode is enabled by APEI bit.\\n\");\n\telse\n\t\tpr_info(GHES_PFX \"Failed to enable APEI firmware first mode.\\n\");\n}\n\n \nstatic struct acpi_platform_list plat_list[] = {\n\t{\"HPE   \", \"Server  \", 0, ACPI_SIG_FADT, all_versions},\n\t{ }  \n};\n\nstruct list_head *ghes_get_devices(void)\n{\n\tint idx = -1;\n\n\tif (IS_ENABLED(CONFIG_X86)) {\n\t\tidx = acpi_match_platform_list(plat_list);\n\t\tif (idx < 0) {\n\t\t\tif (!ghes_edac_force_enable)\n\t\t\t\treturn NULL;\n\n\t\t\tpr_warn_once(\"Force-loading ghes_edac on an unsupported platform. You're on your own!\\n\");\n\t\t}\n\t} else if (list_empty(&ghes_devs)) {\n\t\treturn NULL;\n\t}\n\n\treturn &ghes_devs;\n}\nEXPORT_SYMBOL_GPL(ghes_get_devices);\n\nvoid ghes_register_report_chain(struct notifier_block *nb)\n{\n\tatomic_notifier_chain_register(&ghes_report_chain, nb);\n}\nEXPORT_SYMBOL_GPL(ghes_register_report_chain);\n\nvoid ghes_unregister_report_chain(struct notifier_block *nb)\n{\n\tatomic_notifier_chain_unregister(&ghes_report_chain, nb);\n}\nEXPORT_SYMBOL_GPL(ghes_unregister_report_chain);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}