{
  "module_name": "core.c",
  "hash_id": "d13e0ab9b18305e2cf84d70873d5d9e4f0d0e7c3fa92ae6245d14a477ae26178",
  "original_prompt": "Ingested from linux-6.6.14/drivers/sh/clk/core.c",
  "human_readable_source": " \n#define pr_fmt(fmt) \"clock: \" fmt\n\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/syscore_ops.h>\n#include <linux/seq_file.h>\n#include <linux/err.h>\n#include <linux/io.h>\n#include <linux/cpufreq.h>\n#include <linux/clk.h>\n#include <linux/sh_clk.h>\n\nstatic LIST_HEAD(clock_list);\nstatic DEFINE_SPINLOCK(clock_lock);\nstatic DEFINE_MUTEX(clock_list_sem);\n\n \nstatic int allow_disable;\n\nvoid clk_rate_table_build(struct clk *clk,\n\t\t\t  struct cpufreq_frequency_table *freq_table,\n\t\t\t  int nr_freqs,\n\t\t\t  struct clk_div_mult_table *src_table,\n\t\t\t  unsigned long *bitmap)\n{\n\tunsigned long mult, div;\n\tunsigned long freq;\n\tint i;\n\n\tclk->nr_freqs = nr_freqs;\n\n\tfor (i = 0; i < nr_freqs; i++) {\n\t\tdiv = 1;\n\t\tmult = 1;\n\n\t\tif (src_table->divisors && i < src_table->nr_divisors)\n\t\t\tdiv = src_table->divisors[i];\n\n\t\tif (src_table->multipliers && i < src_table->nr_multipliers)\n\t\t\tmult = src_table->multipliers[i];\n\n\t\tif (!div || !mult || (bitmap && !test_bit(i, bitmap)))\n\t\t\tfreq = CPUFREQ_ENTRY_INVALID;\n\t\telse\n\t\t\tfreq = clk->parent->rate * mult / div;\n\n\t\tfreq_table[i].driver_data = i;\n\t\tfreq_table[i].frequency = freq;\n\t}\n\n\t \n\tfreq_table[i].driver_data = i;\n\tfreq_table[i].frequency = CPUFREQ_TABLE_END;\n}\n\nstruct clk_rate_round_data;\n\nstruct clk_rate_round_data {\n\tunsigned long rate;\n\tunsigned int min, max;\n\tlong (*func)(unsigned int, struct clk_rate_round_data *);\n\tvoid *arg;\n};\n\n#define for_each_frequency(pos, r, freq)\t\t\t\\\n\tfor (pos = r->min, freq = r->func(pos, r);\t\t\\\n\t     pos <= r->max; pos++, freq = r->func(pos, r))\t\\\n\t\tif (unlikely(freq == 0))\t\t\t\\\n\t\t\t;\t\t\t\t\t\\\n\t\telse\n\nstatic long clk_rate_round_helper(struct clk_rate_round_data *rounder)\n{\n\tunsigned long rate_error, rate_error_prev = ~0UL;\n\tunsigned long highest, lowest, freq;\n\tlong rate_best_fit = -ENOENT;\n\tint i;\n\n\thighest = 0;\n\tlowest = ~0UL;\n\n\tfor_each_frequency(i, rounder, freq) {\n\t\tif (freq > highest)\n\t\t\thighest = freq;\n\t\tif (freq < lowest)\n\t\t\tlowest = freq;\n\n\t\trate_error = abs(freq - rounder->rate);\n\t\tif (rate_error < rate_error_prev) {\n\t\t\trate_best_fit = freq;\n\t\t\trate_error_prev = rate_error;\n\t\t}\n\n\t\tif (rate_error == 0)\n\t\t\tbreak;\n\t}\n\n\tif (rounder->rate >= highest)\n\t\trate_best_fit = highest;\n\tif (rounder->rate <= lowest)\n\t\trate_best_fit = lowest;\n\n\treturn rate_best_fit;\n}\n\nstatic long clk_rate_table_iter(unsigned int pos,\n\t\t\t\tstruct clk_rate_round_data *rounder)\n{\n\tstruct cpufreq_frequency_table *freq_table = rounder->arg;\n\tunsigned long freq = freq_table[pos].frequency;\n\n\tif (freq == CPUFREQ_ENTRY_INVALID)\n\t\tfreq = 0;\n\n\treturn freq;\n}\n\nlong clk_rate_table_round(struct clk *clk,\n\t\t\t  struct cpufreq_frequency_table *freq_table,\n\t\t\t  unsigned long rate)\n{\n\tstruct clk_rate_round_data table_round = {\n\t\t.min\t= 0,\n\t\t.max\t= clk->nr_freqs - 1,\n\t\t.func\t= clk_rate_table_iter,\n\t\t.arg\t= freq_table,\n\t\t.rate\t= rate,\n\t};\n\n\tif (clk->nr_freqs < 1)\n\t\treturn -ENOSYS;\n\n\treturn clk_rate_round_helper(&table_round);\n}\n\nstatic long clk_rate_div_range_iter(unsigned int pos,\n\t\t\t\t    struct clk_rate_round_data *rounder)\n{\n\treturn clk_get_rate(rounder->arg) / pos;\n}\n\nlong clk_rate_div_range_round(struct clk *clk, unsigned int div_min,\n\t\t\t      unsigned int div_max, unsigned long rate)\n{\n\tstruct clk_rate_round_data div_range_round = {\n\t\t.min\t= div_min,\n\t\t.max\t= div_max,\n\t\t.func\t= clk_rate_div_range_iter,\n\t\t.arg\t= clk_get_parent(clk),\n\t\t.rate\t= rate,\n\t};\n\n\treturn clk_rate_round_helper(&div_range_round);\n}\n\nstatic long clk_rate_mult_range_iter(unsigned int pos,\n\t\t\t\t      struct clk_rate_round_data *rounder)\n{\n\treturn clk_get_rate(rounder->arg) * pos;\n}\n\nlong clk_rate_mult_range_round(struct clk *clk, unsigned int mult_min,\n\t\t\t       unsigned int mult_max, unsigned long rate)\n{\n\tstruct clk_rate_round_data mult_range_round = {\n\t\t.min\t= mult_min,\n\t\t.max\t= mult_max,\n\t\t.func\t= clk_rate_mult_range_iter,\n\t\t.arg\t= clk_get_parent(clk),\n\t\t.rate\t= rate,\n\t};\n\n\treturn clk_rate_round_helper(&mult_range_round);\n}\n\nint clk_rate_table_find(struct clk *clk,\n\t\t\tstruct cpufreq_frequency_table *freq_table,\n\t\t\tunsigned long rate)\n{\n\tstruct cpufreq_frequency_table *pos;\n\tint idx;\n\n\tcpufreq_for_each_valid_entry_idx(pos, freq_table, idx)\n\t\tif (pos->frequency == rate)\n\t\t\treturn idx;\n\n\treturn -ENOENT;\n}\n\n \nunsigned long followparent_recalc(struct clk *clk)\n{\n\treturn clk->parent ? clk->parent->rate : 0;\n}\n\nint clk_reparent(struct clk *child, struct clk *parent)\n{\n\tlist_del_init(&child->sibling);\n\tif (parent)\n\t\tlist_add(&child->sibling, &parent->children);\n\tchild->parent = parent;\n\n\treturn 0;\n}\n\n \nvoid propagate_rate(struct clk *tclk)\n{\n\tstruct clk *clkp;\n\n\tlist_for_each_entry(clkp, &tclk->children, sibling) {\n\t\tif (clkp->ops && clkp->ops->recalc)\n\t\t\tclkp->rate = clkp->ops->recalc(clkp);\n\n\t\tpropagate_rate(clkp);\n\t}\n}\n\nstatic void __clk_disable(struct clk *clk)\n{\n\tif (WARN(!clk->usecount, \"Trying to disable clock %p with 0 usecount\\n\",\n\t\t clk))\n\t\treturn;\n\n\tif (!(--clk->usecount)) {\n\t\tif (likely(allow_disable && clk->ops && clk->ops->disable))\n\t\t\tclk->ops->disable(clk);\n\t\tif (likely(clk->parent))\n\t\t\t__clk_disable(clk->parent);\n\t}\n}\n\nvoid clk_disable(struct clk *clk)\n{\n\tunsigned long flags;\n\n\tif (!clk)\n\t\treturn;\n\n\tspin_lock_irqsave(&clock_lock, flags);\n\t__clk_disable(clk);\n\tspin_unlock_irqrestore(&clock_lock, flags);\n}\nEXPORT_SYMBOL_GPL(clk_disable);\n\nstatic int __clk_enable(struct clk *clk)\n{\n\tint ret = 0;\n\n\tif (clk->usecount++ == 0) {\n\t\tif (clk->parent) {\n\t\t\tret = __clk_enable(clk->parent);\n\t\t\tif (unlikely(ret))\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tif (clk->ops && clk->ops->enable) {\n\t\t\tret = clk->ops->enable(clk);\n\t\t\tif (ret) {\n\t\t\t\tif (clk->parent)\n\t\t\t\t\t__clk_disable(clk->parent);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ret;\nerr:\n\tclk->usecount--;\n\treturn ret;\n}\n\nint clk_enable(struct clk *clk)\n{\n\tunsigned long flags;\n\tint ret;\n\n\tif (!clk)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&clock_lock, flags);\n\tret = __clk_enable(clk);\n\tspin_unlock_irqrestore(&clock_lock, flags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(clk_enable);\n\nstatic LIST_HEAD(root_clks);\n\n \nvoid recalculate_root_clocks(void)\n{\n\tstruct clk *clkp;\n\n\tlist_for_each_entry(clkp, &root_clks, sibling) {\n\t\tif (clkp->ops && clkp->ops->recalc)\n\t\t\tclkp->rate = clkp->ops->recalc(clkp);\n\t\tpropagate_rate(clkp);\n\t}\n}\n\nstatic struct clk_mapping dummy_mapping;\n\nstatic struct clk *lookup_root_clock(struct clk *clk)\n{\n\twhile (clk->parent)\n\t\tclk = clk->parent;\n\n\treturn clk;\n}\n\nstatic int clk_establish_mapping(struct clk *clk)\n{\n\tstruct clk_mapping *mapping = clk->mapping;\n\n\t \n\tif (!mapping) {\n\t\tstruct clk *clkp;\n\n\t\t \n\t\tif (!clk->parent) {\n\t\t\tclk->mapping = &dummy_mapping;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tclkp = lookup_root_clock(clk);\n\t\tmapping = clkp->mapping;\n\t\tBUG_ON(!mapping);\n\t}\n\n\t \n\tif (!mapping->base && mapping->phys) {\n\t\tkref_init(&mapping->ref);\n\n\t\tmapping->base = ioremap(mapping->phys, mapping->len);\n\t\tif (unlikely(!mapping->base))\n\t\t\treturn -ENXIO;\n\t} else if (mapping->base) {\n\t\t \n\t\tkref_get(&mapping->ref);\n\t}\n\n\tclk->mapping = mapping;\nout:\n\tclk->mapped_reg = clk->mapping->base;\n\tclk->mapped_reg += (phys_addr_t)clk->enable_reg - clk->mapping->phys;\n\treturn 0;\n}\n\nstatic void clk_destroy_mapping(struct kref *kref)\n{\n\tstruct clk_mapping *mapping;\n\n\tmapping = container_of(kref, struct clk_mapping, ref);\n\n\tiounmap(mapping->base);\n}\n\nstatic void clk_teardown_mapping(struct clk *clk)\n{\n\tstruct clk_mapping *mapping = clk->mapping;\n\n\t \n\tif (mapping == &dummy_mapping)\n\t\tgoto out;\n\n\tkref_put(&mapping->ref, clk_destroy_mapping);\n\tclk->mapping = NULL;\nout:\n\tclk->mapped_reg = NULL;\n}\n\nint clk_register(struct clk *clk)\n{\n\tint ret;\n\n\tif (IS_ERR_OR_NULL(clk))\n\t\treturn -EINVAL;\n\n\t \n\tif (clk->node.next || clk->node.prev)\n\t\treturn 0;\n\n\tmutex_lock(&clock_list_sem);\n\n\tINIT_LIST_HEAD(&clk->children);\n\tclk->usecount = 0;\n\n\tret = clk_establish_mapping(clk);\n\tif (unlikely(ret))\n\t\tgoto out_unlock;\n\n\tif (clk->parent)\n\t\tlist_add(&clk->sibling, &clk->parent->children);\n\telse\n\t\tlist_add(&clk->sibling, &root_clks);\n\n\tlist_add(&clk->node, &clock_list);\n\n#ifdef CONFIG_SH_CLK_CPG_LEGACY\n\tif (clk->ops && clk->ops->init)\n\t\tclk->ops->init(clk);\n#endif\n\nout_unlock:\n\tmutex_unlock(&clock_list_sem);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(clk_register);\n\nvoid clk_unregister(struct clk *clk)\n{\n\tmutex_lock(&clock_list_sem);\n\tlist_del(&clk->sibling);\n\tlist_del(&clk->node);\n\tclk_teardown_mapping(clk);\n\tmutex_unlock(&clock_list_sem);\n}\nEXPORT_SYMBOL_GPL(clk_unregister);\n\nvoid clk_enable_init_clocks(void)\n{\n\tstruct clk *clkp;\n\n\tlist_for_each_entry(clkp, &clock_list, node)\n\t\tif (clkp->flags & CLK_ENABLE_ON_INIT)\n\t\t\tclk_enable(clkp);\n}\n\nunsigned long clk_get_rate(struct clk *clk)\n{\n\tif (!clk)\n\t\treturn 0;\n\n\treturn clk->rate;\n}\nEXPORT_SYMBOL_GPL(clk_get_rate);\n\nint clk_set_rate(struct clk *clk, unsigned long rate)\n{\n\tint ret = -EOPNOTSUPP;\n\tunsigned long flags;\n\n\tif (!clk)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&clock_lock, flags);\n\n\tif (likely(clk->ops && clk->ops->set_rate)) {\n\t\tret = clk->ops->set_rate(clk, rate);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t} else {\n\t\tclk->rate = rate;\n\t\tret = 0;\n\t}\n\n\tif (clk->ops && clk->ops->recalc)\n\t\tclk->rate = clk->ops->recalc(clk);\n\n\tpropagate_rate(clk);\n\nout_unlock:\n\tspin_unlock_irqrestore(&clock_lock, flags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(clk_set_rate);\n\nint clk_set_parent(struct clk *clk, struct clk *parent)\n{\n\tunsigned long flags;\n\tint ret = -EINVAL;\n\n\tif (!parent || !clk)\n\t\treturn ret;\n\tif (clk->parent == parent)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&clock_lock, flags);\n\tif (clk->usecount == 0) {\n\t\tif (clk->ops->set_parent)\n\t\t\tret = clk->ops->set_parent(clk, parent);\n\t\telse\n\t\t\tret = clk_reparent(clk, parent);\n\n\t\tif (ret == 0) {\n\t\t\tif (clk->ops->recalc)\n\t\t\t\tclk->rate = clk->ops->recalc(clk);\n\t\t\tpr_debug(\"set parent of %p to %p (new rate %ld)\\n\",\n\t\t\t\t clk, clk->parent, clk->rate);\n\t\t\tpropagate_rate(clk);\n\t\t}\n\t} else\n\t\tret = -EBUSY;\n\tspin_unlock_irqrestore(&clock_lock, flags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(clk_set_parent);\n\nstruct clk *clk_get_parent(struct clk *clk)\n{\n\tif (!clk)\n\t\treturn NULL;\n\n\treturn clk->parent;\n}\nEXPORT_SYMBOL_GPL(clk_get_parent);\n\nlong clk_round_rate(struct clk *clk, unsigned long rate)\n{\n\tif (!clk)\n\t\treturn 0;\n\n\tif (likely(clk->ops && clk->ops->round_rate)) {\n\t\tunsigned long flags, rounded;\n\n\t\tspin_lock_irqsave(&clock_lock, flags);\n\t\trounded = clk->ops->round_rate(clk, rate);\n\t\tspin_unlock_irqrestore(&clock_lock, flags);\n\n\t\treturn rounded;\n\t}\n\n\treturn clk_get_rate(clk);\n}\nEXPORT_SYMBOL_GPL(clk_round_rate);\n\n#ifdef CONFIG_PM\nstatic void clks_core_resume(void)\n{\n\tstruct clk *clkp;\n\n\tlist_for_each_entry(clkp, &clock_list, node) {\n\t\tif (likely(clkp->usecount && clkp->ops)) {\n\t\t\tunsigned long rate = clkp->rate;\n\n\t\t\tif (likely(clkp->ops->set_parent))\n\t\t\t\tclkp->ops->set_parent(clkp,\n\t\t\t\t\tclkp->parent);\n\t\t\tif (likely(clkp->ops->set_rate))\n\t\t\t\tclkp->ops->set_rate(clkp, rate);\n\t\t\telse if (likely(clkp->ops->recalc))\n\t\t\t\tclkp->rate = clkp->ops->recalc(clkp);\n\t\t}\n\t}\n}\n\nstatic struct syscore_ops clks_syscore_ops = {\n\t.resume = clks_core_resume,\n};\n\nstatic int __init clk_syscore_init(void)\n{\n\tregister_syscore_ops(&clks_syscore_ops);\n\n\treturn 0;\n}\nsubsys_initcall(clk_syscore_init);\n#endif\n\nstatic int __init clk_late_init(void)\n{\n\tunsigned long flags;\n\tstruct clk *clk;\n\n\t \n\tmutex_lock(&clock_list_sem);\n\tspin_lock_irqsave(&clock_lock, flags);\n\n\tlist_for_each_entry(clk, &clock_list, node)\n\t\tif (!clk->usecount && clk->ops && clk->ops->disable)\n\t\t\tclk->ops->disable(clk);\n\n\t \n\tallow_disable = 1;\n\n\tspin_unlock_irqrestore(&clock_lock, flags);\n\tmutex_unlock(&clock_list_sem);\n\treturn 0;\n}\nlate_initcall(clk_late_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}