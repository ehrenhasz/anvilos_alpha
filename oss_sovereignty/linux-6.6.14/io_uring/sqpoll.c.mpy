{
  "module_name": "sqpoll.c",
  "hash_id": "0c9ad0396a626cc4ecc6b79cf086e78cbae87210ba8344511b9c1cd206b51a5b",
  "original_prompt": "Ingested from linux-6.6.14/io_uring/sqpoll.c",
  "human_readable_source": "\n \n#include <linux/kernel.h>\n#include <linux/errno.h>\n#include <linux/file.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/audit.h>\n#include <linux/security.h>\n#include <linux/io_uring.h>\n\n#include <uapi/linux/io_uring.h>\n\n#include \"io_uring.h\"\n#include \"sqpoll.h\"\n\n#define IORING_SQPOLL_CAP_ENTRIES_VALUE 8\n\nenum {\n\tIO_SQ_THREAD_SHOULD_STOP = 0,\n\tIO_SQ_THREAD_SHOULD_PARK,\n};\n\nvoid io_sq_thread_unpark(struct io_sq_data *sqd)\n\t__releases(&sqd->lock)\n{\n\tWARN_ON_ONCE(sqd->thread == current);\n\n\t \n\tclear_bit(IO_SQ_THREAD_SHOULD_PARK, &sqd->state);\n\tif (atomic_dec_return(&sqd->park_pending))\n\t\tset_bit(IO_SQ_THREAD_SHOULD_PARK, &sqd->state);\n\tmutex_unlock(&sqd->lock);\n}\n\nvoid io_sq_thread_park(struct io_sq_data *sqd)\n\t__acquires(&sqd->lock)\n{\n\tWARN_ON_ONCE(sqd->thread == current);\n\n\tatomic_inc(&sqd->park_pending);\n\tset_bit(IO_SQ_THREAD_SHOULD_PARK, &sqd->state);\n\tmutex_lock(&sqd->lock);\n\tif (sqd->thread)\n\t\twake_up_process(sqd->thread);\n}\n\nvoid io_sq_thread_stop(struct io_sq_data *sqd)\n{\n\tWARN_ON_ONCE(sqd->thread == current);\n\tWARN_ON_ONCE(test_bit(IO_SQ_THREAD_SHOULD_STOP, &sqd->state));\n\n\tset_bit(IO_SQ_THREAD_SHOULD_STOP, &sqd->state);\n\tmutex_lock(&sqd->lock);\n\tif (sqd->thread)\n\t\twake_up_process(sqd->thread);\n\tmutex_unlock(&sqd->lock);\n\twait_for_completion(&sqd->exited);\n}\n\nvoid io_put_sq_data(struct io_sq_data *sqd)\n{\n\tif (refcount_dec_and_test(&sqd->refs)) {\n\t\tWARN_ON_ONCE(atomic_read(&sqd->park_pending));\n\n\t\tio_sq_thread_stop(sqd);\n\t\tkfree(sqd);\n\t}\n}\n\nstatic __cold void io_sqd_update_thread_idle(struct io_sq_data *sqd)\n{\n\tstruct io_ring_ctx *ctx;\n\tunsigned sq_thread_idle = 0;\n\n\tlist_for_each_entry(ctx, &sqd->ctx_list, sqd_list)\n\t\tsq_thread_idle = max(sq_thread_idle, ctx->sq_thread_idle);\n\tsqd->sq_thread_idle = sq_thread_idle;\n}\n\nvoid io_sq_thread_finish(struct io_ring_ctx *ctx)\n{\n\tstruct io_sq_data *sqd = ctx->sq_data;\n\n\tif (sqd) {\n\t\tio_sq_thread_park(sqd);\n\t\tlist_del_init(&ctx->sqd_list);\n\t\tio_sqd_update_thread_idle(sqd);\n\t\tio_sq_thread_unpark(sqd);\n\n\t\tio_put_sq_data(sqd);\n\t\tctx->sq_data = NULL;\n\t}\n}\n\nstatic struct io_sq_data *io_attach_sq_data(struct io_uring_params *p)\n{\n\tstruct io_ring_ctx *ctx_attach;\n\tstruct io_sq_data *sqd;\n\tstruct fd f;\n\n\tf = fdget(p->wq_fd);\n\tif (!f.file)\n\t\treturn ERR_PTR(-ENXIO);\n\tif (!io_is_uring_fops(f.file)) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tctx_attach = f.file->private_data;\n\tsqd = ctx_attach->sq_data;\n\tif (!sqd) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif (sqd->task_tgid != current->tgid) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-EPERM);\n\t}\n\n\trefcount_inc(&sqd->refs);\n\tfdput(f);\n\treturn sqd;\n}\n\nstatic struct io_sq_data *io_get_sq_data(struct io_uring_params *p,\n\t\t\t\t\t bool *attached)\n{\n\tstruct io_sq_data *sqd;\n\n\t*attached = false;\n\tif (p->flags & IORING_SETUP_ATTACH_WQ) {\n\t\tsqd = io_attach_sq_data(p);\n\t\tif (!IS_ERR(sqd)) {\n\t\t\t*attached = true;\n\t\t\treturn sqd;\n\t\t}\n\t\t \n\t\tif (PTR_ERR(sqd) != -EPERM)\n\t\t\treturn sqd;\n\t}\n\n\tsqd = kzalloc(sizeof(*sqd), GFP_KERNEL);\n\tif (!sqd)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tatomic_set(&sqd->park_pending, 0);\n\trefcount_set(&sqd->refs, 1);\n\tINIT_LIST_HEAD(&sqd->ctx_list);\n\tmutex_init(&sqd->lock);\n\tinit_waitqueue_head(&sqd->wait);\n\tinit_completion(&sqd->exited);\n\treturn sqd;\n}\n\nstatic inline bool io_sqd_events_pending(struct io_sq_data *sqd)\n{\n\treturn READ_ONCE(sqd->state);\n}\n\nstatic int __io_sq_thread(struct io_ring_ctx *ctx, bool cap_entries)\n{\n\tunsigned int to_submit;\n\tint ret = 0;\n\n\tto_submit = io_sqring_entries(ctx);\n\t \n\tif (cap_entries && to_submit > IORING_SQPOLL_CAP_ENTRIES_VALUE)\n\t\tto_submit = IORING_SQPOLL_CAP_ENTRIES_VALUE;\n\n\tif (!wq_list_empty(&ctx->iopoll_list) || to_submit) {\n\t\tconst struct cred *creds = NULL;\n\n\t\tif (ctx->sq_creds != current_cred())\n\t\t\tcreds = override_creds(ctx->sq_creds);\n\n\t\tmutex_lock(&ctx->uring_lock);\n\t\tif (!wq_list_empty(&ctx->iopoll_list))\n\t\t\tio_do_iopoll(ctx, true);\n\n\t\t \n\t\tif (to_submit && likely(!percpu_ref_is_dying(&ctx->refs)) &&\n\t\t    !(ctx->flags & IORING_SETUP_R_DISABLED))\n\t\t\tret = io_submit_sqes(ctx, to_submit);\n\t\tmutex_unlock(&ctx->uring_lock);\n\n\t\tif (to_submit && wq_has_sleeper(&ctx->sqo_sq_wait))\n\t\t\twake_up(&ctx->sqo_sq_wait);\n\t\tif (creds)\n\t\t\trevert_creds(creds);\n\t}\n\n\treturn ret;\n}\n\nstatic bool io_sqd_handle_event(struct io_sq_data *sqd)\n{\n\tbool did_sig = false;\n\tstruct ksignal ksig;\n\n\tif (test_bit(IO_SQ_THREAD_SHOULD_PARK, &sqd->state) ||\n\t    signal_pending(current)) {\n\t\tmutex_unlock(&sqd->lock);\n\t\tif (signal_pending(current))\n\t\t\tdid_sig = get_signal(&ksig);\n\t\tcond_resched();\n\t\tmutex_lock(&sqd->lock);\n\t\tsqd->sq_cpu = raw_smp_processor_id();\n\t}\n\treturn did_sig || test_bit(IO_SQ_THREAD_SHOULD_STOP, &sqd->state);\n}\n\nstatic int io_sq_thread(void *data)\n{\n\tstruct io_sq_data *sqd = data;\n\tstruct io_ring_ctx *ctx;\n\tunsigned long timeout = 0;\n\tchar buf[TASK_COMM_LEN];\n\tDEFINE_WAIT(wait);\n\n\tsnprintf(buf, sizeof(buf), \"iou-sqp-%d\", sqd->task_pid);\n\tset_task_comm(current, buf);\n\n\t \n\tsqd->task_pid = current->pid;\n\n\tif (sqd->sq_cpu != -1) {\n\t\tset_cpus_allowed_ptr(current, cpumask_of(sqd->sq_cpu));\n\t} else {\n\t\tset_cpus_allowed_ptr(current, cpu_online_mask);\n\t\tsqd->sq_cpu = raw_smp_processor_id();\n\t}\n\n\tmutex_lock(&sqd->lock);\n\twhile (1) {\n\t\tbool cap_entries, sqt_spin = false;\n\n\t\tif (io_sqd_events_pending(sqd) || signal_pending(current)) {\n\t\t\tif (io_sqd_handle_event(sqd))\n\t\t\t\tbreak;\n\t\t\ttimeout = jiffies + sqd->sq_thread_idle;\n\t\t}\n\n\t\tcap_entries = !list_is_singular(&sqd->ctx_list);\n\t\tlist_for_each_entry(ctx, &sqd->ctx_list, sqd_list) {\n\t\t\tint ret = __io_sq_thread(ctx, cap_entries);\n\n\t\t\tif (!sqt_spin && (ret > 0 || !wq_list_empty(&ctx->iopoll_list)))\n\t\t\t\tsqt_spin = true;\n\t\t}\n\t\tif (io_run_task_work())\n\t\t\tsqt_spin = true;\n\n\t\tif (sqt_spin || !time_after(jiffies, timeout)) {\n\t\t\tif (sqt_spin)\n\t\t\t\ttimeout = jiffies + sqd->sq_thread_idle;\n\t\t\tif (unlikely(need_resched())) {\n\t\t\t\tmutex_unlock(&sqd->lock);\n\t\t\t\tcond_resched();\n\t\t\t\tmutex_lock(&sqd->lock);\n\t\t\t\tsqd->sq_cpu = raw_smp_processor_id();\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tprepare_to_wait(&sqd->wait, &wait, TASK_INTERRUPTIBLE);\n\t\tif (!io_sqd_events_pending(sqd) && !task_work_pending(current)) {\n\t\t\tbool needs_sched = true;\n\n\t\t\tlist_for_each_entry(ctx, &sqd->ctx_list, sqd_list) {\n\t\t\t\tatomic_or(IORING_SQ_NEED_WAKEUP,\n\t\t\t\t\t\t&ctx->rings->sq_flags);\n\t\t\t\tif ((ctx->flags & IORING_SETUP_IOPOLL) &&\n\t\t\t\t    !wq_list_empty(&ctx->iopoll_list)) {\n\t\t\t\t\tneeds_sched = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tsmp_mb__after_atomic();\n\n\t\t\t\tif (io_sqring_entries(ctx)) {\n\t\t\t\t\tneeds_sched = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (needs_sched) {\n\t\t\t\tmutex_unlock(&sqd->lock);\n\t\t\t\tschedule();\n\t\t\t\tmutex_lock(&sqd->lock);\n\t\t\t\tsqd->sq_cpu = raw_smp_processor_id();\n\t\t\t}\n\t\t\tlist_for_each_entry(ctx, &sqd->ctx_list, sqd_list)\n\t\t\t\tatomic_andnot(IORING_SQ_NEED_WAKEUP,\n\t\t\t\t\t\t&ctx->rings->sq_flags);\n\t\t}\n\n\t\tfinish_wait(&sqd->wait, &wait);\n\t\ttimeout = jiffies + sqd->sq_thread_idle;\n\t}\n\n\tio_uring_cancel_generic(true, sqd);\n\tsqd->thread = NULL;\n\tlist_for_each_entry(ctx, &sqd->ctx_list, sqd_list)\n\t\tatomic_or(IORING_SQ_NEED_WAKEUP, &ctx->rings->sq_flags);\n\tio_run_task_work();\n\tmutex_unlock(&sqd->lock);\n\n\tcomplete(&sqd->exited);\n\tdo_exit(0);\n}\n\nvoid io_sqpoll_wait_sq(struct io_ring_ctx *ctx)\n{\n\tDEFINE_WAIT(wait);\n\n\tdo {\n\t\tif (!io_sqring_full(ctx))\n\t\t\tbreak;\n\t\tprepare_to_wait(&ctx->sqo_sq_wait, &wait, TASK_INTERRUPTIBLE);\n\n\t\tif (!io_sqring_full(ctx))\n\t\t\tbreak;\n\t\tschedule();\n\t} while (!signal_pending(current));\n\n\tfinish_wait(&ctx->sqo_sq_wait, &wait);\n}\n\n__cold int io_sq_offload_create(struct io_ring_ctx *ctx,\n\t\t\t\tstruct io_uring_params *p)\n{\n\tint ret;\n\n\t \n\tif ((ctx->flags & (IORING_SETUP_ATTACH_WQ | IORING_SETUP_SQPOLL)) ==\n\t\t\t\tIORING_SETUP_ATTACH_WQ) {\n\t\tstruct fd f;\n\n\t\tf = fdget(p->wq_fd);\n\t\tif (!f.file)\n\t\t\treturn -ENXIO;\n\t\tif (!io_is_uring_fops(f.file)) {\n\t\t\tfdput(f);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tfdput(f);\n\t}\n\tif (ctx->flags & IORING_SETUP_SQPOLL) {\n\t\tstruct task_struct *tsk;\n\t\tstruct io_sq_data *sqd;\n\t\tbool attached;\n\n\t\tret = security_uring_sqpoll();\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tsqd = io_get_sq_data(p, &attached);\n\t\tif (IS_ERR(sqd)) {\n\t\t\tret = PTR_ERR(sqd);\n\t\t\tgoto err;\n\t\t}\n\n\t\tctx->sq_creds = get_current_cred();\n\t\tctx->sq_data = sqd;\n\t\tctx->sq_thread_idle = msecs_to_jiffies(p->sq_thread_idle);\n\t\tif (!ctx->sq_thread_idle)\n\t\t\tctx->sq_thread_idle = HZ;\n\n\t\tio_sq_thread_park(sqd);\n\t\tlist_add(&ctx->sqd_list, &sqd->ctx_list);\n\t\tio_sqd_update_thread_idle(sqd);\n\t\t \n\t\tret = (attached && !sqd->thread) ? -ENXIO : 0;\n\t\tio_sq_thread_unpark(sqd);\n\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\t\tif (attached)\n\t\t\treturn 0;\n\n\t\tif (p->flags & IORING_SETUP_SQ_AFF) {\n\t\t\tint cpu = p->sq_thread_cpu;\n\n\t\t\tret = -EINVAL;\n\t\t\tif (cpu >= nr_cpu_ids || !cpu_online(cpu))\n\t\t\t\tgoto err_sqpoll;\n\t\t\tsqd->sq_cpu = cpu;\n\t\t} else {\n\t\t\tsqd->sq_cpu = -1;\n\t\t}\n\n\t\tsqd->task_pid = current->pid;\n\t\tsqd->task_tgid = current->tgid;\n\t\ttsk = create_io_thread(io_sq_thread, sqd, NUMA_NO_NODE);\n\t\tif (IS_ERR(tsk)) {\n\t\t\tret = PTR_ERR(tsk);\n\t\t\tgoto err_sqpoll;\n\t\t}\n\n\t\tsqd->thread = tsk;\n\t\tret = io_uring_alloc_task_context(tsk, ctx);\n\t\twake_up_new_task(tsk);\n\t\tif (ret)\n\t\t\tgoto err;\n\t} else if (p->flags & IORING_SETUP_SQ_AFF) {\n\t\t \n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr_sqpoll:\n\tcomplete(&ctx->sq_data->exited);\nerr:\n\tio_sq_thread_finish(ctx);\n\treturn ret;\n}\n\n__cold int io_sqpoll_wq_cpu_affinity(struct io_ring_ctx *ctx,\n\t\t\t\t     cpumask_var_t mask)\n{\n\tstruct io_sq_data *sqd = ctx->sq_data;\n\tint ret = -EINVAL;\n\n\tif (sqd) {\n\t\tio_sq_thread_park(sqd);\n\t\t \n\t\tif (sqd->thread)\n\t\t\tret = io_wq_cpu_affinity(sqd->thread->io_uring, mask);\n\t\tio_sq_thread_unpark(sqd);\n\t}\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}