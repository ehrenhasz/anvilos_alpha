{
  "module_name": "kbuf.h",
  "hash_id": "217ef27960dcbf2a69d2ea9309d8cc896ead88264d926b9bf4fe3d609993c784",
  "original_prompt": "Ingested from linux-6.6.14/io_uring/kbuf.h",
  "human_readable_source": "\n#ifndef IOU_KBUF_H\n#define IOU_KBUF_H\n\n#include <uapi/linux/io_uring.h>\n\nstruct io_buffer_list {\n\t \n\tunion {\n\t\tstruct list_head buf_list;\n\t\tstruct {\n\t\t\tstruct page **buf_pages;\n\t\t\tstruct io_uring_buf_ring *buf_ring;\n\t\t};\n\t\tstruct rcu_head rcu;\n\t};\n\t__u16 bgid;\n\n\t \n\t__u16 buf_nr_pages;\n\t__u16 nr_entries;\n\t__u16 head;\n\t__u16 mask;\n\n\t \n\t__u8 is_mapped;\n\t \n\t__u8 is_mmap;\n\t \n\t__u8 is_ready;\n};\n\nstruct io_buffer {\n\tstruct list_head list;\n\t__u64 addr;\n\t__u32 len;\n\t__u16 bid;\n\t__u16 bgid;\n};\n\nvoid __user *io_buffer_select(struct io_kiocb *req, size_t *len,\n\t\t\t      unsigned int issue_flags);\nvoid io_destroy_buffers(struct io_ring_ctx *ctx);\n\nint io_remove_buffers_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);\nint io_remove_buffers(struct io_kiocb *req, unsigned int issue_flags);\n\nint io_provide_buffers_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);\nint io_provide_buffers(struct io_kiocb *req, unsigned int issue_flags);\n\nint io_register_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);\nint io_unregister_pbuf_ring(struct io_ring_ctx *ctx, void __user *arg);\n\nvoid io_kbuf_mmap_list_free(struct io_ring_ctx *ctx);\n\nunsigned int __io_put_kbuf(struct io_kiocb *req, unsigned issue_flags);\n\nvoid io_kbuf_recycle_legacy(struct io_kiocb *req, unsigned issue_flags);\n\nvoid *io_pbuf_get_address(struct io_ring_ctx *ctx, unsigned long bgid);\n\nstatic inline void io_kbuf_recycle_ring(struct io_kiocb *req)\n{\n\t \n\tif (req->buf_list) {\n\t\tif (req->flags & REQ_F_PARTIAL_IO) {\n\t\t\t \n\t\t\treq->buf_list->head++;\n\t\t\treq->buf_list = NULL;\n\t\t} else {\n\t\t\treq->buf_index = req->buf_list->bgid;\n\t\t\treq->flags &= ~REQ_F_BUFFER_RING;\n\t\t}\n\t}\n}\n\nstatic inline bool io_do_buffer_select(struct io_kiocb *req)\n{\n\tif (!(req->flags & REQ_F_BUFFER_SELECT))\n\t\treturn false;\n\treturn !(req->flags & (REQ_F_BUFFER_SELECTED|REQ_F_BUFFER_RING));\n}\n\nstatic inline void io_kbuf_recycle(struct io_kiocb *req, unsigned issue_flags)\n{\n\tif (req->flags & REQ_F_BUFFER_SELECTED)\n\t\tio_kbuf_recycle_legacy(req, issue_flags);\n\tif (req->flags & REQ_F_BUFFER_RING)\n\t\tio_kbuf_recycle_ring(req);\n}\n\nstatic inline unsigned int __io_put_kbuf_list(struct io_kiocb *req,\n\t\t\t\t\t      struct list_head *list)\n{\n\tunsigned int ret = IORING_CQE_F_BUFFER | (req->buf_index << IORING_CQE_BUFFER_SHIFT);\n\n\tif (req->flags & REQ_F_BUFFER_RING) {\n\t\tif (req->buf_list) {\n\t\t\treq->buf_index = req->buf_list->bgid;\n\t\t\treq->buf_list->head++;\n\t\t}\n\t\treq->flags &= ~REQ_F_BUFFER_RING;\n\t} else {\n\t\treq->buf_index = req->kbuf->bgid;\n\t\tlist_add(&req->kbuf->list, list);\n\t\treq->flags &= ~REQ_F_BUFFER_SELECTED;\n\t}\n\n\treturn ret;\n}\n\nstatic inline unsigned int io_put_kbuf_comp(struct io_kiocb *req)\n{\n\tlockdep_assert_held(&req->ctx->completion_lock);\n\n\tif (!(req->flags & (REQ_F_BUFFER_SELECTED|REQ_F_BUFFER_RING)))\n\t\treturn 0;\n\treturn __io_put_kbuf_list(req, &req->ctx->io_buffers_comp);\n}\n\nstatic inline unsigned int io_put_kbuf(struct io_kiocb *req,\n\t\t\t\t       unsigned issue_flags)\n{\n\n\tif (!(req->flags & (REQ_F_BUFFER_SELECTED|REQ_F_BUFFER_RING)))\n\t\treturn 0;\n\treturn __io_put_kbuf(req, issue_flags);\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}