{
  "module_name": "mm.py",
  "hash_id": "3e415e6c586de8eefc12f630ca06b739307a44433d15ae93167a992a4c520b5b",
  "original_prompt": "Ingested from linux-6.6.14/scripts/gdb/linux/mm.py",
  "human_readable_source": "# SPDX-License-Identifier: GPL-2.0\n#\n# Copyright (c) 2023 MediaTek Inc.\n#\n# Authors:\n#  Kuan-Ying Lee <Kuan-Ying.Lee@mediatek.com>\n#\n\nimport gdb\nimport math\nfrom linux import utils, constants\n\ndef DIV_ROUND_UP(n,d):\n    return ((n) + (d) - 1) // (d)\n\ndef test_bit(nr, addr):\n    if addr.dereference() & (0x1 << nr):\n        return True\n    else:\n        return False\n\nclass page_ops():\n    ops = None\n    def __init__(self):\n        if not constants.LX_CONFIG_SPARSEMEM_VMEMMAP:\n            raise gdb.GdbError('Only support CONFIG_SPARSEMEM_VMEMMAP now')\n        if constants.LX_CONFIG_ARM64 and utils.is_target_arch('aarch64'):\n            self.ops = aarch64_page_ops()\n        else:\n            raise gdb.GdbError('Only support aarch64 now')\n\nclass aarch64_page_ops():\n    def __init__(self):\n        self.SUBSECTION_SHIFT = 21\n        self.SEBSECTION_SIZE = 1 << self.SUBSECTION_SHIFT\n        self.MODULES_VSIZE = 128 * 1024 * 1024\n\n        if constants.LX_CONFIG_ARM64_64K_PAGES:\n            self.SECTION_SIZE_BITS = 29\n        else:\n            self.SECTION_SIZE_BITS = 27\n        self.MAX_PHYSMEM_BITS = constants.LX_CONFIG_ARM64_VA_BITS\n\n        self.PAGE_SHIFT = constants.LX_CONFIG_ARM64_PAGE_SHIFT\n        self.PAGE_SIZE = 1 << self.PAGE_SHIFT\n        self.PAGE_MASK = (~(self.PAGE_SIZE - 1)) & ((1 << 64) - 1)\n\n        self.VA_BITS = constants.LX_CONFIG_ARM64_VA_BITS\n        if self.VA_BITS > 48:\n            self.VA_BITS_MIN = 48\n            self.vabits_actual = gdb.parse_and_eval('vabits_actual')\n        else:\n            self.VA_BITS_MIN = self.VA_BITS\n            self.vabits_actual = self.VA_BITS\n        self.kimage_voffset = gdb.parse_and_eval('kimage_voffset') & ((1 << 64) - 1)\n\n        self.SECTIONS_SHIFT = self.MAX_PHYSMEM_BITS - self.SECTION_SIZE_BITS\n\n        if str(constants.LX_CONFIG_ARCH_FORCE_MAX_ORDER).isdigit():\n            self.MAX_ORDER = constants.LX_CONFIG_ARCH_FORCE_MAX_ORDER\n        else:\n            self.MAX_ORDER = 11\n\n        self.MAX_ORDER_NR_PAGES = 1 << (self.MAX_ORDER - 1)\n        self.PFN_SECTION_SHIFT = self.SECTION_SIZE_BITS - self.PAGE_SHIFT\n        self.NR_MEM_SECTIONS = 1 << self.SECTIONS_SHIFT\n        self.PAGES_PER_SECTION = 1 << self.PFN_SECTION_SHIFT\n        self.PAGE_SECTION_MASK = (~(self.PAGES_PER_SECTION - 1)) & ((1 << 64) - 1)\n\n        if constants.LX_CONFIG_SPARSEMEM_EXTREME:\n            self.SECTIONS_PER_ROOT = self.PAGE_SIZE // gdb.lookup_type(\"struct mem_section\").sizeof\n        else:\n            self.SECTIONS_PER_ROOT = 1\n\n        self.NR_SECTION_ROOTS = DIV_ROUND_UP(self.NR_MEM_SECTIONS, self.SECTIONS_PER_ROOT)\n        self.SECTION_ROOT_MASK = self.SECTIONS_PER_ROOT - 1\n        self.SUBSECTION_SHIFT = 21\n        self.SEBSECTION_SIZE = 1 << self.SUBSECTION_SHIFT\n        self.PFN_SUBSECTION_SHIFT = self.SUBSECTION_SHIFT - self.PAGE_SHIFT\n        self.PAGES_PER_SUBSECTION = 1 << self.PFN_SUBSECTION_SHIFT\n\n        self.SECTION_HAS_MEM_MAP = 1 << int(gdb.parse_and_eval('SECTION_HAS_MEM_MAP_BIT'))\n        self.SECTION_IS_EARLY = 1 << int(gdb.parse_and_eval('SECTION_IS_EARLY_BIT'))\n\n        self.struct_page_size = utils.get_page_type().sizeof\n        self.STRUCT_PAGE_MAX_SHIFT = (int)(math.log(self.struct_page_size, 2))\n\n        self.PAGE_OFFSET = self._PAGE_OFFSET(self.VA_BITS)\n        self.MODULES_VADDR = self._PAGE_END(self.VA_BITS_MIN)\n        self.MODULES_END = self.MODULES_VADDR + self.MODULES_VSIZE\n\n        self.VMEMMAP_SHIFT = (self.PAGE_SHIFT - self.STRUCT_PAGE_MAX_SHIFT)\n        self.VMEMMAP_SIZE = ((self._PAGE_END(self.VA_BITS_MIN) - self.PAGE_OFFSET) >> self.VMEMMAP_SHIFT)\n        self.VMEMMAP_START = (-(1 << (self.VA_BITS - self.VMEMMAP_SHIFT))) & 0xffffffffffffffff\n        self.VMEMMAP_END = self.VMEMMAP_START + self.VMEMMAP_SIZE\n\n        self.VMALLOC_START = self.MODULES_END\n        self.VMALLOC_END = self.VMEMMAP_START - 256 * 1024 * 1024\n\n        self.memstart_addr = gdb.parse_and_eval(\"memstart_addr\")\n        self.PHYS_OFFSET = self.memstart_addr\n        self.vmemmap = gdb.Value(self.VMEMMAP_START).cast(utils.get_page_type().pointer()) - (self.memstart_addr >> self.PAGE_SHIFT)\n\n        self.KERNEL_START = gdb.parse_and_eval(\"_text\")\n        self.KERNEL_END = gdb.parse_and_eval(\"_end\")\n\n        if constants.LX_CONFIG_KASAN_GENERIC or constants.LX_CONFIG_KASAN_SW_TAGS:\n            if constants.LX_CONFIG_KASAN_GENERIC:\n                self.KASAN_SHADOW_SCALE_SHIFT = 3\n            else:\n                self.KASAN_SHADOW_SCALE_SHIFT = 4\n            self.KASAN_SHADOW_OFFSET = constants.LX_CONFIG_KASAN_SHADOW_OFFSET\n            self.KASAN_SHADOW_END = (1 << (64 - self.KASAN_SHADOW_SCALE_SHIFT)) + self.KASAN_SHADOW_OFFSET\n            self.PAGE_END = self.KASAN_SHADOW_END - (1 << (self.vabits_actual - self.KASAN_SHADOW_SCALE_SHIFT))\n        else:\n            self.PAGE_END = self._PAGE_END(self.VA_BITS_MIN)\n\n        if constants.LX_CONFIG_NUMA and constants.LX_CONFIG_NODES_SHIFT:\n            self.NODE_SHIFT = constants.LX_CONFIG_NODES_SHIFT\n        else:\n            self.NODE_SHIFT = 0\n\n        self.MAX_NUMNODES = 1 << self.NODE_SHIFT\n\n    def SECTION_NR_TO_ROOT(self, sec):\n        return sec // self.SECTIONS_PER_ROOT\n\n    def __nr_to_section(self, nr):\n        root = self.SECTION_NR_TO_ROOT(nr)\n        mem_section = gdb.parse_and_eval(\"mem_section\")\n        return mem_section[root][nr & self.SECTION_ROOT_MASK]\n\n    def pfn_to_section_nr(self, pfn):\n        return pfn >> self.PFN_SECTION_SHIFT\n\n    def section_nr_to_pfn(self, sec):\n        return sec << self.PFN_SECTION_SHIFT\n\n    def __pfn_to_section(self, pfn):\n        return self.__nr_to_section(self.pfn_to_section_nr(pfn))\n\n    def pfn_to_section(self, pfn):\n        return self.__pfn_to_section(pfn)\n\n    def subsection_map_index(self, pfn):\n        return (pfn & ~(self.PAGE_SECTION_MASK)) // self.PAGES_PER_SUBSECTION\n\n    def pfn_section_valid(self, ms, pfn):\n        if constants.LX_CONFIG_SPARSEMEM_VMEMMAP:\n            idx = self.subsection_map_index(pfn)\n            return test_bit(idx, ms['usage']['subsection_map'])\n        else:\n            return True\n\n    def valid_section(self, mem_section):\n        if mem_section != None and (mem_section['section_mem_map'] & self.SECTION_HAS_MEM_MAP):\n            return True\n        return False\n\n    def early_section(self, mem_section):\n        if mem_section != None and (mem_section['section_mem_map'] & self.SECTION_IS_EARLY):\n            return True\n        return False\n\n    def pfn_valid(self, pfn):\n        ms = None\n        if self.PHYS_PFN(self.PFN_PHYS(pfn)) != pfn:\n            return False\n        if self.pfn_to_section_nr(pfn) >= self.NR_MEM_SECTIONS:\n            return False\n        ms = self.__pfn_to_section(pfn)\n\n        if not self.valid_section(ms):\n            return False\n        return self.early_section(ms) or self.pfn_section_valid(ms, pfn)\n\n    def _PAGE_OFFSET(self, va):\n        return (-(1 << (va))) & 0xffffffffffffffff\n\n    def _PAGE_END(self, va):\n        return (-(1 << (va - 1))) & 0xffffffffffffffff\n\n    def kasan_reset_tag(self, addr):\n        if constants.LX_CONFIG_KASAN_SW_TAGS or constants.LX_CONFIG_KASAN_HW_TAGS:\n            return int(addr) | (0xff << 56)\n        else:\n            return addr\n\n    def __is_lm_address(self, addr):\n        if (addr - self.PAGE_OFFSET) < (self.PAGE_END - self.PAGE_OFFSET):\n            return True\n        else:\n            return False\n    def __lm_to_phys(self, addr):\n        return addr - self.PAGE_OFFSET + self.PHYS_OFFSET\n\n    def __kimg_to_phys(self, addr):\n        return addr - self.kimage_voffset\n\n    def __virt_to_phys_nodebug(self, va):\n        untagged_va = self.kasan_reset_tag(va)\n        if self.__is_lm_address(untagged_va):\n            return self.__lm_to_phys(untagged_va)\n        else:\n            return self.__kimg_to_phys(untagged_va)\n\n    def __virt_to_phys(self, va):\n        if constants.LX_CONFIG_DEBUG_VIRTUAL:\n            if not self.__is_lm_address(self.kasan_reset_tag(va)):\n                raise gdb.GdbError(\"Warning: virt_to_phys used for non-linear address: 0x%lx\\n\" % va)\n        return self.__virt_to_phys_nodebug(va)\n\n    def virt_to_phys(self, va):\n        return self.__virt_to_phys(va)\n\n    def PFN_PHYS(self, pfn):\n        return pfn << self.PAGE_SHIFT\n\n    def PHYS_PFN(self, phys):\n        return phys >> self.PAGE_SHIFT\n\n    def __phys_to_virt(self, pa):\n        return (pa - self.PHYS_OFFSET) | self.PAGE_OFFSET\n\n    def __phys_to_pfn(self, pa):\n        return self.PHYS_PFN(pa)\n\n    def __pfn_to_phys(self, pfn):\n        return self.PFN_PHYS(pfn)\n\n    def __pa_symbol_nodebug(self, x):\n        return self.__kimg_to_phys(x)\n\n    def __phys_addr_symbol(self, x):\n        if constants.LX_CONFIG_DEBUG_VIRTUAL:\n            if x < self.KERNEL_START or x > self.KERNEL_END:\n                raise gdb.GdbError(\"0x%x exceed kernel range\" % x)\n        return self.__pa_symbol_nodebug(x)\n\n    def __pa_symbol(self, x):\n        return self.__phys_addr_symbol(x)\n\n    def __va(self, pa):\n        return self.__phys_to_virt(pa)\n\n    def pfn_to_kaddr(self, pfn):\n        return self.__va(pfn << self.PAGE_SHIFT)\n\n    def virt_to_pfn(self, va):\n        return self.__phys_to_pfn(self.__virt_to_phys(va))\n\n    def sym_to_pfn(self, x):\n        return self.__phys_to_pfn(self.__pa_symbol(x))\n\n    def page_to_pfn(self, page):\n        return int(page.cast(utils.get_page_type().pointer()) - self.vmemmap.cast(utils.get_page_type().pointer()))\n\n    def page_to_phys(self, page):\n        return self.__pfn_to_phys(self.page_to_pfn(page))\n\n    def pfn_to_page(self, pfn):\n        return (self.vmemmap + pfn).cast(utils.get_page_type().pointer())\n\n    def page_to_virt(self, page):\n        if constants.LX_CONFIG_DEBUG_VIRTUAL:\n            return self.__va(self.page_to_phys(page))\n        else:\n            __idx = int((page.cast(gdb.lookup_type(\"unsigned long\")) - self.VMEMMAP_START).cast(utils.get_ulong_type())) // self.struct_page_size\n            return self.PAGE_OFFSET + (__idx * self.PAGE_SIZE)\n\n    def virt_to_page(self, va):\n        if constants.LX_CONFIG_DEBUG_VIRTUAL:\n            return self.pfn_to_page(self.virt_to_pfn(va))\n        else:\n            __idx = int(self.kasan_reset_tag(va) - self.PAGE_OFFSET) // self.PAGE_SIZE\n            addr = self.VMEMMAP_START + (__idx * self.struct_page_size)\n            return gdb.Value(addr).cast(utils.get_page_type().pointer())\n\n    def page_address(self, page):\n        return self.page_to_virt(page)\n\n    def folio_address(self, folio):\n        return self.page_address(folio['page'].address)\n\nclass LxPFN2Page(gdb.Command):\n    \"\"\"PFN to struct page\"\"\"\n\n    def __init__(self):\n        super(LxPFN2Page, self).__init__(\"lx-pfn_to_page\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        pfn = int(argv[0])\n        page = page_ops().ops.pfn_to_page(pfn)\n        gdb.write(\"pfn_to_page(0x%x) = 0x%x\\n\" % (pfn, page))\n\nLxPFN2Page()\n\nclass LxPage2PFN(gdb.Command):\n    \"\"\"struct page to PFN\"\"\"\n\n    def __init__(self):\n        super(LxPage2PFN, self).__init__(\"lx-page_to_pfn\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        struct_page_addr = int(argv[0], 16)\n        page = gdb.Value(struct_page_addr).cast(utils.get_page_type().pointer())\n        pfn = page_ops().ops.page_to_pfn(page)\n        gdb.write(\"page_to_pfn(0x%x) = 0x%x\\n\" % (page, pfn))\n\nLxPage2PFN()\n\nclass LxPageAddress(gdb.Command):\n    \"\"\"struct page to linear mapping address\"\"\"\n\n    def __init__(self):\n        super(LxPageAddress, self).__init__(\"lx-page_address\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        struct_page_addr = int(argv[0], 16)\n        page = gdb.Value(struct_page_addr).cast(utils.get_page_type().pointer())\n        addr = page_ops().ops.page_address(page)\n        gdb.write(\"page_address(0x%x) = 0x%x\\n\" % (page, addr))\n\nLxPageAddress()\n\nclass LxPage2Phys(gdb.Command):\n    \"\"\"struct page to physical address\"\"\"\n\n    def __init__(self):\n        super(LxPage2Phys, self).__init__(\"lx-page_to_phys\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        struct_page_addr = int(argv[0], 16)\n        page = gdb.Value(struct_page_addr).cast(utils.get_page_type().pointer())\n        phys_addr = page_ops().ops.page_to_phys(page)\n        gdb.write(\"page_to_phys(0x%x) = 0x%x\\n\" % (page, phys_addr))\n\nLxPage2Phys()\n\nclass LxVirt2Phys(gdb.Command):\n    \"\"\"virtual address to physical address\"\"\"\n\n    def __init__(self):\n        super(LxVirt2Phys, self).__init__(\"lx-virt_to_phys\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        linear_addr = int(argv[0], 16)\n        phys_addr = page_ops().ops.virt_to_phys(linear_addr)\n        gdb.write(\"virt_to_phys(0x%x) = 0x%x\\n\" % (linear_addr, phys_addr))\n\nLxVirt2Phys()\n\nclass LxVirt2Page(gdb.Command):\n    \"\"\"virtual address to struct page\"\"\"\n\n    def __init__(self):\n        super(LxVirt2Page, self).__init__(\"lx-virt_to_page\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        linear_addr = int(argv[0], 16)\n        page = page_ops().ops.virt_to_page(linear_addr)\n        gdb.write(\"virt_to_page(0x%x) = 0x%x\\n\" % (linear_addr, page))\n\nLxVirt2Page()\n\nclass LxSym2PFN(gdb.Command):\n    \"\"\"symbol address to PFN\"\"\"\n\n    def __init__(self):\n        super(LxSym2PFN, self).__init__(\"lx-sym_to_pfn\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        sym_addr = int(argv[0], 16)\n        pfn = page_ops().ops.sym_to_pfn(sym_addr)\n        gdb.write(\"sym_to_pfn(0x%x) = %d\\n\" % (sym_addr, pfn))\n\nLxSym2PFN()\n\nclass LxPFN2Kaddr(gdb.Command):\n    \"\"\"PFN to kernel address\"\"\"\n\n    def __init__(self):\n        super(LxPFN2Kaddr, self).__init__(\"lx-pfn_to_kaddr\", gdb.COMMAND_USER)\n\n    def invoke(self, arg, from_tty):\n        argv = gdb.string_to_argv(arg)\n        pfn = int(argv[0])\n        kaddr = page_ops().ops.pfn_to_kaddr(pfn)\n        gdb.write(\"pfn_to_kaddr(%d) = 0x%x\\n\" % (pfn, kaddr))\n\nLxPFN2Kaddr()\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}