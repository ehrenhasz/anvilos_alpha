{
  "module_name": "memcg_slabinfo.py",
  "hash_id": "c5623939f6c312cfebd0ed5a6c62db2030bcef4ec7cd4cb039423a5a7e2c02a3",
  "original_prompt": "Ingested from linux-6.6.14/tools/cgroup/memcg_slabinfo.py",
  "human_readable_source": "#!/usr/bin/env drgn\n#\n# Copyright (C) 2020 Roman Gushchin <guro@fb.com>\n# Copyright (C) 2020 Facebook\n\nfrom os import stat\nimport argparse\nimport sys\n\nfrom drgn.helpers.linux import list_for_each_entry, list_empty\nfrom drgn.helpers.linux import for_each_page\nfrom drgn.helpers.linux.cpumask import for_each_online_cpu\nfrom drgn.helpers.linux.percpu import per_cpu_ptr\nfrom drgn import container_of, FaultError, Object, cast\n\n\nDESC = \"\"\"\nThis is a drgn script to provide slab statistics for memory cgroups.\nIt supports cgroup v2 and v1 and can emulate memory.kmem.slabinfo\ninterface of cgroup v1.\nFor drgn, visit https://github.com/osandov/drgn.\n\"\"\"\n\n\nMEMCGS = {}\n\nOO_SHIFT = 16\nOO_MASK = ((1 << OO_SHIFT) - 1)\n\n\ndef err(s):\n    print('slabinfo.py: error: %s' % s, file=sys.stderr, flush=True)\n    sys.exit(1)\n\n\ndef find_memcg_ids(css=prog['root_mem_cgroup'].css, prefix=''):\n    if not list_empty(css.children.address_of_()):\n        for css in list_for_each_entry('struct cgroup_subsys_state',\n                                       css.children.address_of_(),\n                                       'sibling'):\n            name = prefix + '/' + css.cgroup.kn.name.string_().decode('utf-8')\n            memcg = container_of(css, 'struct mem_cgroup', 'css')\n            MEMCGS[css.cgroup.kn.id.value_()] = memcg\n            find_memcg_ids(css, name)\n\n\ndef is_root_cache(s):\n    try:\n        return False if s.memcg_params.root_cache else True\n    except AttributeError:\n        return True\n\n\ndef cache_name(s):\n    if is_root_cache(s):\n        return s.name.string_().decode('utf-8')\n    else:\n        return s.memcg_params.root_cache.name.string_().decode('utf-8')\n\n\n# SLUB\n\ndef oo_order(s):\n    return s.oo.x >> OO_SHIFT\n\n\ndef oo_objects(s):\n    return s.oo.x & OO_MASK\n\n\ndef count_partial(n, fn):\n    nr_objs = 0\n    for slab in list_for_each_entry('struct slab', n.partial.address_of_(),\n                                    'slab_list'):\n         nr_objs += fn(slab)\n    return nr_objs\n\n\ndef count_free(slab):\n    return slab.objects - slab.inuse\n\n\ndef slub_get_slabinfo(s, cfg):\n    nr_slabs = 0\n    nr_objs = 0\n    nr_free = 0\n\n    for node in range(cfg['nr_nodes']):\n        n = s.node[node]\n        nr_slabs += n.nr_slabs.counter.value_()\n        nr_objs += n.total_objects.counter.value_()\n        nr_free += count_partial(n, count_free)\n\n    return {'active_objs': nr_objs - nr_free,\n            'num_objs': nr_objs,\n            'active_slabs': nr_slabs,\n            'num_slabs': nr_slabs,\n            'objects_per_slab': oo_objects(s),\n            'cache_order': oo_order(s),\n            'limit': 0,\n            'batchcount': 0,\n            'shared': 0,\n            'shared_avail': 0}\n\n\ndef cache_show(s, cfg, objs):\n    if cfg['allocator'] == 'SLUB':\n        sinfo = slub_get_slabinfo(s, cfg)\n    else:\n        err('SLAB isn\\'t supported yet')\n\n    if cfg['shared_slab_pages']:\n        sinfo['active_objs'] = objs\n        sinfo['num_objs'] = objs\n\n    print('%-17s %6lu %6lu %6u %4u %4d'\n          ' : tunables %4u %4u %4u'\n          ' : slabdata %6lu %6lu %6lu' % (\n              cache_name(s), sinfo['active_objs'], sinfo['num_objs'],\n              s.size, sinfo['objects_per_slab'], 1 << sinfo['cache_order'],\n              sinfo['limit'], sinfo['batchcount'], sinfo['shared'],\n              sinfo['active_slabs'], sinfo['num_slabs'],\n              sinfo['shared_avail']))\n\n\ndef detect_kernel_config():\n    cfg = {}\n\n    cfg['nr_nodes'] = prog['nr_online_nodes'].value_()\n\n    if prog.type('struct kmem_cache').members[1].name == 'flags':\n        cfg['allocator'] = 'SLUB'\n    elif prog.type('struct kmem_cache').members[1].name == 'batchcount':\n        cfg['allocator'] = 'SLAB'\n    else:\n        err('Can\\'t determine the slab allocator')\n\n    cfg['shared_slab_pages'] = False\n    try:\n        if prog.type('struct obj_cgroup'):\n            cfg['shared_slab_pages'] = True\n    except:\n        pass\n\n    return cfg\n\n\ndef for_each_slab(prog):\n    PGSlab = 1 << prog.constant('PG_slab')\n    PGHead = 1 << prog.constant('PG_head')\n\n    for page in for_each_page(prog):\n        try:\n            if page.flags.value_() & PGSlab:\n                yield cast('struct slab *', page)\n        except FaultError:\n            pass\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=DESC,\n                                     formatter_class=\n                                     argparse.RawTextHelpFormatter)\n    parser.add_argument('cgroup', metavar='CGROUP',\n                        help='Target memory cgroup')\n    args = parser.parse_args()\n\n    try:\n        cgroup_id = stat(args.cgroup).st_ino\n        find_memcg_ids()\n        memcg = MEMCGS[cgroup_id]\n    except KeyError:\n        err('Can\\'t find the memory cgroup')\n\n    cfg = detect_kernel_config()\n\n    print('# name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab>'\n          ' : tunables <limit> <batchcount> <sharedfactor>'\n          ' : slabdata <active_slabs> <num_slabs> <sharedavail>')\n\n    if cfg['shared_slab_pages']:\n        obj_cgroups = set()\n        stats = {}\n        caches = {}\n\n        # find memcg pointers belonging to the specified cgroup\n        obj_cgroups.add(memcg.objcg.value_())\n        for ptr in list_for_each_entry('struct obj_cgroup',\n                                       memcg.objcg_list.address_of_(),\n                                       'list'):\n            obj_cgroups.add(ptr.value_())\n\n        # look over all slab folios and look for objects belonging\n        # to the given memory cgroup\n        for slab in for_each_slab(prog):\n            objcg_vec_raw = slab.memcg_data.value_()\n            if objcg_vec_raw == 0:\n                continue\n            cache = slab.slab_cache\n            if not cache:\n                continue\n            addr = cache.value_()\n            caches[addr] = cache\n            # clear the lowest bit to get the true obj_cgroups\n            objcg_vec = Object(prog, 'struct obj_cgroup **',\n                               value=objcg_vec_raw & ~1)\n\n            if addr not in stats:\n                stats[addr] = 0\n\n            for i in range(oo_objects(cache)):\n                if objcg_vec[i].value_() in obj_cgroups:\n                    stats[addr] += 1\n\n        for addr in caches:\n            if stats[addr] > 0:\n                cache_show(caches[addr], cfg, stats[addr])\n\n    else:\n        for s in list_for_each_entry('struct kmem_cache',\n                                     memcg.kmem_caches.address_of_(),\n                                     'memcg_params.kmem_caches_node'):\n            cache_show(s, cfg, None)\n\n\nmain()\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}