{
  "module_name": "gen_loader.c",
  "hash_id": "4540946c94a1a9b8803c47bbbd9b76b893208eb872fc6537765c8c32ca4b6bbb",
  "original_prompt": "Ingested from linux-6.6.14/tools/lib/bpf/gen_loader.c",
  "human_readable_source": "\n \n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include <linux/filter.h>\n#include <sys/param.h>\n#include \"btf.h\"\n#include \"bpf.h\"\n#include \"libbpf.h\"\n#include \"libbpf_internal.h\"\n#include \"hashmap.h\"\n#include \"bpf_gen_internal.h\"\n#include \"skel_internal.h\"\n#include <asm/byteorder.h>\n\n#define MAX_USED_MAPS\t64\n#define MAX_USED_PROGS\t32\n#define MAX_KFUNC_DESCS 256\n#define MAX_FD_ARRAY_SZ (MAX_USED_MAPS + MAX_KFUNC_DESCS)\n\n \nstruct loader_stack {\n\t__u32 btf_fd;\n\t__u32 inner_map_fd;\n\t__u32 prog_fd[MAX_USED_PROGS];\n};\n\n#define stack_off(field) \\\n\t(__s16)(-sizeof(struct loader_stack) + offsetof(struct loader_stack, field))\n\n#define attr_field(attr, field) (attr + offsetof(union bpf_attr, field))\n\nstatic int blob_fd_array_off(struct bpf_gen *gen, int index)\n{\n\treturn gen->fd_array + index * sizeof(int);\n}\n\nstatic int realloc_insn_buf(struct bpf_gen *gen, __u32 size)\n{\n\tsize_t off = gen->insn_cur - gen->insn_start;\n\tvoid *insn_start;\n\n\tif (gen->error)\n\t\treturn gen->error;\n\tif (size > INT32_MAX || off + size > INT32_MAX) {\n\t\tgen->error = -ERANGE;\n\t\treturn -ERANGE;\n\t}\n\tinsn_start = realloc(gen->insn_start, off + size);\n\tif (!insn_start) {\n\t\tgen->error = -ENOMEM;\n\t\tfree(gen->insn_start);\n\t\tgen->insn_start = NULL;\n\t\treturn -ENOMEM;\n\t}\n\tgen->insn_start = insn_start;\n\tgen->insn_cur = insn_start + off;\n\treturn 0;\n}\n\nstatic int realloc_data_buf(struct bpf_gen *gen, __u32 size)\n{\n\tsize_t off = gen->data_cur - gen->data_start;\n\tvoid *data_start;\n\n\tif (gen->error)\n\t\treturn gen->error;\n\tif (size > INT32_MAX || off + size > INT32_MAX) {\n\t\tgen->error = -ERANGE;\n\t\treturn -ERANGE;\n\t}\n\tdata_start = realloc(gen->data_start, off + size);\n\tif (!data_start) {\n\t\tgen->error = -ENOMEM;\n\t\tfree(gen->data_start);\n\t\tgen->data_start = NULL;\n\t\treturn -ENOMEM;\n\t}\n\tgen->data_start = data_start;\n\tgen->data_cur = data_start + off;\n\treturn 0;\n}\n\nstatic void emit(struct bpf_gen *gen, struct bpf_insn insn)\n{\n\tif (realloc_insn_buf(gen, sizeof(insn)))\n\t\treturn;\n\tmemcpy(gen->insn_cur, &insn, sizeof(insn));\n\tgen->insn_cur += sizeof(insn);\n}\n\nstatic void emit2(struct bpf_gen *gen, struct bpf_insn insn1, struct bpf_insn insn2)\n{\n\temit(gen, insn1);\n\temit(gen, insn2);\n}\n\nstatic int add_data(struct bpf_gen *gen, const void *data, __u32 size);\nstatic void emit_sys_close_blob(struct bpf_gen *gen, int blob_off);\n\nvoid bpf_gen__init(struct bpf_gen *gen, int log_level, int nr_progs, int nr_maps)\n{\n\tsize_t stack_sz = sizeof(struct loader_stack), nr_progs_sz;\n\tint i;\n\n\tgen->fd_array = add_data(gen, NULL, MAX_FD_ARRAY_SZ * sizeof(int));\n\tgen->log_level = log_level;\n\t \n\temit(gen, BPF_MOV64_REG(BPF_REG_6, BPF_REG_1));\n\n\t \n\temit(gen, BPF_MOV64_REG(BPF_REG_1, BPF_REG_10));\n\temit(gen, BPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -stack_sz));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_2, stack_sz));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_3, 0));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_probe_read_kernel));\n\n\t \n\tnr_progs_sz = offsetof(struct loader_stack, prog_fd[nr_progs]);\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JA, 0, 0,\n\t\t\t       \n\t\t\t      (nr_progs_sz / 4) * 3 + 2 +\n\t\t\t       \n\t\t\t      nr_maps * (6 + (gen->log_level ? 6 : 0))));\n\n\t \n\tgen->cleanup_label = gen->insn_cur - gen->insn_start;\n\t \n\tfor (i = 0; i < nr_progs_sz; i += 4) {\n\t\temit(gen, BPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_10, -stack_sz + i));\n\t\temit(gen, BPF_JMP_IMM(BPF_JSLE, BPF_REG_1, 0, 1));\n\t\temit(gen, BPF_EMIT_CALL(BPF_FUNC_sys_close));\n\t}\n\tfor (i = 0; i < nr_maps; i++)\n\t\temit_sys_close_blob(gen, blob_fd_array_off(gen, i));\n\t \n\temit(gen, BPF_MOV64_REG(BPF_REG_0, BPF_REG_7));\n\temit(gen, BPF_EXIT_INSN());\n}\n\nstatic int add_data(struct bpf_gen *gen, const void *data, __u32 size)\n{\n\t__u32 size8 = roundup(size, 8);\n\t__u64 zero = 0;\n\tvoid *prev;\n\n\tif (realloc_data_buf(gen, size8))\n\t\treturn 0;\n\tprev = gen->data_cur;\n\tif (data) {\n\t\tmemcpy(gen->data_cur, data, size);\n\t\tmemcpy(gen->data_cur + size, &zero, size8 - size);\n\t} else {\n\t\tmemset(gen->data_cur, 0, size8);\n\t}\n\tgen->data_cur += size8;\n\treturn prev - gen->data_start;\n}\n\n \nstatic int add_map_fd(struct bpf_gen *gen)\n{\n\tif (gen->nr_maps == MAX_USED_MAPS) {\n\t\tpr_warn(\"Total maps exceeds %d\\n\", MAX_USED_MAPS);\n\t\tgen->error = -E2BIG;\n\t\treturn 0;\n\t}\n\treturn gen->nr_maps++;\n}\n\nstatic int add_kfunc_btf_fd(struct bpf_gen *gen)\n{\n\tint cur;\n\n\tif (gen->nr_fd_array == MAX_KFUNC_DESCS) {\n\t\tcur = add_data(gen, NULL, sizeof(int));\n\t\treturn (cur - gen->fd_array) / sizeof(int);\n\t}\n\treturn MAX_USED_MAPS + gen->nr_fd_array++;\n}\n\nstatic int insn_bytes_to_bpf_size(__u32 sz)\n{\n\tswitch (sz) {\n\tcase 8: return BPF_DW;\n\tcase 4: return BPF_W;\n\tcase 2: return BPF_H;\n\tcase 1: return BPF_B;\n\tdefault: return -1;\n\t}\n}\n\n \nstatic void emit_rel_store(struct bpf_gen *gen, int off, int data)\n{\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_0, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, data));\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, off));\n\temit(gen, BPF_STX_MEM(BPF_DW, BPF_REG_1, BPF_REG_0, 0));\n}\n\nstatic void move_blob2blob(struct bpf_gen *gen, int off, int size, int blob_off)\n{\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_2, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, blob_off));\n\temit(gen, BPF_LDX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_0, BPF_REG_2, 0));\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, off));\n\temit(gen, BPF_STX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_1, BPF_REG_0, 0));\n}\n\nstatic void move_blob2ctx(struct bpf_gen *gen, int ctx_off, int size, int blob_off)\n{\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, blob_off));\n\temit(gen, BPF_LDX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_0, BPF_REG_1, 0));\n\temit(gen, BPF_STX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_6, BPF_REG_0, ctx_off));\n}\n\nstatic void move_ctx2blob(struct bpf_gen *gen, int off, int size, int ctx_off,\n\t\t\t\t   bool check_non_zero)\n{\n\temit(gen, BPF_LDX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_0, BPF_REG_6, ctx_off));\n\tif (check_non_zero)\n\t\t \n\t\temit(gen, BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 3));\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, off));\n\temit(gen, BPF_STX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_1, BPF_REG_0, 0));\n}\n\nstatic void move_stack2blob(struct bpf_gen *gen, int off, int size, int stack_off)\n{\n\temit(gen, BPF_LDX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_0, BPF_REG_10, stack_off));\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, off));\n\temit(gen, BPF_STX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_1, BPF_REG_0, 0));\n}\n\nstatic void move_stack2ctx(struct bpf_gen *gen, int ctx_off, int size, int stack_off)\n{\n\temit(gen, BPF_LDX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_0, BPF_REG_10, stack_off));\n\temit(gen, BPF_STX_MEM(insn_bytes_to_bpf_size(size), BPF_REG_6, BPF_REG_0, ctx_off));\n}\n\nstatic void emit_sys_bpf(struct bpf_gen *gen, int cmd, int attr, int attr_size)\n{\n\temit(gen, BPF_MOV64_IMM(BPF_REG_1, cmd));\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_2, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, attr));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_3, attr_size));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_sys_bpf));\n\t \n\temit(gen, BPF_MOV64_REG(BPF_REG_7, BPF_REG_0));\n}\n\nstatic bool is_simm16(__s64 value)\n{\n\treturn value == (__s64)(__s16)value;\n}\n\nstatic void emit_check_err(struct bpf_gen *gen)\n{\n\t__s64 off = -(gen->insn_cur - gen->insn_start - gen->cleanup_label) / 8 - 1;\n\n\t \n\tif (is_simm16(off)) {\n\t\temit(gen, BPF_JMP_IMM(BPF_JSLT, BPF_REG_7, 0, off));\n\t} else {\n\t\tgen->error = -ERANGE;\n\t\temit(gen, BPF_JMP_IMM(BPF_JA, 0, 0, -1));\n\t}\n}\n\n \nstatic void emit_debug(struct bpf_gen *gen, int reg1, int reg2,\n\t\t       const char *fmt, va_list args)\n{\n\tchar buf[1024];\n\tint addr, len, ret;\n\n\tif (!gen->log_level)\n\t\treturn;\n\tret = vsnprintf(buf, sizeof(buf), fmt, args);\n\tif (ret < 1024 - 7 && reg1 >= 0 && reg2 < 0)\n\t\t \n\t\tstrcat(buf, \" r=%d\");\n\tlen = strlen(buf) + 1;\n\taddr = add_data(gen, buf, len);\n\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, addr));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_2, len));\n\tif (reg1 >= 0)\n\t\temit(gen, BPF_MOV64_REG(BPF_REG_3, reg1));\n\tif (reg2 >= 0)\n\t\temit(gen, BPF_MOV64_REG(BPF_REG_4, reg2));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_trace_printk));\n}\n\nstatic void debug_regs(struct bpf_gen *gen, int reg1, int reg2, const char *fmt, ...)\n{\n\tva_list args;\n\n\tva_start(args, fmt);\n\temit_debug(gen, reg1, reg2, fmt, args);\n\tva_end(args);\n}\n\nstatic void debug_ret(struct bpf_gen *gen, const char *fmt, ...)\n{\n\tva_list args;\n\n\tva_start(args, fmt);\n\temit_debug(gen, BPF_REG_7, -1, fmt, args);\n\tva_end(args);\n}\n\nstatic void __emit_sys_close(struct bpf_gen *gen)\n{\n\temit(gen, BPF_JMP_IMM(BPF_JSLE, BPF_REG_1, 0,\n\t\t\t       \n\t\t\t      2 + (gen->log_level ? 6 : 0)));\n\temit(gen, BPF_MOV64_REG(BPF_REG_9, BPF_REG_1));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_sys_close));\n\tdebug_regs(gen, BPF_REG_9, BPF_REG_0, \"close(%%d) = %%d\");\n}\n\nstatic void emit_sys_close_stack(struct bpf_gen *gen, int stack_off)\n{\n\temit(gen, BPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_10, stack_off));\n\t__emit_sys_close(gen);\n}\n\nstatic void emit_sys_close_blob(struct bpf_gen *gen, int blob_off)\n{\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_0, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, blob_off));\n\temit(gen, BPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_0, 0));\n\t__emit_sys_close(gen);\n}\n\nint bpf_gen__finish(struct bpf_gen *gen, int nr_progs, int nr_maps)\n{\n\tint i;\n\n\tif (nr_progs < gen->nr_progs || nr_maps != gen->nr_maps) {\n\t\tpr_warn(\"nr_progs %d/%d nr_maps %d/%d mismatch\\n\",\n\t\t\tnr_progs, gen->nr_progs, nr_maps, gen->nr_maps);\n\t\tgen->error = -EFAULT;\n\t\treturn gen->error;\n\t}\n\temit_sys_close_stack(gen, stack_off(btf_fd));\n\tfor (i = 0; i < gen->nr_progs; i++)\n\t\tmove_stack2ctx(gen,\n\t\t\t       sizeof(struct bpf_loader_ctx) +\n\t\t\t       sizeof(struct bpf_map_desc) * gen->nr_maps +\n\t\t\t       sizeof(struct bpf_prog_desc) * i +\n\t\t\t       offsetof(struct bpf_prog_desc, prog_fd), 4,\n\t\t\t       stack_off(prog_fd[i]));\n\tfor (i = 0; i < gen->nr_maps; i++)\n\t\tmove_blob2ctx(gen,\n\t\t\t      sizeof(struct bpf_loader_ctx) +\n\t\t\t      sizeof(struct bpf_map_desc) * i +\n\t\t\t      offsetof(struct bpf_map_desc, map_fd), 4,\n\t\t\t      blob_fd_array_off(gen, i));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_0, 0));\n\temit(gen, BPF_EXIT_INSN());\n\tpr_debug(\"gen: finish %d\\n\", gen->error);\n\tif (!gen->error) {\n\t\tstruct gen_loader_opts *opts = gen->opts;\n\n\t\topts->insns = gen->insn_start;\n\t\topts->insns_sz = gen->insn_cur - gen->insn_start;\n\t\topts->data = gen->data_start;\n\t\topts->data_sz = gen->data_cur - gen->data_start;\n\t}\n\treturn gen->error;\n}\n\nvoid bpf_gen__free(struct bpf_gen *gen)\n{\n\tif (!gen)\n\t\treturn;\n\tfree(gen->data_start);\n\tfree(gen->insn_start);\n\tfree(gen);\n}\n\nvoid bpf_gen__load_btf(struct bpf_gen *gen, const void *btf_raw_data,\n\t\t       __u32 btf_raw_size)\n{\n\tint attr_size = offsetofend(union bpf_attr, btf_log_level);\n\tint btf_data, btf_load_attr;\n\tunion bpf_attr attr;\n\n\tmemset(&attr, 0, attr_size);\n\tpr_debug(\"gen: load_btf: size %d\\n\", btf_raw_size);\n\tbtf_data = add_data(gen, btf_raw_data, btf_raw_size);\n\n\tattr.btf_size = btf_raw_size;\n\tbtf_load_attr = add_data(gen, &attr, attr_size);\n\n\t \n\tmove_ctx2blob(gen, attr_field(btf_load_attr, btf_log_level), 4,\n\t\t      offsetof(struct bpf_loader_ctx, log_level), false);\n\tmove_ctx2blob(gen, attr_field(btf_load_attr, btf_log_size), 4,\n\t\t      offsetof(struct bpf_loader_ctx, log_size), false);\n\tmove_ctx2blob(gen, attr_field(btf_load_attr, btf_log_buf), 8,\n\t\t      offsetof(struct bpf_loader_ctx, log_buf), false);\n\t \n\temit_rel_store(gen, attr_field(btf_load_attr, btf), btf_data);\n\t \n\temit_sys_bpf(gen, BPF_BTF_LOAD, btf_load_attr, attr_size);\n\tdebug_ret(gen, \"btf_load size %d\", btf_raw_size);\n\temit_check_err(gen);\n\t \n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_7, stack_off(btf_fd)));\n}\n\nvoid bpf_gen__map_create(struct bpf_gen *gen,\n\t\t\t enum bpf_map_type map_type,\n\t\t\t const char *map_name,\n\t\t\t __u32 key_size, __u32 value_size, __u32 max_entries,\n\t\t\t struct bpf_map_create_opts *map_attr, int map_idx)\n{\n\tint attr_size = offsetofend(union bpf_attr, map_extra);\n\tbool close_inner_map_fd = false;\n\tint map_create_attr, idx;\n\tunion bpf_attr attr;\n\n\tmemset(&attr, 0, attr_size);\n\tattr.map_type = map_type;\n\tattr.key_size = key_size;\n\tattr.value_size = value_size;\n\tattr.map_flags = map_attr->map_flags;\n\tattr.map_extra = map_attr->map_extra;\n\tif (map_name)\n\t\tlibbpf_strlcpy(attr.map_name, map_name, sizeof(attr.map_name));\n\tattr.numa_node = map_attr->numa_node;\n\tattr.map_ifindex = map_attr->map_ifindex;\n\tattr.max_entries = max_entries;\n\tattr.btf_key_type_id = map_attr->btf_key_type_id;\n\tattr.btf_value_type_id = map_attr->btf_value_type_id;\n\n\tpr_debug(\"gen: map_create: %s idx %d type %d value_type_id %d\\n\",\n\t\t attr.map_name, map_idx, map_type, attr.btf_value_type_id);\n\n\tmap_create_attr = add_data(gen, &attr, attr_size);\n\tif (attr.btf_value_type_id)\n\t\t \n\t\tmove_stack2blob(gen, attr_field(map_create_attr, btf_fd), 4,\n\t\t\t\tstack_off(btf_fd));\n\tswitch (attr.map_type) {\n\tcase BPF_MAP_TYPE_ARRAY_OF_MAPS:\n\tcase BPF_MAP_TYPE_HASH_OF_MAPS:\n\t\tmove_stack2blob(gen, attr_field(map_create_attr, inner_map_fd), 4,\n\t\t\t\tstack_off(inner_map_fd));\n\t\tclose_inner_map_fd = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\t \n\tif (map_idx >= 0)\n\t\tmove_ctx2blob(gen, attr_field(map_create_attr, max_entries), 4,\n\t\t\t      sizeof(struct bpf_loader_ctx) +\n\t\t\t      sizeof(struct bpf_map_desc) * map_idx +\n\t\t\t      offsetof(struct bpf_map_desc, max_entries),\n\t\t\t      true  );\n\t \n\temit_sys_bpf(gen, BPF_MAP_CREATE, map_create_attr, attr_size);\n\tdebug_ret(gen, \"map_create %s idx %d type %d value_size %d value_btf_id %d\",\n\t\t  attr.map_name, map_idx, map_type, value_size,\n\t\t  attr.btf_value_type_id);\n\temit_check_err(gen);\n\t \n\tif (map_idx < 0) {\n\t\t \n\t\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_7,\n\t\t\t\t      stack_off(inner_map_fd)));\n\t} else if (map_idx != gen->nr_maps) {\n\t\tgen->error = -EDOM;  \n\t\treturn;\n\t} else {\n\t\t \n\t\tidx = add_map_fd(gen);\n\t\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t\t 0, 0, 0, blob_fd_array_off(gen, idx)));\n\t\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_1, BPF_REG_7, 0));\n\t}\n\tif (close_inner_map_fd)\n\t\temit_sys_close_stack(gen, stack_off(inner_map_fd));\n}\n\nvoid bpf_gen__record_attach_target(struct bpf_gen *gen, const char *attach_name,\n\t\t\t\t   enum bpf_attach_type type)\n{\n\tconst char *prefix;\n\tint kind, ret;\n\n\tbtf_get_kernel_prefix_kind(type, &prefix, &kind);\n\tgen->attach_kind = kind;\n\tret = snprintf(gen->attach_target, sizeof(gen->attach_target), \"%s%s\",\n\t\t       prefix, attach_name);\n\tif (ret >= sizeof(gen->attach_target))\n\t\tgen->error = -ENOSPC;\n}\n\nstatic void emit_find_attach_target(struct bpf_gen *gen)\n{\n\tint name, len = strlen(gen->attach_target) + 1;\n\n\tpr_debug(\"gen: find_attach_tgt %s %d\\n\", gen->attach_target, gen->attach_kind);\n\tname = add_data(gen, gen->attach_target, len);\n\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, name));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_2, len));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_3, gen->attach_kind));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_4, 0));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_btf_find_by_name_kind));\n\temit(gen, BPF_MOV64_REG(BPF_REG_7, BPF_REG_0));\n\tdebug_ret(gen, \"find_by_name_kind(%s,%d)\",\n\t\t  gen->attach_target, gen->attach_kind);\n\temit_check_err(gen);\n\t \n}\n\nvoid bpf_gen__record_extern(struct bpf_gen *gen, const char *name, bool is_weak,\n\t\t\t    bool is_typeless, bool is_ld64, int kind, int insn_idx)\n{\n\tstruct ksym_relo_desc *relo;\n\n\trelo = libbpf_reallocarray(gen->relos, gen->relo_cnt + 1, sizeof(*relo));\n\tif (!relo) {\n\t\tgen->error = -ENOMEM;\n\t\treturn;\n\t}\n\tgen->relos = relo;\n\trelo += gen->relo_cnt;\n\trelo->name = name;\n\trelo->is_weak = is_weak;\n\trelo->is_typeless = is_typeless;\n\trelo->is_ld64 = is_ld64;\n\trelo->kind = kind;\n\trelo->insn_idx = insn_idx;\n\tgen->relo_cnt++;\n}\n\n \nstatic struct ksym_desc *get_ksym_desc(struct bpf_gen *gen, struct ksym_relo_desc *relo)\n{\n\tstruct ksym_desc *kdesc;\n\tint i;\n\n\tfor (i = 0; i < gen->nr_ksyms; i++) {\n\t\tkdesc = &gen->ksyms[i];\n\t\tif (kdesc->kind == relo->kind && kdesc->is_ld64 == relo->is_ld64 &&\n\t\t    !strcmp(kdesc->name, relo->name)) {\n\t\t\tkdesc->ref++;\n\t\t\treturn kdesc;\n\t\t}\n\t}\n\tkdesc = libbpf_reallocarray(gen->ksyms, gen->nr_ksyms + 1, sizeof(*kdesc));\n\tif (!kdesc) {\n\t\tgen->error = -ENOMEM;\n\t\treturn NULL;\n\t}\n\tgen->ksyms = kdesc;\n\tkdesc = &gen->ksyms[gen->nr_ksyms++];\n\tkdesc->name = relo->name;\n\tkdesc->kind = relo->kind;\n\tkdesc->ref = 1;\n\tkdesc->off = 0;\n\tkdesc->insn = 0;\n\tkdesc->is_ld64 = relo->is_ld64;\n\treturn kdesc;\n}\n\n \nstatic void emit_bpf_find_by_name_kind(struct bpf_gen *gen, struct ksym_relo_desc *relo)\n{\n\tint name_off, len = strlen(relo->name) + 1;\n\n\tname_off = add_data(gen, relo->name, len);\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, name_off));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_2, len));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_3, relo->kind));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_4, 0));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_btf_find_by_name_kind));\n\temit(gen, BPF_MOV64_REG(BPF_REG_7, BPF_REG_0));\n\tdebug_ret(gen, \"find_by_name_kind(%s,%d)\", relo->name, relo->kind);\n}\n\n \nstatic void emit_bpf_kallsyms_lookup_name(struct bpf_gen *gen, struct ksym_relo_desc *relo)\n{\n\tint name_off, len = strlen(relo->name) + 1, res_off;\n\n\tname_off = add_data(gen, relo->name, len);\n\tres_off = add_data(gen, NULL, 8);  \n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, name_off));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_2, len));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_3, 0));\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_4, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, res_off));\n\temit(gen, BPF_MOV64_REG(BPF_REG_7, BPF_REG_4));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_kallsyms_lookup_name));\n\temit(gen, BPF_LDX_MEM(BPF_DW, BPF_REG_9, BPF_REG_7, 0));\n\temit(gen, BPF_MOV64_REG(BPF_REG_7, BPF_REG_0));\n\tdebug_ret(gen, \"kallsyms_lookup_name(%s,%d)\", relo->name, relo->kind);\n}\n\n \nstatic void emit_relo_kfunc_btf(struct bpf_gen *gen, struct ksym_relo_desc *relo, int insn)\n{\n\tstruct ksym_desc *kdesc;\n\tint btf_fd_idx;\n\n\tkdesc = get_ksym_desc(gen, relo);\n\tif (!kdesc)\n\t\treturn;\n\t \n\tif (kdesc->ref > 1) {\n\t\tmove_blob2blob(gen, insn + offsetof(struct bpf_insn, imm), 4,\n\t\t\t       kdesc->insn + offsetof(struct bpf_insn, imm));\n\t\tmove_blob2blob(gen, insn + offsetof(struct bpf_insn, off), 2,\n\t\t\t       kdesc->insn + offsetof(struct bpf_insn, off));\n\t\tgoto log;\n\t}\n\t \n\tkdesc->insn = insn;\n\temit_bpf_find_by_name_kind(gen, relo);\n\tif (!relo->is_weak)\n\t\temit_check_err(gen);\n\t \n\tbtf_fd_idx = add_kfunc_btf_fd(gen);\n\tif (btf_fd_idx > INT16_MAX) {\n\t\tpr_warn(\"BTF fd off %d for kfunc %s exceeds INT16_MAX, cannot process relocation\\n\",\n\t\t\tbtf_fd_idx, relo->name);\n\t\tgen->error = -E2BIG;\n\t\treturn;\n\t}\n\tkdesc->off = btf_fd_idx;\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JSGE, BPF_REG_7, 0, 3));\n\t \n\temit(gen, BPF_ST_MEM(BPF_W, BPF_REG_8, offsetof(struct bpf_insn, imm), 0));\n\temit(gen, BPF_ST_MEM(BPF_H, BPF_REG_8, offsetof(struct bpf_insn, off), 0));\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JA, 0, 0, 10));\n\t \n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_8, BPF_REG_7, offsetof(struct bpf_insn, imm)));\n\t \n\temit(gen, BPF_MOV64_REG(BPF_REG_9, BPF_REG_7));\n\temit(gen, BPF_ALU64_IMM(BPF_RSH, BPF_REG_9, 32));\n\t \n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_0, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, blob_fd_array_off(gen, btf_fd_idx)));\n\t \n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_0, BPF_REG_9, 0));\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JNE, BPF_REG_9, 0, 2));\n\t \n\temit(gen, BPF_ST_MEM(BPF_H, BPF_REG_8, offsetof(struct bpf_insn, off), 0));\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JA, 0, 0, 1));\n\t \n\temit(gen, BPF_ST_MEM(BPF_H, BPF_REG_8, offsetof(struct bpf_insn, off), btf_fd_idx));\nlog:\n\tif (!gen->log_level)\n\t\treturn;\n\temit(gen, BPF_LDX_MEM(BPF_W, BPF_REG_7, BPF_REG_8,\n\t\t\t      offsetof(struct bpf_insn, imm)));\n\temit(gen, BPF_LDX_MEM(BPF_H, BPF_REG_9, BPF_REG_8,\n\t\t\t      offsetof(struct bpf_insn, off)));\n\tdebug_regs(gen, BPF_REG_7, BPF_REG_9, \" func (%s:count=%d): imm: %%d, off: %%d\",\n\t\t   relo->name, kdesc->ref);\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_0, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, blob_fd_array_off(gen, kdesc->off)));\n\temit(gen, BPF_LDX_MEM(BPF_W, BPF_REG_9, BPF_REG_0, 0));\n\tdebug_regs(gen, BPF_REG_9, -1, \" func (%s:count=%d): btf_fd\",\n\t\t   relo->name, kdesc->ref);\n}\n\nstatic void emit_ksym_relo_log(struct bpf_gen *gen, struct ksym_relo_desc *relo,\n\t\t\t       int ref)\n{\n\tif (!gen->log_level)\n\t\treturn;\n\temit(gen, BPF_LDX_MEM(BPF_W, BPF_REG_7, BPF_REG_8,\n\t\t\t      offsetof(struct bpf_insn, imm)));\n\temit(gen, BPF_LDX_MEM(BPF_H, BPF_REG_9, BPF_REG_8, sizeof(struct bpf_insn) +\n\t\t\t      offsetof(struct bpf_insn, imm)));\n\tdebug_regs(gen, BPF_REG_7, BPF_REG_9, \" var t=%d w=%d (%s:count=%d): imm[0]: %%d, imm[1]: %%d\",\n\t\t   relo->is_typeless, relo->is_weak, relo->name, ref);\n\temit(gen, BPF_LDX_MEM(BPF_B, BPF_REG_9, BPF_REG_8, offsetofend(struct bpf_insn, code)));\n\tdebug_regs(gen, BPF_REG_9, -1, \" var t=%d w=%d (%s:count=%d): insn.reg\",\n\t\t   relo->is_typeless, relo->is_weak, relo->name, ref);\n}\n\n \nstatic void emit_relo_ksym_typeless(struct bpf_gen *gen,\n\t\t\t\t    struct ksym_relo_desc *relo, int insn)\n{\n\tstruct ksym_desc *kdesc;\n\n\tkdesc = get_ksym_desc(gen, relo);\n\tif (!kdesc)\n\t\treturn;\n\t \n\tif (kdesc->ref > 1) {\n\t\tmove_blob2blob(gen, insn + offsetof(struct bpf_insn, imm), 4,\n\t\t\t       kdesc->insn + offsetof(struct bpf_insn, imm));\n\t\tmove_blob2blob(gen, insn + sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm), 4,\n\t\t\t       kdesc->insn + sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm));\n\t\tgoto log;\n\t}\n\t \n\tkdesc->insn = insn;\n\t \n\tkdesc->typeless = true;\n\temit_bpf_kallsyms_lookup_name(gen, relo);\n\temit(gen, BPF_JMP_IMM(BPF_JEQ, BPF_REG_7, -ENOENT, 1));\n\temit_check_err(gen);\n\t \n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_8, BPF_REG_9, offsetof(struct bpf_insn, imm)));\n\t \n\temit(gen, BPF_ALU64_IMM(BPF_RSH, BPF_REG_9, 32));\n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_8, BPF_REG_9,\n\t\t      sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm)));\nlog:\n\temit_ksym_relo_log(gen, relo, kdesc->ref);\n}\n\nstatic __u32 src_reg_mask(void)\n{\n#if defined(__LITTLE_ENDIAN_BITFIELD)\n\treturn 0x0f;  \n#elif defined(__BIG_ENDIAN_BITFIELD)\n\treturn 0xf0;  \n#else\n#error \"Unsupported bit endianness, cannot proceed\"\n#endif\n}\n\n \nstatic void emit_relo_ksym_btf(struct bpf_gen *gen, struct ksym_relo_desc *relo, int insn)\n{\n\tstruct ksym_desc *kdesc;\n\t__u32 reg_mask;\n\n\tkdesc = get_ksym_desc(gen, relo);\n\tif (!kdesc)\n\t\treturn;\n\t \n\tif (kdesc->ref > 1) {\n\t\tmove_blob2blob(gen, insn + sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm), 4,\n\t\t\t       kdesc->insn + sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm));\n\t\tmove_blob2blob(gen, insn + offsetof(struct bpf_insn, imm), 4,\n\t\t\t       kdesc->insn + offsetof(struct bpf_insn, imm));\n\t\t \n\t\temit(gen, BPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 3));\n\t\tgoto clear_src_reg;\n\t}\n\t \n\tkdesc->insn = insn;\n\temit_bpf_find_by_name_kind(gen, relo);\n\tif (!relo->is_weak)\n\t\temit_check_err(gen);\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JSGE, BPF_REG_7, 0, 3));\n\t \n\temit(gen, BPF_ST_MEM(BPF_W, BPF_REG_8, offsetof(struct bpf_insn, imm), 0));\n\temit(gen, BPF_ST_MEM(BPF_W, BPF_REG_8, sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm), 0));\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JA, 0, 0, 4));\n\t \n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_8, BPF_REG_7, offsetof(struct bpf_insn, imm)));\n\t \n\temit(gen, BPF_ALU64_IMM(BPF_RSH, BPF_REG_7, 32));\n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_8, BPF_REG_7,\n\t\t\t      sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm)));\n\t \n\temit(gen, BPF_JMP_IMM(BPF_JA, 0, 0, 3));\nclear_src_reg:\n\t \n\treg_mask = src_reg_mask();\n\temit(gen, BPF_LDX_MEM(BPF_B, BPF_REG_9, BPF_REG_8, offsetofend(struct bpf_insn, code)));\n\temit(gen, BPF_ALU32_IMM(BPF_AND, BPF_REG_9, reg_mask));\n\temit(gen, BPF_STX_MEM(BPF_B, BPF_REG_8, BPF_REG_9, offsetofend(struct bpf_insn, code)));\n\n\temit_ksym_relo_log(gen, relo, kdesc->ref);\n}\n\nvoid bpf_gen__record_relo_core(struct bpf_gen *gen,\n\t\t\t       const struct bpf_core_relo *core_relo)\n{\n\tstruct bpf_core_relo *relos;\n\n\trelos = libbpf_reallocarray(gen->core_relos, gen->core_relo_cnt + 1, sizeof(*relos));\n\tif (!relos) {\n\t\tgen->error = -ENOMEM;\n\t\treturn;\n\t}\n\tgen->core_relos = relos;\n\trelos += gen->core_relo_cnt;\n\tmemcpy(relos, core_relo, sizeof(*relos));\n\tgen->core_relo_cnt++;\n}\n\nstatic void emit_relo(struct bpf_gen *gen, struct ksym_relo_desc *relo, int insns)\n{\n\tint insn;\n\n\tpr_debug(\"gen: emit_relo (%d): %s at %d %s\\n\",\n\t\t relo->kind, relo->name, relo->insn_idx, relo->is_ld64 ? \"ld64\" : \"call\");\n\tinsn = insns + sizeof(struct bpf_insn) * relo->insn_idx;\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_8, BPF_PSEUDO_MAP_IDX_VALUE, 0, 0, 0, insn));\n\tif (relo->is_ld64) {\n\t\tif (relo->is_typeless)\n\t\t\temit_relo_ksym_typeless(gen, relo, insn);\n\t\telse\n\t\t\temit_relo_ksym_btf(gen, relo, insn);\n\t} else {\n\t\temit_relo_kfunc_btf(gen, relo, insn);\n\t}\n}\n\nstatic void emit_relos(struct bpf_gen *gen, int insns)\n{\n\tint i;\n\n\tfor (i = 0; i < gen->relo_cnt; i++)\n\t\temit_relo(gen, gen->relos + i, insns);\n}\n\nstatic void cleanup_core_relo(struct bpf_gen *gen)\n{\n\tif (!gen->core_relo_cnt)\n\t\treturn;\n\tfree(gen->core_relos);\n\tgen->core_relo_cnt = 0;\n\tgen->core_relos = NULL;\n}\n\nstatic void cleanup_relos(struct bpf_gen *gen, int insns)\n{\n\tstruct ksym_desc *kdesc;\n\tint i, insn;\n\n\tfor (i = 0; i < gen->nr_ksyms; i++) {\n\t\tkdesc = &gen->ksyms[i];\n\t\t \n\t\tif (kdesc->is_ld64 && !kdesc->typeless) {\n\t\t\t \n\t\t\tinsn = kdesc->insn;\n\t\t\tinsn += sizeof(struct bpf_insn) + offsetof(struct bpf_insn, imm);\n\t\t\temit_sys_close_blob(gen, insn);\n\t\t} else if (!kdesc->is_ld64) {\n\t\t\temit_sys_close_blob(gen, blob_fd_array_off(gen, kdesc->off));\n\t\t\tif (kdesc->off < MAX_FD_ARRAY_SZ)\n\t\t\t\tgen->nr_fd_array--;\n\t\t}\n\t}\n\tif (gen->nr_ksyms) {\n\t\tfree(gen->ksyms);\n\t\tgen->nr_ksyms = 0;\n\t\tgen->ksyms = NULL;\n\t}\n\tif (gen->relo_cnt) {\n\t\tfree(gen->relos);\n\t\tgen->relo_cnt = 0;\n\t\tgen->relos = NULL;\n\t}\n\tcleanup_core_relo(gen);\n}\n\nvoid bpf_gen__prog_load(struct bpf_gen *gen,\n\t\t\tenum bpf_prog_type prog_type, const char *prog_name,\n\t\t\tconst char *license, struct bpf_insn *insns, size_t insn_cnt,\n\t\t\tstruct bpf_prog_load_opts *load_attr, int prog_idx)\n{\n\tint prog_load_attr, license_off, insns_off, func_info, line_info, core_relos;\n\tint attr_size = offsetofend(union bpf_attr, core_relo_rec_size);\n\tunion bpf_attr attr;\n\n\tmemset(&attr, 0, attr_size);\n\tpr_debug(\"gen: prog_load: type %d insns_cnt %zd progi_idx %d\\n\",\n\t\t prog_type, insn_cnt, prog_idx);\n\t \n\tlicense_off = add_data(gen, license, strlen(license) + 1);\n\t \n\tinsns_off = add_data(gen, insns, insn_cnt * sizeof(struct bpf_insn));\n\n\tattr.prog_type = prog_type;\n\tattr.expected_attach_type = load_attr->expected_attach_type;\n\tattr.attach_btf_id = load_attr->attach_btf_id;\n\tattr.prog_ifindex = load_attr->prog_ifindex;\n\tattr.kern_version = 0;\n\tattr.insn_cnt = (__u32)insn_cnt;\n\tattr.prog_flags = load_attr->prog_flags;\n\n\tattr.func_info_rec_size = load_attr->func_info_rec_size;\n\tattr.func_info_cnt = load_attr->func_info_cnt;\n\tfunc_info = add_data(gen, load_attr->func_info,\n\t\t\t     attr.func_info_cnt * attr.func_info_rec_size);\n\n\tattr.line_info_rec_size = load_attr->line_info_rec_size;\n\tattr.line_info_cnt = load_attr->line_info_cnt;\n\tline_info = add_data(gen, load_attr->line_info,\n\t\t\t     attr.line_info_cnt * attr.line_info_rec_size);\n\n\tattr.core_relo_rec_size = sizeof(struct bpf_core_relo);\n\tattr.core_relo_cnt = gen->core_relo_cnt;\n\tcore_relos = add_data(gen, gen->core_relos,\n\t\t\t     attr.core_relo_cnt * attr.core_relo_rec_size);\n\n\tlibbpf_strlcpy(attr.prog_name, prog_name, sizeof(attr.prog_name));\n\tprog_load_attr = add_data(gen, &attr, attr_size);\n\n\t \n\temit_rel_store(gen, attr_field(prog_load_attr, license), license_off);\n\n\t \n\temit_rel_store(gen, attr_field(prog_load_attr, insns), insns_off);\n\n\t \n\temit_rel_store(gen, attr_field(prog_load_attr, func_info), func_info);\n\n\t \n\temit_rel_store(gen, attr_field(prog_load_attr, line_info), line_info);\n\n\t \n\temit_rel_store(gen, attr_field(prog_load_attr, core_relos), core_relos);\n\n\t \n\temit_rel_store(gen, attr_field(prog_load_attr, fd_array), gen->fd_array);\n\n\t \n\tmove_ctx2blob(gen, attr_field(prog_load_attr, log_level), 4,\n\t\t      offsetof(struct bpf_loader_ctx, log_level), false);\n\tmove_ctx2blob(gen, attr_field(prog_load_attr, log_size), 4,\n\t\t      offsetof(struct bpf_loader_ctx, log_size), false);\n\tmove_ctx2blob(gen, attr_field(prog_load_attr, log_buf), 8,\n\t\t      offsetof(struct bpf_loader_ctx, log_buf), false);\n\t \n\tmove_stack2blob(gen, attr_field(prog_load_attr, prog_btf_fd), 4,\n\t\t\tstack_off(btf_fd));\n\tif (gen->attach_kind) {\n\t\temit_find_attach_target(gen);\n\t\t \n\t\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_0, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t\t 0, 0, 0, prog_load_attr));\n\t\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_0, BPF_REG_7,\n\t\t\t\t      offsetof(union bpf_attr, attach_btf_id)));\n\t\temit(gen, BPF_ALU64_IMM(BPF_RSH, BPF_REG_7, 32));\n\t\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_0, BPF_REG_7,\n\t\t\t\t      offsetof(union bpf_attr, attach_btf_obj_fd)));\n\t}\n\temit_relos(gen, insns_off);\n\t \n\temit_sys_bpf(gen, BPF_PROG_LOAD, prog_load_attr, attr_size);\n\tdebug_ret(gen, \"prog_load %s insn_cnt %d\", attr.prog_name, attr.insn_cnt);\n\t \n\tcleanup_relos(gen, insns_off);\n\tif (gen->attach_kind) {\n\t\temit_sys_close_blob(gen,\n\t\t\t\t    attr_field(prog_load_attr, attach_btf_obj_fd));\n\t\tgen->attach_kind = 0;\n\t}\n\temit_check_err(gen);\n\t \n\temit(gen, BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_7,\n\t\t\t      stack_off(prog_fd[gen->nr_progs])));\n\tgen->nr_progs++;\n}\n\nvoid bpf_gen__map_update_elem(struct bpf_gen *gen, int map_idx, void *pvalue,\n\t\t\t      __u32 value_size)\n{\n\tint attr_size = offsetofend(union bpf_attr, flags);\n\tint map_update_attr, value, key;\n\tunion bpf_attr attr;\n\tint zero = 0;\n\n\tmemset(&attr, 0, attr_size);\n\tpr_debug(\"gen: map_update_elem: idx %d\\n\", map_idx);\n\n\tvalue = add_data(gen, pvalue, value_size);\n\tkey = add_data(gen, &zero, sizeof(zero));\n\n\t \n\temit(gen, BPF_LDX_MEM(BPF_DW, BPF_REG_3, BPF_REG_6,\n\t\t\t      sizeof(struct bpf_loader_ctx) +\n\t\t\t      sizeof(struct bpf_map_desc) * map_idx +\n\t\t\t      offsetof(struct bpf_map_desc, initial_value)));\n\temit(gen, BPF_JMP_IMM(BPF_JEQ, BPF_REG_3, 0, 8));\n\temit2(gen, BPF_LD_IMM64_RAW_FULL(BPF_REG_1, BPF_PSEUDO_MAP_IDX_VALUE,\n\t\t\t\t\t 0, 0, 0, value));\n\temit(gen, BPF_MOV64_IMM(BPF_REG_2, value_size));\n\temit(gen, BPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_6,\n\t\t\t      offsetof(struct bpf_loader_ctx, flags)));\n\temit(gen, BPF_JMP_IMM(BPF_JSET, BPF_REG_0, BPF_SKEL_KERNEL, 2));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_copy_from_user));\n\temit(gen, BPF_JMP_IMM(BPF_JA, 0, 0, 1));\n\temit(gen, BPF_EMIT_CALL(BPF_FUNC_probe_read_kernel));\n\n\tmap_update_attr = add_data(gen, &attr, attr_size);\n\tmove_blob2blob(gen, attr_field(map_update_attr, map_fd), 4,\n\t\t       blob_fd_array_off(gen, map_idx));\n\temit_rel_store(gen, attr_field(map_update_attr, key), key);\n\temit_rel_store(gen, attr_field(map_update_attr, value), value);\n\t \n\temit_sys_bpf(gen, BPF_MAP_UPDATE_ELEM, map_update_attr, attr_size);\n\tdebug_ret(gen, \"update_elem idx %d value_size %d\", map_idx, value_size);\n\temit_check_err(gen);\n}\n\nvoid bpf_gen__populate_outer_map(struct bpf_gen *gen, int outer_map_idx, int slot,\n\t\t\t\t int inner_map_idx)\n{\n\tint attr_size = offsetofend(union bpf_attr, flags);\n\tint map_update_attr, key;\n\tunion bpf_attr attr;\n\n\tmemset(&attr, 0, attr_size);\n\tpr_debug(\"gen: populate_outer_map: outer %d key %d inner %d\\n\",\n\t\t outer_map_idx, slot, inner_map_idx);\n\n\tkey = add_data(gen, &slot, sizeof(slot));\n\n\tmap_update_attr = add_data(gen, &attr, attr_size);\n\tmove_blob2blob(gen, attr_field(map_update_attr, map_fd), 4,\n\t\t       blob_fd_array_off(gen, outer_map_idx));\n\temit_rel_store(gen, attr_field(map_update_attr, key), key);\n\temit_rel_store(gen, attr_field(map_update_attr, value),\n\t\t       blob_fd_array_off(gen, inner_map_idx));\n\n\t \n\temit_sys_bpf(gen, BPF_MAP_UPDATE_ELEM, map_update_attr, attr_size);\n\tdebug_ret(gen, \"populate_outer_map outer %d key %d inner %d\",\n\t\t  outer_map_idx, slot, inner_map_idx);\n\temit_check_err(gen);\n}\n\nvoid bpf_gen__map_freeze(struct bpf_gen *gen, int map_idx)\n{\n\tint attr_size = offsetofend(union bpf_attr, map_fd);\n\tint map_freeze_attr;\n\tunion bpf_attr attr;\n\n\tmemset(&attr, 0, attr_size);\n\tpr_debug(\"gen: map_freeze: idx %d\\n\", map_idx);\n\tmap_freeze_attr = add_data(gen, &attr, attr_size);\n\tmove_blob2blob(gen, attr_field(map_freeze_attr, map_fd), 4,\n\t\t       blob_fd_array_off(gen, map_idx));\n\t \n\temit_sys_bpf(gen, BPF_MAP_FREEZE, map_freeze_attr, attr_size);\n\tdebug_ret(gen, \"map_freeze\");\n\temit_check_err(gen);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}