{
  "module_name": "libbpf.c",
  "hash_id": "9b63bc7419ca5b2daf507709b350f543540bc59e0277a43243b2fe1eda9e2e4b",
  "original_prompt": "Ingested from linux-6.6.14/tools/lib/bpf/libbpf.c",
  "human_readable_source": "\n\n \n\n#ifndef _GNU_SOURCE\n#define _GNU_SOURCE\n#endif\n#include <stdlib.h>\n#include <stdio.h>\n#include <stdarg.h>\n#include <libgen.h>\n#include <inttypes.h>\n#include <limits.h>\n#include <string.h>\n#include <unistd.h>\n#include <endian.h>\n#include <fcntl.h>\n#include <errno.h>\n#include <ctype.h>\n#include <asm/unistd.h>\n#include <linux/err.h>\n#include <linux/kernel.h>\n#include <linux/bpf.h>\n#include <linux/btf.h>\n#include <linux/filter.h>\n#include <linux/limits.h>\n#include <linux/perf_event.h>\n#include <linux/ring_buffer.h>\n#include <sys/epoll.h>\n#include <sys/ioctl.h>\n#include <sys/mman.h>\n#include <sys/stat.h>\n#include <sys/types.h>\n#include <sys/vfs.h>\n#include <sys/utsname.h>\n#include <sys/resource.h>\n#include <libelf.h>\n#include <gelf.h>\n#include <zlib.h>\n\n#include \"libbpf.h\"\n#include \"bpf.h\"\n#include \"btf.h\"\n#include \"str_error.h\"\n#include \"libbpf_internal.h\"\n#include \"hashmap.h\"\n#include \"bpf_gen_internal.h\"\n#include \"zip.h\"\n\n#ifndef BPF_FS_MAGIC\n#define BPF_FS_MAGIC\t\t0xcafe4a11\n#endif\n\n#define BPF_INSN_SZ (sizeof(struct bpf_insn))\n\n \n#pragma GCC diagnostic ignored \"-Wformat-nonliteral\"\n\n#define __printf(a, b)\t__attribute__((format(printf, a, b)))\n\nstatic struct bpf_map *bpf_object__add_map(struct bpf_object *obj);\nstatic bool prog_is_subprog(const struct bpf_object *obj, const struct bpf_program *prog);\n\nstatic const char * const attach_type_name[] = {\n\t[BPF_CGROUP_INET_INGRESS]\t= \"cgroup_inet_ingress\",\n\t[BPF_CGROUP_INET_EGRESS]\t= \"cgroup_inet_egress\",\n\t[BPF_CGROUP_INET_SOCK_CREATE]\t= \"cgroup_inet_sock_create\",\n\t[BPF_CGROUP_INET_SOCK_RELEASE]\t= \"cgroup_inet_sock_release\",\n\t[BPF_CGROUP_SOCK_OPS]\t\t= \"cgroup_sock_ops\",\n\t[BPF_CGROUP_DEVICE]\t\t= \"cgroup_device\",\n\t[BPF_CGROUP_INET4_BIND]\t\t= \"cgroup_inet4_bind\",\n\t[BPF_CGROUP_INET6_BIND]\t\t= \"cgroup_inet6_bind\",\n\t[BPF_CGROUP_INET4_CONNECT]\t= \"cgroup_inet4_connect\",\n\t[BPF_CGROUP_INET6_CONNECT]\t= \"cgroup_inet6_connect\",\n\t[BPF_CGROUP_INET4_POST_BIND]\t= \"cgroup_inet4_post_bind\",\n\t[BPF_CGROUP_INET6_POST_BIND]\t= \"cgroup_inet6_post_bind\",\n\t[BPF_CGROUP_INET4_GETPEERNAME]\t= \"cgroup_inet4_getpeername\",\n\t[BPF_CGROUP_INET6_GETPEERNAME]\t= \"cgroup_inet6_getpeername\",\n\t[BPF_CGROUP_INET4_GETSOCKNAME]\t= \"cgroup_inet4_getsockname\",\n\t[BPF_CGROUP_INET6_GETSOCKNAME]\t= \"cgroup_inet6_getsockname\",\n\t[BPF_CGROUP_UDP4_SENDMSG]\t= \"cgroup_udp4_sendmsg\",\n\t[BPF_CGROUP_UDP6_SENDMSG]\t= \"cgroup_udp6_sendmsg\",\n\t[BPF_CGROUP_SYSCTL]\t\t= \"cgroup_sysctl\",\n\t[BPF_CGROUP_UDP4_RECVMSG]\t= \"cgroup_udp4_recvmsg\",\n\t[BPF_CGROUP_UDP6_RECVMSG]\t= \"cgroup_udp6_recvmsg\",\n\t[BPF_CGROUP_GETSOCKOPT]\t\t= \"cgroup_getsockopt\",\n\t[BPF_CGROUP_SETSOCKOPT]\t\t= \"cgroup_setsockopt\",\n\t[BPF_SK_SKB_STREAM_PARSER]\t= \"sk_skb_stream_parser\",\n\t[BPF_SK_SKB_STREAM_VERDICT]\t= \"sk_skb_stream_verdict\",\n\t[BPF_SK_SKB_VERDICT]\t\t= \"sk_skb_verdict\",\n\t[BPF_SK_MSG_VERDICT]\t\t= \"sk_msg_verdict\",\n\t[BPF_LIRC_MODE2]\t\t= \"lirc_mode2\",\n\t[BPF_FLOW_DISSECTOR]\t\t= \"flow_dissector\",\n\t[BPF_TRACE_RAW_TP]\t\t= \"trace_raw_tp\",\n\t[BPF_TRACE_FENTRY]\t\t= \"trace_fentry\",\n\t[BPF_TRACE_FEXIT]\t\t= \"trace_fexit\",\n\t[BPF_MODIFY_RETURN]\t\t= \"modify_return\",\n\t[BPF_LSM_MAC]\t\t\t= \"lsm_mac\",\n\t[BPF_LSM_CGROUP]\t\t= \"lsm_cgroup\",\n\t[BPF_SK_LOOKUP]\t\t\t= \"sk_lookup\",\n\t[BPF_TRACE_ITER]\t\t= \"trace_iter\",\n\t[BPF_XDP_DEVMAP]\t\t= \"xdp_devmap\",\n\t[BPF_XDP_CPUMAP]\t\t= \"xdp_cpumap\",\n\t[BPF_XDP]\t\t\t= \"xdp\",\n\t[BPF_SK_REUSEPORT_SELECT]\t= \"sk_reuseport_select\",\n\t[BPF_SK_REUSEPORT_SELECT_OR_MIGRATE]\t= \"sk_reuseport_select_or_migrate\",\n\t[BPF_PERF_EVENT]\t\t= \"perf_event\",\n\t[BPF_TRACE_KPROBE_MULTI]\t= \"trace_kprobe_multi\",\n\t[BPF_STRUCT_OPS]\t\t= \"struct_ops\",\n\t[BPF_NETFILTER]\t\t\t= \"netfilter\",\n\t[BPF_TCX_INGRESS]\t\t= \"tcx_ingress\",\n\t[BPF_TCX_EGRESS]\t\t= \"tcx_egress\",\n\t[BPF_TRACE_UPROBE_MULTI]\t= \"trace_uprobe_multi\",\n};\n\nstatic const char * const link_type_name[] = {\n\t[BPF_LINK_TYPE_UNSPEC]\t\t\t= \"unspec\",\n\t[BPF_LINK_TYPE_RAW_TRACEPOINT]\t\t= \"raw_tracepoint\",\n\t[BPF_LINK_TYPE_TRACING]\t\t\t= \"tracing\",\n\t[BPF_LINK_TYPE_CGROUP]\t\t\t= \"cgroup\",\n\t[BPF_LINK_TYPE_ITER]\t\t\t= \"iter\",\n\t[BPF_LINK_TYPE_NETNS]\t\t\t= \"netns\",\n\t[BPF_LINK_TYPE_XDP]\t\t\t= \"xdp\",\n\t[BPF_LINK_TYPE_PERF_EVENT]\t\t= \"perf_event\",\n\t[BPF_LINK_TYPE_KPROBE_MULTI]\t\t= \"kprobe_multi\",\n\t[BPF_LINK_TYPE_STRUCT_OPS]\t\t= \"struct_ops\",\n\t[BPF_LINK_TYPE_NETFILTER]\t\t= \"netfilter\",\n\t[BPF_LINK_TYPE_TCX]\t\t\t= \"tcx\",\n\t[BPF_LINK_TYPE_UPROBE_MULTI]\t\t= \"uprobe_multi\",\n};\n\nstatic const char * const map_type_name[] = {\n\t[BPF_MAP_TYPE_UNSPEC]\t\t\t= \"unspec\",\n\t[BPF_MAP_TYPE_HASH]\t\t\t= \"hash\",\n\t[BPF_MAP_TYPE_ARRAY]\t\t\t= \"array\",\n\t[BPF_MAP_TYPE_PROG_ARRAY]\t\t= \"prog_array\",\n\t[BPF_MAP_TYPE_PERF_EVENT_ARRAY]\t\t= \"perf_event_array\",\n\t[BPF_MAP_TYPE_PERCPU_HASH]\t\t= \"percpu_hash\",\n\t[BPF_MAP_TYPE_PERCPU_ARRAY]\t\t= \"percpu_array\",\n\t[BPF_MAP_TYPE_STACK_TRACE]\t\t= \"stack_trace\",\n\t[BPF_MAP_TYPE_CGROUP_ARRAY]\t\t= \"cgroup_array\",\n\t[BPF_MAP_TYPE_LRU_HASH]\t\t\t= \"lru_hash\",\n\t[BPF_MAP_TYPE_LRU_PERCPU_HASH]\t\t= \"lru_percpu_hash\",\n\t[BPF_MAP_TYPE_LPM_TRIE]\t\t\t= \"lpm_trie\",\n\t[BPF_MAP_TYPE_ARRAY_OF_MAPS]\t\t= \"array_of_maps\",\n\t[BPF_MAP_TYPE_HASH_OF_MAPS]\t\t= \"hash_of_maps\",\n\t[BPF_MAP_TYPE_DEVMAP]\t\t\t= \"devmap\",\n\t[BPF_MAP_TYPE_DEVMAP_HASH]\t\t= \"devmap_hash\",\n\t[BPF_MAP_TYPE_SOCKMAP]\t\t\t= \"sockmap\",\n\t[BPF_MAP_TYPE_CPUMAP]\t\t\t= \"cpumap\",\n\t[BPF_MAP_TYPE_XSKMAP]\t\t\t= \"xskmap\",\n\t[BPF_MAP_TYPE_SOCKHASH]\t\t\t= \"sockhash\",\n\t[BPF_MAP_TYPE_CGROUP_STORAGE]\t\t= \"cgroup_storage\",\n\t[BPF_MAP_TYPE_REUSEPORT_SOCKARRAY]\t= \"reuseport_sockarray\",\n\t[BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE]\t= \"percpu_cgroup_storage\",\n\t[BPF_MAP_TYPE_QUEUE]\t\t\t= \"queue\",\n\t[BPF_MAP_TYPE_STACK]\t\t\t= \"stack\",\n\t[BPF_MAP_TYPE_SK_STORAGE]\t\t= \"sk_storage\",\n\t[BPF_MAP_TYPE_STRUCT_OPS]\t\t= \"struct_ops\",\n\t[BPF_MAP_TYPE_RINGBUF]\t\t\t= \"ringbuf\",\n\t[BPF_MAP_TYPE_INODE_STORAGE]\t\t= \"inode_storage\",\n\t[BPF_MAP_TYPE_TASK_STORAGE]\t\t= \"task_storage\",\n\t[BPF_MAP_TYPE_BLOOM_FILTER]\t\t= \"bloom_filter\",\n\t[BPF_MAP_TYPE_USER_RINGBUF]             = \"user_ringbuf\",\n\t[BPF_MAP_TYPE_CGRP_STORAGE]\t\t= \"cgrp_storage\",\n};\n\nstatic const char * const prog_type_name[] = {\n\t[BPF_PROG_TYPE_UNSPEC]\t\t\t= \"unspec\",\n\t[BPF_PROG_TYPE_SOCKET_FILTER]\t\t= \"socket_filter\",\n\t[BPF_PROG_TYPE_KPROBE]\t\t\t= \"kprobe\",\n\t[BPF_PROG_TYPE_SCHED_CLS]\t\t= \"sched_cls\",\n\t[BPF_PROG_TYPE_SCHED_ACT]\t\t= \"sched_act\",\n\t[BPF_PROG_TYPE_TRACEPOINT]\t\t= \"tracepoint\",\n\t[BPF_PROG_TYPE_XDP]\t\t\t= \"xdp\",\n\t[BPF_PROG_TYPE_PERF_EVENT]\t\t= \"perf_event\",\n\t[BPF_PROG_TYPE_CGROUP_SKB]\t\t= \"cgroup_skb\",\n\t[BPF_PROG_TYPE_CGROUP_SOCK]\t\t= \"cgroup_sock\",\n\t[BPF_PROG_TYPE_LWT_IN]\t\t\t= \"lwt_in\",\n\t[BPF_PROG_TYPE_LWT_OUT]\t\t\t= \"lwt_out\",\n\t[BPF_PROG_TYPE_LWT_XMIT]\t\t= \"lwt_xmit\",\n\t[BPF_PROG_TYPE_SOCK_OPS]\t\t= \"sock_ops\",\n\t[BPF_PROG_TYPE_SK_SKB]\t\t\t= \"sk_skb\",\n\t[BPF_PROG_TYPE_CGROUP_DEVICE]\t\t= \"cgroup_device\",\n\t[BPF_PROG_TYPE_SK_MSG]\t\t\t= \"sk_msg\",\n\t[BPF_PROG_TYPE_RAW_TRACEPOINT]\t\t= \"raw_tracepoint\",\n\t[BPF_PROG_TYPE_CGROUP_SOCK_ADDR]\t= \"cgroup_sock_addr\",\n\t[BPF_PROG_TYPE_LWT_SEG6LOCAL]\t\t= \"lwt_seg6local\",\n\t[BPF_PROG_TYPE_LIRC_MODE2]\t\t= \"lirc_mode2\",\n\t[BPF_PROG_TYPE_SK_REUSEPORT]\t\t= \"sk_reuseport\",\n\t[BPF_PROG_TYPE_FLOW_DISSECTOR]\t\t= \"flow_dissector\",\n\t[BPF_PROG_TYPE_CGROUP_SYSCTL]\t\t= \"cgroup_sysctl\",\n\t[BPF_PROG_TYPE_RAW_TRACEPOINT_WRITABLE]\t= \"raw_tracepoint_writable\",\n\t[BPF_PROG_TYPE_CGROUP_SOCKOPT]\t\t= \"cgroup_sockopt\",\n\t[BPF_PROG_TYPE_TRACING]\t\t\t= \"tracing\",\n\t[BPF_PROG_TYPE_STRUCT_OPS]\t\t= \"struct_ops\",\n\t[BPF_PROG_TYPE_EXT]\t\t\t= \"ext\",\n\t[BPF_PROG_TYPE_LSM]\t\t\t= \"lsm\",\n\t[BPF_PROG_TYPE_SK_LOOKUP]\t\t= \"sk_lookup\",\n\t[BPF_PROG_TYPE_SYSCALL]\t\t\t= \"syscall\",\n\t[BPF_PROG_TYPE_NETFILTER]\t\t= \"netfilter\",\n};\n\nstatic int __base_pr(enum libbpf_print_level level, const char *format,\n\t\t     va_list args)\n{\n\tif (level == LIBBPF_DEBUG)\n\t\treturn 0;\n\n\treturn vfprintf(stderr, format, args);\n}\n\nstatic libbpf_print_fn_t __libbpf_pr = __base_pr;\n\nlibbpf_print_fn_t libbpf_set_print(libbpf_print_fn_t fn)\n{\n\tlibbpf_print_fn_t old_print_fn;\n\n\told_print_fn = __atomic_exchange_n(&__libbpf_pr, fn, __ATOMIC_RELAXED);\n\n\treturn old_print_fn;\n}\n\n__printf(2, 3)\nvoid libbpf_print(enum libbpf_print_level level, const char *format, ...)\n{\n\tva_list args;\n\tint old_errno;\n\tlibbpf_print_fn_t print_fn;\n\n\tprint_fn = __atomic_load_n(&__libbpf_pr, __ATOMIC_RELAXED);\n\tif (!print_fn)\n\t\treturn;\n\n\told_errno = errno;\n\n\tva_start(args, format);\n\t__libbpf_pr(level, format, args);\n\tva_end(args);\n\n\terrno = old_errno;\n}\n\nstatic void pr_perm_msg(int err)\n{\n\tstruct rlimit limit;\n\tchar buf[100];\n\n\tif (err != -EPERM || geteuid() != 0)\n\t\treturn;\n\n\terr = getrlimit(RLIMIT_MEMLOCK, &limit);\n\tif (err)\n\t\treturn;\n\n\tif (limit.rlim_cur == RLIM_INFINITY)\n\t\treturn;\n\n\tif (limit.rlim_cur < 1024)\n\t\tsnprintf(buf, sizeof(buf), \"%zu bytes\", (size_t)limit.rlim_cur);\n\telse if (limit.rlim_cur < 1024*1024)\n\t\tsnprintf(buf, sizeof(buf), \"%.1f KiB\", (double)limit.rlim_cur / 1024);\n\telse\n\t\tsnprintf(buf, sizeof(buf), \"%.1f MiB\", (double)limit.rlim_cur / (1024*1024));\n\n\tpr_warn(\"permission error while running as root; try raising 'ulimit -l'? current value: %s\\n\",\n\t\tbuf);\n}\n\n#define STRERR_BUFSIZE  128\n\n \n#ifndef zfree\n# define zfree(ptr) ({ free(*ptr); *ptr = NULL; })\n#endif\n\n#ifndef zclose\n# define zclose(fd) ({\t\t\t\\\n\tint ___err = 0;\t\t\t\\\n\tif ((fd) >= 0)\t\t\t\\\n\t\t___err = close((fd));\t\\\n\tfd = -1;\t\t\t\\\n\t___err; })\n#endif\n\nstatic inline __u64 ptr_to_u64(const void *ptr)\n{\n\treturn (__u64) (unsigned long) ptr;\n}\n\nint libbpf_set_strict_mode(enum libbpf_strict_mode mode)\n{\n\t \n\treturn 0;\n}\n\n__u32 libbpf_major_version(void)\n{\n\treturn LIBBPF_MAJOR_VERSION;\n}\n\n__u32 libbpf_minor_version(void)\n{\n\treturn LIBBPF_MINOR_VERSION;\n}\n\nconst char *libbpf_version_string(void)\n{\n#define __S(X) #X\n#define _S(X) __S(X)\n\treturn  \"v\" _S(LIBBPF_MAJOR_VERSION) \".\" _S(LIBBPF_MINOR_VERSION);\n#undef _S\n#undef __S\n}\n\nenum reloc_type {\n\tRELO_LD64,\n\tRELO_CALL,\n\tRELO_DATA,\n\tRELO_EXTERN_LD64,\n\tRELO_EXTERN_CALL,\n\tRELO_SUBPROG_ADDR,\n\tRELO_CORE,\n};\n\nstruct reloc_desc {\n\tenum reloc_type type;\n\tint insn_idx;\n\tunion {\n\t\tconst struct bpf_core_relo *core_relo;  \n\t\tstruct {\n\t\t\tint map_idx;\n\t\t\tint sym_off;\n\t\t\tint ext_idx;\n\t\t};\n\t};\n};\n\n \nenum sec_def_flags {\n\tSEC_NONE = 0,\n\t \n\tSEC_EXP_ATTACH_OPT = 1,\n\t \n\tSEC_ATTACHABLE = 2,\n\tSEC_ATTACHABLE_OPT = SEC_ATTACHABLE | SEC_EXP_ATTACH_OPT,\n\t \n\tSEC_ATTACH_BTF = 4,\n\t \n\tSEC_SLEEPABLE = 8,\n\t \n\tSEC_XDP_FRAGS = 16,\n\t \n\tSEC_USDT = 32,\n};\n\nstruct bpf_sec_def {\n\tchar *sec;\n\tenum bpf_prog_type prog_type;\n\tenum bpf_attach_type expected_attach_type;\n\tlong cookie;\n\tint handler_id;\n\n\tlibbpf_prog_setup_fn_t prog_setup_fn;\n\tlibbpf_prog_prepare_load_fn_t prog_prepare_load_fn;\n\tlibbpf_prog_attach_fn_t prog_attach_fn;\n};\n\n \nstruct bpf_program {\n\tchar *name;\n\tchar *sec_name;\n\tsize_t sec_idx;\n\tconst struct bpf_sec_def *sec_def;\n\t \n\tsize_t sec_insn_off;\n\t \n\tsize_t sec_insn_cnt;\n\t \n\tsize_t sub_insn_off;\n\n\t \n\tstruct bpf_insn *insns;\n\t \n\tsize_t insns_cnt;\n\n\tstruct reloc_desc *reloc_desc;\n\tint nr_reloc;\n\n\t \n\tchar *log_buf;\n\tsize_t log_size;\n\t__u32 log_level;\n\n\tstruct bpf_object *obj;\n\n\tint fd;\n\tbool autoload;\n\tbool autoattach;\n\tbool mark_btf_static;\n\tenum bpf_prog_type type;\n\tenum bpf_attach_type expected_attach_type;\n\n\tint prog_ifindex;\n\t__u32 attach_btf_obj_fd;\n\t__u32 attach_btf_id;\n\t__u32 attach_prog_fd;\n\n\tvoid *func_info;\n\t__u32 func_info_rec_size;\n\t__u32 func_info_cnt;\n\n\tvoid *line_info;\n\t__u32 line_info_rec_size;\n\t__u32 line_info_cnt;\n\t__u32 prog_flags;\n};\n\nstruct bpf_struct_ops {\n\tconst char *tname;\n\tconst struct btf_type *type;\n\tstruct bpf_program **progs;\n\t__u32 *kern_func_off;\n\t \n\tvoid *data;\n\t \n\tvoid *kern_vdata;\n\t__u32 type_id;\n};\n\n#define DATA_SEC \".data\"\n#define BSS_SEC \".bss\"\n#define RODATA_SEC \".rodata\"\n#define KCONFIG_SEC \".kconfig\"\n#define KSYMS_SEC \".ksyms\"\n#define STRUCT_OPS_SEC \".struct_ops\"\n#define STRUCT_OPS_LINK_SEC \".struct_ops.link\"\n\nenum libbpf_map_type {\n\tLIBBPF_MAP_UNSPEC,\n\tLIBBPF_MAP_DATA,\n\tLIBBPF_MAP_BSS,\n\tLIBBPF_MAP_RODATA,\n\tLIBBPF_MAP_KCONFIG,\n};\n\nstruct bpf_map_def {\n\tunsigned int type;\n\tunsigned int key_size;\n\tunsigned int value_size;\n\tunsigned int max_entries;\n\tunsigned int map_flags;\n};\n\nstruct bpf_map {\n\tstruct bpf_object *obj;\n\tchar *name;\n\t \n\tchar *real_name;\n\tint fd;\n\tint sec_idx;\n\tsize_t sec_offset;\n\tint map_ifindex;\n\tint inner_map_fd;\n\tstruct bpf_map_def def;\n\t__u32 numa_node;\n\t__u32 btf_var_idx;\n\t__u32 btf_key_type_id;\n\t__u32 btf_value_type_id;\n\t__u32 btf_vmlinux_value_type_id;\n\tenum libbpf_map_type libbpf_type;\n\tvoid *mmaped;\n\tstruct bpf_struct_ops *st_ops;\n\tstruct bpf_map *inner_map;\n\tvoid **init_slots;\n\tint init_slots_sz;\n\tchar *pin_path;\n\tbool pinned;\n\tbool reused;\n\tbool autocreate;\n\t__u64 map_extra;\n};\n\nenum extern_type {\n\tEXT_UNKNOWN,\n\tEXT_KCFG,\n\tEXT_KSYM,\n};\n\nenum kcfg_type {\n\tKCFG_UNKNOWN,\n\tKCFG_CHAR,\n\tKCFG_BOOL,\n\tKCFG_INT,\n\tKCFG_TRISTATE,\n\tKCFG_CHAR_ARR,\n};\n\nstruct extern_desc {\n\tenum extern_type type;\n\tint sym_idx;\n\tint btf_id;\n\tint sec_btf_id;\n\tconst char *name;\n\tchar *essent_name;\n\tbool is_set;\n\tbool is_weak;\n\tunion {\n\t\tstruct {\n\t\t\tenum kcfg_type type;\n\t\t\tint sz;\n\t\t\tint align;\n\t\t\tint data_off;\n\t\t\tbool is_signed;\n\t\t} kcfg;\n\t\tstruct {\n\t\t\tunsigned long long addr;\n\n\t\t\t \n\t\t\tint kernel_btf_obj_fd;\n\t\t\tint kernel_btf_id;\n\n\t\t\t \n\t\t\t__u32 type_id;\n\t\t\t \n\t\t\t__s16 btf_fd_idx;\n\t\t} ksym;\n\t};\n};\n\nstruct module_btf {\n\tstruct btf *btf;\n\tchar *name;\n\t__u32 id;\n\tint fd;\n\tint fd_array_idx;\n};\n\nenum sec_type {\n\tSEC_UNUSED = 0,\n\tSEC_RELO,\n\tSEC_BSS,\n\tSEC_DATA,\n\tSEC_RODATA,\n};\n\nstruct elf_sec_desc {\n\tenum sec_type sec_type;\n\tElf64_Shdr *shdr;\n\tElf_Data *data;\n};\n\nstruct elf_state {\n\tint fd;\n\tconst void *obj_buf;\n\tsize_t obj_buf_sz;\n\tElf *elf;\n\tElf64_Ehdr *ehdr;\n\tElf_Data *symbols;\n\tElf_Data *st_ops_data;\n\tElf_Data *st_ops_link_data;\n\tsize_t shstrndx;  \n\tsize_t strtabidx;\n\tstruct elf_sec_desc *secs;\n\tsize_t sec_cnt;\n\tint btf_maps_shndx;\n\t__u32 btf_maps_sec_btf_id;\n\tint text_shndx;\n\tint symbols_shndx;\n\tint st_ops_shndx;\n\tint st_ops_link_shndx;\n};\n\nstruct usdt_manager;\n\nstruct bpf_object {\n\tchar name[BPF_OBJ_NAME_LEN];\n\tchar license[64];\n\t__u32 kern_version;\n\n\tstruct bpf_program *programs;\n\tsize_t nr_programs;\n\tstruct bpf_map *maps;\n\tsize_t nr_maps;\n\tsize_t maps_cap;\n\n\tchar *kconfig;\n\tstruct extern_desc *externs;\n\tint nr_extern;\n\tint kconfig_map_idx;\n\n\tbool loaded;\n\tbool has_subcalls;\n\tbool has_rodata;\n\n\tstruct bpf_gen *gen_loader;\n\n\t \n\tstruct elf_state efile;\n\n\tstruct btf *btf;\n\tstruct btf_ext *btf_ext;\n\n\t \n\tstruct btf *btf_vmlinux;\n\t \n\tchar *btf_custom_path;\n\t \n\tstruct btf *btf_vmlinux_override;\n\t \n\tstruct module_btf *btf_modules;\n\tbool btf_modules_loaded;\n\tsize_t btf_module_cnt;\n\tsize_t btf_module_cap;\n\n\t \n\tchar *log_buf;\n\tsize_t log_size;\n\t__u32 log_level;\n\n\tint *fd_array;\n\tsize_t fd_array_cap;\n\tsize_t fd_array_cnt;\n\n\tstruct usdt_manager *usdt_man;\n\n\tchar path[];\n};\n\nstatic const char *elf_sym_str(const struct bpf_object *obj, size_t off);\nstatic const char *elf_sec_str(const struct bpf_object *obj, size_t off);\nstatic Elf_Scn *elf_sec_by_idx(const struct bpf_object *obj, size_t idx);\nstatic Elf_Scn *elf_sec_by_name(const struct bpf_object *obj, const char *name);\nstatic Elf64_Shdr *elf_sec_hdr(const struct bpf_object *obj, Elf_Scn *scn);\nstatic const char *elf_sec_name(const struct bpf_object *obj, Elf_Scn *scn);\nstatic Elf_Data *elf_sec_data(const struct bpf_object *obj, Elf_Scn *scn);\nstatic Elf64_Sym *elf_sym_by_idx(const struct bpf_object *obj, size_t idx);\nstatic Elf64_Rel *elf_rel_by_idx(Elf_Data *data, size_t idx);\n\nvoid bpf_program__unload(struct bpf_program *prog)\n{\n\tif (!prog)\n\t\treturn;\n\n\tzclose(prog->fd);\n\n\tzfree(&prog->func_info);\n\tzfree(&prog->line_info);\n}\n\nstatic void bpf_program__exit(struct bpf_program *prog)\n{\n\tif (!prog)\n\t\treturn;\n\n\tbpf_program__unload(prog);\n\tzfree(&prog->name);\n\tzfree(&prog->sec_name);\n\tzfree(&prog->insns);\n\tzfree(&prog->reloc_desc);\n\n\tprog->nr_reloc = 0;\n\tprog->insns_cnt = 0;\n\tprog->sec_idx = -1;\n}\n\nstatic bool insn_is_subprog_call(const struct bpf_insn *insn)\n{\n\treturn BPF_CLASS(insn->code) == BPF_JMP &&\n\t       BPF_OP(insn->code) == BPF_CALL &&\n\t       BPF_SRC(insn->code) == BPF_K &&\n\t       insn->src_reg == BPF_PSEUDO_CALL &&\n\t       insn->dst_reg == 0 &&\n\t       insn->off == 0;\n}\n\nstatic bool is_call_insn(const struct bpf_insn *insn)\n{\n\treturn insn->code == (BPF_JMP | BPF_CALL);\n}\n\nstatic bool insn_is_pseudo_func(struct bpf_insn *insn)\n{\n\treturn is_ldimm64_insn(insn) && insn->src_reg == BPF_PSEUDO_FUNC;\n}\n\nstatic int\nbpf_object__init_prog(struct bpf_object *obj, struct bpf_program *prog,\n\t\t      const char *name, size_t sec_idx, const char *sec_name,\n\t\t      size_t sec_off, void *insn_data, size_t insn_data_sz)\n{\n\tif (insn_data_sz == 0 || insn_data_sz % BPF_INSN_SZ || sec_off % BPF_INSN_SZ) {\n\t\tpr_warn(\"sec '%s': corrupted program '%s', offset %zu, size %zu\\n\",\n\t\t\tsec_name, name, sec_off, insn_data_sz);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(prog, 0, sizeof(*prog));\n\tprog->obj = obj;\n\n\tprog->sec_idx = sec_idx;\n\tprog->sec_insn_off = sec_off / BPF_INSN_SZ;\n\tprog->sec_insn_cnt = insn_data_sz / BPF_INSN_SZ;\n\t \n\tprog->insns_cnt = prog->sec_insn_cnt;\n\n\tprog->type = BPF_PROG_TYPE_UNSPEC;\n\tprog->fd = -1;\n\n\t \n\tif (sec_name[0] == '?') {\n\t\tprog->autoload = false;\n\t\t \n\t\tsec_name++;\n\t} else {\n\t\tprog->autoload = true;\n\t}\n\n\tprog->autoattach = true;\n\n\t \n\tprog->log_level = obj->log_level;\n\n\tprog->sec_name = strdup(sec_name);\n\tif (!prog->sec_name)\n\t\tgoto errout;\n\n\tprog->name = strdup(name);\n\tif (!prog->name)\n\t\tgoto errout;\n\n\tprog->insns = malloc(insn_data_sz);\n\tif (!prog->insns)\n\t\tgoto errout;\n\tmemcpy(prog->insns, insn_data, insn_data_sz);\n\n\treturn 0;\nerrout:\n\tpr_warn(\"sec '%s': failed to allocate memory for prog '%s'\\n\", sec_name, name);\n\tbpf_program__exit(prog);\n\treturn -ENOMEM;\n}\n\nstatic int\nbpf_object__add_programs(struct bpf_object *obj, Elf_Data *sec_data,\n\t\t\t const char *sec_name, int sec_idx)\n{\n\tElf_Data *symbols = obj->efile.symbols;\n\tstruct bpf_program *prog, *progs;\n\tvoid *data = sec_data->d_buf;\n\tsize_t sec_sz = sec_data->d_size, sec_off, prog_sz, nr_syms;\n\tint nr_progs, err, i;\n\tconst char *name;\n\tElf64_Sym *sym;\n\n\tprogs = obj->programs;\n\tnr_progs = obj->nr_programs;\n\tnr_syms = symbols->d_size / sizeof(Elf64_Sym);\n\n\tfor (i = 0; i < nr_syms; i++) {\n\t\tsym = elf_sym_by_idx(obj, i);\n\n\t\tif (sym->st_shndx != sec_idx)\n\t\t\tcontinue;\n\t\tif (ELF64_ST_TYPE(sym->st_info) != STT_FUNC)\n\t\t\tcontinue;\n\n\t\tprog_sz = sym->st_size;\n\t\tsec_off = sym->st_value;\n\n\t\tname = elf_sym_str(obj, sym->st_name);\n\t\tif (!name) {\n\t\t\tpr_warn(\"sec '%s': failed to get symbol name for offset %zu\\n\",\n\t\t\t\tsec_name, sec_off);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tif (sec_off + prog_sz > sec_sz) {\n\t\t\tpr_warn(\"sec '%s': program at offset %zu crosses section boundary\\n\",\n\t\t\t\tsec_name, sec_off);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tif (sec_idx != obj->efile.text_shndx && ELF64_ST_BIND(sym->st_info) == STB_LOCAL) {\n\t\t\tpr_warn(\"sec '%s': program '%s' is static and not supported\\n\", sec_name, name);\n\t\t\treturn -ENOTSUP;\n\t\t}\n\n\t\tpr_debug(\"sec '%s': found program '%s' at insn offset %zu (%zu bytes), code size %zu insns (%zu bytes)\\n\",\n\t\t\t sec_name, name, sec_off / BPF_INSN_SZ, sec_off, prog_sz / BPF_INSN_SZ, prog_sz);\n\n\t\tprogs = libbpf_reallocarray(progs, nr_progs + 1, sizeof(*progs));\n\t\tif (!progs) {\n\t\t\t \n\t\t\tpr_warn(\"sec '%s': failed to alloc memory for new program '%s'\\n\",\n\t\t\t\tsec_name, name);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tobj->programs = progs;\n\n\t\tprog = &progs[nr_progs];\n\n\t\terr = bpf_object__init_prog(obj, prog, name, sec_idx, sec_name,\n\t\t\t\t\t    sec_off, data + sec_off, prog_sz);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t \n\t\tif (ELF64_ST_BIND(sym->st_info) != STB_LOCAL\n\t\t    && (ELF64_ST_VISIBILITY(sym->st_other) == STV_HIDDEN\n\t\t\t|| ELF64_ST_VISIBILITY(sym->st_other) == STV_INTERNAL))\n\t\t\tprog->mark_btf_static = true;\n\n\t\tnr_progs++;\n\t\tobj->nr_programs = nr_progs;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct btf_member *\nfind_member_by_offset(const struct btf_type *t, __u32 bit_offset)\n{\n\tstruct btf_member *m;\n\tint i;\n\n\tfor (i = 0, m = btf_members(t); i < btf_vlen(t); i++, m++) {\n\t\tif (btf_member_bit_offset(t, i) == bit_offset)\n\t\t\treturn m;\n\t}\n\n\treturn NULL;\n}\n\nstatic const struct btf_member *\nfind_member_by_name(const struct btf *btf, const struct btf_type *t,\n\t\t    const char *name)\n{\n\tstruct btf_member *m;\n\tint i;\n\n\tfor (i = 0, m = btf_members(t); i < btf_vlen(t); i++, m++) {\n\t\tif (!strcmp(btf__name_by_offset(btf, m->name_off), name))\n\t\t\treturn m;\n\t}\n\n\treturn NULL;\n}\n\n#define STRUCT_OPS_VALUE_PREFIX \"bpf_struct_ops_\"\nstatic int find_btf_by_prefix_kind(const struct btf *btf, const char *prefix,\n\t\t\t\t   const char *name, __u32 kind);\n\nstatic int\nfind_struct_ops_kern_types(const struct btf *btf, const char *tname,\n\t\t\t   const struct btf_type **type, __u32 *type_id,\n\t\t\t   const struct btf_type **vtype, __u32 *vtype_id,\n\t\t\t   const struct btf_member **data_member)\n{\n\tconst struct btf_type *kern_type, *kern_vtype;\n\tconst struct btf_member *kern_data_member;\n\t__s32 kern_vtype_id, kern_type_id;\n\t__u32 i;\n\n\tkern_type_id = btf__find_by_name_kind(btf, tname, BTF_KIND_STRUCT);\n\tif (kern_type_id < 0) {\n\t\tpr_warn(\"struct_ops init_kern: struct %s is not found in kernel BTF\\n\",\n\t\t\ttname);\n\t\treturn kern_type_id;\n\t}\n\tkern_type = btf__type_by_id(btf, kern_type_id);\n\n\t \n\tkern_vtype_id = find_btf_by_prefix_kind(btf, STRUCT_OPS_VALUE_PREFIX,\n\t\t\t\t\t\ttname, BTF_KIND_STRUCT);\n\tif (kern_vtype_id < 0) {\n\t\tpr_warn(\"struct_ops init_kern: struct %s%s is not found in kernel BTF\\n\",\n\t\t\tSTRUCT_OPS_VALUE_PREFIX, tname);\n\t\treturn kern_vtype_id;\n\t}\n\tkern_vtype = btf__type_by_id(btf, kern_vtype_id);\n\n\t \n\tkern_data_member = btf_members(kern_vtype);\n\tfor (i = 0; i < btf_vlen(kern_vtype); i++, kern_data_member++) {\n\t\tif (kern_data_member->type == kern_type_id)\n\t\t\tbreak;\n\t}\n\tif (i == btf_vlen(kern_vtype)) {\n\t\tpr_warn(\"struct_ops init_kern: struct %s data is not found in struct %s%s\\n\",\n\t\t\ttname, STRUCT_OPS_VALUE_PREFIX, tname);\n\t\treturn -EINVAL;\n\t}\n\n\t*type = kern_type;\n\t*type_id = kern_type_id;\n\t*vtype = kern_vtype;\n\t*vtype_id = kern_vtype_id;\n\t*data_member = kern_data_member;\n\n\treturn 0;\n}\n\nstatic bool bpf_map__is_struct_ops(const struct bpf_map *map)\n{\n\treturn map->def.type == BPF_MAP_TYPE_STRUCT_OPS;\n}\n\n \nstatic int bpf_map__init_kern_struct_ops(struct bpf_map *map,\n\t\t\t\t\t const struct btf *btf,\n\t\t\t\t\t const struct btf *kern_btf)\n{\n\tconst struct btf_member *member, *kern_member, *kern_data_member;\n\tconst struct btf_type *type, *kern_type, *kern_vtype;\n\t__u32 i, kern_type_id, kern_vtype_id, kern_data_off;\n\tstruct bpf_struct_ops *st_ops;\n\tvoid *data, *kern_data;\n\tconst char *tname;\n\tint err;\n\n\tst_ops = map->st_ops;\n\ttype = st_ops->type;\n\ttname = st_ops->tname;\n\terr = find_struct_ops_kern_types(kern_btf, tname,\n\t\t\t\t\t &kern_type, &kern_type_id,\n\t\t\t\t\t &kern_vtype, &kern_vtype_id,\n\t\t\t\t\t &kern_data_member);\n\tif (err)\n\t\treturn err;\n\n\tpr_debug(\"struct_ops init_kern %s: type_id:%u kern_type_id:%u kern_vtype_id:%u\\n\",\n\t\t map->name, st_ops->type_id, kern_type_id, kern_vtype_id);\n\n\tmap->def.value_size = kern_vtype->size;\n\tmap->btf_vmlinux_value_type_id = kern_vtype_id;\n\n\tst_ops->kern_vdata = calloc(1, kern_vtype->size);\n\tif (!st_ops->kern_vdata)\n\t\treturn -ENOMEM;\n\n\tdata = st_ops->data;\n\tkern_data_off = kern_data_member->offset / 8;\n\tkern_data = st_ops->kern_vdata + kern_data_off;\n\n\tmember = btf_members(type);\n\tfor (i = 0; i < btf_vlen(type); i++, member++) {\n\t\tconst struct btf_type *mtype, *kern_mtype;\n\t\t__u32 mtype_id, kern_mtype_id;\n\t\tvoid *mdata, *kern_mdata;\n\t\t__s64 msize, kern_msize;\n\t\t__u32 moff, kern_moff;\n\t\t__u32 kern_member_idx;\n\t\tconst char *mname;\n\n\t\tmname = btf__name_by_offset(btf, member->name_off);\n\t\tkern_member = find_member_by_name(kern_btf, kern_type, mname);\n\t\tif (!kern_member) {\n\t\t\tpr_warn(\"struct_ops init_kern %s: Cannot find member %s in kernel BTF\\n\",\n\t\t\t\tmap->name, mname);\n\t\t\treturn -ENOTSUP;\n\t\t}\n\n\t\tkern_member_idx = kern_member - btf_members(kern_type);\n\t\tif (btf_member_bitfield_size(type, i) ||\n\t\t    btf_member_bitfield_size(kern_type, kern_member_idx)) {\n\t\t\tpr_warn(\"struct_ops init_kern %s: bitfield %s is not supported\\n\",\n\t\t\t\tmap->name, mname);\n\t\t\treturn -ENOTSUP;\n\t\t}\n\n\t\tmoff = member->offset / 8;\n\t\tkern_moff = kern_member->offset / 8;\n\n\t\tmdata = data + moff;\n\t\tkern_mdata = kern_data + kern_moff;\n\n\t\tmtype = skip_mods_and_typedefs(btf, member->type, &mtype_id);\n\t\tkern_mtype = skip_mods_and_typedefs(kern_btf, kern_member->type,\n\t\t\t\t\t\t    &kern_mtype_id);\n\t\tif (BTF_INFO_KIND(mtype->info) !=\n\t\t    BTF_INFO_KIND(kern_mtype->info)) {\n\t\t\tpr_warn(\"struct_ops init_kern %s: Unmatched member type %s %u != %u(kernel)\\n\",\n\t\t\t\tmap->name, mname, BTF_INFO_KIND(mtype->info),\n\t\t\t\tBTF_INFO_KIND(kern_mtype->info));\n\t\t\treturn -ENOTSUP;\n\t\t}\n\n\t\tif (btf_is_ptr(mtype)) {\n\t\t\tstruct bpf_program *prog;\n\n\t\t\tprog = st_ops->progs[i];\n\t\t\tif (!prog)\n\t\t\t\tcontinue;\n\n\t\t\tkern_mtype = skip_mods_and_typedefs(kern_btf,\n\t\t\t\t\t\t\t    kern_mtype->type,\n\t\t\t\t\t\t\t    &kern_mtype_id);\n\n\t\t\t \n\t\t\tif (!btf_is_func_proto(kern_mtype)) {\n\t\t\t\tpr_warn(\"struct_ops init_kern %s: kernel member %s is not a func ptr\\n\",\n\t\t\t\t\tmap->name, mname);\n\t\t\t\treturn -ENOTSUP;\n\t\t\t}\n\n\t\t\tprog->attach_btf_id = kern_type_id;\n\t\t\tprog->expected_attach_type = kern_member_idx;\n\n\t\t\tst_ops->kern_func_off[i] = kern_data_off + kern_moff;\n\n\t\t\tpr_debug(\"struct_ops init_kern %s: func ptr %s is set to prog %s from data(+%u) to kern_data(+%u)\\n\",\n\t\t\t\t map->name, mname, prog->name, moff,\n\t\t\t\t kern_moff);\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tmsize = btf__resolve_size(btf, mtype_id);\n\t\tkern_msize = btf__resolve_size(kern_btf, kern_mtype_id);\n\t\tif (msize < 0 || kern_msize < 0 || msize != kern_msize) {\n\t\t\tpr_warn(\"struct_ops init_kern %s: Error in size of member %s: %zd != %zd(kernel)\\n\",\n\t\t\t\tmap->name, mname, (ssize_t)msize,\n\t\t\t\t(ssize_t)kern_msize);\n\t\t\treturn -ENOTSUP;\n\t\t}\n\n\t\tpr_debug(\"struct_ops init_kern %s: copy %s %u bytes from data(+%u) to kern_data(+%u)\\n\",\n\t\t\t map->name, mname, (unsigned int)msize,\n\t\t\t moff, kern_moff);\n\t\tmemcpy(kern_mdata, mdata, msize);\n\t}\n\n\treturn 0;\n}\n\nstatic int bpf_object__init_kern_struct_ops_maps(struct bpf_object *obj)\n{\n\tstruct bpf_map *map;\n\tsize_t i;\n\tint err;\n\n\tfor (i = 0; i < obj->nr_maps; i++) {\n\t\tmap = &obj->maps[i];\n\n\t\tif (!bpf_map__is_struct_ops(map))\n\t\t\tcontinue;\n\n\t\terr = bpf_map__init_kern_struct_ops(map, obj->btf,\n\t\t\t\t\t\t    obj->btf_vmlinux);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int init_struct_ops_maps(struct bpf_object *obj, const char *sec_name,\n\t\t\t\tint shndx, Elf_Data *data, __u32 map_flags)\n{\n\tconst struct btf_type *type, *datasec;\n\tconst struct btf_var_secinfo *vsi;\n\tstruct bpf_struct_ops *st_ops;\n\tconst char *tname, *var_name;\n\t__s32 type_id, datasec_id;\n\tconst struct btf *btf;\n\tstruct bpf_map *map;\n\t__u32 i;\n\n\tif (shndx == -1)\n\t\treturn 0;\n\n\tbtf = obj->btf;\n\tdatasec_id = btf__find_by_name_kind(btf, sec_name,\n\t\t\t\t\t    BTF_KIND_DATASEC);\n\tif (datasec_id < 0) {\n\t\tpr_warn(\"struct_ops init: DATASEC %s not found\\n\",\n\t\t\tsec_name);\n\t\treturn -EINVAL;\n\t}\n\n\tdatasec = btf__type_by_id(btf, datasec_id);\n\tvsi = btf_var_secinfos(datasec);\n\tfor (i = 0; i < btf_vlen(datasec); i++, vsi++) {\n\t\ttype = btf__type_by_id(obj->btf, vsi->type);\n\t\tvar_name = btf__name_by_offset(obj->btf, type->name_off);\n\n\t\ttype_id = btf__resolve_type(obj->btf, vsi->type);\n\t\tif (type_id < 0) {\n\t\t\tpr_warn(\"struct_ops init: Cannot resolve var type_id %u in DATASEC %s\\n\",\n\t\t\t\tvsi->type, sec_name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\ttype = btf__type_by_id(obj->btf, type_id);\n\t\ttname = btf__name_by_offset(obj->btf, type->name_off);\n\t\tif (!tname[0]) {\n\t\t\tpr_warn(\"struct_ops init: anonymous type is not supported\\n\");\n\t\t\treturn -ENOTSUP;\n\t\t}\n\t\tif (!btf_is_struct(type)) {\n\t\t\tpr_warn(\"struct_ops init: %s is not a struct\\n\", tname);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tmap = bpf_object__add_map(obj);\n\t\tif (IS_ERR(map))\n\t\t\treturn PTR_ERR(map);\n\n\t\tmap->sec_idx = shndx;\n\t\tmap->sec_offset = vsi->offset;\n\t\tmap->name = strdup(var_name);\n\t\tif (!map->name)\n\t\t\treturn -ENOMEM;\n\n\t\tmap->def.type = BPF_MAP_TYPE_STRUCT_OPS;\n\t\tmap->def.key_size = sizeof(int);\n\t\tmap->def.value_size = type->size;\n\t\tmap->def.max_entries = 1;\n\t\tmap->def.map_flags = map_flags;\n\n\t\tmap->st_ops = calloc(1, sizeof(*map->st_ops));\n\t\tif (!map->st_ops)\n\t\t\treturn -ENOMEM;\n\t\tst_ops = map->st_ops;\n\t\tst_ops->data = malloc(type->size);\n\t\tst_ops->progs = calloc(btf_vlen(type), sizeof(*st_ops->progs));\n\t\tst_ops->kern_func_off = malloc(btf_vlen(type) *\n\t\t\t\t\t       sizeof(*st_ops->kern_func_off));\n\t\tif (!st_ops->data || !st_ops->progs || !st_ops->kern_func_off)\n\t\t\treturn -ENOMEM;\n\n\t\tif (vsi->offset + type->size > data->d_size) {\n\t\t\tpr_warn(\"struct_ops init: var %s is beyond the end of DATASEC %s\\n\",\n\t\t\t\tvar_name, sec_name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tmemcpy(st_ops->data,\n\t\t       data->d_buf + vsi->offset,\n\t\t       type->size);\n\t\tst_ops->tname = tname;\n\t\tst_ops->type = type;\n\t\tst_ops->type_id = type_id;\n\n\t\tpr_debug(\"struct_ops init: struct %s(type_id=%u) %s found at offset %u\\n\",\n\t\t\t tname, type_id, var_name, vsi->offset);\n\t}\n\n\treturn 0;\n}\n\nstatic int bpf_object_init_struct_ops(struct bpf_object *obj)\n{\n\tint err;\n\n\terr = init_struct_ops_maps(obj, STRUCT_OPS_SEC, obj->efile.st_ops_shndx,\n\t\t\t\t   obj->efile.st_ops_data, 0);\n\terr = err ?: init_struct_ops_maps(obj, STRUCT_OPS_LINK_SEC,\n\t\t\t\t\t  obj->efile.st_ops_link_shndx,\n\t\t\t\t\t  obj->efile.st_ops_link_data,\n\t\t\t\t\t  BPF_F_LINK);\n\treturn err;\n}\n\nstatic struct bpf_object *bpf_object__new(const char *path,\n\t\t\t\t\t  const void *obj_buf,\n\t\t\t\t\t  size_t obj_buf_sz,\n\t\t\t\t\t  const char *obj_name)\n{\n\tstruct bpf_object *obj;\n\tchar *end;\n\n\tobj = calloc(1, sizeof(struct bpf_object) + strlen(path) + 1);\n\tif (!obj) {\n\t\tpr_warn(\"alloc memory failed for %s\\n\", path);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tstrcpy(obj->path, path);\n\tif (obj_name) {\n\t\tlibbpf_strlcpy(obj->name, obj_name, sizeof(obj->name));\n\t} else {\n\t\t \n\t\tlibbpf_strlcpy(obj->name, basename((void *)path), sizeof(obj->name));\n\t\tend = strchr(obj->name, '.');\n\t\tif (end)\n\t\t\t*end = 0;\n\t}\n\n\tobj->efile.fd = -1;\n\t \n\tobj->efile.obj_buf = obj_buf;\n\tobj->efile.obj_buf_sz = obj_buf_sz;\n\tobj->efile.btf_maps_shndx = -1;\n\tobj->efile.st_ops_shndx = -1;\n\tobj->efile.st_ops_link_shndx = -1;\n\tobj->kconfig_map_idx = -1;\n\n\tobj->kern_version = get_kernel_version();\n\tobj->loaded = false;\n\n\treturn obj;\n}\n\nstatic void bpf_object__elf_finish(struct bpf_object *obj)\n{\n\tif (!obj->efile.elf)\n\t\treturn;\n\n\telf_end(obj->efile.elf);\n\tobj->efile.elf = NULL;\n\tobj->efile.symbols = NULL;\n\tobj->efile.st_ops_data = NULL;\n\tobj->efile.st_ops_link_data = NULL;\n\n\tzfree(&obj->efile.secs);\n\tobj->efile.sec_cnt = 0;\n\tzclose(obj->efile.fd);\n\tobj->efile.obj_buf = NULL;\n\tobj->efile.obj_buf_sz = 0;\n}\n\nstatic int bpf_object__elf_init(struct bpf_object *obj)\n{\n\tElf64_Ehdr *ehdr;\n\tint err = 0;\n\tElf *elf;\n\n\tif (obj->efile.elf) {\n\t\tpr_warn(\"elf: init internal error\\n\");\n\t\treturn -LIBBPF_ERRNO__LIBELF;\n\t}\n\n\tif (obj->efile.obj_buf_sz > 0) {\n\t\t \n\t\telf = elf_memory((char *)obj->efile.obj_buf, obj->efile.obj_buf_sz);\n\t} else {\n\t\tobj->efile.fd = open(obj->path, O_RDONLY | O_CLOEXEC);\n\t\tif (obj->efile.fd < 0) {\n\t\t\tchar errmsg[STRERR_BUFSIZE], *cp;\n\n\t\t\terr = -errno;\n\t\t\tcp = libbpf_strerror_r(err, errmsg, sizeof(errmsg));\n\t\t\tpr_warn(\"elf: failed to open %s: %s\\n\", obj->path, cp);\n\t\t\treturn err;\n\t\t}\n\n\t\telf = elf_begin(obj->efile.fd, ELF_C_READ_MMAP, NULL);\n\t}\n\n\tif (!elf) {\n\t\tpr_warn(\"elf: failed to open %s as ELF file: %s\\n\", obj->path, elf_errmsg(-1));\n\t\terr = -LIBBPF_ERRNO__LIBELF;\n\t\tgoto errout;\n\t}\n\n\tobj->efile.elf = elf;\n\n\tif (elf_kind(elf) != ELF_K_ELF) {\n\t\terr = -LIBBPF_ERRNO__FORMAT;\n\t\tpr_warn(\"elf: '%s' is not a proper ELF object\\n\", obj->path);\n\t\tgoto errout;\n\t}\n\n\tif (gelf_getclass(elf) != ELFCLASS64) {\n\t\terr = -LIBBPF_ERRNO__FORMAT;\n\t\tpr_warn(\"elf: '%s' is not a 64-bit ELF object\\n\", obj->path);\n\t\tgoto errout;\n\t}\n\n\tobj->efile.ehdr = ehdr = elf64_getehdr(elf);\n\tif (!obj->efile.ehdr) {\n\t\tpr_warn(\"elf: failed to get ELF header from %s: %s\\n\", obj->path, elf_errmsg(-1));\n\t\terr = -LIBBPF_ERRNO__FORMAT;\n\t\tgoto errout;\n\t}\n\n\tif (elf_getshdrstrndx(elf, &obj->efile.shstrndx)) {\n\t\tpr_warn(\"elf: failed to get section names section index for %s: %s\\n\",\n\t\t\tobj->path, elf_errmsg(-1));\n\t\terr = -LIBBPF_ERRNO__FORMAT;\n\t\tgoto errout;\n\t}\n\n\t \n\tif (!elf_rawdata(elf_getscn(elf, obj->efile.shstrndx), NULL)) {\n\t\tpr_warn(\"elf: failed to get section names strings from %s: %s\\n\",\n\t\t\tobj->path, elf_errmsg(-1));\n\t\terr = -LIBBPF_ERRNO__FORMAT;\n\t\tgoto errout;\n\t}\n\n\t \n\tif (ehdr->e_type != ET_REL || (ehdr->e_machine && ehdr->e_machine != EM_BPF)) {\n\t\tpr_warn(\"elf: %s is not a valid eBPF object file\\n\", obj->path);\n\t\terr = -LIBBPF_ERRNO__FORMAT;\n\t\tgoto errout;\n\t}\n\n\treturn 0;\nerrout:\n\tbpf_object__elf_finish(obj);\n\treturn err;\n}\n\nstatic int bpf_object__check_endianness(struct bpf_object *obj)\n{\n#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__\n\tif (obj->efile.ehdr->e_ident[EI_DATA] == ELFDATA2LSB)\n\t\treturn 0;\n#elif __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__\n\tif (obj->efile.ehdr->e_ident[EI_DATA] == ELFDATA2MSB)\n\t\treturn 0;\n#else\n# error \"Unrecognized __BYTE_ORDER__\"\n#endif\n\tpr_warn(\"elf: endianness mismatch in %s.\\n\", obj->path);\n\treturn -LIBBPF_ERRNO__ENDIAN;\n}\n\nstatic int\nbpf_object__init_license(struct bpf_object *obj, void *data, size_t size)\n{\n\tif (!data) {\n\t\tpr_warn(\"invalid license section in %s\\n\", obj->path);\n\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t}\n\t \n\tlibbpf_strlcpy(obj->license, data, min(size + 1, sizeof(obj->license)));\n\tpr_debug(\"license of %s is %s\\n\", obj->path, obj->license);\n\treturn 0;\n}\n\nstatic int\nbpf_object__init_kversion(struct bpf_object *obj, void *data, size_t size)\n{\n\t__u32 kver;\n\n\tif (!data || size != sizeof(kver)) {\n\t\tpr_warn(\"invalid kver section in %s\\n\", obj->path);\n\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t}\n\tmemcpy(&kver, data, sizeof(kver));\n\tobj->kern_version = kver;\n\tpr_debug(\"kernel version of %s is %x\\n\", obj->path, obj->kern_version);\n\treturn 0;\n}\n\nstatic bool bpf_map_type__is_map_in_map(enum bpf_map_type type)\n{\n\tif (type == BPF_MAP_TYPE_ARRAY_OF_MAPS ||\n\t    type == BPF_MAP_TYPE_HASH_OF_MAPS)\n\t\treturn true;\n\treturn false;\n}\n\nstatic int find_elf_sec_sz(const struct bpf_object *obj, const char *name, __u32 *size)\n{\n\tElf_Data *data;\n\tElf_Scn *scn;\n\n\tif (!name)\n\t\treturn -EINVAL;\n\n\tscn = elf_sec_by_name(obj, name);\n\tdata = elf_sec_data(obj, scn);\n\tif (data) {\n\t\t*size = data->d_size;\n\t\treturn 0;  \n\t}\n\n\treturn -ENOENT;\n}\n\nstatic Elf64_Sym *find_elf_var_sym(const struct bpf_object *obj, const char *name)\n{\n\tElf_Data *symbols = obj->efile.symbols;\n\tconst char *sname;\n\tsize_t si;\n\n\tfor (si = 0; si < symbols->d_size / sizeof(Elf64_Sym); si++) {\n\t\tElf64_Sym *sym = elf_sym_by_idx(obj, si);\n\n\t\tif (ELF64_ST_TYPE(sym->st_info) != STT_OBJECT)\n\t\t\tcontinue;\n\n\t\tif (ELF64_ST_BIND(sym->st_info) != STB_GLOBAL &&\n\t\t    ELF64_ST_BIND(sym->st_info) != STB_WEAK)\n\t\t\tcontinue;\n\n\t\tsname = elf_sym_str(obj, sym->st_name);\n\t\tif (!sname) {\n\t\t\tpr_warn(\"failed to get sym name string for var %s\\n\", name);\n\t\t\treturn ERR_PTR(-EIO);\n\t\t}\n\t\tif (strcmp(name, sname) == 0)\n\t\t\treturn sym;\n\t}\n\n\treturn ERR_PTR(-ENOENT);\n}\n\nstatic struct bpf_map *bpf_object__add_map(struct bpf_object *obj)\n{\n\tstruct bpf_map *map;\n\tint err;\n\n\terr = libbpf_ensure_mem((void **)&obj->maps, &obj->maps_cap,\n\t\t\t\tsizeof(*obj->maps), obj->nr_maps + 1);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tmap = &obj->maps[obj->nr_maps++];\n\tmap->obj = obj;\n\tmap->fd = -1;\n\tmap->inner_map_fd = -1;\n\tmap->autocreate = true;\n\n\treturn map;\n}\n\nstatic size_t bpf_map_mmap_sz(unsigned int value_sz, unsigned int max_entries)\n{\n\tconst long page_sz = sysconf(_SC_PAGE_SIZE);\n\tsize_t map_sz;\n\n\tmap_sz = (size_t)roundup(value_sz, 8) * max_entries;\n\tmap_sz = roundup(map_sz, page_sz);\n\treturn map_sz;\n}\n\nstatic int bpf_map_mmap_resize(struct bpf_map *map, size_t old_sz, size_t new_sz)\n{\n\tvoid *mmaped;\n\n\tif (!map->mmaped)\n\t\treturn -EINVAL;\n\n\tif (old_sz == new_sz)\n\t\treturn 0;\n\n\tmmaped = mmap(NULL, new_sz, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);\n\tif (mmaped == MAP_FAILED)\n\t\treturn -errno;\n\n\tmemcpy(mmaped, map->mmaped, min(old_sz, new_sz));\n\tmunmap(map->mmaped, old_sz);\n\tmap->mmaped = mmaped;\n\treturn 0;\n}\n\nstatic char *internal_map_name(struct bpf_object *obj, const char *real_name)\n{\n\tchar map_name[BPF_OBJ_NAME_LEN], *p;\n\tint pfx_len, sfx_len = max((size_t)7, strlen(real_name));\n\n\t \n\tif (sfx_len >= BPF_OBJ_NAME_LEN)\n\t\tsfx_len = BPF_OBJ_NAME_LEN - 1;\n\n\t \n\tif (strchr(real_name + 1, '.') != NULL)\n\t\tpfx_len = 0;\n\telse\n\t\tpfx_len = min((size_t)BPF_OBJ_NAME_LEN - sfx_len - 1, strlen(obj->name));\n\n\tsnprintf(map_name, sizeof(map_name), \"%.*s%.*s\", pfx_len, obj->name,\n\t\t sfx_len, real_name);\n\n\t \n\tfor (p = map_name; *p && p < map_name + sizeof(map_name); p++)\n\t\tif (!isalnum(*p) && *p != '_' && *p != '.')\n\t\t\t*p = '_';\n\n\treturn strdup(map_name);\n}\n\nstatic int\nmap_fill_btf_type_info(struct bpf_object *obj, struct bpf_map *map);\n\n \nstatic bool map_is_mmapable(struct bpf_object *obj, struct bpf_map *map)\n{\n\tconst struct btf_type *t, *vt;\n\tstruct btf_var_secinfo *vsi;\n\tint i, n;\n\n\tif (!map->btf_value_type_id)\n\t\treturn false;\n\n\tt = btf__type_by_id(obj->btf, map->btf_value_type_id);\n\tif (!btf_is_datasec(t))\n\t\treturn false;\n\n\tvsi = btf_var_secinfos(t);\n\tfor (i = 0, n = btf_vlen(t); i < n; i++, vsi++) {\n\t\tvt = btf__type_by_id(obj->btf, vsi->type);\n\t\tif (!btf_is_var(vt))\n\t\t\tcontinue;\n\n\t\tif (btf_var(vt)->linkage != BTF_VAR_STATIC)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int\nbpf_object__init_internal_map(struct bpf_object *obj, enum libbpf_map_type type,\n\t\t\t      const char *real_name, int sec_idx, void *data, size_t data_sz)\n{\n\tstruct bpf_map_def *def;\n\tstruct bpf_map *map;\n\tsize_t mmap_sz;\n\tint err;\n\n\tmap = bpf_object__add_map(obj);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\n\tmap->libbpf_type = type;\n\tmap->sec_idx = sec_idx;\n\tmap->sec_offset = 0;\n\tmap->real_name = strdup(real_name);\n\tmap->name = internal_map_name(obj, real_name);\n\tif (!map->real_name || !map->name) {\n\t\tzfree(&map->real_name);\n\t\tzfree(&map->name);\n\t\treturn -ENOMEM;\n\t}\n\n\tdef = &map->def;\n\tdef->type = BPF_MAP_TYPE_ARRAY;\n\tdef->key_size = sizeof(int);\n\tdef->value_size = data_sz;\n\tdef->max_entries = 1;\n\tdef->map_flags = type == LIBBPF_MAP_RODATA || type == LIBBPF_MAP_KCONFIG\n\t\t\t ? BPF_F_RDONLY_PROG : 0;\n\n\t \n\t(void) map_fill_btf_type_info(obj, map);\n\n\tif (map_is_mmapable(obj, map))\n\t\tdef->map_flags |= BPF_F_MMAPABLE;\n\n\tpr_debug(\"map '%s' (global data): at sec_idx %d, offset %zu, flags %x.\\n\",\n\t\t map->name, map->sec_idx, map->sec_offset, def->map_flags);\n\n\tmmap_sz = bpf_map_mmap_sz(map->def.value_size, map->def.max_entries);\n\tmap->mmaped = mmap(NULL, mmap_sz, PROT_READ | PROT_WRITE,\n\t\t\t   MAP_SHARED | MAP_ANONYMOUS, -1, 0);\n\tif (map->mmaped == MAP_FAILED) {\n\t\terr = -errno;\n\t\tmap->mmaped = NULL;\n\t\tpr_warn(\"failed to alloc map '%s' content buffer: %d\\n\",\n\t\t\tmap->name, err);\n\t\tzfree(&map->real_name);\n\t\tzfree(&map->name);\n\t\treturn err;\n\t}\n\n\tif (data)\n\t\tmemcpy(map->mmaped, data, data_sz);\n\n\tpr_debug(\"map %td is \\\"%s\\\"\\n\", map - obj->maps, map->name);\n\treturn 0;\n}\n\nstatic int bpf_object__init_global_data_maps(struct bpf_object *obj)\n{\n\tstruct elf_sec_desc *sec_desc;\n\tconst char *sec_name;\n\tint err = 0, sec_idx;\n\n\t \n\tfor (sec_idx = 1; sec_idx < obj->efile.sec_cnt; sec_idx++) {\n\t\tsec_desc = &obj->efile.secs[sec_idx];\n\n\t\t \n\t\tif (!sec_desc->data || sec_desc->data->d_size == 0)\n\t\t\tcontinue;\n\n\t\tswitch (sec_desc->sec_type) {\n\t\tcase SEC_DATA:\n\t\t\tsec_name = elf_sec_name(obj, elf_sec_by_idx(obj, sec_idx));\n\t\t\terr = bpf_object__init_internal_map(obj, LIBBPF_MAP_DATA,\n\t\t\t\t\t\t\t    sec_name, sec_idx,\n\t\t\t\t\t\t\t    sec_desc->data->d_buf,\n\t\t\t\t\t\t\t    sec_desc->data->d_size);\n\t\t\tbreak;\n\t\tcase SEC_RODATA:\n\t\t\tobj->has_rodata = true;\n\t\t\tsec_name = elf_sec_name(obj, elf_sec_by_idx(obj, sec_idx));\n\t\t\terr = bpf_object__init_internal_map(obj, LIBBPF_MAP_RODATA,\n\t\t\t\t\t\t\t    sec_name, sec_idx,\n\t\t\t\t\t\t\t    sec_desc->data->d_buf,\n\t\t\t\t\t\t\t    sec_desc->data->d_size);\n\t\t\tbreak;\n\t\tcase SEC_BSS:\n\t\t\tsec_name = elf_sec_name(obj, elf_sec_by_idx(obj, sec_idx));\n\t\t\terr = bpf_object__init_internal_map(obj, LIBBPF_MAP_BSS,\n\t\t\t\t\t\t\t    sec_name, sec_idx,\n\t\t\t\t\t\t\t    NULL,\n\t\t\t\t\t\t\t    sec_desc->data->d_size);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}\n\n\nstatic struct extern_desc *find_extern_by_name(const struct bpf_object *obj,\n\t\t\t\t\t       const void *name)\n{\n\tint i;\n\n\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\tif (strcmp(obj->externs[i].name, name) == 0)\n\t\t\treturn &obj->externs[i];\n\t}\n\treturn NULL;\n}\n\nstatic int set_kcfg_value_tri(struct extern_desc *ext, void *ext_val,\n\t\t\t      char value)\n{\n\tswitch (ext->kcfg.type) {\n\tcase KCFG_BOOL:\n\t\tif (value == 'm') {\n\t\t\tpr_warn(\"extern (kcfg) '%s': value '%c' implies tristate or char type\\n\",\n\t\t\t\text->name, value);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*(bool *)ext_val = value == 'y' ? true : false;\n\t\tbreak;\n\tcase KCFG_TRISTATE:\n\t\tif (value == 'y')\n\t\t\t*(enum libbpf_tristate *)ext_val = TRI_YES;\n\t\telse if (value == 'm')\n\t\t\t*(enum libbpf_tristate *)ext_val = TRI_MODULE;\n\t\telse  \n\t\t\t*(enum libbpf_tristate *)ext_val = TRI_NO;\n\t\tbreak;\n\tcase KCFG_CHAR:\n\t\t*(char *)ext_val = value;\n\t\tbreak;\n\tcase KCFG_UNKNOWN:\n\tcase KCFG_INT:\n\tcase KCFG_CHAR_ARR:\n\tdefault:\n\t\tpr_warn(\"extern (kcfg) '%s': value '%c' implies bool, tristate, or char type\\n\",\n\t\t\text->name, value);\n\t\treturn -EINVAL;\n\t}\n\text->is_set = true;\n\treturn 0;\n}\n\nstatic int set_kcfg_value_str(struct extern_desc *ext, char *ext_val,\n\t\t\t      const char *value)\n{\n\tsize_t len;\n\n\tif (ext->kcfg.type != KCFG_CHAR_ARR) {\n\t\tpr_warn(\"extern (kcfg) '%s': value '%s' implies char array type\\n\",\n\t\t\text->name, value);\n\t\treturn -EINVAL;\n\t}\n\n\tlen = strlen(value);\n\tif (value[len - 1] != '\"') {\n\t\tpr_warn(\"extern (kcfg) '%s': invalid string config '%s'\\n\",\n\t\t\text->name, value);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tlen -= 2;\n\tif (len >= ext->kcfg.sz) {\n\t\tpr_warn(\"extern (kcfg) '%s': long string '%s' of (%zu bytes) truncated to %d bytes\\n\",\n\t\t\text->name, value, len, ext->kcfg.sz - 1);\n\t\tlen = ext->kcfg.sz - 1;\n\t}\n\tmemcpy(ext_val, value + 1, len);\n\text_val[len] = '\\0';\n\text->is_set = true;\n\treturn 0;\n}\n\nstatic int parse_u64(const char *value, __u64 *res)\n{\n\tchar *value_end;\n\tint err;\n\n\terrno = 0;\n\t*res = strtoull(value, &value_end, 0);\n\tif (errno) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to parse '%s' as integer: %d\\n\", value, err);\n\t\treturn err;\n\t}\n\tif (*value_end) {\n\t\tpr_warn(\"failed to parse '%s' as integer completely\\n\", value);\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic bool is_kcfg_value_in_range(const struct extern_desc *ext, __u64 v)\n{\n\tint bit_sz = ext->kcfg.sz * 8;\n\n\tif (ext->kcfg.sz == 8)\n\t\treturn true;\n\n\t \n\tif (ext->kcfg.is_signed)\n\t\treturn v + (1ULL << (bit_sz - 1)) < (1ULL << bit_sz);\n\telse\n\t\treturn (v >> bit_sz) == 0;\n}\n\nstatic int set_kcfg_value_num(struct extern_desc *ext, void *ext_val,\n\t\t\t      __u64 value)\n{\n\tif (ext->kcfg.type != KCFG_INT && ext->kcfg.type != KCFG_CHAR &&\n\t    ext->kcfg.type != KCFG_BOOL) {\n\t\tpr_warn(\"extern (kcfg) '%s': value '%llu' implies integer, char, or boolean type\\n\",\n\t\t\text->name, (unsigned long long)value);\n\t\treturn -EINVAL;\n\t}\n\tif (ext->kcfg.type == KCFG_BOOL && value > 1) {\n\t\tpr_warn(\"extern (kcfg) '%s': value '%llu' isn't boolean compatible\\n\",\n\t\t\text->name, (unsigned long long)value);\n\t\treturn -EINVAL;\n\n\t}\n\tif (!is_kcfg_value_in_range(ext, value)) {\n\t\tpr_warn(\"extern (kcfg) '%s': value '%llu' doesn't fit in %d bytes\\n\",\n\t\t\text->name, (unsigned long long)value, ext->kcfg.sz);\n\t\treturn -ERANGE;\n\t}\n\tswitch (ext->kcfg.sz) {\n\tcase 1:\n\t\t*(__u8 *)ext_val = value;\n\t\tbreak;\n\tcase 2:\n\t\t*(__u16 *)ext_val = value;\n\t\tbreak;\n\tcase 4:\n\t\t*(__u32 *)ext_val = value;\n\t\tbreak;\n\tcase 8:\n\t\t*(__u64 *)ext_val = value;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\text->is_set = true;\n\treturn 0;\n}\n\nstatic int bpf_object__process_kconfig_line(struct bpf_object *obj,\n\t\t\t\t\t    char *buf, void *data)\n{\n\tstruct extern_desc *ext;\n\tchar *sep, *value;\n\tint len, err = 0;\n\tvoid *ext_val;\n\t__u64 num;\n\n\tif (!str_has_pfx(buf, \"CONFIG_\"))\n\t\treturn 0;\n\n\tsep = strchr(buf, '=');\n\tif (!sep) {\n\t\tpr_warn(\"failed to parse '%s': no separator\\n\", buf);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tlen = strlen(buf);\n\tif (buf[len - 1] == '\\n')\n\t\tbuf[len - 1] = '\\0';\n\t \n\t*sep = '\\0';\n\tif (!sep[1]) {\n\t\t*sep = '=';\n\t\tpr_warn(\"failed to parse '%s': no value\\n\", buf);\n\t\treturn -EINVAL;\n\t}\n\n\text = find_extern_by_name(obj, buf);\n\tif (!ext || ext->is_set)\n\t\treturn 0;\n\n\text_val = data + ext->kcfg.data_off;\n\tvalue = sep + 1;\n\n\tswitch (*value) {\n\tcase 'y': case 'n': case 'm':\n\t\terr = set_kcfg_value_tri(ext, ext_val, *value);\n\t\tbreak;\n\tcase '\"':\n\t\terr = set_kcfg_value_str(ext, ext_val, value);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\terr = parse_u64(value, &num);\n\t\tif (err) {\n\t\t\tpr_warn(\"extern (kcfg) '%s': value '%s' isn't a valid integer\\n\", ext->name, value);\n\t\t\treturn err;\n\t\t}\n\t\tif (ext->kcfg.type != KCFG_INT && ext->kcfg.type != KCFG_CHAR) {\n\t\t\tpr_warn(\"extern (kcfg) '%s': value '%s' implies integer type\\n\", ext->name, value);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\terr = set_kcfg_value_num(ext, ext_val, num);\n\t\tbreak;\n\t}\n\tif (err)\n\t\treturn err;\n\tpr_debug(\"extern (kcfg) '%s': set to %s\\n\", ext->name, value);\n\treturn 0;\n}\n\nstatic int bpf_object__read_kconfig_file(struct bpf_object *obj, void *data)\n{\n\tchar buf[PATH_MAX];\n\tstruct utsname uts;\n\tint len, err = 0;\n\tgzFile file;\n\n\tuname(&uts);\n\tlen = snprintf(buf, PATH_MAX, \"/boot/config-%s\", uts.release);\n\tif (len < 0)\n\t\treturn -EINVAL;\n\telse if (len >= PATH_MAX)\n\t\treturn -ENAMETOOLONG;\n\n\t \n\tfile = gzopen(buf, \"re\");\n\tif (!file)\n\t\tfile = gzopen(\"/proc/config.gz\", \"re\");\n\n\tif (!file) {\n\t\tpr_warn(\"failed to open system Kconfig\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\twhile (gzgets(file, buf, sizeof(buf))) {\n\t\terr = bpf_object__process_kconfig_line(obj, buf, data);\n\t\tif (err) {\n\t\t\tpr_warn(\"error parsing system Kconfig line '%s': %d\\n\",\n\t\t\t\tbuf, err);\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tgzclose(file);\n\treturn err;\n}\n\nstatic int bpf_object__read_kconfig_mem(struct bpf_object *obj,\n\t\t\t\t\tconst char *config, void *data)\n{\n\tchar buf[PATH_MAX];\n\tint err = 0;\n\tFILE *file;\n\n\tfile = fmemopen((void *)config, strlen(config), \"r\");\n\tif (!file) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to open in-memory Kconfig: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\twhile (fgets(buf, sizeof(buf), file)) {\n\t\terr = bpf_object__process_kconfig_line(obj, buf, data);\n\t\tif (err) {\n\t\t\tpr_warn(\"error parsing in-memory Kconfig line '%s': %d\\n\",\n\t\t\t\tbuf, err);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfclose(file);\n\treturn err;\n}\n\nstatic int bpf_object__init_kconfig_map(struct bpf_object *obj)\n{\n\tstruct extern_desc *last_ext = NULL, *ext;\n\tsize_t map_sz;\n\tint i, err;\n\n\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\text = &obj->externs[i];\n\t\tif (ext->type == EXT_KCFG)\n\t\t\tlast_ext = ext;\n\t}\n\n\tif (!last_ext)\n\t\treturn 0;\n\n\tmap_sz = last_ext->kcfg.data_off + last_ext->kcfg.sz;\n\terr = bpf_object__init_internal_map(obj, LIBBPF_MAP_KCONFIG,\n\t\t\t\t\t    \".kconfig\", obj->efile.symbols_shndx,\n\t\t\t\t\t    NULL, map_sz);\n\tif (err)\n\t\treturn err;\n\n\tobj->kconfig_map_idx = obj->nr_maps - 1;\n\n\treturn 0;\n}\n\nconst struct btf_type *\nskip_mods_and_typedefs(const struct btf *btf, __u32 id, __u32 *res_id)\n{\n\tconst struct btf_type *t = btf__type_by_id(btf, id);\n\n\tif (res_id)\n\t\t*res_id = id;\n\n\twhile (btf_is_mod(t) || btf_is_typedef(t)) {\n\t\tif (res_id)\n\t\t\t*res_id = t->type;\n\t\tt = btf__type_by_id(btf, t->type);\n\t}\n\n\treturn t;\n}\n\nstatic const struct btf_type *\nresolve_func_ptr(const struct btf *btf, __u32 id, __u32 *res_id)\n{\n\tconst struct btf_type *t;\n\n\tt = skip_mods_and_typedefs(btf, id, NULL);\n\tif (!btf_is_ptr(t))\n\t\treturn NULL;\n\n\tt = skip_mods_and_typedefs(btf, t->type, res_id);\n\n\treturn btf_is_func_proto(t) ? t : NULL;\n}\n\nstatic const char *__btf_kind_str(__u16 kind)\n{\n\tswitch (kind) {\n\tcase BTF_KIND_UNKN: return \"void\";\n\tcase BTF_KIND_INT: return \"int\";\n\tcase BTF_KIND_PTR: return \"ptr\";\n\tcase BTF_KIND_ARRAY: return \"array\";\n\tcase BTF_KIND_STRUCT: return \"struct\";\n\tcase BTF_KIND_UNION: return \"union\";\n\tcase BTF_KIND_ENUM: return \"enum\";\n\tcase BTF_KIND_FWD: return \"fwd\";\n\tcase BTF_KIND_TYPEDEF: return \"typedef\";\n\tcase BTF_KIND_VOLATILE: return \"volatile\";\n\tcase BTF_KIND_CONST: return \"const\";\n\tcase BTF_KIND_RESTRICT: return \"restrict\";\n\tcase BTF_KIND_FUNC: return \"func\";\n\tcase BTF_KIND_FUNC_PROTO: return \"func_proto\";\n\tcase BTF_KIND_VAR: return \"var\";\n\tcase BTF_KIND_DATASEC: return \"datasec\";\n\tcase BTF_KIND_FLOAT: return \"float\";\n\tcase BTF_KIND_DECL_TAG: return \"decl_tag\";\n\tcase BTF_KIND_TYPE_TAG: return \"type_tag\";\n\tcase BTF_KIND_ENUM64: return \"enum64\";\n\tdefault: return \"unknown\";\n\t}\n}\n\nconst char *btf_kind_str(const struct btf_type *t)\n{\n\treturn __btf_kind_str(btf_kind(t));\n}\n\n \nstatic bool get_map_field_int(const char *map_name, const struct btf *btf,\n\t\t\t      const struct btf_member *m, __u32 *res)\n{\n\tconst struct btf_type *t = skip_mods_and_typedefs(btf, m->type, NULL);\n\tconst char *name = btf__name_by_offset(btf, m->name_off);\n\tconst struct btf_array *arr_info;\n\tconst struct btf_type *arr_t;\n\n\tif (!btf_is_ptr(t)) {\n\t\tpr_warn(\"map '%s': attr '%s': expected PTR, got %s.\\n\",\n\t\t\tmap_name, name, btf_kind_str(t));\n\t\treturn false;\n\t}\n\n\tarr_t = btf__type_by_id(btf, t->type);\n\tif (!arr_t) {\n\t\tpr_warn(\"map '%s': attr '%s': type [%u] not found.\\n\",\n\t\t\tmap_name, name, t->type);\n\t\treturn false;\n\t}\n\tif (!btf_is_array(arr_t)) {\n\t\tpr_warn(\"map '%s': attr '%s': expected ARRAY, got %s.\\n\",\n\t\t\tmap_name, name, btf_kind_str(arr_t));\n\t\treturn false;\n\t}\n\tarr_info = btf_array(arr_t);\n\t*res = arr_info->nelems;\n\treturn true;\n}\n\nstatic int pathname_concat(char *buf, size_t buf_sz, const char *path, const char *name)\n{\n\tint len;\n\n\tlen = snprintf(buf, buf_sz, \"%s/%s\", path, name);\n\tif (len < 0)\n\t\treturn -EINVAL;\n\tif (len >= buf_sz)\n\t\treturn -ENAMETOOLONG;\n\n\treturn 0;\n}\n\nstatic int build_map_pin_path(struct bpf_map *map, const char *path)\n{\n\tchar buf[PATH_MAX];\n\tint err;\n\n\tif (!path)\n\t\tpath = \"/sys/fs/bpf\";\n\n\terr = pathname_concat(buf, sizeof(buf), path, bpf_map__name(map));\n\tif (err)\n\t\treturn err;\n\n\treturn bpf_map__set_pin_path(map, buf);\n}\n\n \nenum libbpf_pin_type {\n\tLIBBPF_PIN_NONE,\n\t \n\tLIBBPF_PIN_BY_NAME,\n};\n\nint parse_btf_map_def(const char *map_name, struct btf *btf,\n\t\t      const struct btf_type *def_t, bool strict,\n\t\t      struct btf_map_def *map_def, struct btf_map_def *inner_def)\n{\n\tconst struct btf_type *t;\n\tconst struct btf_member *m;\n\tbool is_inner = inner_def == NULL;\n\tint vlen, i;\n\n\tvlen = btf_vlen(def_t);\n\tm = btf_members(def_t);\n\tfor (i = 0; i < vlen; i++, m++) {\n\t\tconst char *name = btf__name_by_offset(btf, m->name_off);\n\n\t\tif (!name) {\n\t\t\tpr_warn(\"map '%s': invalid field #%d.\\n\", map_name, i);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (strcmp(name, \"type\") == 0) {\n\t\t\tif (!get_map_field_int(map_name, btf, m, &map_def->map_type))\n\t\t\t\treturn -EINVAL;\n\t\t\tmap_def->parts |= MAP_DEF_MAP_TYPE;\n\t\t} else if (strcmp(name, \"max_entries\") == 0) {\n\t\t\tif (!get_map_field_int(map_name, btf, m, &map_def->max_entries))\n\t\t\t\treturn -EINVAL;\n\t\t\tmap_def->parts |= MAP_DEF_MAX_ENTRIES;\n\t\t} else if (strcmp(name, \"map_flags\") == 0) {\n\t\t\tif (!get_map_field_int(map_name, btf, m, &map_def->map_flags))\n\t\t\t\treturn -EINVAL;\n\t\t\tmap_def->parts |= MAP_DEF_MAP_FLAGS;\n\t\t} else if (strcmp(name, \"numa_node\") == 0) {\n\t\t\tif (!get_map_field_int(map_name, btf, m, &map_def->numa_node))\n\t\t\t\treturn -EINVAL;\n\t\t\tmap_def->parts |= MAP_DEF_NUMA_NODE;\n\t\t} else if (strcmp(name, \"key_size\") == 0) {\n\t\t\t__u32 sz;\n\n\t\t\tif (!get_map_field_int(map_name, btf, m, &sz))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (map_def->key_size && map_def->key_size != sz) {\n\t\t\t\tpr_warn(\"map '%s': conflicting key size %u != %u.\\n\",\n\t\t\t\t\tmap_name, map_def->key_size, sz);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmap_def->key_size = sz;\n\t\t\tmap_def->parts |= MAP_DEF_KEY_SIZE;\n\t\t} else if (strcmp(name, \"key\") == 0) {\n\t\t\t__s64 sz;\n\n\t\t\tt = btf__type_by_id(btf, m->type);\n\t\t\tif (!t) {\n\t\t\t\tpr_warn(\"map '%s': key type [%d] not found.\\n\",\n\t\t\t\t\tmap_name, m->type);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (!btf_is_ptr(t)) {\n\t\t\t\tpr_warn(\"map '%s': key spec is not PTR: %s.\\n\",\n\t\t\t\t\tmap_name, btf_kind_str(t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tsz = btf__resolve_size(btf, t->type);\n\t\t\tif (sz < 0) {\n\t\t\t\tpr_warn(\"map '%s': can't determine key size for type [%u]: %zd.\\n\",\n\t\t\t\t\tmap_name, t->type, (ssize_t)sz);\n\t\t\t\treturn sz;\n\t\t\t}\n\t\t\tif (map_def->key_size && map_def->key_size != sz) {\n\t\t\t\tpr_warn(\"map '%s': conflicting key size %u != %zd.\\n\",\n\t\t\t\t\tmap_name, map_def->key_size, (ssize_t)sz);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmap_def->key_size = sz;\n\t\t\tmap_def->key_type_id = t->type;\n\t\t\tmap_def->parts |= MAP_DEF_KEY_SIZE | MAP_DEF_KEY_TYPE;\n\t\t} else if (strcmp(name, \"value_size\") == 0) {\n\t\t\t__u32 sz;\n\n\t\t\tif (!get_map_field_int(map_name, btf, m, &sz))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (map_def->value_size && map_def->value_size != sz) {\n\t\t\t\tpr_warn(\"map '%s': conflicting value size %u != %u.\\n\",\n\t\t\t\t\tmap_name, map_def->value_size, sz);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmap_def->value_size = sz;\n\t\t\tmap_def->parts |= MAP_DEF_VALUE_SIZE;\n\t\t} else if (strcmp(name, \"value\") == 0) {\n\t\t\t__s64 sz;\n\n\t\t\tt = btf__type_by_id(btf, m->type);\n\t\t\tif (!t) {\n\t\t\t\tpr_warn(\"map '%s': value type [%d] not found.\\n\",\n\t\t\t\t\tmap_name, m->type);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (!btf_is_ptr(t)) {\n\t\t\t\tpr_warn(\"map '%s': value spec is not PTR: %s.\\n\",\n\t\t\t\t\tmap_name, btf_kind_str(t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tsz = btf__resolve_size(btf, t->type);\n\t\t\tif (sz < 0) {\n\t\t\t\tpr_warn(\"map '%s': can't determine value size for type [%u]: %zd.\\n\",\n\t\t\t\t\tmap_name, t->type, (ssize_t)sz);\n\t\t\t\treturn sz;\n\t\t\t}\n\t\t\tif (map_def->value_size && map_def->value_size != sz) {\n\t\t\t\tpr_warn(\"map '%s': conflicting value size %u != %zd.\\n\",\n\t\t\t\t\tmap_name, map_def->value_size, (ssize_t)sz);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmap_def->value_size = sz;\n\t\t\tmap_def->value_type_id = t->type;\n\t\t\tmap_def->parts |= MAP_DEF_VALUE_SIZE | MAP_DEF_VALUE_TYPE;\n\t\t}\n\t\telse if (strcmp(name, \"values\") == 0) {\n\t\t\tbool is_map_in_map = bpf_map_type__is_map_in_map(map_def->map_type);\n\t\t\tbool is_prog_array = map_def->map_type == BPF_MAP_TYPE_PROG_ARRAY;\n\t\t\tconst char *desc = is_map_in_map ? \"map-in-map inner\" : \"prog-array value\";\n\t\t\tchar inner_map_name[128];\n\t\t\tint err;\n\n\t\t\tif (is_inner) {\n\t\t\t\tpr_warn(\"map '%s': multi-level inner maps not supported.\\n\",\n\t\t\t\t\tmap_name);\n\t\t\t\treturn -ENOTSUP;\n\t\t\t}\n\t\t\tif (i != vlen - 1) {\n\t\t\t\tpr_warn(\"map '%s': '%s' member should be last.\\n\",\n\t\t\t\t\tmap_name, name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (!is_map_in_map && !is_prog_array) {\n\t\t\t\tpr_warn(\"map '%s': should be map-in-map or prog-array.\\n\",\n\t\t\t\t\tmap_name);\n\t\t\t\treturn -ENOTSUP;\n\t\t\t}\n\t\t\tif (map_def->value_size && map_def->value_size != 4) {\n\t\t\t\tpr_warn(\"map '%s': conflicting value size %u != 4.\\n\",\n\t\t\t\t\tmap_name, map_def->value_size);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmap_def->value_size = 4;\n\t\t\tt = btf__type_by_id(btf, m->type);\n\t\t\tif (!t) {\n\t\t\t\tpr_warn(\"map '%s': %s type [%d] not found.\\n\",\n\t\t\t\t\tmap_name, desc, m->type);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (!btf_is_array(t) || btf_array(t)->nelems) {\n\t\t\t\tpr_warn(\"map '%s': %s spec is not a zero-sized array.\\n\",\n\t\t\t\t\tmap_name, desc);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tt = skip_mods_and_typedefs(btf, btf_array(t)->type, NULL);\n\t\t\tif (!btf_is_ptr(t)) {\n\t\t\t\tpr_warn(\"map '%s': %s def is of unexpected kind %s.\\n\",\n\t\t\t\t\tmap_name, desc, btf_kind_str(t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tt = skip_mods_and_typedefs(btf, t->type, NULL);\n\t\t\tif (is_prog_array) {\n\t\t\t\tif (!btf_is_func_proto(t)) {\n\t\t\t\t\tpr_warn(\"map '%s': prog-array value def is of unexpected kind %s.\\n\",\n\t\t\t\t\t\tmap_name, btf_kind_str(t));\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!btf_is_struct(t)) {\n\t\t\t\tpr_warn(\"map '%s': map-in-map inner def is of unexpected kind %s.\\n\",\n\t\t\t\t\tmap_name, btf_kind_str(t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tsnprintf(inner_map_name, sizeof(inner_map_name), \"%s.inner\", map_name);\n\t\t\terr = parse_btf_map_def(inner_map_name, btf, t, strict, inner_def, NULL);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\tmap_def->parts |= MAP_DEF_INNER_MAP;\n\t\t} else if (strcmp(name, \"pinning\") == 0) {\n\t\t\t__u32 val;\n\n\t\t\tif (is_inner) {\n\t\t\t\tpr_warn(\"map '%s': inner def can't be pinned.\\n\", map_name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (!get_map_field_int(map_name, btf, m, &val))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (val != LIBBPF_PIN_NONE && val != LIBBPF_PIN_BY_NAME) {\n\t\t\t\tpr_warn(\"map '%s': invalid pinning value %u.\\n\",\n\t\t\t\t\tmap_name, val);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tmap_def->pinning = val;\n\t\t\tmap_def->parts |= MAP_DEF_PINNING;\n\t\t} else if (strcmp(name, \"map_extra\") == 0) {\n\t\t\t__u32 map_extra;\n\n\t\t\tif (!get_map_field_int(map_name, btf, m, &map_extra))\n\t\t\t\treturn -EINVAL;\n\t\t\tmap_def->map_extra = map_extra;\n\t\t\tmap_def->parts |= MAP_DEF_MAP_EXTRA;\n\t\t} else {\n\t\t\tif (strict) {\n\t\t\t\tpr_warn(\"map '%s': unknown field '%s'.\\n\", map_name, name);\n\t\t\t\treturn -ENOTSUP;\n\t\t\t}\n\t\t\tpr_debug(\"map '%s': ignoring unknown field '%s'.\\n\", map_name, name);\n\t\t}\n\t}\n\n\tif (map_def->map_type == BPF_MAP_TYPE_UNSPEC) {\n\t\tpr_warn(\"map '%s': map type isn't specified.\\n\", map_name);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic size_t adjust_ringbuf_sz(size_t sz)\n{\n\t__u32 page_sz = sysconf(_SC_PAGE_SIZE);\n\t__u32 mul;\n\n\t \n\tif (sz == 0)\n\t\treturn 0;\n\t \n\tif ((sz % page_sz) == 0 && is_pow_of_2(sz / page_sz))\n\t\treturn sz;\n\n\t \n\tfor (mul = 1; mul <= UINT_MAX / page_sz; mul <<= 1) {\n\t\tif (mul * page_sz > sz)\n\t\t\treturn mul * page_sz;\n\t}\n\n\t \n\treturn sz;\n}\n\nstatic bool map_is_ringbuf(const struct bpf_map *map)\n{\n\treturn map->def.type == BPF_MAP_TYPE_RINGBUF ||\n\t       map->def.type == BPF_MAP_TYPE_USER_RINGBUF;\n}\n\nstatic void fill_map_from_def(struct bpf_map *map, const struct btf_map_def *def)\n{\n\tmap->def.type = def->map_type;\n\tmap->def.key_size = def->key_size;\n\tmap->def.value_size = def->value_size;\n\tmap->def.max_entries = def->max_entries;\n\tmap->def.map_flags = def->map_flags;\n\tmap->map_extra = def->map_extra;\n\n\tmap->numa_node = def->numa_node;\n\tmap->btf_key_type_id = def->key_type_id;\n\tmap->btf_value_type_id = def->value_type_id;\n\n\t \n\tif (map_is_ringbuf(map))\n\t\tmap->def.max_entries = adjust_ringbuf_sz(map->def.max_entries);\n\n\tif (def->parts & MAP_DEF_MAP_TYPE)\n\t\tpr_debug(\"map '%s': found type = %u.\\n\", map->name, def->map_type);\n\n\tif (def->parts & MAP_DEF_KEY_TYPE)\n\t\tpr_debug(\"map '%s': found key [%u], sz = %u.\\n\",\n\t\t\t map->name, def->key_type_id, def->key_size);\n\telse if (def->parts & MAP_DEF_KEY_SIZE)\n\t\tpr_debug(\"map '%s': found key_size = %u.\\n\", map->name, def->key_size);\n\n\tif (def->parts & MAP_DEF_VALUE_TYPE)\n\t\tpr_debug(\"map '%s': found value [%u], sz = %u.\\n\",\n\t\t\t map->name, def->value_type_id, def->value_size);\n\telse if (def->parts & MAP_DEF_VALUE_SIZE)\n\t\tpr_debug(\"map '%s': found value_size = %u.\\n\", map->name, def->value_size);\n\n\tif (def->parts & MAP_DEF_MAX_ENTRIES)\n\t\tpr_debug(\"map '%s': found max_entries = %u.\\n\", map->name, def->max_entries);\n\tif (def->parts & MAP_DEF_MAP_FLAGS)\n\t\tpr_debug(\"map '%s': found map_flags = 0x%x.\\n\", map->name, def->map_flags);\n\tif (def->parts & MAP_DEF_MAP_EXTRA)\n\t\tpr_debug(\"map '%s': found map_extra = 0x%llx.\\n\", map->name,\n\t\t\t (unsigned long long)def->map_extra);\n\tif (def->parts & MAP_DEF_PINNING)\n\t\tpr_debug(\"map '%s': found pinning = %u.\\n\", map->name, def->pinning);\n\tif (def->parts & MAP_DEF_NUMA_NODE)\n\t\tpr_debug(\"map '%s': found numa_node = %u.\\n\", map->name, def->numa_node);\n\n\tif (def->parts & MAP_DEF_INNER_MAP)\n\t\tpr_debug(\"map '%s': found inner map definition.\\n\", map->name);\n}\n\nstatic const char *btf_var_linkage_str(__u32 linkage)\n{\n\tswitch (linkage) {\n\tcase BTF_VAR_STATIC: return \"static\";\n\tcase BTF_VAR_GLOBAL_ALLOCATED: return \"global\";\n\tcase BTF_VAR_GLOBAL_EXTERN: return \"extern\";\n\tdefault: return \"unknown\";\n\t}\n}\n\nstatic int bpf_object__init_user_btf_map(struct bpf_object *obj,\n\t\t\t\t\t const struct btf_type *sec,\n\t\t\t\t\t int var_idx, int sec_idx,\n\t\t\t\t\t const Elf_Data *data, bool strict,\n\t\t\t\t\t const char *pin_root_path)\n{\n\tstruct btf_map_def map_def = {}, inner_def = {};\n\tconst struct btf_type *var, *def;\n\tconst struct btf_var_secinfo *vi;\n\tconst struct btf_var *var_extra;\n\tconst char *map_name;\n\tstruct bpf_map *map;\n\tint err;\n\n\tvi = btf_var_secinfos(sec) + var_idx;\n\tvar = btf__type_by_id(obj->btf, vi->type);\n\tvar_extra = btf_var(var);\n\tmap_name = btf__name_by_offset(obj->btf, var->name_off);\n\n\tif (map_name == NULL || map_name[0] == '\\0') {\n\t\tpr_warn(\"map #%d: empty name.\\n\", var_idx);\n\t\treturn -EINVAL;\n\t}\n\tif ((__u64)vi->offset + vi->size > data->d_size) {\n\t\tpr_warn(\"map '%s' BTF data is corrupted.\\n\", map_name);\n\t\treturn -EINVAL;\n\t}\n\tif (!btf_is_var(var)) {\n\t\tpr_warn(\"map '%s': unexpected var kind %s.\\n\",\n\t\t\tmap_name, btf_kind_str(var));\n\t\treturn -EINVAL;\n\t}\n\tif (var_extra->linkage != BTF_VAR_GLOBAL_ALLOCATED) {\n\t\tpr_warn(\"map '%s': unsupported map linkage %s.\\n\",\n\t\t\tmap_name, btf_var_linkage_str(var_extra->linkage));\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tdef = skip_mods_and_typedefs(obj->btf, var->type, NULL);\n\tif (!btf_is_struct(def)) {\n\t\tpr_warn(\"map '%s': unexpected def kind %s.\\n\",\n\t\t\tmap_name, btf_kind_str(var));\n\t\treturn -EINVAL;\n\t}\n\tif (def->size > vi->size) {\n\t\tpr_warn(\"map '%s': invalid def size.\\n\", map_name);\n\t\treturn -EINVAL;\n\t}\n\n\tmap = bpf_object__add_map(obj);\n\tif (IS_ERR(map))\n\t\treturn PTR_ERR(map);\n\tmap->name = strdup(map_name);\n\tif (!map->name) {\n\t\tpr_warn(\"map '%s': failed to alloc map name.\\n\", map_name);\n\t\treturn -ENOMEM;\n\t}\n\tmap->libbpf_type = LIBBPF_MAP_UNSPEC;\n\tmap->def.type = BPF_MAP_TYPE_UNSPEC;\n\tmap->sec_idx = sec_idx;\n\tmap->sec_offset = vi->offset;\n\tmap->btf_var_idx = var_idx;\n\tpr_debug(\"map '%s': at sec_idx %d, offset %zu.\\n\",\n\t\t map_name, map->sec_idx, map->sec_offset);\n\n\terr = parse_btf_map_def(map->name, obj->btf, def, strict, &map_def, &inner_def);\n\tif (err)\n\t\treturn err;\n\n\tfill_map_from_def(map, &map_def);\n\n\tif (map_def.pinning == LIBBPF_PIN_BY_NAME) {\n\t\terr = build_map_pin_path(map, pin_root_path);\n\t\tif (err) {\n\t\t\tpr_warn(\"map '%s': couldn't build pin path.\\n\", map->name);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (map_def.parts & MAP_DEF_INNER_MAP) {\n\t\tmap->inner_map = calloc(1, sizeof(*map->inner_map));\n\t\tif (!map->inner_map)\n\t\t\treturn -ENOMEM;\n\t\tmap->inner_map->fd = -1;\n\t\tmap->inner_map->sec_idx = sec_idx;\n\t\tmap->inner_map->name = malloc(strlen(map_name) + sizeof(\".inner\") + 1);\n\t\tif (!map->inner_map->name)\n\t\t\treturn -ENOMEM;\n\t\tsprintf(map->inner_map->name, \"%s.inner\", map_name);\n\n\t\tfill_map_from_def(map->inner_map, &inner_def);\n\t}\n\n\terr = map_fill_btf_type_info(obj, map);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nstatic int bpf_object__init_user_btf_maps(struct bpf_object *obj, bool strict,\n\t\t\t\t\t  const char *pin_root_path)\n{\n\tconst struct btf_type *sec = NULL;\n\tint nr_types, i, vlen, err;\n\tconst struct btf_type *t;\n\tconst char *name;\n\tElf_Data *data;\n\tElf_Scn *scn;\n\n\tif (obj->efile.btf_maps_shndx < 0)\n\t\treturn 0;\n\n\tscn = elf_sec_by_idx(obj, obj->efile.btf_maps_shndx);\n\tdata = elf_sec_data(obj, scn);\n\tif (!scn || !data) {\n\t\tpr_warn(\"elf: failed to get %s map definitions for %s\\n\",\n\t\t\tMAPS_ELF_SEC, obj->path);\n\t\treturn -EINVAL;\n\t}\n\n\tnr_types = btf__type_cnt(obj->btf);\n\tfor (i = 1; i < nr_types; i++) {\n\t\tt = btf__type_by_id(obj->btf, i);\n\t\tif (!btf_is_datasec(t))\n\t\t\tcontinue;\n\t\tname = btf__name_by_offset(obj->btf, t->name_off);\n\t\tif (strcmp(name, MAPS_ELF_SEC) == 0) {\n\t\t\tsec = t;\n\t\t\tobj->efile.btf_maps_sec_btf_id = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!sec) {\n\t\tpr_warn(\"DATASEC '%s' not found.\\n\", MAPS_ELF_SEC);\n\t\treturn -ENOENT;\n\t}\n\n\tvlen = btf_vlen(sec);\n\tfor (i = 0; i < vlen; i++) {\n\t\terr = bpf_object__init_user_btf_map(obj, sec, i,\n\t\t\t\t\t\t    obj->efile.btf_maps_shndx,\n\t\t\t\t\t\t    data, strict,\n\t\t\t\t\t\t    pin_root_path);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int bpf_object__init_maps(struct bpf_object *obj,\n\t\t\t\t const struct bpf_object_open_opts *opts)\n{\n\tconst char *pin_root_path;\n\tbool strict;\n\tint err = 0;\n\n\tstrict = !OPTS_GET(opts, relaxed_maps, false);\n\tpin_root_path = OPTS_GET(opts, pin_root_path, NULL);\n\n\terr = bpf_object__init_user_btf_maps(obj, strict, pin_root_path);\n\terr = err ?: bpf_object__init_global_data_maps(obj);\n\terr = err ?: bpf_object__init_kconfig_map(obj);\n\terr = err ?: bpf_object_init_struct_ops(obj);\n\n\treturn err;\n}\n\nstatic bool section_have_execinstr(struct bpf_object *obj, int idx)\n{\n\tElf64_Shdr *sh;\n\n\tsh = elf_sec_hdr(obj, elf_sec_by_idx(obj, idx));\n\tif (!sh)\n\t\treturn false;\n\n\treturn sh->sh_flags & SHF_EXECINSTR;\n}\n\nstatic bool btf_needs_sanitization(struct bpf_object *obj)\n{\n\tbool has_func_global = kernel_supports(obj, FEAT_BTF_GLOBAL_FUNC);\n\tbool has_datasec = kernel_supports(obj, FEAT_BTF_DATASEC);\n\tbool has_float = kernel_supports(obj, FEAT_BTF_FLOAT);\n\tbool has_func = kernel_supports(obj, FEAT_BTF_FUNC);\n\tbool has_decl_tag = kernel_supports(obj, FEAT_BTF_DECL_TAG);\n\tbool has_type_tag = kernel_supports(obj, FEAT_BTF_TYPE_TAG);\n\tbool has_enum64 = kernel_supports(obj, FEAT_BTF_ENUM64);\n\n\treturn !has_func || !has_datasec || !has_func_global || !has_float ||\n\t       !has_decl_tag || !has_type_tag || !has_enum64;\n}\n\nstatic int bpf_object__sanitize_btf(struct bpf_object *obj, struct btf *btf)\n{\n\tbool has_func_global = kernel_supports(obj, FEAT_BTF_GLOBAL_FUNC);\n\tbool has_datasec = kernel_supports(obj, FEAT_BTF_DATASEC);\n\tbool has_float = kernel_supports(obj, FEAT_BTF_FLOAT);\n\tbool has_func = kernel_supports(obj, FEAT_BTF_FUNC);\n\tbool has_decl_tag = kernel_supports(obj, FEAT_BTF_DECL_TAG);\n\tbool has_type_tag = kernel_supports(obj, FEAT_BTF_TYPE_TAG);\n\tbool has_enum64 = kernel_supports(obj, FEAT_BTF_ENUM64);\n\tint enum64_placeholder_id = 0;\n\tstruct btf_type *t;\n\tint i, j, vlen;\n\n\tfor (i = 1; i < btf__type_cnt(btf); i++) {\n\t\tt = (struct btf_type *)btf__type_by_id(btf, i);\n\n\t\tif ((!has_datasec && btf_is_var(t)) || (!has_decl_tag && btf_is_decl_tag(t))) {\n\t\t\t \n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_INT, 0, 0);\n\t\t\t \n\t\t\tt->size = 1;\n\t\t\t*(int *)(t + 1) = BTF_INT_ENC(0, 0, 8);\n\t\t} else if (!has_datasec && btf_is_datasec(t)) {\n\t\t\t \n\t\t\tconst struct btf_var_secinfo *v = btf_var_secinfos(t);\n\t\t\tstruct btf_member *m = btf_members(t);\n\t\t\tstruct btf_type *vt;\n\t\t\tchar *name;\n\n\t\t\tname = (char *)btf__name_by_offset(btf, t->name_off);\n\t\t\twhile (*name) {\n\t\t\t\tif (*name == '.')\n\t\t\t\t\t*name = '_';\n\t\t\t\tname++;\n\t\t\t}\n\n\t\t\tvlen = btf_vlen(t);\n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_STRUCT, 0, vlen);\n\t\t\tfor (j = 0; j < vlen; j++, v++, m++) {\n\t\t\t\t \n\t\t\t\tm->offset = v->offset * 8;\n\t\t\t\tm->type = v->type;\n\t\t\t\t \n\t\t\t\tvt = (void *)btf__type_by_id(btf, v->type);\n\t\t\t\tm->name_off = vt->name_off;\n\t\t\t}\n\t\t} else if (!has_func && btf_is_func_proto(t)) {\n\t\t\t \n\t\t\tvlen = btf_vlen(t);\n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_ENUM, 0, vlen);\n\t\t\tt->size = sizeof(__u32);  \n\t\t} else if (!has_func && btf_is_func(t)) {\n\t\t\t \n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_TYPEDEF, 0, 0);\n\t\t} else if (!has_func_global && btf_is_func(t)) {\n\t\t\t \n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_FUNC, 0, 0);\n\t\t} else if (!has_float && btf_is_float(t)) {\n\t\t\t \n\t\t\tt->name_off = 0;\n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_STRUCT, 0, 0);\n\t\t} else if (!has_type_tag && btf_is_type_tag(t)) {\n\t\t\t \n\t\t\tt->name_off = 0;\n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_CONST, 0, 0);\n\t\t} else if (!has_enum64 && btf_is_enum(t)) {\n\t\t\t \n\t\t\tt->info = btf_type_info(btf_kind(t), btf_vlen(t), false);\n\t\t} else if (!has_enum64 && btf_is_enum64(t)) {\n\t\t\t \n\t\t\tstruct btf_member *m;\n\n\t\t\tif (enum64_placeholder_id == 0) {\n\t\t\t\tenum64_placeholder_id = btf__add_int(btf, \"enum64_placeholder\", 1, 0);\n\t\t\t\tif (enum64_placeholder_id < 0)\n\t\t\t\t\treturn enum64_placeholder_id;\n\n\t\t\t\tt = (struct btf_type *)btf__type_by_id(btf, i);\n\t\t\t}\n\n\t\t\tm = btf_members(t);\n\t\t\tvlen = btf_vlen(t);\n\t\t\tt->info = BTF_INFO_ENC(BTF_KIND_UNION, 0, vlen);\n\t\t\tfor (j = 0; j < vlen; j++, m++) {\n\t\t\t\tm->type = enum64_placeholder_id;\n\t\t\t\tm->offset = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic bool libbpf_needs_btf(const struct bpf_object *obj)\n{\n\treturn obj->efile.btf_maps_shndx >= 0 ||\n\t       obj->efile.st_ops_shndx >= 0 ||\n\t       obj->efile.st_ops_link_shndx >= 0 ||\n\t       obj->nr_extern > 0;\n}\n\nstatic bool kernel_needs_btf(const struct bpf_object *obj)\n{\n\treturn obj->efile.st_ops_shndx >= 0 || obj->efile.st_ops_link_shndx >= 0;\n}\n\nstatic int bpf_object__init_btf(struct bpf_object *obj,\n\t\t\t\tElf_Data *btf_data,\n\t\t\t\tElf_Data *btf_ext_data)\n{\n\tint err = -ENOENT;\n\n\tif (btf_data) {\n\t\tobj->btf = btf__new(btf_data->d_buf, btf_data->d_size);\n\t\terr = libbpf_get_error(obj->btf);\n\t\tif (err) {\n\t\t\tobj->btf = NULL;\n\t\t\tpr_warn(\"Error loading ELF section %s: %d.\\n\", BTF_ELF_SEC, err);\n\t\t\tgoto out;\n\t\t}\n\t\t \n\t\tbtf__set_pointer_size(obj->btf, 8);\n\t}\n\tif (btf_ext_data) {\n\t\tstruct btf_ext_info *ext_segs[3];\n\t\tint seg_num, sec_num;\n\n\t\tif (!obj->btf) {\n\t\t\tpr_debug(\"Ignore ELF section %s because its depending ELF section %s is not found.\\n\",\n\t\t\t\t BTF_EXT_ELF_SEC, BTF_ELF_SEC);\n\t\t\tgoto out;\n\t\t}\n\t\tobj->btf_ext = btf_ext__new(btf_ext_data->d_buf, btf_ext_data->d_size);\n\t\terr = libbpf_get_error(obj->btf_ext);\n\t\tif (err) {\n\t\t\tpr_warn(\"Error loading ELF section %s: %d. Ignored and continue.\\n\",\n\t\t\t\tBTF_EXT_ELF_SEC, err);\n\t\t\tobj->btf_ext = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\text_segs[0] = &obj->btf_ext->func_info;\n\t\text_segs[1] = &obj->btf_ext->line_info;\n\t\text_segs[2] = &obj->btf_ext->core_relo_info;\n\t\tfor (seg_num = 0; seg_num < ARRAY_SIZE(ext_segs); seg_num++) {\n\t\t\tstruct btf_ext_info *seg = ext_segs[seg_num];\n\t\t\tconst struct btf_ext_info_sec *sec;\n\t\t\tconst char *sec_name;\n\t\t\tElf_Scn *scn;\n\n\t\t\tif (seg->sec_cnt == 0)\n\t\t\t\tcontinue;\n\n\t\t\tseg->sec_idxs = calloc(seg->sec_cnt, sizeof(*seg->sec_idxs));\n\t\t\tif (!seg->sec_idxs) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tsec_num = 0;\n\t\t\tfor_each_btf_ext_sec(seg, sec) {\n\t\t\t\t \n\t\t\t\tsec_num++;\n\n\t\t\t\tsec_name = btf__name_by_offset(obj->btf, sec->sec_name_off);\n\t\t\t\tif (str_is_empty(sec_name))\n\t\t\t\t\tcontinue;\n\t\t\t\tscn = elf_sec_by_name(obj, sec_name);\n\t\t\t\tif (!scn)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tseg->sec_idxs[sec_num - 1] = elf_ndxscn(scn);\n\t\t\t}\n\t\t}\n\t}\nout:\n\tif (err && libbpf_needs_btf(obj)) {\n\t\tpr_warn(\"BTF is required, but is missing or corrupted.\\n\");\n\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic int compare_vsi_off(const void *_a, const void *_b)\n{\n\tconst struct btf_var_secinfo *a = _a;\n\tconst struct btf_var_secinfo *b = _b;\n\n\treturn a->offset - b->offset;\n}\n\nstatic int btf_fixup_datasec(struct bpf_object *obj, struct btf *btf,\n\t\t\t     struct btf_type *t)\n{\n\t__u32 size = 0, i, vars = btf_vlen(t);\n\tconst char *sec_name = btf__name_by_offset(btf, t->name_off);\n\tstruct btf_var_secinfo *vsi;\n\tbool fixup_offsets = false;\n\tint err;\n\n\tif (!sec_name) {\n\t\tpr_debug(\"No name found in string section for DATASEC kind.\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\t \n\tif (strcmp(sec_name, KCONFIG_SEC) == 0 || strcmp(sec_name, KSYMS_SEC) == 0)\n\t\tgoto sort_vars;\n\n\t \n\tif (t->size == 0) {\n\t\terr = find_elf_sec_sz(obj, sec_name, &size);\n\t\tif (err || !size) {\n\t\t\tpr_debug(\"sec '%s': failed to determine size from ELF: size %u, err %d\\n\",\n\t\t\t\t sec_name, size, err);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tt->size = size;\n\t\tfixup_offsets = true;\n\t}\n\n\tfor (i = 0, vsi = btf_var_secinfos(t); i < vars; i++, vsi++) {\n\t\tconst struct btf_type *t_var;\n\t\tstruct btf_var *var;\n\t\tconst char *var_name;\n\t\tElf64_Sym *sym;\n\n\t\tt_var = btf__type_by_id(btf, vsi->type);\n\t\tif (!t_var || !btf_is_var(t_var)) {\n\t\t\tpr_debug(\"sec '%s': unexpected non-VAR type found\\n\", sec_name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvar = btf_var(t_var);\n\t\tif (var->linkage == BTF_VAR_STATIC || var->linkage == BTF_VAR_GLOBAL_EXTERN)\n\t\t\tcontinue;\n\n\t\tvar_name = btf__name_by_offset(btf, t_var->name_off);\n\t\tif (!var_name) {\n\t\t\tpr_debug(\"sec '%s': failed to find name of DATASEC's member #%d\\n\",\n\t\t\t\t sec_name, i);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tsym = find_elf_var_sym(obj, var_name);\n\t\tif (IS_ERR(sym)) {\n\t\t\tpr_debug(\"sec '%s': failed to find ELF symbol for VAR '%s'\\n\",\n\t\t\t\t sec_name, var_name);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tif (fixup_offsets)\n\t\t\tvsi->offset = sym->st_value;\n\n\t\t \n\t\tif (ELF64_ST_VISIBILITY(sym->st_other) == STV_HIDDEN\n\t\t    || ELF64_ST_VISIBILITY(sym->st_other) == STV_INTERNAL)\n\t\t\tvar->linkage = BTF_VAR_STATIC;\n\t}\n\nsort_vars:\n\tqsort(btf_var_secinfos(t), vars, sizeof(*vsi), compare_vsi_off);\n\treturn 0;\n}\n\nstatic int bpf_object_fixup_btf(struct bpf_object *obj)\n{\n\tint i, n, err = 0;\n\n\tif (!obj->btf)\n\t\treturn 0;\n\n\tn = btf__type_cnt(obj->btf);\n\tfor (i = 1; i < n; i++) {\n\t\tstruct btf_type *t = btf_type_by_id(obj->btf, i);\n\n\t\t \n\t\tif (btf_is_datasec(t)) {\n\t\t\terr = btf_fixup_datasec(obj, obj->btf, t);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic bool prog_needs_vmlinux_btf(struct bpf_program *prog)\n{\n\tif (prog->type == BPF_PROG_TYPE_STRUCT_OPS ||\n\t    prog->type == BPF_PROG_TYPE_LSM)\n\t\treturn true;\n\n\t \n\tif (prog->type == BPF_PROG_TYPE_TRACING && !prog->attach_prog_fd)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic bool obj_needs_vmlinux_btf(const struct bpf_object *obj)\n{\n\tstruct bpf_program *prog;\n\tint i;\n\n\t \n\tif (obj->btf_ext && obj->btf_ext->core_relo_info.len && !obj->btf_custom_path)\n\t\treturn true;\n\n\t \n\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\tconst struct extern_desc *ext;\n\n\t\text = &obj->externs[i];\n\t\tif (ext->type == EXT_KSYM && ext->ksym.type_id)\n\t\t\treturn true;\n\t}\n\n\tbpf_object__for_each_program(prog, obj) {\n\t\tif (!prog->autoload)\n\t\t\tcontinue;\n\t\tif (prog_needs_vmlinux_btf(prog))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int bpf_object__load_vmlinux_btf(struct bpf_object *obj, bool force)\n{\n\tint err;\n\n\t \n\tif (obj->btf_vmlinux || obj->gen_loader)\n\t\treturn 0;\n\n\tif (!force && !obj_needs_vmlinux_btf(obj))\n\t\treturn 0;\n\n\tobj->btf_vmlinux = btf__load_vmlinux_btf();\n\terr = libbpf_get_error(obj->btf_vmlinux);\n\tif (err) {\n\t\tpr_warn(\"Error loading vmlinux BTF: %d\\n\", err);\n\t\tobj->btf_vmlinux = NULL;\n\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic int bpf_object__sanitize_and_load_btf(struct bpf_object *obj)\n{\n\tstruct btf *kern_btf = obj->btf;\n\tbool btf_mandatory, sanitize;\n\tint i, err = 0;\n\n\tif (!obj->btf)\n\t\treturn 0;\n\n\tif (!kernel_supports(obj, FEAT_BTF)) {\n\t\tif (kernel_needs_btf(obj)) {\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto report;\n\t\t}\n\t\tpr_debug(\"Kernel doesn't support BTF, skipping uploading it.\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tstruct bpf_program *prog = &obj->programs[i];\n\t\tstruct btf_type *t;\n\t\tconst char *name;\n\t\tint j, n;\n\n\t\tif (!prog->mark_btf_static || !prog_is_subprog(obj, prog))\n\t\t\tcontinue;\n\n\t\tn = btf__type_cnt(obj->btf);\n\t\tfor (j = 1; j < n; j++) {\n\t\t\tt = btf_type_by_id(obj->btf, j);\n\t\t\tif (!btf_is_func(t) || btf_func_linkage(t) != BTF_FUNC_GLOBAL)\n\t\t\t\tcontinue;\n\n\t\t\tname = btf__str_by_offset(obj->btf, t->name_off);\n\t\t\tif (strcmp(name, prog->name) != 0)\n\t\t\t\tcontinue;\n\n\t\t\tt->info = btf_type_info(BTF_KIND_FUNC, BTF_FUNC_STATIC, 0);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tsanitize = btf_needs_sanitization(obj);\n\tif (sanitize) {\n\t\tconst void *raw_data;\n\t\t__u32 sz;\n\n\t\t \n\t\traw_data = btf__raw_data(obj->btf, &sz);\n\t\tkern_btf = btf__new(raw_data, sz);\n\t\terr = libbpf_get_error(kern_btf);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t \n\t\tbtf__set_pointer_size(obj->btf, 8);\n\t\terr = bpf_object__sanitize_btf(obj, kern_btf);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (obj->gen_loader) {\n\t\t__u32 raw_size = 0;\n\t\tconst void *raw_data = btf__raw_data(kern_btf, &raw_size);\n\n\t\tif (!raw_data)\n\t\t\treturn -ENOMEM;\n\t\tbpf_gen__load_btf(obj->gen_loader, raw_data, raw_size);\n\t\t \n\t\tbtf__set_fd(kern_btf, 0);\n\t} else {\n\t\t \n\t\terr = btf_load_into_kernel(kern_btf, obj->log_buf, obj->log_size,\n\t\t\t\t\t   obj->log_level ? 1 : 0);\n\t}\n\tif (sanitize) {\n\t\tif (!err) {\n\t\t\t \n\t\t\tbtf__set_fd(obj->btf, btf__fd(kern_btf));\n\t\t\tbtf__set_fd(kern_btf, -1);\n\t\t}\n\t\tbtf__free(kern_btf);\n\t}\nreport:\n\tif (err) {\n\t\tbtf_mandatory = kernel_needs_btf(obj);\n\t\tpr_warn(\"Error loading .BTF into kernel: %d. %s\\n\", err,\n\t\t\tbtf_mandatory ? \"BTF is mandatory, can't proceed.\"\n\t\t\t\t      : \"BTF is optional, ignoring.\");\n\t\tif (!btf_mandatory)\n\t\t\terr = 0;\n\t}\n\treturn err;\n}\n\nstatic const char *elf_sym_str(const struct bpf_object *obj, size_t off)\n{\n\tconst char *name;\n\n\tname = elf_strptr(obj->efile.elf, obj->efile.strtabidx, off);\n\tif (!name) {\n\t\tpr_warn(\"elf: failed to get section name string at offset %zu from %s: %s\\n\",\n\t\t\toff, obj->path, elf_errmsg(-1));\n\t\treturn NULL;\n\t}\n\n\treturn name;\n}\n\nstatic const char *elf_sec_str(const struct bpf_object *obj, size_t off)\n{\n\tconst char *name;\n\n\tname = elf_strptr(obj->efile.elf, obj->efile.shstrndx, off);\n\tif (!name) {\n\t\tpr_warn(\"elf: failed to get section name string at offset %zu from %s: %s\\n\",\n\t\t\toff, obj->path, elf_errmsg(-1));\n\t\treturn NULL;\n\t}\n\n\treturn name;\n}\n\nstatic Elf_Scn *elf_sec_by_idx(const struct bpf_object *obj, size_t idx)\n{\n\tElf_Scn *scn;\n\n\tscn = elf_getscn(obj->efile.elf, idx);\n\tif (!scn) {\n\t\tpr_warn(\"elf: failed to get section(%zu) from %s: %s\\n\",\n\t\t\tidx, obj->path, elf_errmsg(-1));\n\t\treturn NULL;\n\t}\n\treturn scn;\n}\n\nstatic Elf_Scn *elf_sec_by_name(const struct bpf_object *obj, const char *name)\n{\n\tElf_Scn *scn = NULL;\n\tElf *elf = obj->efile.elf;\n\tconst char *sec_name;\n\n\twhile ((scn = elf_nextscn(elf, scn)) != NULL) {\n\t\tsec_name = elf_sec_name(obj, scn);\n\t\tif (!sec_name)\n\t\t\treturn NULL;\n\n\t\tif (strcmp(sec_name, name) != 0)\n\t\t\tcontinue;\n\n\t\treturn scn;\n\t}\n\treturn NULL;\n}\n\nstatic Elf64_Shdr *elf_sec_hdr(const struct bpf_object *obj, Elf_Scn *scn)\n{\n\tElf64_Shdr *shdr;\n\n\tif (!scn)\n\t\treturn NULL;\n\n\tshdr = elf64_getshdr(scn);\n\tif (!shdr) {\n\t\tpr_warn(\"elf: failed to get section(%zu) header from %s: %s\\n\",\n\t\t\telf_ndxscn(scn), obj->path, elf_errmsg(-1));\n\t\treturn NULL;\n\t}\n\n\treturn shdr;\n}\n\nstatic const char *elf_sec_name(const struct bpf_object *obj, Elf_Scn *scn)\n{\n\tconst char *name;\n\tElf64_Shdr *sh;\n\n\tif (!scn)\n\t\treturn NULL;\n\n\tsh = elf_sec_hdr(obj, scn);\n\tif (!sh)\n\t\treturn NULL;\n\n\tname = elf_sec_str(obj, sh->sh_name);\n\tif (!name) {\n\t\tpr_warn(\"elf: failed to get section(%zu) name from %s: %s\\n\",\n\t\t\telf_ndxscn(scn), obj->path, elf_errmsg(-1));\n\t\treturn NULL;\n\t}\n\n\treturn name;\n}\n\nstatic Elf_Data *elf_sec_data(const struct bpf_object *obj, Elf_Scn *scn)\n{\n\tElf_Data *data;\n\n\tif (!scn)\n\t\treturn NULL;\n\n\tdata = elf_getdata(scn, 0);\n\tif (!data) {\n\t\tpr_warn(\"elf: failed to get section(%zu) %s data from %s: %s\\n\",\n\t\t\telf_ndxscn(scn), elf_sec_name(obj, scn) ?: \"<?>\",\n\t\t\tobj->path, elf_errmsg(-1));\n\t\treturn NULL;\n\t}\n\n\treturn data;\n}\n\nstatic Elf64_Sym *elf_sym_by_idx(const struct bpf_object *obj, size_t idx)\n{\n\tif (idx >= obj->efile.symbols->d_size / sizeof(Elf64_Sym))\n\t\treturn NULL;\n\n\treturn (Elf64_Sym *)obj->efile.symbols->d_buf + idx;\n}\n\nstatic Elf64_Rel *elf_rel_by_idx(Elf_Data *data, size_t idx)\n{\n\tif (idx >= data->d_size / sizeof(Elf64_Rel))\n\t\treturn NULL;\n\n\treturn (Elf64_Rel *)data->d_buf + idx;\n}\n\nstatic bool is_sec_name_dwarf(const char *name)\n{\n\t \n\treturn str_has_pfx(name, \".debug_\");\n}\n\nstatic bool ignore_elf_section(Elf64_Shdr *hdr, const char *name)\n{\n\t \n\tif (hdr->sh_type == SHT_STRTAB)\n\t\treturn true;\n\n\t \n\tif (hdr->sh_type == SHT_LLVM_ADDRSIG)\n\t\treturn true;\n\n\t \n\tif (hdr->sh_type == SHT_PROGBITS && hdr->sh_size == 0 &&\n\t    strcmp(name, \".text\") == 0)\n\t\treturn true;\n\n\t \n\tif (is_sec_name_dwarf(name))\n\t\treturn true;\n\n\tif (str_has_pfx(name, \".rel\")) {\n\t\tname += sizeof(\".rel\") - 1;\n\t\t \n\t\tif (is_sec_name_dwarf(name))\n\t\t\treturn true;\n\n\t\t \n\t\tif (strcmp(name, BTF_ELF_SEC) == 0 ||\n\t\t    strcmp(name, BTF_EXT_ELF_SEC) == 0)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int cmp_progs(const void *_a, const void *_b)\n{\n\tconst struct bpf_program *a = _a;\n\tconst struct bpf_program *b = _b;\n\n\tif (a->sec_idx != b->sec_idx)\n\t\treturn a->sec_idx < b->sec_idx ? -1 : 1;\n\n\t \n\treturn a->sec_insn_off < b->sec_insn_off ? -1 : 1;\n}\n\nstatic int bpf_object__elf_collect(struct bpf_object *obj)\n{\n\tstruct elf_sec_desc *sec_desc;\n\tElf *elf = obj->efile.elf;\n\tElf_Data *btf_ext_data = NULL;\n\tElf_Data *btf_data = NULL;\n\tint idx = 0, err = 0;\n\tconst char *name;\n\tElf_Data *data;\n\tElf_Scn *scn;\n\tElf64_Shdr *sh;\n\n\t \n\tif (elf_getshdrnum(obj->efile.elf, &obj->efile.sec_cnt)) {\n\t\tpr_warn(\"elf: failed to get the number of sections for %s: %s\\n\",\n\t\t\tobj->path, elf_errmsg(-1));\n\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t}\n\tobj->efile.secs = calloc(obj->efile.sec_cnt, sizeof(*obj->efile.secs));\n\tif (!obj->efile.secs)\n\t\treturn -ENOMEM;\n\n\t \n\tscn = NULL;\n\twhile ((scn = elf_nextscn(elf, scn)) != NULL) {\n\t\tsh = elf_sec_hdr(obj, scn);\n\t\tif (!sh)\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\n\t\tif (sh->sh_type == SHT_SYMTAB) {\n\t\t\tif (obj->efile.symbols) {\n\t\t\t\tpr_warn(\"elf: multiple symbol tables in %s\\n\", obj->path);\n\t\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t\t}\n\n\t\t\tdata = elf_sec_data(obj, scn);\n\t\t\tif (!data)\n\t\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\n\t\t\tidx = elf_ndxscn(scn);\n\n\t\t\tobj->efile.symbols = data;\n\t\t\tobj->efile.symbols_shndx = idx;\n\t\t\tobj->efile.strtabidx = sh->sh_link;\n\t\t}\n\t}\n\n\tif (!obj->efile.symbols) {\n\t\tpr_warn(\"elf: couldn't find symbol table in %s, stripped object file?\\n\",\n\t\t\tobj->path);\n\t\treturn -ENOENT;\n\t}\n\n\tscn = NULL;\n\twhile ((scn = elf_nextscn(elf, scn)) != NULL) {\n\t\tidx = elf_ndxscn(scn);\n\t\tsec_desc = &obj->efile.secs[idx];\n\n\t\tsh = elf_sec_hdr(obj, scn);\n\t\tif (!sh)\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\n\t\tname = elf_sec_str(obj, sh->sh_name);\n\t\tif (!name)\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\n\t\tif (ignore_elf_section(sh, name))\n\t\t\tcontinue;\n\n\t\tdata = elf_sec_data(obj, scn);\n\t\tif (!data)\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\n\t\tpr_debug(\"elf: section(%d) %s, size %ld, link %d, flags %lx, type=%d\\n\",\n\t\t\t idx, name, (unsigned long)data->d_size,\n\t\t\t (int)sh->sh_link, (unsigned long)sh->sh_flags,\n\t\t\t (int)sh->sh_type);\n\n\t\tif (strcmp(name, \"license\") == 0) {\n\t\t\terr = bpf_object__init_license(obj, data->d_buf, data->d_size);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else if (strcmp(name, \"version\") == 0) {\n\t\t\terr = bpf_object__init_kversion(obj, data->d_buf, data->d_size);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else if (strcmp(name, \"maps\") == 0) {\n\t\t\tpr_warn(\"elf: legacy map definitions in 'maps' section are not supported by libbpf v1.0+\\n\");\n\t\t\treturn -ENOTSUP;\n\t\t} else if (strcmp(name, MAPS_ELF_SEC) == 0) {\n\t\t\tobj->efile.btf_maps_shndx = idx;\n\t\t} else if (strcmp(name, BTF_ELF_SEC) == 0) {\n\t\t\tif (sh->sh_type != SHT_PROGBITS)\n\t\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t\tbtf_data = data;\n\t\t} else if (strcmp(name, BTF_EXT_ELF_SEC) == 0) {\n\t\t\tif (sh->sh_type != SHT_PROGBITS)\n\t\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t\tbtf_ext_data = data;\n\t\t} else if (sh->sh_type == SHT_SYMTAB) {\n\t\t\t \n\t\t} else if (sh->sh_type == SHT_PROGBITS && data->d_size > 0) {\n\t\t\tif (sh->sh_flags & SHF_EXECINSTR) {\n\t\t\t\tif (strcmp(name, \".text\") == 0)\n\t\t\t\t\tobj->efile.text_shndx = idx;\n\t\t\t\terr = bpf_object__add_programs(obj, data, name, idx);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t} else if (strcmp(name, DATA_SEC) == 0 ||\n\t\t\t\t   str_has_pfx(name, DATA_SEC \".\")) {\n\t\t\t\tsec_desc->sec_type = SEC_DATA;\n\t\t\t\tsec_desc->shdr = sh;\n\t\t\t\tsec_desc->data = data;\n\t\t\t} else if (strcmp(name, RODATA_SEC) == 0 ||\n\t\t\t\t   str_has_pfx(name, RODATA_SEC \".\")) {\n\t\t\t\tsec_desc->sec_type = SEC_RODATA;\n\t\t\t\tsec_desc->shdr = sh;\n\t\t\t\tsec_desc->data = data;\n\t\t\t} else if (strcmp(name, STRUCT_OPS_SEC) == 0) {\n\t\t\t\tobj->efile.st_ops_data = data;\n\t\t\t\tobj->efile.st_ops_shndx = idx;\n\t\t\t} else if (strcmp(name, STRUCT_OPS_LINK_SEC) == 0) {\n\t\t\t\tobj->efile.st_ops_link_data = data;\n\t\t\t\tobj->efile.st_ops_link_shndx = idx;\n\t\t\t} else {\n\t\t\t\tpr_info(\"elf: skipping unrecognized data section(%d) %s\\n\",\n\t\t\t\t\tidx, name);\n\t\t\t}\n\t\t} else if (sh->sh_type == SHT_REL) {\n\t\t\tint targ_sec_idx = sh->sh_info;  \n\n\t\t\tif (sh->sh_entsize != sizeof(Elf64_Rel) ||\n\t\t\t    targ_sec_idx >= obj->efile.sec_cnt)\n\t\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\n\t\t\t \n\t\t\tif (!section_have_execinstr(obj, targ_sec_idx) &&\n\t\t\t    strcmp(name, \".rel\" STRUCT_OPS_SEC) &&\n\t\t\t    strcmp(name, \".rel\" STRUCT_OPS_LINK_SEC) &&\n\t\t\t    strcmp(name, \".rel\" MAPS_ELF_SEC)) {\n\t\t\t\tpr_info(\"elf: skipping relo section(%d) %s for section(%d) %s\\n\",\n\t\t\t\t\tidx, name, targ_sec_idx,\n\t\t\t\t\telf_sec_name(obj, elf_sec_by_idx(obj, targ_sec_idx)) ?: \"<?>\");\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tsec_desc->sec_type = SEC_RELO;\n\t\t\tsec_desc->shdr = sh;\n\t\t\tsec_desc->data = data;\n\t\t} else if (sh->sh_type == SHT_NOBITS && (strcmp(name, BSS_SEC) == 0 ||\n\t\t\t\t\t\t\t str_has_pfx(name, BSS_SEC \".\"))) {\n\t\t\tsec_desc->sec_type = SEC_BSS;\n\t\t\tsec_desc->shdr = sh;\n\t\t\tsec_desc->data = data;\n\t\t} else {\n\t\t\tpr_info(\"elf: skipping section(%d) %s (size %zu)\\n\", idx, name,\n\t\t\t\t(size_t)sh->sh_size);\n\t\t}\n\t}\n\n\tif (!obj->efile.strtabidx || obj->efile.strtabidx > idx) {\n\t\tpr_warn(\"elf: symbol strings section missing or invalid in %s\\n\", obj->path);\n\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t}\n\n\t \n\tif (obj->nr_programs)\n\t\tqsort(obj->programs, obj->nr_programs, sizeof(*obj->programs), cmp_progs);\n\n\treturn bpf_object__init_btf(obj, btf_data, btf_ext_data);\n}\n\nstatic bool sym_is_extern(const Elf64_Sym *sym)\n{\n\tint bind = ELF64_ST_BIND(sym->st_info);\n\t \n\treturn sym->st_shndx == SHN_UNDEF &&\n\t       (bind == STB_GLOBAL || bind == STB_WEAK) &&\n\t       ELF64_ST_TYPE(sym->st_info) == STT_NOTYPE;\n}\n\nstatic bool sym_is_subprog(const Elf64_Sym *sym, int text_shndx)\n{\n\tint bind = ELF64_ST_BIND(sym->st_info);\n\tint type = ELF64_ST_TYPE(sym->st_info);\n\n\t \n\tif (sym->st_shndx != text_shndx)\n\t\treturn false;\n\n\t \n\tif (bind == STB_LOCAL && type == STT_SECTION)\n\t\treturn true;\n\n\t \n\treturn bind == STB_GLOBAL && type == STT_FUNC;\n}\n\nstatic int find_extern_btf_id(const struct btf *btf, const char *ext_name)\n{\n\tconst struct btf_type *t;\n\tconst char *tname;\n\tint i, n;\n\n\tif (!btf)\n\t\treturn -ESRCH;\n\n\tn = btf__type_cnt(btf);\n\tfor (i = 1; i < n; i++) {\n\t\tt = btf__type_by_id(btf, i);\n\n\t\tif (!btf_is_var(t) && !btf_is_func(t))\n\t\t\tcontinue;\n\n\t\ttname = btf__name_by_offset(btf, t->name_off);\n\t\tif (strcmp(tname, ext_name))\n\t\t\tcontinue;\n\n\t\tif (btf_is_var(t) &&\n\t\t    btf_var(t)->linkage != BTF_VAR_GLOBAL_EXTERN)\n\t\t\treturn -EINVAL;\n\n\t\tif (btf_is_func(t) && btf_func_linkage(t) != BTF_FUNC_EXTERN)\n\t\t\treturn -EINVAL;\n\n\t\treturn i;\n\t}\n\n\treturn -ENOENT;\n}\n\nstatic int find_extern_sec_btf_id(struct btf *btf, int ext_btf_id) {\n\tconst struct btf_var_secinfo *vs;\n\tconst struct btf_type *t;\n\tint i, j, n;\n\n\tif (!btf)\n\t\treturn -ESRCH;\n\n\tn = btf__type_cnt(btf);\n\tfor (i = 1; i < n; i++) {\n\t\tt = btf__type_by_id(btf, i);\n\n\t\tif (!btf_is_datasec(t))\n\t\t\tcontinue;\n\n\t\tvs = btf_var_secinfos(t);\n\t\tfor (j = 0; j < btf_vlen(t); j++, vs++) {\n\t\t\tif (vs->type == ext_btf_id)\n\t\t\t\treturn i;\n\t\t}\n\t}\n\n\treturn -ENOENT;\n}\n\nstatic enum kcfg_type find_kcfg_type(const struct btf *btf, int id,\n\t\t\t\t     bool *is_signed)\n{\n\tconst struct btf_type *t;\n\tconst char *name;\n\n\tt = skip_mods_and_typedefs(btf, id, NULL);\n\tname = btf__name_by_offset(btf, t->name_off);\n\n\tif (is_signed)\n\t\t*is_signed = false;\n\tswitch (btf_kind(t)) {\n\tcase BTF_KIND_INT: {\n\t\tint enc = btf_int_encoding(t);\n\n\t\tif (enc & BTF_INT_BOOL)\n\t\t\treturn t->size == 1 ? KCFG_BOOL : KCFG_UNKNOWN;\n\t\tif (is_signed)\n\t\t\t*is_signed = enc & BTF_INT_SIGNED;\n\t\tif (t->size == 1)\n\t\t\treturn KCFG_CHAR;\n\t\tif (t->size < 1 || t->size > 8 || (t->size & (t->size - 1)))\n\t\t\treturn KCFG_UNKNOWN;\n\t\treturn KCFG_INT;\n\t}\n\tcase BTF_KIND_ENUM:\n\t\tif (t->size != 4)\n\t\t\treturn KCFG_UNKNOWN;\n\t\tif (strcmp(name, \"libbpf_tristate\"))\n\t\t\treturn KCFG_UNKNOWN;\n\t\treturn KCFG_TRISTATE;\n\tcase BTF_KIND_ENUM64:\n\t\tif (strcmp(name, \"libbpf_tristate\"))\n\t\t\treturn KCFG_UNKNOWN;\n\t\treturn KCFG_TRISTATE;\n\tcase BTF_KIND_ARRAY:\n\t\tif (btf_array(t)->nelems == 0)\n\t\t\treturn KCFG_UNKNOWN;\n\t\tif (find_kcfg_type(btf, btf_array(t)->type, NULL) != KCFG_CHAR)\n\t\t\treturn KCFG_UNKNOWN;\n\t\treturn KCFG_CHAR_ARR;\n\tdefault:\n\t\treturn KCFG_UNKNOWN;\n\t}\n}\n\nstatic int cmp_externs(const void *_a, const void *_b)\n{\n\tconst struct extern_desc *a = _a;\n\tconst struct extern_desc *b = _b;\n\n\tif (a->type != b->type)\n\t\treturn a->type < b->type ? -1 : 1;\n\n\tif (a->type == EXT_KCFG) {\n\t\t \n\t\tif (a->kcfg.align != b->kcfg.align)\n\t\t\treturn a->kcfg.align > b->kcfg.align ? -1 : 1;\n\t\t \n\t\tif (a->kcfg.sz != b->kcfg.sz)\n\t\t\treturn a->kcfg.sz < b->kcfg.sz ? -1 : 1;\n\t}\n\n\t \n\treturn strcmp(a->name, b->name);\n}\n\nstatic int find_int_btf_id(const struct btf *btf)\n{\n\tconst struct btf_type *t;\n\tint i, n;\n\n\tn = btf__type_cnt(btf);\n\tfor (i = 1; i < n; i++) {\n\t\tt = btf__type_by_id(btf, i);\n\n\t\tif (btf_is_int(t) && btf_int_bits(t) == 32)\n\t\t\treturn i;\n\t}\n\n\treturn 0;\n}\n\nstatic int add_dummy_ksym_var(struct btf *btf)\n{\n\tint i, int_btf_id, sec_btf_id, dummy_var_btf_id;\n\tconst struct btf_var_secinfo *vs;\n\tconst struct btf_type *sec;\n\n\tif (!btf)\n\t\treturn 0;\n\n\tsec_btf_id = btf__find_by_name_kind(btf, KSYMS_SEC,\n\t\t\t\t\t    BTF_KIND_DATASEC);\n\tif (sec_btf_id < 0)\n\t\treturn 0;\n\n\tsec = btf__type_by_id(btf, sec_btf_id);\n\tvs = btf_var_secinfos(sec);\n\tfor (i = 0; i < btf_vlen(sec); i++, vs++) {\n\t\tconst struct btf_type *vt;\n\n\t\tvt = btf__type_by_id(btf, vs->type);\n\t\tif (btf_is_func(vt))\n\t\t\tbreak;\n\t}\n\n\t \n\tif (i == btf_vlen(sec))\n\t\treturn 0;\n\n\tint_btf_id = find_int_btf_id(btf);\n\tdummy_var_btf_id = btf__add_var(btf,\n\t\t\t\t\t\"dummy_ksym\",\n\t\t\t\t\tBTF_VAR_GLOBAL_ALLOCATED,\n\t\t\t\t\tint_btf_id);\n\tif (dummy_var_btf_id < 0)\n\t\tpr_warn(\"cannot create a dummy_ksym var\\n\");\n\n\treturn dummy_var_btf_id;\n}\n\nstatic int bpf_object__collect_externs(struct bpf_object *obj)\n{\n\tstruct btf_type *sec, *kcfg_sec = NULL, *ksym_sec = NULL;\n\tconst struct btf_type *t;\n\tstruct extern_desc *ext;\n\tint i, n, off, dummy_var_btf_id;\n\tconst char *ext_name, *sec_name;\n\tsize_t ext_essent_len;\n\tElf_Scn *scn;\n\tElf64_Shdr *sh;\n\n\tif (!obj->efile.symbols)\n\t\treturn 0;\n\n\tscn = elf_sec_by_idx(obj, obj->efile.symbols_shndx);\n\tsh = elf_sec_hdr(obj, scn);\n\tif (!sh || sh->sh_entsize != sizeof(Elf64_Sym))\n\t\treturn -LIBBPF_ERRNO__FORMAT;\n\n\tdummy_var_btf_id = add_dummy_ksym_var(obj->btf);\n\tif (dummy_var_btf_id < 0)\n\t\treturn dummy_var_btf_id;\n\n\tn = sh->sh_size / sh->sh_entsize;\n\tpr_debug(\"looking for externs among %d symbols...\\n\", n);\n\n\tfor (i = 0; i < n; i++) {\n\t\tElf64_Sym *sym = elf_sym_by_idx(obj, i);\n\n\t\tif (!sym)\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\tif (!sym_is_extern(sym))\n\t\t\tcontinue;\n\t\text_name = elf_sym_str(obj, sym->st_name);\n\t\tif (!ext_name || !ext_name[0])\n\t\t\tcontinue;\n\n\t\text = obj->externs;\n\t\text = libbpf_reallocarray(ext, obj->nr_extern + 1, sizeof(*ext));\n\t\tif (!ext)\n\t\t\treturn -ENOMEM;\n\t\tobj->externs = ext;\n\t\text = &ext[obj->nr_extern];\n\t\tmemset(ext, 0, sizeof(*ext));\n\t\tobj->nr_extern++;\n\n\t\text->btf_id = find_extern_btf_id(obj->btf, ext_name);\n\t\tif (ext->btf_id <= 0) {\n\t\t\tpr_warn(\"failed to find BTF for extern '%s': %d\\n\",\n\t\t\t\text_name, ext->btf_id);\n\t\t\treturn ext->btf_id;\n\t\t}\n\t\tt = btf__type_by_id(obj->btf, ext->btf_id);\n\t\text->name = btf__name_by_offset(obj->btf, t->name_off);\n\t\text->sym_idx = i;\n\t\text->is_weak = ELF64_ST_BIND(sym->st_info) == STB_WEAK;\n\n\t\text_essent_len = bpf_core_essential_name_len(ext->name);\n\t\text->essent_name = NULL;\n\t\tif (ext_essent_len != strlen(ext->name)) {\n\t\t\text->essent_name = strndup(ext->name, ext_essent_len);\n\t\t\tif (!ext->essent_name)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\text->sec_btf_id = find_extern_sec_btf_id(obj->btf, ext->btf_id);\n\t\tif (ext->sec_btf_id <= 0) {\n\t\t\tpr_warn(\"failed to find BTF for extern '%s' [%d] section: %d\\n\",\n\t\t\t\text_name, ext->btf_id, ext->sec_btf_id);\n\t\t\treturn ext->sec_btf_id;\n\t\t}\n\t\tsec = (void *)btf__type_by_id(obj->btf, ext->sec_btf_id);\n\t\tsec_name = btf__name_by_offset(obj->btf, sec->name_off);\n\n\t\tif (strcmp(sec_name, KCONFIG_SEC) == 0) {\n\t\t\tif (btf_is_func(t)) {\n\t\t\t\tpr_warn(\"extern function %s is unsupported under %s section\\n\",\n\t\t\t\t\text->name, KCONFIG_SEC);\n\t\t\t\treturn -ENOTSUP;\n\t\t\t}\n\t\t\tkcfg_sec = sec;\n\t\t\text->type = EXT_KCFG;\n\t\t\text->kcfg.sz = btf__resolve_size(obj->btf, t->type);\n\t\t\tif (ext->kcfg.sz <= 0) {\n\t\t\t\tpr_warn(\"failed to resolve size of extern (kcfg) '%s': %d\\n\",\n\t\t\t\t\text_name, ext->kcfg.sz);\n\t\t\t\treturn ext->kcfg.sz;\n\t\t\t}\n\t\t\text->kcfg.align = btf__align_of(obj->btf, t->type);\n\t\t\tif (ext->kcfg.align <= 0) {\n\t\t\t\tpr_warn(\"failed to determine alignment of extern (kcfg) '%s': %d\\n\",\n\t\t\t\t\text_name, ext->kcfg.align);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\text->kcfg.type = find_kcfg_type(obj->btf, t->type,\n\t\t\t\t\t\t\t&ext->kcfg.is_signed);\n\t\t\tif (ext->kcfg.type == KCFG_UNKNOWN) {\n\t\t\t\tpr_warn(\"extern (kcfg) '%s': type is unsupported\\n\", ext_name);\n\t\t\t\treturn -ENOTSUP;\n\t\t\t}\n\t\t} else if (strcmp(sec_name, KSYMS_SEC) == 0) {\n\t\t\tksym_sec = sec;\n\t\t\text->type = EXT_KSYM;\n\t\t\tskip_mods_and_typedefs(obj->btf, t->type,\n\t\t\t\t\t       &ext->ksym.type_id);\n\t\t} else {\n\t\t\tpr_warn(\"unrecognized extern section '%s'\\n\", sec_name);\n\t\t\treturn -ENOTSUP;\n\t\t}\n\t}\n\tpr_debug(\"collected %d externs total\\n\", obj->nr_extern);\n\n\tif (!obj->nr_extern)\n\t\treturn 0;\n\n\t \n\tqsort(obj->externs, obj->nr_extern, sizeof(*ext), cmp_externs);\n\n\t \n\tif (ksym_sec) {\n\t\t \n\t\tint int_btf_id = find_int_btf_id(obj->btf);\n\t\t \n\t\tconst struct btf_type *dummy_var;\n\n\t\tdummy_var = btf__type_by_id(obj->btf, dummy_var_btf_id);\n\t\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\t\text = &obj->externs[i];\n\t\t\tif (ext->type != EXT_KSYM)\n\t\t\t\tcontinue;\n\t\t\tpr_debug(\"extern (ksym) #%d: symbol %d, name %s\\n\",\n\t\t\t\t i, ext->sym_idx, ext->name);\n\t\t}\n\n\t\tsec = ksym_sec;\n\t\tn = btf_vlen(sec);\n\t\tfor (i = 0, off = 0; i < n; i++, off += sizeof(int)) {\n\t\t\tstruct btf_var_secinfo *vs = btf_var_secinfos(sec) + i;\n\t\t\tstruct btf_type *vt;\n\n\t\t\tvt = (void *)btf__type_by_id(obj->btf, vs->type);\n\t\t\text_name = btf__name_by_offset(obj->btf, vt->name_off);\n\t\t\text = find_extern_by_name(obj, ext_name);\n\t\t\tif (!ext) {\n\t\t\t\tpr_warn(\"failed to find extern definition for BTF %s '%s'\\n\",\n\t\t\t\t\tbtf_kind_str(vt), ext_name);\n\t\t\t\treturn -ESRCH;\n\t\t\t}\n\t\t\tif (btf_is_func(vt)) {\n\t\t\t\tconst struct btf_type *func_proto;\n\t\t\t\tstruct btf_param *param;\n\t\t\t\tint j;\n\n\t\t\t\tfunc_proto = btf__type_by_id(obj->btf,\n\t\t\t\t\t\t\t     vt->type);\n\t\t\t\tparam = btf_params(func_proto);\n\t\t\t\t \n\t\t\t\tfor (j = 0; j < btf_vlen(func_proto); j++)\n\t\t\t\t\tif (param[j].type && !param[j].name_off)\n\t\t\t\t\t\tparam[j].name_off =\n\t\t\t\t\t\t\tdummy_var->name_off;\n\t\t\t\tvs->type = dummy_var_btf_id;\n\t\t\t\tvt->info &= ~0xffff;\n\t\t\t\tvt->info |= BTF_FUNC_GLOBAL;\n\t\t\t} else {\n\t\t\t\tbtf_var(vt)->linkage = BTF_VAR_GLOBAL_ALLOCATED;\n\t\t\t\tvt->type = int_btf_id;\n\t\t\t}\n\t\t\tvs->offset = off;\n\t\t\tvs->size = sizeof(int);\n\t\t}\n\t\tsec->size = off;\n\t}\n\n\tif (kcfg_sec) {\n\t\tsec = kcfg_sec;\n\t\t \n\t\toff = 0;\n\t\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\t\text = &obj->externs[i];\n\t\t\tif (ext->type != EXT_KCFG)\n\t\t\t\tcontinue;\n\n\t\t\text->kcfg.data_off = roundup(off, ext->kcfg.align);\n\t\t\toff = ext->kcfg.data_off + ext->kcfg.sz;\n\t\t\tpr_debug(\"extern (kcfg) #%d: symbol %d, off %u, name %s\\n\",\n\t\t\t\t i, ext->sym_idx, ext->kcfg.data_off, ext->name);\n\t\t}\n\t\tsec->size = off;\n\t\tn = btf_vlen(sec);\n\t\tfor (i = 0; i < n; i++) {\n\t\t\tstruct btf_var_secinfo *vs = btf_var_secinfos(sec) + i;\n\n\t\t\tt = btf__type_by_id(obj->btf, vs->type);\n\t\t\text_name = btf__name_by_offset(obj->btf, t->name_off);\n\t\t\text = find_extern_by_name(obj, ext_name);\n\t\t\tif (!ext) {\n\t\t\t\tpr_warn(\"failed to find extern definition for BTF var '%s'\\n\",\n\t\t\t\t\text_name);\n\t\t\t\treturn -ESRCH;\n\t\t\t}\n\t\t\tbtf_var(t)->linkage = BTF_VAR_GLOBAL_ALLOCATED;\n\t\t\tvs->offset = ext->kcfg.data_off;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic bool prog_is_subprog(const struct bpf_object *obj, const struct bpf_program *prog)\n{\n\treturn prog->sec_idx == obj->efile.text_shndx && obj->nr_programs > 1;\n}\n\nstruct bpf_program *\nbpf_object__find_program_by_name(const struct bpf_object *obj,\n\t\t\t\t const char *name)\n{\n\tstruct bpf_program *prog;\n\n\tbpf_object__for_each_program(prog, obj) {\n\t\tif (prog_is_subprog(obj, prog))\n\t\t\tcontinue;\n\t\tif (!strcmp(prog->name, name))\n\t\t\treturn prog;\n\t}\n\treturn errno = ENOENT, NULL;\n}\n\nstatic bool bpf_object__shndx_is_data(const struct bpf_object *obj,\n\t\t\t\t      int shndx)\n{\n\tswitch (obj->efile.secs[shndx].sec_type) {\n\tcase SEC_BSS:\n\tcase SEC_DATA:\n\tcase SEC_RODATA:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic bool bpf_object__shndx_is_maps(const struct bpf_object *obj,\n\t\t\t\t      int shndx)\n{\n\treturn shndx == obj->efile.btf_maps_shndx;\n}\n\nstatic enum libbpf_map_type\nbpf_object__section_to_libbpf_map_type(const struct bpf_object *obj, int shndx)\n{\n\tif (shndx == obj->efile.symbols_shndx)\n\t\treturn LIBBPF_MAP_KCONFIG;\n\n\tswitch (obj->efile.secs[shndx].sec_type) {\n\tcase SEC_BSS:\n\t\treturn LIBBPF_MAP_BSS;\n\tcase SEC_DATA:\n\t\treturn LIBBPF_MAP_DATA;\n\tcase SEC_RODATA:\n\t\treturn LIBBPF_MAP_RODATA;\n\tdefault:\n\t\treturn LIBBPF_MAP_UNSPEC;\n\t}\n}\n\nstatic int bpf_program__record_reloc(struct bpf_program *prog,\n\t\t\t\t     struct reloc_desc *reloc_desc,\n\t\t\t\t     __u32 insn_idx, const char *sym_name,\n\t\t\t\t     const Elf64_Sym *sym, const Elf64_Rel *rel)\n{\n\tstruct bpf_insn *insn = &prog->insns[insn_idx];\n\tsize_t map_idx, nr_maps = prog->obj->nr_maps;\n\tstruct bpf_object *obj = prog->obj;\n\t__u32 shdr_idx = sym->st_shndx;\n\tenum libbpf_map_type type;\n\tconst char *sym_sec_name;\n\tstruct bpf_map *map;\n\n\tif (!is_call_insn(insn) && !is_ldimm64_insn(insn)) {\n\t\tpr_warn(\"prog '%s': invalid relo against '%s' for insns[%d].code 0x%x\\n\",\n\t\t\tprog->name, sym_name, insn_idx, insn->code);\n\t\treturn -LIBBPF_ERRNO__RELOC;\n\t}\n\n\tif (sym_is_extern(sym)) {\n\t\tint sym_idx = ELF64_R_SYM(rel->r_info);\n\t\tint i, n = obj->nr_extern;\n\t\tstruct extern_desc *ext;\n\n\t\tfor (i = 0; i < n; i++) {\n\t\t\text = &obj->externs[i];\n\t\t\tif (ext->sym_idx == sym_idx)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (i >= n) {\n\t\t\tpr_warn(\"prog '%s': extern relo failed to find extern for '%s' (%d)\\n\",\n\t\t\t\tprog->name, sym_name, sym_idx);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\tpr_debug(\"prog '%s': found extern #%d '%s' (sym %d) for insn #%u\\n\",\n\t\t\t prog->name, i, ext->name, ext->sym_idx, insn_idx);\n\t\tif (insn->code == (BPF_JMP | BPF_CALL))\n\t\t\treloc_desc->type = RELO_EXTERN_CALL;\n\t\telse\n\t\t\treloc_desc->type = RELO_EXTERN_LD64;\n\t\treloc_desc->insn_idx = insn_idx;\n\t\treloc_desc->ext_idx = i;\n\t\treturn 0;\n\t}\n\n\t \n\tif (is_call_insn(insn)) {\n\t\tif (insn->src_reg != BPF_PSEUDO_CALL) {\n\t\t\tpr_warn(\"prog '%s': incorrect bpf_call opcode\\n\", prog->name);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\t \n\t\tif (!shdr_idx || shdr_idx != obj->efile.text_shndx) {\n\t\t\tsym_sec_name = elf_sec_name(obj, elf_sec_by_idx(obj, shdr_idx));\n\t\t\tpr_warn(\"prog '%s': bad call relo against '%s' in section '%s'\\n\",\n\t\t\t\tprog->name, sym_name, sym_sec_name);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\tif (sym->st_value % BPF_INSN_SZ) {\n\t\t\tpr_warn(\"prog '%s': bad call relo against '%s' at offset %zu\\n\",\n\t\t\t\tprog->name, sym_name, (size_t)sym->st_value);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\treloc_desc->type = RELO_CALL;\n\t\treloc_desc->insn_idx = insn_idx;\n\t\treloc_desc->sym_off = sym->st_value;\n\t\treturn 0;\n\t}\n\n\tif (!shdr_idx || shdr_idx >= SHN_LORESERVE) {\n\t\tpr_warn(\"prog '%s': invalid relo against '%s' in special section 0x%x; forgot to initialize global var?..\\n\",\n\t\t\tprog->name, sym_name, shdr_idx);\n\t\treturn -LIBBPF_ERRNO__RELOC;\n\t}\n\n\t \n\tif (sym_is_subprog(sym, obj->efile.text_shndx)) {\n\t\t \n\t\tif ((sym->st_value % BPF_INSN_SZ) || (insn->imm % BPF_INSN_SZ)) {\n\t\t\tpr_warn(\"prog '%s': bad subprog addr relo against '%s' at offset %zu+%d\\n\",\n\t\t\t\tprog->name, sym_name, (size_t)sym->st_value, insn->imm);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\n\t\treloc_desc->type = RELO_SUBPROG_ADDR;\n\t\treloc_desc->insn_idx = insn_idx;\n\t\treloc_desc->sym_off = sym->st_value;\n\t\treturn 0;\n\t}\n\n\ttype = bpf_object__section_to_libbpf_map_type(obj, shdr_idx);\n\tsym_sec_name = elf_sec_name(obj, elf_sec_by_idx(obj, shdr_idx));\n\n\t \n\tif (type == LIBBPF_MAP_UNSPEC) {\n\t\tif (!bpf_object__shndx_is_maps(obj, shdr_idx)) {\n\t\t\tpr_warn(\"prog '%s': bad map relo against '%s' in section '%s'\\n\",\n\t\t\t\tprog->name, sym_name, sym_sec_name);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\tfor (map_idx = 0; map_idx < nr_maps; map_idx++) {\n\t\t\tmap = &obj->maps[map_idx];\n\t\t\tif (map->libbpf_type != type ||\n\t\t\t    map->sec_idx != sym->st_shndx ||\n\t\t\t    map->sec_offset != sym->st_value)\n\t\t\t\tcontinue;\n\t\t\tpr_debug(\"prog '%s': found map %zd (%s, sec %d, off %zu) for insn #%u\\n\",\n\t\t\t\t prog->name, map_idx, map->name, map->sec_idx,\n\t\t\t\t map->sec_offset, insn_idx);\n\t\t\tbreak;\n\t\t}\n\t\tif (map_idx >= nr_maps) {\n\t\t\tpr_warn(\"prog '%s': map relo failed to find map for section '%s', off %zu\\n\",\n\t\t\t\tprog->name, sym_sec_name, (size_t)sym->st_value);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\treloc_desc->type = RELO_LD64;\n\t\treloc_desc->insn_idx = insn_idx;\n\t\treloc_desc->map_idx = map_idx;\n\t\treloc_desc->sym_off = 0;  \n\t\treturn 0;\n\t}\n\n\t \n\tif (!bpf_object__shndx_is_data(obj, shdr_idx)) {\n\t\tpr_warn(\"prog '%s': bad data relo against section '%s'\\n\",\n\t\t\tprog->name, sym_sec_name);\n\t\treturn -LIBBPF_ERRNO__RELOC;\n\t}\n\tfor (map_idx = 0; map_idx < nr_maps; map_idx++) {\n\t\tmap = &obj->maps[map_idx];\n\t\tif (map->libbpf_type != type || map->sec_idx != sym->st_shndx)\n\t\t\tcontinue;\n\t\tpr_debug(\"prog '%s': found data map %zd (%s, sec %d, off %zu) for insn %u\\n\",\n\t\t\t prog->name, map_idx, map->name, map->sec_idx,\n\t\t\t map->sec_offset, insn_idx);\n\t\tbreak;\n\t}\n\tif (map_idx >= nr_maps) {\n\t\tpr_warn(\"prog '%s': data relo failed to find map for section '%s'\\n\",\n\t\t\tprog->name, sym_sec_name);\n\t\treturn -LIBBPF_ERRNO__RELOC;\n\t}\n\n\treloc_desc->type = RELO_DATA;\n\treloc_desc->insn_idx = insn_idx;\n\treloc_desc->map_idx = map_idx;\n\treloc_desc->sym_off = sym->st_value;\n\treturn 0;\n}\n\nstatic bool prog_contains_insn(const struct bpf_program *prog, size_t insn_idx)\n{\n\treturn insn_idx >= prog->sec_insn_off &&\n\t       insn_idx < prog->sec_insn_off + prog->sec_insn_cnt;\n}\n\nstatic struct bpf_program *find_prog_by_sec_insn(const struct bpf_object *obj,\n\t\t\t\t\t\t size_t sec_idx, size_t insn_idx)\n{\n\tint l = 0, r = obj->nr_programs - 1, m;\n\tstruct bpf_program *prog;\n\n\tif (!obj->nr_programs)\n\t\treturn NULL;\n\n\twhile (l < r) {\n\t\tm = l + (r - l + 1) / 2;\n\t\tprog = &obj->programs[m];\n\n\t\tif (prog->sec_idx < sec_idx ||\n\t\t    (prog->sec_idx == sec_idx && prog->sec_insn_off <= insn_idx))\n\t\t\tl = m;\n\t\telse\n\t\t\tr = m - 1;\n\t}\n\t \n\tprog = &obj->programs[l];\n\tif (prog->sec_idx == sec_idx && prog_contains_insn(prog, insn_idx))\n\t\treturn prog;\n\treturn NULL;\n}\n\nstatic int\nbpf_object__collect_prog_relos(struct bpf_object *obj, Elf64_Shdr *shdr, Elf_Data *data)\n{\n\tconst char *relo_sec_name, *sec_name;\n\tsize_t sec_idx = shdr->sh_info, sym_idx;\n\tstruct bpf_program *prog;\n\tstruct reloc_desc *relos;\n\tint err, i, nrels;\n\tconst char *sym_name;\n\t__u32 insn_idx;\n\tElf_Scn *scn;\n\tElf_Data *scn_data;\n\tElf64_Sym *sym;\n\tElf64_Rel *rel;\n\n\tif (sec_idx >= obj->efile.sec_cnt)\n\t\treturn -EINVAL;\n\n\tscn = elf_sec_by_idx(obj, sec_idx);\n\tscn_data = elf_sec_data(obj, scn);\n\n\trelo_sec_name = elf_sec_str(obj, shdr->sh_name);\n\tsec_name = elf_sec_name(obj, scn);\n\tif (!relo_sec_name || !sec_name)\n\t\treturn -EINVAL;\n\n\tpr_debug(\"sec '%s': collecting relocation for section(%zu) '%s'\\n\",\n\t\t relo_sec_name, sec_idx, sec_name);\n\tnrels = shdr->sh_size / shdr->sh_entsize;\n\n\tfor (i = 0; i < nrels; i++) {\n\t\trel = elf_rel_by_idx(data, i);\n\t\tif (!rel) {\n\t\t\tpr_warn(\"sec '%s': failed to get relo #%d\\n\", relo_sec_name, i);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tsym_idx = ELF64_R_SYM(rel->r_info);\n\t\tsym = elf_sym_by_idx(obj, sym_idx);\n\t\tif (!sym) {\n\t\t\tpr_warn(\"sec '%s': symbol #%zu not found for relo #%d\\n\",\n\t\t\t\trelo_sec_name, sym_idx, i);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tif (sym->st_shndx >= obj->efile.sec_cnt) {\n\t\t\tpr_warn(\"sec '%s': corrupted symbol #%zu pointing to invalid section #%zu for relo #%d\\n\",\n\t\t\t\trelo_sec_name, sym_idx, (size_t)sym->st_shndx, i);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tif (rel->r_offset % BPF_INSN_SZ || rel->r_offset >= scn_data->d_size) {\n\t\t\tpr_warn(\"sec '%s': invalid offset 0x%zx for relo #%d\\n\",\n\t\t\t\trelo_sec_name, (size_t)rel->r_offset, i);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tinsn_idx = rel->r_offset / BPF_INSN_SZ;\n\t\t \n\t\tif (ELF64_ST_TYPE(sym->st_info) == STT_SECTION && sym->st_name == 0)\n\t\t\tsym_name = elf_sec_name(obj, elf_sec_by_idx(obj, sym->st_shndx));\n\t\telse\n\t\t\tsym_name = elf_sym_str(obj, sym->st_name);\n\t\tsym_name = sym_name ?: \"<?\";\n\n\t\tpr_debug(\"sec '%s': relo #%d: insn #%u against '%s'\\n\",\n\t\t\t relo_sec_name, i, insn_idx, sym_name);\n\n\t\tprog = find_prog_by_sec_insn(obj, sec_idx, insn_idx);\n\t\tif (!prog) {\n\t\t\tpr_debug(\"sec '%s': relo #%d: couldn't find program in section '%s' for insn #%u, probably overridden weak function, skipping...\\n\",\n\t\t\t\trelo_sec_name, i, sec_name, insn_idx);\n\t\t\tcontinue;\n\t\t}\n\n\t\trelos = libbpf_reallocarray(prog->reloc_desc,\n\t\t\t\t\t    prog->nr_reloc + 1, sizeof(*relos));\n\t\tif (!relos)\n\t\t\treturn -ENOMEM;\n\t\tprog->reloc_desc = relos;\n\n\t\t \n\t\tinsn_idx -= prog->sec_insn_off;\n\t\terr = bpf_program__record_reloc(prog, &relos[prog->nr_reloc],\n\t\t\t\t\t\tinsn_idx, sym_name, sym, rel);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tprog->nr_reloc++;\n\t}\n\treturn 0;\n}\n\nstatic int map_fill_btf_type_info(struct bpf_object *obj, struct bpf_map *map)\n{\n\tint id;\n\n\tif (!obj->btf)\n\t\treturn -ENOENT;\n\n\t \n\tif (map->sec_idx == obj->efile.btf_maps_shndx || bpf_map__is_struct_ops(map))\n\t\treturn 0;\n\n\t \n\tif (!bpf_map__is_internal(map))\n\t\treturn -ENOENT;\n\n\tid = btf__find_by_name(obj->btf, map->real_name);\n\tif (id < 0)\n\t\treturn id;\n\n\tmap->btf_key_type_id = 0;\n\tmap->btf_value_type_id = id;\n\treturn 0;\n}\n\nstatic int bpf_get_map_info_from_fdinfo(int fd, struct bpf_map_info *info)\n{\n\tchar file[PATH_MAX], buff[4096];\n\tFILE *fp;\n\t__u32 val;\n\tint err;\n\n\tsnprintf(file, sizeof(file), \"/proc/%d/fdinfo/%d\", getpid(), fd);\n\tmemset(info, 0, sizeof(*info));\n\n\tfp = fopen(file, \"re\");\n\tif (!fp) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to open %s: %d. No procfs support?\\n\", file,\n\t\t\terr);\n\t\treturn err;\n\t}\n\n\twhile (fgets(buff, sizeof(buff), fp)) {\n\t\tif (sscanf(buff, \"map_type:\\t%u\", &val) == 1)\n\t\t\tinfo->type = val;\n\t\telse if (sscanf(buff, \"key_size:\\t%u\", &val) == 1)\n\t\t\tinfo->key_size = val;\n\t\telse if (sscanf(buff, \"value_size:\\t%u\", &val) == 1)\n\t\t\tinfo->value_size = val;\n\t\telse if (sscanf(buff, \"max_entries:\\t%u\", &val) == 1)\n\t\t\tinfo->max_entries = val;\n\t\telse if (sscanf(buff, \"map_flags:\\t%i\", &val) == 1)\n\t\t\tinfo->map_flags = val;\n\t}\n\n\tfclose(fp);\n\n\treturn 0;\n}\n\nbool bpf_map__autocreate(const struct bpf_map *map)\n{\n\treturn map->autocreate;\n}\n\nint bpf_map__set_autocreate(struct bpf_map *map, bool autocreate)\n{\n\tif (map->obj->loaded)\n\t\treturn libbpf_err(-EBUSY);\n\n\tmap->autocreate = autocreate;\n\treturn 0;\n}\n\nint bpf_map__reuse_fd(struct bpf_map *map, int fd)\n{\n\tstruct bpf_map_info info;\n\t__u32 len = sizeof(info), name_len;\n\tint new_fd, err;\n\tchar *new_name;\n\n\tmemset(&info, 0, len);\n\terr = bpf_map_get_info_by_fd(fd, &info, &len);\n\tif (err && errno == EINVAL)\n\t\terr = bpf_get_map_info_from_fdinfo(fd, &info);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\tname_len = strlen(info.name);\n\tif (name_len == BPF_OBJ_NAME_LEN - 1 && strncmp(map->name, info.name, name_len) == 0)\n\t\tnew_name = strdup(map->name);\n\telse\n\t\tnew_name = strdup(info.name);\n\n\tif (!new_name)\n\t\treturn libbpf_err(-errno);\n\n\t \n\tnew_fd = fcntl(fd, F_DUPFD_CLOEXEC, 3);\n\tif (new_fd < 0) {\n\t\terr = -errno;\n\t\tgoto err_free_new_name;\n\t}\n\n\terr = zclose(map->fd);\n\tif (err) {\n\t\terr = -errno;\n\t\tgoto err_close_new_fd;\n\t}\n\tfree(map->name);\n\n\tmap->fd = new_fd;\n\tmap->name = new_name;\n\tmap->def.type = info.type;\n\tmap->def.key_size = info.key_size;\n\tmap->def.value_size = info.value_size;\n\tmap->def.max_entries = info.max_entries;\n\tmap->def.map_flags = info.map_flags;\n\tmap->btf_key_type_id = info.btf_key_type_id;\n\tmap->btf_value_type_id = info.btf_value_type_id;\n\tmap->reused = true;\n\tmap->map_extra = info.map_extra;\n\n\treturn 0;\n\nerr_close_new_fd:\n\tclose(new_fd);\nerr_free_new_name:\n\tfree(new_name);\n\treturn libbpf_err(err);\n}\n\n__u32 bpf_map__max_entries(const struct bpf_map *map)\n{\n\treturn map->def.max_entries;\n}\n\nstruct bpf_map *bpf_map__inner_map(struct bpf_map *map)\n{\n\tif (!bpf_map_type__is_map_in_map(map->def.type))\n\t\treturn errno = EINVAL, NULL;\n\n\treturn map->inner_map;\n}\n\nint bpf_map__set_max_entries(struct bpf_map *map, __u32 max_entries)\n{\n\tif (map->obj->loaded)\n\t\treturn libbpf_err(-EBUSY);\n\n\tmap->def.max_entries = max_entries;\n\n\t \n\tif (map_is_ringbuf(map))\n\t\tmap->def.max_entries = adjust_ringbuf_sz(map->def.max_entries);\n\n\treturn 0;\n}\n\nstatic int\nbpf_object__probe_loading(struct bpf_object *obj)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tstruct bpf_insn insns[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint ret, insn_cnt = ARRAY_SIZE(insns);\n\n\tif (obj->gen_loader)\n\t\treturn 0;\n\n\tret = bump_rlimit_memlock();\n\tif (ret)\n\t\tpr_warn(\"Failed to bump RLIMIT_MEMLOCK (err = %d), you might need to do it explicitly!\\n\", ret);\n\n\t \n\tret = bpf_prog_load(BPF_PROG_TYPE_SOCKET_FILTER, NULL, \"GPL\", insns, insn_cnt, NULL);\n\tif (ret < 0)\n\t\tret = bpf_prog_load(BPF_PROG_TYPE_TRACEPOINT, NULL, \"GPL\", insns, insn_cnt, NULL);\n\tif (ret < 0) {\n\t\tret = errno;\n\t\tcp = libbpf_strerror_r(ret, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"Error in %s():%s(%d). Couldn't load trivial BPF \"\n\t\t\t\"program. Make sure your kernel supports BPF \"\n\t\t\t\"(CONFIG_BPF_SYSCALL=y) and/or that RLIMIT_MEMLOCK is \"\n\t\t\t\"set to big enough value.\\n\", __func__, cp, ret);\n\t\treturn -ret;\n\t}\n\tclose(ret);\n\n\treturn 0;\n}\n\nstatic int probe_fd(int fd)\n{\n\tif (fd >= 0)\n\t\tclose(fd);\n\treturn fd >= 0;\n}\n\nstatic int probe_kern_prog_name(void)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, prog_name);\n\tstruct bpf_insn insns[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.prog_type = BPF_PROG_TYPE_SOCKET_FILTER;\n\tattr.license = ptr_to_u64(\"GPL\");\n\tattr.insns = ptr_to_u64(insns);\n\tattr.insn_cnt = (__u32)ARRAY_SIZE(insns);\n\tlibbpf_strlcpy(attr.prog_name, \"libbpf_nametest\", sizeof(attr.prog_name));\n\n\t \n\tret = sys_bpf_prog_load(&attr, attr_sz, PROG_LOAD_ATTEMPTS);\n\treturn probe_fd(ret);\n}\n\nstatic int probe_kern_global_data(void)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tstruct bpf_insn insns[] = {\n\t\tBPF_LD_MAP_VALUE(BPF_REG_1, 0, 16),\n\t\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 42),\n\t\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint ret, map, insn_cnt = ARRAY_SIZE(insns);\n\n\tmap = bpf_map_create(BPF_MAP_TYPE_ARRAY, \"libbpf_global\", sizeof(int), 32, 1, NULL);\n\tif (map < 0) {\n\t\tret = -errno;\n\t\tcp = libbpf_strerror_r(ret, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"Error in %s():%s(%d). Couldn't create simple array map.\\n\",\n\t\t\t__func__, cp, -ret);\n\t\treturn ret;\n\t}\n\n\tinsns[0].imm = map;\n\n\tret = bpf_prog_load(BPF_PROG_TYPE_SOCKET_FILTER, NULL, \"GPL\", insns, insn_cnt, NULL);\n\tclose(map);\n\treturn probe_fd(ret);\n}\n\nstatic int probe_kern_btf(void)\n{\n\tstatic const char strs[] = \"\\0int\";\n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_INT_ENC(1, BTF_INT_SIGNED, 0, 32, 4),\n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_btf_func(void)\n{\n\tstatic const char strs[] = \"\\0int\\0x\\0a\";\n\t \n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_INT_ENC(1, BTF_INT_SIGNED, 0, 32, 4),   \n\t\t                                  \n\t\tBTF_TYPE_ENC(0, BTF_INFO_ENC(BTF_KIND_FUNC_PROTO, 0, 1), 0),\n\t\tBTF_PARAM_ENC(7, 1),\n\t\t                                      \n\t\tBTF_TYPE_ENC(5, BTF_INFO_ENC(BTF_KIND_FUNC, 0, 0), 2),\n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_btf_func_global(void)\n{\n\tstatic const char strs[] = \"\\0int\\0x\\0a\";\n\t \n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_INT_ENC(1, BTF_INT_SIGNED, 0, 32, 4),   \n\t\t                                  \n\t\tBTF_TYPE_ENC(0, BTF_INFO_ENC(BTF_KIND_FUNC_PROTO, 0, 1), 0),\n\t\tBTF_PARAM_ENC(7, 1),\n\t\t                      \n\t\tBTF_TYPE_ENC(5, BTF_INFO_ENC(BTF_KIND_FUNC, 0, BTF_FUNC_GLOBAL), 2),\n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_btf_datasec(void)\n{\n\tstatic const char strs[] = \"\\0x\\0.data\";\n\t \n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_INT_ENC(0, BTF_INT_SIGNED, 0, 32, 4),   \n\t\t                                       \n\t\tBTF_TYPE_ENC(1, BTF_INFO_ENC(BTF_KIND_VAR, 0, 0), 1),\n\t\tBTF_VAR_STATIC,\n\t\t                                 \n\t\tBTF_TYPE_ENC(3, BTF_INFO_ENC(BTF_KIND_DATASEC, 0, 1), 4),\n\t\tBTF_VAR_SECINFO_ENC(2, 0, 4),\n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_btf_float(void)\n{\n\tstatic const char strs[] = \"\\0float\";\n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_FLOAT_ENC(1, 4),\n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_btf_decl_tag(void)\n{\n\tstatic const char strs[] = \"\\0tag\";\n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_INT_ENC(0, BTF_INT_SIGNED, 0, 32, 4),   \n\t\t                                       \n\t\tBTF_TYPE_ENC(1, BTF_INFO_ENC(BTF_KIND_VAR, 0, 0), 1),\n\t\tBTF_VAR_STATIC,\n\t\t \n\t\tBTF_TYPE_DECL_TAG_ENC(1, 2, -1),\n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_btf_type_tag(void)\n{\n\tstatic const char strs[] = \"\\0tag\";\n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_INT_ENC(0, BTF_INT_SIGNED, 0, 32, 4),\t\t \n\t\t \n\t\tBTF_TYPE_TYPE_TAG_ENC(1, 1),\t\t\t\t \n\t\t \n\t\tBTF_TYPE_ENC(0, BTF_INFO_ENC(BTF_KIND_PTR, 0, 0), 2),\t \n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_array_mmap(void)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, opts, .map_flags = BPF_F_MMAPABLE);\n\tint fd;\n\n\tfd = bpf_map_create(BPF_MAP_TYPE_ARRAY, \"libbpf_mmap\", sizeof(int), sizeof(int), 1, &opts);\n\treturn probe_fd(fd);\n}\n\nstatic int probe_kern_exp_attach_type(void)\n{\n\tLIBBPF_OPTS(bpf_prog_load_opts, opts, .expected_attach_type = BPF_CGROUP_INET_SOCK_CREATE);\n\tstruct bpf_insn insns[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint fd, insn_cnt = ARRAY_SIZE(insns);\n\n\t \n\tfd = bpf_prog_load(BPF_PROG_TYPE_CGROUP_SOCK, NULL, \"GPL\", insns, insn_cnt, &opts);\n\treturn probe_fd(fd);\n}\n\nstatic int probe_kern_probe_read_kernel(void)\n{\n\tstruct bpf_insn insns[] = {\n\t\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\t \n\t\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\t \n\t\tBPF_MOV64_IMM(BPF_REG_2, 8),\t\t \n\t\tBPF_MOV64_IMM(BPF_REG_3, 0),\t\t \n\t\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_probe_read_kernel),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint fd, insn_cnt = ARRAY_SIZE(insns);\n\n\tfd = bpf_prog_load(BPF_PROG_TYPE_TRACEPOINT, NULL, \"GPL\", insns, insn_cnt, NULL);\n\treturn probe_fd(fd);\n}\n\nstatic int probe_prog_bind_map(void)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tstruct bpf_insn insns[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint ret, map, prog, insn_cnt = ARRAY_SIZE(insns);\n\n\tmap = bpf_map_create(BPF_MAP_TYPE_ARRAY, \"libbpf_det_bind\", sizeof(int), 32, 1, NULL);\n\tif (map < 0) {\n\t\tret = -errno;\n\t\tcp = libbpf_strerror_r(ret, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"Error in %s():%s(%d). Couldn't create simple array map.\\n\",\n\t\t\t__func__, cp, -ret);\n\t\treturn ret;\n\t}\n\n\tprog = bpf_prog_load(BPF_PROG_TYPE_SOCKET_FILTER, NULL, \"GPL\", insns, insn_cnt, NULL);\n\tif (prog < 0) {\n\t\tclose(map);\n\t\treturn 0;\n\t}\n\n\tret = bpf_prog_bind_map(prog, map, NULL);\n\n\tclose(map);\n\tclose(prog);\n\n\treturn ret >= 0;\n}\n\nstatic int probe_module_btf(void)\n{\n\tstatic const char strs[] = \"\\0int\";\n\t__u32 types[] = {\n\t\t \n\t\tBTF_TYPE_INT_ENC(1, BTF_INT_SIGNED, 0, 32, 4),\n\t};\n\tstruct bpf_btf_info info;\n\t__u32 len = sizeof(info);\n\tchar name[16];\n\tint fd, err;\n\n\tfd = libbpf__load_raw_btf((char *)types, sizeof(types), strs, sizeof(strs));\n\tif (fd < 0)\n\t\treturn 0;  \n\n\tmemset(&info, 0, sizeof(info));\n\tinfo.name = ptr_to_u64(name);\n\tinfo.name_len = sizeof(name);\n\n\t \n\terr = bpf_btf_get_info_by_fd(fd, &info, &len);\n\tclose(fd);\n\treturn !err;\n}\n\nstatic int probe_perf_link(void)\n{\n\tstruct bpf_insn insns[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint prog_fd, link_fd, err;\n\n\tprog_fd = bpf_prog_load(BPF_PROG_TYPE_TRACEPOINT, NULL, \"GPL\",\n\t\t\t\tinsns, ARRAY_SIZE(insns), NULL);\n\tif (prog_fd < 0)\n\t\treturn -errno;\n\n\t \n\tlink_fd = bpf_link_create(prog_fd, -1, BPF_PERF_EVENT, NULL);\n\terr = -errno;  \n\n\tif (link_fd >= 0)\n\t\tclose(link_fd);\n\tclose(prog_fd);\n\n\treturn link_fd < 0 && err == -EBADF;\n}\n\nstatic int probe_uprobe_multi_link(void)\n{\n\tLIBBPF_OPTS(bpf_prog_load_opts, load_opts,\n\t\t.expected_attach_type = BPF_TRACE_UPROBE_MULTI,\n\t);\n\tLIBBPF_OPTS(bpf_link_create_opts, link_opts);\n\tstruct bpf_insn insns[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint prog_fd, link_fd, err;\n\tunsigned long offset = 0;\n\n\tprog_fd = bpf_prog_load(BPF_PROG_TYPE_KPROBE, NULL, \"GPL\",\n\t\t\t\tinsns, ARRAY_SIZE(insns), &load_opts);\n\tif (prog_fd < 0)\n\t\treturn -errno;\n\n\t \n\tlink_opts.uprobe_multi.path = \"/\";\n\tlink_opts.uprobe_multi.offsets = &offset;\n\tlink_opts.uprobe_multi.cnt = 1;\n\n\tlink_fd = bpf_link_create(prog_fd, -1, BPF_TRACE_UPROBE_MULTI, &link_opts);\n\terr = -errno;  \n\n\tif (link_fd >= 0)\n\t\tclose(link_fd);\n\tclose(prog_fd);\n\n\treturn link_fd < 0 && err == -EBADF;\n}\n\nstatic int probe_kern_bpf_cookie(void)\n{\n\tstruct bpf_insn insns[] = {\n\t\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_get_attach_cookie),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tint ret, insn_cnt = ARRAY_SIZE(insns);\n\n\tret = bpf_prog_load(BPF_PROG_TYPE_KPROBE, NULL, \"GPL\", insns, insn_cnt, NULL);\n\treturn probe_fd(ret);\n}\n\nstatic int probe_kern_btf_enum64(void)\n{\n\tstatic const char strs[] = \"\\0enum64\";\n\t__u32 types[] = {\n\t\tBTF_TYPE_ENC(1, BTF_INFO_ENC(BTF_KIND_ENUM64, 0, 0), 8),\n\t};\n\n\treturn probe_fd(libbpf__load_raw_btf((char *)types, sizeof(types),\n\t\t\t\t\t     strs, sizeof(strs)));\n}\n\nstatic int probe_kern_syscall_wrapper(void);\n\nenum kern_feature_result {\n\tFEAT_UNKNOWN = 0,\n\tFEAT_SUPPORTED = 1,\n\tFEAT_MISSING = 2,\n};\n\ntypedef int (*feature_probe_fn)(void);\n\nstatic struct kern_feature_desc {\n\tconst char *desc;\n\tfeature_probe_fn probe;\n\tenum kern_feature_result res;\n} feature_probes[__FEAT_CNT] = {\n\t[FEAT_PROG_NAME] = {\n\t\t\"BPF program name\", probe_kern_prog_name,\n\t},\n\t[FEAT_GLOBAL_DATA] = {\n\t\t\"global variables\", probe_kern_global_data,\n\t},\n\t[FEAT_BTF] = {\n\t\t\"minimal BTF\", probe_kern_btf,\n\t},\n\t[FEAT_BTF_FUNC] = {\n\t\t\"BTF functions\", probe_kern_btf_func,\n\t},\n\t[FEAT_BTF_GLOBAL_FUNC] = {\n\t\t\"BTF global function\", probe_kern_btf_func_global,\n\t},\n\t[FEAT_BTF_DATASEC] = {\n\t\t\"BTF data section and variable\", probe_kern_btf_datasec,\n\t},\n\t[FEAT_ARRAY_MMAP] = {\n\t\t\"ARRAY map mmap()\", probe_kern_array_mmap,\n\t},\n\t[FEAT_EXP_ATTACH_TYPE] = {\n\t\t\"BPF_PROG_LOAD expected_attach_type attribute\",\n\t\tprobe_kern_exp_attach_type,\n\t},\n\t[FEAT_PROBE_READ_KERN] = {\n\t\t\"bpf_probe_read_kernel() helper\", probe_kern_probe_read_kernel,\n\t},\n\t[FEAT_PROG_BIND_MAP] = {\n\t\t\"BPF_PROG_BIND_MAP support\", probe_prog_bind_map,\n\t},\n\t[FEAT_MODULE_BTF] = {\n\t\t\"module BTF support\", probe_module_btf,\n\t},\n\t[FEAT_BTF_FLOAT] = {\n\t\t\"BTF_KIND_FLOAT support\", probe_kern_btf_float,\n\t},\n\t[FEAT_PERF_LINK] = {\n\t\t\"BPF perf link support\", probe_perf_link,\n\t},\n\t[FEAT_BTF_DECL_TAG] = {\n\t\t\"BTF_KIND_DECL_TAG support\", probe_kern_btf_decl_tag,\n\t},\n\t[FEAT_BTF_TYPE_TAG] = {\n\t\t\"BTF_KIND_TYPE_TAG support\", probe_kern_btf_type_tag,\n\t},\n\t[FEAT_MEMCG_ACCOUNT] = {\n\t\t\"memcg-based memory accounting\", probe_memcg_account,\n\t},\n\t[FEAT_BPF_COOKIE] = {\n\t\t\"BPF cookie support\", probe_kern_bpf_cookie,\n\t},\n\t[FEAT_BTF_ENUM64] = {\n\t\t\"BTF_KIND_ENUM64 support\", probe_kern_btf_enum64,\n\t},\n\t[FEAT_SYSCALL_WRAPPER] = {\n\t\t\"Kernel using syscall wrapper\", probe_kern_syscall_wrapper,\n\t},\n\t[FEAT_UPROBE_MULTI_LINK] = {\n\t\t\"BPF multi-uprobe link support\", probe_uprobe_multi_link,\n\t},\n};\n\nbool kernel_supports(const struct bpf_object *obj, enum kern_feature_id feat_id)\n{\n\tstruct kern_feature_desc *feat = &feature_probes[feat_id];\n\tint ret;\n\n\tif (obj && obj->gen_loader)\n\t\t \n\t\treturn true;\n\n\tif (READ_ONCE(feat->res) == FEAT_UNKNOWN) {\n\t\tret = feat->probe();\n\t\tif (ret > 0) {\n\t\t\tWRITE_ONCE(feat->res, FEAT_SUPPORTED);\n\t\t} else if (ret == 0) {\n\t\t\tWRITE_ONCE(feat->res, FEAT_MISSING);\n\t\t} else {\n\t\t\tpr_warn(\"Detection of kernel %s support failed: %d\\n\", feat->desc, ret);\n\t\t\tWRITE_ONCE(feat->res, FEAT_MISSING);\n\t\t}\n\t}\n\n\treturn READ_ONCE(feat->res) == FEAT_SUPPORTED;\n}\n\nstatic bool map_is_reuse_compat(const struct bpf_map *map, int map_fd)\n{\n\tstruct bpf_map_info map_info;\n\tchar msg[STRERR_BUFSIZE];\n\t__u32 map_info_len = sizeof(map_info);\n\tint err;\n\n\tmemset(&map_info, 0, map_info_len);\n\terr = bpf_map_get_info_by_fd(map_fd, &map_info, &map_info_len);\n\tif (err && errno == EINVAL)\n\t\terr = bpf_get_map_info_from_fdinfo(map_fd, &map_info);\n\tif (err) {\n\t\tpr_warn(\"failed to get map info for map FD %d: %s\\n\", map_fd,\n\t\t\tlibbpf_strerror_r(errno, msg, sizeof(msg)));\n\t\treturn false;\n\t}\n\n\treturn (map_info.type == map->def.type &&\n\t\tmap_info.key_size == map->def.key_size &&\n\t\tmap_info.value_size == map->def.value_size &&\n\t\tmap_info.max_entries == map->def.max_entries &&\n\t\tmap_info.map_flags == map->def.map_flags &&\n\t\tmap_info.map_extra == map->map_extra);\n}\n\nstatic int\nbpf_object__reuse_map(struct bpf_map *map)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tint err, pin_fd;\n\n\tpin_fd = bpf_obj_get(map->pin_path);\n\tif (pin_fd < 0) {\n\t\terr = -errno;\n\t\tif (err == -ENOENT) {\n\t\t\tpr_debug(\"found no pinned map to reuse at '%s'\\n\",\n\t\t\t\t map->pin_path);\n\t\t\treturn 0;\n\t\t}\n\n\t\tcp = libbpf_strerror_r(-err, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"couldn't retrieve pinned map '%s': %s\\n\",\n\t\t\tmap->pin_path, cp);\n\t\treturn err;\n\t}\n\n\tif (!map_is_reuse_compat(map, pin_fd)) {\n\t\tpr_warn(\"couldn't reuse pinned map at '%s': parameter mismatch\\n\",\n\t\t\tmap->pin_path);\n\t\tclose(pin_fd);\n\t\treturn -EINVAL;\n\t}\n\n\terr = bpf_map__reuse_fd(map, pin_fd);\n\tclose(pin_fd);\n\tif (err)\n\t\treturn err;\n\n\tmap->pinned = true;\n\tpr_debug(\"reused pinned map at '%s'\\n\", map->pin_path);\n\n\treturn 0;\n}\n\nstatic int\nbpf_object__populate_internal_map(struct bpf_object *obj, struct bpf_map *map)\n{\n\tenum libbpf_map_type map_type = map->libbpf_type;\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tint err, zero = 0;\n\n\tif (obj->gen_loader) {\n\t\tbpf_gen__map_update_elem(obj->gen_loader, map - obj->maps,\n\t\t\t\t\t map->mmaped, map->def.value_size);\n\t\tif (map_type == LIBBPF_MAP_RODATA || map_type == LIBBPF_MAP_KCONFIG)\n\t\t\tbpf_gen__map_freeze(obj->gen_loader, map - obj->maps);\n\t\treturn 0;\n\t}\n\terr = bpf_map_update_elem(map->fd, &zero, map->mmaped, 0);\n\tif (err) {\n\t\terr = -errno;\n\t\tcp = libbpf_strerror_r(err, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"Error setting initial map(%s) contents: %s\\n\",\n\t\t\tmap->name, cp);\n\t\treturn err;\n\t}\n\n\t \n\tif (map_type == LIBBPF_MAP_RODATA || map_type == LIBBPF_MAP_KCONFIG) {\n\t\terr = bpf_map_freeze(map->fd);\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tcp = libbpf_strerror_r(err, errmsg, sizeof(errmsg));\n\t\t\tpr_warn(\"Error freezing map(%s) as read-only: %s\\n\",\n\t\t\t\tmap->name, cp);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void bpf_map__destroy(struct bpf_map *map);\n\nstatic int bpf_object__create_map(struct bpf_object *obj, struct bpf_map *map, bool is_inner)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, create_attr);\n\tstruct bpf_map_def *def = &map->def;\n\tconst char *map_name = NULL;\n\tint err = 0;\n\n\tif (kernel_supports(obj, FEAT_PROG_NAME))\n\t\tmap_name = map->name;\n\tcreate_attr.map_ifindex = map->map_ifindex;\n\tcreate_attr.map_flags = def->map_flags;\n\tcreate_attr.numa_node = map->numa_node;\n\tcreate_attr.map_extra = map->map_extra;\n\n\tif (bpf_map__is_struct_ops(map))\n\t\tcreate_attr.btf_vmlinux_value_type_id = map->btf_vmlinux_value_type_id;\n\n\tif (obj->btf && btf__fd(obj->btf) >= 0) {\n\t\tcreate_attr.btf_fd = btf__fd(obj->btf);\n\t\tcreate_attr.btf_key_type_id = map->btf_key_type_id;\n\t\tcreate_attr.btf_value_type_id = map->btf_value_type_id;\n\t}\n\n\tif (bpf_map_type__is_map_in_map(def->type)) {\n\t\tif (map->inner_map) {\n\t\t\terr = bpf_object__create_map(obj, map->inner_map, true);\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"map '%s': failed to create inner map: %d\\n\",\n\t\t\t\t\tmap->name, err);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\tmap->inner_map_fd = bpf_map__fd(map->inner_map);\n\t\t}\n\t\tif (map->inner_map_fd >= 0)\n\t\t\tcreate_attr.inner_map_fd = map->inner_map_fd;\n\t}\n\n\tswitch (def->type) {\n\tcase BPF_MAP_TYPE_PERF_EVENT_ARRAY:\n\tcase BPF_MAP_TYPE_CGROUP_ARRAY:\n\tcase BPF_MAP_TYPE_STACK_TRACE:\n\tcase BPF_MAP_TYPE_ARRAY_OF_MAPS:\n\tcase BPF_MAP_TYPE_HASH_OF_MAPS:\n\tcase BPF_MAP_TYPE_DEVMAP:\n\tcase BPF_MAP_TYPE_DEVMAP_HASH:\n\tcase BPF_MAP_TYPE_CPUMAP:\n\tcase BPF_MAP_TYPE_XSKMAP:\n\tcase BPF_MAP_TYPE_SOCKMAP:\n\tcase BPF_MAP_TYPE_SOCKHASH:\n\tcase BPF_MAP_TYPE_QUEUE:\n\tcase BPF_MAP_TYPE_STACK:\n\t\tcreate_attr.btf_fd = 0;\n\t\tcreate_attr.btf_key_type_id = 0;\n\t\tcreate_attr.btf_value_type_id = 0;\n\t\tmap->btf_key_type_id = 0;\n\t\tmap->btf_value_type_id = 0;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (obj->gen_loader) {\n\t\tbpf_gen__map_create(obj->gen_loader, def->type, map_name,\n\t\t\t\t    def->key_size, def->value_size, def->max_entries,\n\t\t\t\t    &create_attr, is_inner ? -1 : map - obj->maps);\n\t\t \n\t\tmap->fd = 0;\n\t} else {\n\t\tmap->fd = bpf_map_create(def->type, map_name,\n\t\t\t\t\t def->key_size, def->value_size,\n\t\t\t\t\t def->max_entries, &create_attr);\n\t}\n\tif (map->fd < 0 && (create_attr.btf_key_type_id ||\n\t\t\t    create_attr.btf_value_type_id)) {\n\t\tchar *cp, errmsg[STRERR_BUFSIZE];\n\n\t\terr = -errno;\n\t\tcp = libbpf_strerror_r(err, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"Error in bpf_create_map_xattr(%s):%s(%d). Retrying without BTF.\\n\",\n\t\t\tmap->name, cp, err);\n\t\tcreate_attr.btf_fd = 0;\n\t\tcreate_attr.btf_key_type_id = 0;\n\t\tcreate_attr.btf_value_type_id = 0;\n\t\tmap->btf_key_type_id = 0;\n\t\tmap->btf_value_type_id = 0;\n\t\tmap->fd = bpf_map_create(def->type, map_name,\n\t\t\t\t\t def->key_size, def->value_size,\n\t\t\t\t\t def->max_entries, &create_attr);\n\t}\n\n\terr = map->fd < 0 ? -errno : 0;\n\n\tif (bpf_map_type__is_map_in_map(def->type) && map->inner_map) {\n\t\tif (obj->gen_loader)\n\t\t\tmap->inner_map->fd = -1;\n\t\tbpf_map__destroy(map->inner_map);\n\t\tzfree(&map->inner_map);\n\t}\n\n\treturn err;\n}\n\nstatic int init_map_in_map_slots(struct bpf_object *obj, struct bpf_map *map)\n{\n\tconst struct bpf_map *targ_map;\n\tunsigned int i;\n\tint fd, err = 0;\n\n\tfor (i = 0; i < map->init_slots_sz; i++) {\n\t\tif (!map->init_slots[i])\n\t\t\tcontinue;\n\n\t\ttarg_map = map->init_slots[i];\n\t\tfd = bpf_map__fd(targ_map);\n\n\t\tif (obj->gen_loader) {\n\t\t\tbpf_gen__populate_outer_map(obj->gen_loader,\n\t\t\t\t\t\t    map - obj->maps, i,\n\t\t\t\t\t\t    targ_map - obj->maps);\n\t\t} else {\n\t\t\terr = bpf_map_update_elem(map->fd, &i, &fd, 0);\n\t\t}\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"map '%s': failed to initialize slot [%d] to map '%s' fd=%d: %d\\n\",\n\t\t\t\tmap->name, i, targ_map->name, fd, err);\n\t\t\treturn err;\n\t\t}\n\t\tpr_debug(\"map '%s': slot [%d] set to map '%s' fd=%d\\n\",\n\t\t\t map->name, i, targ_map->name, fd);\n\t}\n\n\tzfree(&map->init_slots);\n\tmap->init_slots_sz = 0;\n\n\treturn 0;\n}\n\nstatic int init_prog_array_slots(struct bpf_object *obj, struct bpf_map *map)\n{\n\tconst struct bpf_program *targ_prog;\n\tunsigned int i;\n\tint fd, err;\n\n\tif (obj->gen_loader)\n\t\treturn -ENOTSUP;\n\n\tfor (i = 0; i < map->init_slots_sz; i++) {\n\t\tif (!map->init_slots[i])\n\t\t\tcontinue;\n\n\t\ttarg_prog = map->init_slots[i];\n\t\tfd = bpf_program__fd(targ_prog);\n\n\t\terr = bpf_map_update_elem(map->fd, &i, &fd, 0);\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"map '%s': failed to initialize slot [%d] to prog '%s' fd=%d: %d\\n\",\n\t\t\t\tmap->name, i, targ_prog->name, fd, err);\n\t\t\treturn err;\n\t\t}\n\t\tpr_debug(\"map '%s': slot [%d] set to prog '%s' fd=%d\\n\",\n\t\t\t map->name, i, targ_prog->name, fd);\n\t}\n\n\tzfree(&map->init_slots);\n\tmap->init_slots_sz = 0;\n\n\treturn 0;\n}\n\nstatic int bpf_object_init_prog_arrays(struct bpf_object *obj)\n{\n\tstruct bpf_map *map;\n\tint i, err;\n\n\tfor (i = 0; i < obj->nr_maps; i++) {\n\t\tmap = &obj->maps[i];\n\n\t\tif (!map->init_slots_sz || map->def.type != BPF_MAP_TYPE_PROG_ARRAY)\n\t\t\tcontinue;\n\n\t\terr = init_prog_array_slots(obj, map);\n\t\tif (err < 0) {\n\t\t\tzclose(map->fd);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int map_set_def_max_entries(struct bpf_map *map)\n{\n\tif (map->def.type == BPF_MAP_TYPE_PERF_EVENT_ARRAY && !map->def.max_entries) {\n\t\tint nr_cpus;\n\n\t\tnr_cpus = libbpf_num_possible_cpus();\n\t\tif (nr_cpus < 0) {\n\t\t\tpr_warn(\"map '%s': failed to determine number of system CPUs: %d\\n\",\n\t\t\t\tmap->name, nr_cpus);\n\t\t\treturn nr_cpus;\n\t\t}\n\t\tpr_debug(\"map '%s': setting size to %d\\n\", map->name, nr_cpus);\n\t\tmap->def.max_entries = nr_cpus;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nbpf_object__create_maps(struct bpf_object *obj)\n{\n\tstruct bpf_map *map;\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tunsigned int i, j;\n\tint err;\n\tbool retried;\n\n\tfor (i = 0; i < obj->nr_maps; i++) {\n\t\tmap = &obj->maps[i];\n\n\t\t \n\t\tif (bpf_map__is_internal(map) && !kernel_supports(obj, FEAT_GLOBAL_DATA))\n\t\t\tmap->autocreate = false;\n\n\t\tif (!map->autocreate) {\n\t\t\tpr_debug(\"map '%s': skipped auto-creating...\\n\", map->name);\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = map_set_def_max_entries(map);\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\tretried = false;\nretry:\n\t\tif (map->pin_path) {\n\t\t\terr = bpf_object__reuse_map(map);\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"map '%s': error reusing pinned map\\n\",\n\t\t\t\t\tmap->name);\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\tif (retried && map->fd < 0) {\n\t\t\t\tpr_warn(\"map '%s': cannot find pinned map\\n\",\n\t\t\t\t\tmap->name);\n\t\t\t\terr = -ENOENT;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t}\n\n\t\tif (map->fd >= 0) {\n\t\t\tpr_debug(\"map '%s': skipping creation (preset fd=%d)\\n\",\n\t\t\t\t map->name, map->fd);\n\t\t} else {\n\t\t\terr = bpf_object__create_map(obj, map, false);\n\t\t\tif (err)\n\t\t\t\tgoto err_out;\n\n\t\t\tpr_debug(\"map '%s': created successfully, fd=%d\\n\",\n\t\t\t\t map->name, map->fd);\n\n\t\t\tif (bpf_map__is_internal(map)) {\n\t\t\t\terr = bpf_object__populate_internal_map(obj, map);\n\t\t\t\tif (err < 0) {\n\t\t\t\t\tzclose(map->fd);\n\t\t\t\t\tgoto err_out;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (map->init_slots_sz && map->def.type != BPF_MAP_TYPE_PROG_ARRAY) {\n\t\t\t\terr = init_map_in_map_slots(obj, map);\n\t\t\t\tif (err < 0) {\n\t\t\t\t\tzclose(map->fd);\n\t\t\t\t\tgoto err_out;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (map->pin_path && !map->pinned) {\n\t\t\terr = bpf_map__pin(map, NULL);\n\t\t\tif (err) {\n\t\t\t\tzclose(map->fd);\n\t\t\t\tif (!retried && err == -EEXIST) {\n\t\t\t\t\tretried = true;\n\t\t\t\t\tgoto retry;\n\t\t\t\t}\n\t\t\t\tpr_warn(\"map '%s': failed to auto-pin at '%s': %d\\n\",\n\t\t\t\t\tmap->name, map->pin_path, err);\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_out:\n\tcp = libbpf_strerror_r(err, errmsg, sizeof(errmsg));\n\tpr_warn(\"map '%s': failed to create: %s(%d)\\n\", map->name, cp, err);\n\tpr_perm_msg(err);\n\tfor (j = 0; j < i; j++)\n\t\tzclose(obj->maps[j].fd);\n\treturn err;\n}\n\nstatic bool bpf_core_is_flavor_sep(const char *s)\n{\n\t \n\treturn s[0] != '_' &&\t\t\t\t       \n\t       s[1] == '_' && s[2] == '_' && s[3] == '_' &&    \n\t       s[4] != '_';\t\t\t\t       \n}\n\n \nsize_t bpf_core_essential_name_len(const char *name)\n{\n\tsize_t n = strlen(name);\n\tint i;\n\n\tfor (i = n - 5; i >= 0; i--) {\n\t\tif (bpf_core_is_flavor_sep(name + i))\n\t\t\treturn i + 1;\n\t}\n\treturn n;\n}\n\nvoid bpf_core_free_cands(struct bpf_core_cand_list *cands)\n{\n\tif (!cands)\n\t\treturn;\n\n\tfree(cands->cands);\n\tfree(cands);\n}\n\nint bpf_core_add_cands(struct bpf_core_cand *local_cand,\n\t\t       size_t local_essent_len,\n\t\t       const struct btf *targ_btf,\n\t\t       const char *targ_btf_name,\n\t\t       int targ_start_id,\n\t\t       struct bpf_core_cand_list *cands)\n{\n\tstruct bpf_core_cand *new_cands, *cand;\n\tconst struct btf_type *t, *local_t;\n\tconst char *targ_name, *local_name;\n\tsize_t targ_essent_len;\n\tint n, i;\n\n\tlocal_t = btf__type_by_id(local_cand->btf, local_cand->id);\n\tlocal_name = btf__str_by_offset(local_cand->btf, local_t->name_off);\n\n\tn = btf__type_cnt(targ_btf);\n\tfor (i = targ_start_id; i < n; i++) {\n\t\tt = btf__type_by_id(targ_btf, i);\n\t\tif (!btf_kind_core_compat(t, local_t))\n\t\t\tcontinue;\n\n\t\ttarg_name = btf__name_by_offset(targ_btf, t->name_off);\n\t\tif (str_is_empty(targ_name))\n\t\t\tcontinue;\n\n\t\ttarg_essent_len = bpf_core_essential_name_len(targ_name);\n\t\tif (targ_essent_len != local_essent_len)\n\t\t\tcontinue;\n\n\t\tif (strncmp(local_name, targ_name, local_essent_len) != 0)\n\t\t\tcontinue;\n\n\t\tpr_debug(\"CO-RE relocating [%d] %s %s: found target candidate [%d] %s %s in [%s]\\n\",\n\t\t\t local_cand->id, btf_kind_str(local_t),\n\t\t\t local_name, i, btf_kind_str(t), targ_name,\n\t\t\t targ_btf_name);\n\t\tnew_cands = libbpf_reallocarray(cands->cands, cands->len + 1,\n\t\t\t\t\t      sizeof(*cands->cands));\n\t\tif (!new_cands)\n\t\t\treturn -ENOMEM;\n\n\t\tcand = &new_cands[cands->len];\n\t\tcand->btf = targ_btf;\n\t\tcand->id = i;\n\n\t\tcands->cands = new_cands;\n\t\tcands->len++;\n\t}\n\treturn 0;\n}\n\nstatic int load_module_btfs(struct bpf_object *obj)\n{\n\tstruct bpf_btf_info info;\n\tstruct module_btf *mod_btf;\n\tstruct btf *btf;\n\tchar name[64];\n\t__u32 id = 0, len;\n\tint err, fd;\n\n\tif (obj->btf_modules_loaded)\n\t\treturn 0;\n\n\tif (obj->gen_loader)\n\t\treturn 0;\n\n\t \n\tobj->btf_modules_loaded = true;\n\n\t \n\tif (!kernel_supports(obj, FEAT_MODULE_BTF))\n\t\treturn 0;\n\n\twhile (true) {\n\t\terr = bpf_btf_get_next_id(id, &id);\n\t\tif (err && errno == ENOENT)\n\t\t\treturn 0;\n\t\tif (err && errno == EPERM) {\n\t\t\tpr_debug(\"skipping module BTFs loading, missing privileges\\n\");\n\t\t\treturn 0;\n\t\t}\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"failed to iterate BTF objects: %d\\n\", err);\n\t\t\treturn err;\n\t\t}\n\n\t\tfd = bpf_btf_get_fd_by_id(id);\n\t\tif (fd < 0) {\n\t\t\tif (errno == ENOENT)\n\t\t\t\tcontinue;  \n\t\t\terr = -errno;\n\t\t\tpr_warn(\"failed to get BTF object #%d FD: %d\\n\", id, err);\n\t\t\treturn err;\n\t\t}\n\n\t\tlen = sizeof(info);\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.name = ptr_to_u64(name);\n\t\tinfo.name_len = sizeof(name);\n\n\t\terr = bpf_btf_get_info_by_fd(fd, &info, &len);\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"failed to get BTF object #%d info: %d\\n\", id, err);\n\t\t\tgoto err_out;\n\t\t}\n\n\t\t \n\t\tif (!info.kernel_btf || strcmp(name, \"vmlinux\") == 0) {\n\t\t\tclose(fd);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbtf = btf_get_from_fd(fd, obj->btf_vmlinux);\n\t\terr = libbpf_get_error(btf);\n\t\tif (err) {\n\t\t\tpr_warn(\"failed to load module [%s]'s BTF object #%d: %d\\n\",\n\t\t\t\tname, id, err);\n\t\t\tgoto err_out;\n\t\t}\n\n\t\terr = libbpf_ensure_mem((void **)&obj->btf_modules, &obj->btf_module_cap,\n\t\t\t\t\tsizeof(*obj->btf_modules), obj->btf_module_cnt + 1);\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\tmod_btf = &obj->btf_modules[obj->btf_module_cnt++];\n\n\t\tmod_btf->btf = btf;\n\t\tmod_btf->id = id;\n\t\tmod_btf->fd = fd;\n\t\tmod_btf->name = strdup(name);\n\t\tif (!mod_btf->name) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_out;\n\t\t}\n\t\tcontinue;\n\nerr_out:\n\t\tclose(fd);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic struct bpf_core_cand_list *\nbpf_core_find_cands(struct bpf_object *obj, const struct btf *local_btf, __u32 local_type_id)\n{\n\tstruct bpf_core_cand local_cand = {};\n\tstruct bpf_core_cand_list *cands;\n\tconst struct btf *main_btf;\n\tconst struct btf_type *local_t;\n\tconst char *local_name;\n\tsize_t local_essent_len;\n\tint err, i;\n\n\tlocal_cand.btf = local_btf;\n\tlocal_cand.id = local_type_id;\n\tlocal_t = btf__type_by_id(local_btf, local_type_id);\n\tif (!local_t)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tlocal_name = btf__name_by_offset(local_btf, local_t->name_off);\n\tif (str_is_empty(local_name))\n\t\treturn ERR_PTR(-EINVAL);\n\tlocal_essent_len = bpf_core_essential_name_len(local_name);\n\n\tcands = calloc(1, sizeof(*cands));\n\tif (!cands)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t \n\tmain_btf = obj->btf_vmlinux_override ?: obj->btf_vmlinux;\n\terr = bpf_core_add_cands(&local_cand, local_essent_len, main_btf, \"vmlinux\", 1, cands);\n\tif (err)\n\t\tgoto err_out;\n\n\t \n\tif (cands->len)\n\t\treturn cands;\n\n\t \n\tif (obj->btf_vmlinux_override)\n\t\treturn cands;\n\n\t \n\terr = load_module_btfs(obj);\n\tif (err)\n\t\tgoto err_out;\n\n\tfor (i = 0; i < obj->btf_module_cnt; i++) {\n\t\terr = bpf_core_add_cands(&local_cand, local_essent_len,\n\t\t\t\t\t obj->btf_modules[i].btf,\n\t\t\t\t\t obj->btf_modules[i].name,\n\t\t\t\t\t btf__type_cnt(obj->btf_vmlinux),\n\t\t\t\t\t cands);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t}\n\n\treturn cands;\nerr_out:\n\tbpf_core_free_cands(cands);\n\treturn ERR_PTR(err);\n}\n\n \nint bpf_core_types_are_compat(const struct btf *local_btf, __u32 local_id,\n\t\t\t      const struct btf *targ_btf, __u32 targ_id)\n{\n\treturn __bpf_core_types_are_compat(local_btf, local_id, targ_btf, targ_id, 32);\n}\n\nint bpf_core_types_match(const struct btf *local_btf, __u32 local_id,\n\t\t\t const struct btf *targ_btf, __u32 targ_id)\n{\n\treturn __bpf_core_types_match(local_btf, local_id, targ_btf, targ_id, false, 32);\n}\n\nstatic size_t bpf_core_hash_fn(const long key, void *ctx)\n{\n\treturn key;\n}\n\nstatic bool bpf_core_equal_fn(const long k1, const long k2, void *ctx)\n{\n\treturn k1 == k2;\n}\n\nstatic int record_relo_core(struct bpf_program *prog,\n\t\t\t    const struct bpf_core_relo *core_relo, int insn_idx)\n{\n\tstruct reloc_desc *relos, *relo;\n\n\trelos = libbpf_reallocarray(prog->reloc_desc,\n\t\t\t\t    prog->nr_reloc + 1, sizeof(*relos));\n\tif (!relos)\n\t\treturn -ENOMEM;\n\trelo = &relos[prog->nr_reloc];\n\trelo->type = RELO_CORE;\n\trelo->insn_idx = insn_idx;\n\trelo->core_relo = core_relo;\n\tprog->reloc_desc = relos;\n\tprog->nr_reloc++;\n\treturn 0;\n}\n\nstatic const struct bpf_core_relo *find_relo_core(struct bpf_program *prog, int insn_idx)\n{\n\tstruct reloc_desc *relo;\n\tint i;\n\n\tfor (i = 0; i < prog->nr_reloc; i++) {\n\t\trelo = &prog->reloc_desc[i];\n\t\tif (relo->type != RELO_CORE || relo->insn_idx != insn_idx)\n\t\t\tcontinue;\n\n\t\treturn relo->core_relo;\n\t}\n\n\treturn NULL;\n}\n\nstatic int bpf_core_resolve_relo(struct bpf_program *prog,\n\t\t\t\t const struct bpf_core_relo *relo,\n\t\t\t\t int relo_idx,\n\t\t\t\t const struct btf *local_btf,\n\t\t\t\t struct hashmap *cand_cache,\n\t\t\t\t struct bpf_core_relo_res *targ_res)\n{\n\tstruct bpf_core_spec specs_scratch[3] = {};\n\tstruct bpf_core_cand_list *cands = NULL;\n\tconst char *prog_name = prog->name;\n\tconst struct btf_type *local_type;\n\tconst char *local_name;\n\t__u32 local_id = relo->type_id;\n\tint err;\n\n\tlocal_type = btf__type_by_id(local_btf, local_id);\n\tif (!local_type)\n\t\treturn -EINVAL;\n\n\tlocal_name = btf__name_by_offset(local_btf, local_type->name_off);\n\tif (!local_name)\n\t\treturn -EINVAL;\n\n\tif (relo->kind != BPF_CORE_TYPE_ID_LOCAL &&\n\t    !hashmap__find(cand_cache, local_id, &cands)) {\n\t\tcands = bpf_core_find_cands(prog->obj, local_btf, local_id);\n\t\tif (IS_ERR(cands)) {\n\t\t\tpr_warn(\"prog '%s': relo #%d: target candidate search failed for [%d] %s %s: %ld\\n\",\n\t\t\t\tprog_name, relo_idx, local_id, btf_kind_str(local_type),\n\t\t\t\tlocal_name, PTR_ERR(cands));\n\t\t\treturn PTR_ERR(cands);\n\t\t}\n\t\terr = hashmap__set(cand_cache, local_id, cands, NULL, NULL);\n\t\tif (err) {\n\t\t\tbpf_core_free_cands(cands);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn bpf_core_calc_relo_insn(prog_name, relo, relo_idx, local_btf, cands, specs_scratch,\n\t\t\t\t       targ_res);\n}\n\nstatic int\nbpf_object__relocate_core(struct bpf_object *obj, const char *targ_btf_path)\n{\n\tconst struct btf_ext_info_sec *sec;\n\tstruct bpf_core_relo_res targ_res;\n\tconst struct bpf_core_relo *rec;\n\tconst struct btf_ext_info *seg;\n\tstruct hashmap_entry *entry;\n\tstruct hashmap *cand_cache = NULL;\n\tstruct bpf_program *prog;\n\tstruct bpf_insn *insn;\n\tconst char *sec_name;\n\tint i, err = 0, insn_idx, sec_idx, sec_num;\n\n\tif (obj->btf_ext->core_relo_info.len == 0)\n\t\treturn 0;\n\n\tif (targ_btf_path) {\n\t\tobj->btf_vmlinux_override = btf__parse(targ_btf_path, NULL);\n\t\terr = libbpf_get_error(obj->btf_vmlinux_override);\n\t\tif (err) {\n\t\t\tpr_warn(\"failed to parse target BTF: %d\\n\", err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tcand_cache = hashmap__new(bpf_core_hash_fn, bpf_core_equal_fn, NULL);\n\tif (IS_ERR(cand_cache)) {\n\t\terr = PTR_ERR(cand_cache);\n\t\tgoto out;\n\t}\n\n\tseg = &obj->btf_ext->core_relo_info;\n\tsec_num = 0;\n\tfor_each_btf_ext_sec(seg, sec) {\n\t\tsec_idx = seg->sec_idxs[sec_num];\n\t\tsec_num++;\n\n\t\tsec_name = btf__name_by_offset(obj->btf, sec->sec_name_off);\n\t\tif (str_is_empty(sec_name)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tpr_debug(\"sec '%s': found %d CO-RE relocations\\n\", sec_name, sec->num_info);\n\n\t\tfor_each_btf_ext_rec(seg, sec, i, rec) {\n\t\t\tif (rec->insn_off % BPF_INSN_SZ)\n\t\t\t\treturn -EINVAL;\n\t\t\tinsn_idx = rec->insn_off / BPF_INSN_SZ;\n\t\t\tprog = find_prog_by_sec_insn(obj, sec_idx, insn_idx);\n\t\t\tif (!prog) {\n\t\t\t\t \n\t\t\t\tpr_debug(\"sec '%s': skipping CO-RE relocation #%d for insn #%d belonging to eliminated weak subprogram\\n\",\n\t\t\t\t\t sec_name, i, insn_idx);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t \n\t\t\tif (!prog->autoload)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tinsn_idx = insn_idx - prog->sec_insn_off;\n\t\t\tif (insn_idx >= prog->insns_cnt)\n\t\t\t\treturn -EINVAL;\n\t\t\tinsn = &prog->insns[insn_idx];\n\n\t\t\terr = record_relo_core(prog, rec, insn_idx);\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"prog '%s': relo #%d: failed to record relocation: %d\\n\",\n\t\t\t\t\tprog->name, i, err);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tif (prog->obj->gen_loader)\n\t\t\t\tcontinue;\n\n\t\t\terr = bpf_core_resolve_relo(prog, rec, i, obj->btf, cand_cache, &targ_res);\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"prog '%s': relo #%d: failed to relocate: %d\\n\",\n\t\t\t\t\tprog->name, i, err);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\terr = bpf_core_patch_insn(prog->name, insn, insn_idx, rec, i, &targ_res);\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"prog '%s': relo #%d: failed to patch insn #%u: %d\\n\",\n\t\t\t\t\tprog->name, i, insn_idx, err);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\nout:\n\t \n\tbtf__free(obj->btf_vmlinux_override);\n\tobj->btf_vmlinux_override = NULL;\n\n\tif (!IS_ERR_OR_NULL(cand_cache)) {\n\t\thashmap__for_each_entry(cand_cache, entry, i) {\n\t\t\tbpf_core_free_cands(entry->pvalue);\n\t\t}\n\t\thashmap__free(cand_cache);\n\t}\n\treturn err;\n}\n\n \n#define POISON_LDIMM64_MAP_BASE 2001000000\n#define POISON_LDIMM64_MAP_PFX \"200100\"\n\nstatic void poison_map_ldimm64(struct bpf_program *prog, int relo_idx,\n\t\t\t       int insn_idx, struct bpf_insn *insn,\n\t\t\t       int map_idx, const struct bpf_map *map)\n{\n\tint i;\n\n\tpr_debug(\"prog '%s': relo #%d: poisoning insn #%d that loads map #%d '%s'\\n\",\n\t\t prog->name, relo_idx, insn_idx, map_idx, map->name);\n\n\t \n\tfor (i = 0; i < 2; i++) {\n\t\tinsn->code = BPF_JMP | BPF_CALL;\n\t\tinsn->dst_reg = 0;\n\t\tinsn->src_reg = 0;\n\t\tinsn->off = 0;\n\t\t \n\t\tinsn->imm = POISON_LDIMM64_MAP_BASE + map_idx;\n\n\t\tinsn++;\n\t}\n}\n\n \n#define POISON_CALL_KFUNC_BASE 2002000000\n#define POISON_CALL_KFUNC_PFX \"2002\"\n\nstatic void poison_kfunc_call(struct bpf_program *prog, int relo_idx,\n\t\t\t      int insn_idx, struct bpf_insn *insn,\n\t\t\t      int ext_idx, const struct extern_desc *ext)\n{\n\tpr_debug(\"prog '%s': relo #%d: poisoning insn #%d that calls kfunc '%s'\\n\",\n\t\t prog->name, relo_idx, insn_idx, ext->name);\n\n\t \n\tinsn->code = BPF_JMP | BPF_CALL;\n\tinsn->dst_reg = 0;\n\tinsn->src_reg = 0;\n\tinsn->off = 0;\n\t \n\tinsn->imm = POISON_CALL_KFUNC_BASE + ext_idx;\n}\n\n \nstatic int\nbpf_object__relocate_data(struct bpf_object *obj, struct bpf_program *prog)\n{\n\tint i;\n\n\tfor (i = 0; i < prog->nr_reloc; i++) {\n\t\tstruct reloc_desc *relo = &prog->reloc_desc[i];\n\t\tstruct bpf_insn *insn = &prog->insns[relo->insn_idx];\n\t\tconst struct bpf_map *map;\n\t\tstruct extern_desc *ext;\n\n\t\tswitch (relo->type) {\n\t\tcase RELO_LD64:\n\t\t\tmap = &obj->maps[relo->map_idx];\n\t\t\tif (obj->gen_loader) {\n\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_MAP_IDX;\n\t\t\t\tinsn[0].imm = relo->map_idx;\n\t\t\t} else if (map->autocreate) {\n\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_MAP_FD;\n\t\t\t\tinsn[0].imm = map->fd;\n\t\t\t} else {\n\t\t\t\tpoison_map_ldimm64(prog, i, relo->insn_idx, insn,\n\t\t\t\t\t\t   relo->map_idx, map);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RELO_DATA:\n\t\t\tmap = &obj->maps[relo->map_idx];\n\t\t\tinsn[1].imm = insn[0].imm + relo->sym_off;\n\t\t\tif (obj->gen_loader) {\n\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_MAP_IDX_VALUE;\n\t\t\t\tinsn[0].imm = relo->map_idx;\n\t\t\t} else if (map->autocreate) {\n\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_MAP_VALUE;\n\t\t\t\tinsn[0].imm = map->fd;\n\t\t\t} else {\n\t\t\t\tpoison_map_ldimm64(prog, i, relo->insn_idx, insn,\n\t\t\t\t\t\t   relo->map_idx, map);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RELO_EXTERN_LD64:\n\t\t\text = &obj->externs[relo->ext_idx];\n\t\t\tif (ext->type == EXT_KCFG) {\n\t\t\t\tif (obj->gen_loader) {\n\t\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_MAP_IDX_VALUE;\n\t\t\t\t\tinsn[0].imm = obj->kconfig_map_idx;\n\t\t\t\t} else {\n\t\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_MAP_VALUE;\n\t\t\t\t\tinsn[0].imm = obj->maps[obj->kconfig_map_idx].fd;\n\t\t\t\t}\n\t\t\t\tinsn[1].imm = ext->kcfg.data_off;\n\t\t\t} else   {\n\t\t\t\tif (ext->ksym.type_id && ext->is_set) {  \n\t\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_BTF_ID;\n\t\t\t\t\tinsn[0].imm = ext->ksym.kernel_btf_id;\n\t\t\t\t\tinsn[1].imm = ext->ksym.kernel_btf_obj_fd;\n\t\t\t\t} else {  \n\t\t\t\t\tinsn[0].imm = (__u32)ext->ksym.addr;\n\t\t\t\t\tinsn[1].imm = ext->ksym.addr >> 32;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RELO_EXTERN_CALL:\n\t\t\text = &obj->externs[relo->ext_idx];\n\t\t\tinsn[0].src_reg = BPF_PSEUDO_KFUNC_CALL;\n\t\t\tif (ext->is_set) {\n\t\t\t\tinsn[0].imm = ext->ksym.kernel_btf_id;\n\t\t\t\tinsn[0].off = ext->ksym.btf_fd_idx;\n\t\t\t} else {  \n\t\t\t\tpoison_kfunc_call(prog, i, relo->insn_idx, insn,\n\t\t\t\t\t\t  relo->ext_idx, ext);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RELO_SUBPROG_ADDR:\n\t\t\tif (insn[0].src_reg != BPF_PSEUDO_FUNC) {\n\t\t\t\tpr_warn(\"prog '%s': relo #%d: bad insn\\n\",\n\t\t\t\t\tprog->name, i);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t \n\t\t\tbreak;\n\t\tcase RELO_CALL:\n\t\t\t \n\t\t\tbreak;\n\t\tcase RELO_CORE:\n\t\t\t \n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_warn(\"prog '%s': relo #%d: bad relo type %d\\n\",\n\t\t\t\tprog->name, i, relo->type);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int adjust_prog_btf_ext_info(const struct bpf_object *obj,\n\t\t\t\t    const struct bpf_program *prog,\n\t\t\t\t    const struct btf_ext_info *ext_info,\n\t\t\t\t    void **prog_info, __u32 *prog_rec_cnt,\n\t\t\t\t    __u32 *prog_rec_sz)\n{\n\tvoid *copy_start = NULL, *copy_end = NULL;\n\tvoid *rec, *rec_end, *new_prog_info;\n\tconst struct btf_ext_info_sec *sec;\n\tsize_t old_sz, new_sz;\n\tint i, sec_num, sec_idx, off_adj;\n\n\tsec_num = 0;\n\tfor_each_btf_ext_sec(ext_info, sec) {\n\t\tsec_idx = ext_info->sec_idxs[sec_num];\n\t\tsec_num++;\n\t\tif (prog->sec_idx != sec_idx)\n\t\t\tcontinue;\n\n\t\tfor_each_btf_ext_rec(ext_info, sec, i, rec) {\n\t\t\t__u32 insn_off = *(__u32 *)rec / BPF_INSN_SZ;\n\n\t\t\tif (insn_off < prog->sec_insn_off)\n\t\t\t\tcontinue;\n\t\t\tif (insn_off >= prog->sec_insn_off + prog->sec_insn_cnt)\n\t\t\t\tbreak;\n\n\t\t\tif (!copy_start)\n\t\t\t\tcopy_start = rec;\n\t\t\tcopy_end = rec + ext_info->rec_size;\n\t\t}\n\n\t\tif (!copy_start)\n\t\t\treturn -ENOENT;\n\n\t\t \n\t\told_sz = (size_t)(*prog_rec_cnt) * ext_info->rec_size;\n\t\tnew_sz = old_sz + (copy_end - copy_start);\n\t\tnew_prog_info = realloc(*prog_info, new_sz);\n\t\tif (!new_prog_info)\n\t\t\treturn -ENOMEM;\n\t\t*prog_info = new_prog_info;\n\t\t*prog_rec_cnt = new_sz / ext_info->rec_size;\n\t\tmemcpy(new_prog_info + old_sz, copy_start, copy_end - copy_start);\n\n\t\t \n\t\toff_adj = prog->sub_insn_off - prog->sec_insn_off;\n\t\trec = new_prog_info + old_sz;\n\t\trec_end = new_prog_info + new_sz;\n\t\tfor (; rec < rec_end; rec += ext_info->rec_size) {\n\t\t\t__u32 *insn_off = rec;\n\n\t\t\t*insn_off = *insn_off / BPF_INSN_SZ + off_adj;\n\t\t}\n\t\t*prog_rec_sz = ext_info->rec_size;\n\t\treturn 0;\n\t}\n\n\treturn -ENOENT;\n}\n\nstatic int\nreloc_prog_func_and_line_info(const struct bpf_object *obj,\n\t\t\t      struct bpf_program *main_prog,\n\t\t\t      const struct bpf_program *prog)\n{\n\tint err;\n\n\t \n\tif (!obj->btf_ext || !kernel_supports(obj, FEAT_BTF_FUNC))\n\t\treturn 0;\n\n\t \n\tif (main_prog != prog && !main_prog->func_info)\n\t\tgoto line_info;\n\n\terr = adjust_prog_btf_ext_info(obj, prog, &obj->btf_ext->func_info,\n\t\t\t\t       &main_prog->func_info,\n\t\t\t\t       &main_prog->func_info_cnt,\n\t\t\t\t       &main_prog->func_info_rec_size);\n\tif (err) {\n\t\tif (err != -ENOENT) {\n\t\t\tpr_warn(\"prog '%s': error relocating .BTF.ext function info: %d\\n\",\n\t\t\t\tprog->name, err);\n\t\t\treturn err;\n\t\t}\n\t\tif (main_prog->func_info) {\n\t\t\t \n\t\t\tpr_warn(\"prog '%s': missing .BTF.ext function info.\\n\", prog->name);\n\t\t\treturn err;\n\t\t}\n\t\t \n\t\tpr_warn(\"prog '%s': missing .BTF.ext function info for the main program, skipping all of .BTF.ext func info.\\n\",\n\t\t\tprog->name);\n\t}\n\nline_info:\n\t \n\tif (main_prog != prog && !main_prog->line_info)\n\t\treturn 0;\n\n\terr = adjust_prog_btf_ext_info(obj, prog, &obj->btf_ext->line_info,\n\t\t\t\t       &main_prog->line_info,\n\t\t\t\t       &main_prog->line_info_cnt,\n\t\t\t\t       &main_prog->line_info_rec_size);\n\tif (err) {\n\t\tif (err != -ENOENT) {\n\t\t\tpr_warn(\"prog '%s': error relocating .BTF.ext line info: %d\\n\",\n\t\t\t\tprog->name, err);\n\t\t\treturn err;\n\t\t}\n\t\tif (main_prog->line_info) {\n\t\t\t \n\t\t\tpr_warn(\"prog '%s': missing .BTF.ext line info.\\n\", prog->name);\n\t\t\treturn err;\n\t\t}\n\t\t \n\t\tpr_warn(\"prog '%s': missing .BTF.ext line info for the main program, skipping all of .BTF.ext line info.\\n\",\n\t\t\tprog->name);\n\t}\n\treturn 0;\n}\n\nstatic int cmp_relo_by_insn_idx(const void *key, const void *elem)\n{\n\tsize_t insn_idx = *(const size_t *)key;\n\tconst struct reloc_desc *relo = elem;\n\n\tif (insn_idx == relo->insn_idx)\n\t\treturn 0;\n\treturn insn_idx < relo->insn_idx ? -1 : 1;\n}\n\nstatic struct reloc_desc *find_prog_insn_relo(const struct bpf_program *prog, size_t insn_idx)\n{\n\tif (!prog->nr_reloc)\n\t\treturn NULL;\n\treturn bsearch(&insn_idx, prog->reloc_desc, prog->nr_reloc,\n\t\t       sizeof(*prog->reloc_desc), cmp_relo_by_insn_idx);\n}\n\nstatic int append_subprog_relos(struct bpf_program *main_prog, struct bpf_program *subprog)\n{\n\tint new_cnt = main_prog->nr_reloc + subprog->nr_reloc;\n\tstruct reloc_desc *relos;\n\tint i;\n\n\tif (main_prog == subprog)\n\t\treturn 0;\n\trelos = libbpf_reallocarray(main_prog->reloc_desc, new_cnt, sizeof(*relos));\n\t \n\tif (!relos && new_cnt)\n\t\treturn -ENOMEM;\n\tif (subprog->nr_reloc)\n\t\tmemcpy(relos + main_prog->nr_reloc, subprog->reloc_desc,\n\t\t       sizeof(*relos) * subprog->nr_reloc);\n\n\tfor (i = main_prog->nr_reloc; i < new_cnt; i++)\n\t\trelos[i].insn_idx += subprog->sub_insn_off;\n\t \n\tmain_prog->reloc_desc = relos;\n\tmain_prog->nr_reloc = new_cnt;\n\treturn 0;\n}\n\nstatic int\nbpf_object__reloc_code(struct bpf_object *obj, struct bpf_program *main_prog,\n\t\t       struct bpf_program *prog)\n{\n\tsize_t sub_insn_idx, insn_idx, new_cnt;\n\tstruct bpf_program *subprog;\n\tstruct bpf_insn *insns, *insn;\n\tstruct reloc_desc *relo;\n\tint err;\n\n\terr = reloc_prog_func_and_line_info(obj, main_prog, prog);\n\tif (err)\n\t\treturn err;\n\n\tfor (insn_idx = 0; insn_idx < prog->sec_insn_cnt; insn_idx++) {\n\t\tinsn = &main_prog->insns[prog->sub_insn_off + insn_idx];\n\t\tif (!insn_is_subprog_call(insn) && !insn_is_pseudo_func(insn))\n\t\t\tcontinue;\n\n\t\trelo = find_prog_insn_relo(prog, insn_idx);\n\t\tif (relo && relo->type == RELO_EXTERN_CALL)\n\t\t\t \n\t\t\tcontinue;\n\t\tif (relo && relo->type != RELO_CALL && relo->type != RELO_SUBPROG_ADDR) {\n\t\t\tpr_warn(\"prog '%s': unexpected relo for insn #%zu, type %d\\n\",\n\t\t\t\tprog->name, insn_idx, relo->type);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\tif (relo) {\n\t\t\t \n\t\t\tif (relo->type == RELO_CALL)\n\t\t\t\tsub_insn_idx = relo->sym_off / BPF_INSN_SZ + insn->imm + 1;\n\t\t\telse\n\t\t\t\tsub_insn_idx = (relo->sym_off + insn->imm) / BPF_INSN_SZ;\n\t\t} else if (insn_is_pseudo_func(insn)) {\n\t\t\t \n\t\t\tpr_warn(\"prog '%s': missing subprog addr relo for insn #%zu\\n\",\n\t\t\t\tprog->name, insn_idx);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t} else {\n\t\t\t \n\t\t\tsub_insn_idx = prog->sec_insn_off + insn_idx + insn->imm + 1;\n\t\t}\n\n\t\t \n\t\tsubprog = find_prog_by_sec_insn(obj, obj->efile.text_shndx, sub_insn_idx);\n\t\tif (!subprog) {\n\t\t\tpr_warn(\"prog '%s': no .text section found yet sub-program call exists\\n\",\n\t\t\t\tprog->name);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\n\t\t \n\t\tif (subprog->sub_insn_off == 0) {\n\t\t\tsubprog->sub_insn_off = main_prog->insns_cnt;\n\n\t\t\tnew_cnt = main_prog->insns_cnt + subprog->insns_cnt;\n\t\t\tinsns = libbpf_reallocarray(main_prog->insns, new_cnt, sizeof(*insns));\n\t\t\tif (!insns) {\n\t\t\t\tpr_warn(\"prog '%s': failed to realloc prog code\\n\", main_prog->name);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tmain_prog->insns = insns;\n\t\t\tmain_prog->insns_cnt = new_cnt;\n\n\t\t\tmemcpy(main_prog->insns + subprog->sub_insn_off, subprog->insns,\n\t\t\t       subprog->insns_cnt * sizeof(*insns));\n\n\t\t\tpr_debug(\"prog '%s': added %zu insns from sub-prog '%s'\\n\",\n\t\t\t\t main_prog->name, subprog->insns_cnt, subprog->name);\n\n\t\t\t \n\t\t\terr = append_subprog_relos(main_prog, subprog);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\terr = bpf_object__reloc_code(obj, main_prog, subprog);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\t \n\t\tinsn = &main_prog->insns[prog->sub_insn_off + insn_idx];\n\t\t \n\t\tinsn->imm = subprog->sub_insn_off - (prog->sub_insn_off + insn_idx) - 1;\n\n\t\tpr_debug(\"prog '%s': insn #%zu relocated, imm %d points to subprog '%s' (now at %zu offset)\\n\",\n\t\t\t prog->name, insn_idx, insn->imm, subprog->name, subprog->sub_insn_off);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nbpf_object__relocate_calls(struct bpf_object *obj, struct bpf_program *prog)\n{\n\tstruct bpf_program *subprog;\n\tint i, err;\n\n\t \n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tsubprog = &obj->programs[i];\n\t\tif (!prog_is_subprog(obj, subprog))\n\t\t\tcontinue;\n\n\t\tsubprog->sub_insn_off = 0;\n\t}\n\n\terr = bpf_object__reloc_code(obj, prog, prog);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nstatic void\nbpf_object__free_relocs(struct bpf_object *obj)\n{\n\tstruct bpf_program *prog;\n\tint i;\n\n\t \n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tprog = &obj->programs[i];\n\t\tzfree(&prog->reloc_desc);\n\t\tprog->nr_reloc = 0;\n\t}\n}\n\nstatic int cmp_relocs(const void *_a, const void *_b)\n{\n\tconst struct reloc_desc *a = _a;\n\tconst struct reloc_desc *b = _b;\n\n\tif (a->insn_idx != b->insn_idx)\n\t\treturn a->insn_idx < b->insn_idx ? -1 : 1;\n\n\t \n\tif (a->type != b->type)\n\t\treturn a->type < b->type ? -1 : 1;\n\n\treturn 0;\n}\n\nstatic void bpf_object__sort_relos(struct bpf_object *obj)\n{\n\tint i;\n\n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tstruct bpf_program *p = &obj->programs[i];\n\n\t\tif (!p->nr_reloc)\n\t\t\tcontinue;\n\n\t\tqsort(p->reloc_desc, p->nr_reloc, sizeof(*p->reloc_desc), cmp_relocs);\n\t}\n}\n\nstatic int\nbpf_object__relocate(struct bpf_object *obj, const char *targ_btf_path)\n{\n\tstruct bpf_program *prog;\n\tsize_t i, j;\n\tint err;\n\n\tif (obj->btf_ext) {\n\t\terr = bpf_object__relocate_core(obj, targ_btf_path);\n\t\tif (err) {\n\t\t\tpr_warn(\"failed to perform CO-RE relocations: %d\\n\",\n\t\t\t\terr);\n\t\t\treturn err;\n\t\t}\n\t\tbpf_object__sort_relos(obj);\n\t}\n\n\t \n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tprog = &obj->programs[i];\n\t\tfor (j = 0; j < prog->nr_reloc; j++) {\n\t\t\tstruct reloc_desc *relo = &prog->reloc_desc[j];\n\t\t\tstruct bpf_insn *insn = &prog->insns[relo->insn_idx];\n\n\t\t\t \n\t\t\tif (relo->type == RELO_SUBPROG_ADDR)\n\t\t\t\tinsn[0].src_reg = BPF_PSEUDO_FUNC;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tprog = &obj->programs[i];\n\t\t \n\t\tif (prog_is_subprog(obj, prog))\n\t\t\tcontinue;\n\t\tif (!prog->autoload)\n\t\t\tcontinue;\n\n\t\terr = bpf_object__relocate_calls(obj, prog);\n\t\tif (err) {\n\t\t\tpr_warn(\"prog '%s': failed to relocate calls: %d\\n\",\n\t\t\t\tprog->name, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\t \n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tprog = &obj->programs[i];\n\t\tif (prog_is_subprog(obj, prog))\n\t\t\tcontinue;\n\t\tif (!prog->autoload)\n\t\t\tcontinue;\n\t\terr = bpf_object__relocate_data(obj, prog);\n\t\tif (err) {\n\t\t\tpr_warn(\"prog '%s': failed to relocate data references: %d\\n\",\n\t\t\t\tprog->name, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int bpf_object__collect_st_ops_relos(struct bpf_object *obj,\n\t\t\t\t\t    Elf64_Shdr *shdr, Elf_Data *data);\n\nstatic int bpf_object__collect_map_relos(struct bpf_object *obj,\n\t\t\t\t\t Elf64_Shdr *shdr, Elf_Data *data)\n{\n\tconst int bpf_ptr_sz = 8, host_ptr_sz = sizeof(void *);\n\tint i, j, nrels, new_sz;\n\tconst struct btf_var_secinfo *vi = NULL;\n\tconst struct btf_type *sec, *var, *def;\n\tstruct bpf_map *map = NULL, *targ_map = NULL;\n\tstruct bpf_program *targ_prog = NULL;\n\tbool is_prog_array, is_map_in_map;\n\tconst struct btf_member *member;\n\tconst char *name, *mname, *type;\n\tunsigned int moff;\n\tElf64_Sym *sym;\n\tElf64_Rel *rel;\n\tvoid *tmp;\n\n\tif (!obj->efile.btf_maps_sec_btf_id || !obj->btf)\n\t\treturn -EINVAL;\n\tsec = btf__type_by_id(obj->btf, obj->efile.btf_maps_sec_btf_id);\n\tif (!sec)\n\t\treturn -EINVAL;\n\n\tnrels = shdr->sh_size / shdr->sh_entsize;\n\tfor (i = 0; i < nrels; i++) {\n\t\trel = elf_rel_by_idx(data, i);\n\t\tif (!rel) {\n\t\t\tpr_warn(\".maps relo #%d: failed to get ELF relo\\n\", i);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tsym = elf_sym_by_idx(obj, ELF64_R_SYM(rel->r_info));\n\t\tif (!sym) {\n\t\t\tpr_warn(\".maps relo #%d: symbol %zx not found\\n\",\n\t\t\t\ti, (size_t)ELF64_R_SYM(rel->r_info));\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\t\tname = elf_sym_str(obj, sym->st_name) ?: \"<?>\";\n\n\t\tpr_debug(\".maps relo #%d: for %zd value %zd rel->r_offset %zu name %d ('%s')\\n\",\n\t\t\t i, (ssize_t)(rel->r_info >> 32), (size_t)sym->st_value,\n\t\t\t (size_t)rel->r_offset, sym->st_name, name);\n\n\t\tfor (j = 0; j < obj->nr_maps; j++) {\n\t\t\tmap = &obj->maps[j];\n\t\t\tif (map->sec_idx != obj->efile.btf_maps_shndx)\n\t\t\t\tcontinue;\n\n\t\t\tvi = btf_var_secinfos(sec) + map->btf_var_idx;\n\t\t\tif (vi->offset <= rel->r_offset &&\n\t\t\t    rel->r_offset + bpf_ptr_sz <= vi->offset + vi->size)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (j == obj->nr_maps) {\n\t\t\tpr_warn(\".maps relo #%d: cannot find map '%s' at rel->r_offset %zu\\n\",\n\t\t\t\ti, name, (size_t)rel->r_offset);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tis_map_in_map = bpf_map_type__is_map_in_map(map->def.type);\n\t\tis_prog_array = map->def.type == BPF_MAP_TYPE_PROG_ARRAY;\n\t\ttype = is_map_in_map ? \"map\" : \"prog\";\n\t\tif (is_map_in_map) {\n\t\t\tif (sym->st_shndx != obj->efile.btf_maps_shndx) {\n\t\t\t\tpr_warn(\".maps relo #%d: '%s' isn't a BTF-defined map\\n\",\n\t\t\t\t\ti, name);\n\t\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t\t}\n\t\t\tif (map->def.type == BPF_MAP_TYPE_HASH_OF_MAPS &&\n\t\t\t    map->def.key_size != sizeof(int)) {\n\t\t\t\tpr_warn(\".maps relo #%d: hash-of-maps '%s' should have key size %zu.\\n\",\n\t\t\t\t\ti, map->name, sizeof(int));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\ttarg_map = bpf_object__find_map_by_name(obj, name);\n\t\t\tif (!targ_map) {\n\t\t\t\tpr_warn(\".maps relo #%d: '%s' isn't a valid map reference\\n\",\n\t\t\t\t\ti, name);\n\t\t\t\treturn -ESRCH;\n\t\t\t}\n\t\t} else if (is_prog_array) {\n\t\t\ttarg_prog = bpf_object__find_program_by_name(obj, name);\n\t\t\tif (!targ_prog) {\n\t\t\t\tpr_warn(\".maps relo #%d: '%s' isn't a valid program reference\\n\",\n\t\t\t\t\ti, name);\n\t\t\t\treturn -ESRCH;\n\t\t\t}\n\t\t\tif (targ_prog->sec_idx != sym->st_shndx ||\n\t\t\t    targ_prog->sec_insn_off * 8 != sym->st_value ||\n\t\t\t    prog_is_subprog(obj, targ_prog)) {\n\t\t\t\tpr_warn(\".maps relo #%d: '%s' isn't an entry-point program\\n\",\n\t\t\t\t\ti, name);\n\t\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t\t}\n\t\t} else {\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tvar = btf__type_by_id(obj->btf, vi->type);\n\t\tdef = skip_mods_and_typedefs(obj->btf, var->type, NULL);\n\t\tif (btf_vlen(def) == 0)\n\t\t\treturn -EINVAL;\n\t\tmember = btf_members(def) + btf_vlen(def) - 1;\n\t\tmname = btf__name_by_offset(obj->btf, member->name_off);\n\t\tif (strcmp(mname, \"values\"))\n\t\t\treturn -EINVAL;\n\n\t\tmoff = btf_member_bit_offset(def, btf_vlen(def) - 1) / 8;\n\t\tif (rel->r_offset - vi->offset < moff)\n\t\t\treturn -EINVAL;\n\n\t\tmoff = rel->r_offset - vi->offset - moff;\n\t\t \n\t\tif (moff % bpf_ptr_sz)\n\t\t\treturn -EINVAL;\n\t\tmoff /= bpf_ptr_sz;\n\t\tif (moff >= map->init_slots_sz) {\n\t\t\tnew_sz = moff + 1;\n\t\t\ttmp = libbpf_reallocarray(map->init_slots, new_sz, host_ptr_sz);\n\t\t\tif (!tmp)\n\t\t\t\treturn -ENOMEM;\n\t\t\tmap->init_slots = tmp;\n\t\t\tmemset(map->init_slots + map->init_slots_sz, 0,\n\t\t\t       (new_sz - map->init_slots_sz) * host_ptr_sz);\n\t\t\tmap->init_slots_sz = new_sz;\n\t\t}\n\t\tmap->init_slots[moff] = is_map_in_map ? (void *)targ_map : (void *)targ_prog;\n\n\t\tpr_debug(\".maps relo #%d: map '%s' slot [%d] points to %s '%s'\\n\",\n\t\t\t i, map->name, moff, type, name);\n\t}\n\n\treturn 0;\n}\n\nstatic int bpf_object__collect_relos(struct bpf_object *obj)\n{\n\tint i, err;\n\n\tfor (i = 0; i < obj->efile.sec_cnt; i++) {\n\t\tstruct elf_sec_desc *sec_desc = &obj->efile.secs[i];\n\t\tElf64_Shdr *shdr;\n\t\tElf_Data *data;\n\t\tint idx;\n\n\t\tif (sec_desc->sec_type != SEC_RELO)\n\t\t\tcontinue;\n\n\t\tshdr = sec_desc->shdr;\n\t\tdata = sec_desc->data;\n\t\tidx = shdr->sh_info;\n\n\t\tif (shdr->sh_type != SHT_REL) {\n\t\t\tpr_warn(\"internal error at %d\\n\", __LINE__);\n\t\t\treturn -LIBBPF_ERRNO__INTERNAL;\n\t\t}\n\n\t\tif (idx == obj->efile.st_ops_shndx || idx == obj->efile.st_ops_link_shndx)\n\t\t\terr = bpf_object__collect_st_ops_relos(obj, shdr, data);\n\t\telse if (idx == obj->efile.btf_maps_shndx)\n\t\t\terr = bpf_object__collect_map_relos(obj, shdr, data);\n\t\telse\n\t\t\terr = bpf_object__collect_prog_relos(obj, shdr, data);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tbpf_object__sort_relos(obj);\n\treturn 0;\n}\n\nstatic bool insn_is_helper_call(struct bpf_insn *insn, enum bpf_func_id *func_id)\n{\n\tif (BPF_CLASS(insn->code) == BPF_JMP &&\n\t    BPF_OP(insn->code) == BPF_CALL &&\n\t    BPF_SRC(insn->code) == BPF_K &&\n\t    insn->src_reg == 0 &&\n\t    insn->dst_reg == 0) {\n\t\t    *func_id = insn->imm;\n\t\t    return true;\n\t}\n\treturn false;\n}\n\nstatic int bpf_object__sanitize_prog(struct bpf_object *obj, struct bpf_program *prog)\n{\n\tstruct bpf_insn *insn = prog->insns;\n\tenum bpf_func_id func_id;\n\tint i;\n\n\tif (obj->gen_loader)\n\t\treturn 0;\n\n\tfor (i = 0; i < prog->insns_cnt; i++, insn++) {\n\t\tif (!insn_is_helper_call(insn, &func_id))\n\t\t\tcontinue;\n\n\t\t \n\t\tswitch (func_id) {\n\t\tcase BPF_FUNC_probe_read_kernel:\n\t\tcase BPF_FUNC_probe_read_user:\n\t\t\tif (!kernel_supports(obj, FEAT_PROBE_READ_KERN))\n\t\t\t\tinsn->imm = BPF_FUNC_probe_read;\n\t\t\tbreak;\n\t\tcase BPF_FUNC_probe_read_kernel_str:\n\t\tcase BPF_FUNC_probe_read_user_str:\n\t\t\tif (!kernel_supports(obj, FEAT_PROBE_READ_KERN))\n\t\t\t\tinsn->imm = BPF_FUNC_probe_read_str;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int libbpf_find_attach_btf_id(struct bpf_program *prog, const char *attach_name,\n\t\t\t\t     int *btf_obj_fd, int *btf_type_id);\n\n \nstatic int libbpf_prepare_prog_load(struct bpf_program *prog,\n\t\t\t\t    struct bpf_prog_load_opts *opts, long cookie)\n{\n\tenum sec_def_flags def = cookie;\n\n\t \n\tif ((def & SEC_EXP_ATTACH_OPT) && !kernel_supports(prog->obj, FEAT_EXP_ATTACH_TYPE))\n\t\topts->expected_attach_type = 0;\n\n\tif (def & SEC_SLEEPABLE)\n\t\topts->prog_flags |= BPF_F_SLEEPABLE;\n\n\tif (prog->type == BPF_PROG_TYPE_XDP && (def & SEC_XDP_FRAGS))\n\t\topts->prog_flags |= BPF_F_XDP_HAS_FRAGS;\n\n\t \n\tif ((def & SEC_USDT) && kernel_supports(prog->obj, FEAT_UPROBE_MULTI_LINK))\n\t\tprog->expected_attach_type = BPF_TRACE_UPROBE_MULTI;\n\n\tif ((def & SEC_ATTACH_BTF) && !prog->attach_btf_id) {\n\t\tint btf_obj_fd = 0, btf_type_id = 0, err;\n\t\tconst char *attach_name;\n\n\t\tattach_name = strchr(prog->sec_name, '/');\n\t\tif (!attach_name) {\n\t\t\t \n\t\t\tpr_warn(\"prog '%s': no BTF-based attach target is specified, use bpf_program__set_attach_target()\\n\",\n\t\t\t\tprog->name);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tattach_name++;  \n\n\t\terr = libbpf_find_attach_btf_id(prog, attach_name, &btf_obj_fd, &btf_type_id);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t \n\t\tprog->attach_btf_obj_fd = btf_obj_fd;\n\t\tprog->attach_btf_id = btf_type_id;\n\n\t\t \n\t\topts->attach_btf_obj_fd = btf_obj_fd;\n\t\topts->attach_btf_id = btf_type_id;\n\t}\n\treturn 0;\n}\n\nstatic void fixup_verifier_log(struct bpf_program *prog, char *buf, size_t buf_sz);\n\nstatic int bpf_object_load_prog(struct bpf_object *obj, struct bpf_program *prog,\n\t\t\t\tstruct bpf_insn *insns, int insns_cnt,\n\t\t\t\tconst char *license, __u32 kern_version, int *prog_fd)\n{\n\tLIBBPF_OPTS(bpf_prog_load_opts, load_attr);\n\tconst char *prog_name = NULL;\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tsize_t log_buf_size = 0;\n\tchar *log_buf = NULL, *tmp;\n\tint btf_fd, ret, err;\n\tbool own_log_buf = true;\n\t__u32 log_level = prog->log_level;\n\n\tif (prog->type == BPF_PROG_TYPE_UNSPEC) {\n\t\t \n\t\tpr_warn(\"prog '%s': missing BPF prog type, check ELF section name '%s'\\n\",\n\t\t\tprog->name, prog->sec_name);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!insns || !insns_cnt)\n\t\treturn -EINVAL;\n\n\tif (kernel_supports(obj, FEAT_PROG_NAME))\n\t\tprog_name = prog->name;\n\tload_attr.attach_prog_fd = prog->attach_prog_fd;\n\tload_attr.attach_btf_obj_fd = prog->attach_btf_obj_fd;\n\tload_attr.attach_btf_id = prog->attach_btf_id;\n\tload_attr.kern_version = kern_version;\n\tload_attr.prog_ifindex = prog->prog_ifindex;\n\n\t \n\tbtf_fd = bpf_object__btf_fd(obj);\n\tif (btf_fd >= 0 && kernel_supports(obj, FEAT_BTF_FUNC)) {\n\t\tload_attr.prog_btf_fd = btf_fd;\n\t\tload_attr.func_info = prog->func_info;\n\t\tload_attr.func_info_rec_size = prog->func_info_rec_size;\n\t\tload_attr.func_info_cnt = prog->func_info_cnt;\n\t\tload_attr.line_info = prog->line_info;\n\t\tload_attr.line_info_rec_size = prog->line_info_rec_size;\n\t\tload_attr.line_info_cnt = prog->line_info_cnt;\n\t}\n\tload_attr.log_level = log_level;\n\tload_attr.prog_flags = prog->prog_flags;\n\tload_attr.fd_array = obj->fd_array;\n\n\t \n\tif (prog->sec_def && prog->sec_def->prog_prepare_load_fn) {\n\t\terr = prog->sec_def->prog_prepare_load_fn(prog, &load_attr, prog->sec_def->cookie);\n\t\tif (err < 0) {\n\t\t\tpr_warn(\"prog '%s': failed to prepare load attributes: %d\\n\",\n\t\t\t\tprog->name, err);\n\t\t\treturn err;\n\t\t}\n\t\tinsns = prog->insns;\n\t\tinsns_cnt = prog->insns_cnt;\n\t}\n\n\t \n\tload_attr.expected_attach_type = prog->expected_attach_type;\n\n\tif (obj->gen_loader) {\n\t\tbpf_gen__prog_load(obj->gen_loader, prog->type, prog->name,\n\t\t\t\t   license, insns, insns_cnt, &load_attr,\n\t\t\t\t   prog - obj->programs);\n\t\t*prog_fd = -1;\n\t\treturn 0;\n\t}\n\nretry_load:\n\t \n\tif (log_level) {\n\t\tif (prog->log_buf) {\n\t\t\tlog_buf = prog->log_buf;\n\t\t\tlog_buf_size = prog->log_size;\n\t\t\town_log_buf = false;\n\t\t} else if (obj->log_buf) {\n\t\t\tlog_buf = obj->log_buf;\n\t\t\tlog_buf_size = obj->log_size;\n\t\t\town_log_buf = false;\n\t\t} else {\n\t\t\tlog_buf_size = max((size_t)BPF_LOG_BUF_SIZE, log_buf_size * 2);\n\t\t\ttmp = realloc(log_buf, log_buf_size);\n\t\t\tif (!tmp) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tlog_buf = tmp;\n\t\t\tlog_buf[0] = '\\0';\n\t\t\town_log_buf = true;\n\t\t}\n\t}\n\n\tload_attr.log_buf = log_buf;\n\tload_attr.log_size = log_buf_size;\n\tload_attr.log_level = log_level;\n\n\tret = bpf_prog_load(prog->type, prog_name, license, insns, insns_cnt, &load_attr);\n\tif (ret >= 0) {\n\t\tif (log_level && own_log_buf) {\n\t\t\tpr_debug(\"prog '%s': -- BEGIN PROG LOAD LOG --\\n%s-- END PROG LOAD LOG --\\n\",\n\t\t\t\t prog->name, log_buf);\n\t\t}\n\n\t\tif (obj->has_rodata && kernel_supports(obj, FEAT_PROG_BIND_MAP)) {\n\t\t\tstruct bpf_map *map;\n\t\t\tint i;\n\n\t\t\tfor (i = 0; i < obj->nr_maps; i++) {\n\t\t\t\tmap = &prog->obj->maps[i];\n\t\t\t\tif (map->libbpf_type != LIBBPF_MAP_RODATA)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (bpf_prog_bind_map(ret, bpf_map__fd(map), NULL)) {\n\t\t\t\t\tcp = libbpf_strerror_r(errno, errmsg, sizeof(errmsg));\n\t\t\t\t\tpr_warn(\"prog '%s': failed to bind map '%s': %s\\n\",\n\t\t\t\t\t\tprog->name, map->real_name, cp);\n\t\t\t\t\t \n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t*prog_fd = ret;\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tif (log_level == 0) {\n\t\tlog_level = 1;\n\t\tgoto retry_load;\n\t}\n\t \n\tif (own_log_buf && errno == ENOSPC && log_buf_size <= UINT_MAX / 2)\n\t\tgoto retry_load;\n\n\tret = -errno;\n\n\t \n\tfixup_verifier_log(prog, log_buf, log_buf_size);\n\n\tcp = libbpf_strerror_r(errno, errmsg, sizeof(errmsg));\n\tpr_warn(\"prog '%s': BPF program load failed: %s\\n\", prog->name, cp);\n\tpr_perm_msg(ret);\n\n\tif (own_log_buf && log_buf && log_buf[0] != '\\0') {\n\t\tpr_warn(\"prog '%s': -- BEGIN PROG LOAD LOG --\\n%s-- END PROG LOAD LOG --\\n\",\n\t\t\tprog->name, log_buf);\n\t}\n\nout:\n\tif (own_log_buf)\n\t\tfree(log_buf);\n\treturn ret;\n}\n\nstatic char *find_prev_line(char *buf, char *cur)\n{\n\tchar *p;\n\n\tif (cur == buf)  \n\t\treturn NULL;\n\n\tp = cur - 1;\n\twhile (p - 1 >= buf && *(p - 1) != '\\n')\n\t\tp--;\n\n\treturn p;\n}\n\nstatic void patch_log(char *buf, size_t buf_sz, size_t log_sz,\n\t\t      char *orig, size_t orig_sz, const char *patch)\n{\n\t \n\tsize_t rem_sz = (buf + log_sz) - (orig + orig_sz);\n\tsize_t patch_sz = strlen(patch);\n\n\tif (patch_sz != orig_sz) {\n\t\t \n\t\tif (patch_sz > orig_sz) {\n\t\t\tif (orig + patch_sz >= buf + buf_sz) {\n\t\t\t\t \n\t\t\t\tpatch_sz -= (orig + patch_sz) - (buf + buf_sz) + 1;\n\t\t\t\trem_sz = 0;\n\t\t\t} else if (patch_sz - orig_sz > buf_sz - log_sz) {\n\t\t\t\t \n\t\t\t\trem_sz -= (patch_sz - orig_sz) - (buf_sz - log_sz);\n\t\t\t}\n\t\t}\n\t\t \n\t\tmemmove(orig + patch_sz, orig + orig_sz, rem_sz);\n\t}\n\n\tmemcpy(orig, patch, patch_sz);\n}\n\nstatic void fixup_log_failed_core_relo(struct bpf_program *prog,\n\t\t\t\t       char *buf, size_t buf_sz, size_t log_sz,\n\t\t\t\t       char *line1, char *line2, char *line3)\n{\n\t \n\tconst struct bpf_core_relo *relo;\n\tstruct bpf_core_spec spec;\n\tchar patch[512], spec_buf[256];\n\tint insn_idx, err, spec_len;\n\n\tif (sscanf(line1, \"%d: (%*d) call unknown#195896080\\n\", &insn_idx) != 1)\n\t\treturn;\n\n\trelo = find_relo_core(prog, insn_idx);\n\tif (!relo)\n\t\treturn;\n\n\terr = bpf_core_parse_spec(prog->name, prog->obj->btf, relo, &spec);\n\tif (err)\n\t\treturn;\n\n\tspec_len = bpf_core_format_spec(spec_buf, sizeof(spec_buf), &spec);\n\tsnprintf(patch, sizeof(patch),\n\t\t \"%d: <invalid CO-RE relocation>\\n\"\n\t\t \"failed to resolve CO-RE relocation %s%s\\n\",\n\t\t insn_idx, spec_buf, spec_len >= sizeof(spec_buf) ? \"...\" : \"\");\n\n\tpatch_log(buf, buf_sz, log_sz, line1, line3 - line1, patch);\n}\n\nstatic void fixup_log_missing_map_load(struct bpf_program *prog,\n\t\t\t\t       char *buf, size_t buf_sz, size_t log_sz,\n\t\t\t\t       char *line1, char *line2, char *line3)\n{\n\t \n\tstruct bpf_object *obj = prog->obj;\n\tconst struct bpf_map *map;\n\tint insn_idx, map_idx;\n\tchar patch[128];\n\n\tif (sscanf(line1, \"%d: (%*d) call unknown#%d\\n\", &insn_idx, &map_idx) != 2)\n\t\treturn;\n\n\tmap_idx -= POISON_LDIMM64_MAP_BASE;\n\tif (map_idx < 0 || map_idx >= obj->nr_maps)\n\t\treturn;\n\tmap = &obj->maps[map_idx];\n\n\tsnprintf(patch, sizeof(patch),\n\t\t \"%d: <invalid BPF map reference>\\n\"\n\t\t \"BPF map '%s' is referenced but wasn't created\\n\",\n\t\t insn_idx, map->name);\n\n\tpatch_log(buf, buf_sz, log_sz, line1, line3 - line1, patch);\n}\n\nstatic void fixup_log_missing_kfunc_call(struct bpf_program *prog,\n\t\t\t\t\t char *buf, size_t buf_sz, size_t log_sz,\n\t\t\t\t\t char *line1, char *line2, char *line3)\n{\n\t \n\tstruct bpf_object *obj = prog->obj;\n\tconst struct extern_desc *ext;\n\tint insn_idx, ext_idx;\n\tchar patch[128];\n\n\tif (sscanf(line1, \"%d: (%*d) call unknown#%d\\n\", &insn_idx, &ext_idx) != 2)\n\t\treturn;\n\n\text_idx -= POISON_CALL_KFUNC_BASE;\n\tif (ext_idx < 0 || ext_idx >= obj->nr_extern)\n\t\treturn;\n\text = &obj->externs[ext_idx];\n\n\tsnprintf(patch, sizeof(patch),\n\t\t \"%d: <invalid kfunc call>\\n\"\n\t\t \"kfunc '%s' is referenced but wasn't resolved\\n\",\n\t\t insn_idx, ext->name);\n\n\tpatch_log(buf, buf_sz, log_sz, line1, line3 - line1, patch);\n}\n\nstatic void fixup_verifier_log(struct bpf_program *prog, char *buf, size_t buf_sz)\n{\n\t \n\tconst size_t max_last_line_cnt = 10;\n\tchar *prev_line, *cur_line, *next_line;\n\tsize_t log_sz;\n\tint i;\n\n\tif (!buf)\n\t\treturn;\n\n\tlog_sz = strlen(buf) + 1;\n\tnext_line = buf + log_sz - 1;\n\n\tfor (i = 0; i < max_last_line_cnt; i++, next_line = cur_line) {\n\t\tcur_line = find_prev_line(buf, next_line);\n\t\tif (!cur_line)\n\t\t\treturn;\n\n\t\tif (str_has_pfx(cur_line, \"invalid func unknown#195896080\\n\")) {\n\t\t\tprev_line = find_prev_line(buf, cur_line);\n\t\t\tif (!prev_line)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tfixup_log_failed_core_relo(prog, buf, buf_sz, log_sz,\n\t\t\t\t\t\t   prev_line, cur_line, next_line);\n\t\t\treturn;\n\t\t} else if (str_has_pfx(cur_line, \"invalid func unknown#\"POISON_LDIMM64_MAP_PFX)) {\n\t\t\tprev_line = find_prev_line(buf, cur_line);\n\t\t\tif (!prev_line)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tfixup_log_missing_map_load(prog, buf, buf_sz, log_sz,\n\t\t\t\t\t\t   prev_line, cur_line, next_line);\n\t\t\treturn;\n\t\t} else if (str_has_pfx(cur_line, \"invalid func unknown#\"POISON_CALL_KFUNC_PFX)) {\n\t\t\tprev_line = find_prev_line(buf, cur_line);\n\t\t\tif (!prev_line)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tfixup_log_missing_kfunc_call(prog, buf, buf_sz, log_sz,\n\t\t\t\t\t\t     prev_line, cur_line, next_line);\n\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic int bpf_program_record_relos(struct bpf_program *prog)\n{\n\tstruct bpf_object *obj = prog->obj;\n\tint i;\n\n\tfor (i = 0; i < prog->nr_reloc; i++) {\n\t\tstruct reloc_desc *relo = &prog->reloc_desc[i];\n\t\tstruct extern_desc *ext = &obj->externs[relo->ext_idx];\n\t\tint kind;\n\n\t\tswitch (relo->type) {\n\t\tcase RELO_EXTERN_LD64:\n\t\t\tif (ext->type != EXT_KSYM)\n\t\t\t\tcontinue;\n\t\t\tkind = btf_is_var(btf__type_by_id(obj->btf, ext->btf_id)) ?\n\t\t\t\tBTF_KIND_VAR : BTF_KIND_FUNC;\n\t\t\tbpf_gen__record_extern(obj->gen_loader, ext->name,\n\t\t\t\t\t       ext->is_weak, !ext->ksym.type_id,\n\t\t\t\t\t       true, kind, relo->insn_idx);\n\t\t\tbreak;\n\t\tcase RELO_EXTERN_CALL:\n\t\t\tbpf_gen__record_extern(obj->gen_loader, ext->name,\n\t\t\t\t\t       ext->is_weak, false, false, BTF_KIND_FUNC,\n\t\t\t\t\t       relo->insn_idx);\n\t\t\tbreak;\n\t\tcase RELO_CORE: {\n\t\t\tstruct bpf_core_relo cr = {\n\t\t\t\t.insn_off = relo->insn_idx * 8,\n\t\t\t\t.type_id = relo->core_relo->type_id,\n\t\t\t\t.access_str_off = relo->core_relo->access_str_off,\n\t\t\t\t.kind = relo->core_relo->kind,\n\t\t\t};\n\n\t\t\tbpf_gen__record_relo_core(obj->gen_loader, &cr);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tcontinue;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int\nbpf_object__load_progs(struct bpf_object *obj, int log_level)\n{\n\tstruct bpf_program *prog;\n\tsize_t i;\n\tint err;\n\n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tprog = &obj->programs[i];\n\t\terr = bpf_object__sanitize_prog(obj, prog);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tfor (i = 0; i < obj->nr_programs; i++) {\n\t\tprog = &obj->programs[i];\n\t\tif (prog_is_subprog(obj, prog))\n\t\t\tcontinue;\n\t\tif (!prog->autoload) {\n\t\t\tpr_debug(\"prog '%s': skipped loading\\n\", prog->name);\n\t\t\tcontinue;\n\t\t}\n\t\tprog->log_level |= log_level;\n\n\t\tif (obj->gen_loader)\n\t\t\tbpf_program_record_relos(prog);\n\n\t\terr = bpf_object_load_prog(obj, prog, prog->insns, prog->insns_cnt,\n\t\t\t\t\t   obj->license, obj->kern_version, &prog->fd);\n\t\tif (err) {\n\t\t\tpr_warn(\"prog '%s': failed to load: %d\\n\", prog->name, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tbpf_object__free_relocs(obj);\n\treturn 0;\n}\n\nstatic const struct bpf_sec_def *find_sec_def(const char *sec_name);\n\nstatic int bpf_object_init_progs(struct bpf_object *obj, const struct bpf_object_open_opts *opts)\n{\n\tstruct bpf_program *prog;\n\tint err;\n\n\tbpf_object__for_each_program(prog, obj) {\n\t\tprog->sec_def = find_sec_def(prog->sec_name);\n\t\tif (!prog->sec_def) {\n\t\t\t \n\t\t\tpr_debug(\"prog '%s': unrecognized ELF section name '%s'\\n\",\n\t\t\t\tprog->name, prog->sec_name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tprog->type = prog->sec_def->prog_type;\n\t\tprog->expected_attach_type = prog->sec_def->expected_attach_type;\n\n\t\t \n\t\tif (prog->sec_def->prog_setup_fn) {\n\t\t\terr = prog->sec_def->prog_setup_fn(prog, prog->sec_def->cookie);\n\t\t\tif (err < 0) {\n\t\t\t\tpr_warn(\"prog '%s': failed to initialize: %d\\n\",\n\t\t\t\t\tprog->name, err);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic struct bpf_object *bpf_object_open(const char *path, const void *obj_buf, size_t obj_buf_sz,\n\t\t\t\t\t  const struct bpf_object_open_opts *opts)\n{\n\tconst char *obj_name, *kconfig, *btf_tmp_path;\n\tstruct bpf_object *obj;\n\tchar tmp_name[64];\n\tint err;\n\tchar *log_buf;\n\tsize_t log_size;\n\t__u32 log_level;\n\n\tif (elf_version(EV_CURRENT) == EV_NONE) {\n\t\tpr_warn(\"failed to init libelf for %s\\n\",\n\t\t\tpath ? : \"(mem buf)\");\n\t\treturn ERR_PTR(-LIBBPF_ERRNO__LIBELF);\n\t}\n\n\tif (!OPTS_VALID(opts, bpf_object_open_opts))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tobj_name = OPTS_GET(opts, object_name, NULL);\n\tif (obj_buf) {\n\t\tif (!obj_name) {\n\t\t\tsnprintf(tmp_name, sizeof(tmp_name), \"%lx-%lx\",\n\t\t\t\t (unsigned long)obj_buf,\n\t\t\t\t (unsigned long)obj_buf_sz);\n\t\t\tobj_name = tmp_name;\n\t\t}\n\t\tpath = obj_name;\n\t\tpr_debug(\"loading object '%s' from buffer\\n\", obj_name);\n\t}\n\n\tlog_buf = OPTS_GET(opts, kernel_log_buf, NULL);\n\tlog_size = OPTS_GET(opts, kernel_log_size, 0);\n\tlog_level = OPTS_GET(opts, kernel_log_level, 0);\n\tif (log_size > UINT_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\tif (log_size && !log_buf)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tobj = bpf_object__new(path, obj_buf, obj_buf_sz, obj_name);\n\tif (IS_ERR(obj))\n\t\treturn obj;\n\n\tobj->log_buf = log_buf;\n\tobj->log_size = log_size;\n\tobj->log_level = log_level;\n\n\tbtf_tmp_path = OPTS_GET(opts, btf_custom_path, NULL);\n\tif (btf_tmp_path) {\n\t\tif (strlen(btf_tmp_path) >= PATH_MAX) {\n\t\t\terr = -ENAMETOOLONG;\n\t\t\tgoto out;\n\t\t}\n\t\tobj->btf_custom_path = strdup(btf_tmp_path);\n\t\tif (!obj->btf_custom_path) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tkconfig = OPTS_GET(opts, kconfig, NULL);\n\tif (kconfig) {\n\t\tobj->kconfig = strdup(kconfig);\n\t\tif (!obj->kconfig) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\terr = bpf_object__elf_init(obj);\n\terr = err ? : bpf_object__check_endianness(obj);\n\terr = err ? : bpf_object__elf_collect(obj);\n\terr = err ? : bpf_object__collect_externs(obj);\n\terr = err ? : bpf_object_fixup_btf(obj);\n\terr = err ? : bpf_object__init_maps(obj, opts);\n\terr = err ? : bpf_object_init_progs(obj, opts);\n\terr = err ? : bpf_object__collect_relos(obj);\n\tif (err)\n\t\tgoto out;\n\n\tbpf_object__elf_finish(obj);\n\n\treturn obj;\nout:\n\tbpf_object__close(obj);\n\treturn ERR_PTR(err);\n}\n\nstruct bpf_object *\nbpf_object__open_file(const char *path, const struct bpf_object_open_opts *opts)\n{\n\tif (!path)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tpr_debug(\"loading %s\\n\", path);\n\n\treturn libbpf_ptr(bpf_object_open(path, NULL, 0, opts));\n}\n\nstruct bpf_object *bpf_object__open(const char *path)\n{\n\treturn bpf_object__open_file(path, NULL);\n}\n\nstruct bpf_object *\nbpf_object__open_mem(const void *obj_buf, size_t obj_buf_sz,\n\t\t     const struct bpf_object_open_opts *opts)\n{\n\tif (!obj_buf || obj_buf_sz == 0)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\treturn libbpf_ptr(bpf_object_open(NULL, obj_buf, obj_buf_sz, opts));\n}\n\nstatic int bpf_object_unload(struct bpf_object *obj)\n{\n\tsize_t i;\n\n\tif (!obj)\n\t\treturn libbpf_err(-EINVAL);\n\n\tfor (i = 0; i < obj->nr_maps; i++) {\n\t\tzclose(obj->maps[i].fd);\n\t\tif (obj->maps[i].st_ops)\n\t\t\tzfree(&obj->maps[i].st_ops->kern_vdata);\n\t}\n\n\tfor (i = 0; i < obj->nr_programs; i++)\n\t\tbpf_program__unload(&obj->programs[i]);\n\n\treturn 0;\n}\n\nstatic int bpf_object__sanitize_maps(struct bpf_object *obj)\n{\n\tstruct bpf_map *m;\n\n\tbpf_object__for_each_map(m, obj) {\n\t\tif (!bpf_map__is_internal(m))\n\t\t\tcontinue;\n\t\tif (!kernel_supports(obj, FEAT_ARRAY_MMAP))\n\t\t\tm->def.map_flags &= ~BPF_F_MMAPABLE;\n\t}\n\n\treturn 0;\n}\n\nint libbpf_kallsyms_parse(kallsyms_cb_t cb, void *ctx)\n{\n\tchar sym_type, sym_name[500];\n\tunsigned long long sym_addr;\n\tint ret, err = 0;\n\tFILE *f;\n\n\tf = fopen(\"/proc/kallsyms\", \"re\");\n\tif (!f) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to open /proc/kallsyms: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\twhile (true) {\n\t\tret = fscanf(f, \"%llx %c %499s%*[^\\n]\\n\",\n\t\t\t     &sym_addr, &sym_type, sym_name);\n\t\tif (ret == EOF && feof(f))\n\t\t\tbreak;\n\t\tif (ret != 3) {\n\t\t\tpr_warn(\"failed to read kallsyms entry: %d\\n\", ret);\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = cb(sym_addr, sym_type, sym_name, ctx);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tfclose(f);\n\treturn err;\n}\n\nstatic int kallsyms_cb(unsigned long long sym_addr, char sym_type,\n\t\t       const char *sym_name, void *ctx)\n{\n\tstruct bpf_object *obj = ctx;\n\tconst struct btf_type *t;\n\tstruct extern_desc *ext;\n\n\text = find_extern_by_name(obj, sym_name);\n\tif (!ext || ext->type != EXT_KSYM)\n\t\treturn 0;\n\n\tt = btf__type_by_id(obj->btf, ext->btf_id);\n\tif (!btf_is_var(t))\n\t\treturn 0;\n\n\tif (ext->is_set && ext->ksym.addr != sym_addr) {\n\t\tpr_warn(\"extern (ksym) '%s': resolution is ambiguous: 0x%llx or 0x%llx\\n\",\n\t\t\tsym_name, ext->ksym.addr, sym_addr);\n\t\treturn -EINVAL;\n\t}\n\tif (!ext->is_set) {\n\t\text->is_set = true;\n\t\text->ksym.addr = sym_addr;\n\t\tpr_debug(\"extern (ksym) '%s': set to 0x%llx\\n\", sym_name, sym_addr);\n\t}\n\treturn 0;\n}\n\nstatic int bpf_object__read_kallsyms_file(struct bpf_object *obj)\n{\n\treturn libbpf_kallsyms_parse(kallsyms_cb, obj);\n}\n\nstatic int find_ksym_btf_id(struct bpf_object *obj, const char *ksym_name,\n\t\t\t    __u16 kind, struct btf **res_btf,\n\t\t\t    struct module_btf **res_mod_btf)\n{\n\tstruct module_btf *mod_btf;\n\tstruct btf *btf;\n\tint i, id, err;\n\n\tbtf = obj->btf_vmlinux;\n\tmod_btf = NULL;\n\tid = btf__find_by_name_kind(btf, ksym_name, kind);\n\n\tif (id == -ENOENT) {\n\t\terr = load_module_btfs(obj);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tfor (i = 0; i < obj->btf_module_cnt; i++) {\n\t\t\t \n\t\t\tmod_btf = &obj->btf_modules[i];\n\t\t\tbtf = mod_btf->btf;\n\t\t\tid = btf__find_by_name_kind_own(btf, ksym_name, kind);\n\t\t\tif (id != -ENOENT)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tif (id <= 0)\n\t\treturn -ESRCH;\n\n\t*res_btf = btf;\n\t*res_mod_btf = mod_btf;\n\treturn id;\n}\n\nstatic int bpf_object__resolve_ksym_var_btf_id(struct bpf_object *obj,\n\t\t\t\t\t       struct extern_desc *ext)\n{\n\tconst struct btf_type *targ_var, *targ_type;\n\t__u32 targ_type_id, local_type_id;\n\tstruct module_btf *mod_btf = NULL;\n\tconst char *targ_var_name;\n\tstruct btf *btf = NULL;\n\tint id, err;\n\n\tid = find_ksym_btf_id(obj, ext->name, BTF_KIND_VAR, &btf, &mod_btf);\n\tif (id < 0) {\n\t\tif (id == -ESRCH && ext->is_weak)\n\t\t\treturn 0;\n\t\tpr_warn(\"extern (var ksym) '%s': not found in kernel BTF\\n\",\n\t\t\text->name);\n\t\treturn id;\n\t}\n\n\t \n\tlocal_type_id = ext->ksym.type_id;\n\n\t \n\ttarg_var = btf__type_by_id(btf, id);\n\ttarg_var_name = btf__name_by_offset(btf, targ_var->name_off);\n\ttarg_type = skip_mods_and_typedefs(btf, targ_var->type, &targ_type_id);\n\n\terr = bpf_core_types_are_compat(obj->btf, local_type_id,\n\t\t\t\t\tbtf, targ_type_id);\n\tif (err <= 0) {\n\t\tconst struct btf_type *local_type;\n\t\tconst char *targ_name, *local_name;\n\n\t\tlocal_type = btf__type_by_id(obj->btf, local_type_id);\n\t\tlocal_name = btf__name_by_offset(obj->btf, local_type->name_off);\n\t\ttarg_name = btf__name_by_offset(btf, targ_type->name_off);\n\n\t\tpr_warn(\"extern (var ksym) '%s': incompatible types, expected [%d] %s %s, but kernel has [%d] %s %s\\n\",\n\t\t\text->name, local_type_id,\n\t\t\tbtf_kind_str(local_type), local_name, targ_type_id,\n\t\t\tbtf_kind_str(targ_type), targ_name);\n\t\treturn -EINVAL;\n\t}\n\n\text->is_set = true;\n\text->ksym.kernel_btf_obj_fd = mod_btf ? mod_btf->fd : 0;\n\text->ksym.kernel_btf_id = id;\n\tpr_debug(\"extern (var ksym) '%s': resolved to [%d] %s %s\\n\",\n\t\t ext->name, id, btf_kind_str(targ_var), targ_var_name);\n\n\treturn 0;\n}\n\nstatic int bpf_object__resolve_ksym_func_btf_id(struct bpf_object *obj,\n\t\t\t\t\t\tstruct extern_desc *ext)\n{\n\tint local_func_proto_id, kfunc_proto_id, kfunc_id;\n\tstruct module_btf *mod_btf = NULL;\n\tconst struct btf_type *kern_func;\n\tstruct btf *kern_btf = NULL;\n\tint ret;\n\n\tlocal_func_proto_id = ext->ksym.type_id;\n\n\tkfunc_id = find_ksym_btf_id(obj, ext->essent_name ?: ext->name, BTF_KIND_FUNC, &kern_btf,\n\t\t\t\t    &mod_btf);\n\tif (kfunc_id < 0) {\n\t\tif (kfunc_id == -ESRCH && ext->is_weak)\n\t\t\treturn 0;\n\t\tpr_warn(\"extern (func ksym) '%s': not found in kernel or module BTFs\\n\",\n\t\t\text->name);\n\t\treturn kfunc_id;\n\t}\n\n\tkern_func = btf__type_by_id(kern_btf, kfunc_id);\n\tkfunc_proto_id = kern_func->type;\n\n\tret = bpf_core_types_are_compat(obj->btf, local_func_proto_id,\n\t\t\t\t\tkern_btf, kfunc_proto_id);\n\tif (ret <= 0) {\n\t\tif (ext->is_weak)\n\t\t\treturn 0;\n\n\t\tpr_warn(\"extern (func ksym) '%s': func_proto [%d] incompatible with %s [%d]\\n\",\n\t\t\text->name, local_func_proto_id,\n\t\t\tmod_btf ? mod_btf->name : \"vmlinux\", kfunc_proto_id);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (mod_btf && !mod_btf->fd_array_idx) {\n\t\t \n\t\tif (obj->fd_array_cnt == INT16_MAX) {\n\t\t\tpr_warn(\"extern (func ksym) '%s': module BTF fd index %d too big to fit in bpf_insn offset\\n\",\n\t\t\t\text->name, mod_btf->fd_array_idx);\n\t\t\treturn -E2BIG;\n\t\t}\n\t\t \n\t\tif (!obj->fd_array_cnt)\n\t\t\tobj->fd_array_cnt = 1;\n\n\t\tret = libbpf_ensure_mem((void **)&obj->fd_array, &obj->fd_array_cap, sizeof(int),\n\t\t\t\t\tobj->fd_array_cnt + 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tmod_btf->fd_array_idx = obj->fd_array_cnt;\n\t\t \n\t\tobj->fd_array[obj->fd_array_cnt++] = mod_btf->fd;\n\t}\n\n\text->is_set = true;\n\text->ksym.kernel_btf_id = kfunc_id;\n\text->ksym.btf_fd_idx = mod_btf ? mod_btf->fd_array_idx : 0;\n\t \n\text->ksym.kernel_btf_obj_fd = mod_btf ? mod_btf->fd : 0;\n\tpr_debug(\"extern (func ksym) '%s': resolved to %s [%d]\\n\",\n\t\t ext->name, mod_btf ? mod_btf->name : \"vmlinux\", kfunc_id);\n\n\treturn 0;\n}\n\nstatic int bpf_object__resolve_ksyms_btf_id(struct bpf_object *obj)\n{\n\tconst struct btf_type *t;\n\tstruct extern_desc *ext;\n\tint i, err;\n\n\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\text = &obj->externs[i];\n\t\tif (ext->type != EXT_KSYM || !ext->ksym.type_id)\n\t\t\tcontinue;\n\n\t\tif (obj->gen_loader) {\n\t\t\text->is_set = true;\n\t\t\text->ksym.kernel_btf_obj_fd = 0;\n\t\t\text->ksym.kernel_btf_id = 0;\n\t\t\tcontinue;\n\t\t}\n\t\tt = btf__type_by_id(obj->btf, ext->btf_id);\n\t\tif (btf_is_var(t))\n\t\t\terr = bpf_object__resolve_ksym_var_btf_id(obj, ext);\n\t\telse\n\t\t\terr = bpf_object__resolve_ksym_func_btf_id(obj, ext);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic int bpf_object__resolve_externs(struct bpf_object *obj,\n\t\t\t\t       const char *extra_kconfig)\n{\n\tbool need_config = false, need_kallsyms = false;\n\tbool need_vmlinux_btf = false;\n\tstruct extern_desc *ext;\n\tvoid *kcfg_data = NULL;\n\tint err, i;\n\n\tif (obj->nr_extern == 0)\n\t\treturn 0;\n\n\tif (obj->kconfig_map_idx >= 0)\n\t\tkcfg_data = obj->maps[obj->kconfig_map_idx].mmaped;\n\n\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\text = &obj->externs[i];\n\n\t\tif (ext->type == EXT_KSYM) {\n\t\t\tif (ext->ksym.type_id)\n\t\t\t\tneed_vmlinux_btf = true;\n\t\t\telse\n\t\t\t\tneed_kallsyms = true;\n\t\t\tcontinue;\n\t\t} else if (ext->type == EXT_KCFG) {\n\t\t\tvoid *ext_ptr = kcfg_data + ext->kcfg.data_off;\n\t\t\t__u64 value = 0;\n\n\t\t\t \n\t\t\tif (str_has_pfx(ext->name, \"CONFIG_\")) {\n\t\t\t\tneed_config = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (strcmp(ext->name, \"LINUX_KERNEL_VERSION\") == 0) {\n\t\t\t\tvalue = get_kernel_version();\n\t\t\t\tif (!value) {\n\t\t\t\t\tpr_warn(\"extern (kcfg) '%s': failed to get kernel version\\n\", ext->name);\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t} else if (strcmp(ext->name, \"LINUX_HAS_BPF_COOKIE\") == 0) {\n\t\t\t\tvalue = kernel_supports(obj, FEAT_BPF_COOKIE);\n\t\t\t} else if (strcmp(ext->name, \"LINUX_HAS_SYSCALL_WRAPPER\") == 0) {\n\t\t\t\tvalue = kernel_supports(obj, FEAT_SYSCALL_WRAPPER);\n\t\t\t} else if (!str_has_pfx(ext->name, \"LINUX_\") || !ext->is_weak) {\n\t\t\t\t \n\t\t\t\tpr_warn(\"extern (kcfg) '%s': unrecognized virtual extern\\n\", ext->name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\terr = set_kcfg_value_num(ext, ext_ptr, value);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t\tpr_debug(\"extern (kcfg) '%s': set to 0x%llx\\n\",\n\t\t\t\t ext->name, (long long)value);\n\t\t} else {\n\t\t\tpr_warn(\"extern '%s': unrecognized extern kind\\n\", ext->name);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tif (need_config && extra_kconfig) {\n\t\terr = bpf_object__read_kconfig_mem(obj, extra_kconfig, kcfg_data);\n\t\tif (err)\n\t\t\treturn -EINVAL;\n\t\tneed_config = false;\n\t\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\t\text = &obj->externs[i];\n\t\t\tif (ext->type == EXT_KCFG && !ext->is_set) {\n\t\t\t\tneed_config = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (need_config) {\n\t\terr = bpf_object__read_kconfig_file(obj, kcfg_data);\n\t\tif (err)\n\t\t\treturn -EINVAL;\n\t}\n\tif (need_kallsyms) {\n\t\terr = bpf_object__read_kallsyms_file(obj);\n\t\tif (err)\n\t\t\treturn -EINVAL;\n\t}\n\tif (need_vmlinux_btf) {\n\t\terr = bpf_object__resolve_ksyms_btf_id(obj);\n\t\tif (err)\n\t\t\treturn -EINVAL;\n\t}\n\tfor (i = 0; i < obj->nr_extern; i++) {\n\t\text = &obj->externs[i];\n\n\t\tif (!ext->is_set && !ext->is_weak) {\n\t\t\tpr_warn(\"extern '%s' (strong): not resolved\\n\", ext->name);\n\t\t\treturn -ESRCH;\n\t\t} else if (!ext->is_set) {\n\t\t\tpr_debug(\"extern '%s' (weak): not resolved, defaulting to zero\\n\",\n\t\t\t\t ext->name);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void bpf_map_prepare_vdata(const struct bpf_map *map)\n{\n\tstruct bpf_struct_ops *st_ops;\n\t__u32 i;\n\n\tst_ops = map->st_ops;\n\tfor (i = 0; i < btf_vlen(st_ops->type); i++) {\n\t\tstruct bpf_program *prog = st_ops->progs[i];\n\t\tvoid *kern_data;\n\t\tint prog_fd;\n\n\t\tif (!prog)\n\t\t\tcontinue;\n\n\t\tprog_fd = bpf_program__fd(prog);\n\t\tkern_data = st_ops->kern_vdata + st_ops->kern_func_off[i];\n\t\t*(unsigned long *)kern_data = prog_fd;\n\t}\n}\n\nstatic int bpf_object_prepare_struct_ops(struct bpf_object *obj)\n{\n\tint i;\n\n\tfor (i = 0; i < obj->nr_maps; i++)\n\t\tif (bpf_map__is_struct_ops(&obj->maps[i]))\n\t\t\tbpf_map_prepare_vdata(&obj->maps[i]);\n\n\treturn 0;\n}\n\nstatic int bpf_object_load(struct bpf_object *obj, int extra_log_level, const char *target_btf_path)\n{\n\tint err, i;\n\n\tif (!obj)\n\t\treturn libbpf_err(-EINVAL);\n\n\tif (obj->loaded) {\n\t\tpr_warn(\"object '%s': load can't be attempted twice\\n\", obj->name);\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\tif (obj->gen_loader)\n\t\tbpf_gen__init(obj->gen_loader, extra_log_level, obj->nr_programs, obj->nr_maps);\n\n\terr = bpf_object__probe_loading(obj);\n\terr = err ? : bpf_object__load_vmlinux_btf(obj, false);\n\terr = err ? : bpf_object__resolve_externs(obj, obj->kconfig);\n\terr = err ? : bpf_object__sanitize_and_load_btf(obj);\n\terr = err ? : bpf_object__sanitize_maps(obj);\n\terr = err ? : bpf_object__init_kern_struct_ops_maps(obj);\n\terr = err ? : bpf_object__create_maps(obj);\n\terr = err ? : bpf_object__relocate(obj, obj->btf_custom_path ? : target_btf_path);\n\terr = err ? : bpf_object__load_progs(obj, extra_log_level);\n\terr = err ? : bpf_object_init_prog_arrays(obj);\n\terr = err ? : bpf_object_prepare_struct_ops(obj);\n\n\tif (obj->gen_loader) {\n\t\t \n\t\tif (obj->btf)\n\t\t\tbtf__set_fd(obj->btf, -1);\n\t\tfor (i = 0; i < obj->nr_maps; i++)\n\t\t\tobj->maps[i].fd = -1;\n\t\tif (!err)\n\t\t\terr = bpf_gen__finish(obj->gen_loader, obj->nr_programs, obj->nr_maps);\n\t}\n\n\t \n\tzfree(&obj->fd_array);\n\n\t \n\tfor (i = 0; i < obj->btf_module_cnt; i++) {\n\t\tclose(obj->btf_modules[i].fd);\n\t\tbtf__free(obj->btf_modules[i].btf);\n\t\tfree(obj->btf_modules[i].name);\n\t}\n\tfree(obj->btf_modules);\n\n\t \n\tbtf__free(obj->btf_vmlinux);\n\tobj->btf_vmlinux = NULL;\n\n\tobj->loaded = true;  \n\n\tif (err)\n\t\tgoto out;\n\n\treturn 0;\nout:\n\t \n\tfor (i = 0; i < obj->nr_maps; i++)\n\t\tif (obj->maps[i].pinned && !obj->maps[i].reused)\n\t\t\tbpf_map__unpin(&obj->maps[i], NULL);\n\n\tbpf_object_unload(obj);\n\tpr_warn(\"failed to load object '%s'\\n\", obj->path);\n\treturn libbpf_err(err);\n}\n\nint bpf_object__load(struct bpf_object *obj)\n{\n\treturn bpf_object_load(obj, 0, NULL);\n}\n\nstatic int make_parent_dir(const char *path)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tchar *dname, *dir;\n\tint err = 0;\n\n\tdname = strdup(path);\n\tif (dname == NULL)\n\t\treturn -ENOMEM;\n\n\tdir = dirname(dname);\n\tif (mkdir(dir, 0700) && errno != EEXIST)\n\t\terr = -errno;\n\n\tfree(dname);\n\tif (err) {\n\t\tcp = libbpf_strerror_r(-err, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"failed to mkdir %s: %s\\n\", path, cp);\n\t}\n\treturn err;\n}\n\nstatic int check_path(const char *path)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tstruct statfs st_fs;\n\tchar *dname, *dir;\n\tint err = 0;\n\n\tif (path == NULL)\n\t\treturn -EINVAL;\n\n\tdname = strdup(path);\n\tif (dname == NULL)\n\t\treturn -ENOMEM;\n\n\tdir = dirname(dname);\n\tif (statfs(dir, &st_fs)) {\n\t\tcp = libbpf_strerror_r(errno, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"failed to statfs %s: %s\\n\", dir, cp);\n\t\terr = -errno;\n\t}\n\tfree(dname);\n\n\tif (!err && st_fs.f_type != BPF_FS_MAGIC) {\n\t\tpr_warn(\"specified path %s is not on BPF FS\\n\", path);\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}\n\nint bpf_program__pin(struct bpf_program *prog, const char *path)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tint err;\n\n\tif (prog->fd < 0) {\n\t\tpr_warn(\"prog '%s': can't pin program that wasn't loaded\\n\", prog->name);\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\terr = make_parent_dir(path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\terr = check_path(path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\tif (bpf_obj_pin(prog->fd, path)) {\n\t\terr = -errno;\n\t\tcp = libbpf_strerror_r(err, errmsg, sizeof(errmsg));\n\t\tpr_warn(\"prog '%s': failed to pin at '%s': %s\\n\", prog->name, path, cp);\n\t\treturn libbpf_err(err);\n\t}\n\n\tpr_debug(\"prog '%s': pinned at '%s'\\n\", prog->name, path);\n\treturn 0;\n}\n\nint bpf_program__unpin(struct bpf_program *prog, const char *path)\n{\n\tint err;\n\n\tif (prog->fd < 0) {\n\t\tpr_warn(\"prog '%s': can't unpin program that wasn't loaded\\n\", prog->name);\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\terr = check_path(path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\terr = unlink(path);\n\tif (err)\n\t\treturn libbpf_err(-errno);\n\n\tpr_debug(\"prog '%s': unpinned from '%s'\\n\", prog->name, path);\n\treturn 0;\n}\n\nint bpf_map__pin(struct bpf_map *map, const char *path)\n{\n\tchar *cp, errmsg[STRERR_BUFSIZE];\n\tint err;\n\n\tif (map == NULL) {\n\t\tpr_warn(\"invalid map pointer\\n\");\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\tif (map->pin_path) {\n\t\tif (path && strcmp(path, map->pin_path)) {\n\t\t\tpr_warn(\"map '%s' already has pin path '%s' different from '%s'\\n\",\n\t\t\t\tbpf_map__name(map), map->pin_path, path);\n\t\t\treturn libbpf_err(-EINVAL);\n\t\t} else if (map->pinned) {\n\t\t\tpr_debug(\"map '%s' already pinned at '%s'; not re-pinning\\n\",\n\t\t\t\t bpf_map__name(map), map->pin_path);\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tif (!path) {\n\t\t\tpr_warn(\"missing a path to pin map '%s' at\\n\",\n\t\t\t\tbpf_map__name(map));\n\t\t\treturn libbpf_err(-EINVAL);\n\t\t} else if (map->pinned) {\n\t\t\tpr_warn(\"map '%s' already pinned\\n\", bpf_map__name(map));\n\t\t\treturn libbpf_err(-EEXIST);\n\t\t}\n\n\t\tmap->pin_path = strdup(path);\n\t\tif (!map->pin_path) {\n\t\t\terr = -errno;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\terr = make_parent_dir(map->pin_path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\terr = check_path(map->pin_path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\tif (bpf_obj_pin(map->fd, map->pin_path)) {\n\t\terr = -errno;\n\t\tgoto out_err;\n\t}\n\n\tmap->pinned = true;\n\tpr_debug(\"pinned map '%s'\\n\", map->pin_path);\n\n\treturn 0;\n\nout_err:\n\tcp = libbpf_strerror_r(-err, errmsg, sizeof(errmsg));\n\tpr_warn(\"failed to pin map: %s\\n\", cp);\n\treturn libbpf_err(err);\n}\n\nint bpf_map__unpin(struct bpf_map *map, const char *path)\n{\n\tint err;\n\n\tif (map == NULL) {\n\t\tpr_warn(\"invalid map pointer\\n\");\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\tif (map->pin_path) {\n\t\tif (path && strcmp(path, map->pin_path)) {\n\t\t\tpr_warn(\"map '%s' already has pin path '%s' different from '%s'\\n\",\n\t\t\t\tbpf_map__name(map), map->pin_path, path);\n\t\t\treturn libbpf_err(-EINVAL);\n\t\t}\n\t\tpath = map->pin_path;\n\t} else if (!path) {\n\t\tpr_warn(\"no path to unpin map '%s' from\\n\",\n\t\t\tbpf_map__name(map));\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\terr = check_path(path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\terr = unlink(path);\n\tif (err != 0)\n\t\treturn libbpf_err(-errno);\n\n\tmap->pinned = false;\n\tpr_debug(\"unpinned map '%s' from '%s'\\n\", bpf_map__name(map), path);\n\n\treturn 0;\n}\n\nint bpf_map__set_pin_path(struct bpf_map *map, const char *path)\n{\n\tchar *new = NULL;\n\n\tif (path) {\n\t\tnew = strdup(path);\n\t\tif (!new)\n\t\t\treturn libbpf_err(-errno);\n\t}\n\n\tfree(map->pin_path);\n\tmap->pin_path = new;\n\treturn 0;\n}\n\n__alias(bpf_map__pin_path)\nconst char *bpf_map__get_pin_path(const struct bpf_map *map);\n\nconst char *bpf_map__pin_path(const struct bpf_map *map)\n{\n\treturn map->pin_path;\n}\n\nbool bpf_map__is_pinned(const struct bpf_map *map)\n{\n\treturn map->pinned;\n}\n\nstatic void sanitize_pin_path(char *s)\n{\n\t \n\twhile (*s) {\n\t\tif (*s == '.')\n\t\t\t*s = '_';\n\t\ts++;\n\t}\n}\n\nint bpf_object__pin_maps(struct bpf_object *obj, const char *path)\n{\n\tstruct bpf_map *map;\n\tint err;\n\n\tif (!obj)\n\t\treturn libbpf_err(-ENOENT);\n\n\tif (!obj->loaded) {\n\t\tpr_warn(\"object not yet loaded; load it first\\n\");\n\t\treturn libbpf_err(-ENOENT);\n\t}\n\n\tbpf_object__for_each_map(map, obj) {\n\t\tchar *pin_path = NULL;\n\t\tchar buf[PATH_MAX];\n\n\t\tif (!map->autocreate)\n\t\t\tcontinue;\n\n\t\tif (path) {\n\t\t\terr = pathname_concat(buf, sizeof(buf), path, bpf_map__name(map));\n\t\t\tif (err)\n\t\t\t\tgoto err_unpin_maps;\n\t\t\tsanitize_pin_path(buf);\n\t\t\tpin_path = buf;\n\t\t} else if (!map->pin_path) {\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = bpf_map__pin(map, pin_path);\n\t\tif (err)\n\t\t\tgoto err_unpin_maps;\n\t}\n\n\treturn 0;\n\nerr_unpin_maps:\n\twhile ((map = bpf_object__prev_map(obj, map))) {\n\t\tif (!map->pin_path)\n\t\t\tcontinue;\n\n\t\tbpf_map__unpin(map, NULL);\n\t}\n\n\treturn libbpf_err(err);\n}\n\nint bpf_object__unpin_maps(struct bpf_object *obj, const char *path)\n{\n\tstruct bpf_map *map;\n\tint err;\n\n\tif (!obj)\n\t\treturn libbpf_err(-ENOENT);\n\n\tbpf_object__for_each_map(map, obj) {\n\t\tchar *pin_path = NULL;\n\t\tchar buf[PATH_MAX];\n\n\t\tif (path) {\n\t\t\terr = pathname_concat(buf, sizeof(buf), path, bpf_map__name(map));\n\t\t\tif (err)\n\t\t\t\treturn libbpf_err(err);\n\t\t\tsanitize_pin_path(buf);\n\t\t\tpin_path = buf;\n\t\t} else if (!map->pin_path) {\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = bpf_map__unpin(map, pin_path);\n\t\tif (err)\n\t\t\treturn libbpf_err(err);\n\t}\n\n\treturn 0;\n}\n\nint bpf_object__pin_programs(struct bpf_object *obj, const char *path)\n{\n\tstruct bpf_program *prog;\n\tchar buf[PATH_MAX];\n\tint err;\n\n\tif (!obj)\n\t\treturn libbpf_err(-ENOENT);\n\n\tif (!obj->loaded) {\n\t\tpr_warn(\"object not yet loaded; load it first\\n\");\n\t\treturn libbpf_err(-ENOENT);\n\t}\n\n\tbpf_object__for_each_program(prog, obj) {\n\t\terr = pathname_concat(buf, sizeof(buf), path, prog->name);\n\t\tif (err)\n\t\t\tgoto err_unpin_programs;\n\n\t\terr = bpf_program__pin(prog, buf);\n\t\tif (err)\n\t\t\tgoto err_unpin_programs;\n\t}\n\n\treturn 0;\n\nerr_unpin_programs:\n\twhile ((prog = bpf_object__prev_program(obj, prog))) {\n\t\tif (pathname_concat(buf, sizeof(buf), path, prog->name))\n\t\t\tcontinue;\n\n\t\tbpf_program__unpin(prog, buf);\n\t}\n\n\treturn libbpf_err(err);\n}\n\nint bpf_object__unpin_programs(struct bpf_object *obj, const char *path)\n{\n\tstruct bpf_program *prog;\n\tint err;\n\n\tif (!obj)\n\t\treturn libbpf_err(-ENOENT);\n\n\tbpf_object__for_each_program(prog, obj) {\n\t\tchar buf[PATH_MAX];\n\n\t\terr = pathname_concat(buf, sizeof(buf), path, prog->name);\n\t\tif (err)\n\t\t\treturn libbpf_err(err);\n\n\t\terr = bpf_program__unpin(prog, buf);\n\t\tif (err)\n\t\t\treturn libbpf_err(err);\n\t}\n\n\treturn 0;\n}\n\nint bpf_object__pin(struct bpf_object *obj, const char *path)\n{\n\tint err;\n\n\terr = bpf_object__pin_maps(obj, path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\terr = bpf_object__pin_programs(obj, path);\n\tif (err) {\n\t\tbpf_object__unpin_maps(obj, path);\n\t\treturn libbpf_err(err);\n\t}\n\n\treturn 0;\n}\n\nint bpf_object__unpin(struct bpf_object *obj, const char *path)\n{\n\tint err;\n\n\terr = bpf_object__unpin_programs(obj, path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\terr = bpf_object__unpin_maps(obj, path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\treturn 0;\n}\n\nstatic void bpf_map__destroy(struct bpf_map *map)\n{\n\tif (map->inner_map) {\n\t\tbpf_map__destroy(map->inner_map);\n\t\tzfree(&map->inner_map);\n\t}\n\n\tzfree(&map->init_slots);\n\tmap->init_slots_sz = 0;\n\n\tif (map->mmaped) {\n\t\tsize_t mmap_sz;\n\n\t\tmmap_sz = bpf_map_mmap_sz(map->def.value_size, map->def.max_entries);\n\t\tmunmap(map->mmaped, mmap_sz);\n\t\tmap->mmaped = NULL;\n\t}\n\n\tif (map->st_ops) {\n\t\tzfree(&map->st_ops->data);\n\t\tzfree(&map->st_ops->progs);\n\t\tzfree(&map->st_ops->kern_func_off);\n\t\tzfree(&map->st_ops);\n\t}\n\n\tzfree(&map->name);\n\tzfree(&map->real_name);\n\tzfree(&map->pin_path);\n\n\tif (map->fd >= 0)\n\t\tzclose(map->fd);\n}\n\nvoid bpf_object__close(struct bpf_object *obj)\n{\n\tsize_t i;\n\n\tif (IS_ERR_OR_NULL(obj))\n\t\treturn;\n\n\tusdt_manager_free(obj->usdt_man);\n\tobj->usdt_man = NULL;\n\n\tbpf_gen__free(obj->gen_loader);\n\tbpf_object__elf_finish(obj);\n\tbpf_object_unload(obj);\n\tbtf__free(obj->btf);\n\tbtf__free(obj->btf_vmlinux);\n\tbtf_ext__free(obj->btf_ext);\n\n\tfor (i = 0; i < obj->nr_maps; i++)\n\t\tbpf_map__destroy(&obj->maps[i]);\n\n\tzfree(&obj->btf_custom_path);\n\tzfree(&obj->kconfig);\n\n\tfor (i = 0; i < obj->nr_extern; i++)\n\t\tzfree(&obj->externs[i].essent_name);\n\n\tzfree(&obj->externs);\n\tobj->nr_extern = 0;\n\n\tzfree(&obj->maps);\n\tobj->nr_maps = 0;\n\n\tif (obj->programs && obj->nr_programs) {\n\t\tfor (i = 0; i < obj->nr_programs; i++)\n\t\t\tbpf_program__exit(&obj->programs[i]);\n\t}\n\tzfree(&obj->programs);\n\n\tfree(obj);\n}\n\nconst char *bpf_object__name(const struct bpf_object *obj)\n{\n\treturn obj ? obj->name : libbpf_err_ptr(-EINVAL);\n}\n\nunsigned int bpf_object__kversion(const struct bpf_object *obj)\n{\n\treturn obj ? obj->kern_version : 0;\n}\n\nstruct btf *bpf_object__btf(const struct bpf_object *obj)\n{\n\treturn obj ? obj->btf : NULL;\n}\n\nint bpf_object__btf_fd(const struct bpf_object *obj)\n{\n\treturn obj->btf ? btf__fd(obj->btf) : -1;\n}\n\nint bpf_object__set_kversion(struct bpf_object *obj, __u32 kern_version)\n{\n\tif (obj->loaded)\n\t\treturn libbpf_err(-EINVAL);\n\n\tobj->kern_version = kern_version;\n\n\treturn 0;\n}\n\nint bpf_object__gen_loader(struct bpf_object *obj, struct gen_loader_opts *opts)\n{\n\tstruct bpf_gen *gen;\n\n\tif (!opts)\n\t\treturn -EFAULT;\n\tif (!OPTS_VALID(opts, gen_loader_opts))\n\t\treturn -EINVAL;\n\tgen = calloc(sizeof(*gen), 1);\n\tif (!gen)\n\t\treturn -ENOMEM;\n\tgen->opts = opts;\n\tobj->gen_loader = gen;\n\treturn 0;\n}\n\nstatic struct bpf_program *\n__bpf_program__iter(const struct bpf_program *p, const struct bpf_object *obj,\n\t\t    bool forward)\n{\n\tsize_t nr_programs = obj->nr_programs;\n\tssize_t idx;\n\n\tif (!nr_programs)\n\t\treturn NULL;\n\n\tif (!p)\n\t\t \n\t\treturn forward ? &obj->programs[0] :\n\t\t\t&obj->programs[nr_programs - 1];\n\n\tif (p->obj != obj) {\n\t\tpr_warn(\"error: program handler doesn't match object\\n\");\n\t\treturn errno = EINVAL, NULL;\n\t}\n\n\tidx = (p - obj->programs) + (forward ? 1 : -1);\n\tif (idx >= obj->nr_programs || idx < 0)\n\t\treturn NULL;\n\treturn &obj->programs[idx];\n}\n\nstruct bpf_program *\nbpf_object__next_program(const struct bpf_object *obj, struct bpf_program *prev)\n{\n\tstruct bpf_program *prog = prev;\n\n\tdo {\n\t\tprog = __bpf_program__iter(prog, obj, true);\n\t} while (prog && prog_is_subprog(obj, prog));\n\n\treturn prog;\n}\n\nstruct bpf_program *\nbpf_object__prev_program(const struct bpf_object *obj, struct bpf_program *next)\n{\n\tstruct bpf_program *prog = next;\n\n\tdo {\n\t\tprog = __bpf_program__iter(prog, obj, false);\n\t} while (prog && prog_is_subprog(obj, prog));\n\n\treturn prog;\n}\n\nvoid bpf_program__set_ifindex(struct bpf_program *prog, __u32 ifindex)\n{\n\tprog->prog_ifindex = ifindex;\n}\n\nconst char *bpf_program__name(const struct bpf_program *prog)\n{\n\treturn prog->name;\n}\n\nconst char *bpf_program__section_name(const struct bpf_program *prog)\n{\n\treturn prog->sec_name;\n}\n\nbool bpf_program__autoload(const struct bpf_program *prog)\n{\n\treturn prog->autoload;\n}\n\nint bpf_program__set_autoload(struct bpf_program *prog, bool autoload)\n{\n\tif (prog->obj->loaded)\n\t\treturn libbpf_err(-EINVAL);\n\n\tprog->autoload = autoload;\n\treturn 0;\n}\n\nbool bpf_program__autoattach(const struct bpf_program *prog)\n{\n\treturn prog->autoattach;\n}\n\nvoid bpf_program__set_autoattach(struct bpf_program *prog, bool autoattach)\n{\n\tprog->autoattach = autoattach;\n}\n\nconst struct bpf_insn *bpf_program__insns(const struct bpf_program *prog)\n{\n\treturn prog->insns;\n}\n\nsize_t bpf_program__insn_cnt(const struct bpf_program *prog)\n{\n\treturn prog->insns_cnt;\n}\n\nint bpf_program__set_insns(struct bpf_program *prog,\n\t\t\t   struct bpf_insn *new_insns, size_t new_insn_cnt)\n{\n\tstruct bpf_insn *insns;\n\n\tif (prog->obj->loaded)\n\t\treturn -EBUSY;\n\n\tinsns = libbpf_reallocarray(prog->insns, new_insn_cnt, sizeof(*insns));\n\t \n\tif (!insns && new_insn_cnt) {\n\t\tpr_warn(\"prog '%s': failed to realloc prog code\\n\", prog->name);\n\t\treturn -ENOMEM;\n\t}\n\tmemcpy(insns, new_insns, new_insn_cnt * sizeof(*insns));\n\n\tprog->insns = insns;\n\tprog->insns_cnt = new_insn_cnt;\n\treturn 0;\n}\n\nint bpf_program__fd(const struct bpf_program *prog)\n{\n\tif (!prog)\n\t\treturn libbpf_err(-EINVAL);\n\n\tif (prog->fd < 0)\n\t\treturn libbpf_err(-ENOENT);\n\n\treturn prog->fd;\n}\n\n__alias(bpf_program__type)\nenum bpf_prog_type bpf_program__get_type(const struct bpf_program *prog);\n\nenum bpf_prog_type bpf_program__type(const struct bpf_program *prog)\n{\n\treturn prog->type;\n}\n\nstatic size_t custom_sec_def_cnt;\nstatic struct bpf_sec_def *custom_sec_defs;\nstatic struct bpf_sec_def custom_fallback_def;\nstatic bool has_custom_fallback_def;\nstatic int last_custom_sec_def_handler_id;\n\nint bpf_program__set_type(struct bpf_program *prog, enum bpf_prog_type type)\n{\n\tif (prog->obj->loaded)\n\t\treturn libbpf_err(-EBUSY);\n\n\t \n\tif (prog->type == type)\n\t\treturn 0;\n\n\tprog->type = type;\n\n\t \n\tif (prog->sec_def != &custom_fallback_def)\n\t\tprog->sec_def = NULL;\n\treturn 0;\n}\n\n__alias(bpf_program__expected_attach_type)\nenum bpf_attach_type bpf_program__get_expected_attach_type(const struct bpf_program *prog);\n\nenum bpf_attach_type bpf_program__expected_attach_type(const struct bpf_program *prog)\n{\n\treturn prog->expected_attach_type;\n}\n\nint bpf_program__set_expected_attach_type(struct bpf_program *prog,\n\t\t\t\t\t   enum bpf_attach_type type)\n{\n\tif (prog->obj->loaded)\n\t\treturn libbpf_err(-EBUSY);\n\n\tprog->expected_attach_type = type;\n\treturn 0;\n}\n\n__u32 bpf_program__flags(const struct bpf_program *prog)\n{\n\treturn prog->prog_flags;\n}\n\nint bpf_program__set_flags(struct bpf_program *prog, __u32 flags)\n{\n\tif (prog->obj->loaded)\n\t\treturn libbpf_err(-EBUSY);\n\n\tprog->prog_flags = flags;\n\treturn 0;\n}\n\n__u32 bpf_program__log_level(const struct bpf_program *prog)\n{\n\treturn prog->log_level;\n}\n\nint bpf_program__set_log_level(struct bpf_program *prog, __u32 log_level)\n{\n\tif (prog->obj->loaded)\n\t\treturn libbpf_err(-EBUSY);\n\n\tprog->log_level = log_level;\n\treturn 0;\n}\n\nconst char *bpf_program__log_buf(const struct bpf_program *prog, size_t *log_size)\n{\n\t*log_size = prog->log_size;\n\treturn prog->log_buf;\n}\n\nint bpf_program__set_log_buf(struct bpf_program *prog, char *log_buf, size_t log_size)\n{\n\tif (log_size && !log_buf)\n\t\treturn -EINVAL;\n\tif (prog->log_size > UINT_MAX)\n\t\treturn -EINVAL;\n\tif (prog->obj->loaded)\n\t\treturn -EBUSY;\n\n\tprog->log_buf = log_buf;\n\tprog->log_size = log_size;\n\treturn 0;\n}\n\n#define SEC_DEF(sec_pfx, ptype, atype, flags, ...) {\t\t\t    \\\n\t.sec = (char *)sec_pfx,\t\t\t\t\t\t    \\\n\t.prog_type = BPF_PROG_TYPE_##ptype,\t\t\t\t    \\\n\t.expected_attach_type = atype,\t\t\t\t\t    \\\n\t.cookie = (long)(flags),\t\t\t\t\t    \\\n\t.prog_prepare_load_fn = libbpf_prepare_prog_load,\t\t    \\\n\t__VA_ARGS__\t\t\t\t\t\t\t    \\\n}\n\nstatic int attach_kprobe(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_uprobe(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_ksyscall(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_usdt(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_tp(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_raw_tp(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_trace(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_kprobe_multi(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_uprobe_multi(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_lsm(const struct bpf_program *prog, long cookie, struct bpf_link **link);\nstatic int attach_iter(const struct bpf_program *prog, long cookie, struct bpf_link **link);\n\nstatic const struct bpf_sec_def section_defs[] = {\n\tSEC_DEF(\"socket\",\t\tSOCKET_FILTER, 0, SEC_NONE),\n\tSEC_DEF(\"sk_reuseport/migrate\",\tSK_REUSEPORT, BPF_SK_REUSEPORT_SELECT_OR_MIGRATE, SEC_ATTACHABLE),\n\tSEC_DEF(\"sk_reuseport\",\t\tSK_REUSEPORT, BPF_SK_REUSEPORT_SELECT, SEC_ATTACHABLE),\n\tSEC_DEF(\"kprobe+\",\t\tKPROBE,\t0, SEC_NONE, attach_kprobe),\n\tSEC_DEF(\"uprobe+\",\t\tKPROBE,\t0, SEC_NONE, attach_uprobe),\n\tSEC_DEF(\"uprobe.s+\",\t\tKPROBE,\t0, SEC_SLEEPABLE, attach_uprobe),\n\tSEC_DEF(\"kretprobe+\",\t\tKPROBE, 0, SEC_NONE, attach_kprobe),\n\tSEC_DEF(\"uretprobe+\",\t\tKPROBE, 0, SEC_NONE, attach_uprobe),\n\tSEC_DEF(\"uretprobe.s+\",\t\tKPROBE, 0, SEC_SLEEPABLE, attach_uprobe),\n\tSEC_DEF(\"kprobe.multi+\",\tKPROBE,\tBPF_TRACE_KPROBE_MULTI, SEC_NONE, attach_kprobe_multi),\n\tSEC_DEF(\"kretprobe.multi+\",\tKPROBE,\tBPF_TRACE_KPROBE_MULTI, SEC_NONE, attach_kprobe_multi),\n\tSEC_DEF(\"uprobe.multi+\",\tKPROBE,\tBPF_TRACE_UPROBE_MULTI, SEC_NONE, attach_uprobe_multi),\n\tSEC_DEF(\"uretprobe.multi+\",\tKPROBE,\tBPF_TRACE_UPROBE_MULTI, SEC_NONE, attach_uprobe_multi),\n\tSEC_DEF(\"uprobe.multi.s+\",\tKPROBE,\tBPF_TRACE_UPROBE_MULTI, SEC_SLEEPABLE, attach_uprobe_multi),\n\tSEC_DEF(\"uretprobe.multi.s+\",\tKPROBE,\tBPF_TRACE_UPROBE_MULTI, SEC_SLEEPABLE, attach_uprobe_multi),\n\tSEC_DEF(\"ksyscall+\",\t\tKPROBE,\t0, SEC_NONE, attach_ksyscall),\n\tSEC_DEF(\"kretsyscall+\",\t\tKPROBE, 0, SEC_NONE, attach_ksyscall),\n\tSEC_DEF(\"usdt+\",\t\tKPROBE,\t0, SEC_USDT, attach_usdt),\n\tSEC_DEF(\"usdt.s+\",\t\tKPROBE,\t0, SEC_USDT | SEC_SLEEPABLE, attach_usdt),\n\tSEC_DEF(\"tc/ingress\",\t\tSCHED_CLS, BPF_TCX_INGRESS, SEC_NONE),  \n\tSEC_DEF(\"tc/egress\",\t\tSCHED_CLS, BPF_TCX_EGRESS, SEC_NONE),   \n\tSEC_DEF(\"tcx/ingress\",\t\tSCHED_CLS, BPF_TCX_INGRESS, SEC_NONE),\n\tSEC_DEF(\"tcx/egress\",\t\tSCHED_CLS, BPF_TCX_EGRESS, SEC_NONE),\n\tSEC_DEF(\"tc\",\t\t\tSCHED_CLS, 0, SEC_NONE),  \n\tSEC_DEF(\"classifier\",\t\tSCHED_CLS, 0, SEC_NONE),  \n\tSEC_DEF(\"action\",\t\tSCHED_ACT, 0, SEC_NONE),  \n\tSEC_DEF(\"tracepoint+\",\t\tTRACEPOINT, 0, SEC_NONE, attach_tp),\n\tSEC_DEF(\"tp+\",\t\t\tTRACEPOINT, 0, SEC_NONE, attach_tp),\n\tSEC_DEF(\"raw_tracepoint+\",\tRAW_TRACEPOINT, 0, SEC_NONE, attach_raw_tp),\n\tSEC_DEF(\"raw_tp+\",\t\tRAW_TRACEPOINT, 0, SEC_NONE, attach_raw_tp),\n\tSEC_DEF(\"raw_tracepoint.w+\",\tRAW_TRACEPOINT_WRITABLE, 0, SEC_NONE, attach_raw_tp),\n\tSEC_DEF(\"raw_tp.w+\",\t\tRAW_TRACEPOINT_WRITABLE, 0, SEC_NONE, attach_raw_tp),\n\tSEC_DEF(\"tp_btf+\",\t\tTRACING, BPF_TRACE_RAW_TP, SEC_ATTACH_BTF, attach_trace),\n\tSEC_DEF(\"fentry+\",\t\tTRACING, BPF_TRACE_FENTRY, SEC_ATTACH_BTF, attach_trace),\n\tSEC_DEF(\"fmod_ret+\",\t\tTRACING, BPF_MODIFY_RETURN, SEC_ATTACH_BTF, attach_trace),\n\tSEC_DEF(\"fexit+\",\t\tTRACING, BPF_TRACE_FEXIT, SEC_ATTACH_BTF, attach_trace),\n\tSEC_DEF(\"fentry.s+\",\t\tTRACING, BPF_TRACE_FENTRY, SEC_ATTACH_BTF | SEC_SLEEPABLE, attach_trace),\n\tSEC_DEF(\"fmod_ret.s+\",\t\tTRACING, BPF_MODIFY_RETURN, SEC_ATTACH_BTF | SEC_SLEEPABLE, attach_trace),\n\tSEC_DEF(\"fexit.s+\",\t\tTRACING, BPF_TRACE_FEXIT, SEC_ATTACH_BTF | SEC_SLEEPABLE, attach_trace),\n\tSEC_DEF(\"freplace+\",\t\tEXT, 0, SEC_ATTACH_BTF, attach_trace),\n\tSEC_DEF(\"lsm+\",\t\t\tLSM, BPF_LSM_MAC, SEC_ATTACH_BTF, attach_lsm),\n\tSEC_DEF(\"lsm.s+\",\t\tLSM, BPF_LSM_MAC, SEC_ATTACH_BTF | SEC_SLEEPABLE, attach_lsm),\n\tSEC_DEF(\"lsm_cgroup+\",\t\tLSM, BPF_LSM_CGROUP, SEC_ATTACH_BTF),\n\tSEC_DEF(\"iter+\",\t\tTRACING, BPF_TRACE_ITER, SEC_ATTACH_BTF, attach_iter),\n\tSEC_DEF(\"iter.s+\",\t\tTRACING, BPF_TRACE_ITER, SEC_ATTACH_BTF | SEC_SLEEPABLE, attach_iter),\n\tSEC_DEF(\"syscall\",\t\tSYSCALL, 0, SEC_SLEEPABLE),\n\tSEC_DEF(\"xdp.frags/devmap\",\tXDP, BPF_XDP_DEVMAP, SEC_XDP_FRAGS),\n\tSEC_DEF(\"xdp/devmap\",\t\tXDP, BPF_XDP_DEVMAP, SEC_ATTACHABLE),\n\tSEC_DEF(\"xdp.frags/cpumap\",\tXDP, BPF_XDP_CPUMAP, SEC_XDP_FRAGS),\n\tSEC_DEF(\"xdp/cpumap\",\t\tXDP, BPF_XDP_CPUMAP, SEC_ATTACHABLE),\n\tSEC_DEF(\"xdp.frags\",\t\tXDP, BPF_XDP, SEC_XDP_FRAGS),\n\tSEC_DEF(\"xdp\",\t\t\tXDP, BPF_XDP, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"perf_event\",\t\tPERF_EVENT, 0, SEC_NONE),\n\tSEC_DEF(\"lwt_in\",\t\tLWT_IN, 0, SEC_NONE),\n\tSEC_DEF(\"lwt_out\",\t\tLWT_OUT, 0, SEC_NONE),\n\tSEC_DEF(\"lwt_xmit\",\t\tLWT_XMIT, 0, SEC_NONE),\n\tSEC_DEF(\"lwt_seg6local\",\tLWT_SEG6LOCAL, 0, SEC_NONE),\n\tSEC_DEF(\"sockops\",\t\tSOCK_OPS, BPF_CGROUP_SOCK_OPS, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"sk_skb/stream_parser\",\tSK_SKB, BPF_SK_SKB_STREAM_PARSER, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"sk_skb/stream_verdict\",SK_SKB, BPF_SK_SKB_STREAM_VERDICT, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"sk_skb\",\t\tSK_SKB, 0, SEC_NONE),\n\tSEC_DEF(\"sk_msg\",\t\tSK_MSG, BPF_SK_MSG_VERDICT, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"lirc_mode2\",\t\tLIRC_MODE2, BPF_LIRC_MODE2, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"flow_dissector\",\tFLOW_DISSECTOR, BPF_FLOW_DISSECTOR, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"cgroup_skb/ingress\",\tCGROUP_SKB, BPF_CGROUP_INET_INGRESS, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"cgroup_skb/egress\",\tCGROUP_SKB, BPF_CGROUP_INET_EGRESS, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"cgroup/skb\",\t\tCGROUP_SKB, 0, SEC_NONE),\n\tSEC_DEF(\"cgroup/sock_create\",\tCGROUP_SOCK, BPF_CGROUP_INET_SOCK_CREATE, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/sock_release\",\tCGROUP_SOCK, BPF_CGROUP_INET_SOCK_RELEASE, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/sock\",\t\tCGROUP_SOCK, BPF_CGROUP_INET_SOCK_CREATE, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"cgroup/post_bind4\",\tCGROUP_SOCK, BPF_CGROUP_INET4_POST_BIND, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/post_bind6\",\tCGROUP_SOCK, BPF_CGROUP_INET6_POST_BIND, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/bind4\",\t\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET4_BIND, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/bind6\",\t\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET6_BIND, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/connect4\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET4_CONNECT, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/connect6\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET6_CONNECT, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/sendmsg4\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_UDP4_SENDMSG, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/sendmsg6\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_UDP6_SENDMSG, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/recvmsg4\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_UDP4_RECVMSG, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/recvmsg6\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_UDP6_RECVMSG, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/getpeername4\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET4_GETPEERNAME, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/getpeername6\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET6_GETPEERNAME, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/getsockname4\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET4_GETSOCKNAME, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/getsockname6\",\tCGROUP_SOCK_ADDR, BPF_CGROUP_INET6_GETSOCKNAME, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/sysctl\",\tCGROUP_SYSCTL, BPF_CGROUP_SYSCTL, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/getsockopt\",\tCGROUP_SOCKOPT, BPF_CGROUP_GETSOCKOPT, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/setsockopt\",\tCGROUP_SOCKOPT, BPF_CGROUP_SETSOCKOPT, SEC_ATTACHABLE),\n\tSEC_DEF(\"cgroup/dev\",\t\tCGROUP_DEVICE, BPF_CGROUP_DEVICE, SEC_ATTACHABLE_OPT),\n\tSEC_DEF(\"struct_ops+\",\t\tSTRUCT_OPS, 0, SEC_NONE),\n\tSEC_DEF(\"struct_ops.s+\",\tSTRUCT_OPS, 0, SEC_SLEEPABLE),\n\tSEC_DEF(\"sk_lookup\",\t\tSK_LOOKUP, BPF_SK_LOOKUP, SEC_ATTACHABLE),\n\tSEC_DEF(\"netfilter\",\t\tNETFILTER, BPF_NETFILTER, SEC_NONE),\n};\n\nint libbpf_register_prog_handler(const char *sec,\n\t\t\t\t enum bpf_prog_type prog_type,\n\t\t\t\t enum bpf_attach_type exp_attach_type,\n\t\t\t\t const struct libbpf_prog_handler_opts *opts)\n{\n\tstruct bpf_sec_def *sec_def;\n\n\tif (!OPTS_VALID(opts, libbpf_prog_handler_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tif (last_custom_sec_def_handler_id == INT_MAX)  \n\t\treturn libbpf_err(-E2BIG);\n\n\tif (sec) {\n\t\tsec_def = libbpf_reallocarray(custom_sec_defs, custom_sec_def_cnt + 1,\n\t\t\t\t\t      sizeof(*sec_def));\n\t\tif (!sec_def)\n\t\t\treturn libbpf_err(-ENOMEM);\n\n\t\tcustom_sec_defs = sec_def;\n\t\tsec_def = &custom_sec_defs[custom_sec_def_cnt];\n\t} else {\n\t\tif (has_custom_fallback_def)\n\t\t\treturn libbpf_err(-EBUSY);\n\n\t\tsec_def = &custom_fallback_def;\n\t}\n\n\tsec_def->sec = sec ? strdup(sec) : NULL;\n\tif (sec && !sec_def->sec)\n\t\treturn libbpf_err(-ENOMEM);\n\n\tsec_def->prog_type = prog_type;\n\tsec_def->expected_attach_type = exp_attach_type;\n\tsec_def->cookie = OPTS_GET(opts, cookie, 0);\n\n\tsec_def->prog_setup_fn = OPTS_GET(opts, prog_setup_fn, NULL);\n\tsec_def->prog_prepare_load_fn = OPTS_GET(opts, prog_prepare_load_fn, NULL);\n\tsec_def->prog_attach_fn = OPTS_GET(opts, prog_attach_fn, NULL);\n\n\tsec_def->handler_id = ++last_custom_sec_def_handler_id;\n\n\tif (sec)\n\t\tcustom_sec_def_cnt++;\n\telse\n\t\thas_custom_fallback_def = true;\n\n\treturn sec_def->handler_id;\n}\n\nint libbpf_unregister_prog_handler(int handler_id)\n{\n\tstruct bpf_sec_def *sec_defs;\n\tint i;\n\n\tif (handler_id <= 0)\n\t\treturn libbpf_err(-EINVAL);\n\n\tif (has_custom_fallback_def && custom_fallback_def.handler_id == handler_id) {\n\t\tmemset(&custom_fallback_def, 0, sizeof(custom_fallback_def));\n\t\thas_custom_fallback_def = false;\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < custom_sec_def_cnt; i++) {\n\t\tif (custom_sec_defs[i].handler_id == handler_id)\n\t\t\tbreak;\n\t}\n\n\tif (i == custom_sec_def_cnt)\n\t\treturn libbpf_err(-ENOENT);\n\n\tfree(custom_sec_defs[i].sec);\n\tfor (i = i + 1; i < custom_sec_def_cnt; i++)\n\t\tcustom_sec_defs[i - 1] = custom_sec_defs[i];\n\tcustom_sec_def_cnt--;\n\n\t \n\tsec_defs = libbpf_reallocarray(custom_sec_defs, custom_sec_def_cnt, sizeof(*sec_defs));\n\t \n\tif (sec_defs || custom_sec_def_cnt == 0)\n\t\tcustom_sec_defs = sec_defs;\n\n\treturn 0;\n}\n\nstatic bool sec_def_matches(const struct bpf_sec_def *sec_def, const char *sec_name)\n{\n\tsize_t len = strlen(sec_def->sec);\n\n\t \n\tif (sec_def->sec[len - 1] == '/') {\n\t\tif (str_has_pfx(sec_name, sec_def->sec))\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\n\t \n\tif (sec_def->sec[len - 1] == '+') {\n\t\tlen--;\n\t\t \n\t\tif (strncmp(sec_name, sec_def->sec, len) != 0)\n\t\t\treturn false;\n\t\t \n\t\tif (sec_name[len] == '\\0' || sec_name[len] == '/')\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\n\treturn strcmp(sec_name, sec_def->sec) == 0;\n}\n\nstatic const struct bpf_sec_def *find_sec_def(const char *sec_name)\n{\n\tconst struct bpf_sec_def *sec_def;\n\tint i, n;\n\n\tn = custom_sec_def_cnt;\n\tfor (i = 0; i < n; i++) {\n\t\tsec_def = &custom_sec_defs[i];\n\t\tif (sec_def_matches(sec_def, sec_name))\n\t\t\treturn sec_def;\n\t}\n\n\tn = ARRAY_SIZE(section_defs);\n\tfor (i = 0; i < n; i++) {\n\t\tsec_def = &section_defs[i];\n\t\tif (sec_def_matches(sec_def, sec_name))\n\t\t\treturn sec_def;\n\t}\n\n\tif (has_custom_fallback_def)\n\t\treturn &custom_fallback_def;\n\n\treturn NULL;\n}\n\n#define MAX_TYPE_NAME_SIZE 32\n\nstatic char *libbpf_get_type_names(bool attach_type)\n{\n\tint i, len = ARRAY_SIZE(section_defs) * MAX_TYPE_NAME_SIZE;\n\tchar *buf;\n\n\tbuf = malloc(len);\n\tif (!buf)\n\t\treturn NULL;\n\n\tbuf[0] = '\\0';\n\t \n\tfor (i = 0; i < ARRAY_SIZE(section_defs); i++) {\n\t\tconst struct bpf_sec_def *sec_def = &section_defs[i];\n\n\t\tif (attach_type) {\n\t\t\tif (sec_def->prog_prepare_load_fn != libbpf_prepare_prog_load)\n\t\t\t\tcontinue;\n\n\t\t\tif (!(sec_def->cookie & SEC_ATTACHABLE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (strlen(buf) + strlen(section_defs[i].sec) + 2 > len) {\n\t\t\tfree(buf);\n\t\t\treturn NULL;\n\t\t}\n\t\tstrcat(buf, \" \");\n\t\tstrcat(buf, section_defs[i].sec);\n\t}\n\n\treturn buf;\n}\n\nint libbpf_prog_type_by_name(const char *name, enum bpf_prog_type *prog_type,\n\t\t\t     enum bpf_attach_type *expected_attach_type)\n{\n\tconst struct bpf_sec_def *sec_def;\n\tchar *type_names;\n\n\tif (!name)\n\t\treturn libbpf_err(-EINVAL);\n\n\tsec_def = find_sec_def(name);\n\tif (sec_def) {\n\t\t*prog_type = sec_def->prog_type;\n\t\t*expected_attach_type = sec_def->expected_attach_type;\n\t\treturn 0;\n\t}\n\n\tpr_debug(\"failed to guess program type from ELF section '%s'\\n\", name);\n\ttype_names = libbpf_get_type_names(false);\n\tif (type_names != NULL) {\n\t\tpr_debug(\"supported section(type) names are:%s\\n\", type_names);\n\t\tfree(type_names);\n\t}\n\n\treturn libbpf_err(-ESRCH);\n}\n\nconst char *libbpf_bpf_attach_type_str(enum bpf_attach_type t)\n{\n\tif (t < 0 || t >= ARRAY_SIZE(attach_type_name))\n\t\treturn NULL;\n\n\treturn attach_type_name[t];\n}\n\nconst char *libbpf_bpf_link_type_str(enum bpf_link_type t)\n{\n\tif (t < 0 || t >= ARRAY_SIZE(link_type_name))\n\t\treturn NULL;\n\n\treturn link_type_name[t];\n}\n\nconst char *libbpf_bpf_map_type_str(enum bpf_map_type t)\n{\n\tif (t < 0 || t >= ARRAY_SIZE(map_type_name))\n\t\treturn NULL;\n\n\treturn map_type_name[t];\n}\n\nconst char *libbpf_bpf_prog_type_str(enum bpf_prog_type t)\n{\n\tif (t < 0 || t >= ARRAY_SIZE(prog_type_name))\n\t\treturn NULL;\n\n\treturn prog_type_name[t];\n}\n\nstatic struct bpf_map *find_struct_ops_map_by_offset(struct bpf_object *obj,\n\t\t\t\t\t\t     int sec_idx,\n\t\t\t\t\t\t     size_t offset)\n{\n\tstruct bpf_map *map;\n\tsize_t i;\n\n\tfor (i = 0; i < obj->nr_maps; i++) {\n\t\tmap = &obj->maps[i];\n\t\tif (!bpf_map__is_struct_ops(map))\n\t\t\tcontinue;\n\t\tif (map->sec_idx == sec_idx &&\n\t\t    map->sec_offset <= offset &&\n\t\t    offset - map->sec_offset < map->def.value_size)\n\t\t\treturn map;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic int bpf_object__collect_st_ops_relos(struct bpf_object *obj,\n\t\t\t\t\t    Elf64_Shdr *shdr, Elf_Data *data)\n{\n\tconst struct btf_member *member;\n\tstruct bpf_struct_ops *st_ops;\n\tstruct bpf_program *prog;\n\tunsigned int shdr_idx;\n\tconst struct btf *btf;\n\tstruct bpf_map *map;\n\tunsigned int moff, insn_idx;\n\tconst char *name;\n\t__u32 member_idx;\n\tElf64_Sym *sym;\n\tElf64_Rel *rel;\n\tint i, nrels;\n\n\tbtf = obj->btf;\n\tnrels = shdr->sh_size / shdr->sh_entsize;\n\tfor (i = 0; i < nrels; i++) {\n\t\trel = elf_rel_by_idx(data, i);\n\t\tif (!rel) {\n\t\t\tpr_warn(\"struct_ops reloc: failed to get %d reloc\\n\", i);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tsym = elf_sym_by_idx(obj, ELF64_R_SYM(rel->r_info));\n\t\tif (!sym) {\n\t\t\tpr_warn(\"struct_ops reloc: symbol %zx not found\\n\",\n\t\t\t\t(size_t)ELF64_R_SYM(rel->r_info));\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\n\t\tname = elf_sym_str(obj, sym->st_name) ?: \"<?>\";\n\t\tmap = find_struct_ops_map_by_offset(obj, shdr->sh_info, rel->r_offset);\n\t\tif (!map) {\n\t\t\tpr_warn(\"struct_ops reloc: cannot find map at rel->r_offset %zu\\n\",\n\t\t\t\t(size_t)rel->r_offset);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tmoff = rel->r_offset - map->sec_offset;\n\t\tshdr_idx = sym->st_shndx;\n\t\tst_ops = map->st_ops;\n\t\tpr_debug(\"struct_ops reloc %s: for %lld value %lld shdr_idx %u rel->r_offset %zu map->sec_offset %zu name %d (\\'%s\\')\\n\",\n\t\t\t map->name,\n\t\t\t (long long)(rel->r_info >> 32),\n\t\t\t (long long)sym->st_value,\n\t\t\t shdr_idx, (size_t)rel->r_offset,\n\t\t\t map->sec_offset, sym->st_name, name);\n\n\t\tif (shdr_idx >= SHN_LORESERVE) {\n\t\t\tpr_warn(\"struct_ops reloc %s: rel->r_offset %zu shdr_idx %u unsupported non-static function\\n\",\n\t\t\t\tmap->name, (size_t)rel->r_offset, shdr_idx);\n\t\t\treturn -LIBBPF_ERRNO__RELOC;\n\t\t}\n\t\tif (sym->st_value % BPF_INSN_SZ) {\n\t\t\tpr_warn(\"struct_ops reloc %s: invalid target program offset %llu\\n\",\n\t\t\t\tmap->name, (unsigned long long)sym->st_value);\n\t\t\treturn -LIBBPF_ERRNO__FORMAT;\n\t\t}\n\t\tinsn_idx = sym->st_value / BPF_INSN_SZ;\n\n\t\tmember = find_member_by_offset(st_ops->type, moff * 8);\n\t\tif (!member) {\n\t\t\tpr_warn(\"struct_ops reloc %s: cannot find member at moff %u\\n\",\n\t\t\t\tmap->name, moff);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmember_idx = member - btf_members(st_ops->type);\n\t\tname = btf__name_by_offset(btf, member->name_off);\n\n\t\tif (!resolve_func_ptr(btf, member->type, NULL)) {\n\t\t\tpr_warn(\"struct_ops reloc %s: cannot relocate non func ptr %s\\n\",\n\t\t\t\tmap->name, name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tprog = find_prog_by_sec_insn(obj, shdr_idx, insn_idx);\n\t\tif (!prog) {\n\t\t\tpr_warn(\"struct_ops reloc %s: cannot find prog at shdr_idx %u to relocate func ptr %s\\n\",\n\t\t\t\tmap->name, shdr_idx, name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (prog->type != BPF_PROG_TYPE_STRUCT_OPS) {\n\t\t\tpr_warn(\"struct_ops reloc %s: prog %s is not struct_ops BPF program\\n\",\n\t\t\t\tmap->name, prog->name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (!prog->attach_btf_id) {\n\t\t\tprog->attach_btf_id = st_ops->type_id;\n\t\t\tprog->expected_attach_type = member_idx;\n\t\t}\n\n\t\t \n\t\tif (prog->attach_btf_id != st_ops->type_id ||\n\t\t    prog->expected_attach_type != member_idx) {\n\t\t\tpr_warn(\"struct_ops reloc %s: cannot use prog %s in sec %s with type %u attach_btf_id %u expected_attach_type %u for func ptr %s\\n\",\n\t\t\t\tmap->name, prog->name, prog->sec_name, prog->type,\n\t\t\t\tprog->attach_btf_id, prog->expected_attach_type, name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tst_ops->progs[member_idx] = prog;\n\t}\n\n\treturn 0;\n}\n\n#define BTF_TRACE_PREFIX \"btf_trace_\"\n#define BTF_LSM_PREFIX \"bpf_lsm_\"\n#define BTF_ITER_PREFIX \"bpf_iter_\"\n#define BTF_MAX_NAME_SIZE 128\n\nvoid btf_get_kernel_prefix_kind(enum bpf_attach_type attach_type,\n\t\t\t\tconst char **prefix, int *kind)\n{\n\tswitch (attach_type) {\n\tcase BPF_TRACE_RAW_TP:\n\t\t*prefix = BTF_TRACE_PREFIX;\n\t\t*kind = BTF_KIND_TYPEDEF;\n\t\tbreak;\n\tcase BPF_LSM_MAC:\n\tcase BPF_LSM_CGROUP:\n\t\t*prefix = BTF_LSM_PREFIX;\n\t\t*kind = BTF_KIND_FUNC;\n\t\tbreak;\n\tcase BPF_TRACE_ITER:\n\t\t*prefix = BTF_ITER_PREFIX;\n\t\t*kind = BTF_KIND_FUNC;\n\t\tbreak;\n\tdefault:\n\t\t*prefix = \"\";\n\t\t*kind = BTF_KIND_FUNC;\n\t}\n}\n\nstatic int find_btf_by_prefix_kind(const struct btf *btf, const char *prefix,\n\t\t\t\t   const char *name, __u32 kind)\n{\n\tchar btf_type_name[BTF_MAX_NAME_SIZE];\n\tint ret;\n\n\tret = snprintf(btf_type_name, sizeof(btf_type_name),\n\t\t       \"%s%s\", prefix, name);\n\t \n\tif (ret < 0 || ret >= sizeof(btf_type_name))\n\t\treturn -ENAMETOOLONG;\n\treturn btf__find_by_name_kind(btf, btf_type_name, kind);\n}\n\nstatic inline int find_attach_btf_id(struct btf *btf, const char *name,\n\t\t\t\t     enum bpf_attach_type attach_type)\n{\n\tconst char *prefix;\n\tint kind;\n\n\tbtf_get_kernel_prefix_kind(attach_type, &prefix, &kind);\n\treturn find_btf_by_prefix_kind(btf, prefix, name, kind);\n}\n\nint libbpf_find_vmlinux_btf_id(const char *name,\n\t\t\t       enum bpf_attach_type attach_type)\n{\n\tstruct btf *btf;\n\tint err;\n\n\tbtf = btf__load_vmlinux_btf();\n\terr = libbpf_get_error(btf);\n\tif (err) {\n\t\tpr_warn(\"vmlinux BTF is not found\\n\");\n\t\treturn libbpf_err(err);\n\t}\n\n\terr = find_attach_btf_id(btf, name, attach_type);\n\tif (err <= 0)\n\t\tpr_warn(\"%s is not found in vmlinux BTF\\n\", name);\n\n\tbtf__free(btf);\n\treturn libbpf_err(err);\n}\n\nstatic int libbpf_find_prog_btf_id(const char *name, __u32 attach_prog_fd)\n{\n\tstruct bpf_prog_info info;\n\t__u32 info_len = sizeof(info);\n\tstruct btf *btf;\n\tint err;\n\n\tmemset(&info, 0, info_len);\n\terr = bpf_prog_get_info_by_fd(attach_prog_fd, &info, &info_len);\n\tif (err) {\n\t\tpr_warn(\"failed bpf_prog_get_info_by_fd for FD %d: %d\\n\",\n\t\t\tattach_prog_fd, err);\n\t\treturn err;\n\t}\n\n\terr = -EINVAL;\n\tif (!info.btf_id) {\n\t\tpr_warn(\"The target program doesn't have BTF\\n\");\n\t\tgoto out;\n\t}\n\tbtf = btf__load_from_kernel_by_id(info.btf_id);\n\terr = libbpf_get_error(btf);\n\tif (err) {\n\t\tpr_warn(\"Failed to get BTF %d of the program: %d\\n\", info.btf_id, err);\n\t\tgoto out;\n\t}\n\terr = btf__find_by_name_kind(btf, name, BTF_KIND_FUNC);\n\tbtf__free(btf);\n\tif (err <= 0) {\n\t\tpr_warn(\"%s is not found in prog's BTF\\n\", name);\n\t\tgoto out;\n\t}\nout:\n\treturn err;\n}\n\nstatic int find_kernel_btf_id(struct bpf_object *obj, const char *attach_name,\n\t\t\t      enum bpf_attach_type attach_type,\n\t\t\t      int *btf_obj_fd, int *btf_type_id)\n{\n\tint ret, i;\n\n\tret = find_attach_btf_id(obj->btf_vmlinux, attach_name, attach_type);\n\tif (ret > 0) {\n\t\t*btf_obj_fd = 0;  \n\t\t*btf_type_id = ret;\n\t\treturn 0;\n\t}\n\tif (ret != -ENOENT)\n\t\treturn ret;\n\n\tret = load_module_btfs(obj);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < obj->btf_module_cnt; i++) {\n\t\tconst struct module_btf *mod = &obj->btf_modules[i];\n\n\t\tret = find_attach_btf_id(mod->btf, attach_name, attach_type);\n\t\tif (ret > 0) {\n\t\t\t*btf_obj_fd = mod->fd;\n\t\t\t*btf_type_id = ret;\n\t\t\treturn 0;\n\t\t}\n\t\tif (ret == -ENOENT)\n\t\t\tcontinue;\n\n\t\treturn ret;\n\t}\n\n\treturn -ESRCH;\n}\n\nstatic int libbpf_find_attach_btf_id(struct bpf_program *prog, const char *attach_name,\n\t\t\t\t     int *btf_obj_fd, int *btf_type_id)\n{\n\tenum bpf_attach_type attach_type = prog->expected_attach_type;\n\t__u32 attach_prog_fd = prog->attach_prog_fd;\n\tint err = 0;\n\n\t \n\tif (prog->type == BPF_PROG_TYPE_EXT || attach_prog_fd) {\n\t\tif (!attach_prog_fd) {\n\t\t\tpr_warn(\"prog '%s': attach program FD is not set\\n\", prog->name);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\terr = libbpf_find_prog_btf_id(attach_name, attach_prog_fd);\n\t\tif (err < 0) {\n\t\t\tpr_warn(\"prog '%s': failed to find BPF program (FD %d) BTF ID for '%s': %d\\n\",\n\t\t\t\t prog->name, attach_prog_fd, attach_name, err);\n\t\t\treturn err;\n\t\t}\n\t\t*btf_obj_fd = 0;\n\t\t*btf_type_id = err;\n\t\treturn 0;\n\t}\n\n\t \n\tif (prog->obj->gen_loader) {\n\t\tbpf_gen__record_attach_target(prog->obj->gen_loader, attach_name, attach_type);\n\t\t*btf_obj_fd = 0;\n\t\t*btf_type_id = 1;\n\t} else {\n\t\terr = find_kernel_btf_id(prog->obj, attach_name, attach_type, btf_obj_fd, btf_type_id);\n\t}\n\tif (err) {\n\t\tpr_warn(\"prog '%s': failed to find kernel BTF type ID of '%s': %d\\n\",\n\t\t\tprog->name, attach_name, err);\n\t\treturn err;\n\t}\n\treturn 0;\n}\n\nint libbpf_attach_type_by_name(const char *name,\n\t\t\t       enum bpf_attach_type *attach_type)\n{\n\tchar *type_names;\n\tconst struct bpf_sec_def *sec_def;\n\n\tif (!name)\n\t\treturn libbpf_err(-EINVAL);\n\n\tsec_def = find_sec_def(name);\n\tif (!sec_def) {\n\t\tpr_debug(\"failed to guess attach type based on ELF section name '%s'\\n\", name);\n\t\ttype_names = libbpf_get_type_names(true);\n\t\tif (type_names != NULL) {\n\t\t\tpr_debug(\"attachable section(type) names are:%s\\n\", type_names);\n\t\t\tfree(type_names);\n\t\t}\n\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\tif (sec_def->prog_prepare_load_fn != libbpf_prepare_prog_load)\n\t\treturn libbpf_err(-EINVAL);\n\tif (!(sec_def->cookie & SEC_ATTACHABLE))\n\t\treturn libbpf_err(-EINVAL);\n\n\t*attach_type = sec_def->expected_attach_type;\n\treturn 0;\n}\n\nint bpf_map__fd(const struct bpf_map *map)\n{\n\treturn map ? map->fd : libbpf_err(-EINVAL);\n}\n\nstatic bool map_uses_real_name(const struct bpf_map *map)\n{\n\t \n\tif (map->libbpf_type == LIBBPF_MAP_DATA && strcmp(map->real_name, DATA_SEC) != 0)\n\t\treturn true;\n\tif (map->libbpf_type == LIBBPF_MAP_RODATA && strcmp(map->real_name, RODATA_SEC) != 0)\n\t\treturn true;\n\treturn false;\n}\n\nconst char *bpf_map__name(const struct bpf_map *map)\n{\n\tif (!map)\n\t\treturn NULL;\n\n\tif (map_uses_real_name(map))\n\t\treturn map->real_name;\n\n\treturn map->name;\n}\n\nenum bpf_map_type bpf_map__type(const struct bpf_map *map)\n{\n\treturn map->def.type;\n}\n\nint bpf_map__set_type(struct bpf_map *map, enum bpf_map_type type)\n{\n\tif (map->fd >= 0)\n\t\treturn libbpf_err(-EBUSY);\n\tmap->def.type = type;\n\treturn 0;\n}\n\n__u32 bpf_map__map_flags(const struct bpf_map *map)\n{\n\treturn map->def.map_flags;\n}\n\nint bpf_map__set_map_flags(struct bpf_map *map, __u32 flags)\n{\n\tif (map->fd >= 0)\n\t\treturn libbpf_err(-EBUSY);\n\tmap->def.map_flags = flags;\n\treturn 0;\n}\n\n__u64 bpf_map__map_extra(const struct bpf_map *map)\n{\n\treturn map->map_extra;\n}\n\nint bpf_map__set_map_extra(struct bpf_map *map, __u64 map_extra)\n{\n\tif (map->fd >= 0)\n\t\treturn libbpf_err(-EBUSY);\n\tmap->map_extra = map_extra;\n\treturn 0;\n}\n\n__u32 bpf_map__numa_node(const struct bpf_map *map)\n{\n\treturn map->numa_node;\n}\n\nint bpf_map__set_numa_node(struct bpf_map *map, __u32 numa_node)\n{\n\tif (map->fd >= 0)\n\t\treturn libbpf_err(-EBUSY);\n\tmap->numa_node = numa_node;\n\treturn 0;\n}\n\n__u32 bpf_map__key_size(const struct bpf_map *map)\n{\n\treturn map->def.key_size;\n}\n\nint bpf_map__set_key_size(struct bpf_map *map, __u32 size)\n{\n\tif (map->fd >= 0)\n\t\treturn libbpf_err(-EBUSY);\n\tmap->def.key_size = size;\n\treturn 0;\n}\n\n__u32 bpf_map__value_size(const struct bpf_map *map)\n{\n\treturn map->def.value_size;\n}\n\nstatic int map_btf_datasec_resize(struct bpf_map *map, __u32 size)\n{\n\tstruct btf *btf;\n\tstruct btf_type *datasec_type, *var_type;\n\tstruct btf_var_secinfo *var;\n\tconst struct btf_type *array_type;\n\tconst struct btf_array *array;\n\tint vlen, element_sz, new_array_id;\n\t__u32 nr_elements;\n\n\t \n\tbtf = bpf_object__btf(map->obj);\n\tif (!btf)\n\t\treturn -ENOENT;\n\n\t \n\tdatasec_type = btf_type_by_id(btf, bpf_map__btf_value_type_id(map));\n\tif (!btf_is_datasec(datasec_type)) {\n\t\tpr_warn(\"map '%s': cannot be resized, map value type is not a datasec\\n\",\n\t\t\tbpf_map__name(map));\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tvlen = btf_vlen(datasec_type);\n\tif (vlen == 0) {\n\t\tpr_warn(\"map '%s': cannot be resized, map value datasec is empty\\n\",\n\t\t\tbpf_map__name(map));\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tvar = &btf_var_secinfos(datasec_type)[vlen - 1];\n\tvar_type = btf_type_by_id(btf, var->type);\n\tarray_type = skip_mods_and_typedefs(btf, var_type->type, NULL);\n\tif (!btf_is_array(array_type)) {\n\t\tpr_warn(\"map '%s': cannot be resized, last var must be an array\\n\",\n\t\t\tbpf_map__name(map));\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tarray = btf_array(array_type);\n\telement_sz = btf__resolve_size(btf, array->type);\n\tif (element_sz <= 0 || (size - var->offset) % element_sz != 0) {\n\t\tpr_warn(\"map '%s': cannot be resized, element size (%d) doesn't align with new total size (%u)\\n\",\n\t\t\tbpf_map__name(map), element_sz, size);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tnr_elements = (size - var->offset) / element_sz;\n\tnew_array_id = btf__add_array(btf, array->index_type, array->type, nr_elements);\n\tif (new_array_id < 0)\n\t\treturn new_array_id;\n\n\t \n\tdatasec_type = btf_type_by_id(btf, map->btf_value_type_id);\n\tvar = &btf_var_secinfos(datasec_type)[vlen - 1];\n\tvar_type = btf_type_by_id(btf, var->type);\n\n\t \n\tdatasec_type->size = size;\n\tvar->size = size - var->offset;\n\tvar_type->type = new_array_id;\n\n\treturn 0;\n}\n\nint bpf_map__set_value_size(struct bpf_map *map, __u32 size)\n{\n\tif (map->fd >= 0)\n\t\treturn libbpf_err(-EBUSY);\n\n\tif (map->mmaped) {\n\t\tint err;\n\t\tsize_t mmap_old_sz, mmap_new_sz;\n\n\t\tmmap_old_sz = bpf_map_mmap_sz(map->def.value_size, map->def.max_entries);\n\t\tmmap_new_sz = bpf_map_mmap_sz(size, map->def.max_entries);\n\t\terr = bpf_map_mmap_resize(map, mmap_old_sz, mmap_new_sz);\n\t\tif (err) {\n\t\t\tpr_warn(\"map '%s': failed to resize memory-mapped region: %d\\n\",\n\t\t\t\tbpf_map__name(map), err);\n\t\t\treturn err;\n\t\t}\n\t\terr = map_btf_datasec_resize(map, size);\n\t\tif (err && err != -ENOENT) {\n\t\t\tpr_warn(\"map '%s': failed to adjust resized BTF, clearing BTF key/value info: %d\\n\",\n\t\t\t\tbpf_map__name(map), err);\n\t\t\tmap->btf_value_type_id = 0;\n\t\t\tmap->btf_key_type_id = 0;\n\t\t}\n\t}\n\n\tmap->def.value_size = size;\n\treturn 0;\n}\n\n__u32 bpf_map__btf_key_type_id(const struct bpf_map *map)\n{\n\treturn map ? map->btf_key_type_id : 0;\n}\n\n__u32 bpf_map__btf_value_type_id(const struct bpf_map *map)\n{\n\treturn map ? map->btf_value_type_id : 0;\n}\n\nint bpf_map__set_initial_value(struct bpf_map *map,\n\t\t\t       const void *data, size_t size)\n{\n\tif (!map->mmaped || map->libbpf_type == LIBBPF_MAP_KCONFIG ||\n\t    size != map->def.value_size || map->fd >= 0)\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemcpy(map->mmaped, data, size);\n\treturn 0;\n}\n\nvoid *bpf_map__initial_value(struct bpf_map *map, size_t *psize)\n{\n\tif (!map->mmaped)\n\t\treturn NULL;\n\t*psize = map->def.value_size;\n\treturn map->mmaped;\n}\n\nbool bpf_map__is_internal(const struct bpf_map *map)\n{\n\treturn map->libbpf_type != LIBBPF_MAP_UNSPEC;\n}\n\n__u32 bpf_map__ifindex(const struct bpf_map *map)\n{\n\treturn map->map_ifindex;\n}\n\nint bpf_map__set_ifindex(struct bpf_map *map, __u32 ifindex)\n{\n\tif (map->fd >= 0)\n\t\treturn libbpf_err(-EBUSY);\n\tmap->map_ifindex = ifindex;\n\treturn 0;\n}\n\nint bpf_map__set_inner_map_fd(struct bpf_map *map, int fd)\n{\n\tif (!bpf_map_type__is_map_in_map(map->def.type)) {\n\t\tpr_warn(\"error: unsupported map type\\n\");\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\tif (map->inner_map_fd != -1) {\n\t\tpr_warn(\"error: inner_map_fd already specified\\n\");\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\tif (map->inner_map) {\n\t\tbpf_map__destroy(map->inner_map);\n\t\tzfree(&map->inner_map);\n\t}\n\tmap->inner_map_fd = fd;\n\treturn 0;\n}\n\nstatic struct bpf_map *\n__bpf_map__iter(const struct bpf_map *m, const struct bpf_object *obj, int i)\n{\n\tssize_t idx;\n\tstruct bpf_map *s, *e;\n\n\tif (!obj || !obj->maps)\n\t\treturn errno = EINVAL, NULL;\n\n\ts = obj->maps;\n\te = obj->maps + obj->nr_maps;\n\n\tif ((m < s) || (m >= e)) {\n\t\tpr_warn(\"error in %s: map handler doesn't belong to object\\n\",\n\t\t\t __func__);\n\t\treturn errno = EINVAL, NULL;\n\t}\n\n\tidx = (m - obj->maps) + i;\n\tif (idx >= obj->nr_maps || idx < 0)\n\t\treturn NULL;\n\treturn &obj->maps[idx];\n}\n\nstruct bpf_map *\nbpf_object__next_map(const struct bpf_object *obj, const struct bpf_map *prev)\n{\n\tif (prev == NULL)\n\t\treturn obj->maps;\n\n\treturn __bpf_map__iter(prev, obj, 1);\n}\n\nstruct bpf_map *\nbpf_object__prev_map(const struct bpf_object *obj, const struct bpf_map *next)\n{\n\tif (next == NULL) {\n\t\tif (!obj->nr_maps)\n\t\t\treturn NULL;\n\t\treturn obj->maps + obj->nr_maps - 1;\n\t}\n\n\treturn __bpf_map__iter(next, obj, -1);\n}\n\nstruct bpf_map *\nbpf_object__find_map_by_name(const struct bpf_object *obj, const char *name)\n{\n\tstruct bpf_map *pos;\n\n\tbpf_object__for_each_map(pos, obj) {\n\t\t \n\t\tif (name[0] == '.') {\n\t\t\tif (pos->real_name && strcmp(pos->real_name, name) == 0)\n\t\t\t\treturn pos;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tif (map_uses_real_name(pos)) {\n\t\t\tif (strcmp(pos->real_name, name) == 0)\n\t\t\t\treturn pos;\n\t\t\tcontinue;\n\t\t}\n\t\tif (strcmp(pos->name, name) == 0)\n\t\t\treturn pos;\n\t}\n\treturn errno = ENOENT, NULL;\n}\n\nint\nbpf_object__find_map_fd_by_name(const struct bpf_object *obj, const char *name)\n{\n\treturn bpf_map__fd(bpf_object__find_map_by_name(obj, name));\n}\n\nstatic int validate_map_op(const struct bpf_map *map, size_t key_sz,\n\t\t\t   size_t value_sz, bool check_value_sz)\n{\n\tif (map->fd <= 0)\n\t\treturn -ENOENT;\n\n\tif (map->def.key_size != key_sz) {\n\t\tpr_warn(\"map '%s': unexpected key size %zu provided, expected %u\\n\",\n\t\t\tmap->name, key_sz, map->def.key_size);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!check_value_sz)\n\t\treturn 0;\n\n\tswitch (map->def.type) {\n\tcase BPF_MAP_TYPE_PERCPU_ARRAY:\n\tcase BPF_MAP_TYPE_PERCPU_HASH:\n\tcase BPF_MAP_TYPE_LRU_PERCPU_HASH:\n\tcase BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE: {\n\t\tint num_cpu = libbpf_num_possible_cpus();\n\t\tsize_t elem_sz = roundup(map->def.value_size, 8);\n\n\t\tif (value_sz != num_cpu * elem_sz) {\n\t\t\tpr_warn(\"map '%s': unexpected value size %zu provided for per-CPU map, expected %d * %zu = %zd\\n\",\n\t\t\t\tmap->name, value_sz, num_cpu, elem_sz, num_cpu * elem_sz);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\t}\n\tdefault:\n\t\tif (map->def.value_size != value_sz) {\n\t\t\tpr_warn(\"map '%s': unexpected value size %zu provided, expected %u\\n\",\n\t\t\t\tmap->name, value_sz, map->def.value_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nint bpf_map__lookup_elem(const struct bpf_map *map,\n\t\t\t const void *key, size_t key_sz,\n\t\t\t void *value, size_t value_sz, __u64 flags)\n{\n\tint err;\n\n\terr = validate_map_op(map, key_sz, value_sz, true);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\treturn bpf_map_lookup_elem_flags(map->fd, key, value, flags);\n}\n\nint bpf_map__update_elem(const struct bpf_map *map,\n\t\t\t const void *key, size_t key_sz,\n\t\t\t const void *value, size_t value_sz, __u64 flags)\n{\n\tint err;\n\n\terr = validate_map_op(map, key_sz, value_sz, true);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\treturn bpf_map_update_elem(map->fd, key, value, flags);\n}\n\nint bpf_map__delete_elem(const struct bpf_map *map,\n\t\t\t const void *key, size_t key_sz, __u64 flags)\n{\n\tint err;\n\n\terr = validate_map_op(map, key_sz, 0, false  );\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\treturn bpf_map_delete_elem_flags(map->fd, key, flags);\n}\n\nint bpf_map__lookup_and_delete_elem(const struct bpf_map *map,\n\t\t\t\t    const void *key, size_t key_sz,\n\t\t\t\t    void *value, size_t value_sz, __u64 flags)\n{\n\tint err;\n\n\terr = validate_map_op(map, key_sz, value_sz, true);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\treturn bpf_map_lookup_and_delete_elem_flags(map->fd, key, value, flags);\n}\n\nint bpf_map__get_next_key(const struct bpf_map *map,\n\t\t\t  const void *cur_key, void *next_key, size_t key_sz)\n{\n\tint err;\n\n\terr = validate_map_op(map, key_sz, 0, false  );\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\treturn bpf_map_get_next_key(map->fd, cur_key, next_key);\n}\n\nlong libbpf_get_error(const void *ptr)\n{\n\tif (!IS_ERR_OR_NULL(ptr))\n\t\treturn 0;\n\n\tif (IS_ERR(ptr))\n\t\terrno = -PTR_ERR(ptr);\n\n\t \n\treturn -errno;\n}\n\n \nint bpf_link__update_program(struct bpf_link *link, struct bpf_program *prog)\n{\n\tint ret;\n\n\tret = bpf_link_update(bpf_link__fd(link), bpf_program__fd(prog), NULL);\n\treturn libbpf_err_errno(ret);\n}\n\n \nvoid bpf_link__disconnect(struct bpf_link *link)\n{\n\tlink->disconnected = true;\n}\n\nint bpf_link__destroy(struct bpf_link *link)\n{\n\tint err = 0;\n\n\tif (IS_ERR_OR_NULL(link))\n\t\treturn 0;\n\n\tif (!link->disconnected && link->detach)\n\t\terr = link->detach(link);\n\tif (link->pin_path)\n\t\tfree(link->pin_path);\n\tif (link->dealloc)\n\t\tlink->dealloc(link);\n\telse\n\t\tfree(link);\n\n\treturn libbpf_err(err);\n}\n\nint bpf_link__fd(const struct bpf_link *link)\n{\n\treturn link->fd;\n}\n\nconst char *bpf_link__pin_path(const struct bpf_link *link)\n{\n\treturn link->pin_path;\n}\n\nstatic int bpf_link__detach_fd(struct bpf_link *link)\n{\n\treturn libbpf_err_errno(close(link->fd));\n}\n\nstruct bpf_link *bpf_link__open(const char *path)\n{\n\tstruct bpf_link *link;\n\tint fd;\n\n\tfd = bpf_obj_get(path);\n\tif (fd < 0) {\n\t\tfd = -errno;\n\t\tpr_warn(\"failed to open link at %s: %d\\n\", path, fd);\n\t\treturn libbpf_err_ptr(fd);\n\t}\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link) {\n\t\tclose(fd);\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\t}\n\tlink->detach = &bpf_link__detach_fd;\n\tlink->fd = fd;\n\n\tlink->pin_path = strdup(path);\n\tif (!link->pin_path) {\n\t\tbpf_link__destroy(link);\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\t}\n\n\treturn link;\n}\n\nint bpf_link__detach(struct bpf_link *link)\n{\n\treturn bpf_link_detach(link->fd) ? -errno : 0;\n}\n\nint bpf_link__pin(struct bpf_link *link, const char *path)\n{\n\tint err;\n\n\tif (link->pin_path)\n\t\treturn libbpf_err(-EBUSY);\n\terr = make_parent_dir(path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\terr = check_path(path);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\tlink->pin_path = strdup(path);\n\tif (!link->pin_path)\n\t\treturn libbpf_err(-ENOMEM);\n\n\tif (bpf_obj_pin(link->fd, link->pin_path)) {\n\t\terr = -errno;\n\t\tzfree(&link->pin_path);\n\t\treturn libbpf_err(err);\n\t}\n\n\tpr_debug(\"link fd=%d: pinned at %s\\n\", link->fd, link->pin_path);\n\treturn 0;\n}\n\nint bpf_link__unpin(struct bpf_link *link)\n{\n\tint err;\n\n\tif (!link->pin_path)\n\t\treturn libbpf_err(-EINVAL);\n\n\terr = unlink(link->pin_path);\n\tif (err != 0)\n\t\treturn -errno;\n\n\tpr_debug(\"link fd=%d: unpinned from %s\\n\", link->fd, link->pin_path);\n\tzfree(&link->pin_path);\n\treturn 0;\n}\n\nstruct bpf_link_perf {\n\tstruct bpf_link link;\n\tint perf_event_fd;\n\t \n\tchar *legacy_probe_name;\n\tbool legacy_is_kprobe;\n\tbool legacy_is_retprobe;\n};\n\nstatic int remove_kprobe_event_legacy(const char *probe_name, bool retprobe);\nstatic int remove_uprobe_event_legacy(const char *probe_name, bool retprobe);\n\nstatic int bpf_link_perf_detach(struct bpf_link *link)\n{\n\tstruct bpf_link_perf *perf_link = container_of(link, struct bpf_link_perf, link);\n\tint err = 0;\n\n\tif (ioctl(perf_link->perf_event_fd, PERF_EVENT_IOC_DISABLE, 0) < 0)\n\t\terr = -errno;\n\n\tif (perf_link->perf_event_fd != link->fd)\n\t\tclose(perf_link->perf_event_fd);\n\tclose(link->fd);\n\n\t \n\tif (perf_link->legacy_probe_name) {\n\t\tif (perf_link->legacy_is_kprobe) {\n\t\t\terr = remove_kprobe_event_legacy(perf_link->legacy_probe_name,\n\t\t\t\t\t\t\t perf_link->legacy_is_retprobe);\n\t\t} else {\n\t\t\terr = remove_uprobe_event_legacy(perf_link->legacy_probe_name,\n\t\t\t\t\t\t\t perf_link->legacy_is_retprobe);\n\t\t}\n\t}\n\n\treturn err;\n}\n\nstatic void bpf_link_perf_dealloc(struct bpf_link *link)\n{\n\tstruct bpf_link_perf *perf_link = container_of(link, struct bpf_link_perf, link);\n\n\tfree(perf_link->legacy_probe_name);\n\tfree(perf_link);\n}\n\nstruct bpf_link *bpf_program__attach_perf_event_opts(const struct bpf_program *prog, int pfd,\n\t\t\t\t\t\t     const struct bpf_perf_event_opts *opts)\n{\n\tchar errmsg[STRERR_BUFSIZE];\n\tstruct bpf_link_perf *link;\n\tint prog_fd, link_fd = -1, err;\n\tbool force_ioctl_attach;\n\n\tif (!OPTS_VALID(opts, bpf_perf_event_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tif (pfd < 0) {\n\t\tpr_warn(\"prog '%s': invalid perf event FD %d\\n\",\n\t\t\tprog->name, pfd);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\tprog_fd = bpf_program__fd(prog);\n\tif (prog_fd < 0) {\n\t\tpr_warn(\"prog '%s': can't attach BPF program w/o FD (did you load it?)\\n\",\n\t\t\tprog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link)\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\tlink->link.detach = &bpf_link_perf_detach;\n\tlink->link.dealloc = &bpf_link_perf_dealloc;\n\tlink->perf_event_fd = pfd;\n\n\tforce_ioctl_attach = OPTS_GET(opts, force_ioctl_attach, false);\n\tif (kernel_supports(prog->obj, FEAT_PERF_LINK) && !force_ioctl_attach) {\n\t\tDECLARE_LIBBPF_OPTS(bpf_link_create_opts, link_opts,\n\t\t\t.perf_event.bpf_cookie = OPTS_GET(opts, bpf_cookie, 0));\n\n\t\tlink_fd = bpf_link_create(prog_fd, pfd, BPF_PERF_EVENT, &link_opts);\n\t\tif (link_fd < 0) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"prog '%s': failed to create BPF link for perf_event FD %d: %d (%s)\\n\",\n\t\t\t\tprog->name, pfd,\n\t\t\t\terr, libbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\t\tgoto err_out;\n\t\t}\n\t\tlink->link.fd = link_fd;\n\t} else {\n\t\tif (OPTS_GET(opts, bpf_cookie, 0)) {\n\t\t\tpr_warn(\"prog '%s': user context value is not supported\\n\", prog->name);\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (ioctl(pfd, PERF_EVENT_IOC_SET_BPF, prog_fd) < 0) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"prog '%s': failed to attach to perf_event FD %d: %s\\n\",\n\t\t\t\tprog->name, pfd, libbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\t\tif (err == -EPROTO)\n\t\t\t\tpr_warn(\"prog '%s': try add PERF_SAMPLE_CALLCHAIN to or remove exclude_callchain_[kernel|user] from pfd %d\\n\",\n\t\t\t\t\tprog->name, pfd);\n\t\t\tgoto err_out;\n\t\t}\n\t\tlink->link.fd = pfd;\n\t}\n\tif (ioctl(pfd, PERF_EVENT_IOC_ENABLE, 0) < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"prog '%s': failed to enable perf_event FD %d: %s\\n\",\n\t\t\tprog->name, pfd, libbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto err_out;\n\t}\n\n\treturn &link->link;\nerr_out:\n\tif (link_fd >= 0)\n\t\tclose(link_fd);\n\tfree(link);\n\treturn libbpf_err_ptr(err);\n}\n\nstruct bpf_link *bpf_program__attach_perf_event(const struct bpf_program *prog, int pfd)\n{\n\treturn bpf_program__attach_perf_event_opts(prog, pfd, NULL);\n}\n\n \nstatic int parse_uint_from_file(const char *file, const char *fmt)\n{\n\tchar buf[STRERR_BUFSIZE];\n\tint err, ret;\n\tFILE *f;\n\n\tf = fopen(file, \"re\");\n\tif (!f) {\n\t\terr = -errno;\n\t\tpr_debug(\"failed to open '%s': %s\\n\", file,\n\t\t\t libbpf_strerror_r(err, buf, sizeof(buf)));\n\t\treturn err;\n\t}\n\terr = fscanf(f, fmt, &ret);\n\tif (err != 1) {\n\t\terr = err == EOF ? -EIO : -errno;\n\t\tpr_debug(\"failed to parse '%s': %s\\n\", file,\n\t\t\tlibbpf_strerror_r(err, buf, sizeof(buf)));\n\t\tfclose(f);\n\t\treturn err;\n\t}\n\tfclose(f);\n\treturn ret;\n}\n\nstatic int determine_kprobe_perf_type(void)\n{\n\tconst char *file = \"/sys/bus/event_source/devices/kprobe/type\";\n\n\treturn parse_uint_from_file(file, \"%d\\n\");\n}\n\nstatic int determine_uprobe_perf_type(void)\n{\n\tconst char *file = \"/sys/bus/event_source/devices/uprobe/type\";\n\n\treturn parse_uint_from_file(file, \"%d\\n\");\n}\n\nstatic int determine_kprobe_retprobe_bit(void)\n{\n\tconst char *file = \"/sys/bus/event_source/devices/kprobe/format/retprobe\";\n\n\treturn parse_uint_from_file(file, \"config:%d\\n\");\n}\n\nstatic int determine_uprobe_retprobe_bit(void)\n{\n\tconst char *file = \"/sys/bus/event_source/devices/uprobe/format/retprobe\";\n\n\treturn parse_uint_from_file(file, \"config:%d\\n\");\n}\n\n#define PERF_UPROBE_REF_CTR_OFFSET_BITS 32\n#define PERF_UPROBE_REF_CTR_OFFSET_SHIFT 32\n\nstatic int perf_event_open_probe(bool uprobe, bool retprobe, const char *name,\n\t\t\t\t uint64_t offset, int pid, size_t ref_ctr_off)\n{\n\tconst size_t attr_sz = sizeof(struct perf_event_attr);\n\tstruct perf_event_attr attr;\n\tchar errmsg[STRERR_BUFSIZE];\n\tint type, pfd;\n\n\tif ((__u64)ref_ctr_off >= (1ULL << PERF_UPROBE_REF_CTR_OFFSET_BITS))\n\t\treturn -EINVAL;\n\n\tmemset(&attr, 0, attr_sz);\n\n\ttype = uprobe ? determine_uprobe_perf_type()\n\t\t      : determine_kprobe_perf_type();\n\tif (type < 0) {\n\t\tpr_warn(\"failed to determine %s perf type: %s\\n\",\n\t\t\tuprobe ? \"uprobe\" : \"kprobe\",\n\t\t\tlibbpf_strerror_r(type, errmsg, sizeof(errmsg)));\n\t\treturn type;\n\t}\n\tif (retprobe) {\n\t\tint bit = uprobe ? determine_uprobe_retprobe_bit()\n\t\t\t\t : determine_kprobe_retprobe_bit();\n\n\t\tif (bit < 0) {\n\t\t\tpr_warn(\"failed to determine %s retprobe bit: %s\\n\",\n\t\t\t\tuprobe ? \"uprobe\" : \"kprobe\",\n\t\t\t\tlibbpf_strerror_r(bit, errmsg, sizeof(errmsg)));\n\t\t\treturn bit;\n\t\t}\n\t\tattr.config |= 1 << bit;\n\t}\n\tattr.size = attr_sz;\n\tattr.type = type;\n\tattr.config |= (__u64)ref_ctr_off << PERF_UPROBE_REF_CTR_OFFSET_SHIFT;\n\tattr.config1 = ptr_to_u64(name);  \n\tattr.config2 = offset;\t\t  \n\n\t \n\tpfd = syscall(__NR_perf_event_open, &attr,\n\t\t      pid < 0 ? -1 : pid  ,\n\t\t      pid == -1 ? 0 : -1  ,\n\t\t      -1  , PERF_FLAG_FD_CLOEXEC);\n\treturn pfd >= 0 ? pfd : -errno;\n}\n\nstatic int append_to_file(const char *file, const char *fmt, ...)\n{\n\tint fd, n, err = 0;\n\tva_list ap;\n\tchar buf[1024];\n\n\tva_start(ap, fmt);\n\tn = vsnprintf(buf, sizeof(buf), fmt, ap);\n\tva_end(ap);\n\n\tif (n < 0 || n >= sizeof(buf))\n\t\treturn -EINVAL;\n\n\tfd = open(file, O_WRONLY | O_APPEND | O_CLOEXEC, 0);\n\tif (fd < 0)\n\t\treturn -errno;\n\n\tif (write(fd, buf, n) < 0)\n\t\terr = -errno;\n\n\tclose(fd);\n\treturn err;\n}\n\n#define DEBUGFS \"/sys/kernel/debug/tracing\"\n#define TRACEFS \"/sys/kernel/tracing\"\n\nstatic bool use_debugfs(void)\n{\n\tstatic int has_debugfs = -1;\n\n\tif (has_debugfs < 0)\n\t\thas_debugfs = faccessat(AT_FDCWD, DEBUGFS, F_OK, AT_EACCESS) == 0;\n\n\treturn has_debugfs == 1;\n}\n\nstatic const char *tracefs_path(void)\n{\n\treturn use_debugfs() ? DEBUGFS : TRACEFS;\n}\n\nstatic const char *tracefs_kprobe_events(void)\n{\n\treturn use_debugfs() ? DEBUGFS\"/kprobe_events\" : TRACEFS\"/kprobe_events\";\n}\n\nstatic const char *tracefs_uprobe_events(void)\n{\n\treturn use_debugfs() ? DEBUGFS\"/uprobe_events\" : TRACEFS\"/uprobe_events\";\n}\n\nstatic const char *tracefs_available_filter_functions(void)\n{\n\treturn use_debugfs() ? DEBUGFS\"/available_filter_functions\"\n\t\t\t     : TRACEFS\"/available_filter_functions\";\n}\n\nstatic const char *tracefs_available_filter_functions_addrs(void)\n{\n\treturn use_debugfs() ? DEBUGFS\"/available_filter_functions_addrs\"\n\t\t\t     : TRACEFS\"/available_filter_functions_addrs\";\n}\n\nstatic void gen_kprobe_legacy_event_name(char *buf, size_t buf_sz,\n\t\t\t\t\t const char *kfunc_name, size_t offset)\n{\n\tstatic int index = 0;\n\tint i;\n\n\tsnprintf(buf, buf_sz, \"libbpf_%u_%s_0x%zx_%d\", getpid(), kfunc_name, offset,\n\t\t __sync_fetch_and_add(&index, 1));\n\n\t \n\tfor (i = 0; buf[i]; i++) {\n\t\tif (!isalnum(buf[i]))\n\t\t\tbuf[i] = '_';\n\t}\n}\n\nstatic int add_kprobe_event_legacy(const char *probe_name, bool retprobe,\n\t\t\t\t   const char *kfunc_name, size_t offset)\n{\n\treturn append_to_file(tracefs_kprobe_events(), \"%c:%s/%s %s+0x%zx\",\n\t\t\t      retprobe ? 'r' : 'p',\n\t\t\t      retprobe ? \"kretprobes\" : \"kprobes\",\n\t\t\t      probe_name, kfunc_name, offset);\n}\n\nstatic int remove_kprobe_event_legacy(const char *probe_name, bool retprobe)\n{\n\treturn append_to_file(tracefs_kprobe_events(), \"-:%s/%s\",\n\t\t\t      retprobe ? \"kretprobes\" : \"kprobes\", probe_name);\n}\n\nstatic int determine_kprobe_perf_type_legacy(const char *probe_name, bool retprobe)\n{\n\tchar file[256];\n\n\tsnprintf(file, sizeof(file), \"%s/events/%s/%s/id\",\n\t\t tracefs_path(), retprobe ? \"kretprobes\" : \"kprobes\", probe_name);\n\n\treturn parse_uint_from_file(file, \"%d\\n\");\n}\n\nstatic int perf_event_kprobe_open_legacy(const char *probe_name, bool retprobe,\n\t\t\t\t\t const char *kfunc_name, size_t offset, int pid)\n{\n\tconst size_t attr_sz = sizeof(struct perf_event_attr);\n\tstruct perf_event_attr attr;\n\tchar errmsg[STRERR_BUFSIZE];\n\tint type, pfd, err;\n\n\terr = add_kprobe_event_legacy(probe_name, retprobe, kfunc_name, offset);\n\tif (err < 0) {\n\t\tpr_warn(\"failed to add legacy kprobe event for '%s+0x%zx': %s\\n\",\n\t\t\tkfunc_name, offset,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\treturn err;\n\t}\n\ttype = determine_kprobe_perf_type_legacy(probe_name, retprobe);\n\tif (type < 0) {\n\t\terr = type;\n\t\tpr_warn(\"failed to determine legacy kprobe event id for '%s+0x%zx': %s\\n\",\n\t\t\tkfunc_name, offset,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto err_clean_legacy;\n\t}\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.size = attr_sz;\n\tattr.config = type;\n\tattr.type = PERF_TYPE_TRACEPOINT;\n\n\tpfd = syscall(__NR_perf_event_open, &attr,\n\t\t      pid < 0 ? -1 : pid,  \n\t\t      pid == -1 ? 0 : -1,  \n\t\t      -1  ,  PERF_FLAG_FD_CLOEXEC);\n\tif (pfd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"legacy kprobe perf_event_open() failed: %s\\n\",\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto err_clean_legacy;\n\t}\n\treturn pfd;\n\nerr_clean_legacy:\n\t \n\tremove_kprobe_event_legacy(probe_name, retprobe);\n\treturn err;\n}\n\nstatic const char *arch_specific_syscall_pfx(void)\n{\n#if defined(__x86_64__)\n\treturn \"x64\";\n#elif defined(__i386__)\n\treturn \"ia32\";\n#elif defined(__s390x__)\n\treturn \"s390x\";\n#elif defined(__s390__)\n\treturn \"s390\";\n#elif defined(__arm__)\n\treturn \"arm\";\n#elif defined(__aarch64__)\n\treturn \"arm64\";\n#elif defined(__mips__)\n\treturn \"mips\";\n#elif defined(__riscv)\n\treturn \"riscv\";\n#elif defined(__powerpc__)\n\treturn \"powerpc\";\n#elif defined(__powerpc64__)\n\treturn \"powerpc64\";\n#else\n\treturn NULL;\n#endif\n}\n\nstatic int probe_kern_syscall_wrapper(void)\n{\n\tchar syscall_name[64];\n\tconst char *ksys_pfx;\n\n\tksys_pfx = arch_specific_syscall_pfx();\n\tif (!ksys_pfx)\n\t\treturn 0;\n\n\tsnprintf(syscall_name, sizeof(syscall_name), \"__%s_sys_bpf\", ksys_pfx);\n\n\tif (determine_kprobe_perf_type() >= 0) {\n\t\tint pfd;\n\n\t\tpfd = perf_event_open_probe(false, false, syscall_name, 0, getpid(), 0);\n\t\tif (pfd >= 0)\n\t\t\tclose(pfd);\n\n\t\treturn pfd >= 0 ? 1 : 0;\n\t} else {  \n\t\tchar probe_name[128];\n\n\t\tgen_kprobe_legacy_event_name(probe_name, sizeof(probe_name), syscall_name, 0);\n\t\tif (add_kprobe_event_legacy(probe_name, false, syscall_name, 0) < 0)\n\t\t\treturn 0;\n\n\t\t(void)remove_kprobe_event_legacy(probe_name, false);\n\t\treturn 1;\n\t}\n}\n\nstruct bpf_link *\nbpf_program__attach_kprobe_opts(const struct bpf_program *prog,\n\t\t\t\tconst char *func_name,\n\t\t\t\tconst struct bpf_kprobe_opts *opts)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_perf_event_opts, pe_opts);\n\tenum probe_attach_mode attach_mode;\n\tchar errmsg[STRERR_BUFSIZE];\n\tchar *legacy_probe = NULL;\n\tstruct bpf_link *link;\n\tsize_t offset;\n\tbool retprobe, legacy;\n\tint pfd, err;\n\n\tif (!OPTS_VALID(opts, bpf_kprobe_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tattach_mode = OPTS_GET(opts, attach_mode, PROBE_ATTACH_MODE_DEFAULT);\n\tretprobe = OPTS_GET(opts, retprobe, false);\n\toffset = OPTS_GET(opts, offset, 0);\n\tpe_opts.bpf_cookie = OPTS_GET(opts, bpf_cookie, 0);\n\n\tlegacy = determine_kprobe_perf_type() < 0;\n\tswitch (attach_mode) {\n\tcase PROBE_ATTACH_MODE_LEGACY:\n\t\tlegacy = true;\n\t\tpe_opts.force_ioctl_attach = true;\n\t\tbreak;\n\tcase PROBE_ATTACH_MODE_PERF:\n\t\tif (legacy)\n\t\t\treturn libbpf_err_ptr(-ENOTSUP);\n\t\tpe_opts.force_ioctl_attach = true;\n\t\tbreak;\n\tcase PROBE_ATTACH_MODE_LINK:\n\t\tif (legacy || !kernel_supports(prog->obj, FEAT_PERF_LINK))\n\t\t\treturn libbpf_err_ptr(-ENOTSUP);\n\t\tbreak;\n\tcase PROBE_ATTACH_MODE_DEFAULT:\n\t\tbreak;\n\tdefault:\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tif (!legacy) {\n\t\tpfd = perf_event_open_probe(false  , retprobe,\n\t\t\t\t\t    func_name, offset,\n\t\t\t\t\t    -1  , 0  );\n\t} else {\n\t\tchar probe_name[256];\n\n\t\tgen_kprobe_legacy_event_name(probe_name, sizeof(probe_name),\n\t\t\t\t\t     func_name, offset);\n\n\t\tlegacy_probe = strdup(probe_name);\n\t\tif (!legacy_probe)\n\t\t\treturn libbpf_err_ptr(-ENOMEM);\n\n\t\tpfd = perf_event_kprobe_open_legacy(legacy_probe, retprobe, func_name,\n\t\t\t\t\t\t    offset, -1  );\n\t}\n\tif (pfd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"prog '%s': failed to create %s '%s+0x%zx' perf event: %s\\n\",\n\t\t\tprog->name, retprobe ? \"kretprobe\" : \"kprobe\",\n\t\t\tfunc_name, offset,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto err_out;\n\t}\n\tlink = bpf_program__attach_perf_event_opts(prog, pfd, &pe_opts);\n\terr = libbpf_get_error(link);\n\tif (err) {\n\t\tclose(pfd);\n\t\tpr_warn(\"prog '%s': failed to attach to %s '%s+0x%zx': %s\\n\",\n\t\t\tprog->name, retprobe ? \"kretprobe\" : \"kprobe\",\n\t\t\tfunc_name, offset,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto err_clean_legacy;\n\t}\n\tif (legacy) {\n\t\tstruct bpf_link_perf *perf_link = container_of(link, struct bpf_link_perf, link);\n\n\t\tperf_link->legacy_probe_name = legacy_probe;\n\t\tperf_link->legacy_is_kprobe = true;\n\t\tperf_link->legacy_is_retprobe = retprobe;\n\t}\n\n\treturn link;\n\nerr_clean_legacy:\n\tif (legacy)\n\t\tremove_kprobe_event_legacy(legacy_probe, retprobe);\nerr_out:\n\tfree(legacy_probe);\n\treturn libbpf_err_ptr(err);\n}\n\nstruct bpf_link *bpf_program__attach_kprobe(const struct bpf_program *prog,\n\t\t\t\t\t    bool retprobe,\n\t\t\t\t\t    const char *func_name)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_kprobe_opts, opts,\n\t\t.retprobe = retprobe,\n\t);\n\n\treturn bpf_program__attach_kprobe_opts(prog, func_name, &opts);\n}\n\nstruct bpf_link *bpf_program__attach_ksyscall(const struct bpf_program *prog,\n\t\t\t\t\t      const char *syscall_name,\n\t\t\t\t\t      const struct bpf_ksyscall_opts *opts)\n{\n\tLIBBPF_OPTS(bpf_kprobe_opts, kprobe_opts);\n\tchar func_name[128];\n\n\tif (!OPTS_VALID(opts, bpf_ksyscall_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tif (kernel_supports(prog->obj, FEAT_SYSCALL_WRAPPER)) {\n\t\t \n\t\tsnprintf(func_name, sizeof(func_name), \"__%s_sys_%s\",\n\t\t\t arch_specific_syscall_pfx() ? : \"\", syscall_name);\n\t} else {\n\t\tsnprintf(func_name, sizeof(func_name), \"__se_sys_%s\", syscall_name);\n\t}\n\n\tkprobe_opts.retprobe = OPTS_GET(opts, retprobe, false);\n\tkprobe_opts.bpf_cookie = OPTS_GET(opts, bpf_cookie, 0);\n\n\treturn bpf_program__attach_kprobe_opts(prog, func_name, &kprobe_opts);\n}\n\n \nbool glob_match(const char *str, const char *pat)\n{\n\twhile (*str && *pat && *pat != '*') {\n\t\tif (*pat == '?') {       \n\t\t\tstr++;\n\t\t\tpat++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (*str != *pat)\n\t\t\treturn false;\n\t\tstr++;\n\t\tpat++;\n\t}\n\t \n\tif (*pat == '*') {\n\t\twhile (*pat == '*')\n\t\t\tpat++;\n\t\tif (!*pat)  \n\t\t\treturn true;\n\t\twhile (*str)\n\t\t\tif (glob_match(str++, pat))\n\t\t\t\treturn true;\n\t}\n\treturn !*str && !*pat;\n}\n\nstruct kprobe_multi_resolve {\n\tconst char *pattern;\n\tunsigned long *addrs;\n\tsize_t cap;\n\tsize_t cnt;\n};\n\nstruct avail_kallsyms_data {\n\tchar **syms;\n\tsize_t cnt;\n\tstruct kprobe_multi_resolve *res;\n};\n\nstatic int avail_func_cmp(const void *a, const void *b)\n{\n\treturn strcmp(*(const char **)a, *(const char **)b);\n}\n\nstatic int avail_kallsyms_cb(unsigned long long sym_addr, char sym_type,\n\t\t\t     const char *sym_name, void *ctx)\n{\n\tstruct avail_kallsyms_data *data = ctx;\n\tstruct kprobe_multi_resolve *res = data->res;\n\tint err;\n\n\tif (!bsearch(&sym_name, data->syms, data->cnt, sizeof(*data->syms), avail_func_cmp))\n\t\treturn 0;\n\n\terr = libbpf_ensure_mem((void **)&res->addrs, &res->cap, sizeof(*res->addrs), res->cnt + 1);\n\tif (err)\n\t\treturn err;\n\n\tres->addrs[res->cnt++] = (unsigned long)sym_addr;\n\treturn 0;\n}\n\nstatic int libbpf_available_kallsyms_parse(struct kprobe_multi_resolve *res)\n{\n\tconst char *available_functions_file = tracefs_available_filter_functions();\n\tstruct avail_kallsyms_data data;\n\tchar sym_name[500];\n\tFILE *f;\n\tint err = 0, ret, i;\n\tchar **syms = NULL;\n\tsize_t cap = 0, cnt = 0;\n\n\tf = fopen(available_functions_file, \"re\");\n\tif (!f) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to open %s: %d\\n\", available_functions_file, err);\n\t\treturn err;\n\t}\n\n\twhile (true) {\n\t\tchar *name;\n\n\t\tret = fscanf(f, \"%499s%*[^\\n]\\n\", sym_name);\n\t\tif (ret == EOF && feof(f))\n\t\t\tbreak;\n\n\t\tif (ret != 1) {\n\t\t\tpr_warn(\"failed to parse available_filter_functions entry: %d\\n\", ret);\n\t\t\terr = -EINVAL;\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tif (!glob_match(sym_name, res->pattern))\n\t\t\tcontinue;\n\n\t\terr = libbpf_ensure_mem((void **)&syms, &cap, sizeof(*syms), cnt + 1);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\n\t\tname = strdup(sym_name);\n\t\tif (!name) {\n\t\t\terr = -errno;\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tsyms[cnt++] = name;\n\t}\n\n\t \n\tif (cnt == 0) {\n\t\terr = -ENOENT;\n\t\tgoto cleanup;\n\t}\n\n\t \n\tqsort(syms, cnt, sizeof(*syms), avail_func_cmp);\n\n\tdata.syms = syms;\n\tdata.res = res;\n\tdata.cnt = cnt;\n\tlibbpf_kallsyms_parse(avail_kallsyms_cb, &data);\n\n\tif (res->cnt == 0)\n\t\terr = -ENOENT;\n\ncleanup:\n\tfor (i = 0; i < cnt; i++)\n\t\tfree((char *)syms[i]);\n\tfree(syms);\n\n\tfclose(f);\n\treturn err;\n}\n\nstatic bool has_available_filter_functions_addrs(void)\n{\n\treturn access(tracefs_available_filter_functions_addrs(), R_OK) != -1;\n}\n\nstatic int libbpf_available_kprobes_parse(struct kprobe_multi_resolve *res)\n{\n\tconst char *available_path = tracefs_available_filter_functions_addrs();\n\tchar sym_name[500];\n\tFILE *f;\n\tint ret, err = 0;\n\tunsigned long long sym_addr;\n\n\tf = fopen(available_path, \"re\");\n\tif (!f) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to open %s: %d\\n\", available_path, err);\n\t\treturn err;\n\t}\n\n\twhile (true) {\n\t\tret = fscanf(f, \"%llx %499s%*[^\\n]\\n\", &sym_addr, sym_name);\n\t\tif (ret == EOF && feof(f))\n\t\t\tbreak;\n\n\t\tif (ret != 2) {\n\t\t\tpr_warn(\"failed to parse available_filter_functions_addrs entry: %d\\n\",\n\t\t\t\tret);\n\t\t\terr = -EINVAL;\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tif (!glob_match(sym_name, res->pattern))\n\t\t\tcontinue;\n\n\t\terr = libbpf_ensure_mem((void **)&res->addrs, &res->cap,\n\t\t\t\t\tsizeof(*res->addrs), res->cnt + 1);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\n\t\tres->addrs[res->cnt++] = (unsigned long)sym_addr;\n\t}\n\n\tif (res->cnt == 0)\n\t\terr = -ENOENT;\n\ncleanup:\n\tfclose(f);\n\treturn err;\n}\n\nstruct bpf_link *\nbpf_program__attach_kprobe_multi_opts(const struct bpf_program *prog,\n\t\t\t\t      const char *pattern,\n\t\t\t\t      const struct bpf_kprobe_multi_opts *opts)\n{\n\tLIBBPF_OPTS(bpf_link_create_opts, lopts);\n\tstruct kprobe_multi_resolve res = {\n\t\t.pattern = pattern,\n\t};\n\tstruct bpf_link *link = NULL;\n\tchar errmsg[STRERR_BUFSIZE];\n\tconst unsigned long *addrs;\n\tint err, link_fd, prog_fd;\n\tconst __u64 *cookies;\n\tconst char **syms;\n\tbool retprobe;\n\tsize_t cnt;\n\n\tif (!OPTS_VALID(opts, bpf_kprobe_multi_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tsyms    = OPTS_GET(opts, syms, false);\n\taddrs   = OPTS_GET(opts, addrs, false);\n\tcnt     = OPTS_GET(opts, cnt, false);\n\tcookies = OPTS_GET(opts, cookies, false);\n\n\tif (!pattern && !addrs && !syms)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\tif (pattern && (addrs || syms || cookies || cnt))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\tif (!pattern && !cnt)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\tif (addrs && syms)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tif (pattern) {\n\t\tif (has_available_filter_functions_addrs())\n\t\t\terr = libbpf_available_kprobes_parse(&res);\n\t\telse\n\t\t\terr = libbpf_available_kallsyms_parse(&res);\n\t\tif (err)\n\t\t\tgoto error;\n\t\taddrs = res.addrs;\n\t\tcnt = res.cnt;\n\t}\n\n\tretprobe = OPTS_GET(opts, retprobe, false);\n\n\tlopts.kprobe_multi.syms = syms;\n\tlopts.kprobe_multi.addrs = addrs;\n\tlopts.kprobe_multi.cookies = cookies;\n\tlopts.kprobe_multi.cnt = cnt;\n\tlopts.kprobe_multi.flags = retprobe ? BPF_F_KPROBE_MULTI_RETURN : 0;\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link) {\n\t\terr = -ENOMEM;\n\t\tgoto error;\n\t}\n\tlink->detach = &bpf_link__detach_fd;\n\n\tprog_fd = bpf_program__fd(prog);\n\tlink_fd = bpf_link_create(prog_fd, 0, BPF_TRACE_KPROBE_MULTI, &lopts);\n\tif (link_fd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"prog '%s': failed to attach: %s\\n\",\n\t\t\tprog->name, libbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto error;\n\t}\n\tlink->fd = link_fd;\n\tfree(res.addrs);\n\treturn link;\n\nerror:\n\tfree(link);\n\tfree(res.addrs);\n\treturn libbpf_err_ptr(err);\n}\n\nstatic int attach_kprobe(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_kprobe_opts, opts);\n\tunsigned long offset = 0;\n\tconst char *func_name;\n\tchar *func;\n\tint n;\n\n\t*link = NULL;\n\n\t \n\tif (strcmp(prog->sec_name, \"kprobe\") == 0 || strcmp(prog->sec_name, \"kretprobe\") == 0)\n\t\treturn 0;\n\n\topts.retprobe = str_has_pfx(prog->sec_name, \"kretprobe/\");\n\tif (opts.retprobe)\n\t\tfunc_name = prog->sec_name + sizeof(\"kretprobe/\") - 1;\n\telse\n\t\tfunc_name = prog->sec_name + sizeof(\"kprobe/\") - 1;\n\n\tn = sscanf(func_name, \"%m[a-zA-Z0-9_.]+%li\", &func, &offset);\n\tif (n < 1) {\n\t\tpr_warn(\"kprobe name is invalid: %s\\n\", func_name);\n\t\treturn -EINVAL;\n\t}\n\tif (opts.retprobe && offset != 0) {\n\t\tfree(func);\n\t\tpr_warn(\"kretprobes do not support offset specification\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\topts.offset = offset;\n\t*link = bpf_program__attach_kprobe_opts(prog, func, &opts);\n\tfree(func);\n\treturn libbpf_get_error(*link);\n}\n\nstatic int attach_ksyscall(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tLIBBPF_OPTS(bpf_ksyscall_opts, opts);\n\tconst char *syscall_name;\n\n\t*link = NULL;\n\n\t \n\tif (strcmp(prog->sec_name, \"ksyscall\") == 0 || strcmp(prog->sec_name, \"kretsyscall\") == 0)\n\t\treturn 0;\n\n\topts.retprobe = str_has_pfx(prog->sec_name, \"kretsyscall/\");\n\tif (opts.retprobe)\n\t\tsyscall_name = prog->sec_name + sizeof(\"kretsyscall/\") - 1;\n\telse\n\t\tsyscall_name = prog->sec_name + sizeof(\"ksyscall/\") - 1;\n\n\t*link = bpf_program__attach_ksyscall(prog, syscall_name, &opts);\n\treturn *link ? 0 : -errno;\n}\n\nstatic int attach_kprobe_multi(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tLIBBPF_OPTS(bpf_kprobe_multi_opts, opts);\n\tconst char *spec;\n\tchar *pattern;\n\tint n;\n\n\t*link = NULL;\n\n\t \n\tif (strcmp(prog->sec_name, \"kprobe.multi\") == 0 ||\n\t    strcmp(prog->sec_name, \"kretprobe.multi\") == 0)\n\t\treturn 0;\n\n\topts.retprobe = str_has_pfx(prog->sec_name, \"kretprobe.multi/\");\n\tif (opts.retprobe)\n\t\tspec = prog->sec_name + sizeof(\"kretprobe.multi/\") - 1;\n\telse\n\t\tspec = prog->sec_name + sizeof(\"kprobe.multi/\") - 1;\n\n\tn = sscanf(spec, \"%m[a-zA-Z0-9_.*?]\", &pattern);\n\tif (n < 1) {\n\t\tpr_warn(\"kprobe multi pattern is invalid: %s\\n\", pattern);\n\t\treturn -EINVAL;\n\t}\n\n\t*link = bpf_program__attach_kprobe_multi_opts(prog, pattern, &opts);\n\tfree(pattern);\n\treturn libbpf_get_error(*link);\n}\n\nstatic int attach_uprobe_multi(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tchar *probe_type = NULL, *binary_path = NULL, *func_name = NULL;\n\tLIBBPF_OPTS(bpf_uprobe_multi_opts, opts);\n\tint n, ret = -EINVAL;\n\n\t*link = NULL;\n\n\tn = sscanf(prog->sec_name, \"%m[^/]/%m[^:]:%ms\",\n\t\t   &probe_type, &binary_path, &func_name);\n\tswitch (n) {\n\tcase 1:\n\t\t \n\t\tret = 0;\n\t\tbreak;\n\tcase 3:\n\t\topts.retprobe = strcmp(probe_type, \"uretprobe.multi\") == 0;\n\t\t*link = bpf_program__attach_uprobe_multi(prog, -1, binary_path, func_name, &opts);\n\t\tret = libbpf_get_error(*link);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"prog '%s': invalid format of section definition '%s'\\n\", prog->name,\n\t\t\tprog->sec_name);\n\t\tbreak;\n\t}\n\tfree(probe_type);\n\tfree(binary_path);\n\tfree(func_name);\n\treturn ret;\n}\n\nstatic void gen_uprobe_legacy_event_name(char *buf, size_t buf_sz,\n\t\t\t\t\t const char *binary_path, uint64_t offset)\n{\n\tint i;\n\n\tsnprintf(buf, buf_sz, \"libbpf_%u_%s_0x%zx\", getpid(), binary_path, (size_t)offset);\n\n\t \n\tfor (i = 0; buf[i]; i++) {\n\t\tif (!isalnum(buf[i]))\n\t\t\tbuf[i] = '_';\n\t}\n}\n\nstatic inline int add_uprobe_event_legacy(const char *probe_name, bool retprobe,\n\t\t\t\t\t  const char *binary_path, size_t offset)\n{\n\treturn append_to_file(tracefs_uprobe_events(), \"%c:%s/%s %s:0x%zx\",\n\t\t\t      retprobe ? 'r' : 'p',\n\t\t\t      retprobe ? \"uretprobes\" : \"uprobes\",\n\t\t\t      probe_name, binary_path, offset);\n}\n\nstatic inline int remove_uprobe_event_legacy(const char *probe_name, bool retprobe)\n{\n\treturn append_to_file(tracefs_uprobe_events(), \"-:%s/%s\",\n\t\t\t      retprobe ? \"uretprobes\" : \"uprobes\", probe_name);\n}\n\nstatic int determine_uprobe_perf_type_legacy(const char *probe_name, bool retprobe)\n{\n\tchar file[512];\n\n\tsnprintf(file, sizeof(file), \"%s/events/%s/%s/id\",\n\t\t tracefs_path(), retprobe ? \"uretprobes\" : \"uprobes\", probe_name);\n\n\treturn parse_uint_from_file(file, \"%d\\n\");\n}\n\nstatic int perf_event_uprobe_open_legacy(const char *probe_name, bool retprobe,\n\t\t\t\t\t const char *binary_path, size_t offset, int pid)\n{\n\tconst size_t attr_sz = sizeof(struct perf_event_attr);\n\tstruct perf_event_attr attr;\n\tint type, pfd, err;\n\n\terr = add_uprobe_event_legacy(probe_name, retprobe, binary_path, offset);\n\tif (err < 0) {\n\t\tpr_warn(\"failed to add legacy uprobe event for %s:0x%zx: %d\\n\",\n\t\t\tbinary_path, (size_t)offset, err);\n\t\treturn err;\n\t}\n\ttype = determine_uprobe_perf_type_legacy(probe_name, retprobe);\n\tif (type < 0) {\n\t\terr = type;\n\t\tpr_warn(\"failed to determine legacy uprobe event id for %s:0x%zx: %d\\n\",\n\t\t\tbinary_path, offset, err);\n\t\tgoto err_clean_legacy;\n\t}\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.size = attr_sz;\n\tattr.config = type;\n\tattr.type = PERF_TYPE_TRACEPOINT;\n\n\tpfd = syscall(__NR_perf_event_open, &attr,\n\t\t      pid < 0 ? -1 : pid,  \n\t\t      pid == -1 ? 0 : -1,  \n\t\t      -1  ,  PERF_FLAG_FD_CLOEXEC);\n\tif (pfd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"legacy uprobe perf_event_open() failed: %d\\n\", err);\n\t\tgoto err_clean_legacy;\n\t}\n\treturn pfd;\n\nerr_clean_legacy:\n\t \n\tremove_uprobe_event_legacy(probe_name, retprobe);\n\treturn err;\n}\n\n \nstatic long elf_find_func_offset_from_archive(const char *archive_path, const char *file_name,\n\t\t\t\t\t      const char *func_name)\n{\n\tstruct zip_archive *archive;\n\tstruct zip_entry entry;\n\tlong ret;\n\tElf *elf;\n\n\tarchive = zip_archive_open(archive_path);\n\tif (IS_ERR(archive)) {\n\t\tret = PTR_ERR(archive);\n\t\tpr_warn(\"zip: failed to open %s: %ld\\n\", archive_path, ret);\n\t\treturn ret;\n\t}\n\n\tret = zip_archive_find_entry(archive, file_name, &entry);\n\tif (ret) {\n\t\tpr_warn(\"zip: could not find archive member %s in %s: %ld\\n\", file_name,\n\t\t\tarchive_path, ret);\n\t\tgoto out;\n\t}\n\tpr_debug(\"zip: found entry for %s in %s at 0x%lx\\n\", file_name, archive_path,\n\t\t (unsigned long)entry.data_offset);\n\n\tif (entry.compression) {\n\t\tpr_warn(\"zip: entry %s of %s is compressed and cannot be handled\\n\", file_name,\n\t\t\tarchive_path);\n\t\tret = -LIBBPF_ERRNO__FORMAT;\n\t\tgoto out;\n\t}\n\n\telf = elf_memory((void *)entry.data, entry.data_length);\n\tif (!elf) {\n\t\tpr_warn(\"elf: could not read elf file %s from %s: %s\\n\", file_name, archive_path,\n\t\t\telf_errmsg(-1));\n\t\tret = -LIBBPF_ERRNO__LIBELF;\n\t\tgoto out;\n\t}\n\n\tret = elf_find_func_offset(elf, file_name, func_name);\n\tif (ret > 0) {\n\t\tpr_debug(\"elf: symbol address match for %s of %s in %s: 0x%x + 0x%lx = 0x%lx\\n\",\n\t\t\t func_name, file_name, archive_path, entry.data_offset, ret,\n\t\t\t ret + entry.data_offset);\n\t\tret += entry.data_offset;\n\t}\n\telf_end(elf);\n\nout:\n\tzip_archive_close(archive);\n\treturn ret;\n}\n\nstatic const char *arch_specific_lib_paths(void)\n{\n\t \n#if defined(__x86_64__)\n\treturn \"/lib/x86_64-linux-gnu\";\n#elif defined(__i386__)\n\treturn \"/lib/i386-linux-gnu\";\n#elif defined(__s390x__)\n\treturn \"/lib/s390x-linux-gnu\";\n#elif defined(__s390__)\n\treturn \"/lib/s390-linux-gnu\";\n#elif defined(__arm__) && defined(__SOFTFP__)\n\treturn \"/lib/arm-linux-gnueabi\";\n#elif defined(__arm__) && !defined(__SOFTFP__)\n\treturn \"/lib/arm-linux-gnueabihf\";\n#elif defined(__aarch64__)\n\treturn \"/lib/aarch64-linux-gnu\";\n#elif defined(__mips__) && defined(__MIPSEL__) && _MIPS_SZLONG == 64\n\treturn \"/lib/mips64el-linux-gnuabi64\";\n#elif defined(__mips__) && defined(__MIPSEL__) && _MIPS_SZLONG == 32\n\treturn \"/lib/mipsel-linux-gnu\";\n#elif defined(__powerpc64__) && __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__\n\treturn \"/lib/powerpc64le-linux-gnu\";\n#elif defined(__sparc__) && defined(__arch64__)\n\treturn \"/lib/sparc64-linux-gnu\";\n#elif defined(__riscv) && __riscv_xlen == 64\n\treturn \"/lib/riscv64-linux-gnu\";\n#else\n\treturn NULL;\n#endif\n}\n\n \nstatic int resolve_full_path(const char *file, char *result, size_t result_sz)\n{\n\tconst char *search_paths[3] = {};\n\tint i, perm;\n\n\tif (str_has_sfx(file, \".so\") || strstr(file, \".so.\")) {\n\t\tsearch_paths[0] = getenv(\"LD_LIBRARY_PATH\");\n\t\tsearch_paths[1] = \"/usr/lib64:/usr/lib\";\n\t\tsearch_paths[2] = arch_specific_lib_paths();\n\t\tperm = R_OK;\n\t} else {\n\t\tsearch_paths[0] = getenv(\"PATH\");\n\t\tsearch_paths[1] = \"/usr/bin:/usr/sbin\";\n\t\tperm = R_OK | X_OK;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(search_paths); i++) {\n\t\tconst char *s;\n\n\t\tif (!search_paths[i])\n\t\t\tcontinue;\n\t\tfor (s = search_paths[i]; s != NULL; s = strchr(s, ':')) {\n\t\t\tchar *next_path;\n\t\t\tint seg_len;\n\n\t\t\tif (s[0] == ':')\n\t\t\t\ts++;\n\t\t\tnext_path = strchr(s, ':');\n\t\t\tseg_len = next_path ? next_path - s : strlen(s);\n\t\t\tif (!seg_len)\n\t\t\t\tcontinue;\n\t\t\tsnprintf(result, result_sz, \"%.*s/%s\", seg_len, s, file);\n\t\t\t \n\t\t\tif (faccessat(AT_FDCWD, result, perm, AT_EACCESS) < 0)\n\t\t\t\tcontinue;\n\t\t\tpr_debug(\"resolved '%s' to '%s'\\n\", file, result);\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -ENOENT;\n}\n\nstruct bpf_link *\nbpf_program__attach_uprobe_multi(const struct bpf_program *prog,\n\t\t\t\t pid_t pid,\n\t\t\t\t const char *path,\n\t\t\t\t const char *func_pattern,\n\t\t\t\t const struct bpf_uprobe_multi_opts *opts)\n{\n\tconst unsigned long *ref_ctr_offsets = NULL, *offsets = NULL;\n\tLIBBPF_OPTS(bpf_link_create_opts, lopts);\n\tunsigned long *resolved_offsets = NULL;\n\tint err = 0, link_fd, prog_fd;\n\tstruct bpf_link *link = NULL;\n\tchar errmsg[STRERR_BUFSIZE];\n\tchar full_path[PATH_MAX];\n\tconst __u64 *cookies;\n\tconst char **syms;\n\tsize_t cnt;\n\n\tif (!OPTS_VALID(opts, bpf_uprobe_multi_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tsyms = OPTS_GET(opts, syms, NULL);\n\toffsets = OPTS_GET(opts, offsets, NULL);\n\tref_ctr_offsets = OPTS_GET(opts, ref_ctr_offsets, NULL);\n\tcookies = OPTS_GET(opts, cookies, NULL);\n\tcnt = OPTS_GET(opts, cnt, 0);\n\n\t \n\n\tif (!path)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\tif (!func_pattern && cnt == 0)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tif (func_pattern) {\n\t\tif (syms || offsets || ref_ctr_offsets || cookies || cnt)\n\t\t\treturn libbpf_err_ptr(-EINVAL);\n\t} else {\n\t\tif (!!syms == !!offsets)\n\t\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tif (func_pattern) {\n\t\tif (!strchr(path, '/')) {\n\t\t\terr = resolve_full_path(path, full_path, sizeof(full_path));\n\t\t\tif (err) {\n\t\t\t\tpr_warn(\"prog '%s': failed to resolve full path for '%s': %d\\n\",\n\t\t\t\t\tprog->name, path, err);\n\t\t\t\treturn libbpf_err_ptr(err);\n\t\t\t}\n\t\t\tpath = full_path;\n\t\t}\n\n\t\terr = elf_resolve_pattern_offsets(path, func_pattern,\n\t\t\t\t\t\t  &resolved_offsets, &cnt);\n\t\tif (err < 0)\n\t\t\treturn libbpf_err_ptr(err);\n\t\toffsets = resolved_offsets;\n\t} else if (syms) {\n\t\terr = elf_resolve_syms_offsets(path, cnt, syms, &resolved_offsets);\n\t\tif (err < 0)\n\t\t\treturn libbpf_err_ptr(err);\n\t\toffsets = resolved_offsets;\n\t}\n\n\tlopts.uprobe_multi.path = path;\n\tlopts.uprobe_multi.offsets = offsets;\n\tlopts.uprobe_multi.ref_ctr_offsets = ref_ctr_offsets;\n\tlopts.uprobe_multi.cookies = cookies;\n\tlopts.uprobe_multi.cnt = cnt;\n\tlopts.uprobe_multi.flags = OPTS_GET(opts, retprobe, false) ? BPF_F_UPROBE_MULTI_RETURN : 0;\n\n\tif (pid == 0)\n\t\tpid = getpid();\n\tif (pid > 0)\n\t\tlopts.uprobe_multi.pid = pid;\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link) {\n\t\terr = -ENOMEM;\n\t\tgoto error;\n\t}\n\tlink->detach = &bpf_link__detach_fd;\n\n\tprog_fd = bpf_program__fd(prog);\n\tlink_fd = bpf_link_create(prog_fd, 0, BPF_TRACE_UPROBE_MULTI, &lopts);\n\tif (link_fd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"prog '%s': failed to attach multi-uprobe: %s\\n\",\n\t\t\tprog->name, libbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto error;\n\t}\n\tlink->fd = link_fd;\n\tfree(resolved_offsets);\n\treturn link;\n\nerror:\n\tfree(resolved_offsets);\n\tfree(link);\n\treturn libbpf_err_ptr(err);\n}\n\nLIBBPF_API struct bpf_link *\nbpf_program__attach_uprobe_opts(const struct bpf_program *prog, pid_t pid,\n\t\t\t\tconst char *binary_path, size_t func_offset,\n\t\t\t\tconst struct bpf_uprobe_opts *opts)\n{\n\tconst char *archive_path = NULL, *archive_sep = NULL;\n\tchar errmsg[STRERR_BUFSIZE], *legacy_probe = NULL;\n\tDECLARE_LIBBPF_OPTS(bpf_perf_event_opts, pe_opts);\n\tenum probe_attach_mode attach_mode;\n\tchar full_path[PATH_MAX];\n\tstruct bpf_link *link;\n\tsize_t ref_ctr_off;\n\tint pfd, err;\n\tbool retprobe, legacy;\n\tconst char *func_name;\n\n\tif (!OPTS_VALID(opts, bpf_uprobe_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tattach_mode = OPTS_GET(opts, attach_mode, PROBE_ATTACH_MODE_DEFAULT);\n\tretprobe = OPTS_GET(opts, retprobe, false);\n\tref_ctr_off = OPTS_GET(opts, ref_ctr_offset, 0);\n\tpe_opts.bpf_cookie = OPTS_GET(opts, bpf_cookie, 0);\n\n\tif (!binary_path)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\t \n\tarchive_sep = strstr(binary_path, \"!/\");\n\tif (archive_sep) {\n\t\tfull_path[0] = '\\0';\n\t\tlibbpf_strlcpy(full_path, binary_path,\n\t\t\t       min(sizeof(full_path), (size_t)(archive_sep - binary_path + 1)));\n\t\tarchive_path = full_path;\n\t\tbinary_path = archive_sep + 2;\n\t} else if (!strchr(binary_path, '/')) {\n\t\terr = resolve_full_path(binary_path, full_path, sizeof(full_path));\n\t\tif (err) {\n\t\t\tpr_warn(\"prog '%s': failed to resolve full path for '%s': %d\\n\",\n\t\t\t\tprog->name, binary_path, err);\n\t\t\treturn libbpf_err_ptr(err);\n\t\t}\n\t\tbinary_path = full_path;\n\t}\n\tfunc_name = OPTS_GET(opts, func_name, NULL);\n\tif (func_name) {\n\t\tlong sym_off;\n\n\t\tif (archive_path) {\n\t\t\tsym_off = elf_find_func_offset_from_archive(archive_path, binary_path,\n\t\t\t\t\t\t\t\t    func_name);\n\t\t\tbinary_path = archive_path;\n\t\t} else {\n\t\t\tsym_off = elf_find_func_offset_from_file(binary_path, func_name);\n\t\t}\n\t\tif (sym_off < 0)\n\t\t\treturn libbpf_err_ptr(sym_off);\n\t\tfunc_offset += sym_off;\n\t}\n\n\tlegacy = determine_uprobe_perf_type() < 0;\n\tswitch (attach_mode) {\n\tcase PROBE_ATTACH_MODE_LEGACY:\n\t\tlegacy = true;\n\t\tpe_opts.force_ioctl_attach = true;\n\t\tbreak;\n\tcase PROBE_ATTACH_MODE_PERF:\n\t\tif (legacy)\n\t\t\treturn libbpf_err_ptr(-ENOTSUP);\n\t\tpe_opts.force_ioctl_attach = true;\n\t\tbreak;\n\tcase PROBE_ATTACH_MODE_LINK:\n\t\tif (legacy || !kernel_supports(prog->obj, FEAT_PERF_LINK))\n\t\t\treturn libbpf_err_ptr(-ENOTSUP);\n\t\tbreak;\n\tcase PROBE_ATTACH_MODE_DEFAULT:\n\t\tbreak;\n\tdefault:\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tif (!legacy) {\n\t\tpfd = perf_event_open_probe(true  , retprobe, binary_path,\n\t\t\t\t\t    func_offset, pid, ref_ctr_off);\n\t} else {\n\t\tchar probe_name[PATH_MAX + 64];\n\n\t\tif (ref_ctr_off)\n\t\t\treturn libbpf_err_ptr(-EINVAL);\n\n\t\tgen_uprobe_legacy_event_name(probe_name, sizeof(probe_name),\n\t\t\t\t\t     binary_path, func_offset);\n\n\t\tlegacy_probe = strdup(probe_name);\n\t\tif (!legacy_probe)\n\t\t\treturn libbpf_err_ptr(-ENOMEM);\n\n\t\tpfd = perf_event_uprobe_open_legacy(legacy_probe, retprobe,\n\t\t\t\t\t\t    binary_path, func_offset, pid);\n\t}\n\tif (pfd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"prog '%s': failed to create %s '%s:0x%zx' perf event: %s\\n\",\n\t\t\tprog->name, retprobe ? \"uretprobe\" : \"uprobe\",\n\t\t\tbinary_path, func_offset,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto err_out;\n\t}\n\n\tlink = bpf_program__attach_perf_event_opts(prog, pfd, &pe_opts);\n\terr = libbpf_get_error(link);\n\tif (err) {\n\t\tclose(pfd);\n\t\tpr_warn(\"prog '%s': failed to attach to %s '%s:0x%zx': %s\\n\",\n\t\t\tprog->name, retprobe ? \"uretprobe\" : \"uprobe\",\n\t\t\tbinary_path, func_offset,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\tgoto err_clean_legacy;\n\t}\n\tif (legacy) {\n\t\tstruct bpf_link_perf *perf_link = container_of(link, struct bpf_link_perf, link);\n\n\t\tperf_link->legacy_probe_name = legacy_probe;\n\t\tperf_link->legacy_is_kprobe = false;\n\t\tperf_link->legacy_is_retprobe = retprobe;\n\t}\n\treturn link;\n\nerr_clean_legacy:\n\tif (legacy)\n\t\tremove_uprobe_event_legacy(legacy_probe, retprobe);\nerr_out:\n\tfree(legacy_probe);\n\treturn libbpf_err_ptr(err);\n}\n\n \nstatic int attach_uprobe(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_uprobe_opts, opts);\n\tchar *probe_type = NULL, *binary_path = NULL, *func_name = NULL;\n\tint n, ret = -EINVAL;\n\tlong offset = 0;\n\n\t*link = NULL;\n\n\tn = sscanf(prog->sec_name, \"%m[^/]/%m[^:]:%m[a-zA-Z0-9_.]+%li\",\n\t\t   &probe_type, &binary_path, &func_name, &offset);\n\tswitch (n) {\n\tcase 1:\n\t\t \n\t\tret = 0;\n\t\tbreak;\n\tcase 2:\n\t\tpr_warn(\"prog '%s': section '%s' missing ':function[+offset]' specification\\n\",\n\t\t\tprog->name, prog->sec_name);\n\t\tbreak;\n\tcase 3:\n\tcase 4:\n\t\topts.retprobe = strcmp(probe_type, \"uretprobe\") == 0 ||\n\t\t\t\tstrcmp(probe_type, \"uretprobe.s\") == 0;\n\t\tif (opts.retprobe && offset != 0) {\n\t\t\tpr_warn(\"prog '%s': uretprobes do not support offset specification\\n\",\n\t\t\t\tprog->name);\n\t\t\tbreak;\n\t\t}\n\t\topts.func_name = func_name;\n\t\t*link = bpf_program__attach_uprobe_opts(prog, -1, binary_path, offset, &opts);\n\t\tret = libbpf_get_error(*link);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"prog '%s': invalid format of section definition '%s'\\n\", prog->name,\n\t\t\tprog->sec_name);\n\t\tbreak;\n\t}\n\tfree(probe_type);\n\tfree(binary_path);\n\tfree(func_name);\n\n\treturn ret;\n}\n\nstruct bpf_link *bpf_program__attach_uprobe(const struct bpf_program *prog,\n\t\t\t\t\t    bool retprobe, pid_t pid,\n\t\t\t\t\t    const char *binary_path,\n\t\t\t\t\t    size_t func_offset)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_uprobe_opts, opts, .retprobe = retprobe);\n\n\treturn bpf_program__attach_uprobe_opts(prog, pid, binary_path, func_offset, &opts);\n}\n\nstruct bpf_link *bpf_program__attach_usdt(const struct bpf_program *prog,\n\t\t\t\t\t  pid_t pid, const char *binary_path,\n\t\t\t\t\t  const char *usdt_provider, const char *usdt_name,\n\t\t\t\t\t  const struct bpf_usdt_opts *opts)\n{\n\tchar resolved_path[512];\n\tstruct bpf_object *obj = prog->obj;\n\tstruct bpf_link *link;\n\t__u64 usdt_cookie;\n\tint err;\n\n\tif (!OPTS_VALID(opts, bpf_uprobe_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tif (bpf_program__fd(prog) < 0) {\n\t\tpr_warn(\"prog '%s': can't attach BPF program w/o FD (did you load it?)\\n\",\n\t\t\tprog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tif (!binary_path)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tif (!strchr(binary_path, '/')) {\n\t\terr = resolve_full_path(binary_path, resolved_path, sizeof(resolved_path));\n\t\tif (err) {\n\t\t\tpr_warn(\"prog '%s': failed to resolve full path for '%s': %d\\n\",\n\t\t\t\tprog->name, binary_path, err);\n\t\t\treturn libbpf_err_ptr(err);\n\t\t}\n\t\tbinary_path = resolved_path;\n\t}\n\n\t \n\tif (IS_ERR(obj->usdt_man))\n\t\treturn libbpf_ptr(obj->usdt_man);\n\tif (!obj->usdt_man) {\n\t\tobj->usdt_man = usdt_manager_new(obj);\n\t\tif (IS_ERR(obj->usdt_man))\n\t\t\treturn libbpf_ptr(obj->usdt_man);\n\t}\n\n\tusdt_cookie = OPTS_GET(opts, usdt_cookie, 0);\n\tlink = usdt_manager_attach_usdt(obj->usdt_man, prog, pid, binary_path,\n\t\t\t\t\tusdt_provider, usdt_name, usdt_cookie);\n\terr = libbpf_get_error(link);\n\tif (err)\n\t\treturn libbpf_err_ptr(err);\n\treturn link;\n}\n\nstatic int attach_usdt(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tchar *path = NULL, *provider = NULL, *name = NULL;\n\tconst char *sec_name;\n\tint n, err;\n\n\tsec_name = bpf_program__section_name(prog);\n\tif (strcmp(sec_name, \"usdt\") == 0) {\n\t\t \n\t\t*link = NULL;\n\t\treturn 0;\n\t}\n\n\tn = sscanf(sec_name, \"usdt/%m[^:]:%m[^:]:%m[^:]\", &path, &provider, &name);\n\tif (n != 3) {\n\t\tpr_warn(\"invalid section '%s', expected SEC(\\\"usdt/<path>:<provider>:<name>\\\")\\n\",\n\t\t\tsec_name);\n\t\terr = -EINVAL;\n\t} else {\n\t\t*link = bpf_program__attach_usdt(prog, -1  , path,\n\t\t\t\t\t\t provider, name, NULL);\n\t\terr = libbpf_get_error(*link);\n\t}\n\tfree(path);\n\tfree(provider);\n\tfree(name);\n\treturn err;\n}\n\nstatic int determine_tracepoint_id(const char *tp_category,\n\t\t\t\t   const char *tp_name)\n{\n\tchar file[PATH_MAX];\n\tint ret;\n\n\tret = snprintf(file, sizeof(file), \"%s/events/%s/%s/id\",\n\t\t       tracefs_path(), tp_category, tp_name);\n\tif (ret < 0)\n\t\treturn -errno;\n\tif (ret >= sizeof(file)) {\n\t\tpr_debug(\"tracepoint %s/%s path is too long\\n\",\n\t\t\t tp_category, tp_name);\n\t\treturn -E2BIG;\n\t}\n\treturn parse_uint_from_file(file, \"%d\\n\");\n}\n\nstatic int perf_event_open_tracepoint(const char *tp_category,\n\t\t\t\t      const char *tp_name)\n{\n\tconst size_t attr_sz = sizeof(struct perf_event_attr);\n\tstruct perf_event_attr attr;\n\tchar errmsg[STRERR_BUFSIZE];\n\tint tp_id, pfd, err;\n\n\ttp_id = determine_tracepoint_id(tp_category, tp_name);\n\tif (tp_id < 0) {\n\t\tpr_warn(\"failed to determine tracepoint '%s/%s' perf event ID: %s\\n\",\n\t\t\ttp_category, tp_name,\n\t\t\tlibbpf_strerror_r(tp_id, errmsg, sizeof(errmsg)));\n\t\treturn tp_id;\n\t}\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.type = PERF_TYPE_TRACEPOINT;\n\tattr.size = attr_sz;\n\tattr.config = tp_id;\n\n\tpfd = syscall(__NR_perf_event_open, &attr, -1  , 0  ,\n\t\t      -1  , PERF_FLAG_FD_CLOEXEC);\n\tif (pfd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"tracepoint '%s/%s' perf_event_open() failed: %s\\n\",\n\t\t\ttp_category, tp_name,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\treturn err;\n\t}\n\treturn pfd;\n}\n\nstruct bpf_link *bpf_program__attach_tracepoint_opts(const struct bpf_program *prog,\n\t\t\t\t\t\t     const char *tp_category,\n\t\t\t\t\t\t     const char *tp_name,\n\t\t\t\t\t\t     const struct bpf_tracepoint_opts *opts)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_perf_event_opts, pe_opts);\n\tchar errmsg[STRERR_BUFSIZE];\n\tstruct bpf_link *link;\n\tint pfd, err;\n\n\tif (!OPTS_VALID(opts, bpf_tracepoint_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tpe_opts.bpf_cookie = OPTS_GET(opts, bpf_cookie, 0);\n\n\tpfd = perf_event_open_tracepoint(tp_category, tp_name);\n\tif (pfd < 0) {\n\t\tpr_warn(\"prog '%s': failed to create tracepoint '%s/%s' perf event: %s\\n\",\n\t\t\tprog->name, tp_category, tp_name,\n\t\t\tlibbpf_strerror_r(pfd, errmsg, sizeof(errmsg)));\n\t\treturn libbpf_err_ptr(pfd);\n\t}\n\tlink = bpf_program__attach_perf_event_opts(prog, pfd, &pe_opts);\n\terr = libbpf_get_error(link);\n\tif (err) {\n\t\tclose(pfd);\n\t\tpr_warn(\"prog '%s': failed to attach to tracepoint '%s/%s': %s\\n\",\n\t\t\tprog->name, tp_category, tp_name,\n\t\t\tlibbpf_strerror_r(err, errmsg, sizeof(errmsg)));\n\t\treturn libbpf_err_ptr(err);\n\t}\n\treturn link;\n}\n\nstruct bpf_link *bpf_program__attach_tracepoint(const struct bpf_program *prog,\n\t\t\t\t\t\tconst char *tp_category,\n\t\t\t\t\t\tconst char *tp_name)\n{\n\treturn bpf_program__attach_tracepoint_opts(prog, tp_category, tp_name, NULL);\n}\n\nstatic int attach_tp(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tchar *sec_name, *tp_cat, *tp_name;\n\n\t*link = NULL;\n\n\t \n\tif (strcmp(prog->sec_name, \"tp\") == 0 || strcmp(prog->sec_name, \"tracepoint\") == 0)\n\t\treturn 0;\n\n\tsec_name = strdup(prog->sec_name);\n\tif (!sec_name)\n\t\treturn -ENOMEM;\n\n\t \n\tif (str_has_pfx(prog->sec_name, \"tp/\"))\n\t\ttp_cat = sec_name + sizeof(\"tp/\") - 1;\n\telse\n\t\ttp_cat = sec_name + sizeof(\"tracepoint/\") - 1;\n\ttp_name = strchr(tp_cat, '/');\n\tif (!tp_name) {\n\t\tfree(sec_name);\n\t\treturn -EINVAL;\n\t}\n\t*tp_name = '\\0';\n\ttp_name++;\n\n\t*link = bpf_program__attach_tracepoint(prog, tp_cat, tp_name);\n\tfree(sec_name);\n\treturn libbpf_get_error(*link);\n}\n\nstruct bpf_link *bpf_program__attach_raw_tracepoint(const struct bpf_program *prog,\n\t\t\t\t\t\t    const char *tp_name)\n{\n\tchar errmsg[STRERR_BUFSIZE];\n\tstruct bpf_link *link;\n\tint prog_fd, pfd;\n\n\tprog_fd = bpf_program__fd(prog);\n\tif (prog_fd < 0) {\n\t\tpr_warn(\"prog '%s': can't attach before loaded\\n\", prog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link)\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\tlink->detach = &bpf_link__detach_fd;\n\n\tpfd = bpf_raw_tracepoint_open(tp_name, prog_fd);\n\tif (pfd < 0) {\n\t\tpfd = -errno;\n\t\tfree(link);\n\t\tpr_warn(\"prog '%s': failed to attach to raw tracepoint '%s': %s\\n\",\n\t\t\tprog->name, tp_name, libbpf_strerror_r(pfd, errmsg, sizeof(errmsg)));\n\t\treturn libbpf_err_ptr(pfd);\n\t}\n\tlink->fd = pfd;\n\treturn link;\n}\n\nstatic int attach_raw_tp(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\tstatic const char *const prefixes[] = {\n\t\t\"raw_tp\",\n\t\t\"raw_tracepoint\",\n\t\t\"raw_tp.w\",\n\t\t\"raw_tracepoint.w\",\n\t};\n\tsize_t i;\n\tconst char *tp_name = NULL;\n\n\t*link = NULL;\n\n\tfor (i = 0; i < ARRAY_SIZE(prefixes); i++) {\n\t\tsize_t pfx_len;\n\n\t\tif (!str_has_pfx(prog->sec_name, prefixes[i]))\n\t\t\tcontinue;\n\n\t\tpfx_len = strlen(prefixes[i]);\n\t\t \n\t\tif (prog->sec_name[pfx_len] == '\\0')\n\t\t\treturn 0;\n\n\t\tif (prog->sec_name[pfx_len] != '/')\n\t\t\tcontinue;\n\n\t\ttp_name = prog->sec_name + pfx_len + 1;\n\t\tbreak;\n\t}\n\n\tif (!tp_name) {\n\t\tpr_warn(\"prog '%s': invalid section name '%s'\\n\",\n\t\t\tprog->name, prog->sec_name);\n\t\treturn -EINVAL;\n\t}\n\n\t*link = bpf_program__attach_raw_tracepoint(prog, tp_name);\n\treturn libbpf_get_error(*link);\n}\n\n \nstatic struct bpf_link *bpf_program__attach_btf_id(const struct bpf_program *prog,\n\t\t\t\t\t\t   const struct bpf_trace_opts *opts)\n{\n\tLIBBPF_OPTS(bpf_link_create_opts, link_opts);\n\tchar errmsg[STRERR_BUFSIZE];\n\tstruct bpf_link *link;\n\tint prog_fd, pfd;\n\n\tif (!OPTS_VALID(opts, bpf_trace_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tprog_fd = bpf_program__fd(prog);\n\tif (prog_fd < 0) {\n\t\tpr_warn(\"prog '%s': can't attach before loaded\\n\", prog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link)\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\tlink->detach = &bpf_link__detach_fd;\n\n\t \n\tlink_opts.tracing.cookie = OPTS_GET(opts, cookie, 0);\n\tpfd = bpf_link_create(prog_fd, 0, bpf_program__expected_attach_type(prog), &link_opts);\n\tif (pfd < 0) {\n\t\tpfd = -errno;\n\t\tfree(link);\n\t\tpr_warn(\"prog '%s': failed to attach: %s\\n\",\n\t\t\tprog->name, libbpf_strerror_r(pfd, errmsg, sizeof(errmsg)));\n\t\treturn libbpf_err_ptr(pfd);\n\t}\n\tlink->fd = pfd;\n\treturn link;\n}\n\nstruct bpf_link *bpf_program__attach_trace(const struct bpf_program *prog)\n{\n\treturn bpf_program__attach_btf_id(prog, NULL);\n}\n\nstruct bpf_link *bpf_program__attach_trace_opts(const struct bpf_program *prog,\n\t\t\t\t\t\tconst struct bpf_trace_opts *opts)\n{\n\treturn bpf_program__attach_btf_id(prog, opts);\n}\n\nstruct bpf_link *bpf_program__attach_lsm(const struct bpf_program *prog)\n{\n\treturn bpf_program__attach_btf_id(prog, NULL);\n}\n\nstatic int attach_trace(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\t*link = bpf_program__attach_trace(prog);\n\treturn libbpf_get_error(*link);\n}\n\nstatic int attach_lsm(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\t*link = bpf_program__attach_lsm(prog);\n\treturn libbpf_get_error(*link);\n}\n\nstatic struct bpf_link *\nbpf_program_attach_fd(const struct bpf_program *prog,\n\t\t      int target_fd, const char *target_name,\n\t\t      const struct bpf_link_create_opts *opts)\n{\n\tenum bpf_attach_type attach_type;\n\tchar errmsg[STRERR_BUFSIZE];\n\tstruct bpf_link *link;\n\tint prog_fd, link_fd;\n\n\tprog_fd = bpf_program__fd(prog);\n\tif (prog_fd < 0) {\n\t\tpr_warn(\"prog '%s': can't attach before loaded\\n\", prog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link)\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\tlink->detach = &bpf_link__detach_fd;\n\n\tattach_type = bpf_program__expected_attach_type(prog);\n\tlink_fd = bpf_link_create(prog_fd, target_fd, attach_type, opts);\n\tif (link_fd < 0) {\n\t\tlink_fd = -errno;\n\t\tfree(link);\n\t\tpr_warn(\"prog '%s': failed to attach to %s: %s\\n\",\n\t\t\tprog->name, target_name,\n\t\t\tlibbpf_strerror_r(link_fd, errmsg, sizeof(errmsg)));\n\t\treturn libbpf_err_ptr(link_fd);\n\t}\n\tlink->fd = link_fd;\n\treturn link;\n}\n\nstruct bpf_link *\nbpf_program__attach_cgroup(const struct bpf_program *prog, int cgroup_fd)\n{\n\treturn bpf_program_attach_fd(prog, cgroup_fd, \"cgroup\", NULL);\n}\n\nstruct bpf_link *\nbpf_program__attach_netns(const struct bpf_program *prog, int netns_fd)\n{\n\treturn bpf_program_attach_fd(prog, netns_fd, \"netns\", NULL);\n}\n\nstruct bpf_link *bpf_program__attach_xdp(const struct bpf_program *prog, int ifindex)\n{\n\t \n\treturn bpf_program_attach_fd(prog, ifindex, \"xdp\", NULL);\n}\n\nstruct bpf_link *\nbpf_program__attach_tcx(const struct bpf_program *prog, int ifindex,\n\t\t\tconst struct bpf_tcx_opts *opts)\n{\n\tLIBBPF_OPTS(bpf_link_create_opts, link_create_opts);\n\t__u32 relative_id;\n\tint relative_fd;\n\n\tif (!OPTS_VALID(opts, bpf_tcx_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\trelative_id = OPTS_GET(opts, relative_id, 0);\n\trelative_fd = OPTS_GET(opts, relative_fd, 0);\n\n\t \n\tif (!ifindex) {\n\t\tpr_warn(\"prog '%s': target netdevice ifindex cannot be zero\\n\",\n\t\t\tprog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\tif (relative_fd && relative_id) {\n\t\tpr_warn(\"prog '%s': relative_fd and relative_id cannot be set at the same time\\n\",\n\t\t\tprog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tlink_create_opts.tcx.expected_revision = OPTS_GET(opts, expected_revision, 0);\n\tlink_create_opts.tcx.relative_fd = relative_fd;\n\tlink_create_opts.tcx.relative_id = relative_id;\n\tlink_create_opts.flags = OPTS_GET(opts, flags, 0);\n\n\t \n\treturn bpf_program_attach_fd(prog, ifindex, \"tcx\", &link_create_opts);\n}\n\nstruct bpf_link *bpf_program__attach_freplace(const struct bpf_program *prog,\n\t\t\t\t\t      int target_fd,\n\t\t\t\t\t      const char *attach_func_name)\n{\n\tint btf_id;\n\n\tif (!!target_fd != !!attach_func_name) {\n\t\tpr_warn(\"prog '%s': supply none or both of target_fd and attach_func_name\\n\",\n\t\t\tprog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tif (prog->type != BPF_PROG_TYPE_EXT) {\n\t\tpr_warn(\"prog '%s': only BPF_PROG_TYPE_EXT can attach as freplace\",\n\t\t\tprog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tif (target_fd) {\n\t\tLIBBPF_OPTS(bpf_link_create_opts, target_opts);\n\n\t\tbtf_id = libbpf_find_prog_btf_id(attach_func_name, target_fd);\n\t\tif (btf_id < 0)\n\t\t\treturn libbpf_err_ptr(btf_id);\n\n\t\ttarget_opts.target_btf_id = btf_id;\n\n\t\treturn bpf_program_attach_fd(prog, target_fd, \"freplace\",\n\t\t\t\t\t     &target_opts);\n\t} else {\n\t\t \n\t\treturn bpf_program__attach_trace(prog);\n\t}\n}\n\nstruct bpf_link *\nbpf_program__attach_iter(const struct bpf_program *prog,\n\t\t\t const struct bpf_iter_attach_opts *opts)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_link_create_opts, link_create_opts);\n\tchar errmsg[STRERR_BUFSIZE];\n\tstruct bpf_link *link;\n\tint prog_fd, link_fd;\n\t__u32 target_fd = 0;\n\n\tif (!OPTS_VALID(opts, bpf_iter_attach_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tlink_create_opts.iter_info = OPTS_GET(opts, link_info, (void *)0);\n\tlink_create_opts.iter_info_len = OPTS_GET(opts, link_info_len, 0);\n\n\tprog_fd = bpf_program__fd(prog);\n\tif (prog_fd < 0) {\n\t\tpr_warn(\"prog '%s': can't attach before loaded\\n\", prog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link)\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\tlink->detach = &bpf_link__detach_fd;\n\n\tlink_fd = bpf_link_create(prog_fd, target_fd, BPF_TRACE_ITER,\n\t\t\t\t  &link_create_opts);\n\tif (link_fd < 0) {\n\t\tlink_fd = -errno;\n\t\tfree(link);\n\t\tpr_warn(\"prog '%s': failed to attach to iterator: %s\\n\",\n\t\t\tprog->name, libbpf_strerror_r(link_fd, errmsg, sizeof(errmsg)));\n\t\treturn libbpf_err_ptr(link_fd);\n\t}\n\tlink->fd = link_fd;\n\treturn link;\n}\n\nstatic int attach_iter(const struct bpf_program *prog, long cookie, struct bpf_link **link)\n{\n\t*link = bpf_program__attach_iter(prog, NULL);\n\treturn libbpf_get_error(*link);\n}\n\nstruct bpf_link *bpf_program__attach_netfilter(const struct bpf_program *prog,\n\t\t\t\t\t       const struct bpf_netfilter_opts *opts)\n{\n\tLIBBPF_OPTS(bpf_link_create_opts, lopts);\n\tstruct bpf_link *link;\n\tint prog_fd, link_fd;\n\n\tif (!OPTS_VALID(opts, bpf_netfilter_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tprog_fd = bpf_program__fd(prog);\n\tif (prog_fd < 0) {\n\t\tpr_warn(\"prog '%s': can't attach before loaded\\n\", prog->name);\n\t\treturn libbpf_err_ptr(-EINVAL);\n\t}\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link)\n\t\treturn libbpf_err_ptr(-ENOMEM);\n\n\tlink->detach = &bpf_link__detach_fd;\n\n\tlopts.netfilter.pf = OPTS_GET(opts, pf, 0);\n\tlopts.netfilter.hooknum = OPTS_GET(opts, hooknum, 0);\n\tlopts.netfilter.priority = OPTS_GET(opts, priority, 0);\n\tlopts.netfilter.flags = OPTS_GET(opts, flags, 0);\n\n\tlink_fd = bpf_link_create(prog_fd, 0, BPF_NETFILTER, &lopts);\n\tif (link_fd < 0) {\n\t\tchar errmsg[STRERR_BUFSIZE];\n\n\t\tlink_fd = -errno;\n\t\tfree(link);\n\t\tpr_warn(\"prog '%s': failed to attach to netfilter: %s\\n\",\n\t\t\tprog->name, libbpf_strerror_r(link_fd, errmsg, sizeof(errmsg)));\n\t\treturn libbpf_err_ptr(link_fd);\n\t}\n\tlink->fd = link_fd;\n\n\treturn link;\n}\n\nstruct bpf_link *bpf_program__attach(const struct bpf_program *prog)\n{\n\tstruct bpf_link *link = NULL;\n\tint err;\n\n\tif (!prog->sec_def || !prog->sec_def->prog_attach_fn)\n\t\treturn libbpf_err_ptr(-EOPNOTSUPP);\n\n\terr = prog->sec_def->prog_attach_fn(prog, prog->sec_def->cookie, &link);\n\tif (err)\n\t\treturn libbpf_err_ptr(err);\n\n\t \n\tif (!link)\n\t\treturn libbpf_err_ptr(-EOPNOTSUPP);\n\n\treturn link;\n}\n\nstruct bpf_link_struct_ops {\n\tstruct bpf_link link;\n\tint map_fd;\n};\n\nstatic int bpf_link__detach_struct_ops(struct bpf_link *link)\n{\n\tstruct bpf_link_struct_ops *st_link;\n\t__u32 zero = 0;\n\n\tst_link = container_of(link, struct bpf_link_struct_ops, link);\n\n\tif (st_link->map_fd < 0)\n\t\t \n\t\treturn bpf_map_delete_elem(link->fd, &zero);\n\n\treturn close(link->fd);\n}\n\nstruct bpf_link *bpf_map__attach_struct_ops(const struct bpf_map *map)\n{\n\tstruct bpf_link_struct_ops *link;\n\t__u32 zero = 0;\n\tint err, fd;\n\n\tif (!bpf_map__is_struct_ops(map) || map->fd == -1)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tlink = calloc(1, sizeof(*link));\n\tif (!link)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\t \n\terr = bpf_map_update_elem(map->fd, &zero, map->st_ops->kern_vdata, 0);\n\t \n\tif (err && (!(map->def.map_flags & BPF_F_LINK) || err != -EBUSY)) {\n\t\tfree(link);\n\t\treturn libbpf_err_ptr(err);\n\t}\n\n\tlink->link.detach = bpf_link__detach_struct_ops;\n\n\tif (!(map->def.map_flags & BPF_F_LINK)) {\n\t\t \n\t\tlink->link.fd = map->fd;\n\t\tlink->map_fd = -1;\n\t\treturn &link->link;\n\t}\n\n\tfd = bpf_link_create(map->fd, 0, BPF_STRUCT_OPS, NULL);\n\tif (fd < 0) {\n\t\tfree(link);\n\t\treturn libbpf_err_ptr(fd);\n\t}\n\n\tlink->link.fd = fd;\n\tlink->map_fd = map->fd;\n\n\treturn &link->link;\n}\n\n \nint bpf_link__update_map(struct bpf_link *link, const struct bpf_map *map)\n{\n\tstruct bpf_link_struct_ops *st_ops_link;\n\t__u32 zero = 0;\n\tint err;\n\n\tif (!bpf_map__is_struct_ops(map) || map->fd < 0)\n\t\treturn -EINVAL;\n\n\tst_ops_link = container_of(link, struct bpf_link_struct_ops, link);\n\t \n\tif (st_ops_link->map_fd < 0)\n\t\treturn -EINVAL;\n\n\terr = bpf_map_update_elem(map->fd, &zero, map->st_ops->kern_vdata, 0);\n\t \n\tif (err && err != -EBUSY)\n\t\treturn err;\n\n\terr = bpf_link_update(link->fd, map->fd, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tst_ops_link->map_fd = map->fd;\n\n\treturn 0;\n}\n\ntypedef enum bpf_perf_event_ret (*bpf_perf_event_print_t)(struct perf_event_header *hdr,\n\t\t\t\t\t\t\t  void *private_data);\n\nstatic enum bpf_perf_event_ret\nperf_event_read_simple(void *mmap_mem, size_t mmap_size, size_t page_size,\n\t\t       void **copy_mem, size_t *copy_size,\n\t\t       bpf_perf_event_print_t fn, void *private_data)\n{\n\tstruct perf_event_mmap_page *header = mmap_mem;\n\t__u64 data_head = ring_buffer_read_head(header);\n\t__u64 data_tail = header->data_tail;\n\tvoid *base = ((__u8 *)header) + page_size;\n\tint ret = LIBBPF_PERF_EVENT_CONT;\n\tstruct perf_event_header *ehdr;\n\tsize_t ehdr_size;\n\n\twhile (data_head != data_tail) {\n\t\tehdr = base + (data_tail & (mmap_size - 1));\n\t\tehdr_size = ehdr->size;\n\n\t\tif (((void *)ehdr) + ehdr_size > base + mmap_size) {\n\t\t\tvoid *copy_start = ehdr;\n\t\t\tsize_t len_first = base + mmap_size - copy_start;\n\t\t\tsize_t len_secnd = ehdr_size - len_first;\n\n\t\t\tif (*copy_size < ehdr_size) {\n\t\t\t\tfree(*copy_mem);\n\t\t\t\t*copy_mem = malloc(ehdr_size);\n\t\t\t\tif (!*copy_mem) {\n\t\t\t\t\t*copy_size = 0;\n\t\t\t\t\tret = LIBBPF_PERF_EVENT_ERROR;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t*copy_size = ehdr_size;\n\t\t\t}\n\n\t\t\tmemcpy(*copy_mem, copy_start, len_first);\n\t\t\tmemcpy(*copy_mem + len_first, base, len_secnd);\n\t\t\tehdr = *copy_mem;\n\t\t}\n\n\t\tret = fn(ehdr, private_data);\n\t\tdata_tail += ehdr_size;\n\t\tif (ret != LIBBPF_PERF_EVENT_CONT)\n\t\t\tbreak;\n\t}\n\n\tring_buffer_write_tail(header, data_tail);\n\treturn libbpf_err(ret);\n}\n\nstruct perf_buffer;\n\nstruct perf_buffer_params {\n\tstruct perf_event_attr *attr;\n\t \n\tperf_buffer_event_fn event_cb;\n\t \n\tperf_buffer_sample_fn sample_cb;\n\tperf_buffer_lost_fn lost_cb;\n\tvoid *ctx;\n\tint cpu_cnt;\n\tint *cpus;\n\tint *map_keys;\n};\n\nstruct perf_cpu_buf {\n\tstruct perf_buffer *pb;\n\tvoid *base;  \n\tvoid *buf;  \n\tsize_t buf_size;\n\tint fd;\n\tint cpu;\n\tint map_key;\n};\n\nstruct perf_buffer {\n\tperf_buffer_event_fn event_cb;\n\tperf_buffer_sample_fn sample_cb;\n\tperf_buffer_lost_fn lost_cb;\n\tvoid *ctx;  \n\n\tsize_t page_size;\n\tsize_t mmap_size;\n\tstruct perf_cpu_buf **cpu_bufs;\n\tstruct epoll_event *events;\n\tint cpu_cnt;  \n\tint epoll_fd;  \n\tint map_fd;  \n};\n\nstatic void perf_buffer__free_cpu_buf(struct perf_buffer *pb,\n\t\t\t\t      struct perf_cpu_buf *cpu_buf)\n{\n\tif (!cpu_buf)\n\t\treturn;\n\tif (cpu_buf->base &&\n\t    munmap(cpu_buf->base, pb->mmap_size + pb->page_size))\n\t\tpr_warn(\"failed to munmap cpu_buf #%d\\n\", cpu_buf->cpu);\n\tif (cpu_buf->fd >= 0) {\n\t\tioctl(cpu_buf->fd, PERF_EVENT_IOC_DISABLE, 0);\n\t\tclose(cpu_buf->fd);\n\t}\n\tfree(cpu_buf->buf);\n\tfree(cpu_buf);\n}\n\nvoid perf_buffer__free(struct perf_buffer *pb)\n{\n\tint i;\n\n\tif (IS_ERR_OR_NULL(pb))\n\t\treturn;\n\tif (pb->cpu_bufs) {\n\t\tfor (i = 0; i < pb->cpu_cnt; i++) {\n\t\t\tstruct perf_cpu_buf *cpu_buf = pb->cpu_bufs[i];\n\n\t\t\tif (!cpu_buf)\n\t\t\t\tcontinue;\n\n\t\t\tbpf_map_delete_elem(pb->map_fd, &cpu_buf->map_key);\n\t\t\tperf_buffer__free_cpu_buf(pb, cpu_buf);\n\t\t}\n\t\tfree(pb->cpu_bufs);\n\t}\n\tif (pb->epoll_fd >= 0)\n\t\tclose(pb->epoll_fd);\n\tfree(pb->events);\n\tfree(pb);\n}\n\nstatic struct perf_cpu_buf *\nperf_buffer__open_cpu_buf(struct perf_buffer *pb, struct perf_event_attr *attr,\n\t\t\t  int cpu, int map_key)\n{\n\tstruct perf_cpu_buf *cpu_buf;\n\tchar msg[STRERR_BUFSIZE];\n\tint err;\n\n\tcpu_buf = calloc(1, sizeof(*cpu_buf));\n\tif (!cpu_buf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tcpu_buf->pb = pb;\n\tcpu_buf->cpu = cpu;\n\tcpu_buf->map_key = map_key;\n\n\tcpu_buf->fd = syscall(__NR_perf_event_open, attr, -1  , cpu,\n\t\t\t      -1, PERF_FLAG_FD_CLOEXEC);\n\tif (cpu_buf->fd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to open perf buffer event on cpu #%d: %s\\n\",\n\t\t\tcpu, libbpf_strerror_r(err, msg, sizeof(msg)));\n\t\tgoto error;\n\t}\n\n\tcpu_buf->base = mmap(NULL, pb->mmap_size + pb->page_size,\n\t\t\t     PROT_READ | PROT_WRITE, MAP_SHARED,\n\t\t\t     cpu_buf->fd, 0);\n\tif (cpu_buf->base == MAP_FAILED) {\n\t\tcpu_buf->base = NULL;\n\t\terr = -errno;\n\t\tpr_warn(\"failed to mmap perf buffer on cpu #%d: %s\\n\",\n\t\t\tcpu, libbpf_strerror_r(err, msg, sizeof(msg)));\n\t\tgoto error;\n\t}\n\n\tif (ioctl(cpu_buf->fd, PERF_EVENT_IOC_ENABLE, 0) < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to enable perf buffer event on cpu #%d: %s\\n\",\n\t\t\tcpu, libbpf_strerror_r(err, msg, sizeof(msg)));\n\t\tgoto error;\n\t}\n\n\treturn cpu_buf;\n\nerror:\n\tperf_buffer__free_cpu_buf(pb, cpu_buf);\n\treturn (struct perf_cpu_buf *)ERR_PTR(err);\n}\n\nstatic struct perf_buffer *__perf_buffer__new(int map_fd, size_t page_cnt,\n\t\t\t\t\t      struct perf_buffer_params *p);\n\nstruct perf_buffer *perf_buffer__new(int map_fd, size_t page_cnt,\n\t\t\t\t     perf_buffer_sample_fn sample_cb,\n\t\t\t\t     perf_buffer_lost_fn lost_cb,\n\t\t\t\t     void *ctx,\n\t\t\t\t     const struct perf_buffer_opts *opts)\n{\n\tconst size_t attr_sz = sizeof(struct perf_event_attr);\n\tstruct perf_buffer_params p = {};\n\tstruct perf_event_attr attr;\n\t__u32 sample_period;\n\n\tif (!OPTS_VALID(opts, perf_buffer_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tsample_period = OPTS_GET(opts, sample_period, 1);\n\tif (!sample_period)\n\t\tsample_period = 1;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.size = attr_sz;\n\tattr.config = PERF_COUNT_SW_BPF_OUTPUT;\n\tattr.type = PERF_TYPE_SOFTWARE;\n\tattr.sample_type = PERF_SAMPLE_RAW;\n\tattr.sample_period = sample_period;\n\tattr.wakeup_events = sample_period;\n\n\tp.attr = &attr;\n\tp.sample_cb = sample_cb;\n\tp.lost_cb = lost_cb;\n\tp.ctx = ctx;\n\n\treturn libbpf_ptr(__perf_buffer__new(map_fd, page_cnt, &p));\n}\n\nstruct perf_buffer *perf_buffer__new_raw(int map_fd, size_t page_cnt,\n\t\t\t\t\t struct perf_event_attr *attr,\n\t\t\t\t\t perf_buffer_event_fn event_cb, void *ctx,\n\t\t\t\t\t const struct perf_buffer_raw_opts *opts)\n{\n\tstruct perf_buffer_params p = {};\n\n\tif (!attr)\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tif (!OPTS_VALID(opts, perf_buffer_raw_opts))\n\t\treturn libbpf_err_ptr(-EINVAL);\n\n\tp.attr = attr;\n\tp.event_cb = event_cb;\n\tp.ctx = ctx;\n\tp.cpu_cnt = OPTS_GET(opts, cpu_cnt, 0);\n\tp.cpus = OPTS_GET(opts, cpus, NULL);\n\tp.map_keys = OPTS_GET(opts, map_keys, NULL);\n\n\treturn libbpf_ptr(__perf_buffer__new(map_fd, page_cnt, &p));\n}\n\nstatic struct perf_buffer *__perf_buffer__new(int map_fd, size_t page_cnt,\n\t\t\t\t\t      struct perf_buffer_params *p)\n{\n\tconst char *online_cpus_file = \"/sys/devices/system/cpu/online\";\n\tstruct bpf_map_info map;\n\tchar msg[STRERR_BUFSIZE];\n\tstruct perf_buffer *pb;\n\tbool *online = NULL;\n\t__u32 map_info_len;\n\tint err, i, j, n;\n\n\tif (page_cnt == 0 || (page_cnt & (page_cnt - 1))) {\n\t\tpr_warn(\"page count should be power of two, but is %zu\\n\",\n\t\t\tpage_cnt);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\t \n\tmemset(&map, 0, sizeof(map));\n\tmap_info_len = sizeof(map);\n\terr = bpf_map_get_info_by_fd(map_fd, &map, &map_info_len);\n\tif (err) {\n\t\terr = -errno;\n\t\t \n\t\tif (err != -EINVAL) {\n\t\t\tpr_warn(\"failed to get map info for map FD %d: %s\\n\",\n\t\t\t\tmap_fd, libbpf_strerror_r(err, msg, sizeof(msg)));\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\t\tpr_debug(\"failed to get map info for FD %d; API not supported? Ignoring...\\n\",\n\t\t\t map_fd);\n\t} else {\n\t\tif (map.type != BPF_MAP_TYPE_PERF_EVENT_ARRAY) {\n\t\t\tpr_warn(\"map '%s' should be BPF_MAP_TYPE_PERF_EVENT_ARRAY\\n\",\n\t\t\t\tmap.name);\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\t}\n\n\tpb = calloc(1, sizeof(*pb));\n\tif (!pb)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpb->event_cb = p->event_cb;\n\tpb->sample_cb = p->sample_cb;\n\tpb->lost_cb = p->lost_cb;\n\tpb->ctx = p->ctx;\n\n\tpb->page_size = getpagesize();\n\tpb->mmap_size = pb->page_size * page_cnt;\n\tpb->map_fd = map_fd;\n\n\tpb->epoll_fd = epoll_create1(EPOLL_CLOEXEC);\n\tif (pb->epoll_fd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"failed to create epoll instance: %s\\n\",\n\t\t\tlibbpf_strerror_r(err, msg, sizeof(msg)));\n\t\tgoto error;\n\t}\n\n\tif (p->cpu_cnt > 0) {\n\t\tpb->cpu_cnt = p->cpu_cnt;\n\t} else {\n\t\tpb->cpu_cnt = libbpf_num_possible_cpus();\n\t\tif (pb->cpu_cnt < 0) {\n\t\t\terr = pb->cpu_cnt;\n\t\t\tgoto error;\n\t\t}\n\t\tif (map.max_entries && map.max_entries < pb->cpu_cnt)\n\t\t\tpb->cpu_cnt = map.max_entries;\n\t}\n\n\tpb->events = calloc(pb->cpu_cnt, sizeof(*pb->events));\n\tif (!pb->events) {\n\t\terr = -ENOMEM;\n\t\tpr_warn(\"failed to allocate events: out of memory\\n\");\n\t\tgoto error;\n\t}\n\tpb->cpu_bufs = calloc(pb->cpu_cnt, sizeof(*pb->cpu_bufs));\n\tif (!pb->cpu_bufs) {\n\t\terr = -ENOMEM;\n\t\tpr_warn(\"failed to allocate buffers: out of memory\\n\");\n\t\tgoto error;\n\t}\n\n\terr = parse_cpu_mask_file(online_cpus_file, &online, &n);\n\tif (err) {\n\t\tpr_warn(\"failed to get online CPU mask: %d\\n\", err);\n\t\tgoto error;\n\t}\n\n\tfor (i = 0, j = 0; i < pb->cpu_cnt; i++) {\n\t\tstruct perf_cpu_buf *cpu_buf;\n\t\tint cpu, map_key;\n\n\t\tcpu = p->cpu_cnt > 0 ? p->cpus[i] : i;\n\t\tmap_key = p->cpu_cnt > 0 ? p->map_keys[i] : i;\n\n\t\t \n\t\tif (p->cpu_cnt <= 0 && (cpu >= n || !online[cpu]))\n\t\t\tcontinue;\n\n\t\tcpu_buf = perf_buffer__open_cpu_buf(pb, p->attr, cpu, map_key);\n\t\tif (IS_ERR(cpu_buf)) {\n\t\t\terr = PTR_ERR(cpu_buf);\n\t\t\tgoto error;\n\t\t}\n\n\t\tpb->cpu_bufs[j] = cpu_buf;\n\n\t\terr = bpf_map_update_elem(pb->map_fd, &map_key,\n\t\t\t\t\t  &cpu_buf->fd, 0);\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"failed to set cpu #%d, key %d -> perf FD %d: %s\\n\",\n\t\t\t\tcpu, map_key, cpu_buf->fd,\n\t\t\t\tlibbpf_strerror_r(err, msg, sizeof(msg)));\n\t\t\tgoto error;\n\t\t}\n\n\t\tpb->events[j].events = EPOLLIN;\n\t\tpb->events[j].data.ptr = cpu_buf;\n\t\tif (epoll_ctl(pb->epoll_fd, EPOLL_CTL_ADD, cpu_buf->fd,\n\t\t\t      &pb->events[j]) < 0) {\n\t\t\terr = -errno;\n\t\t\tpr_warn(\"failed to epoll_ctl cpu #%d perf FD %d: %s\\n\",\n\t\t\t\tcpu, cpu_buf->fd,\n\t\t\t\tlibbpf_strerror_r(err, msg, sizeof(msg)));\n\t\t\tgoto error;\n\t\t}\n\t\tj++;\n\t}\n\tpb->cpu_cnt = j;\n\tfree(online);\n\n\treturn pb;\n\nerror:\n\tfree(online);\n\tif (pb)\n\t\tperf_buffer__free(pb);\n\treturn ERR_PTR(err);\n}\n\nstruct perf_sample_raw {\n\tstruct perf_event_header header;\n\tuint32_t size;\n\tchar data[];\n};\n\nstruct perf_sample_lost {\n\tstruct perf_event_header header;\n\tuint64_t id;\n\tuint64_t lost;\n\tuint64_t sample_id;\n};\n\nstatic enum bpf_perf_event_ret\nperf_buffer__process_record(struct perf_event_header *e, void *ctx)\n{\n\tstruct perf_cpu_buf *cpu_buf = ctx;\n\tstruct perf_buffer *pb = cpu_buf->pb;\n\tvoid *data = e;\n\n\t \n\tif (pb->event_cb)\n\t\treturn pb->event_cb(pb->ctx, cpu_buf->cpu, e);\n\n\tswitch (e->type) {\n\tcase PERF_RECORD_SAMPLE: {\n\t\tstruct perf_sample_raw *s = data;\n\n\t\tif (pb->sample_cb)\n\t\t\tpb->sample_cb(pb->ctx, cpu_buf->cpu, s->data, s->size);\n\t\tbreak;\n\t}\n\tcase PERF_RECORD_LOST: {\n\t\tstruct perf_sample_lost *s = data;\n\n\t\tif (pb->lost_cb)\n\t\t\tpb->lost_cb(pb->ctx, cpu_buf->cpu, s->lost);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tpr_warn(\"unknown perf sample type %d\\n\", e->type);\n\t\treturn LIBBPF_PERF_EVENT_ERROR;\n\t}\n\treturn LIBBPF_PERF_EVENT_CONT;\n}\n\nstatic int perf_buffer__process_records(struct perf_buffer *pb,\n\t\t\t\t\tstruct perf_cpu_buf *cpu_buf)\n{\n\tenum bpf_perf_event_ret ret;\n\n\tret = perf_event_read_simple(cpu_buf->base, pb->mmap_size,\n\t\t\t\t     pb->page_size, &cpu_buf->buf,\n\t\t\t\t     &cpu_buf->buf_size,\n\t\t\t\t     perf_buffer__process_record, cpu_buf);\n\tif (ret != LIBBPF_PERF_EVENT_CONT)\n\t\treturn ret;\n\treturn 0;\n}\n\nint perf_buffer__epoll_fd(const struct perf_buffer *pb)\n{\n\treturn pb->epoll_fd;\n}\n\nint perf_buffer__poll(struct perf_buffer *pb, int timeout_ms)\n{\n\tint i, cnt, err;\n\n\tcnt = epoll_wait(pb->epoll_fd, pb->events, pb->cpu_cnt, timeout_ms);\n\tif (cnt < 0)\n\t\treturn -errno;\n\n\tfor (i = 0; i < cnt; i++) {\n\t\tstruct perf_cpu_buf *cpu_buf = pb->events[i].data.ptr;\n\n\t\terr = perf_buffer__process_records(pb, cpu_buf);\n\t\tif (err) {\n\t\t\tpr_warn(\"error while processing records: %d\\n\", err);\n\t\t\treturn libbpf_err(err);\n\t\t}\n\t}\n\treturn cnt;\n}\n\n \nsize_t perf_buffer__buffer_cnt(const struct perf_buffer *pb)\n{\n\treturn pb->cpu_cnt;\n}\n\n \nint perf_buffer__buffer_fd(const struct perf_buffer *pb, size_t buf_idx)\n{\n\tstruct perf_cpu_buf *cpu_buf;\n\n\tif (buf_idx >= pb->cpu_cnt)\n\t\treturn libbpf_err(-EINVAL);\n\n\tcpu_buf = pb->cpu_bufs[buf_idx];\n\tif (!cpu_buf)\n\t\treturn libbpf_err(-ENOENT);\n\n\treturn cpu_buf->fd;\n}\n\nint perf_buffer__buffer(struct perf_buffer *pb, int buf_idx, void **buf, size_t *buf_size)\n{\n\tstruct perf_cpu_buf *cpu_buf;\n\n\tif (buf_idx >= pb->cpu_cnt)\n\t\treturn libbpf_err(-EINVAL);\n\n\tcpu_buf = pb->cpu_bufs[buf_idx];\n\tif (!cpu_buf)\n\t\treturn libbpf_err(-ENOENT);\n\n\t*buf = cpu_buf->base;\n\t*buf_size = pb->mmap_size;\n\treturn 0;\n}\n\n \nint perf_buffer__consume_buffer(struct perf_buffer *pb, size_t buf_idx)\n{\n\tstruct perf_cpu_buf *cpu_buf;\n\n\tif (buf_idx >= pb->cpu_cnt)\n\t\treturn libbpf_err(-EINVAL);\n\n\tcpu_buf = pb->cpu_bufs[buf_idx];\n\tif (!cpu_buf)\n\t\treturn libbpf_err(-ENOENT);\n\n\treturn perf_buffer__process_records(pb, cpu_buf);\n}\n\nint perf_buffer__consume(struct perf_buffer *pb)\n{\n\tint i, err;\n\n\tfor (i = 0; i < pb->cpu_cnt; i++) {\n\t\tstruct perf_cpu_buf *cpu_buf = pb->cpu_bufs[i];\n\n\t\tif (!cpu_buf)\n\t\t\tcontinue;\n\n\t\terr = perf_buffer__process_records(pb, cpu_buf);\n\t\tif (err) {\n\t\t\tpr_warn(\"perf_buffer: failed to process records in buffer #%d: %d\\n\", i, err);\n\t\t\treturn libbpf_err(err);\n\t\t}\n\t}\n\treturn 0;\n}\n\nint bpf_program__set_attach_target(struct bpf_program *prog,\n\t\t\t\t   int attach_prog_fd,\n\t\t\t\t   const char *attach_func_name)\n{\n\tint btf_obj_fd = 0, btf_id = 0, err;\n\n\tif (!prog || attach_prog_fd < 0)\n\t\treturn libbpf_err(-EINVAL);\n\n\tif (prog->obj->loaded)\n\t\treturn libbpf_err(-EINVAL);\n\n\tif (attach_prog_fd && !attach_func_name) {\n\t\t \n\t\tprog->attach_prog_fd = attach_prog_fd;\n\t\treturn 0;\n\t}\n\n\tif (attach_prog_fd) {\n\t\tbtf_id = libbpf_find_prog_btf_id(attach_func_name,\n\t\t\t\t\t\t attach_prog_fd);\n\t\tif (btf_id < 0)\n\t\t\treturn libbpf_err(btf_id);\n\t} else {\n\t\tif (!attach_func_name)\n\t\t\treturn libbpf_err(-EINVAL);\n\n\t\t \n\t\terr = bpf_object__load_vmlinux_btf(prog->obj, true);\n\t\tif (err)\n\t\t\treturn libbpf_err(err);\n\t\terr = find_kernel_btf_id(prog->obj, attach_func_name,\n\t\t\t\t\t prog->expected_attach_type,\n\t\t\t\t\t &btf_obj_fd, &btf_id);\n\t\tif (err)\n\t\t\treturn libbpf_err(err);\n\t}\n\n\tprog->attach_btf_id = btf_id;\n\tprog->attach_btf_obj_fd = btf_obj_fd;\n\tprog->attach_prog_fd = attach_prog_fd;\n\treturn 0;\n}\n\nint parse_cpu_mask_str(const char *s, bool **mask, int *mask_sz)\n{\n\tint err = 0, n, len, start, end = -1;\n\tbool *tmp;\n\n\t*mask = NULL;\n\t*mask_sz = 0;\n\n\t \n\twhile (*s) {\n\t\tif (*s == ',' || *s == '\\n') {\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\t\tn = sscanf(s, \"%d%n-%d%n\", &start, &len, &end, &len);\n\t\tif (n <= 0 || n > 2) {\n\t\t\tpr_warn(\"Failed to get CPU range %s: %d\\n\", s, n);\n\t\t\terr = -EINVAL;\n\t\t\tgoto cleanup;\n\t\t} else if (n == 1) {\n\t\t\tend = start;\n\t\t}\n\t\tif (start < 0 || start > end) {\n\t\t\tpr_warn(\"Invalid CPU range [%d,%d] in %s\\n\",\n\t\t\t\tstart, end, s);\n\t\t\terr = -EINVAL;\n\t\t\tgoto cleanup;\n\t\t}\n\t\ttmp = realloc(*mask, end + 1);\n\t\tif (!tmp) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto cleanup;\n\t\t}\n\t\t*mask = tmp;\n\t\tmemset(tmp + *mask_sz, 0, start - *mask_sz);\n\t\tmemset(tmp + start, 1, end - start + 1);\n\t\t*mask_sz = end + 1;\n\t\ts += len;\n\t}\n\tif (!*mask_sz) {\n\t\tpr_warn(\"Empty CPU range\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\ncleanup:\n\tfree(*mask);\n\t*mask = NULL;\n\treturn err;\n}\n\nint parse_cpu_mask_file(const char *fcpu, bool **mask, int *mask_sz)\n{\n\tint fd, err = 0, len;\n\tchar buf[128];\n\n\tfd = open(fcpu, O_RDONLY | O_CLOEXEC);\n\tif (fd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"Failed to open cpu mask file %s: %d\\n\", fcpu, err);\n\t\treturn err;\n\t}\n\tlen = read(fd, buf, sizeof(buf));\n\tclose(fd);\n\tif (len <= 0) {\n\t\terr = len ? -errno : -EINVAL;\n\t\tpr_warn(\"Failed to read cpu mask from %s: %d\\n\", fcpu, err);\n\t\treturn err;\n\t}\n\tif (len >= sizeof(buf)) {\n\t\tpr_warn(\"CPU mask is too big in file %s\\n\", fcpu);\n\t\treturn -E2BIG;\n\t}\n\tbuf[len] = '\\0';\n\n\treturn parse_cpu_mask_str(buf, mask, mask_sz);\n}\n\nint libbpf_num_possible_cpus(void)\n{\n\tstatic const char *fcpu = \"/sys/devices/system/cpu/possible\";\n\tstatic int cpus;\n\tint err, n, i, tmp_cpus;\n\tbool *mask;\n\n\ttmp_cpus = READ_ONCE(cpus);\n\tif (tmp_cpus > 0)\n\t\treturn tmp_cpus;\n\n\terr = parse_cpu_mask_file(fcpu, &mask, &n);\n\tif (err)\n\t\treturn libbpf_err(err);\n\n\ttmp_cpus = 0;\n\tfor (i = 0; i < n; i++) {\n\t\tif (mask[i])\n\t\t\ttmp_cpus++;\n\t}\n\tfree(mask);\n\n\tWRITE_ONCE(cpus, tmp_cpus);\n\treturn tmp_cpus;\n}\n\nstatic int populate_skeleton_maps(const struct bpf_object *obj,\n\t\t\t\t  struct bpf_map_skeleton *maps,\n\t\t\t\t  size_t map_cnt)\n{\n\tint i;\n\n\tfor (i = 0; i < map_cnt; i++) {\n\t\tstruct bpf_map **map = maps[i].map;\n\t\tconst char *name = maps[i].name;\n\t\tvoid **mmaped = maps[i].mmaped;\n\n\t\t*map = bpf_object__find_map_by_name(obj, name);\n\t\tif (!*map) {\n\t\t\tpr_warn(\"failed to find skeleton map '%s'\\n\", name);\n\t\t\treturn -ESRCH;\n\t\t}\n\n\t\t \n\t\tif (mmaped && (*map)->libbpf_type != LIBBPF_MAP_KCONFIG)\n\t\t\t*mmaped = (*map)->mmaped;\n\t}\n\treturn 0;\n}\n\nstatic int populate_skeleton_progs(const struct bpf_object *obj,\n\t\t\t\t   struct bpf_prog_skeleton *progs,\n\t\t\t\t   size_t prog_cnt)\n{\n\tint i;\n\n\tfor (i = 0; i < prog_cnt; i++) {\n\t\tstruct bpf_program **prog = progs[i].prog;\n\t\tconst char *name = progs[i].name;\n\n\t\t*prog = bpf_object__find_program_by_name(obj, name);\n\t\tif (!*prog) {\n\t\t\tpr_warn(\"failed to find skeleton program '%s'\\n\", name);\n\t\t\treturn -ESRCH;\n\t\t}\n\t}\n\treturn 0;\n}\n\nint bpf_object__open_skeleton(struct bpf_object_skeleton *s,\n\t\t\t      const struct bpf_object_open_opts *opts)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_object_open_opts, skel_opts,\n\t\t.object_name = s->name,\n\t);\n\tstruct bpf_object *obj;\n\tint err;\n\n\t \n\tif (opts) {\n\t\tmemcpy(&skel_opts, opts, sizeof(*opts));\n\t\tif (!opts->object_name)\n\t\t\tskel_opts.object_name = s->name;\n\t}\n\n\tobj = bpf_object__open_mem(s->data, s->data_sz, &skel_opts);\n\terr = libbpf_get_error(obj);\n\tif (err) {\n\t\tpr_warn(\"failed to initialize skeleton BPF object '%s': %d\\n\",\n\t\t\ts->name, err);\n\t\treturn libbpf_err(err);\n\t}\n\n\t*s->obj = obj;\n\terr = populate_skeleton_maps(obj, s->maps, s->map_cnt);\n\tif (err) {\n\t\tpr_warn(\"failed to populate skeleton maps for '%s': %d\\n\", s->name, err);\n\t\treturn libbpf_err(err);\n\t}\n\n\terr = populate_skeleton_progs(obj, s->progs, s->prog_cnt);\n\tif (err) {\n\t\tpr_warn(\"failed to populate skeleton progs for '%s': %d\\n\", s->name, err);\n\t\treturn libbpf_err(err);\n\t}\n\n\treturn 0;\n}\n\nint bpf_object__open_subskeleton(struct bpf_object_subskeleton *s)\n{\n\tint err, len, var_idx, i;\n\tconst char *var_name;\n\tconst struct bpf_map *map;\n\tstruct btf *btf;\n\t__u32 map_type_id;\n\tconst struct btf_type *map_type, *var_type;\n\tconst struct bpf_var_skeleton *var_skel;\n\tstruct btf_var_secinfo *var;\n\n\tif (!s->obj)\n\t\treturn libbpf_err(-EINVAL);\n\n\tbtf = bpf_object__btf(s->obj);\n\tif (!btf) {\n\t\tpr_warn(\"subskeletons require BTF at runtime (object %s)\\n\",\n\t\t\tbpf_object__name(s->obj));\n\t\treturn libbpf_err(-errno);\n\t}\n\n\terr = populate_skeleton_maps(s->obj, s->maps, s->map_cnt);\n\tif (err) {\n\t\tpr_warn(\"failed to populate subskeleton maps: %d\\n\", err);\n\t\treturn libbpf_err(err);\n\t}\n\n\terr = populate_skeleton_progs(s->obj, s->progs, s->prog_cnt);\n\tif (err) {\n\t\tpr_warn(\"failed to populate subskeleton maps: %d\\n\", err);\n\t\treturn libbpf_err(err);\n\t}\n\n\tfor (var_idx = 0; var_idx < s->var_cnt; var_idx++) {\n\t\tvar_skel = &s->vars[var_idx];\n\t\tmap = *var_skel->map;\n\t\tmap_type_id = bpf_map__btf_value_type_id(map);\n\t\tmap_type = btf__type_by_id(btf, map_type_id);\n\n\t\tif (!btf_is_datasec(map_type)) {\n\t\t\tpr_warn(\"type for map '%1$s' is not a datasec: %2$s\",\n\t\t\t\tbpf_map__name(map),\n\t\t\t\t__btf_kind_str(btf_kind(map_type)));\n\t\t\treturn libbpf_err(-EINVAL);\n\t\t}\n\n\t\tlen = btf_vlen(map_type);\n\t\tvar = btf_var_secinfos(map_type);\n\t\tfor (i = 0; i < len; i++, var++) {\n\t\t\tvar_type = btf__type_by_id(btf, var->type);\n\t\t\tvar_name = btf__name_by_offset(btf, var_type->name_off);\n\t\t\tif (strcmp(var_name, var_skel->name) == 0) {\n\t\t\t\t*var_skel->addr = map->mmaped + var->offset;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nvoid bpf_object__destroy_subskeleton(struct bpf_object_subskeleton *s)\n{\n\tif (!s)\n\t\treturn;\n\tfree(s->maps);\n\tfree(s->progs);\n\tfree(s->vars);\n\tfree(s);\n}\n\nint bpf_object__load_skeleton(struct bpf_object_skeleton *s)\n{\n\tint i, err;\n\n\terr = bpf_object__load(*s->obj);\n\tif (err) {\n\t\tpr_warn(\"failed to load BPF skeleton '%s': %d\\n\", s->name, err);\n\t\treturn libbpf_err(err);\n\t}\n\n\tfor (i = 0; i < s->map_cnt; i++) {\n\t\tstruct bpf_map *map = *s->maps[i].map;\n\t\tsize_t mmap_sz = bpf_map_mmap_sz(map->def.value_size, map->def.max_entries);\n\t\tint prot, map_fd = bpf_map__fd(map);\n\t\tvoid **mmaped = s->maps[i].mmaped;\n\n\t\tif (!mmaped)\n\t\t\tcontinue;\n\n\t\tif (!(map->def.map_flags & BPF_F_MMAPABLE)) {\n\t\t\t*mmaped = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (map->def.map_flags & BPF_F_RDONLY_PROG)\n\t\t\tprot = PROT_READ;\n\t\telse\n\t\t\tprot = PROT_READ | PROT_WRITE;\n\n\t\t \n\t\t*mmaped = mmap(map->mmaped, mmap_sz, prot, MAP_SHARED | MAP_FIXED, map_fd, 0);\n\t\tif (*mmaped == MAP_FAILED) {\n\t\t\terr = -errno;\n\t\t\t*mmaped = NULL;\n\t\t\tpr_warn(\"failed to re-mmap() map '%s': %d\\n\",\n\t\t\t\t bpf_map__name(map), err);\n\t\t\treturn libbpf_err(err);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint bpf_object__attach_skeleton(struct bpf_object_skeleton *s)\n{\n\tint i, err;\n\n\tfor (i = 0; i < s->prog_cnt; i++) {\n\t\tstruct bpf_program *prog = *s->progs[i].prog;\n\t\tstruct bpf_link **link = s->progs[i].link;\n\n\t\tif (!prog->autoload || !prog->autoattach)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!prog->sec_def || !prog->sec_def->prog_attach_fn)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (*link)\n\t\t\tcontinue;\n\n\t\terr = prog->sec_def->prog_attach_fn(prog, prog->sec_def->cookie, link);\n\t\tif (err) {\n\t\t\tpr_warn(\"prog '%s': failed to auto-attach: %d\\n\",\n\t\t\t\tbpf_program__name(prog), err);\n\t\t\treturn libbpf_err(err);\n\t\t}\n\n\t\t \n\t}\n\n\treturn 0;\n}\n\nvoid bpf_object__detach_skeleton(struct bpf_object_skeleton *s)\n{\n\tint i;\n\n\tfor (i = 0; i < s->prog_cnt; i++) {\n\t\tstruct bpf_link **link = s->progs[i].link;\n\n\t\tbpf_link__destroy(*link);\n\t\t*link = NULL;\n\t}\n}\n\nvoid bpf_object__destroy_skeleton(struct bpf_object_skeleton *s)\n{\n\tif (!s)\n\t\treturn;\n\n\tif (s->progs)\n\t\tbpf_object__detach_skeleton(s);\n\tif (s->obj)\n\t\tbpf_object__close(*s->obj);\n\tfree(s->maps);\n\tfree(s->progs);\n\tfree(s);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}