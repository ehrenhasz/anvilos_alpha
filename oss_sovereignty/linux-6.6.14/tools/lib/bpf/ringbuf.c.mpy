{
  "module_name": "ringbuf.c",
  "hash_id": "26844e70c73dbacd226fecb74a13af114cdf9dfb6998e9efa41c905d78e0eecb",
  "original_prompt": "Ingested from linux-6.6.14/tools/lib/bpf/ringbuf.c",
  "human_readable_source": "\n \n#ifndef _GNU_SOURCE\n#define _GNU_SOURCE\n#endif\n#include <stdlib.h>\n#include <stdio.h>\n#include <errno.h>\n#include <unistd.h>\n#include <linux/err.h>\n#include <linux/bpf.h>\n#include <asm/barrier.h>\n#include <sys/mman.h>\n#include <sys/epoll.h>\n#include <time.h>\n\n#include \"libbpf.h\"\n#include \"libbpf_internal.h\"\n#include \"bpf.h\"\n\nstruct ring {\n\tring_buffer_sample_fn sample_cb;\n\tvoid *ctx;\n\tvoid *data;\n\tunsigned long *consumer_pos;\n\tunsigned long *producer_pos;\n\tunsigned long mask;\n\tint map_fd;\n};\n\nstruct ring_buffer {\n\tstruct epoll_event *events;\n\tstruct ring *rings;\n\tsize_t page_size;\n\tint epoll_fd;\n\tint ring_cnt;\n};\n\nstruct user_ring_buffer {\n\tstruct epoll_event event;\n\tunsigned long *consumer_pos;\n\tunsigned long *producer_pos;\n\tvoid *data;\n\tunsigned long mask;\n\tsize_t page_size;\n\tint map_fd;\n\tint epoll_fd;\n};\n\n \nstruct ringbuf_hdr {\n\t__u32 len;\n\t__u32 pad;\n};\n\nstatic void ringbuf_unmap_ring(struct ring_buffer *rb, struct ring *r)\n{\n\tif (r->consumer_pos) {\n\t\tmunmap(r->consumer_pos, rb->page_size);\n\t\tr->consumer_pos = NULL;\n\t}\n\tif (r->producer_pos) {\n\t\tmunmap(r->producer_pos, rb->page_size + 2 * (r->mask + 1));\n\t\tr->producer_pos = NULL;\n\t}\n}\n\n \nint ring_buffer__add(struct ring_buffer *rb, int map_fd,\n\t\t     ring_buffer_sample_fn sample_cb, void *ctx)\n{\n\tstruct bpf_map_info info;\n\t__u32 len = sizeof(info);\n\tstruct epoll_event *e;\n\tstruct ring *r;\n\t__u64 mmap_sz;\n\tvoid *tmp;\n\tint err;\n\n\tmemset(&info, 0, sizeof(info));\n\n\terr = bpf_map_get_info_by_fd(map_fd, &info, &len);\n\tif (err) {\n\t\terr = -errno;\n\t\tpr_warn(\"ringbuf: failed to get map info for fd=%d: %d\\n\",\n\t\t\tmap_fd, err);\n\t\treturn libbpf_err(err);\n\t}\n\n\tif (info.type != BPF_MAP_TYPE_RINGBUF) {\n\t\tpr_warn(\"ringbuf: map fd=%d is not BPF_MAP_TYPE_RINGBUF\\n\",\n\t\t\tmap_fd);\n\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\ttmp = libbpf_reallocarray(rb->rings, rb->ring_cnt + 1, sizeof(*rb->rings));\n\tif (!tmp)\n\t\treturn libbpf_err(-ENOMEM);\n\trb->rings = tmp;\n\n\ttmp = libbpf_reallocarray(rb->events, rb->ring_cnt + 1, sizeof(*rb->events));\n\tif (!tmp)\n\t\treturn libbpf_err(-ENOMEM);\n\trb->events = tmp;\n\n\tr = &rb->rings[rb->ring_cnt];\n\tmemset(r, 0, sizeof(*r));\n\n\tr->map_fd = map_fd;\n\tr->sample_cb = sample_cb;\n\tr->ctx = ctx;\n\tr->mask = info.max_entries - 1;\n\n\t \n\ttmp = mmap(NULL, rb->page_size, PROT_READ | PROT_WRITE, MAP_SHARED, map_fd, 0);\n\tif (tmp == MAP_FAILED) {\n\t\terr = -errno;\n\t\tpr_warn(\"ringbuf: failed to mmap consumer page for map fd=%d: %d\\n\",\n\t\t\tmap_fd, err);\n\t\treturn libbpf_err(err);\n\t}\n\tr->consumer_pos = tmp;\n\n\t \n\tmmap_sz = rb->page_size + 2 * (__u64)info.max_entries;\n\tif (mmap_sz != (__u64)(size_t)mmap_sz) {\n\t\tpr_warn(\"ringbuf: ring buffer size (%u) is too big\\n\", info.max_entries);\n\t\treturn libbpf_err(-E2BIG);\n\t}\n\ttmp = mmap(NULL, (size_t)mmap_sz, PROT_READ, MAP_SHARED, map_fd, rb->page_size);\n\tif (tmp == MAP_FAILED) {\n\t\terr = -errno;\n\t\tringbuf_unmap_ring(rb, r);\n\t\tpr_warn(\"ringbuf: failed to mmap data pages for map fd=%d: %d\\n\",\n\t\t\tmap_fd, err);\n\t\treturn libbpf_err(err);\n\t}\n\tr->producer_pos = tmp;\n\tr->data = tmp + rb->page_size;\n\n\te = &rb->events[rb->ring_cnt];\n\tmemset(e, 0, sizeof(*e));\n\n\te->events = EPOLLIN;\n\te->data.fd = rb->ring_cnt;\n\tif (epoll_ctl(rb->epoll_fd, EPOLL_CTL_ADD, map_fd, e) < 0) {\n\t\terr = -errno;\n\t\tringbuf_unmap_ring(rb, r);\n\t\tpr_warn(\"ringbuf: failed to epoll add map fd=%d: %d\\n\",\n\t\t\tmap_fd, err);\n\t\treturn libbpf_err(err);\n\t}\n\n\trb->ring_cnt++;\n\treturn 0;\n}\n\nvoid ring_buffer__free(struct ring_buffer *rb)\n{\n\tint i;\n\n\tif (!rb)\n\t\treturn;\n\n\tfor (i = 0; i < rb->ring_cnt; ++i)\n\t\tringbuf_unmap_ring(rb, &rb->rings[i]);\n\tif (rb->epoll_fd >= 0)\n\t\tclose(rb->epoll_fd);\n\n\tfree(rb->events);\n\tfree(rb->rings);\n\tfree(rb);\n}\n\nstruct ring_buffer *\nring_buffer__new(int map_fd, ring_buffer_sample_fn sample_cb, void *ctx,\n\t\t const struct ring_buffer_opts *opts)\n{\n\tstruct ring_buffer *rb;\n\tint err;\n\n\tif (!OPTS_VALID(opts, ring_buffer_opts))\n\t\treturn errno = EINVAL, NULL;\n\n\trb = calloc(1, sizeof(*rb));\n\tif (!rb)\n\t\treturn errno = ENOMEM, NULL;\n\n\trb->page_size = getpagesize();\n\n\trb->epoll_fd = epoll_create1(EPOLL_CLOEXEC);\n\tif (rb->epoll_fd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"ringbuf: failed to create epoll instance: %d\\n\", err);\n\t\tgoto err_out;\n\t}\n\n\terr = ring_buffer__add(rb, map_fd, sample_cb, ctx);\n\tif (err)\n\t\tgoto err_out;\n\n\treturn rb;\n\nerr_out:\n\tring_buffer__free(rb);\n\treturn errno = -err, NULL;\n}\n\nstatic inline int roundup_len(__u32 len)\n{\n\t \n\tlen <<= 2;\n\tlen >>= 2;\n\t \n\tlen += BPF_RINGBUF_HDR_SZ;\n\t \n\treturn (len + 7) / 8 * 8;\n}\n\nstatic int64_t ringbuf_process_ring(struct ring *r)\n{\n\tint *len_ptr, len, err;\n\t \n\tint64_t cnt = 0;\n\tunsigned long cons_pos, prod_pos;\n\tbool got_new_data;\n\tvoid *sample;\n\n\tcons_pos = smp_load_acquire(r->consumer_pos);\n\tdo {\n\t\tgot_new_data = false;\n\t\tprod_pos = smp_load_acquire(r->producer_pos);\n\t\twhile (cons_pos < prod_pos) {\n\t\t\tlen_ptr = r->data + (cons_pos & r->mask);\n\t\t\tlen = smp_load_acquire(len_ptr);\n\n\t\t\t \n\t\t\tif (len & BPF_RINGBUF_BUSY_BIT)\n\t\t\t\tgoto done;\n\n\t\t\tgot_new_data = true;\n\t\t\tcons_pos += roundup_len(len);\n\n\t\t\tif ((len & BPF_RINGBUF_DISCARD_BIT) == 0) {\n\t\t\t\tsample = (void *)len_ptr + BPF_RINGBUF_HDR_SZ;\n\t\t\t\terr = r->sample_cb(r->ctx, sample, len);\n\t\t\t\tif (err < 0) {\n\t\t\t\t\t \n\t\t\t\t\tsmp_store_release(r->consumer_pos,\n\t\t\t\t\t\t\t  cons_pos);\n\t\t\t\t\treturn err;\n\t\t\t\t}\n\t\t\t\tcnt++;\n\t\t\t}\n\n\t\t\tsmp_store_release(r->consumer_pos, cons_pos);\n\t\t}\n\t} while (got_new_data);\ndone:\n\treturn cnt;\n}\n\n \nint ring_buffer__consume(struct ring_buffer *rb)\n{\n\tint64_t err, res = 0;\n\tint i;\n\n\tfor (i = 0; i < rb->ring_cnt; i++) {\n\t\tstruct ring *ring = &rb->rings[i];\n\n\t\terr = ringbuf_process_ring(ring);\n\t\tif (err < 0)\n\t\t\treturn libbpf_err(err);\n\t\tres += err;\n\t}\n\tif (res > INT_MAX)\n\t\treturn INT_MAX;\n\treturn res;\n}\n\n \nint ring_buffer__poll(struct ring_buffer *rb, int timeout_ms)\n{\n\tint i, cnt;\n\tint64_t err, res = 0;\n\n\tcnt = epoll_wait(rb->epoll_fd, rb->events, rb->ring_cnt, timeout_ms);\n\tif (cnt < 0)\n\t\treturn libbpf_err(-errno);\n\n\tfor (i = 0; i < cnt; i++) {\n\t\t__u32 ring_id = rb->events[i].data.fd;\n\t\tstruct ring *ring = &rb->rings[ring_id];\n\n\t\terr = ringbuf_process_ring(ring);\n\t\tif (err < 0)\n\t\t\treturn libbpf_err(err);\n\t\tres += err;\n\t}\n\tif (res > INT_MAX)\n\t\treturn INT_MAX;\n\treturn res;\n}\n\n \nint ring_buffer__epoll_fd(const struct ring_buffer *rb)\n{\n\treturn rb->epoll_fd;\n}\n\nstatic void user_ringbuf_unmap_ring(struct user_ring_buffer *rb)\n{\n\tif (rb->consumer_pos) {\n\t\tmunmap(rb->consumer_pos, rb->page_size);\n\t\trb->consumer_pos = NULL;\n\t}\n\tif (rb->producer_pos) {\n\t\tmunmap(rb->producer_pos, rb->page_size + 2 * (rb->mask + 1));\n\t\trb->producer_pos = NULL;\n\t}\n}\n\nvoid user_ring_buffer__free(struct user_ring_buffer *rb)\n{\n\tif (!rb)\n\t\treturn;\n\n\tuser_ringbuf_unmap_ring(rb);\n\n\tif (rb->epoll_fd >= 0)\n\t\tclose(rb->epoll_fd);\n\n\tfree(rb);\n}\n\nstatic int user_ringbuf_map(struct user_ring_buffer *rb, int map_fd)\n{\n\tstruct bpf_map_info info;\n\t__u32 len = sizeof(info);\n\t__u64 mmap_sz;\n\tvoid *tmp;\n\tstruct epoll_event *rb_epoll;\n\tint err;\n\n\tmemset(&info, 0, sizeof(info));\n\n\terr = bpf_map_get_info_by_fd(map_fd, &info, &len);\n\tif (err) {\n\t\terr = -errno;\n\t\tpr_warn(\"user ringbuf: failed to get map info for fd=%d: %d\\n\", map_fd, err);\n\t\treturn err;\n\t}\n\n\tif (info.type != BPF_MAP_TYPE_USER_RINGBUF) {\n\t\tpr_warn(\"user ringbuf: map fd=%d is not BPF_MAP_TYPE_USER_RINGBUF\\n\", map_fd);\n\t\treturn -EINVAL;\n\t}\n\n\trb->map_fd = map_fd;\n\trb->mask = info.max_entries - 1;\n\n\t \n\ttmp = mmap(NULL, rb->page_size, PROT_READ, MAP_SHARED, map_fd, 0);\n\tif (tmp == MAP_FAILED) {\n\t\terr = -errno;\n\t\tpr_warn(\"user ringbuf: failed to mmap consumer page for map fd=%d: %d\\n\",\n\t\t\tmap_fd, err);\n\t\treturn err;\n\t}\n\trb->consumer_pos = tmp;\n\n\t \n\tmmap_sz = rb->page_size + 2 * (__u64)info.max_entries;\n\tif (mmap_sz != (__u64)(size_t)mmap_sz) {\n\t\tpr_warn(\"user ringbuf: ring buf size (%u) is too big\\n\", info.max_entries);\n\t\treturn -E2BIG;\n\t}\n\ttmp = mmap(NULL, (size_t)mmap_sz, PROT_READ | PROT_WRITE, MAP_SHARED,\n\t\t   map_fd, rb->page_size);\n\tif (tmp == MAP_FAILED) {\n\t\terr = -errno;\n\t\tpr_warn(\"user ringbuf: failed to mmap data pages for map fd=%d: %d\\n\",\n\t\t\tmap_fd, err);\n\t\treturn err;\n\t}\n\n\trb->producer_pos = tmp;\n\trb->data = tmp + rb->page_size;\n\n\trb_epoll = &rb->event;\n\trb_epoll->events = EPOLLOUT;\n\tif (epoll_ctl(rb->epoll_fd, EPOLL_CTL_ADD, map_fd, rb_epoll) < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"user ringbuf: failed to epoll add map fd=%d: %d\\n\", map_fd, err);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstruct user_ring_buffer *\nuser_ring_buffer__new(int map_fd, const struct user_ring_buffer_opts *opts)\n{\n\tstruct user_ring_buffer *rb;\n\tint err;\n\n\tif (!OPTS_VALID(opts, user_ring_buffer_opts))\n\t\treturn errno = EINVAL, NULL;\n\n\trb = calloc(1, sizeof(*rb));\n\tif (!rb)\n\t\treturn errno = ENOMEM, NULL;\n\n\trb->page_size = getpagesize();\n\n\trb->epoll_fd = epoll_create1(EPOLL_CLOEXEC);\n\tif (rb->epoll_fd < 0) {\n\t\terr = -errno;\n\t\tpr_warn(\"user ringbuf: failed to create epoll instance: %d\\n\", err);\n\t\tgoto err_out;\n\t}\n\n\terr = user_ringbuf_map(rb, map_fd);\n\tif (err)\n\t\tgoto err_out;\n\n\treturn rb;\n\nerr_out:\n\tuser_ring_buffer__free(rb);\n\treturn errno = -err, NULL;\n}\n\nstatic void user_ringbuf_commit(struct user_ring_buffer *rb, void *sample, bool discard)\n{\n\t__u32 new_len;\n\tstruct ringbuf_hdr *hdr;\n\tuintptr_t hdr_offset;\n\n\thdr_offset = rb->mask + 1 + (sample - rb->data) - BPF_RINGBUF_HDR_SZ;\n\thdr = rb->data + (hdr_offset & rb->mask);\n\n\tnew_len = hdr->len & ~BPF_RINGBUF_BUSY_BIT;\n\tif (discard)\n\t\tnew_len |= BPF_RINGBUF_DISCARD_BIT;\n\n\t \n\t__atomic_exchange_n(&hdr->len, new_len, __ATOMIC_ACQ_REL);\n}\n\nvoid user_ring_buffer__discard(struct user_ring_buffer *rb, void *sample)\n{\n\tuser_ringbuf_commit(rb, sample, true);\n}\n\nvoid user_ring_buffer__submit(struct user_ring_buffer *rb, void *sample)\n{\n\tuser_ringbuf_commit(rb, sample, false);\n}\n\nvoid *user_ring_buffer__reserve(struct user_ring_buffer *rb, __u32 size)\n{\n\t__u32 avail_size, total_size, max_size;\n\t \n\t__u64 cons_pos, prod_pos;\n\tstruct ringbuf_hdr *hdr;\n\n\t \n\tif (size & (BPF_RINGBUF_BUSY_BIT | BPF_RINGBUF_DISCARD_BIT))\n\t\treturn errno = E2BIG, NULL;\n\n\t \n\tcons_pos = smp_load_acquire(rb->consumer_pos);\n\t \n\tprod_pos = smp_load_acquire(rb->producer_pos);\n\n\tmax_size = rb->mask + 1;\n\tavail_size = max_size - (prod_pos - cons_pos);\n\t \n\ttotal_size = (size + BPF_RINGBUF_HDR_SZ + 7) / 8 * 8;\n\n\tif (total_size > max_size)\n\t\treturn errno = E2BIG, NULL;\n\n\tif (avail_size < total_size)\n\t\treturn errno = ENOSPC, NULL;\n\n\thdr = rb->data + (prod_pos & rb->mask);\n\thdr->len = size | BPF_RINGBUF_BUSY_BIT;\n\thdr->pad = 0;\n\n\t \n\tsmp_store_release(rb->producer_pos, prod_pos + total_size);\n\n\treturn (void *)rb->data + ((prod_pos + BPF_RINGBUF_HDR_SZ) & rb->mask);\n}\n\nstatic __u64 ns_elapsed_timespec(const struct timespec *start, const struct timespec *end)\n{\n\t__u64 start_ns, end_ns, ns_per_s = 1000000000;\n\n\tstart_ns = (__u64)start->tv_sec * ns_per_s + start->tv_nsec;\n\tend_ns = (__u64)end->tv_sec * ns_per_s + end->tv_nsec;\n\n\treturn end_ns - start_ns;\n}\n\nvoid *user_ring_buffer__reserve_blocking(struct user_ring_buffer *rb, __u32 size, int timeout_ms)\n{\n\tvoid *sample;\n\tint err, ms_remaining = timeout_ms;\n\tstruct timespec start;\n\n\tif (timeout_ms < 0 && timeout_ms != -1)\n\t\treturn errno = EINVAL, NULL;\n\n\tif (timeout_ms != -1) {\n\t\terr = clock_gettime(CLOCK_MONOTONIC, &start);\n\t\tif (err)\n\t\t\treturn NULL;\n\t}\n\n\tdo {\n\t\tint cnt, ms_elapsed;\n\t\tstruct timespec curr;\n\t\t__u64 ns_per_ms = 1000000;\n\n\t\tsample = user_ring_buffer__reserve(rb, size);\n\t\tif (sample)\n\t\t\treturn sample;\n\t\telse if (errno != ENOSPC)\n\t\t\treturn NULL;\n\n\t\t \n\t\tcnt = epoll_wait(rb->epoll_fd, &rb->event, 1, ms_remaining);\n\t\tif (cnt < 0)\n\t\t\treturn NULL;\n\n\t\tif (timeout_ms == -1)\n\t\t\tcontinue;\n\n\t\terr = clock_gettime(CLOCK_MONOTONIC, &curr);\n\t\tif (err)\n\t\t\treturn NULL;\n\n\t\tms_elapsed = ns_elapsed_timespec(&start, &curr) / ns_per_ms;\n\t\tms_remaining = timeout_ms - ms_elapsed;\n\t} while (ms_remaining > 0);\n\n\t \n\treturn user_ring_buffer__reserve(rb, size);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}