{
  "module_name": "bpf.c",
  "hash_id": "6df14f10d31049c67fd071130e2454660324d21047c80e4cf7c94321ce317d8a",
  "original_prompt": "Ingested from linux-6.6.14/tools/lib/bpf/bpf.c",
  "human_readable_source": "\n\n \n\n#include <stdlib.h>\n#include <string.h>\n#include <memory.h>\n#include <unistd.h>\n#include <asm/unistd.h>\n#include <errno.h>\n#include <linux/bpf.h>\n#include <linux/filter.h>\n#include <linux/kernel.h>\n#include <limits.h>\n#include <sys/resource.h>\n#include \"bpf.h\"\n#include \"libbpf.h\"\n#include \"libbpf_internal.h\"\n\n \n#ifndef __NR_bpf\n# if defined(__i386__)\n#  define __NR_bpf 357\n# elif defined(__x86_64__)\n#  define __NR_bpf 321\n# elif defined(__aarch64__)\n#  define __NR_bpf 280\n# elif defined(__sparc__)\n#  define __NR_bpf 349\n# elif defined(__s390__)\n#  define __NR_bpf 351\n# elif defined(__arc__)\n#  define __NR_bpf 280\n# elif defined(__mips__) && defined(_ABIO32)\n#  define __NR_bpf 4355\n# elif defined(__mips__) && defined(_ABIN32)\n#  define __NR_bpf 6319\n# elif defined(__mips__) && defined(_ABI64)\n#  define __NR_bpf 5315\n# else\n#  error __NR_bpf not defined. libbpf does not support your arch.\n# endif\n#endif\n\nstatic inline __u64 ptr_to_u64(const void *ptr)\n{\n\treturn (__u64) (unsigned long) ptr;\n}\n\nstatic inline int sys_bpf(enum bpf_cmd cmd, union bpf_attr *attr,\n\t\t\t  unsigned int size)\n{\n\treturn syscall(__NR_bpf, cmd, attr, size);\n}\n\nstatic inline int sys_bpf_fd(enum bpf_cmd cmd, union bpf_attr *attr,\n\t\t\t     unsigned int size)\n{\n\tint fd;\n\n\tfd = sys_bpf(cmd, attr, size);\n\treturn ensure_good_fd(fd);\n}\n\nint sys_bpf_prog_load(union bpf_attr *attr, unsigned int size, int attempts)\n{\n\tint fd;\n\n\tdo {\n\t\tfd = sys_bpf_fd(BPF_PROG_LOAD, attr, size);\n\t} while (fd < 0 && errno == EAGAIN && --attempts > 0);\n\n\treturn fd;\n}\n\n \nint probe_memcg_account(void)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, attach_btf_obj_fd);\n\tstruct bpf_insn insns[] = {\n\t\tBPF_EMIT_CALL(BPF_FUNC_ktime_get_coarse_ns),\n\t\tBPF_EXIT_INSN(),\n\t};\n\tsize_t insn_cnt = ARRAY_SIZE(insns);\n\tunion bpf_attr attr;\n\tint prog_fd;\n\n\t \n\tmemset(&attr, 0, attr_sz);\n\tattr.prog_type = BPF_PROG_TYPE_SOCKET_FILTER;\n\tattr.insns = ptr_to_u64(insns);\n\tattr.insn_cnt = insn_cnt;\n\tattr.license = ptr_to_u64(\"GPL\");\n\n\tprog_fd = sys_bpf_fd(BPF_PROG_LOAD, &attr, attr_sz);\n\tif (prog_fd >= 0) {\n\t\tclose(prog_fd);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic bool memlock_bumped;\nstatic rlim_t memlock_rlim = RLIM_INFINITY;\n\nint libbpf_set_memlock_rlim(size_t memlock_bytes)\n{\n\tif (memlock_bumped)\n\t\treturn libbpf_err(-EBUSY);\n\n\tmemlock_rlim = memlock_bytes;\n\treturn 0;\n}\n\nint bump_rlimit_memlock(void)\n{\n\tstruct rlimit rlim;\n\n\t \n\tif (memlock_bumped || kernel_supports(NULL, FEAT_MEMCG_ACCOUNT))\n\t\treturn 0;\n\n\tmemlock_bumped = true;\n\n\t \n\tif (memlock_rlim == 0)\n\t\treturn 0;\n\n\trlim.rlim_cur = rlim.rlim_max = memlock_rlim;\n\tif (setrlimit(RLIMIT_MEMLOCK, &rlim))\n\t\treturn -errno;\n\n\treturn 0;\n}\n\nint bpf_map_create(enum bpf_map_type map_type,\n\t\t   const char *map_name,\n\t\t   __u32 key_size,\n\t\t   __u32 value_size,\n\t\t   __u32 max_entries,\n\t\t   const struct bpf_map_create_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, map_extra);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tbump_rlimit_memlock();\n\n\tmemset(&attr, 0, attr_sz);\n\n\tif (!OPTS_VALID(opts, bpf_map_create_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tattr.map_type = map_type;\n\tif (map_name && kernel_supports(NULL, FEAT_PROG_NAME))\n\t\tlibbpf_strlcpy(attr.map_name, map_name, sizeof(attr.map_name));\n\tattr.key_size = key_size;\n\tattr.value_size = value_size;\n\tattr.max_entries = max_entries;\n\n\tattr.btf_fd = OPTS_GET(opts, btf_fd, 0);\n\tattr.btf_key_type_id = OPTS_GET(opts, btf_key_type_id, 0);\n\tattr.btf_value_type_id = OPTS_GET(opts, btf_value_type_id, 0);\n\tattr.btf_vmlinux_value_type_id = OPTS_GET(opts, btf_vmlinux_value_type_id, 0);\n\n\tattr.inner_map_fd = OPTS_GET(opts, inner_map_fd, 0);\n\tattr.map_flags = OPTS_GET(opts, map_flags, 0);\n\tattr.map_extra = OPTS_GET(opts, map_extra, 0);\n\tattr.numa_node = OPTS_GET(opts, numa_node, 0);\n\tattr.map_ifindex = OPTS_GET(opts, map_ifindex, 0);\n\n\tfd = sys_bpf_fd(BPF_MAP_CREATE, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nstatic void *\nalloc_zero_tailing_info(const void *orecord, __u32 cnt,\n\t\t\t__u32 actual_rec_size, __u32 expected_rec_size)\n{\n\t__u64 info_len = (__u64)actual_rec_size * cnt;\n\tvoid *info, *nrecord;\n\tint i;\n\n\tinfo = malloc(info_len);\n\tif (!info)\n\t\treturn NULL;\n\n\t \n\tnrecord = info;\n\tfor (i = 0; i < cnt; i++) {\n\t\tmemcpy(nrecord, orecord, expected_rec_size);\n\t\tmemset(nrecord + expected_rec_size, 0,\n\t\t       actual_rec_size - expected_rec_size);\n\t\torecord += actual_rec_size;\n\t\tnrecord += actual_rec_size;\n\t}\n\n\treturn info;\n}\n\nint bpf_prog_load(enum bpf_prog_type prog_type,\n\t\t  const char *prog_name, const char *license,\n\t\t  const struct bpf_insn *insns, size_t insn_cnt,\n\t\t  struct bpf_prog_load_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, log_true_size);\n\tvoid *finfo = NULL, *linfo = NULL;\n\tconst char *func_info, *line_info;\n\t__u32 log_size, log_level, attach_prog_fd, attach_btf_obj_fd;\n\t__u32 func_info_rec_size, line_info_rec_size;\n\tint fd, attempts;\n\tunion bpf_attr attr;\n\tchar *log_buf;\n\n\tbump_rlimit_memlock();\n\n\tif (!OPTS_VALID(opts, bpf_prog_load_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tattempts = OPTS_GET(opts, attempts, 0);\n\tif (attempts < 0)\n\t\treturn libbpf_err(-EINVAL);\n\tif (attempts == 0)\n\t\tattempts = PROG_LOAD_ATTEMPTS;\n\n\tmemset(&attr, 0, attr_sz);\n\n\tattr.prog_type = prog_type;\n\tattr.expected_attach_type = OPTS_GET(opts, expected_attach_type, 0);\n\n\tattr.prog_btf_fd = OPTS_GET(opts, prog_btf_fd, 0);\n\tattr.prog_flags = OPTS_GET(opts, prog_flags, 0);\n\tattr.prog_ifindex = OPTS_GET(opts, prog_ifindex, 0);\n\tattr.kern_version = OPTS_GET(opts, kern_version, 0);\n\n\tif (prog_name && kernel_supports(NULL, FEAT_PROG_NAME))\n\t\tlibbpf_strlcpy(attr.prog_name, prog_name, sizeof(attr.prog_name));\n\tattr.license = ptr_to_u64(license);\n\n\tif (insn_cnt > UINT_MAX)\n\t\treturn libbpf_err(-E2BIG);\n\n\tattr.insns = ptr_to_u64(insns);\n\tattr.insn_cnt = (__u32)insn_cnt;\n\n\tattach_prog_fd = OPTS_GET(opts, attach_prog_fd, 0);\n\tattach_btf_obj_fd = OPTS_GET(opts, attach_btf_obj_fd, 0);\n\n\tif (attach_prog_fd && attach_btf_obj_fd)\n\t\treturn libbpf_err(-EINVAL);\n\n\tattr.attach_btf_id = OPTS_GET(opts, attach_btf_id, 0);\n\tif (attach_prog_fd)\n\t\tattr.attach_prog_fd = attach_prog_fd;\n\telse\n\t\tattr.attach_btf_obj_fd = attach_btf_obj_fd;\n\n\tlog_buf = OPTS_GET(opts, log_buf, NULL);\n\tlog_size = OPTS_GET(opts, log_size, 0);\n\tlog_level = OPTS_GET(opts, log_level, 0);\n\n\tif (!!log_buf != !!log_size)\n\t\treturn libbpf_err(-EINVAL);\n\n\tfunc_info_rec_size = OPTS_GET(opts, func_info_rec_size, 0);\n\tfunc_info = OPTS_GET(opts, func_info, NULL);\n\tattr.func_info_rec_size = func_info_rec_size;\n\tattr.func_info = ptr_to_u64(func_info);\n\tattr.func_info_cnt = OPTS_GET(opts, func_info_cnt, 0);\n\n\tline_info_rec_size = OPTS_GET(opts, line_info_rec_size, 0);\n\tline_info = OPTS_GET(opts, line_info, NULL);\n\tattr.line_info_rec_size = line_info_rec_size;\n\tattr.line_info = ptr_to_u64(line_info);\n\tattr.line_info_cnt = OPTS_GET(opts, line_info_cnt, 0);\n\n\tattr.fd_array = ptr_to_u64(OPTS_GET(opts, fd_array, NULL));\n\n\tif (log_level) {\n\t\tattr.log_buf = ptr_to_u64(log_buf);\n\t\tattr.log_size = log_size;\n\t\tattr.log_level = log_level;\n\t}\n\n\tfd = sys_bpf_prog_load(&attr, attr_sz, attempts);\n\tOPTS_SET(opts, log_true_size, attr.log_true_size);\n\tif (fd >= 0)\n\t\treturn fd;\n\n\t \n\twhile (errno == E2BIG && (!finfo || !linfo)) {\n\t\tif (!finfo && attr.func_info_cnt &&\n\t\t    attr.func_info_rec_size < func_info_rec_size) {\n\t\t\t \n\t\t\tfinfo = alloc_zero_tailing_info(func_info,\n\t\t\t\t\t\t\tattr.func_info_cnt,\n\t\t\t\t\t\t\tfunc_info_rec_size,\n\t\t\t\t\t\t\tattr.func_info_rec_size);\n\t\t\tif (!finfo) {\n\t\t\t\terrno = E2BIG;\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\tattr.func_info = ptr_to_u64(finfo);\n\t\t\tattr.func_info_rec_size = func_info_rec_size;\n\t\t} else if (!linfo && attr.line_info_cnt &&\n\t\t\t   attr.line_info_rec_size < line_info_rec_size) {\n\t\t\tlinfo = alloc_zero_tailing_info(line_info,\n\t\t\t\t\t\t\tattr.line_info_cnt,\n\t\t\t\t\t\t\tline_info_rec_size,\n\t\t\t\t\t\t\tattr.line_info_rec_size);\n\t\t\tif (!linfo) {\n\t\t\t\terrno = E2BIG;\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\tattr.line_info = ptr_to_u64(linfo);\n\t\t\tattr.line_info_rec_size = line_info_rec_size;\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\n\t\tfd = sys_bpf_prog_load(&attr, attr_sz, attempts);\n\t\tOPTS_SET(opts, log_true_size, attr.log_true_size);\n\t\tif (fd >= 0)\n\t\t\tgoto done;\n\t}\n\n\tif (log_level == 0 && log_buf) {\n\t\t \n\t\tattr.log_buf = ptr_to_u64(log_buf);\n\t\tattr.log_size = log_size;\n\t\tattr.log_level = 1;\n\n\t\tfd = sys_bpf_prog_load(&attr, attr_sz, attempts);\n\t\tOPTS_SET(opts, log_true_size, attr.log_true_size);\n\t}\ndone:\n\t \n\tfree(finfo);\n\tfree(linfo);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_map_update_elem(int fd, const void *key, const void *value,\n\t\t\t__u64 flags)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, flags);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\tattr.value = ptr_to_u64(value);\n\tattr.flags = flags;\n\n\tret = sys_bpf(BPF_MAP_UPDATE_ELEM, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_lookup_elem(int fd, const void *key, void *value)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, flags);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\tattr.value = ptr_to_u64(value);\n\n\tret = sys_bpf(BPF_MAP_LOOKUP_ELEM, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_lookup_elem_flags(int fd, const void *key, void *value, __u64 flags)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, flags);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\tattr.value = ptr_to_u64(value);\n\tattr.flags = flags;\n\n\tret = sys_bpf(BPF_MAP_LOOKUP_ELEM, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_lookup_and_delete_elem(int fd, const void *key, void *value)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, flags);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\tattr.value = ptr_to_u64(value);\n\n\tret = sys_bpf(BPF_MAP_LOOKUP_AND_DELETE_ELEM, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_lookup_and_delete_elem_flags(int fd, const void *key, void *value, __u64 flags)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, flags);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\tattr.value = ptr_to_u64(value);\n\tattr.flags = flags;\n\n\tret = sys_bpf(BPF_MAP_LOOKUP_AND_DELETE_ELEM, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_delete_elem(int fd, const void *key)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, flags);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\n\tret = sys_bpf(BPF_MAP_DELETE_ELEM, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_delete_elem_flags(int fd, const void *key, __u64 flags)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, flags);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\tattr.flags = flags;\n\n\tret = sys_bpf(BPF_MAP_DELETE_ELEM, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_get_next_key(int fd, const void *key, void *next_key)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, next_key);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\tattr.key = ptr_to_u64(key);\n\tattr.next_key = ptr_to_u64(next_key);\n\n\tret = sys_bpf(BPF_MAP_GET_NEXT_KEY, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_freeze(int fd)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, map_fd);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_fd = fd;\n\n\tret = sys_bpf(BPF_MAP_FREEZE, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nstatic int bpf_map_batch_common(int cmd, int fd, void  *in_batch,\n\t\t\t\tvoid *out_batch, void *keys, void *values,\n\t\t\t\t__u32 *count,\n\t\t\t\tconst struct bpf_map_batch_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, batch);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tif (!OPTS_VALID(opts, bpf_map_batch_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.batch.map_fd = fd;\n\tattr.batch.in_batch = ptr_to_u64(in_batch);\n\tattr.batch.out_batch = ptr_to_u64(out_batch);\n\tattr.batch.keys = ptr_to_u64(keys);\n\tattr.batch.values = ptr_to_u64(values);\n\tattr.batch.count = *count;\n\tattr.batch.elem_flags  = OPTS_GET(opts, elem_flags, 0);\n\tattr.batch.flags = OPTS_GET(opts, flags, 0);\n\n\tret = sys_bpf(cmd, &attr, attr_sz);\n\t*count = attr.batch.count;\n\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_map_delete_batch(int fd, const void *keys, __u32 *count,\n\t\t\t const struct bpf_map_batch_opts *opts)\n{\n\treturn bpf_map_batch_common(BPF_MAP_DELETE_BATCH, fd, NULL,\n\t\t\t\t    NULL, (void *)keys, NULL, count, opts);\n}\n\nint bpf_map_lookup_batch(int fd, void *in_batch, void *out_batch, void *keys,\n\t\t\t void *values, __u32 *count,\n\t\t\t const struct bpf_map_batch_opts *opts)\n{\n\treturn bpf_map_batch_common(BPF_MAP_LOOKUP_BATCH, fd, in_batch,\n\t\t\t\t    out_batch, keys, values, count, opts);\n}\n\nint bpf_map_lookup_and_delete_batch(int fd, void *in_batch, void *out_batch,\n\t\t\t\t    void *keys, void *values, __u32 *count,\n\t\t\t\t    const struct bpf_map_batch_opts *opts)\n{\n\treturn bpf_map_batch_common(BPF_MAP_LOOKUP_AND_DELETE_BATCH,\n\t\t\t\t    fd, in_batch, out_batch, keys, values,\n\t\t\t\t    count, opts);\n}\n\nint bpf_map_update_batch(int fd, const void *keys, const void *values, __u32 *count,\n\t\t\t const struct bpf_map_batch_opts *opts)\n{\n\treturn bpf_map_batch_common(BPF_MAP_UPDATE_BATCH, fd, NULL, NULL,\n\t\t\t\t    (void *)keys, (void *)values, count, opts);\n}\n\nint bpf_obj_pin_opts(int fd, const char *pathname, const struct bpf_obj_pin_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, path_fd);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tif (!OPTS_VALID(opts, bpf_obj_pin_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.path_fd = OPTS_GET(opts, path_fd, 0);\n\tattr.pathname = ptr_to_u64((void *)pathname);\n\tattr.file_flags = OPTS_GET(opts, file_flags, 0);\n\tattr.bpf_fd = fd;\n\n\tret = sys_bpf(BPF_OBJ_PIN, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_obj_pin(int fd, const char *pathname)\n{\n\treturn bpf_obj_pin_opts(fd, pathname, NULL);\n}\n\nint bpf_obj_get(const char *pathname)\n{\n\treturn bpf_obj_get_opts(pathname, NULL);\n}\n\nint bpf_obj_get_opts(const char *pathname, const struct bpf_obj_get_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, path_fd);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tif (!OPTS_VALID(opts, bpf_obj_get_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.path_fd = OPTS_GET(opts, path_fd, 0);\n\tattr.pathname = ptr_to_u64((void *)pathname);\n\tattr.file_flags = OPTS_GET(opts, file_flags, 0);\n\n\tfd = sys_bpf_fd(BPF_OBJ_GET, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_prog_attach(int prog_fd, int target_fd, enum bpf_attach_type type,\n\t\t    unsigned int flags)\n{\n\tDECLARE_LIBBPF_OPTS(bpf_prog_attach_opts, opts,\n\t\t.flags = flags,\n\t);\n\n\treturn bpf_prog_attach_opts(prog_fd, target_fd, type, &opts);\n}\n\nint bpf_prog_attach_opts(int prog_fd, int target, enum bpf_attach_type type,\n\t\t\t const struct bpf_prog_attach_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, expected_revision);\n\t__u32 relative_id, flags;\n\tint ret, relative_fd;\n\tunion bpf_attr attr;\n\n\tif (!OPTS_VALID(opts, bpf_prog_attach_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\trelative_id = OPTS_GET(opts, relative_id, 0);\n\trelative_fd = OPTS_GET(opts, relative_fd, 0);\n\tflags = OPTS_GET(opts, flags, 0);\n\n\t \n\tif (relative_fd && relative_id)\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.target_fd\t\t= target;\n\tattr.attach_bpf_fd\t= prog_fd;\n\tattr.attach_type\t= type;\n\tattr.replace_bpf_fd\t= OPTS_GET(opts, replace_fd, 0);\n\tattr.expected_revision\t= OPTS_GET(opts, expected_revision, 0);\n\n\tif (relative_id) {\n\t\tattr.attach_flags = flags | BPF_F_ID;\n\t\tattr.relative_id  = relative_id;\n\t} else {\n\t\tattr.attach_flags = flags;\n\t\tattr.relative_fd  = relative_fd;\n\t}\n\n\tret = sys_bpf(BPF_PROG_ATTACH, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_prog_detach_opts(int prog_fd, int target, enum bpf_attach_type type,\n\t\t\t const struct bpf_prog_detach_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, expected_revision);\n\t__u32 relative_id, flags;\n\tint ret, relative_fd;\n\tunion bpf_attr attr;\n\n\tif (!OPTS_VALID(opts, bpf_prog_detach_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\trelative_id = OPTS_GET(opts, relative_id, 0);\n\trelative_fd = OPTS_GET(opts, relative_fd, 0);\n\tflags = OPTS_GET(opts, flags, 0);\n\n\t \n\tif (relative_fd && relative_id)\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.target_fd\t\t= target;\n\tattr.attach_bpf_fd\t= prog_fd;\n\tattr.attach_type\t= type;\n\tattr.expected_revision\t= OPTS_GET(opts, expected_revision, 0);\n\n\tif (relative_id) {\n\t\tattr.attach_flags = flags | BPF_F_ID;\n\t\tattr.relative_id  = relative_id;\n\t} else {\n\t\tattr.attach_flags = flags;\n\t\tattr.relative_fd  = relative_fd;\n\t}\n\n\tret = sys_bpf(BPF_PROG_DETACH, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_prog_detach(int target_fd, enum bpf_attach_type type)\n{\n\treturn bpf_prog_detach_opts(0, target_fd, type, NULL);\n}\n\nint bpf_prog_detach2(int prog_fd, int target_fd, enum bpf_attach_type type)\n{\n\treturn bpf_prog_detach_opts(prog_fd, target_fd, type, NULL);\n}\n\nint bpf_link_create(int prog_fd, int target_fd,\n\t\t    enum bpf_attach_type attach_type,\n\t\t    const struct bpf_link_create_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, link_create);\n\t__u32 target_btf_id, iter_info_len, relative_id;\n\tint fd, err, relative_fd;\n\tunion bpf_attr attr;\n\n\tif (!OPTS_VALID(opts, bpf_link_create_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\titer_info_len = OPTS_GET(opts, iter_info_len, 0);\n\ttarget_btf_id = OPTS_GET(opts, target_btf_id, 0);\n\n\t \n\tif (iter_info_len || target_btf_id) {\n\t\tif (iter_info_len && target_btf_id)\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tif (!OPTS_ZEROED(opts, target_btf_id))\n\t\t\treturn libbpf_err(-EINVAL);\n\t}\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.link_create.prog_fd = prog_fd;\n\tattr.link_create.target_fd = target_fd;\n\tattr.link_create.attach_type = attach_type;\n\tattr.link_create.flags = OPTS_GET(opts, flags, 0);\n\n\tif (target_btf_id) {\n\t\tattr.link_create.target_btf_id = target_btf_id;\n\t\tgoto proceed;\n\t}\n\n\tswitch (attach_type) {\n\tcase BPF_TRACE_ITER:\n\t\tattr.link_create.iter_info = ptr_to_u64(OPTS_GET(opts, iter_info, (void *)0));\n\t\tattr.link_create.iter_info_len = iter_info_len;\n\t\tbreak;\n\tcase BPF_PERF_EVENT:\n\t\tattr.link_create.perf_event.bpf_cookie = OPTS_GET(opts, perf_event.bpf_cookie, 0);\n\t\tif (!OPTS_ZEROED(opts, perf_event))\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tbreak;\n\tcase BPF_TRACE_KPROBE_MULTI:\n\t\tattr.link_create.kprobe_multi.flags = OPTS_GET(opts, kprobe_multi.flags, 0);\n\t\tattr.link_create.kprobe_multi.cnt = OPTS_GET(opts, kprobe_multi.cnt, 0);\n\t\tattr.link_create.kprobe_multi.syms = ptr_to_u64(OPTS_GET(opts, kprobe_multi.syms, 0));\n\t\tattr.link_create.kprobe_multi.addrs = ptr_to_u64(OPTS_GET(opts, kprobe_multi.addrs, 0));\n\t\tattr.link_create.kprobe_multi.cookies = ptr_to_u64(OPTS_GET(opts, kprobe_multi.cookies, 0));\n\t\tif (!OPTS_ZEROED(opts, kprobe_multi))\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tbreak;\n\tcase BPF_TRACE_UPROBE_MULTI:\n\t\tattr.link_create.uprobe_multi.flags = OPTS_GET(opts, uprobe_multi.flags, 0);\n\t\tattr.link_create.uprobe_multi.cnt = OPTS_GET(opts, uprobe_multi.cnt, 0);\n\t\tattr.link_create.uprobe_multi.path = ptr_to_u64(OPTS_GET(opts, uprobe_multi.path, 0));\n\t\tattr.link_create.uprobe_multi.offsets = ptr_to_u64(OPTS_GET(opts, uprobe_multi.offsets, 0));\n\t\tattr.link_create.uprobe_multi.ref_ctr_offsets = ptr_to_u64(OPTS_GET(opts, uprobe_multi.ref_ctr_offsets, 0));\n\t\tattr.link_create.uprobe_multi.cookies = ptr_to_u64(OPTS_GET(opts, uprobe_multi.cookies, 0));\n\t\tattr.link_create.uprobe_multi.pid = OPTS_GET(opts, uprobe_multi.pid, 0);\n\t\tif (!OPTS_ZEROED(opts, uprobe_multi))\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tbreak;\n\tcase BPF_TRACE_FENTRY:\n\tcase BPF_TRACE_FEXIT:\n\tcase BPF_MODIFY_RETURN:\n\tcase BPF_LSM_MAC:\n\t\tattr.link_create.tracing.cookie = OPTS_GET(opts, tracing.cookie, 0);\n\t\tif (!OPTS_ZEROED(opts, tracing))\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tbreak;\n\tcase BPF_NETFILTER:\n\t\tattr.link_create.netfilter.pf = OPTS_GET(opts, netfilter.pf, 0);\n\t\tattr.link_create.netfilter.hooknum = OPTS_GET(opts, netfilter.hooknum, 0);\n\t\tattr.link_create.netfilter.priority = OPTS_GET(opts, netfilter.priority, 0);\n\t\tattr.link_create.netfilter.flags = OPTS_GET(opts, netfilter.flags, 0);\n\t\tif (!OPTS_ZEROED(opts, netfilter))\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tbreak;\n\tcase BPF_TCX_INGRESS:\n\tcase BPF_TCX_EGRESS:\n\t\trelative_fd = OPTS_GET(opts, tcx.relative_fd, 0);\n\t\trelative_id = OPTS_GET(opts, tcx.relative_id, 0);\n\t\tif (relative_fd && relative_id)\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tif (relative_id) {\n\t\t\tattr.link_create.tcx.relative_id = relative_id;\n\t\t\tattr.link_create.flags |= BPF_F_ID;\n\t\t} else {\n\t\t\tattr.link_create.tcx.relative_fd = relative_fd;\n\t\t}\n\t\tattr.link_create.tcx.expected_revision = OPTS_GET(opts, tcx.expected_revision, 0);\n\t\tif (!OPTS_ZEROED(opts, tcx))\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tbreak;\n\tdefault:\n\t\tif (!OPTS_ZEROED(opts, flags))\n\t\t\treturn libbpf_err(-EINVAL);\n\t\tbreak;\n\t}\nproceed:\n\tfd = sys_bpf_fd(BPF_LINK_CREATE, &attr, attr_sz);\n\tif (fd >= 0)\n\t\treturn fd;\n\t \n\terr = -errno;\n\tif (err != -EINVAL)\n\t\treturn libbpf_err(err);\n\n\t \n\tif (attr.link_create.target_fd || attr.link_create.target_btf_id)\n\t\treturn libbpf_err(err);\n\tif (!OPTS_ZEROED(opts, sz))\n\t\treturn libbpf_err(err);\n\n\t \n\tswitch (attach_type) {\n\tcase BPF_TRACE_RAW_TP:\n\tcase BPF_LSM_MAC:\n\tcase BPF_TRACE_FENTRY:\n\tcase BPF_TRACE_FEXIT:\n\tcase BPF_MODIFY_RETURN:\n\t\treturn bpf_raw_tracepoint_open(NULL, prog_fd);\n\tdefault:\n\t\treturn libbpf_err(err);\n\t}\n}\n\nint bpf_link_detach(int link_fd)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, link_detach);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.link_detach.link_fd = link_fd;\n\n\tret = sys_bpf(BPF_LINK_DETACH, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_link_update(int link_fd, int new_prog_fd,\n\t\t    const struct bpf_link_update_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, link_update);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tif (!OPTS_VALID(opts, bpf_link_update_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tif (OPTS_GET(opts, old_prog_fd, 0) && OPTS_GET(opts, old_map_fd, 0))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.link_update.link_fd = link_fd;\n\tattr.link_update.new_prog_fd = new_prog_fd;\n\tattr.link_update.flags = OPTS_GET(opts, flags, 0);\n\tif (OPTS_GET(opts, old_prog_fd, 0))\n\t\tattr.link_update.old_prog_fd = OPTS_GET(opts, old_prog_fd, 0);\n\telse if (OPTS_GET(opts, old_map_fd, 0))\n\t\tattr.link_update.old_map_fd = OPTS_GET(opts, old_map_fd, 0);\n\n\tret = sys_bpf(BPF_LINK_UPDATE, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_iter_create(int link_fd)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, iter_create);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.iter_create.link_fd = link_fd;\n\n\tfd = sys_bpf_fd(BPF_ITER_CREATE, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_prog_query_opts(int target, enum bpf_attach_type type,\n\t\t\tstruct bpf_prog_query_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, query);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tif (!OPTS_VALID(opts, bpf_prog_query_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.query.target_fd\t\t= target;\n\tattr.query.attach_type\t\t= type;\n\tattr.query.query_flags\t\t= OPTS_GET(opts, query_flags, 0);\n\tattr.query.count\t\t= OPTS_GET(opts, count, 0);\n\tattr.query.prog_ids\t\t= ptr_to_u64(OPTS_GET(opts, prog_ids, NULL));\n\tattr.query.link_ids\t\t= ptr_to_u64(OPTS_GET(opts, link_ids, NULL));\n\tattr.query.prog_attach_flags\t= ptr_to_u64(OPTS_GET(opts, prog_attach_flags, NULL));\n\tattr.query.link_attach_flags\t= ptr_to_u64(OPTS_GET(opts, link_attach_flags, NULL));\n\n\tret = sys_bpf(BPF_PROG_QUERY, &attr, attr_sz);\n\n\tOPTS_SET(opts, attach_flags, attr.query.attach_flags);\n\tOPTS_SET(opts, revision, attr.query.revision);\n\tOPTS_SET(opts, count, attr.query.count);\n\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_prog_query(int target_fd, enum bpf_attach_type type, __u32 query_flags,\n\t\t   __u32 *attach_flags, __u32 *prog_ids, __u32 *prog_cnt)\n{\n\tLIBBPF_OPTS(bpf_prog_query_opts, opts);\n\tint ret;\n\n\topts.query_flags = query_flags;\n\topts.prog_ids = prog_ids;\n\topts.prog_cnt = *prog_cnt;\n\n\tret = bpf_prog_query_opts(target_fd, type, &opts);\n\n\tif (attach_flags)\n\t\t*attach_flags = opts.attach_flags;\n\t*prog_cnt = opts.prog_cnt;\n\n\treturn libbpf_err_errno(ret);\n}\n\nint bpf_prog_test_run_opts(int prog_fd, struct bpf_test_run_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, test);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tif (!OPTS_VALID(opts, bpf_test_run_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.test.prog_fd = prog_fd;\n\tattr.test.batch_size = OPTS_GET(opts, batch_size, 0);\n\tattr.test.cpu = OPTS_GET(opts, cpu, 0);\n\tattr.test.flags = OPTS_GET(opts, flags, 0);\n\tattr.test.repeat = OPTS_GET(opts, repeat, 0);\n\tattr.test.duration = OPTS_GET(opts, duration, 0);\n\tattr.test.ctx_size_in = OPTS_GET(opts, ctx_size_in, 0);\n\tattr.test.ctx_size_out = OPTS_GET(opts, ctx_size_out, 0);\n\tattr.test.data_size_in = OPTS_GET(opts, data_size_in, 0);\n\tattr.test.data_size_out = OPTS_GET(opts, data_size_out, 0);\n\tattr.test.ctx_in = ptr_to_u64(OPTS_GET(opts, ctx_in, NULL));\n\tattr.test.ctx_out = ptr_to_u64(OPTS_GET(opts, ctx_out, NULL));\n\tattr.test.data_in = ptr_to_u64(OPTS_GET(opts, data_in, NULL));\n\tattr.test.data_out = ptr_to_u64(OPTS_GET(opts, data_out, NULL));\n\n\tret = sys_bpf(BPF_PROG_TEST_RUN, &attr, attr_sz);\n\n\tOPTS_SET(opts, data_size_out, attr.test.data_size_out);\n\tOPTS_SET(opts, ctx_size_out, attr.test.ctx_size_out);\n\tOPTS_SET(opts, duration, attr.test.duration);\n\tOPTS_SET(opts, retval, attr.test.retval);\n\n\treturn libbpf_err_errno(ret);\n}\n\nstatic int bpf_obj_get_next_id(__u32 start_id, __u32 *next_id, int cmd)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, open_flags);\n\tunion bpf_attr attr;\n\tint err;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.start_id = start_id;\n\n\terr = sys_bpf(cmd, &attr, attr_sz);\n\tif (!err)\n\t\t*next_id = attr.next_id;\n\n\treturn libbpf_err_errno(err);\n}\n\nint bpf_prog_get_next_id(__u32 start_id, __u32 *next_id)\n{\n\treturn bpf_obj_get_next_id(start_id, next_id, BPF_PROG_GET_NEXT_ID);\n}\n\nint bpf_map_get_next_id(__u32 start_id, __u32 *next_id)\n{\n\treturn bpf_obj_get_next_id(start_id, next_id, BPF_MAP_GET_NEXT_ID);\n}\n\nint bpf_btf_get_next_id(__u32 start_id, __u32 *next_id)\n{\n\treturn bpf_obj_get_next_id(start_id, next_id, BPF_BTF_GET_NEXT_ID);\n}\n\nint bpf_link_get_next_id(__u32 start_id, __u32 *next_id)\n{\n\treturn bpf_obj_get_next_id(start_id, next_id, BPF_LINK_GET_NEXT_ID);\n}\n\nint bpf_prog_get_fd_by_id_opts(__u32 id,\n\t\t\t       const struct bpf_get_fd_by_id_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, open_flags);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tif (!OPTS_VALID(opts, bpf_get_fd_by_id_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.prog_id = id;\n\tattr.open_flags = OPTS_GET(opts, open_flags, 0);\n\n\tfd = sys_bpf_fd(BPF_PROG_GET_FD_BY_ID, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_prog_get_fd_by_id(__u32 id)\n{\n\treturn bpf_prog_get_fd_by_id_opts(id, NULL);\n}\n\nint bpf_map_get_fd_by_id_opts(__u32 id,\n\t\t\t      const struct bpf_get_fd_by_id_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, open_flags);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tif (!OPTS_VALID(opts, bpf_get_fd_by_id_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.map_id = id;\n\tattr.open_flags = OPTS_GET(opts, open_flags, 0);\n\n\tfd = sys_bpf_fd(BPF_MAP_GET_FD_BY_ID, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_map_get_fd_by_id(__u32 id)\n{\n\treturn bpf_map_get_fd_by_id_opts(id, NULL);\n}\n\nint bpf_btf_get_fd_by_id_opts(__u32 id,\n\t\t\t      const struct bpf_get_fd_by_id_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, open_flags);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tif (!OPTS_VALID(opts, bpf_get_fd_by_id_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.btf_id = id;\n\tattr.open_flags = OPTS_GET(opts, open_flags, 0);\n\n\tfd = sys_bpf_fd(BPF_BTF_GET_FD_BY_ID, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_btf_get_fd_by_id(__u32 id)\n{\n\treturn bpf_btf_get_fd_by_id_opts(id, NULL);\n}\n\nint bpf_link_get_fd_by_id_opts(__u32 id,\n\t\t\t       const struct bpf_get_fd_by_id_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, open_flags);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tif (!OPTS_VALID(opts, bpf_get_fd_by_id_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.link_id = id;\n\tattr.open_flags = OPTS_GET(opts, open_flags, 0);\n\n\tfd = sys_bpf_fd(BPF_LINK_GET_FD_BY_ID, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_link_get_fd_by_id(__u32 id)\n{\n\treturn bpf_link_get_fd_by_id_opts(id, NULL);\n}\n\nint bpf_obj_get_info_by_fd(int bpf_fd, void *info, __u32 *info_len)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, info);\n\tunion bpf_attr attr;\n\tint err;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.info.bpf_fd = bpf_fd;\n\tattr.info.info_len = *info_len;\n\tattr.info.info = ptr_to_u64(info);\n\n\terr = sys_bpf(BPF_OBJ_GET_INFO_BY_FD, &attr, attr_sz);\n\tif (!err)\n\t\t*info_len = attr.info.info_len;\n\treturn libbpf_err_errno(err);\n}\n\nint bpf_prog_get_info_by_fd(int prog_fd, struct bpf_prog_info *info, __u32 *info_len)\n{\n\treturn bpf_obj_get_info_by_fd(prog_fd, info, info_len);\n}\n\nint bpf_map_get_info_by_fd(int map_fd, struct bpf_map_info *info, __u32 *info_len)\n{\n\treturn bpf_obj_get_info_by_fd(map_fd, info, info_len);\n}\n\nint bpf_btf_get_info_by_fd(int btf_fd, struct bpf_btf_info *info, __u32 *info_len)\n{\n\treturn bpf_obj_get_info_by_fd(btf_fd, info, info_len);\n}\n\nint bpf_link_get_info_by_fd(int link_fd, struct bpf_link_info *info, __u32 *info_len)\n{\n\treturn bpf_obj_get_info_by_fd(link_fd, info, info_len);\n}\n\nint bpf_raw_tracepoint_open(const char *name, int prog_fd)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, raw_tracepoint);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.raw_tracepoint.name = ptr_to_u64(name);\n\tattr.raw_tracepoint.prog_fd = prog_fd;\n\n\tfd = sys_bpf_fd(BPF_RAW_TRACEPOINT_OPEN, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_btf_load(const void *btf_data, size_t btf_size, struct bpf_btf_load_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, btf_log_true_size);\n\tunion bpf_attr attr;\n\tchar *log_buf;\n\tsize_t log_size;\n\t__u32 log_level;\n\tint fd;\n\n\tbump_rlimit_memlock();\n\n\tmemset(&attr, 0, attr_sz);\n\n\tif (!OPTS_VALID(opts, bpf_btf_load_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tlog_buf = OPTS_GET(opts, log_buf, NULL);\n\tlog_size = OPTS_GET(opts, log_size, 0);\n\tlog_level = OPTS_GET(opts, log_level, 0);\n\n\tif (log_size > UINT_MAX)\n\t\treturn libbpf_err(-EINVAL);\n\tif (log_size && !log_buf)\n\t\treturn libbpf_err(-EINVAL);\n\n\tattr.btf = ptr_to_u64(btf_data);\n\tattr.btf_size = btf_size;\n\t \n\tif (log_level) {\n\t\tattr.btf_log_buf = ptr_to_u64(log_buf);\n\t\tattr.btf_log_size = (__u32)log_size;\n\t\tattr.btf_log_level = log_level;\n\t}\n\n\tfd = sys_bpf_fd(BPF_BTF_LOAD, &attr, attr_sz);\n\tif (fd < 0 && log_buf && log_level == 0) {\n\t\tattr.btf_log_buf = ptr_to_u64(log_buf);\n\t\tattr.btf_log_size = (__u32)log_size;\n\t\tattr.btf_log_level = 1;\n\t\tfd = sys_bpf_fd(BPF_BTF_LOAD, &attr, attr_sz);\n\t}\n\n\tOPTS_SET(opts, log_true_size, attr.btf_log_true_size);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_task_fd_query(int pid, int fd, __u32 flags, char *buf, __u32 *buf_len,\n\t\t      __u32 *prog_id, __u32 *fd_type, __u64 *probe_offset,\n\t\t      __u64 *probe_addr)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, task_fd_query);\n\tunion bpf_attr attr;\n\tint err;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.task_fd_query.pid = pid;\n\tattr.task_fd_query.fd = fd;\n\tattr.task_fd_query.flags = flags;\n\tattr.task_fd_query.buf = ptr_to_u64(buf);\n\tattr.task_fd_query.buf_len = *buf_len;\n\n\terr = sys_bpf(BPF_TASK_FD_QUERY, &attr, attr_sz);\n\n\t*buf_len = attr.task_fd_query.buf_len;\n\t*prog_id = attr.task_fd_query.prog_id;\n\t*fd_type = attr.task_fd_query.fd_type;\n\t*probe_offset = attr.task_fd_query.probe_offset;\n\t*probe_addr = attr.task_fd_query.probe_addr;\n\n\treturn libbpf_err_errno(err);\n}\n\nint bpf_enable_stats(enum bpf_stats_type type)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, enable_stats);\n\tunion bpf_attr attr;\n\tint fd;\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.enable_stats.type = type;\n\n\tfd = sys_bpf_fd(BPF_ENABLE_STATS, &attr, attr_sz);\n\treturn libbpf_err_errno(fd);\n}\n\nint bpf_prog_bind_map(int prog_fd, int map_fd,\n\t\t      const struct bpf_prog_bind_opts *opts)\n{\n\tconst size_t attr_sz = offsetofend(union bpf_attr, prog_bind_map);\n\tunion bpf_attr attr;\n\tint ret;\n\n\tif (!OPTS_VALID(opts, bpf_prog_bind_opts))\n\t\treturn libbpf_err(-EINVAL);\n\n\tmemset(&attr, 0, attr_sz);\n\tattr.prog_bind_map.prog_fd = prog_fd;\n\tattr.prog_bind_map.map_fd = map_fd;\n\tattr.prog_bind_map.flags = OPTS_GET(opts, flags, 0);\n\n\tret = sys_bpf(BPF_PROG_BIND_MAP, &attr, attr_sz);\n\treturn libbpf_err_errno(ret);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}