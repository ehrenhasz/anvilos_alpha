{
  "module_name": "evsel.c",
  "hash_id": "523908d1958acc44175f38ea8db039868ad79316890d2c68b4e71aa086d9727c",
  "original_prompt": "Ingested from linux-6.6.14/tools/lib/perf/evsel.c",
  "human_readable_source": "\n#include <errno.h>\n#include <unistd.h>\n#include <sys/syscall.h>\n#include <perf/evsel.h>\n#include <perf/cpumap.h>\n#include <perf/threadmap.h>\n#include <linux/list.h>\n#include <internal/evsel.h>\n#include <linux/zalloc.h>\n#include <stdlib.h>\n#include <internal/xyarray.h>\n#include <internal/cpumap.h>\n#include <internal/mmap.h>\n#include <internal/threadmap.h>\n#include <internal/lib.h>\n#include <linux/string.h>\n#include <sys/ioctl.h>\n#include <sys/mman.h>\n#include <asm/bug.h>\n\nvoid perf_evsel__init(struct perf_evsel *evsel, struct perf_event_attr *attr,\n\t\t      int idx)\n{\n\tINIT_LIST_HEAD(&evsel->node);\n\tevsel->attr = *attr;\n\tevsel->idx  = idx;\n\tevsel->leader = evsel;\n}\n\nstruct perf_evsel *perf_evsel__new(struct perf_event_attr *attr)\n{\n\tstruct perf_evsel *evsel = zalloc(sizeof(*evsel));\n\n\tif (evsel != NULL)\n\t\tperf_evsel__init(evsel, attr, 0);\n\n\treturn evsel;\n}\n\nvoid perf_evsel__delete(struct perf_evsel *evsel)\n{\n\tfree(evsel);\n}\n\n#define FD(_evsel, _cpu_map_idx, _thread)\t\t\t\t\\\n\t((int *)xyarray__entry(_evsel->fd, _cpu_map_idx, _thread))\n#define MMAP(_evsel, _cpu_map_idx, _thread)\t\t\t\t\\\n\t(_evsel->mmap ? ((struct perf_mmap *) xyarray__entry(_evsel->mmap, _cpu_map_idx, _thread)) \\\n\t\t      : NULL)\n\nint perf_evsel__alloc_fd(struct perf_evsel *evsel, int ncpus, int nthreads)\n{\n\tevsel->fd = xyarray__new(ncpus, nthreads, sizeof(int));\n\n\tif (evsel->fd) {\n\t\tint idx, thread;\n\n\t\tfor (idx = 0; idx < ncpus; idx++) {\n\t\t\tfor (thread = 0; thread < nthreads; thread++) {\n\t\t\t\tint *fd = FD(evsel, idx, thread);\n\n\t\t\t\tif (fd)\n\t\t\t\t\t*fd = -1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn evsel->fd != NULL ? 0 : -ENOMEM;\n}\n\nstatic int perf_evsel__alloc_mmap(struct perf_evsel *evsel, int ncpus, int nthreads)\n{\n\tevsel->mmap = xyarray__new(ncpus, nthreads, sizeof(struct perf_mmap));\n\n\treturn evsel->mmap != NULL ? 0 : -ENOMEM;\n}\n\nstatic int\nsys_perf_event_open(struct perf_event_attr *attr,\n\t\t    pid_t pid, struct perf_cpu cpu, int group_fd,\n\t\t    unsigned long flags)\n{\n\treturn syscall(__NR_perf_event_open, attr, pid, cpu.cpu, group_fd, flags);\n}\n\nstatic int get_group_fd(struct perf_evsel *evsel, int cpu_map_idx, int thread, int *group_fd)\n{\n\tstruct perf_evsel *leader = evsel->leader;\n\tint *fd;\n\n\tif (evsel == leader) {\n\t\t*group_fd = -1;\n\t\treturn 0;\n\t}\n\n\t \n\tif (!leader->fd)\n\t\treturn -ENOTCONN;\n\n\tfd = FD(leader, cpu_map_idx, thread);\n\tif (fd == NULL || *fd == -1)\n\t\treturn -EBADF;\n\n\t*group_fd = *fd;\n\n\treturn 0;\n}\n\nint perf_evsel__open(struct perf_evsel *evsel, struct perf_cpu_map *cpus,\n\t\t     struct perf_thread_map *threads)\n{\n\tstruct perf_cpu cpu;\n\tint idx, thread, err = 0;\n\n\tif (cpus == NULL) {\n\t\tstatic struct perf_cpu_map *empty_cpu_map;\n\n\t\tif (empty_cpu_map == NULL) {\n\t\t\tempty_cpu_map = perf_cpu_map__dummy_new();\n\t\t\tif (empty_cpu_map == NULL)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tcpus = empty_cpu_map;\n\t}\n\n\tif (threads == NULL) {\n\t\tstatic struct perf_thread_map *empty_thread_map;\n\n\t\tif (empty_thread_map == NULL) {\n\t\t\tempty_thread_map = perf_thread_map__new_dummy();\n\t\t\tif (empty_thread_map == NULL)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tthreads = empty_thread_map;\n\t}\n\n\tif (evsel->fd == NULL &&\n\t    perf_evsel__alloc_fd(evsel, perf_cpu_map__nr(cpus), threads->nr) < 0)\n\t\treturn -ENOMEM;\n\n\tperf_cpu_map__for_each_cpu(cpu, idx, cpus) {\n\t\tfor (thread = 0; thread < threads->nr; thread++) {\n\t\t\tint fd, group_fd, *evsel_fd;\n\n\t\t\tevsel_fd = FD(evsel, idx, thread);\n\t\t\tif (evsel_fd == NULL) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\terr = get_group_fd(evsel, idx, thread, &group_fd);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\n\t\t\tfd = sys_perf_event_open(&evsel->attr,\n\t\t\t\t\t\t threads->map[thread].pid,\n\t\t\t\t\t\t cpu, group_fd, 0);\n\n\t\t\tif (fd < 0) {\n\t\t\t\terr = -errno;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t*evsel_fd = fd;\n\t\t}\n\t}\nout:\n\tif (err)\n\t\tperf_evsel__close(evsel);\n\n\treturn err;\n}\n\nstatic void perf_evsel__close_fd_cpu(struct perf_evsel *evsel, int cpu_map_idx)\n{\n\tint thread;\n\n\tfor (thread = 0; thread < xyarray__max_y(evsel->fd); ++thread) {\n\t\tint *fd = FD(evsel, cpu_map_idx, thread);\n\n\t\tif (fd && *fd >= 0) {\n\t\t\tclose(*fd);\n\t\t\t*fd = -1;\n\t\t}\n\t}\n}\n\nvoid perf_evsel__close_fd(struct perf_evsel *evsel)\n{\n\tfor (int idx = 0; idx < xyarray__max_x(evsel->fd); idx++)\n\t\tperf_evsel__close_fd_cpu(evsel, idx);\n}\n\nvoid perf_evsel__free_fd(struct perf_evsel *evsel)\n{\n\txyarray__delete(evsel->fd);\n\tevsel->fd = NULL;\n}\n\nvoid perf_evsel__close(struct perf_evsel *evsel)\n{\n\tif (evsel->fd == NULL)\n\t\treturn;\n\n\tperf_evsel__close_fd(evsel);\n\tperf_evsel__free_fd(evsel);\n}\n\nvoid perf_evsel__close_cpu(struct perf_evsel *evsel, int cpu_map_idx)\n{\n\tif (evsel->fd == NULL)\n\t\treturn;\n\n\tperf_evsel__close_fd_cpu(evsel, cpu_map_idx);\n}\n\nvoid perf_evsel__munmap(struct perf_evsel *evsel)\n{\n\tint idx, thread;\n\n\tif (evsel->fd == NULL || evsel->mmap == NULL)\n\t\treturn;\n\n\tfor (idx = 0; idx < xyarray__max_x(evsel->fd); idx++) {\n\t\tfor (thread = 0; thread < xyarray__max_y(evsel->fd); thread++) {\n\t\t\tint *fd = FD(evsel, idx, thread);\n\n\t\t\tif (fd == NULL || *fd < 0)\n\t\t\t\tcontinue;\n\n\t\t\tperf_mmap__munmap(MMAP(evsel, idx, thread));\n\t\t}\n\t}\n\n\txyarray__delete(evsel->mmap);\n\tevsel->mmap = NULL;\n}\n\nint perf_evsel__mmap(struct perf_evsel *evsel, int pages)\n{\n\tint ret, idx, thread;\n\tstruct perf_mmap_param mp = {\n\t\t.prot = PROT_READ | PROT_WRITE,\n\t\t.mask = (pages * page_size) - 1,\n\t};\n\n\tif (evsel->fd == NULL || evsel->mmap)\n\t\treturn -EINVAL;\n\n\tif (perf_evsel__alloc_mmap(evsel, xyarray__max_x(evsel->fd), xyarray__max_y(evsel->fd)) < 0)\n\t\treturn -ENOMEM;\n\n\tfor (idx = 0; idx < xyarray__max_x(evsel->fd); idx++) {\n\t\tfor (thread = 0; thread < xyarray__max_y(evsel->fd); thread++) {\n\t\t\tint *fd = FD(evsel, idx, thread);\n\t\t\tstruct perf_mmap *map;\n\t\t\tstruct perf_cpu cpu = perf_cpu_map__cpu(evsel->cpus, idx);\n\n\t\t\tif (fd == NULL || *fd < 0)\n\t\t\t\tcontinue;\n\n\t\t\tmap = MMAP(evsel, idx, thread);\n\t\t\tperf_mmap__init(map, NULL, false, NULL);\n\n\t\t\tret = perf_mmap__mmap(map, &mp, *fd, cpu);\n\t\t\tif (ret) {\n\t\t\t\tperf_evsel__munmap(evsel);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nvoid *perf_evsel__mmap_base(struct perf_evsel *evsel, int cpu_map_idx, int thread)\n{\n\tint *fd = FD(evsel, cpu_map_idx, thread);\n\n\tif (fd == NULL || *fd < 0 || MMAP(evsel, cpu_map_idx, thread) == NULL)\n\t\treturn NULL;\n\n\treturn MMAP(evsel, cpu_map_idx, thread)->base;\n}\n\nint perf_evsel__read_size(struct perf_evsel *evsel)\n{\n\tu64 read_format = evsel->attr.read_format;\n\tint entry = sizeof(u64);  \n\tint size = 0;\n\tint nr = 1;\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)\n\t\tsize += sizeof(u64);\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)\n\t\tsize += sizeof(u64);\n\n\tif (read_format & PERF_FORMAT_ID)\n\t\tentry += sizeof(u64);\n\n\tif (read_format & PERF_FORMAT_LOST)\n\t\tentry += sizeof(u64);\n\n\tif (read_format & PERF_FORMAT_GROUP) {\n\t\tnr = evsel->nr_members;\n\t\tsize += sizeof(u64);\n\t}\n\n\tsize += entry * nr;\n\treturn size;\n}\n\n \nstatic int perf_evsel__read_group(struct perf_evsel *evsel, int cpu_map_idx,\n\t\t\t\t  int thread, struct perf_counts_values *count)\n{\n\tsize_t size = perf_evsel__read_size(evsel);\n\tint *fd = FD(evsel, cpu_map_idx, thread);\n\tu64 read_format = evsel->attr.read_format;\n\tu64 *data;\n\tint idx = 1;\n\n\tif (fd == NULL || *fd < 0)\n\t\treturn -EINVAL;\n\n\tdata = calloc(1, size);\n\tif (data == NULL)\n\t\treturn -ENOMEM;\n\n\tif (readn(*fd, data, size) <= 0) {\n\t\tfree(data);\n\t\treturn -errno;\n\t}\n\n\t \n\tif (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)\n\t\tcount->ena = data[idx++];\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)\n\t\tcount->run = data[idx++];\n\n\t \n\tcount->val = data[idx++];\n\tif (read_format & PERF_FORMAT_ID)\n\t\tcount->id = data[idx++];\n\tif (read_format & PERF_FORMAT_LOST)\n\t\tcount->lost = data[idx++];\n\n\tfree(data);\n\treturn 0;\n}\n\n \nstatic void perf_evsel__adjust_values(struct perf_evsel *evsel, u64 *buf,\n\t\t\t\t      struct perf_counts_values *count)\n{\n\tu64 read_format = evsel->attr.read_format;\n\tint n = 0;\n\n\tcount->val = buf[n++];\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)\n\t\tcount->ena = buf[n++];\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)\n\t\tcount->run = buf[n++];\n\n\tif (read_format & PERF_FORMAT_ID)\n\t\tcount->id = buf[n++];\n\n\tif (read_format & PERF_FORMAT_LOST)\n\t\tcount->lost = buf[n++];\n}\n\nint perf_evsel__read(struct perf_evsel *evsel, int cpu_map_idx, int thread,\n\t\t     struct perf_counts_values *count)\n{\n\tsize_t size = perf_evsel__read_size(evsel);\n\tint *fd = FD(evsel, cpu_map_idx, thread);\n\tu64 read_format = evsel->attr.read_format;\n\tstruct perf_counts_values buf;\n\n\tmemset(count, 0, sizeof(*count));\n\n\tif (fd == NULL || *fd < 0)\n\t\treturn -EINVAL;\n\n\tif (read_format & PERF_FORMAT_GROUP)\n\t\treturn perf_evsel__read_group(evsel, cpu_map_idx, thread, count);\n\n\tif (MMAP(evsel, cpu_map_idx, thread) &&\n\t    !(read_format & (PERF_FORMAT_ID | PERF_FORMAT_LOST)) &&\n\t    !perf_mmap__read_self(MMAP(evsel, cpu_map_idx, thread), count))\n\t\treturn 0;\n\n\tif (readn(*fd, buf.values, size) <= 0)\n\t\treturn -errno;\n\n\tperf_evsel__adjust_values(evsel, buf.values, count);\n\treturn 0;\n}\n\nstatic int perf_evsel__ioctl(struct perf_evsel *evsel, int ioc, void *arg,\n\t\t\t     int cpu_map_idx, int thread)\n{\n\tint *fd = FD(evsel, cpu_map_idx, thread);\n\n\tif (fd == NULL || *fd < 0)\n\t\treturn -1;\n\n\treturn ioctl(*fd, ioc, arg);\n}\n\nstatic int perf_evsel__run_ioctl(struct perf_evsel *evsel,\n\t\t\t\t int ioc,  void *arg,\n\t\t\t\t int cpu_map_idx)\n{\n\tint thread;\n\n\tfor (thread = 0; thread < xyarray__max_y(evsel->fd); thread++) {\n\t\tint err = perf_evsel__ioctl(evsel, ioc, arg, cpu_map_idx, thread);\n\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nint perf_evsel__enable_cpu(struct perf_evsel *evsel, int cpu_map_idx)\n{\n\treturn perf_evsel__run_ioctl(evsel, PERF_EVENT_IOC_ENABLE, NULL, cpu_map_idx);\n}\n\nint perf_evsel__enable_thread(struct perf_evsel *evsel, int thread)\n{\n\tstruct perf_cpu cpu __maybe_unused;\n\tint idx;\n\tint err;\n\n\tperf_cpu_map__for_each_cpu(cpu, idx, evsel->cpus) {\n\t\terr = perf_evsel__ioctl(evsel, PERF_EVENT_IOC_ENABLE, NULL, idx, thread);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nint perf_evsel__enable(struct perf_evsel *evsel)\n{\n\tint i;\n\tint err = 0;\n\n\tfor (i = 0; i < xyarray__max_x(evsel->fd) && !err; i++)\n\t\terr = perf_evsel__run_ioctl(evsel, PERF_EVENT_IOC_ENABLE, NULL, i);\n\treturn err;\n}\n\nint perf_evsel__disable_cpu(struct perf_evsel *evsel, int cpu_map_idx)\n{\n\treturn perf_evsel__run_ioctl(evsel, PERF_EVENT_IOC_DISABLE, NULL, cpu_map_idx);\n}\n\nint perf_evsel__disable(struct perf_evsel *evsel)\n{\n\tint i;\n\tint err = 0;\n\n\tfor (i = 0; i < xyarray__max_x(evsel->fd) && !err; i++)\n\t\terr = perf_evsel__run_ioctl(evsel, PERF_EVENT_IOC_DISABLE, NULL, i);\n\treturn err;\n}\n\nint perf_evsel__apply_filter(struct perf_evsel *evsel, const char *filter)\n{\n\tint err = 0, i;\n\n\tfor (i = 0; i < perf_cpu_map__nr(evsel->cpus) && !err; i++)\n\t\terr = perf_evsel__run_ioctl(evsel,\n\t\t\t\t     PERF_EVENT_IOC_SET_FILTER,\n\t\t\t\t     (void *)filter, i);\n\treturn err;\n}\n\nstruct perf_cpu_map *perf_evsel__cpus(struct perf_evsel *evsel)\n{\n\treturn evsel->cpus;\n}\n\nstruct perf_thread_map *perf_evsel__threads(struct perf_evsel *evsel)\n{\n\treturn evsel->threads;\n}\n\nstruct perf_event_attr *perf_evsel__attr(struct perf_evsel *evsel)\n{\n\treturn &evsel->attr;\n}\n\nint perf_evsel__alloc_id(struct perf_evsel *evsel, int ncpus, int nthreads)\n{\n\tif (ncpus == 0 || nthreads == 0)\n\t\treturn 0;\n\n\tevsel->sample_id = xyarray__new(ncpus, nthreads, sizeof(struct perf_sample_id));\n\tif (evsel->sample_id == NULL)\n\t\treturn -ENOMEM;\n\n\tevsel->id = zalloc(ncpus * nthreads * sizeof(u64));\n\tif (evsel->id == NULL) {\n\t\txyarray__delete(evsel->sample_id);\n\t\tevsel->sample_id = NULL;\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nvoid perf_evsel__free_id(struct perf_evsel *evsel)\n{\n\txyarray__delete(evsel->sample_id);\n\tevsel->sample_id = NULL;\n\tzfree(&evsel->id);\n\tevsel->ids = 0;\n}\n\nvoid perf_counts_values__scale(struct perf_counts_values *count,\n\t\t\t       bool scale, __s8 *pscaled)\n{\n\ts8 scaled = 0;\n\n\tif (scale) {\n\t\tif (count->run == 0) {\n\t\t\tscaled = -1;\n\t\t\tcount->val = 0;\n\t\t} else if (count->run < count->ena) {\n\t\t\tscaled = 1;\n\t\t\tcount->val = (u64)((double)count->val * count->ena / count->run);\n\t\t}\n\t}\n\n\tif (pscaled)\n\t\t*pscaled = scaled;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}