{
  "module_name": "user_ringbuf.c",
  "hash_id": "84b54e0ce5962d1f775fc846a1efde7cef2cfbff3c9aaa171217ef31ce01d4e8",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/prog_tests/user_ringbuf.c",
  "human_readable_source": "\n \n\n#define _GNU_SOURCE\n#include <linux/compiler.h>\n#include <linux/ring_buffer.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/mman.h>\n#include <sys/syscall.h>\n#include <sys/sysinfo.h>\n#include <test_progs.h>\n#include <uapi/linux/bpf.h>\n#include <unistd.h>\n\n#include \"user_ringbuf_fail.skel.h\"\n#include \"user_ringbuf_success.skel.h\"\n\n#include \"../progs/test_user_ringbuf.h\"\n\nstatic const long c_sample_size = sizeof(struct sample) + BPF_RINGBUF_HDR_SZ;\nstatic const long c_ringbuf_size = 1 << 12;  \nstatic const long c_max_entries = c_ringbuf_size / c_sample_size;\n\nstatic void drain_current_samples(void)\n{\n\tsyscall(__NR_getpgid);\n}\n\nstatic int write_samples(struct user_ring_buffer *ringbuf, uint32_t num_samples)\n{\n\tint i, err = 0;\n\n\t \n\tfor (i = 0; i < num_samples; i++) {\n\t\tstruct sample *entry;\n\t\tint read;\n\n\t\tentry = user_ring_buffer__reserve(ringbuf, sizeof(*entry));\n\t\tif (!entry) {\n\t\t\terr = -errno;\n\t\t\tgoto done;\n\t\t}\n\n\t\tentry->pid = getpid();\n\t\tentry->seq = i;\n\t\tentry->value = i * i;\n\n\t\tread = snprintf(entry->comm, sizeof(entry->comm), \"%u\", i);\n\t\tif (read <= 0) {\n\t\t\t \n\t\t\tASSERT_GT(read, 0, \"snprintf_comm\");\n\t\t\terr = read;\n\t\t\tuser_ring_buffer__discard(ringbuf, entry);\n\t\t\tgoto done;\n\t\t}\n\n\t\tuser_ring_buffer__submit(ringbuf, entry);\n\t}\n\ndone:\n\tdrain_current_samples();\n\n\treturn err;\n}\n\nstatic struct user_ringbuf_success *open_load_ringbuf_skel(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tint err;\n\n\tskel = user_ringbuf_success__open();\n\tif (!ASSERT_OK_PTR(skel, \"skel_open\"))\n\t\treturn NULL;\n\n\terr = bpf_map__set_max_entries(skel->maps.user_ringbuf, c_ringbuf_size);\n\tif (!ASSERT_OK(err, \"set_max_entries\"))\n\t\tgoto cleanup;\n\n\terr = bpf_map__set_max_entries(skel->maps.kernel_ringbuf, c_ringbuf_size);\n\tif (!ASSERT_OK(err, \"set_max_entries\"))\n\t\tgoto cleanup;\n\n\terr = user_ringbuf_success__load(skel);\n\tif (!ASSERT_OK(err, \"skel_load\"))\n\t\tgoto cleanup;\n\n\treturn skel;\n\ncleanup:\n\tuser_ringbuf_success__destroy(skel);\n\treturn NULL;\n}\n\nstatic void test_user_ringbuf_mappings(void)\n{\n\tint err, rb_fd;\n\tint page_size = getpagesize();\n\tvoid *mmap_ptr;\n\tstruct user_ringbuf_success *skel;\n\n\tskel = open_load_ringbuf_skel();\n\tif (!skel)\n\t\treturn;\n\n\trb_fd = bpf_map__fd(skel->maps.user_ringbuf);\n\t \n\tmmap_ptr = mmap(NULL, page_size, PROT_READ, MAP_SHARED, rb_fd, 0);\n\tASSERT_OK_PTR(mmap_ptr, \"ro_cons_pos\");\n\tASSERT_ERR(mprotect(mmap_ptr, page_size, PROT_WRITE), \"write_cons_pos_protect\");\n\tASSERT_ERR(mprotect(mmap_ptr, page_size, PROT_EXEC), \"exec_cons_pos_protect\");\n\tASSERT_ERR_PTR(mremap(mmap_ptr, 0, 4 * page_size, MREMAP_MAYMOVE), \"wr_prod_pos\");\n\terr = -errno;\n\tASSERT_ERR(err, \"wr_prod_pos_err\");\n\tASSERT_OK(munmap(mmap_ptr, page_size), \"unmap_ro_cons\");\n\n\t \n\tmmap_ptr = mmap(NULL, page_size, PROT_READ | PROT_WRITE, MAP_SHARED,\n\t\t\trb_fd, page_size);\n\tASSERT_OK_PTR(mmap_ptr, \"rw_prod_pos\");\n\tASSERT_ERR(mprotect(mmap_ptr, page_size, PROT_EXEC), \"exec_prod_pos_protect\");\n\terr = -errno;\n\tASSERT_ERR(err, \"wr_prod_pos_err\");\n\tASSERT_OK(munmap(mmap_ptr, page_size), \"unmap_rw_prod\");\n\n\t \n\tmmap_ptr = mmap(NULL, page_size, PROT_WRITE, MAP_SHARED, rb_fd,\n\t\t\t2 * page_size);\n\tASSERT_OK_PTR(mmap_ptr, \"rw_data\");\n\tASSERT_ERR(mprotect(mmap_ptr, page_size, PROT_EXEC), \"exec_data_protect\");\n\terr = -errno;\n\tASSERT_ERR(err, \"exec_data_err\");\n\tASSERT_OK(munmap(mmap_ptr, page_size), \"unmap_rw_data\");\n\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic int load_skel_create_ringbufs(struct user_ringbuf_success **skel_out,\n\t\t\t\t     struct ring_buffer **kern_ringbuf_out,\n\t\t\t\t     ring_buffer_sample_fn callback,\n\t\t\t\t     struct user_ring_buffer **user_ringbuf_out)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct ring_buffer *kern_ringbuf = NULL;\n\tstruct user_ring_buffer *user_ringbuf = NULL;\n\tint err = -ENOMEM, rb_fd;\n\n\tskel = open_load_ringbuf_skel();\n\tif (!skel)\n\t\treturn err;\n\n\t \n\tskel->bss->pid = getpid();\n\n\tif (kern_ringbuf_out) {\n\t\trb_fd = bpf_map__fd(skel->maps.kernel_ringbuf);\n\t\tkern_ringbuf = ring_buffer__new(rb_fd, callback, skel, NULL);\n\t\tif (!ASSERT_OK_PTR(kern_ringbuf, \"kern_ringbuf_create\"))\n\t\t\tgoto cleanup;\n\n\t\t*kern_ringbuf_out = kern_ringbuf;\n\t}\n\n\tif (user_ringbuf_out) {\n\t\trb_fd = bpf_map__fd(skel->maps.user_ringbuf);\n\t\tuser_ringbuf = user_ring_buffer__new(rb_fd, NULL);\n\t\tif (!ASSERT_OK_PTR(user_ringbuf, \"user_ringbuf_create\"))\n\t\t\tgoto cleanup;\n\n\t\t*user_ringbuf_out = user_ringbuf;\n\t\tASSERT_EQ(skel->bss->read, 0, \"no_reads_after_load\");\n\t}\n\n\terr = user_ringbuf_success__attach(skel);\n\tif (!ASSERT_OK(err, \"skel_attach\"))\n\t\tgoto cleanup;\n\n\t*skel_out = skel;\n\treturn 0;\n\ncleanup:\n\tif (kern_ringbuf_out)\n\t\t*kern_ringbuf_out = NULL;\n\tif (user_ringbuf_out)\n\t\t*user_ringbuf_out = NULL;\n\tring_buffer__free(kern_ringbuf);\n\tuser_ring_buffer__free(user_ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n\treturn err;\n}\n\nstatic int load_skel_create_user_ringbuf(struct user_ringbuf_success **skel_out,\n\t\t\t\t\t struct user_ring_buffer **ringbuf_out)\n{\n\treturn load_skel_create_ringbufs(skel_out, NULL, NULL, ringbuf_out);\n}\n\nstatic void manually_write_test_invalid_sample(struct user_ringbuf_success *skel,\n\t\t\t\t\t       __u32 size, __u64 producer_pos, int err)\n{\n\tvoid *data_ptr;\n\t__u64 *producer_pos_ptr;\n\tint rb_fd, page_size = getpagesize();\n\n\trb_fd = bpf_map__fd(skel->maps.user_ringbuf);\n\n\tASSERT_EQ(skel->bss->read, 0, \"num_samples_before_bad_sample\");\n\n\t \n\tproducer_pos_ptr = mmap(NULL, page_size, PROT_READ | PROT_WRITE,\n\t\t\t\tMAP_SHARED, rb_fd, page_size);\n\tASSERT_OK_PTR(producer_pos_ptr, \"producer_pos_ptr\");\n\n\t \n\tdata_ptr = mmap(NULL, page_size, PROT_WRITE, MAP_SHARED, rb_fd, 2 * page_size);\n\tASSERT_OK_PTR(data_ptr, \"rw_data\");\n\n\tmemset(data_ptr, 0, BPF_RINGBUF_HDR_SZ);\n\t*(__u32 *)data_ptr = size;\n\n\t \n\tsmp_store_release(producer_pos_ptr, producer_pos + BPF_RINGBUF_HDR_SZ);\n\n\tdrain_current_samples();\n\tASSERT_EQ(skel->bss->read, 0, \"num_samples_after_bad_sample\");\n\tASSERT_EQ(skel->bss->err, err, \"err_after_bad_sample\");\n\n\tASSERT_OK(munmap(producer_pos_ptr, page_size), \"unmap_producer_pos\");\n\tASSERT_OK(munmap(data_ptr, page_size), \"unmap_data_ptr\");\n}\n\nstatic void test_user_ringbuf_post_misaligned(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err;\n\t__u32 size = (1 << 5) + 7;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (!ASSERT_OK(err, \"misaligned_skel\"))\n\t\treturn;\n\n\tmanually_write_test_invalid_sample(skel, size, size, -EINVAL);\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_post_producer_wrong_offset(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err;\n\t__u32 size = (1 << 5);\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (!ASSERT_OK(err, \"wrong_offset_skel\"))\n\t\treturn;\n\n\tmanually_write_test_invalid_sample(skel, size, size - 8, -EINVAL);\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_post_larger_than_ringbuf_sz(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err;\n\t__u32 size = c_ringbuf_size;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (!ASSERT_OK(err, \"huge_sample_skel\"))\n\t\treturn;\n\n\tmanually_write_test_invalid_sample(skel, size, size, -E2BIG);\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_basic(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (!ASSERT_OK(err, \"ringbuf_basic_skel\"))\n\t\treturn;\n\n\tASSERT_EQ(skel->bss->read, 0, \"num_samples_read_before\");\n\n\terr = write_samples(ringbuf, 2);\n\tif (!ASSERT_OK(err, \"write_samples\"))\n\t\tgoto cleanup;\n\n\tASSERT_EQ(skel->bss->read, 2, \"num_samples_read_after\");\n\ncleanup:\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_sample_full_ring_buffer(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err;\n\tvoid *sample;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (!ASSERT_OK(err, \"ringbuf_full_sample_skel\"))\n\t\treturn;\n\n\tsample = user_ring_buffer__reserve(ringbuf, c_ringbuf_size - BPF_RINGBUF_HDR_SZ);\n\tif (!ASSERT_OK_PTR(sample, \"full_sample\"))\n\t\tgoto cleanup;\n\n\tuser_ring_buffer__submit(ringbuf, sample);\n\tASSERT_EQ(skel->bss->read, 0, \"num_samples_read_before\");\n\tdrain_current_samples();\n\tASSERT_EQ(skel->bss->read, 1, \"num_samples_read_after\");\n\ncleanup:\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_post_alignment_autoadjust(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tstruct sample *sample;\n\tint err;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (!ASSERT_OK(err, \"ringbuf_align_autoadjust_skel\"))\n\t\treturn;\n\n\t \n\tsample = user_ring_buffer__reserve(ringbuf, sizeof(*sample) + 1);\n\tASSERT_OK_PTR(sample, \"reserve_autoaligned\");\n\tuser_ring_buffer__submit(ringbuf, sample);\n\n\tASSERT_EQ(skel->bss->read, 0, \"num_samples_read_before\");\n\tdrain_current_samples();\n\tASSERT_EQ(skel->bss->read, 1, \"num_samples_read_after\");\n\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_overfill(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (err)\n\t\treturn;\n\n\terr = write_samples(ringbuf, c_max_entries * 5);\n\tASSERT_ERR(err, \"write_samples\");\n\tASSERT_EQ(skel->bss->read, c_max_entries, \"max_entries\");\n\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_discards_properly_ignored(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err, num_discarded = 0;\n\t__u64 *token;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (err)\n\t\treturn;\n\n\tASSERT_EQ(skel->bss->read, 0, \"num_samples_read_before\");\n\n\twhile (1) {\n\t\t \n\t\ttoken = user_ring_buffer__reserve(ringbuf, sizeof(*token));\n\t\tif (!token)\n\t\t\tbreak;\n\n\t\tuser_ring_buffer__discard(ringbuf, token);\n\t\tnum_discarded++;\n\t}\n\n\tif (!ASSERT_GE(num_discarded, 0, \"num_discarded\"))\n\t\tgoto cleanup;\n\n\t \n\tASSERT_EQ(skel->bss->read, 0, \"num_pre_kick\");\n\tdrain_current_samples();\n\tASSERT_EQ(skel->bss->read, 0, \"num_post_kick\");\n\n\t \n\ttoken = user_ring_buffer__reserve(ringbuf, sizeof(*token));\n\n\tif (!ASSERT_OK_PTR(token, \"new_token\"))\n\t\tgoto cleanup;\n\n\tuser_ring_buffer__discard(ringbuf, token);\ncleanup:\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void test_user_ringbuf_loop(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tuint32_t total_samples = 8192;\n\tuint32_t remaining_samples = total_samples;\n\tint err;\n\n\tBUILD_BUG_ON(total_samples <= c_max_entries);\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (err)\n\t\treturn;\n\n\tdo  {\n\t\tuint32_t curr_samples;\n\n\t\tcurr_samples = remaining_samples > c_max_entries\n\t\t\t? c_max_entries : remaining_samples;\n\t\terr = write_samples(ringbuf, curr_samples);\n\t\tif (err != 0) {\n\t\t\t \n\t\t\tASSERT_OK(err, \"write_samples\");\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tremaining_samples -= curr_samples;\n\t\tASSERT_EQ(skel->bss->read, total_samples - remaining_samples,\n\t\t\t  \"current_batched_entries\");\n\t} while (remaining_samples > 0);\n\tASSERT_EQ(skel->bss->read, total_samples, \"total_batched_entries\");\n\ncleanup:\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic int send_test_message(struct user_ring_buffer *ringbuf,\n\t\t\t     enum test_msg_op op, s64 operand_64,\n\t\t\t     s32 operand_32)\n{\n\tstruct test_msg *msg;\n\n\tmsg = user_ring_buffer__reserve(ringbuf, sizeof(*msg));\n\tif (!msg) {\n\t\t \n\t\tASSERT_OK_PTR(msg, \"reserve_msg\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmsg->msg_op = op;\n\n\tswitch (op) {\n\tcase TEST_MSG_OP_INC64:\n\tcase TEST_MSG_OP_MUL64:\n\t\tmsg->operand_64 = operand_64;\n\t\tbreak;\n\tcase TEST_MSG_OP_INC32:\n\tcase TEST_MSG_OP_MUL32:\n\t\tmsg->operand_32 = operand_32;\n\t\tbreak;\n\tdefault:\n\t\tPRINT_FAIL(\"Invalid operand %d\\n\", op);\n\t\tuser_ring_buffer__discard(ringbuf, msg);\n\t\treturn -EINVAL;\n\t}\n\n\tuser_ring_buffer__submit(ringbuf, msg);\n\n\treturn 0;\n}\n\nstatic void kick_kernel_read_messages(void)\n{\n\tsyscall(__NR_prctl);\n}\n\nstatic int handle_kernel_msg(void *ctx, void *data, size_t len)\n{\n\tstruct user_ringbuf_success *skel = ctx;\n\tstruct test_msg *msg = data;\n\n\tswitch (msg->msg_op) {\n\tcase TEST_MSG_OP_INC64:\n\t\tskel->bss->user_mutated += msg->operand_64;\n\t\treturn 0;\n\tcase TEST_MSG_OP_INC32:\n\t\tskel->bss->user_mutated += msg->operand_32;\n\t\treturn 0;\n\tcase TEST_MSG_OP_MUL64:\n\t\tskel->bss->user_mutated *= msg->operand_64;\n\t\treturn 0;\n\tcase TEST_MSG_OP_MUL32:\n\t\tskel->bss->user_mutated *= msg->operand_32;\n\t\treturn 0;\n\tdefault:\n\t\tfprintf(stderr, \"Invalid operand %d\\n\", msg->msg_op);\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void drain_kernel_messages_buffer(struct ring_buffer *kern_ringbuf,\n\t\t\t\t\t struct user_ringbuf_success *skel)\n{\n\tint cnt;\n\n\tcnt = ring_buffer__consume(kern_ringbuf);\n\tASSERT_EQ(cnt, 8, \"consume_kern_ringbuf\");\n\tASSERT_OK(skel->bss->err, \"consume_kern_ringbuf_err\");\n}\n\nstatic void test_user_ringbuf_msg_protocol(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *user_ringbuf;\n\tstruct ring_buffer *kern_ringbuf;\n\tint err, i;\n\t__u64 expected_kern = 0;\n\n\terr = load_skel_create_ringbufs(&skel, &kern_ringbuf, handle_kernel_msg, &user_ringbuf);\n\tif (!ASSERT_OK(err, \"create_ringbufs\"))\n\t\treturn;\n\n\tfor (i = 0; i < 64; i++) {\n\t\tenum test_msg_op op = i % TEST_MSG_OP_NUM_OPS;\n\t\t__u64 operand_64 = TEST_OP_64;\n\t\t__u32 operand_32 = TEST_OP_32;\n\n\t\terr = send_test_message(user_ringbuf, op, operand_64, operand_32);\n\t\tif (err) {\n\t\t\t \n\t\t\tASSERT_OK(err, \"send_test_message\");\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tswitch (op) {\n\t\tcase TEST_MSG_OP_INC64:\n\t\t\texpected_kern += operand_64;\n\t\t\tbreak;\n\t\tcase TEST_MSG_OP_INC32:\n\t\t\texpected_kern += operand_32;\n\t\t\tbreak;\n\t\tcase TEST_MSG_OP_MUL64:\n\t\t\texpected_kern *= operand_64;\n\t\t\tbreak;\n\t\tcase TEST_MSG_OP_MUL32:\n\t\t\texpected_kern *= operand_32;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tPRINT_FAIL(\"Unexpected op %d\\n\", op);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tif (i % 8 == 0) {\n\t\t\tkick_kernel_read_messages();\n\t\t\tASSERT_EQ(skel->bss->kern_mutated, expected_kern, \"expected_kern\");\n\t\t\tASSERT_EQ(skel->bss->err, 0, \"bpf_prog_err\");\n\t\t\tdrain_kernel_messages_buffer(kern_ringbuf, skel);\n\t\t}\n\t}\n\ncleanup:\n\tring_buffer__free(kern_ringbuf);\n\tuser_ring_buffer__free(user_ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\nstatic void *kick_kernel_cb(void *arg)\n{\n\t \n\tsyscall(__NR_prlimit64);\n\n\treturn NULL;\n}\n\nstatic int spawn_kick_thread_for_poll(void)\n{\n\tpthread_t thread;\n\n\treturn pthread_create(&thread, NULL, kick_kernel_cb, NULL);\n}\n\nstatic void test_user_ringbuf_blocking_reserve(void)\n{\n\tstruct user_ringbuf_success *skel;\n\tstruct user_ring_buffer *ringbuf;\n\tint err, num_written = 0;\n\t__u64 *token;\n\n\terr = load_skel_create_user_ringbuf(&skel, &ringbuf);\n\tif (err)\n\t\treturn;\n\n\tASSERT_EQ(skel->bss->read, 0, \"num_samples_read_before\");\n\n\twhile (1) {\n\t\t \n\t\ttoken = user_ring_buffer__reserve(ringbuf, sizeof(*token));\n\t\tif (!token)\n\t\t\tbreak;\n\n\t\t*token = 0xdeadbeef;\n\n\t\tuser_ring_buffer__submit(ringbuf, token);\n\t\tnum_written++;\n\t}\n\n\tif (!ASSERT_GE(num_written, 0, \"num_written\"))\n\t\tgoto cleanup;\n\n\t \n\tASSERT_EQ(skel->bss->read, 0, \"num_pre_kick\");\n\n\t \n\ttoken = user_ring_buffer__reserve_blocking(ringbuf, sizeof(*token), 1000);\n\tif (!ASSERT_EQ(token, NULL, \"pre_kick_timeout_token\"))\n\t\tgoto cleanup;\n\n\terr = spawn_kick_thread_for_poll();\n\tif (!ASSERT_EQ(err, 0, \"deferred_kick_thread\\n\"))\n\t\tgoto cleanup;\n\n\t \n\ttoken = user_ring_buffer__reserve_blocking(ringbuf, sizeof(*token), 10000);\n\n\tif (!ASSERT_OK_PTR(token, \"block_token\"))\n\t\tgoto cleanup;\n\n\tASSERT_GT(skel->bss->read, 0, \"num_post_kill\");\n\tASSERT_LE(skel->bss->read, num_written, \"num_post_kill\");\n\tASSERT_EQ(skel->bss->err, 0, \"err_post_poll\");\n\tuser_ring_buffer__discard(ringbuf, token);\n\ncleanup:\n\tuser_ring_buffer__free(ringbuf);\n\tuser_ringbuf_success__destroy(skel);\n}\n\n#define SUCCESS_TEST(_func) { _func, #_func }\n\nstatic struct {\n\tvoid (*test_callback)(void);\n\tconst char *test_name;\n} success_tests[] = {\n\tSUCCESS_TEST(test_user_ringbuf_mappings),\n\tSUCCESS_TEST(test_user_ringbuf_post_misaligned),\n\tSUCCESS_TEST(test_user_ringbuf_post_producer_wrong_offset),\n\tSUCCESS_TEST(test_user_ringbuf_post_larger_than_ringbuf_sz),\n\tSUCCESS_TEST(test_user_ringbuf_basic),\n\tSUCCESS_TEST(test_user_ringbuf_sample_full_ring_buffer),\n\tSUCCESS_TEST(test_user_ringbuf_post_alignment_autoadjust),\n\tSUCCESS_TEST(test_user_ringbuf_overfill),\n\tSUCCESS_TEST(test_user_ringbuf_discards_properly_ignored),\n\tSUCCESS_TEST(test_user_ringbuf_loop),\n\tSUCCESS_TEST(test_user_ringbuf_msg_protocol),\n\tSUCCESS_TEST(test_user_ringbuf_blocking_reserve),\n};\n\nvoid test_user_ringbuf(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(success_tests); i++) {\n\t\tif (!test__start_subtest(success_tests[i].test_name))\n\t\t\tcontinue;\n\n\t\tsuccess_tests[i].test_callback();\n\t}\n\n\tRUN_TESTS(user_ringbuf_fail);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}