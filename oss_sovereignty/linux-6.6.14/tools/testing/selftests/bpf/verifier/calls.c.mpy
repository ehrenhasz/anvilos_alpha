{
  "module_name": "calls.c",
  "hash_id": "bd465be5206219efd171d5c3e1857a386c5965f90b76b2bcf5c8dc7761e6ea9b",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/verifier/calls.c",
  "human_readable_source": "{\n\t\"calls: invalid kfunc call not eliminated\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.result  = REJECT,\n\t.errstr = \"invalid kernel function call not eliminated in verifier pass\",\n},\n{\n\t\"calls: invalid kfunc call unreachable\",\n\t.insns = {\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_JMP_IMM(BPF_JGT, BPF_REG_0, 0, 2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.result  = ACCEPT,\n},\n{\n\t\"calls: invalid kfunc call: ptr_to_mem to struct with non-scalar\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"arg#0 pointer type STRUCT prog_test_fail1 must point to scalar\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_fail1\", 2 },\n\t},\n},\n{\n\t\"calls: invalid kfunc call: ptr_to_mem to struct with nesting depth > 4\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"max struct nesting depth exceeded\\narg#0 pointer type STRUCT prog_test_fail2\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_fail2\", 2 },\n\t},\n},\n{\n\t\"calls: invalid kfunc call: ptr_to_mem to struct with FAM\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"arg#0 pointer type STRUCT prog_test_fail3 must point to scalar\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_fail3\", 2 },\n\t},\n},\n{\n\t\"calls: invalid kfunc call: reg->type != PTR_TO_CTX\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"R1 must have zero offset when passed to release func or trusted arg to kfunc\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_pass_ctx\", 2 },\n\t},\n},\n{\n\t\"calls: invalid kfunc call: void * not allowed in func proto without mem size arg\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"arg#0 pointer type UNKNOWN  must point to scalar\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_mem_len_fail1\", 2 },\n\t},\n},\n{\n\t\"calls: trigger reg2btf_ids[reg->type] for reg->type > __BPF_REG_TYPE_MAX\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"Possibly NULL pointer passed to trusted arg0\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_acquire\", 3 },\n\t\t{ \"bpf_kfunc_call_test_release\", 5 },\n\t},\n},\n{\n\t\"calls: invalid kfunc call: reg->off must be zero when passed to release kfunc\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"R1 must have zero offset when passed to release func\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_acquire\", 3 },\n\t\t{ \"bpf_kfunc_call_memb_release\", 8 },\n\t},\n},\n{\n\t\"calls: invalid kfunc call: don't match first member type when passed to release kfunc\",\n\t.insns = {\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"kernel function bpf_kfunc_call_memb1_release args#0 expected pointer\",\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_memb_acquire\", 1 },\n\t\t{ \"bpf_kfunc_call_memb1_release\", 5 },\n\t},\n},\n{\n\t\"calls: invalid kfunc call: PTR_TO_BTF_ID with negative offset\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -4),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_acquire\", 3 },\n\t\t{ \"bpf_kfunc_call_test_offset\", 9 },\n\t\t{ \"bpf_kfunc_call_test_release\", 12 },\n\t},\n\t.result_unpriv = REJECT,\n\t.result = REJECT,\n\t.errstr = \"ptr R1 off=-4 disallowed\",\n},\n{\n\t\"calls: invalid kfunc call: PTR_TO_BTF_ID with variable offset\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_0, 4),\n\tBPF_JMP_IMM(BPF_JLE, BPF_REG_2, 4, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_JMP_IMM(BPF_JGE, BPF_REG_2, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_ALU64_REG(BPF_ADD, BPF_REG_1, BPF_REG_2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_acquire\", 3 },\n\t\t{ \"bpf_kfunc_call_test_release\", 9 },\n\t\t{ \"bpf_kfunc_call_test_release\", 13 },\n\t\t{ \"bpf_kfunc_call_test_release\", 17 },\n\t},\n\t.result_unpriv = REJECT,\n\t.result = REJECT,\n\t.errstr = \"variable ptr_ access var_off=(0x0; 0x7) disallowed\",\n},\n{\n\t\"calls: invalid kfunc call: referenced arg needs refcounted PTR_TO_BTF_ID\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_1, BPF_REG_6, 16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_acquire\", 3 },\n\t\t{ \"bpf_kfunc_call_test_ref\", 8 },\n\t\t{ \"bpf_kfunc_call_test_ref\", 10 },\n\t},\n\t.result_unpriv = REJECT,\n\t.result = REJECT,\n\t.errstr = \"R1 must be\",\n},\n{\n\t\"calls: valid kfunc call: referenced arg needs refcounted PTR_TO_BTF_ID\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, BPF_PSEUDO_KFUNC_CALL, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_kfunc_btf_id = {\n\t\t{ \"bpf_kfunc_call_test_acquire\", 3 },\n\t\t{ \"bpf_kfunc_call_test_ref\", 8 },\n\t\t{ \"bpf_kfunc_call_test_release\", 10 },\n\t},\n\t.result_unpriv = REJECT,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: basic sanity\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 2),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: not on unprivileged\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 2),\n\tBPF_EXIT_INSN(),\n\t},\n\t.errstr_unpriv = \"loading/calling other bpf or kernel functions are allowed for\",\n\t.result_unpriv = REJECT,\n\t.result = ACCEPT,\n\t.retval = 1,\n},\n{\n\t\"calls: div by 0 in subprog\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 8),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_0),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, 8),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_2, BPF_REG_1, 1),\n\tBPF_LDX_MEM(BPF_B, BPF_REG_0, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV32_IMM(BPF_REG_2, 0),\n\tBPF_MOV32_IMM(BPF_REG_3, 1),\n\tBPF_ALU32_REG(BPF_DIV, BPF_REG_3, BPF_REG_2),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.retval = 1,\n},\n{\n\t\"calls: multiple ret types in subprog 1\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 8),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_0),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, 8),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_2, BPF_REG_1, 1),\n\tBPF_LDX_MEM(BPF_B, BPF_REG_0, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_MOV32_IMM(BPF_REG_0, 42),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = REJECT,\n\t.errstr = \"R0 invalid mem access 'scalar'\",\n},\n{\n\t\"calls: multiple ret types in subprog 2\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 8),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_0),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, 8),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_2, BPF_REG_1, 1),\n\tBPF_LDX_MEM(BPF_B, BPF_REG_0, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 9),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_6,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 64),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_map_hash_8b = { 16 },\n\t.result = REJECT,\n\t.errstr = \"R0 min value is outside of the allowed memory range\",\n},\n{\n\t\"calls: overlapping caller/callee\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"last insn is not an exit or jmp\",\n\t.result = REJECT,\n},\n{\n\t\"calls: wrong recursive calls\",\n\t.insns = {\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 4),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 4),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -2),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"jump out of range\",\n\t.result = REJECT,\n},\n{\n\t\"calls: wrong src reg\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 3, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"BPF_CALL uses reserved fields\",\n\t.result = REJECT,\n},\n{\n\t\"calls: wrong off value\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, -1, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 2),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"BPF_CALL uses reserved fields\",\n\t.result = REJECT,\n},\n{\n\t\"calls: jump back loop\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -1),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"the call stack of 9 frames is too deep\",\n\t.result = REJECT,\n},\n{\n\t\"calls: conditional call\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, mark)),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 2),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"jump out of range\",\n\t.result = REJECT,\n},\n{\n\t\"calls: conditional call 2\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, mark)),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 2),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: conditional call 3\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, mark)),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 3),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 4),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, -6),\n\tBPF_MOV64_IMM(BPF_REG_0, 3),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, -6),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SOCKET_FILTER,\n\t.errstr_unpriv = \"back-edge from insn\",\n\t.result_unpriv = REJECT,\n\t.result = ACCEPT,\n\t.retval = 1,\n},\n{\n\t\"calls: conditional call 4\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, mark)),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, -5),\n\tBPF_MOV64_IMM(BPF_REG_0, 3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: conditional call 5\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, mark)),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, -6),\n\tBPF_MOV64_IMM(BPF_REG_0, 3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.retval = 1,\n},\n{\n\t\"calls: conditional call 6\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, -3),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, mark)),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.errstr = \"infinite loop detected\",\n\t.result = REJECT,\n},\n{\n\t\"calls: using r0 returned by callee\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 2),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: using uninit r0 from callee\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"!read_ok\",\n\t.result = REJECT,\n},\n{\n\t\"calls: callee is using r1\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, len)),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_ACT,\n\t.result = ACCEPT,\n\t.retval = TEST_DATA_LEN,\n},\n{\n\t\"calls: callee using args1\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.errstr_unpriv = \"allowed for\",\n\t.result_unpriv = REJECT,\n\t.result = ACCEPT,\n\t.retval = POINTER_VALUE,\n},\n{\n\t\"calls: callee using wrong args2\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"R2 !read_ok\",\n\t.result = REJECT,\n},\n{\n\t\"calls: callee using two args\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_1, BPF_REG_6,\n\t\t    offsetof(struct __sk_buff, len)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_6,\n\t\t    offsetof(struct __sk_buff, len)),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_1),\n\tBPF_ALU64_REG(BPF_ADD, BPF_REG_0, BPF_REG_2),\n\tBPF_EXIT_INSN(),\n\t},\n\t.errstr_unpriv = \"allowed for\",\n\t.result_unpriv = REJECT,\n\t.result = ACCEPT,\n\t.retval = TEST_DATA_LEN + TEST_DATA_LEN - ETH_HLEN - ETH_HLEN,\n},\n{\n\t\"calls: callee changing pkt pointers\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_6, BPF_REG_1, offsetof(struct xdp_md, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_7, BPF_REG_1,\n\t\t    offsetof(struct xdp_md, data_end)),\n\tBPF_MOV64_REG(BPF_REG_8, BPF_REG_6),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_8, 8),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_8, BPF_REG_7, 2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_6, 0),\n\tBPF_MOV32_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_2, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_xdp_adjust_head),\n\tBPF_EXIT_INSN(),\n\t},\n\t.result = REJECT,\n\t.errstr = \"R6 invalid mem access 'scalar'\",\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: ptr null check in subprog\",\n\t.insns = {\n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_EMIT_CALL(BPF_FUNC_map_lookup_elem),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 1),\n\tBPF_LDX_MEM(BPF_B, BPF_REG_0, BPF_REG_6, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.errstr_unpriv = \"loading/calling other bpf or kernel functions are allowed for\",\n\t.fixup_map_hash_48b = { 3 },\n\t.result_unpriv = REJECT,\n\t.result = ACCEPT,\n\t.retval = 0,\n},\n{\n\t\"calls: two calls with args\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 6),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_ALU64_REG(BPF_ADD, BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_7),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, len)),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.retval = TEST_DATA_LEN + TEST_DATA_LEN,\n},\n{\n\t\"calls: calls with stack arith\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -64),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -64),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -64),\n\tBPF_MOV64_IMM(BPF_REG_0, 42),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_2, BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.retval = 42,\n},\n{\n\t\"calls: calls with misaligned stack access\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -63),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -61),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -63),\n\tBPF_MOV64_IMM(BPF_REG_0, 42),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_2, BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.flags = F_LOAD_WITH_STRICT_ALIGNMENT,\n\t.errstr = \"misaligned stack access\",\n\t.result = REJECT,\n},\n{\n\t\"calls: calls control flow, jump test\",\n\t.insns = {\n\tBPF_MOV64_IMM(BPF_REG_0, 42),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 43),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, -3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.retval = 43,\n},\n{\n\t\"calls: calls control flow, jump test 2\",\n\t.insns = {\n\tBPF_MOV64_IMM(BPF_REG_0, 42),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 43),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.errstr = \"jump out of range from insn 1 to 4\",\n\t.result = REJECT,\n},\n{\n\t\"calls: two calls with bad jump\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 6),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_ALU64_REG(BPF_ADD, BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_7),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, len)),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, -3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"jump out of range from insn 11 to 9\",\n\t.result = REJECT,\n},\n{\n\t\"calls: recursive call. test1\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -1),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"the call stack of 9 frames is too deep\",\n\t.result = REJECT,\n},\n{\n\t\"calls: recursive call. test2\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"the call stack of 9 frames is too deep\",\n\t.result = REJECT,\n},\n{\n\t\"calls: unreachable code\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"unreachable insn 6\",\n\t.result = REJECT,\n},\n{\n\t\"calls: invalid call\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, -4),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"invalid destination\",\n\t.result = REJECT,\n},\n{\n\t\"calls: invalid call 2\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 0x7fffffff),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"invalid destination\",\n\t.result = REJECT,\n},\n{\n\t\"calls: jumping across function bodies. test1\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, -3),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"jump out of range\",\n\t.result = REJECT,\n},\n{\n\t\"calls: jumping across function bodies. test2\",\n\t.insns = {\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"jump out of range\",\n\t.result = REJECT,\n},\n{\n\t\"calls: call without exit\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, -2),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"not an exit\",\n\t.result = REJECT,\n},\n{\n\t\"calls: call into middle of ld_imm64\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_LD_IMM64(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"last insn\",\n\t.result = REJECT,\n},\n{\n\t\"calls: call into middle of other call\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"last insn\",\n\t.result = REJECT,\n},\n{\n\t\"calls: subprog call with ld_abs in main prog\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_LD_ABS(BPF_B, 0),\n\tBPF_LD_ABS(BPF_H, 0),\n\tBPF_LD_ABS(BPF_W, 0),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_6),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 5),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_7),\n\tBPF_LD_ABS(BPF_B, 0),\n\tBPF_LD_ABS(BPF_H, 0),\n\tBPF_LD_ABS(BPF_W, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_IMM(BPF_REG_2, 1),\n\tBPF_MOV64_IMM(BPF_REG_3, 2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_skb_vlan_push),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: two calls with bad fallthrough\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 6),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_ALU64_REG(BPF_ADD, BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_7),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_0),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, len)),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_TRACEPOINT,\n\t.errstr = \"not an exit\",\n\t.result = REJECT,\n},\n{\n\t\"calls: two calls with stack read\",\n\t.insns = {\n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 6),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_ALU64_REG(BPF_ADD, BPF_REG_7, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_7),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: two calls with stack write\",\n\t.insns = {\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_10, -16),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 7),\n\tBPF_MOV64_REG(BPF_REG_8, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_ALU64_REG(BPF_ADD, BPF_REG_8, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_8),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_7, BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_1, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: stack overflow using two frames (pre-call access)\",\n\t.insns = {\n\t \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -300, 0),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -300, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.errstr = \"combined stack size\",\n\t.result = REJECT,\n},\n{\n\t\"calls: stack overflow using two frames (post-call access)\",\n\t.insns = {\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 2),\n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -300, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -300, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.errstr = \"combined stack size\",\n\t.result = REJECT,\n},\n{\n\t\"calls: stack depth check using three frames. test1\",\n\t.insns = {\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 4),  \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 5),  \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -32, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -256, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, -3),  \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -64, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t \n\t.result = ACCEPT,\n},\n{\n\t\"calls: stack depth check using three frames. test2\",\n\t.insns = {\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 4),  \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 5),  \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -32, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -64, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, -3),  \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -256, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t \n\t.result = ACCEPT,\n},\n{\n\t\"calls: stack depth check using three frames. test3\",\n\t.insns = {\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 6),  \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 8),  \n\tBPF_JMP_IMM(BPF_JGE, BPF_REG_6, 0, 1),\n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -64, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_JMP_IMM(BPF_JLT, BPF_REG_1, 10, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -224, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, -3),\n\t \n\tBPF_JMP_IMM(BPF_JGT, BPF_REG_1, 2, 1),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, -6),  \n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -256, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t \n\t.errstr = \"combined stack\",\n\t.result = REJECT,\n},\n{\n\t\"calls: stack depth check using three frames. test4\",\n\t \n\t.insns = {\n\t \n\tBPF_MOV64_IMM(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 6),  \n\tBPF_MOV64_IMM(BPF_REG_1, 1),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 4),  \n\tBPF_MOV64_IMM(BPF_REG_1, 1),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 7),  \n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 2),\n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -300, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 1),\n\tBPF_ST_MEM(BPF_B, BPF_REG_10, -300, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.result = REJECT,\n\t.errstr = \"combined stack\",\n},\n{\n\t\"calls: stack depth check using three frames. test5\",\n\t.insns = {\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.errstr = \"call stack\",\n\t.result = REJECT,\n},\n{\n\t\"calls: stack depth check in dead code\",\n\t.insns = {\n\t \n\tBPF_MOV64_IMM(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 1),\n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 2),  \n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 1),  \n\tBPF_EXIT_INSN(),\n\t \n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.errstr = \"call stack\",\n\t.result = REJECT,\n},\n{\n\t\"calls: spill into caller stack frame\",\n\t.insns = {\n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_1, BPF_REG_1, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.errstr = \"cannot spill\",\n\t.result = REJECT,\n},\n{\n\t\"calls: write into caller stack frame\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_6, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 42),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.result = ACCEPT,\n\t.retval = 42,\n},\n{\n\t\"calls: write into callee stack frame\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 42),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, -8),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.errstr = \"cannot return stack pointer\",\n\t.result = REJECT,\n},\n{\n\t\"calls: two calls with stack write and void return\",\n\t.insns = {\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_10, -16),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_7),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_1, 0, 0),\n\tBPF_EXIT_INSN(),  \n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: ambiguous return value\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 5),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_EXIT_INSN(),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.errstr_unpriv = \"allowed for\",\n\t.result_unpriv = REJECT,\n\t.errstr = \"R0 !read_ok\",\n\t.result = REJECT,\n},\n{\n\t\"calls: two calls that return map_value\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 8),\n\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_10, -8),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 1),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_10, -16),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 1),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_7),\n\t \n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),  \n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.fixup_map_hash_8b = { 23 },\n\t.result = ACCEPT,\n},\n{\n\t\"calls: two calls that return map_value with bool condition\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 9),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_6, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_7),\n\t \n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_7, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),  \n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),  \n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.fixup_map_hash_8b = { 23 },\n\t.result = ACCEPT,\n},\n{\n\t\"calls: two calls that return map_value with incorrect bool check\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 9),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_6, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_7),\n\t \n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_7, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),  \n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 1),\n\tBPF_EXIT_INSN(),  \n\t},\n\t.prog_type = BPF_PROG_TYPE_XDP,\n\t.fixup_map_hash_8b = { 23 },\n\t.result = REJECT,\n\t.errstr = \"R0 invalid mem access 'scalar'\",\n\t.result_unpriv = REJECT,\n\t.errstr_unpriv = \"invalid read from stack R7 off=-16 size=8\",\n},\n{\n\t\"calls: two calls that receive map_value via arg=ptr_stack_of_caller. test1\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_8, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_8, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),  \n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,  \n\t\t     BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_9, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_7, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_9, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),  \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_8),\n\tBPF_MOV64_REG(BPF_REG_3, BPF_REG_7),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_9),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),   \n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_2, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_1, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_4, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_3, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 2, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_map_hash_8b = { 12, 22 },\n\t.result = REJECT,\n\t.errstr = \"invalid access to map value, value_size=8 off=2 size=8\",\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: two calls that receive map_value via arg=ptr_stack_of_caller. test2\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_8, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_8, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),  \n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,  \n\t\t     BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_9, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_7, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_9, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),  \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_8),\n\tBPF_MOV64_REG(BPF_REG_3, BPF_REG_7),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_9),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),   \n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_2, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_1, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_4, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_3, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_map_hash_8b = { 12, 22 },\n\t.result = ACCEPT,\n},\n{\n\t\"calls: two jumps that receive map_value via arg=ptr_stack_of_jumper. test3\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -24, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -24),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_8, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_8, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -24),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_9, 0),  \n\tBPF_JMP_IMM(BPF_JA, 0, 0, 2),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_7, BPF_REG_0, 0),\n\tBPF_MOV64_IMM(BPF_REG_9, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6), \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_8),\n\tBPF_MOV64_REG(BPF_REG_3, BPF_REG_7),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_9),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_1, 0, 1), \n\tBPF_JMP_IMM(BPF_JA, 0, 0, -30),\n\n\t \n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_2, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_1, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_4, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_3, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 2, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, -8),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_map_hash_8b = { 12, 22 },\n\t.result = REJECT,\n\t.errstr = \"invalid access to map value, value_size=8 off=2 size=8\",\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: two calls that receive map_value_ptr_or_null via arg. test1\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_8, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_8, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_7, BPF_REG_0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_9, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_9, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_8),\n\tBPF_MOV64_REG(BPF_REG_3, BPF_REG_7),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_9),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_2, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_1, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_4, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_3, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_map_hash_8b = { 12, 22 },\n\t.result = ACCEPT,\n},\n{\n\t\"calls: two calls that receive map_value_ptr_or_null via arg. test2\",\n\t.insns = {\n\t \n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -16),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_2),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_8, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_8, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_7, BPF_REG_0, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 2),\n\tBPF_MOV64_IMM(BPF_REG_9, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_9, 1),\n\n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_8),\n\tBPF_MOV64_REG(BPF_REG_3, BPF_REG_7),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_9),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_2, 1, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_1, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\n\t \n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_4, 0, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_3, 0),\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_0, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.fixup_map_hash_8b = { 12, 22 },\n\t.result = REJECT,\n\t.errstr = \"R0 invalid mem access 'scalar'\",\n},\n{\n\t\"calls: pkt_ptr spill into caller stack\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 1),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_2, BPF_REG_4, 0),\n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.result = ACCEPT,\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.retval = POINTER_VALUE,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 2\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_ST_MEM(BPF_W, BPF_REG_4, 0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_2, BPF_REG_4, 0),\n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.errstr = \"invalid access to packet\",\n\t.result = REJECT,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 3\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_ST_MEM(BPF_W, BPF_REG_4, 0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 3),\n\tBPF_MOV64_IMM(BPF_REG_5, 1),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_2, BPF_REG_4, 0),\n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_5),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.retval = 1,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 4\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 2),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_ST_MEM(BPF_W, BPF_REG_4, 0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 2),\n\tBPF_MOV64_IMM(BPF_REG_5, 1),\n\t \n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_5),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.retval = 1,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 5\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_4, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 3),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_MOV64_IMM(BPF_REG_5, 1),\n\t \n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_5),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.errstr = \"same insn cannot be used with different\",\n\t.result = REJECT,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 6\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_4, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 3),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_MOV64_IMM(BPF_REG_5, 1),\n\t \n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_5),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.errstr = \"R4 invalid mem access\",\n\t.result = REJECT,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 7\",\n\t.insns = {\n\tBPF_MOV64_IMM(BPF_REG_2, 0),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_4, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 3),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_MOV64_IMM(BPF_REG_5, 1),\n\t \n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_5),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.errstr = \"R4 invalid mem access\",\n\t.result = REJECT,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 8\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_JMP_REG(BPF_JLE, BPF_REG_0, BPF_REG_3, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_4, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 3),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_MOV64_IMM(BPF_REG_5, 1),\n\t \n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_5),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.result = ACCEPT,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: pkt_ptr spill into caller stack 9\",\n\t.insns = {\n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_JMP_REG(BPF_JLE, BPF_REG_0, BPF_REG_3, 1),\n\tBPF_EXIT_INSN(),\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, -8),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 3),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_4, BPF_REG_10, -8),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_0, BPF_REG_4, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data)),\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\n\t\t    offsetof(struct __sk_buff, data_end)),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_2),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_0, 8),\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_4, BPF_REG_2, 0),\n\tBPF_JMP_REG(BPF_JGT, BPF_REG_0, BPF_REG_3, 2),\n\tBPF_MOV64_IMM(BPF_REG_5, 1),\n\t \n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_2, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_0, BPF_REG_5),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SCHED_CLS,\n\t.errstr = \"invalid access to packet\",\n\t.result = REJECT,\n\t.flags = F_NEEDS_EFFICIENT_UNALIGNED_ACCESS,\n},\n{\n\t\"calls: caller stack init to zero or map_value_or_null\",\n\t.insns = {\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_0, -8),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_10, -8),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 1),\n\t \n\tBPF_ST_MEM(BPF_W, BPF_REG_0, 0, 0),\n\tBPF_EXIT_INSN(),\n\n\t \n\t \n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 8),\n\t \n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_2),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\t \n\tBPF_STX_MEM(BPF_DW, BPF_REG_6, BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.fixup_map_hash_8b = { 13 },\n\t.result = ACCEPT,\n\t.prog_type = BPF_PROG_TYPE_XDP,\n},\n{\n\t\"calls: stack init to zero and pruning\",\n\t.insns = {\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -16, 0),\n\t \n\tBPF_EMIT_CALL(BPF_FUNC_get_prandom_u32),\n\tBPF_JMP_IMM(BPF_JGT, BPF_REG_0, 2, 2),\n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\tBPF_JMP_IMM(BPF_JA, 0, 0, 0),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1, 0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.fixup_map_hash_48b = { 7 },\n\t.errstr_unpriv = \"invalid indirect read from stack R2 off -8+0 size 8\",\n\t.result_unpriv = REJECT,\n\t \n\t.result = ACCEPT,\n},\n{\n\t\"calls: ctx read at start of subprog\",\n\t.insns = {\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 5),\n\tBPF_JMP_REG(BPF_JSGT, BPF_REG_0, BPF_REG_0, 0),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_6),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 2),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_EXIT_INSN(),\n\tBPF_LDX_MEM(BPF_B, BPF_REG_9, BPF_REG_1, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SOCKET_FILTER,\n\t.errstr_unpriv = \"loading/calling other bpf or kernel functions are allowed for\",\n\t.result_unpriv = REJECT,\n\t.result = ACCEPT,\n},\n{\n\t\"calls: cross frame pruning\",\n\t.insns = {\n\t \n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_get_prandom_u32),\n\tBPF_MOV64_IMM(BPF_REG_8, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_8, 1),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_8),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_8, 1, 1),\n\tBPF_LDX_MEM(BPF_B, BPF_REG_9, BPF_REG_1, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SOCKET_FILTER,\n\t.errstr_unpriv = \"loading/calling other bpf or kernel functions are allowed for\",\n\t.errstr = \"!read_ok\",\n\t.result = REJECT,\n},\n{\n\t\"calls: cross frame pruning - liveness propagation\",\n\t.insns = {\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_get_prandom_u32),\n\tBPF_MOV64_IMM(BPF_REG_8, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_8, 1),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_get_prandom_u32),\n\tBPF_MOV64_IMM(BPF_REG_9, 0),\n\tBPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, 1),\n\tBPF_MOV64_IMM(BPF_REG_9, 1),\n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_0),\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 1, 0, 4),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_8, 1, 1),\n\tBPF_LDX_MEM(BPF_B, BPF_REG_1, BPF_REG_2, 0),\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_1, 0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.prog_type = BPF_PROG_TYPE_SOCKET_FILTER,\n\t.errstr_unpriv = \"loading/calling other bpf or kernel functions are allowed for\",\n\t.errstr = \"!read_ok\",\n\t.result = REJECT,\n},\n \n{\n\t\"calls: check_ids() across call boundary\",\n\t.insns = {\n\t \n\tBPF_ST_MEM(BPF_DW, BPF_REG_10, -8, 0),\n\t \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1,\n\t\t      0),\n\tBPF_EMIT_CALL(BPF_FUNC_map_lookup_elem),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_FP, BPF_REG_0, -24),\n\t \n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -8),\n\tBPF_LD_MAP_FD(BPF_REG_1,\n\t\t      0),\n\tBPF_EMIT_CALL(BPF_FUNC_map_lookup_elem),\n\tBPF_STX_MEM(BPF_DW, BPF_REG_FP, BPF_REG_0, -32),\n\t \n\tBPF_MOV64_REG(BPF_REG_1, BPF_REG_FP),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_1, -24),\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_FP),\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -32),\n\tBPF_CALL_REL(2),\n\t \n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t \n\tBPF_MOV64_REG(BPF_REG_9, BPF_REG_1),\n\tBPF_MOV64_REG(BPF_REG_8, BPF_REG_2),\n\t \n\tBPF_EMIT_CALL(BPF_FUNC_ktime_get_ns),\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_0),\n\t \n\tBPF_EMIT_CALL(BPF_FUNC_ktime_get_ns),\n\tBPF_MOV64_REG(BPF_REG_6, BPF_REG_0),\n\t \n\tBPF_JMP_REG(BPF_JGT, BPF_REG_6, BPF_REG_7, 1),\n\tBPF_MOV64_REG(BPF_REG_9, BPF_REG_8),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_9, BPF_REG_9, 0),\n\tBPF_JMP_IMM(BPF_JEQ, BPF_REG_9, 0, 1),\n\t \n\tBPF_LDX_MEM(BPF_DW, BPF_REG_8, BPF_REG_8, 0),\n\tBPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_8, 0),\n\t \n\tBPF_MOV64_IMM(BPF_REG_0, 0),\n\tBPF_EXIT_INSN(),\n\t},\n\t.flags = BPF_F_TEST_STATE_FREQ,\n\t.fixup_map_hash_8b = { 3, 9 },\n\t.result = REJECT,\n\t.errstr = \"R8 invalid mem access 'map_value_or_null'\",\n\t.result_unpriv = REJECT,\n\t.errstr_unpriv = \"\",\n\t.prog_type = BPF_PROG_TYPE_CGROUP_SKB,\n},\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}