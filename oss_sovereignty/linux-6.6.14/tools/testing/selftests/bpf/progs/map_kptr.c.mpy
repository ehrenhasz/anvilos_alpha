{
  "module_name": "map_kptr.c",
  "hash_id": "ab86fbaf2ae1b71270890f11f61951627a0385db92305535f64cd5453cd6f907",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/map_kptr.c",
  "human_readable_source": "\n#include <vmlinux.h>\n#include <bpf/bpf_tracing.h>\n#include <bpf/bpf_helpers.h>\n#include \"../bpf_testmod/bpf_testmod_kfunc.h\"\n\nstruct map_value {\n\tstruct prog_test_ref_kfunc __kptr_untrusted *unref_ptr;\n\tstruct prog_test_ref_kfunc __kptr *ref_ptr;\n};\n\nstruct array_map {\n\t__uint(type, BPF_MAP_TYPE_ARRAY);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n} array_map SEC(\".maps\");\n\nstruct pcpu_array_map {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n} pcpu_array_map SEC(\".maps\");\n\nstruct hash_map {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n} hash_map SEC(\".maps\");\n\nstruct pcpu_hash_map {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_HASH);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n} pcpu_hash_map SEC(\".maps\");\n\nstruct hash_malloc_map {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n} hash_malloc_map SEC(\".maps\");\n\nstruct pcpu_hash_malloc_map {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_HASH);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n} pcpu_hash_malloc_map SEC(\".maps\");\n\nstruct lru_hash_map {\n\t__uint(type, BPF_MAP_TYPE_LRU_HASH);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n} lru_hash_map SEC(\".maps\");\n\nstruct lru_pcpu_hash_map {\n\t__uint(type, BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\t__type(key, int);\n\t__type(value, struct map_value);\n\t__uint(max_entries, 1);\n} lru_pcpu_hash_map SEC(\".maps\");\n\nstruct cgrp_ls_map {\n\t__uint(type, BPF_MAP_TYPE_CGRP_STORAGE);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n\t__type(key, int);\n\t__type(value, struct map_value);\n} cgrp_ls_map SEC(\".maps\");\n\nstruct task_ls_map {\n\t__uint(type, BPF_MAP_TYPE_TASK_STORAGE);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n\t__type(key, int);\n\t__type(value, struct map_value);\n} task_ls_map SEC(\".maps\");\n\nstruct inode_ls_map {\n\t__uint(type, BPF_MAP_TYPE_INODE_STORAGE);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n\t__type(key, int);\n\t__type(value, struct map_value);\n} inode_ls_map SEC(\".maps\");\n\nstruct sk_ls_map {\n\t__uint(type, BPF_MAP_TYPE_SK_STORAGE);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n\t__type(key, int);\n\t__type(value, struct map_value);\n} sk_ls_map SEC(\".maps\");\n\n#define DEFINE_MAP_OF_MAP(map_type, inner_map_type, name)       \\\n\tstruct {                                                \\\n\t\t__uint(type, map_type);                         \\\n\t\t__uint(max_entries, 1);                         \\\n\t\t__uint(key_size, sizeof(int));                  \\\n\t\t__uint(value_size, sizeof(int));                \\\n\t\t__array(values, struct inner_map_type);         \\\n\t} name SEC(\".maps\") = {                                 \\\n\t\t.values = { [0] = &inner_map_type },            \\\n\t}\n\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_ARRAY_OF_MAPS, array_map, array_of_array_maps);\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_ARRAY_OF_MAPS, hash_map, array_of_hash_maps);\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_ARRAY_OF_MAPS, hash_malloc_map, array_of_hash_malloc_maps);\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_ARRAY_OF_MAPS, lru_hash_map, array_of_lru_hash_maps);\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_HASH_OF_MAPS, array_map, hash_of_array_maps);\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_HASH_OF_MAPS, hash_map, hash_of_hash_maps);\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_HASH_OF_MAPS, hash_malloc_map, hash_of_hash_malloc_maps);\nDEFINE_MAP_OF_MAP(BPF_MAP_TYPE_HASH_OF_MAPS, lru_hash_map, hash_of_lru_hash_maps);\n\n#define WRITE_ONCE(x, val) ((*(volatile typeof(x) *) &(x)) = (val))\n\nstatic void test_kptr_unref(struct map_value *v)\n{\n\tstruct prog_test_ref_kfunc *p;\n\n\tp = v->unref_ptr;\n\t \n\tWRITE_ONCE(v->unref_ptr, p);\n\tif (!p)\n\t\treturn;\n\tif (p->a + p->b > 100)\n\t\treturn;\n\t \n\tWRITE_ONCE(v->unref_ptr, p);\n\t \n\tWRITE_ONCE(v->unref_ptr, NULL);\n}\n\nstatic void test_kptr_ref(struct map_value *v)\n{\n\tstruct prog_test_ref_kfunc *p;\n\n\tp = v->ref_ptr;\n\t \n\tWRITE_ONCE(v->unref_ptr, p);\n\tif (!p)\n\t\treturn;\n\t \n\tbpf_kfunc_call_test_ref(p);\n\tif (p->a + p->b > 100)\n\t\treturn;\n\t \n\tp = bpf_kptr_xchg(&v->ref_ptr, NULL);\n\tif (!p)\n\t\treturn;\n\t \n\tbpf_kfunc_call_test_ref(p);\n\tif (p->a + p->b > 100) {\n\t\tbpf_kfunc_call_test_release(p);\n\t\treturn;\n\t}\n\t \n\tWRITE_ONCE(v->unref_ptr, p);\n\tbpf_kfunc_call_test_release(p);\n\n\tp = bpf_kfunc_call_test_acquire(&(unsigned long){0});\n\tif (!p)\n\t\treturn;\n\t \n\tp = bpf_kptr_xchg(&v->ref_ptr, p);\n\tif (!p)\n\t\treturn;\n\tif (p->a + p->b > 100) {\n\t\tbpf_kfunc_call_test_release(p);\n\t\treturn;\n\t}\n\tbpf_kfunc_call_test_release(p);\n}\n\nstatic void test_kptr(struct map_value *v)\n{\n\ttest_kptr_unref(v);\n\ttest_kptr_ref(v);\n}\n\nSEC(\"tc\")\nint test_map_kptr(struct __sk_buff *ctx)\n{\n\tstruct map_value *v;\n\tint key = 0;\n\n#define TEST(map)\t\t\t\t\t\\\n\tv = bpf_map_lookup_elem(&map, &key);\t\t\\\n\tif (!v)\t\t\t\t\t\t\\\n\t\treturn 0;\t\t\t\t\\\n\ttest_kptr(v)\n\n\tTEST(array_map);\n\tTEST(hash_map);\n\tTEST(hash_malloc_map);\n\tTEST(lru_hash_map);\n\n#undef TEST\n\treturn 0;\n}\n\nSEC(\"tp_btf/cgroup_mkdir\")\nint BPF_PROG(test_cgrp_map_kptr, struct cgroup *cgrp, const char *path)\n{\n\tstruct map_value *v;\n\n\tv = bpf_cgrp_storage_get(&cgrp_ls_map, cgrp, NULL, BPF_LOCAL_STORAGE_GET_F_CREATE);\n\tif (v)\n\t\ttest_kptr(v);\n\treturn 0;\n}\n\nSEC(\"lsm/inode_unlink\")\nint BPF_PROG(test_task_map_kptr, struct inode *inode, struct dentry *victim)\n{\n\tstruct task_struct *task;\n\tstruct map_value *v;\n\n\ttask = bpf_get_current_task_btf();\n\tif (!task)\n\t\treturn 0;\n\tv = bpf_task_storage_get(&task_ls_map, task, NULL, BPF_LOCAL_STORAGE_GET_F_CREATE);\n\tif (v)\n\t\ttest_kptr(v);\n\treturn 0;\n}\n\nSEC(\"lsm/inode_unlink\")\nint BPF_PROG(test_inode_map_kptr, struct inode *inode, struct dentry *victim)\n{\n\tstruct map_value *v;\n\n\tv = bpf_inode_storage_get(&inode_ls_map, inode, NULL, BPF_LOCAL_STORAGE_GET_F_CREATE);\n\tif (v)\n\t\ttest_kptr(v);\n\treturn 0;\n}\n\nSEC(\"tc\")\nint test_sk_map_kptr(struct __sk_buff *ctx)\n{\n\tstruct map_value *v;\n\tstruct bpf_sock *sk;\n\n\tsk = ctx->sk;\n\tif (!sk)\n\t\treturn 0;\n\tv = bpf_sk_storage_get(&sk_ls_map, sk, NULL, BPF_LOCAL_STORAGE_GET_F_CREATE);\n\tif (v)\n\t\ttest_kptr(v);\n\treturn 0;\n}\n\nSEC(\"tc\")\nint test_map_in_map_kptr(struct __sk_buff *ctx)\n{\n\tstruct map_value *v;\n\tint key = 0;\n\tvoid *map;\n\n#define TEST(map_in_map)                                \\\n\tmap = bpf_map_lookup_elem(&map_in_map, &key);   \\\n\tif (!map)                                       \\\n\t\treturn 0;                               \\\n\tv = bpf_map_lookup_elem(map, &key);\t\t\\\n\tif (!v)\t\t\t\t\t\t\\\n\t\treturn 0;\t\t\t\t\\\n\ttest_kptr(v)\n\n\tTEST(array_of_array_maps);\n\tTEST(array_of_hash_maps);\n\tTEST(array_of_hash_malloc_maps);\n\tTEST(array_of_lru_hash_maps);\n\tTEST(hash_of_array_maps);\n\tTEST(hash_of_hash_maps);\n\tTEST(hash_of_hash_malloc_maps);\n\tTEST(hash_of_lru_hash_maps);\n\n#undef TEST\n\treturn 0;\n}\n\nint ref = 1;\n\nstatic __always_inline\nint test_map_kptr_ref_pre(struct map_value *v)\n{\n\tstruct prog_test_ref_kfunc *p, *p_st;\n\tunsigned long arg = 0;\n\tint ret;\n\n\tp = bpf_kfunc_call_test_acquire(&arg);\n\tif (!p)\n\t\treturn 1;\n\tref++;\n\n\tp_st = p->next;\n\tif (p_st->cnt.refs.counter != ref) {\n\t\tret = 2;\n\t\tgoto end;\n\t}\n\n\tp = bpf_kptr_xchg(&v->ref_ptr, p);\n\tif (p) {\n\t\tret = 3;\n\t\tgoto end;\n\t}\n\tif (p_st->cnt.refs.counter != ref)\n\t\treturn 4;\n\n\tp = bpf_kptr_xchg(&v->ref_ptr, NULL);\n\tif (!p)\n\t\treturn 5;\n\tbpf_kfunc_call_test_release(p);\n\tref--;\n\tif (p_st->cnt.refs.counter != ref)\n\t\treturn 6;\n\n\tp = bpf_kfunc_call_test_acquire(&arg);\n\tif (!p)\n\t\treturn 7;\n\tref++;\n\tp = bpf_kptr_xchg(&v->ref_ptr, p);\n\tif (p) {\n\t\tret = 8;\n\t\tgoto end;\n\t}\n\tif (p_st->cnt.refs.counter != ref)\n\t\treturn 9;\n\t \n\n\treturn 0;\nend:\n\tref--;\n\tbpf_kfunc_call_test_release(p);\n\treturn ret;\n}\n\nstatic __always_inline\nint test_map_kptr_ref_post(struct map_value *v)\n{\n\tstruct prog_test_ref_kfunc *p, *p_st;\n\n\tp_st = v->ref_ptr;\n\tif (!p_st || p_st->cnt.refs.counter != ref)\n\t\treturn 1;\n\n\tp = bpf_kptr_xchg(&v->ref_ptr, NULL);\n\tif (!p)\n\t\treturn 2;\n\tif (p_st->cnt.refs.counter != ref) {\n\t\tbpf_kfunc_call_test_release(p);\n\t\treturn 3;\n\t}\n\n\tp = bpf_kptr_xchg(&v->ref_ptr, p);\n\tif (p) {\n\t\tbpf_kfunc_call_test_release(p);\n\t\treturn 4;\n\t}\n\tif (p_st->cnt.refs.counter != ref)\n\t\treturn 5;\n\n\treturn 0;\n}\n\n#define TEST(map)                            \\\n\tv = bpf_map_lookup_elem(&map, &key); \\\n\tif (!v)                              \\\n\t\treturn -1;                   \\\n\tret = test_map_kptr_ref_pre(v);      \\\n\tif (ret)                             \\\n\t\treturn ret;\n\n#define TEST_PCPU(map)                                 \\\n\tv = bpf_map_lookup_percpu_elem(&map, &key, 0); \\\n\tif (!v)                                        \\\n\t\treturn -1;                             \\\n\tret = test_map_kptr_ref_pre(v);                \\\n\tif (ret)                                       \\\n\t\treturn ret;\n\nSEC(\"tc\")\nint test_map_kptr_ref1(struct __sk_buff *ctx)\n{\n\tstruct map_value *v, val = {};\n\tint key = 0, ret;\n\n\tbpf_map_update_elem(&hash_map, &key, &val, 0);\n\tbpf_map_update_elem(&hash_malloc_map, &key, &val, 0);\n\tbpf_map_update_elem(&lru_hash_map, &key, &val, 0);\n\n\tbpf_map_update_elem(&pcpu_hash_map, &key, &val, 0);\n\tbpf_map_update_elem(&pcpu_hash_malloc_map, &key, &val, 0);\n\tbpf_map_update_elem(&lru_pcpu_hash_map, &key, &val, 0);\n\n\tTEST(array_map);\n\tTEST(hash_map);\n\tTEST(hash_malloc_map);\n\tTEST(lru_hash_map);\n\n\tTEST_PCPU(pcpu_array_map);\n\tTEST_PCPU(pcpu_hash_map);\n\tTEST_PCPU(pcpu_hash_malloc_map);\n\tTEST_PCPU(lru_pcpu_hash_map);\n\n\treturn 0;\n}\n\n#undef TEST\n#undef TEST_PCPU\n\n#define TEST(map)                            \\\n\tv = bpf_map_lookup_elem(&map, &key); \\\n\tif (!v)                              \\\n\t\treturn -1;                   \\\n\tret = test_map_kptr_ref_post(v);     \\\n\tif (ret)                             \\\n\t\treturn ret;\n\n#define TEST_PCPU(map)                                 \\\n\tv = bpf_map_lookup_percpu_elem(&map, &key, 0); \\\n\tif (!v)                                        \\\n\t\treturn -1;                             \\\n\tret = test_map_kptr_ref_post(v);               \\\n\tif (ret)                                       \\\n\t\treturn ret;\n\nSEC(\"tc\")\nint test_map_kptr_ref2(struct __sk_buff *ctx)\n{\n\tstruct map_value *v;\n\tint key = 0, ret;\n\n\tTEST(array_map);\n\tTEST(hash_map);\n\tTEST(hash_malloc_map);\n\tTEST(lru_hash_map);\n\n\tTEST_PCPU(pcpu_array_map);\n\tTEST_PCPU(pcpu_hash_map);\n\tTEST_PCPU(pcpu_hash_malloc_map);\n\tTEST_PCPU(lru_pcpu_hash_map);\n\n\treturn 0;\n}\n\n#undef TEST\n#undef TEST_PCPU\n\nSEC(\"tc\")\nint test_map_kptr_ref3(struct __sk_buff *ctx)\n{\n\tstruct prog_test_ref_kfunc *p;\n\tunsigned long sp = 0;\n\n\tp = bpf_kfunc_call_test_acquire(&sp);\n\tif (!p)\n\t\treturn 1;\n\tref++;\n\tif (p->cnt.refs.counter != ref) {\n\t\tbpf_kfunc_call_test_release(p);\n\t\treturn 2;\n\t}\n\tbpf_kfunc_call_test_release(p);\n\tref--;\n\treturn 0;\n}\n\nSEC(\"syscall\")\nint test_ls_map_kptr_ref1(void *ctx)\n{\n\tstruct task_struct *current;\n\tstruct map_value *v;\n\n\tcurrent = bpf_get_current_task_btf();\n\tif (!current)\n\t\treturn 100;\n\tv = bpf_task_storage_get(&task_ls_map, current, NULL, 0);\n\tif (v)\n\t\treturn 150;\n\tv = bpf_task_storage_get(&task_ls_map, current, NULL, BPF_LOCAL_STORAGE_GET_F_CREATE);\n\tif (!v)\n\t\treturn 200;\n\treturn test_map_kptr_ref_pre(v);\n}\n\nSEC(\"syscall\")\nint test_ls_map_kptr_ref2(void *ctx)\n{\n\tstruct task_struct *current;\n\tstruct map_value *v;\n\n\tcurrent = bpf_get_current_task_btf();\n\tif (!current)\n\t\treturn 100;\n\tv = bpf_task_storage_get(&task_ls_map, current, NULL, 0);\n\tif (!v)\n\t\treturn 200;\n\treturn test_map_kptr_ref_post(v);\n}\n\nSEC(\"syscall\")\nint test_ls_map_kptr_ref_del(void *ctx)\n{\n\tstruct task_struct *current;\n\tstruct map_value *v;\n\n\tcurrent = bpf_get_current_task_btf();\n\tif (!current)\n\t\treturn 100;\n\tv = bpf_task_storage_get(&task_ls_map, current, NULL, 0);\n\tif (!v)\n\t\treturn 200;\n\tif (!v->ref_ptr)\n\t\treturn 300;\n\treturn bpf_task_storage_delete(&task_ls_map, current);\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}