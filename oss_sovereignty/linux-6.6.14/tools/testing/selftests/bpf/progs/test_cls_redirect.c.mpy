{
  "module_name": "test_cls_redirect.c",
  "hash_id": "75e51f5853d3145045f6d89f04e1d9f07a869f9c49f606ac0b00475f595e30eb",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/test_cls_redirect.c",
  "human_readable_source": "\n\n\n#include <stdbool.h>\n#include <stddef.h>\n#include <stdint.h>\n#include <string.h>\n\n#include <linux/bpf.h>\n#include <linux/icmp.h>\n#include <linux/icmpv6.h>\n#include <linux/if_ether.h>\n#include <linux/in.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/pkt_cls.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n\n#include <bpf/bpf_helpers.h>\n#include <bpf/bpf_endian.h>\n\n#include \"test_cls_redirect.h\"\n\n#ifdef SUBPROGS\n#define INLINING __noinline\n#else\n#define INLINING __always_inline\n#endif\n\n#define offsetofend(TYPE, MEMBER) \\\n\t(offsetof(TYPE, MEMBER) + sizeof((((TYPE *)0)->MEMBER)))\n\n#define IP_OFFSET_MASK (0x1FFF)\n#define IP_MF (0x2000)\n\nchar _license[] SEC(\"license\") = \"Dual BSD/GPL\";\n\n \nvolatile const __be16 ENCAPSULATION_PORT;\nvolatile const __be32 ENCAPSULATION_IP;\n\ntypedef struct {\n\tuint64_t processed_packets_total;\n\tuint64_t l3_protocol_packets_total_ipv4;\n\tuint64_t l3_protocol_packets_total_ipv6;\n\tuint64_t l4_protocol_packets_total_tcp;\n\tuint64_t l4_protocol_packets_total_udp;\n\tuint64_t accepted_packets_total_syn;\n\tuint64_t accepted_packets_total_syn_cookies;\n\tuint64_t accepted_packets_total_last_hop;\n\tuint64_t accepted_packets_total_icmp_echo_request;\n\tuint64_t accepted_packets_total_established;\n\tuint64_t forwarded_packets_total_gue;\n\tuint64_t forwarded_packets_total_gre;\n\n\tuint64_t errors_total_unknown_l3_proto;\n\tuint64_t errors_total_unknown_l4_proto;\n\tuint64_t errors_total_malformed_ip;\n\tuint64_t errors_total_fragmented_ip;\n\tuint64_t errors_total_malformed_icmp;\n\tuint64_t errors_total_unwanted_icmp;\n\tuint64_t errors_total_malformed_icmp_pkt_too_big;\n\tuint64_t errors_total_malformed_tcp;\n\tuint64_t errors_total_malformed_udp;\n\tuint64_t errors_total_icmp_echo_replies;\n\tuint64_t errors_total_malformed_encapsulation;\n\tuint64_t errors_total_encap_adjust_failed;\n\tuint64_t errors_total_encap_buffer_too_small;\n\tuint64_t errors_total_redirect_loop;\n\tuint64_t errors_total_encap_mtu_violate;\n} metrics_t;\n\ntypedef enum {\n\tINVALID = 0,\n\tUNKNOWN,\n\tECHO_REQUEST,\n\tSYN,\n\tSYN_COOKIE,\n\tESTABLISHED,\n} verdict_t;\n\ntypedef struct {\n\tuint16_t src, dst;\n} flow_ports_t;\n\n_Static_assert(\n\tsizeof(flow_ports_t) !=\n\t\toffsetofend(struct bpf_sock_tuple, ipv4.dport) -\n\t\t\toffsetof(struct bpf_sock_tuple, ipv4.sport) - 1,\n\t\"flow_ports_t must match sport and dport in struct bpf_sock_tuple\");\n_Static_assert(\n\tsizeof(flow_ports_t) !=\n\t\toffsetofend(struct bpf_sock_tuple, ipv6.dport) -\n\t\t\toffsetof(struct bpf_sock_tuple, ipv6.sport) - 1,\n\t\"flow_ports_t must match sport and dport in struct bpf_sock_tuple\");\n\ntypedef int ret_t;\n\n \nstatic const ret_t CONTINUE_PROCESSING = -1;\n\n \n#define MAYBE_RETURN(x)                           \\\n\tdo {                                      \\\n\t\tret_t __ret = x;                  \\\n\t\tif (__ret != CONTINUE_PROCESSING) \\\n\t\t\treturn __ret;             \\\n\t} while (0)\n\n \ntypedef uint8_t *net_ptr __attribute__((align_value(8)));\n\ntypedef struct buf {\n\tstruct __sk_buff *skb;\n\tnet_ptr head;\n\t \n\tuint8_t *const tail;\n} buf_t;\n\nstatic __always_inline size_t buf_off(const buf_t *buf)\n{\n\t \n\tsize_t off = (size_t)buf->head;\n\tasm(\"%0 -= %1\" : \"+r\"(off) : \"r\"(buf->skb->data));\n\treturn off;\n}\n\nstatic __always_inline bool buf_copy(buf_t *buf, void *dst, size_t len)\n{\n\tif (bpf_skb_load_bytes(buf->skb, buf_off(buf), dst, len)) {\n\t\treturn false;\n\t}\n\n\tbuf->head += len;\n\treturn true;\n}\n\nstatic __always_inline bool buf_skip(buf_t *buf, const size_t len)\n{\n\t \n\tif (buf_off(buf) + len > buf->skb->len) {\n\t\treturn false;\n\t}\n\n\tbuf->head += len;\n\treturn true;\n}\n\n \nstatic __always_inline void *buf_assign(buf_t *buf, const size_t len, void *scratch)\n{\n\tif (buf->head + len > buf->tail) {\n\t\tif (scratch == NULL) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\treturn buf_copy(buf, scratch, len) ? scratch : NULL;\n\t}\n\n\tvoid *ptr = buf->head;\n\tbuf->head += len;\n\treturn ptr;\n}\n\nstatic INLINING bool pkt_skip_ipv4_options(buf_t *buf, const struct iphdr *ipv4)\n{\n\tif (ipv4->ihl <= 5) {\n\t\treturn true;\n\t}\n\n\treturn buf_skip(buf, (ipv4->ihl - 5) * 4);\n}\n\nstatic INLINING bool ipv4_is_fragment(const struct iphdr *ip)\n{\n\tuint16_t frag_off = ip->frag_off & bpf_htons(IP_OFFSET_MASK);\n\treturn (ip->frag_off & bpf_htons(IP_MF)) != 0 || frag_off > 0;\n}\n\nstatic __always_inline struct iphdr *pkt_parse_ipv4(buf_t *pkt, struct iphdr *scratch)\n{\n\tstruct iphdr *ipv4 = buf_assign(pkt, sizeof(*ipv4), scratch);\n\tif (ipv4 == NULL) {\n\t\treturn NULL;\n\t}\n\n\tif (ipv4->ihl < 5) {\n\t\treturn NULL;\n\t}\n\n\tif (!pkt_skip_ipv4_options(pkt, ipv4)) {\n\t\treturn NULL;\n\t}\n\n\treturn ipv4;\n}\n\n \nstatic INLINING bool pkt_parse_icmp_l4_ports(buf_t *pkt, flow_ports_t *ports)\n{\n\tif (!buf_copy(pkt, ports, sizeof(*ports))) {\n\t\treturn false;\n\t}\n\n\t \n\tuint16_t dst = ports->src;\n\tports->src = ports->dst;\n\tports->dst = dst;\n\treturn true;\n}\n\nstatic INLINING uint16_t pkt_checksum_fold(uint32_t csum)\n{\n\t \n\tcsum = (csum & 0xffff) + (csum >> 16);\n\tcsum = (csum & 0xffff) + (csum >> 16);\n\treturn (uint16_t)~csum;\n}\n\nstatic INLINING void pkt_ipv4_checksum(struct iphdr *iph)\n{\n\tiph->check = 0;\n\n\t \n\t_Static_assert(sizeof(struct iphdr) == 20, \"iphdr must be 20 bytes\");\n\tuint32_t acc = 0;\n\tuint16_t *ipw = (uint16_t *)iph;\n\n#pragma clang loop unroll(full)\n\tfor (size_t i = 0; i < sizeof(struct iphdr) / 2; i++) {\n\t\tacc += ipw[i];\n\t}\n\n\tiph->check = pkt_checksum_fold(acc);\n}\n\nstatic INLINING\nbool pkt_skip_ipv6_extension_headers(buf_t *pkt,\n\t\t\t\t     const struct ipv6hdr *ipv6,\n\t\t\t\t     uint8_t *upper_proto,\n\t\t\t\t     bool *is_fragment)\n{\n\t \n\tstruct {\n\t\tuint8_t next;\n\t\tuint8_t len;\n\t} exthdr = {\n\t\t.next = ipv6->nexthdr,\n\t};\n\t*is_fragment = false;\n\n#pragma clang loop unroll(full)\n\tfor (int i = 0; i < 6; i++) {\n\t\tswitch (exthdr.next) {\n\t\tcase IPPROTO_FRAGMENT:\n\t\t\t*is_fragment = true;\n\t\t\t \n\t\t\t \n\n\t\tcase IPPROTO_HOPOPTS:\n\t\tcase IPPROTO_ROUTING:\n\t\tcase IPPROTO_DSTOPTS:\n\t\tcase IPPROTO_MH:\n\t\t\tif (!buf_copy(pkt, &exthdr, sizeof(exthdr))) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (!buf_skip(pkt,\n\t\t\t\t      (exthdr.len + 1) * 8 - sizeof(exthdr))) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\t \n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\t \n\t\t\t*upper_proto = exthdr.next;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t \n\treturn false;\n}\n\n \nstatic __always_inline struct ipv6hdr *\npkt_parse_ipv6(buf_t *pkt, struct ipv6hdr *scratch, uint8_t *proto,\n\t       bool *is_fragment)\n{\n\tstruct ipv6hdr *ipv6 = buf_assign(pkt, sizeof(*ipv6), scratch);\n\tif (ipv6 == NULL) {\n\t\treturn NULL;\n\t}\n\n\tif (!pkt_skip_ipv6_extension_headers(pkt, ipv6, proto, is_fragment)) {\n\t\treturn NULL;\n\t}\n\n\treturn ipv6;\n}\n\n \nstruct {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);\n\t__uint(max_entries, 1);\n\t__type(key, unsigned int);\n\t__type(value, metrics_t);\n} metrics_map SEC(\".maps\");\n\nstatic INLINING metrics_t *get_global_metrics(void)\n{\n\tuint64_t key = 0;\n\treturn bpf_map_lookup_elem(&metrics_map, &key);\n}\n\nstatic INLINING ret_t accept_locally(struct __sk_buff *skb, encap_headers_t *encap)\n{\n\tconst int payload_off =\n\t\tsizeof(*encap) +\n\t\tsizeof(struct in_addr) * encap->unigue.hop_count;\n\tint32_t encap_overhead = payload_off - sizeof(struct ethhdr);\n\n\t \n\tif (encap->gue.proto_ctype == IPPROTO_IPV6) {\n\t\tencap->eth.h_proto = bpf_htons(ETH_P_IPV6);\n\t}\n\n\tif (bpf_skb_adjust_room(skb, -encap_overhead, BPF_ADJ_ROOM_MAC,\n\t\t\t\tBPF_F_ADJ_ROOM_FIXED_GSO |\n\t\t\t\tBPF_F_ADJ_ROOM_NO_CSUM_RESET) ||\n\t    bpf_csum_level(skb, BPF_CSUM_LEVEL_DEC))\n\t\treturn TC_ACT_SHOT;\n\n\treturn bpf_redirect(skb->ifindex, BPF_F_INGRESS);\n}\n\nstatic INLINING ret_t forward_with_gre(struct __sk_buff *skb, encap_headers_t *encap,\n\t\t\t\t       struct in_addr *next_hop, metrics_t *metrics)\n{\n\tmetrics->forwarded_packets_total_gre++;\n\n\tconst int payload_off =\n\t\tsizeof(*encap) +\n\t\tsizeof(struct in_addr) * encap->unigue.hop_count;\n\tint32_t encap_overhead =\n\t\tpayload_off - sizeof(struct ethhdr) - sizeof(struct iphdr);\n\tint32_t delta = sizeof(struct gre_base_hdr) - encap_overhead;\n\tuint16_t proto = ETH_P_IP;\n\tuint32_t mtu_len = 0;\n\n\t \n\tif (encap->gue.proto_ctype == IPPROTO_IPV6) {\n\t\tproto = ETH_P_IPV6;\n\t\tuint8_t ttl;\n\t\tint rc;\n\n\t\trc = bpf_skb_load_bytes(\n\t\t\tskb, payload_off + offsetof(struct ipv6hdr, hop_limit),\n\t\t\t&ttl, 1);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tif (ttl == 0) {\n\t\t\tmetrics->errors_total_redirect_loop++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tttl--;\n\t\trc = bpf_skb_store_bytes(\n\t\t\tskb, payload_off + offsetof(struct ipv6hdr, hop_limit),\n\t\t\t&ttl, 1, 0);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\t} else {\n\t\tuint8_t ttl;\n\t\tint rc;\n\n\t\trc = bpf_skb_load_bytes(\n\t\t\tskb, payload_off + offsetof(struct iphdr, ttl), &ttl,\n\t\t\t1);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tif (ttl == 0) {\n\t\t\tmetrics->errors_total_redirect_loop++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\t \n\t\trc = bpf_l3_csum_replace(\n\t\t\tskb, payload_off + offsetof(struct iphdr, check), ttl,\n\t\t\tttl - 1, 2);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tttl--;\n\t\trc = bpf_skb_store_bytes(\n\t\t\tskb, payload_off + offsetof(struct iphdr, ttl), &ttl, 1,\n\t\t\t0);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\t}\n\n\tif (bpf_check_mtu(skb, skb->ifindex, &mtu_len, delta, 0)) {\n\t\tmetrics->errors_total_encap_mtu_violate++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (bpf_skb_adjust_room(skb, delta, BPF_ADJ_ROOM_NET,\n\t\t\t\tBPF_F_ADJ_ROOM_FIXED_GSO |\n\t\t\t\tBPF_F_ADJ_ROOM_NO_CSUM_RESET) ||\n\t    bpf_csum_level(skb, BPF_CSUM_LEVEL_INC)) {\n\t\tmetrics->errors_total_encap_adjust_failed++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (bpf_skb_pull_data(skb, sizeof(encap_gre_t))) {\n\t\tmetrics->errors_total_encap_buffer_too_small++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tbuf_t pkt = {\n\t\t.skb = skb,\n\t\t.head = (uint8_t *)(long)skb->data,\n\t\t.tail = (uint8_t *)(long)skb->data_end,\n\t};\n\n\tencap_gre_t *encap_gre = buf_assign(&pkt, sizeof(encap_gre_t), NULL);\n\tif (encap_gre == NULL) {\n\t\tmetrics->errors_total_encap_buffer_too_small++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tencap_gre->ip.protocol = IPPROTO_GRE;\n\tencap_gre->ip.daddr = next_hop->s_addr;\n\tencap_gre->ip.saddr = ENCAPSULATION_IP;\n\tencap_gre->ip.tot_len =\n\t\tbpf_htons(bpf_ntohs(encap_gre->ip.tot_len) + delta);\n\tencap_gre->gre.flags = 0;\n\tencap_gre->gre.protocol = bpf_htons(proto);\n\tpkt_ipv4_checksum((void *)&encap_gre->ip);\n\n\treturn bpf_redirect(skb->ifindex, 0);\n}\n\nstatic INLINING ret_t forward_to_next_hop(struct __sk_buff *skb, encap_headers_t *encap,\n\t\t\t\t\t  struct in_addr *next_hop, metrics_t *metrics)\n{\n\t \n\t \n\tunsigned char temp[ETH_ALEN];\n\tmemcpy(temp, encap->eth.h_dest, sizeof(temp));\n\tmemcpy(encap->eth.h_dest, encap->eth.h_source,\n\t       sizeof(encap->eth.h_dest));\n\tmemcpy(encap->eth.h_source, temp, sizeof(encap->eth.h_source));\n\n\tif (encap->unigue.next_hop == encap->unigue.hop_count - 1 &&\n\t    encap->unigue.last_hop_gre) {\n\t\treturn forward_with_gre(skb, encap, next_hop, metrics);\n\t}\n\n\tmetrics->forwarded_packets_total_gue++;\n\tuint32_t old_saddr = encap->ip.saddr;\n\tencap->ip.saddr = encap->ip.daddr;\n\tencap->ip.daddr = next_hop->s_addr;\n\tif (encap->unigue.next_hop < encap->unigue.hop_count) {\n\t\tencap->unigue.next_hop++;\n\t}\n\n\t \n\tconst uint64_t off = offsetof(typeof(*encap), ip.check);\n\tint ret = bpf_l3_csum_replace(skb, off, old_saddr, next_hop->s_addr, 4);\n\tif (ret < 0) {\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\treturn bpf_redirect(skb->ifindex, 0);\n}\n\nstatic INLINING ret_t skip_next_hops(buf_t *pkt, int n)\n{\n\tswitch (n) {\n\tcase 1:\n\t\tif (!buf_skip(pkt, sizeof(struct in_addr)))\n\t\t\treturn TC_ACT_SHOT;\n\tcase 0:\n\t\treturn CONTINUE_PROCESSING;\n\n\tdefault:\n\t\treturn TC_ACT_SHOT;\n\t}\n}\n\n \nstatic INLINING ret_t get_next_hop(buf_t *pkt, encap_headers_t *encap,\n\t\t\t\t   struct in_addr *next_hop)\n{\n\tif (encap->unigue.next_hop > encap->unigue.hop_count) {\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\t \n\tMAYBE_RETURN(skip_next_hops(pkt, encap->unigue.next_hop));\n\n\tif (encap->unigue.next_hop == encap->unigue.hop_count) {\n\t\t \n\t\tnext_hop->s_addr = 0;\n\t\treturn CONTINUE_PROCESSING;\n\t}\n\n\tif (!buf_copy(pkt, next_hop, sizeof(*next_hop))) {\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\t \n\treturn skip_next_hops(pkt, encap->unigue.hop_count -\n\t\t\t\t\t   encap->unigue.next_hop - 1);\n}\n\n \nstatic INLINING uint64_t fill_tuple(struct bpf_sock_tuple *tuple, void *iph,\n\t\t\t\t    uint64_t iphlen, uint16_t sport, uint16_t dport)\n{\n\tswitch (iphlen) {\n\tcase sizeof(struct iphdr): {\n\t\tstruct iphdr *ipv4 = (struct iphdr *)iph;\n\t\ttuple->ipv4.daddr = ipv4->daddr;\n\t\ttuple->ipv4.saddr = ipv4->saddr;\n\t\ttuple->ipv4.sport = sport;\n\t\ttuple->ipv4.dport = dport;\n\t\treturn sizeof(tuple->ipv4);\n\t}\n\n\tcase sizeof(struct ipv6hdr): {\n\t\tstruct ipv6hdr *ipv6 = (struct ipv6hdr *)iph;\n\t\tmemcpy(&tuple->ipv6.daddr, &ipv6->daddr,\n\t\t       sizeof(tuple->ipv6.daddr));\n\t\tmemcpy(&tuple->ipv6.saddr, &ipv6->saddr,\n\t\t       sizeof(tuple->ipv6.saddr));\n\t\ttuple->ipv6.sport = sport;\n\t\ttuple->ipv6.dport = dport;\n\t\treturn sizeof(tuple->ipv6);\n\t}\n\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic INLINING verdict_t classify_tcp(struct __sk_buff *skb,\n\t\t\t\t       struct bpf_sock_tuple *tuple, uint64_t tuplen,\n\t\t\t\t       void *iph, struct tcphdr *tcp)\n{\n\tstruct bpf_sock *sk =\n\t\tbpf_skc_lookup_tcp(skb, tuple, tuplen, BPF_F_CURRENT_NETNS, 0);\n\tif (sk == NULL) {\n\t\treturn UNKNOWN;\n\t}\n\n\tif (sk->state != BPF_TCP_LISTEN) {\n\t\tbpf_sk_release(sk);\n\t\treturn ESTABLISHED;\n\t}\n\n\tif (iph != NULL && tcp != NULL) {\n\t\t \n\t\tuint64_t iphlen = sizeof(struct iphdr);\n\t\tif (tuplen == sizeof(tuple->ipv6)) {\n\t\t\tiphlen = sizeof(struct ipv6hdr);\n\t\t}\n\n\t\tif (bpf_tcp_check_syncookie(sk, iph, iphlen, tcp,\n\t\t\t\t\t    sizeof(*tcp)) == 0) {\n\t\t\tbpf_sk_release(sk);\n\t\t\treturn SYN_COOKIE;\n\t\t}\n\t}\n\n\tbpf_sk_release(sk);\n\treturn UNKNOWN;\n}\n\nstatic INLINING verdict_t classify_udp(struct __sk_buff *skb,\n\t\t\t\t       struct bpf_sock_tuple *tuple, uint64_t tuplen)\n{\n\tstruct bpf_sock *sk =\n\t\tbpf_sk_lookup_udp(skb, tuple, tuplen, BPF_F_CURRENT_NETNS, 0);\n\tif (sk == NULL) {\n\t\treturn UNKNOWN;\n\t}\n\n\tif (sk->state == BPF_TCP_ESTABLISHED) {\n\t\tbpf_sk_release(sk);\n\t\treturn ESTABLISHED;\n\t}\n\n\tbpf_sk_release(sk);\n\treturn UNKNOWN;\n}\n\nstatic INLINING verdict_t classify_icmp(struct __sk_buff *skb, uint8_t proto,\n\t\t\t\t\tstruct bpf_sock_tuple *tuple, uint64_t tuplen,\n\t\t\t\t\tmetrics_t *metrics)\n{\n\tswitch (proto) {\n\tcase IPPROTO_TCP:\n\t\treturn classify_tcp(skb, tuple, tuplen, NULL, NULL);\n\n\tcase IPPROTO_UDP:\n\t\treturn classify_udp(skb, tuple, tuplen);\n\n\tdefault:\n\t\tmetrics->errors_total_malformed_icmp++;\n\t\treturn INVALID;\n\t}\n}\n\nstatic INLINING verdict_t process_icmpv4(buf_t *pkt, metrics_t *metrics)\n{\n\tstruct icmphdr icmp;\n\tif (!buf_copy(pkt, &icmp, sizeof(icmp))) {\n\t\tmetrics->errors_total_malformed_icmp++;\n\t\treturn INVALID;\n\t}\n\n\t \n\tif (icmp.type == ICMP_ECHOREPLY) {\n\t\tmetrics->errors_total_icmp_echo_replies++;\n\t\treturn INVALID;\n\t}\n\n\tif (icmp.type == ICMP_ECHO) {\n\t\treturn ECHO_REQUEST;\n\t}\n\n\tif (icmp.type != ICMP_DEST_UNREACH || icmp.code != ICMP_FRAG_NEEDED) {\n\t\tmetrics->errors_total_unwanted_icmp++;\n\t\treturn INVALID;\n\t}\n\n\tstruct iphdr _ip4;\n\tconst struct iphdr *ipv4 = pkt_parse_ipv4(pkt, &_ip4);\n\tif (ipv4 == NULL) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\t \n\tstruct bpf_sock_tuple tuple;\n\ttuple.ipv4.saddr = ipv4->daddr;\n\ttuple.ipv4.daddr = ipv4->saddr;\n\n\tif (!pkt_parse_icmp_l4_ports(pkt, (flow_ports_t *)&tuple.ipv4.sport)) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\treturn classify_icmp(pkt->skb, ipv4->protocol, &tuple,\n\t\t\t     sizeof(tuple.ipv4), metrics);\n}\n\nstatic INLINING verdict_t process_icmpv6(buf_t *pkt, metrics_t *metrics)\n{\n\tstruct icmp6hdr icmp6;\n\tif (!buf_copy(pkt, &icmp6, sizeof(icmp6))) {\n\t\tmetrics->errors_total_malformed_icmp++;\n\t\treturn INVALID;\n\t}\n\n\t \n\tif (icmp6.icmp6_type == ICMPV6_ECHO_REPLY) {\n\t\tmetrics->errors_total_icmp_echo_replies++;\n\t\treturn INVALID;\n\t}\n\n\tif (icmp6.icmp6_type == ICMPV6_ECHO_REQUEST) {\n\t\treturn ECHO_REQUEST;\n\t}\n\n\tif (icmp6.icmp6_type != ICMPV6_PKT_TOOBIG) {\n\t\tmetrics->errors_total_unwanted_icmp++;\n\t\treturn INVALID;\n\t}\n\n\tbool is_fragment;\n\tuint8_t l4_proto;\n\tstruct ipv6hdr _ipv6;\n\tconst struct ipv6hdr *ipv6 =\n\t\tpkt_parse_ipv6(pkt, &_ipv6, &l4_proto, &is_fragment);\n\tif (ipv6 == NULL) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\tif (is_fragment) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn INVALID;\n\t}\n\n\t \n\tstruct bpf_sock_tuple tuple;\n\tmemcpy(&tuple.ipv6.saddr, &ipv6->daddr, sizeof(tuple.ipv6.saddr));\n\tmemcpy(&tuple.ipv6.daddr, &ipv6->saddr, sizeof(tuple.ipv6.daddr));\n\n\tif (!pkt_parse_icmp_l4_ports(pkt, (flow_ports_t *)&tuple.ipv6.sport)) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\treturn classify_icmp(pkt->skb, l4_proto, &tuple, sizeof(tuple.ipv6),\n\t\t\t     metrics);\n}\n\nstatic INLINING verdict_t process_tcp(buf_t *pkt, void *iph, uint64_t iphlen,\n\t\t\t\t      metrics_t *metrics)\n{\n\tmetrics->l4_protocol_packets_total_tcp++;\n\n\tstruct tcphdr _tcp;\n\tstruct tcphdr *tcp = buf_assign(pkt, sizeof(_tcp), &_tcp);\n\tif (tcp == NULL) {\n\t\tmetrics->errors_total_malformed_tcp++;\n\t\treturn INVALID;\n\t}\n\n\tif (tcp->syn) {\n\t\treturn SYN;\n\t}\n\n\tstruct bpf_sock_tuple tuple;\n\tuint64_t tuplen =\n\t\tfill_tuple(&tuple, iph, iphlen, tcp->source, tcp->dest);\n\treturn classify_tcp(pkt->skb, &tuple, tuplen, iph, tcp);\n}\n\nstatic INLINING verdict_t process_udp(buf_t *pkt, void *iph, uint64_t iphlen,\n\t\t\t\t      metrics_t *metrics)\n{\n\tmetrics->l4_protocol_packets_total_udp++;\n\n\tstruct udphdr _udp;\n\tstruct udphdr *udph = buf_assign(pkt, sizeof(_udp), &_udp);\n\tif (udph == NULL) {\n\t\tmetrics->errors_total_malformed_udp++;\n\t\treturn INVALID;\n\t}\n\n\tstruct bpf_sock_tuple tuple;\n\tuint64_t tuplen =\n\t\tfill_tuple(&tuple, iph, iphlen, udph->source, udph->dest);\n\treturn classify_udp(pkt->skb, &tuple, tuplen);\n}\n\nstatic INLINING verdict_t process_ipv4(buf_t *pkt, metrics_t *metrics)\n{\n\tmetrics->l3_protocol_packets_total_ipv4++;\n\n\tstruct iphdr _ip4;\n\tstruct iphdr *ipv4 = pkt_parse_ipv4(pkt, &_ip4);\n\tif (ipv4 == NULL) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (ipv4->version != 4) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (ipv4_is_fragment(ipv4)) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn INVALID;\n\t}\n\n\tswitch (ipv4->protocol) {\n\tcase IPPROTO_ICMP:\n\t\treturn process_icmpv4(pkt, metrics);\n\n\tcase IPPROTO_TCP:\n\t\treturn process_tcp(pkt, ipv4, sizeof(*ipv4), metrics);\n\n\tcase IPPROTO_UDP:\n\t\treturn process_udp(pkt, ipv4, sizeof(*ipv4), metrics);\n\n\tdefault:\n\t\tmetrics->errors_total_unknown_l4_proto++;\n\t\treturn INVALID;\n\t}\n}\n\nstatic INLINING verdict_t process_ipv6(buf_t *pkt, metrics_t *metrics)\n{\n\tmetrics->l3_protocol_packets_total_ipv6++;\n\n\tuint8_t l4_proto;\n\tbool is_fragment;\n\tstruct ipv6hdr _ipv6;\n\tstruct ipv6hdr *ipv6 =\n\t\tpkt_parse_ipv6(pkt, &_ipv6, &l4_proto, &is_fragment);\n\tif (ipv6 == NULL) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (ipv6->version != 6) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (is_fragment) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn INVALID;\n\t}\n\n\tswitch (l4_proto) {\n\tcase IPPROTO_ICMPV6:\n\t\treturn process_icmpv6(pkt, metrics);\n\n\tcase IPPROTO_TCP:\n\t\treturn process_tcp(pkt, ipv6, sizeof(*ipv6), metrics);\n\n\tcase IPPROTO_UDP:\n\t\treturn process_udp(pkt, ipv6, sizeof(*ipv6), metrics);\n\n\tdefault:\n\t\tmetrics->errors_total_unknown_l4_proto++;\n\t\treturn INVALID;\n\t}\n}\n\nSEC(\"tc\")\nint cls_redirect(struct __sk_buff *skb)\n{\n\tmetrics_t *metrics = get_global_metrics();\n\tif (metrics == NULL) {\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tmetrics->processed_packets_total++;\n\n\t \n\tif (skb->protocol != bpf_htons(ETH_P_IP)) {\n\t\treturn TC_ACT_OK;\n\t}\n\n\tencap_headers_t *encap;\n\n\t \n\tif (bpf_skb_pull_data(skb, sizeof(*encap))) {\n\t\treturn TC_ACT_OK;\n\t}\n\n\tbuf_t pkt = {\n\t\t.skb = skb,\n\t\t.head = (uint8_t *)(long)skb->data,\n\t\t.tail = (uint8_t *)(long)skb->data_end,\n\t};\n\n\tencap = buf_assign(&pkt, sizeof(*encap), NULL);\n\tif (encap == NULL) {\n\t\treturn TC_ACT_OK;\n\t}\n\n\tif (encap->ip.ihl != 5) {\n\t\t \n\t\treturn TC_ACT_OK;\n\t}\n\n\tif (encap->ip.daddr != ENCAPSULATION_IP ||\n\t    encap->ip.protocol != IPPROTO_UDP) {\n\t\treturn TC_ACT_OK;\n\t}\n\n\t \n\tif (encap->udp.dest != ENCAPSULATION_PORT) {\n\t\treturn TC_ACT_OK;\n\t}\n\n\t \n\tif (ipv4_is_fragment((void *)&encap->ip)) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.variant != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.control != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.flags != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.hlen !=\n\t    sizeof(encap->unigue) / 4 + encap->unigue.hop_count) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->unigue.version != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->unigue.reserved != 0) {\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tstruct in_addr next_hop;\n\tMAYBE_RETURN(get_next_hop(&pkt, encap, &next_hop));\n\n\tif (next_hop.s_addr == 0) {\n\t\tmetrics->accepted_packets_total_last_hop++;\n\t\treturn accept_locally(skb, encap);\n\t}\n\n\tverdict_t verdict;\n\tswitch (encap->gue.proto_ctype) {\n\tcase IPPROTO_IPIP:\n\t\tverdict = process_ipv4(&pkt, metrics);\n\t\tbreak;\n\n\tcase IPPROTO_IPV6:\n\t\tverdict = process_ipv6(&pkt, metrics);\n\t\tbreak;\n\n\tdefault:\n\t\tmetrics->errors_total_unknown_l3_proto++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tswitch (verdict) {\n\tcase INVALID:\n\t\t \n\t\treturn TC_ACT_SHOT;\n\n\tcase UNKNOWN:\n\t\treturn forward_to_next_hop(skb, encap, &next_hop, metrics);\n\n\tcase ECHO_REQUEST:\n\t\tmetrics->accepted_packets_total_icmp_echo_request++;\n\t\tbreak;\n\n\tcase SYN:\n\t\tif (encap->unigue.forward_syn) {\n\t\t\treturn forward_to_next_hop(skb, encap, &next_hop,\n\t\t\t\t\t\t   metrics);\n\t\t}\n\n\t\tmetrics->accepted_packets_total_syn++;\n\t\tbreak;\n\n\tcase SYN_COOKIE:\n\t\tmetrics->accepted_packets_total_syn_cookies++;\n\t\tbreak;\n\n\tcase ESTABLISHED:\n\t\tmetrics->accepted_packets_total_established++;\n\t\tbreak;\n\t}\n\n\treturn accept_locally(skb, encap);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}