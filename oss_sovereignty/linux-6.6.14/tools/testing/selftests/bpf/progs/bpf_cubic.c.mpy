{
  "module_name": "bpf_cubic.c",
  "hash_id": "2fea1c8cace9963e3e359276e09c700656530444f7419ea1bd45d426c5e018fa",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/bpf_cubic.c",
  "human_readable_source": "\n\n \n\n#include <linux/bpf.h>\n#include <linux/stddef.h>\n#include <linux/tcp.h>\n#include \"bpf_tcp_helpers.h\"\n\nchar _license[] SEC(\"license\") = \"GPL\";\n\n#define clamp(val, lo, hi) min((typeof(val))max(val, lo), hi)\n\n#define BICTCP_BETA_SCALE    1024\t \n#define\tBICTCP_HZ\t\t10\t \n\n \n#define HYSTART_ACK_TRAIN\t0x1\n#define HYSTART_DELAY\t\t0x2\n\n \n#define HYSTART_MIN_SAMPLES\t8\n#define HYSTART_DELAY_MIN\t(4000U)\t \n#define HYSTART_DELAY_MAX\t(16000U)\t \n#define HYSTART_DELAY_THRESH(x)\tclamp(x, HYSTART_DELAY_MIN, HYSTART_DELAY_MAX)\n\nstatic int fast_convergence = 1;\nstatic const int beta = 717;\t \nstatic int initial_ssthresh;\nstatic const int bic_scale = 41;\nstatic int tcp_friendliness = 1;\n\nstatic int hystart = 1;\nstatic int hystart_detect = HYSTART_ACK_TRAIN | HYSTART_DELAY;\nstatic int hystart_low_window = 16;\nstatic int hystart_ack_delta_us = 2000;\n\nstatic const __u32 cube_rtt_scale = (bic_scale * 10);\t \nstatic const __u32 beta_scale = 8*(BICTCP_BETA_SCALE+beta) / 3\n\t\t\t\t/ (BICTCP_BETA_SCALE - beta);\n \n\n \nstatic const __u64 cube_factor = (__u64)(1ull << (10+3*BICTCP_HZ))\n\t\t\t\t/ (bic_scale * 10);\n\n \nstruct bictcp {\n\t__u32\tcnt;\t\t \n\t__u32\tlast_max_cwnd;\t \n\t__u32\tlast_cwnd;\t \n\t__u32\tlast_time;\t \n\t__u32\tbic_origin_point; \n\t__u32\tbic_K;\t\t \n\t__u32\tdelay_min;\t \n\t__u32\tepoch_start;\t \n\t__u32\tack_cnt;\t \n\t__u32\ttcp_cwnd;\t \n\t__u16\tunused;\n\t__u8\tsample_cnt;\t \n\t__u8\tfound;\t\t \n\t__u32\tround_start;\t \n\t__u32\tend_seq;\t \n\t__u32\tlast_ack;\t \n\t__u32\tcurr_rtt;\t \n};\n\nstatic inline void bictcp_reset(struct bictcp *ca)\n{\n\tca->cnt = 0;\n\tca->last_max_cwnd = 0;\n\tca->last_cwnd = 0;\n\tca->last_time = 0;\n\tca->bic_origin_point = 0;\n\tca->bic_K = 0;\n\tca->delay_min = 0;\n\tca->epoch_start = 0;\n\tca->ack_cnt = 0;\n\tca->tcp_cwnd = 0;\n\tca->found = 0;\n}\n\nextern unsigned long CONFIG_HZ __kconfig;\n#define HZ CONFIG_HZ\n#define USEC_PER_MSEC\t1000UL\n#define USEC_PER_SEC\t1000000UL\n#define USEC_PER_JIFFY\t(USEC_PER_SEC / HZ)\n\nstatic __always_inline __u64 div64_u64(__u64 dividend, __u64 divisor)\n{\n\treturn dividend / divisor;\n}\n\n#define div64_ul div64_u64\n\n#define BITS_PER_U64 (sizeof(__u64) * 8)\nstatic __always_inline int fls64(__u64 x)\n{\n\tint num = BITS_PER_U64 - 1;\n\n\tif (x == 0)\n\t\treturn 0;\n\n\tif (!(x & (~0ull << (BITS_PER_U64-32)))) {\n\t\tnum -= 32;\n\t\tx <<= 32;\n\t}\n\tif (!(x & (~0ull << (BITS_PER_U64-16)))) {\n\t\tnum -= 16;\n\t\tx <<= 16;\n\t}\n\tif (!(x & (~0ull << (BITS_PER_U64-8)))) {\n\t\tnum -= 8;\n\t\tx <<= 8;\n\t}\n\tif (!(x & (~0ull << (BITS_PER_U64-4)))) {\n\t\tnum -= 4;\n\t\tx <<= 4;\n\t}\n\tif (!(x & (~0ull << (BITS_PER_U64-2)))) {\n\t\tnum -= 2;\n\t\tx <<= 2;\n\t}\n\tif (!(x & (~0ull << (BITS_PER_U64-1))))\n\t\tnum -= 1;\n\n\treturn num + 1;\n}\n\nstatic __always_inline __u32 bictcp_clock_us(const struct sock *sk)\n{\n\treturn tcp_sk(sk)->tcp_mstamp;\n}\n\nstatic __always_inline void bictcp_hystart_reset(struct sock *sk)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct bictcp *ca = inet_csk_ca(sk);\n\n\tca->round_start = ca->last_ack = bictcp_clock_us(sk);\n\tca->end_seq = tp->snd_nxt;\n\tca->curr_rtt = ~0U;\n\tca->sample_cnt = 0;\n}\n\n \nSEC(\"struct_ops/bpf_cubic_init\")\nvoid BPF_PROG(bpf_cubic_init, struct sock *sk)\n{\n\tstruct bictcp *ca = inet_csk_ca(sk);\n\n\tbictcp_reset(ca);\n\n\tif (hystart)\n\t\tbictcp_hystart_reset(sk);\n\n\tif (!hystart && initial_ssthresh)\n\t\ttcp_sk(sk)->snd_ssthresh = initial_ssthresh;\n}\n\n \nSEC(\"struct_ops/bpf_cubic_cwnd_event\")\nvoid BPF_PROG(bpf_cubic_cwnd_event, struct sock *sk, enum tcp_ca_event event)\n{\n\tif (event == CA_EVENT_TX_START) {\n\t\tstruct bictcp *ca = inet_csk_ca(sk);\n\t\t__u32 now = tcp_jiffies32;\n\t\t__s32 delta;\n\n\t\tdelta = now - tcp_sk(sk)->lsndtime;\n\n\t\t \n\t\tif (ca->epoch_start && delta > 0) {\n\t\t\tca->epoch_start += delta;\n\t\t\tif (after(ca->epoch_start, now))\n\t\t\t\tca->epoch_start = now;\n\t\t}\n\t\treturn;\n\t}\n}\n\n \nstatic const __u8 v[] = {\n\t     0,   54,   54,   54,  118,  118,  118,  118,\n\t   123,  129,  134,  138,  143,  147,  151,  156,\n\t   157,  161,  164,  168,  170,  173,  176,  179,\n\t   181,  185,  187,  190,  192,  194,  197,  199,\n\t   200,  202,  204,  206,  209,  211,  213,  215,\n\t   217,  219,  221,  222,  224,  225,  227,  229,\n\t   231,  232,  234,  236,  237,  239,  240,  242,\n\t   244,  245,  246,  248,  250,  251,  252,  254,\n};\n\n \nstatic __always_inline __u32 cubic_root(__u64 a)\n{\n\t__u32 x, b, shift;\n\n\tif (a < 64) {\n\t\t \n\t\treturn ((__u32)v[(__u32)a] + 35) >> 6;\n\t}\n\n\tb = fls64(a);\n\tb = ((b * 84) >> 8) - 1;\n\tshift = (a >> (b * 3));\n\n\t \n\tif (shift >= 64)\n\t\treturn 0;\n\n\tx = ((__u32)(((__u32)v[shift] + 10) << b)) >> 6;\n\n\t \n\tx = (2 * x + (__u32)div64_u64(a, (__u64)x * (__u64)(x - 1)));\n\tx = ((x * 341) >> 10);\n\treturn x;\n}\n\n \nstatic __always_inline void bictcp_update(struct bictcp *ca, __u32 cwnd,\n\t\t\t\t\t  __u32 acked)\n{\n\t__u32 delta, bic_target, max_cnt;\n\t__u64 offs, t;\n\n\tca->ack_cnt += acked;\t \n\n\tif (ca->last_cwnd == cwnd &&\n\t    (__s32)(tcp_jiffies32 - ca->last_time) <= HZ / 32)\n\t\treturn;\n\n\t \n\tif (ca->epoch_start && tcp_jiffies32 == ca->last_time)\n\t\tgoto tcp_friendliness;\n\n\tca->last_cwnd = cwnd;\n\tca->last_time = tcp_jiffies32;\n\n\tif (ca->epoch_start == 0) {\n\t\tca->epoch_start = tcp_jiffies32;\t \n\t\tca->ack_cnt = acked;\t\t\t \n\t\tca->tcp_cwnd = cwnd;\t\t\t \n\n\t\tif (ca->last_max_cwnd <= cwnd) {\n\t\t\tca->bic_K = 0;\n\t\t\tca->bic_origin_point = cwnd;\n\t\t} else {\n\t\t\t \n\t\t\tca->bic_K = cubic_root(cube_factor\n\t\t\t\t\t       * (ca->last_max_cwnd - cwnd));\n\t\t\tca->bic_origin_point = ca->last_max_cwnd;\n\t\t}\n\t}\n\n\t \n\t \n\n\tt = (__s32)(tcp_jiffies32 - ca->epoch_start) * USEC_PER_JIFFY;\n\tt += ca->delay_min;\n\t \n\tt <<= BICTCP_HZ;\n\tt /= USEC_PER_SEC;\n\n\tif (t < ca->bic_K)\t\t \n\t\toffs = ca->bic_K - t;\n\telse\n\t\toffs = t - ca->bic_K;\n\n\t \n\tdelta = (cube_rtt_scale * offs * offs * offs) >> (10+3*BICTCP_HZ);\n\tif (t < ca->bic_K)                             \n\t\tbic_target = ca->bic_origin_point - delta;\n\telse                                           \n\t\tbic_target = ca->bic_origin_point + delta;\n\n\t \n\tif (bic_target > cwnd) {\n\t\tca->cnt = cwnd / (bic_target - cwnd);\n\t} else {\n\t\tca->cnt = 100 * cwnd;               \n\t}\n\n\t \n\tif (ca->last_max_cwnd == 0 && ca->cnt > 20)\n\t\tca->cnt = 20;\t \n\ntcp_friendliness:\n\t \n\tif (tcp_friendliness) {\n\t\t__u32 scale = beta_scale;\n\t\t__u32 n;\n\n\t\t \n\t\tdelta = (cwnd * scale) >> 3;\n\t\tif (ca->ack_cnt > delta && delta) {\n\t\t\tn = ca->ack_cnt / delta;\n\t\t\tca->ack_cnt -= n * delta;\n\t\t\tca->tcp_cwnd += n;\n\t\t}\n\n\t\tif (ca->tcp_cwnd > cwnd) {\t \n\t\t\tdelta = ca->tcp_cwnd - cwnd;\n\t\t\tmax_cnt = cwnd / delta;\n\t\t\tif (ca->cnt > max_cnt)\n\t\t\t\tca->cnt = max_cnt;\n\t\t}\n\t}\n\n\t \n\tca->cnt = max(ca->cnt, 2U);\n}\n\n \nvoid BPF_STRUCT_OPS(bpf_cubic_cong_avoid, struct sock *sk, __u32 ack, __u32 acked)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct bictcp *ca = inet_csk_ca(sk);\n\n\tif (!tcp_is_cwnd_limited(sk))\n\t\treturn;\n\n\tif (tcp_in_slow_start(tp)) {\n\t\tif (hystart && after(ack, ca->end_seq))\n\t\t\tbictcp_hystart_reset(sk);\n\t\tacked = tcp_slow_start(tp, acked);\n\t\tif (!acked)\n\t\t\treturn;\n\t}\n\tbictcp_update(ca, tp->snd_cwnd, acked);\n\ttcp_cong_avoid_ai(tp, ca->cnt, acked);\n}\n\n__u32 BPF_STRUCT_OPS(bpf_cubic_recalc_ssthresh, struct sock *sk)\n{\n\tconst struct tcp_sock *tp = tcp_sk(sk);\n\tstruct bictcp *ca = inet_csk_ca(sk);\n\n\tca->epoch_start = 0;\t \n\n\t \n\tif (tp->snd_cwnd < ca->last_max_cwnd && fast_convergence)\n\t\tca->last_max_cwnd = (tp->snd_cwnd * (BICTCP_BETA_SCALE + beta))\n\t\t\t/ (2 * BICTCP_BETA_SCALE);\n\telse\n\t\tca->last_max_cwnd = tp->snd_cwnd;\n\n\treturn max((tp->snd_cwnd * beta) / BICTCP_BETA_SCALE, 2U);\n}\n\nvoid BPF_STRUCT_OPS(bpf_cubic_state, struct sock *sk, __u8 new_state)\n{\n\tif (new_state == TCP_CA_Loss) {\n\t\tbictcp_reset(inet_csk_ca(sk));\n\t\tbictcp_hystart_reset(sk);\n\t}\n}\n\n#define GSO_MAX_SIZE\t\t65536\n\n \nstatic __always_inline __u32 hystart_ack_delay(struct sock *sk)\n{\n\tunsigned long rate;\n\n\trate = sk->sk_pacing_rate;\n\tif (!rate)\n\t\treturn 0;\n\treturn min((__u64)USEC_PER_MSEC,\n\t\t   div64_ul((__u64)GSO_MAX_SIZE * 4 * USEC_PER_SEC, rate));\n}\n\nstatic __always_inline void hystart_update(struct sock *sk, __u32 delay)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct bictcp *ca = inet_csk_ca(sk);\n\t__u32 threshold;\n\n\tif (hystart_detect & HYSTART_ACK_TRAIN) {\n\t\t__u32 now = bictcp_clock_us(sk);\n\n\t\t \n\t\tif ((__s32)(now - ca->last_ack) <= hystart_ack_delta_us) {\n\t\t\tca->last_ack = now;\n\n\t\t\tthreshold = ca->delay_min + hystart_ack_delay(sk);\n\n\t\t\t \n\t\t\tif (sk->sk_pacing_status == SK_PACING_NONE)\n\t\t\t\tthreshold >>= 1;\n\n\t\t\tif ((__s32)(now - ca->round_start) > threshold) {\n\t\t\t\tca->found = 1;\n\t\t\t\ttp->snd_ssthresh = tp->snd_cwnd;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (hystart_detect & HYSTART_DELAY) {\n\t\t \n\t\tif (ca->curr_rtt > delay)\n\t\t\tca->curr_rtt = delay;\n\t\tif (ca->sample_cnt < HYSTART_MIN_SAMPLES) {\n\t\t\tca->sample_cnt++;\n\t\t} else {\n\t\t\tif (ca->curr_rtt > ca->delay_min +\n\t\t\t    HYSTART_DELAY_THRESH(ca->delay_min >> 3)) {\n\t\t\t\tca->found = 1;\n\t\t\t\ttp->snd_ssthresh = tp->snd_cwnd;\n\t\t\t}\n\t\t}\n\t}\n}\n\nint bpf_cubic_acked_called = 0;\n\nvoid BPF_STRUCT_OPS(bpf_cubic_acked, struct sock *sk,\n\t\t    const struct ack_sample *sample)\n{\n\tconst struct tcp_sock *tp = tcp_sk(sk);\n\tstruct bictcp *ca = inet_csk_ca(sk);\n\t__u32 delay;\n\n\tbpf_cubic_acked_called = 1;\n\t \n\tif (sample->rtt_us < 0)\n\t\treturn;\n\n\t \n\tif (ca->epoch_start && (__s32)(tcp_jiffies32 - ca->epoch_start) < HZ)\n\t\treturn;\n\n\tdelay = sample->rtt_us;\n\tif (delay == 0)\n\t\tdelay = 1;\n\n\t \n\tif (ca->delay_min == 0 || ca->delay_min > delay)\n\t\tca->delay_min = delay;\n\n\t \n\tif (!ca->found && tcp_in_slow_start(tp) && hystart &&\n\t    tp->snd_cwnd >= hystart_low_window)\n\t\thystart_update(sk, delay);\n}\n\nextern __u32 tcp_reno_undo_cwnd(struct sock *sk) __ksym;\n\n__u32 BPF_STRUCT_OPS(bpf_cubic_undo_cwnd, struct sock *sk)\n{\n\treturn tcp_reno_undo_cwnd(sk);\n}\n\nSEC(\".struct_ops\")\nstruct tcp_congestion_ops cubic = {\n\t.init\t\t= (void *)bpf_cubic_init,\n\t.ssthresh\t= (void *)bpf_cubic_recalc_ssthresh,\n\t.cong_avoid\t= (void *)bpf_cubic_cong_avoid,\n\t.set_state\t= (void *)bpf_cubic_state,\n\t.undo_cwnd\t= (void *)bpf_cubic_undo_cwnd,\n\t.cwnd_event\t= (void *)bpf_cubic_cwnd_event,\n\t.pkts_acked     = (void *)bpf_cubic_acked,\n\t.name\t\t= \"bpf_cubic\",\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}