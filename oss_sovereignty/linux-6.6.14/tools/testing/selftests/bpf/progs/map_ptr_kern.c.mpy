{
  "module_name": "map_ptr_kern.c",
  "hash_id": "d0b2c1942ef702a8cbe1bd60e94fbd449b7f9a0fb4a1b7376488bbb2a5d6c425",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/map_ptr_kern.c",
  "human_readable_source": "\n\n\n#include <linux/bpf.h>\n#include <bpf/bpf_helpers.h>\n\n#define LOOP_BOUND 0xf\n#define MAX_ENTRIES 8\n#define HALF_ENTRIES (MAX_ENTRIES >> 1)\n\n_Static_assert(MAX_ENTRIES < LOOP_BOUND, \"MAX_ENTRIES must be < LOOP_BOUND\");\n\nenum bpf_map_type g_map_type = BPF_MAP_TYPE_UNSPEC;\n__u32 g_line = 0;\nint page_size = 0;  \n\n#define VERIFY_TYPE(type, func) ({\t\\\n\tg_map_type = type;\t\t\\\n\tif (!func())\t\t\t\\\n\t\treturn 0;\t\t\\\n})\n\n\n#define VERIFY(expr) ({\t\t\\\n\tg_line = __LINE__;\t\\\n\tif (!(expr))\t\t\\\n\t\treturn 0;\t\\\n})\n\nstruct bpf_map {\n\tenum bpf_map_type map_type;\n\t__u32 key_size;\n\t__u32 value_size;\n\t__u32 max_entries;\n\t__u32 id;\n} __attribute__((preserve_access_index));\n\nstatic inline int check_bpf_map_fields(struct bpf_map *map, __u32 key_size,\n\t\t\t\t       __u32 value_size, __u32 max_entries)\n{\n\tVERIFY(map->map_type == g_map_type);\n\tVERIFY(map->key_size == key_size);\n\tVERIFY(map->value_size == value_size);\n\tVERIFY(map->max_entries == max_entries);\n\tVERIFY(map->id > 0);\n\n\treturn 1;\n}\n\nstatic inline int check_bpf_map_ptr(struct bpf_map *indirect,\n\t\t\t\t    struct bpf_map *direct)\n{\n\tVERIFY(indirect->map_type == direct->map_type);\n\tVERIFY(indirect->key_size == direct->key_size);\n\tVERIFY(indirect->value_size == direct->value_size);\n\tVERIFY(indirect->max_entries == direct->max_entries);\n\tVERIFY(indirect->id == direct->id);\n\n\treturn 1;\n}\n\nstatic inline int check(struct bpf_map *indirect, struct bpf_map *direct,\n\t\t\t__u32 key_size, __u32 value_size, __u32 max_entries)\n{\n\tVERIFY(check_bpf_map_ptr(indirect, direct));\n\tVERIFY(check_bpf_map_fields(indirect, key_size, value_size,\n\t\t\t\t    max_entries));\n\treturn 1;\n}\n\nstatic inline int check_default(struct bpf_map *indirect,\n\t\t\t\tstruct bpf_map *direct)\n{\n\tVERIFY(check(indirect, direct, sizeof(__u32), sizeof(__u32),\n\t\t     MAX_ENTRIES));\n\treturn 1;\n}\n\nstatic __noinline int\ncheck_default_noinline(struct bpf_map *indirect, struct bpf_map *direct)\n{\n\tVERIFY(check(indirect, direct, sizeof(__u32), sizeof(__u32),\n\t\t     MAX_ENTRIES));\n\treturn 1;\n}\n\ntypedef struct {\n\tint counter;\n} atomic_t;\n\nstruct bpf_htab {\n\tstruct bpf_map map;\n\tatomic_t count;\n\t__u32 n_buckets;\n\t__u32 elem_size;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);  \n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_hash SEC(\".maps\");\n\n__s64 bpf_map_sum_elem_count(struct bpf_map *map) __ksym;\n\nstatic inline int check_hash(void)\n{\n\tstruct bpf_htab *hash = (struct bpf_htab *)&m_hash;\n\tstruct bpf_map *map = (struct bpf_map *)&m_hash;\n\tint i;\n\n\tVERIFY(check_default_noinline(&hash->map, map));\n\n\tVERIFY(hash->n_buckets == MAX_ENTRIES);\n\tVERIFY(hash->elem_size == 64);\n\n\tVERIFY(hash->count.counter == 0);\n\tVERIFY(bpf_map_sum_elem_count(map) == 0);\n\n\tfor (i = 0; i < HALF_ENTRIES; ++i) {\n\t\tconst __u32 key = i;\n\t\tconst __u32 val = 1;\n\n\t\tif (bpf_map_update_elem(hash, &key, &val, 0))\n\t\t\treturn 0;\n\t}\n\tVERIFY(hash->count.counter == HALF_ENTRIES);\n\tVERIFY(bpf_map_sum_elem_count(map) == HALF_ENTRIES);\n\n\treturn 1;\n}\n\nstruct bpf_array {\n\tstruct bpf_map map;\n\t__u32 elem_size;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_ARRAY);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_array SEC(\".maps\");\n\nstatic inline int check_array(void)\n{\n\tstruct bpf_array *array = (struct bpf_array *)&m_array;\n\tstruct bpf_map *map = (struct bpf_map *)&m_array;\n\tint i, n_lookups = 0, n_keys = 0;\n\n\tVERIFY(check_default(&array->map, map));\n\n\tVERIFY(array->elem_size == 8);\n\n\tfor (i = 0; i < array->map.max_entries && i < LOOP_BOUND; ++i) {\n\t\tconst __u32 key = i;\n\t\t__u32 *val = bpf_map_lookup_elem(array, &key);\n\n\t\t++n_lookups;\n\t\tif (val)\n\t\t\t++n_keys;\n\t}\n\n\tVERIFY(n_lookups == MAX_ENTRIES);\n\tVERIFY(n_keys == MAX_ENTRIES);\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_PROG_ARRAY);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_prog_array SEC(\".maps\");\n\nstatic inline int check_prog_array(void)\n{\n\tstruct bpf_array *prog_array = (struct bpf_array *)&m_prog_array;\n\tstruct bpf_map *map = (struct bpf_map *)&m_prog_array;\n\n\tVERIFY(check_default(&prog_array->map, map));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_perf_event_array SEC(\".maps\");\n\nstatic inline int check_perf_event_array(void)\n{\n\tstruct bpf_array *perf_event_array = (struct bpf_array *)&m_perf_event_array;\n\tstruct bpf_map *map = (struct bpf_map *)&m_perf_event_array;\n\n\tVERIFY(check_default(&perf_event_array->map, map));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_HASH);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_percpu_hash SEC(\".maps\");\n\nstatic inline int check_percpu_hash(void)\n{\n\tstruct bpf_htab *percpu_hash = (struct bpf_htab *)&m_percpu_hash;\n\tstruct bpf_map *map = (struct bpf_map *)&m_percpu_hash;\n\n\tVERIFY(check_default(&percpu_hash->map, map));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_percpu_array SEC(\".maps\");\n\nstatic inline int check_percpu_array(void)\n{\n\tstruct bpf_array *percpu_array = (struct bpf_array *)&m_percpu_array;\n\tstruct bpf_map *map = (struct bpf_map *)&m_percpu_array;\n\n\tVERIFY(check_default(&percpu_array->map, map));\n\n\treturn 1;\n}\n\nstruct bpf_stack_map {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_STACK_TRACE);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u64);\n} m_stack_trace SEC(\".maps\");\n\nstatic inline int check_stack_trace(void)\n{\n\tstruct bpf_stack_map *stack_trace =\n\t\t(struct bpf_stack_map *)&m_stack_trace;\n\tstruct bpf_map *map = (struct bpf_map *)&m_stack_trace;\n\n\tVERIFY(check(&stack_trace->map, map, sizeof(__u32), sizeof(__u64),\n\t\t     MAX_ENTRIES));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_CGROUP_ARRAY);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_cgroup_array SEC(\".maps\");\n\nstatic inline int check_cgroup_array(void)\n{\n\tstruct bpf_array *cgroup_array = (struct bpf_array *)&m_cgroup_array;\n\tstruct bpf_map *map = (struct bpf_map *)&m_cgroup_array;\n\n\tVERIFY(check_default(&cgroup_array->map, map));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_LRU_HASH);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_lru_hash SEC(\".maps\");\n\nstatic inline int check_lru_hash(void)\n{\n\tstruct bpf_htab *lru_hash = (struct bpf_htab *)&m_lru_hash;\n\tstruct bpf_map *map = (struct bpf_map *)&m_lru_hash;\n\n\tVERIFY(check_default(&lru_hash->map, map));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_lru_percpu_hash SEC(\".maps\");\n\nstatic inline int check_lru_percpu_hash(void)\n{\n\tstruct bpf_htab *lru_percpu_hash = (struct bpf_htab *)&m_lru_percpu_hash;\n\tstruct bpf_map *map = (struct bpf_map *)&m_lru_percpu_hash;\n\n\tVERIFY(check_default(&lru_percpu_hash->map, map));\n\n\treturn 1;\n}\n\nstruct lpm_trie {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct lpm_key {\n\tstruct bpf_lpm_trie_key trie_key;\n\t__u32 data;\n};\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_LPM_TRIE);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, struct lpm_key);\n\t__type(value, __u32);\n} m_lpm_trie SEC(\".maps\");\n\nstatic inline int check_lpm_trie(void)\n{\n\tstruct lpm_trie *lpm_trie = (struct lpm_trie *)&m_lpm_trie;\n\tstruct bpf_map *map = (struct bpf_map *)&m_lpm_trie;\n\n\tVERIFY(check(&lpm_trie->map, map, sizeof(struct lpm_key), sizeof(__u32),\n\t\t     MAX_ENTRIES));\n\n\treturn 1;\n}\n\n#define INNER_MAX_ENTRIES 1234\n\nstruct inner_map {\n\t__uint(type, BPF_MAP_TYPE_ARRAY);\n\t__uint(max_entries, INNER_MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} inner_map SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_ARRAY_OF_MAPS);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n\t__array(values, struct {\n\t\t__uint(type, BPF_MAP_TYPE_ARRAY);\n\t\t__uint(max_entries, INNER_MAX_ENTRIES);\n\t\t__type(key, __u32);\n\t\t__type(value, __u32);\n\t});\n} m_array_of_maps SEC(\".maps\") = {\n\t.values = { (void *)&inner_map, 0, 0, 0, 0, 0, 0, 0, 0 },\n};\n\nstatic inline int check_array_of_maps(void)\n{\n\tstruct bpf_array *array_of_maps = (struct bpf_array *)&m_array_of_maps;\n\tstruct bpf_map *map = (struct bpf_map *)&m_array_of_maps;\n\tstruct bpf_array *inner_map;\n\tint key = 0;\n\n\tVERIFY(check_default(&array_of_maps->map, map));\n\tinner_map = bpf_map_lookup_elem(array_of_maps, &key);\n\tVERIFY(inner_map != NULL);\n\tVERIFY(inner_map->map.max_entries == INNER_MAX_ENTRIES);\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH_OF_MAPS);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n\t__array(values, struct inner_map);\n} m_hash_of_maps SEC(\".maps\") = {\n\t.values = {\n\t\t[2] = &inner_map,\n\t},\n};\n\nstatic inline int check_hash_of_maps(void)\n{\n\tstruct bpf_htab *hash_of_maps = (struct bpf_htab *)&m_hash_of_maps;\n\tstruct bpf_map *map = (struct bpf_map *)&m_hash_of_maps;\n\tstruct bpf_htab *inner_map;\n\tint key = 2;\n\n\tVERIFY(check_default(&hash_of_maps->map, map));\n\tinner_map = bpf_map_lookup_elem(hash_of_maps, &key);\n\tVERIFY(inner_map != NULL);\n\tVERIFY(inner_map->map.max_entries == INNER_MAX_ENTRIES);\n\n\treturn 1;\n}\n\nstruct bpf_dtab {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_DEVMAP);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_devmap SEC(\".maps\");\n\nstatic inline int check_devmap(void)\n{\n\tstruct bpf_dtab *devmap = (struct bpf_dtab *)&m_devmap;\n\tstruct bpf_map *map = (struct bpf_map *)&m_devmap;\n\n\tVERIFY(check_default(&devmap->map, map));\n\n\treturn 1;\n}\n\nstruct bpf_stab {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_SOCKMAP);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_sockmap SEC(\".maps\");\n\nstatic inline int check_sockmap(void)\n{\n\tstruct bpf_stab *sockmap = (struct bpf_stab *)&m_sockmap;\n\tstruct bpf_map *map = (struct bpf_map *)&m_sockmap;\n\n\tVERIFY(check_default(&sockmap->map, map));\n\n\treturn 1;\n}\n\nstruct bpf_cpu_map {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_CPUMAP);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_cpumap SEC(\".maps\");\n\nstatic inline int check_cpumap(void)\n{\n\tstruct bpf_cpu_map *cpumap = (struct bpf_cpu_map *)&m_cpumap;\n\tstruct bpf_map *map = (struct bpf_map *)&m_cpumap;\n\n\tVERIFY(check_default(&cpumap->map, map));\n\n\treturn 1;\n}\n\nstruct xsk_map {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_XSKMAP);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_xskmap SEC(\".maps\");\n\nstatic inline int check_xskmap(void)\n{\n\tstruct xsk_map *xskmap = (struct xsk_map *)&m_xskmap;\n\tstruct bpf_map *map = (struct bpf_map *)&m_xskmap;\n\n\tVERIFY(check_default(&xskmap->map, map));\n\n\treturn 1;\n}\n\nstruct bpf_shtab {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_SOCKHASH);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_sockhash SEC(\".maps\");\n\nstatic inline int check_sockhash(void)\n{\n\tstruct bpf_shtab *sockhash = (struct bpf_shtab *)&m_sockhash;\n\tstruct bpf_map *map = (struct bpf_map *)&m_sockhash;\n\n\tVERIFY(check_default(&sockhash->map, map));\n\n\treturn 1;\n}\n\nstruct bpf_cgroup_storage_map {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_CGROUP_STORAGE);\n\t__type(key, struct bpf_cgroup_storage_key);\n\t__type(value, __u32);\n} m_cgroup_storage SEC(\".maps\");\n\nstatic inline int check_cgroup_storage(void)\n{\n\tstruct bpf_cgroup_storage_map *cgroup_storage =\n\t\t(struct bpf_cgroup_storage_map *)&m_cgroup_storage;\n\tstruct bpf_map *map = (struct bpf_map *)&m_cgroup_storage;\n\n\tVERIFY(check(&cgroup_storage->map, map,\n\t\t     sizeof(struct bpf_cgroup_storage_key), sizeof(__u32), 0));\n\n\treturn 1;\n}\n\nstruct reuseport_array {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_REUSEPORT_SOCKARRAY);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_reuseport_sockarray SEC(\".maps\");\n\nstatic inline int check_reuseport_sockarray(void)\n{\n\tstruct reuseport_array *reuseport_sockarray =\n\t\t(struct reuseport_array *)&m_reuseport_sockarray;\n\tstruct bpf_map *map = (struct bpf_map *)&m_reuseport_sockarray;\n\n\tVERIFY(check_default(&reuseport_sockarray->map, map));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE);\n\t__type(key, struct bpf_cgroup_storage_key);\n\t__type(value, __u32);\n} m_percpu_cgroup_storage SEC(\".maps\");\n\nstatic inline int check_percpu_cgroup_storage(void)\n{\n\tstruct bpf_cgroup_storage_map *percpu_cgroup_storage =\n\t\t(struct bpf_cgroup_storage_map *)&m_percpu_cgroup_storage;\n\tstruct bpf_map *map = (struct bpf_map *)&m_percpu_cgroup_storage;\n\n\tVERIFY(check(&percpu_cgroup_storage->map, map,\n\t\t     sizeof(struct bpf_cgroup_storage_key), sizeof(__u32), 0));\n\n\treturn 1;\n}\n\nstruct bpf_queue_stack {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_QUEUE);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(value, __u32);\n} m_queue SEC(\".maps\");\n\nstatic inline int check_queue(void)\n{\n\tstruct bpf_queue_stack *queue = (struct bpf_queue_stack *)&m_queue;\n\tstruct bpf_map *map = (struct bpf_map *)&m_queue;\n\n\tVERIFY(check(&queue->map, map, 0, sizeof(__u32), MAX_ENTRIES));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_STACK);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(value, __u32);\n} m_stack SEC(\".maps\");\n\nstatic inline int check_stack(void)\n{\n\tstruct bpf_queue_stack *stack = (struct bpf_queue_stack *)&m_stack;\n\tstruct bpf_map *map = (struct bpf_map *)&m_stack;\n\n\tVERIFY(check(&stack->map, map, 0, sizeof(__u32), MAX_ENTRIES));\n\n\treturn 1;\n}\n\nstruct bpf_local_storage_map {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_SK_STORAGE);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_sk_storage SEC(\".maps\");\n\nstatic inline int check_sk_storage(void)\n{\n\tstruct bpf_local_storage_map *sk_storage =\n\t\t(struct bpf_local_storage_map *)&m_sk_storage;\n\tstruct bpf_map *map = (struct bpf_map *)&m_sk_storage;\n\n\tVERIFY(check(&sk_storage->map, map, sizeof(__u32), sizeof(__u32), 0));\n\n\treturn 1;\n}\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_DEVMAP_HASH);\n\t__uint(max_entries, MAX_ENTRIES);\n\t__type(key, __u32);\n\t__type(value, __u32);\n} m_devmap_hash SEC(\".maps\");\n\nstatic inline int check_devmap_hash(void)\n{\n\tstruct bpf_dtab *devmap_hash = (struct bpf_dtab *)&m_devmap_hash;\n\tstruct bpf_map *map = (struct bpf_map *)&m_devmap_hash;\n\n\tVERIFY(check_default(&devmap_hash->map, map));\n\n\treturn 1;\n}\n\nstruct bpf_ringbuf_map {\n\tstruct bpf_map map;\n} __attribute__((preserve_access_index));\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_RINGBUF);\n} m_ringbuf SEC(\".maps\");\n\nstatic inline int check_ringbuf(void)\n{\n\tstruct bpf_ringbuf_map *ringbuf = (struct bpf_ringbuf_map *)&m_ringbuf;\n\tstruct bpf_map *map = (struct bpf_map *)&m_ringbuf;\n\n\tVERIFY(check(&ringbuf->map, map, 0, 0, page_size));\n\n\treturn 1;\n}\n\nSEC(\"cgroup_skb/egress\")\nint cg_skb(void *ctx)\n{\n\tVERIFY_TYPE(BPF_MAP_TYPE_HASH, check_hash);\n\tVERIFY_TYPE(BPF_MAP_TYPE_ARRAY, check_array);\n\tVERIFY_TYPE(BPF_MAP_TYPE_PROG_ARRAY, check_prog_array);\n\tVERIFY_TYPE(BPF_MAP_TYPE_PERF_EVENT_ARRAY, check_perf_event_array);\n\tVERIFY_TYPE(BPF_MAP_TYPE_PERCPU_HASH, check_percpu_hash);\n\tVERIFY_TYPE(BPF_MAP_TYPE_PERCPU_ARRAY, check_percpu_array);\n\tVERIFY_TYPE(BPF_MAP_TYPE_STACK_TRACE, check_stack_trace);\n\tVERIFY_TYPE(BPF_MAP_TYPE_CGROUP_ARRAY, check_cgroup_array);\n\tVERIFY_TYPE(BPF_MAP_TYPE_LRU_HASH, check_lru_hash);\n\tVERIFY_TYPE(BPF_MAP_TYPE_LRU_PERCPU_HASH, check_lru_percpu_hash);\n\tVERIFY_TYPE(BPF_MAP_TYPE_LPM_TRIE, check_lpm_trie);\n\tVERIFY_TYPE(BPF_MAP_TYPE_ARRAY_OF_MAPS, check_array_of_maps);\n\tVERIFY_TYPE(BPF_MAP_TYPE_HASH_OF_MAPS, check_hash_of_maps);\n\tVERIFY_TYPE(BPF_MAP_TYPE_DEVMAP, check_devmap);\n\tVERIFY_TYPE(BPF_MAP_TYPE_SOCKMAP, check_sockmap);\n\tVERIFY_TYPE(BPF_MAP_TYPE_CPUMAP, check_cpumap);\n\tVERIFY_TYPE(BPF_MAP_TYPE_XSKMAP, check_xskmap);\n\tVERIFY_TYPE(BPF_MAP_TYPE_SOCKHASH, check_sockhash);\n\tVERIFY_TYPE(BPF_MAP_TYPE_CGROUP_STORAGE, check_cgroup_storage);\n\tVERIFY_TYPE(BPF_MAP_TYPE_REUSEPORT_SOCKARRAY,\n\t\t    check_reuseport_sockarray);\n\tVERIFY_TYPE(BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE,\n\t\t    check_percpu_cgroup_storage);\n\tVERIFY_TYPE(BPF_MAP_TYPE_QUEUE, check_queue);\n\tVERIFY_TYPE(BPF_MAP_TYPE_STACK, check_stack);\n\tVERIFY_TYPE(BPF_MAP_TYPE_SK_STORAGE, check_sk_storage);\n\tVERIFY_TYPE(BPF_MAP_TYPE_DEVMAP_HASH, check_devmap_hash);\n\tVERIFY_TYPE(BPF_MAP_TYPE_RINGBUF, check_ringbuf);\n\n\treturn 1;\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}