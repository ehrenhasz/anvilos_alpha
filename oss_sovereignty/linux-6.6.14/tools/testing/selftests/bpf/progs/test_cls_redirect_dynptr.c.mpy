{
  "module_name": "test_cls_redirect_dynptr.c",
  "hash_id": "06b3a24462ff511047fc78731d9e407a269194344c2c01d027faec32905757fd",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/test_cls_redirect_dynptr.c",
  "human_readable_source": "\n\n\n#include <stdbool.h>\n#include <stddef.h>\n#include <stdint.h>\n#include <string.h>\n\n#include <linux/bpf.h>\n#include <linux/icmp.h>\n#include <linux/icmpv6.h>\n#include <linux/if_ether.h>\n#include <linux/in.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/pkt_cls.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n\n#include <bpf/bpf_helpers.h>\n#include <bpf/bpf_endian.h>\n\n#include \"test_cls_redirect.h\"\n#include \"bpf_kfuncs.h\"\n\n#define offsetofend(TYPE, MEMBER) \\\n\t(offsetof(TYPE, MEMBER) + sizeof((((TYPE *)0)->MEMBER)))\n\n#define IP_OFFSET_MASK (0x1FFF)\n#define IP_MF (0x2000)\n\nchar _license[] SEC(\"license\") = \"Dual BSD/GPL\";\n\n \nvolatile const __be16 ENCAPSULATION_PORT;\nvolatile const __be32 ENCAPSULATION_IP;\n\ntypedef struct {\n\tuint64_t processed_packets_total;\n\tuint64_t l3_protocol_packets_total_ipv4;\n\tuint64_t l3_protocol_packets_total_ipv6;\n\tuint64_t l4_protocol_packets_total_tcp;\n\tuint64_t l4_protocol_packets_total_udp;\n\tuint64_t accepted_packets_total_syn;\n\tuint64_t accepted_packets_total_syn_cookies;\n\tuint64_t accepted_packets_total_last_hop;\n\tuint64_t accepted_packets_total_icmp_echo_request;\n\tuint64_t accepted_packets_total_established;\n\tuint64_t forwarded_packets_total_gue;\n\tuint64_t forwarded_packets_total_gre;\n\n\tuint64_t errors_total_unknown_l3_proto;\n\tuint64_t errors_total_unknown_l4_proto;\n\tuint64_t errors_total_malformed_ip;\n\tuint64_t errors_total_fragmented_ip;\n\tuint64_t errors_total_malformed_icmp;\n\tuint64_t errors_total_unwanted_icmp;\n\tuint64_t errors_total_malformed_icmp_pkt_too_big;\n\tuint64_t errors_total_malformed_tcp;\n\tuint64_t errors_total_malformed_udp;\n\tuint64_t errors_total_icmp_echo_replies;\n\tuint64_t errors_total_malformed_encapsulation;\n\tuint64_t errors_total_encap_adjust_failed;\n\tuint64_t errors_total_encap_buffer_too_small;\n\tuint64_t errors_total_redirect_loop;\n\tuint64_t errors_total_encap_mtu_violate;\n} metrics_t;\n\ntypedef enum {\n\tINVALID = 0,\n\tUNKNOWN,\n\tECHO_REQUEST,\n\tSYN,\n\tSYN_COOKIE,\n\tESTABLISHED,\n} verdict_t;\n\ntypedef struct {\n\tuint16_t src, dst;\n} flow_ports_t;\n\n_Static_assert(\n\tsizeof(flow_ports_t) !=\n\t\toffsetofend(struct bpf_sock_tuple, ipv4.dport) -\n\t\t\toffsetof(struct bpf_sock_tuple, ipv4.sport) - 1,\n\t\"flow_ports_t must match sport and dport in struct bpf_sock_tuple\");\n_Static_assert(\n\tsizeof(flow_ports_t) !=\n\t\toffsetofend(struct bpf_sock_tuple, ipv6.dport) -\n\t\t\toffsetof(struct bpf_sock_tuple, ipv6.sport) - 1,\n\t\"flow_ports_t must match sport and dport in struct bpf_sock_tuple\");\n\nstruct iphdr_info {\n\tvoid *hdr;\n\t__u64 len;\n};\n\ntypedef int ret_t;\n\n \nstatic const ret_t CONTINUE_PROCESSING = -1;\n\n \n#define MAYBE_RETURN(x)                           \\\n\tdo {                                      \\\n\t\tret_t __ret = x;                  \\\n\t\tif (__ret != CONTINUE_PROCESSING) \\\n\t\t\treturn __ret;             \\\n\t} while (0)\n\nstatic bool ipv4_is_fragment(const struct iphdr *ip)\n{\n\tuint16_t frag_off = ip->frag_off & bpf_htons(IP_OFFSET_MASK);\n\treturn (ip->frag_off & bpf_htons(IP_MF)) != 0 || frag_off > 0;\n}\n\nstatic int pkt_parse_ipv4(struct bpf_dynptr *dynptr, __u64 *offset, struct iphdr *iphdr)\n{\n\tif (bpf_dynptr_read(iphdr, sizeof(*iphdr), dynptr, *offset, 0))\n\t\treturn -1;\n\n\t*offset += sizeof(*iphdr);\n\n\tif (iphdr->ihl < 5)\n\t\treturn -1;\n\n\t \n\t*offset += (iphdr->ihl - 5) * 4;\n\n\treturn 0;\n}\n\n \nstatic bool pkt_parse_icmp_l4_ports(struct bpf_dynptr *dynptr, __u64 *offset, flow_ports_t *ports)\n{\n\tif (bpf_dynptr_read(ports, sizeof(*ports), dynptr, *offset, 0))\n\t\treturn false;\n\n\t*offset += sizeof(*ports);\n\n\t \n\tuint16_t dst = ports->src;\n\tports->src = ports->dst;\n\tports->dst = dst;\n\treturn true;\n}\n\nstatic uint16_t pkt_checksum_fold(uint32_t csum)\n{\n\t \n\tcsum = (csum & 0xffff) + (csum >> 16);\n\tcsum = (csum & 0xffff) + (csum >> 16);\n\treturn (uint16_t)~csum;\n}\n\nstatic void pkt_ipv4_checksum(struct iphdr *iph)\n{\n\tiph->check = 0;\n\n\t \n\t_Static_assert(sizeof(struct iphdr) == 20, \"iphdr must be 20 bytes\");\n\tuint32_t acc = 0;\n\tuint16_t *ipw = (uint16_t *)iph;\n\n\tfor (size_t i = 0; i < sizeof(struct iphdr) / 2; i++)\n\t\tacc += ipw[i];\n\n\tiph->check = pkt_checksum_fold(acc);\n}\n\nstatic bool pkt_skip_ipv6_extension_headers(struct bpf_dynptr *dynptr, __u64 *offset,\n\t\t\t\t\t    const struct ipv6hdr *ipv6, uint8_t *upper_proto,\n\t\t\t\t\t    bool *is_fragment)\n{\n\t \n\tstruct {\n\t\tuint8_t next;\n\t\tuint8_t len;\n\t} exthdr = {\n\t\t.next = ipv6->nexthdr,\n\t};\n\t*is_fragment = false;\n\n\tfor (int i = 0; i < 6; i++) {\n\t\tswitch (exthdr.next) {\n\t\tcase IPPROTO_FRAGMENT:\n\t\t\t*is_fragment = true;\n\t\t\t \n\t\t\t \n\n\t\tcase IPPROTO_HOPOPTS:\n\t\tcase IPPROTO_ROUTING:\n\t\tcase IPPROTO_DSTOPTS:\n\t\tcase IPPROTO_MH:\n\t\t\tif (bpf_dynptr_read(&exthdr, sizeof(exthdr), dynptr, *offset, 0))\n\t\t\t\treturn false;\n\n\t\t\t \n\t\t\t*offset += (exthdr.len + 1) * 8;\n\n\t\t\t \n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\t \n\t\t\t*upper_proto = exthdr.next;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t \n\treturn false;\n}\n\nstatic int pkt_parse_ipv6(struct bpf_dynptr *dynptr, __u64 *offset, struct ipv6hdr *ipv6,\n\t\t\t  uint8_t *proto, bool *is_fragment)\n{\n\tif (bpf_dynptr_read(ipv6, sizeof(*ipv6), dynptr, *offset, 0))\n\t\treturn -1;\n\n\t*offset += sizeof(*ipv6);\n\n\tif (!pkt_skip_ipv6_extension_headers(dynptr, offset, ipv6, proto, is_fragment))\n\t\treturn -1;\n\n\treturn 0;\n}\n\n \nstruct {\n\t__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);\n\t__uint(max_entries, 1);\n\t__type(key, unsigned int);\n\t__type(value, metrics_t);\n} metrics_map SEC(\".maps\");\n\nstatic metrics_t *get_global_metrics(void)\n{\n\tuint64_t key = 0;\n\treturn bpf_map_lookup_elem(&metrics_map, &key);\n}\n\nstatic ret_t accept_locally(struct __sk_buff *skb, encap_headers_t *encap)\n{\n\tconst int payload_off =\n\t\tsizeof(*encap) +\n\t\tsizeof(struct in_addr) * encap->unigue.hop_count;\n\tint32_t encap_overhead = payload_off - sizeof(struct ethhdr);\n\n\t \n\tif (encap->gue.proto_ctype == IPPROTO_IPV6)\n\t\tencap->eth.h_proto = bpf_htons(ETH_P_IPV6);\n\n\tif (bpf_skb_adjust_room(skb, -encap_overhead, BPF_ADJ_ROOM_MAC,\n\t\t\t\tBPF_F_ADJ_ROOM_FIXED_GSO |\n\t\t\t\tBPF_F_ADJ_ROOM_NO_CSUM_RESET) ||\n\t    bpf_csum_level(skb, BPF_CSUM_LEVEL_DEC))\n\t\treturn TC_ACT_SHOT;\n\n\treturn bpf_redirect(skb->ifindex, BPF_F_INGRESS);\n}\n\nstatic ret_t forward_with_gre(struct __sk_buff *skb, struct bpf_dynptr *dynptr,\n\t\t\t      encap_headers_t *encap, struct in_addr *next_hop,\n\t\t\t      metrics_t *metrics)\n{\n\tconst int payload_off =\n\t\tsizeof(*encap) +\n\t\tsizeof(struct in_addr) * encap->unigue.hop_count;\n\tint32_t encap_overhead =\n\t\tpayload_off - sizeof(struct ethhdr) - sizeof(struct iphdr);\n\tint32_t delta = sizeof(struct gre_base_hdr) - encap_overhead;\n\t__u8 encap_buffer[sizeof(encap_gre_t)] = {};\n\tuint16_t proto = ETH_P_IP;\n\tuint32_t mtu_len = 0;\n\tencap_gre_t *encap_gre;\n\n\tmetrics->forwarded_packets_total_gre++;\n\n\t \n\tif (encap->gue.proto_ctype == IPPROTO_IPV6) {\n\t\tproto = ETH_P_IPV6;\n\t\tuint8_t ttl;\n\t\tint rc;\n\n\t\trc = bpf_skb_load_bytes(\n\t\t\tskb, payload_off + offsetof(struct ipv6hdr, hop_limit),\n\t\t\t&ttl, 1);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tif (ttl == 0) {\n\t\t\tmetrics->errors_total_redirect_loop++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tttl--;\n\t\trc = bpf_skb_store_bytes(\n\t\t\tskb, payload_off + offsetof(struct ipv6hdr, hop_limit),\n\t\t\t&ttl, 1, 0);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\t} else {\n\t\tuint8_t ttl;\n\t\tint rc;\n\n\t\trc = bpf_skb_load_bytes(\n\t\t\tskb, payload_off + offsetof(struct iphdr, ttl), &ttl,\n\t\t\t1);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tif (ttl == 0) {\n\t\t\tmetrics->errors_total_redirect_loop++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\t \n\t\trc = bpf_l3_csum_replace(\n\t\t\tskb, payload_off + offsetof(struct iphdr, check), ttl,\n\t\t\tttl - 1, 2);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\n\t\tttl--;\n\t\trc = bpf_skb_store_bytes(\n\t\t\tskb, payload_off + offsetof(struct iphdr, ttl), &ttl, 1,\n\t\t\t0);\n\t\tif (rc != 0) {\n\t\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\t\treturn TC_ACT_SHOT;\n\t\t}\n\t}\n\n\tif (bpf_check_mtu(skb, skb->ifindex, &mtu_len, delta, 0)) {\n\t\tmetrics->errors_total_encap_mtu_violate++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (bpf_skb_adjust_room(skb, delta, BPF_ADJ_ROOM_NET,\n\t\t\t\tBPF_F_ADJ_ROOM_FIXED_GSO |\n\t\t\t\tBPF_F_ADJ_ROOM_NO_CSUM_RESET) ||\n\t    bpf_csum_level(skb, BPF_CSUM_LEVEL_INC)) {\n\t\tmetrics->errors_total_encap_adjust_failed++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (bpf_skb_pull_data(skb, sizeof(encap_gre_t))) {\n\t\tmetrics->errors_total_encap_buffer_too_small++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tencap_gre = bpf_dynptr_slice_rdwr(dynptr, 0, encap_buffer, sizeof(encap_buffer));\n\tif (!encap_gre) {\n\t\tmetrics->errors_total_encap_buffer_too_small++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tencap_gre->ip.protocol = IPPROTO_GRE;\n\tencap_gre->ip.daddr = next_hop->s_addr;\n\tencap_gre->ip.saddr = ENCAPSULATION_IP;\n\tencap_gre->ip.tot_len =\n\t\tbpf_htons(bpf_ntohs(encap_gre->ip.tot_len) + delta);\n\tencap_gre->gre.flags = 0;\n\tencap_gre->gre.protocol = bpf_htons(proto);\n\tpkt_ipv4_checksum((void *)&encap_gre->ip);\n\n\tif (encap_gre == encap_buffer)\n\t\tbpf_dynptr_write(dynptr, 0, encap_buffer, sizeof(encap_buffer), 0);\n\n\treturn bpf_redirect(skb->ifindex, 0);\n}\n\nstatic ret_t forward_to_next_hop(struct __sk_buff *skb, struct bpf_dynptr *dynptr,\n\t\t\t\t encap_headers_t *encap, struct in_addr *next_hop,\n\t\t\t\t metrics_t *metrics)\n{\n\t \n\t \n\tunsigned char temp[ETH_ALEN];\n\tmemcpy(temp, encap->eth.h_dest, sizeof(temp));\n\tmemcpy(encap->eth.h_dest, encap->eth.h_source,\n\t       sizeof(encap->eth.h_dest));\n\tmemcpy(encap->eth.h_source, temp, sizeof(encap->eth.h_source));\n\n\tif (encap->unigue.next_hop == encap->unigue.hop_count - 1 &&\n\t    encap->unigue.last_hop_gre) {\n\t\treturn forward_with_gre(skb, dynptr, encap, next_hop, metrics);\n\t}\n\n\tmetrics->forwarded_packets_total_gue++;\n\tuint32_t old_saddr = encap->ip.saddr;\n\tencap->ip.saddr = encap->ip.daddr;\n\tencap->ip.daddr = next_hop->s_addr;\n\tif (encap->unigue.next_hop < encap->unigue.hop_count) {\n\t\tencap->unigue.next_hop++;\n\t}\n\n\t \n\tconst uint64_t off = offsetof(typeof(*encap), ip.check);\n\tint ret = bpf_l3_csum_replace(skb, off, old_saddr, next_hop->s_addr, 4);\n\tif (ret < 0) {\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\treturn bpf_redirect(skb->ifindex, 0);\n}\n\nstatic ret_t skip_next_hops(__u64 *offset, int n)\n{\n\tswitch (n) {\n\tcase 1:\n\t\t*offset += sizeof(struct in_addr);\n\tcase 0:\n\t\treturn CONTINUE_PROCESSING;\n\n\tdefault:\n\t\treturn TC_ACT_SHOT;\n\t}\n}\n\n \nstatic ret_t get_next_hop(struct bpf_dynptr *dynptr, __u64 *offset, encap_headers_t *encap,\n\t\t\t  struct in_addr *next_hop)\n{\n\tif (encap->unigue.next_hop > encap->unigue.hop_count)\n\t\treturn TC_ACT_SHOT;\n\n\t \n\tMAYBE_RETURN(skip_next_hops(offset, encap->unigue.next_hop));\n\n\tif (encap->unigue.next_hop == encap->unigue.hop_count) {\n\t\t \n\t\tnext_hop->s_addr = 0;\n\t\treturn CONTINUE_PROCESSING;\n\t}\n\n\tif (bpf_dynptr_read(next_hop, sizeof(*next_hop), dynptr, *offset, 0))\n\t\treturn TC_ACT_SHOT;\n\n\t*offset += sizeof(*next_hop);\n\n\t \n\treturn skip_next_hops(offset, encap->unigue.hop_count - encap->unigue.next_hop - 1);\n}\n\n \nstatic uint64_t fill_tuple(struct bpf_sock_tuple *tuple, void *iph,\n\t\t\t\t    uint64_t iphlen, uint16_t sport, uint16_t dport)\n{\n\tswitch (iphlen) {\n\tcase sizeof(struct iphdr): {\n\t\tstruct iphdr *ipv4 = (struct iphdr *)iph;\n\t\ttuple->ipv4.daddr = ipv4->daddr;\n\t\ttuple->ipv4.saddr = ipv4->saddr;\n\t\ttuple->ipv4.sport = sport;\n\t\ttuple->ipv4.dport = dport;\n\t\treturn sizeof(tuple->ipv4);\n\t}\n\n\tcase sizeof(struct ipv6hdr): {\n\t\tstruct ipv6hdr *ipv6 = (struct ipv6hdr *)iph;\n\t\tmemcpy(&tuple->ipv6.daddr, &ipv6->daddr,\n\t\t       sizeof(tuple->ipv6.daddr));\n\t\tmemcpy(&tuple->ipv6.saddr, &ipv6->saddr,\n\t\t       sizeof(tuple->ipv6.saddr));\n\t\ttuple->ipv6.sport = sport;\n\t\ttuple->ipv6.dport = dport;\n\t\treturn sizeof(tuple->ipv6);\n\t}\n\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic verdict_t classify_tcp(struct __sk_buff *skb, struct bpf_sock_tuple *tuple,\n\t\t\t      uint64_t tuplen, void *iph, struct tcphdr *tcp)\n{\n\tstruct bpf_sock *sk =\n\t\tbpf_skc_lookup_tcp(skb, tuple, tuplen, BPF_F_CURRENT_NETNS, 0);\n\n\tif (sk == NULL)\n\t\treturn UNKNOWN;\n\n\tif (sk->state != BPF_TCP_LISTEN) {\n\t\tbpf_sk_release(sk);\n\t\treturn ESTABLISHED;\n\t}\n\n\tif (iph != NULL && tcp != NULL) {\n\t\t \n\t\tuint64_t iphlen = sizeof(struct iphdr);\n\n\t\tif (tuplen == sizeof(tuple->ipv6))\n\t\t\tiphlen = sizeof(struct ipv6hdr);\n\n\t\tif (bpf_tcp_check_syncookie(sk, iph, iphlen, tcp,\n\t\t\t\t\t    sizeof(*tcp)) == 0) {\n\t\t\tbpf_sk_release(sk);\n\t\t\treturn SYN_COOKIE;\n\t\t}\n\t}\n\n\tbpf_sk_release(sk);\n\treturn UNKNOWN;\n}\n\nstatic verdict_t classify_udp(struct __sk_buff *skb, struct bpf_sock_tuple *tuple, uint64_t tuplen)\n{\n\tstruct bpf_sock *sk =\n\t\tbpf_sk_lookup_udp(skb, tuple, tuplen, BPF_F_CURRENT_NETNS, 0);\n\n\tif (sk == NULL)\n\t\treturn UNKNOWN;\n\n\tif (sk->state == BPF_TCP_ESTABLISHED) {\n\t\tbpf_sk_release(sk);\n\t\treturn ESTABLISHED;\n\t}\n\n\tbpf_sk_release(sk);\n\treturn UNKNOWN;\n}\n\nstatic verdict_t classify_icmp(struct __sk_buff *skb, uint8_t proto, struct bpf_sock_tuple *tuple,\n\t\t\t       uint64_t tuplen, metrics_t *metrics)\n{\n\tswitch (proto) {\n\tcase IPPROTO_TCP:\n\t\treturn classify_tcp(skb, tuple, tuplen, NULL, NULL);\n\n\tcase IPPROTO_UDP:\n\t\treturn classify_udp(skb, tuple, tuplen);\n\n\tdefault:\n\t\tmetrics->errors_total_malformed_icmp++;\n\t\treturn INVALID;\n\t}\n}\n\nstatic verdict_t process_icmpv4(struct __sk_buff *skb, struct bpf_dynptr *dynptr, __u64 *offset,\n\t\t\t\tmetrics_t *metrics)\n{\n\tstruct icmphdr icmp;\n\tstruct iphdr ipv4;\n\n\tif (bpf_dynptr_read(&icmp, sizeof(icmp), dynptr, *offset, 0)) {\n\t\tmetrics->errors_total_malformed_icmp++;\n\t\treturn INVALID;\n\t}\n\n\t*offset += sizeof(icmp);\n\n\t \n\tif (icmp.type == ICMP_ECHOREPLY) {\n\t\tmetrics->errors_total_icmp_echo_replies++;\n\t\treturn INVALID;\n\t}\n\n\tif (icmp.type == ICMP_ECHO)\n\t\treturn ECHO_REQUEST;\n\n\tif (icmp.type != ICMP_DEST_UNREACH || icmp.code != ICMP_FRAG_NEEDED) {\n\t\tmetrics->errors_total_unwanted_icmp++;\n\t\treturn INVALID;\n\t}\n\n\tif (pkt_parse_ipv4(dynptr, offset, &ipv4)) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\t \n\tstruct bpf_sock_tuple tuple;\n\ttuple.ipv4.saddr = ipv4.daddr;\n\ttuple.ipv4.daddr = ipv4.saddr;\n\n\tif (!pkt_parse_icmp_l4_ports(dynptr, offset, (flow_ports_t *)&tuple.ipv4.sport)) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\treturn classify_icmp(skb, ipv4.protocol, &tuple,\n\t\t\t     sizeof(tuple.ipv4), metrics);\n}\n\nstatic verdict_t process_icmpv6(struct bpf_dynptr *dynptr, __u64 *offset, struct __sk_buff *skb,\n\t\t\t\tmetrics_t *metrics)\n{\n\tstruct bpf_sock_tuple tuple;\n\tstruct ipv6hdr ipv6;\n\tstruct icmp6hdr icmp6;\n\tbool is_fragment;\n\tuint8_t l4_proto;\n\n\tif (bpf_dynptr_read(&icmp6, sizeof(icmp6), dynptr, *offset, 0)) {\n\t\tmetrics->errors_total_malformed_icmp++;\n\t\treturn INVALID;\n\t}\n\n\t \n\tif (icmp6.icmp6_type == ICMPV6_ECHO_REPLY) {\n\t\tmetrics->errors_total_icmp_echo_replies++;\n\t\treturn INVALID;\n\t}\n\n\tif (icmp6.icmp6_type == ICMPV6_ECHO_REQUEST) {\n\t\treturn ECHO_REQUEST;\n\t}\n\n\tif (icmp6.icmp6_type != ICMPV6_PKT_TOOBIG) {\n\t\tmetrics->errors_total_unwanted_icmp++;\n\t\treturn INVALID;\n\t}\n\n\tif (pkt_parse_ipv6(dynptr, offset, &ipv6, &l4_proto, &is_fragment)) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\tif (is_fragment) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn INVALID;\n\t}\n\n\t \n\tmemcpy(&tuple.ipv6.saddr, &ipv6.daddr, sizeof(tuple.ipv6.saddr));\n\tmemcpy(&tuple.ipv6.daddr, &ipv6.saddr, sizeof(tuple.ipv6.daddr));\n\n\tif (!pkt_parse_icmp_l4_ports(dynptr, offset, (flow_ports_t *)&tuple.ipv6.sport)) {\n\t\tmetrics->errors_total_malformed_icmp_pkt_too_big++;\n\t\treturn INVALID;\n\t}\n\n\treturn classify_icmp(skb, l4_proto, &tuple, sizeof(tuple.ipv6),\n\t\t\t     metrics);\n}\n\nstatic verdict_t process_tcp(struct bpf_dynptr *dynptr, __u64 *offset, struct __sk_buff *skb,\n\t\t\t     struct iphdr_info *info, metrics_t *metrics)\n{\n\tstruct bpf_sock_tuple tuple;\n\tstruct tcphdr tcp;\n\tuint64_t tuplen;\n\n\tmetrics->l4_protocol_packets_total_tcp++;\n\n\tif (bpf_dynptr_read(&tcp, sizeof(tcp), dynptr, *offset, 0)) {\n\t\tmetrics->errors_total_malformed_tcp++;\n\t\treturn INVALID;\n\t}\n\n\t*offset += sizeof(tcp);\n\n\tif (tcp.syn)\n\t\treturn SYN;\n\n\ttuplen = fill_tuple(&tuple, info->hdr, info->len, tcp.source, tcp.dest);\n\treturn classify_tcp(skb, &tuple, tuplen, info->hdr, &tcp);\n}\n\nstatic verdict_t process_udp(struct bpf_dynptr *dynptr, __u64 *offset, struct __sk_buff *skb,\n\t\t\t     struct iphdr_info *info, metrics_t *metrics)\n{\n\tstruct bpf_sock_tuple tuple;\n\tstruct udphdr udph;\n\tuint64_t tuplen;\n\n\tmetrics->l4_protocol_packets_total_udp++;\n\n\tif (bpf_dynptr_read(&udph, sizeof(udph), dynptr, *offset, 0)) {\n\t\tmetrics->errors_total_malformed_udp++;\n\t\treturn INVALID;\n\t}\n\t*offset += sizeof(udph);\n\n\ttuplen = fill_tuple(&tuple, info->hdr, info->len, udph.source, udph.dest);\n\treturn classify_udp(skb, &tuple, tuplen);\n}\n\nstatic verdict_t process_ipv4(struct __sk_buff *skb, struct bpf_dynptr *dynptr,\n\t\t\t      __u64 *offset, metrics_t *metrics)\n{\n\tstruct iphdr ipv4;\n\tstruct iphdr_info info = {\n\t\t.hdr = &ipv4,\n\t\t.len = sizeof(ipv4),\n\t};\n\n\tmetrics->l3_protocol_packets_total_ipv4++;\n\n\tif (pkt_parse_ipv4(dynptr, offset, &ipv4)) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (ipv4.version != 4) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (ipv4_is_fragment(&ipv4)) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn INVALID;\n\t}\n\n\tswitch (ipv4.protocol) {\n\tcase IPPROTO_ICMP:\n\t\treturn process_icmpv4(skb, dynptr, offset, metrics);\n\n\tcase IPPROTO_TCP:\n\t\treturn process_tcp(dynptr, offset, skb, &info, metrics);\n\n\tcase IPPROTO_UDP:\n\t\treturn process_udp(dynptr, offset, skb, &info, metrics);\n\n\tdefault:\n\t\tmetrics->errors_total_unknown_l4_proto++;\n\t\treturn INVALID;\n\t}\n}\n\nstatic verdict_t process_ipv6(struct __sk_buff *skb, struct bpf_dynptr *dynptr,\n\t\t\t      __u64 *offset, metrics_t *metrics)\n{\n\tstruct ipv6hdr ipv6;\n\tstruct iphdr_info info = {\n\t\t.hdr = &ipv6,\n\t\t.len = sizeof(ipv6),\n\t};\n\tuint8_t l4_proto;\n\tbool is_fragment;\n\n\tmetrics->l3_protocol_packets_total_ipv6++;\n\n\tif (pkt_parse_ipv6(dynptr, offset, &ipv6, &l4_proto, &is_fragment)) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (ipv6.version != 6) {\n\t\tmetrics->errors_total_malformed_ip++;\n\t\treturn INVALID;\n\t}\n\n\tif (is_fragment) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn INVALID;\n\t}\n\n\tswitch (l4_proto) {\n\tcase IPPROTO_ICMPV6:\n\t\treturn process_icmpv6(dynptr, offset, skb, metrics);\n\n\tcase IPPROTO_TCP:\n\t\treturn process_tcp(dynptr, offset, skb, &info, metrics);\n\n\tcase IPPROTO_UDP:\n\t\treturn process_udp(dynptr, offset, skb, &info, metrics);\n\n\tdefault:\n\t\tmetrics->errors_total_unknown_l4_proto++;\n\t\treturn INVALID;\n\t}\n}\n\nSEC(\"tc\")\nint cls_redirect(struct __sk_buff *skb)\n{\n\t__u8 encap_buffer[sizeof(encap_headers_t)] = {};\n\tstruct bpf_dynptr dynptr;\n\tstruct in_addr next_hop;\n\t \n\t__u64 off = 0;\n\tret_t ret;\n\n\tbpf_dynptr_from_skb(skb, 0, &dynptr);\n\n\tmetrics_t *metrics = get_global_metrics();\n\tif (metrics == NULL)\n\t\treturn TC_ACT_SHOT;\n\n\tmetrics->processed_packets_total++;\n\n\t \n\tif (skb->protocol != bpf_htons(ETH_P_IP))\n\t\treturn TC_ACT_OK;\n\n\tencap_headers_t *encap;\n\n\t \n\tif (bpf_skb_pull_data(skb, sizeof(*encap)))\n\t\treturn TC_ACT_OK;\n\n\tencap = bpf_dynptr_slice_rdwr(&dynptr, 0, encap_buffer, sizeof(encap_buffer));\n\tif (!encap)\n\t\treturn TC_ACT_OK;\n\n\toff += sizeof(*encap);\n\n\tif (encap->ip.ihl != 5)\n\t\t \n\t\treturn TC_ACT_OK;\n\n\tif (encap->ip.daddr != ENCAPSULATION_IP ||\n\t    encap->ip.protocol != IPPROTO_UDP)\n\t\treturn TC_ACT_OK;\n\n\t \n\tif (encap->udp.dest != ENCAPSULATION_PORT)\n\t\treturn TC_ACT_OK;\n\n\t \n\tif (ipv4_is_fragment((void *)&encap->ip)) {\n\t\tmetrics->errors_total_fragmented_ip++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.variant != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.control != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.flags != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->gue.hlen !=\n\t    sizeof(encap->unigue) / 4 + encap->unigue.hop_count) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->unigue.version != 0) {\n\t\tmetrics->errors_total_malformed_encapsulation++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tif (encap->unigue.reserved != 0)\n\t\treturn TC_ACT_SHOT;\n\n\tMAYBE_RETURN(get_next_hop(&dynptr, &off, encap, &next_hop));\n\n\tif (next_hop.s_addr == 0) {\n\t\tmetrics->accepted_packets_total_last_hop++;\n\t\treturn accept_locally(skb, encap);\n\t}\n\n\tverdict_t verdict;\n\tswitch (encap->gue.proto_ctype) {\n\tcase IPPROTO_IPIP:\n\t\tverdict = process_ipv4(skb, &dynptr, &off, metrics);\n\t\tbreak;\n\n\tcase IPPROTO_IPV6:\n\t\tverdict = process_ipv6(skb, &dynptr, &off, metrics);\n\t\tbreak;\n\n\tdefault:\n\t\tmetrics->errors_total_unknown_l3_proto++;\n\t\treturn TC_ACT_SHOT;\n\t}\n\n\tswitch (verdict) {\n\tcase INVALID:\n\t\t \n\t\treturn TC_ACT_SHOT;\n\n\tcase UNKNOWN:\n\t\treturn forward_to_next_hop(skb, &dynptr, encap, &next_hop, metrics);\n\n\tcase ECHO_REQUEST:\n\t\tmetrics->accepted_packets_total_icmp_echo_request++;\n\t\tbreak;\n\n\tcase SYN:\n\t\tif (encap->unigue.forward_syn) {\n\t\t\treturn forward_to_next_hop(skb, &dynptr, encap, &next_hop,\n\t\t\t\t\t\t   metrics);\n\t\t}\n\n\t\tmetrics->accepted_packets_total_syn++;\n\t\tbreak;\n\n\tcase SYN_COOKIE:\n\t\tmetrics->accepted_packets_total_syn_cookies++;\n\t\tbreak;\n\n\tcase ESTABLISHED:\n\t\tmetrics->accepted_packets_total_established++;\n\t\tbreak;\n\t}\n\n\tret = accept_locally(skb, encap);\n\n\tif (encap == encap_buffer)\n\t\tbpf_dynptr_write(&dynptr, 0, encap_buffer, sizeof(encap_buffer), 0);\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}