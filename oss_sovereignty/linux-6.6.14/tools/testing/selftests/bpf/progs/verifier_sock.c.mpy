{
  "module_name": "verifier_sock.c",
  "hash_id": "647d8f9796b4985c36af2c9b2b75f8515b2eadd4015d3b85593f6a9928642785",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/verifier_sock.c",
  "human_readable_source": "\n \n\n#include <linux/bpf.h>\n#include <bpf/bpf_helpers.h>\n#include \"bpf_misc.h\"\n\n#define sizeof_field(TYPE, MEMBER) sizeof((((TYPE *)0)->MEMBER))\n#define offsetofend(TYPE, MEMBER) \\\n\t(offsetof(TYPE, MEMBER)\t+ sizeof_field(TYPE, MEMBER))\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_REUSEPORT_SOCKARRAY);\n\t__uint(max_entries, 1);\n\t__type(key, __u32);\n\t__type(value, __u64);\n} map_reuseport_array SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_SOCKHASH);\n\t__uint(max_entries, 1);\n\t__type(key, int);\n\t__type(value, int);\n} map_sockhash SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_SOCKMAP);\n\t__uint(max_entries, 1);\n\t__type(key, int);\n\t__type(value, int);\n} map_sockmap SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_XSKMAP);\n\t__uint(max_entries, 1);\n\t__type(key, int);\n\t__type(value, int);\n} map_xskmap SEC(\".maps\");\n\nstruct val {\n\tint cnt;\n\tstruct bpf_spin_lock l;\n};\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_SK_STORAGE);\n\t__uint(max_entries, 0);\n\t__type(key, int);\n\t__type(value, struct val);\n\t__uint(map_flags, BPF_F_NO_PREALLOC);\n} sk_storage_map SEC(\".maps\");\n\nSEC(\"cgroup/skb\")\n__description(\"skb->sk: no NULL check\")\n__failure __msg(\"invalid mem access 'sock_common_or_null'\")\n__failure_unpriv\n__naked void skb_sk_no_null_check(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tr0 = *(u32*)(r1 + 0);\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"skb->sk: sk->family [non fullsock field]\")\n__success __success_unpriv __retval(0)\n__naked void sk_family_non_fullsock_field_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr0 = *(u32*)(r1 + %[bpf_sock_family]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_family, offsetof(struct bpf_sock, family))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"skb->sk: sk->type [fullsock field]\")\n__failure __msg(\"invalid sock_common access\")\n__failure_unpriv\n__naked void sk_sk_type_fullsock_field_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr0 = *(u32*)(r1 + %[bpf_sock_type]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"bpf_sk_fullsock(skb->sk): no !skb->sk check\")\n__failure __msg(\"type=sock_common_or_null expected=sock_common\")\n__failure_unpriv\n__naked void sk_no_skb_sk_check_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): no NULL check on ret\")\n__failure __msg(\"invalid mem access 'sock_or_null'\")\n__failure_unpriv\n__naked void no_null_check_on_ret_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tr0 = *(u32*)(r0 + %[bpf_sock_type]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->type [fullsock field]\")\n__success __success_unpriv __retval(0)\n__naked void sk_sk_type_fullsock_field_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u32*)(r0 + %[bpf_sock_type]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->family [non fullsock field]\")\n__success __success_unpriv __retval(0)\n__naked void sk_family_non_fullsock_field_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u32*)(r0 + %[bpf_sock_family]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_family, offsetof(struct bpf_sock, family))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->state [narrow load]\")\n__success __success_unpriv __retval(0)\n__naked void sk_sk_state_narrow_load(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u8*)(r0 + %[bpf_sock_state]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_state, offsetof(struct bpf_sock, state))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->dst_port [word load] (backward compatibility)\")\n__success __success_unpriv __retval(0)\n__naked void port_word_load_backward_compatibility(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u32*)(r0 + %[bpf_sock_dst_port]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_dst_port, offsetof(struct bpf_sock, dst_port))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->dst_port [half load]\")\n__success __success_unpriv __retval(0)\n__naked void sk_dst_port_half_load(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u16*)(r0 + %[bpf_sock_dst_port]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_dst_port, offsetof(struct bpf_sock, dst_port))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->dst_port [half load] (invalid)\")\n__failure __msg(\"invalid sock access\")\n__failure_unpriv\n__naked void dst_port_half_load_invalid_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u16*)(r0 + %[__imm_0]);\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__imm_0, offsetof(struct bpf_sock, dst_port) + 2),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->dst_port [byte load]\")\n__success __success_unpriv __retval(0)\n__naked void sk_dst_port_byte_load(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr2 = *(u8*)(r0 + %[bpf_sock_dst_port]);\t\t\\\n\tr2 = *(u8*)(r0 + %[__imm_0]);\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__imm_0, offsetof(struct bpf_sock, dst_port) + 1),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_dst_port, offsetof(struct bpf_sock, dst_port))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->dst_port [byte load] (invalid)\")\n__failure __msg(\"invalid sock access\")\n__failure_unpriv\n__naked void dst_port_byte_load_invalid(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u8*)(r0 + %[__imm_0]);\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__imm_0, offsetof(struct bpf_sock, dst_port) + 2),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): past sk->dst_port [half load] (invalid)\")\n__failure __msg(\"invalid sock access\")\n__failure_unpriv\n__naked void dst_port_half_load_invalid_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u16*)(r0 + %[bpf_sock_dst_port__end]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_dst_port__end, offsetofend(struct bpf_sock, dst_port))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->dst_ip6 [load 2nd byte]\")\n__success __success_unpriv __retval(0)\n__naked void dst_ip6_load_2nd_byte(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u8*)(r0 + %[__imm_0]);\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__imm_0, offsetof(struct bpf_sock, dst_ip6[0]) + 1),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->type [narrow load]\")\n__success __success_unpriv __retval(0)\n__naked void sk_sk_type_narrow_load(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u8*)(r0 + %[bpf_sock_type]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): sk->protocol [narrow load]\")\n__success __success_unpriv __retval(0)\n__naked void sk_sk_protocol_narrow_load(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u8*)(r0 + %[bpf_sock_protocol]);\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_protocol, offsetof(struct bpf_sock, protocol))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"sk_fullsock(skb->sk): beyond last field\")\n__failure __msg(\"invalid sock access\")\n__failure_unpriv\n__naked void skb_sk_beyond_last_field_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u32*)(r0 + %[bpf_sock_rx_queue_mapping__end]);\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_sock_rx_queue_mapping__end, offsetofend(struct bpf_sock, rx_queue_mapping))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"bpf_tcp_sock(skb->sk): no !skb->sk check\")\n__failure __msg(\"type=sock_common_or_null expected=sock_common\")\n__failure_unpriv\n__naked void sk_no_skb_sk_check_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"bpf_tcp_sock(skb->sk): no NULL check on ret\")\n__failure __msg(\"invalid mem access 'tcp_sock_or_null'\")\n__failure_unpriv\n__naked void no_null_check_on_ret_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tr0 = *(u32*)(r0 + %[bpf_tcp_sock_snd_cwnd]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_tcp_sock_snd_cwnd, offsetof(struct bpf_tcp_sock, snd_cwnd))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"bpf_tcp_sock(skb->sk): tp->snd_cwnd\")\n__success __success_unpriv __retval(0)\n__naked void skb_sk_tp_snd_cwnd_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u32*)(r0 + %[bpf_tcp_sock_snd_cwnd]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_tcp_sock_snd_cwnd, offsetof(struct bpf_tcp_sock, snd_cwnd))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"bpf_tcp_sock(skb->sk): tp->bytes_acked\")\n__success __success_unpriv __retval(0)\n__naked void skb_sk_tp_bytes_acked(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u64*)(r0 + %[bpf_tcp_sock_bytes_acked]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_tcp_sock_bytes_acked, offsetof(struct bpf_tcp_sock, bytes_acked))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"bpf_tcp_sock(skb->sk): beyond last field\")\n__failure __msg(\"invalid tcp_sock access\")\n__failure_unpriv\n__naked void skb_sk_beyond_last_field_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u64*)(r0 + %[bpf_tcp_sock_bytes_acked__end]);\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_tcp_sock_bytes_acked__end, offsetofend(struct bpf_tcp_sock, bytes_acked))\n\t: __clobber_all);\n}\n\nSEC(\"cgroup/skb\")\n__description(\"bpf_tcp_sock(bpf_sk_fullsock(skb->sk)): tp->snd_cwnd\")\n__success __success_unpriv __retval(0)\n__naked void skb_sk_tp_snd_cwnd_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l2_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl2_%=:\tr0 = *(u32*)(r0 + %[bpf_tcp_sock_snd_cwnd]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk)),\n\t  __imm_const(bpf_tcp_sock_snd_cwnd, offsetof(struct bpf_tcp_sock, snd_cwnd))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"bpf_sk_release(skb->sk)\")\n__failure __msg(\"R1 must be referenced when passed to release function\")\n__naked void bpf_sk_release_skb_sk(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"bpf_sk_release(bpf_sk_fullsock(skb->sk))\")\n__failure __msg(\"R1 must be referenced when passed to release function\")\n__naked void bpf_sk_fullsock_skb_sk(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = 1;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"bpf_sk_release(bpf_tcp_sock(skb->sk))\")\n__failure __msg(\"R1 must be referenced when passed to release function\")\n__naked void bpf_tcp_sock_skb_sk(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = 1;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release),\n\t  __imm(bpf_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"sk_storage_get(map, skb->sk, NULL, 0): value == NULL\")\n__success __retval(0)\n__naked void sk_null_0_value_null(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr4 = 0;\t\t\t\t\t\t\\\n\tr3 = 0;\t\t\t\t\t\t\\\n\tr2 = r0;\t\t\t\t\t\\\n\tr1 = %[sk_storage_map] ll;\t\t\t\\\n\tcall %[bpf_sk_storage_get];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_sk_storage_get),\n\t  __imm_addr(sk_storage_map),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"sk_storage_get(map, skb->sk, 1, 1): value == 1\")\n__failure __msg(\"R3 type=scalar expected=fp\")\n__naked void sk_1_1_value_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr4 = 1;\t\t\t\t\t\t\\\n\tr3 = 1;\t\t\t\t\t\t\\\n\tr2 = r0;\t\t\t\t\t\\\n\tr1 = %[sk_storage_map] ll;\t\t\t\\\n\tcall %[bpf_sk_storage_get];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_sk_storage_get),\n\t  __imm_addr(sk_storage_map),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"sk_storage_get(map, skb->sk, &stack_value, 1): stack_value\")\n__success __retval(0)\n__naked void stack_value_1_stack_value(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\t*(u64*)(r10 - 8) = r2;\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr4 = 1;\t\t\t\t\t\t\\\n\tr3 = r10;\t\t\t\t\t\\\n\tr3 += -8;\t\t\t\t\t\\\n\tr2 = r0;\t\t\t\t\t\\\n\tr1 = %[sk_storage_map] ll;\t\t\t\\\n\tcall %[bpf_sk_storage_get];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_sk_storage_get),\n\t  __imm_addr(sk_storage_map),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"bpf_map_lookup_elem(smap, &key)\")\n__failure __msg(\"cannot pass map_type 24 into func bpf_map_lookup_elem\")\n__naked void map_lookup_elem_smap_key(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r1;\t\t\t\t\\\n\tr2 = r10;\t\t\t\t\t\\\n\tr2 += -4;\t\t\t\t\t\\\n\tr1 = %[sk_storage_map] ll;\t\t\t\\\n\tcall %[bpf_map_lookup_elem];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_map_lookup_elem),\n\t  __imm_addr(sk_storage_map)\n\t: __clobber_all);\n}\n\nSEC(\"xdp\")\n__description(\"bpf_map_lookup_elem(xskmap, &key); xs->queue_id\")\n__success __retval(0)\n__naked void xskmap_key_xs_queue_id(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 8) = r1;\t\t\t\t\\\n\tr2 = r10;\t\t\t\t\t\\\n\tr2 += -8;\t\t\t\t\t\\\n\tr1 = %[map_xskmap] ll;\t\t\t\t\\\n\tcall %[bpf_map_lookup_elem];\t\t\t\\\n\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr0 = *(u32*)(r0 + %[bpf_xdp_sock_queue_id]);\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_map_lookup_elem),\n\t  __imm_addr(map_xskmap),\n\t  __imm_const(bpf_xdp_sock_queue_id, offsetof(struct bpf_xdp_sock, queue_id))\n\t: __clobber_all);\n}\n\nSEC(\"sk_skb\")\n__description(\"bpf_map_lookup_elem(sockmap, &key)\")\n__failure __msg(\"Unreleased reference id=2 alloc_insn=6\")\n__naked void map_lookup_elem_sockmap_key(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r1;\t\t\t\t\\\n\tr2 = r10;\t\t\t\t\t\\\n\tr2 += -4;\t\t\t\t\t\\\n\tr1 = %[map_sockmap] ll;\t\t\t\t\\\n\tcall %[bpf_map_lookup_elem];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_map_lookup_elem),\n\t  __imm_addr(map_sockmap)\n\t: __clobber_all);\n}\n\nSEC(\"sk_skb\")\n__description(\"bpf_map_lookup_elem(sockhash, &key)\")\n__failure __msg(\"Unreleased reference id=2 alloc_insn=6\")\n__naked void map_lookup_elem_sockhash_key(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r1;\t\t\t\t\\\n\tr2 = r10;\t\t\t\t\t\\\n\tr2 += -4;\t\t\t\t\t\\\n\tr1 = %[map_sockhash] ll;\t\t\t\\\n\tcall %[bpf_map_lookup_elem];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_map_lookup_elem),\n\t  __imm_addr(map_sockhash)\n\t: __clobber_all);\n}\n\nSEC(\"sk_skb\")\n__description(\"bpf_map_lookup_elem(sockmap, &key); sk->type [fullsock field]; bpf_sk_release(sk)\")\n__success\n__naked void field_bpf_sk_release_sk_1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r1;\t\t\t\t\\\n\tr2 = r10;\t\t\t\t\t\\\n\tr2 += -4;\t\t\t\t\t\\\n\tr1 = %[map_sockmap] ll;\t\t\t\t\\\n\tcall %[bpf_map_lookup_elem];\t\t\t\\\n\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr1 = r0;\t\t\t\t\t\\\n\tr0 = *(u32*)(r0 + %[bpf_sock_type]);\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_map_lookup_elem),\n\t  __imm(bpf_sk_release),\n\t  __imm_addr(map_sockmap),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type))\n\t: __clobber_all);\n}\n\nSEC(\"sk_skb\")\n__description(\"bpf_map_lookup_elem(sockhash, &key); sk->type [fullsock field]; bpf_sk_release(sk)\")\n__success\n__naked void field_bpf_sk_release_sk_2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r1;\t\t\t\t\\\n\tr2 = r10;\t\t\t\t\t\\\n\tr2 += -4;\t\t\t\t\t\\\n\tr1 = %[map_sockhash] ll;\t\t\t\\\n\tcall %[bpf_map_lookup_elem];\t\t\t\\\n\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr1 = r0;\t\t\t\t\t\\\n\tr0 = *(u32*)(r0 + %[bpf_sock_type]);\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_map_lookup_elem),\n\t  __imm(bpf_sk_release),\n\t  __imm_addr(map_sockhash),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type))\n\t: __clobber_all);\n}\n\nSEC(\"sk_reuseport\")\n__description(\"bpf_sk_select_reuseport(ctx, reuseport_array, &key, flags)\")\n__success\n__naked void ctx_reuseport_array_key_flags(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr4 = 0;\t\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r2;\t\t\t\t\\\n\tr3 = r10;\t\t\t\t\t\\\n\tr3 += -4;\t\t\t\t\t\\\n\tr2 = %[map_reuseport_array] ll;\t\t\t\\\n\tcall %[bpf_sk_select_reuseport];\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_select_reuseport),\n\t  __imm_addr(map_reuseport_array)\n\t: __clobber_all);\n}\n\nSEC(\"sk_reuseport\")\n__description(\"bpf_sk_select_reuseport(ctx, sockmap, &key, flags)\")\n__success\n__naked void reuseport_ctx_sockmap_key_flags(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr4 = 0;\t\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r2;\t\t\t\t\\\n\tr3 = r10;\t\t\t\t\t\\\n\tr3 += -4;\t\t\t\t\t\\\n\tr2 = %[map_sockmap] ll;\t\t\t\t\\\n\tcall %[bpf_sk_select_reuseport];\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_select_reuseport),\n\t  __imm_addr(map_sockmap)\n\t: __clobber_all);\n}\n\nSEC(\"sk_reuseport\")\n__description(\"bpf_sk_select_reuseport(ctx, sockhash, &key, flags)\")\n__success\n__naked void reuseport_ctx_sockhash_key_flags(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr4 = 0;\t\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r2;\t\t\t\t\\\n\tr3 = r10;\t\t\t\t\t\\\n\tr3 += -4;\t\t\t\t\t\\\n\tr2 = %[map_sockmap] ll;\t\t\t\t\\\n\tcall %[bpf_sk_select_reuseport];\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_select_reuseport),\n\t  __imm_addr(map_sockmap)\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"mark null check on return value of bpf_skc_to helpers\")\n__failure __msg(\"invalid mem access\")\n__naked void of_bpf_skc_to_helpers(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = *(u64*)(r1 + %[__sk_buff_sk]);\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r1;\t\t\t\t\t\\\n\tcall %[bpf_skc_to_tcp_sock];\t\t\t\\\n\tr7 = r0;\t\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_skc_to_tcp_request_sock];\t\t\\\n\tr8 = r0;\t\t\t\t\t\\\n\tif r8 != 0 goto l1_%=;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u8*)(r7 + 0);\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_skc_to_tcp_request_sock),\n\t  __imm(bpf_skc_to_tcp_sock),\n\t  __imm_const(__sk_buff_sk, offsetof(struct __sk_buff, sk))\n\t: __clobber_all);\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}