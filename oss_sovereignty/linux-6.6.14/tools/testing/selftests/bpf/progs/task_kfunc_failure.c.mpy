{
  "module_name": "task_kfunc_failure.c",
  "hash_id": "62ce6ebda3468fd1833712b0766df823d51777a0efe63915e00f01ebccf64138",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/task_kfunc_failure.c",
  "human_readable_source": "\n \n\n#include <vmlinux.h>\n#include <bpf/bpf_tracing.h>\n#include <bpf/bpf_helpers.h>\n\n#include \"bpf_misc.h\"\n#include \"task_kfunc_common.h\"\n\nchar _license[] SEC(\"license\") = \"GPL\";\n\n \n\nstatic struct __tasks_kfunc_map_value *insert_lookup_task(struct task_struct *task)\n{\n\tint status;\n\n\tstatus = tasks_kfunc_map_insert(task);\n\tif (status)\n\t\treturn NULL;\n\n\treturn tasks_kfunc_map_value_lookup(task);\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\nint BPF_PROG(task_kfunc_acquire_untrusted, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired;\n\tstruct __tasks_kfunc_map_value *v;\n\n\tv = insert_lookup_task(task);\n\tif (!v)\n\t\treturn 0;\n\n\t \n\tacquired = bpf_task_acquire(v->task);\n\tif (!acquired)\n\t\treturn 0;\n\n\tbpf_task_release(acquired);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"arg#0 pointer type STRUCT task_struct must point\")\nint BPF_PROG(task_kfunc_acquire_fp, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired, *stack_task = (struct task_struct *)&clone_flags;\n\n\t \n\tacquired = bpf_task_acquire((struct task_struct *)&stack_task);\n\tif (!acquired)\n\t\treturn 0;\n\n\tbpf_task_release(acquired);\n\n\treturn 0;\n}\n\nSEC(\"kretprobe/free_task\")\n__failure __msg(\"calling kernel function bpf_task_acquire is not allowed\")\nint BPF_PROG(task_kfunc_acquire_unsafe_kretprobe, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired;\n\n\t \n\tacquired = bpf_task_acquire(task);\n\tif (!acquired)\n\t\treturn 0;\n\tbpf_task_release(acquired);\n\n\treturn 0;\n}\n\nSEC(\"kretprobe/free_task\")\n__failure __msg(\"calling kernel function bpf_task_acquire is not allowed\")\nint BPF_PROG(task_kfunc_acquire_unsafe_kretprobe_rcu, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired;\n\n\tbpf_rcu_read_lock();\n\tif (!task) {\n\t\tbpf_rcu_read_unlock();\n\t\treturn 0;\n\t}\n\t \n\tacquired = bpf_task_acquire(task);\n\tif (acquired)\n\t\tbpf_task_release(acquired);\n\tbpf_rcu_read_unlock();\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\nint BPF_PROG(task_kfunc_acquire_null, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired;\n\n\t \n\tacquired = bpf_task_acquire(NULL);\n\tif (!acquired)\n\t\treturn 0;\n\tbpf_task_release(acquired);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Unreleased reference\")\nint BPF_PROG(task_kfunc_acquire_unreleased, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired;\n\n\tacquired = bpf_task_acquire(task);\n\n\t \n\t__sink(acquired);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Unreleased reference\")\nint BPF_PROG(task_kfunc_xchg_unreleased, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *kptr;\n\tstruct __tasks_kfunc_map_value *v;\n\n\tv = insert_lookup_task(task);\n\tif (!v)\n\t\treturn 0;\n\n\tkptr = bpf_kptr_xchg(&v->task, NULL);\n\tif (!kptr)\n\t\treturn 0;\n\n\t \n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\nint BPF_PROG(task_kfunc_acquire_release_no_null_check, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired;\n\n\tacquired = bpf_task_acquire(task);\n\t \n\tbpf_task_release(acquired);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\nint BPF_PROG(task_kfunc_release_untrusted, struct task_struct *task, u64 clone_flags)\n{\n\tstruct __tasks_kfunc_map_value *v;\n\n\tv = insert_lookup_task(task);\n\tif (!v)\n\t\treturn 0;\n\n\t \n\tbpf_task_release(v->task);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"arg#0 pointer type STRUCT task_struct must point\")\nint BPF_PROG(task_kfunc_release_fp, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired = (struct task_struct *)&clone_flags;\n\n\t \n\tbpf_task_release(acquired);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\nint BPF_PROG(task_kfunc_release_null, struct task_struct *task, u64 clone_flags)\n{\n\tstruct __tasks_kfunc_map_value local, *v;\n\tlong status;\n\tstruct task_struct *acquired, *old;\n\ts32 pid;\n\n\tstatus = bpf_probe_read_kernel(&pid, sizeof(pid), &task->pid);\n\tif (status)\n\t\treturn 0;\n\n\tlocal.task = NULL;\n\tstatus = bpf_map_update_elem(&__tasks_kfunc_map, &pid, &local, BPF_NOEXIST);\n\tif (status)\n\t\treturn status;\n\n\tv = bpf_map_lookup_elem(&__tasks_kfunc_map, &pid);\n\tif (!v)\n\t\treturn -ENOENT;\n\n\tacquired = bpf_task_acquire(task);\n\tif (!acquired)\n\t\treturn -EEXIST;\n\n\told = bpf_kptr_xchg(&v->task, acquired);\n\n\t \n\tbpf_task_release(old);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"release kernel function bpf_task_release expects\")\nint BPF_PROG(task_kfunc_release_unacquired, struct task_struct *task, u64 clone_flags)\n{\n\t \n\tbpf_task_release(task);\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\nint BPF_PROG(task_kfunc_from_pid_no_null_check, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *acquired;\n\n\tacquired = bpf_task_from_pid(task->pid);\n\n\t \n\tbpf_task_release(acquired);\n\n\treturn 0;\n}\n\nSEC(\"lsm/task_free\")\n__failure __msg(\"reg type unsupported for arg#0 function\")\nint BPF_PROG(task_kfunc_from_lsm_task_free, struct task_struct *task)\n{\n\tstruct task_struct *acquired;\n\n\t \n\tacquired = bpf_task_acquire(task);\n\tif (!acquired)\n\t\treturn 0;\n\n\tbpf_task_release(acquired);\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"access beyond the end of member comm\")\nint BPF_PROG(task_access_comm1, struct task_struct *task, u64 clone_flags)\n{\n\tbpf_strncmp(task->comm, 17, \"foo\");\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"access beyond the end of member comm\")\nint BPF_PROG(task_access_comm2, struct task_struct *task, u64 clone_flags)\n{\n\tbpf_strncmp(task->comm + 1, 16, \"foo\");\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"write into memory\")\nint BPF_PROG(task_access_comm3, struct task_struct *task, u64 clone_flags)\n{\n\tbpf_probe_read_kernel(task->comm, 16, task->comm);\n\treturn 0;\n}\n\nSEC(\"fentry/__set_task_comm\")\n__failure __msg(\"R1 type=ptr_ expected\")\nint BPF_PROG(task_access_comm4, struct task_struct *task, const char *buf, bool exec)\n{\n\t \n\tbpf_strncmp(task->comm, 16, \"foo\");\n\treturn 0;\n}\n\nSEC(\"tp_btf/task_newtask\")\n__failure __msg(\"R1 must be referenced or trusted\")\nint BPF_PROG(task_kfunc_release_in_map, struct task_struct *task, u64 clone_flags)\n{\n\tstruct task_struct *local;\n\tstruct __tasks_kfunc_map_value *v;\n\n\tif (tasks_kfunc_map_insert(task))\n\t\treturn 0;\n\n\tv = tasks_kfunc_map_value_lookup(task);\n\tif (!v)\n\t\treturn 0;\n\n\tbpf_rcu_read_lock();\n\tlocal = v->task;\n\tif (!local) {\n\t\tbpf_rcu_read_unlock();\n\t\treturn 0;\n\t}\n\t \n\tbpf_task_release(local);\n\tbpf_rcu_read_unlock();\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}