{
  "module_name": "verifier_ref_tracking.c",
  "hash_id": "6bbb84d5ba6c6dc1bd62c347b225ff6490f986f16db6a0fff517072c18bc551a",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/progs/verifier_ref_tracking.c",
  "human_readable_source": "\n \n\n#include <linux/bpf.h>\n#include <bpf/bpf_helpers.h>\n#include \"../../../include/linux/filter.h\"\n#include \"bpf_misc.h\"\n\n#define BPF_SK_LOOKUP(func) \\\n\t  \\\n\t\"r2 = 0;\"\t\t\t\\\n\t\"*(u32*)(r10 - 8) = r2;\"\t\\\n\t\"*(u64*)(r10 - 16) = r2;\"\t\\\n\t\"*(u64*)(r10 - 24) = r2;\"\t\\\n\t\"*(u64*)(r10 - 32) = r2;\"\t\\\n\t\"*(u64*)(r10 - 40) = r2;\"\t\\\n\t\"*(u64*)(r10 - 48) = r2;\"\t\\\n\t  \\\n\t\"r2 = r10;\"\t\t\t\\\n\t\"r2 += -48;\"\t\t\t\\\n\t\"r3 = %[sizeof_bpf_sock_tuple];\"\\\n\t\"r4 = 0;\"\t\t\t\\\n\t\"r5 = 0;\"\t\t\t\\\n\t\"call %[\" #func \"];\"\n\nstruct bpf_key {} __attribute__((preserve_access_index));\n\nextern void bpf_key_put(struct bpf_key *key) __ksym;\nextern struct bpf_key *bpf_lookup_system_key(__u64 id) __ksym;\nextern struct bpf_key *bpf_lookup_user_key(__u32 serial, __u64 flags) __ksym;\n\n \nvoid __kfunc_btf_root(void)\n{\n\tbpf_key_put(0);\n\tbpf_lookup_system_key(0);\n\tbpf_lookup_user_key(0, 0);\n}\n\n#define MAX_ENTRIES 11\n\nstruct test_val {\n\tunsigned int index;\n\tint foo[MAX_ENTRIES];\n};\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_ARRAY);\n\t__uint(max_entries, 1);\n\t__type(key, int);\n\t__type(value, struct test_val);\n} map_array_48b SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_RINGBUF);\n\t__uint(max_entries, 4096);\n} map_ringbuf SEC(\".maps\");\n\nvoid dummy_prog_42_tc(void);\nvoid dummy_prog_24_tc(void);\nvoid dummy_prog_loop1_tc(void);\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_PROG_ARRAY);\n\t__uint(max_entries, 4);\n\t__uint(key_size, sizeof(int));\n\t__array(values, void (void));\n} map_prog1_tc SEC(\".maps\") = {\n\t.values = {\n\t\t[0] = (void *)&dummy_prog_42_tc,\n\t\t[1] = (void *)&dummy_prog_loop1_tc,\n\t\t[2] = (void *)&dummy_prog_24_tc,\n\t},\n};\n\nSEC(\"tc\")\n__auxiliary\n__naked void dummy_prog_42_tc(void)\n{\n\tasm volatile (\"r0 = 42; exit;\");\n}\n\nSEC(\"tc\")\n__auxiliary\n__naked void dummy_prog_24_tc(void)\n{\n\tasm volatile (\"r0 = 24; exit;\");\n}\n\nSEC(\"tc\")\n__auxiliary\n__naked void dummy_prog_loop1_tc(void)\n{\n\tasm volatile (\"\t\t\t\\\n\tr3 = 1;\t\t\t\t\\\n\tr2 = %[map_prog1_tc] ll;\t\\\n\tcall %[bpf_tail_call];\t\t\\\n\tr0 = 41;\t\t\t\\\n\texit;\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_tail_call),\n\t  __imm_addr(map_prog1_tc)\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: leak potential reference\")\n__failure __msg(\"Unreleased reference\")\n__naked void reference_tracking_leak_potential_reference(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr6 = r0;\t\t \t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: leak potential reference to sock_common\")\n__failure __msg(\"Unreleased reference\")\n__naked void potential_reference_to_sock_common_1(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_skc_lookup_tcp)\n\"\tr6 = r0;\t\t \t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_skc_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: leak potential reference on stack\")\n__failure __msg(\"Unreleased reference\")\n__naked void leak_potential_reference_on_stack(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr4 = r10;\t\t\t\t\t\\\n\tr4 += -8;\t\t\t\t\t\\\n\t*(u64*)(r4 + 0) = r0;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: leak potential reference on stack 2\")\n__failure __msg(\"Unreleased reference\")\n__naked void potential_reference_on_stack_2(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr4 = r10;\t\t\t\t\t\\\n\tr4 += -8;\t\t\t\t\t\\\n\t*(u64*)(r4 + 0) = r0;\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\t*(u64*)(r4 + 0) = r1;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: zero potential reference\")\n__failure __msg(\"Unreleased reference\")\n__naked void reference_tracking_zero_potential_reference(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr0 = 0;\t\t\t \t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: zero potential reference to sock_common\")\n__failure __msg(\"Unreleased reference\")\n__naked void potential_reference_to_sock_common_2(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_skc_lookup_tcp)\n\"\tr0 = 0;\t\t\t \t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_skc_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: copy and zero potential references\")\n__failure __msg(\"Unreleased reference\")\n__naked void copy_and_zero_potential_references(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr7 = r0;\t\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\tr7 = 0;\t\t\t \t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"lsm.s/bpf\")\n__description(\"reference tracking: acquire/release user key reference\")\n__success\n__naked void acquire_release_user_key_reference(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = -3;\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_lookup_user_key];\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_key_put];\t\t\t\t\\\nl0_%=:\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_key_put),\n\t  __imm(bpf_lookup_user_key)\n\t: __clobber_all);\n}\n\nSEC(\"lsm.s/bpf\")\n__description(\"reference tracking: acquire/release system key reference\")\n__success\n__naked void acquire_release_system_key_reference(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 1;\t\t\t\t\t\t\\\n\tcall %[bpf_lookup_system_key];\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_key_put];\t\t\t\t\\\nl0_%=:\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_key_put),\n\t  __imm(bpf_lookup_system_key)\n\t: __clobber_all);\n}\n\nSEC(\"lsm.s/bpf\")\n__description(\"reference tracking: release user key reference without check\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\n__naked void user_key_reference_without_check(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = -3;\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_lookup_user_key];\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_key_put];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_key_put),\n\t  __imm(bpf_lookup_user_key)\n\t: __clobber_all);\n}\n\nSEC(\"lsm.s/bpf\")\n__description(\"reference tracking: release system key reference without check\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\n__naked void system_key_reference_without_check(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 1;\t\t\t\t\t\t\\\n\tcall %[bpf_lookup_system_key];\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_key_put];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_key_put),\n\t  __imm(bpf_lookup_system_key)\n\t: __clobber_all);\n}\n\nSEC(\"lsm.s/bpf\")\n__description(\"reference tracking: release with NULL key pointer\")\n__failure __msg(\"Possibly NULL pointer passed to trusted arg0\")\n__naked void release_with_null_key_pointer(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_key_put];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_key_put)\n\t: __clobber_all);\n}\n\nSEC(\"lsm.s/bpf\")\n__description(\"reference tracking: leak potential reference to user key\")\n__failure __msg(\"Unreleased reference\")\n__naked void potential_reference_to_user_key(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = -3;\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_lookup_user_key];\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_lookup_user_key)\n\t: __clobber_all);\n}\n\nSEC(\"lsm.s/bpf\")\n__description(\"reference tracking: leak potential reference to system key\")\n__failure __msg(\"Unreleased reference\")\n__naked void potential_reference_to_system_key(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr1 = 1;\t\t\t\t\t\t\\\n\tcall %[bpf_lookup_system_key];\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_lookup_system_key)\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference without check\")\n__failure __msg(\"type=sock_or_null expected=sock\")\n__naked void tracking_release_reference_without_check(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\t \t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference to sock_common without check\")\n__failure __msg(\"type=sock_common_or_null expected=sock\")\n__naked void to_sock_common_without_check(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_skc_lookup_tcp)\n\"\t \t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release),\n\t  __imm(bpf_skc_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference\")\n__success __retval(0)\n__naked void reference_tracking_release_reference(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference to sock_common\")\n__success __retval(0)\n__naked void release_reference_to_sock_common(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_skc_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release),\n\t  __imm(bpf_skc_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference 2\")\n__success __retval(0)\n__naked void reference_tracking_release_reference_2(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference twice\")\n__failure __msg(\"type=scalar expected=sock\")\n__naked void reference_tracking_release_reference_twice(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tr6 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference twice inside branch\")\n__failure __msg(\"type=scalar expected=sock\")\n__naked void release_reference_twice_inside_branch(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tr6 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t \t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: alloc, check, free in one subbranch\")\n__failure __msg(\"Unreleased reference\")\n__flag(BPF_F_ANY_ALIGNMENT)\n__naked void check_free_in_one_subbranch(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr2 = *(u32*)(r1 + %[__sk_buff_data]);\t\t\\\n\tr3 = *(u32*)(r1 + %[__sk_buff_data_end]);\t\\\n\tr0 = r2;\t\t\t\t\t\\\n\tr0 += 16;\t\t\t\t\t\\\n\t \t\\\n\tif r0 <= r3 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = *(u32*)(r2 + %[__sk_buff_mark]);\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r6 == 0 goto l1_%=;\t\t \\\n\t \t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tif r0 == 0 goto l2_%=;\t\t \t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl2_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(__sk_buff_data, offsetof(struct __sk_buff, data)),\n\t  __imm_const(__sk_buff_data_end, offsetof(struct __sk_buff, data_end)),\n\t  __imm_const(__sk_buff_mark, offsetof(struct __sk_buff, mark)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: alloc, check, free in both subbranches\")\n__success __retval(0) __flag(BPF_F_ANY_ALIGNMENT)\n__naked void check_free_in_both_subbranches(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr2 = *(u32*)(r1 + %[__sk_buff_data]);\t\t\\\n\tr3 = *(u32*)(r1 + %[__sk_buff_data_end]);\t\\\n\tr0 = r2;\t\t\t\t\t\\\n\tr0 += 16;\t\t\t\t\t\\\n\t \t\\\n\tif r0 <= r3 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = *(u32*)(r2 + %[__sk_buff_mark]);\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r6 == 0 goto l1_%=;\t\t \\\n\tif r0 == 0 goto l2_%=;\t\t \t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl2_%=:\texit;\t\t\t\t\t\t\\\nl1_%=:\tif r0 == 0 goto l3_%=;\t\t \t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl3_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(__sk_buff_data, offsetof(struct __sk_buff, data)),\n\t  __imm_const(__sk_buff_data_end, offsetof(struct __sk_buff, data_end)),\n\t  __imm_const(__sk_buff_mark, offsetof(struct __sk_buff, mark)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking in call: free reference in subprog\")\n__success __retval(0)\n__naked void call_free_reference_in_subprog(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t \t\\\n\tcall call_free_reference_in_subprog__1;\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid call_free_reference_in_subprog__1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\tr2 = r1;\t\t\t\t\t\\\n\tif r2 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release)\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking in call: free reference in subprog and outside\")\n__failure __msg(\"type=scalar expected=sock\")\n__naked void reference_in_subprog_and_outside(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t \t\\\n\tr6 = r0;\t\t\t\t\t\\\n\tcall reference_in_subprog_and_outside__1;\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid reference_in_subprog_and_outside__1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\tr2 = r1;\t\t\t\t\t\\\n\tif r2 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release)\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking in call: alloc & leak reference in subprog\")\n__failure __msg(\"Unreleased reference\")\n__naked void alloc_leak_reference_in_subprog(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr4 = r10;\t\t\t\t\t\\\n\tr4 += -8;\t\t\t\t\t\\\n\tcall alloc_leak_reference_in_subprog__1;\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t::: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid alloc_leak_reference_in_subprog__1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\tr6 = r4;\t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\t \\\n\t*(u64*)(r6 + 0) = r0;\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking in call: alloc in subprog, release outside\")\n__success __retval(POINTER_VALUE)\n__naked void alloc_in_subprog_release_outside(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr4 = r10;\t\t\t\t\t\\\n\tcall alloc_in_subprog_release_outside__1;\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release)\n\t: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid alloc_in_subprog_release_outside__1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\texit;\t\t\t\t \t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking in call: sk_ptr leak into caller stack\")\n__failure __msg(\"Unreleased reference\")\n__naked void ptr_leak_into_caller_stack(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr4 = r10;\t\t\t\t\t\\\n\tr4 += -8;\t\t\t\t\t\\\n\tcall ptr_leak_into_caller_stack__1;\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t::: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid ptr_leak_into_caller_stack__1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\tr5 = r10;\t\t\t\t\t\\\n\tr5 += -8;\t\t\t\t\t\\\n\t*(u64*)(r5 + 0) = r4;\t\t\t\t\\\n\tcall ptr_leak_into_caller_stack__2;\t\t\\\n\t \\\n\tr5 = r10;\t\t\t\t\t\\\n\tr5 += -8;\t\t\t\t\t\\\n\tr4 = *(u64*)(r5 + 0);\t\t\t\t\\\n\t*(u64*)(r4 + 0) = r0;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t::: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid ptr_leak_into_caller_stack__2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking in call: sk_ptr spill into caller stack\")\n__success __retval(0)\n__naked void ptr_spill_into_caller_stack(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr4 = r10;\t\t\t\t\t\\\n\tr4 += -8;\t\t\t\t\t\\\n\tcall ptr_spill_into_caller_stack__1;\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t::: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid ptr_spill_into_caller_stack__1(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\tr5 = r10;\t\t\t\t\t\\\n\tr5 += -8;\t\t\t\t\t\\\n\t*(u64*)(r5 + 0) = r4;\t\t\t\t\\\n\tcall ptr_spill_into_caller_stack__2;\t\t\\\n\t \\\n\tr5 = r10;\t\t\t\t\t\\\n\tr5 += -8;\t\t\t\t\t\\\n\tr4 = *(u64*)(r5 + 0);\t\t\t\t\\\n\t*(u64*)(r4 + 0) = r0;\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\t \\\n\tr1 = *(u64*)(r4 + 0);\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_release)\n\t: __clobber_all);\n}\n\nstatic __naked __noinline __attribute__((used))\nvoid ptr_spill_into_caller_stack__2(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: allow LD_ABS\")\n__success __retval(0)\n__naked void reference_tracking_allow_ld_abs(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr6 = r1;\t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\tr0 = *(u8*)skb[0];\t\t\t\t\\\n\tr0 = *(u16*)skb[0];\t\t\t\t\\\n\tr0 = *(u32*)skb[0];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: forbid LD_ABS while holding reference\")\n__failure __msg(\"BPF_LD_[ABS|IND] cannot be mixed with socket references\")\n__naked void ld_abs_while_holding_reference(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr6 = r1;\t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr0 = *(u8*)skb[0];\t\t\t\t\\\n\tr0 = *(u16*)skb[0];\t\t\t\t\\\n\tr0 = *(u32*)skb[0];\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: allow LD_IND\")\n__success __retval(1)\n__naked void reference_tracking_allow_ld_ind(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr6 = r1;\t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\tr7 = 1;\t\t\t\t\t\t\\\n\t.8byte %[ld_ind];\t\t\t\t\\\n\tr0 = r7;\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple)),\n\t  __imm_insn(ld_ind, BPF_LD_IND(BPF_W, BPF_REG_7, -0x200000))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: forbid LD_IND while holding reference\")\n__failure __msg(\"BPF_LD_[ABS|IND] cannot be mixed with socket references\")\n__naked void ld_ind_while_holding_reference(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr6 = r1;\t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr4 = r0;\t\t\t\t\t\\\n\tr7 = 1;\t\t\t\t\t\t\\\n\t.8byte %[ld_ind];\t\t\t\t\\\n\tr0 = r7;\t\t\t\t\t\\\n\tr1 = r4;\t\t\t\t\t\\\n\tif r1 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple)),\n\t  __imm_insn(ld_ind, BPF_LD_IND(BPF_W, BPF_REG_7, -0x200000))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: check reference or tail call\")\n__success __retval(0)\n__naked void check_reference_or_tail_call(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr7 = r1;\t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\t \t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tif r1 != 0 goto l0_%=;\t\t\t\t\\\n\t \t\t\t\t\\\n\tr3 = 3;\t\t\t\t\t\t\\\n\tr2 = %[map_prog1_tc] ll;\t\t\t\\\n\tr1 = r7;\t\t\t\t\t\\\n\tcall %[bpf_tail_call];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tail_call),\n\t  __imm_addr(map_prog1_tc),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: release reference then tail call\")\n__success __retval(0)\n__naked void release_reference_then_tail_call(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr7 = r1;\t\t\t\t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\t \t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tif r1 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\t \t\t\t\t\\\n\tr3 = 3;\t\t\t\t\t\t\\\n\tr2 = %[map_prog1_tc] ll;\t\t\t\\\n\tr1 = r7;\t\t\t\t\t\\\n\tcall %[bpf_tail_call];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tail_call),\n\t  __imm_addr(map_prog1_tc),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: leak possible reference over tail call\")\n__failure __msg(\"tail_call would lead to reference leak\")\n__naked void possible_reference_over_tail_call(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr7 = r1;\t\t\t\t\t\\\n\t \t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\t \t\t\t\t\\\n\tr6 = r0;\t\t\t\t\t\\\n\tr3 = 3;\t\t\t\t\t\t\\\n\tr2 = %[map_prog1_tc] ll;\t\t\t\\\n\tr1 = r7;\t\t\t\t\t\\\n\tcall %[bpf_tail_call];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\t \t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tif r1 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tail_call),\n\t  __imm_addr(map_prog1_tc),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: leak checked reference over tail call\")\n__failure __msg(\"tail_call would lead to reference leak\")\n__naked void checked_reference_over_tail_call(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr7 = r1;\t\t\t\t\t\\\n\t \t\t\\\n\"\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr6 = r0;\t\t\t\t\t\\\n\t \t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\t \t\t\t\t\\\n\tr3 = 0;\t\t\t\t\t\t\\\n\tr2 = %[map_prog1_tc] ll;\t\t\t\\\n\tr1 = r7;\t\t\t\t\t\\\n\tcall %[bpf_tail_call];\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tail_call),\n\t  __imm_addr(map_prog1_tc),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: mangle and release sock_or_null\")\n__failure __msg(\"R1 pointer arithmetic on sock_or_null prohibited\")\n__naked void and_release_sock_or_null(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tr1 += 5;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: mangle and release sock\")\n__failure __msg(\"R1 pointer arithmetic on sock prohibited\")\n__naked void tracking_mangle_and_release_sock(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tr1 += 5;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: access member\")\n__success __retval(0)\n__naked void reference_tracking_access_member(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr6 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tr2 = *(u32*)(r0 + 4);\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: write to member\")\n__failure __msg(\"cannot write into sock\")\n__naked void reference_tracking_write_to_member(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr6 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tr2 = 42 ll;\t\t\t\t\t\\\n\t*(u32*)(r1 + %[bpf_sock_mark]) = r2;\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\nl0_%=:\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = 0 ll;\t\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(bpf_sock_mark, offsetof(struct bpf_sock, mark)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: invalid 64-bit access of member\")\n__failure __msg(\"invalid sock access off=0 size=8\")\n__naked void _64_bit_access_of_member(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr6 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tr2 = *(u64*)(r0 + 0);\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: access after release\")\n__failure __msg(\"!read_ok\")\n__naked void reference_tracking_access_after_release(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr1 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr2 = *(u32*)(r1 + 0);\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: direct access for lookup\")\n__success __retval(0)\n__naked void tracking_direct_access_for_lookup(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\t \\\n\tr2 = *(u32*)(r1 + %[__sk_buff_data]);\t\t\\\n\tr3 = *(u32*)(r1 + %[__sk_buff_data_end]);\t\\\n\tr0 = r2;\t\t\t\t\t\\\n\tr0 += 64;\t\t\t\t\t\\\n\tif r0 > r3 goto l0_%=;\t\t\t\t\\\n\t \t\\\n\tr3 = %[sizeof_bpf_sock_tuple];\t\t\t\\\n\tr4 = 0;\t\t\t\t\t\t\\\n\tr5 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_sk_lookup_tcp];\t\t\t\\\n\tr6 = r0;\t\t\t\t\t\\\n\tif r0 == 0 goto l0_%=;\t\t\t\t\\\n\tr2 = *(u32*)(r0 + 4);\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(__sk_buff_data, offsetof(struct __sk_buff, data)),\n\t  __imm_const(__sk_buff_data_end, offsetof(struct __sk_buff, data_end)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: use ptr from bpf_tcp_sock() after release\")\n__failure __msg(\"invalid mem access\")\n__flag(BPF_F_ANY_ALIGNMENT)\n__naked void bpf_tcp_sock_after_release(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr7 = r0;\t\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = *(u32*)(r7 + %[bpf_tcp_sock_snd_cwnd]);\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tcp_sock),\n\t  __imm_const(bpf_tcp_sock_snd_cwnd, offsetof(struct bpf_tcp_sock, snd_cwnd)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: use ptr from bpf_sk_fullsock() after release\")\n__failure __msg(\"invalid mem access\")\n__flag(BPF_F_ANY_ALIGNMENT)\n__naked void bpf_sk_fullsock_after_release(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr7 = r0;\t\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = *(u32*)(r7 + %[bpf_sock_type]);\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: use ptr from bpf_sk_fullsock(tp) after release\")\n__failure __msg(\"invalid mem access\")\n__flag(BPF_F_ANY_ALIGNMENT)\n__naked void sk_fullsock_tp_after_release(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tr6 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tif r6 != 0 goto l2_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl2_%=:\tr0 = *(u32*)(r6 + %[bpf_sock_type]);\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tcp_sock),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: use sk after bpf_sk_release(tp)\")\n__failure __msg(\"invalid mem access\")\n__flag(BPF_F_ANY_ALIGNMENT)\n__naked void after_bpf_sk_release_tp(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = *(u32*)(r6 + %[bpf_sock_type]);\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tcp_sock),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: use ptr from bpf_get_listener_sock() after bpf_sk_release(sk)\")\n__success __retval(0)\n__naked void after_bpf_sk_release_sk(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_get_listener_sock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r6;\t\t\t\t\t\\\n\tr6 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = *(u32*)(r6 + %[bpf_sock_src_port]);\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_get_listener_sock),\n\t  __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(bpf_sock_src_port, offsetof(struct bpf_sock, src_port)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: bpf_sk_release(listen_sk)\")\n__failure __msg(\"R1 must be referenced when passed to release function\")\n__naked void bpf_sk_release_listen_sk(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_get_listener_sock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = *(u32*)(r6 + %[bpf_sock_type]);\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_get_listener_sock),\n\t  __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(bpf_sock_type, offsetof(struct bpf_sock, type)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\n/* !bpf_sk_fullsock(sk) is checked but !bpf_tcp_sock(sk) is not checked */\nSEC(\"tc\")\n__description(\"reference tracking: tp->snd_cwnd after bpf_sk_fullsock(sk) and bpf_tcp_sock(sk)\")\n__failure __msg(\"invalid mem access\")\n__naked void and_bpf_tcp_sock_sk(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_fullsock];\t\t\t\\\n\tr7 = r0;\t\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_tcp_sock];\t\t\t\t\\\n\tr8 = r0;\t\t\t\t\t\\\n\tif r7 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr0 = *(u32*)(r8 + %[bpf_tcp_sock_snd_cwnd]);\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_fullsock),\n\t  __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_tcp_sock),\n\t  __imm_const(bpf_tcp_sock_snd_cwnd, offsetof(struct bpf_tcp_sock, snd_cwnd)),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: branch tracking valid pointer null comparison\")\n__success __retval(0)\n__naked void tracking_valid_pointer_null_comparison(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr6 = r0;\t\t\t\t\t\\\n\tr3 = 1;\t\t\t\t\t\t\\\n\tif r6 != 0 goto l0_%=;\t\t\t\t\\\n\tr3 = 0;\t\t\t\t\t\t\\\nl0_%=:\tif r6 == 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl1_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: branch tracking valid pointer value comparison\")\n__failure __msg(\"Unreleased reference\")\n__naked void tracking_valid_pointer_value_comparison(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tr6 = r0;\t\t\t\t\t\\\n\tr3 = 1;\t\t\t\t\t\t\\\n\tif r6 == 0 goto l0_%=;\t\t\t\t\\\n\tr3 = 0;\t\t\t\t\t\t\\\n\tif r6 == 1234 goto l0_%=;\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\nl0_%=:\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: bpf_sk_release(btf_tcp_sock)\")\n__success\n__retval(0)\n__naked void sk_release_btf_tcp_sock(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_skc_to_tcp_sock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_skc_to_tcp_sock),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"tc\")\n__description(\"reference tracking: use ptr from bpf_skc_to_tcp_sock() after release\")\n__failure __msg(\"invalid mem access\")\n__naked void to_tcp_sock_after_release(void)\n{\n\tasm volatile (\n\tBPF_SK_LOOKUP(bpf_sk_lookup_tcp)\n\"\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr6 = r0;\t\t\t\t\t\\\n\tr1 = r0;\t\t\t\t\t\\\n\tcall %[bpf_skc_to_tcp_sock];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr7 = r0;\t\t\t\t\t\\\n\tr1 = r6;\t\t\t\t\t\\\n\tcall %[bpf_sk_release];\t\t\t\t\\\n\tr0 = *(u8*)(r7 + 0);\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_sk_lookup_tcp),\n\t  __imm(bpf_sk_release),\n\t  __imm(bpf_skc_to_tcp_sock),\n\t  __imm_const(sizeof_bpf_sock_tuple, sizeof(struct bpf_sock_tuple))\n\t: __clobber_all);\n}\n\nSEC(\"socket\")\n__description(\"reference tracking: try to leak released ptr reg\")\n__success __failure_unpriv __msg_unpriv(\"R8 !read_ok\")\n__retval(0)\n__naked void to_leak_released_ptr_reg(void)\n{\n\tasm volatile (\"\t\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\t*(u32*)(r10 - 4) = r0;\t\t\t\t\\\n\tr2 = r10;\t\t\t\t\t\\\n\tr2 += -4;\t\t\t\t\t\\\n\tr1 = %[map_array_48b] ll;\t\t\t\\\n\tcall %[bpf_map_lookup_elem];\t\t\t\\\n\tif r0 != 0 goto l0_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl0_%=:\tr9 = r0;\t\t\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\tr1 = %[map_ringbuf] ll;\t\t\t\t\\\n\tr2 = 8;\t\t\t\t\t\t\\\n\tr3 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_ringbuf_reserve];\t\t\t\\\n\tif r0 != 0 goto l1_%=;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\nl1_%=:\tr8 = r0;\t\t\t\t\t\\\n\tr1 = r8;\t\t\t\t\t\\\n\tr2 = 0;\t\t\t\t\t\t\\\n\tcall %[bpf_ringbuf_discard];\t\t\t\\\n\tr0 = 0;\t\t\t\t\t\t\\\n\t*(u64*)(r9 + 0) = r8;\t\t\t\t\\\n\texit;\t\t\t\t\t\t\\\n\"\t:\n\t: __imm(bpf_map_lookup_elem),\n\t  __imm(bpf_ringbuf_discard),\n\t  __imm(bpf_ringbuf_reserve),\n\t  __imm_addr(map_array_48b),\n\t  __imm_addr(map_ringbuf)\n\t: __clobber_all);\n}\n\nchar _license[] SEC(\"license\") = \"GPL\";\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}