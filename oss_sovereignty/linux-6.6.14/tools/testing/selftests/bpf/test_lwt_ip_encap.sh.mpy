{
  "module_name": "test_lwt_ip_encap.sh",
  "hash_id": "20702e6d34d13204b4d33e20bab89c996929b9c2f1196a58183afb7587242107",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/test_lwt_ip_encap.sh",
  "human_readable_source": "#!/bin/bash\n# SPDX-License-Identifier: GPL-2.0\n#\n# Setup/topology:\n#\n#    NS1             NS2             NS3\n#   veth1 <---> veth2   veth3 <---> veth4 (the top route)\n#   veth5 <---> veth6   veth7 <---> veth8 (the bottom route)\n#\n#   each vethN gets IPv[4|6]_N address\n#\n#   IPv*_SRC = IPv*_1\n#   IPv*_DST = IPv*_4\n#\n#   all tests test pings from IPv*_SRC to IPv*_DST\n#\n#   by default, routes are configured to allow packets to go\n#   IP*_1 <=> IP*_2 <=> IP*_3 <=> IP*_4 (the top route)\n#\n#   a GRE device is installed in NS3 with IPv*_GRE, and\n#   NS1/NS2 are configured to route packets to IPv*_GRE via IP*_8\n#   (the bottom route)\n#\n# Tests:\n#\n#   1. routes NS2->IPv*_DST are brought down, so the only way a ping\n#      from IP*_SRC to IP*_DST can work is via IPv*_GRE\n#\n#   2a. in an egress test, a bpf LWT_XMIT program is installed on veth1\n#       that encaps the packets with an IP/GRE header to route to IPv*_GRE\n#\n#       ping: SRC->[encap at veth1:egress]->GRE:decap->DST\n#       ping replies go DST->SRC directly\n#\n#   2b. in an ingress test, a bpf LWT_IN program is installed on veth2\n#       that encaps the packets with an IP/GRE header to route to IPv*_GRE\n#\n#       ping: SRC->[encap at veth2:ingress]->GRE:decap->DST\n#       ping replies go DST->SRC directly\n\nBPF_FILE=\"test_lwt_ip_encap.bpf.o\"\nif [[ $EUID -ne 0 ]]; then\n\techo \"This script must be run as root\"\n\techo \"FAIL\"\n\texit 1\nfi\n\nreadonly NS1=\"ns1-$(mktemp -u XXXXXX)\"\nreadonly NS2=\"ns2-$(mktemp -u XXXXXX)\"\nreadonly NS3=\"ns3-$(mktemp -u XXXXXX)\"\n\nreadonly IPv4_1=\"172.16.1.100\"\nreadonly IPv4_2=\"172.16.2.100\"\nreadonly IPv4_3=\"172.16.3.100\"\nreadonly IPv4_4=\"172.16.4.100\"\nreadonly IPv4_5=\"172.16.5.100\"\nreadonly IPv4_6=\"172.16.6.100\"\nreadonly IPv4_7=\"172.16.7.100\"\nreadonly IPv4_8=\"172.16.8.100\"\nreadonly IPv4_GRE=\"172.16.16.100\"\n\nreadonly IPv4_SRC=$IPv4_1\nreadonly IPv4_DST=$IPv4_4\n\nreadonly IPv6_1=\"fb01::1\"\nreadonly IPv6_2=\"fb02::1\"\nreadonly IPv6_3=\"fb03::1\"\nreadonly IPv6_4=\"fb04::1\"\nreadonly IPv6_5=\"fb05::1\"\nreadonly IPv6_6=\"fb06::1\"\nreadonly IPv6_7=\"fb07::1\"\nreadonly IPv6_8=\"fb08::1\"\nreadonly IPv6_GRE=\"fb10::1\"\n\nreadonly IPv6_SRC=$IPv6_1\nreadonly IPv6_DST=$IPv6_4\n\nTEST_STATUS=0\nTESTS_SUCCEEDED=0\nTESTS_FAILED=0\n\nTMPFILE=\"\"\n\nprocess_test_results()\n{\n\tif [[ \"${TEST_STATUS}\" -eq 0 ]] ; then\n\t\techo \"PASS\"\n\t\tTESTS_SUCCEEDED=$((TESTS_SUCCEEDED+1))\n\telse\n\t\techo \"FAIL\"\n\t\tTESTS_FAILED=$((TESTS_FAILED+1))\n\tfi\n}\n\nprint_test_summary_and_exit()\n{\n\techo \"passed tests: ${TESTS_SUCCEEDED}\"\n\techo \"failed tests: ${TESTS_FAILED}\"\n\tif [ \"${TESTS_FAILED}\" -eq \"0\" ] ; then\n\t\texit 0\n\telse\n\t\texit 1\n\tfi\n}\n\nsetup()\n{\n\tset -e  # exit on error\n\tTEST_STATUS=0\n\n\t# create devices and namespaces\n\tip netns add \"${NS1}\"\n\tip netns add \"${NS2}\"\n\tip netns add \"${NS3}\"\n\n\t# rp_filter gets confused by what these tests are doing, so disable it\n\tip netns exec ${NS1} sysctl -wq net.ipv4.conf.all.rp_filter=0\n\tip netns exec ${NS2} sysctl -wq net.ipv4.conf.all.rp_filter=0\n\tip netns exec ${NS3} sysctl -wq net.ipv4.conf.all.rp_filter=0\n\tip netns exec ${NS1} sysctl -wq net.ipv4.conf.default.rp_filter=0\n\tip netns exec ${NS2} sysctl -wq net.ipv4.conf.default.rp_filter=0\n\tip netns exec ${NS3} sysctl -wq net.ipv4.conf.default.rp_filter=0\n\n\t# disable IPv6 DAD because it sometimes takes too long and fails tests\n\tip netns exec ${NS1} sysctl -wq net.ipv6.conf.all.accept_dad=0\n\tip netns exec ${NS2} sysctl -wq net.ipv6.conf.all.accept_dad=0\n\tip netns exec ${NS3} sysctl -wq net.ipv6.conf.all.accept_dad=0\n\tip netns exec ${NS1} sysctl -wq net.ipv6.conf.default.accept_dad=0\n\tip netns exec ${NS2} sysctl -wq net.ipv6.conf.default.accept_dad=0\n\tip netns exec ${NS3} sysctl -wq net.ipv6.conf.default.accept_dad=0\n\n\tip link add veth1 type veth peer name veth2\n\tip link add veth3 type veth peer name veth4\n\tip link add veth5 type veth peer name veth6\n\tip link add veth7 type veth peer name veth8\n\n\tip netns exec ${NS2} sysctl -wq net.ipv4.ip_forward=1\n\tip netns exec ${NS2} sysctl -wq net.ipv6.conf.all.forwarding=1\n\n\tip link set veth1 netns ${NS1}\n\tip link set veth2 netns ${NS2}\n\tip link set veth3 netns ${NS2}\n\tip link set veth4 netns ${NS3}\n\tip link set veth5 netns ${NS1}\n\tip link set veth6 netns ${NS2}\n\tip link set veth7 netns ${NS2}\n\tip link set veth8 netns ${NS3}\n\n\tif [ ! -z \"${VRF}\" ] ; then\n\t\tip -netns ${NS1} link add red type vrf table 1001\n\t\tip -netns ${NS1} link set red up\n\t\tip -netns ${NS1} route add table 1001 unreachable default metric 8192\n\t\tip -netns ${NS1} -6 route add table 1001 unreachable default metric 8192\n\t\tip -netns ${NS1} link set veth1 vrf red\n\t\tip -netns ${NS1} link set veth5 vrf red\n\n\t\tip -netns ${NS2} link add red type vrf table 1001\n\t\tip -netns ${NS2} link set red up\n\t\tip -netns ${NS2} route add table 1001 unreachable default metric 8192\n\t\tip -netns ${NS2} -6 route add table 1001 unreachable default metric 8192\n\t\tip -netns ${NS2} link set veth2 vrf red\n\t\tip -netns ${NS2} link set veth3 vrf red\n\t\tip -netns ${NS2} link set veth6 vrf red\n\t\tip -netns ${NS2} link set veth7 vrf red\n\tfi\n\n\t# configure addesses: the top route (1-2-3-4)\n\tip -netns ${NS1}    addr add ${IPv4_1}/24  dev veth1\n\tip -netns ${NS2}    addr add ${IPv4_2}/24  dev veth2\n\tip -netns ${NS2}    addr add ${IPv4_3}/24  dev veth3\n\tip -netns ${NS3}    addr add ${IPv4_4}/24  dev veth4\n\tip -netns ${NS1} -6 addr add ${IPv6_1}/128 nodad dev veth1\n\tip -netns ${NS2} -6 addr add ${IPv6_2}/128 nodad dev veth2\n\tip -netns ${NS2} -6 addr add ${IPv6_3}/128 nodad dev veth3\n\tip -netns ${NS3} -6 addr add ${IPv6_4}/128 nodad dev veth4\n\n\t# configure addresses: the bottom route (5-6-7-8)\n\tip -netns ${NS1}    addr add ${IPv4_5}/24  dev veth5\n\tip -netns ${NS2}    addr add ${IPv4_6}/24  dev veth6\n\tip -netns ${NS2}    addr add ${IPv4_7}/24  dev veth7\n\tip -netns ${NS3}    addr add ${IPv4_8}/24  dev veth8\n\tip -netns ${NS1} -6 addr add ${IPv6_5}/128 nodad dev veth5\n\tip -netns ${NS2} -6 addr add ${IPv6_6}/128 nodad dev veth6\n\tip -netns ${NS2} -6 addr add ${IPv6_7}/128 nodad dev veth7\n\tip -netns ${NS3} -6 addr add ${IPv6_8}/128 nodad dev veth8\n\n\tip -netns ${NS1} link set dev veth1 up\n\tip -netns ${NS2} link set dev veth2 up\n\tip -netns ${NS2} link set dev veth3 up\n\tip -netns ${NS3} link set dev veth4 up\n\tip -netns ${NS1} link set dev veth5 up\n\tip -netns ${NS2} link set dev veth6 up\n\tip -netns ${NS2} link set dev veth7 up\n\tip -netns ${NS3} link set dev veth8 up\n\n\t# configure routes: IP*_SRC -> veth1/IP*_2 (= top route) default;\n\t# the bottom route to specific bottom addresses\n\n\t# NS1\n\t# top route\n\tip -netns ${NS1}    route add ${IPv4_2}/32  dev veth1 ${VRF}\n\tip -netns ${NS1}    route add default dev veth1 via ${IPv4_2} ${VRF}  # go top by default\n\tip -netns ${NS1} -6 route add ${IPv6_2}/128 dev veth1 ${VRF}\n\tip -netns ${NS1} -6 route add default dev veth1 via ${IPv6_2} ${VRF}  # go top by default\n\t# bottom route\n\tip -netns ${NS1}    route add ${IPv4_6}/32  dev veth5 ${VRF}\n\tip -netns ${NS1}    route add ${IPv4_7}/32  dev veth5 via ${IPv4_6} ${VRF}\n\tip -netns ${NS1}    route add ${IPv4_8}/32  dev veth5 via ${IPv4_6} ${VRF}\n\tip -netns ${NS1} -6 route add ${IPv6_6}/128 dev veth5 ${VRF}\n\tip -netns ${NS1} -6 route add ${IPv6_7}/128 dev veth5 via ${IPv6_6} ${VRF}\n\tip -netns ${NS1} -6 route add ${IPv6_8}/128 dev veth5 via ${IPv6_6} ${VRF}\n\n\t# NS2\n\t# top route\n\tip -netns ${NS2}    route add ${IPv4_1}/32  dev veth2 ${VRF}\n\tip -netns ${NS2}    route add ${IPv4_4}/32  dev veth3 ${VRF}\n\tip -netns ${NS2} -6 route add ${IPv6_1}/128 dev veth2 ${VRF}\n\tip -netns ${NS2} -6 route add ${IPv6_4}/128 dev veth3 ${VRF}\n\t# bottom route\n\tip -netns ${NS2}    route add ${IPv4_5}/32  dev veth6 ${VRF}\n\tip -netns ${NS2}    route add ${IPv4_8}/32  dev veth7 ${VRF}\n\tip -netns ${NS2} -6 route add ${IPv6_5}/128 dev veth6 ${VRF}\n\tip -netns ${NS2} -6 route add ${IPv6_8}/128 dev veth7 ${VRF}\n\n\t# NS3\n\t# top route\n\tip -netns ${NS3}    route add ${IPv4_3}/32  dev veth4\n\tip -netns ${NS3}    route add ${IPv4_1}/32  dev veth4 via ${IPv4_3}\n\tip -netns ${NS3}    route add ${IPv4_2}/32  dev veth4 via ${IPv4_3}\n\tip -netns ${NS3} -6 route add ${IPv6_3}/128 dev veth4\n\tip -netns ${NS3} -6 route add ${IPv6_1}/128 dev veth4 via ${IPv6_3}\n\tip -netns ${NS3} -6 route add ${IPv6_2}/128 dev veth4 via ${IPv6_3}\n\t# bottom route\n\tip -netns ${NS3}    route add ${IPv4_7}/32  dev veth8\n\tip -netns ${NS3}    route add ${IPv4_5}/32  dev veth8 via ${IPv4_7}\n\tip -netns ${NS3}    route add ${IPv4_6}/32  dev veth8 via ${IPv4_7}\n\tip -netns ${NS3} -6 route add ${IPv6_7}/128 dev veth8\n\tip -netns ${NS3} -6 route add ${IPv6_5}/128 dev veth8 via ${IPv6_7}\n\tip -netns ${NS3} -6 route add ${IPv6_6}/128 dev veth8 via ${IPv6_7}\n\n\t# configure IPv4 GRE device in NS3, and a route to it via the \"bottom\" route\n\tip -netns ${NS3} tunnel add gre_dev mode gre remote ${IPv4_1} local ${IPv4_GRE} ttl 255\n\tip -netns ${NS3} link set gre_dev up\n\tip -netns ${NS3} addr add ${IPv4_GRE} dev gre_dev\n\tip -netns ${NS1} route add ${IPv4_GRE}/32 dev veth5 via ${IPv4_6} ${VRF}\n\tip -netns ${NS2} route add ${IPv4_GRE}/32 dev veth7 via ${IPv4_8} ${VRF}\n\n\n\t# configure IPv6 GRE device in NS3, and a route to it via the \"bottom\" route\n\tip -netns ${NS3} -6 tunnel add name gre6_dev mode ip6gre remote ${IPv6_1} local ${IPv6_GRE} ttl 255\n\tip -netns ${NS3} link set gre6_dev up\n\tip -netns ${NS3} -6 addr add ${IPv6_GRE} nodad dev gre6_dev\n\tip -netns ${NS1} -6 route add ${IPv6_GRE}/128 dev veth5 via ${IPv6_6} ${VRF}\n\tip -netns ${NS2} -6 route add ${IPv6_GRE}/128 dev veth7 via ${IPv6_8} ${VRF}\n\n\tTMPFILE=$(mktemp /tmp/test_lwt_ip_encap.XXXXXX)\n\n\tsleep 1  # reduce flakiness\n\tset +e\n}\n\ncleanup()\n{\n\tif [ -f ${TMPFILE} ] ; then\n\t\trm ${TMPFILE}\n\tfi\n\n\tip netns del ${NS1} 2> /dev/null\n\tip netns del ${NS2} 2> /dev/null\n\tip netns del ${NS3} 2> /dev/null\n}\n\ntrap cleanup EXIT\n\nremove_routes_to_gredev()\n{\n\tip -netns ${NS1} route del ${IPv4_GRE} dev veth5 ${VRF}\n\tip -netns ${NS2} route del ${IPv4_GRE} dev veth7 ${VRF}\n\tip -netns ${NS1} -6 route del ${IPv6_GRE}/128 dev veth5 ${VRF}\n\tip -netns ${NS2} -6 route del ${IPv6_GRE}/128 dev veth7 ${VRF}\n}\n\nadd_unreachable_routes_to_gredev()\n{\n\tip -netns ${NS1} route add unreachable ${IPv4_GRE}/32 ${VRF}\n\tip -netns ${NS2} route add unreachable ${IPv4_GRE}/32 ${VRF}\n\tip -netns ${NS1} -6 route add unreachable ${IPv6_GRE}/128 ${VRF}\n\tip -netns ${NS2} -6 route add unreachable ${IPv6_GRE}/128 ${VRF}\n}\n\ntest_ping()\n{\n\tlocal readonly PROTO=$1\n\tlocal readonly EXPECTED=$2\n\tlocal RET=0\n\n\tif [ \"${PROTO}\" == \"IPv4\" ] ; then\n\t\tip netns exec ${NS1} ping  -c 1 -W 1 -I veth1 ${IPv4_DST} 2>&1 > /dev/null\n\t\tRET=$?\n\telif [ \"${PROTO}\" == \"IPv6\" ] ; then\n\t\tip netns exec ${NS1} ping6 -c 1 -W 1 -I veth1 ${IPv6_DST} 2>&1 > /dev/null\n\t\tRET=$?\n\telse\n\t\techo \"    test_ping: unknown PROTO: ${PROTO}\"\n\t\tTEST_STATUS=1\n\tfi\n\n\tif [ \"0\" != \"${RET}\" ]; then\n\t\tRET=1\n\tfi\n\n\tif [ \"${EXPECTED}\" != \"${RET}\" ] ; then\n\t\techo \"    test_ping failed: expected: ${EXPECTED}; got ${RET}\"\n\t\tTEST_STATUS=1\n\tfi\n}\n\ntest_gso()\n{\n\tlocal readonly PROTO=$1\n\tlocal readonly PKT_SZ=5000\n\tlocal IP_DST=\"\"\n\t: > ${TMPFILE}  # trim the capture file\n\n\t# check that nc is present\n\tcommand -v nc >/dev/null 2>&1 || \\\n\t\t{ echo >&2 \"nc is not available: skipping TSO tests\"; return; }\n\n\t# listen on port 9000, capture TCP into $TMPFILE\n\tif [ \"${PROTO}\" == \"IPv4\" ] ; then\n\t\tIP_DST=${IPv4_DST}\n\t\tip netns exec ${NS3} bash -c \\\n\t\t\t\"nc -4 -l -p 9000 > ${TMPFILE} &\"\n\telif [ \"${PROTO}\" == \"IPv6\" ] ; then\n\t\tIP_DST=${IPv6_DST}\n\t\tip netns exec ${NS3} bash -c \\\n\t\t\t\"nc -6 -l -p 9000 > ${TMPFILE} &\"\n\t\tRET=$?\n\telse\n\t\techo \"    test_gso: unknown PROTO: ${PROTO}\"\n\t\tTEST_STATUS=1\n\tfi\n\tsleep 1  # let nc start listening\n\n\t# send a packet larger than MTU\n\tip netns exec ${NS1} bash -c \\\n\t\t\"dd if=/dev/zero bs=$PKT_SZ count=1 > /dev/tcp/${IP_DST}/9000 2>/dev/null\"\n\tsleep 2 # let the packet get delivered\n\n\t# verify we received all expected bytes\n\tSZ=$(stat -c %s ${TMPFILE})\n\tif [ \"$SZ\" != \"$PKT_SZ\" ] ; then\n\t\techo \"    test_gso failed: ${PROTO}\"\n\t\tTEST_STATUS=1\n\tfi\n}\n\ntest_egress()\n{\n\tlocal readonly ENCAP=$1\n\techo \"starting egress ${ENCAP} encap test ${VRF}\"\n\tsetup\n\n\t# by default, pings work\n\ttest_ping IPv4 0\n\ttest_ping IPv6 0\n\n\t# remove NS2->DST routes, ping fails\n\tip -netns ${NS2}    route del ${IPv4_DST}/32  dev veth3 ${VRF}\n\tip -netns ${NS2} -6 route del ${IPv6_DST}/128 dev veth3 ${VRF}\n\ttest_ping IPv4 1\n\ttest_ping IPv6 1\n\n\t# install replacement routes (LWT/eBPF), pings succeed\n\tif [ \"${ENCAP}\" == \"IPv4\" ] ; then\n\t\tip -netns ${NS1} route add ${IPv4_DST} encap bpf xmit obj \\\n\t\t\t${BPF_FILE} sec encap_gre dev veth1 ${VRF}\n\t\tip -netns ${NS1} -6 route add ${IPv6_DST} encap bpf xmit obj \\\n\t\t\t${BPF_FILE} sec encap_gre dev veth1 ${VRF}\n\telif [ \"${ENCAP}\" == \"IPv6\" ] ; then\n\t\tip -netns ${NS1} route add ${IPv4_DST} encap bpf xmit obj \\\n\t\t\t${BPF_FILE} sec encap_gre6 dev veth1 ${VRF}\n\t\tip -netns ${NS1} -6 route add ${IPv6_DST} encap bpf xmit obj \\\n\t\t\t${BPF_FILE} sec encap_gre6 dev veth1 ${VRF}\n\telse\n\t\techo \"    unknown encap ${ENCAP}\"\n\t\tTEST_STATUS=1\n\tfi\n\ttest_ping IPv4 0\n\ttest_ping IPv6 0\n\n\t# skip GSO tests with VRF: VRF routing needs properly assigned\n\t# source IP/device, which is easy to do with ping and hard with dd/nc.\n\tif [ -z \"${VRF}\" ] ; then\n\t\ttest_gso IPv4\n\t\ttest_gso IPv6\n\tfi\n\n\t# a negative test: remove routes to GRE devices: ping fails\n\tremove_routes_to_gredev\n\ttest_ping IPv4 1\n\ttest_ping IPv6 1\n\n\t# another negative test\n\tadd_unreachable_routes_to_gredev\n\ttest_ping IPv4 1\n\ttest_ping IPv6 1\n\n\tcleanup\n\tprocess_test_results\n}\n\ntest_ingress()\n{\n\tlocal readonly ENCAP=$1\n\techo \"starting ingress ${ENCAP} encap test ${VRF}\"\n\tsetup\n\n\t# need to wait a bit for IPv6 to autoconf, otherwise\n\t# ping6 sometimes fails with \"unable to bind to address\"\n\n\t# by default, pings work\n\ttest_ping IPv4 0\n\ttest_ping IPv6 0\n\n\t# remove NS2->DST routes, pings fail\n\tip -netns ${NS2}    route del ${IPv4_DST}/32  dev veth3 ${VRF}\n\tip -netns ${NS2} -6 route del ${IPv6_DST}/128 dev veth3 ${VRF}\n\ttest_ping IPv4 1\n\ttest_ping IPv6 1\n\n\t# install replacement routes (LWT/eBPF), pings succeed\n\tif [ \"${ENCAP}\" == \"IPv4\" ] ; then\n\t\tip -netns ${NS2} route add ${IPv4_DST} encap bpf in obj \\\n\t\t\t${BPF_FILE} sec encap_gre dev veth2 ${VRF}\n\t\tip -netns ${NS2} -6 route add ${IPv6_DST} encap bpf in obj \\\n\t\t\t${BPF_FILE} sec encap_gre dev veth2 ${VRF}\n\telif [ \"${ENCAP}\" == \"IPv6\" ] ; then\n\t\tip -netns ${NS2} route add ${IPv4_DST} encap bpf in obj \\\n\t\t\t${BPF_FILE} sec encap_gre6 dev veth2 ${VRF}\n\t\tip -netns ${NS2} -6 route add ${IPv6_DST} encap bpf in obj \\\n\t\t\t${BPF_FILE} sec encap_gre6 dev veth2 ${VRF}\n\telse\n\t\techo \"FAIL: unknown encap ${ENCAP}\"\n\t\tTEST_STATUS=1\n\tfi\n\ttest_ping IPv4 0\n\ttest_ping IPv6 0\n\n\t# a negative test: remove routes to GRE devices: ping fails\n\tremove_routes_to_gredev\n\ttest_ping IPv4 1\n\ttest_ping IPv6 1\n\n\t# another negative test\n\tadd_unreachable_routes_to_gredev\n\ttest_ping IPv4 1\n\ttest_ping IPv6 1\n\n\tcleanup\n\tprocess_test_results\n}\n\nVRF=\"\"\ntest_egress IPv4\ntest_egress IPv6\ntest_ingress IPv4\ntest_ingress IPv6\n\nVRF=\"vrf red\"\ntest_egress IPv4\ntest_egress IPv6\ntest_ingress IPv4\ntest_ingress IPv6\n\nprint_test_summary_and_exit\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}