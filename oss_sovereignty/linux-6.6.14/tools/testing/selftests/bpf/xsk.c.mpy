{
  "module_name": "xsk.c",
  "hash_id": "b86bbf5afb5e510faa7d6ef30f8469975dc2f8913155d8eacd50098235721519",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/xsk.c",
  "human_readable_source": "\n\n \n\n#include <errno.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <arpa/inet.h>\n#include <asm/barrier.h>\n#include <linux/compiler.h>\n#include <linux/ethtool.h>\n#include <linux/filter.h>\n#include <linux/if_ether.h>\n#include <linux/if_link.h>\n#include <linux/if_packet.h>\n#include <linux/if_xdp.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/netlink.h>\n#include <linux/rtnetlink.h>\n#include <linux/sockios.h>\n#include <net/if.h>\n#include <sys/ioctl.h>\n#include <sys/mman.h>\n#include <sys/socket.h>\n#include <sys/types.h>\n\n#include <bpf/bpf.h>\n#include <bpf/libbpf.h>\n#include \"xsk.h\"\n#include \"bpf_util.h\"\n\n#ifndef SOL_XDP\n #define SOL_XDP 283\n#endif\n\n#ifndef AF_XDP\n #define AF_XDP 44\n#endif\n\n#ifndef PF_XDP\n #define PF_XDP AF_XDP\n#endif\n\n#define pr_warn(fmt, ...) fprintf(stderr, fmt, ##__VA_ARGS__)\n\n#define XSKMAP_SIZE 1\n\nstruct xsk_umem {\n\tstruct xsk_ring_prod *fill_save;\n\tstruct xsk_ring_cons *comp_save;\n\tchar *umem_area;\n\tstruct xsk_umem_config config;\n\tint fd;\n\tint refcount;\n\tstruct list_head ctx_list;\n\tbool rx_ring_setup_done;\n\tbool tx_ring_setup_done;\n};\n\nstruct xsk_ctx {\n\tstruct xsk_ring_prod *fill;\n\tstruct xsk_ring_cons *comp;\n\t__u32 queue_id;\n\tstruct xsk_umem *umem;\n\tint refcount;\n\tint ifindex;\n\tstruct list_head list;\n};\n\nstruct xsk_socket {\n\tstruct xsk_ring_cons *rx;\n\tstruct xsk_ring_prod *tx;\n\tstruct xsk_ctx *ctx;\n\tstruct xsk_socket_config config;\n\tint fd;\n};\n\nstruct nl_mtu_req {\n\tstruct nlmsghdr nh;\n\tstruct ifinfomsg msg;\n\tchar             buf[512];\n};\n\nint xsk_umem__fd(const struct xsk_umem *umem)\n{\n\treturn umem ? umem->fd : -EINVAL;\n}\n\nint xsk_socket__fd(const struct xsk_socket *xsk)\n{\n\treturn xsk ? xsk->fd : -EINVAL;\n}\n\nstatic bool xsk_page_aligned(void *buffer)\n{\n\tunsigned long addr = (unsigned long)buffer;\n\n\treturn !(addr & (getpagesize() - 1));\n}\n\nstatic void xsk_set_umem_config(struct xsk_umem_config *cfg,\n\t\t\t\tconst struct xsk_umem_config *usr_cfg)\n{\n\tif (!usr_cfg) {\n\t\tcfg->fill_size = XSK_RING_PROD__DEFAULT_NUM_DESCS;\n\t\tcfg->comp_size = XSK_RING_CONS__DEFAULT_NUM_DESCS;\n\t\tcfg->frame_size = XSK_UMEM__DEFAULT_FRAME_SIZE;\n\t\tcfg->frame_headroom = XSK_UMEM__DEFAULT_FRAME_HEADROOM;\n\t\tcfg->flags = XSK_UMEM__DEFAULT_FLAGS;\n\t\treturn;\n\t}\n\n\tcfg->fill_size = usr_cfg->fill_size;\n\tcfg->comp_size = usr_cfg->comp_size;\n\tcfg->frame_size = usr_cfg->frame_size;\n\tcfg->frame_headroom = usr_cfg->frame_headroom;\n\tcfg->flags = usr_cfg->flags;\n}\n\nstatic int xsk_set_xdp_socket_config(struct xsk_socket_config *cfg,\n\t\t\t\t     const struct xsk_socket_config *usr_cfg)\n{\n\tif (!usr_cfg) {\n\t\tcfg->rx_size = XSK_RING_CONS__DEFAULT_NUM_DESCS;\n\t\tcfg->tx_size = XSK_RING_PROD__DEFAULT_NUM_DESCS;\n\t\tcfg->bind_flags = 0;\n\t\treturn 0;\n\t}\n\n\tcfg->rx_size = usr_cfg->rx_size;\n\tcfg->tx_size = usr_cfg->tx_size;\n\tcfg->bind_flags = usr_cfg->bind_flags;\n\n\treturn 0;\n}\n\nstatic int xsk_get_mmap_offsets(int fd, struct xdp_mmap_offsets *off)\n{\n\tsocklen_t optlen;\n\tint err;\n\n\toptlen = sizeof(*off);\n\terr = getsockopt(fd, SOL_XDP, XDP_MMAP_OFFSETS, off, &optlen);\n\tif (err)\n\t\treturn err;\n\n\tif (optlen == sizeof(*off))\n\t\treturn 0;\n\n\treturn -EINVAL;\n}\n\nstatic int xsk_create_umem_rings(struct xsk_umem *umem, int fd,\n\t\t\t\t struct xsk_ring_prod *fill,\n\t\t\t\t struct xsk_ring_cons *comp)\n{\n\tstruct xdp_mmap_offsets off;\n\tvoid *map;\n\tint err;\n\n\terr = setsockopt(fd, SOL_XDP, XDP_UMEM_FILL_RING,\n\t\t\t &umem->config.fill_size,\n\t\t\t sizeof(umem->config.fill_size));\n\tif (err)\n\t\treturn -errno;\n\n\terr = setsockopt(fd, SOL_XDP, XDP_UMEM_COMPLETION_RING,\n\t\t\t &umem->config.comp_size,\n\t\t\t sizeof(umem->config.comp_size));\n\tif (err)\n\t\treturn -errno;\n\n\terr = xsk_get_mmap_offsets(fd, &off);\n\tif (err)\n\t\treturn -errno;\n\n\tmap = mmap(NULL, off.fr.desc + umem->config.fill_size * sizeof(__u64),\n\t\t   PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd,\n\t\t   XDP_UMEM_PGOFF_FILL_RING);\n\tif (map == MAP_FAILED)\n\t\treturn -errno;\n\n\tfill->mask = umem->config.fill_size - 1;\n\tfill->size = umem->config.fill_size;\n\tfill->producer = map + off.fr.producer;\n\tfill->consumer = map + off.fr.consumer;\n\tfill->flags = map + off.fr.flags;\n\tfill->ring = map + off.fr.desc;\n\tfill->cached_cons = umem->config.fill_size;\n\n\tmap = mmap(NULL, off.cr.desc + umem->config.comp_size * sizeof(__u64),\n\t\t   PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd,\n\t\t   XDP_UMEM_PGOFF_COMPLETION_RING);\n\tif (map == MAP_FAILED) {\n\t\terr = -errno;\n\t\tgoto out_mmap;\n\t}\n\n\tcomp->mask = umem->config.comp_size - 1;\n\tcomp->size = umem->config.comp_size;\n\tcomp->producer = map + off.cr.producer;\n\tcomp->consumer = map + off.cr.consumer;\n\tcomp->flags = map + off.cr.flags;\n\tcomp->ring = map + off.cr.desc;\n\n\treturn 0;\n\nout_mmap:\n\tmunmap(map, off.fr.desc + umem->config.fill_size * sizeof(__u64));\n\treturn err;\n}\n\nint xsk_umem__create(struct xsk_umem **umem_ptr, void *umem_area,\n\t\t     __u64 size, struct xsk_ring_prod *fill,\n\t\t     struct xsk_ring_cons *comp,\n\t\t     const struct xsk_umem_config *usr_config)\n{\n\tstruct xdp_umem_reg mr;\n\tstruct xsk_umem *umem;\n\tint err;\n\n\tif (!umem_area || !umem_ptr || !fill || !comp)\n\t\treturn -EFAULT;\n\tif (!size && !xsk_page_aligned(umem_area))\n\t\treturn -EINVAL;\n\n\tumem = calloc(1, sizeof(*umem));\n\tif (!umem)\n\t\treturn -ENOMEM;\n\n\tumem->fd = socket(AF_XDP, SOCK_RAW | SOCK_CLOEXEC, 0);\n\tif (umem->fd < 0) {\n\t\terr = -errno;\n\t\tgoto out_umem_alloc;\n\t}\n\n\tumem->umem_area = umem_area;\n\tINIT_LIST_HEAD(&umem->ctx_list);\n\txsk_set_umem_config(&umem->config, usr_config);\n\n\tmemset(&mr, 0, sizeof(mr));\n\tmr.addr = (uintptr_t)umem_area;\n\tmr.len = size;\n\tmr.chunk_size = umem->config.frame_size;\n\tmr.headroom = umem->config.frame_headroom;\n\tmr.flags = umem->config.flags;\n\n\terr = setsockopt(umem->fd, SOL_XDP, XDP_UMEM_REG, &mr, sizeof(mr));\n\tif (err) {\n\t\terr = -errno;\n\t\tgoto out_socket;\n\t}\n\n\terr = xsk_create_umem_rings(umem, umem->fd, fill, comp);\n\tif (err)\n\t\tgoto out_socket;\n\n\tumem->fill_save = fill;\n\tumem->comp_save = comp;\n\t*umem_ptr = umem;\n\treturn 0;\n\nout_socket:\n\tclose(umem->fd);\nout_umem_alloc:\n\tfree(umem);\n\treturn err;\n}\n\nbool xsk_is_in_mode(u32 ifindex, int mode)\n{\n\tLIBBPF_OPTS(bpf_xdp_query_opts, opts);\n\tint ret;\n\n\tret = bpf_xdp_query(ifindex, mode, &opts);\n\tif (ret) {\n\t\tprintf(\"XDP mode query returned error %s\\n\", strerror(errno));\n\t\treturn false;\n\t}\n\n\tif (mode == XDP_FLAGS_DRV_MODE)\n\t\treturn opts.attach_mode == XDP_ATTACHED_DRV;\n\telse if (mode == XDP_FLAGS_SKB_MODE)\n\t\treturn opts.attach_mode == XDP_ATTACHED_SKB;\n\n\treturn false;\n}\n\n \nstatic int netlink_recvmsg(int sock, struct msghdr *mhdr, int flags)\n{\n\tint len;\n\n\tdo {\n\t\tlen = recvmsg(sock, mhdr, flags);\n\t} while (len < 0 && (errno == EINTR || errno == EAGAIN));\n\n\tif (len < 0)\n\t\treturn -errno;\n\treturn len;\n}\n\n \nstatic int alloc_iov(struct iovec *iov, int len)\n{\n\tvoid *nbuf;\n\n\tnbuf = realloc(iov->iov_base, len);\n\tif (!nbuf)\n\t\treturn -ENOMEM;\n\n\tiov->iov_base = nbuf;\n\tiov->iov_len = len;\n\treturn 0;\n}\n\n \nstatic int netlink_recv(int sock)\n{\n\tstruct iovec iov = {};\n\tstruct msghdr mhdr = {\n\t\t.msg_iov = &iov,\n\t\t.msg_iovlen = 1,\n\t};\n\tbool multipart = true;\n\tstruct nlmsgerr *err;\n\tstruct nlmsghdr *nh;\n\tint len, ret;\n\n\tret = alloc_iov(&iov, 4096);\n\tif (ret)\n\t\tgoto done;\n\n\twhile (multipart) {\n\t\tmultipart = false;\n\t\tlen = netlink_recvmsg(sock, &mhdr, MSG_PEEK | MSG_TRUNC);\n\t\tif (len < 0) {\n\t\t\tret = len;\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (len > iov.iov_len) {\n\t\t\tret = alloc_iov(&iov, len);\n\t\t\tif (ret)\n\t\t\t\tgoto done;\n\t\t}\n\n\t\tlen = netlink_recvmsg(sock, &mhdr, 0);\n\t\tif (len < 0) {\n\t\t\tret = len;\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (len == 0)\n\t\t\tbreak;\n\n\t\tfor (nh = (struct nlmsghdr *)iov.iov_base; NLMSG_OK(nh, len);\n\t\t     nh = NLMSG_NEXT(nh, len)) {\n\t\t\tif (nh->nlmsg_flags & NLM_F_MULTI)\n\t\t\t\tmultipart = true;\n\t\t\tswitch (nh->nlmsg_type) {\n\t\t\tcase NLMSG_ERROR:\n\t\t\t\terr = (struct nlmsgerr *)NLMSG_DATA(nh);\n\t\t\t\tif (!err->error)\n\t\t\t\t\tcontinue;\n\t\t\t\tret = err->error;\n\t\t\t\tgoto done;\n\t\t\tcase NLMSG_DONE:\n\t\t\t\tret = 0;\n\t\t\t\tgoto done;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tret = 0;\ndone:\n\tfree(iov.iov_base);\n\treturn ret;\n}\n\nint xsk_set_mtu(int ifindex, int mtu)\n{\n\tstruct nl_mtu_req req;\n\tstruct rtattr *rta;\n\tint fd, ret;\n\n\tfd = socket(AF_NETLINK, SOCK_DGRAM, NETLINK_ROUTE);\n\tif (fd < 0)\n\t\treturn fd;\n\n\tmemset(&req, 0, sizeof(req));\n\treq.nh.nlmsg_len = NLMSG_LENGTH(sizeof(struct ifinfomsg));\n\treq.nh.nlmsg_flags = NLM_F_REQUEST | NLM_F_ACK;\n\treq.nh.nlmsg_type = RTM_NEWLINK;\n\treq.msg.ifi_family = AF_UNSPEC;\n\treq.msg.ifi_index = ifindex;\n\trta = (struct rtattr *)(((char *)&req) + NLMSG_ALIGN(req.nh.nlmsg_len));\n\trta->rta_type = IFLA_MTU;\n\trta->rta_len = RTA_LENGTH(sizeof(unsigned int));\n\treq.nh.nlmsg_len = NLMSG_ALIGN(req.nh.nlmsg_len) + RTA_LENGTH(sizeof(mtu));\n\tmemcpy(RTA_DATA(rta), &mtu, sizeof(mtu));\n\n\tret = send(fd, &req, req.nh.nlmsg_len, 0);\n\tif (ret < 0) {\n\t\tclose(fd);\n\t\treturn errno;\n\t}\n\n\tret = netlink_recv(fd);\n\tclose(fd);\n\treturn ret;\n}\n\nint xsk_attach_xdp_program(struct bpf_program *prog, int ifindex, u32 xdp_flags)\n{\n\tint prog_fd;\n\n\tprog_fd = bpf_program__fd(prog);\n\treturn bpf_xdp_attach(ifindex, prog_fd, xdp_flags, NULL);\n}\n\nvoid xsk_detach_xdp_program(int ifindex, u32 xdp_flags)\n{\n\tbpf_xdp_detach(ifindex, xdp_flags, NULL);\n}\n\nvoid xsk_clear_xskmap(struct bpf_map *map)\n{\n\tu32 index = 0;\n\tint map_fd;\n\n\tmap_fd = bpf_map__fd(map);\n\tbpf_map_delete_elem(map_fd, &index);\n}\n\nint xsk_update_xskmap(struct bpf_map *map, struct xsk_socket *xsk)\n{\n\tint map_fd, sock_fd;\n\tu32 index = 0;\n\n\tmap_fd = bpf_map__fd(map);\n\tsock_fd = xsk_socket__fd(xsk);\n\n\treturn bpf_map_update_elem(map_fd, &index, &sock_fd, 0);\n}\n\nstatic struct xsk_ctx *xsk_get_ctx(struct xsk_umem *umem, int ifindex,\n\t\t\t\t   __u32 queue_id)\n{\n\tstruct xsk_ctx *ctx;\n\n\tif (list_empty(&umem->ctx_list))\n\t\treturn NULL;\n\n\tlist_for_each_entry(ctx, &umem->ctx_list, list) {\n\t\tif (ctx->ifindex == ifindex && ctx->queue_id == queue_id) {\n\t\t\tctx->refcount++;\n\t\t\treturn ctx;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic void xsk_put_ctx(struct xsk_ctx *ctx, bool unmap)\n{\n\tstruct xsk_umem *umem = ctx->umem;\n\tstruct xdp_mmap_offsets off;\n\tint err;\n\n\tif (--ctx->refcount)\n\t\treturn;\n\n\tif (!unmap)\n\t\tgoto out_free;\n\n\terr = xsk_get_mmap_offsets(umem->fd, &off);\n\tif (err)\n\t\tgoto out_free;\n\n\tmunmap(ctx->fill->ring - off.fr.desc, off.fr.desc + umem->config.fill_size *\n\t       sizeof(__u64));\n\tmunmap(ctx->comp->ring - off.cr.desc, off.cr.desc + umem->config.comp_size *\n\t       sizeof(__u64));\n\nout_free:\n\tlist_del(&ctx->list);\n\tfree(ctx);\n}\n\nstatic struct xsk_ctx *xsk_create_ctx(struct xsk_socket *xsk,\n\t\t\t\t      struct xsk_umem *umem, int ifindex,\n\t\t\t\t      __u32 queue_id,\n\t\t\t\t      struct xsk_ring_prod *fill,\n\t\t\t\t      struct xsk_ring_cons *comp)\n{\n\tstruct xsk_ctx *ctx;\n\tint err;\n\n\tctx = calloc(1, sizeof(*ctx));\n\tif (!ctx)\n\t\treturn NULL;\n\n\tif (!umem->fill_save) {\n\t\terr = xsk_create_umem_rings(umem, xsk->fd, fill, comp);\n\t\tif (err) {\n\t\t\tfree(ctx);\n\t\t\treturn NULL;\n\t\t}\n\t} else if (umem->fill_save != fill || umem->comp_save != comp) {\n\t\t \n\t\tmemcpy(fill, umem->fill_save, sizeof(*fill));\n\t\tmemcpy(comp, umem->comp_save, sizeof(*comp));\n\t}\n\n\tctx->ifindex = ifindex;\n\tctx->refcount = 1;\n\tctx->umem = umem;\n\tctx->queue_id = queue_id;\n\n\tctx->fill = fill;\n\tctx->comp = comp;\n\tlist_add(&ctx->list, &umem->ctx_list);\n\treturn ctx;\n}\n\nint xsk_socket__create_shared(struct xsk_socket **xsk_ptr,\n\t\t\t      int ifindex,\n\t\t\t      __u32 queue_id, struct xsk_umem *umem,\n\t\t\t      struct xsk_ring_cons *rx,\n\t\t\t      struct xsk_ring_prod *tx,\n\t\t\t      struct xsk_ring_prod *fill,\n\t\t\t      struct xsk_ring_cons *comp,\n\t\t\t      const struct xsk_socket_config *usr_config)\n{\n\tbool unmap, rx_setup_done = false, tx_setup_done = false;\n\tvoid *rx_map = NULL, *tx_map = NULL;\n\tstruct sockaddr_xdp sxdp = {};\n\tstruct xdp_mmap_offsets off;\n\tstruct xsk_socket *xsk;\n\tstruct xsk_ctx *ctx;\n\tint err;\n\n\tif (!umem || !xsk_ptr || !(rx || tx))\n\t\treturn -EFAULT;\n\n\tunmap = umem->fill_save != fill;\n\n\txsk = calloc(1, sizeof(*xsk));\n\tif (!xsk)\n\t\treturn -ENOMEM;\n\n\terr = xsk_set_xdp_socket_config(&xsk->config, usr_config);\n\tif (err)\n\t\tgoto out_xsk_alloc;\n\n\tif (umem->refcount++ > 0) {\n\t\txsk->fd = socket(AF_XDP, SOCK_RAW | SOCK_CLOEXEC, 0);\n\t\tif (xsk->fd < 0) {\n\t\t\terr = -errno;\n\t\t\tgoto out_xsk_alloc;\n\t\t}\n\t} else {\n\t\txsk->fd = umem->fd;\n\t\trx_setup_done = umem->rx_ring_setup_done;\n\t\ttx_setup_done = umem->tx_ring_setup_done;\n\t}\n\n\tctx = xsk_get_ctx(umem, ifindex, queue_id);\n\tif (!ctx) {\n\t\tif (!fill || !comp) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto out_socket;\n\t\t}\n\n\t\tctx = xsk_create_ctx(xsk, umem, ifindex, queue_id, fill, comp);\n\t\tif (!ctx) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_socket;\n\t\t}\n\t}\n\txsk->ctx = ctx;\n\n\tif (rx && !rx_setup_done) {\n\t\terr = setsockopt(xsk->fd, SOL_XDP, XDP_RX_RING,\n\t\t\t\t &xsk->config.rx_size,\n\t\t\t\t sizeof(xsk->config.rx_size));\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tgoto out_put_ctx;\n\t\t}\n\t\tif (xsk->fd == umem->fd)\n\t\t\tumem->rx_ring_setup_done = true;\n\t}\n\tif (tx && !tx_setup_done) {\n\t\terr = setsockopt(xsk->fd, SOL_XDP, XDP_TX_RING,\n\t\t\t\t &xsk->config.tx_size,\n\t\t\t\t sizeof(xsk->config.tx_size));\n\t\tif (err) {\n\t\t\terr = -errno;\n\t\t\tgoto out_put_ctx;\n\t\t}\n\t\tif (xsk->fd == umem->fd)\n\t\t\tumem->tx_ring_setup_done = true;\n\t}\n\n\terr = xsk_get_mmap_offsets(xsk->fd, &off);\n\tif (err) {\n\t\terr = -errno;\n\t\tgoto out_put_ctx;\n\t}\n\n\tif (rx) {\n\t\trx_map = mmap(NULL, off.rx.desc +\n\t\t\t      xsk->config.rx_size * sizeof(struct xdp_desc),\n\t\t\t      PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE,\n\t\t\t      xsk->fd, XDP_PGOFF_RX_RING);\n\t\tif (rx_map == MAP_FAILED) {\n\t\t\terr = -errno;\n\t\t\tgoto out_put_ctx;\n\t\t}\n\n\t\trx->mask = xsk->config.rx_size - 1;\n\t\trx->size = xsk->config.rx_size;\n\t\trx->producer = rx_map + off.rx.producer;\n\t\trx->consumer = rx_map + off.rx.consumer;\n\t\trx->flags = rx_map + off.rx.flags;\n\t\trx->ring = rx_map + off.rx.desc;\n\t\trx->cached_prod = *rx->producer;\n\t\trx->cached_cons = *rx->consumer;\n\t}\n\txsk->rx = rx;\n\n\tif (tx) {\n\t\ttx_map = mmap(NULL, off.tx.desc +\n\t\t\t      xsk->config.tx_size * sizeof(struct xdp_desc),\n\t\t\t      PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE,\n\t\t\t      xsk->fd, XDP_PGOFF_TX_RING);\n\t\tif (tx_map == MAP_FAILED) {\n\t\t\terr = -errno;\n\t\t\tgoto out_mmap_rx;\n\t\t}\n\n\t\ttx->mask = xsk->config.tx_size - 1;\n\t\ttx->size = xsk->config.tx_size;\n\t\ttx->producer = tx_map + off.tx.producer;\n\t\ttx->consumer = tx_map + off.tx.consumer;\n\t\ttx->flags = tx_map + off.tx.flags;\n\t\ttx->ring = tx_map + off.tx.desc;\n\t\ttx->cached_prod = *tx->producer;\n\t\t \n\t\ttx->cached_cons = *tx->consumer + xsk->config.tx_size;\n\t}\n\txsk->tx = tx;\n\n\tsxdp.sxdp_family = PF_XDP;\n\tsxdp.sxdp_ifindex = ctx->ifindex;\n\tsxdp.sxdp_queue_id = ctx->queue_id;\n\tif (umem->refcount > 1) {\n\t\tsxdp.sxdp_flags |= XDP_SHARED_UMEM;\n\t\tsxdp.sxdp_shared_umem_fd = umem->fd;\n\t} else {\n\t\tsxdp.sxdp_flags = xsk->config.bind_flags;\n\t}\n\n\terr = bind(xsk->fd, (struct sockaddr *)&sxdp, sizeof(sxdp));\n\tif (err) {\n\t\terr = -errno;\n\t\tgoto out_mmap_tx;\n\t}\n\n\t*xsk_ptr = xsk;\n\tumem->fill_save = NULL;\n\tumem->comp_save = NULL;\n\treturn 0;\n\nout_mmap_tx:\n\tif (tx)\n\t\tmunmap(tx_map, off.tx.desc +\n\t\t       xsk->config.tx_size * sizeof(struct xdp_desc));\nout_mmap_rx:\n\tif (rx)\n\t\tmunmap(rx_map, off.rx.desc +\n\t\t       xsk->config.rx_size * sizeof(struct xdp_desc));\nout_put_ctx:\n\txsk_put_ctx(ctx, unmap);\nout_socket:\n\tif (--umem->refcount)\n\t\tclose(xsk->fd);\nout_xsk_alloc:\n\tfree(xsk);\n\treturn err;\n}\n\nint xsk_socket__create(struct xsk_socket **xsk_ptr, int ifindex,\n\t\t       __u32 queue_id, struct xsk_umem *umem,\n\t\t       struct xsk_ring_cons *rx, struct xsk_ring_prod *tx,\n\t\t       const struct xsk_socket_config *usr_config)\n{\n\tif (!umem)\n\t\treturn -EFAULT;\n\n\treturn xsk_socket__create_shared(xsk_ptr, ifindex, queue_id, umem,\n\t\t\t\t\t rx, tx, umem->fill_save,\n\t\t\t\t\t umem->comp_save, usr_config);\n}\n\nint xsk_umem__delete(struct xsk_umem *umem)\n{\n\tstruct xdp_mmap_offsets off;\n\tint err;\n\n\tif (!umem)\n\t\treturn 0;\n\n\tif (umem->refcount)\n\t\treturn -EBUSY;\n\n\terr = xsk_get_mmap_offsets(umem->fd, &off);\n\tif (!err && umem->fill_save && umem->comp_save) {\n\t\tmunmap(umem->fill_save->ring - off.fr.desc,\n\t\t       off.fr.desc + umem->config.fill_size * sizeof(__u64));\n\t\tmunmap(umem->comp_save->ring - off.cr.desc,\n\t\t       off.cr.desc + umem->config.comp_size * sizeof(__u64));\n\t}\n\n\tclose(umem->fd);\n\tfree(umem);\n\n\treturn 0;\n}\n\nvoid xsk_socket__delete(struct xsk_socket *xsk)\n{\n\tsize_t desc_sz = sizeof(struct xdp_desc);\n\tstruct xdp_mmap_offsets off;\n\tstruct xsk_umem *umem;\n\tstruct xsk_ctx *ctx;\n\tint err;\n\n\tif (!xsk)\n\t\treturn;\n\n\tctx = xsk->ctx;\n\tumem = ctx->umem;\n\n\txsk_put_ctx(ctx, true);\n\n\terr = xsk_get_mmap_offsets(xsk->fd, &off);\n\tif (!err) {\n\t\tif (xsk->rx) {\n\t\t\tmunmap(xsk->rx->ring - off.rx.desc,\n\t\t\t       off.rx.desc + xsk->config.rx_size * desc_sz);\n\t\t}\n\t\tif (xsk->tx) {\n\t\t\tmunmap(xsk->tx->ring - off.tx.desc,\n\t\t\t       off.tx.desc + xsk->config.tx_size * desc_sz);\n\t\t}\n\t}\n\n\tumem->refcount--;\n\t \n\tif (xsk->fd != umem->fd)\n\t\tclose(xsk->fd);\n\tfree(xsk);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}