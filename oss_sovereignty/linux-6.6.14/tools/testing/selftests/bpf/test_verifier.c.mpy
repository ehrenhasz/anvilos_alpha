{
  "module_name": "test_verifier.c",
  "hash_id": "873005095bd0ae37ebf54bd8b5dfaf0c3f77c22c30aa51f7c99a8cfed7acb94f",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/test_verifier.c",
  "human_readable_source": "\n \n\n#include <endian.h>\n#include <asm/types.h>\n#include <linux/types.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <errno.h>\n#include <string.h>\n#include <stddef.h>\n#include <stdbool.h>\n#include <sched.h>\n#include <limits.h>\n#include <assert.h>\n\n#include <linux/unistd.h>\n#include <linux/filter.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/if_ether.h>\n#include <linux/btf.h>\n\n#include <bpf/btf.h>\n#include <bpf/bpf.h>\n#include <bpf/libbpf.h>\n\n#include \"autoconf_helper.h\"\n#include \"unpriv_helpers.h\"\n#include \"cap_helpers.h\"\n#include \"bpf_rand.h\"\n#include \"bpf_util.h\"\n#include \"test_btf.h\"\n#include \"../../../include/linux/filter.h\"\n#include \"testing_helpers.h\"\n\n#ifndef ENOTSUPP\n#define ENOTSUPP 524\n#endif\n\n#define MAX_INSNS\tBPF_MAXINSNS\n#define MAX_EXPECTED_INSNS\t32\n#define MAX_UNEXPECTED_INSNS\t32\n#define MAX_TEST_INSNS\t1000000\n#define MAX_FIXUPS\t8\n#define MAX_NR_MAPS\t23\n#define MAX_TEST_RUNS\t8\n#define POINTER_VALUE\t0xcafe4all\n#define TEST_DATA_LEN\t64\n#define MAX_FUNC_INFOS\t8\n#define MAX_BTF_STRINGS\t256\n#define MAX_BTF_TYPES\t256\n\n#define INSN_OFF_MASK\t((__s16)0xFFFF)\n#define INSN_IMM_MASK\t((__s32)0xFFFFFFFF)\n#define SKIP_INSNS()\tBPF_RAW_INSN(0xde, 0xa, 0xd, 0xbeef, 0xdeadbeef)\n\n#define DEFAULT_LIBBPF_LOG_LEVEL\t4\n\n#define F_NEEDS_EFFICIENT_UNALIGNED_ACCESS\t(1 << 0)\n#define F_LOAD_WITH_STRICT_ALIGNMENT\t\t(1 << 1)\n\n \n#define ADMIN_CAPS (1ULL << CAP_NET_ADMIN |\t\\\n\t\t    1ULL << CAP_PERFMON |\t\\\n\t\t    1ULL << CAP_BPF)\n#define UNPRIV_SYSCTL \"kernel/unprivileged_bpf_disabled\"\nstatic bool unpriv_disabled = false;\nstatic int skips;\nstatic bool verbose = false;\nstatic int verif_log_level = 0;\n\nstruct kfunc_btf_id_pair {\n\tconst char *kfunc;\n\tint insn_idx;\n};\n\nstruct bpf_test {\n\tconst char *descr;\n\tstruct bpf_insn\tinsns[MAX_INSNS];\n\tstruct bpf_insn\t*fill_insns;\n\t \n\tstruct bpf_insn expected_insns[MAX_EXPECTED_INSNS];\n\t \n\tstruct bpf_insn unexpected_insns[MAX_UNEXPECTED_INSNS];\n\tint fixup_map_hash_8b[MAX_FIXUPS];\n\tint fixup_map_hash_48b[MAX_FIXUPS];\n\tint fixup_map_hash_16b[MAX_FIXUPS];\n\tint fixup_map_array_48b[MAX_FIXUPS];\n\tint fixup_map_sockmap[MAX_FIXUPS];\n\tint fixup_map_sockhash[MAX_FIXUPS];\n\tint fixup_map_xskmap[MAX_FIXUPS];\n\tint fixup_map_stacktrace[MAX_FIXUPS];\n\tint fixup_prog1[MAX_FIXUPS];\n\tint fixup_prog2[MAX_FIXUPS];\n\tint fixup_map_in_map[MAX_FIXUPS];\n\tint fixup_cgroup_storage[MAX_FIXUPS];\n\tint fixup_percpu_cgroup_storage[MAX_FIXUPS];\n\tint fixup_map_spin_lock[MAX_FIXUPS];\n\tint fixup_map_array_ro[MAX_FIXUPS];\n\tint fixup_map_array_wo[MAX_FIXUPS];\n\tint fixup_map_array_small[MAX_FIXUPS];\n\tint fixup_sk_storage_map[MAX_FIXUPS];\n\tint fixup_map_event_output[MAX_FIXUPS];\n\tint fixup_map_reuseport_array[MAX_FIXUPS];\n\tint fixup_map_ringbuf[MAX_FIXUPS];\n\tint fixup_map_timer[MAX_FIXUPS];\n\tint fixup_map_kptr[MAX_FIXUPS];\n\tstruct kfunc_btf_id_pair fixup_kfunc_btf_id[MAX_FIXUPS];\n\t \n\tconst char *errstr;\n\tconst char *errstr_unpriv;\n\tuint32_t insn_processed;\n\tint prog_len;\n\tenum {\n\t\tUNDEF,\n\t\tACCEPT,\n\t\tREJECT,\n\t\tVERBOSE_ACCEPT,\n\t} result, result_unpriv;\n\tenum bpf_prog_type prog_type;\n\tuint8_t flags;\n\tvoid (*fill_helper)(struct bpf_test *self);\n\tint runs;\n#define bpf_testdata_struct_t\t\t\t\t\t\\\n\tstruct {\t\t\t\t\t\t\\\n\t\tuint32_t retval, retval_unpriv;\t\t\t\\\n\t\tunion {\t\t\t\t\t\t\\\n\t\t\t__u8 data[TEST_DATA_LEN];\t\t\\\n\t\t\t__u64 data64[TEST_DATA_LEN / 8];\t\\\n\t\t};\t\t\t\t\t\t\\\n\t}\n\tunion {\n\t\tbpf_testdata_struct_t;\n\t\tbpf_testdata_struct_t retvals[MAX_TEST_RUNS];\n\t};\n\tenum bpf_attach_type expected_attach_type;\n\tconst char *kfunc;\n\tstruct bpf_func_info func_info[MAX_FUNC_INFOS];\n\tint func_info_cnt;\n\tchar btf_strings[MAX_BTF_STRINGS];\n\t \n\t__u32 btf_types[MAX_BTF_TYPES];\n};\n\n \n#define MAX_ENTRIES 11\n\nstruct test_val {\n\tunsigned int index;\n\tint foo[MAX_ENTRIES];\n};\n\nstruct other_val {\n\tlong long foo;\n\tlong long bar;\n};\n\nstatic void bpf_fill_ld_abs_vlan_push_pop(struct bpf_test *self)\n{\n\t \n#define PUSH_CNT 51\n\t \n\tunsigned int len = (1 << 15) - PUSH_CNT * 2 * 5 * 6;\n\tstruct bpf_insn *insn = self->fill_insns;\n\tint i = 0, j, k = 0;\n\n\tinsn[i++] = BPF_MOV64_REG(BPF_REG_6, BPF_REG_1);\nloop:\n\tfor (j = 0; j < PUSH_CNT; j++) {\n\t\tinsn[i++] = BPF_LD_ABS(BPF_B, 0);\n\t\t \n\t\tinsn[i] = BPF_JMP32_IMM(BPF_JNE, BPF_REG_0, 0x34, len - i - 3);\n\t\ti++;\n\t\tinsn[i++] = BPF_MOV64_REG(BPF_REG_1, BPF_REG_6);\n\t\tinsn[i++] = BPF_MOV64_IMM(BPF_REG_2, 1);\n\t\tinsn[i++] = BPF_MOV64_IMM(BPF_REG_3, 2);\n\t\tinsn[i++] = BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,\n\t\t\t\t\t BPF_FUNC_skb_vlan_push);\n\t\tinsn[i] = BPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, len - i - 3);\n\t\ti++;\n\t}\n\n\tfor (j = 0; j < PUSH_CNT; j++) {\n\t\tinsn[i++] = BPF_LD_ABS(BPF_B, 0);\n\t\tinsn[i] = BPF_JMP32_IMM(BPF_JNE, BPF_REG_0, 0x34, len - i - 3);\n\t\ti++;\n\t\tinsn[i++] = BPF_MOV64_REG(BPF_REG_1, BPF_REG_6);\n\t\tinsn[i++] = BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,\n\t\t\t\t\t BPF_FUNC_skb_vlan_pop);\n\t\tinsn[i] = BPF_JMP_IMM(BPF_JNE, BPF_REG_0, 0, len - i - 3);\n\t\ti++;\n\t}\n\tif (++k < 5)\n\t\tgoto loop;\n\n\tfor (; i < len - 3; i++)\n\t\tinsn[i] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_0, 0xbef);\n\tinsn[len - 3] = BPF_JMP_A(1);\n\t \n\tinsn[len - 2] = BPF_MOV32_IMM(BPF_REG_0, 0);\n\tinsn[len - 1] = BPF_EXIT_INSN();\n\tself->prog_len = len;\n}\n\nstatic void bpf_fill_jump_around_ld_abs(struct bpf_test *self)\n{\n\tstruct bpf_insn *insn = self->fill_insns;\n\t \n\tunsigned int len = (1 << 15) / 7;\n\tint i = 0;\n\n\tinsn[i++] = BPF_MOV64_REG(BPF_REG_6, BPF_REG_1);\n\tinsn[i++] = BPF_LD_ABS(BPF_B, 0);\n\tinsn[i] = BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 10, len - i - 2);\n\ti++;\n\twhile (i < len - 1)\n\t\tinsn[i++] = BPF_LD_ABS(BPF_B, 1);\n\tinsn[i] = BPF_EXIT_INSN();\n\tself->prog_len = i + 1;\n}\n\nstatic void bpf_fill_rand_ld_dw(struct bpf_test *self)\n{\n\tstruct bpf_insn *insn = self->fill_insns;\n\tuint64_t res = 0;\n\tint i = 0;\n\n\tinsn[i++] = BPF_MOV32_IMM(BPF_REG_0, 0);\n\twhile (i < self->retval) {\n\t\tuint64_t val = bpf_semi_rand_get();\n\t\tstruct bpf_insn tmp[2] = { BPF_LD_IMM64(BPF_REG_1, val) };\n\n\t\tres ^= val;\n\t\tinsn[i++] = tmp[0];\n\t\tinsn[i++] = tmp[1];\n\t\tinsn[i++] = BPF_ALU64_REG(BPF_XOR, BPF_REG_0, BPF_REG_1);\n\t}\n\tinsn[i++] = BPF_MOV64_REG(BPF_REG_1, BPF_REG_0);\n\tinsn[i++] = BPF_ALU64_IMM(BPF_RSH, BPF_REG_1, 32);\n\tinsn[i++] = BPF_ALU64_REG(BPF_XOR, BPF_REG_0, BPF_REG_1);\n\tinsn[i] = BPF_EXIT_INSN();\n\tself->prog_len = i + 1;\n\tres ^= (res >> 32);\n\tself->retval = (uint32_t)res;\n}\n\n#define MAX_JMP_SEQ 8192\n\n \nstatic void bpf_fill_scale1(struct bpf_test *self)\n{\n\tstruct bpf_insn *insn = self->fill_insns;\n\tint i = 0, k = 0;\n\n\tinsn[i++] = BPF_MOV64_REG(BPF_REG_6, BPF_REG_1);\n\t \n\twhile (k++ < MAX_JMP_SEQ) {\n\t\tinsn[i++] = BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,\n\t\t\t\t\t BPF_FUNC_get_prandom_u32);\n\t\tinsn[i++] = BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, bpf_semi_rand_get(), 2);\n\t\tinsn[i++] = BPF_MOV64_REG(BPF_REG_1, BPF_REG_10);\n\t\tinsn[i++] = BPF_STX_MEM(BPF_DW, BPF_REG_1, BPF_REG_6,\n\t\t\t\t\t-8 * (k % 64 + 1));\n\t}\n\t \n\twhile (i < MAX_TEST_INSNS - MAX_JMP_SEQ * 4)\n\t\tinsn[i++] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_0, 42);\n\tinsn[i] = BPF_EXIT_INSN();\n\tself->prog_len = i + 1;\n\tself->retval = 42;\n}\n\n \nstatic void bpf_fill_scale2(struct bpf_test *self)\n{\n\tstruct bpf_insn *insn = self->fill_insns;\n\tint i = 0, k = 0;\n\n#define FUNC_NEST 7\n\tfor (k = 0; k < FUNC_NEST; k++) {\n\t\tinsn[i++] = BPF_CALL_REL(1);\n\t\tinsn[i++] = BPF_EXIT_INSN();\n\t}\n\tinsn[i++] = BPF_MOV64_REG(BPF_REG_6, BPF_REG_1);\n\t \n\tk = 0;\n\twhile (k++ < MAX_JMP_SEQ) {\n\t\tinsn[i++] = BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,\n\t\t\t\t\t BPF_FUNC_get_prandom_u32);\n\t\tinsn[i++] = BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, bpf_semi_rand_get(), 2);\n\t\tinsn[i++] = BPF_MOV64_REG(BPF_REG_1, BPF_REG_10);\n\t\tinsn[i++] = BPF_STX_MEM(BPF_DW, BPF_REG_1, BPF_REG_6,\n\t\t\t\t\t-8 * (k % (64 - 4 * FUNC_NEST) + 1));\n\t}\n\twhile (i < MAX_TEST_INSNS - MAX_JMP_SEQ * 4)\n\t\tinsn[i++] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_0, 42);\n\tinsn[i] = BPF_EXIT_INSN();\n\tself->prog_len = i + 1;\n\tself->retval = 42;\n}\n\nstatic void bpf_fill_scale(struct bpf_test *self)\n{\n\tswitch (self->retval) {\n\tcase 1:\n\t\treturn bpf_fill_scale1(self);\n\tcase 2:\n\t\treturn bpf_fill_scale2(self);\n\tdefault:\n\t\tself->prog_len = 0;\n\t\tbreak;\n\t}\n}\n\nstatic int bpf_fill_torturous_jumps_insn_1(struct bpf_insn *insn)\n{\n\tunsigned int len = 259, hlen = 128;\n\tint i;\n\n\tinsn[0] = BPF_EMIT_CALL(BPF_FUNC_get_prandom_u32);\n\tfor (i = 1; i <= hlen; i++) {\n\t\tinsn[i]        = BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, i, hlen);\n\t\tinsn[i + hlen] = BPF_JMP_A(hlen - i);\n\t}\n\tinsn[len - 2] = BPF_MOV64_IMM(BPF_REG_0, 1);\n\tinsn[len - 1] = BPF_EXIT_INSN();\n\n\treturn len;\n}\n\nstatic int bpf_fill_torturous_jumps_insn_2(struct bpf_insn *insn)\n{\n\tunsigned int len = 4100, jmp_off = 2048;\n\tint i, j;\n\n\tinsn[0] = BPF_EMIT_CALL(BPF_FUNC_get_prandom_u32);\n\tfor (i = 1; i <= jmp_off; i++) {\n\t\tinsn[i] = BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, i, jmp_off);\n\t}\n\tinsn[i++] = BPF_JMP_A(jmp_off);\n\tfor (; i <= jmp_off * 2 + 1; i+=16) {\n\t\tfor (j = 0; j < 16; j++) {\n\t\t\tinsn[i + j] = BPF_JMP_A(16 - j - 1);\n\t\t}\n\t}\n\n\tinsn[len - 2] = BPF_MOV64_IMM(BPF_REG_0, 2);\n\tinsn[len - 1] = BPF_EXIT_INSN();\n\n\treturn len;\n}\n\nstatic void bpf_fill_torturous_jumps(struct bpf_test *self)\n{\n\tstruct bpf_insn *insn = self->fill_insns;\n\tint i = 0;\n\n\tswitch (self->retval) {\n\tcase 1:\n\t\tself->prog_len = bpf_fill_torturous_jumps_insn_1(insn);\n\t\treturn;\n\tcase 2:\n\t\tself->prog_len = bpf_fill_torturous_jumps_insn_2(insn);\n\t\treturn;\n\tcase 3:\n\t\t \n\t\tinsn[i++] = BPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 4);\n\t\tinsn[i++] = BPF_RAW_INSN(BPF_JMP|BPF_CALL, 0, 1, 0, 262);\n\t\tinsn[i++] = BPF_ST_MEM(BPF_B, BPF_REG_10, -32, 0);\n\t\tinsn[i++] = BPF_MOV64_IMM(BPF_REG_0, 3);\n\t\tinsn[i++] = BPF_EXIT_INSN();\n\n\t\t \n\t\ti += bpf_fill_torturous_jumps_insn_1(insn + i);\n\n\t\t \n\t\ti += bpf_fill_torturous_jumps_insn_2(insn + i);\n\n\t\tself->prog_len = i;\n\t\treturn;\n\tdefault:\n\t\tself->prog_len = 0;\n\t\tbreak;\n\t}\n}\n\nstatic void bpf_fill_big_prog_with_loop_1(struct bpf_test *self)\n{\n\tstruct bpf_insn *insn = self->fill_insns;\n\t \n\tconst int len = getpagesize() - 25;\n\tint callback_load_idx;\n\tint callback_idx;\n\tint i = 0;\n\n\tinsn[i++] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_1, 1);\n\tcallback_load_idx = i;\n\tinsn[i++] = BPF_RAW_INSN(BPF_LD | BPF_IMM | BPF_DW,\n\t\t\t\t BPF_REG_2, BPF_PSEUDO_FUNC, 0,\n\t\t\t\t 777  );\n\tinsn[i++] = BPF_RAW_INSN(0, 0, 0, 0, 0);\n\tinsn[i++] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_3, 0);\n\tinsn[i++] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_4, 0);\n\tinsn[i++] = BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_loop);\n\n\twhile (i < len - 3)\n\t\tinsn[i++] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_0, 0);\n\tinsn[i++] = BPF_EXIT_INSN();\n\n\tcallback_idx = i;\n\tinsn[i++] = BPF_ALU64_IMM(BPF_MOV, BPF_REG_0, 0);\n\tinsn[i++] = BPF_EXIT_INSN();\n\n\tinsn[callback_load_idx].imm = callback_idx - callback_load_idx - 1;\n\tself->func_info[1].insn_off = callback_idx;\n\tself->prog_len = i;\n\tassert(i == len);\n}\n\n \n#define BPF_SK_LOOKUP(func)\t\t\t\t\t\t\\\n\t \t\t\t\t\\\n\tBPF_MOV64_IMM(BPF_REG_2, 0),\t\t\t\t\t\\\n\tBPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_2, -8),\t\t\t\\\n\tBPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_2, -16),\t\t\\\n\tBPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_2, -24),\t\t\\\n\tBPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_2, -32),\t\t\\\n\tBPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_2, -40),\t\t\\\n\tBPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_2, -48),\t\t\\\n\t \t\t\\\n\tBPF_MOV64_REG(BPF_REG_2, BPF_REG_10),\t\t\t\t\\\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -48),\t\t\t\t\\\n\tBPF_MOV64_IMM(BPF_REG_3, sizeof(struct bpf_sock_tuple)),\t\\\n\tBPF_MOV64_IMM(BPF_REG_4, 0),\t\t\t\t\t\\\n\tBPF_MOV64_IMM(BPF_REG_5, 0),\t\t\t\t\t\\\n\tBPF_EMIT_CALL(BPF_FUNC_ ## func)\n\n \n#define BPF_DIRECT_PKT_R2\t\t\t\t\t\t\\\n\tBPF_MOV64_IMM(BPF_REG_0, 0),\t\t\t\t\t\\\n\tBPF_LDX_MEM(BPF_W, BPF_REG_2, BPF_REG_1,\t\t\t\\\n\t\t    offsetof(struct __sk_buff, data)),\t\t\t\\\n\tBPF_LDX_MEM(BPF_W, BPF_REG_3, BPF_REG_1,\t\t\t\\\n\t\t    offsetof(struct __sk_buff, data_end)),\t\t\\\n\tBPF_MOV64_REG(BPF_REG_4, BPF_REG_2),\t\t\t\t\\\n\tBPF_ALU64_IMM(BPF_ADD, BPF_REG_4, 8),\t\t\t\t\\\n\tBPF_JMP_REG(BPF_JLE, BPF_REG_4, BPF_REG_3, 1),\t\t\t\\\n\tBPF_EXIT_INSN()\n\n \n#define BPF_RAND_UEXT_R7\t\t\t\t\t\t\\\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,\t\t\t\\\n\t\t     BPF_FUNC_get_prandom_u32),\t\t\t\t\\\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_0),\t\t\t\t\\\n\tBPF_ALU64_IMM(BPF_LSH, BPF_REG_7, 33),\t\t\t\t\\\n\tBPF_ALU64_IMM(BPF_RSH, BPF_REG_7, 33)\n\n \n#define BPF_RAND_SEXT_R7\t\t\t\t\t\t\\\n\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,\t\t\t\\\n\t\t     BPF_FUNC_get_prandom_u32),\t\t\t\t\\\n\tBPF_MOV64_REG(BPF_REG_7, BPF_REG_0),\t\t\t\t\\\n\tBPF_ALU64_IMM(BPF_OR, BPF_REG_7, 0x80000000),\t\t\t\\\n\tBPF_ALU64_IMM(BPF_LSH, BPF_REG_7, 32),\t\t\t\t\\\n\tBPF_ALU64_IMM(BPF_ARSH, BPF_REG_7, 32)\n\nstatic struct bpf_test tests[] = {\n#define FILL_ARRAY\n#include <verifier/tests.h>\n#undef FILL_ARRAY\n};\n\nstatic int probe_filter_length(const struct bpf_insn *fp)\n{\n\tint len;\n\n\tfor (len = MAX_INSNS - 1; len > 0; --len)\n\t\tif (fp[len].code != 0 || fp[len].imm != 0)\n\t\t\tbreak;\n\treturn len + 1;\n}\n\nstatic bool skip_unsupported_map(enum bpf_map_type map_type)\n{\n\tif (!libbpf_probe_bpf_map_type(map_type, NULL)) {\n\t\tprintf(\"SKIP (unsupported map type %d)\\n\", map_type);\n\t\tskips++;\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic int __create_map(uint32_t type, uint32_t size_key,\n\t\t\tuint32_t size_value, uint32_t max_elem,\n\t\t\tuint32_t extra_flags)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, opts);\n\tint fd;\n\n\topts.map_flags = (type == BPF_MAP_TYPE_HASH ? BPF_F_NO_PREALLOC : 0) | extra_flags;\n\tfd = bpf_map_create(type, NULL, size_key, size_value, max_elem, &opts);\n\tif (fd < 0) {\n\t\tif (skip_unsupported_map(type))\n\t\t\treturn -1;\n\t\tprintf(\"Failed to create hash map '%s'!\\n\", strerror(errno));\n\t}\n\n\treturn fd;\n}\n\nstatic int create_map(uint32_t type, uint32_t size_key,\n\t\t      uint32_t size_value, uint32_t max_elem)\n{\n\treturn __create_map(type, size_key, size_value, max_elem, 0);\n}\n\nstatic void update_map(int fd, int index)\n{\n\tstruct test_val value = {\n\t\t.index = (6 + 1) * sizeof(int),\n\t\t.foo[6] = 0xabcdef12,\n\t};\n\n\tassert(!bpf_map_update_elem(fd, &index, &value, 0));\n}\n\nstatic int create_prog_dummy_simple(enum bpf_prog_type prog_type, int ret)\n{\n\tstruct bpf_insn prog[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, ret),\n\t\tBPF_EXIT_INSN(),\n\t};\n\n\treturn bpf_prog_load(prog_type, NULL, \"GPL\", prog, ARRAY_SIZE(prog), NULL);\n}\n\nstatic int create_prog_dummy_loop(enum bpf_prog_type prog_type, int mfd,\n\t\t\t\t  int idx, int ret)\n{\n\tstruct bpf_insn prog[] = {\n\t\tBPF_MOV64_IMM(BPF_REG_3, idx),\n\t\tBPF_LD_MAP_FD(BPF_REG_2, mfd),\n\t\tBPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0,\n\t\t\t     BPF_FUNC_tail_call),\n\t\tBPF_MOV64_IMM(BPF_REG_0, ret),\n\t\tBPF_EXIT_INSN(),\n\t};\n\n\treturn bpf_prog_load(prog_type, NULL, \"GPL\", prog, ARRAY_SIZE(prog), NULL);\n}\n\nstatic int create_prog_array(enum bpf_prog_type prog_type, uint32_t max_elem,\n\t\t\t     int p1key, int p2key, int p3key)\n{\n\tint mfd, p1fd, p2fd, p3fd;\n\n\tmfd = bpf_map_create(BPF_MAP_TYPE_PROG_ARRAY, NULL, sizeof(int),\n\t\t\t     sizeof(int), max_elem, NULL);\n\tif (mfd < 0) {\n\t\tif (skip_unsupported_map(BPF_MAP_TYPE_PROG_ARRAY))\n\t\t\treturn -1;\n\t\tprintf(\"Failed to create prog array '%s'!\\n\", strerror(errno));\n\t\treturn -1;\n\t}\n\n\tp1fd = create_prog_dummy_simple(prog_type, 42);\n\tp2fd = create_prog_dummy_loop(prog_type, mfd, p2key, 41);\n\tp3fd = create_prog_dummy_simple(prog_type, 24);\n\tif (p1fd < 0 || p2fd < 0 || p3fd < 0)\n\t\tgoto err;\n\tif (bpf_map_update_elem(mfd, &p1key, &p1fd, BPF_ANY) < 0)\n\t\tgoto err;\n\tif (bpf_map_update_elem(mfd, &p2key, &p2fd, BPF_ANY) < 0)\n\t\tgoto err;\n\tif (bpf_map_update_elem(mfd, &p3key, &p3fd, BPF_ANY) < 0) {\nerr:\n\t\tclose(mfd);\n\t\tmfd = -1;\n\t}\n\tclose(p3fd);\n\tclose(p2fd);\n\tclose(p1fd);\n\treturn mfd;\n}\n\nstatic int create_map_in_map(void)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, opts);\n\tint inner_map_fd, outer_map_fd;\n\n\tinner_map_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY, NULL, sizeof(int),\n\t\t\t\t      sizeof(int), 1, NULL);\n\tif (inner_map_fd < 0) {\n\t\tif (skip_unsupported_map(BPF_MAP_TYPE_ARRAY))\n\t\t\treturn -1;\n\t\tprintf(\"Failed to create array '%s'!\\n\", strerror(errno));\n\t\treturn inner_map_fd;\n\t}\n\n\topts.inner_map_fd = inner_map_fd;\n\touter_map_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY_OF_MAPS, NULL,\n\t\t\t\t      sizeof(int), sizeof(int), 1, &opts);\n\tif (outer_map_fd < 0) {\n\t\tif (skip_unsupported_map(BPF_MAP_TYPE_ARRAY_OF_MAPS))\n\t\t\treturn -1;\n\t\tprintf(\"Failed to create array of maps '%s'!\\n\",\n\t\t       strerror(errno));\n\t}\n\n\tclose(inner_map_fd);\n\n\treturn outer_map_fd;\n}\n\nstatic int create_cgroup_storage(bool percpu)\n{\n\tenum bpf_map_type type = percpu ? BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE :\n\t\tBPF_MAP_TYPE_CGROUP_STORAGE;\n\tint fd;\n\n\tfd = bpf_map_create(type, NULL, sizeof(struct bpf_cgroup_storage_key),\n\t\t\t    TEST_DATA_LEN, 0, NULL);\n\tif (fd < 0) {\n\t\tif (skip_unsupported_map(type))\n\t\t\treturn -1;\n\t\tprintf(\"Failed to create cgroup storage '%s'!\\n\",\n\t\t       strerror(errno));\n\t}\n\n\treturn fd;\n}\n\n \nstatic const char btf_str_sec[] = \"\\0bpf_spin_lock\\0val\\0cnt\\0l\\0bpf_timer\\0timer\\0t\"\n\t\t\t\t  \"\\0btf_ptr\\0prog_test_ref_kfunc\\0ptr\\0kptr\\0kptr_untrusted\"\n\t\t\t\t  \"\\0prog_test_member\";\nstatic __u32 btf_raw_types[] = {\n\t \n\tBTF_TYPE_INT_ENC(0, BTF_INT_SIGNED, 0, 32, 4),   \n\t                        \n\tBTF_TYPE_ENC(1, BTF_INFO_ENC(BTF_KIND_STRUCT, 0, 1), 4),\n\tBTF_MEMBER_ENC(15, 1, 0),  \n\t                                  \n\tBTF_TYPE_ENC(15, BTF_INFO_ENC(BTF_KIND_STRUCT, 0, 2), 8),\n\tBTF_MEMBER_ENC(19, 1, 0),  \n\tBTF_MEMBER_ENC(23, 2, 32), \n\t                            \n\tBTF_TYPE_ENC(25, BTF_INFO_ENC(BTF_KIND_STRUCT, 0, 0), 16),\n\t                                \n\tBTF_TYPE_ENC(35, BTF_INFO_ENC(BTF_KIND_STRUCT, 0, 1), 16),\n\tBTF_MEMBER_ENC(41, 4, 0),  \n\t \t\t \n\tBTF_STRUCT_ENC(51, 0, 0),\n\tBTF_STRUCT_ENC(95, 0, 0),\t\t\t \n\t \n\tBTF_TYPE_TAG_ENC(80, 6),\t\t\t \n\t \n\tBTF_TYPE_TAG_ENC(75, 6),\t\t\t \n\tBTF_TYPE_TAG_ENC(75, 7),\t\t\t \n\tBTF_PTR_ENC(8),\t\t\t\t\t \n\tBTF_PTR_ENC(9),\t\t\t\t\t \n\tBTF_PTR_ENC(10),\t\t\t\t \n\t \t\t\t\t \n\tBTF_STRUCT_ENC(43, 3, 24),\n\tBTF_MEMBER_ENC(71, 11, 0),  \n\tBTF_MEMBER_ENC(71, 12, 64),  \n\tBTF_MEMBER_ENC(71, 13, 128),  \n};\n\nstatic char bpf_vlog[UINT_MAX >> 8];\n\nstatic int load_btf_spec(__u32 *types, int types_len,\n\t\t\t const char *strings, int strings_len)\n{\n\tstruct btf_header hdr = {\n\t\t.magic = BTF_MAGIC,\n\t\t.version = BTF_VERSION,\n\t\t.hdr_len = sizeof(struct btf_header),\n\t\t.type_len = types_len,\n\t\t.str_off = types_len,\n\t\t.str_len = strings_len,\n\t};\n\tvoid *ptr, *raw_btf;\n\tint btf_fd;\n\tLIBBPF_OPTS(bpf_btf_load_opts, opts,\n\t\t    .log_buf = bpf_vlog,\n\t\t    .log_size = sizeof(bpf_vlog),\n\t\t    .log_level = (verbose\n\t\t\t\t  ? verif_log_level\n\t\t\t\t  : DEFAULT_LIBBPF_LOG_LEVEL),\n\t);\n\n\traw_btf = malloc(sizeof(hdr) + types_len + strings_len);\n\n\tptr = raw_btf;\n\tmemcpy(ptr, &hdr, sizeof(hdr));\n\tptr += sizeof(hdr);\n\tmemcpy(ptr, types, hdr.type_len);\n\tptr += hdr.type_len;\n\tmemcpy(ptr, strings, hdr.str_len);\n\tptr += hdr.str_len;\n\n\tbtf_fd = bpf_btf_load(raw_btf, ptr - raw_btf, &opts);\n\tif (btf_fd < 0)\n\t\tprintf(\"Failed to load BTF spec: '%s'\\n\", strerror(errno));\n\n\tfree(raw_btf);\n\n\treturn btf_fd < 0 ? -1 : btf_fd;\n}\n\nstatic int load_btf(void)\n{\n\treturn load_btf_spec(btf_raw_types, sizeof(btf_raw_types),\n\t\t\t     btf_str_sec, sizeof(btf_str_sec));\n}\n\nstatic int load_btf_for_test(struct bpf_test *test)\n{\n\tint types_num = 0;\n\n\twhile (types_num < MAX_BTF_TYPES &&\n\t       test->btf_types[types_num] != BTF_END_RAW)\n\t\t++types_num;\n\n\tint types_len = types_num * sizeof(test->btf_types[0]);\n\n\treturn load_btf_spec(test->btf_types, types_len,\n\t\t\t     test->btf_strings, sizeof(test->btf_strings));\n}\n\nstatic int create_map_spin_lock(void)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, opts,\n\t\t.btf_key_type_id = 1,\n\t\t.btf_value_type_id = 3,\n\t);\n\tint fd, btf_fd;\n\n\tbtf_fd = load_btf();\n\tif (btf_fd < 0)\n\t\treturn -1;\n\topts.btf_fd = btf_fd;\n\tfd = bpf_map_create(BPF_MAP_TYPE_ARRAY, \"test_map\", 4, 8, 1, &opts);\n\tif (fd < 0)\n\t\tprintf(\"Failed to create map with spin_lock\\n\");\n\treturn fd;\n}\n\nstatic int create_sk_storage_map(void)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, opts,\n\t\t.map_flags = BPF_F_NO_PREALLOC,\n\t\t.btf_key_type_id = 1,\n\t\t.btf_value_type_id = 3,\n\t);\n\tint fd, btf_fd;\n\n\tbtf_fd = load_btf();\n\tif (btf_fd < 0)\n\t\treturn -1;\n\topts.btf_fd = btf_fd;\n\tfd = bpf_map_create(BPF_MAP_TYPE_SK_STORAGE, \"test_map\", 4, 8, 0, &opts);\n\tclose(opts.btf_fd);\n\tif (fd < 0)\n\t\tprintf(\"Failed to create sk_storage_map\\n\");\n\treturn fd;\n}\n\nstatic int create_map_timer(void)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, opts,\n\t\t.btf_key_type_id = 1,\n\t\t.btf_value_type_id = 5,\n\t);\n\tint fd, btf_fd;\n\n\tbtf_fd = load_btf();\n\tif (btf_fd < 0)\n\t\treturn -1;\n\n\topts.btf_fd = btf_fd;\n\tfd = bpf_map_create(BPF_MAP_TYPE_ARRAY, \"test_map\", 4, 16, 1, &opts);\n\tif (fd < 0)\n\t\tprintf(\"Failed to create map with timer\\n\");\n\treturn fd;\n}\n\nstatic int create_map_kptr(void)\n{\n\tLIBBPF_OPTS(bpf_map_create_opts, opts,\n\t\t.btf_key_type_id = 1,\n\t\t.btf_value_type_id = 14,\n\t);\n\tint fd, btf_fd;\n\n\tbtf_fd = load_btf();\n\tif (btf_fd < 0)\n\t\treturn -1;\n\n\topts.btf_fd = btf_fd;\n\tfd = bpf_map_create(BPF_MAP_TYPE_ARRAY, \"test_map\", 4, 24, 1, &opts);\n\tif (fd < 0)\n\t\tprintf(\"Failed to create map with btf_id pointer\\n\");\n\treturn fd;\n}\n\nstatic void set_root(bool set)\n{\n\t__u64 caps;\n\n\tif (set) {\n\t\tif (cap_enable_effective(1ULL << CAP_SYS_ADMIN, &caps))\n\t\t\tperror(\"cap_disable_effective(CAP_SYS_ADMIN)\");\n\t} else {\n\t\tif (cap_disable_effective(1ULL << CAP_SYS_ADMIN, &caps))\n\t\t\tperror(\"cap_disable_effective(CAP_SYS_ADMIN)\");\n\t}\n}\n\nstatic __u64 ptr_to_u64(const void *ptr)\n{\n\treturn (uintptr_t) ptr;\n}\n\nstatic struct btf *btf__load_testmod_btf(struct btf *vmlinux)\n{\n\tstruct bpf_btf_info info;\n\t__u32 len = sizeof(info);\n\tstruct btf *btf = NULL;\n\tchar name[64];\n\t__u32 id = 0;\n\tint err, fd;\n\n\t \n\tset_root(true);\n\n\twhile (true) {\n\t\terr = bpf_btf_get_next_id(id, &id);\n\t\tif (err) {\n\t\t\tif (errno == ENOENT)\n\t\t\t\tbreak;\n\t\t\tperror(\"bpf_btf_get_next_id failed\");\n\t\t\tbreak;\n\t\t}\n\n\t\tfd = bpf_btf_get_fd_by_id(id);\n\t\tif (fd < 0) {\n\t\t\tif (errno == ENOENT)\n\t\t\t\tcontinue;\n\t\t\tperror(\"bpf_btf_get_fd_by_id failed\");\n\t\t\tbreak;\n\t\t}\n\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.name_len = sizeof(name);\n\t\tinfo.name = ptr_to_u64(name);\n\t\tlen = sizeof(info);\n\n\t\terr = bpf_obj_get_info_by_fd(fd, &info, &len);\n\t\tif (err) {\n\t\t\tclose(fd);\n\t\t\tperror(\"bpf_obj_get_info_by_fd failed\");\n\t\t\tbreak;\n\t\t}\n\n\t\tif (strcmp(\"bpf_testmod\", name)) {\n\t\t\tclose(fd);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbtf = btf__load_from_kernel_by_id_split(id, vmlinux);\n\t\tif (!btf) {\n\t\t\tclose(fd);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tbtf__set_fd(btf, fd);\n\t\tbreak;\n\t}\n\n\tset_root(false);\n\treturn btf;\n}\n\nstatic struct btf *testmod_btf;\nstatic struct btf *vmlinux_btf;\n\nstatic void kfuncs_cleanup(void)\n{\n\tbtf__free(testmod_btf);\n\tbtf__free(vmlinux_btf);\n}\n\nstatic void fixup_prog_kfuncs(struct bpf_insn *prog, int *fd_array,\n\t\t\t      struct kfunc_btf_id_pair *fixup_kfunc_btf_id)\n{\n\t \n\twhile (fixup_kfunc_btf_id->kfunc) {\n\t\tint btf_id = 0;\n\n\t\t \n\t\tvmlinux_btf = vmlinux_btf ?: btf__load_vmlinux_btf();\n\t\tif (vmlinux_btf) {\n\t\t\tbtf_id = btf__find_by_name_kind(vmlinux_btf,\n\t\t\t\t\t\t\tfixup_kfunc_btf_id->kfunc,\n\t\t\t\t\t\t\tBTF_KIND_FUNC);\n\t\t\tbtf_id = btf_id < 0 ? 0 : btf_id;\n\t\t}\n\n\t\t \n\t\tif (!btf_id) {\n\t\t\ttestmod_btf = testmod_btf ?: btf__load_testmod_btf(vmlinux_btf);\n\t\t\tif (testmod_btf) {\n\t\t\t\tbtf_id = btf__find_by_name_kind(testmod_btf,\n\t\t\t\t\t\t\t\tfixup_kfunc_btf_id->kfunc,\n\t\t\t\t\t\t\t\tBTF_KIND_FUNC);\n\t\t\t\tbtf_id = btf_id < 0 ? 0 : btf_id;\n\t\t\t\tif (btf_id) {\n\t\t\t\t\t \n\t\t\t\t\t*fd_array = btf__fd(testmod_btf);\n\t\t\t\t\tprog[fixup_kfunc_btf_id->insn_idx].off = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tprog[fixup_kfunc_btf_id->insn_idx].imm = btf_id;\n\t\tfixup_kfunc_btf_id++;\n\t}\n}\n\nstatic void do_test_fixup(struct bpf_test *test, enum bpf_prog_type prog_type,\n\t\t\t  struct bpf_insn *prog, int *map_fds, int *fd_array)\n{\n\tint *fixup_map_hash_8b = test->fixup_map_hash_8b;\n\tint *fixup_map_hash_48b = test->fixup_map_hash_48b;\n\tint *fixup_map_hash_16b = test->fixup_map_hash_16b;\n\tint *fixup_map_array_48b = test->fixup_map_array_48b;\n\tint *fixup_map_sockmap = test->fixup_map_sockmap;\n\tint *fixup_map_sockhash = test->fixup_map_sockhash;\n\tint *fixup_map_xskmap = test->fixup_map_xskmap;\n\tint *fixup_map_stacktrace = test->fixup_map_stacktrace;\n\tint *fixup_prog1 = test->fixup_prog1;\n\tint *fixup_prog2 = test->fixup_prog2;\n\tint *fixup_map_in_map = test->fixup_map_in_map;\n\tint *fixup_cgroup_storage = test->fixup_cgroup_storage;\n\tint *fixup_percpu_cgroup_storage = test->fixup_percpu_cgroup_storage;\n\tint *fixup_map_spin_lock = test->fixup_map_spin_lock;\n\tint *fixup_map_array_ro = test->fixup_map_array_ro;\n\tint *fixup_map_array_wo = test->fixup_map_array_wo;\n\tint *fixup_map_array_small = test->fixup_map_array_small;\n\tint *fixup_sk_storage_map = test->fixup_sk_storage_map;\n\tint *fixup_map_event_output = test->fixup_map_event_output;\n\tint *fixup_map_reuseport_array = test->fixup_map_reuseport_array;\n\tint *fixup_map_ringbuf = test->fixup_map_ringbuf;\n\tint *fixup_map_timer = test->fixup_map_timer;\n\tint *fixup_map_kptr = test->fixup_map_kptr;\n\n\tif (test->fill_helper) {\n\t\ttest->fill_insns = calloc(MAX_TEST_INSNS, sizeof(struct bpf_insn));\n\t\ttest->fill_helper(test);\n\t}\n\n\t \n\tif (*fixup_map_hash_8b) {\n\t\tmap_fds[0] = create_map(BPF_MAP_TYPE_HASH, sizeof(long long),\n\t\t\t\t\tsizeof(long long), 1);\n\t\tdo {\n\t\t\tprog[*fixup_map_hash_8b].imm = map_fds[0];\n\t\t\tfixup_map_hash_8b++;\n\t\t} while (*fixup_map_hash_8b);\n\t}\n\n\tif (*fixup_map_hash_48b) {\n\t\tmap_fds[1] = create_map(BPF_MAP_TYPE_HASH, sizeof(long long),\n\t\t\t\t\tsizeof(struct test_val), 1);\n\t\tdo {\n\t\t\tprog[*fixup_map_hash_48b].imm = map_fds[1];\n\t\t\tfixup_map_hash_48b++;\n\t\t} while (*fixup_map_hash_48b);\n\t}\n\n\tif (*fixup_map_hash_16b) {\n\t\tmap_fds[2] = create_map(BPF_MAP_TYPE_HASH, sizeof(long long),\n\t\t\t\t\tsizeof(struct other_val), 1);\n\t\tdo {\n\t\t\tprog[*fixup_map_hash_16b].imm = map_fds[2];\n\t\t\tfixup_map_hash_16b++;\n\t\t} while (*fixup_map_hash_16b);\n\t}\n\n\tif (*fixup_map_array_48b) {\n\t\tmap_fds[3] = create_map(BPF_MAP_TYPE_ARRAY, sizeof(int),\n\t\t\t\t\tsizeof(struct test_val), 1);\n\t\tupdate_map(map_fds[3], 0);\n\t\tdo {\n\t\t\tprog[*fixup_map_array_48b].imm = map_fds[3];\n\t\t\tfixup_map_array_48b++;\n\t\t} while (*fixup_map_array_48b);\n\t}\n\n\tif (*fixup_prog1) {\n\t\tmap_fds[4] = create_prog_array(prog_type, 4, 0, 1, 2);\n\t\tdo {\n\t\t\tprog[*fixup_prog1].imm = map_fds[4];\n\t\t\tfixup_prog1++;\n\t\t} while (*fixup_prog1);\n\t}\n\n\tif (*fixup_prog2) {\n\t\tmap_fds[5] = create_prog_array(prog_type, 8, 7, 1, 2);\n\t\tdo {\n\t\t\tprog[*fixup_prog2].imm = map_fds[5];\n\t\t\tfixup_prog2++;\n\t\t} while (*fixup_prog2);\n\t}\n\n\tif (*fixup_map_in_map) {\n\t\tmap_fds[6] = create_map_in_map();\n\t\tdo {\n\t\t\tprog[*fixup_map_in_map].imm = map_fds[6];\n\t\t\tfixup_map_in_map++;\n\t\t} while (*fixup_map_in_map);\n\t}\n\n\tif (*fixup_cgroup_storage) {\n\t\tmap_fds[7] = create_cgroup_storage(false);\n\t\tdo {\n\t\t\tprog[*fixup_cgroup_storage].imm = map_fds[7];\n\t\t\tfixup_cgroup_storage++;\n\t\t} while (*fixup_cgroup_storage);\n\t}\n\n\tif (*fixup_percpu_cgroup_storage) {\n\t\tmap_fds[8] = create_cgroup_storage(true);\n\t\tdo {\n\t\t\tprog[*fixup_percpu_cgroup_storage].imm = map_fds[8];\n\t\t\tfixup_percpu_cgroup_storage++;\n\t\t} while (*fixup_percpu_cgroup_storage);\n\t}\n\tif (*fixup_map_sockmap) {\n\t\tmap_fds[9] = create_map(BPF_MAP_TYPE_SOCKMAP, sizeof(int),\n\t\t\t\t\tsizeof(int), 1);\n\t\tdo {\n\t\t\tprog[*fixup_map_sockmap].imm = map_fds[9];\n\t\t\tfixup_map_sockmap++;\n\t\t} while (*fixup_map_sockmap);\n\t}\n\tif (*fixup_map_sockhash) {\n\t\tmap_fds[10] = create_map(BPF_MAP_TYPE_SOCKHASH, sizeof(int),\n\t\t\t\t\tsizeof(int), 1);\n\t\tdo {\n\t\t\tprog[*fixup_map_sockhash].imm = map_fds[10];\n\t\t\tfixup_map_sockhash++;\n\t\t} while (*fixup_map_sockhash);\n\t}\n\tif (*fixup_map_xskmap) {\n\t\tmap_fds[11] = create_map(BPF_MAP_TYPE_XSKMAP, sizeof(int),\n\t\t\t\t\tsizeof(int), 1);\n\t\tdo {\n\t\t\tprog[*fixup_map_xskmap].imm = map_fds[11];\n\t\t\tfixup_map_xskmap++;\n\t\t} while (*fixup_map_xskmap);\n\t}\n\tif (*fixup_map_stacktrace) {\n\t\tmap_fds[12] = create_map(BPF_MAP_TYPE_STACK_TRACE, sizeof(u32),\n\t\t\t\t\t sizeof(u64), 1);\n\t\tdo {\n\t\t\tprog[*fixup_map_stacktrace].imm = map_fds[12];\n\t\t\tfixup_map_stacktrace++;\n\t\t} while (*fixup_map_stacktrace);\n\t}\n\tif (*fixup_map_spin_lock) {\n\t\tmap_fds[13] = create_map_spin_lock();\n\t\tdo {\n\t\t\tprog[*fixup_map_spin_lock].imm = map_fds[13];\n\t\t\tfixup_map_spin_lock++;\n\t\t} while (*fixup_map_spin_lock);\n\t}\n\tif (*fixup_map_array_ro) {\n\t\tmap_fds[14] = __create_map(BPF_MAP_TYPE_ARRAY, sizeof(int),\n\t\t\t\t\t   sizeof(struct test_val), 1,\n\t\t\t\t\t   BPF_F_RDONLY_PROG);\n\t\tupdate_map(map_fds[14], 0);\n\t\tdo {\n\t\t\tprog[*fixup_map_array_ro].imm = map_fds[14];\n\t\t\tfixup_map_array_ro++;\n\t\t} while (*fixup_map_array_ro);\n\t}\n\tif (*fixup_map_array_wo) {\n\t\tmap_fds[15] = __create_map(BPF_MAP_TYPE_ARRAY, sizeof(int),\n\t\t\t\t\t   sizeof(struct test_val), 1,\n\t\t\t\t\t   BPF_F_WRONLY_PROG);\n\t\tupdate_map(map_fds[15], 0);\n\t\tdo {\n\t\t\tprog[*fixup_map_array_wo].imm = map_fds[15];\n\t\t\tfixup_map_array_wo++;\n\t\t} while (*fixup_map_array_wo);\n\t}\n\tif (*fixup_map_array_small) {\n\t\tmap_fds[16] = __create_map(BPF_MAP_TYPE_ARRAY, sizeof(int),\n\t\t\t\t\t   1, 1, 0);\n\t\tupdate_map(map_fds[16], 0);\n\t\tdo {\n\t\t\tprog[*fixup_map_array_small].imm = map_fds[16];\n\t\t\tfixup_map_array_small++;\n\t\t} while (*fixup_map_array_small);\n\t}\n\tif (*fixup_sk_storage_map) {\n\t\tmap_fds[17] = create_sk_storage_map();\n\t\tdo {\n\t\t\tprog[*fixup_sk_storage_map].imm = map_fds[17];\n\t\t\tfixup_sk_storage_map++;\n\t\t} while (*fixup_sk_storage_map);\n\t}\n\tif (*fixup_map_event_output) {\n\t\tmap_fds[18] = __create_map(BPF_MAP_TYPE_PERF_EVENT_ARRAY,\n\t\t\t\t\t   sizeof(int), sizeof(int), 1, 0);\n\t\tdo {\n\t\t\tprog[*fixup_map_event_output].imm = map_fds[18];\n\t\t\tfixup_map_event_output++;\n\t\t} while (*fixup_map_event_output);\n\t}\n\tif (*fixup_map_reuseport_array) {\n\t\tmap_fds[19] = __create_map(BPF_MAP_TYPE_REUSEPORT_SOCKARRAY,\n\t\t\t\t\t   sizeof(u32), sizeof(u64), 1, 0);\n\t\tdo {\n\t\t\tprog[*fixup_map_reuseport_array].imm = map_fds[19];\n\t\t\tfixup_map_reuseport_array++;\n\t\t} while (*fixup_map_reuseport_array);\n\t}\n\tif (*fixup_map_ringbuf) {\n\t\tmap_fds[20] = create_map(BPF_MAP_TYPE_RINGBUF, 0,\n\t\t\t\t\t 0, getpagesize());\n\t\tdo {\n\t\t\tprog[*fixup_map_ringbuf].imm = map_fds[20];\n\t\t\tfixup_map_ringbuf++;\n\t\t} while (*fixup_map_ringbuf);\n\t}\n\tif (*fixup_map_timer) {\n\t\tmap_fds[21] = create_map_timer();\n\t\tdo {\n\t\t\tprog[*fixup_map_timer].imm = map_fds[21];\n\t\t\tfixup_map_timer++;\n\t\t} while (*fixup_map_timer);\n\t}\n\tif (*fixup_map_kptr) {\n\t\tmap_fds[22] = create_map_kptr();\n\t\tdo {\n\t\t\tprog[*fixup_map_kptr].imm = map_fds[22];\n\t\t\tfixup_map_kptr++;\n\t\t} while (*fixup_map_kptr);\n\t}\n\n\tfixup_prog_kfuncs(prog, fd_array, test->fixup_kfunc_btf_id);\n}\n\nstruct libcap {\n\tstruct __user_cap_header_struct hdr;\n\tstruct __user_cap_data_struct data[2];\n};\n\nstatic int set_admin(bool admin)\n{\n\tint err;\n\n\tif (admin) {\n\t\terr = cap_enable_effective(ADMIN_CAPS, NULL);\n\t\tif (err)\n\t\t\tperror(\"cap_enable_effective(ADMIN_CAPS)\");\n\t} else {\n\t\terr = cap_disable_effective(ADMIN_CAPS, NULL);\n\t\tif (err)\n\t\t\tperror(\"cap_disable_effective(ADMIN_CAPS)\");\n\t}\n\n\treturn err;\n}\n\nstatic int do_prog_test_run(int fd_prog, bool unpriv, uint32_t expected_val,\n\t\t\t    void *data, size_t size_data)\n{\n\t__u8 tmp[TEST_DATA_LEN << 2];\n\t__u32 size_tmp = sizeof(tmp);\n\tint err, saved_errno;\n\tLIBBPF_OPTS(bpf_test_run_opts, topts,\n\t\t.data_in = data,\n\t\t.data_size_in = size_data,\n\t\t.data_out = tmp,\n\t\t.data_size_out = size_tmp,\n\t\t.repeat = 1,\n\t);\n\n\tif (unpriv)\n\t\tset_admin(true);\n\terr = bpf_prog_test_run_opts(fd_prog, &topts);\n\tsaved_errno = errno;\n\n\tif (unpriv)\n\t\tset_admin(false);\n\n\tif (err) {\n\t\tswitch (saved_errno) {\n\t\tcase ENOTSUPP:\n\t\t\tprintf(\"Did not run the program (not supported) \");\n\t\t\treturn 0;\n\t\tcase EPERM:\n\t\t\tif (unpriv) {\n\t\t\t\tprintf(\"Did not run the program (no permission) \");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\t \n\t\tdefault:\n\t\t\tprintf(\"FAIL: Unexpected bpf_prog_test_run error (%s) \",\n\t\t\t\tstrerror(saved_errno));\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (topts.retval != expected_val && expected_val != POINTER_VALUE) {\n\t\tprintf(\"FAIL retval %d != %d \", topts.retval, expected_val);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\n \nstatic bool cmp_str_seq(const char *log, const char *exp)\n{\n\tchar needle[200];\n\tconst char *p, *q;\n\tint len;\n\n\tdo {\n\t\tif (!strlen(exp))\n\t\t\tbreak;\n\t\tp = strchr(exp, '\\t');\n\t\tif (!p)\n\t\t\tp = exp + strlen(exp);\n\n\t\tlen = p - exp;\n\t\tif (len >= sizeof(needle) || !len) {\n\t\t\tprintf(\"FAIL\\nTestcase bug\\n\");\n\t\t\treturn false;\n\t\t}\n\t\tstrncpy(needle, exp, len);\n\t\tneedle[len] = 0;\n\t\tq = strstr(log, needle);\n\t\tif (!q) {\n\t\t\tprintf(\"FAIL\\nUnexpected verifier log!\\n\"\n\t\t\t       \"EXP: %s\\nRES:\\n\", needle);\n\t\t\treturn false;\n\t\t}\n\t\tlog = q + len;\n\t\texp = p + 1;\n\t} while (*p);\n\treturn true;\n}\n\nstatic struct bpf_insn *get_xlated_program(int fd_prog, int *cnt)\n{\n\t__u32 buf_element_size = sizeof(struct bpf_insn);\n\tstruct bpf_prog_info info = {};\n\t__u32 info_len = sizeof(info);\n\t__u32 xlated_prog_len;\n\tstruct bpf_insn *buf;\n\n\tif (bpf_prog_get_info_by_fd(fd_prog, &info, &info_len)) {\n\t\tperror(\"bpf_prog_get_info_by_fd failed\");\n\t\treturn NULL;\n\t}\n\n\txlated_prog_len = info.xlated_prog_len;\n\tif (xlated_prog_len % buf_element_size) {\n\t\tprintf(\"Program length %d is not multiple of %d\\n\",\n\t\t       xlated_prog_len, buf_element_size);\n\t\treturn NULL;\n\t}\n\n\t*cnt = xlated_prog_len / buf_element_size;\n\tbuf = calloc(*cnt, buf_element_size);\n\tif (!buf) {\n\t\tperror(\"can't allocate xlated program buffer\");\n\t\treturn NULL;\n\t}\n\n\tbzero(&info, sizeof(info));\n\tinfo.xlated_prog_len = xlated_prog_len;\n\tinfo.xlated_prog_insns = (__u64)(unsigned long)buf;\n\tif (bpf_prog_get_info_by_fd(fd_prog, &info, &info_len)) {\n\t\tperror(\"second bpf_prog_get_info_by_fd failed\");\n\t\tgoto out_free_buf;\n\t}\n\n\treturn buf;\n\nout_free_buf:\n\tfree(buf);\n\treturn NULL;\n}\n\nstatic bool is_null_insn(struct bpf_insn *insn)\n{\n\tstruct bpf_insn null_insn = {};\n\n\treturn memcmp(insn, &null_insn, sizeof(null_insn)) == 0;\n}\n\nstatic bool is_skip_insn(struct bpf_insn *insn)\n{\n\tstruct bpf_insn skip_insn = SKIP_INSNS();\n\n\treturn memcmp(insn, &skip_insn, sizeof(skip_insn)) == 0;\n}\n\nstatic int null_terminated_insn_len(struct bpf_insn *seq, int max_len)\n{\n\tint i;\n\n\tfor (i = 0; i < max_len; ++i) {\n\t\tif (is_null_insn(&seq[i]))\n\t\t\treturn i;\n\t}\n\treturn max_len;\n}\n\nstatic bool compare_masked_insn(struct bpf_insn *orig, struct bpf_insn *masked)\n{\n\tstruct bpf_insn orig_masked;\n\n\tmemcpy(&orig_masked, orig, sizeof(orig_masked));\n\tif (masked->imm == INSN_IMM_MASK)\n\t\torig_masked.imm = INSN_IMM_MASK;\n\tif (masked->off == INSN_OFF_MASK)\n\t\torig_masked.off = INSN_OFF_MASK;\n\n\treturn memcmp(&orig_masked, masked, sizeof(orig_masked)) == 0;\n}\n\nstatic int find_insn_subseq(struct bpf_insn *seq, struct bpf_insn *subseq,\n\t\t\t    int seq_len, int subseq_len)\n{\n\tint i, j;\n\n\tif (subseq_len > seq_len)\n\t\treturn -1;\n\n\tfor (i = 0; i < seq_len - subseq_len + 1; ++i) {\n\t\tbool found = true;\n\n\t\tfor (j = 0; j < subseq_len; ++j) {\n\t\t\tif (!compare_masked_insn(&seq[i + j], &subseq[j])) {\n\t\t\t\tfound = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (found)\n\t\t\treturn i;\n\t}\n\n\treturn -1;\n}\n\nstatic int find_skip_insn_marker(struct bpf_insn *seq, int len)\n{\n\tint i;\n\n\tfor (i = 0; i < len; ++i)\n\t\tif (is_skip_insn(&seq[i]))\n\t\t\treturn i;\n\n\treturn -1;\n}\n\n \nstatic bool find_all_insn_subseqs(struct bpf_insn *seq, struct bpf_insn *subseqs,\n\t\t\t\t  int seq_len, int max_subseqs_len)\n{\n\tint subseqs_len = null_terminated_insn_len(subseqs, max_subseqs_len);\n\n\twhile (subseqs_len > 0) {\n\t\tint skip_idx = find_skip_insn_marker(subseqs, subseqs_len);\n\t\tint cur_subseq_len = skip_idx < 0 ? subseqs_len : skip_idx;\n\t\tint subseq_idx = find_insn_subseq(seq, subseqs,\n\t\t\t\t\t\t  seq_len, cur_subseq_len);\n\n\t\tif (subseq_idx < 0)\n\t\t\treturn false;\n\t\tseq += subseq_idx + cur_subseq_len;\n\t\tseq_len -= subseq_idx + cur_subseq_len;\n\t\tsubseqs += cur_subseq_len + 1;\n\t\tsubseqs_len -= cur_subseq_len + 1;\n\t}\n\n\treturn true;\n}\n\nstatic void print_insn(struct bpf_insn *buf, int cnt)\n{\n\tint i;\n\n\tprintf(\"  addr  op d s off  imm\\n\");\n\tfor (i = 0; i < cnt; ++i) {\n\t\tstruct bpf_insn *insn = &buf[i];\n\n\t\tif (is_null_insn(insn))\n\t\t\tbreak;\n\n\t\tif (is_skip_insn(insn))\n\t\t\tprintf(\"  ...\\n\");\n\t\telse\n\t\t\tprintf(\"  %04x: %02x %1x %x %04hx %08x\\n\",\n\t\t\t       i, insn->code, insn->dst_reg,\n\t\t\t       insn->src_reg, insn->off, insn->imm);\n\t}\n}\n\nstatic bool check_xlated_program(struct bpf_test *test, int fd_prog)\n{\n\tstruct bpf_insn *buf;\n\tint cnt;\n\tbool result = true;\n\tbool check_expected = !is_null_insn(test->expected_insns);\n\tbool check_unexpected = !is_null_insn(test->unexpected_insns);\n\n\tif (!check_expected && !check_unexpected)\n\t\tgoto out;\n\n\tbuf = get_xlated_program(fd_prog, &cnt);\n\tif (!buf) {\n\t\tprintf(\"FAIL: can't get xlated program\\n\");\n\t\tresult = false;\n\t\tgoto out;\n\t}\n\n\tif (check_expected &&\n\t    !find_all_insn_subseqs(buf, test->expected_insns,\n\t\t\t\t   cnt, MAX_EXPECTED_INSNS)) {\n\t\tprintf(\"FAIL: can't find expected subsequence of instructions\\n\");\n\t\tresult = false;\n\t\tif (verbose) {\n\t\t\tprintf(\"Program:\\n\");\n\t\t\tprint_insn(buf, cnt);\n\t\t\tprintf(\"Expected subsequence:\\n\");\n\t\t\tprint_insn(test->expected_insns, MAX_EXPECTED_INSNS);\n\t\t}\n\t}\n\n\tif (check_unexpected &&\n\t    find_all_insn_subseqs(buf, test->unexpected_insns,\n\t\t\t\t  cnt, MAX_UNEXPECTED_INSNS)) {\n\t\tprintf(\"FAIL: found unexpected subsequence of instructions\\n\");\n\t\tresult = false;\n\t\tif (verbose) {\n\t\t\tprintf(\"Program:\\n\");\n\t\t\tprint_insn(buf, cnt);\n\t\t\tprintf(\"Un-expected subsequence:\\n\");\n\t\t\tprint_insn(test->unexpected_insns, MAX_UNEXPECTED_INSNS);\n\t\t}\n\t}\n\n\tfree(buf);\n out:\n\treturn result;\n}\n\nstatic void do_test_single(struct bpf_test *test, bool unpriv,\n\t\t\t   int *passes, int *errors)\n{\n\tint fd_prog, btf_fd, expected_ret, alignment_prevented_execution;\n\tint prog_len, prog_type = test->prog_type;\n\tstruct bpf_insn *prog = test->insns;\n\tLIBBPF_OPTS(bpf_prog_load_opts, opts);\n\tint run_errs, run_successes;\n\tint map_fds[MAX_NR_MAPS];\n\tconst char *expected_err;\n\tint fd_array[2] = { -1, -1 };\n\tint saved_errno;\n\tint fixup_skips;\n\t__u32 pflags;\n\tint i, err;\n\n\tfd_prog = -1;\n\tfor (i = 0; i < MAX_NR_MAPS; i++)\n\t\tmap_fds[i] = -1;\n\tbtf_fd = -1;\n\n\tif (!prog_type)\n\t\tprog_type = BPF_PROG_TYPE_SOCKET_FILTER;\n\tfixup_skips = skips;\n\tdo_test_fixup(test, prog_type, prog, map_fds, &fd_array[1]);\n\tif (test->fill_insns) {\n\t\tprog = test->fill_insns;\n\t\tprog_len = test->prog_len;\n\t} else {\n\t\tprog_len = probe_filter_length(prog);\n\t}\n\t \n\tif (fixup_skips != skips)\n\t\treturn;\n\n\tpflags = BPF_F_TEST_RND_HI32;\n\tif (test->flags & F_LOAD_WITH_STRICT_ALIGNMENT)\n\t\tpflags |= BPF_F_STRICT_ALIGNMENT;\n\tif (test->flags & F_NEEDS_EFFICIENT_UNALIGNED_ACCESS)\n\t\tpflags |= BPF_F_ANY_ALIGNMENT;\n\tif (test->flags & ~3)\n\t\tpflags |= test->flags;\n\n\texpected_ret = unpriv && test->result_unpriv != UNDEF ?\n\t\t       test->result_unpriv : test->result;\n\texpected_err = unpriv && test->errstr_unpriv ?\n\t\t       test->errstr_unpriv : test->errstr;\n\n\topts.expected_attach_type = test->expected_attach_type;\n\tif (verbose)\n\t\topts.log_level = verif_log_level | 4;  \n\telse if (expected_ret == VERBOSE_ACCEPT)\n\t\topts.log_level = 2;\n\telse\n\t\topts.log_level = DEFAULT_LIBBPF_LOG_LEVEL;\n\topts.prog_flags = pflags;\n\tif (fd_array[1] != -1)\n\t\topts.fd_array = &fd_array[0];\n\n\tif ((prog_type == BPF_PROG_TYPE_TRACING ||\n\t     prog_type == BPF_PROG_TYPE_LSM) && test->kfunc) {\n\t\tint attach_btf_id;\n\n\t\tattach_btf_id = libbpf_find_vmlinux_btf_id(test->kfunc,\n\t\t\t\t\t\topts.expected_attach_type);\n\t\tif (attach_btf_id < 0) {\n\t\t\tprintf(\"FAIL\\nFailed to find BTF ID for '%s'!\\n\",\n\t\t\t\ttest->kfunc);\n\t\t\t(*errors)++;\n\t\t\treturn;\n\t\t}\n\n\t\topts.attach_btf_id = attach_btf_id;\n\t}\n\n\tif (test->btf_types[0] != 0) {\n\t\tbtf_fd = load_btf_for_test(test);\n\t\tif (btf_fd < 0)\n\t\t\tgoto fail_log;\n\t\topts.prog_btf_fd = btf_fd;\n\t}\n\n\tif (test->func_info_cnt != 0) {\n\t\topts.func_info = test->func_info;\n\t\topts.func_info_cnt = test->func_info_cnt;\n\t\topts.func_info_rec_size = sizeof(test->func_info[0]);\n\t}\n\n\topts.log_buf = bpf_vlog;\n\topts.log_size = sizeof(bpf_vlog);\n\tfd_prog = bpf_prog_load(prog_type, NULL, \"GPL\", prog, prog_len, &opts);\n\tsaved_errno = errno;\n\n\t \n\tif (fd_prog < 0 && prog_type != BPF_PROG_TYPE_TRACING &&\n\t    !libbpf_probe_bpf_prog_type(prog_type, NULL)) {\n\t\tprintf(\"SKIP (unsupported program type %d)\\n\", prog_type);\n\t\tskips++;\n\t\tgoto close_fds;\n\t}\n\n\tif (fd_prog < 0 && saved_errno == ENOTSUPP) {\n\t\tprintf(\"SKIP (program uses an unsupported feature)\\n\");\n\t\tskips++;\n\t\tgoto close_fds;\n\t}\n\n\talignment_prevented_execution = 0;\n\n\tif (expected_ret == ACCEPT || expected_ret == VERBOSE_ACCEPT) {\n\t\tif (fd_prog < 0) {\n\t\t\tprintf(\"FAIL\\nFailed to load prog '%s'!\\n\",\n\t\t\t       strerror(saved_errno));\n\t\t\tgoto fail_log;\n\t\t}\n#ifndef CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS\n\t\tif (fd_prog >= 0 &&\n\t\t    (test->flags & F_NEEDS_EFFICIENT_UNALIGNED_ACCESS))\n\t\t\talignment_prevented_execution = 1;\n#endif\n\t\tif (expected_ret == VERBOSE_ACCEPT && !cmp_str_seq(bpf_vlog, expected_err)) {\n\t\t\tgoto fail_log;\n\t\t}\n\t} else {\n\t\tif (fd_prog >= 0) {\n\t\t\tprintf(\"FAIL\\nUnexpected success to load!\\n\");\n\t\t\tgoto fail_log;\n\t\t}\n\t\tif (!expected_err || !cmp_str_seq(bpf_vlog, expected_err)) {\n\t\t\tprintf(\"FAIL\\nUnexpected error message!\\n\\tEXP: %s\\n\\tRES: %s\\n\",\n\t\t\t      expected_err, bpf_vlog);\n\t\t\tgoto fail_log;\n\t\t}\n\t}\n\n\tif (!unpriv && test->insn_processed) {\n\t\tuint32_t insn_processed;\n\t\tchar *proc;\n\n\t\tproc = strstr(bpf_vlog, \"processed \");\n\t\tinsn_processed = atoi(proc + 10);\n\t\tif (test->insn_processed != insn_processed) {\n\t\t\tprintf(\"FAIL\\nUnexpected insn_processed %u vs %u\\n\",\n\t\t\t       insn_processed, test->insn_processed);\n\t\t\tgoto fail_log;\n\t\t}\n\t}\n\n\tif (verbose)\n\t\tprintf(\", verifier log:\\n%s\", bpf_vlog);\n\n\tif (!check_xlated_program(test, fd_prog))\n\t\tgoto fail_log;\n\n\trun_errs = 0;\n\trun_successes = 0;\n\tif (!alignment_prevented_execution && fd_prog >= 0 && test->runs >= 0) {\n\t\tuint32_t expected_val;\n\t\tint i;\n\n\t\tif (!test->runs)\n\t\t\ttest->runs = 1;\n\n\t\tfor (i = 0; i < test->runs; i++) {\n\t\t\tif (unpriv && test->retvals[i].retval_unpriv)\n\t\t\t\texpected_val = test->retvals[i].retval_unpriv;\n\t\t\telse\n\t\t\t\texpected_val = test->retvals[i].retval;\n\n\t\t\terr = do_prog_test_run(fd_prog, unpriv, expected_val,\n\t\t\t\t\t       test->retvals[i].data,\n\t\t\t\t\t       sizeof(test->retvals[i].data));\n\t\t\tif (err) {\n\t\t\t\tprintf(\"(run %d/%d) \", i + 1, test->runs);\n\t\t\t\trun_errs++;\n\t\t\t} else {\n\t\t\t\trun_successes++;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!run_errs) {\n\t\t(*passes)++;\n\t\tif (run_successes > 1)\n\t\t\tprintf(\"%d cases \", run_successes);\n\t\tprintf(\"OK\");\n\t\tif (alignment_prevented_execution)\n\t\t\tprintf(\" (NOTE: not executed due to unknown alignment)\");\n\t\tprintf(\"\\n\");\n\t} else {\n\t\tprintf(\"\\n\");\n\t\tgoto fail_log;\n\t}\nclose_fds:\n\tif (test->fill_insns)\n\t\tfree(test->fill_insns);\n\tclose(fd_prog);\n\tclose(btf_fd);\n\tfor (i = 0; i < MAX_NR_MAPS; i++)\n\t\tclose(map_fds[i]);\n\tsched_yield();\n\treturn;\nfail_log:\n\t(*errors)++;\n\tprintf(\"%s\", bpf_vlog);\n\tgoto close_fds;\n}\n\nstatic bool is_admin(void)\n{\n\t__u64 caps;\n\n\t \n\tif (cap_disable_effective(1ULL << CAP_SYS_ADMIN, &caps)) {\n\t\tperror(\"cap_disable_effective(CAP_SYS_ADMIN)\");\n\t\treturn false;\n\t}\n\n\treturn (caps & ADMIN_CAPS) == ADMIN_CAPS;\n}\n\nstatic bool test_as_unpriv(struct bpf_test *test)\n{\n#ifndef CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS\n\t \n\tif (test->flags & F_NEEDS_EFFICIENT_UNALIGNED_ACCESS)\n\t\treturn false;\n#endif\n\treturn !test->prog_type ||\n\t       test->prog_type == BPF_PROG_TYPE_SOCKET_FILTER ||\n\t       test->prog_type == BPF_PROG_TYPE_CGROUP_SKB;\n}\n\nstatic int do_test(bool unpriv, unsigned int from, unsigned int to)\n{\n\tint i, passes = 0, errors = 0;\n\n\t \n\tunload_bpf_testmod(verbose);\n\n\tif (load_bpf_testmod(verbose))\n\t\treturn EXIT_FAILURE;\n\n\tfor (i = from; i < to; i++) {\n\t\tstruct bpf_test *test = &tests[i];\n\n\t\t \n\t\tif (test_as_unpriv(test) && unpriv_disabled) {\n\t\t\tprintf(\"#%d/u %s SKIP\\n\", i, test->descr);\n\t\t\tskips++;\n\t\t} else if (test_as_unpriv(test)) {\n\t\t\tif (!unpriv)\n\t\t\t\tset_admin(false);\n\t\t\tprintf(\"#%d/u %s \", i, test->descr);\n\t\t\tdo_test_single(test, true, &passes, &errors);\n\t\t\tif (!unpriv)\n\t\t\t\tset_admin(true);\n\t\t}\n\n\t\tif (unpriv) {\n\t\t\tprintf(\"#%d/p %s SKIP\\n\", i, test->descr);\n\t\t\tskips++;\n\t\t} else {\n\t\t\tprintf(\"#%d/p %s \", i, test->descr);\n\t\t\tdo_test_single(test, false, &passes, &errors);\n\t\t}\n\t}\n\n\tunload_bpf_testmod(verbose);\n\tkfuncs_cleanup();\n\n\tprintf(\"Summary: %d PASSED, %d SKIPPED, %d FAILED\\n\", passes,\n\t       skips, errors);\n\treturn errors ? EXIT_FAILURE : EXIT_SUCCESS;\n}\n\nint main(int argc, char **argv)\n{\n\tunsigned int from = 0, to = ARRAY_SIZE(tests);\n\tbool unpriv = !is_admin();\n\tint arg = 1;\n\n\tif (argc > 1 && strcmp(argv[1], \"-v\") == 0) {\n\t\targ++;\n\t\tverbose = true;\n\t\tverif_log_level = 1;\n\t\targc--;\n\t}\n\tif (argc > 1 && strcmp(argv[1], \"-vv\") == 0) {\n\t\targ++;\n\t\tverbose = true;\n\t\tverif_log_level = 2;\n\t\targc--;\n\t}\n\n\tif (argc == 3) {\n\t\tunsigned int l = atoi(argv[arg]);\n\t\tunsigned int u = atoi(argv[arg + 1]);\n\n\t\tif (l < to && u < to) {\n\t\t\tfrom = l;\n\t\t\tto   = u + 1;\n\t\t}\n\t} else if (argc == 2) {\n\t\tunsigned int t = atoi(argv[arg]);\n\n\t\tif (t < to) {\n\t\t\tfrom = t;\n\t\t\tto   = t + 1;\n\t\t}\n\t}\n\n\tunpriv_disabled = get_unpriv_disabled();\n\tif (unpriv && unpriv_disabled) {\n\t\tprintf(\"Cannot run as unprivileged user with sysctl %s.\\n\",\n\t\t       UNPRIV_SYSCTL);\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t \n\tlibbpf_set_strict_mode(LIBBPF_STRICT_ALL);\n\n\tbpf_semi_rand_init();\n\treturn do_test(unpriv, from, to);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}