{
  "module_name": "xskxceiver.c",
  "hash_id": "8a4e0c0a1b8ee256bc7b18320b22204f4e074bc80ab034d9fe4d8de09ace1af1",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/bpf/xskxceiver.c",
  "human_readable_source": "\n \n\n \n\n#define _GNU_SOURCE\n#include <assert.h>\n#include <fcntl.h>\n#include <errno.h>\n#include <getopt.h>\n#include <linux/if_link.h>\n#include <linux/if_ether.h>\n#include <linux/mman.h>\n#include <linux/netdev.h>\n#include <arpa/inet.h>\n#include <net/if.h>\n#include <locale.h>\n#include <poll.h>\n#include <pthread.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stddef.h>\n#include <sys/mman.h>\n#include <sys/socket.h>\n#include <sys/time.h>\n#include <sys/types.h>\n#include <unistd.h>\n\n#include \"xsk_xdp_progs.skel.h\"\n#include \"xsk.h\"\n#include \"xskxceiver.h\"\n#include <bpf/bpf.h>\n#include <linux/filter.h>\n#include \"../kselftest.h\"\n#include \"xsk_xdp_metadata.h\"\n\nstatic const char *MAC1 = \"\\x00\\x0A\\x56\\x9E\\xEE\\x62\";\nstatic const char *MAC2 = \"\\x00\\x0A\\x56\\x9E\\xEE\\x61\";\n\nstatic void __exit_with_error(int error, const char *file, const char *func, int line)\n{\n\tksft_test_result_fail(\"[%s:%s:%i]: ERROR: %d/\\\"%s\\\"\\n\", file, func, line, error,\n\t\t\t      strerror(error));\n\tksft_exit_xfail();\n}\n\n#define exit_with_error(error) __exit_with_error(error, __FILE__, __func__, __LINE__)\n#define busy_poll_string(test) (test)->ifobj_tx->busy_poll ? \"BUSY-POLL \" : \"\"\nstatic char *mode_string(struct test_spec *test)\n{\n\tswitch (test->mode) {\n\tcase TEST_MODE_SKB:\n\t\treturn \"SKB\";\n\tcase TEST_MODE_DRV:\n\t\treturn \"DRV\";\n\tcase TEST_MODE_ZC:\n\t\treturn \"ZC\";\n\tdefault:\n\t\treturn \"BOGUS\";\n\t}\n}\n\nstatic void report_failure(struct test_spec *test)\n{\n\tif (test->fail)\n\t\treturn;\n\n\tksft_test_result_fail(\"FAIL: %s %s%s\\n\", mode_string(test), busy_poll_string(test),\n\t\t\t      test->name);\n\ttest->fail = true;\n}\n\n \nstatic void write_payload(void *dest, u32 pkt_nb, u32 start, u32 size)\n{\n\tu32 *ptr = (u32 *)dest, i;\n\n\tstart /= sizeof(*ptr);\n\tsize /= sizeof(*ptr);\n\tfor (i = 0; i < size; i++)\n\t\tptr[i] = htonl(pkt_nb << 16 | (i + start));\n}\n\nstatic void gen_eth_hdr(struct ifobject *ifobject, struct ethhdr *eth_hdr)\n{\n\tmemcpy(eth_hdr->h_dest, ifobject->dst_mac, ETH_ALEN);\n\tmemcpy(eth_hdr->h_source, ifobject->src_mac, ETH_ALEN);\n\teth_hdr->h_proto = htons(ETH_P_LOOPBACK);\n}\n\nstatic bool is_umem_valid(struct ifobject *ifobj)\n{\n\treturn !!ifobj->umem->umem;\n}\n\nstatic u32 mode_to_xdp_flags(enum test_mode mode)\n{\n\treturn (mode == TEST_MODE_SKB) ? XDP_FLAGS_SKB_MODE : XDP_FLAGS_DRV_MODE;\n}\n\nstatic u64 umem_size(struct xsk_umem_info *umem)\n{\n\treturn umem->num_frames * umem->frame_size;\n}\n\nstatic int xsk_configure_umem(struct ifobject *ifobj, struct xsk_umem_info *umem, void *buffer,\n\t\t\t      u64 size)\n{\n\tstruct xsk_umem_config cfg = {\n\t\t.fill_size = XSK_RING_PROD__DEFAULT_NUM_DESCS,\n\t\t.comp_size = XSK_RING_CONS__DEFAULT_NUM_DESCS,\n\t\t.frame_size = umem->frame_size,\n\t\t.frame_headroom = umem->frame_headroom,\n\t\t.flags = XSK_UMEM__DEFAULT_FLAGS\n\t};\n\tint ret;\n\n\tif (umem->unaligned_mode)\n\t\tcfg.flags |= XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\n\tret = xsk_umem__create(&umem->umem, buffer, size,\n\t\t\t       &umem->fq, &umem->cq, &cfg);\n\tif (ret)\n\t\treturn ret;\n\n\tumem->buffer = buffer;\n\tif (ifobj->shared_umem && ifobj->rx_on) {\n\t\tumem->base_addr = umem_size(umem);\n\t\tumem->next_buffer = umem_size(umem);\n\t}\n\n\treturn 0;\n}\n\nstatic u64 umem_alloc_buffer(struct xsk_umem_info *umem)\n{\n\tu64 addr;\n\n\taddr = umem->next_buffer;\n\tumem->next_buffer += umem->frame_size;\n\tif (umem->next_buffer >= umem->base_addr + umem_size(umem))\n\t\tumem->next_buffer = umem->base_addr;\n\n\treturn addr;\n}\n\nstatic void umem_reset_alloc(struct xsk_umem_info *umem)\n{\n\tumem->next_buffer = 0;\n}\n\nstatic void enable_busy_poll(struct xsk_socket_info *xsk)\n{\n\tint sock_opt;\n\n\tsock_opt = 1;\n\tif (setsockopt(xsk_socket__fd(xsk->xsk), SOL_SOCKET, SO_PREFER_BUSY_POLL,\n\t\t       (void *)&sock_opt, sizeof(sock_opt)) < 0)\n\t\texit_with_error(errno);\n\n\tsock_opt = 20;\n\tif (setsockopt(xsk_socket__fd(xsk->xsk), SOL_SOCKET, SO_BUSY_POLL,\n\t\t       (void *)&sock_opt, sizeof(sock_opt)) < 0)\n\t\texit_with_error(errno);\n\n\tsock_opt = BATCH_SIZE;\n\tif (setsockopt(xsk_socket__fd(xsk->xsk), SOL_SOCKET, SO_BUSY_POLL_BUDGET,\n\t\t       (void *)&sock_opt, sizeof(sock_opt)) < 0)\n\t\texit_with_error(errno);\n}\n\nstatic int __xsk_configure_socket(struct xsk_socket_info *xsk, struct xsk_umem_info *umem,\n\t\t\t\t  struct ifobject *ifobject, bool shared)\n{\n\tstruct xsk_socket_config cfg = {};\n\tstruct xsk_ring_cons *rxr;\n\tstruct xsk_ring_prod *txr;\n\n\txsk->umem = umem;\n\tcfg.rx_size = xsk->rxqsize;\n\tcfg.tx_size = XSK_RING_PROD__DEFAULT_NUM_DESCS;\n\tcfg.bind_flags = ifobject->bind_flags;\n\tif (shared)\n\t\tcfg.bind_flags |= XDP_SHARED_UMEM;\n\tif (ifobject->pkt_stream && ifobject->mtu > MAX_ETH_PKT_SIZE)\n\t\tcfg.bind_flags |= XDP_USE_SG;\n\n\ttxr = ifobject->tx_on ? &xsk->tx : NULL;\n\trxr = ifobject->rx_on ? &xsk->rx : NULL;\n\treturn xsk_socket__create(&xsk->xsk, ifobject->ifindex, 0, umem->umem, rxr, txr, &cfg);\n}\n\nstatic bool ifobj_zc_avail(struct ifobject *ifobject)\n{\n\tsize_t umem_sz = DEFAULT_UMEM_BUFFERS * XSK_UMEM__DEFAULT_FRAME_SIZE;\n\tint mmap_flags = MAP_PRIVATE | MAP_ANONYMOUS | MAP_NORESERVE;\n\tstruct xsk_socket_info *xsk;\n\tstruct xsk_umem_info *umem;\n\tbool zc_avail = false;\n\tvoid *bufs;\n\tint ret;\n\n\tbufs = mmap(NULL, umem_sz, PROT_READ | PROT_WRITE, mmap_flags, -1, 0);\n\tif (bufs == MAP_FAILED)\n\t\texit_with_error(errno);\n\n\tumem = calloc(1, sizeof(struct xsk_umem_info));\n\tif (!umem) {\n\t\tmunmap(bufs, umem_sz);\n\t\texit_with_error(ENOMEM);\n\t}\n\tumem->frame_size = XSK_UMEM__DEFAULT_FRAME_SIZE;\n\tret = xsk_configure_umem(ifobject, umem, bufs, umem_sz);\n\tif (ret)\n\t\texit_with_error(-ret);\n\n\txsk = calloc(1, sizeof(struct xsk_socket_info));\n\tif (!xsk)\n\t\tgoto out;\n\tifobject->bind_flags = XDP_USE_NEED_WAKEUP | XDP_ZEROCOPY;\n\tifobject->rx_on = true;\n\txsk->rxqsize = XSK_RING_CONS__DEFAULT_NUM_DESCS;\n\tret = __xsk_configure_socket(xsk, umem, ifobject, false);\n\tif (!ret)\n\t\tzc_avail = true;\n\n\txsk_socket__delete(xsk->xsk);\n\tfree(xsk);\nout:\n\tmunmap(umem->buffer, umem_sz);\n\txsk_umem__delete(umem->umem);\n\tfree(umem);\n\treturn zc_avail;\n}\n\nstatic struct option long_options[] = {\n\t{\"interface\", required_argument, 0, 'i'},\n\t{\"busy-poll\", no_argument, 0, 'b'},\n\t{\"verbose\", no_argument, 0, 'v'},\n\t{0, 0, 0, 0}\n};\n\nstatic void usage(const char *prog)\n{\n\tconst char *str =\n\t\t\"  Usage: %s [OPTIONS]\\n\"\n\t\t\"  Options:\\n\"\n\t\t\"  -i, --interface      Use interface\\n\"\n\t\t\"  -v, --verbose        Verbose output\\n\"\n\t\t\"  -b, --busy-poll      Enable busy poll\\n\";\n\n\tksft_print_msg(str, prog);\n}\n\nstatic bool validate_interface(struct ifobject *ifobj)\n{\n\tif (!strcmp(ifobj->ifname, \"\"))\n\t\treturn false;\n\treturn true;\n}\n\nstatic void parse_command_line(struct ifobject *ifobj_tx, struct ifobject *ifobj_rx, int argc,\n\t\t\t       char **argv)\n{\n\tstruct ifobject *ifobj;\n\tu32 interface_nb = 0;\n\tint option_index, c;\n\n\topterr = 0;\n\n\tfor (;;) {\n\t\tc = getopt_long(argc, argv, \"i:vb\", long_options, &option_index);\n\t\tif (c == -1)\n\t\t\tbreak;\n\n\t\tswitch (c) {\n\t\tcase 'i':\n\t\t\tif (interface_nb == 0)\n\t\t\t\tifobj = ifobj_tx;\n\t\t\telse if (interface_nb == 1)\n\t\t\t\tifobj = ifobj_rx;\n\t\t\telse\n\t\t\t\tbreak;\n\n\t\t\tmemcpy(ifobj->ifname, optarg,\n\t\t\t       min_t(size_t, MAX_INTERFACE_NAME_CHARS, strlen(optarg)));\n\n\t\t\tifobj->ifindex = if_nametoindex(ifobj->ifname);\n\t\t\tif (!ifobj->ifindex)\n\t\t\t\texit_with_error(errno);\n\n\t\t\tinterface_nb++;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\topt_verbose = true;\n\t\t\tbreak;\n\t\tcase 'b':\n\t\t\tifobj_tx->busy_poll = true;\n\t\t\tifobj_rx->busy_poll = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusage(basename(argv[0]));\n\t\t\tksft_exit_xfail();\n\t\t}\n\t}\n}\n\nstatic void __test_spec_init(struct test_spec *test, struct ifobject *ifobj_tx,\n\t\t\t     struct ifobject *ifobj_rx)\n{\n\tu32 i, j;\n\n\tfor (i = 0; i < MAX_INTERFACES; i++) {\n\t\tstruct ifobject *ifobj = i ? ifobj_rx : ifobj_tx;\n\n\t\tifobj->xsk = &ifobj->xsk_arr[0];\n\t\tifobj->use_poll = false;\n\t\tifobj->use_fill_ring = true;\n\t\tifobj->release_rx = true;\n\t\tifobj->validation_func = NULL;\n\t\tifobj->use_metadata = false;\n\n\t\tif (i == 0) {\n\t\t\tifobj->rx_on = false;\n\t\t\tifobj->tx_on = true;\n\t\t\tifobj->pkt_stream = test->tx_pkt_stream_default;\n\t\t} else {\n\t\t\tifobj->rx_on = true;\n\t\t\tifobj->tx_on = false;\n\t\t\tifobj->pkt_stream = test->rx_pkt_stream_default;\n\t\t}\n\n\t\tmemset(ifobj->umem, 0, sizeof(*ifobj->umem));\n\t\tifobj->umem->num_frames = DEFAULT_UMEM_BUFFERS;\n\t\tifobj->umem->frame_size = XSK_UMEM__DEFAULT_FRAME_SIZE;\n\n\t\tfor (j = 0; j < MAX_SOCKETS; j++) {\n\t\t\tmemset(&ifobj->xsk_arr[j], 0, sizeof(ifobj->xsk_arr[j]));\n\t\t\tifobj->xsk_arr[j].rxqsize = XSK_RING_CONS__DEFAULT_NUM_DESCS;\n\t\t}\n\t}\n\n\ttest->ifobj_tx = ifobj_tx;\n\ttest->ifobj_rx = ifobj_rx;\n\ttest->current_step = 0;\n\ttest->total_steps = 1;\n\ttest->nb_sockets = 1;\n\ttest->fail = false;\n\ttest->mtu = MAX_ETH_PKT_SIZE;\n\ttest->xdp_prog_rx = ifobj_rx->xdp_progs->progs.xsk_def_prog;\n\ttest->xskmap_rx = ifobj_rx->xdp_progs->maps.xsk;\n\ttest->xdp_prog_tx = ifobj_tx->xdp_progs->progs.xsk_def_prog;\n\ttest->xskmap_tx = ifobj_tx->xdp_progs->maps.xsk;\n}\n\nstatic void test_spec_init(struct test_spec *test, struct ifobject *ifobj_tx,\n\t\t\t   struct ifobject *ifobj_rx, enum test_mode mode)\n{\n\tstruct pkt_stream *tx_pkt_stream;\n\tstruct pkt_stream *rx_pkt_stream;\n\tu32 i;\n\n\ttx_pkt_stream = test->tx_pkt_stream_default;\n\trx_pkt_stream = test->rx_pkt_stream_default;\n\tmemset(test, 0, sizeof(*test));\n\ttest->tx_pkt_stream_default = tx_pkt_stream;\n\ttest->rx_pkt_stream_default = rx_pkt_stream;\n\n\tfor (i = 0; i < MAX_INTERFACES; i++) {\n\t\tstruct ifobject *ifobj = i ? ifobj_rx : ifobj_tx;\n\n\t\tifobj->bind_flags = XDP_USE_NEED_WAKEUP;\n\t\tif (mode == TEST_MODE_ZC)\n\t\t\tifobj->bind_flags |= XDP_ZEROCOPY;\n\t\telse\n\t\t\tifobj->bind_flags |= XDP_COPY;\n\t}\n\n\ttest->mode = mode;\n\t__test_spec_init(test, ifobj_tx, ifobj_rx);\n}\n\nstatic void test_spec_reset(struct test_spec *test)\n{\n\t__test_spec_init(test, test->ifobj_tx, test->ifobj_rx);\n}\n\nstatic void test_spec_set_name(struct test_spec *test, const char *name)\n{\n\tstrncpy(test->name, name, MAX_TEST_NAME_SIZE);\n}\n\nstatic void test_spec_set_xdp_prog(struct test_spec *test, struct bpf_program *xdp_prog_rx,\n\t\t\t\t   struct bpf_program *xdp_prog_tx, struct bpf_map *xskmap_rx,\n\t\t\t\t   struct bpf_map *xskmap_tx)\n{\n\ttest->xdp_prog_rx = xdp_prog_rx;\n\ttest->xdp_prog_tx = xdp_prog_tx;\n\ttest->xskmap_rx = xskmap_rx;\n\ttest->xskmap_tx = xskmap_tx;\n}\n\nstatic int test_spec_set_mtu(struct test_spec *test, int mtu)\n{\n\tint err;\n\n\tif (test->ifobj_rx->mtu != mtu) {\n\t\terr = xsk_set_mtu(test->ifobj_rx->ifindex, mtu);\n\t\tif (err)\n\t\t\treturn err;\n\t\ttest->ifobj_rx->mtu = mtu;\n\t}\n\tif (test->ifobj_tx->mtu != mtu) {\n\t\terr = xsk_set_mtu(test->ifobj_tx->ifindex, mtu);\n\t\tif (err)\n\t\t\treturn err;\n\t\ttest->ifobj_tx->mtu = mtu;\n\t}\n\n\treturn 0;\n}\n\nstatic void pkt_stream_reset(struct pkt_stream *pkt_stream)\n{\n\tif (pkt_stream)\n\t\tpkt_stream->current_pkt_nb = 0;\n}\n\nstatic struct pkt *pkt_stream_get_next_tx_pkt(struct pkt_stream *pkt_stream)\n{\n\tif (pkt_stream->current_pkt_nb >= pkt_stream->nb_pkts)\n\t\treturn NULL;\n\n\treturn &pkt_stream->pkts[pkt_stream->current_pkt_nb++];\n}\n\nstatic struct pkt *pkt_stream_get_next_rx_pkt(struct pkt_stream *pkt_stream, u32 *pkts_sent)\n{\n\twhile (pkt_stream->current_pkt_nb < pkt_stream->nb_pkts) {\n\t\t(*pkts_sent)++;\n\t\tif (pkt_stream->pkts[pkt_stream->current_pkt_nb].valid)\n\t\t\treturn &pkt_stream->pkts[pkt_stream->current_pkt_nb++];\n\t\tpkt_stream->current_pkt_nb++;\n\t}\n\treturn NULL;\n}\n\nstatic void pkt_stream_delete(struct pkt_stream *pkt_stream)\n{\n\tfree(pkt_stream->pkts);\n\tfree(pkt_stream);\n}\n\nstatic void pkt_stream_restore_default(struct test_spec *test)\n{\n\tstruct pkt_stream *tx_pkt_stream = test->ifobj_tx->pkt_stream;\n\tstruct pkt_stream *rx_pkt_stream = test->ifobj_rx->pkt_stream;\n\n\tif (tx_pkt_stream != test->tx_pkt_stream_default) {\n\t\tpkt_stream_delete(test->ifobj_tx->pkt_stream);\n\t\ttest->ifobj_tx->pkt_stream = test->tx_pkt_stream_default;\n\t}\n\n\tif (rx_pkt_stream != test->rx_pkt_stream_default) {\n\t\tpkt_stream_delete(test->ifobj_rx->pkt_stream);\n\t\ttest->ifobj_rx->pkt_stream = test->rx_pkt_stream_default;\n\t}\n}\n\nstatic struct pkt_stream *__pkt_stream_alloc(u32 nb_pkts)\n{\n\tstruct pkt_stream *pkt_stream;\n\n\tpkt_stream = calloc(1, sizeof(*pkt_stream));\n\tif (!pkt_stream)\n\t\treturn NULL;\n\n\tpkt_stream->pkts = calloc(nb_pkts, sizeof(*pkt_stream->pkts));\n\tif (!pkt_stream->pkts) {\n\t\tfree(pkt_stream);\n\t\treturn NULL;\n\t}\n\n\tpkt_stream->nb_pkts = nb_pkts;\n\treturn pkt_stream;\n}\n\nstatic bool pkt_continues(u32 options)\n{\n\treturn options & XDP_PKT_CONTD;\n}\n\nstatic u32 ceil_u32(u32 a, u32 b)\n{\n\treturn (a + b - 1) / b;\n}\n\nstatic u32 pkt_nb_frags(u32 frame_size, struct pkt_stream *pkt_stream, struct pkt *pkt)\n{\n\tu32 nb_frags = 1, next_frag;\n\n\tif (!pkt)\n\t\treturn 1;\n\n\tif (!pkt_stream->verbatim) {\n\t\tif (!pkt->valid || !pkt->len)\n\t\t\treturn 1;\n\t\treturn ceil_u32(pkt->len, frame_size);\n\t}\n\n\t \n\tif (!pkt_continues(pkt->options))\n\t\treturn nb_frags;\n\n\tnext_frag = pkt_stream->current_pkt_nb;\n\tpkt++;\n\twhile (next_frag++ < pkt_stream->nb_pkts) {\n\t\tnb_frags++;\n\t\tif (!pkt_continues(pkt->options) || !pkt->valid)\n\t\t\tbreak;\n\t\tpkt++;\n\t}\n\treturn nb_frags;\n}\n\nstatic void pkt_set(struct xsk_umem_info *umem, struct pkt *pkt, int offset, u32 len)\n{\n\tpkt->offset = offset;\n\tpkt->len = len;\n\tif (len > MAX_ETH_JUMBO_SIZE)\n\t\tpkt->valid = false;\n\telse\n\t\tpkt->valid = true;\n}\n\nstatic u32 pkt_get_buffer_len(struct xsk_umem_info *umem, u32 len)\n{\n\treturn ceil_u32(len, umem->frame_size) * umem->frame_size;\n}\n\nstatic struct pkt_stream *pkt_stream_generate(struct xsk_umem_info *umem, u32 nb_pkts, u32 pkt_len)\n{\n\tstruct pkt_stream *pkt_stream;\n\tu32 i;\n\n\tpkt_stream = __pkt_stream_alloc(nb_pkts);\n\tif (!pkt_stream)\n\t\texit_with_error(ENOMEM);\n\n\tpkt_stream->nb_pkts = nb_pkts;\n\tpkt_stream->max_pkt_len = pkt_len;\n\tfor (i = 0; i < nb_pkts; i++) {\n\t\tstruct pkt *pkt = &pkt_stream->pkts[i];\n\n\t\tpkt_set(umem, pkt, 0, pkt_len);\n\t\tpkt->pkt_nb = i;\n\t}\n\n\treturn pkt_stream;\n}\n\nstatic struct pkt_stream *pkt_stream_clone(struct xsk_umem_info *umem,\n\t\t\t\t\t   struct pkt_stream *pkt_stream)\n{\n\treturn pkt_stream_generate(umem, pkt_stream->nb_pkts, pkt_stream->pkts[0].len);\n}\n\nstatic void pkt_stream_replace(struct test_spec *test, u32 nb_pkts, u32 pkt_len)\n{\n\tstruct pkt_stream *pkt_stream;\n\n\tpkt_stream = pkt_stream_generate(test->ifobj_tx->umem, nb_pkts, pkt_len);\n\ttest->ifobj_tx->pkt_stream = pkt_stream;\n\tpkt_stream = pkt_stream_generate(test->ifobj_rx->umem, nb_pkts, pkt_len);\n\ttest->ifobj_rx->pkt_stream = pkt_stream;\n}\n\nstatic void __pkt_stream_replace_half(struct ifobject *ifobj, u32 pkt_len,\n\t\t\t\t      int offset)\n{\n\tstruct xsk_umem_info *umem = ifobj->umem;\n\tstruct pkt_stream *pkt_stream;\n\tu32 i;\n\n\tpkt_stream = pkt_stream_clone(umem, ifobj->pkt_stream);\n\tfor (i = 1; i < ifobj->pkt_stream->nb_pkts; i += 2)\n\t\tpkt_set(umem, &pkt_stream->pkts[i], offset, pkt_len);\n\n\tifobj->pkt_stream = pkt_stream;\n}\n\nstatic void pkt_stream_replace_half(struct test_spec *test, u32 pkt_len, int offset)\n{\n\t__pkt_stream_replace_half(test->ifobj_tx, pkt_len, offset);\n\t__pkt_stream_replace_half(test->ifobj_rx, pkt_len, offset);\n}\n\nstatic void pkt_stream_receive_half(struct test_spec *test)\n{\n\tstruct xsk_umem_info *umem = test->ifobj_rx->umem;\n\tstruct pkt_stream *pkt_stream = test->ifobj_tx->pkt_stream;\n\tu32 i;\n\n\ttest->ifobj_rx->pkt_stream = pkt_stream_generate(umem, pkt_stream->nb_pkts,\n\t\t\t\t\t\t\t pkt_stream->pkts[0].len);\n\tpkt_stream = test->ifobj_rx->pkt_stream;\n\tfor (i = 1; i < pkt_stream->nb_pkts; i += 2)\n\t\tpkt_stream->pkts[i].valid = false;\n}\n\nstatic u64 pkt_get_addr(struct pkt *pkt, struct xsk_umem_info *umem)\n{\n\tif (!pkt->valid)\n\t\treturn pkt->offset;\n\treturn pkt->offset + umem_alloc_buffer(umem);\n}\n\nstatic void pkt_stream_cancel(struct pkt_stream *pkt_stream)\n{\n\tpkt_stream->current_pkt_nb--;\n}\n\nstatic void pkt_generate(struct ifobject *ifobject, u64 addr, u32 len, u32 pkt_nb,\n\t\t\t u32 bytes_written)\n{\n\tvoid *data = xsk_umem__get_data(ifobject->umem->buffer, addr);\n\n\tif (len < MIN_PKT_SIZE)\n\t\treturn;\n\n\tif (!bytes_written) {\n\t\tgen_eth_hdr(ifobject, data);\n\n\t\tlen -= PKT_HDR_SIZE;\n\t\tdata += PKT_HDR_SIZE;\n\t} else {\n\t\tbytes_written -= PKT_HDR_SIZE;\n\t}\n\n\twrite_payload(data, pkt_nb, bytes_written, len);\n}\n\nstatic struct pkt_stream *__pkt_stream_generate_custom(struct ifobject *ifobj, struct pkt *frames,\n\t\t\t\t\t\t       u32 nb_frames, bool verbatim)\n{\n\tu32 i, len = 0, pkt_nb = 0, payload = 0;\n\tstruct pkt_stream *pkt_stream;\n\n\tpkt_stream = __pkt_stream_alloc(nb_frames);\n\tif (!pkt_stream)\n\t\texit_with_error(ENOMEM);\n\n\tfor (i = 0; i < nb_frames; i++) {\n\t\tstruct pkt *pkt = &pkt_stream->pkts[pkt_nb];\n\t\tstruct pkt *frame = &frames[i];\n\n\t\tpkt->offset = frame->offset;\n\t\tif (verbatim) {\n\t\t\t*pkt = *frame;\n\t\t\tpkt->pkt_nb = payload;\n\t\t\tif (!frame->valid || !pkt_continues(frame->options))\n\t\t\t\tpayload++;\n\t\t} else {\n\t\t\tif (frame->valid)\n\t\t\t\tlen += frame->len;\n\t\t\tif (frame->valid && pkt_continues(frame->options))\n\t\t\t\tcontinue;\n\n\t\t\tpkt->pkt_nb = pkt_nb;\n\t\t\tpkt->len = len;\n\t\t\tpkt->valid = frame->valid;\n\t\t\tpkt->options = 0;\n\n\t\t\tlen = 0;\n\t\t}\n\n\t\tif (pkt->valid && pkt->len > pkt_stream->max_pkt_len)\n\t\t\tpkt_stream->max_pkt_len = pkt->len;\n\t\tpkt_nb++;\n\t}\n\n\tpkt_stream->nb_pkts = pkt_nb;\n\tpkt_stream->verbatim = verbatim;\n\treturn pkt_stream;\n}\n\nstatic void pkt_stream_generate_custom(struct test_spec *test, struct pkt *pkts, u32 nb_pkts)\n{\n\tstruct pkt_stream *pkt_stream;\n\n\tpkt_stream = __pkt_stream_generate_custom(test->ifobj_tx, pkts, nb_pkts, true);\n\ttest->ifobj_tx->pkt_stream = pkt_stream;\n\n\tpkt_stream = __pkt_stream_generate_custom(test->ifobj_rx, pkts, nb_pkts, false);\n\ttest->ifobj_rx->pkt_stream = pkt_stream;\n}\n\nstatic void pkt_print_data(u32 *data, u32 cnt)\n{\n\tu32 i;\n\n\tfor (i = 0; i < cnt; i++) {\n\t\tu32 seqnum, pkt_nb;\n\n\t\tseqnum = ntohl(*data) & 0xffff;\n\t\tpkt_nb = ntohl(*data) >> 16;\n\t\tfprintf(stdout, \"%u:%u \", pkt_nb, seqnum);\n\t\tdata++;\n\t}\n}\n\nstatic void pkt_dump(void *pkt, u32 len, bool eth_header)\n{\n\tstruct ethhdr *ethhdr = pkt;\n\tu32 i, *data;\n\n\tif (eth_header) {\n\t\t \n\t\tfprintf(stdout, \"DEBUG>> L2: dst mac: \");\n\t\tfor (i = 0; i < ETH_ALEN; i++)\n\t\t\tfprintf(stdout, \"%02X\", ethhdr->h_dest[i]);\n\n\t\tfprintf(stdout, \"\\nDEBUG>> L2: src mac: \");\n\t\tfor (i = 0; i < ETH_ALEN; i++)\n\t\t\tfprintf(stdout, \"%02X\", ethhdr->h_source[i]);\n\n\t\tdata = pkt + PKT_HDR_SIZE;\n\t} else {\n\t\tdata = pkt;\n\t}\n\n\t \n\tfprintf(stdout, \"\\nDEBUG>> L5: seqnum: \");\n\tpkt_print_data(data, PKT_DUMP_NB_TO_PRINT);\n\tfprintf(stdout, \"....\");\n\tif (len > PKT_DUMP_NB_TO_PRINT * sizeof(u32)) {\n\t\tfprintf(stdout, \"\\n.... \");\n\t\tpkt_print_data(data + len / sizeof(u32) - PKT_DUMP_NB_TO_PRINT,\n\t\t\t       PKT_DUMP_NB_TO_PRINT);\n\t}\n\tfprintf(stdout, \"\\n---------------------------------------\\n\");\n}\n\nstatic bool is_offset_correct(struct xsk_umem_info *umem, struct pkt *pkt, u64 addr)\n{\n\tu32 headroom = umem->unaligned_mode ? 0 : umem->frame_headroom;\n\tu32 offset = addr % umem->frame_size, expected_offset;\n\tint pkt_offset = pkt->valid ? pkt->offset : 0;\n\n\tif (!umem->unaligned_mode)\n\t\tpkt_offset = 0;\n\n\texpected_offset = (pkt_offset + headroom + XDP_PACKET_HEADROOM) % umem->frame_size;\n\n\tif (offset == expected_offset)\n\t\treturn true;\n\n\tksft_print_msg(\"[%s] expected [%u], got [%u]\\n\", __func__, expected_offset, offset);\n\treturn false;\n}\n\nstatic bool is_metadata_correct(struct pkt *pkt, void *buffer, u64 addr)\n{\n\tvoid *data = xsk_umem__get_data(buffer, addr);\n\tstruct xdp_info *meta = data - sizeof(struct xdp_info);\n\n\tif (meta->count != pkt->pkt_nb) {\n\t\tksft_print_msg(\"[%s] expected meta_count [%d], got meta_count [%d]\\n\",\n\t\t\t       __func__, pkt->pkt_nb, meta->count);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool is_frag_valid(struct xsk_umem_info *umem, u64 addr, u32 len, u32 expected_pkt_nb,\n\t\t\t  u32 bytes_processed)\n{\n\tu32 seqnum, pkt_nb, *pkt_data, words_to_end, expected_seqnum;\n\tvoid *data = xsk_umem__get_data(umem->buffer, addr);\n\n\taddr -= umem->base_addr;\n\n\tif (addr >= umem->num_frames * umem->frame_size ||\n\t    addr + len > umem->num_frames * umem->frame_size) {\n\t\tksft_print_msg(\"Frag invalid addr: %llx len: %u\\n\", addr, len);\n\t\treturn false;\n\t}\n\tif (!umem->unaligned_mode && addr % umem->frame_size + len > umem->frame_size) {\n\t\tksft_print_msg(\"Frag crosses frame boundary addr: %llx len: %u\\n\", addr, len);\n\t\treturn false;\n\t}\n\n\tpkt_data = data;\n\tif (!bytes_processed) {\n\t\tpkt_data += PKT_HDR_SIZE / sizeof(*pkt_data);\n\t\tlen -= PKT_HDR_SIZE;\n\t} else {\n\t\tbytes_processed -= PKT_HDR_SIZE;\n\t}\n\n\texpected_seqnum = bytes_processed / sizeof(*pkt_data);\n\tseqnum = ntohl(*pkt_data) & 0xffff;\n\tpkt_nb = ntohl(*pkt_data) >> 16;\n\n\tif (expected_pkt_nb != pkt_nb) {\n\t\tksft_print_msg(\"[%s] expected pkt_nb [%u], got pkt_nb [%u]\\n\",\n\t\t\t       __func__, expected_pkt_nb, pkt_nb);\n\t\tgoto error;\n\t}\n\tif (expected_seqnum != seqnum) {\n\t\tksft_print_msg(\"[%s] expected seqnum at start [%u], got seqnum [%u]\\n\",\n\t\t\t       __func__, expected_seqnum, seqnum);\n\t\tgoto error;\n\t}\n\n\twords_to_end = len / sizeof(*pkt_data) - 1;\n\tpkt_data += words_to_end;\n\tseqnum = ntohl(*pkt_data) & 0xffff;\n\texpected_seqnum += words_to_end;\n\tif (expected_seqnum != seqnum) {\n\t\tksft_print_msg(\"[%s] expected seqnum at end [%u], got seqnum [%u]\\n\",\n\t\t\t       __func__, expected_seqnum, seqnum);\n\t\tgoto error;\n\t}\n\n\treturn true;\n\nerror:\n\tpkt_dump(data, len, !bytes_processed);\n\treturn false;\n}\n\nstatic bool is_pkt_valid(struct pkt *pkt, void *buffer, u64 addr, u32 len)\n{\n\tif (pkt->len != len) {\n\t\tksft_print_msg(\"[%s] expected packet length [%d], got length [%d]\\n\",\n\t\t\t       __func__, pkt->len, len);\n\t\tpkt_dump(xsk_umem__get_data(buffer, addr), len, true);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void kick_tx(struct xsk_socket_info *xsk)\n{\n\tint ret;\n\n\tret = sendto(xsk_socket__fd(xsk->xsk), NULL, 0, MSG_DONTWAIT, NULL, 0);\n\tif (ret >= 0)\n\t\treturn;\n\tif (errno == ENOBUFS || errno == EAGAIN || errno == EBUSY || errno == ENETDOWN) {\n\t\tusleep(100);\n\t\treturn;\n\t}\n\texit_with_error(errno);\n}\n\nstatic void kick_rx(struct xsk_socket_info *xsk)\n{\n\tint ret;\n\n\tret = recvfrom(xsk_socket__fd(xsk->xsk), NULL, 0, MSG_DONTWAIT, NULL, NULL);\n\tif (ret < 0)\n\t\texit_with_error(errno);\n}\n\nstatic int complete_pkts(struct xsk_socket_info *xsk, int batch_size)\n{\n\tunsigned int rcvd;\n\tu32 idx;\n\n\tif (xsk_ring_prod__needs_wakeup(&xsk->tx))\n\t\tkick_tx(xsk);\n\n\trcvd = xsk_ring_cons__peek(&xsk->umem->cq, batch_size, &idx);\n\tif (rcvd) {\n\t\tif (rcvd > xsk->outstanding_tx) {\n\t\t\tu64 addr = *xsk_ring_cons__comp_addr(&xsk->umem->cq, idx + rcvd - 1);\n\n\t\t\tksft_print_msg(\"[%s] Too many packets completed\\n\", __func__);\n\t\t\tksft_print_msg(\"Last completion address: %llx\\n\", addr);\n\t\t\treturn TEST_FAILURE;\n\t\t}\n\n\t\txsk_ring_cons__release(&xsk->umem->cq, rcvd);\n\t\txsk->outstanding_tx -= rcvd;\n\t}\n\n\treturn TEST_PASS;\n}\n\nstatic int receive_pkts(struct test_spec *test, struct pollfd *fds)\n{\n\tstruct timeval tv_end, tv_now, tv_timeout = {THREAD_TMOUT, 0};\n\tstruct pkt_stream *pkt_stream = test->ifobj_rx->pkt_stream;\n\tstruct xsk_socket_info *xsk = test->ifobj_rx->xsk;\n\tu32 idx_rx = 0, idx_fq = 0, rcvd, pkts_sent = 0;\n\tstruct ifobject *ifobj = test->ifobj_rx;\n\tstruct xsk_umem_info *umem = xsk->umem;\n\tstruct pkt *pkt;\n\tint ret;\n\n\tret = gettimeofday(&tv_now, NULL);\n\tif (ret)\n\t\texit_with_error(errno);\n\ttimeradd(&tv_now, &tv_timeout, &tv_end);\n\n\tpkt = pkt_stream_get_next_rx_pkt(pkt_stream, &pkts_sent);\n\twhile (pkt) {\n\t\tu32 frags_processed = 0, nb_frags = 0, pkt_len = 0;\n\t\tu64 first_addr;\n\n\t\tret = gettimeofday(&tv_now, NULL);\n\t\tif (ret)\n\t\t\texit_with_error(errno);\n\t\tif (timercmp(&tv_now, &tv_end, >)) {\n\t\t\tksft_print_msg(\"ERROR: [%s] Receive loop timed out\\n\", __func__);\n\t\t\treturn TEST_FAILURE;\n\t\t}\n\n\t\tkick_rx(xsk);\n\t\tif (ifobj->use_poll) {\n\t\t\tret = poll(fds, 1, POLL_TMOUT);\n\t\t\tif (ret < 0)\n\t\t\t\texit_with_error(errno);\n\n\t\t\tif (!ret) {\n\t\t\t\tif (!is_umem_valid(test->ifobj_tx))\n\t\t\t\t\treturn TEST_PASS;\n\n\t\t\t\tksft_print_msg(\"ERROR: [%s] Poll timed out\\n\", __func__);\n\t\t\t\treturn TEST_FAILURE;\n\t\t\t}\n\n\t\t\tif (!(fds->revents & POLLIN))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\trcvd = xsk_ring_cons__peek(&xsk->rx, BATCH_SIZE, &idx_rx);\n\t\tif (!rcvd)\n\t\t\tcontinue;\n\n\t\tif (ifobj->use_fill_ring) {\n\t\t\tret = xsk_ring_prod__reserve(&umem->fq, rcvd, &idx_fq);\n\t\t\twhile (ret != rcvd) {\n\t\t\t\tif (ret < 0)\n\t\t\t\t\texit_with_error(-ret);\n\t\t\t\tif (xsk_ring_prod__needs_wakeup(&umem->fq)) {\n\t\t\t\t\tret = poll(fds, 1, POLL_TMOUT);\n\t\t\t\t\tif (ret < 0)\n\t\t\t\t\t\texit_with_error(errno);\n\t\t\t\t}\n\t\t\t\tret = xsk_ring_prod__reserve(&umem->fq, rcvd, &idx_fq);\n\t\t\t}\n\t\t}\n\n\t\twhile (frags_processed < rcvd) {\n\t\t\tconst struct xdp_desc *desc = xsk_ring_cons__rx_desc(&xsk->rx, idx_rx++);\n\t\t\tu64 addr = desc->addr, orig;\n\n\t\t\torig = xsk_umem__extract_addr(addr);\n\t\t\taddr = xsk_umem__add_offset_to_addr(addr);\n\n\t\t\tif (!pkt) {\n\t\t\t\tksft_print_msg(\"[%s] received too many packets addr: %lx len %u\\n\",\n\t\t\t\t\t       __func__, addr, desc->len);\n\t\t\t\treturn TEST_FAILURE;\n\t\t\t}\n\n\t\t\tif (!is_frag_valid(umem, addr, desc->len, pkt->pkt_nb, pkt_len) ||\n\t\t\t    !is_offset_correct(umem, pkt, addr) ||\n\t\t\t    (ifobj->use_metadata && !is_metadata_correct(pkt, umem->buffer, addr)))\n\t\t\t\treturn TEST_FAILURE;\n\n\t\t\tif (!nb_frags++)\n\t\t\t\tfirst_addr = addr;\n\t\t\tfrags_processed++;\n\t\t\tpkt_len += desc->len;\n\t\t\tif (ifobj->use_fill_ring)\n\t\t\t\t*xsk_ring_prod__fill_addr(&umem->fq, idx_fq++) = orig;\n\n\t\t\tif (pkt_continues(desc->options))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (!is_pkt_valid(pkt, umem->buffer, first_addr, pkt_len) ||\n\t\t\t    !is_offset_correct(umem, pkt, addr))\n\t\t\t\treturn TEST_FAILURE;\n\n\t\t\tpkt = pkt_stream_get_next_rx_pkt(pkt_stream, &pkts_sent);\n\t\t\tnb_frags = 0;\n\t\t\tpkt_len = 0;\n\t\t}\n\n\t\tif (nb_frags) {\n\t\t\t \n\t\t\tidx_rx -= nb_frags;\n\t\t\txsk_ring_cons__cancel(&xsk->rx, nb_frags);\n\t\t\tif (ifobj->use_fill_ring) {\n\t\t\t\tidx_fq -= nb_frags;\n\t\t\t\txsk_ring_prod__cancel(&umem->fq, nb_frags);\n\t\t\t}\n\t\t\tfrags_processed -= nb_frags;\n\t\t}\n\n\t\tif (ifobj->use_fill_ring)\n\t\t\txsk_ring_prod__submit(&umem->fq, frags_processed);\n\t\tif (ifobj->release_rx)\n\t\t\txsk_ring_cons__release(&xsk->rx, frags_processed);\n\n\t\tpthread_mutex_lock(&pacing_mutex);\n\t\tpkts_in_flight -= pkts_sent;\n\t\tpthread_mutex_unlock(&pacing_mutex);\n\t\tpkts_sent = 0;\n\t}\n\n\treturn TEST_PASS;\n}\n\nstatic int __send_pkts(struct ifobject *ifobject, struct pollfd *fds, bool timeout)\n{\n\tu32 i, idx = 0, valid_pkts = 0, valid_frags = 0, buffer_len;\n\tstruct pkt_stream *pkt_stream = ifobject->pkt_stream;\n\tstruct xsk_socket_info *xsk = ifobject->xsk;\n\tstruct xsk_umem_info *umem = ifobject->umem;\n\tbool use_poll = ifobject->use_poll;\n\tint ret;\n\n\tbuffer_len = pkt_get_buffer_len(umem, pkt_stream->max_pkt_len);\n\t \n\tif (pkts_in_flight >= (int)((umem_size(umem) - BATCH_SIZE * buffer_len) / buffer_len)) {\n\t\tkick_tx(xsk);\n\t\treturn TEST_CONTINUE;\n\t}\n\n\twhile (xsk_ring_prod__reserve(&xsk->tx, BATCH_SIZE, &idx) < BATCH_SIZE) {\n\t\tif (use_poll) {\n\t\t\tret = poll(fds, 1, POLL_TMOUT);\n\t\t\tif (timeout) {\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tksft_print_msg(\"ERROR: [%s] Poll error %d\\n\",\n\t\t\t\t\t\t       __func__, errno);\n\t\t\t\t\treturn TEST_FAILURE;\n\t\t\t\t}\n\t\t\t\tif (ret == 0)\n\t\t\t\t\treturn TEST_PASS;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ret <= 0) {\n\t\t\t\tksft_print_msg(\"ERROR: [%s] Poll error %d\\n\",\n\t\t\t\t\t       __func__, errno);\n\t\t\t\treturn TEST_FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tcomplete_pkts(xsk, BATCH_SIZE);\n\t}\n\n\tfor (i = 0; i < BATCH_SIZE; i++) {\n\t\tstruct pkt *pkt = pkt_stream_get_next_tx_pkt(pkt_stream);\n\t\tu32 nb_frags_left, nb_frags, bytes_written = 0;\n\n\t\tif (!pkt)\n\t\t\tbreak;\n\n\t\tnb_frags = pkt_nb_frags(umem->frame_size, pkt_stream, pkt);\n\t\tif (nb_frags > BATCH_SIZE - i) {\n\t\t\tpkt_stream_cancel(pkt_stream);\n\t\t\txsk_ring_prod__cancel(&xsk->tx, BATCH_SIZE - i);\n\t\t\tbreak;\n\t\t}\n\t\tnb_frags_left = nb_frags;\n\n\t\twhile (nb_frags_left--) {\n\t\t\tstruct xdp_desc *tx_desc = xsk_ring_prod__tx_desc(&xsk->tx, idx + i);\n\n\t\t\ttx_desc->addr = pkt_get_addr(pkt, ifobject->umem);\n\t\t\tif (pkt_stream->verbatim) {\n\t\t\t\ttx_desc->len = pkt->len;\n\t\t\t\ttx_desc->options = pkt->options;\n\t\t\t} else if (nb_frags_left) {\n\t\t\t\ttx_desc->len = umem->frame_size;\n\t\t\t\ttx_desc->options = XDP_PKT_CONTD;\n\t\t\t} else {\n\t\t\t\ttx_desc->len = pkt->len - bytes_written;\n\t\t\t\ttx_desc->options = 0;\n\t\t\t}\n\t\t\tif (pkt->valid)\n\t\t\t\tpkt_generate(ifobject, tx_desc->addr, tx_desc->len, pkt->pkt_nb,\n\t\t\t\t\t     bytes_written);\n\t\t\tbytes_written += tx_desc->len;\n\n\t\t\tif (nb_frags_left) {\n\t\t\t\ti++;\n\t\t\t\tif (pkt_stream->verbatim)\n\t\t\t\t\tpkt = pkt_stream_get_next_tx_pkt(pkt_stream);\n\t\t\t}\n\t\t}\n\n\t\tif (pkt && pkt->valid) {\n\t\t\tvalid_pkts++;\n\t\t\tvalid_frags += nb_frags;\n\t\t}\n\t}\n\n\tpthread_mutex_lock(&pacing_mutex);\n\tpkts_in_flight += valid_pkts;\n\tpthread_mutex_unlock(&pacing_mutex);\n\n\txsk_ring_prod__submit(&xsk->tx, i);\n\txsk->outstanding_tx += valid_frags;\n\n\tif (use_poll) {\n\t\tret = poll(fds, 1, POLL_TMOUT);\n\t\tif (ret <= 0) {\n\t\t\tif (ret == 0 && timeout)\n\t\t\t\treturn TEST_PASS;\n\n\t\t\tksft_print_msg(\"ERROR: [%s] Poll error %d\\n\", __func__, ret);\n\t\t\treturn TEST_FAILURE;\n\t\t}\n\t}\n\n\tif (!timeout) {\n\t\tif (complete_pkts(xsk, i))\n\t\t\treturn TEST_FAILURE;\n\n\t\tusleep(10);\n\t\treturn TEST_PASS;\n\t}\n\n\treturn TEST_CONTINUE;\n}\n\nstatic void wait_for_tx_completion(struct xsk_socket_info *xsk)\n{\n\twhile (xsk->outstanding_tx)\n\t\tcomplete_pkts(xsk, BATCH_SIZE);\n}\n\nstatic int send_pkts(struct test_spec *test, struct ifobject *ifobject)\n{\n\tstruct pkt_stream *pkt_stream = ifobject->pkt_stream;\n\tbool timeout = !is_umem_valid(test->ifobj_rx);\n\tstruct pollfd fds = { };\n\tu32 ret;\n\n\tfds.fd = xsk_socket__fd(ifobject->xsk->xsk);\n\tfds.events = POLLOUT;\n\n\twhile (pkt_stream->current_pkt_nb < pkt_stream->nb_pkts) {\n\t\tret = __send_pkts(ifobject, &fds, timeout);\n\t\tif (ret == TEST_CONTINUE && !test->fail)\n\t\t\tcontinue;\n\t\tif ((ret || test->fail) && !timeout)\n\t\t\treturn TEST_FAILURE;\n\t\tif (ret == TEST_PASS && timeout)\n\t\t\treturn ret;\n\t}\n\n\twait_for_tx_completion(ifobject->xsk);\n\treturn TEST_PASS;\n}\n\nstatic int get_xsk_stats(struct xsk_socket *xsk, struct xdp_statistics *stats)\n{\n\tint fd = xsk_socket__fd(xsk), err;\n\tsocklen_t optlen, expected_len;\n\n\toptlen = sizeof(*stats);\n\terr = getsockopt(fd, SOL_XDP, XDP_STATISTICS, stats, &optlen);\n\tif (err) {\n\t\tksft_print_msg(\"[%s] getsockopt(XDP_STATISTICS) error %u %s\\n\",\n\t\t\t       __func__, -err, strerror(-err));\n\t\treturn TEST_FAILURE;\n\t}\n\n\texpected_len = sizeof(struct xdp_statistics);\n\tif (optlen != expected_len) {\n\t\tksft_print_msg(\"[%s] getsockopt optlen error. Expected: %u got: %u\\n\",\n\t\t\t       __func__, expected_len, optlen);\n\t\treturn TEST_FAILURE;\n\t}\n\n\treturn TEST_PASS;\n}\n\nstatic int validate_rx_dropped(struct ifobject *ifobject)\n{\n\tstruct xsk_socket *xsk = ifobject->xsk->xsk;\n\tstruct xdp_statistics stats;\n\tint err;\n\n\tkick_rx(ifobject->xsk);\n\n\terr = get_xsk_stats(xsk, &stats);\n\tif (err)\n\t\treturn TEST_FAILURE;\n\n\t \n\tif (stats.rx_dropped == ifobject->pkt_stream->nb_pkts / 2 ||\n\t    stats.rx_dropped == ifobject->pkt_stream->nb_pkts / 2 - 1)\n\t\treturn TEST_PASS;\n\n\treturn TEST_FAILURE;\n}\n\nstatic int validate_rx_full(struct ifobject *ifobject)\n{\n\tstruct xsk_socket *xsk = ifobject->xsk->xsk;\n\tstruct xdp_statistics stats;\n\tint err;\n\n\tusleep(1000);\n\tkick_rx(ifobject->xsk);\n\n\terr = get_xsk_stats(xsk, &stats);\n\tif (err)\n\t\treturn TEST_FAILURE;\n\n\tif (stats.rx_ring_full)\n\t\treturn TEST_PASS;\n\n\treturn TEST_FAILURE;\n}\n\nstatic int validate_fill_empty(struct ifobject *ifobject)\n{\n\tstruct xsk_socket *xsk = ifobject->xsk->xsk;\n\tstruct xdp_statistics stats;\n\tint err;\n\n\tusleep(1000);\n\tkick_rx(ifobject->xsk);\n\n\terr = get_xsk_stats(xsk, &stats);\n\tif (err)\n\t\treturn TEST_FAILURE;\n\n\tif (stats.rx_fill_ring_empty_descs)\n\t\treturn TEST_PASS;\n\n\treturn TEST_FAILURE;\n}\n\nstatic int validate_tx_invalid_descs(struct ifobject *ifobject)\n{\n\tstruct xsk_socket *xsk = ifobject->xsk->xsk;\n\tint fd = xsk_socket__fd(xsk);\n\tstruct xdp_statistics stats;\n\tsocklen_t optlen;\n\tint err;\n\n\toptlen = sizeof(stats);\n\terr = getsockopt(fd, SOL_XDP, XDP_STATISTICS, &stats, &optlen);\n\tif (err) {\n\t\tksft_print_msg(\"[%s] getsockopt(XDP_STATISTICS) error %u %s\\n\",\n\t\t\t       __func__, -err, strerror(-err));\n\t\treturn TEST_FAILURE;\n\t}\n\n\tif (stats.tx_invalid_descs != ifobject->pkt_stream->nb_pkts / 2) {\n\t\tksft_print_msg(\"[%s] tx_invalid_descs incorrect. Got [%u] expected [%u]\\n\",\n\t\t\t       __func__, stats.tx_invalid_descs, ifobject->pkt_stream->nb_pkts);\n\t\treturn TEST_FAILURE;\n\t}\n\n\treturn TEST_PASS;\n}\n\nstatic void xsk_configure_socket(struct test_spec *test, struct ifobject *ifobject,\n\t\t\t\t struct xsk_umem_info *umem, bool tx)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < test->nb_sockets; i++) {\n\t\tbool shared = (ifobject->shared_umem && tx) ? true : !!i;\n\t\tu32 ctr = 0;\n\n\t\twhile (ctr++ < SOCK_RECONF_CTR) {\n\t\t\tret = __xsk_configure_socket(&ifobject->xsk_arr[i], umem,\n\t\t\t\t\t\t     ifobject, shared);\n\t\t\tif (!ret)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tif (ctr >= SOCK_RECONF_CTR)\n\t\t\t\texit_with_error(-ret);\n\t\t\tusleep(USLEEP_MAX);\n\t\t}\n\t\tif (ifobject->busy_poll)\n\t\t\tenable_busy_poll(&ifobject->xsk_arr[i]);\n\t}\n}\n\nstatic void thread_common_ops_tx(struct test_spec *test, struct ifobject *ifobject)\n{\n\txsk_configure_socket(test, ifobject, test->ifobj_rx->umem, true);\n\tifobject->xsk = &ifobject->xsk_arr[0];\n\tifobject->xskmap = test->ifobj_rx->xskmap;\n\tmemcpy(ifobject->umem, test->ifobj_rx->umem, sizeof(struct xsk_umem_info));\n\tifobject->umem->base_addr = 0;\n}\n\nstatic void xsk_populate_fill_ring(struct xsk_umem_info *umem, struct pkt_stream *pkt_stream,\n\t\t\t\t   bool fill_up)\n{\n\tu32 rx_frame_size = umem->frame_size - XDP_PACKET_HEADROOM;\n\tu32 idx = 0, filled = 0, buffers_to_fill, nb_pkts;\n\tint ret;\n\n\tif (umem->num_frames < XSK_RING_PROD__DEFAULT_NUM_DESCS)\n\t\tbuffers_to_fill = umem->num_frames;\n\telse\n\t\tbuffers_to_fill = XSK_RING_PROD__DEFAULT_NUM_DESCS;\n\n\tret = xsk_ring_prod__reserve(&umem->fq, buffers_to_fill, &idx);\n\tif (ret != buffers_to_fill)\n\t\texit_with_error(ENOSPC);\n\n\twhile (filled < buffers_to_fill) {\n\t\tstruct pkt *pkt = pkt_stream_get_next_rx_pkt(pkt_stream, &nb_pkts);\n\t\tu64 addr;\n\t\tu32 i;\n\n\t\tfor (i = 0; i < pkt_nb_frags(rx_frame_size, pkt_stream, pkt); i++) {\n\t\t\tif (!pkt) {\n\t\t\t\tif (!fill_up)\n\t\t\t\t\tbreak;\n\t\t\t\taddr = filled * umem->frame_size + umem->base_addr;\n\t\t\t} else if (pkt->offset >= 0) {\n\t\t\t\taddr = pkt->offset % umem->frame_size + umem_alloc_buffer(umem);\n\t\t\t} else {\n\t\t\t\taddr = pkt->offset + umem_alloc_buffer(umem);\n\t\t\t}\n\n\t\t\t*xsk_ring_prod__fill_addr(&umem->fq, idx++) = addr;\n\t\t\tif (++filled >= buffers_to_fill)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\txsk_ring_prod__submit(&umem->fq, filled);\n\txsk_ring_prod__cancel(&umem->fq, buffers_to_fill - filled);\n\n\tpkt_stream_reset(pkt_stream);\n\tumem_reset_alloc(umem);\n}\n\nstatic void thread_common_ops(struct test_spec *test, struct ifobject *ifobject)\n{\n\tu64 umem_sz = ifobject->umem->num_frames * ifobject->umem->frame_size;\n\tint mmap_flags = MAP_PRIVATE | MAP_ANONYMOUS | MAP_NORESERVE;\n\tLIBBPF_OPTS(bpf_xdp_query_opts, opts);\n\tvoid *bufs;\n\tint ret;\n\n\tif (ifobject->umem->unaligned_mode)\n\t\tmmap_flags |= MAP_HUGETLB | MAP_HUGE_2MB;\n\n\tif (ifobject->shared_umem)\n\t\tumem_sz *= 2;\n\n\tbufs = mmap(NULL, umem_sz, PROT_READ | PROT_WRITE, mmap_flags, -1, 0);\n\tif (bufs == MAP_FAILED)\n\t\texit_with_error(errno);\n\n\tret = xsk_configure_umem(ifobject, ifobject->umem, bufs, umem_sz);\n\tif (ret)\n\t\texit_with_error(-ret);\n\n\txsk_configure_socket(test, ifobject, ifobject->umem, false);\n\n\tifobject->xsk = &ifobject->xsk_arr[0];\n\n\tif (!ifobject->rx_on)\n\t\treturn;\n\n\txsk_populate_fill_ring(ifobject->umem, ifobject->pkt_stream, ifobject->use_fill_ring);\n\n\tret = xsk_update_xskmap(ifobject->xskmap, ifobject->xsk->xsk);\n\tif (ret)\n\t\texit_with_error(errno);\n}\n\nstatic void *worker_testapp_validate_tx(void *arg)\n{\n\tstruct test_spec *test = (struct test_spec *)arg;\n\tstruct ifobject *ifobject = test->ifobj_tx;\n\tint err;\n\n\tif (test->current_step == 1) {\n\t\tif (!ifobject->shared_umem)\n\t\t\tthread_common_ops(test, ifobject);\n\t\telse\n\t\t\tthread_common_ops_tx(test, ifobject);\n\t}\n\n\tprint_verbose(\"Sending %d packets on interface %s\\n\", ifobject->pkt_stream->nb_pkts,\n\t\t      ifobject->ifname);\n\terr = send_pkts(test, ifobject);\n\n\tif (!err && ifobject->validation_func)\n\t\terr = ifobject->validation_func(ifobject);\n\tif (err)\n\t\treport_failure(test);\n\n\tpthread_exit(NULL);\n}\n\nstatic void *worker_testapp_validate_rx(void *arg)\n{\n\tstruct test_spec *test = (struct test_spec *)arg;\n\tstruct ifobject *ifobject = test->ifobj_rx;\n\tstruct pollfd fds = { };\n\tint err;\n\n\tif (test->current_step == 1) {\n\t\tthread_common_ops(test, ifobject);\n\t} else {\n\t\txsk_clear_xskmap(ifobject->xskmap);\n\t\terr = xsk_update_xskmap(ifobject->xskmap, ifobject->xsk->xsk);\n\t\tif (err) {\n\t\t\tprintf(\"Error: Failed to update xskmap, error %s\\n\", strerror(-err));\n\t\t\texit_with_error(-err);\n\t\t}\n\t}\n\n\tfds.fd = xsk_socket__fd(ifobject->xsk->xsk);\n\tfds.events = POLLIN;\n\n\tpthread_barrier_wait(&barr);\n\n\terr = receive_pkts(test, &fds);\n\n\tif (!err && ifobject->validation_func)\n\t\terr = ifobject->validation_func(ifobject);\n\tif (err)\n\t\treport_failure(test);\n\n\tpthread_exit(NULL);\n}\n\nstatic u64 ceil_u64(u64 a, u64 b)\n{\n\treturn (a + b - 1) / b;\n}\n\nstatic void testapp_clean_xsk_umem(struct ifobject *ifobj)\n{\n\tu64 umem_sz = ifobj->umem->num_frames * ifobj->umem->frame_size;\n\n\tif (ifobj->shared_umem)\n\t\tumem_sz *= 2;\n\n\tumem_sz = ceil_u64(umem_sz, HUGEPAGE_SIZE) * HUGEPAGE_SIZE;\n\txsk_umem__delete(ifobj->umem->umem);\n\tmunmap(ifobj->umem->buffer, umem_sz);\n}\n\nstatic void handler(int signum)\n{\n\tpthread_exit(NULL);\n}\n\nstatic bool xdp_prog_changed_rx(struct test_spec *test)\n{\n\tstruct ifobject *ifobj = test->ifobj_rx;\n\n\treturn ifobj->xdp_prog != test->xdp_prog_rx || ifobj->mode != test->mode;\n}\n\nstatic bool xdp_prog_changed_tx(struct test_spec *test)\n{\n\tstruct ifobject *ifobj = test->ifobj_tx;\n\n\treturn ifobj->xdp_prog != test->xdp_prog_tx || ifobj->mode != test->mode;\n}\n\nstatic void xsk_reattach_xdp(struct ifobject *ifobj, struct bpf_program *xdp_prog,\n\t\t\t     struct bpf_map *xskmap, enum test_mode mode)\n{\n\tint err;\n\n\txsk_detach_xdp_program(ifobj->ifindex, mode_to_xdp_flags(ifobj->mode));\n\terr = xsk_attach_xdp_program(xdp_prog, ifobj->ifindex, mode_to_xdp_flags(mode));\n\tif (err) {\n\t\tprintf(\"Error attaching XDP program\\n\");\n\t\texit_with_error(-err);\n\t}\n\n\tif (ifobj->mode != mode && (mode == TEST_MODE_DRV || mode == TEST_MODE_ZC))\n\t\tif (!xsk_is_in_mode(ifobj->ifindex, XDP_FLAGS_DRV_MODE)) {\n\t\t\tksft_print_msg(\"ERROR: XDP prog not in DRV mode\\n\");\n\t\t\texit_with_error(EINVAL);\n\t\t}\n\n\tifobj->xdp_prog = xdp_prog;\n\tifobj->xskmap = xskmap;\n\tifobj->mode = mode;\n}\n\nstatic void xsk_attach_xdp_progs(struct test_spec *test, struct ifobject *ifobj_rx,\n\t\t\t\t struct ifobject *ifobj_tx)\n{\n\tif (xdp_prog_changed_rx(test))\n\t\txsk_reattach_xdp(ifobj_rx, test->xdp_prog_rx, test->xskmap_rx, test->mode);\n\n\tif (!ifobj_tx || ifobj_tx->shared_umem)\n\t\treturn;\n\n\tif (xdp_prog_changed_tx(test))\n\t\txsk_reattach_xdp(ifobj_tx, test->xdp_prog_tx, test->xskmap_tx, test->mode);\n}\n\nstatic int __testapp_validate_traffic(struct test_spec *test, struct ifobject *ifobj1,\n\t\t\t\t      struct ifobject *ifobj2)\n{\n\tpthread_t t0, t1;\n\tint err;\n\n\tif (test->mtu > MAX_ETH_PKT_SIZE) {\n\t\tif (test->mode == TEST_MODE_ZC && (!ifobj1->multi_buff_zc_supp ||\n\t\t\t\t\t\t   (ifobj2 && !ifobj2->multi_buff_zc_supp))) {\n\t\t\tksft_test_result_skip(\"Multi buffer for zero-copy not supported.\\n\");\n\t\t\treturn TEST_SKIP;\n\t\t}\n\t\tif (test->mode != TEST_MODE_ZC && (!ifobj1->multi_buff_supp ||\n\t\t\t\t\t\t   (ifobj2 && !ifobj2->multi_buff_supp))) {\n\t\t\tksft_test_result_skip(\"Multi buffer not supported.\\n\");\n\t\t\treturn TEST_SKIP;\n\t\t}\n\t}\n\terr = test_spec_set_mtu(test, test->mtu);\n\tif (err) {\n\t\tksft_print_msg(\"Error, could not set mtu.\\n\");\n\t\texit_with_error(err);\n\t}\n\n\tif (ifobj2) {\n\t\tif (pthread_barrier_init(&barr, NULL, 2))\n\t\t\texit_with_error(errno);\n\t\tpkt_stream_reset(ifobj2->pkt_stream);\n\t}\n\n\ttest->current_step++;\n\tpkt_stream_reset(ifobj1->pkt_stream);\n\tpkts_in_flight = 0;\n\n\tsignal(SIGUSR1, handler);\n\t \n\tpthread_create(&t0, NULL, ifobj1->func_ptr, test);\n\n\tif (ifobj2) {\n\t\tpthread_barrier_wait(&barr);\n\t\tif (pthread_barrier_destroy(&barr))\n\t\t\texit_with_error(errno);\n\n\t\t \n\t\tpthread_create(&t1, NULL, ifobj2->func_ptr, test);\n\n\t\tpthread_join(t1, NULL);\n\t}\n\n\tif (!ifobj2)\n\t\tpthread_kill(t0, SIGUSR1);\n\telse\n\t\tpthread_join(t0, NULL);\n\n\tif (test->total_steps == test->current_step || test->fail) {\n\t\tif (ifobj2)\n\t\t\txsk_socket__delete(ifobj2->xsk->xsk);\n\t\txsk_socket__delete(ifobj1->xsk->xsk);\n\t\ttestapp_clean_xsk_umem(ifobj1);\n\t\tif (ifobj2 && !ifobj2->shared_umem)\n\t\t\ttestapp_clean_xsk_umem(ifobj2);\n\t}\n\n\treturn !!test->fail;\n}\n\nstatic int testapp_validate_traffic(struct test_spec *test)\n{\n\tstruct ifobject *ifobj_rx = test->ifobj_rx;\n\tstruct ifobject *ifobj_tx = test->ifobj_tx;\n\n\tif ((ifobj_rx->umem->unaligned_mode && !ifobj_rx->unaligned_supp) ||\n\t    (ifobj_tx->umem->unaligned_mode && !ifobj_tx->unaligned_supp)) {\n\t\tksft_test_result_skip(\"No huge pages present.\\n\");\n\t\treturn TEST_SKIP;\n\t}\n\n\txsk_attach_xdp_progs(test, ifobj_rx, ifobj_tx);\n\treturn __testapp_validate_traffic(test, ifobj_rx, ifobj_tx);\n}\n\nstatic int testapp_validate_traffic_single_thread(struct test_spec *test, struct ifobject *ifobj)\n{\n\treturn __testapp_validate_traffic(test, ifobj, NULL);\n}\n\nstatic int testapp_teardown(struct test_spec *test)\n{\n\tint i;\n\n\ttest_spec_set_name(test, \"TEARDOWN\");\n\tfor (i = 0; i < MAX_TEARDOWN_ITER; i++) {\n\t\tif (testapp_validate_traffic(test))\n\t\t\treturn TEST_FAILURE;\n\t\ttest_spec_reset(test);\n\t}\n\n\treturn TEST_PASS;\n}\n\nstatic void swap_directions(struct ifobject **ifobj1, struct ifobject **ifobj2)\n{\n\tthread_func_t tmp_func_ptr = (*ifobj1)->func_ptr;\n\tstruct ifobject *tmp_ifobj = (*ifobj1);\n\n\t(*ifobj1)->func_ptr = (*ifobj2)->func_ptr;\n\t(*ifobj2)->func_ptr = tmp_func_ptr;\n\n\t*ifobj1 = *ifobj2;\n\t*ifobj2 = tmp_ifobj;\n}\n\nstatic int testapp_bidi(struct test_spec *test)\n{\n\tint res;\n\n\ttest_spec_set_name(test, \"BIDIRECTIONAL\");\n\ttest->ifobj_tx->rx_on = true;\n\ttest->ifobj_rx->tx_on = true;\n\ttest->total_steps = 2;\n\tif (testapp_validate_traffic(test))\n\t\treturn TEST_FAILURE;\n\n\tprint_verbose(\"Switching Tx/Rx vectors\\n\");\n\tswap_directions(&test->ifobj_rx, &test->ifobj_tx);\n\tres = __testapp_validate_traffic(test, test->ifobj_rx, test->ifobj_tx);\n\n\tswap_directions(&test->ifobj_rx, &test->ifobj_tx);\n\treturn res;\n}\n\nstatic void swap_xsk_resources(struct ifobject *ifobj_tx, struct ifobject *ifobj_rx)\n{\n\tint ret;\n\n\txsk_socket__delete(ifobj_tx->xsk->xsk);\n\txsk_socket__delete(ifobj_rx->xsk->xsk);\n\tifobj_tx->xsk = &ifobj_tx->xsk_arr[1];\n\tifobj_rx->xsk = &ifobj_rx->xsk_arr[1];\n\n\tret = xsk_update_xskmap(ifobj_rx->xskmap, ifobj_rx->xsk->xsk);\n\tif (ret)\n\t\texit_with_error(errno);\n}\n\nstatic int testapp_bpf_res(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"BPF_RES\");\n\ttest->total_steps = 2;\n\ttest->nb_sockets = 2;\n\tif (testapp_validate_traffic(test))\n\t\treturn TEST_FAILURE;\n\n\tswap_xsk_resources(test->ifobj_tx, test->ifobj_rx);\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_headroom(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"UMEM_HEADROOM\");\n\ttest->ifobj_rx->umem->frame_headroom = UMEM_HEADROOM_TEST_SIZE;\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_stats_rx_dropped(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"STAT_RX_DROPPED\");\n\tif (test->mode == TEST_MODE_ZC) {\n\t\tksft_test_result_skip(\"Can not run RX_DROPPED test for ZC mode\\n\");\n\t\treturn TEST_SKIP;\n\t}\n\n\tpkt_stream_replace_half(test, MIN_PKT_SIZE * 4, 0);\n\ttest->ifobj_rx->umem->frame_headroom = test->ifobj_rx->umem->frame_size -\n\t\tXDP_PACKET_HEADROOM - MIN_PKT_SIZE * 3;\n\tpkt_stream_receive_half(test);\n\ttest->ifobj_rx->validation_func = validate_rx_dropped;\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_stats_tx_invalid_descs(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"STAT_TX_INVALID\");\n\tpkt_stream_replace_half(test, XSK_UMEM__INVALID_FRAME_SIZE, 0);\n\ttest->ifobj_tx->validation_func = validate_tx_invalid_descs;\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_stats_rx_full(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"STAT_RX_FULL\");\n\tpkt_stream_replace(test, DEFAULT_UMEM_BUFFERS + DEFAULT_UMEM_BUFFERS / 2, MIN_PKT_SIZE);\n\ttest->ifobj_rx->pkt_stream = pkt_stream_generate(test->ifobj_rx->umem,\n\t\t\t\t\t\t\t DEFAULT_UMEM_BUFFERS, MIN_PKT_SIZE);\n\n\ttest->ifobj_rx->xsk->rxqsize = DEFAULT_UMEM_BUFFERS;\n\ttest->ifobj_rx->release_rx = false;\n\ttest->ifobj_rx->validation_func = validate_rx_full;\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_stats_fill_empty(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"STAT_RX_FILL_EMPTY\");\n\tpkt_stream_replace(test, DEFAULT_UMEM_BUFFERS + DEFAULT_UMEM_BUFFERS / 2, MIN_PKT_SIZE);\n\ttest->ifobj_rx->pkt_stream = pkt_stream_generate(test->ifobj_rx->umem,\n\t\t\t\t\t\t\t DEFAULT_UMEM_BUFFERS, MIN_PKT_SIZE);\n\n\ttest->ifobj_rx->use_fill_ring = false;\n\ttest->ifobj_rx->validation_func = validate_fill_empty;\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_unaligned(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"UNALIGNED_MODE\");\n\ttest->ifobj_tx->umem->unaligned_mode = true;\n\ttest->ifobj_rx->umem->unaligned_mode = true;\n\t \n\tpkt_stream_replace_half(test, MIN_PKT_SIZE, -MIN_PKT_SIZE / 2);\n\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_unaligned_mb(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"UNALIGNED_MODE_9K\");\n\ttest->mtu = MAX_ETH_JUMBO_SIZE;\n\ttest->ifobj_tx->umem->unaligned_mode = true;\n\ttest->ifobj_rx->umem->unaligned_mode = true;\n\tpkt_stream_replace(test, DEFAULT_PKT_CNT, MAX_ETH_JUMBO_SIZE);\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_single_pkt(struct test_spec *test)\n{\n\tstruct pkt pkts[] = {{0, MIN_PKT_SIZE, 0, true}};\n\n\tpkt_stream_generate_custom(test, pkts, ARRAY_SIZE(pkts));\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_multi_buffer(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"RUN_TO_COMPLETION_9K_PACKETS\");\n\ttest->mtu = MAX_ETH_JUMBO_SIZE;\n\tpkt_stream_replace(test, DEFAULT_PKT_CNT, MAX_ETH_JUMBO_SIZE);\n\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_invalid_desc_mb(struct test_spec *test)\n{\n\tstruct xsk_umem_info *umem = test->ifobj_tx->umem;\n\tu64 umem_size = umem->num_frames * umem->frame_size;\n\tstruct pkt pkts[] = {\n\t\t \n\t\t{0, MIN_PKT_SIZE, 0, true, 0},\n\t\t \n\t\t{0, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t{0, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t{0, 0, 0, false, 0},\n\t\t \n\t\t{0, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t{umem_size, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t \n\t\t{0, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t{0, XSK_UMEM__INVALID_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t \n\t\t{0, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t{0, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XSK_DESC__INVALID_OPTION},\n\t\t \n\t\t{0, XSK_UMEM__MAX_FRAME_SIZE, 0, true, XDP_PKT_CONTD},\n\t\t{0, XSK_UMEM__MAX_FRAME_SIZE, 0, true, 0},\n\t\t \n\t\t{0, XSK_UMEM__LARGE_FRAME_SIZE, 0, false, XDP_PKT_CONTD},\n\t\t{-MIN_PKT_SIZE / 2, MIN_PKT_SIZE, 0, false, 0},\n\t\t \n\t\t{0, MIN_PKT_SIZE, 0, true, 0}};\n\n\tif (umem->unaligned_mode) {\n\t\t \n\t\tpkts[12].valid = true;\n\t\tpkts[13].valid = true;\n\t}\n\n\ttest->mtu = MAX_ETH_JUMBO_SIZE;\n\tpkt_stream_generate_custom(test, pkts, ARRAY_SIZE(pkts));\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_invalid_desc(struct test_spec *test)\n{\n\tstruct xsk_umem_info *umem = test->ifobj_tx->umem;\n\tu64 umem_size = umem->num_frames * umem->frame_size;\n\tstruct pkt pkts[] = {\n\t\t \n\t\t{0, MIN_PKT_SIZE, 0, true},\n\t\t \n\t\t{0, MIN_PKT_SIZE, 0, true},\n\t\t \n\t\t{-2, MIN_PKT_SIZE, 0, false},\n\t\t \n\t\t{0, XSK_UMEM__INVALID_FRAME_SIZE, 0, false},\n\t\t \n\t\t{umem_size - MIN_PKT_SIZE - 2 * umem->frame_size, MIN_PKT_SIZE, 0, true},\n\t\t \n\t\t{umem_size, MIN_PKT_SIZE, 0, false},\n\t\t \n\t\t{umem_size - MIN_PKT_SIZE / 2, MIN_PKT_SIZE, 0, false},\n\t\t \n\t\t{0x1000 - MIN_PKT_SIZE / 2, MIN_PKT_SIZE, 0, false},\n\t\t \n\t\t{0x800 - MIN_PKT_SIZE / 2, MIN_PKT_SIZE, 0, true},\n\t\t \n\t\t{0, MIN_PKT_SIZE, 0, true}};\n\n\tif (umem->unaligned_mode) {\n\t\t \n\t\tpkts[7].valid = true;\n\t}\n\tif (umem->frame_size == XSK_UMEM__DEFAULT_FRAME_SIZE / 2) {\n\t\t \n\t\tpkts[8].valid = false;\n\t}\n\n\tif (test->ifobj_tx->shared_umem) {\n\t\tpkts[4].offset += umem_size;\n\t\tpkts[5].offset += umem_size;\n\t\tpkts[6].offset += umem_size;\n\t}\n\n\tpkt_stream_generate_custom(test, pkts, ARRAY_SIZE(pkts));\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_xdp_drop(struct test_spec *test)\n{\n\tstruct xsk_xdp_progs *skel_rx = test->ifobj_rx->xdp_progs;\n\tstruct xsk_xdp_progs *skel_tx = test->ifobj_tx->xdp_progs;\n\n\ttest_spec_set_name(test, \"XDP_DROP_HALF\");\n\ttest_spec_set_xdp_prog(test, skel_rx->progs.xsk_xdp_drop, skel_tx->progs.xsk_xdp_drop,\n\t\t\t       skel_rx->maps.xsk, skel_tx->maps.xsk);\n\n\tpkt_stream_receive_half(test);\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_xdp_metadata_count(struct test_spec *test)\n{\n\tstruct xsk_xdp_progs *skel_rx = test->ifobj_rx->xdp_progs;\n\tstruct xsk_xdp_progs *skel_tx = test->ifobj_tx->xdp_progs;\n\tstruct bpf_map *data_map;\n\tint count = 0;\n\tint key = 0;\n\n\ttest_spec_set_xdp_prog(test, skel_rx->progs.xsk_xdp_populate_metadata,\n\t\t\t       skel_tx->progs.xsk_xdp_populate_metadata,\n\t\t\t       skel_rx->maps.xsk, skel_tx->maps.xsk);\n\ttest->ifobj_rx->use_metadata = true;\n\n\tdata_map = bpf_object__find_map_by_name(skel_rx->obj, \"xsk_xdp_.bss\");\n\tif (!data_map || !bpf_map__is_internal(data_map))\n\t\texit_with_error(ENOMEM);\n\n\tif (bpf_map_update_elem(bpf_map__fd(data_map), &key, &count, BPF_ANY))\n\t\texit_with_error(errno);\n\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int testapp_poll_txq_tmout(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"POLL_TXQ_FULL\");\n\n\ttest->ifobj_tx->use_poll = true;\n\t \n\ttest->ifobj_tx->umem->frame_size = 2048;\n\tpkt_stream_replace(test, 2 * DEFAULT_PKT_CNT, 2048);\n\treturn testapp_validate_traffic_single_thread(test, test->ifobj_tx);\n}\n\nstatic int testapp_poll_rxq_tmout(struct test_spec *test)\n{\n\ttest_spec_set_name(test, \"POLL_RXQ_EMPTY\");\n\ttest->ifobj_rx->use_poll = true;\n\treturn testapp_validate_traffic_single_thread(test, test->ifobj_rx);\n}\n\nstatic int testapp_too_many_frags(struct test_spec *test)\n{\n\tstruct pkt pkts[2 * XSK_DESC__MAX_SKB_FRAGS + 2] = {};\n\tu32 max_frags, i;\n\n\ttest_spec_set_name(test, \"TOO_MANY_FRAGS\");\n\tif (test->mode == TEST_MODE_ZC)\n\t\tmax_frags = test->ifobj_tx->xdp_zc_max_segs;\n\telse\n\t\tmax_frags = XSK_DESC__MAX_SKB_FRAGS;\n\n\ttest->mtu = MAX_ETH_JUMBO_SIZE;\n\n\t \n\tpkts[0].len = MIN_PKT_SIZE;\n\tpkts[0].valid = true;\n\n\t \n\tfor (i = 1; i < max_frags + 1; i++) {\n\t\tpkts[i].len = MIN_PKT_SIZE;\n\t\tpkts[i].options = XDP_PKT_CONTD;\n\t\tpkts[i].valid = true;\n\t}\n\tpkts[max_frags].options = 0;\n\n\t \n\tfor (i = max_frags + 1; i < 2 * max_frags + 1; i++) {\n\t\tpkts[i].len = MIN_PKT_SIZE;\n\t\tpkts[i].options = XDP_PKT_CONTD;\n\t\tpkts[i].valid = false;\n\t}\n\n\t \n\tpkts[2 * max_frags + 1].len = MIN_PKT_SIZE;\n\tpkts[2 * max_frags + 1].valid = true;\n\n\tpkt_stream_generate_custom(test, pkts, 2 * max_frags + 2);\n\treturn testapp_validate_traffic(test);\n}\n\nstatic int xsk_load_xdp_programs(struct ifobject *ifobj)\n{\n\tifobj->xdp_progs = xsk_xdp_progs__open_and_load();\n\tif (libbpf_get_error(ifobj->xdp_progs))\n\t\treturn libbpf_get_error(ifobj->xdp_progs);\n\n\treturn 0;\n}\n\nstatic void xsk_unload_xdp_programs(struct ifobject *ifobj)\n{\n\txsk_xdp_progs__destroy(ifobj->xdp_progs);\n}\n\n \nstatic bool hugepages_present(void)\n{\n\tsize_t mmap_sz = 2 * DEFAULT_UMEM_BUFFERS * XSK_UMEM__DEFAULT_FRAME_SIZE;\n\tvoid *bufs;\n\n\tbufs = mmap(NULL, mmap_sz, PROT_READ | PROT_WRITE,\n\t\t    MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB, -1, MAP_HUGE_2MB);\n\tif (bufs == MAP_FAILED)\n\t\treturn false;\n\n\tmmap_sz = ceil_u64(mmap_sz, HUGEPAGE_SIZE) * HUGEPAGE_SIZE;\n\tmunmap(bufs, mmap_sz);\n\treturn true;\n}\n\nstatic void init_iface(struct ifobject *ifobj, const char *dst_mac, const char *src_mac,\n\t\t       thread_func_t func_ptr)\n{\n\tLIBBPF_OPTS(bpf_xdp_query_opts, query_opts);\n\tint err;\n\n\tmemcpy(ifobj->dst_mac, dst_mac, ETH_ALEN);\n\tmemcpy(ifobj->src_mac, src_mac, ETH_ALEN);\n\n\tifobj->func_ptr = func_ptr;\n\n\terr = xsk_load_xdp_programs(ifobj);\n\tif (err) {\n\t\tprintf(\"Error loading XDP program\\n\");\n\t\texit_with_error(err);\n\t}\n\n\tif (hugepages_present())\n\t\tifobj->unaligned_supp = true;\n\n\terr = bpf_xdp_query(ifobj->ifindex, XDP_FLAGS_DRV_MODE, &query_opts);\n\tif (err) {\n\t\tksft_print_msg(\"Error querying XDP capabilities\\n\");\n\t\texit_with_error(-err);\n\t}\n\tif (query_opts.feature_flags & NETDEV_XDP_ACT_RX_SG)\n\t\tifobj->multi_buff_supp = true;\n\tif (query_opts.feature_flags & NETDEV_XDP_ACT_XSK_ZEROCOPY) {\n\t\tif (query_opts.xdp_zc_max_segs > 1) {\n\t\t\tifobj->multi_buff_zc_supp = true;\n\t\t\tifobj->xdp_zc_max_segs = query_opts.xdp_zc_max_segs;\n\t\t} else {\n\t\t\tifobj->xdp_zc_max_segs = 0;\n\t\t}\n\t}\n}\n\nstatic void run_pkt_test(struct test_spec *test, enum test_mode mode, enum test_type type)\n{\n\tint ret = TEST_SKIP;\n\n\tswitch (type) {\n\tcase TEST_TYPE_STATS_RX_DROPPED:\n\t\tret = testapp_stats_rx_dropped(test);\n\t\tbreak;\n\tcase TEST_TYPE_STATS_TX_INVALID_DESCS:\n\t\tret = testapp_stats_tx_invalid_descs(test);\n\t\tbreak;\n\tcase TEST_TYPE_STATS_RX_FULL:\n\t\tret = testapp_stats_rx_full(test);\n\t\tbreak;\n\tcase TEST_TYPE_STATS_FILL_EMPTY:\n\t\tret = testapp_stats_fill_empty(test);\n\t\tbreak;\n\tcase TEST_TYPE_TEARDOWN:\n\t\tret = testapp_teardown(test);\n\t\tbreak;\n\tcase TEST_TYPE_BIDI:\n\t\tret = testapp_bidi(test);\n\t\tbreak;\n\tcase TEST_TYPE_BPF_RES:\n\t\tret = testapp_bpf_res(test);\n\t\tbreak;\n\tcase TEST_TYPE_RUN_TO_COMPLETION:\n\t\ttest_spec_set_name(test, \"RUN_TO_COMPLETION\");\n\t\tret = testapp_validate_traffic(test);\n\t\tbreak;\n\tcase TEST_TYPE_RUN_TO_COMPLETION_MB:\n\t\tret = testapp_multi_buffer(test);\n\t\tbreak;\n\tcase TEST_TYPE_RUN_TO_COMPLETION_SINGLE_PKT:\n\t\ttest_spec_set_name(test, \"RUN_TO_COMPLETION_SINGLE_PKT\");\n\t\tret = testapp_single_pkt(test);\n\t\tbreak;\n\tcase TEST_TYPE_RUN_TO_COMPLETION_2K_FRAME:\n\t\ttest_spec_set_name(test, \"RUN_TO_COMPLETION_2K_FRAME_SIZE\");\n\t\ttest->ifobj_tx->umem->frame_size = 2048;\n\t\ttest->ifobj_rx->umem->frame_size = 2048;\n\t\tpkt_stream_replace(test, DEFAULT_PKT_CNT, MIN_PKT_SIZE);\n\t\tret = testapp_validate_traffic(test);\n\t\tbreak;\n\tcase TEST_TYPE_RX_POLL:\n\t\ttest->ifobj_rx->use_poll = true;\n\t\ttest_spec_set_name(test, \"POLL_RX\");\n\t\tret = testapp_validate_traffic(test);\n\t\tbreak;\n\tcase TEST_TYPE_TX_POLL:\n\t\ttest->ifobj_tx->use_poll = true;\n\t\ttest_spec_set_name(test, \"POLL_TX\");\n\t\tret = testapp_validate_traffic(test);\n\t\tbreak;\n\tcase TEST_TYPE_POLL_TXQ_TMOUT:\n\t\tret = testapp_poll_txq_tmout(test);\n\t\tbreak;\n\tcase TEST_TYPE_POLL_RXQ_TMOUT:\n\t\tret = testapp_poll_rxq_tmout(test);\n\t\tbreak;\n\tcase TEST_TYPE_ALIGNED_INV_DESC:\n\t\ttest_spec_set_name(test, \"ALIGNED_INV_DESC\");\n\t\tret = testapp_invalid_desc(test);\n\t\tbreak;\n\tcase TEST_TYPE_ALIGNED_INV_DESC_2K_FRAME:\n\t\ttest_spec_set_name(test, \"ALIGNED_INV_DESC_2K_FRAME_SIZE\");\n\t\ttest->ifobj_tx->umem->frame_size = 2048;\n\t\ttest->ifobj_rx->umem->frame_size = 2048;\n\t\tret = testapp_invalid_desc(test);\n\t\tbreak;\n\tcase TEST_TYPE_UNALIGNED_INV_DESC:\n\t\ttest_spec_set_name(test, \"UNALIGNED_INV_DESC\");\n\t\ttest->ifobj_tx->umem->unaligned_mode = true;\n\t\ttest->ifobj_rx->umem->unaligned_mode = true;\n\t\tret = testapp_invalid_desc(test);\n\t\tbreak;\n\tcase TEST_TYPE_UNALIGNED_INV_DESC_4K1_FRAME: {\n\t\tu64 page_size, umem_size;\n\n\t\ttest_spec_set_name(test, \"UNALIGNED_INV_DESC_4K1_FRAME_SIZE\");\n\t\t \n\t\ttest->ifobj_tx->umem->frame_size = 4001;\n\t\ttest->ifobj_rx->umem->frame_size = 4001;\n\t\ttest->ifobj_tx->umem->unaligned_mode = true;\n\t\ttest->ifobj_rx->umem->unaligned_mode = true;\n\t\t \n\t\tpage_size = sysconf(_SC_PAGESIZE);\n\t\tumem_size = test->ifobj_tx->umem->num_frames * test->ifobj_tx->umem->frame_size;\n\t\tassert(umem_size % page_size > MIN_PKT_SIZE);\n\t\tassert(umem_size % page_size < page_size - MIN_PKT_SIZE);\n\t\tret = testapp_invalid_desc(test);\n\t\tbreak;\n\t}\n\tcase TEST_TYPE_ALIGNED_INV_DESC_MB:\n\t\ttest_spec_set_name(test, \"ALIGNED_INV_DESC_MULTI_BUFF\");\n\t\tret = testapp_invalid_desc_mb(test);\n\t\tbreak;\n\tcase TEST_TYPE_UNALIGNED_INV_DESC_MB:\n\t\ttest_spec_set_name(test, \"UNALIGNED_INV_DESC_MULTI_BUFF\");\n\t\ttest->ifobj_tx->umem->unaligned_mode = true;\n\t\ttest->ifobj_rx->umem->unaligned_mode = true;\n\t\tret = testapp_invalid_desc_mb(test);\n\t\tbreak;\n\tcase TEST_TYPE_UNALIGNED:\n\t\tret = testapp_unaligned(test);\n\t\tbreak;\n\tcase TEST_TYPE_UNALIGNED_MB:\n\t\tret = testapp_unaligned_mb(test);\n\t\tbreak;\n\tcase TEST_TYPE_HEADROOM:\n\t\tret = testapp_headroom(test);\n\t\tbreak;\n\tcase TEST_TYPE_XDP_DROP_HALF:\n\t\tret = testapp_xdp_drop(test);\n\t\tbreak;\n\tcase TEST_TYPE_XDP_METADATA_COUNT:\n\t\ttest_spec_set_name(test, \"XDP_METADATA_COUNT\");\n\t\tret = testapp_xdp_metadata_count(test);\n\t\tbreak;\n\tcase TEST_TYPE_XDP_METADATA_COUNT_MB:\n\t\ttest_spec_set_name(test, \"XDP_METADATA_COUNT_MULTI_BUFF\");\n\t\ttest->mtu = MAX_ETH_JUMBO_SIZE;\n\t\tret = testapp_xdp_metadata_count(test);\n\t\tbreak;\n\tcase TEST_TYPE_TOO_MANY_FRAGS:\n\t\tret = testapp_too_many_frags(test);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (ret == TEST_PASS)\n\t\tksft_test_result_pass(\"PASS: %s %s%s\\n\", mode_string(test), busy_poll_string(test),\n\t\t\t\t      test->name);\n\tpkt_stream_restore_default(test);\n}\n\nstatic struct ifobject *ifobject_create(void)\n{\n\tstruct ifobject *ifobj;\n\n\tifobj = calloc(1, sizeof(struct ifobject));\n\tif (!ifobj)\n\t\treturn NULL;\n\n\tifobj->xsk_arr = calloc(MAX_SOCKETS, sizeof(*ifobj->xsk_arr));\n\tif (!ifobj->xsk_arr)\n\t\tgoto out_xsk_arr;\n\n\tifobj->umem = calloc(1, sizeof(*ifobj->umem));\n\tif (!ifobj->umem)\n\t\tgoto out_umem;\n\n\treturn ifobj;\n\nout_umem:\n\tfree(ifobj->xsk_arr);\nout_xsk_arr:\n\tfree(ifobj);\n\treturn NULL;\n}\n\nstatic void ifobject_delete(struct ifobject *ifobj)\n{\n\tfree(ifobj->umem);\n\tfree(ifobj->xsk_arr);\n\tfree(ifobj);\n}\n\nstatic bool is_xdp_supported(int ifindex)\n{\n\tint flags = XDP_FLAGS_DRV_MODE;\n\n\tLIBBPF_OPTS(bpf_link_create_opts, opts, .flags = flags);\n\tstruct bpf_insn insns[2] = {\n\t\tBPF_MOV64_IMM(BPF_REG_0, XDP_PASS),\n\t\tBPF_EXIT_INSN()\n\t};\n\tint prog_fd, insn_cnt = ARRAY_SIZE(insns);\n\tint err;\n\n\tprog_fd = bpf_prog_load(BPF_PROG_TYPE_XDP, NULL, \"GPL\", insns, insn_cnt, NULL);\n\tif (prog_fd < 0)\n\t\treturn false;\n\n\terr = bpf_xdp_attach(ifindex, prog_fd, flags, NULL);\n\tif (err) {\n\t\tclose(prog_fd);\n\t\treturn false;\n\t}\n\n\tbpf_xdp_detach(ifindex, flags, NULL);\n\tclose(prog_fd);\n\n\treturn true;\n}\n\nint main(int argc, char **argv)\n{\n\tstruct pkt_stream *rx_pkt_stream_default;\n\tstruct pkt_stream *tx_pkt_stream_default;\n\tstruct ifobject *ifobj_tx, *ifobj_rx;\n\tint modes = TEST_MODE_SKB + 1;\n\tu32 i, j, failed_tests = 0;\n\tstruct test_spec test;\n\tbool shared_netdev;\n\n\t \n\tlibbpf_set_strict_mode(LIBBPF_STRICT_ALL);\n\n\tifobj_tx = ifobject_create();\n\tif (!ifobj_tx)\n\t\texit_with_error(ENOMEM);\n\tifobj_rx = ifobject_create();\n\tif (!ifobj_rx)\n\t\texit_with_error(ENOMEM);\n\n\tsetlocale(LC_ALL, \"\");\n\n\tparse_command_line(ifobj_tx, ifobj_rx, argc, argv);\n\n\tshared_netdev = (ifobj_tx->ifindex == ifobj_rx->ifindex);\n\tifobj_tx->shared_umem = shared_netdev;\n\tifobj_rx->shared_umem = shared_netdev;\n\n\tif (!validate_interface(ifobj_tx) || !validate_interface(ifobj_rx)) {\n\t\tusage(basename(argv[0]));\n\t\tksft_exit_xfail();\n\t}\n\n\tif (is_xdp_supported(ifobj_tx->ifindex)) {\n\t\tmodes++;\n\t\tif (ifobj_zc_avail(ifobj_tx))\n\t\t\tmodes++;\n\t}\n\n\tinit_iface(ifobj_rx, MAC1, MAC2, worker_testapp_validate_rx);\n\tinit_iface(ifobj_tx, MAC2, MAC1, worker_testapp_validate_tx);\n\n\ttest_spec_init(&test, ifobj_tx, ifobj_rx, 0);\n\ttx_pkt_stream_default = pkt_stream_generate(ifobj_tx->umem, DEFAULT_PKT_CNT, MIN_PKT_SIZE);\n\trx_pkt_stream_default = pkt_stream_generate(ifobj_rx->umem, DEFAULT_PKT_CNT, MIN_PKT_SIZE);\n\tif (!tx_pkt_stream_default || !rx_pkt_stream_default)\n\t\texit_with_error(ENOMEM);\n\ttest.tx_pkt_stream_default = tx_pkt_stream_default;\n\ttest.rx_pkt_stream_default = rx_pkt_stream_default;\n\n\tksft_set_plan(modes * TEST_TYPE_MAX);\n\n\tfor (i = 0; i < modes; i++) {\n\t\tfor (j = 0; j < TEST_TYPE_MAX; j++) {\n\t\t\ttest_spec_init(&test, ifobj_tx, ifobj_rx, i);\n\t\t\trun_pkt_test(&test, i, j);\n\t\t\tusleep(USLEEP_MAX);\n\n\t\t\tif (test.fail)\n\t\t\t\tfailed_tests++;\n\t\t}\n\t}\n\n\tpkt_stream_delete(tx_pkt_stream_default);\n\tpkt_stream_delete(rx_pkt_stream_default);\n\txsk_unload_xdp_programs(ifobj_tx);\n\txsk_unload_xdp_programs(ifobj_rx);\n\tifobject_delete(ifobj_tx);\n\tifobject_delete(ifobj_rx);\n\n\tif (failed_tests)\n\t\tksft_exit_fail();\n\telse\n\t\tksft_exit_pass();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}