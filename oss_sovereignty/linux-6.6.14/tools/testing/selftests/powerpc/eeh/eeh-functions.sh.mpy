{
  "module_name": "eeh-functions.sh",
  "hash_id": "03715c45e6002f0ce8b1e36cfdb90cd31f733e9bfec6c8fb0577cae904b24415",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/powerpc/eeh/eeh-functions.sh",
  "human_readable_source": "#!/bin/sh\n# SPDX-License-Identifier: GPL-2.0-only\n\nexport KSELFTESTS_SKIP=4\n\nlog() {\n\techo >/dev/stderr $*\n}\n\npe_ok() {\n\tlocal dev=\"$1\"\n\tlocal path=\"/sys/bus/pci/devices/$dev/eeh_pe_state\"\n\n\t# if a driver doesn't support the error handling callbacks then the\n\t# device is recovered by removing and re-probing it. This causes the\n\t# sysfs directory to disappear so read the PE state once and squash\n\t# any potential error messages\n\tlocal eeh_state=\"$(cat $path 2>/dev/null)\"\n\tif [ -z \"$eeh_state\" ]; then\n\t\treturn 1;\n\tfi\n\n\tlocal fw_state=\"$(echo $eeh_state | cut -d' ' -f1)\"\n\tlocal sw_state=\"$(echo $eeh_state | cut -d' ' -f2)\"\n\n\t# If EEH_PE_ISOLATED or EEH_PE_RECOVERING are set then the PE is in an\n\t# error state or being recovered. Either way, not ok.\n\tif [ \"$((sw_state & 0x3))\" -ne 0 ] ; then\n\t\treturn 1\n\tfi\n\n\t# A functioning PE should have the EEH_STATE_MMIO_ACTIVE and\n\t# EEH_STATE_DMA_ACTIVE flags set. For some goddamn stupid reason\n\t# the platform backends set these when the PE is in reset. The\n\t# RECOVERING check above should stop any false positives though.\n\tif [ \"$((fw_state & 0x18))\" -ne \"$((0x18))\" ] ; then\n\t\treturn 1\n\tfi\n\n\treturn 0;\n}\n\neeh_supported() {\n\ttest -e /proc/powerpc/eeh && \\\n\tgrep -q 'EEH Subsystem is enabled' /proc/powerpc/eeh\n}\n\neeh_test_prep() {\n\tif ! eeh_supported ; then\n\t\techo \"EEH not supported on this system, skipping\"\n\t\texit $KSELFTESTS_SKIP;\n\tfi\n\n\tif [ ! -e \"/sys/kernel/debug/powerpc/eeh_dev_check\" ] && \\\n\t   [ ! -e \"/sys/kernel/debug/powerpc/eeh_dev_break\" ] ; then\n\t\tlog \"debugfs EEH testing files are missing. Is debugfs mounted?\"\n\t\texit $KSELFTESTS_SKIP;\n\tfi\n\n\t# Bump the max freeze count to something absurd so we don't\n\t# trip over it while breaking things.\n\techo 5000 > /sys/kernel/debug/powerpc/eeh_max_freezes\n}\n\neeh_can_break() {\n\t# skip bridges since we can't recover them (yet...)\n\tif [ -e \"/sys/bus/pci/devices/$dev/pci_bus\" ] ; then\n\t\tlog \"$dev, Skipped: bridge\"\n\t\treturn 1;\n\tfi\n\n\t# The ahci driver doesn't support error recovery. If the ahci device\n\t# happens to be hosting the root filesystem, and then we go and break\n\t# it the system will generally go down. We should probably fix that\n\t# at some point\n\tif [ \"ahci\" = \"$(basename $(realpath /sys/bus/pci/devices/$dev/driver))\" ] ; then\n\t\tlog \"$dev, Skipped: ahci doesn't support recovery\"\n\t\treturn 1;\n\tfi\n\n\t# Don't inject errosr into an already-frozen PE. This happens with\n\t# PEs that contain multiple PCI devices (e.g. multi-function cards)\n\t# and injecting new errors during the recovery process will probably\n\t# result in the recovery failing and the device being marked as\n\t# failed.\n\tif ! pe_ok $dev ; then\n\t\tlog \"$dev, Skipped: Bad initial PE state\"\n\t\treturn 1;\n\tfi\n\n\treturn 0\n}\n\neeh_one_dev() {\n\tlocal dev=\"$1\"\n\n\t# Using this function from the command line is sometimes useful for\n\t# testing so check that the argument is a well-formed sysfs device\n\t# name.\n\tif ! test -e /sys/bus/pci/devices/$dev/ ; then\n\t\tlog \"Error: '$dev' must be a sysfs device name (DDDD:BB:DD.F)\"\n\t\treturn 1;\n\tfi\n\n\t# Break it\n\techo $dev >/sys/kernel/debug/powerpc/eeh_dev_break\n\n\t# Force an EEH device check. If the kernel has already\n\t# noticed the EEH (due to a driver poll or whatever), this\n\t# is a no-op.\n\techo $dev >/sys/kernel/debug/powerpc/eeh_dev_check\n\n\t# Default to a 60s timeout when waiting for a device to recover. This\n\t# is an arbitrary default which can be overridden by setting the\n\t# EEH_MAX_WAIT environmental variable when required.\n\n\t# The current record holder for longest recovery time is:\n\t#  \"Adaptec Series 8 12G SAS/PCIe 3\" at 39 seconds\n\tmax_wait=${EEH_MAX_WAIT:=60}\n\n\tfor i in `seq 0 ${max_wait}` ; do\n\t\tif pe_ok $dev ; then\n\t\t\tbreak;\n\t\tfi\n\t\tlog \"$dev, waited $i/${max_wait}\"\n\t\tsleep 1\n\tdone\n\n\tif ! pe_ok $dev ; then\n\t\tlog \"$dev, Failed to recover!\"\n\t\treturn 1;\n\tfi\n\n\tlog \"$dev, Recovered after $i seconds\"\n\treturn 0;\n}\n\neeh_has_driver() {\n\ttest -e /sys/bus/pci/devices/$1/driver;\n\treturn $?\n}\n\neeh_can_recover() {\n\t# we'll get an IO error if the device's current driver doesn't support\n\t# error recovery\n\techo $1 > '/sys/kernel/debug/powerpc/eeh_dev_can_recover' 2>/dev/null\n\n\treturn $?\n}\n\neeh_find_all_pfs() {\n\tdevices=\"\"\n\n\t# SR-IOV on pseries requires hypervisor support, so check for that\n\tis_pseries=\"\"\n\tif grep -q pSeries /proc/cpuinfo ; then\n\t\tif [ ! -f /proc/device-tree/rtas/ibm,open-sriov-allow-unfreeze ] ||\n\t\t   [ ! -f /proc/device-tree/rtas/ibm,open-sriov-map-pe-number ] ; then\n\t\t\treturn 1;\n\t\tfi\n\n\t\tis_pseries=\"true\"\n\tfi\n\n\tfor dev in `ls -1 /sys/bus/pci/devices/` ; do\n\t\tsysfs=\"/sys/bus/pci/devices/$dev\"\n\t\tif [ ! -e \"$sysfs/sriov_numvfs\" ] ; then\n\t\t\tcontinue\n\t\tfi\n\n\t\t# skip unsupported PFs on pseries\n\t\tif [ -z \"$is_pseries\" ] &&\n\t\t   [ ! -f \"$sysfs/of_node/ibm,is-open-sriov-pf\" ] &&\n\t\t   [ ! -f \"$sysfs/of_node/ibm,open-sriov-vf-bar-info\" ] ; then\n\t\t\tcontinue;\n\t\tfi\n\n\t\t# no driver, no vfs\n\t\tif ! eeh_has_driver $dev ; then\n\t\t\tcontinue\n\t\tfi\n\n\t\tdevices=\"$devices $dev\"\n\tdone\n\n\tif [ -z \"$devices\" ] ; then\n\t\treturn 1;\n\tfi\n\n\techo $devices\n\treturn 0;\n}\n\n# attempts to enable one VF on each PF so we can do VF specific tests.\n# stdout: list of enabled VFs, one per line\n# return code: 0 if vfs are found, 1 otherwise\neeh_enable_vfs() {\n\tpf_list=\"$(eeh_find_all_pfs)\"\n\n\tvfs=0\n\tfor dev in $pf_list ; do\n\t\tpf_sysfs=\"/sys/bus/pci/devices/$dev\"\n\n\t\t# make sure we have a single VF\n\t\techo 0 > \"$pf_sysfs/sriov_numvfs\"\n\t\techo 1 > \"$pf_sysfs/sriov_numvfs\"\n\t\tif [ \"$?\" != 0 ] ; then\n\t\t\tlog \"Unable to enable VFs on $pf, skipping\"\n\t\t\tcontinue;\n\t\tfi\n\n\t\tvf=\"$(basename $(realpath \"$pf_sysfs/virtfn0\"))\"\n\t\tif [ $? != 0 ] ; then\n\t\t\tlog \"unable to find enabled vf on $pf\"\n\t\t\techo 0 > \"$pf_sysfs/sriov_numvfs\"\n\t\t\tcontinue;\n\t\tfi\n\n\t\tif ! eeh_can_break $vf ; then\n\t\t\tlog \"skipping \"\n\n\t\t\techo 0 > \"$pf_sysfs/sriov_numvfs\"\n\t\t\tcontinue;\n\t\tfi\n\n\t\tvfs=\"$((vfs + 1))\"\n\t\techo $vf\n\tdone\n\n\ttest \"$vfs\" != 0\n\treturn $?\n}\n\neeh_disable_vfs() {\n\tpf_list=\"$(eeh_find_all_pfs)\"\n\tif [ -z \"$pf_list\" ] ; then\n\t\treturn 1;\n\tfi\n\n\tfor dev in $pf_list ; do\n\t\techo 0 > \"/sys/bus/pci/devices/$dev/sriov_numvfs\"\n\tdone\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}