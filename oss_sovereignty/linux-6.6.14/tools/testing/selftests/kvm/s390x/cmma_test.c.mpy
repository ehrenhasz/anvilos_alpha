{
  "module_name": "cmma_test.c",
  "hash_id": "982639cc34f4409502f13ff7d24be0f73dff2def8add8e004fdbd11e7ee00031",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/s390x/cmma_test.c",
  "human_readable_source": "\n \n\n#define _GNU_SOURCE  \n#include <fcntl.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/ioctl.h>\n\n#include \"test_util.h\"\n#include \"kvm_util.h\"\n#include \"kselftest.h\"\n\n#define MAIN_PAGE_COUNT 512\n\n#define TEST_DATA_PAGE_COUNT 512\n#define TEST_DATA_MEMSLOT 1\n#define TEST_DATA_START_GFN 4096\n\n#define TEST_DATA_TWO_PAGE_COUNT 256\n#define TEST_DATA_TWO_MEMSLOT 2\n#define TEST_DATA_TWO_START_GFN 8192\n\nstatic char cmma_value_buf[MAIN_PAGE_COUNT + TEST_DATA_PAGE_COUNT];\n\n \nstatic void guest_do_one_essa(void)\n{\n\tasm volatile(\n\t\t \n\t\t\"\tllilf 1,%[start_gfn]\\n\"\n\t\t \n\t\t\"\tsllg 1,1,12(0)\\n\"\n\t\t \n\t\t\"\t.insn rrf,0xb9ab0000,2,1,1,0\\n\"\n\t\t \n\t\t\"\tdiag 0,0,0x501\\n\"\n\t\t\"0:\tj 0b\"\n\t\t:\n\t\t: [start_gfn] \"L\"(TEST_DATA_START_GFN)\n\t\t: \"r1\", \"r2\", \"memory\", \"cc\"\n\t);\n}\n\n \nstatic void guest_dirty_test_data(void)\n{\n\tasm volatile(\n\t\t \n\t\t\"\txgr 1,1\\n\"\n\t\t\"\tllilf 1,%[start_gfn]\\n\"\n\t\t \n\t\t\"\tlghi 5,%[page_count]\\n\"\n\t\t \n\t\t\"2:\tagfr 5,1\\n\"\n\t\t \n\t\t\"1:\tsllg 2,1,12(0)\\n\"\n\t\t \n\t\t\"\t.insn rrf,0xb9ab0000,4,2,1,0\\n\"\n\t\t \n\t\t\"\tagfi 1,1\\n\"\n\t\t \n\t\t\"\tcgrjl 1,5,1b\\n\"\n\t\t \n\t\t\"\tdiag 0,0,0x501\\n\"\n\t\t\"0:\tj 0b\"\n\t\t:\n\t\t: [start_gfn] \"L\"(TEST_DATA_START_GFN),\n\t\t  [page_count] \"L\"(TEST_DATA_PAGE_COUNT)\n\t\t:\n\t\t\t \n\t\t\t\"r1\",\n\t\t\t \n\t\t\t\"r2\",\n\t\t\t \n\t\t\t\"r4\",\n\t\t\t \n\t\t\t\"r5\",\n\t\t\t\"cc\", \"memory\"\n\t);\n}\n\nstatic struct kvm_vm *create_vm(void)\n{\n\treturn ____vm_create(VM_MODE_DEFAULT);\n}\n\nstatic void create_main_memslot(struct kvm_vm *vm)\n{\n\tint i;\n\n\tvm_userspace_mem_region_add(vm, VM_MEM_SRC_ANONYMOUS, 0, 0, MAIN_PAGE_COUNT, 0);\n\t \n\tfor (i = 0; i < NR_MEM_REGIONS; i++)\n\t\tvm->memslots[i] = 0;\n}\n\nstatic void create_test_memslot(struct kvm_vm *vm)\n{\n\tvm_userspace_mem_region_add(vm,\n\t\t\t\t    VM_MEM_SRC_ANONYMOUS,\n\t\t\t\t    TEST_DATA_START_GFN << vm->page_shift,\n\t\t\t\t    TEST_DATA_MEMSLOT,\n\t\t\t\t    TEST_DATA_PAGE_COUNT,\n\t\t\t\t    0\n\t\t\t\t   );\n\tvm->memslots[MEM_REGION_TEST_DATA] = TEST_DATA_MEMSLOT;\n}\n\nstatic void create_memslots(struct kvm_vm *vm)\n{\n\t \n\tcreate_main_memslot(vm);\n\tcreate_test_memslot(vm);\n}\n\nstatic void finish_vm_setup(struct kvm_vm *vm)\n{\n\tstruct userspace_mem_region *slot0;\n\n\tkvm_vm_elf_load(vm, program_invocation_name);\n\n\tslot0 = memslot2region(vm, 0);\n\tucall_init(vm, slot0->region.guest_phys_addr + slot0->region.memory_size);\n\n\tkvm_arch_vm_post_create(vm);\n}\n\nstatic struct kvm_vm *create_vm_two_memslots(void)\n{\n\tstruct kvm_vm *vm;\n\n\tvm = create_vm();\n\n\tcreate_memslots(vm);\n\n\tfinish_vm_setup(vm);\n\n\treturn vm;\n}\n\nstatic void enable_cmma(struct kvm_vm *vm)\n{\n\tint r;\n\n\tr = __kvm_device_attr_set(vm->fd, KVM_S390_VM_MEM_CTRL, KVM_S390_VM_MEM_ENABLE_CMMA, NULL);\n\tTEST_ASSERT(!r, \"enabling cmma failed r=%d errno=%d\", r, errno);\n}\n\nstatic void enable_dirty_tracking(struct kvm_vm *vm)\n{\n\tvm_mem_region_set_flags(vm, 0, KVM_MEM_LOG_DIRTY_PAGES);\n\tvm_mem_region_set_flags(vm, TEST_DATA_MEMSLOT, KVM_MEM_LOG_DIRTY_PAGES);\n}\n\nstatic int __enable_migration_mode(struct kvm_vm *vm)\n{\n\treturn __kvm_device_attr_set(vm->fd,\n\t\t\t\t     KVM_S390_VM_MIGRATION,\n\t\t\t\t     KVM_S390_VM_MIGRATION_START,\n\t\t\t\t     NULL\n\t\t\t\t    );\n}\n\nstatic void enable_migration_mode(struct kvm_vm *vm)\n{\n\tint r = __enable_migration_mode(vm);\n\n\tTEST_ASSERT(!r, \"enabling migration mode failed r=%d errno=%d\", r, errno);\n}\n\nstatic bool is_migration_mode_on(struct kvm_vm *vm)\n{\n\tu64 out;\n\tint r;\n\n\tr = __kvm_device_attr_get(vm->fd,\n\t\t\t\t  KVM_S390_VM_MIGRATION,\n\t\t\t\t  KVM_S390_VM_MIGRATION_STATUS,\n\t\t\t\t  &out\n\t\t\t\t );\n\tTEST_ASSERT(!r, \"getting migration mode status failed r=%d errno=%d\", r, errno);\n\treturn out;\n}\n\nstatic int vm_get_cmma_bits(struct kvm_vm *vm, u64 flags, int *errno_out)\n{\n\tstruct kvm_s390_cmma_log args;\n\tint rc;\n\n\terrno = 0;\n\n\targs = (struct kvm_s390_cmma_log){\n\t\t.start_gfn = 0,\n\t\t.count = sizeof(cmma_value_buf),\n\t\t.flags = flags,\n\t\t.values = (__u64)&cmma_value_buf[0]\n\t};\n\trc = __vm_ioctl(vm, KVM_S390_GET_CMMA_BITS, &args);\n\n\t*errno_out = errno;\n\treturn rc;\n}\n\nstatic void test_get_cmma_basic(void)\n{\n\tstruct kvm_vm *vm = create_vm_two_memslots();\n\tstruct kvm_vcpu *vcpu;\n\tint rc, errno_out;\n\n\t \n\trc = vm_get_cmma_bits(vm, 0, &errno_out);\n\tTEST_ASSERT_EQ(rc, -1);\n\tTEST_ASSERT_EQ(errno_out, ENXIO);\n\n\tenable_cmma(vm);\n\tvcpu = vm_vcpu_add(vm, 1, guest_do_one_essa);\n\n\tvcpu_run(vcpu);\n\n\t \n\trc = vm_get_cmma_bits(vm, 0, &errno_out);\n\tTEST_ASSERT_EQ(rc, -1);\n\tTEST_ASSERT_EQ(errno_out, EINVAL);\n\n\t \n\trc = vm_get_cmma_bits(vm, KVM_S390_CMMA_PEEK, &errno_out);\n\tTEST_ASSERT_EQ(rc, 0);\n\tTEST_ASSERT_EQ(errno_out, 0);\n\n\tenable_dirty_tracking(vm);\n\tenable_migration_mode(vm);\n\n\t \n\trc = vm_get_cmma_bits(vm, 0xfeedc0fe, &errno_out);\n\tTEST_ASSERT_EQ(rc, -1);\n\tTEST_ASSERT_EQ(errno_out, EINVAL);\n\n\tkvm_vm_free(vm);\n}\n\nstatic void assert_exit_was_hypercall(struct kvm_vcpu *vcpu)\n{\n\tTEST_ASSERT_EQ(vcpu->run->exit_reason, 13);\n\tTEST_ASSERT_EQ(vcpu->run->s390_sieic.icptcode, 4);\n\tTEST_ASSERT_EQ(vcpu->run->s390_sieic.ipa, 0x8300);\n\tTEST_ASSERT_EQ(vcpu->run->s390_sieic.ipb, 0x5010000);\n}\n\nstatic void test_migration_mode(void)\n{\n\tstruct kvm_vm *vm = create_vm();\n\tstruct kvm_vcpu *vcpu;\n\tu64 orig_psw;\n\tint rc;\n\n\t \n\trc = __enable_migration_mode(vm);\n\tTEST_ASSERT_EQ(rc, -1);\n\tTEST_ASSERT_EQ(errno, EINVAL);\n\tTEST_ASSERT(!is_migration_mode_on(vm), \"migration mode should still be off\");\n\terrno = 0;\n\n\tcreate_memslots(vm);\n\tfinish_vm_setup(vm);\n\n\tenable_cmma(vm);\n\tvcpu = vm_vcpu_add(vm, 1, guest_do_one_essa);\n\torig_psw = vcpu->run->psw_addr;\n\n\t \n\tvcpu_run(vcpu);\n\tassert_exit_was_hypercall(vcpu);\n\n\t \n\trc = __enable_migration_mode(vm);\n\tTEST_ASSERT_EQ(rc, -1);\n\tTEST_ASSERT_EQ(errno, EINVAL);\n\tTEST_ASSERT(!is_migration_mode_on(vm), \"migration mode should still be off\");\n\terrno = 0;\n\n\t \n\tenable_dirty_tracking(vm);\n\n\t \n\trc = __enable_migration_mode(vm);\n\tTEST_ASSERT_EQ(rc, 0);\n\tTEST_ASSERT(is_migration_mode_on(vm), \"migration mode should be on\");\n\terrno = 0;\n\n\t \n\tvcpu->run->psw_addr = orig_psw;\n\tvcpu_run(vcpu);\n\tassert_exit_was_hypercall(vcpu);\n\n\t \n\tTEST_ASSERT(is_migration_mode_on(vm), \"migration mode should be on\");\n\tvm_userspace_mem_region_add(vm,\n\t\t\t\t    VM_MEM_SRC_ANONYMOUS,\n\t\t\t\t    TEST_DATA_TWO_START_GFN << vm->page_shift,\n\t\t\t\t    TEST_DATA_TWO_MEMSLOT,\n\t\t\t\t    TEST_DATA_TWO_PAGE_COUNT,\n\t\t\t\t    0\n\t\t\t\t   );\n\tTEST_ASSERT(!is_migration_mode_on(vm),\n\t\t    \"creating memslot without dirty tracking turns off migration mode\"\n\t\t   );\n\n\t \n\tvcpu->run->psw_addr = orig_psw;\n\tvcpu_run(vcpu);\n\tassert_exit_was_hypercall(vcpu);\n\n\t \n\tvm_mem_region_set_flags(vm, TEST_DATA_TWO_MEMSLOT, KVM_MEM_LOG_DIRTY_PAGES);\n\trc = __enable_migration_mode(vm);\n\tTEST_ASSERT_EQ(rc, 0);\n\tTEST_ASSERT(is_migration_mode_on(vm), \"migration mode should be on\");\n\terrno = 0;\n\n\t \n\tTEST_ASSERT(is_migration_mode_on(vm), \"migration mode should be on\");\n\tvm_mem_region_set_flags(vm, TEST_DATA_TWO_MEMSLOT, 0);\n\tTEST_ASSERT(!is_migration_mode_on(vm),\n\t\t    \"disabling dirty tracking should turn off migration mode\"\n\t\t   );\n\n\t \n\tvcpu->run->psw_addr = orig_psw;\n\tvcpu_run(vcpu);\n\tassert_exit_was_hypercall(vcpu);\n\n\tkvm_vm_free(vm);\n}\n\n \nstatic void assert_all_slots_cmma_dirty(struct kvm_vm *vm)\n{\n\tstruct kvm_s390_cmma_log args;\n\n\t \n\targs = (struct kvm_s390_cmma_log){\n\t\t.start_gfn = 0,\n\t\t.count = sizeof(cmma_value_buf),\n\t\t.flags = 0,\n\t\t.values = (__u64)&cmma_value_buf[0]\n\t};\n\tmemset(cmma_value_buf, 0xff, sizeof(cmma_value_buf));\n\tvm_ioctl(vm, KVM_S390_GET_CMMA_BITS, &args);\n\tTEST_ASSERT_EQ(args.count, MAIN_PAGE_COUNT);\n\tTEST_ASSERT_EQ(args.remaining, TEST_DATA_PAGE_COUNT);\n\tTEST_ASSERT_EQ(args.start_gfn, 0);\n\n\t \n\targs = (struct kvm_s390_cmma_log){\n\t\t.start_gfn = MAIN_PAGE_COUNT,\n\t\t.count = sizeof(cmma_value_buf),\n\t\t.flags = 0,\n\t\t.values = (__u64)&cmma_value_buf[0]\n\t};\n\tmemset(cmma_value_buf, 0xff, sizeof(cmma_value_buf));\n\tvm_ioctl(vm, KVM_S390_GET_CMMA_BITS, &args);\n\tTEST_ASSERT_EQ(args.count, TEST_DATA_PAGE_COUNT);\n\tTEST_ASSERT_EQ(args.start_gfn, TEST_DATA_START_GFN);\n\tTEST_ASSERT_EQ(args.remaining, 0);\n\n\t \n\targs = (struct kvm_s390_cmma_log){\n\t\t.start_gfn = TEST_DATA_START_GFN + TEST_DATA_PAGE_COUNT,\n\t\t.count = sizeof(cmma_value_buf),\n\t\t.flags = 0,\n\t\t.values = (__u64)&cmma_value_buf[0]\n\t};\n\tmemset(cmma_value_buf, 0xff, sizeof(cmma_value_buf));\n\tvm_ioctl(vm, KVM_S390_GET_CMMA_BITS, &args);\n\tTEST_ASSERT_EQ(args.count, 0);\n\tTEST_ASSERT_EQ(args.start_gfn, 0);\n\tTEST_ASSERT_EQ(args.remaining, 0);\n}\n\n \nstatic void assert_no_pages_cmma_dirty(struct kvm_vm *vm)\n{\n\tstruct kvm_s390_cmma_log args;\n\n\t \n\targs = (struct kvm_s390_cmma_log){\n\t\t.start_gfn = 0,\n\t\t.count = sizeof(cmma_value_buf),\n\t\t.flags = 0,\n\t\t.values = (__u64)&cmma_value_buf[0]\n\t};\n\tmemset(cmma_value_buf, 0xff, sizeof(cmma_value_buf));\n\tvm_ioctl(vm, KVM_S390_GET_CMMA_BITS, &args);\n\tif (args.count || args.remaining || args.start_gfn)\n\t\tTEST_FAIL(\"pages are still dirty start_gfn=0x%llx count=%u remaining=%llu\",\n\t\t\t  args.start_gfn,\n\t\t\t  args.count,\n\t\t\t  args.remaining\n\t\t\t );\n}\n\nstatic void test_get_inital_dirty(void)\n{\n\tstruct kvm_vm *vm = create_vm_two_memslots();\n\tstruct kvm_vcpu *vcpu;\n\n\tenable_cmma(vm);\n\tvcpu = vm_vcpu_add(vm, 1, guest_do_one_essa);\n\n\t \n\tvcpu_run(vcpu);\n\tassert_exit_was_hypercall(vcpu);\n\n\tenable_dirty_tracking(vm);\n\tenable_migration_mode(vm);\n\n\tassert_all_slots_cmma_dirty(vm);\n\n\t \n\tassert_no_pages_cmma_dirty(vm);\n\n\tkvm_vm_free(vm);\n}\n\nstatic void query_cmma_range(struct kvm_vm *vm,\n\t\t\t     u64 start_gfn, u64 gfn_count,\n\t\t\t     struct kvm_s390_cmma_log *res_out)\n{\n\t*res_out = (struct kvm_s390_cmma_log){\n\t\t.start_gfn = start_gfn,\n\t\t.count = gfn_count,\n\t\t.flags = 0,\n\t\t.values = (__u64)&cmma_value_buf[0]\n\t};\n\tmemset(cmma_value_buf, 0xff, sizeof(cmma_value_buf));\n\tvm_ioctl(vm, KVM_S390_GET_CMMA_BITS, res_out);\n}\n\n \nstatic void assert_cmma_dirty(u64 first_dirty_gfn,\n\t\t\t      u64 dirty_gfn_count,\n\t\t\t      const struct kvm_s390_cmma_log *res)\n{\n\tTEST_ASSERT_EQ(res->start_gfn, first_dirty_gfn);\n\tTEST_ASSERT_EQ(res->count, dirty_gfn_count);\n\tfor (size_t i = 0; i < dirty_gfn_count; i++)\n\t\tTEST_ASSERT_EQ(cmma_value_buf[0], 0x0);  \n\tTEST_ASSERT_EQ(cmma_value_buf[dirty_gfn_count], 0xff);  \n}\n\nstatic void test_get_skip_holes(void)\n{\n\tsize_t gfn_offset;\n\tstruct kvm_vm *vm = create_vm_two_memslots();\n\tstruct kvm_s390_cmma_log log;\n\tstruct kvm_vcpu *vcpu;\n\tu64 orig_psw;\n\n\tenable_cmma(vm);\n\tvcpu = vm_vcpu_add(vm, 1, guest_dirty_test_data);\n\n\torig_psw = vcpu->run->psw_addr;\n\n\t \n\tvcpu_run(vcpu);\n\tassert_exit_was_hypercall(vcpu);\n\n\tenable_dirty_tracking(vm);\n\tenable_migration_mode(vm);\n\n\t \n\tassert_all_slots_cmma_dirty(vm);\n\n\t \n\tvcpu->run->psw_addr = orig_psw;\n\tvcpu_run(vcpu);\n\n\tgfn_offset = TEST_DATA_START_GFN;\n\t \n\tquery_cmma_range(vm, 0, 1, &log);\n\tassert_cmma_dirty(gfn_offset, 1, &log);\n\tgfn_offset++;\n\n\t \n\tquery_cmma_range(vm, TEST_DATA_START_GFN + TEST_DATA_PAGE_COUNT, 0x20, &log);\n\tassert_cmma_dirty(gfn_offset, 0x20, &log);\n\tgfn_offset += 0x20;\n\n\t \n\tgfn_offset += 0x20;\n\n\t \n\tquery_cmma_range(vm, gfn_offset, 0x20, &log);\n\tassert_cmma_dirty(gfn_offset, 0x20, &log);\n\tgfn_offset += 0x20;\n\n\t \n\tquery_cmma_range(vm, TEST_DATA_START_GFN, 1, &log);\n\tassert_cmma_dirty(TEST_DATA_START_GFN + 0x21, 1, &log);\n\tgfn_offset++;\n\n\t \n\tgfn_offset = TEST_DATA_START_GFN + 0x23;\n\tquery_cmma_range(vm, gfn_offset, 15, &log);\n\tassert_cmma_dirty(gfn_offset, 15, &log);\n\n\t \n\tgfn_offset = TEST_DATA_START_GFN + 0x22;\n\tquery_cmma_range(vm, gfn_offset, 17, &log);\n\tassert_cmma_dirty(gfn_offset, 17, &log);\n\n\t \n\tgfn_offset = TEST_DATA_START_GFN + 0x40;\n\tquery_cmma_range(vm, gfn_offset, 25, &log);\n\tassert_cmma_dirty(gfn_offset, 1, &log);\n\n\t \n\tgfn_offset = TEST_DATA_START_GFN + 0x33;\n\tquery_cmma_range(vm, gfn_offset, 0x40 - 0x33, &log);\n\tassert_cmma_dirty(gfn_offset, 0x40 - 0x33, &log);\n\n\t \n\tgfn_offset = TEST_DATA_START_GFN;\n\tquery_cmma_range(vm, gfn_offset, TEST_DATA_PAGE_COUNT - 0x61, &log);\n\tassert_cmma_dirty(TEST_DATA_START_GFN + 0x61, TEST_DATA_PAGE_COUNT - 0x61, &log);\n\n\tassert_no_pages_cmma_dirty(vm);\n}\n\nstruct testdef {\n\tconst char *name;\n\tvoid (*test)(void);\n} testlist[] = {\n\t{ \"migration mode and dirty tracking\", test_migration_mode },\n\t{ \"GET_CMMA_BITS: basic calls\", test_get_cmma_basic },\n\t{ \"GET_CMMA_BITS: all pages are dirty initally\", test_get_inital_dirty },\n\t{ \"GET_CMMA_BITS: holes are skipped\", test_get_skip_holes },\n};\n\n \nstatic int machine_has_cmma(void)\n{\n\tstruct kvm_vm *vm = create_vm();\n\tint r;\n\n\tr = !__kvm_has_device_attr(vm->fd, KVM_S390_VM_MEM_CTRL, KVM_S390_VM_MEM_ENABLE_CMMA);\n\tkvm_vm_free(vm);\n\n\treturn r;\n}\n\nint main(int argc, char *argv[])\n{\n\tint idx;\n\n\tTEST_REQUIRE(kvm_has_cap(KVM_CAP_SYNC_REGS));\n\tTEST_REQUIRE(kvm_has_cap(KVM_CAP_S390_CMMA_MIGRATION));\n\tTEST_REQUIRE(machine_has_cmma());\n\n\tksft_print_header();\n\n\tksft_set_plan(ARRAY_SIZE(testlist));\n\n\tfor (idx = 0; idx < ARRAY_SIZE(testlist); idx++) {\n\t\ttestlist[idx].test();\n\t\tksft_test_result_pass(\"%s\\n\", testlist[idx].name);\n\t}\n\n\tksft_finished();\t \n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}