{
  "module_name": "set_memory_region_test.c",
  "hash_id": "aeabc68f609a5bc261500da8a43e963f3b00bdb7e059a201c71858cdcf80b252",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/set_memory_region_test.c",
  "human_readable_source": "\n#define _GNU_SOURCE  \n#include <fcntl.h>\n#include <pthread.h>\n#include <sched.h>\n#include <semaphore.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/ioctl.h>\n#include <sys/mman.h>\n\n#include <linux/compiler.h>\n\n#include <test_util.h>\n#include <kvm_util.h>\n#include <processor.h>\n\n \n#define MEM_REGION_SIZE\t\t0x200000\n\n#ifdef __x86_64__\n \n#define MEM_REGION_GPA\t\t0xc0000000\n#define MEM_REGION_SLOT\t\t10\n\nstatic const uint64_t MMIO_VAL = 0xbeefull;\n\nextern const uint64_t final_rip_start;\nextern const uint64_t final_rip_end;\n\nstatic sem_t vcpu_ready;\n\nstatic inline uint64_t guest_spin_on_val(uint64_t spin_val)\n{\n\tuint64_t val;\n\n\tdo {\n\t\tval = READ_ONCE(*((uint64_t *)MEM_REGION_GPA));\n\t} while (val == spin_val);\n\n\tGUEST_SYNC(0);\n\treturn val;\n}\n\nstatic void *vcpu_worker(void *data)\n{\n\tstruct kvm_vcpu *vcpu = data;\n\tstruct kvm_run *run = vcpu->run;\n\tstruct ucall uc;\n\tuint64_t cmd;\n\n\t \n\twhile (1) {\n\t\tvcpu_run(vcpu);\n\n\t\tif (run->exit_reason == KVM_EXIT_IO) {\n\t\t\tcmd = get_ucall(vcpu, &uc);\n\t\t\tif (cmd != UCALL_SYNC)\n\t\t\t\tbreak;\n\n\t\t\tsem_post(&vcpu_ready);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (run->exit_reason != KVM_EXIT_MMIO)\n\t\t\tbreak;\n\n\t\tTEST_ASSERT(!run->mmio.is_write, \"Unexpected exit mmio write\");\n\t\tTEST_ASSERT(run->mmio.len == 8,\n\t\t\t    \"Unexpected exit mmio size = %u\", run->mmio.len);\n\n\t\tTEST_ASSERT(run->mmio.phys_addr == MEM_REGION_GPA,\n\t\t\t    \"Unexpected exit mmio address = 0x%llx\",\n\t\t\t    run->mmio.phys_addr);\n\t\tmemcpy(run->mmio.data, &MMIO_VAL, 8);\n\t}\n\n\tif (run->exit_reason == KVM_EXIT_IO && cmd == UCALL_ABORT)\n\t\tREPORT_GUEST_ASSERT(uc);\n\n\treturn NULL;\n}\n\nstatic void wait_for_vcpu(void)\n{\n\tstruct timespec ts;\n\n\tTEST_ASSERT(!clock_gettime(CLOCK_REALTIME, &ts),\n\t\t    \"clock_gettime() failed: %d\\n\", errno);\n\n\tts.tv_sec += 2;\n\tTEST_ASSERT(!sem_timedwait(&vcpu_ready, &ts),\n\t\t    \"sem_timedwait() failed: %d\\n\", errno);\n\n\t \n\tusleep(100000);\n}\n\nstatic struct kvm_vm *spawn_vm(struct kvm_vcpu **vcpu, pthread_t *vcpu_thread,\n\t\t\t       void *guest_code)\n{\n\tstruct kvm_vm *vm;\n\tuint64_t *hva;\n\tuint64_t gpa;\n\n\tvm = vm_create_with_one_vcpu(vcpu, guest_code);\n\n\tvm_userspace_mem_region_add(vm, VM_MEM_SRC_ANONYMOUS_THP,\n\t\t\t\t    MEM_REGION_GPA, MEM_REGION_SLOT,\n\t\t\t\t    MEM_REGION_SIZE / getpagesize(), 0);\n\n\t \n\tgpa = vm_phy_pages_alloc(vm, 2, MEM_REGION_GPA, MEM_REGION_SLOT);\n\tTEST_ASSERT(gpa == MEM_REGION_GPA, \"Failed vm_phy_pages_alloc\\n\");\n\n\tvirt_map(vm, MEM_REGION_GPA, MEM_REGION_GPA, 2);\n\n\t \n\thva = addr_gpa2hva(vm, MEM_REGION_GPA);\n\tmemset(hva, 0, 2 * 4096);\n\n\tpthread_create(vcpu_thread, NULL, vcpu_worker, *vcpu);\n\n\t \n\twait_for_vcpu();\n\n\treturn vm;\n}\n\n\nstatic void guest_code_move_memory_region(void)\n{\n\tuint64_t val;\n\n\tGUEST_SYNC(0);\n\n\t \n\tval = guest_spin_on_val(0);\n\t__GUEST_ASSERT(val == 1 || val == MMIO_VAL,\n\t\t       \"Expected '1' or MMIO ('%llx'), got '%llx'\", MMIO_VAL, val);\n\n\t \n\tval = guest_spin_on_val(MMIO_VAL);\n\t__GUEST_ASSERT(val == 1 || val == 0,\n\t\t       \"Expected '0' or '1' (no MMIO), got '%llx'\", val);\n\n\t \n\tval = guest_spin_on_val(0);\n\t__GUEST_ASSERT(val == 1 || val == MMIO_VAL,\n\t\t       \"Expected '1' or MMIO ('%llx'), got '%llx'\", MMIO_VAL, val);\n\n\t \n\tval = guest_spin_on_val(MMIO_VAL);\n\tGUEST_ASSERT_EQ(val, 1);\n\n\tGUEST_DONE();\n}\n\nstatic void test_move_memory_region(void)\n{\n\tpthread_t vcpu_thread;\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\tuint64_t *hva;\n\n\tvm = spawn_vm(&vcpu, &vcpu_thread, guest_code_move_memory_region);\n\n\thva = addr_gpa2hva(vm, MEM_REGION_GPA);\n\n\t \n\tvm_mem_region_move(vm, MEM_REGION_SLOT, MEM_REGION_GPA - 4096);\n\tWRITE_ONCE(*hva, 2);\n\n\t \n\tusleep(100000);\n\n\t \n\tWRITE_ONCE(*hva, 1);\n\n\t \n\tvm_mem_region_move(vm, MEM_REGION_SLOT, MEM_REGION_GPA);\n\twait_for_vcpu();\n\t \n\twait_for_vcpu();\n\n\tpthread_join(vcpu_thread, NULL);\n\n\tkvm_vm_free(vm);\n}\n\nstatic void guest_code_delete_memory_region(void)\n{\n\tuint64_t val;\n\n\tGUEST_SYNC(0);\n\n\t \n\tval = guest_spin_on_val(0);\n\tGUEST_ASSERT_EQ(val, MMIO_VAL);\n\n\t \n\tval = guest_spin_on_val(MMIO_VAL);\n\tGUEST_ASSERT_EQ(val, 0);\n\n\t \n\tval = guest_spin_on_val(0);\n\tGUEST_ASSERT_EQ(val, MMIO_VAL);\n\n\tasm(\"1:\\n\\t\"\n\t    \".pushsection .rodata\\n\\t\"\n\t    \".global final_rip_start\\n\\t\"\n\t    \"final_rip_start: .quad 1b\\n\\t\"\n\t    \".popsection\");\n\n\t \n\tguest_spin_on_val(MMIO_VAL);\n\n\tasm(\"1:\\n\\t\"\n\t    \".pushsection .rodata\\n\\t\"\n\t    \".global final_rip_end\\n\\t\"\n\t    \"final_rip_end: .quad 1b\\n\\t\"\n\t    \".popsection\");\n\n\tGUEST_ASSERT(0);\n}\n\nstatic void test_delete_memory_region(void)\n{\n\tpthread_t vcpu_thread;\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_regs regs;\n\tstruct kvm_run *run;\n\tstruct kvm_vm *vm;\n\n\tvm = spawn_vm(&vcpu, &vcpu_thread, guest_code_delete_memory_region);\n\n\t \n\tvm_mem_region_delete(vm, MEM_REGION_SLOT);\n\twait_for_vcpu();\n\n\t \n\tvm_userspace_mem_region_add(vm, VM_MEM_SRC_ANONYMOUS_THP,\n\t\t\t\t    MEM_REGION_GPA, MEM_REGION_SLOT,\n\t\t\t\t    MEM_REGION_SIZE / getpagesize(), 0);\n\twait_for_vcpu();\n\n\t \n\tvm_mem_region_delete(vm, MEM_REGION_SLOT);\n\twait_for_vcpu();\n\n\t \n\tvm_mem_region_delete(vm, 0);\n\n\tpthread_join(vcpu_thread, NULL);\n\n\trun = vcpu->run;\n\n\tTEST_ASSERT(run->exit_reason == KVM_EXIT_SHUTDOWN ||\n\t\t    run->exit_reason == KVM_EXIT_INTERNAL_ERROR,\n\t\t    \"Unexpected exit reason = %d\", run->exit_reason);\n\n\tvcpu_regs_get(vcpu, &regs);\n\n\t \n\tif (run->exit_reason == KVM_EXIT_INTERNAL_ERROR)\n\t\tTEST_ASSERT(regs.rip >= final_rip_start &&\n\t\t\t    regs.rip < final_rip_end,\n\t\t\t    \"Bad rip, expected 0x%lx - 0x%lx, got 0x%llx\\n\",\n\t\t\t    final_rip_start, final_rip_end, regs.rip);\n\n\tkvm_vm_free(vm);\n}\n\nstatic void test_zero_memory_regions(void)\n{\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\n\tpr_info(\"Testing KVM_RUN with zero added memory regions\\n\");\n\n\tvm = vm_create_barebones();\n\tvcpu = __vm_vcpu_add(vm, 0);\n\n\tvm_ioctl(vm, KVM_SET_NR_MMU_PAGES, (void *)64ul);\n\tvcpu_run(vcpu);\n\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_INTERNAL_ERROR);\n\n\tkvm_vm_free(vm);\n}\n#endif  \n\n \nstatic void test_add_max_memory_regions(void)\n{\n\tint ret;\n\tstruct kvm_vm *vm;\n\tuint32_t max_mem_slots;\n\tuint32_t slot;\n\tvoid *mem, *mem_aligned, *mem_extra;\n\tsize_t alignment;\n\n#ifdef __s390x__\n\t \n\talignment = 0x100000;\n#else\n\talignment = 1;\n#endif\n\n\tmax_mem_slots = kvm_check_cap(KVM_CAP_NR_MEMSLOTS);\n\tTEST_ASSERT(max_mem_slots > 0,\n\t\t    \"KVM_CAP_NR_MEMSLOTS should be greater than 0\");\n\tpr_info(\"Allowed number of memory slots: %i\\n\", max_mem_slots);\n\n\tvm = vm_create_barebones();\n\n\t \n\tpr_info(\"Adding slots 0..%i, each memory region with %dK size\\n\",\n\t\t(max_mem_slots - 1), MEM_REGION_SIZE >> 10);\n\n\tmem = mmap(NULL, (size_t)max_mem_slots * MEM_REGION_SIZE + alignment,\n\t\t   PROT_READ | PROT_WRITE,\n\t\t   MAP_PRIVATE | MAP_ANONYMOUS | MAP_NORESERVE, -1, 0);\n\tTEST_ASSERT(mem != MAP_FAILED, \"Failed to mmap() host\");\n\tmem_aligned = (void *)(((size_t) mem + alignment - 1) & ~(alignment - 1));\n\n\tfor (slot = 0; slot < max_mem_slots; slot++)\n\t\tvm_set_user_memory_region(vm, slot, 0,\n\t\t\t\t\t  ((uint64_t)slot * MEM_REGION_SIZE),\n\t\t\t\t\t  MEM_REGION_SIZE,\n\t\t\t\t\t  mem_aligned + (uint64_t)slot * MEM_REGION_SIZE);\n\n\t \n\tmem_extra = mmap(NULL, MEM_REGION_SIZE, PROT_READ | PROT_WRITE,\n\t\t\t MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);\n\tTEST_ASSERT(mem_extra != MAP_FAILED, \"Failed to mmap() host\");\n\n\tret = __vm_set_user_memory_region(vm, max_mem_slots, 0,\n\t\t\t\t\t  (uint64_t)max_mem_slots * MEM_REGION_SIZE,\n\t\t\t\t\t  MEM_REGION_SIZE, mem_extra);\n\tTEST_ASSERT(ret == -1 && errno == EINVAL,\n\t\t    \"Adding one more memory slot should fail with EINVAL\");\n\n\tmunmap(mem, (size_t)max_mem_slots * MEM_REGION_SIZE + alignment);\n\tmunmap(mem_extra, MEM_REGION_SIZE);\n\tkvm_vm_free(vm);\n}\n\nint main(int argc, char *argv[])\n{\n#ifdef __x86_64__\n\tint i, loops;\n#endif\n\n#ifdef __x86_64__\n\t \n\ttest_zero_memory_regions();\n#endif\n\n\ttest_add_max_memory_regions();\n\n#ifdef __x86_64__\n\tif (argc > 1)\n\t\tloops = atoi_positive(\"Number of iterations\", argv[1]);\n\telse\n\t\tloops = 10;\n\n\tpr_info(\"Testing MOVE of in-use region, %d loops\\n\", loops);\n\tfor (i = 0; i < loops; i++)\n\t\ttest_move_memory_region();\n\n\tpr_info(\"Testing DELETE of in-use region, %d loops\\n\", loops);\n\tfor (i = 0; i < loops; i++)\n\t\ttest_delete_memory_region();\n#endif\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}