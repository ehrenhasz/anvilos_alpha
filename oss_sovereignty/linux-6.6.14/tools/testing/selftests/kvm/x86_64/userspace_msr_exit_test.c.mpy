{
  "module_name": "userspace_msr_exit_test.c",
  "hash_id": "2af01628aa007b2c809aa5a6c5643ed11c39d1646b5401361c24d68badbde6d4",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/x86_64/userspace_msr_exit_test.c",
  "human_readable_source": "\n \n\n#define _GNU_SOURCE  \n#include <sys/ioctl.h>\n\n#include \"test_util.h\"\n#include \"kvm_util.h\"\n#include \"vmx.h\"\n\n \n#define KVM_FEP \"ud2; .byte 'k', 'v', 'm';\"\n#define KVM_FEP_LENGTH 5\nstatic int fep_available = 1;\n\n#define MSR_NON_EXISTENT 0x474f4f00\n\nstatic u64 deny_bits = 0;\nstruct kvm_msr_filter filter_allow = {\n\t.flags = KVM_MSR_FILTER_DEFAULT_ALLOW,\n\t.ranges = {\n\t\t{\n\t\t\t.flags = KVM_MSR_FILTER_READ |\n\t\t\t\t KVM_MSR_FILTER_WRITE,\n\t\t\t.nmsrs = 1,\n\t\t\t \n\t\t\t.base = MSR_IA32_XSS,\n\t\t\t.bitmap = (uint8_t*)&deny_bits,\n\t\t}, {\n\t\t\t.flags = KVM_MSR_FILTER_READ |\n\t\t\t\t KVM_MSR_FILTER_WRITE,\n\t\t\t.nmsrs = 1,\n\t\t\t \n\t\t\t.base = MSR_IA32_FLUSH_CMD,\n\t\t\t.bitmap = (uint8_t*)&deny_bits,\n\t\t}, {\n\t\t\t.flags = KVM_MSR_FILTER_READ |\n\t\t\t\t KVM_MSR_FILTER_WRITE,\n\t\t\t.nmsrs = 1,\n\t\t\t \n\t\t\t.base = MSR_NON_EXISTENT,\n\t\t\t.bitmap = (uint8_t*)&deny_bits,\n\t\t},\n\t},\n};\n\nstruct kvm_msr_filter filter_fs = {\n\t.flags = KVM_MSR_FILTER_DEFAULT_ALLOW,\n\t.ranges = {\n\t\t{\n\t\t\t.flags = KVM_MSR_FILTER_READ,\n\t\t\t.nmsrs = 1,\n\t\t\t.base = MSR_FS_BASE,\n\t\t\t.bitmap = (uint8_t*)&deny_bits,\n\t\t},\n\t},\n};\n\nstruct kvm_msr_filter filter_gs = {\n\t.flags = KVM_MSR_FILTER_DEFAULT_ALLOW,\n\t.ranges = {\n\t\t{\n\t\t\t.flags = KVM_MSR_FILTER_READ,\n\t\t\t.nmsrs = 1,\n\t\t\t.base = MSR_GS_BASE,\n\t\t\t.bitmap = (uint8_t*)&deny_bits,\n\t\t},\n\t},\n};\n\nstatic uint64_t msr_non_existent_data;\nstatic int guest_exception_count;\nstatic u32 msr_reads, msr_writes;\n\nstatic u8 bitmap_00000000[KVM_MSR_FILTER_MAX_BITMAP_SIZE];\nstatic u8 bitmap_00000000_write[KVM_MSR_FILTER_MAX_BITMAP_SIZE];\nstatic u8 bitmap_40000000[KVM_MSR_FILTER_MAX_BITMAP_SIZE];\nstatic u8 bitmap_c0000000[KVM_MSR_FILTER_MAX_BITMAP_SIZE];\nstatic u8 bitmap_c0000000_read[KVM_MSR_FILTER_MAX_BITMAP_SIZE];\nstatic u8 bitmap_deadbeef[1] = { 0x1 };\n\nstatic void deny_msr(uint8_t *bitmap, u32 msr)\n{\n\tu32 idx = msr & (KVM_MSR_FILTER_MAX_BITMAP_SIZE - 1);\n\n\tbitmap[idx / 8] &= ~(1 << (idx % 8));\n}\n\nstatic void prepare_bitmaps(void)\n{\n\tmemset(bitmap_00000000, 0xff, sizeof(bitmap_00000000));\n\tmemset(bitmap_00000000_write, 0xff, sizeof(bitmap_00000000_write));\n\tmemset(bitmap_40000000, 0xff, sizeof(bitmap_40000000));\n\tmemset(bitmap_c0000000, 0xff, sizeof(bitmap_c0000000));\n\tmemset(bitmap_c0000000_read, 0xff, sizeof(bitmap_c0000000_read));\n\n\tdeny_msr(bitmap_00000000_write, MSR_IA32_POWER_CTL);\n\tdeny_msr(bitmap_c0000000_read, MSR_SYSCALL_MASK);\n\tdeny_msr(bitmap_c0000000_read, MSR_GS_BASE);\n}\n\nstruct kvm_msr_filter filter_deny = {\n\t.flags = KVM_MSR_FILTER_DEFAULT_DENY,\n\t.ranges = {\n\t\t{\n\t\t\t.flags = KVM_MSR_FILTER_READ,\n\t\t\t.base = 0x00000000,\n\t\t\t.nmsrs = KVM_MSR_FILTER_MAX_BITMAP_SIZE * BITS_PER_BYTE,\n\t\t\t.bitmap = bitmap_00000000,\n\t\t}, {\n\t\t\t.flags = KVM_MSR_FILTER_WRITE,\n\t\t\t.base = 0x00000000,\n\t\t\t.nmsrs = KVM_MSR_FILTER_MAX_BITMAP_SIZE * BITS_PER_BYTE,\n\t\t\t.bitmap = bitmap_00000000_write,\n\t\t}, {\n\t\t\t.flags = KVM_MSR_FILTER_READ | KVM_MSR_FILTER_WRITE,\n\t\t\t.base = 0x40000000,\n\t\t\t.nmsrs = KVM_MSR_FILTER_MAX_BITMAP_SIZE * BITS_PER_BYTE,\n\t\t\t.bitmap = bitmap_40000000,\n\t\t}, {\n\t\t\t.flags = KVM_MSR_FILTER_READ,\n\t\t\t.base = 0xc0000000,\n\t\t\t.nmsrs = KVM_MSR_FILTER_MAX_BITMAP_SIZE * BITS_PER_BYTE,\n\t\t\t.bitmap = bitmap_c0000000_read,\n\t\t}, {\n\t\t\t.flags = KVM_MSR_FILTER_WRITE,\n\t\t\t.base = 0xc0000000,\n\t\t\t.nmsrs = KVM_MSR_FILTER_MAX_BITMAP_SIZE * BITS_PER_BYTE,\n\t\t\t.bitmap = bitmap_c0000000,\n\t\t}, {\n\t\t\t.flags = KVM_MSR_FILTER_WRITE | KVM_MSR_FILTER_READ,\n\t\t\t.base = 0xdeadbeef,\n\t\t\t.nmsrs = 1,\n\t\t\t.bitmap = bitmap_deadbeef,\n\t\t},\n\t},\n};\n\nstruct kvm_msr_filter no_filter_deny = {\n\t.flags = KVM_MSR_FILTER_DEFAULT_ALLOW,\n};\n\n \nstatic noinline uint64_t test_rdmsr(uint32_t msr)\n{\n\tuint32_t a, d;\n\n\tguest_exception_count = 0;\n\n\t__asm__ __volatile__(\"rdmsr_start: rdmsr; rdmsr_end:\" :\n\t\t\t\"=a\"(a), \"=d\"(d) : \"c\"(msr) : \"memory\");\n\n\treturn a | ((uint64_t) d << 32);\n}\n\n \nstatic noinline void test_wrmsr(uint32_t msr, uint64_t value)\n{\n\tuint32_t a = value;\n\tuint32_t d = value >> 32;\n\n\tguest_exception_count = 0;\n\n\t__asm__ __volatile__(\"wrmsr_start: wrmsr; wrmsr_end:\" ::\n\t\t\t\"a\"(a), \"d\"(d), \"c\"(msr) : \"memory\");\n}\n\nextern char rdmsr_start, rdmsr_end;\nextern char wrmsr_start, wrmsr_end;\n\n \nstatic noinline uint64_t test_em_rdmsr(uint32_t msr)\n{\n\tuint32_t a, d;\n\n\tguest_exception_count = 0;\n\n\t__asm__ __volatile__(KVM_FEP \"em_rdmsr_start: rdmsr; em_rdmsr_end:\" :\n\t\t\t\"=a\"(a), \"=d\"(d) : \"c\"(msr) : \"memory\");\n\n\treturn a | ((uint64_t) d << 32);\n}\n\n \nstatic noinline void test_em_wrmsr(uint32_t msr, uint64_t value)\n{\n\tuint32_t a = value;\n\tuint32_t d = value >> 32;\n\n\tguest_exception_count = 0;\n\n\t__asm__ __volatile__(KVM_FEP \"em_wrmsr_start: wrmsr; em_wrmsr_end:\" ::\n\t\t\t\"a\"(a), \"d\"(d), \"c\"(msr) : \"memory\");\n}\n\nextern char em_rdmsr_start, em_rdmsr_end;\nextern char em_wrmsr_start, em_wrmsr_end;\n\nstatic void guest_code_filter_allow(void)\n{\n\tuint64_t data;\n\n\t \n\tdata = test_rdmsr(MSR_IA32_XSS);\n\tGUEST_ASSERT(data == 0);\n\tGUEST_ASSERT(guest_exception_count == 0);\n\n\ttest_wrmsr(MSR_IA32_XSS, 0);\n\tGUEST_ASSERT(guest_exception_count == 0);\n\n\ttest_wrmsr(MSR_IA32_XSS, 1);\n\tGUEST_ASSERT(guest_exception_count == 1);\n\n\t \n\ttest_rdmsr(MSR_IA32_FLUSH_CMD);\n\tGUEST_ASSERT(guest_exception_count == 1);\n\n\ttest_wrmsr(MSR_IA32_FLUSH_CMD, 0);\n\tGUEST_ASSERT(guest_exception_count == 1);\n\n\ttest_wrmsr(MSR_IA32_FLUSH_CMD, 1);\n\tGUEST_ASSERT(guest_exception_count == 0);\n\n\t \n\ttest_wrmsr(MSR_NON_EXISTENT, 2);\n\tGUEST_ASSERT(guest_exception_count == 0);\n\n\tdata = test_rdmsr(MSR_NON_EXISTENT);\n\tGUEST_ASSERT(data == 2);\n\tGUEST_ASSERT(guest_exception_count == 0);\n\n\t \n\t__asm__ __volatile__(KVM_FEP \"nop\");\n\n\tif (fep_available) {\n\t\t \n\t\tGUEST_SYNC(0);\n\n\t\t \n\t\tdata = test_em_rdmsr(MSR_IA32_XSS);\n\t\tGUEST_ASSERT(data == 0);\n\t\tGUEST_ASSERT(guest_exception_count == 0);\n\t\ttest_em_wrmsr(MSR_IA32_XSS, 0);\n\t\tGUEST_ASSERT(guest_exception_count == 0);\n\t\ttest_em_wrmsr(MSR_IA32_XSS, 1);\n\t\tGUEST_ASSERT(guest_exception_count == 1);\n\n\t\ttest_em_rdmsr(MSR_IA32_FLUSH_CMD);\n\t\tGUEST_ASSERT(guest_exception_count == 1);\n\t\ttest_em_wrmsr(MSR_IA32_FLUSH_CMD, 0);\n\t\tGUEST_ASSERT(guest_exception_count == 1);\n\t\ttest_em_wrmsr(MSR_IA32_FLUSH_CMD, 1);\n\t\tGUEST_ASSERT(guest_exception_count == 0);\n\n\t\ttest_em_wrmsr(MSR_NON_EXISTENT, 2);\n\t\tGUEST_ASSERT(guest_exception_count == 0);\n\t\tdata = test_em_rdmsr(MSR_NON_EXISTENT);\n\t\tGUEST_ASSERT(data == 2);\n\t\tGUEST_ASSERT(guest_exception_count == 0);\n\t}\n\n\tGUEST_DONE();\n}\n\nstatic void guest_msr_calls(bool trapped)\n{\n\t \n\twrmsr(MSR_SYSCALL_MASK, 0);\n\n\tif (trapped) {\n\t\t \n\t\tGUEST_ASSERT(rdmsr(MSR_SYSCALL_MASK) == MSR_SYSCALL_MASK);\n\t\tGUEST_ASSERT(rdmsr(MSR_GS_BASE) == MSR_GS_BASE);\n\t} else {\n\t\tGUEST_ASSERT(rdmsr(MSR_SYSCALL_MASK) != MSR_SYSCALL_MASK);\n\t\tGUEST_ASSERT(rdmsr(MSR_GS_BASE) != MSR_GS_BASE);\n\t}\n\n\t \n\twrmsr(MSR_IA32_POWER_CTL, 0x1234);\n\n\t \n\trdmsr(MSR_IA32_POWER_CTL);\n\n\t \n\tGUEST_ASSERT(rdmsr(0xdeadbeef) == 0xdeadbeef);\n\twrmsr(0xdeadbeef, 0x1234);\n}\n\nstatic void guest_code_filter_deny(void)\n{\n\tguest_msr_calls(true);\n\n\t \n\tGUEST_SYNC(0);\n\n\tguest_msr_calls(false);\n\n\tGUEST_DONE();\n}\n\nstatic void guest_code_permission_bitmap(void)\n{\n\tuint64_t data;\n\n\tdata = test_rdmsr(MSR_FS_BASE);\n\tGUEST_ASSERT(data == MSR_FS_BASE);\n\tdata = test_rdmsr(MSR_GS_BASE);\n\tGUEST_ASSERT(data != MSR_GS_BASE);\n\n\t \n\tGUEST_SYNC(0);\n\n\tdata = test_rdmsr(MSR_FS_BASE);\n\tGUEST_ASSERT(data != MSR_FS_BASE);\n\tdata = test_rdmsr(MSR_GS_BASE);\n\tGUEST_ASSERT(data == MSR_GS_BASE);\n\n\tGUEST_DONE();\n}\n\nstatic void __guest_gp_handler(struct ex_regs *regs,\n\t\t\t       char *r_start, char *r_end,\n\t\t\t       char *w_start, char *w_end)\n{\n\tif (regs->rip == (uintptr_t)r_start) {\n\t\tregs->rip = (uintptr_t)r_end;\n\t\tregs->rax = 0;\n\t\tregs->rdx = 0;\n\t} else if (regs->rip == (uintptr_t)w_start) {\n\t\tregs->rip = (uintptr_t)w_end;\n\t} else {\n\t\tGUEST_ASSERT(!\"RIP is at an unknown location!\");\n\t}\n\n\t++guest_exception_count;\n}\n\nstatic void guest_gp_handler(struct ex_regs *regs)\n{\n\t__guest_gp_handler(regs, &rdmsr_start, &rdmsr_end,\n\t\t\t   &wrmsr_start, &wrmsr_end);\n}\n\nstatic void guest_fep_gp_handler(struct ex_regs *regs)\n{\n\t__guest_gp_handler(regs, &em_rdmsr_start, &em_rdmsr_end,\n\t\t\t   &em_wrmsr_start, &em_wrmsr_end);\n}\n\nstatic void guest_ud_handler(struct ex_regs *regs)\n{\n\tfep_available = 0;\n\tregs->rip += KVM_FEP_LENGTH;\n}\n\nstatic void check_for_guest_assert(struct kvm_vcpu *vcpu)\n{\n\tstruct ucall uc;\n\n\tif (vcpu->run->exit_reason == KVM_EXIT_IO &&\n\t    get_ucall(vcpu, &uc) == UCALL_ABORT) {\n\t\tREPORT_GUEST_ASSERT(uc);\n\t}\n}\n\nstatic void process_rdmsr(struct kvm_vcpu *vcpu, uint32_t msr_index)\n{\n\tstruct kvm_run *run = vcpu->run;\n\n\tcheck_for_guest_assert(vcpu);\n\n\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_X86_RDMSR);\n\tTEST_ASSERT(run->msr.index == msr_index,\n\t\t\t\"Unexpected msr (0x%04x), expected 0x%04x\",\n\t\t\trun->msr.index, msr_index);\n\n\tswitch (run->msr.index) {\n\tcase MSR_IA32_XSS:\n\t\trun->msr.data = 0;\n\t\tbreak;\n\tcase MSR_IA32_FLUSH_CMD:\n\t\trun->msr.error = 1;\n\t\tbreak;\n\tcase MSR_NON_EXISTENT:\n\t\trun->msr.data = msr_non_existent_data;\n\t\tbreak;\n\tcase MSR_FS_BASE:\n\t\trun->msr.data = MSR_FS_BASE;\n\t\tbreak;\n\tcase MSR_GS_BASE:\n\t\trun->msr.data = MSR_GS_BASE;\n\t\tbreak;\n\tdefault:\n\t\tTEST_ASSERT(false, \"Unexpected MSR: 0x%04x\", run->msr.index);\n\t}\n}\n\nstatic void process_wrmsr(struct kvm_vcpu *vcpu, uint32_t msr_index)\n{\n\tstruct kvm_run *run = vcpu->run;\n\n\tcheck_for_guest_assert(vcpu);\n\n\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_X86_WRMSR);\n\tTEST_ASSERT(run->msr.index == msr_index,\n\t\t\t\"Unexpected msr (0x%04x), expected 0x%04x\",\n\t\t\trun->msr.index, msr_index);\n\n\tswitch (run->msr.index) {\n\tcase MSR_IA32_XSS:\n\t\tif (run->msr.data != 0)\n\t\t\trun->msr.error = 1;\n\t\tbreak;\n\tcase MSR_IA32_FLUSH_CMD:\n\t\tif (run->msr.data != 1)\n\t\t\trun->msr.error = 1;\n\t\tbreak;\n\tcase MSR_NON_EXISTENT:\n\t\tmsr_non_existent_data = run->msr.data;\n\t\tbreak;\n\tdefault:\n\t\tTEST_ASSERT(false, \"Unexpected MSR: 0x%04x\", run->msr.index);\n\t}\n}\n\nstatic void process_ucall_done(struct kvm_vcpu *vcpu)\n{\n\tstruct ucall uc;\n\n\tcheck_for_guest_assert(vcpu);\n\n\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_IO);\n\n\tTEST_ASSERT(get_ucall(vcpu, &uc) == UCALL_DONE,\n\t\t    \"Unexpected ucall command: %lu, expected UCALL_DONE (%d)\",\n\t\t    uc.cmd, UCALL_DONE);\n}\n\nstatic uint64_t process_ucall(struct kvm_vcpu *vcpu)\n{\n\tstruct ucall uc = {};\n\n\tcheck_for_guest_assert(vcpu);\n\n\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_IO);\n\n\tswitch (get_ucall(vcpu, &uc)) {\n\tcase UCALL_SYNC:\n\t\tbreak;\n\tcase UCALL_ABORT:\n\t\tcheck_for_guest_assert(vcpu);\n\t\tbreak;\n\tcase UCALL_DONE:\n\t\tprocess_ucall_done(vcpu);\n\t\tbreak;\n\tdefault:\n\t\tTEST_ASSERT(false, \"Unexpected ucall\");\n\t}\n\n\treturn uc.cmd;\n}\n\nstatic void run_guest_then_process_rdmsr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t uint32_t msr_index)\n{\n\tvcpu_run(vcpu);\n\tprocess_rdmsr(vcpu, msr_index);\n}\n\nstatic void run_guest_then_process_wrmsr(struct kvm_vcpu *vcpu,\n\t\t\t\t\t uint32_t msr_index)\n{\n\tvcpu_run(vcpu);\n\tprocess_wrmsr(vcpu, msr_index);\n}\n\nstatic uint64_t run_guest_then_process_ucall(struct kvm_vcpu *vcpu)\n{\n\tvcpu_run(vcpu);\n\treturn process_ucall(vcpu);\n}\n\nstatic void run_guest_then_process_ucall_done(struct kvm_vcpu *vcpu)\n{\n\tvcpu_run(vcpu);\n\tprocess_ucall_done(vcpu);\n}\n\nstatic void test_msr_filter_allow(void)\n{\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\tint rc;\n\n\tvm = vm_create_with_one_vcpu(&vcpu, guest_code_filter_allow);\n\n\trc = kvm_check_cap(KVM_CAP_X86_USER_SPACE_MSR);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_USER_SPACE_MSR is available\");\n\tvm_enable_cap(vm, KVM_CAP_X86_USER_SPACE_MSR, KVM_MSR_EXIT_REASON_FILTER);\n\n\trc = kvm_check_cap(KVM_CAP_X86_MSR_FILTER);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_MSR_FILTER is available\");\n\n\tvm_ioctl(vm, KVM_X86_SET_MSR_FILTER, &filter_allow);\n\n\tvm_init_descriptor_tables(vm);\n\tvcpu_init_descriptor_tables(vcpu);\n\n\tvm_install_exception_handler(vm, GP_VECTOR, guest_gp_handler);\n\n\t \n\trun_guest_then_process_rdmsr(vcpu, MSR_IA32_XSS);\n\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_XSS);\n\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_XSS);\n\n\trun_guest_then_process_rdmsr(vcpu, MSR_IA32_FLUSH_CMD);\n\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_FLUSH_CMD);\n\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_FLUSH_CMD);\n\n\trun_guest_then_process_wrmsr(vcpu, MSR_NON_EXISTENT);\n\trun_guest_then_process_rdmsr(vcpu, MSR_NON_EXISTENT);\n\n\tvm_install_exception_handler(vm, UD_VECTOR, guest_ud_handler);\n\tvcpu_run(vcpu);\n\tvm_install_exception_handler(vm, UD_VECTOR, NULL);\n\n\tif (process_ucall(vcpu) != UCALL_DONE) {\n\t\tvm_install_exception_handler(vm, GP_VECTOR, guest_fep_gp_handler);\n\n\t\t \n\t\trun_guest_then_process_rdmsr(vcpu, MSR_IA32_XSS);\n\t\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_XSS);\n\t\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_XSS);\n\n\t\trun_guest_then_process_rdmsr(vcpu, MSR_IA32_FLUSH_CMD);\n\t\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_FLUSH_CMD);\n\t\trun_guest_then_process_wrmsr(vcpu, MSR_IA32_FLUSH_CMD);\n\n\t\trun_guest_then_process_wrmsr(vcpu, MSR_NON_EXISTENT);\n\t\trun_guest_then_process_rdmsr(vcpu, MSR_NON_EXISTENT);\n\n\t\t \n\t\trun_guest_then_process_ucall_done(vcpu);\n\t} else {\n\t\tprintf(\"To run the instruction emulated tests set the module parameter 'kvm.force_emulation_prefix=1'\\n\");\n\t}\n\n\tkvm_vm_free(vm);\n}\n\nstatic int handle_ucall(struct kvm_vcpu *vcpu)\n{\n\tstruct ucall uc;\n\n\tswitch (get_ucall(vcpu, &uc)) {\n\tcase UCALL_ABORT:\n\t\tREPORT_GUEST_ASSERT(uc);\n\t\tbreak;\n\tcase UCALL_SYNC:\n\t\tvm_ioctl(vcpu->vm, KVM_X86_SET_MSR_FILTER, &no_filter_deny);\n\t\tbreak;\n\tcase UCALL_DONE:\n\t\treturn 1;\n\tdefault:\n\t\tTEST_FAIL(\"Unknown ucall %lu\", uc.cmd);\n\t}\n\n\treturn 0;\n}\n\nstatic void handle_rdmsr(struct kvm_run *run)\n{\n\trun->msr.data = run->msr.index;\n\tmsr_reads++;\n\n\tif (run->msr.index == MSR_SYSCALL_MASK ||\n\t    run->msr.index == MSR_GS_BASE) {\n\t\tTEST_ASSERT(run->msr.reason == KVM_MSR_EXIT_REASON_FILTER,\n\t\t\t    \"MSR read trap w/o access fault\");\n\t}\n\n\tif (run->msr.index == 0xdeadbeef) {\n\t\tTEST_ASSERT(run->msr.reason == KVM_MSR_EXIT_REASON_UNKNOWN,\n\t\t\t    \"MSR deadbeef read trap w/o inval fault\");\n\t}\n}\n\nstatic void handle_wrmsr(struct kvm_run *run)\n{\n\t \n\tmsr_writes++;\n\n\tif (run->msr.index == MSR_IA32_POWER_CTL) {\n\t\tTEST_ASSERT(run->msr.data == 0x1234,\n\t\t\t    \"MSR data for MSR_IA32_POWER_CTL incorrect\");\n\t\tTEST_ASSERT(run->msr.reason == KVM_MSR_EXIT_REASON_FILTER,\n\t\t\t    \"MSR_IA32_POWER_CTL trap w/o access fault\");\n\t}\n\n\tif (run->msr.index == 0xdeadbeef) {\n\t\tTEST_ASSERT(run->msr.data == 0x1234,\n\t\t\t    \"MSR data for deadbeef incorrect\");\n\t\tTEST_ASSERT(run->msr.reason == KVM_MSR_EXIT_REASON_UNKNOWN,\n\t\t\t    \"deadbeef trap w/o inval fault\");\n\t}\n}\n\nstatic void test_msr_filter_deny(void)\n{\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\tstruct kvm_run *run;\n\tint rc;\n\n\tvm = vm_create_with_one_vcpu(&vcpu, guest_code_filter_deny);\n\trun = vcpu->run;\n\n\trc = kvm_check_cap(KVM_CAP_X86_USER_SPACE_MSR);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_USER_SPACE_MSR is available\");\n\tvm_enable_cap(vm, KVM_CAP_X86_USER_SPACE_MSR, KVM_MSR_EXIT_REASON_INVAL |\n\t\t\t\t\t\t      KVM_MSR_EXIT_REASON_UNKNOWN |\n\t\t\t\t\t\t      KVM_MSR_EXIT_REASON_FILTER);\n\n\trc = kvm_check_cap(KVM_CAP_X86_MSR_FILTER);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_MSR_FILTER is available\");\n\n\tprepare_bitmaps();\n\tvm_ioctl(vm, KVM_X86_SET_MSR_FILTER, &filter_deny);\n\n\twhile (1) {\n\t\tvcpu_run(vcpu);\n\n\t\tswitch (run->exit_reason) {\n\t\tcase KVM_EXIT_X86_RDMSR:\n\t\t\thandle_rdmsr(run);\n\t\t\tbreak;\n\t\tcase KVM_EXIT_X86_WRMSR:\n\t\t\thandle_wrmsr(run);\n\t\t\tbreak;\n\t\tcase KVM_EXIT_IO:\n\t\t\tif (handle_ucall(vcpu))\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\t}\n\n\t}\n\ndone:\n\tTEST_ASSERT(msr_reads == 4, \"Handled 4 rdmsr in user space\");\n\tTEST_ASSERT(msr_writes == 3, \"Handled 3 wrmsr in user space\");\n\n\tkvm_vm_free(vm);\n}\n\nstatic void test_msr_permission_bitmap(void)\n{\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\tint rc;\n\n\tvm = vm_create_with_one_vcpu(&vcpu, guest_code_permission_bitmap);\n\n\trc = kvm_check_cap(KVM_CAP_X86_USER_SPACE_MSR);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_USER_SPACE_MSR is available\");\n\tvm_enable_cap(vm, KVM_CAP_X86_USER_SPACE_MSR, KVM_MSR_EXIT_REASON_FILTER);\n\n\trc = kvm_check_cap(KVM_CAP_X86_MSR_FILTER);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_MSR_FILTER is available\");\n\n\tvm_ioctl(vm, KVM_X86_SET_MSR_FILTER, &filter_fs);\n\trun_guest_then_process_rdmsr(vcpu, MSR_FS_BASE);\n\tTEST_ASSERT(run_guest_then_process_ucall(vcpu) == UCALL_SYNC,\n\t\t    \"Expected ucall state to be UCALL_SYNC.\");\n\tvm_ioctl(vm, KVM_X86_SET_MSR_FILTER, &filter_gs);\n\trun_guest_then_process_rdmsr(vcpu, MSR_GS_BASE);\n\trun_guest_then_process_ucall_done(vcpu);\n\n\tkvm_vm_free(vm);\n}\n\n#define test_user_exit_msr_ioctl(vm, cmd, arg, flag, valid_mask)\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tint r = __vm_ioctl(vm, cmd, arg);\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (flag & valid_mask)\t\t\t\t\t\t\\\n\t\tTEST_ASSERT(!r, __KVM_IOCTL_ERROR(#cmd, r));\t\t\\\n\telse\t\t\t\t\t\t\t\t\\\n\t\tTEST_ASSERT(r == -1 && errno == EINVAL,\t\t\t\\\n\t\t\t    \"Wanted EINVAL for %s with flag = 0x%llx, got  rc: %i errno: %i (%s)\", \\\n\t\t\t    #cmd, flag, r, errno,  strerror(errno));\t\\\n})\n\nstatic void run_user_space_msr_flag_test(struct kvm_vm *vm)\n{\n\tstruct kvm_enable_cap cap = { .cap = KVM_CAP_X86_USER_SPACE_MSR };\n\tint nflags = sizeof(cap.args[0]) * BITS_PER_BYTE;\n\tint rc;\n\tint i;\n\n\trc = kvm_check_cap(KVM_CAP_X86_USER_SPACE_MSR);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_USER_SPACE_MSR is available\");\n\n\tfor (i = 0; i < nflags; i++) {\n\t\tcap.args[0] = BIT_ULL(i);\n\t\ttest_user_exit_msr_ioctl(vm, KVM_ENABLE_CAP, &cap,\n\t\t\t   BIT_ULL(i), KVM_MSR_EXIT_REASON_VALID_MASK);\n\t}\n}\n\nstatic void run_msr_filter_flag_test(struct kvm_vm *vm)\n{\n\tu64 deny_bits = 0;\n\tstruct kvm_msr_filter filter = {\n\t\t.flags = KVM_MSR_FILTER_DEFAULT_ALLOW,\n\t\t.ranges = {\n\t\t\t{\n\t\t\t\t.flags = KVM_MSR_FILTER_READ,\n\t\t\t\t.nmsrs = 1,\n\t\t\t\t.base = 0,\n\t\t\t\t.bitmap = (uint8_t *)&deny_bits,\n\t\t\t},\n\t\t},\n\t};\n\tint nflags;\n\tint rc;\n\tint i;\n\n\trc = kvm_check_cap(KVM_CAP_X86_MSR_FILTER);\n\tTEST_ASSERT(rc, \"KVM_CAP_X86_MSR_FILTER is available\");\n\n\tnflags = sizeof(filter.flags) * BITS_PER_BYTE;\n\tfor (i = 0; i < nflags; i++) {\n\t\tfilter.flags = BIT_ULL(i);\n\t\ttest_user_exit_msr_ioctl(vm, KVM_X86_SET_MSR_FILTER, &filter,\n\t\t\t   BIT_ULL(i), KVM_MSR_FILTER_VALID_MASK);\n\t}\n\n\tfilter.flags = KVM_MSR_FILTER_DEFAULT_ALLOW;\n\tnflags = sizeof(filter.ranges[0].flags) * BITS_PER_BYTE;\n\tfor (i = 0; i < nflags; i++) {\n\t\tfilter.ranges[0].flags = BIT_ULL(i);\n\t\ttest_user_exit_msr_ioctl(vm, KVM_X86_SET_MSR_FILTER, &filter,\n\t\t\t   BIT_ULL(i), KVM_MSR_FILTER_RANGE_VALID_MASK);\n\t}\n}\n\n \nstatic void test_user_exit_msr_flags(void)\n{\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\n\tvm = vm_create_with_one_vcpu(&vcpu, NULL);\n\n\t \n\trun_user_space_msr_flag_test(vm);\n\n\t \n\trun_msr_filter_flag_test(vm);\n\n\tkvm_vm_free(vm);\n}\n\nint main(int argc, char *argv[])\n{\n\ttest_msr_filter_allow();\n\n\ttest_msr_filter_deny();\n\n\ttest_msr_permission_bitmap();\n\n\ttest_user_exit_msr_flags();\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}