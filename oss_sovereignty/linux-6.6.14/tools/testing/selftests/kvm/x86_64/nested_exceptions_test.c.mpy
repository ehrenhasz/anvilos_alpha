{
  "module_name": "nested_exceptions_test.c",
  "hash_id": "6f9292bd76d66d5446948e483a51e3b6703ba71655d46557ce6ace240dcb2873",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/x86_64/nested_exceptions_test.c",
  "human_readable_source": "\n#define _GNU_SOURCE  \n\n#include \"test_util.h\"\n#include \"kvm_util.h\"\n#include \"processor.h\"\n#include \"vmx.h\"\n#include \"svm_util.h\"\n\n#define L2_GUEST_STACK_SIZE 256\n\n \n#define FAKE_TRIPLE_FAULT_VECTOR\t0xaa\n\n \n#define SS_ERROR_CODE 0xdeadbeef\n\n \n#define ERROR_CODE_EXT_FLAG\tBIT(0)\n\n \n#define ERROR_CODE_IDT_FLAG\tBIT(1)\n\n \n#define GP_ERROR_CODE_AMD ((SS_VECTOR * 8) | ERROR_CODE_IDT_FLAG)\n#define GP_ERROR_CODE_INTEL ((SS_VECTOR * 8) | ERROR_CODE_IDT_FLAG | ERROR_CODE_EXT_FLAG)\n\n \n#define DF_ERROR_CODE 0\n\n#define INTERCEPT_SS\t\t(BIT_ULL(SS_VECTOR))\n#define INTERCEPT_SS_DF\t\t(INTERCEPT_SS | BIT_ULL(DF_VECTOR))\n#define INTERCEPT_SS_GP_DF\t(INTERCEPT_SS_DF | BIT_ULL(GP_VECTOR))\n\nstatic void l2_ss_pending_test(void)\n{\n\tGUEST_SYNC(SS_VECTOR);\n}\n\nstatic void l2_ss_injected_gp_test(void)\n{\n\tGUEST_SYNC(GP_VECTOR);\n}\n\nstatic void l2_ss_injected_df_test(void)\n{\n\tGUEST_SYNC(DF_VECTOR);\n}\n\nstatic void l2_ss_injected_tf_test(void)\n{\n\tGUEST_SYNC(FAKE_TRIPLE_FAULT_VECTOR);\n}\n\nstatic void svm_run_l2(struct svm_test_data *svm, void *l2_code, int vector,\n\t\t       uint32_t error_code)\n{\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct vmcb_control_area *ctrl = &vmcb->control;\n\n\tvmcb->save.rip = (u64)l2_code;\n\trun_guest(vmcb, svm->vmcb_gpa);\n\n\tif (vector == FAKE_TRIPLE_FAULT_VECTOR)\n\t\treturn;\n\n\tGUEST_ASSERT_EQ(ctrl->exit_code, (SVM_EXIT_EXCP_BASE + vector));\n\tGUEST_ASSERT_EQ(ctrl->exit_info_1, error_code);\n}\n\nstatic void l1_svm_code(struct svm_test_data *svm)\n{\n\tstruct vmcb_control_area *ctrl = &svm->vmcb->control;\n\tunsigned long l2_guest_stack[L2_GUEST_STACK_SIZE];\n\n\tgeneric_svm_setup(svm, NULL, &l2_guest_stack[L2_GUEST_STACK_SIZE]);\n\tsvm->vmcb->save.idtr.limit = 0;\n\tctrl->intercept |= BIT_ULL(INTERCEPT_SHUTDOWN);\n\n\tctrl->intercept_exceptions = INTERCEPT_SS_GP_DF;\n\tsvm_run_l2(svm, l2_ss_pending_test, SS_VECTOR, SS_ERROR_CODE);\n\tsvm_run_l2(svm, l2_ss_injected_gp_test, GP_VECTOR, GP_ERROR_CODE_AMD);\n\n\tctrl->intercept_exceptions = INTERCEPT_SS_DF;\n\tsvm_run_l2(svm, l2_ss_injected_df_test, DF_VECTOR, DF_ERROR_CODE);\n\n\tctrl->intercept_exceptions = INTERCEPT_SS;\n\tsvm_run_l2(svm, l2_ss_injected_tf_test, FAKE_TRIPLE_FAULT_VECTOR, 0);\n\tGUEST_ASSERT_EQ(ctrl->exit_code, SVM_EXIT_SHUTDOWN);\n\n\tGUEST_DONE();\n}\n\nstatic void vmx_run_l2(void *l2_code, int vector, uint32_t error_code)\n{\n\tGUEST_ASSERT(!vmwrite(GUEST_RIP, (u64)l2_code));\n\n\tGUEST_ASSERT_EQ(vector == SS_VECTOR ? vmlaunch() : vmresume(), 0);\n\n\tif (vector == FAKE_TRIPLE_FAULT_VECTOR)\n\t\treturn;\n\n\tGUEST_ASSERT_EQ(vmreadz(VM_EXIT_REASON), EXIT_REASON_EXCEPTION_NMI);\n\tGUEST_ASSERT_EQ((vmreadz(VM_EXIT_INTR_INFO) & 0xff), vector);\n\tGUEST_ASSERT_EQ(vmreadz(VM_EXIT_INTR_ERROR_CODE), error_code);\n}\n\nstatic void l1_vmx_code(struct vmx_pages *vmx)\n{\n\tunsigned long l2_guest_stack[L2_GUEST_STACK_SIZE];\n\n\tGUEST_ASSERT_EQ(prepare_for_vmx_operation(vmx), true);\n\n\tGUEST_ASSERT_EQ(load_vmcs(vmx), true);\n\n\tprepare_vmcs(vmx, NULL, &l2_guest_stack[L2_GUEST_STACK_SIZE]);\n\tGUEST_ASSERT_EQ(vmwrite(GUEST_IDTR_LIMIT, 0), 0);\n\n\t \n\tGUEST_ASSERT_EQ(vmwrite(EXCEPTION_BITMAP, INTERCEPT_SS_GP_DF), 0);\n\tvmx_run_l2(l2_ss_pending_test, SS_VECTOR, (u16)SS_ERROR_CODE);\n\tvmx_run_l2(l2_ss_injected_gp_test, GP_VECTOR, GP_ERROR_CODE_INTEL);\n\n\tGUEST_ASSERT_EQ(vmwrite(EXCEPTION_BITMAP, INTERCEPT_SS_DF), 0);\n\tvmx_run_l2(l2_ss_injected_df_test, DF_VECTOR, DF_ERROR_CODE);\n\n\tGUEST_ASSERT_EQ(vmwrite(EXCEPTION_BITMAP, INTERCEPT_SS), 0);\n\tvmx_run_l2(l2_ss_injected_tf_test, FAKE_TRIPLE_FAULT_VECTOR, 0);\n\tGUEST_ASSERT_EQ(vmreadz(VM_EXIT_REASON), EXIT_REASON_TRIPLE_FAULT);\n\n\tGUEST_DONE();\n}\n\nstatic void __attribute__((__flatten__)) l1_guest_code(void *test_data)\n{\n\tif (this_cpu_has(X86_FEATURE_SVM))\n\t\tl1_svm_code(test_data);\n\telse\n\t\tl1_vmx_code(test_data);\n}\n\nstatic void assert_ucall_vector(struct kvm_vcpu *vcpu, int vector)\n{\n\tstruct ucall uc;\n\n\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_IO);\n\n\tswitch (get_ucall(vcpu, &uc)) {\n\tcase UCALL_SYNC:\n\t\tTEST_ASSERT(vector == uc.args[1],\n\t\t\t    \"Expected L2 to ask for %d, got %ld\", vector, uc.args[1]);\n\t\tbreak;\n\tcase UCALL_DONE:\n\t\tTEST_ASSERT(vector == -1,\n\t\t\t    \"Expected L2 to ask for %d, L2 says it's done\", vector);\n\t\tbreak;\n\tcase UCALL_ABORT:\n\t\tREPORT_GUEST_ASSERT(uc);\n\t\tbreak;\n\tdefault:\n\t\tTEST_FAIL(\"Expected L2 to ask for %d, got unexpected ucall %lu\", vector, uc.cmd);\n\t}\n}\n\nstatic void queue_ss_exception(struct kvm_vcpu *vcpu, bool inject)\n{\n\tstruct kvm_vcpu_events events;\n\n\tvcpu_events_get(vcpu, &events);\n\n\tTEST_ASSERT(!events.exception.pending,\n\t\t    \"Vector %d unexpectedlt pending\", events.exception.nr);\n\tTEST_ASSERT(!events.exception.injected,\n\t\t    \"Vector %d unexpectedly injected\", events.exception.nr);\n\n\tevents.flags = KVM_VCPUEVENT_VALID_PAYLOAD;\n\tevents.exception.pending = !inject;\n\tevents.exception.injected = inject;\n\tevents.exception.nr = SS_VECTOR;\n\tevents.exception.has_error_code = true;\n\tevents.exception.error_code = SS_ERROR_CODE;\n\tvcpu_events_set(vcpu, &events);\n}\n\n \nint main(int argc, char *argv[])\n{\n\tvm_vaddr_t nested_test_data_gva;\n\tstruct kvm_vcpu_events events;\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\n\tTEST_REQUIRE(kvm_has_cap(KVM_CAP_EXCEPTION_PAYLOAD));\n\tTEST_REQUIRE(kvm_cpu_has(X86_FEATURE_SVM) || kvm_cpu_has(X86_FEATURE_VMX));\n\n\tvm = vm_create_with_one_vcpu(&vcpu, l1_guest_code);\n\tvm_enable_cap(vm, KVM_CAP_EXCEPTION_PAYLOAD, -2ul);\n\n\tif (kvm_cpu_has(X86_FEATURE_SVM))\n\t\tvcpu_alloc_svm(vm, &nested_test_data_gva);\n\telse\n\t\tvcpu_alloc_vmx(vm, &nested_test_data_gva);\n\n\tvcpu_args_set(vcpu, 1, nested_test_data_gva);\n\n\t \n\tvcpu_run(vcpu);\n\tassert_ucall_vector(vcpu, SS_VECTOR);\n\n\t \n\tqueue_ss_exception(vcpu, false);\n\tvcpu->run->immediate_exit = true;\n\tvcpu_run_complete_io(vcpu);\n\n\t \n\tvcpu_events_get(vcpu, &events);\n\tTEST_ASSERT_EQ(events.flags & KVM_VCPUEVENT_VALID_PAYLOAD,\n\t\t\tKVM_VCPUEVENT_VALID_PAYLOAD);\n\tTEST_ASSERT_EQ(events.exception.pending, true);\n\tTEST_ASSERT_EQ(events.exception.nr, SS_VECTOR);\n\tTEST_ASSERT_EQ(events.exception.has_error_code, true);\n\tTEST_ASSERT_EQ(events.exception.error_code, SS_ERROR_CODE);\n\n\t \n\tvcpu->run->immediate_exit = false;\n\tvcpu_run(vcpu);\n\tassert_ucall_vector(vcpu, GP_VECTOR);\n\n\t \n\tqueue_ss_exception(vcpu, true);\n\tvcpu_run(vcpu);\n\tassert_ucall_vector(vcpu, DF_VECTOR);\n\n\t \n\tqueue_ss_exception(vcpu, true);\n\tvcpu_run(vcpu);\n\tassert_ucall_vector(vcpu, FAKE_TRIPLE_FAULT_VECTOR);\n\n\t \n\tqueue_ss_exception(vcpu, true);\n\tvcpu_run(vcpu);\n\tassert_ucall_vector(vcpu, -1);\n\n\tkvm_vm_free(vm);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}