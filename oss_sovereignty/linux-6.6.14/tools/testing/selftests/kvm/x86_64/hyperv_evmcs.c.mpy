{
  "module_name": "hyperv_evmcs.c",
  "hash_id": "1f7e7437a5b7ef9ec295c5b5f601874ad47a4835b15db021196b09c54face689",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/x86_64/hyperv_evmcs.c",
  "human_readable_source": "\n \n#define _GNU_SOURCE  \n#include <fcntl.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/ioctl.h>\n#include <linux/bitmap.h>\n\n#include \"test_util.h\"\n\n#include \"kvm_util.h\"\n\n#include \"hyperv.h\"\n#include \"vmx.h\"\n\nstatic int ud_count;\n\nstatic void guest_ud_handler(struct ex_regs *regs)\n{\n\tud_count++;\n\tregs->rip += 3;  \n}\n\nstatic void guest_nmi_handler(struct ex_regs *regs)\n{\n}\n\nstatic inline void rdmsr_from_l2(uint32_t msr)\n{\n\t \n\t__asm__ __volatile__ (\"rdmsr\" : : \"c\"(msr) :\n\t\t\t      \"rax\", \"rbx\", \"rdx\", \"rsi\", \"rdi\", \"r8\", \"r9\",\n\t\t\t      \"r10\", \"r11\", \"r12\", \"r13\", \"r14\", \"r15\");\n}\n\n \nvoid l2_guest_code(void)\n{\n\tu64 unused;\n\n\tGUEST_SYNC(7);\n\n\tGUEST_SYNC(8);\n\n\t \n\tGUEST_SYNC(9);\n\n\tvmcall();\n\n\t \n\trdmsr_from_l2(MSR_FS_BASE);  \n\trdmsr_from_l2(MSR_FS_BASE);  \n\trdmsr_from_l2(MSR_GS_BASE);  \n\tvmcall();\n\trdmsr_from_l2(MSR_GS_BASE);  \n\n\t \n\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE | HV_HYPERCALL_FAST_BIT, 0x0,\n\t\t\t HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES | HV_FLUSH_ALL_PROCESSORS);\n\trdmsr_from_l2(MSR_FS_BASE);\n\t \n\t__hyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE | HV_HYPERCALL_FAST_BIT, 0x0,\n\t\t\t   HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES | HV_FLUSH_ALL_PROCESSORS,\n\t\t\t   &unused);\n\n\t \n\tvmcall();\n}\n\nvoid guest_code(struct vmx_pages *vmx_pages, struct hyperv_test_pages *hv_pages,\n\t\tvm_vaddr_t hv_hcall_page_gpa)\n{\n#define L2_GUEST_STACK_SIZE 64\n\tunsigned long l2_guest_stack[L2_GUEST_STACK_SIZE];\n\n\twrmsr(HV_X64_MSR_GUEST_OS_ID, HYPERV_LINUX_OS_ID);\n\twrmsr(HV_X64_MSR_HYPERCALL, hv_hcall_page_gpa);\n\n\tx2apic_enable();\n\n\tGUEST_SYNC(1);\n\tGUEST_SYNC(2);\n\n\tenable_vp_assist(hv_pages->vp_assist_gpa, hv_pages->vp_assist);\n\tevmcs_enable();\n\n\tGUEST_ASSERT(prepare_for_vmx_operation(vmx_pages));\n\tGUEST_SYNC(3);\n\tGUEST_ASSERT(load_evmcs(hv_pages));\n\tGUEST_ASSERT(vmptrstz() == hv_pages->enlightened_vmcs_gpa);\n\n\tGUEST_SYNC(4);\n\tGUEST_ASSERT(vmptrstz() == hv_pages->enlightened_vmcs_gpa);\n\n\tprepare_vmcs(vmx_pages, l2_guest_code,\n\t\t     &l2_guest_stack[L2_GUEST_STACK_SIZE]);\n\n\tGUEST_SYNC(5);\n\tGUEST_ASSERT(vmptrstz() == hv_pages->enlightened_vmcs_gpa);\n\tcurrent_evmcs->revision_id = -1u;\n\tGUEST_ASSERT(vmlaunch());\n\tcurrent_evmcs->revision_id = EVMCS_VERSION;\n\tGUEST_SYNC(6);\n\n\tvmwrite(PIN_BASED_VM_EXEC_CONTROL, vmreadz(PIN_BASED_VM_EXEC_CONTROL) |\n\t\tPIN_BASED_NMI_EXITING);\n\n\t \n\tcurrent_evmcs->partition_assist_page = hv_pages->partition_assist_gpa;\n\tcurrent_evmcs->hv_enlightenments_control.nested_flush_hypercall = 1;\n\tcurrent_evmcs->hv_vm_id = 1;\n\tcurrent_evmcs->hv_vp_id = 1;\n\tcurrent_vp_assist->nested_control.features.directhypercall = 1;\n\t*(u32 *)(hv_pages->partition_assist) = 0;\n\n\tGUEST_ASSERT(!vmlaunch());\n\tGUEST_ASSERT_EQ(vmreadz(VM_EXIT_REASON), EXIT_REASON_EXCEPTION_NMI);\n\tGUEST_ASSERT_EQ((vmreadz(VM_EXIT_INTR_INFO) & 0xff), NMI_VECTOR);\n\tGUEST_ASSERT(vmptrstz() == hv_pages->enlightened_vmcs_gpa);\n\n\t \n\tGUEST_ASSERT(!vmresume());\n\n\tGUEST_SYNC(10);\n\n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == EXIT_REASON_VMCALL);\n\tcurrent_evmcs->guest_rip += 3;  \n\n\t \n\tvmwrite(CPU_BASED_VM_EXEC_CONTROL, vmreadz(CPU_BASED_VM_EXEC_CONTROL) |\n\t\tCPU_BASED_USE_MSR_BITMAPS);\n\t__set_bit(MSR_FS_BASE & 0x1fff, vmx_pages->msr + 0x400);\n\tGUEST_ASSERT(!vmresume());\n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == EXIT_REASON_MSR_READ);\n\tcurrent_evmcs->guest_rip += 2;  \n\n\t \n\tcurrent_evmcs->hv_enlightenments_control.msr_bitmap = 1;\n\tGUEST_ASSERT(!vmresume());\n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == EXIT_REASON_MSR_READ);\n\tcurrent_evmcs->guest_rip += 2;  \n\n\t \n\t__set_bit(MSR_GS_BASE & 0x1fff, vmx_pages->msr + 0x400);\n\t \n\tcurrent_evmcs->hv_clean_fields |= HV_VMX_ENLIGHTENED_CLEAN_FIELD_MSR_BITMAP;\n\tGUEST_ASSERT(!vmresume());\n\t \n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == EXIT_REASON_VMCALL);\n\tcurrent_evmcs->guest_rip += 3;  \n\n\t \n\tcurrent_evmcs->hv_clean_fields &= ~HV_VMX_ENLIGHTENED_CLEAN_FIELD_MSR_BITMAP;\n\tGUEST_ASSERT(!vmresume());\n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == EXIT_REASON_MSR_READ);\n\tcurrent_evmcs->guest_rip += 2;  \n\n\t \n\tGUEST_ASSERT(!vmresume());\n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == EXIT_REASON_MSR_READ);\n\tcurrent_evmcs->guest_rip += 2;  \n\t \n\t*(u32 *)(hv_pages->partition_assist) = 1;\n\tGUEST_ASSERT(!vmresume());\n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == HV_VMX_SYNTHETIC_EXIT_REASON_TRAP_AFTER_FLUSH);\n\n\tGUEST_ASSERT(!vmresume());\n\tGUEST_ASSERT(vmreadz(VM_EXIT_REASON) == EXIT_REASON_VMCALL);\n\tGUEST_SYNC(11);\n\n\t \n\tevmcs_vmptrld(0xdeadbeef, hv_pages->enlightened_vmcs);\n\tGUEST_ASSERT(vmlaunch());\n\tGUEST_ASSERT(ud_count == 1);\n\tGUEST_DONE();\n}\n\nvoid inject_nmi(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_vcpu_events events;\n\n\tvcpu_events_get(vcpu, &events);\n\n\tevents.nmi.pending = 1;\n\tevents.flags |= KVM_VCPUEVENT_VALID_NMI_PENDING;\n\n\tvcpu_events_set(vcpu, &events);\n}\n\nstatic struct kvm_vcpu *save_restore_vm(struct kvm_vm *vm,\n\t\t\t\t\tstruct kvm_vcpu *vcpu)\n{\n\tstruct kvm_regs regs1, regs2;\n\tstruct kvm_x86_state *state;\n\n\tstate = vcpu_save_state(vcpu);\n\tmemset(&regs1, 0, sizeof(regs1));\n\tvcpu_regs_get(vcpu, &regs1);\n\n\tkvm_vm_release(vm);\n\n\t \n\tvcpu = vm_recreate_with_one_vcpu(vm);\n\tvcpu_set_hv_cpuid(vcpu);\n\tvcpu_enable_evmcs(vcpu);\n\tvcpu_load_state(vcpu, state);\n\tkvm_x86_state_cleanup(state);\n\n\tmemset(&regs2, 0, sizeof(regs2));\n\tvcpu_regs_get(vcpu, &regs2);\n\tTEST_ASSERT(!memcmp(&regs1, &regs2, sizeof(regs2)),\n\t\t    \"Unexpected register values after vcpu_load_state; rdi: %lx rsi: %lx\",\n\t\t    (ulong) regs2.rdi, (ulong) regs2.rsi);\n\treturn vcpu;\n}\n\nint main(int argc, char *argv[])\n{\n\tvm_vaddr_t vmx_pages_gva = 0, hv_pages_gva = 0;\n\tvm_vaddr_t hcall_page;\n\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vm *vm;\n\tstruct ucall uc;\n\tint stage;\n\n\tvm = vm_create_with_one_vcpu(&vcpu, guest_code);\n\n\tTEST_REQUIRE(kvm_cpu_has(X86_FEATURE_VMX));\n\tTEST_REQUIRE(kvm_has_cap(KVM_CAP_NESTED_STATE));\n\tTEST_REQUIRE(kvm_has_cap(KVM_CAP_HYPERV_ENLIGHTENED_VMCS));\n\n\thcall_page = vm_vaddr_alloc_pages(vm, 1);\n\tmemset(addr_gva2hva(vm, hcall_page), 0x0,  getpagesize());\n\n\tvcpu_set_hv_cpuid(vcpu);\n\tvcpu_enable_evmcs(vcpu);\n\n\tvcpu_alloc_vmx(vm, &vmx_pages_gva);\n\tvcpu_alloc_hyperv_test_pages(vm, &hv_pages_gva);\n\tvcpu_args_set(vcpu, 3, vmx_pages_gva, hv_pages_gva, addr_gva2gpa(vm, hcall_page));\n\tvcpu_set_msr(vcpu, HV_X64_MSR_VP_INDEX, vcpu->id);\n\n\tvm_init_descriptor_tables(vm);\n\tvcpu_init_descriptor_tables(vcpu);\n\tvm_install_exception_handler(vm, UD_VECTOR, guest_ud_handler);\n\tvm_install_exception_handler(vm, NMI_VECTOR, guest_nmi_handler);\n\n\tpr_info(\"Running L1 which uses EVMCS to run L2\\n\");\n\n\tfor (stage = 1;; stage++) {\n\t\tvcpu_run(vcpu);\n\t\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_IO);\n\n\t\tswitch (get_ucall(vcpu, &uc)) {\n\t\tcase UCALL_ABORT:\n\t\t\tREPORT_GUEST_ASSERT(uc);\n\t\t\t \n\t\tcase UCALL_SYNC:\n\t\t\tbreak;\n\t\tcase UCALL_DONE:\n\t\t\tgoto done;\n\t\tdefault:\n\t\t\tTEST_FAIL(\"Unknown ucall %lu\", uc.cmd);\n\t\t}\n\n\t\t \n\t\tTEST_ASSERT(!strcmp((const char *)uc.args[0], \"hello\") &&\n\t\t\t    uc.args[1] == stage, \"Stage %d: Unexpected register values vmexit, got %lx\",\n\t\t\t    stage, (ulong)uc.args[1]);\n\n\t\tvcpu = save_restore_vm(vm, vcpu);\n\n\t\t \n\t\tif (stage == 8) {\n\t\t\tpr_info(\"Injecting NMI into L1 before L2 had a chance to run after restore\\n\");\n\t\t\tinject_nmi(vcpu);\n\t\t}\n\n\t\t \n\t\tif (stage == 9) {\n\t\t\tpr_info(\"Trying extra KVM_GET_NESTED_STATE/KVM_SET_NESTED_STATE cycle\\n\");\n\t\t\tvcpu = save_restore_vm(vm, vcpu);\n\t\t}\n\t}\n\ndone:\n\tkvm_vm_free(vm);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}