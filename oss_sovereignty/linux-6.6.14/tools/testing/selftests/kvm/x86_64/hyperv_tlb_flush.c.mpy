{
  "module_name": "hyperv_tlb_flush.c",
  "hash_id": "4e7f8d18befded4677accb0b4df89f434d9add11e80d87f4eae28b699c35960c",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/x86_64/hyperv_tlb_flush.c",
  "human_readable_source": "\n \n\n#define _GNU_SOURCE  \n#include <asm/barrier.h>\n#include <pthread.h>\n#include <inttypes.h>\n\n#include \"kvm_util.h\"\n#include \"processor.h\"\n#include \"hyperv.h\"\n#include \"test_util.h\"\n#include \"vmx.h\"\n\n#define WORKER_VCPU_ID_1 2\n#define WORKER_VCPU_ID_2 65\n\n#define NTRY 100\n#define NTEST_PAGES 2\n\nstruct hv_vpset {\n\tu64 format;\n\tu64 valid_bank_mask;\n\tu64 bank_contents[];\n};\n\nenum HV_GENERIC_SET_FORMAT {\n\tHV_GENERIC_SET_SPARSE_4K,\n\tHV_GENERIC_SET_ALL,\n};\n\n#define HV_FLUSH_ALL_PROCESSORS\t\t\tBIT(0)\n#define HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES\tBIT(1)\n#define HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY\tBIT(2)\n#define HV_FLUSH_USE_EXTENDED_RANGE_FORMAT\tBIT(3)\n\n \nstruct hv_tlb_flush {\n\tu64 address_space;\n\tu64 flags;\n\tu64 processor_mask;\n\tu64 gva_list[];\n} __packed;\n\n \nstruct hv_tlb_flush_ex {\n\tu64 address_space;\n\tu64 flags;\n\tstruct hv_vpset hv_vp_set;\n\tu64 gva_list[];\n} __packed;\n\n \nstruct test_data {\n\tvm_vaddr_t hcall_gva;\n\tvm_paddr_t hcall_gpa;\n\tvm_vaddr_t test_pages;\n\tvm_vaddr_t test_pages_pte[NTEST_PAGES];\n};\n\n \nstatic void worker_guest_code(vm_vaddr_t test_data)\n{\n\tstruct test_data *data = (struct test_data *)test_data;\n\tu32 vcpu_id = rdmsr(HV_X64_MSR_VP_INDEX);\n\tvoid *exp_page = (void *)data->test_pages + PAGE_SIZE * NTEST_PAGES;\n\tu64 *this_cpu = (u64 *)(exp_page + vcpu_id * sizeof(u64));\n\tu64 expected, val;\n\n\tx2apic_enable();\n\twrmsr(HV_X64_MSR_GUEST_OS_ID, HYPERV_LINUX_OS_ID);\n\n\tfor (;;) {\n\t\tcpu_relax();\n\n\t\texpected = READ_ONCE(*this_cpu);\n\n\t\t \n\t\trmb();\n\n\t\tval = READ_ONCE(*(u64 *)data->test_pages);\n\n\t\t \n\t\trmb();\n\n\t\t \n\t\tif (!expected)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (expected != READ_ONCE(*this_cpu))\n\t\t\tcontinue;\n\n\t\tGUEST_ASSERT(val == expected);\n\t}\n}\n\n \nstatic void set_expected_val(void *addr, u64 val, int vcpu_id)\n{\n\tvoid *exp_page = addr + PAGE_SIZE * NTEST_PAGES;\n\n\t*(u64 *)(exp_page + vcpu_id * sizeof(u64)) = val;\n}\n\n \nstatic void swap_two_test_pages(vm_paddr_t pte_gva1, vm_paddr_t pte_gva2)\n{\n\tuint64_t tmp = *(uint64_t *)pte_gva1;\n\n\t*(uint64_t *)pte_gva1 = *(uint64_t *)pte_gva2;\n\t*(uint64_t *)pte_gva2 = tmp;\n}\n\n \nstatic inline void do_delay(void)\n{\n\tint i;\n\n\tfor (i = 0; i < 1000000; i++)\n\t\tasm volatile(\"nop\");\n}\n\n \nstatic inline void prepare_to_test(struct test_data *data)\n{\n\t \n\tmemset((void *)data->hcall_gva, 0, PAGE_SIZE);\n\n\t \n\tset_expected_val((void *)data->test_pages, 0x0, WORKER_VCPU_ID_1);\n\tset_expected_val((void *)data->test_pages, 0x0, WORKER_VCPU_ID_2);\n\n\t \n\twmb();\n\n\t \n\tdo_delay();\n\n\t \n\tswap_two_test_pages(data->test_pages_pte[0], data->test_pages_pte[1]);\n}\n\n \nstatic inline void post_test(struct test_data *data, u64 exp1, u64 exp2)\n{\n\t \n\twmb();\n\n\t \n\tset_expected_val((void *)data->test_pages, exp1, WORKER_VCPU_ID_1);\n\tset_expected_val((void *)data->test_pages, exp2, WORKER_VCPU_ID_2);\n\n\t \n\tdo_delay();\n}\n\n#define TESTVAL1 0x0101010101010101\n#define TESTVAL2 0x0202020202020202\n\n \nstatic void sender_guest_code(vm_vaddr_t test_data)\n{\n\tstruct test_data *data = (struct test_data *)test_data;\n\tstruct hv_tlb_flush *flush = (struct hv_tlb_flush *)data->hcall_gva;\n\tstruct hv_tlb_flush_ex *flush_ex = (struct hv_tlb_flush_ex *)data->hcall_gva;\n\tvm_paddr_t hcall_gpa = data->hcall_gpa;\n\tint i, stage = 1;\n\n\twrmsr(HV_X64_MSR_GUEST_OS_ID, HYPERV_LINUX_OS_ID);\n\twrmsr(HV_X64_MSR_HYPERCALL, data->hcall_gpa);\n\n\t \n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush->processor_mask = BIT(WORKER_VCPU_ID_1);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE, hcall_gpa,\n\t\t\t\t hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2, 0x0);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush->processor_mask = BIT(WORKER_VCPU_ID_1);\n\t\tflush->gva_list[0] = (u64)data->test_pages;\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2, 0x0);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES |\n\t\t\tHV_FLUSH_ALL_PROCESSORS;\n\t\tflush->processor_mask = 0;\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE, hcall_gpa,\n\t\t\t\t hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2, i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES |\n\t\t\tHV_FLUSH_ALL_PROCESSORS;\n\t\tflush->gva_list[0] = (u64)data->test_pages;\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_2 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX |\n\t\t\t\t (1 << HV_HYPERCALL_VARHEAD_OFFSET),\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, 0x0, i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_2 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\t \n\t\tflush_ex->gva_list[1] = (u64)data->test_pages;\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX |\n\t\t\t\t (1 << HV_HYPERCALL_VARHEAD_OFFSET) |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, 0x0, i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_2 / 64) |\n\t\t\tBIT_ULL(WORKER_VCPU_ID_1 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_1 % 64);\n\t\tflush_ex->hv_vp_set.bank_contents[1] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX |\n\t\t\t\t (2 << HV_HYPERCALL_VARHEAD_OFFSET),\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_1 / 64) |\n\t\t\tBIT_ULL(WORKER_VCPU_ID_2 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_1 % 64);\n\t\tflush_ex->hv_vp_set.bank_contents[1] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\t \n\t\tflush_ex->gva_list[2] = (u64)data->test_pages;\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX |\n\t\t\t\t (2 << HV_HYPERCALL_VARHEAD_OFFSET) |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_ALL;\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX,\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_ALL;\n\t\tflush_ex->gva_list[0] = (u64)data->test_pages;\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t hcall_gpa, hcall_gpa + PAGE_SIZE);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\t \n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush->processor_mask = BIT(WORKER_VCPU_ID_1);\n\t\thyperv_write_xmm_input(&flush->processor_mask, 1);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE |\n\t\t\t\t HV_HYPERCALL_FAST_BIT, 0x0,\n\t\t\t\t HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2, 0x0);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush->processor_mask = BIT(WORKER_VCPU_ID_1);\n\t\tflush->gva_list[0] = (u64)data->test_pages;\n\t\thyperv_write_xmm_input(&flush->processor_mask, 1);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST |\n\t\t\t\t HV_HYPERCALL_FAST_BIT |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t 0x0, HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2, 0x0);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\thyperv_write_xmm_input(&flush->processor_mask, 1);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE |\n\t\t\t\t HV_HYPERCALL_FAST_BIT, 0x0,\n\t\t\t\t HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES |\n\t\t\t\t HV_FLUSH_ALL_PROCESSORS);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush->gva_list[0] = (u64)data->test_pages;\n\t\thyperv_write_xmm_input(&flush->processor_mask, 1);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST |\n\t\t\t\t HV_HYPERCALL_FAST_BIT |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET), 0x0,\n\t\t\t\t HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES |\n\t\t\t\t HV_FLUSH_ALL_PROCESSORS);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_2 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\thyperv_write_xmm_input(&flush_ex->hv_vp_set, 2);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX |\n\t\t\t\t HV_HYPERCALL_FAST_BIT |\n\t\t\t\t (1 << HV_HYPERCALL_VARHEAD_OFFSET),\n\t\t\t\t 0x0, HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, 0x0, i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_2 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\t \n\t\tflush_ex->gva_list[1] = (u64)data->test_pages;\n\t\thyperv_write_xmm_input(&flush_ex->hv_vp_set, 2);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX |\n\t\t\t\t HV_HYPERCALL_FAST_BIT |\n\t\t\t\t (1 << HV_HYPERCALL_VARHEAD_OFFSET) |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t 0x0, HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, 0x0, i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_2 / 64) |\n\t\t\tBIT_ULL(WORKER_VCPU_ID_1 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_1 % 64);\n\t\tflush_ex->hv_vp_set.bank_contents[1] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\thyperv_write_xmm_input(&flush_ex->hv_vp_set, 2);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX |\n\t\t\t\t HV_HYPERCALL_FAST_BIT |\n\t\t\t\t (2 << HV_HYPERCALL_VARHEAD_OFFSET),\n\t\t\t\t 0x0, HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, i % 2 ? TESTVAL1 :\n\t\t\t  TESTVAL2, i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_SPARSE_4K;\n\t\tflush_ex->hv_vp_set.valid_bank_mask = BIT_ULL(WORKER_VCPU_ID_1 / 64) |\n\t\t\tBIT_ULL(WORKER_VCPU_ID_2 / 64);\n\t\tflush_ex->hv_vp_set.bank_contents[0] = BIT_ULL(WORKER_VCPU_ID_1 % 64);\n\t\tflush_ex->hv_vp_set.bank_contents[1] = BIT_ULL(WORKER_VCPU_ID_2 % 64);\n\t\t \n\t\tflush_ex->gva_list[2] = (u64)data->test_pages;\n\t\thyperv_write_xmm_input(&flush_ex->hv_vp_set, 3);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX |\n\t\t\t\t HV_HYPERCALL_FAST_BIT |\n\t\t\t\t (2 << HV_HYPERCALL_VARHEAD_OFFSET) |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t 0x0, HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_ALL;\n\t\thyperv_write_xmm_input(&flush_ex->hv_vp_set, 2);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX |\n\t\t\t\t HV_HYPERCALL_FAST_BIT,\n\t\t\t\t 0x0, HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_SYNC(stage++);\n\n\t \n\tfor (i = 0; i < NTRY; i++) {\n\t\tprepare_to_test(data);\n\t\tflush_ex->flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;\n\t\tflush_ex->hv_vp_set.format = HV_GENERIC_SET_ALL;\n\t\tflush_ex->gva_list[0] = (u64)data->test_pages;\n\t\thyperv_write_xmm_input(&flush_ex->hv_vp_set, 2);\n\t\thyperv_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX |\n\t\t\t\t HV_HYPERCALL_FAST_BIT |\n\t\t\t\t (1UL << HV_HYPERCALL_REP_COMP_OFFSET),\n\t\t\t\t 0x0, HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES);\n\t\tpost_test(data, i % 2 ? TESTVAL1 : TESTVAL2,\n\t\t\t  i % 2 ? TESTVAL1 : TESTVAL2);\n\t}\n\n\tGUEST_DONE();\n}\n\nstatic void *vcpu_thread(void *arg)\n{\n\tstruct kvm_vcpu *vcpu = (struct kvm_vcpu *)arg;\n\tstruct ucall uc;\n\tint old;\n\tint r;\n\n\tr = pthread_setcanceltype(PTHREAD_CANCEL_ASYNCHRONOUS, &old);\n\tTEST_ASSERT(!r, \"pthread_setcanceltype failed on vcpu_id=%u with errno=%d\",\n\t\t    vcpu->id, r);\n\n\tvcpu_run(vcpu);\n\tTEST_ASSERT_KVM_EXIT_REASON(vcpu, KVM_EXIT_IO);\n\n\tswitch (get_ucall(vcpu, &uc)) {\n\tcase UCALL_ABORT:\n\t\tREPORT_GUEST_ASSERT(uc);\n\t\t \n\tdefault:\n\t\tTEST_FAIL(\"Unexpected ucall %lu, vCPU %d\", uc.cmd, vcpu->id);\n\t}\n\n\treturn NULL;\n}\n\nstatic void cancel_join_vcpu_thread(pthread_t thread, struct kvm_vcpu *vcpu)\n{\n\tvoid *retval;\n\tint r;\n\n\tr = pthread_cancel(thread);\n\tTEST_ASSERT(!r, \"pthread_cancel on vcpu_id=%d failed with errno=%d\",\n\t\t    vcpu->id, r);\n\n\tr = pthread_join(thread, &retval);\n\tTEST_ASSERT(!r, \"pthread_join on vcpu_id=%d failed with errno=%d\",\n\t\t    vcpu->id, r);\n\tTEST_ASSERT(retval == PTHREAD_CANCELED,\n\t\t    \"expected retval=%p, got %p\", PTHREAD_CANCELED,\n\t\t    retval);\n}\n\nint main(int argc, char *argv[])\n{\n\tstruct kvm_vm *vm;\n\tstruct kvm_vcpu *vcpu[3];\n\tpthread_t threads[2];\n\tvm_vaddr_t test_data_page, gva;\n\tvm_paddr_t gpa;\n\tuint64_t *pte;\n\tstruct test_data *data;\n\tstruct ucall uc;\n\tint stage = 1, r, i;\n\n\tvm = vm_create_with_one_vcpu(&vcpu[0], sender_guest_code);\n\n\t \n\ttest_data_page = vm_vaddr_alloc_page(vm);\n\tdata = (struct test_data *)addr_gva2hva(vm, test_data_page);\n\n\t \n\tdata->hcall_gva = vm_vaddr_alloc_pages(vm, 2);\n\tdata->hcall_gpa = addr_gva2gpa(vm, data->hcall_gva);\n\tmemset(addr_gva2hva(vm, data->hcall_gva), 0x0, 2 * PAGE_SIZE);\n\n\t \n\tdata->test_pages = vm_vaddr_alloc_pages(vm, NTEST_PAGES + 1);\n\tfor (i = 0; i < NTEST_PAGES; i++)\n\t\tmemset(addr_gva2hva(vm, data->test_pages + PAGE_SIZE * i),\n\t\t       (u8)(i + 1), PAGE_SIZE);\n\tset_expected_val(addr_gva2hva(vm, data->test_pages), 0x0, WORKER_VCPU_ID_1);\n\tset_expected_val(addr_gva2hva(vm, data->test_pages), 0x0, WORKER_VCPU_ID_2);\n\n\t \n\tgva = vm_vaddr_unused_gap(vm, NTEST_PAGES * PAGE_SIZE, KVM_UTIL_MIN_VADDR);\n\tfor (i = 0; i < NTEST_PAGES; i++) {\n\t\tpte = vm_get_page_table_entry(vm, data->test_pages + i * PAGE_SIZE);\n\t\tgpa = addr_hva2gpa(vm, pte);\n\t\t__virt_pg_map(vm, gva + PAGE_SIZE * i, gpa & PAGE_MASK, PG_LEVEL_4K);\n\t\tdata->test_pages_pte[i] = gva + (gpa & ~PAGE_MASK);\n\t}\n\n\t \n\tvcpu_args_set(vcpu[0], 1, test_data_page);\n\tvcpu_set_hv_cpuid(vcpu[0]);\n\n\t \n\tvcpu[1] = vm_vcpu_add(vm, WORKER_VCPU_ID_1, worker_guest_code);\n\tvcpu_args_set(vcpu[1], 1, test_data_page);\n\tvcpu_set_msr(vcpu[1], HV_X64_MSR_VP_INDEX, WORKER_VCPU_ID_1);\n\tvcpu_set_hv_cpuid(vcpu[1]);\n\n\tvcpu[2] = vm_vcpu_add(vm, WORKER_VCPU_ID_2, worker_guest_code);\n\tvcpu_args_set(vcpu[2], 1, test_data_page);\n\tvcpu_set_msr(vcpu[2], HV_X64_MSR_VP_INDEX, WORKER_VCPU_ID_2);\n\tvcpu_set_hv_cpuid(vcpu[2]);\n\n\tr = pthread_create(&threads[0], NULL, vcpu_thread, vcpu[1]);\n\tTEST_ASSERT(!r, \"pthread_create() failed\");\n\n\tr = pthread_create(&threads[1], NULL, vcpu_thread, vcpu[2]);\n\tTEST_ASSERT(!r, \"pthread_create() failed\");\n\n\twhile (true) {\n\t\tvcpu_run(vcpu[0]);\n\t\tTEST_ASSERT_KVM_EXIT_REASON(vcpu[0], KVM_EXIT_IO);\n\n\t\tswitch (get_ucall(vcpu[0], &uc)) {\n\t\tcase UCALL_SYNC:\n\t\t\tTEST_ASSERT(uc.args[1] == stage,\n\t\t\t\t    \"Unexpected stage: %ld (%d expected)\\n\",\n\t\t\t\t    uc.args[1], stage);\n\t\t\tbreak;\n\t\tcase UCALL_ABORT:\n\t\t\tREPORT_GUEST_ASSERT(uc);\n\t\t\t \n\t\tcase UCALL_DONE:\n\t\t\tgoto done;\n\t\tdefault:\n\t\t\tTEST_FAIL(\"Unknown ucall %lu\", uc.cmd);\n\t\t}\n\n\t\tstage++;\n\t}\n\ndone:\n\tcancel_join_vcpu_thread(threads[0], vcpu[1]);\n\tcancel_join_vcpu_thread(threads[1], vcpu[2]);\n\tkvm_vm_free(vm);\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}