{
  "module_name": "dirty_log_page_splitting_test.c",
  "hash_id": "e45c19ef7789bc3adfc5e900f48f7102f4234bd5b86eb0817e175a59b6c16966",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/x86_64/dirty_log_page_splitting_test.c",
  "human_readable_source": "\n \n\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <linux/bitmap.h>\n\n#include \"kvm_util.h\"\n#include \"test_util.h\"\n#include \"memstress.h\"\n#include \"guest_modes.h\"\n\n#define VCPUS\t\t2\n#define SLOTS\t\t2\n#define ITERATIONS\t2\n\nstatic uint64_t guest_percpu_mem_size = DEFAULT_PER_VCPU_MEM_SIZE;\n\nstatic enum vm_mem_backing_src_type backing_src = VM_MEM_SRC_ANONYMOUS_HUGETLB;\n\nstatic u64 dirty_log_manual_caps;\nstatic bool host_quit;\nstatic int iteration;\nstatic int vcpu_last_completed_iteration[KVM_MAX_VCPUS];\n\nstruct kvm_page_stats {\n\tuint64_t pages_4k;\n\tuint64_t pages_2m;\n\tuint64_t pages_1g;\n\tuint64_t hugepages;\n};\n\nstatic void get_page_stats(struct kvm_vm *vm, struct kvm_page_stats *stats, const char *stage)\n{\n\tstats->pages_4k = vm_get_stat(vm, \"pages_4k\");\n\tstats->pages_2m = vm_get_stat(vm, \"pages_2m\");\n\tstats->pages_1g = vm_get_stat(vm, \"pages_1g\");\n\tstats->hugepages = stats->pages_2m + stats->pages_1g;\n\n\tpr_debug(\"\\nPage stats after %s: 4K: %ld 2M: %ld 1G: %ld huge: %ld\\n\",\n\t\t stage, stats->pages_4k, stats->pages_2m, stats->pages_1g,\n\t\t stats->hugepages);\n}\n\nstatic void run_vcpu_iteration(struct kvm_vm *vm)\n{\n\tint i;\n\n\titeration++;\n\tfor (i = 0; i < VCPUS; i++) {\n\t\twhile (READ_ONCE(vcpu_last_completed_iteration[i]) !=\n\t\t       iteration)\n\t\t\t;\n\t}\n}\n\nstatic void vcpu_worker(struct memstress_vcpu_args *vcpu_args)\n{\n\tstruct kvm_vcpu *vcpu = vcpu_args->vcpu;\n\tint vcpu_idx = vcpu_args->vcpu_idx;\n\n\twhile (!READ_ONCE(host_quit)) {\n\t\tint current_iteration = READ_ONCE(iteration);\n\n\t\tvcpu_run(vcpu);\n\n\t\tTEST_ASSERT_EQ(get_ucall(vcpu, NULL), UCALL_SYNC);\n\n\t\tvcpu_last_completed_iteration[vcpu_idx] = current_iteration;\n\n\t\t \n\t\twhile (current_iteration == READ_ONCE(iteration) &&\n\t\t       READ_ONCE(iteration) >= 0 &&\n\t\t       !READ_ONCE(host_quit))\n\t\t\t;\n\t}\n}\n\nstatic void run_test(enum vm_guest_mode mode, void *unused)\n{\n\tstruct kvm_vm *vm;\n\tunsigned long **bitmaps;\n\tuint64_t guest_num_pages;\n\tuint64_t host_num_pages;\n\tuint64_t pages_per_slot;\n\tint i;\n\tuint64_t total_4k_pages;\n\tstruct kvm_page_stats stats_populated;\n\tstruct kvm_page_stats stats_dirty_logging_enabled;\n\tstruct kvm_page_stats stats_dirty_pass[ITERATIONS];\n\tstruct kvm_page_stats stats_clear_pass[ITERATIONS];\n\tstruct kvm_page_stats stats_dirty_logging_disabled;\n\tstruct kvm_page_stats stats_repopulated;\n\n\tvm = memstress_create_vm(mode, VCPUS, guest_percpu_mem_size,\n\t\t\t\t SLOTS, backing_src, false);\n\n\tguest_num_pages = (VCPUS * guest_percpu_mem_size) >> vm->page_shift;\n\tguest_num_pages = vm_adjust_num_guest_pages(mode, guest_num_pages);\n\thost_num_pages = vm_num_host_pages(mode, guest_num_pages);\n\tpages_per_slot = host_num_pages / SLOTS;\n\n\tbitmaps = memstress_alloc_bitmaps(SLOTS, pages_per_slot);\n\n\tif (dirty_log_manual_caps)\n\t\tvm_enable_cap(vm, KVM_CAP_MANUAL_DIRTY_LOG_PROTECT2,\n\t\t\t      dirty_log_manual_caps);\n\n\t \n\titeration = -1;\n\thost_quit = false;\n\n\tfor (i = 0; i < VCPUS; i++)\n\t\tvcpu_last_completed_iteration[i] = -1;\n\n\tmemstress_start_vcpu_threads(VCPUS, vcpu_worker);\n\n\trun_vcpu_iteration(vm);\n\tget_page_stats(vm, &stats_populated, \"populating memory\");\n\n\t \n\tmemstress_enable_dirty_logging(vm, SLOTS);\n\n\tget_page_stats(vm, &stats_dirty_logging_enabled, \"enabling dirty logging\");\n\n\twhile (iteration < ITERATIONS) {\n\t\trun_vcpu_iteration(vm);\n\t\tget_page_stats(vm, &stats_dirty_pass[iteration - 1],\n\t\t\t       \"dirtying memory\");\n\n\t\tmemstress_get_dirty_log(vm, bitmaps, SLOTS);\n\n\t\tif (dirty_log_manual_caps) {\n\t\t\tmemstress_clear_dirty_log(vm, bitmaps, SLOTS, pages_per_slot);\n\n\t\t\tget_page_stats(vm, &stats_clear_pass[iteration - 1], \"clearing dirty log\");\n\t\t}\n\t}\n\n\t \n\tmemstress_disable_dirty_logging(vm, SLOTS);\n\n\tget_page_stats(vm, &stats_dirty_logging_disabled, \"disabling dirty logging\");\n\n\t \n\trun_vcpu_iteration(vm);\n\tget_page_stats(vm, &stats_repopulated, \"repopulating memory\");\n\n\t \n\thost_quit = true;\n\tmemstress_join_vcpu_threads(VCPUS);\n\n\tmemstress_free_bitmaps(bitmaps, SLOTS);\n\tmemstress_destroy_vm(vm);\n\n\t \n\ttotal_4k_pages = stats_populated.pages_4k;\n\ttotal_4k_pages += stats_populated.pages_2m * 512;\n\ttotal_4k_pages += stats_populated.pages_1g * 512 * 512;\n\n\t \n\tif (dirty_log_manual_caps) {\n\t\tTEST_ASSERT_EQ(stats_clear_pass[0].hugepages, 0);\n\t\tTEST_ASSERT_EQ(stats_clear_pass[0].pages_4k, total_4k_pages);\n\t\tTEST_ASSERT_EQ(stats_dirty_logging_enabled.hugepages, stats_populated.hugepages);\n\t} else {\n\t\tTEST_ASSERT_EQ(stats_dirty_logging_enabled.hugepages, 0);\n\t\tTEST_ASSERT_EQ(stats_dirty_logging_enabled.pages_4k, total_4k_pages);\n\t}\n\n\t \n\tTEST_ASSERT_EQ(stats_populated.pages_4k, stats_repopulated.pages_4k);\n\tTEST_ASSERT_EQ(stats_populated.pages_2m, stats_repopulated.pages_2m);\n\tTEST_ASSERT_EQ(stats_populated.pages_1g, stats_repopulated.pages_1g);\n}\n\nstatic void help(char *name)\n{\n\tputs(\"\");\n\tprintf(\"usage: %s [-h] [-b vcpu bytes] [-s mem type]\\n\",\n\t       name);\n\tputs(\"\");\n\tprintf(\" -b: specify the size of the memory region which should be\\n\"\n\t       \"     dirtied by each vCPU. e.g. 10M or 3G.\\n\"\n\t       \"     (default: 1G)\\n\");\n\tbacking_src_help(\"-s\");\n\tputs(\"\");\n}\n\nint main(int argc, char *argv[])\n{\n\tint opt;\n\n\tTEST_REQUIRE(get_kvm_param_bool(\"eager_page_split\"));\n\tTEST_REQUIRE(get_kvm_param_bool(\"tdp_mmu\"));\n\n\twhile ((opt = getopt(argc, argv, \"b:hs:\")) != -1) {\n\t\tswitch (opt) {\n\t\tcase 'b':\n\t\t\tguest_percpu_mem_size = parse_size(optarg);\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\thelp(argv[0]);\n\t\t\texit(0);\n\t\tcase 's':\n\t\t\tbacking_src = parse_backing_src_type(optarg);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\thelp(argv[0]);\n\t\t\texit(1);\n\t\t}\n\t}\n\n\tif (!is_backing_src_hugetlb(backing_src)) {\n\t\tpr_info(\"This test will only work reliably with HugeTLB memory. \"\n\t\t\t\"It can work with THP, but that is best effort.\\n\");\n\t}\n\n\tguest_modes_append_default();\n\n\tdirty_log_manual_caps = 0;\n\tfor_each_guest_mode(run_test, NULL);\n\n\tdirty_log_manual_caps =\n\t\tkvm_check_cap(KVM_CAP_MANUAL_DIRTY_LOG_PROTECT2);\n\n\tif (dirty_log_manual_caps) {\n\t\tdirty_log_manual_caps &= (KVM_DIRTY_LOG_MANUAL_PROTECT_ENABLE |\n\t\t\t\t\t  KVM_DIRTY_LOG_INITIALLY_SET);\n\t\tfor_each_guest_mode(run_test, NULL);\n\t} else {\n\t\tpr_info(\"Skipping testing with MANUAL_PROTECT as it is not supported\");\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}