{
  "module_name": "max_guest_memory_test.c",
  "hash_id": "50bc1849e329e9a293925ebf401426e4fe62b38a2758bd86ca0889c2515cb444",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/max_guest_memory_test.c",
  "human_readable_source": "\n#define _GNU_SOURCE\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <sys/types.h>\n#include <signal.h>\n#include <errno.h>\n#include <linux/bitmap.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sizes.h>\n\n#include \"kvm_util.h\"\n#include \"test_util.h\"\n#include \"guest_modes.h\"\n#include \"processor.h\"\n\nstatic void guest_code(uint64_t start_gpa, uint64_t end_gpa, uint64_t stride)\n{\n\tuint64_t gpa;\n\n\tfor (gpa = start_gpa; gpa < end_gpa; gpa += stride)\n\t\t*((volatile uint64_t *)gpa) = gpa;\n\n\tGUEST_DONE();\n}\n\nstruct vcpu_info {\n\tstruct kvm_vcpu *vcpu;\n\tuint64_t start_gpa;\n\tuint64_t end_gpa;\n};\n\nstatic int nr_vcpus;\nstatic atomic_t rendezvous;\n\nstatic void rendezvous_with_boss(void)\n{\n\tint orig = atomic_read(&rendezvous);\n\n\tif (orig > 0) {\n\t\tatomic_dec_and_test(&rendezvous);\n\t\twhile (atomic_read(&rendezvous) > 0)\n\t\t\tcpu_relax();\n\t} else {\n\t\tatomic_inc(&rendezvous);\n\t\twhile (atomic_read(&rendezvous) < 0)\n\t\t\tcpu_relax();\n\t}\n}\n\nstatic void run_vcpu(struct kvm_vcpu *vcpu)\n{\n\tvcpu_run(vcpu);\n\tTEST_ASSERT_EQ(get_ucall(vcpu, NULL), UCALL_DONE);\n}\n\nstatic void *vcpu_worker(void *data)\n{\n\tstruct vcpu_info *info = data;\n\tstruct kvm_vcpu *vcpu = info->vcpu;\n\tstruct kvm_vm *vm = vcpu->vm;\n\tstruct kvm_sregs sregs;\n\tstruct kvm_regs regs;\n\n\tvcpu_args_set(vcpu, 3, info->start_gpa, info->end_gpa, vm->page_size);\n\n\t \n\tvcpu_regs_get(vcpu, &regs);\n\trendezvous_with_boss();\n\n\trun_vcpu(vcpu);\n\trendezvous_with_boss();\n\tvcpu_regs_set(vcpu, &regs);\n\tvcpu_sregs_get(vcpu, &sregs);\n#ifdef __x86_64__\n\t \n\tsregs.cr0 ^= X86_CR0_WP;\n#endif\n\tvcpu_sregs_set(vcpu, &sregs);\n\trendezvous_with_boss();\n\n\trun_vcpu(vcpu);\n\trendezvous_with_boss();\n\n\treturn NULL;\n}\n\nstatic pthread_t *spawn_workers(struct kvm_vm *vm, struct kvm_vcpu **vcpus,\n\t\t\t\tuint64_t start_gpa, uint64_t end_gpa)\n{\n\tstruct vcpu_info *info;\n\tuint64_t gpa, nr_bytes;\n\tpthread_t *threads;\n\tint i;\n\n\tthreads = malloc(nr_vcpus * sizeof(*threads));\n\tTEST_ASSERT(threads, \"Failed to allocate vCPU threads\");\n\n\tinfo = malloc(nr_vcpus * sizeof(*info));\n\tTEST_ASSERT(info, \"Failed to allocate vCPU gpa ranges\");\n\n\tnr_bytes = ((end_gpa - start_gpa) / nr_vcpus) &\n\t\t\t~((uint64_t)vm->page_size - 1);\n\tTEST_ASSERT(nr_bytes, \"C'mon, no way you have %d CPUs\", nr_vcpus);\n\n\tfor (i = 0, gpa = start_gpa; i < nr_vcpus; i++, gpa += nr_bytes) {\n\t\tinfo[i].vcpu = vcpus[i];\n\t\tinfo[i].start_gpa = gpa;\n\t\tinfo[i].end_gpa = gpa + nr_bytes;\n\t\tpthread_create(&threads[i], NULL, vcpu_worker, &info[i]);\n\t}\n\treturn threads;\n}\n\nstatic void rendezvous_with_vcpus(struct timespec *time, const char *name)\n{\n\tint i, rendezvoused;\n\n\tpr_info(\"Waiting for vCPUs to finish %s...\\n\", name);\n\n\trendezvoused = atomic_read(&rendezvous);\n\tfor (i = 0; abs(rendezvoused) != 1; i++) {\n\t\tusleep(100);\n\t\tif (!(i & 0x3f))\n\t\t\tpr_info(\"\\r%d vCPUs haven't rendezvoused...\",\n\t\t\t\tabs(rendezvoused) - 1);\n\t\trendezvoused = atomic_read(&rendezvous);\n\t}\n\n\tclock_gettime(CLOCK_MONOTONIC, time);\n\n\t \n\tpr_info(\"\\rAll vCPUs finished %s, releasing...\\n\", name);\n\tif (rendezvoused > 0)\n\t\tatomic_set(&rendezvous, -nr_vcpus - 1);\n\telse\n\t\tatomic_set(&rendezvous, nr_vcpus + 1);\n}\n\nstatic void calc_default_nr_vcpus(void)\n{\n\tcpu_set_t possible_mask;\n\tint r;\n\n\tr = sched_getaffinity(0, sizeof(possible_mask), &possible_mask);\n\tTEST_ASSERT(!r, \"sched_getaffinity failed, errno = %d (%s)\",\n\t\t    errno, strerror(errno));\n\n\tnr_vcpus = CPU_COUNT(&possible_mask) * 3/4;\n\tTEST_ASSERT(nr_vcpus > 0, \"Uh, no CPUs?\");\n}\n\nint main(int argc, char *argv[])\n{\n\t \n\tconst uint64_t start_gpa = SZ_4G;\n\tconst int first_slot = 1;\n\n\tstruct timespec time_start, time_run1, time_reset, time_run2;\n\tuint64_t max_gpa, gpa, slot_size, max_mem, i;\n\tint max_slots, slot, opt, fd;\n\tbool hugepages = false;\n\tstruct kvm_vcpu **vcpus;\n\tpthread_t *threads;\n\tstruct kvm_vm *vm;\n\tvoid *mem;\n\n\t \n\tslot_size = SZ_2G;\n\n\tmax_slots = kvm_check_cap(KVM_CAP_NR_MEMSLOTS);\n\tTEST_ASSERT(max_slots > first_slot, \"KVM is broken\");\n\n\t \n\tmax_mem = 128ull * SZ_1G;\n\n\tcalc_default_nr_vcpus();\n\n\twhile ((opt = getopt(argc, argv, \"c:h:m:s:H\")) != -1) {\n\t\tswitch (opt) {\n\t\tcase 'c':\n\t\t\tnr_vcpus = atoi_positive(\"Number of vCPUs\", optarg);\n\t\t\tbreak;\n\t\tcase 'm':\n\t\t\tmax_mem = 1ull * atoi_positive(\"Memory size\", optarg) * SZ_1G;\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tslot_size = 1ull * atoi_positive(\"Slot size\", optarg) * SZ_1G;\n\t\t\tbreak;\n\t\tcase 'H':\n\t\t\thugepages = true;\n\t\t\tbreak;\n\t\tcase 'h':\n\t\tdefault:\n\t\t\tprintf(\"usage: %s [-c nr_vcpus] [-m max_mem_in_gb] [-s slot_size_in_gb] [-H]\\n\", argv[0]);\n\t\t\texit(1);\n\t\t}\n\t}\n\n\tvcpus = malloc(nr_vcpus * sizeof(*vcpus));\n\tTEST_ASSERT(vcpus, \"Failed to allocate vCPU array\");\n\n\tvm = vm_create_with_vcpus(nr_vcpus, guest_code, vcpus);\n\n\tmax_gpa = vm->max_gfn << vm->page_shift;\n\tTEST_ASSERT(max_gpa > (4 * slot_size), \"MAXPHYADDR <4gb \");\n\n\tfd = kvm_memfd_alloc(slot_size, hugepages);\n\tmem = mmap(NULL, slot_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n\tTEST_ASSERT(mem != MAP_FAILED, \"mmap() failed\");\n\n\tTEST_ASSERT(!madvise(mem, slot_size, MADV_NOHUGEPAGE), \"madvise() failed\");\n\n\t \n\tfor (i = 0; i < slot_size; i += vm->page_size)\n\t\t((uint8_t *)mem)[i] = 0xaa;\n\n\tgpa = 0;\n\tfor (slot = first_slot; slot < max_slots; slot++) {\n\t\tgpa = start_gpa + ((slot - first_slot) * slot_size);\n\t\tif (gpa + slot_size > max_gpa)\n\t\t\tbreak;\n\n\t\tif ((gpa - start_gpa) >= max_mem)\n\t\t\tbreak;\n\n\t\tvm_set_user_memory_region(vm, slot, 0, gpa, slot_size, mem);\n\n#ifdef __x86_64__\n\t\t \n\t\tfor (i = 0; i < slot_size; i += SZ_1G)\n\t\t\t__virt_pg_map(vm, gpa + i, gpa + i, PG_LEVEL_1G);\n#else\n\t\tfor (i = 0; i < slot_size; i += vm->page_size)\n\t\t\tvirt_pg_map(vm, gpa + i, gpa + i);\n#endif\n\t}\n\n\tatomic_set(&rendezvous, nr_vcpus + 1);\n\tthreads = spawn_workers(vm, vcpus, start_gpa, gpa);\n\n\tfree(vcpus);\n\tvcpus = NULL;\n\n\tpr_info(\"Running with %lugb of guest memory and %u vCPUs\\n\",\n\t\t(gpa - start_gpa) / SZ_1G, nr_vcpus);\n\n\trendezvous_with_vcpus(&time_start, \"spawning\");\n\trendezvous_with_vcpus(&time_run1, \"run 1\");\n\trendezvous_with_vcpus(&time_reset, \"reset\");\n\trendezvous_with_vcpus(&time_run2, \"run 2\");\n\n\ttime_run2  = timespec_sub(time_run2,   time_reset);\n\ttime_reset = timespec_sub(time_reset, time_run1);\n\ttime_run1  = timespec_sub(time_run1,   time_start);\n\n\tpr_info(\"run1 = %ld.%.9lds, reset = %ld.%.9lds, run2 =  %ld.%.9lds\\n\",\n\t\ttime_run1.tv_sec, time_run1.tv_nsec,\n\t\ttime_reset.tv_sec, time_reset.tv_nsec,\n\t\ttime_run2.tv_sec, time_run2.tv_nsec);\n\n\t \n\tfor (slot = (slot - 1) & ~1ull; slot >= first_slot; slot -= 2)\n\t\tvm_set_user_memory_region(vm, slot, 0, 0, 0, NULL);\n\n\tmunmap(mem, slot_size / 2);\n\n\t \n\tfor (i = 0; i < nr_vcpus; i++)\n\t\tpthread_join(threads[i], NULL);\n\n\t \n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}