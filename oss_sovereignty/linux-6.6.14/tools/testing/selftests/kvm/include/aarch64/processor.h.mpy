{
  "module_name": "processor.h",
  "hash_id": "463a00b141cc338e19f4d1313bebeb855305f3971f59341289fa01806e5a15f0",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/kvm/include/aarch64/processor.h",
  "human_readable_source": " \n \n#ifndef SELFTEST_KVM_PROCESSOR_H\n#define SELFTEST_KVM_PROCESSOR_H\n\n#include \"kvm_util.h\"\n#include <linux/stringify.h>\n#include <linux/types.h>\n#include <asm/sysreg.h>\n\n\n#define ARM64_CORE_REG(x) (KVM_REG_ARM64 | KVM_REG_SIZE_U64 | \\\n\t\t\t   KVM_REG_ARM_CORE | KVM_REG_ARM_CORE_REG(x))\n\n \n#define KVM_ARM64_SYS_REG(sys_reg_id)\t\t\t\\\n\tARM64_SYS_REG(sys_reg_Op0(sys_reg_id),\t\t\\\n\t\t\tsys_reg_Op1(sys_reg_id),\t\\\n\t\t\tsys_reg_CRn(sys_reg_id),\t\\\n\t\t\tsys_reg_CRm(sys_reg_id),\t\\\n\t\t\tsys_reg_Op2(sys_reg_id))\n\n \n\n \n#define MAIR_ATTR_DEVICE_GRE\tUL(0x0c)\n#define MAIR_ATTR_NORMAL_WT\tUL(0xbb)\n\n#define MT_DEVICE_nGnRnE\t0\n#define MT_DEVICE_nGnRE\t\t1\n#define MT_DEVICE_GRE\t\t2\n#define MT_NORMAL_NC\t\t3\n#define MT_NORMAL\t\t4\n#define MT_NORMAL_WT\t\t5\n\n#define DEFAULT_MAIR_EL1\t\t\t\t\t\t\t\\\n\t(MAIR_ATTRIDX(MAIR_ATTR_DEVICE_nGnRnE, MT_DEVICE_nGnRnE) |\t\t\\\n\t MAIR_ATTRIDX(MAIR_ATTR_DEVICE_nGnRE, MT_DEVICE_nGnRE) |\t\t\\\n\t MAIR_ATTRIDX(MAIR_ATTR_DEVICE_GRE, MT_DEVICE_GRE) |\t\t\t\\\n\t MAIR_ATTRIDX(MAIR_ATTR_NORMAL_NC, MT_NORMAL_NC) |\t\t\t\\\n\t MAIR_ATTRIDX(MAIR_ATTR_NORMAL, MT_NORMAL) |\t\t\t\t\\\n\t MAIR_ATTRIDX(MAIR_ATTR_NORMAL_WT, MT_NORMAL_WT))\n\n#define MPIDR_HWID_BITMASK (0xff00fffffful)\n\nvoid aarch64_vcpu_setup(struct kvm_vcpu *vcpu, struct kvm_vcpu_init *init);\nstruct kvm_vcpu *aarch64_vcpu_add(struct kvm_vm *vm, uint32_t vcpu_id,\n\t\t\t\t  struct kvm_vcpu_init *init, void *guest_code);\n\nstruct ex_regs {\n\tu64 regs[31];\n\tu64 sp;\n\tu64 pc;\n\tu64 pstate;\n};\n\n#define VECTOR_NUM\t16\n\nenum {\n\tVECTOR_SYNC_CURRENT_SP0,\n\tVECTOR_IRQ_CURRENT_SP0,\n\tVECTOR_FIQ_CURRENT_SP0,\n\tVECTOR_ERROR_CURRENT_SP0,\n\n\tVECTOR_SYNC_CURRENT,\n\tVECTOR_IRQ_CURRENT,\n\tVECTOR_FIQ_CURRENT,\n\tVECTOR_ERROR_CURRENT,\n\n\tVECTOR_SYNC_LOWER_64,\n\tVECTOR_IRQ_LOWER_64,\n\tVECTOR_FIQ_LOWER_64,\n\tVECTOR_ERROR_LOWER_64,\n\n\tVECTOR_SYNC_LOWER_32,\n\tVECTOR_IRQ_LOWER_32,\n\tVECTOR_FIQ_LOWER_32,\n\tVECTOR_ERROR_LOWER_32,\n};\n\n#define VECTOR_IS_SYNC(v) ((v) == VECTOR_SYNC_CURRENT_SP0 || \\\n\t\t\t   (v) == VECTOR_SYNC_CURRENT     || \\\n\t\t\t   (v) == VECTOR_SYNC_LOWER_64    || \\\n\t\t\t   (v) == VECTOR_SYNC_LOWER_32)\n\n#define ESR_EC_NUM\t\t64\n#define ESR_EC_SHIFT\t\t26\n#define ESR_EC_MASK\t\t(ESR_EC_NUM - 1)\n\n#define ESR_EC_SVC64\t\t0x15\n#define ESR_EC_IABT\t\t0x21\n#define ESR_EC_DABT\t\t0x25\n#define ESR_EC_HW_BP_CURRENT\t0x31\n#define ESR_EC_SSTEP_CURRENT\t0x33\n#define ESR_EC_WP_CURRENT\t0x35\n#define ESR_EC_BRK_INS\t\t0x3c\n\n \n#define PTE_AF\t\t\t(1ULL << 10)\n\n \n#define TCR_EL1_HA\t\t(1ULL << 39)\n\nvoid aarch64_get_supported_page_sizes(uint32_t ipa,\n\t\t\t\t      bool *ps4k, bool *ps16k, bool *ps64k);\n\nvoid vm_init_descriptor_tables(struct kvm_vm *vm);\nvoid vcpu_init_descriptor_tables(struct kvm_vcpu *vcpu);\n\ntypedef void(*handler_fn)(struct ex_regs *);\nvoid vm_install_exception_handler(struct kvm_vm *vm,\n\t\tint vector, handler_fn handler);\nvoid vm_install_sync_handler(struct kvm_vm *vm,\n\t\tint vector, int ec, handler_fn handler);\n\nuint64_t *virt_get_pte_hva(struct kvm_vm *vm, vm_vaddr_t gva);\n\nstatic inline void cpu_relax(void)\n{\n\tasm volatile(\"yield\" ::: \"memory\");\n}\n\n#define isb()\t\tasm volatile(\"isb\" : : : \"memory\")\n#define dsb(opt)\tasm volatile(\"dsb \" #opt : : : \"memory\")\n#define dmb(opt)\tasm volatile(\"dmb \" #opt : : : \"memory\")\n\n#define dma_wmb()\tdmb(oshst)\n#define __iowmb()\tdma_wmb()\n\n#define dma_rmb()\tdmb(oshld)\n\n#define __iormb(v)\t\t\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tunsigned long tmp;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tdma_rmb();\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t \t\t\t\t\t\t\t\t\\\n\tasm volatile(\"eor\t%0, %1, %1\\n\"\t\t\t\t\\\n\t\t     \"cbnz\t%0, .\"\t\t\t\t\t\\\n\t\t     : \"=r\" (tmp) : \"r\" ((unsigned long)(v))\t\t\\\n\t\t     : \"memory\");\t\t\t\t\t\\\n})\n\nstatic __always_inline void __raw_writel(u32 val, volatile void *addr)\n{\n\tasm volatile(\"str %w0, [%1]\" : : \"rZ\" (val), \"r\" (addr));\n}\n\nstatic __always_inline u32 __raw_readl(const volatile void *addr)\n{\n\tu32 val;\n\tasm volatile(\"ldr %w0, [%1]\" : \"=r\" (val) : \"r\" (addr));\n\treturn val;\n}\n\n#define writel_relaxed(v,c)\t((void)__raw_writel((__force u32)cpu_to_le32(v),(c)))\n#define readl_relaxed(c)\t({ u32 __r = le32_to_cpu((__force __le32)__raw_readl(c)); __r; })\n\n#define writel(v,c)\t\t({ __iowmb(); writel_relaxed((v),(c));})\n#define readl(c)\t\t({ u32 __v = readl_relaxed(c); __iormb(__v); __v; })\n\nstatic inline void local_irq_enable(void)\n{\n\tasm volatile(\"msr daifclr, #3\" : : : \"memory\");\n}\n\nstatic inline void local_irq_disable(void)\n{\n\tasm volatile(\"msr daifset, #3\" : : : \"memory\");\n}\n\n \nstruct arm_smccc_res {\n\tunsigned long a0;\n\tunsigned long a1;\n\tunsigned long a2;\n\tunsigned long a3;\n};\n\n \nvoid smccc_hvc(uint32_t function_id, uint64_t arg0, uint64_t arg1,\n\t       uint64_t arg2, uint64_t arg3, uint64_t arg4, uint64_t arg5,\n\t       uint64_t arg6, struct arm_smccc_res *res);\n\n \nvoid smccc_smc(uint32_t function_id, uint64_t arg0, uint64_t arg1,\n\t       uint64_t arg2, uint64_t arg3, uint64_t arg4, uint64_t arg5,\n\t       uint64_t arg6, struct arm_smccc_res *res);\n\n\n\nuint32_t guest_get_vcpuid(void);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}