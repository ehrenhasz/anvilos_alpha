{
  "module_name": "param_test.c",
  "hash_id": "737b3c2f7e1801ae1e578e4dcffaf28dad132434b66a05eed10bdd35fbb721cb",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/rseq/param_test.c",
  "human_readable_source": "\n#define _GNU_SOURCE\n#include <assert.h>\n#include <linux/membarrier.h>\n#include <pthread.h>\n#include <sched.h>\n#include <stdatomic.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <syscall.h>\n#include <unistd.h>\n#include <poll.h>\n#include <sys/types.h>\n#include <signal.h>\n#include <errno.h>\n#include <stddef.h>\n#include <stdbool.h>\n\nstatic inline pid_t rseq_gettid(void)\n{\n\treturn syscall(__NR_gettid);\n}\n\n#define NR_INJECT\t9\nstatic int loop_cnt[NR_INJECT + 1];\n\nstatic int loop_cnt_1 asm(\"asm_loop_cnt_1\") __attribute__((used));\nstatic int loop_cnt_2 asm(\"asm_loop_cnt_2\") __attribute__((used));\nstatic int loop_cnt_3 asm(\"asm_loop_cnt_3\") __attribute__((used));\nstatic int loop_cnt_4 asm(\"asm_loop_cnt_4\") __attribute__((used));\nstatic int loop_cnt_5 asm(\"asm_loop_cnt_5\") __attribute__((used));\nstatic int loop_cnt_6 asm(\"asm_loop_cnt_6\") __attribute__((used));\n\nstatic int opt_modulo, verbose;\n\nstatic int opt_yield, opt_signal, opt_sleep,\n\t\topt_disable_rseq, opt_threads = 200,\n\t\topt_disable_mod = 0, opt_test = 's';\n\nstatic long long opt_reps = 5000;\n\nstatic __thread __attribute__((tls_model(\"initial-exec\")))\nunsigned int signals_delivered;\n\n#ifndef BENCHMARK\n\nstatic __thread __attribute__((tls_model(\"initial-exec\"), unused))\nunsigned int yield_mod_cnt, nr_abort;\n\n#define printf_verbose(fmt, ...)\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\tif (verbose)\t\t\t\t\\\n\t\t\tprintf(fmt, ## __VA_ARGS__);\t\\\n\t} while (0)\n\n#ifdef __i386__\n\n#define INJECT_ASM_REG\t\"eax\"\n\n#define RSEQ_INJECT_CLOBBER \\\n\t, INJECT_ASM_REG\n\n#define RSEQ_INJECT_ASM(n) \\\n\t\"mov asm_loop_cnt_\" #n \", %%\" INJECT_ASM_REG \"\\n\\t\" \\\n\t\"test %%\" INJECT_ASM_REG \",%%\" INJECT_ASM_REG \"\\n\\t\" \\\n\t\"jz 333f\\n\\t\" \\\n\t\"222:\\n\\t\" \\\n\t\"dec %%\" INJECT_ASM_REG \"\\n\\t\" \\\n\t\"jnz 222b\\n\\t\" \\\n\t\"333:\\n\\t\"\n\n#elif defined(__x86_64__)\n\n#define INJECT_ASM_REG_P\t\"rax\"\n#define INJECT_ASM_REG\t\t\"eax\"\n\n#define RSEQ_INJECT_CLOBBER \\\n\t, INJECT_ASM_REG_P \\\n\t, INJECT_ASM_REG\n\n#define RSEQ_INJECT_ASM(n) \\\n\t\"lea asm_loop_cnt_\" #n \"(%%rip), %%\" INJECT_ASM_REG_P \"\\n\\t\" \\\n\t\"mov (%%\" INJECT_ASM_REG_P \"), %%\" INJECT_ASM_REG \"\\n\\t\" \\\n\t\"test %%\" INJECT_ASM_REG \",%%\" INJECT_ASM_REG \"\\n\\t\" \\\n\t\"jz 333f\\n\\t\" \\\n\t\"222:\\n\\t\" \\\n\t\"dec %%\" INJECT_ASM_REG \"\\n\\t\" \\\n\t\"jnz 222b\\n\\t\" \\\n\t\"333:\\n\\t\"\n\n#elif defined(__s390__)\n\n#define RSEQ_INJECT_INPUT \\\n\t, [loop_cnt_1]\"m\"(loop_cnt[1]) \\\n\t, [loop_cnt_2]\"m\"(loop_cnt[2]) \\\n\t, [loop_cnt_3]\"m\"(loop_cnt[3]) \\\n\t, [loop_cnt_4]\"m\"(loop_cnt[4]) \\\n\t, [loop_cnt_5]\"m\"(loop_cnt[5]) \\\n\t, [loop_cnt_6]\"m\"(loop_cnt[6])\n\n#define INJECT_ASM_REG\t\"r12\"\n\n#define RSEQ_INJECT_CLOBBER \\\n\t, INJECT_ASM_REG\n\n#define RSEQ_INJECT_ASM(n) \\\n\t\"l %%\" INJECT_ASM_REG \", %[loop_cnt_\" #n \"]\\n\\t\" \\\n\t\"ltr %%\" INJECT_ASM_REG \", %%\" INJECT_ASM_REG \"\\n\\t\" \\\n\t\"je 333f\\n\\t\" \\\n\t\"222:\\n\\t\" \\\n\t\"ahi %%\" INJECT_ASM_REG \", -1\\n\\t\" \\\n\t\"jnz 222b\\n\\t\" \\\n\t\"333:\\n\\t\"\n\n#elif defined(__ARMEL__)\n\n#define RSEQ_INJECT_INPUT \\\n\t, [loop_cnt_1]\"m\"(loop_cnt[1]) \\\n\t, [loop_cnt_2]\"m\"(loop_cnt[2]) \\\n\t, [loop_cnt_3]\"m\"(loop_cnt[3]) \\\n\t, [loop_cnt_4]\"m\"(loop_cnt[4]) \\\n\t, [loop_cnt_5]\"m\"(loop_cnt[5]) \\\n\t, [loop_cnt_6]\"m\"(loop_cnt[6])\n\n#define INJECT_ASM_REG\t\"r4\"\n\n#define RSEQ_INJECT_CLOBBER \\\n\t, INJECT_ASM_REG\n\n#define RSEQ_INJECT_ASM(n) \\\n\t\"ldr \" INJECT_ASM_REG \", %[loop_cnt_\" #n \"]\\n\\t\" \\\n\t\"cmp \" INJECT_ASM_REG \", #0\\n\\t\" \\\n\t\"beq 333f\\n\\t\" \\\n\t\"222:\\n\\t\" \\\n\t\"subs \" INJECT_ASM_REG \", #1\\n\\t\" \\\n\t\"bne 222b\\n\\t\" \\\n\t\"333:\\n\\t\"\n\n#elif defined(__AARCH64EL__)\n\n#define RSEQ_INJECT_INPUT \\\n\t, [loop_cnt_1] \"Qo\" (loop_cnt[1]) \\\n\t, [loop_cnt_2] \"Qo\" (loop_cnt[2]) \\\n\t, [loop_cnt_3] \"Qo\" (loop_cnt[3]) \\\n\t, [loop_cnt_4] \"Qo\" (loop_cnt[4]) \\\n\t, [loop_cnt_5] \"Qo\" (loop_cnt[5]) \\\n\t, [loop_cnt_6] \"Qo\" (loop_cnt[6])\n\n#define INJECT_ASM_REG\tRSEQ_ASM_TMP_REG32\n\n#define RSEQ_INJECT_ASM(n) \\\n\t\"\tldr\t\" INJECT_ASM_REG \", %[loop_cnt_\" #n \"]\\n\"\t\\\n\t\"\tcbz\t\" INJECT_ASM_REG \", 333f\\n\"\t\t\t\\\n\t\"222:\\n\"\t\t\t\t\t\t\t\\\n\t\"\tsub\t\" INJECT_ASM_REG \", \" INJECT_ASM_REG \", #1\\n\"\t\\\n\t\"\tcbnz\t\" INJECT_ASM_REG \", 222b\\n\"\t\t\t\\\n\t\"333:\\n\"\n\n#elif defined(__PPC__)\n\n#define RSEQ_INJECT_INPUT \\\n\t, [loop_cnt_1]\"m\"(loop_cnt[1]) \\\n\t, [loop_cnt_2]\"m\"(loop_cnt[2]) \\\n\t, [loop_cnt_3]\"m\"(loop_cnt[3]) \\\n\t, [loop_cnt_4]\"m\"(loop_cnt[4]) \\\n\t, [loop_cnt_5]\"m\"(loop_cnt[5]) \\\n\t, [loop_cnt_6]\"m\"(loop_cnt[6])\n\n#define INJECT_ASM_REG\t\"r18\"\n\n#define RSEQ_INJECT_CLOBBER \\\n\t, INJECT_ASM_REG\n\n#define RSEQ_INJECT_ASM(n) \\\n\t\"lwz %%\" INJECT_ASM_REG \", %[loop_cnt_\" #n \"]\\n\\t\" \\\n\t\"cmpwi %%\" INJECT_ASM_REG \", 0\\n\\t\" \\\n\t\"beq 333f\\n\\t\" \\\n\t\"222:\\n\\t\" \\\n\t\"subic. %%\" INJECT_ASM_REG \", %%\" INJECT_ASM_REG \", 1\\n\\t\" \\\n\t\"bne 222b\\n\\t\" \\\n\t\"333:\\n\\t\"\n\n#elif defined(__mips__)\n\n#define RSEQ_INJECT_INPUT \\\n\t, [loop_cnt_1]\"m\"(loop_cnt[1]) \\\n\t, [loop_cnt_2]\"m\"(loop_cnt[2]) \\\n\t, [loop_cnt_3]\"m\"(loop_cnt[3]) \\\n\t, [loop_cnt_4]\"m\"(loop_cnt[4]) \\\n\t, [loop_cnt_5]\"m\"(loop_cnt[5]) \\\n\t, [loop_cnt_6]\"m\"(loop_cnt[6])\n\n#define INJECT_ASM_REG\t\"$5\"\n\n#define RSEQ_INJECT_CLOBBER \\\n\t, INJECT_ASM_REG\n\n#define RSEQ_INJECT_ASM(n) \\\n\t\"lw \" INJECT_ASM_REG \", %[loop_cnt_\" #n \"]\\n\\t\" \\\n\t\"beqz \" INJECT_ASM_REG \", 333f\\n\\t\" \\\n\t\"222:\\n\\t\" \\\n\t\"addiu \" INJECT_ASM_REG \", -1\\n\\t\" \\\n\t\"bnez \" INJECT_ASM_REG \", 222b\\n\\t\" \\\n\t\"333:\\n\\t\"\n#elif defined(__riscv)\n\n#define RSEQ_INJECT_INPUT \\\n\t, [loop_cnt_1]\"m\"(loop_cnt[1]) \\\n\t, [loop_cnt_2]\"m\"(loop_cnt[2]) \\\n\t, [loop_cnt_3]\"m\"(loop_cnt[3]) \\\n\t, [loop_cnt_4]\"m\"(loop_cnt[4]) \\\n\t, [loop_cnt_5]\"m\"(loop_cnt[5]) \\\n\t, [loop_cnt_6]\"m\"(loop_cnt[6])\n\n#define INJECT_ASM_REG\t\"t1\"\n\n#define RSEQ_INJECT_CLOBBER \\\n\t, INJECT_ASM_REG\n\n#define RSEQ_INJECT_ASM(n)\t\t\t\t\t\\\n\t\"lw \" INJECT_ASM_REG \", %[loop_cnt_\" #n \"]\\n\\t\"\t\t\\\n\t\"beqz \" INJECT_ASM_REG \", 333f\\n\\t\"\t\t\t\\\n\t\"222:\\n\\t\"\t\t\t\t\t\t\\\n\t\"addi  \" INJECT_ASM_REG \",\" INJECT_ASM_REG \", -1\\n\\t\"\t\\\n\t\"bnez \" INJECT_ASM_REG \", 222b\\n\\t\"\t\t\t\\\n\t\"333:\\n\\t\"\n\n\n#else\n#error unsupported target\n#endif\n\n#define RSEQ_INJECT_FAILED \\\n\tnr_abort++;\n\n#define RSEQ_INJECT_C(n) \\\n{ \\\n\tint loc_i, loc_nr_loops = loop_cnt[n]; \\\n\t\\\n\tfor (loc_i = 0; loc_i < loc_nr_loops; loc_i++) { \\\n\t\trseq_barrier(); \\\n\t} \\\n\tif (loc_nr_loops == -1 && opt_modulo) { \\\n\t\tif (yield_mod_cnt == opt_modulo - 1) { \\\n\t\t\tif (opt_sleep > 0) \\\n\t\t\t\tpoll(NULL, 0, opt_sleep); \\\n\t\t\tif (opt_yield) \\\n\t\t\t\tsched_yield(); \\\n\t\t\tif (opt_signal) \\\n\t\t\t\traise(SIGUSR1); \\\n\t\t\tyield_mod_cnt = 0; \\\n\t\t} else { \\\n\t\t\tyield_mod_cnt++; \\\n\t\t} \\\n\t} \\\n}\n\n#else\n\n#define printf_verbose(fmt, ...)\n\n#endif  \n\n#include \"rseq.h\"\n\nstatic enum rseq_mo opt_mo = RSEQ_MO_RELAXED;\n\n#ifdef RSEQ_ARCH_HAS_OFFSET_DEREF_ADDV\n#define TEST_MEMBARRIER\n\nstatic int sys_membarrier(int cmd, int flags, int cpu_id)\n{\n\treturn syscall(__NR_membarrier, cmd, flags, cpu_id);\n}\n#endif\n\n#ifdef BUILDOPT_RSEQ_PERCPU_MM_CID\n# define RSEQ_PERCPU\tRSEQ_PERCPU_MM_CID\nstatic\nint get_current_cpu_id(void)\n{\n\treturn rseq_current_mm_cid();\n}\nstatic\nbool rseq_validate_cpu_id(void)\n{\n\treturn rseq_mm_cid_available();\n}\n# ifdef TEST_MEMBARRIER\n \nstatic\nint rseq_membarrier_expedited(int cpu)\n{\n\treturn sys_membarrier(MEMBARRIER_CMD_PRIVATE_EXPEDITED_RSEQ,\n\t\t\t      0, 0);\n}\n# endif  \n#else\n# define RSEQ_PERCPU\tRSEQ_PERCPU_CPU_ID\nstatic\nint get_current_cpu_id(void)\n{\n\treturn rseq_cpu_start();\n}\nstatic\nbool rseq_validate_cpu_id(void)\n{\n\treturn rseq_current_cpu_raw() >= 0;\n}\n# ifdef TEST_MEMBARRIER\nstatic\nint rseq_membarrier_expedited(int cpu)\n{\n\treturn sys_membarrier(MEMBARRIER_CMD_PRIVATE_EXPEDITED_RSEQ,\n\t\t\t      MEMBARRIER_CMD_FLAG_CPU, cpu);\n}\n# endif  \n#endif\n\nstruct percpu_lock_entry {\n\tintptr_t v;\n} __attribute__((aligned(128)));\n\nstruct percpu_lock {\n\tstruct percpu_lock_entry c[CPU_SETSIZE];\n};\n\nstruct test_data_entry {\n\tintptr_t count;\n} __attribute__((aligned(128)));\n\nstruct spinlock_test_data {\n\tstruct percpu_lock lock;\n\tstruct test_data_entry c[CPU_SETSIZE];\n};\n\nstruct spinlock_thread_test_data {\n\tstruct spinlock_test_data *data;\n\tlong long reps;\n\tint reg;\n};\n\nstruct inc_test_data {\n\tstruct test_data_entry c[CPU_SETSIZE];\n};\n\nstruct inc_thread_test_data {\n\tstruct inc_test_data *data;\n\tlong long reps;\n\tint reg;\n};\n\nstruct percpu_list_node {\n\tintptr_t data;\n\tstruct percpu_list_node *next;\n};\n\nstruct percpu_list_entry {\n\tstruct percpu_list_node *head;\n} __attribute__((aligned(128)));\n\nstruct percpu_list {\n\tstruct percpu_list_entry c[CPU_SETSIZE];\n};\n\n#define BUFFER_ITEM_PER_CPU\t100\n\nstruct percpu_buffer_node {\n\tintptr_t data;\n};\n\nstruct percpu_buffer_entry {\n\tintptr_t offset;\n\tintptr_t buflen;\n\tstruct percpu_buffer_node **array;\n} __attribute__((aligned(128)));\n\nstruct percpu_buffer {\n\tstruct percpu_buffer_entry c[CPU_SETSIZE];\n};\n\n#define MEMCPY_BUFFER_ITEM_PER_CPU\t100\n\nstruct percpu_memcpy_buffer_node {\n\tintptr_t data1;\n\tuint64_t data2;\n};\n\nstruct percpu_memcpy_buffer_entry {\n\tintptr_t offset;\n\tintptr_t buflen;\n\tstruct percpu_memcpy_buffer_node *array;\n} __attribute__((aligned(128)));\n\nstruct percpu_memcpy_buffer {\n\tstruct percpu_memcpy_buffer_entry c[CPU_SETSIZE];\n};\n\n \nstatic int rseq_this_cpu_lock(struct percpu_lock *lock)\n{\n\tint cpu;\n\n\tfor (;;) {\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\tif (cpu < 0) {\n\t\t\tfprintf(stderr, \"pid: %d: tid: %d, cpu: %d: cid: %d\\n\",\n\t\t\t\t\tgetpid(), (int) rseq_gettid(), rseq_current_cpu_raw(), cpu);\n\t\t\tabort();\n\t\t}\n\t\tret = rseq_cmpeqv_storev(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t\t &lock->c[cpu].v,\n\t\t\t\t\t 0, 1, cpu);\n\t\tif (rseq_likely(!ret))\n\t\t\tbreak;\n\t\t \n\t}\n\t \n\trseq_smp_acquire__after_ctrl_dep();\n\treturn cpu;\n}\n\nstatic void rseq_percpu_unlock(struct percpu_lock *lock, int cpu)\n{\n\tassert(lock->c[cpu].v == 1);\n\t \n\trseq_smp_store_release(&lock->c[cpu].v, 0);\n}\n\nvoid *test_percpu_spinlock_thread(void *arg)\n{\n\tstruct spinlock_thread_test_data *thread_data = arg;\n\tstruct spinlock_test_data *data = thread_data->data;\n\tlong long i, reps;\n\n\tif (!opt_disable_rseq && thread_data->reg &&\n\t    rseq_register_current_thread())\n\t\tabort();\n\treps = thread_data->reps;\n\tfor (i = 0; i < reps; i++) {\n\t\tint cpu = rseq_this_cpu_lock(&data->lock);\n\t\tdata->c[cpu].count++;\n\t\trseq_percpu_unlock(&data->lock, cpu);\n#ifndef BENCHMARK\n\t\tif (i != 0 && !(i % (reps / 10)))\n\t\t\tprintf_verbose(\"tid %d: count %lld\\n\",\n\t\t\t\t       (int) rseq_gettid(), i);\n#endif\n\t}\n\tprintf_verbose(\"tid %d: number of rseq abort: %d, signals delivered: %u\\n\",\n\t\t       (int) rseq_gettid(), nr_abort, signals_delivered);\n\tif (!opt_disable_rseq && thread_data->reg &&\n\t    rseq_unregister_current_thread())\n\t\tabort();\n\treturn NULL;\n}\n\n \nvoid test_percpu_spinlock(void)\n{\n\tconst int num_threads = opt_threads;\n\tint i, ret;\n\tuint64_t sum;\n\tpthread_t test_threads[num_threads];\n\tstruct spinlock_test_data data;\n\tstruct spinlock_thread_test_data thread_data[num_threads];\n\n\tmemset(&data, 0, sizeof(data));\n\tfor (i = 0; i < num_threads; i++) {\n\t\tthread_data[i].reps = opt_reps;\n\t\tif (opt_disable_mod <= 0 || (i % opt_disable_mod))\n\t\t\tthread_data[i].reg = 1;\n\t\telse\n\t\t\tthread_data[i].reg = 0;\n\t\tthread_data[i].data = &data;\n\t\tret = pthread_create(&test_threads[i], NULL,\n\t\t\t\t     test_percpu_spinlock_thread,\n\t\t\t\t     &thread_data[i]);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_create\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_join(test_threads[i], NULL);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_join\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tsum = 0;\n\tfor (i = 0; i < CPU_SETSIZE; i++)\n\t\tsum += data.c[i].count;\n\n\tassert(sum == (uint64_t)opt_reps * num_threads);\n}\n\nvoid *test_percpu_inc_thread(void *arg)\n{\n\tstruct inc_thread_test_data *thread_data = arg;\n\tstruct inc_test_data *data = thread_data->data;\n\tlong long i, reps;\n\n\tif (!opt_disable_rseq && thread_data->reg &&\n\t    rseq_register_current_thread())\n\t\tabort();\n\treps = thread_data->reps;\n\tfor (i = 0; i < reps; i++) {\n\t\tint ret;\n\n\t\tdo {\n\t\t\tint cpu;\n\n\t\t\tcpu = get_current_cpu_id();\n\t\t\tret = rseq_addv(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t\t&data->c[cpu].count, 1, cpu);\n\t\t} while (rseq_unlikely(ret));\n#ifndef BENCHMARK\n\t\tif (i != 0 && !(i % (reps / 10)))\n\t\t\tprintf_verbose(\"tid %d: count %lld\\n\",\n\t\t\t\t       (int) rseq_gettid(), i);\n#endif\n\t}\n\tprintf_verbose(\"tid %d: number of rseq abort: %d, signals delivered: %u\\n\",\n\t\t       (int) rseq_gettid(), nr_abort, signals_delivered);\n\tif (!opt_disable_rseq && thread_data->reg &&\n\t    rseq_unregister_current_thread())\n\t\tabort();\n\treturn NULL;\n}\n\nvoid test_percpu_inc(void)\n{\n\tconst int num_threads = opt_threads;\n\tint i, ret;\n\tuint64_t sum;\n\tpthread_t test_threads[num_threads];\n\tstruct inc_test_data data;\n\tstruct inc_thread_test_data thread_data[num_threads];\n\n\tmemset(&data, 0, sizeof(data));\n\tfor (i = 0; i < num_threads; i++) {\n\t\tthread_data[i].reps = opt_reps;\n\t\tif (opt_disable_mod <= 0 || (i % opt_disable_mod))\n\t\t\tthread_data[i].reg = 1;\n\t\telse\n\t\t\tthread_data[i].reg = 0;\n\t\tthread_data[i].data = &data;\n\t\tret = pthread_create(&test_threads[i], NULL,\n\t\t\t\t     test_percpu_inc_thread,\n\t\t\t\t     &thread_data[i]);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_create\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_join(test_threads[i], NULL);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_join\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tsum = 0;\n\tfor (i = 0; i < CPU_SETSIZE; i++)\n\t\tsum += data.c[i].count;\n\n\tassert(sum == (uint64_t)opt_reps * num_threads);\n}\n\nvoid this_cpu_list_push(struct percpu_list *list,\n\t\t\tstruct percpu_list_node *node,\n\t\t\tint *_cpu)\n{\n\tint cpu;\n\n\tfor (;;) {\n\t\tintptr_t *targetptr, newval, expect;\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\t \n\t\texpect = (intptr_t)RSEQ_READ_ONCE(list->c[cpu].head);\n\t\tnewval = (intptr_t)node;\n\t\ttargetptr = (intptr_t *)&list->c[cpu].head;\n\t\tnode->next = (struct percpu_list_node *)expect;\n\t\tret = rseq_cmpeqv_storev(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t\t targetptr, expect, newval, cpu);\n\t\tif (rseq_likely(!ret))\n\t\t\tbreak;\n\t\t \n\t}\n\tif (_cpu)\n\t\t*_cpu = cpu;\n}\n\n \nstruct percpu_list_node *this_cpu_list_pop(struct percpu_list *list,\n\t\t\t\t\t   int *_cpu)\n{\n\tstruct percpu_list_node *node = NULL;\n\tint cpu;\n\n\tfor (;;) {\n\t\tstruct percpu_list_node *head;\n\t\tintptr_t *targetptr, expectnot, *load;\n\t\tlong offset;\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\ttargetptr = (intptr_t *)&list->c[cpu].head;\n\t\texpectnot = (intptr_t)NULL;\n\t\toffset = offsetof(struct percpu_list_node, next);\n\t\tload = (intptr_t *)&head;\n\t\tret = rseq_cmpnev_storeoffp_load(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t\t\t targetptr, expectnot,\n\t\t\t\t\t\t offset, load, cpu);\n\t\tif (rseq_likely(!ret)) {\n\t\t\tnode = head;\n\t\t\tbreak;\n\t\t}\n\t\tif (ret > 0)\n\t\t\tbreak;\n\t\t \n\t}\n\tif (_cpu)\n\t\t*_cpu = cpu;\n\treturn node;\n}\n\n \nstruct percpu_list_node *__percpu_list_pop(struct percpu_list *list, int cpu)\n{\n\tstruct percpu_list_node *node;\n\n\tnode = list->c[cpu].head;\n\tif (!node)\n\t\treturn NULL;\n\tlist->c[cpu].head = node->next;\n\treturn node;\n}\n\nvoid *test_percpu_list_thread(void *arg)\n{\n\tlong long i, reps;\n\tstruct percpu_list *list = (struct percpu_list *)arg;\n\n\tif (!opt_disable_rseq && rseq_register_current_thread())\n\t\tabort();\n\n\treps = opt_reps;\n\tfor (i = 0; i < reps; i++) {\n\t\tstruct percpu_list_node *node;\n\n\t\tnode = this_cpu_list_pop(list, NULL);\n\t\tif (opt_yield)\n\t\t\tsched_yield();   \n\t\tif (node)\n\t\t\tthis_cpu_list_push(list, node, NULL);\n\t}\n\n\tprintf_verbose(\"tid %d: number of rseq abort: %d, signals delivered: %u\\n\",\n\t\t       (int) rseq_gettid(), nr_abort, signals_delivered);\n\tif (!opt_disable_rseq && rseq_unregister_current_thread())\n\t\tabort();\n\n\treturn NULL;\n}\n\n \nvoid test_percpu_list(void)\n{\n\tconst int num_threads = opt_threads;\n\tint i, j, ret;\n\tuint64_t sum = 0, expected_sum = 0;\n\tstruct percpu_list list;\n\tpthread_t test_threads[num_threads];\n\tcpu_set_t allowed_cpus;\n\n\tmemset(&list, 0, sizeof(list));\n\n\t \n\tsched_getaffinity(0, sizeof(allowed_cpus), &allowed_cpus);\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\t\tfor (j = 1; j <= 100; j++) {\n\t\t\tstruct percpu_list_node *node;\n\n\t\t\texpected_sum += j;\n\n\t\t\tnode = malloc(sizeof(*node));\n\t\t\tassert(node);\n\t\t\tnode->data = j;\n\t\t\tnode->next = list.c[i].head;\n\t\t\tlist.c[i].head = node;\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_create(&test_threads[i], NULL,\n\t\t\t\t     test_percpu_list_thread, &list);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_create\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_join(test_threads[i], NULL);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_join\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tstruct percpu_list_node *node;\n\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\n\t\twhile ((node = __percpu_list_pop(&list, i))) {\n\t\t\tsum += node->data;\n\t\t\tfree(node);\n\t\t}\n\t}\n\n\t \n\tassert(sum == expected_sum);\n}\n\nbool this_cpu_buffer_push(struct percpu_buffer *buffer,\n\t\t\t  struct percpu_buffer_node *node,\n\t\t\t  int *_cpu)\n{\n\tbool result = false;\n\tint cpu;\n\n\tfor (;;) {\n\t\tintptr_t *targetptr_spec, newval_spec;\n\t\tintptr_t *targetptr_final, newval_final;\n\t\tintptr_t offset;\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\toffset = RSEQ_READ_ONCE(buffer->c[cpu].offset);\n\t\tif (offset == buffer->c[cpu].buflen)\n\t\t\tbreak;\n\t\tnewval_spec = (intptr_t)node;\n\t\ttargetptr_spec = (intptr_t *)&buffer->c[cpu].array[offset];\n\t\tnewval_final = offset + 1;\n\t\ttargetptr_final = &buffer->c[cpu].offset;\n\t\tret = rseq_cmpeqv_trystorev_storev(opt_mo, RSEQ_PERCPU,\n\t\t\ttargetptr_final, offset, targetptr_spec,\n\t\t\tnewval_spec, newval_final, cpu);\n\t\tif (rseq_likely(!ret)) {\n\t\t\tresult = true;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t}\n\tif (_cpu)\n\t\t*_cpu = cpu;\n\treturn result;\n}\n\nstruct percpu_buffer_node *this_cpu_buffer_pop(struct percpu_buffer *buffer,\n\t\t\t\t\t       int *_cpu)\n{\n\tstruct percpu_buffer_node *head;\n\tint cpu;\n\n\tfor (;;) {\n\t\tintptr_t *targetptr, newval;\n\t\tintptr_t offset;\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\t \n\t\toffset = RSEQ_READ_ONCE(buffer->c[cpu].offset);\n\t\tif (offset == 0) {\n\t\t\thead = NULL;\n\t\t\tbreak;\n\t\t}\n\t\thead = RSEQ_READ_ONCE(buffer->c[cpu].array[offset - 1]);\n\t\tnewval = offset - 1;\n\t\ttargetptr = (intptr_t *)&buffer->c[cpu].offset;\n\t\tret = rseq_cmpeqv_cmpeqv_storev(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\ttargetptr, offset,\n\t\t\t(intptr_t *)&buffer->c[cpu].array[offset - 1],\n\t\t\t(intptr_t)head, newval, cpu);\n\t\tif (rseq_likely(!ret))\n\t\t\tbreak;\n\t\t \n\t}\n\tif (_cpu)\n\t\t*_cpu = cpu;\n\treturn head;\n}\n\n \nstruct percpu_buffer_node *__percpu_buffer_pop(struct percpu_buffer *buffer,\n\t\t\t\t\t       int cpu)\n{\n\tstruct percpu_buffer_node *head;\n\tintptr_t offset;\n\n\toffset = buffer->c[cpu].offset;\n\tif (offset == 0)\n\t\treturn NULL;\n\thead = buffer->c[cpu].array[offset - 1];\n\tbuffer->c[cpu].offset = offset - 1;\n\treturn head;\n}\n\nvoid *test_percpu_buffer_thread(void *arg)\n{\n\tlong long i, reps;\n\tstruct percpu_buffer *buffer = (struct percpu_buffer *)arg;\n\n\tif (!opt_disable_rseq && rseq_register_current_thread())\n\t\tabort();\n\n\treps = opt_reps;\n\tfor (i = 0; i < reps; i++) {\n\t\tstruct percpu_buffer_node *node;\n\n\t\tnode = this_cpu_buffer_pop(buffer, NULL);\n\t\tif (opt_yield)\n\t\t\tsched_yield();   \n\t\tif (node) {\n\t\t\tif (!this_cpu_buffer_push(buffer, node, NULL)) {\n\t\t\t\t \n\t\t\t\tabort();\n\t\t\t}\n\t\t}\n\t}\n\n\tprintf_verbose(\"tid %d: number of rseq abort: %d, signals delivered: %u\\n\",\n\t\t       (int) rseq_gettid(), nr_abort, signals_delivered);\n\tif (!opt_disable_rseq && rseq_unregister_current_thread())\n\t\tabort();\n\n\treturn NULL;\n}\n\n \nvoid test_percpu_buffer(void)\n{\n\tconst int num_threads = opt_threads;\n\tint i, j, ret;\n\tuint64_t sum = 0, expected_sum = 0;\n\tstruct percpu_buffer buffer;\n\tpthread_t test_threads[num_threads];\n\tcpu_set_t allowed_cpus;\n\n\tmemset(&buffer, 0, sizeof(buffer));\n\n\t \n\tsched_getaffinity(0, sizeof(allowed_cpus), &allowed_cpus);\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\t\t \n\t\tbuffer.c[i].array =\n\t\t\tmalloc(sizeof(*buffer.c[i].array) * CPU_SETSIZE *\n\t\t\t       BUFFER_ITEM_PER_CPU);\n\t\tassert(buffer.c[i].array);\n\t\tbuffer.c[i].buflen = CPU_SETSIZE * BUFFER_ITEM_PER_CPU;\n\t\tfor (j = 1; j <= BUFFER_ITEM_PER_CPU; j++) {\n\t\t\tstruct percpu_buffer_node *node;\n\n\t\t\texpected_sum += j;\n\n\t\t\t \n\t\t\tnode = malloc(sizeof(*node));\n\t\t\tassert(node);\n\t\t\tnode->data = j;\n\t\t\tbuffer.c[i].array[j - 1] = node;\n\t\t\tbuffer.c[i].offset++;\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_create(&test_threads[i], NULL,\n\t\t\t\t     test_percpu_buffer_thread, &buffer);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_create\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_join(test_threads[i], NULL);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_join\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tstruct percpu_buffer_node *node;\n\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\n\t\twhile ((node = __percpu_buffer_pop(&buffer, i))) {\n\t\t\tsum += node->data;\n\t\t\tfree(node);\n\t\t}\n\t\tfree(buffer.c[i].array);\n\t}\n\n\t \n\tassert(sum == expected_sum);\n}\n\nbool this_cpu_memcpy_buffer_push(struct percpu_memcpy_buffer *buffer,\n\t\t\t\t struct percpu_memcpy_buffer_node item,\n\t\t\t\t int *_cpu)\n{\n\tbool result = false;\n\tint cpu;\n\n\tfor (;;) {\n\t\tintptr_t *targetptr_final, newval_final, offset;\n\t\tchar *destptr, *srcptr;\n\t\tsize_t copylen;\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\t \n\t\toffset = RSEQ_READ_ONCE(buffer->c[cpu].offset);\n\t\tif (offset == buffer->c[cpu].buflen)\n\t\t\tbreak;\n\t\tdestptr = (char *)&buffer->c[cpu].array[offset];\n\t\tsrcptr = (char *)&item;\n\t\t \n\t\tcopylen = sizeof(item);\n\t\tnewval_final = offset + 1;\n\t\ttargetptr_final = &buffer->c[cpu].offset;\n\t\tret = rseq_cmpeqv_trymemcpy_storev(\n\t\t\topt_mo, RSEQ_PERCPU,\n\t\t\ttargetptr_final, offset,\n\t\t\tdestptr, srcptr, copylen,\n\t\t\tnewval_final, cpu);\n\t\tif (rseq_likely(!ret)) {\n\t\t\tresult = true;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t}\n\tif (_cpu)\n\t\t*_cpu = cpu;\n\treturn result;\n}\n\nbool this_cpu_memcpy_buffer_pop(struct percpu_memcpy_buffer *buffer,\n\t\t\t\tstruct percpu_memcpy_buffer_node *item,\n\t\t\t\tint *_cpu)\n{\n\tbool result = false;\n\tint cpu;\n\n\tfor (;;) {\n\t\tintptr_t *targetptr_final, newval_final, offset;\n\t\tchar *destptr, *srcptr;\n\t\tsize_t copylen;\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\t \n\t\toffset = RSEQ_READ_ONCE(buffer->c[cpu].offset);\n\t\tif (offset == 0)\n\t\t\tbreak;\n\t\tdestptr = (char *)item;\n\t\tsrcptr = (char *)&buffer->c[cpu].array[offset - 1];\n\t\t \n\t\tcopylen = sizeof(*item);\n\t\tnewval_final = offset - 1;\n\t\ttargetptr_final = &buffer->c[cpu].offset;\n\t\tret = rseq_cmpeqv_trymemcpy_storev(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\ttargetptr_final, offset, destptr, srcptr, copylen,\n\t\t\tnewval_final, cpu);\n\t\tif (rseq_likely(!ret)) {\n\t\t\tresult = true;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t}\n\tif (_cpu)\n\t\t*_cpu = cpu;\n\treturn result;\n}\n\n \nbool __percpu_memcpy_buffer_pop(struct percpu_memcpy_buffer *buffer,\n\t\t\t\tstruct percpu_memcpy_buffer_node *item,\n\t\t\t\tint cpu)\n{\n\tintptr_t offset;\n\n\toffset = buffer->c[cpu].offset;\n\tif (offset == 0)\n\t\treturn false;\n\tmemcpy(item, &buffer->c[cpu].array[offset - 1], sizeof(*item));\n\tbuffer->c[cpu].offset = offset - 1;\n\treturn true;\n}\n\nvoid *test_percpu_memcpy_buffer_thread(void *arg)\n{\n\tlong long i, reps;\n\tstruct percpu_memcpy_buffer *buffer = (struct percpu_memcpy_buffer *)arg;\n\n\tif (!opt_disable_rseq && rseq_register_current_thread())\n\t\tabort();\n\n\treps = opt_reps;\n\tfor (i = 0; i < reps; i++) {\n\t\tstruct percpu_memcpy_buffer_node item;\n\t\tbool result;\n\n\t\tresult = this_cpu_memcpy_buffer_pop(buffer, &item, NULL);\n\t\tif (opt_yield)\n\t\t\tsched_yield();   \n\t\tif (result) {\n\t\t\tif (!this_cpu_memcpy_buffer_push(buffer, item, NULL)) {\n\t\t\t\t \n\t\t\t\tabort();\n\t\t\t}\n\t\t}\n\t}\n\n\tprintf_verbose(\"tid %d: number of rseq abort: %d, signals delivered: %u\\n\",\n\t\t       (int) rseq_gettid(), nr_abort, signals_delivered);\n\tif (!opt_disable_rseq && rseq_unregister_current_thread())\n\t\tabort();\n\n\treturn NULL;\n}\n\n \nvoid test_percpu_memcpy_buffer(void)\n{\n\tconst int num_threads = opt_threads;\n\tint i, j, ret;\n\tuint64_t sum = 0, expected_sum = 0;\n\tstruct percpu_memcpy_buffer buffer;\n\tpthread_t test_threads[num_threads];\n\tcpu_set_t allowed_cpus;\n\n\tmemset(&buffer, 0, sizeof(buffer));\n\n\t \n\tsched_getaffinity(0, sizeof(allowed_cpus), &allowed_cpus);\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\t\t \n\t\tbuffer.c[i].array =\n\t\t\tmalloc(sizeof(*buffer.c[i].array) * CPU_SETSIZE *\n\t\t\t       MEMCPY_BUFFER_ITEM_PER_CPU);\n\t\tassert(buffer.c[i].array);\n\t\tbuffer.c[i].buflen = CPU_SETSIZE * MEMCPY_BUFFER_ITEM_PER_CPU;\n\t\tfor (j = 1; j <= MEMCPY_BUFFER_ITEM_PER_CPU; j++) {\n\t\t\texpected_sum += 2 * j + 1;\n\n\t\t\t \n\t\t\tbuffer.c[i].array[j - 1].data1 = j;\n\t\t\tbuffer.c[i].array[j - 1].data2 = j + 1;\n\t\t\tbuffer.c[i].offset++;\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_create(&test_threads[i], NULL,\n\t\t\t\t     test_percpu_memcpy_buffer_thread,\n\t\t\t\t     &buffer);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_create\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_join(test_threads[i], NULL);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_join\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tstruct percpu_memcpy_buffer_node item;\n\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\n\t\twhile (__percpu_memcpy_buffer_pop(&buffer, &item, i)) {\n\t\t\tsum += item.data1;\n\t\t\tsum += item.data2;\n\t\t}\n\t\tfree(buffer.c[i].array);\n\t}\n\n\t \n\tassert(sum == expected_sum);\n}\n\nstatic void test_signal_interrupt_handler(int signo)\n{\n\tsignals_delivered++;\n}\n\nstatic int set_signal_handler(void)\n{\n\tint ret = 0;\n\tstruct sigaction sa;\n\tsigset_t sigset;\n\n\tret = sigemptyset(&sigset);\n\tif (ret < 0) {\n\t\tperror(\"sigemptyset\");\n\t\treturn ret;\n\t}\n\n\tsa.sa_handler = test_signal_interrupt_handler;\n\tsa.sa_mask = sigset;\n\tsa.sa_flags = 0;\n\tret = sigaction(SIGUSR1, &sa, NULL);\n\tif (ret < 0) {\n\t\tperror(\"sigaction\");\n\t\treturn ret;\n\t}\n\n\tprintf_verbose(\"Signal handler set for SIGUSR1\\n\");\n\n\treturn ret;\n}\n\n \n#ifdef TEST_MEMBARRIER\nstruct test_membarrier_thread_args {\n\tint stop;\n\tintptr_t percpu_list_ptr;\n};\n\n \nvoid *test_membarrier_worker_thread(void *arg)\n{\n\tstruct test_membarrier_thread_args *args =\n\t\t(struct test_membarrier_thread_args *)arg;\n\tconst int iters = opt_reps;\n\tint i;\n\n\tif (rseq_register_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_register_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\n\t \n\twhile (!atomic_load(&args->percpu_list_ptr)) {}\n\n\tfor (i = 0; i < iters; ++i) {\n\t\tint ret;\n\n\t\tdo {\n\t\t\tint cpu = get_current_cpu_id();\n\n\t\t\tret = rseq_offset_deref_addv(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t&args->percpu_list_ptr,\n\t\t\t\tsizeof(struct percpu_list_entry) * cpu, 1, cpu);\n\t\t} while (rseq_unlikely(ret));\n\t}\n\n\tif (rseq_unregister_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_unregister_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\treturn NULL;\n}\n\nvoid test_membarrier_init_percpu_list(struct percpu_list *list)\n{\n\tint i;\n\n\tmemset(list, 0, sizeof(*list));\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tstruct percpu_list_node *node;\n\n\t\tnode = malloc(sizeof(*node));\n\t\tassert(node);\n\t\tnode->data = 0;\n\t\tnode->next = NULL;\n\t\tlist->c[i].head = node;\n\t}\n}\n\nvoid test_membarrier_free_percpu_list(struct percpu_list *list)\n{\n\tint i;\n\n\tfor (i = 0; i < CPU_SETSIZE; i++)\n\t\tfree(list->c[i].head);\n}\n\n \nvoid *test_membarrier_manager_thread(void *arg)\n{\n\tstruct test_membarrier_thread_args *args =\n\t\t(struct test_membarrier_thread_args *)arg;\n\tstruct percpu_list list_a, list_b;\n\tintptr_t expect_a = 0, expect_b = 0;\n\tint cpu_a = 0, cpu_b = 0;\n\n\tif (rseq_register_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_register_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\n\t \n\ttest_membarrier_init_percpu_list(&list_a);\n\ttest_membarrier_init_percpu_list(&list_b);\n\n\tatomic_store(&args->percpu_list_ptr, (intptr_t)&list_a);\n\n\twhile (!atomic_load(&args->stop)) {\n\t\t \n\t\tcpu_a = rand() % CPU_SETSIZE;\n\t\t \n\t\tif (expect_b != atomic_load(&list_b.c[cpu_b].head->data)) {\n\t\t\tfprintf(stderr, \"Membarrier test failed\\n\");\n\t\t\tabort();\n\t\t}\n\n\t\t \n\t\tatomic_store(&args->percpu_list_ptr, (intptr_t)&list_b);\n\t\tif (rseq_membarrier_expedited(cpu_a) &&\n\t\t\t\terrno != ENXIO  ) {\n\t\t\tperror(\"sys_membarrier\");\n\t\t\tabort();\n\t\t}\n\t\t \n\t\texpect_a = atomic_load(&list_a.c[cpu_a].head->data);\n\n\t\tcpu_b = rand() % CPU_SETSIZE;\n\t\t \n\t\tif (expect_a != atomic_load(&list_a.c[cpu_a].head->data)) {\n\t\t\tfprintf(stderr, \"Membarrier test failed\\n\");\n\t\t\tabort();\n\t\t}\n\n\t\t \n\t\tatomic_store(&args->percpu_list_ptr, (intptr_t)&list_a);\n\t\tif (rseq_membarrier_expedited(cpu_b) &&\n\t\t\t\terrno != ENXIO  ) {\n\t\t\tperror(\"sys_membarrier\");\n\t\t\tabort();\n\t\t}\n\t\t \n\t\texpect_b = atomic_load(&list_b.c[cpu_b].head->data);\n\t}\n\n\ttest_membarrier_free_percpu_list(&list_a);\n\ttest_membarrier_free_percpu_list(&list_b);\n\n\tif (rseq_unregister_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_unregister_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\treturn NULL;\n}\n\nvoid test_membarrier(void)\n{\n\tconst int num_threads = opt_threads;\n\tstruct test_membarrier_thread_args thread_args;\n\tpthread_t worker_threads[num_threads];\n\tpthread_t manager_thread;\n\tint i, ret;\n\n\tif (sys_membarrier(MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_RSEQ, 0, 0)) {\n\t\tperror(\"sys_membarrier\");\n\t\tabort();\n\t}\n\n\tthread_args.stop = 0;\n\tthread_args.percpu_list_ptr = 0;\n\tret = pthread_create(&manager_thread, NULL,\n\t\t\ttest_membarrier_manager_thread, &thread_args);\n\tif (ret) {\n\t\terrno = ret;\n\t\tperror(\"pthread_create\");\n\t\tabort();\n\t}\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_create(&worker_threads[i], NULL,\n\t\t\t\ttest_membarrier_worker_thread, &thread_args);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_create\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\n\tfor (i = 0; i < num_threads; i++) {\n\t\tret = pthread_join(worker_threads[i], NULL);\n\t\tif (ret) {\n\t\t\terrno = ret;\n\t\t\tperror(\"pthread_join\");\n\t\t\tabort();\n\t\t}\n\t}\n\n\tatomic_store(&thread_args.stop, 1);\n\tret = pthread_join(manager_thread, NULL);\n\tif (ret) {\n\t\terrno = ret;\n\t\tperror(\"pthread_join\");\n\t\tabort();\n\t}\n}\n#else  \nvoid test_membarrier(void)\n{\n\tfprintf(stderr, \"rseq_offset_deref_addv is not implemented on this architecture. \"\n\t\t\t\"Skipping membarrier test.\\n\");\n}\n#endif\n\nstatic void show_usage(int argc, char **argv)\n{\n\tprintf(\"Usage : %s <OPTIONS>\\n\",\n\t\targv[0]);\n\tprintf(\"OPTIONS:\\n\");\n\tprintf(\"\t[-1 loops] Number of loops for delay injection 1\\n\");\n\tprintf(\"\t[-2 loops] Number of loops for delay injection 2\\n\");\n\tprintf(\"\t[-3 loops] Number of loops for delay injection 3\\n\");\n\tprintf(\"\t[-4 loops] Number of loops for delay injection 4\\n\");\n\tprintf(\"\t[-5 loops] Number of loops for delay injection 5\\n\");\n\tprintf(\"\t[-6 loops] Number of loops for delay injection 6\\n\");\n\tprintf(\"\t[-7 loops] Number of loops for delay injection 7 (-1 to enable -m)\\n\");\n\tprintf(\"\t[-8 loops] Number of loops for delay injection 8 (-1 to enable -m)\\n\");\n\tprintf(\"\t[-9 loops] Number of loops for delay injection 9 (-1 to enable -m)\\n\");\n\tprintf(\"\t[-m N] Yield/sleep/kill every modulo N (default 0: disabled) (>= 0)\\n\");\n\tprintf(\"\t[-y] Yield\\n\");\n\tprintf(\"\t[-k] Kill thread with signal\\n\");\n\tprintf(\"\t[-s S] S: =0: disabled (default), >0: sleep time (ms)\\n\");\n\tprintf(\"\t[-t N] Number of threads (default 200)\\n\");\n\tprintf(\"\t[-r N] Number of repetitions per thread (default 5000)\\n\");\n\tprintf(\"\t[-d] Disable rseq system call (no initialization)\\n\");\n\tprintf(\"\t[-D M] Disable rseq for each M threads\\n\");\n\tprintf(\"\t[-T test] Choose test: (s)pinlock, (l)ist, (b)uffer, (m)emcpy, (i)ncrement, membarrie(r)\\n\");\n\tprintf(\"\t[-M] Push into buffer and memcpy buffer with memory barriers.\\n\");\n\tprintf(\"\t[-v] Verbose output.\\n\");\n\tprintf(\"\t[-h] Show this help.\\n\");\n\tprintf(\"\\n\");\n}\n\nint main(int argc, char **argv)\n{\n\tint i;\n\n\tfor (i = 1; i < argc; i++) {\n\t\tif (argv[i][0] != '-')\n\t\t\tcontinue;\n\t\tswitch (argv[i][1]) {\n\t\tcase '1':\n\t\tcase '2':\n\t\tcase '3':\n\t\tcase '4':\n\t\tcase '5':\n\t\tcase '6':\n\t\tcase '7':\n\t\tcase '8':\n\t\tcase '9':\n\t\t\tif (argc < i + 2) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tloop_cnt[argv[i][1] - '0'] = atol(argv[i + 1]);\n\t\t\ti++;\n\t\t\tbreak;\n\t\tcase 'm':\n\t\t\tif (argc < i + 2) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\topt_modulo = atol(argv[i + 1]);\n\t\t\tif (opt_modulo < 0) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\ti++;\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tif (argc < i + 2) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\topt_sleep = atol(argv[i + 1]);\n\t\t\tif (opt_sleep < 0) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\ti++;\n\t\t\tbreak;\n\t\tcase 'y':\n\t\t\topt_yield = 1;\n\t\t\tbreak;\n\t\tcase 'k':\n\t\t\topt_signal = 1;\n\t\t\tbreak;\n\t\tcase 'd':\n\t\t\topt_disable_rseq = 1;\n\t\t\tbreak;\n\t\tcase 'D':\n\t\t\tif (argc < i + 2) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\topt_disable_mod = atol(argv[i + 1]);\n\t\t\tif (opt_disable_mod < 0) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\ti++;\n\t\t\tbreak;\n\t\tcase 't':\n\t\t\tif (argc < i + 2) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\topt_threads = atol(argv[i + 1]);\n\t\t\tif (opt_threads < 0) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\ti++;\n\t\t\tbreak;\n\t\tcase 'r':\n\t\t\tif (argc < i + 2) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\topt_reps = atoll(argv[i + 1]);\n\t\t\tif (opt_reps < 0) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\ti++;\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tshow_usage(argc, argv);\n\t\t\tgoto end;\n\t\tcase 'T':\n\t\t\tif (argc < i + 2) {\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\topt_test = *argv[i + 1];\n\t\t\tswitch (opt_test) {\n\t\t\tcase 's':\n\t\t\tcase 'l':\n\t\t\tcase 'i':\n\t\t\tcase 'b':\n\t\t\tcase 'm':\n\t\t\tcase 'r':\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tshow_usage(argc, argv);\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\ti++;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\tverbose = 1;\n\t\t\tbreak;\n\t\tcase 'M':\n\t\t\topt_mo = RSEQ_MO_RELEASE;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tshow_usage(argc, argv);\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\tloop_cnt_1 = loop_cnt[1];\n\tloop_cnt_2 = loop_cnt[2];\n\tloop_cnt_3 = loop_cnt[3];\n\tloop_cnt_4 = loop_cnt[4];\n\tloop_cnt_5 = loop_cnt[5];\n\tloop_cnt_6 = loop_cnt[6];\n\n\tif (set_signal_handler())\n\t\tgoto error;\n\n\tif (!opt_disable_rseq && rseq_register_current_thread())\n\t\tgoto error;\n\tif (!opt_disable_rseq && !rseq_validate_cpu_id()) {\n\t\tfprintf(stderr, \"Error: cpu id getter unavailable\\n\");\n\t\tgoto error;\n\t}\n\tswitch (opt_test) {\n\tcase 's':\n\t\tprintf_verbose(\"spinlock\\n\");\n\t\ttest_percpu_spinlock();\n\t\tbreak;\n\tcase 'l':\n\t\tprintf_verbose(\"linked list\\n\");\n\t\ttest_percpu_list();\n\t\tbreak;\n\tcase 'b':\n\t\tprintf_verbose(\"buffer\\n\");\n\t\ttest_percpu_buffer();\n\t\tbreak;\n\tcase 'm':\n\t\tprintf_verbose(\"memcpy buffer\\n\");\n\t\ttest_percpu_memcpy_buffer();\n\t\tbreak;\n\tcase 'i':\n\t\tprintf_verbose(\"counter increment\\n\");\n\t\ttest_percpu_inc();\n\t\tbreak;\n\tcase 'r':\n\t\tprintf_verbose(\"membarrier\\n\");\n\t\ttest_membarrier();\n\t\tbreak;\n\t}\n\tif (!opt_disable_rseq && rseq_unregister_current_thread())\n\t\tabort();\nend:\n\treturn 0;\n\nerror:\n\treturn -1;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}