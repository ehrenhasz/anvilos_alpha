{
  "module_name": "rseq.h",
  "hash_id": "20a14dd9a7e8d593632d943ed595fbf086de0ae999abd542047e6b8db534237d",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/rseq/rseq.h",
  "human_readable_source": " \n \n\n#ifndef RSEQ_H\n#define RSEQ_H\n\n#include <stdint.h>\n#include <stdbool.h>\n#include <pthread.h>\n#include <signal.h>\n#include <sched.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <stddef.h>\n#include \"rseq-abi.h\"\n#include \"compiler.h\"\n\n#ifndef rseq_sizeof_field\n#define rseq_sizeof_field(TYPE, MEMBER) sizeof((((TYPE *)0)->MEMBER))\n#endif\n\n#ifndef rseq_offsetofend\n#define rseq_offsetofend(TYPE, MEMBER) \\\n\t(offsetof(TYPE, MEMBER)\t+ rseq_sizeof_field(TYPE, MEMBER))\n#endif\n\n \n#ifndef RSEQ_INJECT_ASM\n#define RSEQ_INJECT_ASM(n)\n#endif\n\n#ifndef RSEQ_INJECT_C\n#define RSEQ_INJECT_C(n)\n#endif\n\n#ifndef RSEQ_INJECT_INPUT\n#define RSEQ_INJECT_INPUT\n#endif\n\n#ifndef RSEQ_INJECT_CLOBBER\n#define RSEQ_INJECT_CLOBBER\n#endif\n\n#ifndef RSEQ_INJECT_FAILED\n#define RSEQ_INJECT_FAILED\n#endif\n\n#include \"rseq-thread-pointer.h\"\n\n \nextern ptrdiff_t rseq_offset;\n\n \nextern unsigned int rseq_size;\n\n \nextern unsigned int rseq_flags;\n\n \nextern unsigned int rseq_feature_size;\n\nenum rseq_mo {\n\tRSEQ_MO_RELAXED = 0,\n\tRSEQ_MO_CONSUME = 1,\t \n\tRSEQ_MO_ACQUIRE = 2,\t \n\tRSEQ_MO_RELEASE = 3,\n\tRSEQ_MO_ACQ_REL = 4,\t \n\tRSEQ_MO_SEQ_CST = 5,\t \n};\n\nenum rseq_percpu_mode {\n\tRSEQ_PERCPU_CPU_ID = 0,\n\tRSEQ_PERCPU_MM_CID = 1,\n};\n\nstatic inline struct rseq_abi *rseq_get_abi(void)\n{\n\treturn (struct rseq_abi *) ((uintptr_t) rseq_thread_pointer() + rseq_offset);\n}\n\n#define rseq_likely(x)\t\t__builtin_expect(!!(x), 1)\n#define rseq_unlikely(x)\t__builtin_expect(!!(x), 0)\n#define rseq_barrier()\t\t__asm__ __volatile__(\"\" : : : \"memory\")\n\n#define RSEQ_ACCESS_ONCE(x)\t(*(__volatile__  __typeof__(x) *)&(x))\n#define RSEQ_WRITE_ONCE(x, v)\t__extension__ ({ RSEQ_ACCESS_ONCE(x) = (v); })\n#define RSEQ_READ_ONCE(x)\tRSEQ_ACCESS_ONCE(x)\n\n#define __rseq_str_1(x)\t#x\n#define __rseq_str(x)\t\t__rseq_str_1(x)\n\n#define rseq_log(fmt, args...)\t\t\t\t\t\t       \\\n\tfprintf(stderr, fmt \"(in %s() at \" __FILE__ \":\" __rseq_str(__LINE__)\"\\n\", \\\n\t\t## args, __func__)\n\n#define rseq_bug(fmt, args...)\t\t\\\n\tdo {\t\t\t\t\\\n\t\trseq_log(fmt, ##args);\t\\\n\t\tabort();\t\t\\\n\t} while (0)\n\n#if defined(__x86_64__) || defined(__i386__)\n#include <rseq-x86.h>\n#elif defined(__ARMEL__)\n#include <rseq-arm.h>\n#elif defined (__AARCH64EL__)\n#include <rseq-arm64.h>\n#elif defined(__PPC__)\n#include <rseq-ppc.h>\n#elif defined(__mips__)\n#include <rseq-mips.h>\n#elif defined(__s390__)\n#include <rseq-s390.h>\n#elif defined(__riscv)\n#include <rseq-riscv.h>\n#else\n#error unsupported target\n#endif\n\n \nint rseq_register_current_thread(void);\n\n \nint rseq_unregister_current_thread(void);\n\n \nint32_t rseq_fallback_current_cpu(void);\n\n \nint32_t rseq_fallback_current_node(void);\n\n \nstatic inline int32_t rseq_current_cpu_raw(void)\n{\n\treturn RSEQ_ACCESS_ONCE(rseq_get_abi()->cpu_id);\n}\n\n \nstatic inline uint32_t rseq_cpu_start(void)\n{\n\treturn RSEQ_ACCESS_ONCE(rseq_get_abi()->cpu_id_start);\n}\n\nstatic inline uint32_t rseq_current_cpu(void)\n{\n\tint32_t cpu;\n\n\tcpu = rseq_current_cpu_raw();\n\tif (rseq_unlikely(cpu < 0))\n\t\tcpu = rseq_fallback_current_cpu();\n\treturn cpu;\n}\n\nstatic inline bool rseq_node_id_available(void)\n{\n\treturn (int) rseq_feature_size >= rseq_offsetofend(struct rseq_abi, node_id);\n}\n\n \nstatic inline uint32_t rseq_current_node_id(void)\n{\n\tassert(rseq_node_id_available());\n\treturn RSEQ_ACCESS_ONCE(rseq_get_abi()->node_id);\n}\n\nstatic inline bool rseq_mm_cid_available(void)\n{\n\treturn (int) rseq_feature_size >= rseq_offsetofend(struct rseq_abi, mm_cid);\n}\n\nstatic inline uint32_t rseq_current_mm_cid(void)\n{\n\treturn RSEQ_ACCESS_ONCE(rseq_get_abi()->mm_cid);\n}\n\nstatic inline void rseq_clear_rseq_cs(void)\n{\n\tRSEQ_WRITE_ONCE(rseq_get_abi()->rseq_cs.arch.ptr, 0);\n}\n\n \nstatic inline void rseq_prepare_unload(void)\n{\n\trseq_clear_rseq_cs();\n}\n\nstatic inline __attribute__((always_inline))\nint rseq_cmpeqv_storev(enum rseq_mo rseq_mo, enum rseq_percpu_mode percpu_mode,\n\t\t       intptr_t *v, intptr_t expect,\n\t\t       intptr_t newv, int cpu)\n{\n\tif (rseq_mo != RSEQ_MO_RELAXED)\n\t\treturn -1;\n\tswitch (percpu_mode) {\n\tcase RSEQ_PERCPU_CPU_ID:\n\t\treturn rseq_cmpeqv_storev_relaxed_cpu_id(v, expect, newv, cpu);\n\tcase RSEQ_PERCPU_MM_CID:\n\t\treturn rseq_cmpeqv_storev_relaxed_mm_cid(v, expect, newv, cpu);\n\t}\n\treturn -1;\n}\n\n \nstatic inline __attribute__((always_inline))\nint rseq_cmpnev_storeoffp_load(enum rseq_mo rseq_mo, enum rseq_percpu_mode percpu_mode,\n\t\t\t       intptr_t *v, intptr_t expectnot, long voffp, intptr_t *load,\n\t\t\t       int cpu)\n{\n\tif (rseq_mo != RSEQ_MO_RELAXED)\n\t\treturn -1;\n\tswitch (percpu_mode) {\n\tcase RSEQ_PERCPU_CPU_ID:\n\t\treturn rseq_cmpnev_storeoffp_load_relaxed_cpu_id(v, expectnot, voffp, load, cpu);\n\tcase RSEQ_PERCPU_MM_CID:\n\t\treturn rseq_cmpnev_storeoffp_load_relaxed_mm_cid(v, expectnot, voffp, load, cpu);\n\t}\n\treturn -1;\n}\n\nstatic inline __attribute__((always_inline))\nint rseq_addv(enum rseq_mo rseq_mo, enum rseq_percpu_mode percpu_mode,\n\t      intptr_t *v, intptr_t count, int cpu)\n{\n\tif (rseq_mo != RSEQ_MO_RELAXED)\n\t\treturn -1;\n\tswitch (percpu_mode) {\n\tcase RSEQ_PERCPU_CPU_ID:\n\t\treturn rseq_addv_relaxed_cpu_id(v, count, cpu);\n\tcase RSEQ_PERCPU_MM_CID:\n\t\treturn rseq_addv_relaxed_mm_cid(v, count, cpu);\n\t}\n\treturn -1;\n}\n\n#ifdef RSEQ_ARCH_HAS_OFFSET_DEREF_ADDV\n \nstatic inline __attribute__((always_inline))\nint rseq_offset_deref_addv(enum rseq_mo rseq_mo, enum rseq_percpu_mode percpu_mode,\n\t\t\t   intptr_t *ptr, long off, intptr_t inc, int cpu)\n{\n\tif (rseq_mo != RSEQ_MO_RELAXED)\n\t\treturn -1;\n\tswitch (percpu_mode) {\n\tcase RSEQ_PERCPU_CPU_ID:\n\t\treturn rseq_offset_deref_addv_relaxed_cpu_id(ptr, off, inc, cpu);\n\tcase RSEQ_PERCPU_MM_CID:\n\t\treturn rseq_offset_deref_addv_relaxed_mm_cid(ptr, off, inc, cpu);\n\t}\n\treturn -1;\n}\n#endif\n\nstatic inline __attribute__((always_inline))\nint rseq_cmpeqv_trystorev_storev(enum rseq_mo rseq_mo, enum rseq_percpu_mode percpu_mode,\n\t\t\t\t intptr_t *v, intptr_t expect,\n\t\t\t\t intptr_t *v2, intptr_t newv2,\n\t\t\t\t intptr_t newv, int cpu)\n{\n\tswitch (rseq_mo) {\n\tcase RSEQ_MO_RELAXED:\n\t\tswitch (percpu_mode) {\n\t\tcase RSEQ_PERCPU_CPU_ID:\n\t\t\treturn rseq_cmpeqv_trystorev_storev_relaxed_cpu_id(v, expect, v2, newv2, newv, cpu);\n\t\tcase RSEQ_PERCPU_MM_CID:\n\t\t\treturn rseq_cmpeqv_trystorev_storev_relaxed_mm_cid(v, expect, v2, newv2, newv, cpu);\n\t\t}\n\t\treturn -1;\n\tcase RSEQ_MO_RELEASE:\n\t\tswitch (percpu_mode) {\n\t\tcase RSEQ_PERCPU_CPU_ID:\n\t\t\treturn rseq_cmpeqv_trystorev_storev_release_cpu_id(v, expect, v2, newv2, newv, cpu);\n\t\tcase RSEQ_PERCPU_MM_CID:\n\t\t\treturn rseq_cmpeqv_trystorev_storev_release_mm_cid(v, expect, v2, newv2, newv, cpu);\n\t\t}\n\t\treturn -1;\n\tdefault:\n\t\treturn -1;\n\t}\n}\n\nstatic inline __attribute__((always_inline))\nint rseq_cmpeqv_cmpeqv_storev(enum rseq_mo rseq_mo, enum rseq_percpu_mode percpu_mode,\n\t\t\t      intptr_t *v, intptr_t expect,\n\t\t\t      intptr_t *v2, intptr_t expect2,\n\t\t\t      intptr_t newv, int cpu)\n{\n\tif (rseq_mo != RSEQ_MO_RELAXED)\n\t\treturn -1;\n\tswitch (percpu_mode) {\n\tcase RSEQ_PERCPU_CPU_ID:\n\t\treturn rseq_cmpeqv_cmpeqv_storev_relaxed_cpu_id(v, expect, v2, expect2, newv, cpu);\n\tcase RSEQ_PERCPU_MM_CID:\n\t\treturn rseq_cmpeqv_cmpeqv_storev_relaxed_mm_cid(v, expect, v2, expect2, newv, cpu);\n\t}\n\treturn -1;\n}\n\nstatic inline __attribute__((always_inline))\nint rseq_cmpeqv_trymemcpy_storev(enum rseq_mo rseq_mo, enum rseq_percpu_mode percpu_mode,\n\t\t\t\t intptr_t *v, intptr_t expect,\n\t\t\t\t void *dst, void *src, size_t len,\n\t\t\t\t intptr_t newv, int cpu)\n{\n\tswitch (rseq_mo) {\n\tcase RSEQ_MO_RELAXED:\n\t\tswitch (percpu_mode) {\n\t\tcase RSEQ_PERCPU_CPU_ID:\n\t\t\treturn rseq_cmpeqv_trymemcpy_storev_relaxed_cpu_id(v, expect, dst, src, len, newv, cpu);\n\t\tcase RSEQ_PERCPU_MM_CID:\n\t\t\treturn rseq_cmpeqv_trymemcpy_storev_relaxed_mm_cid(v, expect, dst, src, len, newv, cpu);\n\t\t}\n\t\treturn -1;\n\tcase RSEQ_MO_RELEASE:\n\t\tswitch (percpu_mode) {\n\t\tcase RSEQ_PERCPU_CPU_ID:\n\t\t\treturn rseq_cmpeqv_trymemcpy_storev_release_cpu_id(v, expect, dst, src, len, newv, cpu);\n\t\tcase RSEQ_PERCPU_MM_CID:\n\t\t\treturn rseq_cmpeqv_trymemcpy_storev_release_mm_cid(v, expect, dst, src, len, newv, cpu);\n\t\t}\n\t\treturn -1;\n\tdefault:\n\t\treturn -1;\n\t}\n}\n\n#endif   \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}