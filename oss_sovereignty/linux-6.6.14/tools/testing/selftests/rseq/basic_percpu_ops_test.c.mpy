{
  "module_name": "basic_percpu_ops_test.c",
  "hash_id": "dae6d085f1d2b011d1398a314240d683dc9b24891bc6a6d71aa1c3eb0825e4d7",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/rseq/basic_percpu_ops_test.c",
  "human_readable_source": "\n#define _GNU_SOURCE\n#include <assert.h>\n#include <pthread.h>\n#include <sched.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stddef.h>\n\n#include \"../kselftest.h\"\n#include \"rseq.h\"\n\n#ifdef BUILDOPT_RSEQ_PERCPU_MM_CID\n# define RSEQ_PERCPU\tRSEQ_PERCPU_MM_CID\nstatic\nint get_current_cpu_id(void)\n{\n\treturn rseq_current_mm_cid();\n}\nstatic\nbool rseq_validate_cpu_id(void)\n{\n\treturn rseq_mm_cid_available();\n}\n#else\n# define RSEQ_PERCPU\tRSEQ_PERCPU_CPU_ID\nstatic\nint get_current_cpu_id(void)\n{\n\treturn rseq_cpu_start();\n}\nstatic\nbool rseq_validate_cpu_id(void)\n{\n\treturn rseq_current_cpu_raw() >= 0;\n}\n#endif\n\nstruct percpu_lock_entry {\n\tintptr_t v;\n} __attribute__((aligned(128)));\n\nstruct percpu_lock {\n\tstruct percpu_lock_entry c[CPU_SETSIZE];\n};\n\nstruct test_data_entry {\n\tintptr_t count;\n} __attribute__((aligned(128)));\n\nstruct spinlock_test_data {\n\tstruct percpu_lock lock;\n\tstruct test_data_entry c[CPU_SETSIZE];\n\tint reps;\n};\n\nstruct percpu_list_node {\n\tintptr_t data;\n\tstruct percpu_list_node *next;\n};\n\nstruct percpu_list_entry {\n\tstruct percpu_list_node *head;\n} __attribute__((aligned(128)));\n\nstruct percpu_list {\n\tstruct percpu_list_entry c[CPU_SETSIZE];\n};\n\n \nint rseq_this_cpu_lock(struct percpu_lock *lock)\n{\n\tint cpu;\n\n\tfor (;;) {\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\tret = rseq_cmpeqv_storev(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t\t &lock->c[cpu].v, 0, 1, cpu);\n\t\tif (rseq_likely(!ret))\n\t\t\tbreak;\n\t\t \n\t}\n\t \n\trseq_smp_acquire__after_ctrl_dep();\n\treturn cpu;\n}\n\nvoid rseq_percpu_unlock(struct percpu_lock *lock, int cpu)\n{\n\tassert(lock->c[cpu].v == 1);\n\t \n\trseq_smp_store_release(&lock->c[cpu].v, 0);\n}\n\nvoid *test_percpu_spinlock_thread(void *arg)\n{\n\tstruct spinlock_test_data *data = arg;\n\tint i, cpu;\n\n\tif (rseq_register_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_register_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\tfor (i = 0; i < data->reps; i++) {\n\t\tcpu = rseq_this_cpu_lock(&data->lock);\n\t\tdata->c[cpu].count++;\n\t\trseq_percpu_unlock(&data->lock, cpu);\n\t}\n\tif (rseq_unregister_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_unregister_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\n\treturn NULL;\n}\n\n \nvoid test_percpu_spinlock(void)\n{\n\tconst int num_threads = 200;\n\tint i;\n\tuint64_t sum;\n\tpthread_t test_threads[num_threads];\n\tstruct spinlock_test_data data;\n\n\tmemset(&data, 0, sizeof(data));\n\tdata.reps = 5000;\n\n\tfor (i = 0; i < num_threads; i++)\n\t\tpthread_create(&test_threads[i], NULL,\n\t\t\t       test_percpu_spinlock_thread, &data);\n\n\tfor (i = 0; i < num_threads; i++)\n\t\tpthread_join(test_threads[i], NULL);\n\n\tsum = 0;\n\tfor (i = 0; i < CPU_SETSIZE; i++)\n\t\tsum += data.c[i].count;\n\n\tassert(sum == (uint64_t)data.reps * num_threads);\n}\n\nvoid this_cpu_list_push(struct percpu_list *list,\n\t\t\tstruct percpu_list_node *node,\n\t\t\tint *_cpu)\n{\n\tint cpu;\n\n\tfor (;;) {\n\t\tintptr_t *targetptr, newval, expect;\n\t\tint ret;\n\n\t\tcpu = get_current_cpu_id();\n\t\t \n\t\texpect = (intptr_t)RSEQ_READ_ONCE(list->c[cpu].head);\n\t\tnewval = (intptr_t)node;\n\t\ttargetptr = (intptr_t *)&list->c[cpu].head;\n\t\tnode->next = (struct percpu_list_node *)expect;\n\t\tret = rseq_cmpeqv_storev(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t\t targetptr, expect, newval, cpu);\n\t\tif (rseq_likely(!ret))\n\t\t\tbreak;\n\t\t \n\t}\n\tif (_cpu)\n\t\t*_cpu = cpu;\n}\n\n \nstruct percpu_list_node *this_cpu_list_pop(struct percpu_list *list,\n\t\t\t\t\t   int *_cpu)\n{\n\tfor (;;) {\n\t\tstruct percpu_list_node *head;\n\t\tintptr_t *targetptr, expectnot, *load;\n\t\tlong offset;\n\t\tint ret, cpu;\n\n\t\tcpu = get_current_cpu_id();\n\t\ttargetptr = (intptr_t *)&list->c[cpu].head;\n\t\texpectnot = (intptr_t)NULL;\n\t\toffset = offsetof(struct percpu_list_node, next);\n\t\tload = (intptr_t *)&head;\n\t\tret = rseq_cmpnev_storeoffp_load(RSEQ_MO_RELAXED, RSEQ_PERCPU,\n\t\t\t\t\t\t targetptr, expectnot,\n\t\t\t\t\t\t offset, load, cpu);\n\t\tif (rseq_likely(!ret)) {\n\t\t\tif (_cpu)\n\t\t\t\t*_cpu = cpu;\n\t\t\treturn head;\n\t\t}\n\t\tif (ret > 0)\n\t\t\treturn NULL;\n\t\t \n\t}\n}\n\n \nstruct percpu_list_node *__percpu_list_pop(struct percpu_list *list, int cpu)\n{\n\tstruct percpu_list_node *node;\n\n\tnode = list->c[cpu].head;\n\tif (!node)\n\t\treturn NULL;\n\tlist->c[cpu].head = node->next;\n\treturn node;\n}\n\nvoid *test_percpu_list_thread(void *arg)\n{\n\tint i;\n\tstruct percpu_list *list = (struct percpu_list *)arg;\n\n\tif (rseq_register_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_register_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\n\tfor (i = 0; i < 100000; i++) {\n\t\tstruct percpu_list_node *node;\n\n\t\tnode = this_cpu_list_pop(list, NULL);\n\t\tsched_yield();   \n\t\tif (node)\n\t\t\tthis_cpu_list_push(list, node, NULL);\n\t}\n\n\tif (rseq_unregister_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_unregister_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tabort();\n\t}\n\n\treturn NULL;\n}\n\n \nvoid test_percpu_list(void)\n{\n\tint i, j;\n\tuint64_t sum = 0, expected_sum = 0;\n\tstruct percpu_list list;\n\tpthread_t test_threads[200];\n\tcpu_set_t allowed_cpus;\n\n\tmemset(&list, 0, sizeof(list));\n\n\t \n\tsched_getaffinity(0, sizeof(allowed_cpus), &allowed_cpus);\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\t\tfor (j = 1; j <= 100; j++) {\n\t\t\tstruct percpu_list_node *node;\n\n\t\t\texpected_sum += j;\n\n\t\t\tnode = malloc(sizeof(*node));\n\t\t\tassert(node);\n\t\t\tnode->data = j;\n\t\t\tnode->next = list.c[i].head;\n\t\t\tlist.c[i].head = node;\n\t\t}\n\t}\n\n\tfor (i = 0; i < 200; i++)\n\t\tpthread_create(&test_threads[i], NULL,\n\t\t       test_percpu_list_thread, &list);\n\n\tfor (i = 0; i < 200; i++)\n\t\tpthread_join(test_threads[i], NULL);\n\n\tfor (i = 0; i < CPU_SETSIZE; i++) {\n\t\tstruct percpu_list_node *node;\n\n\t\tif (!CPU_ISSET(i, &allowed_cpus))\n\t\t\tcontinue;\n\n\t\twhile ((node = __percpu_list_pop(&list, i))) {\n\t\t\tsum += node->data;\n\t\t\tfree(node);\n\t\t}\n\t}\n\n\t \n\tassert(sum == expected_sum);\n}\n\nint main(int argc, char **argv)\n{\n\tif (rseq_register_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_register_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tgoto error;\n\t}\n\tif (!rseq_validate_cpu_id()) {\n\t\tfprintf(stderr, \"Error: cpu id getter unavailable\\n\");\n\t\tgoto error;\n\t}\n\tprintf(\"spinlock\\n\");\n\ttest_percpu_spinlock();\n\tprintf(\"percpu_list\\n\");\n\ttest_percpu_list();\n\tif (rseq_unregister_current_thread()) {\n\t\tfprintf(stderr, \"Error: rseq_unregister_current_thread(...) failed(%d): %s\\n\",\n\t\t\terrno, strerror(errno));\n\t\tgoto error;\n\t}\n\treturn 0;\n\nerror:\n\treturn -1;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}