{
  "module_name": "run_vmtests.sh",
  "hash_id": "f4167855a7efef8a511da20c9b859956c532a4502440e1f5a79fd88b46fa3d3b",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/mm/run_vmtests.sh",
  "human_readable_source": "#!/bin/bash\n# SPDX-License-Identifier: GPL-2.0\n# Please run as root\n\n# Kselftest framework requirement - SKIP code is 4.\nksft_skip=4\n\ncount_pass=0\ncount_fail=0\ncount_skip=0\nexitcode=0\n\nusage() {\n\tcat <<EOF\nusage: ${BASH_SOURCE[0]:-$0} [ options ]\n\n  -a: run all tests, including extra ones\n  -t: specify specific categories to tests to run\n  -h: display this message\n\nThe default behavior is to run required tests only.  If -a is specified,\nwill run all tests.\n\nAlternatively, specific groups tests can be run by passing a string\nto the -t argument containing one or more of the following categories\nseparated by spaces:\n- mmap\n\ttests for mmap(2)\n- gup_test\n\ttests for gup\n- userfaultfd\n\ttests for  userfaultfd(2)\n- compaction\n\ta test for the patch \"Allow compaction of unevictable pages\"\n- mlock\n\ttests for mlock(2)\n- mremap\n\ttests for mremap(2)\n- hugevm\n\ttests for very large virtual address space\n- vmalloc\n\tvmalloc smoke tests\n- hmm\n\thmm smoke tests\n- madv_populate\n\ttest memadvise(2) MADV_POPULATE_{READ,WRITE} options\n- memfd_secret\n\ttest memfd_secret(2)\n- process_mrelease\n\ttest process_mrelease(2)\n- ksm\n\tksm tests that do not require >=2 NUMA nodes\n- ksm_numa\n\tksm tests that require >=2 NUMA nodes\n- pkey\n\tmemory protection key tests\n- soft_dirty\n\ttest soft dirty page bit semantics\n- cow\n\ttest copy-on-write semantics\n- thp\n\ttest transparent huge pages\n- migration\n\tinvoke move_pages(2) to exercise the migration entry code\n\tpaths in the kernel\n- mkdirty\n\ttest handling of code that might set PTE/PMD dirty in\n\tread-only VMAs\n- mdwe\n\ttest prctl(PR_SET_MDWE, ...)\n\nexample: ./run_vmtests.sh -t \"hmm mmap ksm\"\nEOF\n\texit 0\n}\n\nRUN_ALL=false\n\nwhile getopts \"aht:\" OPT; do\n\tcase ${OPT} in\n\t\t\"a\") RUN_ALL=true ;;\n\t\t\"h\") usage ;;\n\t\t\"t\") VM_SELFTEST_ITEMS=${OPTARG} ;;\n\tesac\ndone\nshift $((OPTIND -1))\n\n# default behavior: run all tests\nVM_SELFTEST_ITEMS=${VM_SELFTEST_ITEMS:-default}\n\ntest_selected() {\n\tif [ \"$VM_SELFTEST_ITEMS\" == \"default\" ]; then\n\t\t# If no VM_SELFTEST_ITEMS are specified, run all tests\n\t\treturn 0\n\tfi\n\t# If test selected argument is one of the test items\n\tif [[ \" ${VM_SELFTEST_ITEMS[*]} \" =~ \" ${1} \" ]]; then\n\t        return 0\n\telse\n\t        return 1\n\tfi\n}\n\nrun_gup_matrix() {\n    # -t: thp=on, -T: thp=off, -H: hugetlb=on\n    local hugetlb_mb=$(( needmem_KB / 1024 ))\n\n    for huge in -t -T \"-H -m $hugetlb_mb\"; do\n        # -u: gup-fast, -U: gup-basic, -a: pin-fast, -b: pin-basic, -L: pin-longterm\n        for test_cmd in -u -U -a -b -L; do\n            # -w: write=1, -W: write=0\n            for write in -w -W; do\n                # -S: shared\n                for share in -S \" \"; do\n                    # -n: How many pages to fetch together?  512 is special\n                    # because it's default thp size (or 2M on x86), 123 to\n                    # just test partial gup when hit a huge in whatever form\n                    for num in \"-n 1\" \"-n 512\" \"-n 123\"; do\n                        CATEGORY=\"gup_test\" run_test ./gup_test \\\n                                $huge $test_cmd $write $share $num\n                    done\n                done\n            done\n        done\n    done\n}\n\n# get huge pagesize and freepages from /proc/meminfo\nwhile read -r name size unit; do\n\tif [ \"$name\" = \"HugePages_Free:\" ]; then\n\t\tfreepgs=\"$size\"\n\tfi\n\tif [ \"$name\" = \"Hugepagesize:\" ]; then\n\t\thpgsize_KB=\"$size\"\n\tfi\ndone < /proc/meminfo\n\n# Simple hugetlbfs tests have a hardcoded minimum requirement of\n# huge pages totaling 256MB (262144KB) in size.  The userfaultfd\n# hugetlb test requires a minimum of 2 * nr_cpus huge pages.  Take\n# both of these requirements into account and attempt to increase\n# number of huge pages available.\nnr_cpus=$(nproc)\nhpgsize_MB=$((hpgsize_KB / 1024))\nhalf_ufd_size_MB=$((((nr_cpus * hpgsize_MB + 127) / 128) * 128))\nneedmem_KB=$((half_ufd_size_MB * 2 * 1024))\n\n# set proper nr_hugepages\nif [ -n \"$freepgs\" ] && [ -n \"$hpgsize_KB\" ]; then\n\tnr_hugepgs=$(cat /proc/sys/vm/nr_hugepages)\n\tneedpgs=$((needmem_KB / hpgsize_KB))\n\ttries=2\n\twhile [ \"$tries\" -gt 0 ] && [ \"$freepgs\" -lt \"$needpgs\" ]; do\n\t\tlackpgs=$((needpgs - freepgs))\n\t\techo 3 > /proc/sys/vm/drop_caches\n\t\tif ! echo $((lackpgs + nr_hugepgs)) > /proc/sys/vm/nr_hugepages; then\n\t\t\techo \"Please run this test as root\"\n\t\t\texit $ksft_skip\n\t\tfi\n\t\twhile read -r name size unit; do\n\t\t\tif [ \"$name\" = \"HugePages_Free:\" ]; then\n\t\t\t\tfreepgs=$size\n\t\t\tfi\n\t\tdone < /proc/meminfo\n\t\ttries=$((tries - 1))\n\tdone\n\tif [ \"$freepgs\" -lt \"$needpgs\" ]; then\n\t\tprintf \"Not enough huge pages available (%d < %d)\\n\" \\\n\t\t       \"$freepgs\" \"$needpgs\"\n\t\texit 1\n\tfi\nelse\n\techo \"no hugetlbfs support in kernel?\"\n\texit 1\nfi\n\n# filter 64bit architectures\nARCH64STR=\"arm64 ia64 mips64 parisc64 ppc64 ppc64le riscv64 s390x sparc64 x86_64\"\nif [ -z \"$ARCH\" ]; then\n\tARCH=$(uname -m 2>/dev/null | sed -e 's/aarch64.*/arm64/')\nfi\nVADDR64=0\necho \"$ARCH64STR\" | grep \"$ARCH\" &>/dev/null && VADDR64=1\n\n# Usage: run_test [test binary] [arbitrary test arguments...]\nrun_test() {\n\tif test_selected ${CATEGORY}; then\n\t\tlocal title=\"running $*\"\n\t\tlocal sep=$(echo -n \"$title\" | tr \"[:graph:][:space:]\" -)\n\t\tprintf \"%s\\n%s\\n%s\\n\" \"$sep\" \"$title\" \"$sep\"\n\n\t\t\"$@\"\n\t\tlocal ret=$?\n\t\tif [ $ret -eq 0 ]; then\n\t\t\tcount_pass=$(( count_pass + 1 ))\n\t\t\techo \"[PASS]\"\n\t\telif [ $ret -eq $ksft_skip ]; then\n\t\t\tcount_skip=$(( count_skip + 1 ))\n\t\t\techo \"[SKIP]\"\n\t\t\texitcode=$ksft_skip\n\t\telse\n\t\t\tcount_fail=$(( count_fail + 1 ))\n\t\t\techo \"[FAIL]\"\n\t\t\texitcode=1\n\t\tfi\n\tfi # test_selected\n}\n\nCATEGORY=\"hugetlb\" run_test ./hugepage-mmap\n\nshmmax=$(cat /proc/sys/kernel/shmmax)\nshmall=$(cat /proc/sys/kernel/shmall)\necho 268435456 > /proc/sys/kernel/shmmax\necho 4194304 > /proc/sys/kernel/shmall\nCATEGORY=\"hugetlb\" run_test ./hugepage-shm\necho \"$shmmax\" > /proc/sys/kernel/shmmax\necho \"$shmall\" > /proc/sys/kernel/shmall\n\nCATEGORY=\"hugetlb\" run_test ./map_hugetlb\nCATEGORY=\"hugetlb\" run_test ./hugepage-mremap\nCATEGORY=\"hugetlb\" run_test ./hugepage-vmemmap\nCATEGORY=\"hugetlb\" run_test ./hugetlb-madvise\n\nif test_selected \"hugetlb\"; then\n\techo \"NOTE: These hugetlb tests provide minimal coverage.  Use\"\n\techo \"      https://github.com/libhugetlbfs/libhugetlbfs.git for\"\n\techo \"      hugetlb regression testing.\"\nfi\n\nCATEGORY=\"mmap\" run_test ./map_fixed_noreplace\n\nif $RUN_ALL; then\n    run_gup_matrix\nelse\n    # get_user_pages_fast() benchmark\n    CATEGORY=\"gup_test\" run_test ./gup_test -u\n    # pin_user_pages_fast() benchmark\n    CATEGORY=\"gup_test\" run_test ./gup_test -a\nfi\n# Dump pages 0, 19, and 4096, using pin_user_pages:\nCATEGORY=\"gup_test\" run_test ./gup_test -ct -F 0x1 0 19 0x1000\nCATEGORY=\"gup_test\" run_test ./gup_longterm\n\nCATEGORY=\"userfaultfd\" run_test ./uffd-unit-tests\nuffd_stress_bin=./uffd-stress\nCATEGORY=\"userfaultfd\" run_test ${uffd_stress_bin} anon 20 16\n# Hugetlb tests require source and destination huge pages. Pass in half\n# the size ($half_ufd_size_MB), which is used for *each*.\nCATEGORY=\"userfaultfd\" run_test ${uffd_stress_bin} hugetlb \"$half_ufd_size_MB\" 32\nCATEGORY=\"userfaultfd\" run_test ${uffd_stress_bin} hugetlb-private \"$half_ufd_size_MB\" 32\nCATEGORY=\"userfaultfd\" run_test ${uffd_stress_bin} shmem 20 16\nCATEGORY=\"userfaultfd\" run_test ${uffd_stress_bin} shmem-private 20 16\n\n#cleanup\necho \"$nr_hugepgs\" > /proc/sys/vm/nr_hugepages\n\nCATEGORY=\"compaction\" run_test ./compaction_test\n\nCATEGORY=\"mlock\" run_test sudo -u nobody ./on-fault-limit\n\nCATEGORY=\"mmap\" run_test ./map_populate\n\nCATEGORY=\"mlock\" run_test ./mlock-random-test\n\nCATEGORY=\"mlock\" run_test ./mlock2-tests\n\nCATEGORY=\"process_mrelease\" run_test ./mrelease_test\n\nCATEGORY=\"mremap\" run_test ./mremap_test\n\nCATEGORY=\"hugetlb\" run_test ./thuge-gen\n\nif [ $VADDR64 -ne 0 ]; then\n\n\t# set overcommit_policy as OVERCOMMIT_ALWAYS so that kernel\n\t# allows high virtual address allocation requests independent\n\t# of platform's physical memory.\n\n\tprev_policy=$(cat /proc/sys/vm/overcommit_memory)\n\techo 1 > /proc/sys/vm/overcommit_memory\n\tCATEGORY=\"hugevm\" run_test ./virtual_address_range\n\techo $prev_policy > /proc/sys/vm/overcommit_memory\n\n\t# va high address boundary switch test\n\tARCH_ARM64=\"arm64\"\n\tprev_nr_hugepages=$(cat /proc/sys/vm/nr_hugepages)\n\tif [ \"$ARCH\" == \"$ARCH_ARM64\" ]; then\n\t\techo 6 > /proc/sys/vm/nr_hugepages\n\tfi\n\tCATEGORY=\"hugevm\" run_test bash ./va_high_addr_switch.sh\n\tif [ \"$ARCH\" == \"$ARCH_ARM64\" ]; then\n\t\techo $prev_nr_hugepages > /proc/sys/vm/nr_hugepages\n\tfi\nfi # VADDR64\n\n# vmalloc stability smoke test\nCATEGORY=\"vmalloc\" run_test bash ./test_vmalloc.sh smoke\n\nCATEGORY=\"mremap\" run_test ./mremap_dontunmap\n\nCATEGORY=\"hmm\" run_test bash ./test_hmm.sh smoke\n\n# MADV_POPULATE_READ and MADV_POPULATE_WRITE tests\nCATEGORY=\"madv_populate\" run_test ./madv_populate\n\nCATEGORY=\"memfd_secret\" run_test ./memfd_secret\n\n# KSM KSM_MERGE_TIME_HUGE_PAGES test with size of 100\nCATEGORY=\"ksm\" run_test ./ksm_tests -H -s 100\n# KSM KSM_MERGE_TIME test with size of 100\nCATEGORY=\"ksm\" run_test ./ksm_tests -P -s 100\n# KSM MADV_MERGEABLE test with 10 identical pages\nCATEGORY=\"ksm\" run_test ./ksm_tests -M -p 10\n# KSM unmerge test\nCATEGORY=\"ksm\" run_test ./ksm_tests -U\n# KSM test with 10 zero pages and use_zero_pages = 0\nCATEGORY=\"ksm\" run_test ./ksm_tests -Z -p 10 -z 0\n# KSM test with 10 zero pages and use_zero_pages = 1\nCATEGORY=\"ksm\" run_test ./ksm_tests -Z -p 10 -z 1\n# KSM test with 2 NUMA nodes and merge_across_nodes = 1\nCATEGORY=\"ksm_numa\" run_test ./ksm_tests -N -m 1\n# KSM test with 2 NUMA nodes and merge_across_nodes = 0\nCATEGORY=\"ksm_numa\" run_test ./ksm_tests -N -m 0\n\nCATEGORY=\"ksm\" run_test ./ksm_functional_tests\n\nrun_test ./ksm_functional_tests\n\n# protection_keys tests\nif [ -x ./protection_keys_32 ]\nthen\n\tCATEGORY=\"pkey\" run_test ./protection_keys_32\nfi\n\nif [ -x ./protection_keys_64 ]\nthen\n\tCATEGORY=\"pkey\" run_test ./protection_keys_64\nfi\n\nif [ -x ./soft-dirty ]\nthen\n\tCATEGORY=\"soft_dirty\" run_test ./soft-dirty\nfi\n\n# COW tests\nCATEGORY=\"cow\" run_test ./cow\n\nCATEGORY=\"thp\" run_test ./khugepaged\n\nCATEGORY=\"thp\" run_test ./transhuge-stress -d 20\n\nCATEGORY=\"thp\" run_test ./split_huge_page_test\n\nCATEGORY=\"migration\" run_test ./migration\n\nCATEGORY=\"mkdirty\" run_test ./mkdirty\n\nCATEGORY=\"mdwe\" run_test ./mdwe_test\n\necho \"SUMMARY: PASS=${count_pass} SKIP=${count_skip} FAIL=${count_fail}\"\n\nexit $exitcode\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}