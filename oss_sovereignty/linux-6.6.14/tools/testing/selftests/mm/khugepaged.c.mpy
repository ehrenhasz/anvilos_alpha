{
  "module_name": "khugepaged.c",
  "hash_id": "e59e92f4586534f244e3460830ee1c1d1ed5ae590792d433de682b1ebc93ce99",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/selftests/mm/khugepaged.c",
  "human_readable_source": "#define _GNU_SOURCE\n#include <ctype.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <limits.h>\n#include <dirent.h>\n#include <signal.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h>\n#include <string.h>\n#include <unistd.h>\n\n#include <linux/mman.h>\n#include <sys/mman.h>\n#include <sys/wait.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <sys/sysmacros.h>\n#include <sys/vfs.h>\n\n#include \"linux/magic.h\"\n\n#include \"vm_util.h\"\n\n#define BASE_ADDR ((void *)(1UL << 30))\nstatic unsigned long hpage_pmd_size;\nstatic unsigned long page_size;\nstatic int hpage_pmd_nr;\n\n#define THP_SYSFS \"/sys/kernel/mm/transparent_hugepage/\"\n#define PID_SMAPS \"/proc/self/smaps\"\n#define TEST_FILE \"collapse_test_file\"\n\n#define MAX_LINE_LENGTH 500\n\nenum vma_type {\n\tVMA_ANON,\n\tVMA_FILE,\n\tVMA_SHMEM,\n};\n\nstruct mem_ops {\n\tvoid *(*setup_area)(int nr_hpages);\n\tvoid (*cleanup_area)(void *p, unsigned long size);\n\tvoid (*fault)(void *p, unsigned long start, unsigned long end);\n\tbool (*check_huge)(void *addr, int nr_hpages);\n\tconst char *name;\n};\n\nstatic struct mem_ops *file_ops;\nstatic struct mem_ops *anon_ops;\nstatic struct mem_ops *shmem_ops;\n\nstruct collapse_context {\n\tvoid (*collapse)(const char *msg, char *p, int nr_hpages,\n\t\t\t struct mem_ops *ops, bool expect);\n\tbool enforce_pte_scan_limits;\n\tconst char *name;\n};\n\nstatic struct collapse_context *khugepaged_context;\nstatic struct collapse_context *madvise_context;\n\nstruct file_info {\n\tconst char *dir;\n\tchar path[PATH_MAX];\n\tenum vma_type type;\n\tint fd;\n\tchar dev_queue_read_ahead_path[PATH_MAX];\n};\n\nstatic struct file_info finfo;\n\nenum thp_enabled {\n\tTHP_ALWAYS,\n\tTHP_MADVISE,\n\tTHP_NEVER,\n};\n\nstatic const char *thp_enabled_strings[] = {\n\t\"always\",\n\t\"madvise\",\n\t\"never\",\n\tNULL\n};\n\nenum thp_defrag {\n\tTHP_DEFRAG_ALWAYS,\n\tTHP_DEFRAG_DEFER,\n\tTHP_DEFRAG_DEFER_MADVISE,\n\tTHP_DEFRAG_MADVISE,\n\tTHP_DEFRAG_NEVER,\n};\n\nstatic const char *thp_defrag_strings[] = {\n\t\"always\",\n\t\"defer\",\n\t\"defer+madvise\",\n\t\"madvise\",\n\t\"never\",\n\tNULL\n};\n\nenum shmem_enabled {\n\tSHMEM_ALWAYS,\n\tSHMEM_WITHIN_SIZE,\n\tSHMEM_ADVISE,\n\tSHMEM_NEVER,\n\tSHMEM_DENY,\n\tSHMEM_FORCE,\n};\n\nstatic const char *shmem_enabled_strings[] = {\n\t\"always\",\n\t\"within_size\",\n\t\"advise\",\n\t\"never\",\n\t\"deny\",\n\t\"force\",\n\tNULL\n};\n\nstruct khugepaged_settings {\n\tbool defrag;\n\tunsigned int alloc_sleep_millisecs;\n\tunsigned int scan_sleep_millisecs;\n\tunsigned int max_ptes_none;\n\tunsigned int max_ptes_swap;\n\tunsigned int max_ptes_shared;\n\tunsigned long pages_to_scan;\n};\n\nstruct settings {\n\tenum thp_enabled thp_enabled;\n\tenum thp_defrag thp_defrag;\n\tenum shmem_enabled shmem_enabled;\n\tbool use_zero_page;\n\tstruct khugepaged_settings khugepaged;\n\tunsigned long read_ahead_kb;\n};\n\nstatic struct settings saved_settings;\nstatic bool skip_settings_restore;\n\nstatic int exit_status;\n\nstatic void success(const char *msg)\n{\n\tprintf(\" \\e[32m%s\\e[0m\\n\", msg);\n}\n\nstatic void fail(const char *msg)\n{\n\tprintf(\" \\e[31m%s\\e[0m\\n\", msg);\n\texit_status++;\n}\n\nstatic void skip(const char *msg)\n{\n\tprintf(\" \\e[33m%s\\e[0m\\n\", msg);\n}\n\nstatic int read_file(const char *path, char *buf, size_t buflen)\n{\n\tint fd;\n\tssize_t numread;\n\n\tfd = open(path, O_RDONLY);\n\tif (fd == -1)\n\t\treturn 0;\n\n\tnumread = read(fd, buf, buflen - 1);\n\tif (numread < 1) {\n\t\tclose(fd);\n\t\treturn 0;\n\t}\n\n\tbuf[numread] = '\\0';\n\tclose(fd);\n\n\treturn (unsigned int) numread;\n}\n\nstatic int write_file(const char *path, const char *buf, size_t buflen)\n{\n\tint fd;\n\tssize_t numwritten;\n\n\tfd = open(path, O_WRONLY);\n\tif (fd == -1) {\n\t\tprintf(\"open(%s)\\n\", path);\n\t\texit(EXIT_FAILURE);\n\t\treturn 0;\n\t}\n\n\tnumwritten = write(fd, buf, buflen - 1);\n\tclose(fd);\n\tif (numwritten < 1) {\n\t\tprintf(\"write(%s)\\n\", buf);\n\t\texit(EXIT_FAILURE);\n\t\treturn 0;\n\t}\n\n\treturn (unsigned int) numwritten;\n}\n\nstatic int read_string(const char *name, const char *strings[])\n{\n\tchar path[PATH_MAX];\n\tchar buf[256];\n\tchar *c;\n\tint ret;\n\n\tret = snprintf(path, PATH_MAX, THP_SYSFS \"%s\", name);\n\tif (ret >= PATH_MAX) {\n\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tif (!read_file(path, buf, sizeof(buf))) {\n\t\tperror(path);\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tc = strchr(buf, '[');\n\tif (!c) {\n\t\tprintf(\"%s: Parse failure\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tc++;\n\tmemmove(buf, c, sizeof(buf) - (c - buf));\n\n\tc = strchr(buf, ']');\n\tif (!c) {\n\t\tprintf(\"%s: Parse failure\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\t*c = '\\0';\n\n\tret = 0;\n\twhile (strings[ret]) {\n\t\tif (!strcmp(strings[ret], buf))\n\t\t\treturn ret;\n\t\tret++;\n\t}\n\n\tprintf(\"Failed to parse %s\\n\", name);\n\texit(EXIT_FAILURE);\n}\n\nstatic void write_string(const char *name, const char *val)\n{\n\tchar path[PATH_MAX];\n\tint ret;\n\n\tret = snprintf(path, PATH_MAX, THP_SYSFS \"%s\", name);\n\tif (ret >= PATH_MAX) {\n\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tif (!write_file(path, val, strlen(val) + 1)) {\n\t\tperror(path);\n\t\texit(EXIT_FAILURE);\n\t}\n}\n\nstatic const unsigned long _read_num(const char *path)\n{\n\tchar buf[21];\n\n\tif (read_file(path, buf, sizeof(buf)) < 0) {\n\t\tperror(\"read_file(read_num)\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\treturn strtoul(buf, NULL, 10);\n}\n\nstatic const unsigned long read_num(const char *name)\n{\n\tchar path[PATH_MAX];\n\tint ret;\n\n\tret = snprintf(path, PATH_MAX, THP_SYSFS \"%s\", name);\n\tif (ret >= PATH_MAX) {\n\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\treturn _read_num(path);\n}\n\nstatic void _write_num(const char *path, unsigned long num)\n{\n\tchar buf[21];\n\n\tsprintf(buf, \"%ld\", num);\n\tif (!write_file(path, buf, strlen(buf) + 1)) {\n\t\tperror(path);\n\t\texit(EXIT_FAILURE);\n\t}\n}\n\nstatic void write_num(const char *name, unsigned long num)\n{\n\tchar path[PATH_MAX];\n\tint ret;\n\n\tret = snprintf(path, PATH_MAX, THP_SYSFS \"%s\", name);\n\tif (ret >= PATH_MAX) {\n\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\t_write_num(path, num);\n}\n\nstatic void write_settings(struct settings *settings)\n{\n\tstruct khugepaged_settings *khugepaged = &settings->khugepaged;\n\n\twrite_string(\"enabled\", thp_enabled_strings[settings->thp_enabled]);\n\twrite_string(\"defrag\", thp_defrag_strings[settings->thp_defrag]);\n\twrite_string(\"shmem_enabled\",\n\t\t\tshmem_enabled_strings[settings->shmem_enabled]);\n\twrite_num(\"use_zero_page\", settings->use_zero_page);\n\n\twrite_num(\"khugepaged/defrag\", khugepaged->defrag);\n\twrite_num(\"khugepaged/alloc_sleep_millisecs\",\n\t\t\tkhugepaged->alloc_sleep_millisecs);\n\twrite_num(\"khugepaged/scan_sleep_millisecs\",\n\t\t\tkhugepaged->scan_sleep_millisecs);\n\twrite_num(\"khugepaged/max_ptes_none\", khugepaged->max_ptes_none);\n\twrite_num(\"khugepaged/max_ptes_swap\", khugepaged->max_ptes_swap);\n\twrite_num(\"khugepaged/max_ptes_shared\", khugepaged->max_ptes_shared);\n\twrite_num(\"khugepaged/pages_to_scan\", khugepaged->pages_to_scan);\n\n\tif (file_ops && finfo.type == VMA_FILE)\n\t\t_write_num(finfo.dev_queue_read_ahead_path,\n\t\t\t   settings->read_ahead_kb);\n}\n\n#define MAX_SETTINGS_DEPTH 4\nstatic struct settings settings_stack[MAX_SETTINGS_DEPTH];\nstatic int settings_index;\n\nstatic struct settings *current_settings(void)\n{\n\tif (!settings_index) {\n\t\tprintf(\"Fail: No settings set\");\n\t\texit(EXIT_FAILURE);\n\t}\n\treturn settings_stack + settings_index - 1;\n}\n\nstatic void push_settings(struct settings *settings)\n{\n\tif (settings_index >= MAX_SETTINGS_DEPTH) {\n\t\tprintf(\"Fail: Settings stack exceeded\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tsettings_stack[settings_index++] = *settings;\n\twrite_settings(current_settings());\n}\n\nstatic void pop_settings(void)\n{\n\tif (settings_index <= 0) {\n\t\tprintf(\"Fail: Settings stack empty\");\n\t\texit(EXIT_FAILURE);\n\t}\n\t--settings_index;\n\twrite_settings(current_settings());\n}\n\nstatic void restore_settings(int sig)\n{\n\tif (skip_settings_restore)\n\t\tgoto out;\n\n\tprintf(\"Restore THP and khugepaged settings...\");\n\twrite_settings(&saved_settings);\n\tsuccess(\"OK\");\n\tif (sig)\n\t\texit(EXIT_FAILURE);\nout:\n\texit(exit_status);\n}\n\nstatic void save_settings(void)\n{\n\tprintf(\"Save THP and khugepaged settings...\");\n\tsaved_settings = (struct settings) {\n\t\t.thp_enabled = read_string(\"enabled\", thp_enabled_strings),\n\t\t.thp_defrag = read_string(\"defrag\", thp_defrag_strings),\n\t\t.shmem_enabled =\n\t\t\tread_string(\"shmem_enabled\", shmem_enabled_strings),\n\t\t.use_zero_page = read_num(\"use_zero_page\"),\n\t};\n\tsaved_settings.khugepaged = (struct khugepaged_settings) {\n\t\t.defrag = read_num(\"khugepaged/defrag\"),\n\t\t.alloc_sleep_millisecs =\n\t\t\tread_num(\"khugepaged/alloc_sleep_millisecs\"),\n\t\t.scan_sleep_millisecs =\n\t\t\tread_num(\"khugepaged/scan_sleep_millisecs\"),\n\t\t.max_ptes_none = read_num(\"khugepaged/max_ptes_none\"),\n\t\t.max_ptes_swap = read_num(\"khugepaged/max_ptes_swap\"),\n\t\t.max_ptes_shared = read_num(\"khugepaged/max_ptes_shared\"),\n\t\t.pages_to_scan = read_num(\"khugepaged/pages_to_scan\"),\n\t};\n\tif (file_ops && finfo.type == VMA_FILE)\n\t\tsaved_settings.read_ahead_kb =\n\t\t\t\t_read_num(finfo.dev_queue_read_ahead_path);\n\n\tsuccess(\"OK\");\n\n\tsignal(SIGTERM, restore_settings);\n\tsignal(SIGINT, restore_settings);\n\tsignal(SIGHUP, restore_settings);\n\tsignal(SIGQUIT, restore_settings);\n}\n\nstatic void get_finfo(const char *dir)\n{\n\tstruct stat path_stat;\n\tstruct statfs fs;\n\tchar buf[1 << 10];\n\tchar path[PATH_MAX];\n\tchar *str, *end;\n\n\tfinfo.dir = dir;\n\tstat(finfo.dir, &path_stat);\n\tif (!S_ISDIR(path_stat.st_mode)) {\n\t\tprintf(\"%s: Not a directory (%s)\\n\", __func__, finfo.dir);\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (snprintf(finfo.path, sizeof(finfo.path), \"%s/\" TEST_FILE,\n\t\t     finfo.dir) >= sizeof(finfo.path)) {\n\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (statfs(finfo.dir, &fs)) {\n\t\tperror(\"statfs()\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tfinfo.type = fs.f_type == TMPFS_MAGIC ? VMA_SHMEM : VMA_FILE;\n\tif (finfo.type == VMA_SHMEM)\n\t\treturn;\n\n\t \n\tif (snprintf(path, sizeof(path), \"/sys/dev/block/%d:%d/uevent\",\n\t\t     major(path_stat.st_dev), minor(path_stat.st_dev))\n\t    >= sizeof(path)) {\n\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (read_file(path, buf, sizeof(buf)) < 0) {\n\t\tperror(\"read_file(read_num)\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (strstr(buf, \"DEVTYPE=disk\")) {\n\t\t \n\t\tif (snprintf(finfo.dev_queue_read_ahead_path,\n\t\t\t     sizeof(finfo.dev_queue_read_ahead_path),\n\t\t\t     \"/sys/dev/block/%d:%d/queue/read_ahead_kb\",\n\t\t\t     major(path_stat.st_dev), minor(path_stat.st_dev))\n\t\t    >= sizeof(finfo.dev_queue_read_ahead_path)) {\n\t\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\t\treturn;\n\t}\n\tif (!strstr(buf, \"DEVTYPE=partition\")) {\n\t\tprintf(\"%s: Unknown device type: %s\\n\", __func__, path);\n\t\texit(EXIT_FAILURE);\n\t}\n\t \n\tstr = strstr(buf, \"DEVNAME=\");\n\tif (!str) {\n\t\tprintf(\"%s: Could not read: %s\", __func__, path);\n\t\texit(EXIT_FAILURE);\n\t}\n\tstr += 8;\n\tend = str;\n\twhile (*end) {\n\t\tif (isdigit(*end)) {\n\t\t\t*end = '\\0';\n\t\t\tif (snprintf(finfo.dev_queue_read_ahead_path,\n\t\t\t\t     sizeof(finfo.dev_queue_read_ahead_path),\n\t\t\t\t     \"/sys/block/%s/queue/read_ahead_kb\",\n\t\t\t\t     str) >= sizeof(finfo.dev_queue_read_ahead_path)) {\n\t\t\t\tprintf(\"%s: Pathname is too long\\n\", __func__);\n\t\t\t\texit(EXIT_FAILURE);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\t++end;\n\t}\n\tprintf(\"%s: Could not read: %s\\n\", __func__, path);\n\texit(EXIT_FAILURE);\n}\n\nstatic bool check_swap(void *addr, unsigned long size)\n{\n\tbool swap = false;\n\tint ret;\n\tFILE *fp;\n\tchar buffer[MAX_LINE_LENGTH];\n\tchar addr_pattern[MAX_LINE_LENGTH];\n\n\tret = snprintf(addr_pattern, MAX_LINE_LENGTH, \"%08lx-\",\n\t\t       (unsigned long) addr);\n\tif (ret >= MAX_LINE_LENGTH) {\n\t\tprintf(\"%s: Pattern is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\n\n\tfp = fopen(PID_SMAPS, \"r\");\n\tif (!fp) {\n\t\tprintf(\"%s: Failed to open file %s\\n\", __func__, PID_SMAPS);\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (!check_for_pattern(fp, addr_pattern, buffer, sizeof(buffer)))\n\t\tgoto err_out;\n\n\tret = snprintf(addr_pattern, MAX_LINE_LENGTH, \"Swap:%19ld kB\",\n\t\t       size >> 10);\n\tif (ret >= MAX_LINE_LENGTH) {\n\t\tprintf(\"%s: Pattern is too long\\n\", __func__);\n\t\texit(EXIT_FAILURE);\n\t}\n\t \n\tif (!check_for_pattern(fp, \"Swap:\", buffer, sizeof(buffer)))\n\t\tgoto err_out;\n\n\tif (strncmp(buffer, addr_pattern, strlen(addr_pattern)))\n\t\tgoto err_out;\n\n\tswap = true;\nerr_out:\n\tfclose(fp);\n\treturn swap;\n}\n\nstatic void *alloc_mapping(int nr)\n{\n\tvoid *p;\n\n\tp = mmap(BASE_ADDR, nr * hpage_pmd_size, PROT_READ | PROT_WRITE,\n\t\t MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);\n\tif (p != BASE_ADDR) {\n\t\tprintf(\"Failed to allocate VMA at %p\\n\", BASE_ADDR);\n\t\texit(EXIT_FAILURE);\n\t}\n\n\treturn p;\n}\n\nstatic void fill_memory(int *p, unsigned long start, unsigned long end)\n{\n\tint i;\n\n\tfor (i = start / page_size; i < end / page_size; i++)\n\t\tp[i * page_size / sizeof(*p)] = i + 0xdead0000;\n}\n\n \nstatic int madvise_collapse_retry(void *p, unsigned long size)\n{\n\tbool retry = true;\n\tint ret;\n\nretry:\n\tret = madvise(p, size, MADV_COLLAPSE);\n\tif (ret && errno == EAGAIN && retry) {\n\t\tretry = false;\n\t\tgoto retry;\n\t}\n\treturn ret;\n}\n\n \nstatic void *alloc_hpage(struct mem_ops *ops)\n{\n\tvoid *p = ops->setup_area(1);\n\n\tops->fault(p, 0, hpage_pmd_size);\n\n\t \n\tprintf(\"Allocate huge page...\");\n\tif (madvise_collapse_retry(p, hpage_pmd_size)) {\n\t\tperror(\"madvise(MADV_COLLAPSE)\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (!ops->check_huge(p, 1)) {\n\t\tperror(\"madvise(MADV_COLLAPSE)\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (madvise(p, hpage_pmd_size, MADV_HUGEPAGE)) {\n\t\tperror(\"madvise(MADV_HUGEPAGE)\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tsuccess(\"OK\");\n\treturn p;\n}\n\nstatic void validate_memory(int *p, unsigned long start, unsigned long end)\n{\n\tint i;\n\n\tfor (i = start / page_size; i < end / page_size; i++) {\n\t\tif (p[i * page_size / sizeof(*p)] != i + 0xdead0000) {\n\t\t\tprintf(\"Page %d is corrupted: %#x\\n\",\n\t\t\t\t\ti, p[i * page_size / sizeof(*p)]);\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\t}\n}\n\nstatic void *anon_setup_area(int nr_hpages)\n{\n\treturn alloc_mapping(nr_hpages);\n}\n\nstatic void anon_cleanup_area(void *p, unsigned long size)\n{\n\tmunmap(p, size);\n}\n\nstatic void anon_fault(void *p, unsigned long start, unsigned long end)\n{\n\tfill_memory(p, start, end);\n}\n\nstatic bool anon_check_huge(void *addr, int nr_hpages)\n{\n\treturn check_huge_anon(addr, nr_hpages, hpage_pmd_size);\n}\n\nstatic void *file_setup_area(int nr_hpages)\n{\n\tint fd;\n\tvoid *p;\n\tunsigned long size;\n\n\tunlink(finfo.path);   \n\tprintf(\"Creating %s for collapse%s...\", finfo.path,\n\t       finfo.type == VMA_SHMEM ? \" (tmpfs)\" : \"\");\n\tfd = open(finfo.path, O_DSYNC | O_CREAT | O_RDWR | O_TRUNC | O_EXCL,\n\t\t  777);\n\tif (fd < 0) {\n\t\tperror(\"open()\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tsize = nr_hpages * hpage_pmd_size;\n\tp = alloc_mapping(nr_hpages);\n\tfill_memory(p, 0, size);\n\twrite(fd, p, size);\n\tclose(fd);\n\tmunmap(p, size);\n\tsuccess(\"OK\");\n\n\tprintf(\"Opening %s read only for collapse...\", finfo.path);\n\tfinfo.fd = open(finfo.path, O_RDONLY, 777);\n\tif (finfo.fd < 0) {\n\t\tperror(\"open()\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tp = mmap(BASE_ADDR, size, PROT_READ | PROT_EXEC,\n\t\t MAP_PRIVATE, finfo.fd, 0);\n\tif (p == MAP_FAILED || p != BASE_ADDR) {\n\t\tperror(\"mmap()\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\t \n\twrite_file(\"/proc/sys/vm/drop_caches\", \"3\", 2);\n\tsuccess(\"OK\");\n\treturn p;\n}\n\nstatic void file_cleanup_area(void *p, unsigned long size)\n{\n\tmunmap(p, size);\n\tclose(finfo.fd);\n\tunlink(finfo.path);\n}\n\nstatic void file_fault(void *p, unsigned long start, unsigned long end)\n{\n\tif (madvise(((char *)p) + start, end - start, MADV_POPULATE_READ)) {\n\t\tperror(\"madvise(MADV_POPULATE_READ\");\n\t\texit(EXIT_FAILURE);\n\t}\n}\n\nstatic bool file_check_huge(void *addr, int nr_hpages)\n{\n\tswitch (finfo.type) {\n\tcase VMA_FILE:\n\t\treturn check_huge_file(addr, nr_hpages, hpage_pmd_size);\n\tcase VMA_SHMEM:\n\t\treturn check_huge_shmem(addr, nr_hpages, hpage_pmd_size);\n\tdefault:\n\t\texit(EXIT_FAILURE);\n\t\treturn false;\n\t}\n}\n\nstatic void *shmem_setup_area(int nr_hpages)\n{\n\tvoid *p;\n\tunsigned long size = nr_hpages * hpage_pmd_size;\n\n\tfinfo.fd = memfd_create(\"khugepaged-selftest-collapse-shmem\", 0);\n\tif (finfo.fd < 0)  {\n\t\tperror(\"memfd_create()\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (ftruncate(finfo.fd, size)) {\n\t\tperror(\"ftruncate()\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tp = mmap(BASE_ADDR, size, PROT_READ | PROT_WRITE, MAP_SHARED, finfo.fd,\n\t\t 0);\n\tif (p != BASE_ADDR) {\n\t\tperror(\"mmap()\");\n\t\texit(EXIT_FAILURE);\n\t}\n\treturn p;\n}\n\nstatic void shmem_cleanup_area(void *p, unsigned long size)\n{\n\tmunmap(p, size);\n\tclose(finfo.fd);\n}\n\nstatic bool shmem_check_huge(void *addr, int nr_hpages)\n{\n\treturn check_huge_shmem(addr, nr_hpages, hpage_pmd_size);\n}\n\nstatic struct mem_ops __anon_ops = {\n\t.setup_area = &anon_setup_area,\n\t.cleanup_area = &anon_cleanup_area,\n\t.fault = &anon_fault,\n\t.check_huge = &anon_check_huge,\n\t.name = \"anon\",\n};\n\nstatic struct mem_ops __file_ops = {\n\t.setup_area = &file_setup_area,\n\t.cleanup_area = &file_cleanup_area,\n\t.fault = &file_fault,\n\t.check_huge = &file_check_huge,\n\t.name = \"file\",\n};\n\nstatic struct mem_ops __shmem_ops = {\n\t.setup_area = &shmem_setup_area,\n\t.cleanup_area = &shmem_cleanup_area,\n\t.fault = &anon_fault,\n\t.check_huge = &shmem_check_huge,\n\t.name = \"shmem\",\n};\n\nstatic void __madvise_collapse(const char *msg, char *p, int nr_hpages,\n\t\t\t       struct mem_ops *ops, bool expect)\n{\n\tint ret;\n\tstruct settings settings = *current_settings();\n\n\tprintf(\"%s...\", msg);\n\n\t \n\tsettings.thp_enabled = THP_NEVER;\n\tsettings.shmem_enabled = SHMEM_NEVER;\n\tpush_settings(&settings);\n\n\t \n\tmadvise(p, nr_hpages * hpage_pmd_size, MADV_HUGEPAGE);\n\tret = madvise_collapse_retry(p, nr_hpages * hpage_pmd_size);\n\tif (((bool)ret) == expect)\n\t\tfail(\"Fail: Bad return value\");\n\telse if (!ops->check_huge(p, expect ? nr_hpages : 0))\n\t\tfail(\"Fail: check_huge()\");\n\telse\n\t\tsuccess(\"OK\");\n\n\tpop_settings();\n}\n\nstatic void madvise_collapse(const char *msg, char *p, int nr_hpages,\n\t\t\t     struct mem_ops *ops, bool expect)\n{\n\t \n\tif (!ops->check_huge(p, 0)) {\n\t\tprintf(\"Unexpected huge page\\n\");\n\t\texit(EXIT_FAILURE);\n\t}\n\t__madvise_collapse(msg, p, nr_hpages, ops, expect);\n}\n\n#define TICK 500000\nstatic bool wait_for_scan(const char *msg, char *p, int nr_hpages,\n\t\t\t  struct mem_ops *ops)\n{\n\tint full_scans;\n\tint timeout = 6;  \n\n\t \n\tif (!ops->check_huge(p, 0)) {\n\t\tprintf(\"Unexpected huge page\\n\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\tmadvise(p, nr_hpages * hpage_pmd_size, MADV_HUGEPAGE);\n\n\t \n\tfull_scans = read_num(\"khugepaged/full_scans\") + 2;\n\n\tprintf(\"%s...\", msg);\n\twhile (timeout--) {\n\t\tif (ops->check_huge(p, nr_hpages))\n\t\t\tbreak;\n\t\tif (read_num(\"khugepaged/full_scans\") >= full_scans)\n\t\t\tbreak;\n\t\tprintf(\".\");\n\t\tusleep(TICK);\n\t}\n\n\tmadvise(p, nr_hpages * hpage_pmd_size, MADV_NOHUGEPAGE);\n\n\treturn timeout == -1;\n}\n\nstatic void khugepaged_collapse(const char *msg, char *p, int nr_hpages,\n\t\t\t\tstruct mem_ops *ops, bool expect)\n{\n\tif (wait_for_scan(msg, p, nr_hpages, ops)) {\n\t\tif (expect)\n\t\t\tfail(\"Timeout\");\n\t\telse\n\t\t\tsuccess(\"OK\");\n\t\treturn;\n\t}\n\n\t \n\tif (ops != &__anon_ops)\n\t\tops->fault(p, 0, nr_hpages * hpage_pmd_size);\n\n\tif (ops->check_huge(p, expect ? nr_hpages : 0))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n}\n\nstatic struct collapse_context __khugepaged_context = {\n\t.collapse = &khugepaged_collapse,\n\t.enforce_pte_scan_limits = true,\n\t.name = \"khugepaged\",\n};\n\nstatic struct collapse_context __madvise_context = {\n\t.collapse = &madvise_collapse,\n\t.enforce_pte_scan_limits = false,\n\t.name = \"madvise\",\n};\n\nstatic bool is_tmpfs(struct mem_ops *ops)\n{\n\treturn ops == &__file_ops && finfo.type == VMA_SHMEM;\n}\n\nstatic void alloc_at_fault(void)\n{\n\tstruct settings settings = *current_settings();\n\tchar *p;\n\n\tsettings.thp_enabled = THP_ALWAYS;\n\tpush_settings(&settings);\n\n\tp = alloc_mapping(1);\n\t*p = 1;\n\tprintf(\"Allocate huge page on fault...\");\n\tif (check_huge_anon(p, 1, hpage_pmd_size))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\n\tpop_settings();\n\n\tmadvise(p, page_size, MADV_DONTNEED);\n\tprintf(\"Split huge PMD on MADV_DONTNEED...\");\n\tif (check_huge_anon(p, 0, hpage_pmd_size))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\tmunmap(p, hpage_pmd_size);\n}\n\nstatic void collapse_full(struct collapse_context *c, struct mem_ops *ops)\n{\n\tvoid *p;\n\tint nr_hpages = 4;\n\tunsigned long size = nr_hpages * hpage_pmd_size;\n\n\tp = ops->setup_area(nr_hpages);\n\tops->fault(p, 0, size);\n\tc->collapse(\"Collapse multiple fully populated PTE table\", p, nr_hpages,\n\t\t    ops, true);\n\tvalidate_memory(p, 0, size);\n\tops->cleanup_area(p, size);\n}\n\nstatic void collapse_empty(struct collapse_context *c, struct mem_ops *ops)\n{\n\tvoid *p;\n\n\tp = ops->setup_area(1);\n\tc->collapse(\"Do not collapse empty PTE table\", p, 1, ops, false);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_single_pte_entry(struct collapse_context *c, struct mem_ops *ops)\n{\n\tvoid *p;\n\n\tp = ops->setup_area(1);\n\tops->fault(p, 0, page_size);\n\tc->collapse(\"Collapse PTE table with single PTE entry present\", p,\n\t\t    1, ops, true);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_max_ptes_none(struct collapse_context *c, struct mem_ops *ops)\n{\n\tint max_ptes_none = hpage_pmd_nr / 2;\n\tstruct settings settings = *current_settings();\n\tvoid *p;\n\n\tsettings.khugepaged.max_ptes_none = max_ptes_none;\n\tpush_settings(&settings);\n\n\tp = ops->setup_area(1);\n\n\tif (is_tmpfs(ops)) {\n\t\t \n\t\tprintf(\"tmpfs...\");\n\t\tskip(\"Skip\");\n\t\tgoto skip;\n\t}\n\n\tops->fault(p, 0, (hpage_pmd_nr - max_ptes_none - 1) * page_size);\n\tc->collapse(\"Maybe collapse with max_ptes_none exceeded\", p, 1,\n\t\t    ops, !c->enforce_pte_scan_limits);\n\tvalidate_memory(p, 0, (hpage_pmd_nr - max_ptes_none - 1) * page_size);\n\n\tif (c->enforce_pte_scan_limits) {\n\t\tops->fault(p, 0, (hpage_pmd_nr - max_ptes_none) * page_size);\n\t\tc->collapse(\"Collapse with max_ptes_none PTEs empty\", p, 1, ops,\n\t\t\t    true);\n\t\tvalidate_memory(p, 0,\n\t\t\t\t(hpage_pmd_nr - max_ptes_none) * page_size);\n\t}\nskip:\n\tops->cleanup_area(p, hpage_pmd_size);\n\tpop_settings();\n}\n\nstatic void collapse_swapin_single_pte(struct collapse_context *c, struct mem_ops *ops)\n{\n\tvoid *p;\n\n\tp = ops->setup_area(1);\n\tops->fault(p, 0, hpage_pmd_size);\n\n\tprintf(\"Swapout one page...\");\n\tif (madvise(p, page_size, MADV_PAGEOUT)) {\n\t\tperror(\"madvise(MADV_PAGEOUT)\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (check_swap(p, page_size)) {\n\t\tsuccess(\"OK\");\n\t} else {\n\t\tfail(\"Fail\");\n\t\tgoto out;\n\t}\n\n\tc->collapse(\"Collapse with swapping in single PTE entry\", p, 1, ops,\n\t\t    true);\n\tvalidate_memory(p, 0, hpage_pmd_size);\nout:\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_max_ptes_swap(struct collapse_context *c, struct mem_ops *ops)\n{\n\tint max_ptes_swap = read_num(\"khugepaged/max_ptes_swap\");\n\tvoid *p;\n\n\tp = ops->setup_area(1);\n\tops->fault(p, 0, hpage_pmd_size);\n\n\tprintf(\"Swapout %d of %d pages...\", max_ptes_swap + 1, hpage_pmd_nr);\n\tif (madvise(p, (max_ptes_swap + 1) * page_size, MADV_PAGEOUT)) {\n\t\tperror(\"madvise(MADV_PAGEOUT)\");\n\t\texit(EXIT_FAILURE);\n\t}\n\tif (check_swap(p, (max_ptes_swap + 1) * page_size)) {\n\t\tsuccess(\"OK\");\n\t} else {\n\t\tfail(\"Fail\");\n\t\tgoto out;\n\t}\n\n\tc->collapse(\"Maybe collapse with max_ptes_swap exceeded\", p, 1, ops,\n\t\t    !c->enforce_pte_scan_limits);\n\tvalidate_memory(p, 0, hpage_pmd_size);\n\n\tif (c->enforce_pte_scan_limits) {\n\t\tops->fault(p, 0, hpage_pmd_size);\n\t\tprintf(\"Swapout %d of %d pages...\", max_ptes_swap,\n\t\t       hpage_pmd_nr);\n\t\tif (madvise(p, max_ptes_swap * page_size, MADV_PAGEOUT)) {\n\t\t\tperror(\"madvise(MADV_PAGEOUT)\");\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\t\tif (check_swap(p, max_ptes_swap * page_size)) {\n\t\t\tsuccess(\"OK\");\n\t\t} else {\n\t\t\tfail(\"Fail\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tc->collapse(\"Collapse with max_ptes_swap pages swapped out\", p,\n\t\t\t    1, ops, true);\n\t\tvalidate_memory(p, 0, hpage_pmd_size);\n\t}\nout:\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_single_pte_entry_compound(struct collapse_context *c, struct mem_ops *ops)\n{\n\tvoid *p;\n\n\tp = alloc_hpage(ops);\n\n\tif (is_tmpfs(ops)) {\n\t\t \n\t\tprintf(\"tmpfs...\");\n\t\tskip(\"Skip\");\n\t\tgoto skip;\n\t}\n\n\tmadvise(p, hpage_pmd_size, MADV_NOHUGEPAGE);\n\tprintf(\"Split huge page leaving single PTE mapping compound page...\");\n\tmadvise(p + page_size, hpage_pmd_size - page_size, MADV_DONTNEED);\n\tif (ops->check_huge(p, 0))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\n\tc->collapse(\"Collapse PTE table with single PTE mapping compound page\",\n\t\t    p, 1, ops, true);\n\tvalidate_memory(p, 0, page_size);\nskip:\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_full_of_compound(struct collapse_context *c, struct mem_ops *ops)\n{\n\tvoid *p;\n\n\tp = alloc_hpage(ops);\n\tprintf(\"Split huge page leaving single PTE page table full of compound pages...\");\n\tmadvise(p, page_size, MADV_NOHUGEPAGE);\n\tmadvise(p, hpage_pmd_size, MADV_NOHUGEPAGE);\n\tif (ops->check_huge(p, 0))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\n\tc->collapse(\"Collapse PTE table full of compound pages\", p, 1, ops,\n\t\t    true);\n\tvalidate_memory(p, 0, hpage_pmd_size);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_compound_extreme(struct collapse_context *c, struct mem_ops *ops)\n{\n\tvoid *p;\n\tint i;\n\n\tp = ops->setup_area(1);\n\tfor (i = 0; i < hpage_pmd_nr; i++) {\n\t\tprintf(\"\\rConstruct PTE page table full of different PTE-mapped compound pages %3d/%d...\",\n\t\t\t\ti + 1, hpage_pmd_nr);\n\n\t\tmadvise(BASE_ADDR, hpage_pmd_size, MADV_HUGEPAGE);\n\t\tops->fault(BASE_ADDR, 0, hpage_pmd_size);\n\t\tif (!ops->check_huge(BASE_ADDR, 1)) {\n\t\t\tprintf(\"Failed to allocate huge page\\n\");\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\t\tmadvise(BASE_ADDR, hpage_pmd_size, MADV_NOHUGEPAGE);\n\n\t\tp = mremap(BASE_ADDR - i * page_size,\n\t\t\t\ti * page_size + hpage_pmd_size,\n\t\t\t\t(i + 1) * page_size,\n\t\t\t\tMREMAP_MAYMOVE | MREMAP_FIXED,\n\t\t\t\tBASE_ADDR + 2 * hpage_pmd_size);\n\t\tif (p == MAP_FAILED) {\n\t\t\tperror(\"mremap+unmap\");\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\n\t\tp = mremap(BASE_ADDR + 2 * hpage_pmd_size,\n\t\t\t\t(i + 1) * page_size,\n\t\t\t\t(i + 1) * page_size + hpage_pmd_size,\n\t\t\t\tMREMAP_MAYMOVE | MREMAP_FIXED,\n\t\t\t\tBASE_ADDR - (i + 1) * page_size);\n\t\tif (p == MAP_FAILED) {\n\t\t\tperror(\"mremap+alloc\");\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\t}\n\n\tops->cleanup_area(BASE_ADDR, hpage_pmd_size);\n\tops->fault(p, 0, hpage_pmd_size);\n\tif (!ops->check_huge(p, 1))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\n\tc->collapse(\"Collapse PTE table full of different compound pages\", p, 1,\n\t\t    ops, true);\n\n\tvalidate_memory(p, 0, hpage_pmd_size);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_fork(struct collapse_context *c, struct mem_ops *ops)\n{\n\tint wstatus;\n\tvoid *p;\n\n\tp = ops->setup_area(1);\n\n\tprintf(\"Allocate small page...\");\n\tops->fault(p, 0, page_size);\n\tif (ops->check_huge(p, 0))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\n\tprintf(\"Share small page over fork()...\");\n\tif (!fork()) {\n\t\t \n\t\tskip_settings_restore = true;\n\t\texit_status = 0;\n\n\t\tif (ops->check_huge(p, 0))\n\t\t\tsuccess(\"OK\");\n\t\telse\n\t\t\tfail(\"Fail\");\n\n\t\tops->fault(p, page_size, 2 * page_size);\n\t\tc->collapse(\"Collapse PTE table with single page shared with parent process\",\n\t\t\t    p, 1, ops, true);\n\n\t\tvalidate_memory(p, 0, page_size);\n\t\tops->cleanup_area(p, hpage_pmd_size);\n\t\texit(exit_status);\n\t}\n\n\twait(&wstatus);\n\texit_status += WEXITSTATUS(wstatus);\n\n\tprintf(\"Check if parent still has small page...\");\n\tif (ops->check_huge(p, 0))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\tvalidate_memory(p, 0, page_size);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_fork_compound(struct collapse_context *c, struct mem_ops *ops)\n{\n\tint wstatus;\n\tvoid *p;\n\n\tp = alloc_hpage(ops);\n\tprintf(\"Share huge page over fork()...\");\n\tif (!fork()) {\n\t\t \n\t\tskip_settings_restore = true;\n\t\texit_status = 0;\n\n\t\tif (ops->check_huge(p, 1))\n\t\t\tsuccess(\"OK\");\n\t\telse\n\t\t\tfail(\"Fail\");\n\n\t\tprintf(\"Split huge page PMD in child process...\");\n\t\tmadvise(p, page_size, MADV_NOHUGEPAGE);\n\t\tmadvise(p, hpage_pmd_size, MADV_NOHUGEPAGE);\n\t\tif (ops->check_huge(p, 0))\n\t\t\tsuccess(\"OK\");\n\t\telse\n\t\t\tfail(\"Fail\");\n\t\tops->fault(p, 0, page_size);\n\n\t\twrite_num(\"khugepaged/max_ptes_shared\", hpage_pmd_nr - 1);\n\t\tc->collapse(\"Collapse PTE table full of compound pages in child\",\n\t\t\t    p, 1, ops, true);\n\t\twrite_num(\"khugepaged/max_ptes_shared\",\n\t\t\t  current_settings()->khugepaged.max_ptes_shared);\n\n\t\tvalidate_memory(p, 0, hpage_pmd_size);\n\t\tops->cleanup_area(p, hpage_pmd_size);\n\t\texit(exit_status);\n\t}\n\n\twait(&wstatus);\n\texit_status += WEXITSTATUS(wstatus);\n\n\tprintf(\"Check if parent still has huge page...\");\n\tif (ops->check_huge(p, 1))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\tvalidate_memory(p, 0, hpage_pmd_size);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void collapse_max_ptes_shared(struct collapse_context *c, struct mem_ops *ops)\n{\n\tint max_ptes_shared = read_num(\"khugepaged/max_ptes_shared\");\n\tint wstatus;\n\tvoid *p;\n\n\tp = alloc_hpage(ops);\n\tprintf(\"Share huge page over fork()...\");\n\tif (!fork()) {\n\t\t \n\t\tskip_settings_restore = true;\n\t\texit_status = 0;\n\n\t\tif (ops->check_huge(p, 1))\n\t\t\tsuccess(\"OK\");\n\t\telse\n\t\t\tfail(\"Fail\");\n\n\t\tprintf(\"Trigger CoW on page %d of %d...\",\n\t\t\t\thpage_pmd_nr - max_ptes_shared - 1, hpage_pmd_nr);\n\t\tops->fault(p, 0, (hpage_pmd_nr - max_ptes_shared - 1) * page_size);\n\t\tif (ops->check_huge(p, 0))\n\t\t\tsuccess(\"OK\");\n\t\telse\n\t\t\tfail(\"Fail\");\n\n\t\tc->collapse(\"Maybe collapse with max_ptes_shared exceeded\", p,\n\t\t\t    1, ops, !c->enforce_pte_scan_limits);\n\n\t\tif (c->enforce_pte_scan_limits) {\n\t\t\tprintf(\"Trigger CoW on page %d of %d...\",\n\t\t\t       hpage_pmd_nr - max_ptes_shared, hpage_pmd_nr);\n\t\t\tops->fault(p, 0, (hpage_pmd_nr - max_ptes_shared) *\n\t\t\t\t    page_size);\n\t\t\tif (ops->check_huge(p, 0))\n\t\t\t\tsuccess(\"OK\");\n\t\t\telse\n\t\t\t\tfail(\"Fail\");\n\n\t\t\tc->collapse(\"Collapse with max_ptes_shared PTEs shared\",\n\t\t\t\t    p, 1, ops, true);\n\t\t}\n\n\t\tvalidate_memory(p, 0, hpage_pmd_size);\n\t\tops->cleanup_area(p, hpage_pmd_size);\n\t\texit(exit_status);\n\t}\n\n\twait(&wstatus);\n\texit_status += WEXITSTATUS(wstatus);\n\n\tprintf(\"Check if parent still has huge page...\");\n\tif (ops->check_huge(p, 1))\n\t\tsuccess(\"OK\");\n\telse\n\t\tfail(\"Fail\");\n\tvalidate_memory(p, 0, hpage_pmd_size);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\nstatic void madvise_collapse_existing_thps(struct collapse_context *c,\n\t\t\t\t\t   struct mem_ops *ops)\n{\n\tvoid *p;\n\n\tp = ops->setup_area(1);\n\tops->fault(p, 0, hpage_pmd_size);\n\tc->collapse(\"Collapse fully populated PTE table...\", p, 1, ops, true);\n\tvalidate_memory(p, 0, hpage_pmd_size);\n\n\t \n\t__madvise_collapse(\"Re-collapse PMD-mapped hugepage\", p, 1, ops, true);\n\tvalidate_memory(p, 0, hpage_pmd_size);\n\tops->cleanup_area(p, hpage_pmd_size);\n}\n\n \nstatic void madvise_retracted_page_tables(struct collapse_context *c,\n\t\t\t\t\t  struct mem_ops *ops)\n{\n\tvoid *p;\n\tint nr_hpages = 1;\n\tunsigned long size = nr_hpages * hpage_pmd_size;\n\n\tp = ops->setup_area(nr_hpages);\n\tops->fault(p, 0, size);\n\n\t \n\tif (wait_for_scan(\"Collapse and leave PMD cleared\", p, nr_hpages,\n\t\t\t  ops)) {\n\t\tfail(\"Timeout\");\n\t\treturn;\n\t}\n\tsuccess(\"OK\");\n\tc->collapse(\"Install huge PMD from page cache\", p, nr_hpages, ops,\n\t\t    true);\n\tvalidate_memory(p, 0, size);\n\tops->cleanup_area(p, size);\n}\n\nstatic void usage(void)\n{\n\tfprintf(stderr, \"\\nUsage: ./khugepaged <test type> [dir]\\n\\n\");\n\tfprintf(stderr, \"\\t<test type>\\t: <context>:<mem_type>\\n\");\n\tfprintf(stderr, \"\\t<context>\\t: [all|khugepaged|madvise]\\n\");\n\tfprintf(stderr, \"\\t<mem_type>\\t: [all|anon|file|shmem]\\n\");\n\tfprintf(stderr, \"\\n\\t\\\"file,all\\\" mem_type requires [dir] argument\\n\");\n\tfprintf(stderr, \"\\n\\t\\\"file,all\\\" mem_type requires kernel built with\\n\");\n\tfprintf(stderr,\t\"\\tCONFIG_READ_ONLY_THP_FOR_FS=y\\n\");\n\tfprintf(stderr, \"\\n\\tif [dir] is a (sub)directory of a tmpfs mount, tmpfs must be\\n\");\n\tfprintf(stderr,\t\"\\tmounted with huge=madvise option for khugepaged tests to work\\n\");\n\texit(1);\n}\n\nstatic void parse_test_type(int argc, const char **argv)\n{\n\tchar *buf;\n\tconst char *token;\n\n\tif (argc == 1) {\n\t\t \n\t\tkhugepaged_context =  &__khugepaged_context;\n\t\tmadvise_context =  &__madvise_context;\n\t\tanon_ops = &__anon_ops;\n\t\treturn;\n\t}\n\n\tbuf = strdup(argv[1]);\n\ttoken = strsep(&buf, \":\");\n\n\tif (!strcmp(token, \"all\")) {\n\t\tkhugepaged_context =  &__khugepaged_context;\n\t\tmadvise_context =  &__madvise_context;\n\t} else if (!strcmp(token, \"khugepaged\")) {\n\t\tkhugepaged_context =  &__khugepaged_context;\n\t} else if (!strcmp(token, \"madvise\")) {\n\t\tmadvise_context =  &__madvise_context;\n\t} else {\n\t\tusage();\n\t}\n\n\tif (!buf)\n\t\tusage();\n\n\tif (!strcmp(buf, \"all\")) {\n\t\tfile_ops =  &__file_ops;\n\t\tanon_ops = &__anon_ops;\n\t\tshmem_ops = &__shmem_ops;\n\t} else if (!strcmp(buf, \"anon\")) {\n\t\tanon_ops = &__anon_ops;\n\t} else if (!strcmp(buf, \"file\")) {\n\t\tfile_ops =  &__file_ops;\n\t} else if (!strcmp(buf, \"shmem\")) {\n\t\tshmem_ops = &__shmem_ops;\n\t} else {\n\t\tusage();\n\t}\n\n\tif (!file_ops)\n\t\treturn;\n\n\tif (argc != 3)\n\t\tusage();\n}\n\nint main(int argc, const char **argv)\n{\n\tstruct settings default_settings = {\n\t\t.thp_enabled = THP_MADVISE,\n\t\t.thp_defrag = THP_DEFRAG_ALWAYS,\n\t\t.shmem_enabled = SHMEM_ADVISE,\n\t\t.use_zero_page = 0,\n\t\t.khugepaged = {\n\t\t\t.defrag = 1,\n\t\t\t.alloc_sleep_millisecs = 10,\n\t\t\t.scan_sleep_millisecs = 10,\n\t\t},\n\t\t \n\t\t.read_ahead_kb = 0,\n\t};\n\n\tparse_test_type(argc, argv);\n\n\tif (file_ops)\n\t\tget_finfo(argv[2]);\n\n\tsetbuf(stdout, NULL);\n\n\tpage_size = getpagesize();\n\thpage_pmd_size = read_pmd_pagesize();\n\tif (!hpage_pmd_size) {\n\t\tprintf(\"Reading PMD pagesize failed\");\n\t\texit(EXIT_FAILURE);\n\t}\n\thpage_pmd_nr = hpage_pmd_size / page_size;\n\n\tdefault_settings.khugepaged.max_ptes_none = hpage_pmd_nr - 1;\n\tdefault_settings.khugepaged.max_ptes_swap = hpage_pmd_nr / 8;\n\tdefault_settings.khugepaged.max_ptes_shared = hpage_pmd_nr / 2;\n\tdefault_settings.khugepaged.pages_to_scan = hpage_pmd_nr * 8;\n\n\tsave_settings();\n\tpush_settings(&default_settings);\n\n\talloc_at_fault();\n\n#define TEST(t, c, o) do { \\\n\tif (c && o) { \\\n\t\tprintf(\"\\nRun test: \" #t \" (%s:%s)\\n\", c->name, o->name); \\\n\t\tt(c, o); \\\n\t} \\\n\t} while (0)\n\n\tTEST(collapse_full, khugepaged_context, anon_ops);\n\tTEST(collapse_full, khugepaged_context, file_ops);\n\tTEST(collapse_full, khugepaged_context, shmem_ops);\n\tTEST(collapse_full, madvise_context, anon_ops);\n\tTEST(collapse_full, madvise_context, file_ops);\n\tTEST(collapse_full, madvise_context, shmem_ops);\n\n\tTEST(collapse_empty, khugepaged_context, anon_ops);\n\tTEST(collapse_empty, madvise_context, anon_ops);\n\n\tTEST(collapse_single_pte_entry, khugepaged_context, anon_ops);\n\tTEST(collapse_single_pte_entry, khugepaged_context, file_ops);\n\tTEST(collapse_single_pte_entry, khugepaged_context, shmem_ops);\n\tTEST(collapse_single_pte_entry, madvise_context, anon_ops);\n\tTEST(collapse_single_pte_entry, madvise_context, file_ops);\n\tTEST(collapse_single_pte_entry, madvise_context, shmem_ops);\n\n\tTEST(collapse_max_ptes_none, khugepaged_context, anon_ops);\n\tTEST(collapse_max_ptes_none, khugepaged_context, file_ops);\n\tTEST(collapse_max_ptes_none, madvise_context, anon_ops);\n\tTEST(collapse_max_ptes_none, madvise_context, file_ops);\n\n\tTEST(collapse_single_pte_entry_compound, khugepaged_context, anon_ops);\n\tTEST(collapse_single_pte_entry_compound, khugepaged_context, file_ops);\n\tTEST(collapse_single_pte_entry_compound, madvise_context, anon_ops);\n\tTEST(collapse_single_pte_entry_compound, madvise_context, file_ops);\n\n\tTEST(collapse_full_of_compound, khugepaged_context, anon_ops);\n\tTEST(collapse_full_of_compound, khugepaged_context, file_ops);\n\tTEST(collapse_full_of_compound, khugepaged_context, shmem_ops);\n\tTEST(collapse_full_of_compound, madvise_context, anon_ops);\n\tTEST(collapse_full_of_compound, madvise_context, file_ops);\n\tTEST(collapse_full_of_compound, madvise_context, shmem_ops);\n\n\tTEST(collapse_compound_extreme, khugepaged_context, anon_ops);\n\tTEST(collapse_compound_extreme, madvise_context, anon_ops);\n\n\tTEST(collapse_swapin_single_pte, khugepaged_context, anon_ops);\n\tTEST(collapse_swapin_single_pte, madvise_context, anon_ops);\n\n\tTEST(collapse_max_ptes_swap, khugepaged_context, anon_ops);\n\tTEST(collapse_max_ptes_swap, madvise_context, anon_ops);\n\n\tTEST(collapse_fork, khugepaged_context, anon_ops);\n\tTEST(collapse_fork, madvise_context, anon_ops);\n\n\tTEST(collapse_fork_compound, khugepaged_context, anon_ops);\n\tTEST(collapse_fork_compound, madvise_context, anon_ops);\n\n\tTEST(collapse_max_ptes_shared, khugepaged_context, anon_ops);\n\tTEST(collapse_max_ptes_shared, madvise_context, anon_ops);\n\n\tTEST(madvise_collapse_existing_thps, madvise_context, anon_ops);\n\tTEST(madvise_collapse_existing_thps, madvise_context, file_ops);\n\tTEST(madvise_collapse_existing_thps, madvise_context, shmem_ops);\n\n\tTEST(madvise_retracted_page_tables, madvise_context, file_ops);\n\tTEST(madvise_retracted_page_tables, madvise_context, shmem_ops);\n\n\trestore_settings(0);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}