{
  "module_name": "linux.c",
  "hash_id": "ec26acb45b91e2a643b6a9bba40541c3c09d287b650a0acea75e5673f671905a",
  "original_prompt": "Ingested from linux-6.6.14/tools/testing/radix-tree/linux.c",
  "human_readable_source": "\n#include <stdlib.h>\n#include <string.h>\n#include <malloc.h>\n#include <pthread.h>\n#include <unistd.h>\n#include <assert.h>\n\n#include <linux/gfp.h>\n#include <linux/poison.h>\n#include <linux/slab.h>\n#include <linux/radix-tree.h>\n#include <urcu/uatomic.h>\n\nint nr_allocated;\nint preempt_count;\nint test_verbose;\n\nstruct kmem_cache {\n\tpthread_mutex_t lock;\n\tunsigned int size;\n\tunsigned int align;\n\tint nr_objs;\n\tvoid *objs;\n\tvoid (*ctor)(void *);\n\tunsigned int non_kernel;\n\tunsigned long nr_allocated;\n\tunsigned long nr_tallocated;\n};\n\nvoid kmem_cache_set_non_kernel(struct kmem_cache *cachep, unsigned int val)\n{\n\tcachep->non_kernel = val;\n}\n\nunsigned long kmem_cache_get_alloc(struct kmem_cache *cachep)\n{\n\treturn cachep->size * cachep->nr_allocated;\n}\n\nunsigned long kmem_cache_nr_allocated(struct kmem_cache *cachep)\n{\n\treturn cachep->nr_allocated;\n}\n\nunsigned long kmem_cache_nr_tallocated(struct kmem_cache *cachep)\n{\n\treturn cachep->nr_tallocated;\n}\n\nvoid kmem_cache_zero_nr_tallocated(struct kmem_cache *cachep)\n{\n\tcachep->nr_tallocated = 0;\n}\n\nvoid *kmem_cache_alloc_lru(struct kmem_cache *cachep, struct list_lru *lru,\n\t\tint gfp)\n{\n\tvoid *p;\n\n\tif (!(gfp & __GFP_DIRECT_RECLAIM)) {\n\t\tif (!cachep->non_kernel)\n\t\t\treturn NULL;\n\n\t\tcachep->non_kernel--;\n\t}\n\n\tpthread_mutex_lock(&cachep->lock);\n\tif (cachep->nr_objs) {\n\t\tstruct radix_tree_node *node = cachep->objs;\n\t\tcachep->nr_objs--;\n\t\tcachep->objs = node->parent;\n\t\tpthread_mutex_unlock(&cachep->lock);\n\t\tnode->parent = NULL;\n\t\tp = node;\n\t} else {\n\t\tpthread_mutex_unlock(&cachep->lock);\n\t\tif (cachep->align)\n\t\t\tposix_memalign(&p, cachep->align, cachep->size);\n\t\telse\n\t\t\tp = malloc(cachep->size);\n\t\tif (cachep->ctor)\n\t\t\tcachep->ctor(p);\n\t\telse if (gfp & __GFP_ZERO)\n\t\t\tmemset(p, 0, cachep->size);\n\t}\n\n\tuatomic_inc(&cachep->nr_allocated);\n\tuatomic_inc(&nr_allocated);\n\tuatomic_inc(&cachep->nr_tallocated);\n\tif (kmalloc_verbose)\n\t\tprintf(\"Allocating %p from slab\\n\", p);\n\treturn p;\n}\n\nvoid kmem_cache_free_locked(struct kmem_cache *cachep, void *objp)\n{\n\tassert(objp);\n\tuatomic_dec(&nr_allocated);\n\tuatomic_dec(&cachep->nr_allocated);\n\tif (kmalloc_verbose)\n\t\tprintf(\"Freeing %p to slab\\n\", objp);\n\tif (cachep->nr_objs > 10 || cachep->align) {\n\t\tmemset(objp, POISON_FREE, cachep->size);\n\t\tfree(objp);\n\t} else {\n\t\tstruct radix_tree_node *node = objp;\n\t\tcachep->nr_objs++;\n\t\tnode->parent = cachep->objs;\n\t\tcachep->objs = node;\n\t}\n}\n\nvoid kmem_cache_free(struct kmem_cache *cachep, void *objp)\n{\n\tpthread_mutex_lock(&cachep->lock);\n\tkmem_cache_free_locked(cachep, objp);\n\tpthread_mutex_unlock(&cachep->lock);\n}\n\nvoid kmem_cache_free_bulk(struct kmem_cache *cachep, size_t size, void **list)\n{\n\tif (kmalloc_verbose)\n\t\tpr_debug(\"Bulk free %p[0-%lu]\\n\", list, size - 1);\n\n\tpthread_mutex_lock(&cachep->lock);\n\tfor (int i = 0; i < size; i++)\n\t\tkmem_cache_free_locked(cachep, list[i]);\n\tpthread_mutex_unlock(&cachep->lock);\n}\n\nvoid kmem_cache_shrink(struct kmem_cache *cachep)\n{\n}\n\nint kmem_cache_alloc_bulk(struct kmem_cache *cachep, gfp_t gfp, size_t size,\n\t\t\t  void **p)\n{\n\tsize_t i;\n\n\tif (kmalloc_verbose)\n\t\tpr_debug(\"Bulk alloc %lu\\n\", size);\n\n\tif (!(gfp & __GFP_DIRECT_RECLAIM)) {\n\t\tif (cachep->non_kernel < size)\n\t\t\treturn 0;\n\n\t\tcachep->non_kernel -= size;\n\t}\n\n\tpthread_mutex_lock(&cachep->lock);\n\tif (cachep->nr_objs >= size) {\n\t\tstruct radix_tree_node *node;\n\n\t\tfor (i = 0; i < size; i++) {\n\t\t\tnode = cachep->objs;\n\t\t\tcachep->nr_objs--;\n\t\t\tcachep->objs = node->parent;\n\t\t\tp[i] = node;\n\t\t\tnode->parent = NULL;\n\t\t}\n\t\tpthread_mutex_unlock(&cachep->lock);\n\t} else {\n\t\tpthread_mutex_unlock(&cachep->lock);\n\t\tfor (i = 0; i < size; i++) {\n\t\t\tif (cachep->align) {\n\t\t\t\tposix_memalign(&p[i], cachep->align,\n\t\t\t\t\t       cachep->size * size);\n\t\t\t} else {\n\t\t\t\tp[i] = malloc(cachep->size * size);\n\t\t\t}\n\t\t\tif (cachep->ctor)\n\t\t\t\tcachep->ctor(p[i]);\n\t\t\telse if (gfp & __GFP_ZERO)\n\t\t\t\tmemset(p[i], 0, cachep->size);\n\t\t}\n\t}\n\n\tfor (i = 0; i < size; i++) {\n\t\tuatomic_inc(&nr_allocated);\n\t\tuatomic_inc(&cachep->nr_allocated);\n\t\tuatomic_inc(&cachep->nr_tallocated);\n\t\tif (kmalloc_verbose)\n\t\t\tprintf(\"Allocating %p from slab\\n\", p[i]);\n\t}\n\n\treturn size;\n}\n\nstruct kmem_cache *\nkmem_cache_create(const char *name, unsigned int size, unsigned int align,\n\t\tunsigned int flags, void (*ctor)(void *))\n{\n\tstruct kmem_cache *ret = malloc(sizeof(*ret));\n\n\tpthread_mutex_init(&ret->lock, NULL);\n\tret->size = size;\n\tret->align = align;\n\tret->nr_objs = 0;\n\tret->nr_allocated = 0;\n\tret->nr_tallocated = 0;\n\tret->objs = NULL;\n\tret->ctor = ctor;\n\tret->non_kernel = 0;\n\treturn ret;\n}\n\n \nvoid test_kmem_cache_bulk(void)\n{\n\tint i;\n\tvoid *list[12];\n\tstatic struct kmem_cache *test_cache, *test_cache2;\n\n\t \n\ttest_cache = kmem_cache_create(\"test_cache\", 256, 0, SLAB_PANIC, NULL);\n\n\tfor (i = 0; i < 5; i++)\n\t\tlist[i] = kmem_cache_alloc(test_cache, __GFP_DIRECT_RECLAIM);\n\n\tfor (i = 0; i < 5; i++)\n\t\tkmem_cache_free(test_cache, list[i]);\n\tassert(test_cache->nr_objs == 5);\n\n\tkmem_cache_alloc_bulk(test_cache, __GFP_DIRECT_RECLAIM, 5, list);\n\tkmem_cache_free_bulk(test_cache, 5, list);\n\n\tfor (i = 0; i < 12 ; i++)\n\t\tlist[i] = kmem_cache_alloc(test_cache, __GFP_DIRECT_RECLAIM);\n\n\tfor (i = 0; i < 12; i++)\n\t\tkmem_cache_free(test_cache, list[i]);\n\n\t \n\tassert(test_cache->nr_objs == 11);\n\n\t \n\ttest_cache2 = kmem_cache_create(\"test_cache2\", 128, 128, SLAB_PANIC, NULL);\n\n\tkmem_cache_alloc_bulk(test_cache2, __GFP_DIRECT_RECLAIM, 10, list);\n\tkmem_cache_free_bulk(test_cache2, 10, list);\n\tassert(!test_cache2->nr_objs);\n\n\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}