{
  "module_name": "builtin-kmem.c",
  "hash_id": "b0ce7e61fdf6a9e8c8554f8495ee348559bb5f256d68eb70c7e7b247ca77563c",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/builtin-kmem.c",
  "human_readable_source": "\n#include \"builtin.h\"\n\n#include \"util/dso.h\"\n#include \"util/evlist.h\"\n#include \"util/evsel.h\"\n#include \"util/config.h\"\n#include \"util/map.h\"\n#include \"util/symbol.h\"\n#include \"util/thread.h\"\n#include \"util/header.h\"\n#include \"util/session.h\"\n#include \"util/tool.h\"\n#include \"util/callchain.h\"\n#include \"util/time-utils.h\"\n#include <linux/err.h>\n\n#include <subcmd/pager.h>\n#include <subcmd/parse-options.h>\n#include \"util/trace-event.h\"\n#include \"util/data.h\"\n#include \"util/cpumap.h\"\n\n#include \"util/debug.h\"\n#include \"util/string2.h\"\n#include \"util/util.h\"\n\n#include <linux/kernel.h>\n#include <linux/numa.h>\n#include <linux/rbtree.h>\n#include <linux/string.h>\n#include <linux/zalloc.h>\n#include <errno.h>\n#include <inttypes.h>\n#include <locale.h>\n#include <regex.h>\n\n#include <linux/ctype.h>\n#include <traceevent/event-parse.h>\n\nstatic int\tkmem_slab;\nstatic int\tkmem_page;\n\nstatic long\tkmem_page_size;\nstatic enum {\n\tKMEM_SLAB,\n\tKMEM_PAGE,\n} kmem_default = KMEM_SLAB;   \n\nstruct alloc_stat;\ntypedef int (*sort_fn_t)(void *, void *);\n\nstatic int\t\t\talloc_flag;\nstatic int\t\t\tcaller_flag;\n\nstatic int\t\t\talloc_lines = -1;\nstatic int\t\t\tcaller_lines = -1;\n\nstatic bool\t\t\traw_ip;\n\nstruct alloc_stat {\n\tu64\tcall_site;\n\tu64\tptr;\n\tu64\tbytes_req;\n\tu64\tbytes_alloc;\n\tu64\tlast_alloc;\n\tu32\thit;\n\tu32\tpingpong;\n\n\tshort\talloc_cpu;\n\n\tstruct rb_node node;\n};\n\nstatic struct rb_root root_alloc_stat;\nstatic struct rb_root root_alloc_sorted;\nstatic struct rb_root root_caller_stat;\nstatic struct rb_root root_caller_sorted;\n\nstatic unsigned long total_requested, total_allocated, total_freed;\nstatic unsigned long nr_allocs, nr_cross_allocs;\n\n \nstatic struct perf_time_interval ptime;\nconst char *time_str;\n\nstatic int insert_alloc_stat(unsigned long call_site, unsigned long ptr,\n\t\t\t     int bytes_req, int bytes_alloc, int cpu)\n{\n\tstruct rb_node **node = &root_alloc_stat.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct alloc_stat *data = NULL;\n\n\twhile (*node) {\n\t\tparent = *node;\n\t\tdata = rb_entry(*node, struct alloc_stat, node);\n\n\t\tif (ptr > data->ptr)\n\t\t\tnode = &(*node)->rb_right;\n\t\telse if (ptr < data->ptr)\n\t\t\tnode = &(*node)->rb_left;\n\t\telse\n\t\t\tbreak;\n\t}\n\n\tif (data && data->ptr == ptr) {\n\t\tdata->hit++;\n\t\tdata->bytes_req += bytes_req;\n\t\tdata->bytes_alloc += bytes_alloc;\n\t} else {\n\t\tdata = malloc(sizeof(*data));\n\t\tif (!data) {\n\t\t\tpr_err(\"%s: malloc failed\\n\", __func__);\n\t\t\treturn -1;\n\t\t}\n\t\tdata->ptr = ptr;\n\t\tdata->pingpong = 0;\n\t\tdata->hit = 1;\n\t\tdata->bytes_req = bytes_req;\n\t\tdata->bytes_alloc = bytes_alloc;\n\n\t\trb_link_node(&data->node, parent, node);\n\t\trb_insert_color(&data->node, &root_alloc_stat);\n\t}\n\tdata->call_site = call_site;\n\tdata->alloc_cpu = cpu;\n\tdata->last_alloc = bytes_alloc;\n\n\treturn 0;\n}\n\nstatic int insert_caller_stat(unsigned long call_site,\n\t\t\t      int bytes_req, int bytes_alloc)\n{\n\tstruct rb_node **node = &root_caller_stat.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct alloc_stat *data = NULL;\n\n\twhile (*node) {\n\t\tparent = *node;\n\t\tdata = rb_entry(*node, struct alloc_stat, node);\n\n\t\tif (call_site > data->call_site)\n\t\t\tnode = &(*node)->rb_right;\n\t\telse if (call_site < data->call_site)\n\t\t\tnode = &(*node)->rb_left;\n\t\telse\n\t\t\tbreak;\n\t}\n\n\tif (data && data->call_site == call_site) {\n\t\tdata->hit++;\n\t\tdata->bytes_req += bytes_req;\n\t\tdata->bytes_alloc += bytes_alloc;\n\t} else {\n\t\tdata = malloc(sizeof(*data));\n\t\tif (!data) {\n\t\t\tpr_err(\"%s: malloc failed\\n\", __func__);\n\t\t\treturn -1;\n\t\t}\n\t\tdata->call_site = call_site;\n\t\tdata->pingpong = 0;\n\t\tdata->hit = 1;\n\t\tdata->bytes_req = bytes_req;\n\t\tdata->bytes_alloc = bytes_alloc;\n\n\t\trb_link_node(&data->node, parent, node);\n\t\trb_insert_color(&data->node, &root_caller_stat);\n\t}\n\n\treturn 0;\n}\n\nstatic int evsel__process_alloc_event(struct evsel *evsel, struct perf_sample *sample)\n{\n\tunsigned long ptr = evsel__intval(evsel, sample, \"ptr\"),\n\t\t      call_site = evsel__intval(evsel, sample, \"call_site\");\n\tint bytes_req = evsel__intval(evsel, sample, \"bytes_req\"),\n\t    bytes_alloc = evsel__intval(evsel, sample, \"bytes_alloc\");\n\n\tif (insert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, sample->cpu) ||\n\t    insert_caller_stat(call_site, bytes_req, bytes_alloc))\n\t\treturn -1;\n\n\ttotal_requested += bytes_req;\n\ttotal_allocated += bytes_alloc;\n\n\tnr_allocs++;\n\n\t \n\tif (evsel__field(evsel, \"node\")) {\n\t\tint node1, node2;\n\n\t\tnode1 = cpu__get_node((struct perf_cpu){.cpu = sample->cpu});\n\t\tnode2 = evsel__intval(evsel, sample, \"node\");\n\n\t\t \n\t\tif ((node2 != NUMA_NO_NODE) && (node1 != node2))\n\t\t\tnr_cross_allocs++;\n\t}\n\n\treturn 0;\n}\n\nstatic int ptr_cmp(void *, void *);\nstatic int slab_callsite_cmp(void *, void *);\n\nstatic struct alloc_stat *search_alloc_stat(unsigned long ptr,\n\t\t\t\t\t    unsigned long call_site,\n\t\t\t\t\t    struct rb_root *root,\n\t\t\t\t\t    sort_fn_t sort_fn)\n{\n\tstruct rb_node *node = root->rb_node;\n\tstruct alloc_stat key = { .ptr = ptr, .call_site = call_site };\n\n\twhile (node) {\n\t\tstruct alloc_stat *data;\n\t\tint cmp;\n\n\t\tdata = rb_entry(node, struct alloc_stat, node);\n\n\t\tcmp = sort_fn(&key, data);\n\t\tif (cmp < 0)\n\t\t\tnode = node->rb_left;\n\t\telse if (cmp > 0)\n\t\t\tnode = node->rb_right;\n\t\telse\n\t\t\treturn data;\n\t}\n\treturn NULL;\n}\n\nstatic int evsel__process_free_event(struct evsel *evsel, struct perf_sample *sample)\n{\n\tunsigned long ptr = evsel__intval(evsel, sample, \"ptr\");\n\tstruct alloc_stat *s_alloc, *s_caller;\n\n\ts_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);\n\tif (!s_alloc)\n\t\treturn 0;\n\n\ttotal_freed += s_alloc->last_alloc;\n\n\tif ((short)sample->cpu != s_alloc->alloc_cpu) {\n\t\ts_alloc->pingpong++;\n\n\t\ts_caller = search_alloc_stat(0, s_alloc->call_site,\n\t\t\t\t\t     &root_caller_stat,\n\t\t\t\t\t     slab_callsite_cmp);\n\t\tif (!s_caller)\n\t\t\treturn -1;\n\t\ts_caller->pingpong++;\n\t}\n\ts_alloc->alloc_cpu = -1;\n\n\treturn 0;\n}\n\nstatic u64 total_page_alloc_bytes;\nstatic u64 total_page_free_bytes;\nstatic u64 total_page_nomatch_bytes;\nstatic u64 total_page_fail_bytes;\nstatic unsigned long nr_page_allocs;\nstatic unsigned long nr_page_frees;\nstatic unsigned long nr_page_fails;\nstatic unsigned long nr_page_nomatch;\n\nstatic bool use_pfn;\nstatic bool live_page;\nstatic struct perf_session *kmem_session;\n\n#define MAX_MIGRATE_TYPES  6\n#define MAX_PAGE_ORDER     11\n\nstatic int order_stats[MAX_PAGE_ORDER][MAX_MIGRATE_TYPES];\n\nstruct page_stat {\n\tstruct rb_node \tnode;\n\tu64 \t\tpage;\n\tu64 \t\tcallsite;\n\tint \t\torder;\n\tunsigned \tgfp_flags;\n\tunsigned \tmigrate_type;\n\tu64\t\talloc_bytes;\n\tu64 \t\tfree_bytes;\n\tint \t\tnr_alloc;\n\tint \t\tnr_free;\n};\n\nstatic struct rb_root page_live_tree;\nstatic struct rb_root page_alloc_tree;\nstatic struct rb_root page_alloc_sorted;\nstatic struct rb_root page_caller_tree;\nstatic struct rb_root page_caller_sorted;\n\nstruct alloc_func {\n\tu64 start;\n\tu64 end;\n\tchar *name;\n};\n\nstatic int nr_alloc_funcs;\nstatic struct alloc_func *alloc_func_list;\n\nstatic int funcmp(const void *a, const void *b)\n{\n\tconst struct alloc_func *fa = a;\n\tconst struct alloc_func *fb = b;\n\n\tif (fa->start > fb->start)\n\t\treturn 1;\n\telse\n\t\treturn -1;\n}\n\nstatic int callcmp(const void *a, const void *b)\n{\n\tconst struct alloc_func *fa = a;\n\tconst struct alloc_func *fb = b;\n\n\tif (fb->start <= fa->start && fa->end < fb->end)\n\t\treturn 0;\n\n\tif (fa->start > fb->start)\n\t\treturn 1;\n\telse\n\t\treturn -1;\n}\n\nstatic int build_alloc_func_list(void)\n{\n\tint ret;\n\tstruct map *kernel_map;\n\tstruct symbol *sym;\n\tstruct rb_node *node;\n\tstruct alloc_func *func;\n\tstruct machine *machine = &kmem_session->machines.host;\n\tregex_t alloc_func_regex;\n\tstatic const char pattern[] = \"^_?_?(alloc|get_free|get_zeroed)_pages?\";\n\n\tret = regcomp(&alloc_func_regex, pattern, REG_EXTENDED);\n\tif (ret) {\n\t\tchar err[BUFSIZ];\n\n\t\tregerror(ret, &alloc_func_regex, err, sizeof(err));\n\t\tpr_err(\"Invalid regex: %s\\n%s\", pattern, err);\n\t\treturn -EINVAL;\n\t}\n\n\tkernel_map = machine__kernel_map(machine);\n\tif (map__load(kernel_map) < 0) {\n\t\tpr_err(\"cannot load kernel map\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\tmap__for_each_symbol(kernel_map, sym, node) {\n\t\tif (regexec(&alloc_func_regex, sym->name, 0, NULL, 0))\n\t\t\tcontinue;\n\n\t\tfunc = realloc(alloc_func_list,\n\t\t\t       (nr_alloc_funcs + 1) * sizeof(*func));\n\t\tif (func == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tpr_debug(\"alloc func: %s\\n\", sym->name);\n\t\tfunc[nr_alloc_funcs].start = sym->start;\n\t\tfunc[nr_alloc_funcs].end   = sym->end;\n\t\tfunc[nr_alloc_funcs].name  = sym->name;\n\n\t\talloc_func_list = func;\n\t\tnr_alloc_funcs++;\n\t}\n\n\tqsort(alloc_func_list, nr_alloc_funcs, sizeof(*func), funcmp);\n\n\tregfree(&alloc_func_regex);\n\treturn 0;\n}\n\n \nstatic u64 find_callsite(struct evsel *evsel, struct perf_sample *sample)\n{\n\tstruct addr_location al;\n\tstruct machine *machine = &kmem_session->machines.host;\n\tstruct callchain_cursor_node *node;\n\tstruct callchain_cursor *cursor;\n\tu64 result = sample->ip;\n\n\taddr_location__init(&al);\n\tif (alloc_func_list == NULL) {\n\t\tif (build_alloc_func_list() < 0)\n\t\t\tgoto out;\n\t}\n\n\tal.thread = machine__findnew_thread(machine, sample->pid, sample->tid);\n\n\tcursor = get_tls_callchain_cursor();\n\tif (cursor == NULL)\n\t\tgoto out;\n\n\tsample__resolve_callchain(sample, cursor, NULL, evsel, &al, 16);\n\n\tcallchain_cursor_commit(cursor);\n\twhile (true) {\n\t\tstruct alloc_func key, *caller;\n\t\tu64 addr;\n\n\t\tnode = callchain_cursor_current(cursor);\n\t\tif (node == NULL)\n\t\t\tbreak;\n\n\t\tkey.start = key.end = node->ip;\n\t\tcaller = bsearch(&key, alloc_func_list, nr_alloc_funcs,\n\t\t\t\t sizeof(key), callcmp);\n\t\tif (!caller) {\n\t\t\t \n\t\t\tif (node->ms.map)\n\t\t\t\taddr = map__dso_unmap_ip(node->ms.map, node->ip);\n\t\t\telse\n\t\t\t\taddr = node->ip;\n\n\t\t\tresult = addr;\n\t\t\tgoto out;\n\t\t} else\n\t\t\tpr_debug3(\"skipping alloc function: %s\\n\", caller->name);\n\n\t\tcallchain_cursor_advance(cursor);\n\t}\n\n\tpr_debug2(\"unknown callsite: %\"PRIx64 \"\\n\", sample->ip);\nout:\n\taddr_location__exit(&al);\n\treturn result;\n}\n\nstruct sort_dimension {\n\tconst char\t\tname[20];\n\tsort_fn_t\t\tcmp;\n\tstruct list_head\tlist;\n};\n\nstatic LIST_HEAD(page_alloc_sort_input);\nstatic LIST_HEAD(page_caller_sort_input);\n\nstatic struct page_stat *\n__page_stat__findnew_page(struct page_stat *pstat, bool create)\n{\n\tstruct rb_node **node = &page_live_tree.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct page_stat *data;\n\n\twhile (*node) {\n\t\ts64 cmp;\n\n\t\tparent = *node;\n\t\tdata = rb_entry(*node, struct page_stat, node);\n\n\t\tcmp = data->page - pstat->page;\n\t\tif (cmp < 0)\n\t\t\tnode = &parent->rb_left;\n\t\telse if (cmp > 0)\n\t\t\tnode = &parent->rb_right;\n\t\telse\n\t\t\treturn data;\n\t}\n\n\tif (!create)\n\t\treturn NULL;\n\n\tdata = zalloc(sizeof(*data));\n\tif (data != NULL) {\n\t\tdata->page = pstat->page;\n\t\tdata->order = pstat->order;\n\t\tdata->gfp_flags = pstat->gfp_flags;\n\t\tdata->migrate_type = pstat->migrate_type;\n\n\t\trb_link_node(&data->node, parent, node);\n\t\trb_insert_color(&data->node, &page_live_tree);\n\t}\n\n\treturn data;\n}\n\nstatic struct page_stat *page_stat__find_page(struct page_stat *pstat)\n{\n\treturn __page_stat__findnew_page(pstat, false);\n}\n\nstatic struct page_stat *page_stat__findnew_page(struct page_stat *pstat)\n{\n\treturn __page_stat__findnew_page(pstat, true);\n}\n\nstatic struct page_stat *\n__page_stat__findnew_alloc(struct page_stat *pstat, bool create)\n{\n\tstruct rb_node **node = &page_alloc_tree.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct page_stat *data;\n\tstruct sort_dimension *sort;\n\n\twhile (*node) {\n\t\tint cmp = 0;\n\n\t\tparent = *node;\n\t\tdata = rb_entry(*node, struct page_stat, node);\n\n\t\tlist_for_each_entry(sort, &page_alloc_sort_input, list) {\n\t\t\tcmp = sort->cmp(pstat, data);\n\t\t\tif (cmp)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (cmp < 0)\n\t\t\tnode = &parent->rb_left;\n\t\telse if (cmp > 0)\n\t\t\tnode = &parent->rb_right;\n\t\telse\n\t\t\treturn data;\n\t}\n\n\tif (!create)\n\t\treturn NULL;\n\n\tdata = zalloc(sizeof(*data));\n\tif (data != NULL) {\n\t\tdata->page = pstat->page;\n\t\tdata->order = pstat->order;\n\t\tdata->gfp_flags = pstat->gfp_flags;\n\t\tdata->migrate_type = pstat->migrate_type;\n\n\t\trb_link_node(&data->node, parent, node);\n\t\trb_insert_color(&data->node, &page_alloc_tree);\n\t}\n\n\treturn data;\n}\n\nstatic struct page_stat *page_stat__find_alloc(struct page_stat *pstat)\n{\n\treturn __page_stat__findnew_alloc(pstat, false);\n}\n\nstatic struct page_stat *page_stat__findnew_alloc(struct page_stat *pstat)\n{\n\treturn __page_stat__findnew_alloc(pstat, true);\n}\n\nstatic struct page_stat *\n__page_stat__findnew_caller(struct page_stat *pstat, bool create)\n{\n\tstruct rb_node **node = &page_caller_tree.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct page_stat *data;\n\tstruct sort_dimension *sort;\n\n\twhile (*node) {\n\t\tint cmp = 0;\n\n\t\tparent = *node;\n\t\tdata = rb_entry(*node, struct page_stat, node);\n\n\t\tlist_for_each_entry(sort, &page_caller_sort_input, list) {\n\t\t\tcmp = sort->cmp(pstat, data);\n\t\t\tif (cmp)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (cmp < 0)\n\t\t\tnode = &parent->rb_left;\n\t\telse if (cmp > 0)\n\t\t\tnode = &parent->rb_right;\n\t\telse\n\t\t\treturn data;\n\t}\n\n\tif (!create)\n\t\treturn NULL;\n\n\tdata = zalloc(sizeof(*data));\n\tif (data != NULL) {\n\t\tdata->callsite = pstat->callsite;\n\t\tdata->order = pstat->order;\n\t\tdata->gfp_flags = pstat->gfp_flags;\n\t\tdata->migrate_type = pstat->migrate_type;\n\n\t\trb_link_node(&data->node, parent, node);\n\t\trb_insert_color(&data->node, &page_caller_tree);\n\t}\n\n\treturn data;\n}\n\nstatic struct page_stat *page_stat__find_caller(struct page_stat *pstat)\n{\n\treturn __page_stat__findnew_caller(pstat, false);\n}\n\nstatic struct page_stat *page_stat__findnew_caller(struct page_stat *pstat)\n{\n\treturn __page_stat__findnew_caller(pstat, true);\n}\n\nstatic bool valid_page(u64 pfn_or_page)\n{\n\tif (use_pfn && pfn_or_page == -1UL)\n\t\treturn false;\n\tif (!use_pfn && pfn_or_page == 0)\n\t\treturn false;\n\treturn true;\n}\n\nstruct gfp_flag {\n\tunsigned int flags;\n\tchar *compact_str;\n\tchar *human_readable;\n};\n\nstatic struct gfp_flag *gfps;\nstatic int nr_gfps;\n\nstatic int gfpcmp(const void *a, const void *b)\n{\n\tconst struct gfp_flag *fa = a;\n\tconst struct gfp_flag *fb = b;\n\n\treturn fa->flags - fb->flags;\n}\n\n \nstatic const struct {\n\tconst char *original;\n\tconst char *compact;\n} gfp_compact_table[] = {\n\t{ \"GFP_TRANSHUGE\",\t\t\"THP\" },\n\t{ \"GFP_TRANSHUGE_LIGHT\",\t\"THL\" },\n\t{ \"GFP_HIGHUSER_MOVABLE\",\t\"HUM\" },\n\t{ \"GFP_HIGHUSER\",\t\t\"HU\" },\n\t{ \"GFP_USER\",\t\t\t\"U\" },\n\t{ \"GFP_KERNEL_ACCOUNT\",\t\t\"KAC\" },\n\t{ \"GFP_KERNEL\",\t\t\t\"K\" },\n\t{ \"GFP_NOFS\",\t\t\t\"NF\" },\n\t{ \"GFP_ATOMIC\",\t\t\t\"A\" },\n\t{ \"GFP_NOIO\",\t\t\t\"NI\" },\n\t{ \"GFP_NOWAIT\",\t\t\t\"NW\" },\n\t{ \"GFP_DMA\",\t\t\t\"D\" },\n\t{ \"__GFP_HIGHMEM\",\t\t\"HM\" },\n\t{ \"GFP_DMA32\",\t\t\t\"D32\" },\n\t{ \"__GFP_HIGH\",\t\t\t\"H\" },\n\t{ \"__GFP_IO\",\t\t\t\"I\" },\n\t{ \"__GFP_FS\",\t\t\t\"F\" },\n\t{ \"__GFP_NOWARN\",\t\t\"NWR\" },\n\t{ \"__GFP_RETRY_MAYFAIL\",\t\"R\" },\n\t{ \"__GFP_NOFAIL\",\t\t\"NF\" },\n\t{ \"__GFP_NORETRY\",\t\t\"NR\" },\n\t{ \"__GFP_COMP\",\t\t\t\"C\" },\n\t{ \"__GFP_ZERO\",\t\t\t\"Z\" },\n\t{ \"__GFP_NOMEMALLOC\",\t\t\"NMA\" },\n\t{ \"__GFP_MEMALLOC\",\t\t\"MA\" },\n\t{ \"__GFP_HARDWALL\",\t\t\"HW\" },\n\t{ \"__GFP_THISNODE\",\t\t\"TN\" },\n\t{ \"__GFP_RECLAIMABLE\",\t\t\"RC\" },\n\t{ \"__GFP_MOVABLE\",\t\t\"M\" },\n\t{ \"__GFP_ACCOUNT\",\t\t\"AC\" },\n\t{ \"__GFP_WRITE\",\t\t\"WR\" },\n\t{ \"__GFP_RECLAIM\",\t\t\"R\" },\n\t{ \"__GFP_DIRECT_RECLAIM\",\t\"DR\" },\n\t{ \"__GFP_KSWAPD_RECLAIM\",\t\"KR\" },\n};\n\nstatic size_t max_gfp_len;\n\nstatic char *compact_gfp_flags(char *gfp_flags)\n{\n\tchar *orig_flags = strdup(gfp_flags);\n\tchar *new_flags = NULL;\n\tchar *str, *pos = NULL;\n\tsize_t len = 0;\n\n\tif (orig_flags == NULL)\n\t\treturn NULL;\n\n\tstr = strtok_r(orig_flags, \"|\", &pos);\n\twhile (str) {\n\t\tsize_t i;\n\t\tchar *new;\n\t\tconst char *cpt;\n\n\t\tfor (i = 0; i < ARRAY_SIZE(gfp_compact_table); i++) {\n\t\t\tif (strcmp(gfp_compact_table[i].original, str))\n\t\t\t\tcontinue;\n\n\t\t\tcpt = gfp_compact_table[i].compact;\n\t\t\tnew = realloc(new_flags, len + strlen(cpt) + 2);\n\t\t\tif (new == NULL) {\n\t\t\t\tfree(new_flags);\n\t\t\t\tfree(orig_flags);\n\t\t\t\treturn NULL;\n\t\t\t}\n\n\t\t\tnew_flags = new;\n\n\t\t\tif (!len) {\n\t\t\t\tstrcpy(new_flags, cpt);\n\t\t\t} else {\n\t\t\t\tstrcat(new_flags, \"|\");\n\t\t\t\tstrcat(new_flags, cpt);\n\t\t\t\tlen++;\n\t\t\t}\n\n\t\t\tlen += strlen(cpt);\n\t\t}\n\n\t\tstr = strtok_r(NULL, \"|\", &pos);\n\t}\n\n\tif (max_gfp_len < len)\n\t\tmax_gfp_len = len;\n\n\tfree(orig_flags);\n\treturn new_flags;\n}\n\nstatic char *compact_gfp_string(unsigned long gfp_flags)\n{\n\tstruct gfp_flag key = {\n\t\t.flags = gfp_flags,\n\t};\n\tstruct gfp_flag *gfp;\n\n\tgfp = bsearch(&key, gfps, nr_gfps, sizeof(*gfps), gfpcmp);\n\tif (gfp)\n\t\treturn gfp->compact_str;\n\n\treturn NULL;\n}\n\nstatic int parse_gfp_flags(struct evsel *evsel, struct perf_sample *sample,\n\t\t\t   unsigned int gfp_flags)\n{\n\tstruct tep_record record = {\n\t\t.cpu = sample->cpu,\n\t\t.data = sample->raw_data,\n\t\t.size = sample->raw_size,\n\t};\n\tstruct trace_seq seq;\n\tchar *str, *pos = NULL;\n\n\tif (nr_gfps) {\n\t\tstruct gfp_flag key = {\n\t\t\t.flags = gfp_flags,\n\t\t};\n\n\t\tif (bsearch(&key, gfps, nr_gfps, sizeof(*gfps), gfpcmp))\n\t\t\treturn 0;\n\t}\n\n\ttrace_seq_init(&seq);\n\ttep_print_event(evsel->tp_format->tep,\n\t\t\t&seq, &record, \"%s\", TEP_PRINT_INFO);\n\n\tstr = strtok_r(seq.buffer, \" \", &pos);\n\twhile (str) {\n\t\tif (!strncmp(str, \"gfp_flags=\", 10)) {\n\t\t\tstruct gfp_flag *new;\n\n\t\t\tnew = realloc(gfps, (nr_gfps + 1) * sizeof(*gfps));\n\t\t\tif (new == NULL)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tgfps = new;\n\t\t\tnew += nr_gfps++;\n\n\t\t\tnew->flags = gfp_flags;\n\t\t\tnew->human_readable = strdup(str + 10);\n\t\t\tnew->compact_str = compact_gfp_flags(str + 10);\n\t\t\tif (!new->human_readable || !new->compact_str)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tqsort(gfps, nr_gfps, sizeof(*gfps), gfpcmp);\n\t\t}\n\n\t\tstr = strtok_r(NULL, \" \", &pos);\n\t}\n\n\ttrace_seq_destroy(&seq);\n\treturn 0;\n}\n\nstatic int evsel__process_page_alloc_event(struct evsel *evsel, struct perf_sample *sample)\n{\n\tu64 page;\n\tunsigned int order = evsel__intval(evsel, sample, \"order\");\n\tunsigned int gfp_flags = evsel__intval(evsel, sample, \"gfp_flags\");\n\tunsigned int migrate_type = evsel__intval(evsel, sample,\n\t\t\t\t\t\t       \"migratetype\");\n\tu64 bytes = kmem_page_size << order;\n\tu64 callsite;\n\tstruct page_stat *pstat;\n\tstruct page_stat this = {\n\t\t.order = order,\n\t\t.gfp_flags = gfp_flags,\n\t\t.migrate_type = migrate_type,\n\t};\n\n\tif (use_pfn)\n\t\tpage = evsel__intval(evsel, sample, \"pfn\");\n\telse\n\t\tpage = evsel__intval(evsel, sample, \"page\");\n\n\tnr_page_allocs++;\n\ttotal_page_alloc_bytes += bytes;\n\n\tif (!valid_page(page)) {\n\t\tnr_page_fails++;\n\t\ttotal_page_fail_bytes += bytes;\n\n\t\treturn 0;\n\t}\n\n\tif (parse_gfp_flags(evsel, sample, gfp_flags) < 0)\n\t\treturn -1;\n\n\tcallsite = find_callsite(evsel, sample);\n\n\t \n\tthis.page = page;\n\tpstat = page_stat__findnew_page(&this);\n\tif (pstat == NULL)\n\t\treturn -ENOMEM;\n\n\tpstat->nr_alloc++;\n\tpstat->alloc_bytes += bytes;\n\tpstat->callsite = callsite;\n\n\tif (!live_page) {\n\t\tpstat = page_stat__findnew_alloc(&this);\n\t\tif (pstat == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tpstat->nr_alloc++;\n\t\tpstat->alloc_bytes += bytes;\n\t\tpstat->callsite = callsite;\n\t}\n\n\tthis.callsite = callsite;\n\tpstat = page_stat__findnew_caller(&this);\n\tif (pstat == NULL)\n\t\treturn -ENOMEM;\n\n\tpstat->nr_alloc++;\n\tpstat->alloc_bytes += bytes;\n\n\torder_stats[order][migrate_type]++;\n\n\treturn 0;\n}\n\nstatic int evsel__process_page_free_event(struct evsel *evsel, struct perf_sample *sample)\n{\n\tu64 page;\n\tunsigned int order = evsel__intval(evsel, sample, \"order\");\n\tu64 bytes = kmem_page_size << order;\n\tstruct page_stat *pstat;\n\tstruct page_stat this = {\n\t\t.order = order,\n\t};\n\n\tif (use_pfn)\n\t\tpage = evsel__intval(evsel, sample, \"pfn\");\n\telse\n\t\tpage = evsel__intval(evsel, sample, \"page\");\n\n\tnr_page_frees++;\n\ttotal_page_free_bytes += bytes;\n\n\tthis.page = page;\n\tpstat = page_stat__find_page(&this);\n\tif (pstat == NULL) {\n\t\tpr_debug2(\"missing free at page %\"PRIx64\" (order: %d)\\n\",\n\t\t\t  page, order);\n\n\t\tnr_page_nomatch++;\n\t\ttotal_page_nomatch_bytes += bytes;\n\n\t\treturn 0;\n\t}\n\n\tthis.gfp_flags = pstat->gfp_flags;\n\tthis.migrate_type = pstat->migrate_type;\n\tthis.callsite = pstat->callsite;\n\n\trb_erase(&pstat->node, &page_live_tree);\n\tfree(pstat);\n\n\tif (live_page) {\n\t\torder_stats[this.order][this.migrate_type]--;\n\t} else {\n\t\tpstat = page_stat__find_alloc(&this);\n\t\tif (pstat == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tpstat->nr_free++;\n\t\tpstat->free_bytes += bytes;\n\t}\n\n\tpstat = page_stat__find_caller(&this);\n\tif (pstat == NULL)\n\t\treturn -ENOENT;\n\n\tpstat->nr_free++;\n\tpstat->free_bytes += bytes;\n\n\tif (live_page) {\n\t\tpstat->nr_alloc--;\n\t\tpstat->alloc_bytes -= bytes;\n\n\t\tif (pstat->nr_alloc == 0) {\n\t\t\trb_erase(&pstat->node, &page_caller_tree);\n\t\t\tfree(pstat);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic bool perf_kmem__skip_sample(struct perf_sample *sample)\n{\n\t \n\tif (perf_time__skip_sample(&ptime, sample->time))\n\t\treturn true;\n\n\treturn false;\n}\n\ntypedef int (*tracepoint_handler)(struct evsel *evsel,\n\t\t\t\t  struct perf_sample *sample);\n\nstatic int process_sample_event(struct perf_tool *tool __maybe_unused,\n\t\t\t\tunion perf_event *event,\n\t\t\t\tstruct perf_sample *sample,\n\t\t\t\tstruct evsel *evsel,\n\t\t\t\tstruct machine *machine)\n{\n\tint err = 0;\n\tstruct thread *thread = machine__findnew_thread(machine, sample->pid,\n\t\t\t\t\t\t\tsample->tid);\n\n\tif (thread == NULL) {\n\t\tpr_debug(\"problem processing %d event, skipping it.\\n\",\n\t\t\t event->header.type);\n\t\treturn -1;\n\t}\n\n\tif (perf_kmem__skip_sample(sample))\n\t\treturn 0;\n\n\tdump_printf(\" ... thread: %s:%d\\n\", thread__comm_str(thread), thread__tid(thread));\n\n\tif (evsel->handler != NULL) {\n\t\ttracepoint_handler f = evsel->handler;\n\t\terr = f(evsel, sample);\n\t}\n\n\tthread__put(thread);\n\n\treturn err;\n}\n\nstatic struct perf_tool perf_kmem = {\n\t.sample\t\t = process_sample_event,\n\t.comm\t\t = perf_event__process_comm,\n\t.mmap\t\t = perf_event__process_mmap,\n\t.mmap2\t\t = perf_event__process_mmap2,\n\t.namespaces\t = perf_event__process_namespaces,\n\t.ordered_events\t = true,\n};\n\nstatic double fragmentation(unsigned long n_req, unsigned long n_alloc)\n{\n\tif (n_alloc == 0)\n\t\treturn 0.0;\n\telse\n\t\treturn 100.0 - (100.0 * n_req / n_alloc);\n}\n\nstatic void __print_slab_result(struct rb_root *root,\n\t\t\t\tstruct perf_session *session,\n\t\t\t\tint n_lines, int is_caller)\n{\n\tstruct rb_node *next;\n\tstruct machine *machine = &session->machines.host;\n\n\tprintf(\"%.105s\\n\", graph_dotted_line);\n\tprintf(\" %-34s |\",  is_caller ? \"Callsite\": \"Alloc Ptr\");\n\tprintf(\" Total_alloc/Per | Total_req/Per   | Hit      | Ping-pong | Frag\\n\");\n\tprintf(\"%.105s\\n\", graph_dotted_line);\n\n\tnext = rb_first(root);\n\n\twhile (next && n_lines--) {\n\t\tstruct alloc_stat *data = rb_entry(next, struct alloc_stat,\n\t\t\t\t\t\t   node);\n\t\tstruct symbol *sym = NULL;\n\t\tstruct map *map;\n\t\tchar buf[BUFSIZ];\n\t\tu64 addr;\n\n\t\tif (is_caller) {\n\t\t\taddr = data->call_site;\n\t\t\tif (!raw_ip)\n\t\t\t\tsym = machine__find_kernel_symbol(machine, addr, &map);\n\t\t} else\n\t\t\taddr = data->ptr;\n\n\t\tif (sym != NULL)\n\t\t\tsnprintf(buf, sizeof(buf), \"%s+%\" PRIx64 \"\", sym->name,\n\t\t\t\t addr - map__unmap_ip(map, sym->start));\n\t\telse\n\t\t\tsnprintf(buf, sizeof(buf), \"%#\" PRIx64 \"\", addr);\n\t\tprintf(\" %-34s |\", buf);\n\n\t\tprintf(\" %9llu/%-5lu | %9llu/%-5lu | %8lu | %9lu | %6.3f%%\\n\",\n\t\t       (unsigned long long)data->bytes_alloc,\n\t\t       (unsigned long)data->bytes_alloc / data->hit,\n\t\t       (unsigned long long)data->bytes_req,\n\t\t       (unsigned long)data->bytes_req / data->hit,\n\t\t       (unsigned long)data->hit,\n\t\t       (unsigned long)data->pingpong,\n\t\t       fragmentation(data->bytes_req, data->bytes_alloc));\n\n\t\tnext = rb_next(next);\n\t}\n\n\tif (n_lines == -1)\n\t\tprintf(\" ...                                | ...             | ...             | ...      | ...       | ...   \\n\");\n\n\tprintf(\"%.105s\\n\", graph_dotted_line);\n}\n\nstatic const char * const migrate_type_str[] = {\n\t\"UNMOVABL\",\n\t\"RECLAIM\",\n\t\"MOVABLE\",\n\t\"RESERVED\",\n\t\"CMA/ISLT\",\n\t\"UNKNOWN\",\n};\n\nstatic void __print_page_alloc_result(struct perf_session *session, int n_lines)\n{\n\tstruct rb_node *next = rb_first(&page_alloc_sorted);\n\tstruct machine *machine = &session->machines.host;\n\tconst char *format;\n\tint gfp_len = max(strlen(\"GFP flags\"), max_gfp_len);\n\n\tprintf(\"\\n%.105s\\n\", graph_dotted_line);\n\tprintf(\" %-16s | %5s alloc (KB) | Hits      | Order | Mig.type | %-*s | Callsite\\n\",\n\t       use_pfn ? \"PFN\" : \"Page\", live_page ? \"Live\" : \"Total\",\n\t       gfp_len, \"GFP flags\");\n\tprintf(\"%.105s\\n\", graph_dotted_line);\n\n\tif (use_pfn)\n\t\tformat = \" %16llu | %'16llu | %'9d | %5d | %8s | %-*s | %s\\n\";\n\telse\n\t\tformat = \" %016llx | %'16llu | %'9d | %5d | %8s | %-*s | %s\\n\";\n\n\twhile (next && n_lines--) {\n\t\tstruct page_stat *data;\n\t\tstruct symbol *sym;\n\t\tstruct map *map;\n\t\tchar buf[32];\n\t\tchar *caller = buf;\n\n\t\tdata = rb_entry(next, struct page_stat, node);\n\t\tsym = machine__find_kernel_symbol(machine, data->callsite, &map);\n\t\tif (sym)\n\t\t\tcaller = sym->name;\n\t\telse\n\t\t\tscnprintf(buf, sizeof(buf), \"%\"PRIx64, data->callsite);\n\n\t\tprintf(format, (unsigned long long)data->page,\n\t\t       (unsigned long long)data->alloc_bytes / 1024,\n\t\t       data->nr_alloc, data->order,\n\t\t       migrate_type_str[data->migrate_type],\n\t\t       gfp_len, compact_gfp_string(data->gfp_flags), caller);\n\n\t\tnext = rb_next(next);\n\t}\n\n\tif (n_lines == -1) {\n\t\tprintf(\" ...              | ...              | ...       | ...   | ...      | %-*s | ...\\n\",\n\t\t       gfp_len, \"...\");\n\t}\n\n\tprintf(\"%.105s\\n\", graph_dotted_line);\n}\n\nstatic void __print_page_caller_result(struct perf_session *session, int n_lines)\n{\n\tstruct rb_node *next = rb_first(&page_caller_sorted);\n\tstruct machine *machine = &session->machines.host;\n\tint gfp_len = max(strlen(\"GFP flags\"), max_gfp_len);\n\n\tprintf(\"\\n%.105s\\n\", graph_dotted_line);\n\tprintf(\" %5s alloc (KB) | Hits      | Order | Mig.type | %-*s | Callsite\\n\",\n\t       live_page ? \"Live\" : \"Total\", gfp_len, \"GFP flags\");\n\tprintf(\"%.105s\\n\", graph_dotted_line);\n\n\twhile (next && n_lines--) {\n\t\tstruct page_stat *data;\n\t\tstruct symbol *sym;\n\t\tstruct map *map;\n\t\tchar buf[32];\n\t\tchar *caller = buf;\n\n\t\tdata = rb_entry(next, struct page_stat, node);\n\t\tsym = machine__find_kernel_symbol(machine, data->callsite, &map);\n\t\tif (sym)\n\t\t\tcaller = sym->name;\n\t\telse\n\t\t\tscnprintf(buf, sizeof(buf), \"%\"PRIx64, data->callsite);\n\n\t\tprintf(\" %'16llu | %'9d | %5d | %8s | %-*s | %s\\n\",\n\t\t       (unsigned long long)data->alloc_bytes / 1024,\n\t\t       data->nr_alloc, data->order,\n\t\t       migrate_type_str[data->migrate_type],\n\t\t       gfp_len, compact_gfp_string(data->gfp_flags), caller);\n\n\t\tnext = rb_next(next);\n\t}\n\n\tif (n_lines == -1) {\n\t\tprintf(\" ...              | ...       | ...   | ...      | %-*s | ...\\n\",\n\t\t       gfp_len, \"...\");\n\t}\n\n\tprintf(\"%.105s\\n\", graph_dotted_line);\n}\n\nstatic void print_gfp_flags(void)\n{\n\tint i;\n\n\tprintf(\"#\\n\");\n\tprintf(\"# GFP flags\\n\");\n\tprintf(\"# ---------\\n\");\n\tfor (i = 0; i < nr_gfps; i++) {\n\t\tprintf(\"# %08x: %*s: %s\\n\", gfps[i].flags,\n\t\t       (int) max_gfp_len, gfps[i].compact_str,\n\t\t       gfps[i].human_readable);\n\t}\n}\n\nstatic void print_slab_summary(void)\n{\n\tprintf(\"\\nSUMMARY (SLAB allocator)\");\n\tprintf(\"\\n========================\\n\");\n\tprintf(\"Total bytes requested: %'lu\\n\", total_requested);\n\tprintf(\"Total bytes allocated: %'lu\\n\", total_allocated);\n\tprintf(\"Total bytes freed:     %'lu\\n\", total_freed);\n\tif (total_allocated > total_freed) {\n\t\tprintf(\"Net total bytes allocated: %'lu\\n\",\n\t\ttotal_allocated - total_freed);\n\t}\n\tprintf(\"Total bytes wasted on internal fragmentation: %'lu\\n\",\n\t       total_allocated - total_requested);\n\tprintf(\"Internal fragmentation: %f%%\\n\",\n\t       fragmentation(total_requested, total_allocated));\n\tprintf(\"Cross CPU allocations: %'lu/%'lu\\n\", nr_cross_allocs, nr_allocs);\n}\n\nstatic void print_page_summary(void)\n{\n\tint o, m;\n\tu64 nr_alloc_freed = nr_page_frees - nr_page_nomatch;\n\tu64 total_alloc_freed_bytes = total_page_free_bytes - total_page_nomatch_bytes;\n\n\tprintf(\"\\nSUMMARY (page allocator)\");\n\tprintf(\"\\n========================\\n\");\n\tprintf(\"%-30s: %'16lu   [ %'16\"PRIu64\" KB ]\\n\", \"Total allocation requests\",\n\t       nr_page_allocs, total_page_alloc_bytes / 1024);\n\tprintf(\"%-30s: %'16lu   [ %'16\"PRIu64\" KB ]\\n\", \"Total free requests\",\n\t       nr_page_frees, total_page_free_bytes / 1024);\n\tprintf(\"\\n\");\n\n\tprintf(\"%-30s: %'16\"PRIu64\"   [ %'16\"PRIu64\" KB ]\\n\", \"Total alloc+freed requests\",\n\t       nr_alloc_freed, (total_alloc_freed_bytes) / 1024);\n\tprintf(\"%-30s: %'16\"PRIu64\"   [ %'16\"PRIu64\" KB ]\\n\", \"Total alloc-only requests\",\n\t       nr_page_allocs - nr_alloc_freed,\n\t       (total_page_alloc_bytes - total_alloc_freed_bytes) / 1024);\n\tprintf(\"%-30s: %'16lu   [ %'16\"PRIu64\" KB ]\\n\", \"Total free-only requests\",\n\t       nr_page_nomatch, total_page_nomatch_bytes / 1024);\n\tprintf(\"\\n\");\n\n\tprintf(\"%-30s: %'16lu   [ %'16\"PRIu64\" KB ]\\n\", \"Total allocation failures\",\n\t       nr_page_fails, total_page_fail_bytes / 1024);\n\tprintf(\"\\n\");\n\n\tprintf(\"%5s  %12s  %12s  %12s  %12s  %12s\\n\", \"Order\",  \"Unmovable\",\n\t       \"Reclaimable\", \"Movable\", \"Reserved\", \"CMA/Isolated\");\n\tprintf(\"%.5s  %.12s  %.12s  %.12s  %.12s  %.12s\\n\", graph_dotted_line,\n\t       graph_dotted_line, graph_dotted_line, graph_dotted_line,\n\t       graph_dotted_line, graph_dotted_line);\n\n\tfor (o = 0; o < MAX_PAGE_ORDER; o++) {\n\t\tprintf(\"%5d\", o);\n\t\tfor (m = 0; m < MAX_MIGRATE_TYPES - 1; m++) {\n\t\t\tif (order_stats[o][m])\n\t\t\t\tprintf(\"  %'12d\", order_stats[o][m]);\n\t\t\telse\n\t\t\t\tprintf(\"  %12c\", '.');\n\t\t}\n\t\tprintf(\"\\n\");\n\t}\n}\n\nstatic void print_slab_result(struct perf_session *session)\n{\n\tif (caller_flag)\n\t\t__print_slab_result(&root_caller_sorted, session, caller_lines, 1);\n\tif (alloc_flag)\n\t\t__print_slab_result(&root_alloc_sorted, session, alloc_lines, 0);\n\tprint_slab_summary();\n}\n\nstatic void print_page_result(struct perf_session *session)\n{\n\tif (caller_flag || alloc_flag)\n\t\tprint_gfp_flags();\n\tif (caller_flag)\n\t\t__print_page_caller_result(session, caller_lines);\n\tif (alloc_flag)\n\t\t__print_page_alloc_result(session, alloc_lines);\n\tprint_page_summary();\n}\n\nstatic void print_result(struct perf_session *session)\n{\n\tif (kmem_slab)\n\t\tprint_slab_result(session);\n\tif (kmem_page)\n\t\tprint_page_result(session);\n}\n\nstatic LIST_HEAD(slab_caller_sort);\nstatic LIST_HEAD(slab_alloc_sort);\nstatic LIST_HEAD(page_caller_sort);\nstatic LIST_HEAD(page_alloc_sort);\n\nstatic void sort_slab_insert(struct rb_root *root, struct alloc_stat *data,\n\t\t\t     struct list_head *sort_list)\n{\n\tstruct rb_node **new = &(root->rb_node);\n\tstruct rb_node *parent = NULL;\n\tstruct sort_dimension *sort;\n\n\twhile (*new) {\n\t\tstruct alloc_stat *this;\n\t\tint cmp = 0;\n\n\t\tthis = rb_entry(*new, struct alloc_stat, node);\n\t\tparent = *new;\n\n\t\tlist_for_each_entry(sort, sort_list, list) {\n\t\t\tcmp = sort->cmp(data, this);\n\t\t\tif (cmp)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (cmp > 0)\n\t\t\tnew = &((*new)->rb_left);\n\t\telse\n\t\t\tnew = &((*new)->rb_right);\n\t}\n\n\trb_link_node(&data->node, parent, new);\n\trb_insert_color(&data->node, root);\n}\n\nstatic void __sort_slab_result(struct rb_root *root, struct rb_root *root_sorted,\n\t\t\t       struct list_head *sort_list)\n{\n\tstruct rb_node *node;\n\tstruct alloc_stat *data;\n\n\tfor (;;) {\n\t\tnode = rb_first(root);\n\t\tif (!node)\n\t\t\tbreak;\n\n\t\trb_erase(node, root);\n\t\tdata = rb_entry(node, struct alloc_stat, node);\n\t\tsort_slab_insert(root_sorted, data, sort_list);\n\t}\n}\n\nstatic void sort_page_insert(struct rb_root *root, struct page_stat *data,\n\t\t\t     struct list_head *sort_list)\n{\n\tstruct rb_node **new = &root->rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct sort_dimension *sort;\n\n\twhile (*new) {\n\t\tstruct page_stat *this;\n\t\tint cmp = 0;\n\n\t\tthis = rb_entry(*new, struct page_stat, node);\n\t\tparent = *new;\n\n\t\tlist_for_each_entry(sort, sort_list, list) {\n\t\t\tcmp = sort->cmp(data, this);\n\t\t\tif (cmp)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (cmp > 0)\n\t\t\tnew = &parent->rb_left;\n\t\telse\n\t\t\tnew = &parent->rb_right;\n\t}\n\n\trb_link_node(&data->node, parent, new);\n\trb_insert_color(&data->node, root);\n}\n\nstatic void __sort_page_result(struct rb_root *root, struct rb_root *root_sorted,\n\t\t\t       struct list_head *sort_list)\n{\n\tstruct rb_node *node;\n\tstruct page_stat *data;\n\n\tfor (;;) {\n\t\tnode = rb_first(root);\n\t\tif (!node)\n\t\t\tbreak;\n\n\t\trb_erase(node, root);\n\t\tdata = rb_entry(node, struct page_stat, node);\n\t\tsort_page_insert(root_sorted, data, sort_list);\n\t}\n}\n\nstatic void sort_result(void)\n{\n\tif (kmem_slab) {\n\t\t__sort_slab_result(&root_alloc_stat, &root_alloc_sorted,\n\t\t\t\t   &slab_alloc_sort);\n\t\t__sort_slab_result(&root_caller_stat, &root_caller_sorted,\n\t\t\t\t   &slab_caller_sort);\n\t}\n\tif (kmem_page) {\n\t\tif (live_page)\n\t\t\t__sort_page_result(&page_live_tree, &page_alloc_sorted,\n\t\t\t\t\t   &page_alloc_sort);\n\t\telse\n\t\t\t__sort_page_result(&page_alloc_tree, &page_alloc_sorted,\n\t\t\t\t\t   &page_alloc_sort);\n\n\t\t__sort_page_result(&page_caller_tree, &page_caller_sorted,\n\t\t\t\t   &page_caller_sort);\n\t}\n}\n\nstatic int __cmd_kmem(struct perf_session *session)\n{\n\tint err = -EINVAL;\n\tstruct evsel *evsel;\n\tconst struct evsel_str_handler kmem_tracepoints[] = {\n\t\t \n\t\t{ \"kmem:kmalloc\",\t\tevsel__process_alloc_event, },\n\t\t{ \"kmem:kmem_cache_alloc\",\tevsel__process_alloc_event, },\n\t\t{ \"kmem:kmalloc_node\",\t\tevsel__process_alloc_event, },\n\t\t{ \"kmem:kmem_cache_alloc_node\", evsel__process_alloc_event, },\n\t\t{ \"kmem:kfree\",\t\t\tevsel__process_free_event, },\n\t\t{ \"kmem:kmem_cache_free\",\tevsel__process_free_event, },\n\t\t \n\t\t{ \"kmem:mm_page_alloc\",\t\tevsel__process_page_alloc_event, },\n\t\t{ \"kmem:mm_page_free\",\t\tevsel__process_page_free_event, },\n\t};\n\n\tif (!perf_session__has_traces(session, \"kmem record\"))\n\t\tgoto out;\n\n\tif (perf_session__set_tracepoints_handlers(session, kmem_tracepoints)) {\n\t\tpr_err(\"Initializing perf session tracepoint handlers failed\\n\");\n\t\tgoto out;\n\t}\n\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tif (!strcmp(evsel__name(evsel), \"kmem:mm_page_alloc\") &&\n\t\t    evsel__field(evsel, \"pfn\")) {\n\t\t\tuse_pfn = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tsetup_pager();\n\terr = perf_session__process_events(session);\n\tif (err != 0) {\n\t\tpr_err(\"error during process events: %d\\n\", err);\n\t\tgoto out;\n\t}\n\tsort_result();\n\tprint_result(session);\nout:\n\treturn err;\n}\n\n \nstatic int ptr_cmp(void *a, void *b)\n{\n\tstruct alloc_stat *l = a;\n\tstruct alloc_stat *r = b;\n\n\tif (l->ptr < r->ptr)\n\t\treturn -1;\n\telse if (l->ptr > r->ptr)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension ptr_sort_dimension = {\n\t.name\t= \"ptr\",\n\t.cmp\t= ptr_cmp,\n};\n\nstatic int slab_callsite_cmp(void *a, void *b)\n{\n\tstruct alloc_stat *l = a;\n\tstruct alloc_stat *r = b;\n\n\tif (l->call_site < r->call_site)\n\t\treturn -1;\n\telse if (l->call_site > r->call_site)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension callsite_sort_dimension = {\n\t.name\t= \"callsite\",\n\t.cmp\t= slab_callsite_cmp,\n};\n\nstatic int hit_cmp(void *a, void *b)\n{\n\tstruct alloc_stat *l = a;\n\tstruct alloc_stat *r = b;\n\n\tif (l->hit < r->hit)\n\t\treturn -1;\n\telse if (l->hit > r->hit)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension hit_sort_dimension = {\n\t.name\t= \"hit\",\n\t.cmp\t= hit_cmp,\n};\n\nstatic int bytes_cmp(void *a, void *b)\n{\n\tstruct alloc_stat *l = a;\n\tstruct alloc_stat *r = b;\n\n\tif (l->bytes_alloc < r->bytes_alloc)\n\t\treturn -1;\n\telse if (l->bytes_alloc > r->bytes_alloc)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension bytes_sort_dimension = {\n\t.name\t= \"bytes\",\n\t.cmp\t= bytes_cmp,\n};\n\nstatic int frag_cmp(void *a, void *b)\n{\n\tdouble x, y;\n\tstruct alloc_stat *l = a;\n\tstruct alloc_stat *r = b;\n\n\tx = fragmentation(l->bytes_req, l->bytes_alloc);\n\ty = fragmentation(r->bytes_req, r->bytes_alloc);\n\n\tif (x < y)\n\t\treturn -1;\n\telse if (x > y)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension frag_sort_dimension = {\n\t.name\t= \"frag\",\n\t.cmp\t= frag_cmp,\n};\n\nstatic int pingpong_cmp(void *a, void *b)\n{\n\tstruct alloc_stat *l = a;\n\tstruct alloc_stat *r = b;\n\n\tif (l->pingpong < r->pingpong)\n\t\treturn -1;\n\telse if (l->pingpong > r->pingpong)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension pingpong_sort_dimension = {\n\t.name\t= \"pingpong\",\n\t.cmp\t= pingpong_cmp,\n};\n\n \nstatic int page_cmp(void *a, void *b)\n{\n\tstruct page_stat *l = a;\n\tstruct page_stat *r = b;\n\n\tif (l->page < r->page)\n\t\treturn -1;\n\telse if (l->page > r->page)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension page_sort_dimension = {\n\t.name\t= \"page\",\n\t.cmp\t= page_cmp,\n};\n\nstatic int page_callsite_cmp(void *a, void *b)\n{\n\tstruct page_stat *l = a;\n\tstruct page_stat *r = b;\n\n\tif (l->callsite < r->callsite)\n\t\treturn -1;\n\telse if (l->callsite > r->callsite)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension page_callsite_sort_dimension = {\n\t.name\t= \"callsite\",\n\t.cmp\t= page_callsite_cmp,\n};\n\nstatic int page_hit_cmp(void *a, void *b)\n{\n\tstruct page_stat *l = a;\n\tstruct page_stat *r = b;\n\n\tif (l->nr_alloc < r->nr_alloc)\n\t\treturn -1;\n\telse if (l->nr_alloc > r->nr_alloc)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension page_hit_sort_dimension = {\n\t.name\t= \"hit\",\n\t.cmp\t= page_hit_cmp,\n};\n\nstatic int page_bytes_cmp(void *a, void *b)\n{\n\tstruct page_stat *l = a;\n\tstruct page_stat *r = b;\n\n\tif (l->alloc_bytes < r->alloc_bytes)\n\t\treturn -1;\n\telse if (l->alloc_bytes > r->alloc_bytes)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension page_bytes_sort_dimension = {\n\t.name\t= \"bytes\",\n\t.cmp\t= page_bytes_cmp,\n};\n\nstatic int page_order_cmp(void *a, void *b)\n{\n\tstruct page_stat *l = a;\n\tstruct page_stat *r = b;\n\n\tif (l->order < r->order)\n\t\treturn -1;\n\telse if (l->order > r->order)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension page_order_sort_dimension = {\n\t.name\t= \"order\",\n\t.cmp\t= page_order_cmp,\n};\n\nstatic int migrate_type_cmp(void *a, void *b)\n{\n\tstruct page_stat *l = a;\n\tstruct page_stat *r = b;\n\n\t \n\tif (l->migrate_type == -1U)\n\t\treturn 0;\n\n\tif (l->migrate_type < r->migrate_type)\n\t\treturn -1;\n\telse if (l->migrate_type > r->migrate_type)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension migrate_type_sort_dimension = {\n\t.name\t= \"migtype\",\n\t.cmp\t= migrate_type_cmp,\n};\n\nstatic int gfp_flags_cmp(void *a, void *b)\n{\n\tstruct page_stat *l = a;\n\tstruct page_stat *r = b;\n\n\t \n\tif (l->gfp_flags == -1U)\n\t\treturn 0;\n\n\tif (l->gfp_flags < r->gfp_flags)\n\t\treturn -1;\n\telse if (l->gfp_flags > r->gfp_flags)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic struct sort_dimension gfp_flags_sort_dimension = {\n\t.name\t= \"gfp\",\n\t.cmp\t= gfp_flags_cmp,\n};\n\nstatic struct sort_dimension *slab_sorts[] = {\n\t&ptr_sort_dimension,\n\t&callsite_sort_dimension,\n\t&hit_sort_dimension,\n\t&bytes_sort_dimension,\n\t&frag_sort_dimension,\n\t&pingpong_sort_dimension,\n};\n\nstatic struct sort_dimension *page_sorts[] = {\n\t&page_sort_dimension,\n\t&page_callsite_sort_dimension,\n\t&page_hit_sort_dimension,\n\t&page_bytes_sort_dimension,\n\t&page_order_sort_dimension,\n\t&migrate_type_sort_dimension,\n\t&gfp_flags_sort_dimension,\n};\n\nstatic int slab_sort_dimension__add(const char *tok, struct list_head *list)\n{\n\tstruct sort_dimension *sort;\n\tint i;\n\n\tfor (i = 0; i < (int)ARRAY_SIZE(slab_sorts); i++) {\n\t\tif (!strcmp(slab_sorts[i]->name, tok)) {\n\t\t\tsort = memdup(slab_sorts[i], sizeof(*slab_sorts[i]));\n\t\t\tif (!sort) {\n\t\t\t\tpr_err(\"%s: memdup failed\\n\", __func__);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tlist_add_tail(&sort->list, list);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -1;\n}\n\nstatic int page_sort_dimension__add(const char *tok, struct list_head *list)\n{\n\tstruct sort_dimension *sort;\n\tint i;\n\n\tfor (i = 0; i < (int)ARRAY_SIZE(page_sorts); i++) {\n\t\tif (!strcmp(page_sorts[i]->name, tok)) {\n\t\t\tsort = memdup(page_sorts[i], sizeof(*page_sorts[i]));\n\t\t\tif (!sort) {\n\t\t\t\tpr_err(\"%s: memdup failed\\n\", __func__);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tlist_add_tail(&sort->list, list);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -1;\n}\n\nstatic int setup_slab_sorting(struct list_head *sort_list, const char *arg)\n{\n\tchar *tok;\n\tchar *str = strdup(arg);\n\tchar *pos = str;\n\n\tif (!str) {\n\t\tpr_err(\"%s: strdup failed\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\twhile (true) {\n\t\ttok = strsep(&pos, \",\");\n\t\tif (!tok)\n\t\t\tbreak;\n\t\tif (slab_sort_dimension__add(tok, sort_list) < 0) {\n\t\t\tpr_err(\"Unknown slab --sort key: '%s'\", tok);\n\t\t\tfree(str);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tfree(str);\n\treturn 0;\n}\n\nstatic int setup_page_sorting(struct list_head *sort_list, const char *arg)\n{\n\tchar *tok;\n\tchar *str = strdup(arg);\n\tchar *pos = str;\n\n\tif (!str) {\n\t\tpr_err(\"%s: strdup failed\\n\", __func__);\n\t\treturn -1;\n\t}\n\n\twhile (true) {\n\t\ttok = strsep(&pos, \",\");\n\t\tif (!tok)\n\t\t\tbreak;\n\t\tif (page_sort_dimension__add(tok, sort_list) < 0) {\n\t\t\tpr_err(\"Unknown page --sort key: '%s'\", tok);\n\t\t\tfree(str);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tfree(str);\n\treturn 0;\n}\n\nstatic int parse_sort_opt(const struct option *opt __maybe_unused,\n\t\t\t  const char *arg, int unset __maybe_unused)\n{\n\tif (!arg)\n\t\treturn -1;\n\n\tif (kmem_page > kmem_slab ||\n\t    (kmem_page == 0 && kmem_slab == 0 && kmem_default == KMEM_PAGE)) {\n\t\tif (caller_flag > alloc_flag)\n\t\t\treturn setup_page_sorting(&page_caller_sort, arg);\n\t\telse\n\t\t\treturn setup_page_sorting(&page_alloc_sort, arg);\n\t} else {\n\t\tif (caller_flag > alloc_flag)\n\t\t\treturn setup_slab_sorting(&slab_caller_sort, arg);\n\t\telse\n\t\t\treturn setup_slab_sorting(&slab_alloc_sort, arg);\n\t}\n\n\treturn 0;\n}\n\nstatic int parse_caller_opt(const struct option *opt __maybe_unused,\n\t\t\t    const char *arg __maybe_unused,\n\t\t\t    int unset __maybe_unused)\n{\n\tcaller_flag = (alloc_flag + 1);\n\treturn 0;\n}\n\nstatic int parse_alloc_opt(const struct option *opt __maybe_unused,\n\t\t\t   const char *arg __maybe_unused,\n\t\t\t   int unset __maybe_unused)\n{\n\talloc_flag = (caller_flag + 1);\n\treturn 0;\n}\n\nstatic int parse_slab_opt(const struct option *opt __maybe_unused,\n\t\t\t  const char *arg __maybe_unused,\n\t\t\t  int unset __maybe_unused)\n{\n\tkmem_slab = (kmem_page + 1);\n\treturn 0;\n}\n\nstatic int parse_page_opt(const struct option *opt __maybe_unused,\n\t\t\t  const char *arg __maybe_unused,\n\t\t\t  int unset __maybe_unused)\n{\n\tkmem_page = (kmem_slab + 1);\n\treturn 0;\n}\n\nstatic int parse_line_opt(const struct option *opt __maybe_unused,\n\t\t\t  const char *arg, int unset __maybe_unused)\n{\n\tint lines;\n\n\tif (!arg)\n\t\treturn -1;\n\n\tlines = strtoul(arg, NULL, 10);\n\n\tif (caller_flag > alloc_flag)\n\t\tcaller_lines = lines;\n\telse\n\t\talloc_lines = lines;\n\n\treturn 0;\n}\n\nstatic bool slab_legacy_tp_is_exposed(void)\n{\n\t \n\treturn IS_ERR(trace_event__tp_format(\"kmem\", \"kmalloc_node\")) ?\n\t\tfalse : true;\n}\n\nstatic int __cmd_record(int argc, const char **argv)\n{\n\tconst char * const record_args[] = {\n\t\"record\", \"-a\", \"-R\", \"-c\", \"1\",\n\t};\n\tconst char * const slab_events[] = {\n\t\"-e\", \"kmem:kmalloc\",\n\t\"-e\", \"kmem:kfree\",\n\t\"-e\", \"kmem:kmem_cache_alloc\",\n\t\"-e\", \"kmem:kmem_cache_free\",\n\t};\n\tconst char * const slab_legacy_events[] = {\n\t\"-e\", \"kmem:kmalloc_node\",\n\t\"-e\", \"kmem:kmem_cache_alloc_node\",\n\t};\n\tconst char * const page_events[] = {\n\t\"-e\", \"kmem:mm_page_alloc\",\n\t\"-e\", \"kmem:mm_page_free\",\n\t};\n\tunsigned int rec_argc, i, j;\n\tconst char **rec_argv;\n\tunsigned int slab_legacy_tp_exposed = slab_legacy_tp_is_exposed();\n\n\trec_argc = ARRAY_SIZE(record_args) + argc - 1;\n\tif (kmem_slab) {\n\t\trec_argc += ARRAY_SIZE(slab_events);\n\t\tif (slab_legacy_tp_exposed)\n\t\t\trec_argc += ARRAY_SIZE(slab_legacy_events);\n\t}\n\tif (kmem_page)\n\t\trec_argc += ARRAY_SIZE(page_events) + 1;  \n\n\trec_argv = calloc(rec_argc + 1, sizeof(char *));\n\n\tif (rec_argv == NULL)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < ARRAY_SIZE(record_args); i++)\n\t\trec_argv[i] = strdup(record_args[i]);\n\n\tif (kmem_slab) {\n\t\tfor (j = 0; j < ARRAY_SIZE(slab_events); j++, i++)\n\t\t\trec_argv[i] = strdup(slab_events[j]);\n\t\tif (slab_legacy_tp_exposed) {\n\t\t\tfor (j = 0; j < ARRAY_SIZE(slab_legacy_events); j++, i++)\n\t\t\t\trec_argv[i] = strdup(slab_legacy_events[j]);\n\t\t}\n\t}\n\tif (kmem_page) {\n\t\trec_argv[i++] = strdup(\"-g\");\n\n\t\tfor (j = 0; j < ARRAY_SIZE(page_events); j++, i++)\n\t\t\trec_argv[i] = strdup(page_events[j]);\n\t}\n\n\tfor (j = 1; j < (unsigned int)argc; j++, i++)\n\t\trec_argv[i] = argv[j];\n\n\treturn cmd_record(i, rec_argv);\n}\n\nstatic int kmem_config(const char *var, const char *value, void *cb __maybe_unused)\n{\n\tif (!strcmp(var, \"kmem.default\")) {\n\t\tif (!strcmp(value, \"slab\"))\n\t\t\tkmem_default = KMEM_SLAB;\n\t\telse if (!strcmp(value, \"page\"))\n\t\t\tkmem_default = KMEM_PAGE;\n\t\telse\n\t\t\tpr_err(\"invalid default value ('slab' or 'page' required): %s\\n\",\n\t\t\t       value);\n\t\treturn 0;\n\t}\n\n\treturn 0;\n}\n\nint cmd_kmem(int argc, const char **argv)\n{\n\tconst char * const default_slab_sort = \"frag,hit,bytes\";\n\tconst char * const default_page_sort = \"bytes,hit\";\n\tstruct perf_data data = {\n\t\t.mode = PERF_DATA_MODE_READ,\n\t};\n\tconst struct option kmem_options[] = {\n\tOPT_STRING('i', \"input\", &input_name, \"file\", \"input file name\"),\n\tOPT_INCR('v', \"verbose\", &verbose,\n\t\t    \"be more verbose (show symbol address, etc)\"),\n\tOPT_CALLBACK_NOOPT(0, \"caller\", NULL, NULL,\n\t\t\t   \"show per-callsite statistics\", parse_caller_opt),\n\tOPT_CALLBACK_NOOPT(0, \"alloc\", NULL, NULL,\n\t\t\t   \"show per-allocation statistics\", parse_alloc_opt),\n\tOPT_CALLBACK('s', \"sort\", NULL, \"key[,key2...]\",\n\t\t     \"sort by keys: ptr, callsite, bytes, hit, pingpong, frag, \"\n\t\t     \"page, order, migtype, gfp\", parse_sort_opt),\n\tOPT_CALLBACK('l', \"line\", NULL, \"num\", \"show n lines\", parse_line_opt),\n\tOPT_BOOLEAN(0, \"raw-ip\", &raw_ip, \"show raw ip instead of symbol\"),\n\tOPT_BOOLEAN('f', \"force\", &data.force, \"don't complain, do it\"),\n\tOPT_CALLBACK_NOOPT(0, \"slab\", NULL, NULL, \"Analyze slab allocator\",\n\t\t\t   parse_slab_opt),\n\tOPT_CALLBACK_NOOPT(0, \"page\", NULL, NULL, \"Analyze page allocator\",\n\t\t\t   parse_page_opt),\n\tOPT_BOOLEAN(0, \"live\", &live_page, \"Show live page stat\"),\n\tOPT_STRING(0, \"time\", &time_str, \"str\",\n\t\t   \"Time span of interest (start,stop)\"),\n\tOPT_END()\n\t};\n\tconst char *const kmem_subcommands[] = { \"record\", \"stat\", NULL };\n\tconst char *kmem_usage[] = {\n\t\tNULL,\n\t\tNULL\n\t};\n\tstruct perf_session *session;\n\tstatic const char errmsg[] = \"No %s allocation events found.  Have you run 'perf kmem record --%s'?\\n\";\n\tint ret = perf_config(kmem_config, NULL);\n\n\tif (ret)\n\t\treturn ret;\n\n\targc = parse_options_subcommand(argc, argv, kmem_options,\n\t\t\t\t\tkmem_subcommands, kmem_usage,\n\t\t\t\t\tPARSE_OPT_STOP_AT_NON_OPTION);\n\n\tif (!argc)\n\t\tusage_with_options(kmem_usage, kmem_options);\n\n\tif (kmem_slab == 0 && kmem_page == 0) {\n\t\tif (kmem_default == KMEM_SLAB)\n\t\t\tkmem_slab = 1;\n\t\telse\n\t\t\tkmem_page = 1;\n\t}\n\n\tif (strlen(argv[0]) > 2 && strstarts(\"record\", argv[0])) {\n\t\tsymbol__init(NULL);\n\t\treturn __cmd_record(argc, argv);\n\t}\n\n\tdata.path = input_name;\n\n\tkmem_session = session = perf_session__new(&data, &perf_kmem);\n\tif (IS_ERR(session))\n\t\treturn PTR_ERR(session);\n\n\tret = -1;\n\n\tif (kmem_slab) {\n\t\tif (!evlist__find_tracepoint_by_name(session->evlist, \"kmem:kmalloc\")) {\n\t\t\tpr_err(errmsg, \"slab\", \"slab\");\n\t\t\tgoto out_delete;\n\t\t}\n\t}\n\n\tif (kmem_page) {\n\t\tstruct evsel *evsel = evlist__find_tracepoint_by_name(session->evlist, \"kmem:mm_page_alloc\");\n\n\t\tif (evsel == NULL) {\n\t\t\tpr_err(errmsg, \"page\", \"page\");\n\t\t\tgoto out_delete;\n\t\t}\n\n\t\tkmem_page_size = tep_get_page_size(evsel->tp_format->tep);\n\t\tsymbol_conf.use_callchain = true;\n\t}\n\n\tsymbol__init(&session->header.env);\n\n\tif (perf_time__parse_str(&ptime, time_str) != 0) {\n\t\tpr_err(\"Invalid time string\\n\");\n\t\tret = -EINVAL;\n\t\tgoto out_delete;\n\t}\n\n\tif (!strcmp(argv[0], \"stat\")) {\n\t\tsetlocale(LC_ALL, \"\");\n\n\t\tif (cpu__setup_cpunode_map())\n\t\t\tgoto out_delete;\n\n\t\tif (list_empty(&slab_caller_sort))\n\t\t\tsetup_slab_sorting(&slab_caller_sort, default_slab_sort);\n\t\tif (list_empty(&slab_alloc_sort))\n\t\t\tsetup_slab_sorting(&slab_alloc_sort, default_slab_sort);\n\t\tif (list_empty(&page_caller_sort))\n\t\t\tsetup_page_sorting(&page_caller_sort, default_page_sort);\n\t\tif (list_empty(&page_alloc_sort))\n\t\t\tsetup_page_sorting(&page_alloc_sort, default_page_sort);\n\n\t\tif (kmem_page) {\n\t\t\tsetup_page_sorting(&page_alloc_sort_input,\n\t\t\t\t\t   \"page,order,migtype,gfp\");\n\t\t\tsetup_page_sorting(&page_caller_sort_input,\n\t\t\t\t\t   \"callsite,order,migtype,gfp\");\n\t\t}\n\t\tret = __cmd_kmem(session);\n\t} else\n\t\tusage_with_options(kmem_usage, kmem_options);\n\nout_delete:\n\tperf_session__delete(session);\n\n\treturn ret;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}