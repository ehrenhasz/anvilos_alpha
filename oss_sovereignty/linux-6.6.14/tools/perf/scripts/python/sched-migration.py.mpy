{
  "module_name": "sched-migration.py",
  "hash_id": "32aee689909ca4dbf73754bbb9de7fd2f04cf935182387d2bf50ecb613c08f58",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/scripts/python/sched-migration.py",
  "human_readable_source": "# Cpu task migration overview toy\n#\n# Copyright (C) 2010 Frederic Weisbecker <fweisbec@gmail.com>\n#\n# perf script event handlers have been generated by perf script -g python\n#\n# This software is distributed under the terms of the GNU General\n# Public License (\"GPL\") version 2 as published by the Free Software\n# Foundation.\nfrom __future__ import print_function\n\nimport os\nimport sys\n\nfrom collections import defaultdict\ntry:\n\tfrom UserList import UserList\nexcept ImportError:\n\t# Python 3: UserList moved to the collections package\n\tfrom collections import UserList\n\nsys.path.append(os.environ['PERF_EXEC_PATH'] + \\\n\t'/scripts/python/Perf-Trace-Util/lib/Perf/Trace')\nsys.path.append('scripts/python/Perf-Trace-Util/lib/Perf/Trace')\n\nfrom perf_trace_context import *\nfrom Core import *\nfrom SchedGui import *\n\n\nthreads = { 0 : \"idle\"}\n\ndef thread_name(pid):\n\treturn \"%s:%d\" % (threads[pid], pid)\n\nclass RunqueueEventUnknown:\n\t@staticmethod\n\tdef color():\n\t\treturn None\n\n\tdef __repr__(self):\n\t\treturn \"unknown\"\n\nclass RunqueueEventSleep:\n\t@staticmethod\n\tdef color():\n\t\treturn (0, 0, 0xff)\n\n\tdef __init__(self, sleeper):\n\t\tself.sleeper = sleeper\n\n\tdef __repr__(self):\n\t\treturn \"%s gone to sleep\" % thread_name(self.sleeper)\n\nclass RunqueueEventWakeup:\n\t@staticmethod\n\tdef color():\n\t\treturn (0xff, 0xff, 0)\n\n\tdef __init__(self, wakee):\n\t\tself.wakee = wakee\n\n\tdef __repr__(self):\n\t\treturn \"%s woke up\" % thread_name(self.wakee)\n\nclass RunqueueEventFork:\n\t@staticmethod\n\tdef color():\n\t\treturn (0, 0xff, 0)\n\n\tdef __init__(self, child):\n\t\tself.child = child\n\n\tdef __repr__(self):\n\t\treturn \"new forked task %s\" % thread_name(self.child)\n\nclass RunqueueMigrateIn:\n\t@staticmethod\n\tdef color():\n\t\treturn (0, 0xf0, 0xff)\n\n\tdef __init__(self, new):\n\t\tself.new = new\n\n\tdef __repr__(self):\n\t\treturn \"task migrated in %s\" % thread_name(self.new)\n\nclass RunqueueMigrateOut:\n\t@staticmethod\n\tdef color():\n\t\treturn (0xff, 0, 0xff)\n\n\tdef __init__(self, old):\n\t\tself.old = old\n\n\tdef __repr__(self):\n\t\treturn \"task migrated out %s\" % thread_name(self.old)\n\nclass RunqueueSnapshot:\n\tdef __init__(self, tasks = [0], event = RunqueueEventUnknown()):\n\t\tself.tasks = tuple(tasks)\n\t\tself.event = event\n\n\tdef sched_switch(self, prev, prev_state, next):\n\t\tevent = RunqueueEventUnknown()\n\n\t\tif taskState(prev_state) == \"R\" and next in self.tasks \\\n\t\t\tand prev in self.tasks:\n\t\t\treturn self\n\n\t\tif taskState(prev_state) != \"R\":\n\t\t\tevent = RunqueueEventSleep(prev)\n\n\t\tnext_tasks = list(self.tasks[:])\n\t\tif prev in self.tasks:\n\t\t\tif taskState(prev_state) != \"R\":\n\t\t\t\tnext_tasks.remove(prev)\n\t\telif taskState(prev_state) == \"R\":\n\t\t\tnext_tasks.append(prev)\n\n\t\tif next not in next_tasks:\n\t\t\tnext_tasks.append(next)\n\n\t\treturn RunqueueSnapshot(next_tasks, event)\n\n\tdef migrate_out(self, old):\n\t\tif old not in self.tasks:\n\t\t\treturn self\n\t\tnext_tasks = [task for task in self.tasks if task != old]\n\n\t\treturn RunqueueSnapshot(next_tasks, RunqueueMigrateOut(old))\n\n\tdef __migrate_in(self, new, event):\n\t\tif new in self.tasks:\n\t\t\tself.event = event\n\t\t\treturn self\n\t\tnext_tasks = self.tasks[:] + tuple([new])\n\n\t\treturn RunqueueSnapshot(next_tasks, event)\n\n\tdef migrate_in(self, new):\n\t\treturn self.__migrate_in(new, RunqueueMigrateIn(new))\n\n\tdef wake_up(self, new):\n\t\treturn self.__migrate_in(new, RunqueueEventWakeup(new))\n\n\tdef wake_up_new(self, new):\n\t\treturn self.__migrate_in(new, RunqueueEventFork(new))\n\n\tdef load(self):\n\t\t\"\"\" Provide the number of tasks on the runqueue.\n\t\t    Don't count idle\"\"\"\n\t\treturn len(self.tasks) - 1\n\n\tdef __repr__(self):\n\t\tret = self.tasks.__repr__()\n\t\tret += self.origin_tostring()\n\n\t\treturn ret\n\nclass TimeSlice:\n\tdef __init__(self, start, prev):\n\t\tself.start = start\n\t\tself.prev = prev\n\t\tself.end = start\n\t\t# cpus that triggered the event\n\t\tself.event_cpus = []\n\t\tif prev is not None:\n\t\t\tself.total_load = prev.total_load\n\t\t\tself.rqs = prev.rqs.copy()\n\t\telse:\n\t\t\tself.rqs = defaultdict(RunqueueSnapshot)\n\t\t\tself.total_load = 0\n\n\tdef __update_total_load(self, old_rq, new_rq):\n\t\tdiff = new_rq.load() - old_rq.load()\n\t\tself.total_load += diff\n\n\tdef sched_switch(self, ts_list, prev, prev_state, next, cpu):\n\t\told_rq = self.prev.rqs[cpu]\n\t\tnew_rq = old_rq.sched_switch(prev, prev_state, next)\n\n\t\tif old_rq is new_rq:\n\t\t\treturn\n\n\t\tself.rqs[cpu] = new_rq\n\t\tself.__update_total_load(old_rq, new_rq)\n\t\tts_list.append(self)\n\t\tself.event_cpus = [cpu]\n\n\tdef migrate(self, ts_list, new, old_cpu, new_cpu):\n\t\tif old_cpu == new_cpu:\n\t\t\treturn\n\t\told_rq = self.prev.rqs[old_cpu]\n\t\tout_rq = old_rq.migrate_out(new)\n\t\tself.rqs[old_cpu] = out_rq\n\t\tself.__update_total_load(old_rq, out_rq)\n\n\t\tnew_rq = self.prev.rqs[new_cpu]\n\t\tin_rq = new_rq.migrate_in(new)\n\t\tself.rqs[new_cpu] = in_rq\n\t\tself.__update_total_load(new_rq, in_rq)\n\n\t\tts_list.append(self)\n\n\t\tif old_rq is not out_rq:\n\t\t\tself.event_cpus.append(old_cpu)\n\t\tself.event_cpus.append(new_cpu)\n\n\tdef wake_up(self, ts_list, pid, cpu, fork):\n\t\told_rq = self.prev.rqs[cpu]\n\t\tif fork:\n\t\t\tnew_rq = old_rq.wake_up_new(pid)\n\t\telse:\n\t\t\tnew_rq = old_rq.wake_up(pid)\n\n\t\tif new_rq is old_rq:\n\t\t\treturn\n\t\tself.rqs[cpu] = new_rq\n\t\tself.__update_total_load(old_rq, new_rq)\n\t\tts_list.append(self)\n\t\tself.event_cpus = [cpu]\n\n\tdef next(self, t):\n\t\tself.end = t\n\t\treturn TimeSlice(t, self)\n\nclass TimeSliceList(UserList):\n\tdef __init__(self, arg = []):\n\t\tself.data = arg\n\n\tdef get_time_slice(self, ts):\n\t\tif len(self.data) == 0:\n\t\t\tslice = TimeSlice(ts, TimeSlice(-1, None))\n\t\telse:\n\t\t\tslice = self.data[-1].next(ts)\n\t\treturn slice\n\n\tdef find_time_slice(self, ts):\n\t\tstart = 0\n\t\tend = len(self.data)\n\t\tfound = -1\n\t\tsearching = True\n\t\twhile searching:\n\t\t\tif start == end or start == end - 1:\n\t\t\t\tsearching = False\n\n\t\t\ti = (end + start) / 2\n\t\t\tif self.data[i].start <= ts and self.data[i].end >= ts:\n\t\t\t\tfound = i\n\t\t\t\tend = i\n\t\t\t\tcontinue\n\n\t\t\tif self.data[i].end < ts:\n\t\t\t\tstart = i\n\n\t\t\telif self.data[i].start > ts:\n\t\t\t\tend = i\n\n\t\treturn found\n\n\tdef set_root_win(self, win):\n\t\tself.root_win = win\n\n\tdef mouse_down(self, cpu, t):\n\t\tidx = self.find_time_slice(t)\n\t\tif idx == -1:\n\t\t\treturn\n\n\t\tts = self[idx]\n\t\trq = ts.rqs[cpu]\n\t\traw = \"CPU: %d\\n\" % cpu\n\t\traw += \"Last event : %s\\n\" % rq.event.__repr__()\n\t\traw += \"Timestamp : %d.%06d\\n\" % (ts.start / (10 ** 9), (ts.start % (10 ** 9)) / 1000)\n\t\traw += \"Duration : %6d us\\n\" % ((ts.end - ts.start) / (10 ** 6))\n\t\traw += \"Load = %d\\n\" % rq.load()\n\t\tfor t in rq.tasks:\n\t\t\traw += \"%s \\n\" % thread_name(t)\n\n\t\tself.root_win.update_summary(raw)\n\n\tdef update_rectangle_cpu(self, slice, cpu):\n\t\trq = slice.rqs[cpu]\n\n\t\tif slice.total_load != 0:\n\t\t\tload_rate = rq.load() / float(slice.total_load)\n\t\telse:\n\t\t\tload_rate = 0\n\n\t\tred_power = int(0xff - (0xff * load_rate))\n\t\tcolor = (0xff, red_power, red_power)\n\n\t\ttop_color = None\n\n\t\tif cpu in slice.event_cpus:\n\t\t\ttop_color = rq.event.color()\n\n\t\tself.root_win.paint_rectangle_zone(cpu, color, top_color, slice.start, slice.end)\n\n\tdef fill_zone(self, start, end):\n\t\ti = self.find_time_slice(start)\n\t\tif i == -1:\n\t\t\treturn\n\n\t\tfor i in range(i, len(self.data)):\n\t\t\ttimeslice = self.data[i]\n\t\t\tif timeslice.start > end:\n\t\t\t\treturn\n\n\t\t\tfor cpu in timeslice.rqs:\n\t\t\t\tself.update_rectangle_cpu(timeslice, cpu)\n\n\tdef interval(self):\n\t\tif len(self.data) == 0:\n\t\t\treturn (0, 0)\n\n\t\treturn (self.data[0].start, self.data[-1].end)\n\n\tdef nr_rectangles(self):\n\t\tlast_ts = self.data[-1]\n\t\tmax_cpu = 0\n\t\tfor cpu in last_ts.rqs:\n\t\t\tif cpu > max_cpu:\n\t\t\t\tmax_cpu = cpu\n\t\treturn max_cpu\n\n\nclass SchedEventProxy:\n\tdef __init__(self):\n\t\tself.current_tsk = defaultdict(lambda : -1)\n\t\tself.timeslices = TimeSliceList()\n\n\tdef sched_switch(self, headers, prev_comm, prev_pid, prev_prio, prev_state,\n\t\t\t next_comm, next_pid, next_prio):\n\t\t\"\"\" Ensure the task we sched out this cpu is really the one\n\t\t    we logged. Otherwise we may have missed traces \"\"\"\n\n\t\ton_cpu_task = self.current_tsk[headers.cpu]\n\n\t\tif on_cpu_task != -1 and on_cpu_task != prev_pid:\n\t\t\tprint(\"Sched switch event rejected ts: %s cpu: %d prev: %s(%d) next: %s(%d)\" % \\\n\t\t\t\theaders.ts_format(), headers.cpu, prev_comm, prev_pid, next_comm, next_pid)\n\n\t\tthreads[prev_pid] = prev_comm\n\t\tthreads[next_pid] = next_comm\n\t\tself.current_tsk[headers.cpu] = next_pid\n\n\t\tts = self.timeslices.get_time_slice(headers.ts())\n\t\tts.sched_switch(self.timeslices, prev_pid, prev_state, next_pid, headers.cpu)\n\n\tdef migrate(self, headers, pid, prio, orig_cpu, dest_cpu):\n\t\tts = self.timeslices.get_time_slice(headers.ts())\n\t\tts.migrate(self.timeslices, pid, orig_cpu, dest_cpu)\n\n\tdef wake_up(self, headers, comm, pid, success, target_cpu, fork):\n\t\tif success == 0:\n\t\t\treturn\n\t\tts = self.timeslices.get_time_slice(headers.ts())\n\t\tts.wake_up(self.timeslices, pid, target_cpu, fork)\n\n\ndef trace_begin():\n\tglobal parser\n\tparser = SchedEventProxy()\n\ndef trace_end():\n\tapp = wx.App(False)\n\ttimeslices = parser.timeslices\n\tframe = RootFrame(timeslices, \"Migration\")\n\tapp.MainLoop()\n\ndef sched__sched_stat_runtime(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, runtime, vruntime):\n\tpass\n\ndef sched__sched_stat_iowait(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, delay):\n\tpass\n\ndef sched__sched_stat_sleep(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, delay):\n\tpass\n\ndef sched__sched_stat_wait(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, delay):\n\tpass\n\ndef sched__sched_process_fork(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, parent_comm, parent_pid, child_comm, child_pid):\n\tpass\n\ndef sched__sched_process_wait(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, prio):\n\tpass\n\ndef sched__sched_process_exit(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, prio):\n\tpass\n\ndef sched__sched_process_free(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, prio):\n\tpass\n\ndef sched__sched_migrate_task(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, prio, orig_cpu,\n\tdest_cpu):\n\theaders = EventHeaders(common_cpu, common_secs, common_nsecs,\n\t\t\t\tcommon_pid, common_comm, common_callchain)\n\tparser.migrate(headers, pid, prio, orig_cpu, dest_cpu)\n\ndef sched__sched_switch(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm, common_callchain,\n\tprev_comm, prev_pid, prev_prio, prev_state,\n\tnext_comm, next_pid, next_prio):\n\n\theaders = EventHeaders(common_cpu, common_secs, common_nsecs,\n\t\t\t\tcommon_pid, common_comm, common_callchain)\n\tparser.sched_switch(headers, prev_comm, prev_pid, prev_prio, prev_state,\n\t\t\t next_comm, next_pid, next_prio)\n\ndef sched__sched_wakeup_new(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, prio, success,\n\ttarget_cpu):\n\theaders = EventHeaders(common_cpu, common_secs, common_nsecs,\n\t\t\t\tcommon_pid, common_comm, common_callchain)\n\tparser.wake_up(headers, comm, pid, success, target_cpu, 1)\n\ndef sched__sched_wakeup(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, prio, success,\n\ttarget_cpu):\n\theaders = EventHeaders(common_cpu, common_secs, common_nsecs,\n\t\t\t\tcommon_pid, common_comm, common_callchain)\n\tparser.wake_up(headers, comm, pid, success, target_cpu, 0)\n\ndef sched__sched_wait_task(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid, prio):\n\tpass\n\ndef sched__sched_kthread_stop_ret(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, ret):\n\tpass\n\ndef sched__sched_kthread_stop(event_name, context, common_cpu,\n\tcommon_secs, common_nsecs, common_pid, common_comm,\n\tcommon_callchain, comm, pid):\n\tpass\n\ndef trace_unhandled(event_name, context, event_fields_dict):\n\tpass\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}