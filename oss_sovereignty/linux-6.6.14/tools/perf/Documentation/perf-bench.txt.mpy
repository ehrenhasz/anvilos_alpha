{
  "module_name": "perf-bench.txt",
  "hash_id": "0180ac92131cbd21b706f231b42d883838c316ff043174dc3cd3f05fea453aff",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/Documentation/perf-bench.txt",
  "human_readable_source": "perf-bench(1)\n=============\n\nNAME\n----\nperf-bench - General framework for benchmark suites\n\nSYNOPSIS\n--------\n[verse]\n'perf bench' [<common options>] <subsystem> <suite> [<options>]\n\nDESCRIPTION\n-----------\nThis 'perf bench' command is a general framework for benchmark suites.\n\nCOMMON OPTIONS\n--------------\n-r::\n--repeat=::\nSpecify number of times to repeat the run (default 10).\n\n-f::\n--format=::\nSpecify format style.\nCurrent available format styles are:\n\n'default'::\nDefault style. This is mainly for human reading.\n---------------------\n% perf bench sched pipe                      # with no style specified\n(executing 1000000 pipe operations between two tasks)\n        Total time:5.855 sec\n                5.855061 usecs/op\n\t\t170792 ops/sec\n---------------------\n\n'simple'::\nThis simple style is friendly for automated\nprocessing by scripts.\n---------------------\n% perf bench --format=simple sched pipe      # specified simple\n5.988\n---------------------\n\nSUBSYSTEM\n---------\n\n'sched'::\n\tScheduler and IPC mechanisms.\n\n'syscall'::\n\tSystem call performance (throughput).\n\n'mem'::\n\tMemory access performance.\n\n'numa'::\n\tNUMA scheduling and MM benchmarks.\n\n'futex'::\n\tFutex stressing benchmarks.\n\n'epoll'::\n\tEventpoll (epoll) stressing benchmarks.\n\n'internals'::\n\tBenchmark internal perf functionality.\n\n'uprobe'::\n\tBenchmark overhead of uprobe + BPF.\n\n'all'::\n\tAll benchmark subsystems.\n\nSUITES FOR 'sched'\n~~~~~~~~~~~~~~~~~~\n*messaging*::\nSuite for evaluating performance of scheduler and IPC mechanisms.\nBased on hackbench by Rusty Russell.\n\nOptions of *messaging*\n^^^^^^^^^^^^^^^^^^^^^^\n-p::\n--pipe::\nUse pipe() instead of socketpair()\n\n-t::\n--thread::\nBe multi thread instead of multi process\n\n-g::\n--group=::\nSpecify number of groups\n\n-l::\n--nr_loops=::\nSpecify number of loops\n\nExample of *messaging*\n^^^^^^^^^^^^^^^^^^^^^^\n\n---------------------\n% perf bench sched messaging                 # run with default\noptions (20 sender and receiver processes per group)\n(10 groups == 400 processes run)\n\n      Total time:0.308 sec\n\n% perf bench sched messaging -t -g 20        # be multi-thread, with 20 groups\n(20 sender and receiver threads per group)\n(20 groups == 800 threads run)\n\n      Total time:0.582 sec\n---------------------\n\n*pipe*::\nSuite for pipe() system call.\nBased on pipe-test-1m.c by Ingo Molnar.\n\nOptions of *pipe*\n^^^^^^^^^^^^^^^^^\n-l::\n--loop=::\nSpecify number of loops.\n\nExample of *pipe*\n^^^^^^^^^^^^^^^^^\n\n---------------------\n% perf bench sched pipe\n(executing 1000000 pipe operations between two tasks)\n\n        Total time:8.091 sec\n                8.091833 usecs/op\n                123581 ops/sec\n\n% perf bench sched pipe -l 1000              # loop 1000\n(executing 1000 pipe operations between two tasks)\n\n        Total time:0.016 sec\n                16.948000 usecs/op\n                59004 ops/sec\n---------------------\n\nSUITES FOR 'syscall'\n~~~~~~~~~~~~~~~~~~\n*basic*::\nSuite for evaluating performance of core system call throughput (both usecs/op and ops/sec metrics).\nThis uses a single thread simply doing getppid(2), which is a simple syscall where the result is not\ncached by glibc.\n\n\nSUITES FOR 'mem'\n~~~~~~~~~~~~~~~~\n*memcpy*::\nSuite for evaluating performance of simple memory copy in various ways.\n\nOptions of *memcpy*\n^^^^^^^^^^^^^^^^^^^\n-l::\n--size::\nSpecify size of memory to copy (default: 1MB).\nAvailable units are B, KB, MB, GB and TB (case insensitive).\n\n-f::\n--function::\nSpecify function to copy (default: default).\nAvailable functions are depend on the architecture.\nOn x86-64, x86-64-unrolled, x86-64-movsq and x86-64-movsb are supported.\n\n-l::\n--nr_loops::\nRepeat memcpy invocation this number of times.\n\n-c::\n--cycles::\nUse perf's cpu-cycles event instead of gettimeofday syscall.\n\n*memset*::\nSuite for evaluating performance of simple memory set in various ways.\n\nOptions of *memset*\n^^^^^^^^^^^^^^^^^^^\n-l::\n--size::\nSpecify size of memory to set (default: 1MB).\nAvailable units are B, KB, MB, GB and TB (case insensitive).\n\n-f::\n--function::\nSpecify function to set (default: default).\nAvailable functions are depend on the architecture.\nOn x86-64, x86-64-unrolled, x86-64-stosq and x86-64-stosb are supported.\n\n-l::\n--nr_loops::\nRepeat memset invocation this number of times.\n\n-c::\n--cycles::\nUse perf's cpu-cycles event instead of gettimeofday syscall.\n\nSUITES FOR 'numa'\n~~~~~~~~~~~~~~~~~\n*mem*::\nSuite for evaluating NUMA workloads.\n\nSUITES FOR 'futex'\n~~~~~~~~~~~~~~~~~~\n*hash*::\nSuite for evaluating hash tables.\n\n*wake*::\nSuite for evaluating wake calls.\n\n*wake-parallel*::\nSuite for evaluating parallel wake calls.\n\n*requeue*::\nSuite for evaluating requeue calls.\n\n*lock-pi*::\nSuite for evaluating futex lock_pi calls.\n\nSUITES FOR 'epoll'\n~~~~~~~~~~~~~~~~~~\n*wait*::\nSuite for evaluating concurrent epoll_wait calls.\n\n*ctl*::\nSuite for evaluating multiple epoll_ctl calls.\n\nSUITES FOR 'internals'\n~~~~~~~~~~~~~~~~~~~~~~\n*synthesize*::\nSuite for evaluating perf's event synthesis performance.\n\nSEE ALSO\n--------\nlinkperf:perf[1]\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}