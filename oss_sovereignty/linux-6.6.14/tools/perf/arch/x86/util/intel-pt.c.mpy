{
  "module_name": "intel-pt.c",
  "hash_id": "3f04c2477691f12bff36f04ffb8d5497469a5bf6991ddfe34a011aa12a0ddaf4",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/arch/x86/util/intel-pt.c",
  "human_readable_source": "\n \n\n#include <errno.h>\n#include <stdbool.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n#include <linux/bitops.h>\n#include <linux/log2.h>\n#include <linux/zalloc.h>\n#include <linux/err.h>\n#include <cpuid.h>\n\n#include \"../../../util/session.h\"\n#include \"../../../util/event.h\"\n#include \"../../../util/evlist.h\"\n#include \"../../../util/evsel.h\"\n#include \"../../../util/evsel_config.h\"\n#include \"../../../util/cpumap.h\"\n#include \"../../../util/mmap.h\"\n#include <subcmd/parse-options.h>\n#include \"../../../util/parse-events.h\"\n#include \"../../../util/pmus.h\"\n#include \"../../../util/debug.h\"\n#include \"../../../util/auxtrace.h\"\n#include \"../../../util/perf_api_probe.h\"\n#include \"../../../util/record.h\"\n#include \"../../../util/target.h\"\n#include \"../../../util/tsc.h\"\n#include <internal/lib.h> \n#include \"../../../util/intel-pt.h\"\n\n#define KiB(x) ((x) * 1024)\n#define MiB(x) ((x) * 1024 * 1024)\n#define KiB_MASK(x) (KiB(x) - 1)\n#define MiB_MASK(x) (MiB(x) - 1)\n\n#define INTEL_PT_PSB_PERIOD_NEAR\t256\n\nstruct intel_pt_snapshot_ref {\n\tvoid *ref_buf;\n\tsize_t ref_offset;\n\tbool wrapped;\n};\n\nstruct intel_pt_recording {\n\tstruct auxtrace_record\t\titr;\n\tstruct perf_pmu\t\t\t*intel_pt_pmu;\n\tint\t\t\t\thave_sched_switch;\n\tstruct evlist\t\t*evlist;\n\tbool\t\t\t\tsnapshot_mode;\n\tbool\t\t\t\tsnapshot_init_done;\n\tsize_t\t\t\t\tsnapshot_size;\n\tsize_t\t\t\t\tsnapshot_ref_buf_size;\n\tint\t\t\t\tsnapshot_ref_cnt;\n\tstruct intel_pt_snapshot_ref\t*snapshot_refs;\n\tsize_t\t\t\t\tpriv_size;\n};\n\nstatic int intel_pt_parse_terms_with_default(struct perf_pmu *pmu,\n\t\t\t\t\t     const char *str,\n\t\t\t\t\t     u64 *config)\n{\n\tstruct list_head *terms;\n\tstruct perf_event_attr attr = { .size = 0, };\n\tint err;\n\n\tterms = malloc(sizeof(struct list_head));\n\tif (!terms)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(terms);\n\n\terr = parse_events_terms(terms, str,   NULL);\n\tif (err)\n\t\tgoto out_free;\n\n\tattr.config = *config;\n\terr = perf_pmu__config_terms(pmu, &attr, terms,  true,  NULL);\n\tif (err)\n\t\tgoto out_free;\n\n\t*config = attr.config;\nout_free:\n\tparse_events_terms__delete(terms);\n\treturn err;\n}\n\nstatic int intel_pt_parse_terms(struct perf_pmu *pmu, const char *str, u64 *config)\n{\n\t*config = 0;\n\treturn intel_pt_parse_terms_with_default(pmu, str, config);\n}\n\nstatic u64 intel_pt_masked_bits(u64 mask, u64 bits)\n{\n\tconst u64 top_bit = 1ULL << 63;\n\tu64 res = 0;\n\tint i;\n\n\tfor (i = 0; i < 64; i++) {\n\t\tif (mask & top_bit) {\n\t\t\tres <<= 1;\n\t\t\tif (bits & top_bit)\n\t\t\t\tres |= 1;\n\t\t}\n\t\tmask <<= 1;\n\t\tbits <<= 1;\n\t}\n\n\treturn res;\n}\n\nstatic int intel_pt_read_config(struct perf_pmu *intel_pt_pmu, const char *str,\n\t\t\t\tstruct evlist *evlist, u64 *res)\n{\n\tstruct evsel *evsel;\n\tu64 mask;\n\n\t*res = 0;\n\n\tmask = perf_pmu__format_bits(intel_pt_pmu, str);\n\tif (!mask)\n\t\treturn -EINVAL;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.type == intel_pt_pmu->type) {\n\t\t\t*res = intel_pt_masked_bits(mask, evsel->core.attr.config);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic size_t intel_pt_psb_period(struct perf_pmu *intel_pt_pmu,\n\t\t\t\t  struct evlist *evlist)\n{\n\tu64 val;\n\tint err, topa_multiple_entries;\n\tsize_t psb_period;\n\n\tif (perf_pmu__scan_file(intel_pt_pmu, \"caps/topa_multiple_entries\",\n\t\t\t\t\"%d\", &topa_multiple_entries) != 1)\n\t\ttopa_multiple_entries = 0;\n\n\t \n\tif (!topa_multiple_entries) {\n\t\tpsb_period = 256;\n\t\tgoto out;\n\t}\n\n\terr = intel_pt_read_config(intel_pt_pmu, \"psb_period\", evlist, &val);\n\tif (err)\n\t\tval = 0;\n\n\tpsb_period = 1 << (val + 11);\nout:\n\tpr_debug2(\"%s psb_period %zu\\n\", intel_pt_pmu->name, psb_period);\n\treturn psb_period;\n}\n\nstatic int intel_pt_pick_bit(int bits, int target)\n{\n\tint pos, pick = -1;\n\n\tfor (pos = 0; bits; bits >>= 1, pos++) {\n\t\tif (bits & 1) {\n\t\t\tif (pos <= target || pick < 0)\n\t\t\t\tpick = pos;\n\t\t\tif (pos >= target)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn pick;\n}\n\nstatic u64 intel_pt_default_config(struct perf_pmu *intel_pt_pmu)\n{\n\tchar buf[256];\n\tint mtc, mtc_periods = 0, mtc_period;\n\tint psb_cyc, psb_periods, psb_period;\n\tint pos = 0;\n\tu64 config;\n\tchar c;\n\tint dirfd;\n\n\tdirfd = perf_pmu__event_source_devices_fd();\n\n\tpos += scnprintf(buf + pos, sizeof(buf) - pos, \"tsc\");\n\n\tif (perf_pmu__scan_file_at(intel_pt_pmu, dirfd, \"caps/mtc\", \"%d\",\n\t\t\t\t   &mtc) != 1)\n\t\tmtc = 1;\n\n\tif (mtc) {\n\t\tif (perf_pmu__scan_file_at(intel_pt_pmu, dirfd, \"caps/mtc_periods\", \"%x\",\n\t\t\t\t\t   &mtc_periods) != 1)\n\t\t\tmtc_periods = 0;\n\t\tif (mtc_periods) {\n\t\t\tmtc_period = intel_pt_pick_bit(mtc_periods, 3);\n\t\t\tpos += scnprintf(buf + pos, sizeof(buf) - pos,\n\t\t\t\t\t \",mtc,mtc_period=%d\", mtc_period);\n\t\t}\n\t}\n\n\tif (perf_pmu__scan_file_at(intel_pt_pmu, dirfd, \"caps/psb_cyc\", \"%d\",\n\t\t\t\t   &psb_cyc) != 1)\n\t\tpsb_cyc = 1;\n\n\tif (psb_cyc && mtc_periods) {\n\t\tif (perf_pmu__scan_file_at(intel_pt_pmu, dirfd, \"caps/psb_periods\", \"%x\",\n\t\t\t\t\t   &psb_periods) != 1)\n\t\t\tpsb_periods = 0;\n\t\tif (psb_periods) {\n\t\t\tpsb_period = intel_pt_pick_bit(psb_periods, 3);\n\t\t\tpos += scnprintf(buf + pos, sizeof(buf) - pos,\n\t\t\t\t\t \",psb_period=%d\", psb_period);\n\t\t}\n\t}\n\n\tif (perf_pmu__scan_file_at(intel_pt_pmu, dirfd, \"format/pt\", \"%c\", &c) == 1 &&\n\t    perf_pmu__scan_file_at(intel_pt_pmu, dirfd, \"format/branch\", \"%c\", &c) == 1)\n\t\tpos += scnprintf(buf + pos, sizeof(buf) - pos, \",pt,branch\");\n\n\tpr_debug2(\"%s default config: %s\\n\", intel_pt_pmu->name, buf);\n\n\tintel_pt_parse_terms(intel_pt_pmu, buf, &config);\n\n\tclose(dirfd);\n\treturn config;\n}\n\nstatic int intel_pt_parse_snapshot_options(struct auxtrace_record *itr,\n\t\t\t\t\t   struct record_opts *opts,\n\t\t\t\t\t   const char *str)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\tunsigned long long snapshot_size = 0;\n\tchar *endptr;\n\n\tif (str) {\n\t\tsnapshot_size = strtoull(str, &endptr, 0);\n\t\tif (*endptr || snapshot_size > SIZE_MAX)\n\t\t\treturn -1;\n\t}\n\n\topts->auxtrace_snapshot_mode = true;\n\topts->auxtrace_snapshot_size = snapshot_size;\n\n\tptr->snapshot_size = snapshot_size;\n\n\treturn 0;\n}\n\nstruct perf_event_attr *\nintel_pt_pmu_default_config(struct perf_pmu *intel_pt_pmu)\n{\n\tstruct perf_event_attr *attr;\n\n\tattr = zalloc(sizeof(struct perf_event_attr));\n\tif (!attr)\n\t\treturn NULL;\n\n\tattr->config = intel_pt_default_config(intel_pt_pmu);\n\n\tintel_pt_pmu->selectable = true;\n\n\treturn attr;\n}\n\nstatic const char *intel_pt_find_filter(struct evlist *evlist,\n\t\t\t\t\tstruct perf_pmu *intel_pt_pmu)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.type == intel_pt_pmu->type)\n\t\t\treturn evsel->filter;\n\t}\n\n\treturn NULL;\n}\n\nstatic size_t intel_pt_filter_bytes(const char *filter)\n{\n\tsize_t len = filter ? strlen(filter) : 0;\n\n\treturn len ? roundup(len + 1, 8) : 0;\n}\n\nstatic size_t\nintel_pt_info_priv_size(struct auxtrace_record *itr, struct evlist *evlist)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\tconst char *filter = intel_pt_find_filter(evlist, ptr->intel_pt_pmu);\n\n\tptr->priv_size = (INTEL_PT_AUXTRACE_PRIV_MAX * sizeof(u64)) +\n\t\t\t intel_pt_filter_bytes(filter);\n\tptr->priv_size += sizeof(u64);  \n\n\treturn ptr->priv_size;\n}\n\nstatic void intel_pt_tsc_ctc_ratio(u32 *n, u32 *d)\n{\n\tunsigned int eax = 0, ebx = 0, ecx = 0, edx = 0;\n\n\t__get_cpuid(0x15, &eax, &ebx, &ecx, &edx);\n\t*n = ebx;\n\t*d = eax;\n}\n\nstatic int intel_pt_info_fill(struct auxtrace_record *itr,\n\t\t\t      struct perf_session *session,\n\t\t\t      struct perf_record_auxtrace_info *auxtrace_info,\n\t\t\t      size_t priv_size)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\tstruct perf_pmu *intel_pt_pmu = ptr->intel_pt_pmu;\n\tstruct perf_event_mmap_page *pc;\n\tstruct perf_tsc_conversion tc = { .time_mult = 0, };\n\tbool cap_user_time_zero = false, per_cpu_mmaps;\n\tu64 tsc_bit, mtc_bit, mtc_freq_bits, cyc_bit, noretcomp_bit;\n\tu32 tsc_ctc_ratio_n, tsc_ctc_ratio_d;\n\tunsigned long max_non_turbo_ratio;\n\tsize_t filter_str_len;\n\tconst char *filter;\n\tint event_trace;\n\t__u64 *info;\n\tint err;\n\n\tif (priv_size != ptr->priv_size)\n\t\treturn -EINVAL;\n\n\tintel_pt_parse_terms(intel_pt_pmu, \"tsc\", &tsc_bit);\n\tintel_pt_parse_terms(intel_pt_pmu, \"noretcomp\", &noretcomp_bit);\n\tintel_pt_parse_terms(intel_pt_pmu, \"mtc\", &mtc_bit);\n\tmtc_freq_bits = perf_pmu__format_bits(intel_pt_pmu, \"mtc_period\");\n\tintel_pt_parse_terms(intel_pt_pmu, \"cyc\", &cyc_bit);\n\n\tintel_pt_tsc_ctc_ratio(&tsc_ctc_ratio_n, &tsc_ctc_ratio_d);\n\n\tif (perf_pmu__scan_file(intel_pt_pmu, \"max_nonturbo_ratio\",\n\t\t\t\t\"%lu\", &max_non_turbo_ratio) != 1)\n\t\tmax_non_turbo_ratio = 0;\n\tif (perf_pmu__scan_file(intel_pt_pmu, \"caps/event_trace\",\n\t\t\t\t\"%d\", &event_trace) != 1)\n\t\tevent_trace = 0;\n\n\tfilter = intel_pt_find_filter(session->evlist, ptr->intel_pt_pmu);\n\tfilter_str_len = filter ? strlen(filter) : 0;\n\n\tif (!session->evlist->core.nr_mmaps)\n\t\treturn -EINVAL;\n\n\tpc = session->evlist->mmap[0].core.base;\n\tif (pc) {\n\t\terr = perf_read_tsc_conversion(pc, &tc);\n\t\tif (err) {\n\t\t\tif (err != -EOPNOTSUPP)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tcap_user_time_zero = tc.time_mult != 0;\n\t\t}\n\t\tif (!cap_user_time_zero)\n\t\t\tui__warning(\"Intel Processor Trace: TSC not available\\n\");\n\t}\n\n\tper_cpu_mmaps = !perf_cpu_map__empty(session->evlist->core.user_requested_cpus);\n\n\tauxtrace_info->type = PERF_AUXTRACE_INTEL_PT;\n\tauxtrace_info->priv[INTEL_PT_PMU_TYPE] = intel_pt_pmu->type;\n\tauxtrace_info->priv[INTEL_PT_TIME_SHIFT] = tc.time_shift;\n\tauxtrace_info->priv[INTEL_PT_TIME_MULT] = tc.time_mult;\n\tauxtrace_info->priv[INTEL_PT_TIME_ZERO] = tc.time_zero;\n\tauxtrace_info->priv[INTEL_PT_CAP_USER_TIME_ZERO] = cap_user_time_zero;\n\tauxtrace_info->priv[INTEL_PT_TSC_BIT] = tsc_bit;\n\tauxtrace_info->priv[INTEL_PT_NORETCOMP_BIT] = noretcomp_bit;\n\tauxtrace_info->priv[INTEL_PT_HAVE_SCHED_SWITCH] = ptr->have_sched_switch;\n\tauxtrace_info->priv[INTEL_PT_SNAPSHOT_MODE] = ptr->snapshot_mode;\n\tauxtrace_info->priv[INTEL_PT_PER_CPU_MMAPS] = per_cpu_mmaps;\n\tauxtrace_info->priv[INTEL_PT_MTC_BIT] = mtc_bit;\n\tauxtrace_info->priv[INTEL_PT_MTC_FREQ_BITS] = mtc_freq_bits;\n\tauxtrace_info->priv[INTEL_PT_TSC_CTC_N] = tsc_ctc_ratio_n;\n\tauxtrace_info->priv[INTEL_PT_TSC_CTC_D] = tsc_ctc_ratio_d;\n\tauxtrace_info->priv[INTEL_PT_CYC_BIT] = cyc_bit;\n\tauxtrace_info->priv[INTEL_PT_MAX_NONTURBO_RATIO] = max_non_turbo_ratio;\n\tauxtrace_info->priv[INTEL_PT_FILTER_STR_LEN] = filter_str_len;\n\n\tinfo = &auxtrace_info->priv[INTEL_PT_FILTER_STR_LEN] + 1;\n\n\tif (filter_str_len) {\n\t\tsize_t len = intel_pt_filter_bytes(filter);\n\n\t\tstrncpy((char *)info, filter, len);\n\t\tinfo += len >> 3;\n\t}\n\n\t*info++ = event_trace;\n\n\treturn 0;\n}\n\n#ifdef HAVE_LIBTRACEEVENT\nstatic int intel_pt_track_switches(struct evlist *evlist)\n{\n\tconst char *sched_switch = \"sched:sched_switch\";\n\tstruct evsel *evsel;\n\tint err;\n\n\tif (!evlist__can_select_event(evlist, sched_switch))\n\t\treturn -EPERM;\n\n\tevsel = evlist__add_sched_switch(evlist, true);\n\tif (IS_ERR(evsel)) {\n\t\terr = PTR_ERR(evsel);\n\t\tpr_debug2(\"%s: failed to create %s, error = %d\\n\",\n\t\t\t  __func__, sched_switch, err);\n\t\treturn err;\n\t}\n\n\tevsel->immediate = true;\n\n\treturn 0;\n}\n#endif\n\nstatic void intel_pt_valid_str(char *str, size_t len, u64 valid)\n{\n\tunsigned int val, last = 0, state = 1;\n\tint p = 0;\n\n\tstr[0] = '\\0';\n\n\tfor (val = 0; val <= 64; val++, valid >>= 1) {\n\t\tif (valid & 1) {\n\t\t\tlast = val;\n\t\t\tswitch (state) {\n\t\t\tcase 0:\n\t\t\t\tp += scnprintf(str + p, len - p, \",\");\n\t\t\t\t \n\t\t\tcase 1:\n\t\t\t\tp += scnprintf(str + p, len - p, \"%u\", val);\n\t\t\t\tstate = 2;\n\t\t\t\tbreak;\n\t\t\tcase 2:\n\t\t\t\tstate = 3;\n\t\t\t\tbreak;\n\t\t\tcase 3:\n\t\t\t\tstate = 4;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tswitch (state) {\n\t\t\tcase 3:\n\t\t\t\tp += scnprintf(str + p, len - p, \",%u\", last);\n\t\t\t\tstate = 0;\n\t\t\t\tbreak;\n\t\t\tcase 4:\n\t\t\t\tp += scnprintf(str + p, len - p, \"-%u\", last);\n\t\t\t\tstate = 0;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (state != 1)\n\t\t\t\tstate = 0;\n\t\t}\n\t}\n}\n\nstatic int intel_pt_val_config_term(struct perf_pmu *intel_pt_pmu, int dirfd,\n\t\t\t\t    const char *caps, const char *name,\n\t\t\t\t    const char *supported, u64 config)\n{\n\tchar valid_str[256];\n\tunsigned int shift;\n\tunsigned long long valid;\n\tu64 bits;\n\tint ok;\n\n\tif (perf_pmu__scan_file_at(intel_pt_pmu, dirfd, caps, \"%llx\", &valid) != 1)\n\t\tvalid = 0;\n\n\tif (supported &&\n\t    perf_pmu__scan_file_at(intel_pt_pmu, dirfd, supported, \"%d\", &ok) == 1 && !ok)\n\t\tvalid = 0;\n\n\tvalid |= 1;\n\n\tbits = perf_pmu__format_bits(intel_pt_pmu, name);\n\n\tconfig &= bits;\n\n\tfor (shift = 0; bits && !(bits & 1); shift++)\n\t\tbits >>= 1;\n\n\tconfig >>= shift;\n\n\tif (config > 63)\n\t\tgoto out_err;\n\n\tif (valid & (1 << config))\n\t\treturn 0;\nout_err:\n\tintel_pt_valid_str(valid_str, sizeof(valid_str), valid);\n\tpr_err(\"Invalid %s for %s. Valid values are: %s\\n\",\n\t       name, INTEL_PT_PMU_NAME, valid_str);\n\treturn -EINVAL;\n}\n\nstatic int intel_pt_validate_config(struct perf_pmu *intel_pt_pmu,\n\t\t\t\t    struct evsel *evsel)\n{\n\tint err, dirfd;\n\tchar c;\n\n\tif (!evsel)\n\t\treturn 0;\n\n\tdirfd = perf_pmu__event_source_devices_fd();\n\tif (dirfd < 0)\n\t\treturn dirfd;\n\n\t \n\tif (perf_pmu__scan_file_at(intel_pt_pmu, dirfd, \"format/pt\", \"%c\", &c) == 1 &&\n\t    !(evsel->core.attr.config & 1)) {\n\t\tpr_warning(\"pt=0 doesn't make sense, forcing pt=1\\n\");\n\t\tevsel->core.attr.config |= 1;\n\t}\n\n\terr = intel_pt_val_config_term(intel_pt_pmu, dirfd, \"caps/cycle_thresholds\",\n\t\t\t\t       \"cyc_thresh\", \"caps/psb_cyc\",\n\t\t\t\t       evsel->core.attr.config);\n\tif (err)\n\t\tgoto out;\n\n\terr = intel_pt_val_config_term(intel_pt_pmu, dirfd, \"caps/mtc_periods\",\n\t\t\t\t       \"mtc_period\", \"caps/mtc\",\n\t\t\t\t       evsel->core.attr.config);\n\tif (err)\n\t\tgoto out;\n\n\terr = intel_pt_val_config_term(intel_pt_pmu, dirfd, \"caps/psb_periods\",\n\t\t\t\t\t\"psb_period\", \"caps/psb_cyc\",\n\t\t\t\t\tevsel->core.attr.config);\n\nout:\n\tclose(dirfd);\n\treturn err;\n}\n\nstatic void intel_pt_min_max_sample_sz(struct evlist *evlist,\n\t\t\t\t       size_t *min_sz, size_t *max_sz)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tsize_t sz = evsel->core.attr.aux_sample_size;\n\n\t\tif (!sz)\n\t\t\tcontinue;\n\t\tif (min_sz && (sz < *min_sz || !*min_sz))\n\t\t\t*min_sz = sz;\n\t\tif (max_sz && sz > *max_sz)\n\t\t\t*max_sz = sz;\n\t}\n}\n\n \nstatic bool intel_pt_too_many_aux_output(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tint aux_output_cnt = 0;\n\n\tevlist__for_each_entry(evlist, evsel)\n\t\taux_output_cnt += !!evsel->core.attr.aux_output;\n\n\tif (aux_output_cnt > 1) {\n\t\tpr_err(INTEL_PT_PMU_NAME \" supports at most one event with aux-output\\n\");\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int intel_pt_recording_options(struct auxtrace_record *itr,\n\t\t\t\t      struct evlist *evlist,\n\t\t\t\t      struct record_opts *opts)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\tstruct perf_pmu *intel_pt_pmu = ptr->intel_pt_pmu;\n\tbool have_timing_info, need_immediate = false;\n\tstruct evsel *evsel, *intel_pt_evsel = NULL;\n\tconst struct perf_cpu_map *cpus = evlist->core.user_requested_cpus;\n\tbool privileged = perf_event_paranoid_check(-1);\n\tu64 tsc_bit;\n\tint err;\n\n\tptr->evlist = evlist;\n\tptr->snapshot_mode = opts->auxtrace_snapshot_mode;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.type == intel_pt_pmu->type) {\n\t\t\tif (intel_pt_evsel) {\n\t\t\t\tpr_err(\"There may be only one \" INTEL_PT_PMU_NAME \" event\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tevsel->core.attr.freq = 0;\n\t\t\tevsel->core.attr.sample_period = 1;\n\t\t\tevsel->no_aux_samples = true;\n\t\t\tevsel->needs_auxtrace_mmap = true;\n\t\t\tintel_pt_evsel = evsel;\n\t\t\topts->full_auxtrace = true;\n\t\t}\n\t}\n\n\tif (opts->auxtrace_snapshot_mode && !opts->full_auxtrace) {\n\t\tpr_err(\"Snapshot mode (-S option) requires \" INTEL_PT_PMU_NAME \" PMU event (-e \" INTEL_PT_PMU_NAME \")\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (opts->auxtrace_snapshot_mode && opts->auxtrace_sample_mode) {\n\t\tpr_err(\"Snapshot mode (\" INTEL_PT_PMU_NAME \" PMU) and sample trace cannot be used together\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (opts->use_clockid) {\n\t\tpr_err(\"Cannot use clockid (-k option) with \" INTEL_PT_PMU_NAME \"\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (intel_pt_too_many_aux_output(evlist))\n\t\treturn -EINVAL;\n\n\tif (!opts->full_auxtrace)\n\t\treturn 0;\n\n\tif (opts->auxtrace_sample_mode)\n\t\tevsel__set_config_if_unset(intel_pt_pmu, intel_pt_evsel,\n\t\t\t\t\t   \"psb_period\", 0);\n\n\terr = intel_pt_validate_config(intel_pt_pmu, intel_pt_evsel);\n\tif (err)\n\t\treturn err;\n\n\t \n\tif (opts->auxtrace_snapshot_mode) {\n\t\tsize_t psb_period = intel_pt_psb_period(intel_pt_pmu, evlist);\n\n\t\tif (!opts->auxtrace_snapshot_size && !opts->auxtrace_mmap_pages) {\n\t\t\tif (privileged) {\n\t\t\t\topts->auxtrace_mmap_pages = MiB(4) / page_size;\n\t\t\t} else {\n\t\t\t\topts->auxtrace_mmap_pages = KiB(128) / page_size;\n\t\t\t\tif (opts->mmap_pages == UINT_MAX)\n\t\t\t\t\topts->mmap_pages = KiB(256) / page_size;\n\t\t\t}\n\t\t} else if (!opts->auxtrace_mmap_pages && !privileged &&\n\t\t\t   opts->mmap_pages == UINT_MAX) {\n\t\t\topts->mmap_pages = KiB(256) / page_size;\n\t\t}\n\t\tif (!opts->auxtrace_snapshot_size)\n\t\t\topts->auxtrace_snapshot_size =\n\t\t\t\topts->auxtrace_mmap_pages * (size_t)page_size;\n\t\tif (!opts->auxtrace_mmap_pages) {\n\t\t\tsize_t sz = opts->auxtrace_snapshot_size;\n\n\t\t\tsz = round_up(sz, page_size) / page_size;\n\t\t\topts->auxtrace_mmap_pages = roundup_pow_of_two(sz);\n\t\t}\n\t\tif (opts->auxtrace_snapshot_size >\n\t\t\t\topts->auxtrace_mmap_pages * (size_t)page_size) {\n\t\t\tpr_err(\"Snapshot size %zu must not be greater than AUX area tracing mmap size %zu\\n\",\n\t\t\t       opts->auxtrace_snapshot_size,\n\t\t\t       opts->auxtrace_mmap_pages * (size_t)page_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!opts->auxtrace_snapshot_size || !opts->auxtrace_mmap_pages) {\n\t\t\tpr_err(\"Failed to calculate default snapshot size and/or AUX area tracing mmap pages\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tpr_debug2(\"Intel PT snapshot size: %zu\\n\",\n\t\t\t  opts->auxtrace_snapshot_size);\n\t\tif (psb_period &&\n\t\t    opts->auxtrace_snapshot_size <= psb_period +\n\t\t\t\t\t\t  INTEL_PT_PSB_PERIOD_NEAR)\n\t\t\tui__warning(\"Intel PT snapshot size (%zu) may be too small for PSB period (%zu)\\n\",\n\t\t\t\t    opts->auxtrace_snapshot_size, psb_period);\n\t}\n\n\t \n\tif (opts->auxtrace_sample_mode) {\n\t\tsize_t psb_period = intel_pt_psb_period(intel_pt_pmu, evlist);\n\t\tsize_t min_sz = 0, max_sz = 0;\n\n\t\tintel_pt_min_max_sample_sz(evlist, &min_sz, &max_sz);\n\t\tif (!opts->auxtrace_mmap_pages && !privileged &&\n\t\t    opts->mmap_pages == UINT_MAX)\n\t\t\topts->mmap_pages = KiB(256) / page_size;\n\t\tif (!opts->auxtrace_mmap_pages) {\n\t\t\tsize_t sz = round_up(max_sz, page_size) / page_size;\n\n\t\t\topts->auxtrace_mmap_pages = roundup_pow_of_two(sz);\n\t\t}\n\t\tif (max_sz > opts->auxtrace_mmap_pages * (size_t)page_size) {\n\t\t\tpr_err(\"Sample size %zu must not be greater than AUX area tracing mmap size %zu\\n\",\n\t\t\t       max_sz,\n\t\t\t       opts->auxtrace_mmap_pages * (size_t)page_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tpr_debug2(\"Intel PT min. sample size: %zu max. sample size: %zu\\n\",\n\t\t\t  min_sz, max_sz);\n\t\tif (psb_period &&\n\t\t    min_sz <= psb_period + INTEL_PT_PSB_PERIOD_NEAR)\n\t\t\tui__warning(\"Intel PT sample size (%zu) may be too small for PSB period (%zu)\\n\",\n\t\t\t\t    min_sz, psb_period);\n\t}\n\n\t \n\tif (opts->full_auxtrace && !opts->auxtrace_mmap_pages) {\n\t\tif (privileged) {\n\t\t\topts->auxtrace_mmap_pages = MiB(4) / page_size;\n\t\t} else {\n\t\t\topts->auxtrace_mmap_pages = KiB(128) / page_size;\n\t\t\tif (opts->mmap_pages == UINT_MAX)\n\t\t\t\topts->mmap_pages = KiB(256) / page_size;\n\t\t}\n\t}\n\n\t \n\tif (opts->auxtrace_mmap_pages) {\n\t\tsize_t sz = opts->auxtrace_mmap_pages * (size_t)page_size;\n\t\tsize_t min_sz;\n\n\t\tif (opts->auxtrace_snapshot_mode || opts->auxtrace_sample_mode)\n\t\t\tmin_sz = KiB(4);\n\t\telse\n\t\t\tmin_sz = KiB(8);\n\n\t\tif (sz < min_sz || !is_power_of_2(sz)) {\n\t\t\tpr_err(\"Invalid mmap size for Intel Processor Trace: must be at least %zuKiB and a power of 2\\n\",\n\t\t\t       min_sz / 1024);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!opts->auxtrace_snapshot_mode && !opts->auxtrace_sample_mode) {\n\t\tu32 aux_watermark = opts->auxtrace_mmap_pages * page_size / 4;\n\n\t\tintel_pt_evsel->core.attr.aux_watermark = aux_watermark;\n\t}\n\n\tintel_pt_parse_terms(intel_pt_pmu, \"tsc\", &tsc_bit);\n\n\tif (opts->full_auxtrace && (intel_pt_evsel->core.attr.config & tsc_bit))\n\t\thave_timing_info = true;\n\telse\n\t\thave_timing_info = false;\n\n\t \n\tif (have_timing_info && !perf_cpu_map__empty(cpus) &&\n\t    !record_opts__no_switch_events(opts)) {\n\t\tif (perf_can_record_switch_events()) {\n\t\t\tbool cpu_wide = !target__none(&opts->target) &&\n\t\t\t\t\t!target__has_task(&opts->target);\n\n\t\t\tif (!cpu_wide && perf_can_record_cpu_wide()) {\n\t\t\t\tstruct evsel *switch_evsel;\n\n\t\t\t\tswitch_evsel = evlist__add_dummy_on_all_cpus(evlist);\n\t\t\t\tif (!switch_evsel)\n\t\t\t\t\treturn -ENOMEM;\n\n\t\t\t\tswitch_evsel->core.attr.context_switch = 1;\n\t\t\t\tswitch_evsel->immediate = true;\n\n\t\t\t\tevsel__set_sample_bit(switch_evsel, TID);\n\t\t\t\tevsel__set_sample_bit(switch_evsel, TIME);\n\t\t\t\tevsel__set_sample_bit(switch_evsel, CPU);\n\t\t\t\tevsel__reset_sample_bit(switch_evsel, BRANCH_STACK);\n\n\t\t\t\topts->record_switch_events = false;\n\t\t\t\tptr->have_sched_switch = 3;\n\t\t\t} else {\n\t\t\t\topts->record_switch_events = true;\n\t\t\t\tneed_immediate = true;\n\t\t\t\tif (cpu_wide)\n\t\t\t\t\tptr->have_sched_switch = 3;\n\t\t\t\telse\n\t\t\t\t\tptr->have_sched_switch = 2;\n\t\t\t}\n\t\t} else {\n#ifdef HAVE_LIBTRACEEVENT\n\t\t\terr = intel_pt_track_switches(evlist);\n\t\t\tif (err == -EPERM)\n\t\t\t\tpr_debug2(\"Unable to select sched:sched_switch\\n\");\n\t\t\telse if (err)\n\t\t\t\treturn err;\n\t\t\telse\n\t\t\t\tptr->have_sched_switch = 1;\n#endif\n\t\t}\n\t}\n\n\tif (have_timing_info && !intel_pt_evsel->core.attr.exclude_kernel &&\n\t    perf_can_record_text_poke_events() && perf_can_record_cpu_wide())\n\t\topts->text_poke = true;\n\n\tif (intel_pt_evsel) {\n\t\t \n\t\tevlist__to_front(evlist, intel_pt_evsel);\n\t\t \n\t\tif (!perf_cpu_map__empty(cpus))\n\t\t\tevsel__set_sample_bit(intel_pt_evsel, CPU);\n\t}\n\n\t \n\tif (opts->full_auxtrace) {\n\t\tbool need_system_wide_tracking;\n\t\tstruct evsel *tracking_evsel;\n\n\t\t \n\t\tneed_system_wide_tracking = opts->target.cpu_list &&\n\t\t\t\t\t    !intel_pt_evsel->core.attr.exclude_user;\n\n\t\ttracking_evsel = evlist__add_aux_dummy(evlist, need_system_wide_tracking);\n\t\tif (!tracking_evsel)\n\t\t\treturn -ENOMEM;\n\n\t\tevlist__set_tracking_event(evlist, tracking_evsel);\n\n\t\tif (need_immediate)\n\t\t\ttracking_evsel->immediate = true;\n\n\t\t \n\t\tif (!perf_cpu_map__empty(cpus)) {\n\t\t\tevsel__set_sample_bit(tracking_evsel, TIME);\n\t\t\t \n\t\t\tevsel__set_sample_bit(tracking_evsel, CPU);\n\t\t}\n\t\tevsel__reset_sample_bit(tracking_evsel, BRANCH_STACK);\n\t}\n\n\t \n\tif (!ptr->have_sched_switch && !perf_cpu_map__empty(cpus) &&\n\t    !target__none(&opts->target) &&\n\t    !intel_pt_evsel->core.attr.exclude_user)\n\t\tui__warning(\"Intel Processor Trace decoding will not be possible except for kernel tracing!\\n\");\n\n\treturn 0;\n}\n\nstatic int intel_pt_snapshot_start(struct auxtrace_record *itr)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(ptr->evlist, evsel) {\n\t\tif (evsel->core.attr.type == ptr->intel_pt_pmu->type)\n\t\t\treturn evsel__disable(evsel);\n\t}\n\treturn -EINVAL;\n}\n\nstatic int intel_pt_snapshot_finish(struct auxtrace_record *itr)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(ptr->evlist, evsel) {\n\t\tif (evsel->core.attr.type == ptr->intel_pt_pmu->type)\n\t\t\treturn evsel__enable(evsel);\n\t}\n\treturn -EINVAL;\n}\n\nstatic int intel_pt_alloc_snapshot_refs(struct intel_pt_recording *ptr, int idx)\n{\n\tconst size_t sz = sizeof(struct intel_pt_snapshot_ref);\n\tint cnt = ptr->snapshot_ref_cnt, new_cnt = cnt * 2;\n\tstruct intel_pt_snapshot_ref *refs;\n\n\tif (!new_cnt)\n\t\tnew_cnt = 16;\n\n\twhile (new_cnt <= idx)\n\t\tnew_cnt *= 2;\n\n\trefs = calloc(new_cnt, sz);\n\tif (!refs)\n\t\treturn -ENOMEM;\n\n\tmemcpy(refs, ptr->snapshot_refs, cnt * sz);\n\n\tptr->snapshot_refs = refs;\n\tptr->snapshot_ref_cnt = new_cnt;\n\n\treturn 0;\n}\n\nstatic void intel_pt_free_snapshot_refs(struct intel_pt_recording *ptr)\n{\n\tint i;\n\n\tfor (i = 0; i < ptr->snapshot_ref_cnt; i++)\n\t\tzfree(&ptr->snapshot_refs[i].ref_buf);\n\tzfree(&ptr->snapshot_refs);\n}\n\nstatic void intel_pt_recording_free(struct auxtrace_record *itr)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\n\tintel_pt_free_snapshot_refs(ptr);\n\tfree(ptr);\n}\n\nstatic int intel_pt_alloc_snapshot_ref(struct intel_pt_recording *ptr, int idx,\n\t\t\t\t       size_t snapshot_buf_size)\n{\n\tsize_t ref_buf_size = ptr->snapshot_ref_buf_size;\n\tvoid *ref_buf;\n\n\tref_buf = zalloc(ref_buf_size);\n\tif (!ref_buf)\n\t\treturn -ENOMEM;\n\n\tptr->snapshot_refs[idx].ref_buf = ref_buf;\n\tptr->snapshot_refs[idx].ref_offset = snapshot_buf_size - ref_buf_size;\n\n\treturn 0;\n}\n\nstatic size_t intel_pt_snapshot_ref_buf_size(struct intel_pt_recording *ptr,\n\t\t\t\t\t     size_t snapshot_buf_size)\n{\n\tconst size_t max_size = 256 * 1024;\n\tsize_t buf_size = 0, psb_period;\n\n\tif (ptr->snapshot_size <= 64 * 1024)\n\t\treturn 0;\n\n\tpsb_period = intel_pt_psb_period(ptr->intel_pt_pmu, ptr->evlist);\n\tif (psb_period)\n\t\tbuf_size = psb_period * 2;\n\n\tif (!buf_size || buf_size > max_size)\n\t\tbuf_size = max_size;\n\n\tif (buf_size >= snapshot_buf_size)\n\t\treturn 0;\n\n\tif (buf_size >= ptr->snapshot_size / 2)\n\t\treturn 0;\n\n\treturn buf_size;\n}\n\nstatic int intel_pt_snapshot_init(struct intel_pt_recording *ptr,\n\t\t\t\t  size_t snapshot_buf_size)\n{\n\tif (ptr->snapshot_init_done)\n\t\treturn 0;\n\n\tptr->snapshot_init_done = true;\n\n\tptr->snapshot_ref_buf_size = intel_pt_snapshot_ref_buf_size(ptr,\n\t\t\t\t\t\t\tsnapshot_buf_size);\n\n\treturn 0;\n}\n\n \nstatic bool intel_pt_compare_buffers(void *buf1, size_t compare_size,\n\t\t\t\t     void *buf2, size_t offs2, size_t buf2_size)\n{\n\tsize_t end2 = offs2 + compare_size, part_size;\n\n\tif (end2 <= buf2_size)\n\t\treturn memcmp(buf1, buf2 + offs2, compare_size);\n\n\tpart_size = end2 - buf2_size;\n\tif (memcmp(buf1, buf2 + offs2, part_size))\n\t\treturn true;\n\n\tcompare_size -= part_size;\n\n\treturn memcmp(buf1 + part_size, buf2, compare_size);\n}\n\nstatic bool intel_pt_compare_ref(void *ref_buf, size_t ref_offset,\n\t\t\t\t size_t ref_size, size_t buf_size,\n\t\t\t\t void *data, size_t head)\n{\n\tsize_t ref_end = ref_offset + ref_size;\n\n\tif (ref_end > buf_size) {\n\t\tif (head > ref_offset || head < ref_end - buf_size)\n\t\t\treturn true;\n\t} else if (head > ref_offset && head < ref_end) {\n\t\treturn true;\n\t}\n\n\treturn intel_pt_compare_buffers(ref_buf, ref_size, data, ref_offset,\n\t\t\t\t\tbuf_size);\n}\n\nstatic void intel_pt_copy_ref(void *ref_buf, size_t ref_size, size_t buf_size,\n\t\t\t      void *data, size_t head)\n{\n\tif (head >= ref_size) {\n\t\tmemcpy(ref_buf, data + head - ref_size, ref_size);\n\t} else {\n\t\tmemcpy(ref_buf, data, head);\n\t\tref_size -= head;\n\t\tmemcpy(ref_buf + head, data + buf_size - ref_size, ref_size);\n\t}\n}\n\nstatic bool intel_pt_wrapped(struct intel_pt_recording *ptr, int idx,\n\t\t\t     struct auxtrace_mmap *mm, unsigned char *data,\n\t\t\t     u64 head)\n{\n\tstruct intel_pt_snapshot_ref *ref = &ptr->snapshot_refs[idx];\n\tbool wrapped;\n\n\twrapped = intel_pt_compare_ref(ref->ref_buf, ref->ref_offset,\n\t\t\t\t       ptr->snapshot_ref_buf_size, mm->len,\n\t\t\t\t       data, head);\n\n\tintel_pt_copy_ref(ref->ref_buf, ptr->snapshot_ref_buf_size, mm->len,\n\t\t\t  data, head);\n\n\treturn wrapped;\n}\n\nstatic bool intel_pt_first_wrap(u64 *data, size_t buf_size)\n{\n\tint i, a, b;\n\n\tb = buf_size >> 3;\n\ta = b - 512;\n\tif (a < 0)\n\t\ta = 0;\n\n\tfor (i = a; i < b; i++) {\n\t\tif (data[i])\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int intel_pt_find_snapshot(struct auxtrace_record *itr, int idx,\n\t\t\t\t  struct auxtrace_mmap *mm, unsigned char *data,\n\t\t\t\t  u64 *head, u64 *old)\n{\n\tstruct intel_pt_recording *ptr =\n\t\t\tcontainer_of(itr, struct intel_pt_recording, itr);\n\tbool wrapped;\n\tint err;\n\n\tpr_debug3(\"%s: mmap index %d old head %zu new head %zu\\n\",\n\t\t  __func__, idx, (size_t)*old, (size_t)*head);\n\n\terr = intel_pt_snapshot_init(ptr, mm->len);\n\tif (err)\n\t\tgoto out_err;\n\n\tif (idx >= ptr->snapshot_ref_cnt) {\n\t\terr = intel_pt_alloc_snapshot_refs(ptr, idx);\n\t\tif (err)\n\t\t\tgoto out_err;\n\t}\n\n\tif (ptr->snapshot_ref_buf_size) {\n\t\tif (!ptr->snapshot_refs[idx].ref_buf) {\n\t\t\terr = intel_pt_alloc_snapshot_ref(ptr, idx, mm->len);\n\t\t\tif (err)\n\t\t\t\tgoto out_err;\n\t\t}\n\t\twrapped = intel_pt_wrapped(ptr, idx, mm, data, *head);\n\t} else {\n\t\twrapped = ptr->snapshot_refs[idx].wrapped;\n\t\tif (!wrapped && intel_pt_first_wrap((u64 *)data, mm->len)) {\n\t\t\tptr->snapshot_refs[idx].wrapped = true;\n\t\t\twrapped = true;\n\t\t}\n\t}\n\n\t \n\tif (wrapped) {\n\t\t*old = *head;\n\t\t*head += mm->len;\n\t} else {\n\t\tif (mm->mask)\n\t\t\t*old &= mm->mask;\n\t\telse\n\t\t\t*old %= mm->len;\n\t\tif (*old > *head)\n\t\t\t*head += mm->len;\n\t}\n\n\tpr_debug3(\"%s: wrap-around %sdetected, adjusted old head %zu adjusted new head %zu\\n\",\n\t\t  __func__, wrapped ? \"\" : \"not \", (size_t)*old, (size_t)*head);\n\n\treturn 0;\n\nout_err:\n\tpr_err(\"%s: failed, error %d\\n\", __func__, err);\n\treturn err;\n}\n\nstatic u64 intel_pt_reference(struct auxtrace_record *itr __maybe_unused)\n{\n\treturn rdtsc();\n}\n\nstruct auxtrace_record *intel_pt_recording_init(int *err)\n{\n\tstruct perf_pmu *intel_pt_pmu = perf_pmus__find(INTEL_PT_PMU_NAME);\n\tstruct intel_pt_recording *ptr;\n\n\tif (!intel_pt_pmu)\n\t\treturn NULL;\n\n\tif (setenv(\"JITDUMP_USE_ARCH_TIMESTAMP\", \"1\", 1)) {\n\t\t*err = -errno;\n\t\treturn NULL;\n\t}\n\n\tptr = zalloc(sizeof(struct intel_pt_recording));\n\tif (!ptr) {\n\t\t*err = -ENOMEM;\n\t\treturn NULL;\n\t}\n\n\tptr->intel_pt_pmu = intel_pt_pmu;\n\tptr->itr.pmu = intel_pt_pmu;\n\tptr->itr.recording_options = intel_pt_recording_options;\n\tptr->itr.info_priv_size = intel_pt_info_priv_size;\n\tptr->itr.info_fill = intel_pt_info_fill;\n\tptr->itr.free = intel_pt_recording_free;\n\tptr->itr.snapshot_start = intel_pt_snapshot_start;\n\tptr->itr.snapshot_finish = intel_pt_snapshot_finish;\n\tptr->itr.find_snapshot = intel_pt_find_snapshot;\n\tptr->itr.parse_snapshot_options = intel_pt_parse_snapshot_options;\n\tptr->itr.reference = intel_pt_reference;\n\tptr->itr.read_finish = auxtrace_record__read_finish;\n\t \n\tptr->itr.default_aux_sample_size = 4096;\n\treturn &ptr->itr;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}