{
  "module_name": "bpf_counter_cgroup.c",
  "hash_id": "cb1887d9bff088370f26c96764c41e71089739ad885c33d9addc4e53aca03fcc",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/bpf_counter_cgroup.c",
  "human_readable_source": "\n\n \n \n\n#include <assert.h>\n#include <limits.h>\n#include <unistd.h>\n#include <sys/file.h>\n#include <sys/time.h>\n#include <sys/resource.h>\n#include <linux/err.h>\n#include <linux/zalloc.h>\n#include <linux/perf_event.h>\n#include <api/fs/fs.h>\n#include <perf/bpf_perf.h>\n\n#include \"affinity.h\"\n#include \"bpf_counter.h\"\n#include \"cgroup.h\"\n#include \"counts.h\"\n#include \"debug.h\"\n#include \"evsel.h\"\n#include \"evlist.h\"\n#include \"target.h\"\n#include \"cpumap.h\"\n#include \"thread_map.h\"\n\n#include \"bpf_skel/bperf_cgroup.skel.h\"\n\nstatic struct perf_event_attr cgrp_switch_attr = {\n\t.type = PERF_TYPE_SOFTWARE,\n\t.config = PERF_COUNT_SW_CGROUP_SWITCHES,\n\t.size = sizeof(cgrp_switch_attr),\n\t.sample_period = 1,\n\t.disabled = 1,\n};\n\nstatic struct evsel *cgrp_switch;\nstatic struct bperf_cgroup_bpf *skel;\n\n#define FD(evt, cpu) (*(int *)xyarray__entry(evt->core.fd, cpu, 0))\n\nstatic int bperf_load_program(struct evlist *evlist)\n{\n\tstruct bpf_link *link;\n\tstruct evsel *evsel;\n\tstruct cgroup *cgrp, *leader_cgrp;\n\tint i, j;\n\tstruct perf_cpu cpu;\n\tint total_cpus = cpu__max_cpu().cpu;\n\tint map_size, map_fd;\n\tint prog_fd, err;\n\n\tskel = bperf_cgroup_bpf__open();\n\tif (!skel) {\n\t\tpr_err(\"Failed to open cgroup skeleton\\n\");\n\t\treturn -1;\n\t}\n\n\tskel->rodata->num_cpus = total_cpus;\n\tskel->rodata->num_events = evlist->core.nr_entries / nr_cgroups;\n\n\tBUG_ON(evlist->core.nr_entries % nr_cgroups != 0);\n\n\t \n\tmap_size = total_cpus * evlist->core.nr_entries / nr_cgroups;\n\tbpf_map__set_max_entries(skel->maps.events, map_size);\n\tbpf_map__set_max_entries(skel->maps.cgrp_idx, nr_cgroups);\n\t \n\tmap_size = evlist->core.nr_entries / nr_cgroups;\n\tbpf_map__set_max_entries(skel->maps.prev_readings, map_size);\n\t \n\tmap_size = evlist->core.nr_entries;\n\tbpf_map__set_max_entries(skel->maps.cgrp_readings, map_size);\n\n\tset_max_rlimit();\n\n\terr = bperf_cgroup_bpf__load(skel);\n\tif (err) {\n\t\tpr_err(\"Failed to load cgroup skeleton\\n\");\n\t\tgoto out;\n\t}\n\n\tif (cgroup_is_v2(\"perf_event\") > 0)\n\t\tskel->bss->use_cgroup_v2 = 1;\n\n\terr = -1;\n\n\tcgrp_switch = evsel__new(&cgrp_switch_attr);\n\tif (evsel__open_per_cpu(cgrp_switch, evlist->core.all_cpus, -1) < 0) {\n\t\tpr_err(\"Failed to open cgroup switches event\\n\");\n\t\tgoto out;\n\t}\n\n\tperf_cpu_map__for_each_cpu(cpu, i, evlist->core.all_cpus) {\n\t\tlink = bpf_program__attach_perf_event(skel->progs.on_cgrp_switch,\n\t\t\t\t\t\t      FD(cgrp_switch, i));\n\t\tif (IS_ERR(link)) {\n\t\t\tpr_err(\"Failed to attach cgroup program\\n\");\n\t\t\terr = PTR_ERR(link);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tcgrp = NULL;\n\ti = 0;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (cgrp == NULL || evsel->cgrp == leader_cgrp) {\n\t\t\tleader_cgrp = evsel->cgrp;\n\t\t\tevsel->cgrp = NULL;\n\n\t\t\t \n\t\t\terr = evsel__open_per_cpu(evsel, evsel->core.cpus, -1);\n\t\t\tif (err == 0)\n\t\t\t\tevsel->supported = true;\n\n\t\t\tmap_fd = bpf_map__fd(skel->maps.events);\n\t\t\tperf_cpu_map__for_each_cpu(cpu, j, evsel->core.cpus) {\n\t\t\t\tint fd = FD(evsel, j);\n\t\t\t\t__u32 idx = evsel->core.idx * total_cpus + cpu.cpu;\n\n\t\t\t\tbpf_map_update_elem(map_fd, &idx, &fd, BPF_ANY);\n\t\t\t}\n\n\t\t\tevsel->cgrp = leader_cgrp;\n\t\t}\n\n\t\tif (evsel->cgrp == cgrp)\n\t\t\tcontinue;\n\n\t\tcgrp = evsel->cgrp;\n\n\t\tif (read_cgroup_id(cgrp) < 0) {\n\t\t\tpr_err(\"Failed to get cgroup id\\n\");\n\t\t\terr = -1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmap_fd = bpf_map__fd(skel->maps.cgrp_idx);\n\t\terr = bpf_map_update_elem(map_fd, &cgrp->id, &i, BPF_ANY);\n\t\tif (err < 0) {\n\t\t\tpr_err(\"Failed to update cgroup index map\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\ti++;\n\t}\n\n\t \n\tprog_fd = bpf_program__fd(skel->progs.trigger_read);\n\terr = bperf_trigger_reading(prog_fd, 0);\n\tif (err) {\n\t\tpr_warning(\"The kernel does not support test_run for raw_tp BPF programs.\\n\"\n\t\t\t   \"Therefore, --for-each-cgroup might show inaccurate readings\\n\");\n\t\terr = 0;\n\t}\n\nout:\n\treturn err;\n}\n\nstatic int bperf_cgrp__load(struct evsel *evsel,\n\t\t\t    struct target *target __maybe_unused)\n{\n\tstatic bool bperf_loaded = false;\n\n\tevsel->bperf_leader_prog_fd = -1;\n\tevsel->bperf_leader_link_fd = -1;\n\n\tif (!bperf_loaded && bperf_load_program(evsel->evlist))\n\t\treturn -1;\n\n\tbperf_loaded = true;\n\t \n\tevsel->follower_skel = (struct bperf_follower_bpf *)skel;\n\n\treturn 0;\n}\n\nstatic int bperf_cgrp__install_pe(struct evsel *evsel __maybe_unused,\n\t\t\t\t  int cpu __maybe_unused, int fd __maybe_unused)\n{\n\t \n\treturn 0;\n}\n\n \nstatic int bperf_cgrp__sync_counters(struct evlist *evlist)\n{\n\tstruct perf_cpu cpu;\n\tint idx;\n\tint prog_fd = bpf_program__fd(skel->progs.trigger_read);\n\n\tperf_cpu_map__for_each_cpu(cpu, idx, evlist->core.all_cpus)\n\t\tbperf_trigger_reading(prog_fd, cpu.cpu);\n\n\treturn 0;\n}\n\nstatic int bperf_cgrp__enable(struct evsel *evsel)\n{\n\tif (evsel->core.idx)\n\t\treturn 0;\n\n\tbperf_cgrp__sync_counters(evsel->evlist);\n\n\tskel->bss->enabled = 1;\n\treturn 0;\n}\n\nstatic int bperf_cgrp__disable(struct evsel *evsel)\n{\n\tif (evsel->core.idx)\n\t\treturn 0;\n\n\tbperf_cgrp__sync_counters(evsel->evlist);\n\n\tskel->bss->enabled = 0;\n\treturn 0;\n}\n\nstatic int bperf_cgrp__read(struct evsel *evsel)\n{\n\tstruct evlist *evlist = evsel->evlist;\n\tint total_cpus = cpu__max_cpu().cpu;\n\tstruct perf_counts_values *counts;\n\tstruct bpf_perf_event_value *values;\n\tint reading_map_fd, err = 0;\n\n\tif (evsel->core.idx)\n\t\treturn 0;\n\n\tbperf_cgrp__sync_counters(evsel->evlist);\n\n\tvalues = calloc(total_cpus, sizeof(*values));\n\tif (values == NULL)\n\t\treturn -ENOMEM;\n\n\treading_map_fd = bpf_map__fd(skel->maps.cgrp_readings);\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\t__u32 idx = evsel->core.idx;\n\t\tint i;\n\t\tstruct perf_cpu cpu;\n\n\t\terr = bpf_map_lookup_elem(reading_map_fd, &idx, values);\n\t\tif (err) {\n\t\t\tpr_err(\"bpf map lookup failed: idx=%u, event=%s, cgrp=%s\\n\",\n\t\t\t       idx, evsel__name(evsel), evsel->cgrp->name);\n\t\t\tgoto out;\n\t\t}\n\n\t\tperf_cpu_map__for_each_cpu(cpu, i, evsel->core.cpus) {\n\t\t\tcounts = perf_counts(evsel->counts, i, 0);\n\t\t\tcounts->val = values[cpu.cpu].counter;\n\t\t\tcounts->ena = values[cpu.cpu].enabled;\n\t\t\tcounts->run = values[cpu.cpu].running;\n\t\t}\n\t}\n\nout:\n\tfree(values);\n\treturn err;\n}\n\nstatic int bperf_cgrp__destroy(struct evsel *evsel)\n{\n\tif (evsel->core.idx)\n\t\treturn 0;\n\n\tbperf_cgroup_bpf__destroy(skel);\n\tevsel__delete(cgrp_switch);  \n\n\treturn 0;\n}\n\nstruct bpf_counter_ops bperf_cgrp_ops = {\n\t.load       = bperf_cgrp__load,\n\t.enable     = bperf_cgrp__enable,\n\t.disable    = bperf_cgrp__disable,\n\t.read       = bperf_cgrp__read,\n\t.install_pe = bperf_cgrp__install_pe,\n\t.destroy    = bperf_cgrp__destroy,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}