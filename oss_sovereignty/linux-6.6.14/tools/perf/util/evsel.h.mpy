{
  "module_name": "evsel.h",
  "hash_id": "d7158baf63bb976770b7306cfdfd7f496a82295fb0faa120945d24adf75f1a51",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/evsel.h",
  "human_readable_source": " \n#ifndef __PERF_EVSEL_H\n#define __PERF_EVSEL_H 1\n\n#include <linux/list.h>\n#include <stdbool.h>\n#include <sys/types.h>\n#include <linux/perf_event.h>\n#include <linux/types.h>\n#include <internal/evsel.h>\n#include <perf/evsel.h>\n#include \"symbol_conf.h\"\n#include \"pmus.h\"\n\nstruct bpf_object;\nstruct cgroup;\nstruct perf_counts;\nstruct perf_stat_evsel;\nunion perf_event;\nstruct bpf_counter_ops;\nstruct target;\nstruct hashmap;\nstruct bperf_leader_bpf;\nstruct bperf_follower_bpf;\nstruct perf_pmu;\n\ntypedef int (evsel__sb_cb_t)(union perf_event *event, void *data);\n\nenum perf_tool_event {\n\tPERF_TOOL_NONE\t\t= 0,\n\tPERF_TOOL_DURATION_TIME = 1,\n\tPERF_TOOL_USER_TIME = 2,\n\tPERF_TOOL_SYSTEM_TIME = 3,\n\n\tPERF_TOOL_MAX,\n};\n\nconst char *perf_tool_event__to_str(enum perf_tool_event ev);\nenum perf_tool_event perf_tool_event__from_str(const char *str);\n\n#define perf_tool_event__for_each_event(ev)\t\t\\\n\tfor ((ev) = PERF_TOOL_DURATION_TIME; (ev) < PERF_TOOL_MAX; ev++)\n\n \nstruct evsel {\n\tstruct perf_evsel\tcore;\n\tstruct evlist\t\t*evlist;\n\toff_t\t\t\tid_offset;\n\tint\t\t\tid_pos;\n\tint\t\t\tis_pos;\n\tunsigned int\t\tsample_size;\n\n\t \n\tstruct {\n\t\tchar\t\t\t*name;\n\t\tchar\t\t\t*group_name;\n\t\tconst char\t\t*pmu_name;\n\t\tconst char\t\t*group_pmu_name;\n#ifdef HAVE_LIBTRACEEVENT\n\t\tstruct tep_event\t*tp_format;\n#endif\n\t\tchar\t\t\t*filter;\n\t\tunsigned long\t\tmax_events;\n\t\tdouble\t\t\tscale;\n\t\tconst char\t\t*unit;\n\t\tstruct cgroup\t\t*cgrp;\n\t\tconst char\t\t*metric_id;\n\t\tenum perf_tool_event\ttool_event;\n\t\t \n\t\tint\t\t\texclude_GH;\n\t\tint\t\t\tsample_read;\n\t\tbool\t\t\tsnapshot;\n\t\tbool\t\t\tper_pkg;\n\t\tbool\t\t\tpercore;\n\t\tbool\t\t\tprecise_max;\n\t\tbool\t\t\tis_libpfm_event;\n\t\tbool\t\t\tauto_merge_stats;\n\t\tbool\t\t\tcollect_stat;\n\t\tbool\t\t\tweak_group;\n\t\tbool\t\t\tbpf_counter;\n\t\tbool\t\t\tuse_config_name;\n\t\tbool\t\t\tskippable;\n\t\tint\t\t\tbpf_fd;\n\t\tstruct bpf_object\t*bpf_obj;\n\t\tstruct list_head\tconfig_terms;\n\t};\n\n\t \n\tstruct evsel\t\t**metric_events;\n\tstruct evsel\t\t*metric_leader;\n\n\tvoid\t\t\t*handler;\n\tstruct perf_counts\t*counts;\n\tstruct perf_counts\t*prev_raw_counts;\n\tunsigned long\t\tnr_events_printed;\n\tstruct perf_stat_evsel  *stats;\n\tvoid\t\t\t*priv;\n\tu64\t\t\tdb_id;\n\tbool\t\t\tuniquified_name;\n\tbool \t\t\tsupported;\n\tbool \t\t\tneeds_swap;\n\tbool \t\t\tdisabled;\n\tbool\t\t\tno_aux_samples;\n\tbool\t\t\timmediate;\n\tbool\t\t\ttracking;\n\tbool\t\t\tignore_missing_thread;\n\tbool\t\t\tforced_leader;\n\tbool\t\t\tcmdline_group_boundary;\n\tbool\t\t\tmerged_stat;\n\tbool\t\t\treset_group;\n\tbool\t\t\terrored;\n\tbool\t\t\tneeds_auxtrace_mmap;\n\tbool\t\t\tdefault_metricgroup;  \n\tstruct hashmap\t\t*per_pkg_mask;\n\tint\t\t\terr;\n\tstruct {\n\t\tevsel__sb_cb_t\t*cb;\n\t\tvoid\t\t*data;\n\t} side_band;\n\t \n\t__u64\t\t\tsynth_sample_type;\n\n\t \n\tstruct bpf_counter_ops\t*bpf_counter_ops;\n\n\tstruct list_head\tbpf_counter_list;  \n\tstruct list_head\tbpf_filters;  \n\n\t \n\tint\t\t\tbperf_leader_prog_fd;\n\tint\t\t\tbperf_leader_link_fd;\n\tunion {\n\t\tstruct bperf_leader_bpf *leader_skel;\n\t\tstruct bperf_follower_bpf *follower_skel;\n\t\tvoid *bpf_skel;\n\t};\n\tunsigned long\t\topen_flags;\n\tint\t\t\tprecise_ip_original;\n\n\t \n\tstruct perf_pmu\t\t*pmu;\n};\n\nstruct perf_missing_features {\n\tbool sample_id_all;\n\tbool exclude_guest;\n\tbool mmap2;\n\tbool cloexec;\n\tbool clockid;\n\tbool clockid_wrong;\n\tbool lbr_flags;\n\tbool write_backward;\n\tbool group_read;\n\tbool ksymbol;\n\tbool bpf;\n\tbool aux_output;\n\tbool branch_hw_idx;\n\tbool cgroup;\n\tbool data_page_size;\n\tbool code_page_size;\n\tbool weight_struct;\n\tbool read_lost;\n};\n\nextern struct perf_missing_features perf_missing_features;\n\nstruct perf_cpu_map;\nstruct thread_map;\nstruct record_opts;\n\nstatic inline struct perf_cpu_map *evsel__cpus(struct evsel *evsel)\n{\n\treturn perf_evsel__cpus(&evsel->core);\n}\n\nstatic inline int evsel__nr_cpus(struct evsel *evsel)\n{\n\treturn perf_cpu_map__nr(evsel__cpus(evsel));\n}\n\nvoid evsel__compute_deltas(struct evsel *evsel, int cpu, int thread,\n\t\t\t   struct perf_counts_values *count);\n\nint evsel__object_config(size_t object_size,\n\t\t\t int (*init)(struct evsel *evsel),\n\t\t\t void (*fini)(struct evsel *evsel));\n\nstruct perf_pmu *evsel__find_pmu(const struct evsel *evsel);\nbool evsel__is_aux_event(const struct evsel *evsel);\n\nstruct evsel *evsel__new_idx(struct perf_event_attr *attr, int idx);\n\nstatic inline struct evsel *evsel__new(struct perf_event_attr *attr)\n{\n\treturn evsel__new_idx(attr, 0);\n}\n\nstruct evsel *evsel__clone(struct evsel *orig);\n\nint copy_config_terms(struct list_head *dst, struct list_head *src);\nvoid free_config_terms(struct list_head *config_terms);\n\n\n#ifdef HAVE_LIBTRACEEVENT\nstruct evsel *evsel__newtp_idx(const char *sys, const char *name, int idx);\n\n \nstatic inline struct evsel *evsel__newtp(const char *sys, const char *name)\n{\n\treturn evsel__newtp_idx(sys, name, 0);\n}\n#endif\n\n#ifdef HAVE_LIBTRACEEVENT\nstruct tep_event *event_format__new(const char *sys, const char *name);\n#endif\n\nvoid evsel__init(struct evsel *evsel, struct perf_event_attr *attr, int idx);\nvoid evsel__exit(struct evsel *evsel);\nvoid evsel__delete(struct evsel *evsel);\n\nstruct callchain_param;\n\nvoid evsel__config(struct evsel *evsel, struct record_opts *opts,\n\t\t   struct callchain_param *callchain);\nvoid evsel__config_callchain(struct evsel *evsel, struct record_opts *opts,\n\t\t\t     struct callchain_param *callchain);\n\nint __evsel__sample_size(u64 sample_type);\nvoid evsel__calc_id_pos(struct evsel *evsel);\n\nbool evsel__is_cache_op_valid(u8 type, u8 op);\n\nstatic inline bool evsel__is_bpf(struct evsel *evsel)\n{\n\treturn evsel->bpf_counter_ops != NULL;\n}\n\nstatic inline bool evsel__is_bperf(struct evsel *evsel)\n{\n\treturn evsel->bpf_counter_ops != NULL && list_empty(&evsel->bpf_counter_list);\n}\n\n#define EVSEL__MAX_ALIASES 8\n\nextern const char *const evsel__hw_cache[PERF_COUNT_HW_CACHE_MAX][EVSEL__MAX_ALIASES];\nextern const char *const evsel__hw_cache_op[PERF_COUNT_HW_CACHE_OP_MAX][EVSEL__MAX_ALIASES];\nextern const char *const evsel__hw_cache_result[PERF_COUNT_HW_CACHE_RESULT_MAX][EVSEL__MAX_ALIASES];\nextern const char *const evsel__hw_names[PERF_COUNT_HW_MAX];\nextern const char *const evsel__sw_names[PERF_COUNT_SW_MAX];\nextern char *evsel__bpf_counter_events;\nbool evsel__match_bpf_counter_events(const char *name);\nint arch_evsel__hw_name(struct evsel *evsel, char *bf, size_t size);\n\nint __evsel__hw_cache_type_op_res_name(u8 type, u8 op, u8 result, char *bf, size_t size);\nconst char *evsel__name(struct evsel *evsel);\nbool evsel__name_is(struct evsel *evsel, const char *name);\nconst char *evsel__metric_id(const struct evsel *evsel);\n\nstatic inline bool evsel__is_tool(const struct evsel *evsel)\n{\n\treturn evsel->tool_event != PERF_TOOL_NONE;\n}\n\nconst char *evsel__group_name(struct evsel *evsel);\nint evsel__group_desc(struct evsel *evsel, char *buf, size_t size);\n\nvoid __evsel__set_sample_bit(struct evsel *evsel, enum perf_event_sample_format bit);\nvoid __evsel__reset_sample_bit(struct evsel *evsel, enum perf_event_sample_format bit);\n\n#define evsel__set_sample_bit(evsel, bit) \\\n\t__evsel__set_sample_bit(evsel, PERF_SAMPLE_##bit)\n\n#define evsel__reset_sample_bit(evsel, bit) \\\n\t__evsel__reset_sample_bit(evsel, PERF_SAMPLE_##bit)\n\nvoid evsel__set_sample_id(struct evsel *evsel, bool use_sample_identifier);\n\nvoid arch_evsel__set_sample_weight(struct evsel *evsel);\nvoid arch__post_evsel_config(struct evsel *evsel, struct perf_event_attr *attr);\nint arch_evsel__open_strerror(struct evsel *evsel, char *msg, size_t size);\n\nint evsel__set_filter(struct evsel *evsel, const char *filter);\nint evsel__append_tp_filter(struct evsel *evsel, const char *filter);\nint evsel__append_addr_filter(struct evsel *evsel, const char *filter);\nint evsel__enable_cpu(struct evsel *evsel, int cpu_map_idx);\nint evsel__enable(struct evsel *evsel);\nint evsel__disable(struct evsel *evsel);\nint evsel__disable_cpu(struct evsel *evsel, int cpu_map_idx);\n\nint evsel__open_per_cpu(struct evsel *evsel, struct perf_cpu_map *cpus, int cpu_map_idx);\nint evsel__open_per_thread(struct evsel *evsel, struct perf_thread_map *threads);\nint evsel__open(struct evsel *evsel, struct perf_cpu_map *cpus,\n\t\tstruct perf_thread_map *threads);\nvoid evsel__close(struct evsel *evsel);\nint evsel__prepare_open(struct evsel *evsel, struct perf_cpu_map *cpus,\n\t\tstruct perf_thread_map *threads);\nbool evsel__detect_missing_features(struct evsel *evsel);\n\nenum rlimit_action { NO_CHANGE, SET_TO_MAX, INCREASED_MAX };\nbool evsel__increase_rlimit(enum rlimit_action *set_rlimit);\n\nbool evsel__precise_ip_fallback(struct evsel *evsel);\n\nstruct perf_sample;\n\n#ifdef HAVE_LIBTRACEEVENT\nvoid *evsel__rawptr(struct evsel *evsel, struct perf_sample *sample, const char *name);\nu64 evsel__intval(struct evsel *evsel, struct perf_sample *sample, const char *name);\n\nstatic inline char *evsel__strval(struct evsel *evsel, struct perf_sample *sample, const char *name)\n{\n\treturn evsel__rawptr(evsel, sample, name);\n}\n#endif\n\nstruct tep_format_field;\n\nu64 format_field__intval(struct tep_format_field *field, struct perf_sample *sample, bool needs_swap);\n\nstruct tep_format_field *evsel__field(struct evsel *evsel, const char *name);\n\nstatic inline bool __evsel__match(const struct evsel *evsel, u32 type, u64 config)\n{\n\tif (evsel->core.attr.type != type)\n\t\treturn false;\n\n\tif ((type == PERF_TYPE_HARDWARE || type == PERF_TYPE_HW_CACHE)  &&\n\t    perf_pmus__supports_extended_type())\n\t\treturn (evsel->core.attr.config & PERF_HW_EVENT_MASK) == config;\n\n\treturn evsel->core.attr.config == config;\n}\n\n#define evsel__match(evsel, t, c) __evsel__match(evsel, PERF_TYPE_##t, PERF_COUNT_##c)\n\nstatic inline bool evsel__match2(struct evsel *e1, struct evsel *e2)\n{\n\treturn (e1->core.attr.type == e2->core.attr.type) &&\n\t       (e1->core.attr.config == e2->core.attr.config);\n}\n\nint evsel__read_counter(struct evsel *evsel, int cpu_map_idx, int thread);\n\nint __evsel__read_on_cpu(struct evsel *evsel, int cpu_map_idx, int thread, bool scale);\n\n \nstatic inline int evsel__read_on_cpu(struct evsel *evsel, int cpu_map_idx, int thread)\n{\n\treturn __evsel__read_on_cpu(evsel, cpu_map_idx, thread, false);\n}\n\n \nstatic inline int evsel__read_on_cpu_scaled(struct evsel *evsel, int cpu_map_idx, int thread)\n{\n\treturn __evsel__read_on_cpu(evsel, cpu_map_idx, thread, true);\n}\n\nint evsel__parse_sample(struct evsel *evsel, union perf_event *event,\n\t\t\tstruct perf_sample *sample);\n\nint evsel__parse_sample_timestamp(struct evsel *evsel, union perf_event *event,\n\t\t\t\t  u64 *timestamp);\n\nu16 evsel__id_hdr_size(struct evsel *evsel);\n\nstatic inline struct evsel *evsel__next(struct evsel *evsel)\n{\n\treturn list_entry(evsel->core.node.next, struct evsel, core.node);\n}\n\nstatic inline struct evsel *evsel__prev(struct evsel *evsel)\n{\n\treturn list_entry(evsel->core.node.prev, struct evsel, core.node);\n}\n\n \nstatic inline bool evsel__is_group_leader(const struct evsel *evsel)\n{\n\treturn evsel->core.leader == &evsel->core;\n}\n\n \nstatic inline bool evsel__is_group_event(struct evsel *evsel)\n{\n\tif (!symbol_conf.event_group)\n\t\treturn false;\n\n\treturn evsel__is_group_leader(evsel) && evsel->core.nr_members > 1;\n}\n\nbool evsel__is_function_event(struct evsel *evsel);\n\nstatic inline bool evsel__is_bpf_output(struct evsel *evsel)\n{\n\treturn evsel__match(evsel, SOFTWARE, SW_BPF_OUTPUT);\n}\n\nstatic inline bool evsel__is_clock(const struct evsel *evsel)\n{\n\treturn evsel__match(evsel, SOFTWARE, SW_CPU_CLOCK) ||\n\t       evsel__match(evsel, SOFTWARE, SW_TASK_CLOCK);\n}\n\nbool evsel__fallback(struct evsel *evsel, int err, char *msg, size_t msgsize);\nint evsel__open_strerror(struct evsel *evsel, struct target *target,\n\t\t\t int err, char *msg, size_t size);\n\nstatic inline int evsel__group_idx(struct evsel *evsel)\n{\n\treturn evsel->core.idx - evsel->core.leader->idx;\n}\n\n \n#define for_each_group_member_head(_evsel, _leader, _head)\t\t\t\t\\\nfor ((_evsel) = list_entry((_leader)->core.node.next, struct evsel, core.node);\t\t\\\n\t(_evsel) && &(_evsel)->core.node != (_head) &&\t\t\t\t\t\\\n\t(_evsel)->core.leader == &(_leader)->core;\t\t\t\t\t\\\n\t(_evsel) = list_entry((_evsel)->core.node.next, struct evsel, core.node))\n\n#define for_each_group_member(_evsel, _leader)\t\t\t\t\\\n\tfor_each_group_member_head(_evsel, _leader, &(_leader)->evlist->core.entries)\n\n \n#define for_each_group_evsel_head(_evsel, _leader, _head)\t\t\t\t\\\nfor ((_evsel) = _leader;\t\t\t\t\t\t\t\t\\\n\t(_evsel) && &(_evsel)->core.node != (_head) &&\t\t\t\t\t\\\n\t(_evsel)->core.leader == &(_leader)->core;\t\t\t\t\t\\\n\t(_evsel) = list_entry((_evsel)->core.node.next, struct evsel, core.node))\n\n#define for_each_group_evsel(_evsel, _leader)\t\t\t\t\\\n\tfor_each_group_evsel_head(_evsel, _leader, &(_leader)->evlist->core.entries)\n\nstatic inline bool evsel__has_branch_callstack(const struct evsel *evsel)\n{\n\treturn evsel->core.attr.branch_sample_type & PERF_SAMPLE_BRANCH_CALL_STACK;\n}\n\nstatic inline bool evsel__has_branch_hw_idx(const struct evsel *evsel)\n{\n\treturn evsel->core.attr.branch_sample_type & PERF_SAMPLE_BRANCH_HW_INDEX;\n}\n\nstatic inline bool evsel__has_callchain(const struct evsel *evsel)\n{\n\t \n\treturn evsel->core.attr.sample_type & PERF_SAMPLE_CALLCHAIN ||\n\t       evsel->synth_sample_type & PERF_SAMPLE_CALLCHAIN;\n}\n\nstatic inline bool evsel__has_br_stack(const struct evsel *evsel)\n{\n\t \n\treturn evsel->core.attr.sample_type & PERF_SAMPLE_BRANCH_STACK ||\n\t       evsel->synth_sample_type & PERF_SAMPLE_BRANCH_STACK;\n}\n\nstatic inline bool evsel__is_dummy_event(struct evsel *evsel)\n{\n\treturn (evsel->core.attr.type == PERF_TYPE_SOFTWARE) &&\n\t       (evsel->core.attr.config == PERF_COUNT_SW_DUMMY);\n}\n\nstruct perf_env *evsel__env(struct evsel *evsel);\n\nint evsel__store_ids(struct evsel *evsel, struct evlist *evlist);\n\nvoid evsel__zero_per_pkg(struct evsel *evsel);\nbool evsel__is_hybrid(const struct evsel *evsel);\nstruct evsel *evsel__leader(const struct evsel *evsel);\nbool evsel__has_leader(struct evsel *evsel, struct evsel *leader);\nbool evsel__is_leader(struct evsel *evsel);\nvoid evsel__set_leader(struct evsel *evsel, struct evsel *leader);\nint evsel__source_count(const struct evsel *evsel);\nvoid evsel__remove_from_group(struct evsel *evsel, struct evsel *leader);\n\nbool arch_evsel__must_be_in_group(const struct evsel *evsel);\n\n \n#define bitfield_swap(src, pos, size)\t\\\n\t((((src) >> (pos)) & ((1ull << (size)) - 1)) << (63 - ((pos) + (size) - 1)))\n\nu64 evsel__bitfield_swap_branch_flags(u64 value);\nvoid evsel__set_config_if_unset(struct perf_pmu *pmu, struct evsel *evsel,\n\t\t\t\tconst char *config_name, u64 val);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}