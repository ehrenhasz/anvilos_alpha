{
  "module_name": "arm-spe.c",
  "hash_id": "a731b59dc814efdb3bd978a6a500278656e32fadcfcdf70fd7d341be8e543655",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/arm-spe.c",
  "human_readable_source": "\n \n\n#include <byteswap.h>\n#include <endian.h>\n#include <errno.h>\n#include <inttypes.h>\n#include <linux/bitops.h>\n#include <linux/kernel.h>\n#include <linux/log2.h>\n#include <linux/types.h>\n#include <linux/zalloc.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#include \"auxtrace.h\"\n#include \"color.h\"\n#include \"debug.h\"\n#include \"evlist.h\"\n#include \"evsel.h\"\n#include \"machine.h\"\n#include \"session.h\"\n#include \"symbol.h\"\n#include \"thread.h\"\n#include \"thread-stack.h\"\n#include \"tsc.h\"\n#include \"tool.h\"\n#include \"util/synthetic-events.h\"\n\n#include \"arm-spe.h\"\n#include \"arm-spe-decoder/arm-spe-decoder.h\"\n#include \"arm-spe-decoder/arm-spe-pkt-decoder.h\"\n\n#include \"../../arch/arm64/include/asm/cputype.h\"\n#define MAX_TIMESTAMP (~0ULL)\n\nstruct arm_spe {\n\tstruct auxtrace\t\t\tauxtrace;\n\tstruct auxtrace_queues\t\tqueues;\n\tstruct auxtrace_heap\t\theap;\n\tstruct itrace_synth_opts        synth_opts;\n\tu32\t\t\t\tauxtrace_type;\n\tstruct perf_session\t\t*session;\n\tstruct machine\t\t\t*machine;\n\tu32\t\t\t\tpmu_type;\n\tu64\t\t\t\tmidr;\n\n\tstruct perf_tsc_conversion\ttc;\n\n\tu8\t\t\t\ttimeless_decoding;\n\tu8\t\t\t\tdata_queued;\n\n\tu64\t\t\t\tsample_type;\n\tu8\t\t\t\tsample_flc;\n\tu8\t\t\t\tsample_llc;\n\tu8\t\t\t\tsample_tlb;\n\tu8\t\t\t\tsample_branch;\n\tu8\t\t\t\tsample_remote_access;\n\tu8\t\t\t\tsample_memory;\n\tu8\t\t\t\tsample_instructions;\n\tu64\t\t\t\tinstructions_sample_period;\n\n\tu64\t\t\t\tl1d_miss_id;\n\tu64\t\t\t\tl1d_access_id;\n\tu64\t\t\t\tllc_miss_id;\n\tu64\t\t\t\tllc_access_id;\n\tu64\t\t\t\ttlb_miss_id;\n\tu64\t\t\t\ttlb_access_id;\n\tu64\t\t\t\tbranch_miss_id;\n\tu64\t\t\t\tremote_access_id;\n\tu64\t\t\t\tmemory_id;\n\tu64\t\t\t\tinstructions_id;\n\n\tu64\t\t\t\tkernel_start;\n\n\tunsigned long\t\t\tnum_events;\n\tu8\t\t\t\tuse_ctx_pkt_for_pid;\n};\n\nstruct arm_spe_queue {\n\tstruct arm_spe\t\t\t*spe;\n\tunsigned int\t\t\tqueue_nr;\n\tstruct auxtrace_buffer\t\t*buffer;\n\tstruct auxtrace_buffer\t\t*old_buffer;\n\tunion perf_event\t\t*event_buf;\n\tbool\t\t\t\ton_heap;\n\tbool\t\t\t\tdone;\n\tpid_t\t\t\t\tpid;\n\tpid_t\t\t\t\ttid;\n\tint\t\t\t\tcpu;\n\tstruct arm_spe_decoder\t\t*decoder;\n\tu64\t\t\t\ttime;\n\tu64\t\t\t\ttimestamp;\n\tstruct thread\t\t\t*thread;\n\tu64\t\t\t\tperiod_instructions;\n};\n\nstatic void arm_spe_dump(struct arm_spe *spe __maybe_unused,\n\t\t\t unsigned char *buf, size_t len)\n{\n\tstruct arm_spe_pkt packet;\n\tsize_t pos = 0;\n\tint ret, pkt_len, i;\n\tchar desc[ARM_SPE_PKT_DESC_MAX];\n\tconst char *color = PERF_COLOR_BLUE;\n\n\tcolor_fprintf(stdout, color,\n\t\t      \". ... ARM SPE data: size %#zx bytes\\n\",\n\t\t      len);\n\n\twhile (len) {\n\t\tret = arm_spe_get_packet(buf, len, &packet);\n\t\tif (ret > 0)\n\t\t\tpkt_len = ret;\n\t\telse\n\t\t\tpkt_len = 1;\n\t\tprintf(\".\");\n\t\tcolor_fprintf(stdout, color, \"  %08x: \", pos);\n\t\tfor (i = 0; i < pkt_len; i++)\n\t\t\tcolor_fprintf(stdout, color, \" %02x\", buf[i]);\n\t\tfor (; i < 16; i++)\n\t\t\tcolor_fprintf(stdout, color, \"   \");\n\t\tif (ret > 0) {\n\t\t\tret = arm_spe_pkt_desc(&packet, desc,\n\t\t\t\t\t       ARM_SPE_PKT_DESC_MAX);\n\t\t\tif (!ret)\n\t\t\t\tcolor_fprintf(stdout, color, \" %s\\n\", desc);\n\t\t} else {\n\t\t\tcolor_fprintf(stdout, color, \" Bad packet!\\n\");\n\t\t}\n\t\tpos += pkt_len;\n\t\tbuf += pkt_len;\n\t\tlen -= pkt_len;\n\t}\n}\n\nstatic void arm_spe_dump_event(struct arm_spe *spe, unsigned char *buf,\n\t\t\t       size_t len)\n{\n\tprintf(\".\\n\");\n\tarm_spe_dump(spe, buf, len);\n}\n\nstatic int arm_spe_get_trace(struct arm_spe_buffer *b, void *data)\n{\n\tstruct arm_spe_queue *speq = data;\n\tstruct auxtrace_buffer *buffer = speq->buffer;\n\tstruct auxtrace_buffer *old_buffer = speq->old_buffer;\n\tstruct auxtrace_queue *queue;\n\n\tqueue = &speq->spe->queues.queue_array[speq->queue_nr];\n\n\tbuffer = auxtrace_buffer__next(queue, buffer);\n\t \n\tif (!buffer) {\n\t\tif (old_buffer)\n\t\t\tauxtrace_buffer__drop_data(old_buffer);\n\t\tb->len = 0;\n\t\treturn 0;\n\t}\n\n\tspeq->buffer = buffer;\n\n\t \n\tif (!buffer->data) {\n\t\t \n\t\tint fd = perf_data__fd(speq->spe->session->data);\n\n\t\tbuffer->data = auxtrace_buffer__get_data(buffer, fd);\n\t\tif (!buffer->data)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tb->len = buffer->size;\n\tb->buf = buffer->data;\n\n\tif (b->len) {\n\t\tif (old_buffer)\n\t\t\tauxtrace_buffer__drop_data(old_buffer);\n\t\tspeq->old_buffer = buffer;\n\t} else {\n\t\tauxtrace_buffer__drop_data(buffer);\n\t\treturn arm_spe_get_trace(b, data);\n\t}\n\n\treturn 0;\n}\n\nstatic struct arm_spe_queue *arm_spe__alloc_queue(struct arm_spe *spe,\n\t\tunsigned int queue_nr)\n{\n\tstruct arm_spe_params params = { .get_trace = 0, };\n\tstruct arm_spe_queue *speq;\n\n\tspeq = zalloc(sizeof(*speq));\n\tif (!speq)\n\t\treturn NULL;\n\n\tspeq->event_buf = malloc(PERF_SAMPLE_MAX_SIZE);\n\tif (!speq->event_buf)\n\t\tgoto out_free;\n\n\tspeq->spe = spe;\n\tspeq->queue_nr = queue_nr;\n\tspeq->pid = -1;\n\tspeq->tid = -1;\n\tspeq->cpu = -1;\n\tspeq->period_instructions = 0;\n\n\t \n\tparams.get_trace = arm_spe_get_trace;\n\tparams.data = speq;\n\n\t \n\tspeq->decoder = arm_spe_decoder_new(&params);\n\tif (!speq->decoder)\n\t\tgoto out_free;\n\n\treturn speq;\n\nout_free:\n\tzfree(&speq->event_buf);\n\tfree(speq);\n\n\treturn NULL;\n}\n\nstatic inline u8 arm_spe_cpumode(struct arm_spe *spe, u64 ip)\n{\n\treturn ip >= spe->kernel_start ?\n\t\tPERF_RECORD_MISC_KERNEL :\n\t\tPERF_RECORD_MISC_USER;\n}\n\nstatic void arm_spe_set_pid_tid_cpu(struct arm_spe *spe,\n\t\t\t\t    struct auxtrace_queue *queue)\n{\n\tstruct arm_spe_queue *speq = queue->priv;\n\tpid_t tid;\n\n\ttid = machine__get_current_tid(spe->machine, speq->cpu);\n\tif (tid != -1) {\n\t\tspeq->tid = tid;\n\t\tthread__zput(speq->thread);\n\t} else\n\t\tspeq->tid = queue->tid;\n\n\tif ((!speq->thread) && (speq->tid != -1)) {\n\t\tspeq->thread = machine__find_thread(spe->machine, -1,\n\t\t\t\t\t\t    speq->tid);\n\t}\n\n\tif (speq->thread) {\n\t\tspeq->pid = thread__pid(speq->thread);\n\t\tif (queue->cpu == -1)\n\t\t\tspeq->cpu = thread__cpu(speq->thread);\n\t}\n}\n\nstatic int arm_spe_set_tid(struct arm_spe_queue *speq, pid_t tid)\n{\n\tstruct arm_spe *spe = speq->spe;\n\tint err = machine__set_current_tid(spe->machine, speq->cpu, -1, tid);\n\n\tif (err)\n\t\treturn err;\n\n\tarm_spe_set_pid_tid_cpu(spe, &spe->queues.queue_array[speq->queue_nr]);\n\n\treturn 0;\n}\n\nstatic struct simd_flags arm_spe__synth_simd_flags(const struct arm_spe_record *record)\n{\n\tstruct simd_flags simd_flags = {};\n\n\tif ((record->op & ARM_SPE_OP_LDST) && (record->op & ARM_SPE_OP_SVE_LDST))\n\t\tsimd_flags.arch |= SIMD_OP_FLAGS_ARCH_SVE;\n\n\tif ((record->op & ARM_SPE_OP_OTHER) && (record->op & ARM_SPE_OP_SVE_OTHER))\n\t\tsimd_flags.arch |= SIMD_OP_FLAGS_ARCH_SVE;\n\n\tif (record->type & ARM_SPE_SVE_PARTIAL_PRED)\n\t\tsimd_flags.pred |= SIMD_OP_FLAGS_PRED_PARTIAL;\n\n\tif (record->type & ARM_SPE_SVE_EMPTY_PRED)\n\t\tsimd_flags.pred |= SIMD_OP_FLAGS_PRED_EMPTY;\n\n\treturn simd_flags;\n}\n\nstatic void arm_spe_prep_sample(struct arm_spe *spe,\n\t\t\t\tstruct arm_spe_queue *speq,\n\t\t\t\tunion perf_event *event,\n\t\t\t\tstruct perf_sample *sample)\n{\n\tstruct arm_spe_record *record = &speq->decoder->record;\n\n\tif (!spe->timeless_decoding)\n\t\tsample->time = tsc_to_perf_time(record->timestamp, &spe->tc);\n\n\tsample->ip = record->from_ip;\n\tsample->cpumode = arm_spe_cpumode(spe, sample->ip);\n\tsample->pid = speq->pid;\n\tsample->tid = speq->tid;\n\tsample->period = 1;\n\tsample->cpu = speq->cpu;\n\tsample->simd_flags = arm_spe__synth_simd_flags(record);\n\n\tevent->sample.header.type = PERF_RECORD_SAMPLE;\n\tevent->sample.header.misc = sample->cpumode;\n\tevent->sample.header.size = sizeof(struct perf_event_header);\n}\n\nstatic int arm_spe__inject_event(union perf_event *event, struct perf_sample *sample, u64 type)\n{\n\tevent->header.size = perf_event__sample_event_size(sample, type, 0);\n\treturn perf_event__synthesize_sample(event, type, 0, sample);\n}\n\nstatic inline int\narm_spe_deliver_synth_event(struct arm_spe *spe,\n\t\t\t    struct arm_spe_queue *speq __maybe_unused,\n\t\t\t    union perf_event *event,\n\t\t\t    struct perf_sample *sample)\n{\n\tint ret;\n\n\tif (spe->synth_opts.inject) {\n\t\tret = arm_spe__inject_event(event, sample, spe->sample_type);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = perf_session__deliver_synth_event(spe->session, event, sample);\n\tif (ret)\n\t\tpr_err(\"ARM SPE: failed to deliver event, error %d\\n\", ret);\n\n\treturn ret;\n}\n\nstatic int arm_spe__synth_mem_sample(struct arm_spe_queue *speq,\n\t\t\t\t     u64 spe_events_id, u64 data_src)\n{\n\tstruct arm_spe *spe = speq->spe;\n\tstruct arm_spe_record *record = &speq->decoder->record;\n\tunion perf_event *event = speq->event_buf;\n\tstruct perf_sample sample = { .ip = 0, };\n\n\tarm_spe_prep_sample(spe, speq, event, &sample);\n\n\tsample.id = spe_events_id;\n\tsample.stream_id = spe_events_id;\n\tsample.addr = record->virt_addr;\n\tsample.phys_addr = record->phys_addr;\n\tsample.data_src = data_src;\n\tsample.weight = record->latency;\n\n\treturn arm_spe_deliver_synth_event(spe, speq, event, &sample);\n}\n\nstatic int arm_spe__synth_branch_sample(struct arm_spe_queue *speq,\n\t\t\t\t\tu64 spe_events_id)\n{\n\tstruct arm_spe *spe = speq->spe;\n\tstruct arm_spe_record *record = &speq->decoder->record;\n\tunion perf_event *event = speq->event_buf;\n\tstruct perf_sample sample = { .ip = 0, };\n\n\tarm_spe_prep_sample(spe, speq, event, &sample);\n\n\tsample.id = spe_events_id;\n\tsample.stream_id = spe_events_id;\n\tsample.addr = record->to_ip;\n\tsample.weight = record->latency;\n\n\treturn arm_spe_deliver_synth_event(spe, speq, event, &sample);\n}\n\nstatic int arm_spe__synth_instruction_sample(struct arm_spe_queue *speq,\n\t\t\t\t\t     u64 spe_events_id, u64 data_src)\n{\n\tstruct arm_spe *spe = speq->spe;\n\tstruct arm_spe_record *record = &speq->decoder->record;\n\tunion perf_event *event = speq->event_buf;\n\tstruct perf_sample sample = { .ip = 0, };\n\n\t \n\tspeq->period_instructions++;\n\tif (speq->period_instructions < spe->instructions_sample_period)\n\t\treturn 0;\n\tspeq->period_instructions = 0;\n\n\tarm_spe_prep_sample(spe, speq, event, &sample);\n\n\tsample.id = spe_events_id;\n\tsample.stream_id = spe_events_id;\n\tsample.addr = record->virt_addr;\n\tsample.phys_addr = record->phys_addr;\n\tsample.data_src = data_src;\n\tsample.period = spe->instructions_sample_period;\n\tsample.weight = record->latency;\n\n\treturn arm_spe_deliver_synth_event(spe, speq, event, &sample);\n}\n\nstatic const struct midr_range neoverse_spe[] = {\n\tMIDR_ALL_VERSIONS(MIDR_NEOVERSE_N1),\n\tMIDR_ALL_VERSIONS(MIDR_NEOVERSE_N2),\n\tMIDR_ALL_VERSIONS(MIDR_NEOVERSE_V1),\n\t{},\n};\n\nstatic void arm_spe__synth_data_source_neoverse(const struct arm_spe_record *record,\n\t\t\t\t\t\tunion perf_mem_data_src *data_src)\n{\n\t \n\n\t \n\tif (record->op & ARM_SPE_OP_ST) {\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_NA;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_NA;\n\t\tdata_src->mem_snoop = PERF_MEM_SNOOP_NA;\n\t\treturn;\n\t}\n\n\tswitch (record->source) {\n\tcase ARM_SPE_NV_L1D:\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_L1 | PERF_MEM_LVL_HIT;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_L1;\n\t\tdata_src->mem_snoop = PERF_MEM_SNOOP_NONE;\n\t\tbreak;\n\tcase ARM_SPE_NV_L2:\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_L2 | PERF_MEM_LVL_HIT;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_L2;\n\t\tdata_src->mem_snoop = PERF_MEM_SNOOP_NONE;\n\t\tbreak;\n\tcase ARM_SPE_NV_PEER_CORE:\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_L2 | PERF_MEM_LVL_HIT;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_L2;\n\t\tdata_src->mem_snoopx = PERF_MEM_SNOOPX_PEER;\n\t\tbreak;\n\t \n\tcase ARM_SPE_NV_LOCAL_CLUSTER:\n\tcase ARM_SPE_NV_PEER_CLUSTER:\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_L3 | PERF_MEM_LVL_HIT;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_L3;\n\t\tdata_src->mem_snoopx = PERF_MEM_SNOOPX_PEER;\n\t\tbreak;\n\t \n\tcase ARM_SPE_NV_SYS_CACHE:\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_L3 | PERF_MEM_LVL_HIT;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_L3;\n\t\tdata_src->mem_snoop = PERF_MEM_SNOOP_HIT;\n\t\tbreak;\n\t \n\tcase ARM_SPE_NV_REMOTE:\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_REM_CCE1;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_ANY_CACHE;\n\t\tdata_src->mem_remote = PERF_MEM_REMOTE_REMOTE;\n\t\tdata_src->mem_snoopx = PERF_MEM_SNOOPX_PEER;\n\t\tbreak;\n\tcase ARM_SPE_NV_DRAM:\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_LOC_RAM | PERF_MEM_LVL_HIT;\n\t\tdata_src->mem_lvl_num = PERF_MEM_LVLNUM_RAM;\n\t\tdata_src->mem_snoop = PERF_MEM_SNOOP_NONE;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void arm_spe__synth_data_source_generic(const struct arm_spe_record *record,\n\t\t\t\t\t       union perf_mem_data_src *data_src)\n{\n\tif (record->type & (ARM_SPE_LLC_ACCESS | ARM_SPE_LLC_MISS)) {\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_L3;\n\n\t\tif (record->type & ARM_SPE_LLC_MISS)\n\t\t\tdata_src->mem_lvl |= PERF_MEM_LVL_MISS;\n\t\telse\n\t\t\tdata_src->mem_lvl |= PERF_MEM_LVL_HIT;\n\t} else if (record->type & (ARM_SPE_L1D_ACCESS | ARM_SPE_L1D_MISS)) {\n\t\tdata_src->mem_lvl = PERF_MEM_LVL_L1;\n\n\t\tif (record->type & ARM_SPE_L1D_MISS)\n\t\t\tdata_src->mem_lvl |= PERF_MEM_LVL_MISS;\n\t\telse\n\t\t\tdata_src->mem_lvl |= PERF_MEM_LVL_HIT;\n\t}\n\n\tif (record->type & ARM_SPE_REMOTE_ACCESS)\n\t\tdata_src->mem_lvl |= PERF_MEM_LVL_REM_CCE1;\n}\n\nstatic u64 arm_spe__synth_data_source(const struct arm_spe_record *record, u64 midr)\n{\n\tunion perf_mem_data_src\tdata_src = { .mem_op = PERF_MEM_OP_NA };\n\tbool is_neoverse = is_midr_in_range_list(midr, neoverse_spe);\n\n\tif (record->op & ARM_SPE_OP_LD)\n\t\tdata_src.mem_op = PERF_MEM_OP_LOAD;\n\telse if (record->op & ARM_SPE_OP_ST)\n\t\tdata_src.mem_op = PERF_MEM_OP_STORE;\n\telse\n\t\treturn 0;\n\n\tif (is_neoverse)\n\t\tarm_spe__synth_data_source_neoverse(record, &data_src);\n\telse\n\t\tarm_spe__synth_data_source_generic(record, &data_src);\n\n\tif (record->type & (ARM_SPE_TLB_ACCESS | ARM_SPE_TLB_MISS)) {\n\t\tdata_src.mem_dtlb = PERF_MEM_TLB_WK;\n\n\t\tif (record->type & ARM_SPE_TLB_MISS)\n\t\t\tdata_src.mem_dtlb |= PERF_MEM_TLB_MISS;\n\t\telse\n\t\t\tdata_src.mem_dtlb |= PERF_MEM_TLB_HIT;\n\t}\n\n\treturn data_src.val;\n}\n\nstatic int arm_spe_sample(struct arm_spe_queue *speq)\n{\n\tconst struct arm_spe_record *record = &speq->decoder->record;\n\tstruct arm_spe *spe = speq->spe;\n\tu64 data_src;\n\tint err;\n\n\tdata_src = arm_spe__synth_data_source(record, spe->midr);\n\n\tif (spe->sample_flc) {\n\t\tif (record->type & ARM_SPE_L1D_MISS) {\n\t\t\terr = arm_spe__synth_mem_sample(speq, spe->l1d_miss_id,\n\t\t\t\t\t\t\tdata_src);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (record->type & ARM_SPE_L1D_ACCESS) {\n\t\t\terr = arm_spe__synth_mem_sample(speq, spe->l1d_access_id,\n\t\t\t\t\t\t\tdata_src);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (spe->sample_llc) {\n\t\tif (record->type & ARM_SPE_LLC_MISS) {\n\t\t\terr = arm_spe__synth_mem_sample(speq, spe->llc_miss_id,\n\t\t\t\t\t\t\tdata_src);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (record->type & ARM_SPE_LLC_ACCESS) {\n\t\t\terr = arm_spe__synth_mem_sample(speq, spe->llc_access_id,\n\t\t\t\t\t\t\tdata_src);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (spe->sample_tlb) {\n\t\tif (record->type & ARM_SPE_TLB_MISS) {\n\t\t\terr = arm_spe__synth_mem_sample(speq, spe->tlb_miss_id,\n\t\t\t\t\t\t\tdata_src);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (record->type & ARM_SPE_TLB_ACCESS) {\n\t\t\terr = arm_spe__synth_mem_sample(speq, spe->tlb_access_id,\n\t\t\t\t\t\t\tdata_src);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (spe->sample_branch && (record->type & ARM_SPE_BRANCH_MISS)) {\n\t\terr = arm_spe__synth_branch_sample(speq, spe->branch_miss_id);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (spe->sample_remote_access &&\n\t    (record->type & ARM_SPE_REMOTE_ACCESS)) {\n\t\terr = arm_spe__synth_mem_sample(speq, spe->remote_access_id,\n\t\t\t\t\t\tdata_src);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\t \n\tif (spe->sample_memory && data_src) {\n\t\terr = arm_spe__synth_mem_sample(speq, spe->memory_id, data_src);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (spe->sample_instructions) {\n\t\terr = arm_spe__synth_instruction_sample(speq, spe->instructions_id, data_src);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int arm_spe_run_decoder(struct arm_spe_queue *speq, u64 *timestamp)\n{\n\tstruct arm_spe *spe = speq->spe;\n\tstruct arm_spe_record *record;\n\tint ret;\n\n\tif (!spe->kernel_start)\n\t\tspe->kernel_start = machine__kernel_start(spe->machine);\n\n\twhile (1) {\n\t\t \n\n\t\t \n\t\trecord = &speq->decoder->record;\n\t\tif (!spe->timeless_decoding && record->context_id != (u64)-1) {\n\t\t\tret = arm_spe_set_tid(speq, record->context_id);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tspe->use_ctx_pkt_for_pid = true;\n\t\t}\n\n\t\tret = arm_spe_sample(speq);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = arm_spe_decode(speq->decoder);\n\t\tif (!ret) {\n\t\t\tpr_debug(\"No data or all data has been processed.\\n\");\n\t\t\treturn 1;\n\t\t}\n\n\t\t \n\t\tif (ret < 0)\n\t\t\tcontinue;\n\n\t\trecord = &speq->decoder->record;\n\n\t\t \n\t\tif (record->timestamp > speq->timestamp)\n\t\t\tspeq->timestamp = record->timestamp;\n\n\t\t \n\t\tif (!spe->timeless_decoding && speq->timestamp >= *timestamp) {\n\t\t\t*timestamp = speq->timestamp;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int arm_spe__setup_queue(struct arm_spe *spe,\n\t\t\t       struct auxtrace_queue *queue,\n\t\t\t       unsigned int queue_nr)\n{\n\tstruct arm_spe_queue *speq = queue->priv;\n\tstruct arm_spe_record *record;\n\n\tif (list_empty(&queue->head) || speq)\n\t\treturn 0;\n\n\tspeq = arm_spe__alloc_queue(spe, queue_nr);\n\n\tif (!speq)\n\t\treturn -ENOMEM;\n\n\tqueue->priv = speq;\n\n\tif (queue->cpu != -1)\n\t\tspeq->cpu = queue->cpu;\n\n\tif (!speq->on_heap) {\n\t\tint ret;\n\n\t\tif (spe->timeless_decoding)\n\t\t\treturn 0;\n\nretry:\n\t\tret = arm_spe_decode(speq->decoder);\n\n\t\tif (!ret)\n\t\t\treturn 0;\n\n\t\tif (ret < 0)\n\t\t\tgoto retry;\n\n\t\trecord = &speq->decoder->record;\n\n\t\tspeq->timestamp = record->timestamp;\n\t\tret = auxtrace_heap__add(&spe->heap, queue_nr, speq->timestamp);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tspeq->on_heap = true;\n\t}\n\n\treturn 0;\n}\n\nstatic int arm_spe__setup_queues(struct arm_spe *spe)\n{\n\tunsigned int i;\n\tint ret;\n\n\tfor (i = 0; i < spe->queues.nr_queues; i++) {\n\t\tret = arm_spe__setup_queue(spe, &spe->queues.queue_array[i], i);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int arm_spe__update_queues(struct arm_spe *spe)\n{\n\tif (spe->queues.new_data) {\n\t\tspe->queues.new_data = false;\n\t\treturn arm_spe__setup_queues(spe);\n\t}\n\n\treturn 0;\n}\n\nstatic bool arm_spe__is_timeless_decoding(struct arm_spe *spe)\n{\n\tstruct evsel *evsel;\n\tstruct evlist *evlist = spe->session->evlist;\n\tbool timeless_decoding = true;\n\n\t \n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif ((evsel->core.attr.sample_type & PERF_SAMPLE_TIME))\n\t\t\ttimeless_decoding = false;\n\t}\n\n\treturn timeless_decoding;\n}\n\nstatic int arm_spe_process_queues(struct arm_spe *spe, u64 timestamp)\n{\n\tunsigned int queue_nr;\n\tu64 ts;\n\tint ret;\n\n\twhile (1) {\n\t\tstruct auxtrace_queue *queue;\n\t\tstruct arm_spe_queue *speq;\n\n\t\tif (!spe->heap.heap_cnt)\n\t\t\treturn 0;\n\n\t\tif (spe->heap.heap_array[0].ordinal >= timestamp)\n\t\t\treturn 0;\n\n\t\tqueue_nr = spe->heap.heap_array[0].queue_nr;\n\t\tqueue = &spe->queues.queue_array[queue_nr];\n\t\tspeq = queue->priv;\n\n\t\tauxtrace_heap__pop(&spe->heap);\n\n\t\tif (spe->heap.heap_cnt) {\n\t\t\tts = spe->heap.heap_array[0].ordinal + 1;\n\t\t\tif (ts > timestamp)\n\t\t\t\tts = timestamp;\n\t\t} else {\n\t\t\tts = timestamp;\n\t\t}\n\n\t\t \n\t\tif (!spe->use_ctx_pkt_for_pid)\n\t\t\tarm_spe_set_pid_tid_cpu(spe, queue);\n\n\t\tret = arm_spe_run_decoder(speq, &ts);\n\t\tif (ret < 0) {\n\t\t\tauxtrace_heap__add(&spe->heap, queue_nr, ts);\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (!ret) {\n\t\t\tret = auxtrace_heap__add(&spe->heap, queue_nr, ts);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t} else {\n\t\t\tspeq->on_heap = false;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int arm_spe_process_timeless_queues(struct arm_spe *spe, pid_t tid,\n\t\t\t\t\t    u64 time_)\n{\n\tstruct auxtrace_queues *queues = &spe->queues;\n\tunsigned int i;\n\tu64 ts = 0;\n\n\tfor (i = 0; i < queues->nr_queues; i++) {\n\t\tstruct auxtrace_queue *queue = &spe->queues.queue_array[i];\n\t\tstruct arm_spe_queue *speq = queue->priv;\n\n\t\tif (speq && (tid == -1 || speq->tid == tid)) {\n\t\t\tspeq->time = time_;\n\t\t\tarm_spe_set_pid_tid_cpu(spe, queue);\n\t\t\tarm_spe_run_decoder(speq, &ts);\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int arm_spe_context_switch(struct arm_spe *spe, union perf_event *event,\n\t\t\t\t  struct perf_sample *sample)\n{\n\tpid_t pid, tid;\n\tint cpu;\n\n\tif (!(event->header.misc & PERF_RECORD_MISC_SWITCH_OUT))\n\t\treturn 0;\n\n\tpid = event->context_switch.next_prev_pid;\n\ttid = event->context_switch.next_prev_tid;\n\tcpu = sample->cpu;\n\n\tif (tid == -1)\n\t\tpr_warning(\"context_switch event has no tid\\n\");\n\n\treturn machine__set_current_tid(spe->machine, cpu, pid, tid);\n}\n\nstatic int arm_spe_process_event(struct perf_session *session,\n\t\t\t\t union perf_event *event,\n\t\t\t\t struct perf_sample *sample,\n\t\t\t\t struct perf_tool *tool)\n{\n\tint err = 0;\n\tu64 timestamp;\n\tstruct arm_spe *spe = container_of(session->auxtrace,\n\t\t\tstruct arm_spe, auxtrace);\n\n\tif (dump_trace)\n\t\treturn 0;\n\n\tif (!tool->ordered_events) {\n\t\tpr_err(\"SPE trace requires ordered events\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (sample->time && (sample->time != (u64) -1))\n\t\ttimestamp = perf_time_to_tsc(sample->time, &spe->tc);\n\telse\n\t\ttimestamp = 0;\n\n\tif (timestamp || spe->timeless_decoding) {\n\t\terr = arm_spe__update_queues(spe);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (spe->timeless_decoding) {\n\t\tif (event->header.type == PERF_RECORD_EXIT) {\n\t\t\terr = arm_spe_process_timeless_queues(spe,\n\t\t\t\t\tevent->fork.tid,\n\t\t\t\t\tsample->time);\n\t\t}\n\t} else if (timestamp) {\n\t\terr = arm_spe_process_queues(spe, timestamp);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (!spe->use_ctx_pkt_for_pid &&\n\t\t    (event->header.type == PERF_RECORD_SWITCH_CPU_WIDE ||\n\t\t    event->header.type == PERF_RECORD_SWITCH))\n\t\t\terr = arm_spe_context_switch(spe, event, sample);\n\t}\n\n\treturn err;\n}\n\nstatic int arm_spe_process_auxtrace_event(struct perf_session *session,\n\t\t\t\t\t  union perf_event *event,\n\t\t\t\t\t  struct perf_tool *tool __maybe_unused)\n{\n\tstruct arm_spe *spe = container_of(session->auxtrace, struct arm_spe,\n\t\t\t\t\t     auxtrace);\n\n\tif (!spe->data_queued) {\n\t\tstruct auxtrace_buffer *buffer;\n\t\toff_t data_offset;\n\t\tint fd = perf_data__fd(session->data);\n\t\tint err;\n\n\t\tif (perf_data__is_pipe(session->data)) {\n\t\t\tdata_offset = 0;\n\t\t} else {\n\t\t\tdata_offset = lseek(fd, 0, SEEK_CUR);\n\t\t\tif (data_offset == -1)\n\t\t\t\treturn -errno;\n\t\t}\n\n\t\terr = auxtrace_queues__add_event(&spe->queues, session, event,\n\t\t\t\tdata_offset, &buffer);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t \n\t\tif (dump_trace) {\n\t\t\tif (auxtrace_buffer__get_data(buffer, fd)) {\n\t\t\t\tarm_spe_dump_event(spe, buffer->data,\n\t\t\t\t\t\tbuffer->size);\n\t\t\t\tauxtrace_buffer__put_data(buffer);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int arm_spe_flush(struct perf_session *session __maybe_unused,\n\t\t\t struct perf_tool *tool __maybe_unused)\n{\n\tstruct arm_spe *spe = container_of(session->auxtrace, struct arm_spe,\n\t\t\tauxtrace);\n\tint ret;\n\n\tif (dump_trace)\n\t\treturn 0;\n\n\tif (!tool->ordered_events)\n\t\treturn -EINVAL;\n\n\tret = arm_spe__update_queues(spe);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (spe->timeless_decoding)\n\t\treturn arm_spe_process_timeless_queues(spe, -1,\n\t\t\t\tMAX_TIMESTAMP - 1);\n\n\tret = arm_spe_process_queues(spe, MAX_TIMESTAMP);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!spe->use_ctx_pkt_for_pid)\n\t\tui__warning(\"Arm SPE CONTEXT packets not found in the traces.\\n\"\n\t\t\t    \"Matching of TIDs to SPE events could be inaccurate.\\n\");\n\n\treturn 0;\n}\n\nstatic void arm_spe_free_queue(void *priv)\n{\n\tstruct arm_spe_queue *speq = priv;\n\n\tif (!speq)\n\t\treturn;\n\tthread__zput(speq->thread);\n\tarm_spe_decoder_free(speq->decoder);\n\tzfree(&speq->event_buf);\n\tfree(speq);\n}\n\nstatic void arm_spe_free_events(struct perf_session *session)\n{\n\tstruct arm_spe *spe = container_of(session->auxtrace, struct arm_spe,\n\t\t\t\t\t     auxtrace);\n\tstruct auxtrace_queues *queues = &spe->queues;\n\tunsigned int i;\n\n\tfor (i = 0; i < queues->nr_queues; i++) {\n\t\tarm_spe_free_queue(queues->queue_array[i].priv);\n\t\tqueues->queue_array[i].priv = NULL;\n\t}\n\tauxtrace_queues__free(queues);\n}\n\nstatic void arm_spe_free(struct perf_session *session)\n{\n\tstruct arm_spe *spe = container_of(session->auxtrace, struct arm_spe,\n\t\t\t\t\t     auxtrace);\n\n\tauxtrace_heap__free(&spe->heap);\n\tarm_spe_free_events(session);\n\tsession->auxtrace = NULL;\n\tfree(spe);\n}\n\nstatic bool arm_spe_evsel_is_auxtrace(struct perf_session *session,\n\t\t\t\t      struct evsel *evsel)\n{\n\tstruct arm_spe *spe = container_of(session->auxtrace, struct arm_spe, auxtrace);\n\n\treturn evsel->core.attr.type == spe->pmu_type;\n}\n\nstatic const char * const arm_spe_info_fmts[] = {\n\t[ARM_SPE_PMU_TYPE]\t\t= \"  PMU Type           %\"PRId64\"\\n\",\n};\n\nstatic void arm_spe_print_info(__u64 *arr)\n{\n\tif (!dump_trace)\n\t\treturn;\n\n\tfprintf(stdout, arm_spe_info_fmts[ARM_SPE_PMU_TYPE], arr[ARM_SPE_PMU_TYPE]);\n}\n\nstruct arm_spe_synth {\n\tstruct perf_tool dummy_tool;\n\tstruct perf_session *session;\n};\n\nstatic int arm_spe_event_synth(struct perf_tool *tool,\n\t\t\t       union perf_event *event,\n\t\t\t       struct perf_sample *sample __maybe_unused,\n\t\t\t       struct machine *machine __maybe_unused)\n{\n\tstruct arm_spe_synth *arm_spe_synth =\n\t\t      container_of(tool, struct arm_spe_synth, dummy_tool);\n\n\treturn perf_session__deliver_synth_event(arm_spe_synth->session,\n\t\t\t\t\t\t event, NULL);\n}\n\nstatic int arm_spe_synth_event(struct perf_session *session,\n\t\t\t       struct perf_event_attr *attr, u64 id)\n{\n\tstruct arm_spe_synth arm_spe_synth;\n\n\tmemset(&arm_spe_synth, 0, sizeof(struct arm_spe_synth));\n\tarm_spe_synth.session = session;\n\n\treturn perf_event__synthesize_attr(&arm_spe_synth.dummy_tool, attr, 1,\n\t\t\t\t\t   &id, arm_spe_event_synth);\n}\n\nstatic void arm_spe_set_event_name(struct evlist *evlist, u64 id,\n\t\t\t\t    const char *name)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.id && evsel->core.id[0] == id) {\n\t\t\tif (evsel->name)\n\t\t\t\tzfree(&evsel->name);\n\t\t\tevsel->name = strdup(name);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic int\narm_spe_synth_events(struct arm_spe *spe, struct perf_session *session)\n{\n\tstruct evlist *evlist = session->evlist;\n\tstruct evsel *evsel;\n\tstruct perf_event_attr attr;\n\tbool found = false;\n\tu64 id;\n\tint err;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.type == spe->pmu_type) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tpr_debug(\"No selected events with SPE trace data\\n\");\n\t\treturn 0;\n\t}\n\n\tmemset(&attr, 0, sizeof(struct perf_event_attr));\n\tattr.size = sizeof(struct perf_event_attr);\n\tattr.type = PERF_TYPE_HARDWARE;\n\tattr.sample_type = evsel->core.attr.sample_type &\n\t\t\t\t(PERF_SAMPLE_MASK | PERF_SAMPLE_PHYS_ADDR);\n\tattr.sample_type |= PERF_SAMPLE_IP | PERF_SAMPLE_TID |\n\t\t\t    PERF_SAMPLE_PERIOD | PERF_SAMPLE_DATA_SRC |\n\t\t\t    PERF_SAMPLE_WEIGHT | PERF_SAMPLE_ADDR;\n\tif (spe->timeless_decoding)\n\t\tattr.sample_type &= ~(u64)PERF_SAMPLE_TIME;\n\telse\n\t\tattr.sample_type |= PERF_SAMPLE_TIME;\n\n\tspe->sample_type = attr.sample_type;\n\n\tattr.exclude_user = evsel->core.attr.exclude_user;\n\tattr.exclude_kernel = evsel->core.attr.exclude_kernel;\n\tattr.exclude_hv = evsel->core.attr.exclude_hv;\n\tattr.exclude_host = evsel->core.attr.exclude_host;\n\tattr.exclude_guest = evsel->core.attr.exclude_guest;\n\tattr.sample_id_all = evsel->core.attr.sample_id_all;\n\tattr.read_format = evsel->core.attr.read_format;\n\n\t \n\tid = evsel->core.id[0] + 1000000000;\n\n\tif (!id)\n\t\tid = 1;\n\n\tif (spe->synth_opts.flc) {\n\t\tspe->sample_flc = true;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->l1d_miss_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"l1d-miss\");\n\t\tid += 1;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->l1d_access_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"l1d-access\");\n\t\tid += 1;\n\t}\n\n\tif (spe->synth_opts.llc) {\n\t\tspe->sample_llc = true;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->llc_miss_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"llc-miss\");\n\t\tid += 1;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->llc_access_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"llc-access\");\n\t\tid += 1;\n\t}\n\n\tif (spe->synth_opts.tlb) {\n\t\tspe->sample_tlb = true;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->tlb_miss_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"tlb-miss\");\n\t\tid += 1;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->tlb_access_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"tlb-access\");\n\t\tid += 1;\n\t}\n\n\tif (spe->synth_opts.branches) {\n\t\tspe->sample_branch = true;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->branch_miss_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"branch-miss\");\n\t\tid += 1;\n\t}\n\n\tif (spe->synth_opts.remote_access) {\n\t\tspe->sample_remote_access = true;\n\n\t\t \n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->remote_access_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"remote-access\");\n\t\tid += 1;\n\t}\n\n\tif (spe->synth_opts.mem) {\n\t\tspe->sample_memory = true;\n\n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->memory_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"memory\");\n\t\tid += 1;\n\t}\n\n\tif (spe->synth_opts.instructions) {\n\t\tif (spe->synth_opts.period_type != PERF_ITRACE_PERIOD_INSTRUCTIONS) {\n\t\t\tpr_warning(\"Only instruction-based sampling period is currently supported by Arm SPE.\\n\");\n\t\t\tgoto synth_instructions_out;\n\t\t}\n\t\tif (spe->synth_opts.period > 1)\n\t\t\tpr_warning(\"Arm SPE has a hardware-based sample period.\\n\"\n\t\t\t\t   \"Additional instruction events will be discarded by --itrace\\n\");\n\n\t\tspe->sample_instructions = true;\n\t\tattr.config = PERF_COUNT_HW_INSTRUCTIONS;\n\t\tattr.sample_period = spe->synth_opts.period;\n\t\tspe->instructions_sample_period = attr.sample_period;\n\t\terr = arm_spe_synth_event(session, &attr, id);\n\t\tif (err)\n\t\t\treturn err;\n\t\tspe->instructions_id = id;\n\t\tarm_spe_set_event_name(evlist, id, \"instructions\");\n\t}\nsynth_instructions_out:\n\n\treturn 0;\n}\n\nint arm_spe_process_auxtrace_info(union perf_event *event,\n\t\t\t\t  struct perf_session *session)\n{\n\tstruct perf_record_auxtrace_info *auxtrace_info = &event->auxtrace_info;\n\tsize_t min_sz = sizeof(u64) * ARM_SPE_AUXTRACE_PRIV_MAX;\n\tstruct perf_record_time_conv *tc = &session->time_conv;\n\tconst char *cpuid = perf_env__cpuid(session->evlist->env);\n\tu64 midr = strtol(cpuid, NULL, 16);\n\tstruct arm_spe *spe;\n\tint err;\n\n\tif (auxtrace_info->header.size < sizeof(struct perf_record_auxtrace_info) +\n\t\t\t\t\tmin_sz)\n\t\treturn -EINVAL;\n\n\tspe = zalloc(sizeof(struct arm_spe));\n\tif (!spe)\n\t\treturn -ENOMEM;\n\n\terr = auxtrace_queues__init(&spe->queues);\n\tif (err)\n\t\tgoto err_free;\n\n\tspe->session = session;\n\tspe->machine = &session->machines.host;  \n\tspe->auxtrace_type = auxtrace_info->type;\n\tspe->pmu_type = auxtrace_info->priv[ARM_SPE_PMU_TYPE];\n\tspe->midr = midr;\n\n\tspe->timeless_decoding = arm_spe__is_timeless_decoding(spe);\n\n\t \n\tspe->tc.time_shift = tc->time_shift;\n\tspe->tc.time_mult = tc->time_mult;\n\tspe->tc.time_zero = tc->time_zero;\n\n\tif (event_contains(*tc, time_cycles)) {\n\t\tspe->tc.time_cycles = tc->time_cycles;\n\t\tspe->tc.time_mask = tc->time_mask;\n\t\tspe->tc.cap_user_time_zero = tc->cap_user_time_zero;\n\t\tspe->tc.cap_user_time_short = tc->cap_user_time_short;\n\t}\n\n\tspe->auxtrace.process_event = arm_spe_process_event;\n\tspe->auxtrace.process_auxtrace_event = arm_spe_process_auxtrace_event;\n\tspe->auxtrace.flush_events = arm_spe_flush;\n\tspe->auxtrace.free_events = arm_spe_free_events;\n\tspe->auxtrace.free = arm_spe_free;\n\tspe->auxtrace.evsel_is_auxtrace = arm_spe_evsel_is_auxtrace;\n\tsession->auxtrace = &spe->auxtrace;\n\n\tarm_spe_print_info(&auxtrace_info->priv[0]);\n\n\tif (dump_trace)\n\t\treturn 0;\n\n\tif (session->itrace_synth_opts && session->itrace_synth_opts->set)\n\t\tspe->synth_opts = *session->itrace_synth_opts;\n\telse\n\t\titrace_synth_opts__set_default(&spe->synth_opts, false);\n\n\terr = arm_spe_synth_events(spe, session);\n\tif (err)\n\t\tgoto err_free_queues;\n\n\terr = auxtrace_queues__process_index(&spe->queues, session);\n\tif (err)\n\t\tgoto err_free_queues;\n\n\tif (spe->queues.populated)\n\t\tspe->data_queued = true;\n\n\treturn 0;\n\nerr_free_queues:\n\tauxtrace_queues__free(&spe->queues);\n\tsession->auxtrace = NULL;\nerr_free:\n\tfree(spe);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}