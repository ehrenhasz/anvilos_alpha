{
  "module_name": "session.c",
  "hash_id": "f3884977b64a8ace7831b3a32ec8d33a5340888ecc896056362fcde103d00bb7",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/session.c",
  "human_readable_source": "\n#include <errno.h>\n#include <signal.h>\n#include <inttypes.h>\n#include <linux/err.h>\n#include <linux/kernel.h>\n#include <linux/zalloc.h>\n#include <api/fs/fs.h>\n\n#include <byteswap.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/mman.h>\n#include <perf/cpumap.h>\n\n#include \"map_symbol.h\"\n#include \"branch.h\"\n#include \"debug.h\"\n#include \"env.h\"\n#include \"evlist.h\"\n#include \"evsel.h\"\n#include \"memswap.h\"\n#include \"map.h\"\n#include \"symbol.h\"\n#include \"session.h\"\n#include \"tool.h\"\n#include \"perf_regs.h\"\n#include \"asm/bug.h\"\n#include \"auxtrace.h\"\n#include \"thread.h\"\n#include \"thread-stack.h\"\n#include \"sample-raw.h\"\n#include \"stat.h\"\n#include \"tsc.h\"\n#include \"ui/progress.h\"\n#include \"util.h\"\n#include \"arch/common.h\"\n#include \"units.h\"\n#include <internal/lib.h>\n\n#ifdef HAVE_ZSTD_SUPPORT\nstatic int perf_session__process_compressed_event(struct perf_session *session,\n\t\t\t\t\t\t  union perf_event *event, u64 file_offset,\n\t\t\t\t\t\t  const char *file_path)\n{\n\tvoid *src;\n\tsize_t decomp_size, src_size;\n\tu64 decomp_last_rem = 0;\n\tsize_t mmap_len, decomp_len = session->header.env.comp_mmap_len;\n\tstruct decomp *decomp, *decomp_last = session->active_decomp->decomp_last;\n\n\tif (decomp_last) {\n\t\tdecomp_last_rem = decomp_last->size - decomp_last->head;\n\t\tdecomp_len += decomp_last_rem;\n\t}\n\n\tmmap_len = sizeof(struct decomp) + decomp_len;\n\tdecomp = mmap(NULL, mmap_len, PROT_READ|PROT_WRITE,\n\t\t      MAP_ANONYMOUS|MAP_PRIVATE, -1, 0);\n\tif (decomp == MAP_FAILED) {\n\t\tpr_err(\"Couldn't allocate memory for decompression\\n\");\n\t\treturn -1;\n\t}\n\n\tdecomp->file_pos = file_offset;\n\tdecomp->file_path = file_path;\n\tdecomp->mmap_len = mmap_len;\n\tdecomp->head = 0;\n\n\tif (decomp_last_rem) {\n\t\tmemcpy(decomp->data, &(decomp_last->data[decomp_last->head]), decomp_last_rem);\n\t\tdecomp->size = decomp_last_rem;\n\t}\n\n\tsrc = (void *)event + sizeof(struct perf_record_compressed);\n\tsrc_size = event->pack.header.size - sizeof(struct perf_record_compressed);\n\n\tdecomp_size = zstd_decompress_stream(session->active_decomp->zstd_decomp, src, src_size,\n\t\t\t\t&(decomp->data[decomp_last_rem]), decomp_len - decomp_last_rem);\n\tif (!decomp_size) {\n\t\tmunmap(decomp, mmap_len);\n\t\tpr_err(\"Couldn't decompress data\\n\");\n\t\treturn -1;\n\t}\n\n\tdecomp->size += decomp_size;\n\n\tif (session->active_decomp->decomp == NULL)\n\t\tsession->active_decomp->decomp = decomp;\n\telse\n\t\tsession->active_decomp->decomp_last->next = decomp;\n\n\tsession->active_decomp->decomp_last = decomp;\n\n\tpr_debug(\"decomp (B): %zd to %zd\\n\", src_size, decomp_size);\n\n\treturn 0;\n}\n#else  \n#define perf_session__process_compressed_event perf_session__process_compressed_event_stub\n#endif\n\nstatic int perf_session__deliver_event(struct perf_session *session,\n\t\t\t\t       union perf_event *event,\n\t\t\t\t       struct perf_tool *tool,\n\t\t\t\t       u64 file_offset,\n\t\t\t\t       const char *file_path);\n\nstatic int perf_session__open(struct perf_session *session, int repipe_fd)\n{\n\tstruct perf_data *data = session->data;\n\n\tif (perf_session__read_header(session, repipe_fd) < 0) {\n\t\tpr_err(\"incompatible file format (rerun with -v to learn more)\\n\");\n\t\treturn -1;\n\t}\n\n\tif (perf_data__is_pipe(data))\n\t\treturn 0;\n\n\tif (perf_header__has_feat(&session->header, HEADER_STAT))\n\t\treturn 0;\n\n\tif (!evlist__valid_sample_type(session->evlist)) {\n\t\tpr_err(\"non matching sample_type\\n\");\n\t\treturn -1;\n\t}\n\n\tif (!evlist__valid_sample_id_all(session->evlist)) {\n\t\tpr_err(\"non matching sample_id_all\\n\");\n\t\treturn -1;\n\t}\n\n\tif (!evlist__valid_read_format(session->evlist)) {\n\t\tpr_err(\"non matching read_format\\n\");\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nvoid perf_session__set_id_hdr_size(struct perf_session *session)\n{\n\tu16 id_hdr_size = evlist__id_hdr_size(session->evlist);\n\n\tmachines__set_id_hdr_size(&session->machines, id_hdr_size);\n}\n\nint perf_session__create_kernel_maps(struct perf_session *session)\n{\n\tint ret = machine__create_kernel_maps(&session->machines.host);\n\n\tif (ret >= 0)\n\t\tret = machines__create_guest_kernel_maps(&session->machines);\n\treturn ret;\n}\n\nstatic void perf_session__destroy_kernel_maps(struct perf_session *session)\n{\n\tmachines__destroy_kernel_maps(&session->machines);\n}\n\nstatic bool perf_session__has_comm_exec(struct perf_session *session)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tif (evsel->core.attr.comm_exec)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void perf_session__set_comm_exec(struct perf_session *session)\n{\n\tbool comm_exec = perf_session__has_comm_exec(session);\n\n\tmachines__set_comm_exec(&session->machines, comm_exec);\n}\n\nstatic int ordered_events__deliver_event(struct ordered_events *oe,\n\t\t\t\t\t struct ordered_event *event)\n{\n\tstruct perf_session *session = container_of(oe, struct perf_session,\n\t\t\t\t\t\t    ordered_events);\n\n\treturn perf_session__deliver_event(session, event->event,\n\t\t\t\t\t   session->tool, event->file_offset,\n\t\t\t\t\t   event->file_path);\n}\n\nstruct perf_session *__perf_session__new(struct perf_data *data,\n\t\t\t\t\t bool repipe, int repipe_fd,\n\t\t\t\t\t struct perf_tool *tool)\n{\n\tint ret = -ENOMEM;\n\tstruct perf_session *session = zalloc(sizeof(*session));\n\n\tif (!session)\n\t\tgoto out;\n\n\tsession->repipe = repipe;\n\tsession->tool   = tool;\n\tsession->decomp_data.zstd_decomp = &session->zstd_data;\n\tsession->active_decomp = &session->decomp_data;\n\tINIT_LIST_HEAD(&session->auxtrace_index);\n\tmachines__init(&session->machines);\n\tordered_events__init(&session->ordered_events,\n\t\t\t     ordered_events__deliver_event, NULL);\n\n\tperf_env__init(&session->header.env);\n\tif (data) {\n\t\tret = perf_data__open(data);\n\t\tif (ret < 0)\n\t\t\tgoto out_delete;\n\n\t\tsession->data = data;\n\n\t\tif (perf_data__is_read(data)) {\n\t\t\tret = perf_session__open(session, repipe_fd);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_delete;\n\n\t\t\t \n\t\t\tif (!data->is_pipe) {\n\t\t\t\tperf_session__set_id_hdr_size(session);\n\t\t\t\tperf_session__set_comm_exec(session);\n\t\t\t}\n\n\t\t\tevlist__init_trace_event_sample_raw(session->evlist);\n\n\t\t\t \n\t\t\tif (data->is_dir) {\n\t\t\t\tret = perf_data__open_dir(data);\n\t\t\t\tif (ret)\n\t\t\t\t\tgoto out_delete;\n\t\t\t}\n\n\t\t\tif (!symbol_conf.kallsyms_name &&\n\t\t\t    !symbol_conf.vmlinux_name)\n\t\t\t\tsymbol_conf.kallsyms_name = perf_data__kallsyms_name(data);\n\t\t}\n\t} else  {\n\t\tsession->machines.host.env = &perf_env;\n\t}\n\n\tsession->machines.host.single_address_space =\n\t\tperf_env__single_address_space(session->machines.host.env);\n\n\tif (!data || perf_data__is_write(data)) {\n\t\t \n\t\tif (perf_session__create_kernel_maps(session) < 0)\n\t\t\tpr_warning(\"Cannot read kernel map\\n\");\n\t}\n\n\t \n\tif ((!data || !data->is_pipe) && tool && tool->ordering_requires_timestamps &&\n\t    tool->ordered_events && !evlist__sample_id_all(session->evlist)) {\n\t\tdump_printf(\"WARNING: No sample_id_all support, falling back to unordered processing\\n\");\n\t\ttool->ordered_events = false;\n\t}\n\n\treturn session;\n\n out_delete:\n\tperf_session__delete(session);\n out:\n\treturn ERR_PTR(ret);\n}\n\nstatic void perf_decomp__release_events(struct decomp *next)\n{\n\tstruct decomp *decomp;\n\tsize_t mmap_len;\n\n\tdo {\n\t\tdecomp = next;\n\t\tif (decomp == NULL)\n\t\t\tbreak;\n\t\tnext = decomp->next;\n\t\tmmap_len = decomp->mmap_len;\n\t\tmunmap(decomp, mmap_len);\n\t} while (1);\n}\n\nvoid perf_session__delete(struct perf_session *session)\n{\n\tif (session == NULL)\n\t\treturn;\n\tauxtrace__free(session);\n\tauxtrace_index__free(&session->auxtrace_index);\n\tperf_session__destroy_kernel_maps(session);\n\tperf_decomp__release_events(session->decomp_data.decomp);\n\tperf_env__exit(&session->header.env);\n\tmachines__exit(&session->machines);\n\tif (session->data) {\n\t\tif (perf_data__is_read(session->data))\n\t\t\tevlist__delete(session->evlist);\n\t\tperf_data__close(session->data);\n\t}\n#ifdef HAVE_LIBTRACEEVENT\n\ttrace_event__cleanup(&session->tevent);\n#endif\n\tfree(session);\n}\n\nstatic int process_event_synth_tracing_data_stub(struct perf_session *session\n\t\t\t\t\t\t __maybe_unused,\n\t\t\t\t\t\t union perf_event *event\n\t\t\t\t\t\t __maybe_unused)\n{\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_event_synth_attr_stub(struct perf_tool *tool __maybe_unused,\n\t\t\t\t\t union perf_event *event __maybe_unused,\n\t\t\t\t\t struct evlist **pevlist\n\t\t\t\t\t __maybe_unused)\n{\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_event_synth_event_update_stub(struct perf_tool *tool __maybe_unused,\n\t\t\t\t\t\t union perf_event *event __maybe_unused,\n\t\t\t\t\t\t struct evlist **pevlist\n\t\t\t\t\t\t __maybe_unused)\n{\n\tif (dump_trace)\n\t\tperf_event__fprintf_event_update(event, stdout);\n\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_event_sample_stub(struct perf_tool *tool __maybe_unused,\n\t\t\t\t     union perf_event *event __maybe_unused,\n\t\t\t\t     struct perf_sample *sample __maybe_unused,\n\t\t\t\t     struct evsel *evsel __maybe_unused,\n\t\t\t\t     struct machine *machine __maybe_unused)\n{\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_event_stub(struct perf_tool *tool __maybe_unused,\n\t\t\t      union perf_event *event __maybe_unused,\n\t\t\t      struct perf_sample *sample __maybe_unused,\n\t\t\t      struct machine *machine __maybe_unused)\n{\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_finished_round_stub(struct perf_tool *tool __maybe_unused,\n\t\t\t\t       union perf_event *event __maybe_unused,\n\t\t\t\t       struct ordered_events *oe __maybe_unused)\n{\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int skipn(int fd, off_t n)\n{\n\tchar buf[4096];\n\tssize_t ret;\n\n\twhile (n > 0) {\n\t\tret = read(fd, buf, min(n, (off_t)sizeof(buf)));\n\t\tif (ret <= 0)\n\t\t\treturn ret;\n\t\tn -= ret;\n\t}\n\n\treturn 0;\n}\n\nstatic s64 process_event_auxtrace_stub(struct perf_session *session __maybe_unused,\n\t\t\t\t       union perf_event *event)\n{\n\tdump_printf(\": unhandled!\\n\");\n\tif (perf_data__is_pipe(session->data))\n\t\tskipn(perf_data__fd(session->data), event->auxtrace.size);\n\treturn event->auxtrace.size;\n}\n\nstatic int process_event_op2_stub(struct perf_session *session __maybe_unused,\n\t\t\t\t  union perf_event *event __maybe_unused)\n{\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\n\nstatic\nint process_event_thread_map_stub(struct perf_session *session __maybe_unused,\n\t\t\t\t  union perf_event *event __maybe_unused)\n{\n\tif (dump_trace)\n\t\tperf_event__fprintf_thread_map(event, stdout);\n\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic\nint process_event_cpu_map_stub(struct perf_session *session __maybe_unused,\n\t\t\t       union perf_event *event __maybe_unused)\n{\n\tif (dump_trace)\n\t\tperf_event__fprintf_cpu_map(event, stdout);\n\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic\nint process_event_stat_config_stub(struct perf_session *session __maybe_unused,\n\t\t\t\t   union perf_event *event __maybe_unused)\n{\n\tif (dump_trace)\n\t\tperf_event__fprintf_stat_config(event, stdout);\n\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_stat_stub(struct perf_session *perf_session __maybe_unused,\n\t\t\t     union perf_event *event)\n{\n\tif (dump_trace)\n\t\tperf_event__fprintf_stat(event, stdout);\n\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_stat_round_stub(struct perf_session *perf_session __maybe_unused,\n\t\t\t\t   union perf_event *event)\n{\n\tif (dump_trace)\n\t\tperf_event__fprintf_stat_round(event, stdout);\n\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int process_event_time_conv_stub(struct perf_session *perf_session __maybe_unused,\n\t\t\t\t\tunion perf_event *event)\n{\n\tif (dump_trace)\n\t\tperf_event__fprintf_time_conv(event, stdout);\n\n\tdump_printf(\": unhandled!\\n\");\n\treturn 0;\n}\n\nstatic int perf_session__process_compressed_event_stub(struct perf_session *session __maybe_unused,\n\t\t\t\t\t\t       union perf_event *event __maybe_unused,\n\t\t\t\t\t\t       u64 file_offset __maybe_unused,\n\t\t\t\t\t\t       const char *file_path __maybe_unused)\n{\n       dump_printf(\": unhandled!\\n\");\n       return 0;\n}\n\nvoid perf_tool__fill_defaults(struct perf_tool *tool)\n{\n\tif (tool->sample == NULL)\n\t\ttool->sample = process_event_sample_stub;\n\tif (tool->mmap == NULL)\n\t\ttool->mmap = process_event_stub;\n\tif (tool->mmap2 == NULL)\n\t\ttool->mmap2 = process_event_stub;\n\tif (tool->comm == NULL)\n\t\ttool->comm = process_event_stub;\n\tif (tool->namespaces == NULL)\n\t\ttool->namespaces = process_event_stub;\n\tif (tool->cgroup == NULL)\n\t\ttool->cgroup = process_event_stub;\n\tif (tool->fork == NULL)\n\t\ttool->fork = process_event_stub;\n\tif (tool->exit == NULL)\n\t\ttool->exit = process_event_stub;\n\tif (tool->lost == NULL)\n\t\ttool->lost = perf_event__process_lost;\n\tif (tool->lost_samples == NULL)\n\t\ttool->lost_samples = perf_event__process_lost_samples;\n\tif (tool->aux == NULL)\n\t\ttool->aux = perf_event__process_aux;\n\tif (tool->itrace_start == NULL)\n\t\ttool->itrace_start = perf_event__process_itrace_start;\n\tif (tool->context_switch == NULL)\n\t\ttool->context_switch = perf_event__process_switch;\n\tif (tool->ksymbol == NULL)\n\t\ttool->ksymbol = perf_event__process_ksymbol;\n\tif (tool->bpf == NULL)\n\t\ttool->bpf = perf_event__process_bpf;\n\tif (tool->text_poke == NULL)\n\t\ttool->text_poke = perf_event__process_text_poke;\n\tif (tool->aux_output_hw_id == NULL)\n\t\ttool->aux_output_hw_id = perf_event__process_aux_output_hw_id;\n\tif (tool->read == NULL)\n\t\ttool->read = process_event_sample_stub;\n\tif (tool->throttle == NULL)\n\t\ttool->throttle = process_event_stub;\n\tif (tool->unthrottle == NULL)\n\t\ttool->unthrottle = process_event_stub;\n\tif (tool->attr == NULL)\n\t\ttool->attr = process_event_synth_attr_stub;\n\tif (tool->event_update == NULL)\n\t\ttool->event_update = process_event_synth_event_update_stub;\n\tif (tool->tracing_data == NULL)\n\t\ttool->tracing_data = process_event_synth_tracing_data_stub;\n\tif (tool->build_id == NULL)\n\t\ttool->build_id = process_event_op2_stub;\n\tif (tool->finished_round == NULL) {\n\t\tif (tool->ordered_events)\n\t\t\ttool->finished_round = perf_event__process_finished_round;\n\t\telse\n\t\t\ttool->finished_round = process_finished_round_stub;\n\t}\n\tif (tool->id_index == NULL)\n\t\ttool->id_index = process_event_op2_stub;\n\tif (tool->auxtrace_info == NULL)\n\t\ttool->auxtrace_info = process_event_op2_stub;\n\tif (tool->auxtrace == NULL)\n\t\ttool->auxtrace = process_event_auxtrace_stub;\n\tif (tool->auxtrace_error == NULL)\n\t\ttool->auxtrace_error = process_event_op2_stub;\n\tif (tool->thread_map == NULL)\n\t\ttool->thread_map = process_event_thread_map_stub;\n\tif (tool->cpu_map == NULL)\n\t\ttool->cpu_map = process_event_cpu_map_stub;\n\tif (tool->stat_config == NULL)\n\t\ttool->stat_config = process_event_stat_config_stub;\n\tif (tool->stat == NULL)\n\t\ttool->stat = process_stat_stub;\n\tif (tool->stat_round == NULL)\n\t\ttool->stat_round = process_stat_round_stub;\n\tif (tool->time_conv == NULL)\n\t\ttool->time_conv = process_event_time_conv_stub;\n\tif (tool->feature == NULL)\n\t\ttool->feature = process_event_op2_stub;\n\tif (tool->compressed == NULL)\n\t\ttool->compressed = perf_session__process_compressed_event;\n\tif (tool->finished_init == NULL)\n\t\ttool->finished_init = process_event_op2_stub;\n}\n\nstatic void swap_sample_id_all(union perf_event *event, void *data)\n{\n\tvoid *end = (void *) event + event->header.size;\n\tint size = end - data;\n\n\tBUG_ON(size % sizeof(u64));\n\tmem_bswap_64(data, size);\n}\n\nstatic void perf_event__all64_swap(union perf_event *event,\n\t\t\t\t   bool sample_id_all __maybe_unused)\n{\n\tstruct perf_event_header *hdr = &event->header;\n\tmem_bswap_64(hdr + 1, event->header.size - sizeof(*hdr));\n}\n\nstatic void perf_event__comm_swap(union perf_event *event, bool sample_id_all)\n{\n\tevent->comm.pid = bswap_32(event->comm.pid);\n\tevent->comm.tid = bswap_32(event->comm.tid);\n\n\tif (sample_id_all) {\n\t\tvoid *data = &event->comm.comm;\n\n\t\tdata += PERF_ALIGN(strlen(data) + 1, sizeof(u64));\n\t\tswap_sample_id_all(event, data);\n\t}\n}\n\nstatic void perf_event__mmap_swap(union perf_event *event,\n\t\t\t\t  bool sample_id_all)\n{\n\tevent->mmap.pid\t  = bswap_32(event->mmap.pid);\n\tevent->mmap.tid\t  = bswap_32(event->mmap.tid);\n\tevent->mmap.start = bswap_64(event->mmap.start);\n\tevent->mmap.len\t  = bswap_64(event->mmap.len);\n\tevent->mmap.pgoff = bswap_64(event->mmap.pgoff);\n\n\tif (sample_id_all) {\n\t\tvoid *data = &event->mmap.filename;\n\n\t\tdata += PERF_ALIGN(strlen(data) + 1, sizeof(u64));\n\t\tswap_sample_id_all(event, data);\n\t}\n}\n\nstatic void perf_event__mmap2_swap(union perf_event *event,\n\t\t\t\t  bool sample_id_all)\n{\n\tevent->mmap2.pid   = bswap_32(event->mmap2.pid);\n\tevent->mmap2.tid   = bswap_32(event->mmap2.tid);\n\tevent->mmap2.start = bswap_64(event->mmap2.start);\n\tevent->mmap2.len   = bswap_64(event->mmap2.len);\n\tevent->mmap2.pgoff = bswap_64(event->mmap2.pgoff);\n\n\tif (!(event->header.misc & PERF_RECORD_MISC_MMAP_BUILD_ID)) {\n\t\tevent->mmap2.maj   = bswap_32(event->mmap2.maj);\n\t\tevent->mmap2.min   = bswap_32(event->mmap2.min);\n\t\tevent->mmap2.ino   = bswap_64(event->mmap2.ino);\n\t\tevent->mmap2.ino_generation = bswap_64(event->mmap2.ino_generation);\n\t}\n\n\tif (sample_id_all) {\n\t\tvoid *data = &event->mmap2.filename;\n\n\t\tdata += PERF_ALIGN(strlen(data) + 1, sizeof(u64));\n\t\tswap_sample_id_all(event, data);\n\t}\n}\nstatic void perf_event__task_swap(union perf_event *event, bool sample_id_all)\n{\n\tevent->fork.pid\t = bswap_32(event->fork.pid);\n\tevent->fork.tid\t = bswap_32(event->fork.tid);\n\tevent->fork.ppid = bswap_32(event->fork.ppid);\n\tevent->fork.ptid = bswap_32(event->fork.ptid);\n\tevent->fork.time = bswap_64(event->fork.time);\n\n\tif (sample_id_all)\n\t\tswap_sample_id_all(event, &event->fork + 1);\n}\n\nstatic void perf_event__read_swap(union perf_event *event, bool sample_id_all)\n{\n\tevent->read.pid\t\t = bswap_32(event->read.pid);\n\tevent->read.tid\t\t = bswap_32(event->read.tid);\n\tevent->read.value\t = bswap_64(event->read.value);\n\tevent->read.time_enabled = bswap_64(event->read.time_enabled);\n\tevent->read.time_running = bswap_64(event->read.time_running);\n\tevent->read.id\t\t = bswap_64(event->read.id);\n\n\tif (sample_id_all)\n\t\tswap_sample_id_all(event, &event->read + 1);\n}\n\nstatic void perf_event__aux_swap(union perf_event *event, bool sample_id_all)\n{\n\tevent->aux.aux_offset = bswap_64(event->aux.aux_offset);\n\tevent->aux.aux_size   = bswap_64(event->aux.aux_size);\n\tevent->aux.flags      = bswap_64(event->aux.flags);\n\n\tif (sample_id_all)\n\t\tswap_sample_id_all(event, &event->aux + 1);\n}\n\nstatic void perf_event__itrace_start_swap(union perf_event *event,\n\t\t\t\t\t  bool sample_id_all)\n{\n\tevent->itrace_start.pid\t = bswap_32(event->itrace_start.pid);\n\tevent->itrace_start.tid\t = bswap_32(event->itrace_start.tid);\n\n\tif (sample_id_all)\n\t\tswap_sample_id_all(event, &event->itrace_start + 1);\n}\n\nstatic void perf_event__switch_swap(union perf_event *event, bool sample_id_all)\n{\n\tif (event->header.type == PERF_RECORD_SWITCH_CPU_WIDE) {\n\t\tevent->context_switch.next_prev_pid =\n\t\t\t\tbswap_32(event->context_switch.next_prev_pid);\n\t\tevent->context_switch.next_prev_tid =\n\t\t\t\tbswap_32(event->context_switch.next_prev_tid);\n\t}\n\n\tif (sample_id_all)\n\t\tswap_sample_id_all(event, &event->context_switch + 1);\n}\n\nstatic void perf_event__text_poke_swap(union perf_event *event, bool sample_id_all)\n{\n\tevent->text_poke.addr    = bswap_64(event->text_poke.addr);\n\tevent->text_poke.old_len = bswap_16(event->text_poke.old_len);\n\tevent->text_poke.new_len = bswap_16(event->text_poke.new_len);\n\n\tif (sample_id_all) {\n\t\tsize_t len = sizeof(event->text_poke.old_len) +\n\t\t\t     sizeof(event->text_poke.new_len) +\n\t\t\t     event->text_poke.old_len +\n\t\t\t     event->text_poke.new_len;\n\t\tvoid *data = &event->text_poke.old_len;\n\n\t\tdata += PERF_ALIGN(len, sizeof(u64));\n\t\tswap_sample_id_all(event, data);\n\t}\n}\n\nstatic void perf_event__throttle_swap(union perf_event *event,\n\t\t\t\t      bool sample_id_all)\n{\n\tevent->throttle.time\t  = bswap_64(event->throttle.time);\n\tevent->throttle.id\t  = bswap_64(event->throttle.id);\n\tevent->throttle.stream_id = bswap_64(event->throttle.stream_id);\n\n\tif (sample_id_all)\n\t\tswap_sample_id_all(event, &event->throttle + 1);\n}\n\nstatic void perf_event__namespaces_swap(union perf_event *event,\n\t\t\t\t\tbool sample_id_all)\n{\n\tu64 i;\n\n\tevent->namespaces.pid\t\t= bswap_32(event->namespaces.pid);\n\tevent->namespaces.tid\t\t= bswap_32(event->namespaces.tid);\n\tevent->namespaces.nr_namespaces\t= bswap_64(event->namespaces.nr_namespaces);\n\n\tfor (i = 0; i < event->namespaces.nr_namespaces; i++) {\n\t\tstruct perf_ns_link_info *ns = &event->namespaces.link_info[i];\n\n\t\tns->dev = bswap_64(ns->dev);\n\t\tns->ino = bswap_64(ns->ino);\n\t}\n\n\tif (sample_id_all)\n\t\tswap_sample_id_all(event, &event->namespaces.link_info[i]);\n}\n\nstatic void perf_event__cgroup_swap(union perf_event *event, bool sample_id_all)\n{\n\tevent->cgroup.id = bswap_64(event->cgroup.id);\n\n\tif (sample_id_all) {\n\t\tvoid *data = &event->cgroup.path;\n\n\t\tdata += PERF_ALIGN(strlen(data) + 1, sizeof(u64));\n\t\tswap_sample_id_all(event, data);\n\t}\n}\n\nstatic u8 revbyte(u8 b)\n{\n\tint rev = (b >> 4) | ((b & 0xf) << 4);\n\trev = ((rev & 0xcc) >> 2) | ((rev & 0x33) << 2);\n\trev = ((rev & 0xaa) >> 1) | ((rev & 0x55) << 1);\n\treturn (u8) rev;\n}\n\n \nstatic void swap_bitfield(u8 *p, unsigned len)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < len; i++) {\n\t\t*p = revbyte(*p);\n\t\tp++;\n\t}\n}\n\n \nvoid perf_event__attr_swap(struct perf_event_attr *attr)\n{\n\tattr->type\t\t= bswap_32(attr->type);\n\tattr->size\t\t= bswap_32(attr->size);\n\n#define bswap_safe(f, n) \t\t\t\t\t\\\n\t(attr->size > (offsetof(struct perf_event_attr, f) + \t\\\n\t\t       sizeof(attr->f) * (n)))\n#define bswap_field(f, sz) \t\t\t\\\ndo { \t\t\t\t\t\t\\\n\tif (bswap_safe(f, 0))\t\t\t\\\n\t\tattr->f = bswap_##sz(attr->f);\t\\\n} while(0)\n#define bswap_field_16(f) bswap_field(f, 16)\n#define bswap_field_32(f) bswap_field(f, 32)\n#define bswap_field_64(f) bswap_field(f, 64)\n\n\tbswap_field_64(config);\n\tbswap_field_64(sample_period);\n\tbswap_field_64(sample_type);\n\tbswap_field_64(read_format);\n\tbswap_field_32(wakeup_events);\n\tbswap_field_32(bp_type);\n\tbswap_field_64(bp_addr);\n\tbswap_field_64(bp_len);\n\tbswap_field_64(branch_sample_type);\n\tbswap_field_64(sample_regs_user);\n\tbswap_field_32(sample_stack_user);\n\tbswap_field_32(aux_watermark);\n\tbswap_field_16(sample_max_stack);\n\tbswap_field_32(aux_sample_size);\n\n\t \n\tif (bswap_safe(read_format, 1))\n\t\tswap_bitfield((u8 *) (&attr->read_format + 1),\n\t\t\t      sizeof(u64));\n#undef bswap_field_64\n#undef bswap_field_32\n#undef bswap_field\n#undef bswap_safe\n}\n\nstatic void perf_event__hdr_attr_swap(union perf_event *event,\n\t\t\t\t      bool sample_id_all __maybe_unused)\n{\n\tsize_t size;\n\n\tperf_event__attr_swap(&event->attr.attr);\n\n\tsize = event->header.size;\n\tsize -= perf_record_header_attr_id(event) - (void *)event;\n\tmem_bswap_64(perf_record_header_attr_id(event), size);\n}\n\nstatic void perf_event__event_update_swap(union perf_event *event,\n\t\t\t\t\t  bool sample_id_all __maybe_unused)\n{\n\tevent->event_update.type = bswap_64(event->event_update.type);\n\tevent->event_update.id   = bswap_64(event->event_update.id);\n}\n\nstatic void perf_event__event_type_swap(union perf_event *event,\n\t\t\t\t\tbool sample_id_all __maybe_unused)\n{\n\tevent->event_type.event_type.event_id =\n\t\tbswap_64(event->event_type.event_type.event_id);\n}\n\nstatic void perf_event__tracing_data_swap(union perf_event *event,\n\t\t\t\t\t  bool sample_id_all __maybe_unused)\n{\n\tevent->tracing_data.size = bswap_32(event->tracing_data.size);\n}\n\nstatic void perf_event__auxtrace_info_swap(union perf_event *event,\n\t\t\t\t\t   bool sample_id_all __maybe_unused)\n{\n\tsize_t size;\n\n\tevent->auxtrace_info.type = bswap_32(event->auxtrace_info.type);\n\n\tsize = event->header.size;\n\tsize -= (void *)&event->auxtrace_info.priv - (void *)event;\n\tmem_bswap_64(event->auxtrace_info.priv, size);\n}\n\nstatic void perf_event__auxtrace_swap(union perf_event *event,\n\t\t\t\t      bool sample_id_all __maybe_unused)\n{\n\tevent->auxtrace.size      = bswap_64(event->auxtrace.size);\n\tevent->auxtrace.offset    = bswap_64(event->auxtrace.offset);\n\tevent->auxtrace.reference = bswap_64(event->auxtrace.reference);\n\tevent->auxtrace.idx       = bswap_32(event->auxtrace.idx);\n\tevent->auxtrace.tid       = bswap_32(event->auxtrace.tid);\n\tevent->auxtrace.cpu       = bswap_32(event->auxtrace.cpu);\n}\n\nstatic void perf_event__auxtrace_error_swap(union perf_event *event,\n\t\t\t\t\t    bool sample_id_all __maybe_unused)\n{\n\tevent->auxtrace_error.type = bswap_32(event->auxtrace_error.type);\n\tevent->auxtrace_error.code = bswap_32(event->auxtrace_error.code);\n\tevent->auxtrace_error.cpu  = bswap_32(event->auxtrace_error.cpu);\n\tevent->auxtrace_error.pid  = bswap_32(event->auxtrace_error.pid);\n\tevent->auxtrace_error.tid  = bswap_32(event->auxtrace_error.tid);\n\tevent->auxtrace_error.fmt  = bswap_32(event->auxtrace_error.fmt);\n\tevent->auxtrace_error.ip   = bswap_64(event->auxtrace_error.ip);\n\tif (event->auxtrace_error.fmt)\n\t\tevent->auxtrace_error.time = bswap_64(event->auxtrace_error.time);\n\tif (event->auxtrace_error.fmt >= 2) {\n\t\tevent->auxtrace_error.machine_pid = bswap_32(event->auxtrace_error.machine_pid);\n\t\tevent->auxtrace_error.vcpu = bswap_32(event->auxtrace_error.vcpu);\n\t}\n}\n\nstatic void perf_event__thread_map_swap(union perf_event *event,\n\t\t\t\t\tbool sample_id_all __maybe_unused)\n{\n\tunsigned i;\n\n\tevent->thread_map.nr = bswap_64(event->thread_map.nr);\n\n\tfor (i = 0; i < event->thread_map.nr; i++)\n\t\tevent->thread_map.entries[i].pid = bswap_64(event->thread_map.entries[i].pid);\n}\n\nstatic void perf_event__cpu_map_swap(union perf_event *event,\n\t\t\t\t     bool sample_id_all __maybe_unused)\n{\n\tstruct perf_record_cpu_map_data *data = &event->cpu_map.data;\n\n\tdata->type = bswap_16(data->type);\n\n\tswitch (data->type) {\n\tcase PERF_CPU_MAP__CPUS:\n\t\tdata->cpus_data.nr = bswap_16(data->cpus_data.nr);\n\n\t\tfor (unsigned i = 0; i < data->cpus_data.nr; i++)\n\t\t\tdata->cpus_data.cpu[i] = bswap_16(data->cpus_data.cpu[i]);\n\t\tbreak;\n\tcase PERF_CPU_MAP__MASK:\n\t\tdata->mask32_data.long_size = bswap_16(data->mask32_data.long_size);\n\n\t\tswitch (data->mask32_data.long_size) {\n\t\tcase 4:\n\t\t\tdata->mask32_data.nr = bswap_16(data->mask32_data.nr);\n\t\t\tfor (unsigned i = 0; i < data->mask32_data.nr; i++)\n\t\t\t\tdata->mask32_data.mask[i] = bswap_32(data->mask32_data.mask[i]);\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tdata->mask64_data.nr = bswap_16(data->mask64_data.nr);\n\t\t\tfor (unsigned i = 0; i < data->mask64_data.nr; i++)\n\t\t\t\tdata->mask64_data.mask[i] = bswap_64(data->mask64_data.mask[i]);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"cpu_map swap: unsupported long size\\n\");\n\t\t}\n\t\tbreak;\n\tcase PERF_CPU_MAP__RANGE_CPUS:\n\t\tdata->range_cpu_data.start_cpu = bswap_16(data->range_cpu_data.start_cpu);\n\t\tdata->range_cpu_data.end_cpu = bswap_16(data->range_cpu_data.end_cpu);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void perf_event__stat_config_swap(union perf_event *event,\n\t\t\t\t\t bool sample_id_all __maybe_unused)\n{\n\tu64 size;\n\n\tsize  = bswap_64(event->stat_config.nr) * sizeof(event->stat_config.data[0]);\n\tsize += 1;  \n\tmem_bswap_64(&event->stat_config.nr, size);\n}\n\nstatic void perf_event__stat_swap(union perf_event *event,\n\t\t\t\t  bool sample_id_all __maybe_unused)\n{\n\tevent->stat.id     = bswap_64(event->stat.id);\n\tevent->stat.thread = bswap_32(event->stat.thread);\n\tevent->stat.cpu    = bswap_32(event->stat.cpu);\n\tevent->stat.val    = bswap_64(event->stat.val);\n\tevent->stat.ena    = bswap_64(event->stat.ena);\n\tevent->stat.run    = bswap_64(event->stat.run);\n}\n\nstatic void perf_event__stat_round_swap(union perf_event *event,\n\t\t\t\t\tbool sample_id_all __maybe_unused)\n{\n\tevent->stat_round.type = bswap_64(event->stat_round.type);\n\tevent->stat_round.time = bswap_64(event->stat_round.time);\n}\n\nstatic void perf_event__time_conv_swap(union perf_event *event,\n\t\t\t\t       bool sample_id_all __maybe_unused)\n{\n\tevent->time_conv.time_shift = bswap_64(event->time_conv.time_shift);\n\tevent->time_conv.time_mult  = bswap_64(event->time_conv.time_mult);\n\tevent->time_conv.time_zero  = bswap_64(event->time_conv.time_zero);\n\n\tif (event_contains(event->time_conv, time_cycles)) {\n\t\tevent->time_conv.time_cycles = bswap_64(event->time_conv.time_cycles);\n\t\tevent->time_conv.time_mask = bswap_64(event->time_conv.time_mask);\n\t}\n}\n\ntypedef void (*perf_event__swap_op)(union perf_event *event,\n\t\t\t\t    bool sample_id_all);\n\nstatic perf_event__swap_op perf_event__swap_ops[] = {\n\t[PERF_RECORD_MMAP]\t\t  = perf_event__mmap_swap,\n\t[PERF_RECORD_MMAP2]\t\t  = perf_event__mmap2_swap,\n\t[PERF_RECORD_COMM]\t\t  = perf_event__comm_swap,\n\t[PERF_RECORD_FORK]\t\t  = perf_event__task_swap,\n\t[PERF_RECORD_EXIT]\t\t  = perf_event__task_swap,\n\t[PERF_RECORD_LOST]\t\t  = perf_event__all64_swap,\n\t[PERF_RECORD_READ]\t\t  = perf_event__read_swap,\n\t[PERF_RECORD_THROTTLE]\t\t  = perf_event__throttle_swap,\n\t[PERF_RECORD_UNTHROTTLE]\t  = perf_event__throttle_swap,\n\t[PERF_RECORD_SAMPLE]\t\t  = perf_event__all64_swap,\n\t[PERF_RECORD_AUX]\t\t  = perf_event__aux_swap,\n\t[PERF_RECORD_ITRACE_START]\t  = perf_event__itrace_start_swap,\n\t[PERF_RECORD_LOST_SAMPLES]\t  = perf_event__all64_swap,\n\t[PERF_RECORD_SWITCH]\t\t  = perf_event__switch_swap,\n\t[PERF_RECORD_SWITCH_CPU_WIDE]\t  = perf_event__switch_swap,\n\t[PERF_RECORD_NAMESPACES]\t  = perf_event__namespaces_swap,\n\t[PERF_RECORD_CGROUP]\t\t  = perf_event__cgroup_swap,\n\t[PERF_RECORD_TEXT_POKE]\t\t  = perf_event__text_poke_swap,\n\t[PERF_RECORD_AUX_OUTPUT_HW_ID]\t  = perf_event__all64_swap,\n\t[PERF_RECORD_HEADER_ATTR]\t  = perf_event__hdr_attr_swap,\n\t[PERF_RECORD_HEADER_EVENT_TYPE]\t  = perf_event__event_type_swap,\n\t[PERF_RECORD_HEADER_TRACING_DATA] = perf_event__tracing_data_swap,\n\t[PERF_RECORD_HEADER_BUILD_ID]\t  = NULL,\n\t[PERF_RECORD_ID_INDEX]\t\t  = perf_event__all64_swap,\n\t[PERF_RECORD_AUXTRACE_INFO]\t  = perf_event__auxtrace_info_swap,\n\t[PERF_RECORD_AUXTRACE]\t\t  = perf_event__auxtrace_swap,\n\t[PERF_RECORD_AUXTRACE_ERROR]\t  = perf_event__auxtrace_error_swap,\n\t[PERF_RECORD_THREAD_MAP]\t  = perf_event__thread_map_swap,\n\t[PERF_RECORD_CPU_MAP]\t\t  = perf_event__cpu_map_swap,\n\t[PERF_RECORD_STAT_CONFIG]\t  = perf_event__stat_config_swap,\n\t[PERF_RECORD_STAT]\t\t  = perf_event__stat_swap,\n\t[PERF_RECORD_STAT_ROUND]\t  = perf_event__stat_round_swap,\n\t[PERF_RECORD_EVENT_UPDATE]\t  = perf_event__event_update_swap,\n\t[PERF_RECORD_TIME_CONV]\t\t  = perf_event__time_conv_swap,\n\t[PERF_RECORD_HEADER_MAX]\t  = NULL,\n};\n\n \nint perf_event__process_finished_round(struct perf_tool *tool __maybe_unused,\n\t\t\t\t       union perf_event *event __maybe_unused,\n\t\t\t\t       struct ordered_events *oe)\n{\n\tif (dump_trace)\n\t\tfprintf(stdout, \"\\n\");\n\treturn ordered_events__flush(oe, OE_FLUSH__ROUND);\n}\n\nint perf_session__queue_event(struct perf_session *s, union perf_event *event,\n\t\t\t      u64 timestamp, u64 file_offset, const char *file_path)\n{\n\treturn ordered_events__queue(&s->ordered_events, event, timestamp, file_offset, file_path);\n}\n\nstatic void callchain__lbr_callstack_printf(struct perf_sample *sample)\n{\n\tstruct ip_callchain *callchain = sample->callchain;\n\tstruct branch_stack *lbr_stack = sample->branch_stack;\n\tstruct branch_entry *entries = perf_sample__branch_entries(sample);\n\tu64 kernel_callchain_nr = callchain->nr;\n\tunsigned int i;\n\n\tfor (i = 0; i < kernel_callchain_nr; i++) {\n\t\tif (callchain->ips[i] == PERF_CONTEXT_USER)\n\t\t\tbreak;\n\t}\n\n\tif ((i != kernel_callchain_nr) && lbr_stack->nr) {\n\t\tu64 total_nr;\n\t\t \n\t\ttotal_nr = i + 1 + lbr_stack->nr + 1;\n\t\tkernel_callchain_nr = i + 1;\n\n\t\tprintf(\"... LBR call chain: nr:%\" PRIu64 \"\\n\", total_nr);\n\n\t\tfor (i = 0; i < kernel_callchain_nr; i++)\n\t\t\tprintf(\"..... %2d: %016\" PRIx64 \"\\n\",\n\t\t\t       i, callchain->ips[i]);\n\n\t\tprintf(\"..... %2d: %016\" PRIx64 \"\\n\",\n\t\t       (int)(kernel_callchain_nr), entries[0].to);\n\t\tfor (i = 0; i < lbr_stack->nr; i++)\n\t\t\tprintf(\"..... %2d: %016\" PRIx64 \"\\n\",\n\t\t\t       (int)(i + kernel_callchain_nr + 1), entries[i].from);\n\t}\n}\n\nstatic void callchain__printf(struct evsel *evsel,\n\t\t\t      struct perf_sample *sample)\n{\n\tunsigned int i;\n\tstruct ip_callchain *callchain = sample->callchain;\n\n\tif (evsel__has_branch_callstack(evsel))\n\t\tcallchain__lbr_callstack_printf(sample);\n\n\tprintf(\"... FP chain: nr:%\" PRIu64 \"\\n\", callchain->nr);\n\n\tfor (i = 0; i < callchain->nr; i++)\n\t\tprintf(\"..... %2d: %016\" PRIx64 \"\\n\",\n\t\t       i, callchain->ips[i]);\n}\n\nstatic void branch_stack__printf(struct perf_sample *sample, bool callstack)\n{\n\tstruct branch_entry *entries = perf_sample__branch_entries(sample);\n\tuint64_t i;\n\n\tif (!callstack) {\n\t\tprintf(\"%s: nr:%\" PRIu64 \"\\n\", \"... branch stack\", sample->branch_stack->nr);\n\t} else {\n\t\t \n\t\tprintf(\"%s: nr:%\" PRIu64 \"\\n\", \"... branch callstack\", sample->branch_stack->nr+1);\n\t}\n\n\tfor (i = 0; i < sample->branch_stack->nr; i++) {\n\t\tstruct branch_entry *e = &entries[i];\n\n\t\tif (!callstack) {\n\t\t\tprintf(\"..... %2\"PRIu64\": %016\" PRIx64 \" -> %016\" PRIx64 \" %hu cycles %s%s%s%s %x %s %s\\n\",\n\t\t\t\ti, e->from, e->to,\n\t\t\t\t(unsigned short)e->flags.cycles,\n\t\t\t\te->flags.mispred ? \"M\" : \" \",\n\t\t\t\te->flags.predicted ? \"P\" : \" \",\n\t\t\t\te->flags.abort ? \"A\" : \" \",\n\t\t\t\te->flags.in_tx ? \"T\" : \" \",\n\t\t\t\t(unsigned)e->flags.reserved,\n\t\t\t\tget_branch_type(e),\n\t\t\t\te->flags.spec ? branch_spec_desc(e->flags.spec) : \"\");\n\t\t} else {\n\t\t\tif (i == 0) {\n\t\t\t\tprintf(\"..... %2\"PRIu64\": %016\" PRIx64 \"\\n\"\n\t\t\t\t       \"..... %2\"PRIu64\": %016\" PRIx64 \"\\n\",\n\t\t\t\t\t\ti, e->to, i+1, e->from);\n\t\t\t} else {\n\t\t\t\tprintf(\"..... %2\"PRIu64\": %016\" PRIx64 \"\\n\", i+1, e->from);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void regs_dump__printf(u64 mask, u64 *regs, const char *arch)\n{\n\tunsigned rid, i = 0;\n\n\tfor_each_set_bit(rid, (unsigned long *) &mask, sizeof(mask) * 8) {\n\t\tu64 val = regs[i++];\n\n\t\tprintf(\".... %-5s 0x%016\" PRIx64 \"\\n\",\n\t\t       perf_reg_name(rid, arch), val);\n\t}\n}\n\nstatic const char *regs_abi[] = {\n\t[PERF_SAMPLE_REGS_ABI_NONE] = \"none\",\n\t[PERF_SAMPLE_REGS_ABI_32] = \"32-bit\",\n\t[PERF_SAMPLE_REGS_ABI_64] = \"64-bit\",\n};\n\nstatic inline const char *regs_dump_abi(struct regs_dump *d)\n{\n\tif (d->abi > PERF_SAMPLE_REGS_ABI_64)\n\t\treturn \"unknown\";\n\n\treturn regs_abi[d->abi];\n}\n\nstatic void regs__printf(const char *type, struct regs_dump *regs, const char *arch)\n{\n\tu64 mask = regs->mask;\n\n\tprintf(\"... %s regs: mask 0x%\" PRIx64 \" ABI %s\\n\",\n\t       type,\n\t       mask,\n\t       regs_dump_abi(regs));\n\n\tregs_dump__printf(mask, regs->regs, arch);\n}\n\nstatic void regs_user__printf(struct perf_sample *sample, const char *arch)\n{\n\tstruct regs_dump *user_regs = &sample->user_regs;\n\n\tif (user_regs->regs)\n\t\tregs__printf(\"user\", user_regs, arch);\n}\n\nstatic void regs_intr__printf(struct perf_sample *sample, const char *arch)\n{\n\tstruct regs_dump *intr_regs = &sample->intr_regs;\n\n\tif (intr_regs->regs)\n\t\tregs__printf(\"intr\", intr_regs, arch);\n}\n\nstatic void stack_user__printf(struct stack_dump *dump)\n{\n\tprintf(\"... ustack: size %\" PRIu64 \", offset 0x%x\\n\",\n\t       dump->size, dump->offset);\n}\n\nstatic void evlist__print_tstamp(struct evlist *evlist, union perf_event *event, struct perf_sample *sample)\n{\n\tu64 sample_type = __evlist__combined_sample_type(evlist);\n\n\tif (event->header.type != PERF_RECORD_SAMPLE &&\n\t    !evlist__sample_id_all(evlist)) {\n\t\tfputs(\"-1 -1 \", stdout);\n\t\treturn;\n\t}\n\n\tif ((sample_type & PERF_SAMPLE_CPU))\n\t\tprintf(\"%u \", sample->cpu);\n\n\tif (sample_type & PERF_SAMPLE_TIME)\n\t\tprintf(\"%\" PRIu64 \" \", sample->time);\n}\n\nstatic void sample_read__printf(struct perf_sample *sample, u64 read_format)\n{\n\tprintf(\"... sample_read:\\n\");\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)\n\t\tprintf(\"...... time enabled %016\" PRIx64 \"\\n\",\n\t\t       sample->read.time_enabled);\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)\n\t\tprintf(\"...... time running %016\" PRIx64 \"\\n\",\n\t\t       sample->read.time_running);\n\n\tif (read_format & PERF_FORMAT_GROUP) {\n\t\tstruct sample_read_value *value = sample->read.group.values;\n\n\t\tprintf(\".... group nr %\" PRIu64 \"\\n\", sample->read.group.nr);\n\n\t\tsample_read_group__for_each(value, sample->read.group.nr, read_format) {\n\t\t\tprintf(\"..... id %016\" PRIx64\n\t\t\t       \", value %016\" PRIx64,\n\t\t\t       value->id, value->value);\n\t\t\tif (read_format & PERF_FORMAT_LOST)\n\t\t\t\tprintf(\", lost %\" PRIu64, value->lost);\n\t\t\tprintf(\"\\n\");\n\t\t}\n\t} else {\n\t\tprintf(\"..... id %016\" PRIx64 \", value %016\" PRIx64,\n\t\t\tsample->read.one.id, sample->read.one.value);\n\t\tif (read_format & PERF_FORMAT_LOST)\n\t\t\tprintf(\", lost %\" PRIu64, sample->read.one.lost);\n\t\tprintf(\"\\n\");\n\t}\n}\n\nstatic void dump_event(struct evlist *evlist, union perf_event *event,\n\t\t       u64 file_offset, struct perf_sample *sample,\n\t\t       const char *file_path)\n{\n\tif (!dump_trace)\n\t\treturn;\n\n\tprintf(\"\\n%#\" PRIx64 \"@%s [%#x]: event: %d\\n\",\n\t       file_offset, file_path, event->header.size, event->header.type);\n\n\ttrace_event(event);\n\tif (event->header.type == PERF_RECORD_SAMPLE && evlist->trace_event_sample_raw)\n\t\tevlist->trace_event_sample_raw(evlist, event, sample);\n\n\tif (sample)\n\t\tevlist__print_tstamp(evlist, event, sample);\n\n\tprintf(\"%#\" PRIx64 \" [%#x]: PERF_RECORD_%s\", file_offset,\n\t       event->header.size, perf_event__name(event->header.type));\n}\n\nchar *get_page_size_name(u64 size, char *str)\n{\n\tif (!size || !unit_number__scnprintf(str, PAGE_SIZE_NAME_LEN, size))\n\t\tsnprintf(str, PAGE_SIZE_NAME_LEN, \"%s\", \"N/A\");\n\n\treturn str;\n}\n\nstatic void dump_sample(struct evsel *evsel, union perf_event *event,\n\t\t\tstruct perf_sample *sample, const char *arch)\n{\n\tu64 sample_type;\n\tchar str[PAGE_SIZE_NAME_LEN];\n\n\tif (!dump_trace)\n\t\treturn;\n\n\tprintf(\"(IP, 0x%x): %d/%d: %#\" PRIx64 \" period: %\" PRIu64 \" addr: %#\" PRIx64 \"\\n\",\n\t       event->header.misc, sample->pid, sample->tid, sample->ip,\n\t       sample->period, sample->addr);\n\n\tsample_type = evsel->core.attr.sample_type;\n\n\tif (evsel__has_callchain(evsel))\n\t\tcallchain__printf(evsel, sample);\n\n\tif (evsel__has_br_stack(evsel))\n\t\tbranch_stack__printf(sample, evsel__has_branch_callstack(evsel));\n\n\tif (sample_type & PERF_SAMPLE_REGS_USER)\n\t\tregs_user__printf(sample, arch);\n\n\tif (sample_type & PERF_SAMPLE_REGS_INTR)\n\t\tregs_intr__printf(sample, arch);\n\n\tif (sample_type & PERF_SAMPLE_STACK_USER)\n\t\tstack_user__printf(&sample->user_stack);\n\n\tif (sample_type & PERF_SAMPLE_WEIGHT_TYPE) {\n\t\tprintf(\"... weight: %\" PRIu64 \"\", sample->weight);\n\t\t\tif (sample_type & PERF_SAMPLE_WEIGHT_STRUCT) {\n\t\t\t\tprintf(\",0x%\"PRIx16\"\", sample->ins_lat);\n\t\t\t\tprintf(\",0x%\"PRIx16\"\", sample->p_stage_cyc);\n\t\t\t}\n\t\tprintf(\"\\n\");\n\t}\n\n\tif (sample_type & PERF_SAMPLE_DATA_SRC)\n\t\tprintf(\" . data_src: 0x%\"PRIx64\"\\n\", sample->data_src);\n\n\tif (sample_type & PERF_SAMPLE_PHYS_ADDR)\n\t\tprintf(\" .. phys_addr: 0x%\"PRIx64\"\\n\", sample->phys_addr);\n\n\tif (sample_type & PERF_SAMPLE_DATA_PAGE_SIZE)\n\t\tprintf(\" .. data page size: %s\\n\", get_page_size_name(sample->data_page_size, str));\n\n\tif (sample_type & PERF_SAMPLE_CODE_PAGE_SIZE)\n\t\tprintf(\" .. code page size: %s\\n\", get_page_size_name(sample->code_page_size, str));\n\n\tif (sample_type & PERF_SAMPLE_TRANSACTION)\n\t\tprintf(\"... transaction: %\" PRIx64 \"\\n\", sample->transaction);\n\n\tif (sample_type & PERF_SAMPLE_READ)\n\t\tsample_read__printf(sample, evsel->core.attr.read_format);\n}\n\nstatic void dump_read(struct evsel *evsel, union perf_event *event)\n{\n\tstruct perf_record_read *read_event = &event->read;\n\tu64 read_format;\n\n\tif (!dump_trace)\n\t\treturn;\n\n\tprintf(\": %d %d %s %\" PRI_lu64 \"\\n\", event->read.pid, event->read.tid,\n\t       evsel__name(evsel), event->read.value);\n\n\tif (!evsel)\n\t\treturn;\n\n\tread_format = evsel->core.attr.read_format;\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED)\n\t\tprintf(\"... time enabled : %\" PRI_lu64 \"\\n\", read_event->time_enabled);\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING)\n\t\tprintf(\"... time running : %\" PRI_lu64 \"\\n\", read_event->time_running);\n\n\tif (read_format & PERF_FORMAT_ID)\n\t\tprintf(\"... id           : %\" PRI_lu64 \"\\n\", read_event->id);\n\n\tif (read_format & PERF_FORMAT_LOST)\n\t\tprintf(\"... lost         : %\" PRI_lu64 \"\\n\", read_event->lost);\n}\n\nstatic struct machine *machines__find_for_cpumode(struct machines *machines,\n\t\t\t\t\t       union perf_event *event,\n\t\t\t\t\t       struct perf_sample *sample)\n{\n\tif (perf_guest &&\n\t    ((sample->cpumode == PERF_RECORD_MISC_GUEST_KERNEL) ||\n\t     (sample->cpumode == PERF_RECORD_MISC_GUEST_USER))) {\n\t\tu32 pid;\n\n\t\tif (sample->machine_pid)\n\t\t\tpid = sample->machine_pid;\n\t\telse if (event->header.type == PERF_RECORD_MMAP\n\t\t    || event->header.type == PERF_RECORD_MMAP2)\n\t\t\tpid = event->mmap.pid;\n\t\telse\n\t\t\tpid = sample->pid;\n\n\t\t \n\t\tif (symbol_conf.guest_code)\n\t\t\treturn machines__findnew(machines, pid);\n\n\t\treturn machines__find_guest(machines, pid);\n\t}\n\n\treturn &machines->host;\n}\n\nstatic int deliver_sample_value(struct evlist *evlist,\n\t\t\t\tstruct perf_tool *tool,\n\t\t\t\tunion perf_event *event,\n\t\t\t\tstruct perf_sample *sample,\n\t\t\t\tstruct sample_read_value *v,\n\t\t\t\tstruct machine *machine)\n{\n\tstruct perf_sample_id *sid = evlist__id2sid(evlist, v->id);\n\tstruct evsel *evsel;\n\n\tif (sid) {\n\t\tsample->id     = v->id;\n\t\tsample->period = v->value - sid->period;\n\t\tsid->period    = v->value;\n\t}\n\n\tif (!sid || sid->evsel == NULL) {\n\t\t++evlist->stats.nr_unknown_id;\n\t\treturn 0;\n\t}\n\n\t \n\tif (!sample->period)\n\t\treturn 0;\n\n\tevsel = container_of(sid->evsel, struct evsel, core);\n\treturn tool->sample(tool, event, sample, evsel, machine);\n}\n\nstatic int deliver_sample_group(struct evlist *evlist,\n\t\t\t\tstruct perf_tool *tool,\n\t\t\t\tunion  perf_event *event,\n\t\t\t\tstruct perf_sample *sample,\n\t\t\t\tstruct machine *machine,\n\t\t\t\tu64 read_format)\n{\n\tint ret = -EINVAL;\n\tstruct sample_read_value *v = sample->read.group.values;\n\n\tsample_read_group__for_each(v, sample->read.group.nr, read_format) {\n\t\tret = deliver_sample_value(evlist, tool, event, sample, v,\n\t\t\t\t\t   machine);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int evlist__deliver_sample(struct evlist *evlist, struct perf_tool *tool,\n\t\t\t\t  union  perf_event *event, struct perf_sample *sample,\n\t\t\t\t  struct evsel *evsel, struct machine *machine)\n{\n\t \n\tu64 sample_type = evsel->core.attr.sample_type;\n\tu64 read_format = evsel->core.attr.read_format;\n\n\t \n\tif (!(sample_type & PERF_SAMPLE_READ))\n\t\treturn tool->sample(tool, event, sample, evsel, machine);\n\n\t \n\tif (read_format & PERF_FORMAT_GROUP)\n\t\treturn deliver_sample_group(evlist, tool, event, sample,\n\t\t\t\t\t    machine, read_format);\n\telse\n\t\treturn deliver_sample_value(evlist, tool, event, sample,\n\t\t\t\t\t    &sample->read.one, machine);\n}\n\nstatic int machines__deliver_event(struct machines *machines,\n\t\t\t\t   struct evlist *evlist,\n\t\t\t\t   union perf_event *event,\n\t\t\t\t   struct perf_sample *sample,\n\t\t\t\t   struct perf_tool *tool, u64 file_offset,\n\t\t\t\t   const char *file_path)\n{\n\tstruct evsel *evsel;\n\tstruct machine *machine;\n\n\tdump_event(evlist, event, file_offset, sample, file_path);\n\n\tevsel = evlist__id2evsel(evlist, sample->id);\n\n\tmachine = machines__find_for_cpumode(machines, event, sample);\n\n\tswitch (event->header.type) {\n\tcase PERF_RECORD_SAMPLE:\n\t\tif (evsel == NULL) {\n\t\t\t++evlist->stats.nr_unknown_id;\n\t\t\treturn 0;\n\t\t}\n\t\tif (machine == NULL) {\n\t\t\t++evlist->stats.nr_unprocessable_samples;\n\t\t\tdump_sample(evsel, event, sample, perf_env__arch(NULL));\n\t\t\treturn 0;\n\t\t}\n\t\tdump_sample(evsel, event, sample, perf_env__arch(machine->env));\n\t\treturn evlist__deliver_sample(evlist, tool, event, sample, evsel, machine);\n\tcase PERF_RECORD_MMAP:\n\t\treturn tool->mmap(tool, event, sample, machine);\n\tcase PERF_RECORD_MMAP2:\n\t\tif (event->header.misc & PERF_RECORD_MISC_PROC_MAP_PARSE_TIMEOUT)\n\t\t\t++evlist->stats.nr_proc_map_timeout;\n\t\treturn tool->mmap2(tool, event, sample, machine);\n\tcase PERF_RECORD_COMM:\n\t\treturn tool->comm(tool, event, sample, machine);\n\tcase PERF_RECORD_NAMESPACES:\n\t\treturn tool->namespaces(tool, event, sample, machine);\n\tcase PERF_RECORD_CGROUP:\n\t\treturn tool->cgroup(tool, event, sample, machine);\n\tcase PERF_RECORD_FORK:\n\t\treturn tool->fork(tool, event, sample, machine);\n\tcase PERF_RECORD_EXIT:\n\t\treturn tool->exit(tool, event, sample, machine);\n\tcase PERF_RECORD_LOST:\n\t\tif (tool->lost == perf_event__process_lost)\n\t\t\tevlist->stats.total_lost += event->lost.lost;\n\t\treturn tool->lost(tool, event, sample, machine);\n\tcase PERF_RECORD_LOST_SAMPLES:\n\t\tif (tool->lost_samples == perf_event__process_lost_samples &&\n\t\t    !(event->header.misc & PERF_RECORD_MISC_LOST_SAMPLES_BPF))\n\t\t\tevlist->stats.total_lost_samples += event->lost_samples.lost;\n\t\treturn tool->lost_samples(tool, event, sample, machine);\n\tcase PERF_RECORD_READ:\n\t\tdump_read(evsel, event);\n\t\treturn tool->read(tool, event, sample, evsel, machine);\n\tcase PERF_RECORD_THROTTLE:\n\t\treturn tool->throttle(tool, event, sample, machine);\n\tcase PERF_RECORD_UNTHROTTLE:\n\t\treturn tool->unthrottle(tool, event, sample, machine);\n\tcase PERF_RECORD_AUX:\n\t\tif (tool->aux == perf_event__process_aux) {\n\t\t\tif (event->aux.flags & PERF_AUX_FLAG_TRUNCATED)\n\t\t\t\tevlist->stats.total_aux_lost += 1;\n\t\t\tif (event->aux.flags & PERF_AUX_FLAG_PARTIAL)\n\t\t\t\tevlist->stats.total_aux_partial += 1;\n\t\t\tif (event->aux.flags & PERF_AUX_FLAG_COLLISION)\n\t\t\t\tevlist->stats.total_aux_collision += 1;\n\t\t}\n\t\treturn tool->aux(tool, event, sample, machine);\n\tcase PERF_RECORD_ITRACE_START:\n\t\treturn tool->itrace_start(tool, event, sample, machine);\n\tcase PERF_RECORD_SWITCH:\n\tcase PERF_RECORD_SWITCH_CPU_WIDE:\n\t\treturn tool->context_switch(tool, event, sample, machine);\n\tcase PERF_RECORD_KSYMBOL:\n\t\treturn tool->ksymbol(tool, event, sample, machine);\n\tcase PERF_RECORD_BPF_EVENT:\n\t\treturn tool->bpf(tool, event, sample, machine);\n\tcase PERF_RECORD_TEXT_POKE:\n\t\treturn tool->text_poke(tool, event, sample, machine);\n\tcase PERF_RECORD_AUX_OUTPUT_HW_ID:\n\t\treturn tool->aux_output_hw_id(tool, event, sample, machine);\n\tdefault:\n\t\t++evlist->stats.nr_unknown_events;\n\t\treturn -1;\n\t}\n}\n\nstatic int perf_session__deliver_event(struct perf_session *session,\n\t\t\t\t       union perf_event *event,\n\t\t\t\t       struct perf_tool *tool,\n\t\t\t\t       u64 file_offset,\n\t\t\t\t       const char *file_path)\n{\n\tstruct perf_sample sample;\n\tint ret = evlist__parse_sample(session->evlist, event, &sample);\n\n\tif (ret) {\n\t\tpr_err(\"Can't parse sample, err = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = auxtrace__process_event(session, event, &sample, tool);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret > 0)\n\t\treturn 0;\n\n\tret = machines__deliver_event(&session->machines, session->evlist,\n\t\t\t\t      event, &sample, tool, file_offset, file_path);\n\n\tif (dump_trace && sample.aux_sample.size)\n\t\tauxtrace__dump_auxtrace_sample(session, &sample);\n\n\treturn ret;\n}\n\nstatic s64 perf_session__process_user_event(struct perf_session *session,\n\t\t\t\t\t    union perf_event *event,\n\t\t\t\t\t    u64 file_offset,\n\t\t\t\t\t    const char *file_path)\n{\n\tstruct ordered_events *oe = &session->ordered_events;\n\tstruct perf_tool *tool = session->tool;\n\tstruct perf_sample sample = { .time = 0, };\n\tint fd = perf_data__fd(session->data);\n\tint err;\n\n\tif (event->header.type != PERF_RECORD_COMPRESSED ||\n\t    tool->compressed == perf_session__process_compressed_event_stub)\n\t\tdump_event(session->evlist, event, file_offset, &sample, file_path);\n\n\t \n\tswitch (event->header.type) {\n\tcase PERF_RECORD_HEADER_ATTR:\n\t\terr = tool->attr(tool, event, &session->evlist);\n\t\tif (err == 0) {\n\t\t\tperf_session__set_id_hdr_size(session);\n\t\t\tperf_session__set_comm_exec(session);\n\t\t}\n\t\treturn err;\n\tcase PERF_RECORD_EVENT_UPDATE:\n\t\treturn tool->event_update(tool, event, &session->evlist);\n\tcase PERF_RECORD_HEADER_EVENT_TYPE:\n\t\t \n\t\treturn 0;\n\tcase PERF_RECORD_HEADER_TRACING_DATA:\n\t\t \n\t\tif (!perf_data__is_pipe(session->data))\n\t\t\tlseek(fd, file_offset, SEEK_SET);\n\t\treturn tool->tracing_data(session, event);\n\tcase PERF_RECORD_HEADER_BUILD_ID:\n\t\treturn tool->build_id(session, event);\n\tcase PERF_RECORD_FINISHED_ROUND:\n\t\treturn tool->finished_round(tool, event, oe);\n\tcase PERF_RECORD_ID_INDEX:\n\t\treturn tool->id_index(session, event);\n\tcase PERF_RECORD_AUXTRACE_INFO:\n\t\treturn tool->auxtrace_info(session, event);\n\tcase PERF_RECORD_AUXTRACE:\n\t\t \n\t\tif (!perf_data__is_pipe(session->data))\n\t\t\tlseek(fd, file_offset + event->header.size, SEEK_SET);\n\t\treturn tool->auxtrace(session, event);\n\tcase PERF_RECORD_AUXTRACE_ERROR:\n\t\tperf_session__auxtrace_error_inc(session, event);\n\t\treturn tool->auxtrace_error(session, event);\n\tcase PERF_RECORD_THREAD_MAP:\n\t\treturn tool->thread_map(session, event);\n\tcase PERF_RECORD_CPU_MAP:\n\t\treturn tool->cpu_map(session, event);\n\tcase PERF_RECORD_STAT_CONFIG:\n\t\treturn tool->stat_config(session, event);\n\tcase PERF_RECORD_STAT:\n\t\treturn tool->stat(session, event);\n\tcase PERF_RECORD_STAT_ROUND:\n\t\treturn tool->stat_round(session, event);\n\tcase PERF_RECORD_TIME_CONV:\n\t\tsession->time_conv = event->time_conv;\n\t\treturn tool->time_conv(session, event);\n\tcase PERF_RECORD_HEADER_FEATURE:\n\t\treturn tool->feature(session, event);\n\tcase PERF_RECORD_COMPRESSED:\n\t\terr = tool->compressed(session, event, file_offset, file_path);\n\t\tif (err)\n\t\t\tdump_event(session->evlist, event, file_offset, &sample, file_path);\n\t\treturn err;\n\tcase PERF_RECORD_FINISHED_INIT:\n\t\treturn tool->finished_init(session, event);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nint perf_session__deliver_synth_event(struct perf_session *session,\n\t\t\t\t      union perf_event *event,\n\t\t\t\t      struct perf_sample *sample)\n{\n\tstruct evlist *evlist = session->evlist;\n\tstruct perf_tool *tool = session->tool;\n\n\tevents_stats__inc(&evlist->stats, event->header.type);\n\n\tif (event->header.type >= PERF_RECORD_USER_TYPE_START)\n\t\treturn perf_session__process_user_event(session, event, 0, NULL);\n\n\treturn machines__deliver_event(&session->machines, evlist, event, sample, tool, 0, NULL);\n}\n\nstatic void event_swap(union perf_event *event, bool sample_id_all)\n{\n\tperf_event__swap_op swap;\n\n\tswap = perf_event__swap_ops[event->header.type];\n\tif (swap)\n\t\tswap(event, sample_id_all);\n}\n\nint perf_session__peek_event(struct perf_session *session, off_t file_offset,\n\t\t\t     void *buf, size_t buf_sz,\n\t\t\t     union perf_event **event_ptr,\n\t\t\t     struct perf_sample *sample)\n{\n\tunion perf_event *event;\n\tsize_t hdr_sz, rest;\n\tint fd;\n\n\tif (session->one_mmap && !session->header.needs_swap) {\n\t\tevent = file_offset - session->one_mmap_offset +\n\t\t\tsession->one_mmap_addr;\n\t\tgoto out_parse_sample;\n\t}\n\n\tif (perf_data__is_pipe(session->data))\n\t\treturn -1;\n\n\tfd = perf_data__fd(session->data);\n\thdr_sz = sizeof(struct perf_event_header);\n\n\tif (buf_sz < hdr_sz)\n\t\treturn -1;\n\n\tif (lseek(fd, file_offset, SEEK_SET) == (off_t)-1 ||\n\t    readn(fd, buf, hdr_sz) != (ssize_t)hdr_sz)\n\t\treturn -1;\n\n\tevent = (union perf_event *)buf;\n\n\tif (session->header.needs_swap)\n\t\tperf_event_header__bswap(&event->header);\n\n\tif (event->header.size < hdr_sz || event->header.size > buf_sz)\n\t\treturn -1;\n\n\tbuf += hdr_sz;\n\trest = event->header.size - hdr_sz;\n\n\tif (readn(fd, buf, rest) != (ssize_t)rest)\n\t\treturn -1;\n\n\tif (session->header.needs_swap)\n\t\tevent_swap(event, evlist__sample_id_all(session->evlist));\n\nout_parse_sample:\n\n\tif (sample && event->header.type < PERF_RECORD_USER_TYPE_START &&\n\t    evlist__parse_sample(session->evlist, event, sample))\n\t\treturn -1;\n\n\t*event_ptr = event;\n\n\treturn 0;\n}\n\nint perf_session__peek_events(struct perf_session *session, u64 offset,\n\t\t\t      u64 size, peek_events_cb_t cb, void *data)\n{\n\tu64 max_offset = offset + size;\n\tchar buf[PERF_SAMPLE_MAX_SIZE];\n\tunion perf_event *event;\n\tint err;\n\n\tdo {\n\t\terr = perf_session__peek_event(session, offset, buf,\n\t\t\t\t\t       PERF_SAMPLE_MAX_SIZE, &event,\n\t\t\t\t\t       NULL);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = cb(session, event, offset, data);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\toffset += event->header.size;\n\t\tif (event->header.type == PERF_RECORD_AUXTRACE)\n\t\t\toffset += event->auxtrace.size;\n\n\t} while (offset < max_offset);\n\n\treturn err;\n}\n\nstatic s64 perf_session__process_event(struct perf_session *session,\n\t\t\t\t       union perf_event *event, u64 file_offset,\n\t\t\t\t       const char *file_path)\n{\n\tstruct evlist *evlist = session->evlist;\n\tstruct perf_tool *tool = session->tool;\n\tint ret;\n\n\tif (session->header.needs_swap)\n\t\tevent_swap(event, evlist__sample_id_all(evlist));\n\n\tif (event->header.type >= PERF_RECORD_HEADER_MAX)\n\t\treturn -EINVAL;\n\n\tevents_stats__inc(&evlist->stats, event->header.type);\n\n\tif (event->header.type >= PERF_RECORD_USER_TYPE_START)\n\t\treturn perf_session__process_user_event(session, event, file_offset, file_path);\n\n\tif (tool->ordered_events) {\n\t\tu64 timestamp = -1ULL;\n\n\t\tret = evlist__parse_sample_timestamp(evlist, event, &timestamp);\n\t\tif (ret && ret != -1)\n\t\t\treturn ret;\n\n\t\tret = perf_session__queue_event(session, event, timestamp, file_offset, file_path);\n\t\tif (ret != -ETIME)\n\t\t\treturn ret;\n\t}\n\n\treturn perf_session__deliver_event(session, event, tool, file_offset, file_path);\n}\n\nvoid perf_event_header__bswap(struct perf_event_header *hdr)\n{\n\thdr->type = bswap_32(hdr->type);\n\thdr->misc = bswap_16(hdr->misc);\n\thdr->size = bswap_16(hdr->size);\n}\n\nstruct thread *perf_session__findnew(struct perf_session *session, pid_t pid)\n{\n\treturn machine__findnew_thread(&session->machines.host, -1, pid);\n}\n\nint perf_session__register_idle_thread(struct perf_session *session)\n{\n\tstruct thread *thread = machine__idle_thread(&session->machines.host);\n\n\t \n\tthread__put(thread);\n\treturn thread ? 0 : -1;\n}\n\nstatic void\nperf_session__warn_order(const struct perf_session *session)\n{\n\tconst struct ordered_events *oe = &session->ordered_events;\n\tstruct evsel *evsel;\n\tbool should_warn = true;\n\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tif (evsel->core.attr.write_backward)\n\t\t\tshould_warn = false;\n\t}\n\n\tif (!should_warn)\n\t\treturn;\n\tif (oe->nr_unordered_events != 0)\n\t\tui__warning(\"%u out of order events recorded.\\n\", oe->nr_unordered_events);\n}\n\nstatic void perf_session__warn_about_errors(const struct perf_session *session)\n{\n\tconst struct events_stats *stats = &session->evlist->stats;\n\n\tif (session->tool->lost == perf_event__process_lost &&\n\t    stats->nr_events[PERF_RECORD_LOST] != 0) {\n\t\tui__warning(\"Processed %d events and lost %d chunks!\\n\\n\"\n\t\t\t    \"Check IO/CPU overload!\\n\\n\",\n\t\t\t    stats->nr_events[0],\n\t\t\t    stats->nr_events[PERF_RECORD_LOST]);\n\t}\n\n\tif (session->tool->lost_samples == perf_event__process_lost_samples) {\n\t\tdouble drop_rate;\n\n\t\tdrop_rate = (double)stats->total_lost_samples /\n\t\t\t    (double) (stats->nr_events[PERF_RECORD_SAMPLE] + stats->total_lost_samples);\n\t\tif (drop_rate > 0.05) {\n\t\t\tui__warning(\"Processed %\" PRIu64 \" samples and lost %3.2f%%!\\n\\n\",\n\t\t\t\t    stats->nr_events[PERF_RECORD_SAMPLE] + stats->total_lost_samples,\n\t\t\t\t    drop_rate * 100.0);\n\t\t}\n\t}\n\n\tif (session->tool->aux == perf_event__process_aux &&\n\t    stats->total_aux_lost != 0) {\n\t\tui__warning(\"AUX data lost %\" PRIu64 \" times out of %u!\\n\\n\",\n\t\t\t    stats->total_aux_lost,\n\t\t\t    stats->nr_events[PERF_RECORD_AUX]);\n\t}\n\n\tif (session->tool->aux == perf_event__process_aux &&\n\t    stats->total_aux_partial != 0) {\n\t\tbool vmm_exclusive = false;\n\n\t\t(void)sysfs__read_bool(\"module/kvm_intel/parameters/vmm_exclusive\",\n\t\t                       &vmm_exclusive);\n\n\t\tui__warning(\"AUX data had gaps in it %\" PRIu64 \" times out of %u!\\n\\n\"\n\t\t            \"Are you running a KVM guest in the background?%s\\n\\n\",\n\t\t\t    stats->total_aux_partial,\n\t\t\t    stats->nr_events[PERF_RECORD_AUX],\n\t\t\t    vmm_exclusive ?\n\t\t\t    \"\\nReloading kvm_intel module with vmm_exclusive=0\\n\"\n\t\t\t    \"will reduce the gaps to only guest's timeslices.\" :\n\t\t\t    \"\");\n\t}\n\n\tif (session->tool->aux == perf_event__process_aux &&\n\t    stats->total_aux_collision != 0) {\n\t\tui__warning(\"AUX data detected collision  %\" PRIu64 \" times out of %u!\\n\\n\",\n\t\t\t    stats->total_aux_collision,\n\t\t\t    stats->nr_events[PERF_RECORD_AUX]);\n\t}\n\n\tif (stats->nr_unknown_events != 0) {\n\t\tui__warning(\"Found %u unknown events!\\n\\n\"\n\t\t\t    \"Is this an older tool processing a perf.data \"\n\t\t\t    \"file generated by a more recent tool?\\n\\n\"\n\t\t\t    \"If that is not the case, consider \"\n\t\t\t    \"reporting to linux-kernel@vger.kernel.org.\\n\\n\",\n\t\t\t    stats->nr_unknown_events);\n\t}\n\n\tif (stats->nr_unknown_id != 0) {\n\t\tui__warning(\"%u samples with id not present in the header\\n\",\n\t\t\t    stats->nr_unknown_id);\n\t}\n\n\tif (stats->nr_invalid_chains != 0) {\n\t\tui__warning(\"Found invalid callchains!\\n\\n\"\n\t\t\t    \"%u out of %u events were discarded for this reason.\\n\\n\"\n\t\t\t    \"Consider reporting to linux-kernel@vger.kernel.org.\\n\\n\",\n\t\t\t    stats->nr_invalid_chains,\n\t\t\t    stats->nr_events[PERF_RECORD_SAMPLE]);\n\t}\n\n\tif (stats->nr_unprocessable_samples != 0) {\n\t\tui__warning(\"%u unprocessable samples recorded.\\n\"\n\t\t\t    \"Do you have a KVM guest running and not using 'perf kvm'?\\n\",\n\t\t\t    stats->nr_unprocessable_samples);\n\t}\n\n\tperf_session__warn_order(session);\n\n\tevents_stats__auxtrace_error_warn(stats);\n\n\tif (stats->nr_proc_map_timeout != 0) {\n\t\tui__warning(\"%d map information files for pre-existing threads were\\n\"\n\t\t\t    \"not processed, if there are samples for addresses they\\n\"\n\t\t\t    \"will not be resolved, you may find out which are these\\n\"\n\t\t\t    \"threads by running with -v and redirecting the output\\n\"\n\t\t\t    \"to a file.\\n\"\n\t\t\t    \"The time limit to process proc map is too short?\\n\"\n\t\t\t    \"Increase it by --proc-map-timeout\\n\",\n\t\t\t    stats->nr_proc_map_timeout);\n\t}\n}\n\nstatic int perf_session__flush_thread_stack(struct thread *thread,\n\t\t\t\t\t    void *p __maybe_unused)\n{\n\treturn thread_stack__flush(thread);\n}\n\nstatic int perf_session__flush_thread_stacks(struct perf_session *session)\n{\n\treturn machines__for_each_thread(&session->machines,\n\t\t\t\t\t perf_session__flush_thread_stack,\n\t\t\t\t\t NULL);\n}\n\nvolatile sig_atomic_t session_done;\n\nstatic int __perf_session__process_decomp_events(struct perf_session *session);\n\nstatic int __perf_session__process_pipe_events(struct perf_session *session)\n{\n\tstruct ordered_events *oe = &session->ordered_events;\n\tstruct perf_tool *tool = session->tool;\n\tunion perf_event *event;\n\tuint32_t size, cur_size = 0;\n\tvoid *buf = NULL;\n\ts64 skip = 0;\n\tu64 head;\n\tssize_t err;\n\tvoid *p;\n\n\tperf_tool__fill_defaults(tool);\n\n\thead = 0;\n\tcur_size = sizeof(union perf_event);\n\n\tbuf = malloc(cur_size);\n\tif (!buf)\n\t\treturn -errno;\n\tordered_events__set_copy_on_queue(oe, true);\nmore:\n\tevent = buf;\n\terr = perf_data__read(session->data, event,\n\t\t\t      sizeof(struct perf_event_header));\n\tif (err <= 0) {\n\t\tif (err == 0)\n\t\t\tgoto done;\n\n\t\tpr_err(\"failed to read event header\\n\");\n\t\tgoto out_err;\n\t}\n\n\tif (session->header.needs_swap)\n\t\tperf_event_header__bswap(&event->header);\n\n\tsize = event->header.size;\n\tif (size < sizeof(struct perf_event_header)) {\n\t\tpr_err(\"bad event header size\\n\");\n\t\tgoto out_err;\n\t}\n\n\tif (size > cur_size) {\n\t\tvoid *new = realloc(buf, size);\n\t\tif (!new) {\n\t\t\tpr_err(\"failed to allocate memory to read event\\n\");\n\t\t\tgoto out_err;\n\t\t}\n\t\tbuf = new;\n\t\tcur_size = size;\n\t\tevent = buf;\n\t}\n\tp = event;\n\tp += sizeof(struct perf_event_header);\n\n\tif (size - sizeof(struct perf_event_header)) {\n\t\terr = perf_data__read(session->data, p,\n\t\t\t\t      size - sizeof(struct perf_event_header));\n\t\tif (err <= 0) {\n\t\t\tif (err == 0) {\n\t\t\t\tpr_err(\"unexpected end of event stream\\n\");\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\tpr_err(\"failed to read event data\\n\");\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\n\tif ((skip = perf_session__process_event(session, event, head, \"pipe\")) < 0) {\n\t\tpr_err(\"%#\" PRIx64 \" [%#x]: failed to process type: %d\\n\",\n\t\t       head, event->header.size, event->header.type);\n\t\terr = -EINVAL;\n\t\tgoto out_err;\n\t}\n\n\thead += size;\n\n\tif (skip > 0)\n\t\thead += skip;\n\n\terr = __perf_session__process_decomp_events(session);\n\tif (err)\n\t\tgoto out_err;\n\n\tif (!session_done())\n\t\tgoto more;\ndone:\n\t \n\terr = ordered_events__flush(oe, OE_FLUSH__FINAL);\n\tif (err)\n\t\tgoto out_err;\n\terr = auxtrace__flush_events(session, tool);\n\tif (err)\n\t\tgoto out_err;\n\terr = perf_session__flush_thread_stacks(session);\nout_err:\n\tfree(buf);\n\tif (!tool->no_warn)\n\t\tperf_session__warn_about_errors(session);\n\tordered_events__free(&session->ordered_events);\n\tauxtrace__free_events(session);\n\treturn err;\n}\n\nstatic union perf_event *\nprefetch_event(char *buf, u64 head, size_t mmap_size,\n\t       bool needs_swap, union perf_event *error)\n{\n\tunion perf_event *event;\n\tu16 event_size;\n\n\t \n\tif (head + sizeof(event->header) > mmap_size)\n\t\treturn NULL;\n\n\tevent = (union perf_event *)(buf + head);\n\tif (needs_swap)\n\t\tperf_event_header__bswap(&event->header);\n\n\tevent_size = event->header.size;\n\tif (head + event_size <= mmap_size)\n\t\treturn event;\n\n\t \n\tif (needs_swap)\n\t\tperf_event_header__bswap(&event->header);\n\n\t \n\tif (event_size <= mmap_size - head % page_size) {\n\t\t \n\t\treturn NULL;\n\t}\n\n\t \n\tpr_debug(\"%s: head=%#\" PRIx64 \" event->header.size=%#x, mmap_size=%#zx:\"\n\t\t \" fuzzed or compressed perf.data?\\n\", __func__, head, event_size, mmap_size);\n\n\treturn error;\n}\n\nstatic union perf_event *\nfetch_mmaped_event(u64 head, size_t mmap_size, char *buf, bool needs_swap)\n{\n\treturn prefetch_event(buf, head, mmap_size, needs_swap, ERR_PTR(-EINVAL));\n}\n\nstatic union perf_event *\nfetch_decomp_event(u64 head, size_t mmap_size, char *buf, bool needs_swap)\n{\n\treturn prefetch_event(buf, head, mmap_size, needs_swap, NULL);\n}\n\nstatic int __perf_session__process_decomp_events(struct perf_session *session)\n{\n\ts64 skip;\n\tu64 size;\n\tstruct decomp *decomp = session->active_decomp->decomp_last;\n\n\tif (!decomp)\n\t\treturn 0;\n\n\twhile (decomp->head < decomp->size && !session_done()) {\n\t\tunion perf_event *event = fetch_decomp_event(decomp->head, decomp->size, decomp->data,\n\t\t\t\t\t\t\t     session->header.needs_swap);\n\n\t\tif (!event)\n\t\t\tbreak;\n\n\t\tsize = event->header.size;\n\n\t\tif (size < sizeof(struct perf_event_header) ||\n\t\t    (skip = perf_session__process_event(session, event, decomp->file_pos,\n\t\t\t\t\t\t\tdecomp->file_path)) < 0) {\n\t\t\tpr_err(\"%#\" PRIx64 \" [%#x]: failed to process type: %d\\n\",\n\t\t\t\tdecomp->file_pos + decomp->head, event->header.size, event->header.type);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (skip)\n\t\t\tsize += skip;\n\n\t\tdecomp->head += size;\n\t}\n\n\treturn 0;\n}\n\n \n#if BITS_PER_LONG == 64\n#define MMAP_SIZE ULLONG_MAX\n#define NUM_MMAPS 1\n#else\n#define MMAP_SIZE (32 * 1024 * 1024ULL)\n#define NUM_MMAPS 128\n#endif\n\nstruct reader;\n\ntypedef s64 (*reader_cb_t)(struct perf_session *session,\n\t\t\t   union perf_event *event,\n\t\t\t   u64 file_offset,\n\t\t\t   const char *file_path);\n\nstruct reader {\n\tint\t\t fd;\n\tconst char\t *path;\n\tu64\t\t data_size;\n\tu64\t\t data_offset;\n\treader_cb_t\t process;\n\tbool\t\t in_place_update;\n\tchar\t\t *mmaps[NUM_MMAPS];\n\tsize_t\t\t mmap_size;\n\tint\t\t mmap_idx;\n\tchar\t\t *mmap_cur;\n\tu64\t\t file_pos;\n\tu64\t\t file_offset;\n\tu64\t\t head;\n\tu64\t\t size;\n\tbool\t\t done;\n\tstruct zstd_data   zstd_data;\n\tstruct decomp_data decomp_data;\n};\n\nstatic int\nreader__init(struct reader *rd, bool *one_mmap)\n{\n\tu64 data_size = rd->data_size;\n\tchar **mmaps = rd->mmaps;\n\n\trd->head = rd->data_offset;\n\tdata_size += rd->data_offset;\n\n\trd->mmap_size = MMAP_SIZE;\n\tif (rd->mmap_size > data_size) {\n\t\trd->mmap_size = data_size;\n\t\tif (one_mmap)\n\t\t\t*one_mmap = true;\n\t}\n\n\tmemset(mmaps, 0, sizeof(rd->mmaps));\n\n\tif (zstd_init(&rd->zstd_data, 0))\n\t\treturn -1;\n\trd->decomp_data.zstd_decomp = &rd->zstd_data;\n\n\treturn 0;\n}\n\nstatic void\nreader__release_decomp(struct reader *rd)\n{\n\tperf_decomp__release_events(rd->decomp_data.decomp);\n\tzstd_fini(&rd->zstd_data);\n}\n\nstatic int\nreader__mmap(struct reader *rd, struct perf_session *session)\n{\n\tint mmap_prot, mmap_flags;\n\tchar *buf, **mmaps = rd->mmaps;\n\tu64 page_offset;\n\n\tmmap_prot  = PROT_READ;\n\tmmap_flags = MAP_SHARED;\n\n\tif (rd->in_place_update) {\n\t\tmmap_prot  |= PROT_WRITE;\n\t} else if (session->header.needs_swap) {\n\t\tmmap_prot  |= PROT_WRITE;\n\t\tmmap_flags = MAP_PRIVATE;\n\t}\n\n\tif (mmaps[rd->mmap_idx]) {\n\t\tmunmap(mmaps[rd->mmap_idx], rd->mmap_size);\n\t\tmmaps[rd->mmap_idx] = NULL;\n\t}\n\n\tpage_offset = page_size * (rd->head / page_size);\n\trd->file_offset += page_offset;\n\trd->head -= page_offset;\n\n\tbuf = mmap(NULL, rd->mmap_size, mmap_prot, mmap_flags, rd->fd,\n\t\t   rd->file_offset);\n\tif (buf == MAP_FAILED) {\n\t\tpr_err(\"failed to mmap file\\n\");\n\t\treturn -errno;\n\t}\n\tmmaps[rd->mmap_idx] = rd->mmap_cur = buf;\n\trd->mmap_idx = (rd->mmap_idx + 1) & (ARRAY_SIZE(rd->mmaps) - 1);\n\trd->file_pos = rd->file_offset + rd->head;\n\tif (session->one_mmap) {\n\t\tsession->one_mmap_addr = buf;\n\t\tsession->one_mmap_offset = rd->file_offset;\n\t}\n\n\treturn 0;\n}\n\nenum {\n\tREADER_OK,\n\tREADER_NODATA,\n};\n\nstatic int\nreader__read_event(struct reader *rd, struct perf_session *session,\n\t\t   struct ui_progress *prog)\n{\n\tu64 size;\n\tint err = READER_OK;\n\tunion perf_event *event;\n\ts64 skip;\n\n\tevent = fetch_mmaped_event(rd->head, rd->mmap_size, rd->mmap_cur,\n\t\t\t\t   session->header.needs_swap);\n\tif (IS_ERR(event))\n\t\treturn PTR_ERR(event);\n\n\tif (!event)\n\t\treturn READER_NODATA;\n\n\tsize = event->header.size;\n\n\tskip = -EINVAL;\n\n\tif (size < sizeof(struct perf_event_header) ||\n\t    (skip = rd->process(session, event, rd->file_pos, rd->path)) < 0) {\n\t\tpr_err(\"%#\" PRIx64 \" [%#x]: failed to process type: %d [%s]\\n\",\n\t\t       rd->file_offset + rd->head, event->header.size,\n\t\t       event->header.type, strerror(-skip));\n\t\terr = skip;\n\t\tgoto out;\n\t}\n\n\tif (skip)\n\t\tsize += skip;\n\n\trd->size += size;\n\trd->head += size;\n\trd->file_pos += size;\n\n\terr = __perf_session__process_decomp_events(session);\n\tif (err)\n\t\tgoto out;\n\n\tui_progress__update(prog, size);\n\nout:\n\treturn err;\n}\n\nstatic inline bool\nreader__eof(struct reader *rd)\n{\n\treturn (rd->file_pos >= rd->data_size + rd->data_offset);\n}\n\nstatic int\nreader__process_events(struct reader *rd, struct perf_session *session,\n\t\t       struct ui_progress *prog)\n{\n\tint err;\n\n\terr = reader__init(rd, &session->one_mmap);\n\tif (err)\n\t\tgoto out;\n\n\tsession->active_decomp = &rd->decomp_data;\n\nremap:\n\terr = reader__mmap(rd, session);\n\tif (err)\n\t\tgoto out;\n\nmore:\n\terr = reader__read_event(rd, session, prog);\n\tif (err < 0)\n\t\tgoto out;\n\telse if (err == READER_NODATA)\n\t\tgoto remap;\n\n\tif (session_done())\n\t\tgoto out;\n\n\tif (!reader__eof(rd))\n\t\tgoto more;\n\nout:\n\tsession->active_decomp = &session->decomp_data;\n\treturn err;\n}\n\nstatic s64 process_simple(struct perf_session *session,\n\t\t\t  union perf_event *event,\n\t\t\t  u64 file_offset,\n\t\t\t  const char *file_path)\n{\n\treturn perf_session__process_event(session, event, file_offset, file_path);\n}\n\nstatic int __perf_session__process_events(struct perf_session *session)\n{\n\tstruct reader rd = {\n\t\t.fd\t\t= perf_data__fd(session->data),\n\t\t.path\t\t= session->data->file.path,\n\t\t.data_size\t= session->header.data_size,\n\t\t.data_offset\t= session->header.data_offset,\n\t\t.process\t= process_simple,\n\t\t.in_place_update = session->data->in_place_update,\n\t};\n\tstruct ordered_events *oe = &session->ordered_events;\n\tstruct perf_tool *tool = session->tool;\n\tstruct ui_progress prog;\n\tint err;\n\n\tperf_tool__fill_defaults(tool);\n\n\tif (rd.data_size == 0)\n\t\treturn -1;\n\n\tui_progress__init_size(&prog, rd.data_size, \"Processing events...\");\n\n\terr = reader__process_events(&rd, session, &prog);\n\tif (err)\n\t\tgoto out_err;\n\t \n\terr = ordered_events__flush(oe, OE_FLUSH__FINAL);\n\tif (err)\n\t\tgoto out_err;\n\terr = auxtrace__flush_events(session, tool);\n\tif (err)\n\t\tgoto out_err;\n\terr = perf_session__flush_thread_stacks(session);\nout_err:\n\tui_progress__finish();\n\tif (!tool->no_warn)\n\t\tperf_session__warn_about_errors(session);\n\t \n\tordered_events__reinit(&session->ordered_events);\n\tauxtrace__free_events(session);\n\treader__release_decomp(&rd);\n\tsession->one_mmap = false;\n\treturn err;\n}\n\n \n#define READER_MAX_SIZE (2 * 1024 * 1024)\n\n \nstatic int __perf_session__process_dir_events(struct perf_session *session)\n{\n\tstruct perf_data *data = session->data;\n\tstruct perf_tool *tool = session->tool;\n\tint i, ret, readers, nr_readers;\n\tstruct ui_progress prog;\n\tu64 total_size = perf_data__size(session->data);\n\tstruct reader *rd;\n\n\tperf_tool__fill_defaults(tool);\n\n\tui_progress__init_size(&prog, total_size, \"Sorting events...\");\n\n\tnr_readers = 1;\n\tfor (i = 0; i < data->dir.nr; i++) {\n\t\tif (data->dir.files[i].size)\n\t\t\tnr_readers++;\n\t}\n\n\trd = zalloc(nr_readers * sizeof(struct reader));\n\tif (!rd)\n\t\treturn -ENOMEM;\n\n\trd[0] = (struct reader) {\n\t\t.fd\t\t = perf_data__fd(session->data),\n\t\t.path\t\t = session->data->file.path,\n\t\t.data_size\t = session->header.data_size,\n\t\t.data_offset\t = session->header.data_offset,\n\t\t.process\t = process_simple,\n\t\t.in_place_update = session->data->in_place_update,\n\t};\n\tret = reader__init(&rd[0], NULL);\n\tif (ret)\n\t\tgoto out_err;\n\tret = reader__mmap(&rd[0], session);\n\tif (ret)\n\t\tgoto out_err;\n\treaders = 1;\n\n\tfor (i = 0; i < data->dir.nr; i++) {\n\t\tif (!data->dir.files[i].size)\n\t\t\tcontinue;\n\t\trd[readers] = (struct reader) {\n\t\t\t.fd\t\t = data->dir.files[i].fd,\n\t\t\t.path\t\t = data->dir.files[i].path,\n\t\t\t.data_size\t = data->dir.files[i].size,\n\t\t\t.data_offset\t = 0,\n\t\t\t.process\t = process_simple,\n\t\t\t.in_place_update = session->data->in_place_update,\n\t\t};\n\t\tret = reader__init(&rd[readers], NULL);\n\t\tif (ret)\n\t\t\tgoto out_err;\n\t\tret = reader__mmap(&rd[readers], session);\n\t\tif (ret)\n\t\t\tgoto out_err;\n\t\treaders++;\n\t}\n\n\ti = 0;\n\twhile (readers) {\n\t\tif (session_done())\n\t\t\tbreak;\n\n\t\tif (rd[i].done) {\n\t\t\ti = (i + 1) % nr_readers;\n\t\t\tcontinue;\n\t\t}\n\t\tif (reader__eof(&rd[i])) {\n\t\t\trd[i].done = true;\n\t\t\treaders--;\n\t\t\tcontinue;\n\t\t}\n\n\t\tsession->active_decomp = &rd[i].decomp_data;\n\t\tret = reader__read_event(&rd[i], session, &prog);\n\t\tif (ret < 0) {\n\t\t\tgoto out_err;\n\t\t} else if (ret == READER_NODATA) {\n\t\t\tret = reader__mmap(&rd[i], session);\n\t\t\tif (ret)\n\t\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (rd[i].size >= READER_MAX_SIZE) {\n\t\t\trd[i].size = 0;\n\t\t\ti = (i + 1) % nr_readers;\n\t\t}\n\t}\n\n\tret = ordered_events__flush(&session->ordered_events, OE_FLUSH__FINAL);\n\tif (ret)\n\t\tgoto out_err;\n\n\tret = perf_session__flush_thread_stacks(session);\nout_err:\n\tui_progress__finish();\n\n\tif (!tool->no_warn)\n\t\tperf_session__warn_about_errors(session);\n\n\t \n\tordered_events__reinit(&session->ordered_events);\n\n\tsession->one_mmap = false;\n\n\tsession->active_decomp = &session->decomp_data;\n\tfor (i = 0; i < nr_readers; i++)\n\t\treader__release_decomp(&rd[i]);\n\tzfree(&rd);\n\n\treturn ret;\n}\n\nint perf_session__process_events(struct perf_session *session)\n{\n\tif (perf_session__register_idle_thread(session) < 0)\n\t\treturn -ENOMEM;\n\n\tif (perf_data__is_pipe(session->data))\n\t\treturn __perf_session__process_pipe_events(session);\n\n\tif (perf_data__is_dir(session->data) && session->data->dir.nr)\n\t\treturn __perf_session__process_dir_events(session);\n\n\treturn __perf_session__process_events(session);\n}\n\nbool perf_session__has_traces(struct perf_session *session, const char *msg)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tif (evsel->core.attr.type == PERF_TYPE_TRACEPOINT)\n\t\t\treturn true;\n\t}\n\n\tpr_err(\"No trace sample to read. Did you call 'perf %s'?\\n\", msg);\n\treturn false;\n}\n\nint map__set_kallsyms_ref_reloc_sym(struct map *map, const char *symbol_name, u64 addr)\n{\n\tchar *bracket;\n\tstruct ref_reloc_sym *ref;\n\tstruct kmap *kmap;\n\n\tref = zalloc(sizeof(struct ref_reloc_sym));\n\tif (ref == NULL)\n\t\treturn -ENOMEM;\n\n\tref->name = strdup(symbol_name);\n\tif (ref->name == NULL) {\n\t\tfree(ref);\n\t\treturn -ENOMEM;\n\t}\n\n\tbracket = strchr(ref->name, ']');\n\tif (bracket)\n\t\t*bracket = '\\0';\n\n\tref->addr = addr;\n\n\tkmap = map__kmap(map);\n\tif (kmap)\n\t\tkmap->ref_reloc_sym = ref;\n\n\treturn 0;\n}\n\nsize_t perf_session__fprintf_dsos(struct perf_session *session, FILE *fp)\n{\n\treturn machines__fprintf_dsos(&session->machines, fp);\n}\n\nsize_t perf_session__fprintf_dsos_buildid(struct perf_session *session, FILE *fp,\n\t\t\t\t\t  bool (skip)(struct dso *dso, int parm), int parm)\n{\n\treturn machines__fprintf_dsos_buildid(&session->machines, fp, skip, parm);\n}\n\nsize_t perf_session__fprintf_nr_events(struct perf_session *session, FILE *fp,\n\t\t\t\t       bool skip_empty)\n{\n\tsize_t ret;\n\tconst char *msg = \"\";\n\n\tif (perf_header__has_feat(&session->header, HEADER_AUXTRACE))\n\t\tmsg = \" (excludes AUX area (e.g. instruction trace) decoded / synthesized events)\";\n\n\tret = fprintf(fp, \"\\nAggregated stats:%s\\n\", msg);\n\n\tret += events_stats__fprintf(&session->evlist->stats, fp, skip_empty);\n\treturn ret;\n}\n\nsize_t perf_session__fprintf(struct perf_session *session, FILE *fp)\n{\n\t \n\treturn machine__fprintf(&session->machines.host, fp);\n}\n\nstruct evsel *perf_session__find_first_evtype(struct perf_session *session,\n\t\t\t\t\t      unsigned int type)\n{\n\tstruct evsel *pos;\n\n\tevlist__for_each_entry(session->evlist, pos) {\n\t\tif (pos->core.attr.type == type)\n\t\t\treturn pos;\n\t}\n\treturn NULL;\n}\n\nint perf_session__cpu_bitmap(struct perf_session *session,\n\t\t\t     const char *cpu_list, unsigned long *cpu_bitmap)\n{\n\tint i, err = -1;\n\tstruct perf_cpu_map *map;\n\tint nr_cpus = min(session->header.env.nr_cpus_avail, MAX_NR_CPUS);\n\n\tfor (i = 0; i < PERF_TYPE_MAX; ++i) {\n\t\tstruct evsel *evsel;\n\n\t\tevsel = perf_session__find_first_evtype(session, i);\n\t\tif (!evsel)\n\t\t\tcontinue;\n\n\t\tif (!(evsel->core.attr.sample_type & PERF_SAMPLE_CPU)) {\n\t\t\tpr_err(\"File does not contain CPU events. \"\n\t\t\t       \"Remove -C option to proceed.\\n\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tmap = perf_cpu_map__new(cpu_list);\n\tif (map == NULL) {\n\t\tpr_err(\"Invalid cpu_list\\n\");\n\t\treturn -1;\n\t}\n\n\tfor (i = 0; i < perf_cpu_map__nr(map); i++) {\n\t\tstruct perf_cpu cpu = perf_cpu_map__cpu(map, i);\n\n\t\tif (cpu.cpu >= nr_cpus) {\n\t\t\tpr_err(\"Requested CPU %d too large. \"\n\t\t\t       \"Consider raising MAX_NR_CPUS\\n\", cpu.cpu);\n\t\t\tgoto out_delete_map;\n\t\t}\n\n\t\t__set_bit(cpu.cpu, cpu_bitmap);\n\t}\n\n\terr = 0;\n\nout_delete_map:\n\tperf_cpu_map__put(map);\n\treturn err;\n}\n\nvoid perf_session__fprintf_info(struct perf_session *session, FILE *fp,\n\t\t\t\tbool full)\n{\n\tif (session == NULL || fp == NULL)\n\t\treturn;\n\n\tfprintf(fp, \"# ========\\n\");\n\tperf_header__fprintf_info(session, fp, full);\n\tfprintf(fp, \"# ========\\n#\\n\");\n}\n\nstatic int perf_session__register_guest(struct perf_session *session, pid_t machine_pid)\n{\n\tstruct machine *machine = machines__findnew(&session->machines, machine_pid);\n\tstruct thread *thread;\n\n\tif (!machine)\n\t\treturn -ENOMEM;\n\n\tmachine->single_address_space = session->machines.host.single_address_space;\n\n\tthread = machine__idle_thread(machine);\n\tif (!thread)\n\t\treturn -ENOMEM;\n\tthread__put(thread);\n\n\tmachine->kallsyms_filename = perf_data__guest_kallsyms_name(session->data, machine_pid);\n\n\treturn 0;\n}\n\nstatic int perf_session__set_guest_cpu(struct perf_session *session, pid_t pid,\n\t\t\t\t       pid_t tid, int guest_cpu)\n{\n\tstruct machine *machine = &session->machines.host;\n\tstruct thread *thread = machine__findnew_thread(machine, pid, tid);\n\n\tif (!thread)\n\t\treturn -ENOMEM;\n\tthread__set_guest_cpu(thread, guest_cpu);\n\tthread__put(thread);\n\n\treturn 0;\n}\n\nint perf_event__process_id_index(struct perf_session *session,\n\t\t\t\t union perf_event *event)\n{\n\tstruct evlist *evlist = session->evlist;\n\tstruct perf_record_id_index *ie = &event->id_index;\n\tsize_t sz = ie->header.size - sizeof(*ie);\n\tsize_t i, nr, max_nr;\n\tsize_t e1_sz = sizeof(struct id_index_entry);\n\tsize_t e2_sz = sizeof(struct id_index_entry_2);\n\tsize_t etot_sz = e1_sz + e2_sz;\n\tstruct id_index_entry_2 *e2;\n\tpid_t last_pid = 0;\n\n\tmax_nr = sz / e1_sz;\n\tnr = ie->nr;\n\tif (nr > max_nr) {\n\t\tprintf(\"Too big: nr %zu max_nr %zu\\n\", nr, max_nr);\n\t\treturn -EINVAL;\n\t}\n\n\tif (sz >= nr * etot_sz) {\n\t\tmax_nr = sz / etot_sz;\n\t\tif (nr > max_nr) {\n\t\t\tprintf(\"Too big2: nr %zu max_nr %zu\\n\", nr, max_nr);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\te2 = (void *)ie + sizeof(*ie) + nr * e1_sz;\n\t} else {\n\t\te2 = NULL;\n\t}\n\n\tif (dump_trace)\n\t\tfprintf(stdout, \" nr: %zu\\n\", nr);\n\n\tfor (i = 0; i < nr; i++, (e2 ? e2++ : 0)) {\n\t\tstruct id_index_entry *e = &ie->entries[i];\n\t\tstruct perf_sample_id *sid;\n\t\tint ret;\n\n\t\tif (dump_trace) {\n\t\t\tfprintf(stdout,\t\" ... id: %\"PRI_lu64, e->id);\n\t\t\tfprintf(stdout,\t\"  idx: %\"PRI_lu64, e->idx);\n\t\t\tfprintf(stdout,\t\"  cpu: %\"PRI_ld64, e->cpu);\n\t\t\tfprintf(stdout, \"  tid: %\"PRI_ld64, e->tid);\n\t\t\tif (e2) {\n\t\t\t\tfprintf(stdout, \"  machine_pid: %\"PRI_ld64, e2->machine_pid);\n\t\t\t\tfprintf(stdout, \"  vcpu: %\"PRI_lu64\"\\n\", e2->vcpu);\n\t\t\t} else {\n\t\t\t\tfprintf(stdout, \"\\n\");\n\t\t\t}\n\t\t}\n\n\t\tsid = evlist__id2sid(evlist, e->id);\n\t\tif (!sid)\n\t\t\treturn -ENOENT;\n\n\t\tsid->idx = e->idx;\n\t\tsid->cpu.cpu = e->cpu;\n\t\tsid->tid = e->tid;\n\n\t\tif (!e2)\n\t\t\tcontinue;\n\n\t\tsid->machine_pid = e2->machine_pid;\n\t\tsid->vcpu.cpu = e2->vcpu;\n\n\t\tif (!sid->machine_pid)\n\t\t\tcontinue;\n\n\t\tif (sid->machine_pid != last_pid) {\n\t\t\tret = perf_session__register_guest(session, sid->machine_pid);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tlast_pid = sid->machine_pid;\n\t\t\tperf_guest = true;\n\t\t}\n\n\t\tret = perf_session__set_guest_cpu(session, sid->machine_pid, e->tid, e2->vcpu);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}