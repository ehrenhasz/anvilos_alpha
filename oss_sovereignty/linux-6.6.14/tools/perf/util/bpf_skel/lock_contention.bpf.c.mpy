{
  "module_name": "lock_contention.bpf.c",
  "hash_id": "c285c676672719aa2642afa592d36ea2c9eb717c510ffe4341f6f06b8899eab7",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/bpf_skel/lock_contention.bpf.c",
  "human_readable_source": "\n\n#include \"vmlinux.h\"\n#include <bpf/bpf_helpers.h>\n#include <bpf/bpf_tracing.h>\n#include <bpf/bpf_core_read.h>\n#include <asm-generic/errno-base.h>\n\n#include \"lock_data.h\"\n\n \n#define MAX_CPUS  1024\n\n \n#define LCB_F_SPIN\t(1U << 0)\n#define LCB_F_READ\t(1U << 1)\n#define LCB_F_WRITE\t(1U << 2)\n#define LCB_F_RT\t(1U << 3)\n#define LCB_F_PERCPU\t(1U << 4)\n#define LCB_F_MUTEX\t(1U << 5)\n\nstruct tstamp_data {\n\t__u64 timestamp;\n\t__u64 lock;\n\t__u32 flags;\n\t__s32 stack_id;\n};\n\n \nstruct {\n\t__uint(type, BPF_MAP_TYPE_STACK_TRACE);\n\t__uint(key_size, sizeof(__u32));\n\t__uint(value_size, sizeof(__u64));\n\t__uint(max_entries, MAX_ENTRIES);\n} stacks SEC(\".maps\");\n\n \nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__type(key, int);\n\t__type(value, struct tstamp_data);\n\t__uint(max_entries, MAX_ENTRIES);\n} tstamp SEC(\".maps\");\n\n \nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(key_size, sizeof(struct contention_key));\n\t__uint(value_size, sizeof(struct contention_data));\n\t__uint(max_entries, MAX_ENTRIES);\n} lock_stat SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(key_size, sizeof(__u32));\n\t__uint(value_size, sizeof(struct contention_task_data));\n\t__uint(max_entries, MAX_ENTRIES);\n} task_data SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(key_size, sizeof(__u64));\n\t__uint(value_size, sizeof(__u32));\n\t__uint(max_entries, MAX_ENTRIES);\n} lock_syms SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(key_size, sizeof(__u32));\n\t__uint(value_size, sizeof(__u8));\n\t__uint(max_entries, 1);\n} cpu_filter SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(key_size, sizeof(__u32));\n\t__uint(value_size, sizeof(__u8));\n\t__uint(max_entries, 1);\n} task_filter SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(key_size, sizeof(__u32));\n\t__uint(value_size, sizeof(__u8));\n\t__uint(max_entries, 1);\n} type_filter SEC(\".maps\");\n\nstruct {\n\t__uint(type, BPF_MAP_TYPE_HASH);\n\t__uint(key_size, sizeof(__u64));\n\t__uint(value_size, sizeof(__u8));\n\t__uint(max_entries, 1);\n} addr_filter SEC(\".maps\");\n\nstruct rw_semaphore___old {\n\tstruct task_struct *owner;\n} __attribute__((preserve_access_index));\n\nstruct rw_semaphore___new {\n\tatomic_long_t owner;\n} __attribute__((preserve_access_index));\n\nstruct mm_struct___old {\n\tstruct rw_semaphore mmap_sem;\n} __attribute__((preserve_access_index));\n\nstruct mm_struct___new {\n\tstruct rw_semaphore mmap_lock;\n} __attribute__((preserve_access_index));\n\n \nint enabled;\nint has_cpu;\nint has_task;\nint has_type;\nint has_addr;\nint needs_callstack;\nint stack_skip;\nint lock_owner;\n\n \nint aggr_mode;\n\n \nint task_fail;\nint stack_fail;\nint time_fail;\nint data_fail;\n\nint task_map_full;\nint data_map_full;\n\nstatic inline int can_record(u64 *ctx)\n{\n\tif (has_cpu) {\n\t\t__u32 cpu = bpf_get_smp_processor_id();\n\t\t__u8 *ok;\n\n\t\tok = bpf_map_lookup_elem(&cpu_filter, &cpu);\n\t\tif (!ok)\n\t\t\treturn 0;\n\t}\n\n\tif (has_task) {\n\t\t__u8 *ok;\n\t\t__u32 pid = bpf_get_current_pid_tgid();\n\n\t\tok = bpf_map_lookup_elem(&task_filter, &pid);\n\t\tif (!ok)\n\t\t\treturn 0;\n\t}\n\n\tif (has_type) {\n\t\t__u8 *ok;\n\t\t__u32 flags = (__u32)ctx[1];\n\n\t\tok = bpf_map_lookup_elem(&type_filter, &flags);\n\t\tif (!ok)\n\t\t\treturn 0;\n\t}\n\n\tif (has_addr) {\n\t\t__u8 *ok;\n\t\t__u64 addr = ctx[0];\n\n\t\tok = bpf_map_lookup_elem(&addr_filter, &addr);\n\t\tif (!ok)\n\t\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic inline int update_task_data(struct task_struct *task)\n{\n\tstruct contention_task_data *p;\n\tint pid, err;\n\n\terr = bpf_core_read(&pid, sizeof(pid), &task->pid);\n\tif (err)\n\t\treturn -1;\n\n\tp = bpf_map_lookup_elem(&task_data, &pid);\n\tif (p == NULL && !task_map_full) {\n\t\tstruct contention_task_data data = {};\n\n\t\tBPF_CORE_READ_STR_INTO(&data.comm, task, comm);\n\t\tif (bpf_map_update_elem(&task_data, &pid, &data, BPF_NOEXIST) == -E2BIG)\n\t\t\ttask_map_full = 1;\n\t}\n\n\treturn 0;\n}\n\n#ifndef __has_builtin\n# define __has_builtin(x) 0\n#endif\n\nstatic inline struct task_struct *get_lock_owner(__u64 lock, __u32 flags)\n{\n\tstruct task_struct *task;\n\t__u64 owner = 0;\n\n\tif (flags & LCB_F_MUTEX) {\n\t\tstruct mutex *mutex = (void *)lock;\n\t\towner = BPF_CORE_READ(mutex, owner.counter);\n\t} else if (flags == LCB_F_READ || flags == LCB_F_WRITE) {\n\t \n#if __has_builtin(__builtin_preserve_type_info) && __clang_major__ >= 15\n\t\tif (bpf_core_type_matches(struct rw_semaphore___old)) {\n\t\t\tstruct rw_semaphore___old *rwsem = (void *)lock;\n\t\t\towner = (unsigned long)BPF_CORE_READ(rwsem, owner);\n\t\t} else if (bpf_core_type_matches(struct rw_semaphore___new)) {\n\t\t\tstruct rw_semaphore___new *rwsem = (void *)lock;\n\t\t\towner = BPF_CORE_READ(rwsem, owner.counter);\n\t\t}\n#else\n\t\t \n\t\tstruct rw_semaphore *rwsem = (void *)lock;\n\t\towner = BPF_CORE_READ(rwsem, owner.counter);\n#endif\n\t}\n\n\tif (!owner)\n\t\treturn NULL;\n\n\ttask = (void *)(owner & ~7UL);\n\treturn task;\n}\n\nstatic inline __u32 check_lock_type(__u64 lock, __u32 flags)\n{\n\tstruct task_struct *curr;\n\tstruct mm_struct___old *mm_old;\n\tstruct mm_struct___new *mm_new;\n\n\tswitch (flags) {\n\tcase LCB_F_READ:   \n\tcase LCB_F_WRITE:\n\t\tcurr = bpf_get_current_task_btf();\n\t\tif (curr->mm == NULL)\n\t\t\tbreak;\n\t\tmm_new = (void *)curr->mm;\n\t\tif (bpf_core_field_exists(mm_new->mmap_lock)) {\n\t\t\tif (&mm_new->mmap_lock == (void *)lock)\n\t\t\t\treturn LCD_F_MMAP_LOCK;\n\t\t\tbreak;\n\t\t}\n\t\tmm_old = (void *)curr->mm;\n\t\tif (bpf_core_field_exists(mm_old->mmap_sem)) {\n\t\t\tif (&mm_old->mmap_sem == (void *)lock)\n\t\t\t\treturn LCD_F_MMAP_LOCK;\n\t\t}\n\t\tbreak;\n\tcase LCB_F_SPIN:   \n\t\tcurr = bpf_get_current_task_btf();\n\t\tif (&curr->sighand->siglock == (void *)lock)\n\t\t\treturn LCD_F_SIGHAND_LOCK;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nSEC(\"tp_btf/contention_begin\")\nint contention_begin(u64 *ctx)\n{\n\t__u32 pid;\n\tstruct tstamp_data *pelem;\n\n\tif (!enabled || !can_record(ctx))\n\t\treturn 0;\n\n\tpid = bpf_get_current_pid_tgid();\n\tpelem = bpf_map_lookup_elem(&tstamp, &pid);\n\tif (pelem && pelem->lock)\n\t\treturn 0;\n\n\tif (pelem == NULL) {\n\t\tstruct tstamp_data zero = {};\n\n\t\tbpf_map_update_elem(&tstamp, &pid, &zero, BPF_ANY);\n\t\tpelem = bpf_map_lookup_elem(&tstamp, &pid);\n\t\tif (pelem == NULL) {\n\t\t\t__sync_fetch_and_add(&task_fail, 1);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tpelem->timestamp = bpf_ktime_get_ns();\n\tpelem->lock = (__u64)ctx[0];\n\tpelem->flags = (__u32)ctx[1];\n\n\tif (needs_callstack) {\n\t\tpelem->stack_id = bpf_get_stackid(ctx, &stacks,\n\t\t\t\t\t\t  BPF_F_FAST_STACK_CMP | stack_skip);\n\t\tif (pelem->stack_id < 0)\n\t\t\t__sync_fetch_and_add(&stack_fail, 1);\n\t} else if (aggr_mode == LOCK_AGGR_TASK) {\n\t\tstruct task_struct *task;\n\n\t\tif (lock_owner) {\n\t\t\ttask = get_lock_owner(pelem->lock, pelem->flags);\n\n\t\t\t \n\t\t\tif (task)\n\t\t\t\tpelem->flags = BPF_CORE_READ(task, pid);\n\t\t\telse\n\t\t\t\tpelem->flags = -1U;\n\n\t\t} else {\n\t\t\ttask = bpf_get_current_task_btf();\n\t\t}\n\n\t\tif (task) {\n\t\t\tif (update_task_data(task) < 0 && lock_owner)\n\t\t\t\tpelem->flags = -1U;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nSEC(\"tp_btf/contention_end\")\nint contention_end(u64 *ctx)\n{\n\t__u32 pid;\n\tstruct tstamp_data *pelem;\n\tstruct contention_key key = {};\n\tstruct contention_data *data;\n\t__u64 duration;\n\n\tif (!enabled)\n\t\treturn 0;\n\n\tpid = bpf_get_current_pid_tgid();\n\tpelem = bpf_map_lookup_elem(&tstamp, &pid);\n\tif (!pelem || pelem->lock != ctx[0])\n\t\treturn 0;\n\n\tduration = bpf_ktime_get_ns() - pelem->timestamp;\n\tif ((__s64)duration < 0) {\n\t\tbpf_map_delete_elem(&tstamp, &pid);\n\t\t__sync_fetch_and_add(&time_fail, 1);\n\t\treturn 0;\n\t}\n\n\tswitch (aggr_mode) {\n\tcase LOCK_AGGR_CALLER:\n\t\tkey.stack_id = pelem->stack_id;\n\t\tbreak;\n\tcase LOCK_AGGR_TASK:\n\t\tif (lock_owner)\n\t\t\tkey.pid = pelem->flags;\n\t\telse\n\t\t\tkey.pid = pid;\n\t\tif (needs_callstack)\n\t\t\tkey.stack_id = pelem->stack_id;\n\t\tbreak;\n\tcase LOCK_AGGR_ADDR:\n\t\tkey.lock_addr = pelem->lock;\n\t\tif (needs_callstack)\n\t\t\tkey.stack_id = pelem->stack_id;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn 0;\n\t}\n\n\tdata = bpf_map_lookup_elem(&lock_stat, &key);\n\tif (!data) {\n\t\tif (data_map_full) {\n\t\t\tbpf_map_delete_elem(&tstamp, &pid);\n\t\t\t__sync_fetch_and_add(&data_fail, 1);\n\t\t\treturn 0;\n\t\t}\n\n\t\tstruct contention_data first = {\n\t\t\t.total_time = duration,\n\t\t\t.max_time = duration,\n\t\t\t.min_time = duration,\n\t\t\t.count = 1,\n\t\t\t.flags = pelem->flags,\n\t\t};\n\t\tint err;\n\n\t\tif (aggr_mode == LOCK_AGGR_ADDR)\n\t\t\tfirst.flags |= check_lock_type(pelem->lock, pelem->flags);\n\n\t\terr = bpf_map_update_elem(&lock_stat, &key, &first, BPF_NOEXIST);\n\t\tif (err < 0) {\n\t\t\tif (err == -E2BIG)\n\t\t\t\tdata_map_full = 1;\n\t\t\t__sync_fetch_and_add(&data_fail, 1);\n\t\t}\n\t\tbpf_map_delete_elem(&tstamp, &pid);\n\t\treturn 0;\n\t}\n\n\t__sync_fetch_and_add(&data->total_time, duration);\n\t__sync_fetch_and_add(&data->count, 1);\n\n\t \n\tif (data->max_time < duration)\n\t\tdata->max_time = duration;\n\tif (data->min_time > duration)\n\t\tdata->min_time = duration;\n\n\tbpf_map_delete_elem(&tstamp, &pid);\n\treturn 0;\n}\n\nextern struct rq runqueues __ksym;\n\nstruct rq___old {\n\traw_spinlock_t lock;\n} __attribute__((preserve_access_index));\n\nstruct rq___new {\n\traw_spinlock_t __lock;\n} __attribute__((preserve_access_index));\n\nSEC(\"raw_tp/bpf_test_finish\")\nint BPF_PROG(collect_lock_syms)\n{\n\t__u64 lock_addr, lock_off;\n\t__u32 lock_flag;\n\n\tif (bpf_core_field_exists(struct rq___new, __lock))\n\t\tlock_off = offsetof(struct rq___new, __lock);\n\telse\n\t\tlock_off = offsetof(struct rq___old, lock);\n\n\tfor (int i = 0; i < MAX_CPUS; i++) {\n\t\tstruct rq *rq = bpf_per_cpu_ptr(&runqueues, i);\n\n\t\tif (rq == NULL)\n\t\t\tbreak;\n\n\t\tlock_addr = (__u64)(void *)rq + lock_off;\n\t\tlock_flag = LOCK_CLASS_RQLOCK;\n\t\tbpf_map_update_elem(&lock_syms, &lock_addr, &lock_flag, BPF_ANY);\n\t}\n\treturn 0;\n}\n\nchar LICENSE[] SEC(\"license\") = \"Dual BSD/GPL\";\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}