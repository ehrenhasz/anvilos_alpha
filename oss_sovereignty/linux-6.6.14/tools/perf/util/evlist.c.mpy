{
  "module_name": "evlist.c",
  "hash_id": "9f026d2df7863f5896707f40efe15cc53d1503e1fce2ff898de6cb62a1a6ae78",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/evlist.c",
  "human_readable_source": "\n \n#include <api/fs/fs.h>\n#include <errno.h>\n#include <inttypes.h>\n#include <poll.h>\n#include \"cpumap.h\"\n#include \"util/mmap.h\"\n#include \"thread_map.h\"\n#include \"target.h\"\n#include \"evlist.h\"\n#include \"evsel.h\"\n#include \"record.h\"\n#include \"debug.h\"\n#include \"units.h\"\n#include \"bpf_counter.h\"\n#include <internal/lib.h> \n#include \"affinity.h\"\n#include \"../perf.h\"\n#include \"asm/bug.h\"\n#include \"bpf-event.h\"\n#include \"util/event.h\"\n#include \"util/string2.h\"\n#include \"util/perf_api_probe.h\"\n#include \"util/evsel_fprintf.h\"\n#include \"util/pmu.h\"\n#include \"util/sample.h\"\n#include \"util/bpf-filter.h\"\n#include \"util/stat.h\"\n#include \"util/util.h\"\n#include <signal.h>\n#include <unistd.h>\n#include <sched.h>\n#include <stdlib.h>\n\n#include \"parse-events.h\"\n#include <subcmd/parse-options.h>\n\n#include <fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/mman.h>\n#include <sys/prctl.h>\n#include <sys/timerfd.h>\n\n#include <linux/bitops.h>\n#include <linux/hash.h>\n#include <linux/log2.h>\n#include <linux/err.h>\n#include <linux/string.h>\n#include <linux/time64.h>\n#include <linux/zalloc.h>\n#include <perf/evlist.h>\n#include <perf/evsel.h>\n#include <perf/cpumap.h>\n#include <perf/mmap.h>\n\n#include <internal/xyarray.h>\n\n#ifdef LACKS_SIGQUEUE_PROTOTYPE\nint sigqueue(pid_t pid, int sig, const union sigval value);\n#endif\n\n#define FD(e, x, y) (*(int *)xyarray__entry(e->core.fd, x, y))\n#define SID(e, x, y) xyarray__entry(e->core.sample_id, x, y)\n\nvoid evlist__init(struct evlist *evlist, struct perf_cpu_map *cpus,\n\t\t  struct perf_thread_map *threads)\n{\n\tperf_evlist__init(&evlist->core);\n\tperf_evlist__set_maps(&evlist->core, cpus, threads);\n\tevlist->workload.pid = -1;\n\tevlist->bkw_mmap_state = BKW_MMAP_NOTREADY;\n\tevlist->ctl_fd.fd = -1;\n\tevlist->ctl_fd.ack = -1;\n\tevlist->ctl_fd.pos = -1;\n}\n\nstruct evlist *evlist__new(void)\n{\n\tstruct evlist *evlist = zalloc(sizeof(*evlist));\n\n\tif (evlist != NULL)\n\t\tevlist__init(evlist, NULL, NULL);\n\n\treturn evlist;\n}\n\nstruct evlist *evlist__new_default(void)\n{\n\tstruct evlist *evlist = evlist__new();\n\tbool can_profile_kernel;\n\tint err;\n\n\tif (!evlist)\n\t\treturn NULL;\n\n\tcan_profile_kernel = perf_event_paranoid_check(1);\n\terr = parse_event(evlist, can_profile_kernel ? \"cycles:P\" : \"cycles:Pu\");\n\tif (err) {\n\t\tevlist__delete(evlist);\n\t\tevlist = NULL;\n\t}\n\n\treturn evlist;\n}\n\nstruct evlist *evlist__new_dummy(void)\n{\n\tstruct evlist *evlist = evlist__new();\n\n\tif (evlist && evlist__add_dummy(evlist)) {\n\t\tevlist__delete(evlist);\n\t\tevlist = NULL;\n\t}\n\n\treturn evlist;\n}\n\n \nvoid evlist__set_id_pos(struct evlist *evlist)\n{\n\tstruct evsel *first = evlist__first(evlist);\n\n\tevlist->id_pos = first->id_pos;\n\tevlist->is_pos = first->is_pos;\n}\n\nstatic void evlist__update_id_pos(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel)\n\t\tevsel__calc_id_pos(evsel);\n\n\tevlist__set_id_pos(evlist);\n}\n\nstatic void evlist__purge(struct evlist *evlist)\n{\n\tstruct evsel *pos, *n;\n\n\tevlist__for_each_entry_safe(evlist, n, pos) {\n\t\tlist_del_init(&pos->core.node);\n\t\tpos->evlist = NULL;\n\t\tevsel__delete(pos);\n\t}\n\n\tevlist->core.nr_entries = 0;\n}\n\nvoid evlist__exit(struct evlist *evlist)\n{\n\tevent_enable_timer__exit(&evlist->eet);\n\tzfree(&evlist->mmap);\n\tzfree(&evlist->overwrite_mmap);\n\tperf_evlist__exit(&evlist->core);\n}\n\nvoid evlist__delete(struct evlist *evlist)\n{\n\tif (evlist == NULL)\n\t\treturn;\n\n\tevlist__free_stats(evlist);\n\tevlist__munmap(evlist);\n\tevlist__close(evlist);\n\tevlist__purge(evlist);\n\tevlist__exit(evlist);\n\tfree(evlist);\n}\n\nvoid evlist__add(struct evlist *evlist, struct evsel *entry)\n{\n\tperf_evlist__add(&evlist->core, &entry->core);\n\tentry->evlist = evlist;\n\tentry->tracking = !entry->core.idx;\n\n\tif (evlist->core.nr_entries == 1)\n\t\tevlist__set_id_pos(evlist);\n}\n\nvoid evlist__remove(struct evlist *evlist, struct evsel *evsel)\n{\n\tevsel->evlist = NULL;\n\tperf_evlist__remove(&evlist->core, &evsel->core);\n}\n\nvoid evlist__splice_list_tail(struct evlist *evlist, struct list_head *list)\n{\n\twhile (!list_empty(list)) {\n\t\tstruct evsel *evsel, *temp, *leader = NULL;\n\n\t\t__evlist__for_each_entry_safe(list, temp, evsel) {\n\t\t\tlist_del_init(&evsel->core.node);\n\t\t\tevlist__add(evlist, evsel);\n\t\t\tleader = evsel;\n\t\t\tbreak;\n\t\t}\n\n\t\t__evlist__for_each_entry_safe(list, temp, evsel) {\n\t\t\tif (evsel__has_leader(evsel, leader)) {\n\t\t\t\tlist_del_init(&evsel->core.node);\n\t\t\t\tevlist__add(evlist, evsel);\n\t\t\t}\n\t\t}\n\t}\n}\n\nint __evlist__set_tracepoints_handlers(struct evlist *evlist,\n\t\t\t\t       const struct evsel_str_handler *assocs, size_t nr_assocs)\n{\n\tsize_t i;\n\tint err;\n\n\tfor (i = 0; i < nr_assocs; i++) {\n\t\t\n\t\tstruct evsel *evsel = evlist__find_tracepoint_by_name(evlist, assocs[i].name);\n\t\tif (evsel == NULL)\n\t\t\tcontinue;\n\n\t\terr = -EEXIST;\n\t\tif (evsel->handler != NULL)\n\t\t\tgoto out;\n\t\tevsel->handler = assocs[i].handler;\n\t}\n\n\terr = 0;\nout:\n\treturn err;\n}\n\nstatic void evlist__set_leader(struct evlist *evlist)\n{\n\tperf_evlist__set_leader(&evlist->core);\n}\n\nstatic struct evsel *evlist__dummy_event(struct evlist *evlist)\n{\n\tstruct perf_event_attr attr = {\n\t\t.type\t= PERF_TYPE_SOFTWARE,\n\t\t.config = PERF_COUNT_SW_DUMMY,\n\t\t.size\t= sizeof(attr),  \n\t\t \n\t\t.freq = 0,\n\t\t.sample_period = 1,\n\t};\n\n\treturn evsel__new_idx(&attr, evlist->core.nr_entries);\n}\n\nint evlist__add_dummy(struct evlist *evlist)\n{\n\tstruct evsel *evsel = evlist__dummy_event(evlist);\n\n\tif (evsel == NULL)\n\t\treturn -ENOMEM;\n\n\tevlist__add(evlist, evsel);\n\treturn 0;\n}\n\nstruct evsel *evlist__add_aux_dummy(struct evlist *evlist, bool system_wide)\n{\n\tstruct evsel *evsel = evlist__dummy_event(evlist);\n\n\tif (!evsel)\n\t\treturn NULL;\n\n\tevsel->core.attr.exclude_kernel = 1;\n\tevsel->core.attr.exclude_guest = 1;\n\tevsel->core.attr.exclude_hv = 1;\n\tevsel->core.system_wide = system_wide;\n\tevsel->no_aux_samples = true;\n\tevsel->name = strdup(\"dummy:u\");\n\n\tevlist__add(evlist, evsel);\n\treturn evsel;\n}\n\n#ifdef HAVE_LIBTRACEEVENT\nstruct evsel *evlist__add_sched_switch(struct evlist *evlist, bool system_wide)\n{\n\tstruct evsel *evsel = evsel__newtp_idx(\"sched\", \"sched_switch\", 0);\n\n\tif (IS_ERR(evsel))\n\t\treturn evsel;\n\n\tevsel__set_sample_bit(evsel, CPU);\n\tevsel__set_sample_bit(evsel, TIME);\n\n\tevsel->core.system_wide = system_wide;\n\tevsel->no_aux_samples = true;\n\n\tevlist__add(evlist, evsel);\n\treturn evsel;\n}\n#endif\n\nint evlist__add_attrs(struct evlist *evlist, struct perf_event_attr *attrs, size_t nr_attrs)\n{\n\tstruct evsel *evsel, *n;\n\tLIST_HEAD(head);\n\tsize_t i;\n\n\tfor (i = 0; i < nr_attrs; i++) {\n\t\tevsel = evsel__new_idx(attrs + i, evlist->core.nr_entries + i);\n\t\tif (evsel == NULL)\n\t\t\tgoto out_delete_partial_list;\n\t\tlist_add_tail(&evsel->core.node, &head);\n\t}\n\n\tevlist__splice_list_tail(evlist, &head);\n\n\treturn 0;\n\nout_delete_partial_list:\n\t__evlist__for_each_entry_safe(&head, n, evsel)\n\t\tevsel__delete(evsel);\n\treturn -1;\n}\n\nint __evlist__add_default_attrs(struct evlist *evlist, struct perf_event_attr *attrs, size_t nr_attrs)\n{\n\tsize_t i;\n\n\tfor (i = 0; i < nr_attrs; i++)\n\t\tevent_attr_init(attrs + i);\n\n\treturn evlist__add_attrs(evlist, attrs, nr_attrs);\n}\n\n__weak int arch_evlist__add_default_attrs(struct evlist *evlist,\n\t\t\t\t\t  struct perf_event_attr *attrs,\n\t\t\t\t\t  size_t nr_attrs)\n{\n\tif (!nr_attrs)\n\t\treturn 0;\n\n\treturn __evlist__add_default_attrs(evlist, attrs, nr_attrs);\n}\n\nstruct evsel *evlist__find_tracepoint_by_id(struct evlist *evlist, int id)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.type   == PERF_TYPE_TRACEPOINT &&\n\t\t    (int)evsel->core.attr.config == id)\n\t\t\treturn evsel;\n\t}\n\n\treturn NULL;\n}\n\nstruct evsel *evlist__find_tracepoint_by_name(struct evlist *evlist, const char *name)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif ((evsel->core.attr.type == PERF_TYPE_TRACEPOINT) &&\n\t\t    (strcmp(evsel->name, name) == 0))\n\t\t\treturn evsel;\n\t}\n\n\treturn NULL;\n}\n\n#ifdef HAVE_LIBTRACEEVENT\nint evlist__add_newtp(struct evlist *evlist, const char *sys, const char *name, void *handler)\n{\n\tstruct evsel *evsel = evsel__newtp(sys, name);\n\n\tif (IS_ERR(evsel))\n\t\treturn -1;\n\n\tevsel->handler = handler;\n\tevlist__add(evlist, evsel);\n\treturn 0;\n}\n#endif\n\nstruct evlist_cpu_iterator evlist__cpu_begin(struct evlist *evlist, struct affinity *affinity)\n{\n\tstruct evlist_cpu_iterator itr = {\n\t\t.container = evlist,\n\t\t.evsel = NULL,\n\t\t.cpu_map_idx = 0,\n\t\t.evlist_cpu_map_idx = 0,\n\t\t.evlist_cpu_map_nr = perf_cpu_map__nr(evlist->core.all_cpus),\n\t\t.cpu = (struct perf_cpu){ .cpu = -1},\n\t\t.affinity = affinity,\n\t};\n\n\tif (evlist__empty(evlist)) {\n\t\t \n\t\titr.evlist_cpu_map_idx = itr.evlist_cpu_map_nr;\n\t} else {\n\t\titr.evsel = evlist__first(evlist);\n\t\tif (itr.affinity) {\n\t\t\titr.cpu = perf_cpu_map__cpu(evlist->core.all_cpus, 0);\n\t\t\taffinity__set(itr.affinity, itr.cpu.cpu);\n\t\t\titr.cpu_map_idx = perf_cpu_map__idx(itr.evsel->core.cpus, itr.cpu);\n\t\t\t \n\t\t\tif (itr.cpu_map_idx == -1)\n\t\t\t\tevlist_cpu_iterator__next(&itr);\n\t\t}\n\t}\n\treturn itr;\n}\n\nvoid evlist_cpu_iterator__next(struct evlist_cpu_iterator *evlist_cpu_itr)\n{\n\twhile (evlist_cpu_itr->evsel != evlist__last(evlist_cpu_itr->container)) {\n\t\tevlist_cpu_itr->evsel = evsel__next(evlist_cpu_itr->evsel);\n\t\tevlist_cpu_itr->cpu_map_idx =\n\t\t\tperf_cpu_map__idx(evlist_cpu_itr->evsel->core.cpus,\n\t\t\t\t\t  evlist_cpu_itr->cpu);\n\t\tif (evlist_cpu_itr->cpu_map_idx != -1)\n\t\t\treturn;\n\t}\n\tevlist_cpu_itr->evlist_cpu_map_idx++;\n\tif (evlist_cpu_itr->evlist_cpu_map_idx < evlist_cpu_itr->evlist_cpu_map_nr) {\n\t\tevlist_cpu_itr->evsel = evlist__first(evlist_cpu_itr->container);\n\t\tevlist_cpu_itr->cpu =\n\t\t\tperf_cpu_map__cpu(evlist_cpu_itr->container->core.all_cpus,\n\t\t\t\t\t  evlist_cpu_itr->evlist_cpu_map_idx);\n\t\tif (evlist_cpu_itr->affinity)\n\t\t\taffinity__set(evlist_cpu_itr->affinity, evlist_cpu_itr->cpu.cpu);\n\t\tevlist_cpu_itr->cpu_map_idx =\n\t\t\tperf_cpu_map__idx(evlist_cpu_itr->evsel->core.cpus,\n\t\t\t\t\t  evlist_cpu_itr->cpu);\n\t\t \n\t\tif (evlist_cpu_itr->cpu_map_idx == -1)\n\t\t\tevlist_cpu_iterator__next(evlist_cpu_itr);\n\t}\n}\n\nbool evlist_cpu_iterator__end(const struct evlist_cpu_iterator *evlist_cpu_itr)\n{\n\treturn evlist_cpu_itr->evlist_cpu_map_idx >= evlist_cpu_itr->evlist_cpu_map_nr;\n}\n\nstatic int evsel__strcmp(struct evsel *pos, char *evsel_name)\n{\n\tif (!evsel_name)\n\t\treturn 0;\n\tif (evsel__is_dummy_event(pos))\n\t\treturn 1;\n\treturn !evsel__name_is(pos, evsel_name);\n}\n\nstatic int evlist__is_enabled(struct evlist *evlist)\n{\n\tstruct evsel *pos;\n\n\tevlist__for_each_entry(evlist, pos) {\n\t\tif (!evsel__is_group_leader(pos) || !pos->core.fd)\n\t\t\tcontinue;\n\t\t \n\t\tif (!pos->disabled)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic void __evlist__disable(struct evlist *evlist, char *evsel_name, bool excl_dummy)\n{\n\tstruct evsel *pos;\n\tstruct evlist_cpu_iterator evlist_cpu_itr;\n\tstruct affinity saved_affinity, *affinity = NULL;\n\tbool has_imm = false;\n\n\t \n\tif (!cpu_map__is_dummy(evlist->core.user_requested_cpus)) {\n\t\tif (affinity__setup(&saved_affinity) < 0)\n\t\t\treturn;\n\t\taffinity = &saved_affinity;\n\t}\n\n\t \n\tfor (int imm = 0; imm <= 1; imm++) {\n\t\tevlist__for_each_cpu(evlist_cpu_itr, evlist, affinity) {\n\t\t\tpos = evlist_cpu_itr.evsel;\n\t\t\tif (evsel__strcmp(pos, evsel_name))\n\t\t\t\tcontinue;\n\t\t\tif (pos->disabled || !evsel__is_group_leader(pos) || !pos->core.fd)\n\t\t\t\tcontinue;\n\t\t\tif (excl_dummy && evsel__is_dummy_event(pos))\n\t\t\t\tcontinue;\n\t\t\tif (pos->immediate)\n\t\t\t\thas_imm = true;\n\t\t\tif (pos->immediate != imm)\n\t\t\t\tcontinue;\n\t\t\tevsel__disable_cpu(pos, evlist_cpu_itr.cpu_map_idx);\n\t\t}\n\t\tif (!has_imm)\n\t\t\tbreak;\n\t}\n\n\taffinity__cleanup(affinity);\n\tevlist__for_each_entry(evlist, pos) {\n\t\tif (evsel__strcmp(pos, evsel_name))\n\t\t\tcontinue;\n\t\tif (!evsel__is_group_leader(pos) || !pos->core.fd)\n\t\t\tcontinue;\n\t\tif (excl_dummy && evsel__is_dummy_event(pos))\n\t\t\tcontinue;\n\t\tpos->disabled = true;\n\t}\n\n\t \n\tif (evsel_name)\n\t\tevlist->enabled = evlist__is_enabled(evlist);\n\telse\n\t\tevlist->enabled = false;\n}\n\nvoid evlist__disable(struct evlist *evlist)\n{\n\t__evlist__disable(evlist, NULL, false);\n}\n\nvoid evlist__disable_non_dummy(struct evlist *evlist)\n{\n\t__evlist__disable(evlist, NULL, true);\n}\n\nvoid evlist__disable_evsel(struct evlist *evlist, char *evsel_name)\n{\n\t__evlist__disable(evlist, evsel_name, false);\n}\n\nstatic void __evlist__enable(struct evlist *evlist, char *evsel_name, bool excl_dummy)\n{\n\tstruct evsel *pos;\n\tstruct evlist_cpu_iterator evlist_cpu_itr;\n\tstruct affinity saved_affinity, *affinity = NULL;\n\n\t \n\tif (!cpu_map__is_dummy(evlist->core.user_requested_cpus)) {\n\t\tif (affinity__setup(&saved_affinity) < 0)\n\t\t\treturn;\n\t\taffinity = &saved_affinity;\n\t}\n\n\tevlist__for_each_cpu(evlist_cpu_itr, evlist, affinity) {\n\t\tpos = evlist_cpu_itr.evsel;\n\t\tif (evsel__strcmp(pos, evsel_name))\n\t\t\tcontinue;\n\t\tif (!evsel__is_group_leader(pos) || !pos->core.fd)\n\t\t\tcontinue;\n\t\tif (excl_dummy && evsel__is_dummy_event(pos))\n\t\t\tcontinue;\n\t\tevsel__enable_cpu(pos, evlist_cpu_itr.cpu_map_idx);\n\t}\n\taffinity__cleanup(affinity);\n\tevlist__for_each_entry(evlist, pos) {\n\t\tif (evsel__strcmp(pos, evsel_name))\n\t\t\tcontinue;\n\t\tif (!evsel__is_group_leader(pos) || !pos->core.fd)\n\t\t\tcontinue;\n\t\tif (excl_dummy && evsel__is_dummy_event(pos))\n\t\t\tcontinue;\n\t\tpos->disabled = false;\n\t}\n\n\t \n\tevlist->enabled = true;\n}\n\nvoid evlist__enable(struct evlist *evlist)\n{\n\t__evlist__enable(evlist, NULL, false);\n}\n\nvoid evlist__enable_non_dummy(struct evlist *evlist)\n{\n\t__evlist__enable(evlist, NULL, true);\n}\n\nvoid evlist__enable_evsel(struct evlist *evlist, char *evsel_name)\n{\n\t__evlist__enable(evlist, evsel_name, false);\n}\n\nvoid evlist__toggle_enable(struct evlist *evlist)\n{\n\t(evlist->enabled ? evlist__disable : evlist__enable)(evlist);\n}\n\nint evlist__add_pollfd(struct evlist *evlist, int fd)\n{\n\treturn perf_evlist__add_pollfd(&evlist->core, fd, NULL, POLLIN, fdarray_flag__default);\n}\n\nint evlist__filter_pollfd(struct evlist *evlist, short revents_and_mask)\n{\n\treturn perf_evlist__filter_pollfd(&evlist->core, revents_and_mask);\n}\n\n#ifdef HAVE_EVENTFD_SUPPORT\nint evlist__add_wakeup_eventfd(struct evlist *evlist, int fd)\n{\n\treturn perf_evlist__add_pollfd(&evlist->core, fd, NULL, POLLIN,\n\t\t\t\t       fdarray_flag__nonfilterable |\n\t\t\t\t       fdarray_flag__non_perf_event);\n}\n#endif\n\nint evlist__poll(struct evlist *evlist, int timeout)\n{\n\treturn perf_evlist__poll(&evlist->core, timeout);\n}\n\nstruct perf_sample_id *evlist__id2sid(struct evlist *evlist, u64 id)\n{\n\tstruct hlist_head *head;\n\tstruct perf_sample_id *sid;\n\tint hash;\n\n\thash = hash_64(id, PERF_EVLIST__HLIST_BITS);\n\thead = &evlist->core.heads[hash];\n\n\thlist_for_each_entry(sid, head, node)\n\t\tif (sid->id == id)\n\t\t\treturn sid;\n\n\treturn NULL;\n}\n\nstruct evsel *evlist__id2evsel(struct evlist *evlist, u64 id)\n{\n\tstruct perf_sample_id *sid;\n\n\tif (evlist->core.nr_entries == 1 || !id)\n\t\treturn evlist__first(evlist);\n\n\tsid = evlist__id2sid(evlist, id);\n\tif (sid)\n\t\treturn container_of(sid->evsel, struct evsel, core);\n\n\tif (!evlist__sample_id_all(evlist))\n\t\treturn evlist__first(evlist);\n\n\treturn NULL;\n}\n\nstruct evsel *evlist__id2evsel_strict(struct evlist *evlist, u64 id)\n{\n\tstruct perf_sample_id *sid;\n\n\tif (!id)\n\t\treturn NULL;\n\n\tsid = evlist__id2sid(evlist, id);\n\tif (sid)\n\t\treturn container_of(sid->evsel, struct evsel, core);\n\n\treturn NULL;\n}\n\nstatic int evlist__event2id(struct evlist *evlist, union perf_event *event, u64 *id)\n{\n\tconst __u64 *array = event->sample.array;\n\tssize_t n;\n\n\tn = (event->header.size - sizeof(event->header)) >> 3;\n\n\tif (event->header.type == PERF_RECORD_SAMPLE) {\n\t\tif (evlist->id_pos >= n)\n\t\t\treturn -1;\n\t\t*id = array[evlist->id_pos];\n\t} else {\n\t\tif (evlist->is_pos > n)\n\t\t\treturn -1;\n\t\tn -= evlist->is_pos;\n\t\t*id = array[n];\n\t}\n\treturn 0;\n}\n\nstruct evsel *evlist__event2evsel(struct evlist *evlist, union perf_event *event)\n{\n\tstruct evsel *first = evlist__first(evlist);\n\tstruct hlist_head *head;\n\tstruct perf_sample_id *sid;\n\tint hash;\n\tu64 id;\n\n\tif (evlist->core.nr_entries == 1)\n\t\treturn first;\n\n\tif (!first->core.attr.sample_id_all &&\n\t    event->header.type != PERF_RECORD_SAMPLE)\n\t\treturn first;\n\n\tif (evlist__event2id(evlist, event, &id))\n\t\treturn NULL;\n\n\t \n\tif (!id)\n\t\treturn first;\n\n\thash = hash_64(id, PERF_EVLIST__HLIST_BITS);\n\thead = &evlist->core.heads[hash];\n\n\thlist_for_each_entry(sid, head, node) {\n\t\tif (sid->id == id)\n\t\t\treturn container_of(sid->evsel, struct evsel, core);\n\t}\n\treturn NULL;\n}\n\nstatic int evlist__set_paused(struct evlist *evlist, bool value)\n{\n\tint i;\n\n\tif (!evlist->overwrite_mmap)\n\t\treturn 0;\n\n\tfor (i = 0; i < evlist->core.nr_mmaps; i++) {\n\t\tint fd = evlist->overwrite_mmap[i].core.fd;\n\t\tint err;\n\n\t\tif (fd < 0)\n\t\t\tcontinue;\n\t\terr = ioctl(fd, PERF_EVENT_IOC_PAUSE_OUTPUT, value ? 1 : 0);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}\n\nstatic int evlist__pause(struct evlist *evlist)\n{\n\treturn evlist__set_paused(evlist, true);\n}\n\nstatic int evlist__resume(struct evlist *evlist)\n{\n\treturn evlist__set_paused(evlist, false);\n}\n\nstatic void evlist__munmap_nofree(struct evlist *evlist)\n{\n\tint i;\n\n\tif (evlist->mmap)\n\t\tfor (i = 0; i < evlist->core.nr_mmaps; i++)\n\t\t\tperf_mmap__munmap(&evlist->mmap[i].core);\n\n\tif (evlist->overwrite_mmap)\n\t\tfor (i = 0; i < evlist->core.nr_mmaps; i++)\n\t\t\tperf_mmap__munmap(&evlist->overwrite_mmap[i].core);\n}\n\nvoid evlist__munmap(struct evlist *evlist)\n{\n\tevlist__munmap_nofree(evlist);\n\tzfree(&evlist->mmap);\n\tzfree(&evlist->overwrite_mmap);\n}\n\nstatic void perf_mmap__unmap_cb(struct perf_mmap *map)\n{\n\tstruct mmap *m = container_of(map, struct mmap, core);\n\n\tmmap__munmap(m);\n}\n\nstatic struct mmap *evlist__alloc_mmap(struct evlist *evlist,\n\t\t\t\t       bool overwrite)\n{\n\tint i;\n\tstruct mmap *map;\n\n\tmap = zalloc(evlist->core.nr_mmaps * sizeof(struct mmap));\n\tif (!map)\n\t\treturn NULL;\n\n\tfor (i = 0; i < evlist->core.nr_mmaps; i++) {\n\t\tstruct perf_mmap *prev = i ? &map[i - 1].core : NULL;\n\n\t\t \n\t\tperf_mmap__init(&map[i].core, prev, overwrite, perf_mmap__unmap_cb);\n\t}\n\n\treturn map;\n}\n\nstatic void\nperf_evlist__mmap_cb_idx(struct perf_evlist *_evlist,\n\t\t\t struct perf_evsel *_evsel,\n\t\t\t struct perf_mmap_param *_mp,\n\t\t\t int idx)\n{\n\tstruct evlist *evlist = container_of(_evlist, struct evlist, core);\n\tstruct mmap_params *mp = container_of(_mp, struct mmap_params, core);\n\tstruct evsel *evsel = container_of(_evsel, struct evsel, core);\n\n\tauxtrace_mmap_params__set_idx(&mp->auxtrace_mp, evlist, evsel, idx);\n}\n\nstatic struct perf_mmap*\nperf_evlist__mmap_cb_get(struct perf_evlist *_evlist, bool overwrite, int idx)\n{\n\tstruct evlist *evlist = container_of(_evlist, struct evlist, core);\n\tstruct mmap *maps;\n\n\tmaps = overwrite ? evlist->overwrite_mmap : evlist->mmap;\n\n\tif (!maps) {\n\t\tmaps = evlist__alloc_mmap(evlist, overwrite);\n\t\tif (!maps)\n\t\t\treturn NULL;\n\n\t\tif (overwrite) {\n\t\t\tevlist->overwrite_mmap = maps;\n\t\t\tif (evlist->bkw_mmap_state == BKW_MMAP_NOTREADY)\n\t\t\t\tevlist__toggle_bkw_mmap(evlist, BKW_MMAP_RUNNING);\n\t\t} else {\n\t\t\tevlist->mmap = maps;\n\t\t}\n\t}\n\n\treturn &maps[idx].core;\n}\n\nstatic int\nperf_evlist__mmap_cb_mmap(struct perf_mmap *_map, struct perf_mmap_param *_mp,\n\t\t\t  int output, struct perf_cpu cpu)\n{\n\tstruct mmap *map = container_of(_map, struct mmap, core);\n\tstruct mmap_params *mp = container_of(_mp, struct mmap_params, core);\n\n\treturn mmap__mmap(map, mp, output, cpu);\n}\n\nunsigned long perf_event_mlock_kb_in_pages(void)\n{\n\tunsigned long pages;\n\tint max;\n\n\tif (sysctl__read_int(\"kernel/perf_event_mlock_kb\", &max) < 0) {\n\t\t \n\t\tmax = 512;\n\t} else {\n\t\tmax -= (page_size / 1024);\n\t}\n\n\tpages = (max * 1024) / page_size;\n\tif (!is_power_of_2(pages))\n\t\tpages = rounddown_pow_of_two(pages);\n\n\treturn pages;\n}\n\nsize_t evlist__mmap_size(unsigned long pages)\n{\n\tif (pages == UINT_MAX)\n\t\tpages = perf_event_mlock_kb_in_pages();\n\telse if (!is_power_of_2(pages))\n\t\treturn 0;\n\n\treturn (pages + 1) * page_size;\n}\n\nstatic long parse_pages_arg(const char *str, unsigned long min,\n\t\t\t    unsigned long max)\n{\n\tunsigned long pages, val;\n\tstatic struct parse_tag tags[] = {\n\t\t{ .tag  = 'B', .mult = 1       },\n\t\t{ .tag  = 'K', .mult = 1 << 10 },\n\t\t{ .tag  = 'M', .mult = 1 << 20 },\n\t\t{ .tag  = 'G', .mult = 1 << 30 },\n\t\t{ .tag  = 0 },\n\t};\n\n\tif (str == NULL)\n\t\treturn -EINVAL;\n\n\tval = parse_tag_value(str, tags);\n\tif (val != (unsigned long) -1) {\n\t\t \n\t\tpages = PERF_ALIGN(val, page_size) / page_size;\n\t} else {\n\t\t \n\t\tchar *eptr;\n\t\tpages = strtoul(str, &eptr, 10);\n\t\tif (*eptr != '\\0')\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (pages == 0 && min == 0) {\n\t\t \n\t} else if (!is_power_of_2(pages)) {\n\t\tchar buf[100];\n\n\t\t \n\t\tpages = roundup_pow_of_two(pages);\n\t\tif (!pages)\n\t\t\treturn -EINVAL;\n\n\t\tunit_number__scnprintf(buf, sizeof(buf), pages * page_size);\n\t\tpr_info(\"rounding mmap pages size to %s (%lu pages)\\n\",\n\t\t\tbuf, pages);\n\t}\n\n\tif (pages > max)\n\t\treturn -EINVAL;\n\n\treturn pages;\n}\n\nint __evlist__parse_mmap_pages(unsigned int *mmap_pages, const char *str)\n{\n\tunsigned long max = UINT_MAX;\n\tlong pages;\n\n\tif (max > SIZE_MAX / page_size)\n\t\tmax = SIZE_MAX / page_size;\n\n\tpages = parse_pages_arg(str, 1, max);\n\tif (pages < 0) {\n\t\tpr_err(\"Invalid argument for --mmap_pages/-m\\n\");\n\t\treturn -1;\n\t}\n\n\t*mmap_pages = pages;\n\treturn 0;\n}\n\nint evlist__parse_mmap_pages(const struct option *opt, const char *str, int unset __maybe_unused)\n{\n\treturn __evlist__parse_mmap_pages(opt->value, str);\n}\n\n \nint evlist__mmap_ex(struct evlist *evlist, unsigned int pages,\n\t\t\t unsigned int auxtrace_pages,\n\t\t\t bool auxtrace_overwrite, int nr_cblocks, int affinity, int flush,\n\t\t\t int comp_level)\n{\n\t \n\tstruct mmap_params mp = {\n\t\t.nr_cblocks\t= nr_cblocks,\n\t\t.affinity\t= affinity,\n\t\t.flush\t\t= flush,\n\t\t.comp_level\t= comp_level\n\t};\n\tstruct perf_evlist_mmap_ops ops = {\n\t\t.idx  = perf_evlist__mmap_cb_idx,\n\t\t.get  = perf_evlist__mmap_cb_get,\n\t\t.mmap = perf_evlist__mmap_cb_mmap,\n\t};\n\n\tevlist->core.mmap_len = evlist__mmap_size(pages);\n\tpr_debug(\"mmap size %zuB\\n\", evlist->core.mmap_len);\n\n\tauxtrace_mmap_params__init(&mp.auxtrace_mp, evlist->core.mmap_len,\n\t\t\t\t   auxtrace_pages, auxtrace_overwrite);\n\n\treturn perf_evlist__mmap_ops(&evlist->core, &ops, &mp.core);\n}\n\nint evlist__mmap(struct evlist *evlist, unsigned int pages)\n{\n\treturn evlist__mmap_ex(evlist, pages, 0, false, 0, PERF_AFFINITY_SYS, 1, 0);\n}\n\nint evlist__create_maps(struct evlist *evlist, struct target *target)\n{\n\tbool all_threads = (target->per_thread && target->system_wide);\n\tstruct perf_cpu_map *cpus;\n\tstruct perf_thread_map *threads;\n\n\t \n\tthreads = thread_map__new_str(target->pid, target->tid, target->uid,\n\t\t\t\t      all_threads);\n\n\tif (!threads)\n\t\treturn -1;\n\n\tif (target__uses_dummy_map(target))\n\t\tcpus = perf_cpu_map__dummy_new();\n\telse\n\t\tcpus = perf_cpu_map__new(target->cpu_list);\n\n\tif (!cpus)\n\t\tgoto out_delete_threads;\n\n\tevlist->core.has_user_cpus = !!target->cpu_list;\n\n\tperf_evlist__set_maps(&evlist->core, cpus, threads);\n\n\t \n\tperf_cpu_map__put(cpus);\n\tperf_thread_map__put(threads);\n\n\treturn 0;\n\nout_delete_threads:\n\tperf_thread_map__put(threads);\n\treturn -1;\n}\n\nint evlist__apply_filters(struct evlist *evlist, struct evsel **err_evsel)\n{\n\tstruct evsel *evsel;\n\tint err = 0;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\t \n\t\tif (evsel->filter) {\n\t\t\terr = perf_evsel__apply_filter(&evsel->core, evsel->filter);\n\t\t\tif (err) {\n\t\t\t\t*err_evsel = evsel;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (!list_empty(&evsel->bpf_filters)) {\n\t\t\terr = perf_bpf_filter__prepare(evsel);\n\t\t\tif (err) {\n\t\t\t\t*err_evsel = evsel;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn err;\n}\n\nint evlist__set_tp_filter(struct evlist *evlist, const char *filter)\n{\n\tstruct evsel *evsel;\n\tint err = 0;\n\n\tif (filter == NULL)\n\t\treturn -1;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.type != PERF_TYPE_TRACEPOINT)\n\t\t\tcontinue;\n\n\t\terr = evsel__set_filter(evsel, filter);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nint evlist__append_tp_filter(struct evlist *evlist, const char *filter)\n{\n\tstruct evsel *evsel;\n\tint err = 0;\n\n\tif (filter == NULL)\n\t\treturn -1;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.type != PERF_TYPE_TRACEPOINT)\n\t\t\tcontinue;\n\n\t\terr = evsel__append_tp_filter(evsel, filter);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nchar *asprintf__tp_filter_pids(size_t npids, pid_t *pids)\n{\n\tchar *filter;\n\tsize_t i;\n\n\tfor (i = 0; i < npids; ++i) {\n\t\tif (i == 0) {\n\t\t\tif (asprintf(&filter, \"common_pid != %d\", pids[i]) < 0)\n\t\t\t\treturn NULL;\n\t\t} else {\n\t\t\tchar *tmp;\n\n\t\t\tif (asprintf(&tmp, \"%s && common_pid != %d\", filter, pids[i]) < 0)\n\t\t\t\tgoto out_free;\n\n\t\t\tfree(filter);\n\t\t\tfilter = tmp;\n\t\t}\n\t}\n\n\treturn filter;\nout_free:\n\tfree(filter);\n\treturn NULL;\n}\n\nint evlist__set_tp_filter_pids(struct evlist *evlist, size_t npids, pid_t *pids)\n{\n\tchar *filter = asprintf__tp_filter_pids(npids, pids);\n\tint ret = evlist__set_tp_filter(evlist, filter);\n\n\tfree(filter);\n\treturn ret;\n}\n\nint evlist__set_tp_filter_pid(struct evlist *evlist, pid_t pid)\n{\n\treturn evlist__set_tp_filter_pids(evlist, 1, &pid);\n}\n\nint evlist__append_tp_filter_pids(struct evlist *evlist, size_t npids, pid_t *pids)\n{\n\tchar *filter = asprintf__tp_filter_pids(npids, pids);\n\tint ret = evlist__append_tp_filter(evlist, filter);\n\n\tfree(filter);\n\treturn ret;\n}\n\nint evlist__append_tp_filter_pid(struct evlist *evlist, pid_t pid)\n{\n\treturn evlist__append_tp_filter_pids(evlist, 1, &pid);\n}\n\nbool evlist__valid_sample_type(struct evlist *evlist)\n{\n\tstruct evsel *pos;\n\n\tif (evlist->core.nr_entries == 1)\n\t\treturn true;\n\n\tif (evlist->id_pos < 0 || evlist->is_pos < 0)\n\t\treturn false;\n\n\tevlist__for_each_entry(evlist, pos) {\n\t\tif (pos->id_pos != evlist->id_pos ||\n\t\t    pos->is_pos != evlist->is_pos)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nu64 __evlist__combined_sample_type(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\n\tif (evlist->combined_sample_type)\n\t\treturn evlist->combined_sample_type;\n\n\tevlist__for_each_entry(evlist, evsel)\n\t\tevlist->combined_sample_type |= evsel->core.attr.sample_type;\n\n\treturn evlist->combined_sample_type;\n}\n\nu64 evlist__combined_sample_type(struct evlist *evlist)\n{\n\tevlist->combined_sample_type = 0;\n\treturn __evlist__combined_sample_type(evlist);\n}\n\nu64 evlist__combined_branch_type(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tu64 branch_type = 0;\n\n\tevlist__for_each_entry(evlist, evsel)\n\t\tbranch_type |= evsel->core.attr.branch_sample_type;\n\treturn branch_type;\n}\n\nbool evlist__valid_read_format(struct evlist *evlist)\n{\n\tstruct evsel *first = evlist__first(evlist), *pos = first;\n\tu64 read_format = first->core.attr.read_format;\n\tu64 sample_type = first->core.attr.sample_type;\n\n\tevlist__for_each_entry(evlist, pos) {\n\t\tif (read_format != pos->core.attr.read_format) {\n\t\t\tpr_debug(\"Read format differs %#\" PRIx64 \" vs %#\" PRIx64 \"\\n\",\n\t\t\t\t read_format, (u64)pos->core.attr.read_format);\n\t\t}\n\t}\n\n\t \n\tif ((sample_type & PERF_SAMPLE_READ) &&\n\t    !(read_format & PERF_FORMAT_ID)) {\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nu16 evlist__id_hdr_size(struct evlist *evlist)\n{\n\tstruct evsel *first = evlist__first(evlist);\n\n\treturn first->core.attr.sample_id_all ? evsel__id_hdr_size(first) : 0;\n}\n\nbool evlist__valid_sample_id_all(struct evlist *evlist)\n{\n\tstruct evsel *first = evlist__first(evlist), *pos = first;\n\n\tevlist__for_each_entry_continue(evlist, pos) {\n\t\tif (first->core.attr.sample_id_all != pos->core.attr.sample_id_all)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nbool evlist__sample_id_all(struct evlist *evlist)\n{\n\tstruct evsel *first = evlist__first(evlist);\n\treturn first->core.attr.sample_id_all;\n}\n\nvoid evlist__set_selected(struct evlist *evlist, struct evsel *evsel)\n{\n\tevlist->selected = evsel;\n}\n\nvoid evlist__close(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tstruct evlist_cpu_iterator evlist_cpu_itr;\n\tstruct affinity affinity;\n\n\t \n\tif (!evlist->core.user_requested_cpus ||\n\t    cpu_map__is_dummy(evlist->core.user_requested_cpus)) {\n\t\tevlist__for_each_entry_reverse(evlist, evsel)\n\t\t\tevsel__close(evsel);\n\t\treturn;\n\t}\n\n\tif (affinity__setup(&affinity) < 0)\n\t\treturn;\n\n\tevlist__for_each_cpu(evlist_cpu_itr, evlist, &affinity) {\n\t\tperf_evsel__close_cpu(&evlist_cpu_itr.evsel->core,\n\t\t\t\t      evlist_cpu_itr.cpu_map_idx);\n\t}\n\n\taffinity__cleanup(&affinity);\n\tevlist__for_each_entry_reverse(evlist, evsel) {\n\t\tperf_evsel__free_fd(&evsel->core);\n\t\tperf_evsel__free_id(&evsel->core);\n\t}\n\tperf_evlist__reset_id_hash(&evlist->core);\n}\n\nstatic int evlist__create_syswide_maps(struct evlist *evlist)\n{\n\tstruct perf_cpu_map *cpus;\n\tstruct perf_thread_map *threads;\n\n\t \n\tcpus = perf_cpu_map__new(NULL);\n\tif (!cpus)\n\t\tgoto out;\n\n\tthreads = perf_thread_map__new_dummy();\n\tif (!threads)\n\t\tgoto out_put;\n\n\tperf_evlist__set_maps(&evlist->core, cpus, threads);\n\n\tperf_thread_map__put(threads);\nout_put:\n\tperf_cpu_map__put(cpus);\nout:\n\treturn -ENOMEM;\n}\n\nint evlist__open(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tint err;\n\n\t \n\tif (evlist->core.threads == NULL && evlist->core.user_requested_cpus == NULL) {\n\t\terr = evlist__create_syswide_maps(evlist);\n\t\tif (err < 0)\n\t\t\tgoto out_err;\n\t}\n\n\tevlist__update_id_pos(evlist);\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\terr = evsel__open(evsel, evsel->core.cpus, evsel->core.threads);\n\t\tif (err < 0)\n\t\t\tgoto out_err;\n\t}\n\n\treturn 0;\nout_err:\n\tevlist__close(evlist);\n\terrno = -err;\n\treturn err;\n}\n\nint evlist__prepare_workload(struct evlist *evlist, struct target *target, const char *argv[],\n\t\t\t     bool pipe_output, void (*exec_error)(int signo, siginfo_t *info, void *ucontext))\n{\n\tint child_ready_pipe[2], go_pipe[2];\n\tchar bf;\n\n\tif (pipe(child_ready_pipe) < 0) {\n\t\tperror(\"failed to create 'ready' pipe\");\n\t\treturn -1;\n\t}\n\n\tif (pipe(go_pipe) < 0) {\n\t\tperror(\"failed to create 'go' pipe\");\n\t\tgoto out_close_ready_pipe;\n\t}\n\n\tevlist->workload.pid = fork();\n\tif (evlist->workload.pid < 0) {\n\t\tperror(\"failed to fork\");\n\t\tgoto out_close_pipes;\n\t}\n\n\tif (!evlist->workload.pid) {\n\t\tint ret;\n\n\t\tif (pipe_output)\n\t\t\tdup2(2, 1);\n\n\t\tsignal(SIGTERM, SIG_DFL);\n\n\t\tclose(child_ready_pipe[0]);\n\t\tclose(go_pipe[1]);\n\t\tfcntl(go_pipe[0], F_SETFD, FD_CLOEXEC);\n\n\t\t \n\t\tprctl(PR_SET_NAME, \"perf-exec\");\n\n\t\t \n\t\tclose(child_ready_pipe[1]);\n\n\t\t \n\t\tret = read(go_pipe[0], &bf, 1);\n\t\t \n\t\tif (ret != 1) {\n\t\t\tif (ret == -1)\n\t\t\t\tperror(\"unable to read pipe\");\n\t\t\texit(ret);\n\t\t}\n\n\t\texecvp(argv[0], (char **)argv);\n\n\t\tif (exec_error) {\n\t\t\tunion sigval val;\n\n\t\t\tval.sival_int = errno;\n\t\t\tif (sigqueue(getppid(), SIGUSR1, val))\n\t\t\t\tperror(argv[0]);\n\t\t} else\n\t\t\tperror(argv[0]);\n\t\texit(-1);\n\t}\n\n\tif (exec_error) {\n\t\tstruct sigaction act = {\n\t\t\t.sa_flags     = SA_SIGINFO,\n\t\t\t.sa_sigaction = exec_error,\n\t\t};\n\t\tsigaction(SIGUSR1, &act, NULL);\n\t}\n\n\tif (target__none(target)) {\n\t\tif (evlist->core.threads == NULL) {\n\t\t\tfprintf(stderr, \"FATAL: evlist->threads need to be set at this point (%s:%d).\\n\",\n\t\t\t\t__func__, __LINE__);\n\t\t\tgoto out_close_pipes;\n\t\t}\n\t\tperf_thread_map__set_pid(evlist->core.threads, 0, evlist->workload.pid);\n\t}\n\n\tclose(child_ready_pipe[1]);\n\tclose(go_pipe[0]);\n\t \n\tif (read(child_ready_pipe[0], &bf, 1) == -1) {\n\t\tperror(\"unable to read pipe\");\n\t\tgoto out_close_pipes;\n\t}\n\n\tfcntl(go_pipe[1], F_SETFD, FD_CLOEXEC);\n\tevlist->workload.cork_fd = go_pipe[1];\n\tclose(child_ready_pipe[0]);\n\treturn 0;\n\nout_close_pipes:\n\tclose(go_pipe[0]);\n\tclose(go_pipe[1]);\nout_close_ready_pipe:\n\tclose(child_ready_pipe[0]);\n\tclose(child_ready_pipe[1]);\n\treturn -1;\n}\n\nint evlist__start_workload(struct evlist *evlist)\n{\n\tif (evlist->workload.cork_fd > 0) {\n\t\tchar bf = 0;\n\t\tint ret;\n\t\t \n\t\tret = write(evlist->workload.cork_fd, &bf, 1);\n\t\tif (ret < 0)\n\t\t\tperror(\"unable to write to pipe\");\n\n\t\tclose(evlist->workload.cork_fd);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint evlist__parse_sample(struct evlist *evlist, union perf_event *event, struct perf_sample *sample)\n{\n\tstruct evsel *evsel = evlist__event2evsel(evlist, event);\n\tint ret;\n\n\tif (!evsel)\n\t\treturn -EFAULT;\n\tret = evsel__parse_sample(evsel, event, sample);\n\tif (ret)\n\t\treturn ret;\n\tif (perf_guest && sample->id) {\n\t\tstruct perf_sample_id *sid = evlist__id2sid(evlist, sample->id);\n\n\t\tif (sid) {\n\t\t\tsample->machine_pid = sid->machine_pid;\n\t\t\tsample->vcpu = sid->vcpu.cpu;\n\t\t}\n\t}\n\treturn 0;\n}\n\nint evlist__parse_sample_timestamp(struct evlist *evlist, union perf_event *event, u64 *timestamp)\n{\n\tstruct evsel *evsel = evlist__event2evsel(evlist, event);\n\n\tif (!evsel)\n\t\treturn -EFAULT;\n\treturn evsel__parse_sample_timestamp(evsel, event, timestamp);\n}\n\nint evlist__strerror_open(struct evlist *evlist, int err, char *buf, size_t size)\n{\n\tint printed, value;\n\tchar sbuf[STRERR_BUFSIZE], *emsg = str_error_r(err, sbuf, sizeof(sbuf));\n\n\tswitch (err) {\n\tcase EACCES:\n\tcase EPERM:\n\t\tprinted = scnprintf(buf, size,\n\t\t\t\t    \"Error:\\t%s.\\n\"\n\t\t\t\t    \"Hint:\\tCheck /proc/sys/kernel/perf_event_paranoid setting.\", emsg);\n\n\t\tvalue = perf_event_paranoid();\n\n\t\tprinted += scnprintf(buf + printed, size - printed, \"\\nHint:\\t\");\n\n\t\tif (value >= 2) {\n\t\t\tprinted += scnprintf(buf + printed, size - printed,\n\t\t\t\t\t     \"For your workloads it needs to be <= 1\\nHint:\\t\");\n\t\t}\n\t\tprinted += scnprintf(buf + printed, size - printed,\n\t\t\t\t     \"For system wide tracing it needs to be set to -1.\\n\");\n\n\t\tprinted += scnprintf(buf + printed, size - printed,\n\t\t\t\t    \"Hint:\\tTry: 'sudo sh -c \\\"echo -1 > /proc/sys/kernel/perf_event_paranoid\\\"'\\n\"\n\t\t\t\t    \"Hint:\\tThe current value is %d.\", value);\n\t\tbreak;\n\tcase EINVAL: {\n\t\tstruct evsel *first = evlist__first(evlist);\n\t\tint max_freq;\n\n\t\tif (sysctl__read_int(\"kernel/perf_event_max_sample_rate\", &max_freq) < 0)\n\t\t\tgoto out_default;\n\n\t\tif (first->core.attr.sample_freq < (u64)max_freq)\n\t\t\tgoto out_default;\n\n\t\tprinted = scnprintf(buf, size,\n\t\t\t\t    \"Error:\\t%s.\\n\"\n\t\t\t\t    \"Hint:\\tCheck /proc/sys/kernel/perf_event_max_sample_rate.\\n\"\n\t\t\t\t    \"Hint:\\tThe current value is %d and %\" PRIu64 \" is being requested.\",\n\t\t\t\t    emsg, max_freq, first->core.attr.sample_freq);\n\t\tbreak;\n\t}\n\tdefault:\nout_default:\n\t\tscnprintf(buf, size, \"%s\", emsg);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nint evlist__strerror_mmap(struct evlist *evlist, int err, char *buf, size_t size)\n{\n\tchar sbuf[STRERR_BUFSIZE], *emsg = str_error_r(err, sbuf, sizeof(sbuf));\n\tint pages_attempted = evlist->core.mmap_len / 1024, pages_max_per_user, printed = 0;\n\n\tswitch (err) {\n\tcase EPERM:\n\t\tsysctl__read_int(\"kernel/perf_event_mlock_kb\", &pages_max_per_user);\n\t\tprinted += scnprintf(buf + printed, size - printed,\n\t\t\t\t     \"Error:\\t%s.\\n\"\n\t\t\t\t     \"Hint:\\tCheck /proc/sys/kernel/perf_event_mlock_kb (%d kB) setting.\\n\"\n\t\t\t\t     \"Hint:\\tTried using %zd kB.\\n\",\n\t\t\t\t     emsg, pages_max_per_user, pages_attempted);\n\n\t\tif (pages_attempted >= pages_max_per_user) {\n\t\t\tprinted += scnprintf(buf + printed, size - printed,\n\t\t\t\t\t     \"Hint:\\tTry 'sudo sh -c \\\"echo %d > /proc/sys/kernel/perf_event_mlock_kb\\\"', or\\n\",\n\t\t\t\t\t     pages_max_per_user + pages_attempted);\n\t\t}\n\n\t\tprinted += scnprintf(buf + printed, size - printed,\n\t\t\t\t     \"Hint:\\tTry using a smaller -m/--mmap-pages value.\");\n\t\tbreak;\n\tdefault:\n\t\tscnprintf(buf, size, \"%s\", emsg);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nvoid evlist__to_front(struct evlist *evlist, struct evsel *move_evsel)\n{\n\tstruct evsel *evsel, *n;\n\tLIST_HEAD(move);\n\n\tif (move_evsel == evlist__first(evlist))\n\t\treturn;\n\n\tevlist__for_each_entry_safe(evlist, n, evsel) {\n\t\tif (evsel__leader(evsel) == evsel__leader(move_evsel))\n\t\t\tlist_move_tail(&evsel->core.node, &move);\n\t}\n\n\tlist_splice(&move, &evlist->core.entries);\n}\n\nstruct evsel *evlist__get_tracking_event(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->tracking)\n\t\t\treturn evsel;\n\t}\n\n\treturn evlist__first(evlist);\n}\n\nvoid evlist__set_tracking_event(struct evlist *evlist, struct evsel *tracking_evsel)\n{\n\tstruct evsel *evsel;\n\n\tif (tracking_evsel->tracking)\n\t\treturn;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel != tracking_evsel)\n\t\t\tevsel->tracking = false;\n\t}\n\n\ttracking_evsel->tracking = true;\n}\n\nstruct evsel *evlist__find_evsel_by_str(struct evlist *evlist, const char *str)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (!evsel->name)\n\t\t\tcontinue;\n\t\tif (evsel__name_is(evsel, str))\n\t\t\treturn evsel;\n\t}\n\n\treturn NULL;\n}\n\nvoid evlist__toggle_bkw_mmap(struct evlist *evlist, enum bkw_mmap_state state)\n{\n\tenum bkw_mmap_state old_state = evlist->bkw_mmap_state;\n\tenum action {\n\t\tNONE,\n\t\tPAUSE,\n\t\tRESUME,\n\t} action = NONE;\n\n\tif (!evlist->overwrite_mmap)\n\t\treturn;\n\n\tswitch (old_state) {\n\tcase BKW_MMAP_NOTREADY: {\n\t\tif (state != BKW_MMAP_RUNNING)\n\t\t\tgoto state_err;\n\t\tbreak;\n\t}\n\tcase BKW_MMAP_RUNNING: {\n\t\tif (state != BKW_MMAP_DATA_PENDING)\n\t\t\tgoto state_err;\n\t\taction = PAUSE;\n\t\tbreak;\n\t}\n\tcase BKW_MMAP_DATA_PENDING: {\n\t\tif (state != BKW_MMAP_EMPTY)\n\t\t\tgoto state_err;\n\t\tbreak;\n\t}\n\tcase BKW_MMAP_EMPTY: {\n\t\tif (state != BKW_MMAP_RUNNING)\n\t\t\tgoto state_err;\n\t\taction = RESUME;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tWARN_ONCE(1, \"Shouldn't get there\\n\");\n\t}\n\n\tevlist->bkw_mmap_state = state;\n\n\tswitch (action) {\n\tcase PAUSE:\n\t\tevlist__pause(evlist);\n\t\tbreak;\n\tcase RESUME:\n\t\tevlist__resume(evlist);\n\t\tbreak;\n\tcase NONE:\n\tdefault:\n\t\tbreak;\n\t}\n\nstate_err:\n\treturn;\n}\n\nbool evlist__exclude_kernel(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (!evsel->core.attr.exclude_kernel)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nvoid evlist__force_leader(struct evlist *evlist)\n{\n\tif (evlist__nr_groups(evlist) == 0) {\n\t\tstruct evsel *leader = evlist__first(evlist);\n\n\t\tevlist__set_leader(evlist);\n\t\tleader->forced_leader = true;\n\t}\n}\n\nstruct evsel *evlist__reset_weak_group(struct evlist *evsel_list, struct evsel *evsel, bool close)\n{\n\tstruct evsel *c2, *leader;\n\tbool is_open = true;\n\n\tleader = evsel__leader(evsel);\n\n\tpr_debug(\"Weak group for %s/%d failed\\n\",\n\t\t\tleader->name, leader->core.nr_members);\n\n\t \n\tevlist__for_each_entry(evsel_list, c2) {\n\t\tif (c2 == evsel)\n\t\t\tis_open = false;\n\t\tif (evsel__has_leader(c2, leader)) {\n\t\t\tif (is_open && close)\n\t\t\t\tperf_evsel__close(&c2->core);\n\t\t\t \n\t\t\tevsel__remove_from_group(c2, leader);\n\n\t\t\t \n\t\t\tc2->reset_group = true;\n\t\t}\n\t}\n\t \n\tif (leader->core.nr_members == 1)\n\t\tleader->core.nr_members = 0;\n\treturn leader;\n}\n\nstatic int evlist__parse_control_fifo(const char *str, int *ctl_fd, int *ctl_fd_ack, bool *ctl_fd_close)\n{\n\tchar *s, *p;\n\tint ret = 0, fd;\n\n\tif (strncmp(str, \"fifo:\", 5))\n\t\treturn -EINVAL;\n\n\tstr += 5;\n\tif (!*str || *str == ',')\n\t\treturn -EINVAL;\n\n\ts = strdup(str);\n\tif (!s)\n\t\treturn -ENOMEM;\n\n\tp = strchr(s, ',');\n\tif (p)\n\t\t*p = '\\0';\n\n\t \n\tfd = open(s, O_RDWR | O_NONBLOCK | O_CLOEXEC);\n\tif (fd < 0) {\n\t\tpr_err(\"Failed to open '%s'\\n\", s);\n\t\tret = -errno;\n\t\tgoto out_free;\n\t}\n\t*ctl_fd = fd;\n\t*ctl_fd_close = true;\n\n\tif (p && *++p) {\n\t\t \n\t\tfd = open(p, O_RDWR | O_NONBLOCK | O_CLOEXEC);\n\t\tif (fd < 0) {\n\t\t\tpr_err(\"Failed to open '%s'\\n\", p);\n\t\t\tret = -errno;\n\t\t\tgoto out_free;\n\t\t}\n\t\t*ctl_fd_ack = fd;\n\t}\n\nout_free:\n\tfree(s);\n\treturn ret;\n}\n\nint evlist__parse_control(const char *str, int *ctl_fd, int *ctl_fd_ack, bool *ctl_fd_close)\n{\n\tchar *comma = NULL, *endptr = NULL;\n\n\t*ctl_fd_close = false;\n\n\tif (strncmp(str, \"fd:\", 3))\n\t\treturn evlist__parse_control_fifo(str, ctl_fd, ctl_fd_ack, ctl_fd_close);\n\n\t*ctl_fd = strtoul(&str[3], &endptr, 0);\n\tif (endptr == &str[3])\n\t\treturn -EINVAL;\n\n\tcomma = strchr(str, ',');\n\tif (comma) {\n\t\tif (endptr != comma)\n\t\t\treturn -EINVAL;\n\n\t\t*ctl_fd_ack = strtoul(comma + 1, &endptr, 0);\n\t\tif (endptr == comma + 1 || *endptr != '\\0')\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nvoid evlist__close_control(int ctl_fd, int ctl_fd_ack, bool *ctl_fd_close)\n{\n\tif (*ctl_fd_close) {\n\t\t*ctl_fd_close = false;\n\t\tclose(ctl_fd);\n\t\tif (ctl_fd_ack >= 0)\n\t\t\tclose(ctl_fd_ack);\n\t}\n}\n\nint evlist__initialize_ctlfd(struct evlist *evlist, int fd, int ack)\n{\n\tif (fd == -1) {\n\t\tpr_debug(\"Control descriptor is not initialized\\n\");\n\t\treturn 0;\n\t}\n\n\tevlist->ctl_fd.pos = perf_evlist__add_pollfd(&evlist->core, fd, NULL, POLLIN,\n\t\t\t\t\t\t     fdarray_flag__nonfilterable |\n\t\t\t\t\t\t     fdarray_flag__non_perf_event);\n\tif (evlist->ctl_fd.pos < 0) {\n\t\tevlist->ctl_fd.pos = -1;\n\t\tpr_err(\"Failed to add ctl fd entry: %m\\n\");\n\t\treturn -1;\n\t}\n\n\tevlist->ctl_fd.fd = fd;\n\tevlist->ctl_fd.ack = ack;\n\n\treturn 0;\n}\n\nbool evlist__ctlfd_initialized(struct evlist *evlist)\n{\n\treturn evlist->ctl_fd.pos >= 0;\n}\n\nint evlist__finalize_ctlfd(struct evlist *evlist)\n{\n\tstruct pollfd *entries = evlist->core.pollfd.entries;\n\n\tif (!evlist__ctlfd_initialized(evlist))\n\t\treturn 0;\n\n\tentries[evlist->ctl_fd.pos].fd = -1;\n\tentries[evlist->ctl_fd.pos].events = 0;\n\tentries[evlist->ctl_fd.pos].revents = 0;\n\n\tevlist->ctl_fd.pos = -1;\n\tevlist->ctl_fd.ack = -1;\n\tevlist->ctl_fd.fd = -1;\n\n\treturn 0;\n}\n\nstatic int evlist__ctlfd_recv(struct evlist *evlist, enum evlist_ctl_cmd *cmd,\n\t\t\t      char *cmd_data, size_t data_size)\n{\n\tint err;\n\tchar c;\n\tsize_t bytes_read = 0;\n\n\t*cmd = EVLIST_CTL_CMD_UNSUPPORTED;\n\tmemset(cmd_data, 0, data_size);\n\tdata_size--;\n\n\tdo {\n\t\terr = read(evlist->ctl_fd.fd, &c, 1);\n\t\tif (err > 0) {\n\t\t\tif (c == '\\n' || c == '\\0')\n\t\t\t\tbreak;\n\t\t\tcmd_data[bytes_read++] = c;\n\t\t\tif (bytes_read == data_size)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t} else if (err == -1) {\n\t\t\tif (errno == EINTR)\n\t\t\t\tcontinue;\n\t\t\tif (errno == EAGAIN || errno == EWOULDBLOCK)\n\t\t\t\terr = 0;\n\t\t\telse\n\t\t\t\tpr_err(\"Failed to read from ctlfd %d: %m\\n\", evlist->ctl_fd.fd);\n\t\t}\n\t\tbreak;\n\t} while (1);\n\n\tpr_debug(\"Message from ctl_fd: \\\"%s%s\\\"\\n\", cmd_data,\n\t\t bytes_read == data_size ? \"\" : c == '\\n' ? \"\\\\n\" : \"\\\\0\");\n\n\tif (bytes_read > 0) {\n\t\tif (!strncmp(cmd_data, EVLIST_CTL_CMD_ENABLE_TAG,\n\t\t\t     (sizeof(EVLIST_CTL_CMD_ENABLE_TAG)-1))) {\n\t\t\t*cmd = EVLIST_CTL_CMD_ENABLE;\n\t\t} else if (!strncmp(cmd_data, EVLIST_CTL_CMD_DISABLE_TAG,\n\t\t\t\t    (sizeof(EVLIST_CTL_CMD_DISABLE_TAG)-1))) {\n\t\t\t*cmd = EVLIST_CTL_CMD_DISABLE;\n\t\t} else if (!strncmp(cmd_data, EVLIST_CTL_CMD_SNAPSHOT_TAG,\n\t\t\t\t    (sizeof(EVLIST_CTL_CMD_SNAPSHOT_TAG)-1))) {\n\t\t\t*cmd = EVLIST_CTL_CMD_SNAPSHOT;\n\t\t\tpr_debug(\"is snapshot\\n\");\n\t\t} else if (!strncmp(cmd_data, EVLIST_CTL_CMD_EVLIST_TAG,\n\t\t\t\t    (sizeof(EVLIST_CTL_CMD_EVLIST_TAG)-1))) {\n\t\t\t*cmd = EVLIST_CTL_CMD_EVLIST;\n\t\t} else if (!strncmp(cmd_data, EVLIST_CTL_CMD_STOP_TAG,\n\t\t\t\t    (sizeof(EVLIST_CTL_CMD_STOP_TAG)-1))) {\n\t\t\t*cmd = EVLIST_CTL_CMD_STOP;\n\t\t} else if (!strncmp(cmd_data, EVLIST_CTL_CMD_PING_TAG,\n\t\t\t\t    (sizeof(EVLIST_CTL_CMD_PING_TAG)-1))) {\n\t\t\t*cmd = EVLIST_CTL_CMD_PING;\n\t\t}\n\t}\n\n\treturn bytes_read ? (int)bytes_read : err;\n}\n\nint evlist__ctlfd_ack(struct evlist *evlist)\n{\n\tint err;\n\n\tif (evlist->ctl_fd.ack == -1)\n\t\treturn 0;\n\n\terr = write(evlist->ctl_fd.ack, EVLIST_CTL_CMD_ACK_TAG,\n\t\t    sizeof(EVLIST_CTL_CMD_ACK_TAG));\n\tif (err == -1)\n\t\tpr_err(\"failed to write to ctl_ack_fd %d: %m\\n\", evlist->ctl_fd.ack);\n\n\treturn err;\n}\n\nstatic int get_cmd_arg(char *cmd_data, size_t cmd_size, char **arg)\n{\n\tchar *data = cmd_data + cmd_size;\n\n\t \n\tif (!*data)\n\t\treturn 0;\n\n\t \n\tif (*data == ' ') {\n\t\t*arg = data + 1;\n\t\treturn 1;\n\t}\n\n\t \n\treturn -1;\n}\n\nstatic int evlist__ctlfd_enable(struct evlist *evlist, char *cmd_data, bool enable)\n{\n\tstruct evsel *evsel;\n\tchar *name;\n\tint err;\n\n\terr = get_cmd_arg(cmd_data,\n\t\t\t  enable ? sizeof(EVLIST_CTL_CMD_ENABLE_TAG) - 1 :\n\t\t\t\t   sizeof(EVLIST_CTL_CMD_DISABLE_TAG) - 1,\n\t\t\t  &name);\n\tif (err < 0) {\n\t\tpr_info(\"failed: wrong command\\n\");\n\t\treturn -1;\n\t}\n\n\tif (err) {\n\t\tevsel = evlist__find_evsel_by_str(evlist, name);\n\t\tif (evsel) {\n\t\t\tif (enable)\n\t\t\t\tevlist__enable_evsel(evlist, name);\n\t\t\telse\n\t\t\t\tevlist__disable_evsel(evlist, name);\n\t\t\tpr_info(\"Event %s %s\\n\", evsel->name,\n\t\t\t\tenable ? \"enabled\" : \"disabled\");\n\t\t} else {\n\t\t\tpr_info(\"failed: can't find '%s' event\\n\", name);\n\t\t}\n\t} else {\n\t\tif (enable) {\n\t\t\tevlist__enable(evlist);\n\t\t\tpr_info(EVLIST_ENABLED_MSG);\n\t\t} else {\n\t\t\tevlist__disable(evlist);\n\t\t\tpr_info(EVLIST_DISABLED_MSG);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int evlist__ctlfd_list(struct evlist *evlist, char *cmd_data)\n{\n\tstruct perf_attr_details details = { .verbose = false, };\n\tstruct evsel *evsel;\n\tchar *arg;\n\tint err;\n\n\terr = get_cmd_arg(cmd_data,\n\t\t\t  sizeof(EVLIST_CTL_CMD_EVLIST_TAG) - 1,\n\t\t\t  &arg);\n\tif (err < 0) {\n\t\tpr_info(\"failed: wrong command\\n\");\n\t\treturn -1;\n\t}\n\n\tif (err) {\n\t\tif (!strcmp(arg, \"-v\")) {\n\t\t\tdetails.verbose = true;\n\t\t} else if (!strcmp(arg, \"-g\")) {\n\t\t\tdetails.event_group = true;\n\t\t} else if (!strcmp(arg, \"-F\")) {\n\t\t\tdetails.freq = true;\n\t\t} else {\n\t\t\tpr_info(\"failed: wrong command\\n\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tevlist__for_each_entry(evlist, evsel)\n\t\tevsel__fprintf(evsel, &details, stderr);\n\n\treturn 0;\n}\n\nint evlist__ctlfd_process(struct evlist *evlist, enum evlist_ctl_cmd *cmd)\n{\n\tint err = 0;\n\tchar cmd_data[EVLIST_CTL_CMD_MAX_LEN];\n\tint ctlfd_pos = evlist->ctl_fd.pos;\n\tstruct pollfd *entries = evlist->core.pollfd.entries;\n\n\tif (!evlist__ctlfd_initialized(evlist) || !entries[ctlfd_pos].revents)\n\t\treturn 0;\n\n\tif (entries[ctlfd_pos].revents & POLLIN) {\n\t\terr = evlist__ctlfd_recv(evlist, cmd, cmd_data,\n\t\t\t\t\t EVLIST_CTL_CMD_MAX_LEN);\n\t\tif (err > 0) {\n\t\t\tswitch (*cmd) {\n\t\t\tcase EVLIST_CTL_CMD_ENABLE:\n\t\t\tcase EVLIST_CTL_CMD_DISABLE:\n\t\t\t\terr = evlist__ctlfd_enable(evlist, cmd_data,\n\t\t\t\t\t\t\t   *cmd == EVLIST_CTL_CMD_ENABLE);\n\t\t\t\tbreak;\n\t\t\tcase EVLIST_CTL_CMD_EVLIST:\n\t\t\t\terr = evlist__ctlfd_list(evlist, cmd_data);\n\t\t\t\tbreak;\n\t\t\tcase EVLIST_CTL_CMD_SNAPSHOT:\n\t\t\tcase EVLIST_CTL_CMD_STOP:\n\t\t\tcase EVLIST_CTL_CMD_PING:\n\t\t\t\tbreak;\n\t\t\tcase EVLIST_CTL_CMD_ACK:\n\t\t\tcase EVLIST_CTL_CMD_UNSUPPORTED:\n\t\t\tdefault:\n\t\t\t\tpr_debug(\"ctlfd: unsupported %d\\n\", *cmd);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!(*cmd == EVLIST_CTL_CMD_ACK || *cmd == EVLIST_CTL_CMD_UNSUPPORTED ||\n\t\t\t      *cmd == EVLIST_CTL_CMD_SNAPSHOT))\n\t\t\t\tevlist__ctlfd_ack(evlist);\n\t\t}\n\t}\n\n\tif (entries[ctlfd_pos].revents & (POLLHUP | POLLERR))\n\t\tevlist__finalize_ctlfd(evlist);\n\telse\n\t\tentries[ctlfd_pos].revents = 0;\n\n\treturn err;\n}\n\n \nstruct event_enable_time {\n\tint\tstart;\n\tint\tend;\n};\n\nstatic int parse_event_enable_time(const char *str, struct event_enable_time *range, bool first)\n{\n\tconst char *fmt = first ? \"%u - %u %n\" : \" , %u - %u %n\";\n\tint ret, start, end, n;\n\n\tret = sscanf(str, fmt, &start, &end, &n);\n\tif (ret != 2 || end <= start)\n\t\treturn -EINVAL;\n\tif (range) {\n\t\trange->start = start;\n\t\trange->end = end;\n\t}\n\treturn n;\n}\n\nstatic ssize_t parse_event_enable_times(const char *str, struct event_enable_time *range)\n{\n\tint incr = !!range;\n\tbool first = true;\n\tssize_t ret, cnt;\n\n\tfor (cnt = 0; *str; cnt++) {\n\t\tret = parse_event_enable_time(str, range, first);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\t \n\t\tif (!first && range && range->start <= range[-1].end)\n\t\t\treturn -EINVAL;\n\t\tstr += ret;\n\t\trange += incr;\n\t\tfirst = false;\n\t}\n\treturn cnt;\n}\n\n \nstruct event_enable_timer {\n\tstruct evlist *evlist;\n\tstruct event_enable_time *times;\n\tsize_t\ttimes_cnt;\n\tint\ttimerfd;\n\tint\tpollfd_pos;\n\tsize_t\ttimes_step;\n};\n\nstatic int str_to_delay(const char *str)\n{\n\tchar *endptr;\n\tlong d;\n\n\td = strtol(str, &endptr, 10);\n\tif (*endptr || d > INT_MAX || d < -1)\n\t\treturn 0;\n\treturn d;\n}\n\nint evlist__parse_event_enable_time(struct evlist *evlist, struct record_opts *opts,\n\t\t\t\t    const char *str, int unset)\n{\n\tenum fdarray_flags flags = fdarray_flag__nonfilterable | fdarray_flag__non_perf_event;\n\tstruct event_enable_timer *eet;\n\tssize_t times_cnt;\n\tssize_t ret;\n\tint err;\n\n\tif (unset)\n\t\treturn 0;\n\n\topts->target.initial_delay = str_to_delay(str);\n\tif (opts->target.initial_delay)\n\t\treturn 0;\n\n\tret = parse_event_enable_times(str, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttimes_cnt = ret;\n\tif (times_cnt == 0)\n\t\treturn -EINVAL;\n\n\teet = zalloc(sizeof(*eet));\n\tif (!eet)\n\t\treturn -ENOMEM;\n\n\teet->times = calloc(times_cnt, sizeof(*eet->times));\n\tif (!eet->times) {\n\t\terr = -ENOMEM;\n\t\tgoto free_eet;\n\t}\n\n\tif (parse_event_enable_times(str, eet->times) != times_cnt) {\n\t\terr = -EINVAL;\n\t\tgoto free_eet_times;\n\t}\n\n\teet->times_cnt = times_cnt;\n\n\teet->timerfd = timerfd_create(CLOCK_MONOTONIC, TFD_CLOEXEC);\n\tif (eet->timerfd == -1) {\n\t\terr = -errno;\n\t\tpr_err(\"timerfd_create failed: %s\\n\", strerror(errno));\n\t\tgoto free_eet_times;\n\t}\n\n\teet->pollfd_pos = perf_evlist__add_pollfd(&evlist->core, eet->timerfd, NULL, POLLIN, flags);\n\tif (eet->pollfd_pos < 0) {\n\t\terr = eet->pollfd_pos;\n\t\tgoto close_timerfd;\n\t}\n\n\teet->evlist = evlist;\n\tevlist->eet = eet;\n\topts->target.initial_delay = eet->times[0].start;\n\n\treturn 0;\n\nclose_timerfd:\n\tclose(eet->timerfd);\nfree_eet_times:\n\tzfree(&eet->times);\nfree_eet:\n\tfree(eet);\n\treturn err;\n}\n\nstatic int event_enable_timer__set_timer(struct event_enable_timer *eet, int ms)\n{\n\tstruct itimerspec its = {\n\t\t.it_value.tv_sec = ms / MSEC_PER_SEC,\n\t\t.it_value.tv_nsec = (ms % MSEC_PER_SEC) * NSEC_PER_MSEC,\n\t};\n\tint err = 0;\n\n\tif (timerfd_settime(eet->timerfd, 0, &its, NULL) < 0) {\n\t\terr = -errno;\n\t\tpr_err(\"timerfd_settime failed: %s\\n\", strerror(errno));\n\t}\n\treturn err;\n}\n\nint event_enable_timer__start(struct event_enable_timer *eet)\n{\n\tint ms;\n\n\tif (!eet)\n\t\treturn 0;\n\n\tms = eet->times[0].end - eet->times[0].start;\n\teet->times_step = 1;\n\n\treturn event_enable_timer__set_timer(eet, ms);\n}\n\nint event_enable_timer__process(struct event_enable_timer *eet)\n{\n\tstruct pollfd *entries;\n\tshort revents;\n\n\tif (!eet)\n\t\treturn 0;\n\n\tentries = eet->evlist->core.pollfd.entries;\n\trevents = entries[eet->pollfd_pos].revents;\n\tentries[eet->pollfd_pos].revents = 0;\n\n\tif (revents & POLLIN) {\n\t\tsize_t step = eet->times_step;\n\t\tsize_t pos = step / 2;\n\n\t\tif (step & 1) {\n\t\t\tevlist__disable_non_dummy(eet->evlist);\n\t\t\tpr_info(EVLIST_DISABLED_MSG);\n\t\t\tif (pos >= eet->times_cnt - 1) {\n\t\t\t\t \n\t\t\t\tevent_enable_timer__set_timer(eet, 0);\n\t\t\t\treturn 1;  \n\t\t\t}\n\t\t} else {\n\t\t\tevlist__enable_non_dummy(eet->evlist);\n\t\t\tpr_info(EVLIST_ENABLED_MSG);\n\t\t}\n\n\t\tstep += 1;\n\t\tpos = step / 2;\n\n\t\tif (pos < eet->times_cnt) {\n\t\t\tint *times = (int *)eet->times;  \n\t\t\tint ms = times[step] - times[step - 1];\n\n\t\t\teet->times_step = step;\n\t\t\treturn event_enable_timer__set_timer(eet, ms);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nvoid event_enable_timer__exit(struct event_enable_timer **ep)\n{\n\tif (!ep || !*ep)\n\t\treturn;\n\tzfree(&(*ep)->times);\n\tzfree(ep);\n}\n\nstruct evsel *evlist__find_evsel(struct evlist *evlist, int idx)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.idx == idx)\n\t\t\treturn evsel;\n\t}\n\treturn NULL;\n}\n\nint evlist__scnprintf_evsels(struct evlist *evlist, size_t size, char *bf)\n{\n\tstruct evsel *evsel;\n\tint printed = 0;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel__is_dummy_event(evsel))\n\t\t\tcontinue;\n\t\tif (size > (strlen(evsel__name(evsel)) + (printed ? 2 : 1))) {\n\t\t\tprinted += scnprintf(bf + printed, size - printed, \"%s%s\", printed ? \",\" : \"\", evsel__name(evsel));\n\t\t} else {\n\t\t\tprinted += scnprintf(bf + printed, size - printed, \"%s...\", printed ? \",\" : \"\");\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn printed;\n}\n\nvoid evlist__check_mem_load_aux(struct evlist *evlist)\n{\n\tstruct evsel *leader, *evsel, *pos;\n\n\t \n\tevlist__for_each_entry(evlist, evsel) {\n\t\tleader = evsel__leader(evsel);\n\t\tif (leader == evsel)\n\t\t\tcontinue;\n\n\t\tif (leader->name && strstr(leader->name, \"mem-loads-aux\")) {\n\t\t\tfor_each_group_evsel(pos, leader) {\n\t\t\t\tevsel__set_leader(pos, pos);\n\t\t\t\tpos->core.nr_members = 0;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nvoid evlist__warn_user_requested_cpus(struct evlist *evlist, const char *cpu_list)\n{\n\tstruct perf_cpu_map *user_requested_cpus;\n\tstruct evsel *pos;\n\n\tif (!cpu_list)\n\t\treturn;\n\n\tuser_requested_cpus = perf_cpu_map__new(cpu_list);\n\tif (!user_requested_cpus)\n\t\treturn;\n\n\tevlist__for_each_entry(evlist, pos) {\n\t\tstruct perf_cpu_map *intersect, *to_test;\n\t\tconst struct perf_pmu *pmu = evsel__find_pmu(pos);\n\n\t\tto_test = pmu && pmu->is_core ? pmu->cpus : cpu_map__online();\n\t\tintersect = perf_cpu_map__intersect(to_test, user_requested_cpus);\n\t\tif (!perf_cpu_map__equal(intersect, user_requested_cpus)) {\n\t\t\tchar buf[128];\n\n\t\t\tcpu_map__snprint(to_test, buf, sizeof(buf));\n\t\t\tpr_warning(\"WARNING: A requested CPU in '%s' is not supported by PMU '%s' (CPUs %s) for event '%s'\\n\",\n\t\t\t\tcpu_list, pmu ? pmu->name : \"cpu\", buf, evsel__name(pos));\n\t\t}\n\t\tperf_cpu_map__put(intersect);\n\t}\n\tperf_cpu_map__put(user_requested_cpus);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}