{
  "module_name": "auxtrace.c",
  "hash_id": "61c4c5f563ed96b92ab080137ec81a6225706f6682cd69a59d3dd6d8724a7e65",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/auxtrace.c",
  "human_readable_source": "\n \n\n#include <inttypes.h>\n#include <sys/types.h>\n#include <sys/mman.h>\n#include <stdbool.h>\n#include <string.h>\n#include <limits.h>\n#include <errno.h>\n\n#include <linux/kernel.h>\n#include <linux/perf_event.h>\n#include <linux/types.h>\n#include <linux/bitops.h>\n#include <linux/log2.h>\n#include <linux/string.h>\n#include <linux/time64.h>\n\n#include <sys/param.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <linux/list.h>\n#include <linux/zalloc.h>\n\n#include \"config.h\"\n#include \"evlist.h\"\n#include \"dso.h\"\n#include \"map.h\"\n#include \"pmu.h\"\n#include \"evsel.h\"\n#include \"evsel_config.h\"\n#include \"symbol.h\"\n#include \"util/perf_api_probe.h\"\n#include \"util/synthetic-events.h\"\n#include \"thread_map.h\"\n#include \"asm/bug.h\"\n#include \"auxtrace.h\"\n\n#include <linux/hash.h>\n\n#include \"event.h\"\n#include \"record.h\"\n#include \"session.h\"\n#include \"debug.h\"\n#include <subcmd/parse-options.h>\n\n#include \"cs-etm.h\"\n#include \"intel-pt.h\"\n#include \"intel-bts.h\"\n#include \"arm-spe.h\"\n#include \"hisi-ptt.h\"\n#include \"s390-cpumsf.h\"\n#include \"util/mmap.h\"\n\n#include <linux/ctype.h>\n#include \"symbol/kallsyms.h\"\n#include <internal/lib.h>\n#include \"util/sample.h\"\n\n \nstatic int evlist__regroup(struct evlist *evlist, struct evsel *leader, struct evsel *last)\n{\n\tstruct evsel *evsel;\n\tbool grp;\n\n\tif (!evsel__is_group_leader(leader))\n\t\treturn -EINVAL;\n\n\tgrp = false;\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (grp) {\n\t\t\tif (!(evsel__leader(evsel) == leader ||\n\t\t\t     (evsel__leader(evsel) == evsel &&\n\t\t\t      evsel->core.nr_members <= 1)))\n\t\t\t\treturn -EINVAL;\n\t\t} else if (evsel == leader) {\n\t\t\tgrp = true;\n\t\t}\n\t\tif (evsel == last)\n\t\t\tbreak;\n\t}\n\n\tgrp = false;\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (grp) {\n\t\t\tif (!evsel__has_leader(evsel, leader)) {\n\t\t\t\tevsel__set_leader(evsel, leader);\n\t\t\t\tif (leader->core.nr_members < 1)\n\t\t\t\t\tleader->core.nr_members = 1;\n\t\t\t\tleader->core.nr_members += 1;\n\t\t\t}\n\t\t} else if (evsel == leader) {\n\t\t\tgrp = true;\n\t\t}\n\t\tif (evsel == last)\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic bool auxtrace__dont_decode(struct perf_session *session)\n{\n\treturn !session->itrace_synth_opts ||\n\t       session->itrace_synth_opts->dont_decode;\n}\n\nint auxtrace_mmap__mmap(struct auxtrace_mmap *mm,\n\t\t\tstruct auxtrace_mmap_params *mp,\n\t\t\tvoid *userpg, int fd)\n{\n\tstruct perf_event_mmap_page *pc = userpg;\n\n\tWARN_ONCE(mm->base, \"Uninitialized auxtrace_mmap\\n\");\n\n\tmm->userpg = userpg;\n\tmm->mask = mp->mask;\n\tmm->len = mp->len;\n\tmm->prev = 0;\n\tmm->idx = mp->idx;\n\tmm->tid = mp->tid;\n\tmm->cpu = mp->cpu.cpu;\n\n\tif (!mp->len || !mp->mmap_needed) {\n\t\tmm->base = NULL;\n\t\treturn 0;\n\t}\n\n\tpc->aux_offset = mp->offset;\n\tpc->aux_size = mp->len;\n\n\tmm->base = mmap(NULL, mp->len, mp->prot, MAP_SHARED, fd, mp->offset);\n\tif (mm->base == MAP_FAILED) {\n\t\tpr_debug2(\"failed to mmap AUX area\\n\");\n\t\tmm->base = NULL;\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nvoid auxtrace_mmap__munmap(struct auxtrace_mmap *mm)\n{\n\tif (mm->base) {\n\t\tmunmap(mm->base, mm->len);\n\t\tmm->base = NULL;\n\t}\n}\n\nvoid auxtrace_mmap_params__init(struct auxtrace_mmap_params *mp,\n\t\t\t\toff_t auxtrace_offset,\n\t\t\t\tunsigned int auxtrace_pages,\n\t\t\t\tbool auxtrace_overwrite)\n{\n\tif (auxtrace_pages) {\n\t\tmp->offset = auxtrace_offset;\n\t\tmp->len = auxtrace_pages * (size_t)page_size;\n\t\tmp->mask = is_power_of_2(mp->len) ? mp->len - 1 : 0;\n\t\tmp->prot = PROT_READ | (auxtrace_overwrite ? 0 : PROT_WRITE);\n\t\tpr_debug2(\"AUX area mmap length %zu\\n\", mp->len);\n\t} else {\n\t\tmp->len = 0;\n\t}\n}\n\nvoid auxtrace_mmap_params__set_idx(struct auxtrace_mmap_params *mp,\n\t\t\t\t   struct evlist *evlist,\n\t\t\t\t   struct evsel *evsel, int idx)\n{\n\tbool per_cpu = !perf_cpu_map__empty(evlist->core.user_requested_cpus);\n\n\tmp->mmap_needed = evsel->needs_auxtrace_mmap;\n\n\tif (!mp->mmap_needed)\n\t\treturn;\n\n\tmp->idx = idx;\n\n\tif (per_cpu) {\n\t\tmp->cpu = perf_cpu_map__cpu(evlist->core.all_cpus, idx);\n\t\tif (evlist->core.threads)\n\t\t\tmp->tid = perf_thread_map__pid(evlist->core.threads, 0);\n\t\telse\n\t\t\tmp->tid = -1;\n\t} else {\n\t\tmp->cpu.cpu = -1;\n\t\tmp->tid = perf_thread_map__pid(evlist->core.threads, idx);\n\t}\n}\n\n#define AUXTRACE_INIT_NR_QUEUES\t32\n\nstatic struct auxtrace_queue *auxtrace_alloc_queue_array(unsigned int nr_queues)\n{\n\tstruct auxtrace_queue *queue_array;\n\tunsigned int max_nr_queues, i;\n\n\tmax_nr_queues = UINT_MAX / sizeof(struct auxtrace_queue);\n\tif (nr_queues > max_nr_queues)\n\t\treturn NULL;\n\n\tqueue_array = calloc(nr_queues, sizeof(struct auxtrace_queue));\n\tif (!queue_array)\n\t\treturn NULL;\n\n\tfor (i = 0; i < nr_queues; i++) {\n\t\tINIT_LIST_HEAD(&queue_array[i].head);\n\t\tqueue_array[i].priv = NULL;\n\t}\n\n\treturn queue_array;\n}\n\nint auxtrace_queues__init(struct auxtrace_queues *queues)\n{\n\tqueues->nr_queues = AUXTRACE_INIT_NR_QUEUES;\n\tqueues->queue_array = auxtrace_alloc_queue_array(queues->nr_queues);\n\tif (!queues->queue_array)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic int auxtrace_queues__grow(struct auxtrace_queues *queues,\n\t\t\t\t unsigned int new_nr_queues)\n{\n\tunsigned int nr_queues = queues->nr_queues;\n\tstruct auxtrace_queue *queue_array;\n\tunsigned int i;\n\n\tif (!nr_queues)\n\t\tnr_queues = AUXTRACE_INIT_NR_QUEUES;\n\n\twhile (nr_queues && nr_queues < new_nr_queues)\n\t\tnr_queues <<= 1;\n\n\tif (nr_queues < queues->nr_queues || nr_queues < new_nr_queues)\n\t\treturn -EINVAL;\n\n\tqueue_array = auxtrace_alloc_queue_array(nr_queues);\n\tif (!queue_array)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < queues->nr_queues; i++) {\n\t\tlist_splice_tail(&queues->queue_array[i].head,\n\t\t\t\t &queue_array[i].head);\n\t\tqueue_array[i].tid = queues->queue_array[i].tid;\n\t\tqueue_array[i].cpu = queues->queue_array[i].cpu;\n\t\tqueue_array[i].set = queues->queue_array[i].set;\n\t\tqueue_array[i].priv = queues->queue_array[i].priv;\n\t}\n\n\tqueues->nr_queues = nr_queues;\n\tqueues->queue_array = queue_array;\n\n\treturn 0;\n}\n\nstatic void *auxtrace_copy_data(u64 size, struct perf_session *session)\n{\n\tint fd = perf_data__fd(session->data);\n\tvoid *p;\n\tssize_t ret;\n\n\tif (size > SSIZE_MAX)\n\t\treturn NULL;\n\n\tp = malloc(size);\n\tif (!p)\n\t\treturn NULL;\n\n\tret = readn(fd, p, size);\n\tif (ret != (ssize_t)size) {\n\t\tfree(p);\n\t\treturn NULL;\n\t}\n\n\treturn p;\n}\n\nstatic int auxtrace_queues__queue_buffer(struct auxtrace_queues *queues,\n\t\t\t\t\t unsigned int idx,\n\t\t\t\t\t struct auxtrace_buffer *buffer)\n{\n\tstruct auxtrace_queue *queue;\n\tint err;\n\n\tif (idx >= queues->nr_queues) {\n\t\terr = auxtrace_queues__grow(queues, idx + 1);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tqueue = &queues->queue_array[idx];\n\n\tif (!queue->set) {\n\t\tqueue->set = true;\n\t\tqueue->tid = buffer->tid;\n\t\tqueue->cpu = buffer->cpu.cpu;\n\t}\n\n\tbuffer->buffer_nr = queues->next_buffer_nr++;\n\n\tlist_add_tail(&buffer->list, &queue->head);\n\n\tqueues->new_data = true;\n\tqueues->populated = true;\n\n\treturn 0;\n}\n\n \n#define BUFFER_LIMIT_FOR_32_BIT (32 * 1024 * 1024)\n\nstatic int auxtrace_queues__split_buffer(struct auxtrace_queues *queues,\n\t\t\t\t\t unsigned int idx,\n\t\t\t\t\t struct auxtrace_buffer *buffer)\n{\n\tu64 sz = buffer->size;\n\tbool consecutive = false;\n\tstruct auxtrace_buffer *b;\n\tint err;\n\n\twhile (sz > BUFFER_LIMIT_FOR_32_BIT) {\n\t\tb = memdup(buffer, sizeof(struct auxtrace_buffer));\n\t\tif (!b)\n\t\t\treturn -ENOMEM;\n\t\tb->size = BUFFER_LIMIT_FOR_32_BIT;\n\t\tb->consecutive = consecutive;\n\t\terr = auxtrace_queues__queue_buffer(queues, idx, b);\n\t\tif (err) {\n\t\t\tauxtrace_buffer__free(b);\n\t\t\treturn err;\n\t\t}\n\t\tbuffer->data_offset += BUFFER_LIMIT_FOR_32_BIT;\n\t\tsz -= BUFFER_LIMIT_FOR_32_BIT;\n\t\tconsecutive = true;\n\t}\n\n\tbuffer->size = sz;\n\tbuffer->consecutive = consecutive;\n\n\treturn 0;\n}\n\nstatic bool filter_cpu(struct perf_session *session, struct perf_cpu cpu)\n{\n\tunsigned long *cpu_bitmap = session->itrace_synth_opts->cpu_bitmap;\n\n\treturn cpu_bitmap && cpu.cpu != -1 && !test_bit(cpu.cpu, cpu_bitmap);\n}\n\nstatic int auxtrace_queues__add_buffer(struct auxtrace_queues *queues,\n\t\t\t\t       struct perf_session *session,\n\t\t\t\t       unsigned int idx,\n\t\t\t\t       struct auxtrace_buffer *buffer,\n\t\t\t\t       struct auxtrace_buffer **buffer_ptr)\n{\n\tint err = -ENOMEM;\n\n\tif (filter_cpu(session, buffer->cpu))\n\t\treturn 0;\n\n\tbuffer = memdup(buffer, sizeof(*buffer));\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\tif (session->one_mmap) {\n\t\tbuffer->data = buffer->data_offset - session->one_mmap_offset +\n\t\t\t       session->one_mmap_addr;\n\t} else if (perf_data__is_pipe(session->data)) {\n\t\tbuffer->data = auxtrace_copy_data(buffer->size, session);\n\t\tif (!buffer->data)\n\t\t\tgoto out_free;\n\t\tbuffer->data_needs_freeing = true;\n\t} else if (BITS_PER_LONG == 32 &&\n\t\t   buffer->size > BUFFER_LIMIT_FOR_32_BIT) {\n\t\terr = auxtrace_queues__split_buffer(queues, idx, buffer);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t}\n\n\terr = auxtrace_queues__queue_buffer(queues, idx, buffer);\n\tif (err)\n\t\tgoto out_free;\n\n\t \n\tif (buffer_ptr)\n\t\t*buffer_ptr = buffer;\n\n\treturn 0;\n\nout_free:\n\tauxtrace_buffer__free(buffer);\n\treturn err;\n}\n\nint auxtrace_queues__add_event(struct auxtrace_queues *queues,\n\t\t\t       struct perf_session *session,\n\t\t\t       union perf_event *event, off_t data_offset,\n\t\t\t       struct auxtrace_buffer **buffer_ptr)\n{\n\tstruct auxtrace_buffer buffer = {\n\t\t.pid = -1,\n\t\t.tid = event->auxtrace.tid,\n\t\t.cpu = { event->auxtrace.cpu },\n\t\t.data_offset = data_offset,\n\t\t.offset = event->auxtrace.offset,\n\t\t.reference = event->auxtrace.reference,\n\t\t.size = event->auxtrace.size,\n\t};\n\tunsigned int idx = event->auxtrace.idx;\n\n\treturn auxtrace_queues__add_buffer(queues, session, idx, &buffer,\n\t\t\t\t\t   buffer_ptr);\n}\n\nstatic int auxtrace_queues__add_indexed_event(struct auxtrace_queues *queues,\n\t\t\t\t\t      struct perf_session *session,\n\t\t\t\t\t      off_t file_offset, size_t sz)\n{\n\tunion perf_event *event;\n\tint err;\n\tchar buf[PERF_SAMPLE_MAX_SIZE];\n\n\terr = perf_session__peek_event(session, file_offset, buf,\n\t\t\t\t       PERF_SAMPLE_MAX_SIZE, &event, NULL);\n\tif (err)\n\t\treturn err;\n\n\tif (event->header.type == PERF_RECORD_AUXTRACE) {\n\t\tif (event->header.size < sizeof(struct perf_record_auxtrace) ||\n\t\t    event->header.size != sz) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tfile_offset += event->header.size;\n\t\terr = auxtrace_queues__add_event(queues, session, event,\n\t\t\t\t\t\t file_offset, NULL);\n\t}\nout:\n\treturn err;\n}\n\nvoid auxtrace_queues__free(struct auxtrace_queues *queues)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < queues->nr_queues; i++) {\n\t\twhile (!list_empty(&queues->queue_array[i].head)) {\n\t\t\tstruct auxtrace_buffer *buffer;\n\n\t\t\tbuffer = list_entry(queues->queue_array[i].head.next,\n\t\t\t\t\t    struct auxtrace_buffer, list);\n\t\t\tlist_del_init(&buffer->list);\n\t\t\tauxtrace_buffer__free(buffer);\n\t\t}\n\t}\n\n\tzfree(&queues->queue_array);\n\tqueues->nr_queues = 0;\n}\n\nstatic void auxtrace_heapify(struct auxtrace_heap_item *heap_array,\n\t\t\t     unsigned int pos, unsigned int queue_nr,\n\t\t\t     u64 ordinal)\n{\n\tunsigned int parent;\n\n\twhile (pos) {\n\t\tparent = (pos - 1) >> 1;\n\t\tif (heap_array[parent].ordinal <= ordinal)\n\t\t\tbreak;\n\t\theap_array[pos] = heap_array[parent];\n\t\tpos = parent;\n\t}\n\theap_array[pos].queue_nr = queue_nr;\n\theap_array[pos].ordinal = ordinal;\n}\n\nint auxtrace_heap__add(struct auxtrace_heap *heap, unsigned int queue_nr,\n\t\t       u64 ordinal)\n{\n\tstruct auxtrace_heap_item *heap_array;\n\n\tif (queue_nr >= heap->heap_sz) {\n\t\tunsigned int heap_sz = AUXTRACE_INIT_NR_QUEUES;\n\n\t\twhile (heap_sz <= queue_nr)\n\t\t\theap_sz <<= 1;\n\t\theap_array = realloc(heap->heap_array,\n\t\t\t\t     heap_sz * sizeof(struct auxtrace_heap_item));\n\t\tif (!heap_array)\n\t\t\treturn -ENOMEM;\n\t\theap->heap_array = heap_array;\n\t\theap->heap_sz = heap_sz;\n\t}\n\n\tauxtrace_heapify(heap->heap_array, heap->heap_cnt++, queue_nr, ordinal);\n\n\treturn 0;\n}\n\nvoid auxtrace_heap__free(struct auxtrace_heap *heap)\n{\n\tzfree(&heap->heap_array);\n\theap->heap_cnt = 0;\n\theap->heap_sz = 0;\n}\n\nvoid auxtrace_heap__pop(struct auxtrace_heap *heap)\n{\n\tunsigned int pos, last, heap_cnt = heap->heap_cnt;\n\tstruct auxtrace_heap_item *heap_array;\n\n\tif (!heap_cnt)\n\t\treturn;\n\n\theap->heap_cnt -= 1;\n\n\theap_array = heap->heap_array;\n\n\tpos = 0;\n\twhile (1) {\n\t\tunsigned int left, right;\n\n\t\tleft = (pos << 1) + 1;\n\t\tif (left >= heap_cnt)\n\t\t\tbreak;\n\t\tright = left + 1;\n\t\tif (right >= heap_cnt) {\n\t\t\theap_array[pos] = heap_array[left];\n\t\t\treturn;\n\t\t}\n\t\tif (heap_array[left].ordinal < heap_array[right].ordinal) {\n\t\t\theap_array[pos] = heap_array[left];\n\t\t\tpos = left;\n\t\t} else {\n\t\t\theap_array[pos] = heap_array[right];\n\t\t\tpos = right;\n\t\t}\n\t}\n\n\tlast = heap_cnt - 1;\n\tauxtrace_heapify(heap_array, pos, heap_array[last].queue_nr,\n\t\t\t heap_array[last].ordinal);\n}\n\nsize_t auxtrace_record__info_priv_size(struct auxtrace_record *itr,\n\t\t\t\t       struct evlist *evlist)\n{\n\tif (itr)\n\t\treturn itr->info_priv_size(itr, evlist);\n\treturn 0;\n}\n\nstatic int auxtrace_not_supported(void)\n{\n\tpr_err(\"AUX area tracing is not supported on this architecture\\n\");\n\treturn -EINVAL;\n}\n\nint auxtrace_record__info_fill(struct auxtrace_record *itr,\n\t\t\t       struct perf_session *session,\n\t\t\t       struct perf_record_auxtrace_info *auxtrace_info,\n\t\t\t       size_t priv_size)\n{\n\tif (itr)\n\t\treturn itr->info_fill(itr, session, auxtrace_info, priv_size);\n\treturn auxtrace_not_supported();\n}\n\nvoid auxtrace_record__free(struct auxtrace_record *itr)\n{\n\tif (itr)\n\t\titr->free(itr);\n}\n\nint auxtrace_record__snapshot_start(struct auxtrace_record *itr)\n{\n\tif (itr && itr->snapshot_start)\n\t\treturn itr->snapshot_start(itr);\n\treturn 0;\n}\n\nint auxtrace_record__snapshot_finish(struct auxtrace_record *itr, bool on_exit)\n{\n\tif (!on_exit && itr && itr->snapshot_finish)\n\t\treturn itr->snapshot_finish(itr);\n\treturn 0;\n}\n\nint auxtrace_record__find_snapshot(struct auxtrace_record *itr, int idx,\n\t\t\t\t   struct auxtrace_mmap *mm,\n\t\t\t\t   unsigned char *data, u64 *head, u64 *old)\n{\n\tif (itr && itr->find_snapshot)\n\t\treturn itr->find_snapshot(itr, idx, mm, data, head, old);\n\treturn 0;\n}\n\nint auxtrace_record__options(struct auxtrace_record *itr,\n\t\t\t     struct evlist *evlist,\n\t\t\t     struct record_opts *opts)\n{\n\tif (itr) {\n\t\titr->evlist = evlist;\n\t\treturn itr->recording_options(itr, evlist, opts);\n\t}\n\treturn 0;\n}\n\nu64 auxtrace_record__reference(struct auxtrace_record *itr)\n{\n\tif (itr)\n\t\treturn itr->reference(itr);\n\treturn 0;\n}\n\nint auxtrace_parse_snapshot_options(struct auxtrace_record *itr,\n\t\t\t\t    struct record_opts *opts, const char *str)\n{\n\tif (!str)\n\t\treturn 0;\n\n\t \n\tswitch (*str) {\n\tcase 'e':\n\t\topts->auxtrace_snapshot_on_exit = true;\n\t\tstr++;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (itr && itr->parse_snapshot_options)\n\t\treturn itr->parse_snapshot_options(itr, opts, str);\n\n\tpr_err(\"No AUX area tracing to snapshot\\n\");\n\treturn -EINVAL;\n}\n\nstatic int evlist__enable_event_idx(struct evlist *evlist, struct evsel *evsel, int idx)\n{\n\tbool per_cpu_mmaps = !perf_cpu_map__empty(evlist->core.user_requested_cpus);\n\n\tif (per_cpu_mmaps) {\n\t\tstruct perf_cpu evlist_cpu = perf_cpu_map__cpu(evlist->core.all_cpus, idx);\n\t\tint cpu_map_idx = perf_cpu_map__idx(evsel->core.cpus, evlist_cpu);\n\n\t\tif (cpu_map_idx == -1)\n\t\t\treturn -EINVAL;\n\t\treturn perf_evsel__enable_cpu(&evsel->core, cpu_map_idx);\n\t}\n\n\treturn perf_evsel__enable_thread(&evsel->core, idx);\n}\n\nint auxtrace_record__read_finish(struct auxtrace_record *itr, int idx)\n{\n\tstruct evsel *evsel;\n\n\tif (!itr->evlist || !itr->pmu)\n\t\treturn -EINVAL;\n\n\tevlist__for_each_entry(itr->evlist, evsel) {\n\t\tif (evsel->core.attr.type == itr->pmu->type) {\n\t\t\tif (evsel->disabled)\n\t\t\t\treturn 0;\n\t\t\treturn evlist__enable_event_idx(itr->evlist, evsel, idx);\n\t\t}\n\t}\n\treturn -EINVAL;\n}\n\n \n#define MAX_AUX_SAMPLE_SIZE (60 * 1024)\n\n \n#define DEFAULT_AUX_SAMPLE_SIZE (4 * 1024)\n\nstatic int auxtrace_validate_aux_sample_size(struct evlist *evlist,\n\t\t\t\t\t     struct record_opts *opts)\n{\n\tstruct evsel *evsel;\n\tbool has_aux_leader = false;\n\tu32 sz;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tsz = evsel->core.attr.aux_sample_size;\n\t\tif (evsel__is_group_leader(evsel)) {\n\t\t\thas_aux_leader = evsel__is_aux_event(evsel);\n\t\t\tif (sz) {\n\t\t\t\tif (has_aux_leader)\n\t\t\t\t\tpr_err(\"Cannot add AUX area sampling to an AUX area event\\n\");\n\t\t\t\telse\n\t\t\t\t\tpr_err(\"Cannot add AUX area sampling to a group leader\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t\tif (sz > MAX_AUX_SAMPLE_SIZE) {\n\t\t\tpr_err(\"AUX area sample size %u too big, max. %d\\n\",\n\t\t\t       sz, MAX_AUX_SAMPLE_SIZE);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (sz) {\n\t\t\tif (!has_aux_leader) {\n\t\t\t\tpr_err(\"Cannot add AUX area sampling because group leader is not an AUX area event\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tevsel__set_sample_bit(evsel, AUX);\n\t\t\topts->auxtrace_sample_mode = true;\n\t\t} else {\n\t\t\tevsel__reset_sample_bit(evsel, AUX);\n\t\t}\n\t}\n\n\tif (!opts->auxtrace_sample_mode) {\n\t\tpr_err(\"AUX area sampling requires an AUX area event group leader plus other events to which to add samples\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!perf_can_aux_sample()) {\n\t\tpr_err(\"AUX area sampling is not supported by kernel\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nint auxtrace_parse_sample_options(struct auxtrace_record *itr,\n\t\t\t\t  struct evlist *evlist,\n\t\t\t\t  struct record_opts *opts, const char *str)\n{\n\tstruct evsel_config_term *term;\n\tstruct evsel *aux_evsel;\n\tbool has_aux_sample_size = false;\n\tbool has_aux_leader = false;\n\tstruct evsel *evsel;\n\tchar *endptr;\n\tunsigned long sz;\n\n\tif (!str)\n\t\tgoto no_opt;\n\n\tif (!itr) {\n\t\tpr_err(\"No AUX area event to sample\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tsz = strtoul(str, &endptr, 0);\n\tif (*endptr || sz > UINT_MAX) {\n\t\tpr_err(\"Bad AUX area sampling option: '%s'\\n\", str);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!sz)\n\t\tsz = itr->default_aux_sample_size;\n\n\tif (!sz)\n\t\tsz = DEFAULT_AUX_SAMPLE_SIZE;\n\n\t \n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel__is_group_leader(evsel)) {\n\t\t\thas_aux_leader = evsel__is_aux_event(evsel);\n\t\t} else if (has_aux_leader) {\n\t\t\tevsel->core.attr.aux_sample_size = sz;\n\t\t}\n\t}\nno_opt:\n\taux_evsel = NULL;\n\t \n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel__is_aux_event(evsel))\n\t\t\taux_evsel = evsel;\n\t\tterm = evsel__get_config_term(evsel, AUX_SAMPLE_SIZE);\n\t\tif (term) {\n\t\t\thas_aux_sample_size = true;\n\t\t\tevsel->core.attr.aux_sample_size = term->val.aux_sample_size;\n\t\t\t \n\t\t\tif (aux_evsel && evsel->core.attr.aux_sample_size)\n\t\t\t\tevlist__regroup(evlist, aux_evsel, evsel);\n\t\t}\n\t}\n\n\tif (!str && !has_aux_sample_size)\n\t\treturn 0;\n\n\tif (!itr) {\n\t\tpr_err(\"No AUX area event to sample\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn auxtrace_validate_aux_sample_size(evlist, opts);\n}\n\nvoid auxtrace_regroup_aux_output(struct evlist *evlist)\n{\n\tstruct evsel *evsel, *aux_evsel = NULL;\n\tstruct evsel_config_term *term;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel__is_aux_event(evsel))\n\t\t\taux_evsel = evsel;\n\t\tterm = evsel__get_config_term(evsel, AUX_OUTPUT);\n\t\t \n\t\tif (term && aux_evsel)\n\t\t\tevlist__regroup(evlist, aux_evsel, evsel);\n\t}\n}\n\nstruct auxtrace_record *__weak\nauxtrace_record__init(struct evlist *evlist __maybe_unused, int *err)\n{\n\t*err = 0;\n\treturn NULL;\n}\n\nstatic int auxtrace_index__alloc(struct list_head *head)\n{\n\tstruct auxtrace_index *auxtrace_index;\n\n\tauxtrace_index = malloc(sizeof(struct auxtrace_index));\n\tif (!auxtrace_index)\n\t\treturn -ENOMEM;\n\n\tauxtrace_index->nr = 0;\n\tINIT_LIST_HEAD(&auxtrace_index->list);\n\n\tlist_add_tail(&auxtrace_index->list, head);\n\n\treturn 0;\n}\n\nvoid auxtrace_index__free(struct list_head *head)\n{\n\tstruct auxtrace_index *auxtrace_index, *n;\n\n\tlist_for_each_entry_safe(auxtrace_index, n, head, list) {\n\t\tlist_del_init(&auxtrace_index->list);\n\t\tfree(auxtrace_index);\n\t}\n}\n\nstatic struct auxtrace_index *auxtrace_index__last(struct list_head *head)\n{\n\tstruct auxtrace_index *auxtrace_index;\n\tint err;\n\n\tif (list_empty(head)) {\n\t\terr = auxtrace_index__alloc(head);\n\t\tif (err)\n\t\t\treturn NULL;\n\t}\n\n\tauxtrace_index = list_entry(head->prev, struct auxtrace_index, list);\n\n\tif (auxtrace_index->nr >= PERF_AUXTRACE_INDEX_ENTRY_COUNT) {\n\t\terr = auxtrace_index__alloc(head);\n\t\tif (err)\n\t\t\treturn NULL;\n\t\tauxtrace_index = list_entry(head->prev, struct auxtrace_index,\n\t\t\t\t\t    list);\n\t}\n\n\treturn auxtrace_index;\n}\n\nint auxtrace_index__auxtrace_event(struct list_head *head,\n\t\t\t\t   union perf_event *event, off_t file_offset)\n{\n\tstruct auxtrace_index *auxtrace_index;\n\tsize_t nr;\n\n\tauxtrace_index = auxtrace_index__last(head);\n\tif (!auxtrace_index)\n\t\treturn -ENOMEM;\n\n\tnr = auxtrace_index->nr;\n\tauxtrace_index->entries[nr].file_offset = file_offset;\n\tauxtrace_index->entries[nr].sz = event->header.size;\n\tauxtrace_index->nr += 1;\n\n\treturn 0;\n}\n\nstatic int auxtrace_index__do_write(int fd,\n\t\t\t\t    struct auxtrace_index *auxtrace_index)\n{\n\tstruct auxtrace_index_entry ent;\n\tsize_t i;\n\n\tfor (i = 0; i < auxtrace_index->nr; i++) {\n\t\tent.file_offset = auxtrace_index->entries[i].file_offset;\n\t\tent.sz = auxtrace_index->entries[i].sz;\n\t\tif (writen(fd, &ent, sizeof(ent)) != sizeof(ent))\n\t\t\treturn -errno;\n\t}\n\treturn 0;\n}\n\nint auxtrace_index__write(int fd, struct list_head *head)\n{\n\tstruct auxtrace_index *auxtrace_index;\n\tu64 total = 0;\n\tint err;\n\n\tlist_for_each_entry(auxtrace_index, head, list)\n\t\ttotal += auxtrace_index->nr;\n\n\tif (writen(fd, &total, sizeof(total)) != sizeof(total))\n\t\treturn -errno;\n\n\tlist_for_each_entry(auxtrace_index, head, list) {\n\t\terr = auxtrace_index__do_write(fd, auxtrace_index);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int auxtrace_index__process_entry(int fd, struct list_head *head,\n\t\t\t\t\t bool needs_swap)\n{\n\tstruct auxtrace_index *auxtrace_index;\n\tstruct auxtrace_index_entry ent;\n\tsize_t nr;\n\n\tif (readn(fd, &ent, sizeof(ent)) != sizeof(ent))\n\t\treturn -1;\n\n\tauxtrace_index = auxtrace_index__last(head);\n\tif (!auxtrace_index)\n\t\treturn -1;\n\n\tnr = auxtrace_index->nr;\n\tif (needs_swap) {\n\t\tauxtrace_index->entries[nr].file_offset =\n\t\t\t\t\t\tbswap_64(ent.file_offset);\n\t\tauxtrace_index->entries[nr].sz = bswap_64(ent.sz);\n\t} else {\n\t\tauxtrace_index->entries[nr].file_offset = ent.file_offset;\n\t\tauxtrace_index->entries[nr].sz = ent.sz;\n\t}\n\n\tauxtrace_index->nr = nr + 1;\n\n\treturn 0;\n}\n\nint auxtrace_index__process(int fd, u64 size, struct perf_session *session,\n\t\t\t    bool needs_swap)\n{\n\tstruct list_head *head = &session->auxtrace_index;\n\tu64 nr;\n\n\tif (readn(fd, &nr, sizeof(u64)) != sizeof(u64))\n\t\treturn -1;\n\n\tif (needs_swap)\n\t\tnr = bswap_64(nr);\n\n\tif (sizeof(u64) + nr * sizeof(struct auxtrace_index_entry) > size)\n\t\treturn -1;\n\n\twhile (nr--) {\n\t\tint err;\n\n\t\terr = auxtrace_index__process_entry(fd, head, needs_swap);\n\t\tif (err)\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic int auxtrace_queues__process_index_entry(struct auxtrace_queues *queues,\n\t\t\t\t\t\tstruct perf_session *session,\n\t\t\t\t\t\tstruct auxtrace_index_entry *ent)\n{\n\treturn auxtrace_queues__add_indexed_event(queues, session,\n\t\t\t\t\t\t  ent->file_offset, ent->sz);\n}\n\nint auxtrace_queues__process_index(struct auxtrace_queues *queues,\n\t\t\t\t   struct perf_session *session)\n{\n\tstruct auxtrace_index *auxtrace_index;\n\tstruct auxtrace_index_entry *ent;\n\tsize_t i;\n\tint err;\n\n\tif (auxtrace__dont_decode(session))\n\t\treturn 0;\n\n\tlist_for_each_entry(auxtrace_index, &session->auxtrace_index, list) {\n\t\tfor (i = 0; i < auxtrace_index->nr; i++) {\n\t\t\tent = &auxtrace_index->entries[i];\n\t\t\terr = auxtrace_queues__process_index_entry(queues,\n\t\t\t\t\t\t\t\t   session,\n\t\t\t\t\t\t\t\t   ent);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstruct auxtrace_buffer *auxtrace_buffer__next(struct auxtrace_queue *queue,\n\t\t\t\t\t      struct auxtrace_buffer *buffer)\n{\n\tif (buffer) {\n\t\tif (list_is_last(&buffer->list, &queue->head))\n\t\t\treturn NULL;\n\t\treturn list_entry(buffer->list.next, struct auxtrace_buffer,\n\t\t\t\t  list);\n\t} else {\n\t\tif (list_empty(&queue->head))\n\t\t\treturn NULL;\n\t\treturn list_entry(queue->head.next, struct auxtrace_buffer,\n\t\t\t\t  list);\n\t}\n}\n\nstruct auxtrace_queue *auxtrace_queues__sample_queue(struct auxtrace_queues *queues,\n\t\t\t\t\t\t     struct perf_sample *sample,\n\t\t\t\t\t\t     struct perf_session *session)\n{\n\tstruct perf_sample_id *sid;\n\tunsigned int idx;\n\tu64 id;\n\n\tid = sample->id;\n\tif (!id)\n\t\treturn NULL;\n\n\tsid = evlist__id2sid(session->evlist, id);\n\tif (!sid)\n\t\treturn NULL;\n\n\tidx = sid->idx;\n\n\tif (idx >= queues->nr_queues)\n\t\treturn NULL;\n\n\treturn &queues->queue_array[idx];\n}\n\nint auxtrace_queues__add_sample(struct auxtrace_queues *queues,\n\t\t\t\tstruct perf_session *session,\n\t\t\t\tstruct perf_sample *sample, u64 data_offset,\n\t\t\t\tu64 reference)\n{\n\tstruct auxtrace_buffer buffer = {\n\t\t.pid = -1,\n\t\t.data_offset = data_offset,\n\t\t.reference = reference,\n\t\t.size = sample->aux_sample.size,\n\t};\n\tstruct perf_sample_id *sid;\n\tu64 id = sample->id;\n\tunsigned int idx;\n\n\tif (!id)\n\t\treturn -EINVAL;\n\n\tsid = evlist__id2sid(session->evlist, id);\n\tif (!sid)\n\t\treturn -ENOENT;\n\n\tidx = sid->idx;\n\tbuffer.tid = sid->tid;\n\tbuffer.cpu = sid->cpu;\n\n\treturn auxtrace_queues__add_buffer(queues, session, idx, &buffer, NULL);\n}\n\nstruct queue_data {\n\tbool samples;\n\tbool events;\n};\n\nstatic int auxtrace_queue_data_cb(struct perf_session *session,\n\t\t\t\t  union perf_event *event, u64 offset,\n\t\t\t\t  void *data)\n{\n\tstruct queue_data *qd = data;\n\tstruct perf_sample sample;\n\tint err;\n\n\tif (qd->events && event->header.type == PERF_RECORD_AUXTRACE) {\n\t\tif (event->header.size < sizeof(struct perf_record_auxtrace))\n\t\t\treturn -EINVAL;\n\t\toffset += event->header.size;\n\t\treturn session->auxtrace->queue_data(session, NULL, event,\n\t\t\t\t\t\t     offset);\n\t}\n\n\tif (!qd->samples || event->header.type != PERF_RECORD_SAMPLE)\n\t\treturn 0;\n\n\terr = evlist__parse_sample(session->evlist, event, &sample);\n\tif (err)\n\t\treturn err;\n\n\tif (!sample.aux_sample.size)\n\t\treturn 0;\n\n\toffset += sample.aux_sample.data - (void *)event;\n\n\treturn session->auxtrace->queue_data(session, &sample, NULL, offset);\n}\n\nint auxtrace_queue_data(struct perf_session *session, bool samples, bool events)\n{\n\tstruct queue_data qd = {\n\t\t.samples = samples,\n\t\t.events = events,\n\t};\n\n\tif (auxtrace__dont_decode(session))\n\t\treturn 0;\n\n\tif (perf_data__is_pipe(session->data))\n\t\treturn 0;\n\n\tif (!session->auxtrace || !session->auxtrace->queue_data)\n\t\treturn -EINVAL;\n\n\treturn perf_session__peek_events(session, session->header.data_offset,\n\t\t\t\t\t session->header.data_size,\n\t\t\t\t\t auxtrace_queue_data_cb, &qd);\n}\n\nvoid *auxtrace_buffer__get_data_rw(struct auxtrace_buffer *buffer, int fd, bool rw)\n{\n\tint prot = rw ? PROT_READ | PROT_WRITE : PROT_READ;\n\tsize_t adj = buffer->data_offset & (page_size - 1);\n\tsize_t size = buffer->size + adj;\n\toff_t file_offset = buffer->data_offset - adj;\n\tvoid *addr;\n\n\tif (buffer->data)\n\t\treturn buffer->data;\n\n\taddr = mmap(NULL, size, prot, MAP_SHARED, fd, file_offset);\n\tif (addr == MAP_FAILED)\n\t\treturn NULL;\n\n\tbuffer->mmap_addr = addr;\n\tbuffer->mmap_size = size;\n\n\tbuffer->data = addr + adj;\n\n\treturn buffer->data;\n}\n\nvoid auxtrace_buffer__put_data(struct auxtrace_buffer *buffer)\n{\n\tif (!buffer->data || !buffer->mmap_addr)\n\t\treturn;\n\tmunmap(buffer->mmap_addr, buffer->mmap_size);\n\tbuffer->mmap_addr = NULL;\n\tbuffer->mmap_size = 0;\n\tbuffer->data = NULL;\n\tbuffer->use_data = NULL;\n}\n\nvoid auxtrace_buffer__drop_data(struct auxtrace_buffer *buffer)\n{\n\tauxtrace_buffer__put_data(buffer);\n\tif (buffer->data_needs_freeing) {\n\t\tbuffer->data_needs_freeing = false;\n\t\tzfree(&buffer->data);\n\t\tbuffer->use_data = NULL;\n\t\tbuffer->size = 0;\n\t}\n}\n\nvoid auxtrace_buffer__free(struct auxtrace_buffer *buffer)\n{\n\tauxtrace_buffer__drop_data(buffer);\n\tfree(buffer);\n}\n\nvoid auxtrace_synth_guest_error(struct perf_record_auxtrace_error *auxtrace_error, int type,\n\t\t\t\tint code, int cpu, pid_t pid, pid_t tid, u64 ip,\n\t\t\t\tconst char *msg, u64 timestamp,\n\t\t\t\tpid_t machine_pid, int vcpu)\n{\n\tsize_t size;\n\n\tmemset(auxtrace_error, 0, sizeof(struct perf_record_auxtrace_error));\n\n\tauxtrace_error->header.type = PERF_RECORD_AUXTRACE_ERROR;\n\tauxtrace_error->type = type;\n\tauxtrace_error->code = code;\n\tauxtrace_error->cpu = cpu;\n\tauxtrace_error->pid = pid;\n\tauxtrace_error->tid = tid;\n\tauxtrace_error->fmt = 1;\n\tauxtrace_error->ip = ip;\n\tauxtrace_error->time = timestamp;\n\tstrlcpy(auxtrace_error->msg, msg, MAX_AUXTRACE_ERROR_MSG);\n\tif (machine_pid) {\n\t\tauxtrace_error->fmt = 2;\n\t\tauxtrace_error->machine_pid = machine_pid;\n\t\tauxtrace_error->vcpu = vcpu;\n\t\tsize = sizeof(*auxtrace_error);\n\t} else {\n\t\tsize = (void *)auxtrace_error->msg - (void *)auxtrace_error +\n\t\t       strlen(auxtrace_error->msg) + 1;\n\t}\n\tauxtrace_error->header.size = PERF_ALIGN(size, sizeof(u64));\n}\n\nvoid auxtrace_synth_error(struct perf_record_auxtrace_error *auxtrace_error, int type,\n\t\t\t  int code, int cpu, pid_t pid, pid_t tid, u64 ip,\n\t\t\t  const char *msg, u64 timestamp)\n{\n\tauxtrace_synth_guest_error(auxtrace_error, type, code, cpu, pid, tid,\n\t\t\t\t   ip, msg, timestamp, 0, -1);\n}\n\nint perf_event__synthesize_auxtrace_info(struct auxtrace_record *itr,\n\t\t\t\t\t struct perf_tool *tool,\n\t\t\t\t\t struct perf_session *session,\n\t\t\t\t\t perf_event__handler_t process)\n{\n\tunion perf_event *ev;\n\tsize_t priv_size;\n\tint err;\n\n\tpr_debug2(\"Synthesizing auxtrace information\\n\");\n\tpriv_size = auxtrace_record__info_priv_size(itr, session->evlist);\n\tev = zalloc(sizeof(struct perf_record_auxtrace_info) + priv_size);\n\tif (!ev)\n\t\treturn -ENOMEM;\n\n\tev->auxtrace_info.header.type = PERF_RECORD_AUXTRACE_INFO;\n\tev->auxtrace_info.header.size = sizeof(struct perf_record_auxtrace_info) +\n\t\t\t\t\tpriv_size;\n\terr = auxtrace_record__info_fill(itr, session, &ev->auxtrace_info,\n\t\t\t\t\t priv_size);\n\tif (err)\n\t\tgoto out_free;\n\n\terr = process(tool, ev, NULL, NULL);\nout_free:\n\tfree(ev);\n\treturn err;\n}\n\nstatic void unleader_evsel(struct evlist *evlist, struct evsel *leader)\n{\n\tstruct evsel *new_leader = NULL;\n\tstruct evsel *evsel;\n\n\t \n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (!evsel__has_leader(evsel, leader) || evsel == leader)\n\t\t\tcontinue;\n\t\tif (!new_leader)\n\t\t\tnew_leader = evsel;\n\t\tevsel__set_leader(evsel, new_leader);\n\t}\n\n\t \n\tif (new_leader) {\n\t\tzfree(&new_leader->group_name);\n\t\tnew_leader->group_name = leader->group_name;\n\t\tleader->group_name = NULL;\n\n\t\tnew_leader->core.nr_members = leader->core.nr_members - 1;\n\t\tleader->core.nr_members = 1;\n\t}\n}\n\nstatic void unleader_auxtrace(struct perf_session *session)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tif (auxtrace__evsel_is_auxtrace(session, evsel) &&\n\t\t    evsel__is_group_leader(evsel)) {\n\t\t\tunleader_evsel(session->evlist, evsel);\n\t\t}\n\t}\n}\n\nint perf_event__process_auxtrace_info(struct perf_session *session,\n\t\t\t\t      union perf_event *event)\n{\n\tenum auxtrace_type type = event->auxtrace_info.type;\n\tint err;\n\n\tif (dump_trace)\n\t\tfprintf(stdout, \" type: %u\\n\", type);\n\n\tswitch (type) {\n\tcase PERF_AUXTRACE_INTEL_PT:\n\t\terr = intel_pt_process_auxtrace_info(event, session);\n\t\tbreak;\n\tcase PERF_AUXTRACE_INTEL_BTS:\n\t\terr = intel_bts_process_auxtrace_info(event, session);\n\t\tbreak;\n\tcase PERF_AUXTRACE_ARM_SPE:\n\t\terr = arm_spe_process_auxtrace_info(event, session);\n\t\tbreak;\n\tcase PERF_AUXTRACE_CS_ETM:\n\t\terr = cs_etm__process_auxtrace_info(event, session);\n\t\tbreak;\n\tcase PERF_AUXTRACE_S390_CPUMSF:\n\t\terr = s390_cpumsf_process_auxtrace_info(event, session);\n\t\tbreak;\n\tcase PERF_AUXTRACE_HISI_PTT:\n\t\terr = hisi_ptt_process_auxtrace_info(event, session);\n\t\tbreak;\n\tcase PERF_AUXTRACE_UNKNOWN:\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (err)\n\t\treturn err;\n\n\tunleader_auxtrace(session);\n\n\treturn 0;\n}\n\ns64 perf_event__process_auxtrace(struct perf_session *session,\n\t\t\t\t union perf_event *event)\n{\n\ts64 err;\n\n\tif (dump_trace)\n\t\tfprintf(stdout, \" size: %#\"PRI_lx64\"  offset: %#\"PRI_lx64\"  ref: %#\"PRI_lx64\"  idx: %u  tid: %d  cpu: %d\\n\",\n\t\t\tevent->auxtrace.size, event->auxtrace.offset,\n\t\t\tevent->auxtrace.reference, event->auxtrace.idx,\n\t\t\tevent->auxtrace.tid, event->auxtrace.cpu);\n\n\tif (auxtrace__dont_decode(session))\n\t\treturn event->auxtrace.size;\n\n\tif (!session->auxtrace || event->header.type != PERF_RECORD_AUXTRACE)\n\t\treturn -EINVAL;\n\n\terr = session->auxtrace->process_auxtrace_event(session, event, session->tool);\n\tif (err < 0)\n\t\treturn err;\n\n\treturn event->auxtrace.size;\n}\n\n#define PERF_ITRACE_DEFAULT_PERIOD_TYPE\t\tPERF_ITRACE_PERIOD_NANOSECS\n#define PERF_ITRACE_DEFAULT_PERIOD\t\t100000\n#define PERF_ITRACE_DEFAULT_CALLCHAIN_SZ\t16\n#define PERF_ITRACE_MAX_CALLCHAIN_SZ\t\t1024\n#define PERF_ITRACE_DEFAULT_LAST_BRANCH_SZ\t64\n#define PERF_ITRACE_MAX_LAST_BRANCH_SZ\t\t1024\n\nvoid itrace_synth_opts__set_default(struct itrace_synth_opts *synth_opts,\n\t\t\t\t    bool no_sample)\n{\n\tsynth_opts->branches = true;\n\tsynth_opts->transactions = true;\n\tsynth_opts->ptwrites = true;\n\tsynth_opts->pwr_events = true;\n\tsynth_opts->other_events = true;\n\tsynth_opts->intr_events = true;\n\tsynth_opts->errors = true;\n\tsynth_opts->flc = true;\n\tsynth_opts->llc = true;\n\tsynth_opts->tlb = true;\n\tsynth_opts->mem = true;\n\tsynth_opts->remote_access = true;\n\n\tif (no_sample) {\n\t\tsynth_opts->period_type = PERF_ITRACE_PERIOD_INSTRUCTIONS;\n\t\tsynth_opts->period = 1;\n\t\tsynth_opts->calls = true;\n\t} else {\n\t\tsynth_opts->instructions = true;\n\t\tsynth_opts->cycles = true;\n\t\tsynth_opts->period_type = PERF_ITRACE_DEFAULT_PERIOD_TYPE;\n\t\tsynth_opts->period = PERF_ITRACE_DEFAULT_PERIOD;\n\t}\n\tsynth_opts->callchain_sz = PERF_ITRACE_DEFAULT_CALLCHAIN_SZ;\n\tsynth_opts->last_branch_sz = PERF_ITRACE_DEFAULT_LAST_BRANCH_SZ;\n\tsynth_opts->initial_skip = 0;\n}\n\nstatic int get_flag(const char **ptr, unsigned int *flags)\n{\n\twhile (1) {\n\t\tchar c = **ptr;\n\n\t\tif (c >= 'a' && c <= 'z') {\n\t\t\t*flags |= 1 << (c - 'a');\n\t\t\t++*ptr;\n\t\t\treturn 0;\n\t\t} else if (c == ' ') {\n\t\t\t++*ptr;\n\t\t\tcontinue;\n\t\t} else {\n\t\t\treturn -1;\n\t\t}\n\t}\n}\n\nstatic int get_flags(const char **ptr, unsigned int *plus_flags, unsigned int *minus_flags)\n{\n\twhile (1) {\n\t\tswitch (**ptr) {\n\t\tcase '+':\n\t\t\t++*ptr;\n\t\t\tif (get_flag(ptr, plus_flags))\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tcase '-':\n\t\t\t++*ptr;\n\t\t\tif (get_flag(ptr, minus_flags))\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tcase ' ':\n\t\t\t++*ptr;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn 0;\n\t\t}\n\t}\n}\n\n#define ITRACE_DFLT_LOG_ON_ERROR_SZ 16384\n\nstatic unsigned int itrace_log_on_error_size(void)\n{\n\tunsigned int sz = 0;\n\n\tperf_config_scan(\"itrace.debug-log-buffer-size\", \"%u\", &sz);\n\treturn sz ?: ITRACE_DFLT_LOG_ON_ERROR_SZ;\n}\n\n \nint itrace_do_parse_synth_opts(struct itrace_synth_opts *synth_opts,\n\t\t\t       const char *str, int unset)\n{\n\tconst char *p;\n\tchar *endptr;\n\tbool period_type_set = false;\n\tbool period_set = false;\n\n\tsynth_opts->set = true;\n\n\tif (unset) {\n\t\tsynth_opts->dont_decode = true;\n\t\treturn 0;\n\t}\n\n\tif (!str) {\n\t\titrace_synth_opts__set_default(synth_opts,\n\t\t\t\t\t       synth_opts->default_no_sample);\n\t\treturn 0;\n\t}\n\n\tfor (p = str; *p;) {\n\t\tswitch (*p++) {\n\t\tcase 'i':\n\t\tcase 'y':\n\t\t\tif (p[-1] == 'y')\n\t\t\t\tsynth_opts->cycles = true;\n\t\t\telse\n\t\t\t\tsynth_opts->instructions = true;\n\t\t\twhile (*p == ' ' || *p == ',')\n\t\t\t\tp += 1;\n\t\t\tif (isdigit(*p)) {\n\t\t\t\tsynth_opts->period = strtoull(p, &endptr, 10);\n\t\t\t\tperiod_set = true;\n\t\t\t\tp = endptr;\n\t\t\t\twhile (*p == ' ' || *p == ',')\n\t\t\t\t\tp += 1;\n\t\t\t\tswitch (*p++) {\n\t\t\t\tcase 'i':\n\t\t\t\t\tsynth_opts->period_type =\n\t\t\t\t\t\tPERF_ITRACE_PERIOD_INSTRUCTIONS;\n\t\t\t\t\tperiod_type_set = true;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 't':\n\t\t\t\t\tsynth_opts->period_type =\n\t\t\t\t\t\tPERF_ITRACE_PERIOD_TICKS;\n\t\t\t\t\tperiod_type_set = true;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'm':\n\t\t\t\t\tsynth_opts->period *= 1000;\n\t\t\t\t\t \n\t\t\t\tcase 'u':\n\t\t\t\t\tsynth_opts->period *= 1000;\n\t\t\t\t\t \n\t\t\t\tcase 'n':\n\t\t\t\t\tif (*p++ != 's')\n\t\t\t\t\t\tgoto out_err;\n\t\t\t\t\tsynth_opts->period_type =\n\t\t\t\t\t\tPERF_ITRACE_PERIOD_NANOSECS;\n\t\t\t\t\tperiod_type_set = true;\n\t\t\t\t\tbreak;\n\t\t\t\tcase '\\0':\n\t\t\t\t\tgoto out;\n\t\t\t\tdefault:\n\t\t\t\t\tgoto out_err;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'b':\n\t\t\tsynth_opts->branches = true;\n\t\t\tbreak;\n\t\tcase 'x':\n\t\t\tsynth_opts->transactions = true;\n\t\t\tbreak;\n\t\tcase 'w':\n\t\t\tsynth_opts->ptwrites = true;\n\t\t\tbreak;\n\t\tcase 'p':\n\t\t\tsynth_opts->pwr_events = true;\n\t\t\tbreak;\n\t\tcase 'o':\n\t\t\tsynth_opts->other_events = true;\n\t\t\tbreak;\n\t\tcase 'I':\n\t\t\tsynth_opts->intr_events = true;\n\t\t\tbreak;\n\t\tcase 'e':\n\t\t\tsynth_opts->errors = true;\n\t\t\tif (get_flags(&p, &synth_opts->error_plus_flags,\n\t\t\t\t      &synth_opts->error_minus_flags))\n\t\t\t\tgoto out_err;\n\t\t\tbreak;\n\t\tcase 'd':\n\t\t\tsynth_opts->log = true;\n\t\t\tif (get_flags(&p, &synth_opts->log_plus_flags,\n\t\t\t\t      &synth_opts->log_minus_flags))\n\t\t\t\tgoto out_err;\n\t\t\tif (synth_opts->log_plus_flags & AUXTRACE_LOG_FLG_ON_ERROR)\n\t\t\t\tsynth_opts->log_on_error_size = itrace_log_on_error_size();\n\t\t\tbreak;\n\t\tcase 'c':\n\t\t\tsynth_opts->branches = true;\n\t\t\tsynth_opts->calls = true;\n\t\t\tbreak;\n\t\tcase 'r':\n\t\t\tsynth_opts->branches = true;\n\t\t\tsynth_opts->returns = true;\n\t\t\tbreak;\n\t\tcase 'G':\n\t\tcase 'g':\n\t\t\tif (p[-1] == 'G')\n\t\t\t\tsynth_opts->add_callchain = true;\n\t\t\telse\n\t\t\t\tsynth_opts->callchain = true;\n\t\t\tsynth_opts->callchain_sz =\n\t\t\t\t\tPERF_ITRACE_DEFAULT_CALLCHAIN_SZ;\n\t\t\twhile (*p == ' ' || *p == ',')\n\t\t\t\tp += 1;\n\t\t\tif (isdigit(*p)) {\n\t\t\t\tunsigned int val;\n\n\t\t\t\tval = strtoul(p, &endptr, 10);\n\t\t\t\tp = endptr;\n\t\t\t\tif (!val || val > PERF_ITRACE_MAX_CALLCHAIN_SZ)\n\t\t\t\t\tgoto out_err;\n\t\t\t\tsynth_opts->callchain_sz = val;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 'L':\n\t\tcase 'l':\n\t\t\tif (p[-1] == 'L')\n\t\t\t\tsynth_opts->add_last_branch = true;\n\t\t\telse\n\t\t\t\tsynth_opts->last_branch = true;\n\t\t\tsynth_opts->last_branch_sz =\n\t\t\t\t\tPERF_ITRACE_DEFAULT_LAST_BRANCH_SZ;\n\t\t\twhile (*p == ' ' || *p == ',')\n\t\t\t\tp += 1;\n\t\t\tif (isdigit(*p)) {\n\t\t\t\tunsigned int val;\n\n\t\t\t\tval = strtoul(p, &endptr, 10);\n\t\t\t\tp = endptr;\n\t\t\t\tif (!val ||\n\t\t\t\t    val > PERF_ITRACE_MAX_LAST_BRANCH_SZ)\n\t\t\t\t\tgoto out_err;\n\t\t\t\tsynth_opts->last_branch_sz = val;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tsynth_opts->initial_skip = strtoul(p, &endptr, 10);\n\t\t\tif (p == endptr)\n\t\t\t\tgoto out_err;\n\t\t\tp = endptr;\n\t\t\tbreak;\n\t\tcase 'f':\n\t\t\tsynth_opts->flc = true;\n\t\t\tbreak;\n\t\tcase 'm':\n\t\t\tsynth_opts->llc = true;\n\t\t\tbreak;\n\t\tcase 't':\n\t\t\tsynth_opts->tlb = true;\n\t\t\tbreak;\n\t\tcase 'a':\n\t\t\tsynth_opts->remote_access = true;\n\t\t\tbreak;\n\t\tcase 'M':\n\t\t\tsynth_opts->mem = true;\n\t\t\tbreak;\n\t\tcase 'q':\n\t\t\tsynth_opts->quick += 1;\n\t\t\tbreak;\n\t\tcase 'A':\n\t\t\tsynth_opts->approx_ipc = true;\n\t\t\tbreak;\n\t\tcase 'Z':\n\t\t\tsynth_opts->timeless_decoding = true;\n\t\t\tbreak;\n\t\tcase ' ':\n\t\tcase ',':\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto out_err;\n\t\t}\n\t}\nout:\n\tif (synth_opts->instructions || synth_opts->cycles) {\n\t\tif (!period_type_set)\n\t\t\tsynth_opts->period_type =\n\t\t\t\t\tPERF_ITRACE_DEFAULT_PERIOD_TYPE;\n\t\tif (!period_set)\n\t\t\tsynth_opts->period = PERF_ITRACE_DEFAULT_PERIOD;\n\t}\n\n\treturn 0;\n\nout_err:\n\tpr_err(\"Bad Instruction Tracing options '%s'\\n\", str);\n\treturn -EINVAL;\n}\n\nint itrace_parse_synth_opts(const struct option *opt, const char *str, int unset)\n{\n\treturn itrace_do_parse_synth_opts(opt->value, str, unset);\n}\n\nstatic const char * const auxtrace_error_type_name[] = {\n\t[PERF_AUXTRACE_ERROR_ITRACE] = \"instruction trace\",\n};\n\nstatic const char *auxtrace_error_name(int type)\n{\n\tconst char *error_type_name = NULL;\n\n\tif (type < PERF_AUXTRACE_ERROR_MAX)\n\t\terror_type_name = auxtrace_error_type_name[type];\n\tif (!error_type_name)\n\t\terror_type_name = \"unknown AUX\";\n\treturn error_type_name;\n}\n\nsize_t perf_event__fprintf_auxtrace_error(union perf_event *event, FILE *fp)\n{\n\tstruct perf_record_auxtrace_error *e = &event->auxtrace_error;\n\tunsigned long long nsecs = e->time;\n\tconst char *msg = e->msg;\n\tint ret;\n\n\tret = fprintf(fp, \" %s error type %u\",\n\t\t      auxtrace_error_name(e->type), e->type);\n\n\tif (e->fmt && nsecs) {\n\t\tunsigned long secs = nsecs / NSEC_PER_SEC;\n\n\t\tnsecs -= secs * NSEC_PER_SEC;\n\t\tret += fprintf(fp, \" time %lu.%09llu\", secs, nsecs);\n\t} else {\n\t\tret += fprintf(fp, \" time 0\");\n\t}\n\n\tif (!e->fmt)\n\t\tmsg = (const char *)&e->time;\n\n\tif (e->fmt >= 2 && e->machine_pid)\n\t\tret += fprintf(fp, \" machine_pid %d vcpu %d\", e->machine_pid, e->vcpu);\n\n\tret += fprintf(fp, \" cpu %d pid %d tid %d ip %#\"PRI_lx64\" code %u: %s\\n\",\n\t\t       e->cpu, e->pid, e->tid, e->ip, e->code, msg);\n\treturn ret;\n}\n\nvoid perf_session__auxtrace_error_inc(struct perf_session *session,\n\t\t\t\t      union perf_event *event)\n{\n\tstruct perf_record_auxtrace_error *e = &event->auxtrace_error;\n\n\tif (e->type < PERF_AUXTRACE_ERROR_MAX)\n\t\tsession->evlist->stats.nr_auxtrace_errors[e->type] += 1;\n}\n\nvoid events_stats__auxtrace_error_warn(const struct events_stats *stats)\n{\n\tint i;\n\n\tfor (i = 0; i < PERF_AUXTRACE_ERROR_MAX; i++) {\n\t\tif (!stats->nr_auxtrace_errors[i])\n\t\t\tcontinue;\n\t\tui__warning(\"%u %s errors\\n\",\n\t\t\t    stats->nr_auxtrace_errors[i],\n\t\t\t    auxtrace_error_name(i));\n\t}\n}\n\nint perf_event__process_auxtrace_error(struct perf_session *session,\n\t\t\t\t       union perf_event *event)\n{\n\tif (auxtrace__dont_decode(session))\n\t\treturn 0;\n\n\tperf_event__fprintf_auxtrace_error(event, stdout);\n\treturn 0;\n}\n\n \nu64 __weak compat_auxtrace_mmap__read_head(struct auxtrace_mmap *mm)\n{\n\tstruct perf_event_mmap_page *pc = mm->userpg;\n\tu64 first, second, last;\n\tu64 mask = (u64)(UINT32_MAX) << 32;\n\n\tdo {\n\t\tfirst = READ_ONCE(pc->aux_head);\n\t\t \n\t\tsmp_rmb();\n\t\tsecond = READ_ONCE(pc->aux_head);\n\t\t \n\t\tsmp_rmb();\n\t\tlast = READ_ONCE(pc->aux_head);\n\t} while ((first & mask) != (last & mask));\n\n\treturn second;\n}\n\nint __weak compat_auxtrace_mmap__write_tail(struct auxtrace_mmap *mm, u64 tail)\n{\n\tstruct perf_event_mmap_page *pc = mm->userpg;\n\tu64 mask = (u64)(UINT32_MAX) << 32;\n\n\tif (tail & mask)\n\t\treturn -1;\n\n\t \n\tsmp_mb();\n\tWRITE_ONCE(pc->aux_tail, tail);\n\treturn 0;\n}\n\nstatic int __auxtrace_mmap__read(struct mmap *map,\n\t\t\t\t struct auxtrace_record *itr,\n\t\t\t\t struct perf_tool *tool, process_auxtrace_t fn,\n\t\t\t\t bool snapshot, size_t snapshot_size)\n{\n\tstruct auxtrace_mmap *mm = &map->auxtrace_mmap;\n\tu64 head, old = mm->prev, offset, ref;\n\tunsigned char *data = mm->base;\n\tsize_t size, head_off, old_off, len1, len2, padding;\n\tunion perf_event ev;\n\tvoid *data1, *data2;\n\tint kernel_is_64_bit = perf_env__kernel_is_64_bit(evsel__env(NULL));\n\n\thead = auxtrace_mmap__read_head(mm, kernel_is_64_bit);\n\n\tif (snapshot &&\n\t    auxtrace_record__find_snapshot(itr, mm->idx, mm, data, &head, &old))\n\t\treturn -1;\n\n\tif (old == head)\n\t\treturn 0;\n\n\tpr_debug3(\"auxtrace idx %d old %#\"PRIx64\" head %#\"PRIx64\" diff %#\"PRIx64\"\\n\",\n\t\t  mm->idx, old, head, head - old);\n\n\tif (mm->mask) {\n\t\thead_off = head & mm->mask;\n\t\told_off = old & mm->mask;\n\t} else {\n\t\thead_off = head % mm->len;\n\t\told_off = old % mm->len;\n\t}\n\n\tif (head_off > old_off)\n\t\tsize = head_off - old_off;\n\telse\n\t\tsize = mm->len - (old_off - head_off);\n\n\tif (snapshot && size > snapshot_size)\n\t\tsize = snapshot_size;\n\n\tref = auxtrace_record__reference(itr);\n\n\tif (head > old || size <= head || mm->mask) {\n\t\toffset = head - size;\n\t} else {\n\t\t \n\t\tu64 rem = (0ULL - mm->len) % mm->len;\n\n\t\toffset = head - size - rem;\n\t}\n\n\tif (size > head_off) {\n\t\tlen1 = size - head_off;\n\t\tdata1 = &data[mm->len - len1];\n\t\tlen2 = head_off;\n\t\tdata2 = &data[0];\n\t} else {\n\t\tlen1 = size;\n\t\tdata1 = &data[head_off - len1];\n\t\tlen2 = 0;\n\t\tdata2 = NULL;\n\t}\n\n\tif (itr->alignment) {\n\t\tunsigned int unwanted = len1 % itr->alignment;\n\n\t\tlen1 -= unwanted;\n\t\tsize -= unwanted;\n\t}\n\n\t \n\tpadding = size & (PERF_AUXTRACE_RECORD_ALIGNMENT - 1);\n\tif (padding)\n\t\tpadding = PERF_AUXTRACE_RECORD_ALIGNMENT - padding;\n\n\tmemset(&ev, 0, sizeof(ev));\n\tev.auxtrace.header.type = PERF_RECORD_AUXTRACE;\n\tev.auxtrace.header.size = sizeof(ev.auxtrace);\n\tev.auxtrace.size = size + padding;\n\tev.auxtrace.offset = offset;\n\tev.auxtrace.reference = ref;\n\tev.auxtrace.idx = mm->idx;\n\tev.auxtrace.tid = mm->tid;\n\tev.auxtrace.cpu = mm->cpu;\n\n\tif (fn(tool, map, &ev, data1, len1, data2, len2))\n\t\treturn -1;\n\n\tmm->prev = head;\n\n\tif (!snapshot) {\n\t\tint err;\n\n\t\terr = auxtrace_mmap__write_tail(mm, head, kernel_is_64_bit);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (itr->read_finish) {\n\t\t\terr = itr->read_finish(itr, mm->idx);\n\t\t\tif (err < 0)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 1;\n}\n\nint auxtrace_mmap__read(struct mmap *map, struct auxtrace_record *itr,\n\t\t\tstruct perf_tool *tool, process_auxtrace_t fn)\n{\n\treturn __auxtrace_mmap__read(map, itr, tool, fn, false, 0);\n}\n\nint auxtrace_mmap__read_snapshot(struct mmap *map,\n\t\t\t\t struct auxtrace_record *itr,\n\t\t\t\t struct perf_tool *tool, process_auxtrace_t fn,\n\t\t\t\t size_t snapshot_size)\n{\n\treturn __auxtrace_mmap__read(map, itr, tool, fn, true, snapshot_size);\n}\n\n \nstruct auxtrace_cache {\n\tstruct hlist_head *hashtable;\n\tsize_t sz;\n\tsize_t entry_size;\n\tsize_t limit;\n\tsize_t cnt;\n\tunsigned int bits;\n};\n\nstruct auxtrace_cache *auxtrace_cache__new(unsigned int bits, size_t entry_size,\n\t\t\t\t\t   unsigned int limit_percent)\n{\n\tstruct auxtrace_cache *c;\n\tstruct hlist_head *ht;\n\tsize_t sz, i;\n\n\tc = zalloc(sizeof(struct auxtrace_cache));\n\tif (!c)\n\t\treturn NULL;\n\n\tsz = 1UL << bits;\n\n\tht = calloc(sz, sizeof(struct hlist_head));\n\tif (!ht)\n\t\tgoto out_free;\n\n\tfor (i = 0; i < sz; i++)\n\t\tINIT_HLIST_HEAD(&ht[i]);\n\n\tc->hashtable = ht;\n\tc->sz = sz;\n\tc->entry_size = entry_size;\n\tc->limit = (c->sz * limit_percent) / 100;\n\tc->bits = bits;\n\n\treturn c;\n\nout_free:\n\tfree(c);\n\treturn NULL;\n}\n\nstatic void auxtrace_cache__drop(struct auxtrace_cache *c)\n{\n\tstruct auxtrace_cache_entry *entry;\n\tstruct hlist_node *tmp;\n\tsize_t i;\n\n\tif (!c)\n\t\treturn;\n\n\tfor (i = 0; i < c->sz; i++) {\n\t\thlist_for_each_entry_safe(entry, tmp, &c->hashtable[i], hash) {\n\t\t\thlist_del(&entry->hash);\n\t\t\tauxtrace_cache__free_entry(c, entry);\n\t\t}\n\t}\n\n\tc->cnt = 0;\n}\n\nvoid auxtrace_cache__free(struct auxtrace_cache *c)\n{\n\tif (!c)\n\t\treturn;\n\n\tauxtrace_cache__drop(c);\n\tzfree(&c->hashtable);\n\tfree(c);\n}\n\nvoid *auxtrace_cache__alloc_entry(struct auxtrace_cache *c)\n{\n\treturn malloc(c->entry_size);\n}\n\nvoid auxtrace_cache__free_entry(struct auxtrace_cache *c __maybe_unused,\n\t\t\t\tvoid *entry)\n{\n\tfree(entry);\n}\n\nint auxtrace_cache__add(struct auxtrace_cache *c, u32 key,\n\t\t\tstruct auxtrace_cache_entry *entry)\n{\n\tif (c->limit && ++c->cnt > c->limit)\n\t\tauxtrace_cache__drop(c);\n\n\tentry->key = key;\n\thlist_add_head(&entry->hash, &c->hashtable[hash_32(key, c->bits)]);\n\n\treturn 0;\n}\n\nstatic struct auxtrace_cache_entry *auxtrace_cache__rm(struct auxtrace_cache *c,\n\t\t\t\t\t\t       u32 key)\n{\n\tstruct auxtrace_cache_entry *entry;\n\tstruct hlist_head *hlist;\n\tstruct hlist_node *n;\n\n\tif (!c)\n\t\treturn NULL;\n\n\thlist = &c->hashtable[hash_32(key, c->bits)];\n\thlist_for_each_entry_safe(entry, n, hlist, hash) {\n\t\tif (entry->key == key) {\n\t\t\thlist_del(&entry->hash);\n\t\t\treturn entry;\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nvoid auxtrace_cache__remove(struct auxtrace_cache *c, u32 key)\n{\n\tstruct auxtrace_cache_entry *entry = auxtrace_cache__rm(c, key);\n\n\tauxtrace_cache__free_entry(c, entry);\n}\n\nvoid *auxtrace_cache__lookup(struct auxtrace_cache *c, u32 key)\n{\n\tstruct auxtrace_cache_entry *entry;\n\tstruct hlist_head *hlist;\n\n\tif (!c)\n\t\treturn NULL;\n\n\thlist = &c->hashtable[hash_32(key, c->bits)];\n\thlist_for_each_entry(entry, hlist, hash) {\n\t\tif (entry->key == key)\n\t\t\treturn entry;\n\t}\n\n\treturn NULL;\n}\n\nstatic void addr_filter__free_str(struct addr_filter *filt)\n{\n\tzfree(&filt->str);\n\tfilt->action   = NULL;\n\tfilt->sym_from = NULL;\n\tfilt->sym_to   = NULL;\n\tfilt->filename = NULL;\n}\n\nstatic struct addr_filter *addr_filter__new(void)\n{\n\tstruct addr_filter *filt = zalloc(sizeof(*filt));\n\n\tif (filt)\n\t\tINIT_LIST_HEAD(&filt->list);\n\n\treturn filt;\n}\n\nstatic void addr_filter__free(struct addr_filter *filt)\n{\n\tif (filt)\n\t\taddr_filter__free_str(filt);\n\tfree(filt);\n}\n\nstatic void addr_filters__add(struct addr_filters *filts,\n\t\t\t      struct addr_filter *filt)\n{\n\tlist_add_tail(&filt->list, &filts->head);\n\tfilts->cnt += 1;\n}\n\nstatic void addr_filters__del(struct addr_filters *filts,\n\t\t\t      struct addr_filter *filt)\n{\n\tlist_del_init(&filt->list);\n\tfilts->cnt -= 1;\n}\n\nvoid addr_filters__init(struct addr_filters *filts)\n{\n\tINIT_LIST_HEAD(&filts->head);\n\tfilts->cnt = 0;\n}\n\nvoid addr_filters__exit(struct addr_filters *filts)\n{\n\tstruct addr_filter *filt, *n;\n\n\tlist_for_each_entry_safe(filt, n, &filts->head, list) {\n\t\taddr_filters__del(filts, filt);\n\t\taddr_filter__free(filt);\n\t}\n}\n\nstatic int parse_num_or_str(char **inp, u64 *num, const char **str,\n\t\t\t    const char *str_delim)\n{\n\t*inp += strspn(*inp, \" \");\n\n\tif (isdigit(**inp)) {\n\t\tchar *endptr;\n\n\t\tif (!num)\n\t\t\treturn -EINVAL;\n\t\terrno = 0;\n\t\t*num = strtoull(*inp, &endptr, 0);\n\t\tif (errno)\n\t\t\treturn -errno;\n\t\tif (endptr == *inp)\n\t\t\treturn -EINVAL;\n\t\t*inp = endptr;\n\t} else {\n\t\tsize_t n;\n\n\t\tif (!str)\n\t\t\treturn -EINVAL;\n\t\t*inp += strspn(*inp, \" \");\n\t\t*str = *inp;\n\t\tn = strcspn(*inp, str_delim);\n\t\tif (!n)\n\t\t\treturn -EINVAL;\n\t\t*inp += n;\n\t\tif (**inp) {\n\t\t\t**inp = '\\0';\n\t\t\t*inp += 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int parse_action(struct addr_filter *filt)\n{\n\tif (!strcmp(filt->action, \"filter\")) {\n\t\tfilt->start = true;\n\t\tfilt->range = true;\n\t} else if (!strcmp(filt->action, \"start\")) {\n\t\tfilt->start = true;\n\t} else if (!strcmp(filt->action, \"stop\")) {\n\t\tfilt->start = false;\n\t} else if (!strcmp(filt->action, \"tracestop\")) {\n\t\tfilt->start = false;\n\t\tfilt->range = true;\n\t\tfilt->action += 5;  \n\t} else {\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int parse_sym_idx(char **inp, int *idx)\n{\n\t*idx = -1;\n\n\t*inp += strspn(*inp, \" \");\n\n\tif (**inp != '#')\n\t\treturn 0;\n\n\t*inp += 1;\n\n\tif (**inp == 'g' || **inp == 'G') {\n\t\t*inp += 1;\n\t\t*idx = 0;\n\t} else {\n\t\tunsigned long num;\n\t\tchar *endptr;\n\n\t\terrno = 0;\n\t\tnum = strtoul(*inp, &endptr, 0);\n\t\tif (errno)\n\t\t\treturn -errno;\n\t\tif (endptr == *inp || num > INT_MAX)\n\t\t\treturn -EINVAL;\n\t\t*inp = endptr;\n\t\t*idx = num;\n\t}\n\n\treturn 0;\n}\n\nstatic int parse_addr_size(char **inp, u64 *num, const char **str, int *idx)\n{\n\tint err = parse_num_or_str(inp, num, str, \" \");\n\n\tif (!err && *str)\n\t\terr = parse_sym_idx(inp, idx);\n\n\treturn err;\n}\n\nstatic int parse_one_filter(struct addr_filter *filt, const char **filter_inp)\n{\n\tchar *fstr;\n\tint err;\n\n\tfilt->str = fstr = strdup(*filter_inp);\n\tif (!fstr)\n\t\treturn -ENOMEM;\n\n\terr = parse_num_or_str(&fstr, NULL, &filt->action, \" \");\n\tif (err)\n\t\tgoto out_err;\n\n\terr = parse_action(filt);\n\tif (err)\n\t\tgoto out_err;\n\n\terr = parse_addr_size(&fstr, &filt->addr, &filt->sym_from,\n\t\t\t      &filt->sym_from_idx);\n\tif (err)\n\t\tgoto out_err;\n\n\tfstr += strspn(fstr, \" \");\n\n\tif (*fstr == '/') {\n\t\tfstr += 1;\n\t\terr = parse_addr_size(&fstr, &filt->size, &filt->sym_to,\n\t\t\t\t      &filt->sym_to_idx);\n\t\tif (err)\n\t\t\tgoto out_err;\n\t\tfilt->range = true;\n\t}\n\n\tfstr += strspn(fstr, \" \");\n\n\tif (*fstr == '@') {\n\t\tfstr += 1;\n\t\terr = parse_num_or_str(&fstr, NULL, &filt->filename, \" ,\");\n\t\tif (err)\n\t\t\tgoto out_err;\n\t}\n\n\tfstr += strspn(fstr, \" ,\");\n\n\t*filter_inp += fstr - filt->str;\n\n\treturn 0;\n\nout_err:\n\taddr_filter__free_str(filt);\n\n\treturn err;\n}\n\nint addr_filters__parse_bare_filter(struct addr_filters *filts,\n\t\t\t\t    const char *filter)\n{\n\tstruct addr_filter *filt;\n\tconst char *fstr = filter;\n\tint err;\n\n\twhile (*fstr) {\n\t\tfilt = addr_filter__new();\n\t\terr = parse_one_filter(filt, &fstr);\n\t\tif (err) {\n\t\t\taddr_filter__free(filt);\n\t\t\taddr_filters__exit(filts);\n\t\t\treturn err;\n\t\t}\n\t\taddr_filters__add(filts, filt);\n\t}\n\n\treturn 0;\n}\n\nstruct sym_args {\n\tconst char\t*name;\n\tu64\t\tstart;\n\tu64\t\tsize;\n\tint\t\tidx;\n\tint\t\tcnt;\n\tbool\t\tstarted;\n\tbool\t\tglobal;\n\tbool\t\tselected;\n\tbool\t\tduplicate;\n\tbool\t\tnear;\n};\n\nstatic bool kern_sym_name_match(const char *kname, const char *name)\n{\n\tsize_t n = strlen(name);\n\n\treturn !strcmp(kname, name) ||\n\t       (!strncmp(kname, name, n) && kname[n] == '\\t');\n}\n\nstatic bool kern_sym_match(struct sym_args *args, const char *name, char type)\n{\n\t \n\treturn kallsyms__is_function(type) &&\n\t       kern_sym_name_match(name, args->name) &&\n\t       ((args->global && isupper(type)) ||\n\t\t(args->selected && ++(args->cnt) == args->idx) ||\n\t\t(!args->global && !args->selected));\n}\n\nstatic int find_kern_sym_cb(void *arg, const char *name, char type, u64 start)\n{\n\tstruct sym_args *args = arg;\n\n\tif (args->started) {\n\t\tif (!args->size)\n\t\t\targs->size = start - args->start;\n\t\tif (args->selected) {\n\t\t\tif (args->size)\n\t\t\t\treturn 1;\n\t\t} else if (kern_sym_match(args, name, type)) {\n\t\t\targs->duplicate = true;\n\t\t\treturn 1;\n\t\t}\n\t} else if (kern_sym_match(args, name, type)) {\n\t\targs->started = true;\n\t\targs->start = start;\n\t}\n\n\treturn 0;\n}\n\nstatic int print_kern_sym_cb(void *arg, const char *name, char type, u64 start)\n{\n\tstruct sym_args *args = arg;\n\n\tif (kern_sym_match(args, name, type)) {\n\t\tpr_err(\"#%d\\t0x%\"PRIx64\"\\t%c\\t%s\\n\",\n\t\t       ++args->cnt, start, type, name);\n\t\targs->near = true;\n\t} else if (args->near) {\n\t\targs->near = false;\n\t\tpr_err(\"\\t\\twhich is near\\t\\t%s\\n\", name);\n\t}\n\n\treturn 0;\n}\n\nstatic int sym_not_found_error(const char *sym_name, int idx)\n{\n\tif (idx > 0) {\n\t\tpr_err(\"N'th occurrence (N=%d) of symbol '%s' not found.\\n\",\n\t\t       idx, sym_name);\n\t} else if (!idx) {\n\t\tpr_err(\"Global symbol '%s' not found.\\n\", sym_name);\n\t} else {\n\t\tpr_err(\"Symbol '%s' not found.\\n\", sym_name);\n\t}\n\tpr_err(\"Note that symbols must be functions.\\n\");\n\n\treturn -EINVAL;\n}\n\nstatic int find_kern_sym(const char *sym_name, u64 *start, u64 *size, int idx)\n{\n\tstruct sym_args args = {\n\t\t.name = sym_name,\n\t\t.idx = idx,\n\t\t.global = !idx,\n\t\t.selected = idx > 0,\n\t};\n\tint err;\n\n\t*start = 0;\n\t*size = 0;\n\n\terr = kallsyms__parse(\"/proc/kallsyms\", &args, find_kern_sym_cb);\n\tif (err < 0) {\n\t\tpr_err(\"Failed to parse /proc/kallsyms\\n\");\n\t\treturn err;\n\t}\n\n\tif (args.duplicate) {\n\t\tpr_err(\"Multiple kernel symbols with name '%s'\\n\", sym_name);\n\t\targs.cnt = 0;\n\t\tkallsyms__parse(\"/proc/kallsyms\", &args, print_kern_sym_cb);\n\t\tpr_err(\"Disambiguate symbol name by inserting #n after the name e.g. %s #2\\n\",\n\t\t       sym_name);\n\t\tpr_err(\"Or select a global symbol by inserting #0 or #g or #G\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!args.started) {\n\t\tpr_err(\"Kernel symbol lookup: \");\n\t\treturn sym_not_found_error(sym_name, idx);\n\t}\n\n\t*start = args.start;\n\t*size = args.size;\n\n\treturn 0;\n}\n\nstatic int find_entire_kern_cb(void *arg, const char *name __maybe_unused,\n\t\t\t       char type, u64 start)\n{\n\tstruct sym_args *args = arg;\n\tu64 size;\n\n\tif (!kallsyms__is_function(type))\n\t\treturn 0;\n\n\tif (!args->started) {\n\t\targs->started = true;\n\t\targs->start = start;\n\t}\n\t \n\tsize = round_up(start, page_size) + page_size - args->start;\n\tif (size > args->size)\n\t\targs->size = size;\n\n\treturn 0;\n}\n\nstatic int addr_filter__entire_kernel(struct addr_filter *filt)\n{\n\tstruct sym_args args = { .started = false };\n\tint err;\n\n\terr = kallsyms__parse(\"/proc/kallsyms\", &args, find_entire_kern_cb);\n\tif (err < 0 || !args.started) {\n\t\tpr_err(\"Failed to parse /proc/kallsyms\\n\");\n\t\treturn err;\n\t}\n\n\tfilt->addr = args.start;\n\tfilt->size = args.size;\n\n\treturn 0;\n}\n\nstatic int check_end_after_start(struct addr_filter *filt, u64 start, u64 size)\n{\n\tif (start + size >= filt->addr)\n\t\treturn 0;\n\n\tif (filt->sym_from) {\n\t\tpr_err(\"Symbol '%s' (0x%\"PRIx64\") comes before '%s' (0x%\"PRIx64\")\\n\",\n\t\t       filt->sym_to, start, filt->sym_from, filt->addr);\n\t} else {\n\t\tpr_err(\"Symbol '%s' (0x%\"PRIx64\") comes before address 0x%\"PRIx64\")\\n\",\n\t\t       filt->sym_to, start, filt->addr);\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int addr_filter__resolve_kernel_syms(struct addr_filter *filt)\n{\n\tbool no_size = false;\n\tu64 start, size;\n\tint err;\n\n\tif (symbol_conf.kptr_restrict) {\n\t\tpr_err(\"Kernel addresses are restricted. Unable to resolve kernel symbols.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (filt->sym_from && !strcmp(filt->sym_from, \"*\"))\n\t\treturn addr_filter__entire_kernel(filt);\n\n\tif (filt->sym_from) {\n\t\terr = find_kern_sym(filt->sym_from, &start, &size,\n\t\t\t\t    filt->sym_from_idx);\n\t\tif (err)\n\t\t\treturn err;\n\t\tfilt->addr = start;\n\t\tif (filt->range && !filt->size && !filt->sym_to) {\n\t\t\tfilt->size = size;\n\t\t\tno_size = !size;\n\t\t}\n\t}\n\n\tif (filt->sym_to) {\n\t\terr = find_kern_sym(filt->sym_to, &start, &size,\n\t\t\t\t    filt->sym_to_idx);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = check_end_after_start(filt, start, size);\n\t\tif (err)\n\t\t\treturn err;\n\t\tfilt->size = start + size - filt->addr;\n\t\tno_size = !size;\n\t}\n\n\t \n\tif (no_size) {\n\t\tpr_err(\"Cannot determine size of symbol '%s'\\n\",\n\t\t       filt->sym_to ? filt->sym_to : filt->sym_from);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic struct dso *load_dso(const char *name)\n{\n\tstruct map *map;\n\tstruct dso *dso;\n\n\tmap = dso__new_map(name);\n\tif (!map)\n\t\treturn NULL;\n\n\tif (map__load(map) < 0)\n\t\tpr_err(\"File '%s' not found or has no symbols.\\n\", name);\n\n\tdso = dso__get(map__dso(map));\n\n\tmap__put(map);\n\n\treturn dso;\n}\n\nstatic bool dso_sym_match(struct symbol *sym, const char *name, int *cnt,\n\t\t\t  int idx)\n{\n\t \n\treturn !arch__compare_symbol_names(name, sym->name) &&\n\t       ((!idx && sym->binding == STB_GLOBAL) ||\n\t\t(idx > 0 && ++*cnt == idx) ||\n\t\tidx < 0);\n}\n\nstatic void print_duplicate_syms(struct dso *dso, const char *sym_name)\n{\n\tstruct symbol *sym;\n\tbool near = false;\n\tint cnt = 0;\n\n\tpr_err(\"Multiple symbols with name '%s'\\n\", sym_name);\n\n\tsym = dso__first_symbol(dso);\n\twhile (sym) {\n\t\tif (dso_sym_match(sym, sym_name, &cnt, -1)) {\n\t\t\tpr_err(\"#%d\\t0x%\"PRIx64\"\\t%c\\t%s\\n\",\n\t\t\t       ++cnt, sym->start,\n\t\t\t       sym->binding == STB_GLOBAL ? 'g' :\n\t\t\t       sym->binding == STB_LOCAL  ? 'l' : 'w',\n\t\t\t       sym->name);\n\t\t\tnear = true;\n\t\t} else if (near) {\n\t\t\tnear = false;\n\t\t\tpr_err(\"\\t\\twhich is near\\t\\t%s\\n\", sym->name);\n\t\t}\n\t\tsym = dso__next_symbol(sym);\n\t}\n\n\tpr_err(\"Disambiguate symbol name by inserting #n after the name e.g. %s #2\\n\",\n\t       sym_name);\n\tpr_err(\"Or select a global symbol by inserting #0 or #g or #G\\n\");\n}\n\nstatic int find_dso_sym(struct dso *dso, const char *sym_name, u64 *start,\n\t\t\tu64 *size, int idx)\n{\n\tstruct symbol *sym;\n\tint cnt = 0;\n\n\t*start = 0;\n\t*size = 0;\n\n\tsym = dso__first_symbol(dso);\n\twhile (sym) {\n\t\tif (*start) {\n\t\t\tif (!*size)\n\t\t\t\t*size = sym->start - *start;\n\t\t\tif (idx > 0) {\n\t\t\t\tif (*size)\n\t\t\t\t\treturn 0;\n\t\t\t} else if (dso_sym_match(sym, sym_name, &cnt, idx)) {\n\t\t\t\tprint_duplicate_syms(dso, sym_name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else if (dso_sym_match(sym, sym_name, &cnt, idx)) {\n\t\t\t*start = sym->start;\n\t\t\t*size = sym->end - sym->start;\n\t\t}\n\t\tsym = dso__next_symbol(sym);\n\t}\n\n\tif (!*start)\n\t\treturn sym_not_found_error(sym_name, idx);\n\n\treturn 0;\n}\n\nstatic int addr_filter__entire_dso(struct addr_filter *filt, struct dso *dso)\n{\n\tif (dso__data_file_size(dso, NULL)) {\n\t\tpr_err(\"Failed to determine filter for %s\\nCannot determine file size.\\n\",\n\t\t       filt->filename);\n\t\treturn -EINVAL;\n\t}\n\n\tfilt->addr = 0;\n\tfilt->size = dso->data.file_size;\n\n\treturn 0;\n}\n\nstatic int addr_filter__resolve_syms(struct addr_filter *filt)\n{\n\tu64 start, size;\n\tstruct dso *dso;\n\tint err = 0;\n\n\tif (!filt->sym_from && !filt->sym_to)\n\t\treturn 0;\n\n\tif (!filt->filename)\n\t\treturn addr_filter__resolve_kernel_syms(filt);\n\n\tdso = load_dso(filt->filename);\n\tif (!dso) {\n\t\tpr_err(\"Failed to load symbols from: %s\\n\", filt->filename);\n\t\treturn -EINVAL;\n\t}\n\n\tif (filt->sym_from && !strcmp(filt->sym_from, \"*\")) {\n\t\terr = addr_filter__entire_dso(filt, dso);\n\t\tgoto put_dso;\n\t}\n\n\tif (filt->sym_from) {\n\t\terr = find_dso_sym(dso, filt->sym_from, &start, &size,\n\t\t\t\t   filt->sym_from_idx);\n\t\tif (err)\n\t\t\tgoto put_dso;\n\t\tfilt->addr = start;\n\t\tif (filt->range && !filt->size && !filt->sym_to)\n\t\t\tfilt->size = size;\n\t}\n\n\tif (filt->sym_to) {\n\t\terr = find_dso_sym(dso, filt->sym_to, &start, &size,\n\t\t\t\t   filt->sym_to_idx);\n\t\tif (err)\n\t\t\tgoto put_dso;\n\n\t\terr = check_end_after_start(filt, start, size);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tfilt->size = start + size - filt->addr;\n\t}\n\nput_dso:\n\tdso__put(dso);\n\n\treturn err;\n}\n\nstatic char *addr_filter__to_str(struct addr_filter *filt)\n{\n\tchar filename_buf[PATH_MAX];\n\tconst char *at = \"\";\n\tconst char *fn = \"\";\n\tchar *filter;\n\tint err;\n\n\tif (filt->filename) {\n\t\tat = \"@\";\n\t\tfn = realpath(filt->filename, filename_buf);\n\t\tif (!fn)\n\t\t\treturn NULL;\n\t}\n\n\tif (filt->range) {\n\t\terr = asprintf(&filter, \"%s 0x%\"PRIx64\"/0x%\"PRIx64\"%s%s\",\n\t\t\t       filt->action, filt->addr, filt->size, at, fn);\n\t} else {\n\t\terr = asprintf(&filter, \"%s 0x%\"PRIx64\"%s%s\",\n\t\t\t       filt->action, filt->addr, at, fn);\n\t}\n\n\treturn err < 0 ? NULL : filter;\n}\n\nstatic int parse_addr_filter(struct evsel *evsel, const char *filter,\n\t\t\t     int max_nr)\n{\n\tstruct addr_filters filts;\n\tstruct addr_filter *filt;\n\tint err;\n\n\taddr_filters__init(&filts);\n\n\terr = addr_filters__parse_bare_filter(&filts, filter);\n\tif (err)\n\t\tgoto out_exit;\n\n\tif (filts.cnt > max_nr) {\n\t\tpr_err(\"Error: number of address filters (%d) exceeds maximum (%d)\\n\",\n\t\t       filts.cnt, max_nr);\n\t\terr = -EINVAL;\n\t\tgoto out_exit;\n\t}\n\n\tlist_for_each_entry(filt, &filts.head, list) {\n\t\tchar *new_filter;\n\n\t\terr = addr_filter__resolve_syms(filt);\n\t\tif (err)\n\t\t\tgoto out_exit;\n\n\t\tnew_filter = addr_filter__to_str(filt);\n\t\tif (!new_filter) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_exit;\n\t\t}\n\n\t\tif (evsel__append_addr_filter(evsel, new_filter)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_exit;\n\t\t}\n\t}\n\nout_exit:\n\taddr_filters__exit(&filts);\n\n\tif (err) {\n\t\tpr_err(\"Failed to parse address filter: '%s'\\n\", filter);\n\t\tpr_err(\"Filter format is: filter|start|stop|tracestop <start symbol or address> [/ <end symbol or size>] [@<file name>]\\n\");\n\t\tpr_err(\"Where multiple filters are separated by space or comma.\\n\");\n\t}\n\n\treturn err;\n}\n\nstatic int evsel__nr_addr_filter(struct evsel *evsel)\n{\n\tstruct perf_pmu *pmu = evsel__find_pmu(evsel);\n\tint nr_addr_filters = 0;\n\n\tif (!pmu)\n\t\treturn 0;\n\n\tperf_pmu__scan_file(pmu, \"nr_addr_filters\", \"%d\", &nr_addr_filters);\n\n\treturn nr_addr_filters;\n}\n\nint auxtrace_parse_filters(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tchar *filter;\n\tint err, max_nr;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tfilter = evsel->filter;\n\t\tmax_nr = evsel__nr_addr_filter(evsel);\n\t\tif (!filter || !max_nr)\n\t\t\tcontinue;\n\t\tevsel->filter = NULL;\n\t\terr = parse_addr_filter(evsel, filter, max_nr);\n\t\tfree(filter);\n\t\tif (err)\n\t\t\treturn err;\n\t\tpr_debug(\"Address filter: %s\\n\", evsel->filter);\n\t}\n\n\treturn 0;\n}\n\nint auxtrace__process_event(struct perf_session *session, union perf_event *event,\n\t\t\t    struct perf_sample *sample, struct perf_tool *tool)\n{\n\tif (!session->auxtrace)\n\t\treturn 0;\n\n\treturn session->auxtrace->process_event(session, event, sample, tool);\n}\n\nvoid auxtrace__dump_auxtrace_sample(struct perf_session *session,\n\t\t\t\t    struct perf_sample *sample)\n{\n\tif (!session->auxtrace || !session->auxtrace->dump_auxtrace_sample ||\n\t    auxtrace__dont_decode(session))\n\t\treturn;\n\n\tsession->auxtrace->dump_auxtrace_sample(session, sample);\n}\n\nint auxtrace__flush_events(struct perf_session *session, struct perf_tool *tool)\n{\n\tif (!session->auxtrace)\n\t\treturn 0;\n\n\treturn session->auxtrace->flush_events(session, tool);\n}\n\nvoid auxtrace__free_events(struct perf_session *session)\n{\n\tif (!session->auxtrace)\n\t\treturn;\n\n\treturn session->auxtrace->free_events(session);\n}\n\nvoid auxtrace__free(struct perf_session *session)\n{\n\tif (!session->auxtrace)\n\t\treturn;\n\n\treturn session->auxtrace->free(session);\n}\n\nbool auxtrace__evsel_is_auxtrace(struct perf_session *session,\n\t\t\t\t struct evsel *evsel)\n{\n\tif (!session->auxtrace || !session->auxtrace->evsel_is_auxtrace)\n\t\treturn false;\n\n\treturn session->auxtrace->evsel_is_auxtrace(session, evsel);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}