{
  "module_name": "bpf_off_cpu.c",
  "hash_id": "186afcfab5968a44cc178fa1fc2d8f86fb357321551563c8e2d2fd76bdef65ba",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/bpf_off_cpu.c",
  "human_readable_source": "\n#include \"util/bpf_counter.h\"\n#include \"util/debug.h\"\n#include \"util/evsel.h\"\n#include \"util/evlist.h\"\n#include \"util/off_cpu.h\"\n#include \"util/perf-hooks.h\"\n#include \"util/record.h\"\n#include \"util/session.h\"\n#include \"util/target.h\"\n#include \"util/cpumap.h\"\n#include \"util/thread_map.h\"\n#include \"util/cgroup.h\"\n#include \"util/strlist.h\"\n#include <bpf/bpf.h>\n\n#include \"bpf_skel/off_cpu.skel.h\"\n\n#define MAX_STACKS  32\n#define MAX_PROC  4096\n \n#define OFF_CPU_TIMESTAMP  (~0ull << 32)\n\nstatic struct off_cpu_bpf *skel;\n\nstruct off_cpu_key {\n\tu32 pid;\n\tu32 tgid;\n\tu32 stack_id;\n\tu32 state;\n\tu64 cgroup_id;\n};\n\nunion off_cpu_data {\n\tstruct perf_event_header hdr;\n\tu64 array[1024 / sizeof(u64)];\n};\n\nstatic int off_cpu_config(struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tstruct perf_event_attr attr = {\n\t\t.type\t= PERF_TYPE_SOFTWARE,\n\t\t.config = PERF_COUNT_SW_BPF_OUTPUT,\n\t\t.size\t= sizeof(attr),  \n\t};\n\tchar *evname = strdup(OFFCPU_EVENT);\n\n\tif (evname == NULL)\n\t\treturn -ENOMEM;\n\n\tevsel = evsel__new(&attr);\n\tif (!evsel) {\n\t\tfree(evname);\n\t\treturn -ENOMEM;\n\t}\n\n\tevsel->core.attr.freq = 1;\n\tevsel->core.attr.sample_period = 1;\n\t \n\tevsel->core.attr.sample_type = PERF_SAMPLE_CALLCHAIN;\n\n\tevlist__add(evlist, evsel);\n\n\tfree(evsel->name);\n\tevsel->name = evname;\n\n\treturn 0;\n}\n\nstatic void off_cpu_start(void *arg)\n{\n\tstruct evlist *evlist = arg;\n\n\t \n\tif (!skel->bss->has_cpu && !skel->bss->has_task &&\n\t    perf_thread_map__pid(evlist->core.threads, 0) != -1) {\n\t\tint fd;\n\t\tu32 pid;\n\t\tu8 val = 1;\n\n\t\tskel->bss->has_task = 1;\n\t\tskel->bss->uses_tgid = 1;\n\t\tfd = bpf_map__fd(skel->maps.task_filter);\n\t\tpid = perf_thread_map__pid(evlist->core.threads, 0);\n\t\tbpf_map_update_elem(fd, &pid, &val, BPF_ANY);\n\t}\n\n\tskel->bss->enabled = 1;\n}\n\nstatic void off_cpu_finish(void *arg __maybe_unused)\n{\n\tskel->bss->enabled = 0;\n\toff_cpu_bpf__destroy(skel);\n}\n\n \nstatic void check_sched_switch_args(void)\n{\n\tconst struct btf *btf = btf__load_vmlinux_btf();\n\tconst struct btf_type *t1, *t2, *t3;\n\tu32 type_id;\n\n\ttype_id = btf__find_by_name_kind(btf, \"btf_trace_sched_switch\",\n\t\t\t\t\t BTF_KIND_TYPEDEF);\n\tif ((s32)type_id < 0)\n\t\treturn;\n\n\tt1 = btf__type_by_id(btf, type_id);\n\tif (t1 == NULL)\n\t\treturn;\n\n\tt2 = btf__type_by_id(btf, t1->type);\n\tif (t2 == NULL || !btf_is_ptr(t2))\n\t\treturn;\n\n\tt3 = btf__type_by_id(btf, t2->type);\n\t \n\tif (t3 && btf_is_func_proto(t3) && btf_vlen(t3) == 5) {\n\t\t \n\t\tskel->rodata->has_prev_state = true;\n\t}\n}\n\nint off_cpu_prepare(struct evlist *evlist, struct target *target,\n\t\t    struct record_opts *opts)\n{\n\tint err, fd, i;\n\tint ncpus = 1, ntasks = 1, ncgrps = 1;\n\tstruct strlist *pid_slist = NULL;\n\tstruct str_node *pos;\n\n\tif (off_cpu_config(evlist) < 0) {\n\t\tpr_err(\"Failed to config off-cpu BPF event\\n\");\n\t\treturn -1;\n\t}\n\n\tskel = off_cpu_bpf__open();\n\tif (!skel) {\n\t\tpr_err(\"Failed to open off-cpu BPF skeleton\\n\");\n\t\treturn -1;\n\t}\n\n\t \n\tif (target->cpu_list) {\n\t\tncpus = perf_cpu_map__nr(evlist->core.user_requested_cpus);\n\t\tbpf_map__set_max_entries(skel->maps.cpu_filter, ncpus);\n\t}\n\n\tif (target->pid) {\n\t\tpid_slist = strlist__new(target->pid, NULL);\n\t\tif (!pid_slist) {\n\t\t\tpr_err(\"Failed to create a strlist for pid\\n\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tntasks = 0;\n\t\tstrlist__for_each_entry(pos, pid_slist) {\n\t\t\tchar *end_ptr;\n\t\t\tint pid = strtol(pos->s, &end_ptr, 10);\n\n\t\t\tif (pid == INT_MIN || pid == INT_MAX ||\n\t\t\t    (*end_ptr != '\\0' && *end_ptr != ','))\n\t\t\t\tcontinue;\n\n\t\t\tntasks++;\n\t\t}\n\n\t\tif (ntasks < MAX_PROC)\n\t\t\tntasks = MAX_PROC;\n\n\t\tbpf_map__set_max_entries(skel->maps.task_filter, ntasks);\n\t} else if (target__has_task(target)) {\n\t\tntasks = perf_thread_map__nr(evlist->core.threads);\n\t\tbpf_map__set_max_entries(skel->maps.task_filter, ntasks);\n\t} else if (target__none(target)) {\n\t\tbpf_map__set_max_entries(skel->maps.task_filter, MAX_PROC);\n\t}\n\n\tif (evlist__first(evlist)->cgrp) {\n\t\tncgrps = evlist->core.nr_entries - 1;  \n\t\tbpf_map__set_max_entries(skel->maps.cgroup_filter, ncgrps);\n\n\t\tif (!cgroup_is_v2(\"perf_event\"))\n\t\t\tskel->rodata->uses_cgroup_v1 = true;\n\t}\n\n\tif (opts->record_cgroup) {\n\t\tskel->rodata->needs_cgroup = true;\n\n\t\tif (!cgroup_is_v2(\"perf_event\"))\n\t\t\tskel->rodata->uses_cgroup_v1 = true;\n\t}\n\n\tset_max_rlimit();\n\tcheck_sched_switch_args();\n\n\terr = off_cpu_bpf__load(skel);\n\tif (err) {\n\t\tpr_err(\"Failed to load off-cpu skeleton\\n\");\n\t\tgoto out;\n\t}\n\n\tif (target->cpu_list) {\n\t\tu32 cpu;\n\t\tu8 val = 1;\n\n\t\tskel->bss->has_cpu = 1;\n\t\tfd = bpf_map__fd(skel->maps.cpu_filter);\n\n\t\tfor (i = 0; i < ncpus; i++) {\n\t\t\tcpu = perf_cpu_map__cpu(evlist->core.user_requested_cpus, i).cpu;\n\t\t\tbpf_map_update_elem(fd, &cpu, &val, BPF_ANY);\n\t\t}\n\t}\n\n\tif (target->pid) {\n\t\tu8 val = 1;\n\n\t\tskel->bss->has_task = 1;\n\t\tskel->bss->uses_tgid = 1;\n\t\tfd = bpf_map__fd(skel->maps.task_filter);\n\n\t\tstrlist__for_each_entry(pos, pid_slist) {\n\t\t\tchar *end_ptr;\n\t\t\tu32 tgid;\n\t\t\tint pid = strtol(pos->s, &end_ptr, 10);\n\n\t\t\tif (pid == INT_MIN || pid == INT_MAX ||\n\t\t\t    (*end_ptr != '\\0' && *end_ptr != ','))\n\t\t\t\tcontinue;\n\n\t\t\ttgid = pid;\n\t\t\tbpf_map_update_elem(fd, &tgid, &val, BPF_ANY);\n\t\t}\n\t} else if (target__has_task(target)) {\n\t\tu32 pid;\n\t\tu8 val = 1;\n\n\t\tskel->bss->has_task = 1;\n\t\tfd = bpf_map__fd(skel->maps.task_filter);\n\n\t\tfor (i = 0; i < ntasks; i++) {\n\t\t\tpid = perf_thread_map__pid(evlist->core.threads, i);\n\t\t\tbpf_map_update_elem(fd, &pid, &val, BPF_ANY);\n\t\t}\n\t}\n\n\tif (evlist__first(evlist)->cgrp) {\n\t\tstruct evsel *evsel;\n\t\tu8 val = 1;\n\n\t\tskel->bss->has_cgroup = 1;\n\t\tfd = bpf_map__fd(skel->maps.cgroup_filter);\n\n\t\tevlist__for_each_entry(evlist, evsel) {\n\t\t\tstruct cgroup *cgrp = evsel->cgrp;\n\n\t\t\tif (cgrp == NULL)\n\t\t\t\tcontinue;\n\n\t\t\tif (!cgrp->id && read_cgroup_id(cgrp) < 0) {\n\t\t\t\tpr_err(\"Failed to read cgroup id of %s\\n\",\n\t\t\t\t       cgrp->name);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tbpf_map_update_elem(fd, &cgrp->id, &val, BPF_ANY);\n\t\t}\n\t}\n\n\terr = off_cpu_bpf__attach(skel);\n\tif (err) {\n\t\tpr_err(\"Failed to attach off-cpu BPF skeleton\\n\");\n\t\tgoto out;\n\t}\n\n\tif (perf_hooks__set_hook(\"record_start\", off_cpu_start, evlist) ||\n\t    perf_hooks__set_hook(\"record_end\", off_cpu_finish, evlist)) {\n\t\tpr_err(\"Failed to attach off-cpu skeleton\\n\");\n\t\tgoto out;\n\t}\n\n\treturn 0;\n\nout:\n\toff_cpu_bpf__destroy(skel);\n\treturn -1;\n}\n\nint off_cpu_write(struct perf_session *session)\n{\n\tint bytes = 0, size;\n\tint fd, stack;\n\tu64 sample_type, val, sid = 0;\n\tstruct evsel *evsel;\n\tstruct perf_data_file *file = &session->data->file;\n\tstruct off_cpu_key prev, key;\n\tunion off_cpu_data data = {\n\t\t.hdr = {\n\t\t\t.type = PERF_RECORD_SAMPLE,\n\t\t\t.misc = PERF_RECORD_MISC_USER,\n\t\t},\n\t};\n\tu64 tstamp = OFF_CPU_TIMESTAMP;\n\n\tskel->bss->enabled = 0;\n\n\tevsel = evlist__find_evsel_by_str(session->evlist, OFFCPU_EVENT);\n\tif (evsel == NULL) {\n\t\tpr_err(\"%s evsel not found\\n\", OFFCPU_EVENT);\n\t\treturn 0;\n\t}\n\n\tsample_type = evsel->core.attr.sample_type;\n\n\tif (sample_type & ~OFFCPU_SAMPLE_TYPES) {\n\t\tpr_err(\"not supported sample type: %llx\\n\",\n\t\t       (unsigned long long)sample_type);\n\t\treturn -1;\n\t}\n\n\tif (sample_type & (PERF_SAMPLE_ID | PERF_SAMPLE_IDENTIFIER)) {\n\t\tif (evsel->core.id)\n\t\t\tsid = evsel->core.id[0];\n\t}\n\n\tfd = bpf_map__fd(skel->maps.off_cpu);\n\tstack = bpf_map__fd(skel->maps.stacks);\n\tmemset(&prev, 0, sizeof(prev));\n\n\twhile (!bpf_map_get_next_key(fd, &prev, &key)) {\n\t\tint n = 1;   \n\t\tint ip_pos = -1;\n\n\t\tbpf_map_lookup_elem(fd, &key, &val);\n\n\t\tif (sample_type & PERF_SAMPLE_IDENTIFIER)\n\t\t\tdata.array[n++] = sid;\n\t\tif (sample_type & PERF_SAMPLE_IP) {\n\t\t\tip_pos = n;\n\t\t\tdata.array[n++] = 0;   \n\t\t}\n\t\tif (sample_type & PERF_SAMPLE_TID)\n\t\t\tdata.array[n++] = (u64)key.pid << 32 | key.tgid;\n\t\tif (sample_type & PERF_SAMPLE_TIME)\n\t\t\tdata.array[n++] = tstamp;\n\t\tif (sample_type & PERF_SAMPLE_ID)\n\t\t\tdata.array[n++] = sid;\n\t\tif (sample_type & PERF_SAMPLE_CPU)\n\t\t\tdata.array[n++] = 0;\n\t\tif (sample_type & PERF_SAMPLE_PERIOD)\n\t\t\tdata.array[n++] = val;\n\t\tif (sample_type & PERF_SAMPLE_CALLCHAIN) {\n\t\t\tint len = 0;\n\n\t\t\t \n\t\t\tdata.array[n + 1] = PERF_CONTEXT_USER;\n\t\t\tdata.array[n + 2] = 0;\n\n\t\t\tbpf_map_lookup_elem(stack, &key.stack_id, &data.array[n + 2]);\n\t\t\twhile (data.array[n + 2 + len])\n\t\t\t\tlen++;\n\n\t\t\t \n\t\t\tdata.array[n] = len + 1;\n\n\t\t\t \n\t\t\tif (ip_pos >= 0)\n\t\t\t\tdata.array[ip_pos] = data.array[n + 2];\n\n\t\t\t \n\t\t\tn += len + 2;\n\t\t}\n\t\tif (sample_type & PERF_SAMPLE_CGROUP)\n\t\t\tdata.array[n++] = key.cgroup_id;\n\n\t\tsize = n * sizeof(u64);\n\t\tdata.hdr.size = size;\n\t\tbytes += size;\n\n\t\tif (perf_data_file__write(file, &data, size) < 0) {\n\t\t\tpr_err(\"failed to write perf data, error: %m\\n\");\n\t\t\treturn bytes;\n\t\t}\n\n\t\tprev = key;\n\t\t \n\t\ttstamp++;\n\t}\n\treturn bytes;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}