{
  "module_name": "header.c",
  "hash_id": "169c01335b0a308e1ea402c57b1b288b8a0135cfca90e1e2a122389a646bd000",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/header.c",
  "human_readable_source": "\n#include <errno.h>\n#include <inttypes.h>\n#include \"string2.h\"\n#include <sys/param.h>\n#include <sys/types.h>\n#include <byteswap.h>\n#include <unistd.h>\n#include <regex.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <linux/compiler.h>\n#include <linux/list.h>\n#include <linux/kernel.h>\n#include <linux/bitops.h>\n#include <linux/string.h>\n#include <linux/stringify.h>\n#include <linux/zalloc.h>\n#include <sys/stat.h>\n#include <sys/utsname.h>\n#include <linux/time64.h>\n#include <dirent.h>\n#ifdef HAVE_LIBBPF_SUPPORT\n#include <bpf/libbpf.h>\n#endif\n#include <perf/cpumap.h>\n#include <tools/libc_compat.h> \n\n#include \"dso.h\"\n#include \"evlist.h\"\n#include \"evsel.h\"\n#include \"util/evsel_fprintf.h\"\n#include \"header.h\"\n#include \"memswap.h\"\n#include \"trace-event.h\"\n#include \"session.h\"\n#include \"symbol.h\"\n#include \"debug.h\"\n#include \"cpumap.h\"\n#include \"pmu.h\"\n#include \"pmus.h\"\n#include \"vdso.h\"\n#include \"strbuf.h\"\n#include \"build-id.h\"\n#include \"data.h\"\n#include <api/fs/fs.h>\n#include \"asm/bug.h\"\n#include \"tool.h\"\n#include \"time-utils.h\"\n#include \"units.h\"\n#include \"util/util.h\" \n#include \"cputopo.h\"\n#include \"bpf-event.h\"\n#include \"bpf-utils.h\"\n#include \"clockid.h\"\n\n#include <linux/ctype.h>\n#include <internal/lib.h>\n\n#ifdef HAVE_LIBTRACEEVENT\n#include <traceevent/event-parse.h>\n#endif\n\n \nstatic const char *__perf_magic1 = \"PERFFILE\";\nstatic const u64 __perf_magic2    = 0x32454c4946524550ULL;\nstatic const u64 __perf_magic2_sw = 0x50455246494c4532ULL;\n\n#define PERF_MAGIC\t__perf_magic2\n\nconst char perf_version_string[] = PERF_VERSION;\n\nstruct perf_file_attr {\n\tstruct perf_event_attr\tattr;\n\tstruct perf_file_section\tids;\n};\n\nvoid perf_header__set_feat(struct perf_header *header, int feat)\n{\n\t__set_bit(feat, header->adds_features);\n}\n\nvoid perf_header__clear_feat(struct perf_header *header, int feat)\n{\n\t__clear_bit(feat, header->adds_features);\n}\n\nbool perf_header__has_feat(const struct perf_header *header, int feat)\n{\n\treturn test_bit(feat, header->adds_features);\n}\n\nstatic int __do_write_fd(struct feat_fd *ff, const void *buf, size_t size)\n{\n\tssize_t ret = writen(ff->fd, buf, size);\n\n\tif (ret != (ssize_t)size)\n\t\treturn ret < 0 ? (int)ret : -1;\n\treturn 0;\n}\n\nstatic int __do_write_buf(struct feat_fd *ff,  const void *buf, size_t size)\n{\n\t \n\tconst size_t max_size = 0xffff - sizeof(struct perf_event_header);\n\tsize_t new_size = ff->size;\n\tvoid *addr;\n\n\tif (size + ff->offset > max_size)\n\t\treturn -E2BIG;\n\n\twhile (size > (new_size - ff->offset))\n\t\tnew_size <<= 1;\n\tnew_size = min(max_size, new_size);\n\n\tif (ff->size < new_size) {\n\t\taddr = realloc(ff->buf, new_size);\n\t\tif (!addr)\n\t\t\treturn -ENOMEM;\n\t\tff->buf = addr;\n\t\tff->size = new_size;\n\t}\n\n\tmemcpy(ff->buf + ff->offset, buf, size);\n\tff->offset += size;\n\n\treturn 0;\n}\n\n \nint do_write(struct feat_fd *ff, const void *buf, size_t size)\n{\n\tif (!ff->buf)\n\t\treturn __do_write_fd(ff, buf, size);\n\treturn __do_write_buf(ff, buf, size);\n}\n\n \nstatic int do_write_bitmap(struct feat_fd *ff, unsigned long *set, u64 size)\n{\n\tu64 *p = (u64 *) set;\n\tint i, ret;\n\n\tret = do_write(ff, &size, sizeof(size));\n\tif (ret < 0)\n\t\treturn ret;\n\n\tfor (i = 0; (u64) i < BITS_TO_U64(size); i++) {\n\t\tret = do_write(ff, p + i, sizeof(*p));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nint write_padded(struct feat_fd *ff, const void *bf,\n\t\t size_t count, size_t count_aligned)\n{\n\tstatic const char zero_buf[NAME_ALIGN];\n\tint err = do_write(ff, bf, count);\n\n\tif (!err)\n\t\terr = do_write(ff, zero_buf, count_aligned - count);\n\n\treturn err;\n}\n\n#define string_size(str)\t\t\t\t\t\t\\\n\t(PERF_ALIGN((strlen(str) + 1), NAME_ALIGN) + sizeof(u32))\n\n \nstatic int do_write_string(struct feat_fd *ff, const char *str)\n{\n\tu32 len, olen;\n\tint ret;\n\n\tolen = strlen(str) + 1;\n\tlen = PERF_ALIGN(olen, NAME_ALIGN);\n\n\t \n\tret = do_write(ff, &len, sizeof(len));\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn write_padded(ff, str, olen, len);\n}\n\nstatic int __do_read_fd(struct feat_fd *ff, void *addr, ssize_t size)\n{\n\tssize_t ret = readn(ff->fd, addr, size);\n\n\tif (ret != size)\n\t\treturn ret < 0 ? (int)ret : -1;\n\treturn 0;\n}\n\nstatic int __do_read_buf(struct feat_fd *ff, void *addr, ssize_t size)\n{\n\tif (size > (ssize_t)ff->size - ff->offset)\n\t\treturn -1;\n\n\tmemcpy(addr, ff->buf + ff->offset, size);\n\tff->offset += size;\n\n\treturn 0;\n\n}\n\nstatic int __do_read(struct feat_fd *ff, void *addr, ssize_t size)\n{\n\tif (!ff->buf)\n\t\treturn __do_read_fd(ff, addr, size);\n\treturn __do_read_buf(ff, addr, size);\n}\n\nstatic int do_read_u32(struct feat_fd *ff, u32 *addr)\n{\n\tint ret;\n\n\tret = __do_read(ff, addr, sizeof(*addr));\n\tif (ret)\n\t\treturn ret;\n\n\tif (ff->ph->needs_swap)\n\t\t*addr = bswap_32(*addr);\n\treturn 0;\n}\n\nstatic int do_read_u64(struct feat_fd *ff, u64 *addr)\n{\n\tint ret;\n\n\tret = __do_read(ff, addr, sizeof(*addr));\n\tif (ret)\n\t\treturn ret;\n\n\tif (ff->ph->needs_swap)\n\t\t*addr = bswap_64(*addr);\n\treturn 0;\n}\n\nstatic char *do_read_string(struct feat_fd *ff)\n{\n\tu32 len;\n\tchar *buf;\n\n\tif (do_read_u32(ff, &len))\n\t\treturn NULL;\n\n\tbuf = malloc(len);\n\tif (!buf)\n\t\treturn NULL;\n\n\tif (!__do_read(ff, buf, len)) {\n\t\t \n\t\treturn buf;\n\t}\n\n\tfree(buf);\n\treturn NULL;\n}\n\n \nstatic int do_read_bitmap(struct feat_fd *ff, unsigned long **pset, u64 *psize)\n{\n\tunsigned long *set;\n\tu64 size, *p;\n\tint i, ret;\n\n\tret = do_read_u64(ff, &size);\n\tif (ret)\n\t\treturn ret;\n\n\tset = bitmap_zalloc(size);\n\tif (!set)\n\t\treturn -ENOMEM;\n\n\tp = (u64 *) set;\n\n\tfor (i = 0; (u64) i < BITS_TO_U64(size); i++) {\n\t\tret = do_read_u64(ff, p + i);\n\t\tif (ret < 0) {\n\t\t\tfree(set);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t*pset  = set;\n\t*psize = size;\n\treturn 0;\n}\n\n#ifdef HAVE_LIBTRACEEVENT\nstatic int write_tracing_data(struct feat_fd *ff,\n\t\t\t      struct evlist *evlist)\n{\n\tif (WARN(ff->buf, \"Error: calling %s in pipe-mode.\\n\", __func__))\n\t\treturn -1;\n\n\treturn read_tracing_data(ff->fd, &evlist->core.entries);\n}\n#endif\n\nstatic int write_build_id(struct feat_fd *ff,\n\t\t\t  struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_session *session;\n\tint err;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\tif (!perf_session__read_build_ids(session, true))\n\t\treturn -1;\n\n\tif (WARN(ff->buf, \"Error: calling %s in pipe-mode.\\n\", __func__))\n\t\treturn -1;\n\n\terr = perf_session__write_buildid_table(session, ff);\n\tif (err < 0) {\n\t\tpr_debug(\"failed to write buildid table\\n\");\n\t\treturn err;\n\t}\n\tperf_session__cache_build_ids(session);\n\n\treturn 0;\n}\n\nstatic int write_hostname(struct feat_fd *ff,\n\t\t\t  struct evlist *evlist __maybe_unused)\n{\n\tstruct utsname uts;\n\tint ret;\n\n\tret = uname(&uts);\n\tif (ret < 0)\n\t\treturn -1;\n\n\treturn do_write_string(ff, uts.nodename);\n}\n\nstatic int write_osrelease(struct feat_fd *ff,\n\t\t\t   struct evlist *evlist __maybe_unused)\n{\n\tstruct utsname uts;\n\tint ret;\n\n\tret = uname(&uts);\n\tif (ret < 0)\n\t\treturn -1;\n\n\treturn do_write_string(ff, uts.release);\n}\n\nstatic int write_arch(struct feat_fd *ff,\n\t\t      struct evlist *evlist __maybe_unused)\n{\n\tstruct utsname uts;\n\tint ret;\n\n\tret = uname(&uts);\n\tif (ret < 0)\n\t\treturn -1;\n\n\treturn do_write_string(ff, uts.machine);\n}\n\nstatic int write_version(struct feat_fd *ff,\n\t\t\t struct evlist *evlist __maybe_unused)\n{\n\treturn do_write_string(ff, perf_version_string);\n}\n\nstatic int __write_cpudesc(struct feat_fd *ff, const char *cpuinfo_proc)\n{\n\tFILE *file;\n\tchar *buf = NULL;\n\tchar *s, *p;\n\tconst char *search = cpuinfo_proc;\n\tsize_t len = 0;\n\tint ret = -1;\n\n\tif (!search)\n\t\treturn -1;\n\n\tfile = fopen(\"/proc/cpuinfo\", \"r\");\n\tif (!file)\n\t\treturn -1;\n\n\twhile (getline(&buf, &len, file) > 0) {\n\t\tret = strncmp(buf, search, strlen(search));\n\t\tif (!ret)\n\t\t\tbreak;\n\t}\n\n\tif (ret) {\n\t\tret = -1;\n\t\tgoto done;\n\t}\n\n\ts = buf;\n\n\tp = strchr(buf, ':');\n\tif (p && *(p+1) == ' ' && *(p+2))\n\t\ts = p + 2;\n\tp = strchr(s, '\\n');\n\tif (p)\n\t\t*p = '\\0';\n\n\t \n\tp = s;\n\twhile (*p) {\n\t\tif (isspace(*p)) {\n\t\t\tchar *r = p + 1;\n\t\t\tchar *q = skip_spaces(r);\n\t\t\t*p = ' ';\n\t\t\tif (q != (p+1))\n\t\t\t\twhile ((*r++ = *q++));\n\t\t}\n\t\tp++;\n\t}\n\tret = do_write_string(ff, s);\ndone:\n\tfree(buf);\n\tfclose(file);\n\treturn ret;\n}\n\nstatic int write_cpudesc(struct feat_fd *ff,\n\t\t       struct evlist *evlist __maybe_unused)\n{\n#if defined(__powerpc__) || defined(__hppa__) || defined(__sparc__)\n#define CPUINFO_PROC\t{ \"cpu\", }\n#elif defined(__s390__)\n#define CPUINFO_PROC\t{ \"vendor_id\", }\n#elif defined(__sh__)\n#define CPUINFO_PROC\t{ \"cpu type\", }\n#elif defined(__alpha__) || defined(__mips__)\n#define CPUINFO_PROC\t{ \"cpu model\", }\n#elif defined(__arm__)\n#define CPUINFO_PROC\t{ \"model name\", \"Processor\", }\n#elif defined(__arc__)\n#define CPUINFO_PROC\t{ \"Processor\", }\n#elif defined(__xtensa__)\n#define CPUINFO_PROC\t{ \"core ID\", }\n#elif defined(__loongarch__)\n#define CPUINFO_PROC\t{ \"Model Name\", }\n#else\n#define CPUINFO_PROC\t{ \"model name\", }\n#endif\n\tconst char *cpuinfo_procs[] = CPUINFO_PROC;\n#undef CPUINFO_PROC\n\tunsigned int i;\n\n\tfor (i = 0; i < ARRAY_SIZE(cpuinfo_procs); i++) {\n\t\tint ret;\n\t\tret = __write_cpudesc(ff, cpuinfo_procs[i]);\n\t\tif (ret >= 0)\n\t\t\treturn ret;\n\t}\n\treturn -1;\n}\n\n\nstatic int write_nrcpus(struct feat_fd *ff,\n\t\t\tstruct evlist *evlist __maybe_unused)\n{\n\tlong nr;\n\tu32 nrc, nra;\n\tint ret;\n\n\tnrc = cpu__max_present_cpu().cpu;\n\n\tnr = sysconf(_SC_NPROCESSORS_ONLN);\n\tif (nr < 0)\n\t\treturn -1;\n\n\tnra = (u32)(nr & UINT_MAX);\n\n\tret = do_write(ff, &nrc, sizeof(nrc));\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn do_write(ff, &nra, sizeof(nra));\n}\n\nstatic int write_event_desc(struct feat_fd *ff,\n\t\t\t    struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tu32 nre, nri, sz;\n\tint ret;\n\n\tnre = evlist->core.nr_entries;\n\n\t \n\tret = do_write(ff, &nre, sizeof(nre));\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tsz = (u32)sizeof(evsel->core.attr);\n\tret = do_write(ff, &sz, sizeof(sz));\n\tif (ret < 0)\n\t\treturn ret;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tret = do_write(ff, &evsel->core.attr, sz);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\t \n\t\tnri = evsel->core.ids;\n\t\tret = do_write(ff, &nri, sizeof(nri));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\t \n\t\tret = do_write_string(ff, evsel__name(evsel));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\t \n\t\tret = do_write(ff, evsel->core.id, evsel->core.ids * sizeof(u64));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int write_cmdline(struct feat_fd *ff,\n\t\t\t struct evlist *evlist __maybe_unused)\n{\n\tchar pbuf[MAXPATHLEN], *buf;\n\tint i, ret, n;\n\n\t \n\tbuf = perf_exe(pbuf, MAXPATHLEN);\n\n\t \n\tn = perf_env.nr_cmdline + 1;\n\n\tret = do_write(ff, &n, sizeof(n));\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = do_write_string(ff, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tfor (i = 0 ; i < perf_env.nr_cmdline; i++) {\n\t\tret = do_write_string(ff, perf_env.cmdline_argv[i]);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\n\nstatic int write_cpu_topology(struct feat_fd *ff,\n\t\t\t      struct evlist *evlist __maybe_unused)\n{\n\tstruct cpu_topology *tp;\n\tu32 i;\n\tint ret, j;\n\n\ttp = cpu_topology__new();\n\tif (!tp)\n\t\treturn -1;\n\n\tret = do_write(ff, &tp->package_cpus_lists, sizeof(tp->package_cpus_lists));\n\tif (ret < 0)\n\t\tgoto done;\n\n\tfor (i = 0; i < tp->package_cpus_lists; i++) {\n\t\tret = do_write_string(ff, tp->package_cpus_list[i]);\n\t\tif (ret < 0)\n\t\t\tgoto done;\n\t}\n\tret = do_write(ff, &tp->core_cpus_lists, sizeof(tp->core_cpus_lists));\n\tif (ret < 0)\n\t\tgoto done;\n\n\tfor (i = 0; i < tp->core_cpus_lists; i++) {\n\t\tret = do_write_string(ff, tp->core_cpus_list[i]);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t}\n\n\tret = perf_env__read_cpu_topology_map(&perf_env);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tfor (j = 0; j < perf_env.nr_cpus_avail; j++) {\n\t\tret = do_write(ff, &perf_env.cpu[j].core_id,\n\t\t\t       sizeof(perf_env.cpu[j].core_id));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = do_write(ff, &perf_env.cpu[j].socket_id,\n\t\t\t       sizeof(perf_env.cpu[j].socket_id));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tif (!tp->die_cpus_lists)\n\t\tgoto done;\n\n\tret = do_write(ff, &tp->die_cpus_lists, sizeof(tp->die_cpus_lists));\n\tif (ret < 0)\n\t\tgoto done;\n\n\tfor (i = 0; i < tp->die_cpus_lists; i++) {\n\t\tret = do_write_string(ff, tp->die_cpus_list[i]);\n\t\tif (ret < 0)\n\t\t\tgoto done;\n\t}\n\n\tfor (j = 0; j < perf_env.nr_cpus_avail; j++) {\n\t\tret = do_write(ff, &perf_env.cpu[j].die_id,\n\t\t\t       sizeof(perf_env.cpu[j].die_id));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\ndone:\n\tcpu_topology__delete(tp);\n\treturn ret;\n}\n\n\n\nstatic int write_total_mem(struct feat_fd *ff,\n\t\t\t   struct evlist *evlist __maybe_unused)\n{\n\tchar *buf = NULL;\n\tFILE *fp;\n\tsize_t len = 0;\n\tint ret = -1, n;\n\tuint64_t mem;\n\n\tfp = fopen(\"/proc/meminfo\", \"r\");\n\tif (!fp)\n\t\treturn -1;\n\n\twhile (getline(&buf, &len, fp) > 0) {\n\t\tret = strncmp(buf, \"MemTotal:\", 9);\n\t\tif (!ret)\n\t\t\tbreak;\n\t}\n\tif (!ret) {\n\t\tn = sscanf(buf, \"%*s %\"PRIu64, &mem);\n\t\tif (n == 1)\n\t\t\tret = do_write(ff, &mem, sizeof(mem));\n\t} else\n\t\tret = -1;\n\tfree(buf);\n\tfclose(fp);\n\treturn ret;\n}\n\nstatic int write_numa_topology(struct feat_fd *ff,\n\t\t\t       struct evlist *evlist __maybe_unused)\n{\n\tstruct numa_topology *tp;\n\tint ret = -1;\n\tu32 i;\n\n\ttp = numa_topology__new();\n\tif (!tp)\n\t\treturn -ENOMEM;\n\n\tret = do_write(ff, &tp->nr, sizeof(u32));\n\tif (ret < 0)\n\t\tgoto err;\n\n\tfor (i = 0; i < tp->nr; i++) {\n\t\tstruct numa_topology_node *n = &tp->nodes[i];\n\n\t\tret = do_write(ff, &n->node, sizeof(u32));\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\n\t\tret = do_write(ff, &n->mem_total, sizeof(u64));\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = do_write(ff, &n->mem_free, sizeof(u64));\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = do_write_string(ff, n->cpus);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\t}\n\n\tret = 0;\n\nerr:\n\tnuma_topology__delete(tp);\n\treturn ret;\n}\n\n \n\nstatic int write_pmu_mappings(struct feat_fd *ff,\n\t\t\t      struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_pmu *pmu = NULL;\n\tu32 pmu_num = 0;\n\tint ret;\n\n\t \n\twhile ((pmu = perf_pmus__scan(pmu)))\n\t\tpmu_num++;\n\n\tret = do_write(ff, &pmu_num, sizeof(pmu_num));\n\tif (ret < 0)\n\t\treturn ret;\n\n\twhile ((pmu = perf_pmus__scan(pmu))) {\n\t\tret = do_write(ff, &pmu->type, sizeof(pmu->type));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = do_write_string(ff, pmu->name);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int write_group_desc(struct feat_fd *ff,\n\t\t\t    struct evlist *evlist)\n{\n\tu32 nr_groups = evlist__nr_groups(evlist);\n\tstruct evsel *evsel;\n\tint ret;\n\n\tret = do_write(ff, &nr_groups, sizeof(nr_groups));\n\tif (ret < 0)\n\t\treturn ret;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel__is_group_leader(evsel) && evsel->core.nr_members > 1) {\n\t\t\tconst char *name = evsel->group_name ?: \"{anon_group}\";\n\t\t\tu32 leader_idx = evsel->core.idx;\n\t\t\tu32 nr_members = evsel->core.nr_members;\n\n\t\t\tret = do_write_string(ff, name);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tret = do_write(ff, &leader_idx, sizeof(leader_idx));\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tret = do_write(ff, &nr_members, sizeof(nr_members));\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nchar * __weak get_cpuid_str(struct perf_pmu *pmu __maybe_unused)\n{\n\treturn NULL;\n}\n\n \nint __weak strcmp_cpuid_str(const char *mapcpuid, const char *cpuid)\n{\n\tregex_t re;\n\tregmatch_t pmatch[1];\n\tint match;\n\n\tif (regcomp(&re, mapcpuid, REG_EXTENDED) != 0) {\n\t\t \n\t\tpr_info(\"Invalid regular expression %s\\n\", mapcpuid);\n\t\treturn 1;\n\t}\n\n\tmatch = !regexec(&re, cpuid, 1, pmatch, 0);\n\tregfree(&re);\n\tif (match) {\n\t\tsize_t match_len = (pmatch[0].rm_eo - pmatch[0].rm_so);\n\n\t\t \n\t\tif (match_len == strlen(cpuid))\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\n \nint __weak get_cpuid(char *buffer __maybe_unused, size_t sz __maybe_unused)\n{\n\treturn ENOSYS;  \n}\n\nstatic int write_cpuid(struct feat_fd *ff,\n\t\t       struct evlist *evlist __maybe_unused)\n{\n\tchar buffer[64];\n\tint ret;\n\n\tret = get_cpuid(buffer, sizeof(buffer));\n\tif (ret)\n\t\treturn -1;\n\n\treturn do_write_string(ff, buffer);\n}\n\nstatic int write_branch_stack(struct feat_fd *ff __maybe_unused,\n\t\t\t      struct evlist *evlist __maybe_unused)\n{\n\treturn 0;\n}\n\nstatic int write_auxtrace(struct feat_fd *ff,\n\t\t\t  struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_session *session;\n\tint err;\n\n\tif (WARN(ff->buf, \"Error: calling %s in pipe-mode.\\n\", __func__))\n\t\treturn -1;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\terr = auxtrace_index__write(ff->fd, &session->auxtrace_index);\n\tif (err < 0)\n\t\tpr_err(\"Failed to write auxtrace index\\n\");\n\treturn err;\n}\n\nstatic int write_clockid(struct feat_fd *ff,\n\t\t\t struct evlist *evlist __maybe_unused)\n{\n\treturn do_write(ff, &ff->ph->env.clock.clockid_res_ns,\n\t\t\tsizeof(ff->ph->env.clock.clockid_res_ns));\n}\n\nstatic int write_clock_data(struct feat_fd *ff,\n\t\t\t    struct evlist *evlist __maybe_unused)\n{\n\tu64 *data64;\n\tu32 data32;\n\tint ret;\n\n\t \n\tdata32 = 1;\n\n\tret = do_write(ff, &data32, sizeof(data32));\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tdata32 = ff->ph->env.clock.clockid;\n\n\tret = do_write(ff, &data32, sizeof(data32));\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tdata64 = &ff->ph->env.clock.tod_ns;\n\n\tret = do_write(ff, data64, sizeof(*data64));\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tdata64 = &ff->ph->env.clock.clockid_ns;\n\n\treturn do_write(ff, data64, sizeof(*data64));\n}\n\nstatic int write_hybrid_topology(struct feat_fd *ff,\n\t\t\t\t struct evlist *evlist __maybe_unused)\n{\n\tstruct hybrid_topology *tp;\n\tint ret;\n\tu32 i;\n\n\ttp = hybrid_topology__new();\n\tif (!tp)\n\t\treturn -ENOENT;\n\n\tret = do_write(ff, &tp->nr, sizeof(u32));\n\tif (ret < 0)\n\t\tgoto err;\n\n\tfor (i = 0; i < tp->nr; i++) {\n\t\tstruct hybrid_topology_node *n = &tp->nodes[i];\n\n\t\tret = do_write_string(ff, n->pmu_name);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\n\t\tret = do_write_string(ff, n->cpus);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\t}\n\n\tret = 0;\n\nerr:\n\thybrid_topology__delete(tp);\n\treturn ret;\n}\n\nstatic int write_dir_format(struct feat_fd *ff,\n\t\t\t    struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_session *session;\n\tstruct perf_data *data;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\tdata = session->data;\n\n\tif (WARN_ON(!perf_data__is_dir(data)))\n\t\treturn -1;\n\n\treturn do_write(ff, &data->dir.version, sizeof(data->dir.version));\n}\n\n \nint is_cpu_online(unsigned int cpu)\n{\n\tchar *str;\n\tsize_t strlen;\n\tchar buf[256];\n\tint status = -1;\n\tstruct stat statbuf;\n\n\tsnprintf(buf, sizeof(buf),\n\t\t\"/sys/devices/system/cpu/cpu%d\", cpu);\n\tif (stat(buf, &statbuf) != 0)\n\t\treturn 0;\n\n\t \n\tsnprintf(buf, sizeof(buf),\n\t\t\"/sys/devices/system/cpu/cpu%d/online\", cpu);\n\tif (stat(buf, &statbuf) != 0)\n\t\treturn 1;\n\n\t \n\tsnprintf(buf, sizeof(buf),\n\t\t\"devices/system/cpu/cpu%d/online\", cpu);\n\n\tif (sysfs__read_str(buf, &str, &strlen) < 0)\n\t\treturn status;\n\n\tstatus = atoi(str);\n\n\tfree(str);\n\treturn status;\n}\n\n#ifdef HAVE_LIBBPF_SUPPORT\nstatic int write_bpf_prog_info(struct feat_fd *ff,\n\t\t\t       struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_env *env = &ff->ph->env;\n\tstruct rb_root *root;\n\tstruct rb_node *next;\n\tint ret;\n\n\tdown_read(&env->bpf_progs.lock);\n\n\tret = do_write(ff, &env->bpf_progs.infos_cnt,\n\t\t       sizeof(env->bpf_progs.infos_cnt));\n\tif (ret < 0)\n\t\tgoto out;\n\n\troot = &env->bpf_progs.infos;\n\tnext = rb_first(root);\n\twhile (next) {\n\t\tstruct bpf_prog_info_node *node;\n\t\tsize_t len;\n\n\t\tnode = rb_entry(next, struct bpf_prog_info_node, rb_node);\n\t\tnext = rb_next(&node->rb_node);\n\t\tlen = sizeof(struct perf_bpil) +\n\t\t\tnode->info_linear->data_len;\n\n\t\t \n\t\tbpil_addr_to_offs(node->info_linear);\n\t\tret = do_write(ff, node->info_linear, len);\n\t\t \n\t\tbpil_offs_to_addr(node->info_linear);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\nout:\n\tup_read(&env->bpf_progs.lock);\n\treturn ret;\n}\n\nstatic int write_bpf_btf(struct feat_fd *ff,\n\t\t\t struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_env *env = &ff->ph->env;\n\tstruct rb_root *root;\n\tstruct rb_node *next;\n\tint ret;\n\n\tdown_read(&env->bpf_progs.lock);\n\n\tret = do_write(ff, &env->bpf_progs.btfs_cnt,\n\t\t       sizeof(env->bpf_progs.btfs_cnt));\n\n\tif (ret < 0)\n\t\tgoto out;\n\n\troot = &env->bpf_progs.btfs;\n\tnext = rb_first(root);\n\twhile (next) {\n\t\tstruct btf_node *node;\n\n\t\tnode = rb_entry(next, struct btf_node, rb_node);\n\t\tnext = rb_next(&node->rb_node);\n\t\tret = do_write(ff, &node->id,\n\t\t\t       sizeof(u32) * 2 + node->data_size);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\nout:\n\tup_read(&env->bpf_progs.lock);\n\treturn ret;\n}\n#endif \n\nstatic int cpu_cache_level__sort(const void *a, const void *b)\n{\n\tstruct cpu_cache_level *cache_a = (struct cpu_cache_level *)a;\n\tstruct cpu_cache_level *cache_b = (struct cpu_cache_level *)b;\n\n\treturn cache_a->level - cache_b->level;\n}\n\nstatic bool cpu_cache_level__cmp(struct cpu_cache_level *a, struct cpu_cache_level *b)\n{\n\tif (a->level != b->level)\n\t\treturn false;\n\n\tif (a->line_size != b->line_size)\n\t\treturn false;\n\n\tif (a->sets != b->sets)\n\t\treturn false;\n\n\tif (a->ways != b->ways)\n\t\treturn false;\n\n\tif (strcmp(a->type, b->type))\n\t\treturn false;\n\n\tif (strcmp(a->size, b->size))\n\t\treturn false;\n\n\tif (strcmp(a->map, b->map))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int cpu_cache_level__read(struct cpu_cache_level *cache, u32 cpu, u16 level)\n{\n\tchar path[PATH_MAX], file[PATH_MAX];\n\tstruct stat st;\n\tsize_t len;\n\n\tscnprintf(path, PATH_MAX, \"devices/system/cpu/cpu%d/cache/index%d/\", cpu, level);\n\tscnprintf(file, PATH_MAX, \"%s/%s\", sysfs__mountpoint(), path);\n\n\tif (stat(file, &st))\n\t\treturn 1;\n\n\tscnprintf(file, PATH_MAX, \"%s/level\", path);\n\tif (sysfs__read_int(file, (int *) &cache->level))\n\t\treturn -1;\n\n\tscnprintf(file, PATH_MAX, \"%s/coherency_line_size\", path);\n\tif (sysfs__read_int(file, (int *) &cache->line_size))\n\t\treturn -1;\n\n\tscnprintf(file, PATH_MAX, \"%s/number_of_sets\", path);\n\tif (sysfs__read_int(file, (int *) &cache->sets))\n\t\treturn -1;\n\n\tscnprintf(file, PATH_MAX, \"%s/ways_of_associativity\", path);\n\tif (sysfs__read_int(file, (int *) &cache->ways))\n\t\treturn -1;\n\n\tscnprintf(file, PATH_MAX, \"%s/type\", path);\n\tif (sysfs__read_str(file, &cache->type, &len))\n\t\treturn -1;\n\n\tcache->type[len] = 0;\n\tcache->type = strim(cache->type);\n\n\tscnprintf(file, PATH_MAX, \"%s/size\", path);\n\tif (sysfs__read_str(file, &cache->size, &len)) {\n\t\tzfree(&cache->type);\n\t\treturn -1;\n\t}\n\n\tcache->size[len] = 0;\n\tcache->size = strim(cache->size);\n\n\tscnprintf(file, PATH_MAX, \"%s/shared_cpu_list\", path);\n\tif (sysfs__read_str(file, &cache->map, &len)) {\n\t\tzfree(&cache->size);\n\t\tzfree(&cache->type);\n\t\treturn -1;\n\t}\n\n\tcache->map[len] = 0;\n\tcache->map = strim(cache->map);\n\treturn 0;\n}\n\nstatic void cpu_cache_level__fprintf(FILE *out, struct cpu_cache_level *c)\n{\n\tfprintf(out, \"L%d %-15s %8s [%s]\\n\", c->level, c->type, c->size, c->map);\n}\n\n \nint build_caches_for_cpu(u32 cpu, struct cpu_cache_level caches[], u32 *cntp)\n{\n\tu16 level;\n\n\tfor (level = 0; level < MAX_CACHE_LVL; level++) {\n\t\tstruct cpu_cache_level c;\n\t\tint err;\n\t\tu32 i;\n\n\t\terr = cpu_cache_level__read(&c, cpu, level);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (err == 1)\n\t\t\tbreak;\n\n\t\tfor (i = 0; i < *cntp; i++) {\n\t\t\tif (cpu_cache_level__cmp(&c, &caches[i]))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (i == *cntp) {\n\t\t\tcaches[*cntp] = c;\n\t\t\t*cntp = *cntp + 1;\n\t\t} else\n\t\t\tcpu_cache_level__free(&c);\n\t}\n\n\treturn 0;\n}\n\nstatic int build_caches(struct cpu_cache_level caches[], u32 *cntp)\n{\n\tu32 nr, cpu, cnt = 0;\n\n\tnr = cpu__max_cpu().cpu;\n\n\tfor (cpu = 0; cpu < nr; cpu++) {\n\t\tint ret = build_caches_for_cpu(cpu, caches, &cnt);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\t*cntp = cnt;\n\treturn 0;\n}\n\nstatic int write_cache(struct feat_fd *ff,\n\t\t       struct evlist *evlist __maybe_unused)\n{\n\tu32 max_caches = cpu__max_cpu().cpu * MAX_CACHE_LVL;\n\tstruct cpu_cache_level caches[max_caches];\n\tu32 cnt = 0, i, version = 1;\n\tint ret;\n\n\tret = build_caches(caches, &cnt);\n\tif (ret)\n\t\tgoto out;\n\n\tqsort(&caches, cnt, sizeof(struct cpu_cache_level), cpu_cache_level__sort);\n\n\tret = do_write(ff, &version, sizeof(u32));\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = do_write(ff, &cnt, sizeof(u32));\n\tif (ret < 0)\n\t\tgoto out;\n\n\tfor (i = 0; i < cnt; i++) {\n\t\tstruct cpu_cache_level *c = &caches[i];\n\n\t\t#define _W(v)\t\t\t\t\t\\\n\t\t\tret = do_write(ff, &c->v, sizeof(u32));\t\\\n\t\t\tif (ret < 0)\t\t\t\t\\\n\t\t\t\tgoto out;\n\n\t\t_W(level)\n\t\t_W(line_size)\n\t\t_W(sets)\n\t\t_W(ways)\n\t\t#undef _W\n\n\t\t#define _W(v)\t\t\t\t\t\t\\\n\t\t\tret = do_write_string(ff, (const char *) c->v);\t\\\n\t\t\tif (ret < 0)\t\t\t\t\t\\\n\t\t\t\tgoto out;\n\n\t\t_W(type)\n\t\t_W(size)\n\t\t_W(map)\n\t\t#undef _W\n\t}\n\nout:\n\tfor (i = 0; i < cnt; i++)\n\t\tcpu_cache_level__free(&caches[i]);\n\treturn ret;\n}\n\nstatic int write_stat(struct feat_fd *ff __maybe_unused,\n\t\t      struct evlist *evlist __maybe_unused)\n{\n\treturn 0;\n}\n\nstatic int write_sample_time(struct feat_fd *ff,\n\t\t\t     struct evlist *evlist)\n{\n\tint ret;\n\n\tret = do_write(ff, &evlist->first_sample_time,\n\t\t       sizeof(evlist->first_sample_time));\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn do_write(ff, &evlist->last_sample_time,\n\t\t\tsizeof(evlist->last_sample_time));\n}\n\n\nstatic int memory_node__read(struct memory_node *n, unsigned long idx)\n{\n\tunsigned int phys, size = 0;\n\tchar path[PATH_MAX];\n\tstruct dirent *ent;\n\tDIR *dir;\n\n#define for_each_memory(mem, dir)\t\t\t\t\t\\\n\twhile ((ent = readdir(dir)))\t\t\t\t\t\\\n\t\tif (strcmp(ent->d_name, \".\") &&\t\t\t\t\\\n\t\t    strcmp(ent->d_name, \"..\") &&\t\t\t\\\n\t\t    sscanf(ent->d_name, \"memory%u\", &mem) == 1)\n\n\tscnprintf(path, PATH_MAX,\n\t\t  \"%s/devices/system/node/node%lu\",\n\t\t  sysfs__mountpoint(), idx);\n\n\tdir = opendir(path);\n\tif (!dir) {\n\t\tpr_warning(\"failed: can't open memory sysfs data\\n\");\n\t\treturn -1;\n\t}\n\n\tfor_each_memory(phys, dir) {\n\t\tsize = max(phys, size);\n\t}\n\n\tsize++;\n\n\tn->set = bitmap_zalloc(size);\n\tif (!n->set) {\n\t\tclosedir(dir);\n\t\treturn -ENOMEM;\n\t}\n\n\tn->node = idx;\n\tn->size = size;\n\n\trewinddir(dir);\n\n\tfor_each_memory(phys, dir) {\n\t\t__set_bit(phys, n->set);\n\t}\n\n\tclosedir(dir);\n\treturn 0;\n}\n\nstatic void memory_node__delete_nodes(struct memory_node *nodesp, u64 cnt)\n{\n\tfor (u64 i = 0; i < cnt; i++)\n\t\tbitmap_free(nodesp[i].set);\n\n\tfree(nodesp);\n}\n\nstatic int memory_node__sort(const void *a, const void *b)\n{\n\tconst struct memory_node *na = a;\n\tconst struct memory_node *nb = b;\n\n\treturn na->node - nb->node;\n}\n\nstatic int build_mem_topology(struct memory_node **nodesp, u64 *cntp)\n{\n\tchar path[PATH_MAX];\n\tstruct dirent *ent;\n\tDIR *dir;\n\tint ret = 0;\n\tsize_t cnt = 0, size = 0;\n\tstruct memory_node *nodes = NULL;\n\n\tscnprintf(path, PATH_MAX, \"%s/devices/system/node/\",\n\t\t  sysfs__mountpoint());\n\n\tdir = opendir(path);\n\tif (!dir) {\n\t\tpr_debug2(\"%s: couldn't read %s, does this arch have topology information?\\n\",\n\t\t\t  __func__, path);\n\t\treturn -1;\n\t}\n\n\twhile (!ret && (ent = readdir(dir))) {\n\t\tunsigned int idx;\n\t\tint r;\n\n\t\tif (!strcmp(ent->d_name, \".\") ||\n\t\t    !strcmp(ent->d_name, \"..\"))\n\t\t\tcontinue;\n\n\t\tr = sscanf(ent->d_name, \"node%u\", &idx);\n\t\tif (r != 1)\n\t\t\tcontinue;\n\n\t\tif (cnt >= size) {\n\t\t\tstruct memory_node *new_nodes =\n\t\t\t\treallocarray(nodes, cnt + 4, sizeof(*nodes));\n\n\t\t\tif (!new_nodes) {\n\t\t\t\tpr_err(\"Failed to write MEM_TOPOLOGY, size %zd nodes\\n\", size);\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tnodes = new_nodes;\n\t\t\tsize += 4;\n\t\t}\n\t\tret = memory_node__read(&nodes[cnt], idx);\n\t\tif (!ret)\n\t\t\tcnt += 1;\n\t}\nout:\n\tclosedir(dir);\n\tif (!ret) {\n\t\t*cntp = cnt;\n\t\t*nodesp = nodes;\n\t\tqsort(nodes, cnt, sizeof(nodes[0]), memory_node__sort);\n\t} else\n\t\tmemory_node__delete_nodes(nodes, cnt);\n\n\treturn ret;\n}\n\n \nstatic int write_mem_topology(struct feat_fd *ff __maybe_unused,\n\t\t\t      struct evlist *evlist __maybe_unused)\n{\n\tstruct memory_node *nodes = NULL;\n\tu64 bsize, version = 1, i, nr = 0;\n\tint ret;\n\n\tret = sysfs__read_xll(\"devices/system/memory/block_size_bytes\",\n\t\t\t      (unsigned long long *) &bsize);\n\tif (ret)\n\t\treturn ret;\n\n\tret = build_mem_topology(&nodes, &nr);\n\tif (ret)\n\t\treturn ret;\n\n\tret = do_write(ff, &version, sizeof(version));\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = do_write(ff, &bsize, sizeof(bsize));\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = do_write(ff, &nr, sizeof(nr));\n\tif (ret < 0)\n\t\tgoto out;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tstruct memory_node *n = &nodes[i];\n\n\t\t#define _W(v)\t\t\t\t\t\t\\\n\t\t\tret = do_write(ff, &n->v, sizeof(n->v));\t\\\n\t\t\tif (ret < 0)\t\t\t\t\t\\\n\t\t\t\tgoto out;\n\n\t\t_W(node)\n\t\t_W(size)\n\n\t\t#undef _W\n\n\t\tret = do_write_bitmap(ff, n->set, n->size);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\n\nout:\n\tmemory_node__delete_nodes(nodes, nr);\n\treturn ret;\n}\n\nstatic int write_compressed(struct feat_fd *ff __maybe_unused,\n\t\t\t    struct evlist *evlist __maybe_unused)\n{\n\tint ret;\n\n\tret = do_write(ff, &(ff->ph->env.comp_ver), sizeof(ff->ph->env.comp_ver));\n\tif (ret)\n\t\treturn ret;\n\n\tret = do_write(ff, &(ff->ph->env.comp_type), sizeof(ff->ph->env.comp_type));\n\tif (ret)\n\t\treturn ret;\n\n\tret = do_write(ff, &(ff->ph->env.comp_level), sizeof(ff->ph->env.comp_level));\n\tif (ret)\n\t\treturn ret;\n\n\tret = do_write(ff, &(ff->ph->env.comp_ratio), sizeof(ff->ph->env.comp_ratio));\n\tif (ret)\n\t\treturn ret;\n\n\treturn do_write(ff, &(ff->ph->env.comp_mmap_len), sizeof(ff->ph->env.comp_mmap_len));\n}\n\nstatic int __write_pmu_caps(struct feat_fd *ff, struct perf_pmu *pmu,\n\t\t\t    bool write_pmu)\n{\n\tstruct perf_pmu_caps *caps = NULL;\n\tint ret;\n\n\tret = do_write(ff, &pmu->nr_caps, sizeof(pmu->nr_caps));\n\tif (ret < 0)\n\t\treturn ret;\n\n\tlist_for_each_entry(caps, &pmu->caps, list) {\n\t\tret = do_write_string(ff, caps->name);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = do_write_string(ff, caps->value);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tif (write_pmu) {\n\t\tret = do_write_string(ff, pmu->name);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic int write_cpu_pmu_caps(struct feat_fd *ff,\n\t\t\t      struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_pmu *cpu_pmu = perf_pmus__find(\"cpu\");\n\tint ret;\n\n\tif (!cpu_pmu)\n\t\treturn -ENOENT;\n\n\tret = perf_pmu__caps_parse(cpu_pmu);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn __write_pmu_caps(ff, cpu_pmu, false);\n}\n\nstatic int write_pmu_caps(struct feat_fd *ff,\n\t\t\t  struct evlist *evlist __maybe_unused)\n{\n\tstruct perf_pmu *pmu = NULL;\n\tint nr_pmu = 0;\n\tint ret;\n\n\twhile ((pmu = perf_pmus__scan(pmu))) {\n\t\tif (!strcmp(pmu->name, \"cpu\")) {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\t\tif (perf_pmu__caps_parse(pmu) <= 0)\n\t\t\tcontinue;\n\t\tnr_pmu++;\n\t}\n\n\tret = do_write(ff, &nr_pmu, sizeof(nr_pmu));\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (!nr_pmu)\n\t\treturn 0;\n\n\t \n\tpmu = NULL;\n\twhile ((pmu = perf_pmus__scan(pmu))) {\n\t\tif (!strcmp(pmu->name, \"cpu\")) {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\t\tif (perf_pmu__caps_parse(pmu) <= 0)\n\t\t\tcontinue;\n\t\tret = __write_pmu_caps(ff, pmu, true);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic void print_hostname(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# hostname : %s\\n\", ff->ph->env.hostname);\n}\n\nstatic void print_osrelease(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# os release : %s\\n\", ff->ph->env.os_release);\n}\n\nstatic void print_arch(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# arch : %s\\n\", ff->ph->env.arch);\n}\n\nstatic void print_cpudesc(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# cpudesc : %s\\n\", ff->ph->env.cpu_desc);\n}\n\nstatic void print_nrcpus(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# nrcpus online : %u\\n\", ff->ph->env.nr_cpus_online);\n\tfprintf(fp, \"# nrcpus avail : %u\\n\", ff->ph->env.nr_cpus_avail);\n}\n\nstatic void print_version(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# perf version : %s\\n\", ff->ph->env.version);\n}\n\nstatic void print_cmdline(struct feat_fd *ff, FILE *fp)\n{\n\tint nr, i;\n\n\tnr = ff->ph->env.nr_cmdline;\n\n\tfprintf(fp, \"# cmdline : \");\n\n\tfor (i = 0; i < nr; i++) {\n\t\tchar *argv_i = strdup(ff->ph->env.cmdline_argv[i]);\n\t\tif (!argv_i) {\n\t\t\tfprintf(fp, \"%s \", ff->ph->env.cmdline_argv[i]);\n\t\t} else {\n\t\t\tchar *mem = argv_i;\n\t\t\tdo {\n\t\t\t\tchar *quote = strchr(argv_i, '\\'');\n\t\t\t\tif (!quote)\n\t\t\t\t\tbreak;\n\t\t\t\t*quote++ = '\\0';\n\t\t\t\tfprintf(fp, \"%s\\\\\\'\", argv_i);\n\t\t\t\targv_i = quote;\n\t\t\t} while (1);\n\t\t\tfprintf(fp, \"%s \", argv_i);\n\t\t\tfree(mem);\n\t\t}\n\t}\n\tfputc('\\n', fp);\n}\n\nstatic void print_cpu_topology(struct feat_fd *ff, FILE *fp)\n{\n\tstruct perf_header *ph = ff->ph;\n\tint cpu_nr = ph->env.nr_cpus_avail;\n\tint nr, i;\n\tchar *str;\n\n\tnr = ph->env.nr_sibling_cores;\n\tstr = ph->env.sibling_cores;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tfprintf(fp, \"# sibling sockets : %s\\n\", str);\n\t\tstr += strlen(str) + 1;\n\t}\n\n\tif (ph->env.nr_sibling_dies) {\n\t\tnr = ph->env.nr_sibling_dies;\n\t\tstr = ph->env.sibling_dies;\n\n\t\tfor (i = 0; i < nr; i++) {\n\t\t\tfprintf(fp, \"# sibling dies    : %s\\n\", str);\n\t\t\tstr += strlen(str) + 1;\n\t\t}\n\t}\n\n\tnr = ph->env.nr_sibling_threads;\n\tstr = ph->env.sibling_threads;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tfprintf(fp, \"# sibling threads : %s\\n\", str);\n\t\tstr += strlen(str) + 1;\n\t}\n\n\tif (ph->env.nr_sibling_dies) {\n\t\tif (ph->env.cpu != NULL) {\n\t\t\tfor (i = 0; i < cpu_nr; i++)\n\t\t\t\tfprintf(fp, \"# CPU %d: Core ID %d, \"\n\t\t\t\t\t    \"Die ID %d, Socket ID %d\\n\",\n\t\t\t\t\t    i, ph->env.cpu[i].core_id,\n\t\t\t\t\t    ph->env.cpu[i].die_id,\n\t\t\t\t\t    ph->env.cpu[i].socket_id);\n\t\t} else\n\t\t\tfprintf(fp, \"# Core ID, Die ID and Socket ID \"\n\t\t\t\t    \"information is not available\\n\");\n\t} else {\n\t\tif (ph->env.cpu != NULL) {\n\t\t\tfor (i = 0; i < cpu_nr; i++)\n\t\t\t\tfprintf(fp, \"# CPU %d: Core ID %d, \"\n\t\t\t\t\t    \"Socket ID %d\\n\",\n\t\t\t\t\t    i, ph->env.cpu[i].core_id,\n\t\t\t\t\t    ph->env.cpu[i].socket_id);\n\t\t} else\n\t\t\tfprintf(fp, \"# Core ID and Socket ID \"\n\t\t\t\t    \"information is not available\\n\");\n\t}\n}\n\nstatic void print_clockid(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# clockid frequency: %\"PRIu64\" MHz\\n\",\n\t\tff->ph->env.clock.clockid_res_ns * 1000);\n}\n\nstatic void print_clock_data(struct feat_fd *ff, FILE *fp)\n{\n\tstruct timespec clockid_ns;\n\tchar tstr[64], date[64];\n\tstruct timeval tod_ns;\n\tclockid_t clockid;\n\tstruct tm ltime;\n\tu64 ref;\n\n\tif (!ff->ph->env.clock.enabled) {\n\t\tfprintf(fp, \"# reference time disabled\\n\");\n\t\treturn;\n\t}\n\n\t \n\tref = ff->ph->env.clock.tod_ns;\n\ttod_ns.tv_sec = ref / NSEC_PER_SEC;\n\tref -= tod_ns.tv_sec * NSEC_PER_SEC;\n\ttod_ns.tv_usec = ref / NSEC_PER_USEC;\n\n\t \n\tref = ff->ph->env.clock.clockid_ns;\n\tclockid_ns.tv_sec = ref / NSEC_PER_SEC;\n\tref -= clockid_ns.tv_sec * NSEC_PER_SEC;\n\tclockid_ns.tv_nsec = ref;\n\n\tclockid = ff->ph->env.clock.clockid;\n\n\tif (localtime_r(&tod_ns.tv_sec, &ltime) == NULL)\n\t\tsnprintf(tstr, sizeof(tstr), \"<error>\");\n\telse {\n\t\tstrftime(date, sizeof(date), \"%F %T\", &ltime);\n\t\tscnprintf(tstr, sizeof(tstr), \"%s.%06d\",\n\t\t\t  date, (int) tod_ns.tv_usec);\n\t}\n\n\tfprintf(fp, \"# clockid: %s (%u)\\n\", clockid_name(clockid), clockid);\n\tfprintf(fp, \"# reference time: %s = %ld.%06d (TOD) = %ld.%09ld (%s)\\n\",\n\t\t    tstr, (long) tod_ns.tv_sec, (int) tod_ns.tv_usec,\n\t\t    (long) clockid_ns.tv_sec, clockid_ns.tv_nsec,\n\t\t    clockid_name(clockid));\n}\n\nstatic void print_hybrid_topology(struct feat_fd *ff, FILE *fp)\n{\n\tint i;\n\tstruct hybrid_node *n;\n\n\tfprintf(fp, \"# hybrid cpu system:\\n\");\n\tfor (i = 0; i < ff->ph->env.nr_hybrid_nodes; i++) {\n\t\tn = &ff->ph->env.hybrid_nodes[i];\n\t\tfprintf(fp, \"# %s cpu list : %s\\n\", n->pmu_name, n->cpus);\n\t}\n}\n\nstatic void print_dir_format(struct feat_fd *ff, FILE *fp)\n{\n\tstruct perf_session *session;\n\tstruct perf_data *data;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\tdata = session->data;\n\n\tfprintf(fp, \"# directory data version : %\"PRIu64\"\\n\", data->dir.version);\n}\n\n#ifdef HAVE_LIBBPF_SUPPORT\nstatic void print_bpf_prog_info(struct feat_fd *ff, FILE *fp)\n{\n\tstruct perf_env *env = &ff->ph->env;\n\tstruct rb_root *root;\n\tstruct rb_node *next;\n\n\tdown_read(&env->bpf_progs.lock);\n\n\troot = &env->bpf_progs.infos;\n\tnext = rb_first(root);\n\n\twhile (next) {\n\t\tstruct bpf_prog_info_node *node;\n\n\t\tnode = rb_entry(next, struct bpf_prog_info_node, rb_node);\n\t\tnext = rb_next(&node->rb_node);\n\n\t\t__bpf_event__print_bpf_prog_info(&node->info_linear->info,\n\t\t\t\t\t\t env, fp);\n\t}\n\n\tup_read(&env->bpf_progs.lock);\n}\n\nstatic void print_bpf_btf(struct feat_fd *ff, FILE *fp)\n{\n\tstruct perf_env *env = &ff->ph->env;\n\tstruct rb_root *root;\n\tstruct rb_node *next;\n\n\tdown_read(&env->bpf_progs.lock);\n\n\troot = &env->bpf_progs.btfs;\n\tnext = rb_first(root);\n\n\twhile (next) {\n\t\tstruct btf_node *node;\n\n\t\tnode = rb_entry(next, struct btf_node, rb_node);\n\t\tnext = rb_next(&node->rb_node);\n\t\tfprintf(fp, \"# btf info of id %u\\n\", node->id);\n\t}\n\n\tup_read(&env->bpf_progs.lock);\n}\n#endif \n\nstatic void free_event_desc(struct evsel *events)\n{\n\tstruct evsel *evsel;\n\n\tif (!events)\n\t\treturn;\n\n\tfor (evsel = events; evsel->core.attr.size; evsel++) {\n\t\tzfree(&evsel->name);\n\t\tzfree(&evsel->core.id);\n\t}\n\n\tfree(events);\n}\n\nstatic bool perf_attr_check(struct perf_event_attr *attr)\n{\n\tif (attr->__reserved_1 || attr->__reserved_2 || attr->__reserved_3) {\n\t\tpr_warning(\"Reserved bits are set unexpectedly. \"\n\t\t\t   \"Please update perf tool.\\n\");\n\t\treturn false;\n\t}\n\n\tif (attr->sample_type & ~(PERF_SAMPLE_MAX-1)) {\n\t\tpr_warning(\"Unknown sample type (0x%llx) is detected. \"\n\t\t\t   \"Please update perf tool.\\n\",\n\t\t\t   attr->sample_type);\n\t\treturn false;\n\t}\n\n\tif (attr->read_format & ~(PERF_FORMAT_MAX-1)) {\n\t\tpr_warning(\"Unknown read format (0x%llx) is detected. \"\n\t\t\t   \"Please update perf tool.\\n\",\n\t\t\t   attr->read_format);\n\t\treturn false;\n\t}\n\n\tif ((attr->sample_type & PERF_SAMPLE_BRANCH_STACK) &&\n\t    (attr->branch_sample_type & ~(PERF_SAMPLE_BRANCH_MAX-1))) {\n\t\tpr_warning(\"Unknown branch sample type (0x%llx) is detected. \"\n\t\t\t   \"Please update perf tool.\\n\",\n\t\t\t   attr->branch_sample_type);\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic struct evsel *read_event_desc(struct feat_fd *ff)\n{\n\tstruct evsel *evsel, *events = NULL;\n\tu64 *id;\n\tvoid *buf = NULL;\n\tu32 nre, sz, nr, i, j;\n\tsize_t msz;\n\n\t \n\tif (do_read_u32(ff, &nre))\n\t\tgoto error;\n\n\tif (do_read_u32(ff, &sz))\n\t\tgoto error;\n\n\t \n\tbuf = malloc(sz);\n\tif (!buf)\n\t\tgoto error;\n\n\t \n\tevents = calloc(nre + 1, sizeof(*events));\n\tif (!events)\n\t\tgoto error;\n\n\tmsz = sizeof(evsel->core.attr);\n\tif (sz < msz)\n\t\tmsz = sz;\n\n\tfor (i = 0, evsel = events; i < nre; evsel++, i++) {\n\t\tevsel->core.idx = i;\n\n\t\t \n\t\tif (__do_read(ff, buf, sz))\n\t\t\tgoto error;\n\n\t\tif (ff->ph->needs_swap)\n\t\t\tperf_event__attr_swap(buf);\n\n\t\tmemcpy(&evsel->core.attr, buf, msz);\n\n\t\tif (!perf_attr_check(&evsel->core.attr))\n\t\t\tgoto error;\n\n\t\tif (do_read_u32(ff, &nr))\n\t\t\tgoto error;\n\n\t\tif (ff->ph->needs_swap)\n\t\t\tevsel->needs_swap = true;\n\n\t\tevsel->name = do_read_string(ff);\n\t\tif (!evsel->name)\n\t\t\tgoto error;\n\n\t\tif (!nr)\n\t\t\tcontinue;\n\n\t\tid = calloc(nr, sizeof(*id));\n\t\tif (!id)\n\t\t\tgoto error;\n\t\tevsel->core.ids = nr;\n\t\tevsel->core.id = id;\n\n\t\tfor (j = 0 ; j < nr; j++) {\n\t\t\tif (do_read_u64(ff, id))\n\t\t\t\tgoto error;\n\t\t\tid++;\n\t\t}\n\t}\nout:\n\tfree(buf);\n\treturn events;\nerror:\n\tfree_event_desc(events);\n\tevents = NULL;\n\tgoto out;\n}\n\nstatic int __desc_attr__fprintf(FILE *fp, const char *name, const char *val,\n\t\t\t\tvoid *priv __maybe_unused)\n{\n\treturn fprintf(fp, \", %s = %s\", name, val);\n}\n\nstatic void print_event_desc(struct feat_fd *ff, FILE *fp)\n{\n\tstruct evsel *evsel, *events;\n\tu32 j;\n\tu64 *id;\n\n\tif (ff->events)\n\t\tevents = ff->events;\n\telse\n\t\tevents = read_event_desc(ff);\n\n\tif (!events) {\n\t\tfprintf(fp, \"# event desc: not available or unable to read\\n\");\n\t\treturn;\n\t}\n\n\tfor (evsel = events; evsel->core.attr.size; evsel++) {\n\t\tfprintf(fp, \"# event : name = %s, \", evsel->name);\n\n\t\tif (evsel->core.ids) {\n\t\t\tfprintf(fp, \", id = {\");\n\t\t\tfor (j = 0, id = evsel->core.id; j < evsel->core.ids; j++, id++) {\n\t\t\t\tif (j)\n\t\t\t\t\tfputc(',', fp);\n\t\t\t\tfprintf(fp, \" %\"PRIu64, *id);\n\t\t\t}\n\t\t\tfprintf(fp, \" }\");\n\t\t}\n\n\t\tperf_event_attr__fprintf(fp, &evsel->core.attr, __desc_attr__fprintf, NULL);\n\n\t\tfputc('\\n', fp);\n\t}\n\n\tfree_event_desc(events);\n\tff->events = NULL;\n}\n\nstatic void print_total_mem(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# total memory : %llu kB\\n\", ff->ph->env.total_mem);\n}\n\nstatic void print_numa_topology(struct feat_fd *ff, FILE *fp)\n{\n\tint i;\n\tstruct numa_node *n;\n\n\tfor (i = 0; i < ff->ph->env.nr_numa_nodes; i++) {\n\t\tn = &ff->ph->env.numa_nodes[i];\n\n\t\tfprintf(fp, \"# node%u meminfo  : total = %\"PRIu64\" kB,\"\n\t\t\t    \" free = %\"PRIu64\" kB\\n\",\n\t\t\tn->node, n->mem_total, n->mem_free);\n\n\t\tfprintf(fp, \"# node%u cpu list : \", n->node);\n\t\tcpu_map__fprintf(n->map, fp);\n\t}\n}\n\nstatic void print_cpuid(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# cpuid : %s\\n\", ff->ph->env.cpuid);\n}\n\nstatic void print_branch_stack(struct feat_fd *ff __maybe_unused, FILE *fp)\n{\n\tfprintf(fp, \"# contains samples with branch stack\\n\");\n}\n\nstatic void print_auxtrace(struct feat_fd *ff __maybe_unused, FILE *fp)\n{\n\tfprintf(fp, \"# contains AUX area data (e.g. instruction trace)\\n\");\n}\n\nstatic void print_stat(struct feat_fd *ff __maybe_unused, FILE *fp)\n{\n\tfprintf(fp, \"# contains stat data\\n\");\n}\n\nstatic void print_cache(struct feat_fd *ff, FILE *fp __maybe_unused)\n{\n\tint i;\n\n\tfprintf(fp, \"# CPU cache info:\\n\");\n\tfor (i = 0; i < ff->ph->env.caches_cnt; i++) {\n\t\tfprintf(fp, \"#  \");\n\t\tcpu_cache_level__fprintf(fp, &ff->ph->env.caches[i]);\n\t}\n}\n\nstatic void print_compressed(struct feat_fd *ff, FILE *fp)\n{\n\tfprintf(fp, \"# compressed : %s, level = %d, ratio = %d\\n\",\n\t\tff->ph->env.comp_type == PERF_COMP_ZSTD ? \"Zstd\" : \"Unknown\",\n\t\tff->ph->env.comp_level, ff->ph->env.comp_ratio);\n}\n\nstatic void __print_pmu_caps(FILE *fp, int nr_caps, char **caps, char *pmu_name)\n{\n\tconst char *delimiter = \"\";\n\tint i;\n\n\tif (!nr_caps) {\n\t\tfprintf(fp, \"# %s pmu capabilities: not available\\n\", pmu_name);\n\t\treturn;\n\t}\n\n\tfprintf(fp, \"# %s pmu capabilities: \", pmu_name);\n\tfor (i = 0; i < nr_caps; i++) {\n\t\tfprintf(fp, \"%s%s\", delimiter, caps[i]);\n\t\tdelimiter = \", \";\n\t}\n\n\tfprintf(fp, \"\\n\");\n}\n\nstatic void print_cpu_pmu_caps(struct feat_fd *ff, FILE *fp)\n{\n\t__print_pmu_caps(fp, ff->ph->env.nr_cpu_pmu_caps,\n\t\t\t ff->ph->env.cpu_pmu_caps, (char *)\"cpu\");\n}\n\nstatic void print_pmu_caps(struct feat_fd *ff, FILE *fp)\n{\n\tstruct pmu_caps *pmu_caps;\n\n\tfor (int i = 0; i < ff->ph->env.nr_pmus_with_caps; i++) {\n\t\tpmu_caps = &ff->ph->env.pmu_caps[i];\n\t\t__print_pmu_caps(fp, pmu_caps->nr_caps, pmu_caps->caps,\n\t\t\t\t pmu_caps->pmu_name);\n\t}\n}\n\nstatic void print_pmu_mappings(struct feat_fd *ff, FILE *fp)\n{\n\tconst char *delimiter = \"# pmu mappings: \";\n\tchar *str, *tmp;\n\tu32 pmu_num;\n\tu32 type;\n\n\tpmu_num = ff->ph->env.nr_pmu_mappings;\n\tif (!pmu_num) {\n\t\tfprintf(fp, \"# pmu mappings: not available\\n\");\n\t\treturn;\n\t}\n\n\tstr = ff->ph->env.pmu_mappings;\n\n\twhile (pmu_num) {\n\t\ttype = strtoul(str, &tmp, 0);\n\t\tif (*tmp != ':')\n\t\t\tgoto error;\n\n\t\tstr = tmp + 1;\n\t\tfprintf(fp, \"%s%s = %\" PRIu32, delimiter, str, type);\n\n\t\tdelimiter = \", \";\n\t\tstr += strlen(str) + 1;\n\t\tpmu_num--;\n\t}\n\n\tfprintf(fp, \"\\n\");\n\n\tif (!pmu_num)\n\t\treturn;\nerror:\n\tfprintf(fp, \"# pmu mappings: unable to read\\n\");\n}\n\nstatic void print_group_desc(struct feat_fd *ff, FILE *fp)\n{\n\tstruct perf_session *session;\n\tstruct evsel *evsel;\n\tu32 nr = 0;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tif (evsel__is_group_leader(evsel) && evsel->core.nr_members > 1) {\n\t\t\tfprintf(fp, \"# group: %s{%s\", evsel->group_name ?: \"\", evsel__name(evsel));\n\n\t\t\tnr = evsel->core.nr_members - 1;\n\t\t} else if (nr) {\n\t\t\tfprintf(fp, \",%s\", evsel__name(evsel));\n\n\t\t\tif (--nr == 0)\n\t\t\t\tfprintf(fp, \"}\\n\");\n\t\t}\n\t}\n}\n\nstatic void print_sample_time(struct feat_fd *ff, FILE *fp)\n{\n\tstruct perf_session *session;\n\tchar time_buf[32];\n\tdouble d;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\ttimestamp__scnprintf_usec(session->evlist->first_sample_time,\n\t\t\t\t  time_buf, sizeof(time_buf));\n\tfprintf(fp, \"# time of first sample : %s\\n\", time_buf);\n\n\ttimestamp__scnprintf_usec(session->evlist->last_sample_time,\n\t\t\t\t  time_buf, sizeof(time_buf));\n\tfprintf(fp, \"# time of last sample : %s\\n\", time_buf);\n\n\td = (double)(session->evlist->last_sample_time -\n\t\tsession->evlist->first_sample_time) / NSEC_PER_MSEC;\n\n\tfprintf(fp, \"# sample duration : %10.3f ms\\n\", d);\n}\n\nstatic void memory_node__fprintf(struct memory_node *n,\n\t\t\t\t unsigned long long bsize, FILE *fp)\n{\n\tchar buf_map[100], buf_size[50];\n\tunsigned long long size;\n\n\tsize = bsize * bitmap_weight(n->set, n->size);\n\tunit_number__scnprintf(buf_size, 50, size);\n\n\tbitmap_scnprintf(n->set, n->size, buf_map, 100);\n\tfprintf(fp, \"#  %3\" PRIu64 \" [%s]: %s\\n\", n->node, buf_size, buf_map);\n}\n\nstatic void print_mem_topology(struct feat_fd *ff, FILE *fp)\n{\n\tstruct memory_node *nodes;\n\tint i, nr;\n\n\tnodes = ff->ph->env.memory_nodes;\n\tnr    = ff->ph->env.nr_memory_nodes;\n\n\tfprintf(fp, \"# memory nodes (nr %d, block size 0x%llx):\\n\",\n\t\tnr, ff->ph->env.memory_bsize);\n\n\tfor (i = 0; i < nr; i++) {\n\t\tmemory_node__fprintf(&nodes[i], ff->ph->env.memory_bsize, fp);\n\t}\n}\n\nstatic int __event_process_build_id(struct perf_record_header_build_id *bev,\n\t\t\t\t    char *filename,\n\t\t\t\t    struct perf_session *session)\n{\n\tint err = -1;\n\tstruct machine *machine;\n\tu16 cpumode;\n\tstruct dso *dso;\n\tenum dso_space_type dso_space;\n\n\tmachine = perf_session__findnew_machine(session, bev->pid);\n\tif (!machine)\n\t\tgoto out;\n\n\tcpumode = bev->header.misc & PERF_RECORD_MISC_CPUMODE_MASK;\n\n\tswitch (cpumode) {\n\tcase PERF_RECORD_MISC_KERNEL:\n\t\tdso_space = DSO_SPACE__KERNEL;\n\t\tbreak;\n\tcase PERF_RECORD_MISC_GUEST_KERNEL:\n\t\tdso_space = DSO_SPACE__KERNEL_GUEST;\n\t\tbreak;\n\tcase PERF_RECORD_MISC_USER:\n\tcase PERF_RECORD_MISC_GUEST_USER:\n\t\tdso_space = DSO_SPACE__USER;\n\t\tbreak;\n\tdefault:\n\t\tgoto out;\n\t}\n\n\tdso = machine__findnew_dso(machine, filename);\n\tif (dso != NULL) {\n\t\tchar sbuild_id[SBUILD_ID_SIZE];\n\t\tstruct build_id bid;\n\t\tsize_t size = BUILD_ID_SIZE;\n\n\t\tif (bev->header.misc & PERF_RECORD_MISC_BUILD_ID_SIZE)\n\t\t\tsize = bev->size;\n\n\t\tbuild_id__init(&bid, bev->data, size);\n\t\tdso__set_build_id(dso, &bid);\n\t\tdso->header_build_id = 1;\n\n\t\tif (dso_space != DSO_SPACE__USER) {\n\t\t\tstruct kmod_path m = { .name = NULL, };\n\n\t\t\tif (!kmod_path__parse_name(&m, filename) && m.kmod)\n\t\t\t\tdso__set_module_info(dso, &m, machine);\n\n\t\t\tdso->kernel = dso_space;\n\t\t\tfree(m.name);\n\t\t}\n\n\t\tbuild_id__sprintf(&dso->bid, sbuild_id);\n\t\tpr_debug(\"build id event received for %s: %s [%zu]\\n\",\n\t\t\t dso->long_name, sbuild_id, size);\n\t\tdso__put(dso);\n\t}\n\n\terr = 0;\nout:\n\treturn err;\n}\n\nstatic int perf_header__read_build_ids_abi_quirk(struct perf_header *header,\n\t\t\t\t\t\t int input, u64 offset, u64 size)\n{\n\tstruct perf_session *session = container_of(header, struct perf_session, header);\n\tstruct {\n\t\tstruct perf_event_header   header;\n\t\tu8\t\t\t   build_id[PERF_ALIGN(BUILD_ID_SIZE, sizeof(u64))];\n\t\tchar\t\t\t   filename[0];\n\t} old_bev;\n\tstruct perf_record_header_build_id bev;\n\tchar filename[PATH_MAX];\n\tu64 limit = offset + size;\n\n\twhile (offset < limit) {\n\t\tssize_t len;\n\n\t\tif (readn(input, &old_bev, sizeof(old_bev)) != sizeof(old_bev))\n\t\t\treturn -1;\n\n\t\tif (header->needs_swap)\n\t\t\tperf_event_header__bswap(&old_bev.header);\n\n\t\tlen = old_bev.header.size - sizeof(old_bev);\n\t\tif (readn(input, filename, len) != len)\n\t\t\treturn -1;\n\n\t\tbev.header = old_bev.header;\n\n\t\t \n\t\tbev.pid\t= HOST_KERNEL_ID;\n\t\tif (bev.header.misc == PERF_RECORD_MISC_GUEST_USER ||\n\t\t    bev.header.misc == PERF_RECORD_MISC_GUEST_KERNEL)\n\t\t\tbev.pid\t= DEFAULT_GUEST_KERNEL_ID;\n\n\t\tmemcpy(bev.build_id, old_bev.build_id, sizeof(bev.build_id));\n\t\t__event_process_build_id(&bev, filename, session);\n\n\t\toffset += bev.header.size;\n\t}\n\n\treturn 0;\n}\n\nstatic int perf_header__read_build_ids(struct perf_header *header,\n\t\t\t\t       int input, u64 offset, u64 size)\n{\n\tstruct perf_session *session = container_of(header, struct perf_session, header);\n\tstruct perf_record_header_build_id bev;\n\tchar filename[PATH_MAX];\n\tu64 limit = offset + size, orig_offset = offset;\n\tint err = -1;\n\n\twhile (offset < limit) {\n\t\tssize_t len;\n\n\t\tif (readn(input, &bev, sizeof(bev)) != sizeof(bev))\n\t\t\tgoto out;\n\n\t\tif (header->needs_swap)\n\t\t\tperf_event_header__bswap(&bev.header);\n\n\t\tlen = bev.header.size - sizeof(bev);\n\t\tif (readn(input, filename, len) != len)\n\t\t\tgoto out;\n\t\t \n\t\tif (memcmp(filename, \"nel.kallsyms]\", 13) == 0) {\n\t\t\tif (lseek(input, orig_offset, SEEK_SET) == (off_t)-1)\n\t\t\t\treturn -1;\n\t\t\treturn perf_header__read_build_ids_abi_quirk(header, input, offset, size);\n\t\t}\n\n\t\t__event_process_build_id(&bev, filename, session);\n\n\t\toffset += bev.header.size;\n\t}\n\terr = 0;\nout:\n\treturn err;\n}\n\n \n#define FEAT_PROCESS_STR_FUN(__feat, __feat_env) \\\nstatic int process_##__feat(struct feat_fd *ff, void *data __maybe_unused) \\\n{\\\n\tfree(ff->ph->env.__feat_env);\t\t     \\\n\tff->ph->env.__feat_env = do_read_string(ff); \\\n\treturn ff->ph->env.__feat_env ? 0 : -ENOMEM; \\\n}\n\nFEAT_PROCESS_STR_FUN(hostname, hostname);\nFEAT_PROCESS_STR_FUN(osrelease, os_release);\nFEAT_PROCESS_STR_FUN(version, version);\nFEAT_PROCESS_STR_FUN(arch, arch);\nFEAT_PROCESS_STR_FUN(cpudesc, cpu_desc);\nFEAT_PROCESS_STR_FUN(cpuid, cpuid);\n\n#ifdef HAVE_LIBTRACEEVENT\nstatic int process_tracing_data(struct feat_fd *ff, void *data)\n{\n\tssize_t ret = trace_report(ff->fd, data, false);\n\n\treturn ret < 0 ? -1 : 0;\n}\n#endif\n\nstatic int process_build_id(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tif (perf_header__read_build_ids(ff->ph, ff->fd, ff->offset, ff->size))\n\t\tpr_debug(\"Failed to read buildids, continuing...\\n\");\n\treturn 0;\n}\n\nstatic int process_nrcpus(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tint ret;\n\tu32 nr_cpus_avail, nr_cpus_online;\n\n\tret = do_read_u32(ff, &nr_cpus_avail);\n\tif (ret)\n\t\treturn ret;\n\n\tret = do_read_u32(ff, &nr_cpus_online);\n\tif (ret)\n\t\treturn ret;\n\tff->ph->env.nr_cpus_avail = (int)nr_cpus_avail;\n\tff->ph->env.nr_cpus_online = (int)nr_cpus_online;\n\treturn 0;\n}\n\nstatic int process_total_mem(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tu64 total_mem;\n\tint ret;\n\n\tret = do_read_u64(ff, &total_mem);\n\tif (ret)\n\t\treturn -1;\n\tff->ph->env.total_mem = (unsigned long long)total_mem;\n\treturn 0;\n}\n\nstatic struct evsel *evlist__find_by_index(struct evlist *evlist, int idx)\n{\n\tstruct evsel *evsel;\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.idx == idx)\n\t\t\treturn evsel;\n\t}\n\n\treturn NULL;\n}\n\nstatic void evlist__set_event_name(struct evlist *evlist, struct evsel *event)\n{\n\tstruct evsel *evsel;\n\n\tif (!event->name)\n\t\treturn;\n\n\tevsel = evlist__find_by_index(evlist, event->core.idx);\n\tif (!evsel)\n\t\treturn;\n\n\tif (evsel->name)\n\t\treturn;\n\n\tevsel->name = strdup(event->name);\n}\n\nstatic int\nprocess_event_desc(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct perf_session *session;\n\tstruct evsel *evsel, *events = read_event_desc(ff);\n\n\tif (!events)\n\t\treturn 0;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\tif (session->data->is_pipe) {\n\t\t \n\t\tff->events = events;\n\t}\n\n\tfor (evsel = events; evsel->core.attr.size; evsel++)\n\t\tevlist__set_event_name(session->evlist, evsel);\n\n\tif (!session->data->is_pipe)\n\t\tfree_event_desc(events);\n\n\treturn 0;\n}\n\nstatic int process_cmdline(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tchar *str, *cmdline = NULL, **argv = NULL;\n\tu32 nr, i, len = 0;\n\n\tif (do_read_u32(ff, &nr))\n\t\treturn -1;\n\n\tff->ph->env.nr_cmdline = nr;\n\n\tcmdline = zalloc(ff->size + nr + 1);\n\tif (!cmdline)\n\t\treturn -1;\n\n\targv = zalloc(sizeof(char *) * (nr + 1));\n\tif (!argv)\n\t\tgoto error;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tstr = do_read_string(ff);\n\t\tif (!str)\n\t\t\tgoto error;\n\n\t\targv[i] = cmdline + len;\n\t\tmemcpy(argv[i], str, strlen(str) + 1);\n\t\tlen += strlen(str) + 1;\n\t\tfree(str);\n\t}\n\tff->ph->env.cmdline = cmdline;\n\tff->ph->env.cmdline_argv = (const char **) argv;\n\treturn 0;\n\nerror:\n\tfree(argv);\n\tfree(cmdline);\n\treturn -1;\n}\n\nstatic int process_cpu_topology(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tu32 nr, i;\n\tchar *str;\n\tstruct strbuf sb;\n\tint cpu_nr = ff->ph->env.nr_cpus_avail;\n\tu64 size = 0;\n\tstruct perf_header *ph = ff->ph;\n\tbool do_core_id_test = true;\n\n\tph->env.cpu = calloc(cpu_nr, sizeof(*ph->env.cpu));\n\tif (!ph->env.cpu)\n\t\treturn -1;\n\n\tif (do_read_u32(ff, &nr))\n\t\tgoto free_cpu;\n\n\tph->env.nr_sibling_cores = nr;\n\tsize += sizeof(u32);\n\tif (strbuf_init(&sb, 128) < 0)\n\t\tgoto free_cpu;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tstr = do_read_string(ff);\n\t\tif (!str)\n\t\t\tgoto error;\n\n\t\t \n\t\tif (strbuf_add(&sb, str, strlen(str) + 1) < 0)\n\t\t\tgoto error;\n\t\tsize += string_size(str);\n\t\tfree(str);\n\t}\n\tph->env.sibling_cores = strbuf_detach(&sb, NULL);\n\n\tif (do_read_u32(ff, &nr))\n\t\treturn -1;\n\n\tph->env.nr_sibling_threads = nr;\n\tsize += sizeof(u32);\n\n\tfor (i = 0; i < nr; i++) {\n\t\tstr = do_read_string(ff);\n\t\tif (!str)\n\t\t\tgoto error;\n\n\t\t \n\t\tif (strbuf_add(&sb, str, strlen(str) + 1) < 0)\n\t\t\tgoto error;\n\t\tsize += string_size(str);\n\t\tfree(str);\n\t}\n\tph->env.sibling_threads = strbuf_detach(&sb, NULL);\n\n\t \n\tif (ff->size <= size) {\n\t\tzfree(&ph->env.cpu);\n\t\treturn 0;\n\t}\n\n\t \n\tif (ph->env.arch && (!strncmp(ph->env.arch, \"s390\", 4)\n\t\t\t  || !strncmp(ph->env.arch, \"aarch64\", 7)))\n\t\tdo_core_id_test = false;\n\n\tfor (i = 0; i < (u32)cpu_nr; i++) {\n\t\tif (do_read_u32(ff, &nr))\n\t\t\tgoto free_cpu;\n\n\t\tph->env.cpu[i].core_id = nr;\n\t\tsize += sizeof(u32);\n\n\t\tif (do_read_u32(ff, &nr))\n\t\t\tgoto free_cpu;\n\n\t\tif (do_core_id_test && nr != (u32)-1 && nr > (u32)cpu_nr) {\n\t\t\tpr_debug(\"socket_id number is too big.\"\n\t\t\t\t \"You may need to upgrade the perf tool.\\n\");\n\t\t\tgoto free_cpu;\n\t\t}\n\n\t\tph->env.cpu[i].socket_id = nr;\n\t\tsize += sizeof(u32);\n\t}\n\n\t \n\tif (ff->size <= size)\n\t\treturn 0;\n\n\tif (do_read_u32(ff, &nr))\n\t\treturn -1;\n\n\tph->env.nr_sibling_dies = nr;\n\tsize += sizeof(u32);\n\n\tfor (i = 0; i < nr; i++) {\n\t\tstr = do_read_string(ff);\n\t\tif (!str)\n\t\t\tgoto error;\n\n\t\t \n\t\tif (strbuf_add(&sb, str, strlen(str) + 1) < 0)\n\t\t\tgoto error;\n\t\tsize += string_size(str);\n\t\tfree(str);\n\t}\n\tph->env.sibling_dies = strbuf_detach(&sb, NULL);\n\n\tfor (i = 0; i < (u32)cpu_nr; i++) {\n\t\tif (do_read_u32(ff, &nr))\n\t\t\tgoto free_cpu;\n\n\t\tph->env.cpu[i].die_id = nr;\n\t}\n\n\treturn 0;\n\nerror:\n\tstrbuf_release(&sb);\nfree_cpu:\n\tzfree(&ph->env.cpu);\n\treturn -1;\n}\n\nstatic int process_numa_topology(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct numa_node *nodes, *n;\n\tu32 nr, i;\n\tchar *str;\n\n\t \n\tif (do_read_u32(ff, &nr))\n\t\treturn -1;\n\n\tnodes = zalloc(sizeof(*nodes) * nr);\n\tif (!nodes)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tn = &nodes[i];\n\n\t\t \n\t\tif (do_read_u32(ff, &n->node))\n\t\t\tgoto error;\n\n\t\tif (do_read_u64(ff, &n->mem_total))\n\t\t\tgoto error;\n\n\t\tif (do_read_u64(ff, &n->mem_free))\n\t\t\tgoto error;\n\n\t\tstr = do_read_string(ff);\n\t\tif (!str)\n\t\t\tgoto error;\n\n\t\tn->map = perf_cpu_map__new(str);\n\t\tif (!n->map)\n\t\t\tgoto error;\n\n\t\tfree(str);\n\t}\n\tff->ph->env.nr_numa_nodes = nr;\n\tff->ph->env.numa_nodes = nodes;\n\treturn 0;\n\nerror:\n\tfree(nodes);\n\treturn -1;\n}\n\nstatic int process_pmu_mappings(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tchar *name;\n\tu32 pmu_num;\n\tu32 type;\n\tstruct strbuf sb;\n\n\tif (do_read_u32(ff, &pmu_num))\n\t\treturn -1;\n\n\tif (!pmu_num) {\n\t\tpr_debug(\"pmu mappings not available\\n\");\n\t\treturn 0;\n\t}\n\n\tff->ph->env.nr_pmu_mappings = pmu_num;\n\tif (strbuf_init(&sb, 128) < 0)\n\t\treturn -1;\n\n\twhile (pmu_num) {\n\t\tif (do_read_u32(ff, &type))\n\t\t\tgoto error;\n\n\t\tname = do_read_string(ff);\n\t\tif (!name)\n\t\t\tgoto error;\n\n\t\tif (strbuf_addf(&sb, \"%u:%s\", type, name) < 0)\n\t\t\tgoto error;\n\t\t \n\t\tif (strbuf_add(&sb, \"\", 1) < 0)\n\t\t\tgoto error;\n\n\t\tif (!strcmp(name, \"msr\"))\n\t\t\tff->ph->env.msr_pmu_type = type;\n\n\t\tfree(name);\n\t\tpmu_num--;\n\t}\n\tff->ph->env.pmu_mappings = strbuf_detach(&sb, NULL);\n\treturn 0;\n\nerror:\n\tstrbuf_release(&sb);\n\treturn -1;\n}\n\nstatic int process_group_desc(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tsize_t ret = -1;\n\tu32 i, nr, nr_groups;\n\tstruct perf_session *session;\n\tstruct evsel *evsel, *leader = NULL;\n\tstruct group_desc {\n\t\tchar *name;\n\t\tu32 leader_idx;\n\t\tu32 nr_members;\n\t} *desc;\n\n\tif (do_read_u32(ff, &nr_groups))\n\t\treturn -1;\n\n\tff->ph->env.nr_groups = nr_groups;\n\tif (!nr_groups) {\n\t\tpr_debug(\"group desc not available\\n\");\n\t\treturn 0;\n\t}\n\n\tdesc = calloc(nr_groups, sizeof(*desc));\n\tif (!desc)\n\t\treturn -1;\n\n\tfor (i = 0; i < nr_groups; i++) {\n\t\tdesc[i].name = do_read_string(ff);\n\t\tif (!desc[i].name)\n\t\t\tgoto out_free;\n\n\t\tif (do_read_u32(ff, &desc[i].leader_idx))\n\t\t\tgoto out_free;\n\n\t\tif (do_read_u32(ff, &desc[i].nr_members))\n\t\t\tgoto out_free;\n\t}\n\n\t \n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\ti = nr = 0;\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tif (i < nr_groups && evsel->core.idx == (int) desc[i].leader_idx) {\n\t\t\tevsel__set_leader(evsel, evsel);\n\t\t\t \n\t\t\tif (strcmp(desc[i].name, \"{anon_group}\")) {\n\t\t\t\tevsel->group_name = desc[i].name;\n\t\t\t\tdesc[i].name = NULL;\n\t\t\t}\n\t\t\tevsel->core.nr_members = desc[i].nr_members;\n\n\t\t\tif (i >= nr_groups || nr > 0) {\n\t\t\t\tpr_debug(\"invalid group desc\\n\");\n\t\t\t\tgoto out_free;\n\t\t\t}\n\n\t\t\tleader = evsel;\n\t\t\tnr = evsel->core.nr_members - 1;\n\t\t\ti++;\n\t\t} else if (nr) {\n\t\t\t \n\t\t\tevsel__set_leader(evsel, leader);\n\n\t\t\tnr--;\n\t\t}\n\t}\n\n\tif (i != nr_groups || nr != 0) {\n\t\tpr_debug(\"invalid group desc\\n\");\n\t\tgoto out_free;\n\t}\n\n\tret = 0;\nout_free:\n\tfor (i = 0; i < nr_groups; i++)\n\t\tzfree(&desc[i].name);\n\tfree(desc);\n\n\treturn ret;\n}\n\nstatic int process_auxtrace(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct perf_session *session;\n\tint err;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\terr = auxtrace_index__process(ff->fd, ff->size, session,\n\t\t\t\t      ff->ph->needs_swap);\n\tif (err < 0)\n\t\tpr_err(\"Failed to process auxtrace index\\n\");\n\treturn err;\n}\n\nstatic int process_cache(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct cpu_cache_level *caches;\n\tu32 cnt, i, version;\n\n\tif (do_read_u32(ff, &version))\n\t\treturn -1;\n\n\tif (version != 1)\n\t\treturn -1;\n\n\tif (do_read_u32(ff, &cnt))\n\t\treturn -1;\n\n\tcaches = zalloc(sizeof(*caches) * cnt);\n\tif (!caches)\n\t\treturn -1;\n\n\tfor (i = 0; i < cnt; i++) {\n\t\tstruct cpu_cache_level c;\n\n\t\t#define _R(v)\t\t\t\t\t\t\\\n\t\t\tif (do_read_u32(ff, &c.v))\\\n\t\t\t\tgoto out_free_caches;\t\t\t\\\n\n\t\t_R(level)\n\t\t_R(line_size)\n\t\t_R(sets)\n\t\t_R(ways)\n\t\t#undef _R\n\n\t\t#define _R(v)\t\t\t\t\t\\\n\t\t\tc.v = do_read_string(ff);\t\t\\\n\t\t\tif (!c.v)\t\t\t\t\\\n\t\t\t\tgoto out_free_caches;\n\n\t\t_R(type)\n\t\t_R(size)\n\t\t_R(map)\n\t\t#undef _R\n\n\t\tcaches[i] = c;\n\t}\n\n\tff->ph->env.caches = caches;\n\tff->ph->env.caches_cnt = cnt;\n\treturn 0;\nout_free_caches:\n\tfree(caches);\n\treturn -1;\n}\n\nstatic int process_sample_time(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct perf_session *session;\n\tu64 first_sample_time, last_sample_time;\n\tint ret;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\n\tret = do_read_u64(ff, &first_sample_time);\n\tif (ret)\n\t\treturn -1;\n\n\tret = do_read_u64(ff, &last_sample_time);\n\tif (ret)\n\t\treturn -1;\n\n\tsession->evlist->first_sample_time = first_sample_time;\n\tsession->evlist->last_sample_time = last_sample_time;\n\treturn 0;\n}\n\nstatic int process_mem_topology(struct feat_fd *ff,\n\t\t\t\tvoid *data __maybe_unused)\n{\n\tstruct memory_node *nodes;\n\tu64 version, i, nr, bsize;\n\tint ret = -1;\n\n\tif (do_read_u64(ff, &version))\n\t\treturn -1;\n\n\tif (version != 1)\n\t\treturn -1;\n\n\tif (do_read_u64(ff, &bsize))\n\t\treturn -1;\n\n\tif (do_read_u64(ff, &nr))\n\t\treturn -1;\n\n\tnodes = zalloc(sizeof(*nodes) * nr);\n\tif (!nodes)\n\t\treturn -1;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tstruct memory_node n;\n\n\t\t#define _R(v)\t\t\t\t\\\n\t\t\tif (do_read_u64(ff, &n.v))\t\\\n\t\t\t\tgoto out;\t\t\\\n\n\t\t_R(node)\n\t\t_R(size)\n\n\t\t#undef _R\n\n\t\tif (do_read_bitmap(ff, &n.set, &n.size))\n\t\t\tgoto out;\n\n\t\tnodes[i] = n;\n\t}\n\n\tff->ph->env.memory_bsize    = bsize;\n\tff->ph->env.memory_nodes    = nodes;\n\tff->ph->env.nr_memory_nodes = nr;\n\tret = 0;\n\nout:\n\tif (ret)\n\t\tfree(nodes);\n\treturn ret;\n}\n\nstatic int process_clockid(struct feat_fd *ff,\n\t\t\t   void *data __maybe_unused)\n{\n\tif (do_read_u64(ff, &ff->ph->env.clock.clockid_res_ns))\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic int process_clock_data(struct feat_fd *ff,\n\t\t\t      void *_data __maybe_unused)\n{\n\tu32 data32;\n\tu64 data64;\n\n\t \n\tif (do_read_u32(ff, &data32))\n\t\treturn -1;\n\n\tif (data32 != 1)\n\t\treturn -1;\n\n\t \n\tif (do_read_u32(ff, &data32))\n\t\treturn -1;\n\n\tff->ph->env.clock.clockid = data32;\n\n\t \n\tif (do_read_u64(ff, &data64))\n\t\treturn -1;\n\n\tff->ph->env.clock.tod_ns = data64;\n\n\t \n\tif (do_read_u64(ff, &data64))\n\t\treturn -1;\n\n\tff->ph->env.clock.clockid_ns = data64;\n\tff->ph->env.clock.enabled = true;\n\treturn 0;\n}\n\nstatic int process_hybrid_topology(struct feat_fd *ff,\n\t\t\t\t   void *data __maybe_unused)\n{\n\tstruct hybrid_node *nodes, *n;\n\tu32 nr, i;\n\n\t \n\tif (do_read_u32(ff, &nr))\n\t\treturn -1;\n\n\tnodes = zalloc(sizeof(*nodes) * nr);\n\tif (!nodes)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tn = &nodes[i];\n\n\t\tn->pmu_name = do_read_string(ff);\n\t\tif (!n->pmu_name)\n\t\t\tgoto error;\n\n\t\tn->cpus = do_read_string(ff);\n\t\tif (!n->cpus)\n\t\t\tgoto error;\n\t}\n\n\tff->ph->env.nr_hybrid_nodes = nr;\n\tff->ph->env.hybrid_nodes = nodes;\n\treturn 0;\n\nerror:\n\tfor (i = 0; i < nr; i++) {\n\t\tfree(nodes[i].pmu_name);\n\t\tfree(nodes[i].cpus);\n\t}\n\n\tfree(nodes);\n\treturn -1;\n}\n\nstatic int process_dir_format(struct feat_fd *ff,\n\t\t\t      void *_data __maybe_unused)\n{\n\tstruct perf_session *session;\n\tstruct perf_data *data;\n\n\tsession = container_of(ff->ph, struct perf_session, header);\n\tdata = session->data;\n\n\tif (WARN_ON(!perf_data__is_dir(data)))\n\t\treturn -1;\n\n\treturn do_read_u64(ff, &data->dir.version);\n}\n\n#ifdef HAVE_LIBBPF_SUPPORT\nstatic int process_bpf_prog_info(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct bpf_prog_info_node *info_node;\n\tstruct perf_env *env = &ff->ph->env;\n\tstruct perf_bpil *info_linear;\n\tu32 count, i;\n\tint err = -1;\n\n\tif (ff->ph->needs_swap) {\n\t\tpr_warning(\"interpreting bpf_prog_info from systems with endianness is not yet supported\\n\");\n\t\treturn 0;\n\t}\n\n\tif (do_read_u32(ff, &count))\n\t\treturn -1;\n\n\tdown_write(&env->bpf_progs.lock);\n\n\tfor (i = 0; i < count; ++i) {\n\t\tu32 info_len, data_len;\n\n\t\tinfo_linear = NULL;\n\t\tinfo_node = NULL;\n\t\tif (do_read_u32(ff, &info_len))\n\t\t\tgoto out;\n\t\tif (do_read_u32(ff, &data_len))\n\t\t\tgoto out;\n\n\t\tif (info_len > sizeof(struct bpf_prog_info)) {\n\t\t\tpr_warning(\"detected invalid bpf_prog_info\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tinfo_linear = malloc(sizeof(struct perf_bpil) +\n\t\t\t\t     data_len);\n\t\tif (!info_linear)\n\t\t\tgoto out;\n\t\tinfo_linear->info_len = sizeof(struct bpf_prog_info);\n\t\tinfo_linear->data_len = data_len;\n\t\tif (do_read_u64(ff, (u64 *)(&info_linear->arrays)))\n\t\t\tgoto out;\n\t\tif (__do_read(ff, &info_linear->info, info_len))\n\t\t\tgoto out;\n\t\tif (info_len < sizeof(struct bpf_prog_info))\n\t\t\tmemset(((void *)(&info_linear->info)) + info_len, 0,\n\t\t\t       sizeof(struct bpf_prog_info) - info_len);\n\n\t\tif (__do_read(ff, info_linear->data, data_len))\n\t\t\tgoto out;\n\n\t\tinfo_node = malloc(sizeof(struct bpf_prog_info_node));\n\t\tif (!info_node)\n\t\t\tgoto out;\n\n\t\t \n\t\tbpil_offs_to_addr(info_linear);\n\t\tinfo_node->info_linear = info_linear;\n\t\t__perf_env__insert_bpf_prog_info(env, info_node);\n\t}\n\n\tup_write(&env->bpf_progs.lock);\n\treturn 0;\nout:\n\tfree(info_linear);\n\tfree(info_node);\n\tup_write(&env->bpf_progs.lock);\n\treturn err;\n}\n\nstatic int process_bpf_btf(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct perf_env *env = &ff->ph->env;\n\tstruct btf_node *node = NULL;\n\tu32 count, i;\n\tint err = -1;\n\n\tif (ff->ph->needs_swap) {\n\t\tpr_warning(\"interpreting btf from systems with endianness is not yet supported\\n\");\n\t\treturn 0;\n\t}\n\n\tif (do_read_u32(ff, &count))\n\t\treturn -1;\n\n\tdown_write(&env->bpf_progs.lock);\n\n\tfor (i = 0; i < count; ++i) {\n\t\tu32 id, data_size;\n\n\t\tif (do_read_u32(ff, &id))\n\t\t\tgoto out;\n\t\tif (do_read_u32(ff, &data_size))\n\t\t\tgoto out;\n\n\t\tnode = malloc(sizeof(struct btf_node) + data_size);\n\t\tif (!node)\n\t\t\tgoto out;\n\n\t\tnode->id = id;\n\t\tnode->data_size = data_size;\n\n\t\tif (__do_read(ff, node->data, data_size))\n\t\t\tgoto out;\n\n\t\t__perf_env__insert_btf(env, node);\n\t\tnode = NULL;\n\t}\n\n\terr = 0;\nout:\n\tup_write(&env->bpf_progs.lock);\n\tfree(node);\n\treturn err;\n}\n#endif \n\nstatic int process_compressed(struct feat_fd *ff,\n\t\t\t      void *data __maybe_unused)\n{\n\tif (do_read_u32(ff, &(ff->ph->env.comp_ver)))\n\t\treturn -1;\n\n\tif (do_read_u32(ff, &(ff->ph->env.comp_type)))\n\t\treturn -1;\n\n\tif (do_read_u32(ff, &(ff->ph->env.comp_level)))\n\t\treturn -1;\n\n\tif (do_read_u32(ff, &(ff->ph->env.comp_ratio)))\n\t\treturn -1;\n\n\tif (do_read_u32(ff, &(ff->ph->env.comp_mmap_len)))\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic int __process_pmu_caps(struct feat_fd *ff, int *nr_caps,\n\t\t\t      char ***caps, unsigned int *max_branches)\n{\n\tchar *name, *value, *ptr;\n\tu32 nr_pmu_caps, i;\n\n\t*nr_caps = 0;\n\t*caps = NULL;\n\n\tif (do_read_u32(ff, &nr_pmu_caps))\n\t\treturn -1;\n\n\tif (!nr_pmu_caps)\n\t\treturn 0;\n\n\t*caps = zalloc(sizeof(char *) * nr_pmu_caps);\n\tif (!*caps)\n\t\treturn -1;\n\n\tfor (i = 0; i < nr_pmu_caps; i++) {\n\t\tname = do_read_string(ff);\n\t\tif (!name)\n\t\t\tgoto error;\n\n\t\tvalue = do_read_string(ff);\n\t\tif (!value)\n\t\t\tgoto free_name;\n\n\t\tif (asprintf(&ptr, \"%s=%s\", name, value) < 0)\n\t\t\tgoto free_value;\n\n\t\t(*caps)[i] = ptr;\n\n\t\tif (!strcmp(name, \"branches\"))\n\t\t\t*max_branches = atoi(value);\n\n\t\tfree(value);\n\t\tfree(name);\n\t}\n\t*nr_caps = nr_pmu_caps;\n\treturn 0;\n\nfree_value:\n\tfree(value);\nfree_name:\n\tfree(name);\nerror:\n\tfor (; i > 0; i--)\n\t\tfree((*caps)[i - 1]);\n\tfree(*caps);\n\t*caps = NULL;\n\t*nr_caps = 0;\n\treturn -1;\n}\n\nstatic int process_cpu_pmu_caps(struct feat_fd *ff,\n\t\t\t\tvoid *data __maybe_unused)\n{\n\tint ret = __process_pmu_caps(ff, &ff->ph->env.nr_cpu_pmu_caps,\n\t\t\t\t     &ff->ph->env.cpu_pmu_caps,\n\t\t\t\t     &ff->ph->env.max_branches);\n\n\tif (!ret && !ff->ph->env.cpu_pmu_caps)\n\t\tpr_debug(\"cpu pmu capabilities not available\\n\");\n\treturn ret;\n}\n\nstatic int process_pmu_caps(struct feat_fd *ff, void *data __maybe_unused)\n{\n\tstruct pmu_caps *pmu_caps;\n\tu32 nr_pmu, i;\n\tint ret;\n\tint j;\n\n\tif (do_read_u32(ff, &nr_pmu))\n\t\treturn -1;\n\n\tif (!nr_pmu) {\n\t\tpr_debug(\"pmu capabilities not available\\n\");\n\t\treturn 0;\n\t}\n\n\tpmu_caps = zalloc(sizeof(*pmu_caps) * nr_pmu);\n\tif (!pmu_caps)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < nr_pmu; i++) {\n\t\tret = __process_pmu_caps(ff, &pmu_caps[i].nr_caps,\n\t\t\t\t\t &pmu_caps[i].caps,\n\t\t\t\t\t &pmu_caps[i].max_branches);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tpmu_caps[i].pmu_name = do_read_string(ff);\n\t\tif (!pmu_caps[i].pmu_name) {\n\t\t\tret = -1;\n\t\t\tgoto err;\n\t\t}\n\t\tif (!pmu_caps[i].nr_caps) {\n\t\t\tpr_debug(\"%s pmu capabilities not available\\n\",\n\t\t\t\t pmu_caps[i].pmu_name);\n\t\t}\n\t}\n\n\tff->ph->env.nr_pmus_with_caps = nr_pmu;\n\tff->ph->env.pmu_caps = pmu_caps;\n\treturn 0;\n\nerr:\n\tfor (i = 0; i < nr_pmu; i++) {\n\t\tfor (j = 0; j < pmu_caps[i].nr_caps; j++)\n\t\t\tfree(pmu_caps[i].caps[j]);\n\t\tfree(pmu_caps[i].caps);\n\t\tfree(pmu_caps[i].pmu_name);\n\t}\n\n\tfree(pmu_caps);\n\treturn ret;\n}\n\n#define FEAT_OPR(n, func, __full_only) \\\n\t[HEADER_##n] = {\t\t\t\t\t\\\n\t\t.name\t    = __stringify(n),\t\t\t\\\n\t\t.write\t    = write_##func,\t\t\t\\\n\t\t.print\t    = print_##func,\t\t\t\\\n\t\t.full_only  = __full_only,\t\t\t\\\n\t\t.process    = process_##func,\t\t\t\\\n\t\t.synthesize = true\t\t\t\t\\\n\t}\n\n#define FEAT_OPN(n, func, __full_only) \\\n\t[HEADER_##n] = {\t\t\t\t\t\\\n\t\t.name\t    = __stringify(n),\t\t\t\\\n\t\t.write\t    = write_##func,\t\t\t\\\n\t\t.print\t    = print_##func,\t\t\t\\\n\t\t.full_only  = __full_only,\t\t\t\\\n\t\t.process    = process_##func\t\t\t\\\n\t}\n\n \n#define print_tracing_data\tNULL\n#define print_build_id\t\tNULL\n\n#define process_branch_stack\tNULL\n#define process_stat\t\tNULL\n\n\nconst struct perf_header_feature_ops feat_ops[HEADER_LAST_FEATURE];\n\nconst struct perf_header_feature_ops feat_ops[HEADER_LAST_FEATURE] = {\n#ifdef HAVE_LIBTRACEEVENT\n\tFEAT_OPN(TRACING_DATA,\ttracing_data,\tfalse),\n#endif\n\tFEAT_OPN(BUILD_ID,\tbuild_id,\tfalse),\n\tFEAT_OPR(HOSTNAME,\thostname,\tfalse),\n\tFEAT_OPR(OSRELEASE,\tosrelease,\tfalse),\n\tFEAT_OPR(VERSION,\tversion,\tfalse),\n\tFEAT_OPR(ARCH,\t\tarch,\t\tfalse),\n\tFEAT_OPR(NRCPUS,\tnrcpus,\t\tfalse),\n\tFEAT_OPR(CPUDESC,\tcpudesc,\tfalse),\n\tFEAT_OPR(CPUID,\t\tcpuid,\t\tfalse),\n\tFEAT_OPR(TOTAL_MEM,\ttotal_mem,\tfalse),\n\tFEAT_OPR(EVENT_DESC,\tevent_desc,\tfalse),\n\tFEAT_OPR(CMDLINE,\tcmdline,\tfalse),\n\tFEAT_OPR(CPU_TOPOLOGY,\tcpu_topology,\ttrue),\n\tFEAT_OPR(NUMA_TOPOLOGY,\tnuma_topology,\ttrue),\n\tFEAT_OPN(BRANCH_STACK,\tbranch_stack,\tfalse),\n\tFEAT_OPR(PMU_MAPPINGS,\tpmu_mappings,\tfalse),\n\tFEAT_OPR(GROUP_DESC,\tgroup_desc,\tfalse),\n\tFEAT_OPN(AUXTRACE,\tauxtrace,\tfalse),\n\tFEAT_OPN(STAT,\t\tstat,\t\tfalse),\n\tFEAT_OPN(CACHE,\t\tcache,\t\ttrue),\n\tFEAT_OPR(SAMPLE_TIME,\tsample_time,\tfalse),\n\tFEAT_OPR(MEM_TOPOLOGY,\tmem_topology,\ttrue),\n\tFEAT_OPR(CLOCKID,\tclockid,\tfalse),\n\tFEAT_OPN(DIR_FORMAT,\tdir_format,\tfalse),\n#ifdef HAVE_LIBBPF_SUPPORT\n\tFEAT_OPR(BPF_PROG_INFO, bpf_prog_info,  false),\n\tFEAT_OPR(BPF_BTF,       bpf_btf,        false),\n#endif\n\tFEAT_OPR(COMPRESSED,\tcompressed,\tfalse),\n\tFEAT_OPR(CPU_PMU_CAPS,\tcpu_pmu_caps,\tfalse),\n\tFEAT_OPR(CLOCK_DATA,\tclock_data,\tfalse),\n\tFEAT_OPN(HYBRID_TOPOLOGY,\thybrid_topology,\ttrue),\n\tFEAT_OPR(PMU_CAPS,\tpmu_caps,\tfalse),\n};\n\nstruct header_print_data {\n\tFILE *fp;\n\tbool full;  \n};\n\nstatic int perf_file_section__fprintf_info(struct perf_file_section *section,\n\t\t\t\t\t   struct perf_header *ph,\n\t\t\t\t\t   int feat, int fd, void *data)\n{\n\tstruct header_print_data *hd = data;\n\tstruct feat_fd ff;\n\n\tif (lseek(fd, section->offset, SEEK_SET) == (off_t)-1) {\n\t\tpr_debug(\"Failed to lseek to %\" PRIu64 \" offset for feature \"\n\t\t\t\t\"%d, continuing...\\n\", section->offset, feat);\n\t\treturn 0;\n\t}\n\tif (feat >= HEADER_LAST_FEATURE) {\n\t\tpr_warning(\"unknown feature %d\\n\", feat);\n\t\treturn 0;\n\t}\n\tif (!feat_ops[feat].print)\n\t\treturn 0;\n\n\tff = (struct  feat_fd) {\n\t\t.fd = fd,\n\t\t.ph = ph,\n\t};\n\n\tif (!feat_ops[feat].full_only || hd->full)\n\t\tfeat_ops[feat].print(&ff, hd->fp);\n\telse\n\t\tfprintf(hd->fp, \"# %s info available, use -I to display\\n\",\n\t\t\tfeat_ops[feat].name);\n\n\treturn 0;\n}\n\nint perf_header__fprintf_info(struct perf_session *session, FILE *fp, bool full)\n{\n\tstruct header_print_data hd;\n\tstruct perf_header *header = &session->header;\n\tint fd = perf_data__fd(session->data);\n\tstruct stat st;\n\ttime_t stctime;\n\tint ret, bit;\n\n\thd.fp = fp;\n\thd.full = full;\n\n\tret = fstat(fd, &st);\n\tif (ret == -1)\n\t\treturn -1;\n\n\tstctime = st.st_mtime;\n\tfprintf(fp, \"# captured on    : %s\", ctime(&stctime));\n\n\tfprintf(fp, \"# header version : %u\\n\", header->version);\n\tfprintf(fp, \"# data offset    : %\" PRIu64 \"\\n\", header->data_offset);\n\tfprintf(fp, \"# data size      : %\" PRIu64 \"\\n\", header->data_size);\n\tfprintf(fp, \"# feat offset    : %\" PRIu64 \"\\n\", header->feat_offset);\n\n\tperf_header__process_sections(header, fd, &hd,\n\t\t\t\t      perf_file_section__fprintf_info);\n\n\tif (session->data->is_pipe)\n\t\treturn 0;\n\n\tfprintf(fp, \"# missing features: \");\n\tfor_each_clear_bit(bit, header->adds_features, HEADER_LAST_FEATURE) {\n\t\tif (bit)\n\t\t\tfprintf(fp, \"%s \", feat_ops[bit].name);\n\t}\n\n\tfprintf(fp, \"\\n\");\n\treturn 0;\n}\n\nstruct header_fw {\n\tstruct feat_writer\tfw;\n\tstruct feat_fd\t\t*ff;\n};\n\nstatic int feat_writer_cb(struct feat_writer *fw, void *buf, size_t sz)\n{\n\tstruct header_fw *h = container_of(fw, struct header_fw, fw);\n\n\treturn do_write(h->ff, buf, sz);\n}\n\nstatic int do_write_feat(struct feat_fd *ff, int type,\n\t\t\t struct perf_file_section **p,\n\t\t\t struct evlist *evlist,\n\t\t\t struct feat_copier *fc)\n{\n\tint err;\n\tint ret = 0;\n\n\tif (perf_header__has_feat(ff->ph, type)) {\n\t\tif (!feat_ops[type].write)\n\t\t\treturn -1;\n\n\t\tif (WARN(ff->buf, \"Error: calling %s in pipe-mode.\\n\", __func__))\n\t\t\treturn -1;\n\n\t\t(*p)->offset = lseek(ff->fd, 0, SEEK_CUR);\n\n\t\t \n\t\tif (fc && fc->copy) {\n\t\t\tstruct header_fw h = {\n\t\t\t\t.fw.write = feat_writer_cb,\n\t\t\t\t.ff = ff,\n\t\t\t};\n\n\t\t\t \n\t\t\terr = fc->copy(fc, type, &h.fw);\n\t\t} else {\n\t\t\terr = 0;\n\t\t}\n\t\tif (!err)\n\t\t\terr = feat_ops[type].write(ff, evlist);\n\t\tif (err < 0) {\n\t\t\tpr_debug(\"failed to write feature %s\\n\", feat_ops[type].name);\n\n\t\t\t \n\t\t\tlseek(ff->fd, (*p)->offset, SEEK_SET);\n\n\t\t\treturn -1;\n\t\t}\n\t\t(*p)->size = lseek(ff->fd, 0, SEEK_CUR) - (*p)->offset;\n\t\t(*p)++;\n\t}\n\treturn ret;\n}\n\nstatic int perf_header__adds_write(struct perf_header *header,\n\t\t\t\t   struct evlist *evlist, int fd,\n\t\t\t\t   struct feat_copier *fc)\n{\n\tint nr_sections;\n\tstruct feat_fd ff;\n\tstruct perf_file_section *feat_sec, *p;\n\tint sec_size;\n\tu64 sec_start;\n\tint feat;\n\tint err;\n\n\tff = (struct feat_fd){\n\t\t.fd  = fd,\n\t\t.ph = header,\n\t};\n\n\tnr_sections = bitmap_weight(header->adds_features, HEADER_FEAT_BITS);\n\tif (!nr_sections)\n\t\treturn 0;\n\n\tfeat_sec = p = calloc(nr_sections, sizeof(*feat_sec));\n\tif (feat_sec == NULL)\n\t\treturn -ENOMEM;\n\n\tsec_size = sizeof(*feat_sec) * nr_sections;\n\n\tsec_start = header->feat_offset;\n\tlseek(fd, sec_start + sec_size, SEEK_SET);\n\n\tfor_each_set_bit(feat, header->adds_features, HEADER_FEAT_BITS) {\n\t\tif (do_write_feat(&ff, feat, &p, evlist, fc))\n\t\t\tperf_header__clear_feat(header, feat);\n\t}\n\n\tlseek(fd, sec_start, SEEK_SET);\n\t \n\terr = do_write(&ff, feat_sec, sec_size);\n\tif (err < 0)\n\t\tpr_debug(\"failed to write feature section\\n\");\n\tfree(feat_sec);\n\treturn err;\n}\n\nint perf_header__write_pipe(int fd)\n{\n\tstruct perf_pipe_file_header f_header;\n\tstruct feat_fd ff;\n\tint err;\n\n\tff = (struct feat_fd){ .fd = fd };\n\n\tf_header = (struct perf_pipe_file_header){\n\t\t.magic\t   = PERF_MAGIC,\n\t\t.size\t   = sizeof(f_header),\n\t};\n\n\terr = do_write(&ff, &f_header, sizeof(f_header));\n\tif (err < 0) {\n\t\tpr_debug(\"failed to write perf pipe header\\n\");\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int perf_session__do_write_header(struct perf_session *session,\n\t\t\t\t\t struct evlist *evlist,\n\t\t\t\t\t int fd, bool at_exit,\n\t\t\t\t\t struct feat_copier *fc)\n{\n\tstruct perf_file_header f_header;\n\tstruct perf_file_attr   f_attr;\n\tstruct perf_header *header = &session->header;\n\tstruct evsel *evsel;\n\tstruct feat_fd ff;\n\tu64 attr_offset;\n\tint err;\n\n\tff = (struct feat_fd){ .fd = fd};\n\tlseek(fd, sizeof(f_header), SEEK_SET);\n\n\tevlist__for_each_entry(session->evlist, evsel) {\n\t\tevsel->id_offset = lseek(fd, 0, SEEK_CUR);\n\t\terr = do_write(&ff, evsel->core.id, evsel->core.ids * sizeof(u64));\n\t\tif (err < 0) {\n\t\t\tpr_debug(\"failed to write perf header\\n\");\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tattr_offset = lseek(ff.fd, 0, SEEK_CUR);\n\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tif (evsel->core.attr.size < sizeof(evsel->core.attr)) {\n\t\t\t \n\t\t\tevsel->core.attr.size = sizeof(evsel->core.attr);\n\t\t}\n\t\tf_attr = (struct perf_file_attr){\n\t\t\t.attr = evsel->core.attr,\n\t\t\t.ids  = {\n\t\t\t\t.offset = evsel->id_offset,\n\t\t\t\t.size   = evsel->core.ids * sizeof(u64),\n\t\t\t}\n\t\t};\n\t\terr = do_write(&ff, &f_attr, sizeof(f_attr));\n\t\tif (err < 0) {\n\t\t\tpr_debug(\"failed to write perf header attribute\\n\");\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (!header->data_offset)\n\t\theader->data_offset = lseek(fd, 0, SEEK_CUR);\n\theader->feat_offset = header->data_offset + header->data_size;\n\n\tif (at_exit) {\n\t\terr = perf_header__adds_write(header, evlist, fd, fc);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\tf_header = (struct perf_file_header){\n\t\t.magic\t   = PERF_MAGIC,\n\t\t.size\t   = sizeof(f_header),\n\t\t.attr_size = sizeof(f_attr),\n\t\t.attrs = {\n\t\t\t.offset = attr_offset,\n\t\t\t.size   = evlist->core.nr_entries * sizeof(f_attr),\n\t\t},\n\t\t.data = {\n\t\t\t.offset = header->data_offset,\n\t\t\t.size\t= header->data_size,\n\t\t},\n\t\t \n\t};\n\n\tmemcpy(&f_header.adds_features, &header->adds_features, sizeof(header->adds_features));\n\n\tlseek(fd, 0, SEEK_SET);\n\terr = do_write(&ff, &f_header, sizeof(f_header));\n\tif (err < 0) {\n\t\tpr_debug(\"failed to write perf header\\n\");\n\t\treturn err;\n\t}\n\tlseek(fd, header->data_offset + header->data_size, SEEK_SET);\n\n\treturn 0;\n}\n\nint perf_session__write_header(struct perf_session *session,\n\t\t\t       struct evlist *evlist,\n\t\t\t       int fd, bool at_exit)\n{\n\treturn perf_session__do_write_header(session, evlist, fd, at_exit, NULL);\n}\n\nsize_t perf_session__data_offset(const struct evlist *evlist)\n{\n\tstruct evsel *evsel;\n\tsize_t data_offset;\n\n\tdata_offset = sizeof(struct perf_file_header);\n\tevlist__for_each_entry(evlist, evsel) {\n\t\tdata_offset += evsel->core.ids * sizeof(u64);\n\t}\n\tdata_offset += evlist->core.nr_entries * sizeof(struct perf_file_attr);\n\n\treturn data_offset;\n}\n\nint perf_session__inject_header(struct perf_session *session,\n\t\t\t\tstruct evlist *evlist,\n\t\t\t\tint fd,\n\t\t\t\tstruct feat_copier *fc)\n{\n\treturn perf_session__do_write_header(session, evlist, fd, true, fc);\n}\n\nstatic int perf_header__getbuffer64(struct perf_header *header,\n\t\t\t\t    int fd, void *buf, size_t size)\n{\n\tif (readn(fd, buf, size) <= 0)\n\t\treturn -1;\n\n\tif (header->needs_swap)\n\t\tmem_bswap_64(buf, size);\n\n\treturn 0;\n}\n\nint perf_header__process_sections(struct perf_header *header, int fd,\n\t\t\t\t  void *data,\n\t\t\t\t  int (*process)(struct perf_file_section *section,\n\t\t\t\t\t\t struct perf_header *ph,\n\t\t\t\t\t\t int feat, int fd, void *data))\n{\n\tstruct perf_file_section *feat_sec, *sec;\n\tint nr_sections;\n\tint sec_size;\n\tint feat;\n\tint err;\n\n\tnr_sections = bitmap_weight(header->adds_features, HEADER_FEAT_BITS);\n\tif (!nr_sections)\n\t\treturn 0;\n\n\tfeat_sec = sec = calloc(nr_sections, sizeof(*feat_sec));\n\tif (!feat_sec)\n\t\treturn -1;\n\n\tsec_size = sizeof(*feat_sec) * nr_sections;\n\n\tlseek(fd, header->feat_offset, SEEK_SET);\n\n\terr = perf_header__getbuffer64(header, fd, feat_sec, sec_size);\n\tif (err < 0)\n\t\tgoto out_free;\n\n\tfor_each_set_bit(feat, header->adds_features, HEADER_LAST_FEATURE) {\n\t\terr = process(sec++, header, feat, fd, data);\n\t\tif (err < 0)\n\t\t\tgoto out_free;\n\t}\n\terr = 0;\nout_free:\n\tfree(feat_sec);\n\treturn err;\n}\n\nstatic const int attr_file_abi_sizes[] = {\n\t[0] = PERF_ATTR_SIZE_VER0,\n\t[1] = PERF_ATTR_SIZE_VER1,\n\t[2] = PERF_ATTR_SIZE_VER2,\n\t[3] = PERF_ATTR_SIZE_VER3,\n\t[4] = PERF_ATTR_SIZE_VER4,\n\t0,\n};\n\n \nstatic int try_all_file_abis(uint64_t hdr_sz, struct perf_header *ph)\n{\n\tuint64_t ref_size, attr_size;\n\tint i;\n\n\tfor (i = 0 ; attr_file_abi_sizes[i]; i++) {\n\t\tref_size = attr_file_abi_sizes[i]\n\t\t\t + sizeof(struct perf_file_section);\n\t\tif (hdr_sz != ref_size) {\n\t\t\tattr_size = bswap_64(hdr_sz);\n\t\t\tif (attr_size != ref_size)\n\t\t\t\tcontinue;\n\n\t\t\tph->needs_swap = true;\n\t\t}\n\t\tpr_debug(\"ABI%d perf.data file detected, need_swap=%d\\n\",\n\t\t\t i,\n\t\t\t ph->needs_swap);\n\t\treturn 0;\n\t}\n\t \n\treturn -1;\n}\n\n#define PERF_PIPE_HDR_VER0\t16\n\nstatic const size_t attr_pipe_abi_sizes[] = {\n\t[0] = PERF_PIPE_HDR_VER0,\n\t0,\n};\n\n \nstatic int try_all_pipe_abis(uint64_t hdr_sz, struct perf_header *ph)\n{\n\tu64 attr_size;\n\tint i;\n\n\tfor (i = 0 ; attr_pipe_abi_sizes[i]; i++) {\n\t\tif (hdr_sz != attr_pipe_abi_sizes[i]) {\n\t\t\tattr_size = bswap_64(hdr_sz);\n\t\t\tif (attr_size != hdr_sz)\n\t\t\t\tcontinue;\n\n\t\t\tph->needs_swap = true;\n\t\t}\n\t\tpr_debug(\"Pipe ABI%d perf.data file detected\\n\", i);\n\t\treturn 0;\n\t}\n\treturn -1;\n}\n\nbool is_perf_magic(u64 magic)\n{\n\tif (!memcmp(&magic, __perf_magic1, sizeof(magic))\n\t\t|| magic == __perf_magic2\n\t\t|| magic == __perf_magic2_sw)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int check_magic_endian(u64 magic, uint64_t hdr_sz,\n\t\t\t      bool is_pipe, struct perf_header *ph)\n{\n\tint ret;\n\n\t \n\tret = memcmp(&magic, __perf_magic1, sizeof(magic));\n\tif (ret == 0) {\n\t\tph->version = PERF_HEADER_VERSION_1;\n\t\tpr_debug(\"legacy perf.data format\\n\");\n\t\tif (is_pipe)\n\t\t\treturn try_all_pipe_abis(hdr_sz, ph);\n\n\t\treturn try_all_file_abis(hdr_sz, ph);\n\t}\n\t \n\tph->version = PERF_HEADER_VERSION_2;\n\n\t \n\tif (magic == __perf_magic2)\n\t\treturn 0;\n\n\t \n\tif (magic != __perf_magic2_sw)\n\t\treturn -1;\n\n\tph->needs_swap = true;\n\n\treturn 0;\n}\n\nint perf_file_header__read(struct perf_file_header *header,\n\t\t\t   struct perf_header *ph, int fd)\n{\n\tssize_t ret;\n\n\tlseek(fd, 0, SEEK_SET);\n\n\tret = readn(fd, header, sizeof(*header));\n\tif (ret <= 0)\n\t\treturn -1;\n\n\tif (check_magic_endian(header->magic,\n\t\t\t       header->attr_size, false, ph) < 0) {\n\t\tpr_debug(\"magic/endian check failed\\n\");\n\t\treturn -1;\n\t}\n\n\tif (ph->needs_swap) {\n\t\tmem_bswap_64(header, offsetof(struct perf_file_header,\n\t\t\t     adds_features));\n\t}\n\n\tif (header->size != sizeof(*header)) {\n\t\t \n\t\tif (header->size == offsetof(typeof(*header), adds_features))\n\t\t\tbitmap_zero(header->adds_features, HEADER_FEAT_BITS);\n\t\telse\n\t\t\treturn -1;\n\t} else if (ph->needs_swap) {\n\t\t \n\t\tmem_bswap_64(&header->adds_features,\n\t\t\t    BITS_TO_U64(HEADER_FEAT_BITS));\n\n\t\tif (!test_bit(HEADER_HOSTNAME, header->adds_features)) {\n\t\t\t \n\t\t\tmem_bswap_64(&header->adds_features,\n\t\t\t\t    BITS_TO_U64(HEADER_FEAT_BITS));\n\n\t\t\t \n\t\t\tmem_bswap_32(&header->adds_features,\n\t\t\t\t    BITS_TO_U32(HEADER_FEAT_BITS));\n\t\t}\n\n\t\tif (!test_bit(HEADER_HOSTNAME, header->adds_features)) {\n\t\t\tbitmap_zero(header->adds_features, HEADER_FEAT_BITS);\n\t\t\t__set_bit(HEADER_BUILD_ID, header->adds_features);\n\t\t}\n\t}\n\n\tmemcpy(&ph->adds_features, &header->adds_features,\n\t       sizeof(ph->adds_features));\n\n\tph->data_offset  = header->data.offset;\n\tph->data_size\t = header->data.size;\n\tph->feat_offset  = header->data.offset + header->data.size;\n\treturn 0;\n}\n\nstatic int perf_file_section__process(struct perf_file_section *section,\n\t\t\t\t      struct perf_header *ph,\n\t\t\t\t      int feat, int fd, void *data)\n{\n\tstruct feat_fd fdd = {\n\t\t.fd\t= fd,\n\t\t.ph\t= ph,\n\t\t.size\t= section->size,\n\t\t.offset\t= section->offset,\n\t};\n\n\tif (lseek(fd, section->offset, SEEK_SET) == (off_t)-1) {\n\t\tpr_debug(\"Failed to lseek to %\" PRIu64 \" offset for feature \"\n\t\t\t  \"%d, continuing...\\n\", section->offset, feat);\n\t\treturn 0;\n\t}\n\n\tif (feat >= HEADER_LAST_FEATURE) {\n\t\tpr_debug(\"unknown feature %d, continuing...\\n\", feat);\n\t\treturn 0;\n\t}\n\n\tif (!feat_ops[feat].process)\n\t\treturn 0;\n\n\treturn feat_ops[feat].process(&fdd, data);\n}\n\nstatic int perf_file_header__read_pipe(struct perf_pipe_file_header *header,\n\t\t\t\t       struct perf_header *ph,\n\t\t\t\t       struct perf_data* data,\n\t\t\t\t       bool repipe, int repipe_fd)\n{\n\tstruct feat_fd ff = {\n\t\t.fd = repipe_fd,\n\t\t.ph = ph,\n\t};\n\tssize_t ret;\n\n\tret = perf_data__read(data, header, sizeof(*header));\n\tif (ret <= 0)\n\t\treturn -1;\n\n\tif (check_magic_endian(header->magic, header->size, true, ph) < 0) {\n\t\tpr_debug(\"endian/magic failed\\n\");\n\t\treturn -1;\n\t}\n\n\tif (ph->needs_swap)\n\t\theader->size = bswap_64(header->size);\n\n\tif (repipe && do_write(&ff, header, sizeof(*header)) < 0)\n\t\treturn -1;\n\n\treturn 0;\n}\n\nstatic int perf_header__read_pipe(struct perf_session *session, int repipe_fd)\n{\n\tstruct perf_header *header = &session->header;\n\tstruct perf_pipe_file_header f_header;\n\n\tif (perf_file_header__read_pipe(&f_header, header, session->data,\n\t\t\t\t\tsession->repipe, repipe_fd) < 0) {\n\t\tpr_debug(\"incompatible file format\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn f_header.size == sizeof(f_header) ? 0 : -1;\n}\n\nstatic int read_attr(int fd, struct perf_header *ph,\n\t\t     struct perf_file_attr *f_attr)\n{\n\tstruct perf_event_attr *attr = &f_attr->attr;\n\tsize_t sz, left;\n\tsize_t our_sz = sizeof(f_attr->attr);\n\tssize_t ret;\n\n\tmemset(f_attr, 0, sizeof(*f_attr));\n\n\t \n\tret = readn(fd, attr, PERF_ATTR_SIZE_VER0);\n\tif (ret <= 0) {\n\t\tpr_debug(\"cannot read %d bytes of header attr\\n\",\n\t\t\t PERF_ATTR_SIZE_VER0);\n\t\treturn -1;\n\t}\n\n\t \n\tsz = attr->size;\n\n\tif (ph->needs_swap)\n\t\tsz = bswap_32(sz);\n\n\tif (sz == 0) {\n\t\t \n\t\tsz =  PERF_ATTR_SIZE_VER0;\n\t} else if (sz > our_sz) {\n\t\tpr_debug(\"file uses a more recent and unsupported ABI\"\n\t\t\t \" (%zu bytes extra)\\n\", sz - our_sz);\n\t\treturn -1;\n\t}\n\t \n\tleft = sz - PERF_ATTR_SIZE_VER0;\n\tif (left) {\n\t\tvoid *ptr = attr;\n\t\tptr += PERF_ATTR_SIZE_VER0;\n\n\t\tret = readn(fd, ptr, left);\n\t}\n\t \n\tret = readn(fd, &f_attr->ids, sizeof(f_attr->ids));\n\n\treturn ret <= 0 ? -1 : 0;\n}\n\n#ifdef HAVE_LIBTRACEEVENT\nstatic int evsel__prepare_tracepoint_event(struct evsel *evsel, struct tep_handle *pevent)\n{\n\tstruct tep_event *event;\n\tchar bf[128];\n\n\t \n\tif (evsel->tp_format)\n\t\treturn 0;\n\n\tif (pevent == NULL) {\n\t\tpr_debug(\"broken or missing trace data\\n\");\n\t\treturn -1;\n\t}\n\n\tevent = tep_find_event(pevent, evsel->core.attr.config);\n\tif (event == NULL) {\n\t\tpr_debug(\"cannot find event format for %d\\n\", (int)evsel->core.attr.config);\n\t\treturn -1;\n\t}\n\n\tif (!evsel->name) {\n\t\tsnprintf(bf, sizeof(bf), \"%s:%s\", event->system, event->name);\n\t\tevsel->name = strdup(bf);\n\t\tif (evsel->name == NULL)\n\t\t\treturn -1;\n\t}\n\n\tevsel->tp_format = event;\n\treturn 0;\n}\n\nstatic int evlist__prepare_tracepoint_events(struct evlist *evlist, struct tep_handle *pevent)\n{\n\tstruct evsel *pos;\n\n\tevlist__for_each_entry(evlist, pos) {\n\t\tif (pos->core.attr.type == PERF_TYPE_TRACEPOINT &&\n\t\t    evsel__prepare_tracepoint_event(pos, pevent))\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n#endif\n\nint perf_session__read_header(struct perf_session *session, int repipe_fd)\n{\n\tstruct perf_data *data = session->data;\n\tstruct perf_header *header = &session->header;\n\tstruct perf_file_header\tf_header;\n\tstruct perf_file_attr\tf_attr;\n\tu64\t\t\tf_id;\n\tint nr_attrs, nr_ids, i, j, err;\n\tint fd = perf_data__fd(data);\n\n\tsession->evlist = evlist__new();\n\tif (session->evlist == NULL)\n\t\treturn -ENOMEM;\n\n\tsession->evlist->env = &header->env;\n\tsession->machines.host.env = &header->env;\n\n\t \n\terr = perf_header__read_pipe(session, repipe_fd);\n\tif (!err || perf_data__is_pipe(data)) {\n\t\tdata->is_pipe = true;\n\t\treturn err;\n\t}\n\n\tif (perf_file_header__read(&f_header, header, fd) < 0)\n\t\treturn -EINVAL;\n\n\tif (header->needs_swap && data->in_place_update) {\n\t\tpr_err(\"In-place update not supported when byte-swapping is required\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (f_header.data.size == 0) {\n\t\tpr_warning(\"WARNING: The %s file's data size field is 0 which is unexpected.\\n\"\n\t\t\t   \"Was the 'perf record' command properly terminated?\\n\",\n\t\t\t   data->file.path);\n\t}\n\n\tif (f_header.attr_size == 0) {\n\t\tpr_err(\"ERROR: The %s file's attr size field is 0 which is unexpected.\\n\"\n\t\t       \"Was the 'perf record' command properly terminated?\\n\",\n\t\t       data->file.path);\n\t\treturn -EINVAL;\n\t}\n\n\tnr_attrs = f_header.attrs.size / f_header.attr_size;\n\tlseek(fd, f_header.attrs.offset, SEEK_SET);\n\n\tfor (i = 0; i < nr_attrs; i++) {\n\t\tstruct evsel *evsel;\n\t\toff_t tmp;\n\n\t\tif (read_attr(fd, header, &f_attr) < 0)\n\t\t\tgoto out_errno;\n\n\t\tif (header->needs_swap) {\n\t\t\tf_attr.ids.size   = bswap_64(f_attr.ids.size);\n\t\t\tf_attr.ids.offset = bswap_64(f_attr.ids.offset);\n\t\t\tperf_event__attr_swap(&f_attr.attr);\n\t\t}\n\n\t\ttmp = lseek(fd, 0, SEEK_CUR);\n\t\tevsel = evsel__new(&f_attr.attr);\n\n\t\tif (evsel == NULL)\n\t\t\tgoto out_delete_evlist;\n\n\t\tevsel->needs_swap = header->needs_swap;\n\t\t \n\t\tevlist__add(session->evlist, evsel);\n\n\t\tnr_ids = f_attr.ids.size / sizeof(u64);\n\t\t \n\t\tif (perf_evsel__alloc_id(&evsel->core, 1, nr_ids))\n\t\t\tgoto out_delete_evlist;\n\n\t\tlseek(fd, f_attr.ids.offset, SEEK_SET);\n\n\t\tfor (j = 0; j < nr_ids; j++) {\n\t\t\tif (perf_header__getbuffer64(header, fd, &f_id, sizeof(f_id)))\n\t\t\t\tgoto out_errno;\n\n\t\t\tperf_evlist__id_add(&session->evlist->core, &evsel->core, 0, j, f_id);\n\t\t}\n\n\t\tlseek(fd, tmp, SEEK_SET);\n\t}\n\n#ifdef HAVE_LIBTRACEEVENT\n\tperf_header__process_sections(header, fd, &session->tevent,\n\t\t\t\t      perf_file_section__process);\n\n\tif (evlist__prepare_tracepoint_events(session->evlist, session->tevent.pevent))\n\t\tgoto out_delete_evlist;\n#else\n\tperf_header__process_sections(header, fd, NULL, perf_file_section__process);\n#endif\n\n\treturn 0;\nout_errno:\n\treturn -errno;\n\nout_delete_evlist:\n\tevlist__delete(session->evlist);\n\tsession->evlist = NULL;\n\treturn -ENOMEM;\n}\n\nint perf_event__process_feature(struct perf_session *session,\n\t\t\t\tunion perf_event *event)\n{\n\tstruct perf_tool *tool = session->tool;\n\tstruct feat_fd ff = { .fd = 0 };\n\tstruct perf_record_header_feature *fe = (struct perf_record_header_feature *)event;\n\tint type = fe->header.type;\n\tu64 feat = fe->feat_id;\n\tint ret = 0;\n\n\tif (type < 0 || type >= PERF_RECORD_HEADER_MAX) {\n\t\tpr_warning(\"invalid record type %d in pipe-mode\\n\", type);\n\t\treturn 0;\n\t}\n\tif (feat == HEADER_RESERVED || feat >= HEADER_LAST_FEATURE) {\n\t\tpr_warning(\"invalid record type %d in pipe-mode\\n\", type);\n\t\treturn -1;\n\t}\n\n\tif (!feat_ops[feat].process)\n\t\treturn 0;\n\n\tff.buf  = (void *)fe->data;\n\tff.size = event->header.size - sizeof(*fe);\n\tff.ph = &session->header;\n\n\tif (feat_ops[feat].process(&ff, NULL)) {\n\t\tret = -1;\n\t\tgoto out;\n\t}\n\n\tif (!feat_ops[feat].print || !tool->show_feat_hdr)\n\t\tgoto out;\n\n\tif (!feat_ops[feat].full_only ||\n\t    tool->show_feat_hdr >= SHOW_FEAT_HEADER_FULL_INFO) {\n\t\tfeat_ops[feat].print(&ff, stdout);\n\t} else {\n\t\tfprintf(stdout, \"# %s info available, use -I to display\\n\",\n\t\t\tfeat_ops[feat].name);\n\t}\nout:\n\tfree_event_desc(ff.events);\n\treturn ret;\n}\n\nsize_t perf_event__fprintf_event_update(union perf_event *event, FILE *fp)\n{\n\tstruct perf_record_event_update *ev = &event->event_update;\n\tstruct perf_cpu_map *map;\n\tsize_t ret;\n\n\tret = fprintf(fp, \"\\n... id:    %\" PRI_lu64 \"\\n\", ev->id);\n\n\tswitch (ev->type) {\n\tcase PERF_EVENT_UPDATE__SCALE:\n\t\tret += fprintf(fp, \"... scale: %f\\n\", ev->scale.scale);\n\t\tbreak;\n\tcase PERF_EVENT_UPDATE__UNIT:\n\t\tret += fprintf(fp, \"... unit:  %s\\n\", ev->unit);\n\t\tbreak;\n\tcase PERF_EVENT_UPDATE__NAME:\n\t\tret += fprintf(fp, \"... name:  %s\\n\", ev->name);\n\t\tbreak;\n\tcase PERF_EVENT_UPDATE__CPUS:\n\t\tret += fprintf(fp, \"... \");\n\n\t\tmap = cpu_map__new_data(&ev->cpus.cpus);\n\t\tif (map) {\n\t\t\tret += cpu_map__fprintf(map, fp);\n\t\t\tperf_cpu_map__put(map);\n\t\t} else\n\t\t\tret += fprintf(fp, \"failed to get cpus\\n\");\n\t\tbreak;\n\tdefault:\n\t\tret += fprintf(fp, \"... unknown type\\n\");\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nint perf_event__process_attr(struct perf_tool *tool __maybe_unused,\n\t\t\t     union perf_event *event,\n\t\t\t     struct evlist **pevlist)\n{\n\tu32 i, n_ids;\n\tu64 *ids;\n\tstruct evsel *evsel;\n\tstruct evlist *evlist = *pevlist;\n\n\tif (evlist == NULL) {\n\t\t*pevlist = evlist = evlist__new();\n\t\tif (evlist == NULL)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tevsel = evsel__new(&event->attr.attr);\n\tif (evsel == NULL)\n\t\treturn -ENOMEM;\n\n\tevlist__add(evlist, evsel);\n\n\tn_ids = event->header.size - sizeof(event->header) - event->attr.attr.size;\n\tn_ids = n_ids / sizeof(u64);\n\t \n\tif (perf_evsel__alloc_id(&evsel->core, 1, n_ids))\n\t\treturn -ENOMEM;\n\n\tids = perf_record_header_attr_id(event);\n\tfor (i = 0; i < n_ids; i++) {\n\t\tperf_evlist__id_add(&evlist->core, &evsel->core, 0, i, ids[i]);\n\t}\n\n\treturn 0;\n}\n\nint perf_event__process_event_update(struct perf_tool *tool __maybe_unused,\n\t\t\t\t     union perf_event *event,\n\t\t\t\t     struct evlist **pevlist)\n{\n\tstruct perf_record_event_update *ev = &event->event_update;\n\tstruct evlist *evlist;\n\tstruct evsel *evsel;\n\tstruct perf_cpu_map *map;\n\n\tif (dump_trace)\n\t\tperf_event__fprintf_event_update(event, stdout);\n\n\tif (!pevlist || *pevlist == NULL)\n\t\treturn -EINVAL;\n\n\tevlist = *pevlist;\n\n\tevsel = evlist__id2evsel(evlist, ev->id);\n\tif (evsel == NULL)\n\t\treturn -EINVAL;\n\n\tswitch (ev->type) {\n\tcase PERF_EVENT_UPDATE__UNIT:\n\t\tfree((char *)evsel->unit);\n\t\tevsel->unit = strdup(ev->unit);\n\t\tbreak;\n\tcase PERF_EVENT_UPDATE__NAME:\n\t\tfree(evsel->name);\n\t\tevsel->name = strdup(ev->name);\n\t\tbreak;\n\tcase PERF_EVENT_UPDATE__SCALE:\n\t\tevsel->scale = ev->scale.scale;\n\t\tbreak;\n\tcase PERF_EVENT_UPDATE__CPUS:\n\t\tmap = cpu_map__new_data(&ev->cpus.cpus);\n\t\tif (map) {\n\t\t\tperf_cpu_map__put(evsel->core.own_cpus);\n\t\t\tevsel->core.own_cpus = map;\n\t\t} else\n\t\t\tpr_err(\"failed to get event_update cpus\\n\");\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n#ifdef HAVE_LIBTRACEEVENT\nint perf_event__process_tracing_data(struct perf_session *session,\n\t\t\t\t     union perf_event *event)\n{\n\tssize_t size_read, padding, size = event->tracing_data.size;\n\tint fd = perf_data__fd(session->data);\n\tchar buf[BUFSIZ];\n\n\t \n\tif (!perf_data__is_pipe(session->data)) {\n\t\toff_t offset = lseek(fd, 0, SEEK_CUR);\n\n\t\t \n\t\tlseek(fd, offset + sizeof(struct perf_record_header_tracing_data),\n\t\t      SEEK_SET);\n\t}\n\n\tsize_read = trace_report(fd, &session->tevent,\n\t\t\t\t session->repipe);\n\tpadding = PERF_ALIGN(size_read, sizeof(u64)) - size_read;\n\n\tif (readn(fd, buf, padding) < 0) {\n\t\tpr_err(\"%s: reading input file\", __func__);\n\t\treturn -1;\n\t}\n\tif (session->repipe) {\n\t\tint retw = write(STDOUT_FILENO, buf, padding);\n\t\tif (retw <= 0 || retw != padding) {\n\t\t\tpr_err(\"%s: repiping tracing data padding\", __func__);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (size_read + padding != size) {\n\t\tpr_err(\"%s: tracing data size mismatch\", __func__);\n\t\treturn -1;\n\t}\n\n\tevlist__prepare_tracepoint_events(session->evlist, session->tevent.pevent);\n\n\treturn size_read + padding;\n}\n#endif\n\nint perf_event__process_build_id(struct perf_session *session,\n\t\t\t\t union perf_event *event)\n{\n\t__event_process_build_id(&event->build_id,\n\t\t\t\t event->build_id.filename,\n\t\t\t\t session);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}