{
  "module_name": "bpf_ftrace.c",
  "hash_id": "166540bb11929c9c71b41655d3d38795c94db06cd087a6627f1351076b461ecf",
  "original_prompt": "Ingested from linux-6.6.14/tools/perf/util/bpf_ftrace.c",
  "human_readable_source": "#include <stdio.h>\n#include <fcntl.h>\n#include <stdint.h>\n#include <stdlib.h>\n\n#include <linux/err.h>\n\n#include \"util/ftrace.h\"\n#include \"util/cpumap.h\"\n#include \"util/thread_map.h\"\n#include \"util/debug.h\"\n#include \"util/evlist.h\"\n#include \"util/bpf_counter.h\"\n\n#include \"util/bpf_skel/func_latency.skel.h\"\n\nstatic struct func_latency_bpf *skel;\n\nint perf_ftrace__latency_prepare_bpf(struct perf_ftrace *ftrace)\n{\n\tint fd, err;\n\tint i, ncpus = 1, ntasks = 1;\n\tstruct filter_entry *func;\n\n\tif (!list_is_singular(&ftrace->filters)) {\n\t\tpr_err(\"ERROR: %s target function(s).\\n\",\n\t\t       list_empty(&ftrace->filters) ? \"No\" : \"Too many\");\n\t\treturn -1;\n\t}\n\n\tfunc = list_first_entry(&ftrace->filters, struct filter_entry, list);\n\n\tskel = func_latency_bpf__open();\n\tif (!skel) {\n\t\tpr_err(\"Failed to open func latency skeleton\\n\");\n\t\treturn -1;\n\t}\n\n\t \n\tif (ftrace->target.cpu_list) {\n\t\tncpus = perf_cpu_map__nr(ftrace->evlist->core.user_requested_cpus);\n\t\tbpf_map__set_max_entries(skel->maps.cpu_filter, ncpus);\n\t}\n\n\tif (target__has_task(&ftrace->target) || target__none(&ftrace->target)) {\n\t\tntasks = perf_thread_map__nr(ftrace->evlist->core.threads);\n\t\tbpf_map__set_max_entries(skel->maps.task_filter, ntasks);\n\t}\n\n\tset_max_rlimit();\n\n\terr = func_latency_bpf__load(skel);\n\tif (err) {\n\t\tpr_err(\"Failed to load func latency skeleton\\n\");\n\t\tgoto out;\n\t}\n\n\tif (ftrace->target.cpu_list) {\n\t\tu32 cpu;\n\t\tu8 val = 1;\n\n\t\tskel->bss->has_cpu = 1;\n\t\tfd = bpf_map__fd(skel->maps.cpu_filter);\n\n\t\tfor (i = 0; i < ncpus; i++) {\n\t\t\tcpu = perf_cpu_map__cpu(ftrace->evlist->core.user_requested_cpus, i).cpu;\n\t\t\tbpf_map_update_elem(fd, &cpu, &val, BPF_ANY);\n\t\t}\n\t}\n\n\tif (target__has_task(&ftrace->target) || target__none(&ftrace->target)) {\n\t\tu32 pid;\n\t\tu8 val = 1;\n\n\t\tskel->bss->has_task = 1;\n\t\tfd = bpf_map__fd(skel->maps.task_filter);\n\n\t\tfor (i = 0; i < ntasks; i++) {\n\t\t\tpid = perf_thread_map__pid(ftrace->evlist->core.threads, i);\n\t\t\tbpf_map_update_elem(fd, &pid, &val, BPF_ANY);\n\t\t}\n\t}\n\n\tskel->bss->use_nsec = ftrace->use_nsec;\n\n\tskel->links.func_begin = bpf_program__attach_kprobe(skel->progs.func_begin,\n\t\t\t\t\t\t\t    false, func->name);\n\tif (IS_ERR(skel->links.func_begin)) {\n\t\tpr_err(\"Failed to attach fentry program\\n\");\n\t\terr = PTR_ERR(skel->links.func_begin);\n\t\tgoto out;\n\t}\n\n\tskel->links.func_end = bpf_program__attach_kprobe(skel->progs.func_end,\n\t\t\t\t\t\t\t  true, func->name);\n\tif (IS_ERR(skel->links.func_end)) {\n\t\tpr_err(\"Failed to attach fexit program\\n\");\n\t\terr = PTR_ERR(skel->links.func_end);\n\t\tgoto out;\n\t}\n\n\t \n\treturn open(\"/dev/null\", O_RDONLY);\n\nout:\n\treturn err;\n}\n\nint perf_ftrace__latency_start_bpf(struct perf_ftrace *ftrace __maybe_unused)\n{\n\tskel->bss->enabled = 1;\n\treturn 0;\n}\n\nint perf_ftrace__latency_stop_bpf(struct perf_ftrace *ftrace __maybe_unused)\n{\n\tskel->bss->enabled = 0;\n\treturn 0;\n}\n\nint perf_ftrace__latency_read_bpf(struct perf_ftrace *ftrace __maybe_unused,\n\t\t\t\t  int buckets[])\n{\n\tint i, fd, err;\n\tu32 idx;\n\tu64 *hist;\n\tint ncpus = cpu__max_cpu().cpu;\n\n\tfd = bpf_map__fd(skel->maps.latency);\n\n\thist = calloc(ncpus, sizeof(*hist));\n\tif (hist == NULL)\n\t\treturn -ENOMEM;\n\n\tfor (idx = 0; idx < NUM_BUCKET; idx++) {\n\t\terr = bpf_map_lookup_elem(fd, &idx, hist);\n\t\tif (err) {\n\t\t\tbuckets[idx] = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor (i = 0; i < ncpus; i++)\n\t\t\tbuckets[idx] += hist[i];\n\t}\n\n\tfree(hist);\n\treturn 0;\n}\n\nint perf_ftrace__latency_cleanup_bpf(struct perf_ftrace *ftrace __maybe_unused)\n{\n\tfunc_latency_bpf__destroy(skel);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}