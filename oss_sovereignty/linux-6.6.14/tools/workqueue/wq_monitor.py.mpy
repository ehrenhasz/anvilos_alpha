{
  "module_name": "wq_monitor.py",
  "hash_id": "9a530690a0706cda1a4f19c3daafa9ccef642ade119c25230efb7441bab1048d",
  "original_prompt": "Ingested from linux-6.6.14/tools/workqueue/wq_monitor.py",
  "human_readable_source": "#!/usr/bin/env drgn\n#\n# Copyright (C) 2023 Tejun Heo <tj@kernel.org>\n# Copyright (C) 2023 Meta Platforms, Inc. and affiliates.\n\ndesc = \"\"\"\nThis is a drgn script to monitor workqueues. For more info on drgn, visit\nhttps://github.com/osandov/drgn.\n\n  total    Total number of work items executed by the workqueue.\n\n  infl     The number of currently in-flight work items.\n\n  CPUtime  Total CPU time consumed by the workqueue in seconds. This is\n           sampled from scheduler ticks and only provides ballpark\n           measurement. \"nohz_full=\" CPUs are excluded from measurement.\n\n  CPUitsv  The number of times a concurrency-managed work item hogged CPU\n           longer than the threshold (workqueue.cpu_intensive_thresh_us)\n           and got excluded from concurrency management to avoid stalling\n           other work items.\n\n  CMW/RPR  For per-cpu workqueues, the number of concurrency-management\n           wake-ups while executing a work item of the workqueue. For\n           unbound workqueues, the number of times a worker was repatriated\n           to its affinity scope after being migrated to an off-scope CPU by\n           the scheduler.\n\n  mayday   The number of times the rescuer was requested while waiting for\n           new worker creation.\n\n  rescued  The number of work items executed by the rescuer.\n\"\"\"\n\nimport sys\nimport signal\nimport os\nimport re\nimport time\nimport json\n\nimport drgn\nfrom drgn.helpers.linux.list import list_for_each_entry,list_empty\nfrom drgn.helpers.linux.cpumask import for_each_possible_cpu\n\nimport argparse\nparser = argparse.ArgumentParser(description=desc,\n                                 formatter_class=argparse.RawTextHelpFormatter)\nparser.add_argument('workqueue', metavar='REGEX', nargs='*',\n                    help='Target workqueue name patterns (all if empty)')\nparser.add_argument('-i', '--interval', metavar='SECS', type=float, default=1,\n                    help='Monitoring interval (0 to print once and exit)')\nparser.add_argument('-j', '--json', action='store_true',\n                    help='Output in json')\nargs = parser.parse_args()\n\ndef err(s):\n    print(s, file=sys.stderr, flush=True)\n    sys.exit(1)\n\nworkqueues              = prog['workqueues']\n\nWQ_UNBOUND              = prog['WQ_UNBOUND']\nWQ_MEM_RECLAIM          = prog['WQ_MEM_RECLAIM']\n\nPWQ_STAT_STARTED        = prog['PWQ_STAT_STARTED']      # work items started execution\nPWQ_STAT_COMPLETED      = prog['PWQ_STAT_COMPLETED']\t# work items completed execution\nPWQ_STAT_CPU_TIME       = prog['PWQ_STAT_CPU_TIME']     # total CPU time consumed\nPWQ_STAT_CPU_INTENSIVE  = prog['PWQ_STAT_CPU_INTENSIVE'] # wq_cpu_intensive_thresh_us violations\nPWQ_STAT_CM_WAKEUP      = prog['PWQ_STAT_CM_WAKEUP']    # concurrency-management worker wakeups\nPWQ_STAT_REPATRIATED    = prog['PWQ_STAT_REPATRIATED']  # unbound workers brought back into scope\nPWQ_STAT_MAYDAY         = prog['PWQ_STAT_MAYDAY']\t# maydays to rescuer\nPWQ_STAT_RESCUED        = prog['PWQ_STAT_RESCUED']\t# linked work items executed by rescuer\nPWQ_NR_STATS            = prog['PWQ_NR_STATS']\n\nclass WqStats:\n    def __init__(self, wq):\n        self.name = wq.name.string_().decode()\n        self.unbound = wq.flags & WQ_UNBOUND != 0\n        self.mem_reclaim = wq.flags & WQ_MEM_RECLAIM != 0\n        self.stats = [0] * PWQ_NR_STATS\n        for pwq in list_for_each_entry('struct pool_workqueue', wq.pwqs.address_of_(), 'pwqs_node'):\n            for i in range(PWQ_NR_STATS):\n                self.stats[i] += int(pwq.stats[i])\n\n    def dict(self, now):\n        return { 'timestamp'            : now,\n                 'name'                 : self.name,\n                 'unbound'              : self.unbound,\n                 'mem_reclaim'          : self.mem_reclaim,\n                 'started'              : self.stats[PWQ_STAT_STARTED],\n                 'completed'            : self.stats[PWQ_STAT_COMPLETED],\n                 'cpu_time'             : self.stats[PWQ_STAT_CPU_TIME],\n                 'cpu_intensive'        : self.stats[PWQ_STAT_CPU_INTENSIVE],\n                 'cm_wakeup'            : self.stats[PWQ_STAT_CM_WAKEUP],\n                 'repatriated'          : self.stats[PWQ_STAT_REPATRIATED],\n                 'mayday'               : self.stats[PWQ_STAT_MAYDAY],\n                 'rescued'              : self.stats[PWQ_STAT_RESCUED], }\n\n    def table_header_str():\n        return f'{\"\":>24} {\"total\":>8} {\"infl\":>5} {\"CPUtime\":>8} '\\\n            f'{\"CPUitsv\":>7} {\"CMW/RPR\":>7} {\"mayday\":>7} {\"rescued\":>7}'\n\n    def table_row_str(self):\n        cpu_intensive = '-'\n        cmw_rpr = '-'\n        mayday = '-'\n        rescued = '-'\n\n        if self.unbound:\n            cmw_rpr = str(self.stats[PWQ_STAT_REPATRIATED]);\n        else:\n            cpu_intensive = str(self.stats[PWQ_STAT_CPU_INTENSIVE])\n            cmw_rpr = str(self.stats[PWQ_STAT_CM_WAKEUP])\n\n        if self.mem_reclaim:\n            mayday = str(self.stats[PWQ_STAT_MAYDAY])\n            rescued = str(self.stats[PWQ_STAT_RESCUED])\n\n        out = f'{self.name[-24:]:24} ' \\\n              f'{self.stats[PWQ_STAT_STARTED]:8} ' \\\n              f'{max(self.stats[PWQ_STAT_STARTED] - self.stats[PWQ_STAT_COMPLETED], 0):5} ' \\\n              f'{self.stats[PWQ_STAT_CPU_TIME] / 1000000:8.1f} ' \\\n              f'{cpu_intensive:>7} ' \\\n              f'{cmw_rpr:>7} ' \\\n              f'{mayday:>7} ' \\\n              f'{rescued:>7} '\n        return out.rstrip(':')\n\nexit_req = False\n\ndef sigint_handler(signr, frame):\n    global exit_req\n    exit_req = True\n\ndef main():\n    # handle args\n    table_fmt = not args.json\n    interval = args.interval\n\n    re_str = None\n    if args.workqueue:\n        for r in args.workqueue:\n            if re_str is None:\n                re_str = r\n            else:\n                re_str += '|' + r\n\n    filter_re = re.compile(re_str) if re_str else None\n\n    # monitoring loop\n    signal.signal(signal.SIGINT, sigint_handler)\n\n    while not exit_req:\n        now = time.time()\n\n        if table_fmt:\n            print()\n            print(WqStats.table_header_str())\n\n        for wq in list_for_each_entry('struct workqueue_struct', workqueues.address_of_(), 'list'):\n            stats = WqStats(wq)\n            if filter_re and not filter_re.search(stats.name):\n                continue\n            if table_fmt:\n                print(stats.table_row_str())\n            else:\n                print(stats.dict(now))\n\n        if interval == 0:\n            break\n        time.sleep(interval)\n\nif __name__ == \"__main__\":\n    main()\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}