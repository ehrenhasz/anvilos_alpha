{
  "module_name": "skl-sst-cldma.c",
  "hash_id": "de9af6f59f4d3e3b3b1451786f61282469ef71bb6c93ab206c728a91780df5b9",
  "original_prompt": "Ingested from linux-6.6.14/sound/soc/intel/skylake/skl-sst-cldma.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/io.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <sound/hda_register.h>\n#include \"../common/sst-dsp.h\"\n#include \"../common/sst-dsp-priv.h\"\n\nstatic void skl_cldma_int_enable(struct sst_dsp *ctx)\n{\n\tsst_dsp_shim_update_bits_unlocked(ctx, SKL_ADSP_REG_ADSPIC,\n\t\t\t\tSKL_ADSPIC_CL_DMA, SKL_ADSPIC_CL_DMA);\n}\n\nvoid skl_cldma_int_disable(struct sst_dsp *ctx)\n{\n\tsst_dsp_shim_update_bits_unlocked(ctx,\n\t\t\tSKL_ADSP_REG_ADSPIC, SKL_ADSPIC_CL_DMA, 0);\n}\n\nstatic void skl_cldma_stream_run(struct sst_dsp  *ctx, bool enable)\n{\n\tunsigned char val;\n\tint timeout;\n\n\tsst_dsp_shim_update_bits_unlocked(ctx,\n\t\t\tSKL_ADSP_REG_CL_SD_CTL,\n\t\t\tCL_SD_CTL_RUN_MASK, CL_SD_CTL_RUN(enable));\n\n\tudelay(3);\n\ttimeout = 300;\n\tdo {\n\t\t \n\t\tval = sst_dsp_shim_read(ctx, SKL_ADSP_REG_CL_SD_CTL) &\n\t\t\tCL_SD_CTL_RUN_MASK;\n\t\tif (enable && val)\n\t\t\tbreak;\n\t\telse if (!enable && !val)\n\t\t\tbreak;\n\t\tudelay(3);\n\t} while (--timeout);\n\n\tif (timeout == 0)\n\t\tdev_err(ctx->dev, \"Failed to set Run bit=%d enable=%d\\n\", val, enable);\n}\n\nstatic void skl_cldma_stream_clear(struct sst_dsp  *ctx)\n{\n\t \n\tskl_cldma_stream_run(ctx, 0);\n\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\t\tCL_SD_CTL_IOCE_MASK, CL_SD_CTL_IOCE(0));\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\t\tCL_SD_CTL_FEIE_MASK, CL_SD_CTL_FEIE(0));\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\t\tCL_SD_CTL_DEIE_MASK, CL_SD_CTL_DEIE(0));\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\t\tCL_SD_CTL_STRM_MASK, CL_SD_CTL_STRM(0));\n\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_BDLPL, CL_SD_BDLPLBA(0));\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_BDLPU, 0);\n\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_CBL, 0);\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_LVI, 0);\n}\n\n \nstatic void skl_cldma_setup_bdle(struct sst_dsp *ctx,\n\t\tstruct snd_dma_buffer *dmab_data,\n\t\t__le32 **bdlp, int size, int with_ioc)\n{\n\t__le32 *bdl = *bdlp;\n\tint remaining = ctx->cl_dev.bufsize;\n\tint offset = 0;\n\n\tctx->cl_dev.frags = 0;\n\twhile (remaining > 0) {\n\t\tphys_addr_t addr;\n\t\tint chunk;\n\n\t\taddr = snd_sgbuf_get_addr(dmab_data, offset);\n\t\tbdl[0] = cpu_to_le32(lower_32_bits(addr));\n\t\tbdl[1] = cpu_to_le32(upper_32_bits(addr));\n\t\tchunk = snd_sgbuf_get_chunk_size(dmab_data, offset, size);\n\t\tbdl[2] = cpu_to_le32(chunk);\n\n\t\tremaining -= chunk;\n\t\tbdl[3] = (remaining > 0) ? 0 : cpu_to_le32(0x01);\n\n\t\tbdl += 4;\n\t\toffset += chunk;\n\t\tctx->cl_dev.frags++;\n\t}\n}\n\n \nstatic void skl_cldma_setup_controller(struct sst_dsp  *ctx,\n\t\tstruct snd_dma_buffer *dmab_bdl, unsigned int max_size,\n\t\tu32 count)\n{\n\tskl_cldma_stream_clear(ctx);\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_BDLPL,\n\t\t\tCL_SD_BDLPLBA(dmab_bdl->addr));\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_BDLPU,\n\t\t\tCL_SD_BDLPUBA(dmab_bdl->addr));\n\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_CBL, max_size);\n\tsst_dsp_shim_write(ctx, SKL_ADSP_REG_CL_SD_LVI, count - 1);\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\tCL_SD_CTL_IOCE_MASK, CL_SD_CTL_IOCE(1));\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\tCL_SD_CTL_FEIE_MASK, CL_SD_CTL_FEIE(1));\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\tCL_SD_CTL_DEIE_MASK, CL_SD_CTL_DEIE(1));\n\tsst_dsp_shim_update_bits(ctx, SKL_ADSP_REG_CL_SD_CTL,\n\t\t\tCL_SD_CTL_STRM_MASK, CL_SD_CTL_STRM(FW_CL_STREAM_NUMBER));\n}\n\nstatic void skl_cldma_setup_spb(struct sst_dsp  *ctx,\n\t\tunsigned int size, bool enable)\n{\n\tif (enable)\n\t\tsst_dsp_shim_update_bits_unlocked(ctx,\n\t\t\t\tSKL_ADSP_REG_CL_SPBFIFO_SPBFCCTL,\n\t\t\t\tCL_SPBFIFO_SPBFCCTL_SPIBE_MASK,\n\t\t\t\tCL_SPBFIFO_SPBFCCTL_SPIBE(1));\n\n\tsst_dsp_shim_write_unlocked(ctx, SKL_ADSP_REG_CL_SPBFIFO_SPIB, size);\n}\n\nstatic void skl_cldma_cleanup_spb(struct sst_dsp  *ctx)\n{\n\tsst_dsp_shim_update_bits_unlocked(ctx,\n\t\t\tSKL_ADSP_REG_CL_SPBFIFO_SPBFCCTL,\n\t\t\tCL_SPBFIFO_SPBFCCTL_SPIBE_MASK,\n\t\t\tCL_SPBFIFO_SPBFCCTL_SPIBE(0));\n\n\tsst_dsp_shim_write_unlocked(ctx, SKL_ADSP_REG_CL_SPBFIFO_SPIB, 0);\n}\n\nstatic void skl_cldma_cleanup(struct sst_dsp  *ctx)\n{\n\tskl_cldma_cleanup_spb(ctx);\n\tskl_cldma_stream_clear(ctx);\n\n\tctx->dsp_ops.free_dma_buf(ctx->dev, &ctx->cl_dev.dmab_data);\n\tctx->dsp_ops.free_dma_buf(ctx->dev, &ctx->cl_dev.dmab_bdl);\n}\n\nint skl_cldma_wait_interruptible(struct sst_dsp *ctx)\n{\n\tint ret = 0;\n\n\tif (!wait_event_timeout(ctx->cl_dev.wait_queue,\n\t\t\t\tctx->cl_dev.wait_condition,\n\t\t\t\tmsecs_to_jiffies(SKL_WAIT_TIMEOUT))) {\n\t\tdev_err(ctx->dev, \"%s: Wait timeout\\n\", __func__);\n\t\tret = -EIO;\n\t\tgoto cleanup;\n\t}\n\n\tdev_dbg(ctx->dev, \"%s: Event wake\\n\", __func__);\n\tif (ctx->cl_dev.wake_status != SKL_CL_DMA_BUF_COMPLETE) {\n\t\tdev_err(ctx->dev, \"%s: DMA Error\\n\", __func__);\n\t\tret = -EIO;\n\t}\n\ncleanup:\n\tctx->cl_dev.wake_status = SKL_CL_DMA_STATUS_NONE;\n\treturn ret;\n}\n\nstatic void skl_cldma_stop(struct sst_dsp *ctx)\n{\n\tskl_cldma_stream_run(ctx, false);\n}\n\nstatic void skl_cldma_fill_buffer(struct sst_dsp *ctx, unsigned int size,\n\t\tconst void *curr_pos, bool intr_enable, bool trigger)\n{\n\tdev_dbg(ctx->dev, \"Size: %x, intr_enable: %d\\n\", size, intr_enable);\n\tdev_dbg(ctx->dev, \"buf_pos_index:%d, trigger:%d\\n\",\n\t\t\tctx->cl_dev.dma_buffer_offset, trigger);\n\tdev_dbg(ctx->dev, \"spib position: %d\\n\", ctx->cl_dev.curr_spib_pos);\n\n\t \n\tif (ctx->cl_dev.dma_buffer_offset + size > ctx->cl_dev.bufsize) {\n\t\tunsigned int size_b = ctx->cl_dev.bufsize -\n\t\t\t\t\tctx->cl_dev.dma_buffer_offset;\n\t\tmemcpy(ctx->cl_dev.dmab_data.area + ctx->cl_dev.dma_buffer_offset,\n\t\t\tcurr_pos, size_b);\n\t\tsize -= size_b;\n\t\tcurr_pos += size_b;\n\t\tctx->cl_dev.dma_buffer_offset = 0;\n\t}\n\n\tmemcpy(ctx->cl_dev.dmab_data.area + ctx->cl_dev.dma_buffer_offset,\n\t\t\tcurr_pos, size);\n\n\tif (ctx->cl_dev.curr_spib_pos == ctx->cl_dev.bufsize)\n\t\tctx->cl_dev.dma_buffer_offset = 0;\n\telse\n\t\tctx->cl_dev.dma_buffer_offset = ctx->cl_dev.curr_spib_pos;\n\n\tctx->cl_dev.wait_condition = false;\n\n\tif (intr_enable)\n\t\tskl_cldma_int_enable(ctx);\n\n\tctx->cl_dev.ops.cl_setup_spb(ctx, ctx->cl_dev.curr_spib_pos, trigger);\n\tif (trigger)\n\t\tctx->cl_dev.ops.cl_trigger(ctx, true);\n}\n\n \nstatic int\nskl_cldma_copy_to_buf(struct sst_dsp *ctx, const void *bin,\n\t\t\tu32 total_size, bool wait)\n{\n\tint ret;\n\tbool start = true;\n\tunsigned int excess_bytes;\n\tu32 size;\n\tunsigned int bytes_left = total_size;\n\tconst void *curr_pos = bin;\n\n\tif (total_size <= 0)\n\t\treturn -EINVAL;\n\n\tdev_dbg(ctx->dev, \"%s: Total binary size: %u\\n\", __func__, bytes_left);\n\n\twhile (bytes_left) {\n\t\tif (bytes_left > ctx->cl_dev.bufsize) {\n\n\t\t\t \n\t\t\tif (ctx->cl_dev.curr_spib_pos == 0)\n\t\t\t\tctx->cl_dev.curr_spib_pos = ctx->cl_dev.bufsize;\n\n\t\t\tsize = ctx->cl_dev.bufsize;\n\t\t\tskl_cldma_fill_buffer(ctx, size, curr_pos, true, start);\n\n\t\t\tif (wait) {\n\t\t\t\tstart = false;\n\t\t\t\tret = skl_cldma_wait_interruptible(ctx);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tskl_cldma_stop(ctx);\n\t\t\t\t\treturn ret;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tskl_cldma_int_disable(ctx);\n\n\t\t\tif ((ctx->cl_dev.curr_spib_pos + bytes_left)\n\t\t\t\t\t\t\t<= ctx->cl_dev.bufsize) {\n\t\t\t\tctx->cl_dev.curr_spib_pos += bytes_left;\n\t\t\t} else {\n\t\t\t\texcess_bytes = bytes_left -\n\t\t\t\t\t(ctx->cl_dev.bufsize -\n\t\t\t\t\tctx->cl_dev.curr_spib_pos);\n\t\t\t\tctx->cl_dev.curr_spib_pos = excess_bytes;\n\t\t\t}\n\n\t\t\tsize = bytes_left;\n\t\t\tskl_cldma_fill_buffer(ctx, size,\n\t\t\t\t\tcurr_pos, false, start);\n\t\t}\n\t\tbytes_left -= size;\n\t\tcurr_pos = curr_pos + size;\n\t\tif (!wait)\n\t\t\treturn bytes_left;\n\t}\n\n\treturn bytes_left;\n}\n\nvoid skl_cldma_process_intr(struct sst_dsp *ctx)\n{\n\tu8 cl_dma_intr_status;\n\n\tcl_dma_intr_status =\n\t\tsst_dsp_shim_read_unlocked(ctx, SKL_ADSP_REG_CL_SD_STS);\n\n\tif (!(cl_dma_intr_status & SKL_CL_DMA_SD_INT_COMPLETE))\n\t\tctx->cl_dev.wake_status = SKL_CL_DMA_ERR;\n\telse\n\t\tctx->cl_dev.wake_status = SKL_CL_DMA_BUF_COMPLETE;\n\n\tctx->cl_dev.wait_condition = true;\n\twake_up(&ctx->cl_dev.wait_queue);\n}\n\nint skl_cldma_prepare(struct sst_dsp *ctx)\n{\n\tint ret;\n\t__le32 *bdl;\n\n\tctx->cl_dev.bufsize = SKL_MAX_BUFFER_SIZE;\n\n\t \n\tctx->cl_dev.ops.cl_setup_bdle = skl_cldma_setup_bdle;\n\tctx->cl_dev.ops.cl_setup_controller = skl_cldma_setup_controller;\n\tctx->cl_dev.ops.cl_setup_spb = skl_cldma_setup_spb;\n\tctx->cl_dev.ops.cl_cleanup_spb = skl_cldma_cleanup_spb;\n\tctx->cl_dev.ops.cl_trigger = skl_cldma_stream_run;\n\tctx->cl_dev.ops.cl_cleanup_controller = skl_cldma_cleanup;\n\tctx->cl_dev.ops.cl_copy_to_dmabuf = skl_cldma_copy_to_buf;\n\tctx->cl_dev.ops.cl_stop_dma = skl_cldma_stop;\n\n\t \n\tret = snd_dma_alloc_pages(SNDRV_DMA_TYPE_DEV_SG, ctx->dev, ctx->cl_dev.bufsize,\n\t\t\t\t  &ctx->cl_dev.dmab_data);\n\tif (ret < 0) {\n\t\tdev_err(ctx->dev, \"Alloc buffer for base fw failed: %x\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tret = snd_dma_alloc_pages(SNDRV_DMA_TYPE_DEV, ctx->dev, BDL_SIZE, &ctx->cl_dev.dmab_bdl);\n\tif (ret < 0) {\n\t\tdev_err(ctx->dev, \"Alloc buffer for blde failed: %x\\n\", ret);\n\t\tctx->dsp_ops.free_dma_buf(ctx->dev, &ctx->cl_dev.dmab_data);\n\t\treturn ret;\n\t}\n\tbdl = (__le32 *)ctx->cl_dev.dmab_bdl.area;\n\n\t \n\tctx->cl_dev.ops.cl_setup_bdle(ctx, &ctx->cl_dev.dmab_data,\n\t\t\t&bdl, ctx->cl_dev.bufsize, 1);\n\tctx->cl_dev.ops.cl_setup_controller(ctx, &ctx->cl_dev.dmab_bdl,\n\t\t\tctx->cl_dev.bufsize, ctx->cl_dev.frags);\n\n\tctx->cl_dev.curr_spib_pos = 0;\n\tctx->cl_dev.dma_buffer_offset = 0;\n\tinit_waitqueue_head(&ctx->cl_dev.wait_queue);\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}