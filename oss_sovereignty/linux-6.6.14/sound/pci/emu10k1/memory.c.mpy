{
  "module_name": "memory.c",
  "hash_id": "ce8121b621fa75d9fc46c5a06f717c1ba32513616c76ebd4b5122514d3e3bac8",
  "original_prompt": "Ingested from linux-6.6.14/sound/pci/emu10k1/memory.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n#include <linux/gfp.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n\n#include <sound/core.h>\n#include <sound/emu10k1.h>\n\n \n#define __set_ptb_entry(emu,page,addr) \\\n\t(((__le32 *)(emu)->ptb_pages.area)[page] = \\\n\t cpu_to_le32(((addr) << (emu->address_mode)) | (page)))\n#define __get_ptb_entry(emu, page) \\\n\t(le32_to_cpu(((__le32 *)(emu)->ptb_pages.area)[page]))\n\n#define UNIT_PAGES\t\t(PAGE_SIZE / EMUPAGESIZE)\n#define MAX_ALIGN_PAGES0\t\t(MAXPAGES0 / UNIT_PAGES)\n#define MAX_ALIGN_PAGES1\t\t(MAXPAGES1 / UNIT_PAGES)\n \n#define get_aligned_page(offset)\t((offset) >> PAGE_SHIFT)\n \n#define aligned_page_offset(page)\t((page) << PAGE_SHIFT)\n\n#if PAGE_SIZE == EMUPAGESIZE && !IS_ENABLED(CONFIG_DYNAMIC_DEBUG)\n \n#define set_ptb_entry(emu,page,addr)\t__set_ptb_entry(emu,page,addr)\n \n#define set_silent_ptb(emu,page)\t__set_ptb_entry(emu,page,emu->silent_page.addr)\n#else\n \nstatic inline void set_ptb_entry(struct snd_emu10k1 *emu, int page, dma_addr_t addr)\n{\n\tint i;\n\tpage *= UNIT_PAGES;\n\tfor (i = 0; i < UNIT_PAGES; i++, page++) {\n\t\t__set_ptb_entry(emu, page, addr);\n\t\tdev_dbg(emu->card->dev, \"mapped page %d to entry %.8x\\n\", page,\n\t\t\t(unsigned int)__get_ptb_entry(emu, page));\n\t\taddr += EMUPAGESIZE;\n\t}\n}\nstatic inline void set_silent_ptb(struct snd_emu10k1 *emu, int page)\n{\n\tint i;\n\tpage *= UNIT_PAGES;\n\tfor (i = 0; i < UNIT_PAGES; i++, page++) {\n\t\t \n\t\t__set_ptb_entry(emu, page, emu->silent_page.addr);\n\t\tdev_dbg(emu->card->dev, \"mapped silent page %d to entry %.8x\\n\",\n\t\t\tpage, (unsigned int)__get_ptb_entry(emu, page));\n\t}\n}\n#endif  \n\n\n \nstatic int synth_alloc_pages(struct snd_emu10k1 *hw, struct snd_emu10k1_memblk *blk);\nstatic int synth_free_pages(struct snd_emu10k1 *hw, struct snd_emu10k1_memblk *blk);\n\n#define get_emu10k1_memblk(l,member)\tlist_entry(l, struct snd_emu10k1_memblk, member)\n\n\n \nstatic void emu10k1_memblk_init(struct snd_emu10k1_memblk *blk)\n{\n\tblk->mapped_page = -1;\n\tINIT_LIST_HEAD(&blk->mapped_link);\n\tINIT_LIST_HEAD(&blk->mapped_order_link);\n\tblk->map_locked = 0;\n\n\tblk->first_page = get_aligned_page(blk->mem.offset);\n\tblk->last_page = get_aligned_page(blk->mem.offset + blk->mem.size - 1);\n\tblk->pages = blk->last_page - blk->first_page + 1;\n}\n\n \nstatic int search_empty_map_area(struct snd_emu10k1 *emu, int npages, struct list_head **nextp)\n{\n\tint page = 1, found_page = -ENOMEM;\n\tint max_size = npages;\n\tint size;\n\tstruct list_head *candidate = &emu->mapped_link_head;\n\tstruct list_head *pos;\n\n\tlist_for_each (pos, &emu->mapped_link_head) {\n\t\tstruct snd_emu10k1_memblk *blk = get_emu10k1_memblk(pos, mapped_link);\n\t\tif (blk->mapped_page < 0)\n\t\t\tcontinue;\n\t\tsize = blk->mapped_page - page;\n\t\tif (size == npages) {\n\t\t\t*nextp = pos;\n\t\t\treturn page;\n\t\t}\n\t\telse if (size > max_size) {\n\t\t\t \n\t\t\tmax_size = size;\n\t\t\tcandidate = pos;\n\t\t\tfound_page = page;\n\t\t}\n\t\tpage = blk->mapped_page + blk->pages;\n\t}\n\tsize = (emu->address_mode ? MAX_ALIGN_PAGES1 : MAX_ALIGN_PAGES0) - page;\n\tif (size >= max_size) {\n\t\t*nextp = pos;\n\t\treturn page;\n\t}\n\t*nextp = candidate;\n\treturn found_page;\n}\n\n \nstatic int map_memblk(struct snd_emu10k1 *emu, struct snd_emu10k1_memblk *blk)\n{\n\tint page, pg;\n\tstruct list_head *next;\n\n\tpage = search_empty_map_area(emu, blk->pages, &next);\n\tif (page < 0)  \n\t\treturn page;\n\tif (page == 0) {\n\t\tdev_err(emu->card->dev, \"trying to map zero (reserved) page\\n\");\n\t\treturn -EINVAL;\n\t}\n\t \n\tlist_add_tail(&blk->mapped_link, next);\n\t \n\tlist_add_tail(&blk->mapped_order_link, &emu->mapped_order_link_head);\n\tblk->mapped_page = page;\n\t \n\tfor (pg = blk->first_page; pg <= blk->last_page; pg++) {\n\t\tset_ptb_entry(emu, page, emu->page_addr_table[pg]);\n\t\tpage++;\n\t}\n\treturn 0;\n}\n\n \nstatic int unmap_memblk(struct snd_emu10k1 *emu, struct snd_emu10k1_memblk *blk)\n{\n\tint start_page, end_page, mpage, pg;\n\tstruct list_head *p;\n\tstruct snd_emu10k1_memblk *q;\n\n\t \n\tp = blk->mapped_link.prev;\n\tif (p != &emu->mapped_link_head) {\n\t\tq = get_emu10k1_memblk(p, mapped_link);\n\t\tstart_page = q->mapped_page + q->pages;\n\t} else {\n\t\tstart_page = 1;\n\t}\n\tp = blk->mapped_link.next;\n\tif (p != &emu->mapped_link_head) {\n\t\tq = get_emu10k1_memblk(p, mapped_link);\n\t\tend_page = q->mapped_page;\n\t} else {\n\t\tend_page = (emu->address_mode ? MAX_ALIGN_PAGES1 : MAX_ALIGN_PAGES0);\n\t}\n\n\t \n\tlist_del(&blk->mapped_link);\n\tlist_del(&blk->mapped_order_link);\n\t \n\tmpage = blk->mapped_page;\n\tfor (pg = blk->first_page; pg <= blk->last_page; pg++) {\n\t\tset_silent_ptb(emu, mpage);\n\t\tmpage++;\n\t}\n\tblk->mapped_page = -1;\n\treturn end_page - start_page;  \n}\n\n \nstatic struct snd_emu10k1_memblk *\nsearch_empty(struct snd_emu10k1 *emu, int size)\n{\n\tstruct list_head *p;\n\tstruct snd_emu10k1_memblk *blk;\n\tint page, psize;\n\n\tpsize = get_aligned_page(size + PAGE_SIZE -1);\n\tpage = 0;\n\tlist_for_each(p, &emu->memhdr->block) {\n\t\tblk = get_emu10k1_memblk(p, mem.list);\n\t\tif (page + psize <= blk->first_page)\n\t\t\tgoto __found_pages;\n\t\tpage = blk->last_page + 1;\n\t}\n\tif (page + psize > emu->max_cache_pages)\n\t\treturn NULL;\n\n__found_pages:\n\t \n\tblk = (struct snd_emu10k1_memblk *)__snd_util_memblk_new(emu->memhdr, psize << PAGE_SHIFT, p->prev);\n\tif (blk == NULL)\n\t\treturn NULL;\n\tblk->mem.offset = aligned_page_offset(page);  \n\temu10k1_memblk_init(blk);\n\treturn blk;\n}\n\n\n \nstatic int is_valid_page(struct snd_emu10k1 *emu, dma_addr_t addr)\n{\n\tif (addr & ~emu->dma_mask) {\n\t\tdev_err_ratelimited(emu->card->dev,\n\t\t\t\"max memory size is 0x%lx (addr = 0x%lx)!!\\n\",\n\t\t\temu->dma_mask, (unsigned long)addr);\n\t\treturn 0;\n\t}\n\tif (addr & (EMUPAGESIZE-1)) {\n\t\tdev_err_ratelimited(emu->card->dev, \"page is not aligned\\n\");\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\n \nint snd_emu10k1_memblk_map(struct snd_emu10k1 *emu, struct snd_emu10k1_memblk *blk)\n{\n\tint err;\n\tint size;\n\tstruct list_head *p, *nextp;\n\tstruct snd_emu10k1_memblk *deleted;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&emu->memblk_lock, flags);\n\tif (blk->mapped_page >= 0) {\n\t\t \n\t\tlist_move_tail(&blk->mapped_order_link,\n\t\t\t       &emu->mapped_order_link_head);\n\t\tspin_unlock_irqrestore(&emu->memblk_lock, flags);\n\t\treturn 0;\n\t}\n\terr = map_memblk(emu, blk);\n\tif (err < 0) {\n\t\t \n\t\t \n\t\tp = emu->mapped_order_link_head.next;\n\t\tfor (; p != &emu->mapped_order_link_head; p = nextp) {\n\t\t\tnextp = p->next;\n\t\t\tdeleted = get_emu10k1_memblk(p, mapped_order_link);\n\t\t\tif (deleted->map_locked)\n\t\t\t\tcontinue;\n\t\t\tsize = unmap_memblk(emu, deleted);\n\t\t\tif (size >= blk->pages) {\n\t\t\t\t \n\t\t\t\terr = map_memblk(emu, blk);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&emu->memblk_lock, flags);\n\treturn err;\n}\n\nEXPORT_SYMBOL(snd_emu10k1_memblk_map);\n\n \nstruct snd_util_memblk *\nsnd_emu10k1_alloc_pages(struct snd_emu10k1 *emu, struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_runtime *runtime = substream->runtime;\n\tstruct snd_util_memhdr *hdr;\n\tstruct snd_emu10k1_memblk *blk;\n\tint page, err, idx;\n\n\tif (snd_BUG_ON(!emu))\n\t\treturn NULL;\n\tif (snd_BUG_ON(runtime->dma_bytes <= 0 ||\n\t\t       runtime->dma_bytes >= (emu->address_mode ? MAXPAGES1 : MAXPAGES0) * EMUPAGESIZE))\n\t\treturn NULL;\n\thdr = emu->memhdr;\n\tif (snd_BUG_ON(!hdr))\n\t\treturn NULL;\n\n\tmutex_lock(&hdr->block_mutex);\n\tblk = search_empty(emu, runtime->dma_bytes);\n\tif (blk == NULL) {\n\t\tmutex_unlock(&hdr->block_mutex);\n\t\treturn NULL;\n\t}\n\t \n\tidx = 0;\n\tfor (page = blk->first_page; page <= blk->last_page; page++, idx++) {\n\t\tunsigned long ofs = idx << PAGE_SHIFT;\n\t\tdma_addr_t addr;\n\t\tif (ofs >= runtime->dma_bytes)\n\t\t\taddr = emu->silent_page.addr;\n\t\telse\n\t\t\taddr = snd_pcm_sgbuf_get_addr(substream, ofs);\n\t\tif (! is_valid_page(emu, addr)) {\n\t\t\tdev_err_ratelimited(emu->card->dev,\n\t\t\t\t\"emu: failure page = %d\\n\", idx);\n\t\t\tmutex_unlock(&hdr->block_mutex);\n\t\t\treturn NULL;\n\t\t}\n\t\temu->page_addr_table[page] = addr;\n\t\temu->page_ptr_table[page] = NULL;\n\t}\n\n\t \n\tblk->map_locked = 1;  \n\terr = snd_emu10k1_memblk_map(emu, blk);\n\tif (err < 0) {\n\t\t__snd_util_mem_free(hdr, (struct snd_util_memblk *)blk);\n\t\tmutex_unlock(&hdr->block_mutex);\n\t\treturn NULL;\n\t}\n\tmutex_unlock(&hdr->block_mutex);\n\treturn (struct snd_util_memblk *)blk;\n}\n\n\n \nint snd_emu10k1_free_pages(struct snd_emu10k1 *emu, struct snd_util_memblk *blk)\n{\n\tif (snd_BUG_ON(!emu || !blk))\n\t\treturn -EINVAL;\n\treturn snd_emu10k1_synth_free(emu, blk);\n}\n\n \nint snd_emu10k1_alloc_pages_maybe_wider(struct snd_emu10k1 *emu, size_t size,\n\t\t\t\t\tstruct snd_dma_buffer *dmab)\n{\n\tif (emu->iommu_workaround) {\n\t\tsize_t npages = DIV_ROUND_UP(size, PAGE_SIZE);\n\t\tsize_t size_real = npages * PAGE_SIZE;\n\n\t\t \n\t\tif (size_real < size + 1024)\n\t\t\tsize += PAGE_SIZE;\n\t}\n\n\treturn snd_dma_alloc_pages(SNDRV_DMA_TYPE_DEV,\n\t\t\t\t   &emu->pci->dev, size, dmab);\n}\n\n \n\n \nstruct snd_util_memblk *\nsnd_emu10k1_synth_alloc(struct snd_emu10k1 *hw, unsigned int size)\n{\n\tstruct snd_emu10k1_memblk *blk;\n\tstruct snd_util_memhdr *hdr = hw->memhdr; \n\n\tmutex_lock(&hdr->block_mutex);\n\tblk = (struct snd_emu10k1_memblk *)__snd_util_mem_alloc(hdr, size);\n\tif (blk == NULL) {\n\t\tmutex_unlock(&hdr->block_mutex);\n\t\treturn NULL;\n\t}\n\tif (synth_alloc_pages(hw, blk)) {\n\t\t__snd_util_mem_free(hdr, (struct snd_util_memblk *)blk);\n\t\tmutex_unlock(&hdr->block_mutex);\n\t\treturn NULL;\n\t}\n\tsnd_emu10k1_memblk_map(hw, blk);\n\tmutex_unlock(&hdr->block_mutex);\n\treturn (struct snd_util_memblk *)blk;\n}\n\nEXPORT_SYMBOL(snd_emu10k1_synth_alloc);\n\n \nint\nsnd_emu10k1_synth_free(struct snd_emu10k1 *emu, struct snd_util_memblk *memblk)\n{\n\tstruct snd_util_memhdr *hdr = emu->memhdr; \n\tstruct snd_emu10k1_memblk *blk = (struct snd_emu10k1_memblk *)memblk;\n\tunsigned long flags;\n\n\tmutex_lock(&hdr->block_mutex);\n\tspin_lock_irqsave(&emu->memblk_lock, flags);\n\tif (blk->mapped_page >= 0)\n\t\tunmap_memblk(emu, blk);\n\tspin_unlock_irqrestore(&emu->memblk_lock, flags);\n\tsynth_free_pages(emu, blk);\n\t __snd_util_mem_free(hdr, memblk);\n\tmutex_unlock(&hdr->block_mutex);\n\treturn 0;\n}\n\nEXPORT_SYMBOL(snd_emu10k1_synth_free);\n\n \nstatic void get_single_page_range(struct snd_util_memhdr *hdr,\n\t\t\t\t  struct snd_emu10k1_memblk *blk,\n\t\t\t\t  int *first_page_ret, int *last_page_ret)\n{\n\tstruct list_head *p;\n\tstruct snd_emu10k1_memblk *q;\n\tint first_page, last_page;\n\tfirst_page = blk->first_page;\n\tp = blk->mem.list.prev;\n\tif (p != &hdr->block) {\n\t\tq = get_emu10k1_memblk(p, mem.list);\n\t\tif (q->last_page == first_page)\n\t\t\tfirst_page++;   \n\t}\n\tlast_page = blk->last_page;\n\tp = blk->mem.list.next;\n\tif (p != &hdr->block) {\n\t\tq = get_emu10k1_memblk(p, mem.list);\n\t\tif (q->first_page == last_page)\n\t\t\tlast_page--;  \n\t}\n\t*first_page_ret = first_page;\n\t*last_page_ret = last_page;\n}\n\n \nstatic void __synth_free_pages(struct snd_emu10k1 *emu, int first_page,\n\t\t\t       int last_page)\n{\n\tstruct snd_dma_buffer dmab;\n\tint page;\n\n\tdmab.dev.type = SNDRV_DMA_TYPE_DEV;\n\tdmab.dev.dev = &emu->pci->dev;\n\n\tfor (page = first_page; page <= last_page; page++) {\n\t\tif (emu->page_ptr_table[page] == NULL)\n\t\t\tcontinue;\n\t\tdmab.area = emu->page_ptr_table[page];\n\t\tdmab.addr = emu->page_addr_table[page];\n\n\t\t \n\t\tdmab.bytes = PAGE_SIZE;\n\t\tif (emu->iommu_workaround)\n\t\t\tdmab.bytes *= 2;\n\n\t\tsnd_dma_free_pages(&dmab);\n\t\temu->page_addr_table[page] = 0;\n\t\temu->page_ptr_table[page] = NULL;\n\t}\n}\n\n \nstatic int synth_alloc_pages(struct snd_emu10k1 *emu, struct snd_emu10k1_memblk *blk)\n{\n\tint page, first_page, last_page;\n\tstruct snd_dma_buffer dmab;\n\n\temu10k1_memblk_init(blk);\n\tget_single_page_range(emu->memhdr, blk, &first_page, &last_page);\n\t \n\tfor (page = first_page; page <= last_page; page++) {\n\t\tif (snd_emu10k1_alloc_pages_maybe_wider(emu, PAGE_SIZE,\n\t\t\t\t\t\t\t&dmab) < 0)\n\t\t\tgoto __fail;\n\t\tif (!is_valid_page(emu, dmab.addr)) {\n\t\t\tsnd_dma_free_pages(&dmab);\n\t\t\tgoto __fail;\n\t\t}\n\t\temu->page_addr_table[page] = dmab.addr;\n\t\temu->page_ptr_table[page] = dmab.area;\n\t}\n\treturn 0;\n\n__fail:\n\t \n\tlast_page = page - 1;\n\t__synth_free_pages(emu, first_page, last_page);\n\n\treturn -ENOMEM;\n}\n\n \nstatic int synth_free_pages(struct snd_emu10k1 *emu, struct snd_emu10k1_memblk *blk)\n{\n\tint first_page, last_page;\n\n\tget_single_page_range(emu->memhdr, blk, &first_page, &last_page);\n\t__synth_free_pages(emu, first_page, last_page);\n\treturn 0;\n}\n\n \nstatic inline void *offset_ptr(struct snd_emu10k1 *emu, int page, int offset)\n{\n\tchar *ptr;\n\tif (snd_BUG_ON(page < 0 || page >= emu->max_cache_pages))\n\t\treturn NULL;\n\tptr = emu->page_ptr_table[page];\n\tif (! ptr) {\n\t\tdev_err(emu->card->dev,\n\t\t\t\"access to NULL ptr: page = %d\\n\", page);\n\t\treturn NULL;\n\t}\n\tptr += offset & (PAGE_SIZE - 1);\n\treturn (void*)ptr;\n}\n\n \nint snd_emu10k1_synth_bzero(struct snd_emu10k1 *emu, struct snd_util_memblk *blk,\n\t\t\t    int offset, int size)\n{\n\tint page, nextofs, end_offset, temp, temp1;\n\tvoid *ptr;\n\tstruct snd_emu10k1_memblk *p = (struct snd_emu10k1_memblk *)blk;\n\n\toffset += blk->offset & (PAGE_SIZE - 1);\n\tend_offset = offset + size;\n\tpage = get_aligned_page(offset);\n\tdo {\n\t\tnextofs = aligned_page_offset(page + 1);\n\t\ttemp = nextofs - offset;\n\t\ttemp1 = end_offset - offset;\n\t\tif (temp1 < temp)\n\t\t\ttemp = temp1;\n\t\tptr = offset_ptr(emu, page + p->first_page, offset);\n\t\tif (ptr)\n\t\t\tmemset(ptr, 0, temp);\n\t\toffset = nextofs;\n\t\tpage++;\n\t} while (offset < end_offset);\n\treturn 0;\n}\n\nEXPORT_SYMBOL(snd_emu10k1_synth_bzero);\n\n \nint snd_emu10k1_synth_copy_from_user(struct snd_emu10k1 *emu, struct snd_util_memblk *blk,\n\t\t\t\t     int offset, const char __user *data, int size)\n{\n\tint page, nextofs, end_offset, temp, temp1;\n\tvoid *ptr;\n\tstruct snd_emu10k1_memblk *p = (struct snd_emu10k1_memblk *)blk;\n\n\toffset += blk->offset & (PAGE_SIZE - 1);\n\tend_offset = offset + size;\n\tpage = get_aligned_page(offset);\n\tdo {\n\t\tnextofs = aligned_page_offset(page + 1);\n\t\ttemp = nextofs - offset;\n\t\ttemp1 = end_offset - offset;\n\t\tif (temp1 < temp)\n\t\t\ttemp = temp1;\n\t\tptr = offset_ptr(emu, page + p->first_page, offset);\n\t\tif (ptr && copy_from_user(ptr, data, temp))\n\t\t\treturn -EFAULT;\n\t\toffset = nextofs;\n\t\tdata += temp;\n\t\tpage++;\n\t} while (offset < end_offset);\n\treturn 0;\n}\n\nEXPORT_SYMBOL(snd_emu10k1_synth_copy_from_user);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}