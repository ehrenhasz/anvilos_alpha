{
  "module_name": "lrw.c",
  "hash_id": "0af83c2b0401224d6420c867bff151f4622ccba8c7147791e451a4f8aa00ba3a",
  "original_prompt": "Ingested from linux-6.6.14/crypto/lrw.c",
  "human_readable_source": "\n \n \n\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n\n#include <crypto/b128ops.h>\n#include <crypto/gf128mul.h>\n\n#define LRW_BLOCK_SIZE 16\n\nstruct lrw_tfm_ctx {\n\tstruct crypto_skcipher *child;\n\n\t \n\tstruct gf128mul_64k *table;\n\n\t \n\tbe128 mulinc[128];\n};\n\nstruct lrw_request_ctx {\n\tbe128 t;\n\tstruct skcipher_request subreq;\n};\n\nstatic inline void lrw_setbit128_bbe(void *b, int bit)\n{\n\t__set_bit(bit ^ (0x80 -\n#ifdef __BIG_ENDIAN\n\t\t\t BITS_PER_LONG\n#else\n\t\t\t BITS_PER_BYTE\n#endif\n\t\t\t), b);\n}\n\nstatic int lrw_setkey(struct crypto_skcipher *parent, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tstruct lrw_tfm_ctx *ctx = crypto_skcipher_ctx(parent);\n\tstruct crypto_skcipher *child = ctx->child;\n\tint err, bsize = LRW_BLOCK_SIZE;\n\tconst u8 *tweak = key + keylen - bsize;\n\tbe128 tmp = { 0 };\n\tint i;\n\n\tcrypto_skcipher_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(child, crypto_skcipher_get_flags(parent) &\n\t\t\t\t\t CRYPTO_TFM_REQ_MASK);\n\terr = crypto_skcipher_setkey(child, key, keylen - bsize);\n\tif (err)\n\t\treturn err;\n\n\tif (ctx->table)\n\t\tgf128mul_free_64k(ctx->table);\n\n\t \n\tctx->table = gf128mul_init_64k_bbe((be128 *)tweak);\n\tif (!ctx->table)\n\t\treturn -ENOMEM;\n\n\t \n\tfor (i = 0; i < 128; i++) {\n\t\tlrw_setbit128_bbe(&tmp, i);\n\t\tctx->mulinc[i] = tmp;\n\t\tgf128mul_64k_bbe(&ctx->mulinc[i], ctx->table);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int lrw_next_index(u32 *counter)\n{\n\tint i, res = 0;\n\n\tfor (i = 0; i < 4; i++) {\n\t\tif (counter[i] + 1 != 0)\n\t\t\treturn res + ffz(counter[i]++);\n\n\t\tcounter[i] = 0;\n\t\tres += 32;\n\t}\n\n\t \n\treturn 127;\n}\n\n \nstatic int lrw_xor_tweak(struct skcipher_request *req, bool second_pass)\n{\n\tconst int bs = LRW_BLOCK_SIZE;\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tconst struct lrw_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tstruct lrw_request_ctx *rctx = skcipher_request_ctx(req);\n\tbe128 t = rctx->t;\n\tstruct skcipher_walk w;\n\t__be32 *iv;\n\tu32 counter[4];\n\tint err;\n\n\tif (second_pass) {\n\t\treq = &rctx->subreq;\n\t\t \n\t\tskcipher_request_set_tfm(req, tfm);\n\t}\n\n\terr = skcipher_walk_virt(&w, req, false);\n\tif (err)\n\t\treturn err;\n\n\tiv = (__be32 *)w.iv;\n\tcounter[0] = be32_to_cpu(iv[3]);\n\tcounter[1] = be32_to_cpu(iv[2]);\n\tcounter[2] = be32_to_cpu(iv[1]);\n\tcounter[3] = be32_to_cpu(iv[0]);\n\n\twhile (w.nbytes) {\n\t\tunsigned int avail = w.nbytes;\n\t\tbe128 *wsrc;\n\t\tbe128 *wdst;\n\n\t\twsrc = w.src.virt.addr;\n\t\twdst = w.dst.virt.addr;\n\n\t\tdo {\n\t\t\tbe128_xor(wdst++, &t, wsrc++);\n\n\t\t\t \n\t\t\tbe128_xor(&t, &t,\n\t\t\t\t  &ctx->mulinc[lrw_next_index(counter)]);\n\t\t} while ((avail -= bs) >= bs);\n\n\t\tif (second_pass && w.nbytes == w.total) {\n\t\t\tiv[0] = cpu_to_be32(counter[3]);\n\t\t\tiv[1] = cpu_to_be32(counter[2]);\n\t\t\tiv[2] = cpu_to_be32(counter[1]);\n\t\t\tiv[3] = cpu_to_be32(counter[0]);\n\t\t}\n\n\t\terr = skcipher_walk_done(&w, avail);\n\t}\n\n\treturn err;\n}\n\nstatic int lrw_xor_tweak_pre(struct skcipher_request *req)\n{\n\treturn lrw_xor_tweak(req, false);\n}\n\nstatic int lrw_xor_tweak_post(struct skcipher_request *req)\n{\n\treturn lrw_xor_tweak(req, true);\n}\n\nstatic void lrw_crypt_done(void *data, int err)\n{\n\tstruct skcipher_request *req = data;\n\n\tif (!err) {\n\t\tstruct lrw_request_ctx *rctx = skcipher_request_ctx(req);\n\n\t\trctx->subreq.base.flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\t\terr = lrw_xor_tweak_post(req);\n\t}\n\n\tskcipher_request_complete(req, err);\n}\n\nstatic void lrw_init_crypt(struct skcipher_request *req)\n{\n\tconst struct lrw_tfm_ctx *ctx =\n\t\tcrypto_skcipher_ctx(crypto_skcipher_reqtfm(req));\n\tstruct lrw_request_ctx *rctx = skcipher_request_ctx(req);\n\tstruct skcipher_request *subreq = &rctx->subreq;\n\n\tskcipher_request_set_tfm(subreq, ctx->child);\n\tskcipher_request_set_callback(subreq, req->base.flags, lrw_crypt_done,\n\t\t\t\t      req);\n\t \n\tskcipher_request_set_crypt(subreq, req->dst, req->dst,\n\t\t\t\t   req->cryptlen, req->iv);\n\n\t \n\tmemcpy(&rctx->t, req->iv, sizeof(rctx->t));\n\n\t \n\tgf128mul_64k_bbe(&rctx->t, ctx->table);\n}\n\nstatic int lrw_encrypt(struct skcipher_request *req)\n{\n\tstruct lrw_request_ctx *rctx = skcipher_request_ctx(req);\n\tstruct skcipher_request *subreq = &rctx->subreq;\n\n\tlrw_init_crypt(req);\n\treturn lrw_xor_tweak_pre(req) ?:\n\t\tcrypto_skcipher_encrypt(subreq) ?:\n\t\tlrw_xor_tweak_post(req);\n}\n\nstatic int lrw_decrypt(struct skcipher_request *req)\n{\n\tstruct lrw_request_ctx *rctx = skcipher_request_ctx(req);\n\tstruct skcipher_request *subreq = &rctx->subreq;\n\n\tlrw_init_crypt(req);\n\treturn lrw_xor_tweak_pre(req) ?:\n\t\tcrypto_skcipher_decrypt(subreq) ?:\n\t\tlrw_xor_tweak_post(req);\n}\n\nstatic int lrw_init_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct skcipher_instance *inst = skcipher_alg_instance(tfm);\n\tstruct crypto_skcipher_spawn *spawn = skcipher_instance_ctx(inst);\n\tstruct lrw_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tstruct crypto_skcipher *cipher;\n\n\tcipher = crypto_spawn_skcipher(spawn);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\n\tcrypto_skcipher_set_reqsize(tfm, crypto_skcipher_reqsize(cipher) +\n\t\t\t\t\t sizeof(struct lrw_request_ctx));\n\n\treturn 0;\n}\n\nstatic void lrw_exit_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct lrw_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\n\tif (ctx->table)\n\t\tgf128mul_free_64k(ctx->table);\n\tcrypto_free_skcipher(ctx->child);\n}\n\nstatic void lrw_free_instance(struct skcipher_instance *inst)\n{\n\tcrypto_drop_skcipher(skcipher_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic int lrw_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct crypto_skcipher_spawn *spawn;\n\tstruct skcipher_instance *inst;\n\tstruct skcipher_alg *alg;\n\tconst char *cipher_name;\n\tchar ecb_name[CRYPTO_MAX_ALG_NAME];\n\tu32 mask;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SKCIPHER, &mask);\n\tif (err)\n\t\treturn err;\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn PTR_ERR(cipher_name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\n\tspawn = skcipher_instance_ctx(inst);\n\n\terr = crypto_grab_skcipher(spawn, skcipher_crypto_instance(inst),\n\t\t\t\t   cipher_name, 0, mask);\n\tif (err == -ENOENT) {\n\t\terr = -ENAMETOOLONG;\n\t\tif (snprintf(ecb_name, CRYPTO_MAX_ALG_NAME, \"ecb(%s)\",\n\t\t\t     cipher_name) >= CRYPTO_MAX_ALG_NAME)\n\t\t\tgoto err_free_inst;\n\n\t\terr = crypto_grab_skcipher(spawn,\n\t\t\t\t\t   skcipher_crypto_instance(inst),\n\t\t\t\t\t   ecb_name, 0, mask);\n\t}\n\n\tif (err)\n\t\tgoto err_free_inst;\n\n\talg = crypto_skcipher_spawn_alg(spawn);\n\n\terr = -EINVAL;\n\tif (alg->base.cra_blocksize != LRW_BLOCK_SIZE)\n\t\tgoto err_free_inst;\n\n\tif (crypto_skcipher_alg_ivsize(alg))\n\t\tgoto err_free_inst;\n\n\terr = crypto_inst_setname(skcipher_crypto_instance(inst), \"lrw\",\n\t\t\t\t  &alg->base);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\terr = -EINVAL;\n\tcipher_name = alg->base.cra_name;\n\n\t \n\tif (!strncmp(cipher_name, \"ecb(\", 4)) {\n\t\tint len;\n\n\t\tlen = strscpy(ecb_name, cipher_name + 4, sizeof(ecb_name));\n\t\tif (len < 2)\n\t\t\tgoto err_free_inst;\n\n\t\tif (ecb_name[len - 1] != ')')\n\t\t\tgoto err_free_inst;\n\n\t\tecb_name[len - 1] = 0;\n\n\t\tif (snprintf(inst->alg.base.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t\t     \"lrw(%s)\", ecb_name) >= CRYPTO_MAX_ALG_NAME) {\n\t\t\terr = -ENAMETOOLONG;\n\t\t\tgoto err_free_inst;\n\t\t}\n\t} else\n\t\tgoto err_free_inst;\n\n\tinst->alg.base.cra_priority = alg->base.cra_priority;\n\tinst->alg.base.cra_blocksize = LRW_BLOCK_SIZE;\n\tinst->alg.base.cra_alignmask = alg->base.cra_alignmask |\n\t\t\t\t       (__alignof__(be128) - 1);\n\n\tinst->alg.ivsize = LRW_BLOCK_SIZE;\n\tinst->alg.min_keysize = crypto_skcipher_alg_min_keysize(alg) +\n\t\t\t\tLRW_BLOCK_SIZE;\n\tinst->alg.max_keysize = crypto_skcipher_alg_max_keysize(alg) +\n\t\t\t\tLRW_BLOCK_SIZE;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct lrw_tfm_ctx);\n\n\tinst->alg.init = lrw_init_tfm;\n\tinst->alg.exit = lrw_exit_tfm;\n\n\tinst->alg.setkey = lrw_setkey;\n\tinst->alg.encrypt = lrw_encrypt;\n\tinst->alg.decrypt = lrw_decrypt;\n\n\tinst->free = lrw_free_instance;\n\n\terr = skcipher_register_instance(tmpl, inst);\n\tif (err) {\nerr_free_inst:\n\t\tlrw_free_instance(inst);\n\t}\n\treturn err;\n}\n\nstatic struct crypto_template lrw_tmpl = {\n\t.name = \"lrw\",\n\t.create = lrw_create,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init lrw_module_init(void)\n{\n\treturn crypto_register_template(&lrw_tmpl);\n}\n\nstatic void __exit lrw_module_exit(void)\n{\n\tcrypto_unregister_template(&lrw_tmpl);\n}\n\nsubsys_initcall(lrw_module_init);\nmodule_exit(lrw_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"LRW block cipher mode\");\nMODULE_ALIAS_CRYPTO(\"lrw\");\nMODULE_SOFTDEP(\"pre: ecb\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}