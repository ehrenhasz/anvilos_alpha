{
  "module_name": "ahash.c",
  "hash_id": "5d43a770877500b81717e9c4b4e287a573903bce67c292b0ed1b8ee01d7a5c35",
  "original_prompt": "Ingested from linux-6.6.14/crypto/ahash.c",
  "human_readable_source": "\n \n\n#include <crypto/scatterwalk.h>\n#include <linux/cryptouser.h>\n#include <linux/err.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/string.h>\n#include <net/netlink.h>\n\n#include \"hash.h\"\n\nstatic const struct crypto_type crypto_ahash_type;\n\nstruct ahash_request_priv {\n\tcrypto_completion_t complete;\n\tvoid *data;\n\tu8 *result;\n\tu32 flags;\n\tvoid *ubuf[] CRYPTO_MINALIGN_ATTR;\n};\n\nstatic int hash_walk_next(struct crypto_hash_walk *walk)\n{\n\tunsigned int alignmask = walk->alignmask;\n\tunsigned int offset = walk->offset;\n\tunsigned int nbytes = min(walk->entrylen,\n\t\t\t\t  ((unsigned int)(PAGE_SIZE)) - offset);\n\n\twalk->data = kmap_local_page(walk->pg);\n\twalk->data += offset;\n\n\tif (offset & alignmask) {\n\t\tunsigned int unaligned = alignmask + 1 - (offset & alignmask);\n\n\t\tif (nbytes > unaligned)\n\t\t\tnbytes = unaligned;\n\t}\n\n\twalk->entrylen -= nbytes;\n\treturn nbytes;\n}\n\nstatic int hash_walk_new_entry(struct crypto_hash_walk *walk)\n{\n\tstruct scatterlist *sg;\n\n\tsg = walk->sg;\n\twalk->offset = sg->offset;\n\twalk->pg = sg_page(walk->sg) + (walk->offset >> PAGE_SHIFT);\n\twalk->offset = offset_in_page(walk->offset);\n\twalk->entrylen = sg->length;\n\n\tif (walk->entrylen > walk->total)\n\t\twalk->entrylen = walk->total;\n\twalk->total -= walk->entrylen;\n\n\treturn hash_walk_next(walk);\n}\n\nint crypto_hash_walk_done(struct crypto_hash_walk *walk, int err)\n{\n\tunsigned int alignmask = walk->alignmask;\n\n\twalk->data -= walk->offset;\n\n\tif (walk->entrylen && (walk->offset & alignmask) && !err) {\n\t\tunsigned int nbytes;\n\n\t\twalk->offset = ALIGN(walk->offset, alignmask + 1);\n\t\tnbytes = min(walk->entrylen,\n\t\t\t     (unsigned int)(PAGE_SIZE - walk->offset));\n\t\tif (nbytes) {\n\t\t\twalk->entrylen -= nbytes;\n\t\t\twalk->data += walk->offset;\n\t\t\treturn nbytes;\n\t\t}\n\t}\n\n\tkunmap_local(walk->data);\n\tcrypto_yield(walk->flags);\n\n\tif (err)\n\t\treturn err;\n\n\tif (walk->entrylen) {\n\t\twalk->offset = 0;\n\t\twalk->pg++;\n\t\treturn hash_walk_next(walk);\n\t}\n\n\tif (!walk->total)\n\t\treturn 0;\n\n\twalk->sg = sg_next(walk->sg);\n\n\treturn hash_walk_new_entry(walk);\n}\nEXPORT_SYMBOL_GPL(crypto_hash_walk_done);\n\nint crypto_hash_walk_first(struct ahash_request *req,\n\t\t\t   struct crypto_hash_walk *walk)\n{\n\twalk->total = req->nbytes;\n\n\tif (!walk->total) {\n\t\twalk->entrylen = 0;\n\t\treturn 0;\n\t}\n\n\twalk->alignmask = crypto_ahash_alignmask(crypto_ahash_reqtfm(req));\n\twalk->sg = req->src;\n\twalk->flags = req->base.flags;\n\n\treturn hash_walk_new_entry(walk);\n}\nEXPORT_SYMBOL_GPL(crypto_hash_walk_first);\n\nstatic int ahash_setkey_unaligned(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t\tunsigned int keylen)\n{\n\tunsigned long alignmask = crypto_ahash_alignmask(tfm);\n\tint ret;\n\tu8 *buffer, *alignbuffer;\n\tunsigned long absize;\n\n\tabsize = keylen + alignmask;\n\tbuffer = kmalloc(absize, GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\talignbuffer = (u8 *)ALIGN((unsigned long)buffer, alignmask + 1);\n\tmemcpy(alignbuffer, key, keylen);\n\tret = tfm->setkey(tfm, alignbuffer, keylen);\n\tkfree_sensitive(buffer);\n\treturn ret;\n}\n\nstatic int ahash_nosetkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t  unsigned int keylen)\n{\n\treturn -ENOSYS;\n}\n\nstatic void ahash_set_needkey(struct crypto_ahash *tfm)\n{\n\tconst struct hash_alg_common *alg = crypto_hash_alg_common(tfm);\n\n\tif (tfm->setkey != ahash_nosetkey &&\n\t    !(alg->base.cra_flags & CRYPTO_ALG_OPTIONAL_KEY))\n\t\tcrypto_ahash_set_flags(tfm, CRYPTO_TFM_NEED_KEY);\n}\n\nint crypto_ahash_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tunsigned long alignmask = crypto_ahash_alignmask(tfm);\n\tint err;\n\n\tif ((unsigned long)key & alignmask)\n\t\terr = ahash_setkey_unaligned(tfm, key, keylen);\n\telse\n\t\terr = tfm->setkey(tfm, key, keylen);\n\n\tif (unlikely(err)) {\n\t\tahash_set_needkey(tfm);\n\t\treturn err;\n\t}\n\n\tcrypto_ahash_clear_flags(tfm, CRYPTO_TFM_NEED_KEY);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(crypto_ahash_setkey);\n\nstatic int ahash_save_req(struct ahash_request *req, crypto_completion_t cplt,\n\t\t\t  bool has_state)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tunsigned long alignmask = crypto_ahash_alignmask(tfm);\n\tunsigned int ds = crypto_ahash_digestsize(tfm);\n\tstruct ahash_request *subreq;\n\tunsigned int subreq_size;\n\tunsigned int reqsize;\n\tu8 *result;\n\tgfp_t gfp;\n\tu32 flags;\n\n\tsubreq_size = sizeof(*subreq);\n\treqsize = crypto_ahash_reqsize(tfm);\n\treqsize = ALIGN(reqsize, crypto_tfm_ctx_alignment());\n\tsubreq_size += reqsize;\n\tsubreq_size += ds;\n\tsubreq_size += alignmask & ~(crypto_tfm_ctx_alignment() - 1);\n\n\tflags = ahash_request_flags(req);\n\tgfp = (flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?  GFP_KERNEL : GFP_ATOMIC;\n\tsubreq = kmalloc(subreq_size, gfp);\n\tif (!subreq)\n\t\treturn -ENOMEM;\n\n\tahash_request_set_tfm(subreq, tfm);\n\tahash_request_set_callback(subreq, flags, cplt, req);\n\n\tresult = (u8 *)(subreq + 1) + reqsize;\n\tresult = PTR_ALIGN(result, alignmask + 1);\n\n\tahash_request_set_crypt(subreq, req->src, result, req->nbytes);\n\n\tif (has_state) {\n\t\tvoid *state;\n\n\t\tstate = kmalloc(crypto_ahash_statesize(tfm), gfp);\n\t\tif (!state) {\n\t\t\tkfree(subreq);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tcrypto_ahash_export(req, state);\n\t\tcrypto_ahash_import(subreq, state);\n\t\tkfree_sensitive(state);\n\t}\n\n\treq->priv = subreq;\n\n\treturn 0;\n}\n\nstatic void ahash_restore_req(struct ahash_request *req, int err)\n{\n\tstruct ahash_request *subreq = req->priv;\n\n\tif (!err)\n\t\tmemcpy(req->result, subreq->result,\n\t\t       crypto_ahash_digestsize(crypto_ahash_reqtfm(req)));\n\n\treq->priv = NULL;\n\n\tkfree_sensitive(subreq);\n}\n\nstatic void ahash_op_unaligned_done(void *data, int err)\n{\n\tstruct ahash_request *areq = data;\n\n\tif (err == -EINPROGRESS)\n\t\tgoto out;\n\n\t \n\tahash_restore_req(areq, err);\n\nout:\n\t \n\tahash_request_complete(areq, err);\n}\n\nstatic int ahash_op_unaligned(struct ahash_request *req,\n\t\t\t      int (*op)(struct ahash_request *),\n\t\t\t      bool has_state)\n{\n\tint err;\n\n\terr = ahash_save_req(req, ahash_op_unaligned_done, has_state);\n\tif (err)\n\t\treturn err;\n\n\terr = op(req->priv);\n\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\treturn err;\n\n\tahash_restore_req(req, err);\n\n\treturn err;\n}\n\nstatic int crypto_ahash_op(struct ahash_request *req,\n\t\t\t   int (*op)(struct ahash_request *),\n\t\t\t   bool has_state)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tunsigned long alignmask = crypto_ahash_alignmask(tfm);\n\tint err;\n\n\tif ((unsigned long)req->result & alignmask)\n\t\terr = ahash_op_unaligned(req, op, has_state);\n\telse\n\t\terr = op(req);\n\n\treturn crypto_hash_errstat(crypto_hash_alg_common(tfm), err);\n}\n\nint crypto_ahash_final(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_alg_common *alg = crypto_hash_alg_common(tfm);\n\n\tif (IS_ENABLED(CONFIG_CRYPTO_STATS))\n\t\tatomic64_inc(&hash_get_stat(alg)->hash_cnt);\n\n\treturn crypto_ahash_op(req, tfm->final, true);\n}\nEXPORT_SYMBOL_GPL(crypto_ahash_final);\n\nint crypto_ahash_finup(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_alg_common *alg = crypto_hash_alg_common(tfm);\n\n\tif (IS_ENABLED(CONFIG_CRYPTO_STATS)) {\n\t\tstruct crypto_istat_hash *istat = hash_get_stat(alg);\n\n\t\tatomic64_inc(&istat->hash_cnt);\n\t\tatomic64_add(req->nbytes, &istat->hash_tlen);\n\t}\n\n\treturn crypto_ahash_op(req, tfm->finup, true);\n}\nEXPORT_SYMBOL_GPL(crypto_ahash_finup);\n\nint crypto_ahash_digest(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct hash_alg_common *alg = crypto_hash_alg_common(tfm);\n\n\tif (IS_ENABLED(CONFIG_CRYPTO_STATS)) {\n\t\tstruct crypto_istat_hash *istat = hash_get_stat(alg);\n\n\t\tatomic64_inc(&istat->hash_cnt);\n\t\tatomic64_add(req->nbytes, &istat->hash_tlen);\n\t}\n\n\tif (crypto_ahash_get_flags(tfm) & CRYPTO_TFM_NEED_KEY)\n\t\treturn crypto_hash_errstat(alg, -ENOKEY);\n\n\treturn crypto_ahash_op(req, tfm->digest, false);\n}\nEXPORT_SYMBOL_GPL(crypto_ahash_digest);\n\nstatic void ahash_def_finup_done2(void *data, int err)\n{\n\tstruct ahash_request *areq = data;\n\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\n\tahash_restore_req(areq, err);\n\n\tahash_request_complete(areq, err);\n}\n\nstatic int ahash_def_finup_finish1(struct ahash_request *req, int err)\n{\n\tstruct ahash_request *subreq = req->priv;\n\n\tif (err)\n\t\tgoto out;\n\n\tsubreq->base.complete = ahash_def_finup_done2;\n\n\terr = crypto_ahash_reqtfm(req)->final(subreq);\n\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\treturn err;\n\nout:\n\tahash_restore_req(req, err);\n\treturn err;\n}\n\nstatic void ahash_def_finup_done1(void *data, int err)\n{\n\tstruct ahash_request *areq = data;\n\tstruct ahash_request *subreq;\n\n\tif (err == -EINPROGRESS)\n\t\tgoto out;\n\n\tsubreq = areq->priv;\n\tsubreq->base.flags &= CRYPTO_TFM_REQ_MAY_BACKLOG;\n\n\terr = ahash_def_finup_finish1(areq, err);\n\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\treturn;\n\nout:\n\tahash_request_complete(areq, err);\n}\n\nstatic int ahash_def_finup(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tint err;\n\n\terr = ahash_save_req(req, ahash_def_finup_done1, true);\n\tif (err)\n\t\treturn err;\n\n\terr = tfm->update(req->priv);\n\tif (err == -EINPROGRESS || err == -EBUSY)\n\t\treturn err;\n\n\treturn ahash_def_finup_finish1(req, err);\n}\n\nstatic void crypto_ahash_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_ahash *hash = __crypto_ahash_cast(tfm);\n\tstruct ahash_alg *alg = crypto_ahash_alg(hash);\n\n\talg->exit_tfm(hash);\n}\n\nstatic int crypto_ahash_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_ahash *hash = __crypto_ahash_cast(tfm);\n\tstruct ahash_alg *alg = crypto_ahash_alg(hash);\n\n\thash->setkey = ahash_nosetkey;\n\n\tcrypto_ahash_set_statesize(hash, alg->halg.statesize);\n\n\tif (tfm->__crt_alg->cra_type != &crypto_ahash_type)\n\t\treturn crypto_init_shash_ops_async(tfm);\n\n\thash->init = alg->init;\n\thash->update = alg->update;\n\thash->final = alg->final;\n\thash->finup = alg->finup ?: ahash_def_finup;\n\thash->digest = alg->digest;\n\thash->export = alg->export;\n\thash->import = alg->import;\n\n\tif (alg->setkey) {\n\t\thash->setkey = alg->setkey;\n\t\tahash_set_needkey(hash);\n\t}\n\n\tif (alg->exit_tfm)\n\t\ttfm->exit = crypto_ahash_exit_tfm;\n\n\treturn alg->init_tfm ? alg->init_tfm(hash) : 0;\n}\n\nstatic unsigned int crypto_ahash_extsize(struct crypto_alg *alg)\n{\n\tif (alg->cra_type != &crypto_ahash_type)\n\t\treturn sizeof(struct crypto_shash *);\n\n\treturn crypto_alg_extsize(alg);\n}\n\nstatic void crypto_ahash_free_instance(struct crypto_instance *inst)\n{\n\tstruct ahash_instance *ahash = ahash_instance(inst);\n\n\tahash->free(ahash);\n}\n\nstatic int __maybe_unused crypto_ahash_report(\n\tstruct sk_buff *skb, struct crypto_alg *alg)\n{\n\tstruct crypto_report_hash rhash;\n\n\tmemset(&rhash, 0, sizeof(rhash));\n\n\tstrscpy(rhash.type, \"ahash\", sizeof(rhash.type));\n\n\trhash.blocksize = alg->cra_blocksize;\n\trhash.digestsize = __crypto_hash_alg_common(alg)->digestsize;\n\n\treturn nla_put(skb, CRYPTOCFGA_REPORT_HASH, sizeof(rhash), &rhash);\n}\n\nstatic void crypto_ahash_show(struct seq_file *m, struct crypto_alg *alg)\n\t__maybe_unused;\nstatic void crypto_ahash_show(struct seq_file *m, struct crypto_alg *alg)\n{\n\tseq_printf(m, \"type         : ahash\\n\");\n\tseq_printf(m, \"async        : %s\\n\", alg->cra_flags & CRYPTO_ALG_ASYNC ?\n\t\t\t\t\t     \"yes\" : \"no\");\n\tseq_printf(m, \"blocksize    : %u\\n\", alg->cra_blocksize);\n\tseq_printf(m, \"digestsize   : %u\\n\",\n\t\t   __crypto_hash_alg_common(alg)->digestsize);\n}\n\nstatic int __maybe_unused crypto_ahash_report_stat(\n\tstruct sk_buff *skb, struct crypto_alg *alg)\n{\n\treturn crypto_hash_report_stat(skb, alg, \"ahash\");\n}\n\nstatic const struct crypto_type crypto_ahash_type = {\n\t.extsize = crypto_ahash_extsize,\n\t.init_tfm = crypto_ahash_init_tfm,\n\t.free = crypto_ahash_free_instance,\n#ifdef CONFIG_PROC_FS\n\t.show = crypto_ahash_show,\n#endif\n#if IS_ENABLED(CONFIG_CRYPTO_USER)\n\t.report = crypto_ahash_report,\n#endif\n#ifdef CONFIG_CRYPTO_STATS\n\t.report_stat = crypto_ahash_report_stat,\n#endif\n\t.maskclear = ~CRYPTO_ALG_TYPE_MASK,\n\t.maskset = CRYPTO_ALG_TYPE_AHASH_MASK,\n\t.type = CRYPTO_ALG_TYPE_AHASH,\n\t.tfmsize = offsetof(struct crypto_ahash, base),\n};\n\nint crypto_grab_ahash(struct crypto_ahash_spawn *spawn,\n\t\t      struct crypto_instance *inst,\n\t\t      const char *name, u32 type, u32 mask)\n{\n\tspawn->base.frontend = &crypto_ahash_type;\n\treturn crypto_grab_spawn(&spawn->base, inst, name, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_grab_ahash);\n\nstruct crypto_ahash *crypto_alloc_ahash(const char *alg_name, u32 type,\n\t\t\t\t\tu32 mask)\n{\n\treturn crypto_alloc_tfm(alg_name, &crypto_ahash_type, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_alloc_ahash);\n\nint crypto_has_ahash(const char *alg_name, u32 type, u32 mask)\n{\n\treturn crypto_type_has_alg(alg_name, &crypto_ahash_type, type, mask);\n}\nEXPORT_SYMBOL_GPL(crypto_has_ahash);\n\nstruct crypto_ahash *crypto_clone_ahash(struct crypto_ahash *hash)\n{\n\tstruct hash_alg_common *halg = crypto_hash_alg_common(hash);\n\tstruct crypto_tfm *tfm = crypto_ahash_tfm(hash);\n\tstruct crypto_ahash *nhash;\n\tstruct ahash_alg *alg;\n\tint err;\n\n\tif (!crypto_hash_alg_has_setkey(halg)) {\n\t\ttfm = crypto_tfm_get(tfm);\n\t\tif (IS_ERR(tfm))\n\t\t\treturn ERR_CAST(tfm);\n\n\t\treturn hash;\n\t}\n\n\tnhash = crypto_clone_tfm(&crypto_ahash_type, tfm);\n\n\tif (IS_ERR(nhash))\n\t\treturn nhash;\n\n\tnhash->init = hash->init;\n\tnhash->update = hash->update;\n\tnhash->final = hash->final;\n\tnhash->finup = hash->finup;\n\tnhash->digest = hash->digest;\n\tnhash->export = hash->export;\n\tnhash->import = hash->import;\n\tnhash->setkey = hash->setkey;\n\tnhash->reqsize = hash->reqsize;\n\tnhash->statesize = hash->statesize;\n\n\tif (tfm->__crt_alg->cra_type != &crypto_ahash_type)\n\t\treturn crypto_clone_shash_ops_async(nhash, hash);\n\n\terr = -ENOSYS;\n\talg = crypto_ahash_alg(hash);\n\tif (!alg->clone_tfm)\n\t\tgoto out_free_nhash;\n\n\terr = alg->clone_tfm(nhash, hash);\n\tif (err)\n\t\tgoto out_free_nhash;\n\n\treturn nhash;\n\nout_free_nhash:\n\tcrypto_free_ahash(nhash);\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL_GPL(crypto_clone_ahash);\n\nstatic int ahash_prepare_alg(struct ahash_alg *alg)\n{\n\tstruct crypto_alg *base = &alg->halg.base;\n\tint err;\n\n\tif (alg->halg.statesize == 0)\n\t\treturn -EINVAL;\n\n\terr = hash_prepare_alg(&alg->halg);\n\tif (err)\n\t\treturn err;\n\n\tbase->cra_type = &crypto_ahash_type;\n\tbase->cra_flags |= CRYPTO_ALG_TYPE_AHASH;\n\n\treturn 0;\n}\n\nint crypto_register_ahash(struct ahash_alg *alg)\n{\n\tstruct crypto_alg *base = &alg->halg.base;\n\tint err;\n\n\terr = ahash_prepare_alg(alg);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_alg(base);\n}\nEXPORT_SYMBOL_GPL(crypto_register_ahash);\n\nvoid crypto_unregister_ahash(struct ahash_alg *alg)\n{\n\tcrypto_unregister_alg(&alg->halg.base);\n}\nEXPORT_SYMBOL_GPL(crypto_unregister_ahash);\n\nint crypto_register_ahashes(struct ahash_alg *algs, int count)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < count; i++) {\n\t\tret = crypto_register_ahash(&algs[i]);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (--i; i >= 0; --i)\n\t\tcrypto_unregister_ahash(&algs[i]);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(crypto_register_ahashes);\n\nvoid crypto_unregister_ahashes(struct ahash_alg *algs, int count)\n{\n\tint i;\n\n\tfor (i = count - 1; i >= 0; --i)\n\t\tcrypto_unregister_ahash(&algs[i]);\n}\nEXPORT_SYMBOL_GPL(crypto_unregister_ahashes);\n\nint ahash_register_instance(struct crypto_template *tmpl,\n\t\t\t    struct ahash_instance *inst)\n{\n\tint err;\n\n\tif (WARN_ON(!inst->free))\n\t\treturn -EINVAL;\n\n\terr = ahash_prepare_alg(&inst->alg);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_register_instance(tmpl, ahash_crypto_instance(inst));\n}\nEXPORT_SYMBOL_GPL(ahash_register_instance);\n\nbool crypto_hash_alg_has_setkey(struct hash_alg_common *halg)\n{\n\tstruct crypto_alg *alg = &halg->base;\n\n\tif (alg->cra_type != &crypto_ahash_type)\n\t\treturn crypto_shash_alg_has_setkey(__crypto_shash_alg(alg));\n\n\treturn __crypto_ahash_alg(alg)->setkey != NULL;\n}\nEXPORT_SYMBOL_GPL(crypto_hash_alg_has_setkey);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Asynchronous cryptographic hash type\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}