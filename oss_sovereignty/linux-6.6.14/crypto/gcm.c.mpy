{
  "module_name": "gcm.c",
  "hash_id": "948ea776becacd99521f560746b90ce118d8b2aff436cb0fa1dce15603065bf7",
  "original_prompt": "Ingested from linux-6.6.14/crypto/gcm.c",
  "human_readable_source": "\n \n\n#include <crypto/gf128mul.h>\n#include <crypto/internal/aead.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/internal/hash.h>\n#include <crypto/null.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/gcm.h>\n#include <crypto/hash.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n\nstruct gcm_instance_ctx {\n\tstruct crypto_skcipher_spawn ctr;\n\tstruct crypto_ahash_spawn ghash;\n};\n\nstruct crypto_gcm_ctx {\n\tstruct crypto_skcipher *ctr;\n\tstruct crypto_ahash *ghash;\n};\n\nstruct crypto_rfc4106_ctx {\n\tstruct crypto_aead *child;\n\tu8 nonce[4];\n};\n\nstruct crypto_rfc4106_req_ctx {\n\tstruct scatterlist src[3];\n\tstruct scatterlist dst[3];\n\tstruct aead_request subreq;\n};\n\nstruct crypto_rfc4543_instance_ctx {\n\tstruct crypto_aead_spawn aead;\n};\n\nstruct crypto_rfc4543_ctx {\n\tstruct crypto_aead *child;\n\tstruct crypto_sync_skcipher *null;\n\tu8 nonce[4];\n};\n\nstruct crypto_rfc4543_req_ctx {\n\tstruct aead_request subreq;\n};\n\nstruct crypto_gcm_ghash_ctx {\n\tunsigned int cryptlen;\n\tstruct scatterlist *src;\n\tint (*complete)(struct aead_request *req, u32 flags);\n};\n\nstruct crypto_gcm_req_priv_ctx {\n\tu8 iv[16];\n\tu8 auth_tag[16];\n\tu8 iauth_tag[16];\n\tstruct scatterlist src[3];\n\tstruct scatterlist dst[3];\n\tstruct scatterlist sg;\n\tstruct crypto_gcm_ghash_ctx ghash_ctx;\n\tunion {\n\t\tstruct ahash_request ahreq;\n\t\tstruct skcipher_request skreq;\n\t} u;\n};\n\nstatic struct {\n\tu8 buf[16];\n\tstruct scatterlist sg;\n} *gcm_zeroes;\n\nstatic int crypto_rfc4543_copy_src_to_dst(struct aead_request *req, bool enc);\n\nstatic inline struct crypto_gcm_req_priv_ctx *crypto_gcm_reqctx(\n\tstruct aead_request *req)\n{\n\tunsigned long align = crypto_aead_alignmask(crypto_aead_reqtfm(req));\n\n\treturn (void *)PTR_ALIGN((u8 *)aead_request_ctx(req), align + 1);\n}\n\nstatic int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_ahash *ghash = ctx->ghash;\n\tstruct crypto_skcipher *ctr = ctx->ctr;\n\tstruct {\n\t\tbe128 hash;\n\t\tu8 iv[16];\n\n\t\tstruct crypto_wait wait;\n\n\t\tstruct scatterlist sg[1];\n\t\tstruct skcipher_request req;\n\t} *data;\n\tint err;\n\n\tcrypto_skcipher_clear_flags(ctr, CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(ctr, crypto_aead_get_flags(aead) &\n\t\t\t\t       CRYPTO_TFM_REQ_MASK);\n\terr = crypto_skcipher_setkey(ctr, key, keylen);\n\tif (err)\n\t\treturn err;\n\n\tdata = kzalloc(sizeof(*data) + crypto_skcipher_reqsize(ctr),\n\t\t       GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tcrypto_init_wait(&data->wait);\n\tsg_init_one(data->sg, &data->hash, sizeof(data->hash));\n\tskcipher_request_set_tfm(&data->req, ctr);\n\tskcipher_request_set_callback(&data->req, CRYPTO_TFM_REQ_MAY_SLEEP |\n\t\t\t\t\t\t  CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t      crypto_req_done,\n\t\t\t\t      &data->wait);\n\tskcipher_request_set_crypt(&data->req, data->sg, data->sg,\n\t\t\t\t   sizeof(data->hash), data->iv);\n\n\terr = crypto_wait_req(crypto_skcipher_encrypt(&data->req),\n\t\t\t\t\t\t\t&data->wait);\n\n\tif (err)\n\t\tgoto out;\n\n\tcrypto_ahash_clear_flags(ghash, CRYPTO_TFM_REQ_MASK);\n\tcrypto_ahash_set_flags(ghash, crypto_aead_get_flags(aead) &\n\t\t\t       CRYPTO_TFM_REQ_MASK);\n\terr = crypto_ahash_setkey(ghash, (u8 *)&data->hash, sizeof(be128));\nout:\n\tkfree_sensitive(data);\n\treturn err;\n}\n\nstatic int crypto_gcm_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t  unsigned int authsize)\n{\n\treturn crypto_gcm_check_authsize(authsize);\n}\n\nstatic void crypto_gcm_init_common(struct aead_request *req)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\t__be32 counter = cpu_to_be32(1);\n\tstruct scatterlist *sg;\n\n\tmemset(pctx->auth_tag, 0, sizeof(pctx->auth_tag));\n\tmemcpy(pctx->iv, req->iv, GCM_AES_IV_SIZE);\n\tmemcpy(pctx->iv + GCM_AES_IV_SIZE, &counter, 4);\n\n\tsg_init_table(pctx->src, 3);\n\tsg_set_buf(pctx->src, pctx->auth_tag, sizeof(pctx->auth_tag));\n\tsg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);\n\tif (sg != pctx->src + 1)\n\t\tsg_chain(pctx->src, 2, sg);\n\n\tif (req->src != req->dst) {\n\t\tsg_init_table(pctx->dst, 3);\n\t\tsg_set_buf(pctx->dst, pctx->auth_tag, sizeof(pctx->auth_tag));\n\t\tsg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);\n\t\tif (sg != pctx->dst + 1)\n\t\t\tsg_chain(pctx->dst, 2, sg);\n\t}\n}\n\nstatic void crypto_gcm_init_crypt(struct aead_request *req,\n\t\t\t\t  unsigned int cryptlen)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct skcipher_request *skreq = &pctx->u.skreq;\n\tstruct scatterlist *dst;\n\n\tdst = req->src == req->dst ? pctx->src : pctx->dst;\n\n\tskcipher_request_set_tfm(skreq, ctx->ctr);\n\tskcipher_request_set_crypt(skreq, pctx->src, dst,\n\t\t\t\t     cryptlen + sizeof(pctx->auth_tag),\n\t\t\t\t     pctx->iv);\n}\n\nstatic inline unsigned int gcm_remain(unsigned int len)\n{\n\tlen &= 0xfU;\n\treturn len ? 16 - len : 0;\n}\n\nstatic void gcm_hash_len_done(void *data, int err);\n\nstatic int gcm_hash_update(struct aead_request *req,\n\t\t\t   crypto_completion_t compl,\n\t\t\t   struct scatterlist *src,\n\t\t\t   unsigned int len, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\n\tahash_request_set_callback(ahreq, flags, compl, req);\n\tahash_request_set_crypt(ahreq, src, NULL, len);\n\n\treturn crypto_ahash_update(ahreq);\n}\n\nstatic int gcm_hash_remain(struct aead_request *req,\n\t\t\t   unsigned int remain,\n\t\t\t   crypto_completion_t compl, u32 flags)\n{\n\treturn gcm_hash_update(req, compl, &gcm_zeroes->sg, remain, flags);\n}\n\nstatic int gcm_hash_len(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tbe128 lengths;\n\n\tlengths.a = cpu_to_be64(req->assoclen * 8);\n\tlengths.b = cpu_to_be64(gctx->cryptlen * 8);\n\tmemcpy(pctx->iauth_tag, &lengths, 16);\n\tsg_init_one(&pctx->sg, pctx->iauth_tag, 16);\n\tahash_request_set_callback(ahreq, flags, gcm_hash_len_done, req);\n\tahash_request_set_crypt(ahreq, &pctx->sg,\n\t\t\t\tpctx->iauth_tag, sizeof(lengths));\n\n\treturn crypto_ahash_finup(ahreq);\n}\n\nstatic int gcm_hash_len_continue(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\treturn gctx->complete(req, flags);\n}\n\nstatic void gcm_hash_len_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (err)\n\t\tgoto out;\n\n\terr = gcm_hash_len_continue(req, 0);\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\nout:\n\taead_request_complete(req, err);\n}\n\nstatic int gcm_hash_crypt_remain_continue(struct aead_request *req, u32 flags)\n{\n\treturn gcm_hash_len(req, flags) ?:\n\t       gcm_hash_len_continue(req, flags);\n}\n\nstatic void gcm_hash_crypt_remain_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (err)\n\t\tgoto out;\n\n\terr = gcm_hash_crypt_remain_continue(req, 0);\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\nout:\n\taead_request_complete(req, err);\n}\n\nstatic int gcm_hash_crypt_continue(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tunsigned int remain;\n\n\tremain = gcm_remain(gctx->cryptlen);\n\tif (remain)\n\t\treturn gcm_hash_remain(req, remain,\n\t\t\t\t       gcm_hash_crypt_remain_done, flags) ?:\n\t\t       gcm_hash_crypt_remain_continue(req, flags);\n\n\treturn gcm_hash_crypt_remain_continue(req, flags);\n}\n\nstatic void gcm_hash_crypt_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (err)\n\t\tgoto out;\n\n\terr = gcm_hash_crypt_continue(req, 0);\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\nout:\n\taead_request_complete(req, err);\n}\n\nstatic int gcm_hash_assoc_remain_continue(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\tif (gctx->cryptlen)\n\t\treturn gcm_hash_update(req, gcm_hash_crypt_done,\n\t\t\t\t       gctx->src, gctx->cryptlen, flags) ?:\n\t\t       gcm_hash_crypt_continue(req, flags);\n\n\treturn gcm_hash_crypt_remain_continue(req, flags);\n}\n\nstatic void gcm_hash_assoc_remain_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (err)\n\t\tgoto out;\n\n\terr = gcm_hash_assoc_remain_continue(req, 0);\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\nout:\n\taead_request_complete(req, err);\n}\n\nstatic int gcm_hash_assoc_continue(struct aead_request *req, u32 flags)\n{\n\tunsigned int remain;\n\n\tremain = gcm_remain(req->assoclen);\n\tif (remain)\n\t\treturn gcm_hash_remain(req, remain,\n\t\t\t\t       gcm_hash_assoc_remain_done, flags) ?:\n\t\t       gcm_hash_assoc_remain_continue(req, flags);\n\n\treturn gcm_hash_assoc_remain_continue(req, flags);\n}\n\nstatic void gcm_hash_assoc_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (err)\n\t\tgoto out;\n\n\terr = gcm_hash_assoc_continue(req, 0);\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\nout:\n\taead_request_complete(req, err);\n}\n\nstatic int gcm_hash_init_continue(struct aead_request *req, u32 flags)\n{\n\tif (req->assoclen)\n\t\treturn gcm_hash_update(req, gcm_hash_assoc_done,\n\t\t\t\t       req->src, req->assoclen, flags) ?:\n\t\t       gcm_hash_assoc_continue(req, flags);\n\n\treturn gcm_hash_assoc_remain_continue(req, flags);\n}\n\nstatic void gcm_hash_init_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (err)\n\t\tgoto out;\n\n\terr = gcm_hash_init_continue(req, 0);\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\nout:\n\taead_request_complete(req, err);\n}\n\nstatic int gcm_hash(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct ahash_request *ahreq = &pctx->u.ahreq;\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(crypto_aead_reqtfm(req));\n\n\tahash_request_set_tfm(ahreq, ctx->ghash);\n\n\tahash_request_set_callback(ahreq, flags, gcm_hash_init_done, req);\n\treturn crypto_ahash_init(ahreq) ?:\n\t       gcm_hash_init_continue(req, flags);\n}\n\nstatic int gcm_enc_copy_hash(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tu8 *auth_tag = pctx->auth_tag;\n\n\tcrypto_xor(auth_tag, pctx->iauth_tag, 16);\n\tscatterwalk_map_and_copy(auth_tag, req->dst,\n\t\t\t\t req->assoclen + req->cryptlen,\n\t\t\t\t crypto_aead_authsize(aead), 1);\n\treturn 0;\n}\n\nstatic int gcm_encrypt_continue(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\tgctx->src = sg_next(req->src == req->dst ? pctx->src : pctx->dst);\n\tgctx->cryptlen = req->cryptlen;\n\tgctx->complete = gcm_enc_copy_hash;\n\n\treturn gcm_hash(req, flags);\n}\n\nstatic void gcm_encrypt_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (err)\n\t\tgoto out;\n\n\terr = gcm_encrypt_continue(req, 0);\n\tif (err == -EINPROGRESS)\n\t\treturn;\n\nout:\n\taead_request_complete(req, err);\n}\n\nstatic int crypto_gcm_encrypt(struct aead_request *req)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct skcipher_request *skreq = &pctx->u.skreq;\n\tu32 flags = aead_request_flags(req);\n\n\tcrypto_gcm_init_common(req);\n\tcrypto_gcm_init_crypt(req, req->cryptlen);\n\tskcipher_request_set_callback(skreq, flags, gcm_encrypt_done, req);\n\n\treturn crypto_skcipher_encrypt(skreq) ?:\n\t       gcm_encrypt_continue(req, flags);\n}\n\nstatic int crypto_gcm_verify(struct aead_request *req)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tu8 *auth_tag = pctx->auth_tag;\n\tu8 *iauth_tag = pctx->iauth_tag;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen - authsize;\n\n\tcrypto_xor(auth_tag, iauth_tag, 16);\n\tscatterwalk_map_and_copy(iauth_tag, req->src,\n\t\t\t\t req->assoclen + cryptlen, authsize, 0);\n\treturn crypto_memneq(iauth_tag, auth_tag, authsize) ? -EBADMSG : 0;\n}\n\nstatic void gcm_decrypt_done(void *data, int err)\n{\n\tstruct aead_request *req = data;\n\n\tif (!err)\n\t\terr = crypto_gcm_verify(req);\n\n\taead_request_complete(req, err);\n}\n\nstatic int gcm_dec_hash_continue(struct aead_request *req, u32 flags)\n{\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct skcipher_request *skreq = &pctx->u.skreq;\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\n\tcrypto_gcm_init_crypt(req, gctx->cryptlen);\n\tskcipher_request_set_callback(skreq, flags, gcm_decrypt_done, req);\n\treturn crypto_skcipher_decrypt(skreq) ?: crypto_gcm_verify(req);\n}\n\nstatic int crypto_gcm_decrypt(struct aead_request *req)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_gcm_req_priv_ctx *pctx = crypto_gcm_reqctx(req);\n\tstruct crypto_gcm_ghash_ctx *gctx = &pctx->ghash_ctx;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int cryptlen = req->cryptlen;\n\tu32 flags = aead_request_flags(req);\n\n\tcryptlen -= authsize;\n\n\tcrypto_gcm_init_common(req);\n\n\tgctx->src = sg_next(pctx->src);\n\tgctx->cryptlen = cryptlen;\n\tgctx->complete = gcm_dec_hash_continue;\n\n\treturn gcm_hash(req, flags);\n}\n\nstatic int crypto_gcm_init_tfm(struct crypto_aead *tfm)\n{\n\tstruct aead_instance *inst = aead_alg_instance(tfm);\n\tstruct gcm_instance_ctx *ictx = aead_instance_ctx(inst);\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct crypto_skcipher *ctr;\n\tstruct crypto_ahash *ghash;\n\tunsigned long align;\n\tint err;\n\n\tghash = crypto_spawn_ahash(&ictx->ghash);\n\tif (IS_ERR(ghash))\n\t\treturn PTR_ERR(ghash);\n\n\tctr = crypto_spawn_skcipher(&ictx->ctr);\n\terr = PTR_ERR(ctr);\n\tif (IS_ERR(ctr))\n\t\tgoto err_free_hash;\n\n\tctx->ctr = ctr;\n\tctx->ghash = ghash;\n\n\talign = crypto_aead_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\tcrypto_aead_set_reqsize(tfm,\n\t\talign + offsetof(struct crypto_gcm_req_priv_ctx, u) +\n\t\tmax(sizeof(struct skcipher_request) +\n\t\t    crypto_skcipher_reqsize(ctr),\n\t\t    sizeof(struct ahash_request) +\n\t\t    crypto_ahash_reqsize(ghash)));\n\n\treturn 0;\n\nerr_free_hash:\n\tcrypto_free_ahash(ghash);\n\treturn err;\n}\n\nstatic void crypto_gcm_exit_tfm(struct crypto_aead *tfm)\n{\n\tstruct crypto_gcm_ctx *ctx = crypto_aead_ctx(tfm);\n\n\tcrypto_free_ahash(ctx->ghash);\n\tcrypto_free_skcipher(ctx->ctr);\n}\n\nstatic void crypto_gcm_free(struct aead_instance *inst)\n{\n\tstruct gcm_instance_ctx *ctx = aead_instance_ctx(inst);\n\n\tcrypto_drop_skcipher(&ctx->ctr);\n\tcrypto_drop_ahash(&ctx->ghash);\n\tkfree(inst);\n}\n\nstatic int crypto_gcm_create_common(struct crypto_template *tmpl,\n\t\t\t\t    struct rtattr **tb,\n\t\t\t\t    const char *ctr_name,\n\t\t\t\t    const char *ghash_name)\n{\n\tu32 mask;\n\tstruct aead_instance *inst;\n\tstruct gcm_instance_ctx *ctx;\n\tstruct skcipher_alg *ctr;\n\tstruct hash_alg_common *ghash;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_AEAD, &mask);\n\tif (err)\n\t\treturn err;\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\tctx = aead_instance_ctx(inst);\n\n\terr = crypto_grab_ahash(&ctx->ghash, aead_crypto_instance(inst),\n\t\t\t\tghash_name, 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\tghash = crypto_spawn_ahash_alg(&ctx->ghash);\n\n\terr = -EINVAL;\n\tif (strcmp(ghash->base.cra_name, \"ghash\") != 0 ||\n\t    ghash->digestsize != 16)\n\t\tgoto err_free_inst;\n\n\terr = crypto_grab_skcipher(&ctx->ctr, aead_crypto_instance(inst),\n\t\t\t\t   ctr_name, 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\tctr = crypto_spawn_skcipher_alg(&ctx->ctr);\n\n\t \n\terr = -EINVAL;\n\tif (strncmp(ctr->base.cra_name, \"ctr(\", 4) != 0 ||\n\t    crypto_skcipher_alg_ivsize(ctr) != 16 ||\n\t    ctr->base.cra_blocksize != 1)\n\t\tgoto err_free_inst;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.base.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"gcm(%s\", ctr->base.cra_name + 4) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\n\tif (snprintf(inst->alg.base.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"gcm_base(%s,%s)\", ctr->base.cra_driver_name,\n\t\t     ghash->base.cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\n\tinst->alg.base.cra_priority = (ghash->base.cra_priority +\n\t\t\t\t       ctr->base.cra_priority) / 2;\n\tinst->alg.base.cra_blocksize = 1;\n\tinst->alg.base.cra_alignmask = ghash->base.cra_alignmask |\n\t\t\t\t       ctr->base.cra_alignmask;\n\tinst->alg.base.cra_ctxsize = sizeof(struct crypto_gcm_ctx);\n\tinst->alg.ivsize = GCM_AES_IV_SIZE;\n\tinst->alg.chunksize = crypto_skcipher_alg_chunksize(ctr);\n\tinst->alg.maxauthsize = 16;\n\tinst->alg.init = crypto_gcm_init_tfm;\n\tinst->alg.exit = crypto_gcm_exit_tfm;\n\tinst->alg.setkey = crypto_gcm_setkey;\n\tinst->alg.setauthsize = crypto_gcm_setauthsize;\n\tinst->alg.encrypt = crypto_gcm_encrypt;\n\tinst->alg.decrypt = crypto_gcm_decrypt;\n\n\tinst->free = crypto_gcm_free;\n\n\terr = aead_register_instance(tmpl, inst);\n\tif (err) {\nerr_free_inst:\n\t\tcrypto_gcm_free(inst);\n\t}\n\treturn err;\n}\n\nstatic int crypto_gcm_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tconst char *cipher_name;\n\tchar ctr_name[CRYPTO_MAX_ALG_NAME];\n\n\tcipher_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(cipher_name))\n\t\treturn PTR_ERR(cipher_name);\n\n\tif (snprintf(ctr_name, CRYPTO_MAX_ALG_NAME, \"ctr(%s)\", cipher_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\treturn -ENAMETOOLONG;\n\n\treturn crypto_gcm_create_common(tmpl, tb, ctr_name, \"ghash\");\n}\n\nstatic int crypto_gcm_base_create(struct crypto_template *tmpl,\n\t\t\t\t  struct rtattr **tb)\n{\n\tconst char *ctr_name;\n\tconst char *ghash_name;\n\n\tctr_name = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(ctr_name))\n\t\treturn PTR_ERR(ctr_name);\n\n\tghash_name = crypto_attr_alg_name(tb[2]);\n\tif (IS_ERR(ghash_name))\n\t\treturn PTR_ERR(ghash_name);\n\n\treturn crypto_gcm_create_common(tmpl, tb, ctr_name, ghash_name);\n}\n\nstatic int crypto_rfc4106_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\n\tif (keylen < 4)\n\t\treturn -EINVAL;\n\n\tkeylen -= 4;\n\tmemcpy(ctx->nonce, key + keylen, 4);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\treturn crypto_aead_setkey(child, key, keylen);\n}\n\nstatic int crypto_rfc4106_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(parent);\n\tint err;\n\n\terr = crypto_rfc4106_check_authsize(authsize);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic struct aead_request *crypto_rfc4106_crypt(struct aead_request *req)\n{\n\tstruct crypto_rfc4106_req_ctx *rctx = aead_request_ctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct aead_request *subreq = &rctx->subreq;\n\tstruct crypto_aead *child = ctx->child;\n\tstruct scatterlist *sg;\n\tu8 *iv = PTR_ALIGN((u8 *)(subreq + 1) + crypto_aead_reqsize(child),\n\t\t\t   crypto_aead_alignmask(child) + 1);\n\n\tscatterwalk_map_and_copy(iv + GCM_AES_IV_SIZE, req->src, 0, req->assoclen - 8, 0);\n\n\tmemcpy(iv, ctx->nonce, 4);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\tsg_init_table(rctx->src, 3);\n\tsg_set_buf(rctx->src, iv + GCM_AES_IV_SIZE, req->assoclen - 8);\n\tsg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);\n\tif (sg != rctx->src + 1)\n\t\tsg_chain(rctx->src, 2, sg);\n\n\tif (req->src != req->dst) {\n\t\tsg_init_table(rctx->dst, 3);\n\t\tsg_set_buf(rctx->dst, iv + GCM_AES_IV_SIZE, req->assoclen - 8);\n\t\tsg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);\n\t\tif (sg != rctx->dst + 1)\n\t\t\tsg_chain(rctx->dst, 2, sg);\n\t}\n\n\taead_request_set_tfm(subreq, child);\n\taead_request_set_callback(subreq, req->base.flags, req->base.complete,\n\t\t\t\t  req->base.data);\n\taead_request_set_crypt(subreq, rctx->src,\n\t\t\t       req->src == req->dst ? rctx->src : rctx->dst,\n\t\t\t       req->cryptlen, iv);\n\taead_request_set_ad(subreq, req->assoclen - 8);\n\n\treturn subreq;\n}\n\nstatic int crypto_rfc4106_encrypt(struct aead_request *req)\n{\n\tint err;\n\n\terr = crypto_ipsec_check_assoclen(req->assoclen);\n\tif (err)\n\t\treturn err;\n\n\treq = crypto_rfc4106_crypt(req);\n\n\treturn crypto_aead_encrypt(req);\n}\n\nstatic int crypto_rfc4106_decrypt(struct aead_request *req)\n{\n\tint err;\n\n\terr = crypto_ipsec_check_assoclen(req->assoclen);\n\tif (err)\n\t\treturn err;\n\n\treq = crypto_rfc4106_crypt(req);\n\n\treturn crypto_aead_decrypt(req);\n}\n\nstatic int crypto_rfc4106_init_tfm(struct crypto_aead *tfm)\n{\n\tstruct aead_instance *inst = aead_alg_instance(tfm);\n\tstruct crypto_aead_spawn *spawn = aead_instance_ctx(inst);\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tunsigned long align;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tctx->child = aead;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\tcrypto_aead_set_reqsize(\n\t\ttfm,\n\t\tsizeof(struct crypto_rfc4106_req_ctx) +\n\t\tALIGN(crypto_aead_reqsize(aead), crypto_tfm_ctx_alignment()) +\n\t\talign + 24);\n\n\treturn 0;\n}\n\nstatic void crypto_rfc4106_exit_tfm(struct crypto_aead *tfm)\n{\n\tstruct crypto_rfc4106_ctx *ctx = crypto_aead_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n}\n\nstatic void crypto_rfc4106_free(struct aead_instance *inst)\n{\n\tcrypto_drop_aead(aead_instance_ctx(inst));\n\tkfree(inst);\n}\n\nstatic int crypto_rfc4106_create(struct crypto_template *tmpl,\n\t\t\t\t struct rtattr **tb)\n{\n\tu32 mask;\n\tstruct aead_instance *inst;\n\tstruct crypto_aead_spawn *spawn;\n\tstruct aead_alg *alg;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_AEAD, &mask);\n\tif (err)\n\t\treturn err;\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\n\tspawn = aead_instance_ctx(inst);\n\terr = crypto_grab_aead(spawn, aead_crypto_instance(inst),\n\t\t\t       crypto_attr_alg_name(tb[1]), 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\talg = crypto_spawn_aead_alg(spawn);\n\n\terr = -EINVAL;\n\n\t \n\tif (crypto_aead_alg_ivsize(alg) != GCM_AES_IV_SIZE)\n\t\tgoto err_free_inst;\n\n\t \n\tif (alg->base.cra_blocksize != 1)\n\t\tgoto err_free_inst;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.base.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4106(%s)\", alg->base.cra_name) >=\n\t    CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.base.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4106(%s)\", alg->base.cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\n\tinst->alg.base.cra_priority = alg->base.cra_priority;\n\tinst->alg.base.cra_blocksize = 1;\n\tinst->alg.base.cra_alignmask = alg->base.cra_alignmask;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct crypto_rfc4106_ctx);\n\n\tinst->alg.ivsize = GCM_RFC4106_IV_SIZE;\n\tinst->alg.chunksize = crypto_aead_alg_chunksize(alg);\n\tinst->alg.maxauthsize = crypto_aead_alg_maxauthsize(alg);\n\n\tinst->alg.init = crypto_rfc4106_init_tfm;\n\tinst->alg.exit = crypto_rfc4106_exit_tfm;\n\n\tinst->alg.setkey = crypto_rfc4106_setkey;\n\tinst->alg.setauthsize = crypto_rfc4106_setauthsize;\n\tinst->alg.encrypt = crypto_rfc4106_encrypt;\n\tinst->alg.decrypt = crypto_rfc4106_decrypt;\n\n\tinst->free = crypto_rfc4106_free;\n\n\terr = aead_register_instance(tmpl, inst);\n\tif (err) {\nerr_free_inst:\n\t\tcrypto_rfc4106_free(inst);\n\t}\n\treturn err;\n}\n\nstatic int crypto_rfc4543_setkey(struct crypto_aead *parent, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(parent);\n\tstruct crypto_aead *child = ctx->child;\n\n\tif (keylen < 4)\n\t\treturn -EINVAL;\n\n\tkeylen -= 4;\n\tmemcpy(ctx->nonce, key + keylen, 4);\n\n\tcrypto_aead_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(child, crypto_aead_get_flags(parent) &\n\t\t\t\t     CRYPTO_TFM_REQ_MASK);\n\treturn crypto_aead_setkey(child, key, keylen);\n}\n\nstatic int crypto_rfc4543_setauthsize(struct crypto_aead *parent,\n\t\t\t\t      unsigned int authsize)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(parent);\n\n\tif (authsize != 16)\n\t\treturn -EINVAL;\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic int crypto_rfc4543_crypt(struct aead_request *req, bool enc)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(aead);\n\tstruct crypto_rfc4543_req_ctx *rctx = aead_request_ctx(req);\n\tstruct aead_request *subreq = &rctx->subreq;\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tu8 *iv = PTR_ALIGN((u8 *)(rctx + 1) + crypto_aead_reqsize(ctx->child),\n\t\t\t   crypto_aead_alignmask(ctx->child) + 1);\n\tint err;\n\n\tif (req->src != req->dst) {\n\t\terr = crypto_rfc4543_copy_src_to_dst(req, enc);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tmemcpy(iv, ctx->nonce, 4);\n\tmemcpy(iv + 4, req->iv, 8);\n\n\taead_request_set_tfm(subreq, ctx->child);\n\taead_request_set_callback(subreq, req->base.flags,\n\t\t\t\t  req->base.complete, req->base.data);\n\taead_request_set_crypt(subreq, req->src, req->dst,\n\t\t\t       enc ? 0 : authsize, iv);\n\taead_request_set_ad(subreq, req->assoclen + req->cryptlen -\n\t\t\t\t    subreq->cryptlen);\n\n\treturn enc ? crypto_aead_encrypt(subreq) : crypto_aead_decrypt(subreq);\n}\n\nstatic int crypto_rfc4543_copy_src_to_dst(struct aead_request *req, bool enc)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(aead);\n\tunsigned int authsize = crypto_aead_authsize(aead);\n\tunsigned int nbytes = req->assoclen + req->cryptlen -\n\t\t\t      (enc ? 0 : authsize);\n\tSYNC_SKCIPHER_REQUEST_ON_STACK(nreq, ctx->null);\n\n\tskcipher_request_set_sync_tfm(nreq, ctx->null);\n\tskcipher_request_set_callback(nreq, req->base.flags, NULL, NULL);\n\tskcipher_request_set_crypt(nreq, req->src, req->dst, nbytes, NULL);\n\n\treturn crypto_skcipher_encrypt(nreq);\n}\n\nstatic int crypto_rfc4543_encrypt(struct aead_request *req)\n{\n\treturn crypto_ipsec_check_assoclen(req->assoclen) ?:\n\t       crypto_rfc4543_crypt(req, true);\n}\n\nstatic int crypto_rfc4543_decrypt(struct aead_request *req)\n{\n\treturn crypto_ipsec_check_assoclen(req->assoclen) ?:\n\t       crypto_rfc4543_crypt(req, false);\n}\n\nstatic int crypto_rfc4543_init_tfm(struct crypto_aead *tfm)\n{\n\tstruct aead_instance *inst = aead_alg_instance(tfm);\n\tstruct crypto_rfc4543_instance_ctx *ictx = aead_instance_ctx(inst);\n\tstruct crypto_aead_spawn *spawn = &ictx->aead;\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct crypto_aead *aead;\n\tstruct crypto_sync_skcipher *null;\n\tunsigned long align;\n\tint err = 0;\n\n\taead = crypto_spawn_aead(spawn);\n\tif (IS_ERR(aead))\n\t\treturn PTR_ERR(aead);\n\n\tnull = crypto_get_default_null_skcipher();\n\terr = PTR_ERR(null);\n\tif (IS_ERR(null))\n\t\tgoto err_free_aead;\n\n\tctx->child = aead;\n\tctx->null = null;\n\n\talign = crypto_aead_alignmask(aead);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\tcrypto_aead_set_reqsize(\n\t\ttfm,\n\t\tsizeof(struct crypto_rfc4543_req_ctx) +\n\t\tALIGN(crypto_aead_reqsize(aead), crypto_tfm_ctx_alignment()) +\n\t\talign + GCM_AES_IV_SIZE);\n\n\treturn 0;\n\nerr_free_aead:\n\tcrypto_free_aead(aead);\n\treturn err;\n}\n\nstatic void crypto_rfc4543_exit_tfm(struct crypto_aead *tfm)\n{\n\tstruct crypto_rfc4543_ctx *ctx = crypto_aead_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n\tcrypto_put_default_null_skcipher();\n}\n\nstatic void crypto_rfc4543_free(struct aead_instance *inst)\n{\n\tstruct crypto_rfc4543_instance_ctx *ctx = aead_instance_ctx(inst);\n\n\tcrypto_drop_aead(&ctx->aead);\n\n\tkfree(inst);\n}\n\nstatic int crypto_rfc4543_create(struct crypto_template *tmpl,\n\t\t\t\tstruct rtattr **tb)\n{\n\tu32 mask;\n\tstruct aead_instance *inst;\n\tstruct aead_alg *alg;\n\tstruct crypto_rfc4543_instance_ctx *ctx;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_AEAD, &mask);\n\tif (err)\n\t\treturn err;\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\n\tctx = aead_instance_ctx(inst);\n\terr = crypto_grab_aead(&ctx->aead, aead_crypto_instance(inst),\n\t\t\t       crypto_attr_alg_name(tb[1]), 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\talg = crypto_spawn_aead_alg(&ctx->aead);\n\n\terr = -EINVAL;\n\n\t \n\tif (crypto_aead_alg_ivsize(alg) != GCM_AES_IV_SIZE)\n\t\tgoto err_free_inst;\n\n\t \n\tif (alg->base.cra_blocksize != 1)\n\t\tgoto err_free_inst;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.base.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4543(%s)\", alg->base.cra_name) >=\n\t    CRYPTO_MAX_ALG_NAME ||\n\t    snprintf(inst->alg.base.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc4543(%s)\", alg->base.cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\n\tinst->alg.base.cra_priority = alg->base.cra_priority;\n\tinst->alg.base.cra_blocksize = 1;\n\tinst->alg.base.cra_alignmask = alg->base.cra_alignmask;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct crypto_rfc4543_ctx);\n\n\tinst->alg.ivsize = GCM_RFC4543_IV_SIZE;\n\tinst->alg.chunksize = crypto_aead_alg_chunksize(alg);\n\tinst->alg.maxauthsize = crypto_aead_alg_maxauthsize(alg);\n\n\tinst->alg.init = crypto_rfc4543_init_tfm;\n\tinst->alg.exit = crypto_rfc4543_exit_tfm;\n\n\tinst->alg.setkey = crypto_rfc4543_setkey;\n\tinst->alg.setauthsize = crypto_rfc4543_setauthsize;\n\tinst->alg.encrypt = crypto_rfc4543_encrypt;\n\tinst->alg.decrypt = crypto_rfc4543_decrypt;\n\n\tinst->free = crypto_rfc4543_free;\n\n\terr = aead_register_instance(tmpl, inst);\n\tif (err) {\nerr_free_inst:\n\t\tcrypto_rfc4543_free(inst);\n\t}\n\treturn err;\n}\n\nstatic struct crypto_template crypto_gcm_tmpls[] = {\n\t{\n\t\t.name = \"gcm_base\",\n\t\t.create = crypto_gcm_base_create,\n\t\t.module = THIS_MODULE,\n\t}, {\n\t\t.name = \"gcm\",\n\t\t.create = crypto_gcm_create,\n\t\t.module = THIS_MODULE,\n\t}, {\n\t\t.name = \"rfc4106\",\n\t\t.create = crypto_rfc4106_create,\n\t\t.module = THIS_MODULE,\n\t}, {\n\t\t.name = \"rfc4543\",\n\t\t.create = crypto_rfc4543_create,\n\t\t.module = THIS_MODULE,\n\t},\n};\n\nstatic int __init crypto_gcm_module_init(void)\n{\n\tint err;\n\n\tgcm_zeroes = kzalloc(sizeof(*gcm_zeroes), GFP_KERNEL);\n\tif (!gcm_zeroes)\n\t\treturn -ENOMEM;\n\n\tsg_init_one(&gcm_zeroes->sg, gcm_zeroes->buf, sizeof(gcm_zeroes->buf));\n\n\terr = crypto_register_templates(crypto_gcm_tmpls,\n\t\t\t\t\tARRAY_SIZE(crypto_gcm_tmpls));\n\tif (err)\n\t\tkfree(gcm_zeroes);\n\n\treturn err;\n}\n\nstatic void __exit crypto_gcm_module_exit(void)\n{\n\tkfree(gcm_zeroes);\n\tcrypto_unregister_templates(crypto_gcm_tmpls,\n\t\t\t\t    ARRAY_SIZE(crypto_gcm_tmpls));\n}\n\nsubsys_initcall(crypto_gcm_module_init);\nmodule_exit(crypto_gcm_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Galois/Counter Mode\");\nMODULE_AUTHOR(\"Mikko Herranen <mh1@iki.fi>\");\nMODULE_ALIAS_CRYPTO(\"gcm_base\");\nMODULE_ALIAS_CRYPTO(\"rfc4106\");\nMODULE_ALIAS_CRYPTO(\"rfc4543\");\nMODULE_ALIAS_CRYPTO(\"gcm\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}