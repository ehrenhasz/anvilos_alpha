{
  "module_name": "adiantum.c",
  "hash_id": "d7cd40c400826c9fc429b6d1ea0ae6065885562b0449fcac8de0b9739ab86359",
  "original_prompt": "Ingested from linux-6.6.14/crypto/adiantum.c",
  "human_readable_source": "\n \n\n \n\n#include <crypto/b128ops.h>\n#include <crypto/chacha.h>\n#include <crypto/internal/cipher.h>\n#include <crypto/internal/hash.h>\n#include <crypto/internal/poly1305.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/nhpoly1305.h>\n#include <crypto/scatterwalk.h>\n#include <linux/module.h>\n\n \n#define BLOCKCIPHER_BLOCK_SIZE\t\t16\n\n \n#define BLOCKCIPHER_KEY_SIZE\t\t32\n\n \n#define HASH_KEY_SIZE\t\t(POLY1305_BLOCK_SIZE + NHPOLY1305_KEY_SIZE)\n\n \n#define TWEAK_SIZE\t\t32\n\nstruct adiantum_instance_ctx {\n\tstruct crypto_skcipher_spawn streamcipher_spawn;\n\tstruct crypto_cipher_spawn blockcipher_spawn;\n\tstruct crypto_shash_spawn hash_spawn;\n};\n\nstruct adiantum_tfm_ctx {\n\tstruct crypto_skcipher *streamcipher;\n\tstruct crypto_cipher *blockcipher;\n\tstruct crypto_shash *hash;\n\tstruct poly1305_core_key header_hash_key;\n};\n\nstruct adiantum_request_ctx {\n\n\t \n\tunion {\n\t\tu8 bytes[XCHACHA_IV_SIZE];\n\t\t__le32 words[XCHACHA_IV_SIZE / sizeof(__le32)];\n\t\tle128 bignum;\t \n\t} rbuf;\n\n\tbool enc;  \n\n\t \n\tle128 header_hash;\n\n\t \n\tunion {\n\t\tstruct shash_desc hash_desc;\n\t\tstruct skcipher_request streamcipher_req;\n\t} u;\n};\n\n \nstatic int adiantum_setkey(struct crypto_skcipher *tfm, const u8 *key,\n\t\t\t   unsigned int keylen)\n{\n\tstruct adiantum_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct {\n\t\tu8 iv[XCHACHA_IV_SIZE];\n\t\tu8 derived_keys[BLOCKCIPHER_KEY_SIZE + HASH_KEY_SIZE];\n\t\tstruct scatterlist sg;\n\t\tstruct crypto_wait wait;\n\t\tstruct skcipher_request req;  \n\t} *data;\n\tu8 *keyp;\n\tint err;\n\n\t \n\tcrypto_skcipher_clear_flags(tctx->streamcipher, CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(tctx->streamcipher,\n\t\t\t\t  crypto_skcipher_get_flags(tfm) &\n\t\t\t\t  CRYPTO_TFM_REQ_MASK);\n\terr = crypto_skcipher_setkey(tctx->streamcipher, key, keylen);\n\tif (err)\n\t\treturn err;\n\n\t \n\tdata = kzalloc(sizeof(*data) +\n\t\t       crypto_skcipher_reqsize(tctx->streamcipher), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\tdata->iv[0] = 1;\n\tsg_init_one(&data->sg, data->derived_keys, sizeof(data->derived_keys));\n\tcrypto_init_wait(&data->wait);\n\tskcipher_request_set_tfm(&data->req, tctx->streamcipher);\n\tskcipher_request_set_callback(&data->req, CRYPTO_TFM_REQ_MAY_SLEEP |\n\t\t\t\t\t\t  CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t      crypto_req_done, &data->wait);\n\tskcipher_request_set_crypt(&data->req, &data->sg, &data->sg,\n\t\t\t\t   sizeof(data->derived_keys), data->iv);\n\terr = crypto_wait_req(crypto_skcipher_encrypt(&data->req), &data->wait);\n\tif (err)\n\t\tgoto out;\n\tkeyp = data->derived_keys;\n\n\t \n\tcrypto_cipher_clear_flags(tctx->blockcipher, CRYPTO_TFM_REQ_MASK);\n\tcrypto_cipher_set_flags(tctx->blockcipher,\n\t\t\t\tcrypto_skcipher_get_flags(tfm) &\n\t\t\t\tCRYPTO_TFM_REQ_MASK);\n\terr = crypto_cipher_setkey(tctx->blockcipher, keyp,\n\t\t\t\t   BLOCKCIPHER_KEY_SIZE);\n\tif (err)\n\t\tgoto out;\n\tkeyp += BLOCKCIPHER_KEY_SIZE;\n\n\t \n\tpoly1305_core_setkey(&tctx->header_hash_key, keyp);\n\tkeyp += POLY1305_BLOCK_SIZE;\n\n\tcrypto_shash_clear_flags(tctx->hash, CRYPTO_TFM_REQ_MASK);\n\tcrypto_shash_set_flags(tctx->hash, crypto_skcipher_get_flags(tfm) &\n\t\t\t\t\t   CRYPTO_TFM_REQ_MASK);\n\terr = crypto_shash_setkey(tctx->hash, keyp, NHPOLY1305_KEY_SIZE);\n\tkeyp += NHPOLY1305_KEY_SIZE;\n\tWARN_ON(keyp != &data->derived_keys[ARRAY_SIZE(data->derived_keys)]);\nout:\n\tkfree_sensitive(data);\n\treturn err;\n}\n\n \nstatic inline void le128_add(le128 *r, const le128 *v1, const le128 *v2)\n{\n\tu64 x = le64_to_cpu(v1->b);\n\tu64 y = le64_to_cpu(v2->b);\n\n\tr->b = cpu_to_le64(x + y);\n\tr->a = cpu_to_le64(le64_to_cpu(v1->a) + le64_to_cpu(v2->a) +\n\t\t\t   (x + y < x));\n}\n\n \nstatic inline void le128_sub(le128 *r, const le128 *v1, const le128 *v2)\n{\n\tu64 x = le64_to_cpu(v1->b);\n\tu64 y = le64_to_cpu(v2->b);\n\n\tr->b = cpu_to_le64(x - y);\n\tr->a = cpu_to_le64(le64_to_cpu(v1->a) - le64_to_cpu(v2->a) -\n\t\t\t   (x - y > x));\n}\n\n \nstatic void adiantum_hash_header(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tconst struct adiantum_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct adiantum_request_ctx *rctx = skcipher_request_ctx(req);\n\tconst unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;\n\tstruct {\n\t\t__le64 message_bits;\n\t\t__le64 padding;\n\t} header = {\n\t\t.message_bits = cpu_to_le64((u64)bulk_len * 8)\n\t};\n\tstruct poly1305_state state;\n\n\tpoly1305_core_init(&state);\n\n\tBUILD_BUG_ON(sizeof(header) % POLY1305_BLOCK_SIZE != 0);\n\tpoly1305_core_blocks(&state, &tctx->header_hash_key,\n\t\t\t     &header, sizeof(header) / POLY1305_BLOCK_SIZE, 1);\n\n\tBUILD_BUG_ON(TWEAK_SIZE % POLY1305_BLOCK_SIZE != 0);\n\tpoly1305_core_blocks(&state, &tctx->header_hash_key, req->iv,\n\t\t\t     TWEAK_SIZE / POLY1305_BLOCK_SIZE, 1);\n\n\tpoly1305_core_emit(&state, NULL, &rctx->header_hash);\n}\n\n \nstatic int adiantum_hash_message(struct skcipher_request *req,\n\t\t\t\t struct scatterlist *sgl, le128 *digest)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tconst struct adiantum_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct adiantum_request_ctx *rctx = skcipher_request_ctx(req);\n\tconst unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;\n\tstruct shash_desc *hash_desc = &rctx->u.hash_desc;\n\tstruct sg_mapping_iter miter;\n\tunsigned int i, n;\n\tint err;\n\n\thash_desc->tfm = tctx->hash;\n\n\terr = crypto_shash_init(hash_desc);\n\tif (err)\n\t\treturn err;\n\n\tsg_miter_start(&miter, sgl, sg_nents(sgl),\n\t\t       SG_MITER_FROM_SG | SG_MITER_ATOMIC);\n\tfor (i = 0; i < bulk_len; i += n) {\n\t\tsg_miter_next(&miter);\n\t\tn = min_t(unsigned int, miter.length, bulk_len - i);\n\t\terr = crypto_shash_update(hash_desc, miter.addr, n);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\tsg_miter_stop(&miter);\n\tif (err)\n\t\treturn err;\n\n\treturn crypto_shash_final(hash_desc, (u8 *)digest);\n}\n\n \nstatic int adiantum_finish(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tconst struct adiantum_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct adiantum_request_ctx *rctx = skcipher_request_ctx(req);\n\tconst unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;\n\tle128 digest;\n\tint err;\n\n\t \n\tif (!rctx->enc)\n\t\tcrypto_cipher_decrypt_one(tctx->blockcipher, rctx->rbuf.bytes,\n\t\t\t\t\t  rctx->rbuf.bytes);\n\n\t \n\terr = adiantum_hash_message(req, req->dst, &digest);\n\tif (err)\n\t\treturn err;\n\tle128_add(&digest, &digest, &rctx->header_hash);\n\tle128_sub(&rctx->rbuf.bignum, &rctx->rbuf.bignum, &digest);\n\tscatterwalk_map_and_copy(&rctx->rbuf.bignum, req->dst,\n\t\t\t\t bulk_len, BLOCKCIPHER_BLOCK_SIZE, 1);\n\treturn 0;\n}\n\nstatic void adiantum_streamcipher_done(void *data, int err)\n{\n\tstruct skcipher_request *req = data;\n\n\tif (!err)\n\t\terr = adiantum_finish(req);\n\n\tskcipher_request_complete(req, err);\n}\n\nstatic int adiantum_crypt(struct skcipher_request *req, bool enc)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tconst struct adiantum_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct adiantum_request_ctx *rctx = skcipher_request_ctx(req);\n\tconst unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;\n\tunsigned int stream_len;\n\tle128 digest;\n\tint err;\n\n\tif (req->cryptlen < BLOCKCIPHER_BLOCK_SIZE)\n\t\treturn -EINVAL;\n\n\trctx->enc = enc;\n\n\t \n\tadiantum_hash_header(req);\n\terr = adiantum_hash_message(req, req->src, &digest);\n\tif (err)\n\t\treturn err;\n\tle128_add(&digest, &digest, &rctx->header_hash);\n\tscatterwalk_map_and_copy(&rctx->rbuf.bignum, req->src,\n\t\t\t\t bulk_len, BLOCKCIPHER_BLOCK_SIZE, 0);\n\tle128_add(&rctx->rbuf.bignum, &rctx->rbuf.bignum, &digest);\n\n\t \n\tif (enc)\n\t\tcrypto_cipher_encrypt_one(tctx->blockcipher, rctx->rbuf.bytes,\n\t\t\t\t\t  rctx->rbuf.bytes);\n\n\t \n\tBUILD_BUG_ON(BLOCKCIPHER_BLOCK_SIZE != 16);\n\tBUILD_BUG_ON(XCHACHA_IV_SIZE != 32);\t \n\trctx->rbuf.words[4] = cpu_to_le32(1);\n\trctx->rbuf.words[5] = 0;\n\trctx->rbuf.words[6] = 0;\n\trctx->rbuf.words[7] = 0;\n\n\t \n\tstream_len = bulk_len;\n\tif (round_up(stream_len, CHACHA_BLOCK_SIZE) <= req->cryptlen)\n\t\tstream_len = round_up(stream_len, CHACHA_BLOCK_SIZE);\n\n\tskcipher_request_set_tfm(&rctx->u.streamcipher_req, tctx->streamcipher);\n\tskcipher_request_set_crypt(&rctx->u.streamcipher_req, req->src,\n\t\t\t\t   req->dst, stream_len, &rctx->rbuf);\n\tskcipher_request_set_callback(&rctx->u.streamcipher_req,\n\t\t\t\t      req->base.flags,\n\t\t\t\t      adiantum_streamcipher_done, req);\n\treturn crypto_skcipher_encrypt(&rctx->u.streamcipher_req) ?:\n\t\tadiantum_finish(req);\n}\n\nstatic int adiantum_encrypt(struct skcipher_request *req)\n{\n\treturn adiantum_crypt(req, true);\n}\n\nstatic int adiantum_decrypt(struct skcipher_request *req)\n{\n\treturn adiantum_crypt(req, false);\n}\n\nstatic int adiantum_init_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct skcipher_instance *inst = skcipher_alg_instance(tfm);\n\tstruct adiantum_instance_ctx *ictx = skcipher_instance_ctx(inst);\n\tstruct adiantum_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct crypto_skcipher *streamcipher;\n\tstruct crypto_cipher *blockcipher;\n\tstruct crypto_shash *hash;\n\tunsigned int subreq_size;\n\tint err;\n\n\tstreamcipher = crypto_spawn_skcipher(&ictx->streamcipher_spawn);\n\tif (IS_ERR(streamcipher))\n\t\treturn PTR_ERR(streamcipher);\n\n\tblockcipher = crypto_spawn_cipher(&ictx->blockcipher_spawn);\n\tif (IS_ERR(blockcipher)) {\n\t\terr = PTR_ERR(blockcipher);\n\t\tgoto err_free_streamcipher;\n\t}\n\n\thash = crypto_spawn_shash(&ictx->hash_spawn);\n\tif (IS_ERR(hash)) {\n\t\terr = PTR_ERR(hash);\n\t\tgoto err_free_blockcipher;\n\t}\n\n\ttctx->streamcipher = streamcipher;\n\ttctx->blockcipher = blockcipher;\n\ttctx->hash = hash;\n\n\tBUILD_BUG_ON(offsetofend(struct adiantum_request_ctx, u) !=\n\t\t     sizeof(struct adiantum_request_ctx));\n\tsubreq_size = max(sizeof_field(struct adiantum_request_ctx,\n\t\t\t\t       u.hash_desc) +\n\t\t\t  crypto_shash_descsize(hash),\n\t\t\t  sizeof_field(struct adiantum_request_ctx,\n\t\t\t\t       u.streamcipher_req) +\n\t\t\t  crypto_skcipher_reqsize(streamcipher));\n\n\tcrypto_skcipher_set_reqsize(tfm,\n\t\t\t\t    offsetof(struct adiantum_request_ctx, u) +\n\t\t\t\t    subreq_size);\n\treturn 0;\n\nerr_free_blockcipher:\n\tcrypto_free_cipher(blockcipher);\nerr_free_streamcipher:\n\tcrypto_free_skcipher(streamcipher);\n\treturn err;\n}\n\nstatic void adiantum_exit_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct adiantum_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\n\tcrypto_free_skcipher(tctx->streamcipher);\n\tcrypto_free_cipher(tctx->blockcipher);\n\tcrypto_free_shash(tctx->hash);\n}\n\nstatic void adiantum_free_instance(struct skcipher_instance *inst)\n{\n\tstruct adiantum_instance_ctx *ictx = skcipher_instance_ctx(inst);\n\n\tcrypto_drop_skcipher(&ictx->streamcipher_spawn);\n\tcrypto_drop_cipher(&ictx->blockcipher_spawn);\n\tcrypto_drop_shash(&ictx->hash_spawn);\n\tkfree(inst);\n}\n\n \nstatic bool adiantum_supported_algorithms(struct skcipher_alg *streamcipher_alg,\n\t\t\t\t\t  struct crypto_alg *blockcipher_alg,\n\t\t\t\t\t  struct shash_alg *hash_alg)\n{\n\tif (strcmp(streamcipher_alg->base.cra_name, \"xchacha12\") != 0 &&\n\t    strcmp(streamcipher_alg->base.cra_name, \"xchacha20\") != 0)\n\t\treturn false;\n\n\tif (blockcipher_alg->cra_cipher.cia_min_keysize > BLOCKCIPHER_KEY_SIZE ||\n\t    blockcipher_alg->cra_cipher.cia_max_keysize < BLOCKCIPHER_KEY_SIZE)\n\t\treturn false;\n\tif (blockcipher_alg->cra_blocksize != BLOCKCIPHER_BLOCK_SIZE)\n\t\treturn false;\n\n\tif (strcmp(hash_alg->base.cra_name, \"nhpoly1305\") != 0)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int adiantum_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tu32 mask;\n\tconst char *nhpoly1305_name;\n\tstruct skcipher_instance *inst;\n\tstruct adiantum_instance_ctx *ictx;\n\tstruct skcipher_alg *streamcipher_alg;\n\tstruct crypto_alg *blockcipher_alg;\n\tstruct shash_alg *hash_alg;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SKCIPHER, &mask);\n\tif (err)\n\t\treturn err;\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ictx), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\tictx = skcipher_instance_ctx(inst);\n\n\t \n\terr = crypto_grab_skcipher(&ictx->streamcipher_spawn,\n\t\t\t\t   skcipher_crypto_instance(inst),\n\t\t\t\t   crypto_attr_alg_name(tb[1]), 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\tstreamcipher_alg = crypto_spawn_skcipher_alg(&ictx->streamcipher_spawn);\n\n\t \n\terr = crypto_grab_cipher(&ictx->blockcipher_spawn,\n\t\t\t\t skcipher_crypto_instance(inst),\n\t\t\t\t crypto_attr_alg_name(tb[2]), 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\tblockcipher_alg = crypto_spawn_cipher_alg(&ictx->blockcipher_spawn);\n\n\t \n\tnhpoly1305_name = crypto_attr_alg_name(tb[3]);\n\tif (nhpoly1305_name == ERR_PTR(-ENOENT))\n\t\tnhpoly1305_name = \"nhpoly1305\";\n\terr = crypto_grab_shash(&ictx->hash_spawn,\n\t\t\t\tskcipher_crypto_instance(inst),\n\t\t\t\tnhpoly1305_name, 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\thash_alg = crypto_spawn_shash_alg(&ictx->hash_spawn);\n\n\t \n\tif (!adiantum_supported_algorithms(streamcipher_alg, blockcipher_alg,\n\t\t\t\t\t   hash_alg)) {\n\t\tpr_warn(\"Unsupported Adiantum instantiation: (%s,%s,%s)\\n\",\n\t\t\tstreamcipher_alg->base.cra_name,\n\t\t\tblockcipher_alg->cra_name, hash_alg->base.cra_name);\n\t\terr = -EINVAL;\n\t\tgoto err_free_inst;\n\t}\n\n\t \n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.base.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"adiantum(%s,%s)\", streamcipher_alg->base.cra_name,\n\t\t     blockcipher_alg->cra_name) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\tif (snprintf(inst->alg.base.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"adiantum(%s,%s,%s)\",\n\t\t     streamcipher_alg->base.cra_driver_name,\n\t\t     blockcipher_alg->cra_driver_name,\n\t\t     hash_alg->base.cra_driver_name) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\n\tinst->alg.base.cra_blocksize = BLOCKCIPHER_BLOCK_SIZE;\n\tinst->alg.base.cra_ctxsize = sizeof(struct adiantum_tfm_ctx);\n\tinst->alg.base.cra_alignmask = streamcipher_alg->base.cra_alignmask |\n\t\t\t\t       hash_alg->base.cra_alignmask;\n\t \n\tinst->alg.base.cra_priority = (4 * streamcipher_alg->base.cra_priority +\n\t\t\t\t       2 * hash_alg->base.cra_priority +\n\t\t\t\t       blockcipher_alg->cra_priority) / 7;\n\n\tinst->alg.setkey = adiantum_setkey;\n\tinst->alg.encrypt = adiantum_encrypt;\n\tinst->alg.decrypt = adiantum_decrypt;\n\tinst->alg.init = adiantum_init_tfm;\n\tinst->alg.exit = adiantum_exit_tfm;\n\tinst->alg.min_keysize = crypto_skcipher_alg_min_keysize(streamcipher_alg);\n\tinst->alg.max_keysize = crypto_skcipher_alg_max_keysize(streamcipher_alg);\n\tinst->alg.ivsize = TWEAK_SIZE;\n\n\tinst->free = adiantum_free_instance;\n\n\terr = skcipher_register_instance(tmpl, inst);\n\tif (err) {\nerr_free_inst:\n\t\tadiantum_free_instance(inst);\n\t}\n\treturn err;\n}\n\n \nstatic struct crypto_template adiantum_tmpl = {\n\t.name = \"adiantum\",\n\t.create = adiantum_create,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init adiantum_module_init(void)\n{\n\treturn crypto_register_template(&adiantum_tmpl);\n}\n\nstatic void __exit adiantum_module_exit(void)\n{\n\tcrypto_unregister_template(&adiantum_tmpl);\n}\n\nsubsys_initcall(adiantum_module_init);\nmodule_exit(adiantum_module_exit);\n\nMODULE_DESCRIPTION(\"Adiantum length-preserving encryption mode\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Eric Biggers <ebiggers@google.com>\");\nMODULE_ALIAS_CRYPTO(\"adiantum\");\nMODULE_IMPORT_NS(CRYPTO_INTERNAL);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}