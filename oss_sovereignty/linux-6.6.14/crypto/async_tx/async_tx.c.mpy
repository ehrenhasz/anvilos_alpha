{
  "module_name": "async_tx.c",
  "hash_id": "fdf7baec1ff8eaed9159d2384a7492e06d0dadddb78e56d0f4ca11c70f62b9f2",
  "original_prompt": "Ingested from linux-6.6.14/crypto/async_tx/async_tx.c",
  "human_readable_source": "\n \n#include <linux/rculist.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/async_tx.h>\n\n#ifdef CONFIG_DMA_ENGINE\nstatic int __init async_tx_init(void)\n{\n\tasync_dmaengine_get();\n\n\tprintk(KERN_INFO \"async_tx: api initialized (async)\\n\");\n\n\treturn 0;\n}\n\nstatic void __exit async_tx_exit(void)\n{\n\tasync_dmaengine_put();\n}\n\nmodule_init(async_tx_init);\nmodule_exit(async_tx_exit);\n\n \nstruct dma_chan *\n__async_tx_find_channel(struct async_submit_ctl *submit,\n\t\t\tenum dma_transaction_type tx_type)\n{\n\tstruct dma_async_tx_descriptor *depend_tx = submit->depend_tx;\n\n\t \n\tif (depend_tx &&\n\t    dma_has_cap(tx_type, depend_tx->chan->device->cap_mask))\n\t\treturn depend_tx->chan;\n\treturn async_dma_find_channel(tx_type);\n}\nEXPORT_SYMBOL_GPL(__async_tx_find_channel);\n#endif\n\n\n \nstatic void\nasync_tx_channel_switch(struct dma_async_tx_descriptor *depend_tx,\n\t\t\tstruct dma_async_tx_descriptor *tx)\n{\n\tstruct dma_chan *chan = depend_tx->chan;\n\tstruct dma_device *device = chan->device;\n\tstruct dma_async_tx_descriptor *intr_tx = (void *) ~0;\n\n\t \n\ttxd_lock(depend_tx);\n\tif (txd_parent(depend_tx) && depend_tx->chan == tx->chan) {\n\t\ttxd_chain(depend_tx, tx);\n\t\tintr_tx = NULL;\n\t}\n\ttxd_unlock(depend_tx);\n\n\t \n\tif (!intr_tx) {\n\t\tdevice->device_issue_pending(chan);\n\t\treturn;\n\t}\n\n\t \n\tif (dma_has_cap(DMA_INTERRUPT, device->cap_mask))\n\t\tintr_tx = device->device_prep_dma_interrupt(chan, 0);\n\telse\n\t\tintr_tx = NULL;\n\n\tif (intr_tx) {\n\t\tintr_tx->callback = NULL;\n\t\tintr_tx->callback_param = NULL;\n\t\t \n\t\ttxd_chain(intr_tx, tx);\n\n\t\t \n\t\ttxd_lock(depend_tx);\n\t\tif (txd_parent(depend_tx)) {\n\t\t\ttxd_chain(depend_tx, intr_tx);\n\t\t\tasync_tx_ack(intr_tx);\n\t\t\tintr_tx = NULL;\n\t\t}\n\t\ttxd_unlock(depend_tx);\n\n\t\tif (intr_tx) {\n\t\t\ttxd_clear_parent(intr_tx);\n\t\t\tintr_tx->tx_submit(intr_tx);\n\t\t\tasync_tx_ack(intr_tx);\n\t\t}\n\t\tdevice->device_issue_pending(chan);\n\t} else {\n\t\tif (dma_wait_for_async_tx(depend_tx) != DMA_COMPLETE)\n\t\t\tpanic(\"%s: DMA error waiting for depend_tx\\n\",\n\t\t\t      __func__);\n\t\ttx->tx_submit(tx);\n\t}\n}\n\n\n \nenum submit_disposition {\n\tASYNC_TX_SUBMITTED,\n\tASYNC_TX_CHANNEL_SWITCH,\n\tASYNC_TX_DIRECT_SUBMIT,\n};\n\nvoid\nasync_tx_submit(struct dma_chan *chan, struct dma_async_tx_descriptor *tx,\n\t\tstruct async_submit_ctl *submit)\n{\n\tstruct dma_async_tx_descriptor *depend_tx = submit->depend_tx;\n\n\ttx->callback = submit->cb_fn;\n\ttx->callback_param = submit->cb_param;\n\n\tif (depend_tx) {\n\t\tenum submit_disposition s;\n\n\t\t \n\t\tBUG_ON(async_tx_test_ack(depend_tx) || txd_next(depend_tx) ||\n\t\t       txd_parent(tx));\n\n\t\t \n\t\ttxd_lock(depend_tx);\n\t\tif (txd_parent(depend_tx)) {\n\t\t\t \n\t\t\tif (depend_tx->chan == chan) {\n\t\t\t\ttxd_chain(depend_tx, tx);\n\t\t\t\ts = ASYNC_TX_SUBMITTED;\n\t\t\t} else\n\t\t\t\ts = ASYNC_TX_CHANNEL_SWITCH;\n\t\t} else {\n\t\t\t \n\t\t\tif (depend_tx->chan == chan)\n\t\t\t\ts = ASYNC_TX_DIRECT_SUBMIT;\n\t\t\telse\n\t\t\t\ts = ASYNC_TX_CHANNEL_SWITCH;\n\t\t}\n\t\ttxd_unlock(depend_tx);\n\n\t\tswitch (s) {\n\t\tcase ASYNC_TX_SUBMITTED:\n\t\t\tbreak;\n\t\tcase ASYNC_TX_CHANNEL_SWITCH:\n\t\t\tasync_tx_channel_switch(depend_tx, tx);\n\t\t\tbreak;\n\t\tcase ASYNC_TX_DIRECT_SUBMIT:\n\t\t\ttxd_clear_parent(tx);\n\t\t\ttx->tx_submit(tx);\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\ttxd_clear_parent(tx);\n\t\ttx->tx_submit(tx);\n\t}\n\n\tif (submit->flags & ASYNC_TX_ACK)\n\t\tasync_tx_ack(tx);\n\n\tif (depend_tx)\n\t\tasync_tx_ack(depend_tx);\n}\nEXPORT_SYMBOL_GPL(async_tx_submit);\n\n \nstruct dma_async_tx_descriptor *\nasync_trigger_callback(struct async_submit_ctl *submit)\n{\n\tstruct dma_chan *chan;\n\tstruct dma_device *device;\n\tstruct dma_async_tx_descriptor *tx;\n\tstruct dma_async_tx_descriptor *depend_tx = submit->depend_tx;\n\n\tif (depend_tx) {\n\t\tchan = depend_tx->chan;\n\t\tdevice = chan->device;\n\n\t\t \n\t\tif (device && !dma_has_cap(DMA_INTERRUPT, device->cap_mask))\n\t\t\tdevice = NULL;\n\n\t\ttx = device ? device->device_prep_dma_interrupt(chan, 0) : NULL;\n\t} else\n\t\ttx = NULL;\n\n\tif (tx) {\n\t\tpr_debug(\"%s: (async)\\n\", __func__);\n\n\t\tasync_tx_submit(chan, tx, submit);\n\t} else {\n\t\tpr_debug(\"%s: (sync)\\n\", __func__);\n\n\t\t \n\t\tasync_tx_quiesce(&submit->depend_tx);\n\n\t\tasync_tx_sync_epilog(submit);\n\t}\n\n\treturn tx;\n}\nEXPORT_SYMBOL_GPL(async_trigger_callback);\n\n \nvoid async_tx_quiesce(struct dma_async_tx_descriptor **tx)\n{\n\tif (*tx) {\n\t\t \n\t\tBUG_ON(async_tx_test_ack(*tx));\n\t\tif (dma_wait_for_async_tx(*tx) != DMA_COMPLETE)\n\t\t\tpanic(\"%s: DMA error waiting for transaction\\n\",\n\t\t\t      __func__);\n\t\tasync_tx_ack(*tx);\n\t\t*tx = NULL;\n\t}\n}\nEXPORT_SYMBOL_GPL(async_tx_quiesce);\n\nMODULE_AUTHOR(\"Intel Corporation\");\nMODULE_DESCRIPTION(\"Asynchronous Bulk Memory Transactions API\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}