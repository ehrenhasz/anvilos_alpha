{
  "module_name": "ctr.c",
  "hash_id": "36bc00448fc4a94a2a650fb1f990622428e6fc53cb78d8d689132b89f8278d64",
  "original_prompt": "Ingested from linux-6.6.14/crypto/ctr.c",
  "human_readable_source": "\n \n\n#include <crypto/algapi.h>\n#include <crypto/ctr.h>\n#include <crypto/internal/cipher.h>\n#include <crypto/internal/skcipher.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n\nstruct crypto_rfc3686_ctx {\n\tstruct crypto_skcipher *child;\n\tu8 nonce[CTR_RFC3686_NONCE_SIZE];\n};\n\nstruct crypto_rfc3686_req_ctx {\n\tu8 iv[CTR_RFC3686_BLOCK_SIZE];\n\tstruct skcipher_request subreq CRYPTO_MINALIGN_ATTR;\n};\n\nstatic void crypto_ctr_crypt_final(struct skcipher_walk *walk,\n\t\t\t\t   struct crypto_cipher *tfm)\n{\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tunsigned long alignmask = crypto_cipher_alignmask(tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 tmp[MAX_CIPHER_BLOCKSIZE + MAX_CIPHER_ALIGNMASK];\n\tu8 *keystream = PTR_ALIGN(tmp + 0, alignmask + 1);\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tcrypto_cipher_encrypt_one(tfm, keystream, ctrblk);\n\tcrypto_xor_cpy(dst, keystream, src, nbytes);\n\n\tcrypto_inc(ctrblk, bsize);\n}\n\nstatic int crypto_ctr_crypt_segment(struct skcipher_walk *walk,\n\t\t\t\t    struct crypto_cipher *tfm)\n{\n\tvoid (*fn)(struct crypto_tfm *, u8 *, const u8 *) =\n\t\t   crypto_cipher_alg(tfm)->cia_encrypt;\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tu8 *ctrblk = walk->iv;\n\tu8 *src = walk->src.virt.addr;\n\tu8 *dst = walk->dst.virt.addr;\n\tunsigned int nbytes = walk->nbytes;\n\n\tdo {\n\t\t \n\t\tfn(crypto_cipher_tfm(tfm), dst, ctrblk);\n\t\tcrypto_xor(dst, src, bsize);\n\n\t\t \n\t\tcrypto_inc(ctrblk, bsize);\n\n\t\tsrc += bsize;\n\t\tdst += bsize;\n\t} while ((nbytes -= bsize) >= bsize);\n\n\treturn nbytes;\n}\n\nstatic int crypto_ctr_crypt_inplace(struct skcipher_walk *walk,\n\t\t\t\t    struct crypto_cipher *tfm)\n{\n\tvoid (*fn)(struct crypto_tfm *, u8 *, const u8 *) =\n\t\t   crypto_cipher_alg(tfm)->cia_encrypt;\n\tunsigned int bsize = crypto_cipher_blocksize(tfm);\n\tunsigned long alignmask = crypto_cipher_alignmask(tfm);\n\tunsigned int nbytes = walk->nbytes;\n\tu8 *ctrblk = walk->iv;\n\tu8 *src = walk->src.virt.addr;\n\tu8 tmp[MAX_CIPHER_BLOCKSIZE + MAX_CIPHER_ALIGNMASK];\n\tu8 *keystream = PTR_ALIGN(tmp + 0, alignmask + 1);\n\n\tdo {\n\t\t \n\t\tfn(crypto_cipher_tfm(tfm), keystream, ctrblk);\n\t\tcrypto_xor(src, keystream, bsize);\n\n\t\t \n\t\tcrypto_inc(ctrblk, bsize);\n\n\t\tsrc += bsize;\n\t} while ((nbytes -= bsize) >= bsize);\n\n\treturn nbytes;\n}\n\nstatic int crypto_ctr_crypt(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct crypto_cipher *cipher = skcipher_cipher_simple(tfm);\n\tconst unsigned int bsize = crypto_cipher_blocksize(cipher);\n\tstruct skcipher_walk walk;\n\tunsigned int nbytes;\n\tint err;\n\n\terr = skcipher_walk_virt(&walk, req, false);\n\n\twhile (walk.nbytes >= bsize) {\n\t\tif (walk.src.virt.addr == walk.dst.virt.addr)\n\t\t\tnbytes = crypto_ctr_crypt_inplace(&walk, cipher);\n\t\telse\n\t\t\tnbytes = crypto_ctr_crypt_segment(&walk, cipher);\n\n\t\terr = skcipher_walk_done(&walk, nbytes);\n\t}\n\n\tif (walk.nbytes) {\n\t\tcrypto_ctr_crypt_final(&walk, cipher);\n\t\terr = skcipher_walk_done(&walk, 0);\n\t}\n\n\treturn err;\n}\n\nstatic int crypto_ctr_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct skcipher_instance *inst;\n\tstruct crypto_alg *alg;\n\tint err;\n\n\tinst = skcipher_alloc_instance_simple(tmpl, tb);\n\tif (IS_ERR(inst))\n\t\treturn PTR_ERR(inst);\n\n\talg = skcipher_ialg_simple(inst);\n\n\t \n\terr = -EINVAL;\n\tif (alg->cra_blocksize < 4)\n\t\tgoto out_free_inst;\n\n\t \n\tif (alg->cra_blocksize % 4)\n\t\tgoto out_free_inst;\n\n\t \n\tinst->alg.base.cra_blocksize = 1;\n\n\t \n\tinst->alg.chunksize = alg->cra_blocksize;\n\n\tinst->alg.encrypt = crypto_ctr_crypt;\n\tinst->alg.decrypt = crypto_ctr_crypt;\n\n\terr = skcipher_register_instance(tmpl, inst);\n\tif (err) {\nout_free_inst:\n\t\tinst->free(inst);\n\t}\n\n\treturn err;\n}\n\nstatic int crypto_rfc3686_setkey(struct crypto_skcipher *parent,\n\t\t\t\t const u8 *key, unsigned int keylen)\n{\n\tstruct crypto_rfc3686_ctx *ctx = crypto_skcipher_ctx(parent);\n\tstruct crypto_skcipher *child = ctx->child;\n\n\t \n\tif (keylen < CTR_RFC3686_NONCE_SIZE)\n\t\treturn -EINVAL;\n\n\tmemcpy(ctx->nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),\n\t       CTR_RFC3686_NONCE_SIZE);\n\n\tkeylen -= CTR_RFC3686_NONCE_SIZE;\n\n\tcrypto_skcipher_clear_flags(child, CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(child, crypto_skcipher_get_flags(parent) &\n\t\t\t\t\t CRYPTO_TFM_REQ_MASK);\n\treturn crypto_skcipher_setkey(child, key, keylen);\n}\n\nstatic int crypto_rfc3686_crypt(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct crypto_rfc3686_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tstruct crypto_skcipher *child = ctx->child;\n\tunsigned long align = crypto_skcipher_alignmask(tfm);\n\tstruct crypto_rfc3686_req_ctx *rctx =\n\t\t(void *)PTR_ALIGN((u8 *)skcipher_request_ctx(req), align + 1);\n\tstruct skcipher_request *subreq = &rctx->subreq;\n\tu8 *iv = rctx->iv;\n\n\t \n\tmemcpy(iv, ctx->nonce, CTR_RFC3686_NONCE_SIZE);\n\tmemcpy(iv + CTR_RFC3686_NONCE_SIZE, req->iv, CTR_RFC3686_IV_SIZE);\n\n\t \n\t*(__be32 *)(iv + CTR_RFC3686_NONCE_SIZE + CTR_RFC3686_IV_SIZE) =\n\t\tcpu_to_be32(1);\n\n\tskcipher_request_set_tfm(subreq, child);\n\tskcipher_request_set_callback(subreq, req->base.flags,\n\t\t\t\t      req->base.complete, req->base.data);\n\tskcipher_request_set_crypt(subreq, req->src, req->dst,\n\t\t\t\t   req->cryptlen, iv);\n\n\treturn crypto_skcipher_encrypt(subreq);\n}\n\nstatic int crypto_rfc3686_init_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct skcipher_instance *inst = skcipher_alg_instance(tfm);\n\tstruct crypto_skcipher_spawn *spawn = skcipher_instance_ctx(inst);\n\tstruct crypto_rfc3686_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tstruct crypto_skcipher *cipher;\n\tunsigned long align;\n\tunsigned int reqsize;\n\n\tcipher = crypto_spawn_skcipher(spawn);\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\n\talign = crypto_skcipher_alignmask(tfm);\n\talign &= ~(crypto_tfm_ctx_alignment() - 1);\n\treqsize = align + sizeof(struct crypto_rfc3686_req_ctx) +\n\t\t  crypto_skcipher_reqsize(cipher);\n\tcrypto_skcipher_set_reqsize(tfm, reqsize);\n\n\treturn 0;\n}\n\nstatic void crypto_rfc3686_exit_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct crypto_rfc3686_ctx *ctx = crypto_skcipher_ctx(tfm);\n\n\tcrypto_free_skcipher(ctx->child);\n}\n\nstatic void crypto_rfc3686_free(struct skcipher_instance *inst)\n{\n\tstruct crypto_skcipher_spawn *spawn = skcipher_instance_ctx(inst);\n\n\tcrypto_drop_skcipher(spawn);\n\tkfree(inst);\n}\n\nstatic int crypto_rfc3686_create(struct crypto_template *tmpl,\n\t\t\t\t struct rtattr **tb)\n{\n\tstruct skcipher_instance *inst;\n\tstruct skcipher_alg *alg;\n\tstruct crypto_skcipher_spawn *spawn;\n\tu32 mask;\n\tint err;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SKCIPHER, &mask);\n\tif (err)\n\t\treturn err;\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\n\tspawn = skcipher_instance_ctx(inst);\n\n\terr = crypto_grab_skcipher(spawn, skcipher_crypto_instance(inst),\n\t\t\t\t   crypto_attr_alg_name(tb[1]), 0, mask);\n\tif (err)\n\t\tgoto err_free_inst;\n\n\talg = crypto_spawn_skcipher_alg(spawn);\n\n\t \n\terr = -EINVAL;\n\tif (crypto_skcipher_alg_ivsize(alg) != CTR_RFC3686_BLOCK_SIZE)\n\t\tgoto err_free_inst;\n\n\t \n\tif (alg->base.cra_blocksize != 1)\n\t\tgoto err_free_inst;\n\n\terr = -ENAMETOOLONG;\n\tif (snprintf(inst->alg.base.cra_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc3686(%s)\", alg->base.cra_name) >= CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\tif (snprintf(inst->alg.base.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"rfc3686(%s)\", alg->base.cra_driver_name) >=\n\t    CRYPTO_MAX_ALG_NAME)\n\t\tgoto err_free_inst;\n\n\tinst->alg.base.cra_priority = alg->base.cra_priority;\n\tinst->alg.base.cra_blocksize = 1;\n\tinst->alg.base.cra_alignmask = alg->base.cra_alignmask;\n\n\tinst->alg.ivsize = CTR_RFC3686_IV_SIZE;\n\tinst->alg.chunksize = crypto_skcipher_alg_chunksize(alg);\n\tinst->alg.min_keysize = crypto_skcipher_alg_min_keysize(alg) +\n\t\t\t\tCTR_RFC3686_NONCE_SIZE;\n\tinst->alg.max_keysize = crypto_skcipher_alg_max_keysize(alg) +\n\t\t\t\tCTR_RFC3686_NONCE_SIZE;\n\n\tinst->alg.setkey = crypto_rfc3686_setkey;\n\tinst->alg.encrypt = crypto_rfc3686_crypt;\n\tinst->alg.decrypt = crypto_rfc3686_crypt;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct crypto_rfc3686_ctx);\n\n\tinst->alg.init = crypto_rfc3686_init_tfm;\n\tinst->alg.exit = crypto_rfc3686_exit_tfm;\n\n\tinst->free = crypto_rfc3686_free;\n\n\terr = skcipher_register_instance(tmpl, inst);\n\tif (err) {\nerr_free_inst:\n\t\tcrypto_rfc3686_free(inst);\n\t}\n\treturn err;\n}\n\nstatic struct crypto_template crypto_ctr_tmpls[] = {\n\t{\n\t\t.name = \"ctr\",\n\t\t.create = crypto_ctr_create,\n\t\t.module = THIS_MODULE,\n\t}, {\n\t\t.name = \"rfc3686\",\n\t\t.create = crypto_rfc3686_create,\n\t\t.module = THIS_MODULE,\n\t},\n};\n\nstatic int __init crypto_ctr_module_init(void)\n{\n\treturn crypto_register_templates(crypto_ctr_tmpls,\n\t\t\t\t\t ARRAY_SIZE(crypto_ctr_tmpls));\n}\n\nstatic void __exit crypto_ctr_module_exit(void)\n{\n\tcrypto_unregister_templates(crypto_ctr_tmpls,\n\t\t\t\t    ARRAY_SIZE(crypto_ctr_tmpls));\n}\n\nsubsys_initcall(crypto_ctr_module_init);\nmodule_exit(crypto_ctr_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"CTR block cipher mode of operation\");\nMODULE_ALIAS_CRYPTO(\"rfc3686\");\nMODULE_ALIAS_CRYPTO(\"ctr\");\nMODULE_IMPORT_NS(CRYPTO_INTERNAL);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}