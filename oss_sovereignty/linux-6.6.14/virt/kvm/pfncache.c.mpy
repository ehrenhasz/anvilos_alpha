{
  "module_name": "pfncache.c",
  "hash_id": "654b8d39ddd4f73913a89384dca893cd8275da53f8fc42816a788dd4985a4d65",
  "original_prompt": "Ingested from linux-6.6.14/virt/kvm/pfncache.c",
  "human_readable_source": "\n \n\n#include <linux/kvm_host.h>\n#include <linux/kvm.h>\n#include <linux/highmem.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n\n#include \"kvm_mm.h\"\n\n \nvoid gfn_to_pfn_cache_invalidate_start(struct kvm *kvm, unsigned long start,\n\t\t\t\t       unsigned long end, bool may_block)\n{\n\tDECLARE_BITMAP(vcpu_bitmap, KVM_MAX_VCPUS);\n\tstruct gfn_to_pfn_cache *gpc;\n\tbool evict_vcpus = false;\n\n\tspin_lock(&kvm->gpc_lock);\n\tlist_for_each_entry(gpc, &kvm->gpc_list, list) {\n\t\twrite_lock_irq(&gpc->lock);\n\n\t\t \n\t\tif (gpc->valid && !is_error_noslot_pfn(gpc->pfn) &&\n\t\t    gpc->uhva >= start && gpc->uhva < end) {\n\t\t\tgpc->valid = false;\n\n\t\t\t \n\t\t\tif (gpc->usage & KVM_GUEST_USES_PFN) {\n\t\t\t\tif (!evict_vcpus) {\n\t\t\t\t\tevict_vcpus = true;\n\t\t\t\t\tbitmap_zero(vcpu_bitmap, KVM_MAX_VCPUS);\n\t\t\t\t}\n\t\t\t\t__set_bit(gpc->vcpu->vcpu_idx, vcpu_bitmap);\n\t\t\t}\n\t\t}\n\t\twrite_unlock_irq(&gpc->lock);\n\t}\n\tspin_unlock(&kvm->gpc_lock);\n\n\tif (evict_vcpus) {\n\t\t \n\t\tunsigned int req = KVM_REQ_OUTSIDE_GUEST_MODE;\n\t\tbool called;\n\n\t\t \n\t\tif (!may_block)\n\t\t\treq &= ~KVM_REQUEST_WAIT;\n\n\t\tcalled = kvm_make_vcpus_request_mask(kvm, req, vcpu_bitmap);\n\n\t\tWARN_ON_ONCE(called && !may_block);\n\t}\n}\n\nbool kvm_gpc_check(struct gfn_to_pfn_cache *gpc, unsigned long len)\n{\n\tstruct kvm_memslots *slots = kvm_memslots(gpc->kvm);\n\n\tif (!gpc->active)\n\t\treturn false;\n\n\tif ((gpc->gpa & ~PAGE_MASK) + len > PAGE_SIZE)\n\t\treturn false;\n\n\tif (gpc->generation != slots->generation || kvm_is_error_hva(gpc->uhva))\n\t\treturn false;\n\n\tif (!gpc->valid)\n\t\treturn false;\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(kvm_gpc_check);\n\nstatic void gpc_unmap_khva(kvm_pfn_t pfn, void *khva)\n{\n\t \n\tif (!is_error_noslot_pfn(pfn) && khva) {\n\t\tif (pfn_valid(pfn))\n\t\t\tkunmap(pfn_to_page(pfn));\n#ifdef CONFIG_HAS_IOMEM\n\t\telse\n\t\t\tmemunmap(khva);\n#endif\n\t}\n}\n\nstatic inline bool mmu_notifier_retry_cache(struct kvm *kvm, unsigned long mmu_seq)\n{\n\t \n\tif (kvm->mn_active_invalidate_count)\n\t\treturn true;\n\n\t \n\tsmp_rmb();\n\treturn kvm->mmu_invalidate_seq != mmu_seq;\n}\n\nstatic kvm_pfn_t hva_to_pfn_retry(struct gfn_to_pfn_cache *gpc)\n{\n\t \n\tvoid *old_khva = gpc->khva - offset_in_page(gpc->khva);\n\tkvm_pfn_t new_pfn = KVM_PFN_ERR_FAULT;\n\tvoid *new_khva = NULL;\n\tunsigned long mmu_seq;\n\n\tlockdep_assert_held(&gpc->refresh_lock);\n\n\tlockdep_assert_held_write(&gpc->lock);\n\n\t \n\tgpc->valid = false;\n\n\tdo {\n\t\tmmu_seq = gpc->kvm->mmu_invalidate_seq;\n\t\tsmp_rmb();\n\n\t\twrite_unlock_irq(&gpc->lock);\n\n\t\t \n\t\tif (new_pfn != KVM_PFN_ERR_FAULT) {\n\t\t\t \n\t\t\tif (new_khva != old_khva)\n\t\t\t\tgpc_unmap_khva(new_pfn, new_khva);\n\n\t\t\tkvm_release_pfn_clean(new_pfn);\n\n\t\t\tcond_resched();\n\t\t}\n\n\t\t \n\t\tnew_pfn = hva_to_pfn(gpc->uhva, false, false, NULL, true, NULL);\n\t\tif (is_error_noslot_pfn(new_pfn))\n\t\t\tgoto out_error;\n\n\t\t \n\t\tif (gpc->usage & KVM_HOST_USES_PFN) {\n\t\t\tif (new_pfn == gpc->pfn) {\n\t\t\t\tnew_khva = old_khva;\n\t\t\t} else if (pfn_valid(new_pfn)) {\n\t\t\t\tnew_khva = kmap(pfn_to_page(new_pfn));\n#ifdef CONFIG_HAS_IOMEM\n\t\t\t} else {\n\t\t\t\tnew_khva = memremap(pfn_to_hpa(new_pfn), PAGE_SIZE, MEMREMAP_WB);\n#endif\n\t\t\t}\n\t\t\tif (!new_khva) {\n\t\t\t\tkvm_release_pfn_clean(new_pfn);\n\t\t\t\tgoto out_error;\n\t\t\t}\n\t\t}\n\n\t\twrite_lock_irq(&gpc->lock);\n\n\t\t \n\t\tWARN_ON_ONCE(gpc->valid);\n\t} while (mmu_notifier_retry_cache(gpc->kvm, mmu_seq));\n\n\tgpc->valid = true;\n\tgpc->pfn = new_pfn;\n\tgpc->khva = new_khva + (gpc->gpa & ~PAGE_MASK);\n\n\t \n\tkvm_release_pfn_clean(new_pfn);\n\n\treturn 0;\n\nout_error:\n\twrite_lock_irq(&gpc->lock);\n\n\treturn -EFAULT;\n}\n\nstatic int __kvm_gpc_refresh(struct gfn_to_pfn_cache *gpc, gpa_t gpa,\n\t\t\t     unsigned long len)\n{\n\tstruct kvm_memslots *slots = kvm_memslots(gpc->kvm);\n\tunsigned long page_offset = gpa & ~PAGE_MASK;\n\tbool unmap_old = false;\n\tunsigned long old_uhva;\n\tkvm_pfn_t old_pfn;\n\tvoid *old_khva;\n\tint ret;\n\n\t \n\tif (page_offset + len > PAGE_SIZE)\n\t\treturn -EINVAL;\n\n\t \n\tmutex_lock(&gpc->refresh_lock);\n\n\twrite_lock_irq(&gpc->lock);\n\n\tif (!gpc->active) {\n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\told_pfn = gpc->pfn;\n\told_khva = gpc->khva - offset_in_page(gpc->khva);\n\told_uhva = gpc->uhva;\n\n\t \n\tif (gpc->gpa != gpa || gpc->generation != slots->generation ||\n\t    kvm_is_error_hva(gpc->uhva)) {\n\t\tgfn_t gfn = gpa_to_gfn(gpa);\n\n\t\tgpc->gpa = gpa;\n\t\tgpc->generation = slots->generation;\n\t\tgpc->memslot = __gfn_to_memslot(slots, gfn);\n\t\tgpc->uhva = gfn_to_hva_memslot(gpc->memslot, gfn);\n\n\t\tif (kvm_is_error_hva(gpc->uhva)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tif (!gpc->valid || old_uhva != gpc->uhva) {\n\t\tret = hva_to_pfn_retry(gpc);\n\t} else {\n\t\t \n\t\tgpc->khva = old_khva + page_offset;\n\t\tret = 0;\n\t\tgoto out_unlock;\n\t}\n\n out:\n\t \n\tif (ret) {\n\t\tgpc->valid = false;\n\t\tgpc->pfn = KVM_PFN_ERR_FAULT;\n\t\tgpc->khva = NULL;\n\t}\n\n\t \n\tunmap_old = (old_pfn != gpc->pfn);\n\nout_unlock:\n\twrite_unlock_irq(&gpc->lock);\n\n\tmutex_unlock(&gpc->refresh_lock);\n\n\tif (unmap_old)\n\t\tgpc_unmap_khva(old_pfn, old_khva);\n\n\treturn ret;\n}\n\nint kvm_gpc_refresh(struct gfn_to_pfn_cache *gpc, unsigned long len)\n{\n\treturn __kvm_gpc_refresh(gpc, gpc->gpa, len);\n}\nEXPORT_SYMBOL_GPL(kvm_gpc_refresh);\n\nvoid kvm_gpc_init(struct gfn_to_pfn_cache *gpc, struct kvm *kvm,\n\t\t  struct kvm_vcpu *vcpu, enum pfn_cache_usage usage)\n{\n\tWARN_ON_ONCE(!usage || (usage & KVM_GUEST_AND_HOST_USE_PFN) != usage);\n\tWARN_ON_ONCE((usage & KVM_GUEST_USES_PFN) && !vcpu);\n\n\trwlock_init(&gpc->lock);\n\tmutex_init(&gpc->refresh_lock);\n\n\tgpc->kvm = kvm;\n\tgpc->vcpu = vcpu;\n\tgpc->usage = usage;\n\tgpc->pfn = KVM_PFN_ERR_FAULT;\n\tgpc->uhva = KVM_HVA_ERR_BAD;\n}\nEXPORT_SYMBOL_GPL(kvm_gpc_init);\n\nint kvm_gpc_activate(struct gfn_to_pfn_cache *gpc, gpa_t gpa, unsigned long len)\n{\n\tstruct kvm *kvm = gpc->kvm;\n\n\tif (!gpc->active) {\n\t\tif (KVM_BUG_ON(gpc->valid, kvm))\n\t\t\treturn -EIO;\n\n\t\tspin_lock(&kvm->gpc_lock);\n\t\tlist_add(&gpc->list, &kvm->gpc_list);\n\t\tspin_unlock(&kvm->gpc_lock);\n\n\t\t \n\t\twrite_lock_irq(&gpc->lock);\n\t\tgpc->active = true;\n\t\twrite_unlock_irq(&gpc->lock);\n\t}\n\treturn __kvm_gpc_refresh(gpc, gpa, len);\n}\nEXPORT_SYMBOL_GPL(kvm_gpc_activate);\n\nvoid kvm_gpc_deactivate(struct gfn_to_pfn_cache *gpc)\n{\n\tstruct kvm *kvm = gpc->kvm;\n\tkvm_pfn_t old_pfn;\n\tvoid *old_khva;\n\n\tif (gpc->active) {\n\t\t \n\t\twrite_lock_irq(&gpc->lock);\n\t\tgpc->active = false;\n\t\tgpc->valid = false;\n\n\t\t \n\t\told_khva = gpc->khva - offset_in_page(gpc->khva);\n\t\tgpc->khva = NULL;\n\n\t\told_pfn = gpc->pfn;\n\t\tgpc->pfn = KVM_PFN_ERR_FAULT;\n\t\twrite_unlock_irq(&gpc->lock);\n\n\t\tspin_lock(&kvm->gpc_lock);\n\t\tlist_del(&gpc->list);\n\t\tspin_unlock(&kvm->gpc_lock);\n\n\t\tgpc_unmap_khva(old_pfn, old_khva);\n\t}\n}\nEXPORT_SYMBOL_GPL(kvm_gpc_deactivate);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}