{
  "module_name": "dirty_ring.c",
  "hash_id": "3009a173e56b2427a7af02155c67366396d619847b3aef18d911dc357c72c78f",
  "original_prompt": "Ingested from linux-6.6.14/virt/kvm/dirty_ring.c",
  "human_readable_source": "\n \n#include <linux/kvm_host.h>\n#include <linux/kvm.h>\n#include <linux/vmalloc.h>\n#include <linux/kvm_dirty_ring.h>\n#include <trace/events/kvm.h>\n#include \"kvm_mm.h\"\n\nint __weak kvm_cpu_dirty_log_size(void)\n{\n\treturn 0;\n}\n\nu32 kvm_dirty_ring_get_rsvd_entries(void)\n{\n\treturn KVM_DIRTY_RING_RSVD_ENTRIES + kvm_cpu_dirty_log_size();\n}\n\nbool kvm_use_dirty_bitmap(struct kvm *kvm)\n{\n\tlockdep_assert_held(&kvm->slots_lock);\n\n\treturn !kvm->dirty_ring_size || kvm->dirty_ring_with_bitmap;\n}\n\n#ifndef CONFIG_NEED_KVM_DIRTY_RING_WITH_BITMAP\nbool kvm_arch_allow_write_without_running_vcpu(struct kvm *kvm)\n{\n\treturn false;\n}\n#endif\n\nstatic u32 kvm_dirty_ring_used(struct kvm_dirty_ring *ring)\n{\n\treturn READ_ONCE(ring->dirty_index) - READ_ONCE(ring->reset_index);\n}\n\nstatic bool kvm_dirty_ring_soft_full(struct kvm_dirty_ring *ring)\n{\n\treturn kvm_dirty_ring_used(ring) >= ring->soft_limit;\n}\n\nstatic bool kvm_dirty_ring_full(struct kvm_dirty_ring *ring)\n{\n\treturn kvm_dirty_ring_used(ring) >= ring->size;\n}\n\nstatic void kvm_reset_dirty_gfn(struct kvm *kvm, u32 slot, u64 offset, u64 mask)\n{\n\tstruct kvm_memory_slot *memslot;\n\tint as_id, id;\n\n\tas_id = slot >> 16;\n\tid = (u16)slot;\n\n\tif (as_id >= KVM_ADDRESS_SPACE_NUM || id >= KVM_USER_MEM_SLOTS)\n\t\treturn;\n\n\tmemslot = id_to_memslot(__kvm_memslots(kvm, as_id), id);\n\n\tif (!memslot || (offset + __fls(mask)) >= memslot->npages)\n\t\treturn;\n\n\tKVM_MMU_LOCK(kvm);\n\tkvm_arch_mmu_enable_log_dirty_pt_masked(kvm, memslot, offset, mask);\n\tKVM_MMU_UNLOCK(kvm);\n}\n\nint kvm_dirty_ring_alloc(struct kvm_dirty_ring *ring, int index, u32 size)\n{\n\tring->dirty_gfns = vzalloc(size);\n\tif (!ring->dirty_gfns)\n\t\treturn -ENOMEM;\n\n\tring->size = size / sizeof(struct kvm_dirty_gfn);\n\tring->soft_limit = ring->size - kvm_dirty_ring_get_rsvd_entries();\n\tring->dirty_index = 0;\n\tring->reset_index = 0;\n\tring->index = index;\n\n\treturn 0;\n}\n\nstatic inline void kvm_dirty_gfn_set_invalid(struct kvm_dirty_gfn *gfn)\n{\n\tsmp_store_release(&gfn->flags, 0);\n}\n\nstatic inline void kvm_dirty_gfn_set_dirtied(struct kvm_dirty_gfn *gfn)\n{\n\tgfn->flags = KVM_DIRTY_GFN_F_DIRTY;\n}\n\nstatic inline bool kvm_dirty_gfn_harvested(struct kvm_dirty_gfn *gfn)\n{\n\treturn smp_load_acquire(&gfn->flags) & KVM_DIRTY_GFN_F_RESET;\n}\n\nint kvm_dirty_ring_reset(struct kvm *kvm, struct kvm_dirty_ring *ring)\n{\n\tu32 cur_slot, next_slot;\n\tu64 cur_offset, next_offset;\n\tunsigned long mask;\n\tint count = 0;\n\tstruct kvm_dirty_gfn *entry;\n\tbool first_round = true;\n\n\t \n\tcur_slot = cur_offset = mask = 0;\n\n\twhile (true) {\n\t\tentry = &ring->dirty_gfns[ring->reset_index & (ring->size - 1)];\n\n\t\tif (!kvm_dirty_gfn_harvested(entry))\n\t\t\tbreak;\n\n\t\tnext_slot = READ_ONCE(entry->slot);\n\t\tnext_offset = READ_ONCE(entry->offset);\n\n\t\t \n\t\tkvm_dirty_gfn_set_invalid(entry);\n\n\t\tring->reset_index++;\n\t\tcount++;\n\t\t \n\t\tif (!first_round && next_slot == cur_slot) {\n\t\t\ts64 delta = next_offset - cur_offset;\n\n\t\t\tif (delta >= 0 && delta < BITS_PER_LONG) {\n\t\t\t\tmask |= 1ull << delta;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (delta > -BITS_PER_LONG && delta < 0 &&\n\t\t\t    (mask << -delta >> -delta) == mask) {\n\t\t\t\tcur_offset = next_offset;\n\t\t\t\tmask = (mask << -delta) | 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tkvm_reset_dirty_gfn(kvm, cur_slot, cur_offset, mask);\n\t\tcur_slot = next_slot;\n\t\tcur_offset = next_offset;\n\t\tmask = 1;\n\t\tfirst_round = false;\n\t}\n\n\tkvm_reset_dirty_gfn(kvm, cur_slot, cur_offset, mask);\n\n\t \n\n\ttrace_kvm_dirty_ring_reset(ring);\n\n\treturn count;\n}\n\nvoid kvm_dirty_ring_push(struct kvm_vcpu *vcpu, u32 slot, u64 offset)\n{\n\tstruct kvm_dirty_ring *ring = &vcpu->dirty_ring;\n\tstruct kvm_dirty_gfn *entry;\n\n\t \n\tWARN_ON_ONCE(kvm_dirty_ring_full(ring));\n\n\tentry = &ring->dirty_gfns[ring->dirty_index & (ring->size - 1)];\n\n\tentry->slot = slot;\n\tentry->offset = offset;\n\t \n\tsmp_wmb();\n\tkvm_dirty_gfn_set_dirtied(entry);\n\tring->dirty_index++;\n\ttrace_kvm_dirty_ring_push(ring, slot, offset);\n\n\tif (kvm_dirty_ring_soft_full(ring))\n\t\tkvm_make_request(KVM_REQ_DIRTY_RING_SOFT_FULL, vcpu);\n}\n\nbool kvm_dirty_ring_check_request(struct kvm_vcpu *vcpu)\n{\n\t \n\tif (kvm_check_request(KVM_REQ_DIRTY_RING_SOFT_FULL, vcpu) &&\n\t    kvm_dirty_ring_soft_full(&vcpu->dirty_ring)) {\n\t\tkvm_make_request(KVM_REQ_DIRTY_RING_SOFT_FULL, vcpu);\n\t\tvcpu->run->exit_reason = KVM_EXIT_DIRTY_RING_FULL;\n\t\ttrace_kvm_dirty_ring_exit(vcpu);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstruct page *kvm_dirty_ring_get_page(struct kvm_dirty_ring *ring, u32 offset)\n{\n\treturn vmalloc_to_page((void *)ring->dirty_gfns + offset * PAGE_SIZE);\n}\n\nvoid kvm_dirty_ring_free(struct kvm_dirty_ring *ring)\n{\n\tvfree(ring->dirty_gfns);\n\tring->dirty_gfns = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}