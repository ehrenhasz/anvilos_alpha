{
  "module_name": "direct-io.c",
  "hash_id": "642ceea11cb954541557270304ca04654a23b90b9cafe7f8ca93283b62862b81",
  "original_prompt": "Ingested from linux-6.6.14/fs/direct-io.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/highmem.h>\n#include <linux/pagemap.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/bio.h>\n#include <linux/wait.h>\n#include <linux/err.h>\n#include <linux/blkdev.h>\n#include <linux/buffer_head.h>\n#include <linux/rwsem.h>\n#include <linux/uio.h>\n#include <linux/atomic.h>\n#include <linux/prefetch.h>\n\n#include \"internal.h\"\n\n \n#define DIO_PAGES\t64\n\n \n#define DIO_COMPLETE_ASYNC\t\t0x01\t \n#define DIO_COMPLETE_INVALIDATE\t\t0x02\t \n\n \n\n \n\nstruct dio_submit {\n\tstruct bio *bio;\t\t \n\tunsigned blkbits;\t\t \n\tunsigned blkfactor;\t\t \n\tunsigned start_zero_done;\t \n\tint pages_in_io;\t\t \n\tsector_t block_in_file;\t\t \n\tunsigned blocks_available;\t \n\tint reap_counter;\t\t \n\tsector_t final_block_in_request; \n\tint boundary;\t\t\t \n\tget_block_t *get_block;\t\t \n\n\tloff_t logical_offset_in_bio;\t \n\tsector_t final_block_in_bio;\t \n\tsector_t next_block_for_io;\t \n\n\t \n\tstruct page *cur_page;\t\t \n\tunsigned cur_page_offset;\t \n\tunsigned cur_page_len;\t\t \n\tsector_t cur_page_block;\t \n\tloff_t cur_page_fs_offset;\t \n\n\tstruct iov_iter *iter;\n\t \n\tunsigned head;\t\t\t \n\tunsigned tail;\t\t\t \n\tsize_t from, to;\n};\n\n \nstruct dio {\n\tint flags;\t\t\t \n\tblk_opf_t opf;\t\t\t \n\tstruct gendisk *bio_disk;\n\tstruct inode *inode;\n\tloff_t i_size;\t\t\t \n\tdio_iodone_t *end_io;\t\t \n\tbool is_pinned;\t\t\t \n\n\tvoid *private;\t\t\t \n\n\t \n\tspinlock_t bio_lock;\t\t \n\tint page_errors;\t\t \n\tint is_async;\t\t\t \n\tbool defer_completion;\t\t \n\tbool should_dirty;\t\t \n\tint io_error;\t\t\t \n\tunsigned long refcount;\t\t \n\tstruct bio *bio_list;\t\t \n\tstruct task_struct *waiter;\t \n\n\t \n\tstruct kiocb *iocb;\t\t \n\tssize_t result;                  \n\n\t \n\tunion {\n\t\tstruct page *pages[DIO_PAGES];\t \n\t\tstruct work_struct complete_work; \n\t};\n} ____cacheline_aligned_in_smp;\n\nstatic struct kmem_cache *dio_cache __read_mostly;\n\n \nstatic inline unsigned dio_pages_present(struct dio_submit *sdio)\n{\n\treturn sdio->tail - sdio->head;\n}\n\n \nstatic inline int dio_refill_pages(struct dio *dio, struct dio_submit *sdio)\n{\n\tstruct page **pages = dio->pages;\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tssize_t ret;\n\n\tret = iov_iter_extract_pages(sdio->iter, &pages, LONG_MAX,\n\t\t\t\t     DIO_PAGES, 0, &sdio->from);\n\n\tif (ret < 0 && sdio->blocks_available && dio_op == REQ_OP_WRITE) {\n\t\t \n\t\tif (dio->page_errors == 0)\n\t\t\tdio->page_errors = ret;\n\t\tdio->pages[0] = ZERO_PAGE(0);\n\t\tsdio->head = 0;\n\t\tsdio->tail = 1;\n\t\tsdio->from = 0;\n\t\tsdio->to = PAGE_SIZE;\n\t\treturn 0;\n\t}\n\n\tif (ret >= 0) {\n\t\tret += sdio->from;\n\t\tsdio->head = 0;\n\t\tsdio->tail = (ret + PAGE_SIZE - 1) / PAGE_SIZE;\n\t\tsdio->to = ((ret - 1) & (PAGE_SIZE - 1)) + 1;\n\t\treturn 0;\n\t}\n\treturn ret;\t\n}\n\n \nstatic inline struct page *dio_get_page(struct dio *dio,\n\t\t\t\t\tstruct dio_submit *sdio)\n{\n\tif (dio_pages_present(sdio) == 0) {\n\t\tint ret;\n\n\t\tret = dio_refill_pages(dio, sdio);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t\tBUG_ON(dio_pages_present(sdio) == 0);\n\t}\n\treturn dio->pages[sdio->head];\n}\n\nstatic void dio_pin_page(struct dio *dio, struct page *page)\n{\n\tif (dio->is_pinned)\n\t\tfolio_add_pin(page_folio(page));\n}\n\nstatic void dio_unpin_page(struct dio *dio, struct page *page)\n{\n\tif (dio->is_pinned)\n\t\tunpin_user_page(page);\n}\n\n \nstatic ssize_t dio_complete(struct dio *dio, ssize_t ret, unsigned int flags)\n{\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tloff_t offset = dio->iocb->ki_pos;\n\tssize_t transferred = 0;\n\tint err;\n\n\t \n\tif (ret == -EIOCBQUEUED)\n\t\tret = 0;\n\n\tif (dio->result) {\n\t\ttransferred = dio->result;\n\n\t\t \n\t\tif (dio_op == REQ_OP_READ &&\n\t\t    ((offset + transferred) > dio->i_size))\n\t\t\ttransferred = dio->i_size - offset;\n\t\t \n\t\tif (unlikely(ret == -EFAULT) && transferred)\n\t\t\tret = 0;\n\t}\n\n\tif (ret == 0)\n\t\tret = dio->page_errors;\n\tif (ret == 0)\n\t\tret = dio->io_error;\n\tif (ret == 0)\n\t\tret = transferred;\n\n\tif (dio->end_io) {\n\t\t \n\t\terr = dio->end_io(dio->iocb, offset, ret, dio->private);\n\t\tif (err)\n\t\t\tret = err;\n\t}\n\n\t \n\tif (flags & DIO_COMPLETE_INVALIDATE &&\n\t    ret > 0 && dio_op == REQ_OP_WRITE)\n\t\tkiocb_invalidate_post_direct_write(dio->iocb, ret);\n\n\tinode_dio_end(dio->inode);\n\n\tif (flags & DIO_COMPLETE_ASYNC) {\n\t\t \n\t\tdio->iocb->ki_pos += transferred;\n\n\t\tif (ret > 0 && dio_op == REQ_OP_WRITE)\n\t\t\tret = generic_write_sync(dio->iocb, ret);\n\t\tdio->iocb->ki_complete(dio->iocb, ret);\n\t}\n\n\tkmem_cache_free(dio_cache, dio);\n\treturn ret;\n}\n\nstatic void dio_aio_complete_work(struct work_struct *work)\n{\n\tstruct dio *dio = container_of(work, struct dio, complete_work);\n\n\tdio_complete(dio, 0, DIO_COMPLETE_ASYNC | DIO_COMPLETE_INVALIDATE);\n}\n\nstatic blk_status_t dio_bio_complete(struct dio *dio, struct bio *bio);\n\n \nstatic void dio_bio_end_aio(struct bio *bio)\n{\n\tstruct dio *dio = bio->bi_private;\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tunsigned long remaining;\n\tunsigned long flags;\n\tbool defer_completion = false;\n\n\t \n\tdio_bio_complete(dio, bio);\n\n\tspin_lock_irqsave(&dio->bio_lock, flags);\n\tremaining = --dio->refcount;\n\tif (remaining == 1 && dio->waiter)\n\t\twake_up_process(dio->waiter);\n\tspin_unlock_irqrestore(&dio->bio_lock, flags);\n\n\tif (remaining == 0) {\n\t\t \n\t\tif (dio->result)\n\t\t\tdefer_completion = dio->defer_completion ||\n\t\t\t\t\t   (dio_op == REQ_OP_WRITE &&\n\t\t\t\t\t    dio->inode->i_mapping->nrpages);\n\t\tif (defer_completion) {\n\t\t\tINIT_WORK(&dio->complete_work, dio_aio_complete_work);\n\t\t\tqueue_work(dio->inode->i_sb->s_dio_done_wq,\n\t\t\t\t   &dio->complete_work);\n\t\t} else {\n\t\t\tdio_complete(dio, 0, DIO_COMPLETE_ASYNC);\n\t\t}\n\t}\n}\n\n \nstatic void dio_bio_end_io(struct bio *bio)\n{\n\tstruct dio *dio = bio->bi_private;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dio->bio_lock, flags);\n\tbio->bi_private = dio->bio_list;\n\tdio->bio_list = bio;\n\tif (--dio->refcount == 1 && dio->waiter)\n\t\twake_up_process(dio->waiter);\n\tspin_unlock_irqrestore(&dio->bio_lock, flags);\n}\n\nstatic inline void\ndio_bio_alloc(struct dio *dio, struct dio_submit *sdio,\n\t      struct block_device *bdev,\n\t      sector_t first_sector, int nr_vecs)\n{\n\tstruct bio *bio;\n\n\t \n\tbio = bio_alloc(bdev, nr_vecs, dio->opf, GFP_KERNEL);\n\tbio->bi_iter.bi_sector = first_sector;\n\tif (dio->is_async)\n\t\tbio->bi_end_io = dio_bio_end_aio;\n\telse\n\t\tbio->bi_end_io = dio_bio_end_io;\n\tif (dio->is_pinned)\n\t\tbio_set_flag(bio, BIO_PAGE_PINNED);\n\tsdio->bio = bio;\n\tsdio->logical_offset_in_bio = sdio->cur_page_fs_offset;\n}\n\n \nstatic inline void dio_bio_submit(struct dio *dio, struct dio_submit *sdio)\n{\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tstruct bio *bio = sdio->bio;\n\tunsigned long flags;\n\n\tbio->bi_private = dio;\n\n\tspin_lock_irqsave(&dio->bio_lock, flags);\n\tdio->refcount++;\n\tspin_unlock_irqrestore(&dio->bio_lock, flags);\n\n\tif (dio->is_async && dio_op == REQ_OP_READ && dio->should_dirty)\n\t\tbio_set_pages_dirty(bio);\n\n\tdio->bio_disk = bio->bi_bdev->bd_disk;\n\n\tsubmit_bio(bio);\n\n\tsdio->bio = NULL;\n\tsdio->boundary = 0;\n\tsdio->logical_offset_in_bio = 0;\n}\n\n \nstatic inline void dio_cleanup(struct dio *dio, struct dio_submit *sdio)\n{\n\tif (dio->is_pinned)\n\t\tunpin_user_pages(dio->pages + sdio->head,\n\t\t\t\t sdio->tail - sdio->head);\n\tsdio->head = sdio->tail;\n}\n\n \nstatic struct bio *dio_await_one(struct dio *dio)\n{\n\tunsigned long flags;\n\tstruct bio *bio = NULL;\n\n\tspin_lock_irqsave(&dio->bio_lock, flags);\n\n\t \n\twhile (dio->refcount > 1 && dio->bio_list == NULL) {\n\t\t__set_current_state(TASK_UNINTERRUPTIBLE);\n\t\tdio->waiter = current;\n\t\tspin_unlock_irqrestore(&dio->bio_lock, flags);\n\t\tblk_io_schedule();\n\t\t \n\t\tspin_lock_irqsave(&dio->bio_lock, flags);\n\t\tdio->waiter = NULL;\n\t}\n\tif (dio->bio_list) {\n\t\tbio = dio->bio_list;\n\t\tdio->bio_list = bio->bi_private;\n\t}\n\tspin_unlock_irqrestore(&dio->bio_lock, flags);\n\treturn bio;\n}\n\n \nstatic blk_status_t dio_bio_complete(struct dio *dio, struct bio *bio)\n{\n\tblk_status_t err = bio->bi_status;\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tbool should_dirty = dio_op == REQ_OP_READ && dio->should_dirty;\n\n\tif (err) {\n\t\tif (err == BLK_STS_AGAIN && (bio->bi_opf & REQ_NOWAIT))\n\t\t\tdio->io_error = -EAGAIN;\n\t\telse\n\t\t\tdio->io_error = -EIO;\n\t}\n\n\tif (dio->is_async && should_dirty) {\n\t\tbio_check_pages_dirty(bio);\t \n\t} else {\n\t\tbio_release_pages(bio, should_dirty);\n\t\tbio_put(bio);\n\t}\n\treturn err;\n}\n\n \nstatic void dio_await_completion(struct dio *dio)\n{\n\tstruct bio *bio;\n\tdo {\n\t\tbio = dio_await_one(dio);\n\t\tif (bio)\n\t\t\tdio_bio_complete(dio, bio);\n\t} while (bio);\n}\n\n \nstatic inline int dio_bio_reap(struct dio *dio, struct dio_submit *sdio)\n{\n\tint ret = 0;\n\n\tif (sdio->reap_counter++ >= 64) {\n\t\twhile (dio->bio_list) {\n\t\t\tunsigned long flags;\n\t\t\tstruct bio *bio;\n\t\t\tint ret2;\n\n\t\t\tspin_lock_irqsave(&dio->bio_lock, flags);\n\t\t\tbio = dio->bio_list;\n\t\t\tdio->bio_list = bio->bi_private;\n\t\t\tspin_unlock_irqrestore(&dio->bio_lock, flags);\n\t\t\tret2 = blk_status_to_errno(dio_bio_complete(dio, bio));\n\t\t\tif (ret == 0)\n\t\t\t\tret = ret2;\n\t\t}\n\t\tsdio->reap_counter = 0;\n\t}\n\treturn ret;\n}\n\nstatic int dio_set_defer_completion(struct dio *dio)\n{\n\tstruct super_block *sb = dio->inode->i_sb;\n\n\tif (dio->defer_completion)\n\t\treturn 0;\n\tdio->defer_completion = true;\n\tif (!sb->s_dio_done_wq)\n\t\treturn sb_init_dio_done_wq(sb);\n\treturn 0;\n}\n\n \nstatic int get_more_blocks(struct dio *dio, struct dio_submit *sdio,\n\t\t\t   struct buffer_head *map_bh)\n{\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tint ret;\n\tsector_t fs_startblk;\t \n\tsector_t fs_endblk;\t \n\tunsigned long fs_count;\t \n\tint create;\n\tunsigned int i_blkbits = sdio->blkbits + sdio->blkfactor;\n\tloff_t i_size;\n\n\t \n\tret = dio->page_errors;\n\tif (ret == 0) {\n\t\tBUG_ON(sdio->block_in_file >= sdio->final_block_in_request);\n\t\tfs_startblk = sdio->block_in_file >> sdio->blkfactor;\n\t\tfs_endblk = (sdio->final_block_in_request - 1) >>\n\t\t\t\t\tsdio->blkfactor;\n\t\tfs_count = fs_endblk - fs_startblk + 1;\n\n\t\tmap_bh->b_state = 0;\n\t\tmap_bh->b_size = fs_count << i_blkbits;\n\n\t\t \n\t\tcreate = dio_op == REQ_OP_WRITE;\n\t\tif (dio->flags & DIO_SKIP_HOLES) {\n\t\t\ti_size = i_size_read(dio->inode);\n\t\t\tif (i_size && fs_startblk <= (i_size - 1) >> i_blkbits)\n\t\t\t\tcreate = 0;\n\t\t}\n\n\t\tret = (*sdio->get_block)(dio->inode, fs_startblk,\n\t\t\t\t\t\tmap_bh, create);\n\n\t\t \n\t\tdio->private = map_bh->b_private;\n\n\t\tif (ret == 0 && buffer_defer_completion(map_bh))\n\t\t\tret = dio_set_defer_completion(dio);\n\t}\n\treturn ret;\n}\n\n \nstatic inline int dio_new_bio(struct dio *dio, struct dio_submit *sdio,\n\t\tsector_t start_sector, struct buffer_head *map_bh)\n{\n\tsector_t sector;\n\tint ret, nr_pages;\n\n\tret = dio_bio_reap(dio, sdio);\n\tif (ret)\n\t\tgoto out;\n\tsector = start_sector << (sdio->blkbits - 9);\n\tnr_pages = bio_max_segs(sdio->pages_in_io);\n\tBUG_ON(nr_pages <= 0);\n\tdio_bio_alloc(dio, sdio, map_bh->b_bdev, sector, nr_pages);\n\tsdio->boundary = 0;\nout:\n\treturn ret;\n}\n\n \nstatic inline int dio_bio_add_page(struct dio *dio, struct dio_submit *sdio)\n{\n\tint ret;\n\n\tret = bio_add_page(sdio->bio, sdio->cur_page,\n\t\t\tsdio->cur_page_len, sdio->cur_page_offset);\n\tif (ret == sdio->cur_page_len) {\n\t\t \n\t\tif ((sdio->cur_page_len + sdio->cur_page_offset) == PAGE_SIZE)\n\t\t\tsdio->pages_in_io--;\n\t\tdio_pin_page(dio, sdio->cur_page);\n\t\tsdio->final_block_in_bio = sdio->cur_page_block +\n\t\t\t(sdio->cur_page_len >> sdio->blkbits);\n\t\tret = 0;\n\t} else {\n\t\tret = 1;\n\t}\n\treturn ret;\n}\n\t\t\n \nstatic inline int dio_send_cur_page(struct dio *dio, struct dio_submit *sdio,\n\t\tstruct buffer_head *map_bh)\n{\n\tint ret = 0;\n\n\tif (sdio->bio) {\n\t\tloff_t cur_offset = sdio->cur_page_fs_offset;\n\t\tloff_t bio_next_offset = sdio->logical_offset_in_bio +\n\t\t\tsdio->bio->bi_iter.bi_size;\n\n\t\t \n\t\tif (sdio->final_block_in_bio != sdio->cur_page_block ||\n\t\t    cur_offset != bio_next_offset)\n\t\t\tdio_bio_submit(dio, sdio);\n\t}\n\n\tif (sdio->bio == NULL) {\n\t\tret = dio_new_bio(dio, sdio, sdio->cur_page_block, map_bh);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tif (dio_bio_add_page(dio, sdio) != 0) {\n\t\tdio_bio_submit(dio, sdio);\n\t\tret = dio_new_bio(dio, sdio, sdio->cur_page_block, map_bh);\n\t\tif (ret == 0) {\n\t\t\tret = dio_bio_add_page(dio, sdio);\n\t\t\tBUG_ON(ret != 0);\n\t\t}\n\t}\nout:\n\treturn ret;\n}\n\n \nstatic inline int\nsubmit_page_section(struct dio *dio, struct dio_submit *sdio, struct page *page,\n\t\t    unsigned offset, unsigned len, sector_t blocknr,\n\t\t    struct buffer_head *map_bh)\n{\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tint ret = 0;\n\tint boundary = sdio->boundary;\t \n\n\tif (dio_op == REQ_OP_WRITE) {\n\t\t \n\t\ttask_io_account_write(len);\n\t}\n\n\t \n\tif (sdio->cur_page == page &&\n\t    sdio->cur_page_offset + sdio->cur_page_len == offset &&\n\t    sdio->cur_page_block +\n\t    (sdio->cur_page_len >> sdio->blkbits) == blocknr) {\n\t\tsdio->cur_page_len += len;\n\t\tgoto out;\n\t}\n\n\t \n\tif (sdio->cur_page) {\n\t\tret = dio_send_cur_page(dio, sdio, map_bh);\n\t\tdio_unpin_page(dio, sdio->cur_page);\n\t\tsdio->cur_page = NULL;\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tdio_pin_page(dio, page);\t\t \n\tsdio->cur_page = page;\n\tsdio->cur_page_offset = offset;\n\tsdio->cur_page_len = len;\n\tsdio->cur_page_block = blocknr;\n\tsdio->cur_page_fs_offset = sdio->block_in_file << sdio->blkbits;\nout:\n\t \n\tif (boundary) {\n\t\tret = dio_send_cur_page(dio, sdio, map_bh);\n\t\tif (sdio->bio)\n\t\t\tdio_bio_submit(dio, sdio);\n\t\tdio_unpin_page(dio, sdio->cur_page);\n\t\tsdio->cur_page = NULL;\n\t}\n\treturn ret;\n}\n\n \nstatic inline void dio_zero_block(struct dio *dio, struct dio_submit *sdio,\n\t\tint end, struct buffer_head *map_bh)\n{\n\tunsigned dio_blocks_per_fs_block;\n\tunsigned this_chunk_blocks;\t \n\tunsigned this_chunk_bytes;\n\tstruct page *page;\n\n\tsdio->start_zero_done = 1;\n\tif (!sdio->blkfactor || !buffer_new(map_bh))\n\t\treturn;\n\n\tdio_blocks_per_fs_block = 1 << sdio->blkfactor;\n\tthis_chunk_blocks = sdio->block_in_file & (dio_blocks_per_fs_block - 1);\n\n\tif (!this_chunk_blocks)\n\t\treturn;\n\n\t \n\tif (end) \n\t\tthis_chunk_blocks = dio_blocks_per_fs_block - this_chunk_blocks;\n\n\tthis_chunk_bytes = this_chunk_blocks << sdio->blkbits;\n\n\tpage = ZERO_PAGE(0);\n\tif (submit_page_section(dio, sdio, page, 0, this_chunk_bytes,\n\t\t\t\tsdio->next_block_for_io, map_bh))\n\t\treturn;\n\n\tsdio->next_block_for_io += this_chunk_blocks;\n}\n\n \nstatic int do_direct_IO(struct dio *dio, struct dio_submit *sdio,\n\t\t\tstruct buffer_head *map_bh)\n{\n\tconst enum req_op dio_op = dio->opf & REQ_OP_MASK;\n\tconst unsigned blkbits = sdio->blkbits;\n\tconst unsigned i_blkbits = blkbits + sdio->blkfactor;\n\tint ret = 0;\n\n\twhile (sdio->block_in_file < sdio->final_block_in_request) {\n\t\tstruct page *page;\n\t\tsize_t from, to;\n\n\t\tpage = dio_get_page(dio, sdio);\n\t\tif (IS_ERR(page)) {\n\t\t\tret = PTR_ERR(page);\n\t\t\tgoto out;\n\t\t}\n\t\tfrom = sdio->head ? 0 : sdio->from;\n\t\tto = (sdio->head == sdio->tail - 1) ? sdio->to : PAGE_SIZE;\n\t\tsdio->head++;\n\n\t\twhile (from < to) {\n\t\t\tunsigned this_chunk_bytes;\t \n\t\t\tunsigned this_chunk_blocks;\t \n\t\t\tunsigned u;\n\n\t\t\tif (sdio->blocks_available == 0) {\n\t\t\t\t \n\t\t\t\tunsigned long blkmask;\n\t\t\t\tunsigned long dio_remainder;\n\n\t\t\t\tret = get_more_blocks(dio, sdio, map_bh);\n\t\t\t\tif (ret) {\n\t\t\t\t\tdio_unpin_page(dio, page);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tif (!buffer_mapped(map_bh))\n\t\t\t\t\tgoto do_holes;\n\n\t\t\t\tsdio->blocks_available =\n\t\t\t\t\t\tmap_bh->b_size >> blkbits;\n\t\t\t\tsdio->next_block_for_io =\n\t\t\t\t\tmap_bh->b_blocknr << sdio->blkfactor;\n\t\t\t\tif (buffer_new(map_bh)) {\n\t\t\t\t\tclean_bdev_aliases(\n\t\t\t\t\t\tmap_bh->b_bdev,\n\t\t\t\t\t\tmap_bh->b_blocknr,\n\t\t\t\t\t\tmap_bh->b_size >> i_blkbits);\n\t\t\t\t}\n\n\t\t\t\tif (!sdio->blkfactor)\n\t\t\t\t\tgoto do_holes;\n\n\t\t\t\tblkmask = (1 << sdio->blkfactor) - 1;\n\t\t\t\tdio_remainder = (sdio->block_in_file & blkmask);\n\n\t\t\t\t \n\t\t\t\tif (!buffer_new(map_bh))\n\t\t\t\t\tsdio->next_block_for_io += dio_remainder;\n\t\t\t\tsdio->blocks_available -= dio_remainder;\n\t\t\t}\ndo_holes:\n\t\t\t \n\t\t\tif (!buffer_mapped(map_bh)) {\n\t\t\t\tloff_t i_size_aligned;\n\n\t\t\t\t \n\t\t\t\tif (dio_op == REQ_OP_WRITE) {\n\t\t\t\t\tdio_unpin_page(dio, page);\n\t\t\t\t\treturn -ENOTBLK;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\ti_size_aligned = ALIGN(i_size_read(dio->inode),\n\t\t\t\t\t\t\t1 << blkbits);\n\t\t\t\tif (sdio->block_in_file >=\n\t\t\t\t\t\ti_size_aligned >> blkbits) {\n\t\t\t\t\t \n\t\t\t\t\tdio_unpin_page(dio, page);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tzero_user(page, from, 1 << blkbits);\n\t\t\t\tsdio->block_in_file++;\n\t\t\t\tfrom += 1 << blkbits;\n\t\t\t\tdio->result += 1 << blkbits;\n\t\t\t\tgoto next_block;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (unlikely(sdio->blkfactor && !sdio->start_zero_done))\n\t\t\t\tdio_zero_block(dio, sdio, 0, map_bh);\n\n\t\t\t \n\t\t\tthis_chunk_blocks = sdio->blocks_available;\n\t\t\tu = (to - from) >> blkbits;\n\t\t\tif (this_chunk_blocks > u)\n\t\t\t\tthis_chunk_blocks = u;\n\t\t\tu = sdio->final_block_in_request - sdio->block_in_file;\n\t\t\tif (this_chunk_blocks > u)\n\t\t\t\tthis_chunk_blocks = u;\n\t\t\tthis_chunk_bytes = this_chunk_blocks << blkbits;\n\t\t\tBUG_ON(this_chunk_bytes == 0);\n\n\t\t\tif (this_chunk_blocks == sdio->blocks_available)\n\t\t\t\tsdio->boundary = buffer_boundary(map_bh);\n\t\t\tret = submit_page_section(dio, sdio, page,\n\t\t\t\t\t\t  from,\n\t\t\t\t\t\t  this_chunk_bytes,\n\t\t\t\t\t\t  sdio->next_block_for_io,\n\t\t\t\t\t\t  map_bh);\n\t\t\tif (ret) {\n\t\t\t\tdio_unpin_page(dio, page);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsdio->next_block_for_io += this_chunk_blocks;\n\n\t\t\tsdio->block_in_file += this_chunk_blocks;\n\t\t\tfrom += this_chunk_bytes;\n\t\t\tdio->result += this_chunk_bytes;\n\t\t\tsdio->blocks_available -= this_chunk_blocks;\nnext_block:\n\t\t\tBUG_ON(sdio->block_in_file > sdio->final_block_in_request);\n\t\t\tif (sdio->block_in_file == sdio->final_block_in_request)\n\t\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tdio_unpin_page(dio, page);\n\t}\nout:\n\treturn ret;\n}\n\nstatic inline int drop_refcount(struct dio *dio)\n{\n\tint ret2;\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&dio->bio_lock, flags);\n\tret2 = --dio->refcount;\n\tspin_unlock_irqrestore(&dio->bio_lock, flags);\n\treturn ret2;\n}\n\n \nssize_t __blockdev_direct_IO(struct kiocb *iocb, struct inode *inode,\n\t\tstruct block_device *bdev, struct iov_iter *iter,\n\t\tget_block_t get_block, dio_iodone_t end_io,\n\t\tint flags)\n{\n\tunsigned i_blkbits = READ_ONCE(inode->i_blkbits);\n\tunsigned blkbits = i_blkbits;\n\tunsigned blocksize_mask = (1 << blkbits) - 1;\n\tssize_t retval = -EINVAL;\n\tconst size_t count = iov_iter_count(iter);\n\tloff_t offset = iocb->ki_pos;\n\tconst loff_t end = offset + count;\n\tstruct dio *dio;\n\tstruct dio_submit sdio = { 0, };\n\tstruct buffer_head map_bh = { 0, };\n\tstruct blk_plug plug;\n\tunsigned long align = offset | iov_iter_alignment(iter);\n\n\t \n\n\t \n\tif (iov_iter_rw(iter) == READ && !count)\n\t\treturn 0;\n\n\tdio = kmem_cache_alloc(dio_cache, GFP_KERNEL);\n\tif (!dio)\n\t\treturn -ENOMEM;\n\t \n\tmemset(dio, 0, offsetof(struct dio, pages));\n\n\tdio->flags = flags;\n\tif (dio->flags & DIO_LOCKING && iov_iter_rw(iter) == READ) {\n\t\t \n\t\tinode_lock(inode);\n\t}\n\tdio->is_pinned = iov_iter_extract_will_pin(iter);\n\n\t \n\tdio->i_size = i_size_read(inode);\n\tif (iov_iter_rw(iter) == READ && offset >= dio->i_size) {\n\t\tretval = 0;\n\t\tgoto fail_dio;\n\t}\n\n\tif (align & blocksize_mask) {\n\t\tif (bdev)\n\t\t\tblkbits = blksize_bits(bdev_logical_block_size(bdev));\n\t\tblocksize_mask = (1 << blkbits) - 1;\n\t\tif (align & blocksize_mask)\n\t\t\tgoto fail_dio;\n\t}\n\n\tif (dio->flags & DIO_LOCKING && iov_iter_rw(iter) == READ) {\n\t\tstruct address_space *mapping = iocb->ki_filp->f_mapping;\n\n\t\tretval = filemap_write_and_wait_range(mapping, offset, end - 1);\n\t\tif (retval)\n\t\t\tgoto fail_dio;\n\t}\n\n\t \n\tif (is_sync_kiocb(iocb))\n\t\tdio->is_async = false;\n\telse if (iov_iter_rw(iter) == WRITE && end > i_size_read(inode))\n\t\tdio->is_async = false;\n\telse\n\t\tdio->is_async = true;\n\n\tdio->inode = inode;\n\tif (iov_iter_rw(iter) == WRITE) {\n\t\tdio->opf = REQ_OP_WRITE | REQ_SYNC | REQ_IDLE;\n\t\tif (iocb->ki_flags & IOCB_NOWAIT)\n\t\t\tdio->opf |= REQ_NOWAIT;\n\t} else {\n\t\tdio->opf = REQ_OP_READ;\n\t}\n\n\t \n\tif (dio->is_async && iov_iter_rw(iter) == WRITE) {\n\t\tretval = 0;\n\t\tif (iocb_is_dsync(iocb))\n\t\t\tretval = dio_set_defer_completion(dio);\n\t\telse if (!dio->inode->i_sb->s_dio_done_wq) {\n\t\t\t \n\t\t\tretval = sb_init_dio_done_wq(dio->inode->i_sb);\n\t\t}\n\t\tif (retval)\n\t\t\tgoto fail_dio;\n\t}\n\n\t \n\tinode_dio_begin(inode);\n\n\tretval = 0;\n\tsdio.blkbits = blkbits;\n\tsdio.blkfactor = i_blkbits - blkbits;\n\tsdio.block_in_file = offset >> blkbits;\n\n\tsdio.get_block = get_block;\n\tdio->end_io = end_io;\n\tsdio.final_block_in_bio = -1;\n\tsdio.next_block_for_io = -1;\n\n\tdio->iocb = iocb;\n\n\tspin_lock_init(&dio->bio_lock);\n\tdio->refcount = 1;\n\n\tdio->should_dirty = user_backed_iter(iter) && iov_iter_rw(iter) == READ;\n\tsdio.iter = iter;\n\tsdio.final_block_in_request = end >> blkbits;\n\n\t \n\tif (unlikely(sdio.blkfactor))\n\t\tsdio.pages_in_io = 2;\n\n\tsdio.pages_in_io += iov_iter_npages(iter, INT_MAX);\n\n\tblk_start_plug(&plug);\n\n\tretval = do_direct_IO(dio, &sdio, &map_bh);\n\tif (retval)\n\t\tdio_cleanup(dio, &sdio);\n\n\tif (retval == -ENOTBLK) {\n\t\t \n\t\tretval = 0;\n\t}\n\t \n\tdio_zero_block(dio, &sdio, 1, &map_bh);\n\n\tif (sdio.cur_page) {\n\t\tssize_t ret2;\n\n\t\tret2 = dio_send_cur_page(dio, &sdio, &map_bh);\n\t\tif (retval == 0)\n\t\t\tretval = ret2;\n\t\tdio_unpin_page(dio, sdio.cur_page);\n\t\tsdio.cur_page = NULL;\n\t}\n\tif (sdio.bio)\n\t\tdio_bio_submit(dio, &sdio);\n\n\tblk_finish_plug(&plug);\n\n\t \n\tdio_cleanup(dio, &sdio);\n\n\t \n\tif (iov_iter_rw(iter) == READ && (dio->flags & DIO_LOCKING))\n\t\tinode_unlock(dio->inode);\n\n\t \n\tBUG_ON(retval == -EIOCBQUEUED);\n\tif (dio->is_async && retval == 0 && dio->result &&\n\t    (iov_iter_rw(iter) == READ || dio->result == count))\n\t\tretval = -EIOCBQUEUED;\n\telse\n\t\tdio_await_completion(dio);\n\n\tif (drop_refcount(dio) == 0) {\n\t\tretval = dio_complete(dio, retval, DIO_COMPLETE_INVALIDATE);\n\t} else\n\t\tBUG_ON(retval != -EIOCBQUEUED);\n\n\treturn retval;\n\nfail_dio:\n\tif (dio->flags & DIO_LOCKING && iov_iter_rw(iter) == READ)\n\t\tinode_unlock(inode);\n\n\tkmem_cache_free(dio_cache, dio);\n\treturn retval;\n}\nEXPORT_SYMBOL(__blockdev_direct_IO);\n\nstatic __init int dio_init(void)\n{\n\tdio_cache = KMEM_CACHE(dio, SLAB_PANIC);\n\treturn 0;\n}\nmodule_init(dio_init)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}