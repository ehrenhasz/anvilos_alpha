{
  "module_name": "record.c",
  "hash_id": "8b8d3b6cfdc670cb89f3dcdf2cece176f4b41cf3155e05de238f76e95bca1af9",
  "original_prompt": "Ingested from linux-6.6.14/fs/ntfs3/record.c",
  "human_readable_source": "\n \n\n#include <linux/fs.h>\n\n#include \"debug.h\"\n#include \"ntfs.h\"\n#include \"ntfs_fs.h\"\n\nstatic inline int compare_attr(const struct ATTRIB *left, enum ATTR_TYPE type,\n\t\t\t       const __le16 *name, u8 name_len,\n\t\t\t       const u16 *upcase)\n{\n\t \n\tint diff = le32_to_cpu(left->type) - le32_to_cpu(type);\n\n\tif (diff)\n\t\treturn diff;\n\n\t \n\treturn ntfs_cmp_names(attr_name(left), left->name_len, name, name_len,\n\t\t\t      upcase, true);\n}\n\n \nstatic __le16 mi_new_attt_id(struct mft_inode *mi)\n{\n\tu16 free_id, max_id, t16;\n\tstruct MFT_REC *rec = mi->mrec;\n\tstruct ATTRIB *attr;\n\t__le16 id;\n\n\tid = rec->next_attr_id;\n\tfree_id = le16_to_cpu(id);\n\tif (free_id < 0x7FFF) {\n\t\trec->next_attr_id = cpu_to_le16(free_id + 1);\n\t\treturn id;\n\t}\n\n\t \n\tfree_id = 0;\n\tmax_id = 0;\n\n\tattr = NULL;\n\n\tfor (;;) {\n\t\tattr = mi_enum_attr(mi, attr);\n\t\tif (!attr) {\n\t\t\trec->next_attr_id = cpu_to_le16(max_id + 1);\n\t\t\tmi->dirty = true;\n\t\t\treturn cpu_to_le16(free_id);\n\t\t}\n\n\t\tt16 = le16_to_cpu(attr->id);\n\t\tif (t16 == free_id) {\n\t\t\tfree_id += 1;\n\t\t\tattr = NULL;\n\t\t} else if (max_id < t16)\n\t\t\tmax_id = t16;\n\t}\n}\n\nint mi_get(struct ntfs_sb_info *sbi, CLST rno, struct mft_inode **mi)\n{\n\tint err;\n\tstruct mft_inode *m = kzalloc(sizeof(struct mft_inode), GFP_NOFS);\n\n\tif (!m)\n\t\treturn -ENOMEM;\n\n\terr = mi_init(m, sbi, rno);\n\tif (err) {\n\t\tkfree(m);\n\t\treturn err;\n\t}\n\n\terr = mi_read(m, false);\n\tif (err) {\n\t\tmi_put(m);\n\t\treturn err;\n\t}\n\n\t*mi = m;\n\treturn 0;\n}\n\nvoid mi_put(struct mft_inode *mi)\n{\n\tmi_clear(mi);\n\tkfree(mi);\n}\n\nint mi_init(struct mft_inode *mi, struct ntfs_sb_info *sbi, CLST rno)\n{\n\tmi->sbi = sbi;\n\tmi->rno = rno;\n\tmi->mrec = kmalloc(sbi->record_size, GFP_NOFS);\n\tif (!mi->mrec)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n \nint mi_read(struct mft_inode *mi, bool is_mft)\n{\n\tint err;\n\tstruct MFT_REC *rec = mi->mrec;\n\tstruct ntfs_sb_info *sbi = mi->sbi;\n\tu32 bpr = sbi->record_size;\n\tu64 vbo = (u64)mi->rno << sbi->record_bits;\n\tstruct ntfs_inode *mft_ni = sbi->mft.ni;\n\tstruct runs_tree *run = mft_ni ? &mft_ni->file.run : NULL;\n\tstruct rw_semaphore *rw_lock = NULL;\n\n\tif (is_mounted(sbi)) {\n\t\tif (!is_mft && mft_ni) {\n\t\t\trw_lock = &mft_ni->file.run_lock;\n\t\t\tdown_read(rw_lock);\n\t\t}\n\t}\n\n\terr = ntfs_read_bh(sbi, run, vbo, &rec->rhdr, bpr, &mi->nb);\n\tif (rw_lock)\n\t\tup_read(rw_lock);\n\tif (!err)\n\t\tgoto ok;\n\n\tif (err == -E_NTFS_FIXUP) {\n\t\tmi->dirty = true;\n\t\tgoto ok;\n\t}\n\n\tif (err != -ENOENT)\n\t\tgoto out;\n\n\tif (rw_lock) {\n\t\tni_lock(mft_ni);\n\t\tdown_write(rw_lock);\n\t}\n\terr = attr_load_runs_vcn(mft_ni, ATTR_DATA, NULL, 0, run,\n\t\t\t\t vbo >> sbi->cluster_bits);\n\tif (rw_lock) {\n\t\tup_write(rw_lock);\n\t\tni_unlock(mft_ni);\n\t}\n\tif (err)\n\t\tgoto out;\n\n\tif (rw_lock)\n\t\tdown_read(rw_lock);\n\terr = ntfs_read_bh(sbi, run, vbo, &rec->rhdr, bpr, &mi->nb);\n\tif (rw_lock)\n\t\tup_read(rw_lock);\n\n\tif (err == -E_NTFS_FIXUP) {\n\t\tmi->dirty = true;\n\t\tgoto ok;\n\t}\n\tif (err)\n\t\tgoto out;\n\nok:\n\t \n\tif (le32_to_cpu(rec->total) != bpr) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\treturn 0;\n\nout:\n\tif (err == -E_NTFS_CORRUPT) {\n\t\tntfs_err(sbi->sb, \"mft corrupted\");\n\t\tntfs_set_state(sbi, NTFS_DIRTY_ERROR);\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}\n\n \nstruct ATTRIB *mi_enum_attr(struct mft_inode *mi, struct ATTRIB *attr)\n{\n\tconst struct MFT_REC *rec = mi->mrec;\n\tu32 used = le32_to_cpu(rec->used);\n\tu32 t32, off, asize, prev_type;\n\tu16 t16;\n\tu64 data_size, alloc_size, tot_size;\n\n\tif (!attr) {\n\t\tu32 total = le32_to_cpu(rec->total);\n\n\t\toff = le16_to_cpu(rec->attr_off);\n\n\t\tif (used > total)\n\t\t\treturn NULL;\n\n\t\tif (off >= used || off < MFTRECORD_FIXUP_OFFSET_1 ||\n\t\t    !IS_ALIGNED(off, 4)) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\t \n\t\tif (!is_rec_inuse(rec))\n\t\t\treturn NULL;\n\n\t\tprev_type = 0;\n\t\tattr = Add2Ptr(rec, off);\n\t} else {\n\t\t \n\t\toff = PtrOffset(rec, attr);\n\t\tif (off >= used)\n\t\t\treturn NULL;\n\n\t\tasize = le32_to_cpu(attr->size);\n\t\tif (asize < SIZEOF_RESIDENT) {\n\t\t\t \n\t\t\treturn NULL;\n\t\t}\n\n\t\t \n\t\tif (off + asize < off)\n\t\t\treturn NULL;\n\n\t\tprev_type = le32_to_cpu(attr->type);\n\t\tattr = Add2Ptr(attr, asize);\n\t\toff += asize;\n\t}\n\n\tasize = le32_to_cpu(attr->size);\n\n\t \n\tif (off + 8 > used) {\n\t\tstatic_assert(ALIGN(sizeof(enum ATTR_TYPE), 8) == 8);\n\t\treturn NULL;\n\t}\n\n\tif (attr->type == ATTR_END) {\n\t\t \n\t\treturn NULL;\n\t}\n\n\t \n\tt32 = le32_to_cpu(attr->type);\n\tif (!t32 || (t32 & 0xf) || (t32 > 0x100))\n\t\treturn NULL;\n\n\t \n\tif (t32 < prev_type)\n\t\treturn NULL;\n\n\t \n\tif (off + asize < off || off + asize > used)\n\t\treturn NULL;\n\n\t \n\tif (!attr->non_res) {\n\t\t \n\t\tif (asize < SIZEOF_RESIDENT)\n\t\t\treturn NULL;\n\n\t\tt16 = le16_to_cpu(attr->res.data_off);\n\t\tif (t16 > asize)\n\t\t\treturn NULL;\n\n\t\tif (t16 + le32_to_cpu(attr->res.data_size) > asize)\n\t\t\treturn NULL;\n\n\t\tt32 = sizeof(short) * attr->name_len;\n\t\tif (t32 && le16_to_cpu(attr->name_off) + t32 > t16)\n\t\t\treturn NULL;\n\n\t\treturn attr;\n\t}\n\n\t \n\tif (attr->non_res != 1)\n\t\treturn NULL;\n\n\tt16 = le16_to_cpu(attr->nres.run_off);\n\tif (t16 > asize)\n\t\treturn NULL;\n\n\tt32 = sizeof(short) * attr->name_len;\n\tif (t32 && le16_to_cpu(attr->name_off) + t32 > t16)\n\t\treturn NULL;\n\n\t \n\tif (le64_to_cpu(attr->nres.svcn) > le64_to_cpu(attr->nres.evcn) + 1)\n\t\treturn NULL;\n\n\tdata_size = le64_to_cpu(attr->nres.data_size);\n\tif (le64_to_cpu(attr->nres.valid_size) > data_size)\n\t\treturn NULL;\n\n\talloc_size = le64_to_cpu(attr->nres.alloc_size);\n\tif (data_size > alloc_size)\n\t\treturn NULL;\n\n\tt32 = mi->sbi->cluster_mask;\n\tif (alloc_size & t32)\n\t\treturn NULL;\n\n\tif (!attr->nres.svcn && is_attr_ext(attr)) {\n\t\t \n\t\tif (asize + 8 < SIZEOF_NONRESIDENT_EX)\n\t\t\treturn NULL;\n\n\t\ttot_size = le64_to_cpu(attr->nres.total_size);\n\t\tif (tot_size & t32)\n\t\t\treturn NULL;\n\n\t\tif (tot_size > alloc_size)\n\t\t\treturn NULL;\n\t} else {\n\t\tif (asize + 8 < SIZEOF_NONRESIDENT)\n\t\t\treturn NULL;\n\n\t\tif (attr->nres.c_unit)\n\t\t\treturn NULL;\n\t}\n\n\treturn attr;\n}\n\n \nstruct ATTRIB *mi_find_attr(struct mft_inode *mi, struct ATTRIB *attr,\n\t\t\t    enum ATTR_TYPE type, const __le16 *name,\n\t\t\t    u8 name_len, const __le16 *id)\n{\n\tu32 type_in = le32_to_cpu(type);\n\tu32 atype;\n\nnext_attr:\n\tattr = mi_enum_attr(mi, attr);\n\tif (!attr)\n\t\treturn NULL;\n\n\tatype = le32_to_cpu(attr->type);\n\tif (atype > type_in)\n\t\treturn NULL;\n\n\tif (atype < type_in)\n\t\tgoto next_attr;\n\n\tif (attr->name_len != name_len)\n\t\tgoto next_attr;\n\n\tif (name_len && memcmp(attr_name(attr), name, name_len * sizeof(short)))\n\t\tgoto next_attr;\n\n\tif (id && *id != attr->id)\n\t\tgoto next_attr;\n\n\treturn attr;\n}\n\nint mi_write(struct mft_inode *mi, int wait)\n{\n\tstruct MFT_REC *rec;\n\tint err;\n\tstruct ntfs_sb_info *sbi;\n\n\tif (!mi->dirty)\n\t\treturn 0;\n\n\tsbi = mi->sbi;\n\trec = mi->mrec;\n\n\terr = ntfs_write_bh(sbi, &rec->rhdr, &mi->nb, wait);\n\tif (err)\n\t\treturn err;\n\n\tif (mi->rno < sbi->mft.recs_mirr)\n\t\tsbi->flags |= NTFS_FLAGS_MFTMIRR;\n\n\tmi->dirty = false;\n\n\treturn 0;\n}\n\nint mi_format_new(struct mft_inode *mi, struct ntfs_sb_info *sbi, CLST rno,\n\t\t  __le16 flags, bool is_mft)\n{\n\tint err;\n\tu16 seq = 1;\n\tstruct MFT_REC *rec;\n\tu64 vbo = (u64)rno << sbi->record_bits;\n\n\terr = mi_init(mi, sbi, rno);\n\tif (err)\n\t\treturn err;\n\n\trec = mi->mrec;\n\n\tif (rno == MFT_REC_MFT) {\n\t\t;\n\t} else if (rno < MFT_REC_FREE) {\n\t\tseq = rno;\n\t} else if (rno >= sbi->mft.used) {\n\t\t;\n\t} else if (mi_read(mi, is_mft)) {\n\t\t;\n\t} else if (rec->rhdr.sign == NTFS_FILE_SIGNATURE) {\n\t\t \n\t\tseq = le16_to_cpu(rec->seq) + 1;\n\t\tif (!seq)\n\t\t\tseq = 1;\n\t}\n\n\tmemcpy(rec, sbi->new_rec, sbi->record_size);\n\n\trec->seq = cpu_to_le16(seq);\n\trec->flags = RECORD_FLAG_IN_USE | flags;\n\tif (MFTRECORD_FIXUP_OFFSET == MFTRECORD_FIXUP_OFFSET_3)\n\t\trec->mft_record = cpu_to_le32(rno);\n\n\tmi->dirty = true;\n\n\tif (!mi->nb.nbufs) {\n\t\tstruct ntfs_inode *ni = sbi->mft.ni;\n\t\tbool lock = false;\n\n\t\tif (is_mounted(sbi) && !is_mft) {\n\t\t\tdown_read(&ni->file.run_lock);\n\t\t\tlock = true;\n\t\t}\n\n\t\terr = ntfs_get_bh(sbi, &ni->file.run, vbo, sbi->record_size,\n\t\t\t\t  &mi->nb);\n\t\tif (lock)\n\t\t\tup_read(&ni->file.run_lock);\n\t}\n\n\treturn err;\n}\n\n \nstruct ATTRIB *mi_insert_attr(struct mft_inode *mi, enum ATTR_TYPE type,\n\t\t\t      const __le16 *name, u8 name_len, u32 asize,\n\t\t\t      u16 name_off)\n{\n\tsize_t tail;\n\tstruct ATTRIB *attr;\n\t__le16 id;\n\tstruct MFT_REC *rec = mi->mrec;\n\tstruct ntfs_sb_info *sbi = mi->sbi;\n\tu32 used = le32_to_cpu(rec->used);\n\tconst u16 *upcase = sbi->upcase;\n\n\t \n\tif (used + asize > sbi->record_size)\n\t\treturn NULL;\n\n\t \n\tattr = NULL;\n\twhile ((attr = mi_enum_attr(mi, attr))) {\n\t\tint diff = compare_attr(attr, type, name, name_len, upcase);\n\n\t\tif (diff < 0)\n\t\t\tcontinue;\n\n\t\tif (!diff && !is_attr_indexed(attr))\n\t\t\treturn NULL;\n\t\tbreak;\n\t}\n\n\tif (!attr) {\n\t\t \n\t\ttail = 8;\n\t\tattr = Add2Ptr(rec, used - 8);\n\t} else {\n\t\t \n\t\ttail = used - PtrOffset(rec, attr);\n\t}\n\n\tid = mi_new_attt_id(mi);\n\n\tmemmove(Add2Ptr(attr, asize), attr, tail);\n\tmemset(attr, 0, asize);\n\n\tattr->type = type;\n\tattr->size = cpu_to_le32(asize);\n\tattr->name_len = name_len;\n\tattr->name_off = cpu_to_le16(name_off);\n\tattr->id = id;\n\n\tmemmove(Add2Ptr(attr, name_off), name, name_len * sizeof(short));\n\trec->used = cpu_to_le32(used + asize);\n\n\tmi->dirty = true;\n\n\treturn attr;\n}\n\n \nbool mi_remove_attr(struct ntfs_inode *ni, struct mft_inode *mi,\n\t\t    struct ATTRIB *attr)\n{\n\tstruct MFT_REC *rec = mi->mrec;\n\tu32 aoff = PtrOffset(rec, attr);\n\tu32 used = le32_to_cpu(rec->used);\n\tu32 asize = le32_to_cpu(attr->size);\n\n\tif (aoff + asize > used)\n\t\treturn false;\n\n\tif (ni && is_attr_indexed(attr)) {\n\t\tle16_add_cpu(&ni->mi.mrec->hard_links, -1);\n\t\tni->mi.dirty = true;\n\t}\n\n\tused -= asize;\n\tmemmove(attr, Add2Ptr(attr, asize), used - aoff);\n\trec->used = cpu_to_le32(used);\n\tmi->dirty = true;\n\n\treturn true;\n}\n\n \nbool mi_resize_attr(struct mft_inode *mi, struct ATTRIB *attr, int bytes)\n{\n\tstruct MFT_REC *rec = mi->mrec;\n\tu32 aoff = PtrOffset(rec, attr);\n\tu32 total, used = le32_to_cpu(rec->used);\n\tu32 nsize, asize = le32_to_cpu(attr->size);\n\tu32 rsize = le32_to_cpu(attr->res.data_size);\n\tint tail = (int)(used - aoff - asize);\n\tint dsize;\n\tchar *next;\n\n\tif (tail < 0 || aoff >= used)\n\t\treturn false;\n\n\tif (!bytes)\n\t\treturn true;\n\n\ttotal = le32_to_cpu(rec->total);\n\tnext = Add2Ptr(attr, asize);\n\n\tif (bytes > 0) {\n\t\tdsize = ALIGN(bytes, 8);\n\t\tif (used + dsize > total)\n\t\t\treturn false;\n\t\tnsize = asize + dsize;\n\t\t \n\t\tmemmove(next + dsize, next, tail);\n\t\tmemset(next, 0, dsize);\n\t\tused += dsize;\n\t\trsize += dsize;\n\t} else {\n\t\tdsize = ALIGN(-bytes, 8);\n\t\tif (dsize > asize)\n\t\t\treturn false;\n\t\tnsize = asize - dsize;\n\t\tmemmove(next - dsize, next, tail);\n\t\tused -= dsize;\n\t\trsize -= dsize;\n\t}\n\n\trec->used = cpu_to_le32(used);\n\tattr->size = cpu_to_le32(nsize);\n\tif (!attr->non_res)\n\t\tattr->res.data_size = cpu_to_le32(rsize);\n\tmi->dirty = true;\n\n\treturn true;\n}\n\n \nint mi_pack_runs(struct mft_inode *mi, struct ATTRIB *attr,\n\t\t struct runs_tree *run, CLST len)\n{\n\tint err = 0;\n\tstruct ntfs_sb_info *sbi = mi->sbi;\n\tu32 new_run_size;\n\tCLST plen;\n\tstruct MFT_REC *rec = mi->mrec;\n\tCLST svcn = le64_to_cpu(attr->nres.svcn);\n\tu32 used = le32_to_cpu(rec->used);\n\tu32 aoff = PtrOffset(rec, attr);\n\tu32 asize = le32_to_cpu(attr->size);\n\tchar *next = Add2Ptr(attr, asize);\n\tu16 run_off = le16_to_cpu(attr->nres.run_off);\n\tu32 run_size = asize - run_off;\n\tu32 tail = used - aoff - asize;\n\tu32 dsize = sbi->record_size - used;\n\n\t \n\tmemmove(next + dsize, next, tail);\n\n\t \n\terr = run_pack(run, svcn, len, Add2Ptr(attr, run_off), run_size + dsize,\n\t\t       &plen);\n\tif (err < 0) {\n\t\tmemmove(next, next + dsize, tail);\n\t\treturn err;\n\t}\n\n\tnew_run_size = ALIGN(err, 8);\n\n\tmemmove(next + new_run_size - run_size, next + dsize, tail);\n\n\tattr->size = cpu_to_le32(asize + new_run_size - run_size);\n\tattr->nres.evcn = cpu_to_le64(svcn + plen - 1);\n\trec->used = cpu_to_le32(used + new_run_size - run_size);\n\tmi->dirty = true;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}