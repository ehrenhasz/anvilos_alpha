{
  "module_name": "data.c",
  "hash_id": "261e39f624426778b59e8adaf6048312eacd0d7ca37f93acd1c32be56e7a5c90",
  "original_prompt": "Ingested from linux-6.6.14/fs/erofs/data.c",
  "human_readable_source": "\n \n#include \"internal.h\"\n#include <linux/prefetch.h>\n#include <linux/sched/mm.h>\n#include <linux/dax.h>\n#include <trace/events/erofs.h>\n\nvoid erofs_unmap_metabuf(struct erofs_buf *buf)\n{\n\tif (buf->kmap_type == EROFS_KMAP)\n\t\tkunmap_local(buf->base);\n\tbuf->base = NULL;\n\tbuf->kmap_type = EROFS_NO_KMAP;\n}\n\nvoid erofs_put_metabuf(struct erofs_buf *buf)\n{\n\tif (!buf->page)\n\t\treturn;\n\terofs_unmap_metabuf(buf);\n\tput_page(buf->page);\n\tbuf->page = NULL;\n}\n\n \nvoid *erofs_bread(struct erofs_buf *buf, erofs_blk_t blkaddr,\n\t\t  enum erofs_kmap_type type)\n{\n\tstruct inode *inode = buf->inode;\n\terofs_off_t offset = (erofs_off_t)blkaddr << inode->i_blkbits;\n\tpgoff_t index = offset >> PAGE_SHIFT;\n\tstruct page *page = buf->page;\n\tstruct folio *folio;\n\tunsigned int nofs_flag;\n\n\tif (!page || page->index != index) {\n\t\terofs_put_metabuf(buf);\n\n\t\tnofs_flag = memalloc_nofs_save();\n\t\tfolio = read_cache_folio(inode->i_mapping, index, NULL, NULL);\n\t\tmemalloc_nofs_restore(nofs_flag);\n\t\tif (IS_ERR(folio))\n\t\t\treturn folio;\n\n\t\t \n\t\tpage = folio_file_page(folio, index);\n\t\tbuf->page = page;\n\t}\n\tif (buf->kmap_type == EROFS_NO_KMAP) {\n\t\tif (type == EROFS_KMAP)\n\t\t\tbuf->base = kmap_local_page(page);\n\t\tbuf->kmap_type = type;\n\t} else if (buf->kmap_type != type) {\n\t\tDBG_BUGON(1);\n\t\treturn ERR_PTR(-EFAULT);\n\t}\n\tif (type == EROFS_NO_KMAP)\n\t\treturn NULL;\n\treturn buf->base + (offset & ~PAGE_MASK);\n}\n\nvoid erofs_init_metabuf(struct erofs_buf *buf, struct super_block *sb)\n{\n\tif (erofs_is_fscache_mode(sb))\n\t\tbuf->inode = EROFS_SB(sb)->s_fscache->inode;\n\telse\n\t\tbuf->inode = sb->s_bdev->bd_inode;\n}\n\nvoid *erofs_read_metabuf(struct erofs_buf *buf, struct super_block *sb,\n\t\t\t erofs_blk_t blkaddr, enum erofs_kmap_type type)\n{\n\terofs_init_metabuf(buf, sb);\n\treturn erofs_bread(buf, blkaddr, type);\n}\n\nstatic int erofs_map_blocks_flatmode(struct inode *inode,\n\t\t\t\t     struct erofs_map_blocks *map)\n{\n\terofs_blk_t nblocks, lastblk;\n\tu64 offset = map->m_la;\n\tstruct erofs_inode *vi = EROFS_I(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tbool tailendpacking = (vi->datalayout == EROFS_INODE_FLAT_INLINE);\n\n\tnblocks = erofs_iblks(inode);\n\tlastblk = nblocks - tailendpacking;\n\n\t \n\tmap->m_flags = EROFS_MAP_MAPPED;\n\tif (offset < erofs_pos(sb, lastblk)) {\n\t\tmap->m_pa = erofs_pos(sb, vi->raw_blkaddr) + map->m_la;\n\t\tmap->m_plen = erofs_pos(sb, lastblk) - offset;\n\t} else if (tailendpacking) {\n\t\tmap->m_pa = erofs_iloc(inode) + vi->inode_isize +\n\t\t\tvi->xattr_isize + erofs_blkoff(sb, offset);\n\t\tmap->m_plen = inode->i_size - offset;\n\n\t\t \n\t\tif (erofs_blkoff(sb, map->m_pa) + map->m_plen > sb->s_blocksize) {\n\t\t\terofs_err(sb, \"inline data cross block boundary @ nid %llu\",\n\t\t\t\t  vi->nid);\n\t\t\tDBG_BUGON(1);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t\tmap->m_flags |= EROFS_MAP_META;\n\t} else {\n\t\terofs_err(sb, \"internal error @ nid: %llu (size %llu), m_la 0x%llx\",\n\t\t\t  vi->nid, inode->i_size, map->m_la);\n\t\tDBG_BUGON(1);\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\nint erofs_map_blocks(struct inode *inode, struct erofs_map_blocks *map)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct erofs_inode *vi = EROFS_I(inode);\n\tstruct erofs_inode_chunk_index *idx;\n\tstruct erofs_buf buf = __EROFS_BUF_INITIALIZER;\n\tu64 chunknr;\n\tunsigned int unit;\n\terofs_off_t pos;\n\tvoid *kaddr;\n\tint err = 0;\n\n\ttrace_erofs_map_blocks_enter(inode, map, 0);\n\tmap->m_deviceid = 0;\n\tif (map->m_la >= inode->i_size) {\n\t\t \n\t\tmap->m_flags = 0;\n\t\tmap->m_plen = 0;\n\t\tgoto out;\n\t}\n\n\tif (vi->datalayout != EROFS_INODE_CHUNK_BASED) {\n\t\terr = erofs_map_blocks_flatmode(inode, map);\n\t\tgoto out;\n\t}\n\n\tif (vi->chunkformat & EROFS_CHUNK_FORMAT_INDEXES)\n\t\tunit = sizeof(*idx);\t\t\t \n\telse\n\t\tunit = EROFS_BLOCK_MAP_ENTRY_SIZE;\t \n\n\tchunknr = map->m_la >> vi->chunkbits;\n\tpos = ALIGN(erofs_iloc(inode) + vi->inode_isize +\n\t\t    vi->xattr_isize, unit) + unit * chunknr;\n\n\tkaddr = erofs_read_metabuf(&buf, sb, erofs_blknr(sb, pos), EROFS_KMAP);\n\tif (IS_ERR(kaddr)) {\n\t\terr = PTR_ERR(kaddr);\n\t\tgoto out;\n\t}\n\tmap->m_la = chunknr << vi->chunkbits;\n\tmap->m_plen = min_t(erofs_off_t, 1UL << vi->chunkbits,\n\t\t\tround_up(inode->i_size - map->m_la, sb->s_blocksize));\n\n\t \n\tif (!(vi->chunkformat & EROFS_CHUNK_FORMAT_INDEXES)) {\n\t\t__le32 *blkaddr = kaddr + erofs_blkoff(sb, pos);\n\n\t\tif (le32_to_cpu(*blkaddr) == EROFS_NULL_ADDR) {\n\t\t\tmap->m_flags = 0;\n\t\t} else {\n\t\t\tmap->m_pa = erofs_pos(sb, le32_to_cpu(*blkaddr));\n\t\t\tmap->m_flags = EROFS_MAP_MAPPED;\n\t\t}\n\t\tgoto out_unlock;\n\t}\n\t \n\tidx = kaddr + erofs_blkoff(sb, pos);\n\tswitch (le32_to_cpu(idx->blkaddr)) {\n\tcase EROFS_NULL_ADDR:\n\t\tmap->m_flags = 0;\n\t\tbreak;\n\tdefault:\n\t\tmap->m_deviceid = le16_to_cpu(idx->device_id) &\n\t\t\tEROFS_SB(sb)->device_id_mask;\n\t\tmap->m_pa = erofs_pos(sb, le32_to_cpu(idx->blkaddr));\n\t\tmap->m_flags = EROFS_MAP_MAPPED;\n\t\tbreak;\n\t}\nout_unlock:\n\terofs_put_metabuf(&buf);\nout:\n\tif (!err)\n\t\tmap->m_llen = map->m_plen;\n\ttrace_erofs_map_blocks_exit(inode, map, 0, err);\n\treturn err;\n}\n\nint erofs_map_dev(struct super_block *sb, struct erofs_map_dev *map)\n{\n\tstruct erofs_dev_context *devs = EROFS_SB(sb)->devs;\n\tstruct erofs_device_info *dif;\n\tint id;\n\n\tmap->m_bdev = sb->s_bdev;\n\tmap->m_daxdev = EROFS_SB(sb)->dax_dev;\n\tmap->m_dax_part_off = EROFS_SB(sb)->dax_part_off;\n\tmap->m_fscache = EROFS_SB(sb)->s_fscache;\n\n\tif (map->m_deviceid) {\n\t\tdown_read(&devs->rwsem);\n\t\tdif = idr_find(&devs->tree, map->m_deviceid - 1);\n\t\tif (!dif) {\n\t\t\tup_read(&devs->rwsem);\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tif (devs->flatdev) {\n\t\t\tmap->m_pa += erofs_pos(sb, dif->mapped_blkaddr);\n\t\t\tup_read(&devs->rwsem);\n\t\t\treturn 0;\n\t\t}\n\t\tmap->m_bdev = dif->bdev;\n\t\tmap->m_daxdev = dif->dax_dev;\n\t\tmap->m_dax_part_off = dif->dax_part_off;\n\t\tmap->m_fscache = dif->fscache;\n\t\tup_read(&devs->rwsem);\n\t} else if (devs->extra_devices && !devs->flatdev) {\n\t\tdown_read(&devs->rwsem);\n\t\tidr_for_each_entry(&devs->tree, dif, id) {\n\t\t\terofs_off_t startoff, length;\n\n\t\t\tif (!dif->mapped_blkaddr)\n\t\t\t\tcontinue;\n\t\t\tstartoff = erofs_pos(sb, dif->mapped_blkaddr);\n\t\t\tlength = erofs_pos(sb, dif->blocks);\n\n\t\t\tif (map->m_pa >= startoff &&\n\t\t\t    map->m_pa < startoff + length) {\n\t\t\t\tmap->m_pa -= startoff;\n\t\t\t\tmap->m_bdev = dif->bdev;\n\t\t\t\tmap->m_daxdev = dif->dax_dev;\n\t\t\t\tmap->m_dax_part_off = dif->dax_part_off;\n\t\t\t\tmap->m_fscache = dif->fscache;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tup_read(&devs->rwsem);\n\t}\n\treturn 0;\n}\n\nstatic int erofs_iomap_begin(struct inode *inode, loff_t offset, loff_t length,\n\t\tunsigned int flags, struct iomap *iomap, struct iomap *srcmap)\n{\n\tint ret;\n\tstruct super_block *sb = inode->i_sb;\n\tstruct erofs_map_blocks map;\n\tstruct erofs_map_dev mdev;\n\n\tmap.m_la = offset;\n\tmap.m_llen = length;\n\n\tret = erofs_map_blocks(inode, &map);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmdev = (struct erofs_map_dev) {\n\t\t.m_deviceid = map.m_deviceid,\n\t\t.m_pa = map.m_pa,\n\t};\n\tret = erofs_map_dev(sb, &mdev);\n\tif (ret)\n\t\treturn ret;\n\n\tiomap->offset = map.m_la;\n\tif (flags & IOMAP_DAX)\n\t\tiomap->dax_dev = mdev.m_daxdev;\n\telse\n\t\tiomap->bdev = mdev.m_bdev;\n\tiomap->length = map.m_llen;\n\tiomap->flags = 0;\n\tiomap->private = NULL;\n\n\tif (!(map.m_flags & EROFS_MAP_MAPPED)) {\n\t\tiomap->type = IOMAP_HOLE;\n\t\tiomap->addr = IOMAP_NULL_ADDR;\n\t\tif (!iomap->length)\n\t\t\tiomap->length = length;\n\t\treturn 0;\n\t}\n\n\tif (map.m_flags & EROFS_MAP_META) {\n\t\tvoid *ptr;\n\t\tstruct erofs_buf buf = __EROFS_BUF_INITIALIZER;\n\n\t\tiomap->type = IOMAP_INLINE;\n\t\tptr = erofs_read_metabuf(&buf, sb,\n\t\t\t\terofs_blknr(sb, mdev.m_pa), EROFS_KMAP);\n\t\tif (IS_ERR(ptr))\n\t\t\treturn PTR_ERR(ptr);\n\t\tiomap->inline_data = ptr + erofs_blkoff(sb, mdev.m_pa);\n\t\tiomap->private = buf.base;\n\t} else {\n\t\tiomap->type = IOMAP_MAPPED;\n\t\tiomap->addr = mdev.m_pa;\n\t\tif (flags & IOMAP_DAX)\n\t\t\tiomap->addr += mdev.m_dax_part_off;\n\t}\n\treturn 0;\n}\n\nstatic int erofs_iomap_end(struct inode *inode, loff_t pos, loff_t length,\n\t\tssize_t written, unsigned int flags, struct iomap *iomap)\n{\n\tvoid *ptr = iomap->private;\n\n\tif (ptr) {\n\t\tstruct erofs_buf buf = {\n\t\t\t.page = kmap_to_page(ptr),\n\t\t\t.base = ptr,\n\t\t\t.kmap_type = EROFS_KMAP,\n\t\t};\n\n\t\tDBG_BUGON(iomap->type != IOMAP_INLINE);\n\t\terofs_put_metabuf(&buf);\n\t} else {\n\t\tDBG_BUGON(iomap->type == IOMAP_INLINE);\n\t}\n\treturn written;\n}\n\nstatic const struct iomap_ops erofs_iomap_ops = {\n\t.iomap_begin = erofs_iomap_begin,\n\t.iomap_end = erofs_iomap_end,\n};\n\nint erofs_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,\n\t\t u64 start, u64 len)\n{\n\tif (erofs_inode_is_data_compressed(EROFS_I(inode)->datalayout)) {\n#ifdef CONFIG_EROFS_FS_ZIP\n\t\treturn iomap_fiemap(inode, fieinfo, start, len,\n\t\t\t\t    &z_erofs_iomap_report_ops);\n#else\n\t\treturn -EOPNOTSUPP;\n#endif\n\t}\n\treturn iomap_fiemap(inode, fieinfo, start, len, &erofs_iomap_ops);\n}\n\n \nstatic int erofs_read_folio(struct file *file, struct folio *folio)\n{\n\treturn iomap_read_folio(folio, &erofs_iomap_ops);\n}\n\nstatic void erofs_readahead(struct readahead_control *rac)\n{\n\treturn iomap_readahead(rac, &erofs_iomap_ops);\n}\n\nstatic sector_t erofs_bmap(struct address_space *mapping, sector_t block)\n{\n\treturn iomap_bmap(mapping, block, &erofs_iomap_ops);\n}\n\nstatic ssize_t erofs_file_read_iter(struct kiocb *iocb, struct iov_iter *to)\n{\n\tstruct inode *inode = file_inode(iocb->ki_filp);\n\n\t \n\tif (!iov_iter_count(to))\n\t\treturn 0;\n\n#ifdef CONFIG_FS_DAX\n\tif (IS_DAX(inode))\n\t\treturn dax_iomap_rw(iocb, to, &erofs_iomap_ops);\n#endif\n\tif (iocb->ki_flags & IOCB_DIRECT) {\n\t\tstruct block_device *bdev = inode->i_sb->s_bdev;\n\t\tunsigned int blksize_mask;\n\n\t\tif (bdev)\n\t\t\tblksize_mask = bdev_logical_block_size(bdev) - 1;\n\t\telse\n\t\t\tblksize_mask = i_blocksize(inode) - 1;\n\n\t\tif ((iocb->ki_pos | iov_iter_count(to) |\n\t\t     iov_iter_alignment(to)) & blksize_mask)\n\t\t\treturn -EINVAL;\n\n\t\treturn iomap_dio_rw(iocb, to, &erofs_iomap_ops,\n\t\t\t\t    NULL, 0, NULL, 0);\n\t}\n\treturn filemap_read(iocb, to, 0);\n}\n\n \nconst struct address_space_operations erofs_raw_access_aops = {\n\t.read_folio = erofs_read_folio,\n\t.readahead = erofs_readahead,\n\t.bmap = erofs_bmap,\n\t.direct_IO = noop_direct_IO,\n\t.release_folio = iomap_release_folio,\n\t.invalidate_folio = iomap_invalidate_folio,\n};\n\n#ifdef CONFIG_FS_DAX\nstatic vm_fault_t erofs_dax_huge_fault(struct vm_fault *vmf,\n\t\tunsigned int order)\n{\n\treturn dax_iomap_fault(vmf, order, NULL, NULL, &erofs_iomap_ops);\n}\n\nstatic vm_fault_t erofs_dax_fault(struct vm_fault *vmf)\n{\n\treturn erofs_dax_huge_fault(vmf, 0);\n}\n\nstatic const struct vm_operations_struct erofs_dax_vm_ops = {\n\t.fault\t\t= erofs_dax_fault,\n\t.huge_fault\t= erofs_dax_huge_fault,\n};\n\nstatic int erofs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tif (!IS_DAX(file_inode(file)))\n\t\treturn generic_file_readonly_mmap(file, vma);\n\n\tif ((vma->vm_flags & VM_SHARED) && (vma->vm_flags & VM_MAYWRITE))\n\t\treturn -EINVAL;\n\n\tvma->vm_ops = &erofs_dax_vm_ops;\n\tvm_flags_set(vma, VM_HUGEPAGE);\n\treturn 0;\n}\n#else\n#define erofs_file_mmap\tgeneric_file_readonly_mmap\n#endif\n\nconst struct file_operations erofs_file_fops = {\n\t.llseek\t\t= generic_file_llseek,\n\t.read_iter\t= erofs_file_read_iter,\n\t.mmap\t\t= erofs_file_mmap,\n\t.splice_read\t= filemap_splice_read,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}