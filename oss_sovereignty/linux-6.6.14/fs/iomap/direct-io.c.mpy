{
  "module_name": "direct-io.c",
  "hash_id": "a660550cc29c2039dca9cfa810691897abb1f9c1f1e1d6d080f7353804aa4d3e",
  "original_prompt": "Ingested from linux-6.6.14/fs/iomap/direct-io.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/compiler.h>\n#include <linux/fs.h>\n#include <linux/fscrypt.h>\n#include <linux/pagemap.h>\n#include <linux/iomap.h>\n#include <linux/backing-dev.h>\n#include <linux/uio.h>\n#include <linux/task_io_accounting_ops.h>\n#include \"trace.h\"\n\n#include \"../internal.h\"\n\n \n#define IOMAP_DIO_CALLER_COMP\t(1U << 26)\n#define IOMAP_DIO_INLINE_COMP\t(1U << 27)\n#define IOMAP_DIO_WRITE_THROUGH\t(1U << 28)\n#define IOMAP_DIO_NEED_SYNC\t(1U << 29)\n#define IOMAP_DIO_WRITE\t\t(1U << 30)\n#define IOMAP_DIO_DIRTY\t\t(1U << 31)\n\nstruct iomap_dio {\n\tstruct kiocb\t\t*iocb;\n\tconst struct iomap_dio_ops *dops;\n\tloff_t\t\t\ti_size;\n\tloff_t\t\t\tsize;\n\tatomic_t\t\tref;\n\tunsigned\t\tflags;\n\tint\t\t\terror;\n\tsize_t\t\t\tdone_before;\n\tbool\t\t\twait_for_completion;\n\n\tunion {\n\t\t \n\t\tstruct {\n\t\t\tstruct iov_iter\t\t*iter;\n\t\t\tstruct task_struct\t*waiter;\n\t\t} submit;\n\n\t\t \n\t\tstruct {\n\t\t\tstruct work_struct\twork;\n\t\t} aio;\n\t};\n};\n\nstatic struct bio *iomap_dio_alloc_bio(const struct iomap_iter *iter,\n\t\tstruct iomap_dio *dio, unsigned short nr_vecs, blk_opf_t opf)\n{\n\tif (dio->dops && dio->dops->bio_set)\n\t\treturn bio_alloc_bioset(iter->iomap.bdev, nr_vecs, opf,\n\t\t\t\t\tGFP_KERNEL, dio->dops->bio_set);\n\treturn bio_alloc(iter->iomap.bdev, nr_vecs, opf, GFP_KERNEL);\n}\n\nstatic void iomap_dio_submit_bio(const struct iomap_iter *iter,\n\t\tstruct iomap_dio *dio, struct bio *bio, loff_t pos)\n{\n\tstruct kiocb *iocb = dio->iocb;\n\n\tatomic_inc(&dio->ref);\n\n\t \n\tif ((iocb->ki_flags & IOCB_HIPRI) && !is_sync_kiocb(iocb)) {\n\t\tbio_set_polled(bio, iocb);\n\t\tWRITE_ONCE(iocb->private, bio);\n\t}\n\n\tif (dio->dops && dio->dops->submit_io)\n\t\tdio->dops->submit_io(iter, bio, pos);\n\telse\n\t\tsubmit_bio(bio);\n}\n\nssize_t iomap_dio_complete(struct iomap_dio *dio)\n{\n\tconst struct iomap_dio_ops *dops = dio->dops;\n\tstruct kiocb *iocb = dio->iocb;\n\tloff_t offset = iocb->ki_pos;\n\tssize_t ret = dio->error;\n\n\tif (dops && dops->end_io)\n\t\tret = dops->end_io(iocb, dio->size, ret, dio->flags);\n\n\tif (likely(!ret)) {\n\t\tret = dio->size;\n\t\t \n\t\tif (offset + ret > dio->i_size &&\n\t\t    !(dio->flags & IOMAP_DIO_WRITE))\n\t\t\tret = dio->i_size - offset;\n\t}\n\n\t \n\tif (!dio->error && dio->size && (dio->flags & IOMAP_DIO_WRITE))\n\t\tkiocb_invalidate_post_direct_write(iocb, dio->size);\n\n\tinode_dio_end(file_inode(iocb->ki_filp));\n\n\tif (ret > 0) {\n\t\tiocb->ki_pos += ret;\n\n\t\t \n\t\tif (dio->flags & IOMAP_DIO_NEED_SYNC)\n\t\t\tret = generic_write_sync(iocb, ret);\n\t\tif (ret > 0)\n\t\t\tret += dio->done_before;\n\t}\n\ttrace_iomap_dio_complete(iocb, dio->error, ret);\n\tkfree(dio);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(iomap_dio_complete);\n\nstatic ssize_t iomap_dio_deferred_complete(void *data)\n{\n\treturn iomap_dio_complete(data);\n}\n\nstatic void iomap_dio_complete_work(struct work_struct *work)\n{\n\tstruct iomap_dio *dio = container_of(work, struct iomap_dio, aio.work);\n\tstruct kiocb *iocb = dio->iocb;\n\n\tiocb->ki_complete(iocb, iomap_dio_complete(dio));\n}\n\n \nstatic inline void iomap_dio_set_error(struct iomap_dio *dio, int ret)\n{\n\tcmpxchg(&dio->error, 0, ret);\n}\n\nvoid iomap_dio_bio_end_io(struct bio *bio)\n{\n\tstruct iomap_dio *dio = bio->bi_private;\n\tbool should_dirty = (dio->flags & IOMAP_DIO_DIRTY);\n\tstruct kiocb *iocb = dio->iocb;\n\n\tif (bio->bi_status)\n\t\tiomap_dio_set_error(dio, blk_status_to_errno(bio->bi_status));\n\tif (!atomic_dec_and_test(&dio->ref))\n\t\tgoto release_bio;\n\n\t \n\tif (dio->wait_for_completion) {\n\t\tstruct task_struct *waiter = dio->submit.waiter;\n\n\t\tWRITE_ONCE(dio->submit.waiter, NULL);\n\t\tblk_wake_io_task(waiter);\n\t\tgoto release_bio;\n\t}\n\n\t \n\tif (dio->flags & IOMAP_DIO_INLINE_COMP) {\n\t\tWRITE_ONCE(iocb->private, NULL);\n\t\tiomap_dio_complete_work(&dio->aio.work);\n\t\tgoto release_bio;\n\t}\n\n\t \n\tif (dio->flags & IOMAP_DIO_CALLER_COMP) {\n\t\t \n\t\tiocb->private = dio;\n\t\tiocb->dio_complete = iomap_dio_deferred_complete;\n\n\t\t \n\t\tiocb->ki_complete(iocb, 0);\n\t\tgoto release_bio;\n\t}\n\n\t \n\tINIT_WORK(&dio->aio.work, iomap_dio_complete_work);\n\tqueue_work(file_inode(iocb->ki_filp)->i_sb->s_dio_done_wq,\n\t\t\t&dio->aio.work);\nrelease_bio:\n\tif (should_dirty) {\n\t\tbio_check_pages_dirty(bio);\n\t} else {\n\t\tbio_release_pages(bio, false);\n\t\tbio_put(bio);\n\t}\n}\nEXPORT_SYMBOL_GPL(iomap_dio_bio_end_io);\n\nstatic void iomap_dio_zero(const struct iomap_iter *iter, struct iomap_dio *dio,\n\t\tloff_t pos, unsigned len)\n{\n\tstruct inode *inode = file_inode(dio->iocb->ki_filp);\n\tstruct page *page = ZERO_PAGE(0);\n\tstruct bio *bio;\n\n\tbio = iomap_dio_alloc_bio(iter, dio, 1, REQ_OP_WRITE | REQ_SYNC | REQ_IDLE);\n\tfscrypt_set_bio_crypt_ctx(bio, inode, pos >> inode->i_blkbits,\n\t\t\t\t  GFP_KERNEL);\n\tbio->bi_iter.bi_sector = iomap_sector(&iter->iomap, pos);\n\tbio->bi_private = dio;\n\tbio->bi_end_io = iomap_dio_bio_end_io;\n\n\t__bio_add_page(bio, page, len, 0);\n\tiomap_dio_submit_bio(iter, dio, bio, pos);\n}\n\n \nstatic inline blk_opf_t iomap_dio_bio_opflags(struct iomap_dio *dio,\n\t\tconst struct iomap *iomap, bool use_fua)\n{\n\tblk_opf_t opflags = REQ_SYNC | REQ_IDLE;\n\n\tif (!(dio->flags & IOMAP_DIO_WRITE))\n\t\treturn REQ_OP_READ;\n\n\topflags |= REQ_OP_WRITE;\n\tif (use_fua)\n\t\topflags |= REQ_FUA;\n\telse\n\t\tdio->flags &= ~IOMAP_DIO_WRITE_THROUGH;\n\n\treturn opflags;\n}\n\nstatic loff_t iomap_dio_bio_iter(const struct iomap_iter *iter,\n\t\tstruct iomap_dio *dio)\n{\n\tconst struct iomap *iomap = &iter->iomap;\n\tstruct inode *inode = iter->inode;\n\tunsigned int fs_block_size = i_blocksize(inode), pad;\n\tloff_t length = iomap_length(iter);\n\tloff_t pos = iter->pos;\n\tblk_opf_t bio_opf;\n\tstruct bio *bio;\n\tbool need_zeroout = false;\n\tbool use_fua = false;\n\tint nr_pages, ret = 0;\n\tsize_t copied = 0;\n\tsize_t orig_count;\n\n\tif ((pos | length) & (bdev_logical_block_size(iomap->bdev) - 1) ||\n\t    !bdev_iter_is_aligned(iomap->bdev, dio->submit.iter))\n\t\treturn -EINVAL;\n\n\tif (iomap->type == IOMAP_UNWRITTEN) {\n\t\tdio->flags |= IOMAP_DIO_UNWRITTEN;\n\t\tneed_zeroout = true;\n\t}\n\n\tif (iomap->flags & IOMAP_F_SHARED)\n\t\tdio->flags |= IOMAP_DIO_COW;\n\n\tif (iomap->flags & IOMAP_F_NEW) {\n\t\tneed_zeroout = true;\n\t} else if (iomap->type == IOMAP_MAPPED) {\n\t\t \n\t\tif (!(iomap->flags & (IOMAP_F_SHARED|IOMAP_F_DIRTY)) &&\n\t\t    (dio->flags & IOMAP_DIO_WRITE_THROUGH) &&\n\t\t    (bdev_fua(iomap->bdev) || !bdev_write_cache(iomap->bdev)))\n\t\t\tuse_fua = true;\n\t\telse if (dio->flags & IOMAP_DIO_NEED_SYNC)\n\t\t\tdio->flags &= ~IOMAP_DIO_CALLER_COMP;\n\t}\n\n\t \n\torig_count = iov_iter_count(dio->submit.iter);\n\tiov_iter_truncate(dio->submit.iter, length);\n\n\tif (!iov_iter_count(dio->submit.iter))\n\t\tgoto out;\n\n\t \n\tif (need_zeroout ||\n\t    ((dio->flags & IOMAP_DIO_NEED_SYNC) && !use_fua) ||\n\t    ((dio->flags & IOMAP_DIO_WRITE) && pos >= i_size_read(inode)))\n\t\tdio->flags &= ~IOMAP_DIO_CALLER_COMP;\n\n\t \n\tif (!(dio->flags & (IOMAP_DIO_INLINE_COMP|IOMAP_DIO_CALLER_COMP)))\n\t\tdio->iocb->ki_flags &= ~IOCB_HIPRI;\n\n\tif (need_zeroout) {\n\t\t \n\t\tpad = pos & (fs_block_size - 1);\n\t\tif (pad)\n\t\t\tiomap_dio_zero(iter, dio, pos - pad, pad);\n\t}\n\n\t \n\tbio_opf = iomap_dio_bio_opflags(dio, iomap, use_fua);\n\n\tnr_pages = bio_iov_vecs_to_alloc(dio->submit.iter, BIO_MAX_VECS);\n\tdo {\n\t\tsize_t n;\n\t\tif (dio->error) {\n\t\t\tiov_iter_revert(dio->submit.iter, copied);\n\t\t\tcopied = ret = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\tbio = iomap_dio_alloc_bio(iter, dio, nr_pages, bio_opf);\n\t\tfscrypt_set_bio_crypt_ctx(bio, inode, pos >> inode->i_blkbits,\n\t\t\t\t\t  GFP_KERNEL);\n\t\tbio->bi_iter.bi_sector = iomap_sector(iomap, pos);\n\t\tbio->bi_ioprio = dio->iocb->ki_ioprio;\n\t\tbio->bi_private = dio;\n\t\tbio->bi_end_io = iomap_dio_bio_end_io;\n\n\t\tret = bio_iov_iter_get_pages(bio, dio->submit.iter);\n\t\tif (unlikely(ret)) {\n\t\t\t \n\t\t\tbio_put(bio);\n\t\t\tgoto zero_tail;\n\t\t}\n\n\t\tn = bio->bi_iter.bi_size;\n\t\tif (dio->flags & IOMAP_DIO_WRITE) {\n\t\t\ttask_io_account_write(n);\n\t\t} else {\n\t\t\tif (dio->flags & IOMAP_DIO_DIRTY)\n\t\t\t\tbio_set_pages_dirty(bio);\n\t\t}\n\n\t\tdio->size += n;\n\t\tcopied += n;\n\n\t\tnr_pages = bio_iov_vecs_to_alloc(dio->submit.iter,\n\t\t\t\t\t\t BIO_MAX_VECS);\n\t\t \n\t\tif (nr_pages)\n\t\t\tdio->iocb->ki_flags &= ~IOCB_HIPRI;\n\t\tiomap_dio_submit_bio(iter, dio, bio, pos);\n\t\tpos += n;\n\t} while (nr_pages);\n\n\t \nzero_tail:\n\tif (need_zeroout ||\n\t    ((dio->flags & IOMAP_DIO_WRITE) && pos >= i_size_read(inode))) {\n\t\t \n\t\tpad = pos & (fs_block_size - 1);\n\t\tif (pad)\n\t\t\tiomap_dio_zero(iter, dio, pos, fs_block_size - pad);\n\t}\nout:\n\t \n\tiov_iter_reexpand(dio->submit.iter, orig_count - copied);\n\tif (copied)\n\t\treturn copied;\n\treturn ret;\n}\n\nstatic loff_t iomap_dio_hole_iter(const struct iomap_iter *iter,\n\t\tstruct iomap_dio *dio)\n{\n\tloff_t length = iov_iter_zero(iomap_length(iter), dio->submit.iter);\n\n\tdio->size += length;\n\tif (!length)\n\t\treturn -EFAULT;\n\treturn length;\n}\n\nstatic loff_t iomap_dio_inline_iter(const struct iomap_iter *iomi,\n\t\tstruct iomap_dio *dio)\n{\n\tconst struct iomap *iomap = &iomi->iomap;\n\tstruct iov_iter *iter = dio->submit.iter;\n\tvoid *inline_data = iomap_inline_data(iomap, iomi->pos);\n\tloff_t length = iomap_length(iomi);\n\tloff_t pos = iomi->pos;\n\tsize_t copied;\n\n\tif (WARN_ON_ONCE(!iomap_inline_data_valid(iomap)))\n\t\treturn -EIO;\n\n\tif (dio->flags & IOMAP_DIO_WRITE) {\n\t\tloff_t size = iomi->inode->i_size;\n\n\t\tif (pos > size)\n\t\t\tmemset(iomap_inline_data(iomap, size), 0, pos - size);\n\t\tcopied = copy_from_iter(inline_data, length, iter);\n\t\tif (copied) {\n\t\t\tif (pos + copied > size)\n\t\t\t\ti_size_write(iomi->inode, pos + copied);\n\t\t\tmark_inode_dirty(iomi->inode);\n\t\t}\n\t} else {\n\t\tcopied = copy_to_iter(inline_data, length, iter);\n\t}\n\tdio->size += copied;\n\tif (!copied)\n\t\treturn -EFAULT;\n\treturn copied;\n}\n\nstatic loff_t iomap_dio_iter(const struct iomap_iter *iter,\n\t\tstruct iomap_dio *dio)\n{\n\tswitch (iter->iomap.type) {\n\tcase IOMAP_HOLE:\n\t\tif (WARN_ON_ONCE(dio->flags & IOMAP_DIO_WRITE))\n\t\t\treturn -EIO;\n\t\treturn iomap_dio_hole_iter(iter, dio);\n\tcase IOMAP_UNWRITTEN:\n\t\tif (!(dio->flags & IOMAP_DIO_WRITE))\n\t\t\treturn iomap_dio_hole_iter(iter, dio);\n\t\treturn iomap_dio_bio_iter(iter, dio);\n\tcase IOMAP_MAPPED:\n\t\treturn iomap_dio_bio_iter(iter, dio);\n\tcase IOMAP_INLINE:\n\t\treturn iomap_dio_inline_iter(iter, dio);\n\tcase IOMAP_DELALLOC:\n\t\t \n\t\tpr_warn_ratelimited(\"Direct I/O collision with buffered writes! File: %pD4 Comm: %.20s\\n\",\n\t\t\t\t    dio->iocb->ki_filp, current->comm);\n\t\treturn -EIO;\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -EIO;\n\t}\n}\n\n \nstruct iomap_dio *\n__iomap_dio_rw(struct kiocb *iocb, struct iov_iter *iter,\n\t\tconst struct iomap_ops *ops, const struct iomap_dio_ops *dops,\n\t\tunsigned int dio_flags, void *private, size_t done_before)\n{\n\tstruct inode *inode = file_inode(iocb->ki_filp);\n\tstruct iomap_iter iomi = {\n\t\t.inode\t\t= inode,\n\t\t.pos\t\t= iocb->ki_pos,\n\t\t.len\t\t= iov_iter_count(iter),\n\t\t.flags\t\t= IOMAP_DIRECT,\n\t\t.private\t= private,\n\t};\n\tbool wait_for_completion =\n\t\tis_sync_kiocb(iocb) || (dio_flags & IOMAP_DIO_FORCE_WAIT);\n\tstruct blk_plug plug;\n\tstruct iomap_dio *dio;\n\tloff_t ret = 0;\n\n\ttrace_iomap_dio_rw_begin(iocb, iter, dio_flags, done_before);\n\n\tif (!iomi.len)\n\t\treturn NULL;\n\n\tdio = kmalloc(sizeof(*dio), GFP_KERNEL);\n\tif (!dio)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdio->iocb = iocb;\n\tatomic_set(&dio->ref, 1);\n\tdio->size = 0;\n\tdio->i_size = i_size_read(inode);\n\tdio->dops = dops;\n\tdio->error = 0;\n\tdio->flags = 0;\n\tdio->done_before = done_before;\n\n\tdio->submit.iter = iter;\n\tdio->submit.waiter = current;\n\n\tif (iocb->ki_flags & IOCB_NOWAIT)\n\t\tiomi.flags |= IOMAP_NOWAIT;\n\n\tif (iov_iter_rw(iter) == READ) {\n\t\t \n\t\tdio->flags |= IOMAP_DIO_INLINE_COMP;\n\n\t\tif (iomi.pos >= dio->i_size)\n\t\t\tgoto out_free_dio;\n\n\t\tif (user_backed_iter(iter))\n\t\t\tdio->flags |= IOMAP_DIO_DIRTY;\n\n\t\tret = kiocb_write_and_wait(iocb, iomi.len);\n\t\tif (ret)\n\t\t\tgoto out_free_dio;\n\t} else {\n\t\tiomi.flags |= IOMAP_WRITE;\n\t\tdio->flags |= IOMAP_DIO_WRITE;\n\n\t\t \n\t\tif (iocb->ki_flags & IOCB_DIO_CALLER_COMP)\n\t\t\tdio->flags |= IOMAP_DIO_CALLER_COMP;\n\n\t\tif (dio_flags & IOMAP_DIO_OVERWRITE_ONLY) {\n\t\t\tret = -EAGAIN;\n\t\t\tif (iomi.pos >= dio->i_size ||\n\t\t\t    iomi.pos + iomi.len > dio->i_size)\n\t\t\t\tgoto out_free_dio;\n\t\t\tiomi.flags |= IOMAP_OVERWRITE_ONLY;\n\t\t}\n\n\t\t \n\t\tif (iocb_is_dsync(iocb)) {\n\t\t\tdio->flags |= IOMAP_DIO_NEED_SYNC;\n\n\t\t        \n\t\t\tif (!(iocb->ki_flags & IOCB_SYNC))\n\t\t\t\tdio->flags |= IOMAP_DIO_WRITE_THROUGH;\n\t\t}\n\n\t\t \n\t\tret = kiocb_invalidate_pages(iocb, iomi.len);\n\t\tif (ret) {\n\t\t\tif (ret != -EAGAIN) {\n\t\t\t\ttrace_iomap_dio_invalidate_fail(inode, iomi.pos,\n\t\t\t\t\t\t\t\tiomi.len);\n\t\t\t\tret = -ENOTBLK;\n\t\t\t}\n\t\t\tgoto out_free_dio;\n\t\t}\n\n\t\tif (!wait_for_completion && !inode->i_sb->s_dio_done_wq) {\n\t\t\tret = sb_init_dio_done_wq(inode->i_sb);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out_free_dio;\n\t\t}\n\t}\n\n\tinode_dio_begin(inode);\n\n\tblk_start_plug(&plug);\n\twhile ((ret = iomap_iter(&iomi, ops)) > 0) {\n\t\tiomi.processed = iomap_dio_iter(&iomi, dio);\n\n\t\t \n\t\tiocb->ki_flags &= ~IOCB_HIPRI;\n\t}\n\n\tblk_finish_plug(&plug);\n\n\t \n\tif (iov_iter_rw(iter) == READ && iomi.pos >= dio->i_size)\n\t\tiov_iter_revert(iter, iomi.pos - dio->i_size);\n\n\tif (ret == -EFAULT && dio->size && (dio_flags & IOMAP_DIO_PARTIAL)) {\n\t\tif (!(iocb->ki_flags & IOCB_NOWAIT))\n\t\t\twait_for_completion = true;\n\t\tret = 0;\n\t}\n\n\t \n\tif (ret == -ENOTBLK) {\n\t\twait_for_completion = true;\n\t\tret = 0;\n\t}\n\tif (ret < 0)\n\t\tiomap_dio_set_error(dio, ret);\n\n\t \n\tif (dio->flags & IOMAP_DIO_WRITE_THROUGH)\n\t\tdio->flags &= ~IOMAP_DIO_NEED_SYNC;\n\n\t \n\tdio->wait_for_completion = wait_for_completion;\n\tif (!atomic_dec_and_test(&dio->ref)) {\n\t\tif (!wait_for_completion) {\n\t\t\ttrace_iomap_dio_rw_queued(inode, iomi.pos, iomi.len);\n\t\t\treturn ERR_PTR(-EIOCBQUEUED);\n\t\t}\n\n\t\tfor (;;) {\n\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\tif (!READ_ONCE(dio->submit.waiter))\n\t\t\t\tbreak;\n\n\t\t\tblk_io_schedule();\n\t\t}\n\t\t__set_current_state(TASK_RUNNING);\n\t}\n\n\treturn dio;\n\nout_free_dio:\n\tkfree(dio);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(__iomap_dio_rw);\n\nssize_t\niomap_dio_rw(struct kiocb *iocb, struct iov_iter *iter,\n\t\tconst struct iomap_ops *ops, const struct iomap_dio_ops *dops,\n\t\tunsigned int dio_flags, void *private, size_t done_before)\n{\n\tstruct iomap_dio *dio;\n\n\tdio = __iomap_dio_rw(iocb, iter, ops, dops, dio_flags, private,\n\t\t\t     done_before);\n\tif (IS_ERR_OR_NULL(dio))\n\t\treturn PTR_ERR_OR_ZERO(dio);\n\treturn iomap_dio_complete(dio);\n}\nEXPORT_SYMBOL_GPL(iomap_dio_rw);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}