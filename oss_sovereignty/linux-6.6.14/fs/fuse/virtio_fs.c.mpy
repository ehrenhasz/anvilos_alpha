{
  "module_name": "virtio_fs.c",
  "hash_id": "70e4c5f65dc9a375f176a4a68c2d583f301416bf6025bee09884bdbc460cf1bc",
  "original_prompt": "Ingested from linux-6.6.14/fs/fuse/virtio_fs.c",
  "human_readable_source": "\n \n\n#include <linux/fs.h>\n#include <linux/dax.h>\n#include <linux/pci.h>\n#include <linux/pfn_t.h>\n#include <linux/memremap.h>\n#include <linux/module.h>\n#include <linux/virtio.h>\n#include <linux/virtio_fs.h>\n#include <linux/delay.h>\n#include <linux/fs_context.h>\n#include <linux/fs_parser.h>\n#include <linux/highmem.h>\n#include <linux/uio.h>\n#include \"fuse_i.h\"\n\n \n#define FUSE_HEADER_OVERHEAD    4\n\n \nstatic DEFINE_MUTEX(virtio_fs_mutex);\nstatic LIST_HEAD(virtio_fs_instances);\n\nenum {\n\tVQ_HIPRIO,\n\tVQ_REQUEST\n};\n\n#define VQ_NAME_LEN\t24\n\n \nstruct virtio_fs_vq {\n\tspinlock_t lock;\n\tstruct virtqueue *vq;      \n\tstruct work_struct done_work;\n\tstruct list_head queued_reqs;\n\tstruct list_head end_reqs;\t \n\tstruct delayed_work dispatch_work;\n\tstruct fuse_dev *fud;\n\tbool connected;\n\tlong in_flight;\n\tstruct completion in_flight_zero;  \n\tchar name[VQ_NAME_LEN];\n} ____cacheline_aligned_in_smp;\n\n \nstruct virtio_fs {\n\tstruct kref refcount;\n\tstruct list_head list;     \n\tchar *tag;\n\tstruct virtio_fs_vq *vqs;\n\tunsigned int nvqs;                \n\tunsigned int num_request_queues;  \n\tstruct dax_device *dax_dev;\n\n\t \n\tvoid *window_kaddr;\n\tphys_addr_t window_phys_addr;\n\tsize_t window_len;\n};\n\nstruct virtio_fs_forget_req {\n\tstruct fuse_in_header ih;\n\tstruct fuse_forget_in arg;\n};\n\nstruct virtio_fs_forget {\n\t \n\tstruct list_head list;\n\tstruct virtio_fs_forget_req req;\n};\n\nstruct virtio_fs_req_work {\n\tstruct fuse_req *req;\n\tstruct virtio_fs_vq *fsvq;\n\tstruct work_struct done_work;\n};\n\nstatic int virtio_fs_enqueue_req(struct virtio_fs_vq *fsvq,\n\t\t\t\t struct fuse_req *req, bool in_flight);\n\nstatic const struct constant_table dax_param_enums[] = {\n\t{\"always\",\tFUSE_DAX_ALWAYS },\n\t{\"never\",\tFUSE_DAX_NEVER },\n\t{\"inode\",\tFUSE_DAX_INODE_USER },\n\t{}\n};\n\nenum {\n\tOPT_DAX,\n\tOPT_DAX_ENUM,\n};\n\nstatic const struct fs_parameter_spec virtio_fs_parameters[] = {\n\tfsparam_flag(\"dax\", OPT_DAX),\n\tfsparam_enum(\"dax\", OPT_DAX_ENUM, dax_param_enums),\n\t{}\n};\n\nstatic int virtio_fs_parse_param(struct fs_context *fsc,\n\t\t\t\t struct fs_parameter *param)\n{\n\tstruct fs_parse_result result;\n\tstruct fuse_fs_context *ctx = fsc->fs_private;\n\tint opt;\n\n\topt = fs_parse(fsc, virtio_fs_parameters, param, &result);\n\tif (opt < 0)\n\t\treturn opt;\n\n\tswitch (opt) {\n\tcase OPT_DAX:\n\t\tctx->dax_mode = FUSE_DAX_ALWAYS;\n\t\tbreak;\n\tcase OPT_DAX_ENUM:\n\t\tctx->dax_mode = result.uint_32;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void virtio_fs_free_fsc(struct fs_context *fsc)\n{\n\tstruct fuse_fs_context *ctx = fsc->fs_private;\n\n\tkfree(ctx);\n}\n\nstatic inline struct virtio_fs_vq *vq_to_fsvq(struct virtqueue *vq)\n{\n\tstruct virtio_fs *fs = vq->vdev->priv;\n\n\treturn &fs->vqs[vq->index];\n}\n\n \nstatic inline void inc_in_flight_req(struct virtio_fs_vq *fsvq)\n{\n\tfsvq->in_flight++;\n}\n\n \nstatic inline void dec_in_flight_req(struct virtio_fs_vq *fsvq)\n{\n\tWARN_ON(fsvq->in_flight <= 0);\n\tfsvq->in_flight--;\n\tif (!fsvq->in_flight)\n\t\tcomplete(&fsvq->in_flight_zero);\n}\n\nstatic void release_virtio_fs_obj(struct kref *ref)\n{\n\tstruct virtio_fs *vfs = container_of(ref, struct virtio_fs, refcount);\n\n\tkfree(vfs->vqs);\n\tkfree(vfs);\n}\n\n \nstatic void virtio_fs_put(struct virtio_fs *fs)\n{\n\tkref_put(&fs->refcount, release_virtio_fs_obj);\n}\n\nstatic void virtio_fs_fiq_release(struct fuse_iqueue *fiq)\n{\n\tstruct virtio_fs *vfs = fiq->priv;\n\n\tmutex_lock(&virtio_fs_mutex);\n\tvirtio_fs_put(vfs);\n\tmutex_unlock(&virtio_fs_mutex);\n}\n\nstatic void virtio_fs_drain_queue(struct virtio_fs_vq *fsvq)\n{\n\tWARN_ON(fsvq->in_flight < 0);\n\n\t \n\tspin_lock(&fsvq->lock);\n\tif (fsvq->in_flight) {\n\t\t \n\t\treinit_completion(&fsvq->in_flight_zero);\n\t\tspin_unlock(&fsvq->lock);\n\t\twait_for_completion(&fsvq->in_flight_zero);\n\t} else {\n\t\tspin_unlock(&fsvq->lock);\n\t}\n\n\tflush_work(&fsvq->done_work);\n\tflush_delayed_work(&fsvq->dispatch_work);\n}\n\nstatic void virtio_fs_drain_all_queues_locked(struct virtio_fs *fs)\n{\n\tstruct virtio_fs_vq *fsvq;\n\tint i;\n\n\tfor (i = 0; i < fs->nvqs; i++) {\n\t\tfsvq = &fs->vqs[i];\n\t\tvirtio_fs_drain_queue(fsvq);\n\t}\n}\n\nstatic void virtio_fs_drain_all_queues(struct virtio_fs *fs)\n{\n\t \n\tmutex_lock(&virtio_fs_mutex);\n\tvirtio_fs_drain_all_queues_locked(fs);\n\tmutex_unlock(&virtio_fs_mutex);\n}\n\nstatic void virtio_fs_start_all_queues(struct virtio_fs *fs)\n{\n\tstruct virtio_fs_vq *fsvq;\n\tint i;\n\n\tfor (i = 0; i < fs->nvqs; i++) {\n\t\tfsvq = &fs->vqs[i];\n\t\tspin_lock(&fsvq->lock);\n\t\tfsvq->connected = true;\n\t\tspin_unlock(&fsvq->lock);\n\t}\n}\n\n \nstatic int virtio_fs_add_instance(struct virtio_fs *fs)\n{\n\tstruct virtio_fs *fs2;\n\tbool duplicate = false;\n\n\tmutex_lock(&virtio_fs_mutex);\n\n\tlist_for_each_entry(fs2, &virtio_fs_instances, list) {\n\t\tif (strcmp(fs->tag, fs2->tag) == 0)\n\t\t\tduplicate = true;\n\t}\n\n\tif (!duplicate)\n\t\tlist_add_tail(&fs->list, &virtio_fs_instances);\n\n\tmutex_unlock(&virtio_fs_mutex);\n\n\tif (duplicate)\n\t\treturn -EEXIST;\n\treturn 0;\n}\n\n \nstatic struct virtio_fs *virtio_fs_find_instance(const char *tag)\n{\n\tstruct virtio_fs *fs;\n\n\tmutex_lock(&virtio_fs_mutex);\n\n\tlist_for_each_entry(fs, &virtio_fs_instances, list) {\n\t\tif (strcmp(fs->tag, tag) == 0) {\n\t\t\tkref_get(&fs->refcount);\n\t\t\tgoto found;\n\t\t}\n\t}\n\n\tfs = NULL;  \n\nfound:\n\tmutex_unlock(&virtio_fs_mutex);\n\n\treturn fs;\n}\n\nstatic void virtio_fs_free_devs(struct virtio_fs *fs)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < fs->nvqs; i++) {\n\t\tstruct virtio_fs_vq *fsvq = &fs->vqs[i];\n\n\t\tif (!fsvq->fud)\n\t\t\tcontinue;\n\n\t\tfuse_dev_free(fsvq->fud);\n\t\tfsvq->fud = NULL;\n\t}\n}\n\n \nstatic int virtio_fs_read_tag(struct virtio_device *vdev, struct virtio_fs *fs)\n{\n\tchar tag_buf[sizeof_field(struct virtio_fs_config, tag)];\n\tchar *end;\n\tsize_t len;\n\n\tvirtio_cread_bytes(vdev, offsetof(struct virtio_fs_config, tag),\n\t\t\t   &tag_buf, sizeof(tag_buf));\n\tend = memchr(tag_buf, '\\0', sizeof(tag_buf));\n\tif (end == tag_buf)\n\t\treturn -EINVAL;  \n\tif (!end)\n\t\tend = &tag_buf[sizeof(tag_buf)];\n\n\tlen = end - tag_buf;\n\tfs->tag = devm_kmalloc(&vdev->dev, len + 1, GFP_KERNEL);\n\tif (!fs->tag)\n\t\treturn -ENOMEM;\n\tmemcpy(fs->tag, tag_buf, len);\n\tfs->tag[len] = '\\0';\n\treturn 0;\n}\n\n \nstatic void virtio_fs_hiprio_done_work(struct work_struct *work)\n{\n\tstruct virtio_fs_vq *fsvq = container_of(work, struct virtio_fs_vq,\n\t\t\t\t\t\t done_work);\n\tstruct virtqueue *vq = fsvq->vq;\n\n\t \n\tspin_lock(&fsvq->lock);\n\tdo {\n\t\tunsigned int len;\n\t\tvoid *req;\n\n\t\tvirtqueue_disable_cb(vq);\n\n\t\twhile ((req = virtqueue_get_buf(vq, &len)) != NULL) {\n\t\t\tkfree(req);\n\t\t\tdec_in_flight_req(fsvq);\n\t\t}\n\t} while (!virtqueue_enable_cb(vq) && likely(!virtqueue_is_broken(vq)));\n\tspin_unlock(&fsvq->lock);\n}\n\nstatic void virtio_fs_request_dispatch_work(struct work_struct *work)\n{\n\tstruct fuse_req *req;\n\tstruct virtio_fs_vq *fsvq = container_of(work, struct virtio_fs_vq,\n\t\t\t\t\t\t dispatch_work.work);\n\tint ret;\n\n\tpr_debug(\"virtio-fs: worker %s called.\\n\", __func__);\n\twhile (1) {\n\t\tspin_lock(&fsvq->lock);\n\t\treq = list_first_entry_or_null(&fsvq->end_reqs, struct fuse_req,\n\t\t\t\t\t       list);\n\t\tif (!req) {\n\t\t\tspin_unlock(&fsvq->lock);\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_del_init(&req->list);\n\t\tspin_unlock(&fsvq->lock);\n\t\tfuse_request_end(req);\n\t}\n\n\t \n\twhile (1) {\n\t\tspin_lock(&fsvq->lock);\n\t\treq = list_first_entry_or_null(&fsvq->queued_reqs,\n\t\t\t\t\t       struct fuse_req, list);\n\t\tif (!req) {\n\t\t\tspin_unlock(&fsvq->lock);\n\t\t\treturn;\n\t\t}\n\t\tlist_del_init(&req->list);\n\t\tspin_unlock(&fsvq->lock);\n\n\t\tret = virtio_fs_enqueue_req(fsvq, req, true);\n\t\tif (ret < 0) {\n\t\t\tif (ret == -ENOMEM || ret == -ENOSPC) {\n\t\t\t\tspin_lock(&fsvq->lock);\n\t\t\t\tlist_add_tail(&req->list, &fsvq->queued_reqs);\n\t\t\t\tschedule_delayed_work(&fsvq->dispatch_work,\n\t\t\t\t\t\t      msecs_to_jiffies(1));\n\t\t\t\tspin_unlock(&fsvq->lock);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\treq->out.h.error = ret;\n\t\t\tspin_lock(&fsvq->lock);\n\t\t\tdec_in_flight_req(fsvq);\n\t\t\tspin_unlock(&fsvq->lock);\n\t\t\tpr_err(\"virtio-fs: virtio_fs_enqueue_req() failed %d\\n\",\n\t\t\t       ret);\n\t\t\tfuse_request_end(req);\n\t\t}\n\t}\n}\n\n \nstatic int send_forget_request(struct virtio_fs_vq *fsvq,\n\t\t\t       struct virtio_fs_forget *forget,\n\t\t\t       bool in_flight)\n{\n\tstruct scatterlist sg;\n\tstruct virtqueue *vq;\n\tint ret = 0;\n\tbool notify;\n\tstruct virtio_fs_forget_req *req = &forget->req;\n\n\tspin_lock(&fsvq->lock);\n\tif (!fsvq->connected) {\n\t\tif (in_flight)\n\t\t\tdec_in_flight_req(fsvq);\n\t\tkfree(forget);\n\t\tgoto out;\n\t}\n\n\tsg_init_one(&sg, req, sizeof(*req));\n\tvq = fsvq->vq;\n\tdev_dbg(&vq->vdev->dev, \"%s\\n\", __func__);\n\n\tret = virtqueue_add_outbuf(vq, &sg, 1, forget, GFP_ATOMIC);\n\tif (ret < 0) {\n\t\tif (ret == -ENOMEM || ret == -ENOSPC) {\n\t\t\tpr_debug(\"virtio-fs: Could not queue FORGET: err=%d. Will try later\\n\",\n\t\t\t\t ret);\n\t\t\tlist_add_tail(&forget->list, &fsvq->queued_reqs);\n\t\t\tschedule_delayed_work(&fsvq->dispatch_work,\n\t\t\t\t\t      msecs_to_jiffies(1));\n\t\t\tif (!in_flight)\n\t\t\t\tinc_in_flight_req(fsvq);\n\t\t\t \n\t\t\tret = 1;\n\t\t} else {\n\t\t\tpr_debug(\"virtio-fs: Could not queue FORGET: err=%d. Dropping it.\\n\",\n\t\t\t\t ret);\n\t\t\tkfree(forget);\n\t\t\tif (in_flight)\n\t\t\t\tdec_in_flight_req(fsvq);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tif (!in_flight)\n\t\tinc_in_flight_req(fsvq);\n\tnotify = virtqueue_kick_prepare(vq);\n\tspin_unlock(&fsvq->lock);\n\n\tif (notify)\n\t\tvirtqueue_notify(vq);\n\treturn ret;\nout:\n\tspin_unlock(&fsvq->lock);\n\treturn ret;\n}\n\nstatic void virtio_fs_hiprio_dispatch_work(struct work_struct *work)\n{\n\tstruct virtio_fs_forget *forget;\n\tstruct virtio_fs_vq *fsvq = container_of(work, struct virtio_fs_vq,\n\t\t\t\t\t\t dispatch_work.work);\n\tpr_debug(\"virtio-fs: worker %s called.\\n\", __func__);\n\twhile (1) {\n\t\tspin_lock(&fsvq->lock);\n\t\tforget = list_first_entry_or_null(&fsvq->queued_reqs,\n\t\t\t\t\tstruct virtio_fs_forget, list);\n\t\tif (!forget) {\n\t\t\tspin_unlock(&fsvq->lock);\n\t\t\treturn;\n\t\t}\n\n\t\tlist_del(&forget->list);\n\t\tspin_unlock(&fsvq->lock);\n\t\tif (send_forget_request(fsvq, forget, true))\n\t\t\treturn;\n\t}\n}\n\n \nstatic int copy_args_to_argbuf(struct fuse_req *req)\n{\n\tstruct fuse_args *args = req->args;\n\tunsigned int offset = 0;\n\tunsigned int num_in;\n\tunsigned int num_out;\n\tunsigned int len;\n\tunsigned int i;\n\n\tnum_in = args->in_numargs - args->in_pages;\n\tnum_out = args->out_numargs - args->out_pages;\n\tlen = fuse_len_args(num_in, (struct fuse_arg *) args->in_args) +\n\t      fuse_len_args(num_out, args->out_args);\n\n\treq->argbuf = kmalloc(len, GFP_ATOMIC);\n\tif (!req->argbuf)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_in; i++) {\n\t\tmemcpy(req->argbuf + offset,\n\t\t       args->in_args[i].value,\n\t\t       args->in_args[i].size);\n\t\toffset += args->in_args[i].size;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void copy_args_from_argbuf(struct fuse_args *args, struct fuse_req *req)\n{\n\tunsigned int remaining;\n\tunsigned int offset;\n\tunsigned int num_in;\n\tunsigned int num_out;\n\tunsigned int i;\n\n\tremaining = req->out.h.len - sizeof(req->out.h);\n\tnum_in = args->in_numargs - args->in_pages;\n\tnum_out = args->out_numargs - args->out_pages;\n\toffset = fuse_len_args(num_in, (struct fuse_arg *)args->in_args);\n\n\tfor (i = 0; i < num_out; i++) {\n\t\tunsigned int argsize = args->out_args[i].size;\n\n\t\tif (args->out_argvar &&\n\t\t    i == args->out_numargs - 1 &&\n\t\t    argsize > remaining) {\n\t\t\targsize = remaining;\n\t\t}\n\n\t\tmemcpy(args->out_args[i].value, req->argbuf + offset, argsize);\n\t\toffset += argsize;\n\n\t\tif (i != args->out_numargs - 1)\n\t\t\tremaining -= argsize;\n\t}\n\n\t \n\tif (args->out_argvar)\n\t\targs->out_args[args->out_numargs - 1].size = remaining;\n\n\tkfree(req->argbuf);\n\treq->argbuf = NULL;\n}\n\n \nstatic void virtio_fs_request_complete(struct fuse_req *req,\n\t\t\t\t       struct virtio_fs_vq *fsvq)\n{\n\tstruct fuse_pqueue *fpq = &fsvq->fud->pq;\n\tstruct fuse_args *args;\n\tstruct fuse_args_pages *ap;\n\tunsigned int len, i, thislen;\n\tstruct page *page;\n\n\t \n\targs = req->args;\n\tcopy_args_from_argbuf(args, req);\n\n\tif (args->out_pages && args->page_zeroing) {\n\t\tlen = args->out_args[args->out_numargs - 1].size;\n\t\tap = container_of(args, typeof(*ap), args);\n\t\tfor (i = 0; i < ap->num_pages; i++) {\n\t\t\tthislen = ap->descs[i].length;\n\t\t\tif (len < thislen) {\n\t\t\t\tWARN_ON(ap->descs[i].offset);\n\t\t\t\tpage = ap->pages[i];\n\t\t\t\tzero_user_segment(page, len, thislen);\n\t\t\t\tlen = 0;\n\t\t\t} else {\n\t\t\t\tlen -= thislen;\n\t\t\t}\n\t\t}\n\t}\n\n\tspin_lock(&fpq->lock);\n\tclear_bit(FR_SENT, &req->flags);\n\tspin_unlock(&fpq->lock);\n\n\tfuse_request_end(req);\n\tspin_lock(&fsvq->lock);\n\tdec_in_flight_req(fsvq);\n\tspin_unlock(&fsvq->lock);\n}\n\nstatic void virtio_fs_complete_req_work(struct work_struct *work)\n{\n\tstruct virtio_fs_req_work *w =\n\t\tcontainer_of(work, typeof(*w), done_work);\n\n\tvirtio_fs_request_complete(w->req, w->fsvq);\n\tkfree(w);\n}\n\nstatic void virtio_fs_requests_done_work(struct work_struct *work)\n{\n\tstruct virtio_fs_vq *fsvq = container_of(work, struct virtio_fs_vq,\n\t\t\t\t\t\t done_work);\n\tstruct fuse_pqueue *fpq = &fsvq->fud->pq;\n\tstruct virtqueue *vq = fsvq->vq;\n\tstruct fuse_req *req;\n\tstruct fuse_req *next;\n\tunsigned int len;\n\tLIST_HEAD(reqs);\n\n\t \n\tspin_lock(&fsvq->lock);\n\tdo {\n\t\tvirtqueue_disable_cb(vq);\n\n\t\twhile ((req = virtqueue_get_buf(vq, &len)) != NULL) {\n\t\t\tspin_lock(&fpq->lock);\n\t\t\tlist_move_tail(&req->list, &reqs);\n\t\t\tspin_unlock(&fpq->lock);\n\t\t}\n\t} while (!virtqueue_enable_cb(vq) && likely(!virtqueue_is_broken(vq)));\n\tspin_unlock(&fsvq->lock);\n\n\t \n\tlist_for_each_entry_safe(req, next, &reqs, list) {\n\t\tlist_del_init(&req->list);\n\n\t\t \n\t\tif (req->args->may_block) {\n\t\t\tstruct virtio_fs_req_work *w;\n\n\t\t\tw = kzalloc(sizeof(*w), GFP_NOFS | __GFP_NOFAIL);\n\t\t\tINIT_WORK(&w->done_work, virtio_fs_complete_req_work);\n\t\t\tw->fsvq = fsvq;\n\t\t\tw->req = req;\n\t\t\tschedule_work(&w->done_work);\n\t\t} else {\n\t\t\tvirtio_fs_request_complete(req, fsvq);\n\t\t}\n\t}\n}\n\n \nstatic void virtio_fs_vq_done(struct virtqueue *vq)\n{\n\tstruct virtio_fs_vq *fsvq = vq_to_fsvq(vq);\n\n\tdev_dbg(&vq->vdev->dev, \"%s %s\\n\", __func__, fsvq->name);\n\n\tschedule_work(&fsvq->done_work);\n}\n\nstatic void virtio_fs_init_vq(struct virtio_fs_vq *fsvq, char *name,\n\t\t\t      int vq_type)\n{\n\tstrscpy(fsvq->name, name, VQ_NAME_LEN);\n\tspin_lock_init(&fsvq->lock);\n\tINIT_LIST_HEAD(&fsvq->queued_reqs);\n\tINIT_LIST_HEAD(&fsvq->end_reqs);\n\tinit_completion(&fsvq->in_flight_zero);\n\n\tif (vq_type == VQ_REQUEST) {\n\t\tINIT_WORK(&fsvq->done_work, virtio_fs_requests_done_work);\n\t\tINIT_DELAYED_WORK(&fsvq->dispatch_work,\n\t\t\t\t  virtio_fs_request_dispatch_work);\n\t} else {\n\t\tINIT_WORK(&fsvq->done_work, virtio_fs_hiprio_done_work);\n\t\tINIT_DELAYED_WORK(&fsvq->dispatch_work,\n\t\t\t\t  virtio_fs_hiprio_dispatch_work);\n\t}\n}\n\n \nstatic int virtio_fs_setup_vqs(struct virtio_device *vdev,\n\t\t\t       struct virtio_fs *fs)\n{\n\tstruct virtqueue **vqs;\n\tvq_callback_t **callbacks;\n\tconst char **names;\n\tunsigned int i;\n\tint ret = 0;\n\n\tvirtio_cread_le(vdev, struct virtio_fs_config, num_request_queues,\n\t\t\t&fs->num_request_queues);\n\tif (fs->num_request_queues == 0)\n\t\treturn -EINVAL;\n\n\tfs->nvqs = VQ_REQUEST + fs->num_request_queues;\n\tfs->vqs = kcalloc(fs->nvqs, sizeof(fs->vqs[VQ_HIPRIO]), GFP_KERNEL);\n\tif (!fs->vqs)\n\t\treturn -ENOMEM;\n\n\tvqs = kmalloc_array(fs->nvqs, sizeof(vqs[VQ_HIPRIO]), GFP_KERNEL);\n\tcallbacks = kmalloc_array(fs->nvqs, sizeof(callbacks[VQ_HIPRIO]),\n\t\t\t\t\tGFP_KERNEL);\n\tnames = kmalloc_array(fs->nvqs, sizeof(names[VQ_HIPRIO]), GFP_KERNEL);\n\tif (!vqs || !callbacks || !names) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t \n\tcallbacks[VQ_HIPRIO] = virtio_fs_vq_done;\n\tvirtio_fs_init_vq(&fs->vqs[VQ_HIPRIO], \"hiprio\", VQ_HIPRIO);\n\tnames[VQ_HIPRIO] = fs->vqs[VQ_HIPRIO].name;\n\n\t \n\tfor (i = VQ_REQUEST; i < fs->nvqs; i++) {\n\t\tchar vq_name[VQ_NAME_LEN];\n\n\t\tsnprintf(vq_name, VQ_NAME_LEN, \"requests.%u\", i - VQ_REQUEST);\n\t\tvirtio_fs_init_vq(&fs->vqs[i], vq_name, VQ_REQUEST);\n\t\tcallbacks[i] = virtio_fs_vq_done;\n\t\tnames[i] = fs->vqs[i].name;\n\t}\n\n\tret = virtio_find_vqs(vdev, fs->nvqs, vqs, callbacks, names, NULL);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tfor (i = 0; i < fs->nvqs; i++)\n\t\tfs->vqs[i].vq = vqs[i];\n\n\tvirtio_fs_start_all_queues(fs);\nout:\n\tkfree(names);\n\tkfree(callbacks);\n\tkfree(vqs);\n\tif (ret)\n\t\tkfree(fs->vqs);\n\treturn ret;\n}\n\n \nstatic void virtio_fs_cleanup_vqs(struct virtio_device *vdev)\n{\n\tvdev->config->del_vqs(vdev);\n}\n\n \nstatic long virtio_fs_direct_access(struct dax_device *dax_dev, pgoff_t pgoff,\n\t\t\t\t    long nr_pages, enum dax_access_mode mode,\n\t\t\t\t    void **kaddr, pfn_t *pfn)\n{\n\tstruct virtio_fs *fs = dax_get_private(dax_dev);\n\tphys_addr_t offset = PFN_PHYS(pgoff);\n\tsize_t max_nr_pages = fs->window_len / PAGE_SIZE - pgoff;\n\n\tif (kaddr)\n\t\t*kaddr = fs->window_kaddr + offset;\n\tif (pfn)\n\t\t*pfn = phys_to_pfn_t(fs->window_phys_addr + offset,\n\t\t\t\t\tPFN_DEV | PFN_MAP);\n\treturn nr_pages > max_nr_pages ? max_nr_pages : nr_pages;\n}\n\nstatic int virtio_fs_zero_page_range(struct dax_device *dax_dev,\n\t\t\t\t     pgoff_t pgoff, size_t nr_pages)\n{\n\tlong rc;\n\tvoid *kaddr;\n\n\trc = dax_direct_access(dax_dev, pgoff, nr_pages, DAX_ACCESS, &kaddr,\n\t\t\t       NULL);\n\tif (rc < 0)\n\t\treturn dax_mem2blk_err(rc);\n\n\tmemset(kaddr, 0, nr_pages << PAGE_SHIFT);\n\tdax_flush(dax_dev, kaddr, nr_pages << PAGE_SHIFT);\n\treturn 0;\n}\n\nstatic const struct dax_operations virtio_fs_dax_ops = {\n\t.direct_access = virtio_fs_direct_access,\n\t.zero_page_range = virtio_fs_zero_page_range,\n};\n\nstatic void virtio_fs_cleanup_dax(void *data)\n{\n\tstruct dax_device *dax_dev = data;\n\n\tkill_dax(dax_dev);\n\tput_dax(dax_dev);\n}\n\nstatic int virtio_fs_setup_dax(struct virtio_device *vdev, struct virtio_fs *fs)\n{\n\tstruct virtio_shm_region cache_reg;\n\tstruct dev_pagemap *pgmap;\n\tbool have_cache;\n\n\tif (!IS_ENABLED(CONFIG_FUSE_DAX))\n\t\treturn 0;\n\n\t \n\thave_cache = virtio_get_shm_region(vdev, &cache_reg,\n\t\t\t\t\t   (u8)VIRTIO_FS_SHMCAP_ID_CACHE);\n\tif (!have_cache) {\n\t\tdev_notice(&vdev->dev, \"%s: No cache capability\\n\", __func__);\n\t\treturn 0;\n\t}\n\n\tif (!devm_request_mem_region(&vdev->dev, cache_reg.addr, cache_reg.len,\n\t\t\t\t     dev_name(&vdev->dev))) {\n\t\tdev_warn(&vdev->dev, \"could not reserve region addr=0x%llx len=0x%llx\\n\",\n\t\t\t cache_reg.addr, cache_reg.len);\n\t\treturn -EBUSY;\n\t}\n\n\tdev_notice(&vdev->dev, \"Cache len: 0x%llx @ 0x%llx\\n\", cache_reg.len,\n\t\t   cache_reg.addr);\n\n\tpgmap = devm_kzalloc(&vdev->dev, sizeof(*pgmap), GFP_KERNEL);\n\tif (!pgmap)\n\t\treturn -ENOMEM;\n\n\tpgmap->type = MEMORY_DEVICE_FS_DAX;\n\n\t \n\tpgmap->range = (struct range) {\n\t\t.start = (phys_addr_t) cache_reg.addr,\n\t\t.end = (phys_addr_t) cache_reg.addr + cache_reg.len - 1,\n\t};\n\tpgmap->nr_range = 1;\n\n\tfs->window_kaddr = devm_memremap_pages(&vdev->dev, pgmap);\n\tif (IS_ERR(fs->window_kaddr))\n\t\treturn PTR_ERR(fs->window_kaddr);\n\n\tfs->window_phys_addr = (phys_addr_t) cache_reg.addr;\n\tfs->window_len = (phys_addr_t) cache_reg.len;\n\n\tdev_dbg(&vdev->dev, \"%s: window kaddr 0x%px phys_addr 0x%llx len 0x%llx\\n\",\n\t\t__func__, fs->window_kaddr, cache_reg.addr, cache_reg.len);\n\n\tfs->dax_dev = alloc_dax(fs, &virtio_fs_dax_ops);\n\tif (IS_ERR(fs->dax_dev))\n\t\treturn PTR_ERR(fs->dax_dev);\n\n\treturn devm_add_action_or_reset(&vdev->dev, virtio_fs_cleanup_dax,\n\t\t\t\t\tfs->dax_dev);\n}\n\nstatic int virtio_fs_probe(struct virtio_device *vdev)\n{\n\tstruct virtio_fs *fs;\n\tint ret;\n\n\tfs = kzalloc(sizeof(*fs), GFP_KERNEL);\n\tif (!fs)\n\t\treturn -ENOMEM;\n\tkref_init(&fs->refcount);\n\tvdev->priv = fs;\n\n\tret = virtio_fs_read_tag(vdev, fs);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = virtio_fs_setup_vqs(vdev, fs);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t \n\n\tret = virtio_fs_setup_dax(vdev, fs);\n\tif (ret < 0)\n\t\tgoto out_vqs;\n\n\t \n\tvirtio_device_ready(vdev);\n\n\tret = virtio_fs_add_instance(fs);\n\tif (ret < 0)\n\t\tgoto out_vqs;\n\n\treturn 0;\n\nout_vqs:\n\tvirtio_reset_device(vdev);\n\tvirtio_fs_cleanup_vqs(vdev);\n\tkfree(fs->vqs);\n\nout:\n\tvdev->priv = NULL;\n\tkfree(fs);\n\treturn ret;\n}\n\nstatic void virtio_fs_stop_all_queues(struct virtio_fs *fs)\n{\n\tstruct virtio_fs_vq *fsvq;\n\tint i;\n\n\tfor (i = 0; i < fs->nvqs; i++) {\n\t\tfsvq = &fs->vqs[i];\n\t\tspin_lock(&fsvq->lock);\n\t\tfsvq->connected = false;\n\t\tspin_unlock(&fsvq->lock);\n\t}\n}\n\nstatic void virtio_fs_remove(struct virtio_device *vdev)\n{\n\tstruct virtio_fs *fs = vdev->priv;\n\n\tmutex_lock(&virtio_fs_mutex);\n\t \n\tlist_del_init(&fs->list);\n\tvirtio_fs_stop_all_queues(fs);\n\tvirtio_fs_drain_all_queues_locked(fs);\n\tvirtio_reset_device(vdev);\n\tvirtio_fs_cleanup_vqs(vdev);\n\n\tvdev->priv = NULL;\n\t \n\tvirtio_fs_put(fs);\n\tmutex_unlock(&virtio_fs_mutex);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int virtio_fs_freeze(struct virtio_device *vdev)\n{\n\t \n\tpr_warn(\"virtio-fs: suspend/resume not yet supported\\n\");\n\treturn -EOPNOTSUPP;\n}\n\nstatic int virtio_fs_restore(struct virtio_device *vdev)\n{\n\t  \n\treturn 0;\n}\n#endif  \n\nstatic const struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_FS, VIRTIO_DEV_ANY_ID },\n\t{},\n};\n\nstatic const unsigned int feature_table[] = {};\n\nstatic struct virtio_driver virtio_fs_driver = {\n\t.driver.name\t\t= KBUILD_MODNAME,\n\t.driver.owner\t\t= THIS_MODULE,\n\t.id_table\t\t= id_table,\n\t.feature_table\t\t= feature_table,\n\t.feature_table_size\t= ARRAY_SIZE(feature_table),\n\t.probe\t\t\t= virtio_fs_probe,\n\t.remove\t\t\t= virtio_fs_remove,\n#ifdef CONFIG_PM_SLEEP\n\t.freeze\t\t\t= virtio_fs_freeze,\n\t.restore\t\t= virtio_fs_restore,\n#endif\n};\n\nstatic void virtio_fs_wake_forget_and_unlock(struct fuse_iqueue *fiq)\n__releases(fiq->lock)\n{\n\tstruct fuse_forget_link *link;\n\tstruct virtio_fs_forget *forget;\n\tstruct virtio_fs_forget_req *req;\n\tstruct virtio_fs *fs;\n\tstruct virtio_fs_vq *fsvq;\n\tu64 unique;\n\n\tlink = fuse_dequeue_forget(fiq, 1, NULL);\n\tunique = fuse_get_unique(fiq);\n\n\tfs = fiq->priv;\n\tfsvq = &fs->vqs[VQ_HIPRIO];\n\tspin_unlock(&fiq->lock);\n\n\t \n\tforget = kmalloc(sizeof(*forget), GFP_NOFS | __GFP_NOFAIL);\n\treq = &forget->req;\n\n\treq->ih = (struct fuse_in_header){\n\t\t.opcode = FUSE_FORGET,\n\t\t.nodeid = link->forget_one.nodeid,\n\t\t.unique = unique,\n\t\t.len = sizeof(*req),\n\t};\n\treq->arg = (struct fuse_forget_in){\n\t\t.nlookup = link->forget_one.nlookup,\n\t};\n\n\tsend_forget_request(fsvq, forget, false);\n\tkfree(link);\n}\n\nstatic void virtio_fs_wake_interrupt_and_unlock(struct fuse_iqueue *fiq)\n__releases(fiq->lock)\n{\n\t \n\tspin_unlock(&fiq->lock);\n}\n\n \nstatic unsigned int sg_count_fuse_pages(struct fuse_page_desc *page_descs,\n\t\t\t\t       unsigned int num_pages,\n\t\t\t\t       unsigned int total_len)\n{\n\tunsigned int i;\n\tunsigned int this_len;\n\n\tfor (i = 0; i < num_pages && total_len; i++) {\n\t\tthis_len =  min(page_descs[i].length, total_len);\n\t\ttotal_len -= this_len;\n\t}\n\n\treturn i;\n}\n\n \nstatic unsigned int sg_count_fuse_req(struct fuse_req *req)\n{\n\tstruct fuse_args *args = req->args;\n\tstruct fuse_args_pages *ap = container_of(args, typeof(*ap), args);\n\tunsigned int size, total_sgs = 1  ;\n\n\tif (args->in_numargs - args->in_pages)\n\t\ttotal_sgs += 1;\n\n\tif (args->in_pages) {\n\t\tsize = args->in_args[args->in_numargs - 1].size;\n\t\ttotal_sgs += sg_count_fuse_pages(ap->descs, ap->num_pages,\n\t\t\t\t\t\t size);\n\t}\n\n\tif (!test_bit(FR_ISREPLY, &req->flags))\n\t\treturn total_sgs;\n\n\ttotal_sgs += 1  ;\n\n\tif (args->out_numargs - args->out_pages)\n\t\ttotal_sgs += 1;\n\n\tif (args->out_pages) {\n\t\tsize = args->out_args[args->out_numargs - 1].size;\n\t\ttotal_sgs += sg_count_fuse_pages(ap->descs, ap->num_pages,\n\t\t\t\t\t\t size);\n\t}\n\n\treturn total_sgs;\n}\n\n \nstatic unsigned int sg_init_fuse_pages(struct scatterlist *sg,\n\t\t\t\t       struct page **pages,\n\t\t\t\t       struct fuse_page_desc *page_descs,\n\t\t\t\t       unsigned int num_pages,\n\t\t\t\t       unsigned int total_len)\n{\n\tunsigned int i;\n\tunsigned int this_len;\n\n\tfor (i = 0; i < num_pages && total_len; i++) {\n\t\tsg_init_table(&sg[i], 1);\n\t\tthis_len =  min(page_descs[i].length, total_len);\n\t\tsg_set_page(&sg[i], pages[i], this_len, page_descs[i].offset);\n\t\ttotal_len -= this_len;\n\t}\n\n\treturn i;\n}\n\n \nstatic unsigned int sg_init_fuse_args(struct scatterlist *sg,\n\t\t\t\t      struct fuse_req *req,\n\t\t\t\t      struct fuse_arg *args,\n\t\t\t\t      unsigned int numargs,\n\t\t\t\t      bool argpages,\n\t\t\t\t      void *argbuf,\n\t\t\t\t      unsigned int *len_used)\n{\n\tstruct fuse_args_pages *ap = container_of(req->args, typeof(*ap), args);\n\tunsigned int total_sgs = 0;\n\tunsigned int len;\n\n\tlen = fuse_len_args(numargs - argpages, args);\n\tif (len)\n\t\tsg_init_one(&sg[total_sgs++], argbuf, len);\n\n\tif (argpages)\n\t\ttotal_sgs += sg_init_fuse_pages(&sg[total_sgs],\n\t\t\t\t\t\tap->pages, ap->descs,\n\t\t\t\t\t\tap->num_pages,\n\t\t\t\t\t\targs[numargs - 1].size);\n\n\tif (len_used)\n\t\t*len_used = len;\n\n\treturn total_sgs;\n}\n\n \nstatic int virtio_fs_enqueue_req(struct virtio_fs_vq *fsvq,\n\t\t\t\t struct fuse_req *req, bool in_flight)\n{\n\t \n\tstruct scatterlist *stack_sgs[6];\n\tstruct scatterlist stack_sg[ARRAY_SIZE(stack_sgs)];\n\tstruct scatterlist **sgs = stack_sgs;\n\tstruct scatterlist *sg = stack_sg;\n\tstruct virtqueue *vq;\n\tstruct fuse_args *args = req->args;\n\tunsigned int argbuf_used = 0;\n\tunsigned int out_sgs = 0;\n\tunsigned int in_sgs = 0;\n\tunsigned int total_sgs;\n\tunsigned int i;\n\tint ret;\n\tbool notify;\n\tstruct fuse_pqueue *fpq;\n\n\t \n\ttotal_sgs = sg_count_fuse_req(req);\n\tif (total_sgs > ARRAY_SIZE(stack_sgs)) {\n\t\tsgs = kmalloc_array(total_sgs, sizeof(sgs[0]), GFP_ATOMIC);\n\t\tsg = kmalloc_array(total_sgs, sizeof(sg[0]), GFP_ATOMIC);\n\t\tif (!sgs || !sg) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tret = copy_args_to_argbuf(req);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t \n\tsg_init_one(&sg[out_sgs++], &req->in.h, sizeof(req->in.h));\n\tout_sgs += sg_init_fuse_args(&sg[out_sgs], req,\n\t\t\t\t     (struct fuse_arg *)args->in_args,\n\t\t\t\t     args->in_numargs, args->in_pages,\n\t\t\t\t     req->argbuf, &argbuf_used);\n\n\t \n\tif (test_bit(FR_ISREPLY, &req->flags)) {\n\t\tsg_init_one(&sg[out_sgs + in_sgs++],\n\t\t\t    &req->out.h, sizeof(req->out.h));\n\t\tin_sgs += sg_init_fuse_args(&sg[out_sgs + in_sgs], req,\n\t\t\t\t\t    args->out_args, args->out_numargs,\n\t\t\t\t\t    args->out_pages,\n\t\t\t\t\t    req->argbuf + argbuf_used, NULL);\n\t}\n\n\tWARN_ON(out_sgs + in_sgs != total_sgs);\n\n\tfor (i = 0; i < total_sgs; i++)\n\t\tsgs[i] = &sg[i];\n\n\tspin_lock(&fsvq->lock);\n\n\tif (!fsvq->connected) {\n\t\tspin_unlock(&fsvq->lock);\n\t\tret = -ENOTCONN;\n\t\tgoto out;\n\t}\n\n\tvq = fsvq->vq;\n\tret = virtqueue_add_sgs(vq, sgs, out_sgs, in_sgs, req, GFP_ATOMIC);\n\tif (ret < 0) {\n\t\tspin_unlock(&fsvq->lock);\n\t\tgoto out;\n\t}\n\n\t \n\tfpq = &fsvq->fud->pq;\n\tspin_lock(&fpq->lock);\n\tlist_add_tail(&req->list, fpq->processing);\n\tspin_unlock(&fpq->lock);\n\tset_bit(FR_SENT, &req->flags);\n\t \n\tsmp_mb__after_atomic();\n\n\tif (!in_flight)\n\t\tinc_in_flight_req(fsvq);\n\tnotify = virtqueue_kick_prepare(vq);\n\n\tspin_unlock(&fsvq->lock);\n\n\tif (notify)\n\t\tvirtqueue_notify(vq);\n\nout:\n\tif (ret < 0 && req->argbuf) {\n\t\tkfree(req->argbuf);\n\t\treq->argbuf = NULL;\n\t}\n\tif (sgs != stack_sgs) {\n\t\tkfree(sgs);\n\t\tkfree(sg);\n\t}\n\n\treturn ret;\n}\n\nstatic void virtio_fs_wake_pending_and_unlock(struct fuse_iqueue *fiq)\n__releases(fiq->lock)\n{\n\tunsigned int queue_id = VQ_REQUEST;  \n\tstruct virtio_fs *fs;\n\tstruct fuse_req *req;\n\tstruct virtio_fs_vq *fsvq;\n\tint ret;\n\n\tWARN_ON(list_empty(&fiq->pending));\n\treq = list_last_entry(&fiq->pending, struct fuse_req, list);\n\tclear_bit(FR_PENDING, &req->flags);\n\tlist_del_init(&req->list);\n\tWARN_ON(!list_empty(&fiq->pending));\n\tspin_unlock(&fiq->lock);\n\n\tfs = fiq->priv;\n\n\tpr_debug(\"%s: opcode %u unique %#llx nodeid %#llx in.len %u out.len %u\\n\",\n\t\t  __func__, req->in.h.opcode, req->in.h.unique,\n\t\t req->in.h.nodeid, req->in.h.len,\n\t\t fuse_len_args(req->args->out_numargs, req->args->out_args));\n\n\tfsvq = &fs->vqs[queue_id];\n\tret = virtio_fs_enqueue_req(fsvq, req, false);\n\tif (ret < 0) {\n\t\tif (ret == -ENOMEM || ret == -ENOSPC) {\n\t\t\t \n\t\t\tspin_lock(&fsvq->lock);\n\t\t\tlist_add_tail(&req->list, &fsvq->queued_reqs);\n\t\t\tinc_in_flight_req(fsvq);\n\t\t\tschedule_delayed_work(&fsvq->dispatch_work,\n\t\t\t\t\t\tmsecs_to_jiffies(1));\n\t\t\tspin_unlock(&fsvq->lock);\n\t\t\treturn;\n\t\t}\n\t\treq->out.h.error = ret;\n\t\tpr_err(\"virtio-fs: virtio_fs_enqueue_req() failed %d\\n\", ret);\n\n\t\t \n\t\tspin_lock(&fsvq->lock);\n\t\tlist_add_tail(&req->list, &fsvq->end_reqs);\n\t\tschedule_delayed_work(&fsvq->dispatch_work, 0);\n\t\tspin_unlock(&fsvq->lock);\n\t\treturn;\n\t}\n}\n\nstatic const struct fuse_iqueue_ops virtio_fs_fiq_ops = {\n\t.wake_forget_and_unlock\t\t= virtio_fs_wake_forget_and_unlock,\n\t.wake_interrupt_and_unlock\t= virtio_fs_wake_interrupt_and_unlock,\n\t.wake_pending_and_unlock\t= virtio_fs_wake_pending_and_unlock,\n\t.release\t\t\t= virtio_fs_fiq_release,\n};\n\nstatic inline void virtio_fs_ctx_set_defaults(struct fuse_fs_context *ctx)\n{\n\tctx->rootmode = S_IFDIR;\n\tctx->default_permissions = 1;\n\tctx->allow_other = 1;\n\tctx->max_read = UINT_MAX;\n\tctx->blksize = 512;\n\tctx->destroy = true;\n\tctx->no_control = true;\n\tctx->no_force_umount = true;\n}\n\nstatic int virtio_fs_fill_super(struct super_block *sb, struct fs_context *fsc)\n{\n\tstruct fuse_mount *fm = get_fuse_mount_super(sb);\n\tstruct fuse_conn *fc = fm->fc;\n\tstruct virtio_fs *fs = fc->iq.priv;\n\tstruct fuse_fs_context *ctx = fsc->fs_private;\n\tunsigned int i;\n\tint err;\n\n\tvirtio_fs_ctx_set_defaults(ctx);\n\tmutex_lock(&virtio_fs_mutex);\n\n\t \n\terr = -EINVAL;\n\tif (list_empty(&fs->list)) {\n\t\tpr_info(\"virtio-fs: tag <%s> not found\\n\", fs->tag);\n\t\tgoto err;\n\t}\n\n\terr = -ENOMEM;\n\t \n\tfor (i = 0; i < fs->nvqs; i++) {\n\t\tstruct virtio_fs_vq *fsvq = &fs->vqs[i];\n\n\t\tfsvq->fud = fuse_dev_alloc();\n\t\tif (!fsvq->fud)\n\t\t\tgoto err_free_fuse_devs;\n\t}\n\n\t \n\tctx->fudptr = NULL;\n\tif (ctx->dax_mode != FUSE_DAX_NEVER) {\n\t\tif (ctx->dax_mode == FUSE_DAX_ALWAYS && !fs->dax_dev) {\n\t\t\terr = -EINVAL;\n\t\t\tpr_err(\"virtio-fs: dax can't be enabled as filesystem\"\n\t\t\t       \" device does not support it.\\n\");\n\t\t\tgoto err_free_fuse_devs;\n\t\t}\n\t\tctx->dax_dev = fs->dax_dev;\n\t}\n\terr = fuse_fill_super_common(sb, ctx);\n\tif (err < 0)\n\t\tgoto err_free_fuse_devs;\n\n\tfor (i = 0; i < fs->nvqs; i++) {\n\t\tstruct virtio_fs_vq *fsvq = &fs->vqs[i];\n\n\t\tfuse_dev_install(fsvq->fud, fc);\n\t}\n\n\t \n\tvirtio_fs_start_all_queues(fs);\n\tfuse_send_init(fm);\n\tmutex_unlock(&virtio_fs_mutex);\n\treturn 0;\n\nerr_free_fuse_devs:\n\tvirtio_fs_free_devs(fs);\nerr:\n\tmutex_unlock(&virtio_fs_mutex);\n\treturn err;\n}\n\nstatic void virtio_fs_conn_destroy(struct fuse_mount *fm)\n{\n\tstruct fuse_conn *fc = fm->fc;\n\tstruct virtio_fs *vfs = fc->iq.priv;\n\tstruct virtio_fs_vq *fsvq = &vfs->vqs[VQ_HIPRIO];\n\n\t \n\tif (IS_ENABLED(CONFIG_FUSE_DAX))\n\t\tfuse_dax_cancel_work(fc);\n\n\t \n\tspin_lock(&fsvq->lock);\n\tfsvq->connected = false;\n\tspin_unlock(&fsvq->lock);\n\tvirtio_fs_drain_all_queues(vfs);\n\n\tfuse_conn_destroy(fm);\n\n\t \n\tvirtio_fs_stop_all_queues(vfs);\n\tvirtio_fs_drain_all_queues(vfs);\n\tvirtio_fs_free_devs(vfs);\n}\n\nstatic void virtio_kill_sb(struct super_block *sb)\n{\n\tstruct fuse_mount *fm = get_fuse_mount_super(sb);\n\tbool last;\n\n\t \n\tif (sb->s_root) {\n\t\tlast = fuse_mount_remove(fm);\n\t\tif (last)\n\t\t\tvirtio_fs_conn_destroy(fm);\n\t}\n\tkill_anon_super(sb);\n\tfuse_mount_destroy(fm);\n}\n\nstatic int virtio_fs_test_super(struct super_block *sb,\n\t\t\t\tstruct fs_context *fsc)\n{\n\tstruct fuse_mount *fsc_fm = fsc->s_fs_info;\n\tstruct fuse_mount *sb_fm = get_fuse_mount_super(sb);\n\n\treturn fsc_fm->fc->iq.priv == sb_fm->fc->iq.priv;\n}\n\nstatic int virtio_fs_get_tree(struct fs_context *fsc)\n{\n\tstruct virtio_fs *fs;\n\tstruct super_block *sb;\n\tstruct fuse_conn *fc = NULL;\n\tstruct fuse_mount *fm;\n\tunsigned int virtqueue_size;\n\tint err = -EIO;\n\n\t \n\tfs = virtio_fs_find_instance(fsc->source);\n\tif (!fs) {\n\t\tpr_info(\"virtio-fs: tag <%s> not found\\n\", fsc->source);\n\t\treturn -EINVAL;\n\t}\n\n\tvirtqueue_size = virtqueue_get_vring_size(fs->vqs[VQ_REQUEST].vq);\n\tif (WARN_ON(virtqueue_size <= FUSE_HEADER_OVERHEAD))\n\t\tgoto out_err;\n\n\terr = -ENOMEM;\n\tfc = kzalloc(sizeof(struct fuse_conn), GFP_KERNEL);\n\tif (!fc)\n\t\tgoto out_err;\n\n\tfm = kzalloc(sizeof(struct fuse_mount), GFP_KERNEL);\n\tif (!fm)\n\t\tgoto out_err;\n\n\tfuse_conn_init(fc, fm, fsc->user_ns, &virtio_fs_fiq_ops, fs);\n\tfc->release = fuse_free_conn;\n\tfc->delete_stale = true;\n\tfc->auto_submounts = true;\n\tfc->sync_fs = true;\n\n\t \n\tfc->max_pages_limit = min_t(unsigned int, fc->max_pages_limit,\n\t\t\t\t    virtqueue_size - FUSE_HEADER_OVERHEAD);\n\n\tfsc->s_fs_info = fm;\n\tsb = sget_fc(fsc, virtio_fs_test_super, set_anon_super_fc);\n\tif (fsc->s_fs_info)\n\t\tfuse_mount_destroy(fm);\n\tif (IS_ERR(sb))\n\t\treturn PTR_ERR(sb);\n\n\tif (!sb->s_root) {\n\t\terr = virtio_fs_fill_super(sb, fsc);\n\t\tif (err) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn err;\n\t\t}\n\n\t\tsb->s_flags |= SB_ACTIVE;\n\t}\n\n\tWARN_ON(fsc->root);\n\tfsc->root = dget(sb->s_root);\n\treturn 0;\n\nout_err:\n\tkfree(fc);\n\tmutex_lock(&virtio_fs_mutex);\n\tvirtio_fs_put(fs);\n\tmutex_unlock(&virtio_fs_mutex);\n\treturn err;\n}\n\nstatic const struct fs_context_operations virtio_fs_context_ops = {\n\t.free\t\t= virtio_fs_free_fsc,\n\t.parse_param\t= virtio_fs_parse_param,\n\t.get_tree\t= virtio_fs_get_tree,\n};\n\nstatic int virtio_fs_init_fs_context(struct fs_context *fsc)\n{\n\tstruct fuse_fs_context *ctx;\n\n\tif (fsc->purpose == FS_CONTEXT_FOR_SUBMOUNT)\n\t\treturn fuse_init_fs_context_submount(fsc);\n\n\tctx = kzalloc(sizeof(struct fuse_fs_context), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\tfsc->fs_private = ctx;\n\tfsc->ops = &virtio_fs_context_ops;\n\treturn 0;\n}\n\nstatic struct file_system_type virtio_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"virtiofs\",\n\t.init_fs_context = virtio_fs_init_fs_context,\n\t.kill_sb\t= virtio_kill_sb,\n};\n\nstatic int __init virtio_fs_init(void)\n{\n\tint ret;\n\n\tret = register_virtio_driver(&virtio_fs_driver);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = register_filesystem(&virtio_fs_type);\n\tif (ret < 0) {\n\t\tunregister_virtio_driver(&virtio_fs_driver);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nmodule_init(virtio_fs_init);\n\nstatic void __exit virtio_fs_exit(void)\n{\n\tunregister_filesystem(&virtio_fs_type);\n\tunregister_virtio_driver(&virtio_fs_driver);\n}\nmodule_exit(virtio_fs_exit);\n\nMODULE_AUTHOR(\"Stefan Hajnoczi <stefanha@redhat.com>\");\nMODULE_DESCRIPTION(\"Virtio Filesystem\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_FS(KBUILD_MODNAME);\nMODULE_DEVICE_TABLE(virtio, id_table);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}