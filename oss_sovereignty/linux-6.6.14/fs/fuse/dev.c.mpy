{
  "module_name": "dev.c",
  "hash_id": "9f8ed77a8446af7531baf30c0efadf62d61bd352d162203c7e48963a5fe2b25c",
  "original_prompt": "Ingested from linux-6.6.14/fs/fuse/dev.c",
  "human_readable_source": " \n\n#include \"fuse_i.h\"\n\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/poll.h>\n#include <linux/sched/signal.h>\n#include <linux/uio.h>\n#include <linux/miscdevice.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/slab.h>\n#include <linux/pipe_fs_i.h>\n#include <linux/swap.h>\n#include <linux/splice.h>\n#include <linux/sched.h>\n\nMODULE_ALIAS_MISCDEV(FUSE_MINOR);\nMODULE_ALIAS(\"devname:fuse\");\n\n \n#define FUSE_INT_REQ_BIT (1ULL << 0)\n#define FUSE_REQ_ID_STEP (1ULL << 1)\n\nstatic struct kmem_cache *fuse_req_cachep;\n\nstatic struct fuse_dev *fuse_get_dev(struct file *file)\n{\n\t \n\treturn READ_ONCE(file->private_data);\n}\n\nstatic void fuse_request_init(struct fuse_mount *fm, struct fuse_req *req)\n{\n\tINIT_LIST_HEAD(&req->list);\n\tINIT_LIST_HEAD(&req->intr_entry);\n\tinit_waitqueue_head(&req->waitq);\n\trefcount_set(&req->count, 1);\n\t__set_bit(FR_PENDING, &req->flags);\n\treq->fm = fm;\n}\n\nstatic struct fuse_req *fuse_request_alloc(struct fuse_mount *fm, gfp_t flags)\n{\n\tstruct fuse_req *req = kmem_cache_zalloc(fuse_req_cachep, flags);\n\tif (req)\n\t\tfuse_request_init(fm, req);\n\n\treturn req;\n}\n\nstatic void fuse_request_free(struct fuse_req *req)\n{\n\tkmem_cache_free(fuse_req_cachep, req);\n}\n\nstatic void __fuse_get_request(struct fuse_req *req)\n{\n\trefcount_inc(&req->count);\n}\n\n \nstatic void __fuse_put_request(struct fuse_req *req)\n{\n\trefcount_dec(&req->count);\n}\n\nvoid fuse_set_initialized(struct fuse_conn *fc)\n{\n\t \n\tsmp_wmb();\n\tfc->initialized = 1;\n}\n\nstatic bool fuse_block_alloc(struct fuse_conn *fc, bool for_background)\n{\n\treturn !fc->initialized || (for_background && fc->blocked);\n}\n\nstatic void fuse_drop_waiting(struct fuse_conn *fc)\n{\n\t \n\tif (atomic_dec_and_test(&fc->num_waiting) &&\n\t    !READ_ONCE(fc->connected)) {\n\t\t \n\t\twake_up_all(&fc->blocked_waitq);\n\t}\n}\n\nstatic void fuse_put_request(struct fuse_req *req);\n\nstatic struct fuse_req *fuse_get_req(struct fuse_mount *fm, bool for_background)\n{\n\tstruct fuse_conn *fc = fm->fc;\n\tstruct fuse_req *req;\n\tint err;\n\tatomic_inc(&fc->num_waiting);\n\n\tif (fuse_block_alloc(fc, for_background)) {\n\t\terr = -EINTR;\n\t\tif (wait_event_killable_exclusive(fc->blocked_waitq,\n\t\t\t\t!fuse_block_alloc(fc, for_background)))\n\t\t\tgoto out;\n\t}\n\t \n\tsmp_rmb();\n\n\terr = -ENOTCONN;\n\tif (!fc->connected)\n\t\tgoto out;\n\n\terr = -ECONNREFUSED;\n\tif (fc->conn_error)\n\t\tgoto out;\n\n\treq = fuse_request_alloc(fm, GFP_KERNEL);\n\terr = -ENOMEM;\n\tif (!req) {\n\t\tif (for_background)\n\t\t\twake_up(&fc->blocked_waitq);\n\t\tgoto out;\n\t}\n\n\treq->in.h.uid = from_kuid(fc->user_ns, current_fsuid());\n\treq->in.h.gid = from_kgid(fc->user_ns, current_fsgid());\n\treq->in.h.pid = pid_nr_ns(task_pid(current), fc->pid_ns);\n\n\t__set_bit(FR_WAITING, &req->flags);\n\tif (for_background)\n\t\t__set_bit(FR_BACKGROUND, &req->flags);\n\n\tif (unlikely(req->in.h.uid == ((uid_t)-1) ||\n\t\t     req->in.h.gid == ((gid_t)-1))) {\n\t\tfuse_put_request(req);\n\t\treturn ERR_PTR(-EOVERFLOW);\n\t}\n\treturn req;\n\n out:\n\tfuse_drop_waiting(fc);\n\treturn ERR_PTR(err);\n}\n\nstatic void fuse_put_request(struct fuse_req *req)\n{\n\tstruct fuse_conn *fc = req->fm->fc;\n\n\tif (refcount_dec_and_test(&req->count)) {\n\t\tif (test_bit(FR_BACKGROUND, &req->flags)) {\n\t\t\t \n\t\t\tspin_lock(&fc->bg_lock);\n\t\t\tif (!fc->blocked)\n\t\t\t\twake_up(&fc->blocked_waitq);\n\t\t\tspin_unlock(&fc->bg_lock);\n\t\t}\n\n\t\tif (test_bit(FR_WAITING, &req->flags)) {\n\t\t\t__clear_bit(FR_WAITING, &req->flags);\n\t\t\tfuse_drop_waiting(fc);\n\t\t}\n\n\t\tfuse_request_free(req);\n\t}\n}\n\nunsigned int fuse_len_args(unsigned int numargs, struct fuse_arg *args)\n{\n\tunsigned nbytes = 0;\n\tunsigned i;\n\n\tfor (i = 0; i < numargs; i++)\n\t\tnbytes += args[i].size;\n\n\treturn nbytes;\n}\nEXPORT_SYMBOL_GPL(fuse_len_args);\n\nu64 fuse_get_unique(struct fuse_iqueue *fiq)\n{\n\tfiq->reqctr += FUSE_REQ_ID_STEP;\n\treturn fiq->reqctr;\n}\nEXPORT_SYMBOL_GPL(fuse_get_unique);\n\nstatic unsigned int fuse_req_hash(u64 unique)\n{\n\treturn hash_long(unique & ~FUSE_INT_REQ_BIT, FUSE_PQ_HASH_BITS);\n}\n\n \nstatic void fuse_dev_wake_and_unlock(struct fuse_iqueue *fiq)\n__releases(fiq->lock)\n{\n\twake_up(&fiq->waitq);\n\tkill_fasync(&fiq->fasync, SIGIO, POLL_IN);\n\tspin_unlock(&fiq->lock);\n}\n\nconst struct fuse_iqueue_ops fuse_dev_fiq_ops = {\n\t.wake_forget_and_unlock\t\t= fuse_dev_wake_and_unlock,\n\t.wake_interrupt_and_unlock\t= fuse_dev_wake_and_unlock,\n\t.wake_pending_and_unlock\t= fuse_dev_wake_and_unlock,\n};\nEXPORT_SYMBOL_GPL(fuse_dev_fiq_ops);\n\nstatic void queue_request_and_unlock(struct fuse_iqueue *fiq,\n\t\t\t\t     struct fuse_req *req)\n__releases(fiq->lock)\n{\n\treq->in.h.len = sizeof(struct fuse_in_header) +\n\t\tfuse_len_args(req->args->in_numargs,\n\t\t\t      (struct fuse_arg *) req->args->in_args);\n\tlist_add_tail(&req->list, &fiq->pending);\n\tfiq->ops->wake_pending_and_unlock(fiq);\n}\n\nvoid fuse_queue_forget(struct fuse_conn *fc, struct fuse_forget_link *forget,\n\t\t       u64 nodeid, u64 nlookup)\n{\n\tstruct fuse_iqueue *fiq = &fc->iq;\n\n\tforget->forget_one.nodeid = nodeid;\n\tforget->forget_one.nlookup = nlookup;\n\n\tspin_lock(&fiq->lock);\n\tif (fiq->connected) {\n\t\tfiq->forget_list_tail->next = forget;\n\t\tfiq->forget_list_tail = forget;\n\t\tfiq->ops->wake_forget_and_unlock(fiq);\n\t} else {\n\t\tkfree(forget);\n\t\tspin_unlock(&fiq->lock);\n\t}\n}\n\nstatic void flush_bg_queue(struct fuse_conn *fc)\n{\n\tstruct fuse_iqueue *fiq = &fc->iq;\n\n\twhile (fc->active_background < fc->max_background &&\n\t       !list_empty(&fc->bg_queue)) {\n\t\tstruct fuse_req *req;\n\n\t\treq = list_first_entry(&fc->bg_queue, struct fuse_req, list);\n\t\tlist_del(&req->list);\n\t\tfc->active_background++;\n\t\tspin_lock(&fiq->lock);\n\t\treq->in.h.unique = fuse_get_unique(fiq);\n\t\tqueue_request_and_unlock(fiq, req);\n\t}\n}\n\n \nvoid fuse_request_end(struct fuse_req *req)\n{\n\tstruct fuse_mount *fm = req->fm;\n\tstruct fuse_conn *fc = fm->fc;\n\tstruct fuse_iqueue *fiq = &fc->iq;\n\n\tif (test_and_set_bit(FR_FINISHED, &req->flags))\n\t\tgoto put_request;\n\n\t \n\tif (test_bit(FR_INTERRUPTED, &req->flags)) {\n\t\tspin_lock(&fiq->lock);\n\t\tlist_del_init(&req->intr_entry);\n\t\tspin_unlock(&fiq->lock);\n\t}\n\tWARN_ON(test_bit(FR_PENDING, &req->flags));\n\tWARN_ON(test_bit(FR_SENT, &req->flags));\n\tif (test_bit(FR_BACKGROUND, &req->flags)) {\n\t\tspin_lock(&fc->bg_lock);\n\t\tclear_bit(FR_BACKGROUND, &req->flags);\n\t\tif (fc->num_background == fc->max_background) {\n\t\t\tfc->blocked = 0;\n\t\t\twake_up(&fc->blocked_waitq);\n\t\t} else if (!fc->blocked) {\n\t\t\t \n\t\t\tif (waitqueue_active(&fc->blocked_waitq))\n\t\t\t\twake_up(&fc->blocked_waitq);\n\t\t}\n\n\t\tfc->num_background--;\n\t\tfc->active_background--;\n\t\tflush_bg_queue(fc);\n\t\tspin_unlock(&fc->bg_lock);\n\t} else {\n\t\t \n\t\twake_up(&req->waitq);\n\t}\n\n\tif (test_bit(FR_ASYNC, &req->flags))\n\t\treq->args->end(fm, req->args, req->out.h.error);\nput_request:\n\tfuse_put_request(req);\n}\nEXPORT_SYMBOL_GPL(fuse_request_end);\n\nstatic int queue_interrupt(struct fuse_req *req)\n{\n\tstruct fuse_iqueue *fiq = &req->fm->fc->iq;\n\n\tspin_lock(&fiq->lock);\n\t \n\tif (unlikely(!test_bit(FR_INTERRUPTED, &req->flags))) {\n\t\tspin_unlock(&fiq->lock);\n\t\treturn -EINVAL;\n\t}\n\n\tif (list_empty(&req->intr_entry)) {\n\t\tlist_add_tail(&req->intr_entry, &fiq->interrupts);\n\t\t \n\t\tsmp_mb();\n\t\tif (test_bit(FR_FINISHED, &req->flags)) {\n\t\t\tlist_del_init(&req->intr_entry);\n\t\t\tspin_unlock(&fiq->lock);\n\t\t\treturn 0;\n\t\t}\n\t\tfiq->ops->wake_interrupt_and_unlock(fiq);\n\t} else {\n\t\tspin_unlock(&fiq->lock);\n\t}\n\treturn 0;\n}\n\nstatic void request_wait_answer(struct fuse_req *req)\n{\n\tstruct fuse_conn *fc = req->fm->fc;\n\tstruct fuse_iqueue *fiq = &fc->iq;\n\tint err;\n\n\tif (!fc->no_interrupt) {\n\t\t \n\t\terr = wait_event_interruptible(req->waitq,\n\t\t\t\t\ttest_bit(FR_FINISHED, &req->flags));\n\t\tif (!err)\n\t\t\treturn;\n\n\t\tset_bit(FR_INTERRUPTED, &req->flags);\n\t\t \n\t\tsmp_mb__after_atomic();\n\t\tif (test_bit(FR_SENT, &req->flags))\n\t\t\tqueue_interrupt(req);\n\t}\n\n\tif (!test_bit(FR_FORCE, &req->flags)) {\n\t\t \n\t\terr = wait_event_killable(req->waitq,\n\t\t\t\t\ttest_bit(FR_FINISHED, &req->flags));\n\t\tif (!err)\n\t\t\treturn;\n\n\t\tspin_lock(&fiq->lock);\n\t\t \n\t\tif (test_bit(FR_PENDING, &req->flags)) {\n\t\t\tlist_del(&req->list);\n\t\t\tspin_unlock(&fiq->lock);\n\t\t\t__fuse_put_request(req);\n\t\t\treq->out.h.error = -EINTR;\n\t\t\treturn;\n\t\t}\n\t\tspin_unlock(&fiq->lock);\n\t}\n\n\t \n\twait_event(req->waitq, test_bit(FR_FINISHED, &req->flags));\n}\n\nstatic void __fuse_request_send(struct fuse_req *req)\n{\n\tstruct fuse_iqueue *fiq = &req->fm->fc->iq;\n\n\tBUG_ON(test_bit(FR_BACKGROUND, &req->flags));\n\tspin_lock(&fiq->lock);\n\tif (!fiq->connected) {\n\t\tspin_unlock(&fiq->lock);\n\t\treq->out.h.error = -ENOTCONN;\n\t} else {\n\t\treq->in.h.unique = fuse_get_unique(fiq);\n\t\t \n\t\t__fuse_get_request(req);\n\t\tqueue_request_and_unlock(fiq, req);\n\n\t\trequest_wait_answer(req);\n\t\t \n\t\tsmp_rmb();\n\t}\n}\n\nstatic void fuse_adjust_compat(struct fuse_conn *fc, struct fuse_args *args)\n{\n\tif (fc->minor < 4 && args->opcode == FUSE_STATFS)\n\t\targs->out_args[0].size = FUSE_COMPAT_STATFS_SIZE;\n\n\tif (fc->minor < 9) {\n\t\tswitch (args->opcode) {\n\t\tcase FUSE_LOOKUP:\n\t\tcase FUSE_CREATE:\n\t\tcase FUSE_MKNOD:\n\t\tcase FUSE_MKDIR:\n\t\tcase FUSE_SYMLINK:\n\t\tcase FUSE_LINK:\n\t\t\targs->out_args[0].size = FUSE_COMPAT_ENTRY_OUT_SIZE;\n\t\t\tbreak;\n\t\tcase FUSE_GETATTR:\n\t\tcase FUSE_SETATTR:\n\t\t\targs->out_args[0].size = FUSE_COMPAT_ATTR_OUT_SIZE;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (fc->minor < 12) {\n\t\tswitch (args->opcode) {\n\t\tcase FUSE_CREATE:\n\t\t\targs->in_args[0].size = sizeof(struct fuse_open_in);\n\t\t\tbreak;\n\t\tcase FUSE_MKNOD:\n\t\t\targs->in_args[0].size = FUSE_COMPAT_MKNOD_IN_SIZE;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void fuse_force_creds(struct fuse_req *req)\n{\n\tstruct fuse_conn *fc = req->fm->fc;\n\n\treq->in.h.uid = from_kuid_munged(fc->user_ns, current_fsuid());\n\treq->in.h.gid = from_kgid_munged(fc->user_ns, current_fsgid());\n\treq->in.h.pid = pid_nr_ns(task_pid(current), fc->pid_ns);\n}\n\nstatic void fuse_args_to_req(struct fuse_req *req, struct fuse_args *args)\n{\n\treq->in.h.opcode = args->opcode;\n\treq->in.h.nodeid = args->nodeid;\n\treq->args = args;\n\tif (args->is_ext)\n\t\treq->in.h.total_extlen = args->in_args[args->ext_idx].size / 8;\n\tif (args->end)\n\t\t__set_bit(FR_ASYNC, &req->flags);\n}\n\nssize_t fuse_simple_request(struct fuse_mount *fm, struct fuse_args *args)\n{\n\tstruct fuse_conn *fc = fm->fc;\n\tstruct fuse_req *req;\n\tssize_t ret;\n\n\tif (args->force) {\n\t\tatomic_inc(&fc->num_waiting);\n\t\treq = fuse_request_alloc(fm, GFP_KERNEL | __GFP_NOFAIL);\n\n\t\tif (!args->nocreds)\n\t\t\tfuse_force_creds(req);\n\n\t\t__set_bit(FR_WAITING, &req->flags);\n\t\t__set_bit(FR_FORCE, &req->flags);\n\t} else {\n\t\tWARN_ON(args->nocreds);\n\t\treq = fuse_get_req(fm, false);\n\t\tif (IS_ERR(req))\n\t\t\treturn PTR_ERR(req);\n\t}\n\n\t \n\tfuse_adjust_compat(fc, args);\n\tfuse_args_to_req(req, args);\n\n\tif (!args->noreply)\n\t\t__set_bit(FR_ISREPLY, &req->flags);\n\t__fuse_request_send(req);\n\tret = req->out.h.error;\n\tif (!ret && args->out_argvar) {\n\t\tBUG_ON(args->out_numargs == 0);\n\t\tret = args->out_args[args->out_numargs - 1].size;\n\t}\n\tfuse_put_request(req);\n\n\treturn ret;\n}\n\nstatic bool fuse_request_queue_background(struct fuse_req *req)\n{\n\tstruct fuse_mount *fm = req->fm;\n\tstruct fuse_conn *fc = fm->fc;\n\tbool queued = false;\n\n\tWARN_ON(!test_bit(FR_BACKGROUND, &req->flags));\n\tif (!test_bit(FR_WAITING, &req->flags)) {\n\t\t__set_bit(FR_WAITING, &req->flags);\n\t\tatomic_inc(&fc->num_waiting);\n\t}\n\t__set_bit(FR_ISREPLY, &req->flags);\n\tspin_lock(&fc->bg_lock);\n\tif (likely(fc->connected)) {\n\t\tfc->num_background++;\n\t\tif (fc->num_background == fc->max_background)\n\t\t\tfc->blocked = 1;\n\t\tlist_add_tail(&req->list, &fc->bg_queue);\n\t\tflush_bg_queue(fc);\n\t\tqueued = true;\n\t}\n\tspin_unlock(&fc->bg_lock);\n\n\treturn queued;\n}\n\nint fuse_simple_background(struct fuse_mount *fm, struct fuse_args *args,\n\t\t\t    gfp_t gfp_flags)\n{\n\tstruct fuse_req *req;\n\n\tif (args->force) {\n\t\tWARN_ON(!args->nocreds);\n\t\treq = fuse_request_alloc(fm, gfp_flags);\n\t\tif (!req)\n\t\t\treturn -ENOMEM;\n\t\t__set_bit(FR_BACKGROUND, &req->flags);\n\t} else {\n\t\tWARN_ON(args->nocreds);\n\t\treq = fuse_get_req(fm, true);\n\t\tif (IS_ERR(req))\n\t\t\treturn PTR_ERR(req);\n\t}\n\n\tfuse_args_to_req(req, args);\n\n\tif (!fuse_request_queue_background(req)) {\n\t\tfuse_put_request(req);\n\t\treturn -ENOTCONN;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(fuse_simple_background);\n\nstatic int fuse_simple_notify_reply(struct fuse_mount *fm,\n\t\t\t\t    struct fuse_args *args, u64 unique)\n{\n\tstruct fuse_req *req;\n\tstruct fuse_iqueue *fiq = &fm->fc->iq;\n\tint err = 0;\n\n\treq = fuse_get_req(fm, false);\n\tif (IS_ERR(req))\n\t\treturn PTR_ERR(req);\n\n\t__clear_bit(FR_ISREPLY, &req->flags);\n\treq->in.h.unique = unique;\n\n\tfuse_args_to_req(req, args);\n\n\tspin_lock(&fiq->lock);\n\tif (fiq->connected) {\n\t\tqueue_request_and_unlock(fiq, req);\n\t} else {\n\t\terr = -ENODEV;\n\t\tspin_unlock(&fiq->lock);\n\t\tfuse_put_request(req);\n\t}\n\n\treturn err;\n}\n\n \nstatic int lock_request(struct fuse_req *req)\n{\n\tint err = 0;\n\tif (req) {\n\t\tspin_lock(&req->waitq.lock);\n\t\tif (test_bit(FR_ABORTED, &req->flags))\n\t\t\terr = -ENOENT;\n\t\telse\n\t\t\tset_bit(FR_LOCKED, &req->flags);\n\t\tspin_unlock(&req->waitq.lock);\n\t}\n\treturn err;\n}\n\n \nstatic int unlock_request(struct fuse_req *req)\n{\n\tint err = 0;\n\tif (req) {\n\t\tspin_lock(&req->waitq.lock);\n\t\tif (test_bit(FR_ABORTED, &req->flags))\n\t\t\terr = -ENOENT;\n\t\telse\n\t\t\tclear_bit(FR_LOCKED, &req->flags);\n\t\tspin_unlock(&req->waitq.lock);\n\t}\n\treturn err;\n}\n\nstruct fuse_copy_state {\n\tint write;\n\tstruct fuse_req *req;\n\tstruct iov_iter *iter;\n\tstruct pipe_buffer *pipebufs;\n\tstruct pipe_buffer *currbuf;\n\tstruct pipe_inode_info *pipe;\n\tunsigned long nr_segs;\n\tstruct page *pg;\n\tunsigned len;\n\tunsigned offset;\n\tunsigned move_pages:1;\n};\n\nstatic void fuse_copy_init(struct fuse_copy_state *cs, int write,\n\t\t\t   struct iov_iter *iter)\n{\n\tmemset(cs, 0, sizeof(*cs));\n\tcs->write = write;\n\tcs->iter = iter;\n}\n\n \nstatic void fuse_copy_finish(struct fuse_copy_state *cs)\n{\n\tif (cs->currbuf) {\n\t\tstruct pipe_buffer *buf = cs->currbuf;\n\n\t\tif (cs->write)\n\t\t\tbuf->len = PAGE_SIZE - cs->len;\n\t\tcs->currbuf = NULL;\n\t} else if (cs->pg) {\n\t\tif (cs->write) {\n\t\t\tflush_dcache_page(cs->pg);\n\t\t\tset_page_dirty_lock(cs->pg);\n\t\t}\n\t\tput_page(cs->pg);\n\t}\n\tcs->pg = NULL;\n}\n\n \nstatic int fuse_copy_fill(struct fuse_copy_state *cs)\n{\n\tstruct page *page;\n\tint err;\n\n\terr = unlock_request(cs->req);\n\tif (err)\n\t\treturn err;\n\n\tfuse_copy_finish(cs);\n\tif (cs->pipebufs) {\n\t\tstruct pipe_buffer *buf = cs->pipebufs;\n\n\t\tif (!cs->write) {\n\t\t\terr = pipe_buf_confirm(cs->pipe, buf);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\tBUG_ON(!cs->nr_segs);\n\t\t\tcs->currbuf = buf;\n\t\t\tcs->pg = buf->page;\n\t\t\tcs->offset = buf->offset;\n\t\t\tcs->len = buf->len;\n\t\t\tcs->pipebufs++;\n\t\t\tcs->nr_segs--;\n\t\t} else {\n\t\t\tif (cs->nr_segs >= cs->pipe->max_usage)\n\t\t\t\treturn -EIO;\n\n\t\t\tpage = alloc_page(GFP_HIGHUSER);\n\t\t\tif (!page)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tbuf->page = page;\n\t\t\tbuf->offset = 0;\n\t\t\tbuf->len = 0;\n\n\t\t\tcs->currbuf = buf;\n\t\t\tcs->pg = page;\n\t\t\tcs->offset = 0;\n\t\t\tcs->len = PAGE_SIZE;\n\t\t\tcs->pipebufs++;\n\t\t\tcs->nr_segs++;\n\t\t}\n\t} else {\n\t\tsize_t off;\n\t\terr = iov_iter_get_pages2(cs->iter, &page, PAGE_SIZE, 1, &off);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tBUG_ON(!err);\n\t\tcs->len = err;\n\t\tcs->offset = off;\n\t\tcs->pg = page;\n\t}\n\n\treturn lock_request(cs->req);\n}\n\n \nstatic int fuse_copy_do(struct fuse_copy_state *cs, void **val, unsigned *size)\n{\n\tunsigned ncpy = min(*size, cs->len);\n\tif (val) {\n\t\tvoid *pgaddr = kmap_local_page(cs->pg);\n\t\tvoid *buf = pgaddr + cs->offset;\n\n\t\tif (cs->write)\n\t\t\tmemcpy(buf, *val, ncpy);\n\t\telse\n\t\t\tmemcpy(*val, buf, ncpy);\n\n\t\tkunmap_local(pgaddr);\n\t\t*val += ncpy;\n\t}\n\t*size -= ncpy;\n\tcs->len -= ncpy;\n\tcs->offset += ncpy;\n\treturn ncpy;\n}\n\nstatic int fuse_check_folio(struct folio *folio)\n{\n\tif (folio_mapped(folio) ||\n\t    folio->mapping != NULL ||\n\t    (folio->flags & PAGE_FLAGS_CHECK_AT_PREP &\n\t     ~(1 << PG_locked |\n\t       1 << PG_referenced |\n\t       1 << PG_uptodate |\n\t       1 << PG_lru |\n\t       1 << PG_active |\n\t       1 << PG_workingset |\n\t       1 << PG_reclaim |\n\t       1 << PG_waiters |\n\t       LRU_GEN_MASK | LRU_REFS_MASK))) {\n\t\tdump_page(&folio->page, \"fuse: trying to steal weird page\");\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic int fuse_try_move_page(struct fuse_copy_state *cs, struct page **pagep)\n{\n\tint err;\n\tstruct folio *oldfolio = page_folio(*pagep);\n\tstruct folio *newfolio;\n\tstruct pipe_buffer *buf = cs->pipebufs;\n\n\tfolio_get(oldfolio);\n\terr = unlock_request(cs->req);\n\tif (err)\n\t\tgoto out_put_old;\n\n\tfuse_copy_finish(cs);\n\n\terr = pipe_buf_confirm(cs->pipe, buf);\n\tif (err)\n\t\tgoto out_put_old;\n\n\tBUG_ON(!cs->nr_segs);\n\tcs->currbuf = buf;\n\tcs->len = buf->len;\n\tcs->pipebufs++;\n\tcs->nr_segs--;\n\n\tif (cs->len != PAGE_SIZE)\n\t\tgoto out_fallback;\n\n\tif (!pipe_buf_try_steal(cs->pipe, buf))\n\t\tgoto out_fallback;\n\n\tnewfolio = page_folio(buf->page);\n\n\tif (!folio_test_uptodate(newfolio))\n\t\tfolio_mark_uptodate(newfolio);\n\n\tfolio_clear_mappedtodisk(newfolio);\n\n\tif (fuse_check_folio(newfolio) != 0)\n\t\tgoto out_fallback_unlock;\n\n\t \n\tif (WARN_ON(folio_mapped(oldfolio)))\n\t\tgoto out_fallback_unlock;\n\tif (WARN_ON(folio_has_private(oldfolio)))\n\t\tgoto out_fallback_unlock;\n\tif (WARN_ON(folio_test_dirty(oldfolio) ||\n\t\t\t\tfolio_test_writeback(oldfolio)))\n\t\tgoto out_fallback_unlock;\n\tif (WARN_ON(folio_test_mlocked(oldfolio)))\n\t\tgoto out_fallback_unlock;\n\n\treplace_page_cache_folio(oldfolio, newfolio);\n\n\tfolio_get(newfolio);\n\n\tif (!(buf->flags & PIPE_BUF_FLAG_LRU))\n\t\tfolio_add_lru(newfolio);\n\n\t \n\tpipe_buf_release(cs->pipe, buf);\n\n\terr = 0;\n\tspin_lock(&cs->req->waitq.lock);\n\tif (test_bit(FR_ABORTED, &cs->req->flags))\n\t\terr = -ENOENT;\n\telse\n\t\t*pagep = &newfolio->page;\n\tspin_unlock(&cs->req->waitq.lock);\n\n\tif (err) {\n\t\tfolio_unlock(newfolio);\n\t\tfolio_put(newfolio);\n\t\tgoto out_put_old;\n\t}\n\n\tfolio_unlock(oldfolio);\n\t \n\tfolio_put(oldfolio);\n\tcs->len = 0;\n\n\terr = 0;\nout_put_old:\n\t \n\tfolio_put(oldfolio);\n\treturn err;\n\nout_fallback_unlock:\n\tfolio_unlock(newfolio);\nout_fallback:\n\tcs->pg = buf->page;\n\tcs->offset = buf->offset;\n\n\terr = lock_request(cs->req);\n\tif (!err)\n\t\terr = 1;\n\n\tgoto out_put_old;\n}\n\nstatic int fuse_ref_page(struct fuse_copy_state *cs, struct page *page,\n\t\t\t unsigned offset, unsigned count)\n{\n\tstruct pipe_buffer *buf;\n\tint err;\n\n\tif (cs->nr_segs >= cs->pipe->max_usage)\n\t\treturn -EIO;\n\n\tget_page(page);\n\terr = unlock_request(cs->req);\n\tif (err) {\n\t\tput_page(page);\n\t\treturn err;\n\t}\n\n\tfuse_copy_finish(cs);\n\n\tbuf = cs->pipebufs;\n\tbuf->page = page;\n\tbuf->offset = offset;\n\tbuf->len = count;\n\n\tcs->pipebufs++;\n\tcs->nr_segs++;\n\tcs->len = 0;\n\n\treturn 0;\n}\n\n \nstatic int fuse_copy_page(struct fuse_copy_state *cs, struct page **pagep,\n\t\t\t  unsigned offset, unsigned count, int zeroing)\n{\n\tint err;\n\tstruct page *page = *pagep;\n\n\tif (page && zeroing && count < PAGE_SIZE)\n\t\tclear_highpage(page);\n\n\twhile (count) {\n\t\tif (cs->write && cs->pipebufs && page) {\n\t\t\t \n\t\t\tif (cs->req->args->user_pages) {\n\t\t\t\terr = fuse_copy_fill(cs);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t} else {\n\t\t\t\treturn fuse_ref_page(cs, page, offset, count);\n\t\t\t}\n\t\t} else if (!cs->len) {\n\t\t\tif (cs->move_pages && page &&\n\t\t\t    offset == 0 && count == PAGE_SIZE) {\n\t\t\t\terr = fuse_try_move_page(cs, pagep);\n\t\t\t\tif (err <= 0)\n\t\t\t\t\treturn err;\n\t\t\t} else {\n\t\t\t\terr = fuse_copy_fill(cs);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t\tif (page) {\n\t\t\tvoid *mapaddr = kmap_local_page(page);\n\t\t\tvoid *buf = mapaddr + offset;\n\t\t\toffset += fuse_copy_do(cs, &buf, &count);\n\t\t\tkunmap_local(mapaddr);\n\t\t} else\n\t\t\toffset += fuse_copy_do(cs, NULL, &count);\n\t}\n\tif (page && !cs->write)\n\t\tflush_dcache_page(page);\n\treturn 0;\n}\n\n \nstatic int fuse_copy_pages(struct fuse_copy_state *cs, unsigned nbytes,\n\t\t\t   int zeroing)\n{\n\tunsigned i;\n\tstruct fuse_req *req = cs->req;\n\tstruct fuse_args_pages *ap = container_of(req->args, typeof(*ap), args);\n\n\n\tfor (i = 0; i < ap->num_pages && (nbytes || zeroing); i++) {\n\t\tint err;\n\t\tunsigned int offset = ap->descs[i].offset;\n\t\tunsigned int count = min(nbytes, ap->descs[i].length);\n\n\t\terr = fuse_copy_page(cs, &ap->pages[i], offset, count, zeroing);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tnbytes -= count;\n\t}\n\treturn 0;\n}\n\n \nstatic int fuse_copy_one(struct fuse_copy_state *cs, void *val, unsigned size)\n{\n\twhile (size) {\n\t\tif (!cs->len) {\n\t\t\tint err = fuse_copy_fill(cs);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\tfuse_copy_do(cs, &val, &size);\n\t}\n\treturn 0;\n}\n\n \nstatic int fuse_copy_args(struct fuse_copy_state *cs, unsigned numargs,\n\t\t\t  unsigned argpages, struct fuse_arg *args,\n\t\t\t  int zeroing)\n{\n\tint err = 0;\n\tunsigned i;\n\n\tfor (i = 0; !err && i < numargs; i++)  {\n\t\tstruct fuse_arg *arg = &args[i];\n\t\tif (i == numargs - 1 && argpages)\n\t\t\terr = fuse_copy_pages(cs, arg->size, zeroing);\n\t\telse\n\t\t\terr = fuse_copy_one(cs, arg->value, arg->size);\n\t}\n\treturn err;\n}\n\nstatic int forget_pending(struct fuse_iqueue *fiq)\n{\n\treturn fiq->forget_list_head.next != NULL;\n}\n\nstatic int request_pending(struct fuse_iqueue *fiq)\n{\n\treturn !list_empty(&fiq->pending) || !list_empty(&fiq->interrupts) ||\n\t\tforget_pending(fiq);\n}\n\n \nstatic int fuse_read_interrupt(struct fuse_iqueue *fiq,\n\t\t\t       struct fuse_copy_state *cs,\n\t\t\t       size_t nbytes, struct fuse_req *req)\n__releases(fiq->lock)\n{\n\tstruct fuse_in_header ih;\n\tstruct fuse_interrupt_in arg;\n\tunsigned reqsize = sizeof(ih) + sizeof(arg);\n\tint err;\n\n\tlist_del_init(&req->intr_entry);\n\tmemset(&ih, 0, sizeof(ih));\n\tmemset(&arg, 0, sizeof(arg));\n\tih.len = reqsize;\n\tih.opcode = FUSE_INTERRUPT;\n\tih.unique = (req->in.h.unique | FUSE_INT_REQ_BIT);\n\targ.unique = req->in.h.unique;\n\n\tspin_unlock(&fiq->lock);\n\tif (nbytes < reqsize)\n\t\treturn -EINVAL;\n\n\terr = fuse_copy_one(cs, &ih, sizeof(ih));\n\tif (!err)\n\t\terr = fuse_copy_one(cs, &arg, sizeof(arg));\n\tfuse_copy_finish(cs);\n\n\treturn err ? err : reqsize;\n}\n\nstruct fuse_forget_link *fuse_dequeue_forget(struct fuse_iqueue *fiq,\n\t\t\t\t\t     unsigned int max,\n\t\t\t\t\t     unsigned int *countp)\n{\n\tstruct fuse_forget_link *head = fiq->forget_list_head.next;\n\tstruct fuse_forget_link **newhead = &head;\n\tunsigned count;\n\n\tfor (count = 0; *newhead != NULL && count < max; count++)\n\t\tnewhead = &(*newhead)->next;\n\n\tfiq->forget_list_head.next = *newhead;\n\t*newhead = NULL;\n\tif (fiq->forget_list_head.next == NULL)\n\t\tfiq->forget_list_tail = &fiq->forget_list_head;\n\n\tif (countp != NULL)\n\t\t*countp = count;\n\n\treturn head;\n}\nEXPORT_SYMBOL(fuse_dequeue_forget);\n\nstatic int fuse_read_single_forget(struct fuse_iqueue *fiq,\n\t\t\t\t   struct fuse_copy_state *cs,\n\t\t\t\t   size_t nbytes)\n__releases(fiq->lock)\n{\n\tint err;\n\tstruct fuse_forget_link *forget = fuse_dequeue_forget(fiq, 1, NULL);\n\tstruct fuse_forget_in arg = {\n\t\t.nlookup = forget->forget_one.nlookup,\n\t};\n\tstruct fuse_in_header ih = {\n\t\t.opcode = FUSE_FORGET,\n\t\t.nodeid = forget->forget_one.nodeid,\n\t\t.unique = fuse_get_unique(fiq),\n\t\t.len = sizeof(ih) + sizeof(arg),\n\t};\n\n\tspin_unlock(&fiq->lock);\n\tkfree(forget);\n\tif (nbytes < ih.len)\n\t\treturn -EINVAL;\n\n\terr = fuse_copy_one(cs, &ih, sizeof(ih));\n\tif (!err)\n\t\terr = fuse_copy_one(cs, &arg, sizeof(arg));\n\tfuse_copy_finish(cs);\n\n\tif (err)\n\t\treturn err;\n\n\treturn ih.len;\n}\n\nstatic int fuse_read_batch_forget(struct fuse_iqueue *fiq,\n\t\t\t\t   struct fuse_copy_state *cs, size_t nbytes)\n__releases(fiq->lock)\n{\n\tint err;\n\tunsigned max_forgets;\n\tunsigned count;\n\tstruct fuse_forget_link *head;\n\tstruct fuse_batch_forget_in arg = { .count = 0 };\n\tstruct fuse_in_header ih = {\n\t\t.opcode = FUSE_BATCH_FORGET,\n\t\t.unique = fuse_get_unique(fiq),\n\t\t.len = sizeof(ih) + sizeof(arg),\n\t};\n\n\tif (nbytes < ih.len) {\n\t\tspin_unlock(&fiq->lock);\n\t\treturn -EINVAL;\n\t}\n\n\tmax_forgets = (nbytes - ih.len) / sizeof(struct fuse_forget_one);\n\thead = fuse_dequeue_forget(fiq, max_forgets, &count);\n\tspin_unlock(&fiq->lock);\n\n\targ.count = count;\n\tih.len += count * sizeof(struct fuse_forget_one);\n\terr = fuse_copy_one(cs, &ih, sizeof(ih));\n\tif (!err)\n\t\terr = fuse_copy_one(cs, &arg, sizeof(arg));\n\n\twhile (head) {\n\t\tstruct fuse_forget_link *forget = head;\n\n\t\tif (!err) {\n\t\t\terr = fuse_copy_one(cs, &forget->forget_one,\n\t\t\t\t\t    sizeof(forget->forget_one));\n\t\t}\n\t\thead = forget->next;\n\t\tkfree(forget);\n\t}\n\n\tfuse_copy_finish(cs);\n\n\tif (err)\n\t\treturn err;\n\n\treturn ih.len;\n}\n\nstatic int fuse_read_forget(struct fuse_conn *fc, struct fuse_iqueue *fiq,\n\t\t\t    struct fuse_copy_state *cs,\n\t\t\t    size_t nbytes)\n__releases(fiq->lock)\n{\n\tif (fc->minor < 16 || fiq->forget_list_head.next->next == NULL)\n\t\treturn fuse_read_single_forget(fiq, cs, nbytes);\n\telse\n\t\treturn fuse_read_batch_forget(fiq, cs, nbytes);\n}\n\n \nstatic ssize_t fuse_dev_do_read(struct fuse_dev *fud, struct file *file,\n\t\t\t\tstruct fuse_copy_state *cs, size_t nbytes)\n{\n\tssize_t err;\n\tstruct fuse_conn *fc = fud->fc;\n\tstruct fuse_iqueue *fiq = &fc->iq;\n\tstruct fuse_pqueue *fpq = &fud->pq;\n\tstruct fuse_req *req;\n\tstruct fuse_args *args;\n\tunsigned reqsize;\n\tunsigned int hash;\n\n\t \n\tif (nbytes < max_t(size_t, FUSE_MIN_READ_BUFFER,\n\t\t\t   sizeof(struct fuse_in_header) +\n\t\t\t   sizeof(struct fuse_write_in) +\n\t\t\t   fc->max_write))\n\t\treturn -EINVAL;\n\n restart:\n\tfor (;;) {\n\t\tspin_lock(&fiq->lock);\n\t\tif (!fiq->connected || request_pending(fiq))\n\t\t\tbreak;\n\t\tspin_unlock(&fiq->lock);\n\n\t\tif (file->f_flags & O_NONBLOCK)\n\t\t\treturn -EAGAIN;\n\t\terr = wait_event_interruptible_exclusive(fiq->waitq,\n\t\t\t\t!fiq->connected || request_pending(fiq));\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (!fiq->connected) {\n\t\terr = fc->aborted ? -ECONNABORTED : -ENODEV;\n\t\tgoto err_unlock;\n\t}\n\n\tif (!list_empty(&fiq->interrupts)) {\n\t\treq = list_entry(fiq->interrupts.next, struct fuse_req,\n\t\t\t\t intr_entry);\n\t\treturn fuse_read_interrupt(fiq, cs, nbytes, req);\n\t}\n\n\tif (forget_pending(fiq)) {\n\t\tif (list_empty(&fiq->pending) || fiq->forget_batch-- > 0)\n\t\t\treturn fuse_read_forget(fc, fiq, cs, nbytes);\n\n\t\tif (fiq->forget_batch <= -8)\n\t\t\tfiq->forget_batch = 16;\n\t}\n\n\treq = list_entry(fiq->pending.next, struct fuse_req, list);\n\tclear_bit(FR_PENDING, &req->flags);\n\tlist_del_init(&req->list);\n\tspin_unlock(&fiq->lock);\n\n\targs = req->args;\n\treqsize = req->in.h.len;\n\n\t \n\tif (nbytes < reqsize) {\n\t\treq->out.h.error = -EIO;\n\t\t \n\t\tif (args->opcode == FUSE_SETXATTR)\n\t\t\treq->out.h.error = -E2BIG;\n\t\tfuse_request_end(req);\n\t\tgoto restart;\n\t}\n\tspin_lock(&fpq->lock);\n\t \n\tif (!fpq->connected) {\n\t\treq->out.h.error = err = -ECONNABORTED;\n\t\tgoto out_end;\n\n\t}\n\tlist_add(&req->list, &fpq->io);\n\tspin_unlock(&fpq->lock);\n\tcs->req = req;\n\terr = fuse_copy_one(cs, &req->in.h, sizeof(req->in.h));\n\tif (!err)\n\t\terr = fuse_copy_args(cs, args->in_numargs, args->in_pages,\n\t\t\t\t     (struct fuse_arg *) args->in_args, 0);\n\tfuse_copy_finish(cs);\n\tspin_lock(&fpq->lock);\n\tclear_bit(FR_LOCKED, &req->flags);\n\tif (!fpq->connected) {\n\t\terr = fc->aborted ? -ECONNABORTED : -ENODEV;\n\t\tgoto out_end;\n\t}\n\tif (err) {\n\t\treq->out.h.error = -EIO;\n\t\tgoto out_end;\n\t}\n\tif (!test_bit(FR_ISREPLY, &req->flags)) {\n\t\terr = reqsize;\n\t\tgoto out_end;\n\t}\n\thash = fuse_req_hash(req->in.h.unique);\n\tlist_move_tail(&req->list, &fpq->processing[hash]);\n\t__fuse_get_request(req);\n\tset_bit(FR_SENT, &req->flags);\n\tspin_unlock(&fpq->lock);\n\t \n\tsmp_mb__after_atomic();\n\tif (test_bit(FR_INTERRUPTED, &req->flags))\n\t\tqueue_interrupt(req);\n\tfuse_put_request(req);\n\n\treturn reqsize;\n\nout_end:\n\tif (!test_bit(FR_PRIVATE, &req->flags))\n\t\tlist_del_init(&req->list);\n\tspin_unlock(&fpq->lock);\n\tfuse_request_end(req);\n\treturn err;\n\n err_unlock:\n\tspin_unlock(&fiq->lock);\n\treturn err;\n}\n\nstatic int fuse_dev_open(struct inode *inode, struct file *file)\n{\n\t \n\tfile->private_data = NULL;\n\treturn 0;\n}\n\nstatic ssize_t fuse_dev_read(struct kiocb *iocb, struct iov_iter *to)\n{\n\tstruct fuse_copy_state cs;\n\tstruct file *file = iocb->ki_filp;\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tif (!user_backed_iter(to))\n\t\treturn -EINVAL;\n\n\tfuse_copy_init(&cs, 1, to);\n\n\treturn fuse_dev_do_read(fud, file, &cs, iov_iter_count(to));\n}\n\nstatic ssize_t fuse_dev_splice_read(struct file *in, loff_t *ppos,\n\t\t\t\t    struct pipe_inode_info *pipe,\n\t\t\t\t    size_t len, unsigned int flags)\n{\n\tint total, ret;\n\tint page_nr = 0;\n\tstruct pipe_buffer *bufs;\n\tstruct fuse_copy_state cs;\n\tstruct fuse_dev *fud = fuse_get_dev(in);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tbufs = kvmalloc_array(pipe->max_usage, sizeof(struct pipe_buffer),\n\t\t\t      GFP_KERNEL);\n\tif (!bufs)\n\t\treturn -ENOMEM;\n\n\tfuse_copy_init(&cs, 1, NULL);\n\tcs.pipebufs = bufs;\n\tcs.pipe = pipe;\n\tret = fuse_dev_do_read(fud, in, &cs, len);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (pipe_occupancy(pipe->head, pipe->tail) + cs.nr_segs > pipe->max_usage) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tfor (ret = total = 0; page_nr < cs.nr_segs; total += ret) {\n\t\t \n\t\tbufs[page_nr].ops = &nosteal_pipe_buf_ops;\n\t\tbufs[page_nr].flags = 0;\n\t\tret = add_to_pipe(pipe, &bufs[page_nr++]);\n\t\tif (unlikely(ret < 0))\n\t\t\tbreak;\n\t}\n\tif (total)\n\t\tret = total;\nout:\n\tfor (; page_nr < cs.nr_segs; page_nr++)\n\t\tput_page(bufs[page_nr].page);\n\n\tkvfree(bufs);\n\treturn ret;\n}\n\nstatic int fuse_notify_poll(struct fuse_conn *fc, unsigned int size,\n\t\t\t    struct fuse_copy_state *cs)\n{\n\tstruct fuse_notify_poll_wakeup_out outarg;\n\tint err = -EINVAL;\n\n\tif (size != sizeof(outarg))\n\t\tgoto err;\n\n\terr = fuse_copy_one(cs, &outarg, sizeof(outarg));\n\tif (err)\n\t\tgoto err;\n\n\tfuse_copy_finish(cs);\n\treturn fuse_notify_poll_wakeup(fc, &outarg);\n\nerr:\n\tfuse_copy_finish(cs);\n\treturn err;\n}\n\nstatic int fuse_notify_inval_inode(struct fuse_conn *fc, unsigned int size,\n\t\t\t\t   struct fuse_copy_state *cs)\n{\n\tstruct fuse_notify_inval_inode_out outarg;\n\tint err = -EINVAL;\n\n\tif (size != sizeof(outarg))\n\t\tgoto err;\n\n\terr = fuse_copy_one(cs, &outarg, sizeof(outarg));\n\tif (err)\n\t\tgoto err;\n\tfuse_copy_finish(cs);\n\n\tdown_read(&fc->killsb);\n\terr = fuse_reverse_inval_inode(fc, outarg.ino,\n\t\t\t\t       outarg.off, outarg.len);\n\tup_read(&fc->killsb);\n\treturn err;\n\nerr:\n\tfuse_copy_finish(cs);\n\treturn err;\n}\n\nstatic int fuse_notify_inval_entry(struct fuse_conn *fc, unsigned int size,\n\t\t\t\t   struct fuse_copy_state *cs)\n{\n\tstruct fuse_notify_inval_entry_out outarg;\n\tint err = -ENOMEM;\n\tchar *buf;\n\tstruct qstr name;\n\n\tbuf = kzalloc(FUSE_NAME_MAX + 1, GFP_KERNEL);\n\tif (!buf)\n\t\tgoto err;\n\n\terr = -EINVAL;\n\tif (size < sizeof(outarg))\n\t\tgoto err;\n\n\terr = fuse_copy_one(cs, &outarg, sizeof(outarg));\n\tif (err)\n\t\tgoto err;\n\n\terr = -ENAMETOOLONG;\n\tif (outarg.namelen > FUSE_NAME_MAX)\n\t\tgoto err;\n\n\terr = -EINVAL;\n\tif (size != sizeof(outarg) + outarg.namelen + 1)\n\t\tgoto err;\n\n\tname.name = buf;\n\tname.len = outarg.namelen;\n\terr = fuse_copy_one(cs, buf, outarg.namelen + 1);\n\tif (err)\n\t\tgoto err;\n\tfuse_copy_finish(cs);\n\tbuf[outarg.namelen] = 0;\n\n\tdown_read(&fc->killsb);\n\terr = fuse_reverse_inval_entry(fc, outarg.parent, 0, &name, outarg.flags);\n\tup_read(&fc->killsb);\n\tkfree(buf);\n\treturn err;\n\nerr:\n\tkfree(buf);\n\tfuse_copy_finish(cs);\n\treturn err;\n}\n\nstatic int fuse_notify_delete(struct fuse_conn *fc, unsigned int size,\n\t\t\t      struct fuse_copy_state *cs)\n{\n\tstruct fuse_notify_delete_out outarg;\n\tint err = -ENOMEM;\n\tchar *buf;\n\tstruct qstr name;\n\n\tbuf = kzalloc(FUSE_NAME_MAX + 1, GFP_KERNEL);\n\tif (!buf)\n\t\tgoto err;\n\n\terr = -EINVAL;\n\tif (size < sizeof(outarg))\n\t\tgoto err;\n\n\terr = fuse_copy_one(cs, &outarg, sizeof(outarg));\n\tif (err)\n\t\tgoto err;\n\n\terr = -ENAMETOOLONG;\n\tif (outarg.namelen > FUSE_NAME_MAX)\n\t\tgoto err;\n\n\terr = -EINVAL;\n\tif (size != sizeof(outarg) + outarg.namelen + 1)\n\t\tgoto err;\n\n\tname.name = buf;\n\tname.len = outarg.namelen;\n\terr = fuse_copy_one(cs, buf, outarg.namelen + 1);\n\tif (err)\n\t\tgoto err;\n\tfuse_copy_finish(cs);\n\tbuf[outarg.namelen] = 0;\n\n\tdown_read(&fc->killsb);\n\terr = fuse_reverse_inval_entry(fc, outarg.parent, outarg.child, &name, 0);\n\tup_read(&fc->killsb);\n\tkfree(buf);\n\treturn err;\n\nerr:\n\tkfree(buf);\n\tfuse_copy_finish(cs);\n\treturn err;\n}\n\nstatic int fuse_notify_store(struct fuse_conn *fc, unsigned int size,\n\t\t\t     struct fuse_copy_state *cs)\n{\n\tstruct fuse_notify_store_out outarg;\n\tstruct inode *inode;\n\tstruct address_space *mapping;\n\tu64 nodeid;\n\tint err;\n\tpgoff_t index;\n\tunsigned int offset;\n\tunsigned int num;\n\tloff_t file_size;\n\tloff_t end;\n\n\terr = -EINVAL;\n\tif (size < sizeof(outarg))\n\t\tgoto out_finish;\n\n\terr = fuse_copy_one(cs, &outarg, sizeof(outarg));\n\tif (err)\n\t\tgoto out_finish;\n\n\terr = -EINVAL;\n\tif (size - sizeof(outarg) != outarg.size)\n\t\tgoto out_finish;\n\n\tnodeid = outarg.nodeid;\n\n\tdown_read(&fc->killsb);\n\n\terr = -ENOENT;\n\tinode = fuse_ilookup(fc, nodeid,  NULL);\n\tif (!inode)\n\t\tgoto out_up_killsb;\n\n\tmapping = inode->i_mapping;\n\tindex = outarg.offset >> PAGE_SHIFT;\n\toffset = outarg.offset & ~PAGE_MASK;\n\tfile_size = i_size_read(inode);\n\tend = outarg.offset + outarg.size;\n\tif (end > file_size) {\n\t\tfile_size = end;\n\t\tfuse_write_update_attr(inode, file_size, outarg.size);\n\t}\n\n\tnum = outarg.size;\n\twhile (num) {\n\t\tstruct page *page;\n\t\tunsigned int this_num;\n\n\t\terr = -ENOMEM;\n\t\tpage = find_or_create_page(mapping, index,\n\t\t\t\t\t   mapping_gfp_mask(mapping));\n\t\tif (!page)\n\t\t\tgoto out_iput;\n\n\t\tthis_num = min_t(unsigned, num, PAGE_SIZE - offset);\n\t\terr = fuse_copy_page(cs, &page, offset, this_num, 0);\n\t\tif (!err && offset == 0 &&\n\t\t    (this_num == PAGE_SIZE || file_size == end))\n\t\t\tSetPageUptodate(page);\n\t\tunlock_page(page);\n\t\tput_page(page);\n\n\t\tif (err)\n\t\t\tgoto out_iput;\n\n\t\tnum -= this_num;\n\t\toffset = 0;\n\t\tindex++;\n\t}\n\n\terr = 0;\n\nout_iput:\n\tiput(inode);\nout_up_killsb:\n\tup_read(&fc->killsb);\nout_finish:\n\tfuse_copy_finish(cs);\n\treturn err;\n}\n\nstruct fuse_retrieve_args {\n\tstruct fuse_args_pages ap;\n\tstruct fuse_notify_retrieve_in inarg;\n};\n\nstatic void fuse_retrieve_end(struct fuse_mount *fm, struct fuse_args *args,\n\t\t\t      int error)\n{\n\tstruct fuse_retrieve_args *ra =\n\t\tcontainer_of(args, typeof(*ra), ap.args);\n\n\trelease_pages(ra->ap.pages, ra->ap.num_pages);\n\tkfree(ra);\n}\n\nstatic int fuse_retrieve(struct fuse_mount *fm, struct inode *inode,\n\t\t\t struct fuse_notify_retrieve_out *outarg)\n{\n\tint err;\n\tstruct address_space *mapping = inode->i_mapping;\n\tpgoff_t index;\n\tloff_t file_size;\n\tunsigned int num;\n\tunsigned int offset;\n\tsize_t total_len = 0;\n\tunsigned int num_pages;\n\tstruct fuse_conn *fc = fm->fc;\n\tstruct fuse_retrieve_args *ra;\n\tsize_t args_size = sizeof(*ra);\n\tstruct fuse_args_pages *ap;\n\tstruct fuse_args *args;\n\n\toffset = outarg->offset & ~PAGE_MASK;\n\tfile_size = i_size_read(inode);\n\n\tnum = min(outarg->size, fc->max_write);\n\tif (outarg->offset > file_size)\n\t\tnum = 0;\n\telse if (outarg->offset + num > file_size)\n\t\tnum = file_size - outarg->offset;\n\n\tnum_pages = (num + offset + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tnum_pages = min(num_pages, fc->max_pages);\n\n\targs_size += num_pages * (sizeof(ap->pages[0]) + sizeof(ap->descs[0]));\n\n\tra = kzalloc(args_size, GFP_KERNEL);\n\tif (!ra)\n\t\treturn -ENOMEM;\n\n\tap = &ra->ap;\n\tap->pages = (void *) (ra + 1);\n\tap->descs = (void *) (ap->pages + num_pages);\n\n\targs = &ap->args;\n\targs->nodeid = outarg->nodeid;\n\targs->opcode = FUSE_NOTIFY_REPLY;\n\targs->in_numargs = 2;\n\targs->in_pages = true;\n\targs->end = fuse_retrieve_end;\n\n\tindex = outarg->offset >> PAGE_SHIFT;\n\n\twhile (num && ap->num_pages < num_pages) {\n\t\tstruct page *page;\n\t\tunsigned int this_num;\n\n\t\tpage = find_get_page(mapping, index);\n\t\tif (!page)\n\t\t\tbreak;\n\n\t\tthis_num = min_t(unsigned, num, PAGE_SIZE - offset);\n\t\tap->pages[ap->num_pages] = page;\n\t\tap->descs[ap->num_pages].offset = offset;\n\t\tap->descs[ap->num_pages].length = this_num;\n\t\tap->num_pages++;\n\n\t\toffset = 0;\n\t\tnum -= this_num;\n\t\ttotal_len += this_num;\n\t\tindex++;\n\t}\n\tra->inarg.offset = outarg->offset;\n\tra->inarg.size = total_len;\n\targs->in_args[0].size = sizeof(ra->inarg);\n\targs->in_args[0].value = &ra->inarg;\n\targs->in_args[1].size = total_len;\n\n\terr = fuse_simple_notify_reply(fm, args, outarg->notify_unique);\n\tif (err)\n\t\tfuse_retrieve_end(fm, args, err);\n\n\treturn err;\n}\n\nstatic int fuse_notify_retrieve(struct fuse_conn *fc, unsigned int size,\n\t\t\t\tstruct fuse_copy_state *cs)\n{\n\tstruct fuse_notify_retrieve_out outarg;\n\tstruct fuse_mount *fm;\n\tstruct inode *inode;\n\tu64 nodeid;\n\tint err;\n\n\terr = -EINVAL;\n\tif (size != sizeof(outarg))\n\t\tgoto copy_finish;\n\n\terr = fuse_copy_one(cs, &outarg, sizeof(outarg));\n\tif (err)\n\t\tgoto copy_finish;\n\n\tfuse_copy_finish(cs);\n\n\tdown_read(&fc->killsb);\n\terr = -ENOENT;\n\tnodeid = outarg.nodeid;\n\n\tinode = fuse_ilookup(fc, nodeid, &fm);\n\tif (inode) {\n\t\terr = fuse_retrieve(fm, inode, &outarg);\n\t\tiput(inode);\n\t}\n\tup_read(&fc->killsb);\n\n\treturn err;\n\ncopy_finish:\n\tfuse_copy_finish(cs);\n\treturn err;\n}\n\nstatic int fuse_notify(struct fuse_conn *fc, enum fuse_notify_code code,\n\t\t       unsigned int size, struct fuse_copy_state *cs)\n{\n\t \n\tcs->move_pages = 0;\n\n\tswitch (code) {\n\tcase FUSE_NOTIFY_POLL:\n\t\treturn fuse_notify_poll(fc, size, cs);\n\n\tcase FUSE_NOTIFY_INVAL_INODE:\n\t\treturn fuse_notify_inval_inode(fc, size, cs);\n\n\tcase FUSE_NOTIFY_INVAL_ENTRY:\n\t\treturn fuse_notify_inval_entry(fc, size, cs);\n\n\tcase FUSE_NOTIFY_STORE:\n\t\treturn fuse_notify_store(fc, size, cs);\n\n\tcase FUSE_NOTIFY_RETRIEVE:\n\t\treturn fuse_notify_retrieve(fc, size, cs);\n\n\tcase FUSE_NOTIFY_DELETE:\n\t\treturn fuse_notify_delete(fc, size, cs);\n\n\tdefault:\n\t\tfuse_copy_finish(cs);\n\t\treturn -EINVAL;\n\t}\n}\n\n \nstatic struct fuse_req *request_find(struct fuse_pqueue *fpq, u64 unique)\n{\n\tunsigned int hash = fuse_req_hash(unique);\n\tstruct fuse_req *req;\n\n\tlist_for_each_entry(req, &fpq->processing[hash], list) {\n\t\tif (req->in.h.unique == unique)\n\t\t\treturn req;\n\t}\n\treturn NULL;\n}\n\nstatic int copy_out_args(struct fuse_copy_state *cs, struct fuse_args *args,\n\t\t\t unsigned nbytes)\n{\n\tunsigned reqsize = sizeof(struct fuse_out_header);\n\n\treqsize += fuse_len_args(args->out_numargs, args->out_args);\n\n\tif (reqsize < nbytes || (reqsize > nbytes && !args->out_argvar))\n\t\treturn -EINVAL;\n\telse if (reqsize > nbytes) {\n\t\tstruct fuse_arg *lastarg = &args->out_args[args->out_numargs-1];\n\t\tunsigned diffsize = reqsize - nbytes;\n\n\t\tif (diffsize > lastarg->size)\n\t\t\treturn -EINVAL;\n\t\tlastarg->size -= diffsize;\n\t}\n\treturn fuse_copy_args(cs, args->out_numargs, args->out_pages,\n\t\t\t      args->out_args, args->page_zeroing);\n}\n\n \nstatic ssize_t fuse_dev_do_write(struct fuse_dev *fud,\n\t\t\t\t struct fuse_copy_state *cs, size_t nbytes)\n{\n\tint err;\n\tstruct fuse_conn *fc = fud->fc;\n\tstruct fuse_pqueue *fpq = &fud->pq;\n\tstruct fuse_req *req;\n\tstruct fuse_out_header oh;\n\n\terr = -EINVAL;\n\tif (nbytes < sizeof(struct fuse_out_header))\n\t\tgoto out;\n\n\terr = fuse_copy_one(cs, &oh, sizeof(oh));\n\tif (err)\n\t\tgoto copy_finish;\n\n\terr = -EINVAL;\n\tif (oh.len != nbytes)\n\t\tgoto copy_finish;\n\n\t \n\tif (!oh.unique) {\n\t\terr = fuse_notify(fc, oh.error, nbytes - sizeof(oh), cs);\n\t\tgoto out;\n\t}\n\n\terr = -EINVAL;\n\tif (oh.error <= -512 || oh.error > 0)\n\t\tgoto copy_finish;\n\n\tspin_lock(&fpq->lock);\n\treq = NULL;\n\tif (fpq->connected)\n\t\treq = request_find(fpq, oh.unique & ~FUSE_INT_REQ_BIT);\n\n\terr = -ENOENT;\n\tif (!req) {\n\t\tspin_unlock(&fpq->lock);\n\t\tgoto copy_finish;\n\t}\n\n\t \n\tif (oh.unique & FUSE_INT_REQ_BIT) {\n\t\t__fuse_get_request(req);\n\t\tspin_unlock(&fpq->lock);\n\n\t\terr = 0;\n\t\tif (nbytes != sizeof(struct fuse_out_header))\n\t\t\terr = -EINVAL;\n\t\telse if (oh.error == -ENOSYS)\n\t\t\tfc->no_interrupt = 1;\n\t\telse if (oh.error == -EAGAIN)\n\t\t\terr = queue_interrupt(req);\n\n\t\tfuse_put_request(req);\n\n\t\tgoto copy_finish;\n\t}\n\n\tclear_bit(FR_SENT, &req->flags);\n\tlist_move(&req->list, &fpq->io);\n\treq->out.h = oh;\n\tset_bit(FR_LOCKED, &req->flags);\n\tspin_unlock(&fpq->lock);\n\tcs->req = req;\n\tif (!req->args->page_replace)\n\t\tcs->move_pages = 0;\n\n\tif (oh.error)\n\t\terr = nbytes != sizeof(oh) ? -EINVAL : 0;\n\telse\n\t\terr = copy_out_args(cs, req->args, nbytes);\n\tfuse_copy_finish(cs);\n\n\tspin_lock(&fpq->lock);\n\tclear_bit(FR_LOCKED, &req->flags);\n\tif (!fpq->connected)\n\t\terr = -ENOENT;\n\telse if (err)\n\t\treq->out.h.error = -EIO;\n\tif (!test_bit(FR_PRIVATE, &req->flags))\n\t\tlist_del_init(&req->list);\n\tspin_unlock(&fpq->lock);\n\n\tfuse_request_end(req);\nout:\n\treturn err ? err : nbytes;\n\ncopy_finish:\n\tfuse_copy_finish(cs);\n\tgoto out;\n}\n\nstatic ssize_t fuse_dev_write(struct kiocb *iocb, struct iov_iter *from)\n{\n\tstruct fuse_copy_state cs;\n\tstruct fuse_dev *fud = fuse_get_dev(iocb->ki_filp);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tif (!user_backed_iter(from))\n\t\treturn -EINVAL;\n\n\tfuse_copy_init(&cs, 0, from);\n\n\treturn fuse_dev_do_write(fud, &cs, iov_iter_count(from));\n}\n\nstatic ssize_t fuse_dev_splice_write(struct pipe_inode_info *pipe,\n\t\t\t\t     struct file *out, loff_t *ppos,\n\t\t\t\t     size_t len, unsigned int flags)\n{\n\tunsigned int head, tail, mask, count;\n\tunsigned nbuf;\n\tunsigned idx;\n\tstruct pipe_buffer *bufs;\n\tstruct fuse_copy_state cs;\n\tstruct fuse_dev *fud;\n\tsize_t rem;\n\tssize_t ret;\n\n\tfud = fuse_get_dev(out);\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tpipe_lock(pipe);\n\n\thead = pipe->head;\n\ttail = pipe->tail;\n\tmask = pipe->ring_size - 1;\n\tcount = head - tail;\n\n\tbufs = kvmalloc_array(count, sizeof(struct pipe_buffer), GFP_KERNEL);\n\tif (!bufs) {\n\t\tpipe_unlock(pipe);\n\t\treturn -ENOMEM;\n\t}\n\n\tnbuf = 0;\n\trem = 0;\n\tfor (idx = tail; idx != head && rem < len; idx++)\n\t\trem += pipe->bufs[idx & mask].len;\n\n\tret = -EINVAL;\n\tif (rem < len)\n\t\tgoto out_free;\n\n\trem = len;\n\twhile (rem) {\n\t\tstruct pipe_buffer *ibuf;\n\t\tstruct pipe_buffer *obuf;\n\n\t\tif (WARN_ON(nbuf >= count || tail == head))\n\t\t\tgoto out_free;\n\n\t\tibuf = &pipe->bufs[tail & mask];\n\t\tobuf = &bufs[nbuf];\n\n\t\tif (rem >= ibuf->len) {\n\t\t\t*obuf = *ibuf;\n\t\t\tibuf->ops = NULL;\n\t\t\ttail++;\n\t\t\tpipe->tail = tail;\n\t\t} else {\n\t\t\tif (!pipe_buf_get(pipe, ibuf))\n\t\t\t\tgoto out_free;\n\n\t\t\t*obuf = *ibuf;\n\t\t\tobuf->flags &= ~PIPE_BUF_FLAG_GIFT;\n\t\t\tobuf->len = rem;\n\t\t\tibuf->offset += obuf->len;\n\t\t\tibuf->len -= obuf->len;\n\t\t}\n\t\tnbuf++;\n\t\trem -= obuf->len;\n\t}\n\tpipe_unlock(pipe);\n\n\tfuse_copy_init(&cs, 0, NULL);\n\tcs.pipebufs = bufs;\n\tcs.nr_segs = nbuf;\n\tcs.pipe = pipe;\n\n\tif (flags & SPLICE_F_MOVE)\n\t\tcs.move_pages = 1;\n\n\tret = fuse_dev_do_write(fud, &cs, len);\n\n\tpipe_lock(pipe);\nout_free:\n\tfor (idx = 0; idx < nbuf; idx++) {\n\t\tstruct pipe_buffer *buf = &bufs[idx];\n\n\t\tif (buf->ops)\n\t\t\tpipe_buf_release(pipe, buf);\n\t}\n\tpipe_unlock(pipe);\n\n\tkvfree(bufs);\n\treturn ret;\n}\n\nstatic __poll_t fuse_dev_poll(struct file *file, poll_table *wait)\n{\n\t__poll_t mask = EPOLLOUT | EPOLLWRNORM;\n\tstruct fuse_iqueue *fiq;\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (!fud)\n\t\treturn EPOLLERR;\n\n\tfiq = &fud->fc->iq;\n\tpoll_wait(file, &fiq->waitq, wait);\n\n\tspin_lock(&fiq->lock);\n\tif (!fiq->connected)\n\t\tmask = EPOLLERR;\n\telse if (request_pending(fiq))\n\t\tmask |= EPOLLIN | EPOLLRDNORM;\n\tspin_unlock(&fiq->lock);\n\n\treturn mask;\n}\n\n \nstatic void end_requests(struct list_head *head)\n{\n\twhile (!list_empty(head)) {\n\t\tstruct fuse_req *req;\n\t\treq = list_entry(head->next, struct fuse_req, list);\n\t\treq->out.h.error = -ECONNABORTED;\n\t\tclear_bit(FR_SENT, &req->flags);\n\t\tlist_del_init(&req->list);\n\t\tfuse_request_end(req);\n\t}\n}\n\nstatic void end_polls(struct fuse_conn *fc)\n{\n\tstruct rb_node *p;\n\n\tp = rb_first(&fc->polled_files);\n\n\twhile (p) {\n\t\tstruct fuse_file *ff;\n\t\tff = rb_entry(p, struct fuse_file, polled_node);\n\t\twake_up_interruptible_all(&ff->poll_wait);\n\n\t\tp = rb_next(p);\n\t}\n}\n\n \nvoid fuse_abort_conn(struct fuse_conn *fc)\n{\n\tstruct fuse_iqueue *fiq = &fc->iq;\n\n\tspin_lock(&fc->lock);\n\tif (fc->connected) {\n\t\tstruct fuse_dev *fud;\n\t\tstruct fuse_req *req, *next;\n\t\tLIST_HEAD(to_end);\n\t\tunsigned int i;\n\n\t\t \n\t\tspin_lock(&fc->bg_lock);\n\t\tfc->connected = 0;\n\t\tspin_unlock(&fc->bg_lock);\n\n\t\tfuse_set_initialized(fc);\n\t\tlist_for_each_entry(fud, &fc->devices, entry) {\n\t\t\tstruct fuse_pqueue *fpq = &fud->pq;\n\n\t\t\tspin_lock(&fpq->lock);\n\t\t\tfpq->connected = 0;\n\t\t\tlist_for_each_entry_safe(req, next, &fpq->io, list) {\n\t\t\t\treq->out.h.error = -ECONNABORTED;\n\t\t\t\tspin_lock(&req->waitq.lock);\n\t\t\t\tset_bit(FR_ABORTED, &req->flags);\n\t\t\t\tif (!test_bit(FR_LOCKED, &req->flags)) {\n\t\t\t\t\tset_bit(FR_PRIVATE, &req->flags);\n\t\t\t\t\t__fuse_get_request(req);\n\t\t\t\t\tlist_move(&req->list, &to_end);\n\t\t\t\t}\n\t\t\t\tspin_unlock(&req->waitq.lock);\n\t\t\t}\n\t\t\tfor (i = 0; i < FUSE_PQ_HASH_SIZE; i++)\n\t\t\t\tlist_splice_tail_init(&fpq->processing[i],\n\t\t\t\t\t\t      &to_end);\n\t\t\tspin_unlock(&fpq->lock);\n\t\t}\n\t\tspin_lock(&fc->bg_lock);\n\t\tfc->blocked = 0;\n\t\tfc->max_background = UINT_MAX;\n\t\tflush_bg_queue(fc);\n\t\tspin_unlock(&fc->bg_lock);\n\n\t\tspin_lock(&fiq->lock);\n\t\tfiq->connected = 0;\n\t\tlist_for_each_entry(req, &fiq->pending, list)\n\t\t\tclear_bit(FR_PENDING, &req->flags);\n\t\tlist_splice_tail_init(&fiq->pending, &to_end);\n\t\twhile (forget_pending(fiq))\n\t\t\tkfree(fuse_dequeue_forget(fiq, 1, NULL));\n\t\twake_up_all(&fiq->waitq);\n\t\tspin_unlock(&fiq->lock);\n\t\tkill_fasync(&fiq->fasync, SIGIO, POLL_IN);\n\t\tend_polls(fc);\n\t\twake_up_all(&fc->blocked_waitq);\n\t\tspin_unlock(&fc->lock);\n\n\t\tend_requests(&to_end);\n\t} else {\n\t\tspin_unlock(&fc->lock);\n\t}\n}\nEXPORT_SYMBOL_GPL(fuse_abort_conn);\n\nvoid fuse_wait_aborted(struct fuse_conn *fc)\n{\n\t \n\tsmp_mb();\n\twait_event(fc->blocked_waitq, atomic_read(&fc->num_waiting) == 0);\n}\n\nint fuse_dev_release(struct inode *inode, struct file *file)\n{\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (fud) {\n\t\tstruct fuse_conn *fc = fud->fc;\n\t\tstruct fuse_pqueue *fpq = &fud->pq;\n\t\tLIST_HEAD(to_end);\n\t\tunsigned int i;\n\n\t\tspin_lock(&fpq->lock);\n\t\tWARN_ON(!list_empty(&fpq->io));\n\t\tfor (i = 0; i < FUSE_PQ_HASH_SIZE; i++)\n\t\t\tlist_splice_init(&fpq->processing[i], &to_end);\n\t\tspin_unlock(&fpq->lock);\n\n\t\tend_requests(&to_end);\n\n\t\t \n\t\tif (atomic_dec_and_test(&fc->dev_count)) {\n\t\t\tWARN_ON(fc->iq.fasync != NULL);\n\t\t\tfuse_abort_conn(fc);\n\t\t}\n\t\tfuse_dev_free(fud);\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(fuse_dev_release);\n\nstatic int fuse_dev_fasync(int fd, struct file *file, int on)\n{\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\t \n\treturn fasync_helper(fd, file, on, &fud->fc->iq.fasync);\n}\n\nstatic int fuse_device_clone(struct fuse_conn *fc, struct file *new)\n{\n\tstruct fuse_dev *fud;\n\n\tif (new->private_data)\n\t\treturn -EINVAL;\n\n\tfud = fuse_dev_alloc_install(fc);\n\tif (!fud)\n\t\treturn -ENOMEM;\n\n\tnew->private_data = fud;\n\tatomic_inc(&fc->dev_count);\n\n\treturn 0;\n}\n\nstatic long fuse_dev_ioctl(struct file *file, unsigned int cmd,\n\t\t\t   unsigned long arg)\n{\n\tint res;\n\tint oldfd;\n\tstruct fuse_dev *fud = NULL;\n\tstruct fd f;\n\n\tswitch (cmd) {\n\tcase FUSE_DEV_IOC_CLONE:\n\t\tif (get_user(oldfd, (__u32 __user *)arg))\n\t\t\treturn -EFAULT;\n\n\t\tf = fdget(oldfd);\n\t\tif (!f.file)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (f.file->f_op == file->f_op)\n\t\t\tfud = fuse_get_dev(f.file);\n\n\t\tres = -EINVAL;\n\t\tif (fud) {\n\t\t\tmutex_lock(&fuse_mutex);\n\t\t\tres = fuse_device_clone(fud->fc, file);\n\t\t\tmutex_unlock(&fuse_mutex);\n\t\t}\n\t\tfdput(f);\n\t\tbreak;\n\tdefault:\n\t\tres = -ENOTTY;\n\t\tbreak;\n\t}\n\treturn res;\n}\n\nconst struct file_operations fuse_dev_operations = {\n\t.owner\t\t= THIS_MODULE,\n\t.open\t\t= fuse_dev_open,\n\t.llseek\t\t= no_llseek,\n\t.read_iter\t= fuse_dev_read,\n\t.splice_read\t= fuse_dev_splice_read,\n\t.write_iter\t= fuse_dev_write,\n\t.splice_write\t= fuse_dev_splice_write,\n\t.poll\t\t= fuse_dev_poll,\n\t.release\t= fuse_dev_release,\n\t.fasync\t\t= fuse_dev_fasync,\n\t.unlocked_ioctl = fuse_dev_ioctl,\n\t.compat_ioctl   = compat_ptr_ioctl,\n};\nEXPORT_SYMBOL_GPL(fuse_dev_operations);\n\nstatic struct miscdevice fuse_miscdevice = {\n\t.minor = FUSE_MINOR,\n\t.name  = \"fuse\",\n\t.fops = &fuse_dev_operations,\n};\n\nint __init fuse_dev_init(void)\n{\n\tint err = -ENOMEM;\n\tfuse_req_cachep = kmem_cache_create(\"fuse_request\",\n\t\t\t\t\t    sizeof(struct fuse_req),\n\t\t\t\t\t    0, 0, NULL);\n\tif (!fuse_req_cachep)\n\t\tgoto out;\n\n\terr = misc_register(&fuse_miscdevice);\n\tif (err)\n\t\tgoto out_cache_clean;\n\n\treturn 0;\n\n out_cache_clean:\n\tkmem_cache_destroy(fuse_req_cachep);\n out:\n\treturn err;\n}\n\nvoid fuse_dev_cleanup(void)\n{\n\tmisc_deregister(&fuse_miscdevice);\n\tkmem_cache_destroy(fuse_req_cachep);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}