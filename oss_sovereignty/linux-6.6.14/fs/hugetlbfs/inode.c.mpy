{
  "module_name": "inode.c",
  "hash_id": "c55d2b539ea3f7a56e20c988a53217f3c13b674eed9ab6dcdc41018fc61607ef",
  "original_prompt": "Ingested from linux-6.6.14/fs/hugetlbfs/inode.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/thread_info.h>\n#include <asm/current.h>\n#include <linux/falloc.h>\n#include <linux/fs.h>\n#include <linux/mount.h>\n#include <linux/file.h>\n#include <linux/kernel.h>\n#include <linux/writeback.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/init.h>\n#include <linux/string.h>\n#include <linux/capability.h>\n#include <linux/ctype.h>\n#include <linux/backing-dev.h>\n#include <linux/hugetlb.h>\n#include <linux/pagevec.h>\n#include <linux/fs_parser.h>\n#include <linux/mman.h>\n#include <linux/slab.h>\n#include <linux/dnotify.h>\n#include <linux/statfs.h>\n#include <linux/security.h>\n#include <linux/magic.h>\n#include <linux/migrate.h>\n#include <linux/uio.h>\n\n#include <linux/uaccess.h>\n#include <linux/sched/mm.h>\n\nstatic const struct address_space_operations hugetlbfs_aops;\nconst struct file_operations hugetlbfs_file_operations;\nstatic const struct inode_operations hugetlbfs_dir_inode_operations;\nstatic const struct inode_operations hugetlbfs_inode_operations;\n\nenum hugetlbfs_size_type { NO_SIZE, SIZE_STD, SIZE_PERCENT };\n\nstruct hugetlbfs_fs_context {\n\tstruct hstate\t\t*hstate;\n\tunsigned long long\tmax_size_opt;\n\tunsigned long long\tmin_size_opt;\n\tlong\t\t\tmax_hpages;\n\tlong\t\t\tnr_inodes;\n\tlong\t\t\tmin_hpages;\n\tenum hugetlbfs_size_type max_val_type;\n\tenum hugetlbfs_size_type min_val_type;\n\tkuid_t\t\t\tuid;\n\tkgid_t\t\t\tgid;\n\tumode_t\t\t\tmode;\n};\n\nint sysctl_hugetlb_shm_group;\n\nenum hugetlb_param {\n\tOpt_gid,\n\tOpt_min_size,\n\tOpt_mode,\n\tOpt_nr_inodes,\n\tOpt_pagesize,\n\tOpt_size,\n\tOpt_uid,\n};\n\nstatic const struct fs_parameter_spec hugetlb_fs_parameters[] = {\n\tfsparam_u32   (\"gid\",\t\tOpt_gid),\n\tfsparam_string(\"min_size\",\tOpt_min_size),\n\tfsparam_u32oct(\"mode\",\t\tOpt_mode),\n\tfsparam_string(\"nr_inodes\",\tOpt_nr_inodes),\n\tfsparam_string(\"pagesize\",\tOpt_pagesize),\n\tfsparam_string(\"size\",\t\tOpt_size),\n\tfsparam_u32   (\"uid\",\t\tOpt_uid),\n\t{}\n};\n\n#ifdef CONFIG_NUMA\nstatic inline void hugetlb_set_vma_policy(struct vm_area_struct *vma,\n\t\t\t\t\tstruct inode *inode, pgoff_t index)\n{\n\tvma->vm_policy = mpol_shared_policy_lookup(&HUGETLBFS_I(inode)->policy,\n\t\t\t\t\t\t\tindex);\n}\n\nstatic inline void hugetlb_drop_vma_policy(struct vm_area_struct *vma)\n{\n\tmpol_cond_put(vma->vm_policy);\n}\n#else\nstatic inline void hugetlb_set_vma_policy(struct vm_area_struct *vma,\n\t\t\t\t\tstruct inode *inode, pgoff_t index)\n{\n}\n\nstatic inline void hugetlb_drop_vma_policy(struct vm_area_struct *vma)\n{\n}\n#endif\n\n \n#define PGOFF_LOFFT_MAX \\\n\t(((1UL << (PAGE_SHIFT + 1)) - 1) <<  (BITS_PER_LONG - (PAGE_SHIFT + 1)))\n\nstatic int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct hugetlbfs_inode_info *info = HUGETLBFS_I(inode);\n\tloff_t len, vma_len;\n\tint ret;\n\tstruct hstate *h = hstate_file(file);\n\n\t \n\tvm_flags_set(vma, VM_HUGETLB | VM_DONTEXPAND);\n\tvma->vm_ops = &hugetlb_vm_ops;\n\n\tret = seal_check_future_write(info->seals, vma);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (sizeof(unsigned long) == sizeof(loff_t)) {\n\t\tif (vma->vm_pgoff & PGOFF_LOFFT_MAX)\n\t\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\n\t\treturn -EINVAL;\n\n\tvma_len = (loff_t)(vma->vm_end - vma->vm_start);\n\tlen = vma_len + ((loff_t)vma->vm_pgoff << PAGE_SHIFT);\n\t \n\tif (len < vma_len)\n\t\treturn -EINVAL;\n\n\tinode_lock(inode);\n\tfile_accessed(file);\n\n\tret = -ENOMEM;\n\tif (!hugetlb_reserve_pages(inode,\n\t\t\t\tvma->vm_pgoff >> huge_page_order(h),\n\t\t\t\tlen >> huge_page_shift(h), vma,\n\t\t\t\tvma->vm_flags))\n\t\tgoto out;\n\n\tret = 0;\n\tif (vma->vm_flags & VM_WRITE && inode->i_size < len)\n\t\ti_size_write(inode, len);\nout:\n\tinode_unlock(inode);\n\n\treturn ret;\n}\n\n \n\nstatic unsigned long\nhugetlb_get_unmapped_area_bottomup(struct file *file, unsigned long addr,\n\t\tunsigned long len, unsigned long pgoff, unsigned long flags)\n{\n\tstruct hstate *h = hstate_file(file);\n\tstruct vm_unmapped_area_info info;\n\n\tinfo.flags = 0;\n\tinfo.length = len;\n\tinfo.low_limit = current->mm->mmap_base;\n\tinfo.high_limit = arch_get_mmap_end(addr, len, flags);\n\tinfo.align_mask = PAGE_MASK & ~huge_page_mask(h);\n\tinfo.align_offset = 0;\n\treturn vm_unmapped_area(&info);\n}\n\nstatic unsigned long\nhugetlb_get_unmapped_area_topdown(struct file *file, unsigned long addr,\n\t\tunsigned long len, unsigned long pgoff, unsigned long flags)\n{\n\tstruct hstate *h = hstate_file(file);\n\tstruct vm_unmapped_area_info info;\n\n\tinfo.flags = VM_UNMAPPED_AREA_TOPDOWN;\n\tinfo.length = len;\n\tinfo.low_limit = PAGE_SIZE;\n\tinfo.high_limit = arch_get_mmap_base(addr, current->mm->mmap_base);\n\tinfo.align_mask = PAGE_MASK & ~huge_page_mask(h);\n\tinfo.align_offset = 0;\n\taddr = vm_unmapped_area(&info);\n\n\t \n\tif (unlikely(offset_in_page(addr))) {\n\t\tVM_BUG_ON(addr != -ENOMEM);\n\t\tinfo.flags = 0;\n\t\tinfo.low_limit = current->mm->mmap_base;\n\t\tinfo.high_limit = arch_get_mmap_end(addr, len, flags);\n\t\taddr = vm_unmapped_area(&info);\n\t}\n\n\treturn addr;\n}\n\nunsigned long\ngeneric_hugetlb_get_unmapped_area(struct file *file, unsigned long addr,\n\t\t\t\t  unsigned long len, unsigned long pgoff,\n\t\t\t\t  unsigned long flags)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma;\n\tstruct hstate *h = hstate_file(file);\n\tconst unsigned long mmap_end = arch_get_mmap_end(addr, len, flags);\n\n\tif (len & ~huge_page_mask(h))\n\t\treturn -EINVAL;\n\tif (len > TASK_SIZE)\n\t\treturn -ENOMEM;\n\n\tif (flags & MAP_FIXED) {\n\t\tif (prepare_hugepage_range(file, addr, len))\n\t\t\treturn -EINVAL;\n\t\treturn addr;\n\t}\n\n\tif (addr) {\n\t\taddr = ALIGN(addr, huge_page_size(h));\n\t\tvma = find_vma(mm, addr);\n\t\tif (mmap_end - len >= addr &&\n\t\t    (!vma || addr + len <= vm_start_gap(vma)))\n\t\t\treturn addr;\n\t}\n\n\t \n\tif (mm->get_unmapped_area == arch_get_unmapped_area_topdown)\n\t\treturn hugetlb_get_unmapped_area_topdown(file, addr, len,\n\t\t\t\tpgoff, flags);\n\treturn hugetlb_get_unmapped_area_bottomup(file, addr, len,\n\t\t\tpgoff, flags);\n}\n\n#ifndef HAVE_ARCH_HUGETLB_UNMAPPED_AREA\nstatic unsigned long\nhugetlb_get_unmapped_area(struct file *file, unsigned long addr,\n\t\t\t  unsigned long len, unsigned long pgoff,\n\t\t\t  unsigned long flags)\n{\n\treturn generic_hugetlb_get_unmapped_area(file, addr, len, pgoff, flags);\n}\n#endif\n\n \nstatic size_t adjust_range_hwpoison(struct page *page, size_t offset, size_t bytes)\n{\n\tsize_t n = 0;\n\tsize_t res = 0;\n\n\t \n\tpage = nth_page(page, offset / PAGE_SIZE);\n\toffset %= PAGE_SIZE;\n\twhile (1) {\n\t\tif (is_raw_hwpoison_page_in_hugepage(page))\n\t\t\tbreak;\n\n\t\t \n\t\tn = min(bytes, (size_t)PAGE_SIZE - offset);\n\t\tres += n;\n\t\tbytes -= n;\n\t\tif (!bytes || !n)\n\t\t\tbreak;\n\t\toffset += n;\n\t\tif (offset == PAGE_SIZE) {\n\t\t\tpage = nth_page(page, 1);\n\t\t\toffset = 0;\n\t\t}\n\t}\n\n\treturn res;\n}\n\n \nstatic ssize_t hugetlbfs_read_iter(struct kiocb *iocb, struct iov_iter *to)\n{\n\tstruct file *file = iocb->ki_filp;\n\tstruct hstate *h = hstate_file(file);\n\tstruct address_space *mapping = file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tunsigned long index = iocb->ki_pos >> huge_page_shift(h);\n\tunsigned long offset = iocb->ki_pos & ~huge_page_mask(h);\n\tunsigned long end_index;\n\tloff_t isize;\n\tssize_t retval = 0;\n\n\twhile (iov_iter_count(to)) {\n\t\tstruct page *page;\n\t\tsize_t nr, copied, want;\n\n\t\t \n\t\tnr = huge_page_size(h);\n\t\tisize = i_size_read(inode);\n\t\tif (!isize)\n\t\t\tbreak;\n\t\tend_index = (isize - 1) >> huge_page_shift(h);\n\t\tif (index > end_index)\n\t\t\tbreak;\n\t\tif (index == end_index) {\n\t\t\tnr = ((isize - 1) & ~huge_page_mask(h)) + 1;\n\t\t\tif (nr <= offset)\n\t\t\t\tbreak;\n\t\t}\n\t\tnr = nr - offset;\n\n\t\t \n\t\tpage = find_lock_page(mapping, index);\n\t\tif (unlikely(page == NULL)) {\n\t\t\t \n\t\t\tcopied = iov_iter_zero(nr, to);\n\t\t} else {\n\t\t\tunlock_page(page);\n\n\t\t\tif (!PageHWPoison(page))\n\t\t\t\twant = nr;\n\t\t\telse {\n\t\t\t\t \n\t\t\t\twant = adjust_range_hwpoison(page, offset, nr);\n\t\t\t\tif (want == 0) {\n\t\t\t\t\tput_page(page);\n\t\t\t\t\tretval = -EIO;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\tcopied = copy_page_to_iter(page, offset, want, to);\n\t\t\tput_page(page);\n\t\t}\n\t\toffset += copied;\n\t\tretval += copied;\n\t\tif (copied != nr && iov_iter_count(to)) {\n\t\t\tif (!retval)\n\t\t\t\tretval = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tindex += offset >> huge_page_shift(h);\n\t\toffset &= ~huge_page_mask(h);\n\t}\n\tiocb->ki_pos = ((loff_t)index << huge_page_shift(h)) + offset;\n\treturn retval;\n}\n\nstatic int hugetlbfs_write_begin(struct file *file,\n\t\t\tstruct address_space *mapping,\n\t\t\tloff_t pos, unsigned len,\n\t\t\tstruct page **pagep, void **fsdata)\n{\n\treturn -EINVAL;\n}\n\nstatic int hugetlbfs_write_end(struct file *file, struct address_space *mapping,\n\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\tstruct page *page, void *fsdata)\n{\n\tBUG();\n\treturn -EINVAL;\n}\n\nstatic void hugetlb_delete_from_page_cache(struct folio *folio)\n{\n\tfolio_clear_dirty(folio);\n\tfolio_clear_uptodate(folio);\n\tfilemap_remove_folio(folio);\n}\n\n \nstatic bool hugetlb_vma_maps_page(struct vm_area_struct *vma,\n\t\t\t\tunsigned long addr, struct page *page)\n{\n\tpte_t *ptep, pte;\n\n\tptep = hugetlb_walk(vma, addr, huge_page_size(hstate_vma(vma)));\n\tif (!ptep)\n\t\treturn false;\n\n\tpte = huge_ptep_get(ptep);\n\tif (huge_pte_none(pte) || !pte_present(pte))\n\t\treturn false;\n\n\tif (pte_page(pte) == page)\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic unsigned long vma_offset_start(struct vm_area_struct *vma, pgoff_t start)\n{\n\tunsigned long offset = 0;\n\n\tif (vma->vm_pgoff < start)\n\t\toffset = (start - vma->vm_pgoff) << PAGE_SHIFT;\n\n\treturn vma->vm_start + offset;\n}\n\nstatic unsigned long vma_offset_end(struct vm_area_struct *vma, pgoff_t end)\n{\n\tunsigned long t_end;\n\n\tif (!end)\n\t\treturn vma->vm_end;\n\n\tt_end = ((end - vma->vm_pgoff) << PAGE_SHIFT) + vma->vm_start;\n\tif (t_end > vma->vm_end)\n\t\tt_end = vma->vm_end;\n\treturn t_end;\n}\n\n \nstatic void hugetlb_unmap_file_folio(struct hstate *h,\n\t\t\t\t\tstruct address_space *mapping,\n\t\t\t\t\tstruct folio *folio, pgoff_t index)\n{\n\tstruct rb_root_cached *root = &mapping->i_mmap;\n\tstruct hugetlb_vma_lock *vma_lock;\n\tstruct page *page = &folio->page;\n\tstruct vm_area_struct *vma;\n\tunsigned long v_start;\n\tunsigned long v_end;\n\tpgoff_t start, end;\n\n\tstart = index * pages_per_huge_page(h);\n\tend = (index + 1) * pages_per_huge_page(h);\n\n\ti_mmap_lock_write(mapping);\nretry:\n\tvma_lock = NULL;\n\tvma_interval_tree_foreach(vma, root, start, end - 1) {\n\t\tv_start = vma_offset_start(vma, start);\n\t\tv_end = vma_offset_end(vma, end);\n\n\t\tif (!hugetlb_vma_maps_page(vma, v_start, page))\n\t\t\tcontinue;\n\n\t\tif (!hugetlb_vma_trylock_write(vma)) {\n\t\t\tvma_lock = vma->vm_private_data;\n\t\t\t \n\t\t\tkref_get(&vma_lock->refs);\n\t\t\tbreak;\n\t\t}\n\n\t\tunmap_hugepage_range(vma, v_start, v_end, NULL,\n\t\t\t\t     ZAP_FLAG_DROP_MARKER);\n\t\thugetlb_vma_unlock_write(vma);\n\t}\n\n\ti_mmap_unlock_write(mapping);\n\n\tif (vma_lock) {\n\t\t \n\t\tdown_write(&vma_lock->rw_sema);\n\t\ti_mmap_lock_write(mapping);\n\n\t\tvma = vma_lock->vma;\n\t\tif (!vma) {\n\t\t\t \n\t\t\tup_write(&vma_lock->rw_sema);\n\t\t\tkref_put(&vma_lock->refs, hugetlb_vma_lock_release);\n\t\t\tgoto retry;\n\t\t}\n\n\t\t \n\t\tv_start = vma_offset_start(vma, start);\n\t\tv_end = vma_offset_end(vma, end);\n\t\tif (hugetlb_vma_maps_page(vma, v_start, page))\n\t\t\tunmap_hugepage_range(vma, v_start, v_end, NULL,\n\t\t\t\t\t     ZAP_FLAG_DROP_MARKER);\n\n\t\tkref_put(&vma_lock->refs, hugetlb_vma_lock_release);\n\t\thugetlb_vma_unlock_write(vma);\n\n\t\tgoto retry;\n\t}\n}\n\nstatic void\nhugetlb_vmdelete_list(struct rb_root_cached *root, pgoff_t start, pgoff_t end,\n\t\t      zap_flags_t zap_flags)\n{\n\tstruct vm_area_struct *vma;\n\n\t \n\tvma_interval_tree_foreach(vma, root, start, end ? end - 1 : ULONG_MAX) {\n\t\tunsigned long v_start;\n\t\tunsigned long v_end;\n\n\t\tif (!hugetlb_vma_trylock_write(vma))\n\t\t\tcontinue;\n\n\t\tv_start = vma_offset_start(vma, start);\n\t\tv_end = vma_offset_end(vma, end);\n\n\t\tunmap_hugepage_range(vma, v_start, v_end, NULL, zap_flags);\n\n\t\t \n\t\thugetlb_vma_unlock_write(vma);\n\t}\n}\n\n \nstatic bool remove_inode_single_folio(struct hstate *h, struct inode *inode,\n\t\t\t\t\tstruct address_space *mapping,\n\t\t\t\t\tstruct folio *folio, pgoff_t index,\n\t\t\t\t\tbool truncate_op)\n{\n\tbool ret = false;\n\n\t \n\tif (unlikely(folio_mapped(folio)))\n\t\thugetlb_unmap_file_folio(h, mapping, folio, index);\n\n\tfolio_lock(folio);\n\t \n\tVM_BUG_ON_FOLIO(folio_test_hugetlb_restore_reserve(folio), folio);\n\thugetlb_delete_from_page_cache(folio);\n\tret = true;\n\tif (!truncate_op) {\n\t\tif (unlikely(hugetlb_unreserve_pages(inode, index,\n\t\t\t\t\t\t\tindex + 1, 1)))\n\t\t\thugetlb_fix_reserve_counts(inode);\n\t}\n\n\tfolio_unlock(folio);\n\treturn ret;\n}\n\n \nstatic void remove_inode_hugepages(struct inode *inode, loff_t lstart,\n\t\t\t\t   loff_t lend)\n{\n\tstruct hstate *h = hstate_inode(inode);\n\tstruct address_space *mapping = &inode->i_data;\n\tconst pgoff_t start = lstart >> huge_page_shift(h);\n\tconst pgoff_t end = lend >> huge_page_shift(h);\n\tstruct folio_batch fbatch;\n\tpgoff_t next, index;\n\tint i, freed = 0;\n\tbool truncate_op = (lend == LLONG_MAX);\n\n\tfolio_batch_init(&fbatch);\n\tnext = start;\n\twhile (filemap_get_folios(mapping, &next, end - 1, &fbatch)) {\n\t\tfor (i = 0; i < folio_batch_count(&fbatch); ++i) {\n\t\t\tstruct folio *folio = fbatch.folios[i];\n\t\t\tu32 hash = 0;\n\n\t\t\tindex = folio->index;\n\t\t\thash = hugetlb_fault_mutex_hash(mapping, index);\n\t\t\tmutex_lock(&hugetlb_fault_mutex_table[hash]);\n\n\t\t\t \n\t\t\tif (remove_inode_single_folio(h, inode, mapping, folio,\n\t\t\t\t\t\t\tindex, truncate_op))\n\t\t\t\tfreed++;\n\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t}\n\t\tfolio_batch_release(&fbatch);\n\t\tcond_resched();\n\t}\n\n\tif (truncate_op)\n\t\t(void)hugetlb_unreserve_pages(inode, start, LONG_MAX, freed);\n}\n\nstatic void hugetlbfs_evict_inode(struct inode *inode)\n{\n\tstruct resv_map *resv_map;\n\n\tremove_inode_hugepages(inode, 0, LLONG_MAX);\n\n\t \n\tresv_map = (struct resv_map *)(&inode->i_data)->private_data;\n\t \n\tif (resv_map)\n\t\tresv_map_release(&resv_map->refs);\n\tclear_inode(inode);\n}\n\nstatic void hugetlb_vmtruncate(struct inode *inode, loff_t offset)\n{\n\tpgoff_t pgoff;\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct hstate *h = hstate_inode(inode);\n\n\tBUG_ON(offset & ~huge_page_mask(h));\n\tpgoff = offset >> PAGE_SHIFT;\n\n\ti_size_write(inode, offset);\n\ti_mmap_lock_write(mapping);\n\tif (!RB_EMPTY_ROOT(&mapping->i_mmap.rb_root))\n\t\thugetlb_vmdelete_list(&mapping->i_mmap, pgoff, 0,\n\t\t\t\t      ZAP_FLAG_DROP_MARKER);\n\ti_mmap_unlock_write(mapping);\n\tremove_inode_hugepages(inode, offset, LLONG_MAX);\n}\n\nstatic void hugetlbfs_zero_partial_page(struct hstate *h,\n\t\t\t\t\tstruct address_space *mapping,\n\t\t\t\t\tloff_t start,\n\t\t\t\t\tloff_t end)\n{\n\tpgoff_t idx = start >> huge_page_shift(h);\n\tstruct folio *folio;\n\n\tfolio = filemap_lock_folio(mapping, idx);\n\tif (IS_ERR(folio))\n\t\treturn;\n\n\tstart = start & ~huge_page_mask(h);\n\tend = end & ~huge_page_mask(h);\n\tif (!end)\n\t\tend = huge_page_size(h);\n\n\tfolio_zero_segment(folio, (size_t)start, (size_t)end);\n\n\tfolio_unlock(folio);\n\tfolio_put(folio);\n}\n\nstatic long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)\n{\n\tstruct hugetlbfs_inode_info *info = HUGETLBFS_I(inode);\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct hstate *h = hstate_inode(inode);\n\tloff_t hpage_size = huge_page_size(h);\n\tloff_t hole_start, hole_end;\n\n\t \n\thole_start = round_up(offset, hpage_size);\n\thole_end = round_down(offset + len, hpage_size);\n\n\tinode_lock(inode);\n\n\t \n\tif (info->seals & (F_SEAL_WRITE | F_SEAL_FUTURE_WRITE)) {\n\t\tinode_unlock(inode);\n\t\treturn -EPERM;\n\t}\n\n\ti_mmap_lock_write(mapping);\n\n\t \n\tif (offset < hole_start)\n\t\thugetlbfs_zero_partial_page(h, mapping,\n\t\t\t\toffset, min(offset + len, hole_start));\n\n\t \n\tif (hole_end > hole_start) {\n\t\tif (!RB_EMPTY_ROOT(&mapping->i_mmap.rb_root))\n\t\t\thugetlb_vmdelete_list(&mapping->i_mmap,\n\t\t\t\t\t      hole_start >> PAGE_SHIFT,\n\t\t\t\t\t      hole_end >> PAGE_SHIFT, 0);\n\t}\n\n\t \n\tif ((offset + len) > hole_end && (offset + len) > hole_start)\n\t\thugetlbfs_zero_partial_page(h, mapping,\n\t\t\t\thole_end, offset + len);\n\n\ti_mmap_unlock_write(mapping);\n\n\t \n\tif (hole_end > hole_start)\n\t\tremove_inode_hugepages(inode, hole_start, hole_end);\n\n\tinode_unlock(inode);\n\n\treturn 0;\n}\n\nstatic long hugetlbfs_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t\tloff_t len)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct hugetlbfs_inode_info *info = HUGETLBFS_I(inode);\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct hstate *h = hstate_inode(inode);\n\tstruct vm_area_struct pseudo_vma;\n\tstruct mm_struct *mm = current->mm;\n\tloff_t hpage_size = huge_page_size(h);\n\tunsigned long hpage_shift = huge_page_shift(h);\n\tpgoff_t start, index, end;\n\tint error;\n\tu32 hash;\n\n\tif (mode & ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))\n\t\treturn -EOPNOTSUPP;\n\n\tif (mode & FALLOC_FL_PUNCH_HOLE)\n\t\treturn hugetlbfs_punch_hole(inode, offset, len);\n\n\t \n\tstart = offset >> hpage_shift;\n\tend = (offset + len + hpage_size - 1) >> hpage_shift;\n\n\tinode_lock(inode);\n\n\t \n\terror = inode_newsize_ok(inode, offset + len);\n\tif (error)\n\t\tgoto out;\n\n\tif ((info->seals & F_SEAL_GROW) && offset + len > inode->i_size) {\n\t\terror = -EPERM;\n\t\tgoto out;\n\t}\n\n\t \n\tvma_init(&pseudo_vma, mm);\n\tvm_flags_init(&pseudo_vma, VM_HUGETLB | VM_MAYSHARE | VM_SHARED);\n\tpseudo_vma.vm_file = file;\n\n\tfor (index = start; index < end; index++) {\n\t\t \n\t\tstruct folio *folio;\n\t\tunsigned long addr;\n\n\t\tcond_resched();\n\n\t\t \n\t\tif (signal_pending(current)) {\n\t\t\terror = -EINTR;\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\taddr = index * hpage_size;\n\n\t\t \n\t\thash = hugetlb_fault_mutex_hash(mapping, index);\n\t\tmutex_lock(&hugetlb_fault_mutex_table[hash]);\n\n\t\t \n\t\tfolio = filemap_get_folio(mapping, index);\n\t\tif (!IS_ERR(folio)) {\n\t\t\tfolio_put(folio);\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\thugetlb_set_vma_policy(&pseudo_vma, inode, index);\n\t\tfolio = alloc_hugetlb_folio(&pseudo_vma, addr, 0);\n\t\thugetlb_drop_vma_policy(&pseudo_vma);\n\t\tif (IS_ERR(folio)) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\terror = PTR_ERR(folio);\n\t\t\tgoto out;\n\t\t}\n\t\tclear_huge_page(&folio->page, addr, pages_per_huge_page(h));\n\t\t__folio_mark_uptodate(folio);\n\t\terror = hugetlb_add_to_page_cache(folio, mapping, index);\n\t\tif (unlikely(error)) {\n\t\t\trestore_reserve_on_error(h, &pseudo_vma, addr, folio);\n\t\t\tfolio_put(folio);\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out;\n\t\t}\n\n\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\n\t\tfolio_set_hugetlb_migratable(folio);\n\t\t \n\t\tfolio_unlock(folio);\n\t\tfolio_put(folio);\n\t}\n\n\tif (!(mode & FALLOC_FL_KEEP_SIZE) && offset + len > inode->i_size)\n\t\ti_size_write(inode, offset + len);\n\tinode_set_ctime_current(inode);\nout:\n\tinode_unlock(inode);\n\treturn error;\n}\n\nstatic int hugetlbfs_setattr(struct mnt_idmap *idmap,\n\t\t\t     struct dentry *dentry, struct iattr *attr)\n{\n\tstruct inode *inode = d_inode(dentry);\n\tstruct hstate *h = hstate_inode(inode);\n\tint error;\n\tunsigned int ia_valid = attr->ia_valid;\n\tstruct hugetlbfs_inode_info *info = HUGETLBFS_I(inode);\n\n\terror = setattr_prepare(&nop_mnt_idmap, dentry, attr);\n\tif (error)\n\t\treturn error;\n\n\tif (ia_valid & ATTR_SIZE) {\n\t\tloff_t oldsize = inode->i_size;\n\t\tloff_t newsize = attr->ia_size;\n\n\t\tif (newsize & ~huge_page_mask(h))\n\t\t\treturn -EINVAL;\n\t\t \n\t\tif ((newsize < oldsize && (info->seals & F_SEAL_SHRINK)) ||\n\t\t    (newsize > oldsize && (info->seals & F_SEAL_GROW)))\n\t\t\treturn -EPERM;\n\t\thugetlb_vmtruncate(inode, newsize);\n\t}\n\n\tsetattr_copy(&nop_mnt_idmap, inode, attr);\n\tmark_inode_dirty(inode);\n\treturn 0;\n}\n\nstatic struct inode *hugetlbfs_get_root(struct super_block *sb,\n\t\t\t\t\tstruct hugetlbfs_fs_context *ctx)\n{\n\tstruct inode *inode;\n\n\tinode = new_inode(sb);\n\tif (inode) {\n\t\tinode->i_ino = get_next_ino();\n\t\tinode->i_mode = S_IFDIR | ctx->mode;\n\t\tinode->i_uid = ctx->uid;\n\t\tinode->i_gid = ctx->gid;\n\t\tinode->i_atime = inode->i_mtime = inode_set_ctime_current(inode);\n\t\tinode->i_op = &hugetlbfs_dir_inode_operations;\n\t\tinode->i_fop = &simple_dir_operations;\n\t\t \n\t\tinc_nlink(inode);\n\t\tlockdep_annotate_inode_mutex_key(inode);\n\t}\n\treturn inode;\n}\n\n \nstatic struct lock_class_key hugetlbfs_i_mmap_rwsem_key;\n\nstatic struct inode *hugetlbfs_get_inode(struct super_block *sb,\n\t\t\t\t\tstruct inode *dir,\n\t\t\t\t\tumode_t mode, dev_t dev)\n{\n\tstruct inode *inode;\n\tstruct resv_map *resv_map = NULL;\n\n\t \n\tif (S_ISREG(mode) || S_ISLNK(mode)) {\n\t\tresv_map = resv_map_alloc();\n\t\tif (!resv_map)\n\t\t\treturn NULL;\n\t}\n\n\tinode = new_inode(sb);\n\tif (inode) {\n\t\tstruct hugetlbfs_inode_info *info = HUGETLBFS_I(inode);\n\n\t\tinode->i_ino = get_next_ino();\n\t\tinode_init_owner(&nop_mnt_idmap, inode, dir, mode);\n\t\tlockdep_set_class(&inode->i_mapping->i_mmap_rwsem,\n\t\t\t\t&hugetlbfs_i_mmap_rwsem_key);\n\t\tinode->i_mapping->a_ops = &hugetlbfs_aops;\n\t\tinode->i_atime = inode->i_mtime = inode_set_ctime_current(inode);\n\t\tinode->i_mapping->private_data = resv_map;\n\t\tinfo->seals = F_SEAL_SEAL;\n\t\tswitch (mode & S_IFMT) {\n\t\tdefault:\n\t\t\tinit_special_inode(inode, mode, dev);\n\t\t\tbreak;\n\t\tcase S_IFREG:\n\t\t\tinode->i_op = &hugetlbfs_inode_operations;\n\t\t\tinode->i_fop = &hugetlbfs_file_operations;\n\t\t\tbreak;\n\t\tcase S_IFDIR:\n\t\t\tinode->i_op = &hugetlbfs_dir_inode_operations;\n\t\t\tinode->i_fop = &simple_dir_operations;\n\n\t\t\t \n\t\t\tinc_nlink(inode);\n\t\t\tbreak;\n\t\tcase S_IFLNK:\n\t\t\tinode->i_op = &page_symlink_inode_operations;\n\t\t\tinode_nohighmem(inode);\n\t\t\tbreak;\n\t\t}\n\t\tlockdep_annotate_inode_mutex_key(inode);\n\t} else {\n\t\tif (resv_map)\n\t\t\tkref_put(&resv_map->refs, resv_map_release);\n\t}\n\n\treturn inode;\n}\n\n \nstatic int hugetlbfs_mknod(struct mnt_idmap *idmap, struct inode *dir,\n\t\t\t   struct dentry *dentry, umode_t mode, dev_t dev)\n{\n\tstruct inode *inode;\n\n\tinode = hugetlbfs_get_inode(dir->i_sb, dir, mode, dev);\n\tif (!inode)\n\t\treturn -ENOSPC;\n\tdir->i_mtime = inode_set_ctime_current(dir);\n\td_instantiate(dentry, inode);\n\tdget(dentry); \n\treturn 0;\n}\n\nstatic int hugetlbfs_mkdir(struct mnt_idmap *idmap, struct inode *dir,\n\t\t\t   struct dentry *dentry, umode_t mode)\n{\n\tint retval = hugetlbfs_mknod(&nop_mnt_idmap, dir, dentry,\n\t\t\t\t     mode | S_IFDIR, 0);\n\tif (!retval)\n\t\tinc_nlink(dir);\n\treturn retval;\n}\n\nstatic int hugetlbfs_create(struct mnt_idmap *idmap,\n\t\t\t    struct inode *dir, struct dentry *dentry,\n\t\t\t    umode_t mode, bool excl)\n{\n\treturn hugetlbfs_mknod(&nop_mnt_idmap, dir, dentry, mode | S_IFREG, 0);\n}\n\nstatic int hugetlbfs_tmpfile(struct mnt_idmap *idmap,\n\t\t\t     struct inode *dir, struct file *file,\n\t\t\t     umode_t mode)\n{\n\tstruct inode *inode;\n\n\tinode = hugetlbfs_get_inode(dir->i_sb, dir, mode | S_IFREG, 0);\n\tif (!inode)\n\t\treturn -ENOSPC;\n\tdir->i_mtime = inode_set_ctime_current(dir);\n\td_tmpfile(file, inode);\n\treturn finish_open_simple(file, 0);\n}\n\nstatic int hugetlbfs_symlink(struct mnt_idmap *idmap,\n\t\t\t     struct inode *dir, struct dentry *dentry,\n\t\t\t     const char *symname)\n{\n\tstruct inode *inode;\n\tint error = -ENOSPC;\n\n\tinode = hugetlbfs_get_inode(dir->i_sb, dir, S_IFLNK|S_IRWXUGO, 0);\n\tif (inode) {\n\t\tint l = strlen(symname)+1;\n\t\terror = page_symlink(inode, symname, l);\n\t\tif (!error) {\n\t\t\td_instantiate(dentry, inode);\n\t\t\tdget(dentry);\n\t\t} else\n\t\t\tiput(inode);\n\t}\n\tdir->i_mtime = inode_set_ctime_current(dir);\n\n\treturn error;\n}\n\n#ifdef CONFIG_MIGRATION\nstatic int hugetlbfs_migrate_folio(struct address_space *mapping,\n\t\t\t\tstruct folio *dst, struct folio *src,\n\t\t\t\tenum migrate_mode mode)\n{\n\tint rc;\n\n\trc = migrate_huge_page_move_mapping(mapping, dst, src);\n\tif (rc != MIGRATEPAGE_SUCCESS)\n\t\treturn rc;\n\n\tif (hugetlb_folio_subpool(src)) {\n\t\thugetlb_set_folio_subpool(dst,\n\t\t\t\t\thugetlb_folio_subpool(src));\n\t\thugetlb_set_folio_subpool(src, NULL);\n\t}\n\n\tif (mode != MIGRATE_SYNC_NO_COPY)\n\t\tfolio_migrate_copy(dst, src);\n\telse\n\t\tfolio_migrate_flags(dst, src);\n\n\treturn MIGRATEPAGE_SUCCESS;\n}\n#else\n#define hugetlbfs_migrate_folio NULL\n#endif\n\nstatic int hugetlbfs_error_remove_page(struct address_space *mapping,\n\t\t\t\tstruct page *page)\n{\n\treturn 0;\n}\n\n \nstatic int hugetlbfs_show_options(struct seq_file *m, struct dentry *root)\n{\n\tstruct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(root->d_sb);\n\tstruct hugepage_subpool *spool = sbinfo->spool;\n\tunsigned long hpage_size = huge_page_size(sbinfo->hstate);\n\tunsigned hpage_shift = huge_page_shift(sbinfo->hstate);\n\tchar mod;\n\n\tif (!uid_eq(sbinfo->uid, GLOBAL_ROOT_UID))\n\t\tseq_printf(m, \",uid=%u\",\n\t\t\t   from_kuid_munged(&init_user_ns, sbinfo->uid));\n\tif (!gid_eq(sbinfo->gid, GLOBAL_ROOT_GID))\n\t\tseq_printf(m, \",gid=%u\",\n\t\t\t   from_kgid_munged(&init_user_ns, sbinfo->gid));\n\tif (sbinfo->mode != 0755)\n\t\tseq_printf(m, \",mode=%o\", sbinfo->mode);\n\tif (sbinfo->max_inodes != -1)\n\t\tseq_printf(m, \",nr_inodes=%lu\", sbinfo->max_inodes);\n\n\thpage_size /= 1024;\n\tmod = 'K';\n\tif (hpage_size >= 1024) {\n\t\thpage_size /= 1024;\n\t\tmod = 'M';\n\t}\n\tseq_printf(m, \",pagesize=%lu%c\", hpage_size, mod);\n\tif (spool) {\n\t\tif (spool->max_hpages != -1)\n\t\t\tseq_printf(m, \",size=%llu\",\n\t\t\t\t   (unsigned long long)spool->max_hpages << hpage_shift);\n\t\tif (spool->min_hpages != -1)\n\t\t\tseq_printf(m, \",min_size=%llu\",\n\t\t\t\t   (unsigned long long)spool->min_hpages << hpage_shift);\n\t}\n\treturn 0;\n}\n\nstatic int hugetlbfs_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(dentry->d_sb);\n\tstruct hstate *h = hstate_inode(d_inode(dentry));\n\n\tbuf->f_type = HUGETLBFS_MAGIC;\n\tbuf->f_bsize = huge_page_size(h);\n\tif (sbinfo) {\n\t\tspin_lock(&sbinfo->stat_lock);\n\t\t \n\t\tif (sbinfo->spool) {\n\t\t\tlong free_pages;\n\n\t\t\tspin_lock_irq(&sbinfo->spool->lock);\n\t\t\tbuf->f_blocks = sbinfo->spool->max_hpages;\n\t\t\tfree_pages = sbinfo->spool->max_hpages\n\t\t\t\t- sbinfo->spool->used_hpages;\n\t\t\tbuf->f_bavail = buf->f_bfree = free_pages;\n\t\t\tspin_unlock_irq(&sbinfo->spool->lock);\n\t\t\tbuf->f_files = sbinfo->max_inodes;\n\t\t\tbuf->f_ffree = sbinfo->free_inodes;\n\t\t}\n\t\tspin_unlock(&sbinfo->stat_lock);\n\t}\n\tbuf->f_namelen = NAME_MAX;\n\treturn 0;\n}\n\nstatic void hugetlbfs_put_super(struct super_block *sb)\n{\n\tstruct hugetlbfs_sb_info *sbi = HUGETLBFS_SB(sb);\n\n\tif (sbi) {\n\t\tsb->s_fs_info = NULL;\n\n\t\tif (sbi->spool)\n\t\t\thugepage_put_subpool(sbi->spool);\n\n\t\tkfree(sbi);\n\t}\n}\n\nstatic inline int hugetlbfs_dec_free_inodes(struct hugetlbfs_sb_info *sbinfo)\n{\n\tif (sbinfo->free_inodes >= 0) {\n\t\tspin_lock(&sbinfo->stat_lock);\n\t\tif (unlikely(!sbinfo->free_inodes)) {\n\t\t\tspin_unlock(&sbinfo->stat_lock);\n\t\t\treturn 0;\n\t\t}\n\t\tsbinfo->free_inodes--;\n\t\tspin_unlock(&sbinfo->stat_lock);\n\t}\n\n\treturn 1;\n}\n\nstatic void hugetlbfs_inc_free_inodes(struct hugetlbfs_sb_info *sbinfo)\n{\n\tif (sbinfo->free_inodes >= 0) {\n\t\tspin_lock(&sbinfo->stat_lock);\n\t\tsbinfo->free_inodes++;\n\t\tspin_unlock(&sbinfo->stat_lock);\n\t}\n}\n\n\nstatic struct kmem_cache *hugetlbfs_inode_cachep;\n\nstatic struct inode *hugetlbfs_alloc_inode(struct super_block *sb)\n{\n\tstruct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(sb);\n\tstruct hugetlbfs_inode_info *p;\n\n\tif (unlikely(!hugetlbfs_dec_free_inodes(sbinfo)))\n\t\treturn NULL;\n\tp = alloc_inode_sb(sb, hugetlbfs_inode_cachep, GFP_KERNEL);\n\tif (unlikely(!p)) {\n\t\thugetlbfs_inc_free_inodes(sbinfo);\n\t\treturn NULL;\n\t}\n\n\t \n\tmpol_shared_policy_init(&p->policy, NULL);\n\n\treturn &p->vfs_inode;\n}\n\nstatic void hugetlbfs_free_inode(struct inode *inode)\n{\n\tkmem_cache_free(hugetlbfs_inode_cachep, HUGETLBFS_I(inode));\n}\n\nstatic void hugetlbfs_destroy_inode(struct inode *inode)\n{\n\thugetlbfs_inc_free_inodes(HUGETLBFS_SB(inode->i_sb));\n\tmpol_free_shared_policy(&HUGETLBFS_I(inode)->policy);\n}\n\nstatic const struct address_space_operations hugetlbfs_aops = {\n\t.write_begin\t= hugetlbfs_write_begin,\n\t.write_end\t= hugetlbfs_write_end,\n\t.dirty_folio\t= noop_dirty_folio,\n\t.migrate_folio  = hugetlbfs_migrate_folio,\n\t.error_remove_page\t= hugetlbfs_error_remove_page,\n};\n\n\nstatic void init_once(void *foo)\n{\n\tstruct hugetlbfs_inode_info *ei = foo;\n\n\tinode_init_once(&ei->vfs_inode);\n}\n\nconst struct file_operations hugetlbfs_file_operations = {\n\t.read_iter\t\t= hugetlbfs_read_iter,\n\t.mmap\t\t\t= hugetlbfs_file_mmap,\n\t.fsync\t\t\t= noop_fsync,\n\t.get_unmapped_area\t= hugetlb_get_unmapped_area,\n\t.llseek\t\t\t= default_llseek,\n\t.fallocate\t\t= hugetlbfs_fallocate,\n};\n\nstatic const struct inode_operations hugetlbfs_dir_inode_operations = {\n\t.create\t\t= hugetlbfs_create,\n\t.lookup\t\t= simple_lookup,\n\t.link\t\t= simple_link,\n\t.unlink\t\t= simple_unlink,\n\t.symlink\t= hugetlbfs_symlink,\n\t.mkdir\t\t= hugetlbfs_mkdir,\n\t.rmdir\t\t= simple_rmdir,\n\t.mknod\t\t= hugetlbfs_mknod,\n\t.rename\t\t= simple_rename,\n\t.setattr\t= hugetlbfs_setattr,\n\t.tmpfile\t= hugetlbfs_tmpfile,\n};\n\nstatic const struct inode_operations hugetlbfs_inode_operations = {\n\t.setattr\t= hugetlbfs_setattr,\n};\n\nstatic const struct super_operations hugetlbfs_ops = {\n\t.alloc_inode    = hugetlbfs_alloc_inode,\n\t.free_inode     = hugetlbfs_free_inode,\n\t.destroy_inode  = hugetlbfs_destroy_inode,\n\t.evict_inode\t= hugetlbfs_evict_inode,\n\t.statfs\t\t= hugetlbfs_statfs,\n\t.put_super\t= hugetlbfs_put_super,\n\t.show_options\t= hugetlbfs_show_options,\n};\n\n \nstatic long\nhugetlbfs_size_to_hpages(struct hstate *h, unsigned long long size_opt,\n\t\t\t enum hugetlbfs_size_type val_type)\n{\n\tif (val_type == NO_SIZE)\n\t\treturn -1;\n\n\tif (val_type == SIZE_PERCENT) {\n\t\tsize_opt <<= huge_page_shift(h);\n\t\tsize_opt *= h->max_huge_pages;\n\t\tdo_div(size_opt, 100);\n\t}\n\n\tsize_opt >>= huge_page_shift(h);\n\treturn size_opt;\n}\n\n \nstatic int hugetlbfs_parse_param(struct fs_context *fc, struct fs_parameter *param)\n{\n\tstruct hugetlbfs_fs_context *ctx = fc->fs_private;\n\tstruct fs_parse_result result;\n\tchar *rest;\n\tunsigned long ps;\n\tint opt;\n\n\topt = fs_parse(fc, hugetlb_fs_parameters, param, &result);\n\tif (opt < 0)\n\t\treturn opt;\n\n\tswitch (opt) {\n\tcase Opt_uid:\n\t\tctx->uid = make_kuid(current_user_ns(), result.uint_32);\n\t\tif (!uid_valid(ctx->uid))\n\t\t\tgoto bad_val;\n\t\treturn 0;\n\n\tcase Opt_gid:\n\t\tctx->gid = make_kgid(current_user_ns(), result.uint_32);\n\t\tif (!gid_valid(ctx->gid))\n\t\t\tgoto bad_val;\n\t\treturn 0;\n\n\tcase Opt_mode:\n\t\tctx->mode = result.uint_32 & 01777U;\n\t\treturn 0;\n\n\tcase Opt_size:\n\t\t \n\t\tif (!param->string || !isdigit(param->string[0]))\n\t\t\tgoto bad_val;\n\t\tctx->max_size_opt = memparse(param->string, &rest);\n\t\tctx->max_val_type = SIZE_STD;\n\t\tif (*rest == '%')\n\t\t\tctx->max_val_type = SIZE_PERCENT;\n\t\treturn 0;\n\n\tcase Opt_nr_inodes:\n\t\t \n\t\tif (!param->string || !isdigit(param->string[0]))\n\t\t\tgoto bad_val;\n\t\tctx->nr_inodes = memparse(param->string, &rest);\n\t\treturn 0;\n\n\tcase Opt_pagesize:\n\t\tps = memparse(param->string, &rest);\n\t\tctx->hstate = size_to_hstate(ps);\n\t\tif (!ctx->hstate) {\n\t\t\tpr_err(\"Unsupported page size %lu MB\\n\", ps / SZ_1M);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn 0;\n\n\tcase Opt_min_size:\n\t\t \n\t\tif (!param->string || !isdigit(param->string[0]))\n\t\t\tgoto bad_val;\n\t\tctx->min_size_opt = memparse(param->string, &rest);\n\t\tctx->min_val_type = SIZE_STD;\n\t\tif (*rest == '%')\n\t\t\tctx->min_val_type = SIZE_PERCENT;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\nbad_val:\n\treturn invalfc(fc, \"Bad value '%s' for mount option '%s'\\n\",\n\t\t      param->string, param->key);\n}\n\n \nstatic int hugetlbfs_validate(struct fs_context *fc)\n{\n\tstruct hugetlbfs_fs_context *ctx = fc->fs_private;\n\n\t \n\tctx->max_hpages = hugetlbfs_size_to_hpages(ctx->hstate,\n\t\t\t\t\t\t   ctx->max_size_opt,\n\t\t\t\t\t\t   ctx->max_val_type);\n\tctx->min_hpages = hugetlbfs_size_to_hpages(ctx->hstate,\n\t\t\t\t\t\t   ctx->min_size_opt,\n\t\t\t\t\t\t   ctx->min_val_type);\n\n\t \n\tif (ctx->max_val_type > NO_SIZE &&\n\t    ctx->min_hpages > ctx->max_hpages) {\n\t\tpr_err(\"Minimum size can not be greater than maximum size\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nhugetlbfs_fill_super(struct super_block *sb, struct fs_context *fc)\n{\n\tstruct hugetlbfs_fs_context *ctx = fc->fs_private;\n\tstruct hugetlbfs_sb_info *sbinfo;\n\n\tsbinfo = kmalloc(sizeof(struct hugetlbfs_sb_info), GFP_KERNEL);\n\tif (!sbinfo)\n\t\treturn -ENOMEM;\n\tsb->s_fs_info = sbinfo;\n\tspin_lock_init(&sbinfo->stat_lock);\n\tsbinfo->hstate\t\t= ctx->hstate;\n\tsbinfo->max_inodes\t= ctx->nr_inodes;\n\tsbinfo->free_inodes\t= ctx->nr_inodes;\n\tsbinfo->spool\t\t= NULL;\n\tsbinfo->uid\t\t= ctx->uid;\n\tsbinfo->gid\t\t= ctx->gid;\n\tsbinfo->mode\t\t= ctx->mode;\n\n\t \n\tif (ctx->max_hpages != -1 || ctx->min_hpages != -1) {\n\t\tsbinfo->spool = hugepage_new_subpool(ctx->hstate,\n\t\t\t\t\t\t     ctx->max_hpages,\n\t\t\t\t\t\t     ctx->min_hpages);\n\t\tif (!sbinfo->spool)\n\t\t\tgoto out_free;\n\t}\n\tsb->s_maxbytes = MAX_LFS_FILESIZE;\n\tsb->s_blocksize = huge_page_size(ctx->hstate);\n\tsb->s_blocksize_bits = huge_page_shift(ctx->hstate);\n\tsb->s_magic = HUGETLBFS_MAGIC;\n\tsb->s_op = &hugetlbfs_ops;\n\tsb->s_time_gran = 1;\n\n\t \n\tsb->s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH;\n\tsb->s_root = d_make_root(hugetlbfs_get_root(sb, ctx));\n\tif (!sb->s_root)\n\t\tgoto out_free;\n\treturn 0;\nout_free:\n\tkfree(sbinfo->spool);\n\tkfree(sbinfo);\n\treturn -ENOMEM;\n}\n\nstatic int hugetlbfs_get_tree(struct fs_context *fc)\n{\n\tint err = hugetlbfs_validate(fc);\n\tif (err)\n\t\treturn err;\n\treturn get_tree_nodev(fc, hugetlbfs_fill_super);\n}\n\nstatic void hugetlbfs_fs_context_free(struct fs_context *fc)\n{\n\tkfree(fc->fs_private);\n}\n\nstatic const struct fs_context_operations hugetlbfs_fs_context_ops = {\n\t.free\t\t= hugetlbfs_fs_context_free,\n\t.parse_param\t= hugetlbfs_parse_param,\n\t.get_tree\t= hugetlbfs_get_tree,\n};\n\nstatic int hugetlbfs_init_fs_context(struct fs_context *fc)\n{\n\tstruct hugetlbfs_fs_context *ctx;\n\n\tctx = kzalloc(sizeof(struct hugetlbfs_fs_context), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->max_hpages\t= -1;  \n\tctx->nr_inodes\t= -1;  \n\tctx->uid\t= current_fsuid();\n\tctx->gid\t= current_fsgid();\n\tctx->mode\t= 0755;\n\tctx->hstate\t= &default_hstate;\n\tctx->min_hpages\t= -1;  \n\tctx->max_val_type = NO_SIZE;\n\tctx->min_val_type = NO_SIZE;\n\tfc->fs_private = ctx;\n\tfc->ops\t= &hugetlbfs_fs_context_ops;\n\treturn 0;\n}\n\nstatic struct file_system_type hugetlbfs_fs_type = {\n\t.name\t\t\t= \"hugetlbfs\",\n\t.init_fs_context\t= hugetlbfs_init_fs_context,\n\t.parameters\t\t= hugetlb_fs_parameters,\n\t.kill_sb\t\t= kill_litter_super,\n};\n\nstatic struct vfsmount *hugetlbfs_vfsmount[HUGE_MAX_HSTATE];\n\nstatic int can_do_hugetlb_shm(void)\n{\n\tkgid_t shm_group;\n\tshm_group = make_kgid(&init_user_ns, sysctl_hugetlb_shm_group);\n\treturn capable(CAP_IPC_LOCK) || in_group_p(shm_group);\n}\n\nstatic int get_hstate_idx(int page_size_log)\n{\n\tstruct hstate *h = hstate_sizelog(page_size_log);\n\n\tif (!h)\n\t\treturn -1;\n\treturn hstate_index(h);\n}\n\n \nstruct file *hugetlb_file_setup(const char *name, size_t size,\n\t\t\t\tvm_flags_t acctflag, int creat_flags,\n\t\t\t\tint page_size_log)\n{\n\tstruct inode *inode;\n\tstruct vfsmount *mnt;\n\tint hstate_idx;\n\tstruct file *file;\n\n\thstate_idx = get_hstate_idx(page_size_log);\n\tif (hstate_idx < 0)\n\t\treturn ERR_PTR(-ENODEV);\n\n\tmnt = hugetlbfs_vfsmount[hstate_idx];\n\tif (!mnt)\n\t\treturn ERR_PTR(-ENOENT);\n\n\tif (creat_flags == HUGETLB_SHMFS_INODE && !can_do_hugetlb_shm()) {\n\t\tstruct ucounts *ucounts = current_ucounts();\n\n\t\tif (user_shm_lock(size, ucounts)) {\n\t\t\tpr_warn_once(\"%s (%d): Using mlock ulimits for SHM_HUGETLB is obsolete\\n\",\n\t\t\t\tcurrent->comm, current->pid);\n\t\t\tuser_shm_unlock(size, ucounts);\n\t\t}\n\t\treturn ERR_PTR(-EPERM);\n\t}\n\n\tfile = ERR_PTR(-ENOSPC);\n\tinode = hugetlbfs_get_inode(mnt->mnt_sb, NULL, S_IFREG | S_IRWXUGO, 0);\n\tif (!inode)\n\t\tgoto out;\n\tif (creat_flags == HUGETLB_SHMFS_INODE)\n\t\tinode->i_flags |= S_PRIVATE;\n\n\tinode->i_size = size;\n\tclear_nlink(inode);\n\n\tif (!hugetlb_reserve_pages(inode, 0,\n\t\t\tsize >> huge_page_shift(hstate_inode(inode)), NULL,\n\t\t\tacctflag))\n\t\tfile = ERR_PTR(-ENOMEM);\n\telse\n\t\tfile = alloc_file_pseudo(inode, mnt, name, O_RDWR,\n\t\t\t\t\t&hugetlbfs_file_operations);\n\tif (!IS_ERR(file))\n\t\treturn file;\n\n\tiput(inode);\nout:\n\treturn file;\n}\n\nstatic struct vfsmount *__init mount_one_hugetlbfs(struct hstate *h)\n{\n\tstruct fs_context *fc;\n\tstruct vfsmount *mnt;\n\n\tfc = fs_context_for_mount(&hugetlbfs_fs_type, SB_KERNMOUNT);\n\tif (IS_ERR(fc)) {\n\t\tmnt = ERR_CAST(fc);\n\t} else {\n\t\tstruct hugetlbfs_fs_context *ctx = fc->fs_private;\n\t\tctx->hstate = h;\n\t\tmnt = fc_mount(fc);\n\t\tput_fs_context(fc);\n\t}\n\tif (IS_ERR(mnt))\n\t\tpr_err(\"Cannot mount internal hugetlbfs for page size %luK\",\n\t\t       huge_page_size(h) / SZ_1K);\n\treturn mnt;\n}\n\nstatic int __init init_hugetlbfs_fs(void)\n{\n\tstruct vfsmount *mnt;\n\tstruct hstate *h;\n\tint error;\n\tint i;\n\n\tif (!hugepages_supported()) {\n\t\tpr_info(\"disabling because there are no supported hugepage sizes\\n\");\n\t\treturn -ENOTSUPP;\n\t}\n\n\terror = -ENOMEM;\n\thugetlbfs_inode_cachep = kmem_cache_create(\"hugetlbfs_inode_cache\",\n\t\t\t\t\tsizeof(struct hugetlbfs_inode_info),\n\t\t\t\t\t0, SLAB_ACCOUNT, init_once);\n\tif (hugetlbfs_inode_cachep == NULL)\n\t\tgoto out;\n\n\terror = register_filesystem(&hugetlbfs_fs_type);\n\tif (error)\n\t\tgoto out_free;\n\n\t \n\tmnt = mount_one_hugetlbfs(&default_hstate);\n\tif (IS_ERR(mnt)) {\n\t\terror = PTR_ERR(mnt);\n\t\tgoto out_unreg;\n\t}\n\thugetlbfs_vfsmount[default_hstate_idx] = mnt;\n\n\t \n\ti = 0;\n\tfor_each_hstate(h) {\n\t\tif (i == default_hstate_idx) {\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tmnt = mount_one_hugetlbfs(h);\n\t\tif (IS_ERR(mnt))\n\t\t\thugetlbfs_vfsmount[i] = NULL;\n\t\telse\n\t\t\thugetlbfs_vfsmount[i] = mnt;\n\t\ti++;\n\t}\n\n\treturn 0;\n\n out_unreg:\n\t(void)unregister_filesystem(&hugetlbfs_fs_type);\n out_free:\n\tkmem_cache_destroy(hugetlbfs_inode_cachep);\n out:\n\treturn error;\n}\nfs_initcall(init_hugetlbfs_fs)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}