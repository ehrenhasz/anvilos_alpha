{
  "module_name": "vfs_cache.c",
  "hash_id": "eca41a86aa20164c4aae31f9ebd38770f03054ffaaa60ffd5c770b4a957000a5",
  "original_prompt": "Ingested from linux-6.6.14/fs/smb/server/vfs_cache.c",
  "human_readable_source": "\n \n\n#include <linux/fs.h>\n#include <linux/filelock.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n\n#include \"glob.h\"\n#include \"vfs_cache.h\"\n#include \"oplock.h\"\n#include \"vfs.h\"\n#include \"connection.h\"\n#include \"mgmt/tree_connect.h\"\n#include \"mgmt/user_session.h\"\n#include \"smb_common.h\"\n\n#define S_DEL_PENDING\t\t\t1\n#define S_DEL_ON_CLS\t\t\t2\n#define S_DEL_ON_CLS_STREAM\t\t8\n\nstatic unsigned int inode_hash_mask __read_mostly;\nstatic unsigned int inode_hash_shift __read_mostly;\nstatic struct hlist_head *inode_hashtable __read_mostly;\nstatic DEFINE_RWLOCK(inode_hash_lock);\n\nstatic struct ksmbd_file_table global_ft;\nstatic atomic_long_t fd_limit;\nstatic struct kmem_cache *filp_cache;\n\nvoid ksmbd_set_fd_limit(unsigned long limit)\n{\n\tlimit = min(limit, get_max_files());\n\tatomic_long_set(&fd_limit, limit);\n}\n\nstatic bool fd_limit_depleted(void)\n{\n\tlong v = atomic_long_dec_return(&fd_limit);\n\n\tif (v >= 0)\n\t\treturn false;\n\tatomic_long_inc(&fd_limit);\n\treturn true;\n}\n\nstatic void fd_limit_close(void)\n{\n\tatomic_long_inc(&fd_limit);\n}\n\n \n\nstatic unsigned long inode_hash(struct super_block *sb, unsigned long hashval)\n{\n\tunsigned long tmp;\n\n\ttmp = (hashval * (unsigned long)sb) ^ (GOLDEN_RATIO_PRIME + hashval) /\n\t\tL1_CACHE_BYTES;\n\ttmp = tmp ^ ((tmp ^ GOLDEN_RATIO_PRIME) >> inode_hash_shift);\n\treturn tmp & inode_hash_mask;\n}\n\nstatic struct ksmbd_inode *__ksmbd_inode_lookup(struct dentry *de)\n{\n\tstruct hlist_head *head = inode_hashtable +\n\t\tinode_hash(d_inode(de)->i_sb, (unsigned long)de);\n\tstruct ksmbd_inode *ci = NULL, *ret_ci = NULL;\n\n\thlist_for_each_entry(ci, head, m_hash) {\n\t\tif (ci->m_de == de) {\n\t\t\tif (atomic_inc_not_zero(&ci->m_count))\n\t\t\t\tret_ci = ci;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn ret_ci;\n}\n\nstatic struct ksmbd_inode *ksmbd_inode_lookup(struct ksmbd_file *fp)\n{\n\treturn __ksmbd_inode_lookup(fp->filp->f_path.dentry);\n}\n\nstruct ksmbd_inode *ksmbd_inode_lookup_lock(struct dentry *d)\n{\n\tstruct ksmbd_inode *ci;\n\n\tread_lock(&inode_hash_lock);\n\tci = __ksmbd_inode_lookup(d);\n\tread_unlock(&inode_hash_lock);\n\n\treturn ci;\n}\n\nint ksmbd_query_inode_status(struct dentry *dentry)\n{\n\tstruct ksmbd_inode *ci;\n\tint ret = KSMBD_INODE_STATUS_UNKNOWN;\n\n\tread_lock(&inode_hash_lock);\n\tci = __ksmbd_inode_lookup(dentry);\n\tif (ci) {\n\t\tret = KSMBD_INODE_STATUS_OK;\n\t\tif (ci->m_flags & (S_DEL_PENDING | S_DEL_ON_CLS))\n\t\t\tret = KSMBD_INODE_STATUS_PENDING_DELETE;\n\t\tatomic_dec(&ci->m_count);\n\t}\n\tread_unlock(&inode_hash_lock);\n\treturn ret;\n}\n\nbool ksmbd_inode_pending_delete(struct ksmbd_file *fp)\n{\n\treturn (fp->f_ci->m_flags & (S_DEL_PENDING | S_DEL_ON_CLS));\n}\n\nvoid ksmbd_set_inode_pending_delete(struct ksmbd_file *fp)\n{\n\tfp->f_ci->m_flags |= S_DEL_PENDING;\n}\n\nvoid ksmbd_clear_inode_pending_delete(struct ksmbd_file *fp)\n{\n\tfp->f_ci->m_flags &= ~S_DEL_PENDING;\n}\n\nvoid ksmbd_fd_set_delete_on_close(struct ksmbd_file *fp,\n\t\t\t\t  int file_info)\n{\n\tif (ksmbd_stream_fd(fp)) {\n\t\tfp->f_ci->m_flags |= S_DEL_ON_CLS_STREAM;\n\t\treturn;\n\t}\n\n\tfp->f_ci->m_flags |= S_DEL_ON_CLS;\n}\n\nstatic void ksmbd_inode_hash(struct ksmbd_inode *ci)\n{\n\tstruct hlist_head *b = inode_hashtable +\n\t\tinode_hash(d_inode(ci->m_de)->i_sb, (unsigned long)ci->m_de);\n\n\thlist_add_head(&ci->m_hash, b);\n}\n\nstatic void ksmbd_inode_unhash(struct ksmbd_inode *ci)\n{\n\twrite_lock(&inode_hash_lock);\n\thlist_del_init(&ci->m_hash);\n\twrite_unlock(&inode_hash_lock);\n}\n\nstatic int ksmbd_inode_init(struct ksmbd_inode *ci, struct ksmbd_file *fp)\n{\n\tatomic_set(&ci->m_count, 1);\n\tatomic_set(&ci->op_count, 0);\n\tatomic_set(&ci->sop_count, 0);\n\tci->m_flags = 0;\n\tci->m_fattr = 0;\n\tINIT_LIST_HEAD(&ci->m_fp_list);\n\tINIT_LIST_HEAD(&ci->m_op_list);\n\trwlock_init(&ci->m_lock);\n\tci->m_de = fp->filp->f_path.dentry;\n\treturn 0;\n}\n\nstatic struct ksmbd_inode *ksmbd_inode_get(struct ksmbd_file *fp)\n{\n\tstruct ksmbd_inode *ci, *tmpci;\n\tint rc;\n\n\tread_lock(&inode_hash_lock);\n\tci = ksmbd_inode_lookup(fp);\n\tread_unlock(&inode_hash_lock);\n\tif (ci)\n\t\treturn ci;\n\n\tci = kmalloc(sizeof(struct ksmbd_inode), GFP_KERNEL);\n\tif (!ci)\n\t\treturn NULL;\n\n\trc = ksmbd_inode_init(ci, fp);\n\tif (rc) {\n\t\tpr_err(\"inode initialized failed\\n\");\n\t\tkfree(ci);\n\t\treturn NULL;\n\t}\n\n\twrite_lock(&inode_hash_lock);\n\ttmpci = ksmbd_inode_lookup(fp);\n\tif (!tmpci) {\n\t\tksmbd_inode_hash(ci);\n\t} else {\n\t\tkfree(ci);\n\t\tci = tmpci;\n\t}\n\twrite_unlock(&inode_hash_lock);\n\treturn ci;\n}\n\nstatic void ksmbd_inode_free(struct ksmbd_inode *ci)\n{\n\tksmbd_inode_unhash(ci);\n\tkfree(ci);\n}\n\nvoid ksmbd_inode_put(struct ksmbd_inode *ci)\n{\n\tif (atomic_dec_and_test(&ci->m_count))\n\t\tksmbd_inode_free(ci);\n}\n\nint __init ksmbd_inode_hash_init(void)\n{\n\tunsigned int loop;\n\tunsigned long numentries = 16384;\n\tunsigned long bucketsize = sizeof(struct hlist_head);\n\tunsigned long size;\n\n\tinode_hash_shift = ilog2(numentries);\n\tinode_hash_mask = (1 << inode_hash_shift) - 1;\n\n\tsize = bucketsize << inode_hash_shift;\n\n\t \n\tinode_hashtable = vmalloc(size);\n\tif (!inode_hashtable)\n\t\treturn -ENOMEM;\n\n\tfor (loop = 0; loop < (1U << inode_hash_shift); loop++)\n\t\tINIT_HLIST_HEAD(&inode_hashtable[loop]);\n\treturn 0;\n}\n\nvoid ksmbd_release_inode_hash(void)\n{\n\tvfree(inode_hashtable);\n}\n\nstatic void __ksmbd_inode_close(struct ksmbd_file *fp)\n{\n\tstruct ksmbd_inode *ci = fp->f_ci;\n\tint err;\n\tstruct file *filp;\n\n\tfilp = fp->filp;\n\tif (ksmbd_stream_fd(fp) && (ci->m_flags & S_DEL_ON_CLS_STREAM)) {\n\t\tci->m_flags &= ~S_DEL_ON_CLS_STREAM;\n\t\terr = ksmbd_vfs_remove_xattr(file_mnt_idmap(filp),\n\t\t\t\t\t     &filp->f_path,\n\t\t\t\t\t     fp->stream.name);\n\t\tif (err)\n\t\t\tpr_err(\"remove xattr failed : %s\\n\",\n\t\t\t       fp->stream.name);\n\t}\n\n\tif (atomic_dec_and_test(&ci->m_count)) {\n\t\twrite_lock(&ci->m_lock);\n\t\tif (ci->m_flags & (S_DEL_ON_CLS | S_DEL_PENDING)) {\n\t\t\tci->m_flags &= ~(S_DEL_ON_CLS | S_DEL_PENDING);\n\t\t\twrite_unlock(&ci->m_lock);\n\t\t\tksmbd_vfs_unlink(filp);\n\t\t\twrite_lock(&ci->m_lock);\n\t\t}\n\t\twrite_unlock(&ci->m_lock);\n\n\t\tksmbd_inode_free(ci);\n\t}\n}\n\nstatic void __ksmbd_remove_durable_fd(struct ksmbd_file *fp)\n{\n\tif (!has_file_id(fp->persistent_id))\n\t\treturn;\n\n\twrite_lock(&global_ft.lock);\n\tidr_remove(global_ft.idr, fp->persistent_id);\n\twrite_unlock(&global_ft.lock);\n}\n\nstatic void __ksmbd_remove_fd(struct ksmbd_file_table *ft, struct ksmbd_file *fp)\n{\n\tif (!has_file_id(fp->volatile_id))\n\t\treturn;\n\n\twrite_lock(&fp->f_ci->m_lock);\n\tlist_del_init(&fp->node);\n\twrite_unlock(&fp->f_ci->m_lock);\n\n\twrite_lock(&ft->lock);\n\tidr_remove(ft->idr, fp->volatile_id);\n\twrite_unlock(&ft->lock);\n}\n\nstatic void __ksmbd_close_fd(struct ksmbd_file_table *ft, struct ksmbd_file *fp)\n{\n\tstruct file *filp;\n\tstruct ksmbd_lock *smb_lock, *tmp_lock;\n\n\tfd_limit_close();\n\t__ksmbd_remove_durable_fd(fp);\n\t__ksmbd_remove_fd(ft, fp);\n\n\tclose_id_del_oplock(fp);\n\tfilp = fp->filp;\n\n\t__ksmbd_inode_close(fp);\n\tif (!IS_ERR_OR_NULL(filp))\n\t\tfput(filp);\n\n\t \n\tlist_for_each_entry_safe(smb_lock, tmp_lock, &fp->lock_list, flist) {\n\t\tspin_lock(&fp->conn->llist_lock);\n\t\tlist_del(&smb_lock->clist);\n\t\tspin_unlock(&fp->conn->llist_lock);\n\n\t\tlist_del(&smb_lock->flist);\n\t\tlocks_free_lock(smb_lock->fl);\n\t\tkfree(smb_lock);\n\t}\n\n\tif (ksmbd_stream_fd(fp))\n\t\tkfree(fp->stream.name);\n\tkmem_cache_free(filp_cache, fp);\n}\n\nstatic struct ksmbd_file *ksmbd_fp_get(struct ksmbd_file *fp)\n{\n\tif (fp->f_state != FP_INITED)\n\t\treturn NULL;\n\n\tif (!atomic_inc_not_zero(&fp->refcount))\n\t\treturn NULL;\n\treturn fp;\n}\n\nstatic struct ksmbd_file *__ksmbd_lookup_fd(struct ksmbd_file_table *ft,\n\t\t\t\t\t    u64 id)\n{\n\tstruct ksmbd_file *fp;\n\n\tif (!has_file_id(id))\n\t\treturn NULL;\n\n\tread_lock(&ft->lock);\n\tfp = idr_find(ft->idr, id);\n\tif (fp)\n\t\tfp = ksmbd_fp_get(fp);\n\tread_unlock(&ft->lock);\n\treturn fp;\n}\n\nstatic void __put_fd_final(struct ksmbd_work *work, struct ksmbd_file *fp)\n{\n\t__ksmbd_close_fd(&work->sess->file_table, fp);\n\tatomic_dec(&work->conn->stats.open_files_count);\n}\n\nstatic void set_close_state_blocked_works(struct ksmbd_file *fp)\n{\n\tstruct ksmbd_work *cancel_work;\n\n\tspin_lock(&fp->f_lock);\n\tlist_for_each_entry(cancel_work, &fp->blocked_works,\n\t\t\t\t fp_entry) {\n\t\tcancel_work->state = KSMBD_WORK_CLOSED;\n\t\tcancel_work->cancel_fn(cancel_work->cancel_argv);\n\t}\n\tspin_unlock(&fp->f_lock);\n}\n\nint ksmbd_close_fd(struct ksmbd_work *work, u64 id)\n{\n\tstruct ksmbd_file\t*fp;\n\tstruct ksmbd_file_table\t*ft;\n\n\tif (!has_file_id(id))\n\t\treturn 0;\n\n\tft = &work->sess->file_table;\n\twrite_lock(&ft->lock);\n\tfp = idr_find(ft->idr, id);\n\tif (fp) {\n\t\tset_close_state_blocked_works(fp);\n\n\t\tif (fp->f_state != FP_INITED)\n\t\t\tfp = NULL;\n\t\telse {\n\t\t\tfp->f_state = FP_CLOSED;\n\t\t\tif (!atomic_dec_and_test(&fp->refcount))\n\t\t\t\tfp = NULL;\n\t\t}\n\t}\n\twrite_unlock(&ft->lock);\n\n\tif (!fp)\n\t\treturn -EINVAL;\n\n\t__put_fd_final(work, fp);\n\treturn 0;\n}\n\nvoid ksmbd_fd_put(struct ksmbd_work *work, struct ksmbd_file *fp)\n{\n\tif (!fp)\n\t\treturn;\n\n\tif (!atomic_dec_and_test(&fp->refcount))\n\t\treturn;\n\t__put_fd_final(work, fp);\n}\n\nstatic bool __sanity_check(struct ksmbd_tree_connect *tcon, struct ksmbd_file *fp)\n{\n\tif (!fp)\n\t\treturn false;\n\tif (fp->tcon != tcon)\n\t\treturn false;\n\treturn true;\n}\n\nstruct ksmbd_file *ksmbd_lookup_foreign_fd(struct ksmbd_work *work, u64 id)\n{\n\treturn __ksmbd_lookup_fd(&work->sess->file_table, id);\n}\n\nstruct ksmbd_file *ksmbd_lookup_fd_fast(struct ksmbd_work *work, u64 id)\n{\n\tstruct ksmbd_file *fp = __ksmbd_lookup_fd(&work->sess->file_table, id);\n\n\tif (__sanity_check(work->tcon, fp))\n\t\treturn fp;\n\n\tksmbd_fd_put(work, fp);\n\treturn NULL;\n}\n\nstruct ksmbd_file *ksmbd_lookup_fd_slow(struct ksmbd_work *work, u64 id,\n\t\t\t\t\tu64 pid)\n{\n\tstruct ksmbd_file *fp;\n\n\tif (!has_file_id(id)) {\n\t\tid = work->compound_fid;\n\t\tpid = work->compound_pfid;\n\t}\n\n\tfp = __ksmbd_lookup_fd(&work->sess->file_table, id);\n\tif (!__sanity_check(work->tcon, fp)) {\n\t\tksmbd_fd_put(work, fp);\n\t\treturn NULL;\n\t}\n\tif (fp->persistent_id != pid) {\n\t\tksmbd_fd_put(work, fp);\n\t\treturn NULL;\n\t}\n\treturn fp;\n}\n\nstruct ksmbd_file *ksmbd_lookup_durable_fd(unsigned long long id)\n{\n\treturn __ksmbd_lookup_fd(&global_ft, id);\n}\n\nstruct ksmbd_file *ksmbd_lookup_fd_cguid(char *cguid)\n{\n\tstruct ksmbd_file\t*fp = NULL;\n\tunsigned int\t\tid;\n\n\tread_lock(&global_ft.lock);\n\tidr_for_each_entry(global_ft.idr, fp, id) {\n\t\tif (!memcmp(fp->create_guid,\n\t\t\t    cguid,\n\t\t\t    SMB2_CREATE_GUID_SIZE)) {\n\t\t\tfp = ksmbd_fp_get(fp);\n\t\t\tbreak;\n\t\t}\n\t}\n\tread_unlock(&global_ft.lock);\n\n\treturn fp;\n}\n\nstruct ksmbd_file *ksmbd_lookup_fd_inode(struct dentry *dentry)\n{\n\tstruct ksmbd_file\t*lfp;\n\tstruct ksmbd_inode\t*ci;\n\tstruct inode\t\t*inode = d_inode(dentry);\n\n\tread_lock(&inode_hash_lock);\n\tci = __ksmbd_inode_lookup(dentry);\n\tread_unlock(&inode_hash_lock);\n\tif (!ci)\n\t\treturn NULL;\n\n\tread_lock(&ci->m_lock);\n\tlist_for_each_entry(lfp, &ci->m_fp_list, node) {\n\t\tif (inode == file_inode(lfp->filp)) {\n\t\t\tatomic_dec(&ci->m_count);\n\t\t\tlfp = ksmbd_fp_get(lfp);\n\t\t\tread_unlock(&ci->m_lock);\n\t\t\treturn lfp;\n\t\t}\n\t}\n\tatomic_dec(&ci->m_count);\n\tread_unlock(&ci->m_lock);\n\treturn NULL;\n}\n\n#define OPEN_ID_TYPE_VOLATILE_ID\t(0)\n#define OPEN_ID_TYPE_PERSISTENT_ID\t(1)\n\nstatic void __open_id_set(struct ksmbd_file *fp, u64 id, int type)\n{\n\tif (type == OPEN_ID_TYPE_VOLATILE_ID)\n\t\tfp->volatile_id = id;\n\tif (type == OPEN_ID_TYPE_PERSISTENT_ID)\n\t\tfp->persistent_id = id;\n}\n\nstatic int __open_id(struct ksmbd_file_table *ft, struct ksmbd_file *fp,\n\t\t     int type)\n{\n\tu64\t\t\tid = 0;\n\tint\t\t\tret;\n\n\tif (type == OPEN_ID_TYPE_VOLATILE_ID && fd_limit_depleted()) {\n\t\t__open_id_set(fp, KSMBD_NO_FID, type);\n\t\treturn -EMFILE;\n\t}\n\n\tidr_preload(GFP_KERNEL);\n\twrite_lock(&ft->lock);\n\tret = idr_alloc_cyclic(ft->idr, fp, 0, INT_MAX - 1, GFP_NOWAIT);\n\tif (ret >= 0) {\n\t\tid = ret;\n\t\tret = 0;\n\t} else {\n\t\tid = KSMBD_NO_FID;\n\t\tfd_limit_close();\n\t}\n\n\t__open_id_set(fp, id, type);\n\twrite_unlock(&ft->lock);\n\tidr_preload_end();\n\treturn ret;\n}\n\nunsigned int ksmbd_open_durable_fd(struct ksmbd_file *fp)\n{\n\t__open_id(&global_ft, fp, OPEN_ID_TYPE_PERSISTENT_ID);\n\treturn fp->persistent_id;\n}\n\nstruct ksmbd_file *ksmbd_open_fd(struct ksmbd_work *work, struct file *filp)\n{\n\tstruct ksmbd_file *fp;\n\tint ret;\n\n\tfp = kmem_cache_zalloc(filp_cache, GFP_KERNEL);\n\tif (!fp) {\n\t\tpr_err(\"Failed to allocate memory\\n\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tINIT_LIST_HEAD(&fp->blocked_works);\n\tINIT_LIST_HEAD(&fp->node);\n\tINIT_LIST_HEAD(&fp->lock_list);\n\tspin_lock_init(&fp->f_lock);\n\tatomic_set(&fp->refcount, 1);\n\n\tfp->filp\t\t= filp;\n\tfp->conn\t\t= work->conn;\n\tfp->tcon\t\t= work->tcon;\n\tfp->volatile_id\t\t= KSMBD_NO_FID;\n\tfp->persistent_id\t= KSMBD_NO_FID;\n\tfp->f_state\t\t= FP_NEW;\n\tfp->f_ci\t\t= ksmbd_inode_get(fp);\n\n\tif (!fp->f_ci) {\n\t\tret = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tret = __open_id(&work->sess->file_table, fp, OPEN_ID_TYPE_VOLATILE_ID);\n\tif (ret) {\n\t\tksmbd_inode_put(fp->f_ci);\n\t\tgoto err_out;\n\t}\n\n\tatomic_inc(&work->conn->stats.open_files_count);\n\treturn fp;\n\nerr_out:\n\tkmem_cache_free(filp_cache, fp);\n\treturn ERR_PTR(ret);\n}\n\nvoid ksmbd_update_fstate(struct ksmbd_file_table *ft, struct ksmbd_file *fp,\n\t\t\t unsigned int state)\n{\n\tif (!fp)\n\t\treturn;\n\n\twrite_lock(&ft->lock);\n\tfp->f_state = state;\n\twrite_unlock(&ft->lock);\n}\n\nstatic int\n__close_file_table_ids(struct ksmbd_file_table *ft,\n\t\t       struct ksmbd_tree_connect *tcon,\n\t\t       bool (*skip)(struct ksmbd_tree_connect *tcon,\n\t\t\t\t    struct ksmbd_file *fp))\n{\n\tunsigned int\t\t\tid;\n\tstruct ksmbd_file\t\t*fp;\n\tint\t\t\t\tnum = 0;\n\n\tidr_for_each_entry(ft->idr, fp, id) {\n\t\tif (skip(tcon, fp))\n\t\t\tcontinue;\n\n\t\tset_close_state_blocked_works(fp);\n\n\t\tif (!atomic_dec_and_test(&fp->refcount))\n\t\t\tcontinue;\n\t\t__ksmbd_close_fd(ft, fp);\n\t\tnum++;\n\t}\n\treturn num;\n}\n\nstatic bool tree_conn_fd_check(struct ksmbd_tree_connect *tcon,\n\t\t\t       struct ksmbd_file *fp)\n{\n\treturn fp->tcon != tcon;\n}\n\nstatic bool session_fd_check(struct ksmbd_tree_connect *tcon,\n\t\t\t     struct ksmbd_file *fp)\n{\n\treturn false;\n}\n\nvoid ksmbd_close_tree_conn_fds(struct ksmbd_work *work)\n{\n\tint num = __close_file_table_ids(&work->sess->file_table,\n\t\t\t\t\t work->tcon,\n\t\t\t\t\t tree_conn_fd_check);\n\n\tatomic_sub(num, &work->conn->stats.open_files_count);\n}\n\nvoid ksmbd_close_session_fds(struct ksmbd_work *work)\n{\n\tint num = __close_file_table_ids(&work->sess->file_table,\n\t\t\t\t\t work->tcon,\n\t\t\t\t\t session_fd_check);\n\n\tatomic_sub(num, &work->conn->stats.open_files_count);\n}\n\nint ksmbd_init_global_file_table(void)\n{\n\treturn ksmbd_init_file_table(&global_ft);\n}\n\nvoid ksmbd_free_global_file_table(void)\n{\n\tstruct ksmbd_file\t*fp = NULL;\n\tunsigned int\t\tid;\n\n\tidr_for_each_entry(global_ft.idr, fp, id) {\n\t\t__ksmbd_remove_durable_fd(fp);\n\t\tkmem_cache_free(filp_cache, fp);\n\t}\n\n\tksmbd_destroy_file_table(&global_ft);\n}\n\nint ksmbd_init_file_table(struct ksmbd_file_table *ft)\n{\n\tft->idr = kzalloc(sizeof(struct idr), GFP_KERNEL);\n\tif (!ft->idr)\n\t\treturn -ENOMEM;\n\n\tidr_init(ft->idr);\n\trwlock_init(&ft->lock);\n\treturn 0;\n}\n\nvoid ksmbd_destroy_file_table(struct ksmbd_file_table *ft)\n{\n\tif (!ft->idr)\n\t\treturn;\n\n\t__close_file_table_ids(ft, NULL, session_fd_check);\n\tidr_destroy(ft->idr);\n\tkfree(ft->idr);\n\tft->idr = NULL;\n}\n\nint ksmbd_init_file_cache(void)\n{\n\tfilp_cache = kmem_cache_create(\"ksmbd_file_cache\",\n\t\t\t\t       sizeof(struct ksmbd_file), 0,\n\t\t\t\t       SLAB_HWCACHE_ALIGN, NULL);\n\tif (!filp_cache)\n\t\tgoto out;\n\n\treturn 0;\n\nout:\n\tpr_err(\"failed to allocate file cache\\n\");\n\treturn -ENOMEM;\n}\n\nvoid ksmbd_exit_file_cache(void)\n{\n\tkmem_cache_destroy(filp_cache);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}