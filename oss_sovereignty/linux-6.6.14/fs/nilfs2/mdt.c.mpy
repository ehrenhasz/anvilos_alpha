{
  "module_name": "mdt.c",
  "hash_id": "27646f856f8c834d7d3bb3cc18d412c27a4ab4f01d0adfd26d6eff00da8d858b",
  "original_prompt": "Ingested from linux-6.6.14/fs/nilfs2/mdt.c",
  "human_readable_source": "\n \n\n#include <linux/buffer_head.h>\n#include <linux/mpage.h>\n#include <linux/mm.h>\n#include <linux/writeback.h>\n#include <linux/backing-dev.h>\n#include <linux/swap.h>\n#include <linux/slab.h>\n#include \"nilfs.h\"\n#include \"btnode.h\"\n#include \"segment.h\"\n#include \"page.h\"\n#include \"mdt.h\"\n#include \"alloc.h\"\t\t \n\n#include <trace/events/nilfs2.h>\n\n#define NILFS_MDT_MAX_RA_BLOCKS\t\t(16 - 1)\n\n\nstatic int\nnilfs_mdt_insert_new_block(struct inode *inode, unsigned long block,\n\t\t\t   struct buffer_head *bh,\n\t\t\t   void (*init_block)(struct inode *,\n\t\t\t\t\t      struct buffer_head *, void *))\n{\n\tstruct nilfs_inode_info *ii = NILFS_I(inode);\n\tvoid *kaddr;\n\tint ret;\n\n\t \n\n\t \n\tbh->b_blocknr = 0;\n\n\tret = nilfs_bmap_insert(ii->i_bmap, block, (unsigned long)bh);\n\tif (unlikely(ret))\n\t\treturn ret;\n\n\tset_buffer_mapped(bh);\n\n\tkaddr = kmap_atomic(bh->b_page);\n\tmemset(kaddr + bh_offset(bh), 0, i_blocksize(inode));\n\tif (init_block)\n\t\tinit_block(inode, bh, kaddr);\n\tflush_dcache_page(bh->b_page);\n\tkunmap_atomic(kaddr);\n\n\tset_buffer_uptodate(bh);\n\tmark_buffer_dirty(bh);\n\tnilfs_mdt_mark_dirty(inode);\n\n\ttrace_nilfs2_mdt_insert_new_block(inode, inode->i_ino, block);\n\n\treturn 0;\n}\n\nstatic int nilfs_mdt_create_block(struct inode *inode, unsigned long block,\n\t\t\t\t  struct buffer_head **out_bh,\n\t\t\t\t  void (*init_block)(struct inode *,\n\t\t\t\t\t\t     struct buffer_head *,\n\t\t\t\t\t\t     void *))\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct nilfs_transaction_info ti;\n\tstruct buffer_head *bh;\n\tint err;\n\n\tnilfs_transaction_begin(sb, &ti, 0);\n\n\terr = -ENOMEM;\n\tbh = nilfs_grab_buffer(inode, inode->i_mapping, block, 0);\n\tif (unlikely(!bh))\n\t\tgoto failed_unlock;\n\n\terr = -EEXIST;\n\tif (buffer_uptodate(bh))\n\t\tgoto failed_bh;\n\n\twait_on_buffer(bh);\n\tif (buffer_uptodate(bh))\n\t\tgoto failed_bh;\n\n\tbh->b_bdev = sb->s_bdev;\n\terr = nilfs_mdt_insert_new_block(inode, block, bh, init_block);\n\tif (likely(!err)) {\n\t\tget_bh(bh);\n\t\t*out_bh = bh;\n\t}\n\n failed_bh:\n\tunlock_page(bh->b_page);\n\tput_page(bh->b_page);\n\tbrelse(bh);\n\n failed_unlock:\n\tif (likely(!err))\n\t\terr = nilfs_transaction_commit(sb);\n\telse\n\t\tnilfs_transaction_abort(sb);\n\n\treturn err;\n}\n\nstatic int\nnilfs_mdt_submit_block(struct inode *inode, unsigned long blkoff, blk_opf_t opf,\n\t\t       struct buffer_head **out_bh)\n{\n\tstruct buffer_head *bh;\n\t__u64 blknum = 0;\n\tint ret = -ENOMEM;\n\n\tbh = nilfs_grab_buffer(inode, inode->i_mapping, blkoff, 0);\n\tif (unlikely(!bh))\n\t\tgoto failed;\n\n\tret = -EEXIST;  \n\tif (buffer_uptodate(bh))\n\t\tgoto out;\n\n\tif (opf & REQ_RAHEAD) {\n\t\tif (!trylock_buffer(bh)) {\n\t\t\tret = -EBUSY;\n\t\t\tgoto failed_bh;\n\t\t}\n\t} else  \n\t\tlock_buffer(bh);\n\n\tif (buffer_uptodate(bh)) {\n\t\tunlock_buffer(bh);\n\t\tgoto out;\n\t}\n\n\tret = nilfs_bmap_lookup(NILFS_I(inode)->i_bmap, blkoff, &blknum);\n\tif (unlikely(ret)) {\n\t\tunlock_buffer(bh);\n\t\tgoto failed_bh;\n\t}\n\tmap_bh(bh, inode->i_sb, (sector_t)blknum);\n\n\tbh->b_end_io = end_buffer_read_sync;\n\tget_bh(bh);\n\tsubmit_bh(opf, bh);\n\tret = 0;\n\n\ttrace_nilfs2_mdt_submit_block(inode, inode->i_ino, blkoff,\n\t\t\t\t      opf & REQ_OP_MASK);\n out:\n\tget_bh(bh);\n\t*out_bh = bh;\n\n failed_bh:\n\tunlock_page(bh->b_page);\n\tput_page(bh->b_page);\n\tbrelse(bh);\n failed:\n\treturn ret;\n}\n\nstatic int nilfs_mdt_read_block(struct inode *inode, unsigned long block,\n\t\t\t\tint readahead, struct buffer_head **out_bh)\n{\n\tstruct buffer_head *first_bh, *bh;\n\tunsigned long blkoff;\n\tint i, nr_ra_blocks = NILFS_MDT_MAX_RA_BLOCKS;\n\tint err;\n\n\terr = nilfs_mdt_submit_block(inode, block, REQ_OP_READ, &first_bh);\n\tif (err == -EEXIST)  \n\t\tgoto out;\n\n\tif (unlikely(err))\n\t\tgoto failed;\n\n\tif (readahead) {\n\t\tblkoff = block + 1;\n\t\tfor (i = 0; i < nr_ra_blocks; i++, blkoff++) {\n\t\t\terr = nilfs_mdt_submit_block(inode, blkoff,\n\t\t\t\t\t\tREQ_OP_READ | REQ_RAHEAD, &bh);\n\t\t\tif (likely(!err || err == -EEXIST))\n\t\t\t\tbrelse(bh);\n\t\t\telse if (err != -EBUSY)\n\t\t\t\tbreak;\n\t\t\t\t \n\t\t\tif (!buffer_locked(first_bh))\n\t\t\t\tgoto out_no_wait;\n\t\t}\n\t}\n\n\twait_on_buffer(first_bh);\n\n out_no_wait:\n\terr = -EIO;\n\tif (!buffer_uptodate(first_bh)) {\n\t\tnilfs_err(inode->i_sb,\n\t\t\t  \"I/O error reading meta-data file (ino=%lu, block-offset=%lu)\",\n\t\t\t  inode->i_ino, block);\n\t\tgoto failed_bh;\n\t}\n out:\n\t*out_bh = first_bh;\n\treturn 0;\n\n failed_bh:\n\tbrelse(first_bh);\n failed:\n\treturn err;\n}\n\n \nint nilfs_mdt_get_block(struct inode *inode, unsigned long blkoff, int create,\n\t\t\tvoid (*init_block)(struct inode *,\n\t\t\t\t\t   struct buffer_head *, void *),\n\t\t\tstruct buffer_head **out_bh)\n{\n\tint ret;\n\n\t \n retry:\n\tret = nilfs_mdt_read_block(inode, blkoff, !create, out_bh);\n\tif (!create || ret != -ENOENT)\n\t\treturn ret;\n\n\tret = nilfs_mdt_create_block(inode, blkoff, out_bh, init_block);\n\tif (unlikely(ret == -EEXIST)) {\n\t\t    \n\t\tgoto retry;\n\t}\n\treturn ret;\n}\n\n \nint nilfs_mdt_find_block(struct inode *inode, unsigned long start,\n\t\t\t unsigned long end, unsigned long *blkoff,\n\t\t\t struct buffer_head **out_bh)\n{\n\t__u64 next;\n\tint ret;\n\n\tif (unlikely(start > end))\n\t\treturn -ENOENT;\n\n\tret = nilfs_mdt_read_block(inode, start, true, out_bh);\n\tif (!ret) {\n\t\t*blkoff = start;\n\t\tgoto out;\n\t}\n\tif (unlikely(ret != -ENOENT || start == ULONG_MAX))\n\t\tgoto out;\n\n\tret = nilfs_bmap_seek_key(NILFS_I(inode)->i_bmap, start + 1, &next);\n\tif (!ret) {\n\t\tif (next <= end) {\n\t\t\tret = nilfs_mdt_read_block(inode, next, true, out_bh);\n\t\t\tif (!ret)\n\t\t\t\t*blkoff = next;\n\t\t} else {\n\t\t\tret = -ENOENT;\n\t\t}\n\t}\nout:\n\treturn ret;\n}\n\n \nint nilfs_mdt_delete_block(struct inode *inode, unsigned long block)\n{\n\tstruct nilfs_inode_info *ii = NILFS_I(inode);\n\tint err;\n\n\terr = nilfs_bmap_delete(ii->i_bmap, block);\n\tif (!err || err == -ENOENT) {\n\t\tnilfs_mdt_mark_dirty(inode);\n\t\tnilfs_mdt_forget_block(inode, block);\n\t}\n\treturn err;\n}\n\n \nint nilfs_mdt_forget_block(struct inode *inode, unsigned long block)\n{\n\tpgoff_t index = (pgoff_t)block >>\n\t\t(PAGE_SHIFT - inode->i_blkbits);\n\tstruct page *page;\n\tunsigned long first_block;\n\tint ret = 0;\n\tint still_dirty;\n\n\tpage = find_lock_page(inode->i_mapping, index);\n\tif (!page)\n\t\treturn -ENOENT;\n\n\twait_on_page_writeback(page);\n\n\tfirst_block = (unsigned long)index <<\n\t\t(PAGE_SHIFT - inode->i_blkbits);\n\tif (page_has_buffers(page)) {\n\t\tstruct buffer_head *bh;\n\n\t\tbh = nilfs_page_get_nth_block(page, block - first_block);\n\t\tnilfs_forget_buffer(bh);\n\t}\n\tstill_dirty = PageDirty(page);\n\tunlock_page(page);\n\tput_page(page);\n\n\tif (still_dirty ||\n\t    invalidate_inode_pages2_range(inode->i_mapping, index, index) != 0)\n\t\tret = -EBUSY;\n\treturn ret;\n}\n\nint nilfs_mdt_fetch_dirty(struct inode *inode)\n{\n\tstruct nilfs_inode_info *ii = NILFS_I(inode);\n\n\tif (nilfs_bmap_test_and_clear_dirty(ii->i_bmap)) {\n\t\tset_bit(NILFS_I_DIRTY, &ii->i_state);\n\t\treturn 1;\n\t}\n\treturn test_bit(NILFS_I_DIRTY, &ii->i_state);\n}\n\nstatic int\nnilfs_mdt_write_page(struct page *page, struct writeback_control *wbc)\n{\n\tstruct inode *inode = page->mapping->host;\n\tstruct super_block *sb;\n\tint err = 0;\n\n\tif (inode && sb_rdonly(inode->i_sb)) {\n\t\t \n\t\tnilfs_clear_dirty_page(page, false);\n\t\tunlock_page(page);\n\t\treturn -EROFS;\n\t}\n\n\tredirty_page_for_writepage(wbc, page);\n\tunlock_page(page);\n\n\tif (!inode)\n\t\treturn 0;\n\n\tsb = inode->i_sb;\n\n\tif (wbc->sync_mode == WB_SYNC_ALL)\n\t\terr = nilfs_construct_segment(sb);\n\telse if (wbc->for_reclaim)\n\t\tnilfs_flush_segment(sb, inode->i_ino);\n\n\treturn err;\n}\n\n\nstatic const struct address_space_operations def_mdt_aops = {\n\t.dirty_folio\t\t= block_dirty_folio,\n\t.invalidate_folio\t= block_invalidate_folio,\n\t.writepage\t\t= nilfs_mdt_write_page,\n};\n\nstatic const struct inode_operations def_mdt_iops;\nstatic const struct file_operations def_mdt_fops;\n\n\nint nilfs_mdt_init(struct inode *inode, gfp_t gfp_mask, size_t objsz)\n{\n\tstruct nilfs_mdt_info *mi;\n\n\tmi = kzalloc(max(sizeof(*mi), objsz), GFP_NOFS);\n\tif (!mi)\n\t\treturn -ENOMEM;\n\n\tinit_rwsem(&mi->mi_sem);\n\tinode->i_private = mi;\n\n\tinode->i_mode = S_IFREG;\n\tmapping_set_gfp_mask(inode->i_mapping, gfp_mask);\n\n\tinode->i_op = &def_mdt_iops;\n\tinode->i_fop = &def_mdt_fops;\n\tinode->i_mapping->a_ops = &def_mdt_aops;\n\n\treturn 0;\n}\n\n \nvoid nilfs_mdt_clear(struct inode *inode)\n{\n\tstruct nilfs_mdt_info *mdi = NILFS_MDT(inode);\n\tstruct nilfs_shadow_map *shadow = mdi->mi_shadow;\n\n\tif (mdi->mi_palloc_cache)\n\t\tnilfs_palloc_destroy_cache(inode);\n\n\tif (shadow) {\n\t\tstruct inode *s_inode = shadow->inode;\n\n\t\tshadow->inode = NULL;\n\t\tiput(s_inode);\n\t\tmdi->mi_shadow = NULL;\n\t}\n}\n\n \nvoid nilfs_mdt_destroy(struct inode *inode)\n{\n\tstruct nilfs_mdt_info *mdi = NILFS_MDT(inode);\n\n\tkfree(mdi->mi_bgl);  \n\tkfree(mdi);\n}\n\nvoid nilfs_mdt_set_entry_size(struct inode *inode, unsigned int entry_size,\n\t\t\t      unsigned int header_size)\n{\n\tstruct nilfs_mdt_info *mi = NILFS_MDT(inode);\n\n\tmi->mi_entry_size = entry_size;\n\tmi->mi_entries_per_block = i_blocksize(inode) / entry_size;\n\tmi->mi_first_entry_offset = DIV_ROUND_UP(header_size, entry_size);\n}\n\n \nint nilfs_mdt_setup_shadow_map(struct inode *inode,\n\t\t\t       struct nilfs_shadow_map *shadow)\n{\n\tstruct nilfs_mdt_info *mi = NILFS_MDT(inode);\n\tstruct inode *s_inode;\n\n\tINIT_LIST_HEAD(&shadow->frozen_buffers);\n\n\ts_inode = nilfs_iget_for_shadow(inode);\n\tif (IS_ERR(s_inode))\n\t\treturn PTR_ERR(s_inode);\n\n\tshadow->inode = s_inode;\n\tmi->mi_shadow = shadow;\n\treturn 0;\n}\n\n \nint nilfs_mdt_save_to_shadow_map(struct inode *inode)\n{\n\tstruct nilfs_mdt_info *mi = NILFS_MDT(inode);\n\tstruct nilfs_inode_info *ii = NILFS_I(inode);\n\tstruct nilfs_shadow_map *shadow = mi->mi_shadow;\n\tstruct inode *s_inode = shadow->inode;\n\tint ret;\n\n\tret = nilfs_copy_dirty_pages(s_inode->i_mapping, inode->i_mapping);\n\tif (ret)\n\t\tgoto out;\n\n\tret = nilfs_copy_dirty_pages(NILFS_I(s_inode)->i_assoc_inode->i_mapping,\n\t\t\t\t     ii->i_assoc_inode->i_mapping);\n\tif (ret)\n\t\tgoto out;\n\n\tnilfs_bmap_save(ii->i_bmap, &shadow->bmap_store);\n out:\n\treturn ret;\n}\n\nint nilfs_mdt_freeze_buffer(struct inode *inode, struct buffer_head *bh)\n{\n\tstruct nilfs_shadow_map *shadow = NILFS_MDT(inode)->mi_shadow;\n\tstruct buffer_head *bh_frozen;\n\tstruct page *page;\n\tint blkbits = inode->i_blkbits;\n\n\tpage = grab_cache_page(shadow->inode->i_mapping, bh->b_folio->index);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tif (!page_has_buffers(page))\n\t\tcreate_empty_buffers(page, 1 << blkbits, 0);\n\n\tbh_frozen = nilfs_page_get_nth_block(page, bh_offset(bh) >> blkbits);\n\n\tif (!buffer_uptodate(bh_frozen))\n\t\tnilfs_copy_buffer(bh_frozen, bh);\n\tif (list_empty(&bh_frozen->b_assoc_buffers)) {\n\t\tlist_add_tail(&bh_frozen->b_assoc_buffers,\n\t\t\t      &shadow->frozen_buffers);\n\t\tset_buffer_nilfs_redirected(bh);\n\t} else {\n\t\tbrelse(bh_frozen);  \n\t}\n\n\tunlock_page(page);\n\tput_page(page);\n\treturn 0;\n}\n\nstruct buffer_head *\nnilfs_mdt_get_frozen_buffer(struct inode *inode, struct buffer_head *bh)\n{\n\tstruct nilfs_shadow_map *shadow = NILFS_MDT(inode)->mi_shadow;\n\tstruct buffer_head *bh_frozen = NULL;\n\tstruct page *page;\n\tint n;\n\n\tpage = find_lock_page(shadow->inode->i_mapping, bh->b_folio->index);\n\tif (page) {\n\t\tif (page_has_buffers(page)) {\n\t\t\tn = bh_offset(bh) >> inode->i_blkbits;\n\t\t\tbh_frozen = nilfs_page_get_nth_block(page, n);\n\t\t}\n\t\tunlock_page(page);\n\t\tput_page(page);\n\t}\n\treturn bh_frozen;\n}\n\nstatic void nilfs_release_frozen_buffers(struct nilfs_shadow_map *shadow)\n{\n\tstruct list_head *head = &shadow->frozen_buffers;\n\tstruct buffer_head *bh;\n\n\twhile (!list_empty(head)) {\n\t\tbh = list_first_entry(head, struct buffer_head,\n\t\t\t\t      b_assoc_buffers);\n\t\tlist_del_init(&bh->b_assoc_buffers);\n\t\tbrelse(bh);  \n\t}\n}\n\n \nvoid nilfs_mdt_restore_from_shadow_map(struct inode *inode)\n{\n\tstruct nilfs_mdt_info *mi = NILFS_MDT(inode);\n\tstruct nilfs_inode_info *ii = NILFS_I(inode);\n\tstruct nilfs_shadow_map *shadow = mi->mi_shadow;\n\n\tdown_write(&mi->mi_sem);\n\n\tif (mi->mi_palloc_cache)\n\t\tnilfs_palloc_clear_cache(inode);\n\n\tnilfs_clear_dirty_pages(inode->i_mapping, true);\n\tnilfs_copy_back_pages(inode->i_mapping, shadow->inode->i_mapping);\n\n\tnilfs_clear_dirty_pages(ii->i_assoc_inode->i_mapping, true);\n\tnilfs_copy_back_pages(ii->i_assoc_inode->i_mapping,\n\t\t\t      NILFS_I(shadow->inode)->i_assoc_inode->i_mapping);\n\n\tnilfs_bmap_restore(ii->i_bmap, &shadow->bmap_store);\n\n\tup_write(&mi->mi_sem);\n}\n\n \nvoid nilfs_mdt_clear_shadow_map(struct inode *inode)\n{\n\tstruct nilfs_mdt_info *mi = NILFS_MDT(inode);\n\tstruct nilfs_shadow_map *shadow = mi->mi_shadow;\n\tstruct inode *shadow_btnc_inode = NILFS_I(shadow->inode)->i_assoc_inode;\n\n\tdown_write(&mi->mi_sem);\n\tnilfs_release_frozen_buffers(shadow);\n\ttruncate_inode_pages(shadow->inode->i_mapping, 0);\n\ttruncate_inode_pages(shadow_btnc_inode->i_mapping, 0);\n\tup_write(&mi->mi_sem);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}