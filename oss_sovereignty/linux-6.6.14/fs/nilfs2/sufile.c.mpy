{
  "module_name": "sufile.c",
  "hash_id": "9639318bc47d1ce7ea2b7d1ed651af5ab1f8d7e34b8b71c67e1e548529430cb3",
  "original_prompt": "Ingested from linux-6.6.14/fs/nilfs2/sufile.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/fs.h>\n#include <linux/string.h>\n#include <linux/buffer_head.h>\n#include <linux/errno.h>\n#include \"mdt.h\"\n#include \"sufile.h\"\n\n#include <trace/events/nilfs2.h>\n\n \nstruct nilfs_sufile_info {\n\tstruct nilfs_mdt_info mi;\n\tunsigned long ncleansegs; \n\t__u64 allocmin;\t\t \n\t__u64 allocmax;\t\t \n};\n\nstatic inline struct nilfs_sufile_info *NILFS_SUI(struct inode *sufile)\n{\n\treturn (struct nilfs_sufile_info *)NILFS_MDT(sufile);\n}\n\nstatic inline unsigned long\nnilfs_sufile_segment_usages_per_block(const struct inode *sufile)\n{\n\treturn NILFS_MDT(sufile)->mi_entries_per_block;\n}\n\nstatic unsigned long\nnilfs_sufile_get_blkoff(const struct inode *sufile, __u64 segnum)\n{\n\t__u64 t = segnum + NILFS_MDT(sufile)->mi_first_entry_offset;\n\n\tdo_div(t, nilfs_sufile_segment_usages_per_block(sufile));\n\treturn (unsigned long)t;\n}\n\nstatic unsigned long\nnilfs_sufile_get_offset(const struct inode *sufile, __u64 segnum)\n{\n\t__u64 t = segnum + NILFS_MDT(sufile)->mi_first_entry_offset;\n\n\treturn do_div(t, nilfs_sufile_segment_usages_per_block(sufile));\n}\n\nstatic unsigned long\nnilfs_sufile_segment_usages_in_block(const struct inode *sufile, __u64 curr,\n\t\t\t\t     __u64 max)\n{\n\treturn min_t(unsigned long,\n\t\t     nilfs_sufile_segment_usages_per_block(sufile) -\n\t\t     nilfs_sufile_get_offset(sufile, curr),\n\t\t     max - curr + 1);\n}\n\nstatic struct nilfs_segment_usage *\nnilfs_sufile_block_get_segment_usage(const struct inode *sufile, __u64 segnum,\n\t\t\t\t     struct buffer_head *bh, void *kaddr)\n{\n\treturn kaddr + bh_offset(bh) +\n\t\tnilfs_sufile_get_offset(sufile, segnum) *\n\t\tNILFS_MDT(sufile)->mi_entry_size;\n}\n\nstatic inline int nilfs_sufile_get_header_block(struct inode *sufile,\n\t\t\t\t\t\tstruct buffer_head **bhp)\n{\n\treturn nilfs_mdt_get_block(sufile, 0, 0, NULL, bhp);\n}\n\nstatic inline int\nnilfs_sufile_get_segment_usage_block(struct inode *sufile, __u64 segnum,\n\t\t\t\t     int create, struct buffer_head **bhp)\n{\n\treturn nilfs_mdt_get_block(sufile,\n\t\t\t\t   nilfs_sufile_get_blkoff(sufile, segnum),\n\t\t\t\t   create, NULL, bhp);\n}\n\nstatic int nilfs_sufile_delete_segment_usage_block(struct inode *sufile,\n\t\t\t\t\t\t   __u64 segnum)\n{\n\treturn nilfs_mdt_delete_block(sufile,\n\t\t\t\t      nilfs_sufile_get_blkoff(sufile, segnum));\n}\n\nstatic void nilfs_sufile_mod_counter(struct buffer_head *header_bh,\n\t\t\t\t     u64 ncleanadd, u64 ndirtyadd)\n{\n\tstruct nilfs_sufile_header *header;\n\tvoid *kaddr;\n\n\tkaddr = kmap_atomic(header_bh->b_page);\n\theader = kaddr + bh_offset(header_bh);\n\tle64_add_cpu(&header->sh_ncleansegs, ncleanadd);\n\tle64_add_cpu(&header->sh_ndirtysegs, ndirtyadd);\n\tkunmap_atomic(kaddr);\n\n\tmark_buffer_dirty(header_bh);\n}\n\n \nunsigned long nilfs_sufile_get_ncleansegs(struct inode *sufile)\n{\n\treturn NILFS_SUI(sufile)->ncleansegs;\n}\n\n \nint nilfs_sufile_updatev(struct inode *sufile, __u64 *segnumv, size_t nsegs,\n\t\t\t int create, size_t *ndone,\n\t\t\t void (*dofunc)(struct inode *, __u64,\n\t\t\t\t\tstruct buffer_head *,\n\t\t\t\t\tstruct buffer_head *))\n{\n\tstruct buffer_head *header_bh, *bh;\n\tunsigned long blkoff, prev_blkoff;\n\t__u64 *seg;\n\tsize_t nerr = 0, n = 0;\n\tint ret = 0;\n\n\tif (unlikely(nsegs == 0))\n\t\tgoto out;\n\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\tfor (seg = segnumv; seg < segnumv + nsegs; seg++) {\n\t\tif (unlikely(*seg >= nilfs_sufile_get_nsegments(sufile))) {\n\t\t\tnilfs_warn(sufile->i_sb,\n\t\t\t\t   \"%s: invalid segment number: %llu\",\n\t\t\t\t   __func__, (unsigned long long)*seg);\n\t\t\tnerr++;\n\t\t}\n\t}\n\tif (nerr > 0) {\n\t\tret = -EINVAL;\n\t\tgoto out_sem;\n\t}\n\n\tret = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (ret < 0)\n\t\tgoto out_sem;\n\n\tseg = segnumv;\n\tblkoff = nilfs_sufile_get_blkoff(sufile, *seg);\n\tret = nilfs_mdt_get_block(sufile, blkoff, create, NULL, &bh);\n\tif (ret < 0)\n\t\tgoto out_header;\n\n\tfor (;;) {\n\t\tdofunc(sufile, *seg, header_bh, bh);\n\n\t\tif (++seg >= segnumv + nsegs)\n\t\t\tbreak;\n\t\tprev_blkoff = blkoff;\n\t\tblkoff = nilfs_sufile_get_blkoff(sufile, *seg);\n\t\tif (blkoff == prev_blkoff)\n\t\t\tcontinue;\n\n\t\t \n\t\tbrelse(bh);\n\t\tret = nilfs_mdt_get_block(sufile, blkoff, create, NULL, &bh);\n\t\tif (unlikely(ret < 0))\n\t\t\tgoto out_header;\n\t}\n\tbrelse(bh);\n\n out_header:\n\tn = seg - segnumv;\n\tbrelse(header_bh);\n out_sem:\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n out:\n\tif (ndone)\n\t\t*ndone = n;\n\treturn ret;\n}\n\nint nilfs_sufile_update(struct inode *sufile, __u64 segnum, int create,\n\t\t\tvoid (*dofunc)(struct inode *, __u64,\n\t\t\t\t       struct buffer_head *,\n\t\t\t\t       struct buffer_head *))\n{\n\tstruct buffer_head *header_bh, *bh;\n\tint ret;\n\n\tif (unlikely(segnum >= nilfs_sufile_get_nsegments(sufile))) {\n\t\tnilfs_warn(sufile->i_sb, \"%s: invalid segment number: %llu\",\n\t\t\t   __func__, (unsigned long long)segnum);\n\t\treturn -EINVAL;\n\t}\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\n\tret = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (ret < 0)\n\t\tgoto out_sem;\n\n\tret = nilfs_sufile_get_segment_usage_block(sufile, segnum, create, &bh);\n\tif (!ret) {\n\t\tdofunc(sufile, segnum, header_bh, bh);\n\t\tbrelse(bh);\n\t}\n\tbrelse(header_bh);\n\n out_sem:\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\n \nint nilfs_sufile_set_alloc_range(struct inode *sufile, __u64 start, __u64 end)\n{\n\tstruct nilfs_sufile_info *sui = NILFS_SUI(sufile);\n\t__u64 nsegs;\n\tint ret = -ERANGE;\n\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\tnsegs = nilfs_sufile_get_nsegments(sufile);\n\n\tif (start <= end && end < nsegs) {\n\t\tsui->allocmin = start;\n\t\tsui->allocmax = end;\n\t\tret = 0;\n\t}\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\n \nint nilfs_sufile_alloc(struct inode *sufile, __u64 *segnump)\n{\n\tstruct buffer_head *header_bh, *su_bh;\n\tstruct nilfs_sufile_header *header;\n\tstruct nilfs_segment_usage *su;\n\tstruct nilfs_sufile_info *sui = NILFS_SUI(sufile);\n\tsize_t susz = NILFS_MDT(sufile)->mi_entry_size;\n\t__u64 segnum, maxsegnum, last_alloc;\n\tvoid *kaddr;\n\tunsigned long nsegments, nsus, cnt;\n\tint ret, j;\n\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\n\tret = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (ret < 0)\n\t\tgoto out_sem;\n\tkaddr = kmap_atomic(header_bh->b_page);\n\theader = kaddr + bh_offset(header_bh);\n\tlast_alloc = le64_to_cpu(header->sh_last_alloc);\n\tkunmap_atomic(kaddr);\n\n\tnsegments = nilfs_sufile_get_nsegments(sufile);\n\tmaxsegnum = sui->allocmax;\n\tsegnum = last_alloc + 1;\n\tif (segnum < sui->allocmin || segnum > sui->allocmax)\n\t\tsegnum = sui->allocmin;\n\n\tfor (cnt = 0; cnt < nsegments; cnt += nsus) {\n\t\tif (segnum > maxsegnum) {\n\t\t\tif (cnt < sui->allocmax - sui->allocmin + 1) {\n\t\t\t\t \n\t\t\t\tsegnum = sui->allocmin;\n\t\t\t\tmaxsegnum = last_alloc;\n\t\t\t} else if (segnum > sui->allocmin &&\n\t\t\t\t   sui->allocmax + 1 < nsegments) {\n\t\t\t\tsegnum = sui->allocmax + 1;\n\t\t\t\tmaxsegnum = nsegments - 1;\n\t\t\t} else if (sui->allocmin > 0)  {\n\t\t\t\tsegnum = 0;\n\t\t\t\tmaxsegnum = sui->allocmin - 1;\n\t\t\t} else {\n\t\t\t\tbreak;  \n\t\t\t}\n\t\t}\n\t\ttrace_nilfs2_segment_usage_check(sufile, segnum, cnt);\n\t\tret = nilfs_sufile_get_segment_usage_block(sufile, segnum, 1,\n\t\t\t\t\t\t\t   &su_bh);\n\t\tif (ret < 0)\n\t\t\tgoto out_header;\n\t\tkaddr = kmap_atomic(su_bh->b_page);\n\t\tsu = nilfs_sufile_block_get_segment_usage(\n\t\t\tsufile, segnum, su_bh, kaddr);\n\n\t\tnsus = nilfs_sufile_segment_usages_in_block(\n\t\t\tsufile, segnum, maxsegnum);\n\t\tfor (j = 0; j < nsus; j++, su = (void *)su + susz, segnum++) {\n\t\t\tif (!nilfs_segment_usage_clean(su))\n\t\t\t\tcontinue;\n\t\t\t \n\t\t\tnilfs_segment_usage_set_dirty(su);\n\t\t\tkunmap_atomic(kaddr);\n\n\t\t\tkaddr = kmap_atomic(header_bh->b_page);\n\t\t\theader = kaddr + bh_offset(header_bh);\n\t\t\tle64_add_cpu(&header->sh_ncleansegs, -1);\n\t\t\tle64_add_cpu(&header->sh_ndirtysegs, 1);\n\t\t\theader->sh_last_alloc = cpu_to_le64(segnum);\n\t\t\tkunmap_atomic(kaddr);\n\n\t\t\tsui->ncleansegs--;\n\t\t\tmark_buffer_dirty(header_bh);\n\t\t\tmark_buffer_dirty(su_bh);\n\t\t\tnilfs_mdt_mark_dirty(sufile);\n\t\t\tbrelse(su_bh);\n\t\t\t*segnump = segnum;\n\n\t\t\ttrace_nilfs2_segment_usage_allocated(sufile, segnum);\n\n\t\t\tgoto out_header;\n\t\t}\n\n\t\tkunmap_atomic(kaddr);\n\t\tbrelse(su_bh);\n\t}\n\n\t \n\tret = -ENOSPC;\n\n out_header:\n\tbrelse(header_bh);\n\n out_sem:\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\nvoid nilfs_sufile_do_cancel_free(struct inode *sufile, __u64 segnum,\n\t\t\t\t struct buffer_head *header_bh,\n\t\t\t\t struct buffer_head *su_bh)\n{\n\tstruct nilfs_segment_usage *su;\n\tvoid *kaddr;\n\n\tkaddr = kmap_atomic(su_bh->b_page);\n\tsu = nilfs_sufile_block_get_segment_usage(sufile, segnum, su_bh, kaddr);\n\tif (unlikely(!nilfs_segment_usage_clean(su))) {\n\t\tnilfs_warn(sufile->i_sb, \"%s: segment %llu must be clean\",\n\t\t\t   __func__, (unsigned long long)segnum);\n\t\tkunmap_atomic(kaddr);\n\t\treturn;\n\t}\n\tnilfs_segment_usage_set_dirty(su);\n\tkunmap_atomic(kaddr);\n\n\tnilfs_sufile_mod_counter(header_bh, -1, 1);\n\tNILFS_SUI(sufile)->ncleansegs--;\n\n\tmark_buffer_dirty(su_bh);\n\tnilfs_mdt_mark_dirty(sufile);\n}\n\nvoid nilfs_sufile_do_scrap(struct inode *sufile, __u64 segnum,\n\t\t\t   struct buffer_head *header_bh,\n\t\t\t   struct buffer_head *su_bh)\n{\n\tstruct nilfs_segment_usage *su;\n\tvoid *kaddr;\n\tint clean, dirty;\n\n\tkaddr = kmap_atomic(su_bh->b_page);\n\tsu = nilfs_sufile_block_get_segment_usage(sufile, segnum, su_bh, kaddr);\n\tif (su->su_flags == cpu_to_le32(BIT(NILFS_SEGMENT_USAGE_DIRTY)) &&\n\t    su->su_nblocks == cpu_to_le32(0)) {\n\t\tkunmap_atomic(kaddr);\n\t\treturn;\n\t}\n\tclean = nilfs_segment_usage_clean(su);\n\tdirty = nilfs_segment_usage_dirty(su);\n\n\t \n\tsu->su_lastmod = cpu_to_le64(0);\n\tsu->su_nblocks = cpu_to_le32(0);\n\tsu->su_flags = cpu_to_le32(BIT(NILFS_SEGMENT_USAGE_DIRTY));\n\tkunmap_atomic(kaddr);\n\n\tnilfs_sufile_mod_counter(header_bh, clean ? (u64)-1 : 0, dirty ? 0 : 1);\n\tNILFS_SUI(sufile)->ncleansegs -= clean;\n\n\tmark_buffer_dirty(su_bh);\n\tnilfs_mdt_mark_dirty(sufile);\n}\n\nvoid nilfs_sufile_do_free(struct inode *sufile, __u64 segnum,\n\t\t\t  struct buffer_head *header_bh,\n\t\t\t  struct buffer_head *su_bh)\n{\n\tstruct nilfs_segment_usage *su;\n\tvoid *kaddr;\n\tint sudirty;\n\n\tkaddr = kmap_atomic(su_bh->b_page);\n\tsu = nilfs_sufile_block_get_segment_usage(sufile, segnum, su_bh, kaddr);\n\tif (nilfs_segment_usage_clean(su)) {\n\t\tnilfs_warn(sufile->i_sb, \"%s: segment %llu is already clean\",\n\t\t\t   __func__, (unsigned long long)segnum);\n\t\tkunmap_atomic(kaddr);\n\t\treturn;\n\t}\n\tWARN_ON(nilfs_segment_usage_error(su));\n\tWARN_ON(!nilfs_segment_usage_dirty(su));\n\n\tsudirty = nilfs_segment_usage_dirty(su);\n\tnilfs_segment_usage_set_clean(su);\n\tkunmap_atomic(kaddr);\n\tmark_buffer_dirty(su_bh);\n\n\tnilfs_sufile_mod_counter(header_bh, 1, sudirty ? (u64)-1 : 0);\n\tNILFS_SUI(sufile)->ncleansegs++;\n\n\tnilfs_mdt_mark_dirty(sufile);\n\n\ttrace_nilfs2_segment_usage_freed(sufile, segnum);\n}\n\n \nint nilfs_sufile_mark_dirty(struct inode *sufile, __u64 segnum)\n{\n\tstruct buffer_head *bh;\n\tvoid *kaddr;\n\tstruct nilfs_segment_usage *su;\n\tint ret;\n\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\tret = nilfs_sufile_get_segment_usage_block(sufile, segnum, 0, &bh);\n\tif (ret)\n\t\tgoto out_sem;\n\n\tkaddr = kmap_atomic(bh->b_page);\n\tsu = nilfs_sufile_block_get_segment_usage(sufile, segnum, bh, kaddr);\n\tif (unlikely(nilfs_segment_usage_error(su))) {\n\t\tstruct the_nilfs *nilfs = sufile->i_sb->s_fs_info;\n\n\t\tkunmap_atomic(kaddr);\n\t\tbrelse(bh);\n\t\tif (nilfs_segment_is_active(nilfs, segnum)) {\n\t\t\tnilfs_error(sufile->i_sb,\n\t\t\t\t    \"active segment %llu is erroneous\",\n\t\t\t\t    (unsigned long long)segnum);\n\t\t} else {\n\t\t\t \n\t\t\tWARN_ON_ONCE(1);\n\t\t}\n\t\tret = -EIO;\n\t} else {\n\t\tnilfs_segment_usage_set_dirty(su);\n\t\tkunmap_atomic(kaddr);\n\t\tmark_buffer_dirty(bh);\n\t\tnilfs_mdt_mark_dirty(sufile);\n\t\tbrelse(bh);\n\t}\nout_sem:\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\n \nint nilfs_sufile_set_segment_usage(struct inode *sufile, __u64 segnum,\n\t\t\t\t   unsigned long nblocks, time64_t modtime)\n{\n\tstruct buffer_head *bh;\n\tstruct nilfs_segment_usage *su;\n\tvoid *kaddr;\n\tint ret;\n\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\tret = nilfs_sufile_get_segment_usage_block(sufile, segnum, 0, &bh);\n\tif (ret < 0)\n\t\tgoto out_sem;\n\n\tkaddr = kmap_atomic(bh->b_page);\n\tsu = nilfs_sufile_block_get_segment_usage(sufile, segnum, bh, kaddr);\n\tif (modtime) {\n\t\t \n\t\tWARN_ON_ONCE(nilfs_segment_usage_error(su));\n\t\tsu->su_lastmod = cpu_to_le64(modtime);\n\t}\n\tsu->su_nblocks = cpu_to_le32(nblocks);\n\tkunmap_atomic(kaddr);\n\n\tmark_buffer_dirty(bh);\n\tnilfs_mdt_mark_dirty(sufile);\n\tbrelse(bh);\n\n out_sem:\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\n \nint nilfs_sufile_get_stat(struct inode *sufile, struct nilfs_sustat *sustat)\n{\n\tstruct buffer_head *header_bh;\n\tstruct nilfs_sufile_header *header;\n\tstruct the_nilfs *nilfs = sufile->i_sb->s_fs_info;\n\tvoid *kaddr;\n\tint ret;\n\n\tdown_read(&NILFS_MDT(sufile)->mi_sem);\n\n\tret = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (ret < 0)\n\t\tgoto out_sem;\n\n\tkaddr = kmap_atomic(header_bh->b_page);\n\theader = kaddr + bh_offset(header_bh);\n\tsustat->ss_nsegs = nilfs_sufile_get_nsegments(sufile);\n\tsustat->ss_ncleansegs = le64_to_cpu(header->sh_ncleansegs);\n\tsustat->ss_ndirtysegs = le64_to_cpu(header->sh_ndirtysegs);\n\tsustat->ss_ctime = nilfs->ns_ctime;\n\tsustat->ss_nongc_ctime = nilfs->ns_nongc_ctime;\n\tspin_lock(&nilfs->ns_last_segment_lock);\n\tsustat->ss_prot_seq = nilfs->ns_prot_seq;\n\tspin_unlock(&nilfs->ns_last_segment_lock);\n\tkunmap_atomic(kaddr);\n\tbrelse(header_bh);\n\n out_sem:\n\tup_read(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\nvoid nilfs_sufile_do_set_error(struct inode *sufile, __u64 segnum,\n\t\t\t       struct buffer_head *header_bh,\n\t\t\t       struct buffer_head *su_bh)\n{\n\tstruct nilfs_segment_usage *su;\n\tvoid *kaddr;\n\tint suclean;\n\n\tkaddr = kmap_atomic(su_bh->b_page);\n\tsu = nilfs_sufile_block_get_segment_usage(sufile, segnum, su_bh, kaddr);\n\tif (nilfs_segment_usage_error(su)) {\n\t\tkunmap_atomic(kaddr);\n\t\treturn;\n\t}\n\tsuclean = nilfs_segment_usage_clean(su);\n\tnilfs_segment_usage_set_error(su);\n\tkunmap_atomic(kaddr);\n\n\tif (suclean) {\n\t\tnilfs_sufile_mod_counter(header_bh, -1, 0);\n\t\tNILFS_SUI(sufile)->ncleansegs--;\n\t}\n\tmark_buffer_dirty(su_bh);\n\tnilfs_mdt_mark_dirty(sufile);\n}\n\n \nstatic int nilfs_sufile_truncate_range(struct inode *sufile,\n\t\t\t\t       __u64 start, __u64 end)\n{\n\tstruct the_nilfs *nilfs = sufile->i_sb->s_fs_info;\n\tstruct buffer_head *header_bh;\n\tstruct buffer_head *su_bh;\n\tstruct nilfs_segment_usage *su, *su2;\n\tsize_t susz = NILFS_MDT(sufile)->mi_entry_size;\n\tunsigned long segusages_per_block;\n\tunsigned long nsegs, ncleaned;\n\t__u64 segnum;\n\tvoid *kaddr;\n\tssize_t n, nc;\n\tint ret;\n\tint j;\n\n\tnsegs = nilfs_sufile_get_nsegments(sufile);\n\n\tret = -EINVAL;\n\tif (start > end || start >= nsegs)\n\t\tgoto out;\n\n\tret = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tsegusages_per_block = nilfs_sufile_segment_usages_per_block(sufile);\n\tncleaned = 0;\n\n\tfor (segnum = start; segnum <= end; segnum += n) {\n\t\tn = min_t(unsigned long,\n\t\t\t  segusages_per_block -\n\t\t\t\t  nilfs_sufile_get_offset(sufile, segnum),\n\t\t\t  end - segnum + 1);\n\t\tret = nilfs_sufile_get_segment_usage_block(sufile, segnum, 0,\n\t\t\t\t\t\t\t   &su_bh);\n\t\tif (ret < 0) {\n\t\t\tif (ret != -ENOENT)\n\t\t\t\tgoto out_header;\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\t\tkaddr = kmap_atomic(su_bh->b_page);\n\t\tsu = nilfs_sufile_block_get_segment_usage(\n\t\t\tsufile, segnum, su_bh, kaddr);\n\t\tsu2 = su;\n\t\tfor (j = 0; j < n; j++, su = (void *)su + susz) {\n\t\t\tif ((le32_to_cpu(su->su_flags) &\n\t\t\t     ~BIT(NILFS_SEGMENT_USAGE_ERROR)) ||\n\t\t\t    nilfs_segment_is_active(nilfs, segnum + j)) {\n\t\t\t\tret = -EBUSY;\n\t\t\t\tkunmap_atomic(kaddr);\n\t\t\t\tbrelse(su_bh);\n\t\t\t\tgoto out_header;\n\t\t\t}\n\t\t}\n\t\tnc = 0;\n\t\tfor (su = su2, j = 0; j < n; j++, su = (void *)su + susz) {\n\t\t\tif (nilfs_segment_usage_error(su)) {\n\t\t\t\tnilfs_segment_usage_set_clean(su);\n\t\t\t\tnc++;\n\t\t\t}\n\t\t}\n\t\tkunmap_atomic(kaddr);\n\t\tif (nc > 0) {\n\t\t\tmark_buffer_dirty(su_bh);\n\t\t\tncleaned += nc;\n\t\t}\n\t\tbrelse(su_bh);\n\n\t\tif (n == segusages_per_block) {\n\t\t\t \n\t\t\tnilfs_sufile_delete_segment_usage_block(sufile, segnum);\n\t\t}\n\t}\n\tret = 0;\n\nout_header:\n\tif (ncleaned > 0) {\n\t\tNILFS_SUI(sufile)->ncleansegs += ncleaned;\n\t\tnilfs_sufile_mod_counter(header_bh, ncleaned, 0);\n\t\tnilfs_mdt_mark_dirty(sufile);\n\t}\n\tbrelse(header_bh);\nout:\n\treturn ret;\n}\n\n \nint nilfs_sufile_resize(struct inode *sufile, __u64 newnsegs)\n{\n\tstruct the_nilfs *nilfs = sufile->i_sb->s_fs_info;\n\tstruct buffer_head *header_bh;\n\tstruct nilfs_sufile_header *header;\n\tstruct nilfs_sufile_info *sui = NILFS_SUI(sufile);\n\tvoid *kaddr;\n\tunsigned long nsegs, nrsvsegs;\n\tint ret = 0;\n\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\n\tnsegs = nilfs_sufile_get_nsegments(sufile);\n\tif (nsegs == newnsegs)\n\t\tgoto out;\n\n\tret = -ENOSPC;\n\tnrsvsegs = nilfs_nrsvsegs(nilfs, newnsegs);\n\tif (newnsegs < nsegs && nsegs - newnsegs + nrsvsegs > sui->ncleansegs)\n\t\tgoto out;\n\n\tret = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (newnsegs > nsegs) {\n\t\tsui->ncleansegs += newnsegs - nsegs;\n\t} else   {\n\t\tret = nilfs_sufile_truncate_range(sufile, newnsegs, nsegs - 1);\n\t\tif (ret < 0)\n\t\t\tgoto out_header;\n\n\t\tsui->ncleansegs -= nsegs - newnsegs;\n\n\t\t \n\t\tsui->allocmax = newnsegs - 1;\n\t\tsui->allocmin = 0;\n\t}\n\n\tkaddr = kmap_atomic(header_bh->b_page);\n\theader = kaddr + bh_offset(header_bh);\n\theader->sh_ncleansegs = cpu_to_le64(sui->ncleansegs);\n\tkunmap_atomic(kaddr);\n\n\tmark_buffer_dirty(header_bh);\n\tnilfs_mdt_mark_dirty(sufile);\n\tnilfs_set_nsegments(nilfs, newnsegs);\n\nout_header:\n\tbrelse(header_bh);\nout:\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\n \nssize_t nilfs_sufile_get_suinfo(struct inode *sufile, __u64 segnum, void *buf,\n\t\t\t\tunsigned int sisz, size_t nsi)\n{\n\tstruct buffer_head *su_bh;\n\tstruct nilfs_segment_usage *su;\n\tstruct nilfs_suinfo *si = buf;\n\tsize_t susz = NILFS_MDT(sufile)->mi_entry_size;\n\tstruct the_nilfs *nilfs = sufile->i_sb->s_fs_info;\n\tvoid *kaddr;\n\tunsigned long nsegs, segusages_per_block;\n\tssize_t n;\n\tint ret, i, j;\n\n\tdown_read(&NILFS_MDT(sufile)->mi_sem);\n\n\tsegusages_per_block = nilfs_sufile_segment_usages_per_block(sufile);\n\tnsegs = min_t(unsigned long,\n\t\t      nilfs_sufile_get_nsegments(sufile) - segnum,\n\t\t      nsi);\n\tfor (i = 0; i < nsegs; i += n, segnum += n) {\n\t\tn = min_t(unsigned long,\n\t\t\t  segusages_per_block -\n\t\t\t\t  nilfs_sufile_get_offset(sufile, segnum),\n\t\t\t  nsegs - i);\n\t\tret = nilfs_sufile_get_segment_usage_block(sufile, segnum, 0,\n\t\t\t\t\t\t\t   &su_bh);\n\t\tif (ret < 0) {\n\t\t\tif (ret != -ENOENT)\n\t\t\t\tgoto out;\n\t\t\t \n\t\t\tmemset(si, 0, sisz * n);\n\t\t\tsi = (void *)si + sisz * n;\n\t\t\tcontinue;\n\t\t}\n\n\t\tkaddr = kmap_atomic(su_bh->b_page);\n\t\tsu = nilfs_sufile_block_get_segment_usage(\n\t\t\tsufile, segnum, su_bh, kaddr);\n\t\tfor (j = 0; j < n;\n\t\t     j++, su = (void *)su + susz, si = (void *)si + sisz) {\n\t\t\tsi->sui_lastmod = le64_to_cpu(su->su_lastmod);\n\t\t\tsi->sui_nblocks = le32_to_cpu(su->su_nblocks);\n\t\t\tsi->sui_flags = le32_to_cpu(su->su_flags) &\n\t\t\t\t~BIT(NILFS_SEGMENT_USAGE_ACTIVE);\n\t\t\tif (nilfs_segment_is_active(nilfs, segnum + j))\n\t\t\t\tsi->sui_flags |=\n\t\t\t\t\tBIT(NILFS_SEGMENT_USAGE_ACTIVE);\n\t\t}\n\t\tkunmap_atomic(kaddr);\n\t\tbrelse(su_bh);\n\t}\n\tret = nsegs;\n\n out:\n\tup_read(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\n \nssize_t nilfs_sufile_set_suinfo(struct inode *sufile, void *buf,\n\t\t\t\tunsigned int supsz, size_t nsup)\n{\n\tstruct the_nilfs *nilfs = sufile->i_sb->s_fs_info;\n\tstruct buffer_head *header_bh, *bh;\n\tstruct nilfs_suinfo_update *sup, *supend = buf + supsz * nsup;\n\tstruct nilfs_segment_usage *su;\n\tvoid *kaddr;\n\tunsigned long blkoff, prev_blkoff;\n\tint cleansi, cleansu, dirtysi, dirtysu;\n\tlong ncleaned = 0, ndirtied = 0;\n\tint ret = 0;\n\n\tif (unlikely(nsup == 0))\n\t\treturn ret;\n\n\tfor (sup = buf; sup < supend; sup = (void *)sup + supsz) {\n\t\tif (sup->sup_segnum >= nilfs->ns_nsegments\n\t\t\t|| (sup->sup_flags &\n\t\t\t\t(~0UL << __NR_NILFS_SUINFO_UPDATE_FIELDS))\n\t\t\t|| (nilfs_suinfo_update_nblocks(sup) &&\n\t\t\t\tsup->sup_sui.sui_nblocks >\n\t\t\t\tnilfs->ns_blocks_per_segment))\n\t\t\treturn -EINVAL;\n\t}\n\n\tdown_write(&NILFS_MDT(sufile)->mi_sem);\n\n\tret = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (ret < 0)\n\t\tgoto out_sem;\n\n\tsup = buf;\n\tblkoff = nilfs_sufile_get_blkoff(sufile, sup->sup_segnum);\n\tret = nilfs_mdt_get_block(sufile, blkoff, 1, NULL, &bh);\n\tif (ret < 0)\n\t\tgoto out_header;\n\n\tfor (;;) {\n\t\tkaddr = kmap_atomic(bh->b_page);\n\t\tsu = nilfs_sufile_block_get_segment_usage(\n\t\t\tsufile, sup->sup_segnum, bh, kaddr);\n\n\t\tif (nilfs_suinfo_update_lastmod(sup))\n\t\t\tsu->su_lastmod = cpu_to_le64(sup->sup_sui.sui_lastmod);\n\n\t\tif (nilfs_suinfo_update_nblocks(sup))\n\t\t\tsu->su_nblocks = cpu_to_le32(sup->sup_sui.sui_nblocks);\n\n\t\tif (nilfs_suinfo_update_flags(sup)) {\n\t\t\t \n\t\t\tsup->sup_sui.sui_flags &=\n\t\t\t\t\t~BIT(NILFS_SEGMENT_USAGE_ACTIVE);\n\n\t\t\tcleansi = nilfs_suinfo_clean(&sup->sup_sui);\n\t\t\tcleansu = nilfs_segment_usage_clean(su);\n\t\t\tdirtysi = nilfs_suinfo_dirty(&sup->sup_sui);\n\t\t\tdirtysu = nilfs_segment_usage_dirty(su);\n\n\t\t\tif (cleansi && !cleansu)\n\t\t\t\t++ncleaned;\n\t\t\telse if (!cleansi && cleansu)\n\t\t\t\t--ncleaned;\n\n\t\t\tif (dirtysi && !dirtysu)\n\t\t\t\t++ndirtied;\n\t\t\telse if (!dirtysi && dirtysu)\n\t\t\t\t--ndirtied;\n\n\t\t\tsu->su_flags = cpu_to_le32(sup->sup_sui.sui_flags);\n\t\t}\n\n\t\tkunmap_atomic(kaddr);\n\n\t\tsup = (void *)sup + supsz;\n\t\tif (sup >= supend)\n\t\t\tbreak;\n\n\t\tprev_blkoff = blkoff;\n\t\tblkoff = nilfs_sufile_get_blkoff(sufile, sup->sup_segnum);\n\t\tif (blkoff == prev_blkoff)\n\t\t\tcontinue;\n\n\t\t \n\t\tmark_buffer_dirty(bh);\n\t\tput_bh(bh);\n\t\tret = nilfs_mdt_get_block(sufile, blkoff, 1, NULL, &bh);\n\t\tif (unlikely(ret < 0))\n\t\t\tgoto out_mark;\n\t}\n\tmark_buffer_dirty(bh);\n\tput_bh(bh);\n\n out_mark:\n\tif (ncleaned || ndirtied) {\n\t\tnilfs_sufile_mod_counter(header_bh, (u64)ncleaned,\n\t\t\t\t(u64)ndirtied);\n\t\tNILFS_SUI(sufile)->ncleansegs += ncleaned;\n\t}\n\tnilfs_mdt_mark_dirty(sufile);\n out_header:\n\tput_bh(header_bh);\n out_sem:\n\tup_write(&NILFS_MDT(sufile)->mi_sem);\n\treturn ret;\n}\n\n \nint nilfs_sufile_trim_fs(struct inode *sufile, struct fstrim_range *range)\n{\n\tstruct the_nilfs *nilfs = sufile->i_sb->s_fs_info;\n\tstruct buffer_head *su_bh;\n\tstruct nilfs_segment_usage *su;\n\tvoid *kaddr;\n\tsize_t n, i, susz = NILFS_MDT(sufile)->mi_entry_size;\n\tsector_t seg_start, seg_end, start_block, end_block;\n\tsector_t start = 0, nblocks = 0;\n\tu64 segnum, segnum_end, minlen, len, max_blocks, ndiscarded = 0;\n\tint ret = 0;\n\tunsigned int sects_per_block;\n\n\tsects_per_block = (1 << nilfs->ns_blocksize_bits) /\n\t\t\tbdev_logical_block_size(nilfs->ns_bdev);\n\tlen = range->len >> nilfs->ns_blocksize_bits;\n\tminlen = range->minlen >> nilfs->ns_blocksize_bits;\n\tmax_blocks = ((u64)nilfs->ns_nsegments * nilfs->ns_blocks_per_segment);\n\n\tif (!len || range->start >= max_blocks << nilfs->ns_blocksize_bits)\n\t\treturn -EINVAL;\n\n\tstart_block = (range->start + nilfs->ns_blocksize - 1) >>\n\t\t\tnilfs->ns_blocksize_bits;\n\n\t \n\tif (max_blocks - start_block < len)\n\t\tend_block = max_blocks - 1;\n\telse\n\t\tend_block = start_block + len - 1;\n\n\tsegnum = nilfs_get_segnum_of_block(nilfs, start_block);\n\tsegnum_end = nilfs_get_segnum_of_block(nilfs, end_block);\n\n\tdown_read(&NILFS_MDT(sufile)->mi_sem);\n\n\twhile (segnum <= segnum_end) {\n\t\tn = nilfs_sufile_segment_usages_in_block(sufile, segnum,\n\t\t\t\tsegnum_end);\n\n\t\tret = nilfs_sufile_get_segment_usage_block(sufile, segnum, 0,\n\t\t\t\t\t\t\t   &su_bh);\n\t\tif (ret < 0) {\n\t\t\tif (ret != -ENOENT)\n\t\t\t\tgoto out_sem;\n\t\t\t \n\t\t\tsegnum += n;\n\t\t\tcontinue;\n\t\t}\n\n\t\tkaddr = kmap_atomic(su_bh->b_page);\n\t\tsu = nilfs_sufile_block_get_segment_usage(sufile, segnum,\n\t\t\t\tsu_bh, kaddr);\n\t\tfor (i = 0; i < n; ++i, ++segnum, su = (void *)su + susz) {\n\t\t\tif (!nilfs_segment_usage_clean(su))\n\t\t\t\tcontinue;\n\n\t\t\tnilfs_get_segment_range(nilfs, segnum, &seg_start,\n\t\t\t\t\t\t&seg_end);\n\n\t\t\tif (!nblocks) {\n\t\t\t\t \n\t\t\t\tstart = seg_start;\n\t\t\t\tnblocks = seg_end - seg_start + 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (start + nblocks == seg_start) {\n\t\t\t\t \n\t\t\t\tnblocks += seg_end - seg_start + 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (start < start_block) {\n\t\t\t\tnblocks -= start_block - start;\n\t\t\t\tstart = start_block;\n\t\t\t}\n\n\t\t\tif (nblocks >= minlen) {\n\t\t\t\tkunmap_atomic(kaddr);\n\n\t\t\t\tret = blkdev_issue_discard(nilfs->ns_bdev,\n\t\t\t\t\t\tstart * sects_per_block,\n\t\t\t\t\t\tnblocks * sects_per_block,\n\t\t\t\t\t\tGFP_NOFS);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tput_bh(su_bh);\n\t\t\t\t\tgoto out_sem;\n\t\t\t\t}\n\n\t\t\t\tndiscarded += nblocks;\n\t\t\t\tkaddr = kmap_atomic(su_bh->b_page);\n\t\t\t\tsu = nilfs_sufile_block_get_segment_usage(\n\t\t\t\t\tsufile, segnum, su_bh, kaddr);\n\t\t\t}\n\n\t\t\t \n\t\t\tstart = seg_start;\n\t\t\tnblocks = seg_end - seg_start + 1;\n\t\t}\n\t\tkunmap_atomic(kaddr);\n\t\tput_bh(su_bh);\n\t}\n\n\n\tif (nblocks) {\n\t\t \n\t\tif (start < start_block) {\n\t\t\tnblocks -= start_block - start;\n\t\t\tstart = start_block;\n\t\t}\n\t\tif (start + nblocks > end_block + 1)\n\t\t\tnblocks = end_block - start + 1;\n\n\t\tif (nblocks >= minlen) {\n\t\t\tret = blkdev_issue_discard(nilfs->ns_bdev,\n\t\t\t\t\tstart * sects_per_block,\n\t\t\t\t\tnblocks * sects_per_block,\n\t\t\t\t\tGFP_NOFS);\n\t\t\tif (!ret)\n\t\t\t\tndiscarded += nblocks;\n\t\t}\n\t}\n\nout_sem:\n\tup_read(&NILFS_MDT(sufile)->mi_sem);\n\n\trange->len = ndiscarded << nilfs->ns_blocksize_bits;\n\treturn ret;\n}\n\n \nint nilfs_sufile_read(struct super_block *sb, size_t susize,\n\t\t      struct nilfs_inode *raw_inode, struct inode **inodep)\n{\n\tstruct inode *sufile;\n\tstruct nilfs_sufile_info *sui;\n\tstruct buffer_head *header_bh;\n\tstruct nilfs_sufile_header *header;\n\tvoid *kaddr;\n\tint err;\n\n\tif (susize > sb->s_blocksize) {\n\t\tnilfs_err(sb, \"too large segment usage size: %zu bytes\",\n\t\t\t  susize);\n\t\treturn -EINVAL;\n\t} else if (susize < NILFS_MIN_SEGMENT_USAGE_SIZE) {\n\t\tnilfs_err(sb, \"too small segment usage size: %zu bytes\",\n\t\t\t  susize);\n\t\treturn -EINVAL;\n\t}\n\n\tsufile = nilfs_iget_locked(sb, NULL, NILFS_SUFILE_INO);\n\tif (unlikely(!sufile))\n\t\treturn -ENOMEM;\n\tif (!(sufile->i_state & I_NEW))\n\t\tgoto out;\n\n\terr = nilfs_mdt_init(sufile, NILFS_MDT_GFP, sizeof(*sui));\n\tif (err)\n\t\tgoto failed;\n\n\tnilfs_mdt_set_entry_size(sufile, susize,\n\t\t\t\t sizeof(struct nilfs_sufile_header));\n\n\terr = nilfs_read_inode_common(sufile, raw_inode);\n\tif (err)\n\t\tgoto failed;\n\n\terr = nilfs_sufile_get_header_block(sufile, &header_bh);\n\tif (err)\n\t\tgoto failed;\n\n\tsui = NILFS_SUI(sufile);\n\tkaddr = kmap_atomic(header_bh->b_page);\n\theader = kaddr + bh_offset(header_bh);\n\tsui->ncleansegs = le64_to_cpu(header->sh_ncleansegs);\n\tkunmap_atomic(kaddr);\n\tbrelse(header_bh);\n\n\tsui->allocmax = nilfs_sufile_get_nsegments(sufile) - 1;\n\tsui->allocmin = 0;\n\n\tunlock_new_inode(sufile);\n out:\n\t*inodep = sufile;\n\treturn 0;\n failed:\n\tiget_failed(sufile);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}