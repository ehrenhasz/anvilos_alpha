{
  "module_name": "segment.c",
  "hash_id": "fd3031419d32e599fffc936155784787fbd1b85462e528cf31f0e7251daf5078",
  "original_prompt": "Ingested from linux-6.6.14/fs/nilfs2/segment.c",
  "human_readable_source": "\n \n\n#include <linux/pagemap.h>\n#include <linux/buffer_head.h>\n#include <linux/writeback.h>\n#include <linux/bitops.h>\n#include <linux/bio.h>\n#include <linux/completion.h>\n#include <linux/blkdev.h>\n#include <linux/backing-dev.h>\n#include <linux/freezer.h>\n#include <linux/kthread.h>\n#include <linux/crc32.h>\n#include <linux/pagevec.h>\n#include <linux/slab.h>\n#include <linux/sched/signal.h>\n\n#include \"nilfs.h\"\n#include \"btnode.h\"\n#include \"page.h\"\n#include \"segment.h\"\n#include \"sufile.h\"\n#include \"cpfile.h\"\n#include \"ifile.h\"\n#include \"segbuf.h\"\n\n\n \n#define SC_N_INODEVEC\t16    \n\n#define SC_MAX_SEGDELTA 64    \n\n \nenum {\n\tSC_LSEG_SR = 1,\t \n\tSC_LSEG_DSYNC,\t \n\tSC_FLUSH_FILE,\t \n\tSC_FLUSH_DAT,\t \n};\n\n \nenum {\n\tNILFS_ST_INIT = 0,\n\tNILFS_ST_GC,\t\t \n\tNILFS_ST_FILE,\n\tNILFS_ST_IFILE,\n\tNILFS_ST_CPFILE,\n\tNILFS_ST_SUFILE,\n\tNILFS_ST_DAT,\n\tNILFS_ST_SR,\t\t \n\tNILFS_ST_DSYNC,\t\t \n\tNILFS_ST_DONE,\n};\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/nilfs2.h>\n\n \nstatic inline void nilfs_sc_cstage_inc(struct nilfs_sc_info *sci)\n{\n\tsci->sc_stage.scnt++;\n\ttrace_nilfs2_collection_stage_transition(sci);\n}\n\nstatic inline void nilfs_sc_cstage_set(struct nilfs_sc_info *sci, int next_scnt)\n{\n\tsci->sc_stage.scnt = next_scnt;\n\ttrace_nilfs2_collection_stage_transition(sci);\n}\n\nstatic inline int nilfs_sc_cstage_get(struct nilfs_sc_info *sci)\n{\n\treturn sci->sc_stage.scnt;\n}\n\n \n#define NILFS_CF_NODE\t\t0x0001\t \n#define NILFS_CF_IFILE_STARTED\t0x0002\t \n#define NILFS_CF_SUFREED\t0x0004\t \n#define NILFS_CF_HISTORY_MASK\t(NILFS_CF_IFILE_STARTED | NILFS_CF_SUFREED)\n\n \nstruct nilfs_sc_operations {\n\tint (*collect_data)(struct nilfs_sc_info *, struct buffer_head *,\n\t\t\t    struct inode *);\n\tint (*collect_node)(struct nilfs_sc_info *, struct buffer_head *,\n\t\t\t    struct inode *);\n\tint (*collect_bmap)(struct nilfs_sc_info *, struct buffer_head *,\n\t\t\t    struct inode *);\n\tvoid (*write_data_binfo)(struct nilfs_sc_info *,\n\t\t\t\t struct nilfs_segsum_pointer *,\n\t\t\t\t union nilfs_binfo *);\n\tvoid (*write_node_binfo)(struct nilfs_sc_info *,\n\t\t\t\t struct nilfs_segsum_pointer *,\n\t\t\t\t union nilfs_binfo *);\n};\n\n \nstatic void nilfs_segctor_start_timer(struct nilfs_sc_info *);\nstatic void nilfs_segctor_do_flush(struct nilfs_sc_info *, int);\nstatic void nilfs_segctor_do_immediate_flush(struct nilfs_sc_info *);\nstatic void nilfs_dispose_list(struct the_nilfs *, struct list_head *, int);\n\n#define nilfs_cnt32_ge(a, b)   \\\n\t(typecheck(__u32, a) && typecheck(__u32, b) && \\\n\t ((__s32)(a) - (__s32)(b) >= 0))\n\nstatic int nilfs_prepare_segment_lock(struct super_block *sb,\n\t\t\t\t      struct nilfs_transaction_info *ti)\n{\n\tstruct nilfs_transaction_info *cur_ti = current->journal_info;\n\tvoid *save = NULL;\n\n\tif (cur_ti) {\n\t\tif (cur_ti->ti_magic == NILFS_TI_MAGIC)\n\t\t\treturn ++cur_ti->ti_count;\n\n\t\t \n\t\tnilfs_warn(sb, \"journal info from a different FS\");\n\t\tsave = current->journal_info;\n\t}\n\tif (!ti) {\n\t\tti = kmem_cache_alloc(nilfs_transaction_cachep, GFP_NOFS);\n\t\tif (!ti)\n\t\t\treturn -ENOMEM;\n\t\tti->ti_flags = NILFS_TI_DYNAMIC_ALLOC;\n\t} else {\n\t\tti->ti_flags = 0;\n\t}\n\tti->ti_count = 0;\n\tti->ti_save = save;\n\tti->ti_magic = NILFS_TI_MAGIC;\n\tcurrent->journal_info = ti;\n\treturn 0;\n}\n\n \nint nilfs_transaction_begin(struct super_block *sb,\n\t\t\t    struct nilfs_transaction_info *ti,\n\t\t\t    int vacancy_check)\n{\n\tstruct the_nilfs *nilfs;\n\tint ret = nilfs_prepare_segment_lock(sb, ti);\n\tstruct nilfs_transaction_info *trace_ti;\n\n\tif (unlikely(ret < 0))\n\t\treturn ret;\n\tif (ret > 0) {\n\t\ttrace_ti = current->journal_info;\n\n\t\ttrace_nilfs2_transaction_transition(sb, trace_ti,\n\t\t\t\t    trace_ti->ti_count, trace_ti->ti_flags,\n\t\t\t\t    TRACE_NILFS2_TRANSACTION_BEGIN);\n\t\treturn 0;\n\t}\n\n\tsb_start_intwrite(sb);\n\n\tnilfs = sb->s_fs_info;\n\tdown_read(&nilfs->ns_segctor_sem);\n\tif (vacancy_check && nilfs_near_disk_full(nilfs)) {\n\t\tup_read(&nilfs->ns_segctor_sem);\n\t\tret = -ENOSPC;\n\t\tgoto failed;\n\t}\n\n\ttrace_ti = current->journal_info;\n\ttrace_nilfs2_transaction_transition(sb, trace_ti, trace_ti->ti_count,\n\t\t\t\t\t    trace_ti->ti_flags,\n\t\t\t\t\t    TRACE_NILFS2_TRANSACTION_BEGIN);\n\treturn 0;\n\n failed:\n\tti = current->journal_info;\n\tcurrent->journal_info = ti->ti_save;\n\tif (ti->ti_flags & NILFS_TI_DYNAMIC_ALLOC)\n\t\tkmem_cache_free(nilfs_transaction_cachep, ti);\n\tsb_end_intwrite(sb);\n\treturn ret;\n}\n\n \nint nilfs_transaction_commit(struct super_block *sb)\n{\n\tstruct nilfs_transaction_info *ti = current->journal_info;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tint err = 0;\n\n\tBUG_ON(ti == NULL || ti->ti_magic != NILFS_TI_MAGIC);\n\tti->ti_flags |= NILFS_TI_COMMIT;\n\tif (ti->ti_count > 0) {\n\t\tti->ti_count--;\n\t\ttrace_nilfs2_transaction_transition(sb, ti, ti->ti_count,\n\t\t\t    ti->ti_flags, TRACE_NILFS2_TRANSACTION_COMMIT);\n\t\treturn 0;\n\t}\n\tif (nilfs->ns_writer) {\n\t\tstruct nilfs_sc_info *sci = nilfs->ns_writer;\n\n\t\tif (ti->ti_flags & NILFS_TI_COMMIT)\n\t\t\tnilfs_segctor_start_timer(sci);\n\t\tif (atomic_read(&nilfs->ns_ndirtyblks) > sci->sc_watermark)\n\t\t\tnilfs_segctor_do_flush(sci, 0);\n\t}\n\tup_read(&nilfs->ns_segctor_sem);\n\ttrace_nilfs2_transaction_transition(sb, ti, ti->ti_count,\n\t\t\t    ti->ti_flags, TRACE_NILFS2_TRANSACTION_COMMIT);\n\n\tcurrent->journal_info = ti->ti_save;\n\n\tif (ti->ti_flags & NILFS_TI_SYNC)\n\t\terr = nilfs_construct_segment(sb);\n\tif (ti->ti_flags & NILFS_TI_DYNAMIC_ALLOC)\n\t\tkmem_cache_free(nilfs_transaction_cachep, ti);\n\tsb_end_intwrite(sb);\n\treturn err;\n}\n\nvoid nilfs_transaction_abort(struct super_block *sb)\n{\n\tstruct nilfs_transaction_info *ti = current->journal_info;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\n\tBUG_ON(ti == NULL || ti->ti_magic != NILFS_TI_MAGIC);\n\tif (ti->ti_count > 0) {\n\t\tti->ti_count--;\n\t\ttrace_nilfs2_transaction_transition(sb, ti, ti->ti_count,\n\t\t\t    ti->ti_flags, TRACE_NILFS2_TRANSACTION_ABORT);\n\t\treturn;\n\t}\n\tup_read(&nilfs->ns_segctor_sem);\n\n\ttrace_nilfs2_transaction_transition(sb, ti, ti->ti_count,\n\t\t    ti->ti_flags, TRACE_NILFS2_TRANSACTION_ABORT);\n\n\tcurrent->journal_info = ti->ti_save;\n\tif (ti->ti_flags & NILFS_TI_DYNAMIC_ALLOC)\n\t\tkmem_cache_free(nilfs_transaction_cachep, ti);\n\tsb_end_intwrite(sb);\n}\n\nvoid nilfs_relax_pressure_in_lock(struct super_block *sb)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct nilfs_sc_info *sci = nilfs->ns_writer;\n\n\tif (sb_rdonly(sb) || unlikely(!sci) || !sci->sc_flush_request)\n\t\treturn;\n\n\tset_bit(NILFS_SC_PRIOR_FLUSH, &sci->sc_flags);\n\tup_read(&nilfs->ns_segctor_sem);\n\n\tdown_write(&nilfs->ns_segctor_sem);\n\tif (sci->sc_flush_request &&\n\t    test_bit(NILFS_SC_PRIOR_FLUSH, &sci->sc_flags)) {\n\t\tstruct nilfs_transaction_info *ti = current->journal_info;\n\n\t\tti->ti_flags |= NILFS_TI_WRITER;\n\t\tnilfs_segctor_do_immediate_flush(sci);\n\t\tti->ti_flags &= ~NILFS_TI_WRITER;\n\t}\n\tdowngrade_write(&nilfs->ns_segctor_sem);\n}\n\nstatic void nilfs_transaction_lock(struct super_block *sb,\n\t\t\t\t   struct nilfs_transaction_info *ti,\n\t\t\t\t   int gcflag)\n{\n\tstruct nilfs_transaction_info *cur_ti = current->journal_info;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct nilfs_sc_info *sci = nilfs->ns_writer;\n\n\tWARN_ON(cur_ti);\n\tti->ti_flags = NILFS_TI_WRITER;\n\tti->ti_count = 0;\n\tti->ti_save = cur_ti;\n\tti->ti_magic = NILFS_TI_MAGIC;\n\tcurrent->journal_info = ti;\n\n\tfor (;;) {\n\t\ttrace_nilfs2_transaction_transition(sb, ti, ti->ti_count,\n\t\t\t    ti->ti_flags, TRACE_NILFS2_TRANSACTION_TRYLOCK);\n\n\t\tdown_write(&nilfs->ns_segctor_sem);\n\t\tif (!test_bit(NILFS_SC_PRIOR_FLUSH, &sci->sc_flags))\n\t\t\tbreak;\n\n\t\tnilfs_segctor_do_immediate_flush(sci);\n\n\t\tup_write(&nilfs->ns_segctor_sem);\n\t\tcond_resched();\n\t}\n\tif (gcflag)\n\t\tti->ti_flags |= NILFS_TI_GC;\n\n\ttrace_nilfs2_transaction_transition(sb, ti, ti->ti_count,\n\t\t\t    ti->ti_flags, TRACE_NILFS2_TRANSACTION_LOCK);\n}\n\nstatic void nilfs_transaction_unlock(struct super_block *sb)\n{\n\tstruct nilfs_transaction_info *ti = current->journal_info;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\n\tBUG_ON(ti == NULL || ti->ti_magic != NILFS_TI_MAGIC);\n\tBUG_ON(ti->ti_count > 0);\n\n\tup_write(&nilfs->ns_segctor_sem);\n\tcurrent->journal_info = ti->ti_save;\n\n\ttrace_nilfs2_transaction_transition(sb, ti, ti->ti_count,\n\t\t\t    ti->ti_flags, TRACE_NILFS2_TRANSACTION_UNLOCK);\n}\n\nstatic void *nilfs_segctor_map_segsum_entry(struct nilfs_sc_info *sci,\n\t\t\t\t\t    struct nilfs_segsum_pointer *ssp,\n\t\t\t\t\t    unsigned int bytes)\n{\n\tstruct nilfs_segment_buffer *segbuf = sci->sc_curseg;\n\tunsigned int blocksize = sci->sc_super->s_blocksize;\n\tvoid *p;\n\n\tif (unlikely(ssp->offset + bytes > blocksize)) {\n\t\tssp->offset = 0;\n\t\tBUG_ON(NILFS_SEGBUF_BH_IS_LAST(ssp->bh,\n\t\t\t\t\t       &segbuf->sb_segsum_buffers));\n\t\tssp->bh = NILFS_SEGBUF_NEXT_BH(ssp->bh);\n\t}\n\tp = ssp->bh->b_data + ssp->offset;\n\tssp->offset += bytes;\n\treturn p;\n}\n\n \nstatic int nilfs_segctor_reset_segment_buffer(struct nilfs_sc_info *sci)\n{\n\tstruct nilfs_segment_buffer *segbuf = sci->sc_curseg;\n\tstruct buffer_head *sumbh;\n\tunsigned int sumbytes;\n\tunsigned int flags = 0;\n\tint err;\n\n\tif (nilfs_doing_gc())\n\t\tflags = NILFS_SS_GC;\n\terr = nilfs_segbuf_reset(segbuf, flags, sci->sc_seg_ctime, sci->sc_cno);\n\tif (unlikely(err))\n\t\treturn err;\n\n\tsumbh = NILFS_SEGBUF_FIRST_BH(&segbuf->sb_segsum_buffers);\n\tsumbytes = segbuf->sb_sum.sumbytes;\n\tsci->sc_finfo_ptr.bh = sumbh;  sci->sc_finfo_ptr.offset = sumbytes;\n\tsci->sc_binfo_ptr.bh = sumbh;  sci->sc_binfo_ptr.offset = sumbytes;\n\tsci->sc_blk_cnt = sci->sc_datablk_cnt = 0;\n\treturn 0;\n}\n\n \nstatic void nilfs_segctor_zeropad_segsum(struct nilfs_sc_info *sci)\n{\n\tstruct nilfs_segsum_pointer *ssp;\n\n\tssp = sci->sc_blk_cnt > 0 ? &sci->sc_binfo_ptr : &sci->sc_finfo_ptr;\n\tif (ssp->offset < ssp->bh->b_size)\n\t\tmemset(ssp->bh->b_data + ssp->offset, 0,\n\t\t       ssp->bh->b_size - ssp->offset);\n}\n\nstatic int nilfs_segctor_feed_segment(struct nilfs_sc_info *sci)\n{\n\tsci->sc_nblk_this_inc += sci->sc_curseg->sb_sum.nblocks;\n\tif (NILFS_SEGBUF_IS_LAST(sci->sc_curseg, &sci->sc_segbufs))\n\t\treturn -E2BIG;  \n\tnilfs_segctor_zeropad_segsum(sci);\n\tsci->sc_curseg = NILFS_NEXT_SEGBUF(sci->sc_curseg);\n\treturn nilfs_segctor_reset_segment_buffer(sci);\n}\n\nstatic int nilfs_segctor_add_super_root(struct nilfs_sc_info *sci)\n{\n\tstruct nilfs_segment_buffer *segbuf = sci->sc_curseg;\n\tint err;\n\n\tif (segbuf->sb_sum.nblocks >= segbuf->sb_rest_blocks) {\n\t\terr = nilfs_segctor_feed_segment(sci);\n\t\tif (err)\n\t\t\treturn err;\n\t\tsegbuf = sci->sc_curseg;\n\t}\n\terr = nilfs_segbuf_extend_payload(segbuf, &segbuf->sb_super_root);\n\tif (likely(!err))\n\t\tsegbuf->sb_sum.flags |= NILFS_SS_SR;\n\treturn err;\n}\n\n \nstatic int nilfs_segctor_segsum_block_required(\n\tstruct nilfs_sc_info *sci, const struct nilfs_segsum_pointer *ssp,\n\tunsigned int binfo_size)\n{\n\tunsigned int blocksize = sci->sc_super->s_blocksize;\n\t \n\n\treturn ssp->offset + binfo_size +\n\t\t(!sci->sc_blk_cnt ? sizeof(struct nilfs_finfo) : 0) >\n\t\tblocksize;\n}\n\nstatic void nilfs_segctor_begin_finfo(struct nilfs_sc_info *sci,\n\t\t\t\t      struct inode *inode)\n{\n\tsci->sc_curseg->sb_sum.nfinfo++;\n\tsci->sc_binfo_ptr = sci->sc_finfo_ptr;\n\tnilfs_segctor_map_segsum_entry(\n\t\tsci, &sci->sc_binfo_ptr, sizeof(struct nilfs_finfo));\n\n\tif (NILFS_I(inode)->i_root &&\n\t    !test_bit(NILFS_SC_HAVE_DELTA, &sci->sc_flags))\n\t\tset_bit(NILFS_SC_HAVE_DELTA, &sci->sc_flags);\n\t \n}\n\nstatic void nilfs_segctor_end_finfo(struct nilfs_sc_info *sci,\n\t\t\t\t    struct inode *inode)\n{\n\tstruct nilfs_finfo *finfo;\n\tstruct nilfs_inode_info *ii;\n\tstruct nilfs_segment_buffer *segbuf;\n\t__u64 cno;\n\n\tif (sci->sc_blk_cnt == 0)\n\t\treturn;\n\n\tii = NILFS_I(inode);\n\n\tif (test_bit(NILFS_I_GCINODE, &ii->i_state))\n\t\tcno = ii->i_cno;\n\telse if (NILFS_ROOT_METADATA_FILE(inode->i_ino))\n\t\tcno = 0;\n\telse\n\t\tcno = sci->sc_cno;\n\n\tfinfo = nilfs_segctor_map_segsum_entry(sci, &sci->sc_finfo_ptr,\n\t\t\t\t\t\t sizeof(*finfo));\n\tfinfo->fi_ino = cpu_to_le64(inode->i_ino);\n\tfinfo->fi_nblocks = cpu_to_le32(sci->sc_blk_cnt);\n\tfinfo->fi_ndatablk = cpu_to_le32(sci->sc_datablk_cnt);\n\tfinfo->fi_cno = cpu_to_le64(cno);\n\n\tsegbuf = sci->sc_curseg;\n\tsegbuf->sb_sum.sumbytes = sci->sc_binfo_ptr.offset +\n\t\tsci->sc_super->s_blocksize * (segbuf->sb_sum.nsumblk - 1);\n\tsci->sc_finfo_ptr = sci->sc_binfo_ptr;\n\tsci->sc_blk_cnt = sci->sc_datablk_cnt = 0;\n}\n\nstatic int nilfs_segctor_add_file_block(struct nilfs_sc_info *sci,\n\t\t\t\t\tstruct buffer_head *bh,\n\t\t\t\t\tstruct inode *inode,\n\t\t\t\t\tunsigned int binfo_size)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tint required, err = 0;\n\n retry:\n\tsegbuf = sci->sc_curseg;\n\trequired = nilfs_segctor_segsum_block_required(\n\t\tsci, &sci->sc_binfo_ptr, binfo_size);\n\tif (segbuf->sb_sum.nblocks + required + 1 > segbuf->sb_rest_blocks) {\n\t\tnilfs_segctor_end_finfo(sci, inode);\n\t\terr = nilfs_segctor_feed_segment(sci);\n\t\tif (err)\n\t\t\treturn err;\n\t\tgoto retry;\n\t}\n\tif (unlikely(required)) {\n\t\tnilfs_segctor_zeropad_segsum(sci);\n\t\terr = nilfs_segbuf_extend_segsum(segbuf);\n\t\tif (unlikely(err))\n\t\t\tgoto failed;\n\t}\n\tif (sci->sc_blk_cnt == 0)\n\t\tnilfs_segctor_begin_finfo(sci, inode);\n\n\tnilfs_segctor_map_segsum_entry(sci, &sci->sc_binfo_ptr, binfo_size);\n\t \n\tnilfs_segbuf_add_file_buffer(segbuf, bh);\n\tsci->sc_blk_cnt++;\n failed:\n\treturn err;\n}\n\n \nstatic int nilfs_collect_file_data(struct nilfs_sc_info *sci,\n\t\t\t\t   struct buffer_head *bh, struct inode *inode)\n{\n\tint err;\n\n\terr = nilfs_bmap_propagate(NILFS_I(inode)->i_bmap, bh);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = nilfs_segctor_add_file_block(sci, bh, inode,\n\t\t\t\t\t   sizeof(struct nilfs_binfo_v));\n\tif (!err)\n\t\tsci->sc_datablk_cnt++;\n\treturn err;\n}\n\nstatic int nilfs_collect_file_node(struct nilfs_sc_info *sci,\n\t\t\t\t   struct buffer_head *bh,\n\t\t\t\t   struct inode *inode)\n{\n\treturn nilfs_bmap_propagate(NILFS_I(inode)->i_bmap, bh);\n}\n\nstatic int nilfs_collect_file_bmap(struct nilfs_sc_info *sci,\n\t\t\t\t   struct buffer_head *bh,\n\t\t\t\t   struct inode *inode)\n{\n\tWARN_ON(!buffer_dirty(bh));\n\treturn nilfs_segctor_add_file_block(sci, bh, inode, sizeof(__le64));\n}\n\nstatic void nilfs_write_file_data_binfo(struct nilfs_sc_info *sci,\n\t\t\t\t\tstruct nilfs_segsum_pointer *ssp,\n\t\t\t\t\tunion nilfs_binfo *binfo)\n{\n\tstruct nilfs_binfo_v *binfo_v = nilfs_segctor_map_segsum_entry(\n\t\tsci, ssp, sizeof(*binfo_v));\n\t*binfo_v = binfo->bi_v;\n}\n\nstatic void nilfs_write_file_node_binfo(struct nilfs_sc_info *sci,\n\t\t\t\t\tstruct nilfs_segsum_pointer *ssp,\n\t\t\t\t\tunion nilfs_binfo *binfo)\n{\n\t__le64 *vblocknr = nilfs_segctor_map_segsum_entry(\n\t\tsci, ssp, sizeof(*vblocknr));\n\t*vblocknr = binfo->bi_v.bi_vblocknr;\n}\n\nstatic const struct nilfs_sc_operations nilfs_sc_file_ops = {\n\t.collect_data = nilfs_collect_file_data,\n\t.collect_node = nilfs_collect_file_node,\n\t.collect_bmap = nilfs_collect_file_bmap,\n\t.write_data_binfo = nilfs_write_file_data_binfo,\n\t.write_node_binfo = nilfs_write_file_node_binfo,\n};\n\nstatic int nilfs_collect_dat_data(struct nilfs_sc_info *sci,\n\t\t\t\t  struct buffer_head *bh, struct inode *inode)\n{\n\tint err;\n\n\terr = nilfs_bmap_propagate(NILFS_I(inode)->i_bmap, bh);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = nilfs_segctor_add_file_block(sci, bh, inode, sizeof(__le64));\n\tif (!err)\n\t\tsci->sc_datablk_cnt++;\n\treturn err;\n}\n\nstatic int nilfs_collect_dat_bmap(struct nilfs_sc_info *sci,\n\t\t\t\t  struct buffer_head *bh, struct inode *inode)\n{\n\tWARN_ON(!buffer_dirty(bh));\n\treturn nilfs_segctor_add_file_block(sci, bh, inode,\n\t\t\t\t\t    sizeof(struct nilfs_binfo_dat));\n}\n\nstatic void nilfs_write_dat_data_binfo(struct nilfs_sc_info *sci,\n\t\t\t\t       struct nilfs_segsum_pointer *ssp,\n\t\t\t\t       union nilfs_binfo *binfo)\n{\n\t__le64 *blkoff = nilfs_segctor_map_segsum_entry(sci, ssp,\n\t\t\t\t\t\t\t  sizeof(*blkoff));\n\t*blkoff = binfo->bi_dat.bi_blkoff;\n}\n\nstatic void nilfs_write_dat_node_binfo(struct nilfs_sc_info *sci,\n\t\t\t\t       struct nilfs_segsum_pointer *ssp,\n\t\t\t\t       union nilfs_binfo *binfo)\n{\n\tstruct nilfs_binfo_dat *binfo_dat =\n\t\tnilfs_segctor_map_segsum_entry(sci, ssp, sizeof(*binfo_dat));\n\t*binfo_dat = binfo->bi_dat;\n}\n\nstatic const struct nilfs_sc_operations nilfs_sc_dat_ops = {\n\t.collect_data = nilfs_collect_dat_data,\n\t.collect_node = nilfs_collect_file_node,\n\t.collect_bmap = nilfs_collect_dat_bmap,\n\t.write_data_binfo = nilfs_write_dat_data_binfo,\n\t.write_node_binfo = nilfs_write_dat_node_binfo,\n};\n\nstatic const struct nilfs_sc_operations nilfs_sc_dsync_ops = {\n\t.collect_data = nilfs_collect_file_data,\n\t.collect_node = NULL,\n\t.collect_bmap = NULL,\n\t.write_data_binfo = nilfs_write_file_data_binfo,\n\t.write_node_binfo = NULL,\n};\n\nstatic size_t nilfs_lookup_dirty_data_buffers(struct inode *inode,\n\t\t\t\t\t      struct list_head *listp,\n\t\t\t\t\t      size_t nlimit,\n\t\t\t\t\t      loff_t start, loff_t end)\n{\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct folio_batch fbatch;\n\tpgoff_t index = 0, last = ULONG_MAX;\n\tsize_t ndirties = 0;\n\tint i;\n\n\tif (unlikely(start != 0 || end != LLONG_MAX)) {\n\t\t \n\t\tindex = start >> PAGE_SHIFT;\n\t\tlast = end >> PAGE_SHIFT;\n\t}\n\tfolio_batch_init(&fbatch);\n repeat:\n\tif (unlikely(index > last) ||\n\t      !filemap_get_folios_tag(mapping, &index, last,\n\t\t      PAGECACHE_TAG_DIRTY, &fbatch))\n\t\treturn ndirties;\n\n\tfor (i = 0; i < folio_batch_count(&fbatch); i++) {\n\t\tstruct buffer_head *bh, *head;\n\t\tstruct folio *folio = fbatch.folios[i];\n\n\t\tfolio_lock(folio);\n\t\tif (unlikely(folio->mapping != mapping)) {\n\t\t\t \n\t\t\tfolio_unlock(folio);\n\t\t\tcontinue;\n\t\t}\n\t\thead = folio_buffers(folio);\n\t\tif (!head) {\n\t\t\tcreate_empty_buffers(&folio->page, i_blocksize(inode), 0);\n\t\t\thead = folio_buffers(folio);\n\t\t}\n\t\tfolio_unlock(folio);\n\n\t\tbh = head;\n\t\tdo {\n\t\t\tif (!buffer_dirty(bh) || buffer_async_write(bh))\n\t\t\t\tcontinue;\n\t\t\tget_bh(bh);\n\t\t\tlist_add_tail(&bh->b_assoc_buffers, listp);\n\t\t\tndirties++;\n\t\t\tif (unlikely(ndirties >= nlimit)) {\n\t\t\t\tfolio_batch_release(&fbatch);\n\t\t\t\tcond_resched();\n\t\t\t\treturn ndirties;\n\t\t\t}\n\t\t} while (bh = bh->b_this_page, bh != head);\n\t}\n\tfolio_batch_release(&fbatch);\n\tcond_resched();\n\tgoto repeat;\n}\n\nstatic void nilfs_lookup_dirty_node_buffers(struct inode *inode,\n\t\t\t\t\t    struct list_head *listp)\n{\n\tstruct nilfs_inode_info *ii = NILFS_I(inode);\n\tstruct inode *btnc_inode = ii->i_assoc_inode;\n\tstruct folio_batch fbatch;\n\tstruct buffer_head *bh, *head;\n\tunsigned int i;\n\tpgoff_t index = 0;\n\n\tif (!btnc_inode)\n\t\treturn;\n\tfolio_batch_init(&fbatch);\n\n\twhile (filemap_get_folios_tag(btnc_inode->i_mapping, &index,\n\t\t\t\t(pgoff_t)-1, PAGECACHE_TAG_DIRTY, &fbatch)) {\n\t\tfor (i = 0; i < folio_batch_count(&fbatch); i++) {\n\t\t\tbh = head = folio_buffers(fbatch.folios[i]);\n\t\t\tdo {\n\t\t\t\tif (buffer_dirty(bh) &&\n\t\t\t\t\t\t!buffer_async_write(bh)) {\n\t\t\t\t\tget_bh(bh);\n\t\t\t\t\tlist_add_tail(&bh->b_assoc_buffers,\n\t\t\t\t\t\t      listp);\n\t\t\t\t}\n\t\t\t\tbh = bh->b_this_page;\n\t\t\t} while (bh != head);\n\t\t}\n\t\tfolio_batch_release(&fbatch);\n\t\tcond_resched();\n\t}\n}\n\nstatic void nilfs_dispose_list(struct the_nilfs *nilfs,\n\t\t\t       struct list_head *head, int force)\n{\n\tstruct nilfs_inode_info *ii, *n;\n\tstruct nilfs_inode_info *ivec[SC_N_INODEVEC], **pii;\n\tunsigned int nv = 0;\n\n\twhile (!list_empty(head)) {\n\t\tspin_lock(&nilfs->ns_inode_lock);\n\t\tlist_for_each_entry_safe(ii, n, head, i_dirty) {\n\t\t\tlist_del_init(&ii->i_dirty);\n\t\t\tif (force) {\n\t\t\t\tif (unlikely(ii->i_bh)) {\n\t\t\t\t\tbrelse(ii->i_bh);\n\t\t\t\t\tii->i_bh = NULL;\n\t\t\t\t}\n\t\t\t} else if (test_bit(NILFS_I_DIRTY, &ii->i_state)) {\n\t\t\t\tset_bit(NILFS_I_QUEUED, &ii->i_state);\n\t\t\t\tlist_add_tail(&ii->i_dirty,\n\t\t\t\t\t      &nilfs->ns_dirty_files);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tivec[nv++] = ii;\n\t\t\tif (nv == SC_N_INODEVEC)\n\t\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&nilfs->ns_inode_lock);\n\n\t\tfor (pii = ivec; nv > 0; pii++, nv--)\n\t\t\tiput(&(*pii)->vfs_inode);\n\t}\n}\n\nstatic void nilfs_iput_work_func(struct work_struct *work)\n{\n\tstruct nilfs_sc_info *sci = container_of(work, struct nilfs_sc_info,\n\t\t\t\t\t\t sc_iput_work);\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\n\tnilfs_dispose_list(nilfs, &sci->sc_iput_queue, 0);\n}\n\nstatic int nilfs_test_metadata_dirty(struct the_nilfs *nilfs,\n\t\t\t\t     struct nilfs_root *root)\n{\n\tint ret = 0;\n\n\tif (nilfs_mdt_fetch_dirty(root->ifile))\n\t\tret++;\n\tif (nilfs_mdt_fetch_dirty(nilfs->ns_cpfile))\n\t\tret++;\n\tif (nilfs_mdt_fetch_dirty(nilfs->ns_sufile))\n\t\tret++;\n\tif ((ret || nilfs_doing_gc()) && nilfs_mdt_fetch_dirty(nilfs->ns_dat))\n\t\tret++;\n\treturn ret;\n}\n\nstatic int nilfs_segctor_clean(struct nilfs_sc_info *sci)\n{\n\treturn list_empty(&sci->sc_dirty_files) &&\n\t\t!test_bit(NILFS_SC_DIRTY, &sci->sc_flags) &&\n\t\tsci->sc_nfreesegs == 0 &&\n\t\t(!nilfs_doing_gc() || list_empty(&sci->sc_gc_inodes));\n}\n\nstatic int nilfs_segctor_confirm(struct nilfs_sc_info *sci)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tint ret = 0;\n\n\tif (nilfs_test_metadata_dirty(nilfs, sci->sc_root))\n\t\tset_bit(NILFS_SC_DIRTY, &sci->sc_flags);\n\n\tspin_lock(&nilfs->ns_inode_lock);\n\tif (list_empty(&nilfs->ns_dirty_files) && nilfs_segctor_clean(sci))\n\t\tret++;\n\n\tspin_unlock(&nilfs->ns_inode_lock);\n\treturn ret;\n}\n\nstatic void nilfs_segctor_clear_metadata_dirty(struct nilfs_sc_info *sci)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\n\tnilfs_mdt_clear_dirty(sci->sc_root->ifile);\n\tnilfs_mdt_clear_dirty(nilfs->ns_cpfile);\n\tnilfs_mdt_clear_dirty(nilfs->ns_sufile);\n\tnilfs_mdt_clear_dirty(nilfs->ns_dat);\n}\n\nstatic int nilfs_segctor_create_checkpoint(struct nilfs_sc_info *sci)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tstruct buffer_head *bh_cp;\n\tstruct nilfs_checkpoint *raw_cp;\n\tint err;\n\n\t \n\terr = nilfs_cpfile_get_checkpoint(nilfs->ns_cpfile, nilfs->ns_cno, 1,\n\t\t\t\t\t  &raw_cp, &bh_cp);\n\tif (likely(!err)) {\n\t\t \n\t\tmark_buffer_dirty(bh_cp);\n\t\tnilfs_mdt_mark_dirty(nilfs->ns_cpfile);\n\t\tnilfs_cpfile_put_checkpoint(\n\t\t\tnilfs->ns_cpfile, nilfs->ns_cno, bh_cp);\n\t} else if (err == -EINVAL || err == -ENOENT) {\n\t\tnilfs_error(sci->sc_super,\n\t\t\t    \"checkpoint creation failed due to metadata corruption.\");\n\t\terr = -EIO;\n\t}\n\treturn err;\n}\n\nstatic int nilfs_segctor_fill_in_checkpoint(struct nilfs_sc_info *sci)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tstruct buffer_head *bh_cp;\n\tstruct nilfs_checkpoint *raw_cp;\n\tint err;\n\n\terr = nilfs_cpfile_get_checkpoint(nilfs->ns_cpfile, nilfs->ns_cno, 0,\n\t\t\t\t\t  &raw_cp, &bh_cp);\n\tif (unlikely(err)) {\n\t\tif (err == -EINVAL || err == -ENOENT) {\n\t\t\tnilfs_error(sci->sc_super,\n\t\t\t\t    \"checkpoint finalization failed due to metadata corruption.\");\n\t\t\terr = -EIO;\n\t\t}\n\t\tgoto failed_ibh;\n\t}\n\traw_cp->cp_snapshot_list.ssl_next = 0;\n\traw_cp->cp_snapshot_list.ssl_prev = 0;\n\traw_cp->cp_inodes_count =\n\t\tcpu_to_le64(atomic64_read(&sci->sc_root->inodes_count));\n\traw_cp->cp_blocks_count =\n\t\tcpu_to_le64(atomic64_read(&sci->sc_root->blocks_count));\n\traw_cp->cp_nblk_inc =\n\t\tcpu_to_le64(sci->sc_nblk_inc + sci->sc_nblk_this_inc);\n\traw_cp->cp_create = cpu_to_le64(sci->sc_seg_ctime);\n\traw_cp->cp_cno = cpu_to_le64(nilfs->ns_cno);\n\n\tif (test_bit(NILFS_SC_HAVE_DELTA, &sci->sc_flags))\n\t\tnilfs_checkpoint_clear_minor(raw_cp);\n\telse\n\t\tnilfs_checkpoint_set_minor(raw_cp);\n\n\tnilfs_write_inode_common(sci->sc_root->ifile,\n\t\t\t\t &raw_cp->cp_ifile_inode, 1);\n\tnilfs_cpfile_put_checkpoint(nilfs->ns_cpfile, nilfs->ns_cno, bh_cp);\n\treturn 0;\n\n failed_ibh:\n\treturn err;\n}\n\nstatic void nilfs_fill_in_file_bmap(struct inode *ifile,\n\t\t\t\t    struct nilfs_inode_info *ii)\n\n{\n\tstruct buffer_head *ibh;\n\tstruct nilfs_inode *raw_inode;\n\n\tif (test_bit(NILFS_I_BMAP, &ii->i_state)) {\n\t\tibh = ii->i_bh;\n\t\tBUG_ON(!ibh);\n\t\traw_inode = nilfs_ifile_map_inode(ifile, ii->vfs_inode.i_ino,\n\t\t\t\t\t\t  ibh);\n\t\tnilfs_bmap_write(ii->i_bmap, raw_inode);\n\t\tnilfs_ifile_unmap_inode(ifile, ii->vfs_inode.i_ino, ibh);\n\t}\n}\n\nstatic void nilfs_segctor_fill_in_file_bmap(struct nilfs_sc_info *sci)\n{\n\tstruct nilfs_inode_info *ii;\n\n\tlist_for_each_entry(ii, &sci->sc_dirty_files, i_dirty) {\n\t\tnilfs_fill_in_file_bmap(sci->sc_root->ifile, ii);\n\t\tset_bit(NILFS_I_COLLECTED, &ii->i_state);\n\t}\n}\n\nstatic void nilfs_segctor_fill_in_super_root(struct nilfs_sc_info *sci,\n\t\t\t\t\t     struct the_nilfs *nilfs)\n{\n\tstruct buffer_head *bh_sr;\n\tstruct nilfs_super_root *raw_sr;\n\tunsigned int isz, srsz;\n\n\tbh_sr = NILFS_LAST_SEGBUF(&sci->sc_segbufs)->sb_super_root;\n\n\tlock_buffer(bh_sr);\n\traw_sr = (struct nilfs_super_root *)bh_sr->b_data;\n\tisz = nilfs->ns_inode_size;\n\tsrsz = NILFS_SR_BYTES(isz);\n\n\traw_sr->sr_sum = 0;   \n\traw_sr->sr_bytes = cpu_to_le16(srsz);\n\traw_sr->sr_nongc_ctime\n\t\t= cpu_to_le64(nilfs_doing_gc() ?\n\t\t\t      nilfs->ns_nongc_ctime : sci->sc_seg_ctime);\n\traw_sr->sr_flags = 0;\n\n\tnilfs_write_inode_common(nilfs->ns_dat, (void *)raw_sr +\n\t\t\t\t NILFS_SR_DAT_OFFSET(isz), 1);\n\tnilfs_write_inode_common(nilfs->ns_cpfile, (void *)raw_sr +\n\t\t\t\t NILFS_SR_CPFILE_OFFSET(isz), 1);\n\tnilfs_write_inode_common(nilfs->ns_sufile, (void *)raw_sr +\n\t\t\t\t NILFS_SR_SUFILE_OFFSET(isz), 1);\n\tmemset((void *)raw_sr + srsz, 0, nilfs->ns_blocksize - srsz);\n\tset_buffer_uptodate(bh_sr);\n\tunlock_buffer(bh_sr);\n}\n\nstatic void nilfs_redirty_inodes(struct list_head *head)\n{\n\tstruct nilfs_inode_info *ii;\n\n\tlist_for_each_entry(ii, head, i_dirty) {\n\t\tif (test_bit(NILFS_I_COLLECTED, &ii->i_state))\n\t\t\tclear_bit(NILFS_I_COLLECTED, &ii->i_state);\n\t}\n}\n\nstatic void nilfs_drop_collected_inodes(struct list_head *head)\n{\n\tstruct nilfs_inode_info *ii;\n\n\tlist_for_each_entry(ii, head, i_dirty) {\n\t\tif (!test_and_clear_bit(NILFS_I_COLLECTED, &ii->i_state))\n\t\t\tcontinue;\n\n\t\tclear_bit(NILFS_I_INODE_SYNC, &ii->i_state);\n\t\tset_bit(NILFS_I_UPDATED, &ii->i_state);\n\t}\n}\n\nstatic int nilfs_segctor_apply_buffers(struct nilfs_sc_info *sci,\n\t\t\t\t       struct inode *inode,\n\t\t\t\t       struct list_head *listp,\n\t\t\t\t       int (*collect)(struct nilfs_sc_info *,\n\t\t\t\t\t\t      struct buffer_head *,\n\t\t\t\t\t\t      struct inode *))\n{\n\tstruct buffer_head *bh, *n;\n\tint err = 0;\n\n\tif (collect) {\n\t\tlist_for_each_entry_safe(bh, n, listp, b_assoc_buffers) {\n\t\t\tlist_del_init(&bh->b_assoc_buffers);\n\t\t\terr = collect(sci, bh, inode);\n\t\t\tbrelse(bh);\n\t\t\tif (unlikely(err))\n\t\t\t\tgoto dispose_buffers;\n\t\t}\n\t\treturn 0;\n\t}\n\n dispose_buffers:\n\twhile (!list_empty(listp)) {\n\t\tbh = list_first_entry(listp, struct buffer_head,\n\t\t\t\t      b_assoc_buffers);\n\t\tlist_del_init(&bh->b_assoc_buffers);\n\t\tbrelse(bh);\n\t}\n\treturn err;\n}\n\nstatic size_t nilfs_segctor_buffer_rest(struct nilfs_sc_info *sci)\n{\n\t \n\treturn sci->sc_segbuf_nblocks -\n\t\t(sci->sc_nblk_this_inc + sci->sc_curseg->sb_sum.nblocks);\n}\n\nstatic int nilfs_segctor_scan_file(struct nilfs_sc_info *sci,\n\t\t\t\t   struct inode *inode,\n\t\t\t\t   const struct nilfs_sc_operations *sc_ops)\n{\n\tLIST_HEAD(data_buffers);\n\tLIST_HEAD(node_buffers);\n\tint err;\n\n\tif (!(sci->sc_stage.flags & NILFS_CF_NODE)) {\n\t\tsize_t n, rest = nilfs_segctor_buffer_rest(sci);\n\n\t\tn = nilfs_lookup_dirty_data_buffers(\n\t\t\tinode, &data_buffers, rest + 1, 0, LLONG_MAX);\n\t\tif (n > rest) {\n\t\t\terr = nilfs_segctor_apply_buffers(\n\t\t\t\tsci, inode, &data_buffers,\n\t\t\t\tsc_ops->collect_data);\n\t\t\tBUG_ON(!err);  \n\t\t\tgoto break_or_fail;\n\t\t}\n\t}\n\tnilfs_lookup_dirty_node_buffers(inode, &node_buffers);\n\n\tif (!(sci->sc_stage.flags & NILFS_CF_NODE)) {\n\t\terr = nilfs_segctor_apply_buffers(\n\t\t\tsci, inode, &data_buffers, sc_ops->collect_data);\n\t\tif (unlikely(err)) {\n\t\t\t \n\t\t\tnilfs_segctor_apply_buffers(\n\t\t\t\tsci, inode, &node_buffers, NULL);\n\t\t\tgoto break_or_fail;\n\t\t}\n\t\tsci->sc_stage.flags |= NILFS_CF_NODE;\n\t}\n\t \n\terr = nilfs_segctor_apply_buffers(\n\t\tsci, inode, &node_buffers, sc_ops->collect_node);\n\tif (unlikely(err))\n\t\tgoto break_or_fail;\n\n\tnilfs_bmap_lookup_dirty_buffers(NILFS_I(inode)->i_bmap, &node_buffers);\n\terr = nilfs_segctor_apply_buffers(\n\t\tsci, inode, &node_buffers, sc_ops->collect_bmap);\n\tif (unlikely(err))\n\t\tgoto break_or_fail;\n\n\tnilfs_segctor_end_finfo(sci, inode);\n\tsci->sc_stage.flags &= ~NILFS_CF_NODE;\n\n break_or_fail:\n\treturn err;\n}\n\nstatic int nilfs_segctor_scan_file_dsync(struct nilfs_sc_info *sci,\n\t\t\t\t\t struct inode *inode)\n{\n\tLIST_HEAD(data_buffers);\n\tsize_t n, rest = nilfs_segctor_buffer_rest(sci);\n\tint err;\n\n\tn = nilfs_lookup_dirty_data_buffers(inode, &data_buffers, rest + 1,\n\t\t\t\t\t    sci->sc_dsync_start,\n\t\t\t\t\t    sci->sc_dsync_end);\n\n\terr = nilfs_segctor_apply_buffers(sci, inode, &data_buffers,\n\t\t\t\t\t  nilfs_collect_file_data);\n\tif (!err) {\n\t\tnilfs_segctor_end_finfo(sci, inode);\n\t\tBUG_ON(n > rest);\n\t\t \n\t}\n\treturn err;\n}\n\nstatic int nilfs_segctor_collect_blocks(struct nilfs_sc_info *sci, int mode)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tstruct list_head *head;\n\tstruct nilfs_inode_info *ii;\n\tsize_t ndone;\n\tint err = 0;\n\n\tswitch (nilfs_sc_cstage_get(sci)) {\n\tcase NILFS_ST_INIT:\n\t\t \n\t\tsci->sc_stage.flags = 0;\n\n\t\tif (!test_bit(NILFS_SC_UNCLOSED, &sci->sc_flags)) {\n\t\t\tsci->sc_nblk_inc = 0;\n\t\t\tsci->sc_curseg->sb_sum.flags = NILFS_SS_LOGBGN;\n\t\t\tif (mode == SC_LSEG_DSYNC) {\n\t\t\t\tnilfs_sc_cstage_set(sci, NILFS_ST_DSYNC);\n\t\t\t\tgoto dsync_mode;\n\t\t\t}\n\t\t}\n\n\t\tsci->sc_stage.dirty_file_ptr = NULL;\n\t\tsci->sc_stage.gc_inode_ptr = NULL;\n\t\tif (mode == SC_FLUSH_DAT) {\n\t\t\tnilfs_sc_cstage_set(sci, NILFS_ST_DAT);\n\t\t\tgoto dat_stage;\n\t\t}\n\t\tnilfs_sc_cstage_inc(sci);\n\t\tfallthrough;\n\tcase NILFS_ST_GC:\n\t\tif (nilfs_doing_gc()) {\n\t\t\thead = &sci->sc_gc_inodes;\n\t\t\tii = list_prepare_entry(sci->sc_stage.gc_inode_ptr,\n\t\t\t\t\t\thead, i_dirty);\n\t\t\tlist_for_each_entry_continue(ii, head, i_dirty) {\n\t\t\t\terr = nilfs_segctor_scan_file(\n\t\t\t\t\tsci, &ii->vfs_inode,\n\t\t\t\t\t&nilfs_sc_file_ops);\n\t\t\t\tif (unlikely(err)) {\n\t\t\t\t\tsci->sc_stage.gc_inode_ptr = list_entry(\n\t\t\t\t\t\tii->i_dirty.prev,\n\t\t\t\t\t\tstruct nilfs_inode_info,\n\t\t\t\t\t\ti_dirty);\n\t\t\t\t\tgoto break_or_fail;\n\t\t\t\t}\n\t\t\t\tset_bit(NILFS_I_COLLECTED, &ii->i_state);\n\t\t\t}\n\t\t\tsci->sc_stage.gc_inode_ptr = NULL;\n\t\t}\n\t\tnilfs_sc_cstage_inc(sci);\n\t\tfallthrough;\n\tcase NILFS_ST_FILE:\n\t\thead = &sci->sc_dirty_files;\n\t\tii = list_prepare_entry(sci->sc_stage.dirty_file_ptr, head,\n\t\t\t\t\ti_dirty);\n\t\tlist_for_each_entry_continue(ii, head, i_dirty) {\n\t\t\tclear_bit(NILFS_I_DIRTY, &ii->i_state);\n\n\t\t\terr = nilfs_segctor_scan_file(sci, &ii->vfs_inode,\n\t\t\t\t\t\t      &nilfs_sc_file_ops);\n\t\t\tif (unlikely(err)) {\n\t\t\t\tsci->sc_stage.dirty_file_ptr =\n\t\t\t\t\tlist_entry(ii->i_dirty.prev,\n\t\t\t\t\t\t   struct nilfs_inode_info,\n\t\t\t\t\t\t   i_dirty);\n\t\t\t\tgoto break_or_fail;\n\t\t\t}\n\t\t\t \n\t\t\t \n\t\t}\n\t\tsci->sc_stage.dirty_file_ptr = NULL;\n\t\tif (mode == SC_FLUSH_FILE) {\n\t\t\tnilfs_sc_cstage_set(sci, NILFS_ST_DONE);\n\t\t\treturn 0;\n\t\t}\n\t\tnilfs_sc_cstage_inc(sci);\n\t\tsci->sc_stage.flags |= NILFS_CF_IFILE_STARTED;\n\t\tfallthrough;\n\tcase NILFS_ST_IFILE:\n\t\terr = nilfs_segctor_scan_file(sci, sci->sc_root->ifile,\n\t\t\t\t\t      &nilfs_sc_file_ops);\n\t\tif (unlikely(err))\n\t\t\tbreak;\n\t\tnilfs_sc_cstage_inc(sci);\n\t\t \n\t\terr = nilfs_segctor_create_checkpoint(sci);\n\t\tif (unlikely(err))\n\t\t\tbreak;\n\t\tfallthrough;\n\tcase NILFS_ST_CPFILE:\n\t\terr = nilfs_segctor_scan_file(sci, nilfs->ns_cpfile,\n\t\t\t\t\t      &nilfs_sc_file_ops);\n\t\tif (unlikely(err))\n\t\t\tbreak;\n\t\tnilfs_sc_cstage_inc(sci);\n\t\tfallthrough;\n\tcase NILFS_ST_SUFILE:\n\t\terr = nilfs_sufile_freev(nilfs->ns_sufile, sci->sc_freesegs,\n\t\t\t\t\t sci->sc_nfreesegs, &ndone);\n\t\tif (unlikely(err)) {\n\t\t\tnilfs_sufile_cancel_freev(nilfs->ns_sufile,\n\t\t\t\t\t\t  sci->sc_freesegs, ndone,\n\t\t\t\t\t\t  NULL);\n\t\t\tbreak;\n\t\t}\n\t\tsci->sc_stage.flags |= NILFS_CF_SUFREED;\n\n\t\terr = nilfs_segctor_scan_file(sci, nilfs->ns_sufile,\n\t\t\t\t\t      &nilfs_sc_file_ops);\n\t\tif (unlikely(err))\n\t\t\tbreak;\n\t\tnilfs_sc_cstage_inc(sci);\n\t\tfallthrough;\n\tcase NILFS_ST_DAT:\n dat_stage:\n\t\terr = nilfs_segctor_scan_file(sci, nilfs->ns_dat,\n\t\t\t\t\t      &nilfs_sc_dat_ops);\n\t\tif (unlikely(err))\n\t\t\tbreak;\n\t\tif (mode == SC_FLUSH_DAT) {\n\t\t\tnilfs_sc_cstage_set(sci, NILFS_ST_DONE);\n\t\t\treturn 0;\n\t\t}\n\t\tnilfs_sc_cstage_inc(sci);\n\t\tfallthrough;\n\tcase NILFS_ST_SR:\n\t\tif (mode == SC_LSEG_SR) {\n\t\t\t \n\t\t\terr = nilfs_segctor_add_super_root(sci);\n\t\t\tif (unlikely(err))\n\t\t\t\tbreak;\n\t\t}\n\t\t \n\t\tsci->sc_curseg->sb_sum.flags |= NILFS_SS_LOGEND;\n\t\tnilfs_sc_cstage_set(sci, NILFS_ST_DONE);\n\t\treturn 0;\n\tcase NILFS_ST_DSYNC:\n dsync_mode:\n\t\tsci->sc_curseg->sb_sum.flags |= NILFS_SS_SYNDT;\n\t\tii = sci->sc_dsync_inode;\n\t\tif (!test_bit(NILFS_I_BUSY, &ii->i_state))\n\t\t\tbreak;\n\n\t\terr = nilfs_segctor_scan_file_dsync(sci, &ii->vfs_inode);\n\t\tif (unlikely(err))\n\t\t\tbreak;\n\t\tsci->sc_curseg->sb_sum.flags |= NILFS_SS_LOGEND;\n\t\tnilfs_sc_cstage_set(sci, NILFS_ST_DONE);\n\t\treturn 0;\n\tcase NILFS_ST_DONE:\n\t\treturn 0;\n\tdefault:\n\t\tBUG();\n\t}\n\n break_or_fail:\n\treturn err;\n}\n\n \nstatic int nilfs_segctor_begin_construction(struct nilfs_sc_info *sci,\n\t\t\t\t\t    struct the_nilfs *nilfs)\n{\n\tstruct nilfs_segment_buffer *segbuf, *prev;\n\t__u64 nextnum;\n\tint err, alloc = 0;\n\n\tsegbuf = nilfs_segbuf_new(sci->sc_super);\n\tif (unlikely(!segbuf))\n\t\treturn -ENOMEM;\n\n\tif (list_empty(&sci->sc_write_logs)) {\n\t\tnilfs_segbuf_map(segbuf, nilfs->ns_segnum,\n\t\t\t\t nilfs->ns_pseg_offset, nilfs);\n\t\tif (segbuf->sb_rest_blocks < NILFS_PSEG_MIN_BLOCKS) {\n\t\t\tnilfs_shift_to_next_segment(nilfs);\n\t\t\tnilfs_segbuf_map(segbuf, nilfs->ns_segnum, 0, nilfs);\n\t\t}\n\n\t\tsegbuf->sb_sum.seg_seq = nilfs->ns_seg_seq;\n\t\tnextnum = nilfs->ns_nextnum;\n\n\t\tif (nilfs->ns_segnum == nilfs->ns_nextnum)\n\t\t\t \n\t\t\talloc++;\n\t} else {\n\t\t \n\t\tprev = NILFS_LAST_SEGBUF(&sci->sc_write_logs);\n\t\tnilfs_segbuf_map_cont(segbuf, prev);\n\t\tsegbuf->sb_sum.seg_seq = prev->sb_sum.seg_seq;\n\t\tnextnum = prev->sb_nextnum;\n\n\t\tif (segbuf->sb_rest_blocks < NILFS_PSEG_MIN_BLOCKS) {\n\t\t\tnilfs_segbuf_map(segbuf, prev->sb_nextnum, 0, nilfs);\n\t\t\tsegbuf->sb_sum.seg_seq++;\n\t\t\talloc++;\n\t\t}\n\t}\n\n\terr = nilfs_sufile_mark_dirty(nilfs->ns_sufile, segbuf->sb_segnum);\n\tif (err)\n\t\tgoto failed;\n\n\tif (alloc) {\n\t\terr = nilfs_sufile_alloc(nilfs->ns_sufile, &nextnum);\n\t\tif (err)\n\t\t\tgoto failed;\n\t}\n\tnilfs_segbuf_set_next_segnum(segbuf, nextnum, nilfs);\n\n\tBUG_ON(!list_empty(&sci->sc_segbufs));\n\tlist_add_tail(&segbuf->sb_list, &sci->sc_segbufs);\n\tsci->sc_segbuf_nblocks = segbuf->sb_rest_blocks;\n\treturn 0;\n\n failed:\n\tnilfs_segbuf_free(segbuf);\n\treturn err;\n}\n\nstatic int nilfs_segctor_extend_segments(struct nilfs_sc_info *sci,\n\t\t\t\t\t struct the_nilfs *nilfs, int nadd)\n{\n\tstruct nilfs_segment_buffer *segbuf, *prev;\n\tstruct inode *sufile = nilfs->ns_sufile;\n\t__u64 nextnextnum;\n\tLIST_HEAD(list);\n\tint err, ret, i;\n\n\tprev = NILFS_LAST_SEGBUF(&sci->sc_segbufs);\n\t \n\terr = nilfs_sufile_mark_dirty(sufile, prev->sb_nextnum);\n\tif (unlikely(err))\n\t\treturn err;\n\n\tfor (i = 0; i < nadd; i++) {\n\t\t \n\t\terr = -ENOMEM;\n\t\tsegbuf = nilfs_segbuf_new(sci->sc_super);\n\t\tif (unlikely(!segbuf))\n\t\t\tgoto failed;\n\n\t\t \n\t\tnilfs_segbuf_map(segbuf, prev->sb_nextnum, 0, nilfs);\n\t\tsci->sc_segbuf_nblocks += segbuf->sb_rest_blocks;\n\n\t\t \n\t\terr = nilfs_sufile_alloc(sufile, &nextnextnum);\n\t\tif (unlikely(err))\n\t\t\tgoto failed_segbuf;\n\n\t\tsegbuf->sb_sum.seg_seq = prev->sb_sum.seg_seq + 1;\n\t\tnilfs_segbuf_set_next_segnum(segbuf, nextnextnum, nilfs);\n\n\t\tlist_add_tail(&segbuf->sb_list, &list);\n\t\tprev = segbuf;\n\t}\n\tlist_splice_tail(&list, &sci->sc_segbufs);\n\treturn 0;\n\n failed_segbuf:\n\tnilfs_segbuf_free(segbuf);\n failed:\n\tlist_for_each_entry(segbuf, &list, sb_list) {\n\t\tret = nilfs_sufile_free(sufile, segbuf->sb_nextnum);\n\t\tWARN_ON(ret);  \n\t}\n\tnilfs_destroy_logs(&list);\n\treturn err;\n}\n\nstatic void nilfs_free_incomplete_logs(struct list_head *logs,\n\t\t\t\t       struct the_nilfs *nilfs)\n{\n\tstruct nilfs_segment_buffer *segbuf, *prev;\n\tstruct inode *sufile = nilfs->ns_sufile;\n\tint ret;\n\n\tsegbuf = NILFS_FIRST_SEGBUF(logs);\n\tif (nilfs->ns_nextnum != segbuf->sb_nextnum) {\n\t\tret = nilfs_sufile_free(sufile, segbuf->sb_nextnum);\n\t\tWARN_ON(ret);  \n\t}\n\tif (atomic_read(&segbuf->sb_err)) {\n\t\t \n\t\tif (segbuf->sb_pseg_start != segbuf->sb_fseg_start)\n\t\t\t \n\t\t\tnilfs_terminate_segment(nilfs, segbuf->sb_fseg_start,\n\t\t\t\t\t\tsegbuf->sb_fseg_end);\n\t\telse  \n\t\t\tset_nilfs_discontinued(nilfs);\n\t}\n\n\tprev = segbuf;\n\tlist_for_each_entry_continue(segbuf, logs, sb_list) {\n\t\tif (prev->sb_nextnum != segbuf->sb_nextnum) {\n\t\t\tret = nilfs_sufile_free(sufile, segbuf->sb_nextnum);\n\t\t\tWARN_ON(ret);  \n\t\t}\n\t\tif (atomic_read(&segbuf->sb_err) &&\n\t\t    segbuf->sb_segnum != nilfs->ns_nextnum)\n\t\t\t \n\t\t\tnilfs_sufile_set_error(sufile, segbuf->sb_segnum);\n\t\tprev = segbuf;\n\t}\n}\n\nstatic void nilfs_segctor_update_segusage(struct nilfs_sc_info *sci,\n\t\t\t\t\t  struct inode *sufile)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tunsigned long live_blocks;\n\tint ret;\n\n\tlist_for_each_entry(segbuf, &sci->sc_segbufs, sb_list) {\n\t\tlive_blocks = segbuf->sb_sum.nblocks +\n\t\t\t(segbuf->sb_pseg_start - segbuf->sb_fseg_start);\n\t\tret = nilfs_sufile_set_segment_usage(sufile, segbuf->sb_segnum,\n\t\t\t\t\t\t     live_blocks,\n\t\t\t\t\t\t     sci->sc_seg_ctime);\n\t\tWARN_ON(ret);  \n\t}\n}\n\nstatic void nilfs_cancel_segusage(struct list_head *logs, struct inode *sufile)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tint ret;\n\n\tsegbuf = NILFS_FIRST_SEGBUF(logs);\n\tret = nilfs_sufile_set_segment_usage(sufile, segbuf->sb_segnum,\n\t\t\t\t\t     segbuf->sb_pseg_start -\n\t\t\t\t\t     segbuf->sb_fseg_start, 0);\n\tWARN_ON(ret);  \n\n\tlist_for_each_entry_continue(segbuf, logs, sb_list) {\n\t\tret = nilfs_sufile_set_segment_usage(sufile, segbuf->sb_segnum,\n\t\t\t\t\t\t     0, 0);\n\t\tWARN_ON(ret);  \n\t}\n}\n\nstatic void nilfs_segctor_truncate_segments(struct nilfs_sc_info *sci,\n\t\t\t\t\t    struct nilfs_segment_buffer *last,\n\t\t\t\t\t    struct inode *sufile)\n{\n\tstruct nilfs_segment_buffer *segbuf = last;\n\tint ret;\n\n\tlist_for_each_entry_continue(segbuf, &sci->sc_segbufs, sb_list) {\n\t\tsci->sc_segbuf_nblocks -= segbuf->sb_rest_blocks;\n\t\tret = nilfs_sufile_free(sufile, segbuf->sb_nextnum);\n\t\tWARN_ON(ret);\n\t}\n\tnilfs_truncate_logs(&sci->sc_segbufs, last);\n}\n\n\nstatic int nilfs_segctor_collect(struct nilfs_sc_info *sci,\n\t\t\t\t struct the_nilfs *nilfs, int mode)\n{\n\tstruct nilfs_cstage prev_stage = sci->sc_stage;\n\tint err, nadd = 1;\n\n\t \n\tfor (;;) {\n\t\tsci->sc_nblk_this_inc = 0;\n\t\tsci->sc_curseg = NILFS_FIRST_SEGBUF(&sci->sc_segbufs);\n\n\t\terr = nilfs_segctor_reset_segment_buffer(sci);\n\t\tif (unlikely(err))\n\t\t\tgoto failed;\n\n\t\terr = nilfs_segctor_collect_blocks(sci, mode);\n\t\tsci->sc_nblk_this_inc += sci->sc_curseg->sb_sum.nblocks;\n\t\tif (!err)\n\t\t\tbreak;\n\n\t\tif (unlikely(err != -E2BIG))\n\t\t\tgoto failed;\n\n\t\t \n\t\tif (mode != SC_LSEG_SR ||\n\t\t    nilfs_sc_cstage_get(sci) < NILFS_ST_CPFILE)\n\t\t\tbreak;\n\n\t\tnilfs_clear_logs(&sci->sc_segbufs);\n\n\t\tif (sci->sc_stage.flags & NILFS_CF_SUFREED) {\n\t\t\terr = nilfs_sufile_cancel_freev(nilfs->ns_sufile,\n\t\t\t\t\t\t\tsci->sc_freesegs,\n\t\t\t\t\t\t\tsci->sc_nfreesegs,\n\t\t\t\t\t\t\tNULL);\n\t\t\tWARN_ON(err);  \n\t\t\tsci->sc_stage.flags &= ~NILFS_CF_SUFREED;\n\t\t}\n\n\t\terr = nilfs_segctor_extend_segments(sci, nilfs, nadd);\n\t\tif (unlikely(err))\n\t\t\treturn err;\n\n\t\tnadd = min_t(int, nadd << 1, SC_MAX_SEGDELTA);\n\t\tsci->sc_stage = prev_stage;\n\t}\n\tnilfs_segctor_zeropad_segsum(sci);\n\tnilfs_segctor_truncate_segments(sci, sci->sc_curseg, nilfs->ns_sufile);\n\treturn 0;\n\n failed:\n\treturn err;\n}\n\nstatic void nilfs_list_replace_buffer(struct buffer_head *old_bh,\n\t\t\t\t      struct buffer_head *new_bh)\n{\n\tBUG_ON(!list_empty(&new_bh->b_assoc_buffers));\n\n\tlist_replace_init(&old_bh->b_assoc_buffers, &new_bh->b_assoc_buffers);\n\t \n}\n\nstatic int\nnilfs_segctor_update_payload_blocknr(struct nilfs_sc_info *sci,\n\t\t\t\t     struct nilfs_segment_buffer *segbuf,\n\t\t\t\t     int mode)\n{\n\tstruct inode *inode = NULL;\n\tsector_t blocknr;\n\tunsigned long nfinfo = segbuf->sb_sum.nfinfo;\n\tunsigned long nblocks = 0, ndatablk = 0;\n\tconst struct nilfs_sc_operations *sc_op = NULL;\n\tstruct nilfs_segsum_pointer ssp;\n\tstruct nilfs_finfo *finfo = NULL;\n\tunion nilfs_binfo binfo;\n\tstruct buffer_head *bh, *bh_org;\n\tino_t ino = 0;\n\tint err = 0;\n\n\tif (!nfinfo)\n\t\tgoto out;\n\n\tblocknr = segbuf->sb_pseg_start + segbuf->sb_sum.nsumblk;\n\tssp.bh = NILFS_SEGBUF_FIRST_BH(&segbuf->sb_segsum_buffers);\n\tssp.offset = sizeof(struct nilfs_segment_summary);\n\n\tlist_for_each_entry(bh, &segbuf->sb_payload_buffers, b_assoc_buffers) {\n\t\tif (bh == segbuf->sb_super_root)\n\t\t\tbreak;\n\t\tif (!finfo) {\n\t\t\tfinfo =\tnilfs_segctor_map_segsum_entry(\n\t\t\t\tsci, &ssp, sizeof(*finfo));\n\t\t\tino = le64_to_cpu(finfo->fi_ino);\n\t\t\tnblocks = le32_to_cpu(finfo->fi_nblocks);\n\t\t\tndatablk = le32_to_cpu(finfo->fi_ndatablk);\n\n\t\t\tinode = bh->b_folio->mapping->host;\n\n\t\t\tif (mode == SC_LSEG_DSYNC)\n\t\t\t\tsc_op = &nilfs_sc_dsync_ops;\n\t\t\telse if (ino == NILFS_DAT_INO)\n\t\t\t\tsc_op = &nilfs_sc_dat_ops;\n\t\t\telse  \n\t\t\t\tsc_op = &nilfs_sc_file_ops;\n\t\t}\n\t\tbh_org = bh;\n\t\tget_bh(bh_org);\n\t\terr = nilfs_bmap_assign(NILFS_I(inode)->i_bmap, &bh, blocknr,\n\t\t\t\t\t&binfo);\n\t\tif (bh != bh_org)\n\t\t\tnilfs_list_replace_buffer(bh_org, bh);\n\t\tbrelse(bh_org);\n\t\tif (unlikely(err))\n\t\t\tgoto failed_bmap;\n\n\t\tif (ndatablk > 0)\n\t\t\tsc_op->write_data_binfo(sci, &ssp, &binfo);\n\t\telse\n\t\t\tsc_op->write_node_binfo(sci, &ssp, &binfo);\n\n\t\tblocknr++;\n\t\tif (--nblocks == 0) {\n\t\t\tfinfo = NULL;\n\t\t\tif (--nfinfo == 0)\n\t\t\t\tbreak;\n\t\t} else if (ndatablk > 0)\n\t\t\tndatablk--;\n\t}\n out:\n\treturn 0;\n\n failed_bmap:\n\treturn err;\n}\n\nstatic int nilfs_segctor_assign(struct nilfs_sc_info *sci, int mode)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tint err;\n\n\tlist_for_each_entry(segbuf, &sci->sc_segbufs, sb_list) {\n\t\terr = nilfs_segctor_update_payload_blocknr(sci, segbuf, mode);\n\t\tif (unlikely(err))\n\t\t\treturn err;\n\t\tnilfs_segbuf_fill_in_segsum(segbuf);\n\t}\n\treturn 0;\n}\n\nstatic void nilfs_begin_page_io(struct page *page)\n{\n\tif (!page || PageWriteback(page))\n\t\t \n\t\treturn;\n\n\tlock_page(page);\n\tclear_page_dirty_for_io(page);\n\tset_page_writeback(page);\n\tunlock_page(page);\n}\n\nstatic void nilfs_segctor_prepare_write(struct nilfs_sc_info *sci)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tstruct page *bd_page = NULL, *fs_page = NULL;\n\n\tlist_for_each_entry(segbuf, &sci->sc_segbufs, sb_list) {\n\t\tstruct buffer_head *bh;\n\n\t\tlist_for_each_entry(bh, &segbuf->sb_segsum_buffers,\n\t\t\t\t    b_assoc_buffers) {\n\t\t\tif (bh->b_page != bd_page) {\n\t\t\t\tif (bd_page) {\n\t\t\t\t\tlock_page(bd_page);\n\t\t\t\t\tclear_page_dirty_for_io(bd_page);\n\t\t\t\t\tset_page_writeback(bd_page);\n\t\t\t\t\tunlock_page(bd_page);\n\t\t\t\t}\n\t\t\t\tbd_page = bh->b_page;\n\t\t\t}\n\t\t}\n\n\t\tlist_for_each_entry(bh, &segbuf->sb_payload_buffers,\n\t\t\t\t    b_assoc_buffers) {\n\t\t\tset_buffer_async_write(bh);\n\t\t\tif (bh == segbuf->sb_super_root) {\n\t\t\t\tif (bh->b_page != bd_page) {\n\t\t\t\t\tlock_page(bd_page);\n\t\t\t\t\tclear_page_dirty_for_io(bd_page);\n\t\t\t\t\tset_page_writeback(bd_page);\n\t\t\t\t\tunlock_page(bd_page);\n\t\t\t\t\tbd_page = bh->b_page;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (bh->b_page != fs_page) {\n\t\t\t\tnilfs_begin_page_io(fs_page);\n\t\t\t\tfs_page = bh->b_page;\n\t\t\t}\n\t\t}\n\t}\n\tif (bd_page) {\n\t\tlock_page(bd_page);\n\t\tclear_page_dirty_for_io(bd_page);\n\t\tset_page_writeback(bd_page);\n\t\tunlock_page(bd_page);\n\t}\n\tnilfs_begin_page_io(fs_page);\n}\n\nstatic int nilfs_segctor_write(struct nilfs_sc_info *sci,\n\t\t\t       struct the_nilfs *nilfs)\n{\n\tint ret;\n\n\tret = nilfs_write_logs(&sci->sc_segbufs, nilfs);\n\tlist_splice_tail_init(&sci->sc_segbufs, &sci->sc_write_logs);\n\treturn ret;\n}\n\nstatic void nilfs_end_page_io(struct page *page, int err)\n{\n\tif (!page)\n\t\treturn;\n\n\tif (buffer_nilfs_node(page_buffers(page)) && !PageWriteback(page)) {\n\t\t \n\t\tif (PageDirty(page)) {\n\t\t\t \n\t\t\tlock_page(page);\n\t\t\tif (nilfs_page_buffers_clean(page))\n\t\t\t\t__nilfs_clear_page_dirty(page);\n\t\t\tunlock_page(page);\n\t\t}\n\t\treturn;\n\t}\n\n\tif (!err) {\n\t\tif (!nilfs_page_buffers_clean(page))\n\t\t\t__set_page_dirty_nobuffers(page);\n\t\tClearPageError(page);\n\t} else {\n\t\t__set_page_dirty_nobuffers(page);\n\t\tSetPageError(page);\n\t}\n\n\tend_page_writeback(page);\n}\n\nstatic void nilfs_abort_logs(struct list_head *logs, int err)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tstruct page *bd_page = NULL, *fs_page = NULL;\n\tstruct buffer_head *bh;\n\n\tif (list_empty(logs))\n\t\treturn;\n\n\tlist_for_each_entry(segbuf, logs, sb_list) {\n\t\tlist_for_each_entry(bh, &segbuf->sb_segsum_buffers,\n\t\t\t\t    b_assoc_buffers) {\n\t\t\tclear_buffer_uptodate(bh);\n\t\t\tif (bh->b_page != bd_page) {\n\t\t\t\tif (bd_page)\n\t\t\t\t\tend_page_writeback(bd_page);\n\t\t\t\tbd_page = bh->b_page;\n\t\t\t}\n\t\t}\n\n\t\tlist_for_each_entry(bh, &segbuf->sb_payload_buffers,\n\t\t\t\t    b_assoc_buffers) {\n\t\t\tclear_buffer_async_write(bh);\n\t\t\tif (bh == segbuf->sb_super_root) {\n\t\t\t\tclear_buffer_uptodate(bh);\n\t\t\t\tif (bh->b_page != bd_page) {\n\t\t\t\t\tend_page_writeback(bd_page);\n\t\t\t\t\tbd_page = bh->b_page;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (bh->b_page != fs_page) {\n\t\t\t\tnilfs_end_page_io(fs_page, err);\n\t\t\t\tfs_page = bh->b_page;\n\t\t\t}\n\t\t}\n\t}\n\tif (bd_page)\n\t\tend_page_writeback(bd_page);\n\n\tnilfs_end_page_io(fs_page, err);\n}\n\nstatic void nilfs_segctor_abort_construction(struct nilfs_sc_info *sci,\n\t\t\t\t\t     struct the_nilfs *nilfs, int err)\n{\n\tLIST_HEAD(logs);\n\tint ret;\n\n\tlist_splice_tail_init(&sci->sc_write_logs, &logs);\n\tret = nilfs_wait_on_logs(&logs);\n\tnilfs_abort_logs(&logs, ret ? : err);\n\n\tlist_splice_tail_init(&sci->sc_segbufs, &logs);\n\tnilfs_cancel_segusage(&logs, nilfs->ns_sufile);\n\tnilfs_free_incomplete_logs(&logs, nilfs);\n\n\tif (sci->sc_stage.flags & NILFS_CF_SUFREED) {\n\t\tret = nilfs_sufile_cancel_freev(nilfs->ns_sufile,\n\t\t\t\t\t\tsci->sc_freesegs,\n\t\t\t\t\t\tsci->sc_nfreesegs,\n\t\t\t\t\t\tNULL);\n\t\tWARN_ON(ret);  \n\t}\n\n\tnilfs_destroy_logs(&logs);\n}\n\nstatic void nilfs_set_next_segment(struct the_nilfs *nilfs,\n\t\t\t\t   struct nilfs_segment_buffer *segbuf)\n{\n\tnilfs->ns_segnum = segbuf->sb_segnum;\n\tnilfs->ns_nextnum = segbuf->sb_nextnum;\n\tnilfs->ns_pseg_offset = segbuf->sb_pseg_start - segbuf->sb_fseg_start\n\t\t+ segbuf->sb_sum.nblocks;\n\tnilfs->ns_seg_seq = segbuf->sb_sum.seg_seq;\n\tnilfs->ns_ctime = segbuf->sb_sum.ctime;\n}\n\nstatic void nilfs_segctor_complete_write(struct nilfs_sc_info *sci)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tstruct page *bd_page = NULL, *fs_page = NULL;\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tint update_sr = false;\n\n\tlist_for_each_entry(segbuf, &sci->sc_write_logs, sb_list) {\n\t\tstruct buffer_head *bh;\n\n\t\tlist_for_each_entry(bh, &segbuf->sb_segsum_buffers,\n\t\t\t\t    b_assoc_buffers) {\n\t\t\tset_buffer_uptodate(bh);\n\t\t\tclear_buffer_dirty(bh);\n\t\t\tif (bh->b_page != bd_page) {\n\t\t\t\tif (bd_page)\n\t\t\t\t\tend_page_writeback(bd_page);\n\t\t\t\tbd_page = bh->b_page;\n\t\t\t}\n\t\t}\n\t\t \n\t\tlist_for_each_entry(bh, &segbuf->sb_payload_buffers,\n\t\t\t\t    b_assoc_buffers) {\n\t\t\tconst unsigned long set_bits = BIT(BH_Uptodate);\n\t\t\tconst unsigned long clear_bits =\n\t\t\t\t(BIT(BH_Dirty) | BIT(BH_Async_Write) |\n\t\t\t\t BIT(BH_Delay) | BIT(BH_NILFS_Volatile) |\n\t\t\t\t BIT(BH_NILFS_Redirected));\n\n\t\t\tset_mask_bits(&bh->b_state, clear_bits, set_bits);\n\t\t\tif (bh == segbuf->sb_super_root) {\n\t\t\t\tif (bh->b_page != bd_page) {\n\t\t\t\t\tend_page_writeback(bd_page);\n\t\t\t\t\tbd_page = bh->b_page;\n\t\t\t\t}\n\t\t\t\tupdate_sr = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (bh->b_page != fs_page) {\n\t\t\t\tnilfs_end_page_io(fs_page, 0);\n\t\t\t\tfs_page = bh->b_page;\n\t\t\t}\n\t\t}\n\n\t\tif (!nilfs_segbuf_simplex(segbuf)) {\n\t\t\tif (segbuf->sb_sum.flags & NILFS_SS_LOGBGN) {\n\t\t\t\tset_bit(NILFS_SC_UNCLOSED, &sci->sc_flags);\n\t\t\t\tsci->sc_lseg_stime = jiffies;\n\t\t\t}\n\t\t\tif (segbuf->sb_sum.flags & NILFS_SS_LOGEND)\n\t\t\t\tclear_bit(NILFS_SC_UNCLOSED, &sci->sc_flags);\n\t\t}\n\t}\n\t \n\tif (bd_page)\n\t\tend_page_writeback(bd_page);\n\n\tnilfs_end_page_io(fs_page, 0);\n\n\tnilfs_drop_collected_inodes(&sci->sc_dirty_files);\n\n\tif (nilfs_doing_gc())\n\t\tnilfs_drop_collected_inodes(&sci->sc_gc_inodes);\n\telse\n\t\tnilfs->ns_nongc_ctime = sci->sc_seg_ctime;\n\n\tsci->sc_nblk_inc += sci->sc_nblk_this_inc;\n\n\tsegbuf = NILFS_LAST_SEGBUF(&sci->sc_write_logs);\n\tnilfs_set_next_segment(nilfs, segbuf);\n\n\tif (update_sr) {\n\t\tnilfs->ns_flushed_device = 0;\n\t\tnilfs_set_last_segment(nilfs, segbuf->sb_pseg_start,\n\t\t\t\t       segbuf->sb_sum.seg_seq, nilfs->ns_cno++);\n\n\t\tclear_bit(NILFS_SC_HAVE_DELTA, &sci->sc_flags);\n\t\tclear_bit(NILFS_SC_DIRTY, &sci->sc_flags);\n\t\tset_bit(NILFS_SC_SUPER_ROOT, &sci->sc_flags);\n\t\tnilfs_segctor_clear_metadata_dirty(sci);\n\t} else\n\t\tclear_bit(NILFS_SC_SUPER_ROOT, &sci->sc_flags);\n}\n\nstatic int nilfs_segctor_wait(struct nilfs_sc_info *sci)\n{\n\tint ret;\n\n\tret = nilfs_wait_on_logs(&sci->sc_write_logs);\n\tif (!ret) {\n\t\tnilfs_segctor_complete_write(sci);\n\t\tnilfs_destroy_logs(&sci->sc_write_logs);\n\t}\n\treturn ret;\n}\n\nstatic int nilfs_segctor_collect_dirty_files(struct nilfs_sc_info *sci,\n\t\t\t\t\t     struct the_nilfs *nilfs)\n{\n\tstruct nilfs_inode_info *ii, *n;\n\tstruct inode *ifile = sci->sc_root->ifile;\n\n\tspin_lock(&nilfs->ns_inode_lock);\n retry:\n\tlist_for_each_entry_safe(ii, n, &nilfs->ns_dirty_files, i_dirty) {\n\t\tif (!ii->i_bh) {\n\t\t\tstruct buffer_head *ibh;\n\t\t\tint err;\n\n\t\t\tspin_unlock(&nilfs->ns_inode_lock);\n\t\t\terr = nilfs_ifile_get_inode_block(\n\t\t\t\tifile, ii->vfs_inode.i_ino, &ibh);\n\t\t\tif (unlikely(err)) {\n\t\t\t\tnilfs_warn(sci->sc_super,\n\t\t\t\t\t   \"log writer: error %d getting inode block (ino=%lu)\",\n\t\t\t\t\t   err, ii->vfs_inode.i_ino);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\tspin_lock(&nilfs->ns_inode_lock);\n\t\t\tif (likely(!ii->i_bh))\n\t\t\t\tii->i_bh = ibh;\n\t\t\telse\n\t\t\t\tbrelse(ibh);\n\t\t\tgoto retry;\n\t\t}\n\n\t\t\n\t\tmark_buffer_dirty(ii->i_bh);\n\t\tnilfs_mdt_mark_dirty(ifile);\n\n\t\tclear_bit(NILFS_I_QUEUED, &ii->i_state);\n\t\tset_bit(NILFS_I_BUSY, &ii->i_state);\n\t\tlist_move_tail(&ii->i_dirty, &sci->sc_dirty_files);\n\t}\n\tspin_unlock(&nilfs->ns_inode_lock);\n\n\treturn 0;\n}\n\nstatic void nilfs_segctor_drop_written_files(struct nilfs_sc_info *sci,\n\t\t\t\t\t     struct the_nilfs *nilfs)\n{\n\tstruct nilfs_inode_info *ii, *n;\n\tint during_mount = !(sci->sc_super->s_flags & SB_ACTIVE);\n\tint defer_iput = false;\n\n\tspin_lock(&nilfs->ns_inode_lock);\n\tlist_for_each_entry_safe(ii, n, &sci->sc_dirty_files, i_dirty) {\n\t\tif (!test_and_clear_bit(NILFS_I_UPDATED, &ii->i_state) ||\n\t\t    test_bit(NILFS_I_DIRTY, &ii->i_state))\n\t\t\tcontinue;\n\n\t\tclear_bit(NILFS_I_BUSY, &ii->i_state);\n\t\tbrelse(ii->i_bh);\n\t\tii->i_bh = NULL;\n\t\tlist_del_init(&ii->i_dirty);\n\t\tif (!ii->vfs_inode.i_nlink || during_mount) {\n\t\t\t \n\t\t\tlist_add_tail(&ii->i_dirty, &sci->sc_iput_queue);\n\t\t\tdefer_iput = true;\n\t\t} else {\n\t\t\tspin_unlock(&nilfs->ns_inode_lock);\n\t\t\tiput(&ii->vfs_inode);\n\t\t\tspin_lock(&nilfs->ns_inode_lock);\n\t\t}\n\t}\n\tspin_unlock(&nilfs->ns_inode_lock);\n\n\tif (defer_iput)\n\t\tschedule_work(&sci->sc_iput_work);\n}\n\n \nstatic int nilfs_segctor_do_construct(struct nilfs_sc_info *sci, int mode)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tint err;\n\n\tif (sb_rdonly(sci->sc_super))\n\t\treturn -EROFS;\n\n\tnilfs_sc_cstage_set(sci, NILFS_ST_INIT);\n\tsci->sc_cno = nilfs->ns_cno;\n\n\terr = nilfs_segctor_collect_dirty_files(sci, nilfs);\n\tif (unlikely(err))\n\t\tgoto out;\n\n\tif (nilfs_test_metadata_dirty(nilfs, sci->sc_root))\n\t\tset_bit(NILFS_SC_DIRTY, &sci->sc_flags);\n\n\tif (nilfs_segctor_clean(sci))\n\t\tgoto out;\n\n\tdo {\n\t\tsci->sc_stage.flags &= ~NILFS_CF_HISTORY_MASK;\n\n\t\terr = nilfs_segctor_begin_construction(sci, nilfs);\n\t\tif (unlikely(err))\n\t\t\tgoto out;\n\n\t\t \n\t\tsci->sc_seg_ctime = ktime_get_real_seconds();\n\n\t\terr = nilfs_segctor_collect(sci, nilfs, mode);\n\t\tif (unlikely(err))\n\t\t\tgoto failed;\n\n\t\t \n\t\tif (nilfs_sc_cstage_get(sci) == NILFS_ST_DONE &&\n\t\t    nilfs_segbuf_empty(sci->sc_curseg)) {\n\t\t\tnilfs_segctor_abort_construction(sci, nilfs, 1);\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = nilfs_segctor_assign(sci, mode);\n\t\tif (unlikely(err))\n\t\t\tgoto failed;\n\n\t\tif (sci->sc_stage.flags & NILFS_CF_IFILE_STARTED)\n\t\t\tnilfs_segctor_fill_in_file_bmap(sci);\n\n\t\tif (mode == SC_LSEG_SR &&\n\t\t    nilfs_sc_cstage_get(sci) >= NILFS_ST_CPFILE) {\n\t\t\terr = nilfs_segctor_fill_in_checkpoint(sci);\n\t\t\tif (unlikely(err))\n\t\t\t\tgoto failed_to_write;\n\n\t\t\tnilfs_segctor_fill_in_super_root(sci, nilfs);\n\t\t}\n\t\tnilfs_segctor_update_segusage(sci, nilfs->ns_sufile);\n\n\t\t \n\t\tnilfs_segctor_prepare_write(sci);\n\n\t\tnilfs_add_checksums_on_logs(&sci->sc_segbufs,\n\t\t\t\t\t    nilfs->ns_crc_seed);\n\n\t\terr = nilfs_segctor_write(sci, nilfs);\n\t\tif (unlikely(err))\n\t\t\tgoto failed_to_write;\n\n\t\tif (nilfs_sc_cstage_get(sci) == NILFS_ST_DONE ||\n\t\t    nilfs->ns_blocksize_bits != PAGE_SHIFT) {\n\t\t\t \n\t\t\terr = nilfs_segctor_wait(sci);\n\t\t\tif (err)\n\t\t\t\tgoto failed_to_write;\n\t\t}\n\t} while (nilfs_sc_cstage_get(sci) != NILFS_ST_DONE);\n\n out:\n\tnilfs_segctor_drop_written_files(sci, nilfs);\n\treturn err;\n\n failed_to_write:\n\tif (sci->sc_stage.flags & NILFS_CF_IFILE_STARTED)\n\t\tnilfs_redirty_inodes(&sci->sc_dirty_files);\n\n failed:\n\tif (nilfs_doing_gc())\n\t\tnilfs_redirty_inodes(&sci->sc_gc_inodes);\n\tnilfs_segctor_abort_construction(sci, nilfs, err);\n\tgoto out;\n}\n\n \nstatic void nilfs_segctor_start_timer(struct nilfs_sc_info *sci)\n{\n\tspin_lock(&sci->sc_state_lock);\n\tif (!(sci->sc_state & NILFS_SEGCTOR_COMMIT)) {\n\t\tsci->sc_timer.expires = jiffies + sci->sc_interval;\n\t\tadd_timer(&sci->sc_timer);\n\t\tsci->sc_state |= NILFS_SEGCTOR_COMMIT;\n\t}\n\tspin_unlock(&sci->sc_state_lock);\n}\n\nstatic void nilfs_segctor_do_flush(struct nilfs_sc_info *sci, int bn)\n{\n\tspin_lock(&sci->sc_state_lock);\n\tif (!(sci->sc_flush_request & BIT(bn))) {\n\t\tunsigned long prev_req = sci->sc_flush_request;\n\n\t\tsci->sc_flush_request |= BIT(bn);\n\t\tif (!prev_req)\n\t\t\twake_up(&sci->sc_wait_daemon);\n\t}\n\tspin_unlock(&sci->sc_state_lock);\n}\n\n \nvoid nilfs_flush_segment(struct super_block *sb, ino_t ino)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct nilfs_sc_info *sci = nilfs->ns_writer;\n\n\tif (!sci || nilfs_doing_construction())\n\t\treturn;\n\tnilfs_segctor_do_flush(sci, NILFS_MDT_INODE(sb, ino) ? ino : 0);\n\t\t\t\t\t \n}\n\nstruct nilfs_segctor_wait_request {\n\twait_queue_entry_t\twq;\n\t__u32\t\tseq;\n\tint\t\terr;\n\tatomic_t\tdone;\n};\n\nstatic int nilfs_segctor_sync(struct nilfs_sc_info *sci)\n{\n\tstruct nilfs_segctor_wait_request wait_req;\n\tint err = 0;\n\n\tspin_lock(&sci->sc_state_lock);\n\tinit_wait(&wait_req.wq);\n\twait_req.err = 0;\n\tatomic_set(&wait_req.done, 0);\n\twait_req.seq = ++sci->sc_seq_request;\n\tspin_unlock(&sci->sc_state_lock);\n\n\tinit_waitqueue_entry(&wait_req.wq, current);\n\tadd_wait_queue(&sci->sc_wait_request, &wait_req.wq);\n\tset_current_state(TASK_INTERRUPTIBLE);\n\twake_up(&sci->sc_wait_daemon);\n\n\tfor (;;) {\n\t\tif (atomic_read(&wait_req.done)) {\n\t\t\terr = wait_req.err;\n\t\t\tbreak;\n\t\t}\n\t\tif (!signal_pending(current)) {\n\t\t\tschedule();\n\t\t\tcontinue;\n\t\t}\n\t\terr = -ERESTARTSYS;\n\t\tbreak;\n\t}\n\tfinish_wait(&sci->sc_wait_request, &wait_req.wq);\n\treturn err;\n}\n\nstatic void nilfs_segctor_wakeup(struct nilfs_sc_info *sci, int err)\n{\n\tstruct nilfs_segctor_wait_request *wrq, *n;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&sci->sc_wait_request.lock, flags);\n\tlist_for_each_entry_safe(wrq, n, &sci->sc_wait_request.head, wq.entry) {\n\t\tif (!atomic_read(&wrq->done) &&\n\t\t    nilfs_cnt32_ge(sci->sc_seq_done, wrq->seq)) {\n\t\t\twrq->err = err;\n\t\t\tatomic_set(&wrq->done, 1);\n\t\t}\n\t\tif (atomic_read(&wrq->done)) {\n\t\t\twrq->wq.func(&wrq->wq,\n\t\t\t\t     TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE,\n\t\t\t\t     0, NULL);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&sci->sc_wait_request.lock, flags);\n}\n\n \nint nilfs_construct_segment(struct super_block *sb)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct nilfs_sc_info *sci = nilfs->ns_writer;\n\tstruct nilfs_transaction_info *ti;\n\n\tif (sb_rdonly(sb) || unlikely(!sci))\n\t\treturn -EROFS;\n\n\t \n\tBUG_ON((ti = current->journal_info) && ti->ti_magic == NILFS_TI_MAGIC);\n\n\treturn nilfs_segctor_sync(sci);\n}\n\n \nint nilfs_construct_dsync_segment(struct super_block *sb, struct inode *inode,\n\t\t\t\t  loff_t start, loff_t end)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct nilfs_sc_info *sci = nilfs->ns_writer;\n\tstruct nilfs_inode_info *ii;\n\tstruct nilfs_transaction_info ti;\n\tint err = 0;\n\n\tif (sb_rdonly(sb) || unlikely(!sci))\n\t\treturn -EROFS;\n\n\tnilfs_transaction_lock(sb, &ti, 0);\n\n\tii = NILFS_I(inode);\n\tif (test_bit(NILFS_I_INODE_SYNC, &ii->i_state) ||\n\t    nilfs_test_opt(nilfs, STRICT_ORDER) ||\n\t    test_bit(NILFS_SC_UNCLOSED, &sci->sc_flags) ||\n\t    nilfs_discontinued(nilfs)) {\n\t\tnilfs_transaction_unlock(sb);\n\t\terr = nilfs_segctor_sync(sci);\n\t\treturn err;\n\t}\n\n\tspin_lock(&nilfs->ns_inode_lock);\n\tif (!test_bit(NILFS_I_QUEUED, &ii->i_state) &&\n\t    !test_bit(NILFS_I_BUSY, &ii->i_state)) {\n\t\tspin_unlock(&nilfs->ns_inode_lock);\n\t\tnilfs_transaction_unlock(sb);\n\t\treturn 0;\n\t}\n\tspin_unlock(&nilfs->ns_inode_lock);\n\tsci->sc_dsync_inode = ii;\n\tsci->sc_dsync_start = start;\n\tsci->sc_dsync_end = end;\n\n\terr = nilfs_segctor_do_construct(sci, SC_LSEG_DSYNC);\n\tif (!err)\n\t\tnilfs->ns_flushed_device = 0;\n\n\tnilfs_transaction_unlock(sb);\n\treturn err;\n}\n\n#define FLUSH_FILE_BIT\t(0x1)  \n#define FLUSH_DAT_BIT\tBIT(NILFS_DAT_INO)  \n\n \nstatic void nilfs_segctor_accept(struct nilfs_sc_info *sci)\n{\n\tspin_lock(&sci->sc_state_lock);\n\tsci->sc_seq_accepted = sci->sc_seq_request;\n\tspin_unlock(&sci->sc_state_lock);\n\tdel_timer_sync(&sci->sc_timer);\n}\n\n \nstatic void nilfs_segctor_notify(struct nilfs_sc_info *sci, int mode, int err)\n{\n\t \n\tspin_lock(&sci->sc_state_lock);\n\n\tif (mode == SC_LSEG_SR) {\n\t\tsci->sc_state &= ~NILFS_SEGCTOR_COMMIT;\n\t\tsci->sc_seq_done = sci->sc_seq_accepted;\n\t\tnilfs_segctor_wakeup(sci, err);\n\t\tsci->sc_flush_request = 0;\n\t} else {\n\t\tif (mode == SC_FLUSH_FILE)\n\t\t\tsci->sc_flush_request &= ~FLUSH_FILE_BIT;\n\t\telse if (mode == SC_FLUSH_DAT)\n\t\t\tsci->sc_flush_request &= ~FLUSH_DAT_BIT;\n\n\t\t \n\t\tif ((sci->sc_state & NILFS_SEGCTOR_COMMIT) &&\n\t\t    time_before(jiffies, sci->sc_timer.expires))\n\t\t\tadd_timer(&sci->sc_timer);\n\t}\n\tspin_unlock(&sci->sc_state_lock);\n}\n\n \nstatic int nilfs_segctor_construct(struct nilfs_sc_info *sci, int mode)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tstruct nilfs_super_block **sbp;\n\tint err = 0;\n\n\tnilfs_segctor_accept(sci);\n\n\tif (nilfs_discontinued(nilfs))\n\t\tmode = SC_LSEG_SR;\n\tif (!nilfs_segctor_confirm(sci))\n\t\terr = nilfs_segctor_do_construct(sci, mode);\n\n\tif (likely(!err)) {\n\t\tif (mode != SC_FLUSH_DAT)\n\t\t\tatomic_set(&nilfs->ns_ndirtyblks, 0);\n\t\tif (test_bit(NILFS_SC_SUPER_ROOT, &sci->sc_flags) &&\n\t\t    nilfs_discontinued(nilfs)) {\n\t\t\tdown_write(&nilfs->ns_sem);\n\t\t\terr = -EIO;\n\t\t\tsbp = nilfs_prepare_super(sci->sc_super,\n\t\t\t\t\t\t  nilfs_sb_will_flip(nilfs));\n\t\t\tif (likely(sbp)) {\n\t\t\t\tnilfs_set_log_cursor(sbp[0], nilfs);\n\t\t\t\terr = nilfs_commit_super(sci->sc_super,\n\t\t\t\t\t\t\t NILFS_SB_COMMIT);\n\t\t\t}\n\t\t\tup_write(&nilfs->ns_sem);\n\t\t}\n\t}\n\n\tnilfs_segctor_notify(sci, mode, err);\n\treturn err;\n}\n\nstatic void nilfs_construction_timeout(struct timer_list *t)\n{\n\tstruct nilfs_sc_info *sci = from_timer(sci, t, sc_timer);\n\n\twake_up_process(sci->sc_timer_task);\n}\n\nstatic void\nnilfs_remove_written_gcinodes(struct the_nilfs *nilfs, struct list_head *head)\n{\n\tstruct nilfs_inode_info *ii, *n;\n\n\tlist_for_each_entry_safe(ii, n, head, i_dirty) {\n\t\tif (!test_bit(NILFS_I_UPDATED, &ii->i_state))\n\t\t\tcontinue;\n\t\tlist_del_init(&ii->i_dirty);\n\t\ttruncate_inode_pages(&ii->vfs_inode.i_data, 0);\n\t\tnilfs_btnode_cache_clear(ii->i_assoc_inode->i_mapping);\n\t\tiput(&ii->vfs_inode);\n\t}\n}\n\nint nilfs_clean_segments(struct super_block *sb, struct nilfs_argv *argv,\n\t\t\t void **kbufs)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct nilfs_sc_info *sci = nilfs->ns_writer;\n\tstruct nilfs_transaction_info ti;\n\tint err;\n\n\tif (unlikely(!sci))\n\t\treturn -EROFS;\n\n\tnilfs_transaction_lock(sb, &ti, 1);\n\n\terr = nilfs_mdt_save_to_shadow_map(nilfs->ns_dat);\n\tif (unlikely(err))\n\t\tgoto out_unlock;\n\n\terr = nilfs_ioctl_prepare_clean_segments(nilfs, argv, kbufs);\n\tif (unlikely(err)) {\n\t\tnilfs_mdt_restore_from_shadow_map(nilfs->ns_dat);\n\t\tgoto out_unlock;\n\t}\n\n\tsci->sc_freesegs = kbufs[4];\n\tsci->sc_nfreesegs = argv[4].v_nmembs;\n\tlist_splice_tail_init(&nilfs->ns_gc_inodes, &sci->sc_gc_inodes);\n\n\tfor (;;) {\n\t\terr = nilfs_segctor_construct(sci, SC_LSEG_SR);\n\t\tnilfs_remove_written_gcinodes(nilfs, &sci->sc_gc_inodes);\n\n\t\tif (likely(!err))\n\t\t\tbreak;\n\n\t\tnilfs_warn(sb, \"error %d cleaning segments\", err);\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tschedule_timeout(sci->sc_interval);\n\t}\n\tif (nilfs_test_opt(nilfs, DISCARD)) {\n\t\tint ret = nilfs_discard_segments(nilfs, sci->sc_freesegs,\n\t\t\t\t\t\t sci->sc_nfreesegs);\n\t\tif (ret) {\n\t\t\tnilfs_warn(sb,\n\t\t\t\t   \"error %d on discard request, turning discards off for the device\",\n\t\t\t\t   ret);\n\t\t\tnilfs_clear_opt(nilfs, DISCARD);\n\t\t}\n\t}\n\n out_unlock:\n\tsci->sc_freesegs = NULL;\n\tsci->sc_nfreesegs = 0;\n\tnilfs_mdt_clear_shadow_map(nilfs->ns_dat);\n\tnilfs_transaction_unlock(sb);\n\treturn err;\n}\n\nstatic void nilfs_segctor_thread_construct(struct nilfs_sc_info *sci, int mode)\n{\n\tstruct nilfs_transaction_info ti;\n\n\tnilfs_transaction_lock(sci->sc_super, &ti, 0);\n\tnilfs_segctor_construct(sci, mode);\n\n\t \n\tif (test_bit(NILFS_SC_UNCLOSED, &sci->sc_flags))\n\t\tnilfs_segctor_start_timer(sci);\n\n\tnilfs_transaction_unlock(sci->sc_super);\n}\n\nstatic void nilfs_segctor_do_immediate_flush(struct nilfs_sc_info *sci)\n{\n\tint mode = 0;\n\n\tspin_lock(&sci->sc_state_lock);\n\tmode = (sci->sc_flush_request & FLUSH_DAT_BIT) ?\n\t\tSC_FLUSH_DAT : SC_FLUSH_FILE;\n\tspin_unlock(&sci->sc_state_lock);\n\n\tif (mode) {\n\t\tnilfs_segctor_do_construct(sci, mode);\n\n\t\tspin_lock(&sci->sc_state_lock);\n\t\tsci->sc_flush_request &= (mode == SC_FLUSH_FILE) ?\n\t\t\t~FLUSH_FILE_BIT : ~FLUSH_DAT_BIT;\n\t\tspin_unlock(&sci->sc_state_lock);\n\t}\n\tclear_bit(NILFS_SC_PRIOR_FLUSH, &sci->sc_flags);\n}\n\nstatic int nilfs_segctor_flush_mode(struct nilfs_sc_info *sci)\n{\n\tif (!test_bit(NILFS_SC_UNCLOSED, &sci->sc_flags) ||\n\t    time_before(jiffies, sci->sc_lseg_stime + sci->sc_mjcp_freq)) {\n\t\tif (!(sci->sc_flush_request & ~FLUSH_FILE_BIT))\n\t\t\treturn SC_FLUSH_FILE;\n\t\telse if (!(sci->sc_flush_request & ~FLUSH_DAT_BIT))\n\t\t\treturn SC_FLUSH_DAT;\n\t}\n\treturn SC_LSEG_SR;\n}\n\n \nstatic int nilfs_segctor_thread(void *arg)\n{\n\tstruct nilfs_sc_info *sci = (struct nilfs_sc_info *)arg;\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tint timeout = 0;\n\n\tsci->sc_timer_task = current;\n\n\t \n\tsci->sc_task = current;\n\twake_up(&sci->sc_wait_task);  \n\tnilfs_info(sci->sc_super,\n\t\t   \"segctord starting. Construction interval = %lu seconds, CP frequency < %lu seconds\",\n\t\t   sci->sc_interval / HZ, sci->sc_mjcp_freq / HZ);\n\n\tspin_lock(&sci->sc_state_lock);\n loop:\n\tfor (;;) {\n\t\tint mode;\n\n\t\tif (sci->sc_state & NILFS_SEGCTOR_QUIT)\n\t\t\tgoto end_thread;\n\n\t\tif (timeout || sci->sc_seq_request != sci->sc_seq_done)\n\t\t\tmode = SC_LSEG_SR;\n\t\telse if (sci->sc_flush_request)\n\t\t\tmode = nilfs_segctor_flush_mode(sci);\n\t\telse\n\t\t\tbreak;\n\n\t\tspin_unlock(&sci->sc_state_lock);\n\t\tnilfs_segctor_thread_construct(sci, mode);\n\t\tspin_lock(&sci->sc_state_lock);\n\t\ttimeout = 0;\n\t}\n\n\n\tif (freezing(current)) {\n\t\tspin_unlock(&sci->sc_state_lock);\n\t\ttry_to_freeze();\n\t\tspin_lock(&sci->sc_state_lock);\n\t} else {\n\t\tDEFINE_WAIT(wait);\n\t\tint should_sleep = 1;\n\n\t\tprepare_to_wait(&sci->sc_wait_daemon, &wait,\n\t\t\t\tTASK_INTERRUPTIBLE);\n\n\t\tif (sci->sc_seq_request != sci->sc_seq_done)\n\t\t\tshould_sleep = 0;\n\t\telse if (sci->sc_flush_request)\n\t\t\tshould_sleep = 0;\n\t\telse if (sci->sc_state & NILFS_SEGCTOR_COMMIT)\n\t\t\tshould_sleep = time_before(jiffies,\n\t\t\t\t\tsci->sc_timer.expires);\n\n\t\tif (should_sleep) {\n\t\t\tspin_unlock(&sci->sc_state_lock);\n\t\t\tschedule();\n\t\t\tspin_lock(&sci->sc_state_lock);\n\t\t}\n\t\tfinish_wait(&sci->sc_wait_daemon, &wait);\n\t\ttimeout = ((sci->sc_state & NILFS_SEGCTOR_COMMIT) &&\n\t\t\t   time_after_eq(jiffies, sci->sc_timer.expires));\n\n\t\tif (nilfs_sb_dirty(nilfs) && nilfs_sb_need_update(nilfs))\n\t\t\tset_nilfs_discontinued(nilfs);\n\t}\n\tgoto loop;\n\n end_thread:\n\t \n\tsci->sc_task = NULL;\n\twake_up(&sci->sc_wait_task);  \n\tspin_unlock(&sci->sc_state_lock);\n\treturn 0;\n}\n\nstatic int nilfs_segctor_start_thread(struct nilfs_sc_info *sci)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(nilfs_segctor_thread, sci, \"segctord\");\n\tif (IS_ERR(t)) {\n\t\tint err = PTR_ERR(t);\n\n\t\tnilfs_err(sci->sc_super, \"error %d creating segctord thread\",\n\t\t\t  err);\n\t\treturn err;\n\t}\n\twait_event(sci->sc_wait_task, sci->sc_task != NULL);\n\treturn 0;\n}\n\nstatic void nilfs_segctor_kill_thread(struct nilfs_sc_info *sci)\n\t__acquires(&sci->sc_state_lock)\n\t__releases(&sci->sc_state_lock)\n{\n\tsci->sc_state |= NILFS_SEGCTOR_QUIT;\n\n\twhile (sci->sc_task) {\n\t\twake_up(&sci->sc_wait_daemon);\n\t\tspin_unlock(&sci->sc_state_lock);\n\t\twait_event(sci->sc_wait_task, sci->sc_task == NULL);\n\t\tspin_lock(&sci->sc_state_lock);\n\t}\n}\n\n \nstatic struct nilfs_sc_info *nilfs_segctor_new(struct super_block *sb,\n\t\t\t\t\t       struct nilfs_root *root)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct nilfs_sc_info *sci;\n\n\tsci = kzalloc(sizeof(*sci), GFP_KERNEL);\n\tif (!sci)\n\t\treturn NULL;\n\n\tsci->sc_super = sb;\n\n\tnilfs_get_root(root);\n\tsci->sc_root = root;\n\n\tinit_waitqueue_head(&sci->sc_wait_request);\n\tinit_waitqueue_head(&sci->sc_wait_daemon);\n\tinit_waitqueue_head(&sci->sc_wait_task);\n\tspin_lock_init(&sci->sc_state_lock);\n\tINIT_LIST_HEAD(&sci->sc_dirty_files);\n\tINIT_LIST_HEAD(&sci->sc_segbufs);\n\tINIT_LIST_HEAD(&sci->sc_write_logs);\n\tINIT_LIST_HEAD(&sci->sc_gc_inodes);\n\tINIT_LIST_HEAD(&sci->sc_iput_queue);\n\tINIT_WORK(&sci->sc_iput_work, nilfs_iput_work_func);\n\ttimer_setup(&sci->sc_timer, nilfs_construction_timeout, 0);\n\n\tsci->sc_interval = HZ * NILFS_SC_DEFAULT_TIMEOUT;\n\tsci->sc_mjcp_freq = HZ * NILFS_SC_DEFAULT_SR_FREQ;\n\tsci->sc_watermark = NILFS_SC_DEFAULT_WATERMARK;\n\n\tif (nilfs->ns_interval)\n\t\tsci->sc_interval = HZ * nilfs->ns_interval;\n\tif (nilfs->ns_watermark)\n\t\tsci->sc_watermark = nilfs->ns_watermark;\n\treturn sci;\n}\n\nstatic void nilfs_segctor_write_out(struct nilfs_sc_info *sci)\n{\n\tint ret, retrycount = NILFS_SC_CLEANUP_RETRY;\n\n\t \n\tdo {\n\t\tstruct nilfs_transaction_info ti;\n\n\t\tnilfs_transaction_lock(sci->sc_super, &ti, 0);\n\t\tret = nilfs_segctor_construct(sci, SC_LSEG_SR);\n\t\tnilfs_transaction_unlock(sci->sc_super);\n\n\t\tflush_work(&sci->sc_iput_work);\n\n\t} while (ret && ret != -EROFS && retrycount-- > 0);\n}\n\n \nstatic void nilfs_segctor_destroy(struct nilfs_sc_info *sci)\n{\n\tstruct the_nilfs *nilfs = sci->sc_super->s_fs_info;\n\tint flag;\n\n\tup_write(&nilfs->ns_segctor_sem);\n\n\tspin_lock(&sci->sc_state_lock);\n\tnilfs_segctor_kill_thread(sci);\n\tflag = ((sci->sc_state & NILFS_SEGCTOR_COMMIT) || sci->sc_flush_request\n\t\t|| sci->sc_seq_request != sci->sc_seq_done);\n\tspin_unlock(&sci->sc_state_lock);\n\n\tif (flush_work(&sci->sc_iput_work))\n\t\tflag = true;\n\n\tif (flag || !nilfs_segctor_confirm(sci))\n\t\tnilfs_segctor_write_out(sci);\n\n\tif (!list_empty(&sci->sc_dirty_files)) {\n\t\tnilfs_warn(sci->sc_super,\n\t\t\t   \"disposed unprocessed dirty file(s) when stopping log writer\");\n\t\tnilfs_dispose_list(nilfs, &sci->sc_dirty_files, 1);\n\t}\n\n\tif (!list_empty(&sci->sc_iput_queue)) {\n\t\tnilfs_warn(sci->sc_super,\n\t\t\t   \"disposed unprocessed inode(s) in iput queue when stopping log writer\");\n\t\tnilfs_dispose_list(nilfs, &sci->sc_iput_queue, 1);\n\t}\n\n\tWARN_ON(!list_empty(&sci->sc_segbufs));\n\tWARN_ON(!list_empty(&sci->sc_write_logs));\n\n\tnilfs_put_root(sci->sc_root);\n\n\tdown_write(&nilfs->ns_segctor_sem);\n\n\ttimer_shutdown_sync(&sci->sc_timer);\n\tkfree(sci);\n}\n\n \nint nilfs_attach_log_writer(struct super_block *sb, struct nilfs_root *root)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tint err;\n\n\tif (nilfs->ns_writer) {\n\t\t \n\t\treturn 0;\n\t}\n\n\tnilfs->ns_writer = nilfs_segctor_new(sb, root);\n\tif (!nilfs->ns_writer)\n\t\treturn -ENOMEM;\n\n\tinode_attach_wb(nilfs->ns_bdev->bd_inode, NULL);\n\n\terr = nilfs_segctor_start_thread(nilfs->ns_writer);\n\tif (unlikely(err))\n\t\tnilfs_detach_log_writer(sb);\n\n\treturn err;\n}\n\n \nvoid nilfs_detach_log_writer(struct super_block *sb)\n{\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tLIST_HEAD(garbage_list);\n\n\tdown_write(&nilfs->ns_segctor_sem);\n\tif (nilfs->ns_writer) {\n\t\tnilfs_segctor_destroy(nilfs->ns_writer);\n\t\tnilfs->ns_writer = NULL;\n\t}\n\tset_nilfs_purging(nilfs);\n\n\t \n\tspin_lock(&nilfs->ns_inode_lock);\n\tif (!list_empty(&nilfs->ns_dirty_files)) {\n\t\tlist_splice_init(&nilfs->ns_dirty_files, &garbage_list);\n\t\tnilfs_warn(sb,\n\t\t\t   \"disposed unprocessed dirty file(s) when detaching log writer\");\n\t}\n\tspin_unlock(&nilfs->ns_inode_lock);\n\tup_write(&nilfs->ns_segctor_sem);\n\n\tnilfs_dispose_list(nilfs, &garbage_list, 1);\n\tclear_nilfs_purging(nilfs);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}