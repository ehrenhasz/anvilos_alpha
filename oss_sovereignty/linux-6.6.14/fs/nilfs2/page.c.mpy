{
  "module_name": "page.c",
  "hash_id": "c4f38c55a6f3ccc6f9ce817fef6b82f9918413f07b1f2eb0a9782cdc4d8e0780",
  "original_prompt": "Ingested from linux-6.6.14/fs/nilfs2/page.c",
  "human_readable_source": "\n \n\n#include <linux/pagemap.h>\n#include <linux/writeback.h>\n#include <linux/swap.h>\n#include <linux/bitops.h>\n#include <linux/page-flags.h>\n#include <linux/list.h>\n#include <linux/highmem.h>\n#include <linux/pagevec.h>\n#include <linux/gfp.h>\n#include \"nilfs.h\"\n#include \"page.h\"\n#include \"mdt.h\"\n\n\n#define NILFS_BUFFER_INHERENT_BITS\t\t\t\t\t\\\n\t(BIT(BH_Uptodate) | BIT(BH_Mapped) | BIT(BH_NILFS_Node) |\t\\\n\t BIT(BH_NILFS_Volatile) | BIT(BH_NILFS_Checked))\n\nstatic struct buffer_head *\n__nilfs_get_page_block(struct page *page, unsigned long block, pgoff_t index,\n\t\t       int blkbits, unsigned long b_state)\n\n{\n\tunsigned long first_block;\n\tstruct buffer_head *bh;\n\n\tif (!page_has_buffers(page))\n\t\tcreate_empty_buffers(page, 1 << blkbits, b_state);\n\n\tfirst_block = (unsigned long)index << (PAGE_SHIFT - blkbits);\n\tbh = nilfs_page_get_nth_block(page, block - first_block);\n\n\ttouch_buffer(bh);\n\twait_on_buffer(bh);\n\treturn bh;\n}\n\nstruct buffer_head *nilfs_grab_buffer(struct inode *inode,\n\t\t\t\t      struct address_space *mapping,\n\t\t\t\t      unsigned long blkoff,\n\t\t\t\t      unsigned long b_state)\n{\n\tint blkbits = inode->i_blkbits;\n\tpgoff_t index = blkoff >> (PAGE_SHIFT - blkbits);\n\tstruct page *page;\n\tstruct buffer_head *bh;\n\n\tpage = grab_cache_page(mapping, index);\n\tif (unlikely(!page))\n\t\treturn NULL;\n\n\tbh = __nilfs_get_page_block(page, blkoff, index, blkbits, b_state);\n\tif (unlikely(!bh)) {\n\t\tunlock_page(page);\n\t\tput_page(page);\n\t\treturn NULL;\n\t}\n\treturn bh;\n}\n\n \nvoid nilfs_forget_buffer(struct buffer_head *bh)\n{\n\tstruct page *page = bh->b_page;\n\tconst unsigned long clear_bits =\n\t\t(BIT(BH_Uptodate) | BIT(BH_Dirty) | BIT(BH_Mapped) |\n\t\t BIT(BH_Async_Write) | BIT(BH_NILFS_Volatile) |\n\t\t BIT(BH_NILFS_Checked) | BIT(BH_NILFS_Redirected));\n\n\tlock_buffer(bh);\n\tset_mask_bits(&bh->b_state, clear_bits, 0);\n\tif (nilfs_page_buffers_clean(page))\n\t\t__nilfs_clear_page_dirty(page);\n\n\tbh->b_blocknr = -1;\n\tClearPageUptodate(page);\n\tClearPageMappedToDisk(page);\n\tunlock_buffer(bh);\n\tbrelse(bh);\n}\n\n \nvoid nilfs_copy_buffer(struct buffer_head *dbh, struct buffer_head *sbh)\n{\n\tvoid *kaddr0, *kaddr1;\n\tunsigned long bits;\n\tstruct page *spage = sbh->b_page, *dpage = dbh->b_page;\n\tstruct buffer_head *bh;\n\n\tkaddr0 = kmap_atomic(spage);\n\tkaddr1 = kmap_atomic(dpage);\n\tmemcpy(kaddr1 + bh_offset(dbh), kaddr0 + bh_offset(sbh), sbh->b_size);\n\tkunmap_atomic(kaddr1);\n\tkunmap_atomic(kaddr0);\n\n\tdbh->b_state = sbh->b_state & NILFS_BUFFER_INHERENT_BITS;\n\tdbh->b_blocknr = sbh->b_blocknr;\n\tdbh->b_bdev = sbh->b_bdev;\n\n\tbh = dbh;\n\tbits = sbh->b_state & (BIT(BH_Uptodate) | BIT(BH_Mapped));\n\twhile ((bh = bh->b_this_page) != dbh) {\n\t\tlock_buffer(bh);\n\t\tbits &= bh->b_state;\n\t\tunlock_buffer(bh);\n\t}\n\tif (bits & BIT(BH_Uptodate))\n\t\tSetPageUptodate(dpage);\n\telse\n\t\tClearPageUptodate(dpage);\n\tif (bits & BIT(BH_Mapped))\n\t\tSetPageMappedToDisk(dpage);\n\telse\n\t\tClearPageMappedToDisk(dpage);\n}\n\n \nint nilfs_page_buffers_clean(struct page *page)\n{\n\tstruct buffer_head *bh, *head;\n\n\tbh = head = page_buffers(page);\n\tdo {\n\t\tif (buffer_dirty(bh))\n\t\t\treturn 0;\n\t\tbh = bh->b_this_page;\n\t} while (bh != head);\n\treturn 1;\n}\n\nvoid nilfs_page_bug(struct page *page)\n{\n\tstruct address_space *m;\n\tunsigned long ino;\n\n\tif (unlikely(!page)) {\n\t\tprintk(KERN_CRIT \"NILFS_PAGE_BUG(NULL)\\n\");\n\t\treturn;\n\t}\n\n\tm = page->mapping;\n\tino = m ? m->host->i_ino : 0;\n\n\tprintk(KERN_CRIT \"NILFS_PAGE_BUG(%p): cnt=%d index#=%llu flags=0x%lx \"\n\t       \"mapping=%p ino=%lu\\n\",\n\t       page, page_ref_count(page),\n\t       (unsigned long long)page->index, page->flags, m, ino);\n\n\tif (page_has_buffers(page)) {\n\t\tstruct buffer_head *bh, *head;\n\t\tint i = 0;\n\n\t\tbh = head = page_buffers(page);\n\t\tdo {\n\t\t\tprintk(KERN_CRIT\n\t\t\t       \" BH[%d] %p: cnt=%d block#=%llu state=0x%lx\\n\",\n\t\t\t       i++, bh, atomic_read(&bh->b_count),\n\t\t\t       (unsigned long long)bh->b_blocknr, bh->b_state);\n\t\t\tbh = bh->b_this_page;\n\t\t} while (bh != head);\n\t}\n}\n\n \nstatic void nilfs_copy_page(struct page *dst, struct page *src, int copy_dirty)\n{\n\tstruct buffer_head *dbh, *dbufs, *sbh;\n\tunsigned long mask = NILFS_BUFFER_INHERENT_BITS;\n\n\tBUG_ON(PageWriteback(dst));\n\n\tsbh = page_buffers(src);\n\tif (!page_has_buffers(dst))\n\t\tcreate_empty_buffers(dst, sbh->b_size, 0);\n\n\tif (copy_dirty)\n\t\tmask |= BIT(BH_Dirty);\n\n\tdbh = dbufs = page_buffers(dst);\n\tdo {\n\t\tlock_buffer(sbh);\n\t\tlock_buffer(dbh);\n\t\tdbh->b_state = sbh->b_state & mask;\n\t\tdbh->b_blocknr = sbh->b_blocknr;\n\t\tdbh->b_bdev = sbh->b_bdev;\n\t\tsbh = sbh->b_this_page;\n\t\tdbh = dbh->b_this_page;\n\t} while (dbh != dbufs);\n\n\tcopy_highpage(dst, src);\n\n\tif (PageUptodate(src) && !PageUptodate(dst))\n\t\tSetPageUptodate(dst);\n\telse if (!PageUptodate(src) && PageUptodate(dst))\n\t\tClearPageUptodate(dst);\n\tif (PageMappedToDisk(src) && !PageMappedToDisk(dst))\n\t\tSetPageMappedToDisk(dst);\n\telse if (!PageMappedToDisk(src) && PageMappedToDisk(dst))\n\t\tClearPageMappedToDisk(dst);\n\n\tdo {\n\t\tunlock_buffer(sbh);\n\t\tunlock_buffer(dbh);\n\t\tsbh = sbh->b_this_page;\n\t\tdbh = dbh->b_this_page;\n\t} while (dbh != dbufs);\n}\n\nint nilfs_copy_dirty_pages(struct address_space *dmap,\n\t\t\t   struct address_space *smap)\n{\n\tstruct folio_batch fbatch;\n\tunsigned int i;\n\tpgoff_t index = 0;\n\tint err = 0;\n\n\tfolio_batch_init(&fbatch);\nrepeat:\n\tif (!filemap_get_folios_tag(smap, &index, (pgoff_t)-1,\n\t\t\t\tPAGECACHE_TAG_DIRTY, &fbatch))\n\t\treturn 0;\n\n\tfor (i = 0; i < folio_batch_count(&fbatch); i++) {\n\t\tstruct folio *folio = fbatch.folios[i], *dfolio;\n\n\t\tfolio_lock(folio);\n\t\tif (unlikely(!folio_test_dirty(folio)))\n\t\t\tNILFS_PAGE_BUG(&folio->page, \"inconsistent dirty state\");\n\n\t\tdfolio = filemap_grab_folio(dmap, folio->index);\n\t\tif (unlikely(IS_ERR(dfolio))) {\n\t\t\t \n\t\t\tfolio_unlock(folio);\n\t\t\terr = PTR_ERR(dfolio);\n\t\t\tbreak;\n\t\t}\n\t\tif (unlikely(!folio_buffers(folio)))\n\t\t\tNILFS_PAGE_BUG(&folio->page,\n\t\t\t\t       \"found empty page in dat page cache\");\n\n\t\tnilfs_copy_page(&dfolio->page, &folio->page, 1);\n\t\tfilemap_dirty_folio(folio_mapping(dfolio), dfolio);\n\n\t\tfolio_unlock(dfolio);\n\t\tfolio_put(dfolio);\n\t\tfolio_unlock(folio);\n\t}\n\tfolio_batch_release(&fbatch);\n\tcond_resched();\n\n\tif (likely(!err))\n\t\tgoto repeat;\n\treturn err;\n}\n\n \nvoid nilfs_copy_back_pages(struct address_space *dmap,\n\t\t\t   struct address_space *smap)\n{\n\tstruct folio_batch fbatch;\n\tunsigned int i, n;\n\tpgoff_t start = 0;\n\n\tfolio_batch_init(&fbatch);\nrepeat:\n\tn = filemap_get_folios(smap, &start, ~0UL, &fbatch);\n\tif (!n)\n\t\treturn;\n\n\tfor (i = 0; i < folio_batch_count(&fbatch); i++) {\n\t\tstruct folio *folio = fbatch.folios[i], *dfolio;\n\t\tpgoff_t index = folio->index;\n\n\t\tfolio_lock(folio);\n\t\tdfolio = filemap_lock_folio(dmap, index);\n\t\tif (!IS_ERR(dfolio)) {\n\t\t\t \n\t\t\tWARN_ON(folio_test_dirty(dfolio));\n\t\t\tnilfs_copy_page(&dfolio->page, &folio->page, 0);\n\t\t\tfolio_unlock(dfolio);\n\t\t\tfolio_put(dfolio);\n\t\t\t \n\t\t} else {\n\t\t\tstruct folio *f;\n\n\t\t\t \n\t\t\txa_lock_irq(&smap->i_pages);\n\t\t\tf = __xa_erase(&smap->i_pages, index);\n\t\t\tWARN_ON(folio != f);\n\t\t\tsmap->nrpages--;\n\t\t\txa_unlock_irq(&smap->i_pages);\n\n\t\t\txa_lock_irq(&dmap->i_pages);\n\t\t\tf = __xa_store(&dmap->i_pages, index, folio, GFP_NOFS);\n\t\t\tif (unlikely(f)) {\n\t\t\t\t \n\t\t\t\tfolio->mapping = NULL;\n\t\t\t\tfolio_put(folio);\n\t\t\t} else {\n\t\t\t\tfolio->mapping = dmap;\n\t\t\t\tdmap->nrpages++;\n\t\t\t\tif (folio_test_dirty(folio))\n\t\t\t\t\t__xa_set_mark(&dmap->i_pages, index,\n\t\t\t\t\t\t\tPAGECACHE_TAG_DIRTY);\n\t\t\t}\n\t\t\txa_unlock_irq(&dmap->i_pages);\n\t\t}\n\t\tfolio_unlock(folio);\n\t}\n\tfolio_batch_release(&fbatch);\n\tcond_resched();\n\n\tgoto repeat;\n}\n\n \nvoid nilfs_clear_dirty_pages(struct address_space *mapping, bool silent)\n{\n\tstruct folio_batch fbatch;\n\tunsigned int i;\n\tpgoff_t index = 0;\n\n\tfolio_batch_init(&fbatch);\n\n\twhile (filemap_get_folios_tag(mapping, &index, (pgoff_t)-1,\n\t\t\t\tPAGECACHE_TAG_DIRTY, &fbatch)) {\n\t\tfor (i = 0; i < folio_batch_count(&fbatch); i++) {\n\t\t\tstruct folio *folio = fbatch.folios[i];\n\n\t\t\tfolio_lock(folio);\n\n\t\t\t \n\t\t\tif (likely(folio->mapping == mapping))\n\t\t\t\tnilfs_clear_dirty_page(&folio->page, silent);\n\n\t\t\tfolio_unlock(folio);\n\t\t}\n\t\tfolio_batch_release(&fbatch);\n\t\tcond_resched();\n\t}\n}\n\n \nvoid nilfs_clear_dirty_page(struct page *page, bool silent)\n{\n\tstruct inode *inode = page->mapping->host;\n\tstruct super_block *sb = inode->i_sb;\n\n\tBUG_ON(!PageLocked(page));\n\n\tif (!silent)\n\t\tnilfs_warn(sb, \"discard dirty page: offset=%lld, ino=%lu\",\n\t\t\t   page_offset(page), inode->i_ino);\n\n\tClearPageUptodate(page);\n\tClearPageMappedToDisk(page);\n\n\tif (page_has_buffers(page)) {\n\t\tstruct buffer_head *bh, *head;\n\t\tconst unsigned long clear_bits =\n\t\t\t(BIT(BH_Uptodate) | BIT(BH_Dirty) | BIT(BH_Mapped) |\n\t\t\t BIT(BH_Async_Write) | BIT(BH_NILFS_Volatile) |\n\t\t\t BIT(BH_NILFS_Checked) | BIT(BH_NILFS_Redirected));\n\n\t\tbh = head = page_buffers(page);\n\t\tdo {\n\t\t\tlock_buffer(bh);\n\t\t\tif (!silent)\n\t\t\t\tnilfs_warn(sb,\n\t\t\t\t\t   \"discard dirty block: blocknr=%llu, size=%zu\",\n\t\t\t\t\t   (u64)bh->b_blocknr, bh->b_size);\n\n\t\t\tset_mask_bits(&bh->b_state, clear_bits, 0);\n\t\t\tunlock_buffer(bh);\n\t\t} while (bh = bh->b_this_page, bh != head);\n\t}\n\n\t__nilfs_clear_page_dirty(page);\n}\n\nunsigned int nilfs_page_count_clean_buffers(struct page *page,\n\t\t\t\t\t    unsigned int from, unsigned int to)\n{\n\tunsigned int block_start, block_end;\n\tstruct buffer_head *bh, *head;\n\tunsigned int nc = 0;\n\n\tfor (bh = head = page_buffers(page), block_start = 0;\n\t     bh != head || !block_start;\n\t     block_start = block_end, bh = bh->b_this_page) {\n\t\tblock_end = block_start + bh->b_size;\n\t\tif (block_end > from && block_start < to && !buffer_dirty(bh))\n\t\t\tnc++;\n\t}\n\treturn nc;\n}\n\n \nint __nilfs_clear_page_dirty(struct page *page)\n{\n\tstruct address_space *mapping = page->mapping;\n\n\tif (mapping) {\n\t\txa_lock_irq(&mapping->i_pages);\n\t\tif (test_bit(PG_dirty, &page->flags)) {\n\t\t\t__xa_clear_mark(&mapping->i_pages, page_index(page),\n\t\t\t\t\t     PAGECACHE_TAG_DIRTY);\n\t\t\txa_unlock_irq(&mapping->i_pages);\n\t\t\treturn clear_page_dirty_for_io(page);\n\t\t}\n\t\txa_unlock_irq(&mapping->i_pages);\n\t\treturn 0;\n\t}\n\treturn TestClearPageDirty(page);\n}\n\n \nunsigned long nilfs_find_uncommitted_extent(struct inode *inode,\n\t\t\t\t\t    sector_t start_blk,\n\t\t\t\t\t    sector_t *blkoff)\n{\n\tunsigned int i, nr_folios;\n\tpgoff_t index;\n\tunsigned long length = 0;\n\tstruct folio_batch fbatch;\n\tstruct folio *folio;\n\n\tif (inode->i_mapping->nrpages == 0)\n\t\treturn 0;\n\n\tindex = start_blk >> (PAGE_SHIFT - inode->i_blkbits);\n\n\tfolio_batch_init(&fbatch);\n\nrepeat:\n\tnr_folios = filemap_get_folios_contig(inode->i_mapping, &index, ULONG_MAX,\n\t\t\t&fbatch);\n\tif (nr_folios == 0)\n\t\treturn length;\n\n\ti = 0;\n\tdo {\n\t\tfolio = fbatch.folios[i];\n\n\t\tfolio_lock(folio);\n\t\tif (folio_buffers(folio)) {\n\t\t\tstruct buffer_head *bh, *head;\n\t\t\tsector_t b;\n\n\t\t\tb = folio->index << (PAGE_SHIFT - inode->i_blkbits);\n\t\t\tbh = head = folio_buffers(folio);\n\t\t\tdo {\n\t\t\t\tif (b < start_blk)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (buffer_delay(bh)) {\n\t\t\t\t\tif (length == 0)\n\t\t\t\t\t\t*blkoff = b;\n\t\t\t\t\tlength++;\n\t\t\t\t} else if (length > 0) {\n\t\t\t\t\tgoto out_locked;\n\t\t\t\t}\n\t\t\t} while (++b, bh = bh->b_this_page, bh != head);\n\t\t} else {\n\t\t\tif (length > 0)\n\t\t\t\tgoto out_locked;\n\t\t}\n\t\tfolio_unlock(folio);\n\n\t} while (++i < nr_folios);\n\n\tfolio_batch_release(&fbatch);\n\tcond_resched();\n\tgoto repeat;\n\nout_locked:\n\tfolio_unlock(folio);\n\tfolio_batch_release(&fbatch);\n\treturn length;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}