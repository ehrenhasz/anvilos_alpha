{
  "module_name": "segbuf.c",
  "hash_id": "8f2ce846b7cba840aa00db24b5e538f2a6b39721a98c17bbae796bbacb4e81ac",
  "original_prompt": "Ingested from linux-6.6.14/fs/nilfs2/segbuf.c",
  "human_readable_source": "\n \n\n#include <linux/buffer_head.h>\n#include <linux/writeback.h>\n#include <linux/crc32.h>\n#include <linux/backing-dev.h>\n#include <linux/slab.h>\n#include \"page.h\"\n#include \"segbuf.h\"\n\n\nstruct nilfs_write_info {\n\tstruct the_nilfs       *nilfs;\n\tstruct bio\t       *bio;\n\tint\t\t\tstart, end;  \n\tint\t\t\trest_blocks;\n\tint\t\t\tmax_pages;\n\tint\t\t\tnr_vecs;\n\tsector_t\t\tblocknr;\n};\n\nstatic int nilfs_segbuf_write(struct nilfs_segment_buffer *segbuf,\n\t\t\t      struct the_nilfs *nilfs);\nstatic int nilfs_segbuf_wait(struct nilfs_segment_buffer *segbuf);\n\nstruct nilfs_segment_buffer *nilfs_segbuf_new(struct super_block *sb)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\n\tsegbuf = kmem_cache_alloc(nilfs_segbuf_cachep, GFP_NOFS);\n\tif (unlikely(!segbuf))\n\t\treturn NULL;\n\n\tsegbuf->sb_super = sb;\n\tINIT_LIST_HEAD(&segbuf->sb_list);\n\tINIT_LIST_HEAD(&segbuf->sb_segsum_buffers);\n\tINIT_LIST_HEAD(&segbuf->sb_payload_buffers);\n\tsegbuf->sb_super_root = NULL;\n\n\tinit_completion(&segbuf->sb_bio_event);\n\tatomic_set(&segbuf->sb_err, 0);\n\tsegbuf->sb_nbio = 0;\n\n\treturn segbuf;\n}\n\nvoid nilfs_segbuf_free(struct nilfs_segment_buffer *segbuf)\n{\n\tkmem_cache_free(nilfs_segbuf_cachep, segbuf);\n}\n\nvoid nilfs_segbuf_map(struct nilfs_segment_buffer *segbuf, __u64 segnum,\n\t\t     unsigned long offset, struct the_nilfs *nilfs)\n{\n\tsegbuf->sb_segnum = segnum;\n\tnilfs_get_segment_range(nilfs, segnum, &segbuf->sb_fseg_start,\n\t\t\t\t&segbuf->sb_fseg_end);\n\n\tsegbuf->sb_pseg_start = segbuf->sb_fseg_start + offset;\n\tsegbuf->sb_rest_blocks =\n\t\tsegbuf->sb_fseg_end - segbuf->sb_pseg_start + 1;\n}\n\n \nvoid nilfs_segbuf_map_cont(struct nilfs_segment_buffer *segbuf,\n\t\t\t   struct nilfs_segment_buffer *prev)\n{\n\tsegbuf->sb_segnum = prev->sb_segnum;\n\tsegbuf->sb_fseg_start = prev->sb_fseg_start;\n\tsegbuf->sb_fseg_end = prev->sb_fseg_end;\n\tsegbuf->sb_pseg_start = prev->sb_pseg_start + prev->sb_sum.nblocks;\n\tsegbuf->sb_rest_blocks =\n\t\tsegbuf->sb_fseg_end - segbuf->sb_pseg_start + 1;\n}\n\nvoid nilfs_segbuf_set_next_segnum(struct nilfs_segment_buffer *segbuf,\n\t\t\t\t  __u64 nextnum, struct the_nilfs *nilfs)\n{\n\tsegbuf->sb_nextnum = nextnum;\n\tsegbuf->sb_sum.next = nilfs_get_segment_start_blocknr(nilfs, nextnum);\n}\n\nint nilfs_segbuf_extend_segsum(struct nilfs_segment_buffer *segbuf)\n{\n\tstruct buffer_head *bh;\n\n\tbh = sb_getblk(segbuf->sb_super,\n\t\t       segbuf->sb_pseg_start + segbuf->sb_sum.nsumblk);\n\tif (unlikely(!bh))\n\t\treturn -ENOMEM;\n\n\tlock_buffer(bh);\n\tif (!buffer_uptodate(bh)) {\n\t\tmemset(bh->b_data, 0, bh->b_size);\n\t\tset_buffer_uptodate(bh);\n\t}\n\tunlock_buffer(bh);\n\tnilfs_segbuf_add_segsum_buffer(segbuf, bh);\n\treturn 0;\n}\n\nint nilfs_segbuf_extend_payload(struct nilfs_segment_buffer *segbuf,\n\t\t\t\tstruct buffer_head **bhp)\n{\n\tstruct buffer_head *bh;\n\n\tbh = sb_getblk(segbuf->sb_super,\n\t\t       segbuf->sb_pseg_start + segbuf->sb_sum.nblocks);\n\tif (unlikely(!bh))\n\t\treturn -ENOMEM;\n\n\tnilfs_segbuf_add_payload_buffer(segbuf, bh);\n\t*bhp = bh;\n\treturn 0;\n}\n\nint nilfs_segbuf_reset(struct nilfs_segment_buffer *segbuf, unsigned int flags,\n\t\t       time64_t ctime, __u64 cno)\n{\n\tint err;\n\n\tsegbuf->sb_sum.nblocks = segbuf->sb_sum.nsumblk = 0;\n\terr = nilfs_segbuf_extend_segsum(segbuf);\n\tif (unlikely(err))\n\t\treturn err;\n\n\tsegbuf->sb_sum.flags = flags;\n\tsegbuf->sb_sum.sumbytes = sizeof(struct nilfs_segment_summary);\n\tsegbuf->sb_sum.nfinfo = segbuf->sb_sum.nfileblk = 0;\n\tsegbuf->sb_sum.ctime = ctime;\n\tsegbuf->sb_sum.cno = cno;\n\treturn 0;\n}\n\n \nvoid nilfs_segbuf_fill_in_segsum(struct nilfs_segment_buffer *segbuf)\n{\n\tstruct nilfs_segment_summary *raw_sum;\n\tstruct buffer_head *bh_sum;\n\n\tbh_sum = list_entry(segbuf->sb_segsum_buffers.next,\n\t\t\t    struct buffer_head, b_assoc_buffers);\n\traw_sum = (struct nilfs_segment_summary *)bh_sum->b_data;\n\n\traw_sum->ss_magic    = cpu_to_le32(NILFS_SEGSUM_MAGIC);\n\traw_sum->ss_bytes    = cpu_to_le16(sizeof(*raw_sum));\n\traw_sum->ss_flags    = cpu_to_le16(segbuf->sb_sum.flags);\n\traw_sum->ss_seq      = cpu_to_le64(segbuf->sb_sum.seg_seq);\n\traw_sum->ss_create   = cpu_to_le64(segbuf->sb_sum.ctime);\n\traw_sum->ss_next     = cpu_to_le64(segbuf->sb_sum.next);\n\traw_sum->ss_nblocks  = cpu_to_le32(segbuf->sb_sum.nblocks);\n\traw_sum->ss_nfinfo   = cpu_to_le32(segbuf->sb_sum.nfinfo);\n\traw_sum->ss_sumbytes = cpu_to_le32(segbuf->sb_sum.sumbytes);\n\traw_sum->ss_pad      = 0;\n\traw_sum->ss_cno      = cpu_to_le64(segbuf->sb_sum.cno);\n}\n\n \nstatic void\nnilfs_segbuf_fill_in_segsum_crc(struct nilfs_segment_buffer *segbuf, u32 seed)\n{\n\tstruct buffer_head *bh;\n\tstruct nilfs_segment_summary *raw_sum;\n\tunsigned long size, bytes = segbuf->sb_sum.sumbytes;\n\tu32 crc;\n\n\tbh = list_entry(segbuf->sb_segsum_buffers.next, struct buffer_head,\n\t\t\tb_assoc_buffers);\n\n\traw_sum = (struct nilfs_segment_summary *)bh->b_data;\n\tsize = min_t(unsigned long, bytes, bh->b_size);\n\tcrc = crc32_le(seed,\n\t\t       (unsigned char *)raw_sum +\n\t\t       sizeof(raw_sum->ss_datasum) + sizeof(raw_sum->ss_sumsum),\n\t\t       size - (sizeof(raw_sum->ss_datasum) +\n\t\t\t       sizeof(raw_sum->ss_sumsum)));\n\n\tlist_for_each_entry_continue(bh, &segbuf->sb_segsum_buffers,\n\t\t\t\t     b_assoc_buffers) {\n\t\tbytes -= size;\n\t\tsize = min_t(unsigned long, bytes, bh->b_size);\n\t\tcrc = crc32_le(crc, bh->b_data, size);\n\t}\n\traw_sum->ss_sumsum = cpu_to_le32(crc);\n}\n\nstatic void nilfs_segbuf_fill_in_data_crc(struct nilfs_segment_buffer *segbuf,\n\t\t\t\t\t  u32 seed)\n{\n\tstruct buffer_head *bh;\n\tstruct nilfs_segment_summary *raw_sum;\n\tvoid *kaddr;\n\tu32 crc;\n\n\tbh = list_entry(segbuf->sb_segsum_buffers.next, struct buffer_head,\n\t\t\tb_assoc_buffers);\n\traw_sum = (struct nilfs_segment_summary *)bh->b_data;\n\tcrc = crc32_le(seed,\n\t\t       (unsigned char *)raw_sum + sizeof(raw_sum->ss_datasum),\n\t\t       bh->b_size - sizeof(raw_sum->ss_datasum));\n\n\tlist_for_each_entry_continue(bh, &segbuf->sb_segsum_buffers,\n\t\t\t\t     b_assoc_buffers) {\n\t\tcrc = crc32_le(crc, bh->b_data, bh->b_size);\n\t}\n\tlist_for_each_entry(bh, &segbuf->sb_payload_buffers, b_assoc_buffers) {\n\t\tkaddr = kmap_atomic(bh->b_page);\n\t\tcrc = crc32_le(crc, kaddr + bh_offset(bh), bh->b_size);\n\t\tkunmap_atomic(kaddr);\n\t}\n\traw_sum->ss_datasum = cpu_to_le32(crc);\n}\n\nstatic void\nnilfs_segbuf_fill_in_super_root_crc(struct nilfs_segment_buffer *segbuf,\n\t\t\t\t    u32 seed)\n{\n\tstruct nilfs_super_root *raw_sr;\n\tstruct the_nilfs *nilfs = segbuf->sb_super->s_fs_info;\n\tunsigned int srsize;\n\tu32 crc;\n\n\traw_sr = (struct nilfs_super_root *)segbuf->sb_super_root->b_data;\n\tsrsize = NILFS_SR_BYTES(nilfs->ns_inode_size);\n\tcrc = crc32_le(seed,\n\t\t       (unsigned char *)raw_sr + sizeof(raw_sr->sr_sum),\n\t\t       srsize - sizeof(raw_sr->sr_sum));\n\traw_sr->sr_sum = cpu_to_le32(crc);\n}\n\nstatic void nilfs_release_buffers(struct list_head *list)\n{\n\tstruct buffer_head *bh, *n;\n\n\tlist_for_each_entry_safe(bh, n, list, b_assoc_buffers) {\n\t\tlist_del_init(&bh->b_assoc_buffers);\n\t\tbrelse(bh);\n\t}\n}\n\nstatic void nilfs_segbuf_clear(struct nilfs_segment_buffer *segbuf)\n{\n\tnilfs_release_buffers(&segbuf->sb_segsum_buffers);\n\tnilfs_release_buffers(&segbuf->sb_payload_buffers);\n\tsegbuf->sb_super_root = NULL;\n}\n\n \nvoid nilfs_clear_logs(struct list_head *logs)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\n\tlist_for_each_entry(segbuf, logs, sb_list)\n\t\tnilfs_segbuf_clear(segbuf);\n}\n\nvoid nilfs_truncate_logs(struct list_head *logs,\n\t\t\t struct nilfs_segment_buffer *last)\n{\n\tstruct nilfs_segment_buffer *n, *segbuf;\n\n\tsegbuf = list_prepare_entry(last, logs, sb_list);\n\tlist_for_each_entry_safe_continue(segbuf, n, logs, sb_list) {\n\t\tlist_del_init(&segbuf->sb_list);\n\t\tnilfs_segbuf_clear(segbuf);\n\t\tnilfs_segbuf_free(segbuf);\n\t}\n}\n\nint nilfs_write_logs(struct list_head *logs, struct the_nilfs *nilfs)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tint ret = 0;\n\n\tlist_for_each_entry(segbuf, logs, sb_list) {\n\t\tret = nilfs_segbuf_write(segbuf, nilfs);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\nint nilfs_wait_on_logs(struct list_head *logs)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\tint err, ret = 0;\n\n\tlist_for_each_entry(segbuf, logs, sb_list) {\n\t\terr = nilfs_segbuf_wait(segbuf);\n\t\tif (err && !ret)\n\t\t\tret = err;\n\t}\n\treturn ret;\n}\n\n \nvoid nilfs_add_checksums_on_logs(struct list_head *logs, u32 seed)\n{\n\tstruct nilfs_segment_buffer *segbuf;\n\n\tlist_for_each_entry(segbuf, logs, sb_list) {\n\t\tif (segbuf->sb_super_root)\n\t\t\tnilfs_segbuf_fill_in_super_root_crc(segbuf, seed);\n\t\tnilfs_segbuf_fill_in_segsum_crc(segbuf, seed);\n\t\tnilfs_segbuf_fill_in_data_crc(segbuf, seed);\n\t}\n}\n\n \nstatic void nilfs_end_bio_write(struct bio *bio)\n{\n\tstruct nilfs_segment_buffer *segbuf = bio->bi_private;\n\n\tif (bio->bi_status)\n\t\tatomic_inc(&segbuf->sb_err);\n\n\tbio_put(bio);\n\tcomplete(&segbuf->sb_bio_event);\n}\n\nstatic int nilfs_segbuf_submit_bio(struct nilfs_segment_buffer *segbuf,\n\t\t\t\t   struct nilfs_write_info *wi)\n{\n\tstruct bio *bio = wi->bio;\n\n\tbio->bi_end_io = nilfs_end_bio_write;\n\tbio->bi_private = segbuf;\n\tsubmit_bio(bio);\n\tsegbuf->sb_nbio++;\n\n\twi->bio = NULL;\n\twi->rest_blocks -= wi->end - wi->start;\n\twi->nr_vecs = min(wi->max_pages, wi->rest_blocks);\n\twi->start = wi->end;\n\treturn 0;\n}\n\nstatic void nilfs_segbuf_prepare_write(struct nilfs_segment_buffer *segbuf,\n\t\t\t\t       struct nilfs_write_info *wi)\n{\n\twi->bio = NULL;\n\twi->rest_blocks = segbuf->sb_sum.nblocks;\n\twi->max_pages = BIO_MAX_VECS;\n\twi->nr_vecs = min(wi->max_pages, wi->rest_blocks);\n\twi->start = wi->end = 0;\n\twi->blocknr = segbuf->sb_pseg_start;\n}\n\nstatic int nilfs_segbuf_submit_bh(struct nilfs_segment_buffer *segbuf,\n\t\t\t\t  struct nilfs_write_info *wi,\n\t\t\t\t  struct buffer_head *bh)\n{\n\tint len, err;\n\n\tBUG_ON(wi->nr_vecs <= 0);\n repeat:\n\tif (!wi->bio) {\n\t\twi->bio = bio_alloc(wi->nilfs->ns_bdev, wi->nr_vecs,\n\t\t\t\t    REQ_OP_WRITE, GFP_NOIO);\n\t\twi->bio->bi_iter.bi_sector = (wi->blocknr + wi->end) <<\n\t\t\t(wi->nilfs->ns_blocksize_bits - 9);\n\t}\n\n\tlen = bio_add_page(wi->bio, bh->b_page, bh->b_size, bh_offset(bh));\n\tif (len == bh->b_size) {\n\t\twi->end++;\n\t\treturn 0;\n\t}\n\t \n\terr = nilfs_segbuf_submit_bio(segbuf, wi);\n\t \n\tif (likely(!err))\n\t\tgoto repeat;\n\treturn err;\n}\n\n \nstatic int nilfs_segbuf_write(struct nilfs_segment_buffer *segbuf,\n\t\t\t      struct the_nilfs *nilfs)\n{\n\tstruct nilfs_write_info wi;\n\tstruct buffer_head *bh;\n\tint res = 0;\n\n\twi.nilfs = nilfs;\n\tnilfs_segbuf_prepare_write(segbuf, &wi);\n\n\tlist_for_each_entry(bh, &segbuf->sb_segsum_buffers, b_assoc_buffers) {\n\t\tres = nilfs_segbuf_submit_bh(segbuf, &wi, bh);\n\t\tif (unlikely(res))\n\t\t\tgoto failed_bio;\n\t}\n\n\tlist_for_each_entry(bh, &segbuf->sb_payload_buffers, b_assoc_buffers) {\n\t\tres = nilfs_segbuf_submit_bh(segbuf, &wi, bh);\n\t\tif (unlikely(res))\n\t\t\tgoto failed_bio;\n\t}\n\n\tif (wi.bio) {\n\t\t \n\t\twi.bio->bi_opf |= REQ_SYNC;\n\t\tres = nilfs_segbuf_submit_bio(segbuf, &wi);\n\t}\n\n failed_bio:\n\treturn res;\n}\n\n \nstatic int nilfs_segbuf_wait(struct nilfs_segment_buffer *segbuf)\n{\n\tint err = 0;\n\n\tif (!segbuf->sb_nbio)\n\t\treturn 0;\n\n\tdo {\n\t\twait_for_completion(&segbuf->sb_bio_event);\n\t} while (--segbuf->sb_nbio > 0);\n\n\tif (unlikely(atomic_read(&segbuf->sb_err) > 0)) {\n\t\tnilfs_err(segbuf->sb_super,\n\t\t\t  \"I/O error writing log (start-blocknr=%llu, block-count=%lu) in segment %llu\",\n\t\t\t  (unsigned long long)segbuf->sb_pseg_start,\n\t\t\t  segbuf->sb_sum.nblocks,\n\t\t\t  (unsigned long long)segbuf->sb_segnum);\n\t\terr = -EIO;\n\t}\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}