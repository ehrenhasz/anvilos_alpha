{
  "module_name": "write.c",
  "hash_id": "ef8257cf98bda26099d8cd72c9585627e8a63b3b3b4ba097863e6c618a62ed90",
  "original_prompt": "Ingested from linux-6.6.14/fs/afs/write.c",
  "human_readable_source": "\n \n\n#include <linux/backing-dev.h>\n#include <linux/slab.h>\n#include <linux/fs.h>\n#include <linux/pagemap.h>\n#include <linux/writeback.h>\n#include <linux/pagevec.h>\n#include <linux/netfs.h>\n#include \"internal.h\"\n\nstatic int afs_writepages_region(struct address_space *mapping,\n\t\t\t\t struct writeback_control *wbc,\n\t\t\t\t loff_t start, loff_t end, loff_t *_next,\n\t\t\t\t bool max_one_loop);\n\nstatic void afs_write_to_cache(struct afs_vnode *vnode, loff_t start, size_t len,\n\t\t\t       loff_t i_size, bool caching);\n\n#ifdef CONFIG_AFS_FSCACHE\n \nbool afs_dirty_folio(struct address_space *mapping, struct folio *folio)\n{\n\treturn fscache_dirty_folio(mapping, folio,\n\t\t\t\tafs_vnode_cache(AFS_FS_I(mapping->host)));\n}\nstatic void afs_folio_start_fscache(bool caching, struct folio *folio)\n{\n\tif (caching)\n\t\tfolio_start_fscache(folio);\n}\n#else\nstatic void afs_folio_start_fscache(bool caching, struct folio *folio)\n{\n}\n#endif\n\n \nstatic int afs_flush_conflicting_write(struct address_space *mapping,\n\t\t\t\t       struct folio *folio)\n{\n\tstruct writeback_control wbc = {\n\t\t.sync_mode\t= WB_SYNC_ALL,\n\t\t.nr_to_write\t= LONG_MAX,\n\t\t.range_start\t= folio_pos(folio),\n\t\t.range_end\t= LLONG_MAX,\n\t};\n\tloff_t next;\n\n\treturn afs_writepages_region(mapping, &wbc, folio_pos(folio), LLONG_MAX,\n\t\t\t\t     &next, true);\n}\n\n \nint afs_write_begin(struct file *file, struct address_space *mapping,\n\t\t    loff_t pos, unsigned len,\n\t\t    struct page **_page, void **fsdata)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(file_inode(file));\n\tstruct folio *folio;\n\tunsigned long priv;\n\tunsigned f, from;\n\tunsigned t, to;\n\tpgoff_t index;\n\tint ret;\n\n\t_enter(\"{%llx:%llu},%llx,%x\",\n\t       vnode->fid.vid, vnode->fid.vnode, pos, len);\n\n\t \n\tret = netfs_write_begin(&vnode->netfs, file, mapping, pos, len, &folio, fsdata);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tindex = folio_index(folio);\n\tfrom = pos - index * PAGE_SIZE;\n\tto = from + len;\n\ntry_again:\n\t \n\tif (folio_test_private(folio)) {\n\t\tpriv = (unsigned long)folio_get_private(folio);\n\t\tf = afs_folio_dirty_from(folio, priv);\n\t\tt = afs_folio_dirty_to(folio, priv);\n\t\tASSERTCMP(f, <=, t);\n\n\t\tif (folio_test_writeback(folio)) {\n\t\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"alrdy\"), folio);\n\t\t\tfolio_unlock(folio);\n\t\t\tgoto wait_for_writeback;\n\t\t}\n\t\t \n\t\tif (!test_bit(AFS_VNODE_NEW_CONTENT, &vnode->flags) &&\n\t\t    (to < f || from > t))\n\t\t\tgoto flush_conflicting_write;\n\t}\n\n\t*_page = folio_file_page(folio, pos / PAGE_SIZE);\n\t_leave(\" = 0\");\n\treturn 0;\n\n\t \nflush_conflicting_write:\n\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"confl\"), folio);\n\tfolio_unlock(folio);\n\n\tret = afs_flush_conflicting_write(mapping, folio);\n\tif (ret < 0)\n\t\tgoto error;\n\nwait_for_writeback:\n\tret = folio_wait_writeback_killable(folio);\n\tif (ret < 0)\n\t\tgoto error;\n\n\tret = folio_lock_killable(folio);\n\tif (ret < 0)\n\t\tgoto error;\n\tgoto try_again;\n\nerror:\n\tfolio_put(folio);\n\t_leave(\" = %d\", ret);\n\treturn ret;\n}\n\n \nint afs_write_end(struct file *file, struct address_space *mapping,\n\t\t  loff_t pos, unsigned len, unsigned copied,\n\t\t  struct page *subpage, void *fsdata)\n{\n\tstruct folio *folio = page_folio(subpage);\n\tstruct afs_vnode *vnode = AFS_FS_I(file_inode(file));\n\tunsigned long priv;\n\tunsigned int f, from = offset_in_folio(folio, pos);\n\tunsigned int t, to = from + copied;\n\tloff_t i_size, write_end_pos;\n\n\t_enter(\"{%llx:%llu},{%lx}\",\n\t       vnode->fid.vid, vnode->fid.vnode, folio_index(folio));\n\n\tif (!folio_test_uptodate(folio)) {\n\t\tif (copied < len) {\n\t\t\tcopied = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\tfolio_mark_uptodate(folio);\n\t}\n\n\tif (copied == 0)\n\t\tgoto out;\n\n\twrite_end_pos = pos + copied;\n\n\ti_size = i_size_read(&vnode->netfs.inode);\n\tif (write_end_pos > i_size) {\n\t\twrite_seqlock(&vnode->cb_lock);\n\t\ti_size = i_size_read(&vnode->netfs.inode);\n\t\tif (write_end_pos > i_size)\n\t\t\tafs_set_i_size(vnode, write_end_pos);\n\t\twrite_sequnlock(&vnode->cb_lock);\n\t\tfscache_update_cookie(afs_vnode_cache(vnode), NULL, &write_end_pos);\n\t}\n\n\tif (folio_test_private(folio)) {\n\t\tpriv = (unsigned long)folio_get_private(folio);\n\t\tf = afs_folio_dirty_from(folio, priv);\n\t\tt = afs_folio_dirty_to(folio, priv);\n\t\tif (from < f)\n\t\t\tf = from;\n\t\tif (to > t)\n\t\t\tt = to;\n\t\tpriv = afs_folio_dirty(folio, f, t);\n\t\tfolio_change_private(folio, (void *)priv);\n\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"dirty+\"), folio);\n\t} else {\n\t\tpriv = afs_folio_dirty(folio, from, to);\n\t\tfolio_attach_private(folio, (void *)priv);\n\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"dirty\"), folio);\n\t}\n\n\tif (folio_mark_dirty(folio))\n\t\t_debug(\"dirtied %lx\", folio_index(folio));\n\nout:\n\tfolio_unlock(folio);\n\tfolio_put(folio);\n\treturn copied;\n}\n\n \nstatic void afs_kill_pages(struct address_space *mapping,\n\t\t\t   loff_t start, loff_t len)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(mapping->host);\n\tstruct folio *folio;\n\tpgoff_t index = start / PAGE_SIZE;\n\tpgoff_t last = (start + len - 1) / PAGE_SIZE, next;\n\n\t_enter(\"{%llx:%llu},%llx @%llx\",\n\t       vnode->fid.vid, vnode->fid.vnode, len, start);\n\n\tdo {\n\t\t_debug(\"kill %lx (to %lx)\", index, last);\n\n\t\tfolio = filemap_get_folio(mapping, index);\n\t\tif (IS_ERR(folio)) {\n\t\t\tnext = index + 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnext = folio_next_index(folio);\n\n\t\tfolio_clear_uptodate(folio);\n\t\tfolio_end_writeback(folio);\n\t\tfolio_lock(folio);\n\t\tgeneric_error_remove_page(mapping, &folio->page);\n\t\tfolio_unlock(folio);\n\t\tfolio_put(folio);\n\n\t} while (index = next, index <= last);\n\n\t_leave(\"\");\n}\n\n \nstatic void afs_redirty_pages(struct writeback_control *wbc,\n\t\t\t      struct address_space *mapping,\n\t\t\t      loff_t start, loff_t len)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(mapping->host);\n\tstruct folio *folio;\n\tpgoff_t index = start / PAGE_SIZE;\n\tpgoff_t last = (start + len - 1) / PAGE_SIZE, next;\n\n\t_enter(\"{%llx:%llu},%llx @%llx\",\n\t       vnode->fid.vid, vnode->fid.vnode, len, start);\n\n\tdo {\n\t\t_debug(\"redirty %llx @%llx\", len, start);\n\n\t\tfolio = filemap_get_folio(mapping, index);\n\t\tif (IS_ERR(folio)) {\n\t\t\tnext = index + 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnext = index + folio_nr_pages(folio);\n\t\tfolio_redirty_for_writepage(wbc, folio);\n\t\tfolio_end_writeback(folio);\n\t\tfolio_put(folio);\n\t} while (index = next, index <= last);\n\n\t_leave(\"\");\n}\n\n \nstatic void afs_pages_written_back(struct afs_vnode *vnode, loff_t start, unsigned int len)\n{\n\tstruct address_space *mapping = vnode->netfs.inode.i_mapping;\n\tstruct folio *folio;\n\tpgoff_t end;\n\n\tXA_STATE(xas, &mapping->i_pages, start / PAGE_SIZE);\n\n\t_enter(\"{%llx:%llu},{%x @%llx}\",\n\t       vnode->fid.vid, vnode->fid.vnode, len, start);\n\n\trcu_read_lock();\n\n\tend = (start + len - 1) / PAGE_SIZE;\n\txas_for_each(&xas, folio, end) {\n\t\tif (!folio_test_writeback(folio)) {\n\t\t\tkdebug(\"bad %x @%llx page %lx %lx\",\n\t\t\t       len, start, folio_index(folio), end);\n\t\t\tASSERT(folio_test_writeback(folio));\n\t\t}\n\n\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"clear\"), folio);\n\t\tfolio_detach_private(folio);\n\t\tfolio_end_writeback(folio);\n\t}\n\n\trcu_read_unlock();\n\n\tafs_prune_wb_keys(vnode);\n\t_leave(\"\");\n}\n\n \nstatic int afs_get_writeback_key(struct afs_vnode *vnode,\n\t\t\t\t struct afs_wb_key **_wbk)\n{\n\tstruct afs_wb_key *wbk = NULL;\n\tstruct list_head *p;\n\tint ret = -ENOKEY, ret2;\n\n\tspin_lock(&vnode->wb_lock);\n\tif (*_wbk)\n\t\tp = (*_wbk)->vnode_link.next;\n\telse\n\t\tp = vnode->wb_keys.next;\n\n\twhile (p != &vnode->wb_keys) {\n\t\twbk = list_entry(p, struct afs_wb_key, vnode_link);\n\t\t_debug(\"wbk %u\", key_serial(wbk->key));\n\t\tret2 = key_validate(wbk->key);\n\t\tif (ret2 == 0) {\n\t\t\trefcount_inc(&wbk->usage);\n\t\t\t_debug(\"USE WB KEY %u\", key_serial(wbk->key));\n\t\t\tbreak;\n\t\t}\n\n\t\twbk = NULL;\n\t\tif (ret == -ENOKEY)\n\t\t\tret = ret2;\n\t\tp = p->next;\n\t}\n\n\tspin_unlock(&vnode->wb_lock);\n\tif (*_wbk)\n\t\tafs_put_wb_key(*_wbk);\n\t*_wbk = wbk;\n\treturn 0;\n}\n\nstatic void afs_store_data_success(struct afs_operation *op)\n{\n\tstruct afs_vnode *vnode = op->file[0].vnode;\n\n\top->ctime = op->file[0].scb.status.mtime_client;\n\tafs_vnode_commit_status(op, &op->file[0]);\n\tif (op->error == 0) {\n\t\tif (!op->store.laundering)\n\t\t\tafs_pages_written_back(vnode, op->store.pos, op->store.size);\n\t\tafs_stat_v(vnode, n_stores);\n\t\tatomic_long_add(op->store.size, &afs_v2net(vnode)->n_store_bytes);\n\t}\n}\n\nstatic const struct afs_operation_ops afs_store_data_operation = {\n\t.issue_afs_rpc\t= afs_fs_store_data,\n\t.issue_yfs_rpc\t= yfs_fs_store_data,\n\t.success\t= afs_store_data_success,\n};\n\n \nstatic int afs_store_data(struct afs_vnode *vnode, struct iov_iter *iter, loff_t pos,\n\t\t\t  bool laundering)\n{\n\tstruct afs_operation *op;\n\tstruct afs_wb_key *wbk = NULL;\n\tloff_t size = iov_iter_count(iter);\n\tint ret = -ENOKEY;\n\n\t_enter(\"%s{%llx:%llu.%u},%llx,%llx\",\n\t       vnode->volume->name,\n\t       vnode->fid.vid,\n\t       vnode->fid.vnode,\n\t       vnode->fid.unique,\n\t       size, pos);\n\n\tret = afs_get_writeback_key(vnode, &wbk);\n\tif (ret) {\n\t\t_leave(\" = %d [no keys]\", ret);\n\t\treturn ret;\n\t}\n\n\top = afs_alloc_operation(wbk->key, vnode->volume);\n\tif (IS_ERR(op)) {\n\t\tafs_put_wb_key(wbk);\n\t\treturn -ENOMEM;\n\t}\n\n\tafs_op_set_vnode(op, 0, vnode);\n\top->file[0].dv_delta = 1;\n\top->file[0].modification = true;\n\top->store.pos = pos;\n\top->store.size = size;\n\top->store.laundering = laundering;\n\top->flags |= AFS_OPERATION_UNINTR;\n\top->ops = &afs_store_data_operation;\n\ntry_next_key:\n\tafs_begin_vnode_operation(op);\n\n\top->store.write_iter = iter;\n\top->store.i_size = max(pos + size, vnode->netfs.remote_i_size);\n\top->mtime = vnode->netfs.inode.i_mtime;\n\n\tafs_wait_for_operation(op);\n\n\tswitch (op->error) {\n\tcase -EACCES:\n\tcase -EPERM:\n\tcase -ENOKEY:\n\tcase -EKEYEXPIRED:\n\tcase -EKEYREJECTED:\n\tcase -EKEYREVOKED:\n\t\t_debug(\"next\");\n\n\t\tret = afs_get_writeback_key(vnode, &wbk);\n\t\tif (ret == 0) {\n\t\t\tkey_put(op->key);\n\t\t\top->key = key_get(wbk->key);\n\t\t\tgoto try_next_key;\n\t\t}\n\t\tbreak;\n\t}\n\n\tafs_put_wb_key(wbk);\n\t_leave(\" = %d\", op->error);\n\treturn afs_put_operation(op);\n}\n\n \nstatic void afs_extend_writeback(struct address_space *mapping,\n\t\t\t\t struct afs_vnode *vnode,\n\t\t\t\t long *_count,\n\t\t\t\t loff_t start,\n\t\t\t\t loff_t max_len,\n\t\t\t\t bool new_content,\n\t\t\t\t bool caching,\n\t\t\t\t unsigned int *_len)\n{\n\tstruct folio_batch fbatch;\n\tstruct folio *folio;\n\tunsigned long priv;\n\tunsigned int psize, filler = 0;\n\tunsigned int f, t;\n\tloff_t len = *_len;\n\tpgoff_t index = (start + len) / PAGE_SIZE;\n\tbool stop = true;\n\tunsigned int i;\n\n\tXA_STATE(xas, &mapping->i_pages, index);\n\tfolio_batch_init(&fbatch);\n\n\tdo {\n\t\t \n\t\trcu_read_lock();\n\n\t\txas_for_each(&xas, folio, ULONG_MAX) {\n\t\t\tstop = true;\n\t\t\tif (xas_retry(&xas, folio))\n\t\t\t\tcontinue;\n\t\t\tif (xa_is_value(folio))\n\t\t\t\tbreak;\n\t\t\tif (folio_index(folio) != index)\n\t\t\t\tbreak;\n\n\t\t\tif (!folio_try_get_rcu(folio)) {\n\t\t\t\txas_reset(&xas);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (unlikely(folio != xas_reload(&xas))) {\n\t\t\t\tfolio_put(folio);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (!folio_trylock(folio)) {\n\t\t\t\tfolio_put(folio);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!folio_test_dirty(folio) ||\n\t\t\t    folio_test_writeback(folio) ||\n\t\t\t    folio_test_fscache(folio)) {\n\t\t\t\tfolio_unlock(folio);\n\t\t\t\tfolio_put(folio);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tpsize = folio_size(folio);\n\t\t\tpriv = (unsigned long)folio_get_private(folio);\n\t\t\tf = afs_folio_dirty_from(folio, priv);\n\t\t\tt = afs_folio_dirty_to(folio, priv);\n\t\t\tif (f != 0 && !new_content) {\n\t\t\t\tfolio_unlock(folio);\n\t\t\t\tfolio_put(folio);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tlen += filler + t;\n\t\t\tfiller = psize - t;\n\t\t\tif (len >= max_len || *_count <= 0)\n\t\t\t\tstop = true;\n\t\t\telse if (t == psize || new_content)\n\t\t\t\tstop = false;\n\n\t\t\tindex += folio_nr_pages(folio);\n\t\t\tif (!folio_batch_add(&fbatch, folio))\n\t\t\t\tbreak;\n\t\t\tif (stop)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (!stop)\n\t\t\txas_pause(&xas);\n\t\trcu_read_unlock();\n\n\t\t \n\t\tif (!folio_batch_count(&fbatch))\n\t\t\tbreak;\n\n\t\tfor (i = 0; i < folio_batch_count(&fbatch); i++) {\n\t\t\tfolio = fbatch.folios[i];\n\t\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"store+\"), folio);\n\n\t\t\tif (!folio_clear_dirty_for_io(folio))\n\t\t\t\tBUG();\n\t\t\tif (folio_start_writeback(folio))\n\t\t\t\tBUG();\n\t\t\tafs_folio_start_fscache(caching, folio);\n\n\t\t\t*_count -= folio_nr_pages(folio);\n\t\t\tfolio_unlock(folio);\n\t\t}\n\n\t\tfolio_batch_release(&fbatch);\n\t\tcond_resched();\n\t} while (!stop);\n\n\t*_len = len;\n}\n\n \nstatic ssize_t afs_write_back_from_locked_folio(struct address_space *mapping,\n\t\t\t\t\t\tstruct writeback_control *wbc,\n\t\t\t\t\t\tstruct folio *folio,\n\t\t\t\t\t\tloff_t start, loff_t end)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(mapping->host);\n\tstruct iov_iter iter;\n\tunsigned long priv;\n\tunsigned int offset, to, len, max_len;\n\tloff_t i_size = i_size_read(&vnode->netfs.inode);\n\tbool new_content = test_bit(AFS_VNODE_NEW_CONTENT, &vnode->flags);\n\tbool caching = fscache_cookie_enabled(afs_vnode_cache(vnode));\n\tlong count = wbc->nr_to_write;\n\tint ret;\n\n\t_enter(\",%lx,%llx-%llx\", folio_index(folio), start, end);\n\n\tif (folio_start_writeback(folio))\n\t\tBUG();\n\tafs_folio_start_fscache(caching, folio);\n\n\tcount -= folio_nr_pages(folio);\n\n\t \n\tpriv = (unsigned long)folio_get_private(folio);\n\toffset = afs_folio_dirty_from(folio, priv);\n\tto = afs_folio_dirty_to(folio, priv);\n\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"store\"), folio);\n\n\tlen = to - offset;\n\tstart += offset;\n\tif (start < i_size) {\n\t\t \n\t\tmax_len = 65536 * 4096;\n\t\tmax_len = min_t(unsigned long long, max_len, end - start + 1);\n\t\tmax_len = min_t(unsigned long long, max_len, i_size - start);\n\n\t\tif (len < max_len &&\n\t\t    (to == folio_size(folio) || new_content))\n\t\t\tafs_extend_writeback(mapping, vnode, &count,\n\t\t\t\t\t     start, max_len, new_content,\n\t\t\t\t\t     caching, &len);\n\t\tlen = min_t(loff_t, len, max_len);\n\t}\n\n\t \n\tfolio_unlock(folio);\n\n\tif (start < i_size) {\n\t\t_debug(\"write back %x @%llx [%llx]\", len, start, i_size);\n\n\t\t \n\t\tafs_write_to_cache(vnode, start, len, i_size, caching);\n\n\t\tiov_iter_xarray(&iter, ITER_SOURCE, &mapping->i_pages, start, len);\n\t\tret = afs_store_data(vnode, &iter, start, false);\n\t} else {\n\t\t_debug(\"write discard %x @%llx [%llx]\", len, start, i_size);\n\n\t\t \n\t\tfscache_clear_page_bits(mapping, start, len, caching);\n\t\tafs_pages_written_back(vnode, start, len);\n\t\tret = 0;\n\t}\n\n\tswitch (ret) {\n\tcase 0:\n\t\twbc->nr_to_write = count;\n\t\tret = len;\n\t\tbreak;\n\n\tdefault:\n\t\tpr_notice(\"kAFS: Unexpected error from FS.StoreData %d\\n\", ret);\n\t\tfallthrough;\n\tcase -EACCES:\n\tcase -EPERM:\n\tcase -ENOKEY:\n\tcase -EKEYEXPIRED:\n\tcase -EKEYREJECTED:\n\tcase -EKEYREVOKED:\n\tcase -ENETRESET:\n\t\tafs_redirty_pages(wbc, mapping, start, len);\n\t\tmapping_set_error(mapping, ret);\n\t\tbreak;\n\n\tcase -EDQUOT:\n\tcase -ENOSPC:\n\t\tafs_redirty_pages(wbc, mapping, start, len);\n\t\tmapping_set_error(mapping, -ENOSPC);\n\t\tbreak;\n\n\tcase -EROFS:\n\tcase -EIO:\n\tcase -EREMOTEIO:\n\tcase -EFBIG:\n\tcase -ENOENT:\n\tcase -ENOMEDIUM:\n\tcase -ENXIO:\n\t\ttrace_afs_file_error(vnode, ret, afs_file_error_writeback_fail);\n\t\tafs_kill_pages(mapping, start, len);\n\t\tmapping_set_error(mapping, ret);\n\t\tbreak;\n\t}\n\n\t_leave(\" = %d\", ret);\n\treturn ret;\n}\n\n \nstatic int afs_writepages_region(struct address_space *mapping,\n\t\t\t\t struct writeback_control *wbc,\n\t\t\t\t loff_t start, loff_t end, loff_t *_next,\n\t\t\t\t bool max_one_loop)\n{\n\tstruct folio *folio;\n\tstruct folio_batch fbatch;\n\tssize_t ret;\n\tunsigned int i;\n\tint n, skips = 0;\n\n\t_enter(\"%llx,%llx,\", start, end);\n\tfolio_batch_init(&fbatch);\n\n\tdo {\n\t\tpgoff_t index = start / PAGE_SIZE;\n\n\t\tn = filemap_get_folios_tag(mapping, &index, end / PAGE_SIZE,\n\t\t\t\t\tPAGECACHE_TAG_DIRTY, &fbatch);\n\n\t\tif (!n)\n\t\t\tbreak;\n\t\tfor (i = 0; i < n; i++) {\n\t\t\tfolio = fbatch.folios[i];\n\t\t\tstart = folio_pos(folio);  \n\n\t\t\t_debug(\"wback %lx\", folio_index(folio));\n\n\t\t\t \ntry_again:\n\t\t\tif (wbc->sync_mode != WB_SYNC_NONE) {\n\t\t\t\tret = folio_lock_killable(folio);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tfolio_batch_release(&fbatch);\n\t\t\t\t\treturn ret;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (!folio_trylock(folio))\n\t\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (folio->mapping != mapping ||\n\t\t\t    !folio_test_dirty(folio)) {\n\t\t\t\tstart += folio_size(folio);\n\t\t\t\tfolio_unlock(folio);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (folio_test_writeback(folio) ||\n\t\t\t    folio_test_fscache(folio)) {\n\t\t\t\tfolio_unlock(folio);\n\t\t\t\tif (wbc->sync_mode != WB_SYNC_NONE) {\n\t\t\t\t\tfolio_wait_writeback(folio);\n#ifdef CONFIG_AFS_FSCACHE\n\t\t\t\t\tfolio_wait_fscache(folio);\n#endif\n\t\t\t\t\tgoto try_again;\n\t\t\t\t}\n\n\t\t\t\tstart += folio_size(folio);\n\t\t\t\tif (wbc->sync_mode == WB_SYNC_NONE) {\n\t\t\t\t\tif (skips >= 5 || need_resched()) {\n\t\t\t\t\t\t*_next = start;\n\t\t\t\t\t\tfolio_batch_release(&fbatch);\n\t\t\t\t\t\t_leave(\" = 0 [%llx]\", *_next);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\tskips++;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!folio_clear_dirty_for_io(folio))\n\t\t\t\tBUG();\n\t\t\tret = afs_write_back_from_locked_folio(mapping, wbc,\n\t\t\t\t\tfolio, start, end);\n\t\t\tif (ret < 0) {\n\t\t\t\t_leave(\" = %zd\", ret);\n\t\t\t\tfolio_batch_release(&fbatch);\n\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tstart += ret;\n\t\t}\n\n\t\tfolio_batch_release(&fbatch);\n\t\tcond_resched();\n\t} while (wbc->nr_to_write > 0);\n\n\t*_next = start;\n\t_leave(\" = 0 [%llx]\", *_next);\n\treturn 0;\n}\n\n \nint afs_writepages(struct address_space *mapping,\n\t\t   struct writeback_control *wbc)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(mapping->host);\n\tloff_t start, next;\n\tint ret;\n\n\t_enter(\"\");\n\n\t \n\tif (wbc->sync_mode == WB_SYNC_ALL)\n\t\tdown_read(&vnode->validate_lock);\n\telse if (!down_read_trylock(&vnode->validate_lock))\n\t\treturn 0;\n\n\tif (wbc->range_cyclic) {\n\t\tstart = mapping->writeback_index * PAGE_SIZE;\n\t\tret = afs_writepages_region(mapping, wbc, start, LLONG_MAX,\n\t\t\t\t\t    &next, false);\n\t\tif (ret == 0) {\n\t\t\tmapping->writeback_index = next / PAGE_SIZE;\n\t\t\tif (start > 0 && wbc->nr_to_write > 0) {\n\t\t\t\tret = afs_writepages_region(mapping, wbc, 0,\n\t\t\t\t\t\t\t    start, &next, false);\n\t\t\t\tif (ret == 0)\n\t\t\t\t\tmapping->writeback_index =\n\t\t\t\t\t\tnext / PAGE_SIZE;\n\t\t\t}\n\t\t}\n\t} else if (wbc->range_start == 0 && wbc->range_end == LLONG_MAX) {\n\t\tret = afs_writepages_region(mapping, wbc, 0, LLONG_MAX,\n\t\t\t\t\t    &next, false);\n\t\tif (wbc->nr_to_write > 0 && ret == 0)\n\t\t\tmapping->writeback_index = next / PAGE_SIZE;\n\t} else {\n\t\tret = afs_writepages_region(mapping, wbc,\n\t\t\t\t\t    wbc->range_start, wbc->range_end,\n\t\t\t\t\t    &next, false);\n\t}\n\n\tup_read(&vnode->validate_lock);\n\t_leave(\" = %d\", ret);\n\treturn ret;\n}\n\n \nssize_t afs_file_write(struct kiocb *iocb, struct iov_iter *from)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(file_inode(iocb->ki_filp));\n\tstruct afs_file *af = iocb->ki_filp->private_data;\n\tssize_t result;\n\tsize_t count = iov_iter_count(from);\n\n\t_enter(\"{%llx:%llu},{%zu},\",\n\t       vnode->fid.vid, vnode->fid.vnode, count);\n\n\tif (IS_SWAPFILE(&vnode->netfs.inode)) {\n\t\tprintk(KERN_INFO\n\t\t       \"AFS: Attempt to write to active swap file!\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\tif (!count)\n\t\treturn 0;\n\n\tresult = afs_validate(vnode, af->key);\n\tif (result < 0)\n\t\treturn result;\n\n\tresult = generic_file_write_iter(iocb, from);\n\n\t_leave(\" = %zd\", result);\n\treturn result;\n}\n\n \nint afs_fsync(struct file *file, loff_t start, loff_t end, int datasync)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(file_inode(file));\n\tstruct afs_file *af = file->private_data;\n\tint ret;\n\n\t_enter(\"{%llx:%llu},{n=%pD},%d\",\n\t       vnode->fid.vid, vnode->fid.vnode, file,\n\t       datasync);\n\n\tret = afs_validate(vnode, af->key);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn file_write_and_wait_range(file, start, end);\n}\n\n \nvm_fault_t afs_page_mkwrite(struct vm_fault *vmf)\n{\n\tstruct folio *folio = page_folio(vmf->page);\n\tstruct file *file = vmf->vma->vm_file;\n\tstruct inode *inode = file_inode(file);\n\tstruct afs_vnode *vnode = AFS_FS_I(inode);\n\tstruct afs_file *af = file->private_data;\n\tunsigned long priv;\n\tvm_fault_t ret = VM_FAULT_RETRY;\n\n\t_enter(\"{{%llx:%llu}},{%lx}\", vnode->fid.vid, vnode->fid.vnode, folio_index(folio));\n\n\tafs_validate(vnode, af->key);\n\n\tsb_start_pagefault(inode->i_sb);\n\n\t \n#ifdef CONFIG_AFS_FSCACHE\n\tif (folio_test_fscache(folio) &&\n\t    folio_wait_fscache_killable(folio) < 0)\n\t\tgoto out;\n#endif\n\n\tif (folio_wait_writeback_killable(folio))\n\t\tgoto out;\n\n\tif (folio_lock_killable(folio) < 0)\n\t\tgoto out;\n\n\t \n\tif (folio_wait_writeback_killable(folio) < 0) {\n\t\tfolio_unlock(folio);\n\t\tgoto out;\n\t}\n\n\tpriv = afs_folio_dirty(folio, 0, folio_size(folio));\n\tpriv = afs_folio_dirty_mmapped(priv);\n\tif (folio_test_private(folio)) {\n\t\tfolio_change_private(folio, (void *)priv);\n\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"mkwrite+\"), folio);\n\t} else {\n\t\tfolio_attach_private(folio, (void *)priv);\n\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"mkwrite\"), folio);\n\t}\n\tfile_update_time(file);\n\n\tret = VM_FAULT_LOCKED;\nout:\n\tsb_end_pagefault(inode->i_sb);\n\treturn ret;\n}\n\n \nvoid afs_prune_wb_keys(struct afs_vnode *vnode)\n{\n\tLIST_HEAD(graveyard);\n\tstruct afs_wb_key *wbk, *tmp;\n\n\t \n\tspin_lock(&vnode->wb_lock);\n\n\tif (!mapping_tagged(&vnode->netfs.inode.i_data, PAGECACHE_TAG_WRITEBACK) &&\n\t    !mapping_tagged(&vnode->netfs.inode.i_data, PAGECACHE_TAG_DIRTY)) {\n\t\tlist_for_each_entry_safe(wbk, tmp, &vnode->wb_keys, vnode_link) {\n\t\t\tif (refcount_read(&wbk->usage) == 1)\n\t\t\t\tlist_move(&wbk->vnode_link, &graveyard);\n\t\t}\n\t}\n\n\tspin_unlock(&vnode->wb_lock);\n\n\twhile (!list_empty(&graveyard)) {\n\t\twbk = list_entry(graveyard.next, struct afs_wb_key, vnode_link);\n\t\tlist_del(&wbk->vnode_link);\n\t\tafs_put_wb_key(wbk);\n\t}\n}\n\n \nint afs_launder_folio(struct folio *folio)\n{\n\tstruct afs_vnode *vnode = AFS_FS_I(folio_inode(folio));\n\tstruct iov_iter iter;\n\tstruct bio_vec bv;\n\tunsigned long priv;\n\tunsigned int f, t;\n\tint ret = 0;\n\n\t_enter(\"{%lx}\", folio->index);\n\n\tpriv = (unsigned long)folio_get_private(folio);\n\tif (folio_clear_dirty_for_io(folio)) {\n\t\tf = 0;\n\t\tt = folio_size(folio);\n\t\tif (folio_test_private(folio)) {\n\t\t\tf = afs_folio_dirty_from(folio, priv);\n\t\t\tt = afs_folio_dirty_to(folio, priv);\n\t\t}\n\n\t\tbvec_set_folio(&bv, folio, t - f, f);\n\t\tiov_iter_bvec(&iter, ITER_SOURCE, &bv, 1, bv.bv_len);\n\n\t\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"launder\"), folio);\n\t\tret = afs_store_data(vnode, &iter, folio_pos(folio) + f, true);\n\t}\n\n\ttrace_afs_folio_dirty(vnode, tracepoint_string(\"laundered\"), folio);\n\tfolio_detach_private(folio);\n\tfolio_wait_fscache(folio);\n\treturn ret;\n}\n\n \nstatic void afs_write_to_cache_done(void *priv, ssize_t transferred_or_error,\n\t\t\t\t    bool was_async)\n{\n\tstruct afs_vnode *vnode = priv;\n\n\tif (IS_ERR_VALUE(transferred_or_error) &&\n\t    transferred_or_error != -ENOBUFS)\n\t\tafs_invalidate_cache(vnode, 0);\n}\n\n \nstatic void afs_write_to_cache(struct afs_vnode *vnode,\n\t\t\t       loff_t start, size_t len, loff_t i_size,\n\t\t\t       bool caching)\n{\n\tfscache_write_to_cache(afs_vnode_cache(vnode),\n\t\t\t       vnode->netfs.inode.i_mapping, start, len, i_size,\n\t\t\t       afs_write_to_cache_done, vnode, caching);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}