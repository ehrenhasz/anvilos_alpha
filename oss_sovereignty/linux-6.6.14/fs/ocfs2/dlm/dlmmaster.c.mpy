{
  "module_name": "dlmmaster.c",
  "hash_id": "b3916010c366a6dd37571acf734e9730ed8677efae62b793b949484cbca788fa",
  "original_prompt": "Ingested from linux-6.6.14/fs/ocfs2/dlm/dlmmaster.c",
  "human_readable_source": "\n \n\n\n#include <linux/module.h>\n#include <linux/fs.h>\n#include <linux/types.h>\n#include <linux/slab.h>\n#include <linux/highmem.h>\n#include <linux/init.h>\n#include <linux/sysctl.h>\n#include <linux/random.h>\n#include <linux/blkdev.h>\n#include <linux/socket.h>\n#include <linux/inet.h>\n#include <linux/spinlock.h>\n#include <linux/delay.h>\n\n\n#include \"../cluster/heartbeat.h\"\n#include \"../cluster/nodemanager.h\"\n#include \"../cluster/tcp.h\"\n\n#include \"dlmapi.h\"\n#include \"dlmcommon.h\"\n#include \"dlmdomain.h\"\n#include \"dlmdebug.h\"\n\n#define MLOG_MASK_PREFIX (ML_DLM|ML_DLM_MASTER)\n#include \"../cluster/masklog.h\"\n\nstatic void dlm_mle_node_down(struct dlm_ctxt *dlm,\n\t\t\t      struct dlm_master_list_entry *mle,\n\t\t\t      struct o2nm_node *node,\n\t\t\t      int idx);\nstatic void dlm_mle_node_up(struct dlm_ctxt *dlm,\n\t\t\t    struct dlm_master_list_entry *mle,\n\t\t\t    struct o2nm_node *node,\n\t\t\t    int idx);\n\nstatic void dlm_assert_master_worker(struct dlm_work_item *item, void *data);\nstatic int dlm_do_assert_master(struct dlm_ctxt *dlm,\n\t\t\t\tstruct dlm_lock_resource *res,\n\t\t\t\tvoid *nodemap, u32 flags);\nstatic void dlm_deref_lockres_worker(struct dlm_work_item *item, void *data);\n\nstatic inline int dlm_mle_equal(struct dlm_ctxt *dlm,\n\t\t\t\tstruct dlm_master_list_entry *mle,\n\t\t\t\tconst char *name,\n\t\t\t\tunsigned int namelen)\n{\n\tif (dlm != mle->dlm)\n\t\treturn 0;\n\n\tif (namelen != mle->mnamelen ||\n\t    memcmp(name, mle->mname, namelen) != 0)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic struct kmem_cache *dlm_lockres_cache;\nstatic struct kmem_cache *dlm_lockname_cache;\nstatic struct kmem_cache *dlm_mle_cache;\n\nstatic void dlm_mle_release(struct kref *kref);\nstatic void dlm_init_mle(struct dlm_master_list_entry *mle,\n\t\t\tenum dlm_mle_type type,\n\t\t\tstruct dlm_ctxt *dlm,\n\t\t\tstruct dlm_lock_resource *res,\n\t\t\tconst char *name,\n\t\t\tunsigned int namelen);\nstatic void dlm_put_mle(struct dlm_master_list_entry *mle);\nstatic void __dlm_put_mle(struct dlm_master_list_entry *mle);\nstatic int dlm_find_mle(struct dlm_ctxt *dlm,\n\t\t\tstruct dlm_master_list_entry **mle,\n\t\t\tchar *name, unsigned int namelen);\n\nstatic int dlm_do_master_request(struct dlm_lock_resource *res,\n\t\t\t\t struct dlm_master_list_entry *mle, int to);\n\n\nstatic int dlm_wait_for_lock_mastery(struct dlm_ctxt *dlm,\n\t\t\t\t     struct dlm_lock_resource *res,\n\t\t\t\t     struct dlm_master_list_entry *mle,\n\t\t\t\t     int *blocked);\nstatic int dlm_restart_lock_mastery(struct dlm_ctxt *dlm,\n\t\t\t\t    struct dlm_lock_resource *res,\n\t\t\t\t    struct dlm_master_list_entry *mle,\n\t\t\t\t    int blocked);\nstatic int dlm_add_migration_mle(struct dlm_ctxt *dlm,\n\t\t\t\t struct dlm_lock_resource *res,\n\t\t\t\t struct dlm_master_list_entry *mle,\n\t\t\t\t struct dlm_master_list_entry **oldmle,\n\t\t\t\t const char *name, unsigned int namelen,\n\t\t\t\t u8 new_master, u8 master);\n\nstatic u8 dlm_pick_migration_target(struct dlm_ctxt *dlm,\n\t\t\t\t    struct dlm_lock_resource *res);\nstatic void dlm_remove_nonlocal_locks(struct dlm_ctxt *dlm,\n\t\t\t\t      struct dlm_lock_resource *res);\nstatic int dlm_mark_lockres_migrating(struct dlm_ctxt *dlm,\n\t\t\t\t       struct dlm_lock_resource *res,\n\t\t\t\t       u8 target);\nstatic int dlm_pre_master_reco_lockres(struct dlm_ctxt *dlm,\n\t\t\t\t       struct dlm_lock_resource *res);\n\n\nint dlm_is_host_down(int errno)\n{\n\tswitch (errno) {\n\t\tcase -EBADF:\n\t\tcase -ECONNREFUSED:\n\t\tcase -ENOTCONN:\n\t\tcase -ECONNRESET:\n\t\tcase -EPIPE:\n\t\tcase -EHOSTDOWN:\n\t\tcase -EHOSTUNREACH:\n\t\tcase -ETIMEDOUT:\n\t\tcase -ECONNABORTED:\n\t\tcase -ENETDOWN:\n\t\tcase -ENETUNREACH:\n\t\tcase -ENETRESET:\n\t\tcase -ESHUTDOWN:\n\t\tcase -ENOPROTOOPT:\n\t\tcase -EINVAL:    \n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n\n \n\n\n \nstatic inline void __dlm_mle_attach_hb_events(struct dlm_ctxt *dlm,\n\t\t\t\t\t      struct dlm_master_list_entry *mle)\n{\n\tassert_spin_locked(&dlm->spinlock);\n\n\tlist_add_tail(&mle->hb_events, &dlm->mle_hb_events);\n}\n\n\nstatic inline void __dlm_mle_detach_hb_events(struct dlm_ctxt *dlm,\n\t\t\t\t\t      struct dlm_master_list_entry *mle)\n{\n\tif (!list_empty(&mle->hb_events))\n\t\tlist_del_init(&mle->hb_events);\n}\n\n\nstatic inline void dlm_mle_detach_hb_events(struct dlm_ctxt *dlm,\n\t\t\t\t\t    struct dlm_master_list_entry *mle)\n{\n\tspin_lock(&dlm->spinlock);\n\t__dlm_mle_detach_hb_events(dlm, mle);\n\tspin_unlock(&dlm->spinlock);\n}\n\nstatic void dlm_get_mle_inuse(struct dlm_master_list_entry *mle)\n{\n\tstruct dlm_ctxt *dlm;\n\tdlm = mle->dlm;\n\n\tassert_spin_locked(&dlm->spinlock);\n\tassert_spin_locked(&dlm->master_lock);\n\tmle->inuse++;\n\tkref_get(&mle->mle_refs);\n}\n\nstatic void dlm_put_mle_inuse(struct dlm_master_list_entry *mle)\n{\n\tstruct dlm_ctxt *dlm;\n\tdlm = mle->dlm;\n\n\tspin_lock(&dlm->spinlock);\n\tspin_lock(&dlm->master_lock);\n\tmle->inuse--;\n\t__dlm_put_mle(mle);\n\tspin_unlock(&dlm->master_lock);\n\tspin_unlock(&dlm->spinlock);\n\n}\n\n \nstatic void __dlm_put_mle(struct dlm_master_list_entry *mle)\n{\n\tstruct dlm_ctxt *dlm;\n\tdlm = mle->dlm;\n\n\tassert_spin_locked(&dlm->spinlock);\n\tassert_spin_locked(&dlm->master_lock);\n\tif (!kref_read(&mle->mle_refs)) {\n\t\t \n\t\tmlog(ML_ERROR, \"bad mle: %p\\n\", mle);\n\t\tdlm_print_one_mle(mle);\n\t\tBUG();\n\t} else\n\t\tkref_put(&mle->mle_refs, dlm_mle_release);\n}\n\n\n \nstatic void dlm_put_mle(struct dlm_master_list_entry *mle)\n{\n\tstruct dlm_ctxt *dlm;\n\tdlm = mle->dlm;\n\n\tspin_lock(&dlm->spinlock);\n\tspin_lock(&dlm->master_lock);\n\t__dlm_put_mle(mle);\n\tspin_unlock(&dlm->master_lock);\n\tspin_unlock(&dlm->spinlock);\n}\n\nstatic inline void dlm_get_mle(struct dlm_master_list_entry *mle)\n{\n\tkref_get(&mle->mle_refs);\n}\n\nstatic void dlm_init_mle(struct dlm_master_list_entry *mle,\n\t\t\tenum dlm_mle_type type,\n\t\t\tstruct dlm_ctxt *dlm,\n\t\t\tstruct dlm_lock_resource *res,\n\t\t\tconst char *name,\n\t\t\tunsigned int namelen)\n{\n\tassert_spin_locked(&dlm->spinlock);\n\n\tmle->dlm = dlm;\n\tmle->type = type;\n\tINIT_HLIST_NODE(&mle->master_hash_node);\n\tINIT_LIST_HEAD(&mle->hb_events);\n\tbitmap_zero(mle->maybe_map, O2NM_MAX_NODES);\n\tspin_lock_init(&mle->spinlock);\n\tinit_waitqueue_head(&mle->wq);\n\tatomic_set(&mle->woken, 0);\n\tkref_init(&mle->mle_refs);\n\tbitmap_zero(mle->response_map, O2NM_MAX_NODES);\n\tmle->master = O2NM_MAX_NODES;\n\tmle->new_master = O2NM_MAX_NODES;\n\tmle->inuse = 0;\n\n\tBUG_ON(mle->type != DLM_MLE_BLOCK &&\n\t       mle->type != DLM_MLE_MASTER &&\n\t       mle->type != DLM_MLE_MIGRATION);\n\n\tif (mle->type == DLM_MLE_MASTER) {\n\t\tBUG_ON(!res);\n\t\tmle->mleres = res;\n\t\tmemcpy(mle->mname, res->lockname.name, res->lockname.len);\n\t\tmle->mnamelen = res->lockname.len;\n\t\tmle->mnamehash = res->lockname.hash;\n\t} else {\n\t\tBUG_ON(!name);\n\t\tmle->mleres = NULL;\n\t\tmemcpy(mle->mname, name, namelen);\n\t\tmle->mnamelen = namelen;\n\t\tmle->mnamehash = dlm_lockid_hash(name, namelen);\n\t}\n\n\tatomic_inc(&dlm->mle_tot_count[mle->type]);\n\tatomic_inc(&dlm->mle_cur_count[mle->type]);\n\n\t \n\tbitmap_copy(mle->node_map, dlm->domain_map, O2NM_MAX_NODES);\n\tbitmap_copy(mle->vote_map, dlm->domain_map, O2NM_MAX_NODES);\n\tclear_bit(dlm->node_num, mle->vote_map);\n\tclear_bit(dlm->node_num, mle->node_map);\n\n\t \n\t__dlm_mle_attach_hb_events(dlm, mle);\n}\n\nvoid __dlm_unlink_mle(struct dlm_ctxt *dlm, struct dlm_master_list_entry *mle)\n{\n\tassert_spin_locked(&dlm->spinlock);\n\tassert_spin_locked(&dlm->master_lock);\n\n\tif (!hlist_unhashed(&mle->master_hash_node))\n\t\thlist_del_init(&mle->master_hash_node);\n}\n\nvoid __dlm_insert_mle(struct dlm_ctxt *dlm, struct dlm_master_list_entry *mle)\n{\n\tstruct hlist_head *bucket;\n\n\tassert_spin_locked(&dlm->master_lock);\n\n\tbucket = dlm_master_hash(dlm, mle->mnamehash);\n\thlist_add_head(&mle->master_hash_node, bucket);\n}\n\n \nstatic int dlm_find_mle(struct dlm_ctxt *dlm,\n\t\t\tstruct dlm_master_list_entry **mle,\n\t\t\tchar *name, unsigned int namelen)\n{\n\tstruct dlm_master_list_entry *tmpmle;\n\tstruct hlist_head *bucket;\n\tunsigned int hash;\n\n\tassert_spin_locked(&dlm->master_lock);\n\n\thash = dlm_lockid_hash(name, namelen);\n\tbucket = dlm_master_hash(dlm, hash);\n\thlist_for_each_entry(tmpmle, bucket, master_hash_node) {\n\t\tif (!dlm_mle_equal(dlm, tmpmle, name, namelen))\n\t\t\tcontinue;\n\t\tdlm_get_mle(tmpmle);\n\t\t*mle = tmpmle;\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nvoid dlm_hb_event_notify_attached(struct dlm_ctxt *dlm, int idx, int node_up)\n{\n\tstruct dlm_master_list_entry *mle;\n\n\tassert_spin_locked(&dlm->spinlock);\n\n\tlist_for_each_entry(mle, &dlm->mle_hb_events, hb_events) {\n\t\tif (node_up)\n\t\t\tdlm_mle_node_up(dlm, mle, NULL, idx);\n\t\telse\n\t\t\tdlm_mle_node_down(dlm, mle, NULL, idx);\n\t}\n}\n\nstatic void dlm_mle_node_down(struct dlm_ctxt *dlm,\n\t\t\t      struct dlm_master_list_entry *mle,\n\t\t\t      struct o2nm_node *node, int idx)\n{\n\tspin_lock(&mle->spinlock);\n\n\tif (!test_bit(idx, mle->node_map))\n\t\tmlog(0, \"node %u already removed from nodemap!\\n\", idx);\n\telse\n\t\tclear_bit(idx, mle->node_map);\n\n\tspin_unlock(&mle->spinlock);\n}\n\nstatic void dlm_mle_node_up(struct dlm_ctxt *dlm,\n\t\t\t    struct dlm_master_list_entry *mle,\n\t\t\t    struct o2nm_node *node, int idx)\n{\n\tspin_lock(&mle->spinlock);\n\n\tif (test_bit(idx, mle->node_map))\n\t\tmlog(0, \"node %u already in node map!\\n\", idx);\n\telse\n\t\tset_bit(idx, mle->node_map);\n\n\tspin_unlock(&mle->spinlock);\n}\n\n\nint dlm_init_mle_cache(void)\n{\n\tdlm_mle_cache = kmem_cache_create(\"o2dlm_mle\",\n\t\t\t\t\t  sizeof(struct dlm_master_list_entry),\n\t\t\t\t\t  0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t  NULL);\n\tif (dlm_mle_cache == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid dlm_destroy_mle_cache(void)\n{\n\tkmem_cache_destroy(dlm_mle_cache);\n}\n\nstatic void dlm_mle_release(struct kref *kref)\n{\n\tstruct dlm_master_list_entry *mle;\n\tstruct dlm_ctxt *dlm;\n\n\tmle = container_of(kref, struct dlm_master_list_entry, mle_refs);\n\tdlm = mle->dlm;\n\n\tassert_spin_locked(&dlm->spinlock);\n\tassert_spin_locked(&dlm->master_lock);\n\n\tmlog(0, \"Releasing mle for %.*s, type %d\\n\", mle->mnamelen, mle->mname,\n\t     mle->type);\n\n\t \n\t__dlm_unlink_mle(dlm, mle);\n\n\t \n\t__dlm_mle_detach_hb_events(dlm, mle);\n\n\tatomic_dec(&dlm->mle_cur_count[mle->type]);\n\n\t \n\tkmem_cache_free(dlm_mle_cache, mle);\n}\n\n\n \n\nint dlm_init_master_caches(void)\n{\n\tdlm_lockres_cache = kmem_cache_create(\"o2dlm_lockres\",\n\t\t\t\t\t      sizeof(struct dlm_lock_resource),\n\t\t\t\t\t      0, SLAB_HWCACHE_ALIGN, NULL);\n\tif (!dlm_lockres_cache)\n\t\tgoto bail;\n\n\tdlm_lockname_cache = kmem_cache_create(\"o2dlm_lockname\",\n\t\t\t\t\t       DLM_LOCKID_NAME_MAX, 0,\n\t\t\t\t\t       SLAB_HWCACHE_ALIGN, NULL);\n\tif (!dlm_lockname_cache)\n\t\tgoto bail;\n\n\treturn 0;\nbail:\n\tdlm_destroy_master_caches();\n\treturn -ENOMEM;\n}\n\nvoid dlm_destroy_master_caches(void)\n{\n\tkmem_cache_destroy(dlm_lockname_cache);\n\tdlm_lockname_cache = NULL;\n\n\tkmem_cache_destroy(dlm_lockres_cache);\n\tdlm_lockres_cache = NULL;\n}\n\nstatic void dlm_lockres_release(struct kref *kref)\n{\n\tstruct dlm_lock_resource *res;\n\tstruct dlm_ctxt *dlm;\n\n\tres = container_of(kref, struct dlm_lock_resource, refs);\n\tdlm = res->dlm;\n\n\t \n\tBUG_ON(!res->lockname.name);\n\n\tmlog(0, \"destroying lockres %.*s\\n\", res->lockname.len,\n\t     res->lockname.name);\n\n\tatomic_dec(&dlm->res_cur_count);\n\n\tif (!hlist_unhashed(&res->hash_node) ||\n\t    !list_empty(&res->granted) ||\n\t    !list_empty(&res->converting) ||\n\t    !list_empty(&res->blocked) ||\n\t    !list_empty(&res->dirty) ||\n\t    !list_empty(&res->recovering) ||\n\t    !list_empty(&res->purge)) {\n\t\tmlog(ML_ERROR,\n\t\t     \"Going to BUG for resource %.*s.\"\n\t\t     \"  We're on a list! [%c%c%c%c%c%c%c]\\n\",\n\t\t     res->lockname.len, res->lockname.name,\n\t\t     !hlist_unhashed(&res->hash_node) ? 'H' : ' ',\n\t\t     !list_empty(&res->granted) ? 'G' : ' ',\n\t\t     !list_empty(&res->converting) ? 'C' : ' ',\n\t\t     !list_empty(&res->blocked) ? 'B' : ' ',\n\t\t     !list_empty(&res->dirty) ? 'D' : ' ',\n\t\t     !list_empty(&res->recovering) ? 'R' : ' ',\n\t\t     !list_empty(&res->purge) ? 'P' : ' ');\n\n\t\tdlm_print_one_lock_resource(res);\n\t}\n\n\t \n\tBUG_ON(!hlist_unhashed(&res->hash_node));\n\tBUG_ON(!list_empty(&res->granted));\n\tBUG_ON(!list_empty(&res->converting));\n\tBUG_ON(!list_empty(&res->blocked));\n\tBUG_ON(!list_empty(&res->dirty));\n\tBUG_ON(!list_empty(&res->recovering));\n\tBUG_ON(!list_empty(&res->purge));\n\n\tkmem_cache_free(dlm_lockname_cache, (void *)res->lockname.name);\n\n\tkmem_cache_free(dlm_lockres_cache, res);\n}\n\nvoid dlm_lockres_put(struct dlm_lock_resource *res)\n{\n\tkref_put(&res->refs, dlm_lockres_release);\n}\n\nstatic void dlm_init_lockres(struct dlm_ctxt *dlm,\n\t\t\t     struct dlm_lock_resource *res,\n\t\t\t     const char *name, unsigned int namelen)\n{\n\tchar *qname;\n\n\t \n\n\tqname = (char *) res->lockname.name;\n\tmemcpy(qname, name, namelen);\n\n\tres->lockname.len = namelen;\n\tres->lockname.hash = dlm_lockid_hash(name, namelen);\n\n\tinit_waitqueue_head(&res->wq);\n\tspin_lock_init(&res->spinlock);\n\tINIT_HLIST_NODE(&res->hash_node);\n\tINIT_LIST_HEAD(&res->granted);\n\tINIT_LIST_HEAD(&res->converting);\n\tINIT_LIST_HEAD(&res->blocked);\n\tINIT_LIST_HEAD(&res->dirty);\n\tINIT_LIST_HEAD(&res->recovering);\n\tINIT_LIST_HEAD(&res->purge);\n\tINIT_LIST_HEAD(&res->tracking);\n\tatomic_set(&res->asts_reserved, 0);\n\tres->migration_pending = 0;\n\tres->inflight_locks = 0;\n\tres->inflight_assert_workers = 0;\n\n\tres->dlm = dlm;\n\n\tkref_init(&res->refs);\n\n\tatomic_inc(&dlm->res_tot_count);\n\tatomic_inc(&dlm->res_cur_count);\n\n\t \n\tspin_lock(&res->spinlock);\n\tdlm_set_lockres_owner(dlm, res, DLM_LOCK_RES_OWNER_UNKNOWN);\n\tspin_unlock(&res->spinlock);\n\n\tres->state = DLM_LOCK_RES_IN_PROGRESS;\n\n\tres->last_used = 0;\n\n\tspin_lock(&dlm->track_lock);\n\tlist_add_tail(&res->tracking, &dlm->tracking_list);\n\tspin_unlock(&dlm->track_lock);\n\n\tmemset(res->lvb, 0, DLM_LVB_LEN);\n\tbitmap_zero(res->refmap, O2NM_MAX_NODES);\n}\n\nstruct dlm_lock_resource *dlm_new_lockres(struct dlm_ctxt *dlm,\n\t\t\t\t   const char *name,\n\t\t\t\t   unsigned int namelen)\n{\n\tstruct dlm_lock_resource *res = NULL;\n\n\tres = kmem_cache_zalloc(dlm_lockres_cache, GFP_NOFS);\n\tif (!res)\n\t\tgoto error;\n\n\tres->lockname.name = kmem_cache_zalloc(dlm_lockname_cache, GFP_NOFS);\n\tif (!res->lockname.name)\n\t\tgoto error;\n\n\tdlm_init_lockres(dlm, res, name, namelen);\n\treturn res;\n\nerror:\n\tif (res)\n\t\tkmem_cache_free(dlm_lockres_cache, res);\n\treturn NULL;\n}\n\nvoid dlm_lockres_set_refmap_bit(struct dlm_ctxt *dlm,\n\t\t\t\tstruct dlm_lock_resource *res, int bit)\n{\n\tassert_spin_locked(&res->spinlock);\n\n\tmlog(0, \"res %.*s, set node %u, %ps()\\n\", res->lockname.len,\n\t     res->lockname.name, bit, __builtin_return_address(0));\n\n\tset_bit(bit, res->refmap);\n}\n\nvoid dlm_lockres_clear_refmap_bit(struct dlm_ctxt *dlm,\n\t\t\t\t  struct dlm_lock_resource *res, int bit)\n{\n\tassert_spin_locked(&res->spinlock);\n\n\tmlog(0, \"res %.*s, clr node %u, %ps()\\n\", res->lockname.len,\n\t     res->lockname.name, bit, __builtin_return_address(0));\n\n\tclear_bit(bit, res->refmap);\n}\n\nstatic void __dlm_lockres_grab_inflight_ref(struct dlm_ctxt *dlm,\n\t\t\t\t   struct dlm_lock_resource *res)\n{\n\tres->inflight_locks++;\n\n\tmlog(0, \"%s: res %.*s, inflight++: now %u, %ps()\\n\", dlm->name,\n\t     res->lockname.len, res->lockname.name, res->inflight_locks,\n\t     __builtin_return_address(0));\n}\n\nvoid dlm_lockres_grab_inflight_ref(struct dlm_ctxt *dlm,\n\t\t\t\t   struct dlm_lock_resource *res)\n{\n\tassert_spin_locked(&res->spinlock);\n\t__dlm_lockres_grab_inflight_ref(dlm, res);\n}\n\nvoid dlm_lockres_drop_inflight_ref(struct dlm_ctxt *dlm,\n\t\t\t\t   struct dlm_lock_resource *res)\n{\n\tassert_spin_locked(&res->spinlock);\n\n\tBUG_ON(res->inflight_locks == 0);\n\n\tres->inflight_locks--;\n\n\tmlog(0, \"%s: res %.*s, inflight--: now %u, %ps()\\n\", dlm->name,\n\t     res->lockname.len, res->lockname.name, res->inflight_locks,\n\t     __builtin_return_address(0));\n\n\twake_up(&res->wq);\n}\n\nvoid __dlm_lockres_grab_inflight_worker(struct dlm_ctxt *dlm,\n\t\tstruct dlm_lock_resource *res)\n{\n\tassert_spin_locked(&res->spinlock);\n\tres->inflight_assert_workers++;\n\tmlog(0, \"%s:%.*s: inflight assert worker++: now %u\\n\",\n\t\t\tdlm->name, res->lockname.len, res->lockname.name,\n\t\t\tres->inflight_assert_workers);\n}\n\nstatic void __dlm_lockres_drop_inflight_worker(struct dlm_ctxt *dlm,\n\t\tstruct dlm_lock_resource *res)\n{\n\tassert_spin_locked(&res->spinlock);\n\tBUG_ON(res->inflight_assert_workers == 0);\n\tres->inflight_assert_workers--;\n\tmlog(0, \"%s:%.*s: inflight assert worker--: now %u\\n\",\n\t\t\tdlm->name, res->lockname.len, res->lockname.name,\n\t\t\tres->inflight_assert_workers);\n}\n\nstatic void dlm_lockres_drop_inflight_worker(struct dlm_ctxt *dlm,\n\t\tstruct dlm_lock_resource *res)\n{\n\tspin_lock(&res->spinlock);\n\t__dlm_lockres_drop_inflight_worker(dlm, res);\n\tspin_unlock(&res->spinlock);\n}\n\n \nstruct dlm_lock_resource * dlm_get_lock_resource(struct dlm_ctxt *dlm,\n\t\t\t\t\t  const char *lockid,\n\t\t\t\t\t  int namelen,\n\t\t\t\t\t  int flags)\n{\n\tstruct dlm_lock_resource *tmpres=NULL, *res=NULL;\n\tstruct dlm_master_list_entry *mle = NULL;\n\tstruct dlm_master_list_entry *alloc_mle = NULL;\n\tint blocked = 0;\n\tint ret, nodenum;\n\tstruct dlm_node_iter iter;\n\tunsigned int hash;\n\tint tries = 0;\n\tint bit, wait_on_recovery = 0;\n\n\tBUG_ON(!lockid);\n\n\thash = dlm_lockid_hash(lockid, namelen);\n\n\tmlog(0, \"get lockres %s (len %d)\\n\", lockid, namelen);\n\nlookup:\n\tspin_lock(&dlm->spinlock);\n\ttmpres = __dlm_lookup_lockres_full(dlm, lockid, namelen, hash);\n\tif (tmpres) {\n\t\tspin_unlock(&dlm->spinlock);\n\t\tspin_lock(&tmpres->spinlock);\n\n\t\t \n\t\tif (hlist_unhashed(&tmpres->hash_node)) {\n\t\t\tspin_unlock(&tmpres->spinlock);\n\t\t\tdlm_lockres_put(tmpres);\n\t\t\ttmpres = NULL;\n\t\t\tgoto lookup;\n\t\t}\n\n\t\t \n\t\tif (tmpres->owner == DLM_LOCK_RES_OWNER_UNKNOWN) {\n\t\t\t__dlm_wait_on_lockres(tmpres);\n\t\t\tBUG_ON(tmpres->owner == DLM_LOCK_RES_OWNER_UNKNOWN);\n\t\t\tspin_unlock(&tmpres->spinlock);\n\t\t\tdlm_lockres_put(tmpres);\n\t\t\ttmpres = NULL;\n\t\t\tgoto lookup;\n\t\t}\n\n\t\t \n\t\tif (tmpres->state & DLM_LOCK_RES_DROPPING_REF) {\n\t\t\tBUG_ON(tmpres->owner == dlm->node_num);\n\t\t\t__dlm_wait_on_lockres_flags(tmpres,\n\t\t\t\t\t\t    DLM_LOCK_RES_DROPPING_REF);\n\t\t\tspin_unlock(&tmpres->spinlock);\n\t\t\tdlm_lockres_put(tmpres);\n\t\t\ttmpres = NULL;\n\t\t\tgoto lookup;\n\t\t}\n\n\t\t \n\t\tdlm_lockres_grab_inflight_ref(dlm, tmpres);\n\n\t\tspin_unlock(&tmpres->spinlock);\n\t\tif (res) {\n\t\t\tspin_lock(&dlm->track_lock);\n\t\t\tif (!list_empty(&res->tracking))\n\t\t\t\tlist_del_init(&res->tracking);\n\t\t\telse\n\t\t\t\tmlog(ML_ERROR, \"Resource %.*s not \"\n\t\t\t\t\t\t\"on the Tracking list\\n\",\n\t\t\t\t\t\tres->lockname.len,\n\t\t\t\t\t\tres->lockname.name);\n\t\t\tspin_unlock(&dlm->track_lock);\n\t\t\tdlm_lockres_put(res);\n\t\t}\n\t\tres = tmpres;\n\t\tgoto leave;\n\t}\n\n\tif (!res) {\n\t\tspin_unlock(&dlm->spinlock);\n\t\tmlog(0, \"allocating a new resource\\n\");\n\t\t \n\t\talloc_mle = kmem_cache_alloc(dlm_mle_cache, GFP_NOFS);\n\t\tif (!alloc_mle)\n\t\t\tgoto leave;\n\t\tres = dlm_new_lockres(dlm, lockid, namelen);\n\t\tif (!res)\n\t\t\tgoto leave;\n\t\tgoto lookup;\n\t}\n\n\tmlog(0, \"no lockres found, allocated our own: %p\\n\", res);\n\n\tif (flags & LKM_LOCAL) {\n\t\t \n\t\tspin_lock(&res->spinlock);\n\t\tdlm_change_lockres_owner(dlm, res, dlm->node_num);\n\t\t__dlm_insert_lockres(dlm, res);\n\t\tdlm_lockres_grab_inflight_ref(dlm, res);\n\t\tspin_unlock(&res->spinlock);\n\t\tspin_unlock(&dlm->spinlock);\n\t\t \n\t\tgoto wake_waiters;\n\t}\n\n\t \n\tspin_lock(&dlm->master_lock);\n\n\t \n\tblocked = dlm_find_mle(dlm, &mle, (char *)lockid, namelen);\n\tif (blocked) {\n\t\tint mig;\n\t\tif (mle->type == DLM_MLE_MASTER) {\n\t\t\tmlog(ML_ERROR, \"master entry for nonexistent lock!\\n\");\n\t\t\tBUG();\n\t\t}\n\t\tmig = (mle->type == DLM_MLE_MIGRATION);\n\t\t \n\t\tif (mig || mle->master != O2NM_MAX_NODES) {\n\t\t\tBUG_ON(mig && mle->master == dlm->node_num);\n\t\t\t \n\t\t\tmlog(0, \"%s:%.*s: late on %s\\n\",\n\t\t\t     dlm->name, namelen, lockid,\n\t\t\t     mig ?  \"MIGRATION\" : \"BLOCK\");\n\t\t\tspin_unlock(&dlm->master_lock);\n\t\t\tspin_unlock(&dlm->spinlock);\n\n\t\t\t \n\t\t\tif (!mig)\n\t\t\t\tdlm_mle_detach_hb_events(dlm, mle);\n\t\t\tdlm_put_mle(mle);\n\t\t\tmle = NULL;\n\t\t\t \n\t\t\tif (mig)\n\t\t\t\tmsleep(100);\n\t\t\tgoto lookup;\n\t\t}\n\t} else {\n\t\t \n\t\tmle = alloc_mle;\n\t\t \n\t\talloc_mle = NULL;\n\t\tdlm_init_mle(mle, DLM_MLE_MASTER, dlm, res, NULL, 0);\n\t\tset_bit(dlm->node_num, mle->maybe_map);\n\t\t__dlm_insert_mle(dlm, mle);\n\n\t\t \n\t\tbit = find_first_bit(dlm->recovery_map, O2NM_MAX_NODES);\n\t\tif (bit < O2NM_MAX_NODES) {\n\t\t\tmlog(0, \"%s: res %.*s, At least one node (%d) \"\n\t\t\t     \"to recover before lock mastery can begin\\n\",\n\t\t\t     dlm->name, namelen, (char *)lockid, bit);\n\t\t\twait_on_recovery = 1;\n\t\t}\n\t}\n\n\t \n\n\t \n\t__dlm_insert_lockres(dlm, res);\n\n\t \n\t__dlm_lockres_grab_inflight_ref(dlm, res);\n\n\t \n\tdlm_get_mle_inuse(mle);\n\tspin_unlock(&dlm->master_lock);\n\tspin_unlock(&dlm->spinlock);\n\nredo_request:\n\twhile (wait_on_recovery) {\n\t\t \n\t\tif (dlm_is_recovery_lock(lockid, namelen)) {\n\t\t\tmlog(0, \"%s: Recovery map is not empty, but must \"\n\t\t\t     \"master $RECOVERY lock now\\n\", dlm->name);\n\t\t\tif (!dlm_pre_master_reco_lockres(dlm, res))\n\t\t\t\twait_on_recovery = 0;\n\t\t\telse {\n\t\t\t\tmlog(0, \"%s: waiting 500ms for heartbeat state \"\n\t\t\t\t    \"change\\n\", dlm->name);\n\t\t\t\tmsleep(500);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tdlm_kick_recovery_thread(dlm);\n\t\tmsleep(1000);\n\t\tdlm_wait_for_recovery(dlm);\n\n\t\tspin_lock(&dlm->spinlock);\n\t\tbit = find_first_bit(dlm->recovery_map, O2NM_MAX_NODES);\n\t\tif (bit < O2NM_MAX_NODES) {\n\t\t\tmlog(0, \"%s: res %.*s, At least one node (%d) \"\n\t\t\t     \"to recover before lock mastery can begin\\n\",\n\t\t\t     dlm->name, namelen, (char *)lockid, bit);\n\t\t\twait_on_recovery = 1;\n\t\t} else\n\t\t\twait_on_recovery = 0;\n\t\tspin_unlock(&dlm->spinlock);\n\n\t\tif (wait_on_recovery)\n\t\t\tdlm_wait_for_node_recovery(dlm, bit, 10000);\n\t}\n\n\t \n\tif (blocked)\n\t\tgoto wait;\n\n\tret = -EINVAL;\n\tdlm_node_iter_init(mle->vote_map, &iter);\n\twhile ((nodenum = dlm_node_iter_next(&iter)) >= 0) {\n\t\tret = dlm_do_master_request(res, mle, nodenum);\n\t\tif (ret < 0)\n\t\t\tmlog_errno(ret);\n\t\tif (mle->master != O2NM_MAX_NODES) {\n\t\t\t \n\t\t\tif (mle->master <= nodenum)\n\t\t\t\tbreak;\n\t\t\t \n\t\t\tmlog(0, \"%s: res %.*s, Requests only up to %u but \"\n\t\t\t     \"master is %u, keep going\\n\", dlm->name, namelen,\n\t\t\t     lockid, nodenum, mle->master);\n\t\t}\n\t}\n\nwait:\n\t \n\tret = dlm_wait_for_lock_mastery(dlm, res, mle, &blocked);\n\tif (ret < 0) {\n\t\twait_on_recovery = 1;\n\t\tmlog(0, \"%s: res %.*s, Node map changed, redo the master \"\n\t\t     \"request now, blocked=%d\\n\", dlm->name, res->lockname.len,\n\t\t     res->lockname.name, blocked);\n\t\tif (++tries > 20) {\n\t\t\tmlog(ML_ERROR, \"%s: res %.*s, Spinning on \"\n\t\t\t     \"dlm_wait_for_lock_mastery, blocked = %d\\n\",\n\t\t\t     dlm->name, res->lockname.len,\n\t\t\t     res->lockname.name, blocked);\n\t\t\tdlm_print_one_lock_resource(res);\n\t\t\tdlm_print_one_mle(mle);\n\t\t\ttries = 0;\n\t\t}\n\t\tgoto redo_request;\n\t}\n\n\tmlog(0, \"%s: res %.*s, Mastered by %u\\n\", dlm->name, res->lockname.len,\n\t     res->lockname.name, res->owner);\n\t \n\tBUG_ON(res->owner == O2NM_MAX_NODES);\n\n\t \n\tdlm_mle_detach_hb_events(dlm, mle);\n\tdlm_put_mle(mle);\n\t \n\tdlm_put_mle_inuse(mle);\n\nwake_waiters:\n\tspin_lock(&res->spinlock);\n\tres->state &= ~DLM_LOCK_RES_IN_PROGRESS;\n\tspin_unlock(&res->spinlock);\n\twake_up(&res->wq);\n\nleave:\n\t \n\tif (alloc_mle)\n\t\tkmem_cache_free(dlm_mle_cache, alloc_mle);\n\n\treturn res;\n}\n\n\n#define DLM_MASTERY_TIMEOUT_MS   5000\n\nstatic int dlm_wait_for_lock_mastery(struct dlm_ctxt *dlm,\n\t\t\t\t     struct dlm_lock_resource *res,\n\t\t\t\t     struct dlm_master_list_entry *mle,\n\t\t\t\t     int *blocked)\n{\n\tu8 m;\n\tint ret, bit;\n\tint map_changed, voting_done;\n\tint assert, sleep;\n\nrecheck:\n\tret = 0;\n\tassert = 0;\n\n\t \n\tspin_lock(&res->spinlock);\n\tif (res->owner != DLM_LOCK_RES_OWNER_UNKNOWN) {\n\t\tmlog(0, \"%s:%.*s: owner is suddenly %u\\n\", dlm->name,\n\t\t     res->lockname.len, res->lockname.name, res->owner);\n\t\tspin_unlock(&res->spinlock);\n\t\t \n\t\tif (res->owner != dlm->node_num) {\n\t\t\tret = dlm_do_master_request(res, mle, res->owner);\n\t\t\tif (ret < 0) {\n\t\t\t\t \n\t\t\t\tmlog(ML_ERROR, \"link to %u went down?: %d\\n\", res->owner, ret);\n\t\t\t\tmsleep(500);\n\t\t\t\tgoto recheck;\n\t\t\t}\n\t\t}\n\t\tret = 0;\n\t\tgoto leave;\n\t}\n\tspin_unlock(&res->spinlock);\n\n\tspin_lock(&mle->spinlock);\n\tm = mle->master;\n\tmap_changed = !bitmap_equal(mle->vote_map, mle->node_map,\n\t\t\t\t    O2NM_MAX_NODES);\n\tvoting_done = bitmap_equal(mle->vote_map, mle->response_map,\n\t\t\t\t   O2NM_MAX_NODES);\n\n\t \n\tif (map_changed) {\n\t\tint b;\n\t\tmlog(0, \"%s: %.*s: node map changed, restarting\\n\",\n\t\t     dlm->name, res->lockname.len, res->lockname.name);\n\t\tret = dlm_restart_lock_mastery(dlm, res, mle, *blocked);\n\t\tb = (mle->type == DLM_MLE_BLOCK);\n\t\tif ((*blocked && !b) || (!*blocked && b)) {\n\t\t\tmlog(0, \"%s:%.*s: status change: old=%d new=%d\\n\",\n\t\t\t     dlm->name, res->lockname.len, res->lockname.name,\n\t\t\t     *blocked, b);\n\t\t\t*blocked = b;\n\t\t}\n\t\tspin_unlock(&mle->spinlock);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto leave;\n\t\t}\n\t\tmlog(0, \"%s:%.*s: restart lock mastery succeeded, \"\n\t\t     \"rechecking now\\n\", dlm->name, res->lockname.len,\n\t\t     res->lockname.name);\n\t\tgoto recheck;\n\t} else {\n\t\tif (!voting_done) {\n\t\t\tmlog(0, \"map not changed and voting not done \"\n\t\t\t     \"for %s:%.*s\\n\", dlm->name, res->lockname.len,\n\t\t\t     res->lockname.name);\n\t\t}\n\t}\n\n\tif (m != O2NM_MAX_NODES) {\n\t\t \n\t\tsleep = 0;\n\t} else {\n\t\tsleep = 1;\n\t\t \n\t\tif (voting_done && !*blocked) {\n\t\t\tbit = find_first_bit(mle->maybe_map, O2NM_MAX_NODES);\n\t\t\tif (dlm->node_num <= bit) {\n\t\t\t\t \n\t\t\t\tmle->master = dlm->node_num;\n\t\t\t\t \n\t\t\t\tassert = 1;\n\t\t\t\tsleep = 0;\n\t\t\t}\n\t\t\t \n\t\t}\n\t}\n\n\tspin_unlock(&mle->spinlock);\n\n\t \n\tif (sleep) {\n\t\tunsigned long timeo = msecs_to_jiffies(DLM_MASTERY_TIMEOUT_MS);\n\t\tatomic_set(&mle->woken, 0);\n\t\t(void)wait_event_timeout(mle->wq,\n\t\t\t\t\t (atomic_read(&mle->woken) == 1),\n\t\t\t\t\t timeo);\n\t\tif (res->owner == O2NM_MAX_NODES) {\n\t\t\tmlog(0, \"%s:%.*s: waiting again\\n\", dlm->name,\n\t\t\t     res->lockname.len, res->lockname.name);\n\t\t\tgoto recheck;\n\t\t}\n\t\tmlog(0, \"done waiting, master is %u\\n\", res->owner);\n\t\tret = 0;\n\t\tgoto leave;\n\t}\n\n\tret = 0;    \n\tif (assert) {\n\t\tm = dlm->node_num;\n\t\tmlog(0, \"about to master %.*s here, this=%u\\n\",\n\t\t     res->lockname.len, res->lockname.name, m);\n\t\tret = dlm_do_assert_master(dlm, res, mle->vote_map, 0);\n\t\tif (ret) {\n\t\t\t \n\t\t\tmlog_errno(ret);\n\t\t}\n\t\t \n\t\tret = 0;\n\t}\n\n\t \n\tspin_lock(&res->spinlock);\n\t \n\tdlm_change_lockres_owner(dlm, res, m);\n\tspin_unlock(&res->spinlock);\n\nleave:\n\treturn ret;\n}\n\nstruct dlm_bitmap_diff_iter\n{\n\tint curnode;\n\tunsigned long *orig_bm;\n\tunsigned long *cur_bm;\n\tunsigned long diff_bm[BITS_TO_LONGS(O2NM_MAX_NODES)];\n};\n\nenum dlm_node_state_change\n{\n\tNODE_DOWN = -1,\n\tNODE_NO_CHANGE = 0,\n\tNODE_UP\n};\n\nstatic void dlm_bitmap_diff_iter_init(struct dlm_bitmap_diff_iter *iter,\n\t\t\t\t      unsigned long *orig_bm,\n\t\t\t\t      unsigned long *cur_bm)\n{\n\tunsigned long p1, p2;\n\tint i;\n\n\titer->curnode = -1;\n\titer->orig_bm = orig_bm;\n\titer->cur_bm = cur_bm;\n\n\tfor (i = 0; i < BITS_TO_LONGS(O2NM_MAX_NODES); i++) {\n       \t\tp1 = *(iter->orig_bm + i);\n\t       \tp2 = *(iter->cur_bm + i);\n\t\titer->diff_bm[i] = (p1 & ~p2) | (p2 & ~p1);\n\t}\n}\n\nstatic int dlm_bitmap_diff_iter_next(struct dlm_bitmap_diff_iter *iter,\n\t\t\t\t     enum dlm_node_state_change *state)\n{\n\tint bit;\n\n\tif (iter->curnode >= O2NM_MAX_NODES)\n\t\treturn -ENOENT;\n\n\tbit = find_next_bit(iter->diff_bm, O2NM_MAX_NODES,\n\t\t\t    iter->curnode+1);\n\tif (bit >= O2NM_MAX_NODES) {\n\t\titer->curnode = O2NM_MAX_NODES;\n\t\treturn -ENOENT;\n\t}\n\n\t \n\tif (test_bit(bit, iter->orig_bm))\n\t\t*state = NODE_DOWN;\n\telse\n\t\t*state = NODE_UP;\n\n\titer->curnode = bit;\n\treturn bit;\n}\n\n\nstatic int dlm_restart_lock_mastery(struct dlm_ctxt *dlm,\n\t\t\t\t    struct dlm_lock_resource *res,\n\t\t\t\t    struct dlm_master_list_entry *mle,\n\t\t\t\t    int blocked)\n{\n\tstruct dlm_bitmap_diff_iter bdi;\n\tenum dlm_node_state_change sc;\n\tint node;\n\tint ret = 0;\n\n\tmlog(0, \"something happened such that the \"\n\t     \"master process may need to be restarted!\\n\");\n\n\tassert_spin_locked(&mle->spinlock);\n\n\tdlm_bitmap_diff_iter_init(&bdi, mle->vote_map, mle->node_map);\n\tnode = dlm_bitmap_diff_iter_next(&bdi, &sc);\n\twhile (node >= 0) {\n\t\tif (sc == NODE_UP) {\n\t\t\t \n\t\t\tmlog(ML_NOTICE, \"node %d up while restarting\\n\", node);\n\n\t\t\t \n\t\t\tmlog(0, \"sending request to new node\\n\");\n\t\t\tclear_bit(node, mle->response_map);\n\t\t\tset_bit(node, mle->vote_map);\n\t\t} else {\n\t\t\tmlog(ML_ERROR, \"node down! %d\\n\", node);\n\t\t\tif (blocked) {\n\t\t\t\tint lowest = find_first_bit(mle->maybe_map,\n\t\t\t\t\t\t       O2NM_MAX_NODES);\n\n\t\t\t\t \n\t\t\t\tclear_bit(node, mle->maybe_map);\n\n\t\t\t       \tif (node == lowest) {\n\t\t\t\t\tmlog(0, \"expected master %u died\"\n\t\t\t\t\t    \" while this node was blocked \"\n\t\t\t\t\t    \"waiting on it!\\n\", node);\n\t\t\t\t\tlowest = find_next_bit(mle->maybe_map,\n\t\t\t\t\t\t       \tO2NM_MAX_NODES,\n\t\t\t\t\t\t       \tlowest+1);\n\t\t\t\t\tif (lowest < O2NM_MAX_NODES) {\n\t\t\t\t\t\tmlog(0, \"%s:%.*s:still \"\n\t\t\t\t\t\t     \"blocked. waiting on %u \"\n\t\t\t\t\t\t     \"now\\n\", dlm->name,\n\t\t\t\t\t\t     res->lockname.len,\n\t\t\t\t\t\t     res->lockname.name,\n\t\t\t\t\t\t     lowest);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t \n\t\t\t\t\t\tmlog(0, \"%s:%.*s: no \"\n\t\t\t\t\t\t     \"longer blocking. try to \"\n\t\t\t\t\t\t     \"master this here\\n\",\n\t\t\t\t\t\t     dlm->name,\n\t\t\t\t\t\t     res->lockname.len,\n\t\t\t\t\t\t     res->lockname.name);\n\t\t\t\t\t\tmle->type = DLM_MLE_MASTER;\n\t\t\t\t\t\tmle->mleres = res;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\tbitmap_zero(mle->maybe_map, O2NM_MAX_NODES);\n\t\t\tbitmap_zero(mle->response_map, O2NM_MAX_NODES);\n\t\t\t \n\t\t\tbitmap_copy(mle->vote_map, mle->node_map,\n\t\t\t\t    O2NM_MAX_NODES);\n\t\t\t \n\t\t\tif (mle->type != DLM_MLE_BLOCK)\n\t\t\t\tset_bit(dlm->node_num, mle->maybe_map);\n\t\t}\n\t\tret = -EAGAIN;\n\t\tnode = dlm_bitmap_diff_iter_next(&bdi, &sc);\n\t}\n\treturn ret;\n}\n\n\n \n\nstatic int dlm_do_master_request(struct dlm_lock_resource *res,\n\t\t\t\t struct dlm_master_list_entry *mle, int to)\n{\n\tstruct dlm_ctxt *dlm = mle->dlm;\n\tstruct dlm_master_request request;\n\tint ret, response=0, resend;\n\n\tmemset(&request, 0, sizeof(request));\n\trequest.node_idx = dlm->node_num;\n\n\tBUG_ON(mle->type == DLM_MLE_MIGRATION);\n\n\trequest.namelen = (u8)mle->mnamelen;\n\tmemcpy(request.name, mle->mname, request.namelen);\n\nagain:\n\tret = o2net_send_message(DLM_MASTER_REQUEST_MSG, dlm->key, &request,\n\t\t\t\t sizeof(request), to, &response);\n\tif (ret < 0)  {\n\t\tif (ret == -ESRCH) {\n\t\t\t \n\t\t\tmlog(ML_ERROR, \"TCP stack not ready!\\n\");\n\t\t\tBUG();\n\t\t} else if (ret == -EINVAL) {\n\t\t\tmlog(ML_ERROR, \"bad args passed to o2net!\\n\");\n\t\t\tBUG();\n\t\t} else if (ret == -ENOMEM) {\n\t\t\tmlog(ML_ERROR, \"out of memory while trying to send \"\n\t\t\t     \"network message!  retrying\\n\");\n\t\t\t \n\t\t\tmsleep(50);\n\t\t\tgoto again;\n\t\t} else if (!dlm_is_host_down(ret)) {\n\t\t\t \n\t\t\tmlog_errno(ret);\n\t\t\tmlog(ML_ERROR, \"unhandled error!\");\n\t\t\tBUG();\n\t\t}\n\t\t \n\t\tmlog(ML_ERROR, \"link to %d went down!\\n\", to);\n\t\tgoto out;\n\t}\n\n\tret = 0;\n\tresend = 0;\n\tspin_lock(&mle->spinlock);\n\tswitch (response) {\n\t\tcase DLM_MASTER_RESP_YES:\n\t\t\tset_bit(to, mle->response_map);\n\t\t\tmlog(0, \"node %u is the master, response=YES\\n\", to);\n\t\t\tmlog(0, \"%s:%.*s: master node %u now knows I have a \"\n\t\t\t     \"reference\\n\", dlm->name, res->lockname.len,\n\t\t\t     res->lockname.name, to);\n\t\t\tmle->master = to;\n\t\t\tbreak;\n\t\tcase DLM_MASTER_RESP_NO:\n\t\t\tmlog(0, \"node %u not master, response=NO\\n\", to);\n\t\t\tset_bit(to, mle->response_map);\n\t\t\tbreak;\n\t\tcase DLM_MASTER_RESP_MAYBE:\n\t\t\tmlog(0, \"node %u not master, response=MAYBE\\n\", to);\n\t\t\tset_bit(to, mle->response_map);\n\t\t\tset_bit(to, mle->maybe_map);\n\t\t\tbreak;\n\t\tcase DLM_MASTER_RESP_ERROR:\n\t\t\tmlog(0, \"node %u hit an error, resending\\n\", to);\n\t\t\tresend = 1;\n\t\t\tresponse = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tmlog(ML_ERROR, \"bad response! %u\\n\", response);\n\t\t\tBUG();\n\t}\n\tspin_unlock(&mle->spinlock);\n\tif (resend) {\n\t\t \n\t\tmsleep(50);\n\t\tgoto again;\n\t}\n\nout:\n\treturn ret;\n}\n\n \nint dlm_master_request_handler(struct o2net_msg *msg, u32 len, void *data,\n\t\t\t       void **ret_data)\n{\n\tu8 response = DLM_MASTER_RESP_MAYBE;\n\tstruct dlm_ctxt *dlm = data;\n\tstruct dlm_lock_resource *res = NULL;\n\tstruct dlm_master_request *request = (struct dlm_master_request *) msg->buf;\n\tstruct dlm_master_list_entry *mle = NULL, *tmpmle = NULL;\n\tchar *name;\n\tunsigned int namelen, hash;\n\tint found, ret;\n\tint set_maybe;\n\tint dispatch_assert = 0;\n\tint dispatched = 0;\n\n\tif (!dlm_grab(dlm))\n\t\treturn DLM_MASTER_RESP_NO;\n\n\tif (!dlm_domain_fully_joined(dlm)) {\n\t\tresponse = DLM_MASTER_RESP_NO;\n\t\tgoto send_response;\n\t}\n\n\tname = request->name;\n\tnamelen = request->namelen;\n\thash = dlm_lockid_hash(name, namelen);\n\n\tif (namelen > DLM_LOCKID_NAME_MAX) {\n\t\tresponse = DLM_IVBUFLEN;\n\t\tgoto send_response;\n\t}\n\nway_up_top:\n\tspin_lock(&dlm->spinlock);\n\tres = __dlm_lookup_lockres(dlm, name, namelen, hash);\n\tif (res) {\n\t\tspin_unlock(&dlm->spinlock);\n\n\t\t \n\t\tspin_lock(&res->spinlock);\n\n\t\t \n\t\tif (hlist_unhashed(&res->hash_node)) {\n\t\t\tspin_unlock(&res->spinlock);\n\t\t\tdlm_lockres_put(res);\n\t\t\tgoto way_up_top;\n\t\t}\n\n\t\tif (res->state & (DLM_LOCK_RES_RECOVERING|\n\t\t\t\t  DLM_LOCK_RES_MIGRATING)) {\n\t\t\tspin_unlock(&res->spinlock);\n\t\t\tmlog(0, \"returning DLM_MASTER_RESP_ERROR since res is \"\n\t\t\t     \"being recovered/migrated\\n\");\n\t\t\tresponse = DLM_MASTER_RESP_ERROR;\n\t\t\tif (mle)\n\t\t\t\tkmem_cache_free(dlm_mle_cache, mle);\n\t\t\tgoto send_response;\n\t\t}\n\n\t\tif (res->owner == dlm->node_num) {\n\t\t\tdlm_lockres_set_refmap_bit(dlm, res, request->node_idx);\n\t\t\tspin_unlock(&res->spinlock);\n\t\t\tresponse = DLM_MASTER_RESP_YES;\n\t\t\tif (mle)\n\t\t\t\tkmem_cache_free(dlm_mle_cache, mle);\n\n\t\t\t \n\t\t\tdispatch_assert = 1;\n\t\t\tgoto send_response;\n\t\t} else if (res->owner != DLM_LOCK_RES_OWNER_UNKNOWN) {\n\t\t\tspin_unlock(&res->spinlock);\n\t\t\t \n\t\t\tresponse = DLM_MASTER_RESP_NO;\n\t\t\tif (mle)\n\t\t\t\tkmem_cache_free(dlm_mle_cache, mle);\n\t\t\tgoto send_response;\n\t\t}\n\n\t\t \n\t\tif (!(res->state & DLM_LOCK_RES_IN_PROGRESS)) {\n\t\t\tmlog(ML_ERROR, \"lock with no owner should be \"\n\t\t\t     \"in-progress!\\n\");\n\t\t\tBUG();\n\t\t}\n\n\t\t \n\t\tspin_lock(&dlm->master_lock);\n\t\tfound = dlm_find_mle(dlm, &tmpmle, name, namelen);\n\t\tif (!found) {\n\t\t\tmlog(ML_ERROR, \"no mle found for this lock!\\n\");\n\t\t\tBUG();\n\t\t}\n\t\tset_maybe = 1;\n\t\tspin_lock(&tmpmle->spinlock);\n\t\tif (tmpmle->type == DLM_MLE_BLOCK) {\n\t\t\t \n\t\t\t \n\t\t\tresponse = DLM_MASTER_RESP_NO;\n\t\t} else if (tmpmle->type == DLM_MLE_MIGRATION) {\n\t\t\tmlog(0, \"node %u is master, but trying to migrate to \"\n\t\t\t     \"node %u.\\n\", tmpmle->master, tmpmle->new_master);\n\t\t\tif (tmpmle->master == dlm->node_num) {\n\t\t\t\tmlog(ML_ERROR, \"no owner on lockres, but this \"\n\t\t\t\t     \"node is trying to migrate it to %u?!\\n\",\n\t\t\t\t     tmpmle->new_master);\n\t\t\t\tBUG();\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tresponse = DLM_MASTER_RESP_NO;\n\t\t\t}\n\t\t} else if (tmpmle->master != DLM_LOCK_RES_OWNER_UNKNOWN) {\n\t\t\tset_maybe = 0;\n\t\t\tif (tmpmle->master == dlm->node_num) {\n\t\t\t\tresponse = DLM_MASTER_RESP_YES;\n\t\t\t\t \n\t\t\t\tdispatch_assert = 1;\n\t\t\t\tdlm_lockres_set_refmap_bit(dlm, res,\n\t\t\t\t\t\t\t   request->node_idx);\n\t\t\t} else\n\t\t\t\tresponse = DLM_MASTER_RESP_NO;\n\t\t} else {\n\t\t\t \n\t\t\t \n\t\t\tresponse = DLM_MASTER_RESP_MAYBE;\n\t\t}\n\t\tif (set_maybe)\n\t\t\tset_bit(request->node_idx, tmpmle->maybe_map);\n\t\tspin_unlock(&tmpmle->spinlock);\n\n\t\tspin_unlock(&dlm->master_lock);\n\t\tspin_unlock(&res->spinlock);\n\n\t\t \n\t\tdlm_put_mle(tmpmle);\n\t\tif (mle)\n\t\t\tkmem_cache_free(dlm_mle_cache, mle);\n\t\tgoto send_response;\n\t}\n\n\t \n\tspin_lock(&dlm->master_lock);\n\tfound = dlm_find_mle(dlm, &tmpmle, name, namelen);\n\tif (!found) {\n\t\t \n\t\t \n\t\tif (!mle) {\n\t\t\tspin_unlock(&dlm->master_lock);\n\t\t\tspin_unlock(&dlm->spinlock);\n\n\t\t\tmle = kmem_cache_alloc(dlm_mle_cache, GFP_NOFS);\n\t\t\tif (!mle) {\n\t\t\t\tresponse = DLM_MASTER_RESP_ERROR;\n\t\t\t\tmlog_errno(-ENOMEM);\n\t\t\t\tgoto send_response;\n\t\t\t}\n\t\t\tgoto way_up_top;\n\t\t}\n\n\t\t \n\t\t \n\t\tdlm_init_mle(mle, DLM_MLE_BLOCK, dlm, NULL, name, namelen);\n\t\tset_bit(request->node_idx, mle->maybe_map);\n\t\t__dlm_insert_mle(dlm, mle);\n\t\tresponse = DLM_MASTER_RESP_NO;\n\t} else {\n\t\tspin_lock(&tmpmle->spinlock);\n\t\tif (tmpmle->master == dlm->node_num) {\n\t\t\tmlog(ML_ERROR, \"no lockres, but an mle with this node as master!\\n\");\n\t\t\tBUG();\n\t\t}\n\t\tif (tmpmle->type == DLM_MLE_BLOCK)\n\t\t\tresponse = DLM_MASTER_RESP_NO;\n\t\telse if (tmpmle->type == DLM_MLE_MIGRATION) {\n\t\t\tmlog(0, \"migration mle was found (%u->%u)\\n\",\n\t\t\t     tmpmle->master, tmpmle->new_master);\n\t\t\t \n\t\t\tresponse = DLM_MASTER_RESP_NO;\n\t\t} else\n\t\t\tresponse = DLM_MASTER_RESP_MAYBE;\n\t\tset_bit(request->node_idx, tmpmle->maybe_map);\n\t\tspin_unlock(&tmpmle->spinlock);\n\t}\n\tspin_unlock(&dlm->master_lock);\n\tspin_unlock(&dlm->spinlock);\n\n\tif (found) {\n\t\t \n\t\tdlm_put_mle(tmpmle);\n\t}\nsend_response:\n\t \n\tif (dispatch_assert) {\n\t\tmlog(0, \"%u is the owner of %.*s, cleaning everyone else\\n\",\n\t\t\t     dlm->node_num, res->lockname.len, res->lockname.name);\n\t\tspin_lock(&res->spinlock);\n\t\tret = dlm_dispatch_assert_master(dlm, res, 0, request->node_idx,\n\t\t\t\t\t\t DLM_ASSERT_MASTER_MLE_CLEANUP);\n\t\tif (ret < 0) {\n\t\t\tmlog(ML_ERROR, \"failed to dispatch assert master work\\n\");\n\t\t\tresponse = DLM_MASTER_RESP_ERROR;\n\t\t\tspin_unlock(&res->spinlock);\n\t\t\tdlm_lockres_put(res);\n\t\t} else {\n\t\t\tdispatched = 1;\n\t\t\t__dlm_lockres_grab_inflight_worker(dlm, res);\n\t\t\tspin_unlock(&res->spinlock);\n\t\t}\n\t} else {\n\t\tif (res)\n\t\t\tdlm_lockres_put(res);\n\t}\n\n\tif (!dispatched)\n\t\tdlm_put(dlm);\n\treturn response;\n}\n\n \n\n\n \nstatic int dlm_do_assert_master(struct dlm_ctxt *dlm,\n\t\t\t\tstruct dlm_lock_resource *res,\n\t\t\t\tvoid *nodemap, u32 flags)\n{\n\tstruct dlm_assert_master assert;\n\tint to, tmpret;\n\tstruct dlm_node_iter iter;\n\tint ret = 0;\n\tint reassert;\n\tconst char *lockname = res->lockname.name;\n\tunsigned int namelen = res->lockname.len;\n\n\tBUG_ON(namelen > O2NM_MAX_NAME_LEN);\n\n\tspin_lock(&res->spinlock);\n\tres->state |= DLM_LOCK_RES_SETREF_INPROG;\n\tspin_unlock(&res->spinlock);\n\nagain:\n\treassert = 0;\n\n\t \n\tdlm_node_iter_init(nodemap, &iter);\n\twhile ((to = dlm_node_iter_next(&iter)) >= 0) {\n\t\tint r = 0;\n\t\tstruct dlm_master_list_entry *mle = NULL;\n\n\t\tmlog(0, \"sending assert master to %d (%.*s)\\n\", to,\n\t\t     namelen, lockname);\n\t\tmemset(&assert, 0, sizeof(assert));\n\t\tassert.node_idx = dlm->node_num;\n\t\tassert.namelen = namelen;\n\t\tmemcpy(assert.name, lockname, namelen);\n\t\tassert.flags = cpu_to_be32(flags);\n\n\t\ttmpret = o2net_send_message(DLM_ASSERT_MASTER_MSG, dlm->key,\n\t\t\t\t\t    &assert, sizeof(assert), to, &r);\n\t\tif (tmpret < 0) {\n\t\t\tmlog(ML_ERROR, \"Error %d when sending message %u (key \"\n\t\t\t     \"0x%x) to node %u\\n\", tmpret,\n\t\t\t     DLM_ASSERT_MASTER_MSG, dlm->key, to);\n\t\t\tif (!dlm_is_host_down(tmpret)) {\n\t\t\t\tmlog(ML_ERROR, \"unhandled error=%d!\\n\", tmpret);\n\t\t\t\tBUG();\n\t\t\t}\n\t\t\t \n\t\t\tmlog(0, \"link to %d went down!\\n\", to);\n\t\t\t \n\t\t\tret = tmpret;\n\t\t\tr = 0;\n\t\t} else if (r < 0) {\n\t\t\t \n\t\t\tmlog(ML_ERROR,\"during assert master of %.*s to %u, \"\n\t\t\t     \"got %d.\\n\", namelen, lockname, to, r);\n\t\t\tspin_lock(&dlm->spinlock);\n\t\t\tspin_lock(&dlm->master_lock);\n\t\t\tif (dlm_find_mle(dlm, &mle, (char *)lockname,\n\t\t\t\t\t namelen)) {\n\t\t\t\tdlm_print_one_mle(mle);\n\t\t\t\t__dlm_put_mle(mle);\n\t\t\t}\n\t\t\tspin_unlock(&dlm->master_lock);\n\t\t\tspin_unlock(&dlm->spinlock);\n\t\t\tBUG();\n\t\t}\n\n\t\tif (r & DLM_ASSERT_RESPONSE_REASSERT &&\n\t\t    !(r & DLM_ASSERT_RESPONSE_MASTERY_REF)) {\n\t\t\t\tmlog(ML_ERROR, \"%.*s: very strange, \"\n\t\t\t\t     \"master MLE but no lockres on %u\\n\",\n\t\t\t\t     namelen, lockname, to);\n\t\t}\n\n\t\tif (r & DLM_ASSERT_RESPONSE_REASSERT) {\n\t\t\tmlog(0, \"%.*s: node %u create mles on other \"\n\t\t\t     \"nodes and requests a re-assert\\n\",\n\t\t\t     namelen, lockname, to);\n\t\t\treassert = 1;\n\t\t}\n\t\tif (r & DLM_ASSERT_RESPONSE_MASTERY_REF) {\n\t\t\tmlog(0, \"%.*s: node %u has a reference to this \"\n\t\t\t     \"lockres, set the bit in the refmap\\n\",\n\t\t\t     namelen, lockname, to);\n\t\t\tspin_lock(&res->spinlock);\n\t\t\tdlm_lockres_set_refmap_bit(dlm, res, to);\n\t\t\tspin_unlock(&res->spinlock);\n\t\t}\n\t}\n\n\tif (reassert)\n\t\tgoto again;\n\n\tspin_lock(&res->spinlock);\n\tres->state &= ~DLM_LOCK_RES_SETREF_INPROG;\n\tspin_unlock(&res->spinlock);\n\twake_up(&res->wq);\n\n\treturn ret;\n}\n\n \nint dlm_assert_master_handler(struct o2net_msg *msg, u32 len, void *data,\n\t\t\t      void **ret_data)\n{\n\tstruct dlm_ctxt *dlm = data;\n\tstruct dlm_master_list_entry *mle = NULL;\n\tstruct dlm_assert_master *assert = (struct dlm_assert_master *)msg->buf;\n\tstruct dlm_lock_resource *res = NULL;\n\tchar *name;\n\tunsigned int namelen, hash;\n\tu32 flags;\n\tint master_request = 0, have_lockres_ref = 0;\n\tint ret = 0;\n\n\tif (!dlm_grab(dlm))\n\t\treturn 0;\n\n\tname = assert->name;\n\tnamelen = assert->namelen;\n\thash = dlm_lockid_hash(name, namelen);\n\tflags = be32_to_cpu(assert->flags);\n\n\tif (namelen > DLM_LOCKID_NAME_MAX) {\n\t\tmlog(ML_ERROR, \"Invalid name length!\");\n\t\tgoto done;\n\t}\n\n\tspin_lock(&dlm->spinlock);\n\n\tif (flags)\n\t\tmlog(0, \"assert_master with flags: %u\\n\", flags);\n\n\t \n\tspin_lock(&dlm->master_lock);\n\tif (!dlm_find_mle(dlm, &mle, name, namelen)) {\n\t\t \n\t\tmlog(0, \"just got an assert_master from %u, but no \"\n\t\t     \"MLE for it! (%.*s)\\n\", assert->node_idx,\n\t\t     namelen, name);\n\t} else {\n\t\tint bit = find_first_bit(mle->maybe_map, O2NM_MAX_NODES);\n\t\tif (bit >= O2NM_MAX_NODES) {\n\t\t\t \n\t\t\tmlog(0, \"no bits set in the maybe_map, but %u \"\n\t\t\t     \"is asserting! (%.*s)\\n\", assert->node_idx,\n\t\t\t     namelen, name);\n\t\t} else if (bit != assert->node_idx) {\n\t\t\tif (flags & DLM_ASSERT_MASTER_MLE_CLEANUP) {\n\t\t\t\tmlog(0, \"master %u was found, %u should \"\n\t\t\t\t     \"back off\\n\", assert->node_idx, bit);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tmlog(0, \"%u is the lowest node, \"\n\t\t\t\t     \"%u is asserting. (%.*s)  %u must \"\n\t\t\t\t     \"have begun after %u won.\\n\", bit,\n\t\t\t\t     assert->node_idx, namelen, name, bit,\n\t\t\t\t     assert->node_idx);\n\t\t\t}\n\t\t}\n\t\tif (mle->type == DLM_MLE_MIGRATION) {\n\t\t\tif (flags & DLM_ASSERT_MASTER_MLE_CLEANUP) {\n\t\t\t\tmlog(0, \"%s:%.*s: got cleanup assert\"\n\t\t\t\t     \" from %u for migration\\n\",\n\t\t\t\t     dlm->name, namelen, name,\n\t\t\t\t     assert->node_idx);\n\t\t\t} else if (!(flags & DLM_ASSERT_MASTER_FINISH_MIGRATION)) {\n\t\t\t\tmlog(0, \"%s:%.*s: got unrelated assert\"\n\t\t\t\t     \" from %u for migration, ignoring\\n\",\n\t\t\t\t     dlm->name, namelen, name,\n\t\t\t\t     assert->node_idx);\n\t\t\t\t__dlm_put_mle(mle);\n\t\t\t\tspin_unlock(&dlm->master_lock);\n\t\t\t\tspin_unlock(&dlm->spinlock);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock(&dlm->master_lock);\n\n\t \n\tres = __dlm_lookup_lockres(dlm, name, namelen, hash);\n\tif (res) {\n\t\tspin_lock(&res->spinlock);\n\t\tif (res->state & DLM_LOCK_RES_RECOVERING)  {\n\t\t\tmlog(ML_ERROR, \"%u asserting but %.*s is \"\n\t\t\t     \"RECOVERING!\\n\", assert->node_idx, namelen, name);\n\t\t\tgoto kill;\n\t\t}\n\t\tif (!mle) {\n\t\t\tif (res->owner != DLM_LOCK_RES_OWNER_UNKNOWN &&\n\t\t\t    res->owner != assert->node_idx) {\n\t\t\t\tmlog(ML_ERROR, \"DIE! Mastery assert from %u, \"\n\t\t\t\t     \"but current owner is %u! (%.*s)\\n\",\n\t\t\t\t     assert->node_idx, res->owner, namelen,\n\t\t\t\t     name);\n\t\t\t\t__dlm_print_one_lock_resource(res);\n\t\t\t\tBUG();\n\t\t\t}\n\t\t} else if (mle->type != DLM_MLE_MIGRATION) {\n\t\t\tif (res->owner != DLM_LOCK_RES_OWNER_UNKNOWN) {\n\t\t\t\t \n\t\t\t\tif (res->owner == assert->node_idx) {\n\t\t\t\t\tmlog(0, \"owner %u re-asserting on \"\n\t\t\t\t\t     \"lock %.*s\\n\", assert->node_idx,\n\t\t\t\t\t     namelen, name);\n\t\t\t\t\tgoto ok;\n\t\t\t\t}\n\t\t\t\tmlog(ML_ERROR, \"got assert_master from \"\n\t\t\t\t     \"node %u, but %u is the owner! \"\n\t\t\t\t     \"(%.*s)\\n\", assert->node_idx,\n\t\t\t\t     res->owner, namelen, name);\n\t\t\t\tgoto kill;\n\t\t\t}\n\t\t\tif (!(res->state & DLM_LOCK_RES_IN_PROGRESS)) {\n\t\t\t\tmlog(ML_ERROR, \"got assert from %u, but lock \"\n\t\t\t\t     \"with no owner should be \"\n\t\t\t\t     \"in-progress! (%.*s)\\n\",\n\t\t\t\t     assert->node_idx,\n\t\t\t\t     namelen, name);\n\t\t\t\tgoto kill;\n\t\t\t}\n\t\t} else   {\n\t\t\t \n\t\t\tif (assert->node_idx != mle->new_master) {\n\t\t\t\tmlog(ML_ERROR, \"got assert from %u, but \"\n\t\t\t\t     \"new master is %u, and old master \"\n\t\t\t\t     \"was %u (%.*s)\\n\",\n\t\t\t\t     assert->node_idx, mle->new_master,\n\t\t\t\t     mle->master, namelen, name);\n\t\t\t\tgoto kill;\n\t\t\t}\n\n\t\t}\nok:\n\t\tspin_unlock(&res->spinlock);\n\t}\n\n\t \n\t \n\tif (mle) {\n\t\tint extra_ref = 0;\n\t\tint nn = -1;\n\t\tint rr, err = 0;\n\n\t\tspin_lock(&mle->spinlock);\n\t\tif (mle->type == DLM_MLE_BLOCK || mle->type == DLM_MLE_MIGRATION)\n\t\t\textra_ref = 1;\n\t\telse {\n\t\t\t \n\t\t\twhile ((nn = find_next_bit (mle->response_map, O2NM_MAX_NODES,\n\t\t\t\t\t\t    nn+1)) < O2NM_MAX_NODES) {\n\t\t\t\tif (nn != dlm->node_num && nn != assert->node_idx) {\n\t\t\t\t\tmaster_request = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmle->master = assert->node_idx;\n\t\tatomic_set(&mle->woken, 1);\n\t\twake_up(&mle->wq);\n\t\tspin_unlock(&mle->spinlock);\n\n\t\tif (res) {\n\t\t\tint wake = 0;\n\t\t\tspin_lock(&res->spinlock);\n\t\t\tif (mle->type == DLM_MLE_MIGRATION) {\n\t\t\t\tmlog(0, \"finishing off migration of lockres %.*s, \"\n\t\t\t     \t\t\"from %u to %u\\n\",\n\t\t\t       \t\tres->lockname.len, res->lockname.name,\n\t\t\t       \t\tdlm->node_num, mle->new_master);\n\t\t\t\tres->state &= ~DLM_LOCK_RES_MIGRATING;\n\t\t\t\twake = 1;\n\t\t\t\tdlm_change_lockres_owner(dlm, res, mle->new_master);\n\t\t\t\tBUG_ON(res->state & DLM_LOCK_RES_DIRTY);\n\t\t\t} else {\n\t\t\t\tdlm_change_lockres_owner(dlm, res, mle->master);\n\t\t\t}\n\t\t\tspin_unlock(&res->spinlock);\n\t\t\thave_lockres_ref = 1;\n\t\t\tif (wake)\n\t\t\t\twake_up(&res->wq);\n\t\t}\n\n\t\t \n\t\tspin_lock(&dlm->master_lock);\n\n\t\trr = kref_read(&mle->mle_refs);\n\t\tif (mle->inuse > 0) {\n\t\t\tif (extra_ref && rr < 3)\n\t\t\t\terr = 1;\n\t\t\telse if (!extra_ref && rr < 2)\n\t\t\t\terr = 1;\n\t\t} else {\n\t\t\tif (extra_ref && rr < 2)\n\t\t\t\terr = 1;\n\t\t\telse if (!extra_ref && rr < 1)\n\t\t\t\terr = 1;\n\t\t}\n\t\tif (err) {\n\t\t\tmlog(ML_ERROR, \"%s:%.*s: got assert master from %u \"\n\t\t\t     \"that will mess up this node, refs=%d, extra=%d, \"\n\t\t\t     \"inuse=%d\\n\", dlm->name, namelen, name,\n\t\t\t     assert->node_idx, rr, extra_ref, mle->inuse);\n\t\t\tdlm_print_one_mle(mle);\n\t\t}\n\t\t__dlm_unlink_mle(dlm, mle);\n\t\t__dlm_mle_detach_hb_events(dlm, mle);\n\t\t__dlm_put_mle(mle);\n\t\tif (extra_ref) {\n\t\t\t \n\t\t\t__dlm_put_mle(mle);\n\t\t}\n\t\tspin_unlock(&dlm->master_lock);\n\t} else if (res) {\n\t\tif (res->owner != assert->node_idx) {\n\t\t\tmlog(0, \"assert_master from %u, but current \"\n\t\t\t     \"owner is %u (%.*s), no mle\\n\", assert->node_idx,\n\t\t\t     res->owner, namelen, name);\n\t\t}\n\t}\n\tspin_unlock(&dlm->spinlock);\n\ndone:\n\tret = 0;\n\tif (res) {\n\t\tspin_lock(&res->spinlock);\n\t\tres->state |= DLM_LOCK_RES_SETREF_INPROG;\n\t\tspin_unlock(&res->spinlock);\n\t\t*ret_data = (void *)res;\n\t}\n\tdlm_put(dlm);\n\tif (master_request) {\n\t\tmlog(0, \"need to tell master to reassert\\n\");\n\t\t \n\t\tret |= DLM_ASSERT_RESPONSE_REASSERT;\n\t\tif (!have_lockres_ref) {\n\t\t\tmlog(ML_ERROR, \"strange, got assert from %u, MASTER \"\n\t\t\t     \"mle present here for %s:%.*s, but no lockres!\\n\",\n\t\t\t     assert->node_idx, dlm->name, namelen, name);\n\t\t}\n\t}\n\tif (have_lockres_ref) {\n\t\t \n\t\tret |= DLM_ASSERT_RESPONSE_MASTERY_REF;\n\t\tmlog(0, \"%s:%.*s: got assert from %u, need a ref\\n\",\n\t\t     dlm->name, namelen, name, assert->node_idx);\n\t}\n\treturn ret;\n\nkill:\n\t \n\tmlog(ML_ERROR, \"Bad message received from another node.  Dumping state \"\n\t     \"and killing the other node now!  This node is OK and can continue.\\n\");\n\t__dlm_print_one_lock_resource(res);\n\tspin_unlock(&res->spinlock);\n\tspin_lock(&dlm->master_lock);\n\tif (mle)\n\t\t__dlm_put_mle(mle);\n\tspin_unlock(&dlm->master_lock);\n\tspin_unlock(&dlm->spinlock);\n\t*ret_data = (void *)res;\n\tdlm_put(dlm);\n\treturn -EINVAL;\n}\n\nvoid dlm_assert_master_post_handler(int status, void *data, void *ret_data)\n{\n\tstruct dlm_lock_resource *res = (struct dlm_lock_resource *)ret_data;\n\n\tif (ret_data) {\n\t\tspin_lock(&res->spinlock);\n\t\tres->state &= ~DLM_LOCK_RES_SETREF_INPROG;\n\t\tspin_unlock(&res->spinlock);\n\t\twake_up(&res->wq);\n\t\tdlm_lockres_put(res);\n\t}\n\treturn;\n}\n\nint dlm_dispatch_assert_master(struct dlm_ctxt *dlm,\n\t\t\t       struct dlm_lock_resource *res,\n\t\t\t       int ignore_higher, u8 request_from, u32 flags)\n{\n\tstruct dlm_work_item *item;\n\titem = kzalloc(sizeof(*item), GFP_ATOMIC);\n\tif (!item)\n\t\treturn -ENOMEM;\n\n\n\t \n\tdlm_init_work_item(dlm, item, dlm_assert_master_worker, NULL);\n\titem->u.am.lockres = res;  \n\t \n\titem->u.am.ignore_higher = ignore_higher;\n\titem->u.am.request_from = request_from;\n\titem->u.am.flags = flags;\n\n\tif (ignore_higher)\n\t\tmlog(0, \"IGNORE HIGHER: %.*s\\n\", res->lockname.len,\n\t\t     res->lockname.name);\n\n\tspin_lock(&dlm->work_lock);\n\tlist_add_tail(&item->list, &dlm->work_list);\n\tspin_unlock(&dlm->work_lock);\n\n\tqueue_work(dlm->dlm_worker, &dlm->dispatched_work);\n\treturn 0;\n}\n\nstatic void dlm_assert_master_worker(struct dlm_work_item *item, void *data)\n{\n\tstruct dlm_ctxt *dlm = data;\n\tint ret = 0;\n\tstruct dlm_lock_resource *res;\n\tunsigned long nodemap[BITS_TO_LONGS(O2NM_MAX_NODES)];\n\tint ignore_higher;\n\tint bit;\n\tu8 request_from;\n\tu32 flags;\n\n\tdlm = item->dlm;\n\tres = item->u.am.lockres;\n\tignore_higher = item->u.am.ignore_higher;\n\trequest_from = item->u.am.request_from;\n\tflags = item->u.am.flags;\n\n\tspin_lock(&dlm->spinlock);\n\tbitmap_copy(nodemap, dlm->domain_map, O2NM_MAX_NODES);\n\tspin_unlock(&dlm->spinlock);\n\n\tclear_bit(dlm->node_num, nodemap);\n\tif (ignore_higher) {\n\t\t \n\t\tclear_bit(request_from, nodemap);\n\t\tbit = dlm->node_num;\n\t\twhile (1) {\n\t\t\tbit = find_next_bit(nodemap, O2NM_MAX_NODES,\n\t\t\t\t\t    bit+1);\n\t\t       \tif (bit >= O2NM_MAX_NODES)\n\t\t\t\tbreak;\n\t\t\tclear_bit(bit, nodemap);\n\t\t}\n\t}\n\n\t \n\tspin_lock(&res->spinlock);\n\tif (res->state & DLM_LOCK_RES_MIGRATING) {\n\t\tmlog(0, \"Someone asked us to assert mastery, but we're \"\n\t\t     \"in the middle of migration.  Skipping assert, \"\n\t\t     \"the new master will handle that.\\n\");\n\t\tspin_unlock(&res->spinlock);\n\t\tgoto put;\n\t} else\n\t\t__dlm_lockres_reserve_ast(res);\n\tspin_unlock(&res->spinlock);\n\n\t \n\tmlog(0, \"worker about to master %.*s here, this=%u\\n\",\n\t\t     res->lockname.len, res->lockname.name, dlm->node_num);\n\tret = dlm_do_assert_master(dlm, res, nodemap, flags);\n\tif (ret < 0) {\n\t\t \n\t\tif (!dlm_is_host_down(ret))\n\t\t\tmlog_errno(ret);\n\t}\n\n\t \n\tdlm_lockres_release_ast(dlm, res);\n\nput:\n\tdlm_lockres_drop_inflight_worker(dlm, res);\n\n\tdlm_lockres_put(res);\n\n\tmlog(0, \"finished with dlm_assert_master_worker\\n\");\n}\n\n \nstatic int dlm_pre_master_reco_lockres(struct dlm_ctxt *dlm,\n\t\t\t\t       struct dlm_lock_resource *res)\n{\n\tstruct dlm_node_iter iter;\n\tint nodenum;\n\tint ret = 0;\n\tu8 master = DLM_LOCK_RES_OWNER_UNKNOWN;\n\n\tspin_lock(&dlm->spinlock);\n\tdlm_node_iter_init(dlm->domain_map, &iter);\n\tspin_unlock(&dlm->spinlock);\n\n\twhile ((nodenum = dlm_node_iter_next(&iter)) >= 0) {\n\t\t \n\t\tif (nodenum == dlm->node_num)\n\t\t\tcontinue;\n\t\tret = dlm_do_master_requery(dlm, res, nodenum, &master);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tif (!dlm_is_host_down(ret))\n\t\t\t\tBUG();\n\t\t\t \n\t\t\tret = 0;\n\t\t}\n\n\t\tif (master != DLM_LOCK_RES_OWNER_UNKNOWN) {\n\t\t\t \n\t\t\tspin_lock(&dlm->spinlock);\n\t\t\tif (test_bit(master, dlm->recovery_map)) {\n\t\t\t\tmlog(ML_NOTICE, \"%s: node %u has not seen \"\n\t\t\t\t     \"node %u go down yet, and thinks the \"\n\t\t\t\t     \"dead node is mastering the recovery \"\n\t\t\t\t     \"lock.  must wait.\\n\", dlm->name,\n\t\t\t\t     nodenum, master);\n\t\t\t\tret = -EAGAIN;\n\t\t\t}\n\t\t\tspin_unlock(&dlm->spinlock);\n\t\t\tmlog(0, \"%s: reco lock master is %u\\n\", dlm->name,\n\t\t\t     master);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn ret;\n}\n\n \n\nint dlm_drop_lockres_ref(struct dlm_ctxt *dlm, struct dlm_lock_resource *res)\n{\n\tstruct dlm_deref_lockres deref;\n\tint ret = 0, r;\n\tconst char *lockname;\n\tunsigned int namelen;\n\n\tlockname = res->lockname.name;\n\tnamelen = res->lockname.len;\n\tBUG_ON(namelen > O2NM_MAX_NAME_LEN);\n\n\tmemset(&deref, 0, sizeof(deref));\n\tderef.node_idx = dlm->node_num;\n\tderef.namelen = namelen;\n\tmemcpy(deref.name, lockname, namelen);\n\n\tret = o2net_send_message(DLM_DEREF_LOCKRES_MSG, dlm->key,\n\t\t\t\t &deref, sizeof(deref), res->owner, &r);\n\tif (ret < 0)\n\t\tmlog(ML_ERROR, \"%s: res %.*s, error %d send DEREF to node %u\\n\",\n\t\t     dlm->name, namelen, lockname, ret, res->owner);\n\telse if (r < 0) {\n\t\t \n\t\tmlog(ML_ERROR, \"%s: res %.*s, DEREF to node %u got %d\\n\",\n\t\t     dlm->name, namelen, lockname, res->owner, r);\n\t\tdlm_print_one_lock_resource(res);\n\t\tif (r == -ENOMEM)\n\t\t\tBUG();\n\t} else\n\t\tret = r;\n\n\treturn ret;\n}\n\nint dlm_deref_lockres_handler(struct o2net_msg *msg, u32 len, void *data,\n\t\t\t      void **ret_data)\n{\n\tstruct dlm_ctxt *dlm = data;\n\tstruct dlm_deref_lockres *deref = (struct dlm_deref_lockres *)msg->buf;\n\tstruct dlm_lock_resource *res = NULL;\n\tchar *name;\n\tunsigned int namelen;\n\tint ret = -EINVAL;\n\tu8 node;\n\tunsigned int hash;\n\tstruct dlm_work_item *item;\n\tint cleared = 0;\n\tint dispatch = 0;\n\n\tif (!dlm_grab(dlm))\n\t\treturn 0;\n\n\tname = deref->name;\n\tnamelen = deref->namelen;\n\tnode = deref->node_idx;\n\n\tif (namelen > DLM_LOCKID_NAME_MAX) {\n\t\tmlog(ML_ERROR, \"Invalid name length!\");\n\t\tgoto done;\n\t}\n\tif (deref->node_idx >= O2NM_MAX_NODES) {\n\t\tmlog(ML_ERROR, \"Invalid node number: %u\\n\", node);\n\t\tgoto done;\n\t}\n\n\thash = dlm_lockid_hash(name, namelen);\n\n\tspin_lock(&dlm->spinlock);\n\tres = __dlm_lookup_lockres_full(dlm, name, namelen, hash);\n\tif (!res) {\n\t\tspin_unlock(&dlm->spinlock);\n\t\tmlog(ML_ERROR, \"%s:%.*s: bad lockres name\\n\",\n\t\t     dlm->name, namelen, name);\n\t\tgoto done;\n\t}\n\tspin_unlock(&dlm->spinlock);\n\n\tspin_lock(&res->spinlock);\n\tif (res->state & DLM_LOCK_RES_SETREF_INPROG)\n\t\tdispatch = 1;\n\telse {\n\t\tBUG_ON(res->state & DLM_LOCK_RES_DROPPING_REF);\n\t\tif (test_bit(node, res->refmap)) {\n\t\t\tdlm_lockres_clear_refmap_bit(dlm, res, node);\n\t\t\tcleared = 1;\n\t\t}\n\t}\n\tspin_unlock(&res->spinlock);\n\n\tif (!dispatch) {\n\t\tif (cleared)\n\t\t\tdlm_lockres_calc_usage(dlm, res);\n\t\telse {\n\t\t\tmlog(ML_ERROR, \"%s:%.*s: node %u trying to drop ref \"\n\t\t     \t\"but it is already dropped!\\n\", dlm->name,\n\t\t     \tres->lockname.len, res->lockname.name, node);\n\t\t\tdlm_print_one_lock_resource(res);\n\t\t}\n\t\tret = DLM_DEREF_RESPONSE_DONE;\n\t\tgoto done;\n\t}\n\n\titem = kzalloc(sizeof(*item), GFP_NOFS);\n\tif (!item) {\n\t\tret = -ENOMEM;\n\t\tmlog_errno(ret);\n\t\tgoto done;\n\t}\n\n\tdlm_init_work_item(dlm, item, dlm_deref_lockres_worker, NULL);\n\titem->u.dl.deref_res = res;\n\titem->u.dl.deref_node = node;\n\n\tspin_lock(&dlm->work_lock);\n\tlist_add_tail(&item->list, &dlm->work_list);\n\tspin_unlock(&dlm->work_lock);\n\n\tqueue_work(dlm->dlm_worker, &dlm->dispatched_work);\n\treturn DLM_DEREF_RESPONSE_INPROG;\n\ndone:\n\tif (res)\n\t\tdlm_lockres_put(res);\n\tdlm_put(dlm);\n\n\treturn ret;\n}\n\nint dlm_deref_lockres_done_handler(struct o2net_msg *msg, u32 len, void *data,\n\t\t\t      void **ret_data)\n{\n\tstruct dlm_ctxt *dlm = data;\n\tstruct dlm_deref_lockres_done *deref\n\t\t\t= (struct dlm_deref_lockres_done *)msg->buf;\n\tstruct dlm_lock_resource *res = NULL;\n\tchar *name;\n\tunsigned int namelen;\n\tint ret = -EINVAL;\n\tu8 node;\n\tunsigned int hash;\n\n\tif (!dlm_grab(dlm))\n\t\treturn 0;\n\n\tname = deref->name;\n\tnamelen = deref->namelen;\n\tnode = deref->node_idx;\n\n\tif (namelen > DLM_LOCKID_NAME_MAX) {\n\t\tmlog(ML_ERROR, \"Invalid name length!\");\n\t\tgoto done;\n\t}\n\tif (deref->node_idx >= O2NM_MAX_NODES) {\n\t\tmlog(ML_ERROR, \"Invalid node number: %u\\n\", node);\n\t\tgoto done;\n\t}\n\n\thash = dlm_lockid_hash(name, namelen);\n\n\tspin_lock(&dlm->spinlock);\n\tres = __dlm_lookup_lockres_full(dlm, name, namelen, hash);\n\tif (!res) {\n\t\tspin_unlock(&dlm->spinlock);\n\t\tmlog(ML_ERROR, \"%s:%.*s: bad lockres name\\n\",\n\t\t     dlm->name, namelen, name);\n\t\tgoto done;\n\t}\n\n\tspin_lock(&res->spinlock);\n\tif (!(res->state & DLM_LOCK_RES_DROPPING_REF)) {\n\t\tspin_unlock(&res->spinlock);\n\t\tspin_unlock(&dlm->spinlock);\n\t\tmlog(ML_NOTICE, \"%s:%.*s: node %u sends deref done \"\n\t\t\t\"but it is already derefed!\\n\", dlm->name,\n\t\t\tres->lockname.len, res->lockname.name, node);\n\t\tret = 0;\n\t\tgoto done;\n\t}\n\n\t__dlm_do_purge_lockres(dlm, res);\n\tspin_unlock(&res->spinlock);\n\twake_up(&res->wq);\n\n\tspin_unlock(&dlm->spinlock);\n\n\tret = 0;\ndone:\n\tif (res)\n\t\tdlm_lockres_put(res);\n\tdlm_put(dlm);\n\treturn ret;\n}\n\nstatic void dlm_drop_lockres_ref_done(struct dlm_ctxt *dlm,\n\t\tstruct dlm_lock_resource *res, u8 node)\n{\n\tstruct dlm_deref_lockres_done deref;\n\tint ret = 0, r;\n\tconst char *lockname;\n\tunsigned int namelen;\n\n\tlockname = res->lockname.name;\n\tnamelen = res->lockname.len;\n\tBUG_ON(namelen > O2NM_MAX_NAME_LEN);\n\n\tmemset(&deref, 0, sizeof(deref));\n\tderef.node_idx = dlm->node_num;\n\tderef.namelen = namelen;\n\tmemcpy(deref.name, lockname, namelen);\n\n\tret = o2net_send_message(DLM_DEREF_LOCKRES_DONE, dlm->key,\n\t\t\t\t &deref, sizeof(deref), node, &r);\n\tif (ret < 0) {\n\t\tmlog(ML_ERROR, \"%s: res %.*s, error %d send DEREF DONE \"\n\t\t\t\t\" to node %u\\n\", dlm->name, namelen,\n\t\t\t\tlockname, ret, node);\n\t} else if (r < 0) {\n\t\t \n\t\tmlog(ML_ERROR, \"%s: res %.*s, DEREF to node %u got %d\\n\",\n\t\t     dlm->name, namelen, lockname, node, r);\n\t\tdlm_print_one_lock_resource(res);\n\t}\n}\n\nstatic void dlm_deref_lockres_worker(struct dlm_work_item *item, void *data)\n{\n\tstruct dlm_ctxt *dlm;\n\tstruct dlm_lock_resource *res;\n\tu8 node;\n\tu8 cleared = 0;\n\n\tdlm = item->dlm;\n\tres = item->u.dl.deref_res;\n\tnode = item->u.dl.deref_node;\n\n\tspin_lock(&res->spinlock);\n\tBUG_ON(res->state & DLM_LOCK_RES_DROPPING_REF);\n\t__dlm_wait_on_lockres_flags(res, DLM_LOCK_RES_SETREF_INPROG);\n\tif (test_bit(node, res->refmap)) {\n\t\tdlm_lockres_clear_refmap_bit(dlm, res, node);\n\t\tcleared = 1;\n\t}\n\tspin_unlock(&res->spinlock);\n\n\tdlm_drop_lockres_ref_done(dlm, res, node);\n\n\tif (cleared) {\n\t\tmlog(0, \"%s:%.*s node %u ref dropped in dispatch\\n\",\n\t\t     dlm->name, res->lockname.len, res->lockname.name, node);\n\t\tdlm_lockres_calc_usage(dlm, res);\n\t} else {\n\t\tmlog(ML_ERROR, \"%s:%.*s: node %u trying to drop ref \"\n\t\t     \"but it is already dropped!\\n\", dlm->name,\n\t\t     res->lockname.len, res->lockname.name, node);\n\t\tdlm_print_one_lock_resource(res);\n\t}\n\n\tdlm_lockres_put(res);\n}\n\n \nstatic int dlm_is_lockres_migratable(struct dlm_ctxt *dlm,\n\t\t\t\t      struct dlm_lock_resource *res)\n{\n\tenum dlm_lockres_list idx;\n\tint nonlocal = 0, node_ref;\n\tstruct list_head *queue;\n\tstruct dlm_lock *lock;\n\tu64 cookie;\n\n\tassert_spin_locked(&res->spinlock);\n\n\t \n\tif (res->state & DLM_LOCK_RES_MIGRATING)\n\t\treturn 0;\n\n\t \n\tif (res->state & (DLM_LOCK_RES_RECOVERING|\n\t\t\tDLM_LOCK_RES_RECOVERY_WAITING))\n\t\treturn 0;\n\n\tif (res->owner != dlm->node_num)\n\t\treturn 0;\n\n        for (idx = DLM_GRANTED_LIST; idx <= DLM_BLOCKED_LIST; idx++) {\n\t\tqueue = dlm_list_idx_to_ptr(res, idx);\n\t\tlist_for_each_entry(lock, queue, list) {\n\t\t\tif (lock->ml.node != dlm->node_num) {\n\t\t\t\tnonlocal++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tcookie = be64_to_cpu(lock->ml.cookie);\n\t\t\tmlog(0, \"%s: Not migratable res %.*s, lock %u:%llu on \"\n\t\t\t     \"%s list\\n\", dlm->name, res->lockname.len,\n\t\t\t     res->lockname.name,\n\t\t\t     dlm_get_lock_cookie_node(cookie),\n\t\t\t     dlm_get_lock_cookie_seq(cookie),\n\t\t\t     dlm_list_in_text(idx));\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (!nonlocal) {\n\t\tnode_ref = find_first_bit(res->refmap, O2NM_MAX_NODES);\n\t\tif (node_ref >= O2NM_MAX_NODES)\n\t\t\treturn 0;\n\t}\n\n\tmlog(0, \"%s: res %.*s, Migratable\\n\", dlm->name, res->lockname.len,\n\t     res->lockname.name);\n\n\treturn 1;\n}\n\n \n\n\nstatic int dlm_migrate_lockres(struct dlm_ctxt *dlm,\n\t\t\t       struct dlm_lock_resource *res, u8 target)\n{\n\tstruct dlm_master_list_entry *mle = NULL;\n\tstruct dlm_master_list_entry *oldmle = NULL;\n \tstruct dlm_migratable_lockres *mres = NULL;\n\tint ret = 0;\n\tconst char *name;\n\tunsigned int namelen;\n\tint mle_added = 0;\n\tint wake = 0;\n\n\tif (!dlm_grab(dlm))\n\t\treturn -EINVAL;\n\n\tname = res->lockname.name;\n\tnamelen = res->lockname.len;\n\n\tmlog(0, \"%s: Migrating %.*s to node %u\\n\", dlm->name, namelen, name,\n\t     target);\n\n\t \n\tret = -ENOMEM;\n\tmres = (struct dlm_migratable_lockres *) __get_free_page(GFP_NOFS);\n\tif (!mres) {\n\t\tmlog_errno(ret);\n\t\tgoto leave;\n\t}\n\n\tmle = kmem_cache_alloc(dlm_mle_cache, GFP_NOFS);\n\tif (!mle) {\n\t\tmlog_errno(ret);\n\t\tgoto leave;\n\t}\n\tret = 0;\n\n\t \n\tspin_lock(&dlm->spinlock);\n\tspin_lock(&dlm->master_lock);\n\tret = dlm_add_migration_mle(dlm, res, mle, &oldmle, name,\n\t\t\t\t    namelen, target, dlm->node_num);\n\t \n\tif (ret != -EEXIST)\n\t\tdlm_get_mle_inuse(mle);\n\n\tspin_unlock(&dlm->master_lock);\n\tspin_unlock(&dlm->spinlock);\n\n\tif (ret == -EEXIST) {\n\t\tmlog(0, \"another process is already migrating it\\n\");\n\t\tgoto fail;\n\t}\n\tmle_added = 1;\n\n\t \n\tif (dlm_mark_lockres_migrating(dlm, res, target) < 0) {\n\t\tmlog(ML_ERROR, \"tried to migrate %.*s to %u, but \"\n\t\t     \"the target went down.\\n\", res->lockname.len,\n\t\t     res->lockname.name, target);\n\t\tspin_lock(&res->spinlock);\n\t\tres->state &= ~DLM_LOCK_RES_MIGRATING;\n\t\twake = 1;\n\t\tspin_unlock(&res->spinlock);\n\t\tret = -EINVAL;\n\t}\n\nfail:\n\tif (ret != -EEXIST && oldmle) {\n\t\t \n\t\tdlm_mle_detach_hb_events(dlm, oldmle);\n\t\tdlm_put_mle(oldmle);\n\t}\n\n\tif (ret < 0) {\n\t\tif (mle_added) {\n\t\t\tdlm_mle_detach_hb_events(dlm, mle);\n\t\t\tdlm_put_mle(mle);\n\t\t\tdlm_put_mle_inuse(mle);\n\t\t} else if (mle) {\n\t\t\tkmem_cache_free(dlm_mle_cache, mle);\n\t\t\tmle = NULL;\n\t\t}\n\t\tgoto leave;\n\t}\n\n\t \n\n\t \n\tflush_workqueue(dlm->dlm_worker);\n\n\t \n\t \n\tret = dlm_send_one_lockres(dlm, res, mres, target,\n\t\t\t\t   DLM_MRES_MIGRATION);\n\n\tif (ret < 0) {\n\t\tmlog(0, \"migration to node %u failed with %d\\n\",\n\t\t     target, ret);\n\t\t \n\t\tdlm_mle_detach_hb_events(dlm, mle);\n\t\tdlm_put_mle(mle);\n\t\tdlm_put_mle_inuse(mle);\n\t\tspin_lock(&res->spinlock);\n\t\tres->state &= ~DLM_LOCK_RES_MIGRATING;\n\t\twake = 1;\n\t\tspin_unlock(&res->spinlock);\n\t\tif (dlm_is_host_down(ret))\n\t\t\tdlm_wait_for_node_death(dlm, target,\n\t\t\t\t\t\tDLM_NODE_DEATH_WAIT_MAX);\n\t\tgoto leave;\n\t}\n\n\t \n\n\n\t \n\twhile (1) {\n\t\tret = wait_event_interruptible_timeout(mle->wq,\n\t\t\t\t\t(atomic_read(&mle->woken) == 1),\n\t\t\t\t\tmsecs_to_jiffies(5000));\n\n\t\tif (ret >= 0) {\n\t\t       \tif (atomic_read(&mle->woken) == 1 ||\n\t\t\t    res->owner == target)\n\t\t\t\tbreak;\n\n\t\t\tmlog(0, \"%s:%.*s: timed out during migration\\n\",\n\t\t\t     dlm->name, res->lockname.len, res->lockname.name);\n\t\t\t \n\t\t\tif (dlm_is_node_dead(dlm, target)) {\n\t\t\t\tmlog(0, \"%s:%.*s: expected migration \"\n\t\t\t\t     \"target %u is no longer up, restarting\\n\",\n\t\t\t\t     dlm->name, res->lockname.len,\n\t\t\t\t     res->lockname.name, target);\n\t\t\t\tret = -EINVAL;\n\t\t\t\t \n\t\t\t\tdlm_mle_detach_hb_events(dlm, mle);\n\t\t\t\tdlm_put_mle(mle);\n\t\t\t\tdlm_put_mle_inuse(mle);\n\t\t\t\tspin_lock(&res->spinlock);\n\t\t\t\tres->state &= ~DLM_LOCK_RES_MIGRATING;\n\t\t\t\twake = 1;\n\t\t\t\tspin_unlock(&res->spinlock);\n\t\t\t\tgoto leave;\n\t\t\t}\n\t\t} else\n\t\t\tmlog(0, \"%s:%.*s: caught signal during migration\\n\",\n\t\t\t     dlm->name, res->lockname.len, res->lockname.name);\n\t}\n\n\t \n\tspin_lock(&res->spinlock);\n\tdlm_set_lockres_owner(dlm, res, target);\n\tres->state &= ~DLM_LOCK_RES_MIGRATING;\n\tdlm_remove_nonlocal_locks(dlm, res);\n\tspin_unlock(&res->spinlock);\n\twake_up(&res->wq);\n\n\t \n\tdlm_mle_detach_hb_events(dlm, mle);\n\tdlm_put_mle_inuse(mle);\n\tret = 0;\n\n\tdlm_lockres_calc_usage(dlm, res);\n\nleave:\n\t \n\tif (ret < 0)\n\t\tdlm_kick_thread(dlm, res);\n\n\t \n\tif (wake)\n\t\twake_up(&res->wq);\n\n\tif (mres)\n\t\tfree_page((unsigned long)mres);\n\n\tdlm_put(dlm);\n\n\tmlog(0, \"%s: Migrating %.*s to %u, returns %d\\n\", dlm->name, namelen,\n\t     name, target, ret);\n\treturn ret;\n}\n\n \nint dlm_empty_lockres(struct dlm_ctxt *dlm, struct dlm_lock_resource *res)\n\t__must_hold(&dlm->spinlock)\n{\n\tint ret;\n\tint lock_dropped = 0;\n\tu8 target = O2NM_MAX_NODES;\n\n\tassert_spin_locked(&dlm->spinlock);\n\n\tspin_lock(&res->spinlock);\n\tif (dlm_is_lockres_migratable(dlm, res))\n\t\ttarget = dlm_pick_migration_target(dlm, res);\n\tspin_unlock(&res->spinlock);\n\n\tif (target == O2NM_MAX_NODES)\n\t\tgoto leave;\n\n\t \n\tspin_unlock(&dlm->spinlock);\n\tlock_dropped = 1;\n\tret = dlm_migrate_lockres(dlm, res, target);\n\tif (ret)\n\t\tmlog(0, \"%s: res %.*s, Migrate to node %u failed with %d\\n\",\n\t\t     dlm->name, res->lockname.len, res->lockname.name,\n\t\t     target, ret);\n\tspin_lock(&dlm->spinlock);\nleave:\n\treturn lock_dropped;\n}\n\nint dlm_lock_basts_flushed(struct dlm_ctxt *dlm, struct dlm_lock *lock)\n{\n\tint ret;\n\tspin_lock(&dlm->ast_lock);\n\tspin_lock(&lock->spinlock);\n\tret = (list_empty(&lock->bast_list) && !lock->bast_pending);\n\tspin_unlock(&lock->spinlock);\n\tspin_unlock(&dlm->ast_lock);\n\treturn ret;\n}\n\nstatic int dlm_migration_can_proceed(struct dlm_ctxt *dlm,\n\t\t\t\t     struct dlm_lock_resource *res,\n\t\t\t\t     u8 mig_target)\n{\n\tint can_proceed;\n\tspin_lock(&res->spinlock);\n\tcan_proceed = !!(res->state & DLM_LOCK_RES_MIGRATING);\n\tspin_unlock(&res->spinlock);\n\n\t \n\tspin_lock(&dlm->spinlock);\n\tif (!test_bit(mig_target, dlm->domain_map))\n\t\tcan_proceed = 1;\n\tspin_unlock(&dlm->spinlock);\n\treturn can_proceed;\n}\n\nstatic int dlm_lockres_is_dirty(struct dlm_ctxt *dlm,\n\t\t\t\tstruct dlm_lock_resource *res)\n{\n\tint ret;\n\tspin_lock(&res->spinlock);\n\tret = !!(res->state & DLM_LOCK_RES_DIRTY);\n\tspin_unlock(&res->spinlock);\n\treturn ret;\n}\n\n\nstatic int dlm_mark_lockres_migrating(struct dlm_ctxt *dlm,\n\t\t\t\t       struct dlm_lock_resource *res,\n\t\t\t\t       u8 target)\n{\n\tint ret = 0;\n\n\tmlog(0, \"dlm_mark_lockres_migrating: %.*s, from %u to %u\\n\",\n\t       res->lockname.len, res->lockname.name, dlm->node_num,\n\t       target);\n\t \n\tspin_lock(&res->spinlock);\n\tBUG_ON(res->migration_pending);\n\tres->migration_pending = 1;\n\t \n\t__dlm_lockres_reserve_ast(res);\n\tspin_unlock(&res->spinlock);\n\n\t \n\tdlm_kick_thread(dlm, res);\n\t \n\tspin_lock(&res->spinlock);\n\tBUG_ON(res->state & DLM_LOCK_RES_BLOCK_DIRTY);\n\tres->state |= DLM_LOCK_RES_BLOCK_DIRTY;\n\tspin_unlock(&res->spinlock);\n\t \n\twait_event(dlm->ast_wq, !dlm_lockres_is_dirty(dlm, res));\n\tdlm_lockres_release_ast(dlm, res);\n\n\tmlog(0, \"about to wait on migration_wq, dirty=%s\\n\",\n\t       res->state & DLM_LOCK_RES_DIRTY ? \"yes\" : \"no\");\n\t \nagain:\n\tret = wait_event_interruptible_timeout(dlm->migration_wq,\n\t\t   dlm_migration_can_proceed(dlm, res, target),\n\t\t   msecs_to_jiffies(1000));\n\tif (ret < 0) {\n\t\tmlog(0, \"woken again: migrating? %s, dead? %s\\n\",\n\t\t       res->state & DLM_LOCK_RES_MIGRATING ? \"yes\":\"no\",\n\t\t       test_bit(target, dlm->domain_map) ? \"no\":\"yes\");\n\t} else {\n\t\tmlog(0, \"all is well: migrating? %s, dead? %s\\n\",\n\t\t       res->state & DLM_LOCK_RES_MIGRATING ? \"yes\":\"no\",\n\t\t       test_bit(target, dlm->domain_map) ? \"no\":\"yes\");\n\t}\n\tif (!dlm_migration_can_proceed(dlm, res, target)) {\n\t\tmlog(0, \"trying again...\\n\");\n\t\tgoto again;\n\t}\n\n\tret = 0;\n\t \n\tspin_lock(&dlm->spinlock);\n\tif (!test_bit(target, dlm->domain_map)) {\n\t\tmlog(ML_ERROR, \"aha. migration target %u just went down\\n\",\n\t\t     target);\n\t\tret = -EHOSTDOWN;\n\t}\n\tspin_unlock(&dlm->spinlock);\n\n\t \n\tspin_lock(&res->spinlock);\n\tBUG_ON(!(res->state & DLM_LOCK_RES_BLOCK_DIRTY));\n\tres->state &= ~DLM_LOCK_RES_BLOCK_DIRTY;\n\tif (!ret)\n\t\tBUG_ON(!(res->state & DLM_LOCK_RES_MIGRATING));\n\telse\n\t\tres->migration_pending = 0;\n\tspin_unlock(&res->spinlock);\n\n\t \n\treturn ret;\n}\n\n \nstatic void dlm_remove_nonlocal_locks(struct dlm_ctxt *dlm,\n\t\t\t\t      struct dlm_lock_resource *res)\n{\n\tstruct list_head *queue = &res->granted;\n\tint i, bit;\n\tstruct dlm_lock *lock, *next;\n\n\tassert_spin_locked(&res->spinlock);\n\n\tBUG_ON(res->owner == dlm->node_num);\n\n\tfor (i=0; i<3; i++) {\n\t\tlist_for_each_entry_safe(lock, next, queue, list) {\n\t\t\tif (lock->ml.node != dlm->node_num) {\n\t\t\t\tmlog(0, \"putting lock for node %u\\n\",\n\t\t\t\t     lock->ml.node);\n\t\t\t\t \n\t\t\t\tBUG_ON(!list_empty(&lock->ast_list));\n\t\t\t\tBUG_ON(!list_empty(&lock->bast_list));\n\t\t\t\tBUG_ON(lock->ast_pending);\n\t\t\t\tBUG_ON(lock->bast_pending);\n\t\t\t\tdlm_lockres_clear_refmap_bit(dlm, res,\n\t\t\t\t\t\t\t     lock->ml.node);\n\t\t\t\tlist_del_init(&lock->list);\n\t\t\t\tdlm_lock_put(lock);\n\t\t\t\t \n\t\t\t\tdlm_lock_put(lock);\n\t\t\t}\n\t\t}\n\t\tqueue++;\n\t}\n\tbit = 0;\n\twhile (1) {\n\t\tbit = find_next_bit(res->refmap, O2NM_MAX_NODES, bit);\n\t\tif (bit >= O2NM_MAX_NODES)\n\t\t\tbreak;\n\t\t \n\t\tif (bit != dlm->node_num) {\n\t\t\tmlog(0, \"%s:%.*s: node %u had a ref to this \"\n\t\t\t     \"migrating lockres, clearing\\n\", dlm->name,\n\t\t\t     res->lockname.len, res->lockname.name, bit);\n\t\t\tdlm_lockres_clear_refmap_bit(dlm, res, bit);\n\t\t}\n\t\tbit++;\n\t}\n}\n\n \nstatic u8 dlm_pick_migration_target(struct dlm_ctxt *dlm,\n\t\t\t\t    struct dlm_lock_resource *res)\n{\n\tenum dlm_lockres_list idx;\n\tstruct list_head *queue;\n\tstruct dlm_lock *lock;\n\tint noderef;\n\tu8 nodenum = O2NM_MAX_NODES;\n\n\tassert_spin_locked(&dlm->spinlock);\n\tassert_spin_locked(&res->spinlock);\n\n\t \n\tfor (idx = DLM_GRANTED_LIST; idx <= DLM_BLOCKED_LIST; idx++) {\n\t\tqueue = dlm_list_idx_to_ptr(res, idx);\n\t\tlist_for_each_entry(lock, queue, list) {\n\t\t\tif (lock->ml.node == dlm->node_num)\n\t\t\t\tcontinue;\n\t\t\tif (test_bit(lock->ml.node, dlm->exit_domain_map))\n\t\t\t\tcontinue;\n\t\t\tnodenum = lock->ml.node;\n\t\t\tgoto bail;\n\t\t}\n\t}\n\n\t \n\tnoderef = -1;\n\twhile (1) {\n\t\tnoderef = find_next_bit(res->refmap, O2NM_MAX_NODES,\n\t\t\t\t\tnoderef + 1);\n\t\tif (noderef >= O2NM_MAX_NODES)\n\t\t\tbreak;\n\t\tif (noderef == dlm->node_num)\n\t\t\tcontinue;\n\t\tif (test_bit(noderef, dlm->exit_domain_map))\n\t\t\tcontinue;\n\t\tnodenum = noderef;\n\t\tgoto bail;\n\t}\n\nbail:\n\treturn nodenum;\n}\n\n \nstatic int dlm_do_migrate_request(struct dlm_ctxt *dlm,\n\t\t\t\t  struct dlm_lock_resource *res,\n\t\t\t\t  u8 master, u8 new_master,\n\t\t\t\t  struct dlm_node_iter *iter)\n{\n\tstruct dlm_migrate_request migrate;\n\tint ret, skip, status = 0;\n\tint nodenum;\n\n\tmemset(&migrate, 0, sizeof(migrate));\n\tmigrate.namelen = res->lockname.len;\n\tmemcpy(migrate.name, res->lockname.name, migrate.namelen);\n\tmigrate.new_master = new_master;\n\tmigrate.master = master;\n\n\tret = 0;\n\n\t \n\twhile ((nodenum = dlm_node_iter_next(iter)) >= 0) {\n\t\tif (nodenum == master ||\n\t\t    nodenum == new_master)\n\t\t\tcontinue;\n\n\t\t \n\t\tspin_lock(&dlm->spinlock);\n\t\tskip = (!test_bit(nodenum, dlm->domain_map));\n\t\tspin_unlock(&dlm->spinlock);\n\t\tif (skip) {\n\t\t\tclear_bit(nodenum, iter->node_map);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = o2net_send_message(DLM_MIGRATE_REQUEST_MSG, dlm->key,\n\t\t\t\t\t &migrate, sizeof(migrate), nodenum,\n\t\t\t\t\t &status);\n\t\tif (ret < 0) {\n\t\t\tmlog(ML_ERROR, \"%s: res %.*s, Error %d send \"\n\t\t\t     \"MIGRATE_REQUEST to node %u\\n\", dlm->name,\n\t\t\t     migrate.namelen, migrate.name, ret, nodenum);\n\t\t\tif (!dlm_is_host_down(ret)) {\n\t\t\t\tmlog(ML_ERROR, \"unhandled error=%d!\\n\", ret);\n\t\t\t\tBUG();\n\t\t\t}\n\t\t\tclear_bit(nodenum, iter->node_map);\n\t\t\tret = 0;\n\t\t} else if (status < 0) {\n\t\t\tmlog(0, \"migrate request (node %u) returned %d!\\n\",\n\t\t\t     nodenum, status);\n\t\t\tret = status;\n\t\t} else if (status == DLM_MIGRATE_RESPONSE_MASTERY_REF) {\n\t\t\t \n\t\t\tmlog(0, \"%s:%.*s: need ref for node %u\\n\",\n\t\t\t     dlm->name, res->lockname.len, res->lockname.name,\n\t\t\t     nodenum);\n\t\t\tspin_lock(&res->spinlock);\n\t\t\tdlm_lockres_set_refmap_bit(dlm, res, nodenum);\n\t\t\tspin_unlock(&res->spinlock);\n\t\t}\n\t}\n\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\n\tmlog(0, \"returning ret=%d\\n\", ret);\n\treturn ret;\n}\n\n\n \nint dlm_migrate_request_handler(struct o2net_msg *msg, u32 len, void *data,\n\t\t\t\tvoid **ret_data)\n{\n\tstruct dlm_ctxt *dlm = data;\n\tstruct dlm_lock_resource *res = NULL;\n\tstruct dlm_migrate_request *migrate = (struct dlm_migrate_request *) msg->buf;\n\tstruct dlm_master_list_entry *mle = NULL, *oldmle = NULL;\n\tconst char *name;\n\tunsigned int namelen, hash;\n\tint ret = 0;\n\n\tif (!dlm_grab(dlm))\n\t\treturn 0;\n\n\tname = migrate->name;\n\tnamelen = migrate->namelen;\n\thash = dlm_lockid_hash(name, namelen);\n\n\t \n\tmle = kmem_cache_alloc(dlm_mle_cache, GFP_NOFS);\n\n\tif (!mle) {\n\t\tret = -ENOMEM;\n\t\tgoto leave;\n\t}\n\n\t \n\tspin_lock(&dlm->spinlock);\n\tres = __dlm_lookup_lockres(dlm, name, namelen, hash);\n\tif (res) {\n\t\tspin_lock(&res->spinlock);\n\t\tif (res->state & DLM_LOCK_RES_RECOVERING) {\n\t\t\t \n\t\t\tspin_unlock(&res->spinlock);\n\t\t\tmlog(ML_ERROR, \"Got a migrate request, but the \"\n\t\t\t     \"lockres is marked as recovering!\");\n\t\t\tkmem_cache_free(dlm_mle_cache, mle);\n\t\t\tret = -EINVAL;  \n\t\t\tgoto unlock;\n\t\t}\n\t\tres->state |= DLM_LOCK_RES_MIGRATING;\n\t\tspin_unlock(&res->spinlock);\n\t}\n\n\tspin_lock(&dlm->master_lock);\n\t \n\tret = dlm_add_migration_mle(dlm, res, mle, &oldmle,\n\t\t\t\t    name, namelen,\n\t\t\t\t    migrate->new_master,\n\t\t\t\t    migrate->master);\n\n\tif (ret < 0)\n\t\tkmem_cache_free(dlm_mle_cache, mle);\n\n\tspin_unlock(&dlm->master_lock);\nunlock:\n\tspin_unlock(&dlm->spinlock);\n\n\tif (oldmle) {\n\t\t \n\t\tdlm_mle_detach_hb_events(dlm, oldmle);\n\t\tdlm_put_mle(oldmle);\n\t}\n\n\tif (res)\n\t\tdlm_lockres_put(res);\nleave:\n\tdlm_put(dlm);\n\treturn ret;\n}\n\n \nstatic int dlm_add_migration_mle(struct dlm_ctxt *dlm,\n\t\t\t\t struct dlm_lock_resource *res,\n\t\t\t\t struct dlm_master_list_entry *mle,\n\t\t\t\t struct dlm_master_list_entry **oldmle,\n\t\t\t\t const char *name, unsigned int namelen,\n\t\t\t\t u8 new_master, u8 master)\n{\n\tint found;\n\tint ret = 0;\n\n\t*oldmle = NULL;\n\n\tassert_spin_locked(&dlm->spinlock);\n\tassert_spin_locked(&dlm->master_lock);\n\n\t \n\tfound = dlm_find_mle(dlm, oldmle, (char *)name, namelen);\n\tif (found) {\n\t\tstruct dlm_master_list_entry *tmp = *oldmle;\n\t\tspin_lock(&tmp->spinlock);\n\t\tif (tmp->type == DLM_MLE_MIGRATION) {\n\t\t\tif (master == dlm->node_num) {\n\t\t\t\t \n\t\t\t\tmlog(0, \"tried to migrate %.*s, but some \"\n\t\t\t\t     \"process beat me to it\\n\",\n\t\t\t\t     namelen, name);\n\t\t\t\tspin_unlock(&tmp->spinlock);\n\t\t\t\treturn -EEXIST;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tmlog(ML_ERROR, \"migration error  mle: \"\n\t\t\t\t     \"master=%u new_master=%u // request: \"\n\t\t\t\t     \"master=%u new_master=%u // \"\n\t\t\t\t     \"lockres=%.*s\\n\",\n\t\t\t\t     tmp->master, tmp->new_master,\n\t\t\t\t     master, new_master,\n\t\t\t\t     namelen, name);\n\t\t\t\tBUG();\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\ttmp->master = master;\n\t\t\tatomic_set(&tmp->woken, 1);\n\t\t\twake_up(&tmp->wq);\n\t\t\t \n\t\t\t__dlm_unlink_mle(dlm, tmp);\n\t\t\t__dlm_mle_detach_hb_events(dlm, tmp);\n\t\t\tif (tmp->type == DLM_MLE_MASTER) {\n\t\t\t\tret = DLM_MIGRATE_RESPONSE_MASTERY_REF;\n\t\t\t\tmlog(0, \"%s:%.*s: master=%u, newmaster=%u, \"\n\t\t\t\t\t\t\"telling master to get ref \"\n\t\t\t\t\t\t\"for cleared out mle during \"\n\t\t\t\t\t\t\"migration\\n\", dlm->name,\n\t\t\t\t\t\tnamelen, name, master,\n\t\t\t\t\t\tnew_master);\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&tmp->spinlock);\n\t}\n\n\t \n\tdlm_init_mle(mle, DLM_MLE_MIGRATION, dlm, res, name, namelen);\n\tmle->new_master = new_master;\n\t \n\tmle->master = master;\n\t \n\tset_bit(new_master, mle->maybe_map);\n\t__dlm_insert_mle(dlm, mle);\n\n\treturn ret;\n}\n\n \nstatic struct dlm_lock_resource *dlm_reset_mleres_owner(struct dlm_ctxt *dlm,\n\t\t\t\t\tstruct dlm_master_list_entry *mle)\n{\n\tstruct dlm_lock_resource *res;\n\n\t \n\tres = __dlm_lookup_lockres(dlm, mle->mname, mle->mnamelen,\n\t\t\t\t   mle->mnamehash);\n\tif (res) {\n\t\tspin_unlock(&dlm->master_lock);\n\n\t\t \n\t\tspin_lock(&res->spinlock);\n\t\tdlm_set_lockres_owner(dlm, res, DLM_LOCK_RES_OWNER_UNKNOWN);\n\t\tdlm_move_lockres_to_recovery_list(dlm, res);\n\t\tspin_unlock(&res->spinlock);\n\t\tdlm_lockres_put(res);\n\n\t\t \n\t\t__dlm_mle_detach_hb_events(dlm, mle);\n\n\t\t \n\t\tspin_lock(&dlm->master_lock);\n\t\t__dlm_put_mle(mle);\n\t\tspin_unlock(&dlm->master_lock);\n\t}\n\n\treturn res;\n}\n\nstatic void dlm_clean_migration_mle(struct dlm_ctxt *dlm,\n\t\t\t\t    struct dlm_master_list_entry *mle)\n{\n\t__dlm_mle_detach_hb_events(dlm, mle);\n\n\tspin_lock(&mle->spinlock);\n\t__dlm_unlink_mle(dlm, mle);\n\tatomic_set(&mle->woken, 1);\n\tspin_unlock(&mle->spinlock);\n\n\twake_up(&mle->wq);\n}\n\nstatic void dlm_clean_block_mle(struct dlm_ctxt *dlm,\n\t\t\t\tstruct dlm_master_list_entry *mle, u8 dead_node)\n{\n\tint bit;\n\n\tBUG_ON(mle->type != DLM_MLE_BLOCK);\n\n\tspin_lock(&mle->spinlock);\n\tbit = find_first_bit(mle->maybe_map, O2NM_MAX_NODES);\n\tif (bit != dead_node) {\n\t\tmlog(0, \"mle found, but dead node %u would not have been \"\n\t\t     \"master\\n\", dead_node);\n\t\tspin_unlock(&mle->spinlock);\n\t} else {\n\t\t \n\t\tmlog(0, \"node %u was expected master\\n\", dead_node);\n\t\tatomic_set(&mle->woken, 1);\n\t\tspin_unlock(&mle->spinlock);\n\t\twake_up(&mle->wq);\n\n\t\t \n\t\t__dlm_mle_detach_hb_events(dlm, mle);\n\t\t__dlm_put_mle(mle);\n\t}\n}\n\nvoid dlm_clean_master_list(struct dlm_ctxt *dlm, u8 dead_node)\n{\n\tstruct dlm_master_list_entry *mle;\n\tstruct dlm_lock_resource *res;\n\tstruct hlist_head *bucket;\n\tstruct hlist_node *tmp;\n\tunsigned int i;\n\n\tmlog(0, \"dlm=%s, dead node=%u\\n\", dlm->name, dead_node);\ntop:\n\tassert_spin_locked(&dlm->spinlock);\n\n\t \n\tspin_lock(&dlm->master_lock);\n\tfor (i = 0; i < DLM_HASH_BUCKETS; i++) {\n\t\tbucket = dlm_master_hash(dlm, i);\n\t\thlist_for_each_entry_safe(mle, tmp, bucket, master_hash_node) {\n\t\t\tBUG_ON(mle->type != DLM_MLE_BLOCK &&\n\t\t\t       mle->type != DLM_MLE_MASTER &&\n\t\t\t       mle->type != DLM_MLE_MIGRATION);\n\n\t\t\t \n\t\t\tif (mle->type == DLM_MLE_MASTER)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (mle->type == DLM_MLE_BLOCK) {\n\t\t\t\tdlm_clean_block_mle(dlm, mle, dead_node);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\n\t\t\t \n\n\t\t\tif (mle->master != dead_node &&\n\t\t\t    mle->new_master != dead_node)\n\t\t\t\tcontinue;\n\n\t\t\tif (mle->new_master == dead_node && mle->inuse) {\n\t\t\t\tmlog(ML_NOTICE, \"%s: target %u died during \"\n\t\t\t\t\t\t\"migration from %u, the MLE is \"\n\t\t\t\t\t\t\"still keep used, ignore it!\\n\",\n\t\t\t\t\t\tdlm->name, dead_node,\n\t\t\t\t\t\tmle->master);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tdlm_clean_migration_mle(dlm, mle);\n\n\t\t\tmlog(0, \"%s: node %u died during migration from \"\n\t\t\t     \"%u to %u!\\n\", dlm->name, dead_node, mle->master,\n\t\t\t     mle->new_master);\n\n\t\t\t \n\t\t\tres = dlm_reset_mleres_owner(dlm, mle);\n\t\t\tif (res)\n\t\t\t\t \n\t\t\t\tgoto top;\n\n\t\t\t \n\t\t\t__dlm_put_mle(mle);\n\t\t}\n\t}\n\tspin_unlock(&dlm->master_lock);\n}\n\nint dlm_finish_migration(struct dlm_ctxt *dlm, struct dlm_lock_resource *res,\n\t\t\t u8 old_master)\n{\n\tstruct dlm_node_iter iter;\n\tint ret = 0;\n\n\tspin_lock(&dlm->spinlock);\n\tdlm_node_iter_init(dlm->domain_map, &iter);\n\tclear_bit(old_master, iter.node_map);\n\tclear_bit(dlm->node_num, iter.node_map);\n\tspin_unlock(&dlm->spinlock);\n\n\t \n\tspin_lock(&res->spinlock);\n\tdlm_lockres_set_refmap_bit(dlm, res, old_master);\n\tspin_unlock(&res->spinlock);\n\n\tmlog(0, \"now time to do a migrate request to other nodes\\n\");\n\tret = dlm_do_migrate_request(dlm, res, old_master,\n\t\t\t\t     dlm->node_num, &iter);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto leave;\n\t}\n\n\tmlog(0, \"doing assert master of %.*s to all except the original node\\n\",\n\t     res->lockname.len, res->lockname.name);\n\t \n\tret = dlm_do_assert_master(dlm, res, iter.node_map,\n\t\t\t\t   DLM_ASSERT_MASTER_FINISH_MIGRATION);\n\tif (ret < 0) {\n\t\t \n\t\tmlog_errno(ret);\n\t\tret = 0;\n\t}\n\n\tbitmap_zero(iter.node_map, O2NM_MAX_NODES);\n\tset_bit(old_master, iter.node_map);\n\tmlog(0, \"doing assert master of %.*s back to %u\\n\",\n\t     res->lockname.len, res->lockname.name, old_master);\n\tret = dlm_do_assert_master(dlm, res, iter.node_map,\n\t\t\t\t   DLM_ASSERT_MASTER_FINISH_MIGRATION);\n\tif (ret < 0) {\n\t\tmlog(0, \"assert master to original master failed \"\n\t\t     \"with %d.\\n\", ret);\n\t\t \n\t\tret = 0;\n\t}\n\n\t \n\tspin_lock(&res->spinlock);\n\tdlm_set_lockres_owner(dlm, res, dlm->node_num);\n\tres->state &= ~DLM_LOCK_RES_MIGRATING;\n\tspin_unlock(&res->spinlock);\n\t \n\tdlm_kick_thread(dlm, res);\n\twake_up(&res->wq);\nleave:\n\treturn ret;\n}\n\n \n\n \nvoid __dlm_lockres_reserve_ast(struct dlm_lock_resource *res)\n{\n\tassert_spin_locked(&res->spinlock);\n\tif (res->state & DLM_LOCK_RES_MIGRATING) {\n\t\t__dlm_print_one_lock_resource(res);\n\t}\n\tBUG_ON(res->state & DLM_LOCK_RES_MIGRATING);\n\n\tatomic_inc(&res->asts_reserved);\n}\n\n \nvoid dlm_lockres_release_ast(struct dlm_ctxt *dlm,\n\t\t\t     struct dlm_lock_resource *res)\n{\n\tif (!atomic_dec_and_lock(&res->asts_reserved, &res->spinlock))\n\t\treturn;\n\n\tif (!res->migration_pending) {\n\t\tspin_unlock(&res->spinlock);\n\t\treturn;\n\t}\n\n\tBUG_ON(res->state & DLM_LOCK_RES_MIGRATING);\n\tres->migration_pending = 0;\n\tres->state |= DLM_LOCK_RES_MIGRATING;\n\tspin_unlock(&res->spinlock);\n\twake_up(&res->wq);\n\twake_up(&dlm->migration_wq);\n}\n\nvoid dlm_force_free_mles(struct dlm_ctxt *dlm)\n{\n\tint i;\n\tstruct hlist_head *bucket;\n\tstruct dlm_master_list_entry *mle;\n\tstruct hlist_node *tmp;\n\n\t \n\tspin_lock(&dlm->spinlock);\n\tspin_lock(&dlm->master_lock);\n\n\tBUG_ON(dlm->dlm_state != DLM_CTXT_LEAVING);\n\tBUG_ON((find_first_bit(dlm->domain_map, O2NM_MAX_NODES) < O2NM_MAX_NODES));\n\n\tfor (i = 0; i < DLM_HASH_BUCKETS; i++) {\n\t\tbucket = dlm_master_hash(dlm, i);\n\t\thlist_for_each_entry_safe(mle, tmp, bucket, master_hash_node) {\n\t\t\tif (mle->type != DLM_MLE_BLOCK) {\n\t\t\t\tmlog(ML_ERROR, \"bad mle: %p\\n\", mle);\n\t\t\t\tdlm_print_one_mle(mle);\n\t\t\t}\n\t\t\tatomic_set(&mle->woken, 1);\n\t\t\twake_up(&mle->wq);\n\n\t\t\t__dlm_unlink_mle(dlm, mle);\n\t\t\t__dlm_mle_detach_hb_events(dlm, mle);\n\t\t\t__dlm_put_mle(mle);\n\t\t}\n\t}\n\tspin_unlock(&dlm->master_lock);\n\tspin_unlock(&dlm->spinlock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}