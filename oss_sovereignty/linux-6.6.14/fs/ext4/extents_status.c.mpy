{
  "module_name": "extents_status.c",
  "hash_id": "e4985d6b7ea712cead1f72e1509d1e99de2f50d241c950e1c5f44e58d47ff46c",
  "original_prompt": "Ingested from linux-6.6.14/fs/ext4/extents_status.c",
  "human_readable_source": "\n \n#include <linux/list_sort.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include \"ext4.h\"\n\n#include <trace/events/ext4.h>\n\n \n\n \n\nstatic struct kmem_cache *ext4_es_cachep;\nstatic struct kmem_cache *ext4_pending_cachep;\n\nstatic int __es_insert_extent(struct inode *inode, struct extent_status *newes,\n\t\t\t      struct extent_status *prealloc);\nstatic int __es_remove_extent(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t      ext4_lblk_t end, int *reserved,\n\t\t\t      struct extent_status *prealloc);\nstatic int es_reclaim_extents(struct ext4_inode_info *ei, int *nr_to_scan);\nstatic int __es_shrink(struct ext4_sb_info *sbi, int nr_to_scan,\n\t\t       struct ext4_inode_info *locked_ei);\nstatic int __revise_pending(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t    ext4_lblk_t len,\n\t\t\t    struct pending_reservation **prealloc);\n\nint __init ext4_init_es(void)\n{\n\text4_es_cachep = KMEM_CACHE(extent_status, SLAB_RECLAIM_ACCOUNT);\n\tif (ext4_es_cachep == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid ext4_exit_es(void)\n{\n\tkmem_cache_destroy(ext4_es_cachep);\n}\n\nvoid ext4_es_init_tree(struct ext4_es_tree *tree)\n{\n\ttree->root = RB_ROOT;\n\ttree->cache_es = NULL;\n}\n\n#ifdef ES_DEBUG__\nstatic void ext4_es_print_tree(struct inode *inode)\n{\n\tstruct ext4_es_tree *tree;\n\tstruct rb_node *node;\n\n\tprintk(KERN_DEBUG \"status extents for inode %lu:\", inode->i_ino);\n\ttree = &EXT4_I(inode)->i_es_tree;\n\tnode = rb_first(&tree->root);\n\twhile (node) {\n\t\tstruct extent_status *es;\n\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t\tprintk(KERN_DEBUG \" [%u/%u) %llu %x\",\n\t\t       es->es_lblk, es->es_len,\n\t\t       ext4_es_pblock(es), ext4_es_status(es));\n\t\tnode = rb_next(node);\n\t}\n\tprintk(KERN_DEBUG \"\\n\");\n}\n#else\n#define ext4_es_print_tree(inode)\n#endif\n\nstatic inline ext4_lblk_t ext4_es_end(struct extent_status *es)\n{\n\tBUG_ON(es->es_lblk + es->es_len < es->es_lblk);\n\treturn es->es_lblk + es->es_len - 1;\n}\n\n \nstatic struct extent_status *__es_tree_search(struct rb_root *root,\n\t\t\t\t\t      ext4_lblk_t lblk)\n{\n\tstruct rb_node *node = root->rb_node;\n\tstruct extent_status *es = NULL;\n\n\twhile (node) {\n\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t\tif (lblk < es->es_lblk)\n\t\t\tnode = node->rb_left;\n\t\telse if (lblk > ext4_es_end(es))\n\t\t\tnode = node->rb_right;\n\t\telse\n\t\t\treturn es;\n\t}\n\n\tif (es && lblk < es->es_lblk)\n\t\treturn es;\n\n\tif (es && lblk > ext4_es_end(es)) {\n\t\tnode = rb_next(&es->rb_node);\n\t\treturn node ? rb_entry(node, struct extent_status, rb_node) :\n\t\t\t      NULL;\n\t}\n\n\treturn NULL;\n}\n\n \nstatic void __es_find_extent_range(struct inode *inode,\n\t\t\t\t   int (*matching_fn)(struct extent_status *es),\n\t\t\t\t   ext4_lblk_t lblk, ext4_lblk_t end,\n\t\t\t\t   struct extent_status *es)\n{\n\tstruct ext4_es_tree *tree = NULL;\n\tstruct extent_status *es1 = NULL;\n\tstruct rb_node *node;\n\n\tWARN_ON(es == NULL);\n\tWARN_ON(end < lblk);\n\n\ttree = &EXT4_I(inode)->i_es_tree;\n\n\t \n\tes->es_lblk = es->es_len = es->es_pblk = 0;\n\tes1 = READ_ONCE(tree->cache_es);\n\tif (es1 && in_range(lblk, es1->es_lblk, es1->es_len)) {\n\t\tes_debug(\"%u cached by [%u/%u) %llu %x\\n\",\n\t\t\t lblk, es1->es_lblk, es1->es_len,\n\t\t\t ext4_es_pblock(es1), ext4_es_status(es1));\n\t\tgoto out;\n\t}\n\n\tes1 = __es_tree_search(&tree->root, lblk);\n\nout:\n\tif (es1 && !matching_fn(es1)) {\n\t\twhile ((node = rb_next(&es1->rb_node)) != NULL) {\n\t\t\tes1 = rb_entry(node, struct extent_status, rb_node);\n\t\t\tif (es1->es_lblk > end) {\n\t\t\t\tes1 = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (matching_fn(es1))\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (es1 && matching_fn(es1)) {\n\t\tWRITE_ONCE(tree->cache_es, es1);\n\t\tes->es_lblk = es1->es_lblk;\n\t\tes->es_len = es1->es_len;\n\t\tes->es_pblk = es1->es_pblk;\n\t}\n\n}\n\n \nvoid ext4_es_find_extent_range(struct inode *inode,\n\t\t\t       int (*matching_fn)(struct extent_status *es),\n\t\t\t       ext4_lblk_t lblk, ext4_lblk_t end,\n\t\t\t       struct extent_status *es)\n{\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn;\n\n\ttrace_ext4_es_find_extent_range_enter(inode, lblk);\n\n\tread_lock(&EXT4_I(inode)->i_es_lock);\n\t__es_find_extent_range(inode, matching_fn, lblk, end, es);\n\tread_unlock(&EXT4_I(inode)->i_es_lock);\n\n\ttrace_ext4_es_find_extent_range_exit(inode, es);\n}\n\n \nstatic bool __es_scan_range(struct inode *inode,\n\t\t\t    int (*matching_fn)(struct extent_status *es),\n\t\t\t    ext4_lblk_t start, ext4_lblk_t end)\n{\n\tstruct extent_status es;\n\n\t__es_find_extent_range(inode, matching_fn, start, end, &es);\n\tif (es.es_len == 0)\n\t\treturn false;    \n\telse if (es.es_lblk <= start &&\n\t\t start < es.es_lblk + es.es_len)\n\t\treturn true;\n\telse if (start <= es.es_lblk && es.es_lblk <= end)\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n \nbool ext4_es_scan_range(struct inode *inode,\n\t\t\tint (*matching_fn)(struct extent_status *es),\n\t\t\text4_lblk_t lblk, ext4_lblk_t end)\n{\n\tbool ret;\n\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn false;\n\n\tread_lock(&EXT4_I(inode)->i_es_lock);\n\tret = __es_scan_range(inode, matching_fn, lblk, end);\n\tread_unlock(&EXT4_I(inode)->i_es_lock);\n\n\treturn ret;\n}\n\n \nstatic bool __es_scan_clu(struct inode *inode,\n\t\t\t  int (*matching_fn)(struct extent_status *es),\n\t\t\t  ext4_lblk_t lblk)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\text4_lblk_t lblk_start, lblk_end;\n\n\tlblk_start = EXT4_LBLK_CMASK(sbi, lblk);\n\tlblk_end = lblk_start + sbi->s_cluster_ratio - 1;\n\n\treturn __es_scan_range(inode, matching_fn, lblk_start, lblk_end);\n}\n\n \nbool ext4_es_scan_clu(struct inode *inode,\n\t\t      int (*matching_fn)(struct extent_status *es),\n\t\t      ext4_lblk_t lblk)\n{\n\tbool ret;\n\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn false;\n\n\tread_lock(&EXT4_I(inode)->i_es_lock);\n\tret = __es_scan_clu(inode, matching_fn, lblk);\n\tread_unlock(&EXT4_I(inode)->i_es_lock);\n\n\treturn ret;\n}\n\nstatic void ext4_es_list_add(struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\n\tif (!list_empty(&ei->i_es_list))\n\t\treturn;\n\n\tspin_lock(&sbi->s_es_lock);\n\tif (list_empty(&ei->i_es_list)) {\n\t\tlist_add_tail(&ei->i_es_list, &sbi->s_es_list);\n\t\tsbi->s_es_nr_inode++;\n\t}\n\tspin_unlock(&sbi->s_es_lock);\n}\n\nstatic void ext4_es_list_del(struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\n\tspin_lock(&sbi->s_es_lock);\n\tif (!list_empty(&ei->i_es_list)) {\n\t\tlist_del_init(&ei->i_es_list);\n\t\tsbi->s_es_nr_inode--;\n\t\tWARN_ON_ONCE(sbi->s_es_nr_inode < 0);\n\t}\n\tspin_unlock(&sbi->s_es_lock);\n}\n\nstatic inline struct pending_reservation *__alloc_pending(bool nofail)\n{\n\tif (!nofail)\n\t\treturn kmem_cache_alloc(ext4_pending_cachep, GFP_ATOMIC);\n\n\treturn kmem_cache_zalloc(ext4_pending_cachep, GFP_KERNEL | __GFP_NOFAIL);\n}\n\nstatic inline void __free_pending(struct pending_reservation *pr)\n{\n\tkmem_cache_free(ext4_pending_cachep, pr);\n}\n\n \nstatic inline bool ext4_es_must_keep(struct extent_status *es)\n{\n\t \n\tif (ext4_es_is_delayed(es))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic inline struct extent_status *__es_alloc_extent(bool nofail)\n{\n\tif (!nofail)\n\t\treturn kmem_cache_alloc(ext4_es_cachep, GFP_ATOMIC);\n\n\treturn kmem_cache_zalloc(ext4_es_cachep, GFP_KERNEL | __GFP_NOFAIL);\n}\n\nstatic void ext4_es_init_extent(struct inode *inode, struct extent_status *es,\n\t\text4_lblk_t lblk, ext4_lblk_t len, ext4_fsblk_t pblk)\n{\n\tes->es_lblk = lblk;\n\tes->es_len = len;\n\tes->es_pblk = pblk;\n\n\t \n\tif (!ext4_es_must_keep(es)) {\n\t\tif (!EXT4_I(inode)->i_es_shk_nr++)\n\t\t\text4_es_list_add(inode);\n\t\tpercpu_counter_inc(&EXT4_SB(inode->i_sb)->\n\t\t\t\t\ts_es_stats.es_stats_shk_cnt);\n\t}\n\n\tEXT4_I(inode)->i_es_all_nr++;\n\tpercpu_counter_inc(&EXT4_SB(inode->i_sb)->s_es_stats.es_stats_all_cnt);\n}\n\nstatic inline void __es_free_extent(struct extent_status *es)\n{\n\tkmem_cache_free(ext4_es_cachep, es);\n}\n\nstatic void ext4_es_free_extent(struct inode *inode, struct extent_status *es)\n{\n\tEXT4_I(inode)->i_es_all_nr--;\n\tpercpu_counter_dec(&EXT4_SB(inode->i_sb)->s_es_stats.es_stats_all_cnt);\n\n\t \n\tif (!ext4_es_must_keep(es)) {\n\t\tBUG_ON(EXT4_I(inode)->i_es_shk_nr == 0);\n\t\tif (!--EXT4_I(inode)->i_es_shk_nr)\n\t\t\text4_es_list_del(inode);\n\t\tpercpu_counter_dec(&EXT4_SB(inode->i_sb)->\n\t\t\t\t\ts_es_stats.es_stats_shk_cnt);\n\t}\n\n\t__es_free_extent(es);\n}\n\n \nstatic int ext4_es_can_be_merged(struct extent_status *es1,\n\t\t\t\t struct extent_status *es2)\n{\n\tif (ext4_es_type(es1) != ext4_es_type(es2))\n\t\treturn 0;\n\n\tif (((__u64) es1->es_len) + es2->es_len > EXT_MAX_BLOCKS) {\n\t\tpr_warn(\"ES assertion failed when merging extents. \"\n\t\t\t\"The sum of lengths of es1 (%d) and es2 (%d) \"\n\t\t\t\"is bigger than allowed file size (%d)\\n\",\n\t\t\tes1->es_len, es2->es_len, EXT_MAX_BLOCKS);\n\t\tWARN_ON(1);\n\t\treturn 0;\n\t}\n\n\tif (((__u64) es1->es_lblk) + es1->es_len != es2->es_lblk)\n\t\treturn 0;\n\n\tif ((ext4_es_is_written(es1) || ext4_es_is_unwritten(es1)) &&\n\t    (ext4_es_pblock(es1) + es1->es_len == ext4_es_pblock(es2)))\n\t\treturn 1;\n\n\tif (ext4_es_is_hole(es1))\n\t\treturn 1;\n\n\t \n\tif (ext4_es_is_delayed(es1) && !ext4_es_is_unwritten(es1))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic struct extent_status *\next4_es_try_to_merge_left(struct inode *inode, struct extent_status *es)\n{\n\tstruct ext4_es_tree *tree = &EXT4_I(inode)->i_es_tree;\n\tstruct extent_status *es1;\n\tstruct rb_node *node;\n\n\tnode = rb_prev(&es->rb_node);\n\tif (!node)\n\t\treturn es;\n\n\tes1 = rb_entry(node, struct extent_status, rb_node);\n\tif (ext4_es_can_be_merged(es1, es)) {\n\t\tes1->es_len += es->es_len;\n\t\tif (ext4_es_is_referenced(es))\n\t\t\text4_es_set_referenced(es1);\n\t\trb_erase(&es->rb_node, &tree->root);\n\t\text4_es_free_extent(inode, es);\n\t\tes = es1;\n\t}\n\n\treturn es;\n}\n\nstatic struct extent_status *\next4_es_try_to_merge_right(struct inode *inode, struct extent_status *es)\n{\n\tstruct ext4_es_tree *tree = &EXT4_I(inode)->i_es_tree;\n\tstruct extent_status *es1;\n\tstruct rb_node *node;\n\n\tnode = rb_next(&es->rb_node);\n\tif (!node)\n\t\treturn es;\n\n\tes1 = rb_entry(node, struct extent_status, rb_node);\n\tif (ext4_es_can_be_merged(es, es1)) {\n\t\tes->es_len += es1->es_len;\n\t\tif (ext4_es_is_referenced(es1))\n\t\t\text4_es_set_referenced(es);\n\t\trb_erase(node, &tree->root);\n\t\text4_es_free_extent(inode, es1);\n\t}\n\n\treturn es;\n}\n\n#ifdef ES_AGGRESSIVE_TEST\n#include \"ext4_extents.h\"\t \n\nstatic void ext4_es_insert_extent_ext_check(struct inode *inode,\n\t\t\t\t\t    struct extent_status *es)\n{\n\tstruct ext4_ext_path *path = NULL;\n\tstruct ext4_extent *ex;\n\text4_lblk_t ee_block;\n\text4_fsblk_t ee_start;\n\tunsigned short ee_len;\n\tint depth, ee_status, es_status;\n\n\tpath = ext4_find_extent(inode, es->es_lblk, NULL, EXT4_EX_NOCACHE);\n\tif (IS_ERR(path))\n\t\treturn;\n\n\tdepth = ext_depth(inode);\n\tex = path[depth].p_ext;\n\n\tif (ex) {\n\n\t\tee_block = le32_to_cpu(ex->ee_block);\n\t\tee_start = ext4_ext_pblock(ex);\n\t\tee_len = ext4_ext_get_actual_len(ex);\n\n\t\tee_status = ext4_ext_is_unwritten(ex) ? 1 : 0;\n\t\tes_status = ext4_es_is_unwritten(es) ? 1 : 0;\n\n\t\t \n\t\tif (!ext4_es_is_written(es) && !ext4_es_is_unwritten(es)) {\n\t\t\tif (in_range(es->es_lblk, ee_block, ee_len)) {\n\t\t\t\tpr_warn(\"ES insert assertion failed for \"\n\t\t\t\t\t\"inode: %lu we can find an extent \"\n\t\t\t\t\t\"at block [%d/%d/%llu/%c], but we \"\n\t\t\t\t\t\"want to add a delayed/hole extent \"\n\t\t\t\t\t\"[%d/%d/%llu/%x]\\n\",\n\t\t\t\t\tinode->i_ino, ee_block, ee_len,\n\t\t\t\t\tee_start, ee_status ? 'u' : 'w',\n\t\t\t\t\tes->es_lblk, es->es_len,\n\t\t\t\t\text4_es_pblock(es), ext4_es_status(es));\n\t\t\t}\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (es->es_lblk < ee_block ||\n\t\t    ext4_es_pblock(es) != ee_start + es->es_lblk - ee_block) {\n\t\t\tpr_warn(\"ES insert assertion failed for inode: %lu \"\n\t\t\t\t\"ex_status [%d/%d/%llu/%c] != \"\n\t\t\t\t\"es_status [%d/%d/%llu/%c]\\n\", inode->i_ino,\n\t\t\t\tee_block, ee_len, ee_start,\n\t\t\t\tee_status ? 'u' : 'w', es->es_lblk, es->es_len,\n\t\t\t\text4_es_pblock(es), es_status ? 'u' : 'w');\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (ee_status ^ es_status) {\n\t\t\tpr_warn(\"ES insert assertion failed for inode: %lu \"\n\t\t\t\t\"ex_status [%d/%d/%llu/%c] != \"\n\t\t\t\t\"es_status [%d/%d/%llu/%c]\\n\", inode->i_ino,\n\t\t\t\tee_block, ee_len, ee_start,\n\t\t\t\tee_status ? 'u' : 'w', es->es_lblk, es->es_len,\n\t\t\t\text4_es_pblock(es), es_status ? 'u' : 'w');\n\t\t}\n\t} else {\n\t\t \n\t\tif (!ext4_es_is_delayed(es) && !ext4_es_is_hole(es)) {\n\t\t\tpr_warn(\"ES insert assertion failed for inode: %lu \"\n\t\t\t\t\"can't find an extent at block %d but we want \"\n\t\t\t\t\"to add a written/unwritten extent \"\n\t\t\t\t\"[%d/%d/%llu/%x]\\n\", inode->i_ino,\n\t\t\t\tes->es_lblk, es->es_lblk, es->es_len,\n\t\t\t\text4_es_pblock(es), ext4_es_status(es));\n\t\t}\n\t}\nout:\n\text4_free_ext_path(path);\n}\n\nstatic void ext4_es_insert_extent_ind_check(struct inode *inode,\n\t\t\t\t\t    struct extent_status *es)\n{\n\tstruct ext4_map_blocks map;\n\tint retval;\n\n\t \n\n\tmap.m_lblk = es->es_lblk;\n\tmap.m_len = es->es_len;\n\n\tretval = ext4_ind_map_blocks(NULL, inode, &map, 0);\n\tif (retval > 0) {\n\t\tif (ext4_es_is_delayed(es) || ext4_es_is_hole(es)) {\n\t\t\t \n\t\t\tpr_warn(\"ES insert assertion failed for inode: %lu \"\n\t\t\t\t\"We can find blocks but we want to add a \"\n\t\t\t\t\"delayed/hole extent [%d/%d/%llu/%x]\\n\",\n\t\t\t\tinode->i_ino, es->es_lblk, es->es_len,\n\t\t\t\text4_es_pblock(es), ext4_es_status(es));\n\t\t\treturn;\n\t\t} else if (ext4_es_is_written(es)) {\n\t\t\tif (retval != es->es_len) {\n\t\t\t\tpr_warn(\"ES insert assertion failed for \"\n\t\t\t\t\t\"inode: %lu retval %d != es_len %d\\n\",\n\t\t\t\t\tinode->i_ino, retval, es->es_len);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (map.m_pblk != ext4_es_pblock(es)) {\n\t\t\t\tpr_warn(\"ES insert assertion failed for \"\n\t\t\t\t\t\"inode: %lu m_pblk %llu != \"\n\t\t\t\t\t\"es_pblk %llu\\n\",\n\t\t\t\t\tinode->i_ino, map.m_pblk,\n\t\t\t\t\text4_es_pblock(es));\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tBUG();\n\t\t}\n\t} else if (retval == 0) {\n\t\tif (ext4_es_is_written(es)) {\n\t\t\tpr_warn(\"ES insert assertion failed for inode: %lu \"\n\t\t\t\t\"We can't find the block but we want to add \"\n\t\t\t\t\"a written extent [%d/%d/%llu/%x]\\n\",\n\t\t\t\tinode->i_ino, es->es_lblk, es->es_len,\n\t\t\t\text4_es_pblock(es), ext4_es_status(es));\n\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic inline void ext4_es_insert_extent_check(struct inode *inode,\n\t\t\t\t\t       struct extent_status *es)\n{\n\t \n\tBUG_ON(!rwsem_is_locked(&EXT4_I(inode)->i_data_sem));\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\text4_es_insert_extent_ext_check(inode, es);\n\telse\n\t\text4_es_insert_extent_ind_check(inode, es);\n}\n#else\nstatic inline void ext4_es_insert_extent_check(struct inode *inode,\n\t\t\t\t\t       struct extent_status *es)\n{\n}\n#endif\n\nstatic int __es_insert_extent(struct inode *inode, struct extent_status *newes,\n\t\t\t      struct extent_status *prealloc)\n{\n\tstruct ext4_es_tree *tree = &EXT4_I(inode)->i_es_tree;\n\tstruct rb_node **p = &tree->root.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct extent_status *es;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tes = rb_entry(parent, struct extent_status, rb_node);\n\n\t\tif (newes->es_lblk < es->es_lblk) {\n\t\t\tif (ext4_es_can_be_merged(newes, es)) {\n\t\t\t\t \n\t\t\t\tes->es_lblk = newes->es_lblk;\n\t\t\t\tes->es_len += newes->es_len;\n\t\t\t\tif (ext4_es_is_written(es) ||\n\t\t\t\t    ext4_es_is_unwritten(es))\n\t\t\t\t\text4_es_store_pblock(es,\n\t\t\t\t\t\t\t     newes->es_pblk);\n\t\t\t\tes = ext4_es_try_to_merge_left(inode, es);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tp = &(*p)->rb_left;\n\t\t} else if (newes->es_lblk > ext4_es_end(es)) {\n\t\t\tif (ext4_es_can_be_merged(es, newes)) {\n\t\t\t\tes->es_len += newes->es_len;\n\t\t\t\tes = ext4_es_try_to_merge_right(inode, es);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tp = &(*p)->rb_right;\n\t\t} else {\n\t\t\tBUG();\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (prealloc)\n\t\tes = prealloc;\n\telse\n\t\tes = __es_alloc_extent(false);\n\tif (!es)\n\t\treturn -ENOMEM;\n\text4_es_init_extent(inode, es, newes->es_lblk, newes->es_len,\n\t\t\t    newes->es_pblk);\n\n\trb_link_node(&es->rb_node, parent, p);\n\trb_insert_color(&es->rb_node, &tree->root);\n\nout:\n\ttree->cache_es = es;\n\treturn 0;\n}\n\n \nvoid ext4_es_insert_extent(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t   ext4_lblk_t len, ext4_fsblk_t pblk,\n\t\t\t   unsigned int status)\n{\n\tstruct extent_status newes;\n\text4_lblk_t end = lblk + len - 1;\n\tint err1 = 0, err2 = 0, err3 = 0;\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct extent_status *es1 = NULL;\n\tstruct extent_status *es2 = NULL;\n\tstruct pending_reservation *pr = NULL;\n\tbool revise_pending = false;\n\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn;\n\n\tes_debug(\"add [%u/%u) %llu %x to extent status tree of inode %lu\\n\",\n\t\t lblk, len, pblk, status, inode->i_ino);\n\n\tif (!len)\n\t\treturn;\n\n\tBUG_ON(end < lblk);\n\n\tif ((status & EXTENT_STATUS_DELAYED) &&\n\t    (status & EXTENT_STATUS_WRITTEN)) {\n\t\text4_warning(inode->i_sb, \"Inserting extent [%u/%u] as \"\n\t\t\t\t\" delayed and written which can potentially \"\n\t\t\t\t\" cause data loss.\", lblk, len);\n\t\tWARN_ON(1);\n\t}\n\n\tnewes.es_lblk = lblk;\n\tnewes.es_len = len;\n\text4_es_store_pblock_status(&newes, pblk, status);\n\ttrace_ext4_es_insert_extent(inode, &newes);\n\n\text4_es_insert_extent_check(inode, &newes);\n\n\trevise_pending = sbi->s_cluster_ratio > 1 &&\n\t\t\t test_opt(inode->i_sb, DELALLOC) &&\n\t\t\t (status & (EXTENT_STATUS_WRITTEN |\n\t\t\t\t    EXTENT_STATUS_UNWRITTEN));\nretry:\n\tif (err1 && !es1)\n\t\tes1 = __es_alloc_extent(true);\n\tif ((err1 || err2) && !es2)\n\t\tes2 = __es_alloc_extent(true);\n\tif ((err1 || err2 || err3) && revise_pending && !pr)\n\t\tpr = __alloc_pending(true);\n\twrite_lock(&EXT4_I(inode)->i_es_lock);\n\n\terr1 = __es_remove_extent(inode, lblk, end, NULL, es1);\n\tif (err1 != 0)\n\t\tgoto error;\n\t \n\tif (es1) {\n\t\tif (!es1->es_len)\n\t\t\t__es_free_extent(es1);\n\t\tes1 = NULL;\n\t}\n\n\terr2 = __es_insert_extent(inode, &newes, es2);\n\tif (err2 == -ENOMEM && !ext4_es_must_keep(&newes))\n\t\terr2 = 0;\n\tif (err2 != 0)\n\t\tgoto error;\n\t \n\tif (es2) {\n\t\tif (!es2->es_len)\n\t\t\t__es_free_extent(es2);\n\t\tes2 = NULL;\n\t}\n\n\tif (revise_pending) {\n\t\terr3 = __revise_pending(inode, lblk, len, &pr);\n\t\tif (err3 != 0)\n\t\t\tgoto error;\n\t\tif (pr) {\n\t\t\t__free_pending(pr);\n\t\t\tpr = NULL;\n\t\t}\n\t}\nerror:\n\twrite_unlock(&EXT4_I(inode)->i_es_lock);\n\tif (err1 || err2 || err3)\n\t\tgoto retry;\n\n\text4_es_print_tree(inode);\n\treturn;\n}\n\n \nvoid ext4_es_cache_extent(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t  ext4_lblk_t len, ext4_fsblk_t pblk,\n\t\t\t  unsigned int status)\n{\n\tstruct extent_status *es;\n\tstruct extent_status newes;\n\text4_lblk_t end = lblk + len - 1;\n\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn;\n\n\tnewes.es_lblk = lblk;\n\tnewes.es_len = len;\n\text4_es_store_pblock_status(&newes, pblk, status);\n\ttrace_ext4_es_cache_extent(inode, &newes);\n\n\tif (!len)\n\t\treturn;\n\n\tBUG_ON(end < lblk);\n\n\twrite_lock(&EXT4_I(inode)->i_es_lock);\n\n\tes = __es_tree_search(&EXT4_I(inode)->i_es_tree.root, lblk);\n\tif (!es || es->es_lblk > end)\n\t\t__es_insert_extent(inode, &newes, NULL);\n\twrite_unlock(&EXT4_I(inode)->i_es_lock);\n}\n\n \nint ext4_es_lookup_extent(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t  ext4_lblk_t *next_lblk,\n\t\t\t  struct extent_status *es)\n{\n\tstruct ext4_es_tree *tree;\n\tstruct ext4_es_stats *stats;\n\tstruct extent_status *es1 = NULL;\n\tstruct rb_node *node;\n\tint found = 0;\n\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn 0;\n\n\ttrace_ext4_es_lookup_extent_enter(inode, lblk);\n\tes_debug(\"lookup extent in block %u\\n\", lblk);\n\n\ttree = &EXT4_I(inode)->i_es_tree;\n\tread_lock(&EXT4_I(inode)->i_es_lock);\n\n\t \n\tes->es_lblk = es->es_len = es->es_pblk = 0;\n\tes1 = READ_ONCE(tree->cache_es);\n\tif (es1 && in_range(lblk, es1->es_lblk, es1->es_len)) {\n\t\tes_debug(\"%u cached by [%u/%u)\\n\",\n\t\t\t lblk, es1->es_lblk, es1->es_len);\n\t\tfound = 1;\n\t\tgoto out;\n\t}\n\n\tnode = tree->root.rb_node;\n\twhile (node) {\n\t\tes1 = rb_entry(node, struct extent_status, rb_node);\n\t\tif (lblk < es1->es_lblk)\n\t\t\tnode = node->rb_left;\n\t\telse if (lblk > ext4_es_end(es1))\n\t\t\tnode = node->rb_right;\n\t\telse {\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\tstats = &EXT4_SB(inode->i_sb)->s_es_stats;\n\tif (found) {\n\t\tBUG_ON(!es1);\n\t\tes->es_lblk = es1->es_lblk;\n\t\tes->es_len = es1->es_len;\n\t\tes->es_pblk = es1->es_pblk;\n\t\tif (!ext4_es_is_referenced(es1))\n\t\t\text4_es_set_referenced(es1);\n\t\tpercpu_counter_inc(&stats->es_stats_cache_hits);\n\t\tif (next_lblk) {\n\t\t\tnode = rb_next(&es1->rb_node);\n\t\t\tif (node) {\n\t\t\t\tes1 = rb_entry(node, struct extent_status,\n\t\t\t\t\t       rb_node);\n\t\t\t\t*next_lblk = es1->es_lblk;\n\t\t\t} else\n\t\t\t\t*next_lblk = 0;\n\t\t}\n\t} else {\n\t\tpercpu_counter_inc(&stats->es_stats_cache_misses);\n\t}\n\n\tread_unlock(&EXT4_I(inode)->i_es_lock);\n\n\ttrace_ext4_es_lookup_extent_exit(inode, es, found);\n\treturn found;\n}\n\nstruct rsvd_count {\n\tint ndelonly;\n\tbool first_do_lblk_found;\n\text4_lblk_t first_do_lblk;\n\text4_lblk_t last_do_lblk;\n\tstruct extent_status *left_es;\n\tbool partial;\n\text4_lblk_t lclu;\n};\n\n \nstatic void init_rsvd(struct inode *inode, ext4_lblk_t lblk,\n\t\t      struct extent_status *es, struct rsvd_count *rc)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct rb_node *node;\n\n\trc->ndelonly = 0;\n\n\t \n\tif (sbi->s_cluster_ratio > 1) {\n\t\trc->first_do_lblk_found = false;\n\t\tif (lblk > es->es_lblk) {\n\t\t\trc->left_es = es;\n\t\t} else {\n\t\t\tnode = rb_prev(&es->rb_node);\n\t\t\trc->left_es = node ? rb_entry(node,\n\t\t\t\t\t\t      struct extent_status,\n\t\t\t\t\t\t      rb_node) : NULL;\n\t\t}\n\t\trc->partial = false;\n\t}\n}\n\n \nstatic void count_rsvd(struct inode *inode, ext4_lblk_t lblk, long len,\n\t\t       struct extent_status *es, struct rsvd_count *rc)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\text4_lblk_t i, end, nclu;\n\n\tif (!ext4_es_is_delonly(es))\n\t\treturn;\n\n\tWARN_ON(len <= 0);\n\n\tif (sbi->s_cluster_ratio == 1) {\n\t\trc->ndelonly += (int) len;\n\t\treturn;\n\t}\n\n\t \n\n\ti = (lblk < es->es_lblk) ? es->es_lblk : lblk;\n\tend = lblk + (ext4_lblk_t) len - 1;\n\tend = (end > ext4_es_end(es)) ? ext4_es_end(es) : end;\n\n\t \n\tif (!rc->first_do_lblk_found) {\n\t\trc->first_do_lblk = i;\n\t\trc->first_do_lblk_found = true;\n\t}\n\n\t \n\trc->last_do_lblk = end;\n\n\t \n\tif (rc->partial && (rc->lclu != EXT4_B2C(sbi, i))) {\n\t\trc->ndelonly++;\n\t\trc->partial = false;\n\t}\n\n\t \n\tif (EXT4_LBLK_COFF(sbi, i) != 0) {\n\t\tif (end >= EXT4_LBLK_CFILL(sbi, i)) {\n\t\t\trc->ndelonly++;\n\t\t\trc->partial = false;\n\t\t\ti = EXT4_LBLK_CFILL(sbi, i) + 1;\n\t\t}\n\t}\n\n\t \n\tif ((i + sbi->s_cluster_ratio - 1) <= end) {\n\t\tnclu = (end - i + 1) >> sbi->s_cluster_bits;\n\t\trc->ndelonly += nclu;\n\t\ti += nclu << sbi->s_cluster_bits;\n\t}\n\n\t \n\tif (!rc->partial && i <= end) {\n\t\trc->partial = true;\n\t\trc->lclu = EXT4_B2C(sbi, i);\n\t}\n}\n\n \nstatic struct pending_reservation *__pr_tree_search(struct rb_root *root,\n\t\t\t\t\t\t    ext4_lblk_t lclu)\n{\n\tstruct rb_node *node = root->rb_node;\n\tstruct pending_reservation *pr = NULL;\n\n\twhile (node) {\n\t\tpr = rb_entry(node, struct pending_reservation, rb_node);\n\t\tif (lclu < pr->lclu)\n\t\t\tnode = node->rb_left;\n\t\telse if (lclu > pr->lclu)\n\t\t\tnode = node->rb_right;\n\t\telse\n\t\t\treturn pr;\n\t}\n\tif (pr && lclu < pr->lclu)\n\t\treturn pr;\n\tif (pr && lclu > pr->lclu) {\n\t\tnode = rb_next(&pr->rb_node);\n\t\treturn node ? rb_entry(node, struct pending_reservation,\n\t\t\t\t       rb_node) : NULL;\n\t}\n\treturn NULL;\n}\n\n \nstatic unsigned int get_rsvd(struct inode *inode, ext4_lblk_t end,\n\t\t\t     struct extent_status *right_es,\n\t\t\t     struct rsvd_count *rc)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct pending_reservation *pr;\n\tstruct ext4_pending_tree *tree = &EXT4_I(inode)->i_pending_tree;\n\tstruct rb_node *node;\n\text4_lblk_t first_lclu, last_lclu;\n\tbool left_delonly, right_delonly, count_pending;\n\tstruct extent_status *es;\n\n\tif (sbi->s_cluster_ratio > 1) {\n\t\t \n\t\tif (rc->partial)\n\t\t\trc->ndelonly++;\n\n\t\tif (rc->ndelonly == 0)\n\t\t\treturn 0;\n\n\t\tfirst_lclu = EXT4_B2C(sbi, rc->first_do_lblk);\n\t\tlast_lclu = EXT4_B2C(sbi, rc->last_do_lblk);\n\n\t\t \n\t\tleft_delonly = right_delonly = false;\n\n\t\tes = rc->left_es;\n\t\twhile (es && ext4_es_end(es) >=\n\t\t       EXT4_LBLK_CMASK(sbi, rc->first_do_lblk)) {\n\t\t\tif (ext4_es_is_delonly(es)) {\n\t\t\t\trc->ndelonly--;\n\t\t\t\tleft_delonly = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tnode = rb_prev(&es->rb_node);\n\t\t\tif (!node)\n\t\t\t\tbreak;\n\t\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t\t}\n\t\tif (right_es && (!left_delonly || first_lclu != last_lclu)) {\n\t\t\tif (end < ext4_es_end(right_es)) {\n\t\t\t\tes = right_es;\n\t\t\t} else {\n\t\t\t\tnode = rb_next(&right_es->rb_node);\n\t\t\t\tes = node ? rb_entry(node, struct extent_status,\n\t\t\t\t\t\t     rb_node) : NULL;\n\t\t\t}\n\t\t\twhile (es && es->es_lblk <=\n\t\t\t       EXT4_LBLK_CFILL(sbi, rc->last_do_lblk)) {\n\t\t\t\tif (ext4_es_is_delonly(es)) {\n\t\t\t\t\trc->ndelonly--;\n\t\t\t\t\tright_delonly = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnode = rb_next(&es->rb_node);\n\t\t\t\tif (!node)\n\t\t\t\t\tbreak;\n\t\t\t\tes = rb_entry(node, struct extent_status,\n\t\t\t\t\t      rb_node);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (first_lclu == last_lclu) {\n\t\t\tif (left_delonly | right_delonly)\n\t\t\t\tcount_pending = false;\n\t\t\telse\n\t\t\t\tcount_pending = true;\n\t\t} else {\n\t\t\tif (left_delonly)\n\t\t\t\tfirst_lclu++;\n\t\t\tif (right_delonly)\n\t\t\t\tlast_lclu--;\n\t\t\tif (first_lclu <= last_lclu)\n\t\t\t\tcount_pending = true;\n\t\t\telse\n\t\t\t\tcount_pending = false;\n\t\t}\n\n\t\t \n\t\tif (count_pending) {\n\t\t\tpr = __pr_tree_search(&tree->root, first_lclu);\n\t\t\twhile (pr && pr->lclu <= last_lclu) {\n\t\t\t\trc->ndelonly--;\n\t\t\t\tnode = rb_next(&pr->rb_node);\n\t\t\t\trb_erase(&pr->rb_node, &tree->root);\n\t\t\t\t__free_pending(pr);\n\t\t\t\tif (!node)\n\t\t\t\t\tbreak;\n\t\t\t\tpr = rb_entry(node, struct pending_reservation,\n\t\t\t\t\t      rb_node);\n\t\t\t}\n\t\t}\n\t}\n\treturn rc->ndelonly;\n}\n\n\n \nstatic int __es_remove_extent(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t      ext4_lblk_t end, int *reserved,\n\t\t\t      struct extent_status *prealloc)\n{\n\tstruct ext4_es_tree *tree = &EXT4_I(inode)->i_es_tree;\n\tstruct rb_node *node;\n\tstruct extent_status *es;\n\tstruct extent_status orig_es;\n\text4_lblk_t len1, len2;\n\text4_fsblk_t block;\n\tint err = 0;\n\tbool count_reserved = true;\n\tstruct rsvd_count rc;\n\n\tif (reserved == NULL || !test_opt(inode->i_sb, DELALLOC))\n\t\tcount_reserved = false;\n\n\tes = __es_tree_search(&tree->root, lblk);\n\tif (!es)\n\t\tgoto out;\n\tif (es->es_lblk > end)\n\t\tgoto out;\n\n\t \n\ttree->cache_es = NULL;\n\tif (count_reserved)\n\t\tinit_rsvd(inode, lblk, es, &rc);\n\n\torig_es.es_lblk = es->es_lblk;\n\torig_es.es_len = es->es_len;\n\torig_es.es_pblk = es->es_pblk;\n\n\tlen1 = lblk > es->es_lblk ? lblk - es->es_lblk : 0;\n\tlen2 = ext4_es_end(es) > end ? ext4_es_end(es) - end : 0;\n\tif (len1 > 0)\n\t\tes->es_len = len1;\n\tif (len2 > 0) {\n\t\tif (len1 > 0) {\n\t\t\tstruct extent_status newes;\n\n\t\t\tnewes.es_lblk = end + 1;\n\t\t\tnewes.es_len = len2;\n\t\t\tblock = 0x7FDEADBEEFULL;\n\t\t\tif (ext4_es_is_written(&orig_es) ||\n\t\t\t    ext4_es_is_unwritten(&orig_es))\n\t\t\t\tblock = ext4_es_pblock(&orig_es) +\n\t\t\t\t\torig_es.es_len - len2;\n\t\t\text4_es_store_pblock_status(&newes, block,\n\t\t\t\t\t\t    ext4_es_status(&orig_es));\n\t\t\terr = __es_insert_extent(inode, &newes, prealloc);\n\t\t\tif (err) {\n\t\t\t\tif (!ext4_es_must_keep(&newes))\n\t\t\t\t\treturn 0;\n\n\t\t\t\tes->es_lblk = orig_es.es_lblk;\n\t\t\t\tes->es_len = orig_es.es_len;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tes->es_lblk = end + 1;\n\t\t\tes->es_len = len2;\n\t\t\tif (ext4_es_is_written(es) ||\n\t\t\t    ext4_es_is_unwritten(es)) {\n\t\t\t\tblock = orig_es.es_pblk + orig_es.es_len - len2;\n\t\t\t\text4_es_store_pblock(es, block);\n\t\t\t}\n\t\t}\n\t\tif (count_reserved)\n\t\t\tcount_rsvd(inode, orig_es.es_lblk + len1,\n\t\t\t\t   orig_es.es_len - len1 - len2, &orig_es, &rc);\n\t\tgoto out_get_reserved;\n\t}\n\n\tif (len1 > 0) {\n\t\tif (count_reserved)\n\t\t\tcount_rsvd(inode, lblk, orig_es.es_len - len1,\n\t\t\t\t   &orig_es, &rc);\n\t\tnode = rb_next(&es->rb_node);\n\t\tif (node)\n\t\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t\telse\n\t\t\tes = NULL;\n\t}\n\n\twhile (es && ext4_es_end(es) <= end) {\n\t\tif (count_reserved)\n\t\t\tcount_rsvd(inode, es->es_lblk, es->es_len, es, &rc);\n\t\tnode = rb_next(&es->rb_node);\n\t\trb_erase(&es->rb_node, &tree->root);\n\t\text4_es_free_extent(inode, es);\n\t\tif (!node) {\n\t\t\tes = NULL;\n\t\t\tbreak;\n\t\t}\n\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t}\n\n\tif (es && es->es_lblk < end + 1) {\n\t\text4_lblk_t orig_len = es->es_len;\n\n\t\tlen1 = ext4_es_end(es) - end;\n\t\tif (count_reserved)\n\t\t\tcount_rsvd(inode, es->es_lblk, orig_len - len1,\n\t\t\t\t   es, &rc);\n\t\tes->es_lblk = end + 1;\n\t\tes->es_len = len1;\n\t\tif (ext4_es_is_written(es) || ext4_es_is_unwritten(es)) {\n\t\t\tblock = es->es_pblk + orig_len - len1;\n\t\t\text4_es_store_pblock(es, block);\n\t\t}\n\t}\n\nout_get_reserved:\n\tif (count_reserved)\n\t\t*reserved = get_rsvd(inode, end, es, &rc);\nout:\n\treturn err;\n}\n\n \nvoid ext4_es_remove_extent(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t   ext4_lblk_t len)\n{\n\text4_lblk_t end;\n\tint err = 0;\n\tint reserved = 0;\n\tstruct extent_status *es = NULL;\n\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn;\n\n\ttrace_ext4_es_remove_extent(inode, lblk, len);\n\tes_debug(\"remove [%u/%u) from extent status tree of inode %lu\\n\",\n\t\t lblk, len, inode->i_ino);\n\n\tif (!len)\n\t\treturn;\n\n\tend = lblk + len - 1;\n\tBUG_ON(end < lblk);\n\nretry:\n\tif (err && !es)\n\t\tes = __es_alloc_extent(true);\n\t \n\twrite_lock(&EXT4_I(inode)->i_es_lock);\n\terr = __es_remove_extent(inode, lblk, end, &reserved, es);\n\t \n\tif (es) {\n\t\tif (!es->es_len)\n\t\t\t__es_free_extent(es);\n\t\tes = NULL;\n\t}\n\twrite_unlock(&EXT4_I(inode)->i_es_lock);\n\tif (err)\n\t\tgoto retry;\n\n\text4_es_print_tree(inode);\n\text4_da_release_space(inode, reserved);\n\treturn;\n}\n\nstatic int __es_shrink(struct ext4_sb_info *sbi, int nr_to_scan,\n\t\t       struct ext4_inode_info *locked_ei)\n{\n\tstruct ext4_inode_info *ei;\n\tstruct ext4_es_stats *es_stats;\n\tktime_t start_time;\n\tu64 scan_time;\n\tint nr_to_walk;\n\tint nr_shrunk = 0;\n\tint retried = 0, nr_skipped = 0;\n\n\tes_stats = &sbi->s_es_stats;\n\tstart_time = ktime_get();\n\nretry:\n\tspin_lock(&sbi->s_es_lock);\n\tnr_to_walk = sbi->s_es_nr_inode;\n\twhile (nr_to_walk-- > 0) {\n\t\tif (list_empty(&sbi->s_es_list)) {\n\t\t\tspin_unlock(&sbi->s_es_lock);\n\t\t\tgoto out;\n\t\t}\n\t\tei = list_first_entry(&sbi->s_es_list, struct ext4_inode_info,\n\t\t\t\t      i_es_list);\n\t\t \n\t\tlist_move_tail(&ei->i_es_list, &sbi->s_es_list);\n\n\t\t \n\t\tif (!retried && ext4_test_inode_state(&ei->vfs_inode,\n\t\t\t\t\t\tEXT4_STATE_EXT_PRECACHED)) {\n\t\t\tnr_skipped++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ei == locked_ei || !write_trylock(&ei->i_es_lock)) {\n\t\t\tnr_skipped++;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tspin_unlock(&sbi->s_es_lock);\n\n\t\tnr_shrunk += es_reclaim_extents(ei, &nr_to_scan);\n\t\twrite_unlock(&ei->i_es_lock);\n\n\t\tif (nr_to_scan <= 0)\n\t\t\tgoto out;\n\t\tspin_lock(&sbi->s_es_lock);\n\t}\n\tspin_unlock(&sbi->s_es_lock);\n\n\t \n\tif ((nr_shrunk == 0) && nr_skipped && !retried) {\n\t\tretried++;\n\t\tgoto retry;\n\t}\n\n\tif (locked_ei && nr_shrunk == 0)\n\t\tnr_shrunk = es_reclaim_extents(locked_ei, &nr_to_scan);\n\nout:\n\tscan_time = ktime_to_ns(ktime_sub(ktime_get(), start_time));\n\tif (likely(es_stats->es_stats_scan_time))\n\t\tes_stats->es_stats_scan_time = (scan_time +\n\t\t\t\tes_stats->es_stats_scan_time*3) / 4;\n\telse\n\t\tes_stats->es_stats_scan_time = scan_time;\n\tif (scan_time > es_stats->es_stats_max_scan_time)\n\t\tes_stats->es_stats_max_scan_time = scan_time;\n\tif (likely(es_stats->es_stats_shrunk))\n\t\tes_stats->es_stats_shrunk = (nr_shrunk +\n\t\t\t\tes_stats->es_stats_shrunk*3) / 4;\n\telse\n\t\tes_stats->es_stats_shrunk = nr_shrunk;\n\n\ttrace_ext4_es_shrink(sbi->s_sb, nr_shrunk, scan_time,\n\t\t\t     nr_skipped, retried);\n\treturn nr_shrunk;\n}\n\nstatic unsigned long ext4_es_count(struct shrinker *shrink,\n\t\t\t\t   struct shrink_control *sc)\n{\n\tunsigned long nr;\n\tstruct ext4_sb_info *sbi;\n\n\tsbi = container_of(shrink, struct ext4_sb_info, s_es_shrinker);\n\tnr = percpu_counter_read_positive(&sbi->s_es_stats.es_stats_shk_cnt);\n\ttrace_ext4_es_shrink_count(sbi->s_sb, sc->nr_to_scan, nr);\n\treturn nr;\n}\n\nstatic unsigned long ext4_es_scan(struct shrinker *shrink,\n\t\t\t\t  struct shrink_control *sc)\n{\n\tstruct ext4_sb_info *sbi = container_of(shrink,\n\t\t\t\t\tstruct ext4_sb_info, s_es_shrinker);\n\tint nr_to_scan = sc->nr_to_scan;\n\tint ret, nr_shrunk;\n\n\tret = percpu_counter_read_positive(&sbi->s_es_stats.es_stats_shk_cnt);\n\ttrace_ext4_es_shrink_scan_enter(sbi->s_sb, nr_to_scan, ret);\n\n\tnr_shrunk = __es_shrink(sbi, nr_to_scan, NULL);\n\n\tret = percpu_counter_read_positive(&sbi->s_es_stats.es_stats_shk_cnt);\n\ttrace_ext4_es_shrink_scan_exit(sbi->s_sb, nr_shrunk, ret);\n\treturn nr_shrunk;\n}\n\nint ext4_seq_es_shrinker_info_show(struct seq_file *seq, void *v)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB((struct super_block *) seq->private);\n\tstruct ext4_es_stats *es_stats = &sbi->s_es_stats;\n\tstruct ext4_inode_info *ei, *max = NULL;\n\tunsigned int inode_cnt = 0;\n\n\tif (v != SEQ_START_TOKEN)\n\t\treturn 0;\n\n\t \n\tspin_lock(&sbi->s_es_lock);\n\tlist_for_each_entry(ei, &sbi->s_es_list, i_es_list) {\n\t\tinode_cnt++;\n\t\tif (max && max->i_es_all_nr < ei->i_es_all_nr)\n\t\t\tmax = ei;\n\t\telse if (!max)\n\t\t\tmax = ei;\n\t}\n\tspin_unlock(&sbi->s_es_lock);\n\n\tseq_printf(seq, \"stats:\\n  %lld objects\\n  %lld reclaimable objects\\n\",\n\t\t   percpu_counter_sum_positive(&es_stats->es_stats_all_cnt),\n\t\t   percpu_counter_sum_positive(&es_stats->es_stats_shk_cnt));\n\tseq_printf(seq, \"  %lld/%lld cache hits/misses\\n\",\n\t\t   percpu_counter_sum_positive(&es_stats->es_stats_cache_hits),\n\t\t   percpu_counter_sum_positive(&es_stats->es_stats_cache_misses));\n\tif (inode_cnt)\n\t\tseq_printf(seq, \"  %d inodes on list\\n\", inode_cnt);\n\n\tseq_printf(seq, \"average:\\n  %llu us scan time\\n\",\n\t    div_u64(es_stats->es_stats_scan_time, 1000));\n\tseq_printf(seq, \"  %lu shrunk objects\\n\", es_stats->es_stats_shrunk);\n\tif (inode_cnt)\n\t\tseq_printf(seq,\n\t\t    \"maximum:\\n  %lu inode (%u objects, %u reclaimable)\\n\"\n\t\t    \"  %llu us max scan time\\n\",\n\t\t    max->vfs_inode.i_ino, max->i_es_all_nr, max->i_es_shk_nr,\n\t\t    div_u64(es_stats->es_stats_max_scan_time, 1000));\n\n\treturn 0;\n}\n\nint ext4_es_register_shrinker(struct ext4_sb_info *sbi)\n{\n\tint err;\n\n\t \n\tBUILD_BUG_ON(ES_SHIFT < 48);\n\tINIT_LIST_HEAD(&sbi->s_es_list);\n\tsbi->s_es_nr_inode = 0;\n\tspin_lock_init(&sbi->s_es_lock);\n\tsbi->s_es_stats.es_stats_shrunk = 0;\n\terr = percpu_counter_init(&sbi->s_es_stats.es_stats_cache_hits, 0,\n\t\t\t\t  GFP_KERNEL);\n\tif (err)\n\t\treturn err;\n\terr = percpu_counter_init(&sbi->s_es_stats.es_stats_cache_misses, 0,\n\t\t\t\t  GFP_KERNEL);\n\tif (err)\n\t\tgoto err1;\n\tsbi->s_es_stats.es_stats_scan_time = 0;\n\tsbi->s_es_stats.es_stats_max_scan_time = 0;\n\terr = percpu_counter_init(&sbi->s_es_stats.es_stats_all_cnt, 0, GFP_KERNEL);\n\tif (err)\n\t\tgoto err2;\n\terr = percpu_counter_init(&sbi->s_es_stats.es_stats_shk_cnt, 0, GFP_KERNEL);\n\tif (err)\n\t\tgoto err3;\n\n\tsbi->s_es_shrinker.scan_objects = ext4_es_scan;\n\tsbi->s_es_shrinker.count_objects = ext4_es_count;\n\tsbi->s_es_shrinker.seeks = DEFAULT_SEEKS;\n\terr = register_shrinker(&sbi->s_es_shrinker, \"ext4-es:%s\",\n\t\t\t\tsbi->s_sb->s_id);\n\tif (err)\n\t\tgoto err4;\n\n\treturn 0;\nerr4:\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_shk_cnt);\nerr3:\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_all_cnt);\nerr2:\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_cache_misses);\nerr1:\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_cache_hits);\n\treturn err;\n}\n\nvoid ext4_es_unregister_shrinker(struct ext4_sb_info *sbi)\n{\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_cache_hits);\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_cache_misses);\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_all_cnt);\n\tpercpu_counter_destroy(&sbi->s_es_stats.es_stats_shk_cnt);\n\tunregister_shrinker(&sbi->s_es_shrinker);\n}\n\n \nstatic int es_do_reclaim_extents(struct ext4_inode_info *ei, ext4_lblk_t end,\n\t\t\t\t int *nr_to_scan, int *nr_shrunk)\n{\n\tstruct inode *inode = &ei->vfs_inode;\n\tstruct ext4_es_tree *tree = &ei->i_es_tree;\n\tstruct extent_status *es;\n\tstruct rb_node *node;\n\n\tes = __es_tree_search(&tree->root, ei->i_es_shrink_lblk);\n\tif (!es)\n\t\tgoto out_wrap;\n\n\twhile (*nr_to_scan > 0) {\n\t\tif (es->es_lblk > end) {\n\t\t\tei->i_es_shrink_lblk = end + 1;\n\t\t\treturn 0;\n\t\t}\n\n\t\t(*nr_to_scan)--;\n\t\tnode = rb_next(&es->rb_node);\n\n\t\tif (ext4_es_must_keep(es))\n\t\t\tgoto next;\n\t\tif (ext4_es_is_referenced(es)) {\n\t\t\text4_es_clear_referenced(es);\n\t\t\tgoto next;\n\t\t}\n\n\t\trb_erase(&es->rb_node, &tree->root);\n\t\text4_es_free_extent(inode, es);\n\t\t(*nr_shrunk)++;\nnext:\n\t\tif (!node)\n\t\t\tgoto out_wrap;\n\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t}\n\tei->i_es_shrink_lblk = es->es_lblk;\n\treturn 1;\nout_wrap:\n\tei->i_es_shrink_lblk = 0;\n\treturn 0;\n}\n\nstatic int es_reclaim_extents(struct ext4_inode_info *ei, int *nr_to_scan)\n{\n\tstruct inode *inode = &ei->vfs_inode;\n\tint nr_shrunk = 0;\n\text4_lblk_t start = ei->i_es_shrink_lblk;\n\tstatic DEFINE_RATELIMIT_STATE(_rs, DEFAULT_RATELIMIT_INTERVAL,\n\t\t\t\t      DEFAULT_RATELIMIT_BURST);\n\n\tif (ei->i_es_shk_nr == 0)\n\t\treturn 0;\n\n\tif (ext4_test_inode_state(inode, EXT4_STATE_EXT_PRECACHED) &&\n\t    __ratelimit(&_rs))\n\t\text4_warning(inode->i_sb, \"forced shrink of precached extents\");\n\n\tif (!es_do_reclaim_extents(ei, EXT_MAX_BLOCKS, nr_to_scan, &nr_shrunk) &&\n\t    start != 0)\n\t\tes_do_reclaim_extents(ei, start - 1, nr_to_scan, &nr_shrunk);\n\n\tei->i_es_tree.cache_es = NULL;\n\treturn nr_shrunk;\n}\n\n \nvoid ext4_clear_inode_es(struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct extent_status *es;\n\tstruct ext4_es_tree *tree;\n\tstruct rb_node *node;\n\n\twrite_lock(&ei->i_es_lock);\n\ttree = &EXT4_I(inode)->i_es_tree;\n\ttree->cache_es = NULL;\n\tnode = rb_first(&tree->root);\n\twhile (node) {\n\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t\tnode = rb_next(node);\n\t\tif (!ext4_es_must_keep(es)) {\n\t\t\trb_erase(&es->rb_node, &tree->root);\n\t\t\text4_es_free_extent(inode, es);\n\t\t}\n\t}\n\text4_clear_inode_state(inode, EXT4_STATE_EXT_PRECACHED);\n\twrite_unlock(&ei->i_es_lock);\n}\n\n#ifdef ES_DEBUG__\nstatic void ext4_print_pending_tree(struct inode *inode)\n{\n\tstruct ext4_pending_tree *tree;\n\tstruct rb_node *node;\n\tstruct pending_reservation *pr;\n\n\tprintk(KERN_DEBUG \"pending reservations for inode %lu:\", inode->i_ino);\n\ttree = &EXT4_I(inode)->i_pending_tree;\n\tnode = rb_first(&tree->root);\n\twhile (node) {\n\t\tpr = rb_entry(node, struct pending_reservation, rb_node);\n\t\tprintk(KERN_DEBUG \" %u\", pr->lclu);\n\t\tnode = rb_next(node);\n\t}\n\tprintk(KERN_DEBUG \"\\n\");\n}\n#else\n#define ext4_print_pending_tree(inode)\n#endif\n\nint __init ext4_init_pending(void)\n{\n\text4_pending_cachep = KMEM_CACHE(pending_reservation, SLAB_RECLAIM_ACCOUNT);\n\tif (ext4_pending_cachep == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid ext4_exit_pending(void)\n{\n\tkmem_cache_destroy(ext4_pending_cachep);\n}\n\nvoid ext4_init_pending_tree(struct ext4_pending_tree *tree)\n{\n\ttree->root = RB_ROOT;\n}\n\n \nstatic struct pending_reservation *__get_pending(struct inode *inode,\n\t\t\t\t\t\t ext4_lblk_t lclu)\n{\n\tstruct ext4_pending_tree *tree;\n\tstruct rb_node *node;\n\tstruct pending_reservation *pr = NULL;\n\n\ttree = &EXT4_I(inode)->i_pending_tree;\n\tnode = (&tree->root)->rb_node;\n\n\twhile (node) {\n\t\tpr = rb_entry(node, struct pending_reservation, rb_node);\n\t\tif (lclu < pr->lclu)\n\t\t\tnode = node->rb_left;\n\t\telse if (lclu > pr->lclu)\n\t\t\tnode = node->rb_right;\n\t\telse if (lclu == pr->lclu)\n\t\t\treturn pr;\n\t}\n\treturn NULL;\n}\n\n \nstatic int __insert_pending(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t    struct pending_reservation **prealloc)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct ext4_pending_tree *tree = &EXT4_I(inode)->i_pending_tree;\n\tstruct rb_node **p = &tree->root.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct pending_reservation *pr;\n\text4_lblk_t lclu;\n\tint ret = 0;\n\n\tlclu = EXT4_B2C(sbi, lblk);\n\t \n\twhile (*p) {\n\t\tparent = *p;\n\t\tpr = rb_entry(parent, struct pending_reservation, rb_node);\n\n\t\tif (lclu < pr->lclu) {\n\t\t\tp = &(*p)->rb_left;\n\t\t} else if (lclu > pr->lclu) {\n\t\t\tp = &(*p)->rb_right;\n\t\t} else {\n\t\t\t \n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (likely(*prealloc == NULL)) {\n\t\tpr = __alloc_pending(false);\n\t\tif (!pr) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpr = *prealloc;\n\t\t*prealloc = NULL;\n\t}\n\tpr->lclu = lclu;\n\n\trb_link_node(&pr->rb_node, parent, p);\n\trb_insert_color(&pr->rb_node, &tree->root);\n\nout:\n\treturn ret;\n}\n\n \nstatic void __remove_pending(struct inode *inode, ext4_lblk_t lblk)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct pending_reservation *pr;\n\tstruct ext4_pending_tree *tree;\n\n\tpr = __get_pending(inode, EXT4_B2C(sbi, lblk));\n\tif (pr != NULL) {\n\t\ttree = &EXT4_I(inode)->i_pending_tree;\n\t\trb_erase(&pr->rb_node, &tree->root);\n\t\t__free_pending(pr);\n\t}\n}\n\n \nvoid ext4_remove_pending(struct inode *inode, ext4_lblk_t lblk)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\n\twrite_lock(&ei->i_es_lock);\n\t__remove_pending(inode, lblk);\n\twrite_unlock(&ei->i_es_lock);\n}\n\n \nbool ext4_is_pending(struct inode *inode, ext4_lblk_t lblk)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tbool ret;\n\n\tread_lock(&ei->i_es_lock);\n\tret = (bool)(__get_pending(inode, EXT4_B2C(sbi, lblk)) != NULL);\n\tread_unlock(&ei->i_es_lock);\n\n\treturn ret;\n}\n\n \nvoid ext4_es_insert_delayed_block(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t\t  bool allocated)\n{\n\tstruct extent_status newes;\n\tint err1 = 0, err2 = 0, err3 = 0;\n\tstruct extent_status *es1 = NULL;\n\tstruct extent_status *es2 = NULL;\n\tstruct pending_reservation *pr = NULL;\n\n\tif (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\treturn;\n\n\tes_debug(\"add [%u/1) delayed to extent status tree of inode %lu\\n\",\n\t\t lblk, inode->i_ino);\n\n\tnewes.es_lblk = lblk;\n\tnewes.es_len = 1;\n\text4_es_store_pblock_status(&newes, ~0, EXTENT_STATUS_DELAYED);\n\ttrace_ext4_es_insert_delayed_block(inode, &newes, allocated);\n\n\text4_es_insert_extent_check(inode, &newes);\n\nretry:\n\tif (err1 && !es1)\n\t\tes1 = __es_alloc_extent(true);\n\tif ((err1 || err2) && !es2)\n\t\tes2 = __es_alloc_extent(true);\n\tif ((err1 || err2 || err3) && allocated && !pr)\n\t\tpr = __alloc_pending(true);\n\twrite_lock(&EXT4_I(inode)->i_es_lock);\n\n\terr1 = __es_remove_extent(inode, lblk, lblk, NULL, es1);\n\tif (err1 != 0)\n\t\tgoto error;\n\t \n\tif (es1) {\n\t\tif (!es1->es_len)\n\t\t\t__es_free_extent(es1);\n\t\tes1 = NULL;\n\t}\n\n\terr2 = __es_insert_extent(inode, &newes, es2);\n\tif (err2 != 0)\n\t\tgoto error;\n\t \n\tif (es2) {\n\t\tif (!es2->es_len)\n\t\t\t__es_free_extent(es2);\n\t\tes2 = NULL;\n\t}\n\n\tif (allocated) {\n\t\terr3 = __insert_pending(inode, lblk, &pr);\n\t\tif (err3 != 0)\n\t\t\tgoto error;\n\t\tif (pr) {\n\t\t\t__free_pending(pr);\n\t\t\tpr = NULL;\n\t\t}\n\t}\nerror:\n\twrite_unlock(&EXT4_I(inode)->i_es_lock);\n\tif (err1 || err2 || err3)\n\t\tgoto retry;\n\n\text4_es_print_tree(inode);\n\text4_print_pending_tree(inode);\n\treturn;\n}\n\n \nstatic unsigned int __es_delayed_clu(struct inode *inode, ext4_lblk_t start,\n\t\t\t\t     ext4_lblk_t end)\n{\n\tstruct ext4_es_tree *tree = &EXT4_I(inode)->i_es_tree;\n\tstruct extent_status *es;\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct rb_node *node;\n\text4_lblk_t first_lclu, last_lclu;\n\tunsigned long long last_counted_lclu;\n\tunsigned int n = 0;\n\n\t \n\tlast_counted_lclu = ~0ULL;\n\n\tes = __es_tree_search(&tree->root, start);\n\n\twhile (es && (es->es_lblk <= end)) {\n\t\tif (ext4_es_is_delonly(es)) {\n\t\t\tif (es->es_lblk <= start)\n\t\t\t\tfirst_lclu = EXT4_B2C(sbi, start);\n\t\t\telse\n\t\t\t\tfirst_lclu = EXT4_B2C(sbi, es->es_lblk);\n\n\t\t\tif (ext4_es_end(es) >= end)\n\t\t\t\tlast_lclu = EXT4_B2C(sbi, end);\n\t\t\telse\n\t\t\t\tlast_lclu = EXT4_B2C(sbi, ext4_es_end(es));\n\n\t\t\tif (first_lclu == last_counted_lclu)\n\t\t\t\tn += last_lclu - first_lclu;\n\t\t\telse\n\t\t\t\tn += last_lclu - first_lclu + 1;\n\t\t\tlast_counted_lclu = last_lclu;\n\t\t}\n\t\tnode = rb_next(&es->rb_node);\n\t\tif (!node)\n\t\t\tbreak;\n\t\tes = rb_entry(node, struct extent_status, rb_node);\n\t}\n\n\treturn n;\n}\n\n \nunsigned int ext4_es_delayed_clu(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t\t ext4_lblk_t len)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\text4_lblk_t end;\n\tunsigned int n;\n\n\tif (len == 0)\n\t\treturn 0;\n\n\tend = lblk + len - 1;\n\tWARN_ON(end < lblk);\n\n\tread_lock(&ei->i_es_lock);\n\n\tn = __es_delayed_clu(inode, lblk, end);\n\n\tread_unlock(&ei->i_es_lock);\n\n\treturn n;\n}\n\n \nstatic int __revise_pending(struct inode *inode, ext4_lblk_t lblk,\n\t\t\t    ext4_lblk_t len,\n\t\t\t    struct pending_reservation **prealloc)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\text4_lblk_t end = lblk + len - 1;\n\text4_lblk_t first, last;\n\tbool f_del = false, l_del = false;\n\tint ret = 0;\n\n\tif (len == 0)\n\t\treturn 0;\n\n\t \n\n\tif (EXT4_B2C(sbi, lblk) == EXT4_B2C(sbi, end)) {\n\t\tfirst = EXT4_LBLK_CMASK(sbi, lblk);\n\t\tif (first != lblk)\n\t\t\tf_del = __es_scan_range(inode, &ext4_es_is_delonly,\n\t\t\t\t\t\tfirst, lblk - 1);\n\t\tif (f_del) {\n\t\t\tret = __insert_pending(inode, first, prealloc);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\tlast = EXT4_LBLK_CMASK(sbi, end) +\n\t\t\t       sbi->s_cluster_ratio - 1;\n\t\t\tif (last != end)\n\t\t\t\tl_del = __es_scan_range(inode,\n\t\t\t\t\t\t\t&ext4_es_is_delonly,\n\t\t\t\t\t\t\tend + 1, last);\n\t\t\tif (l_del) {\n\t\t\t\tret = __insert_pending(inode, last, prealloc);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tgoto out;\n\t\t\t} else\n\t\t\t\t__remove_pending(inode, last);\n\t\t}\n\t} else {\n\t\tfirst = EXT4_LBLK_CMASK(sbi, lblk);\n\t\tif (first != lblk)\n\t\t\tf_del = __es_scan_range(inode, &ext4_es_is_delonly,\n\t\t\t\t\t\tfirst, lblk - 1);\n\t\tif (f_del) {\n\t\t\tret = __insert_pending(inode, first, prealloc);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t} else\n\t\t\t__remove_pending(inode, first);\n\n\t\tlast = EXT4_LBLK_CMASK(sbi, end) + sbi->s_cluster_ratio - 1;\n\t\tif (last != end)\n\t\t\tl_del = __es_scan_range(inode, &ext4_es_is_delonly,\n\t\t\t\t\t\tend + 1, last);\n\t\tif (l_del) {\n\t\t\tret = __insert_pending(inode, last, prealloc);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t} else\n\t\t\t__remove_pending(inode, last);\n\t}\nout:\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}