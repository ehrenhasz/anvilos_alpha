{
  "module_name": "inode.c",
  "hash_id": "2b5080787033016df397367c0e6802685df37603340ee4749b90804de636a83a",
  "original_prompt": "Ingested from linux-6.6.14/fs/ext4/inode.c",
  "human_readable_source": "\n \n\n#include <linux/fs.h>\n#include <linux/mount.h>\n#include <linux/time.h>\n#include <linux/highuid.h>\n#include <linux/pagemap.h>\n#include <linux/dax.h>\n#include <linux/quotaops.h>\n#include <linux/string.h>\n#include <linux/buffer_head.h>\n#include <linux/writeback.h>\n#include <linux/pagevec.h>\n#include <linux/mpage.h>\n#include <linux/namei.h>\n#include <linux/uio.h>\n#include <linux/bio.h>\n#include <linux/workqueue.h>\n#include <linux/kernel.h>\n#include <linux/printk.h>\n#include <linux/slab.h>\n#include <linux/bitops.h>\n#include <linux/iomap.h>\n#include <linux/iversion.h>\n\n#include \"ext4_jbd2.h\"\n#include \"xattr.h\"\n#include \"acl.h\"\n#include \"truncate.h\"\n\n#include <trace/events/ext4.h>\n\nstatic __u32 ext4_inode_csum(struct inode *inode, struct ext4_inode *raw,\n\t\t\t      struct ext4_inode_info *ei)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\t__u32 csum;\n\t__u16 dummy_csum = 0;\n\tint offset = offsetof(struct ext4_inode, i_checksum_lo);\n\tunsigned int csum_size = sizeof(dummy_csum);\n\n\tcsum = ext4_chksum(sbi, ei->i_csum_seed, (__u8 *)raw, offset);\n\tcsum = ext4_chksum(sbi, csum, (__u8 *)&dummy_csum, csum_size);\n\toffset += csum_size;\n\tcsum = ext4_chksum(sbi, csum, (__u8 *)raw + offset,\n\t\t\t   EXT4_GOOD_OLD_INODE_SIZE - offset);\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\toffset = offsetof(struct ext4_inode, i_checksum_hi);\n\t\tcsum = ext4_chksum(sbi, csum, (__u8 *)raw +\n\t\t\t\t   EXT4_GOOD_OLD_INODE_SIZE,\n\t\t\t\t   offset - EXT4_GOOD_OLD_INODE_SIZE);\n\t\tif (EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi)) {\n\t\t\tcsum = ext4_chksum(sbi, csum, (__u8 *)&dummy_csum,\n\t\t\t\t\t   csum_size);\n\t\t\toffset += csum_size;\n\t\t}\n\t\tcsum = ext4_chksum(sbi, csum, (__u8 *)raw + offset,\n\t\t\t\t   EXT4_INODE_SIZE(inode->i_sb) - offset);\n\t}\n\n\treturn csum;\n}\n\nstatic int ext4_inode_csum_verify(struct inode *inode, struct ext4_inode *raw,\n\t\t\t\t  struct ext4_inode_info *ei)\n{\n\t__u32 provided, calculated;\n\n\tif (EXT4_SB(inode->i_sb)->s_es->s_creator_os !=\n\t    cpu_to_le32(EXT4_OS_LINUX) ||\n\t    !ext4_has_metadata_csum(inode->i_sb))\n\t\treturn 1;\n\n\tprovided = le16_to_cpu(raw->i_checksum_lo);\n\tcalculated = ext4_inode_csum(inode, raw, ei);\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi))\n\t\tprovided |= ((__u32)le16_to_cpu(raw->i_checksum_hi)) << 16;\n\telse\n\t\tcalculated &= 0xFFFF;\n\n\treturn provided == calculated;\n}\n\nvoid ext4_inode_csum_set(struct inode *inode, struct ext4_inode *raw,\n\t\t\t struct ext4_inode_info *ei)\n{\n\t__u32 csum;\n\n\tif (EXT4_SB(inode->i_sb)->s_es->s_creator_os !=\n\t    cpu_to_le32(EXT4_OS_LINUX) ||\n\t    !ext4_has_metadata_csum(inode->i_sb))\n\t\treturn;\n\n\tcsum = ext4_inode_csum(inode, raw, ei);\n\traw->i_checksum_lo = cpu_to_le16(csum & 0xFFFF);\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi))\n\t\traw->i_checksum_hi = cpu_to_le16(csum >> 16);\n}\n\nstatic inline int ext4_begin_ordered_truncate(struct inode *inode,\n\t\t\t\t\t      loff_t new_size)\n{\n\ttrace_ext4_begin_ordered_truncate(inode, new_size);\n\t \n\tif (!EXT4_I(inode)->jinode)\n\t\treturn 0;\n\treturn jbd2_journal_begin_ordered_truncate(EXT4_JOURNAL(inode),\n\t\t\t\t\t\t   EXT4_I(inode)->jinode,\n\t\t\t\t\t\t   new_size);\n}\n\nstatic int ext4_meta_trans_blocks(struct inode *inode, int lblocks,\n\t\t\t\t  int pextents);\n\n \nint ext4_inode_is_fast_symlink(struct inode *inode)\n{\n\tif (!(EXT4_I(inode)->i_flags & EXT4_EA_INODE_FL)) {\n\t\tint ea_blocks = EXT4_I(inode)->i_file_acl ?\n\t\t\t\tEXT4_CLUSTER_SIZE(inode->i_sb) >> 9 : 0;\n\n\t\tif (ext4_has_inline_data(inode))\n\t\t\treturn 0;\n\n\t\treturn (S_ISLNK(inode->i_mode) && inode->i_blocks - ea_blocks == 0);\n\t}\n\treturn S_ISLNK(inode->i_mode) && inode->i_size &&\n\t       (inode->i_size < EXT4_N_BLOCKS * 4);\n}\n\n \nvoid ext4_evict_inode(struct inode *inode)\n{\n\thandle_t *handle;\n\tint err;\n\t \n\tint extra_credits = 6;\n\tstruct ext4_xattr_inode_array *ea_inode_array = NULL;\n\tbool freeze_protected = false;\n\n\ttrace_ext4_evict_inode(inode);\n\n\tif (EXT4_I(inode)->i_flags & EXT4_EA_INODE_FL)\n\t\text4_evict_ea_inode(inode);\n\tif (inode->i_nlink) {\n\t\ttruncate_inode_pages_final(&inode->i_data);\n\n\t\tgoto no_delete;\n\t}\n\n\tif (is_bad_inode(inode))\n\t\tgoto no_delete;\n\tdquot_initialize(inode);\n\n\tif (ext4_should_order_data(inode))\n\t\text4_begin_ordered_truncate(inode, 0);\n\ttruncate_inode_pages_final(&inode->i_data);\n\n\t \n\tif (!list_empty_careful(&inode->i_io_list))\n\t\tinode_io_list_del(inode);\n\n\t \n\tif (!ext4_journal_current_handle()) {\n\t\tsb_start_intwrite(inode->i_sb);\n\t\tfreeze_protected = true;\n\t}\n\n\tif (!IS_NOQUOTA(inode))\n\t\textra_credits += EXT4_MAXQUOTAS_DEL_BLOCKS(inode->i_sb);\n\n\t \n\thandle = ext4_journal_start(inode, EXT4_HT_TRUNCATE,\n\t\t\t ext4_blocks_for_truncate(inode) + extra_credits - 3);\n\tif (IS_ERR(handle)) {\n\t\text4_std_error(inode->i_sb, PTR_ERR(handle));\n\t\t \n\t\text4_orphan_del(NULL, inode);\n\t\tif (freeze_protected)\n\t\t\tsb_end_intwrite(inode->i_sb);\n\t\tgoto no_delete;\n\t}\n\n\tif (IS_SYNC(inode))\n\t\text4_handle_sync(handle);\n\n\t \n\tif (ext4_inode_is_fast_symlink(inode))\n\t\tmemset(EXT4_I(inode)->i_data, 0, sizeof(EXT4_I(inode)->i_data));\n\tinode->i_size = 0;\n\terr = ext4_mark_inode_dirty(handle, inode);\n\tif (err) {\n\t\text4_warning(inode->i_sb,\n\t\t\t     \"couldn't mark inode dirty (err %d)\", err);\n\t\tgoto stop_handle;\n\t}\n\tif (inode->i_blocks) {\n\t\terr = ext4_truncate(inode);\n\t\tif (err) {\n\t\t\text4_error_err(inode->i_sb, -err,\n\t\t\t\t       \"couldn't truncate inode %lu (err %d)\",\n\t\t\t\t       inode->i_ino, err);\n\t\t\tgoto stop_handle;\n\t\t}\n\t}\n\n\t \n\terr = ext4_xattr_delete_inode(handle, inode, &ea_inode_array,\n\t\t\t\t      extra_credits);\n\tif (err) {\n\t\text4_warning(inode->i_sb, \"xattr delete (err %d)\", err);\nstop_handle:\n\t\text4_journal_stop(handle);\n\t\text4_orphan_del(NULL, inode);\n\t\tif (freeze_protected)\n\t\t\tsb_end_intwrite(inode->i_sb);\n\t\text4_xattr_inode_array_free(ea_inode_array);\n\t\tgoto no_delete;\n\t}\n\n\t \n\text4_orphan_del(handle, inode);\n\tEXT4_I(inode)->i_dtime\t= (__u32)ktime_get_real_seconds();\n\n\t \n\tif (ext4_mark_inode_dirty(handle, inode))\n\t\t \n\t\text4_clear_inode(inode);\n\telse\n\t\text4_free_inode(handle, inode);\n\text4_journal_stop(handle);\n\tif (freeze_protected)\n\t\tsb_end_intwrite(inode->i_sb);\n\text4_xattr_inode_array_free(ea_inode_array);\n\treturn;\nno_delete:\n\t \n\tWARN_ON_ONCE(!list_empty_careful(&inode->i_io_list));\n\n\tif (!list_empty(&EXT4_I(inode)->i_fc_list))\n\t\text4_fc_mark_ineligible(inode->i_sb, EXT4_FC_REASON_NOMEM, NULL);\n\text4_clear_inode(inode);\t \n}\n\n#ifdef CONFIG_QUOTA\nqsize_t *ext4_get_reserved_space(struct inode *inode)\n{\n\treturn &EXT4_I(inode)->i_reserved_quota;\n}\n#endif\n\n \nvoid ext4_da_update_reserve_space(struct inode *inode,\n\t\t\t\t\tint used, int quota_claim)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\n\tspin_lock(&ei->i_block_reservation_lock);\n\ttrace_ext4_da_update_reserve_space(inode, used, quota_claim);\n\tif (unlikely(used > ei->i_reserved_data_blocks)) {\n\t\text4_warning(inode->i_sb, \"%s: ino %lu, used %d \"\n\t\t\t \"with only %d reserved data blocks\",\n\t\t\t __func__, inode->i_ino, used,\n\t\t\t ei->i_reserved_data_blocks);\n\t\tWARN_ON(1);\n\t\tused = ei->i_reserved_data_blocks;\n\t}\n\n\t \n\tei->i_reserved_data_blocks -= used;\n\tpercpu_counter_sub(&sbi->s_dirtyclusters_counter, used);\n\n\tspin_unlock(&ei->i_block_reservation_lock);\n\n\t \n\tif (quota_claim)\n\t\tdquot_claim_block(inode, EXT4_C2B(sbi, used));\n\telse {\n\t\t \n\t\tdquot_release_reservation_block(inode, EXT4_C2B(sbi, used));\n\t}\n\n\t \n\tif ((ei->i_reserved_data_blocks == 0) &&\n\t    !inode_is_open_for_write(inode))\n\t\text4_discard_preallocations(inode, 0);\n}\n\nstatic int __check_block_validity(struct inode *inode, const char *func,\n\t\t\t\tunsigned int line,\n\t\t\t\tstruct ext4_map_blocks *map)\n{\n\tif (ext4_has_feature_journal(inode->i_sb) &&\n\t    (inode->i_ino ==\n\t     le32_to_cpu(EXT4_SB(inode->i_sb)->s_es->s_journal_inum)))\n\t\treturn 0;\n\tif (!ext4_inode_block_valid(inode, map->m_pblk, map->m_len)) {\n\t\text4_error_inode(inode, func, line, map->m_pblk,\n\t\t\t\t \"lblock %lu mapped to illegal pblock %llu \"\n\t\t\t\t \"(length %d)\", (unsigned long) map->m_lblk,\n\t\t\t\t map->m_pblk, map->m_len);\n\t\treturn -EFSCORRUPTED;\n\t}\n\treturn 0;\n}\n\nint ext4_issue_zeroout(struct inode *inode, ext4_lblk_t lblk, ext4_fsblk_t pblk,\n\t\t       ext4_lblk_t len)\n{\n\tint ret;\n\n\tif (IS_ENCRYPTED(inode) && S_ISREG(inode->i_mode))\n\t\treturn fscrypt_zeroout_range(inode, lblk, pblk, len);\n\n\tret = sb_issue_zeroout(inode->i_sb, pblk, len, GFP_NOFS);\n\tif (ret > 0)\n\t\tret = 0;\n\n\treturn ret;\n}\n\n#define check_block_validity(inode, map)\t\\\n\t__check_block_validity((inode), __func__, __LINE__, (map))\n\n#ifdef ES_AGGRESSIVE_TEST\nstatic void ext4_map_blocks_es_recheck(handle_t *handle,\n\t\t\t\t       struct inode *inode,\n\t\t\t\t       struct ext4_map_blocks *es_map,\n\t\t\t\t       struct ext4_map_blocks *map,\n\t\t\t\t       int flags)\n{\n\tint retval;\n\n\tmap->m_flags = 0;\n\t \n\tdown_read(&EXT4_I(inode)->i_data_sem);\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {\n\t\tretval = ext4_ext_map_blocks(handle, inode, map, 0);\n\t} else {\n\t\tretval = ext4_ind_map_blocks(handle, inode, map, 0);\n\t}\n\tup_read((&EXT4_I(inode)->i_data_sem));\n\n\t \n\tif (es_map->m_lblk != map->m_lblk ||\n\t    es_map->m_flags != map->m_flags ||\n\t    es_map->m_pblk != map->m_pblk) {\n\t\tprintk(\"ES cache assertion failed for inode: %lu \"\n\t\t       \"es_cached ex [%d/%d/%llu/%x] != \"\n\t\t       \"found ex [%d/%d/%llu/%x] retval %d flags %x\\n\",\n\t\t       inode->i_ino, es_map->m_lblk, es_map->m_len,\n\t\t       es_map->m_pblk, es_map->m_flags, map->m_lblk,\n\t\t       map->m_len, map->m_pblk, map->m_flags,\n\t\t       retval, flags);\n\t}\n}\n#endif  \n\n \nint ext4_map_blocks(handle_t *handle, struct inode *inode,\n\t\t    struct ext4_map_blocks *map, int flags)\n{\n\tstruct extent_status es;\n\tint retval;\n\tint ret = 0;\n#ifdef ES_AGGRESSIVE_TEST\n\tstruct ext4_map_blocks orig_map;\n\n\tmemcpy(&orig_map, map, sizeof(*map));\n#endif\n\n\tmap->m_flags = 0;\n\text_debug(inode, \"flag 0x%x, max_blocks %u, logical block %lu\\n\",\n\t\t  flags, map->m_len, (unsigned long) map->m_lblk);\n\n\t \n\tif (unlikely(map->m_len > INT_MAX))\n\t\tmap->m_len = INT_MAX;\n\n\t \n\tif (unlikely(map->m_lblk >= EXT_MAX_BLOCKS))\n\t\treturn -EFSCORRUPTED;\n\n\t \n\tif (!(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY) &&\n\t    ext4_es_lookup_extent(inode, map->m_lblk, NULL, &es)) {\n\t\tif (ext4_es_is_written(&es) || ext4_es_is_unwritten(&es)) {\n\t\t\tmap->m_pblk = ext4_es_pblock(&es) +\n\t\t\t\t\tmap->m_lblk - es.es_lblk;\n\t\t\tmap->m_flags |= ext4_es_is_written(&es) ?\n\t\t\t\t\tEXT4_MAP_MAPPED : EXT4_MAP_UNWRITTEN;\n\t\t\tretval = es.es_len - (map->m_lblk - es.es_lblk);\n\t\t\tif (retval > map->m_len)\n\t\t\t\tretval = map->m_len;\n\t\t\tmap->m_len = retval;\n\t\t} else if (ext4_es_is_delayed(&es) || ext4_es_is_hole(&es)) {\n\t\t\tmap->m_pblk = 0;\n\t\t\tretval = es.es_len - (map->m_lblk - es.es_lblk);\n\t\t\tif (retval > map->m_len)\n\t\t\t\tretval = map->m_len;\n\t\t\tmap->m_len = retval;\n\t\t\tretval = 0;\n\t\t} else {\n\t\t\tBUG();\n\t\t}\n\n\t\tif (flags & EXT4_GET_BLOCKS_CACHED_NOWAIT)\n\t\t\treturn retval;\n#ifdef ES_AGGRESSIVE_TEST\n\t\text4_map_blocks_es_recheck(handle, inode, map,\n\t\t\t\t\t   &orig_map, flags);\n#endif\n\t\tgoto found;\n\t}\n\t \n\tif (flags & EXT4_GET_BLOCKS_CACHED_NOWAIT)\n\t\treturn 0;\n\n\t \n\tdown_read(&EXT4_I(inode)->i_data_sem);\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {\n\t\tretval = ext4_ext_map_blocks(handle, inode, map, 0);\n\t} else {\n\t\tretval = ext4_ind_map_blocks(handle, inode, map, 0);\n\t}\n\tif (retval > 0) {\n\t\tunsigned int status;\n\n\t\tif (unlikely(retval != map->m_len)) {\n\t\t\text4_warning(inode->i_sb,\n\t\t\t\t     \"ES len assertion failed for inode \"\n\t\t\t\t     \"%lu: retval %d != map->m_len %d\",\n\t\t\t\t     inode->i_ino, retval, map->m_len);\n\t\t\tWARN_ON(1);\n\t\t}\n\n\t\tstatus = map->m_flags & EXT4_MAP_UNWRITTEN ?\n\t\t\t\tEXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;\n\t\tif (!(flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE) &&\n\t\t    !(status & EXTENT_STATUS_WRITTEN) &&\n\t\t    ext4_es_scan_range(inode, &ext4_es_is_delayed, map->m_lblk,\n\t\t\t\t       map->m_lblk + map->m_len - 1))\n\t\t\tstatus |= EXTENT_STATUS_DELAYED;\n\t\text4_es_insert_extent(inode, map->m_lblk, map->m_len,\n\t\t\t\t      map->m_pblk, status);\n\t}\n\tup_read((&EXT4_I(inode)->i_data_sem));\n\nfound:\n\tif (retval > 0 && map->m_flags & EXT4_MAP_MAPPED) {\n\t\tret = check_block_validity(inode, map);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\n\t \n\tif ((flags & EXT4_GET_BLOCKS_CREATE) == 0)\n\t\treturn retval;\n\n\t \n\tif (retval > 0 && map->m_flags & EXT4_MAP_MAPPED)\n\t\t \n\t\tif (!(flags & EXT4_GET_BLOCKS_CONVERT_UNWRITTEN))\n\t\t\treturn retval;\n\n\t \n\tmap->m_flags &= ~EXT4_MAP_FLAGS;\n\n\t \n\tdown_write(&EXT4_I(inode)->i_data_sem);\n\n\t \n\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {\n\t\tretval = ext4_ext_map_blocks(handle, inode, map, flags);\n\t} else {\n\t\tretval = ext4_ind_map_blocks(handle, inode, map, flags);\n\n\t\tif (retval > 0 && map->m_flags & EXT4_MAP_NEW) {\n\t\t\t \n\t\t\text4_clear_inode_state(inode, EXT4_STATE_EXT_MIGRATE);\n\t\t}\n\t}\n\n\tif (retval > 0) {\n\t\tunsigned int status;\n\n\t\tif (unlikely(retval != map->m_len)) {\n\t\t\text4_warning(inode->i_sb,\n\t\t\t\t     \"ES len assertion failed for inode \"\n\t\t\t\t     \"%lu: retval %d != map->m_len %d\",\n\t\t\t\t     inode->i_ino, retval, map->m_len);\n\t\t\tWARN_ON(1);\n\t\t}\n\n\t\t \n\t\tif (flags & EXT4_GET_BLOCKS_ZERO &&\n\t\t    map->m_flags & EXT4_MAP_MAPPED &&\n\t\t    map->m_flags & EXT4_MAP_NEW) {\n\t\t\tret = ext4_issue_zeroout(inode, map->m_lblk,\n\t\t\t\t\t\t map->m_pblk, map->m_len);\n\t\t\tif (ret) {\n\t\t\t\tretval = ret;\n\t\t\t\tgoto out_sem;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif ((flags & EXT4_GET_BLOCKS_PRE_IO) &&\n\t\t    ext4_es_lookup_extent(inode, map->m_lblk, NULL, &es)) {\n\t\t\tif (ext4_es_is_written(&es))\n\t\t\t\tgoto out_sem;\n\t\t}\n\t\tstatus = map->m_flags & EXT4_MAP_UNWRITTEN ?\n\t\t\t\tEXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;\n\t\tif (!(flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE) &&\n\t\t    !(status & EXTENT_STATUS_WRITTEN) &&\n\t\t    ext4_es_scan_range(inode, &ext4_es_is_delayed, map->m_lblk,\n\t\t\t\t       map->m_lblk + map->m_len - 1))\n\t\t\tstatus |= EXTENT_STATUS_DELAYED;\n\t\text4_es_insert_extent(inode, map->m_lblk, map->m_len,\n\t\t\t\t      map->m_pblk, status);\n\t}\n\nout_sem:\n\tup_write((&EXT4_I(inode)->i_data_sem));\n\tif (retval > 0 && map->m_flags & EXT4_MAP_MAPPED) {\n\t\tret = check_block_validity(inode, map);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\n\t\t \n\t\tif (map->m_flags & EXT4_MAP_NEW &&\n\t\t    !(map->m_flags & EXT4_MAP_UNWRITTEN) &&\n\t\t    !(flags & EXT4_GET_BLOCKS_ZERO) &&\n\t\t    !ext4_is_quota_file(inode) &&\n\t\t    ext4_should_order_data(inode)) {\n\t\t\tloff_t start_byte =\n\t\t\t\t(loff_t)map->m_lblk << inode->i_blkbits;\n\t\t\tloff_t length = (loff_t)map->m_len << inode->i_blkbits;\n\n\t\t\tif (flags & EXT4_GET_BLOCKS_IO_SUBMIT)\n\t\t\t\tret = ext4_jbd2_inode_add_wait(handle, inode,\n\t\t\t\t\t\tstart_byte, length);\n\t\t\telse\n\t\t\t\tret = ext4_jbd2_inode_add_write(handle, inode,\n\t\t\t\t\t\tstart_byte, length);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\tif (retval > 0 && (map->m_flags & EXT4_MAP_UNWRITTEN ||\n\t\t\t\tmap->m_flags & EXT4_MAP_MAPPED))\n\t\text4_fc_track_range(handle, inode, map->m_lblk,\n\t\t\t\t\tmap->m_lblk + map->m_len - 1);\n\tif (retval < 0)\n\t\text_debug(inode, \"failed with err %d\\n\", retval);\n\treturn retval;\n}\n\n \nstatic void ext4_update_bh_state(struct buffer_head *bh, unsigned long flags)\n{\n\tunsigned long old_state;\n\tunsigned long new_state;\n\n\tflags &= EXT4_MAP_FLAGS;\n\n\t \n\tif (!bh->b_page) {\n\t\tbh->b_state = (bh->b_state & ~EXT4_MAP_FLAGS) | flags;\n\t\treturn;\n\t}\n\t \n\told_state = READ_ONCE(bh->b_state);\n\tdo {\n\t\tnew_state = (old_state & ~EXT4_MAP_FLAGS) | flags;\n\t} while (unlikely(!try_cmpxchg(&bh->b_state, &old_state, new_state)));\n}\n\nstatic int _ext4_get_block(struct inode *inode, sector_t iblock,\n\t\t\t   struct buffer_head *bh, int flags)\n{\n\tstruct ext4_map_blocks map;\n\tint ret = 0;\n\n\tif (ext4_has_inline_data(inode))\n\t\treturn -ERANGE;\n\n\tmap.m_lblk = iblock;\n\tmap.m_len = bh->b_size >> inode->i_blkbits;\n\n\tret = ext4_map_blocks(ext4_journal_current_handle(), inode, &map,\n\t\t\t      flags);\n\tif (ret > 0) {\n\t\tmap_bh(bh, inode->i_sb, map.m_pblk);\n\t\text4_update_bh_state(bh, map.m_flags);\n\t\tbh->b_size = inode->i_sb->s_blocksize * map.m_len;\n\t\tret = 0;\n\t} else if (ret == 0) {\n\t\t \n\t\tbh->b_size = inode->i_sb->s_blocksize * map.m_len;\n\t}\n\treturn ret;\n}\n\nint ext4_get_block(struct inode *inode, sector_t iblock,\n\t\t   struct buffer_head *bh, int create)\n{\n\treturn _ext4_get_block(inode, iblock, bh,\n\t\t\t       create ? EXT4_GET_BLOCKS_CREATE : 0);\n}\n\n \nint ext4_get_block_unwritten(struct inode *inode, sector_t iblock,\n\t\t\t     struct buffer_head *bh_result, int create)\n{\n\tint ret = 0;\n\n\text4_debug(\"ext4_get_block_unwritten: inode %lu, create flag %d\\n\",\n\t\t   inode->i_ino, create);\n\tret = _ext4_get_block(inode, iblock, bh_result,\n\t\t\t       EXT4_GET_BLOCKS_CREATE_UNWRIT_EXT);\n\n\t \n\tif (ret == 0 && buffer_unwritten(bh_result))\n\t\tset_buffer_new(bh_result);\n\n\treturn ret;\n}\n\n \n#define DIO_MAX_BLOCKS 4096\n\n \nstruct buffer_head *ext4_getblk(handle_t *handle, struct inode *inode,\n\t\t\t\text4_lblk_t block, int map_flags)\n{\n\tstruct ext4_map_blocks map;\n\tstruct buffer_head *bh;\n\tint create = map_flags & EXT4_GET_BLOCKS_CREATE;\n\tbool nowait = map_flags & EXT4_GET_BLOCKS_CACHED_NOWAIT;\n\tint err;\n\n\tASSERT((EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\t    || handle != NULL || create == 0);\n\tASSERT(create == 0 || !nowait);\n\n\tmap.m_lblk = block;\n\tmap.m_len = 1;\n\terr = ext4_map_blocks(handle, inode, &map, map_flags);\n\n\tif (err == 0)\n\t\treturn create ? ERR_PTR(-ENOSPC) : NULL;\n\tif (err < 0)\n\t\treturn ERR_PTR(err);\n\n\tif (nowait)\n\t\treturn sb_find_get_block(inode->i_sb, map.m_pblk);\n\n\tbh = sb_getblk(inode->i_sb, map.m_pblk);\n\tif (unlikely(!bh))\n\t\treturn ERR_PTR(-ENOMEM);\n\tif (map.m_flags & EXT4_MAP_NEW) {\n\t\tASSERT(create != 0);\n\t\tASSERT((EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)\n\t\t\t    || (handle != NULL));\n\n\t\t \n\t\tlock_buffer(bh);\n\t\tBUFFER_TRACE(bh, \"call get_create_access\");\n\t\terr = ext4_journal_get_create_access(handle, inode->i_sb, bh,\n\t\t\t\t\t\t     EXT4_JTR_NONE);\n\t\tif (unlikely(err)) {\n\t\t\tunlock_buffer(bh);\n\t\t\tgoto errout;\n\t\t}\n\t\tif (!buffer_uptodate(bh)) {\n\t\t\tmemset(bh->b_data, 0, inode->i_sb->s_blocksize);\n\t\t\tset_buffer_uptodate(bh);\n\t\t}\n\t\tunlock_buffer(bh);\n\t\tBUFFER_TRACE(bh, \"call ext4_handle_dirty_metadata\");\n\t\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\t\tif (unlikely(err))\n\t\t\tgoto errout;\n\t} else\n\t\tBUFFER_TRACE(bh, \"not a new buffer\");\n\treturn bh;\nerrout:\n\tbrelse(bh);\n\treturn ERR_PTR(err);\n}\n\nstruct buffer_head *ext4_bread(handle_t *handle, struct inode *inode,\n\t\t\t       ext4_lblk_t block, int map_flags)\n{\n\tstruct buffer_head *bh;\n\tint ret;\n\n\tbh = ext4_getblk(handle, inode, block, map_flags);\n\tif (IS_ERR(bh))\n\t\treturn bh;\n\tif (!bh || ext4_buffer_uptodate(bh))\n\t\treturn bh;\n\n\tret = ext4_read_bh_lock(bh, REQ_META | REQ_PRIO, true);\n\tif (ret) {\n\t\tput_bh(bh);\n\t\treturn ERR_PTR(ret);\n\t}\n\treturn bh;\n}\n\n \nint ext4_bread_batch(struct inode *inode, ext4_lblk_t block, int bh_count,\n\t\t     bool wait, struct buffer_head **bhs)\n{\n\tint i, err;\n\n\tfor (i = 0; i < bh_count; i++) {\n\t\tbhs[i] = ext4_getblk(NULL, inode, block + i, 0  );\n\t\tif (IS_ERR(bhs[i])) {\n\t\t\terr = PTR_ERR(bhs[i]);\n\t\t\tbh_count = i;\n\t\t\tgoto out_brelse;\n\t\t}\n\t}\n\n\tfor (i = 0; i < bh_count; i++)\n\t\t \n\t\tif (bhs[i] && !ext4_buffer_uptodate(bhs[i]))\n\t\t\text4_read_bh_lock(bhs[i], REQ_META | REQ_PRIO, false);\n\n\tif (!wait)\n\t\treturn 0;\n\n\tfor (i = 0; i < bh_count; i++)\n\t\tif (bhs[i])\n\t\t\twait_on_buffer(bhs[i]);\n\n\tfor (i = 0; i < bh_count; i++) {\n\t\tif (bhs[i] && !buffer_uptodate(bhs[i])) {\n\t\t\terr = -EIO;\n\t\t\tgoto out_brelse;\n\t\t}\n\t}\n\treturn 0;\n\nout_brelse:\n\tfor (i = 0; i < bh_count; i++) {\n\t\tbrelse(bhs[i]);\n\t\tbhs[i] = NULL;\n\t}\n\treturn err;\n}\n\nint ext4_walk_page_buffers(handle_t *handle, struct inode *inode,\n\t\t\t   struct buffer_head *head,\n\t\t\t   unsigned from,\n\t\t\t   unsigned to,\n\t\t\t   int *partial,\n\t\t\t   int (*fn)(handle_t *handle, struct inode *inode,\n\t\t\t\t     struct buffer_head *bh))\n{\n\tstruct buffer_head *bh;\n\tunsigned block_start, block_end;\n\tunsigned blocksize = head->b_size;\n\tint err, ret = 0;\n\tstruct buffer_head *next;\n\n\tfor (bh = head, block_start = 0;\n\t     ret == 0 && (bh != head || !block_start);\n\t     block_start = block_end, bh = next) {\n\t\tnext = bh->b_this_page;\n\t\tblock_end = block_start + blocksize;\n\t\tif (block_end <= from || block_start >= to) {\n\t\t\tif (partial && !buffer_uptodate(bh))\n\t\t\t\t*partial = 1;\n\t\t\tcontinue;\n\t\t}\n\t\terr = (*fn)(handle, inode, bh);\n\t\tif (!ret)\n\t\t\tret = err;\n\t}\n\treturn ret;\n}\n\n \nstatic int ext4_dirty_journalled_data(handle_t *handle, struct buffer_head *bh)\n{\n\tfolio_mark_dirty(bh->b_folio);\n\treturn ext4_handle_dirty_metadata(handle, NULL, bh);\n}\n\nint do_journal_get_write_access(handle_t *handle, struct inode *inode,\n\t\t\t\tstruct buffer_head *bh)\n{\n\tint dirty = buffer_dirty(bh);\n\tint ret;\n\n\tif (!buffer_mapped(bh) || buffer_freed(bh))\n\t\treturn 0;\n\t \n\tif (dirty)\n\t\tclear_buffer_dirty(bh);\n\tBUFFER_TRACE(bh, \"get write access\");\n\tret = ext4_journal_get_write_access(handle, inode->i_sb, bh,\n\t\t\t\t\t    EXT4_JTR_NONE);\n\tif (!ret && dirty)\n\t\tret = ext4_dirty_journalled_data(handle, bh);\n\treturn ret;\n}\n\n#ifdef CONFIG_FS_ENCRYPTION\nstatic int ext4_block_write_begin(struct folio *folio, loff_t pos, unsigned len,\n\t\t\t\t  get_block_t *get_block)\n{\n\tunsigned from = pos & (PAGE_SIZE - 1);\n\tunsigned to = from + len;\n\tstruct inode *inode = folio->mapping->host;\n\tunsigned block_start, block_end;\n\tsector_t block;\n\tint err = 0;\n\tunsigned blocksize = inode->i_sb->s_blocksize;\n\tunsigned bbits;\n\tstruct buffer_head *bh, *head, *wait[2];\n\tint nr_wait = 0;\n\tint i;\n\n\tBUG_ON(!folio_test_locked(folio));\n\tBUG_ON(from > PAGE_SIZE);\n\tBUG_ON(to > PAGE_SIZE);\n\tBUG_ON(from > to);\n\n\thead = folio_buffers(folio);\n\tif (!head) {\n\t\tcreate_empty_buffers(&folio->page, blocksize, 0);\n\t\thead = folio_buffers(folio);\n\t}\n\tbbits = ilog2(blocksize);\n\tblock = (sector_t)folio->index << (PAGE_SHIFT - bbits);\n\n\tfor (bh = head, block_start = 0; bh != head || !block_start;\n\t    block++, block_start = block_end, bh = bh->b_this_page) {\n\t\tblock_end = block_start + blocksize;\n\t\tif (block_end <= from || block_start >= to) {\n\t\t\tif (folio_test_uptodate(folio)) {\n\t\t\t\tset_buffer_uptodate(bh);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tif (buffer_new(bh))\n\t\t\tclear_buffer_new(bh);\n\t\tif (!buffer_mapped(bh)) {\n\t\t\tWARN_ON(bh->b_size != blocksize);\n\t\t\terr = get_block(inode, block, bh, 1);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\tif (buffer_new(bh)) {\n\t\t\t\tif (folio_test_uptodate(folio)) {\n\t\t\t\t\tclear_buffer_new(bh);\n\t\t\t\t\tset_buffer_uptodate(bh);\n\t\t\t\t\tmark_buffer_dirty(bh);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (block_end > to || block_start < from)\n\t\t\t\t\tfolio_zero_segments(folio, to,\n\t\t\t\t\t\t\t    block_end,\n\t\t\t\t\t\t\t    block_start, from);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (folio_test_uptodate(folio)) {\n\t\t\tset_buffer_uptodate(bh);\n\t\t\tcontinue;\n\t\t}\n\t\tif (!buffer_uptodate(bh) && !buffer_delay(bh) &&\n\t\t    !buffer_unwritten(bh) &&\n\t\t    (block_start < from || block_end > to)) {\n\t\t\text4_read_bh_lock(bh, 0, false);\n\t\t\twait[nr_wait++] = bh;\n\t\t}\n\t}\n\t \n\tfor (i = 0; i < nr_wait; i++) {\n\t\twait_on_buffer(wait[i]);\n\t\tif (!buffer_uptodate(wait[i]))\n\t\t\terr = -EIO;\n\t}\n\tif (unlikely(err)) {\n\t\tfolio_zero_new_buffers(folio, from, to);\n\t} else if (fscrypt_inode_uses_fs_layer_crypto(inode)) {\n\t\tfor (i = 0; i < nr_wait; i++) {\n\t\t\tint err2;\n\n\t\t\terr2 = fscrypt_decrypt_pagecache_blocks(folio,\n\t\t\t\t\t\tblocksize, bh_offset(wait[i]));\n\t\t\tif (err2) {\n\t\t\t\tclear_buffer_uptodate(wait[i]);\n\t\t\t\terr = err2;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn err;\n}\n#endif\n\n \nstatic int ext4_write_begin(struct file *file, struct address_space *mapping,\n\t\t\t    loff_t pos, unsigned len,\n\t\t\t    struct page **pagep, void **fsdata)\n{\n\tstruct inode *inode = mapping->host;\n\tint ret, needed_blocks;\n\thandle_t *handle;\n\tint retries = 0;\n\tstruct folio *folio;\n\tpgoff_t index;\n\tunsigned from, to;\n\n\tif (unlikely(ext4_forced_shutdown(inode->i_sb)))\n\t\treturn -EIO;\n\n\ttrace_ext4_write_begin(inode, pos, len);\n\t \n\tneeded_blocks = ext4_writepage_trans_blocks(inode) + 1;\n\tindex = pos >> PAGE_SHIFT;\n\tfrom = pos & (PAGE_SIZE - 1);\n\tto = from + len;\n\n\tif (ext4_test_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA)) {\n\t\tret = ext4_try_to_write_inline_data(mapping, inode, pos, len,\n\t\t\t\t\t\t    pagep);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (ret == 1)\n\t\t\treturn 0;\n\t}\n\n\t \nretry_grab:\n\tfolio = __filemap_get_folio(mapping, index, FGP_WRITEBEGIN,\n\t\t\t\t\tmapping_gfp_mask(mapping));\n\tif (IS_ERR(folio))\n\t\treturn PTR_ERR(folio);\n\t \n\tif (!folio_buffers(folio))\n\t\tcreate_empty_buffers(&folio->page, inode->i_sb->s_blocksize, 0);\n\n\tfolio_unlock(folio);\n\nretry_journal:\n\thandle = ext4_journal_start(inode, EXT4_HT_WRITE_PAGE, needed_blocks);\n\tif (IS_ERR(handle)) {\n\t\tfolio_put(folio);\n\t\treturn PTR_ERR(handle);\n\t}\n\n\tfolio_lock(folio);\n\tif (folio->mapping != mapping) {\n\t\t \n\t\tfolio_unlock(folio);\n\t\tfolio_put(folio);\n\t\text4_journal_stop(handle);\n\t\tgoto retry_grab;\n\t}\n\t \n\tfolio_wait_stable(folio);\n\n#ifdef CONFIG_FS_ENCRYPTION\n\tif (ext4_should_dioread_nolock(inode))\n\t\tret = ext4_block_write_begin(folio, pos, len,\n\t\t\t\t\t     ext4_get_block_unwritten);\n\telse\n\t\tret = ext4_block_write_begin(folio, pos, len, ext4_get_block);\n#else\n\tif (ext4_should_dioread_nolock(inode))\n\t\tret = __block_write_begin(&folio->page, pos, len,\n\t\t\t\t\t  ext4_get_block_unwritten);\n\telse\n\t\tret = __block_write_begin(&folio->page, pos, len, ext4_get_block);\n#endif\n\tif (!ret && ext4_should_journal_data(inode)) {\n\t\tret = ext4_walk_page_buffers(handle, inode,\n\t\t\t\t\t     folio_buffers(folio), from, to,\n\t\t\t\t\t     NULL, do_journal_get_write_access);\n\t}\n\n\tif (ret) {\n\t\tbool extended = (pos + len > inode->i_size) &&\n\t\t\t\t!ext4_verity_in_progress(inode);\n\n\t\tfolio_unlock(folio);\n\t\t \n\t\tif (extended && ext4_can_truncate(inode))\n\t\t\text4_orphan_add(handle, inode);\n\n\t\text4_journal_stop(handle);\n\t\tif (extended) {\n\t\t\text4_truncate_failed_write(inode);\n\t\t\t \n\t\t\tif (inode->i_nlink)\n\t\t\t\text4_orphan_del(NULL, inode);\n\t\t}\n\n\t\tif (ret == -ENOSPC &&\n\t\t    ext4_should_retry_alloc(inode->i_sb, &retries))\n\t\t\tgoto retry_journal;\n\t\tfolio_put(folio);\n\t\treturn ret;\n\t}\n\t*pagep = &folio->page;\n\treturn ret;\n}\n\n \nstatic int write_end_fn(handle_t *handle, struct inode *inode,\n\t\t\tstruct buffer_head *bh)\n{\n\tint ret;\n\tif (!buffer_mapped(bh) || buffer_freed(bh))\n\t\treturn 0;\n\tset_buffer_uptodate(bh);\n\tret = ext4_dirty_journalled_data(handle, bh);\n\tclear_buffer_meta(bh);\n\tclear_buffer_prio(bh);\n\treturn ret;\n}\n\n \nstatic int ext4_write_end(struct file *file,\n\t\t\t  struct address_space *mapping,\n\t\t\t  loff_t pos, unsigned len, unsigned copied,\n\t\t\t  struct page *page, void *fsdata)\n{\n\tstruct folio *folio = page_folio(page);\n\thandle_t *handle = ext4_journal_current_handle();\n\tstruct inode *inode = mapping->host;\n\tloff_t old_size = inode->i_size;\n\tint ret = 0, ret2;\n\tint i_size_changed = 0;\n\tbool verity = ext4_verity_in_progress(inode);\n\n\ttrace_ext4_write_end(inode, pos, len, copied);\n\n\tif (ext4_has_inline_data(inode) &&\n\t    ext4_test_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA))\n\t\treturn ext4_write_inline_data_end(inode, pos, len, copied,\n\t\t\t\t\t\t  folio);\n\n\tcopied = block_write_end(file, mapping, pos, len, copied, page, fsdata);\n\t \n\tif (!verity)\n\t\ti_size_changed = ext4_update_inode_size(inode, pos + copied);\n\tfolio_unlock(folio);\n\tfolio_put(folio);\n\n\tif (old_size < pos && !verity)\n\t\tpagecache_isize_extended(inode, old_size, pos);\n\t \n\tif (i_size_changed)\n\t\tret = ext4_mark_inode_dirty(handle, inode);\n\n\tif (pos + len > inode->i_size && !verity && ext4_can_truncate(inode))\n\t\t \n\t\text4_orphan_add(handle, inode);\n\n\tret2 = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = ret2;\n\n\tif (pos + len > inode->i_size && !verity) {\n\t\text4_truncate_failed_write(inode);\n\t\t \n\t\tif (inode->i_nlink)\n\t\t\text4_orphan_del(NULL, inode);\n\t}\n\n\treturn ret ? ret : copied;\n}\n\n \nstatic void ext4_journalled_zero_new_buffers(handle_t *handle,\n\t\t\t\t\t    struct inode *inode,\n\t\t\t\t\t    struct folio *folio,\n\t\t\t\t\t    unsigned from, unsigned to)\n{\n\tunsigned int block_start = 0, block_end;\n\tstruct buffer_head *head, *bh;\n\n\tbh = head = folio_buffers(folio);\n\tdo {\n\t\tblock_end = block_start + bh->b_size;\n\t\tif (buffer_new(bh)) {\n\t\t\tif (block_end > from && block_start < to) {\n\t\t\t\tif (!folio_test_uptodate(folio)) {\n\t\t\t\t\tunsigned start, size;\n\n\t\t\t\t\tstart = max(from, block_start);\n\t\t\t\t\tsize = min(to, block_end) - start;\n\n\t\t\t\t\tfolio_zero_range(folio, start, size);\n\t\t\t\t\twrite_end_fn(handle, inode, bh);\n\t\t\t\t}\n\t\t\t\tclear_buffer_new(bh);\n\t\t\t}\n\t\t}\n\t\tblock_start = block_end;\n\t\tbh = bh->b_this_page;\n\t} while (bh != head);\n}\n\nstatic int ext4_journalled_write_end(struct file *file,\n\t\t\t\t     struct address_space *mapping,\n\t\t\t\t     loff_t pos, unsigned len, unsigned copied,\n\t\t\t\t     struct page *page, void *fsdata)\n{\n\tstruct folio *folio = page_folio(page);\n\thandle_t *handle = ext4_journal_current_handle();\n\tstruct inode *inode = mapping->host;\n\tloff_t old_size = inode->i_size;\n\tint ret = 0, ret2;\n\tint partial = 0;\n\tunsigned from, to;\n\tint size_changed = 0;\n\tbool verity = ext4_verity_in_progress(inode);\n\n\ttrace_ext4_journalled_write_end(inode, pos, len, copied);\n\tfrom = pos & (PAGE_SIZE - 1);\n\tto = from + len;\n\n\tBUG_ON(!ext4_handle_valid(handle));\n\n\tif (ext4_has_inline_data(inode))\n\t\treturn ext4_write_inline_data_end(inode, pos, len, copied,\n\t\t\t\t\t\t  folio);\n\n\tif (unlikely(copied < len) && !folio_test_uptodate(folio)) {\n\t\tcopied = 0;\n\t\text4_journalled_zero_new_buffers(handle, inode, folio,\n\t\t\t\t\t\t from, to);\n\t} else {\n\t\tif (unlikely(copied < len))\n\t\t\text4_journalled_zero_new_buffers(handle, inode, folio,\n\t\t\t\t\t\t\t from + copied, to);\n\t\tret = ext4_walk_page_buffers(handle, inode,\n\t\t\t\t\t     folio_buffers(folio),\n\t\t\t\t\t     from, from + copied, &partial,\n\t\t\t\t\t     write_end_fn);\n\t\tif (!partial)\n\t\t\tfolio_mark_uptodate(folio);\n\t}\n\tif (!verity)\n\t\tsize_changed = ext4_update_inode_size(inode, pos + copied);\n\tEXT4_I(inode)->i_datasync_tid = handle->h_transaction->t_tid;\n\tfolio_unlock(folio);\n\tfolio_put(folio);\n\n\tif (old_size < pos && !verity)\n\t\tpagecache_isize_extended(inode, old_size, pos);\n\n\tif (size_changed) {\n\t\tret2 = ext4_mark_inode_dirty(handle, inode);\n\t\tif (!ret)\n\t\t\tret = ret2;\n\t}\n\n\tif (pos + len > inode->i_size && !verity && ext4_can_truncate(inode))\n\t\t \n\t\text4_orphan_add(handle, inode);\n\n\tret2 = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = ret2;\n\tif (pos + len > inode->i_size && !verity) {\n\t\text4_truncate_failed_write(inode);\n\t\t \n\t\tif (inode->i_nlink)\n\t\t\text4_orphan_del(NULL, inode);\n\t}\n\n\treturn ret ? ret : copied;\n}\n\n \nstatic int ext4_da_reserve_space(struct inode *inode)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tint ret;\n\n\t \n\tret = dquot_reserve_block(inode, EXT4_C2B(sbi, 1));\n\tif (ret)\n\t\treturn ret;\n\n\tspin_lock(&ei->i_block_reservation_lock);\n\tif (ext4_claim_free_clusters(sbi, 1, 0)) {\n\t\tspin_unlock(&ei->i_block_reservation_lock);\n\t\tdquot_release_reservation_block(inode, EXT4_C2B(sbi, 1));\n\t\treturn -ENOSPC;\n\t}\n\tei->i_reserved_data_blocks++;\n\ttrace_ext4_da_reserve_space(inode);\n\tspin_unlock(&ei->i_block_reservation_lock);\n\n\treturn 0;        \n}\n\nvoid ext4_da_release_space(struct inode *inode, int to_free)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\n\tif (!to_free)\n\t\treturn;\t\t \n\n\tspin_lock(&EXT4_I(inode)->i_block_reservation_lock);\n\n\ttrace_ext4_da_release_space(inode, to_free);\n\tif (unlikely(to_free > ei->i_reserved_data_blocks)) {\n\t\t \n\t\text4_warning(inode->i_sb, \"ext4_da_release_space: \"\n\t\t\t \"ino %lu, to_free %d with only %d reserved \"\n\t\t\t \"data blocks\", inode->i_ino, to_free,\n\t\t\t ei->i_reserved_data_blocks);\n\t\tWARN_ON(1);\n\t\tto_free = ei->i_reserved_data_blocks;\n\t}\n\tei->i_reserved_data_blocks -= to_free;\n\n\t \n\tpercpu_counter_sub(&sbi->s_dirtyclusters_counter, to_free);\n\n\tspin_unlock(&EXT4_I(inode)->i_block_reservation_lock);\n\n\tdquot_release_reservation_block(inode, EXT4_C2B(sbi, to_free));\n}\n\n \n\nstruct mpage_da_data {\n\t \n\tstruct inode *inode;\n\tstruct writeback_control *wbc;\n\tunsigned int can_map:1;\t \n\n\t \n\tpgoff_t first_page;\t \n\tpgoff_t next_page;\t \n\tpgoff_t last_page;\t \n\t \n\tstruct ext4_map_blocks map;\n\tstruct ext4_io_submit io_submit;\t \n\tunsigned int do_map:1;\n\tunsigned int scanned_until_end:1;\n\tunsigned int journalled_more_data:1;\n};\n\nstatic void mpage_release_unused_pages(struct mpage_da_data *mpd,\n\t\t\t\t       bool invalidate)\n{\n\tunsigned nr, i;\n\tpgoff_t index, end;\n\tstruct folio_batch fbatch;\n\tstruct inode *inode = mpd->inode;\n\tstruct address_space *mapping = inode->i_mapping;\n\n\t \n\tif (mpd->first_page >= mpd->next_page)\n\t\treturn;\n\n\tmpd->scanned_until_end = 0;\n\tindex = mpd->first_page;\n\tend   = mpd->next_page - 1;\n\tif (invalidate) {\n\t\text4_lblk_t start, last;\n\t\tstart = index << (PAGE_SHIFT - inode->i_blkbits);\n\t\tlast = end << (PAGE_SHIFT - inode->i_blkbits);\n\n\t\t \n\t\tdown_write(&EXT4_I(inode)->i_data_sem);\n\t\text4_es_remove_extent(inode, start, last - start + 1);\n\t\tup_write(&EXT4_I(inode)->i_data_sem);\n\t}\n\n\tfolio_batch_init(&fbatch);\n\twhile (index <= end) {\n\t\tnr = filemap_get_folios(mapping, &index, end, &fbatch);\n\t\tif (nr == 0)\n\t\t\tbreak;\n\t\tfor (i = 0; i < nr; i++) {\n\t\t\tstruct folio *folio = fbatch.folios[i];\n\n\t\t\tif (folio->index < mpd->first_page)\n\t\t\t\tcontinue;\n\t\t\tif (folio_next_index(folio) - 1 > end)\n\t\t\t\tcontinue;\n\t\t\tBUG_ON(!folio_test_locked(folio));\n\t\t\tBUG_ON(folio_test_writeback(folio));\n\t\t\tif (invalidate) {\n\t\t\t\tif (folio_mapped(folio))\n\t\t\t\t\tfolio_clear_dirty_for_io(folio);\n\t\t\t\tblock_invalidate_folio(folio, 0,\n\t\t\t\t\t\tfolio_size(folio));\n\t\t\t\tfolio_clear_uptodate(folio);\n\t\t\t}\n\t\t\tfolio_unlock(folio);\n\t\t}\n\t\tfolio_batch_release(&fbatch);\n\t}\n}\n\nstatic void ext4_print_free_blocks(struct inode *inode)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tstruct super_block *sb = inode->i_sb;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\n\text4_msg(sb, KERN_CRIT, \"Total free blocks count %lld\",\n\t       EXT4_C2B(EXT4_SB(inode->i_sb),\n\t\t\text4_count_free_clusters(sb)));\n\text4_msg(sb, KERN_CRIT, \"Free/Dirty block details\");\n\text4_msg(sb, KERN_CRIT, \"free_blocks=%lld\",\n\t       (long long) EXT4_C2B(EXT4_SB(sb),\n\t\tpercpu_counter_sum(&sbi->s_freeclusters_counter)));\n\text4_msg(sb, KERN_CRIT, \"dirty_blocks=%lld\",\n\t       (long long) EXT4_C2B(EXT4_SB(sb),\n\t\tpercpu_counter_sum(&sbi->s_dirtyclusters_counter)));\n\text4_msg(sb, KERN_CRIT, \"Block reservation details\");\n\text4_msg(sb, KERN_CRIT, \"i_reserved_data_blocks=%u\",\n\t\t ei->i_reserved_data_blocks);\n\treturn;\n}\n\n \nstatic int ext4_insert_delayed_block(struct inode *inode, ext4_lblk_t lblk)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tint ret;\n\tbool allocated = false;\n\n\t \n\tif (sbi->s_cluster_ratio == 1) {\n\t\tret = ext4_da_reserve_space(inode);\n\t\tif (ret != 0)    \n\t\t\treturn ret;\n\t} else {    \n\t\tif (!ext4_es_scan_clu(inode, &ext4_es_is_delonly, lblk)) {\n\t\t\tif (!ext4_es_scan_clu(inode,\n\t\t\t\t\t      &ext4_es_is_mapped, lblk)) {\n\t\t\t\tret = ext4_clu_mapped(inode,\n\t\t\t\t\t\t      EXT4_B2C(sbi, lblk));\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tif (ret == 0) {\n\t\t\t\t\tret = ext4_da_reserve_space(inode);\n\t\t\t\t\tif (ret != 0)    \n\t\t\t\t\t\treturn ret;\n\t\t\t\t} else {\n\t\t\t\t\tallocated = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tallocated = true;\n\t\t\t}\n\t\t}\n\t}\n\n\text4_es_insert_delayed_block(inode, lblk, allocated);\n\treturn 0;\n}\n\n \nstatic int ext4_da_map_blocks(struct inode *inode, sector_t iblock,\n\t\t\t      struct ext4_map_blocks *map,\n\t\t\t      struct buffer_head *bh)\n{\n\tstruct extent_status es;\n\tint retval;\n\tsector_t invalid_block = ~((sector_t) 0xffff);\n#ifdef ES_AGGRESSIVE_TEST\n\tstruct ext4_map_blocks orig_map;\n\n\tmemcpy(&orig_map, map, sizeof(*map));\n#endif\n\n\tif (invalid_block < ext4_blocks_count(EXT4_SB(inode->i_sb)->s_es))\n\t\tinvalid_block = ~0;\n\n\tmap->m_flags = 0;\n\text_debug(inode, \"max_blocks %u, logical block %lu\\n\", map->m_len,\n\t\t  (unsigned long) map->m_lblk);\n\n\t \n\tif (ext4_es_lookup_extent(inode, iblock, NULL, &es)) {\n\t\tif (ext4_es_is_hole(&es)) {\n\t\t\tretval = 0;\n\t\t\tdown_read(&EXT4_I(inode)->i_data_sem);\n\t\t\tgoto add_delayed;\n\t\t}\n\n\t\t \n\t\tif (ext4_es_is_delayed(&es) && !ext4_es_is_unwritten(&es)) {\n\t\t\tmap_bh(bh, inode->i_sb, invalid_block);\n\t\t\tset_buffer_new(bh);\n\t\t\tset_buffer_delay(bh);\n\t\t\treturn 0;\n\t\t}\n\n\t\tmap->m_pblk = ext4_es_pblock(&es) + iblock - es.es_lblk;\n\t\tretval = es.es_len - (iblock - es.es_lblk);\n\t\tif (retval > map->m_len)\n\t\t\tretval = map->m_len;\n\t\tmap->m_len = retval;\n\t\tif (ext4_es_is_written(&es))\n\t\t\tmap->m_flags |= EXT4_MAP_MAPPED;\n\t\telse if (ext4_es_is_unwritten(&es))\n\t\t\tmap->m_flags |= EXT4_MAP_UNWRITTEN;\n\t\telse\n\t\t\tBUG();\n\n#ifdef ES_AGGRESSIVE_TEST\n\t\text4_map_blocks_es_recheck(NULL, inode, map, &orig_map, 0);\n#endif\n\t\treturn retval;\n\t}\n\n\t \n\tdown_read(&EXT4_I(inode)->i_data_sem);\n\tif (ext4_has_inline_data(inode))\n\t\tretval = 0;\n\telse if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\tretval = ext4_ext_map_blocks(NULL, inode, map, 0);\n\telse\n\t\tretval = ext4_ind_map_blocks(NULL, inode, map, 0);\n\nadd_delayed:\n\tif (retval == 0) {\n\t\tint ret;\n\n\t\t \n\n\t\tret = ext4_insert_delayed_block(inode, map->m_lblk);\n\t\tif (ret != 0) {\n\t\t\tretval = ret;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tmap_bh(bh, inode->i_sb, invalid_block);\n\t\tset_buffer_new(bh);\n\t\tset_buffer_delay(bh);\n\t} else if (retval > 0) {\n\t\tunsigned int status;\n\n\t\tif (unlikely(retval != map->m_len)) {\n\t\t\text4_warning(inode->i_sb,\n\t\t\t\t     \"ES len assertion failed for inode \"\n\t\t\t\t     \"%lu: retval %d != map->m_len %d\",\n\t\t\t\t     inode->i_ino, retval, map->m_len);\n\t\t\tWARN_ON(1);\n\t\t}\n\n\t\tstatus = map->m_flags & EXT4_MAP_UNWRITTEN ?\n\t\t\t\tEXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;\n\t\text4_es_insert_extent(inode, map->m_lblk, map->m_len,\n\t\t\t\t      map->m_pblk, status);\n\t}\n\nout_unlock:\n\tup_read((&EXT4_I(inode)->i_data_sem));\n\n\treturn retval;\n}\n\n \nint ext4_da_get_block_prep(struct inode *inode, sector_t iblock,\n\t\t\t   struct buffer_head *bh, int create)\n{\n\tstruct ext4_map_blocks map;\n\tint ret = 0;\n\n\tBUG_ON(create == 0);\n\tBUG_ON(bh->b_size != inode->i_sb->s_blocksize);\n\n\tmap.m_lblk = iblock;\n\tmap.m_len = 1;\n\n\t \n\tret = ext4_da_map_blocks(inode, iblock, &map, bh);\n\tif (ret <= 0)\n\t\treturn ret;\n\n\tmap_bh(bh, inode->i_sb, map.m_pblk);\n\text4_update_bh_state(bh, map.m_flags);\n\n\tif (buffer_unwritten(bh)) {\n\t\t \n\t\tset_buffer_new(bh);\n\t\tset_buffer_mapped(bh);\n\t}\n\treturn 0;\n}\n\nstatic void mpage_folio_done(struct mpage_da_data *mpd, struct folio *folio)\n{\n\tmpd->first_page += folio_nr_pages(folio);\n\tfolio_unlock(folio);\n}\n\nstatic int mpage_submit_folio(struct mpage_da_data *mpd, struct folio *folio)\n{\n\tsize_t len;\n\tloff_t size;\n\tint err;\n\n\tBUG_ON(folio->index != mpd->first_page);\n\tfolio_clear_dirty_for_io(folio);\n\t \n\tsize = i_size_read(mpd->inode);\n\tlen = folio_size(folio);\n\tif (folio_pos(folio) + len > size &&\n\t    !ext4_verity_in_progress(mpd->inode))\n\t\tlen = size & ~PAGE_MASK;\n\terr = ext4_bio_write_folio(&mpd->io_submit, folio, len);\n\tif (!err)\n\t\tmpd->wbc->nr_to_write--;\n\n\treturn err;\n}\n\n#define BH_FLAGS (BIT(BH_Unwritten) | BIT(BH_Delay))\n\n \n#define MAX_WRITEPAGES_EXTENT_LEN 2048\n\n \nstatic bool mpage_add_bh_to_extent(struct mpage_da_data *mpd, ext4_lblk_t lblk,\n\t\t\t\t   struct buffer_head *bh)\n{\n\tstruct ext4_map_blocks *map = &mpd->map;\n\n\t \n\tif (!buffer_dirty(bh) || !buffer_mapped(bh) ||\n\t    (!buffer_delay(bh) && !buffer_unwritten(bh))) {\n\t\t \n\t\tif (map->m_len == 0)\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\n\t \n\tif (map->m_len == 0) {\n\t\t \n\t\tif (!mpd->do_map)\n\t\t\treturn false;\n\t\tmap->m_lblk = lblk;\n\t\tmap->m_len = 1;\n\t\tmap->m_flags = bh->b_state & BH_FLAGS;\n\t\treturn true;\n\t}\n\n\t \n\tif (map->m_len >= MAX_WRITEPAGES_EXTENT_LEN)\n\t\treturn false;\n\n\t \n\tif (lblk == map->m_lblk + map->m_len &&\n\t    (bh->b_state & BH_FLAGS) == map->m_flags) {\n\t\tmap->m_len++;\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic int mpage_process_page_bufs(struct mpage_da_data *mpd,\n\t\t\t\t   struct buffer_head *head,\n\t\t\t\t   struct buffer_head *bh,\n\t\t\t\t   ext4_lblk_t lblk)\n{\n\tstruct inode *inode = mpd->inode;\n\tint err;\n\text4_lblk_t blocks = (i_size_read(inode) + i_blocksize(inode) - 1)\n\t\t\t\t\t\t\t>> inode->i_blkbits;\n\n\tif (ext4_verity_in_progress(inode))\n\t\tblocks = EXT_MAX_BLOCKS;\n\n\tdo {\n\t\tBUG_ON(buffer_locked(bh));\n\n\t\tif (lblk >= blocks || !mpage_add_bh_to_extent(mpd, lblk, bh)) {\n\t\t\t \n\t\t\tif (mpd->map.m_len)\n\t\t\t\treturn 0;\n\t\t\t \n\t\t\tif (!mpd->do_map)\n\t\t\t\treturn 0;\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\t} while (lblk++, (bh = bh->b_this_page) != head);\n\t \n\tif (mpd->map.m_len == 0) {\n\t\terr = mpage_submit_folio(mpd, head->b_folio);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tmpage_folio_done(mpd, head->b_folio);\n\t}\n\tif (lblk >= blocks) {\n\t\tmpd->scanned_until_end = 1;\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\n \nstatic int mpage_process_folio(struct mpage_da_data *mpd, struct folio *folio,\n\t\t\t      ext4_lblk_t *m_lblk, ext4_fsblk_t *m_pblk,\n\t\t\t      bool *map_bh)\n{\n\tstruct buffer_head *head, *bh;\n\text4_io_end_t *io_end = mpd->io_submit.io_end;\n\text4_lblk_t lblk = *m_lblk;\n\text4_fsblk_t pblock = *m_pblk;\n\tint err = 0;\n\tint blkbits = mpd->inode->i_blkbits;\n\tssize_t io_end_size = 0;\n\tstruct ext4_io_end_vec *io_end_vec = ext4_last_io_end_vec(io_end);\n\n\tbh = head = folio_buffers(folio);\n\tdo {\n\t\tif (lblk < mpd->map.m_lblk)\n\t\t\tcontinue;\n\t\tif (lblk >= mpd->map.m_lblk + mpd->map.m_len) {\n\t\t\t \n\t\t\tmpd->map.m_len = 0;\n\t\t\tmpd->map.m_flags = 0;\n\t\t\tio_end_vec->size += io_end_size;\n\n\t\t\terr = mpage_process_page_bufs(mpd, head, bh, lblk);\n\t\t\tif (err > 0)\n\t\t\t\terr = 0;\n\t\t\tif (!err && mpd->map.m_len && mpd->map.m_lblk > lblk) {\n\t\t\t\tio_end_vec = ext4_alloc_io_end_vec(io_end);\n\t\t\t\tif (IS_ERR(io_end_vec)) {\n\t\t\t\t\terr = PTR_ERR(io_end_vec);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tio_end_vec->offset = (loff_t)mpd->map.m_lblk << blkbits;\n\t\t\t}\n\t\t\t*map_bh = true;\n\t\t\tgoto out;\n\t\t}\n\t\tif (buffer_delay(bh)) {\n\t\t\tclear_buffer_delay(bh);\n\t\t\tbh->b_blocknr = pblock++;\n\t\t}\n\t\tclear_buffer_unwritten(bh);\n\t\tio_end_size += (1 << blkbits);\n\t} while (lblk++, (bh = bh->b_this_page) != head);\n\n\tio_end_vec->size += io_end_size;\n\t*map_bh = false;\nout:\n\t*m_lblk = lblk;\n\t*m_pblk = pblock;\n\treturn err;\n}\n\n \nstatic int mpage_map_and_submit_buffers(struct mpage_da_data *mpd)\n{\n\tstruct folio_batch fbatch;\n\tunsigned nr, i;\n\tstruct inode *inode = mpd->inode;\n\tint bpp_bits = PAGE_SHIFT - inode->i_blkbits;\n\tpgoff_t start, end;\n\text4_lblk_t lblk;\n\text4_fsblk_t pblock;\n\tint err;\n\tbool map_bh = false;\n\n\tstart = mpd->map.m_lblk >> bpp_bits;\n\tend = (mpd->map.m_lblk + mpd->map.m_len - 1) >> bpp_bits;\n\tlblk = start << bpp_bits;\n\tpblock = mpd->map.m_pblk;\n\n\tfolio_batch_init(&fbatch);\n\twhile (start <= end) {\n\t\tnr = filemap_get_folios(inode->i_mapping, &start, end, &fbatch);\n\t\tif (nr == 0)\n\t\t\tbreak;\n\t\tfor (i = 0; i < nr; i++) {\n\t\t\tstruct folio *folio = fbatch.folios[i];\n\n\t\t\terr = mpage_process_folio(mpd, folio, &lblk, &pblock,\n\t\t\t\t\t\t &map_bh);\n\t\t\t \n\t\t\tif (err < 0 || map_bh)\n\t\t\t\tgoto out;\n\t\t\t \n\t\t\terr = mpage_submit_folio(mpd, folio);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t\tmpage_folio_done(mpd, folio);\n\t\t}\n\t\tfolio_batch_release(&fbatch);\n\t}\n\t \n\tmpd->map.m_len = 0;\n\tmpd->map.m_flags = 0;\n\treturn 0;\nout:\n\tfolio_batch_release(&fbatch);\n\treturn err;\n}\n\nstatic int mpage_map_one_extent(handle_t *handle, struct mpage_da_data *mpd)\n{\n\tstruct inode *inode = mpd->inode;\n\tstruct ext4_map_blocks *map = &mpd->map;\n\tint get_blocks_flags;\n\tint err, dioread_nolock;\n\n\ttrace_ext4_da_write_pages_extent(inode, map);\n\t \n\tget_blocks_flags = EXT4_GET_BLOCKS_CREATE |\n\t\t\t   EXT4_GET_BLOCKS_METADATA_NOFAIL |\n\t\t\t   EXT4_GET_BLOCKS_IO_SUBMIT;\n\tdioread_nolock = ext4_should_dioread_nolock(inode);\n\tif (dioread_nolock)\n\t\tget_blocks_flags |= EXT4_GET_BLOCKS_IO_CREATE_EXT;\n\tif (map->m_flags & BIT(BH_Delay))\n\t\tget_blocks_flags |= EXT4_GET_BLOCKS_DELALLOC_RESERVE;\n\n\terr = ext4_map_blocks(handle, inode, map, get_blocks_flags);\n\tif (err < 0)\n\t\treturn err;\n\tif (dioread_nolock && (map->m_flags & EXT4_MAP_UNWRITTEN)) {\n\t\tif (!mpd->io_submit.io_end->handle &&\n\t\t    ext4_handle_valid(handle)) {\n\t\t\tmpd->io_submit.io_end->handle = handle->h_rsv_handle;\n\t\t\thandle->h_rsv_handle = NULL;\n\t\t}\n\t\text4_set_io_unwritten_flag(inode, mpd->io_submit.io_end);\n\t}\n\n\tBUG_ON(map->m_len == 0);\n\treturn 0;\n}\n\n \nstatic int mpage_map_and_submit_extent(handle_t *handle,\n\t\t\t\t       struct mpage_da_data *mpd,\n\t\t\t\t       bool *give_up_on_write)\n{\n\tstruct inode *inode = mpd->inode;\n\tstruct ext4_map_blocks *map = &mpd->map;\n\tint err;\n\tloff_t disksize;\n\tint progress = 0;\n\text4_io_end_t *io_end = mpd->io_submit.io_end;\n\tstruct ext4_io_end_vec *io_end_vec;\n\n\tio_end_vec = ext4_alloc_io_end_vec(io_end);\n\tif (IS_ERR(io_end_vec))\n\t\treturn PTR_ERR(io_end_vec);\n\tio_end_vec->offset = ((loff_t)map->m_lblk) << inode->i_blkbits;\n\tdo {\n\t\terr = mpage_map_one_extent(handle, mpd);\n\t\tif (err < 0) {\n\t\t\tstruct super_block *sb = inode->i_sb;\n\n\t\t\tif (ext4_forced_shutdown(sb))\n\t\t\t\tgoto invalidate_dirty_pages;\n\t\t\t \n\t\t\tif ((err == -ENOMEM) ||\n\t\t\t    (err == -ENOSPC && ext4_count_free_clusters(sb))) {\n\t\t\t\tif (progress)\n\t\t\t\t\tgoto update_disksize;\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\text4_msg(sb, KERN_CRIT,\n\t\t\t\t \"Delayed block allocation failed for \"\n\t\t\t\t \"inode %lu at logical offset %llu with\"\n\t\t\t\t \" max blocks %u with error %d\",\n\t\t\t\t inode->i_ino,\n\t\t\t\t (unsigned long long)map->m_lblk,\n\t\t\t\t (unsigned)map->m_len, -err);\n\t\t\text4_msg(sb, KERN_CRIT,\n\t\t\t\t \"This should not happen!! Data will \"\n\t\t\t\t \"be lost\\n\");\n\t\t\tif (err == -ENOSPC)\n\t\t\t\text4_print_free_blocks(inode);\n\t\tinvalidate_dirty_pages:\n\t\t\t*give_up_on_write = true;\n\t\t\treturn err;\n\t\t}\n\t\tprogress = 1;\n\t\t \n\t\terr = mpage_map_and_submit_buffers(mpd);\n\t\tif (err < 0)\n\t\t\tgoto update_disksize;\n\t} while (map->m_len);\n\nupdate_disksize:\n\t \n\tdisksize = ((loff_t)mpd->first_page) << PAGE_SHIFT;\n\tif (disksize > READ_ONCE(EXT4_I(inode)->i_disksize)) {\n\t\tint err2;\n\t\tloff_t i_size;\n\n\t\tdown_write(&EXT4_I(inode)->i_data_sem);\n\t\ti_size = i_size_read(inode);\n\t\tif (disksize > i_size)\n\t\t\tdisksize = i_size;\n\t\tif (disksize > EXT4_I(inode)->i_disksize)\n\t\t\tEXT4_I(inode)->i_disksize = disksize;\n\t\tup_write(&EXT4_I(inode)->i_data_sem);\n\t\terr2 = ext4_mark_inode_dirty(handle, inode);\n\t\tif (err2) {\n\t\t\text4_error_err(inode->i_sb, -err2,\n\t\t\t\t       \"Failed to mark inode %lu dirty\",\n\t\t\t\t       inode->i_ino);\n\t\t}\n\t\tif (!err)\n\t\t\terr = err2;\n\t}\n\treturn err;\n}\n\n \nstatic int ext4_da_writepages_trans_blocks(struct inode *inode)\n{\n\tint bpp = ext4_journal_blocks_per_page(inode);\n\n\treturn ext4_meta_trans_blocks(inode,\n\t\t\t\tMAX_WRITEPAGES_EXTENT_LEN + bpp - 1, bpp);\n}\n\nstatic int ext4_journal_folio_buffers(handle_t *handle, struct folio *folio,\n\t\t\t\t     size_t len)\n{\n\tstruct buffer_head *page_bufs = folio_buffers(folio);\n\tstruct inode *inode = folio->mapping->host;\n\tint ret, err;\n\n\tret = ext4_walk_page_buffers(handle, inode, page_bufs, 0, len,\n\t\t\t\t     NULL, do_journal_get_write_access);\n\terr = ext4_walk_page_buffers(handle, inode, page_bufs, 0, len,\n\t\t\t\t     NULL, write_end_fn);\n\tif (ret == 0)\n\t\tret = err;\n\terr = ext4_jbd2_inode_add_write(handle, inode, folio_pos(folio), len);\n\tif (ret == 0)\n\t\tret = err;\n\tEXT4_I(inode)->i_datasync_tid = handle->h_transaction->t_tid;\n\n\treturn ret;\n}\n\nstatic int mpage_journal_page_buffers(handle_t *handle,\n\t\t\t\t      struct mpage_da_data *mpd,\n\t\t\t\t      struct folio *folio)\n{\n\tstruct inode *inode = mpd->inode;\n\tloff_t size = i_size_read(inode);\n\tsize_t len = folio_size(folio);\n\n\tfolio_clear_checked(folio);\n\tmpd->wbc->nr_to_write--;\n\n\tif (folio_pos(folio) + len > size &&\n\t    !ext4_verity_in_progress(inode))\n\t\tlen = size - folio_pos(folio);\n\n\treturn ext4_journal_folio_buffers(handle, folio, len);\n}\n\n \nstatic int mpage_prepare_extent_to_map(struct mpage_da_data *mpd)\n{\n\tstruct address_space *mapping = mpd->inode->i_mapping;\n\tstruct folio_batch fbatch;\n\tunsigned int nr_folios;\n\tpgoff_t index = mpd->first_page;\n\tpgoff_t end = mpd->last_page;\n\txa_mark_t tag;\n\tint i, err = 0;\n\tint blkbits = mpd->inode->i_blkbits;\n\text4_lblk_t lblk;\n\tstruct buffer_head *head;\n\thandle_t *handle = NULL;\n\tint bpp = ext4_journal_blocks_per_page(mpd->inode);\n\n\tif (mpd->wbc->sync_mode == WB_SYNC_ALL || mpd->wbc->tagged_writepages)\n\t\ttag = PAGECACHE_TAG_TOWRITE;\n\telse\n\t\ttag = PAGECACHE_TAG_DIRTY;\n\n\tmpd->map.m_len = 0;\n\tmpd->next_page = index;\n\tif (ext4_should_journal_data(mpd->inode)) {\n\t\thandle = ext4_journal_start(mpd->inode, EXT4_HT_WRITE_PAGE,\n\t\t\t\t\t    bpp);\n\t\tif (IS_ERR(handle))\n\t\t\treturn PTR_ERR(handle);\n\t}\n\tfolio_batch_init(&fbatch);\n\twhile (index <= end) {\n\t\tnr_folios = filemap_get_folios_tag(mapping, &index, end,\n\t\t\t\ttag, &fbatch);\n\t\tif (nr_folios == 0)\n\t\t\tbreak;\n\n\t\tfor (i = 0; i < nr_folios; i++) {\n\t\t\tstruct folio *folio = fbatch.folios[i];\n\n\t\t\t \n\t\t\tif (mpd->wbc->sync_mode == WB_SYNC_NONE &&\n\t\t\t    mpd->wbc->nr_to_write <=\n\t\t\t    mpd->map.m_len >> (PAGE_SHIFT - blkbits))\n\t\t\t\tgoto out;\n\n\t\t\t \n\t\t\tif (mpd->map.m_len > 0 && mpd->next_page != folio->index)\n\t\t\t\tgoto out;\n\n\t\t\tif (handle) {\n\t\t\t\terr = ext4_journal_ensure_credits(handle, bpp,\n\t\t\t\t\t\t\t\t  0);\n\t\t\t\tif (err < 0)\n\t\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tfolio_lock(folio);\n\t\t\t \n\t\t\tif (!folio_test_dirty(folio) ||\n\t\t\t    (folio_test_writeback(folio) &&\n\t\t\t     (mpd->wbc->sync_mode == WB_SYNC_NONE)) ||\n\t\t\t    unlikely(folio->mapping != mapping)) {\n\t\t\t\tfolio_unlock(folio);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tfolio_wait_writeback(folio);\n\t\t\tBUG_ON(folio_test_writeback(folio));\n\n\t\t\t \n\t\t\tif (!folio_buffers(folio)) {\n\t\t\t\text4_warning_inode(mpd->inode, \"page %lu does not have buffers attached\", folio->index);\n\t\t\t\tfolio_clear_dirty(folio);\n\t\t\t\tfolio_unlock(folio);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (mpd->map.m_len == 0)\n\t\t\t\tmpd->first_page = folio->index;\n\t\t\tmpd->next_page = folio_next_index(folio);\n\t\t\t \n\t\t\tif (!mpd->can_map) {\n\t\t\t\terr = mpage_submit_folio(mpd, folio);\n\t\t\t\tif (err < 0)\n\t\t\t\t\tgoto out;\n\t\t\t\t \n\t\t\t\tif (folio_test_checked(folio)) {\n\t\t\t\t\terr = mpage_journal_page_buffers(handle,\n\t\t\t\t\t\tmpd, folio);\n\t\t\t\t\tif (err < 0)\n\t\t\t\t\t\tgoto out;\n\t\t\t\t\tmpd->journalled_more_data = 1;\n\t\t\t\t}\n\t\t\t\tmpage_folio_done(mpd, folio);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tlblk = ((ext4_lblk_t)folio->index) <<\n\t\t\t\t\t(PAGE_SHIFT - blkbits);\n\t\t\t\thead = folio_buffers(folio);\n\t\t\t\terr = mpage_process_page_bufs(mpd, head, head,\n\t\t\t\t\t\tlblk);\n\t\t\t\tif (err <= 0)\n\t\t\t\t\tgoto out;\n\t\t\t\terr = 0;\n\t\t\t}\n\t\t}\n\t\tfolio_batch_release(&fbatch);\n\t\tcond_resched();\n\t}\n\tmpd->scanned_until_end = 1;\n\tif (handle)\n\t\text4_journal_stop(handle);\n\treturn 0;\nout:\n\tfolio_batch_release(&fbatch);\n\tif (handle)\n\t\text4_journal_stop(handle);\n\treturn err;\n}\n\nstatic int ext4_do_writepages(struct mpage_da_data *mpd)\n{\n\tstruct writeback_control *wbc = mpd->wbc;\n\tpgoff_t\twriteback_index = 0;\n\tlong nr_to_write = wbc->nr_to_write;\n\tint range_whole = 0;\n\tint cycled = 1;\n\thandle_t *handle = NULL;\n\tstruct inode *inode = mpd->inode;\n\tstruct address_space *mapping = inode->i_mapping;\n\tint needed_blocks, rsv_blocks = 0, ret = 0;\n\tstruct ext4_sb_info *sbi = EXT4_SB(mapping->host->i_sb);\n\tstruct blk_plug plug;\n\tbool give_up_on_write = false;\n\n\ttrace_ext4_writepages(inode, wbc);\n\n\t \n\tif (!mapping->nrpages || !mapping_tagged(mapping, PAGECACHE_TAG_DIRTY))\n\t\tgoto out_writepages;\n\n\t \n\tif (unlikely(ext4_forced_shutdown(mapping->host->i_sb))) {\n\t\tret = -EROFS;\n\t\tgoto out_writepages;\n\t}\n\n\t \n\tif (ext4_has_inline_data(inode)) {\n\t\t \n\t\thandle = ext4_journal_start(inode, EXT4_HT_INODE, 1);\n\t\tif (IS_ERR(handle)) {\n\t\t\tret = PTR_ERR(handle);\n\t\t\tgoto out_writepages;\n\t\t}\n\t\tBUG_ON(ext4_test_inode_state(inode,\n\t\t\t\tEXT4_STATE_MAY_INLINE_DATA));\n\t\text4_destroy_inline_data(handle, inode);\n\t\text4_journal_stop(handle);\n\t}\n\n\t \n\tif (ext4_should_journal_data(inode)) {\n\t\tmpd->can_map = 0;\n\t\tif (wbc->sync_mode == WB_SYNC_ALL)\n\t\t\text4_fc_commit(sbi->s_journal,\n\t\t\t\t       EXT4_I(inode)->i_datasync_tid);\n\t}\n\tmpd->journalled_more_data = 0;\n\n\tif (ext4_should_dioread_nolock(inode)) {\n\t\t \n\t\trsv_blocks = 1 + ext4_chunk_trans_blocks(inode,\n\t\t\t\t\t\tPAGE_SIZE >> inode->i_blkbits);\n\t}\n\n\tif (wbc->range_start == 0 && wbc->range_end == LLONG_MAX)\n\t\trange_whole = 1;\n\n\tif (wbc->range_cyclic) {\n\t\twriteback_index = mapping->writeback_index;\n\t\tif (writeback_index)\n\t\t\tcycled = 0;\n\t\tmpd->first_page = writeback_index;\n\t\tmpd->last_page = -1;\n\t} else {\n\t\tmpd->first_page = wbc->range_start >> PAGE_SHIFT;\n\t\tmpd->last_page = wbc->range_end >> PAGE_SHIFT;\n\t}\n\n\text4_io_submit_init(&mpd->io_submit, wbc);\nretry:\n\tif (wbc->sync_mode == WB_SYNC_ALL || wbc->tagged_writepages)\n\t\ttag_pages_for_writeback(mapping, mpd->first_page,\n\t\t\t\t\tmpd->last_page);\n\tblk_start_plug(&plug);\n\n\t \n\tmpd->do_map = 0;\n\tmpd->scanned_until_end = 0;\n\tmpd->io_submit.io_end = ext4_init_io_end(inode, GFP_KERNEL);\n\tif (!mpd->io_submit.io_end) {\n\t\tret = -ENOMEM;\n\t\tgoto unplug;\n\t}\n\tret = mpage_prepare_extent_to_map(mpd);\n\t \n\tmpage_release_unused_pages(mpd, false);\n\t \n\text4_io_submit(&mpd->io_submit);\n\text4_put_io_end_defer(mpd->io_submit.io_end);\n\tmpd->io_submit.io_end = NULL;\n\tif (ret < 0)\n\t\tgoto unplug;\n\n\twhile (!mpd->scanned_until_end && wbc->nr_to_write > 0) {\n\t\t \n\t\tmpd->io_submit.io_end = ext4_init_io_end(inode, GFP_KERNEL);\n\t\tif (!mpd->io_submit.io_end) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tWARN_ON_ONCE(!mpd->can_map);\n\t\t \n\t\tBUG_ON(ext4_should_journal_data(inode));\n\t\tneeded_blocks = ext4_da_writepages_trans_blocks(inode);\n\n\t\t \n\t\thandle = ext4_journal_start_with_reserve(inode,\n\t\t\t\tEXT4_HT_WRITE_PAGE, needed_blocks, rsv_blocks);\n\t\tif (IS_ERR(handle)) {\n\t\t\tret = PTR_ERR(handle);\n\t\t\text4_msg(inode->i_sb, KERN_CRIT, \"%s: jbd2_start: \"\n\t\t\t       \"%ld pages, ino %lu; err %d\", __func__,\n\t\t\t\twbc->nr_to_write, inode->i_ino, ret);\n\t\t\t \n\t\t\text4_put_io_end(mpd->io_submit.io_end);\n\t\t\tmpd->io_submit.io_end = NULL;\n\t\t\tbreak;\n\t\t}\n\t\tmpd->do_map = 1;\n\n\t\ttrace_ext4_da_write_pages(inode, mpd->first_page, wbc);\n\t\tret = mpage_prepare_extent_to_map(mpd);\n\t\tif (!ret && mpd->map.m_len)\n\t\t\tret = mpage_map_and_submit_extent(handle, mpd,\n\t\t\t\t\t&give_up_on_write);\n\t\t \n\t\tif (!ext4_handle_valid(handle) || handle->h_sync == 0) {\n\t\t\text4_journal_stop(handle);\n\t\t\thandle = NULL;\n\t\t\tmpd->do_map = 0;\n\t\t}\n\t\t \n\t\tmpage_release_unused_pages(mpd, give_up_on_write);\n\t\t \n\t\text4_io_submit(&mpd->io_submit);\n\n\t\t \n\t\tif (handle) {\n\t\t\text4_put_io_end_defer(mpd->io_submit.io_end);\n\t\t\text4_journal_stop(handle);\n\t\t} else\n\t\t\text4_put_io_end(mpd->io_submit.io_end);\n\t\tmpd->io_submit.io_end = NULL;\n\n\t\tif (ret == -ENOSPC && sbi->s_journal) {\n\t\t\t \n\t\t\tjbd2_journal_force_commit_nested(sbi->s_journal);\n\t\t\tret = 0;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tif (ret)\n\t\t\tbreak;\n\t}\nunplug:\n\tblk_finish_plug(&plug);\n\tif (!ret && !cycled && wbc->nr_to_write > 0) {\n\t\tcycled = 1;\n\t\tmpd->last_page = writeback_index - 1;\n\t\tmpd->first_page = 0;\n\t\tgoto retry;\n\t}\n\n\t \n\tif (wbc->range_cyclic || (range_whole && wbc->nr_to_write > 0))\n\t\t \n\t\tmapping->writeback_index = mpd->first_page;\n\nout_writepages:\n\ttrace_ext4_writepages_result(inode, wbc, ret,\n\t\t\t\t     nr_to_write - wbc->nr_to_write);\n\treturn ret;\n}\n\nstatic int ext4_writepages(struct address_space *mapping,\n\t\t\t   struct writeback_control *wbc)\n{\n\tstruct super_block *sb = mapping->host->i_sb;\n\tstruct mpage_da_data mpd = {\n\t\t.inode = mapping->host,\n\t\t.wbc = wbc,\n\t\t.can_map = 1,\n\t};\n\tint ret;\n\tint alloc_ctx;\n\n\tif (unlikely(ext4_forced_shutdown(sb)))\n\t\treturn -EIO;\n\n\talloc_ctx = ext4_writepages_down_read(sb);\n\tret = ext4_do_writepages(&mpd);\n\t \n\tif (!ret && mpd.journalled_more_data)\n\t\tret = ext4_do_writepages(&mpd);\n\text4_writepages_up_read(sb, alloc_ctx);\n\n\treturn ret;\n}\n\nint ext4_normal_submit_inode_data_buffers(struct jbd2_inode *jinode)\n{\n\tstruct writeback_control wbc = {\n\t\t.sync_mode = WB_SYNC_ALL,\n\t\t.nr_to_write = LONG_MAX,\n\t\t.range_start = jinode->i_dirty_start,\n\t\t.range_end = jinode->i_dirty_end,\n\t};\n\tstruct mpage_da_data mpd = {\n\t\t.inode = jinode->i_vfs_inode,\n\t\t.wbc = &wbc,\n\t\t.can_map = 0,\n\t};\n\treturn ext4_do_writepages(&mpd);\n}\n\nstatic int ext4_dax_writepages(struct address_space *mapping,\n\t\t\t       struct writeback_control *wbc)\n{\n\tint ret;\n\tlong nr_to_write = wbc->nr_to_write;\n\tstruct inode *inode = mapping->host;\n\tint alloc_ctx;\n\n\tif (unlikely(ext4_forced_shutdown(inode->i_sb)))\n\t\treturn -EIO;\n\n\talloc_ctx = ext4_writepages_down_read(inode->i_sb);\n\ttrace_ext4_writepages(inode, wbc);\n\n\tret = dax_writeback_mapping_range(mapping,\n\t\t\t\t\t  EXT4_SB(inode->i_sb)->s_daxdev, wbc);\n\ttrace_ext4_writepages_result(inode, wbc, ret,\n\t\t\t\t     nr_to_write - wbc->nr_to_write);\n\text4_writepages_up_read(inode->i_sb, alloc_ctx);\n\treturn ret;\n}\n\nstatic int ext4_nonda_switch(struct super_block *sb)\n{\n\ts64 free_clusters, dirty_clusters;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\t \n\tfree_clusters =\n\t\tpercpu_counter_read_positive(&sbi->s_freeclusters_counter);\n\tdirty_clusters =\n\t\tpercpu_counter_read_positive(&sbi->s_dirtyclusters_counter);\n\t \n\tif (dirty_clusters && (free_clusters < 2 * dirty_clusters))\n\t\ttry_to_writeback_inodes_sb(sb, WB_REASON_FS_FREE_SPACE);\n\n\tif (2 * free_clusters < 3 * dirty_clusters ||\n\t    free_clusters < (dirty_clusters + EXT4_FREECLUSTERS_WATERMARK)) {\n\t\t \n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic int ext4_da_write_begin(struct file *file, struct address_space *mapping,\n\t\t\t       loff_t pos, unsigned len,\n\t\t\t       struct page **pagep, void **fsdata)\n{\n\tint ret, retries = 0;\n\tstruct folio *folio;\n\tpgoff_t index;\n\tstruct inode *inode = mapping->host;\n\n\tif (unlikely(ext4_forced_shutdown(inode->i_sb)))\n\t\treturn -EIO;\n\n\tindex = pos >> PAGE_SHIFT;\n\n\tif (ext4_nonda_switch(inode->i_sb) || ext4_verity_in_progress(inode)) {\n\t\t*fsdata = (void *)FALL_BACK_TO_NONDELALLOC;\n\t\treturn ext4_write_begin(file, mapping, pos,\n\t\t\t\t\tlen, pagep, fsdata);\n\t}\n\t*fsdata = (void *)0;\n\ttrace_ext4_da_write_begin(inode, pos, len);\n\n\tif (ext4_test_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA)) {\n\t\tret = ext4_da_write_inline_data_begin(mapping, inode, pos, len,\n\t\t\t\t\t\t      pagep, fsdata);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tif (ret == 1)\n\t\t\treturn 0;\n\t}\n\nretry:\n\tfolio = __filemap_get_folio(mapping, index, FGP_WRITEBEGIN,\n\t\t\tmapping_gfp_mask(mapping));\n\tif (IS_ERR(folio))\n\t\treturn PTR_ERR(folio);\n\n\t \n\tfolio_wait_stable(folio);\n\n#ifdef CONFIG_FS_ENCRYPTION\n\tret = ext4_block_write_begin(folio, pos, len, ext4_da_get_block_prep);\n#else\n\tret = __block_write_begin(&folio->page, pos, len, ext4_da_get_block_prep);\n#endif\n\tif (ret < 0) {\n\t\tfolio_unlock(folio);\n\t\tfolio_put(folio);\n\t\t \n\t\tif (pos + len > inode->i_size)\n\t\t\text4_truncate_failed_write(inode);\n\n\t\tif (ret == -ENOSPC &&\n\t\t    ext4_should_retry_alloc(inode->i_sb, &retries))\n\t\t\tgoto retry;\n\t\treturn ret;\n\t}\n\n\t*pagep = &folio->page;\n\treturn ret;\n}\n\n \nstatic int ext4_da_should_update_i_disksize(struct folio *folio,\n\t\t\t\t\t    unsigned long offset)\n{\n\tstruct buffer_head *bh;\n\tstruct inode *inode = folio->mapping->host;\n\tunsigned int idx;\n\tint i;\n\n\tbh = folio_buffers(folio);\n\tidx = offset >> inode->i_blkbits;\n\n\tfor (i = 0; i < idx; i++)\n\t\tbh = bh->b_this_page;\n\n\tif (!buffer_mapped(bh) || (buffer_delay(bh)) || buffer_unwritten(bh))\n\t\treturn 0;\n\treturn 1;\n}\n\nstatic int ext4_da_do_write_end(struct address_space *mapping,\n\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\tstruct page *page)\n{\n\tstruct inode *inode = mapping->host;\n\tloff_t old_size = inode->i_size;\n\tbool disksize_changed = false;\n\tloff_t new_i_size;\n\n\t \n\tcopied = block_write_end(NULL, mapping, pos, len, copied, page, NULL);\n\tnew_i_size = pos + copied;\n\n\t \n\tif (new_i_size > inode->i_size) {\n\t\tunsigned long end;\n\n\t\ti_size_write(inode, new_i_size);\n\t\tend = (new_i_size - 1) & (PAGE_SIZE - 1);\n\t\tif (copied && ext4_da_should_update_i_disksize(page_folio(page), end)) {\n\t\t\text4_update_i_disksize(inode, new_i_size);\n\t\t\tdisksize_changed = true;\n\t\t}\n\t}\n\n\tunlock_page(page);\n\tput_page(page);\n\n\tif (old_size < pos)\n\t\tpagecache_isize_extended(inode, old_size, pos);\n\n\tif (disksize_changed) {\n\t\thandle_t *handle;\n\n\t\thandle = ext4_journal_start(inode, EXT4_HT_INODE, 2);\n\t\tif (IS_ERR(handle))\n\t\t\treturn PTR_ERR(handle);\n\t\text4_mark_inode_dirty(handle, inode);\n\t\text4_journal_stop(handle);\n\t}\n\n\treturn copied;\n}\n\nstatic int ext4_da_write_end(struct file *file,\n\t\t\t     struct address_space *mapping,\n\t\t\t     loff_t pos, unsigned len, unsigned copied,\n\t\t\t     struct page *page, void *fsdata)\n{\n\tstruct inode *inode = mapping->host;\n\tint write_mode = (int)(unsigned long)fsdata;\n\tstruct folio *folio = page_folio(page);\n\n\tif (write_mode == FALL_BACK_TO_NONDELALLOC)\n\t\treturn ext4_write_end(file, mapping, pos,\n\t\t\t\t      len, copied, &folio->page, fsdata);\n\n\ttrace_ext4_da_write_end(inode, pos, len, copied);\n\n\tif (write_mode != CONVERT_INLINE_DATA &&\n\t    ext4_test_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA) &&\n\t    ext4_has_inline_data(inode))\n\t\treturn ext4_write_inline_data_end(inode, pos, len, copied,\n\t\t\t\t\t\t  folio);\n\n\tif (unlikely(copied < len) && !PageUptodate(page))\n\t\tcopied = 0;\n\n\treturn ext4_da_do_write_end(mapping, pos, len, copied, &folio->page);\n}\n\n \nint ext4_alloc_da_blocks(struct inode *inode)\n{\n\ttrace_ext4_alloc_da_blocks(inode);\n\n\tif (!EXT4_I(inode)->i_reserved_data_blocks)\n\t\treturn 0;\n\n\t \n\treturn filemap_flush(inode->i_mapping);\n}\n\n \nstatic sector_t ext4_bmap(struct address_space *mapping, sector_t block)\n{\n\tstruct inode *inode = mapping->host;\n\tsector_t ret = 0;\n\n\tinode_lock_shared(inode);\n\t \n\tif (ext4_has_inline_data(inode))\n\t\tgoto out;\n\n\tif (mapping_tagged(mapping, PAGECACHE_TAG_DIRTY) &&\n\t    (test_opt(inode->i_sb, DELALLOC) ||\n\t     ext4_should_journal_data(inode))) {\n\t\t \n\t\tfilemap_write_and_wait(mapping);\n\t}\n\n\tret = iomap_bmap(mapping, block, &ext4_iomap_ops);\n\nout:\n\tinode_unlock_shared(inode);\n\treturn ret;\n}\n\nstatic int ext4_read_folio(struct file *file, struct folio *folio)\n{\n\tint ret = -EAGAIN;\n\tstruct inode *inode = folio->mapping->host;\n\n\ttrace_ext4_read_folio(inode, folio);\n\n\tif (ext4_has_inline_data(inode))\n\t\tret = ext4_readpage_inline(inode, folio);\n\n\tif (ret == -EAGAIN)\n\t\treturn ext4_mpage_readpages(inode, NULL, folio);\n\n\treturn ret;\n}\n\nstatic void ext4_readahead(struct readahead_control *rac)\n{\n\tstruct inode *inode = rac->mapping->host;\n\n\t \n\tif (ext4_has_inline_data(inode))\n\t\treturn;\n\n\text4_mpage_readpages(inode, rac, NULL);\n}\n\nstatic void ext4_invalidate_folio(struct folio *folio, size_t offset,\n\t\t\t\tsize_t length)\n{\n\ttrace_ext4_invalidate_folio(folio, offset, length);\n\n\t \n\tWARN_ON(folio_buffers(folio) && buffer_jbd(folio_buffers(folio)));\n\n\tblock_invalidate_folio(folio, offset, length);\n}\n\nstatic int __ext4_journalled_invalidate_folio(struct folio *folio,\n\t\t\t\t\t    size_t offset, size_t length)\n{\n\tjournal_t *journal = EXT4_JOURNAL(folio->mapping->host);\n\n\ttrace_ext4_journalled_invalidate_folio(folio, offset, length);\n\n\t \n\tif (offset == 0 && length == folio_size(folio))\n\t\tfolio_clear_checked(folio);\n\n\treturn jbd2_journal_invalidate_folio(journal, folio, offset, length);\n}\n\n \nstatic void ext4_journalled_invalidate_folio(struct folio *folio,\n\t\t\t\t\t   size_t offset,\n\t\t\t\t\t   size_t length)\n{\n\tWARN_ON(__ext4_journalled_invalidate_folio(folio, offset, length) < 0);\n}\n\nstatic bool ext4_release_folio(struct folio *folio, gfp_t wait)\n{\n\tstruct inode *inode = folio->mapping->host;\n\tjournal_t *journal = EXT4_JOURNAL(inode);\n\n\ttrace_ext4_release_folio(inode, folio);\n\n\t \n\tif (folio_test_checked(folio))\n\t\treturn false;\n\tif (journal)\n\t\treturn jbd2_journal_try_to_free_buffers(journal, folio);\n\telse\n\t\treturn try_to_free_buffers(folio);\n}\n\nstatic bool ext4_inode_datasync_dirty(struct inode *inode)\n{\n\tjournal_t *journal = EXT4_SB(inode->i_sb)->s_journal;\n\n\tif (journal) {\n\t\tif (jbd2_transaction_committed(journal,\n\t\t\tEXT4_I(inode)->i_datasync_tid))\n\t\t\treturn false;\n\t\tif (test_opt2(inode->i_sb, JOURNAL_FAST_COMMIT))\n\t\t\treturn !list_empty(&EXT4_I(inode)->i_fc_list);\n\t\treturn true;\n\t}\n\n\t \n\tif (!list_empty(&inode->i_mapping->private_list))\n\t\treturn true;\n\treturn inode->i_state & I_DIRTY_DATASYNC;\n}\n\nstatic void ext4_set_iomap(struct inode *inode, struct iomap *iomap,\n\t\t\t   struct ext4_map_blocks *map, loff_t offset,\n\t\t\t   loff_t length, unsigned int flags)\n{\n\tu8 blkbits = inode->i_blkbits;\n\n\t \n\tiomap->flags = 0;\n\tif (ext4_inode_datasync_dirty(inode) ||\n\t    offset + length > i_size_read(inode))\n\t\tiomap->flags |= IOMAP_F_DIRTY;\n\n\tif (map->m_flags & EXT4_MAP_NEW)\n\t\tiomap->flags |= IOMAP_F_NEW;\n\n\tif (flags & IOMAP_DAX)\n\t\tiomap->dax_dev = EXT4_SB(inode->i_sb)->s_daxdev;\n\telse\n\t\tiomap->bdev = inode->i_sb->s_bdev;\n\tiomap->offset = (u64) map->m_lblk << blkbits;\n\tiomap->length = (u64) map->m_len << blkbits;\n\n\tif ((map->m_flags & EXT4_MAP_MAPPED) &&\n\t    !ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\tiomap->flags |= IOMAP_F_MERGED;\n\n\t \n\tif (map->m_flags & EXT4_MAP_UNWRITTEN) {\n\t\tiomap->type = IOMAP_UNWRITTEN;\n\t\tiomap->addr = (u64) map->m_pblk << blkbits;\n\t\tif (flags & IOMAP_DAX)\n\t\t\tiomap->addr += EXT4_SB(inode->i_sb)->s_dax_part_off;\n\t} else if (map->m_flags & EXT4_MAP_MAPPED) {\n\t\tiomap->type = IOMAP_MAPPED;\n\t\tiomap->addr = (u64) map->m_pblk << blkbits;\n\t\tif (flags & IOMAP_DAX)\n\t\t\tiomap->addr += EXT4_SB(inode->i_sb)->s_dax_part_off;\n\t} else {\n\t\tiomap->type = IOMAP_HOLE;\n\t\tiomap->addr = IOMAP_NULL_ADDR;\n\t}\n}\n\nstatic int ext4_iomap_alloc(struct inode *inode, struct ext4_map_blocks *map,\n\t\t\t    unsigned int flags)\n{\n\thandle_t *handle;\n\tu8 blkbits = inode->i_blkbits;\n\tint ret, dio_credits, m_flags = 0, retries = 0;\n\n\t \n\tif (map->m_len > DIO_MAX_BLOCKS)\n\t\tmap->m_len = DIO_MAX_BLOCKS;\n\tdio_credits = ext4_chunk_trans_blocks(inode, map->m_len);\n\nretry:\n\t \n\thandle = ext4_journal_start(inode, EXT4_HT_MAP_BLOCKS, dio_credits);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\n\t \n\tWARN_ON(!(flags & (IOMAP_DAX | IOMAP_DIRECT)));\n\tif (flags & IOMAP_DAX)\n\t\tm_flags = EXT4_GET_BLOCKS_CREATE_ZERO;\n\t \n\telse if (((loff_t)map->m_lblk << blkbits) >= i_size_read(inode))\n\t\tm_flags = EXT4_GET_BLOCKS_CREATE;\n\telse if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\tm_flags = EXT4_GET_BLOCKS_IO_CREATE_EXT;\n\n\tret = ext4_map_blocks(handle, inode, map, m_flags);\n\n\t \n\tif (!m_flags && !ret)\n\t\tret = -ENOTBLK;\n\n\text4_journal_stop(handle);\n\tif (ret == -ENOSPC && ext4_should_retry_alloc(inode->i_sb, &retries))\n\t\tgoto retry;\n\n\treturn ret;\n}\n\n\nstatic int ext4_iomap_begin(struct inode *inode, loff_t offset, loff_t length,\n\t\tunsigned flags, struct iomap *iomap, struct iomap *srcmap)\n{\n\tint ret;\n\tstruct ext4_map_blocks map;\n\tu8 blkbits = inode->i_blkbits;\n\n\tif ((offset >> blkbits) > EXT4_MAX_LOGICAL_BLOCK)\n\t\treturn -EINVAL;\n\n\tif (WARN_ON_ONCE(ext4_has_inline_data(inode)))\n\t\treturn -ERANGE;\n\n\t \n\tmap.m_lblk = offset >> blkbits;\n\tmap.m_len = min_t(loff_t, (offset + length - 1) >> blkbits,\n\t\t\t  EXT4_MAX_LOGICAL_BLOCK) - map.m_lblk + 1;\n\n\tif (flags & IOMAP_WRITE) {\n\t\t \n\t\tif (offset + length <= i_size_read(inode)) {\n\t\t\tret = ext4_map_blocks(NULL, inode, &map, 0);\n\t\t\tif (ret > 0 && (map.m_flags & EXT4_MAP_MAPPED))\n\t\t\t\tgoto out;\n\t\t}\n\t\tret = ext4_iomap_alloc(inode, &map, flags);\n\t} else {\n\t\tret = ext4_map_blocks(NULL, inode, &map, 0);\n\t}\n\n\tif (ret < 0)\n\t\treturn ret;\nout:\n\t \n\tmap.m_len = fscrypt_limit_io_blocks(inode, map.m_lblk, map.m_len);\n\n\text4_set_iomap(inode, iomap, &map, offset, length, flags);\n\n\treturn 0;\n}\n\nstatic int ext4_iomap_overwrite_begin(struct inode *inode, loff_t offset,\n\t\tloff_t length, unsigned flags, struct iomap *iomap,\n\t\tstruct iomap *srcmap)\n{\n\tint ret;\n\n\t \n\tflags &= ~IOMAP_WRITE;\n\tret = ext4_iomap_begin(inode, offset, length, flags, iomap, srcmap);\n\tWARN_ON_ONCE(!ret && iomap->type != IOMAP_MAPPED);\n\treturn ret;\n}\n\nstatic int ext4_iomap_end(struct inode *inode, loff_t offset, loff_t length,\n\t\t\t  ssize_t written, unsigned flags, struct iomap *iomap)\n{\n\t \n\tif (flags & (IOMAP_WRITE | IOMAP_DIRECT) && written == 0)\n\t\treturn -ENOTBLK;\n\n\treturn 0;\n}\n\nconst struct iomap_ops ext4_iomap_ops = {\n\t.iomap_begin\t\t= ext4_iomap_begin,\n\t.iomap_end\t\t= ext4_iomap_end,\n};\n\nconst struct iomap_ops ext4_iomap_overwrite_ops = {\n\t.iomap_begin\t\t= ext4_iomap_overwrite_begin,\n\t.iomap_end\t\t= ext4_iomap_end,\n};\n\nstatic bool ext4_iomap_is_delalloc(struct inode *inode,\n\t\t\t\t   struct ext4_map_blocks *map)\n{\n\tstruct extent_status es;\n\text4_lblk_t offset = 0, end = map->m_lblk + map->m_len - 1;\n\n\text4_es_find_extent_range(inode, &ext4_es_is_delayed,\n\t\t\t\t  map->m_lblk, end, &es);\n\n\tif (!es.es_len || es.es_lblk > end)\n\t\treturn false;\n\n\tif (es.es_lblk > map->m_lblk) {\n\t\tmap->m_len = es.es_lblk - map->m_lblk;\n\t\treturn false;\n\t}\n\n\toffset = map->m_lblk - es.es_lblk;\n\tmap->m_len = es.es_len - offset;\n\n\treturn true;\n}\n\nstatic int ext4_iomap_begin_report(struct inode *inode, loff_t offset,\n\t\t\t\t   loff_t length, unsigned int flags,\n\t\t\t\t   struct iomap *iomap, struct iomap *srcmap)\n{\n\tint ret;\n\tbool delalloc = false;\n\tstruct ext4_map_blocks map;\n\tu8 blkbits = inode->i_blkbits;\n\n\tif ((offset >> blkbits) > EXT4_MAX_LOGICAL_BLOCK)\n\t\treturn -EINVAL;\n\n\tif (ext4_has_inline_data(inode)) {\n\t\tret = ext4_inline_data_iomap(inode, iomap);\n\t\tif (ret != -EAGAIN) {\n\t\t\tif (ret == 0 && offset >= iomap->length)\n\t\t\t\tret = -ENOENT;\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tmap.m_lblk = offset >> blkbits;\n\tmap.m_len = min_t(loff_t, (offset + length - 1) >> blkbits,\n\t\t\t  EXT4_MAX_LOGICAL_BLOCK) - map.m_lblk + 1;\n\n\t \n\tif (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))) {\n\t\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\n\t\tif (offset >= sbi->s_bitmap_maxbytes) {\n\t\t\tmap.m_flags = 0;\n\t\t\tgoto set_iomap;\n\t\t}\n\t}\n\n\tret = ext4_map_blocks(NULL, inode, &map, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret == 0)\n\t\tdelalloc = ext4_iomap_is_delalloc(inode, &map);\n\nset_iomap:\n\text4_set_iomap(inode, iomap, &map, offset, length, flags);\n\tif (delalloc && iomap->type == IOMAP_HOLE)\n\t\tiomap->type = IOMAP_DELALLOC;\n\n\treturn 0;\n}\n\nconst struct iomap_ops ext4_iomap_report_ops = {\n\t.iomap_begin = ext4_iomap_begin_report,\n};\n\n \nstatic bool ext4_journalled_dirty_folio(struct address_space *mapping,\n\t\tstruct folio *folio)\n{\n\tWARN_ON_ONCE(!folio_buffers(folio));\n\tif (folio_maybe_dma_pinned(folio))\n\t\tfolio_set_checked(folio);\n\treturn filemap_dirty_folio(mapping, folio);\n}\n\nstatic bool ext4_dirty_folio(struct address_space *mapping, struct folio *folio)\n{\n\tWARN_ON_ONCE(!folio_test_locked(folio) && !folio_test_dirty(folio));\n\tWARN_ON_ONCE(!folio_buffers(folio));\n\treturn block_dirty_folio(mapping, folio);\n}\n\nstatic int ext4_iomap_swap_activate(struct swap_info_struct *sis,\n\t\t\t\t    struct file *file, sector_t *span)\n{\n\treturn iomap_swapfile_activate(sis, file, span,\n\t\t\t\t       &ext4_iomap_report_ops);\n}\n\nstatic const struct address_space_operations ext4_aops = {\n\t.read_folio\t\t= ext4_read_folio,\n\t.readahead\t\t= ext4_readahead,\n\t.writepages\t\t= ext4_writepages,\n\t.write_begin\t\t= ext4_write_begin,\n\t.write_end\t\t= ext4_write_end,\n\t.dirty_folio\t\t= ext4_dirty_folio,\n\t.bmap\t\t\t= ext4_bmap,\n\t.invalidate_folio\t= ext4_invalidate_folio,\n\t.release_folio\t\t= ext4_release_folio,\n\t.direct_IO\t\t= noop_direct_IO,\n\t.migrate_folio\t\t= buffer_migrate_folio,\n\t.is_partially_uptodate  = block_is_partially_uptodate,\n\t.error_remove_page\t= generic_error_remove_page,\n\t.swap_activate\t\t= ext4_iomap_swap_activate,\n};\n\nstatic const struct address_space_operations ext4_journalled_aops = {\n\t.read_folio\t\t= ext4_read_folio,\n\t.readahead\t\t= ext4_readahead,\n\t.writepages\t\t= ext4_writepages,\n\t.write_begin\t\t= ext4_write_begin,\n\t.write_end\t\t= ext4_journalled_write_end,\n\t.dirty_folio\t\t= ext4_journalled_dirty_folio,\n\t.bmap\t\t\t= ext4_bmap,\n\t.invalidate_folio\t= ext4_journalled_invalidate_folio,\n\t.release_folio\t\t= ext4_release_folio,\n\t.direct_IO\t\t= noop_direct_IO,\n\t.migrate_folio\t\t= buffer_migrate_folio_norefs,\n\t.is_partially_uptodate  = block_is_partially_uptodate,\n\t.error_remove_page\t= generic_error_remove_page,\n\t.swap_activate\t\t= ext4_iomap_swap_activate,\n};\n\nstatic const struct address_space_operations ext4_da_aops = {\n\t.read_folio\t\t= ext4_read_folio,\n\t.readahead\t\t= ext4_readahead,\n\t.writepages\t\t= ext4_writepages,\n\t.write_begin\t\t= ext4_da_write_begin,\n\t.write_end\t\t= ext4_da_write_end,\n\t.dirty_folio\t\t= ext4_dirty_folio,\n\t.bmap\t\t\t= ext4_bmap,\n\t.invalidate_folio\t= ext4_invalidate_folio,\n\t.release_folio\t\t= ext4_release_folio,\n\t.direct_IO\t\t= noop_direct_IO,\n\t.migrate_folio\t\t= buffer_migrate_folio,\n\t.is_partially_uptodate  = block_is_partially_uptodate,\n\t.error_remove_page\t= generic_error_remove_page,\n\t.swap_activate\t\t= ext4_iomap_swap_activate,\n};\n\nstatic const struct address_space_operations ext4_dax_aops = {\n\t.writepages\t\t= ext4_dax_writepages,\n\t.direct_IO\t\t= noop_direct_IO,\n\t.dirty_folio\t\t= noop_dirty_folio,\n\t.bmap\t\t\t= ext4_bmap,\n\t.swap_activate\t\t= ext4_iomap_swap_activate,\n};\n\nvoid ext4_set_aops(struct inode *inode)\n{\n\tswitch (ext4_inode_journal_mode(inode)) {\n\tcase EXT4_INODE_ORDERED_DATA_MODE:\n\tcase EXT4_INODE_WRITEBACK_DATA_MODE:\n\t\tbreak;\n\tcase EXT4_INODE_JOURNAL_DATA_MODE:\n\t\tinode->i_mapping->a_ops = &ext4_journalled_aops;\n\t\treturn;\n\tdefault:\n\t\tBUG();\n\t}\n\tif (IS_DAX(inode))\n\t\tinode->i_mapping->a_ops = &ext4_dax_aops;\n\telse if (test_opt(inode->i_sb, DELALLOC))\n\t\tinode->i_mapping->a_ops = &ext4_da_aops;\n\telse\n\t\tinode->i_mapping->a_ops = &ext4_aops;\n}\n\nstatic int __ext4_block_zero_page_range(handle_t *handle,\n\t\tstruct address_space *mapping, loff_t from, loff_t length)\n{\n\text4_fsblk_t index = from >> PAGE_SHIFT;\n\tunsigned offset = from & (PAGE_SIZE-1);\n\tunsigned blocksize, pos;\n\text4_lblk_t iblock;\n\tstruct inode *inode = mapping->host;\n\tstruct buffer_head *bh;\n\tstruct folio *folio;\n\tint err = 0;\n\n\tfolio = __filemap_get_folio(mapping, from >> PAGE_SHIFT,\n\t\t\t\t    FGP_LOCK | FGP_ACCESSED | FGP_CREAT,\n\t\t\t\t    mapping_gfp_constraint(mapping, ~__GFP_FS));\n\tif (IS_ERR(folio))\n\t\treturn PTR_ERR(folio);\n\n\tblocksize = inode->i_sb->s_blocksize;\n\n\tiblock = index << (PAGE_SHIFT - inode->i_sb->s_blocksize_bits);\n\n\tbh = folio_buffers(folio);\n\tif (!bh) {\n\t\tcreate_empty_buffers(&folio->page, blocksize, 0);\n\t\tbh = folio_buffers(folio);\n\t}\n\n\t \n\tpos = blocksize;\n\twhile (offset >= pos) {\n\t\tbh = bh->b_this_page;\n\t\tiblock++;\n\t\tpos += blocksize;\n\t}\n\tif (buffer_freed(bh)) {\n\t\tBUFFER_TRACE(bh, \"freed: skip\");\n\t\tgoto unlock;\n\t}\n\tif (!buffer_mapped(bh)) {\n\t\tBUFFER_TRACE(bh, \"unmapped\");\n\t\text4_get_block(inode, iblock, bh, 0);\n\t\t \n\t\tif (!buffer_mapped(bh)) {\n\t\t\tBUFFER_TRACE(bh, \"still unmapped\");\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\t \n\tif (folio_test_uptodate(folio))\n\t\tset_buffer_uptodate(bh);\n\n\tif (!buffer_uptodate(bh)) {\n\t\terr = ext4_read_bh_lock(bh, 0, true);\n\t\tif (err)\n\t\t\tgoto unlock;\n\t\tif (fscrypt_inode_uses_fs_layer_crypto(inode)) {\n\t\t\t \n\t\t\tBUG_ON(!fscrypt_has_encryption_key(inode));\n\t\t\terr = fscrypt_decrypt_pagecache_blocks(folio,\n\t\t\t\t\t\t\t       blocksize,\n\t\t\t\t\t\t\t       bh_offset(bh));\n\t\t\tif (err) {\n\t\t\t\tclear_buffer_uptodate(bh);\n\t\t\t\tgoto unlock;\n\t\t\t}\n\t\t}\n\t}\n\tif (ext4_should_journal_data(inode)) {\n\t\tBUFFER_TRACE(bh, \"get write access\");\n\t\terr = ext4_journal_get_write_access(handle, inode->i_sb, bh,\n\t\t\t\t\t\t    EXT4_JTR_NONE);\n\t\tif (err)\n\t\t\tgoto unlock;\n\t}\n\tfolio_zero_range(folio, offset, length);\n\tBUFFER_TRACE(bh, \"zeroed end of block\");\n\n\tif (ext4_should_journal_data(inode)) {\n\t\terr = ext4_dirty_journalled_data(handle, bh);\n\t} else {\n\t\terr = 0;\n\t\tmark_buffer_dirty(bh);\n\t\tif (ext4_should_order_data(inode))\n\t\t\terr = ext4_jbd2_inode_add_write(handle, inode, from,\n\t\t\t\t\tlength);\n\t}\n\nunlock:\n\tfolio_unlock(folio);\n\tfolio_put(folio);\n\treturn err;\n}\n\n \nstatic int ext4_block_zero_page_range(handle_t *handle,\n\t\tstruct address_space *mapping, loff_t from, loff_t length)\n{\n\tstruct inode *inode = mapping->host;\n\tunsigned offset = from & (PAGE_SIZE-1);\n\tunsigned blocksize = inode->i_sb->s_blocksize;\n\tunsigned max = blocksize - (offset & (blocksize - 1));\n\n\t \n\tif (length > max || length < 0)\n\t\tlength = max;\n\n\tif (IS_DAX(inode)) {\n\t\treturn dax_zero_range(inode, from, length, NULL,\n\t\t\t\t      &ext4_iomap_ops);\n\t}\n\treturn __ext4_block_zero_page_range(handle, mapping, from, length);\n}\n\n \nstatic int ext4_block_truncate_page(handle_t *handle,\n\t\tstruct address_space *mapping, loff_t from)\n{\n\tunsigned offset = from & (PAGE_SIZE-1);\n\tunsigned length;\n\tunsigned blocksize;\n\tstruct inode *inode = mapping->host;\n\n\t \n\tif (IS_ENCRYPTED(inode) && !fscrypt_has_encryption_key(inode))\n\t\treturn 0;\n\n\tblocksize = inode->i_sb->s_blocksize;\n\tlength = blocksize - (offset & (blocksize - 1));\n\n\treturn ext4_block_zero_page_range(handle, mapping, from, length);\n}\n\nint ext4_zero_partial_blocks(handle_t *handle, struct inode *inode,\n\t\t\t     loff_t lstart, loff_t length)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct address_space *mapping = inode->i_mapping;\n\tunsigned partial_start, partial_end;\n\text4_fsblk_t start, end;\n\tloff_t byte_end = (lstart + length - 1);\n\tint err = 0;\n\n\tpartial_start = lstart & (sb->s_blocksize - 1);\n\tpartial_end = byte_end & (sb->s_blocksize - 1);\n\n\tstart = lstart >> sb->s_blocksize_bits;\n\tend = byte_end >> sb->s_blocksize_bits;\n\n\t \n\tif (start == end &&\n\t    (partial_start || (partial_end != sb->s_blocksize - 1))) {\n\t\terr = ext4_block_zero_page_range(handle, mapping,\n\t\t\t\t\t\t lstart, length);\n\t\treturn err;\n\t}\n\t \n\tif (partial_start) {\n\t\terr = ext4_block_zero_page_range(handle, mapping,\n\t\t\t\t\t\t lstart, sb->s_blocksize);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\t \n\tif (partial_end != sb->s_blocksize - 1)\n\t\terr = ext4_block_zero_page_range(handle, mapping,\n\t\t\t\t\t\t byte_end - partial_end,\n\t\t\t\t\t\t partial_end + 1);\n\treturn err;\n}\n\nint ext4_can_truncate(struct inode *inode)\n{\n\tif (S_ISREG(inode->i_mode))\n\t\treturn 1;\n\tif (S_ISDIR(inode->i_mode))\n\t\treturn 1;\n\tif (S_ISLNK(inode->i_mode))\n\t\treturn !ext4_inode_is_fast_symlink(inode);\n\treturn 0;\n}\n\n \nint ext4_update_disksize_before_punch(struct inode *inode, loff_t offset,\n\t\t\t\t      loff_t len)\n{\n\thandle_t *handle;\n\tint ret;\n\n\tloff_t size = i_size_read(inode);\n\n\tWARN_ON(!inode_is_locked(inode));\n\tif (offset > size || offset + len < size)\n\t\treturn 0;\n\n\tif (EXT4_I(inode)->i_disksize >= size)\n\t\treturn 0;\n\n\thandle = ext4_journal_start(inode, EXT4_HT_MISC, 1);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\text4_update_i_disksize(inode, size);\n\tret = ext4_mark_inode_dirty(handle, inode);\n\text4_journal_stop(handle);\n\n\treturn ret;\n}\n\nstatic void ext4_wait_dax_page(struct inode *inode)\n{\n\tfilemap_invalidate_unlock(inode->i_mapping);\n\tschedule();\n\tfilemap_invalidate_lock(inode->i_mapping);\n}\n\nint ext4_break_layouts(struct inode *inode)\n{\n\tstruct page *page;\n\tint error;\n\n\tif (WARN_ON_ONCE(!rwsem_is_locked(&inode->i_mapping->invalidate_lock)))\n\t\treturn -EINVAL;\n\n\tdo {\n\t\tpage = dax_layout_busy_page(inode->i_mapping);\n\t\tif (!page)\n\t\t\treturn 0;\n\n\t\terror = ___wait_var_event(&page->_refcount,\n\t\t\t\tatomic_read(&page->_refcount) == 1,\n\t\t\t\tTASK_INTERRUPTIBLE, 0, 0,\n\t\t\t\text4_wait_dax_page(inode));\n\t} while (error == 0);\n\n\treturn error;\n}\n\n \n\nint ext4_punch_hole(struct file *file, loff_t offset, loff_t length)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct super_block *sb = inode->i_sb;\n\text4_lblk_t first_block, stop_block;\n\tstruct address_space *mapping = inode->i_mapping;\n\tloff_t first_block_offset, last_block_offset, max_length;\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\thandle_t *handle;\n\tunsigned int credits;\n\tint ret = 0, ret2 = 0;\n\n\ttrace_ext4_punch_hole(inode, offset, length, 0);\n\n\t \n\tif (mapping_tagged(mapping, PAGECACHE_TAG_DIRTY)) {\n\t\tret = filemap_write_and_wait_range(mapping, offset,\n\t\t\t\t\t\t   offset + length - 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tinode_lock(inode);\n\n\t \n\tif (offset >= inode->i_size)\n\t\tgoto out_mutex;\n\n\t \n\tif (offset + length > inode->i_size) {\n\t\tlength = inode->i_size +\n\t\t   PAGE_SIZE - (inode->i_size & (PAGE_SIZE - 1)) -\n\t\t   offset;\n\t}\n\n\t \n\tmax_length = sbi->s_bitmap_maxbytes - inode->i_sb->s_blocksize;\n\tif (offset + length > max_length)\n\t\tlength = max_length - offset;\n\n\tif (offset & (sb->s_blocksize - 1) ||\n\t    (offset + length) & (sb->s_blocksize - 1)) {\n\t\t \n\t\tret = ext4_inode_attach_jinode(inode);\n\t\tif (ret < 0)\n\t\t\tgoto out_mutex;\n\n\t}\n\n\t \n\tinode_dio_wait(inode);\n\n\tret = file_modified(file);\n\tif (ret)\n\t\tgoto out_mutex;\n\n\t \n\tfilemap_invalidate_lock(mapping);\n\n\tret = ext4_break_layouts(inode);\n\tif (ret)\n\t\tgoto out_dio;\n\n\tfirst_block_offset = round_up(offset, sb->s_blocksize);\n\tlast_block_offset = round_down((offset + length), sb->s_blocksize) - 1;\n\n\t \n\tif (last_block_offset > first_block_offset) {\n\t\tret = ext4_update_disksize_before_punch(inode, offset, length);\n\t\tif (ret)\n\t\t\tgoto out_dio;\n\t\ttruncate_pagecache_range(inode, first_block_offset,\n\t\t\t\t\t last_block_offset);\n\t}\n\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\tcredits = ext4_writepage_trans_blocks(inode);\n\telse\n\t\tcredits = ext4_blocks_for_truncate(inode);\n\thandle = ext4_journal_start(inode, EXT4_HT_TRUNCATE, credits);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\text4_std_error(sb, ret);\n\t\tgoto out_dio;\n\t}\n\n\tret = ext4_zero_partial_blocks(handle, inode, offset,\n\t\t\t\t       length);\n\tif (ret)\n\t\tgoto out_stop;\n\n\tfirst_block = (offset + sb->s_blocksize - 1) >>\n\t\tEXT4_BLOCK_SIZE_BITS(sb);\n\tstop_block = (offset + length) >> EXT4_BLOCK_SIZE_BITS(sb);\n\n\t \n\tif (stop_block > first_block) {\n\n\t\tdown_write(&EXT4_I(inode)->i_data_sem);\n\t\text4_discard_preallocations(inode, 0);\n\n\t\text4_es_remove_extent(inode, first_block,\n\t\t\t\t      stop_block - first_block);\n\n\t\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\t\tret = ext4_ext_remove_space(inode, first_block,\n\t\t\t\t\t\t    stop_block - 1);\n\t\telse\n\t\t\tret = ext4_ind_remove_space(handle, inode, first_block,\n\t\t\t\t\t\t    stop_block);\n\n\t\tup_write(&EXT4_I(inode)->i_data_sem);\n\t}\n\text4_fc_track_range(handle, inode, first_block, stop_block);\n\tif (IS_SYNC(inode))\n\t\text4_handle_sync(handle);\n\n\tinode->i_mtime = inode_set_ctime_current(inode);\n\tret2 = ext4_mark_inode_dirty(handle, inode);\n\tif (unlikely(ret2))\n\t\tret = ret2;\n\tif (ret >= 0)\n\t\text4_update_inode_fsync_trans(handle, inode, 1);\nout_stop:\n\text4_journal_stop(handle);\nout_dio:\n\tfilemap_invalidate_unlock(mapping);\nout_mutex:\n\tinode_unlock(inode);\n\treturn ret;\n}\n\nint ext4_inode_attach_jinode(struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct jbd2_inode *jinode;\n\n\tif (ei->jinode || !EXT4_SB(inode->i_sb)->s_journal)\n\t\treturn 0;\n\n\tjinode = jbd2_alloc_inode(GFP_KERNEL);\n\tspin_lock(&inode->i_lock);\n\tif (!ei->jinode) {\n\t\tif (!jinode) {\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tei->jinode = jinode;\n\t\tjbd2_journal_init_jbd_inode(ei->jinode, inode);\n\t\tjinode = NULL;\n\t}\n\tspin_unlock(&inode->i_lock);\n\tif (unlikely(jinode != NULL))\n\t\tjbd2_free_inode(jinode);\n\treturn 0;\n}\n\n \nint ext4_truncate(struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tunsigned int credits;\n\tint err = 0, err2;\n\thandle_t *handle;\n\tstruct address_space *mapping = inode->i_mapping;\n\n\t \n\tif (!(inode->i_state & (I_NEW|I_FREEING)))\n\t\tWARN_ON(!inode_is_locked(inode));\n\ttrace_ext4_truncate_enter(inode);\n\n\tif (!ext4_can_truncate(inode))\n\t\tgoto out_trace;\n\n\tif (inode->i_size == 0 && !test_opt(inode->i_sb, NO_AUTO_DA_ALLOC))\n\t\text4_set_inode_state(inode, EXT4_STATE_DA_ALLOC_CLOSE);\n\n\tif (ext4_has_inline_data(inode)) {\n\t\tint has_inline = 1;\n\n\t\terr = ext4_inline_data_truncate(inode, &has_inline);\n\t\tif (err || has_inline)\n\t\t\tgoto out_trace;\n\t}\n\n\t \n\tif (inode->i_size & (inode->i_sb->s_blocksize - 1)) {\n\t\terr = ext4_inode_attach_jinode(inode);\n\t\tif (err)\n\t\t\tgoto out_trace;\n\t}\n\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\tcredits = ext4_writepage_trans_blocks(inode);\n\telse\n\t\tcredits = ext4_blocks_for_truncate(inode);\n\n\thandle = ext4_journal_start(inode, EXT4_HT_TRUNCATE, credits);\n\tif (IS_ERR(handle)) {\n\t\terr = PTR_ERR(handle);\n\t\tgoto out_trace;\n\t}\n\n\tif (inode->i_size & (inode->i_sb->s_blocksize - 1))\n\t\text4_block_truncate_page(handle, mapping, inode->i_size);\n\n\t \n\terr = ext4_orphan_add(handle, inode);\n\tif (err)\n\t\tgoto out_stop;\n\n\tdown_write(&EXT4_I(inode)->i_data_sem);\n\n\text4_discard_preallocations(inode, 0);\n\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\terr = ext4_ext_truncate(handle, inode);\n\telse\n\t\text4_ind_truncate(handle, inode);\n\n\tup_write(&ei->i_data_sem);\n\tif (err)\n\t\tgoto out_stop;\n\n\tif (IS_SYNC(inode))\n\t\text4_handle_sync(handle);\n\nout_stop:\n\t \n\tif (inode->i_nlink)\n\t\text4_orphan_del(handle, inode);\n\n\tinode->i_mtime = inode_set_ctime_current(inode);\n\terr2 = ext4_mark_inode_dirty(handle, inode);\n\tif (unlikely(err2 && !err))\n\t\terr = err2;\n\text4_journal_stop(handle);\n\nout_trace:\n\ttrace_ext4_truncate_exit(inode);\n\treturn err;\n}\n\nstatic inline u64 ext4_inode_peek_iversion(const struct inode *inode)\n{\n\tif (unlikely(EXT4_I(inode)->i_flags & EXT4_EA_INODE_FL))\n\t\treturn inode_peek_iversion_raw(inode);\n\telse\n\t\treturn inode_peek_iversion(inode);\n}\n\nstatic int ext4_inode_blocks_set(struct ext4_inode *raw_inode,\n\t\t\t\t struct ext4_inode_info *ei)\n{\n\tstruct inode *inode = &(ei->vfs_inode);\n\tu64 i_blocks = READ_ONCE(inode->i_blocks);\n\tstruct super_block *sb = inode->i_sb;\n\n\tif (i_blocks <= ~0U) {\n\t\t \n\t\traw_inode->i_blocks_lo   = cpu_to_le32(i_blocks);\n\t\traw_inode->i_blocks_high = 0;\n\t\text4_clear_inode_flag(inode, EXT4_INODE_HUGE_FILE);\n\t\treturn 0;\n\t}\n\n\t \n\tif (!ext4_has_feature_huge_file(sb))\n\t\treturn -EFSCORRUPTED;\n\n\tif (i_blocks <= 0xffffffffffffULL) {\n\t\t \n\t\traw_inode->i_blocks_lo   = cpu_to_le32(i_blocks);\n\t\traw_inode->i_blocks_high = cpu_to_le16(i_blocks >> 32);\n\t\text4_clear_inode_flag(inode, EXT4_INODE_HUGE_FILE);\n\t} else {\n\t\text4_set_inode_flag(inode, EXT4_INODE_HUGE_FILE);\n\t\t \n\t\ti_blocks = i_blocks >> (inode->i_blkbits - 9);\n\t\traw_inode->i_blocks_lo   = cpu_to_le32(i_blocks);\n\t\traw_inode->i_blocks_high = cpu_to_le16(i_blocks >> 32);\n\t}\n\treturn 0;\n}\n\nstatic int ext4_fill_raw_inode(struct inode *inode, struct ext4_inode *raw_inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tuid_t i_uid;\n\tgid_t i_gid;\n\tprojid_t i_projid;\n\tint block;\n\tint err;\n\n\terr = ext4_inode_blocks_set(raw_inode, ei);\n\n\traw_inode->i_mode = cpu_to_le16(inode->i_mode);\n\ti_uid = i_uid_read(inode);\n\ti_gid = i_gid_read(inode);\n\ti_projid = from_kprojid(&init_user_ns, ei->i_projid);\n\tif (!(test_opt(inode->i_sb, NO_UID32))) {\n\t\traw_inode->i_uid_low = cpu_to_le16(low_16_bits(i_uid));\n\t\traw_inode->i_gid_low = cpu_to_le16(low_16_bits(i_gid));\n\t\t \n\t\tif (ei->i_dtime && list_empty(&ei->i_orphan)) {\n\t\t\traw_inode->i_uid_high = 0;\n\t\t\traw_inode->i_gid_high = 0;\n\t\t} else {\n\t\t\traw_inode->i_uid_high =\n\t\t\t\tcpu_to_le16(high_16_bits(i_uid));\n\t\t\traw_inode->i_gid_high =\n\t\t\t\tcpu_to_le16(high_16_bits(i_gid));\n\t\t}\n\t} else {\n\t\traw_inode->i_uid_low = cpu_to_le16(fs_high2lowuid(i_uid));\n\t\traw_inode->i_gid_low = cpu_to_le16(fs_high2lowgid(i_gid));\n\t\traw_inode->i_uid_high = 0;\n\t\traw_inode->i_gid_high = 0;\n\t}\n\traw_inode->i_links_count = cpu_to_le16(inode->i_nlink);\n\n\tEXT4_INODE_SET_CTIME(inode, raw_inode);\n\tEXT4_INODE_SET_XTIME(i_mtime, inode, raw_inode);\n\tEXT4_INODE_SET_XTIME(i_atime, inode, raw_inode);\n\tEXT4_EINODE_SET_XTIME(i_crtime, ei, raw_inode);\n\n\traw_inode->i_dtime = cpu_to_le32(ei->i_dtime);\n\traw_inode->i_flags = cpu_to_le32(ei->i_flags & 0xFFFFFFFF);\n\tif (likely(!test_opt2(inode->i_sb, HURD_COMPAT)))\n\t\traw_inode->i_file_acl_high =\n\t\t\tcpu_to_le16(ei->i_file_acl >> 32);\n\traw_inode->i_file_acl_lo = cpu_to_le32(ei->i_file_acl);\n\text4_isize_set(raw_inode, ei->i_disksize);\n\n\traw_inode->i_generation = cpu_to_le32(inode->i_generation);\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tif (old_valid_dev(inode->i_rdev)) {\n\t\t\traw_inode->i_block[0] =\n\t\t\t\tcpu_to_le32(old_encode_dev(inode->i_rdev));\n\t\t\traw_inode->i_block[1] = 0;\n\t\t} else {\n\t\t\traw_inode->i_block[0] = 0;\n\t\t\traw_inode->i_block[1] =\n\t\t\t\tcpu_to_le32(new_encode_dev(inode->i_rdev));\n\t\t\traw_inode->i_block[2] = 0;\n\t\t}\n\t} else if (!ext4_has_inline_data(inode)) {\n\t\tfor (block = 0; block < EXT4_N_BLOCKS; block++)\n\t\t\traw_inode->i_block[block] = ei->i_data[block];\n\t}\n\n\tif (likely(!test_opt2(inode->i_sb, HURD_COMPAT))) {\n\t\tu64 ivers = ext4_inode_peek_iversion(inode);\n\n\t\traw_inode->i_disk_version = cpu_to_le32(ivers);\n\t\tif (ei->i_extra_isize) {\n\t\t\tif (EXT4_FITS_IN_INODE(raw_inode, ei, i_version_hi))\n\t\t\t\traw_inode->i_version_hi =\n\t\t\t\t\tcpu_to_le32(ivers >> 32);\n\t\t\traw_inode->i_extra_isize =\n\t\t\t\tcpu_to_le16(ei->i_extra_isize);\n\t\t}\n\t}\n\n\tif (i_projid != EXT4_DEF_PROJID &&\n\t    !ext4_has_feature_project(inode->i_sb))\n\t\terr = err ?: -EFSCORRUPTED;\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    EXT4_FITS_IN_INODE(raw_inode, ei, i_projid))\n\t\traw_inode->i_projid = cpu_to_le32(i_projid);\n\n\text4_inode_csum_set(inode, raw_inode, ei);\n\treturn err;\n}\n\n \nstatic int __ext4_get_inode_loc(struct super_block *sb, unsigned long ino,\n\t\t\t\tstruct inode *inode, struct ext4_iloc *iloc,\n\t\t\t\text4_fsblk_t *ret_block)\n{\n\tstruct ext4_group_desc\t*gdp;\n\tstruct buffer_head\t*bh;\n\text4_fsblk_t\t\tblock;\n\tstruct blk_plug\t\tplug;\n\tint\t\t\tinodes_per_block, inode_offset;\n\n\tiloc->bh = NULL;\n\tif (ino < EXT4_ROOT_INO ||\n\t    ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))\n\t\treturn -EFSCORRUPTED;\n\n\tiloc->block_group = (ino - 1) / EXT4_INODES_PER_GROUP(sb);\n\tgdp = ext4_get_group_desc(sb, iloc->block_group, NULL);\n\tif (!gdp)\n\t\treturn -EIO;\n\n\t \n\tinodes_per_block = EXT4_SB(sb)->s_inodes_per_block;\n\tinode_offset = ((ino - 1) %\n\t\t\tEXT4_INODES_PER_GROUP(sb));\n\tiloc->offset = (inode_offset % inodes_per_block) * EXT4_INODE_SIZE(sb);\n\n\tblock = ext4_inode_table(sb, gdp);\n\tif ((block <= le32_to_cpu(EXT4_SB(sb)->s_es->s_first_data_block)) ||\n\t    (block >= ext4_blocks_count(EXT4_SB(sb)->s_es))) {\n\t\text4_error(sb, \"Invalid inode table block %llu in \"\n\t\t\t   \"block_group %u\", block, iloc->block_group);\n\t\treturn -EFSCORRUPTED;\n\t}\n\tblock += (inode_offset / inodes_per_block);\n\n\tbh = sb_getblk(sb, block);\n\tif (unlikely(!bh))\n\t\treturn -ENOMEM;\n\tif (ext4_buffer_uptodate(bh))\n\t\tgoto has_buffer;\n\n\tlock_buffer(bh);\n\tif (ext4_buffer_uptodate(bh)) {\n\t\t \n\t\tunlock_buffer(bh);\n\t\tgoto has_buffer;\n\t}\n\n\t \n\tif (inode && !ext4_test_inode_state(inode, EXT4_STATE_XATTR)) {\n\t\tstruct buffer_head *bitmap_bh;\n\t\tint i, start;\n\n\t\tstart = inode_offset & ~(inodes_per_block - 1);\n\n\t\t \n\t\tbitmap_bh = sb_getblk(sb, ext4_inode_bitmap(sb, gdp));\n\t\tif (unlikely(!bitmap_bh))\n\t\t\tgoto make_io;\n\n\t\t \n\t\tif (!buffer_uptodate(bitmap_bh)) {\n\t\t\tbrelse(bitmap_bh);\n\t\t\tgoto make_io;\n\t\t}\n\t\tfor (i = start; i < start + inodes_per_block; i++) {\n\t\t\tif (i == inode_offset)\n\t\t\t\tcontinue;\n\t\t\tif (ext4_test_bit(i, bitmap_bh->b_data))\n\t\t\t\tbreak;\n\t\t}\n\t\tbrelse(bitmap_bh);\n\t\tif (i == start + inodes_per_block) {\n\t\t\tstruct ext4_inode *raw_inode =\n\t\t\t\t(struct ext4_inode *) (bh->b_data + iloc->offset);\n\n\t\t\t \n\t\t\tmemset(bh->b_data, 0, bh->b_size);\n\t\t\tif (!ext4_test_inode_state(inode, EXT4_STATE_NEW))\n\t\t\t\text4_fill_raw_inode(inode, raw_inode);\n\t\t\tset_buffer_uptodate(bh);\n\t\t\tunlock_buffer(bh);\n\t\t\tgoto has_buffer;\n\t\t}\n\t}\n\nmake_io:\n\t \n\tblk_start_plug(&plug);\n\tif (EXT4_SB(sb)->s_inode_readahead_blks) {\n\t\text4_fsblk_t b, end, table;\n\t\tunsigned num;\n\t\t__u32 ra_blks = EXT4_SB(sb)->s_inode_readahead_blks;\n\n\t\ttable = ext4_inode_table(sb, gdp);\n\t\t \n\t\tb = block & ~((ext4_fsblk_t) ra_blks - 1);\n\t\tif (table > b)\n\t\t\tb = table;\n\t\tend = b + ra_blks;\n\t\tnum = EXT4_INODES_PER_GROUP(sb);\n\t\tif (ext4_has_group_desc_csum(sb))\n\t\t\tnum -= ext4_itable_unused_count(sb, gdp);\n\t\ttable += num / inodes_per_block;\n\t\tif (end > table)\n\t\t\tend = table;\n\t\twhile (b <= end)\n\t\t\text4_sb_breadahead_unmovable(sb, b++);\n\t}\n\n\t \n\ttrace_ext4_load_inode(sb, ino);\n\text4_read_bh_nowait(bh, REQ_META | REQ_PRIO, NULL);\n\tblk_finish_plug(&plug);\n\twait_on_buffer(bh);\n\text4_simulate_fail_bh(sb, bh, EXT4_SIM_INODE_EIO);\n\tif (!buffer_uptodate(bh)) {\n\t\tif (ret_block)\n\t\t\t*ret_block = block;\n\t\tbrelse(bh);\n\t\treturn -EIO;\n\t}\nhas_buffer:\n\tiloc->bh = bh;\n\treturn 0;\n}\n\nstatic int __ext4_get_inode_loc_noinmem(struct inode *inode,\n\t\t\t\t\tstruct ext4_iloc *iloc)\n{\n\text4_fsblk_t err_blk = 0;\n\tint ret;\n\n\tret = __ext4_get_inode_loc(inode->i_sb, inode->i_ino, NULL, iloc,\n\t\t\t\t\t&err_blk);\n\n\tif (ret == -EIO)\n\t\text4_error_inode_block(inode, err_blk, EIO,\n\t\t\t\t\t\"unable to read itable block\");\n\n\treturn ret;\n}\n\nint ext4_get_inode_loc(struct inode *inode, struct ext4_iloc *iloc)\n{\n\text4_fsblk_t err_blk = 0;\n\tint ret;\n\n\tret = __ext4_get_inode_loc(inode->i_sb, inode->i_ino, inode, iloc,\n\t\t\t\t\t&err_blk);\n\n\tif (ret == -EIO)\n\t\text4_error_inode_block(inode, err_blk, EIO,\n\t\t\t\t\t\"unable to read itable block\");\n\n\treturn ret;\n}\n\n\nint ext4_get_fc_inode_loc(struct super_block *sb, unsigned long ino,\n\t\t\t  struct ext4_iloc *iloc)\n{\n\treturn __ext4_get_inode_loc(sb, ino, NULL, iloc, NULL);\n}\n\nstatic bool ext4_should_enable_dax(struct inode *inode)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\n\tif (test_opt2(inode->i_sb, DAX_NEVER))\n\t\treturn false;\n\tif (!S_ISREG(inode->i_mode))\n\t\treturn false;\n\tif (ext4_should_journal_data(inode))\n\t\treturn false;\n\tif (ext4_has_inline_data(inode))\n\t\treturn false;\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_ENCRYPT))\n\t\treturn false;\n\tif (ext4_test_inode_flag(inode, EXT4_INODE_VERITY))\n\t\treturn false;\n\tif (!test_bit(EXT4_FLAGS_BDEV_IS_DAX, &sbi->s_ext4_flags))\n\t\treturn false;\n\tif (test_opt(inode->i_sb, DAX_ALWAYS))\n\t\treturn true;\n\n\treturn ext4_test_inode_flag(inode, EXT4_INODE_DAX);\n}\n\nvoid ext4_set_inode_flags(struct inode *inode, bool init)\n{\n\tunsigned int flags = EXT4_I(inode)->i_flags;\n\tunsigned int new_fl = 0;\n\n\tWARN_ON_ONCE(IS_DAX(inode) && init);\n\n\tif (flags & EXT4_SYNC_FL)\n\t\tnew_fl |= S_SYNC;\n\tif (flags & EXT4_APPEND_FL)\n\t\tnew_fl |= S_APPEND;\n\tif (flags & EXT4_IMMUTABLE_FL)\n\t\tnew_fl |= S_IMMUTABLE;\n\tif (flags & EXT4_NOATIME_FL)\n\t\tnew_fl |= S_NOATIME;\n\tif (flags & EXT4_DIRSYNC_FL)\n\t\tnew_fl |= S_DIRSYNC;\n\n\t \n\tnew_fl |= (inode->i_flags & S_DAX);\n\tif (init && ext4_should_enable_dax(inode))\n\t\tnew_fl |= S_DAX;\n\n\tif (flags & EXT4_ENCRYPT_FL)\n\t\tnew_fl |= S_ENCRYPTED;\n\tif (flags & EXT4_CASEFOLD_FL)\n\t\tnew_fl |= S_CASEFOLD;\n\tif (flags & EXT4_VERITY_FL)\n\t\tnew_fl |= S_VERITY;\n\tinode_set_flags(inode, new_fl,\n\t\t\tS_SYNC|S_APPEND|S_IMMUTABLE|S_NOATIME|S_DIRSYNC|S_DAX|\n\t\t\tS_ENCRYPTED|S_CASEFOLD|S_VERITY);\n}\n\nstatic blkcnt_t ext4_inode_blocks(struct ext4_inode *raw_inode,\n\t\t\t\t  struct ext4_inode_info *ei)\n{\n\tblkcnt_t i_blocks ;\n\tstruct inode *inode = &(ei->vfs_inode);\n\tstruct super_block *sb = inode->i_sb;\n\n\tif (ext4_has_feature_huge_file(sb)) {\n\t\t \n\t\ti_blocks = ((u64)le16_to_cpu(raw_inode->i_blocks_high)) << 32 |\n\t\t\t\t\tle32_to_cpu(raw_inode->i_blocks_lo);\n\t\tif (ext4_test_inode_flag(inode, EXT4_INODE_HUGE_FILE)) {\n\t\t\t \n\t\t\treturn i_blocks  << (inode->i_blkbits - 9);\n\t\t} else {\n\t\t\treturn i_blocks;\n\t\t}\n\t} else {\n\t\treturn le32_to_cpu(raw_inode->i_blocks_lo);\n\t}\n}\n\nstatic inline int ext4_iget_extra_inode(struct inode *inode,\n\t\t\t\t\t struct ext4_inode *raw_inode,\n\t\t\t\t\t struct ext4_inode_info *ei)\n{\n\t__le32 *magic = (void *)raw_inode +\n\t\t\tEXT4_GOOD_OLD_INODE_SIZE + ei->i_extra_isize;\n\n\tif (EXT4_INODE_HAS_XATTR_SPACE(inode)  &&\n\t    *magic == cpu_to_le32(EXT4_XATTR_MAGIC)) {\n\t\tint err;\n\n\t\text4_set_inode_state(inode, EXT4_STATE_XATTR);\n\t\terr = ext4_find_inline_data_nolock(inode);\n\t\tif (!err && ext4_has_inline_data(inode))\n\t\t\text4_set_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA);\n\t\treturn err;\n\t} else\n\t\tEXT4_I(inode)->i_inline_off = 0;\n\treturn 0;\n}\n\nint ext4_get_projid(struct inode *inode, kprojid_t *projid)\n{\n\tif (!ext4_has_feature_project(inode->i_sb))\n\t\treturn -EOPNOTSUPP;\n\t*projid = EXT4_I(inode)->i_projid;\n\treturn 0;\n}\n\n \nstatic inline void ext4_inode_set_iversion_queried(struct inode *inode, u64 val)\n{\n\tif (unlikely(EXT4_I(inode)->i_flags & EXT4_EA_INODE_FL))\n\t\tinode_set_iversion_raw(inode, val);\n\telse\n\t\tinode_set_iversion_queried(inode, val);\n}\n\nstatic const char *check_igot_inode(struct inode *inode, ext4_iget_flags flags)\n\n{\n\tif (flags & EXT4_IGET_EA_INODE) {\n\t\tif (!(EXT4_I(inode)->i_flags & EXT4_EA_INODE_FL))\n\t\t\treturn \"missing EA_INODE flag\";\n\t\tif (ext4_test_inode_state(inode, EXT4_STATE_XATTR) ||\n\t\t    EXT4_I(inode)->i_file_acl)\n\t\t\treturn \"ea_inode with extended attributes\";\n\t} else {\n\t\tif ((EXT4_I(inode)->i_flags & EXT4_EA_INODE_FL))\n\t\t\treturn \"unexpected EA_INODE flag\";\n\t}\n\tif (is_bad_inode(inode) && !(flags & EXT4_IGET_BAD))\n\t\treturn \"unexpected bad inode w/o EXT4_IGET_BAD\";\n\treturn NULL;\n}\n\nstruct inode *__ext4_iget(struct super_block *sb, unsigned long ino,\n\t\t\t  ext4_iget_flags flags, const char *function,\n\t\t\t  unsigned int line)\n{\n\tstruct ext4_iloc iloc;\n\tstruct ext4_inode *raw_inode;\n\tstruct ext4_inode_info *ei;\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\tstruct inode *inode;\n\tconst char *err_str;\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\tlong ret;\n\tloff_t size;\n\tint block;\n\tuid_t i_uid;\n\tgid_t i_gid;\n\tprojid_t i_projid;\n\n\tif ((!(flags & EXT4_IGET_SPECIAL) &&\n\t     ((ino < EXT4_FIRST_INO(sb) && ino != EXT4_ROOT_INO) ||\n\t      ino == le32_to_cpu(es->s_usr_quota_inum) ||\n\t      ino == le32_to_cpu(es->s_grp_quota_inum) ||\n\t      ino == le32_to_cpu(es->s_prj_quota_inum) ||\n\t      ino == le32_to_cpu(es->s_orphan_file_inum))) ||\n\t    (ino < EXT4_ROOT_INO) ||\n\t    (ino > le32_to_cpu(es->s_inodes_count))) {\n\t\tif (flags & EXT4_IGET_HANDLE)\n\t\t\treturn ERR_PTR(-ESTALE);\n\t\t__ext4_error(sb, function, line, false, EFSCORRUPTED, 0,\n\t\t\t     \"inode #%lu: comm %s: iget: illegal inode #\",\n\t\t\t     ino, current->comm);\n\t\treturn ERR_PTR(-EFSCORRUPTED);\n\t}\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\tif (!(inode->i_state & I_NEW)) {\n\t\tif ((err_str = check_igot_inode(inode, flags)) != NULL) {\n\t\t\text4_error_inode(inode, function, line, 0, err_str);\n\t\t\tiput(inode);\n\t\t\treturn ERR_PTR(-EFSCORRUPTED);\n\t\t}\n\t\treturn inode;\n\t}\n\n\tei = EXT4_I(inode);\n\tiloc.bh = NULL;\n\n\tret = __ext4_get_inode_loc_noinmem(inode, &iloc);\n\tif (ret < 0)\n\t\tgoto bad_inode;\n\traw_inode = ext4_raw_inode(&iloc);\n\n\tif ((flags & EXT4_IGET_HANDLE) &&\n\t    (raw_inode->i_links_count == 0) && (raw_inode->i_mode == 0)) {\n\t\tret = -ESTALE;\n\t\tgoto bad_inode;\n\t}\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tei->i_extra_isize = le16_to_cpu(raw_inode->i_extra_isize);\n\t\tif (EXT4_GOOD_OLD_INODE_SIZE + ei->i_extra_isize >\n\t\t\tEXT4_INODE_SIZE(inode->i_sb) ||\n\t\t    (ei->i_extra_isize & 3)) {\n\t\t\text4_error_inode(inode, function, line, 0,\n\t\t\t\t\t \"iget: bad extra_isize %u \"\n\t\t\t\t\t \"(inode size %u)\",\n\t\t\t\t\t ei->i_extra_isize,\n\t\t\t\t\t EXT4_INODE_SIZE(inode->i_sb));\n\t\t\tret = -EFSCORRUPTED;\n\t\t\tgoto bad_inode;\n\t\t}\n\t} else\n\t\tei->i_extra_isize = 0;\n\n\t \n\tif (ext4_has_metadata_csum(sb)) {\n\t\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\t\t__u32 csum;\n\t\t__le32 inum = cpu_to_le32(inode->i_ino);\n\t\t__le32 gen = raw_inode->i_generation;\n\t\tcsum = ext4_chksum(sbi, sbi->s_csum_seed, (__u8 *)&inum,\n\t\t\t\t   sizeof(inum));\n\t\tei->i_csum_seed = ext4_chksum(sbi, csum, (__u8 *)&gen,\n\t\t\t\t\t      sizeof(gen));\n\t}\n\n\tif ((!ext4_inode_csum_verify(inode, raw_inode, ei) ||\n\t    ext4_simulate_fail(sb, EXT4_SIM_INODE_CRC)) &&\n\t     (!(EXT4_SB(sb)->s_mount_state & EXT4_FC_REPLAY))) {\n\t\text4_error_inode_err(inode, function, line, 0,\n\t\t\t\tEFSBADCRC, \"iget: checksum invalid\");\n\t\tret = -EFSBADCRC;\n\t\tgoto bad_inode;\n\t}\n\n\tinode->i_mode = le16_to_cpu(raw_inode->i_mode);\n\ti_uid = (uid_t)le16_to_cpu(raw_inode->i_uid_low);\n\ti_gid = (gid_t)le16_to_cpu(raw_inode->i_gid_low);\n\tif (ext4_has_feature_project(sb) &&\n\t    EXT4_INODE_SIZE(sb) > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    EXT4_FITS_IN_INODE(raw_inode, ei, i_projid))\n\t\ti_projid = (projid_t)le32_to_cpu(raw_inode->i_projid);\n\telse\n\t\ti_projid = EXT4_DEF_PROJID;\n\n\tif (!(test_opt(inode->i_sb, NO_UID32))) {\n\t\ti_uid |= le16_to_cpu(raw_inode->i_uid_high) << 16;\n\t\ti_gid |= le16_to_cpu(raw_inode->i_gid_high) << 16;\n\t}\n\ti_uid_write(inode, i_uid);\n\ti_gid_write(inode, i_gid);\n\tei->i_projid = make_kprojid(&init_user_ns, i_projid);\n\tset_nlink(inode, le16_to_cpu(raw_inode->i_links_count));\n\n\text4_clear_state_flags(ei);\t \n\tei->i_inline_off = 0;\n\tei->i_dir_start_lookup = 0;\n\tei->i_dtime = le32_to_cpu(raw_inode->i_dtime);\n\t \n\tif (inode->i_nlink == 0) {\n\t\tif ((inode->i_mode == 0 || flags & EXT4_IGET_SPECIAL ||\n\t\t     !(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_ORPHAN_FS)) &&\n\t\t    ino != EXT4_BOOT_LOADER_INO) {\n\t\t\t \n\t\t\tif (flags & EXT4_IGET_SPECIAL) {\n\t\t\t\text4_error_inode(inode, function, line, 0,\n\t\t\t\t\t\t \"iget: special inode unallocated\");\n\t\t\t\tret = -EFSCORRUPTED;\n\t\t\t} else\n\t\t\t\tret = -ESTALE;\n\t\t\tgoto bad_inode;\n\t\t}\n\t\t \n\t}\n\tei->i_flags = le32_to_cpu(raw_inode->i_flags);\n\text4_set_inode_flags(inode, true);\n\tinode->i_blocks = ext4_inode_blocks(raw_inode, ei);\n\tei->i_file_acl = le32_to_cpu(raw_inode->i_file_acl_lo);\n\tif (ext4_has_feature_64bit(sb))\n\t\tei->i_file_acl |=\n\t\t\t((__u64)le16_to_cpu(raw_inode->i_file_acl_high)) << 32;\n\tinode->i_size = ext4_isize(sb, raw_inode);\n\tif ((size = i_size_read(inode)) < 0) {\n\t\text4_error_inode(inode, function, line, 0,\n\t\t\t\t \"iget: bad i_size value: %lld\", size);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\t \n\tif (!ext4_has_feature_dir_index(sb) && ext4_has_metadata_csum(sb) &&\n\t    ext4_test_inode_flag(inode, EXT4_INODE_INDEX)) {\n\t\text4_error_inode(inode, function, line, 0,\n\t\t\t \"iget: Dir with htree data on filesystem without dir_index feature.\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\tei->i_disksize = inode->i_size;\n#ifdef CONFIG_QUOTA\n\tei->i_reserved_quota = 0;\n#endif\n\tinode->i_generation = le32_to_cpu(raw_inode->i_generation);\n\tei->i_block_group = iloc.block_group;\n\tei->i_last_alloc_group = ~0;\n\t \n\tfor (block = 0; block < EXT4_N_BLOCKS; block++)\n\t\tei->i_data[block] = raw_inode->i_block[block];\n\tINIT_LIST_HEAD(&ei->i_orphan);\n\text4_fc_init_inode(&ei->vfs_inode);\n\n\t \n\tif (journal) {\n\t\ttransaction_t *transaction;\n\t\ttid_t tid;\n\n\t\tread_lock(&journal->j_state_lock);\n\t\tif (journal->j_running_transaction)\n\t\t\ttransaction = journal->j_running_transaction;\n\t\telse\n\t\t\ttransaction = journal->j_committing_transaction;\n\t\tif (transaction)\n\t\t\ttid = transaction->t_tid;\n\t\telse\n\t\t\ttid = journal->j_commit_sequence;\n\t\tread_unlock(&journal->j_state_lock);\n\t\tei->i_sync_tid = tid;\n\t\tei->i_datasync_tid = tid;\n\t}\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tif (ei->i_extra_isize == 0) {\n\t\t\t \n\t\t\tBUILD_BUG_ON(sizeof(struct ext4_inode) & 3);\n\t\t\tei->i_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t    EXT4_GOOD_OLD_INODE_SIZE;\n\t\t} else {\n\t\t\tret = ext4_iget_extra_inode(inode, raw_inode, ei);\n\t\t\tif (ret)\n\t\t\t\tgoto bad_inode;\n\t\t}\n\t}\n\n\tEXT4_INODE_GET_CTIME(inode, raw_inode);\n\tEXT4_INODE_GET_XTIME(i_mtime, inode, raw_inode);\n\tEXT4_INODE_GET_XTIME(i_atime, inode, raw_inode);\n\tEXT4_EINODE_GET_XTIME(i_crtime, ei, raw_inode);\n\n\tif (likely(!test_opt2(inode->i_sb, HURD_COMPAT))) {\n\t\tu64 ivers = le32_to_cpu(raw_inode->i_disk_version);\n\n\t\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\t\tif (EXT4_FITS_IN_INODE(raw_inode, ei, i_version_hi))\n\t\t\t\tivers |=\n\t\t    (__u64)(le32_to_cpu(raw_inode->i_version_hi)) << 32;\n\t\t}\n\t\text4_inode_set_iversion_queried(inode, ivers);\n\t}\n\n\tret = 0;\n\tif (ei->i_file_acl &&\n\t    !ext4_inode_block_valid(inode, ei->i_file_acl, 1)) {\n\t\text4_error_inode(inode, function, line, 0,\n\t\t\t\t \"iget: bad extended attribute block %llu\",\n\t\t\t\t ei->i_file_acl);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t} else if (!ext4_has_inline_data(inode)) {\n\t\t \n\t\tif (!(EXT4_SB(sb)->s_mount_state & EXT4_FC_REPLAY) &&\n\t\t\t(S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t\t\t(S_ISLNK(inode->i_mode) &&\n\t\t\t!ext4_inode_is_fast_symlink(inode)))) {\n\t\t\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))\n\t\t\t\tret = ext4_ext_check_inode(inode);\n\t\t\telse\n\t\t\t\tret = ext4_ind_check_inode(inode);\n\t\t}\n\t}\n\tif (ret)\n\t\tgoto bad_inode;\n\n\tif (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &ext4_file_inode_operations;\n\t\tinode->i_fop = &ext4_file_operations;\n\t\text4_set_aops(inode);\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &ext4_dir_inode_operations;\n\t\tinode->i_fop = &ext4_dir_operations;\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\t \n\t\tif (IS_APPEND(inode) || IS_IMMUTABLE(inode)) {\n\t\t\text4_error_inode(inode, function, line, 0,\n\t\t\t\t\t \"iget: immutable or append flags \"\n\t\t\t\t\t \"not allowed on symlinks\");\n\t\t\tret = -EFSCORRUPTED;\n\t\t\tgoto bad_inode;\n\t\t}\n\t\tif (IS_ENCRYPTED(inode)) {\n\t\t\tinode->i_op = &ext4_encrypted_symlink_inode_operations;\n\t\t} else if (ext4_inode_is_fast_symlink(inode)) {\n\t\t\tinode->i_link = (char *)ei->i_data;\n\t\t\tinode->i_op = &ext4_fast_symlink_inode_operations;\n\t\t\tnd_terminate_link(ei->i_data, inode->i_size,\n\t\t\t\tsizeof(ei->i_data) - 1);\n\t\t} else {\n\t\t\tinode->i_op = &ext4_symlink_inode_operations;\n\t\t}\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t      S_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &ext4_special_inode_operations;\n\t\tif (raw_inode->i_block[0])\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   old_decode_dev(le32_to_cpu(raw_inode->i_block[0])));\n\t\telse\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   new_decode_dev(le32_to_cpu(raw_inode->i_block[1])));\n\t} else if (ino == EXT4_BOOT_LOADER_INO) {\n\t\tmake_bad_inode(inode);\n\t} else {\n\t\tret = -EFSCORRUPTED;\n\t\text4_error_inode(inode, function, line, 0,\n\t\t\t\t \"iget: bogus i_mode (%o)\", inode->i_mode);\n\t\tgoto bad_inode;\n\t}\n\tif (IS_CASEFOLDED(inode) && !ext4_has_feature_casefold(inode->i_sb)) {\n\t\text4_error_inode(inode, function, line, 0,\n\t\t\t\t \"casefold flag without casefold feature\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\tif ((err_str = check_igot_inode(inode, flags)) != NULL) {\n\t\text4_error_inode(inode, function, line, 0, err_str);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\n\tbrelse(iloc.bh);\n\tunlock_new_inode(inode);\n\treturn inode;\n\nbad_inode:\n\tbrelse(iloc.bh);\n\tiget_failed(inode);\n\treturn ERR_PTR(ret);\n}\n\nstatic void __ext4_update_other_inode_time(struct super_block *sb,\n\t\t\t\t\t   unsigned long orig_ino,\n\t\t\t\t\t   unsigned long ino,\n\t\t\t\t\t   struct ext4_inode *raw_inode)\n{\n\tstruct inode *inode;\n\n\tinode = find_inode_by_ino_rcu(sb, ino);\n\tif (!inode)\n\t\treturn;\n\n\tif (!inode_is_dirtytime_only(inode))\n\t\treturn;\n\n\tspin_lock(&inode->i_lock);\n\tif (inode_is_dirtytime_only(inode)) {\n\t\tstruct ext4_inode_info\t*ei = EXT4_I(inode);\n\n\t\tinode->i_state &= ~I_DIRTY_TIME;\n\t\tspin_unlock(&inode->i_lock);\n\n\t\tspin_lock(&ei->i_raw_lock);\n\t\tEXT4_INODE_SET_CTIME(inode, raw_inode);\n\t\tEXT4_INODE_SET_XTIME(i_mtime, inode, raw_inode);\n\t\tEXT4_INODE_SET_XTIME(i_atime, inode, raw_inode);\n\t\text4_inode_csum_set(inode, raw_inode, ei);\n\t\tspin_unlock(&ei->i_raw_lock);\n\t\ttrace_ext4_other_inode_update_time(inode, orig_ino);\n\t\treturn;\n\t}\n\tspin_unlock(&inode->i_lock);\n}\n\n \nstatic void ext4_update_other_inodes_time(struct super_block *sb,\n\t\t\t\t\t  unsigned long orig_ino, char *buf)\n{\n\tunsigned long ino;\n\tint i, inodes_per_block = EXT4_SB(sb)->s_inodes_per_block;\n\tint inode_size = EXT4_INODE_SIZE(sb);\n\n\t \n\tino = ((orig_ino - 1) & ~(inodes_per_block - 1)) + 1;\n\trcu_read_lock();\n\tfor (i = 0; i < inodes_per_block; i++, ino++, buf += inode_size) {\n\t\tif (ino == orig_ino)\n\t\t\tcontinue;\n\t\t__ext4_update_other_inode_time(sb, orig_ino, ino,\n\t\t\t\t\t       (struct ext4_inode *)buf);\n\t}\n\trcu_read_unlock();\n}\n\n \nstatic int ext4_do_update_inode(handle_t *handle,\n\t\t\t\tstruct inode *inode,\n\t\t\t\tstruct ext4_iloc *iloc)\n{\n\tstruct ext4_inode *raw_inode = ext4_raw_inode(iloc);\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct buffer_head *bh = iloc->bh;\n\tstruct super_block *sb = inode->i_sb;\n\tint err;\n\tint need_datasync = 0, set_large_file = 0;\n\n\tspin_lock(&ei->i_raw_lock);\n\n\t \n\tif (ext4_test_inode_state(inode, EXT4_STATE_NEW))\n\t\tmemset(raw_inode, 0, EXT4_SB(inode->i_sb)->s_inode_size);\n\n\tif (READ_ONCE(ei->i_disksize) != ext4_isize(inode->i_sb, raw_inode))\n\t\tneed_datasync = 1;\n\tif (ei->i_disksize > 0x7fffffffULL) {\n\t\tif (!ext4_has_feature_large_file(sb) ||\n\t\t    EXT4_SB(sb)->s_es->s_rev_level == cpu_to_le32(EXT4_GOOD_OLD_REV))\n\t\t\tset_large_file = 1;\n\t}\n\n\terr = ext4_fill_raw_inode(inode, raw_inode);\n\tspin_unlock(&ei->i_raw_lock);\n\tif (err) {\n\t\tEXT4_ERROR_INODE(inode, \"corrupted inode contents\");\n\t\tgoto out_brelse;\n\t}\n\n\tif (inode->i_sb->s_flags & SB_LAZYTIME)\n\t\text4_update_other_inodes_time(inode->i_sb, inode->i_ino,\n\t\t\t\t\t      bh->b_data);\n\n\tBUFFER_TRACE(bh, \"call ext4_handle_dirty_metadata\");\n\terr = ext4_handle_dirty_metadata(handle, NULL, bh);\n\tif (err)\n\t\tgoto out_error;\n\text4_clear_inode_state(inode, EXT4_STATE_NEW);\n\tif (set_large_file) {\n\t\tBUFFER_TRACE(EXT4_SB(sb)->s_sbh, \"get write access\");\n\t\terr = ext4_journal_get_write_access(handle, sb,\n\t\t\t\t\t\t    EXT4_SB(sb)->s_sbh,\n\t\t\t\t\t\t    EXT4_JTR_NONE);\n\t\tif (err)\n\t\t\tgoto out_error;\n\t\tlock_buffer(EXT4_SB(sb)->s_sbh);\n\t\text4_set_feature_large_file(sb);\n\t\text4_superblock_csum_set(sb);\n\t\tunlock_buffer(EXT4_SB(sb)->s_sbh);\n\t\text4_handle_sync(handle);\n\t\terr = ext4_handle_dirty_metadata(handle, NULL,\n\t\t\t\t\t\t EXT4_SB(sb)->s_sbh);\n\t}\n\text4_update_inode_fsync_trans(handle, inode, need_datasync);\nout_error:\n\text4_std_error(inode->i_sb, err);\nout_brelse:\n\tbrelse(bh);\n\treturn err;\n}\n\n \nint ext4_write_inode(struct inode *inode, struct writeback_control *wbc)\n{\n\tint err;\n\n\tif (WARN_ON_ONCE(current->flags & PF_MEMALLOC))\n\t\treturn 0;\n\n\tif (unlikely(ext4_forced_shutdown(inode->i_sb)))\n\t\treturn -EIO;\n\n\tif (EXT4_SB(inode->i_sb)->s_journal) {\n\t\tif (ext4_journal_current_handle()) {\n\t\t\text4_debug(\"called recursively, non-PF_MEMALLOC!\\n\");\n\t\t\tdump_stack();\n\t\t\treturn -EIO;\n\t\t}\n\n\t\t \n\t\tif (wbc->sync_mode != WB_SYNC_ALL || wbc->for_sync)\n\t\t\treturn 0;\n\n\t\terr = ext4_fc_commit(EXT4_SB(inode->i_sb)->s_journal,\n\t\t\t\t\t\tEXT4_I(inode)->i_sync_tid);\n\t} else {\n\t\tstruct ext4_iloc iloc;\n\n\t\terr = __ext4_get_inode_loc_noinmem(inode, &iloc);\n\t\tif (err)\n\t\t\treturn err;\n\t\t \n\t\tif (wbc->sync_mode == WB_SYNC_ALL && !wbc->for_sync)\n\t\t\tsync_dirty_buffer(iloc.bh);\n\t\tif (buffer_req(iloc.bh) && !buffer_uptodate(iloc.bh)) {\n\t\t\text4_error_inode_block(inode, iloc.bh->b_blocknr, EIO,\n\t\t\t\t\t       \"IO error syncing inode\");\n\t\t\terr = -EIO;\n\t\t}\n\t\tbrelse(iloc.bh);\n\t}\n\treturn err;\n}\n\n \nstatic void ext4_wait_for_tail_page_commit(struct inode *inode)\n{\n\tunsigned offset;\n\tjournal_t *journal = EXT4_SB(inode->i_sb)->s_journal;\n\ttid_t commit_tid = 0;\n\tint ret;\n\n\toffset = inode->i_size & (PAGE_SIZE - 1);\n\t \n\tif (!offset || offset > (PAGE_SIZE - i_blocksize(inode)))\n\t\treturn;\n\twhile (1) {\n\t\tstruct folio *folio = filemap_lock_folio(inode->i_mapping,\n\t\t\t\t      inode->i_size >> PAGE_SHIFT);\n\t\tif (IS_ERR(folio))\n\t\t\treturn;\n\t\tret = __ext4_journalled_invalidate_folio(folio, offset,\n\t\t\t\t\t\tfolio_size(folio) - offset);\n\t\tfolio_unlock(folio);\n\t\tfolio_put(folio);\n\t\tif (ret != -EBUSY)\n\t\t\treturn;\n\t\tcommit_tid = 0;\n\t\tread_lock(&journal->j_state_lock);\n\t\tif (journal->j_committing_transaction)\n\t\t\tcommit_tid = journal->j_committing_transaction->t_tid;\n\t\tread_unlock(&journal->j_state_lock);\n\t\tif (commit_tid)\n\t\t\tjbd2_log_wait_commit(journal, commit_tid);\n\t}\n}\n\n \nint ext4_setattr(struct mnt_idmap *idmap, struct dentry *dentry,\n\t\t struct iattr *attr)\n{\n\tstruct inode *inode = d_inode(dentry);\n\tint error, rc = 0;\n\tint orphan = 0;\n\tconst unsigned int ia_valid = attr->ia_valid;\n\tbool inc_ivers = true;\n\n\tif (unlikely(ext4_forced_shutdown(inode->i_sb)))\n\t\treturn -EIO;\n\n\tif (unlikely(IS_IMMUTABLE(inode)))\n\t\treturn -EPERM;\n\n\tif (unlikely(IS_APPEND(inode) &&\n\t\t     (ia_valid & (ATTR_MODE | ATTR_UID |\n\t\t\t\t  ATTR_GID | ATTR_TIMES_SET))))\n\t\treturn -EPERM;\n\n\terror = setattr_prepare(idmap, dentry, attr);\n\tif (error)\n\t\treturn error;\n\n\terror = fscrypt_prepare_setattr(dentry, attr);\n\tif (error)\n\t\treturn error;\n\n\terror = fsverity_prepare_setattr(dentry, attr);\n\tif (error)\n\t\treturn error;\n\n\tif (is_quota_modification(idmap, inode, attr)) {\n\t\terror = dquot_initialize(inode);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\tif (i_uid_needs_update(idmap, attr, inode) ||\n\t    i_gid_needs_update(idmap, attr, inode)) {\n\t\thandle_t *handle;\n\n\t\t \n\t\thandle = ext4_journal_start(inode, EXT4_HT_QUOTA,\n\t\t\t(EXT4_MAXQUOTAS_INIT_BLOCKS(inode->i_sb) +\n\t\t\t EXT4_MAXQUOTAS_DEL_BLOCKS(inode->i_sb)) + 3);\n\t\tif (IS_ERR(handle)) {\n\t\t\terror = PTR_ERR(handle);\n\t\t\tgoto err_out;\n\t\t}\n\n\t\t \n\t\tdown_read(&EXT4_I(inode)->xattr_sem);\n\t\terror = dquot_transfer(idmap, inode, attr);\n\t\tup_read(&EXT4_I(inode)->xattr_sem);\n\n\t\tif (error) {\n\t\t\text4_journal_stop(handle);\n\t\t\treturn error;\n\t\t}\n\t\t \n\t\ti_uid_update(idmap, attr, inode);\n\t\ti_gid_update(idmap, attr, inode);\n\t\terror = ext4_mark_inode_dirty(handle, inode);\n\t\text4_journal_stop(handle);\n\t\tif (unlikely(error)) {\n\t\t\treturn error;\n\t\t}\n\t}\n\n\tif (attr->ia_valid & ATTR_SIZE) {\n\t\thandle_t *handle;\n\t\tloff_t oldsize = inode->i_size;\n\t\tloff_t old_disksize;\n\t\tint shrink = (attr->ia_size < inode->i_size);\n\n\t\tif (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))) {\n\t\t\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\n\t\t\tif (attr->ia_size > sbi->s_bitmap_maxbytes) {\n\t\t\t\treturn -EFBIG;\n\t\t\t}\n\t\t}\n\t\tif (!S_ISREG(inode->i_mode)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (attr->ia_size == inode->i_size)\n\t\t\tinc_ivers = false;\n\n\t\tif (shrink) {\n\t\t\tif (ext4_should_order_data(inode)) {\n\t\t\t\terror = ext4_begin_ordered_truncate(inode,\n\t\t\t\t\t\t\t    attr->ia_size);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\t \n\t\t\tinode_dio_wait(inode);\n\t\t}\n\n\t\tfilemap_invalidate_lock(inode->i_mapping);\n\n\t\trc = ext4_break_layouts(inode);\n\t\tif (rc) {\n\t\t\tfilemap_invalidate_unlock(inode->i_mapping);\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (attr->ia_size != inode->i_size) {\n\t\t\thandle = ext4_journal_start(inode, EXT4_HT_INODE, 3);\n\t\t\tif (IS_ERR(handle)) {\n\t\t\t\terror = PTR_ERR(handle);\n\t\t\t\tgoto out_mmap_sem;\n\t\t\t}\n\t\t\tif (ext4_handle_valid(handle) && shrink) {\n\t\t\t\terror = ext4_orphan_add(handle, inode);\n\t\t\t\torphan = 1;\n\t\t\t}\n\t\t\t \n\t\t\tif (!shrink)\n\t\t\t\tinode->i_mtime = inode_set_ctime_current(inode);\n\n\t\t\tif (shrink)\n\t\t\t\text4_fc_track_range(handle, inode,\n\t\t\t\t\t(attr->ia_size > 0 ? attr->ia_size - 1 : 0) >>\n\t\t\t\t\tinode->i_sb->s_blocksize_bits,\n\t\t\t\t\tEXT_MAX_BLOCKS - 1);\n\t\t\telse\n\t\t\t\text4_fc_track_range(\n\t\t\t\t\thandle, inode,\n\t\t\t\t\t(oldsize > 0 ? oldsize - 1 : oldsize) >>\n\t\t\t\t\tinode->i_sb->s_blocksize_bits,\n\t\t\t\t\t(attr->ia_size > 0 ? attr->ia_size - 1 : 0) >>\n\t\t\t\t\tinode->i_sb->s_blocksize_bits);\n\n\t\t\tdown_write(&EXT4_I(inode)->i_data_sem);\n\t\t\told_disksize = EXT4_I(inode)->i_disksize;\n\t\t\tEXT4_I(inode)->i_disksize = attr->ia_size;\n\t\t\trc = ext4_mark_inode_dirty(handle, inode);\n\t\t\tif (!error)\n\t\t\t\terror = rc;\n\t\t\t \n\t\t\tif (!error)\n\t\t\t\ti_size_write(inode, attr->ia_size);\n\t\t\telse\n\t\t\t\tEXT4_I(inode)->i_disksize = old_disksize;\n\t\t\tup_write(&EXT4_I(inode)->i_data_sem);\n\t\t\text4_journal_stop(handle);\n\t\t\tif (error)\n\t\t\t\tgoto out_mmap_sem;\n\t\t\tif (!shrink) {\n\t\t\t\tpagecache_isize_extended(inode, oldsize,\n\t\t\t\t\t\t\t inode->i_size);\n\t\t\t} else if (ext4_should_journal_data(inode)) {\n\t\t\t\text4_wait_for_tail_page_commit(inode);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\ttruncate_pagecache(inode, inode->i_size);\n\t\t \n\t\tif (attr->ia_size <= oldsize) {\n\t\t\trc = ext4_truncate(inode);\n\t\t\tif (rc)\n\t\t\t\terror = rc;\n\t\t}\nout_mmap_sem:\n\t\tfilemap_invalidate_unlock(inode->i_mapping);\n\t}\n\n\tif (!error) {\n\t\tif (inc_ivers)\n\t\t\tinode_inc_iversion(inode);\n\t\tsetattr_copy(idmap, inode, attr);\n\t\tmark_inode_dirty(inode);\n\t}\n\n\t \n\tif (orphan && inode->i_nlink)\n\t\text4_orphan_del(NULL, inode);\n\n\tif (!error && (ia_valid & ATTR_MODE))\n\t\trc = posix_acl_chmod(idmap, dentry, inode->i_mode);\n\nerr_out:\n\tif  (error)\n\t\text4_std_error(inode->i_sb, error);\n\tif (!error)\n\t\terror = rc;\n\treturn error;\n}\n\nu32 ext4_dio_alignment(struct inode *inode)\n{\n\tif (fsverity_active(inode))\n\t\treturn 0;\n\tif (ext4_should_journal_data(inode))\n\t\treturn 0;\n\tif (ext4_has_inline_data(inode))\n\t\treturn 0;\n\tif (IS_ENCRYPTED(inode)) {\n\t\tif (!fscrypt_dio_supported(inode))\n\t\t\treturn 0;\n\t\treturn i_blocksize(inode);\n\t}\n\treturn 1;  \n}\n\nint ext4_getattr(struct mnt_idmap *idmap, const struct path *path,\n\t\t struct kstat *stat, u32 request_mask, unsigned int query_flags)\n{\n\tstruct inode *inode = d_inode(path->dentry);\n\tstruct ext4_inode *raw_inode;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tunsigned int flags;\n\n\tif ((request_mask & STATX_BTIME) &&\n\t    EXT4_FITS_IN_INODE(raw_inode, ei, i_crtime)) {\n\t\tstat->result_mask |= STATX_BTIME;\n\t\tstat->btime.tv_sec = ei->i_crtime.tv_sec;\n\t\tstat->btime.tv_nsec = ei->i_crtime.tv_nsec;\n\t}\n\n\t \n\tif ((request_mask & STATX_DIOALIGN) && S_ISREG(inode->i_mode)) {\n\t\tu32 dio_align = ext4_dio_alignment(inode);\n\n\t\tstat->result_mask |= STATX_DIOALIGN;\n\t\tif (dio_align == 1) {\n\t\t\tstruct block_device *bdev = inode->i_sb->s_bdev;\n\n\t\t\t \n\t\t\tstat->dio_mem_align = bdev_dma_alignment(bdev) + 1;\n\t\t\tstat->dio_offset_align = bdev_logical_block_size(bdev);\n\t\t} else {\n\t\t\tstat->dio_mem_align = dio_align;\n\t\t\tstat->dio_offset_align = dio_align;\n\t\t}\n\t}\n\n\tflags = ei->i_flags & EXT4_FL_USER_VISIBLE;\n\tif (flags & EXT4_APPEND_FL)\n\t\tstat->attributes |= STATX_ATTR_APPEND;\n\tif (flags & EXT4_COMPR_FL)\n\t\tstat->attributes |= STATX_ATTR_COMPRESSED;\n\tif (flags & EXT4_ENCRYPT_FL)\n\t\tstat->attributes |= STATX_ATTR_ENCRYPTED;\n\tif (flags & EXT4_IMMUTABLE_FL)\n\t\tstat->attributes |= STATX_ATTR_IMMUTABLE;\n\tif (flags & EXT4_NODUMP_FL)\n\t\tstat->attributes |= STATX_ATTR_NODUMP;\n\tif (flags & EXT4_VERITY_FL)\n\t\tstat->attributes |= STATX_ATTR_VERITY;\n\n\tstat->attributes_mask |= (STATX_ATTR_APPEND |\n\t\t\t\t  STATX_ATTR_COMPRESSED |\n\t\t\t\t  STATX_ATTR_ENCRYPTED |\n\t\t\t\t  STATX_ATTR_IMMUTABLE |\n\t\t\t\t  STATX_ATTR_NODUMP |\n\t\t\t\t  STATX_ATTR_VERITY);\n\n\tgeneric_fillattr(idmap, request_mask, inode, stat);\n\treturn 0;\n}\n\nint ext4_file_getattr(struct mnt_idmap *idmap,\n\t\t      const struct path *path, struct kstat *stat,\n\t\t      u32 request_mask, unsigned int query_flags)\n{\n\tstruct inode *inode = d_inode(path->dentry);\n\tu64 delalloc_blocks;\n\n\text4_getattr(idmap, path, stat, request_mask, query_flags);\n\n\t \n\tif (unlikely(ext4_has_inline_data(inode)))\n\t\tstat->blocks += (stat->size + 511) >> 9;\n\n\t \n\tdelalloc_blocks = EXT4_C2B(EXT4_SB(inode->i_sb),\n\t\t\t\t   EXT4_I(inode)->i_reserved_data_blocks);\n\tstat->blocks += delalloc_blocks << (inode->i_sb->s_blocksize_bits - 9);\n\treturn 0;\n}\n\nstatic int ext4_index_trans_blocks(struct inode *inode, int lblocks,\n\t\t\t\t   int pextents)\n{\n\tif (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))\n\t\treturn ext4_ind_trans_blocks(inode, lblocks);\n\treturn ext4_ext_index_trans_blocks(inode, pextents);\n}\n\n \nstatic int ext4_meta_trans_blocks(struct inode *inode, int lblocks,\n\t\t\t\t  int pextents)\n{\n\text4_group_t groups, ngroups = ext4_get_groups_count(inode->i_sb);\n\tint gdpblocks;\n\tint idxblocks;\n\tint ret;\n\n\t \n\tidxblocks = ext4_index_trans_blocks(inode, lblocks, pextents);\n\n\tret = idxblocks;\n\n\t \n\tgroups = idxblocks + pextents;\n\tgdpblocks = groups;\n\tif (groups > ngroups)\n\t\tgroups = ngroups;\n\tif (groups > EXT4_SB(inode->i_sb)->s_gdb_count)\n\t\tgdpblocks = EXT4_SB(inode->i_sb)->s_gdb_count;\n\n\t \n\tret += groups + gdpblocks;\n\n\t \n\tret += EXT4_META_TRANS_BLOCKS(inode->i_sb);\n\n\treturn ret;\n}\n\n \nint ext4_writepage_trans_blocks(struct inode *inode)\n{\n\tint bpp = ext4_journal_blocks_per_page(inode);\n\tint ret;\n\n\tret = ext4_meta_trans_blocks(inode, bpp, bpp);\n\n\t \n\tif (ext4_should_journal_data(inode))\n\t\tret += bpp;\n\treturn ret;\n}\n\n \nint ext4_chunk_trans_blocks(struct inode *inode, int nrblocks)\n{\n\treturn ext4_meta_trans_blocks(inode, nrblocks, 1);\n}\n\n \nint ext4_mark_iloc_dirty(handle_t *handle,\n\t\t\t struct inode *inode, struct ext4_iloc *iloc)\n{\n\tint err = 0;\n\n\tif (unlikely(ext4_forced_shutdown(inode->i_sb))) {\n\t\tput_bh(iloc->bh);\n\t\treturn -EIO;\n\t}\n\text4_fc_track_inode(handle, inode);\n\n\t \n\tget_bh(iloc->bh);\n\n\t \n\terr = ext4_do_update_inode(handle, inode, iloc);\n\tput_bh(iloc->bh);\n\treturn err;\n}\n\n \n\nint\next4_reserve_inode_write(handle_t *handle, struct inode *inode,\n\t\t\t struct ext4_iloc *iloc)\n{\n\tint err;\n\n\tif (unlikely(ext4_forced_shutdown(inode->i_sb)))\n\t\treturn -EIO;\n\n\terr = ext4_get_inode_loc(inode, iloc);\n\tif (!err) {\n\t\tBUFFER_TRACE(iloc->bh, \"get_write_access\");\n\t\terr = ext4_journal_get_write_access(handle, inode->i_sb,\n\t\t\t\t\t\t    iloc->bh, EXT4_JTR_NONE);\n\t\tif (err) {\n\t\t\tbrelse(iloc->bh);\n\t\t\tiloc->bh = NULL;\n\t\t}\n\t}\n\text4_std_error(inode->i_sb, err);\n\treturn err;\n}\n\nstatic int __ext4_expand_extra_isize(struct inode *inode,\n\t\t\t\t     unsigned int new_extra_isize,\n\t\t\t\t     struct ext4_iloc *iloc,\n\t\t\t\t     handle_t *handle, int *no_expand)\n{\n\tstruct ext4_inode *raw_inode;\n\tstruct ext4_xattr_ibody_header *header;\n\tunsigned int inode_size = EXT4_INODE_SIZE(inode->i_sb);\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tint error;\n\n\t \n\tif ((EXT4_GOOD_OLD_INODE_SIZE + ei->i_extra_isize > inode_size) ||\n\t    (ei->i_extra_isize & 3)) {\n\t\tEXT4_ERROR_INODE(inode, \"bad extra_isize %u (inode size %u)\",\n\t\t\t\t ei->i_extra_isize,\n\t\t\t\t EXT4_INODE_SIZE(inode->i_sb));\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif ((new_extra_isize < ei->i_extra_isize) ||\n\t    (new_extra_isize < 4) ||\n\t    (new_extra_isize > inode_size - EXT4_GOOD_OLD_INODE_SIZE))\n\t\treturn -EINVAL;\t \n\n\traw_inode = ext4_raw_inode(iloc);\n\n\theader = IHDR(inode, raw_inode);\n\n\t \n\tif (!ext4_test_inode_state(inode, EXT4_STATE_XATTR) ||\n\t    header->h_magic != cpu_to_le32(EXT4_XATTR_MAGIC)) {\n\t\tmemset((void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE +\n\t\t       EXT4_I(inode)->i_extra_isize, 0,\n\t\t       new_extra_isize - EXT4_I(inode)->i_extra_isize);\n\t\tEXT4_I(inode)->i_extra_isize = new_extra_isize;\n\t\treturn 0;\n\t}\n\n\t \n\tif (dquot_initialize_needed(inode))\n\t\treturn -EAGAIN;\n\n\t \n\terror = ext4_expand_extra_isize_ea(inode, new_extra_isize,\n\t\t\t\t\t   raw_inode, handle);\n\tif (error) {\n\t\t \n\t\t*no_expand = 1;\n\t}\n\n\treturn error;\n}\n\n \nstatic int ext4_try_to_expand_extra_isize(struct inode *inode,\n\t\t\t\t\t  unsigned int new_extra_isize,\n\t\t\t\t\t  struct ext4_iloc iloc,\n\t\t\t\t\t  handle_t *handle)\n{\n\tint no_expand;\n\tint error;\n\n\tif (ext4_test_inode_state(inode, EXT4_STATE_NO_EXPAND))\n\t\treturn -EOVERFLOW;\n\n\t \n\tif (ext4_journal_extend(handle,\n\t\t\t\tEXT4_DATA_TRANS_BLOCKS(inode->i_sb), 0) != 0)\n\t\treturn -ENOSPC;\n\n\tif (ext4_write_trylock_xattr(inode, &no_expand) == 0)\n\t\treturn -EBUSY;\n\n\terror = __ext4_expand_extra_isize(inode, new_extra_isize, &iloc,\n\t\t\t\t\t  handle, &no_expand);\n\text4_write_unlock_xattr(inode, &no_expand);\n\n\treturn error;\n}\n\nint ext4_expand_extra_isize(struct inode *inode,\n\t\t\t    unsigned int new_extra_isize,\n\t\t\t    struct ext4_iloc *iloc)\n{\n\thandle_t *handle;\n\tint no_expand;\n\tint error, rc;\n\n\tif (ext4_test_inode_state(inode, EXT4_STATE_NO_EXPAND)) {\n\t\tbrelse(iloc->bh);\n\t\treturn -EOVERFLOW;\n\t}\n\n\thandle = ext4_journal_start(inode, EXT4_HT_INODE,\n\t\t\t\t    EXT4_DATA_TRANS_BLOCKS(inode->i_sb));\n\tif (IS_ERR(handle)) {\n\t\terror = PTR_ERR(handle);\n\t\tbrelse(iloc->bh);\n\t\treturn error;\n\t}\n\n\text4_write_lock_xattr(inode, &no_expand);\n\n\tBUFFER_TRACE(iloc->bh, \"get_write_access\");\n\terror = ext4_journal_get_write_access(handle, inode->i_sb, iloc->bh,\n\t\t\t\t\t      EXT4_JTR_NONE);\n\tif (error) {\n\t\tbrelse(iloc->bh);\n\t\tgoto out_unlock;\n\t}\n\n\terror = __ext4_expand_extra_isize(inode, new_extra_isize, iloc,\n\t\t\t\t\t  handle, &no_expand);\n\n\trc = ext4_mark_iloc_dirty(handle, inode, iloc);\n\tif (!error)\n\t\terror = rc;\n\nout_unlock:\n\text4_write_unlock_xattr(inode, &no_expand);\n\text4_journal_stop(handle);\n\treturn error;\n}\n\n \nint __ext4_mark_inode_dirty(handle_t *handle, struct inode *inode,\n\t\t\t\tconst char *func, unsigned int line)\n{\n\tstruct ext4_iloc iloc;\n\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\tint err;\n\n\tmight_sleep();\n\ttrace_ext4_mark_inode_dirty(inode, _RET_IP_);\n\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\tif (err)\n\t\tgoto out;\n\n\tif (EXT4_I(inode)->i_extra_isize < sbi->s_want_extra_isize)\n\t\text4_try_to_expand_extra_isize(inode, sbi->s_want_extra_isize,\n\t\t\t\t\t       iloc, handle);\n\n\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\nout:\n\tif (unlikely(err))\n\t\text4_error_inode_err(inode, func, line, 0, err,\n\t\t\t\t\t\"mark_inode_dirty error\");\n\treturn err;\n}\n\n \nvoid ext4_dirty_inode(struct inode *inode, int flags)\n{\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(inode, EXT4_HT_INODE, 2);\n\tif (IS_ERR(handle))\n\t\treturn;\n\text4_mark_inode_dirty(handle, inode);\n\text4_journal_stop(handle);\n}\n\nint ext4_change_inode_journal_flag(struct inode *inode, int val)\n{\n\tjournal_t *journal;\n\thandle_t *handle;\n\tint err;\n\tint alloc_ctx;\n\n\t \n\n\tjournal = EXT4_JOURNAL(inode);\n\tif (!journal)\n\t\treturn 0;\n\tif (is_journal_aborted(journal))\n\t\treturn -EROFS;\n\n\t \n\tinode_dio_wait(inode);\n\n\t \n\tif (val) {\n\t\tfilemap_invalidate_lock(inode->i_mapping);\n\t\terr = filemap_write_and_wait(inode->i_mapping);\n\t\tif (err < 0) {\n\t\t\tfilemap_invalidate_unlock(inode->i_mapping);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\talloc_ctx = ext4_writepages_down_write(inode->i_sb);\n\tjbd2_journal_lock_updates(journal);\n\n\t \n\n\tif (val)\n\t\text4_set_inode_flag(inode, EXT4_INODE_JOURNAL_DATA);\n\telse {\n\t\terr = jbd2_journal_flush(journal, 0);\n\t\tif (err < 0) {\n\t\t\tjbd2_journal_unlock_updates(journal);\n\t\t\text4_writepages_up_write(inode->i_sb, alloc_ctx);\n\t\t\treturn err;\n\t\t}\n\t\text4_clear_inode_flag(inode, EXT4_INODE_JOURNAL_DATA);\n\t}\n\text4_set_aops(inode);\n\n\tjbd2_journal_unlock_updates(journal);\n\text4_writepages_up_write(inode->i_sb, alloc_ctx);\n\n\tif (val)\n\t\tfilemap_invalidate_unlock(inode->i_mapping);\n\n\t \n\n\thandle = ext4_journal_start(inode, EXT4_HT_INODE, 1);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\n\text4_fc_mark_ineligible(inode->i_sb,\n\t\tEXT4_FC_REASON_JOURNAL_FLAG_CHANGE, handle);\n\terr = ext4_mark_inode_dirty(handle, inode);\n\text4_handle_sync(handle);\n\text4_journal_stop(handle);\n\text4_std_error(inode->i_sb, err);\n\n\treturn err;\n}\n\nstatic int ext4_bh_unmapped(handle_t *handle, struct inode *inode,\n\t\t\t    struct buffer_head *bh)\n{\n\treturn !buffer_mapped(bh);\n}\n\nvm_fault_t ext4_page_mkwrite(struct vm_fault *vmf)\n{\n\tstruct vm_area_struct *vma = vmf->vma;\n\tstruct folio *folio = page_folio(vmf->page);\n\tloff_t size;\n\tunsigned long len;\n\tint err;\n\tvm_fault_t ret;\n\tstruct file *file = vma->vm_file;\n\tstruct inode *inode = file_inode(file);\n\tstruct address_space *mapping = inode->i_mapping;\n\thandle_t *handle;\n\tget_block_t *get_block;\n\tint retries = 0;\n\n\tif (unlikely(IS_IMMUTABLE(inode)))\n\t\treturn VM_FAULT_SIGBUS;\n\n\tsb_start_pagefault(inode->i_sb);\n\tfile_update_time(vma->vm_file);\n\n\tfilemap_invalidate_lock_shared(mapping);\n\n\terr = ext4_convert_inline_data(inode);\n\tif (err)\n\t\tgoto out_ret;\n\n\t \n\tif (ext4_should_journal_data(inode))\n\t\tgoto retry_alloc;\n\n\t \n\tif (test_opt(inode->i_sb, DELALLOC) &&\n\t    !ext4_nonda_switch(inode->i_sb)) {\n\t\tdo {\n\t\t\terr = block_page_mkwrite(vma, vmf,\n\t\t\t\t\t\t   ext4_da_get_block_prep);\n\t\t} while (err == -ENOSPC &&\n\t\t       ext4_should_retry_alloc(inode->i_sb, &retries));\n\t\tgoto out_ret;\n\t}\n\n\tfolio_lock(folio);\n\tsize = i_size_read(inode);\n\t \n\tif (folio->mapping != mapping || folio_pos(folio) > size) {\n\t\tfolio_unlock(folio);\n\t\tret = VM_FAULT_NOPAGE;\n\t\tgoto out;\n\t}\n\n\tlen = folio_size(folio);\n\tif (folio_pos(folio) + len > size)\n\t\tlen = size - folio_pos(folio);\n\t \n\tif (folio_buffers(folio)) {\n\t\tif (!ext4_walk_page_buffers(NULL, inode, folio_buffers(folio),\n\t\t\t\t\t    0, len, NULL,\n\t\t\t\t\t    ext4_bh_unmapped)) {\n\t\t\t \n\t\t\tfolio_wait_stable(folio);\n\t\t\tret = VM_FAULT_LOCKED;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tfolio_unlock(folio);\n\t \n\tif (ext4_should_dioread_nolock(inode))\n\t\tget_block = ext4_get_block_unwritten;\n\telse\n\t\tget_block = ext4_get_block;\nretry_alloc:\n\thandle = ext4_journal_start(inode, EXT4_HT_WRITE_PAGE,\n\t\t\t\t    ext4_writepage_trans_blocks(inode));\n\tif (IS_ERR(handle)) {\n\t\tret = VM_FAULT_SIGBUS;\n\t\tgoto out;\n\t}\n\t \n\tif (!ext4_should_journal_data(inode)) {\n\t\terr = block_page_mkwrite(vma, vmf, get_block);\n\t} else {\n\t\tfolio_lock(folio);\n\t\tsize = i_size_read(inode);\n\t\t \n\t\tif (folio->mapping != mapping || folio_pos(folio) > size) {\n\t\t\tret = VM_FAULT_NOPAGE;\n\t\t\tgoto out_error;\n\t\t}\n\n\t\tlen = folio_size(folio);\n\t\tif (folio_pos(folio) + len > size)\n\t\t\tlen = size - folio_pos(folio);\n\n\t\terr = __block_write_begin(&folio->page, 0, len, ext4_get_block);\n\t\tif (!err) {\n\t\t\tret = VM_FAULT_SIGBUS;\n\t\t\tif (ext4_journal_folio_buffers(handle, folio, len))\n\t\t\t\tgoto out_error;\n\t\t} else {\n\t\t\tfolio_unlock(folio);\n\t\t}\n\t}\n\text4_journal_stop(handle);\n\tif (err == -ENOSPC && ext4_should_retry_alloc(inode->i_sb, &retries))\n\t\tgoto retry_alloc;\nout_ret:\n\tret = vmf_fs_error(err);\nout:\n\tfilemap_invalidate_unlock_shared(mapping);\n\tsb_end_pagefault(inode->i_sb);\n\treturn ret;\nout_error:\n\tfolio_unlock(folio);\n\text4_journal_stop(handle);\n\tgoto out;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}