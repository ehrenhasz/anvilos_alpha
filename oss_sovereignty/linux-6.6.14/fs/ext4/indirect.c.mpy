{
  "module_name": "indirect.c",
  "hash_id": "cd2f1c709455b72dfd583e002c089f1804ca7393021adb7e8da1cc9c1834441c",
  "original_prompt": "Ingested from linux-6.6.14/fs/ext4/indirect.c",
  "human_readable_source": "\n \n\n#include \"ext4_jbd2.h\"\n#include \"truncate.h\"\n#include <linux/dax.h>\n#include <linux/uio.h>\n\n#include <trace/events/ext4.h>\n\ntypedef struct {\n\t__le32\t*p;\n\t__le32\tkey;\n\tstruct buffer_head *bh;\n} Indirect;\n\nstatic inline void add_chain(Indirect *p, struct buffer_head *bh, __le32 *v)\n{\n\tp->key = *(p->p = v);\n\tp->bh = bh;\n}\n\n \n\n \n\nstatic int ext4_block_to_path(struct inode *inode,\n\t\t\t      ext4_lblk_t i_block,\n\t\t\t      ext4_lblk_t offsets[4], int *boundary)\n{\n\tint ptrs = EXT4_ADDR_PER_BLOCK(inode->i_sb);\n\tint ptrs_bits = EXT4_ADDR_PER_BLOCK_BITS(inode->i_sb);\n\tconst long direct_blocks = EXT4_NDIR_BLOCKS,\n\t\tindirect_blocks = ptrs,\n\t\tdouble_blocks = (1 << (ptrs_bits * 2));\n\tint n = 0;\n\tint final = 0;\n\n\tif (i_block < direct_blocks) {\n\t\toffsets[n++] = i_block;\n\t\tfinal = direct_blocks;\n\t} else if ((i_block -= direct_blocks) < indirect_blocks) {\n\t\toffsets[n++] = EXT4_IND_BLOCK;\n\t\toffsets[n++] = i_block;\n\t\tfinal = ptrs;\n\t} else if ((i_block -= indirect_blocks) < double_blocks) {\n\t\toffsets[n++] = EXT4_DIND_BLOCK;\n\t\toffsets[n++] = i_block >> ptrs_bits;\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else if (((i_block -= double_blocks) >> (ptrs_bits * 2)) < ptrs) {\n\t\toffsets[n++] = EXT4_TIND_BLOCK;\n\t\toffsets[n++] = i_block >> (ptrs_bits * 2);\n\t\toffsets[n++] = (i_block >> ptrs_bits) & (ptrs - 1);\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else {\n\t\text4_warning(inode->i_sb, \"block %lu > max in inode %lu\",\n\t\t\t     i_block + direct_blocks +\n\t\t\t     indirect_blocks + double_blocks, inode->i_ino);\n\t}\n\tif (boundary)\n\t\t*boundary = final - 1 - (i_block & (ptrs - 1));\n\treturn n;\n}\n\n \nstatic Indirect *ext4_get_branch(struct inode *inode, int depth,\n\t\t\t\t ext4_lblk_t  *offsets,\n\t\t\t\t Indirect chain[4], int *err)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tIndirect *p = chain;\n\tstruct buffer_head *bh;\n\tunsigned int key;\n\tint ret = -EIO;\n\n\t*err = 0;\n\t \n\tadd_chain(chain, NULL, EXT4_I(inode)->i_data + *offsets);\n\tif (!p->key)\n\t\tgoto no_block;\n\twhile (--depth) {\n\t\tkey = le32_to_cpu(p->key);\n\t\tif (key > ext4_blocks_count(EXT4_SB(sb)->s_es)) {\n\t\t\t \n\t\t\tret = -EFSCORRUPTED;\n\t\t\tgoto failure;\n\t\t}\n\t\tbh = sb_getblk(sb, key);\n\t\tif (unlikely(!bh)) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto failure;\n\t\t}\n\n\t\tif (!bh_uptodate_or_lock(bh)) {\n\t\t\tif (ext4_read_bh(bh, 0, NULL) < 0) {\n\t\t\t\tput_bh(bh);\n\t\t\t\tgoto failure;\n\t\t\t}\n\t\t\t \n\t\t\tif (ext4_check_indirect_blockref(inode, bh)) {\n\t\t\t\tput_bh(bh);\n\t\t\t\tgoto failure;\n\t\t\t}\n\t\t}\n\n\t\tadd_chain(++p, bh, (__le32 *)bh->b_data + *++offsets);\n\t\t \n\t\tif (!p->key)\n\t\t\tgoto no_block;\n\t}\n\treturn NULL;\n\nfailure:\n\t*err = ret;\nno_block:\n\treturn p;\n}\n\n \nstatic ext4_fsblk_t ext4_find_near(struct inode *inode, Indirect *ind)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\t__le32 *start = ind->bh ? (__le32 *) ind->bh->b_data : ei->i_data;\n\t__le32 *p;\n\n\t \n\tfor (p = ind->p - 1; p >= start; p--) {\n\t\tif (*p)\n\t\t\treturn le32_to_cpu(*p);\n\t}\n\n\t \n\tif (ind->bh)\n\t\treturn ind->bh->b_blocknr;\n\n\t \n\treturn ext4_inode_to_goal_block(inode);\n}\n\n \nstatic ext4_fsblk_t ext4_find_goal(struct inode *inode, ext4_lblk_t block,\n\t\t\t\t   Indirect *partial)\n{\n\text4_fsblk_t goal;\n\n\t \n\n\tgoal = ext4_find_near(inode, partial);\n\tgoal = goal & EXT4_MAX_BLOCK_FILE_PHYS;\n\treturn goal;\n}\n\n \nstatic int ext4_blks_to_allocate(Indirect *branch, int k, unsigned int blks,\n\t\t\t\t int blocks_to_boundary)\n{\n\tunsigned int count = 0;\n\n\t \n\tif (k > 0) {\n\t\t \n\t\tif (blks < blocks_to_boundary + 1)\n\t\t\tcount += blks;\n\t\telse\n\t\t\tcount += blocks_to_boundary + 1;\n\t\treturn count;\n\t}\n\n\tcount++;\n\twhile (count < blks && count <= blocks_to_boundary &&\n\t\tle32_to_cpu(*(branch[0].p + count)) == 0) {\n\t\tcount++;\n\t}\n\treturn count;\n}\n\n \nstatic int ext4_alloc_branch(handle_t *handle,\n\t\t\t     struct ext4_allocation_request *ar,\n\t\t\t     int indirect_blks, ext4_lblk_t *offsets,\n\t\t\t     Indirect *branch)\n{\n\tstruct buffer_head *\t\tbh;\n\text4_fsblk_t\t\t\tb, new_blocks[4];\n\t__le32\t\t\t\t*p;\n\tint\t\t\t\ti, j, err, len = 1;\n\n\tfor (i = 0; i <= indirect_blks; i++) {\n\t\tif (i == indirect_blks) {\n\t\t\tnew_blocks[i] = ext4_mb_new_blocks(handle, ar, &err);\n\t\t} else {\n\t\t\tar->goal = new_blocks[i] = ext4_new_meta_blocks(handle,\n\t\t\t\t\tar->inode, ar->goal,\n\t\t\t\t\tar->flags & EXT4_MB_DELALLOC_RESERVED,\n\t\t\t\t\tNULL, &err);\n\t\t\t \n\t\t\tbranch[i+1].bh = NULL;\n\t\t}\n\t\tif (err) {\n\t\t\ti--;\n\t\t\tgoto failed;\n\t\t}\n\t\tbranch[i].key = cpu_to_le32(new_blocks[i]);\n\t\tif (i == 0)\n\t\t\tcontinue;\n\n\t\tbh = branch[i].bh = sb_getblk(ar->inode->i_sb, new_blocks[i-1]);\n\t\tif (unlikely(!bh)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto failed;\n\t\t}\n\t\tlock_buffer(bh);\n\t\tBUFFER_TRACE(bh, \"call get_create_access\");\n\t\terr = ext4_journal_get_create_access(handle, ar->inode->i_sb,\n\t\t\t\t\t\t     bh, EXT4_JTR_NONE);\n\t\tif (err) {\n\t\t\tunlock_buffer(bh);\n\t\t\tgoto failed;\n\t\t}\n\n\t\tmemset(bh->b_data, 0, bh->b_size);\n\t\tp = branch[i].p = (__le32 *) bh->b_data + offsets[i];\n\t\tb = new_blocks[i];\n\n\t\tif (i == indirect_blks)\n\t\t\tlen = ar->len;\n\t\tfor (j = 0; j < len; j++)\n\t\t\t*p++ = cpu_to_le32(b++);\n\n\t\tBUFFER_TRACE(bh, \"marking uptodate\");\n\t\tset_buffer_uptodate(bh);\n\t\tunlock_buffer(bh);\n\n\t\tBUFFER_TRACE(bh, \"call ext4_handle_dirty_metadata\");\n\t\terr = ext4_handle_dirty_metadata(handle, ar->inode, bh);\n\t\tif (err)\n\t\t\tgoto failed;\n\t}\n\treturn 0;\nfailed:\n\tif (i == indirect_blks) {\n\t\t \n\t\text4_free_blocks(handle, ar->inode, NULL, new_blocks[i],\n\t\t\t\t ar->len, 0);\n\t\ti--;\n\t}\n\tfor (; i >= 0; i--) {\n\t\t \n\t\text4_free_blocks(handle, ar->inode, branch[i+1].bh,\n\t\t\t\t new_blocks[i], 1,\n\t\t\t\t branch[i+1].bh ? EXT4_FREE_BLOCKS_FORGET : 0);\n\t}\n\treturn err;\n}\n\n \nstatic int ext4_splice_branch(handle_t *handle,\n\t\t\t      struct ext4_allocation_request *ar,\n\t\t\t      Indirect *where, int num)\n{\n\tint i;\n\tint err = 0;\n\text4_fsblk_t current_block;\n\n\t \n\tif (where->bh) {\n\t\tBUFFER_TRACE(where->bh, \"get_write_access\");\n\t\terr = ext4_journal_get_write_access(handle, ar->inode->i_sb,\n\t\t\t\t\t\t    where->bh, EXT4_JTR_NONE);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t}\n\t \n\n\t*where->p = where->key;\n\n\t \n\tif (num == 0 && ar->len > 1) {\n\t\tcurrent_block = le32_to_cpu(where->key) + 1;\n\t\tfor (i = 1; i < ar->len; i++)\n\t\t\t*(where->p + i) = cpu_to_le32(current_block++);\n\t}\n\n\t \n\t \n\tif (where->bh) {\n\t\t \n\t\text4_debug(\"splicing indirect only\\n\");\n\t\tBUFFER_TRACE(where->bh, \"call ext4_handle_dirty_metadata\");\n\t\terr = ext4_handle_dirty_metadata(handle, ar->inode, where->bh);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t} else {\n\t\t \n\t\terr = ext4_mark_inode_dirty(handle, ar->inode);\n\t\tif (unlikely(err))\n\t\t\tgoto err_out;\n\t\text4_debug(\"splicing direct\\n\");\n\t}\n\treturn err;\n\nerr_out:\n\tfor (i = 1; i <= num; i++) {\n\t\t \n\t\text4_free_blocks(handle, ar->inode, where[i].bh, 0, 1,\n\t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n\t}\n\text4_free_blocks(handle, ar->inode, NULL, le32_to_cpu(where[num].key),\n\t\t\t ar->len, 0);\n\n\treturn err;\n}\n\n \nint ext4_ind_map_blocks(handle_t *handle, struct inode *inode,\n\t\t\tstruct ext4_map_blocks *map,\n\t\t\tint flags)\n{\n\tstruct ext4_allocation_request ar;\n\tint err = -EIO;\n\text4_lblk_t offsets[4];\n\tIndirect chain[4];\n\tIndirect *partial;\n\tint indirect_blks;\n\tint blocks_to_boundary = 0;\n\tint depth;\n\tint count = 0;\n\text4_fsblk_t first_block = 0;\n\n\ttrace_ext4_ind_map_blocks_enter(inode, map->m_lblk, map->m_len, flags);\n\tASSERT(!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)));\n\tASSERT(handle != NULL || (flags & EXT4_GET_BLOCKS_CREATE) == 0);\n\tdepth = ext4_block_to_path(inode, map->m_lblk, offsets,\n\t\t\t\t   &blocks_to_boundary);\n\n\tif (depth == 0)\n\t\tgoto out;\n\n\tpartial = ext4_get_branch(inode, depth, offsets, chain, &err);\n\n\t \n\tif (!partial) {\n\t\tfirst_block = le32_to_cpu(chain[depth - 1].key);\n\t\tcount++;\n\t\t \n\t\twhile (count < map->m_len && count <= blocks_to_boundary) {\n\t\t\text4_fsblk_t blk;\n\n\t\t\tblk = le32_to_cpu(*(chain[depth-1].p + count));\n\n\t\t\tif (blk == first_block + count)\n\t\t\t\tcount++;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\tgoto got_it;\n\t}\n\n\t \n\tif ((flags & EXT4_GET_BLOCKS_CREATE) == 0) {\n\t\tunsigned epb = inode->i_sb->s_blocksize / sizeof(u32);\n\t\tint i;\n\n\t\t \n\t\tcount = 0;\n\t\tfor (i = partial - chain + 1; i < depth; i++)\n\t\t\tcount = count * epb + (epb - offsets[i] - 1);\n\t\tcount++;\n\t\t \n\t\tmap->m_pblk = 0;\n\t\tmap->m_len = min_t(unsigned int, map->m_len, count);\n\t\tgoto cleanup;\n\t}\n\n\t \n\tif (err == -EIO)\n\t\tgoto cleanup;\n\n\t \n\tif (ext4_has_feature_bigalloc(inode->i_sb)) {\n\t\tEXT4_ERROR_INODE(inode, \"Can't allocate blocks for \"\n\t\t\t\t \"non-extent mapped inodes with bigalloc\");\n\t\terr = -EFSCORRUPTED;\n\t\tgoto out;\n\t}\n\n\t \n\tmemset(&ar, 0, sizeof(ar));\n\tar.inode = inode;\n\tar.logical = map->m_lblk;\n\tif (S_ISREG(inode->i_mode))\n\t\tar.flags = EXT4_MB_HINT_DATA;\n\tif (flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE)\n\t\tar.flags |= EXT4_MB_DELALLOC_RESERVED;\n\tif (flags & EXT4_GET_BLOCKS_METADATA_NOFAIL)\n\t\tar.flags |= EXT4_MB_USE_RESERVED;\n\n\tar.goal = ext4_find_goal(inode, map->m_lblk, partial);\n\n\t \n\tindirect_blks = (chain + depth) - partial - 1;\n\n\t \n\tar.len = ext4_blks_to_allocate(partial, indirect_blks,\n\t\t\t\t       map->m_len, blocks_to_boundary);\n\n\t \n\terr = ext4_alloc_branch(handle, &ar, indirect_blks,\n\t\t\t\toffsets + (partial - chain), partial);\n\n\t \n\tif (!err)\n\t\terr = ext4_splice_branch(handle, &ar, partial, indirect_blks);\n\tif (err)\n\t\tgoto cleanup;\n\n\tmap->m_flags |= EXT4_MAP_NEW;\n\n\text4_update_inode_fsync_trans(handle, inode, 1);\n\tcount = ar.len;\n\n\t \n\tif (flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE)\n\t\text4_da_update_reserve_space(inode, count, 1);\n\ngot_it:\n\tmap->m_flags |= EXT4_MAP_MAPPED;\n\tmap->m_pblk = le32_to_cpu(chain[depth-1].key);\n\tmap->m_len = count;\n\tif (count > blocks_to_boundary)\n\t\tmap->m_flags |= EXT4_MAP_BOUNDARY;\n\terr = count;\n\t \n\tpartial = chain + depth - 1;\t \ncleanup:\n\twhile (partial > chain) {\n\t\tBUFFER_TRACE(partial->bh, \"call brelse\");\n\t\tbrelse(partial->bh);\n\t\tpartial--;\n\t}\nout:\n\ttrace_ext4_ind_map_blocks_exit(inode, flags, map, err);\n\treturn err;\n}\n\n \nint ext4_ind_trans_blocks(struct inode *inode, int nrblocks)\n{\n\t \n\treturn DIV_ROUND_UP(nrblocks, EXT4_ADDR_PER_BLOCK(inode->i_sb)) + 4;\n}\n\nstatic int ext4_ind_trunc_restart_fn(handle_t *handle, struct inode *inode,\n\t\t\t\t     struct buffer_head *bh, int *dropped)\n{\n\tint err;\n\n\tif (bh) {\n\t\tBUFFER_TRACE(bh, \"call ext4_handle_dirty_metadata\");\n\t\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\t\tif (unlikely(err))\n\t\t\treturn err;\n\t}\n\terr = ext4_mark_inode_dirty(handle, inode);\n\tif (unlikely(err))\n\t\treturn err;\n\t \n\tBUG_ON(EXT4_JOURNAL(inode) == NULL);\n\text4_discard_preallocations(inode, 0);\n\tup_write(&EXT4_I(inode)->i_data_sem);\n\t*dropped = 1;\n\treturn 0;\n}\n\n \nstatic int ext4_ind_truncate_ensure_credits(handle_t *handle,\n\t\t\t\t\t    struct inode *inode,\n\t\t\t\t\t    struct buffer_head *bh,\n\t\t\t\t\t    int revoke_creds)\n{\n\tint ret;\n\tint dropped = 0;\n\n\tret = ext4_journal_ensure_credits_fn(handle, EXT4_RESERVE_TRANS_BLOCKS,\n\t\t\text4_blocks_for_truncate(inode), revoke_creds,\n\t\t\text4_ind_trunc_restart_fn(handle, inode, bh, &dropped));\n\tif (dropped)\n\t\tdown_write(&EXT4_I(inode)->i_data_sem);\n\tif (ret <= 0)\n\t\treturn ret;\n\tif (bh) {\n\t\tBUFFER_TRACE(bh, \"retaking write access\");\n\t\tret = ext4_journal_get_write_access(handle, inode->i_sb, bh,\n\t\t\t\t\t\t    EXT4_JTR_NONE);\n\t\tif (unlikely(ret))\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\n \nstatic inline int all_zeroes(__le32 *p, __le32 *q)\n{\n\twhile (p < q)\n\t\tif (*p++)\n\t\t\treturn 0;\n\treturn 1;\n}\n\n \n\nstatic Indirect *ext4_find_shared(struct inode *inode, int depth,\n\t\t\t\t  ext4_lblk_t offsets[4], Indirect chain[4],\n\t\t\t\t  __le32 *top)\n{\n\tIndirect *partial, *p;\n\tint k, err;\n\n\t*top = 0;\n\t \n\tfor (k = depth; k > 1 && !offsets[k-1]; k--)\n\t\t;\n\tpartial = ext4_get_branch(inode, k, offsets, chain, &err);\n\t \n\tif (!partial)\n\t\tpartial = chain + k-1;\n\t \n\tif (!partial->key && *partial->p)\n\t\t \n\t\tgoto no_top;\n\tfor (p = partial; (p > chain) && all_zeroes((__le32 *) p->bh->b_data, p->p); p--)\n\t\t;\n\t \n\tif (p == chain + k - 1 && p > chain) {\n\t\tp->p--;\n\t} else {\n\t\t*top = *p->p;\n\t\t \n#if 0\n\t\t*p->p = 0;\n#endif\n\t}\n\t \n\n\twhile (partial > p) {\n\t\tbrelse(partial->bh);\n\t\tpartial--;\n\t}\nno_top:\n\treturn partial;\n}\n\n \nstatic int ext4_clear_blocks(handle_t *handle, struct inode *inode,\n\t\t\t     struct buffer_head *bh,\n\t\t\t     ext4_fsblk_t block_to_free,\n\t\t\t     unsigned long count, __le32 *first,\n\t\t\t     __le32 *last)\n{\n\t__le32 *p;\n\tint\tflags = EXT4_FREE_BLOCKS_VALIDATED;\n\tint\terr;\n\n\tif (S_ISDIR(inode->i_mode) || S_ISLNK(inode->i_mode) ||\n\t    ext4_test_inode_flag(inode, EXT4_INODE_EA_INODE))\n\t\tflags |= EXT4_FREE_BLOCKS_FORGET | EXT4_FREE_BLOCKS_METADATA;\n\telse if (ext4_should_journal_data(inode))\n\t\tflags |= EXT4_FREE_BLOCKS_FORGET;\n\n\tif (!ext4_inode_block_valid(inode, block_to_free, count)) {\n\t\tEXT4_ERROR_INODE(inode, \"attempt to clear invalid \"\n\t\t\t\t \"blocks %llu len %lu\",\n\t\t\t\t (unsigned long long) block_to_free, count);\n\t\treturn 1;\n\t}\n\n\terr = ext4_ind_truncate_ensure_credits(handle, inode, bh,\n\t\t\t\text4_free_data_revoke_credits(inode, count));\n\tif (err < 0)\n\t\tgoto out_err;\n\n\tfor (p = first; p < last; p++)\n\t\t*p = 0;\n\n\text4_free_blocks(handle, inode, NULL, block_to_free, count, flags);\n\treturn 0;\nout_err:\n\text4_std_error(inode->i_sb, err);\n\treturn err;\n}\n\n \nstatic void ext4_free_data(handle_t *handle, struct inode *inode,\n\t\t\t   struct buffer_head *this_bh,\n\t\t\t   __le32 *first, __le32 *last)\n{\n\text4_fsblk_t block_to_free = 0;     \n\tunsigned long count = 0;\t     \n\t__le32 *block_to_free_p = NULL;\t     \n\text4_fsblk_t nr;\t\t     \n\t__le32 *p;\t\t\t     \n\tint err = 0;\n\n\tif (this_bh) {\t\t\t\t \n\t\tBUFFER_TRACE(this_bh, \"get_write_access\");\n\t\terr = ext4_journal_get_write_access(handle, inode->i_sb,\n\t\t\t\t\t\t    this_bh, EXT4_JTR_NONE);\n\t\t \n\t\tif (err)\n\t\t\treturn;\n\t}\n\n\tfor (p = first; p < last; p++) {\n\t\tnr = le32_to_cpu(*p);\n\t\tif (nr) {\n\t\t\t \n\t\t\tif (count == 0) {\n\t\t\t\tblock_to_free = nr;\n\t\t\t\tblock_to_free_p = p;\n\t\t\t\tcount = 1;\n\t\t\t} else if (nr == block_to_free + count) {\n\t\t\t\tcount++;\n\t\t\t} else {\n\t\t\t\terr = ext4_clear_blocks(handle, inode, this_bh,\n\t\t\t\t\t\t        block_to_free, count,\n\t\t\t\t\t\t        block_to_free_p, p);\n\t\t\t\tif (err)\n\t\t\t\t\tbreak;\n\t\t\t\tblock_to_free = nr;\n\t\t\t\tblock_to_free_p = p;\n\t\t\t\tcount = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!err && count > 0)\n\t\terr = ext4_clear_blocks(handle, inode, this_bh, block_to_free,\n\t\t\t\t\tcount, block_to_free_p, p);\n\tif (err < 0)\n\t\t \n\t\treturn;\n\n\tif (this_bh) {\n\t\tBUFFER_TRACE(this_bh, \"call ext4_handle_dirty_metadata\");\n\n\t\t \n\t\tif ((EXT4_JOURNAL(inode) == NULL) || bh2jh(this_bh))\n\t\t\text4_handle_dirty_metadata(handle, inode, this_bh);\n\t\telse\n\t\t\tEXT4_ERROR_INODE(inode,\n\t\t\t\t\t \"circular indirect block detected at \"\n\t\t\t\t\t \"block %llu\",\n\t\t\t\t(unsigned long long) this_bh->b_blocknr);\n\t}\n}\n\n \nstatic void ext4_free_branches(handle_t *handle, struct inode *inode,\n\t\t\t       struct buffer_head *parent_bh,\n\t\t\t       __le32 *first, __le32 *last, int depth)\n{\n\text4_fsblk_t nr;\n\t__le32 *p;\n\n\tif (ext4_handle_is_aborted(handle))\n\t\treturn;\n\n\tif (depth--) {\n\t\tstruct buffer_head *bh;\n\t\tint addr_per_block = EXT4_ADDR_PER_BLOCK(inode->i_sb);\n\t\tp = last;\n\t\twhile (--p >= first) {\n\t\t\tnr = le32_to_cpu(*p);\n\t\t\tif (!nr)\n\t\t\t\tcontinue;\t\t \n\n\t\t\tif (!ext4_inode_block_valid(inode, nr, 1)) {\n\t\t\t\tEXT4_ERROR_INODE(inode,\n\t\t\t\t\t\t \"invalid indirect mapped \"\n\t\t\t\t\t\t \"block %lu (level %d)\",\n\t\t\t\t\t\t (unsigned long) nr, depth);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tbh = ext4_sb_bread(inode->i_sb, nr, 0);\n\n\t\t\t \n\t\t\tif (IS_ERR(bh)) {\n\t\t\t\text4_error_inode_block(inode, nr, -PTR_ERR(bh),\n\t\t\t\t\t\t       \"Read failure\");\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t \n\t\t\tBUFFER_TRACE(bh, \"free child branches\");\n\t\t\text4_free_branches(handle, inode, bh,\n\t\t\t\t\t(__le32 *) bh->b_data,\n\t\t\t\t\t(__le32 *) bh->b_data + addr_per_block,\n\t\t\t\t\tdepth);\n\t\t\tbrelse(bh);\n\n\t\t\t \n\t\t\tif (ext4_handle_is_aborted(handle))\n\t\t\t\treturn;\n\t\t\tif (ext4_ind_truncate_ensure_credits(handle, inode,\n\t\t\t\t\tNULL,\n\t\t\t\t\text4_free_metadata_revoke_credits(\n\t\t\t\t\t\t\tinode->i_sb, 1)) < 0)\n\t\t\t\treturn;\n\n\t\t\t \n\t\t\text4_free_blocks(handle, inode, NULL, nr, 1,\n\t\t\t\t\t EXT4_FREE_BLOCKS_METADATA|\n\t\t\t\t\t EXT4_FREE_BLOCKS_FORGET);\n\n\t\t\tif (parent_bh) {\n\t\t\t\t \n\t\t\t\tBUFFER_TRACE(parent_bh, \"get_write_access\");\n\t\t\t\tif (!ext4_journal_get_write_access(handle,\n\t\t\t\t\t\tinode->i_sb, parent_bh,\n\t\t\t\t\t\tEXT4_JTR_NONE)) {\n\t\t\t\t\t*p = 0;\n\t\t\t\t\tBUFFER_TRACE(parent_bh,\n\t\t\t\t\t\"call ext4_handle_dirty_metadata\");\n\t\t\t\t\text4_handle_dirty_metadata(handle,\n\t\t\t\t\t\t\t\t   inode,\n\t\t\t\t\t\t\t\t   parent_bh);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\t \n\t\tBUFFER_TRACE(parent_bh, \"free data blocks\");\n\t\text4_free_data(handle, inode, parent_bh, first, last);\n\t}\n}\n\nvoid ext4_ind_truncate(handle_t *handle, struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\t__le32 *i_data = ei->i_data;\n\tint addr_per_block = EXT4_ADDR_PER_BLOCK(inode->i_sb);\n\text4_lblk_t offsets[4];\n\tIndirect chain[4];\n\tIndirect *partial;\n\t__le32 nr = 0;\n\tint n = 0;\n\text4_lblk_t last_block, max_block;\n\tunsigned blocksize = inode->i_sb->s_blocksize;\n\n\tlast_block = (inode->i_size + blocksize-1)\n\t\t\t\t\t>> EXT4_BLOCK_SIZE_BITS(inode->i_sb);\n\tmax_block = (EXT4_SB(inode->i_sb)->s_bitmap_maxbytes + blocksize-1)\n\t\t\t\t\t>> EXT4_BLOCK_SIZE_BITS(inode->i_sb);\n\n\tif (last_block != max_block) {\n\t\tn = ext4_block_to_path(inode, last_block, offsets, NULL);\n\t\tif (n == 0)\n\t\t\treturn;\n\t}\n\n\text4_es_remove_extent(inode, last_block, EXT_MAX_BLOCKS - last_block);\n\n\t \n\tei->i_disksize = inode->i_size;\n\n\tif (last_block == max_block) {\n\t\t \n\t\treturn;\n\t} else if (n == 1) {\t\t \n\t\text4_free_data(handle, inode, NULL, i_data+offsets[0],\n\t\t\t       i_data + EXT4_NDIR_BLOCKS);\n\t\tgoto do_indirects;\n\t}\n\n\tpartial = ext4_find_shared(inode, n, offsets, chain, &nr);\n\t \n\tif (nr) {\n\t\tif (partial == chain) {\n\t\t\t \n\t\t\text4_free_branches(handle, inode, NULL,\n\t\t\t\t\t   &nr, &nr+1, (chain+n-1) - partial);\n\t\t\t*partial->p = 0;\n\t\t\t \n\t\t} else {\n\t\t\t \n\t\t\tBUFFER_TRACE(partial->bh, \"get_write_access\");\n\t\t\text4_free_branches(handle, inode, partial->bh,\n\t\t\t\t\tpartial->p,\n\t\t\t\t\tpartial->p+1, (chain+n-1) - partial);\n\t\t}\n\t}\n\t \n\twhile (partial > chain) {\n\t\text4_free_branches(handle, inode, partial->bh, partial->p + 1,\n\t\t\t\t   (__le32*)partial->bh->b_data+addr_per_block,\n\t\t\t\t   (chain+n-1) - partial);\n\t\tBUFFER_TRACE(partial->bh, \"call brelse\");\n\t\tbrelse(partial->bh);\n\t\tpartial--;\n\t}\ndo_indirects:\n\t \n\tswitch (offsets[0]) {\n\tdefault:\n\t\tnr = i_data[EXT4_IND_BLOCK];\n\t\tif (nr) {\n\t\t\text4_free_branches(handle, inode, NULL, &nr, &nr+1, 1);\n\t\t\ti_data[EXT4_IND_BLOCK] = 0;\n\t\t}\n\t\tfallthrough;\n\tcase EXT4_IND_BLOCK:\n\t\tnr = i_data[EXT4_DIND_BLOCK];\n\t\tif (nr) {\n\t\t\text4_free_branches(handle, inode, NULL, &nr, &nr+1, 2);\n\t\t\ti_data[EXT4_DIND_BLOCK] = 0;\n\t\t}\n\t\tfallthrough;\n\tcase EXT4_DIND_BLOCK:\n\t\tnr = i_data[EXT4_TIND_BLOCK];\n\t\tif (nr) {\n\t\t\text4_free_branches(handle, inode, NULL, &nr, &nr+1, 3);\n\t\t\ti_data[EXT4_TIND_BLOCK] = 0;\n\t\t}\n\t\tfallthrough;\n\tcase EXT4_TIND_BLOCK:\n\t\t;\n\t}\n}\n\n \nint ext4_ind_remove_space(handle_t *handle, struct inode *inode,\n\t\t\t  ext4_lblk_t start, ext4_lblk_t end)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\t__le32 *i_data = ei->i_data;\n\tint addr_per_block = EXT4_ADDR_PER_BLOCK(inode->i_sb);\n\text4_lblk_t offsets[4], offsets2[4];\n\tIndirect chain[4], chain2[4];\n\tIndirect *partial, *partial2;\n\tIndirect *p = NULL, *p2 = NULL;\n\text4_lblk_t max_block;\n\t__le32 nr = 0, nr2 = 0;\n\tint n = 0, n2 = 0;\n\tunsigned blocksize = inode->i_sb->s_blocksize;\n\n\tmax_block = (EXT4_SB(inode->i_sb)->s_bitmap_maxbytes + blocksize-1)\n\t\t\t\t\t>> EXT4_BLOCK_SIZE_BITS(inode->i_sb);\n\tif (end >= max_block)\n\t\tend = max_block;\n\tif ((start >= end) || (start > max_block))\n\t\treturn 0;\n\n\tn = ext4_block_to_path(inode, start, offsets, NULL);\n\tn2 = ext4_block_to_path(inode, end, offsets2, NULL);\n\n\tBUG_ON(n > n2);\n\n\tif ((n == 1) && (n == n2)) {\n\t\t \n\t\text4_free_data(handle, inode, NULL, i_data + offsets[0],\n\t\t\t       i_data + offsets2[0]);\n\t\treturn 0;\n\t} else if (n2 > n) {\n\t\t \n\n\t\tif (n == 1) {\n\t\t\t \n\t\t\text4_free_data(handle, inode, NULL, i_data + offsets[0],\n\t\t\t\t       i_data + EXT4_NDIR_BLOCKS);\n\t\t\tgoto end_range;\n\t\t}\n\n\n\t\tpartial = p = ext4_find_shared(inode, n, offsets, chain, &nr);\n\t\tif (nr) {\n\t\t\tif (partial == chain) {\n\t\t\t\t \n\t\t\t\text4_free_branches(handle, inode, NULL,\n\t\t\t\t\t   &nr, &nr+1, (chain+n-1) - partial);\n\t\t\t\t*partial->p = 0;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tBUFFER_TRACE(partial->bh, \"get_write_access\");\n\t\t\t\text4_free_branches(handle, inode, partial->bh,\n\t\t\t\t\tpartial->p,\n\t\t\t\t\tpartial->p+1, (chain+n-1) - partial);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\twhile (partial > chain) {\n\t\t\text4_free_branches(handle, inode, partial->bh,\n\t\t\t\tpartial->p + 1,\n\t\t\t\t(__le32 *)partial->bh->b_data+addr_per_block,\n\t\t\t\t(chain+n-1) - partial);\n\t\t\tpartial--;\n\t\t}\n\nend_range:\n\t\tpartial2 = p2 = ext4_find_shared(inode, n2, offsets2, chain2, &nr2);\n\t\tif (nr2) {\n\t\t\tif (partial2 == chain2) {\n\t\t\t\t \n\t\t\t\tgoto do_indirects;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tpartial2->p++;\n\t\t}\n\n\t\t \n\t\twhile (partial2 > chain2) {\n\t\t\text4_free_branches(handle, inode, partial2->bh,\n\t\t\t\t\t   (__le32 *)partial2->bh->b_data,\n\t\t\t\t\t   partial2->p,\n\t\t\t\t\t   (chain2+n2-1) - partial2);\n\t\t\tpartial2--;\n\t\t}\n\t\tgoto do_indirects;\n\t}\n\n\t \n\tpartial = p = ext4_find_shared(inode, n, offsets, chain, &nr);\n\tpartial2 = p2 = ext4_find_shared(inode, n2, offsets2, chain2, &nr2);\n\n\t \n\tif (nr) {\n\t\tint level = min(partial - chain, partial2 - chain2);\n\t\tint i;\n\t\tint subtree = 1;\n\n\t\tfor (i = 0; i <= level; i++) {\n\t\t\tif (offsets[i] != offsets2[i]) {\n\t\t\t\tsubtree = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!subtree) {\n\t\t\tif (partial == chain) {\n\t\t\t\t \n\t\t\t\text4_free_branches(handle, inode, NULL,\n\t\t\t\t\t\t   &nr, &nr+1,\n\t\t\t\t\t\t   (chain+n-1) - partial);\n\t\t\t\t*partial->p = 0;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tBUFFER_TRACE(partial->bh, \"get_write_access\");\n\t\t\t\text4_free_branches(handle, inode, partial->bh,\n\t\t\t\t\t\t   partial->p,\n\t\t\t\t\t\t   partial->p+1,\n\t\t\t\t\t\t   (chain+n-1) - partial);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!nr2) {\n\t\t \n\t\tpartial2->p++;\n\t}\n\n\twhile (partial > chain || partial2 > chain2) {\n\t\tint depth = (chain+n-1) - partial;\n\t\tint depth2 = (chain2+n2-1) - partial2;\n\n\t\tif (partial > chain && partial2 > chain2 &&\n\t\t    partial->bh->b_blocknr == partial2->bh->b_blocknr) {\n\t\t\t \n\t\t\text4_free_branches(handle, inode, partial->bh,\n\t\t\t\t\t   partial->p + 1,\n\t\t\t\t\t   partial2->p,\n\t\t\t\t\t   (chain+n-1) - partial);\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\t \n\t\tif (partial > chain && depth <= depth2) {\n\t\t\text4_free_branches(handle, inode, partial->bh,\n\t\t\t\t\t   partial->p + 1,\n\t\t\t\t\t   (__le32 *)partial->bh->b_data+addr_per_block,\n\t\t\t\t\t   (chain+n-1) - partial);\n\t\t\tpartial--;\n\t\t}\n\t\tif (partial2 > chain2 && depth2 <= depth) {\n\t\t\text4_free_branches(handle, inode, partial2->bh,\n\t\t\t\t\t   (__le32 *)partial2->bh->b_data,\n\t\t\t\t\t   partial2->p,\n\t\t\t\t\t   (chain2+n2-1) - partial2);\n\t\t\tpartial2--;\n\t\t}\n\t}\n\ncleanup:\n\twhile (p && p > chain) {\n\t\tBUFFER_TRACE(p->bh, \"call brelse\");\n\t\tbrelse(p->bh);\n\t\tp--;\n\t}\n\twhile (p2 && p2 > chain2) {\n\t\tBUFFER_TRACE(p2->bh, \"call brelse\");\n\t\tbrelse(p2->bh);\n\t\tp2--;\n\t}\n\treturn 0;\n\ndo_indirects:\n\t \n\tswitch (offsets[0]) {\n\tdefault:\n\t\tif (++n >= n2)\n\t\t\tbreak;\n\t\tnr = i_data[EXT4_IND_BLOCK];\n\t\tif (nr) {\n\t\t\text4_free_branches(handle, inode, NULL, &nr, &nr+1, 1);\n\t\t\ti_data[EXT4_IND_BLOCK] = 0;\n\t\t}\n\t\tfallthrough;\n\tcase EXT4_IND_BLOCK:\n\t\tif (++n >= n2)\n\t\t\tbreak;\n\t\tnr = i_data[EXT4_DIND_BLOCK];\n\t\tif (nr) {\n\t\t\text4_free_branches(handle, inode, NULL, &nr, &nr+1, 2);\n\t\t\ti_data[EXT4_DIND_BLOCK] = 0;\n\t\t}\n\t\tfallthrough;\n\tcase EXT4_DIND_BLOCK:\n\t\tif (++n >= n2)\n\t\t\tbreak;\n\t\tnr = i_data[EXT4_TIND_BLOCK];\n\t\tif (nr) {\n\t\t\text4_free_branches(handle, inode, NULL, &nr, &nr+1, 3);\n\t\t\ti_data[EXT4_TIND_BLOCK] = 0;\n\t\t}\n\t\tfallthrough;\n\tcase EXT4_TIND_BLOCK:\n\t\t;\n\t}\n\tgoto cleanup;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}