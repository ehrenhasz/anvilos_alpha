{
  "module_name": "node.h",
  "hash_id": "e54a3fb7696ed38a996c33d0fbcc2e1f4ba33df095500484b3430e7d14804e72",
  "original_prompt": "Ingested from linux-6.6.14/fs/f2fs/node.h",
  "human_readable_source": " \n \n \n#define\tSTART_NID(nid) (((nid) / NAT_ENTRY_PER_BLOCK) * NAT_ENTRY_PER_BLOCK)\n\n \n#define\tNAT_BLOCK_OFFSET(start_nid) ((start_nid) / NAT_ENTRY_PER_BLOCK)\n\n \n#define FREE_NID_PAGES\t8\n#define MAX_FREE_NIDS\t(NAT_ENTRY_PER_BLOCK * FREE_NID_PAGES)\n\n \n#define SHRINK_NID_BATCH_SIZE\t8\n\n#define DEF_RA_NID_PAGES\t0\t \n\n \n#define MAX_RA_NODE\t\t128\n\n \n#define DEF_RAM_THRESHOLD\t1\n\n \n#define DEF_DIRTY_NAT_RATIO_THRESHOLD\t\t10\n \n#define DEF_NAT_CACHE_THRESHOLD\t\t\t100000\n\n \n#define DEF_RF_NODE_BLOCKS\t\t\t0\n\n \n#define NAT_VEC_SIZE\t32\n\n \n#define LOCKED_PAGE\t1\n\n \n#define FILE_NOT_ALIGNED\t1\n\n \nenum {\n\tIS_CHECKPOINTED,\t \n\tHAS_FSYNCED_INODE,\t \n\tHAS_LAST_FSYNC,\t\t \n\tIS_DIRTY,\t\t \n\tIS_PREALLOC,\t\t \n};\n\n \nstruct node_info {\n\tnid_t nid;\t\t \n\tnid_t ino;\t\t \n\tblock_t\tblk_addr;\t \n\tunsigned char version;\t \n\tunsigned char flag;\t \n};\n\nstruct nat_entry {\n\tstruct list_head list;\t \n\tstruct node_info ni;\t \n};\n\n#define nat_get_nid(nat)\t\t((nat)->ni.nid)\n#define nat_set_nid(nat, n)\t\t((nat)->ni.nid = (n))\n#define nat_get_blkaddr(nat)\t\t((nat)->ni.blk_addr)\n#define nat_set_blkaddr(nat, b)\t\t((nat)->ni.blk_addr = (b))\n#define nat_get_ino(nat)\t\t((nat)->ni.ino)\n#define nat_set_ino(nat, i)\t\t((nat)->ni.ino = (i))\n#define nat_get_version(nat)\t\t((nat)->ni.version)\n#define nat_set_version(nat, v)\t\t((nat)->ni.version = (v))\n\n#define inc_node_version(version)\t(++(version))\n\nstatic inline void copy_node_info(struct node_info *dst,\n\t\t\t\t\t\tstruct node_info *src)\n{\n\tdst->nid = src->nid;\n\tdst->ino = src->ino;\n\tdst->blk_addr = src->blk_addr;\n\tdst->version = src->version;\n\t \n}\n\nstatic inline void set_nat_flag(struct nat_entry *ne,\n\t\t\t\tunsigned int type, bool set)\n{\n\tif (set)\n\t\tne->ni.flag |= BIT(type);\n\telse\n\t\tne->ni.flag &= ~BIT(type);\n}\n\nstatic inline bool get_nat_flag(struct nat_entry *ne, unsigned int type)\n{\n\treturn ne->ni.flag & BIT(type);\n}\n\nstatic inline void nat_reset_flag(struct nat_entry *ne)\n{\n\t \n\tset_nat_flag(ne, IS_CHECKPOINTED, true);\n\tset_nat_flag(ne, HAS_FSYNCED_INODE, false);\n\tset_nat_flag(ne, HAS_LAST_FSYNC, true);\n}\n\nstatic inline void node_info_from_raw_nat(struct node_info *ni,\n\t\t\t\t\t\tstruct f2fs_nat_entry *raw_ne)\n{\n\tni->ino = le32_to_cpu(raw_ne->ino);\n\tni->blk_addr = le32_to_cpu(raw_ne->block_addr);\n\tni->version = raw_ne->version;\n}\n\nstatic inline void raw_nat_from_node_info(struct f2fs_nat_entry *raw_ne,\n\t\t\t\t\t\tstruct node_info *ni)\n{\n\traw_ne->ino = cpu_to_le32(ni->ino);\n\traw_ne->block_addr = cpu_to_le32(ni->blk_addr);\n\traw_ne->version = ni->version;\n}\n\nstatic inline bool excess_dirty_nats(struct f2fs_sb_info *sbi)\n{\n\treturn NM_I(sbi)->nat_cnt[DIRTY_NAT] >= NM_I(sbi)->max_nid *\n\t\t\t\t\tNM_I(sbi)->dirty_nats_ratio / 100;\n}\n\nstatic inline bool excess_cached_nats(struct f2fs_sb_info *sbi)\n{\n\treturn NM_I(sbi)->nat_cnt[TOTAL_NAT] >= DEF_NAT_CACHE_THRESHOLD;\n}\n\nenum mem_type {\n\tFREE_NIDS,\t \n\tNAT_ENTRIES,\t \n\tDIRTY_DENTS,\t \n\tINO_ENTRIES,\t \n\tREAD_EXTENT_CACHE,\t \n\tAGE_EXTENT_CACHE,\t \n\tDISCARD_CACHE,\t \n\tCOMPRESS_PAGE,\t \n\tBASE_CHECK,\t \n};\n\nstruct nat_entry_set {\n\tstruct list_head set_list;\t \n\tstruct list_head entry_list;\t \n\tnid_t set;\t\t\t \n\tunsigned int entry_cnt;\t\t \n};\n\nstruct free_nid {\n\tstruct list_head list;\t \n\tnid_t nid;\t\t \n\tint state;\t\t \n};\n\nstatic inline void next_free_nid(struct f2fs_sb_info *sbi, nid_t *nid)\n{\n\tstruct f2fs_nm_info *nm_i = NM_I(sbi);\n\tstruct free_nid *fnid;\n\n\tspin_lock(&nm_i->nid_list_lock);\n\tif (nm_i->nid_cnt[FREE_NID] <= 0) {\n\t\tspin_unlock(&nm_i->nid_list_lock);\n\t\treturn;\n\t}\n\tfnid = list_first_entry(&nm_i->free_nid_list, struct free_nid, list);\n\t*nid = fnid->nid;\n\tspin_unlock(&nm_i->nid_list_lock);\n}\n\n \nstatic inline void get_nat_bitmap(struct f2fs_sb_info *sbi, void *addr)\n{\n\tstruct f2fs_nm_info *nm_i = NM_I(sbi);\n\n#ifdef CONFIG_F2FS_CHECK_FS\n\tif (memcmp(nm_i->nat_bitmap, nm_i->nat_bitmap_mir,\n\t\t\t\t\t\tnm_i->bitmap_size))\n\t\tf2fs_bug_on(sbi, 1);\n#endif\n\tmemcpy(addr, nm_i->nat_bitmap, nm_i->bitmap_size);\n}\n\nstatic inline pgoff_t current_nat_addr(struct f2fs_sb_info *sbi, nid_t start)\n{\n\tstruct f2fs_nm_info *nm_i = NM_I(sbi);\n\tpgoff_t block_off;\n\tpgoff_t block_addr;\n\n\t \n\tblock_off = NAT_BLOCK_OFFSET(start);\n\n\tblock_addr = (pgoff_t)(nm_i->nat_blkaddr +\n\t\t(block_off << 1) -\n\t\t(block_off & (sbi->blocks_per_seg - 1)));\n\n\tif (f2fs_test_bit(block_off, nm_i->nat_bitmap))\n\t\tblock_addr += sbi->blocks_per_seg;\n\n\treturn block_addr;\n}\n\nstatic inline pgoff_t next_nat_addr(struct f2fs_sb_info *sbi,\n\t\t\t\t\t\tpgoff_t block_addr)\n{\n\tstruct f2fs_nm_info *nm_i = NM_I(sbi);\n\n\tblock_addr -= nm_i->nat_blkaddr;\n\tblock_addr ^= BIT(sbi->log_blocks_per_seg);\n\treturn block_addr + nm_i->nat_blkaddr;\n}\n\nstatic inline void set_to_next_nat(struct f2fs_nm_info *nm_i, nid_t start_nid)\n{\n\tunsigned int block_off = NAT_BLOCK_OFFSET(start_nid);\n\n\tf2fs_change_bit(block_off, nm_i->nat_bitmap);\n#ifdef CONFIG_F2FS_CHECK_FS\n\tf2fs_change_bit(block_off, nm_i->nat_bitmap_mir);\n#endif\n}\n\nstatic inline nid_t ino_of_node(struct page *node_page)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(node_page);\n\treturn le32_to_cpu(rn->footer.ino);\n}\n\nstatic inline nid_t nid_of_node(struct page *node_page)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(node_page);\n\treturn le32_to_cpu(rn->footer.nid);\n}\n\nstatic inline unsigned int ofs_of_node(struct page *node_page)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(node_page);\n\tunsigned flag = le32_to_cpu(rn->footer.flag);\n\treturn flag >> OFFSET_BIT_SHIFT;\n}\n\nstatic inline __u64 cpver_of_node(struct page *node_page)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(node_page);\n\treturn le64_to_cpu(rn->footer.cp_ver);\n}\n\nstatic inline block_t next_blkaddr_of_node(struct page *node_page)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(node_page);\n\treturn le32_to_cpu(rn->footer.next_blkaddr);\n}\n\nstatic inline void fill_node_footer(struct page *page, nid_t nid,\n\t\t\t\tnid_t ino, unsigned int ofs, bool reset)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(page);\n\tunsigned int old_flag = 0;\n\n\tif (reset)\n\t\tmemset(rn, 0, sizeof(*rn));\n\telse\n\t\told_flag = le32_to_cpu(rn->footer.flag);\n\n\trn->footer.nid = cpu_to_le32(nid);\n\trn->footer.ino = cpu_to_le32(ino);\n\n\t \n\trn->footer.flag = cpu_to_le32((ofs << OFFSET_BIT_SHIFT) |\n\t\t\t\t\t(old_flag & OFFSET_BIT_MASK));\n}\n\nstatic inline void copy_node_footer(struct page *dst, struct page *src)\n{\n\tstruct f2fs_node *src_rn = F2FS_NODE(src);\n\tstruct f2fs_node *dst_rn = F2FS_NODE(dst);\n\tmemcpy(&dst_rn->footer, &src_rn->footer, sizeof(struct node_footer));\n}\n\nstatic inline void fill_node_footer_blkaddr(struct page *page, block_t blkaddr)\n{\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));\n\tstruct f2fs_node *rn = F2FS_NODE(page);\n\t__u64 cp_ver = cur_cp_version(ckpt);\n\n\tif (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG))\n\t\tcp_ver |= (cur_cp_crc(ckpt) << 32);\n\n\trn->footer.cp_ver = cpu_to_le64(cp_ver);\n\trn->footer.next_blkaddr = cpu_to_le32(blkaddr);\n}\n\nstatic inline bool is_recoverable_dnode(struct page *page)\n{\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(F2FS_P_SB(page));\n\t__u64 cp_ver = cur_cp_version(ckpt);\n\n\t \n\tif (__is_set_ckpt_flags(ckpt, CP_NOCRC_RECOVERY_FLAG))\n\t\treturn (cp_ver << 32) == (cpver_of_node(page) << 32);\n\n\tif (__is_set_ckpt_flags(ckpt, CP_CRC_RECOVERY_FLAG))\n\t\tcp_ver |= (cur_cp_crc(ckpt) << 32);\n\n\treturn cp_ver == cpver_of_node(page);\n}\n\n \nstatic inline bool IS_DNODE(struct page *node_page)\n{\n\tunsigned int ofs = ofs_of_node(node_page);\n\n\tif (f2fs_has_xattr_block(ofs))\n\t\treturn true;\n\n\tif (ofs == 3 || ofs == 4 + NIDS_PER_BLOCK ||\n\t\t\tofs == 5 + 2 * NIDS_PER_BLOCK)\n\t\treturn false;\n\tif (ofs >= 6 + 2 * NIDS_PER_BLOCK) {\n\t\tofs -= 6 + 2 * NIDS_PER_BLOCK;\n\t\tif (!((long int)ofs % (NIDS_PER_BLOCK + 1)))\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic inline int set_nid(struct page *p, int off, nid_t nid, bool i)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(p);\n\n\tf2fs_wait_on_page_writeback(p, NODE, true, true);\n\n\tif (i)\n\t\trn->i.i_nid[off - NODE_DIR1_BLOCK] = cpu_to_le32(nid);\n\telse\n\t\trn->in.nid[off] = cpu_to_le32(nid);\n\treturn set_page_dirty(p);\n}\n\nstatic inline nid_t get_nid(struct page *p, int off, bool i)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(p);\n\n\tif (i)\n\t\treturn le32_to_cpu(rn->i.i_nid[off - NODE_DIR1_BLOCK]);\n\treturn le32_to_cpu(rn->in.nid[off]);\n}\n\n \n\nstatic inline int is_node(struct page *page, int type)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(page);\n\treturn le32_to_cpu(rn->footer.flag) & BIT(type);\n}\n\n#define is_cold_node(page)\tis_node(page, COLD_BIT_SHIFT)\n#define is_fsync_dnode(page)\tis_node(page, FSYNC_BIT_SHIFT)\n#define is_dent_dnode(page)\tis_node(page, DENT_BIT_SHIFT)\n\nstatic inline void set_cold_node(struct page *page, bool is_dir)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(page);\n\tunsigned int flag = le32_to_cpu(rn->footer.flag);\n\n\tif (is_dir)\n\t\tflag &= ~BIT(COLD_BIT_SHIFT);\n\telse\n\t\tflag |= BIT(COLD_BIT_SHIFT);\n\trn->footer.flag = cpu_to_le32(flag);\n}\n\nstatic inline void set_mark(struct page *page, int mark, int type)\n{\n\tstruct f2fs_node *rn = F2FS_NODE(page);\n\tunsigned int flag = le32_to_cpu(rn->footer.flag);\n\tif (mark)\n\t\tflag |= BIT(type);\n\telse\n\t\tflag &= ~BIT(type);\n\trn->footer.flag = cpu_to_le32(flag);\n\n#ifdef CONFIG_F2FS_CHECK_FS\n\tf2fs_inode_chksum_set(F2FS_P_SB(page), page);\n#endif\n}\n#define set_dentry_mark(page, mark)\tset_mark(page, mark, DENT_BIT_SHIFT)\n#define set_fsync_mark(page, mark)\tset_mark(page, mark, FSYNC_BIT_SHIFT)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}