{
  "module_name": "super.c",
  "hash_id": "c03b85f8da9d61c76d90a75d3343ce8894b476c512c255836f49da0ed9e03c0c",
  "original_prompt": "Ingested from linux-6.6.14/fs/f2fs/super.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n#include <linux/fs_context.h>\n#include <linux/sched/mm.h>\n#include <linux/statfs.h>\n#include <linux/buffer_head.h>\n#include <linux/kthread.h>\n#include <linux/parser.h>\n#include <linux/mount.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/random.h>\n#include <linux/exportfs.h>\n#include <linux/blkdev.h>\n#include <linux/quotaops.h>\n#include <linux/f2fs_fs.h>\n#include <linux/sysfs.h>\n#include <linux/quota.h>\n#include <linux/unicode.h>\n#include <linux/part_stat.h>\n#include <linux/zstd.h>\n#include <linux/lz4.h>\n\n#include \"f2fs.h\"\n#include \"node.h\"\n#include \"segment.h\"\n#include \"xattr.h\"\n#include \"gc.h\"\n#include \"iostat.h\"\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/f2fs.h>\n\nstatic struct kmem_cache *f2fs_inode_cachep;\n\n#ifdef CONFIG_F2FS_FAULT_INJECTION\n\nconst char *f2fs_fault_name[FAULT_MAX] = {\n\t[FAULT_KMALLOC]\t\t= \"kmalloc\",\n\t[FAULT_KVMALLOC]\t= \"kvmalloc\",\n\t[FAULT_PAGE_ALLOC]\t= \"page alloc\",\n\t[FAULT_PAGE_GET]\t= \"page get\",\n\t[FAULT_ALLOC_NID]\t= \"alloc nid\",\n\t[FAULT_ORPHAN]\t\t= \"orphan\",\n\t[FAULT_BLOCK]\t\t= \"no more block\",\n\t[FAULT_DIR_DEPTH]\t= \"too big dir depth\",\n\t[FAULT_EVICT_INODE]\t= \"evict_inode fail\",\n\t[FAULT_TRUNCATE]\t= \"truncate fail\",\n\t[FAULT_READ_IO]\t\t= \"read IO error\",\n\t[FAULT_CHECKPOINT]\t= \"checkpoint error\",\n\t[FAULT_DISCARD]\t\t= \"discard error\",\n\t[FAULT_WRITE_IO]\t= \"write IO error\",\n\t[FAULT_SLAB_ALLOC]\t= \"slab alloc\",\n\t[FAULT_DQUOT_INIT]\t= \"dquot initialize\",\n\t[FAULT_LOCK_OP]\t\t= \"lock_op\",\n\t[FAULT_BLKADDR]\t\t= \"invalid blkaddr\",\n};\n\nvoid f2fs_build_fault_attr(struct f2fs_sb_info *sbi, unsigned int rate,\n\t\t\t\t\t\t\tunsigned int type)\n{\n\tstruct f2fs_fault_info *ffi = &F2FS_OPTION(sbi).fault_info;\n\n\tif (rate) {\n\t\tatomic_set(&ffi->inject_ops, 0);\n\t\tffi->inject_rate = rate;\n\t}\n\n\tif (type)\n\t\tffi->inject_type = type;\n\n\tif (!rate && !type)\n\t\tmemset(ffi, 0, sizeof(struct f2fs_fault_info));\n}\n#endif\n\n \nstatic struct shrinker f2fs_shrinker_info = {\n\t.scan_objects = f2fs_shrink_scan,\n\t.count_objects = f2fs_shrink_count,\n\t.seeks = DEFAULT_SEEKS,\n};\n\nenum {\n\tOpt_gc_background,\n\tOpt_disable_roll_forward,\n\tOpt_norecovery,\n\tOpt_discard,\n\tOpt_nodiscard,\n\tOpt_noheap,\n\tOpt_heap,\n\tOpt_user_xattr,\n\tOpt_nouser_xattr,\n\tOpt_acl,\n\tOpt_noacl,\n\tOpt_active_logs,\n\tOpt_disable_ext_identify,\n\tOpt_inline_xattr,\n\tOpt_noinline_xattr,\n\tOpt_inline_xattr_size,\n\tOpt_inline_data,\n\tOpt_inline_dentry,\n\tOpt_noinline_dentry,\n\tOpt_flush_merge,\n\tOpt_noflush_merge,\n\tOpt_barrier,\n\tOpt_nobarrier,\n\tOpt_fastboot,\n\tOpt_extent_cache,\n\tOpt_noextent_cache,\n\tOpt_noinline_data,\n\tOpt_data_flush,\n\tOpt_reserve_root,\n\tOpt_resgid,\n\tOpt_resuid,\n\tOpt_mode,\n\tOpt_io_size_bits,\n\tOpt_fault_injection,\n\tOpt_fault_type,\n\tOpt_lazytime,\n\tOpt_nolazytime,\n\tOpt_quota,\n\tOpt_noquota,\n\tOpt_usrquota,\n\tOpt_grpquota,\n\tOpt_prjquota,\n\tOpt_usrjquota,\n\tOpt_grpjquota,\n\tOpt_prjjquota,\n\tOpt_offusrjquota,\n\tOpt_offgrpjquota,\n\tOpt_offprjjquota,\n\tOpt_jqfmt_vfsold,\n\tOpt_jqfmt_vfsv0,\n\tOpt_jqfmt_vfsv1,\n\tOpt_alloc,\n\tOpt_fsync,\n\tOpt_test_dummy_encryption,\n\tOpt_inlinecrypt,\n\tOpt_checkpoint_disable,\n\tOpt_checkpoint_disable_cap,\n\tOpt_checkpoint_disable_cap_perc,\n\tOpt_checkpoint_enable,\n\tOpt_checkpoint_merge,\n\tOpt_nocheckpoint_merge,\n\tOpt_compress_algorithm,\n\tOpt_compress_log_size,\n\tOpt_compress_extension,\n\tOpt_nocompress_extension,\n\tOpt_compress_chksum,\n\tOpt_compress_mode,\n\tOpt_compress_cache,\n\tOpt_atgc,\n\tOpt_gc_merge,\n\tOpt_nogc_merge,\n\tOpt_discard_unit,\n\tOpt_memory_mode,\n\tOpt_age_extent_cache,\n\tOpt_errors,\n\tOpt_err,\n};\n\nstatic match_table_t f2fs_tokens = {\n\t{Opt_gc_background, \"background_gc=%s\"},\n\t{Opt_disable_roll_forward, \"disable_roll_forward\"},\n\t{Opt_norecovery, \"norecovery\"},\n\t{Opt_discard, \"discard\"},\n\t{Opt_nodiscard, \"nodiscard\"},\n\t{Opt_noheap, \"no_heap\"},\n\t{Opt_heap, \"heap\"},\n\t{Opt_user_xattr, \"user_xattr\"},\n\t{Opt_nouser_xattr, \"nouser_xattr\"},\n\t{Opt_acl, \"acl\"},\n\t{Opt_noacl, \"noacl\"},\n\t{Opt_active_logs, \"active_logs=%u\"},\n\t{Opt_disable_ext_identify, \"disable_ext_identify\"},\n\t{Opt_inline_xattr, \"inline_xattr\"},\n\t{Opt_noinline_xattr, \"noinline_xattr\"},\n\t{Opt_inline_xattr_size, \"inline_xattr_size=%u\"},\n\t{Opt_inline_data, \"inline_data\"},\n\t{Opt_inline_dentry, \"inline_dentry\"},\n\t{Opt_noinline_dentry, \"noinline_dentry\"},\n\t{Opt_flush_merge, \"flush_merge\"},\n\t{Opt_noflush_merge, \"noflush_merge\"},\n\t{Opt_barrier, \"barrier\"},\n\t{Opt_nobarrier, \"nobarrier\"},\n\t{Opt_fastboot, \"fastboot\"},\n\t{Opt_extent_cache, \"extent_cache\"},\n\t{Opt_noextent_cache, \"noextent_cache\"},\n\t{Opt_noinline_data, \"noinline_data\"},\n\t{Opt_data_flush, \"data_flush\"},\n\t{Opt_reserve_root, \"reserve_root=%u\"},\n\t{Opt_resgid, \"resgid=%u\"},\n\t{Opt_resuid, \"resuid=%u\"},\n\t{Opt_mode, \"mode=%s\"},\n\t{Opt_io_size_bits, \"io_bits=%u\"},\n\t{Opt_fault_injection, \"fault_injection=%u\"},\n\t{Opt_fault_type, \"fault_type=%u\"},\n\t{Opt_lazytime, \"lazytime\"},\n\t{Opt_nolazytime, \"nolazytime\"},\n\t{Opt_quota, \"quota\"},\n\t{Opt_noquota, \"noquota\"},\n\t{Opt_usrquota, \"usrquota\"},\n\t{Opt_grpquota, \"grpquota\"},\n\t{Opt_prjquota, \"prjquota\"},\n\t{Opt_usrjquota, \"usrjquota=%s\"},\n\t{Opt_grpjquota, \"grpjquota=%s\"},\n\t{Opt_prjjquota, \"prjjquota=%s\"},\n\t{Opt_offusrjquota, \"usrjquota=\"},\n\t{Opt_offgrpjquota, \"grpjquota=\"},\n\t{Opt_offprjjquota, \"prjjquota=\"},\n\t{Opt_jqfmt_vfsold, \"jqfmt=vfsold\"},\n\t{Opt_jqfmt_vfsv0, \"jqfmt=vfsv0\"},\n\t{Opt_jqfmt_vfsv1, \"jqfmt=vfsv1\"},\n\t{Opt_alloc, \"alloc_mode=%s\"},\n\t{Opt_fsync, \"fsync_mode=%s\"},\n\t{Opt_test_dummy_encryption, \"test_dummy_encryption=%s\"},\n\t{Opt_test_dummy_encryption, \"test_dummy_encryption\"},\n\t{Opt_inlinecrypt, \"inlinecrypt\"},\n\t{Opt_checkpoint_disable, \"checkpoint=disable\"},\n\t{Opt_checkpoint_disable_cap, \"checkpoint=disable:%u\"},\n\t{Opt_checkpoint_disable_cap_perc, \"checkpoint=disable:%u%%\"},\n\t{Opt_checkpoint_enable, \"checkpoint=enable\"},\n\t{Opt_checkpoint_merge, \"checkpoint_merge\"},\n\t{Opt_nocheckpoint_merge, \"nocheckpoint_merge\"},\n\t{Opt_compress_algorithm, \"compress_algorithm=%s\"},\n\t{Opt_compress_log_size, \"compress_log_size=%u\"},\n\t{Opt_compress_extension, \"compress_extension=%s\"},\n\t{Opt_nocompress_extension, \"nocompress_extension=%s\"},\n\t{Opt_compress_chksum, \"compress_chksum\"},\n\t{Opt_compress_mode, \"compress_mode=%s\"},\n\t{Opt_compress_cache, \"compress_cache\"},\n\t{Opt_atgc, \"atgc\"},\n\t{Opt_gc_merge, \"gc_merge\"},\n\t{Opt_nogc_merge, \"nogc_merge\"},\n\t{Opt_discard_unit, \"discard_unit=%s\"},\n\t{Opt_memory_mode, \"memory=%s\"},\n\t{Opt_age_extent_cache, \"age_extent_cache\"},\n\t{Opt_errors, \"errors=%s\"},\n\t{Opt_err, NULL},\n};\n\nvoid f2fs_printk(struct f2fs_sb_info *sbi, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\tint level;\n\n\tva_start(args, fmt);\n\n\tlevel = printk_get_level(fmt);\n\tvaf.fmt = printk_skip_level(fmt);\n\tvaf.va = &args;\n\tprintk(\"%c%cF2FS-fs (%s): %pV\\n\",\n\t       KERN_SOH_ASCII, level, sbi->sb->s_id, &vaf);\n\n\tva_end(args);\n}\n\n#if IS_ENABLED(CONFIG_UNICODE)\nstatic const struct f2fs_sb_encodings {\n\t__u16 magic;\n\tchar *name;\n\tunsigned int version;\n} f2fs_sb_encoding_map[] = {\n\t{F2FS_ENC_UTF8_12_1, \"utf8\", UNICODE_AGE(12, 1, 0)},\n};\n\nstatic const struct f2fs_sb_encodings *\nf2fs_sb_read_encoding(const struct f2fs_super_block *sb)\n{\n\t__u16 magic = le16_to_cpu(sb->s_encoding);\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(f2fs_sb_encoding_map); i++)\n\t\tif (magic == f2fs_sb_encoding_map[i].magic)\n\t\t\treturn &f2fs_sb_encoding_map[i];\n\n\treturn NULL;\n}\n\nstruct kmem_cache *f2fs_cf_name_slab;\nstatic int __init f2fs_create_casefold_cache(void)\n{\n\tf2fs_cf_name_slab = f2fs_kmem_cache_create(\"f2fs_casefolded_name\",\n\t\t\t\t\t\t\tF2FS_NAME_LEN);\n\treturn f2fs_cf_name_slab ? 0 : -ENOMEM;\n}\n\nstatic void f2fs_destroy_casefold_cache(void)\n{\n\tkmem_cache_destroy(f2fs_cf_name_slab);\n}\n#else\nstatic int __init f2fs_create_casefold_cache(void) { return 0; }\nstatic void f2fs_destroy_casefold_cache(void) { }\n#endif\n\nstatic inline void limit_reserve_root(struct f2fs_sb_info *sbi)\n{\n\tblock_t limit = min((sbi->user_block_count >> 3),\n\t\t\tsbi->user_block_count - sbi->reserved_blocks);\n\n\t \n\tif (test_opt(sbi, RESERVE_ROOT) &&\n\t\t\tF2FS_OPTION(sbi).root_reserved_blocks > limit) {\n\t\tF2FS_OPTION(sbi).root_reserved_blocks = limit;\n\t\tf2fs_info(sbi, \"Reduce reserved blocks for root = %u\",\n\t\t\t  F2FS_OPTION(sbi).root_reserved_blocks);\n\t}\n\tif (!test_opt(sbi, RESERVE_ROOT) &&\n\t\t(!uid_eq(F2FS_OPTION(sbi).s_resuid,\n\t\t\t\tmake_kuid(&init_user_ns, F2FS_DEF_RESUID)) ||\n\t\t!gid_eq(F2FS_OPTION(sbi).s_resgid,\n\t\t\t\tmake_kgid(&init_user_ns, F2FS_DEF_RESGID))))\n\t\tf2fs_info(sbi, \"Ignore s_resuid=%u, s_resgid=%u w/o reserve_root\",\n\t\t\t  from_kuid_munged(&init_user_ns,\n\t\t\t\t\t   F2FS_OPTION(sbi).s_resuid),\n\t\t\t  from_kgid_munged(&init_user_ns,\n\t\t\t\t\t   F2FS_OPTION(sbi).s_resgid));\n}\n\nstatic inline int adjust_reserved_segment(struct f2fs_sb_info *sbi)\n{\n\tunsigned int sec_blks = sbi->blocks_per_seg * sbi->segs_per_sec;\n\tunsigned int avg_vblocks;\n\tunsigned int wanted_reserved_segments;\n\tblock_t avail_user_block_count;\n\n\tif (!F2FS_IO_ALIGNED(sbi))\n\t\treturn 0;\n\n\t \n\tavg_vblocks = sec_blks / F2FS_IO_SIZE(sbi);\n\n\t \n\twanted_reserved_segments = (F2FS_IO_SIZE(sbi) / avg_vblocks) *\n\t\t\t\t\t\treserved_segments(sbi);\n\twanted_reserved_segments -= reserved_segments(sbi);\n\n\tavail_user_block_count = sbi->user_block_count -\n\t\t\t\tsbi->current_reserved_blocks -\n\t\t\t\tF2FS_OPTION(sbi).root_reserved_blocks;\n\n\tif (wanted_reserved_segments * sbi->blocks_per_seg >\n\t\t\t\t\tavail_user_block_count) {\n\t\tf2fs_err(sbi, \"IO align feature can't grab additional reserved segment: %u, available segments: %u\",\n\t\t\twanted_reserved_segments,\n\t\t\tavail_user_block_count >> sbi->log_blocks_per_seg);\n\t\treturn -ENOSPC;\n\t}\n\n\tSM_I(sbi)->additional_reserved_segments = wanted_reserved_segments;\n\n\tf2fs_info(sbi, \"IO align feature needs additional reserved segment: %u\",\n\t\t\t wanted_reserved_segments);\n\n\treturn 0;\n}\n\nstatic inline void adjust_unusable_cap_perc(struct f2fs_sb_info *sbi)\n{\n\tif (!F2FS_OPTION(sbi).unusable_cap_perc)\n\t\treturn;\n\n\tif (F2FS_OPTION(sbi).unusable_cap_perc == 100)\n\t\tF2FS_OPTION(sbi).unusable_cap = sbi->user_block_count;\n\telse\n\t\tF2FS_OPTION(sbi).unusable_cap = (sbi->user_block_count / 100) *\n\t\t\t\t\tF2FS_OPTION(sbi).unusable_cap_perc;\n\n\tf2fs_info(sbi, \"Adjust unusable cap for checkpoint=disable = %u / %u%%\",\n\t\t\tF2FS_OPTION(sbi).unusable_cap,\n\t\t\tF2FS_OPTION(sbi).unusable_cap_perc);\n}\n\nstatic void init_once(void *foo)\n{\n\tstruct f2fs_inode_info *fi = (struct f2fs_inode_info *) foo;\n\n\tinode_init_once(&fi->vfs_inode);\n}\n\n#ifdef CONFIG_QUOTA\nstatic const char * const quotatypes[] = INITQFNAMES;\n#define QTYPE2NAME(t) (quotatypes[t])\nstatic int f2fs_set_qf_name(struct super_block *sb, int qtype,\n\t\t\t\t\t\t\tsubstring_t *args)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tchar *qname;\n\tint ret = -EINVAL;\n\n\tif (sb_any_quota_loaded(sb) && !F2FS_OPTION(sbi).s_qf_names[qtype]) {\n\t\tf2fs_err(sbi, \"Cannot change journaled quota options when quota turned on\");\n\t\treturn -EINVAL;\n\t}\n\tif (f2fs_sb_has_quota_ino(sbi)) {\n\t\tf2fs_info(sbi, \"QUOTA feature is enabled, so ignore qf_name\");\n\t\treturn 0;\n\t}\n\n\tqname = match_strdup(args);\n\tif (!qname) {\n\t\tf2fs_err(sbi, \"Not enough memory for storing quotafile name\");\n\t\treturn -ENOMEM;\n\t}\n\tif (F2FS_OPTION(sbi).s_qf_names[qtype]) {\n\t\tif (strcmp(F2FS_OPTION(sbi).s_qf_names[qtype], qname) == 0)\n\t\t\tret = 0;\n\t\telse\n\t\t\tf2fs_err(sbi, \"%s quota file already specified\",\n\t\t\t\t QTYPE2NAME(qtype));\n\t\tgoto errout;\n\t}\n\tif (strchr(qname, '/')) {\n\t\tf2fs_err(sbi, \"quotafile must be on filesystem root\");\n\t\tgoto errout;\n\t}\n\tF2FS_OPTION(sbi).s_qf_names[qtype] = qname;\n\tset_opt(sbi, QUOTA);\n\treturn 0;\nerrout:\n\tkfree(qname);\n\treturn ret;\n}\n\nstatic int f2fs_clear_qf_name(struct super_block *sb, int qtype)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\n\tif (sb_any_quota_loaded(sb) && F2FS_OPTION(sbi).s_qf_names[qtype]) {\n\t\tf2fs_err(sbi, \"Cannot change journaled quota options when quota turned on\");\n\t\treturn -EINVAL;\n\t}\n\tkfree(F2FS_OPTION(sbi).s_qf_names[qtype]);\n\tF2FS_OPTION(sbi).s_qf_names[qtype] = NULL;\n\treturn 0;\n}\n\nstatic int f2fs_check_quota_options(struct f2fs_sb_info *sbi)\n{\n\t \n\tif (test_opt(sbi, PRJQUOTA) && !f2fs_sb_has_project_quota(sbi)) {\n\t\tf2fs_err(sbi, \"Project quota feature not enabled. Cannot enable project quota enforcement.\");\n\t\treturn -1;\n\t}\n\tif (F2FS_OPTION(sbi).s_qf_names[USRQUOTA] ||\n\t\t\tF2FS_OPTION(sbi).s_qf_names[GRPQUOTA] ||\n\t\t\tF2FS_OPTION(sbi).s_qf_names[PRJQUOTA]) {\n\t\tif (test_opt(sbi, USRQUOTA) &&\n\t\t\t\tF2FS_OPTION(sbi).s_qf_names[USRQUOTA])\n\t\t\tclear_opt(sbi, USRQUOTA);\n\n\t\tif (test_opt(sbi, GRPQUOTA) &&\n\t\t\t\tF2FS_OPTION(sbi).s_qf_names[GRPQUOTA])\n\t\t\tclear_opt(sbi, GRPQUOTA);\n\n\t\tif (test_opt(sbi, PRJQUOTA) &&\n\t\t\t\tF2FS_OPTION(sbi).s_qf_names[PRJQUOTA])\n\t\t\tclear_opt(sbi, PRJQUOTA);\n\n\t\tif (test_opt(sbi, GRPQUOTA) || test_opt(sbi, USRQUOTA) ||\n\t\t\t\ttest_opt(sbi, PRJQUOTA)) {\n\t\t\tf2fs_err(sbi, \"old and new quota format mixing\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (!F2FS_OPTION(sbi).s_jquota_fmt) {\n\t\t\tf2fs_err(sbi, \"journaled quota format not specified\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (f2fs_sb_has_quota_ino(sbi) && F2FS_OPTION(sbi).s_jquota_fmt) {\n\t\tf2fs_info(sbi, \"QUOTA feature is enabled, so ignore jquota_fmt\");\n\t\tF2FS_OPTION(sbi).s_jquota_fmt = 0;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic int f2fs_set_test_dummy_encryption(struct super_block *sb,\n\t\t\t\t\t  const char *opt,\n\t\t\t\t\t  const substring_t *arg,\n\t\t\t\t\t  bool is_remount)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct fs_parameter param = {\n\t\t.type = fs_value_is_string,\n\t\t.string = arg->from ? arg->from : \"\",\n\t};\n\tstruct fscrypt_dummy_policy *policy =\n\t\t&F2FS_OPTION(sbi).dummy_enc_policy;\n\tint err;\n\n\tif (!IS_ENABLED(CONFIG_FS_ENCRYPTION)) {\n\t\tf2fs_warn(sbi, \"test_dummy_encryption option not supported\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!f2fs_sb_has_encrypt(sbi)) {\n\t\tf2fs_err(sbi, \"Encrypt feature is off\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (is_remount && !fscrypt_is_dummy_policy_set(policy)) {\n\t\tf2fs_warn(sbi, \"Can't set test_dummy_encryption on remount\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = fscrypt_parse_test_dummy_encryption(&param, policy);\n\tif (err) {\n\t\tif (err == -EEXIST)\n\t\t\tf2fs_warn(sbi,\n\t\t\t\t  \"Can't change test_dummy_encryption on remount\");\n\t\telse if (err == -EINVAL)\n\t\t\tf2fs_warn(sbi, \"Value of option \\\"%s\\\" is unrecognized\",\n\t\t\t\t  opt);\n\t\telse\n\t\t\tf2fs_warn(sbi, \"Error processing option \\\"%s\\\" [%d]\",\n\t\t\t\t  opt, err);\n\t\treturn -EINVAL;\n\t}\n\tf2fs_warn(sbi, \"Test dummy encryption mode enabled\");\n\treturn 0;\n}\n\n#ifdef CONFIG_F2FS_FS_COMPRESSION\nstatic bool is_compress_extension_exist(struct f2fs_sb_info *sbi,\n\t\t\t\t\tconst char *new_ext, bool is_ext)\n{\n\tunsigned char (*ext)[F2FS_EXTENSION_LEN];\n\tint ext_cnt;\n\tint i;\n\n\tif (is_ext) {\n\t\text = F2FS_OPTION(sbi).extensions;\n\t\text_cnt = F2FS_OPTION(sbi).compress_ext_cnt;\n\t} else {\n\t\text = F2FS_OPTION(sbi).noextensions;\n\t\text_cnt = F2FS_OPTION(sbi).nocompress_ext_cnt;\n\t}\n\n\tfor (i = 0; i < ext_cnt; i++) {\n\t\tif (!strcasecmp(new_ext, ext[i]))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic int f2fs_test_compress_extension(struct f2fs_sb_info *sbi)\n{\n\tunsigned char (*ext)[F2FS_EXTENSION_LEN];\n\tunsigned char (*noext)[F2FS_EXTENSION_LEN];\n\tint ext_cnt, noext_cnt, index = 0, no_index = 0;\n\n\text = F2FS_OPTION(sbi).extensions;\n\text_cnt = F2FS_OPTION(sbi).compress_ext_cnt;\n\tnoext = F2FS_OPTION(sbi).noextensions;\n\tnoext_cnt = F2FS_OPTION(sbi).nocompress_ext_cnt;\n\n\tif (!noext_cnt)\n\t\treturn 0;\n\n\tfor (no_index = 0; no_index < noext_cnt; no_index++) {\n\t\tif (!strcasecmp(\"*\", noext[no_index])) {\n\t\t\tf2fs_info(sbi, \"Don't allow the nocompress extension specifies all files\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tfor (index = 0; index < ext_cnt; index++) {\n\t\t\tif (!strcasecmp(ext[index], noext[no_index])) {\n\t\t\t\tf2fs_info(sbi, \"Don't allow the same extension %s appear in both compress and nocompress extension\",\n\t\t\t\t\t\text[index]);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n#ifdef CONFIG_F2FS_FS_LZ4\nstatic int f2fs_set_lz4hc_level(struct f2fs_sb_info *sbi, const char *str)\n{\n#ifdef CONFIG_F2FS_FS_LZ4HC\n\tunsigned int level;\n\n\tif (strlen(str) == 3) {\n\t\tF2FS_OPTION(sbi).compress_level = 0;\n\t\treturn 0;\n\t}\n\n\tstr += 3;\n\n\tif (str[0] != ':') {\n\t\tf2fs_info(sbi, \"wrong format, e.g. <alg_name>:<compr_level>\");\n\t\treturn -EINVAL;\n\t}\n\tif (kstrtouint(str + 1, 10, &level))\n\t\treturn -EINVAL;\n\n\tif (!f2fs_is_compress_level_valid(COMPRESS_LZ4, level)) {\n\t\tf2fs_info(sbi, \"invalid lz4hc compress level: %d\", level);\n\t\treturn -EINVAL;\n\t}\n\n\tF2FS_OPTION(sbi).compress_level = level;\n\treturn 0;\n#else\n\tif (strlen(str) == 3) {\n\t\tF2FS_OPTION(sbi).compress_level = 0;\n\t\treturn 0;\n\t}\n\tf2fs_info(sbi, \"kernel doesn't support lz4hc compression\");\n\treturn -EINVAL;\n#endif\n}\n#endif\n\n#ifdef CONFIG_F2FS_FS_ZSTD\nstatic int f2fs_set_zstd_level(struct f2fs_sb_info *sbi, const char *str)\n{\n\tunsigned int level;\n\tint len = 4;\n\n\tif (strlen(str) == len) {\n\t\tF2FS_OPTION(sbi).compress_level = F2FS_ZSTD_DEFAULT_CLEVEL;\n\t\treturn 0;\n\t}\n\n\tstr += len;\n\n\tif (str[0] != ':') {\n\t\tf2fs_info(sbi, \"wrong format, e.g. <alg_name>:<compr_level>\");\n\t\treturn -EINVAL;\n\t}\n\tif (kstrtouint(str + 1, 10, &level))\n\t\treturn -EINVAL;\n\n\tif (!f2fs_is_compress_level_valid(COMPRESS_ZSTD, level)) {\n\t\tf2fs_info(sbi, \"invalid zstd compress level: %d\", level);\n\t\treturn -EINVAL;\n\t}\n\n\tF2FS_OPTION(sbi).compress_level = level;\n\treturn 0;\n}\n#endif\n#endif\n\nstatic int parse_options(struct super_block *sb, char *options, bool is_remount)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tsubstring_t args[MAX_OPT_ARGS];\n#ifdef CONFIG_F2FS_FS_COMPRESSION\n\tunsigned char (*ext)[F2FS_EXTENSION_LEN];\n\tunsigned char (*noext)[F2FS_EXTENSION_LEN];\n\tint ext_cnt, noext_cnt;\n#endif\n\tchar *p, *name;\n\tint arg = 0;\n\tkuid_t uid;\n\tkgid_t gid;\n\tint ret;\n\n\tif (!options)\n\t\tgoto default_check;\n\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tint token;\n\n\t\tif (!*p)\n\t\t\tcontinue;\n\t\t \n\t\targs[0].to = args[0].from = NULL;\n\t\ttoken = match_token(p, f2fs_tokens, args);\n\n\t\tswitch (token) {\n\t\tcase Opt_gc_background:\n\t\t\tname = match_strdup(&args[0]);\n\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"on\")) {\n\t\t\t\tF2FS_OPTION(sbi).bggc_mode = BGGC_MODE_ON;\n\t\t\t} else if (!strcmp(name, \"off\")) {\n\t\t\t\tF2FS_OPTION(sbi).bggc_mode = BGGC_MODE_OFF;\n\t\t\t} else if (!strcmp(name, \"sync\")) {\n\t\t\t\tF2FS_OPTION(sbi).bggc_mode = BGGC_MODE_SYNC;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_disable_roll_forward:\n\t\t\tset_opt(sbi, DISABLE_ROLL_FORWARD);\n\t\t\tbreak;\n\t\tcase Opt_norecovery:\n\t\t\t \n\t\t\tset_opt(sbi, NORECOVERY);\n\t\t\tif (!f2fs_readonly(sb))\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase Opt_discard:\n\t\t\tif (!f2fs_hw_support_discard(sbi)) {\n\t\t\t\tf2fs_warn(sbi, \"device does not support discard\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tset_opt(sbi, DISCARD);\n\t\t\tbreak;\n\t\tcase Opt_nodiscard:\n\t\t\tif (f2fs_hw_should_discard(sbi)) {\n\t\t\t\tf2fs_warn(sbi, \"discard is required for zoned block devices\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tclear_opt(sbi, DISCARD);\n\t\t\tbreak;\n\t\tcase Opt_noheap:\n\t\t\tset_opt(sbi, NOHEAP);\n\t\t\tbreak;\n\t\tcase Opt_heap:\n\t\t\tclear_opt(sbi, NOHEAP);\n\t\t\tbreak;\n#ifdef CONFIG_F2FS_FS_XATTR\n\t\tcase Opt_user_xattr:\n\t\t\tset_opt(sbi, XATTR_USER);\n\t\t\tbreak;\n\t\tcase Opt_nouser_xattr:\n\t\t\tclear_opt(sbi, XATTR_USER);\n\t\t\tbreak;\n\t\tcase Opt_inline_xattr:\n\t\t\tset_opt(sbi, INLINE_XATTR);\n\t\t\tbreak;\n\t\tcase Opt_noinline_xattr:\n\t\t\tclear_opt(sbi, INLINE_XATTR);\n\t\t\tbreak;\n\t\tcase Opt_inline_xattr_size:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tset_opt(sbi, INLINE_XATTR_SIZE);\n\t\t\tF2FS_OPTION(sbi).inline_xattr_size = arg;\n\t\t\tbreak;\n#else\n\t\tcase Opt_user_xattr:\n\t\t\tf2fs_info(sbi, \"user_xattr options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_nouser_xattr:\n\t\t\tf2fs_info(sbi, \"nouser_xattr options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_inline_xattr:\n\t\t\tf2fs_info(sbi, \"inline_xattr options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_noinline_xattr:\n\t\t\tf2fs_info(sbi, \"noinline_xattr options not supported\");\n\t\t\tbreak;\n#endif\n#ifdef CONFIG_F2FS_FS_POSIX_ACL\n\t\tcase Opt_acl:\n\t\t\tset_opt(sbi, POSIX_ACL);\n\t\t\tbreak;\n\t\tcase Opt_noacl:\n\t\t\tclear_opt(sbi, POSIX_ACL);\n\t\t\tbreak;\n#else\n\t\tcase Opt_acl:\n\t\t\tf2fs_info(sbi, \"acl options not supported\");\n\t\t\tbreak;\n\t\tcase Opt_noacl:\n\t\t\tf2fs_info(sbi, \"noacl options not supported\");\n\t\t\tbreak;\n#endif\n\t\tcase Opt_active_logs:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (arg != 2 && arg != 4 &&\n\t\t\t\targ != NR_CURSEG_PERSIST_TYPE)\n\t\t\t\treturn -EINVAL;\n\t\t\tF2FS_OPTION(sbi).active_logs = arg;\n\t\t\tbreak;\n\t\tcase Opt_disable_ext_identify:\n\t\t\tset_opt(sbi, DISABLE_EXT_IDENTIFY);\n\t\t\tbreak;\n\t\tcase Opt_inline_data:\n\t\t\tset_opt(sbi, INLINE_DATA);\n\t\t\tbreak;\n\t\tcase Opt_inline_dentry:\n\t\t\tset_opt(sbi, INLINE_DENTRY);\n\t\t\tbreak;\n\t\tcase Opt_noinline_dentry:\n\t\t\tclear_opt(sbi, INLINE_DENTRY);\n\t\t\tbreak;\n\t\tcase Opt_flush_merge:\n\t\t\tset_opt(sbi, FLUSH_MERGE);\n\t\t\tbreak;\n\t\tcase Opt_noflush_merge:\n\t\t\tclear_opt(sbi, FLUSH_MERGE);\n\t\t\tbreak;\n\t\tcase Opt_nobarrier:\n\t\t\tset_opt(sbi, NOBARRIER);\n\t\t\tbreak;\n\t\tcase Opt_barrier:\n\t\t\tclear_opt(sbi, NOBARRIER);\n\t\t\tbreak;\n\t\tcase Opt_fastboot:\n\t\t\tset_opt(sbi, FASTBOOT);\n\t\t\tbreak;\n\t\tcase Opt_extent_cache:\n\t\t\tset_opt(sbi, READ_EXTENT_CACHE);\n\t\t\tbreak;\n\t\tcase Opt_noextent_cache:\n\t\t\tclear_opt(sbi, READ_EXTENT_CACHE);\n\t\t\tbreak;\n\t\tcase Opt_noinline_data:\n\t\t\tclear_opt(sbi, INLINE_DATA);\n\t\t\tbreak;\n\t\tcase Opt_data_flush:\n\t\t\tset_opt(sbi, DATA_FLUSH);\n\t\t\tbreak;\n\t\tcase Opt_reserve_root:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (test_opt(sbi, RESERVE_ROOT)) {\n\t\t\t\tf2fs_info(sbi, \"Preserve previous reserve_root=%u\",\n\t\t\t\t\t  F2FS_OPTION(sbi).root_reserved_blocks);\n\t\t\t} else {\n\t\t\t\tF2FS_OPTION(sbi).root_reserved_blocks = arg;\n\t\t\t\tset_opt(sbi, RESERVE_ROOT);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Opt_resuid:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tuid = make_kuid(current_user_ns(), arg);\n\t\t\tif (!uid_valid(uid)) {\n\t\t\t\tf2fs_err(sbi, \"Invalid uid value %d\", arg);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tF2FS_OPTION(sbi).s_resuid = uid;\n\t\t\tbreak;\n\t\tcase Opt_resgid:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tgid = make_kgid(current_user_ns(), arg);\n\t\t\tif (!gid_valid(gid)) {\n\t\t\t\tf2fs_err(sbi, \"Invalid gid value %d\", arg);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tF2FS_OPTION(sbi).s_resgid = gid;\n\t\t\tbreak;\n\t\tcase Opt_mode:\n\t\t\tname = match_strdup(&args[0]);\n\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"adaptive\")) {\n\t\t\t\tF2FS_OPTION(sbi).fs_mode = FS_MODE_ADAPTIVE;\n\t\t\t} else if (!strcmp(name, \"lfs\")) {\n\t\t\t\tF2FS_OPTION(sbi).fs_mode = FS_MODE_LFS;\n\t\t\t} else if (!strcmp(name, \"fragment:segment\")) {\n\t\t\t\tF2FS_OPTION(sbi).fs_mode = FS_MODE_FRAGMENT_SEG;\n\t\t\t} else if (!strcmp(name, \"fragment:block\")) {\n\t\t\t\tF2FS_OPTION(sbi).fs_mode = FS_MODE_FRAGMENT_BLK;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_io_size_bits:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (arg <= 0 || arg > __ilog2_u32(BIO_MAX_VECS)) {\n\t\t\t\tf2fs_warn(sbi, \"Not support %ld, larger than %d\",\n\t\t\t\t\tBIT(arg), BIO_MAX_VECS);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tF2FS_OPTION(sbi).write_io_size_bits = arg;\n\t\t\tbreak;\n#ifdef CONFIG_F2FS_FAULT_INJECTION\n\t\tcase Opt_fault_injection:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tf2fs_build_fault_attr(sbi, arg, F2FS_ALL_FAULT_TYPE);\n\t\t\tset_opt(sbi, FAULT_INJECTION);\n\t\t\tbreak;\n\n\t\tcase Opt_fault_type:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tf2fs_build_fault_attr(sbi, 0, arg);\n\t\t\tset_opt(sbi, FAULT_INJECTION);\n\t\t\tbreak;\n#else\n\t\tcase Opt_fault_injection:\n\t\t\tf2fs_info(sbi, \"fault_injection options not supported\");\n\t\t\tbreak;\n\n\t\tcase Opt_fault_type:\n\t\t\tf2fs_info(sbi, \"fault_type options not supported\");\n\t\t\tbreak;\n#endif\n\t\tcase Opt_lazytime:\n\t\t\tsb->s_flags |= SB_LAZYTIME;\n\t\t\tbreak;\n\t\tcase Opt_nolazytime:\n\t\t\tsb->s_flags &= ~SB_LAZYTIME;\n\t\t\tbreak;\n#ifdef CONFIG_QUOTA\n\t\tcase Opt_quota:\n\t\tcase Opt_usrquota:\n\t\t\tset_opt(sbi, USRQUOTA);\n\t\t\tbreak;\n\t\tcase Opt_grpquota:\n\t\t\tset_opt(sbi, GRPQUOTA);\n\t\t\tbreak;\n\t\tcase Opt_prjquota:\n\t\t\tset_opt(sbi, PRJQUOTA);\n\t\t\tbreak;\n\t\tcase Opt_usrjquota:\n\t\t\tret = f2fs_set_qf_name(sb, USRQUOTA, &args[0]);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase Opt_grpjquota:\n\t\t\tret = f2fs_set_qf_name(sb, GRPQUOTA, &args[0]);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase Opt_prjjquota:\n\t\t\tret = f2fs_set_qf_name(sb, PRJQUOTA, &args[0]);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase Opt_offusrjquota:\n\t\t\tret = f2fs_clear_qf_name(sb, USRQUOTA);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase Opt_offgrpjquota:\n\t\t\tret = f2fs_clear_qf_name(sb, GRPQUOTA);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase Opt_offprjjquota:\n\t\t\tret = f2fs_clear_qf_name(sb, PRJQUOTA);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase Opt_jqfmt_vfsold:\n\t\t\tF2FS_OPTION(sbi).s_jquota_fmt = QFMT_VFS_OLD;\n\t\t\tbreak;\n\t\tcase Opt_jqfmt_vfsv0:\n\t\t\tF2FS_OPTION(sbi).s_jquota_fmt = QFMT_VFS_V0;\n\t\t\tbreak;\n\t\tcase Opt_jqfmt_vfsv1:\n\t\t\tF2FS_OPTION(sbi).s_jquota_fmt = QFMT_VFS_V1;\n\t\t\tbreak;\n\t\tcase Opt_noquota:\n\t\t\tclear_opt(sbi, QUOTA);\n\t\t\tclear_opt(sbi, USRQUOTA);\n\t\t\tclear_opt(sbi, GRPQUOTA);\n\t\t\tclear_opt(sbi, PRJQUOTA);\n\t\t\tbreak;\n#else\n\t\tcase Opt_quota:\n\t\tcase Opt_usrquota:\n\t\tcase Opt_grpquota:\n\t\tcase Opt_prjquota:\n\t\tcase Opt_usrjquota:\n\t\tcase Opt_grpjquota:\n\t\tcase Opt_prjjquota:\n\t\tcase Opt_offusrjquota:\n\t\tcase Opt_offgrpjquota:\n\t\tcase Opt_offprjjquota:\n\t\tcase Opt_jqfmt_vfsold:\n\t\tcase Opt_jqfmt_vfsv0:\n\t\tcase Opt_jqfmt_vfsv1:\n\t\tcase Opt_noquota:\n\t\t\tf2fs_info(sbi, \"quota operations not supported\");\n\t\t\tbreak;\n#endif\n\t\tcase Opt_alloc:\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tif (!strcmp(name, \"default\")) {\n\t\t\t\tF2FS_OPTION(sbi).alloc_mode = ALLOC_MODE_DEFAULT;\n\t\t\t} else if (!strcmp(name, \"reuse\")) {\n\t\t\t\tF2FS_OPTION(sbi).alloc_mode = ALLOC_MODE_REUSE;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_fsync:\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"posix\")) {\n\t\t\t\tF2FS_OPTION(sbi).fsync_mode = FSYNC_MODE_POSIX;\n\t\t\t} else if (!strcmp(name, \"strict\")) {\n\t\t\t\tF2FS_OPTION(sbi).fsync_mode = FSYNC_MODE_STRICT;\n\t\t\t} else if (!strcmp(name, \"nobarrier\")) {\n\t\t\t\tF2FS_OPTION(sbi).fsync_mode =\n\t\t\t\t\t\t\tFSYNC_MODE_NOBARRIER;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_test_dummy_encryption:\n\t\t\tret = f2fs_set_test_dummy_encryption(sb, p, &args[0],\n\t\t\t\t\t\t\t     is_remount);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tbreak;\n\t\tcase Opt_inlinecrypt:\n#ifdef CONFIG_FS_ENCRYPTION_INLINE_CRYPT\n\t\t\tsb->s_flags |= SB_INLINECRYPT;\n#else\n\t\t\tf2fs_info(sbi, \"inline encryption not supported\");\n#endif\n\t\t\tbreak;\n\t\tcase Opt_checkpoint_disable_cap_perc:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (arg < 0 || arg > 100)\n\t\t\t\treturn -EINVAL;\n\t\t\tF2FS_OPTION(sbi).unusable_cap_perc = arg;\n\t\t\tset_opt(sbi, DISABLE_CHECKPOINT);\n\t\t\tbreak;\n\t\tcase Opt_checkpoint_disable_cap:\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tF2FS_OPTION(sbi).unusable_cap = arg;\n\t\t\tset_opt(sbi, DISABLE_CHECKPOINT);\n\t\t\tbreak;\n\t\tcase Opt_checkpoint_disable:\n\t\t\tset_opt(sbi, DISABLE_CHECKPOINT);\n\t\t\tbreak;\n\t\tcase Opt_checkpoint_enable:\n\t\t\tclear_opt(sbi, DISABLE_CHECKPOINT);\n\t\t\tbreak;\n\t\tcase Opt_checkpoint_merge:\n\t\t\tset_opt(sbi, MERGE_CHECKPOINT);\n\t\t\tbreak;\n\t\tcase Opt_nocheckpoint_merge:\n\t\t\tclear_opt(sbi, MERGE_CHECKPOINT);\n\t\t\tbreak;\n#ifdef CONFIG_F2FS_FS_COMPRESSION\n\t\tcase Opt_compress_algorithm:\n\t\t\tif (!f2fs_sb_has_compression(sbi)) {\n\t\t\t\tf2fs_info(sbi, \"Image doesn't support compression\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"lzo\")) {\n#ifdef CONFIG_F2FS_FS_LZO\n\t\t\t\tF2FS_OPTION(sbi).compress_level = 0;\n\t\t\t\tF2FS_OPTION(sbi).compress_algorithm =\n\t\t\t\t\t\t\t\tCOMPRESS_LZO;\n#else\n\t\t\t\tf2fs_info(sbi, \"kernel doesn't support lzo compression\");\n#endif\n\t\t\t} else if (!strncmp(name, \"lz4\", 3)) {\n#ifdef CONFIG_F2FS_FS_LZ4\n\t\t\t\tret = f2fs_set_lz4hc_level(sbi, name);\n\t\t\t\tif (ret) {\n\t\t\t\t\tkfree(name);\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\tF2FS_OPTION(sbi).compress_algorithm =\n\t\t\t\t\t\t\t\tCOMPRESS_LZ4;\n#else\n\t\t\t\tf2fs_info(sbi, \"kernel doesn't support lz4 compression\");\n#endif\n\t\t\t} else if (!strncmp(name, \"zstd\", 4)) {\n#ifdef CONFIG_F2FS_FS_ZSTD\n\t\t\t\tret = f2fs_set_zstd_level(sbi, name);\n\t\t\t\tif (ret) {\n\t\t\t\t\tkfree(name);\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\tF2FS_OPTION(sbi).compress_algorithm =\n\t\t\t\t\t\t\t\tCOMPRESS_ZSTD;\n#else\n\t\t\t\tf2fs_info(sbi, \"kernel doesn't support zstd compression\");\n#endif\n\t\t\t} else if (!strcmp(name, \"lzo-rle\")) {\n#ifdef CONFIG_F2FS_FS_LZORLE\n\t\t\t\tF2FS_OPTION(sbi).compress_level = 0;\n\t\t\t\tF2FS_OPTION(sbi).compress_algorithm =\n\t\t\t\t\t\t\t\tCOMPRESS_LZORLE;\n#else\n\t\t\t\tf2fs_info(sbi, \"kernel doesn't support lzorle compression\");\n#endif\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_compress_log_size:\n\t\t\tif (!f2fs_sb_has_compression(sbi)) {\n\t\t\t\tf2fs_info(sbi, \"Image doesn't support compression\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (args->from && match_int(args, &arg))\n\t\t\t\treturn -EINVAL;\n\t\t\tif (arg < MIN_COMPRESS_LOG_SIZE ||\n\t\t\t\targ > MAX_COMPRESS_LOG_SIZE) {\n\t\t\t\tf2fs_err(sbi,\n\t\t\t\t\t\"Compress cluster log size is out of range\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tF2FS_OPTION(sbi).compress_log_size = arg;\n\t\t\tbreak;\n\t\tcase Opt_compress_extension:\n\t\t\tif (!f2fs_sb_has_compression(sbi)) {\n\t\t\t\tf2fs_info(sbi, \"Image doesn't support compression\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\text = F2FS_OPTION(sbi).extensions;\n\t\t\text_cnt = F2FS_OPTION(sbi).compress_ext_cnt;\n\n\t\t\tif (strlen(name) >= F2FS_EXTENSION_LEN ||\n\t\t\t\text_cnt >= COMPRESS_EXT_NUM) {\n\t\t\t\tf2fs_err(sbi,\n\t\t\t\t\t\"invalid extension length/number\");\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (is_compress_extension_exist(sbi, name, true)) {\n\t\t\t\tkfree(name);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tstrcpy(ext[ext_cnt], name);\n\t\t\tF2FS_OPTION(sbi).compress_ext_cnt++;\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_nocompress_extension:\n\t\t\tif (!f2fs_sb_has_compression(sbi)) {\n\t\t\t\tf2fs_info(sbi, \"Image doesn't support compression\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tnoext = F2FS_OPTION(sbi).noextensions;\n\t\t\tnoext_cnt = F2FS_OPTION(sbi).nocompress_ext_cnt;\n\n\t\t\tif (strlen(name) >= F2FS_EXTENSION_LEN ||\n\t\t\t\tnoext_cnt >= COMPRESS_EXT_NUM) {\n\t\t\t\tf2fs_err(sbi,\n\t\t\t\t\t\"invalid extension length/number\");\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (is_compress_extension_exist(sbi, name, false)) {\n\t\t\t\tkfree(name);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tstrcpy(noext[noext_cnt], name);\n\t\t\tF2FS_OPTION(sbi).nocompress_ext_cnt++;\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_compress_chksum:\n\t\t\tif (!f2fs_sb_has_compression(sbi)) {\n\t\t\t\tf2fs_info(sbi, \"Image doesn't support compression\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tF2FS_OPTION(sbi).compress_chksum = true;\n\t\t\tbreak;\n\t\tcase Opt_compress_mode:\n\t\t\tif (!f2fs_sb_has_compression(sbi)) {\n\t\t\t\tf2fs_info(sbi, \"Image doesn't support compression\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"fs\")) {\n\t\t\t\tF2FS_OPTION(sbi).compress_mode = COMPR_MODE_FS;\n\t\t\t} else if (!strcmp(name, \"user\")) {\n\t\t\t\tF2FS_OPTION(sbi).compress_mode = COMPR_MODE_USER;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_compress_cache:\n\t\t\tif (!f2fs_sb_has_compression(sbi)) {\n\t\t\t\tf2fs_info(sbi, \"Image doesn't support compression\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tset_opt(sbi, COMPRESS_CACHE);\n\t\t\tbreak;\n#else\n\t\tcase Opt_compress_algorithm:\n\t\tcase Opt_compress_log_size:\n\t\tcase Opt_compress_extension:\n\t\tcase Opt_nocompress_extension:\n\t\tcase Opt_compress_chksum:\n\t\tcase Opt_compress_mode:\n\t\tcase Opt_compress_cache:\n\t\t\tf2fs_info(sbi, \"compression options not supported\");\n\t\t\tbreak;\n#endif\n\t\tcase Opt_atgc:\n\t\t\tset_opt(sbi, ATGC);\n\t\t\tbreak;\n\t\tcase Opt_gc_merge:\n\t\t\tset_opt(sbi, GC_MERGE);\n\t\t\tbreak;\n\t\tcase Opt_nogc_merge:\n\t\t\tclear_opt(sbi, GC_MERGE);\n\t\t\tbreak;\n\t\tcase Opt_discard_unit:\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"block\")) {\n\t\t\t\tF2FS_OPTION(sbi).discard_unit =\n\t\t\t\t\t\tDISCARD_UNIT_BLOCK;\n\t\t\t} else if (!strcmp(name, \"segment\")) {\n\t\t\t\tF2FS_OPTION(sbi).discard_unit =\n\t\t\t\t\t\tDISCARD_UNIT_SEGMENT;\n\t\t\t} else if (!strcmp(name, \"section\")) {\n\t\t\t\tF2FS_OPTION(sbi).discard_unit =\n\t\t\t\t\t\tDISCARD_UNIT_SECTION;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_memory_mode:\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"normal\")) {\n\t\t\t\tF2FS_OPTION(sbi).memory_mode =\n\t\t\t\t\t\tMEMORY_MODE_NORMAL;\n\t\t\t} else if (!strcmp(name, \"low\")) {\n\t\t\t\tF2FS_OPTION(sbi).memory_mode =\n\t\t\t\t\t\tMEMORY_MODE_LOW;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tcase Opt_age_extent_cache:\n\t\t\tset_opt(sbi, AGE_EXTENT_CACHE);\n\t\t\tbreak;\n\t\tcase Opt_errors:\n\t\t\tname = match_strdup(&args[0]);\n\t\t\tif (!name)\n\t\t\t\treturn -ENOMEM;\n\t\t\tif (!strcmp(name, \"remount-ro\")) {\n\t\t\t\tF2FS_OPTION(sbi).errors =\n\t\t\t\t\t\tMOUNT_ERRORS_READONLY;\n\t\t\t} else if (!strcmp(name, \"continue\")) {\n\t\t\t\tF2FS_OPTION(sbi).errors =\n\t\t\t\t\t\tMOUNT_ERRORS_CONTINUE;\n\t\t\t} else if (!strcmp(name, \"panic\")) {\n\t\t\t\tF2FS_OPTION(sbi).errors =\n\t\t\t\t\t\tMOUNT_ERRORS_PANIC;\n\t\t\t} else {\n\t\t\t\tkfree(name);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tkfree(name);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tf2fs_err(sbi, \"Unrecognized mount option \\\"%s\\\" or missing value\",\n\t\t\t\t p);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\ndefault_check:\n#ifdef CONFIG_QUOTA\n\tif (f2fs_check_quota_options(sbi))\n\t\treturn -EINVAL;\n#else\n\tif (f2fs_sb_has_quota_ino(sbi) && !f2fs_readonly(sbi->sb)) {\n\t\tf2fs_info(sbi, \"Filesystem with quota feature cannot be mounted RDWR without CONFIG_QUOTA\");\n\t\treturn -EINVAL;\n\t}\n\tif (f2fs_sb_has_project_quota(sbi) && !f2fs_readonly(sbi->sb)) {\n\t\tf2fs_err(sbi, \"Filesystem with project quota feature cannot be mounted RDWR without CONFIG_QUOTA\");\n\t\treturn -EINVAL;\n\t}\n#endif\n#if !IS_ENABLED(CONFIG_UNICODE)\n\tif (f2fs_sb_has_casefold(sbi)) {\n\t\tf2fs_err(sbi,\n\t\t\t\"Filesystem with casefold feature cannot be mounted without CONFIG_UNICODE\");\n\t\treturn -EINVAL;\n\t}\n#endif\n\t \n\tif (f2fs_sb_has_blkzoned(sbi)) {\n#ifdef CONFIG_BLK_DEV_ZONED\n\t\tif (F2FS_OPTION(sbi).discard_unit !=\n\t\t\t\t\t\tDISCARD_UNIT_SECTION) {\n\t\t\tf2fs_info(sbi, \"Zoned block device doesn't need small discard, set discard_unit=section by default\");\n\t\t\tF2FS_OPTION(sbi).discard_unit =\n\t\t\t\t\tDISCARD_UNIT_SECTION;\n\t\t}\n\n\t\tif (F2FS_OPTION(sbi).fs_mode != FS_MODE_LFS) {\n\t\t\tf2fs_info(sbi, \"Only lfs mode is allowed with zoned block device feature\");\n\t\t\treturn -EINVAL;\n\t\t}\n#else\n\t\tf2fs_err(sbi, \"Zoned block device support is not enabled\");\n\t\treturn -EINVAL;\n#endif\n\t}\n\n#ifdef CONFIG_F2FS_FS_COMPRESSION\n\tif (f2fs_test_compress_extension(sbi)) {\n\t\tf2fs_err(sbi, \"invalid compress or nocompress extension\");\n\t\treturn -EINVAL;\n\t}\n#endif\n\n\tif (F2FS_IO_SIZE_BITS(sbi) && !f2fs_lfs_mode(sbi)) {\n\t\tf2fs_err(sbi, \"Should set mode=lfs with %luKB-sized IO\",\n\t\t\t F2FS_IO_SIZE_KB(sbi));\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_opt(sbi, INLINE_XATTR_SIZE)) {\n\t\tint min_size, max_size;\n\n\t\tif (!f2fs_sb_has_extra_attr(sbi) ||\n\t\t\t!f2fs_sb_has_flexible_inline_xattr(sbi)) {\n\t\t\tf2fs_err(sbi, \"extra_attr or flexible_inline_xattr feature is off\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!test_opt(sbi, INLINE_XATTR)) {\n\t\t\tf2fs_err(sbi, \"inline_xattr_size option should be set with inline_xattr option\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tmin_size = MIN_INLINE_XATTR_SIZE;\n\t\tmax_size = MAX_INLINE_XATTR_SIZE;\n\n\t\tif (F2FS_OPTION(sbi).inline_xattr_size < min_size ||\n\t\t\t\tF2FS_OPTION(sbi).inline_xattr_size > max_size) {\n\t\t\tf2fs_err(sbi, \"inline xattr size is out of range: %d ~ %d\",\n\t\t\t\t min_size, max_size);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (test_opt(sbi, DISABLE_CHECKPOINT) && f2fs_lfs_mode(sbi)) {\n\t\tf2fs_err(sbi, \"LFS is not compatible with checkpoint=disable\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_opt(sbi, ATGC) && f2fs_lfs_mode(sbi)) {\n\t\tf2fs_err(sbi, \"LFS is not compatible with ATGC\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (f2fs_is_readonly(sbi) && test_opt(sbi, FLUSH_MERGE)) {\n\t\tf2fs_err(sbi, \"FLUSH_MERGE not compatible with readonly mode\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (f2fs_sb_has_readonly(sbi) && !f2fs_readonly(sbi->sb)) {\n\t\tf2fs_err(sbi, \"Allow to mount readonly mode only\");\n\t\treturn -EROFS;\n\t}\n\treturn 0;\n}\n\nstatic struct inode *f2fs_alloc_inode(struct super_block *sb)\n{\n\tstruct f2fs_inode_info *fi;\n\n\tif (time_to_inject(F2FS_SB(sb), FAULT_SLAB_ALLOC))\n\t\treturn NULL;\n\n\tfi = alloc_inode_sb(sb, f2fs_inode_cachep, GFP_F2FS_ZERO);\n\tif (!fi)\n\t\treturn NULL;\n\n\tinit_once((void *) fi);\n\n\t \n\tatomic_set(&fi->dirty_pages, 0);\n\tatomic_set(&fi->i_compr_blocks, 0);\n\tinit_f2fs_rwsem(&fi->i_sem);\n\tspin_lock_init(&fi->i_size_lock);\n\tINIT_LIST_HEAD(&fi->dirty_list);\n\tINIT_LIST_HEAD(&fi->gdirty_list);\n\tinit_f2fs_rwsem(&fi->i_gc_rwsem[READ]);\n\tinit_f2fs_rwsem(&fi->i_gc_rwsem[WRITE]);\n\tinit_f2fs_rwsem(&fi->i_xattr_sem);\n\n\t \n\tfi->i_dir_level = F2FS_SB(sb)->dir_level;\n\n\treturn &fi->vfs_inode;\n}\n\nstatic int f2fs_drop_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tint ret;\n\n\t \n\tif (unlikely(is_sbi_flag_set(sbi, SBI_CP_DISABLED))) {\n\t\tif (inode->i_ino == F2FS_NODE_INO(sbi) ||\n\t\t\tinode->i_ino == F2FS_META_INO(sbi)) {\n\t\t\ttrace_f2fs_drop_inode(inode, 1);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t \n\tif ((!inode_unhashed(inode) && inode->i_state & I_SYNC)) {\n\t\tif (!inode->i_nlink && !is_bad_inode(inode)) {\n\t\t\t \n\t\t\tatomic_inc(&inode->i_count);\n\t\t\tspin_unlock(&inode->i_lock);\n\n\t\t\t \n\t\t\tf2fs_destroy_extent_node(inode);\n\n\t\t\tsb_start_intwrite(inode->i_sb);\n\t\t\tf2fs_i_size_write(inode, 0);\n\n\t\t\tf2fs_submit_merged_write_cond(F2FS_I_SB(inode),\n\t\t\t\t\tinode, NULL, 0, DATA);\n\t\t\ttruncate_inode_pages_final(inode->i_mapping);\n\n\t\t\tif (F2FS_HAS_BLOCKS(inode))\n\t\t\t\tf2fs_truncate(inode);\n\n\t\t\tsb_end_intwrite(inode->i_sb);\n\n\t\t\tspin_lock(&inode->i_lock);\n\t\t\tatomic_dec(&inode->i_count);\n\t\t}\n\t\ttrace_f2fs_drop_inode(inode, 0);\n\t\treturn 0;\n\t}\n\tret = generic_drop_inode(inode);\n\tif (!ret)\n\t\tret = fscrypt_drop_inode(inode);\n\ttrace_f2fs_drop_inode(inode, ret);\n\treturn ret;\n}\n\nint f2fs_inode_dirtied(struct inode *inode, bool sync)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tint ret = 0;\n\n\tspin_lock(&sbi->inode_lock[DIRTY_META]);\n\tif (is_inode_flag_set(inode, FI_DIRTY_INODE)) {\n\t\tret = 1;\n\t} else {\n\t\tset_inode_flag(inode, FI_DIRTY_INODE);\n\t\tstat_inc_dirty_inode(sbi, DIRTY_META);\n\t}\n\tif (sync && list_empty(&F2FS_I(inode)->gdirty_list)) {\n\t\tlist_add_tail(&F2FS_I(inode)->gdirty_list,\n\t\t\t\t&sbi->inode_list[DIRTY_META]);\n\t\tinc_page_count(sbi, F2FS_DIRTY_IMETA);\n\t}\n\tspin_unlock(&sbi->inode_lock[DIRTY_META]);\n\treturn ret;\n}\n\nvoid f2fs_inode_synced(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\tspin_lock(&sbi->inode_lock[DIRTY_META]);\n\tif (!is_inode_flag_set(inode, FI_DIRTY_INODE)) {\n\t\tspin_unlock(&sbi->inode_lock[DIRTY_META]);\n\t\treturn;\n\t}\n\tif (!list_empty(&F2FS_I(inode)->gdirty_list)) {\n\t\tlist_del_init(&F2FS_I(inode)->gdirty_list);\n\t\tdec_page_count(sbi, F2FS_DIRTY_IMETA);\n\t}\n\tclear_inode_flag(inode, FI_DIRTY_INODE);\n\tclear_inode_flag(inode, FI_AUTO_RECOVER);\n\tstat_dec_dirty_inode(F2FS_I_SB(inode), DIRTY_META);\n\tspin_unlock(&sbi->inode_lock[DIRTY_META]);\n}\n\n \nstatic void f2fs_dirty_inode(struct inode *inode, int flags)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\tif (inode->i_ino == F2FS_NODE_INO(sbi) ||\n\t\t\tinode->i_ino == F2FS_META_INO(sbi))\n\t\treturn;\n\n\tif (is_inode_flag_set(inode, FI_AUTO_RECOVER))\n\t\tclear_inode_flag(inode, FI_AUTO_RECOVER);\n\n\tf2fs_inode_dirtied(inode, false);\n}\n\nstatic void f2fs_free_inode(struct inode *inode)\n{\n\tfscrypt_free_inode(inode);\n\tkmem_cache_free(f2fs_inode_cachep, F2FS_I(inode));\n}\n\nstatic void destroy_percpu_info(struct f2fs_sb_info *sbi)\n{\n\tpercpu_counter_destroy(&sbi->total_valid_inode_count);\n\tpercpu_counter_destroy(&sbi->rf_node_block_count);\n\tpercpu_counter_destroy(&sbi->alloc_valid_block_count);\n}\n\nstatic void destroy_device_list(struct f2fs_sb_info *sbi)\n{\n\tint i;\n\n\tfor (i = 0; i < sbi->s_ndevs; i++) {\n\t\tif (i > 0)\n\t\t\tblkdev_put(FDEV(i).bdev, sbi->sb);\n#ifdef CONFIG_BLK_DEV_ZONED\n\t\tkvfree(FDEV(i).blkz_seq);\n#endif\n\t}\n\tkvfree(sbi->devs);\n}\n\nstatic void f2fs_put_super(struct super_block *sb)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tint i;\n\tint err = 0;\n\tbool done;\n\n\t \n\tf2fs_unregister_sysfs(sbi);\n\n\tf2fs_quota_off_umount(sb);\n\n\t \n\tmutex_lock(&sbi->umount_mutex);\n\n\t \n\tf2fs_stop_ckpt_thread(sbi);\n\n\t \n\tif ((is_sbi_flag_set(sbi, SBI_IS_DIRTY) ||\n\t\t\t!is_set_ckpt_flags(sbi, CP_UMOUNT_FLAG))) {\n\t\tstruct cp_control cpc = {\n\t\t\t.reason = CP_UMOUNT,\n\t\t};\n\t\tstat_inc_cp_call_count(sbi, TOTAL_CALL);\n\t\terr = f2fs_write_checkpoint(sbi, &cpc);\n\t}\n\n\t \n\tdone = f2fs_issue_discard_timeout(sbi);\n\tif (f2fs_realtime_discard_enable(sbi) && !sbi->discard_blks && done) {\n\t\tstruct cp_control cpc = {\n\t\t\t.reason = CP_UMOUNT | CP_TRIMMED,\n\t\t};\n\t\tstat_inc_cp_call_count(sbi, TOTAL_CALL);\n\t\terr = f2fs_write_checkpoint(sbi, &cpc);\n\t}\n\n\t \n\tf2fs_release_ino_entry(sbi, true);\n\n\tf2fs_leave_shrinker(sbi);\n\tmutex_unlock(&sbi->umount_mutex);\n\n\t \n\tf2fs_flush_merged_writes(sbi);\n\n\tf2fs_wait_on_all_pages(sbi, F2FS_WB_CP_DATA);\n\n\tif (err || f2fs_cp_error(sbi)) {\n\t\ttruncate_inode_pages_final(NODE_MAPPING(sbi));\n\t\ttruncate_inode_pages_final(META_MAPPING(sbi));\n\t}\n\n\tfor (i = 0; i < NR_COUNT_TYPE; i++) {\n\t\tif (!get_pages(sbi, i))\n\t\t\tcontinue;\n\t\tf2fs_err(sbi, \"detect filesystem reference count leak during \"\n\t\t\t\"umount, type: %d, count: %lld\", i, get_pages(sbi, i));\n\t\tf2fs_bug_on(sbi, 1);\n\t}\n\n\tf2fs_bug_on(sbi, sbi->fsync_node_num);\n\n\tf2fs_destroy_compress_inode(sbi);\n\n\tiput(sbi->node_inode);\n\tsbi->node_inode = NULL;\n\n\tiput(sbi->meta_inode);\n\tsbi->meta_inode = NULL;\n\n\t \n\tf2fs_destroy_stats(sbi);\n\n\t \n\tf2fs_destroy_node_manager(sbi);\n\tf2fs_destroy_segment_manager(sbi);\n\n\t \n\tflush_work(&sbi->s_error_work);\n\n\tf2fs_destroy_post_read_wq(sbi);\n\n\tkvfree(sbi->ckpt);\n\n\tsb->s_fs_info = NULL;\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n\tkfree(sbi->raw_super);\n\n\tdestroy_device_list(sbi);\n\tf2fs_destroy_page_array_cache(sbi);\n\tf2fs_destroy_xattr_caches(sbi);\n\tmempool_destroy(sbi->write_io_dummy);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tkfree(F2FS_OPTION(sbi).s_qf_names[i]);\n#endif\n\tfscrypt_free_dummy_policy(&F2FS_OPTION(sbi).dummy_enc_policy);\n\tdestroy_percpu_info(sbi);\n\tf2fs_destroy_iostat(sbi);\n\tfor (i = 0; i < NR_PAGE_TYPE; i++)\n\t\tkvfree(sbi->write_io[i]);\n#if IS_ENABLED(CONFIG_UNICODE)\n\tutf8_unload(sb->s_encoding);\n#endif\n\tkfree(sbi);\n}\n\nint f2fs_sync_fs(struct super_block *sb, int sync)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tint err = 0;\n\n\tif (unlikely(f2fs_cp_error(sbi)))\n\t\treturn 0;\n\tif (unlikely(is_sbi_flag_set(sbi, SBI_CP_DISABLED)))\n\t\treturn 0;\n\n\ttrace_f2fs_sync_fs(sb, sync);\n\n\tif (unlikely(is_sbi_flag_set(sbi, SBI_POR_DOING)))\n\t\treturn -EAGAIN;\n\n\tif (sync) {\n\t\tstat_inc_cp_call_count(sbi, TOTAL_CALL);\n\t\terr = f2fs_issue_checkpoint(sbi);\n\t}\n\n\treturn err;\n}\n\nstatic int f2fs_freeze(struct super_block *sb)\n{\n\tif (f2fs_readonly(sb))\n\t\treturn 0;\n\n\t \n\tif (unlikely(f2fs_cp_error(F2FS_SB(sb))))\n\t\treturn -EIO;\n\n\t \n\tif (is_sbi_flag_set(F2FS_SB(sb), SBI_IS_DIRTY))\n\t\treturn -EINVAL;\n\n\t \n\tf2fs_flush_ckpt_thread(F2FS_SB(sb));\n\n\t \n\tset_sbi_flag(F2FS_SB(sb), SBI_IS_FREEZING);\n\treturn 0;\n}\n\nstatic int f2fs_unfreeze(struct super_block *sb)\n{\n\tclear_sbi_flag(F2FS_SB(sb), SBI_IS_FREEZING);\n\treturn 0;\n}\n\n#ifdef CONFIG_QUOTA\nstatic int f2fs_statfs_project(struct super_block *sb,\n\t\t\t\tkprojid_t projid, struct kstatfs *buf)\n{\n\tstruct kqid qid;\n\tstruct dquot *dquot;\n\tu64 limit;\n\tu64 curblock;\n\n\tqid = make_kqid_projid(projid);\n\tdquot = dqget(sb, qid);\n\tif (IS_ERR(dquot))\n\t\treturn PTR_ERR(dquot);\n\tspin_lock(&dquot->dq_dqb_lock);\n\n\tlimit = min_not_zero(dquot->dq_dqb.dqb_bsoftlimit,\n\t\t\t\t\tdquot->dq_dqb.dqb_bhardlimit);\n\tif (limit)\n\t\tlimit >>= sb->s_blocksize_bits;\n\n\tif (limit && buf->f_blocks > limit) {\n\t\tcurblock = (dquot->dq_dqb.dqb_curspace +\n\t\t\t    dquot->dq_dqb.dqb_rsvspace) >> sb->s_blocksize_bits;\n\t\tbuf->f_blocks = limit;\n\t\tbuf->f_bfree = buf->f_bavail =\n\t\t\t(buf->f_blocks > curblock) ?\n\t\t\t (buf->f_blocks - curblock) : 0;\n\t}\n\n\tlimit = min_not_zero(dquot->dq_dqb.dqb_isoftlimit,\n\t\t\t\t\tdquot->dq_dqb.dqb_ihardlimit);\n\n\tif (limit && buf->f_files > limit) {\n\t\tbuf->f_files = limit;\n\t\tbuf->f_ffree =\n\t\t\t(buf->f_files > dquot->dq_dqb.dqb_curinodes) ?\n\t\t\t (buf->f_files - dquot->dq_dqb.dqb_curinodes) : 0;\n\t}\n\n\tspin_unlock(&dquot->dq_dqb_lock);\n\tdqput(dquot);\n\treturn 0;\n}\n#endif\n\nstatic int f2fs_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tu64 id = huge_encode_dev(sb->s_bdev->bd_dev);\n\tblock_t total_count, user_block_count, start_count;\n\tu64 avail_node_count;\n\tunsigned int total_valid_node_count;\n\n\ttotal_count = le64_to_cpu(sbi->raw_super->block_count);\n\tstart_count = le32_to_cpu(sbi->raw_super->segment0_blkaddr);\n\tbuf->f_type = F2FS_SUPER_MAGIC;\n\tbuf->f_bsize = sbi->blocksize;\n\n\tbuf->f_blocks = total_count - start_count;\n\n\tspin_lock(&sbi->stat_lock);\n\n\tuser_block_count = sbi->user_block_count;\n\ttotal_valid_node_count = valid_node_count(sbi);\n\tavail_node_count = sbi->total_node_count - F2FS_RESERVED_NODE_NUM;\n\tbuf->f_bfree = user_block_count - valid_user_blocks(sbi) -\n\t\t\t\t\t\tsbi->current_reserved_blocks;\n\n\tif (unlikely(buf->f_bfree <= sbi->unusable_block_count))\n\t\tbuf->f_bfree = 0;\n\telse\n\t\tbuf->f_bfree -= sbi->unusable_block_count;\n\tspin_unlock(&sbi->stat_lock);\n\n\tif (buf->f_bfree > F2FS_OPTION(sbi).root_reserved_blocks)\n\t\tbuf->f_bavail = buf->f_bfree -\n\t\t\t\tF2FS_OPTION(sbi).root_reserved_blocks;\n\telse\n\t\tbuf->f_bavail = 0;\n\n\tif (avail_node_count > user_block_count) {\n\t\tbuf->f_files = user_block_count;\n\t\tbuf->f_ffree = buf->f_bavail;\n\t} else {\n\t\tbuf->f_files = avail_node_count;\n\t\tbuf->f_ffree = min(avail_node_count - total_valid_node_count,\n\t\t\t\t\tbuf->f_bavail);\n\t}\n\n\tbuf->f_namelen = F2FS_NAME_LEN;\n\tbuf->f_fsid    = u64_to_fsid(id);\n\n#ifdef CONFIG_QUOTA\n\tif (is_inode_flag_set(dentry->d_inode, FI_PROJ_INHERIT) &&\n\t\t\tsb_has_quota_limits_enabled(sb, PRJQUOTA)) {\n\t\tf2fs_statfs_project(sb, F2FS_I(dentry->d_inode)->i_projid, buf);\n\t}\n#endif\n\treturn 0;\n}\n\nstatic inline void f2fs_show_quota_options(struct seq_file *seq,\n\t\t\t\t\t   struct super_block *sb)\n{\n#ifdef CONFIG_QUOTA\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\n\tif (F2FS_OPTION(sbi).s_jquota_fmt) {\n\t\tchar *fmtname = \"\";\n\n\t\tswitch (F2FS_OPTION(sbi).s_jquota_fmt) {\n\t\tcase QFMT_VFS_OLD:\n\t\t\tfmtname = \"vfsold\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V0:\n\t\t\tfmtname = \"vfsv0\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V1:\n\t\t\tfmtname = \"vfsv1\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(seq, \",jqfmt=%s\", fmtname);\n\t}\n\n\tif (F2FS_OPTION(sbi).s_qf_names[USRQUOTA])\n\t\tseq_show_option(seq, \"usrjquota\",\n\t\t\tF2FS_OPTION(sbi).s_qf_names[USRQUOTA]);\n\n\tif (F2FS_OPTION(sbi).s_qf_names[GRPQUOTA])\n\t\tseq_show_option(seq, \"grpjquota\",\n\t\t\tF2FS_OPTION(sbi).s_qf_names[GRPQUOTA]);\n\n\tif (F2FS_OPTION(sbi).s_qf_names[PRJQUOTA])\n\t\tseq_show_option(seq, \"prjjquota\",\n\t\t\tF2FS_OPTION(sbi).s_qf_names[PRJQUOTA]);\n#endif\n}\n\n#ifdef CONFIG_F2FS_FS_COMPRESSION\nstatic inline void f2fs_show_compress_options(struct seq_file *seq,\n\t\t\t\t\t\t\tstruct super_block *sb)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tchar *algtype = \"\";\n\tint i;\n\n\tif (!f2fs_sb_has_compression(sbi))\n\t\treturn;\n\n\tswitch (F2FS_OPTION(sbi).compress_algorithm) {\n\tcase COMPRESS_LZO:\n\t\talgtype = \"lzo\";\n\t\tbreak;\n\tcase COMPRESS_LZ4:\n\t\talgtype = \"lz4\";\n\t\tbreak;\n\tcase COMPRESS_ZSTD:\n\t\talgtype = \"zstd\";\n\t\tbreak;\n\tcase COMPRESS_LZORLE:\n\t\talgtype = \"lzo-rle\";\n\t\tbreak;\n\t}\n\tseq_printf(seq, \",compress_algorithm=%s\", algtype);\n\n\tif (F2FS_OPTION(sbi).compress_level)\n\t\tseq_printf(seq, \":%d\", F2FS_OPTION(sbi).compress_level);\n\n\tseq_printf(seq, \",compress_log_size=%u\",\n\t\t\tF2FS_OPTION(sbi).compress_log_size);\n\n\tfor (i = 0; i < F2FS_OPTION(sbi).compress_ext_cnt; i++) {\n\t\tseq_printf(seq, \",compress_extension=%s\",\n\t\t\tF2FS_OPTION(sbi).extensions[i]);\n\t}\n\n\tfor (i = 0; i < F2FS_OPTION(sbi).nocompress_ext_cnt; i++) {\n\t\tseq_printf(seq, \",nocompress_extension=%s\",\n\t\t\tF2FS_OPTION(sbi).noextensions[i]);\n\t}\n\n\tif (F2FS_OPTION(sbi).compress_chksum)\n\t\tseq_puts(seq, \",compress_chksum\");\n\n\tif (F2FS_OPTION(sbi).compress_mode == COMPR_MODE_FS)\n\t\tseq_printf(seq, \",compress_mode=%s\", \"fs\");\n\telse if (F2FS_OPTION(sbi).compress_mode == COMPR_MODE_USER)\n\t\tseq_printf(seq, \",compress_mode=%s\", \"user\");\n\n\tif (test_opt(sbi, COMPRESS_CACHE))\n\t\tseq_puts(seq, \",compress_cache\");\n}\n#endif\n\nstatic int f2fs_show_options(struct seq_file *seq, struct dentry *root)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(root->d_sb);\n\n\tif (F2FS_OPTION(sbi).bggc_mode == BGGC_MODE_SYNC)\n\t\tseq_printf(seq, \",background_gc=%s\", \"sync\");\n\telse if (F2FS_OPTION(sbi).bggc_mode == BGGC_MODE_ON)\n\t\tseq_printf(seq, \",background_gc=%s\", \"on\");\n\telse if (F2FS_OPTION(sbi).bggc_mode == BGGC_MODE_OFF)\n\t\tseq_printf(seq, \",background_gc=%s\", \"off\");\n\n\tif (test_opt(sbi, GC_MERGE))\n\t\tseq_puts(seq, \",gc_merge\");\n\telse\n\t\tseq_puts(seq, \",nogc_merge\");\n\n\tif (test_opt(sbi, DISABLE_ROLL_FORWARD))\n\t\tseq_puts(seq, \",disable_roll_forward\");\n\tif (test_opt(sbi, NORECOVERY))\n\t\tseq_puts(seq, \",norecovery\");\n\tif (test_opt(sbi, DISCARD)) {\n\t\tseq_puts(seq, \",discard\");\n\t\tif (F2FS_OPTION(sbi).discard_unit == DISCARD_UNIT_BLOCK)\n\t\t\tseq_printf(seq, \",discard_unit=%s\", \"block\");\n\t\telse if (F2FS_OPTION(sbi).discard_unit == DISCARD_UNIT_SEGMENT)\n\t\t\tseq_printf(seq, \",discard_unit=%s\", \"segment\");\n\t\telse if (F2FS_OPTION(sbi).discard_unit == DISCARD_UNIT_SECTION)\n\t\t\tseq_printf(seq, \",discard_unit=%s\", \"section\");\n\t} else {\n\t\tseq_puts(seq, \",nodiscard\");\n\t}\n\tif (test_opt(sbi, NOHEAP))\n\t\tseq_puts(seq, \",no_heap\");\n\telse\n\t\tseq_puts(seq, \",heap\");\n#ifdef CONFIG_F2FS_FS_XATTR\n\tif (test_opt(sbi, XATTR_USER))\n\t\tseq_puts(seq, \",user_xattr\");\n\telse\n\t\tseq_puts(seq, \",nouser_xattr\");\n\tif (test_opt(sbi, INLINE_XATTR))\n\t\tseq_puts(seq, \",inline_xattr\");\n\telse\n\t\tseq_puts(seq, \",noinline_xattr\");\n\tif (test_opt(sbi, INLINE_XATTR_SIZE))\n\t\tseq_printf(seq, \",inline_xattr_size=%u\",\n\t\t\t\t\tF2FS_OPTION(sbi).inline_xattr_size);\n#endif\n#ifdef CONFIG_F2FS_FS_POSIX_ACL\n\tif (test_opt(sbi, POSIX_ACL))\n\t\tseq_puts(seq, \",acl\");\n\telse\n\t\tseq_puts(seq, \",noacl\");\n#endif\n\tif (test_opt(sbi, DISABLE_EXT_IDENTIFY))\n\t\tseq_puts(seq, \",disable_ext_identify\");\n\tif (test_opt(sbi, INLINE_DATA))\n\t\tseq_puts(seq, \",inline_data\");\n\telse\n\t\tseq_puts(seq, \",noinline_data\");\n\tif (test_opt(sbi, INLINE_DENTRY))\n\t\tseq_puts(seq, \",inline_dentry\");\n\telse\n\t\tseq_puts(seq, \",noinline_dentry\");\n\tif (test_opt(sbi, FLUSH_MERGE))\n\t\tseq_puts(seq, \",flush_merge\");\n\telse\n\t\tseq_puts(seq, \",noflush_merge\");\n\tif (test_opt(sbi, NOBARRIER))\n\t\tseq_puts(seq, \",nobarrier\");\n\telse\n\t\tseq_puts(seq, \",barrier\");\n\tif (test_opt(sbi, FASTBOOT))\n\t\tseq_puts(seq, \",fastboot\");\n\tif (test_opt(sbi, READ_EXTENT_CACHE))\n\t\tseq_puts(seq, \",extent_cache\");\n\telse\n\t\tseq_puts(seq, \",noextent_cache\");\n\tif (test_opt(sbi, AGE_EXTENT_CACHE))\n\t\tseq_puts(seq, \",age_extent_cache\");\n\tif (test_opt(sbi, DATA_FLUSH))\n\t\tseq_puts(seq, \",data_flush\");\n\n\tseq_puts(seq, \",mode=\");\n\tif (F2FS_OPTION(sbi).fs_mode == FS_MODE_ADAPTIVE)\n\t\tseq_puts(seq, \"adaptive\");\n\telse if (F2FS_OPTION(sbi).fs_mode == FS_MODE_LFS)\n\t\tseq_puts(seq, \"lfs\");\n\telse if (F2FS_OPTION(sbi).fs_mode == FS_MODE_FRAGMENT_SEG)\n\t\tseq_puts(seq, \"fragment:segment\");\n\telse if (F2FS_OPTION(sbi).fs_mode == FS_MODE_FRAGMENT_BLK)\n\t\tseq_puts(seq, \"fragment:block\");\n\tseq_printf(seq, \",active_logs=%u\", F2FS_OPTION(sbi).active_logs);\n\tif (test_opt(sbi, RESERVE_ROOT))\n\t\tseq_printf(seq, \",reserve_root=%u,resuid=%u,resgid=%u\",\n\t\t\t\tF2FS_OPTION(sbi).root_reserved_blocks,\n\t\t\t\tfrom_kuid_munged(&init_user_ns,\n\t\t\t\t\tF2FS_OPTION(sbi).s_resuid),\n\t\t\t\tfrom_kgid_munged(&init_user_ns,\n\t\t\t\t\tF2FS_OPTION(sbi).s_resgid));\n\tif (F2FS_IO_SIZE_BITS(sbi))\n\t\tseq_printf(seq, \",io_bits=%u\",\n\t\t\t\tF2FS_OPTION(sbi).write_io_size_bits);\n#ifdef CONFIG_F2FS_FAULT_INJECTION\n\tif (test_opt(sbi, FAULT_INJECTION)) {\n\t\tseq_printf(seq, \",fault_injection=%u\",\n\t\t\t\tF2FS_OPTION(sbi).fault_info.inject_rate);\n\t\tseq_printf(seq, \",fault_type=%u\",\n\t\t\t\tF2FS_OPTION(sbi).fault_info.inject_type);\n\t}\n#endif\n#ifdef CONFIG_QUOTA\n\tif (test_opt(sbi, QUOTA))\n\t\tseq_puts(seq, \",quota\");\n\tif (test_opt(sbi, USRQUOTA))\n\t\tseq_puts(seq, \",usrquota\");\n\tif (test_opt(sbi, GRPQUOTA))\n\t\tseq_puts(seq, \",grpquota\");\n\tif (test_opt(sbi, PRJQUOTA))\n\t\tseq_puts(seq, \",prjquota\");\n#endif\n\tf2fs_show_quota_options(seq, sbi->sb);\n\n\tfscrypt_show_test_dummy_encryption(seq, ',', sbi->sb);\n\n\tif (sbi->sb->s_flags & SB_INLINECRYPT)\n\t\tseq_puts(seq, \",inlinecrypt\");\n\n\tif (F2FS_OPTION(sbi).alloc_mode == ALLOC_MODE_DEFAULT)\n\t\tseq_printf(seq, \",alloc_mode=%s\", \"default\");\n\telse if (F2FS_OPTION(sbi).alloc_mode == ALLOC_MODE_REUSE)\n\t\tseq_printf(seq, \",alloc_mode=%s\", \"reuse\");\n\n\tif (test_opt(sbi, DISABLE_CHECKPOINT))\n\t\tseq_printf(seq, \",checkpoint=disable:%u\",\n\t\t\t\tF2FS_OPTION(sbi).unusable_cap);\n\tif (test_opt(sbi, MERGE_CHECKPOINT))\n\t\tseq_puts(seq, \",checkpoint_merge\");\n\telse\n\t\tseq_puts(seq, \",nocheckpoint_merge\");\n\tif (F2FS_OPTION(sbi).fsync_mode == FSYNC_MODE_POSIX)\n\t\tseq_printf(seq, \",fsync_mode=%s\", \"posix\");\n\telse if (F2FS_OPTION(sbi).fsync_mode == FSYNC_MODE_STRICT)\n\t\tseq_printf(seq, \",fsync_mode=%s\", \"strict\");\n\telse if (F2FS_OPTION(sbi).fsync_mode == FSYNC_MODE_NOBARRIER)\n\t\tseq_printf(seq, \",fsync_mode=%s\", \"nobarrier\");\n\n#ifdef CONFIG_F2FS_FS_COMPRESSION\n\tf2fs_show_compress_options(seq, sbi->sb);\n#endif\n\n\tif (test_opt(sbi, ATGC))\n\t\tseq_puts(seq, \",atgc\");\n\n\tif (F2FS_OPTION(sbi).memory_mode == MEMORY_MODE_NORMAL)\n\t\tseq_printf(seq, \",memory=%s\", \"normal\");\n\telse if (F2FS_OPTION(sbi).memory_mode == MEMORY_MODE_LOW)\n\t\tseq_printf(seq, \",memory=%s\", \"low\");\n\n\tif (F2FS_OPTION(sbi).errors == MOUNT_ERRORS_READONLY)\n\t\tseq_printf(seq, \",errors=%s\", \"remount-ro\");\n\telse if (F2FS_OPTION(sbi).errors == MOUNT_ERRORS_CONTINUE)\n\t\tseq_printf(seq, \",errors=%s\", \"continue\");\n\telse if (F2FS_OPTION(sbi).errors == MOUNT_ERRORS_PANIC)\n\t\tseq_printf(seq, \",errors=%s\", \"panic\");\n\n\treturn 0;\n}\n\nstatic void default_options(struct f2fs_sb_info *sbi, bool remount)\n{\n\t \n\tif (!remount) {\n\t\tset_opt(sbi, READ_EXTENT_CACHE);\n\t\tclear_opt(sbi, DISABLE_CHECKPOINT);\n\n\t\tif (f2fs_hw_support_discard(sbi) || f2fs_hw_should_discard(sbi))\n\t\t\tset_opt(sbi, DISCARD);\n\n\t\tif (f2fs_sb_has_blkzoned(sbi))\n\t\t\tF2FS_OPTION(sbi).discard_unit = DISCARD_UNIT_SECTION;\n\t\telse\n\t\t\tF2FS_OPTION(sbi).discard_unit = DISCARD_UNIT_BLOCK;\n\t}\n\n\tif (f2fs_sb_has_readonly(sbi))\n\t\tF2FS_OPTION(sbi).active_logs = NR_CURSEG_RO_TYPE;\n\telse\n\t\tF2FS_OPTION(sbi).active_logs = NR_CURSEG_PERSIST_TYPE;\n\n\tF2FS_OPTION(sbi).inline_xattr_size = DEFAULT_INLINE_XATTR_ADDRS;\n\tif (le32_to_cpu(F2FS_RAW_SUPER(sbi)->segment_count_main) <=\n\t\t\t\t\t\t\tSMALL_VOLUME_SEGMENTS)\n\t\tF2FS_OPTION(sbi).alloc_mode = ALLOC_MODE_REUSE;\n\telse\n\t\tF2FS_OPTION(sbi).alloc_mode = ALLOC_MODE_DEFAULT;\n\tF2FS_OPTION(sbi).fsync_mode = FSYNC_MODE_POSIX;\n\tF2FS_OPTION(sbi).s_resuid = make_kuid(&init_user_ns, F2FS_DEF_RESUID);\n\tF2FS_OPTION(sbi).s_resgid = make_kgid(&init_user_ns, F2FS_DEF_RESGID);\n\tif (f2fs_sb_has_compression(sbi)) {\n\t\tF2FS_OPTION(sbi).compress_algorithm = COMPRESS_LZ4;\n\t\tF2FS_OPTION(sbi).compress_log_size = MIN_COMPRESS_LOG_SIZE;\n\t\tF2FS_OPTION(sbi).compress_ext_cnt = 0;\n\t\tF2FS_OPTION(sbi).compress_mode = COMPR_MODE_FS;\n\t}\n\tF2FS_OPTION(sbi).bggc_mode = BGGC_MODE_ON;\n\tF2FS_OPTION(sbi).memory_mode = MEMORY_MODE_NORMAL;\n\tF2FS_OPTION(sbi).errors = MOUNT_ERRORS_CONTINUE;\n\n\tsbi->sb->s_flags &= ~SB_INLINECRYPT;\n\n\tset_opt(sbi, INLINE_XATTR);\n\tset_opt(sbi, INLINE_DATA);\n\tset_opt(sbi, INLINE_DENTRY);\n\tset_opt(sbi, NOHEAP);\n\tset_opt(sbi, MERGE_CHECKPOINT);\n\tF2FS_OPTION(sbi).unusable_cap = 0;\n\tsbi->sb->s_flags |= SB_LAZYTIME;\n\tif (!f2fs_is_readonly(sbi))\n\t\tset_opt(sbi, FLUSH_MERGE);\n\tif (f2fs_sb_has_blkzoned(sbi))\n\t\tF2FS_OPTION(sbi).fs_mode = FS_MODE_LFS;\n\telse\n\t\tF2FS_OPTION(sbi).fs_mode = FS_MODE_ADAPTIVE;\n\n#ifdef CONFIG_F2FS_FS_XATTR\n\tset_opt(sbi, XATTR_USER);\n#endif\n#ifdef CONFIG_F2FS_FS_POSIX_ACL\n\tset_opt(sbi, POSIX_ACL);\n#endif\n\n\tf2fs_build_fault_attr(sbi, 0, 0);\n}\n\n#ifdef CONFIG_QUOTA\nstatic int f2fs_enable_quotas(struct super_block *sb);\n#endif\n\nstatic int f2fs_disable_checkpoint(struct f2fs_sb_info *sbi)\n{\n\tunsigned int s_flags = sbi->sb->s_flags;\n\tstruct cp_control cpc;\n\tunsigned int gc_mode = sbi->gc_mode;\n\tint err = 0;\n\tint ret;\n\tblock_t unusable;\n\n\tif (s_flags & SB_RDONLY) {\n\t\tf2fs_err(sbi, \"checkpoint=disable on readonly fs\");\n\t\treturn -EINVAL;\n\t}\n\tsbi->sb->s_flags |= SB_ACTIVE;\n\n\t \n\tunusable = f2fs_get_unusable_blocks(sbi);\n\tif (!f2fs_disable_cp_again(sbi, unusable))\n\t\tgoto skip_gc;\n\n\tf2fs_update_time(sbi, DISABLE_TIME);\n\n\tsbi->gc_mode = GC_URGENT_HIGH;\n\n\twhile (!f2fs_time_over(sbi, DISABLE_TIME)) {\n\t\tstruct f2fs_gc_control gc_control = {\n\t\t\t.victim_segno = NULL_SEGNO,\n\t\t\t.init_gc_type = FG_GC,\n\t\t\t.should_migrate_blocks = false,\n\t\t\t.err_gc_skipped = true,\n\t\t\t.nr_free_secs = 1 };\n\n\t\tf2fs_down_write(&sbi->gc_lock);\n\t\tstat_inc_gc_call_count(sbi, FOREGROUND);\n\t\terr = f2fs_gc(sbi, &gc_control);\n\t\tif (err == -ENODATA) {\n\t\t\terr = 0;\n\t\t\tbreak;\n\t\t}\n\t\tif (err && err != -EAGAIN)\n\t\t\tbreak;\n\t}\n\n\tret = sync_filesystem(sbi->sb);\n\tif (ret || err) {\n\t\terr = ret ? ret : err;\n\t\tgoto restore_flag;\n\t}\n\n\tunusable = f2fs_get_unusable_blocks(sbi);\n\tif (f2fs_disable_cp_again(sbi, unusable)) {\n\t\terr = -EAGAIN;\n\t\tgoto restore_flag;\n\t}\n\nskip_gc:\n\tf2fs_down_write(&sbi->gc_lock);\n\tcpc.reason = CP_PAUSE;\n\tset_sbi_flag(sbi, SBI_CP_DISABLED);\n\tstat_inc_cp_call_count(sbi, TOTAL_CALL);\n\terr = f2fs_write_checkpoint(sbi, &cpc);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tspin_lock(&sbi->stat_lock);\n\tsbi->unusable_block_count = unusable;\n\tspin_unlock(&sbi->stat_lock);\n\nout_unlock:\n\tf2fs_up_write(&sbi->gc_lock);\nrestore_flag:\n\tsbi->gc_mode = gc_mode;\n\tsbi->sb->s_flags = s_flags;\t \n\treturn err;\n}\n\nstatic void f2fs_enable_checkpoint(struct f2fs_sb_info *sbi)\n{\n\tint retry = DEFAULT_RETRY_IO_COUNT;\n\n\t \n\tdo {\n\t\tsync_inodes_sb(sbi->sb);\n\t\tf2fs_io_schedule_timeout(DEFAULT_IO_TIMEOUT);\n\t} while (get_pages(sbi, F2FS_DIRTY_DATA) && retry--);\n\n\tif (unlikely(retry < 0))\n\t\tf2fs_warn(sbi, \"checkpoint=enable has some unwritten data.\");\n\n\tf2fs_down_write(&sbi->gc_lock);\n\tf2fs_dirty_to_prefree(sbi);\n\n\tclear_sbi_flag(sbi, SBI_CP_DISABLED);\n\tset_sbi_flag(sbi, SBI_IS_DIRTY);\n\tf2fs_up_write(&sbi->gc_lock);\n\n\tf2fs_sync_fs(sbi->sb, 1);\n\n\t \n\tf2fs_flush_ckpt_thread(sbi);\n}\n\nstatic int f2fs_remount(struct super_block *sb, int *flags, char *data)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct f2fs_mount_info org_mount_opt;\n\tunsigned long old_sb_flags;\n\tint err;\n\tbool need_restart_gc = false, need_stop_gc = false;\n\tbool need_restart_ckpt = false, need_stop_ckpt = false;\n\tbool need_restart_flush = false, need_stop_flush = false;\n\tbool need_restart_discard = false, need_stop_discard = false;\n\tbool no_read_extent_cache = !test_opt(sbi, READ_EXTENT_CACHE);\n\tbool no_age_extent_cache = !test_opt(sbi, AGE_EXTENT_CACHE);\n\tbool enable_checkpoint = !test_opt(sbi, DISABLE_CHECKPOINT);\n\tbool no_io_align = !F2FS_IO_ALIGNED(sbi);\n\tbool no_atgc = !test_opt(sbi, ATGC);\n\tbool no_discard = !test_opt(sbi, DISCARD);\n\tbool no_compress_cache = !test_opt(sbi, COMPRESS_CACHE);\n\tbool block_unit_discard = f2fs_block_unit_discard(sbi);\n#ifdef CONFIG_QUOTA\n\tint i, j;\n#endif\n\n\t \n\torg_mount_opt = sbi->mount_opt;\n\told_sb_flags = sb->s_flags;\n\n#ifdef CONFIG_QUOTA\n\torg_mount_opt.s_jquota_fmt = F2FS_OPTION(sbi).s_jquota_fmt;\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (F2FS_OPTION(sbi).s_qf_names[i]) {\n\t\t\torg_mount_opt.s_qf_names[i] =\n\t\t\t\tkstrdup(F2FS_OPTION(sbi).s_qf_names[i],\n\t\t\t\tGFP_KERNEL);\n\t\t\tif (!org_mount_opt.s_qf_names[i]) {\n\t\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\t\tkfree(org_mount_opt.s_qf_names[j]);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t} else {\n\t\t\torg_mount_opt.s_qf_names[i] = NULL;\n\t\t}\n\t}\n#endif\n\n\t \n\tif (!(*flags & SB_RDONLY) && is_sbi_flag_set(sbi, SBI_NEED_SB_WRITE)) {\n\t\terr = f2fs_commit_super(sbi, false);\n\t\tf2fs_info(sbi, \"Try to recover all the superblocks, ret: %d\",\n\t\t\t  err);\n\t\tif (!err)\n\t\t\tclear_sbi_flag(sbi, SBI_NEED_SB_WRITE);\n\t}\n\n\tdefault_options(sbi, true);\n\n\t \n\terr = parse_options(sb, data, true);\n\tif (err)\n\t\tgoto restore_opts;\n\n\t \n\tflush_work(&sbi->s_error_work);\n\n\t \n\tif (f2fs_readonly(sb) && (*flags & SB_RDONLY))\n\t\tgoto skip;\n\n\tif (f2fs_dev_is_readonly(sbi) && !(*flags & SB_RDONLY)) {\n\t\terr = -EROFS;\n\t\tgoto restore_opts;\n\t}\n\n#ifdef CONFIG_QUOTA\n\tif (!f2fs_readonly(sb) && (*flags & SB_RDONLY)) {\n\t\terr = dquot_suspend(sb, -1);\n\t\tif (err < 0)\n\t\t\tgoto restore_opts;\n\t} else if (f2fs_readonly(sb) && !(*flags & SB_RDONLY)) {\n\t\t \n\t\tsb->s_flags &= ~SB_RDONLY;\n\t\tif (sb_any_quota_suspended(sb)) {\n\t\t\tdquot_resume(sb, -1);\n\t\t} else if (f2fs_sb_has_quota_ino(sbi)) {\n\t\t\terr = f2fs_enable_quotas(sb);\n\t\t\tif (err)\n\t\t\t\tgoto restore_opts;\n\t\t}\n\t}\n#endif\n\tif (f2fs_lfs_mode(sbi) && !IS_F2FS_IPU_DISABLE(sbi)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"LFS is not compatible with IPU\");\n\t\tgoto restore_opts;\n\t}\n\n\t \n\tif (no_atgc == !!test_opt(sbi, ATGC)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"switch atgc option is not allowed\");\n\t\tgoto restore_opts;\n\t}\n\n\t \n\tif (no_read_extent_cache == !!test_opt(sbi, READ_EXTENT_CACHE)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"switch extent_cache option is not allowed\");\n\t\tgoto restore_opts;\n\t}\n\t \n\tif (no_age_extent_cache == !!test_opt(sbi, AGE_EXTENT_CACHE)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"switch age_extent_cache option is not allowed\");\n\t\tgoto restore_opts;\n\t}\n\n\tif (no_io_align == !!F2FS_IO_ALIGNED(sbi)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"switch io_bits option is not allowed\");\n\t\tgoto restore_opts;\n\t}\n\n\tif (no_compress_cache == !!test_opt(sbi, COMPRESS_CACHE)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"switch compress_cache option is not allowed\");\n\t\tgoto restore_opts;\n\t}\n\n\tif (block_unit_discard != f2fs_block_unit_discard(sbi)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"switch discard_unit option is not allowed\");\n\t\tgoto restore_opts;\n\t}\n\n\tif ((*flags & SB_RDONLY) && test_opt(sbi, DISABLE_CHECKPOINT)) {\n\t\terr = -EINVAL;\n\t\tf2fs_warn(sbi, \"disabling checkpoint not compatible with read-only\");\n\t\tgoto restore_opts;\n\t}\n\n\t \n\tif ((*flags & SB_RDONLY) ||\n\t\t\t(F2FS_OPTION(sbi).bggc_mode == BGGC_MODE_OFF &&\n\t\t\t!test_opt(sbi, GC_MERGE))) {\n\t\tif (sbi->gc_thread) {\n\t\t\tf2fs_stop_gc_thread(sbi);\n\t\t\tneed_restart_gc = true;\n\t\t}\n\t} else if (!sbi->gc_thread) {\n\t\terr = f2fs_start_gc_thread(sbi);\n\t\tif (err)\n\t\t\tgoto restore_opts;\n\t\tneed_stop_gc = true;\n\t}\n\n\tif (*flags & SB_RDONLY) {\n\t\tsync_inodes_sb(sb);\n\n\t\tset_sbi_flag(sbi, SBI_IS_DIRTY);\n\t\tset_sbi_flag(sbi, SBI_IS_CLOSE);\n\t\tf2fs_sync_fs(sb, 1);\n\t\tclear_sbi_flag(sbi, SBI_IS_CLOSE);\n\t}\n\n\tif ((*flags & SB_RDONLY) || test_opt(sbi, DISABLE_CHECKPOINT) ||\n\t\t\t!test_opt(sbi, MERGE_CHECKPOINT)) {\n\t\tf2fs_stop_ckpt_thread(sbi);\n\t\tneed_restart_ckpt = true;\n\t} else {\n\t\t \n\t\tf2fs_flush_ckpt_thread(sbi);\n\n\t\terr = f2fs_start_ckpt_thread(sbi);\n\t\tif (err) {\n\t\t\tf2fs_err(sbi,\n\t\t\t    \"Failed to start F2FS issue_checkpoint_thread (%d)\",\n\t\t\t    err);\n\t\t\tgoto restore_gc;\n\t\t}\n\t\tneed_stop_ckpt = true;\n\t}\n\n\t \n\tif ((*flags & SB_RDONLY) || !test_opt(sbi, FLUSH_MERGE)) {\n\t\tclear_opt(sbi, FLUSH_MERGE);\n\t\tf2fs_destroy_flush_cmd_control(sbi, false);\n\t\tneed_restart_flush = true;\n\t} else {\n\t\terr = f2fs_create_flush_cmd_control(sbi);\n\t\tif (err)\n\t\t\tgoto restore_ckpt;\n\t\tneed_stop_flush = true;\n\t}\n\n\tif (no_discard == !!test_opt(sbi, DISCARD)) {\n\t\tif (test_opt(sbi, DISCARD)) {\n\t\t\terr = f2fs_start_discard_thread(sbi);\n\t\t\tif (err)\n\t\t\t\tgoto restore_flush;\n\t\t\tneed_stop_discard = true;\n\t\t} else {\n\t\t\tf2fs_stop_discard_thread(sbi);\n\t\t\tf2fs_issue_discard_timeout(sbi);\n\t\t\tneed_restart_discard = true;\n\t\t}\n\t}\n\n\tif (enable_checkpoint == !!test_opt(sbi, DISABLE_CHECKPOINT)) {\n\t\tif (test_opt(sbi, DISABLE_CHECKPOINT)) {\n\t\t\terr = f2fs_disable_checkpoint(sbi);\n\t\t\tif (err)\n\t\t\t\tgoto restore_discard;\n\t\t} else {\n\t\t\tf2fs_enable_checkpoint(sbi);\n\t\t}\n\t}\n\nskip:\n#ifdef CONFIG_QUOTA\n\t \n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tkfree(org_mount_opt.s_qf_names[i]);\n#endif\n\t \n\tsb->s_flags = (sb->s_flags & ~SB_POSIXACL) |\n\t\t(test_opt(sbi, POSIX_ACL) ? SB_POSIXACL : 0);\n\n\tlimit_reserve_root(sbi);\n\tadjust_unusable_cap_perc(sbi);\n\t*flags = (*flags & ~SB_LAZYTIME) | (sb->s_flags & SB_LAZYTIME);\n\treturn 0;\nrestore_discard:\n\tif (need_restart_discard) {\n\t\tif (f2fs_start_discard_thread(sbi))\n\t\t\tf2fs_warn(sbi, \"discard has been stopped\");\n\t} else if (need_stop_discard) {\n\t\tf2fs_stop_discard_thread(sbi);\n\t}\nrestore_flush:\n\tif (need_restart_flush) {\n\t\tif (f2fs_create_flush_cmd_control(sbi))\n\t\t\tf2fs_warn(sbi, \"background flush thread has stopped\");\n\t} else if (need_stop_flush) {\n\t\tclear_opt(sbi, FLUSH_MERGE);\n\t\tf2fs_destroy_flush_cmd_control(sbi, false);\n\t}\nrestore_ckpt:\n\tif (need_restart_ckpt) {\n\t\tif (f2fs_start_ckpt_thread(sbi))\n\t\t\tf2fs_warn(sbi, \"background ckpt thread has stopped\");\n\t} else if (need_stop_ckpt) {\n\t\tf2fs_stop_ckpt_thread(sbi);\n\t}\nrestore_gc:\n\tif (need_restart_gc) {\n\t\tif (f2fs_start_gc_thread(sbi))\n\t\t\tf2fs_warn(sbi, \"background gc thread has stopped\");\n\t} else if (need_stop_gc) {\n\t\tf2fs_stop_gc_thread(sbi);\n\t}\nrestore_opts:\n#ifdef CONFIG_QUOTA\n\tF2FS_OPTION(sbi).s_jquota_fmt = org_mount_opt.s_jquota_fmt;\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tkfree(F2FS_OPTION(sbi).s_qf_names[i]);\n\t\tF2FS_OPTION(sbi).s_qf_names[i] = org_mount_opt.s_qf_names[i];\n\t}\n#endif\n\tsbi->mount_opt = org_mount_opt;\n\tsb->s_flags = old_sb_flags;\n\treturn err;\n}\n\n#ifdef CONFIG_QUOTA\nstatic bool f2fs_need_recovery(struct f2fs_sb_info *sbi)\n{\n\t \n\tif (is_set_ckpt_flags(sbi, CP_ORPHAN_PRESENT_FLAG))\n\t\treturn true;\n\t \n\tif (test_opt(sbi, DISABLE_ROLL_FORWARD))\n\t\treturn false;\n\tif (test_opt(sbi, NORECOVERY))\n\t\treturn false;\n\treturn !is_set_ckpt_flags(sbi, CP_UMOUNT_FLAG);\n}\n\nstatic bool f2fs_recover_quota_begin(struct f2fs_sb_info *sbi)\n{\n\tbool readonly = f2fs_readonly(sbi->sb);\n\n\tif (!f2fs_need_recovery(sbi))\n\t\treturn false;\n\n\t \n\tif (f2fs_hw_is_readonly(sbi))\n\t\treturn false;\n\n\tif (readonly) {\n\t\tsbi->sb->s_flags &= ~SB_RDONLY;\n\t\tset_sbi_flag(sbi, SBI_IS_WRITABLE);\n\t}\n\n\t \n\treturn f2fs_enable_quota_files(sbi, readonly);\n}\n\nstatic void f2fs_recover_quota_end(struct f2fs_sb_info *sbi,\n\t\t\t\t\t\tbool quota_enabled)\n{\n\tif (quota_enabled)\n\t\tf2fs_quota_off_umount(sbi->sb);\n\n\tif (is_sbi_flag_set(sbi, SBI_IS_WRITABLE)) {\n\t\tclear_sbi_flag(sbi, SBI_IS_WRITABLE);\n\t\tsbi->sb->s_flags |= SB_RDONLY;\n\t}\n}\n\n \nstatic ssize_t f2fs_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\tstruct address_space *mapping = inode->i_mapping;\n\tblock_t blkidx = F2FS_BYTES_TO_BLK(off);\n\tint offset = off & (sb->s_blocksize - 1);\n\tint tocopy;\n\tsize_t toread;\n\tloff_t i_size = i_size_read(inode);\n\tstruct page *page;\n\n\tif (off > i_size)\n\t\treturn 0;\n\n\tif (off + len > i_size)\n\t\tlen = i_size - off;\n\ttoread = len;\n\twhile (toread > 0) {\n\t\ttocopy = min_t(unsigned long, sb->s_blocksize - offset, toread);\nrepeat:\n\t\tpage = read_cache_page_gfp(mapping, blkidx, GFP_NOFS);\n\t\tif (IS_ERR(page)) {\n\t\t\tif (PTR_ERR(page) == -ENOMEM) {\n\t\t\t\tmemalloc_retry_wait(GFP_NOFS);\n\t\t\t\tgoto repeat;\n\t\t\t}\n\t\t\tset_sbi_flag(F2FS_SB(sb), SBI_QUOTA_NEED_REPAIR);\n\t\t\treturn PTR_ERR(page);\n\t\t}\n\n\t\tlock_page(page);\n\n\t\tif (unlikely(page->mapping != mapping)) {\n\t\t\tf2fs_put_page(page, 1);\n\t\t\tgoto repeat;\n\t\t}\n\t\tif (unlikely(!PageUptodate(page))) {\n\t\t\tf2fs_put_page(page, 1);\n\t\t\tset_sbi_flag(F2FS_SB(sb), SBI_QUOTA_NEED_REPAIR);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tmemcpy_from_page(data, page, offset, tocopy);\n\t\tf2fs_put_page(page, 1);\n\n\t\toffset = 0;\n\t\ttoread -= tocopy;\n\t\tdata += tocopy;\n\t\tblkidx++;\n\t}\n\treturn len;\n}\n\n \nstatic ssize_t f2fs_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\tstruct address_space *mapping = inode->i_mapping;\n\tconst struct address_space_operations *a_ops = mapping->a_ops;\n\tint offset = off & (sb->s_blocksize - 1);\n\tsize_t towrite = len;\n\tstruct page *page;\n\tvoid *fsdata = NULL;\n\tint err = 0;\n\tint tocopy;\n\n\twhile (towrite > 0) {\n\t\ttocopy = min_t(unsigned long, sb->s_blocksize - offset,\n\t\t\t\t\t\t\t\ttowrite);\nretry:\n\t\terr = a_ops->write_begin(NULL, mapping, off, tocopy,\n\t\t\t\t\t\t\t&page, &fsdata);\n\t\tif (unlikely(err)) {\n\t\t\tif (err == -ENOMEM) {\n\t\t\t\tf2fs_io_schedule_timeout(DEFAULT_IO_TIMEOUT);\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tset_sbi_flag(F2FS_SB(sb), SBI_QUOTA_NEED_REPAIR);\n\t\t\tbreak;\n\t\t}\n\n\t\tmemcpy_to_page(page, offset, data, tocopy);\n\n\t\ta_ops->write_end(NULL, mapping, off, tocopy, tocopy,\n\t\t\t\t\t\tpage, fsdata);\n\t\toffset = 0;\n\t\ttowrite -= tocopy;\n\t\toff += tocopy;\n\t\tdata += tocopy;\n\t\tcond_resched();\n\t}\n\n\tif (len == towrite)\n\t\treturn err;\n\tinode->i_mtime = inode_set_ctime_current(inode);\n\tf2fs_mark_inode_dirty_sync(inode, false);\n\treturn len - towrite;\n}\n\nint f2fs_dquot_initialize(struct inode *inode)\n{\n\tif (time_to_inject(F2FS_I_SB(inode), FAULT_DQUOT_INIT))\n\t\treturn -ESRCH;\n\n\treturn dquot_initialize(inode);\n}\n\nstatic struct dquot **f2fs_get_dquots(struct inode *inode)\n{\n\treturn F2FS_I(inode)->i_dquot;\n}\n\nstatic qsize_t *f2fs_get_reserved_space(struct inode *inode)\n{\n\treturn &F2FS_I(inode)->i_reserved_quota;\n}\n\nstatic int f2fs_quota_on_mount(struct f2fs_sb_info *sbi, int type)\n{\n\tif (is_set_ckpt_flags(sbi, CP_QUOTA_NEED_FSCK_FLAG)) {\n\t\tf2fs_err(sbi, \"quota sysfile may be corrupted, skip loading it\");\n\t\treturn 0;\n\t}\n\n\treturn dquot_quota_on_mount(sbi->sb, F2FS_OPTION(sbi).s_qf_names[type],\n\t\t\t\t\tF2FS_OPTION(sbi).s_jquota_fmt, type);\n}\n\nint f2fs_enable_quota_files(struct f2fs_sb_info *sbi, bool rdonly)\n{\n\tint enabled = 0;\n\tint i, err;\n\n\tif (f2fs_sb_has_quota_ino(sbi) && rdonly) {\n\t\terr = f2fs_enable_quotas(sbi->sb);\n\t\tif (err) {\n\t\t\tf2fs_err(sbi, \"Cannot turn on quota_ino: %d\", err);\n\t\t\treturn 0;\n\t\t}\n\t\treturn 1;\n\t}\n\n\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\tif (F2FS_OPTION(sbi).s_qf_names[i]) {\n\t\t\terr = f2fs_quota_on_mount(sbi, i);\n\t\t\tif (!err) {\n\t\t\t\tenabled = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tf2fs_err(sbi, \"Cannot turn on quotas: %d on %d\",\n\t\t\t\t err, i);\n\t\t}\n\t}\n\treturn enabled;\n}\n\nstatic int f2fs_quota_enable(struct super_block *sb, int type, int format_id,\n\t\t\t     unsigned int flags)\n{\n\tstruct inode *qf_inode;\n\tunsigned long qf_inum;\n\tunsigned long qf_flag = F2FS_QUOTA_DEFAULT_FL;\n\tint err;\n\n\tBUG_ON(!f2fs_sb_has_quota_ino(F2FS_SB(sb)));\n\n\tqf_inum = f2fs_qf_ino(sb, type);\n\tif (!qf_inum)\n\t\treturn -EPERM;\n\n\tqf_inode = f2fs_iget(sb, qf_inum);\n\tif (IS_ERR(qf_inode)) {\n\t\tf2fs_err(F2FS_SB(sb), \"Bad quota inode %u:%lu\", type, qf_inum);\n\t\treturn PTR_ERR(qf_inode);\n\t}\n\n\t \n\tinode_lock(qf_inode);\n\tqf_inode->i_flags |= S_NOQUOTA;\n\n\tif ((F2FS_I(qf_inode)->i_flags & qf_flag) != qf_flag) {\n\t\tF2FS_I(qf_inode)->i_flags |= qf_flag;\n\t\tf2fs_set_inode_flags(qf_inode);\n\t}\n\tinode_unlock(qf_inode);\n\n\terr = dquot_load_quota_inode(qf_inode, type, format_id, flags);\n\tiput(qf_inode);\n\treturn err;\n}\n\nstatic int f2fs_enable_quotas(struct super_block *sb)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tint type, err = 0;\n\tunsigned long qf_inum;\n\tbool quota_mopt[MAXQUOTAS] = {\n\t\ttest_opt(sbi, USRQUOTA),\n\t\ttest_opt(sbi, GRPQUOTA),\n\t\ttest_opt(sbi, PRJQUOTA),\n\t};\n\n\tif (is_set_ckpt_flags(F2FS_SB(sb), CP_QUOTA_NEED_FSCK_FLAG)) {\n\t\tf2fs_err(sbi, \"quota file may be corrupted, skip loading it\");\n\t\treturn 0;\n\t}\n\n\tsb_dqopt(sb)->flags |= DQUOT_QUOTA_SYS_FILE;\n\n\tfor (type = 0; type < MAXQUOTAS; type++) {\n\t\tqf_inum = f2fs_qf_ino(sb, type);\n\t\tif (qf_inum) {\n\t\t\terr = f2fs_quota_enable(sb, type, QFMT_VFS_V1,\n\t\t\t\tDQUOT_USAGE_ENABLED |\n\t\t\t\t(quota_mopt[type] ? DQUOT_LIMITS_ENABLED : 0));\n\t\t\tif (err) {\n\t\t\t\tf2fs_err(sbi, \"Failed to enable quota tracking (type=%d, err=%d). Please run fsck to fix.\",\n\t\t\t\t\t type, err);\n\t\t\t\tfor (type--; type >= 0; type--)\n\t\t\t\t\tdquot_quota_off(sb, type);\n\t\t\t\tset_sbi_flag(F2FS_SB(sb),\n\t\t\t\t\t\tSBI_QUOTA_NEED_REPAIR);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int f2fs_quota_sync_file(struct f2fs_sb_info *sbi, int type)\n{\n\tstruct quota_info *dqopt = sb_dqopt(sbi->sb);\n\tstruct address_space *mapping = dqopt->files[type]->i_mapping;\n\tint ret = 0;\n\n\tret = dquot_writeback_dquots(sbi->sb, type);\n\tif (ret)\n\t\tgoto out;\n\n\tret = filemap_fdatawrite(mapping);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tif (is_journalled_quota(sbi))\n\t\tgoto out;\n\n\tret = filemap_fdatawait(mapping);\n\n\ttruncate_inode_pages(&dqopt->files[type]->i_data, 0);\nout:\n\tif (ret)\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\treturn ret;\n}\n\nint f2fs_quota_sync(struct super_block *sb, int type)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct quota_info *dqopt = sb_dqopt(sb);\n\tint cnt;\n\tint ret = 0;\n\n\t \n\tfor (cnt = 0; cnt < MAXQUOTAS; cnt++) {\n\n\t\tif (type != -1 && cnt != type)\n\t\t\tcontinue;\n\n\t\tif (!sb_has_quota_active(sb, cnt))\n\t\t\tcontinue;\n\n\t\tif (!f2fs_sb_has_quota_ino(sbi))\n\t\t\tinode_lock(dqopt->files[cnt]);\n\n\t\t \n\t\tf2fs_lock_op(sbi);\n\t\tf2fs_down_read(&sbi->quota_sem);\n\n\t\tret = f2fs_quota_sync_file(sbi, cnt);\n\n\t\tf2fs_up_read(&sbi->quota_sem);\n\t\tf2fs_unlock_op(sbi);\n\n\t\tif (!f2fs_sb_has_quota_ino(sbi))\n\t\t\tinode_unlock(dqopt->files[cnt]);\n\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\nstatic int f2fs_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t\t\t\t\tconst struct path *path)\n{\n\tstruct inode *inode;\n\tint err;\n\n\t \n\tif (f2fs_sb_has_quota_ino(F2FS_SB(sb))) {\n\t\tf2fs_err(F2FS_SB(sb), \"quota sysfile already exists\");\n\t\treturn -EBUSY;\n\t}\n\n\tif (path->dentry->d_sb != sb)\n\t\treturn -EXDEV;\n\n\terr = f2fs_quota_sync(sb, type);\n\tif (err)\n\t\treturn err;\n\n\tinode = d_inode(path->dentry);\n\n\terr = filemap_fdatawrite(inode->i_mapping);\n\tif (err)\n\t\treturn err;\n\n\terr = filemap_fdatawait(inode->i_mapping);\n\tif (err)\n\t\treturn err;\n\n\terr = dquot_quota_on(sb, type, format_id, path);\n\tif (err)\n\t\treturn err;\n\n\tinode_lock(inode);\n\tF2FS_I(inode)->i_flags |= F2FS_QUOTA_DEFAULT_FL;\n\tf2fs_set_inode_flags(inode);\n\tinode_unlock(inode);\n\tf2fs_mark_inode_dirty_sync(inode, false);\n\n\treturn 0;\n}\n\nstatic int __f2fs_quota_off(struct super_block *sb, int type)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\tint err;\n\n\tif (!inode || !igrab(inode))\n\t\treturn dquot_quota_off(sb, type);\n\n\terr = f2fs_quota_sync(sb, type);\n\tif (err)\n\t\tgoto out_put;\n\n\terr = dquot_quota_off(sb, type);\n\tif (err || f2fs_sb_has_quota_ino(F2FS_SB(sb)))\n\t\tgoto out_put;\n\n\tinode_lock(inode);\n\tF2FS_I(inode)->i_flags &= ~F2FS_QUOTA_DEFAULT_FL;\n\tf2fs_set_inode_flags(inode);\n\tinode_unlock(inode);\n\tf2fs_mark_inode_dirty_sync(inode, false);\nout_put:\n\tiput(inode);\n\treturn err;\n}\n\nstatic int f2fs_quota_off(struct super_block *sb, int type)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tint err;\n\n\terr = __f2fs_quota_off(sb, type);\n\n\t \n\tif (is_journalled_quota(sbi))\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\treturn err;\n}\n\nvoid f2fs_quota_off_umount(struct super_block *sb)\n{\n\tint type;\n\tint err;\n\n\tfor (type = 0; type < MAXQUOTAS; type++) {\n\t\terr = __f2fs_quota_off(sb, type);\n\t\tif (err) {\n\t\t\tint ret = dquot_quota_off(sb, type);\n\n\t\t\tf2fs_err(F2FS_SB(sb), \"Fail to turn off disk quota (type: %d, err: %d, ret:%d), Please run fsck to fix it.\",\n\t\t\t\t type, err, ret);\n\t\t\tset_sbi_flag(F2FS_SB(sb), SBI_QUOTA_NEED_REPAIR);\n\t\t}\n\t}\n\t \n\tsync_filesystem(sb);\n}\n\nstatic void f2fs_truncate_quota_inode_pages(struct super_block *sb)\n{\n\tstruct quota_info *dqopt = sb_dqopt(sb);\n\tint type;\n\n\tfor (type = 0; type < MAXQUOTAS; type++) {\n\t\tif (!dqopt->files[type])\n\t\t\tcontinue;\n\t\tf2fs_inode_synced(dqopt->files[type]);\n\t}\n}\n\nstatic int f2fs_dquot_commit(struct dquot *dquot)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(dquot->dq_sb);\n\tint ret;\n\n\tf2fs_down_read_nested(&sbi->quota_sem, SINGLE_DEPTH_NESTING);\n\tret = dquot_commit(dquot);\n\tif (ret < 0)\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\tf2fs_up_read(&sbi->quota_sem);\n\treturn ret;\n}\n\nstatic int f2fs_dquot_acquire(struct dquot *dquot)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(dquot->dq_sb);\n\tint ret;\n\n\tf2fs_down_read(&sbi->quota_sem);\n\tret = dquot_acquire(dquot);\n\tif (ret < 0)\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\tf2fs_up_read(&sbi->quota_sem);\n\treturn ret;\n}\n\nstatic int f2fs_dquot_release(struct dquot *dquot)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(dquot->dq_sb);\n\tint ret = dquot_release(dquot);\n\n\tif (ret < 0)\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\treturn ret;\n}\n\nstatic int f2fs_dquot_mark_dquot_dirty(struct dquot *dquot)\n{\n\tstruct super_block *sb = dquot->dq_sb;\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tint ret = dquot_mark_dquot_dirty(dquot);\n\n\t \n\tif (is_journalled_quota(sbi))\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_FLUSH);\n\n\treturn ret;\n}\n\nstatic int f2fs_dquot_commit_info(struct super_block *sb, int type)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tint ret = dquot_commit_info(sb, type);\n\n\tif (ret < 0)\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\treturn ret;\n}\n\nstatic int f2fs_get_projid(struct inode *inode, kprojid_t *projid)\n{\n\t*projid = F2FS_I(inode)->i_projid;\n\treturn 0;\n}\n\nstatic const struct dquot_operations f2fs_quota_operations = {\n\t.get_reserved_space = f2fs_get_reserved_space,\n\t.write_dquot\t= f2fs_dquot_commit,\n\t.acquire_dquot\t= f2fs_dquot_acquire,\n\t.release_dquot\t= f2fs_dquot_release,\n\t.mark_dirty\t= f2fs_dquot_mark_dquot_dirty,\n\t.write_info\t= f2fs_dquot_commit_info,\n\t.alloc_dquot\t= dquot_alloc,\n\t.destroy_dquot\t= dquot_destroy,\n\t.get_projid\t= f2fs_get_projid,\n\t.get_next_id\t= dquot_get_next_id,\n};\n\nstatic const struct quotactl_ops f2fs_quotactl_ops = {\n\t.quota_on\t= f2fs_quota_on,\n\t.quota_off\t= f2fs_quota_off,\n\t.quota_sync\t= f2fs_quota_sync,\n\t.get_state\t= dquot_get_state,\n\t.set_info\t= dquot_set_dqinfo,\n\t.get_dqblk\t= dquot_get_dqblk,\n\t.set_dqblk\t= dquot_set_dqblk,\n\t.get_nextdqblk\t= dquot_get_next_dqblk,\n};\n#else\nint f2fs_dquot_initialize(struct inode *inode)\n{\n\treturn 0;\n}\n\nint f2fs_quota_sync(struct super_block *sb, int type)\n{\n\treturn 0;\n}\n\nvoid f2fs_quota_off_umount(struct super_block *sb)\n{\n}\n#endif\n\nstatic const struct super_operations f2fs_sops = {\n\t.alloc_inode\t= f2fs_alloc_inode,\n\t.free_inode\t= f2fs_free_inode,\n\t.drop_inode\t= f2fs_drop_inode,\n\t.write_inode\t= f2fs_write_inode,\n\t.dirty_inode\t= f2fs_dirty_inode,\n\t.show_options\t= f2fs_show_options,\n#ifdef CONFIG_QUOTA\n\t.quota_read\t= f2fs_quota_read,\n\t.quota_write\t= f2fs_quota_write,\n\t.get_dquots\t= f2fs_get_dquots,\n#endif\n\t.evict_inode\t= f2fs_evict_inode,\n\t.put_super\t= f2fs_put_super,\n\t.sync_fs\t= f2fs_sync_fs,\n\t.freeze_fs\t= f2fs_freeze,\n\t.unfreeze_fs\t= f2fs_unfreeze,\n\t.statfs\t\t= f2fs_statfs,\n\t.remount_fs\t= f2fs_remount,\n};\n\n#ifdef CONFIG_FS_ENCRYPTION\nstatic int f2fs_get_context(struct inode *inode, void *ctx, size_t len)\n{\n\treturn f2fs_getxattr(inode, F2FS_XATTR_INDEX_ENCRYPTION,\n\t\t\t\tF2FS_XATTR_NAME_ENCRYPTION_CONTEXT,\n\t\t\t\tctx, len, NULL);\n}\n\nstatic int f2fs_set_context(struct inode *inode, const void *ctx, size_t len,\n\t\t\t\t\t\t\tvoid *fs_data)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\t \n\tif (f2fs_sb_has_lost_found(sbi) &&\n\t\t\tinode->i_ino == F2FS_ROOT_INO(sbi))\n\t\treturn -EPERM;\n\n\treturn f2fs_setxattr(inode, F2FS_XATTR_INDEX_ENCRYPTION,\n\t\t\t\tF2FS_XATTR_NAME_ENCRYPTION_CONTEXT,\n\t\t\t\tctx, len, fs_data, XATTR_CREATE);\n}\n\nstatic const union fscrypt_policy *f2fs_get_dummy_policy(struct super_block *sb)\n{\n\treturn F2FS_OPTION(F2FS_SB(sb)).dummy_enc_policy.policy;\n}\n\nstatic bool f2fs_has_stable_inodes(struct super_block *sb)\n{\n\treturn true;\n}\n\nstatic void f2fs_get_ino_and_lblk_bits(struct super_block *sb,\n\t\t\t\t       int *ino_bits_ret, int *lblk_bits_ret)\n{\n\t*ino_bits_ret = 8 * sizeof(nid_t);\n\t*lblk_bits_ret = 8 * sizeof(block_t);\n}\n\nstatic struct block_device **f2fs_get_devices(struct super_block *sb,\n\t\t\t\t\t      unsigned int *num_devs)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct block_device **devs;\n\tint i;\n\n\tif (!f2fs_is_multi_device(sbi))\n\t\treturn NULL;\n\n\tdevs = kmalloc_array(sbi->s_ndevs, sizeof(*devs), GFP_KERNEL);\n\tif (!devs)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor (i = 0; i < sbi->s_ndevs; i++)\n\t\tdevs[i] = FDEV(i).bdev;\n\t*num_devs = sbi->s_ndevs;\n\treturn devs;\n}\n\nstatic const struct fscrypt_operations f2fs_cryptops = {\n\t.key_prefix\t\t= \"f2fs:\",\n\t.get_context\t\t= f2fs_get_context,\n\t.set_context\t\t= f2fs_set_context,\n\t.get_dummy_policy\t= f2fs_get_dummy_policy,\n\t.empty_dir\t\t= f2fs_empty_dir,\n\t.has_stable_inodes\t= f2fs_has_stable_inodes,\n\t.get_ino_and_lblk_bits\t= f2fs_get_ino_and_lblk_bits,\n\t.get_devices\t\t= f2fs_get_devices,\n};\n#endif\n\nstatic struct inode *f2fs_nfs_get_inode(struct super_block *sb,\n\t\tu64 ino, u32 generation)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct inode *inode;\n\n\tif (f2fs_check_nid_range(sbi, ino))\n\t\treturn ERR_PTR(-ESTALE);\n\n\t \n\tinode = f2fs_iget(sb, ino);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\tif (unlikely(generation && inode->i_generation != generation)) {\n\t\t \n\t\tiput(inode);\n\t\treturn ERR_PTR(-ESTALE);\n\t}\n\treturn inode;\n}\n\nstatic struct dentry *f2fs_fh_to_dentry(struct super_block *sb, struct fid *fid,\n\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_dentry(sb, fid, fh_len, fh_type,\n\t\t\t\t    f2fs_nfs_get_inode);\n}\n\nstatic struct dentry *f2fs_fh_to_parent(struct super_block *sb, struct fid *fid,\n\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_parent(sb, fid, fh_len, fh_type,\n\t\t\t\t    f2fs_nfs_get_inode);\n}\n\nstatic const struct export_operations f2fs_export_ops = {\n\t.fh_to_dentry = f2fs_fh_to_dentry,\n\t.fh_to_parent = f2fs_fh_to_parent,\n\t.get_parent = f2fs_get_parent,\n};\n\nloff_t max_file_blocks(struct inode *inode)\n{\n\tloff_t result = 0;\n\tloff_t leaf_count;\n\n\t \n\n\tif (inode && f2fs_compressed_file(inode))\n\t\tleaf_count = ADDRS_PER_BLOCK(inode);\n\telse\n\t\tleaf_count = DEF_ADDRS_PER_BLOCK;\n\n\t \n\tresult += (leaf_count * 2);\n\n\t \n\tleaf_count *= NIDS_PER_BLOCK;\n\tresult += (leaf_count * 2);\n\n\t \n\tleaf_count *= NIDS_PER_BLOCK;\n\tresult += leaf_count;\n\n\treturn result;\n}\n\nstatic int __f2fs_commit_super(struct buffer_head *bh,\n\t\t\tstruct f2fs_super_block *super)\n{\n\tlock_buffer(bh);\n\tif (super)\n\t\tmemcpy(bh->b_data + F2FS_SUPER_OFFSET, super, sizeof(*super));\n\tset_buffer_dirty(bh);\n\tunlock_buffer(bh);\n\n\t \n\treturn __sync_dirty_buffer(bh, REQ_SYNC | REQ_PREFLUSH | REQ_FUA);\n}\n\nstatic inline bool sanity_check_area_boundary(struct f2fs_sb_info *sbi,\n\t\t\t\t\tstruct buffer_head *bh)\n{\n\tstruct f2fs_super_block *raw_super = (struct f2fs_super_block *)\n\t\t\t\t\t(bh->b_data + F2FS_SUPER_OFFSET);\n\tstruct super_block *sb = sbi->sb;\n\tu32 segment0_blkaddr = le32_to_cpu(raw_super->segment0_blkaddr);\n\tu32 cp_blkaddr = le32_to_cpu(raw_super->cp_blkaddr);\n\tu32 sit_blkaddr = le32_to_cpu(raw_super->sit_blkaddr);\n\tu32 nat_blkaddr = le32_to_cpu(raw_super->nat_blkaddr);\n\tu32 ssa_blkaddr = le32_to_cpu(raw_super->ssa_blkaddr);\n\tu32 main_blkaddr = le32_to_cpu(raw_super->main_blkaddr);\n\tu32 segment_count_ckpt = le32_to_cpu(raw_super->segment_count_ckpt);\n\tu32 segment_count_sit = le32_to_cpu(raw_super->segment_count_sit);\n\tu32 segment_count_nat = le32_to_cpu(raw_super->segment_count_nat);\n\tu32 segment_count_ssa = le32_to_cpu(raw_super->segment_count_ssa);\n\tu32 segment_count_main = le32_to_cpu(raw_super->segment_count_main);\n\tu32 segment_count = le32_to_cpu(raw_super->segment_count);\n\tu32 log_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n\tu64 main_end_blkaddr = main_blkaddr +\n\t\t\t\t(segment_count_main << log_blocks_per_seg);\n\tu64 seg_end_blkaddr = segment0_blkaddr +\n\t\t\t\t(segment_count << log_blocks_per_seg);\n\n\tif (segment0_blkaddr != cp_blkaddr) {\n\t\tf2fs_info(sbi, \"Mismatch start address, segment0(%u) cp_blkaddr(%u)\",\n\t\t\t  segment0_blkaddr, cp_blkaddr);\n\t\treturn true;\n\t}\n\n\tif (cp_blkaddr + (segment_count_ckpt << log_blocks_per_seg) !=\n\t\t\t\t\t\t\tsit_blkaddr) {\n\t\tf2fs_info(sbi, \"Wrong CP boundary, start(%u) end(%u) blocks(%u)\",\n\t\t\t  cp_blkaddr, sit_blkaddr,\n\t\t\t  segment_count_ckpt << log_blocks_per_seg);\n\t\treturn true;\n\t}\n\n\tif (sit_blkaddr + (segment_count_sit << log_blocks_per_seg) !=\n\t\t\t\t\t\t\tnat_blkaddr) {\n\t\tf2fs_info(sbi, \"Wrong SIT boundary, start(%u) end(%u) blocks(%u)\",\n\t\t\t  sit_blkaddr, nat_blkaddr,\n\t\t\t  segment_count_sit << log_blocks_per_seg);\n\t\treturn true;\n\t}\n\n\tif (nat_blkaddr + (segment_count_nat << log_blocks_per_seg) !=\n\t\t\t\t\t\t\tssa_blkaddr) {\n\t\tf2fs_info(sbi, \"Wrong NAT boundary, start(%u) end(%u) blocks(%u)\",\n\t\t\t  nat_blkaddr, ssa_blkaddr,\n\t\t\t  segment_count_nat << log_blocks_per_seg);\n\t\treturn true;\n\t}\n\n\tif (ssa_blkaddr + (segment_count_ssa << log_blocks_per_seg) !=\n\t\t\t\t\t\t\tmain_blkaddr) {\n\t\tf2fs_info(sbi, \"Wrong SSA boundary, start(%u) end(%u) blocks(%u)\",\n\t\t\t  ssa_blkaddr, main_blkaddr,\n\t\t\t  segment_count_ssa << log_blocks_per_seg);\n\t\treturn true;\n\t}\n\n\tif (main_end_blkaddr > seg_end_blkaddr) {\n\t\tf2fs_info(sbi, \"Wrong MAIN_AREA boundary, start(%u) end(%llu) block(%u)\",\n\t\t\t  main_blkaddr, seg_end_blkaddr,\n\t\t\t  segment_count_main << log_blocks_per_seg);\n\t\treturn true;\n\t} else if (main_end_blkaddr < seg_end_blkaddr) {\n\t\tint err = 0;\n\t\tchar *res;\n\n\t\t \n\t\traw_super->segment_count = cpu_to_le32((main_end_blkaddr -\n\t\t\t\tsegment0_blkaddr) >> log_blocks_per_seg);\n\n\t\tif (f2fs_readonly(sb) || f2fs_hw_is_readonly(sbi)) {\n\t\t\tset_sbi_flag(sbi, SBI_NEED_SB_WRITE);\n\t\t\tres = \"internally\";\n\t\t} else {\n\t\t\terr = __f2fs_commit_super(bh, NULL);\n\t\t\tres = err ? \"failed\" : \"done\";\n\t\t}\n\t\tf2fs_info(sbi, \"Fix alignment : %s, start(%u) end(%llu) block(%u)\",\n\t\t\t  res, main_blkaddr, seg_end_blkaddr,\n\t\t\t  segment_count_main << log_blocks_per_seg);\n\t\tif (err)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic int sanity_check_raw_super(struct f2fs_sb_info *sbi,\n\t\t\t\tstruct buffer_head *bh)\n{\n\tblock_t segment_count, segs_per_sec, secs_per_zone, segment_count_main;\n\tblock_t total_sections, blocks_per_seg;\n\tstruct f2fs_super_block *raw_super = (struct f2fs_super_block *)\n\t\t\t\t\t(bh->b_data + F2FS_SUPER_OFFSET);\n\tsize_t crc_offset = 0;\n\t__u32 crc = 0;\n\n\tif (le32_to_cpu(raw_super->magic) != F2FS_SUPER_MAGIC) {\n\t\tf2fs_info(sbi, \"Magic Mismatch, valid(0x%x) - read(0x%x)\",\n\t\t\t  F2FS_SUPER_MAGIC, le32_to_cpu(raw_super->magic));\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (__F2FS_HAS_FEATURE(raw_super, F2FS_FEATURE_SB_CHKSUM)) {\n\t\tcrc_offset = le32_to_cpu(raw_super->checksum_offset);\n\t\tif (crc_offset !=\n\t\t\toffsetof(struct f2fs_super_block, crc)) {\n\t\t\tf2fs_info(sbi, \"Invalid SB checksum offset: %zu\",\n\t\t\t\t  crc_offset);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t\tcrc = le32_to_cpu(raw_super->crc);\n\t\tif (!f2fs_crc_valid(sbi, crc, raw_super, crc_offset)) {\n\t\t\tf2fs_info(sbi, \"Invalid SB checksum value: %u\", crc);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t}\n\n\t \n\tif (le32_to_cpu(raw_super->log_blocksize) != F2FS_BLKSIZE_BITS) {\n\t\tf2fs_info(sbi, \"Invalid log_blocksize (%u), supports only %u\",\n\t\t\t  le32_to_cpu(raw_super->log_blocksize),\n\t\t\t  F2FS_BLKSIZE_BITS);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t \n\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {\n\t\tf2fs_info(sbi, \"Invalid log blocks per segment (%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_blocks_per_seg));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t \n\tif (le32_to_cpu(raw_super->log_sectorsize) >\n\t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n\t\tle32_to_cpu(raw_super->log_sectorsize) <\n\t\t\t\tF2FS_MIN_LOG_SECTOR_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid log sectorsize (%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_sectorsize));\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (le32_to_cpu(raw_super->log_sectors_per_block) +\n\t\tle32_to_cpu(raw_super->log_sectorsize) !=\n\t\t\tF2FS_MAX_LOG_SECTOR_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid log sectors per block(%u) log sectorsize(%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_sectors_per_block),\n\t\t\t  le32_to_cpu(raw_super->log_sectorsize));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tsegment_count = le32_to_cpu(raw_super->segment_count);\n\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);\n\tsegs_per_sec = le32_to_cpu(raw_super->segs_per_sec);\n\tsecs_per_zone = le32_to_cpu(raw_super->secs_per_zone);\n\ttotal_sections = le32_to_cpu(raw_super->section_count);\n\n\t \n\tblocks_per_seg = BIT(le32_to_cpu(raw_super->log_blocks_per_seg));\n\n\tif (segment_count > F2FS_MAX_SEGMENT ||\n\t\t\t\tsegment_count < F2FS_MIN_SEGMENTS) {\n\t\tf2fs_info(sbi, \"Invalid segment count (%u)\", segment_count);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (total_sections > segment_count_main || total_sections < 1 ||\n\t\t\tsegs_per_sec > segment_count || !segs_per_sec) {\n\t\tf2fs_info(sbi, \"Invalid segment/section count (%u, %u x %u)\",\n\t\t\t  segment_count, total_sections, segs_per_sec);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (segment_count_main != total_sections * segs_per_sec) {\n\t\tf2fs_info(sbi, \"Invalid segment/section count (%u != %u * %u)\",\n\t\t\t  segment_count_main, total_sections, segs_per_sec);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif ((segment_count / segs_per_sec) < total_sections) {\n\t\tf2fs_info(sbi, \"Small segment_count (%u < %u * %u)\",\n\t\t\t  segment_count, segs_per_sec, total_sections);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (segment_count > (le64_to_cpu(raw_super->block_count) >> 9)) {\n\t\tf2fs_info(sbi, \"Wrong segment_count / block_count (%u > %llu)\",\n\t\t\t  segment_count, le64_to_cpu(raw_super->block_count));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (RDEV(0).path[0]) {\n\t\tblock_t dev_seg_count = le32_to_cpu(RDEV(0).total_segments);\n\t\tint i = 1;\n\n\t\twhile (i < MAX_DEVICES && RDEV(i).path[0]) {\n\t\t\tdev_seg_count += le32_to_cpu(RDEV(i).total_segments);\n\t\t\ti++;\n\t\t}\n\t\tif (segment_count != dev_seg_count) {\n\t\t\tf2fs_info(sbi, \"Segment count (%u) mismatch with total segments from devices (%u)\",\n\t\t\t\t\tsegment_count, dev_seg_count);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t} else {\n\t\tif (__F2FS_HAS_FEATURE(raw_super, F2FS_FEATURE_BLKZONED) &&\n\t\t\t\t\t!bdev_is_zoned(sbi->sb->s_bdev)) {\n\t\t\tf2fs_info(sbi, \"Zoned block device path is missing\");\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t}\n\n\tif (secs_per_zone > total_sections || !secs_per_zone) {\n\t\tf2fs_info(sbi, \"Wrong secs_per_zone / total_sections (%u, %u)\",\n\t\t\t  secs_per_zone, total_sections);\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (le32_to_cpu(raw_super->extension_count) > F2FS_MAX_EXTENSION ||\n\t\t\traw_super->hot_ext_count > F2FS_MAX_EXTENSION ||\n\t\t\t(le32_to_cpu(raw_super->extension_count) +\n\t\t\traw_super->hot_ext_count) > F2FS_MAX_EXTENSION) {\n\t\tf2fs_info(sbi, \"Corrupted extension count (%u + %u > %u)\",\n\t\t\t  le32_to_cpu(raw_super->extension_count),\n\t\t\t  raw_super->hot_ext_count,\n\t\t\t  F2FS_MAX_EXTENSION);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (le32_to_cpu(raw_super->cp_payload) >=\n\t\t\t\t(blocks_per_seg - F2FS_CP_PACKS -\n\t\t\t\tNR_CURSEG_PERSIST_TYPE)) {\n\t\tf2fs_info(sbi, \"Insane cp_payload (%u >= %u)\",\n\t\t\t  le32_to_cpu(raw_super->cp_payload),\n\t\t\t  blocks_per_seg - F2FS_CP_PACKS -\n\t\t\t  NR_CURSEG_PERSIST_TYPE);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t \n\tif (le32_to_cpu(raw_super->node_ino) != 1 ||\n\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||\n\t\tle32_to_cpu(raw_super->root_ino) != 3) {\n\t\tf2fs_info(sbi, \"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",\n\t\t\t  le32_to_cpu(raw_super->node_ino),\n\t\t\t  le32_to_cpu(raw_super->meta_ino),\n\t\t\t  le32_to_cpu(raw_super->root_ino));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t \n\tif (sanity_check_area_boundary(sbi, bh))\n\t\treturn -EFSCORRUPTED;\n\n\treturn 0;\n}\n\nint f2fs_sanity_check_ckpt(struct f2fs_sb_info *sbi)\n{\n\tunsigned int total, fsmeta;\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);\n\tunsigned int ovp_segments, reserved_segments;\n\tunsigned int main_segs, blocks_per_seg;\n\tunsigned int sit_segs, nat_segs;\n\tunsigned int sit_bitmap_size, nat_bitmap_size;\n\tunsigned int log_blocks_per_seg;\n\tunsigned int segment_count_main;\n\tunsigned int cp_pack_start_sum, cp_payload;\n\tblock_t user_block_count, valid_user_blocks;\n\tblock_t avail_node_count, valid_node_count;\n\tunsigned int nat_blocks, nat_bits_bytes, nat_bits_blocks;\n\tint i, j;\n\n\ttotal = le32_to_cpu(raw_super->segment_count);\n\tfsmeta = le32_to_cpu(raw_super->segment_count_ckpt);\n\tsit_segs = le32_to_cpu(raw_super->segment_count_sit);\n\tfsmeta += sit_segs;\n\tnat_segs = le32_to_cpu(raw_super->segment_count_nat);\n\tfsmeta += nat_segs;\n\tfsmeta += le32_to_cpu(ckpt->rsvd_segment_count);\n\tfsmeta += le32_to_cpu(raw_super->segment_count_ssa);\n\n\tif (unlikely(fsmeta >= total))\n\t\treturn 1;\n\n\tovp_segments = le32_to_cpu(ckpt->overprov_segment_count);\n\treserved_segments = le32_to_cpu(ckpt->rsvd_segment_count);\n\n\tif (!f2fs_sb_has_readonly(sbi) &&\n\t\t\tunlikely(fsmeta < F2FS_MIN_META_SEGMENTS ||\n\t\t\tovp_segments == 0 || reserved_segments == 0)) {\n\t\tf2fs_err(sbi, \"Wrong layout: check mkfs.f2fs version\");\n\t\treturn 1;\n\t}\n\tuser_block_count = le64_to_cpu(ckpt->user_block_count);\n\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main) +\n\t\t\t(f2fs_sb_has_readonly(sbi) ? 1 : 0);\n\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n\tif (!user_block_count || user_block_count >=\n\t\t\tsegment_count_main << log_blocks_per_seg) {\n\t\tf2fs_err(sbi, \"Wrong user_block_count: %u\",\n\t\t\t user_block_count);\n\t\treturn 1;\n\t}\n\n\tvalid_user_blocks = le64_to_cpu(ckpt->valid_block_count);\n\tif (valid_user_blocks > user_block_count) {\n\t\tf2fs_err(sbi, \"Wrong valid_user_blocks: %u, user_block_count: %u\",\n\t\t\t valid_user_blocks, user_block_count);\n\t\treturn 1;\n\t}\n\n\tvalid_node_count = le32_to_cpu(ckpt->valid_node_count);\n\tavail_node_count = sbi->total_node_count - F2FS_RESERVED_NODE_NUM;\n\tif (valid_node_count > avail_node_count) {\n\t\tf2fs_err(sbi, \"Wrong valid_node_count: %u, avail_node_count: %u\",\n\t\t\t valid_node_count, avail_node_count);\n\t\treturn 1;\n\t}\n\n\tmain_segs = le32_to_cpu(raw_super->segment_count_main);\n\tblocks_per_seg = sbi->blocks_per_seg;\n\n\tfor (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_node_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_node_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\n\t\tif (f2fs_sb_has_readonly(sbi))\n\t\t\tgoto check_data;\n\n\t\tfor (j = i + 1; j < NR_CURSEG_NODE_TYPE; j++) {\n\t\t\tif (le32_to_cpu(ckpt->cur_node_segno[i]) ==\n\t\t\t\tle32_to_cpu(ckpt->cur_node_segno[j])) {\n\t\t\t\tf2fs_err(sbi, \"Node segment (%u, %u) has the same segno: %u\",\n\t\t\t\t\t i, j,\n\t\t\t\t\t le32_to_cpu(ckpt->cur_node_segno[i]));\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\ncheck_data:\n\tfor (i = 0; i < NR_CURSEG_DATA_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_data_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_data_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\n\t\tif (f2fs_sb_has_readonly(sbi))\n\t\t\tgoto skip_cross;\n\n\t\tfor (j = i + 1; j < NR_CURSEG_DATA_TYPE; j++) {\n\t\t\tif (le32_to_cpu(ckpt->cur_data_segno[i]) ==\n\t\t\t\tle32_to_cpu(ckpt->cur_data_segno[j])) {\n\t\t\t\tf2fs_err(sbi, \"Data segment (%u, %u) has the same segno: %u\",\n\t\t\t\t\t i, j,\n\t\t\t\t\t le32_to_cpu(ckpt->cur_data_segno[i]));\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\n\tfor (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {\n\t\tfor (j = 0; j < NR_CURSEG_DATA_TYPE; j++) {\n\t\t\tif (le32_to_cpu(ckpt->cur_node_segno[i]) ==\n\t\t\t\tle32_to_cpu(ckpt->cur_data_segno[j])) {\n\t\t\t\tf2fs_err(sbi, \"Node segment (%u) and Data segment (%u) has the same segno: %u\",\n\t\t\t\t\t i, j,\n\t\t\t\t\t le32_to_cpu(ckpt->cur_node_segno[i]));\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t}\nskip_cross:\n\tsit_bitmap_size = le32_to_cpu(ckpt->sit_ver_bitmap_bytesize);\n\tnat_bitmap_size = le32_to_cpu(ckpt->nat_ver_bitmap_bytesize);\n\n\tif (sit_bitmap_size != ((sit_segs / 2) << log_blocks_per_seg) / 8 ||\n\t\tnat_bitmap_size != ((nat_segs / 2) << log_blocks_per_seg) / 8) {\n\t\tf2fs_err(sbi, \"Wrong bitmap size: sit: %u, nat:%u\",\n\t\t\t sit_bitmap_size, nat_bitmap_size);\n\t\treturn 1;\n\t}\n\n\tcp_pack_start_sum = __start_sum_addr(sbi);\n\tcp_payload = __cp_payload(sbi);\n\tif (cp_pack_start_sum < cp_payload + 1 ||\n\t\tcp_pack_start_sum > blocks_per_seg - 1 -\n\t\t\tNR_CURSEG_PERSIST_TYPE) {\n\t\tf2fs_err(sbi, \"Wrong cp_pack_start_sum: %u\",\n\t\t\t cp_pack_start_sum);\n\t\treturn 1;\n\t}\n\n\tif (__is_set_ckpt_flags(ckpt, CP_LARGE_NAT_BITMAP_FLAG) &&\n\t\tle32_to_cpu(ckpt->checksum_offset) != CP_MIN_CHKSUM_OFFSET) {\n\t\tf2fs_warn(sbi, \"using deprecated layout of large_nat_bitmap, \"\n\t\t\t  \"please run fsck v1.13.0 or higher to repair, chksum_offset: %u, \"\n\t\t\t  \"fixed with patch: \\\"f2fs-tools: relocate chksum_offset for large_nat_bitmap feature\\\"\",\n\t\t\t  le32_to_cpu(ckpt->checksum_offset));\n\t\treturn 1;\n\t}\n\n\tnat_blocks = nat_segs << log_blocks_per_seg;\n\tnat_bits_bytes = nat_blocks / BITS_PER_BYTE;\n\tnat_bits_blocks = F2FS_BLK_ALIGN((nat_bits_bytes << 1) + 8);\n\tif (__is_set_ckpt_flags(ckpt, CP_NAT_BITS_FLAG) &&\n\t\t(cp_payload + F2FS_CP_PACKS +\n\t\tNR_CURSEG_PERSIST_TYPE + nat_bits_blocks >= blocks_per_seg)) {\n\t\tf2fs_warn(sbi, \"Insane cp_payload: %u, nat_bits_blocks: %u)\",\n\t\t\t  cp_payload, nat_bits_blocks);\n\t\treturn 1;\n\t}\n\n\tif (unlikely(f2fs_cp_error(sbi))) {\n\t\tf2fs_err(sbi, \"A bug case: need to run fsck\");\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic void init_sb_info(struct f2fs_sb_info *sbi)\n{\n\tstruct f2fs_super_block *raw_super = sbi->raw_super;\n\tint i;\n\n\tsbi->log_sectors_per_block =\n\t\tle32_to_cpu(raw_super->log_sectors_per_block);\n\tsbi->log_blocksize = le32_to_cpu(raw_super->log_blocksize);\n\tsbi->blocksize = BIT(sbi->log_blocksize);\n\tsbi->log_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n\tsbi->blocks_per_seg = BIT(sbi->log_blocks_per_seg);\n\tsbi->segs_per_sec = le32_to_cpu(raw_super->segs_per_sec);\n\tsbi->secs_per_zone = le32_to_cpu(raw_super->secs_per_zone);\n\tsbi->total_sections = le32_to_cpu(raw_super->section_count);\n\tsbi->total_node_count =\n\t\t(le32_to_cpu(raw_super->segment_count_nat) / 2)\n\t\t\t* sbi->blocks_per_seg * NAT_ENTRY_PER_BLOCK;\n\tF2FS_ROOT_INO(sbi) = le32_to_cpu(raw_super->root_ino);\n\tF2FS_NODE_INO(sbi) = le32_to_cpu(raw_super->node_ino);\n\tF2FS_META_INO(sbi) = le32_to_cpu(raw_super->meta_ino);\n\tsbi->cur_victim_sec = NULL_SECNO;\n\tsbi->gc_mode = GC_NORMAL;\n\tsbi->next_victim_seg[BG_GC] = NULL_SEGNO;\n\tsbi->next_victim_seg[FG_GC] = NULL_SEGNO;\n\tsbi->max_victim_search = DEF_MAX_VICTIM_SEARCH;\n\tsbi->migration_granularity = sbi->segs_per_sec;\n\tsbi->seq_file_ra_mul = MIN_RA_MUL;\n\tsbi->max_fragment_chunk = DEF_FRAGMENT_SIZE;\n\tsbi->max_fragment_hole = DEF_FRAGMENT_SIZE;\n\tspin_lock_init(&sbi->gc_remaining_trials_lock);\n\tatomic64_set(&sbi->current_atomic_write, 0);\n\n\tsbi->dir_level = DEF_DIR_LEVEL;\n\tsbi->interval_time[CP_TIME] = DEF_CP_INTERVAL;\n\tsbi->interval_time[REQ_TIME] = DEF_IDLE_INTERVAL;\n\tsbi->interval_time[DISCARD_TIME] = DEF_IDLE_INTERVAL;\n\tsbi->interval_time[GC_TIME] = DEF_IDLE_INTERVAL;\n\tsbi->interval_time[DISABLE_TIME] = DEF_DISABLE_INTERVAL;\n\tsbi->interval_time[UMOUNT_DISCARD_TIMEOUT] =\n\t\t\t\tDEF_UMOUNT_DISCARD_TIMEOUT;\n\tclear_sbi_flag(sbi, SBI_NEED_FSCK);\n\n\tfor (i = 0; i < NR_COUNT_TYPE; i++)\n\t\tatomic_set(&sbi->nr_pages[i], 0);\n\n\tfor (i = 0; i < META; i++)\n\t\tatomic_set(&sbi->wb_sync_req[i], 0);\n\n\tINIT_LIST_HEAD(&sbi->s_list);\n\tmutex_init(&sbi->umount_mutex);\n\tinit_f2fs_rwsem(&sbi->io_order_lock);\n\tspin_lock_init(&sbi->cp_lock);\n\n\tsbi->dirty_device = 0;\n\tspin_lock_init(&sbi->dev_lock);\n\n\tinit_f2fs_rwsem(&sbi->sb_lock);\n\tinit_f2fs_rwsem(&sbi->pin_sem);\n}\n\nstatic int init_percpu_info(struct f2fs_sb_info *sbi)\n{\n\tint err;\n\n\terr = percpu_counter_init(&sbi->alloc_valid_block_count, 0, GFP_KERNEL);\n\tif (err)\n\t\treturn err;\n\n\terr = percpu_counter_init(&sbi->rf_node_block_count, 0, GFP_KERNEL);\n\tif (err)\n\t\tgoto err_valid_block;\n\n\terr = percpu_counter_init(&sbi->total_valid_inode_count, 0,\n\t\t\t\t\t\t\t\tGFP_KERNEL);\n\tif (err)\n\t\tgoto err_node_block;\n\treturn 0;\n\nerr_node_block:\n\tpercpu_counter_destroy(&sbi->rf_node_block_count);\nerr_valid_block:\n\tpercpu_counter_destroy(&sbi->alloc_valid_block_count);\n\treturn err;\n}\n\n#ifdef CONFIG_BLK_DEV_ZONED\n\nstruct f2fs_report_zones_args {\n\tstruct f2fs_sb_info *sbi;\n\tstruct f2fs_dev_info *dev;\n};\n\nstatic int f2fs_report_zone_cb(struct blk_zone *zone, unsigned int idx,\n\t\t\t      void *data)\n{\n\tstruct f2fs_report_zones_args *rz_args = data;\n\tblock_t unusable_blocks = (zone->len - zone->capacity) >>\n\t\t\t\t\tF2FS_LOG_SECTORS_PER_BLOCK;\n\n\tif (zone->type == BLK_ZONE_TYPE_CONVENTIONAL)\n\t\treturn 0;\n\n\tset_bit(idx, rz_args->dev->blkz_seq);\n\tif (!rz_args->sbi->unusable_blocks_per_sec) {\n\t\trz_args->sbi->unusable_blocks_per_sec = unusable_blocks;\n\t\treturn 0;\n\t}\n\tif (rz_args->sbi->unusable_blocks_per_sec != unusable_blocks) {\n\t\tf2fs_err(rz_args->sbi, \"F2FS supports single zone capacity\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int init_blkz_info(struct f2fs_sb_info *sbi, int devi)\n{\n\tstruct block_device *bdev = FDEV(devi).bdev;\n\tsector_t nr_sectors = bdev_nr_sectors(bdev);\n\tstruct f2fs_report_zones_args rep_zone_arg;\n\tu64 zone_sectors;\n\tint ret;\n\n\tif (!f2fs_sb_has_blkzoned(sbi))\n\t\treturn 0;\n\n\tzone_sectors = bdev_zone_sectors(bdev);\n\tif (!is_power_of_2(zone_sectors)) {\n\t\tf2fs_err(sbi, \"F2FS does not support non power of 2 zone sizes\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (sbi->blocks_per_blkz && sbi->blocks_per_blkz !=\n\t\t\t\tSECTOR_TO_BLOCK(zone_sectors))\n\t\treturn -EINVAL;\n\tsbi->blocks_per_blkz = SECTOR_TO_BLOCK(zone_sectors);\n\tFDEV(devi).nr_blkz = div_u64(SECTOR_TO_BLOCK(nr_sectors),\n\t\t\t\t\tsbi->blocks_per_blkz);\n\tif (nr_sectors & (zone_sectors - 1))\n\t\tFDEV(devi).nr_blkz++;\n\n\tFDEV(devi).blkz_seq = f2fs_kvzalloc(sbi,\n\t\t\t\t\tBITS_TO_LONGS(FDEV(devi).nr_blkz)\n\t\t\t\t\t* sizeof(unsigned long),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!FDEV(devi).blkz_seq)\n\t\treturn -ENOMEM;\n\n\trep_zone_arg.sbi = sbi;\n\trep_zone_arg.dev = &FDEV(devi);\n\n\tret = blkdev_report_zones(bdev, 0, BLK_ALL_ZONES, f2fs_report_zone_cb,\n\t\t\t\t  &rep_zone_arg);\n\tif (ret < 0)\n\t\treturn ret;\n\treturn 0;\n}\n#endif\n\n \nstatic int read_raw_super_block(struct f2fs_sb_info *sbi,\n\t\t\tstruct f2fs_super_block **raw_super,\n\t\t\tint *valid_super_block, int *recovery)\n{\n\tstruct super_block *sb = sbi->sb;\n\tint block;\n\tstruct buffer_head *bh;\n\tstruct f2fs_super_block *super;\n\tint err = 0;\n\n\tsuper = kzalloc(sizeof(struct f2fs_super_block), GFP_KERNEL);\n\tif (!super)\n\t\treturn -ENOMEM;\n\n\tfor (block = 0; block < 2; block++) {\n\t\tbh = sb_bread(sb, block);\n\t\tif (!bh) {\n\t\t\tf2fs_err(sbi, \"Unable to read %dth superblock\",\n\t\t\t\t block + 1);\n\t\t\terr = -EIO;\n\t\t\t*recovery = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\terr = sanity_check_raw_super(sbi, bh);\n\t\tif (err) {\n\t\t\tf2fs_err(sbi, \"Can't find valid F2FS filesystem in %dth superblock\",\n\t\t\t\t block + 1);\n\t\t\tbrelse(bh);\n\t\t\t*recovery = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!*raw_super) {\n\t\t\tmemcpy(super, bh->b_data + F2FS_SUPER_OFFSET,\n\t\t\t\t\t\t\tsizeof(*super));\n\t\t\t*valid_super_block = block;\n\t\t\t*raw_super = super;\n\t\t}\n\t\tbrelse(bh);\n\t}\n\n\t \n\tif (!*raw_super)\n\t\tkfree(super);\n\telse\n\t\terr = 0;\n\n\treturn err;\n}\n\nint f2fs_commit_super(struct f2fs_sb_info *sbi, bool recover)\n{\n\tstruct buffer_head *bh;\n\t__u32 crc = 0;\n\tint err;\n\n\tif ((recover && f2fs_readonly(sbi->sb)) ||\n\t\t\t\tf2fs_hw_is_readonly(sbi)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_SB_WRITE);\n\t\treturn -EROFS;\n\t}\n\n\t \n\tif (!recover && f2fs_sb_has_sb_chksum(sbi)) {\n\t\tcrc = f2fs_crc32(sbi, F2FS_RAW_SUPER(sbi),\n\t\t\t\toffsetof(struct f2fs_super_block, crc));\n\t\tF2FS_RAW_SUPER(sbi)->crc = cpu_to_le32(crc);\n\t}\n\n\t \n\tbh = sb_bread(sbi->sb, sbi->valid_super_block ? 0 : 1);\n\tif (!bh)\n\t\treturn -EIO;\n\terr = __f2fs_commit_super(bh, F2FS_RAW_SUPER(sbi));\n\tbrelse(bh);\n\n\t \n\tif (recover || err)\n\t\treturn err;\n\n\t \n\tbh = sb_bread(sbi->sb, sbi->valid_super_block);\n\tif (!bh)\n\t\treturn -EIO;\n\terr = __f2fs_commit_super(bh, F2FS_RAW_SUPER(sbi));\n\tbrelse(bh);\n\treturn err;\n}\n\nstatic void save_stop_reason(struct f2fs_sb_info *sbi, unsigned char reason)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&sbi->error_lock, flags);\n\tif (sbi->stop_reason[reason] < GENMASK(BITS_PER_BYTE - 1, 0))\n\t\tsbi->stop_reason[reason]++;\n\tspin_unlock_irqrestore(&sbi->error_lock, flags);\n}\n\nstatic void f2fs_record_stop_reason(struct f2fs_sb_info *sbi)\n{\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tunsigned long flags;\n\tint err;\n\n\tf2fs_down_write(&sbi->sb_lock);\n\n\tspin_lock_irqsave(&sbi->error_lock, flags);\n\tif (sbi->error_dirty) {\n\t\tmemcpy(F2FS_RAW_SUPER(sbi)->s_errors, sbi->errors,\n\t\t\t\t\t\t\tMAX_F2FS_ERRORS);\n\t\tsbi->error_dirty = false;\n\t}\n\tmemcpy(raw_super->s_stop_reason, sbi->stop_reason, MAX_STOP_REASON);\n\tspin_unlock_irqrestore(&sbi->error_lock, flags);\n\n\terr = f2fs_commit_super(sbi, false);\n\n\tf2fs_up_write(&sbi->sb_lock);\n\tif (err)\n\t\tf2fs_err(sbi, \"f2fs_commit_super fails to record err:%d\", err);\n}\n\nvoid f2fs_save_errors(struct f2fs_sb_info *sbi, unsigned char flag)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&sbi->error_lock, flags);\n\tif (!test_bit(flag, (unsigned long *)sbi->errors)) {\n\t\tset_bit(flag, (unsigned long *)sbi->errors);\n\t\tsbi->error_dirty = true;\n\t}\n\tspin_unlock_irqrestore(&sbi->error_lock, flags);\n}\n\nstatic bool f2fs_update_errors(struct f2fs_sb_info *sbi)\n{\n\tunsigned long flags;\n\tbool need_update = false;\n\n\tspin_lock_irqsave(&sbi->error_lock, flags);\n\tif (sbi->error_dirty) {\n\t\tmemcpy(F2FS_RAW_SUPER(sbi)->s_errors, sbi->errors,\n\t\t\t\t\t\t\tMAX_F2FS_ERRORS);\n\t\tsbi->error_dirty = false;\n\t\tneed_update = true;\n\t}\n\tspin_unlock_irqrestore(&sbi->error_lock, flags);\n\n\treturn need_update;\n}\n\nstatic void f2fs_record_errors(struct f2fs_sb_info *sbi, unsigned char error)\n{\n\tint err;\n\n\tf2fs_down_write(&sbi->sb_lock);\n\n\tif (!f2fs_update_errors(sbi))\n\t\tgoto out_unlock;\n\n\terr = f2fs_commit_super(sbi, false);\n\tif (err)\n\t\tf2fs_err(sbi, \"f2fs_commit_super fails to record errors:%u, err:%d\",\n\t\t\t\t\t\t\t\terror, err);\nout_unlock:\n\tf2fs_up_write(&sbi->sb_lock);\n}\n\nvoid f2fs_handle_error(struct f2fs_sb_info *sbi, unsigned char error)\n{\n\tf2fs_save_errors(sbi, error);\n\tf2fs_record_errors(sbi, error);\n}\n\nvoid f2fs_handle_error_async(struct f2fs_sb_info *sbi, unsigned char error)\n{\n\tf2fs_save_errors(sbi, error);\n\n\tif (!sbi->error_dirty)\n\t\treturn;\n\tif (!test_bit(error, (unsigned long *)sbi->errors))\n\t\treturn;\n\tschedule_work(&sbi->s_error_work);\n}\n\nstatic bool system_going_down(void)\n{\n\treturn system_state == SYSTEM_HALT || system_state == SYSTEM_POWER_OFF\n\t\t|| system_state == SYSTEM_RESTART;\n}\n\nvoid f2fs_handle_critical_error(struct f2fs_sb_info *sbi, unsigned char reason,\n\t\t\t\t\t\t\tbool irq_context)\n{\n\tstruct super_block *sb = sbi->sb;\n\tbool shutdown = reason == STOP_CP_REASON_SHUTDOWN;\n\tbool continue_fs = !shutdown &&\n\t\t\tF2FS_OPTION(sbi).errors == MOUNT_ERRORS_CONTINUE;\n\n\tset_ckpt_flags(sbi, CP_ERROR_FLAG);\n\n\tif (!f2fs_hw_is_readonly(sbi)) {\n\t\tsave_stop_reason(sbi, reason);\n\n\t\tif (irq_context && !shutdown)\n\t\t\tschedule_work(&sbi->s_error_work);\n\t\telse\n\t\t\tf2fs_record_stop_reason(sbi);\n\t}\n\n\t \n\tif (F2FS_OPTION(sbi).errors == MOUNT_ERRORS_PANIC &&\n\t\t\t\t!shutdown && !system_going_down() &&\n\t\t\t\t!is_sbi_flag_set(sbi, SBI_IS_SHUTDOWN))\n\t\tpanic(\"F2FS-fs (device %s): panic forced after error\\n\",\n\t\t\t\t\t\t\tsb->s_id);\n\n\tif (shutdown)\n\t\tset_sbi_flag(sbi, SBI_IS_SHUTDOWN);\n\n\t \n\tif (continue_fs || f2fs_readonly(sb))\n\t\treturn;\n\n\tf2fs_warn(sbi, \"Remounting filesystem read-only\");\n\t \n\tsmp_wmb();\n\tsb->s_flags |= SB_RDONLY;\n}\n\nstatic void f2fs_record_error_work(struct work_struct *work)\n{\n\tstruct f2fs_sb_info *sbi = container_of(work,\n\t\t\t\t\tstruct f2fs_sb_info, s_error_work);\n\n\tf2fs_record_stop_reason(sbi);\n}\n\nstatic int f2fs_scan_devices(struct f2fs_sb_info *sbi)\n{\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tunsigned int max_devices = MAX_DEVICES;\n\tunsigned int logical_blksize;\n\tblk_mode_t mode = sb_open_mode(sbi->sb->s_flags);\n\tint i;\n\n\t \n\tif (!RDEV(0).path[0]) {\n\t\tif (!bdev_is_zoned(sbi->sb->s_bdev))\n\t\t\treturn 0;\n\t\tmax_devices = 1;\n\t}\n\n\t \n\tsbi->devs = f2fs_kzalloc(sbi,\n\t\t\t\t array_size(max_devices,\n\t\t\t\t\t    sizeof(struct f2fs_dev_info)),\n\t\t\t\t GFP_KERNEL);\n\tif (!sbi->devs)\n\t\treturn -ENOMEM;\n\n\tlogical_blksize = bdev_logical_block_size(sbi->sb->s_bdev);\n\tsbi->aligned_blksize = true;\n\n\tfor (i = 0; i < max_devices; i++) {\n\t\tif (i == 0)\n\t\t\tFDEV(0).bdev = sbi->sb->s_bdev;\n\t\telse if (!RDEV(i).path[0])\n\t\t\tbreak;\n\n\t\tif (max_devices > 1) {\n\t\t\t \n\t\t\tmemcpy(FDEV(i).path, RDEV(i).path, MAX_PATH_LEN);\n\t\t\tFDEV(i).total_segments =\n\t\t\t\tle32_to_cpu(RDEV(i).total_segments);\n\t\t\tif (i == 0) {\n\t\t\t\tFDEV(i).start_blk = 0;\n\t\t\t\tFDEV(i).end_blk = FDEV(i).start_blk +\n\t\t\t\t    (FDEV(i).total_segments <<\n\t\t\t\t    sbi->log_blocks_per_seg) - 1 +\n\t\t\t\t    le32_to_cpu(raw_super->segment0_blkaddr);\n\t\t\t} else {\n\t\t\t\tFDEV(i).start_blk = FDEV(i - 1).end_blk + 1;\n\t\t\t\tFDEV(i).end_blk = FDEV(i).start_blk +\n\t\t\t\t\t(FDEV(i).total_segments <<\n\t\t\t\t\tsbi->log_blocks_per_seg) - 1;\n\t\t\t\tFDEV(i).bdev = blkdev_get_by_path(FDEV(i).path,\n\t\t\t\t\tmode, sbi->sb, NULL);\n\t\t\t}\n\t\t}\n\t\tif (IS_ERR(FDEV(i).bdev))\n\t\t\treturn PTR_ERR(FDEV(i).bdev);\n\n\t\t \n\t\tsbi->s_ndevs = i + 1;\n\n\t\tif (logical_blksize != bdev_logical_block_size(FDEV(i).bdev))\n\t\t\tsbi->aligned_blksize = false;\n\n#ifdef CONFIG_BLK_DEV_ZONED\n\t\tif (bdev_zoned_model(FDEV(i).bdev) == BLK_ZONED_HM &&\n\t\t\t\t!f2fs_sb_has_blkzoned(sbi)) {\n\t\t\tf2fs_err(sbi, \"Zoned block device feature not enabled\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (bdev_zoned_model(FDEV(i).bdev) != BLK_ZONED_NONE) {\n\t\t\tif (init_blkz_info(sbi, i)) {\n\t\t\t\tf2fs_err(sbi, \"Failed to initialize F2FS blkzone information\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (max_devices == 1)\n\t\t\t\tbreak;\n\t\t\tf2fs_info(sbi, \"Mount Device [%2d]: %20s, %8u, %8x - %8x (zone: %s)\",\n\t\t\t\t  i, FDEV(i).path,\n\t\t\t\t  FDEV(i).total_segments,\n\t\t\t\t  FDEV(i).start_blk, FDEV(i).end_blk,\n\t\t\t\t  bdev_zoned_model(FDEV(i).bdev) == BLK_ZONED_HA ?\n\t\t\t\t  \"Host-aware\" : \"Host-managed\");\n\t\t\tcontinue;\n\t\t}\n#endif\n\t\tf2fs_info(sbi, \"Mount Device [%2d]: %20s, %8u, %8x - %8x\",\n\t\t\t  i, FDEV(i).path,\n\t\t\t  FDEV(i).total_segments,\n\t\t\t  FDEV(i).start_blk, FDEV(i).end_blk);\n\t}\n\tf2fs_info(sbi,\n\t\t  \"IO Block Size: %8ld KB\", F2FS_IO_SIZE_KB(sbi));\n\treturn 0;\n}\n\nstatic int f2fs_setup_casefold(struct f2fs_sb_info *sbi)\n{\n#if IS_ENABLED(CONFIG_UNICODE)\n\tif (f2fs_sb_has_casefold(sbi) && !sbi->sb->s_encoding) {\n\t\tconst struct f2fs_sb_encodings *encoding_info;\n\t\tstruct unicode_map *encoding;\n\t\t__u16 encoding_flags;\n\n\t\tencoding_info = f2fs_sb_read_encoding(sbi->raw_super);\n\t\tif (!encoding_info) {\n\t\t\tf2fs_err(sbi,\n\t\t\t\t \"Encoding requested by superblock is unknown\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tencoding_flags = le16_to_cpu(sbi->raw_super->s_encoding_flags);\n\t\tencoding = utf8_load(encoding_info->version);\n\t\tif (IS_ERR(encoding)) {\n\t\t\tf2fs_err(sbi,\n\t\t\t\t \"can't mount with superblock charset: %s-%u.%u.%u \"\n\t\t\t\t \"not supported by the kernel. flags: 0x%x.\",\n\t\t\t\t encoding_info->name,\n\t\t\t\t unicode_major(encoding_info->version),\n\t\t\t\t unicode_minor(encoding_info->version),\n\t\t\t\t unicode_rev(encoding_info->version),\n\t\t\t\t encoding_flags);\n\t\t\treturn PTR_ERR(encoding);\n\t\t}\n\t\tf2fs_info(sbi, \"Using encoding defined by superblock: \"\n\t\t\t \"%s-%u.%u.%u with flags 0x%hx\", encoding_info->name,\n\t\t\t unicode_major(encoding_info->version),\n\t\t\t unicode_minor(encoding_info->version),\n\t\t\t unicode_rev(encoding_info->version),\n\t\t\t encoding_flags);\n\n\t\tsbi->sb->s_encoding = encoding;\n\t\tsbi->sb->s_encoding_flags = encoding_flags;\n\t}\n#else\n\tif (f2fs_sb_has_casefold(sbi)) {\n\t\tf2fs_err(sbi, \"Filesystem with casefold feature cannot be mounted without CONFIG_UNICODE\");\n\t\treturn -EINVAL;\n\t}\n#endif\n\treturn 0;\n}\n\nstatic void f2fs_tuning_parameters(struct f2fs_sb_info *sbi)\n{\n\t \n\tif (MAIN_SEGS(sbi) <= SMALL_VOLUME_SEGMENTS) {\n\t\tif (f2fs_block_unit_discard(sbi))\n\t\t\tSM_I(sbi)->dcc_info->discard_granularity =\n\t\t\t\t\t\tMIN_DISCARD_GRANULARITY;\n\t\tif (!f2fs_lfs_mode(sbi))\n\t\t\tSM_I(sbi)->ipu_policy = BIT(F2FS_IPU_FORCE) |\n\t\t\t\t\t\tBIT(F2FS_IPU_HONOR_OPU_WRITE);\n\t}\n\n\tsbi->readdir_ra = true;\n}\n\nstatic int f2fs_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct f2fs_sb_info *sbi;\n\tstruct f2fs_super_block *raw_super;\n\tstruct inode *root;\n\tint err;\n\tbool skip_recovery = false, need_fsck = false;\n\tchar *options = NULL;\n\tint recovery, i, valid_super_block;\n\tstruct curseg_info *seg_i;\n\tint retry_cnt = 1;\n#ifdef CONFIG_QUOTA\n\tbool quota_enabled = false;\n#endif\n\ntry_onemore:\n\terr = -EINVAL;\n\traw_super = NULL;\n\tvalid_super_block = -1;\n\trecovery = 0;\n\n\t \n\tsbi = kzalloc(sizeof(struct f2fs_sb_info), GFP_KERNEL);\n\tif (!sbi)\n\t\treturn -ENOMEM;\n\n\tsbi->sb = sb;\n\n\t \n\tinit_f2fs_rwsem(&sbi->gc_lock);\n\tmutex_init(&sbi->writepages);\n\tinit_f2fs_rwsem(&sbi->cp_global_sem);\n\tinit_f2fs_rwsem(&sbi->node_write);\n\tinit_f2fs_rwsem(&sbi->node_change);\n\tspin_lock_init(&sbi->stat_lock);\n\tinit_f2fs_rwsem(&sbi->cp_rwsem);\n\tinit_f2fs_rwsem(&sbi->quota_sem);\n\tinit_waitqueue_head(&sbi->cp_wait);\n\tspin_lock_init(&sbi->error_lock);\n\n\tfor (i = 0; i < NR_INODE_TYPE; i++) {\n\t\tINIT_LIST_HEAD(&sbi->inode_list[i]);\n\t\tspin_lock_init(&sbi->inode_lock[i]);\n\t}\n\tmutex_init(&sbi->flush_lock);\n\n\t \n\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32\", 0, 0);\n\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\tf2fs_err(sbi, \"Cannot load crc32 driver.\");\n\t\terr = PTR_ERR(sbi->s_chksum_driver);\n\t\tsbi->s_chksum_driver = NULL;\n\t\tgoto free_sbi;\n\t}\n\n\t \n\tif (unlikely(!sb_set_blocksize(sb, F2FS_BLKSIZE))) {\n\t\tf2fs_err(sbi, \"unable to set blocksize\");\n\t\tgoto free_sbi;\n\t}\n\n\terr = read_raw_super_block(sbi, &raw_super, &valid_super_block,\n\t\t\t\t\t\t\t\t&recovery);\n\tif (err)\n\t\tgoto free_sbi;\n\n\tsb->s_fs_info = sbi;\n\tsbi->raw_super = raw_super;\n\n\tINIT_WORK(&sbi->s_error_work, f2fs_record_error_work);\n\tmemcpy(sbi->errors, raw_super->s_errors, MAX_F2FS_ERRORS);\n\tmemcpy(sbi->stop_reason, raw_super->s_stop_reason, MAX_STOP_REASON);\n\n\t \n\tif (f2fs_sb_has_inode_chksum(sbi))\n\t\tsbi->s_chksum_seed = f2fs_chksum(sbi, ~0, raw_super->uuid,\n\t\t\t\t\t\tsizeof(raw_super->uuid));\n\n\tdefault_options(sbi, false);\n\t \n\toptions = kstrdup((const char *)data, GFP_KERNEL);\n\tif (data && !options) {\n\t\terr = -ENOMEM;\n\t\tgoto free_sb_buf;\n\t}\n\n\terr = parse_options(sb, options, false);\n\tif (err)\n\t\tgoto free_options;\n\n\tsb->s_maxbytes = max_file_blocks(NULL) <<\n\t\t\t\tle32_to_cpu(raw_super->log_blocksize);\n\tsb->s_max_links = F2FS_LINK_MAX;\n\n\terr = f2fs_setup_casefold(sbi);\n\tif (err)\n\t\tgoto free_options;\n\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &f2fs_quota_operations;\n\tsb->s_qcop = &f2fs_quotactl_ops;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n\n\tif (f2fs_sb_has_quota_ino(sbi)) {\n\t\tfor (i = 0; i < MAXQUOTAS; i++) {\n\t\t\tif (f2fs_qf_ino(sbi->sb, i))\n\t\t\t\tsbi->nquota_files++;\n\t\t}\n\t}\n#endif\n\n\tsb->s_op = &f2fs_sops;\n#ifdef CONFIG_FS_ENCRYPTION\n\tsb->s_cop = &f2fs_cryptops;\n#endif\n#ifdef CONFIG_FS_VERITY\n\tsb->s_vop = &f2fs_verityops;\n#endif\n\tsb->s_xattr = f2fs_xattr_handlers;\n\tsb->s_export_op = &f2fs_export_ops;\n\tsb->s_magic = F2FS_SUPER_MAGIC;\n\tsb->s_time_gran = 1;\n\tsb->s_flags = (sb->s_flags & ~SB_POSIXACL) |\n\t\t(test_opt(sbi, POSIX_ACL) ? SB_POSIXACL : 0);\n\tmemcpy(&sb->s_uuid, raw_super->uuid, sizeof(raw_super->uuid));\n\tsb->s_iflags |= SB_I_CGROUPWB;\n\n\t \n\tsbi->valid_super_block = valid_super_block;\n\n\t \n\tset_sbi_flag(sbi, SBI_POR_DOING);\n\n\terr = f2fs_init_write_merge_io(sbi);\n\tif (err)\n\t\tgoto free_bio_info;\n\n\tinit_sb_info(sbi);\n\n\terr = f2fs_init_iostat(sbi);\n\tif (err)\n\t\tgoto free_bio_info;\n\n\terr = init_percpu_info(sbi);\n\tif (err)\n\t\tgoto free_iostat;\n\n\tif (F2FS_IO_ALIGNED(sbi)) {\n\t\tsbi->write_io_dummy =\n\t\t\tmempool_create_page_pool(2 * (F2FS_IO_SIZE(sbi) - 1), 0);\n\t\tif (!sbi->write_io_dummy) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free_percpu;\n\t\t}\n\t}\n\n\t \n\terr = f2fs_init_xattr_caches(sbi);\n\tif (err)\n\t\tgoto free_io_dummy;\n\terr = f2fs_init_page_array_cache(sbi);\n\tif (err)\n\t\tgoto free_xattr_cache;\n\n\t \n\tsbi->meta_inode = f2fs_iget(sb, F2FS_META_INO(sbi));\n\tif (IS_ERR(sbi->meta_inode)) {\n\t\tf2fs_err(sbi, \"Failed to read F2FS meta data inode\");\n\t\terr = PTR_ERR(sbi->meta_inode);\n\t\tgoto free_page_array_cache;\n\t}\n\n\terr = f2fs_get_valid_checkpoint(sbi);\n\tif (err) {\n\t\tf2fs_err(sbi, \"Failed to get valid F2FS checkpoint\");\n\t\tgoto free_meta_inode;\n\t}\n\n\tif (__is_set_ckpt_flags(F2FS_CKPT(sbi), CP_QUOTA_NEED_FSCK_FLAG))\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\tif (__is_set_ckpt_flags(F2FS_CKPT(sbi), CP_DISABLED_QUICK_FLAG)) {\n\t\tset_sbi_flag(sbi, SBI_CP_DISABLED_QUICK);\n\t\tsbi->interval_time[DISABLE_TIME] = DEF_DISABLE_QUICK_INTERVAL;\n\t}\n\n\tif (__is_set_ckpt_flags(F2FS_CKPT(sbi), CP_FSCK_FLAG))\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\n\t \n\terr = f2fs_scan_devices(sbi);\n\tif (err) {\n\t\tf2fs_err(sbi, \"Failed to find devices\");\n\t\tgoto free_devices;\n\t}\n\n\terr = f2fs_init_post_read_wq(sbi);\n\tif (err) {\n\t\tf2fs_err(sbi, \"Failed to initialize post read workqueue\");\n\t\tgoto free_devices;\n\t}\n\n\tsbi->total_valid_node_count =\n\t\t\t\tle32_to_cpu(sbi->ckpt->valid_node_count);\n\tpercpu_counter_set(&sbi->total_valid_inode_count,\n\t\t\t\tle32_to_cpu(sbi->ckpt->valid_inode_count));\n\tsbi->user_block_count = le64_to_cpu(sbi->ckpt->user_block_count);\n\tsbi->total_valid_block_count =\n\t\t\t\tle64_to_cpu(sbi->ckpt->valid_block_count);\n\tsbi->last_valid_block_count = sbi->total_valid_block_count;\n\tsbi->reserved_blocks = 0;\n\tsbi->current_reserved_blocks = 0;\n\tlimit_reserve_root(sbi);\n\tadjust_unusable_cap_perc(sbi);\n\n\tf2fs_init_extent_cache_info(sbi);\n\n\tf2fs_init_ino_entry_info(sbi);\n\n\tf2fs_init_fsync_node_info(sbi);\n\n\t \n\tf2fs_init_ckpt_req_control(sbi);\n\tif (!f2fs_readonly(sb) && !test_opt(sbi, DISABLE_CHECKPOINT) &&\n\t\t\ttest_opt(sbi, MERGE_CHECKPOINT)) {\n\t\terr = f2fs_start_ckpt_thread(sbi);\n\t\tif (err) {\n\t\t\tf2fs_err(sbi,\n\t\t\t    \"Failed to start F2FS issue_checkpoint_thread (%d)\",\n\t\t\t    err);\n\t\t\tgoto stop_ckpt_thread;\n\t\t}\n\t}\n\n\t \n\terr = f2fs_build_segment_manager(sbi);\n\tif (err) {\n\t\tf2fs_err(sbi, \"Failed to initialize F2FS segment manager (%d)\",\n\t\t\t err);\n\t\tgoto free_sm;\n\t}\n\terr = f2fs_build_node_manager(sbi);\n\tif (err) {\n\t\tf2fs_err(sbi, \"Failed to initialize F2FS node manager (%d)\",\n\t\t\t err);\n\t\tgoto free_nm;\n\t}\n\n\terr = adjust_reserved_segment(sbi);\n\tif (err)\n\t\tgoto free_nm;\n\n\t \n\tsbi->sectors_written_start = f2fs_get_sectors_written(sbi);\n\n\t \n\tseg_i = CURSEG_I(sbi, CURSEG_HOT_NODE);\n\tif (__exist_node_summaries(sbi))\n\t\tsbi->kbytes_written =\n\t\t\tle64_to_cpu(seg_i->journal->info.kbytes_written);\n\n\tf2fs_build_gc_manager(sbi);\n\n\terr = f2fs_build_stats(sbi);\n\tif (err)\n\t\tgoto free_nm;\n\n\t \n\tsbi->node_inode = f2fs_iget(sb, F2FS_NODE_INO(sbi));\n\tif (IS_ERR(sbi->node_inode)) {\n\t\tf2fs_err(sbi, \"Failed to read node inode\");\n\t\terr = PTR_ERR(sbi->node_inode);\n\t\tgoto free_stats;\n\t}\n\n\t \n\troot = f2fs_iget(sb, F2FS_ROOT_INO(sbi));\n\tif (IS_ERR(root)) {\n\t\tf2fs_err(sbi, \"Failed to read root inode\");\n\t\terr = PTR_ERR(root);\n\t\tgoto free_node_inode;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks ||\n\t\t\t!root->i_size || !root->i_nlink) {\n\t\tiput(root);\n\t\terr = -EINVAL;\n\t\tgoto free_node_inode;\n\t}\n\n\tsb->s_root = d_make_root(root);  \n\tif (!sb->s_root) {\n\t\terr = -ENOMEM;\n\t\tgoto free_node_inode;\n\t}\n\n\terr = f2fs_init_compress_inode(sbi);\n\tif (err)\n\t\tgoto free_root_inode;\n\n\terr = f2fs_register_sysfs(sbi);\n\tif (err)\n\t\tgoto free_compress_inode;\n\n#ifdef CONFIG_QUOTA\n\t \n\tif (f2fs_sb_has_quota_ino(sbi) && !f2fs_readonly(sb)) {\n\t\terr = f2fs_enable_quotas(sb);\n\t\tif (err)\n\t\t\tf2fs_err(sbi, \"Cannot turn on quotas: error %d\", err);\n\t}\n\n\tquota_enabled = f2fs_recover_quota_begin(sbi);\n#endif\n\t \n\terr = f2fs_recover_orphan_inodes(sbi);\n\tif (err)\n\t\tgoto free_meta;\n\n\tif (unlikely(is_set_ckpt_flags(sbi, CP_DISABLED_FLAG)))\n\t\tgoto reset_checkpoint;\n\n\t \n\tif (!test_opt(sbi, DISABLE_ROLL_FORWARD) &&\n\t\t\t!test_opt(sbi, NORECOVERY)) {\n\t\t \n\t\tif (f2fs_hw_is_readonly(sbi)) {\n\t\t\tif (!is_set_ckpt_flags(sbi, CP_UMOUNT_FLAG)) {\n\t\t\t\terr = f2fs_recover_fsync_data(sbi, true);\n\t\t\t\tif (err > 0) {\n\t\t\t\t\terr = -EROFS;\n\t\t\t\t\tf2fs_err(sbi, \"Need to recover fsync data, but \"\n\t\t\t\t\t\t\"write access unavailable, please try \"\n\t\t\t\t\t\t\"mount w/ disable_roll_forward or norecovery\");\n\t\t\t\t}\n\t\t\t\tif (err < 0)\n\t\t\t\t\tgoto free_meta;\n\t\t\t}\n\t\t\tf2fs_info(sbi, \"write access unavailable, skipping recovery\");\n\t\t\tgoto reset_checkpoint;\n\t\t}\n\n\t\tif (need_fsck)\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\n\t\tif (skip_recovery)\n\t\t\tgoto reset_checkpoint;\n\n\t\terr = f2fs_recover_fsync_data(sbi, false);\n\t\tif (err < 0) {\n\t\t\tif (err != -ENOMEM)\n\t\t\t\tskip_recovery = true;\n\t\t\tneed_fsck = true;\n\t\t\tf2fs_err(sbi, \"Cannot recover all fsync data errno=%d\",\n\t\t\t\t err);\n\t\t\tgoto free_meta;\n\t\t}\n\t} else {\n\t\terr = f2fs_recover_fsync_data(sbi, true);\n\n\t\tif (!f2fs_readonly(sb) && err > 0) {\n\t\t\terr = -EINVAL;\n\t\t\tf2fs_err(sbi, \"Need to recover fsync data\");\n\t\t\tgoto free_meta;\n\t\t}\n\t}\n\n#ifdef CONFIG_QUOTA\n\tf2fs_recover_quota_end(sbi, quota_enabled);\n#endif\n\n\t \n\tif (!err && !f2fs_readonly(sb) && f2fs_sb_has_blkzoned(sbi)) {\n\t\terr = f2fs_check_write_pointer(sbi);\n\t\tif (err)\n\t\t\tgoto free_meta;\n\t}\n\nreset_checkpoint:\n\tf2fs_init_inmem_curseg(sbi);\n\n\t \n\tclear_sbi_flag(sbi, SBI_POR_DOING);\n\n\tif (test_opt(sbi, DISABLE_CHECKPOINT)) {\n\t\terr = f2fs_disable_checkpoint(sbi);\n\t\tif (err)\n\t\t\tgoto sync_free_meta;\n\t} else if (is_set_ckpt_flags(sbi, CP_DISABLED_FLAG)) {\n\t\tf2fs_enable_checkpoint(sbi);\n\t}\n\n\t \n\tif ((F2FS_OPTION(sbi).bggc_mode != BGGC_MODE_OFF ||\n\t\ttest_opt(sbi, GC_MERGE)) && !f2fs_readonly(sb)) {\n\t\t \n\t\terr = f2fs_start_gc_thread(sbi);\n\t\tif (err)\n\t\t\tgoto sync_free_meta;\n\t}\n\tkvfree(options);\n\n\t \n\tif (recovery) {\n\t\terr = f2fs_commit_super(sbi, true);\n\t\tf2fs_info(sbi, \"Try to recover %dth superblock, ret: %d\",\n\t\t\t  sbi->valid_super_block ? 1 : 2, err);\n\t}\n\n\tf2fs_join_shrinker(sbi);\n\n\tf2fs_tuning_parameters(sbi);\n\n\tf2fs_notice(sbi, \"Mounted with checkpoint version = %llx\",\n\t\t    cur_cp_version(F2FS_CKPT(sbi)));\n\tf2fs_update_time(sbi, CP_TIME);\n\tf2fs_update_time(sbi, REQ_TIME);\n\tclear_sbi_flag(sbi, SBI_CP_DISABLED_QUICK);\n\treturn 0;\n\nsync_free_meta:\n\t \n\tsync_filesystem(sbi->sb);\n\tretry_cnt = 0;\n\nfree_meta:\n#ifdef CONFIG_QUOTA\n\tf2fs_truncate_quota_inode_pages(sb);\n\tif (f2fs_sb_has_quota_ino(sbi) && !f2fs_readonly(sb))\n\t\tf2fs_quota_off_umount(sbi->sb);\n#endif\n\t \n\ttruncate_inode_pages_final(META_MAPPING(sbi));\n\t \n\tevict_inodes(sb);\n\tf2fs_unregister_sysfs(sbi);\nfree_compress_inode:\n\tf2fs_destroy_compress_inode(sbi);\nfree_root_inode:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfree_node_inode:\n\tf2fs_release_ino_entry(sbi, true);\n\ttruncate_inode_pages_final(NODE_MAPPING(sbi));\n\tiput(sbi->node_inode);\n\tsbi->node_inode = NULL;\nfree_stats:\n\tf2fs_destroy_stats(sbi);\nfree_nm:\n\t \n\tf2fs_stop_discard_thread(sbi);\n\tf2fs_destroy_node_manager(sbi);\nfree_sm:\n\tf2fs_destroy_segment_manager(sbi);\nstop_ckpt_thread:\n\tf2fs_stop_ckpt_thread(sbi);\n\t \n\tflush_work(&sbi->s_error_work);\n\tf2fs_destroy_post_read_wq(sbi);\nfree_devices:\n\tdestroy_device_list(sbi);\n\tkvfree(sbi->ckpt);\nfree_meta_inode:\n\tmake_bad_inode(sbi->meta_inode);\n\tiput(sbi->meta_inode);\n\tsbi->meta_inode = NULL;\nfree_page_array_cache:\n\tf2fs_destroy_page_array_cache(sbi);\nfree_xattr_cache:\n\tf2fs_destroy_xattr_caches(sbi);\nfree_io_dummy:\n\tmempool_destroy(sbi->write_io_dummy);\nfree_percpu:\n\tdestroy_percpu_info(sbi);\nfree_iostat:\n\tf2fs_destroy_iostat(sbi);\nfree_bio_info:\n\tfor (i = 0; i < NR_PAGE_TYPE; i++)\n\t\tkvfree(sbi->write_io[i]);\n\n#if IS_ENABLED(CONFIG_UNICODE)\n\tutf8_unload(sb->s_encoding);\n\tsb->s_encoding = NULL;\n#endif\nfree_options:\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < MAXQUOTAS; i++)\n\t\tkfree(F2FS_OPTION(sbi).s_qf_names[i]);\n#endif\n\tfscrypt_free_dummy_policy(&F2FS_OPTION(sbi).dummy_enc_policy);\n\tkvfree(options);\nfree_sb_buf:\n\tkfree(raw_super);\nfree_sbi:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n\tkfree(sbi);\n\n\t \n\tif (retry_cnt > 0 && skip_recovery) {\n\t\tretry_cnt--;\n\t\tshrink_dcache_sb(sb);\n\t\tgoto try_onemore;\n\t}\n\treturn err;\n}\n\nstatic struct dentry *f2fs_mount(struct file_system_type *fs_type, int flags,\n\t\t\tconst char *dev_name, void *data)\n{\n\treturn mount_bdev(fs_type, flags, dev_name, data, f2fs_fill_super);\n}\n\nstatic void kill_f2fs_super(struct super_block *sb)\n{\n\tif (sb->s_root) {\n\t\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\n\t\tset_sbi_flag(sbi, SBI_IS_CLOSE);\n\t\tf2fs_stop_gc_thread(sbi);\n\t\tf2fs_stop_discard_thread(sbi);\n\n#ifdef CONFIG_F2FS_FS_COMPRESSION\n\t\t \n\t\tif (test_opt(sbi, COMPRESS_CACHE))\n\t\t\ttruncate_inode_pages_final(COMPRESS_MAPPING(sbi));\n#endif\n\n\t\tif (is_sbi_flag_set(sbi, SBI_IS_DIRTY) ||\n\t\t\t\t!is_set_ckpt_flags(sbi, CP_UMOUNT_FLAG)) {\n\t\t\tstruct cp_control cpc = {\n\t\t\t\t.reason = CP_UMOUNT,\n\t\t\t};\n\t\t\tstat_inc_cp_call_count(sbi, TOTAL_CALL);\n\t\t\tf2fs_write_checkpoint(sbi, &cpc);\n\t\t}\n\n\t\tif (is_sbi_flag_set(sbi, SBI_IS_RECOVERED) && f2fs_readonly(sb))\n\t\t\tsb->s_flags &= ~SB_RDONLY;\n\t}\n\tkill_block_super(sb);\n}\n\nstatic struct file_system_type f2fs_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"f2fs\",\n\t.mount\t\t= f2fs_mount,\n\t.kill_sb\t= kill_f2fs_super,\n\t.fs_flags\t= FS_REQUIRES_DEV | FS_ALLOW_IDMAP,\n};\nMODULE_ALIAS_FS(\"f2fs\");\n\nstatic int __init init_inodecache(void)\n{\n\tf2fs_inode_cachep = kmem_cache_create(\"f2fs_inode_cache\",\n\t\t\tsizeof(struct f2fs_inode_info), 0,\n\t\t\tSLAB_RECLAIM_ACCOUNT|SLAB_ACCOUNT, NULL);\n\treturn f2fs_inode_cachep ? 0 : -ENOMEM;\n}\n\nstatic void destroy_inodecache(void)\n{\n\t \n\trcu_barrier();\n\tkmem_cache_destroy(f2fs_inode_cachep);\n}\n\nstatic int __init init_f2fs_fs(void)\n{\n\tint err;\n\n\tif (PAGE_SIZE != F2FS_BLKSIZE) {\n\t\tprintk(\"F2FS not supported on PAGE_SIZE(%lu) != %d\\n\",\n\t\t\t\tPAGE_SIZE, F2FS_BLKSIZE);\n\t\treturn -EINVAL;\n\t}\n\n\terr = init_inodecache();\n\tif (err)\n\t\tgoto fail;\n\terr = f2fs_create_node_manager_caches();\n\tif (err)\n\t\tgoto free_inodecache;\n\terr = f2fs_create_segment_manager_caches();\n\tif (err)\n\t\tgoto free_node_manager_caches;\n\terr = f2fs_create_checkpoint_caches();\n\tif (err)\n\t\tgoto free_segment_manager_caches;\n\terr = f2fs_create_recovery_cache();\n\tif (err)\n\t\tgoto free_checkpoint_caches;\n\terr = f2fs_create_extent_cache();\n\tif (err)\n\t\tgoto free_recovery_cache;\n\terr = f2fs_create_garbage_collection_cache();\n\tif (err)\n\t\tgoto free_extent_cache;\n\terr = f2fs_init_sysfs();\n\tif (err)\n\t\tgoto free_garbage_collection_cache;\n\terr = register_shrinker(&f2fs_shrinker_info, \"f2fs-shrinker\");\n\tif (err)\n\t\tgoto free_sysfs;\n\terr = register_filesystem(&f2fs_fs_type);\n\tif (err)\n\t\tgoto free_shrinker;\n\tf2fs_create_root_stats();\n\terr = f2fs_init_post_read_processing();\n\tif (err)\n\t\tgoto free_root_stats;\n\terr = f2fs_init_iostat_processing();\n\tif (err)\n\t\tgoto free_post_read;\n\terr = f2fs_init_bio_entry_cache();\n\tif (err)\n\t\tgoto free_iostat;\n\terr = f2fs_init_bioset();\n\tif (err)\n\t\tgoto free_bio_entry_cache;\n\terr = f2fs_init_compress_mempool();\n\tif (err)\n\t\tgoto free_bioset;\n\terr = f2fs_init_compress_cache();\n\tif (err)\n\t\tgoto free_compress_mempool;\n\terr = f2fs_create_casefold_cache();\n\tif (err)\n\t\tgoto free_compress_cache;\n\treturn 0;\nfree_compress_cache:\n\tf2fs_destroy_compress_cache();\nfree_compress_mempool:\n\tf2fs_destroy_compress_mempool();\nfree_bioset:\n\tf2fs_destroy_bioset();\nfree_bio_entry_cache:\n\tf2fs_destroy_bio_entry_cache();\nfree_iostat:\n\tf2fs_destroy_iostat_processing();\nfree_post_read:\n\tf2fs_destroy_post_read_processing();\nfree_root_stats:\n\tf2fs_destroy_root_stats();\n\tunregister_filesystem(&f2fs_fs_type);\nfree_shrinker:\n\tunregister_shrinker(&f2fs_shrinker_info);\nfree_sysfs:\n\tf2fs_exit_sysfs();\nfree_garbage_collection_cache:\n\tf2fs_destroy_garbage_collection_cache();\nfree_extent_cache:\n\tf2fs_destroy_extent_cache();\nfree_recovery_cache:\n\tf2fs_destroy_recovery_cache();\nfree_checkpoint_caches:\n\tf2fs_destroy_checkpoint_caches();\nfree_segment_manager_caches:\n\tf2fs_destroy_segment_manager_caches();\nfree_node_manager_caches:\n\tf2fs_destroy_node_manager_caches();\nfree_inodecache:\n\tdestroy_inodecache();\nfail:\n\treturn err;\n}\n\nstatic void __exit exit_f2fs_fs(void)\n{\n\tf2fs_destroy_casefold_cache();\n\tf2fs_destroy_compress_cache();\n\tf2fs_destroy_compress_mempool();\n\tf2fs_destroy_bioset();\n\tf2fs_destroy_bio_entry_cache();\n\tf2fs_destroy_iostat_processing();\n\tf2fs_destroy_post_read_processing();\n\tf2fs_destroy_root_stats();\n\tunregister_filesystem(&f2fs_fs_type);\n\tunregister_shrinker(&f2fs_shrinker_info);\n\tf2fs_exit_sysfs();\n\tf2fs_destroy_garbage_collection_cache();\n\tf2fs_destroy_extent_cache();\n\tf2fs_destroy_recovery_cache();\n\tf2fs_destroy_checkpoint_caches();\n\tf2fs_destroy_segment_manager_caches();\n\tf2fs_destroy_node_manager_caches();\n\tdestroy_inodecache();\n}\n\nmodule_init(init_f2fs_fs)\nmodule_exit(exit_f2fs_fs)\n\nMODULE_AUTHOR(\"Samsung Electronics's Praesto Team\");\nMODULE_DESCRIPTION(\"Flash Friendly File System\");\nMODULE_LICENSE(\"GPL\");\nMODULE_SOFTDEP(\"pre: crc32\");\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}