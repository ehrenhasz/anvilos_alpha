{
  "module_name": "inode.c",
  "hash_id": "2b9526bfb91483e318e766c78a4f99d37f2947700fdbf95bae834e2138093251",
  "original_prompt": "Ingested from linux-6.6.14/fs/f2fs/inode.c",
  "human_readable_source": "\n \n#include <linux/fs.h>\n#include <linux/f2fs_fs.h>\n#include <linux/buffer_head.h>\n#include <linux/writeback.h>\n#include <linux/sched/mm.h>\n#include <linux/lz4.h>\n#include <linux/zstd.h>\n\n#include \"f2fs.h\"\n#include \"node.h\"\n#include \"segment.h\"\n#include \"xattr.h\"\n\n#include <trace/events/f2fs.h>\n\n#ifdef CONFIG_F2FS_FS_COMPRESSION\nextern const struct address_space_operations f2fs_compress_aops;\n#endif\n\nvoid f2fs_mark_inode_dirty_sync(struct inode *inode, bool sync)\n{\n\tif (is_inode_flag_set(inode, FI_NEW_INODE))\n\t\treturn;\n\n\tif (f2fs_inode_dirtied(inode, sync))\n\t\treturn;\n\n\tmark_inode_dirty_sync(inode);\n}\n\nvoid f2fs_set_inode_flags(struct inode *inode)\n{\n\tunsigned int flags = F2FS_I(inode)->i_flags;\n\tunsigned int new_fl = 0;\n\n\tif (flags & F2FS_SYNC_FL)\n\t\tnew_fl |= S_SYNC;\n\tif (flags & F2FS_APPEND_FL)\n\t\tnew_fl |= S_APPEND;\n\tif (flags & F2FS_IMMUTABLE_FL)\n\t\tnew_fl |= S_IMMUTABLE;\n\tif (flags & F2FS_NOATIME_FL)\n\t\tnew_fl |= S_NOATIME;\n\tif (flags & F2FS_DIRSYNC_FL)\n\t\tnew_fl |= S_DIRSYNC;\n\tif (file_is_encrypt(inode))\n\t\tnew_fl |= S_ENCRYPTED;\n\tif (file_is_verity(inode))\n\t\tnew_fl |= S_VERITY;\n\tif (flags & F2FS_CASEFOLD_FL)\n\t\tnew_fl |= S_CASEFOLD;\n\tinode_set_flags(inode, new_fl,\n\t\t\tS_SYNC|S_APPEND|S_IMMUTABLE|S_NOATIME|S_DIRSYNC|\n\t\t\tS_ENCRYPTED|S_VERITY|S_CASEFOLD);\n}\n\nstatic void __get_inode_rdev(struct inode *inode, struct f2fs_inode *ri)\n{\n\tint extra_size = get_extra_isize(inode);\n\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t\t\tS_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tif (ri->i_addr[extra_size])\n\t\t\tinode->i_rdev = old_decode_dev(\n\t\t\t\tle32_to_cpu(ri->i_addr[extra_size]));\n\t\telse\n\t\t\tinode->i_rdev = new_decode_dev(\n\t\t\t\tle32_to_cpu(ri->i_addr[extra_size + 1]));\n\t}\n}\n\nstatic int __written_first_block(struct f2fs_sb_info *sbi,\n\t\t\t\t\tstruct f2fs_inode *ri)\n{\n\tblock_t addr = le32_to_cpu(ri->i_addr[offset_in_addr(ri)]);\n\n\tif (!__is_valid_data_blkaddr(addr))\n\t\treturn 1;\n\tif (!f2fs_is_valid_blkaddr(sbi, addr, DATA_GENERIC_ENHANCE)) {\n\t\tf2fs_handle_error(sbi, ERROR_INVALID_BLKADDR);\n\t\treturn -EFSCORRUPTED;\n\t}\n\treturn 0;\n}\n\nstatic void __set_inode_rdev(struct inode *inode, struct f2fs_inode *ri)\n{\n\tint extra_size = get_extra_isize(inode);\n\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tif (old_valid_dev(inode->i_rdev)) {\n\t\t\tri->i_addr[extra_size] =\n\t\t\t\tcpu_to_le32(old_encode_dev(inode->i_rdev));\n\t\t\tri->i_addr[extra_size + 1] = 0;\n\t\t} else {\n\t\t\tri->i_addr[extra_size] = 0;\n\t\t\tri->i_addr[extra_size + 1] =\n\t\t\t\tcpu_to_le32(new_encode_dev(inode->i_rdev));\n\t\t\tri->i_addr[extra_size + 2] = 0;\n\t\t}\n\t}\n}\n\nstatic void __recover_inline_status(struct inode *inode, struct page *ipage)\n{\n\tvoid *inline_data = inline_data_addr(inode, ipage);\n\t__le32 *start = inline_data;\n\t__le32 *end = start + MAX_INLINE_DATA(inode) / sizeof(__le32);\n\n\twhile (start < end) {\n\t\tif (*start++) {\n\t\t\tf2fs_wait_on_page_writeback(ipage, NODE, true, true);\n\n\t\t\tset_inode_flag(inode, FI_DATA_EXIST);\n\t\t\tset_raw_inline(inode, F2FS_INODE(ipage));\n\t\t\tset_page_dirty(ipage);\n\t\t\treturn;\n\t\t}\n\t}\n\treturn;\n}\n\nstatic bool f2fs_enable_inode_chksum(struct f2fs_sb_info *sbi, struct page *page)\n{\n\tstruct f2fs_inode *ri = &F2FS_NODE(page)->i;\n\n\tif (!f2fs_sb_has_inode_chksum(sbi))\n\t\treturn false;\n\n\tif (!IS_INODE(page) || !(ri->i_inline & F2FS_EXTRA_ATTR))\n\t\treturn false;\n\n\tif (!F2FS_FITS_IN_INODE(ri, le16_to_cpu(ri->i_extra_isize),\n\t\t\t\ti_inode_checksum))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic __u32 f2fs_inode_chksum(struct f2fs_sb_info *sbi, struct page *page)\n{\n\tstruct f2fs_node *node = F2FS_NODE(page);\n\tstruct f2fs_inode *ri = &node->i;\n\t__le32 ino = node->footer.ino;\n\t__le32 gen = ri->i_generation;\n\t__u32 chksum, chksum_seed;\n\t__u32 dummy_cs = 0;\n\tunsigned int offset = offsetof(struct f2fs_inode, i_inode_checksum);\n\tunsigned int cs_size = sizeof(dummy_cs);\n\n\tchksum = f2fs_chksum(sbi, sbi->s_chksum_seed, (__u8 *)&ino,\n\t\t\t\t\t\t\tsizeof(ino));\n\tchksum_seed = f2fs_chksum(sbi, chksum, (__u8 *)&gen, sizeof(gen));\n\n\tchksum = f2fs_chksum(sbi, chksum_seed, (__u8 *)ri, offset);\n\tchksum = f2fs_chksum(sbi, chksum, (__u8 *)&dummy_cs, cs_size);\n\toffset += cs_size;\n\tchksum = f2fs_chksum(sbi, chksum, (__u8 *)ri + offset,\n\t\t\t\t\t\tF2FS_BLKSIZE - offset);\n\treturn chksum;\n}\n\nbool f2fs_inode_chksum_verify(struct f2fs_sb_info *sbi, struct page *page)\n{\n\tstruct f2fs_inode *ri;\n\t__u32 provided, calculated;\n\n\tif (unlikely(is_sbi_flag_set(sbi, SBI_IS_SHUTDOWN)))\n\t\treturn true;\n\n#ifdef CONFIG_F2FS_CHECK_FS\n\tif (!f2fs_enable_inode_chksum(sbi, page))\n#else\n\tif (!f2fs_enable_inode_chksum(sbi, page) ||\n\t\t\tPageDirty(page) || PageWriteback(page))\n#endif\n\t\treturn true;\n\n\tri = &F2FS_NODE(page)->i;\n\tprovided = le32_to_cpu(ri->i_inode_checksum);\n\tcalculated = f2fs_inode_chksum(sbi, page);\n\n\tif (provided != calculated)\n\t\tf2fs_warn(sbi, \"checksum invalid, nid = %lu, ino_of_node = %x, %x vs. %x\",\n\t\t\t  page->index, ino_of_node(page), provided, calculated);\n\n\treturn provided == calculated;\n}\n\nvoid f2fs_inode_chksum_set(struct f2fs_sb_info *sbi, struct page *page)\n{\n\tstruct f2fs_inode *ri = &F2FS_NODE(page)->i;\n\n\tif (!f2fs_enable_inode_chksum(sbi, page))\n\t\treturn;\n\n\tri->i_inode_checksum = cpu_to_le32(f2fs_inode_chksum(sbi, page));\n}\n\nstatic bool sanity_check_compress_inode(struct inode *inode,\n\t\t\tstruct f2fs_inode *ri)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tunsigned char clevel;\n\n\tif (ri->i_compress_algorithm >= COMPRESS_MAX) {\n\t\tf2fs_warn(sbi,\n\t\t\t\"%s: inode (ino=%lx) has unsupported compress algorithm: %u, run fsck to fix\",\n\t\t\t__func__, inode->i_ino, ri->i_compress_algorithm);\n\t\treturn false;\n\t}\n\tif (le64_to_cpu(ri->i_compr_blocks) >\n\t\t\tSECTOR_TO_BLOCK(inode->i_blocks)) {\n\t\tf2fs_warn(sbi,\n\t\t\t\"%s: inode (ino=%lx) has inconsistent i_compr_blocks:%llu, i_blocks:%llu, run fsck to fix\",\n\t\t\t__func__, inode->i_ino, le64_to_cpu(ri->i_compr_blocks),\n\t\t\tSECTOR_TO_BLOCK(inode->i_blocks));\n\t\treturn false;\n\t}\n\tif (ri->i_log_cluster_size < MIN_COMPRESS_LOG_SIZE ||\n\t\tri->i_log_cluster_size > MAX_COMPRESS_LOG_SIZE) {\n\t\tf2fs_warn(sbi,\n\t\t\t\"%s: inode (ino=%lx) has unsupported log cluster size: %u, run fsck to fix\",\n\t\t\t__func__, inode->i_ino, ri->i_log_cluster_size);\n\t\treturn false;\n\t}\n\n\tclevel = le16_to_cpu(ri->i_compress_flag) >>\n\t\t\t\tCOMPRESS_LEVEL_OFFSET;\n\tswitch (ri->i_compress_algorithm) {\n\tcase COMPRESS_LZO:\n#ifdef CONFIG_F2FS_FS_LZO\n\t\tif (clevel)\n\t\t\tgoto err_level;\n#endif\n\t\tbreak;\n\tcase COMPRESS_LZORLE:\n#ifdef CONFIG_F2FS_FS_LZORLE\n\t\tif (clevel)\n\t\t\tgoto err_level;\n#endif\n\t\tbreak;\n\tcase COMPRESS_LZ4:\n#ifdef CONFIG_F2FS_FS_LZ4\n#ifdef CONFIG_F2FS_FS_LZ4HC\n\t\tif (clevel &&\n\t\t   (clevel < LZ4HC_MIN_CLEVEL || clevel > LZ4HC_MAX_CLEVEL))\n\t\t\tgoto err_level;\n#else\n\t\tif (clevel)\n\t\t\tgoto err_level;\n#endif\n#endif\n\t\tbreak;\n\tcase COMPRESS_ZSTD:\n#ifdef CONFIG_F2FS_FS_ZSTD\n\t\tif (clevel < zstd_min_clevel() || clevel > zstd_max_clevel())\n\t\t\tgoto err_level;\n#endif\n\t\tbreak;\n\tdefault:\n\t\tgoto err_level;\n\t}\n\n\treturn true;\nerr_level:\n\tf2fs_warn(sbi, \"%s: inode (ino=%lx) has unsupported compress level: %u, run fsck to fix\",\n\t\t  __func__, inode->i_ino, clevel);\n\treturn false;\n}\n\nstatic bool sanity_check_inode(struct inode *inode, struct page *node_page)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\tstruct f2fs_inode *ri = F2FS_INODE(node_page);\n\tunsigned long long iblocks;\n\n\tiblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\n\tif (!iblocks) {\n\t\tf2fs_warn(sbi, \"%s: corrupted inode i_blocks i_ino=%lx iblocks=%llu, run fsck to fix.\",\n\t\t\t  __func__, inode->i_ino, iblocks);\n\t\treturn false;\n\t}\n\n\tif (ino_of_node(node_page) != nid_of_node(node_page)) {\n\t\tf2fs_warn(sbi, \"%s: corrupted inode footer i_ino=%lx, ino,nid: [%u, %u] run fsck to fix.\",\n\t\t\t  __func__, inode->i_ino,\n\t\t\t  ino_of_node(node_page), nid_of_node(node_page));\n\t\treturn false;\n\t}\n\n\tif (f2fs_has_extra_attr(inode)) {\n\t\tif (!f2fs_sb_has_extra_attr(sbi)) {\n\t\t\tf2fs_warn(sbi, \"%s: inode (ino=%lx) is with extra_attr, but extra_attr feature is off\",\n\t\t\t\t  __func__, inode->i_ino);\n\t\t\treturn false;\n\t\t}\n\t\tif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||\n\t\t\tfi->i_extra_isize < F2FS_MIN_EXTRA_ATTR_SIZE ||\n\t\t\tfi->i_extra_isize % sizeof(__le32)) {\n\t\t\tf2fs_warn(sbi, \"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, max: %zu\",\n\t\t\t\t  __func__, inode->i_ino, fi->i_extra_isize,\n\t\t\t\t  F2FS_TOTAL_EXTRA_ATTR_SIZE);\n\t\t\treturn false;\n\t\t}\n\t\tif (f2fs_sb_has_flexible_inline_xattr(sbi) &&\n\t\t\tf2fs_has_inline_xattr(inode) &&\n\t\t\t(!fi->i_inline_xattr_size ||\n\t\t\tfi->i_inline_xattr_size > MAX_INLINE_XATTR_SIZE)) {\n\t\t\tf2fs_warn(sbi, \"%s: inode (ino=%lx) has corrupted i_inline_xattr_size: %d, max: %zu\",\n\t\t\t\t  __func__, inode->i_ino, fi->i_inline_xattr_size,\n\t\t\t\t  MAX_INLINE_XATTR_SIZE);\n\t\t\treturn false;\n\t\t}\n\t\tif (f2fs_sb_has_compression(sbi) &&\n\t\t\tfi->i_flags & F2FS_COMPR_FL &&\n\t\t\tF2FS_FITS_IN_INODE(ri, fi->i_extra_isize,\n\t\t\t\t\t\ti_compress_flag)) {\n\t\t\tif (!sanity_check_compress_inode(inode, ri))\n\t\t\t\treturn false;\n\t\t}\n\t} else if (f2fs_sb_has_flexible_inline_xattr(sbi)) {\n\t\tf2fs_warn(sbi, \"%s: corrupted inode ino=%lx, run fsck to fix.\",\n\t\t\t  __func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (!f2fs_sb_has_extra_attr(sbi)) {\n\t\tif (f2fs_sb_has_project_quota(sbi)) {\n\t\t\tf2fs_warn(sbi, \"%s: corrupted inode ino=%lx, wrong feature flag: %u, run fsck to fix.\",\n\t\t\t\t  __func__, inode->i_ino, F2FS_FEATURE_PRJQUOTA);\n\t\t\treturn false;\n\t\t}\n\t\tif (f2fs_sb_has_inode_chksum(sbi)) {\n\t\t\tf2fs_warn(sbi, \"%s: corrupted inode ino=%lx, wrong feature flag: %u, run fsck to fix.\",\n\t\t\t\t  __func__, inode->i_ino, F2FS_FEATURE_INODE_CHKSUM);\n\t\t\treturn false;\n\t\t}\n\t\tif (f2fs_sb_has_flexible_inline_xattr(sbi)) {\n\t\t\tf2fs_warn(sbi, \"%s: corrupted inode ino=%lx, wrong feature flag: %u, run fsck to fix.\",\n\t\t\t\t  __func__, inode->i_ino, F2FS_FEATURE_FLEXIBLE_INLINE_XATTR);\n\t\t\treturn false;\n\t\t}\n\t\tif (f2fs_sb_has_inode_crtime(sbi)) {\n\t\t\tf2fs_warn(sbi, \"%s: corrupted inode ino=%lx, wrong feature flag: %u, run fsck to fix.\",\n\t\t\t\t  __func__, inode->i_ino, F2FS_FEATURE_INODE_CRTIME);\n\t\t\treturn false;\n\t\t}\n\t\tif (f2fs_sb_has_compression(sbi)) {\n\t\t\tf2fs_warn(sbi, \"%s: corrupted inode ino=%lx, wrong feature flag: %u, run fsck to fix.\",\n\t\t\t\t  __func__, inode->i_ino, F2FS_FEATURE_COMPRESSION);\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tif (f2fs_sanity_check_inline_data(inode)) {\n\t\tf2fs_warn(sbi, \"%s: inode (ino=%lx, mode=%u) should not have inline_data, run fsck to fix\",\n\t\t\t  __func__, inode->i_ino, inode->i_mode);\n\t\treturn false;\n\t}\n\n\tif (f2fs_has_inline_dentry(inode) && !S_ISDIR(inode->i_mode)) {\n\t\tf2fs_warn(sbi, \"%s: inode (ino=%lx, mode=%u) should not have inline_dentry, run fsck to fix\",\n\t\t\t  __func__, inode->i_ino, inode->i_mode);\n\t\treturn false;\n\t}\n\n\tif ((fi->i_flags & F2FS_CASEFOLD_FL) && !f2fs_sb_has_casefold(sbi)) {\n\t\tf2fs_warn(sbi, \"%s: inode (ino=%lx) has casefold flag, but casefold feature is off\",\n\t\t\t  __func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void init_idisk_time(struct inode *inode)\n{\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\n\tfi->i_disk_time[0] = inode->i_atime;\n\tfi->i_disk_time[1] = inode_get_ctime(inode);\n\tfi->i_disk_time[2] = inode->i_mtime;\n}\n\nstatic int do_read_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\tstruct page *node_page;\n\tstruct f2fs_inode *ri;\n\tprojid_t i_projid;\n\tint err;\n\n\t \n\tif (f2fs_check_nid_range(sbi, inode->i_ino))\n\t\treturn -EINVAL;\n\n\tnode_page = f2fs_get_node_page(sbi, inode->i_ino);\n\tif (IS_ERR(node_page))\n\t\treturn PTR_ERR(node_page);\n\n\tri = F2FS_INODE(node_page);\n\n\tinode->i_mode = le16_to_cpu(ri->i_mode);\n\ti_uid_write(inode, le32_to_cpu(ri->i_uid));\n\ti_gid_write(inode, le32_to_cpu(ri->i_gid));\n\tset_nlink(inode, le32_to_cpu(ri->i_links));\n\tinode->i_size = le64_to_cpu(ri->i_size);\n\tinode->i_blocks = SECTOR_FROM_BLOCK(le64_to_cpu(ri->i_blocks) - 1);\n\n\tinode->i_atime.tv_sec = le64_to_cpu(ri->i_atime);\n\tinode_set_ctime(inode, le64_to_cpu(ri->i_ctime),\n\t\t\tle32_to_cpu(ri->i_ctime_nsec));\n\tinode->i_mtime.tv_sec = le64_to_cpu(ri->i_mtime);\n\tinode->i_atime.tv_nsec = le32_to_cpu(ri->i_atime_nsec);\n\tinode->i_mtime.tv_nsec = le32_to_cpu(ri->i_mtime_nsec);\n\tinode->i_generation = le32_to_cpu(ri->i_generation);\n\tif (S_ISDIR(inode->i_mode))\n\t\tfi->i_current_depth = le32_to_cpu(ri->i_current_depth);\n\telse if (S_ISREG(inode->i_mode))\n\t\tfi->i_gc_failures[GC_FAILURE_PIN] =\n\t\t\t\t\tle16_to_cpu(ri->i_gc_failures);\n\tfi->i_xattr_nid = le32_to_cpu(ri->i_xattr_nid);\n\tfi->i_flags = le32_to_cpu(ri->i_flags);\n\tif (S_ISREG(inode->i_mode))\n\t\tfi->i_flags &= ~F2FS_PROJINHERIT_FL;\n\tbitmap_zero(fi->flags, FI_MAX);\n\tfi->i_advise = ri->i_advise;\n\tfi->i_pino = le32_to_cpu(ri->i_pino);\n\tfi->i_dir_level = ri->i_dir_level;\n\n\tget_inline_info(inode, ri);\n\n\tfi->i_extra_isize = f2fs_has_extra_attr(inode) ?\n\t\t\t\t\tle16_to_cpu(ri->i_extra_isize) : 0;\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi)) {\n\t\tfi->i_inline_xattr_size = le16_to_cpu(ri->i_inline_xattr_size);\n\t} else if (f2fs_has_inline_xattr(inode) ||\n\t\t\t\tf2fs_has_inline_dentry(inode)) {\n\t\tfi->i_inline_xattr_size = DEFAULT_INLINE_XATTR_ADDRS;\n\t} else {\n\n\t\t \n\t\tfi->i_inline_xattr_size = 0;\n\t}\n\n\tif (!sanity_check_inode(inode, node_page)) {\n\t\tf2fs_put_page(node_page, 1);\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_handle_error(sbi, ERROR_CORRUPTED_INODE);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t \n\tif (f2fs_has_inline_data(inode) && !f2fs_exist_data(inode))\n\t\t__recover_inline_status(inode, node_page);\n\n\t \n\tif (!S_ISDIR(inode->i_mode) && !is_cold_node(node_page)) {\n\t\tf2fs_wait_on_page_writeback(node_page, NODE, true, true);\n\t\tset_cold_node(node_page, false);\n\t\tset_page_dirty(node_page);\n\t}\n\n\t \n\t__get_inode_rdev(inode, ri);\n\n\tif (S_ISREG(inode->i_mode)) {\n\t\terr = __written_first_block(sbi, ri);\n\t\tif (err < 0) {\n\t\t\tf2fs_put_page(node_page, 1);\n\t\t\treturn err;\n\t\t}\n\t\tif (!err)\n\t\t\tset_inode_flag(inode, FI_FIRST_BLOCK_WRITTEN);\n\t}\n\n\tif (!f2fs_need_inode_block_update(sbi, inode->i_ino))\n\t\tfi->last_disk_size = inode->i_size;\n\n\tif (fi->i_flags & F2FS_PROJINHERIT_FL)\n\t\tset_inode_flag(inode, FI_PROJ_INHERIT);\n\n\tif (f2fs_has_extra_attr(inode) && f2fs_sb_has_project_quota(sbi) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, fi->i_extra_isize, i_projid))\n\t\ti_projid = (projid_t)le32_to_cpu(ri->i_projid);\n\telse\n\t\ti_projid = F2FS_DEF_PROJID;\n\tfi->i_projid = make_kprojid(&init_user_ns, i_projid);\n\n\tif (f2fs_has_extra_attr(inode) && f2fs_sb_has_inode_crtime(sbi) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, fi->i_extra_isize, i_crtime)) {\n\t\tfi->i_crtime.tv_sec = le64_to_cpu(ri->i_crtime);\n\t\tfi->i_crtime.tv_nsec = le32_to_cpu(ri->i_crtime_nsec);\n\t}\n\n\tif (f2fs_has_extra_attr(inode) && f2fs_sb_has_compression(sbi) &&\n\t\t\t\t\t(fi->i_flags & F2FS_COMPR_FL)) {\n\t\tif (F2FS_FITS_IN_INODE(ri, fi->i_extra_isize,\n\t\t\t\t\ti_compress_flag)) {\n\t\t\tunsigned short compress_flag;\n\n\t\t\tatomic_set(&fi->i_compr_blocks,\n\t\t\t\t\tle64_to_cpu(ri->i_compr_blocks));\n\t\t\tfi->i_compress_algorithm = ri->i_compress_algorithm;\n\t\t\tfi->i_log_cluster_size = ri->i_log_cluster_size;\n\t\t\tcompress_flag = le16_to_cpu(ri->i_compress_flag);\n\t\t\tfi->i_compress_level = compress_flag >>\n\t\t\t\t\t\tCOMPRESS_LEVEL_OFFSET;\n\t\t\tfi->i_compress_flag = compress_flag &\n\t\t\t\t\tGENMASK(COMPRESS_LEVEL_OFFSET - 1, 0);\n\t\t\tfi->i_cluster_size = BIT(fi->i_log_cluster_size);\n\t\t\tset_inode_flag(inode, FI_COMPRESSED_FILE);\n\t\t}\n\t}\n\n\tinit_idisk_time(inode);\n\n\t \n\tf2fs_init_read_extent_tree(inode, node_page);\n\tf2fs_init_age_extent_tree(inode);\n\n\tif (!sanity_check_extent_cache(inode)) {\n\t\tf2fs_put_page(node_page, 1);\n\t\tf2fs_handle_error(sbi, ERROR_CORRUPTED_INODE);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tf2fs_put_page(node_page, 1);\n\n\tstat_inc_inline_xattr(inode);\n\tstat_inc_inline_inode(inode);\n\tstat_inc_inline_dir(inode);\n\tstat_inc_compr_inode(inode);\n\tstat_add_compr_blocks(inode, atomic_read(&fi->i_compr_blocks));\n\n\treturn 0;\n}\n\nstatic bool is_meta_ino(struct f2fs_sb_info *sbi, unsigned int ino)\n{\n\treturn ino == F2FS_NODE_INO(sbi) || ino == F2FS_META_INO(sbi) ||\n\t\tino == F2FS_COMPRESS_INO(sbi);\n}\n\nstruct inode *f2fs_iget(struct super_block *sb, unsigned long ino)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct inode *inode;\n\tint ret = 0;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (!(inode->i_state & I_NEW)) {\n\t\tif (is_meta_ino(sbi, ino)) {\n\t\t\tf2fs_err(sbi, \"inaccessible inode: %lu, run fsck to repair\", ino);\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tret = -EFSCORRUPTED;\n\t\t\ttrace_f2fs_iget_exit(inode, ret);\n\t\t\tiput(inode);\n\t\t\tf2fs_handle_error(sbi, ERROR_CORRUPTED_INODE);\n\t\t\treturn ERR_PTR(ret);\n\t\t}\n\n\t\ttrace_f2fs_iget(inode);\n\t\treturn inode;\n\t}\n\n\tif (is_meta_ino(sbi, ino))\n\t\tgoto make_now;\n\n\tret = do_read_inode(inode);\n\tif (ret)\n\t\tgoto bad_inode;\nmake_now:\n\tif (ino == F2FS_NODE_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_node_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (ino == F2FS_META_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_meta_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (ino == F2FS_COMPRESS_INO(sbi)) {\n#ifdef CONFIG_F2FS_FS_COMPRESSION\n\t\tinode->i_mapping->a_ops = &f2fs_compress_aops;\n\t\t \n\t\tinode->i_mode |= S_IFREG;\n#endif\n\t\tmapping_set_gfp_mask(inode->i_mapping,\n\t\t\tGFP_NOFS | __GFP_HIGHMEM | __GFP_MOVABLE);\n\t} else if (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_file_inode_operations;\n\t\tinode->i_fop = &f2fs_file_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_dir_inode_operations;\n\t\tinode->i_fop = &f2fs_dir_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (file_is_encrypt(inode))\n\t\t\tinode->i_op = &f2fs_encrypted_symlink_inode_operations;\n\t\telse\n\t\t\tinode->i_op = &f2fs_symlink_inode_operations;\n\t\tinode_nohighmem(inode);\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t\t\tS_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_special_inode_operations;\n\t\tinit_special_inode(inode, inode->i_mode, inode->i_rdev);\n\t} else {\n\t\tret = -EIO;\n\t\tgoto bad_inode;\n\t}\n\tf2fs_set_inode_flags(inode);\n\n\tif (file_should_truncate(inode) &&\n\t\t\t!is_sbi_flag_set(sbi, SBI_POR_DOING)) {\n\t\tret = f2fs_truncate(inode);\n\t\tif (ret)\n\t\t\tgoto bad_inode;\n\t\tfile_dont_truncate(inode);\n\t}\n\n\tunlock_new_inode(inode);\n\ttrace_f2fs_iget(inode);\n\treturn inode;\n\nbad_inode:\n\tf2fs_inode_synced(inode);\n\tiget_failed(inode);\n\ttrace_f2fs_iget_exit(inode, ret);\n\treturn ERR_PTR(ret);\n}\n\nstruct inode *f2fs_iget_retry(struct super_block *sb, unsigned long ino)\n{\n\tstruct inode *inode;\nretry:\n\tinode = f2fs_iget(sb, ino);\n\tif (IS_ERR(inode)) {\n\t\tif (PTR_ERR(inode) == -ENOMEM) {\n\t\t\tmemalloc_retry_wait(GFP_NOFS);\n\t\t\tgoto retry;\n\t\t}\n\t}\n\treturn inode;\n}\n\nvoid f2fs_update_inode(struct inode *inode, struct page *node_page)\n{\n\tstruct f2fs_inode *ri;\n\tstruct extent_tree *et = F2FS_I(inode)->extent_tree[EX_READ];\n\n\tf2fs_wait_on_page_writeback(node_page, NODE, true, true);\n\tset_page_dirty(node_page);\n\n\tf2fs_inode_synced(inode);\n\n\tri = F2FS_INODE(node_page);\n\n\tri->i_mode = cpu_to_le16(inode->i_mode);\n\tri->i_advise = F2FS_I(inode)->i_advise;\n\tri->i_uid = cpu_to_le32(i_uid_read(inode));\n\tri->i_gid = cpu_to_le32(i_gid_read(inode));\n\tri->i_links = cpu_to_le32(inode->i_nlink);\n\tri->i_blocks = cpu_to_le64(SECTOR_TO_BLOCK(inode->i_blocks) + 1);\n\n\tif (!f2fs_is_atomic_file(inode) ||\n\t\t\tis_inode_flag_set(inode, FI_ATOMIC_COMMITTED))\n\t\tri->i_size = cpu_to_le64(i_size_read(inode));\n\n\tif (et) {\n\t\tread_lock(&et->lock);\n\t\tset_raw_read_extent(&et->largest, &ri->i_ext);\n\t\tread_unlock(&et->lock);\n\t} else {\n\t\tmemset(&ri->i_ext, 0, sizeof(ri->i_ext));\n\t}\n\tset_raw_inline(inode, ri);\n\n\tri->i_atime = cpu_to_le64(inode->i_atime.tv_sec);\n\tri->i_ctime = cpu_to_le64(inode_get_ctime(inode).tv_sec);\n\tri->i_mtime = cpu_to_le64(inode->i_mtime.tv_sec);\n\tri->i_atime_nsec = cpu_to_le32(inode->i_atime.tv_nsec);\n\tri->i_ctime_nsec = cpu_to_le32(inode_get_ctime(inode).tv_nsec);\n\tri->i_mtime_nsec = cpu_to_le32(inode->i_mtime.tv_nsec);\n\tif (S_ISDIR(inode->i_mode))\n\t\tri->i_current_depth =\n\t\t\tcpu_to_le32(F2FS_I(inode)->i_current_depth);\n\telse if (S_ISREG(inode->i_mode))\n\t\tri->i_gc_failures =\n\t\t\tcpu_to_le16(F2FS_I(inode)->i_gc_failures[GC_FAILURE_PIN]);\n\tri->i_xattr_nid = cpu_to_le32(F2FS_I(inode)->i_xattr_nid);\n\tri->i_flags = cpu_to_le32(F2FS_I(inode)->i_flags);\n\tri->i_pino = cpu_to_le32(F2FS_I(inode)->i_pino);\n\tri->i_generation = cpu_to_le32(inode->i_generation);\n\tri->i_dir_level = F2FS_I(inode)->i_dir_level;\n\n\tif (f2fs_has_extra_attr(inode)) {\n\t\tri->i_extra_isize = cpu_to_le16(F2FS_I(inode)->i_extra_isize);\n\n\t\tif (f2fs_sb_has_flexible_inline_xattr(F2FS_I_SB(inode)))\n\t\t\tri->i_inline_xattr_size =\n\t\t\t\tcpu_to_le16(F2FS_I(inode)->i_inline_xattr_size);\n\n\t\tif (f2fs_sb_has_project_quota(F2FS_I_SB(inode)) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, F2FS_I(inode)->i_extra_isize,\n\t\t\t\t\t\t\t\ti_projid)) {\n\t\t\tprojid_t i_projid;\n\n\t\t\ti_projid = from_kprojid(&init_user_ns,\n\t\t\t\t\t\tF2FS_I(inode)->i_projid);\n\t\t\tri->i_projid = cpu_to_le32(i_projid);\n\t\t}\n\n\t\tif (f2fs_sb_has_inode_crtime(F2FS_I_SB(inode)) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, F2FS_I(inode)->i_extra_isize,\n\t\t\t\t\t\t\t\ti_crtime)) {\n\t\t\tri->i_crtime =\n\t\t\t\tcpu_to_le64(F2FS_I(inode)->i_crtime.tv_sec);\n\t\t\tri->i_crtime_nsec =\n\t\t\t\tcpu_to_le32(F2FS_I(inode)->i_crtime.tv_nsec);\n\t\t}\n\n\t\tif (f2fs_sb_has_compression(F2FS_I_SB(inode)) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, F2FS_I(inode)->i_extra_isize,\n\t\t\t\t\t\t\ti_compress_flag)) {\n\t\t\tunsigned short compress_flag;\n\n\t\t\tri->i_compr_blocks =\n\t\t\t\tcpu_to_le64(atomic_read(\n\t\t\t\t\t&F2FS_I(inode)->i_compr_blocks));\n\t\t\tri->i_compress_algorithm =\n\t\t\t\tF2FS_I(inode)->i_compress_algorithm;\n\t\t\tcompress_flag = F2FS_I(inode)->i_compress_flag |\n\t\t\t\tF2FS_I(inode)->i_compress_level <<\n\t\t\t\t\t\tCOMPRESS_LEVEL_OFFSET;\n\t\t\tri->i_compress_flag = cpu_to_le16(compress_flag);\n\t\t\tri->i_log_cluster_size =\n\t\t\t\tF2FS_I(inode)->i_log_cluster_size;\n\t\t}\n\t}\n\n\t__set_inode_rdev(inode, ri);\n\n\t \n\tif (inode->i_nlink == 0)\n\t\tclear_page_private_inline(node_page);\n\n\tinit_idisk_time(inode);\n#ifdef CONFIG_F2FS_CHECK_FS\n\tf2fs_inode_chksum_set(F2FS_I_SB(inode), node_page);\n#endif\n}\n\nvoid f2fs_update_inode_page(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct page *node_page;\n\tint count = 0;\nretry:\n\tnode_page = f2fs_get_node_page(sbi, inode->i_ino);\n\tif (IS_ERR(node_page)) {\n\t\tint err = PTR_ERR(node_page);\n\n\t\t \n\t\tif (err == -ENOENT)\n\t\t\treturn;\n\n\t\tif (err == -ENOMEM || ++count <= DEFAULT_RETRY_IO_COUNT)\n\t\t\tgoto retry;\n\t\tf2fs_stop_checkpoint(sbi, false, STOP_CP_REASON_UPDATE_INODE);\n\t\treturn;\n\t}\n\tf2fs_update_inode(inode, node_page);\n\tf2fs_put_page(node_page, 1);\n}\n\nint f2fs_write_inode(struct inode *inode, struct writeback_control *wbc)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\tif (inode->i_ino == F2FS_NODE_INO(sbi) ||\n\t\t\tinode->i_ino == F2FS_META_INO(sbi))\n\t\treturn 0;\n\n\t \n\tif (f2fs_is_time_consistent(inode) &&\n\t\t!is_inode_flag_set(inode, FI_DIRTY_INODE))\n\t\treturn 0;\n\n\tif (!f2fs_is_checkpoint_ready(sbi))\n\t\treturn -ENOSPC;\n\n\t \n\tf2fs_update_inode_page(inode);\n\tif (wbc && wbc->nr_to_write)\n\t\tf2fs_balance_fs(sbi, true);\n\treturn 0;\n}\n\n \nvoid f2fs_evict_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\tnid_t xnid = fi->i_xattr_nid;\n\tint err = 0;\n\n\tf2fs_abort_atomic_write(inode, true);\n\n\tif (fi->cow_inode) {\n\t\tclear_inode_flag(fi->cow_inode, FI_COW_FILE);\n\t\tiput(fi->cow_inode);\n\t\tfi->cow_inode = NULL;\n\t}\n\n\ttrace_f2fs_evict_inode(inode);\n\ttruncate_inode_pages_final(&inode->i_data);\n\n\tif ((inode->i_nlink || is_bad_inode(inode)) &&\n\t\ttest_opt(sbi, COMPRESS_CACHE) && f2fs_compressed_file(inode))\n\t\tf2fs_invalidate_compress_pages(sbi, inode->i_ino);\n\n\tif (inode->i_ino == F2FS_NODE_INO(sbi) ||\n\t\t\tinode->i_ino == F2FS_META_INO(sbi) ||\n\t\t\tinode->i_ino == F2FS_COMPRESS_INO(sbi))\n\t\tgoto out_clear;\n\n\tf2fs_bug_on(sbi, get_dirty_pages(inode));\n\tf2fs_remove_dirty_inode(inode);\n\n\tf2fs_destroy_extent_tree(inode);\n\n\tif (inode->i_nlink || is_bad_inode(inode))\n\t\tgoto no_delete;\n\n\terr = f2fs_dquot_initialize(inode);\n\tif (err) {\n\t\terr = 0;\n\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\t}\n\n\tf2fs_remove_ino_entry(sbi, inode->i_ino, APPEND_INO);\n\tf2fs_remove_ino_entry(sbi, inode->i_ino, UPDATE_INO);\n\tf2fs_remove_ino_entry(sbi, inode->i_ino, FLUSH_INO);\n\n\tif (!is_sbi_flag_set(sbi, SBI_IS_FREEZING))\n\t\tsb_start_intwrite(inode->i_sb);\n\tset_inode_flag(inode, FI_NO_ALLOC);\n\ti_size_write(inode, 0);\nretry:\n\tif (F2FS_HAS_BLOCKS(inode))\n\t\terr = f2fs_truncate(inode);\n\n\tif (time_to_inject(sbi, FAULT_EVICT_INODE))\n\t\terr = -EIO;\n\n\tif (!err) {\n\t\tf2fs_lock_op(sbi);\n\t\terr = f2fs_remove_inode_page(inode);\n\t\tf2fs_unlock_op(sbi);\n\t\tif (err == -ENOENT) {\n\t\t\terr = 0;\n\n\t\t\t \n\t\t\tif (is_inode_flag_set(inode, FI_DIRTY_INODE)) {\n\t\t\t\tf2fs_warn(F2FS_I_SB(inode),\n\t\t\t\t\t\"f2fs_evict_inode: inconsistent node id, ino:%lu\",\n\t\t\t\t\tinode->i_ino);\n\t\t\t\tf2fs_inode_synced(inode);\n\t\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (err == -ENOMEM) {\n\t\terr = 0;\n\t\tgoto retry;\n\t}\n\n\tif (err) {\n\t\tf2fs_update_inode_page(inode);\n\t\tif (dquot_initialize_needed(inode))\n\t\t\tset_sbi_flag(sbi, SBI_QUOTA_NEED_REPAIR);\n\t}\n\tif (!is_sbi_flag_set(sbi, SBI_IS_FREEZING))\n\t\tsb_end_intwrite(inode->i_sb);\nno_delete:\n\tdquot_drop(inode);\n\n\tstat_dec_inline_xattr(inode);\n\tstat_dec_inline_dir(inode);\n\tstat_dec_inline_inode(inode);\n\tstat_dec_compr_inode(inode);\n\tstat_sub_compr_blocks(inode,\n\t\t\tatomic_read(&fi->i_compr_blocks));\n\n\tif (likely(!f2fs_cp_error(sbi) &&\n\t\t\t\t!is_sbi_flag_set(sbi, SBI_CP_DISABLED)))\n\t\tf2fs_bug_on(sbi, is_inode_flag_set(inode, FI_DIRTY_INODE));\n\telse\n\t\tf2fs_inode_synced(inode);\n\n\t \n\tif (inode->i_ino)\n\t\tinvalidate_mapping_pages(NODE_MAPPING(sbi), inode->i_ino,\n\t\t\t\t\t\t\tinode->i_ino);\n\tif (xnid)\n\t\tinvalidate_mapping_pages(NODE_MAPPING(sbi), xnid, xnid);\n\tif (inode->i_nlink) {\n\t\tif (is_inode_flag_set(inode, FI_APPEND_WRITE))\n\t\t\tf2fs_add_ino_entry(sbi, inode->i_ino, APPEND_INO);\n\t\tif (is_inode_flag_set(inode, FI_UPDATE_WRITE))\n\t\t\tf2fs_add_ino_entry(sbi, inode->i_ino, UPDATE_INO);\n\t}\n\tif (is_inode_flag_set(inode, FI_FREE_NID)) {\n\t\tf2fs_alloc_nid_failed(sbi, inode->i_ino);\n\t\tclear_inode_flag(inode, FI_FREE_NID);\n\t} else {\n\t\t \n\t}\nout_clear:\n\tfscrypt_put_encryption_info(inode);\n\tfsverity_cleanup_inode(inode);\n\tclear_inode(inode);\n}\n\n \nvoid f2fs_handle_failed_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct node_info ni;\n\tint err;\n\n\t \n\tclear_nlink(inode);\n\n\t \n\tf2fs_update_inode_page(inode);\n\tf2fs_inode_synced(inode);\n\n\t \n\tunlock_new_inode(inode);\n\n\t \n\terr = f2fs_get_node_info(sbi, inode->i_ino, &ni, false);\n\tif (err) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tset_inode_flag(inode, FI_FREE_NID);\n\t\tf2fs_warn(sbi, \"May loss orphan inode, run fsck to fix.\");\n\t\tgoto out;\n\t}\n\n\tif (ni.blk_addr != NULL_ADDR) {\n\t\terr = f2fs_acquire_orphan_inode(sbi);\n\t\tif (err) {\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tf2fs_warn(sbi, \"Too many orphan inodes, run fsck to fix.\");\n\t\t} else {\n\t\t\tf2fs_add_orphan_inode(inode);\n\t\t}\n\t\tf2fs_alloc_nid_done(sbi, inode->i_ino);\n\t} else {\n\t\tset_inode_flag(inode, FI_FREE_NID);\n\t}\n\nout:\n\tf2fs_unlock_op(sbi);\n\n\t \n\tiput(inode);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}