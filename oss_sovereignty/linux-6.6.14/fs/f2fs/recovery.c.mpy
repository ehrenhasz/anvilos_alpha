{
  "module_name": "recovery.c",
  "hash_id": "e5a2f106bd972e18bbe04300a44edbdfc21519f88fac4d39bd6f0468a31bcba6",
  "original_prompt": "Ingested from linux-6.6.14/fs/f2fs/recovery.c",
  "human_readable_source": "\n \n#include <asm/unaligned.h>\n#include <linux/fs.h>\n#include <linux/f2fs_fs.h>\n#include <linux/sched/mm.h>\n#include \"f2fs.h\"\n#include \"node.h\"\n#include \"segment.h\"\n\n \n\nstatic struct kmem_cache *fsync_entry_slab;\n\n#if IS_ENABLED(CONFIG_UNICODE)\nextern struct kmem_cache *f2fs_cf_name_slab;\n#endif\n\nbool f2fs_space_for_roll_forward(struct f2fs_sb_info *sbi)\n{\n\ts64 nalloc = percpu_counter_sum_positive(&sbi->alloc_valid_block_count);\n\n\tif (sbi->last_valid_block_count + nalloc > sbi->user_block_count)\n\t\treturn false;\n\tif (NM_I(sbi)->max_rf_node_blocks &&\n\t\tpercpu_counter_sum_positive(&sbi->rf_node_block_count) >=\n\t\t\t\t\t\tNM_I(sbi)->max_rf_node_blocks)\n\t\treturn false;\n\treturn true;\n}\n\nstatic struct fsync_inode_entry *get_fsync_inode(struct list_head *head,\n\t\t\t\t\t\t\t\tnid_t ino)\n{\n\tstruct fsync_inode_entry *entry;\n\n\tlist_for_each_entry(entry, head, list)\n\t\tif (entry->inode->i_ino == ino)\n\t\t\treturn entry;\n\n\treturn NULL;\n}\n\nstatic struct fsync_inode_entry *add_fsync_inode(struct f2fs_sb_info *sbi,\n\t\t\tstruct list_head *head, nid_t ino, bool quota_inode)\n{\n\tstruct inode *inode;\n\tstruct fsync_inode_entry *entry;\n\tint err;\n\n\tinode = f2fs_iget_retry(sbi->sb, ino);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\n\terr = f2fs_dquot_initialize(inode);\n\tif (err)\n\t\tgoto err_out;\n\n\tif (quota_inode) {\n\t\terr = dquot_alloc_inode(inode);\n\t\tif (err)\n\t\t\tgoto err_out;\n\t}\n\n\tentry = f2fs_kmem_cache_alloc(fsync_entry_slab,\n\t\t\t\t\tGFP_F2FS_ZERO, true, NULL);\n\tentry->inode = inode;\n\tlist_add_tail(&entry->list, head);\n\n\treturn entry;\nerr_out:\n\tiput(inode);\n\treturn ERR_PTR(err);\n}\n\nstatic void del_fsync_inode(struct fsync_inode_entry *entry, int drop)\n{\n\tif (drop) {\n\t\t \n\t\tf2fs_inode_synced(entry->inode);\n\t}\n\tiput(entry->inode);\n\tlist_del(&entry->list);\n\tkmem_cache_free(fsync_entry_slab, entry);\n}\n\nstatic int init_recovered_filename(const struct inode *dir,\n\t\t\t\t   struct f2fs_inode *raw_inode,\n\t\t\t\t   struct f2fs_filename *fname,\n\t\t\t\t   struct qstr *usr_fname)\n{\n\tint err;\n\n\tmemset(fname, 0, sizeof(*fname));\n\tfname->disk_name.len = le32_to_cpu(raw_inode->i_namelen);\n\tfname->disk_name.name = raw_inode->i_name;\n\n\tif (WARN_ON(fname->disk_name.len > F2FS_NAME_LEN))\n\t\treturn -ENAMETOOLONG;\n\n\tif (!IS_ENCRYPTED(dir)) {\n\t\tusr_fname->name = fname->disk_name.name;\n\t\tusr_fname->len = fname->disk_name.len;\n\t\tfname->usr_fname = usr_fname;\n\t}\n\n\t \n\tif (IS_ENCRYPTED(dir) && IS_CASEFOLDED(dir)) {\n\t\t \n\t\tif (fname->disk_name.len + sizeof(f2fs_hash_t) > F2FS_NAME_LEN)\n\t\t\treturn -EINVAL;\n\t\tfname->hash = get_unaligned((f2fs_hash_t *)\n\t\t\t\t&raw_inode->i_name[fname->disk_name.len]);\n\t} else if (IS_CASEFOLDED(dir)) {\n\t\terr = f2fs_init_casefolded_name(dir, fname);\n\t\tif (err)\n\t\t\treturn err;\n\t\tf2fs_hash_filename(dir, fname);\n#if IS_ENABLED(CONFIG_UNICODE)\n\t\t \n\t\tkmem_cache_free(f2fs_cf_name_slab, fname->cf_name.name);\n\t\tfname->cf_name.name = NULL;\n#endif\n\t} else {\n\t\tf2fs_hash_filename(dir, fname);\n\t}\n\treturn 0;\n}\n\nstatic int recover_dentry(struct inode *inode, struct page *ipage,\n\t\t\t\t\t\tstruct list_head *dir_list)\n{\n\tstruct f2fs_inode *raw_inode = F2FS_INODE(ipage);\n\tnid_t pino = le32_to_cpu(raw_inode->i_pino);\n\tstruct f2fs_dir_entry *de;\n\tstruct f2fs_filename fname;\n\tstruct qstr usr_fname;\n\tstruct page *page;\n\tstruct inode *dir, *einode;\n\tstruct fsync_inode_entry *entry;\n\tint err = 0;\n\tchar *name;\n\n\tentry = get_fsync_inode(dir_list, pino);\n\tif (!entry) {\n\t\tentry = add_fsync_inode(F2FS_I_SB(inode), dir_list,\n\t\t\t\t\t\t\tpino, false);\n\t\tif (IS_ERR(entry)) {\n\t\t\tdir = ERR_CAST(entry);\n\t\t\terr = PTR_ERR(entry);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tdir = entry->inode;\n\terr = init_recovered_filename(dir, raw_inode, &fname, &usr_fname);\n\tif (err)\n\t\tgoto out;\nretry:\n\tde = __f2fs_find_entry(dir, &fname, &page);\n\tif (de && inode->i_ino == le32_to_cpu(de->ino))\n\t\tgoto out_put;\n\n\tif (de) {\n\t\teinode = f2fs_iget_retry(inode->i_sb, le32_to_cpu(de->ino));\n\t\tif (IS_ERR(einode)) {\n\t\t\tWARN_ON(1);\n\t\t\terr = PTR_ERR(einode);\n\t\t\tif (err == -ENOENT)\n\t\t\t\terr = -EEXIST;\n\t\t\tgoto out_put;\n\t\t}\n\n\t\terr = f2fs_dquot_initialize(einode);\n\t\tif (err) {\n\t\t\tiput(einode);\n\t\t\tgoto out_put;\n\t\t}\n\n\t\terr = f2fs_acquire_orphan_inode(F2FS_I_SB(inode));\n\t\tif (err) {\n\t\t\tiput(einode);\n\t\t\tgoto out_put;\n\t\t}\n\t\tf2fs_delete_entry(de, page, dir, einode);\n\t\tiput(einode);\n\t\tgoto retry;\n\t} else if (IS_ERR(page)) {\n\t\terr = PTR_ERR(page);\n\t} else {\n\t\terr = f2fs_add_dentry(dir, &fname, inode,\n\t\t\t\t\tinode->i_ino, inode->i_mode);\n\t}\n\tif (err == -ENOMEM)\n\t\tgoto retry;\n\tgoto out;\n\nout_put:\n\tf2fs_put_page(page, 0);\nout:\n\tif (file_enc_name(inode))\n\t\tname = \"<encrypted>\";\n\telse\n\t\tname = raw_inode->i_name;\n\tf2fs_notice(F2FS_I_SB(inode), \"%s: ino = %x, name = %s, dir = %lx, err = %d\",\n\t\t    __func__, ino_of_node(ipage), name,\n\t\t    IS_ERR(dir) ? 0 : dir->i_ino, err);\n\treturn err;\n}\n\nstatic int recover_quota_data(struct inode *inode, struct page *page)\n{\n\tstruct f2fs_inode *raw = F2FS_INODE(page);\n\tstruct iattr attr;\n\tuid_t i_uid = le32_to_cpu(raw->i_uid);\n\tgid_t i_gid = le32_to_cpu(raw->i_gid);\n\tint err;\n\n\tmemset(&attr, 0, sizeof(attr));\n\n\tattr.ia_vfsuid = VFSUIDT_INIT(make_kuid(inode->i_sb->s_user_ns, i_uid));\n\tattr.ia_vfsgid = VFSGIDT_INIT(make_kgid(inode->i_sb->s_user_ns, i_gid));\n\n\tif (!vfsuid_eq(attr.ia_vfsuid, i_uid_into_vfsuid(&nop_mnt_idmap, inode)))\n\t\tattr.ia_valid |= ATTR_UID;\n\tif (!vfsgid_eq(attr.ia_vfsgid, i_gid_into_vfsgid(&nop_mnt_idmap, inode)))\n\t\tattr.ia_valid |= ATTR_GID;\n\n\tif (!attr.ia_valid)\n\t\treturn 0;\n\n\terr = dquot_transfer(&nop_mnt_idmap, inode, &attr);\n\tif (err)\n\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_QUOTA_NEED_REPAIR);\n\treturn err;\n}\n\nstatic void recover_inline_flags(struct inode *inode, struct f2fs_inode *ri)\n{\n\tif (ri->i_inline & F2FS_PIN_FILE)\n\t\tset_inode_flag(inode, FI_PIN_FILE);\n\telse\n\t\tclear_inode_flag(inode, FI_PIN_FILE);\n\tif (ri->i_inline & F2FS_DATA_EXIST)\n\t\tset_inode_flag(inode, FI_DATA_EXIST);\n\telse\n\t\tclear_inode_flag(inode, FI_DATA_EXIST);\n}\n\nstatic int recover_inode(struct inode *inode, struct page *page)\n{\n\tstruct f2fs_inode *raw = F2FS_INODE(page);\n\tchar *name;\n\tint err;\n\n\tinode->i_mode = le16_to_cpu(raw->i_mode);\n\n\terr = recover_quota_data(inode, page);\n\tif (err)\n\t\treturn err;\n\n\ti_uid_write(inode, le32_to_cpu(raw->i_uid));\n\ti_gid_write(inode, le32_to_cpu(raw->i_gid));\n\n\tif (raw->i_inline & F2FS_EXTRA_ATTR) {\n\t\tif (f2fs_sb_has_project_quota(F2FS_I_SB(inode)) &&\n\t\t\tF2FS_FITS_IN_INODE(raw, le16_to_cpu(raw->i_extra_isize),\n\t\t\t\t\t\t\t\ti_projid)) {\n\t\t\tprojid_t i_projid;\n\t\t\tkprojid_t kprojid;\n\n\t\t\ti_projid = (projid_t)le32_to_cpu(raw->i_projid);\n\t\t\tkprojid = make_kprojid(&init_user_ns, i_projid);\n\n\t\t\tif (!projid_eq(kprojid, F2FS_I(inode)->i_projid)) {\n\t\t\t\terr = f2fs_transfer_project_quota(inode,\n\t\t\t\t\t\t\t\tkprojid);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t\tF2FS_I(inode)->i_projid = kprojid;\n\t\t\t}\n\t\t}\n\t}\n\n\tf2fs_i_size_write(inode, le64_to_cpu(raw->i_size));\n\tinode->i_atime.tv_sec = le64_to_cpu(raw->i_atime);\n\tinode_set_ctime(inode, le64_to_cpu(raw->i_ctime),\n\t\t\tle32_to_cpu(raw->i_ctime_nsec));\n\tinode->i_mtime.tv_sec = le64_to_cpu(raw->i_mtime);\n\tinode->i_atime.tv_nsec = le32_to_cpu(raw->i_atime_nsec);\n\tinode->i_mtime.tv_nsec = le32_to_cpu(raw->i_mtime_nsec);\n\n\tF2FS_I(inode)->i_advise = raw->i_advise;\n\tF2FS_I(inode)->i_flags = le32_to_cpu(raw->i_flags);\n\tf2fs_set_inode_flags(inode);\n\tF2FS_I(inode)->i_gc_failures[GC_FAILURE_PIN] =\n\t\t\t\tle16_to_cpu(raw->i_gc_failures);\n\n\trecover_inline_flags(inode, raw);\n\n\tf2fs_mark_inode_dirty_sync(inode, true);\n\n\tif (file_enc_name(inode))\n\t\tname = \"<encrypted>\";\n\telse\n\t\tname = F2FS_INODE(page)->i_name;\n\n\tf2fs_notice(F2FS_I_SB(inode), \"recover_inode: ino = %x, name = %s, inline = %x\",\n\t\t    ino_of_node(page), name, raw->i_inline);\n\treturn 0;\n}\n\nstatic unsigned int adjust_por_ra_blocks(struct f2fs_sb_info *sbi,\n\t\t\t\tunsigned int ra_blocks, unsigned int blkaddr,\n\t\t\t\tunsigned int next_blkaddr)\n{\n\tif (blkaddr + 1 == next_blkaddr)\n\t\tra_blocks = min_t(unsigned int, RECOVERY_MAX_RA_BLOCKS,\n\t\t\t\t\t\t\tra_blocks * 2);\n\telse if (next_blkaddr % sbi->blocks_per_seg)\n\t\tra_blocks = max_t(unsigned int, RECOVERY_MIN_RA_BLOCKS,\n\t\t\t\t\t\t\tra_blocks / 2);\n\treturn ra_blocks;\n}\n\n \nstatic int sanity_check_node_chain(struct f2fs_sb_info *sbi, block_t blkaddr,\n\t\tblock_t *blkaddr_fast, bool *is_detecting)\n{\n\tunsigned int ra_blocks = RECOVERY_MAX_RA_BLOCKS;\n\tstruct page *page = NULL;\n\tint i;\n\n\tif (!*is_detecting)\n\t\treturn 0;\n\n\tfor (i = 0; i < 2; i++) {\n\t\tif (!f2fs_is_valid_blkaddr(sbi, *blkaddr_fast, META_POR)) {\n\t\t\t*is_detecting = false;\n\t\t\treturn 0;\n\t\t}\n\n\t\tpage = f2fs_get_tmp_page(sbi, *blkaddr_fast);\n\t\tif (IS_ERR(page))\n\t\t\treturn PTR_ERR(page);\n\n\t\tif (!is_recoverable_dnode(page)) {\n\t\t\tf2fs_put_page(page, 1);\n\t\t\t*is_detecting = false;\n\t\t\treturn 0;\n\t\t}\n\n\t\tra_blocks = adjust_por_ra_blocks(sbi, ra_blocks, *blkaddr_fast,\n\t\t\t\t\t\tnext_blkaddr_of_node(page));\n\n\t\t*blkaddr_fast = next_blkaddr_of_node(page);\n\t\tf2fs_put_page(page, 1);\n\n\t\tf2fs_ra_meta_pages_cond(sbi, *blkaddr_fast, ra_blocks);\n\t}\n\n\tif (*blkaddr_fast == blkaddr) {\n\t\tf2fs_notice(sbi, \"%s: Detect looped node chain on blkaddr:%u.\"\n\t\t\t\t\" Run fsck to fix it.\", __func__, blkaddr);\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int find_fsync_dnodes(struct f2fs_sb_info *sbi, struct list_head *head,\n\t\t\t\tbool check_only)\n{\n\tstruct curseg_info *curseg;\n\tstruct page *page = NULL;\n\tblock_t blkaddr, blkaddr_fast;\n\tbool is_detecting = true;\n\tint err = 0;\n\n\t \n\tcurseg = CURSEG_I(sbi, CURSEG_WARM_NODE);\n\tblkaddr = NEXT_FREE_BLKADDR(sbi, curseg);\n\tblkaddr_fast = blkaddr;\n\n\twhile (1) {\n\t\tstruct fsync_inode_entry *entry;\n\n\t\tif (!f2fs_is_valid_blkaddr(sbi, blkaddr, META_POR))\n\t\t\treturn 0;\n\n\t\tpage = f2fs_get_tmp_page(sbi, blkaddr);\n\t\tif (IS_ERR(page)) {\n\t\t\terr = PTR_ERR(page);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!is_recoverable_dnode(page)) {\n\t\t\tf2fs_put_page(page, 1);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!is_fsync_dnode(page))\n\t\t\tgoto next;\n\n\t\tentry = get_fsync_inode(head, ino_of_node(page));\n\t\tif (!entry) {\n\t\t\tbool quota_inode = false;\n\n\t\t\tif (!check_only &&\n\t\t\t\t\tIS_INODE(page) && is_dent_dnode(page)) {\n\t\t\t\terr = f2fs_recover_inode_page(sbi, page);\n\t\t\t\tif (err) {\n\t\t\t\t\tf2fs_put_page(page, 1);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tquota_inode = true;\n\t\t\t}\n\n\t\t\t \n\t\t\tentry = add_fsync_inode(sbi, head, ino_of_node(page),\n\t\t\t\t\t\t\t\tquota_inode);\n\t\t\tif (IS_ERR(entry)) {\n\t\t\t\terr = PTR_ERR(entry);\n\t\t\t\tif (err == -ENOENT)\n\t\t\t\t\tgoto next;\n\t\t\t\tf2fs_put_page(page, 1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tentry->blkaddr = blkaddr;\n\n\t\tif (IS_INODE(page) && is_dent_dnode(page))\n\t\t\tentry->last_dentry = blkaddr;\nnext:\n\t\t \n\t\tblkaddr = next_blkaddr_of_node(page);\n\t\tf2fs_put_page(page, 1);\n\n\t\terr = sanity_check_node_chain(sbi, blkaddr, &blkaddr_fast,\n\t\t\t\t&is_detecting);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\treturn err;\n}\n\nstatic void destroy_fsync_dnodes(struct list_head *head, int drop)\n{\n\tstruct fsync_inode_entry *entry, *tmp;\n\n\tlist_for_each_entry_safe(entry, tmp, head, list)\n\t\tdel_fsync_inode(entry, drop);\n}\n\nstatic int check_index_in_prev_nodes(struct f2fs_sb_info *sbi,\n\t\t\tblock_t blkaddr, struct dnode_of_data *dn)\n{\n\tstruct seg_entry *sentry;\n\tunsigned int segno = GET_SEGNO(sbi, blkaddr);\n\tunsigned short blkoff = GET_BLKOFF_FROM_SEG0(sbi, blkaddr);\n\tstruct f2fs_summary_block *sum_node;\n\tstruct f2fs_summary sum;\n\tstruct page *sum_page, *node_page;\n\tstruct dnode_of_data tdn = *dn;\n\tnid_t ino, nid;\n\tstruct inode *inode;\n\tunsigned int offset, ofs_in_node, max_addrs;\n\tblock_t bidx;\n\tint i;\n\n\tsentry = get_seg_entry(sbi, segno);\n\tif (!f2fs_test_bit(blkoff, sentry->cur_valid_map))\n\t\treturn 0;\n\n\t \n\tfor (i = CURSEG_HOT_DATA; i <= CURSEG_COLD_DATA; i++) {\n\t\tstruct curseg_info *curseg = CURSEG_I(sbi, i);\n\n\t\tif (curseg->segno == segno) {\n\t\t\tsum = curseg->sum_blk->entries[blkoff];\n\t\t\tgoto got_it;\n\t\t}\n\t}\n\n\tsum_page = f2fs_get_sum_page(sbi, segno);\n\tif (IS_ERR(sum_page))\n\t\treturn PTR_ERR(sum_page);\n\tsum_node = (struct f2fs_summary_block *)page_address(sum_page);\n\tsum = sum_node->entries[blkoff];\n\tf2fs_put_page(sum_page, 1);\ngot_it:\n\t \n\tnid = le32_to_cpu(sum.nid);\n\tofs_in_node = le16_to_cpu(sum.ofs_in_node);\n\n\tmax_addrs = ADDRS_PER_PAGE(dn->node_page, dn->inode);\n\tif (ofs_in_node >= max_addrs) {\n\t\tf2fs_err(sbi, \"Inconsistent ofs_in_node:%u in summary, ino:%lu, nid:%u, max:%u\",\n\t\t\tofs_in_node, dn->inode->i_ino, nid, max_addrs);\n\t\tf2fs_handle_error(sbi, ERROR_INCONSISTENT_SUMMARY);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (dn->inode->i_ino == nid) {\n\t\ttdn.nid = nid;\n\t\tif (!dn->inode_page_locked)\n\t\t\tlock_page(dn->inode_page);\n\t\ttdn.node_page = dn->inode_page;\n\t\ttdn.ofs_in_node = ofs_in_node;\n\t\tgoto truncate_out;\n\t} else if (dn->nid == nid) {\n\t\ttdn.ofs_in_node = ofs_in_node;\n\t\tgoto truncate_out;\n\t}\n\n\t \n\tnode_page = f2fs_get_node_page(sbi, nid);\n\tif (IS_ERR(node_page))\n\t\treturn PTR_ERR(node_page);\n\n\toffset = ofs_of_node(node_page);\n\tino = ino_of_node(node_page);\n\tf2fs_put_page(node_page, 1);\n\n\tif (ino != dn->inode->i_ino) {\n\t\tint ret;\n\n\t\t \n\t\tinode = f2fs_iget_retry(sbi->sb, ino);\n\t\tif (IS_ERR(inode))\n\t\t\treturn PTR_ERR(inode);\n\n\t\tret = f2fs_dquot_initialize(inode);\n\t\tif (ret) {\n\t\t\tiput(inode);\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\tinode = dn->inode;\n\t}\n\n\tbidx = f2fs_start_bidx_of_node(offset, inode) +\n\t\t\t\tle16_to_cpu(sum.ofs_in_node);\n\n\t \n\tif (ino == dn->inode->i_ino && dn->inode_page_locked)\n\t\tunlock_page(dn->inode_page);\n\n\tset_new_dnode(&tdn, inode, NULL, NULL, 0);\n\tif (f2fs_get_dnode_of_data(&tdn, bidx, LOOKUP_NODE))\n\t\tgoto out;\n\n\tif (tdn.data_blkaddr == blkaddr)\n\t\tf2fs_truncate_data_blocks_range(&tdn, 1);\n\n\tf2fs_put_dnode(&tdn);\nout:\n\tif (ino != dn->inode->i_ino)\n\t\tiput(inode);\n\telse if (dn->inode_page_locked)\n\t\tlock_page(dn->inode_page);\n\treturn 0;\n\ntruncate_out:\n\tif (f2fs_data_blkaddr(&tdn) == blkaddr)\n\t\tf2fs_truncate_data_blocks_range(&tdn, 1);\n\tif (dn->inode->i_ino == nid && !dn->inode_page_locked)\n\t\tunlock_page(dn->inode_page);\n\treturn 0;\n}\n\nstatic int do_recover_data(struct f2fs_sb_info *sbi, struct inode *inode,\n\t\t\t\t\tstruct page *page)\n{\n\tstruct dnode_of_data dn;\n\tstruct node_info ni;\n\tunsigned int start, end;\n\tint err = 0, recovered = 0;\n\n\t \n\tif (IS_INODE(page)) {\n\t\terr = f2fs_recover_inline_xattr(inode, page);\n\t\tif (err)\n\t\t\tgoto out;\n\t} else if (f2fs_has_xattr_block(ofs_of_node(page))) {\n\t\terr = f2fs_recover_xattr_data(inode, page);\n\t\tif (!err)\n\t\t\trecovered++;\n\t\tgoto out;\n\t}\n\n\t \n\terr = f2fs_recover_inline_data(inode, page);\n\tif (err) {\n\t\tif (err == 1)\n\t\t\terr = 0;\n\t\tgoto out;\n\t}\n\n\t \n\tstart = f2fs_start_bidx_of_node(ofs_of_node(page), inode);\n\tend = start + ADDRS_PER_PAGE(page, inode);\n\n\tset_new_dnode(&dn, inode, NULL, NULL, 0);\nretry_dn:\n\terr = f2fs_get_dnode_of_data(&dn, start, ALLOC_NODE);\n\tif (err) {\n\t\tif (err == -ENOMEM) {\n\t\t\tmemalloc_retry_wait(GFP_NOFS);\n\t\t\tgoto retry_dn;\n\t\t}\n\t\tgoto out;\n\t}\n\n\tf2fs_wait_on_page_writeback(dn.node_page, NODE, true, true);\n\n\terr = f2fs_get_node_info(sbi, dn.nid, &ni, false);\n\tif (err)\n\t\tgoto err;\n\n\tf2fs_bug_on(sbi, ni.ino != ino_of_node(page));\n\n\tif (ofs_of_node(dn.node_page) != ofs_of_node(page)) {\n\t\tf2fs_warn(sbi, \"Inconsistent ofs_of_node, ino:%lu, ofs:%u, %u\",\n\t\t\t  inode->i_ino, ofs_of_node(dn.node_page),\n\t\t\t  ofs_of_node(page));\n\t\terr = -EFSCORRUPTED;\n\t\tf2fs_handle_error(sbi, ERROR_INCONSISTENT_FOOTER);\n\t\tgoto err;\n\t}\n\n\tfor (; start < end; start++, dn.ofs_in_node++) {\n\t\tblock_t src, dest;\n\n\t\tsrc = f2fs_data_blkaddr(&dn);\n\t\tdest = data_blkaddr(dn.inode, page, dn.ofs_in_node);\n\n\t\tif (__is_valid_data_blkaddr(src) &&\n\t\t\t!f2fs_is_valid_blkaddr(sbi, src, META_POR)) {\n\t\t\terr = -EFSCORRUPTED;\n\t\t\tf2fs_handle_error(sbi, ERROR_INVALID_BLKADDR);\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (__is_valid_data_blkaddr(dest) &&\n\t\t\t!f2fs_is_valid_blkaddr(sbi, dest, META_POR)) {\n\t\t\terr = -EFSCORRUPTED;\n\t\t\tf2fs_handle_error(sbi, ERROR_INVALID_BLKADDR);\n\t\t\tgoto err;\n\t\t}\n\n\t\t \n\t\tif (src == dest)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (dest == NULL_ADDR) {\n\t\t\tf2fs_truncate_data_blocks_range(&dn, 1);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!file_keep_isize(inode) &&\n\t\t\t(i_size_read(inode) <= ((loff_t)start << PAGE_SHIFT)))\n\t\t\tf2fs_i_size_write(inode,\n\t\t\t\t(loff_t)(start + 1) << PAGE_SHIFT);\n\n\t\t \n\t\tif (dest == NEW_ADDR) {\n\t\t\tf2fs_truncate_data_blocks_range(&dn, 1);\n\t\t\tf2fs_reserve_new_block(&dn);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (f2fs_is_valid_blkaddr(sbi, dest, META_POR)) {\n\n\t\t\tif (src == NULL_ADDR) {\n\t\t\t\terr = f2fs_reserve_new_block(&dn);\n\t\t\t\twhile (err &&\n\t\t\t\t       IS_ENABLED(CONFIG_F2FS_FAULT_INJECTION))\n\t\t\t\t\terr = f2fs_reserve_new_block(&dn);\n\t\t\t\t \n\t\t\t\tf2fs_bug_on(sbi, err);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto err;\n\t\t\t}\nretry_prev:\n\t\t\t \n\t\t\terr = check_index_in_prev_nodes(sbi, dest, &dn);\n\t\t\tif (err) {\n\t\t\t\tif (err == -ENOMEM) {\n\t\t\t\t\tmemalloc_retry_wait(GFP_NOFS);\n\t\t\t\t\tgoto retry_prev;\n\t\t\t\t}\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tif (f2fs_is_valid_blkaddr(sbi, dest,\n\t\t\t\t\tDATA_GENERIC_ENHANCE_UPDATE)) {\n\t\t\t\tf2fs_err(sbi, \"Inconsistent dest blkaddr:%u, ino:%lu, ofs:%u\",\n\t\t\t\t\tdest, inode->i_ino, dn.ofs_in_node);\n\t\t\t\terr = -EFSCORRUPTED;\n\t\t\t\tf2fs_handle_error(sbi,\n\t\t\t\t\t\tERROR_INVALID_BLKADDR);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\t \n\t\t\tf2fs_replace_block(sbi, &dn, src, dest,\n\t\t\t\t\t\tni.version, false, false);\n\t\t\trecovered++;\n\t\t}\n\t}\n\n\tcopy_node_footer(dn.node_page, page);\n\tfill_node_footer(dn.node_page, dn.nid, ni.ino,\n\t\t\t\t\tofs_of_node(page), false);\n\tset_page_dirty(dn.node_page);\nerr:\n\tf2fs_put_dnode(&dn);\nout:\n\tf2fs_notice(sbi, \"recover_data: ino = %lx (i_size: %s) recovered = %d, err = %d\",\n\t\t    inode->i_ino, file_keep_isize(inode) ? \"keep\" : \"recover\",\n\t\t    recovered, err);\n\treturn err;\n}\n\nstatic int recover_data(struct f2fs_sb_info *sbi, struct list_head *inode_list,\n\t\tstruct list_head *tmp_inode_list, struct list_head *dir_list)\n{\n\tstruct curseg_info *curseg;\n\tstruct page *page = NULL;\n\tint err = 0;\n\tblock_t blkaddr;\n\tunsigned int ra_blocks = RECOVERY_MAX_RA_BLOCKS;\n\n\t \n\tcurseg = CURSEG_I(sbi, CURSEG_WARM_NODE);\n\tblkaddr = NEXT_FREE_BLKADDR(sbi, curseg);\n\n\twhile (1) {\n\t\tstruct fsync_inode_entry *entry;\n\n\t\tif (!f2fs_is_valid_blkaddr(sbi, blkaddr, META_POR))\n\t\t\tbreak;\n\n\t\tpage = f2fs_get_tmp_page(sbi, blkaddr);\n\t\tif (IS_ERR(page)) {\n\t\t\terr = PTR_ERR(page);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!is_recoverable_dnode(page)) {\n\t\t\tf2fs_put_page(page, 1);\n\t\t\tbreak;\n\t\t}\n\n\t\tentry = get_fsync_inode(inode_list, ino_of_node(page));\n\t\tif (!entry)\n\t\t\tgoto next;\n\t\t \n\t\tif (IS_INODE(page)) {\n\t\t\terr = recover_inode(entry->inode, page);\n\t\t\tif (err) {\n\t\t\t\tf2fs_put_page(page, 1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (entry->last_dentry == blkaddr) {\n\t\t\terr = recover_dentry(entry->inode, page, dir_list);\n\t\t\tif (err) {\n\t\t\t\tf2fs_put_page(page, 1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\terr = do_recover_data(sbi, entry->inode, page);\n\t\tif (err) {\n\t\t\tf2fs_put_page(page, 1);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (entry->blkaddr == blkaddr)\n\t\t\tlist_move_tail(&entry->list, tmp_inode_list);\nnext:\n\t\tra_blocks = adjust_por_ra_blocks(sbi, ra_blocks, blkaddr,\n\t\t\t\t\t\tnext_blkaddr_of_node(page));\n\n\t\t \n\t\tblkaddr = next_blkaddr_of_node(page);\n\t\tf2fs_put_page(page, 1);\n\n\t\tf2fs_ra_meta_pages_cond(sbi, blkaddr, ra_blocks);\n\t}\n\tif (!err)\n\t\tf2fs_allocate_new_segments(sbi);\n\treturn err;\n}\n\nint f2fs_recover_fsync_data(struct f2fs_sb_info *sbi, bool check_only)\n{\n\tstruct list_head inode_list, tmp_inode_list;\n\tstruct list_head dir_list;\n\tint err;\n\tint ret = 0;\n\tunsigned long s_flags = sbi->sb->s_flags;\n\tbool need_writecp = false;\n\tbool fix_curseg_write_pointer = false;\n\n\tif (is_sbi_flag_set(sbi, SBI_IS_WRITABLE))\n\t\tf2fs_info(sbi, \"recover fsync data on readonly fs\");\n\n\tINIT_LIST_HEAD(&inode_list);\n\tINIT_LIST_HEAD(&tmp_inode_list);\n\tINIT_LIST_HEAD(&dir_list);\n\n\t \n\tf2fs_down_write(&sbi->cp_global_sem);\n\n\t \n\terr = find_fsync_dnodes(sbi, &inode_list, check_only);\n\tif (err || list_empty(&inode_list))\n\t\tgoto skip;\n\n\tif (check_only) {\n\t\tret = 1;\n\t\tgoto skip;\n\t}\n\n\tneed_writecp = true;\n\n\t \n\terr = recover_data(sbi, &inode_list, &tmp_inode_list, &dir_list);\n\tif (!err)\n\t\tf2fs_bug_on(sbi, !list_empty(&inode_list));\n\telse\n\t\tf2fs_bug_on(sbi, sbi->sb->s_flags & SB_ACTIVE);\nskip:\n\tfix_curseg_write_pointer = !check_only || list_empty(&inode_list);\n\n\tdestroy_fsync_dnodes(&inode_list, err);\n\tdestroy_fsync_dnodes(&tmp_inode_list, err);\n\n\t \n\ttruncate_inode_pages_range(META_MAPPING(sbi),\n\t\t\t(loff_t)MAIN_BLKADDR(sbi) << PAGE_SHIFT, -1);\n\n\tif (err) {\n\t\ttruncate_inode_pages_final(NODE_MAPPING(sbi));\n\t\ttruncate_inode_pages_final(META_MAPPING(sbi));\n\t}\n\n\t \n\tif (!err && fix_curseg_write_pointer && !f2fs_readonly(sbi->sb) &&\n\t\t\tf2fs_sb_has_blkzoned(sbi)) {\n\t\terr = f2fs_fix_curseg_write_pointer(sbi);\n\t\tret = err;\n\t}\n\n\tif (!err)\n\t\tclear_sbi_flag(sbi, SBI_POR_DOING);\n\n\tf2fs_up_write(&sbi->cp_global_sem);\n\n\t \n\tdestroy_fsync_dnodes(&dir_list, err);\n\n\tif (need_writecp) {\n\t\tset_sbi_flag(sbi, SBI_IS_RECOVERED);\n\n\t\tif (!err) {\n\t\t\tstruct cp_control cpc = {\n\t\t\t\t.reason = CP_RECOVERY,\n\t\t\t};\n\t\t\tstat_inc_cp_call_count(sbi, TOTAL_CALL);\n\t\t\terr = f2fs_write_checkpoint(sbi, &cpc);\n\t\t}\n\t}\n\n\tsbi->sb->s_flags = s_flags;  \n\n\treturn ret ? ret : err;\n}\n\nint __init f2fs_create_recovery_cache(void)\n{\n\tfsync_entry_slab = f2fs_kmem_cache_create(\"f2fs_fsync_inode_entry\",\n\t\t\t\t\tsizeof(struct fsync_inode_entry));\n\treturn fsync_entry_slab ? 0 : -ENOMEM;\n}\n\nvoid f2fs_destroy_recovery_cache(void)\n{\n\tkmem_cache_destroy(fsync_entry_slab);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}