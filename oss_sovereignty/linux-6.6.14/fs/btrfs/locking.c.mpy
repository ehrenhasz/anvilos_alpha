{
  "module_name": "locking.c",
  "hash_id": "88274accf2045958c145c630557bad71f22c907a4fa13cba327bb2322f95034d",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/locking.c",
  "human_readable_source": "\n \n\n#include <linux/sched.h>\n#include <linux/pagemap.h>\n#include <linux/spinlock.h>\n#include <linux/page-flags.h>\n#include <asm/bug.h>\n#include \"misc.h\"\n#include \"ctree.h\"\n#include \"extent_io.h\"\n#include \"locking.h\"\n#include \"accessors.h\"\n\n \n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n#if BTRFS_MAX_LEVEL != 8\n#error\n#endif\n\n#define DEFINE_LEVEL(stem, level)\t\t\t\t\t\\\n\t.names[level] = \"btrfs-\" stem \"-0\" #level,\n\n#define DEFINE_NAME(stem)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 0)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 1)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 2)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 3)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 4)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 5)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 6)\t\t\t\t\t\t\\\n\tDEFINE_LEVEL(stem, 7)\n\nstatic struct btrfs_lockdep_keyset {\n\tu64\t\t\tid;\t\t \n\t \n\tchar\t\t\tnames[BTRFS_MAX_LEVEL][24];\n\tstruct lock_class_key\tkeys[BTRFS_MAX_LEVEL];\n} btrfs_lockdep_keysets[] = {\n\t{ .id = BTRFS_ROOT_TREE_OBJECTID,\tDEFINE_NAME(\"root\")\t},\n\t{ .id = BTRFS_EXTENT_TREE_OBJECTID,\tDEFINE_NAME(\"extent\")\t},\n\t{ .id = BTRFS_CHUNK_TREE_OBJECTID,\tDEFINE_NAME(\"chunk\")\t},\n\t{ .id = BTRFS_DEV_TREE_OBJECTID,\tDEFINE_NAME(\"dev\")\t},\n\t{ .id = BTRFS_CSUM_TREE_OBJECTID,\tDEFINE_NAME(\"csum\")\t},\n\t{ .id = BTRFS_QUOTA_TREE_OBJECTID,\tDEFINE_NAME(\"quota\")\t},\n\t{ .id = BTRFS_TREE_LOG_OBJECTID,\tDEFINE_NAME(\"log\")\t},\n\t{ .id = BTRFS_TREE_RELOC_OBJECTID,\tDEFINE_NAME(\"treloc\")\t},\n\t{ .id = BTRFS_DATA_RELOC_TREE_OBJECTID,\tDEFINE_NAME(\"dreloc\")\t},\n\t{ .id = BTRFS_UUID_TREE_OBJECTID,\tDEFINE_NAME(\"uuid\")\t},\n\t{ .id = BTRFS_FREE_SPACE_TREE_OBJECTID,\tDEFINE_NAME(\"free-space\") },\n\t{ .id = BTRFS_BLOCK_GROUP_TREE_OBJECTID, DEFINE_NAME(\"block-group\") },\n\t{ .id = 0,\t\t\t\tDEFINE_NAME(\"tree\")\t},\n};\n\n#undef DEFINE_LEVEL\n#undef DEFINE_NAME\n\nvoid btrfs_set_buffer_lockdep_class(u64 objectid, struct extent_buffer *eb, int level)\n{\n\tstruct btrfs_lockdep_keyset *ks;\n\n\tBUG_ON(level >= ARRAY_SIZE(ks->keys));\n\n\t \n\tfor (ks = btrfs_lockdep_keysets; ks->id; ks++)\n\t\tif (ks->id == objectid)\n\t\t\tbreak;\n\n\tlockdep_set_class_and_name(&eb->lock, &ks->keys[level], ks->names[level]);\n}\n\nvoid btrfs_maybe_reset_lockdep_class(struct btrfs_root *root, struct extent_buffer *eb)\n{\n\tif (test_bit(BTRFS_ROOT_RESET_LOCKDEP_CLASS, &root->state))\n\t\tbtrfs_set_buffer_lockdep_class(root->root_key.objectid,\n\t\t\t\t\t       eb, btrfs_header_level(eb));\n}\n\n#endif\n\n \n\n \nvoid __btrfs_tree_read_lock(struct extent_buffer *eb, enum btrfs_lock_nesting nest)\n{\n\tu64 start_ns = 0;\n\n\tif (trace_btrfs_tree_read_lock_enabled())\n\t\tstart_ns = ktime_get_ns();\n\n\tdown_read_nested(&eb->lock, nest);\n\ttrace_btrfs_tree_read_lock(eb, start_ns);\n}\n\nvoid btrfs_tree_read_lock(struct extent_buffer *eb)\n{\n\t__btrfs_tree_read_lock(eb, BTRFS_NESTING_NORMAL);\n}\n\n \nint btrfs_try_tree_read_lock(struct extent_buffer *eb)\n{\n\tif (down_read_trylock(&eb->lock)) {\n\t\ttrace_btrfs_try_tree_read_lock(eb);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nint btrfs_try_tree_write_lock(struct extent_buffer *eb)\n{\n\tif (down_write_trylock(&eb->lock)) {\n\t\teb->lock_owner = current->pid;\n\t\ttrace_btrfs_try_tree_write_lock(eb);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nvoid btrfs_tree_read_unlock(struct extent_buffer *eb)\n{\n\ttrace_btrfs_tree_read_unlock(eb);\n\tup_read(&eb->lock);\n}\n\n \nvoid __btrfs_tree_lock(struct extent_buffer *eb, enum btrfs_lock_nesting nest)\n\t__acquires(&eb->lock)\n{\n\tu64 start_ns = 0;\n\n\tif (trace_btrfs_tree_lock_enabled())\n\t\tstart_ns = ktime_get_ns();\n\n\tdown_write_nested(&eb->lock, nest);\n\teb->lock_owner = current->pid;\n\ttrace_btrfs_tree_lock(eb, start_ns);\n}\n\nvoid btrfs_tree_lock(struct extent_buffer *eb)\n{\n\t__btrfs_tree_lock(eb, BTRFS_NESTING_NORMAL);\n}\n\n \nvoid btrfs_tree_unlock(struct extent_buffer *eb)\n{\n\ttrace_btrfs_tree_unlock(eb);\n\teb->lock_owner = 0;\n\tup_write(&eb->lock);\n}\n\n \nvoid btrfs_unlock_up_safe(struct btrfs_path *path, int level)\n{\n\tint i;\n\n\tif (path->keep_locks)\n\t\treturn;\n\n\tfor (i = level; i < BTRFS_MAX_LEVEL; i++) {\n\t\tif (!path->nodes[i])\n\t\t\tcontinue;\n\t\tif (!path->locks[i])\n\t\t\tcontinue;\n\t\tbtrfs_tree_unlock_rw(path->nodes[i], path->locks[i]);\n\t\tpath->locks[i] = 0;\n\t}\n}\n\n \nstruct extent_buffer *btrfs_lock_root_node(struct btrfs_root *root)\n{\n\tstruct extent_buffer *eb;\n\n\twhile (1) {\n\t\teb = btrfs_root_node(root);\n\n\t\tbtrfs_maybe_reset_lockdep_class(root, eb);\n\t\tbtrfs_tree_lock(eb);\n\t\tif (eb == root->node)\n\t\t\tbreak;\n\t\tbtrfs_tree_unlock(eb);\n\t\tfree_extent_buffer(eb);\n\t}\n\treturn eb;\n}\n\n \nstruct extent_buffer *btrfs_read_lock_root_node(struct btrfs_root *root)\n{\n\tstruct extent_buffer *eb;\n\n\twhile (1) {\n\t\teb = btrfs_root_node(root);\n\n\t\tbtrfs_maybe_reset_lockdep_class(root, eb);\n\t\tbtrfs_tree_read_lock(eb);\n\t\tif (eb == root->node)\n\t\t\tbreak;\n\t\tbtrfs_tree_read_unlock(eb);\n\t\tfree_extent_buffer(eb);\n\t}\n\treturn eb;\n}\n\n \nstruct extent_buffer *btrfs_try_read_lock_root_node(struct btrfs_root *root)\n{\n\tstruct extent_buffer *eb;\n\n\twhile (1) {\n\t\teb = btrfs_root_node(root);\n\t\tif (!btrfs_try_tree_read_lock(eb)) {\n\t\t\tfree_extent_buffer(eb);\n\t\t\treturn ERR_PTR(-EAGAIN);\n\t\t}\n\t\tif (eb == root->node)\n\t\t\tbreak;\n\t\tbtrfs_tree_read_unlock(eb);\n\t\tfree_extent_buffer(eb);\n\t}\n\treturn eb;\n}\n\n \n\nvoid btrfs_drew_lock_init(struct btrfs_drew_lock *lock)\n{\n\tatomic_set(&lock->readers, 0);\n\tatomic_set(&lock->writers, 0);\n\tinit_waitqueue_head(&lock->pending_readers);\n\tinit_waitqueue_head(&lock->pending_writers);\n}\n\n \nbool btrfs_drew_try_write_lock(struct btrfs_drew_lock *lock)\n{\n\tif (atomic_read(&lock->readers))\n\t\treturn false;\n\n\tatomic_inc(&lock->writers);\n\n\t \n\tsmp_mb__after_atomic();\n\tif (atomic_read(&lock->readers)) {\n\t\tbtrfs_drew_write_unlock(lock);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nvoid btrfs_drew_write_lock(struct btrfs_drew_lock *lock)\n{\n\twhile (true) {\n\t\tif (btrfs_drew_try_write_lock(lock))\n\t\t\treturn;\n\t\twait_event(lock->pending_writers, !atomic_read(&lock->readers));\n\t}\n}\n\nvoid btrfs_drew_write_unlock(struct btrfs_drew_lock *lock)\n{\n\tatomic_dec(&lock->writers);\n\tcond_wake_up(&lock->pending_readers);\n}\n\nvoid btrfs_drew_read_lock(struct btrfs_drew_lock *lock)\n{\n\tatomic_inc(&lock->readers);\n\n\t \n\tsmp_mb__after_atomic();\n\n\twait_event(lock->pending_readers, atomic_read(&lock->writers) == 0);\n}\n\nvoid btrfs_drew_read_unlock(struct btrfs_drew_lock *lock)\n{\n\t \n\tif (atomic_dec_and_test(&lock->readers))\n\t\twake_up(&lock->pending_writers);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}