{
  "module_name": "qgroup.c",
  "hash_id": "d9111b513c1babeb02f50f181eff3f50232a0eb4dff604c0072b01ea7a05e636",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/qgroup.c",
  "human_readable_source": "\n \n\n#include <linux/sched.h>\n#include <linux/pagemap.h>\n#include <linux/writeback.h>\n#include <linux/blkdev.h>\n#include <linux/rbtree.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/btrfs.h>\n#include <linux/sched/mm.h>\n\n#include \"ctree.h\"\n#include \"transaction.h\"\n#include \"disk-io.h\"\n#include \"locking.h\"\n#include \"ulist.h\"\n#include \"backref.h\"\n#include \"extent_io.h\"\n#include \"qgroup.h\"\n#include \"block-group.h\"\n#include \"sysfs.h\"\n#include \"tree-mod-log.h\"\n#include \"fs.h\"\n#include \"accessors.h\"\n#include \"extent-tree.h\"\n#include \"root-tree.h\"\n#include \"tree-checker.h\"\n\n \n\nstatic u64 qgroup_rsv_total(const struct btrfs_qgroup *qgroup)\n{\n\tu64 ret = 0;\n\tint i;\n\n\tfor (i = 0; i < BTRFS_QGROUP_RSV_LAST; i++)\n\t\tret += qgroup->rsv.values[i];\n\n\treturn ret;\n}\n\n#ifdef CONFIG_BTRFS_DEBUG\nstatic const char *qgroup_rsv_type_str(enum btrfs_qgroup_rsv_type type)\n{\n\tif (type == BTRFS_QGROUP_RSV_DATA)\n\t\treturn \"data\";\n\tif (type == BTRFS_QGROUP_RSV_META_PERTRANS)\n\t\treturn \"meta_pertrans\";\n\tif (type == BTRFS_QGROUP_RSV_META_PREALLOC)\n\t\treturn \"meta_prealloc\";\n\treturn NULL;\n}\n#endif\n\nstatic void qgroup_rsv_add(struct btrfs_fs_info *fs_info,\n\t\t\t   struct btrfs_qgroup *qgroup, u64 num_bytes,\n\t\t\t   enum btrfs_qgroup_rsv_type type)\n{\n\ttrace_qgroup_update_reserve(fs_info, qgroup, num_bytes, type);\n\tqgroup->rsv.values[type] += num_bytes;\n}\n\nstatic void qgroup_rsv_release(struct btrfs_fs_info *fs_info,\n\t\t\t       struct btrfs_qgroup *qgroup, u64 num_bytes,\n\t\t\t       enum btrfs_qgroup_rsv_type type)\n{\n\ttrace_qgroup_update_reserve(fs_info, qgroup, -(s64)num_bytes, type);\n\tif (qgroup->rsv.values[type] >= num_bytes) {\n\t\tqgroup->rsv.values[type] -= num_bytes;\n\t\treturn;\n\t}\n#ifdef CONFIG_BTRFS_DEBUG\n\tWARN_RATELIMIT(1,\n\t\t\"qgroup %llu %s reserved space underflow, have %llu to free %llu\",\n\t\tqgroup->qgroupid, qgroup_rsv_type_str(type),\n\t\tqgroup->rsv.values[type], num_bytes);\n#endif\n\tqgroup->rsv.values[type] = 0;\n}\n\nstatic void qgroup_rsv_add_by_qgroup(struct btrfs_fs_info *fs_info,\n\t\t\t\t     struct btrfs_qgroup *dest,\n\t\t\t\t     struct btrfs_qgroup *src)\n{\n\tint i;\n\n\tfor (i = 0; i < BTRFS_QGROUP_RSV_LAST; i++)\n\t\tqgroup_rsv_add(fs_info, dest, src->rsv.values[i], i);\n}\n\nstatic void qgroup_rsv_release_by_qgroup(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t struct btrfs_qgroup *dest,\n\t\t\t\t\t  struct btrfs_qgroup *src)\n{\n\tint i;\n\n\tfor (i = 0; i < BTRFS_QGROUP_RSV_LAST; i++)\n\t\tqgroup_rsv_release(fs_info, dest, src->rsv.values[i], i);\n}\n\nstatic void btrfs_qgroup_update_old_refcnt(struct btrfs_qgroup *qg, u64 seq,\n\t\t\t\t\t   int mod)\n{\n\tif (qg->old_refcnt < seq)\n\t\tqg->old_refcnt = seq;\n\tqg->old_refcnt += mod;\n}\n\nstatic void btrfs_qgroup_update_new_refcnt(struct btrfs_qgroup *qg, u64 seq,\n\t\t\t\t\t   int mod)\n{\n\tif (qg->new_refcnt < seq)\n\t\tqg->new_refcnt = seq;\n\tqg->new_refcnt += mod;\n}\n\nstatic inline u64 btrfs_qgroup_get_old_refcnt(struct btrfs_qgroup *qg, u64 seq)\n{\n\tif (qg->old_refcnt < seq)\n\t\treturn 0;\n\treturn qg->old_refcnt - seq;\n}\n\nstatic inline u64 btrfs_qgroup_get_new_refcnt(struct btrfs_qgroup *qg, u64 seq)\n{\n\tif (qg->new_refcnt < seq)\n\t\treturn 0;\n\treturn qg->new_refcnt - seq;\n}\n\n \nstruct btrfs_qgroup_list {\n\tstruct list_head next_group;\n\tstruct list_head next_member;\n\tstruct btrfs_qgroup *group;\n\tstruct btrfs_qgroup *member;\n};\n\nstatic inline u64 qgroup_to_aux(struct btrfs_qgroup *qg)\n{\n\treturn (u64)(uintptr_t)qg;\n}\n\nstatic inline struct btrfs_qgroup* unode_aux_to_qgroup(struct ulist_node *n)\n{\n\treturn (struct btrfs_qgroup *)(uintptr_t)n->aux;\n}\n\nstatic int\nqgroup_rescan_init(struct btrfs_fs_info *fs_info, u64 progress_objectid,\n\t\t   int init_flags);\nstatic void qgroup_rescan_zero_tracking(struct btrfs_fs_info *fs_info);\n\n \nstatic struct btrfs_qgroup *find_qgroup_rb(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t   u64 qgroupid)\n{\n\tstruct rb_node *n = fs_info->qgroup_tree.rb_node;\n\tstruct btrfs_qgroup *qgroup;\n\n\twhile (n) {\n\t\tqgroup = rb_entry(n, struct btrfs_qgroup, node);\n\t\tif (qgroup->qgroupid < qgroupid)\n\t\t\tn = n->rb_left;\n\t\telse if (qgroup->qgroupid > qgroupid)\n\t\t\tn = n->rb_right;\n\t\telse\n\t\t\treturn qgroup;\n\t}\n\treturn NULL;\n}\n\n \nstatic struct btrfs_qgroup *add_qgroup_rb(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t  u64 qgroupid)\n{\n\tstruct rb_node **p = &fs_info->qgroup_tree.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct btrfs_qgroup *qgroup;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tqgroup = rb_entry(parent, struct btrfs_qgroup, node);\n\n\t\tif (qgroup->qgroupid < qgroupid)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (qgroup->qgroupid > qgroupid)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\treturn qgroup;\n\t}\n\n\tqgroup = kzalloc(sizeof(*qgroup), GFP_ATOMIC);\n\tif (!qgroup)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tqgroup->qgroupid = qgroupid;\n\tINIT_LIST_HEAD(&qgroup->groups);\n\tINIT_LIST_HEAD(&qgroup->members);\n\tINIT_LIST_HEAD(&qgroup->dirty);\n\tINIT_LIST_HEAD(&qgroup->iterator);\n\n\trb_link_node(&qgroup->node, parent, p);\n\trb_insert_color(&qgroup->node, &fs_info->qgroup_tree);\n\n\treturn qgroup;\n}\n\nstatic void __del_qgroup_rb(struct btrfs_fs_info *fs_info,\n\t\t\t    struct btrfs_qgroup *qgroup)\n{\n\tstruct btrfs_qgroup_list *list;\n\n\tlist_del(&qgroup->dirty);\n\twhile (!list_empty(&qgroup->groups)) {\n\t\tlist = list_first_entry(&qgroup->groups,\n\t\t\t\t\tstruct btrfs_qgroup_list, next_group);\n\t\tlist_del(&list->next_group);\n\t\tlist_del(&list->next_member);\n\t\tkfree(list);\n\t}\n\n\twhile (!list_empty(&qgroup->members)) {\n\t\tlist = list_first_entry(&qgroup->members,\n\t\t\t\t\tstruct btrfs_qgroup_list, next_member);\n\t\tlist_del(&list->next_group);\n\t\tlist_del(&list->next_member);\n\t\tkfree(list);\n\t}\n}\n\n \nstatic int del_qgroup_rb(struct btrfs_fs_info *fs_info, u64 qgroupid)\n{\n\tstruct btrfs_qgroup *qgroup = find_qgroup_rb(fs_info, qgroupid);\n\n\tif (!qgroup)\n\t\treturn -ENOENT;\n\n\trb_erase(&qgroup->node, &fs_info->qgroup_tree);\n\t__del_qgroup_rb(fs_info, qgroup);\n\treturn 0;\n}\n\n \nstatic int __add_relation_rb(struct btrfs_qgroup *member, struct btrfs_qgroup *parent)\n{\n\tstruct btrfs_qgroup_list *list;\n\n\tif (!member || !parent)\n\t\treturn -ENOENT;\n\n\tlist = kzalloc(sizeof(*list), GFP_ATOMIC);\n\tif (!list)\n\t\treturn -ENOMEM;\n\n\tlist->group = parent;\n\tlist->member = member;\n\tlist_add_tail(&list->next_group, &member->groups);\n\tlist_add_tail(&list->next_member, &parent->members);\n\n\treturn 0;\n}\n\n \nstatic int add_relation_rb(struct btrfs_fs_info *fs_info, u64 memberid, u64 parentid)\n{\n\tstruct btrfs_qgroup *member;\n\tstruct btrfs_qgroup *parent;\n\n\tmember = find_qgroup_rb(fs_info, memberid);\n\tparent = find_qgroup_rb(fs_info, parentid);\n\n\treturn __add_relation_rb(member, parent);\n}\n\n \nstatic int del_relation_rb(struct btrfs_fs_info *fs_info,\n\t\t\t   u64 memberid, u64 parentid)\n{\n\tstruct btrfs_qgroup *member;\n\tstruct btrfs_qgroup *parent;\n\tstruct btrfs_qgroup_list *list;\n\n\tmember = find_qgroup_rb(fs_info, memberid);\n\tparent = find_qgroup_rb(fs_info, parentid);\n\tif (!member || !parent)\n\t\treturn -ENOENT;\n\n\tlist_for_each_entry(list, &member->groups, next_group) {\n\t\tif (list->group == parent) {\n\t\t\tlist_del(&list->next_group);\n\t\t\tlist_del(&list->next_member);\n\t\t\tkfree(list);\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -ENOENT;\n}\n\n#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\nint btrfs_verify_qgroup_counts(struct btrfs_fs_info *fs_info, u64 qgroupid,\n\t\t\t       u64 rfer, u64 excl)\n{\n\tstruct btrfs_qgroup *qgroup;\n\n\tqgroup = find_qgroup_rb(fs_info, qgroupid);\n\tif (!qgroup)\n\t\treturn -EINVAL;\n\tif (qgroup->rfer != rfer || qgroup->excl != excl)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n#endif\n\nstatic void qgroup_mark_inconsistent(struct btrfs_fs_info *fs_info)\n{\n\tfs_info->qgroup_flags |= (BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT |\n\t\t\t\t  BTRFS_QGROUP_RUNTIME_FLAG_CANCEL_RESCAN |\n\t\t\t\t  BTRFS_QGROUP_RUNTIME_FLAG_NO_ACCOUNTING);\n}\n\n \nint btrfs_read_qgroup_config(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_key key;\n\tstruct btrfs_key found_key;\n\tstruct btrfs_root *quota_root = fs_info->quota_root;\n\tstruct btrfs_path *path = NULL;\n\tstruct extent_buffer *l;\n\tint slot;\n\tint ret = 0;\n\tu64 flags = 0;\n\tu64 rescan_progress = 0;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\treturn 0;\n\n\tfs_info->qgroup_ulist = ulist_alloc(GFP_KERNEL);\n\tif (!fs_info->qgroup_ulist) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = btrfs_sysfs_add_qgroups(fs_info);\n\tif (ret < 0)\n\t\tgoto out;\n\t \n\tfs_info->qgroup_flags = 0;\n\n\t \n\tkey.objectid = 0;\n\tkey.type = 0;\n\tkey.offset = 0;\n\tret = btrfs_search_slot_for_read(quota_root, &key, path, 1, 1);\n\tif (ret)\n\t\tgoto out;\n\n\twhile (1) {\n\t\tstruct btrfs_qgroup *qgroup;\n\n\t\tslot = path->slots[0];\n\t\tl = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(l, &found_key, slot);\n\n\t\tif (found_key.type == BTRFS_QGROUP_STATUS_KEY) {\n\t\t\tstruct btrfs_qgroup_status_item *ptr;\n\n\t\t\tptr = btrfs_item_ptr(l, slot,\n\t\t\t\t\t     struct btrfs_qgroup_status_item);\n\n\t\t\tif (btrfs_qgroup_status_version(l, ptr) !=\n\t\t\t    BTRFS_QGROUP_STATUS_VERSION) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\t \"old qgroup version, quota disabled\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (btrfs_qgroup_status_generation(l, ptr) !=\n\t\t\t    fs_info->generation) {\n\t\t\t\tqgroup_mark_inconsistent(fs_info);\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\t\t\"qgroup generation mismatch, marked as inconsistent\");\n\t\t\t}\n\t\t\tfs_info->qgroup_flags = btrfs_qgroup_status_flags(l,\n\t\t\t\t\t\t\t\t\t  ptr);\n\t\t\trescan_progress = btrfs_qgroup_status_rescan(l, ptr);\n\t\t\tgoto next1;\n\t\t}\n\n\t\tif (found_key.type != BTRFS_QGROUP_INFO_KEY &&\n\t\t    found_key.type != BTRFS_QGROUP_LIMIT_KEY)\n\t\t\tgoto next1;\n\n\t\tqgroup = find_qgroup_rb(fs_info, found_key.offset);\n\t\tif ((qgroup && found_key.type == BTRFS_QGROUP_INFO_KEY) ||\n\t\t    (!qgroup && found_key.type == BTRFS_QGROUP_LIMIT_KEY)) {\n\t\t\tbtrfs_err(fs_info, \"inconsistent qgroup config\");\n\t\t\tqgroup_mark_inconsistent(fs_info);\n\t\t}\n\t\tif (!qgroup) {\n\t\t\tqgroup = add_qgroup_rb(fs_info, found_key.offset);\n\t\t\tif (IS_ERR(qgroup)) {\n\t\t\t\tret = PTR_ERR(qgroup);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tret = btrfs_sysfs_add_one_qgroup(fs_info, qgroup);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tswitch (found_key.type) {\n\t\tcase BTRFS_QGROUP_INFO_KEY: {\n\t\t\tstruct btrfs_qgroup_info_item *ptr;\n\n\t\t\tptr = btrfs_item_ptr(l, slot,\n\t\t\t\t\t     struct btrfs_qgroup_info_item);\n\t\t\tqgroup->rfer = btrfs_qgroup_info_rfer(l, ptr);\n\t\t\tqgroup->rfer_cmpr = btrfs_qgroup_info_rfer_cmpr(l, ptr);\n\t\t\tqgroup->excl = btrfs_qgroup_info_excl(l, ptr);\n\t\t\tqgroup->excl_cmpr = btrfs_qgroup_info_excl_cmpr(l, ptr);\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\t\tcase BTRFS_QGROUP_LIMIT_KEY: {\n\t\t\tstruct btrfs_qgroup_limit_item *ptr;\n\n\t\t\tptr = btrfs_item_ptr(l, slot,\n\t\t\t\t\t     struct btrfs_qgroup_limit_item);\n\t\t\tqgroup->lim_flags = btrfs_qgroup_limit_flags(l, ptr);\n\t\t\tqgroup->max_rfer = btrfs_qgroup_limit_max_rfer(l, ptr);\n\t\t\tqgroup->max_excl = btrfs_qgroup_limit_max_excl(l, ptr);\n\t\t\tqgroup->rsv_rfer = btrfs_qgroup_limit_rsv_rfer(l, ptr);\n\t\t\tqgroup->rsv_excl = btrfs_qgroup_limit_rsv_excl(l, ptr);\n\t\t\tbreak;\n\t\t}\n\t\t}\nnext1:\n\t\tret = btrfs_next_item(quota_root, path);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\tbtrfs_release_path(path);\n\n\t \n\tkey.objectid = 0;\n\tkey.type = BTRFS_QGROUP_RELATION_KEY;\n\tkey.offset = 0;\n\tret = btrfs_search_slot_for_read(quota_root, &key, path, 1, 0);\n\tif (ret)\n\t\tgoto out;\n\twhile (1) {\n\t\tslot = path->slots[0];\n\t\tl = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(l, &found_key, slot);\n\n\t\tif (found_key.type != BTRFS_QGROUP_RELATION_KEY)\n\t\t\tgoto next2;\n\n\t\tif (found_key.objectid > found_key.offset) {\n\t\t\t \n\t\t\t \n\t\t\tgoto next2;\n\t\t}\n\n\t\tret = add_relation_rb(fs_info, found_key.objectid,\n\t\t\t\t      found_key.offset);\n\t\tif (ret == -ENOENT) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t\"orphan qgroup relation 0x%llx->0x%llx\",\n\t\t\t\tfound_key.objectid, found_key.offset);\n\t\t\tret = 0;\t \n\t\t}\n\t\tif (ret)\n\t\t\tgoto out;\nnext2:\n\t\tret = btrfs_next_item(quota_root, path);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tif (ret)\n\t\t\tbreak;\n\t}\nout:\n\tbtrfs_free_path(path);\n\tfs_info->qgroup_flags |= flags;\n\tif (!(fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_ON))\n\t\tclear_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);\n\telse if (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN &&\n\t\t ret >= 0)\n\t\tret = qgroup_rescan_init(fs_info, rescan_progress, 0);\n\n\tif (ret < 0) {\n\t\tulist_free(fs_info->qgroup_ulist);\n\t\tfs_info->qgroup_ulist = NULL;\n\t\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\n\t\tbtrfs_sysfs_del_qgroups(fs_info);\n\t}\n\n\treturn ret < 0 ? ret : 0;\n}\n\n \nbool btrfs_check_quota_leak(struct btrfs_fs_info *fs_info)\n{\n\tstruct rb_node *node;\n\tbool ret = false;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\treturn ret;\n\t \n\tfor (node = rb_first(&fs_info->qgroup_tree); node; node = rb_next(node)) {\n\t\tstruct btrfs_qgroup *qgroup;\n\t\tint i;\n\n\t\tqgroup = rb_entry(node, struct btrfs_qgroup, node);\n\t\tfor (i = 0; i < BTRFS_QGROUP_RSV_LAST; i++) {\n\t\t\tif (qgroup->rsv.values[i]) {\n\t\t\t\tret = true;\n\t\t\t\tbtrfs_warn(fs_info,\n\t\t\"qgroup %hu/%llu has unreleased space, type %d rsv %llu\",\n\t\t\t\t   btrfs_qgroup_level(qgroup->qgroupid),\n\t\t\t\t   btrfs_qgroup_subvolid(qgroup->qgroupid),\n\t\t\t\t   i, qgroup->rsv.values[i]);\n\t\t\t}\n\t\t}\n\t}\n\treturn ret;\n}\n\n \nvoid btrfs_free_qgroup_config(struct btrfs_fs_info *fs_info)\n{\n\tstruct rb_node *n;\n\tstruct btrfs_qgroup *qgroup;\n\n\twhile ((n = rb_first(&fs_info->qgroup_tree))) {\n\t\tqgroup = rb_entry(n, struct btrfs_qgroup, node);\n\t\trb_erase(n, &fs_info->qgroup_tree);\n\t\t__del_qgroup_rb(fs_info, qgroup);\n\t\tbtrfs_sysfs_del_one_qgroup(fs_info, qgroup);\n\t\tkfree(qgroup);\n\t}\n\t \n\tulist_free(fs_info->qgroup_ulist);\n\tfs_info->qgroup_ulist = NULL;\n\tbtrfs_sysfs_del_qgroups(fs_info);\n}\n\nstatic int add_qgroup_relation_item(struct btrfs_trans_handle *trans, u64 src,\n\t\t\t\t    u64 dst)\n{\n\tint ret;\n\tstruct btrfs_root *quota_root = trans->fs_info->quota_root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tkey.objectid = src;\n\tkey.type = BTRFS_QGROUP_RELATION_KEY;\n\tkey.offset = dst;\n\n\tret = btrfs_insert_empty_item(trans, quota_root, path, &key, 0);\n\n\tbtrfs_mark_buffer_dirty(trans, path->nodes[0]);\n\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int del_qgroup_relation_item(struct btrfs_trans_handle *trans, u64 src,\n\t\t\t\t    u64 dst)\n{\n\tint ret;\n\tstruct btrfs_root *quota_root = trans->fs_info->quota_root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tkey.objectid = src;\n\tkey.type = BTRFS_QGROUP_RELATION_KEY;\n\tkey.offset = dst;\n\n\tret = btrfs_search_slot(trans, quota_root, &key, path, -1, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (ret > 0) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = btrfs_del_item(trans, quota_root, path);\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int add_qgroup_item(struct btrfs_trans_handle *trans,\n\t\t\t   struct btrfs_root *quota_root, u64 qgroupid)\n{\n\tint ret;\n\tstruct btrfs_path *path;\n\tstruct btrfs_qgroup_info_item *qgroup_info;\n\tstruct btrfs_qgroup_limit_item *qgroup_limit;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key key;\n\n\tif (btrfs_is_testing(quota_root->fs_info))\n\t\treturn 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tkey.objectid = 0;\n\tkey.type = BTRFS_QGROUP_INFO_KEY;\n\tkey.offset = qgroupid;\n\n\t \n\n\tret = btrfs_insert_empty_item(trans, quota_root, path, &key,\n\t\t\t\t      sizeof(*qgroup_info));\n\tif (ret && ret != -EEXIST)\n\t\tgoto out;\n\n\tleaf = path->nodes[0];\n\tqgroup_info = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t struct btrfs_qgroup_info_item);\n\tbtrfs_set_qgroup_info_generation(leaf, qgroup_info, trans->transid);\n\tbtrfs_set_qgroup_info_rfer(leaf, qgroup_info, 0);\n\tbtrfs_set_qgroup_info_rfer_cmpr(leaf, qgroup_info, 0);\n\tbtrfs_set_qgroup_info_excl(leaf, qgroup_info, 0);\n\tbtrfs_set_qgroup_info_excl_cmpr(leaf, qgroup_info, 0);\n\n\tbtrfs_mark_buffer_dirty(trans, leaf);\n\n\tbtrfs_release_path(path);\n\n\tkey.type = BTRFS_QGROUP_LIMIT_KEY;\n\tret = btrfs_insert_empty_item(trans, quota_root, path, &key,\n\t\t\t\t      sizeof(*qgroup_limit));\n\tif (ret && ret != -EEXIST)\n\t\tgoto out;\n\n\tleaf = path->nodes[0];\n\tqgroup_limit = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t  struct btrfs_qgroup_limit_item);\n\tbtrfs_set_qgroup_limit_flags(leaf, qgroup_limit, 0);\n\tbtrfs_set_qgroup_limit_max_rfer(leaf, qgroup_limit, 0);\n\tbtrfs_set_qgroup_limit_max_excl(leaf, qgroup_limit, 0);\n\tbtrfs_set_qgroup_limit_rsv_rfer(leaf, qgroup_limit, 0);\n\tbtrfs_set_qgroup_limit_rsv_excl(leaf, qgroup_limit, 0);\n\n\tbtrfs_mark_buffer_dirty(trans, leaf);\n\n\tret = 0;\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int del_qgroup_item(struct btrfs_trans_handle *trans, u64 qgroupid)\n{\n\tint ret;\n\tstruct btrfs_root *quota_root = trans->fs_info->quota_root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tkey.objectid = 0;\n\tkey.type = BTRFS_QGROUP_INFO_KEY;\n\tkey.offset = qgroupid;\n\tret = btrfs_search_slot(trans, quota_root, &key, path, -1, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (ret > 0) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = btrfs_del_item(trans, quota_root, path);\n\tif (ret)\n\t\tgoto out;\n\n\tbtrfs_release_path(path);\n\n\tkey.type = BTRFS_QGROUP_LIMIT_KEY;\n\tret = btrfs_search_slot(trans, quota_root, &key, path, -1, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (ret > 0) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = btrfs_del_item(trans, quota_root, path);\n\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int update_qgroup_limit_item(struct btrfs_trans_handle *trans,\n\t\t\t\t    struct btrfs_qgroup *qgroup)\n{\n\tstruct btrfs_root *quota_root = trans->fs_info->quota_root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\tstruct extent_buffer *l;\n\tstruct btrfs_qgroup_limit_item *qgroup_limit;\n\tint ret;\n\tint slot;\n\n\tkey.objectid = 0;\n\tkey.type = BTRFS_QGROUP_LIMIT_KEY;\n\tkey.offset = qgroup->qgroupid;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tret = btrfs_search_slot(trans, quota_root, &key, path, 0, 1);\n\tif (ret > 0)\n\t\tret = -ENOENT;\n\n\tif (ret)\n\t\tgoto out;\n\n\tl = path->nodes[0];\n\tslot = path->slots[0];\n\tqgroup_limit = btrfs_item_ptr(l, slot, struct btrfs_qgroup_limit_item);\n\tbtrfs_set_qgroup_limit_flags(l, qgroup_limit, qgroup->lim_flags);\n\tbtrfs_set_qgroup_limit_max_rfer(l, qgroup_limit, qgroup->max_rfer);\n\tbtrfs_set_qgroup_limit_max_excl(l, qgroup_limit, qgroup->max_excl);\n\tbtrfs_set_qgroup_limit_rsv_rfer(l, qgroup_limit, qgroup->rsv_rfer);\n\tbtrfs_set_qgroup_limit_rsv_excl(l, qgroup_limit, qgroup->rsv_excl);\n\n\tbtrfs_mark_buffer_dirty(trans, l);\n\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int update_qgroup_info_item(struct btrfs_trans_handle *trans,\n\t\t\t\t   struct btrfs_qgroup *qgroup)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_root *quota_root = fs_info->quota_root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\tstruct extent_buffer *l;\n\tstruct btrfs_qgroup_info_item *qgroup_info;\n\tint ret;\n\tint slot;\n\n\tif (btrfs_is_testing(fs_info))\n\t\treturn 0;\n\n\tkey.objectid = 0;\n\tkey.type = BTRFS_QGROUP_INFO_KEY;\n\tkey.offset = qgroup->qgroupid;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tret = btrfs_search_slot(trans, quota_root, &key, path, 0, 1);\n\tif (ret > 0)\n\t\tret = -ENOENT;\n\n\tif (ret)\n\t\tgoto out;\n\n\tl = path->nodes[0];\n\tslot = path->slots[0];\n\tqgroup_info = btrfs_item_ptr(l, slot, struct btrfs_qgroup_info_item);\n\tbtrfs_set_qgroup_info_generation(l, qgroup_info, trans->transid);\n\tbtrfs_set_qgroup_info_rfer(l, qgroup_info, qgroup->rfer);\n\tbtrfs_set_qgroup_info_rfer_cmpr(l, qgroup_info, qgroup->rfer_cmpr);\n\tbtrfs_set_qgroup_info_excl(l, qgroup_info, qgroup->excl);\n\tbtrfs_set_qgroup_info_excl_cmpr(l, qgroup_info, qgroup->excl_cmpr);\n\n\tbtrfs_mark_buffer_dirty(trans, l);\n\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int update_qgroup_status_item(struct btrfs_trans_handle *trans)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_root *quota_root = fs_info->quota_root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\tstruct extent_buffer *l;\n\tstruct btrfs_qgroup_status_item *ptr;\n\tint ret;\n\tint slot;\n\n\tkey.objectid = 0;\n\tkey.type = BTRFS_QGROUP_STATUS_KEY;\n\tkey.offset = 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tret = btrfs_search_slot(trans, quota_root, &key, path, 0, 1);\n\tif (ret > 0)\n\t\tret = -ENOENT;\n\n\tif (ret)\n\t\tgoto out;\n\n\tl = path->nodes[0];\n\tslot = path->slots[0];\n\tptr = btrfs_item_ptr(l, slot, struct btrfs_qgroup_status_item);\n\tbtrfs_set_qgroup_status_flags(l, ptr, fs_info->qgroup_flags &\n\t\t\t\t      BTRFS_QGROUP_STATUS_FLAGS_MASK);\n\tbtrfs_set_qgroup_status_generation(l, ptr, trans->transid);\n\tbtrfs_set_qgroup_status_rescan(l, ptr,\n\t\t\t\tfs_info->qgroup_rescan_progress.objectid);\n\n\tbtrfs_mark_buffer_dirty(trans, l);\n\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\n \nstatic int btrfs_clean_quota_tree(struct btrfs_trans_handle *trans,\n\t\t\t\t  struct btrfs_root *root)\n{\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\tstruct extent_buffer *leaf = NULL;\n\tint ret;\n\tint nr = 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tkey.objectid = 0;\n\tkey.offset = 0;\n\tkey.type = 0;\n\n\twhile (1) {\n\t\tret = btrfs_search_slot(trans, root, &key, path, -1, 1);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tleaf = path->nodes[0];\n\t\tnr = btrfs_header_nritems(leaf);\n\t\tif (!nr)\n\t\t\tbreak;\n\t\t \n\t\tpath->slots[0] = 0;\n\t\tret = btrfs_del_items(trans, root, path, 0, nr);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tbtrfs_release_path(path);\n\t}\n\tret = 0;\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nint btrfs_quota_enable(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *quota_root;\n\tstruct btrfs_root *tree_root = fs_info->tree_root;\n\tstruct btrfs_path *path = NULL;\n\tstruct btrfs_qgroup_status_item *ptr;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key key;\n\tstruct btrfs_key found_key;\n\tstruct btrfs_qgroup *qgroup = NULL;\n\tstruct btrfs_trans_handle *trans = NULL;\n\tstruct ulist *ulist = NULL;\n\tint ret = 0;\n\tint slot;\n\n\t \n\tlockdep_assert_held_write(&fs_info->subvol_sem);\n\n\tif (btrfs_fs_incompat(fs_info, EXTENT_TREE_V2)) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"qgroups are currently unsupported in extent tree v2\");\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (fs_info->quota_root)\n\t\tgoto out;\n\n\tulist = ulist_alloc(GFP_KERNEL);\n\tif (!ulist) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = btrfs_sysfs_add_qgroups(fs_info);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t \n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\n\t \n\ttrans = btrfs_start_transaction(tree_root, 2);\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\ttrans = NULL;\n\t\tgoto out;\n\t}\n\n\tif (fs_info->quota_root)\n\t\tgoto out;\n\n\tfs_info->qgroup_ulist = ulist;\n\tulist = NULL;\n\n\t \n\tquota_root = btrfs_create_tree(trans, BTRFS_QUOTA_TREE_OBJECTID);\n\tif (IS_ERR(quota_root)) {\n\t\tret =  PTR_ERR(quota_root);\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_free_root;\n\t}\n\n\tkey.objectid = 0;\n\tkey.type = BTRFS_QGROUP_STATUS_KEY;\n\tkey.offset = 0;\n\n\tret = btrfs_insert_empty_item(trans, quota_root, path, &key,\n\t\t\t\t      sizeof(*ptr));\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_free_path;\n\t}\n\n\tleaf = path->nodes[0];\n\tptr = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t struct btrfs_qgroup_status_item);\n\tbtrfs_set_qgroup_status_generation(leaf, ptr, trans->transid);\n\tbtrfs_set_qgroup_status_version(leaf, ptr, BTRFS_QGROUP_STATUS_VERSION);\n\tfs_info->qgroup_flags = BTRFS_QGROUP_STATUS_FLAG_ON |\n\t\t\t\tBTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\n\tbtrfs_set_qgroup_status_flags(leaf, ptr, fs_info->qgroup_flags &\n\t\t\t\t      BTRFS_QGROUP_STATUS_FLAGS_MASK);\n\tbtrfs_set_qgroup_status_rescan(leaf, ptr, 0);\n\n\tbtrfs_mark_buffer_dirty(trans, leaf);\n\n\tkey.objectid = 0;\n\tkey.type = BTRFS_ROOT_REF_KEY;\n\tkey.offset = 0;\n\n\tbtrfs_release_path(path);\n\tret = btrfs_search_slot_for_read(tree_root, &key, path, 1, 0);\n\tif (ret > 0)\n\t\tgoto out_add_root;\n\tif (ret < 0) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_free_path;\n\t}\n\n\twhile (1) {\n\t\tslot = path->slots[0];\n\t\tleaf = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\tif (found_key.type == BTRFS_ROOT_REF_KEY) {\n\n\t\t\t \n\t\t\tbtrfs_release_path(path);\n\n\t\t\tret = add_qgroup_item(trans, quota_root,\n\t\t\t\t\t      found_key.offset);\n\t\t\tif (ret) {\n\t\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\t\tgoto out_free_path;\n\t\t\t}\n\n\t\t\tqgroup = add_qgroup_rb(fs_info, found_key.offset);\n\t\t\tif (IS_ERR(qgroup)) {\n\t\t\t\tret = PTR_ERR(qgroup);\n\t\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\t\tgoto out_free_path;\n\t\t\t}\n\t\t\tret = btrfs_sysfs_add_one_qgroup(fs_info, qgroup);\n\t\t\tif (ret < 0) {\n\t\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\t\tgoto out_free_path;\n\t\t\t}\n\t\t\tret = btrfs_search_slot_for_read(tree_root, &found_key,\n\t\t\t\t\t\t\t path, 1, 0);\n\t\t\tif (ret < 0) {\n\t\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\t\tgoto out_free_path;\n\t\t\t}\n\t\t\tif (ret > 0) {\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tret = btrfs_next_item(tree_root, path);\n\t\tif (ret < 0) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tgoto out_free_path;\n\t\t}\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\nout_add_root:\n\tbtrfs_release_path(path);\n\tret = add_qgroup_item(trans, quota_root, BTRFS_FS_TREE_OBJECTID);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_free_path;\n\t}\n\n\tqgroup = add_qgroup_rb(fs_info, BTRFS_FS_TREE_OBJECTID);\n\tif (IS_ERR(qgroup)) {\n\t\tret = PTR_ERR(qgroup);\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_free_path;\n\t}\n\tret = btrfs_sysfs_add_one_qgroup(fs_info, qgroup);\n\tif (ret < 0) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out_free_path;\n\t}\n\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\t \n\tret = btrfs_commit_transaction(trans);\n\ttrans = NULL;\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (ret)\n\t\tgoto out_free_path;\n\n\t \n\tspin_lock(&fs_info->qgroup_lock);\n\tfs_info->quota_root = quota_root;\n\tset_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);\n\tspin_unlock(&fs_info->qgroup_lock);\n\n\tret = qgroup_rescan_init(fs_info, 0, 1);\n\tif (!ret) {\n\t        qgroup_rescan_zero_tracking(fs_info);\n\t\tfs_info->qgroup_rescan_running = true;\n\t        btrfs_queue_work(fs_info->qgroup_rescan_workers,\n\t                         &fs_info->qgroup_rescan_work);\n\t} else {\n\t\t \n\t\tASSERT(ret == -EINPROGRESS);\n\t\tret = 0;\n\t}\n\nout_free_path:\n\tbtrfs_free_path(path);\nout_free_root:\n\tif (ret)\n\t\tbtrfs_put_root(quota_root);\nout:\n\tif (ret) {\n\t\tulist_free(fs_info->qgroup_ulist);\n\t\tfs_info->qgroup_ulist = NULL;\n\t\tbtrfs_sysfs_del_qgroups(fs_info);\n\t}\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\tif (ret && trans)\n\t\tbtrfs_end_transaction(trans);\n\telse if (trans)\n\t\tret = btrfs_end_transaction(trans);\n\tulist_free(ulist);\n\treturn ret;\n}\n\nint btrfs_quota_disable(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *quota_root;\n\tstruct btrfs_trans_handle *trans = NULL;\n\tint ret = 0;\n\n\t \n\tlockdep_assert_held_write(&fs_info->subvol_sem);\n\n\t \n\tmutex_lock(&fs_info->cleaner_mutex);\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (!fs_info->quota_root)\n\t\tgoto out;\n\n\t \n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\n\t \n\tclear_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);\n\tbtrfs_qgroup_wait_for_completion(fs_info, false);\n\n\t \n\ttrans = btrfs_start_transaction(fs_info->tree_root, 1);\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\ttrans = NULL;\n\t\tset_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);\n\t\tgoto out;\n\t}\n\n\tif (!fs_info->quota_root)\n\t\tgoto out;\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tquota_root = fs_info->quota_root;\n\tfs_info->quota_root = NULL;\n\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_ON;\n\tfs_info->qgroup_drop_subtree_thres = BTRFS_MAX_LEVEL;\n\tspin_unlock(&fs_info->qgroup_lock);\n\n\tbtrfs_free_qgroup_config(fs_info);\n\n\tret = btrfs_clean_quota_tree(trans, quota_root);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\tret = btrfs_del_root(trans, &quota_root->root_key);\n\tif (ret) {\n\t\tbtrfs_abort_transaction(trans, ret);\n\t\tgoto out;\n\t}\n\n\tspin_lock(&fs_info->trans_lock);\n\tlist_del(&quota_root->dirty_list);\n\tspin_unlock(&fs_info->trans_lock);\n\n\tbtrfs_tree_lock(quota_root->node);\n\tbtrfs_clear_buffer_dirty(trans, quota_root->node);\n\tbtrfs_tree_unlock(quota_root->node);\n\tbtrfs_free_tree_block(trans, btrfs_root_id(quota_root),\n\t\t\t      quota_root->node, 0, 1);\n\n\tbtrfs_put_root(quota_root);\n\nout:\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\tif (ret && trans)\n\t\tbtrfs_end_transaction(trans);\n\telse if (trans)\n\t\tret = btrfs_end_transaction(trans);\n\tmutex_unlock(&fs_info->cleaner_mutex);\n\n\treturn ret;\n}\n\nstatic void qgroup_dirty(struct btrfs_fs_info *fs_info,\n\t\t\t struct btrfs_qgroup *qgroup)\n{\n\tif (list_empty(&qgroup->dirty))\n\t\tlist_add(&qgroup->dirty, &fs_info->dirty_qgroups);\n}\n\nstatic void qgroup_iterator_add(struct list_head *head, struct btrfs_qgroup *qgroup)\n{\n\tif (!list_empty(&qgroup->iterator))\n\t\treturn;\n\n\tlist_add_tail(&qgroup->iterator, head);\n}\n\nstatic void qgroup_iterator_clean(struct list_head *head)\n{\n\twhile (!list_empty(head)) {\n\t\tstruct btrfs_qgroup *qgroup;\n\n\t\tqgroup = list_first_entry(head, struct btrfs_qgroup, iterator);\n\t\tlist_del_init(&qgroup->iterator);\n\t}\n}\n\n \nstatic int __qgroup_excl_accounting(struct btrfs_fs_info *fs_info,\n\t\t\t\t    struct ulist *tmp, u64 ref_root,\n\t\t\t\t    struct btrfs_qgroup *src, int sign)\n{\n\tstruct btrfs_qgroup *qgroup;\n\tstruct btrfs_qgroup_list *glist;\n\tstruct ulist_node *unode;\n\tstruct ulist_iterator uiter;\n\tu64 num_bytes = src->excl;\n\tint ret = 0;\n\n\tqgroup = find_qgroup_rb(fs_info, ref_root);\n\tif (!qgroup)\n\t\tgoto out;\n\n\tqgroup->rfer += sign * num_bytes;\n\tqgroup->rfer_cmpr += sign * num_bytes;\n\n\tWARN_ON(sign < 0 && qgroup->excl < num_bytes);\n\tqgroup->excl += sign * num_bytes;\n\tqgroup->excl_cmpr += sign * num_bytes;\n\n\tif (sign > 0)\n\t\tqgroup_rsv_add_by_qgroup(fs_info, qgroup, src);\n\telse\n\t\tqgroup_rsv_release_by_qgroup(fs_info, qgroup, src);\n\n\tqgroup_dirty(fs_info, qgroup);\n\n\t \n\tlist_for_each_entry(glist, &qgroup->groups, next_group) {\n\t\tret = ulist_add(tmp, glist->group->qgroupid,\n\t\t\t\tqgroup_to_aux(glist->group), GFP_ATOMIC);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\n\n\t \n\tULIST_ITER_INIT(&uiter);\n\twhile ((unode = ulist_next(tmp, &uiter))) {\n\t\tqgroup = unode_aux_to_qgroup(unode);\n\t\tqgroup->rfer += sign * num_bytes;\n\t\tqgroup->rfer_cmpr += sign * num_bytes;\n\t\tWARN_ON(sign < 0 && qgroup->excl < num_bytes);\n\t\tqgroup->excl += sign * num_bytes;\n\t\tif (sign > 0)\n\t\t\tqgroup_rsv_add_by_qgroup(fs_info, qgroup, src);\n\t\telse\n\t\t\tqgroup_rsv_release_by_qgroup(fs_info, qgroup, src);\n\t\tqgroup->excl_cmpr += sign * num_bytes;\n\t\tqgroup_dirty(fs_info, qgroup);\n\n\t\t \n\t\tlist_for_each_entry(glist, &qgroup->groups, next_group) {\n\t\t\tret = ulist_add(tmp, glist->group->qgroupid,\n\t\t\t\t\tqgroup_to_aux(glist->group), GFP_ATOMIC);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\tret = 0;\nout:\n\treturn ret;\n}\n\n\n \nstatic int quick_update_accounting(struct btrfs_fs_info *fs_info,\n\t\t\t\t   struct ulist *tmp, u64 src, u64 dst,\n\t\t\t\t   int sign)\n{\n\tstruct btrfs_qgroup *qgroup;\n\tint ret = 1;\n\tint err = 0;\n\n\tqgroup = find_qgroup_rb(fs_info, src);\n\tif (!qgroup)\n\t\tgoto out;\n\tif (qgroup->excl == qgroup->rfer) {\n\t\tret = 0;\n\t\terr = __qgroup_excl_accounting(fs_info, tmp, dst,\n\t\t\t\t\t       qgroup, sign);\n\t\tif (err < 0) {\n\t\t\tret = err;\n\t\t\tgoto out;\n\t\t}\n\t}\nout:\n\tif (ret)\n\t\tfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\n\treturn ret;\n}\n\nint btrfs_add_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,\n\t\t\t      u64 dst)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_qgroup *parent;\n\tstruct btrfs_qgroup *member;\n\tstruct btrfs_qgroup_list *list;\n\tstruct ulist *tmp;\n\tunsigned int nofs_flag;\n\tint ret = 0;\n\n\t \n\tif (btrfs_qgroup_level(src) >= btrfs_qgroup_level(dst))\n\t\treturn -EINVAL;\n\n\t \n\tnofs_flag = memalloc_nofs_save();\n\ttmp = ulist_alloc(GFP_KERNEL);\n\tmemalloc_nofs_restore(nofs_flag);\n\tif (!tmp)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (!fs_info->quota_root) {\n\t\tret = -ENOTCONN;\n\t\tgoto out;\n\t}\n\tmember = find_qgroup_rb(fs_info, src);\n\tparent = find_qgroup_rb(fs_info, dst);\n\tif (!member || !parent) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t \n\tlist_for_each_entry(list, &member->groups, next_group) {\n\t\tif (list->group == parent) {\n\t\t\tret = -EEXIST;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = add_qgroup_relation_item(trans, src, dst);\n\tif (ret)\n\t\tgoto out;\n\n\tret = add_qgroup_relation_item(trans, dst, src);\n\tif (ret) {\n\t\tdel_qgroup_relation_item(trans, src, dst);\n\t\tgoto out;\n\t}\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tret = __add_relation_rb(member, parent);\n\tif (ret < 0) {\n\t\tspin_unlock(&fs_info->qgroup_lock);\n\t\tgoto out;\n\t}\n\tret = quick_update_accounting(fs_info, tmp, src, dst, 1);\n\tspin_unlock(&fs_info->qgroup_lock);\nout:\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\tulist_free(tmp);\n\treturn ret;\n}\n\nstatic int __del_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,\n\t\t\t\t u64 dst)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_qgroup *parent;\n\tstruct btrfs_qgroup *member;\n\tstruct btrfs_qgroup_list *list;\n\tstruct ulist *tmp;\n\tbool found = false;\n\tunsigned int nofs_flag;\n\tint ret = 0;\n\tint ret2;\n\n\t \n\tnofs_flag = memalloc_nofs_save();\n\ttmp = ulist_alloc(GFP_KERNEL);\n\tmemalloc_nofs_restore(nofs_flag);\n\tif (!tmp)\n\t\treturn -ENOMEM;\n\n\tif (!fs_info->quota_root) {\n\t\tret = -ENOTCONN;\n\t\tgoto out;\n\t}\n\n\tmember = find_qgroup_rb(fs_info, src);\n\tparent = find_qgroup_rb(fs_info, dst);\n\t \n\tif (!member || !parent)\n\t\tgoto delete_item;\n\n\t \n\tlist_for_each_entry(list, &member->groups, next_group) {\n\t\tif (list->group == parent) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\ndelete_item:\n\tret = del_qgroup_relation_item(trans, src, dst);\n\tif (ret < 0 && ret != -ENOENT)\n\t\tgoto out;\n\tret2 = del_qgroup_relation_item(trans, dst, src);\n\tif (ret2 < 0 && ret2 != -ENOENT)\n\t\tgoto out;\n\n\t \n\tif (!ret || !ret2)\n\t\tret = 0;\n\n\tif (found) {\n\t\tspin_lock(&fs_info->qgroup_lock);\n\t\tdel_relation_rb(fs_info, src, dst);\n\t\tret = quick_update_accounting(fs_info, tmp, src, dst, -1);\n\t\tspin_unlock(&fs_info->qgroup_lock);\n\t}\nout:\n\tulist_free(tmp);\n\treturn ret;\n}\n\nint btrfs_del_qgroup_relation(struct btrfs_trans_handle *trans, u64 src,\n\t\t\t      u64 dst)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tint ret = 0;\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tret = __del_qgroup_relation(trans, src, dst);\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\n\treturn ret;\n}\n\nint btrfs_create_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_root *quota_root;\n\tstruct btrfs_qgroup *qgroup;\n\tint ret = 0;\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (!fs_info->quota_root) {\n\t\tret = -ENOTCONN;\n\t\tgoto out;\n\t}\n\tquota_root = fs_info->quota_root;\n\tqgroup = find_qgroup_rb(fs_info, qgroupid);\n\tif (qgroup) {\n\t\tret = -EEXIST;\n\t\tgoto out;\n\t}\n\n\tret = add_qgroup_item(trans, quota_root, qgroupid);\n\tif (ret)\n\t\tgoto out;\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tqgroup = add_qgroup_rb(fs_info, qgroupid);\n\tspin_unlock(&fs_info->qgroup_lock);\n\n\tif (IS_ERR(qgroup)) {\n\t\tret = PTR_ERR(qgroup);\n\t\tgoto out;\n\t}\n\tret = btrfs_sysfs_add_one_qgroup(fs_info, qgroup);\nout:\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\treturn ret;\n}\n\nint btrfs_remove_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_qgroup *qgroup;\n\tstruct btrfs_qgroup_list *list;\n\tint ret = 0;\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (!fs_info->quota_root) {\n\t\tret = -ENOTCONN;\n\t\tgoto out;\n\t}\n\n\tqgroup = find_qgroup_rb(fs_info, qgroupid);\n\tif (!qgroup) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\t \n\tif (!list_empty(&qgroup->members)) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tret = del_qgroup_item(trans, qgroupid);\n\tif (ret && ret != -ENOENT)\n\t\tgoto out;\n\n\twhile (!list_empty(&qgroup->groups)) {\n\t\tlist = list_first_entry(&qgroup->groups,\n\t\t\t\t\tstruct btrfs_qgroup_list, next_group);\n\t\tret = __del_qgroup_relation(trans, qgroupid,\n\t\t\t\t\t    list->group->qgroupid);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tdel_qgroup_rb(fs_info, qgroupid);\n\tspin_unlock(&fs_info->qgroup_lock);\n\n\t \n\tbtrfs_sysfs_del_one_qgroup(fs_info, qgroup);\n\tkfree(qgroup);\nout:\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\treturn ret;\n}\n\nint btrfs_limit_qgroup(struct btrfs_trans_handle *trans, u64 qgroupid,\n\t\t       struct btrfs_qgroup_limit *limit)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_qgroup *qgroup;\n\tint ret = 0;\n\t \n\tconst u64 CLEAR_VALUE = -1;\n\n\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (!fs_info->quota_root) {\n\t\tret = -ENOTCONN;\n\t\tgoto out;\n\t}\n\n\tqgroup = find_qgroup_rb(fs_info, qgroupid);\n\tif (!qgroup) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tif (limit->flags & BTRFS_QGROUP_LIMIT_MAX_RFER) {\n\t\tif (limit->max_rfer == CLEAR_VALUE) {\n\t\t\tqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_MAX_RFER;\n\t\t\tlimit->flags &= ~BTRFS_QGROUP_LIMIT_MAX_RFER;\n\t\t\tqgroup->max_rfer = 0;\n\t\t} else {\n\t\t\tqgroup->max_rfer = limit->max_rfer;\n\t\t}\n\t}\n\tif (limit->flags & BTRFS_QGROUP_LIMIT_MAX_EXCL) {\n\t\tif (limit->max_excl == CLEAR_VALUE) {\n\t\t\tqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_MAX_EXCL;\n\t\t\tlimit->flags &= ~BTRFS_QGROUP_LIMIT_MAX_EXCL;\n\t\t\tqgroup->max_excl = 0;\n\t\t} else {\n\t\t\tqgroup->max_excl = limit->max_excl;\n\t\t}\n\t}\n\tif (limit->flags & BTRFS_QGROUP_LIMIT_RSV_RFER) {\n\t\tif (limit->rsv_rfer == CLEAR_VALUE) {\n\t\t\tqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_RSV_RFER;\n\t\t\tlimit->flags &= ~BTRFS_QGROUP_LIMIT_RSV_RFER;\n\t\t\tqgroup->rsv_rfer = 0;\n\t\t} else {\n\t\t\tqgroup->rsv_rfer = limit->rsv_rfer;\n\t\t}\n\t}\n\tif (limit->flags & BTRFS_QGROUP_LIMIT_RSV_EXCL) {\n\t\tif (limit->rsv_excl == CLEAR_VALUE) {\n\t\t\tqgroup->lim_flags &= ~BTRFS_QGROUP_LIMIT_RSV_EXCL;\n\t\t\tlimit->flags &= ~BTRFS_QGROUP_LIMIT_RSV_EXCL;\n\t\t\tqgroup->rsv_excl = 0;\n\t\t} else {\n\t\t\tqgroup->rsv_excl = limit->rsv_excl;\n\t\t}\n\t}\n\tqgroup->lim_flags |= limit->flags;\n\n\tspin_unlock(&fs_info->qgroup_lock);\n\n\tret = update_qgroup_limit_item(trans, qgroup);\n\tif (ret) {\n\t\tqgroup_mark_inconsistent(fs_info);\n\t\tbtrfs_info(fs_info, \"unable to update quota limit for %llu\",\n\t\t       qgroupid);\n\t}\n\nout:\n\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\treturn ret;\n}\n\nint btrfs_qgroup_trace_extent_nolock(struct btrfs_fs_info *fs_info,\n\t\t\t\tstruct btrfs_delayed_ref_root *delayed_refs,\n\t\t\t\tstruct btrfs_qgroup_extent_record *record)\n{\n\tstruct rb_node **p = &delayed_refs->dirty_extent_root.rb_node;\n\tstruct rb_node *parent_node = NULL;\n\tstruct btrfs_qgroup_extent_record *entry;\n\tu64 bytenr = record->bytenr;\n\n\tlockdep_assert_held(&delayed_refs->lock);\n\ttrace_btrfs_qgroup_trace_extent(fs_info, record);\n\n\twhile (*p) {\n\t\tparent_node = *p;\n\t\tentry = rb_entry(parent_node, struct btrfs_qgroup_extent_record,\n\t\t\t\t node);\n\t\tif (bytenr < entry->bytenr) {\n\t\t\tp = &(*p)->rb_left;\n\t\t} else if (bytenr > entry->bytenr) {\n\t\t\tp = &(*p)->rb_right;\n\t\t} else {\n\t\t\tif (record->data_rsv && !entry->data_rsv) {\n\t\t\t\tentry->data_rsv = record->data_rsv;\n\t\t\t\tentry->data_rsv_refroot =\n\t\t\t\t\trecord->data_rsv_refroot;\n\t\t\t}\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\trb_link_node(&record->node, parent_node, p);\n\trb_insert_color(&record->node, &delayed_refs->dirty_extent_root);\n\treturn 0;\n}\n\nint btrfs_qgroup_trace_extent_post(struct btrfs_trans_handle *trans,\n\t\t\t\t   struct btrfs_qgroup_extent_record *qrecord)\n{\n\tstruct btrfs_backref_walk_ctx ctx = { 0 };\n\tint ret;\n\n\t \n\tASSERT(trans != NULL);\n\n\tif (trans->fs_info->qgroup_flags & BTRFS_QGROUP_RUNTIME_FLAG_NO_ACCOUNTING)\n\t\treturn 0;\n\n\tctx.bytenr = qrecord->bytenr;\n\tctx.fs_info = trans->fs_info;\n\n\tret = btrfs_find_all_roots(&ctx, true);\n\tif (ret < 0) {\n\t\tqgroup_mark_inconsistent(trans->fs_info);\n\t\tbtrfs_warn(trans->fs_info,\n\"error accounting new delayed refs extent (err code: %d), quota inconsistent\",\n\t\t\tret);\n\t\treturn 0;\n\t}\n\n\t \n\tqrecord->old_roots = ctx.roots;\n\treturn 0;\n}\n\nint btrfs_qgroup_trace_extent(struct btrfs_trans_handle *trans, u64 bytenr,\n\t\t\t      u64 num_bytes)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_qgroup_extent_record *record;\n\tstruct btrfs_delayed_ref_root *delayed_refs;\n\tint ret;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags)\n\t    || bytenr == 0 || num_bytes == 0)\n\t\treturn 0;\n\trecord = kzalloc(sizeof(*record), GFP_NOFS);\n\tif (!record)\n\t\treturn -ENOMEM;\n\n\tdelayed_refs = &trans->transaction->delayed_refs;\n\trecord->bytenr = bytenr;\n\trecord->num_bytes = num_bytes;\n\trecord->old_roots = NULL;\n\n\tspin_lock(&delayed_refs->lock);\n\tret = btrfs_qgroup_trace_extent_nolock(fs_info, delayed_refs, record);\n\tspin_unlock(&delayed_refs->lock);\n\tif (ret > 0) {\n\t\tkfree(record);\n\t\treturn 0;\n\t}\n\treturn btrfs_qgroup_trace_extent_post(trans, record);\n}\n\nint btrfs_qgroup_trace_leaf_items(struct btrfs_trans_handle *trans,\n\t\t\t\t  struct extent_buffer *eb)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tint nr = btrfs_header_nritems(eb);\n\tint i, extent_type, ret;\n\tstruct btrfs_key key;\n\tstruct btrfs_file_extent_item *fi;\n\tu64 bytenr, num_bytes;\n\n\t \n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\treturn 0;\n\n\tfor (i = 0; i < nr; i++) {\n\t\tbtrfs_item_key_to_cpu(eb, &key, i);\n\n\t\tif (key.type != BTRFS_EXTENT_DATA_KEY)\n\t\t\tcontinue;\n\n\t\tfi = btrfs_item_ptr(eb, i, struct btrfs_file_extent_item);\n\t\t \n\t\textent_type = btrfs_file_extent_type(eb, fi);\n\n\t\tif (extent_type == BTRFS_FILE_EXTENT_INLINE)\n\t\t\tcontinue;\n\n\t\tbytenr = btrfs_file_extent_disk_bytenr(eb, fi);\n\t\tif (!bytenr)\n\t\t\tcontinue;\n\n\t\tnum_bytes = btrfs_file_extent_disk_num_bytes(eb, fi);\n\n\t\tret = btrfs_qgroup_trace_extent(trans, bytenr, num_bytes);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\tcond_resched();\n\treturn 0;\n}\n\n \nstatic int adjust_slots_upwards(struct btrfs_path *path, int root_level)\n{\n\tint level = 0;\n\tint nr, slot;\n\tstruct extent_buffer *eb;\n\n\tif (root_level == 0)\n\t\treturn 1;\n\n\twhile (level <= root_level) {\n\t\teb = path->nodes[level];\n\t\tnr = btrfs_header_nritems(eb);\n\t\tpath->slots[level]++;\n\t\tslot = path->slots[level];\n\t\tif (slot >= nr || level == 0) {\n\t\t\t \n\t\t\tif (level != root_level) {\n\t\t\t\tbtrfs_tree_unlock_rw(eb, path->locks[level]);\n\t\t\t\tpath->locks[level] = 0;\n\n\t\t\t\tfree_extent_buffer(eb);\n\t\t\t\tpath->nodes[level] = NULL;\n\t\t\t\tpath->slots[level] = 0;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\n\t\tlevel++;\n\t}\n\n\teb = path->nodes[root_level];\n\tif (path->slots[root_level] >= btrfs_header_nritems(eb))\n\t\treturn 1;\n\n\treturn 0;\n}\n\n \nstatic int qgroup_trace_extent_swap(struct btrfs_trans_handle* trans,\n\t\t\t\t    struct extent_buffer *src_eb,\n\t\t\t\t    struct btrfs_path *dst_path,\n\t\t\t\t    int dst_level, int root_level,\n\t\t\t\t    bool trace_leaf)\n{\n\tstruct btrfs_key key;\n\tstruct btrfs_path *src_path;\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tu32 nodesize = fs_info->nodesize;\n\tint cur_level = root_level;\n\tint ret;\n\n\tBUG_ON(dst_level > root_level);\n\t \n\tif (btrfs_header_level(src_eb) != root_level)\n\t\treturn -EINVAL;\n\n\tsrc_path = btrfs_alloc_path();\n\tif (!src_path) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (dst_level)\n\t\tbtrfs_node_key_to_cpu(dst_path->nodes[dst_level], &key, 0);\n\telse\n\t\tbtrfs_item_key_to_cpu(dst_path->nodes[dst_level], &key, 0);\n\n\t \n\tatomic_inc(&src_eb->refs);\n\tsrc_path->nodes[root_level] = src_eb;\n\tsrc_path->slots[root_level] = dst_path->slots[root_level];\n\tsrc_path->locks[root_level] = 0;\n\n\t \n\twhile (cur_level >= dst_level) {\n\t\tstruct btrfs_key src_key;\n\t\tstruct btrfs_key dst_key;\n\n\t\tif (src_path->nodes[cur_level] == NULL) {\n\t\t\tstruct extent_buffer *eb;\n\t\t\tint parent_slot;\n\n\t\t\teb = src_path->nodes[cur_level + 1];\n\t\t\tparent_slot = src_path->slots[cur_level + 1];\n\n\t\t\teb = btrfs_read_node_slot(eb, parent_slot);\n\t\t\tif (IS_ERR(eb)) {\n\t\t\t\tret = PTR_ERR(eb);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tsrc_path->nodes[cur_level] = eb;\n\n\t\t\tbtrfs_tree_read_lock(eb);\n\t\t\tsrc_path->locks[cur_level] = BTRFS_READ_LOCK;\n\t\t}\n\n\t\tsrc_path->slots[cur_level] = dst_path->slots[cur_level];\n\t\tif (cur_level) {\n\t\t\tbtrfs_node_key_to_cpu(dst_path->nodes[cur_level],\n\t\t\t\t\t&dst_key, dst_path->slots[cur_level]);\n\t\t\tbtrfs_node_key_to_cpu(src_path->nodes[cur_level],\n\t\t\t\t\t&src_key, src_path->slots[cur_level]);\n\t\t} else {\n\t\t\tbtrfs_item_key_to_cpu(dst_path->nodes[cur_level],\n\t\t\t\t\t&dst_key, dst_path->slots[cur_level]);\n\t\t\tbtrfs_item_key_to_cpu(src_path->nodes[cur_level],\n\t\t\t\t\t&src_key, src_path->slots[cur_level]);\n\t\t}\n\t\t \n\t\tif (btrfs_comp_cpu_keys(&dst_key, &src_key)) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tcur_level--;\n\t}\n\n\t \n\tret = btrfs_qgroup_trace_extent(trans, src_path->nodes[dst_level]->start,\n\t\t\t\t\tnodesize);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = btrfs_qgroup_trace_extent(trans, dst_path->nodes[dst_level]->start,\n\t\t\t\t\tnodesize);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t \n\tif (dst_level == 0 && trace_leaf) {\n\t\tret = btrfs_qgroup_trace_leaf_items(trans, src_path->nodes[0]);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tret = btrfs_qgroup_trace_leaf_items(trans, dst_path->nodes[0]);\n\t}\nout:\n\tbtrfs_free_path(src_path);\n\treturn ret;\n}\n\n \nstatic int qgroup_trace_new_subtree_blocks(struct btrfs_trans_handle* trans,\n\t\t\t\t\t   struct extent_buffer *src_eb,\n\t\t\t\t\t   struct btrfs_path *dst_path,\n\t\t\t\t\t   int cur_level, int root_level,\n\t\t\t\t\t   u64 last_snapshot, bool trace_leaf)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct extent_buffer *eb;\n\tbool need_cleanup = false;\n\tint ret = 0;\n\tint i;\n\n\t \n\tif (cur_level < 0 || cur_level >= BTRFS_MAX_LEVEL - 1 ||\n\t    root_level < 0 || root_level >= BTRFS_MAX_LEVEL - 1 ||\n\t    root_level < cur_level) {\n\t\tbtrfs_err_rl(fs_info,\n\t\t\t\"%s: bad levels, cur_level=%d root_level=%d\",\n\t\t\t__func__, cur_level, root_level);\n\t\treturn -EUCLEAN;\n\t}\n\n\t \n\tif (dst_path->nodes[cur_level] == NULL) {\n\t\tint parent_slot;\n\t\tu64 child_gen;\n\n\t\t \n\t\tif (cur_level == root_level) {\n\t\t\tbtrfs_err_rl(fs_info,\n\t\"%s: dst_path->nodes[%d] not initialized, root_level=%d cur_level=%d\",\n\t\t\t\t__func__, root_level, root_level, cur_level);\n\t\t\treturn -EUCLEAN;\n\t\t}\n\n\t\t \n\t\teb = dst_path->nodes[cur_level + 1];\n\t\tparent_slot = dst_path->slots[cur_level + 1];\n\t\tchild_gen = btrfs_node_ptr_generation(eb, parent_slot);\n\n\t\t \n\t\tif (child_gen < last_snapshot)\n\t\t\tgoto out;\n\n\t\teb = btrfs_read_node_slot(eb, parent_slot);\n\t\tif (IS_ERR(eb)) {\n\t\t\tret = PTR_ERR(eb);\n\t\t\tgoto out;\n\t\t}\n\n\t\tdst_path->nodes[cur_level] = eb;\n\t\tdst_path->slots[cur_level] = 0;\n\n\t\tbtrfs_tree_read_lock(eb);\n\t\tdst_path->locks[cur_level] = BTRFS_READ_LOCK;\n\t\tneed_cleanup = true;\n\t}\n\n\t \n\tret = qgroup_trace_extent_swap(trans, src_eb, dst_path, cur_level,\n\t\t\t\t       root_level, trace_leaf);\n\tif (ret < 0)\n\t\tgoto cleanup;\n\n\teb = dst_path->nodes[cur_level];\n\n\tif (cur_level > 0) {\n\t\t \n\t\tfor (i = 0; i < btrfs_header_nritems(eb); i++) {\n\t\t\t \n\t\t\tif (btrfs_node_ptr_generation(eb, i) < last_snapshot)\n\t\t\t\tcontinue;\n\t\t\tdst_path->slots[cur_level] = i;\n\n\t\t\t \n\t\t\tret = qgroup_trace_new_subtree_blocks(trans, src_eb,\n\t\t\t\t\tdst_path, cur_level - 1, root_level,\n\t\t\t\t\tlast_snapshot, trace_leaf);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto cleanup;\n\t\t}\n\t}\n\ncleanup:\n\tif (need_cleanup) {\n\t\t \n\t\tbtrfs_tree_unlock_rw(dst_path->nodes[cur_level],\n\t\t\t\t     dst_path->locks[cur_level]);\n\t\tfree_extent_buffer(dst_path->nodes[cur_level]);\n\t\tdst_path->nodes[cur_level] = NULL;\n\t\tdst_path->slots[cur_level] = 0;\n\t\tdst_path->locks[cur_level] = 0;\n\t}\nout:\n\treturn ret;\n}\n\nstatic int qgroup_trace_subtree_swap(struct btrfs_trans_handle *trans,\n\t\t\t\tstruct extent_buffer *src_eb,\n\t\t\t\tstruct extent_buffer *dst_eb,\n\t\t\t\tu64 last_snapshot, bool trace_leaf)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_path *dst_path = NULL;\n\tint level;\n\tint ret;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\treturn 0;\n\n\t \n\tif (btrfs_header_generation(src_eb) > btrfs_header_generation(dst_eb)) {\n\t\tbtrfs_err_rl(fs_info,\n\t\t\"%s: bad parameter order, src_gen=%llu dst_gen=%llu\", __func__,\n\t\t\t     btrfs_header_generation(src_eb),\n\t\t\t     btrfs_header_generation(dst_eb));\n\t\treturn -EUCLEAN;\n\t}\n\n\tif (!extent_buffer_uptodate(src_eb) || !extent_buffer_uptodate(dst_eb)) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tlevel = btrfs_header_level(dst_eb);\n\tdst_path = btrfs_alloc_path();\n\tif (!dst_path) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\t \n\tatomic_inc(&dst_eb->refs);\n\tdst_path->nodes[level] = dst_eb;\n\tdst_path->slots[level] = 0;\n\tdst_path->locks[level] = 0;\n\n\t \n\tret = qgroup_trace_new_subtree_blocks(trans, src_eb, dst_path, level,\n\t\t\t\t\t      level, last_snapshot, trace_leaf);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = 0;\n\nout:\n\tbtrfs_free_path(dst_path);\n\tif (ret < 0)\n\t\tqgroup_mark_inconsistent(fs_info);\n\treturn ret;\n}\n\nint btrfs_qgroup_trace_subtree(struct btrfs_trans_handle *trans,\n\t\t\t       struct extent_buffer *root_eb,\n\t\t\t       u64 root_gen, int root_level)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tint ret = 0;\n\tint level;\n\tu8 drop_subptree_thres;\n\tstruct extent_buffer *eb = root_eb;\n\tstruct btrfs_path *path = NULL;\n\n\tBUG_ON(root_level < 0 || root_level >= BTRFS_MAX_LEVEL);\n\tBUG_ON(root_eb == NULL);\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\treturn 0;\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tdrop_subptree_thres = fs_info->qgroup_drop_subtree_thres;\n\tspin_unlock(&fs_info->qgroup_lock);\n\n\t \n\tif (root_level >= drop_subptree_thres) {\n\t\tqgroup_mark_inconsistent(fs_info);\n\t\treturn 0;\n\t}\n\n\tif (!extent_buffer_uptodate(root_eb)) {\n\t\tstruct btrfs_tree_parent_check check = {\n\t\t\t.has_first_key = false,\n\t\t\t.transid = root_gen,\n\t\t\t.level = root_level\n\t\t};\n\n\t\tret = btrfs_read_extent_buffer(root_eb, &check);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tif (root_level == 0) {\n\t\tret = btrfs_qgroup_trace_leaf_items(trans, root_eb);\n\t\tgoto out;\n\t}\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\t \n\tatomic_inc(&root_eb->refs);\t \n\tpath->nodes[root_level] = root_eb;\n\tpath->slots[root_level] = 0;\n\tpath->locks[root_level] = 0;  \nwalk_down:\n\tlevel = root_level;\n\twhile (level >= 0) {\n\t\tif (path->nodes[level] == NULL) {\n\t\t\tint parent_slot;\n\t\t\tu64 child_bytenr;\n\n\t\t\t \n\t\t\teb = path->nodes[level + 1];\n\t\t\tparent_slot = path->slots[level + 1];\n\t\t\tchild_bytenr = btrfs_node_blockptr(eb, parent_slot);\n\n\t\t\teb = btrfs_read_node_slot(eb, parent_slot);\n\t\t\tif (IS_ERR(eb)) {\n\t\t\t\tret = PTR_ERR(eb);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tpath->nodes[level] = eb;\n\t\t\tpath->slots[level] = 0;\n\n\t\t\tbtrfs_tree_read_lock(eb);\n\t\t\tpath->locks[level] = BTRFS_READ_LOCK;\n\n\t\t\tret = btrfs_qgroup_trace_extent(trans, child_bytenr,\n\t\t\t\t\t\t\tfs_info->nodesize);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t}\n\n\t\tif (level == 0) {\n\t\t\tret = btrfs_qgroup_trace_leaf_items(trans,\n\t\t\t\t\t\t\t    path->nodes[level]);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\n\t\t\t \n\t\t\tret = adjust_slots_upwards(path, root_level);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tgoto walk_down;\n\t\t}\n\n\t\tlevel--;\n\t}\n\n\tret = 0;\nout:\n\tbtrfs_free_path(path);\n\n\treturn ret;\n}\n\n#define UPDATE_NEW\t0\n#define UPDATE_OLD\t1\n \nstatic int qgroup_update_refcnt(struct btrfs_fs_info *fs_info,\n\t\t\t\tstruct ulist *roots, struct ulist *tmp,\n\t\t\t\tstruct ulist *qgroups, u64 seq, int update_old)\n{\n\tstruct ulist_node *unode;\n\tstruct ulist_iterator uiter;\n\tstruct ulist_node *tmp_unode;\n\tstruct ulist_iterator tmp_uiter;\n\tstruct btrfs_qgroup *qg;\n\tint ret = 0;\n\n\tif (!roots)\n\t\treturn 0;\n\tULIST_ITER_INIT(&uiter);\n\twhile ((unode = ulist_next(roots, &uiter))) {\n\t\tqg = find_qgroup_rb(fs_info, unode->val);\n\t\tif (!qg)\n\t\t\tcontinue;\n\n\t\tulist_reinit(tmp);\n\t\tret = ulist_add(qgroups, qg->qgroupid, qgroup_to_aux(qg),\n\t\t\t\tGFP_ATOMIC);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = ulist_add(tmp, qg->qgroupid, qgroup_to_aux(qg), GFP_ATOMIC);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tULIST_ITER_INIT(&tmp_uiter);\n\t\twhile ((tmp_unode = ulist_next(tmp, &tmp_uiter))) {\n\t\t\tstruct btrfs_qgroup_list *glist;\n\n\t\t\tqg = unode_aux_to_qgroup(tmp_unode);\n\t\t\tif (update_old)\n\t\t\t\tbtrfs_qgroup_update_old_refcnt(qg, seq, 1);\n\t\t\telse\n\t\t\t\tbtrfs_qgroup_update_new_refcnt(qg, seq, 1);\n\t\t\tlist_for_each_entry(glist, &qg->groups, next_group) {\n\t\t\t\tret = ulist_add(qgroups, glist->group->qgroupid,\n\t\t\t\t\t\tqgroup_to_aux(glist->group),\n\t\t\t\t\t\tGFP_ATOMIC);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tret = ulist_add(tmp, glist->group->qgroupid,\n\t\t\t\t\t\tqgroup_to_aux(glist->group),\n\t\t\t\t\t\tGFP_ATOMIC);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic int qgroup_update_counters(struct btrfs_fs_info *fs_info,\n\t\t\t\t  struct ulist *qgroups,\n\t\t\t\t  u64 nr_old_roots,\n\t\t\t\t  u64 nr_new_roots,\n\t\t\t\t  u64 num_bytes, u64 seq)\n{\n\tstruct ulist_node *unode;\n\tstruct ulist_iterator uiter;\n\tstruct btrfs_qgroup *qg;\n\tu64 cur_new_count, cur_old_count;\n\n\tULIST_ITER_INIT(&uiter);\n\twhile ((unode = ulist_next(qgroups, &uiter))) {\n\t\tbool dirty = false;\n\n\t\tqg = unode_aux_to_qgroup(unode);\n\t\tcur_old_count = btrfs_qgroup_get_old_refcnt(qg, seq);\n\t\tcur_new_count = btrfs_qgroup_get_new_refcnt(qg, seq);\n\n\t\ttrace_qgroup_update_counters(fs_info, qg, cur_old_count,\n\t\t\t\t\t     cur_new_count);\n\n\t\t \n\t\tif (cur_old_count == 0 && cur_new_count > 0) {\n\t\t\tqg->rfer += num_bytes;\n\t\t\tqg->rfer_cmpr += num_bytes;\n\t\t\tdirty = true;\n\t\t}\n\t\tif (cur_old_count > 0 && cur_new_count == 0) {\n\t\t\tqg->rfer -= num_bytes;\n\t\t\tqg->rfer_cmpr -= num_bytes;\n\t\t\tdirty = true;\n\t\t}\n\n\t\t \n\t\t \n\t\tif (cur_old_count == nr_old_roots &&\n\t\t    cur_new_count < nr_new_roots) {\n\t\t\t \n\t\t\tif (cur_old_count != 0) {\n\t\t\t\tqg->excl -= num_bytes;\n\t\t\t\tqg->excl_cmpr -= num_bytes;\n\t\t\t\tdirty = true;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (cur_old_count < nr_old_roots &&\n\t\t    cur_new_count == nr_new_roots) {\n\t\t\t \n\t\t\tif (cur_new_count != 0) {\n\t\t\t\tqg->excl += num_bytes;\n\t\t\t\tqg->excl_cmpr += num_bytes;\n\t\t\t\tdirty = true;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (cur_old_count == nr_old_roots &&\n\t\t    cur_new_count == nr_new_roots) {\n\t\t\tif (cur_old_count == 0) {\n\t\t\t\t \n\n\t\t\t\tif (cur_new_count != 0) {\n\t\t\t\t\t \n\t\t\t\t\tqg->excl += num_bytes;\n\t\t\t\t\tqg->excl_cmpr += num_bytes;\n\t\t\t\t\tdirty = true;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t} else {\n\t\t\t\t \n\n\t\t\t\tif (cur_new_count == 0) {\n\t\t\t\t\t \n\t\t\t\t\tqg->excl -= num_bytes;\n\t\t\t\t\tqg->excl_cmpr -= num_bytes;\n\t\t\t\t\tdirty = true;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t}\n\t\t}\n\n\t\tif (dirty)\n\t\t\tqgroup_dirty(fs_info, qg);\n\t}\n\treturn 0;\n}\n\n \nstatic int maybe_fs_roots(struct ulist *roots)\n{\n\tstruct ulist_node *unode;\n\tstruct ulist_iterator uiter;\n\n\t \n\tif (!roots || roots->nnodes == 0)\n\t\treturn 1;\n\n\tULIST_ITER_INIT(&uiter);\n\tunode = ulist_next(roots, &uiter);\n\tif (!unode)\n\t\treturn 1;\n\n\t \n\treturn is_fstree(unode->val);\n}\n\nint btrfs_qgroup_account_extent(struct btrfs_trans_handle *trans, u64 bytenr,\n\t\t\t\tu64 num_bytes, struct ulist *old_roots,\n\t\t\t\tstruct ulist *new_roots)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct ulist *qgroups = NULL;\n\tstruct ulist *tmp = NULL;\n\tu64 seq;\n\tu64 nr_new_roots = 0;\n\tu64 nr_old_roots = 0;\n\tint ret = 0;\n\n\t \n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) ||\n\t    fs_info->qgroup_flags & BTRFS_QGROUP_RUNTIME_FLAG_NO_ACCOUNTING)\n\t\tgoto out_free;\n\n\tif (new_roots) {\n\t\tif (!maybe_fs_roots(new_roots))\n\t\t\tgoto out_free;\n\t\tnr_new_roots = new_roots->nnodes;\n\t}\n\tif (old_roots) {\n\t\tif (!maybe_fs_roots(old_roots))\n\t\t\tgoto out_free;\n\t\tnr_old_roots = old_roots->nnodes;\n\t}\n\n\t \n\tif (nr_old_roots == 0 && nr_new_roots == 0)\n\t\tgoto out_free;\n\n\tBUG_ON(!fs_info->quota_root);\n\n\ttrace_btrfs_qgroup_account_extent(fs_info, trans->transid, bytenr,\n\t\t\t\t\tnum_bytes, nr_old_roots, nr_new_roots);\n\n\tqgroups = ulist_alloc(GFP_NOFS);\n\tif (!qgroups) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\ttmp = ulist_alloc(GFP_NOFS);\n\tif (!tmp) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\tif (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN) {\n\t\tif (fs_info->qgroup_rescan_progress.objectid <= bytenr) {\n\t\t\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\t\t\tret = 0;\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tseq = fs_info->qgroup_seq;\n\n\t \n\tret = qgroup_update_refcnt(fs_info, old_roots, tmp, qgroups, seq,\n\t\t\t\t   UPDATE_OLD);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t \n\tret = qgroup_update_refcnt(fs_info, new_roots, tmp, qgroups, seq,\n\t\t\t\t   UPDATE_NEW);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tqgroup_update_counters(fs_info, qgroups, nr_old_roots, nr_new_roots,\n\t\t\t       num_bytes, seq);\n\n\t \n\tfs_info->qgroup_seq += max(nr_old_roots, nr_new_roots) + 1;\nout:\n\tspin_unlock(&fs_info->qgroup_lock);\nout_free:\n\tulist_free(tmp);\n\tulist_free(qgroups);\n\tulist_free(old_roots);\n\tulist_free(new_roots);\n\treturn ret;\n}\n\nint btrfs_qgroup_account_extents(struct btrfs_trans_handle *trans)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_qgroup_extent_record *record;\n\tstruct btrfs_delayed_ref_root *delayed_refs;\n\tstruct ulist *new_roots = NULL;\n\tstruct rb_node *node;\n\tu64 num_dirty_extents = 0;\n\tu64 qgroup_to_skip;\n\tint ret = 0;\n\n\tdelayed_refs = &trans->transaction->delayed_refs;\n\tqgroup_to_skip = delayed_refs->qgroup_to_skip;\n\twhile ((node = rb_first(&delayed_refs->dirty_extent_root))) {\n\t\trecord = rb_entry(node, struct btrfs_qgroup_extent_record,\n\t\t\t\t  node);\n\n\t\tnum_dirty_extents++;\n\t\ttrace_btrfs_qgroup_account_extents(fs_info, record);\n\n\t\tif (!ret && !(fs_info->qgroup_flags &\n\t\t\t      BTRFS_QGROUP_RUNTIME_FLAG_NO_ACCOUNTING)) {\n\t\t\tstruct btrfs_backref_walk_ctx ctx = { 0 };\n\n\t\t\tctx.bytenr = record->bytenr;\n\t\t\tctx.fs_info = fs_info;\n\n\t\t\t \n\t\t\tif (!record->old_roots) {\n\t\t\t\t \n\t\t\t\tret = btrfs_find_all_roots(&ctx, false);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\tgoto cleanup;\n\t\t\t\trecord->old_roots = ctx.roots;\n\t\t\t\tctx.roots = NULL;\n\t\t\t}\n\n\t\t\t \n\t\t\tbtrfs_qgroup_free_refroot(fs_info,\n\t\t\t\t\trecord->data_rsv_refroot,\n\t\t\t\t\trecord->data_rsv,\n\t\t\t\t\tBTRFS_QGROUP_RSV_DATA);\n\t\t\t \n\t\t\tctx.trans = trans;\n\t\t\tctx.time_seq = BTRFS_SEQ_LAST;\n\t\t\tret = btrfs_find_all_roots(&ctx, false);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto cleanup;\n\t\t\tnew_roots = ctx.roots;\n\t\t\tif (qgroup_to_skip) {\n\t\t\t\tulist_del(new_roots, qgroup_to_skip, 0);\n\t\t\t\tulist_del(record->old_roots, qgroup_to_skip,\n\t\t\t\t\t  0);\n\t\t\t}\n\t\t\tret = btrfs_qgroup_account_extent(trans, record->bytenr,\n\t\t\t\t\t\t\t  record->num_bytes,\n\t\t\t\t\t\t\t  record->old_roots,\n\t\t\t\t\t\t\t  new_roots);\n\t\t\trecord->old_roots = NULL;\n\t\t\tnew_roots = NULL;\n\t\t}\ncleanup:\n\t\tulist_free(record->old_roots);\n\t\tulist_free(new_roots);\n\t\tnew_roots = NULL;\n\t\trb_erase(node, &delayed_refs->dirty_extent_root);\n\t\tkfree(record);\n\n\t}\n\ttrace_qgroup_num_dirty_extents(fs_info, trans->transid,\n\t\t\t\t       num_dirty_extents);\n\treturn ret;\n}\n\n \nint btrfs_run_qgroups(struct btrfs_trans_handle *trans)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tint ret = 0;\n\n\t \n\tif (trans->transaction->state != TRANS_STATE_COMMIT_DOING)\n\t\tlockdep_assert_held(&fs_info->qgroup_ioctl_lock);\n\n\tif (!fs_info->quota_root)\n\t\treturn ret;\n\n\tspin_lock(&fs_info->qgroup_lock);\n\twhile (!list_empty(&fs_info->dirty_qgroups)) {\n\t\tstruct btrfs_qgroup *qgroup;\n\t\tqgroup = list_first_entry(&fs_info->dirty_qgroups,\n\t\t\t\t\t  struct btrfs_qgroup, dirty);\n\t\tlist_del_init(&qgroup->dirty);\n\t\tspin_unlock(&fs_info->qgroup_lock);\n\t\tret = update_qgroup_info_item(trans, qgroup);\n\t\tif (ret)\n\t\t\tqgroup_mark_inconsistent(fs_info);\n\t\tret = update_qgroup_limit_item(trans, qgroup);\n\t\tif (ret)\n\t\t\tqgroup_mark_inconsistent(fs_info);\n\t\tspin_lock(&fs_info->qgroup_lock);\n\t}\n\tif (test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\tfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_ON;\n\telse\n\t\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_ON;\n\tspin_unlock(&fs_info->qgroup_lock);\n\n\tret = update_qgroup_status_item(trans);\n\tif (ret)\n\t\tqgroup_mark_inconsistent(fs_info);\n\n\treturn ret;\n}\n\n \nint btrfs_qgroup_inherit(struct btrfs_trans_handle *trans, u64 srcid,\n\t\t\t u64 objectid, struct btrfs_qgroup_inherit *inherit)\n{\n\tint ret = 0;\n\tint i;\n\tu64 *i_qgroups;\n\tbool committing = false;\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_root *quota_root;\n\tstruct btrfs_qgroup *srcgroup;\n\tstruct btrfs_qgroup *dstgroup;\n\tbool need_rescan = false;\n\tu32 level_size = 0;\n\tu64 nums;\n\n\t \n\tspin_lock(&fs_info->trans_lock);\n\tif (trans->transaction->state == TRANS_STATE_COMMIT_DOING)\n\t\tcommitting = true;\n\tspin_unlock(&fs_info->trans_lock);\n\n\tif (!committing)\n\t\tmutex_lock(&fs_info->qgroup_ioctl_lock);\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\tgoto out;\n\n\tquota_root = fs_info->quota_root;\n\tif (!quota_root) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (inherit) {\n\t\ti_qgroups = (u64 *)(inherit + 1);\n\t\tnums = inherit->num_qgroups + 2 * inherit->num_ref_copies +\n\t\t       2 * inherit->num_excl_copies;\n\t\tfor (i = 0; i < nums; ++i) {\n\t\t\tsrcgroup = find_qgroup_rb(fs_info, *i_qgroups);\n\n\t\t\t \n\t\t\tif (!srcgroup ||\n\t\t\t    ((srcgroup->qgroupid >> 48) <= (objectid >> 48)))\n\t\t\t\t*i_qgroups = 0ULL;\n\n\t\t\t++i_qgroups;\n\t\t}\n\t}\n\n\t \n\tret = add_qgroup_item(trans, quota_root, objectid);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tif (inherit) {\n\t\ti_qgroups = (u64 *)(inherit + 1);\n\t\tfor (i = 0; i < inherit->num_qgroups; ++i, ++i_qgroups) {\n\t\t\tif (*i_qgroups == 0)\n\t\t\t\tcontinue;\n\t\t\tret = add_qgroup_relation_item(trans, objectid,\n\t\t\t\t\t\t       *i_qgroups);\n\t\t\tif (ret && ret != -EEXIST)\n\t\t\t\tgoto out;\n\t\t\tret = add_qgroup_relation_item(trans, *i_qgroups,\n\t\t\t\t\t\t       objectid);\n\t\t\tif (ret && ret != -EEXIST)\n\t\t\t\tgoto out;\n\t\t}\n\t\tret = 0;\n\t}\n\n\n\tspin_lock(&fs_info->qgroup_lock);\n\n\tdstgroup = add_qgroup_rb(fs_info, objectid);\n\tif (IS_ERR(dstgroup)) {\n\t\tret = PTR_ERR(dstgroup);\n\t\tgoto unlock;\n\t}\n\n\tif (inherit && inherit->flags & BTRFS_QGROUP_INHERIT_SET_LIMITS) {\n\t\tdstgroup->lim_flags = inherit->lim.flags;\n\t\tdstgroup->max_rfer = inherit->lim.max_rfer;\n\t\tdstgroup->max_excl = inherit->lim.max_excl;\n\t\tdstgroup->rsv_rfer = inherit->lim.rsv_rfer;\n\t\tdstgroup->rsv_excl = inherit->lim.rsv_excl;\n\n\t\tqgroup_dirty(fs_info, dstgroup);\n\t}\n\n\tif (srcid) {\n\t\tsrcgroup = find_qgroup_rb(fs_info, srcid);\n\t\tif (!srcgroup)\n\t\t\tgoto unlock;\n\n\t\t \n\t\tlevel_size = fs_info->nodesize;\n\t\tdstgroup->rfer = srcgroup->rfer;\n\t\tdstgroup->rfer_cmpr = srcgroup->rfer_cmpr;\n\t\tdstgroup->excl = level_size;\n\t\tdstgroup->excl_cmpr = level_size;\n\t\tsrcgroup->excl = level_size;\n\t\tsrcgroup->excl_cmpr = level_size;\n\n\t\t \n\t\tdstgroup->lim_flags = srcgroup->lim_flags;\n\t\tdstgroup->max_rfer = srcgroup->max_rfer;\n\t\tdstgroup->max_excl = srcgroup->max_excl;\n\t\tdstgroup->rsv_rfer = srcgroup->rsv_rfer;\n\t\tdstgroup->rsv_excl = srcgroup->rsv_excl;\n\n\t\tqgroup_dirty(fs_info, dstgroup);\n\t\tqgroup_dirty(fs_info, srcgroup);\n\t}\n\n\tif (!inherit)\n\t\tgoto unlock;\n\n\ti_qgroups = (u64 *)(inherit + 1);\n\tfor (i = 0; i < inherit->num_qgroups; ++i) {\n\t\tif (*i_qgroups) {\n\t\t\tret = add_relation_rb(fs_info, objectid, *i_qgroups);\n\t\t\tif (ret)\n\t\t\t\tgoto unlock;\n\t\t}\n\t\t++i_qgroups;\n\n\t\t \n\t\tif (srcid)\n\t\t\tneed_rescan = true;\n\t}\n\n\tfor (i = 0; i <  inherit->num_ref_copies; ++i, i_qgroups += 2) {\n\t\tstruct btrfs_qgroup *src;\n\t\tstruct btrfs_qgroup *dst;\n\n\t\tif (!i_qgroups[0] || !i_qgroups[1])\n\t\t\tcontinue;\n\n\t\tsrc = find_qgroup_rb(fs_info, i_qgroups[0]);\n\t\tdst = find_qgroup_rb(fs_info, i_qgroups[1]);\n\n\t\tif (!src || !dst) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto unlock;\n\t\t}\n\n\t\tdst->rfer = src->rfer - level_size;\n\t\tdst->rfer_cmpr = src->rfer_cmpr - level_size;\n\n\t\t \n\t\tneed_rescan = true;\n\t}\n\tfor (i = 0; i <  inherit->num_excl_copies; ++i, i_qgroups += 2) {\n\t\tstruct btrfs_qgroup *src;\n\t\tstruct btrfs_qgroup *dst;\n\n\t\tif (!i_qgroups[0] || !i_qgroups[1])\n\t\t\tcontinue;\n\n\t\tsrc = find_qgroup_rb(fs_info, i_qgroups[0]);\n\t\tdst = find_qgroup_rb(fs_info, i_qgroups[1]);\n\n\t\tif (!src || !dst) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto unlock;\n\t\t}\n\n\t\tdst->excl = src->excl + level_size;\n\t\tdst->excl_cmpr = src->excl_cmpr + level_size;\n\t\tneed_rescan = true;\n\t}\n\nunlock:\n\tspin_unlock(&fs_info->qgroup_lock);\n\tif (!ret)\n\t\tret = btrfs_sysfs_add_one_qgroup(fs_info, dstgroup);\nout:\n\tif (!committing)\n\t\tmutex_unlock(&fs_info->qgroup_ioctl_lock);\n\tif (need_rescan)\n\t\tqgroup_mark_inconsistent(fs_info);\n\treturn ret;\n}\n\nstatic bool qgroup_check_limits(const struct btrfs_qgroup *qg, u64 num_bytes)\n{\n\tif ((qg->lim_flags & BTRFS_QGROUP_LIMIT_MAX_RFER) &&\n\t    qgroup_rsv_total(qg) + (s64)qg->rfer + num_bytes > qg->max_rfer)\n\t\treturn false;\n\n\tif ((qg->lim_flags & BTRFS_QGROUP_LIMIT_MAX_EXCL) &&\n\t    qgroup_rsv_total(qg) + (s64)qg->excl + num_bytes > qg->max_excl)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int qgroup_reserve(struct btrfs_root *root, u64 num_bytes, bool enforce,\n\t\t\t  enum btrfs_qgroup_rsv_type type)\n{\n\tstruct btrfs_qgroup *qgroup;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tu64 ref_root = root->root_key.objectid;\n\tint ret = 0;\n\tLIST_HEAD(qgroup_list);\n\n\tif (!is_fstree(ref_root))\n\t\treturn 0;\n\n\tif (num_bytes == 0)\n\t\treturn 0;\n\n\tif (test_bit(BTRFS_FS_QUOTA_OVERRIDE, &fs_info->flags) &&\n\t    capable(CAP_SYS_RESOURCE))\n\t\tenforce = false;\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tif (!fs_info->quota_root)\n\t\tgoto out;\n\n\tqgroup = find_qgroup_rb(fs_info, ref_root);\n\tif (!qgroup)\n\t\tgoto out;\n\n\tqgroup_iterator_add(&qgroup_list, qgroup);\n\tlist_for_each_entry(qgroup, &qgroup_list, iterator) {\n\t\tstruct btrfs_qgroup_list *glist;\n\n\t\tif (enforce && !qgroup_check_limits(qgroup, num_bytes)) {\n\t\t\tret = -EDQUOT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tlist_for_each_entry(glist, &qgroup->groups, next_group)\n\t\t\tqgroup_iterator_add(&qgroup_list, glist->group);\n\t}\n\n\tret = 0;\n\t \n\tlist_for_each_entry(qgroup, &qgroup_list, iterator)\n\t\tqgroup_rsv_add(fs_info, qgroup, num_bytes, type);\n\nout:\n\tqgroup_iterator_clean(&qgroup_list);\n\tspin_unlock(&fs_info->qgroup_lock);\n\treturn ret;\n}\n\n \nvoid btrfs_qgroup_free_refroot(struct btrfs_fs_info *fs_info,\n\t\t\t       u64 ref_root, u64 num_bytes,\n\t\t\t       enum btrfs_qgroup_rsv_type type)\n{\n\tstruct btrfs_qgroup *qgroup;\n\tstruct ulist_node *unode;\n\tstruct ulist_iterator uiter;\n\tint ret = 0;\n\n\tif (!is_fstree(ref_root))\n\t\treturn;\n\n\tif (num_bytes == 0)\n\t\treturn;\n\n\tif (num_bytes == (u64)-1 && type != BTRFS_QGROUP_RSV_META_PERTRANS) {\n\t\tWARN(1, \"%s: Invalid type to free\", __func__);\n\t\treturn;\n\t}\n\tspin_lock(&fs_info->qgroup_lock);\n\n\tif (!fs_info->quota_root)\n\t\tgoto out;\n\n\tqgroup = find_qgroup_rb(fs_info, ref_root);\n\tif (!qgroup)\n\t\tgoto out;\n\n\tif (num_bytes == (u64)-1)\n\t\t \n\t\tnum_bytes = qgroup->rsv.values[type];\n\n\tulist_reinit(fs_info->qgroup_ulist);\n\tret = ulist_add(fs_info->qgroup_ulist, qgroup->qgroupid,\n\t\t\tqgroup_to_aux(qgroup), GFP_ATOMIC);\n\tif (ret < 0)\n\t\tgoto out;\n\tULIST_ITER_INIT(&uiter);\n\twhile ((unode = ulist_next(fs_info->qgroup_ulist, &uiter))) {\n\t\tstruct btrfs_qgroup *qg;\n\t\tstruct btrfs_qgroup_list *glist;\n\n\t\tqg = unode_aux_to_qgroup(unode);\n\n\t\tqgroup_rsv_release(fs_info, qg, num_bytes, type);\n\n\t\tlist_for_each_entry(glist, &qg->groups, next_group) {\n\t\t\tret = ulist_add(fs_info->qgroup_ulist,\n\t\t\t\t\tglist->group->qgroupid,\n\t\t\t\t\tqgroup_to_aux(glist->group), GFP_ATOMIC);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tspin_unlock(&fs_info->qgroup_lock);\n}\n\n \nstatic bool is_last_leaf(struct btrfs_path *path)\n{\n\tint i;\n\n\tfor (i = 1; i < BTRFS_MAX_LEVEL && path->nodes[i]; i++) {\n\t\tif (path->slots[i] != btrfs_header_nritems(path->nodes[i]) - 1)\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\n \nstatic int qgroup_rescan_leaf(struct btrfs_trans_handle *trans,\n\t\t\t      struct btrfs_path *path)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_root *extent_root;\n\tstruct btrfs_key found;\n\tstruct extent_buffer *scratch_leaf = NULL;\n\tu64 num_bytes;\n\tbool done;\n\tint slot;\n\tint ret;\n\n\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\textent_root = btrfs_extent_root(fs_info,\n\t\t\t\tfs_info->qgroup_rescan_progress.objectid);\n\tret = btrfs_search_slot_for_read(extent_root,\n\t\t\t\t\t &fs_info->qgroup_rescan_progress,\n\t\t\t\t\t path, 1, 0);\n\n\tbtrfs_debug(fs_info,\n\t\t\"current progress key (%llu %u %llu), search_slot ret %d\",\n\t\tfs_info->qgroup_rescan_progress.objectid,\n\t\tfs_info->qgroup_rescan_progress.type,\n\t\tfs_info->qgroup_rescan_progress.offset, ret);\n\n\tif (ret) {\n\t\t \n\t\tfs_info->qgroup_rescan_progress.objectid = (u64)-1;\n\t\tbtrfs_release_path(path);\n\t\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\t\treturn ret;\n\t}\n\tdone = is_last_leaf(path);\n\n\tbtrfs_item_key_to_cpu(path->nodes[0], &found,\n\t\t\t      btrfs_header_nritems(path->nodes[0]) - 1);\n\tfs_info->qgroup_rescan_progress.objectid = found.objectid + 1;\n\n\tscratch_leaf = btrfs_clone_extent_buffer(path->nodes[0]);\n\tif (!scratch_leaf) {\n\t\tret = -ENOMEM;\n\t\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\t\tgoto out;\n\t}\n\tslot = path->slots[0];\n\tbtrfs_release_path(path);\n\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\n\tfor (; slot < btrfs_header_nritems(scratch_leaf); ++slot) {\n\t\tstruct btrfs_backref_walk_ctx ctx = { 0 };\n\n\t\tbtrfs_item_key_to_cpu(scratch_leaf, &found, slot);\n\t\tif (found.type != BTRFS_EXTENT_ITEM_KEY &&\n\t\t    found.type != BTRFS_METADATA_ITEM_KEY)\n\t\t\tcontinue;\n\t\tif (found.type == BTRFS_METADATA_ITEM_KEY)\n\t\t\tnum_bytes = fs_info->nodesize;\n\t\telse\n\t\t\tnum_bytes = found.offset;\n\n\t\tctx.bytenr = found.objectid;\n\t\tctx.fs_info = fs_info;\n\n\t\tret = btrfs_find_all_roots(&ctx, false);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\t \n\t\tret = btrfs_qgroup_account_extent(trans, found.objectid,\n\t\t\t\t\t\t  num_bytes, NULL, ctx.roots);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\nout:\n\tif (scratch_leaf)\n\t\tfree_extent_buffer(scratch_leaf);\n\n\tif (done && !ret) {\n\t\tret = 1;\n\t\tfs_info->qgroup_rescan_progress.objectid = (u64)-1;\n\t}\n\treturn ret;\n}\n\nstatic bool rescan_should_stop(struct btrfs_fs_info *fs_info)\n{\n\treturn btrfs_fs_closing(fs_info) ||\n\t\ttest_bit(BTRFS_FS_STATE_REMOUNTING, &fs_info->fs_state) ||\n\t\t!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) ||\n\t\t\t  fs_info->qgroup_flags & BTRFS_QGROUP_RUNTIME_FLAG_CANCEL_RESCAN;\n}\n\nstatic void btrfs_qgroup_rescan_worker(struct btrfs_work *work)\n{\n\tstruct btrfs_fs_info *fs_info = container_of(work, struct btrfs_fs_info,\n\t\t\t\t\t\t     qgroup_rescan_work);\n\tstruct btrfs_path *path;\n\tstruct btrfs_trans_handle *trans = NULL;\n\tint err = -ENOMEM;\n\tint ret = 0;\n\tbool stopped = false;\n\tbool did_leaf_rescans = false;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\tgoto out;\n\t \n\tpath->search_commit_root = 1;\n\tpath->skip_locking = 1;\n\n\terr = 0;\n\twhile (!err && !(stopped = rescan_should_stop(fs_info))) {\n\t\ttrans = btrfs_start_transaction(fs_info->fs_root, 0);\n\t\tif (IS_ERR(trans)) {\n\t\t\terr = PTR_ERR(trans);\n\t\t\tbreak;\n\t\t}\n\n\t\terr = qgroup_rescan_leaf(trans, path);\n\t\tdid_leaf_rescans = true;\n\n\t\tif (err > 0)\n\t\t\tbtrfs_commit_transaction(trans);\n\t\telse\n\t\t\tbtrfs_end_transaction(trans);\n\t}\n\nout:\n\tbtrfs_free_path(path);\n\n\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\tif (err > 0 &&\n\t    fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT) {\n\t\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\n\t} else if (err < 0 || stopped) {\n\t\tfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_INCONSISTENT;\n\t}\n\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\n\t \n\tif (did_leaf_rescans) {\n\t\ttrans = btrfs_start_transaction(fs_info->quota_root, 1);\n\t\tif (IS_ERR(trans)) {\n\t\t\terr = PTR_ERR(trans);\n\t\t\ttrans = NULL;\n\t\t\tbtrfs_err(fs_info,\n\t\t\t\t  \"fail to start transaction for status update: %d\",\n\t\t\t\t  err);\n\t\t}\n\t} else {\n\t\ttrans = NULL;\n\t}\n\n\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\tif (!stopped ||\n\t    fs_info->qgroup_flags & BTRFS_QGROUP_RUNTIME_FLAG_CANCEL_RESCAN)\n\t\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\n\tif (trans) {\n\t\tret = update_qgroup_status_item(trans);\n\t\tif (ret < 0) {\n\t\t\terr = ret;\n\t\t\tbtrfs_err(fs_info, \"fail to update qgroup status: %d\",\n\t\t\t\t  err);\n\t\t}\n\t}\n\tfs_info->qgroup_rescan_running = false;\n\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_RUNTIME_FLAG_CANCEL_RESCAN;\n\tcomplete_all(&fs_info->qgroup_rescan_completion);\n\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\n\tif (!trans)\n\t\treturn;\n\n\tbtrfs_end_transaction(trans);\n\n\tif (stopped) {\n\t\tbtrfs_info(fs_info, \"qgroup scan paused\");\n\t} else if (fs_info->qgroup_flags & BTRFS_QGROUP_RUNTIME_FLAG_CANCEL_RESCAN) {\n\t\tbtrfs_info(fs_info, \"qgroup scan cancelled\");\n\t} else if (err >= 0) {\n\t\tbtrfs_info(fs_info, \"qgroup scan completed%s\",\n\t\t\terr > 0 ? \" (inconsistency flag cleared)\" : \"\");\n\t} else {\n\t\tbtrfs_err(fs_info, \"qgroup scan failed with %d\", err);\n\t}\n}\n\n \nstatic int\nqgroup_rescan_init(struct btrfs_fs_info *fs_info, u64 progress_objectid,\n\t\t   int init_flags)\n{\n\tint ret = 0;\n\n\tif (!init_flags) {\n\t\t \n\t\tif (!(fs_info->qgroup_flags &\n\t\t      BTRFS_QGROUP_STATUS_FLAG_RESCAN)) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\"qgroup rescan init failed, qgroup rescan is not queued\");\n\t\t\tret = -EINVAL;\n\t\t} else if (!(fs_info->qgroup_flags &\n\t\t\t     BTRFS_QGROUP_STATUS_FLAG_ON)) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\"qgroup rescan init failed, qgroup is not enabled\");\n\t\t\tret = -EINVAL;\n\t\t}\n\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\n\tif (init_flags) {\n\t\tif (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t   \"qgroup rescan is already in progress\");\n\t\t\tret = -EINPROGRESS;\n\t\t} else if (!(fs_info->qgroup_flags &\n\t\t\t     BTRFS_QGROUP_STATUS_FLAG_ON)) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\"qgroup rescan init failed, qgroup is not enabled\");\n\t\t\tret = -EINVAL;\n\t\t} else if (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags)) {\n\t\t\t \n\t\t\tret = -EBUSY;\n\t\t}\n\n\t\tif (ret) {\n\t\t\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\t\t\treturn ret;\n\t\t}\n\t\tfs_info->qgroup_flags |= BTRFS_QGROUP_STATUS_FLAG_RESCAN;\n\t}\n\n\tmemset(&fs_info->qgroup_rescan_progress, 0,\n\t\tsizeof(fs_info->qgroup_rescan_progress));\n\tfs_info->qgroup_flags &= ~(BTRFS_QGROUP_RUNTIME_FLAG_CANCEL_RESCAN |\n\t\t\t\t   BTRFS_QGROUP_RUNTIME_FLAG_NO_ACCOUNTING);\n\tfs_info->qgroup_rescan_progress.objectid = progress_objectid;\n\tinit_completion(&fs_info->qgroup_rescan_completion);\n\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\n\tbtrfs_init_work(&fs_info->qgroup_rescan_work,\n\t\t\tbtrfs_qgroup_rescan_worker, NULL, NULL);\n\treturn 0;\n}\n\nstatic void\nqgroup_rescan_zero_tracking(struct btrfs_fs_info *fs_info)\n{\n\tstruct rb_node *n;\n\tstruct btrfs_qgroup *qgroup;\n\n\tspin_lock(&fs_info->qgroup_lock);\n\t \n\tfor (n = rb_first(&fs_info->qgroup_tree); n; n = rb_next(n)) {\n\t\tqgroup = rb_entry(n, struct btrfs_qgroup, node);\n\t\tqgroup->rfer = 0;\n\t\tqgroup->rfer_cmpr = 0;\n\t\tqgroup->excl = 0;\n\t\tqgroup->excl_cmpr = 0;\n\t\tqgroup_dirty(fs_info, qgroup);\n\t}\n\tspin_unlock(&fs_info->qgroup_lock);\n}\n\nint\nbtrfs_qgroup_rescan(struct btrfs_fs_info *fs_info)\n{\n\tint ret = 0;\n\tstruct btrfs_trans_handle *trans;\n\n\tret = qgroup_rescan_init(fs_info, 0, 1);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\n\ttrans = btrfs_attach_transaction_barrier(fs_info->fs_root);\n\tif (IS_ERR(trans) && trans != ERR_PTR(-ENOENT)) {\n\t\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\n\t\treturn PTR_ERR(trans);\n\t} else if (trans != ERR_PTR(-ENOENT)) {\n\t\tret = btrfs_commit_transaction(trans);\n\t\tif (ret) {\n\t\t\tfs_info->qgroup_flags &= ~BTRFS_QGROUP_STATUS_FLAG_RESCAN;\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tqgroup_rescan_zero_tracking(fs_info);\n\n\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\tfs_info->qgroup_rescan_running = true;\n\tbtrfs_queue_work(fs_info->qgroup_rescan_workers,\n\t\t\t &fs_info->qgroup_rescan_work);\n\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\n\treturn 0;\n}\n\nint btrfs_qgroup_wait_for_completion(struct btrfs_fs_info *fs_info,\n\t\t\t\t     bool interruptible)\n{\n\tint running;\n\tint ret = 0;\n\n\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\trunning = fs_info->qgroup_rescan_running;\n\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\n\tif (!running)\n\t\treturn 0;\n\n\tif (interruptible)\n\t\tret = wait_for_completion_interruptible(\n\t\t\t\t\t&fs_info->qgroup_rescan_completion);\n\telse\n\t\twait_for_completion(&fs_info->qgroup_rescan_completion);\n\n\treturn ret;\n}\n\n \nvoid\nbtrfs_qgroup_rescan_resume(struct btrfs_fs_info *fs_info)\n{\n\tif (fs_info->qgroup_flags & BTRFS_QGROUP_STATUS_FLAG_RESCAN) {\n\t\tmutex_lock(&fs_info->qgroup_rescan_lock);\n\t\tfs_info->qgroup_rescan_running = true;\n\t\tbtrfs_queue_work(fs_info->qgroup_rescan_workers,\n\t\t\t\t &fs_info->qgroup_rescan_work);\n\t\tmutex_unlock(&fs_info->qgroup_rescan_lock);\n\t}\n}\n\n#define rbtree_iterate_from_safe(node, next, start)\t\t\t\t\\\n       for (node = start; node && ({ next = rb_next(node); 1;}); node = next)\n\nstatic int qgroup_unreserve_range(struct btrfs_inode *inode,\n\t\t\t\t  struct extent_changeset *reserved, u64 start,\n\t\t\t\t  u64 len)\n{\n\tstruct rb_node *node;\n\tstruct rb_node *next;\n\tstruct ulist_node *entry;\n\tint ret = 0;\n\n\tnode = reserved->range_changed.root.rb_node;\n\tif (!node)\n\t\treturn 0;\n\twhile (node) {\n\t\tentry = rb_entry(node, struct ulist_node, rb_node);\n\t\tif (entry->val < start)\n\t\t\tnode = node->rb_right;\n\t\telse\n\t\t\tnode = node->rb_left;\n\t}\n\n\tif (entry->val > start && rb_prev(&entry->rb_node))\n\t\tentry = rb_entry(rb_prev(&entry->rb_node), struct ulist_node,\n\t\t\t\t rb_node);\n\n\trbtree_iterate_from_safe(node, next, &entry->rb_node) {\n\t\tu64 entry_start;\n\t\tu64 entry_end;\n\t\tu64 entry_len;\n\t\tint clear_ret;\n\n\t\tentry = rb_entry(node, struct ulist_node, rb_node);\n\t\tentry_start = entry->val;\n\t\tentry_end = entry->aux;\n\t\tentry_len = entry_end - entry_start + 1;\n\n\t\tif (entry_start >= start + len)\n\t\t\tbreak;\n\t\tif (entry_start + entry_len <= start)\n\t\t\tcontinue;\n\t\t \n\t\tclear_ret = clear_extent_bits(&inode->io_tree, entry_start,\n\t\t\t\t\t      entry_end, EXTENT_QGROUP_RESERVED);\n\t\tif (!ret && clear_ret < 0)\n\t\t\tret = clear_ret;\n\n\t\tulist_del(&reserved->range_changed, entry->val, entry->aux);\n\t\tif (likely(reserved->bytes_changed >= entry_len)) {\n\t\t\treserved->bytes_changed -= entry_len;\n\t\t} else {\n\t\t\tWARN_ON(1);\n\t\t\treserved->bytes_changed = 0;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n \nstatic int try_flush_qgroup(struct btrfs_root *root)\n{\n\tstruct btrfs_trans_handle *trans;\n\tint ret;\n\n\t \n\tASSERT(current->journal_info == NULL);\n\tif (WARN_ON(current->journal_info))\n\t\treturn 0;\n\n\t \n\tif (test_and_set_bit(BTRFS_ROOT_QGROUP_FLUSHING, &root->state)) {\n\t\twait_event(root->qgroup_flush_wait,\n\t\t\t!test_bit(BTRFS_ROOT_QGROUP_FLUSHING, &root->state));\n\t\treturn 0;\n\t}\n\n\tret = btrfs_start_delalloc_snapshot(root, true);\n\tif (ret < 0)\n\t\tgoto out;\n\tbtrfs_wait_ordered_extents(root, U64_MAX, 0, (u64)-1);\n\n\ttrans = btrfs_attach_transaction_barrier(root);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\tif (ret == -ENOENT)\n\t\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tret = btrfs_commit_transaction(trans);\nout:\n\tclear_bit(BTRFS_ROOT_QGROUP_FLUSHING, &root->state);\n\twake_up(&root->qgroup_flush_wait);\n\treturn ret;\n}\n\nstatic int qgroup_reserve_data(struct btrfs_inode *inode,\n\t\t\tstruct extent_changeset **reserved_ret, u64 start,\n\t\t\tu64 len)\n{\n\tstruct btrfs_root *root = inode->root;\n\tstruct extent_changeset *reserved;\n\tbool new_reserved = false;\n\tu64 orig_reserved;\n\tu64 to_reserve;\n\tint ret;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &root->fs_info->flags) ||\n\t    !is_fstree(root->root_key.objectid) || len == 0)\n\t\treturn 0;\n\n\t \n\tif (WARN_ON(!reserved_ret))\n\t\treturn -EINVAL;\n\tif (!*reserved_ret) {\n\t\tnew_reserved = true;\n\t\t*reserved_ret = extent_changeset_alloc();\n\t\tif (!*reserved_ret)\n\t\t\treturn -ENOMEM;\n\t}\n\treserved = *reserved_ret;\n\t \n\torig_reserved = reserved->bytes_changed;\n\tret = set_record_extent_bits(&inode->io_tree, start,\n\t\t\tstart + len -1, EXTENT_QGROUP_RESERVED, reserved);\n\n\t \n\tto_reserve = reserved->bytes_changed - orig_reserved;\n\ttrace_btrfs_qgroup_reserve_data(&inode->vfs_inode, start, len,\n\t\t\t\t\tto_reserve, QGROUP_RESERVE);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = qgroup_reserve(root, to_reserve, true, BTRFS_QGROUP_RSV_DATA);\n\tif (ret < 0)\n\t\tgoto cleanup;\n\n\treturn ret;\n\ncleanup:\n\tqgroup_unreserve_range(inode, reserved, start, len);\nout:\n\tif (new_reserved) {\n\t\textent_changeset_free(reserved);\n\t\t*reserved_ret = NULL;\n\t}\n\treturn ret;\n}\n\n \nint btrfs_qgroup_reserve_data(struct btrfs_inode *inode,\n\t\t\tstruct extent_changeset **reserved_ret, u64 start,\n\t\t\tu64 len)\n{\n\tint ret;\n\n\tret = qgroup_reserve_data(inode, reserved_ret, start, len);\n\tif (ret <= 0 && ret != -EDQUOT)\n\t\treturn ret;\n\n\tret = try_flush_qgroup(inode->root);\n\tif (ret < 0)\n\t\treturn ret;\n\treturn qgroup_reserve_data(inode, reserved_ret, start, len);\n}\n\n \nstatic int qgroup_free_reserved_data(struct btrfs_inode *inode,\n\t\t\t\t     struct extent_changeset *reserved,\n\t\t\t\t     u64 start, u64 len, u64 *freed_ret)\n{\n\tstruct btrfs_root *root = inode->root;\n\tstruct ulist_node *unode;\n\tstruct ulist_iterator uiter;\n\tstruct extent_changeset changeset;\n\tu64 freed = 0;\n\tint ret;\n\n\textent_changeset_init(&changeset);\n\tlen = round_up(start + len, root->fs_info->sectorsize);\n\tstart = round_down(start, root->fs_info->sectorsize);\n\n\tULIST_ITER_INIT(&uiter);\n\twhile ((unode = ulist_next(&reserved->range_changed, &uiter))) {\n\t\tu64 range_start = unode->val;\n\t\t \n\t\tu64 range_len = unode->aux - range_start + 1;\n\t\tu64 free_start;\n\t\tu64 free_len;\n\n\t\textent_changeset_release(&changeset);\n\n\t\t \n\t\tif (range_start >= start + len ||\n\t\t    range_start + range_len <= start)\n\t\t\tcontinue;\n\t\tfree_start = max(range_start, start);\n\t\tfree_len = min(start + len, range_start + range_len) -\n\t\t\t   free_start;\n\t\t \n\t\tret = clear_record_extent_bits(&inode->io_tree, free_start,\n\t\t\t\tfree_start + free_len - 1,\n\t\t\t\tEXTENT_QGROUP_RESERVED, &changeset);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tfreed += changeset.bytes_changed;\n\t}\n\tbtrfs_qgroup_free_refroot(root->fs_info, root->root_key.objectid, freed,\n\t\t\t\t  BTRFS_QGROUP_RSV_DATA);\n\tif (freed_ret)\n\t\t*freed_ret = freed;\n\tret = 0;\nout:\n\textent_changeset_release(&changeset);\n\treturn ret;\n}\n\nstatic int __btrfs_qgroup_release_data(struct btrfs_inode *inode,\n\t\t\tstruct extent_changeset *reserved, u64 start, u64 len,\n\t\t\tu64 *released, int free)\n{\n\tstruct extent_changeset changeset;\n\tint trace_op = QGROUP_RELEASE;\n\tint ret;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &inode->root->fs_info->flags))\n\t\treturn 0;\n\n\t \n\tWARN_ON(!free && reserved);\n\tif (free && reserved)\n\t\treturn qgroup_free_reserved_data(inode, reserved, start, len, released);\n\textent_changeset_init(&changeset);\n\tret = clear_record_extent_bits(&inode->io_tree, start, start + len -1,\n\t\t\t\t       EXTENT_QGROUP_RESERVED, &changeset);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (free)\n\t\ttrace_op = QGROUP_FREE;\n\ttrace_btrfs_qgroup_release_data(&inode->vfs_inode, start, len,\n\t\t\t\t\tchangeset.bytes_changed, trace_op);\n\tif (free)\n\t\tbtrfs_qgroup_free_refroot(inode->root->fs_info,\n\t\t\t\tinode->root->root_key.objectid,\n\t\t\t\tchangeset.bytes_changed, BTRFS_QGROUP_RSV_DATA);\n\tif (released)\n\t\t*released = changeset.bytes_changed;\nout:\n\textent_changeset_release(&changeset);\n\treturn ret;\n}\n\n \nint btrfs_qgroup_free_data(struct btrfs_inode *inode,\n\t\t\t   struct extent_changeset *reserved,\n\t\t\t   u64 start, u64 len, u64 *freed)\n{\n\treturn __btrfs_qgroup_release_data(inode, reserved, start, len, freed, 1);\n}\n\n \nint btrfs_qgroup_release_data(struct btrfs_inode *inode, u64 start, u64 len, u64 *released)\n{\n\treturn __btrfs_qgroup_release_data(inode, NULL, start, len, released, 0);\n}\n\nstatic void add_root_meta_rsv(struct btrfs_root *root, int num_bytes,\n\t\t\t      enum btrfs_qgroup_rsv_type type)\n{\n\tif (type != BTRFS_QGROUP_RSV_META_PREALLOC &&\n\t    type != BTRFS_QGROUP_RSV_META_PERTRANS)\n\t\treturn;\n\tif (num_bytes == 0)\n\t\treturn;\n\n\tspin_lock(&root->qgroup_meta_rsv_lock);\n\tif (type == BTRFS_QGROUP_RSV_META_PREALLOC)\n\t\troot->qgroup_meta_rsv_prealloc += num_bytes;\n\telse\n\t\troot->qgroup_meta_rsv_pertrans += num_bytes;\n\tspin_unlock(&root->qgroup_meta_rsv_lock);\n}\n\nstatic int sub_root_meta_rsv(struct btrfs_root *root, int num_bytes,\n\t\t\t     enum btrfs_qgroup_rsv_type type)\n{\n\tif (type != BTRFS_QGROUP_RSV_META_PREALLOC &&\n\t    type != BTRFS_QGROUP_RSV_META_PERTRANS)\n\t\treturn 0;\n\tif (num_bytes == 0)\n\t\treturn 0;\n\n\tspin_lock(&root->qgroup_meta_rsv_lock);\n\tif (type == BTRFS_QGROUP_RSV_META_PREALLOC) {\n\t\tnum_bytes = min_t(u64, root->qgroup_meta_rsv_prealloc,\n\t\t\t\t  num_bytes);\n\t\troot->qgroup_meta_rsv_prealloc -= num_bytes;\n\t} else {\n\t\tnum_bytes = min_t(u64, root->qgroup_meta_rsv_pertrans,\n\t\t\t\t  num_bytes);\n\t\troot->qgroup_meta_rsv_pertrans -= num_bytes;\n\t}\n\tspin_unlock(&root->qgroup_meta_rsv_lock);\n\treturn num_bytes;\n}\n\nint btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes,\n\t\t\t      enum btrfs_qgroup_rsv_type type, bool enforce)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tint ret;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) ||\n\t    !is_fstree(root->root_key.objectid) || num_bytes == 0)\n\t\treturn 0;\n\n\tBUG_ON(num_bytes != round_down(num_bytes, fs_info->nodesize));\n\ttrace_qgroup_meta_reserve(root, (s64)num_bytes, type);\n\tret = qgroup_reserve(root, num_bytes, enforce, type);\n\tif (ret < 0)\n\t\treturn ret;\n\t \n\tadd_root_meta_rsv(root, num_bytes, type);\n\treturn ret;\n}\n\nint __btrfs_qgroup_reserve_meta(struct btrfs_root *root, int num_bytes,\n\t\t\t\tenum btrfs_qgroup_rsv_type type, bool enforce,\n\t\t\t\tbool noflush)\n{\n\tint ret;\n\n\tret = btrfs_qgroup_reserve_meta(root, num_bytes, type, enforce);\n\tif ((ret <= 0 && ret != -EDQUOT) || noflush)\n\t\treturn ret;\n\n\tret = try_flush_qgroup(root);\n\tif (ret < 0)\n\t\treturn ret;\n\treturn btrfs_qgroup_reserve_meta(root, num_bytes, type, enforce);\n}\n\nvoid btrfs_qgroup_free_meta_all_pertrans(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) ||\n\t    !is_fstree(root->root_key.objectid))\n\t\treturn;\n\n\t \n\ttrace_qgroup_meta_free_all_pertrans(root);\n\t \n\tbtrfs_qgroup_free_refroot(fs_info, root->root_key.objectid, (u64)-1,\n\t\t\t\t  BTRFS_QGROUP_RSV_META_PERTRANS);\n}\n\nvoid __btrfs_qgroup_free_meta(struct btrfs_root *root, int num_bytes,\n\t\t\t      enum btrfs_qgroup_rsv_type type)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) ||\n\t    !is_fstree(root->root_key.objectid))\n\t\treturn;\n\n\t \n\tnum_bytes = sub_root_meta_rsv(root, num_bytes, type);\n\tBUG_ON(num_bytes != round_down(num_bytes, fs_info->nodesize));\n\ttrace_qgroup_meta_reserve(root, -(s64)num_bytes, type);\n\tbtrfs_qgroup_free_refroot(fs_info, root->root_key.objectid,\n\t\t\t\t  num_bytes, type);\n}\n\nstatic void qgroup_convert_meta(struct btrfs_fs_info *fs_info, u64 ref_root,\n\t\t\t\tint num_bytes)\n{\n\tstruct btrfs_qgroup *qgroup;\n\tLIST_HEAD(qgroup_list);\n\n\tif (num_bytes == 0)\n\t\treturn;\n\tif (!fs_info->quota_root)\n\t\treturn;\n\n\tspin_lock(&fs_info->qgroup_lock);\n\tqgroup = find_qgroup_rb(fs_info, ref_root);\n\tif (!qgroup)\n\t\tgoto out;\n\n\tqgroup_iterator_add(&qgroup_list, qgroup);\n\tlist_for_each_entry(qgroup, &qgroup_list, iterator) {\n\t\tstruct btrfs_qgroup_list *glist;\n\n\t\tqgroup_rsv_release(fs_info, qgroup, num_bytes,\n\t\t\t\tBTRFS_QGROUP_RSV_META_PREALLOC);\n\t\tif (!sb_rdonly(fs_info->sb))\n\t\t\tqgroup_rsv_add(fs_info, qgroup, num_bytes,\n\t\t\t\t       BTRFS_QGROUP_RSV_META_PERTRANS);\n\n\t\tlist_for_each_entry(glist, &qgroup->groups, next_group)\n\t\t\tqgroup_iterator_add(&qgroup_list, glist->group);\n\t}\nout:\n\tqgroup_iterator_clean(&qgroup_list);\n\tspin_unlock(&fs_info->qgroup_lock);\n}\n\nvoid btrfs_qgroup_convert_reserved_meta(struct btrfs_root *root, int num_bytes)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) ||\n\t    !is_fstree(root->root_key.objectid))\n\t\treturn;\n\t \n\tnum_bytes = sub_root_meta_rsv(root, num_bytes,\n\t\t\t\t      BTRFS_QGROUP_RSV_META_PREALLOC);\n\ttrace_qgroup_meta_convert(root, num_bytes);\n\tqgroup_convert_meta(fs_info, root->root_key.objectid, num_bytes);\n}\n\n \nvoid btrfs_qgroup_check_reserved_leak(struct btrfs_inode *inode)\n{\n\tstruct extent_changeset changeset;\n\tstruct ulist_node *unode;\n\tstruct ulist_iterator iter;\n\tint ret;\n\n\textent_changeset_init(&changeset);\n\tret = clear_record_extent_bits(&inode->io_tree, 0, (u64)-1,\n\t\t\tEXTENT_QGROUP_RESERVED, &changeset);\n\n\tWARN_ON(ret < 0);\n\tif (WARN_ON(changeset.bytes_changed)) {\n\t\tULIST_ITER_INIT(&iter);\n\t\twhile ((unode = ulist_next(&changeset.range_changed, &iter))) {\n\t\t\tbtrfs_warn(inode->root->fs_info,\n\t\t\"leaking qgroup reserved space, ino: %llu, start: %llu, end: %llu\",\n\t\t\t\tbtrfs_ino(inode), unode->val, unode->aux);\n\t\t}\n\t\tbtrfs_qgroup_free_refroot(inode->root->fs_info,\n\t\t\t\tinode->root->root_key.objectid,\n\t\t\t\tchangeset.bytes_changed, BTRFS_QGROUP_RSV_DATA);\n\n\t}\n\textent_changeset_release(&changeset);\n}\n\nvoid btrfs_qgroup_init_swapped_blocks(\n\tstruct btrfs_qgroup_swapped_blocks *swapped_blocks)\n{\n\tint i;\n\n\tspin_lock_init(&swapped_blocks->lock);\n\tfor (i = 0; i < BTRFS_MAX_LEVEL; i++)\n\t\tswapped_blocks->blocks[i] = RB_ROOT;\n\tswapped_blocks->swapped = false;\n}\n\n \nvoid btrfs_qgroup_clean_swapped_blocks(struct btrfs_root *root)\n{\n\tstruct btrfs_qgroup_swapped_blocks *swapped_blocks;\n\tint i;\n\n\tswapped_blocks = &root->swapped_blocks;\n\n\tspin_lock(&swapped_blocks->lock);\n\tif (!swapped_blocks->swapped)\n\t\tgoto out;\n\tfor (i = 0; i < BTRFS_MAX_LEVEL; i++) {\n\t\tstruct rb_root *cur_root = &swapped_blocks->blocks[i];\n\t\tstruct btrfs_qgroup_swapped_block *entry;\n\t\tstruct btrfs_qgroup_swapped_block *next;\n\n\t\trbtree_postorder_for_each_entry_safe(entry, next, cur_root,\n\t\t\t\t\t\t     node)\n\t\t\tkfree(entry);\n\t\tswapped_blocks->blocks[i] = RB_ROOT;\n\t}\n\tswapped_blocks->swapped = false;\nout:\n\tspin_unlock(&swapped_blocks->lock);\n}\n\n \nint btrfs_qgroup_add_swapped_blocks(struct btrfs_trans_handle *trans,\n\t\tstruct btrfs_root *subvol_root,\n\t\tstruct btrfs_block_group *bg,\n\t\tstruct extent_buffer *subvol_parent, int subvol_slot,\n\t\tstruct extent_buffer *reloc_parent, int reloc_slot,\n\t\tu64 last_snapshot)\n{\n\tstruct btrfs_fs_info *fs_info = subvol_root->fs_info;\n\tstruct btrfs_qgroup_swapped_blocks *blocks = &subvol_root->swapped_blocks;\n\tstruct btrfs_qgroup_swapped_block *block;\n\tstruct rb_node **cur;\n\tstruct rb_node *parent = NULL;\n\tint level = btrfs_header_level(subvol_parent) - 1;\n\tint ret = 0;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\treturn 0;\n\n\tif (btrfs_node_ptr_generation(subvol_parent, subvol_slot) >\n\t    btrfs_node_ptr_generation(reloc_parent, reloc_slot)) {\n\t\tbtrfs_err_rl(fs_info,\n\t\t\"%s: bad parameter order, subvol_gen=%llu reloc_gen=%llu\",\n\t\t\t__func__,\n\t\t\tbtrfs_node_ptr_generation(subvol_parent, subvol_slot),\n\t\t\tbtrfs_node_ptr_generation(reloc_parent, reloc_slot));\n\t\treturn -EUCLEAN;\n\t}\n\n\tblock = kmalloc(sizeof(*block), GFP_NOFS);\n\tif (!block) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t \n\tblock->subvol_bytenr = btrfs_node_blockptr(reloc_parent, reloc_slot);\n\tblock->subvol_generation = btrfs_node_ptr_generation(reloc_parent,\n\t\t\t\t\t\t\t     reloc_slot);\n\tblock->reloc_bytenr = btrfs_node_blockptr(subvol_parent, subvol_slot);\n\tblock->reloc_generation = btrfs_node_ptr_generation(subvol_parent,\n\t\t\t\t\t\t\t    subvol_slot);\n\tblock->last_snapshot = last_snapshot;\n\tblock->level = level;\n\n\t \n\tif (bg && bg->flags & BTRFS_BLOCK_GROUP_DATA)\n\t\tblock->trace_leaf = true;\n\telse\n\t\tblock->trace_leaf = false;\n\tbtrfs_node_key_to_cpu(reloc_parent, &block->first_key, reloc_slot);\n\n\t \n\tspin_lock(&blocks->lock);\n\tcur = &blocks->blocks[level].rb_node;\n\twhile (*cur) {\n\t\tstruct btrfs_qgroup_swapped_block *entry;\n\n\t\tparent = *cur;\n\t\tentry = rb_entry(parent, struct btrfs_qgroup_swapped_block,\n\t\t\t\t node);\n\n\t\tif (entry->subvol_bytenr < block->subvol_bytenr) {\n\t\t\tcur = &(*cur)->rb_left;\n\t\t} else if (entry->subvol_bytenr > block->subvol_bytenr) {\n\t\t\tcur = &(*cur)->rb_right;\n\t\t} else {\n\t\t\tif (entry->subvol_generation !=\n\t\t\t\t\tblock->subvol_generation ||\n\t\t\t    entry->reloc_bytenr != block->reloc_bytenr ||\n\t\t\t    entry->reloc_generation !=\n\t\t\t\t\tblock->reloc_generation) {\n\t\t\t\t \n\t\t\t\tWARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));\n\t\t\t\tret = -EEXIST;\n\t\t\t}\n\t\t\tkfree(block);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\trb_link_node(&block->node, parent, cur);\n\trb_insert_color(&block->node, &blocks->blocks[level]);\n\tblocks->swapped = true;\nout_unlock:\n\tspin_unlock(&blocks->lock);\nout:\n\tif (ret < 0)\n\t\tqgroup_mark_inconsistent(fs_info);\n\treturn ret;\n}\n\n \nint btrfs_qgroup_trace_subtree_after_cow(struct btrfs_trans_handle *trans,\n\t\t\t\t\t struct btrfs_root *root,\n\t\t\t\t\t struct extent_buffer *subvol_eb)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_tree_parent_check check = { 0 };\n\tstruct btrfs_qgroup_swapped_blocks *blocks = &root->swapped_blocks;\n\tstruct btrfs_qgroup_swapped_block *block;\n\tstruct extent_buffer *reloc_eb = NULL;\n\tstruct rb_node *node;\n\tbool found = false;\n\tbool swapped = false;\n\tint level = btrfs_header_level(subvol_eb);\n\tint ret = 0;\n\tint i;\n\n\tif (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))\n\t\treturn 0;\n\tif (!is_fstree(root->root_key.objectid) || !root->reloc_root)\n\t\treturn 0;\n\n\tspin_lock(&blocks->lock);\n\tif (!blocks->swapped) {\n\t\tspin_unlock(&blocks->lock);\n\t\treturn 0;\n\t}\n\tnode = blocks->blocks[level].rb_node;\n\n\twhile (node) {\n\t\tblock = rb_entry(node, struct btrfs_qgroup_swapped_block, node);\n\t\tif (block->subvol_bytenr < subvol_eb->start) {\n\t\t\tnode = node->rb_left;\n\t\t} else if (block->subvol_bytenr > subvol_eb->start) {\n\t\t\tnode = node->rb_right;\n\t\t} else {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!found) {\n\t\tspin_unlock(&blocks->lock);\n\t\tgoto out;\n\t}\n\t \n\trb_erase(&block->node, &blocks->blocks[level]);\n\tfor (i = 0; i < BTRFS_MAX_LEVEL; i++) {\n\t\tif (RB_EMPTY_ROOT(&blocks->blocks[i])) {\n\t\t\tswapped = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tblocks->swapped = swapped;\n\tspin_unlock(&blocks->lock);\n\n\tcheck.level = block->level;\n\tcheck.transid = block->reloc_generation;\n\tcheck.has_first_key = true;\n\tmemcpy(&check.first_key, &block->first_key, sizeof(check.first_key));\n\n\t \n\treloc_eb = read_tree_block(fs_info, block->reloc_bytenr, &check);\n\tif (IS_ERR(reloc_eb)) {\n\t\tret = PTR_ERR(reloc_eb);\n\t\treloc_eb = NULL;\n\t\tgoto free_out;\n\t}\n\tif (!extent_buffer_uptodate(reloc_eb)) {\n\t\tret = -EIO;\n\t\tgoto free_out;\n\t}\n\n\tret = qgroup_trace_subtree_swap(trans, reloc_eb, subvol_eb,\n\t\t\tblock->last_snapshot, block->trace_leaf);\nfree_out:\n\tkfree(block);\n\tfree_extent_buffer(reloc_eb);\nout:\n\tif (ret < 0) {\n\t\tbtrfs_err_rl(fs_info,\n\t\t\t     \"failed to account subtree at bytenr %llu: %d\",\n\t\t\t     subvol_eb->start, ret);\n\t\tqgroup_mark_inconsistent(fs_info);\n\t}\n\treturn ret;\n}\n\nvoid btrfs_qgroup_destroy_extent_records(struct btrfs_transaction *trans)\n{\n\tstruct btrfs_qgroup_extent_record *entry;\n\tstruct btrfs_qgroup_extent_record *next;\n\tstruct rb_root *root;\n\n\troot = &trans->delayed_refs.dirty_extent_root;\n\trbtree_postorder_for_each_entry_safe(entry, next, root, node) {\n\t\tulist_free(entry->old_roots);\n\t\tkfree(entry);\n\t}\n\t*root = RB_ROOT;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}