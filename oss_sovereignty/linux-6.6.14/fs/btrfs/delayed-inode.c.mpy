{
  "module_name": "delayed-inode.c",
  "hash_id": "fc23702967235c0ff456cd421f6c5636188f793a73d154ed3c146262ca40767f",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/delayed-inode.c",
  "human_readable_source": "\n \n\n#include <linux/slab.h>\n#include <linux/iversion.h>\n#include \"ctree.h\"\n#include \"fs.h\"\n#include \"messages.h\"\n#include \"misc.h\"\n#include \"delayed-inode.h\"\n#include \"disk-io.h\"\n#include \"transaction.h\"\n#include \"qgroup.h\"\n#include \"locking.h\"\n#include \"inode-item.h\"\n#include \"space-info.h\"\n#include \"accessors.h\"\n#include \"file-item.h\"\n\n#define BTRFS_DELAYED_WRITEBACK\t\t512\n#define BTRFS_DELAYED_BACKGROUND\t128\n#define BTRFS_DELAYED_BATCH\t\t16\n\nstatic struct kmem_cache *delayed_node_cache;\n\nint __init btrfs_delayed_inode_init(void)\n{\n\tdelayed_node_cache = kmem_cache_create(\"btrfs_delayed_node\",\n\t\t\t\t\tsizeof(struct btrfs_delayed_node),\n\t\t\t\t\t0,\n\t\t\t\t\tSLAB_MEM_SPREAD,\n\t\t\t\t\tNULL);\n\tif (!delayed_node_cache)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid __cold btrfs_delayed_inode_exit(void)\n{\n\tkmem_cache_destroy(delayed_node_cache);\n}\n\nstatic inline void btrfs_init_delayed_node(\n\t\t\t\tstruct btrfs_delayed_node *delayed_node,\n\t\t\t\tstruct btrfs_root *root, u64 inode_id)\n{\n\tdelayed_node->root = root;\n\tdelayed_node->inode_id = inode_id;\n\trefcount_set(&delayed_node->refs, 0);\n\tdelayed_node->ins_root = RB_ROOT_CACHED;\n\tdelayed_node->del_root = RB_ROOT_CACHED;\n\tmutex_init(&delayed_node->mutex);\n\tINIT_LIST_HEAD(&delayed_node->n_list);\n\tINIT_LIST_HEAD(&delayed_node->p_list);\n}\n\nstatic struct btrfs_delayed_node *btrfs_get_delayed_node(\n\t\tstruct btrfs_inode *btrfs_inode)\n{\n\tstruct btrfs_root *root = btrfs_inode->root;\n\tu64 ino = btrfs_ino(btrfs_inode);\n\tstruct btrfs_delayed_node *node;\n\n\tnode = READ_ONCE(btrfs_inode->delayed_node);\n\tif (node) {\n\t\trefcount_inc(&node->refs);\n\t\treturn node;\n\t}\n\n\tspin_lock(&root->inode_lock);\n\tnode = radix_tree_lookup(&root->delayed_nodes_tree, ino);\n\n\tif (node) {\n\t\tif (btrfs_inode->delayed_node) {\n\t\t\trefcount_inc(&node->refs);\t \n\t\t\tBUG_ON(btrfs_inode->delayed_node != node);\n\t\t\tspin_unlock(&root->inode_lock);\n\t\t\treturn node;\n\t\t}\n\n\t\t \n\t\tif (refcount_inc_not_zero(&node->refs)) {\n\t\t\trefcount_inc(&node->refs);\n\t\t\tbtrfs_inode->delayed_node = node;\n\t\t} else {\n\t\t\tnode = NULL;\n\t\t}\n\n\t\tspin_unlock(&root->inode_lock);\n\t\treturn node;\n\t}\n\tspin_unlock(&root->inode_lock);\n\n\treturn NULL;\n}\n\n \nstatic struct btrfs_delayed_node *btrfs_get_or_create_delayed_node(\n\t\tstruct btrfs_inode *btrfs_inode)\n{\n\tstruct btrfs_delayed_node *node;\n\tstruct btrfs_root *root = btrfs_inode->root;\n\tu64 ino = btrfs_ino(btrfs_inode);\n\tint ret;\n\nagain:\n\tnode = btrfs_get_delayed_node(btrfs_inode);\n\tif (node)\n\t\treturn node;\n\n\tnode = kmem_cache_zalloc(delayed_node_cache, GFP_NOFS);\n\tif (!node)\n\t\treturn ERR_PTR(-ENOMEM);\n\tbtrfs_init_delayed_node(node, root, ino);\n\n\t \n\trefcount_set(&node->refs, 2);\n\n\tret = radix_tree_preload(GFP_NOFS);\n\tif (ret) {\n\t\tkmem_cache_free(delayed_node_cache, node);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tspin_lock(&root->inode_lock);\n\tret = radix_tree_insert(&root->delayed_nodes_tree, ino, node);\n\tif (ret == -EEXIST) {\n\t\tspin_unlock(&root->inode_lock);\n\t\tkmem_cache_free(delayed_node_cache, node);\n\t\tradix_tree_preload_end();\n\t\tgoto again;\n\t}\n\tbtrfs_inode->delayed_node = node;\n\tspin_unlock(&root->inode_lock);\n\tradix_tree_preload_end();\n\n\treturn node;\n}\n\n \nstatic void btrfs_queue_delayed_node(struct btrfs_delayed_root *root,\n\t\t\t\t     struct btrfs_delayed_node *node,\n\t\t\t\t     int mod)\n{\n\tspin_lock(&root->lock);\n\tif (test_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags)) {\n\t\tif (!list_empty(&node->p_list))\n\t\t\tlist_move_tail(&node->p_list, &root->prepare_list);\n\t\telse if (mod)\n\t\t\tlist_add_tail(&node->p_list, &root->prepare_list);\n\t} else {\n\t\tlist_add_tail(&node->n_list, &root->node_list);\n\t\tlist_add_tail(&node->p_list, &root->prepare_list);\n\t\trefcount_inc(&node->refs);\t \n\t\troot->nodes++;\n\t\tset_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags);\n\t}\n\tspin_unlock(&root->lock);\n}\n\n \nstatic void btrfs_dequeue_delayed_node(struct btrfs_delayed_root *root,\n\t\t\t\t       struct btrfs_delayed_node *node)\n{\n\tspin_lock(&root->lock);\n\tif (test_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags)) {\n\t\troot->nodes--;\n\t\trefcount_dec(&node->refs);\t \n\t\tlist_del_init(&node->n_list);\n\t\tif (!list_empty(&node->p_list))\n\t\t\tlist_del_init(&node->p_list);\n\t\tclear_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags);\n\t}\n\tspin_unlock(&root->lock);\n}\n\nstatic struct btrfs_delayed_node *btrfs_first_delayed_node(\n\t\t\tstruct btrfs_delayed_root *delayed_root)\n{\n\tstruct list_head *p;\n\tstruct btrfs_delayed_node *node = NULL;\n\n\tspin_lock(&delayed_root->lock);\n\tif (list_empty(&delayed_root->node_list))\n\t\tgoto out;\n\n\tp = delayed_root->node_list.next;\n\tnode = list_entry(p, struct btrfs_delayed_node, n_list);\n\trefcount_inc(&node->refs);\nout:\n\tspin_unlock(&delayed_root->lock);\n\n\treturn node;\n}\n\nstatic struct btrfs_delayed_node *btrfs_next_delayed_node(\n\t\t\t\t\t\tstruct btrfs_delayed_node *node)\n{\n\tstruct btrfs_delayed_root *delayed_root;\n\tstruct list_head *p;\n\tstruct btrfs_delayed_node *next = NULL;\n\n\tdelayed_root = node->root->fs_info->delayed_root;\n\tspin_lock(&delayed_root->lock);\n\tif (!test_bit(BTRFS_DELAYED_NODE_IN_LIST, &node->flags)) {\n\t\t \n\t\tif (list_empty(&delayed_root->node_list))\n\t\t\tgoto out;\n\t\tp = delayed_root->node_list.next;\n\t} else if (list_is_last(&node->n_list, &delayed_root->node_list))\n\t\tgoto out;\n\telse\n\t\tp = node->n_list.next;\n\n\tnext = list_entry(p, struct btrfs_delayed_node, n_list);\n\trefcount_inc(&next->refs);\nout:\n\tspin_unlock(&delayed_root->lock);\n\n\treturn next;\n}\n\nstatic void __btrfs_release_delayed_node(\n\t\t\t\tstruct btrfs_delayed_node *delayed_node,\n\t\t\t\tint mod)\n{\n\tstruct btrfs_delayed_root *delayed_root;\n\n\tif (!delayed_node)\n\t\treturn;\n\n\tdelayed_root = delayed_node->root->fs_info->delayed_root;\n\n\tmutex_lock(&delayed_node->mutex);\n\tif (delayed_node->count)\n\t\tbtrfs_queue_delayed_node(delayed_root, delayed_node, mod);\n\telse\n\t\tbtrfs_dequeue_delayed_node(delayed_root, delayed_node);\n\tmutex_unlock(&delayed_node->mutex);\n\n\tif (refcount_dec_and_test(&delayed_node->refs)) {\n\t\tstruct btrfs_root *root = delayed_node->root;\n\n\t\tspin_lock(&root->inode_lock);\n\t\t \n\t\tASSERT(refcount_read(&delayed_node->refs) == 0);\n\t\tradix_tree_delete(&root->delayed_nodes_tree,\n\t\t\t\t  delayed_node->inode_id);\n\t\tspin_unlock(&root->inode_lock);\n\t\tkmem_cache_free(delayed_node_cache, delayed_node);\n\t}\n}\n\nstatic inline void btrfs_release_delayed_node(struct btrfs_delayed_node *node)\n{\n\t__btrfs_release_delayed_node(node, 0);\n}\n\nstatic struct btrfs_delayed_node *btrfs_first_prepared_delayed_node(\n\t\t\t\t\tstruct btrfs_delayed_root *delayed_root)\n{\n\tstruct list_head *p;\n\tstruct btrfs_delayed_node *node = NULL;\n\n\tspin_lock(&delayed_root->lock);\n\tif (list_empty(&delayed_root->prepare_list))\n\t\tgoto out;\n\n\tp = delayed_root->prepare_list.next;\n\tlist_del_init(p);\n\tnode = list_entry(p, struct btrfs_delayed_node, p_list);\n\trefcount_inc(&node->refs);\nout:\n\tspin_unlock(&delayed_root->lock);\n\n\treturn node;\n}\n\nstatic inline void btrfs_release_prepared_delayed_node(\n\t\t\t\t\tstruct btrfs_delayed_node *node)\n{\n\t__btrfs_release_delayed_node(node, 1);\n}\n\nstatic struct btrfs_delayed_item *btrfs_alloc_delayed_item(u16 data_len,\n\t\t\t\t\t   struct btrfs_delayed_node *node,\n\t\t\t\t\t   enum btrfs_delayed_item_type type)\n{\n\tstruct btrfs_delayed_item *item;\n\n\titem = kmalloc(struct_size(item, data, data_len), GFP_NOFS);\n\tif (item) {\n\t\titem->data_len = data_len;\n\t\titem->type = type;\n\t\titem->bytes_reserved = 0;\n\t\titem->delayed_node = node;\n\t\tRB_CLEAR_NODE(&item->rb_node);\n\t\tINIT_LIST_HEAD(&item->log_list);\n\t\titem->logged = false;\n\t\trefcount_set(&item->refs, 1);\n\t}\n\treturn item;\n}\n\n \nstatic struct btrfs_delayed_item *__btrfs_lookup_delayed_item(\n\t\t\t\tstruct rb_root *root,\n\t\t\t\tu64 index)\n{\n\tstruct rb_node *node = root->rb_node;\n\tstruct btrfs_delayed_item *delayed_item = NULL;\n\n\twhile (node) {\n\t\tdelayed_item = rb_entry(node, struct btrfs_delayed_item,\n\t\t\t\t\trb_node);\n\t\tif (delayed_item->index < index)\n\t\t\tnode = node->rb_right;\n\t\telse if (delayed_item->index > index)\n\t\t\tnode = node->rb_left;\n\t\telse\n\t\t\treturn delayed_item;\n\t}\n\n\treturn NULL;\n}\n\nstatic int __btrfs_add_delayed_item(struct btrfs_delayed_node *delayed_node,\n\t\t\t\t    struct btrfs_delayed_item *ins)\n{\n\tstruct rb_node **p, *node;\n\tstruct rb_node *parent_node = NULL;\n\tstruct rb_root_cached *root;\n\tstruct btrfs_delayed_item *item;\n\tbool leftmost = true;\n\n\tif (ins->type == BTRFS_DELAYED_INSERTION_ITEM)\n\t\troot = &delayed_node->ins_root;\n\telse\n\t\troot = &delayed_node->del_root;\n\n\tp = &root->rb_root.rb_node;\n\tnode = &ins->rb_node;\n\n\twhile (*p) {\n\t\tparent_node = *p;\n\t\titem = rb_entry(parent_node, struct btrfs_delayed_item,\n\t\t\t\t rb_node);\n\n\t\tif (item->index < ins->index) {\n\t\t\tp = &(*p)->rb_right;\n\t\t\tleftmost = false;\n\t\t} else if (item->index > ins->index) {\n\t\t\tp = &(*p)->rb_left;\n\t\t} else {\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\trb_link_node(node, parent_node, p);\n\trb_insert_color_cached(node, root, leftmost);\n\n\tif (ins->type == BTRFS_DELAYED_INSERTION_ITEM &&\n\t    ins->index >= delayed_node->index_cnt)\n\t\tdelayed_node->index_cnt = ins->index + 1;\n\n\tdelayed_node->count++;\n\tatomic_inc(&delayed_node->root->fs_info->delayed_root->items);\n\treturn 0;\n}\n\nstatic void finish_one_item(struct btrfs_delayed_root *delayed_root)\n{\n\tint seq = atomic_inc_return(&delayed_root->items_seq);\n\n\t \n\tif ((atomic_dec_return(&delayed_root->items) <\n\t    BTRFS_DELAYED_BACKGROUND || seq % BTRFS_DELAYED_BATCH == 0))\n\t\tcond_wake_up_nomb(&delayed_root->wait);\n}\n\nstatic void __btrfs_remove_delayed_item(struct btrfs_delayed_item *delayed_item)\n{\n\tstruct btrfs_delayed_node *delayed_node = delayed_item->delayed_node;\n\tstruct rb_root_cached *root;\n\tstruct btrfs_delayed_root *delayed_root;\n\n\t \n\tif (RB_EMPTY_NODE(&delayed_item->rb_node))\n\t\treturn;\n\n\t \n\tlockdep_assert_held(&delayed_node->mutex);\n\n\tdelayed_root = delayed_node->root->fs_info->delayed_root;\n\n\tBUG_ON(!delayed_root);\n\n\tif (delayed_item->type == BTRFS_DELAYED_INSERTION_ITEM)\n\t\troot = &delayed_node->ins_root;\n\telse\n\t\troot = &delayed_node->del_root;\n\n\trb_erase_cached(&delayed_item->rb_node, root);\n\tRB_CLEAR_NODE(&delayed_item->rb_node);\n\tdelayed_node->count--;\n\n\tfinish_one_item(delayed_root);\n}\n\nstatic void btrfs_release_delayed_item(struct btrfs_delayed_item *item)\n{\n\tif (item) {\n\t\t__btrfs_remove_delayed_item(item);\n\t\tif (refcount_dec_and_test(&item->refs))\n\t\t\tkfree(item);\n\t}\n}\n\nstatic struct btrfs_delayed_item *__btrfs_first_delayed_insertion_item(\n\t\t\t\t\tstruct btrfs_delayed_node *delayed_node)\n{\n\tstruct rb_node *p;\n\tstruct btrfs_delayed_item *item = NULL;\n\n\tp = rb_first_cached(&delayed_node->ins_root);\n\tif (p)\n\t\titem = rb_entry(p, struct btrfs_delayed_item, rb_node);\n\n\treturn item;\n}\n\nstatic struct btrfs_delayed_item *__btrfs_first_delayed_deletion_item(\n\t\t\t\t\tstruct btrfs_delayed_node *delayed_node)\n{\n\tstruct rb_node *p;\n\tstruct btrfs_delayed_item *item = NULL;\n\n\tp = rb_first_cached(&delayed_node->del_root);\n\tif (p)\n\t\titem = rb_entry(p, struct btrfs_delayed_item, rb_node);\n\n\treturn item;\n}\n\nstatic struct btrfs_delayed_item *__btrfs_next_delayed_item(\n\t\t\t\t\t\tstruct btrfs_delayed_item *item)\n{\n\tstruct rb_node *p;\n\tstruct btrfs_delayed_item *next = NULL;\n\n\tp = rb_next(&item->rb_node);\n\tif (p)\n\t\tnext = rb_entry(p, struct btrfs_delayed_item, rb_node);\n\n\treturn next;\n}\n\nstatic int btrfs_delayed_item_reserve_metadata(struct btrfs_trans_handle *trans,\n\t\t\t\t\t       struct btrfs_delayed_item *item)\n{\n\tstruct btrfs_block_rsv *src_rsv;\n\tstruct btrfs_block_rsv *dst_rsv;\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tu64 num_bytes;\n\tint ret;\n\n\tif (!trans->bytes_reserved)\n\t\treturn 0;\n\n\tsrc_rsv = trans->block_rsv;\n\tdst_rsv = &fs_info->delayed_block_rsv;\n\n\tnum_bytes = btrfs_calc_insert_metadata_size(fs_info, 1);\n\n\t \n\tret = btrfs_block_rsv_migrate(src_rsv, dst_rsv, num_bytes, true);\n\tif (!ret) {\n\t\ttrace_btrfs_space_reservation(fs_info, \"delayed_item\",\n\t\t\t\t\t      item->delayed_node->inode_id,\n\t\t\t\t\t      num_bytes, 1);\n\t\t \n\t\tif (item->type == BTRFS_DELAYED_DELETION_ITEM)\n\t\t\titem->bytes_reserved = num_bytes;\n\t}\n\n\treturn ret;\n}\n\nstatic void btrfs_delayed_item_release_metadata(struct btrfs_root *root,\n\t\t\t\t\t\tstruct btrfs_delayed_item *item)\n{\n\tstruct btrfs_block_rsv *rsv;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\n\tif (!item->bytes_reserved)\n\t\treturn;\n\n\trsv = &fs_info->delayed_block_rsv;\n\t \n\ttrace_btrfs_space_reservation(fs_info, \"delayed_item\",\n\t\t\t\t      item->delayed_node->inode_id,\n\t\t\t\t      item->bytes_reserved, 0);\n\tbtrfs_block_rsv_release(fs_info, rsv, item->bytes_reserved, NULL);\n}\n\nstatic void btrfs_delayed_item_release_leaves(struct btrfs_delayed_node *node,\n\t\t\t\t\t      unsigned int num_leaves)\n{\n\tstruct btrfs_fs_info *fs_info = node->root->fs_info;\n\tconst u64 bytes = btrfs_calc_insert_metadata_size(fs_info, num_leaves);\n\n\t \n\tif (test_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags))\n\t\treturn;\n\n\ttrace_btrfs_space_reservation(fs_info, \"delayed_item\", node->inode_id,\n\t\t\t\t      bytes, 0);\n\tbtrfs_block_rsv_release(fs_info, &fs_info->delayed_block_rsv, bytes, NULL);\n}\n\nstatic int btrfs_delayed_inode_reserve_metadata(\n\t\t\t\t\tstruct btrfs_trans_handle *trans,\n\t\t\t\t\tstruct btrfs_root *root,\n\t\t\t\t\tstruct btrfs_delayed_node *node)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_block_rsv *src_rsv;\n\tstruct btrfs_block_rsv *dst_rsv;\n\tu64 num_bytes;\n\tint ret;\n\n\tsrc_rsv = trans->block_rsv;\n\tdst_rsv = &fs_info->delayed_block_rsv;\n\n\tnum_bytes = btrfs_calc_metadata_size(fs_info, 1);\n\n\t \n\tif (!src_rsv || (!trans->bytes_reserved &&\n\t\t\t src_rsv->type != BTRFS_BLOCK_RSV_DELALLOC)) {\n\t\tret = btrfs_qgroup_reserve_meta(root, num_bytes,\n\t\t\t\t\t  BTRFS_QGROUP_RSV_META_PREALLOC, true);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = btrfs_block_rsv_add(fs_info, dst_rsv, num_bytes,\n\t\t\t\t\t  BTRFS_RESERVE_NO_FLUSH);\n\t\t \n\t\tASSERT(ret == 0 || ret == -ENOSPC);\n\t\tif (ret)\n\t\t\tbtrfs_qgroup_free_meta_prealloc(root, num_bytes);\n\t} else {\n\t\tret = btrfs_block_rsv_migrate(src_rsv, dst_rsv, num_bytes, true);\n\t}\n\n\tif (!ret) {\n\t\ttrace_btrfs_space_reservation(fs_info, \"delayed_inode\",\n\t\t\t\t\t      node->inode_id, num_bytes, 1);\n\t\tnode->bytes_reserved = num_bytes;\n\t}\n\n\treturn ret;\n}\n\nstatic void btrfs_delayed_inode_release_metadata(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t\tstruct btrfs_delayed_node *node,\n\t\t\t\t\t\tbool qgroup_free)\n{\n\tstruct btrfs_block_rsv *rsv;\n\n\tif (!node->bytes_reserved)\n\t\treturn;\n\n\trsv = &fs_info->delayed_block_rsv;\n\ttrace_btrfs_space_reservation(fs_info, \"delayed_inode\",\n\t\t\t\t      node->inode_id, node->bytes_reserved, 0);\n\tbtrfs_block_rsv_release(fs_info, rsv, node->bytes_reserved, NULL);\n\tif (qgroup_free)\n\t\tbtrfs_qgroup_free_meta_prealloc(node->root,\n\t\t\t\tnode->bytes_reserved);\n\telse\n\t\tbtrfs_qgroup_convert_reserved_meta(node->root,\n\t\t\t\tnode->bytes_reserved);\n\tnode->bytes_reserved = 0;\n}\n\n \nstatic int btrfs_insert_delayed_item(struct btrfs_trans_handle *trans,\n\t\t\t\t     struct btrfs_root *root,\n\t\t\t\t     struct btrfs_path *path,\n\t\t\t\t     struct btrfs_delayed_item *first_item)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_delayed_node *node = first_item->delayed_node;\n\tLIST_HEAD(item_list);\n\tstruct btrfs_delayed_item *curr;\n\tstruct btrfs_delayed_item *next;\n\tconst int max_size = BTRFS_LEAF_DATA_SIZE(fs_info);\n\tstruct btrfs_item_batch batch;\n\tstruct btrfs_key first_key;\n\tconst u32 first_data_size = first_item->data_len;\n\tint total_size;\n\tchar *ins_data = NULL;\n\tint ret;\n\tbool continuous_keys_only = false;\n\n\tlockdep_assert_held(&node->mutex);\n\n\t \n\tif (test_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags))\n\t\tcontinuous_keys_only = true;\n\n\t \n\tASSERT(first_item->bytes_reserved == 0);\n\n\tlist_add_tail(&first_item->tree_list, &item_list);\n\tbatch.total_data_size = first_data_size;\n\tbatch.nr = 1;\n\ttotal_size = first_data_size + sizeof(struct btrfs_item);\n\tcurr = first_item;\n\n\twhile (true) {\n\t\tint next_size;\n\n\t\tnext = __btrfs_next_delayed_item(curr);\n\t\tif (!next)\n\t\t\tbreak;\n\n\t\t \n\t\tif (continuous_keys_only && (next->index != curr->index + 1))\n\t\t\tbreak;\n\n\t\tASSERT(next->bytes_reserved == 0);\n\n\t\tnext_size = next->data_len + sizeof(struct btrfs_item);\n\t\tif (total_size + next_size > max_size)\n\t\t\tbreak;\n\n\t\tlist_add_tail(&next->tree_list, &item_list);\n\t\tbatch.nr++;\n\t\ttotal_size += next_size;\n\t\tbatch.total_data_size += next->data_len;\n\t\tcurr = next;\n\t}\n\n\tif (batch.nr == 1) {\n\t\tfirst_key.objectid = node->inode_id;\n\t\tfirst_key.type = BTRFS_DIR_INDEX_KEY;\n\t\tfirst_key.offset = first_item->index;\n\t\tbatch.keys = &first_key;\n\t\tbatch.data_sizes = &first_data_size;\n\t} else {\n\t\tstruct btrfs_key *ins_keys;\n\t\tu32 *ins_sizes;\n\t\tint i = 0;\n\n\t\tins_data = kmalloc(batch.nr * sizeof(u32) +\n\t\t\t\t   batch.nr * sizeof(struct btrfs_key), GFP_NOFS);\n\t\tif (!ins_data) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tins_sizes = (u32 *)ins_data;\n\t\tins_keys = (struct btrfs_key *)(ins_data + batch.nr * sizeof(u32));\n\t\tbatch.keys = ins_keys;\n\t\tbatch.data_sizes = ins_sizes;\n\t\tlist_for_each_entry(curr, &item_list, tree_list) {\n\t\t\tins_keys[i].objectid = node->inode_id;\n\t\t\tins_keys[i].type = BTRFS_DIR_INDEX_KEY;\n\t\t\tins_keys[i].offset = curr->index;\n\t\t\tins_sizes[i] = curr->data_len;\n\t\t\ti++;\n\t\t}\n\t}\n\n\tret = btrfs_insert_empty_items(trans, root, path, &batch);\n\tif (ret)\n\t\tgoto out;\n\n\tlist_for_each_entry(curr, &item_list, tree_list) {\n\t\tchar *data_ptr;\n\n\t\tdata_ptr = btrfs_item_ptr(path->nodes[0], path->slots[0], char);\n\t\twrite_extent_buffer(path->nodes[0], &curr->data,\n\t\t\t\t    (unsigned long)data_ptr, curr->data_len);\n\t\tpath->slots[0]++;\n\t}\n\n\t \n\tbtrfs_release_path(path);\n\n\tASSERT(node->index_item_leaves > 0);\n\n\t \n\tif (next && !continuous_keys_only) {\n\t\t \n\t\tbtrfs_delayed_item_release_leaves(node, 1);\n\t\tnode->index_item_leaves--;\n\t} else if (!next) {\n\t\t \n\t\tbtrfs_delayed_item_release_leaves(node, node->index_item_leaves);\n\t\tnode->index_item_leaves = 0;\n\t}\n\n\tlist_for_each_entry_safe(curr, next, &item_list, tree_list) {\n\t\tlist_del(&curr->tree_list);\n\t\tbtrfs_release_delayed_item(curr);\n\t}\nout:\n\tkfree(ins_data);\n\treturn ret;\n}\n\nstatic int btrfs_insert_delayed_items(struct btrfs_trans_handle *trans,\n\t\t\t\t      struct btrfs_path *path,\n\t\t\t\t      struct btrfs_root *root,\n\t\t\t\t      struct btrfs_delayed_node *node)\n{\n\tint ret = 0;\n\n\twhile (ret == 0) {\n\t\tstruct btrfs_delayed_item *curr;\n\n\t\tmutex_lock(&node->mutex);\n\t\tcurr = __btrfs_first_delayed_insertion_item(node);\n\t\tif (!curr) {\n\t\t\tmutex_unlock(&node->mutex);\n\t\t\tbreak;\n\t\t}\n\t\tret = btrfs_insert_delayed_item(trans, root, path, curr);\n\t\tmutex_unlock(&node->mutex);\n\t}\n\n\treturn ret;\n}\n\nstatic int btrfs_batch_delete_items(struct btrfs_trans_handle *trans,\n\t\t\t\t    struct btrfs_root *root,\n\t\t\t\t    struct btrfs_path *path,\n\t\t\t\t    struct btrfs_delayed_item *item)\n{\n\tconst u64 ino = item->delayed_node->inode_id;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_delayed_item *curr, *next;\n\tstruct extent_buffer *leaf = path->nodes[0];\n\tLIST_HEAD(batch_list);\n\tint nitems, slot, last_slot;\n\tint ret;\n\tu64 total_reserved_size = item->bytes_reserved;\n\n\tASSERT(leaf != NULL);\n\n\tslot = path->slots[0];\n\tlast_slot = btrfs_header_nritems(leaf) - 1;\n\t \n\tASSERT(slot <= last_slot);\n\tif (WARN_ON(slot > last_slot))\n\t\treturn -ENOENT;\n\n\tnitems = 1;\n\tcurr = item;\n\tlist_add_tail(&curr->tree_list, &batch_list);\n\n\t \n\twhile (slot < last_slot) {\n\t\tstruct btrfs_key key;\n\n\t\tnext = __btrfs_next_delayed_item(curr);\n\t\tif (!next)\n\t\t\tbreak;\n\n\t\tslot++;\n\t\tbtrfs_item_key_to_cpu(leaf, &key, slot);\n\t\tif (key.objectid != ino ||\n\t\t    key.type != BTRFS_DIR_INDEX_KEY ||\n\t\t    key.offset != next->index)\n\t\t\tbreak;\n\t\tnitems++;\n\t\tcurr = next;\n\t\tlist_add_tail(&curr->tree_list, &batch_list);\n\t\ttotal_reserved_size += curr->bytes_reserved;\n\t}\n\n\tret = btrfs_del_items(trans, root, path, path->slots[0], nitems);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (total_reserved_size > 0) {\n\t\t \n\t\ttrace_btrfs_space_reservation(fs_info, \"delayed_item\", ino,\n\t\t\t\t\t      total_reserved_size, 0);\n\t\tbtrfs_block_rsv_release(fs_info, &fs_info->delayed_block_rsv,\n\t\t\t\t\ttotal_reserved_size, NULL);\n\t}\n\n\tlist_for_each_entry_safe(curr, next, &batch_list, tree_list) {\n\t\tlist_del(&curr->tree_list);\n\t\tbtrfs_release_delayed_item(curr);\n\t}\n\n\treturn 0;\n}\n\nstatic int btrfs_delete_delayed_items(struct btrfs_trans_handle *trans,\n\t\t\t\t      struct btrfs_path *path,\n\t\t\t\t      struct btrfs_root *root,\n\t\t\t\t      struct btrfs_delayed_node *node)\n{\n\tstruct btrfs_key key;\n\tint ret = 0;\n\n\tkey.objectid = node->inode_id;\n\tkey.type = BTRFS_DIR_INDEX_KEY;\n\n\twhile (ret == 0) {\n\t\tstruct btrfs_delayed_item *item;\n\n\t\tmutex_lock(&node->mutex);\n\t\titem = __btrfs_first_delayed_deletion_item(node);\n\t\tif (!item) {\n\t\t\tmutex_unlock(&node->mutex);\n\t\t\tbreak;\n\t\t}\n\n\t\tkey.offset = item->index;\n\t\tret = btrfs_search_slot(trans, root, &key, path, -1, 1);\n\t\tif (ret > 0) {\n\t\t\t \n\t\t\tbtrfs_release_path(path);\n\t\t\tbtrfs_release_delayed_item(item);\n\t\t\tret = 0;\n\t\t} else if (ret == 0) {\n\t\t\tret = btrfs_batch_delete_items(trans, root, path, item);\n\t\t\tbtrfs_release_path(path);\n\t\t}\n\n\t\t \n\t\tmutex_unlock(&node->mutex);\n\t}\n\n\treturn ret;\n}\n\nstatic void btrfs_release_delayed_inode(struct btrfs_delayed_node *delayed_node)\n{\n\tstruct btrfs_delayed_root *delayed_root;\n\n\tif (delayed_node &&\n\t    test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\n\t\tBUG_ON(!delayed_node->root);\n\t\tclear_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags);\n\t\tdelayed_node->count--;\n\n\t\tdelayed_root = delayed_node->root->fs_info->delayed_root;\n\t\tfinish_one_item(delayed_root);\n\t}\n}\n\nstatic void btrfs_release_delayed_iref(struct btrfs_delayed_node *delayed_node)\n{\n\n\tif (test_and_clear_bit(BTRFS_DELAYED_NODE_DEL_IREF, &delayed_node->flags)) {\n\t\tstruct btrfs_delayed_root *delayed_root;\n\n\t\tASSERT(delayed_node->root);\n\t\tdelayed_node->count--;\n\n\t\tdelayed_root = delayed_node->root->fs_info->delayed_root;\n\t\tfinish_one_item(delayed_root);\n\t}\n}\n\nstatic int __btrfs_update_delayed_inode(struct btrfs_trans_handle *trans,\n\t\t\t\t\tstruct btrfs_root *root,\n\t\t\t\t\tstruct btrfs_path *path,\n\t\t\t\t\tstruct btrfs_delayed_node *node)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_key key;\n\tstruct btrfs_inode_item *inode_item;\n\tstruct extent_buffer *leaf;\n\tint mod;\n\tint ret;\n\n\tkey.objectid = node->inode_id;\n\tkey.type = BTRFS_INODE_ITEM_KEY;\n\tkey.offset = 0;\n\n\tif (test_bit(BTRFS_DELAYED_NODE_DEL_IREF, &node->flags))\n\t\tmod = -1;\n\telse\n\t\tmod = 1;\n\n\tret = btrfs_lookup_inode(trans, root, path, &key, mod);\n\tif (ret > 0)\n\t\tret = -ENOENT;\n\tif (ret < 0)\n\t\tgoto out;\n\n\tleaf = path->nodes[0];\n\tinode_item = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t    struct btrfs_inode_item);\n\twrite_extent_buffer(leaf, &node->inode_item, (unsigned long)inode_item,\n\t\t\t    sizeof(struct btrfs_inode_item));\n\tbtrfs_mark_buffer_dirty(trans, leaf);\n\n\tif (!test_bit(BTRFS_DELAYED_NODE_DEL_IREF, &node->flags))\n\t\tgoto out;\n\n\tpath->slots[0]++;\n\tif (path->slots[0] >= btrfs_header_nritems(leaf))\n\t\tgoto search;\nagain:\n\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n\tif (key.objectid != node->inode_id)\n\t\tgoto out;\n\n\tif (key.type != BTRFS_INODE_REF_KEY &&\n\t    key.type != BTRFS_INODE_EXTREF_KEY)\n\t\tgoto out;\n\n\t \n\tret = btrfs_del_item(trans, root, path);\nout:\n\tbtrfs_release_delayed_iref(node);\n\tbtrfs_release_path(path);\nerr_out:\n\tbtrfs_delayed_inode_release_metadata(fs_info, node, (ret < 0));\n\tbtrfs_release_delayed_inode(node);\n\n\t \n\tif (ret && ret != -ENOENT)\n\t\tbtrfs_abort_transaction(trans, ret);\n\n\treturn ret;\n\nsearch:\n\tbtrfs_release_path(path);\n\n\tkey.type = BTRFS_INODE_EXTREF_KEY;\n\tkey.offset = -1;\n\n\tret = btrfs_search_slot(trans, root, &key, path, -1, 1);\n\tif (ret < 0)\n\t\tgoto err_out;\n\tASSERT(ret);\n\n\tret = 0;\n\tleaf = path->nodes[0];\n\tpath->slots[0]--;\n\tgoto again;\n}\n\nstatic inline int btrfs_update_delayed_inode(struct btrfs_trans_handle *trans,\n\t\t\t\t\t     struct btrfs_root *root,\n\t\t\t\t\t     struct btrfs_path *path,\n\t\t\t\t\t     struct btrfs_delayed_node *node)\n{\n\tint ret;\n\n\tmutex_lock(&node->mutex);\n\tif (!test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &node->flags)) {\n\t\tmutex_unlock(&node->mutex);\n\t\treturn 0;\n\t}\n\n\tret = __btrfs_update_delayed_inode(trans, root, path, node);\n\tmutex_unlock(&node->mutex);\n\treturn ret;\n}\n\nstatic inline int\n__btrfs_commit_inode_delayed_items(struct btrfs_trans_handle *trans,\n\t\t\t\t   struct btrfs_path *path,\n\t\t\t\t   struct btrfs_delayed_node *node)\n{\n\tint ret;\n\n\tret = btrfs_insert_delayed_items(trans, path, node->root, node);\n\tif (ret)\n\t\treturn ret;\n\n\tret = btrfs_delete_delayed_items(trans, path, node->root, node);\n\tif (ret)\n\t\treturn ret;\n\n\tret = btrfs_update_delayed_inode(trans, node->root, path, node);\n\treturn ret;\n}\n\n \nstatic int __btrfs_run_delayed_items(struct btrfs_trans_handle *trans, int nr)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct btrfs_delayed_root *delayed_root;\n\tstruct btrfs_delayed_node *curr_node, *prev_node;\n\tstruct btrfs_path *path;\n\tstruct btrfs_block_rsv *block_rsv;\n\tint ret = 0;\n\tbool count = (nr > 0);\n\n\tif (TRANS_ABORTED(trans))\n\t\treturn -EIO;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tblock_rsv = trans->block_rsv;\n\ttrans->block_rsv = &fs_info->delayed_block_rsv;\n\n\tdelayed_root = fs_info->delayed_root;\n\n\tcurr_node = btrfs_first_delayed_node(delayed_root);\n\twhile (curr_node && (!count || nr--)) {\n\t\tret = __btrfs_commit_inode_delayed_items(trans, path,\n\t\t\t\t\t\t\t curr_node);\n\t\tif (ret) {\n\t\t\tbtrfs_abort_transaction(trans, ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tprev_node = curr_node;\n\t\tcurr_node = btrfs_next_delayed_node(curr_node);\n\t\t \n\t\tASSERT(path->nodes[0] == NULL);\n\t\tbtrfs_release_delayed_node(prev_node);\n\t}\n\n\t \n\tbtrfs_free_path(path);\n\n\tif (curr_node)\n\t\tbtrfs_release_delayed_node(curr_node);\n\ttrans->block_rsv = block_rsv;\n\n\treturn ret;\n}\n\nint btrfs_run_delayed_items(struct btrfs_trans_handle *trans)\n{\n\treturn __btrfs_run_delayed_items(trans, -1);\n}\n\nint btrfs_run_delayed_items_nr(struct btrfs_trans_handle *trans, int nr)\n{\n\treturn __btrfs_run_delayed_items(trans, nr);\n}\n\nint btrfs_commit_inode_delayed_items(struct btrfs_trans_handle *trans,\n\t\t\t\t     struct btrfs_inode *inode)\n{\n\tstruct btrfs_delayed_node *delayed_node = btrfs_get_delayed_node(inode);\n\tstruct btrfs_path *path;\n\tstruct btrfs_block_rsv *block_rsv;\n\tint ret;\n\n\tif (!delayed_node)\n\t\treturn 0;\n\n\tmutex_lock(&delayed_node->mutex);\n\tif (!delayed_node->count) {\n\t\tmutex_unlock(&delayed_node->mutex);\n\t\tbtrfs_release_delayed_node(delayed_node);\n\t\treturn 0;\n\t}\n\tmutex_unlock(&delayed_node->mutex);\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tbtrfs_release_delayed_node(delayed_node);\n\t\treturn -ENOMEM;\n\t}\n\n\tblock_rsv = trans->block_rsv;\n\ttrans->block_rsv = &delayed_node->root->fs_info->delayed_block_rsv;\n\n\tret = __btrfs_commit_inode_delayed_items(trans, path, delayed_node);\n\n\tbtrfs_release_delayed_node(delayed_node);\n\tbtrfs_free_path(path);\n\ttrans->block_rsv = block_rsv;\n\n\treturn ret;\n}\n\nint btrfs_commit_inode_delayed_inode(struct btrfs_inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_delayed_node *delayed_node = btrfs_get_delayed_node(inode);\n\tstruct btrfs_path *path;\n\tstruct btrfs_block_rsv *block_rsv;\n\tint ret;\n\n\tif (!delayed_node)\n\t\treturn 0;\n\n\tmutex_lock(&delayed_node->mutex);\n\tif (!test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\n\t\tmutex_unlock(&delayed_node->mutex);\n\t\tbtrfs_release_delayed_node(delayed_node);\n\t\treturn 0;\n\t}\n\tmutex_unlock(&delayed_node->mutex);\n\n\ttrans = btrfs_join_transaction(delayed_node->root);\n\tif (IS_ERR(trans)) {\n\t\tret = PTR_ERR(trans);\n\t\tgoto out;\n\t}\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tgoto trans_out;\n\t}\n\n\tblock_rsv = trans->block_rsv;\n\ttrans->block_rsv = &fs_info->delayed_block_rsv;\n\n\tmutex_lock(&delayed_node->mutex);\n\tif (test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags))\n\t\tret = __btrfs_update_delayed_inode(trans, delayed_node->root,\n\t\t\t\t\t\t   path, delayed_node);\n\telse\n\t\tret = 0;\n\tmutex_unlock(&delayed_node->mutex);\n\n\tbtrfs_free_path(path);\n\ttrans->block_rsv = block_rsv;\ntrans_out:\n\tbtrfs_end_transaction(trans);\n\tbtrfs_btree_balance_dirty(fs_info);\nout:\n\tbtrfs_release_delayed_node(delayed_node);\n\n\treturn ret;\n}\n\nvoid btrfs_remove_delayed_node(struct btrfs_inode *inode)\n{\n\tstruct btrfs_delayed_node *delayed_node;\n\n\tdelayed_node = READ_ONCE(inode->delayed_node);\n\tif (!delayed_node)\n\t\treturn;\n\n\tinode->delayed_node = NULL;\n\tbtrfs_release_delayed_node(delayed_node);\n}\n\nstruct btrfs_async_delayed_work {\n\tstruct btrfs_delayed_root *delayed_root;\n\tint nr;\n\tstruct btrfs_work work;\n};\n\nstatic void btrfs_async_run_delayed_root(struct btrfs_work *work)\n{\n\tstruct btrfs_async_delayed_work *async_work;\n\tstruct btrfs_delayed_root *delayed_root;\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_path *path;\n\tstruct btrfs_delayed_node *delayed_node = NULL;\n\tstruct btrfs_root *root;\n\tstruct btrfs_block_rsv *block_rsv;\n\tint total_done = 0;\n\n\tasync_work = container_of(work, struct btrfs_async_delayed_work, work);\n\tdelayed_root = async_work->delayed_root;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\tgoto out;\n\n\tdo {\n\t\tif (atomic_read(&delayed_root->items) <\n\t\t    BTRFS_DELAYED_BACKGROUND / 2)\n\t\t\tbreak;\n\n\t\tdelayed_node = btrfs_first_prepared_delayed_node(delayed_root);\n\t\tif (!delayed_node)\n\t\t\tbreak;\n\n\t\troot = delayed_node->root;\n\n\t\ttrans = btrfs_join_transaction(root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tbtrfs_release_path(path);\n\t\t\tbtrfs_release_prepared_delayed_node(delayed_node);\n\t\t\ttotal_done++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tblock_rsv = trans->block_rsv;\n\t\ttrans->block_rsv = &root->fs_info->delayed_block_rsv;\n\n\t\t__btrfs_commit_inode_delayed_items(trans, path, delayed_node);\n\n\t\ttrans->block_rsv = block_rsv;\n\t\tbtrfs_end_transaction(trans);\n\t\tbtrfs_btree_balance_dirty_nodelay(root->fs_info);\n\n\t\tbtrfs_release_path(path);\n\t\tbtrfs_release_prepared_delayed_node(delayed_node);\n\t\ttotal_done++;\n\n\t} while ((async_work->nr == 0 && total_done < BTRFS_DELAYED_WRITEBACK)\n\t\t || total_done < async_work->nr);\n\n\tbtrfs_free_path(path);\nout:\n\twake_up(&delayed_root->wait);\n\tkfree(async_work);\n}\n\n\nstatic int btrfs_wq_run_delayed_node(struct btrfs_delayed_root *delayed_root,\n\t\t\t\t     struct btrfs_fs_info *fs_info, int nr)\n{\n\tstruct btrfs_async_delayed_work *async_work;\n\n\tasync_work = kmalloc(sizeof(*async_work), GFP_NOFS);\n\tif (!async_work)\n\t\treturn -ENOMEM;\n\n\tasync_work->delayed_root = delayed_root;\n\tbtrfs_init_work(&async_work->work, btrfs_async_run_delayed_root, NULL,\n\t\t\tNULL);\n\tasync_work->nr = nr;\n\n\tbtrfs_queue_work(fs_info->delayed_workers, &async_work->work);\n\treturn 0;\n}\n\nvoid btrfs_assert_delayed_root_empty(struct btrfs_fs_info *fs_info)\n{\n\tWARN_ON(btrfs_first_delayed_node(fs_info->delayed_root));\n}\n\nstatic int could_end_wait(struct btrfs_delayed_root *delayed_root, int seq)\n{\n\tint val = atomic_read(&delayed_root->items_seq);\n\n\tif (val < seq || val >= seq + BTRFS_DELAYED_BATCH)\n\t\treturn 1;\n\n\tif (atomic_read(&delayed_root->items) < BTRFS_DELAYED_BACKGROUND)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nvoid btrfs_balance_delayed_items(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_delayed_root *delayed_root = fs_info->delayed_root;\n\n\tif ((atomic_read(&delayed_root->items) < BTRFS_DELAYED_BACKGROUND) ||\n\t\tbtrfs_workqueue_normal_congested(fs_info->delayed_workers))\n\t\treturn;\n\n\tif (atomic_read(&delayed_root->items) >= BTRFS_DELAYED_WRITEBACK) {\n\t\tint seq;\n\t\tint ret;\n\n\t\tseq = atomic_read(&delayed_root->items_seq);\n\n\t\tret = btrfs_wq_run_delayed_node(delayed_root, fs_info, 0);\n\t\tif (ret)\n\t\t\treturn;\n\n\t\twait_event_interruptible(delayed_root->wait,\n\t\t\t\t\t could_end_wait(delayed_root, seq));\n\t\treturn;\n\t}\n\n\tbtrfs_wq_run_delayed_node(delayed_root, fs_info, BTRFS_DELAYED_BATCH);\n}\n\nstatic void btrfs_release_dir_index_item_space(struct btrfs_trans_handle *trans)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tconst u64 bytes = btrfs_calc_insert_metadata_size(fs_info, 1);\n\n\tif (test_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags))\n\t\treturn;\n\n\t \n\ttrace_btrfs_space_reservation(fs_info, \"transaction\",\n\t\t\t\t      trans->transid, bytes, 0);\n\tbtrfs_block_rsv_release(fs_info, trans->block_rsv, bytes, NULL);\n\tASSERT(trans->bytes_reserved >= bytes);\n\ttrans->bytes_reserved -= bytes;\n}\n\n \nint btrfs_insert_delayed_dir_index(struct btrfs_trans_handle *trans,\n\t\t\t\t   const char *name, int name_len,\n\t\t\t\t   struct btrfs_inode *dir,\n\t\t\t\t   struct btrfs_disk_key *disk_key, u8 flags,\n\t\t\t\t   u64 index)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tconst unsigned int leaf_data_size = BTRFS_LEAF_DATA_SIZE(fs_info);\n\tstruct btrfs_delayed_node *delayed_node;\n\tstruct btrfs_delayed_item *delayed_item;\n\tstruct btrfs_dir_item *dir_item;\n\tbool reserve_leaf_space;\n\tu32 data_len;\n\tint ret;\n\n\tdelayed_node = btrfs_get_or_create_delayed_node(dir);\n\tif (IS_ERR(delayed_node))\n\t\treturn PTR_ERR(delayed_node);\n\n\tdelayed_item = btrfs_alloc_delayed_item(sizeof(*dir_item) + name_len,\n\t\t\t\t\t\tdelayed_node,\n\t\t\t\t\t\tBTRFS_DELAYED_INSERTION_ITEM);\n\tif (!delayed_item) {\n\t\tret = -ENOMEM;\n\t\tgoto release_node;\n\t}\n\n\tdelayed_item->index = index;\n\n\tdir_item = (struct btrfs_dir_item *)delayed_item->data;\n\tdir_item->location = *disk_key;\n\tbtrfs_set_stack_dir_transid(dir_item, trans->transid);\n\tbtrfs_set_stack_dir_data_len(dir_item, 0);\n\tbtrfs_set_stack_dir_name_len(dir_item, name_len);\n\tbtrfs_set_stack_dir_flags(dir_item, flags);\n\tmemcpy((char *)(dir_item + 1), name, name_len);\n\n\tdata_len = delayed_item->data_len + sizeof(struct btrfs_item);\n\n\tmutex_lock(&delayed_node->mutex);\n\n\t \n\tret = __btrfs_add_delayed_item(delayed_node, delayed_item);\n\tif (unlikely(ret)) {\n\t\tbtrfs_err(trans->fs_info,\n\"error adding delayed dir index item, name: %.*s, index: %llu, root: %llu, dir: %llu, dir->index_cnt: %llu, delayed_node->index_cnt: %llu, error: %d\",\n\t\t\t  name_len, name, index, btrfs_root_id(delayed_node->root),\n\t\t\t  delayed_node->inode_id, dir->index_cnt,\n\t\t\t  delayed_node->index_cnt, ret);\n\t\tbtrfs_release_delayed_item(delayed_item);\n\t\tbtrfs_release_dir_index_item_space(trans);\n\t\tmutex_unlock(&delayed_node->mutex);\n\t\tgoto release_node;\n\t}\n\n\tif (delayed_node->index_item_leaves == 0 ||\n\t    delayed_node->curr_index_batch_size + data_len > leaf_data_size) {\n\t\tdelayed_node->curr_index_batch_size = data_len;\n\t\treserve_leaf_space = true;\n\t} else {\n\t\tdelayed_node->curr_index_batch_size += data_len;\n\t\treserve_leaf_space = false;\n\t}\n\n\tif (reserve_leaf_space) {\n\t\tret = btrfs_delayed_item_reserve_metadata(trans, delayed_item);\n\t\t \n\t\tif (WARN_ON(ret)) {\n\t\t\tbtrfs_release_delayed_item(delayed_item);\n\t\t\tmutex_unlock(&delayed_node->mutex);\n\t\t\tgoto release_node;\n\t\t}\n\n\t\tdelayed_node->index_item_leaves++;\n\t} else {\n\t\tbtrfs_release_dir_index_item_space(trans);\n\t}\n\tmutex_unlock(&delayed_node->mutex);\n\nrelease_node:\n\tbtrfs_release_delayed_node(delayed_node);\n\treturn ret;\n}\n\nstatic int btrfs_delete_delayed_insertion_item(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t       struct btrfs_delayed_node *node,\n\t\t\t\t\t       u64 index)\n{\n\tstruct btrfs_delayed_item *item;\n\n\tmutex_lock(&node->mutex);\n\titem = __btrfs_lookup_delayed_item(&node->ins_root.rb_root, index);\n\tif (!item) {\n\t\tmutex_unlock(&node->mutex);\n\t\treturn 1;\n\t}\n\n\t \n\tASSERT(item->bytes_reserved == 0);\n\tASSERT(node->index_item_leaves > 0);\n\n\t \n\tif (node->index_item_leaves == 1) {\n\t\tconst u32 data_len = item->data_len + sizeof(struct btrfs_item);\n\n\t\tASSERT(node->curr_index_batch_size >= data_len);\n\t\tnode->curr_index_batch_size -= data_len;\n\t}\n\n\tbtrfs_release_delayed_item(item);\n\n\t \n\tif (RB_EMPTY_ROOT(&node->ins_root.rb_root)) {\n\t\tbtrfs_delayed_item_release_leaves(node, node->index_item_leaves);\n\t\tnode->index_item_leaves = 0;\n\t}\n\n\tmutex_unlock(&node->mutex);\n\treturn 0;\n}\n\nint btrfs_delete_delayed_dir_index(struct btrfs_trans_handle *trans,\n\t\t\t\t   struct btrfs_inode *dir, u64 index)\n{\n\tstruct btrfs_delayed_node *node;\n\tstruct btrfs_delayed_item *item;\n\tint ret;\n\n\tnode = btrfs_get_or_create_delayed_node(dir);\n\tif (IS_ERR(node))\n\t\treturn PTR_ERR(node);\n\n\tret = btrfs_delete_delayed_insertion_item(trans->fs_info, node, index);\n\tif (!ret)\n\t\tgoto end;\n\n\titem = btrfs_alloc_delayed_item(0, node, BTRFS_DELAYED_DELETION_ITEM);\n\tif (!item) {\n\t\tret = -ENOMEM;\n\t\tgoto end;\n\t}\n\n\titem->index = index;\n\n\tret = btrfs_delayed_item_reserve_metadata(trans, item);\n\t \n\tif (ret < 0) {\n\t\tbtrfs_err(trans->fs_info,\n\"metadata reservation failed for delayed dir item deltiona, should have been reserved\");\n\t\tbtrfs_release_delayed_item(item);\n\t\tgoto end;\n\t}\n\n\tmutex_lock(&node->mutex);\n\tret = __btrfs_add_delayed_item(node, item);\n\tif (unlikely(ret)) {\n\t\tbtrfs_err(trans->fs_info,\n\t\t\t  \"err add delayed dir index item(index: %llu) into the deletion tree of the delayed node(root id: %llu, inode id: %llu, errno: %d)\",\n\t\t\t  index, node->root->root_key.objectid,\n\t\t\t  node->inode_id, ret);\n\t\tbtrfs_delayed_item_release_metadata(dir->root, item);\n\t\tbtrfs_release_delayed_item(item);\n\t}\n\tmutex_unlock(&node->mutex);\nend:\n\tbtrfs_release_delayed_node(node);\n\treturn ret;\n}\n\nint btrfs_inode_delayed_dir_index_count(struct btrfs_inode *inode)\n{\n\tstruct btrfs_delayed_node *delayed_node = btrfs_get_delayed_node(inode);\n\n\tif (!delayed_node)\n\t\treturn -ENOENT;\n\n\t \n\tif (!delayed_node->index_cnt) {\n\t\tbtrfs_release_delayed_node(delayed_node);\n\t\treturn -EINVAL;\n\t}\n\n\tinode->index_cnt = delayed_node->index_cnt;\n\tbtrfs_release_delayed_node(delayed_node);\n\treturn 0;\n}\n\nbool btrfs_readdir_get_delayed_items(struct inode *inode,\n\t\t\t\t     u64 last_index,\n\t\t\t\t     struct list_head *ins_list,\n\t\t\t\t     struct list_head *del_list)\n{\n\tstruct btrfs_delayed_node *delayed_node;\n\tstruct btrfs_delayed_item *item;\n\n\tdelayed_node = btrfs_get_delayed_node(BTRFS_I(inode));\n\tif (!delayed_node)\n\t\treturn false;\n\n\t \n\tbtrfs_inode_unlock(BTRFS_I(inode), BTRFS_ILOCK_SHARED);\n\tbtrfs_inode_lock(BTRFS_I(inode), 0);\n\n\tmutex_lock(&delayed_node->mutex);\n\titem = __btrfs_first_delayed_insertion_item(delayed_node);\n\twhile (item && item->index <= last_index) {\n\t\trefcount_inc(&item->refs);\n\t\tlist_add_tail(&item->readdir_list, ins_list);\n\t\titem = __btrfs_next_delayed_item(item);\n\t}\n\n\titem = __btrfs_first_delayed_deletion_item(delayed_node);\n\twhile (item && item->index <= last_index) {\n\t\trefcount_inc(&item->refs);\n\t\tlist_add_tail(&item->readdir_list, del_list);\n\t\titem = __btrfs_next_delayed_item(item);\n\t}\n\tmutex_unlock(&delayed_node->mutex);\n\t \n\trefcount_dec(&delayed_node->refs);\n\n\treturn true;\n}\n\nvoid btrfs_readdir_put_delayed_items(struct inode *inode,\n\t\t\t\t     struct list_head *ins_list,\n\t\t\t\t     struct list_head *del_list)\n{\n\tstruct btrfs_delayed_item *curr, *next;\n\n\tlist_for_each_entry_safe(curr, next, ins_list, readdir_list) {\n\t\tlist_del(&curr->readdir_list);\n\t\tif (refcount_dec_and_test(&curr->refs))\n\t\t\tkfree(curr);\n\t}\n\n\tlist_for_each_entry_safe(curr, next, del_list, readdir_list) {\n\t\tlist_del(&curr->readdir_list);\n\t\tif (refcount_dec_and_test(&curr->refs))\n\t\t\tkfree(curr);\n\t}\n\n\t \n\tdowngrade_write(&inode->i_rwsem);\n}\n\nint btrfs_should_delete_dir_index(struct list_head *del_list,\n\t\t\t\t  u64 index)\n{\n\tstruct btrfs_delayed_item *curr;\n\tint ret = 0;\n\n\tlist_for_each_entry(curr, del_list, readdir_list) {\n\t\tif (curr->index > index)\n\t\t\tbreak;\n\t\tif (curr->index == index) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn ret;\n}\n\n \nint btrfs_readdir_delayed_dir_index(struct dir_context *ctx,\n\t\t\t\t    struct list_head *ins_list)\n{\n\tstruct btrfs_dir_item *di;\n\tstruct btrfs_delayed_item *curr, *next;\n\tstruct btrfs_key location;\n\tchar *name;\n\tint name_len;\n\tint over = 0;\n\tunsigned char d_type;\n\n\t \n\tlist_for_each_entry_safe(curr, next, ins_list, readdir_list) {\n\t\tlist_del(&curr->readdir_list);\n\n\t\tif (curr->index < ctx->pos) {\n\t\t\tif (refcount_dec_and_test(&curr->refs))\n\t\t\t\tkfree(curr);\n\t\t\tcontinue;\n\t\t}\n\n\t\tctx->pos = curr->index;\n\n\t\tdi = (struct btrfs_dir_item *)curr->data;\n\t\tname = (char *)(di + 1);\n\t\tname_len = btrfs_stack_dir_name_len(di);\n\n\t\td_type = fs_ftype_to_dtype(btrfs_dir_flags_to_ftype(di->type));\n\t\tbtrfs_disk_key_to_cpu(&location, &di->location);\n\n\t\tover = !dir_emit(ctx, name, name_len,\n\t\t\t       location.objectid, d_type);\n\n\t\tif (refcount_dec_and_test(&curr->refs))\n\t\t\tkfree(curr);\n\n\t\tif (over)\n\t\t\treturn 1;\n\t\tctx->pos++;\n\t}\n\treturn 0;\n}\n\nstatic void fill_stack_inode_item(struct btrfs_trans_handle *trans,\n\t\t\t\t  struct btrfs_inode_item *inode_item,\n\t\t\t\t  struct inode *inode)\n{\n\tu64 flags;\n\n\tbtrfs_set_stack_inode_uid(inode_item, i_uid_read(inode));\n\tbtrfs_set_stack_inode_gid(inode_item, i_gid_read(inode));\n\tbtrfs_set_stack_inode_size(inode_item, BTRFS_I(inode)->disk_i_size);\n\tbtrfs_set_stack_inode_mode(inode_item, inode->i_mode);\n\tbtrfs_set_stack_inode_nlink(inode_item, inode->i_nlink);\n\tbtrfs_set_stack_inode_nbytes(inode_item, inode_get_bytes(inode));\n\tbtrfs_set_stack_inode_generation(inode_item,\n\t\t\t\t\t BTRFS_I(inode)->generation);\n\tbtrfs_set_stack_inode_sequence(inode_item,\n\t\t\t\t       inode_peek_iversion(inode));\n\tbtrfs_set_stack_inode_transid(inode_item, trans->transid);\n\tbtrfs_set_stack_inode_rdev(inode_item, inode->i_rdev);\n\tflags = btrfs_inode_combine_flags(BTRFS_I(inode)->flags,\n\t\t\t\t\t  BTRFS_I(inode)->ro_flags);\n\tbtrfs_set_stack_inode_flags(inode_item, flags);\n\tbtrfs_set_stack_inode_block_group(inode_item, 0);\n\n\tbtrfs_set_stack_timespec_sec(&inode_item->atime,\n\t\t\t\t     inode->i_atime.tv_sec);\n\tbtrfs_set_stack_timespec_nsec(&inode_item->atime,\n\t\t\t\t      inode->i_atime.tv_nsec);\n\n\tbtrfs_set_stack_timespec_sec(&inode_item->mtime,\n\t\t\t\t     inode->i_mtime.tv_sec);\n\tbtrfs_set_stack_timespec_nsec(&inode_item->mtime,\n\t\t\t\t      inode->i_mtime.tv_nsec);\n\n\tbtrfs_set_stack_timespec_sec(&inode_item->ctime,\n\t\t\t\t     inode_get_ctime(inode).tv_sec);\n\tbtrfs_set_stack_timespec_nsec(&inode_item->ctime,\n\t\t\t\t      inode_get_ctime(inode).tv_nsec);\n\n\tbtrfs_set_stack_timespec_sec(&inode_item->otime,\n\t\t\t\t     BTRFS_I(inode)->i_otime.tv_sec);\n\tbtrfs_set_stack_timespec_nsec(&inode_item->otime,\n\t\t\t\t     BTRFS_I(inode)->i_otime.tv_nsec);\n}\n\nint btrfs_fill_inode(struct inode *inode, u32 *rdev)\n{\n\tstruct btrfs_fs_info *fs_info = BTRFS_I(inode)->root->fs_info;\n\tstruct btrfs_delayed_node *delayed_node;\n\tstruct btrfs_inode_item *inode_item;\n\n\tdelayed_node = btrfs_get_delayed_node(BTRFS_I(inode));\n\tif (!delayed_node)\n\t\treturn -ENOENT;\n\n\tmutex_lock(&delayed_node->mutex);\n\tif (!test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\n\t\tmutex_unlock(&delayed_node->mutex);\n\t\tbtrfs_release_delayed_node(delayed_node);\n\t\treturn -ENOENT;\n\t}\n\n\tinode_item = &delayed_node->inode_item;\n\n\ti_uid_write(inode, btrfs_stack_inode_uid(inode_item));\n\ti_gid_write(inode, btrfs_stack_inode_gid(inode_item));\n\tbtrfs_i_size_write(BTRFS_I(inode), btrfs_stack_inode_size(inode_item));\n\tbtrfs_inode_set_file_extent_range(BTRFS_I(inode), 0,\n\t\t\tround_up(i_size_read(inode), fs_info->sectorsize));\n\tinode->i_mode = btrfs_stack_inode_mode(inode_item);\n\tset_nlink(inode, btrfs_stack_inode_nlink(inode_item));\n\tinode_set_bytes(inode, btrfs_stack_inode_nbytes(inode_item));\n\tBTRFS_I(inode)->generation = btrfs_stack_inode_generation(inode_item);\n        BTRFS_I(inode)->last_trans = btrfs_stack_inode_transid(inode_item);\n\n\tinode_set_iversion_queried(inode,\n\t\t\t\t   btrfs_stack_inode_sequence(inode_item));\n\tinode->i_rdev = 0;\n\t*rdev = btrfs_stack_inode_rdev(inode_item);\n\tbtrfs_inode_split_flags(btrfs_stack_inode_flags(inode_item),\n\t\t\t\t&BTRFS_I(inode)->flags, &BTRFS_I(inode)->ro_flags);\n\n\tinode->i_atime.tv_sec = btrfs_stack_timespec_sec(&inode_item->atime);\n\tinode->i_atime.tv_nsec = btrfs_stack_timespec_nsec(&inode_item->atime);\n\n\tinode->i_mtime.tv_sec = btrfs_stack_timespec_sec(&inode_item->mtime);\n\tinode->i_mtime.tv_nsec = btrfs_stack_timespec_nsec(&inode_item->mtime);\n\n\tinode_set_ctime(inode, btrfs_stack_timespec_sec(&inode_item->ctime),\n\t\t\tbtrfs_stack_timespec_nsec(&inode_item->ctime));\n\n\tBTRFS_I(inode)->i_otime.tv_sec =\n\t\tbtrfs_stack_timespec_sec(&inode_item->otime);\n\tBTRFS_I(inode)->i_otime.tv_nsec =\n\t\tbtrfs_stack_timespec_nsec(&inode_item->otime);\n\n\tinode->i_generation = BTRFS_I(inode)->generation;\n\tBTRFS_I(inode)->index_cnt = (u64)-1;\n\n\tmutex_unlock(&delayed_node->mutex);\n\tbtrfs_release_delayed_node(delayed_node);\n\treturn 0;\n}\n\nint btrfs_delayed_update_inode(struct btrfs_trans_handle *trans,\n\t\t\t       struct btrfs_root *root,\n\t\t\t       struct btrfs_inode *inode)\n{\n\tstruct btrfs_delayed_node *delayed_node;\n\tint ret = 0;\n\n\tdelayed_node = btrfs_get_or_create_delayed_node(inode);\n\tif (IS_ERR(delayed_node))\n\t\treturn PTR_ERR(delayed_node);\n\n\tmutex_lock(&delayed_node->mutex);\n\tif (test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\n\t\tfill_stack_inode_item(trans, &delayed_node->inode_item,\n\t\t\t\t      &inode->vfs_inode);\n\t\tgoto release_node;\n\t}\n\n\tret = btrfs_delayed_inode_reserve_metadata(trans, root, delayed_node);\n\tif (ret)\n\t\tgoto release_node;\n\n\tfill_stack_inode_item(trans, &delayed_node->inode_item, &inode->vfs_inode);\n\tset_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags);\n\tdelayed_node->count++;\n\tatomic_inc(&root->fs_info->delayed_root->items);\nrelease_node:\n\tmutex_unlock(&delayed_node->mutex);\n\tbtrfs_release_delayed_node(delayed_node);\n\treturn ret;\n}\n\nint btrfs_delayed_delete_inode_ref(struct btrfs_inode *inode)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct btrfs_delayed_node *delayed_node;\n\n\t \n\tif (test_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags))\n\t\treturn -EAGAIN;\n\n\tdelayed_node = btrfs_get_or_create_delayed_node(inode);\n\tif (IS_ERR(delayed_node))\n\t\treturn PTR_ERR(delayed_node);\n\n\t \n\tmutex_lock(&delayed_node->mutex);\n\tif (test_bit(BTRFS_DELAYED_NODE_DEL_IREF, &delayed_node->flags))\n\t\tgoto release_node;\n\n\tset_bit(BTRFS_DELAYED_NODE_DEL_IREF, &delayed_node->flags);\n\tdelayed_node->count++;\n\tatomic_inc(&fs_info->delayed_root->items);\nrelease_node:\n\tmutex_unlock(&delayed_node->mutex);\n\tbtrfs_release_delayed_node(delayed_node);\n\treturn 0;\n}\n\nstatic void __btrfs_kill_delayed_node(struct btrfs_delayed_node *delayed_node)\n{\n\tstruct btrfs_root *root = delayed_node->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_delayed_item *curr_item, *prev_item;\n\n\tmutex_lock(&delayed_node->mutex);\n\tcurr_item = __btrfs_first_delayed_insertion_item(delayed_node);\n\twhile (curr_item) {\n\t\tprev_item = curr_item;\n\t\tcurr_item = __btrfs_next_delayed_item(prev_item);\n\t\tbtrfs_release_delayed_item(prev_item);\n\t}\n\n\tif (delayed_node->index_item_leaves > 0) {\n\t\tbtrfs_delayed_item_release_leaves(delayed_node,\n\t\t\t\t\t  delayed_node->index_item_leaves);\n\t\tdelayed_node->index_item_leaves = 0;\n\t}\n\n\tcurr_item = __btrfs_first_delayed_deletion_item(delayed_node);\n\twhile (curr_item) {\n\t\tbtrfs_delayed_item_release_metadata(root, curr_item);\n\t\tprev_item = curr_item;\n\t\tcurr_item = __btrfs_next_delayed_item(prev_item);\n\t\tbtrfs_release_delayed_item(prev_item);\n\t}\n\n\tbtrfs_release_delayed_iref(delayed_node);\n\n\tif (test_bit(BTRFS_DELAYED_NODE_INODE_DIRTY, &delayed_node->flags)) {\n\t\tbtrfs_delayed_inode_release_metadata(fs_info, delayed_node, false);\n\t\tbtrfs_release_delayed_inode(delayed_node);\n\t}\n\tmutex_unlock(&delayed_node->mutex);\n}\n\nvoid btrfs_kill_delayed_inode_items(struct btrfs_inode *inode)\n{\n\tstruct btrfs_delayed_node *delayed_node;\n\n\tdelayed_node = btrfs_get_delayed_node(inode);\n\tif (!delayed_node)\n\t\treturn;\n\n\t__btrfs_kill_delayed_node(delayed_node);\n\tbtrfs_release_delayed_node(delayed_node);\n}\n\nvoid btrfs_kill_all_delayed_nodes(struct btrfs_root *root)\n{\n\tu64 inode_id = 0;\n\tstruct btrfs_delayed_node *delayed_nodes[8];\n\tint i, n;\n\n\twhile (1) {\n\t\tspin_lock(&root->inode_lock);\n\t\tn = radix_tree_gang_lookup(&root->delayed_nodes_tree,\n\t\t\t\t\t   (void **)delayed_nodes, inode_id,\n\t\t\t\t\t   ARRAY_SIZE(delayed_nodes));\n\t\tif (!n) {\n\t\t\tspin_unlock(&root->inode_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\tinode_id = delayed_nodes[n - 1]->inode_id + 1;\n\t\tfor (i = 0; i < n; i++) {\n\t\t\t \n\t\t\tif (!refcount_inc_not_zero(&delayed_nodes[i]->refs))\n\t\t\t\tdelayed_nodes[i] = NULL;\n\t\t}\n\t\tspin_unlock(&root->inode_lock);\n\n\t\tfor (i = 0; i < n; i++) {\n\t\t\tif (!delayed_nodes[i])\n\t\t\t\tcontinue;\n\t\t\t__btrfs_kill_delayed_node(delayed_nodes[i]);\n\t\t\tbtrfs_release_delayed_node(delayed_nodes[i]);\n\t\t}\n\t}\n}\n\nvoid btrfs_destroy_delayed_inodes(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_delayed_node *curr_node, *prev_node;\n\n\tcurr_node = btrfs_first_delayed_node(fs_info->delayed_root);\n\twhile (curr_node) {\n\t\t__btrfs_kill_delayed_node(curr_node);\n\n\t\tprev_node = curr_node;\n\t\tcurr_node = btrfs_next_delayed_node(curr_node);\n\t\tbtrfs_release_delayed_node(prev_node);\n\t}\n}\n\nvoid btrfs_log_get_delayed_items(struct btrfs_inode *inode,\n\t\t\t\t struct list_head *ins_list,\n\t\t\t\t struct list_head *del_list)\n{\n\tstruct btrfs_delayed_node *node;\n\tstruct btrfs_delayed_item *item;\n\n\tnode = btrfs_get_delayed_node(inode);\n\tif (!node)\n\t\treturn;\n\n\tmutex_lock(&node->mutex);\n\titem = __btrfs_first_delayed_insertion_item(node);\n\twhile (item) {\n\t\t \n\t\tif (!item->logged && list_empty(&item->log_list)) {\n\t\t\trefcount_inc(&item->refs);\n\t\t\tlist_add_tail(&item->log_list, ins_list);\n\t\t}\n\t\titem = __btrfs_next_delayed_item(item);\n\t}\n\n\titem = __btrfs_first_delayed_deletion_item(node);\n\twhile (item) {\n\t\t \n\t\tif (!item->logged && list_empty(&item->log_list)) {\n\t\t\trefcount_inc(&item->refs);\n\t\t\tlist_add_tail(&item->log_list, del_list);\n\t\t}\n\t\titem = __btrfs_next_delayed_item(item);\n\t}\n\tmutex_unlock(&node->mutex);\n\n\t \n\tASSERT(refcount_read(&node->refs) > 1);\n\trefcount_dec(&node->refs);\n}\n\nvoid btrfs_log_put_delayed_items(struct btrfs_inode *inode,\n\t\t\t\t struct list_head *ins_list,\n\t\t\t\t struct list_head *del_list)\n{\n\tstruct btrfs_delayed_node *node;\n\tstruct btrfs_delayed_item *item;\n\tstruct btrfs_delayed_item *next;\n\n\tnode = btrfs_get_delayed_node(inode);\n\tif (!node)\n\t\treturn;\n\n\tmutex_lock(&node->mutex);\n\n\tlist_for_each_entry_safe(item, next, ins_list, log_list) {\n\t\titem->logged = true;\n\t\tlist_del_init(&item->log_list);\n\t\tif (refcount_dec_and_test(&item->refs))\n\t\t\tkfree(item);\n\t}\n\n\tlist_for_each_entry_safe(item, next, del_list, log_list) {\n\t\titem->logged = true;\n\t\tlist_del_init(&item->log_list);\n\t\tif (refcount_dec_and_test(&item->refs))\n\t\t\tkfree(item);\n\t}\n\n\tmutex_unlock(&node->mutex);\n\n\t \n\tASSERT(refcount_read(&node->refs) > 1);\n\trefcount_dec(&node->refs);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}