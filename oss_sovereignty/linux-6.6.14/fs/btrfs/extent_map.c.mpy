{
  "module_name": "extent_map.c",
  "hash_id": "93a30fcf391f8a849cf18f634a9aa195b9b7cd8d144383d8f3c5c16b2193f82e",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/extent_map.c",
  "human_readable_source": "\n\n#include <linux/err.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include \"messages.h\"\n#include \"ctree.h\"\n#include \"volumes.h\"\n#include \"extent_map.h\"\n#include \"compression.h\"\n#include \"btrfs_inode.h\"\n\n\nstatic struct kmem_cache *extent_map_cache;\n\nint __init extent_map_init(void)\n{\n\textent_map_cache = kmem_cache_create(\"btrfs_extent_map\",\n\t\t\tsizeof(struct extent_map), 0,\n\t\t\tSLAB_MEM_SPREAD, NULL);\n\tif (!extent_map_cache)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid __cold extent_map_exit(void)\n{\n\tkmem_cache_destroy(extent_map_cache);\n}\n\n \nvoid extent_map_tree_init(struct extent_map_tree *tree)\n{\n\ttree->map = RB_ROOT_CACHED;\n\tINIT_LIST_HEAD(&tree->modified_extents);\n\trwlock_init(&tree->lock);\n}\n\n \nstruct extent_map *alloc_extent_map(void)\n{\n\tstruct extent_map *em;\n\tem = kmem_cache_zalloc(extent_map_cache, GFP_NOFS);\n\tif (!em)\n\t\treturn NULL;\n\tRB_CLEAR_NODE(&em->rb_node);\n\tem->compress_type = BTRFS_COMPRESS_NONE;\n\trefcount_set(&em->refs, 1);\n\tINIT_LIST_HEAD(&em->list);\n\treturn em;\n}\n\n \nvoid free_extent_map(struct extent_map *em)\n{\n\tif (!em)\n\t\treturn;\n\tif (refcount_dec_and_test(&em->refs)) {\n\t\tWARN_ON(extent_map_in_tree(em));\n\t\tWARN_ON(!list_empty(&em->list));\n\t\tif (test_bit(EXTENT_FLAG_FS_MAPPING, &em->flags))\n\t\t\tkfree(em->map_lookup);\n\t\tkmem_cache_free(extent_map_cache, em);\n\t}\n}\n\n \nstatic u64 range_end(u64 start, u64 len)\n{\n\tif (start + len < start)\n\t\treturn (u64)-1;\n\treturn start + len;\n}\n\nstatic int tree_insert(struct rb_root_cached *root, struct extent_map *em)\n{\n\tstruct rb_node **p = &root->rb_root.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct extent_map *entry = NULL;\n\tstruct rb_node *orig_parent = NULL;\n\tu64 end = range_end(em->start, em->len);\n\tbool leftmost = true;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tentry = rb_entry(parent, struct extent_map, rb_node);\n\n\t\tif (em->start < entry->start) {\n\t\t\tp = &(*p)->rb_left;\n\t\t} else if (em->start >= extent_map_end(entry)) {\n\t\t\tp = &(*p)->rb_right;\n\t\t\tleftmost = false;\n\t\t} else {\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\torig_parent = parent;\n\twhile (parent && em->start >= extent_map_end(entry)) {\n\t\tparent = rb_next(parent);\n\t\tentry = rb_entry(parent, struct extent_map, rb_node);\n\t}\n\tif (parent)\n\t\tif (end > entry->start && em->start < extent_map_end(entry))\n\t\t\treturn -EEXIST;\n\n\tparent = orig_parent;\n\tentry = rb_entry(parent, struct extent_map, rb_node);\n\twhile (parent && em->start < entry->start) {\n\t\tparent = rb_prev(parent);\n\t\tentry = rb_entry(parent, struct extent_map, rb_node);\n\t}\n\tif (parent)\n\t\tif (end > entry->start && em->start < extent_map_end(entry))\n\t\t\treturn -EEXIST;\n\n\trb_link_node(&em->rb_node, orig_parent, p);\n\trb_insert_color_cached(&em->rb_node, root, leftmost);\n\treturn 0;\n}\n\n \nstatic struct rb_node *__tree_search(struct rb_root *root, u64 offset,\n\t\t\t\t     struct rb_node **prev_or_next_ret)\n{\n\tstruct rb_node *n = root->rb_node;\n\tstruct rb_node *prev = NULL;\n\tstruct rb_node *orig_prev = NULL;\n\tstruct extent_map *entry;\n\tstruct extent_map *prev_entry = NULL;\n\n\tASSERT(prev_or_next_ret);\n\n\twhile (n) {\n\t\tentry = rb_entry(n, struct extent_map, rb_node);\n\t\tprev = n;\n\t\tprev_entry = entry;\n\n\t\tif (offset < entry->start)\n\t\t\tn = n->rb_left;\n\t\telse if (offset >= extent_map_end(entry))\n\t\t\tn = n->rb_right;\n\t\telse\n\t\t\treturn n;\n\t}\n\n\torig_prev = prev;\n\twhile (prev && offset >= extent_map_end(prev_entry)) {\n\t\tprev = rb_next(prev);\n\t\tprev_entry = rb_entry(prev, struct extent_map, rb_node);\n\t}\n\n\t \n\tif (prev) {\n\t\t*prev_or_next_ret = prev;\n\t\treturn NULL;\n\t}\n\n\tprev = orig_prev;\n\tprev_entry = rb_entry(prev, struct extent_map, rb_node);\n\twhile (prev && offset < prev_entry->start) {\n\t\tprev = rb_prev(prev);\n\t\tprev_entry = rb_entry(prev, struct extent_map, rb_node);\n\t}\n\t*prev_or_next_ret = prev;\n\n\treturn NULL;\n}\n\n \nstatic int mergable_maps(struct extent_map *prev, struct extent_map *next)\n{\n\tif (test_bit(EXTENT_FLAG_PINNED, &prev->flags))\n\t\treturn 0;\n\n\t \n\tif (test_bit(EXTENT_FLAG_COMPRESSED, &prev->flags))\n\t\treturn 0;\n\n\tif (test_bit(EXTENT_FLAG_LOGGING, &prev->flags) ||\n\t    test_bit(EXTENT_FLAG_LOGGING, &next->flags))\n\t\treturn 0;\n\n\t \n\tif (!list_empty(&prev->list) || !list_empty(&next->list))\n\t\treturn 0;\n\n\tASSERT(next->block_start != EXTENT_MAP_DELALLOC &&\n\t       prev->block_start != EXTENT_MAP_DELALLOC);\n\n\tif (prev->map_lookup || next->map_lookup)\n\t\tASSERT(test_bit(EXTENT_FLAG_FS_MAPPING, &prev->flags) &&\n\t\t       test_bit(EXTENT_FLAG_FS_MAPPING, &next->flags));\n\n\tif (extent_map_end(prev) == next->start &&\n\t    prev->flags == next->flags &&\n\t    prev->map_lookup == next->map_lookup &&\n\t    ((next->block_start == EXTENT_MAP_HOLE &&\n\t      prev->block_start == EXTENT_MAP_HOLE) ||\n\t     (next->block_start == EXTENT_MAP_INLINE &&\n\t      prev->block_start == EXTENT_MAP_INLINE) ||\n\t     (next->block_start < EXTENT_MAP_LAST_BYTE - 1 &&\n\t      next->block_start == extent_map_block_end(prev)))) {\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic void try_merge_map(struct extent_map_tree *tree, struct extent_map *em)\n{\n\tstruct extent_map *merge = NULL;\n\tstruct rb_node *rb;\n\n\t \n\tif (refcount_read(&em->refs) > 2)\n\t\treturn;\n\n\tif (em->start != 0) {\n\t\trb = rb_prev(&em->rb_node);\n\t\tif (rb)\n\t\t\tmerge = rb_entry(rb, struct extent_map, rb_node);\n\t\tif (rb && mergable_maps(merge, em)) {\n\t\t\tem->start = merge->start;\n\t\t\tem->orig_start = merge->orig_start;\n\t\t\tem->len += merge->len;\n\t\t\tem->block_len += merge->block_len;\n\t\t\tem->block_start = merge->block_start;\n\t\t\tem->mod_len = (em->mod_len + em->mod_start) - merge->mod_start;\n\t\t\tem->mod_start = merge->mod_start;\n\t\t\tem->generation = max(em->generation, merge->generation);\n\t\t\tset_bit(EXTENT_FLAG_MERGED, &em->flags);\n\n\t\t\trb_erase_cached(&merge->rb_node, &tree->map);\n\t\t\tRB_CLEAR_NODE(&merge->rb_node);\n\t\t\tfree_extent_map(merge);\n\t\t}\n\t}\n\n\trb = rb_next(&em->rb_node);\n\tif (rb)\n\t\tmerge = rb_entry(rb, struct extent_map, rb_node);\n\tif (rb && mergable_maps(em, merge)) {\n\t\tem->len += merge->len;\n\t\tem->block_len += merge->block_len;\n\t\trb_erase_cached(&merge->rb_node, &tree->map);\n\t\tRB_CLEAR_NODE(&merge->rb_node);\n\t\tem->mod_len = (merge->mod_start + merge->mod_len) - em->mod_start;\n\t\tem->generation = max(em->generation, merge->generation);\n\t\tset_bit(EXTENT_FLAG_MERGED, &em->flags);\n\t\tfree_extent_map(merge);\n\t}\n}\n\n \nint unpin_extent_cache(struct extent_map_tree *tree, u64 start, u64 len,\n\t\t       u64 gen)\n{\n\tint ret = 0;\n\tstruct extent_map *em;\n\tbool prealloc = false;\n\n\twrite_lock(&tree->lock);\n\tem = lookup_extent_mapping(tree, start, len);\n\n\tWARN_ON(!em || em->start != start);\n\n\tif (!em)\n\t\tgoto out;\n\n\tem->generation = gen;\n\tclear_bit(EXTENT_FLAG_PINNED, &em->flags);\n\tem->mod_start = em->start;\n\tem->mod_len = em->len;\n\n\tif (test_bit(EXTENT_FLAG_FILLING, &em->flags)) {\n\t\tprealloc = true;\n\t\tclear_bit(EXTENT_FLAG_FILLING, &em->flags);\n\t}\n\n\ttry_merge_map(tree, em);\n\n\tif (prealloc) {\n\t\tem->mod_start = em->start;\n\t\tem->mod_len = em->len;\n\t}\n\n\tfree_extent_map(em);\nout:\n\twrite_unlock(&tree->lock);\n\treturn ret;\n\n}\n\nvoid clear_em_logging(struct extent_map_tree *tree, struct extent_map *em)\n{\n\tlockdep_assert_held_write(&tree->lock);\n\n\tclear_bit(EXTENT_FLAG_LOGGING, &em->flags);\n\tif (extent_map_in_tree(em))\n\t\ttry_merge_map(tree, em);\n}\n\nstatic inline void setup_extent_mapping(struct extent_map_tree *tree,\n\t\t\t\t\tstruct extent_map *em,\n\t\t\t\t\tint modified)\n{\n\trefcount_inc(&em->refs);\n\tem->mod_start = em->start;\n\tem->mod_len = em->len;\n\n\tif (modified)\n\t\tlist_move(&em->list, &tree->modified_extents);\n\telse\n\t\ttry_merge_map(tree, em);\n}\n\nstatic void extent_map_device_set_bits(struct extent_map *em, unsigned bits)\n{\n\tstruct map_lookup *map = em->map_lookup;\n\tu64 stripe_size = em->orig_block_len;\n\tint i;\n\n\tfor (i = 0; i < map->num_stripes; i++) {\n\t\tstruct btrfs_io_stripe *stripe = &map->stripes[i];\n\t\tstruct btrfs_device *device = stripe->dev;\n\n\t\tset_extent_bit(&device->alloc_state, stripe->physical,\n\t\t\t       stripe->physical + stripe_size - 1,\n\t\t\t       bits | EXTENT_NOWAIT, NULL);\n\t}\n}\n\nstatic void extent_map_device_clear_bits(struct extent_map *em, unsigned bits)\n{\n\tstruct map_lookup *map = em->map_lookup;\n\tu64 stripe_size = em->orig_block_len;\n\tint i;\n\n\tfor (i = 0; i < map->num_stripes; i++) {\n\t\tstruct btrfs_io_stripe *stripe = &map->stripes[i];\n\t\tstruct btrfs_device *device = stripe->dev;\n\n\t\t__clear_extent_bit(&device->alloc_state, stripe->physical,\n\t\t\t\t   stripe->physical + stripe_size - 1,\n\t\t\t\t   bits | EXTENT_NOWAIT,\n\t\t\t\t   NULL, NULL);\n\t}\n}\n\n \nint add_extent_mapping(struct extent_map_tree *tree,\n\t\t       struct extent_map *em, int modified)\n{\n\tint ret = 0;\n\n\tlockdep_assert_held_write(&tree->lock);\n\n\tret = tree_insert(&tree->map, em);\n\tif (ret)\n\t\tgoto out;\n\n\tsetup_extent_mapping(tree, em, modified);\n\tif (test_bit(EXTENT_FLAG_FS_MAPPING, &em->flags)) {\n\t\textent_map_device_set_bits(em, CHUNK_ALLOCATED);\n\t\textent_map_device_clear_bits(em, CHUNK_TRIMMED);\n\t}\nout:\n\treturn ret;\n}\n\nstatic struct extent_map *\n__lookup_extent_mapping(struct extent_map_tree *tree,\n\t\t\tu64 start, u64 len, int strict)\n{\n\tstruct extent_map *em;\n\tstruct rb_node *rb_node;\n\tstruct rb_node *prev_or_next = NULL;\n\tu64 end = range_end(start, len);\n\n\trb_node = __tree_search(&tree->map.rb_root, start, &prev_or_next);\n\tif (!rb_node) {\n\t\tif (prev_or_next)\n\t\t\trb_node = prev_or_next;\n\t\telse\n\t\t\treturn NULL;\n\t}\n\n\tem = rb_entry(rb_node, struct extent_map, rb_node);\n\n\tif (strict && !(end > em->start && start < extent_map_end(em)))\n\t\treturn NULL;\n\n\trefcount_inc(&em->refs);\n\treturn em;\n}\n\n \nstruct extent_map *lookup_extent_mapping(struct extent_map_tree *tree,\n\t\t\t\t\t u64 start, u64 len)\n{\n\treturn __lookup_extent_mapping(tree, start, len, 1);\n}\n\n \nstruct extent_map *search_extent_mapping(struct extent_map_tree *tree,\n\t\t\t\t\t u64 start, u64 len)\n{\n\treturn __lookup_extent_mapping(tree, start, len, 0);\n}\n\n \nvoid remove_extent_mapping(struct extent_map_tree *tree, struct extent_map *em)\n{\n\tlockdep_assert_held_write(&tree->lock);\n\n\tWARN_ON(test_bit(EXTENT_FLAG_PINNED, &em->flags));\n\trb_erase_cached(&em->rb_node, &tree->map);\n\tif (!test_bit(EXTENT_FLAG_LOGGING, &em->flags))\n\t\tlist_del_init(&em->list);\n\tif (test_bit(EXTENT_FLAG_FS_MAPPING, &em->flags))\n\t\textent_map_device_clear_bits(em, CHUNK_ALLOCATED);\n\tRB_CLEAR_NODE(&em->rb_node);\n}\n\nstatic void replace_extent_mapping(struct extent_map_tree *tree,\n\t\t\t\t   struct extent_map *cur,\n\t\t\t\t   struct extent_map *new,\n\t\t\t\t   int modified)\n{\n\tlockdep_assert_held_write(&tree->lock);\n\n\tWARN_ON(test_bit(EXTENT_FLAG_PINNED, &cur->flags));\n\tASSERT(extent_map_in_tree(cur));\n\tif (!test_bit(EXTENT_FLAG_LOGGING, &cur->flags))\n\t\tlist_del_init(&cur->list);\n\trb_replace_node_cached(&cur->rb_node, &new->rb_node, &tree->map);\n\tRB_CLEAR_NODE(&cur->rb_node);\n\n\tsetup_extent_mapping(tree, new, modified);\n}\n\nstatic struct extent_map *next_extent_map(const struct extent_map *em)\n{\n\tstruct rb_node *next;\n\n\tnext = rb_next(&em->rb_node);\n\tif (!next)\n\t\treturn NULL;\n\treturn container_of(next, struct extent_map, rb_node);\n}\n\nstatic struct extent_map *prev_extent_map(struct extent_map *em)\n{\n\tstruct rb_node *prev;\n\n\tprev = rb_prev(&em->rb_node);\n\tif (!prev)\n\t\treturn NULL;\n\treturn container_of(prev, struct extent_map, rb_node);\n}\n\n \nstatic noinline int merge_extent_mapping(struct extent_map_tree *em_tree,\n\t\t\t\t\t struct extent_map *existing,\n\t\t\t\t\t struct extent_map *em,\n\t\t\t\t\t u64 map_start)\n{\n\tstruct extent_map *prev;\n\tstruct extent_map *next;\n\tu64 start;\n\tu64 end;\n\tu64 start_diff;\n\n\tBUG_ON(map_start < em->start || map_start >= extent_map_end(em));\n\n\tif (existing->start > map_start) {\n\t\tnext = existing;\n\t\tprev = prev_extent_map(next);\n\t} else {\n\t\tprev = existing;\n\t\tnext = next_extent_map(prev);\n\t}\n\n\tstart = prev ? extent_map_end(prev) : em->start;\n\tstart = max_t(u64, start, em->start);\n\tend = next ? next->start : extent_map_end(em);\n\tend = min_t(u64, end, extent_map_end(em));\n\tstart_diff = start - em->start;\n\tem->start = start;\n\tem->len = end - start;\n\tif (em->block_start < EXTENT_MAP_LAST_BYTE &&\n\t    !test_bit(EXTENT_FLAG_COMPRESSED, &em->flags)) {\n\t\tem->block_start += start_diff;\n\t\tem->block_len = em->len;\n\t}\n\treturn add_extent_mapping(em_tree, em, 0);\n}\n\n \nint btrfs_add_extent_mapping(struct btrfs_fs_info *fs_info,\n\t\t\t     struct extent_map_tree *em_tree,\n\t\t\t     struct extent_map **em_in, u64 start, u64 len)\n{\n\tint ret;\n\tstruct extent_map *em = *em_in;\n\n\t \n\tif (em->block_start == EXTENT_MAP_INLINE)\n\t\tASSERT(em->start == 0);\n\n\tret = add_extent_mapping(em_tree, em, 0);\n\t \n\tif (ret == -EEXIST) {\n\t\tstruct extent_map *existing;\n\n\t\tret = 0;\n\n\t\texisting = search_extent_mapping(em_tree, start, len);\n\n\t\ttrace_btrfs_handle_em_exist(fs_info, existing, em, start, len);\n\n\t\t \n\t\tif (start >= existing->start &&\n\t\t    start < extent_map_end(existing)) {\n\t\t\tfree_extent_map(em);\n\t\t\t*em_in = existing;\n\t\t\tret = 0;\n\t\t} else {\n\t\t\tu64 orig_start = em->start;\n\t\t\tu64 orig_len = em->len;\n\n\t\t\t \n\t\t\tret = merge_extent_mapping(em_tree, existing,\n\t\t\t\t\t\t   em, start);\n\t\t\tif (ret) {\n\t\t\t\tfree_extent_map(em);\n\t\t\t\t*em_in = NULL;\n\t\t\t\tWARN_ONCE(ret,\n\"unexpected error %d: merge existing(start %llu len %llu) with em(start %llu len %llu)\\n\",\n\t\t\t\t\t  ret, existing->start, existing->len,\n\t\t\t\t\t  orig_start, orig_len);\n\t\t\t}\n\t\t\tfree_extent_map(existing);\n\t\t}\n\t}\n\n\tASSERT(ret == 0 || ret == -EEXIST);\n\treturn ret;\n}\n\n \nstatic void drop_all_extent_maps_fast(struct extent_map_tree *tree)\n{\n\twrite_lock(&tree->lock);\n\twhile (!RB_EMPTY_ROOT(&tree->map.rb_root)) {\n\t\tstruct extent_map *em;\n\t\tstruct rb_node *node;\n\n\t\tnode = rb_first_cached(&tree->map);\n\t\tem = rb_entry(node, struct extent_map, rb_node);\n\t\tclear_bit(EXTENT_FLAG_PINNED, &em->flags);\n\t\tclear_bit(EXTENT_FLAG_LOGGING, &em->flags);\n\t\tremove_extent_mapping(tree, em);\n\t\tfree_extent_map(em);\n\t\tcond_resched_rwlock_write(&tree->lock);\n\t}\n\twrite_unlock(&tree->lock);\n}\n\n \nvoid btrfs_drop_extent_map_range(struct btrfs_inode *inode, u64 start, u64 end,\n\t\t\t\t bool skip_pinned)\n{\n\tstruct extent_map *split;\n\tstruct extent_map *split2;\n\tstruct extent_map *em;\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tu64 len = end - start + 1;\n\n\tWARN_ON(end < start);\n\tif (end == (u64)-1) {\n\t\tif (start == 0 && !skip_pinned) {\n\t\t\tdrop_all_extent_maps_fast(em_tree);\n\t\t\treturn;\n\t\t}\n\t\tlen = (u64)-1;\n\t} else {\n\t\t \n\t\tend++;\n\t}\n\n\t \n\tsplit = alloc_extent_map();\n\tsplit2 = alloc_extent_map();\n\n\twrite_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, start, len);\n\n\twhile (em) {\n\t\t \n\t\tconst u64 em_end = extent_map_end(em);\n\t\tstruct extent_map *next_em = NULL;\n\t\tu64 gen;\n\t\tunsigned long flags;\n\t\tbool modified;\n\t\tbool compressed;\n\n\t\tif (em_end < end) {\n\t\t\tnext_em = next_extent_map(em);\n\t\t\tif (next_em) {\n\t\t\t\tif (next_em->start < end)\n\t\t\t\t\trefcount_inc(&next_em->refs);\n\t\t\t\telse\n\t\t\t\t\tnext_em = NULL;\n\t\t\t}\n\t\t}\n\n\t\tif (skip_pinned && test_bit(EXTENT_FLAG_PINNED, &em->flags)) {\n\t\t\tstart = em_end;\n\t\t\tgoto next;\n\t\t}\n\n\t\tflags = em->flags;\n\t\tclear_bit(EXTENT_FLAG_PINNED, &em->flags);\n\t\t \n\t\tclear_bit(EXTENT_FLAG_LOGGING, &flags);\n\t\tmodified = !list_empty(&em->list);\n\n\t\t \n\t\tif (em->start >= start && em_end <= end)\n\t\t\tgoto remove_em;\n\n\t\tgen = em->generation;\n\t\tcompressed = test_bit(EXTENT_FLAG_COMPRESSED, &em->flags);\n\n\t\tif (em->start < start) {\n\t\t\tif (!split) {\n\t\t\t\tsplit = split2;\n\t\t\t\tsplit2 = NULL;\n\t\t\t\tif (!split)\n\t\t\t\t\tgoto remove_em;\n\t\t\t}\n\t\t\tsplit->start = em->start;\n\t\t\tsplit->len = start - em->start;\n\n\t\t\tif (em->block_start < EXTENT_MAP_LAST_BYTE) {\n\t\t\t\tsplit->orig_start = em->orig_start;\n\t\t\t\tsplit->block_start = em->block_start;\n\n\t\t\t\tif (compressed)\n\t\t\t\t\tsplit->block_len = em->block_len;\n\t\t\t\telse\n\t\t\t\t\tsplit->block_len = split->len;\n\t\t\t\tsplit->orig_block_len = max(split->block_len,\n\t\t\t\t\t\tem->orig_block_len);\n\t\t\t\tsplit->ram_bytes = em->ram_bytes;\n\t\t\t} else {\n\t\t\t\tsplit->orig_start = split->start;\n\t\t\t\tsplit->block_len = 0;\n\t\t\t\tsplit->block_start = em->block_start;\n\t\t\t\tsplit->orig_block_len = 0;\n\t\t\t\tsplit->ram_bytes = split->len;\n\t\t\t}\n\n\t\t\tsplit->generation = gen;\n\t\t\tsplit->flags = flags;\n\t\t\tsplit->compress_type = em->compress_type;\n\t\t\treplace_extent_mapping(em_tree, em, split, modified);\n\t\t\tfree_extent_map(split);\n\t\t\tsplit = split2;\n\t\t\tsplit2 = NULL;\n\t\t}\n\t\tif (em_end > end) {\n\t\t\tif (!split) {\n\t\t\t\tsplit = split2;\n\t\t\t\tsplit2 = NULL;\n\t\t\t\tif (!split)\n\t\t\t\t\tgoto remove_em;\n\t\t\t}\n\t\t\tsplit->start = end;\n\t\t\tsplit->len = em_end - end;\n\t\t\tsplit->block_start = em->block_start;\n\t\t\tsplit->flags = flags;\n\t\t\tsplit->compress_type = em->compress_type;\n\t\t\tsplit->generation = gen;\n\n\t\t\tif (em->block_start < EXTENT_MAP_LAST_BYTE) {\n\t\t\t\tsplit->orig_block_len = max(em->block_len,\n\t\t\t\t\t\t    em->orig_block_len);\n\n\t\t\t\tsplit->ram_bytes = em->ram_bytes;\n\t\t\t\tif (compressed) {\n\t\t\t\t\tsplit->block_len = em->block_len;\n\t\t\t\t\tsplit->orig_start = em->orig_start;\n\t\t\t\t} else {\n\t\t\t\t\tconst u64 diff = start + len - em->start;\n\n\t\t\t\t\tsplit->block_len = split->len;\n\t\t\t\t\tsplit->block_start += diff;\n\t\t\t\t\tsplit->orig_start = em->orig_start;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tsplit->ram_bytes = split->len;\n\t\t\t\tsplit->orig_start = split->start;\n\t\t\t\tsplit->block_len = 0;\n\t\t\t\tsplit->orig_block_len = 0;\n\t\t\t}\n\n\t\t\tif (extent_map_in_tree(em)) {\n\t\t\t\treplace_extent_mapping(em_tree, em, split,\n\t\t\t\t\t\t       modified);\n\t\t\t} else {\n\t\t\t\tint ret;\n\n\t\t\t\tret = add_extent_mapping(em_tree, split,\n\t\t\t\t\t\t\t modified);\n\t\t\t\t \n\t\t\t\tASSERT(ret == 0);\n\t\t\t\tif (WARN_ON(ret != 0) && modified)\n\t\t\t\t\tbtrfs_set_inode_full_sync(inode);\n\t\t\t}\n\t\t\tfree_extent_map(split);\n\t\t\tsplit = NULL;\n\t\t}\nremove_em:\n\t\tif (extent_map_in_tree(em)) {\n\t\t\t \n\t\t\tif ((em->start < start || em_end > end) && modified) {\n\t\t\t\tASSERT(!split);\n\t\t\t\tbtrfs_set_inode_full_sync(inode);\n\t\t\t}\n\t\t\tremove_extent_mapping(em_tree, em);\n\t\t}\n\n\t\t \n\t\tfree_extent_map(em);\nnext:\n\t\t \n\t\tfree_extent_map(em);\n\n\t\tem = next_em;\n\t}\n\n\twrite_unlock(&em_tree->lock);\n\n\tfree_extent_map(split);\n\tfree_extent_map(split2);\n}\n\n \nint btrfs_replace_extent_map_range(struct btrfs_inode *inode,\n\t\t\t\t   struct extent_map *new_em,\n\t\t\t\t   bool modified)\n{\n\tconst u64 end = new_em->start + new_em->len - 1;\n\tstruct extent_map_tree *tree = &inode->extent_tree;\n\tint ret;\n\n\tASSERT(!extent_map_in_tree(new_em));\n\n\t \n\tdo {\n\t\tbtrfs_drop_extent_map_range(inode, new_em->start, end, false);\n\t\twrite_lock(&tree->lock);\n\t\tret = add_extent_mapping(tree, new_em, modified);\n\t\twrite_unlock(&tree->lock);\n\t} while (ret == -EEXIST);\n\n\treturn ret;\n}\n\n \nint split_extent_map(struct btrfs_inode *inode, u64 start, u64 len, u64 pre,\n\t\t     u64 new_logical)\n{\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tstruct extent_map *em;\n\tstruct extent_map *split_pre = NULL;\n\tstruct extent_map *split_mid = NULL;\n\tint ret = 0;\n\tunsigned long flags;\n\n\tASSERT(pre != 0);\n\tASSERT(pre < len);\n\n\tsplit_pre = alloc_extent_map();\n\tif (!split_pre)\n\t\treturn -ENOMEM;\n\tsplit_mid = alloc_extent_map();\n\tif (!split_mid) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free_pre;\n\t}\n\n\tlock_extent(&inode->io_tree, start, start + len - 1, NULL);\n\twrite_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, start, len);\n\tif (!em) {\n\t\tret = -EIO;\n\t\tgoto out_unlock;\n\t}\n\n\tASSERT(em->len == len);\n\tASSERT(!test_bit(EXTENT_FLAG_COMPRESSED, &em->flags));\n\tASSERT(em->block_start < EXTENT_MAP_LAST_BYTE);\n\tASSERT(test_bit(EXTENT_FLAG_PINNED, &em->flags));\n\tASSERT(!test_bit(EXTENT_FLAG_LOGGING, &em->flags));\n\tASSERT(!list_empty(&em->list));\n\n\tflags = em->flags;\n\tclear_bit(EXTENT_FLAG_PINNED, &em->flags);\n\n\t \n\tsplit_pre->start = em->start;\n\tsplit_pre->len = pre;\n\tsplit_pre->orig_start = split_pre->start;\n\tsplit_pre->block_start = new_logical;\n\tsplit_pre->block_len = split_pre->len;\n\tsplit_pre->orig_block_len = split_pre->block_len;\n\tsplit_pre->ram_bytes = split_pre->len;\n\tsplit_pre->flags = flags;\n\tsplit_pre->compress_type = em->compress_type;\n\tsplit_pre->generation = em->generation;\n\n\treplace_extent_mapping(em_tree, em, split_pre, 1);\n\n\t \n\n\t \n\tsplit_mid->start = em->start + pre;\n\tsplit_mid->len = em->len - pre;\n\tsplit_mid->orig_start = split_mid->start;\n\tsplit_mid->block_start = em->block_start + pre;\n\tsplit_mid->block_len = split_mid->len;\n\tsplit_mid->orig_block_len = split_mid->block_len;\n\tsplit_mid->ram_bytes = split_mid->len;\n\tsplit_mid->flags = flags;\n\tsplit_mid->compress_type = em->compress_type;\n\tsplit_mid->generation = em->generation;\n\tadd_extent_mapping(em_tree, split_mid, 1);\n\n\t \n\tfree_extent_map(em);\n\t \n\tfree_extent_map(em);\n\nout_unlock:\n\twrite_unlock(&em_tree->lock);\n\tunlock_extent(&inode->io_tree, start, start + len - 1, NULL);\n\tfree_extent_map(split_mid);\nout_free_pre:\n\tfree_extent_map(split_pre);\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}