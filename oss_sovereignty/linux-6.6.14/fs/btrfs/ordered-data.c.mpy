{
  "module_name": "ordered-data.c",
  "hash_id": "bc1fa3c7ef82115ffe4e073d83c8ed60e7fce7acebb2838d91c3654981650264",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/ordered-data.c",
  "human_readable_source": "\n \n\n#include <linux/slab.h>\n#include <linux/blkdev.h>\n#include <linux/writeback.h>\n#include <linux/sched/mm.h>\n#include \"messages.h\"\n#include \"misc.h\"\n#include \"ctree.h\"\n#include \"transaction.h\"\n#include \"btrfs_inode.h\"\n#include \"extent_io.h\"\n#include \"disk-io.h\"\n#include \"compression.h\"\n#include \"delalloc-space.h\"\n#include \"qgroup.h\"\n#include \"subpage.h\"\n#include \"file.h\"\n#include \"super.h\"\n\nstatic struct kmem_cache *btrfs_ordered_extent_cache;\n\nstatic u64 entry_end(struct btrfs_ordered_extent *entry)\n{\n\tif (entry->file_offset + entry->num_bytes < entry->file_offset)\n\t\treturn (u64)-1;\n\treturn entry->file_offset + entry->num_bytes;\n}\n\n \nstatic struct rb_node *tree_insert(struct rb_root *root, u64 file_offset,\n\t\t\t\t   struct rb_node *node)\n{\n\tstruct rb_node **p = &root->rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct btrfs_ordered_extent *entry;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tentry = rb_entry(parent, struct btrfs_ordered_extent, rb_node);\n\n\t\tif (file_offset < entry->file_offset)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (file_offset >= entry_end(entry))\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\treturn parent;\n\t}\n\n\trb_link_node(node, parent, p);\n\trb_insert_color(node, root);\n\treturn NULL;\n}\n\n \nstatic struct rb_node *__tree_search(struct rb_root *root, u64 file_offset,\n\t\t\t\t     struct rb_node **prev_ret)\n{\n\tstruct rb_node *n = root->rb_node;\n\tstruct rb_node *prev = NULL;\n\tstruct rb_node *test;\n\tstruct btrfs_ordered_extent *entry;\n\tstruct btrfs_ordered_extent *prev_entry = NULL;\n\n\twhile (n) {\n\t\tentry = rb_entry(n, struct btrfs_ordered_extent, rb_node);\n\t\tprev = n;\n\t\tprev_entry = entry;\n\n\t\tif (file_offset < entry->file_offset)\n\t\t\tn = n->rb_left;\n\t\telse if (file_offset >= entry_end(entry))\n\t\t\tn = n->rb_right;\n\t\telse\n\t\t\treturn n;\n\t}\n\tif (!prev_ret)\n\t\treturn NULL;\n\n\twhile (prev && file_offset >= entry_end(prev_entry)) {\n\t\ttest = rb_next(prev);\n\t\tif (!test)\n\t\t\tbreak;\n\t\tprev_entry = rb_entry(test, struct btrfs_ordered_extent,\n\t\t\t\t      rb_node);\n\t\tif (file_offset < entry_end(prev_entry))\n\t\t\tbreak;\n\n\t\tprev = test;\n\t}\n\tif (prev)\n\t\tprev_entry = rb_entry(prev, struct btrfs_ordered_extent,\n\t\t\t\t      rb_node);\n\twhile (prev && file_offset < entry_end(prev_entry)) {\n\t\ttest = rb_prev(prev);\n\t\tif (!test)\n\t\t\tbreak;\n\t\tprev_entry = rb_entry(test, struct btrfs_ordered_extent,\n\t\t\t\t      rb_node);\n\t\tprev = test;\n\t}\n\t*prev_ret = prev;\n\treturn NULL;\n}\n\nstatic int range_overlaps(struct btrfs_ordered_extent *entry, u64 file_offset,\n\t\t\t  u64 len)\n{\n\tif (file_offset + len <= entry->file_offset ||\n\t    entry->file_offset + entry->num_bytes <= file_offset)\n\t\treturn 0;\n\treturn 1;\n}\n\n \nstatic inline struct rb_node *tree_search(struct btrfs_ordered_inode_tree *tree,\n\t\t\t\t\t  u64 file_offset)\n{\n\tstruct rb_root *root = &tree->tree;\n\tstruct rb_node *prev = NULL;\n\tstruct rb_node *ret;\n\tstruct btrfs_ordered_extent *entry;\n\n\tif (tree->last) {\n\t\tentry = rb_entry(tree->last, struct btrfs_ordered_extent,\n\t\t\t\t rb_node);\n\t\tif (in_range(file_offset, entry->file_offset, entry->num_bytes))\n\t\t\treturn tree->last;\n\t}\n\tret = __tree_search(root, file_offset, &prev);\n\tif (!ret)\n\t\tret = prev;\n\tif (ret)\n\t\ttree->last = ret;\n\treturn ret;\n}\n\nstatic struct btrfs_ordered_extent *alloc_ordered_extent(\n\t\t\tstruct btrfs_inode *inode, u64 file_offset, u64 num_bytes,\n\t\t\tu64 ram_bytes, u64 disk_bytenr, u64 disk_num_bytes,\n\t\t\tu64 offset, unsigned long flags, int compress_type)\n{\n\tstruct btrfs_ordered_extent *entry;\n\tint ret;\n\tu64 qgroup_rsv = 0;\n\n\tif (flags &\n\t    ((1 << BTRFS_ORDERED_NOCOW) | (1 << BTRFS_ORDERED_PREALLOC))) {\n\t\t \n\t\tret = btrfs_qgroup_free_data(inode, NULL, file_offset, num_bytes, &qgroup_rsv);\n\t\tif (ret < 0)\n\t\t\treturn ERR_PTR(ret);\n\t} else {\n\t\t \n\t\tret = btrfs_qgroup_release_data(inode, file_offset, num_bytes, &qgroup_rsv);\n\t\tif (ret < 0)\n\t\t\treturn ERR_PTR(ret);\n\t}\n\tentry = kmem_cache_zalloc(btrfs_ordered_extent_cache, GFP_NOFS);\n\tif (!entry)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tentry->file_offset = file_offset;\n\tentry->num_bytes = num_bytes;\n\tentry->ram_bytes = ram_bytes;\n\tentry->disk_bytenr = disk_bytenr;\n\tentry->disk_num_bytes = disk_num_bytes;\n\tentry->offset = offset;\n\tentry->bytes_left = num_bytes;\n\tentry->inode = igrab(&inode->vfs_inode);\n\tentry->compress_type = compress_type;\n\tentry->truncated_len = (u64)-1;\n\tentry->qgroup_rsv = qgroup_rsv;\n\tentry->flags = flags;\n\trefcount_set(&entry->refs, 1);\n\tinit_waitqueue_head(&entry->wait);\n\tINIT_LIST_HEAD(&entry->list);\n\tINIT_LIST_HEAD(&entry->log_list);\n\tINIT_LIST_HEAD(&entry->root_extent_list);\n\tINIT_LIST_HEAD(&entry->work_list);\n\tinit_completion(&entry->completion);\n\n\t \n\tspin_lock(&inode->lock);\n\tbtrfs_mod_outstanding_extents(inode, 1);\n\tspin_unlock(&inode->lock);\n\n\treturn entry;\n}\n\nstatic void insert_ordered_extent(struct btrfs_ordered_extent *entry)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(entry->inode);\n\tstruct btrfs_ordered_inode_tree *tree = &inode->ordered_tree;\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct rb_node *node;\n\n\ttrace_btrfs_ordered_extent_add(inode, entry);\n\n\tpercpu_counter_add_batch(&fs_info->ordered_bytes, entry->num_bytes,\n\t\t\t\t fs_info->delalloc_batch);\n\n\t \n\trefcount_inc(&entry->refs);\n\n\tspin_lock_irq(&tree->lock);\n\tnode = tree_insert(&tree->tree, entry->file_offset, &entry->rb_node);\n\tif (node)\n\t\tbtrfs_panic(fs_info, -EEXIST,\n\t\t\t\t\"inconsistency in ordered tree at offset %llu\",\n\t\t\t\tentry->file_offset);\n\tspin_unlock_irq(&tree->lock);\n\n\tspin_lock(&root->ordered_extent_lock);\n\tlist_add_tail(&entry->root_extent_list,\n\t\t      &root->ordered_extents);\n\troot->nr_ordered_extents++;\n\tif (root->nr_ordered_extents == 1) {\n\t\tspin_lock(&fs_info->ordered_root_lock);\n\t\tBUG_ON(!list_empty(&root->ordered_root));\n\t\tlist_add_tail(&root->ordered_root, &fs_info->ordered_roots);\n\t\tspin_unlock(&fs_info->ordered_root_lock);\n\t}\n\tspin_unlock(&root->ordered_extent_lock);\n}\n\n \nstruct btrfs_ordered_extent *btrfs_alloc_ordered_extent(\n\t\t\tstruct btrfs_inode *inode, u64 file_offset,\n\t\t\tu64 num_bytes, u64 ram_bytes, u64 disk_bytenr,\n\t\t\tu64 disk_num_bytes, u64 offset, unsigned long flags,\n\t\t\tint compress_type)\n{\n\tstruct btrfs_ordered_extent *entry;\n\n\tASSERT((flags & ~BTRFS_ORDERED_TYPE_FLAGS) == 0);\n\n\tentry = alloc_ordered_extent(inode, file_offset, num_bytes, ram_bytes,\n\t\t\t\t     disk_bytenr, disk_num_bytes, offset, flags,\n\t\t\t\t     compress_type);\n\tif (!IS_ERR(entry))\n\t\tinsert_ordered_extent(entry);\n\treturn entry;\n}\n\n \nvoid btrfs_add_ordered_sum(struct btrfs_ordered_extent *entry,\n\t\t\t   struct btrfs_ordered_sum *sum)\n{\n\tstruct btrfs_ordered_inode_tree *tree;\n\n\ttree = &BTRFS_I(entry->inode)->ordered_tree;\n\tspin_lock_irq(&tree->lock);\n\tlist_add_tail(&sum->list, &entry->list);\n\tspin_unlock_irq(&tree->lock);\n}\n\nstatic void finish_ordered_fn(struct btrfs_work *work)\n{\n\tstruct btrfs_ordered_extent *ordered_extent;\n\n\tordered_extent = container_of(work, struct btrfs_ordered_extent, work);\n\tbtrfs_finish_ordered_io(ordered_extent);\n}\n\nstatic bool can_finish_ordered_extent(struct btrfs_ordered_extent *ordered,\n\t\t\t\t      struct page *page, u64 file_offset,\n\t\t\t\t      u64 len, bool uptodate)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(ordered->inode);\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\n\tlockdep_assert_held(&inode->ordered_tree.lock);\n\n\tif (page) {\n\t\tASSERT(page->mapping);\n\t\tASSERT(page_offset(page) <= file_offset);\n\t\tASSERT(file_offset + len <= page_offset(page) + PAGE_SIZE);\n\n\t\t \n\t\tif (!btrfs_page_test_ordered(fs_info, page, file_offset, len))\n\t\t\treturn false;\n\t\tbtrfs_page_clear_ordered(fs_info, page, file_offset, len);\n\t}\n\n\t \n\tif (WARN_ON_ONCE(len > ordered->bytes_left)) {\n\t\tbtrfs_crit(fs_info,\n\"bad ordered extent accounting, root=%llu ino=%llu OE offset=%llu OE len=%llu to_dec=%llu left=%llu\",\n\t\t\t   inode->root->root_key.objectid, btrfs_ino(inode),\n\t\t\t   ordered->file_offset, ordered->num_bytes,\n\t\t\t   len, ordered->bytes_left);\n\t\tordered->bytes_left = 0;\n\t} else {\n\t\tordered->bytes_left -= len;\n\t}\n\n\tif (!uptodate)\n\t\tset_bit(BTRFS_ORDERED_IOERR, &ordered->flags);\n\n\tif (ordered->bytes_left)\n\t\treturn false;\n\n\t \n\tset_bit(BTRFS_ORDERED_IO_DONE, &ordered->flags);\n\tcond_wake_up(&ordered->wait);\n\trefcount_inc(&ordered->refs);\n\ttrace_btrfs_ordered_extent_mark_finished(inode, ordered);\n\treturn true;\n}\n\nstatic void btrfs_queue_ordered_fn(struct btrfs_ordered_extent *ordered)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(ordered->inode);\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tstruct btrfs_workqueue *wq = btrfs_is_free_space_inode(inode) ?\n\t\tfs_info->endio_freespace_worker : fs_info->endio_write_workers;\n\n\tbtrfs_init_work(&ordered->work, finish_ordered_fn, NULL, NULL);\n\tbtrfs_queue_work(wq, &ordered->work);\n}\n\nbool btrfs_finish_ordered_extent(struct btrfs_ordered_extent *ordered,\n\t\t\t\t struct page *page, u64 file_offset, u64 len,\n\t\t\t\t bool uptodate)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(ordered->inode);\n\tunsigned long flags;\n\tbool ret;\n\n\ttrace_btrfs_finish_ordered_extent(inode, file_offset, len, uptodate);\n\n\tspin_lock_irqsave(&inode->ordered_tree.lock, flags);\n\tret = can_finish_ordered_extent(ordered, page, file_offset, len, uptodate);\n\tspin_unlock_irqrestore(&inode->ordered_tree.lock, flags);\n\n\tif (ret)\n\t\tbtrfs_queue_ordered_fn(ordered);\n\treturn ret;\n}\n\n \nvoid btrfs_mark_ordered_io_finished(struct btrfs_inode *inode,\n\t\t\t\t    struct page *page, u64 file_offset,\n\t\t\t\t    u64 num_bytes, bool uptodate)\n{\n\tstruct btrfs_ordered_inode_tree *tree = &inode->ordered_tree;\n\tstruct rb_node *node;\n\tstruct btrfs_ordered_extent *entry = NULL;\n\tunsigned long flags;\n\tu64 cur = file_offset;\n\n\ttrace_btrfs_writepage_end_io_hook(inode, file_offset,\n\t\t\t\t\t  file_offset + num_bytes - 1,\n\t\t\t\t\t  uptodate);\n\n\tspin_lock_irqsave(&tree->lock, flags);\n\twhile (cur < file_offset + num_bytes) {\n\t\tu64 entry_end;\n\t\tu64 end;\n\t\tu32 len;\n\n\t\tnode = tree_search(tree, cur);\n\t\t \n\t\tif (!node)\n\t\t\tbreak;\n\n\t\tentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\n\t\tentry_end = entry->file_offset + entry->num_bytes;\n\t\t \n\t\tif (cur >= entry_end) {\n\t\t\tnode = rb_next(node);\n\t\t\t \n\t\t\tif (!node)\n\t\t\t\tbreak;\n\t\t\tentry = rb_entry(node, struct btrfs_ordered_extent,\n\t\t\t\t\t rb_node);\n\n\t\t\t \n\t\t\tcur = entry->file_offset;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tif (cur < entry->file_offset) {\n\t\t\tcur = entry->file_offset;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tend = min(entry->file_offset + entry->num_bytes,\n\t\t\t  file_offset + num_bytes) - 1;\n\t\tASSERT(end + 1 - cur < U32_MAX);\n\t\tlen = end + 1 - cur;\n\n\t\tif (can_finish_ordered_extent(entry, page, cur, len, uptodate)) {\n\t\t\tspin_unlock_irqrestore(&tree->lock, flags);\n\t\t\tbtrfs_queue_ordered_fn(entry);\n\t\t\tspin_lock_irqsave(&tree->lock, flags);\n\t\t}\n\t\tcur += len;\n\t}\n\tspin_unlock_irqrestore(&tree->lock, flags);\n}\n\n \nbool btrfs_dec_test_ordered_pending(struct btrfs_inode *inode,\n\t\t\t\t    struct btrfs_ordered_extent **cached,\n\t\t\t\t    u64 file_offset, u64 io_size)\n{\n\tstruct btrfs_ordered_inode_tree *tree = &inode->ordered_tree;\n\tstruct rb_node *node;\n\tstruct btrfs_ordered_extent *entry = NULL;\n\tunsigned long flags;\n\tbool finished = false;\n\n\tspin_lock_irqsave(&tree->lock, flags);\n\tif (cached && *cached) {\n\t\tentry = *cached;\n\t\tgoto have_entry;\n\t}\n\n\tnode = tree_search(tree, file_offset);\n\tif (!node)\n\t\tgoto out;\n\n\tentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\nhave_entry:\n\tif (!in_range(file_offset, entry->file_offset, entry->num_bytes))\n\t\tgoto out;\n\n\tif (io_size > entry->bytes_left)\n\t\tbtrfs_crit(inode->root->fs_info,\n\t\t\t   \"bad ordered accounting left %llu size %llu\",\n\t\t       entry->bytes_left, io_size);\n\n\tentry->bytes_left -= io_size;\n\n\tif (entry->bytes_left == 0) {\n\t\t \n\t\tfinished = !test_and_set_bit(BTRFS_ORDERED_IO_DONE, &entry->flags);\n\t\t \n\t\tcond_wake_up_nomb(&entry->wait);\n\t}\nout:\n\tif (finished && cached && entry) {\n\t\t*cached = entry;\n\t\trefcount_inc(&entry->refs);\n\t\ttrace_btrfs_ordered_extent_dec_test_pending(inode, entry);\n\t}\n\tspin_unlock_irqrestore(&tree->lock, flags);\n\treturn finished;\n}\n\n \nvoid btrfs_put_ordered_extent(struct btrfs_ordered_extent *entry)\n{\n\tstruct list_head *cur;\n\tstruct btrfs_ordered_sum *sum;\n\n\ttrace_btrfs_ordered_extent_put(BTRFS_I(entry->inode), entry);\n\n\tif (refcount_dec_and_test(&entry->refs)) {\n\t\tASSERT(list_empty(&entry->root_extent_list));\n\t\tASSERT(list_empty(&entry->log_list));\n\t\tASSERT(RB_EMPTY_NODE(&entry->rb_node));\n\t\tif (entry->inode)\n\t\t\tbtrfs_add_delayed_iput(BTRFS_I(entry->inode));\n\t\twhile (!list_empty(&entry->list)) {\n\t\t\tcur = entry->list.next;\n\t\t\tsum = list_entry(cur, struct btrfs_ordered_sum, list);\n\t\t\tlist_del(&sum->list);\n\t\t\tkvfree(sum);\n\t\t}\n\t\tkmem_cache_free(btrfs_ordered_extent_cache, entry);\n\t}\n}\n\n \nvoid btrfs_remove_ordered_extent(struct btrfs_inode *btrfs_inode,\n\t\t\t\t struct btrfs_ordered_extent *entry)\n{\n\tstruct btrfs_ordered_inode_tree *tree;\n\tstruct btrfs_root *root = btrfs_inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct rb_node *node;\n\tbool pending;\n\tbool freespace_inode;\n\n\t \n\tfreespace_inode = btrfs_is_free_space_inode(btrfs_inode);\n\n\tbtrfs_lockdep_acquire(fs_info, btrfs_trans_pending_ordered);\n\t \n\tspin_lock(&btrfs_inode->lock);\n\tbtrfs_mod_outstanding_extents(btrfs_inode, -1);\n\tspin_unlock(&btrfs_inode->lock);\n\tif (root != fs_info->tree_root) {\n\t\tu64 release;\n\n\t\tif (test_bit(BTRFS_ORDERED_ENCODED, &entry->flags))\n\t\t\trelease = entry->disk_num_bytes;\n\t\telse\n\t\t\trelease = entry->num_bytes;\n\t\tbtrfs_delalloc_release_metadata(btrfs_inode, release,\n\t\t\t\t\t\ttest_bit(BTRFS_ORDERED_IOERR,\n\t\t\t\t\t\t\t &entry->flags));\n\t}\n\n\tpercpu_counter_add_batch(&fs_info->ordered_bytes, -entry->num_bytes,\n\t\t\t\t fs_info->delalloc_batch);\n\n\ttree = &btrfs_inode->ordered_tree;\n\tspin_lock_irq(&tree->lock);\n\tnode = &entry->rb_node;\n\trb_erase(node, &tree->tree);\n\tRB_CLEAR_NODE(node);\n\tif (tree->last == node)\n\t\ttree->last = NULL;\n\tset_bit(BTRFS_ORDERED_COMPLETE, &entry->flags);\n\tpending = test_and_clear_bit(BTRFS_ORDERED_PENDING, &entry->flags);\n\tspin_unlock_irq(&tree->lock);\n\n\t \n\tif (pending) {\n\t\tstruct btrfs_transaction *trans;\n\n\t\t \n\t\tspin_lock(&fs_info->trans_lock);\n\t\ttrans = fs_info->running_transaction;\n\t\tif (trans)\n\t\t\trefcount_inc(&trans->use_count);\n\t\tspin_unlock(&fs_info->trans_lock);\n\n\t\tASSERT(trans || BTRFS_FS_ERROR(fs_info));\n\t\tif (trans) {\n\t\t\tif (atomic_dec_and_test(&trans->pending_ordered))\n\t\t\t\twake_up(&trans->pending_wait);\n\t\t\tbtrfs_put_transaction(trans);\n\t\t}\n\t}\n\n\tbtrfs_lockdep_release(fs_info, btrfs_trans_pending_ordered);\n\n\tspin_lock(&root->ordered_extent_lock);\n\tlist_del_init(&entry->root_extent_list);\n\troot->nr_ordered_extents--;\n\n\ttrace_btrfs_ordered_extent_remove(btrfs_inode, entry);\n\n\tif (!root->nr_ordered_extents) {\n\t\tspin_lock(&fs_info->ordered_root_lock);\n\t\tBUG_ON(list_empty(&root->ordered_root));\n\t\tlist_del_init(&root->ordered_root);\n\t\tspin_unlock(&fs_info->ordered_root_lock);\n\t}\n\tspin_unlock(&root->ordered_extent_lock);\n\twake_up(&entry->wait);\n\tif (!freespace_inode)\n\t\tbtrfs_lockdep_release(fs_info, btrfs_ordered_extent);\n}\n\nstatic void btrfs_run_ordered_extent_work(struct btrfs_work *work)\n{\n\tstruct btrfs_ordered_extent *ordered;\n\n\tordered = container_of(work, struct btrfs_ordered_extent, flush_work);\n\tbtrfs_start_ordered_extent(ordered);\n\tcomplete(&ordered->completion);\n}\n\n \nu64 btrfs_wait_ordered_extents(struct btrfs_root *root, u64 nr,\n\t\t\t       const u64 range_start, const u64 range_len)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tLIST_HEAD(splice);\n\tLIST_HEAD(skipped);\n\tLIST_HEAD(works);\n\tstruct btrfs_ordered_extent *ordered, *next;\n\tu64 count = 0;\n\tconst u64 range_end = range_start + range_len;\n\n\tmutex_lock(&root->ordered_extent_mutex);\n\tspin_lock(&root->ordered_extent_lock);\n\tlist_splice_init(&root->ordered_extents, &splice);\n\twhile (!list_empty(&splice) && nr) {\n\t\tordered = list_first_entry(&splice, struct btrfs_ordered_extent,\n\t\t\t\t\t   root_extent_list);\n\n\t\tif (range_end <= ordered->disk_bytenr ||\n\t\t    ordered->disk_bytenr + ordered->disk_num_bytes <= range_start) {\n\t\t\tlist_move_tail(&ordered->root_extent_list, &skipped);\n\t\t\tcond_resched_lock(&root->ordered_extent_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tlist_move_tail(&ordered->root_extent_list,\n\t\t\t       &root->ordered_extents);\n\t\trefcount_inc(&ordered->refs);\n\t\tspin_unlock(&root->ordered_extent_lock);\n\n\t\tbtrfs_init_work(&ordered->flush_work,\n\t\t\t\tbtrfs_run_ordered_extent_work, NULL, NULL);\n\t\tlist_add_tail(&ordered->work_list, &works);\n\t\tbtrfs_queue_work(fs_info->flush_workers, &ordered->flush_work);\n\n\t\tcond_resched();\n\t\tspin_lock(&root->ordered_extent_lock);\n\t\tif (nr != U64_MAX)\n\t\t\tnr--;\n\t\tcount++;\n\t}\n\tlist_splice_tail(&skipped, &root->ordered_extents);\n\tlist_splice_tail(&splice, &root->ordered_extents);\n\tspin_unlock(&root->ordered_extent_lock);\n\n\tlist_for_each_entry_safe(ordered, next, &works, work_list) {\n\t\tlist_del_init(&ordered->work_list);\n\t\twait_for_completion(&ordered->completion);\n\t\tbtrfs_put_ordered_extent(ordered);\n\t\tcond_resched();\n\t}\n\tmutex_unlock(&root->ordered_extent_mutex);\n\n\treturn count;\n}\n\nvoid btrfs_wait_ordered_roots(struct btrfs_fs_info *fs_info, u64 nr,\n\t\t\t     const u64 range_start, const u64 range_len)\n{\n\tstruct btrfs_root *root;\n\tLIST_HEAD(splice);\n\tu64 done;\n\n\tmutex_lock(&fs_info->ordered_operations_mutex);\n\tspin_lock(&fs_info->ordered_root_lock);\n\tlist_splice_init(&fs_info->ordered_roots, &splice);\n\twhile (!list_empty(&splice) && nr) {\n\t\troot = list_first_entry(&splice, struct btrfs_root,\n\t\t\t\t\tordered_root);\n\t\troot = btrfs_grab_root(root);\n\t\tBUG_ON(!root);\n\t\tlist_move_tail(&root->ordered_root,\n\t\t\t       &fs_info->ordered_roots);\n\t\tspin_unlock(&fs_info->ordered_root_lock);\n\n\t\tdone = btrfs_wait_ordered_extents(root, nr,\n\t\t\t\t\t\t  range_start, range_len);\n\t\tbtrfs_put_root(root);\n\n\t\tspin_lock(&fs_info->ordered_root_lock);\n\t\tif (nr != U64_MAX) {\n\t\t\tnr -= done;\n\t\t}\n\t}\n\tlist_splice_tail(&splice, &fs_info->ordered_roots);\n\tspin_unlock(&fs_info->ordered_root_lock);\n\tmutex_unlock(&fs_info->ordered_operations_mutex);\n}\n\n \nvoid btrfs_start_ordered_extent(struct btrfs_ordered_extent *entry)\n{\n\tu64 start = entry->file_offset;\n\tu64 end = start + entry->num_bytes - 1;\n\tstruct btrfs_inode *inode = BTRFS_I(entry->inode);\n\tbool freespace_inode;\n\n\ttrace_btrfs_ordered_extent_start(inode, entry);\n\n\t \n\tfreespace_inode = btrfs_is_free_space_inode(inode);\n\n\t \n\tif (!test_bit(BTRFS_ORDERED_DIRECT, &entry->flags))\n\t\tfilemap_fdatawrite_range(inode->vfs_inode.i_mapping, start, end);\n\n\tif (!freespace_inode)\n\t\tbtrfs_might_wait_for_event(inode->root->fs_info, btrfs_ordered_extent);\n\twait_event(entry->wait, test_bit(BTRFS_ORDERED_COMPLETE, &entry->flags));\n}\n\n \nint btrfs_wait_ordered_range(struct inode *inode, u64 start, u64 len)\n{\n\tint ret = 0;\n\tint ret_wb = 0;\n\tu64 end;\n\tu64 orig_end;\n\tstruct btrfs_ordered_extent *ordered;\n\n\tif (start + len < start) {\n\t\torig_end = OFFSET_MAX;\n\t} else {\n\t\torig_end = start + len - 1;\n\t\tif (orig_end > OFFSET_MAX)\n\t\t\torig_end = OFFSET_MAX;\n\t}\n\n\t \n\tret = btrfs_fdatawrite_range(inode, start, orig_end);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret_wb = filemap_fdatawait_range(inode->i_mapping, start, orig_end);\n\n\tend = orig_end;\n\twhile (1) {\n\t\tordered = btrfs_lookup_first_ordered_extent(BTRFS_I(inode), end);\n\t\tif (!ordered)\n\t\t\tbreak;\n\t\tif (ordered->file_offset > orig_end) {\n\t\t\tbtrfs_put_ordered_extent(ordered);\n\t\t\tbreak;\n\t\t}\n\t\tif (ordered->file_offset + ordered->num_bytes <= start) {\n\t\t\tbtrfs_put_ordered_extent(ordered);\n\t\t\tbreak;\n\t\t}\n\t\tbtrfs_start_ordered_extent(ordered);\n\t\tend = ordered->file_offset;\n\t\t \n\t\tif (test_bit(BTRFS_ORDERED_IOERR, &ordered->flags))\n\t\t\tret = -EIO;\n\t\tbtrfs_put_ordered_extent(ordered);\n\t\tif (end == 0 || end == start)\n\t\t\tbreak;\n\t\tend--;\n\t}\n\treturn ret_wb ? ret_wb : ret;\n}\n\n \nstruct btrfs_ordered_extent *btrfs_lookup_ordered_extent(struct btrfs_inode *inode,\n\t\t\t\t\t\t\t u64 file_offset)\n{\n\tstruct btrfs_ordered_inode_tree *tree;\n\tstruct rb_node *node;\n\tstruct btrfs_ordered_extent *entry = NULL;\n\tunsigned long flags;\n\n\ttree = &inode->ordered_tree;\n\tspin_lock_irqsave(&tree->lock, flags);\n\tnode = tree_search(tree, file_offset);\n\tif (!node)\n\t\tgoto out;\n\n\tentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\n\tif (!in_range(file_offset, entry->file_offset, entry->num_bytes))\n\t\tentry = NULL;\n\tif (entry) {\n\t\trefcount_inc(&entry->refs);\n\t\ttrace_btrfs_ordered_extent_lookup(inode, entry);\n\t}\nout:\n\tspin_unlock_irqrestore(&tree->lock, flags);\n\treturn entry;\n}\n\n \nstruct btrfs_ordered_extent *btrfs_lookup_ordered_range(\n\t\tstruct btrfs_inode *inode, u64 file_offset, u64 len)\n{\n\tstruct btrfs_ordered_inode_tree *tree;\n\tstruct rb_node *node;\n\tstruct btrfs_ordered_extent *entry = NULL;\n\n\ttree = &inode->ordered_tree;\n\tspin_lock_irq(&tree->lock);\n\tnode = tree_search(tree, file_offset);\n\tif (!node) {\n\t\tnode = tree_search(tree, file_offset + len);\n\t\tif (!node)\n\t\t\tgoto out;\n\t}\n\n\twhile (1) {\n\t\tentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\n\t\tif (range_overlaps(entry, file_offset, len))\n\t\t\tbreak;\n\n\t\tif (entry->file_offset >= file_offset + len) {\n\t\t\tentry = NULL;\n\t\t\tbreak;\n\t\t}\n\t\tentry = NULL;\n\t\tnode = rb_next(node);\n\t\tif (!node)\n\t\t\tbreak;\n\t}\nout:\n\tif (entry) {\n\t\trefcount_inc(&entry->refs);\n\t\ttrace_btrfs_ordered_extent_lookup_range(inode, entry);\n\t}\n\tspin_unlock_irq(&tree->lock);\n\treturn entry;\n}\n\n \nvoid btrfs_get_ordered_extents_for_logging(struct btrfs_inode *inode,\n\t\t\t\t\t   struct list_head *list)\n{\n\tstruct btrfs_ordered_inode_tree *tree = &inode->ordered_tree;\n\tstruct rb_node *n;\n\n\tASSERT(inode_is_locked(&inode->vfs_inode));\n\n\tspin_lock_irq(&tree->lock);\n\tfor (n = rb_first(&tree->tree); n; n = rb_next(n)) {\n\t\tstruct btrfs_ordered_extent *ordered;\n\n\t\tordered = rb_entry(n, struct btrfs_ordered_extent, rb_node);\n\n\t\tif (test_bit(BTRFS_ORDERED_LOGGED, &ordered->flags))\n\t\t\tcontinue;\n\n\t\tASSERT(list_empty(&ordered->log_list));\n\t\tlist_add_tail(&ordered->log_list, list);\n\t\trefcount_inc(&ordered->refs);\n\t\ttrace_btrfs_ordered_extent_lookup_for_logging(inode, ordered);\n\t}\n\tspin_unlock_irq(&tree->lock);\n}\n\n \nstruct btrfs_ordered_extent *\nbtrfs_lookup_first_ordered_extent(struct btrfs_inode *inode, u64 file_offset)\n{\n\tstruct btrfs_ordered_inode_tree *tree;\n\tstruct rb_node *node;\n\tstruct btrfs_ordered_extent *entry = NULL;\n\n\ttree = &inode->ordered_tree;\n\tspin_lock_irq(&tree->lock);\n\tnode = tree_search(tree, file_offset);\n\tif (!node)\n\t\tgoto out;\n\n\tentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\n\trefcount_inc(&entry->refs);\n\ttrace_btrfs_ordered_extent_lookup_first(inode, entry);\nout:\n\tspin_unlock_irq(&tree->lock);\n\treturn entry;\n}\n\n \nstruct btrfs_ordered_extent *btrfs_lookup_first_ordered_range(\n\t\t\tstruct btrfs_inode *inode, u64 file_offset, u64 len)\n{\n\tstruct btrfs_ordered_inode_tree *tree = &inode->ordered_tree;\n\tstruct rb_node *node;\n\tstruct rb_node *cur;\n\tstruct rb_node *prev;\n\tstruct rb_node *next;\n\tstruct btrfs_ordered_extent *entry = NULL;\n\n\tspin_lock_irq(&tree->lock);\n\tnode = tree->tree.rb_node;\n\t \n\twhile (node) {\n\t\tentry = rb_entry(node, struct btrfs_ordered_extent, rb_node);\n\n\t\tif (file_offset < entry->file_offset) {\n\t\t\tnode = node->rb_left;\n\t\t} else if (file_offset >= entry_end(entry)) {\n\t\t\tnode = node->rb_right;\n\t\t} else {\n\t\t\t \n\t\t\tgoto out;\n\t\t}\n\t}\n\tif (!entry) {\n\t\t \n\t\tgoto out;\n\t}\n\n\tcur = &entry->rb_node;\n\t \n\tif (entry->file_offset < file_offset) {\n\t\tprev = cur;\n\t\tnext = rb_next(cur);\n\t} else {\n\t\tprev = rb_prev(cur);\n\t\tnext = cur;\n\t}\n\tif (prev) {\n\t\tentry = rb_entry(prev, struct btrfs_ordered_extent, rb_node);\n\t\tif (range_overlaps(entry, file_offset, len))\n\t\t\tgoto out;\n\t}\n\tif (next) {\n\t\tentry = rb_entry(next, struct btrfs_ordered_extent, rb_node);\n\t\tif (range_overlaps(entry, file_offset, len))\n\t\t\tgoto out;\n\t}\n\t \n\tentry = NULL;\nout:\n\tif (entry) {\n\t\trefcount_inc(&entry->refs);\n\t\ttrace_btrfs_ordered_extent_lookup_first_range(inode, entry);\n\t}\n\n\tspin_unlock_irq(&tree->lock);\n\treturn entry;\n}\n\n \nvoid btrfs_lock_and_flush_ordered_range(struct btrfs_inode *inode, u64 start,\n\t\t\t\t\tu64 end,\n\t\t\t\t\tstruct extent_state **cached_state)\n{\n\tstruct btrfs_ordered_extent *ordered;\n\tstruct extent_state *cache = NULL;\n\tstruct extent_state **cachedp = &cache;\n\n\tif (cached_state)\n\t\tcachedp = cached_state;\n\n\twhile (1) {\n\t\tlock_extent(&inode->io_tree, start, end, cachedp);\n\t\tordered = btrfs_lookup_ordered_range(inode, start,\n\t\t\t\t\t\t     end - start + 1);\n\t\tif (!ordered) {\n\t\t\t \n\t\t\tif (!cached_state)\n\t\t\t\trefcount_dec(&cache->refs);\n\t\t\tbreak;\n\t\t}\n\t\tunlock_extent(&inode->io_tree, start, end, cachedp);\n\t\tbtrfs_start_ordered_extent(ordered);\n\t\tbtrfs_put_ordered_extent(ordered);\n\t}\n}\n\n \nbool btrfs_try_lock_ordered_range(struct btrfs_inode *inode, u64 start, u64 end,\n\t\t\t\t  struct extent_state **cached_state)\n{\n\tstruct btrfs_ordered_extent *ordered;\n\n\tif (!try_lock_extent(&inode->io_tree, start, end, cached_state))\n\t\treturn false;\n\n\tordered = btrfs_lookup_ordered_range(inode, start, end - start + 1);\n\tif (!ordered)\n\t\treturn true;\n\n\tbtrfs_put_ordered_extent(ordered);\n\tunlock_extent(&inode->io_tree, start, end, cached_state);\n\n\treturn false;\n}\n\n \nstruct btrfs_ordered_extent *btrfs_split_ordered_extent(\n\t\t\tstruct btrfs_ordered_extent *ordered, u64 len)\n{\n\tstruct btrfs_inode *inode = BTRFS_I(ordered->inode);\n\tstruct btrfs_ordered_inode_tree *tree = &inode->ordered_tree;\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tu64 file_offset = ordered->file_offset;\n\tu64 disk_bytenr = ordered->disk_bytenr;\n\tunsigned long flags = ordered->flags;\n\tstruct btrfs_ordered_sum *sum, *tmpsum;\n\tstruct btrfs_ordered_extent *new;\n\tstruct rb_node *node;\n\tu64 offset = 0;\n\n\ttrace_btrfs_ordered_extent_split(inode, ordered);\n\n\tASSERT(!(flags & (1U << BTRFS_ORDERED_COMPRESSED)));\n\n\t \n\tif (WARN_ON_ONCE(len >= ordered->num_bytes))\n\t\treturn ERR_PTR(-EINVAL);\n\t \n\tif (ordered->bytes_left) {\n\t\tASSERT(!(flags & ~BTRFS_ORDERED_TYPE_FLAGS));\n\t\tif (WARN_ON_ONCE(ordered->bytes_left != ordered->disk_num_bytes))\n\t\t\treturn ERR_PTR(-EINVAL);\n\t}\n\t \n\tif (WARN_ON_ONCE(ordered->disk_num_bytes != ordered->num_bytes))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnew = alloc_ordered_extent(inode, file_offset, len, len, disk_bytenr,\n\t\t\t\t   len, 0, flags, ordered->compress_type);\n\tif (IS_ERR(new))\n\t\treturn new;\n\n\t \n\trefcount_inc(&new->refs);\n\n\tspin_lock_irq(&root->ordered_extent_lock);\n\tspin_lock(&tree->lock);\n\t \n\tnode = &ordered->rb_node;\n\trb_erase(node, &tree->tree);\n\tRB_CLEAR_NODE(node);\n\tif (tree->last == node)\n\t\ttree->last = NULL;\n\n\tordered->file_offset += len;\n\tordered->disk_bytenr += len;\n\tordered->num_bytes -= len;\n\tordered->disk_num_bytes -= len;\n\n\tif (test_bit(BTRFS_ORDERED_IO_DONE, &ordered->flags)) {\n\t\tASSERT(ordered->bytes_left == 0);\n\t\tnew->bytes_left = 0;\n\t} else {\n\t\tordered->bytes_left -= len;\n\t}\n\n\tif (test_bit(BTRFS_ORDERED_TRUNCATED, &ordered->flags)) {\n\t\tif (ordered->truncated_len > len) {\n\t\t\tordered->truncated_len -= len;\n\t\t} else {\n\t\t\tnew->truncated_len = ordered->truncated_len;\n\t\t\tordered->truncated_len = 0;\n\t\t}\n\t}\n\n\tlist_for_each_entry_safe(sum, tmpsum, &ordered->list, list) {\n\t\tif (offset == len)\n\t\t\tbreak;\n\t\tlist_move_tail(&sum->list, &new->list);\n\t\toffset += sum->len;\n\t}\n\n\t \n\tnode = tree_insert(&tree->tree, ordered->file_offset, &ordered->rb_node);\n\tif (node)\n\t\tbtrfs_panic(fs_info, -EEXIST,\n\t\t\t\"zoned: inconsistency in ordered tree at offset %llu\",\n\t\t\tordered->file_offset);\n\n\tnode = tree_insert(&tree->tree, new->file_offset, &new->rb_node);\n\tif (node)\n\t\tbtrfs_panic(fs_info, -EEXIST,\n\t\t\t\"zoned: inconsistency in ordered tree at offset %llu\",\n\t\t\tnew->file_offset);\n\tspin_unlock(&tree->lock);\n\n\tlist_add_tail(&new->root_extent_list, &root->ordered_extents);\n\troot->nr_ordered_extents++;\n\tspin_unlock_irq(&root->ordered_extent_lock);\n\treturn new;\n}\n\nint __init ordered_data_init(void)\n{\n\tbtrfs_ordered_extent_cache = kmem_cache_create(\"btrfs_ordered_extent\",\n\t\t\t\t     sizeof(struct btrfs_ordered_extent), 0,\n\t\t\t\t     SLAB_MEM_SPREAD,\n\t\t\t\t     NULL);\n\tif (!btrfs_ordered_extent_cache)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nvoid __cold ordered_data_exit(void)\n{\n\tkmem_cache_destroy(btrfs_ordered_extent_cache);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}