{
  "module_name": "space-info.c",
  "hash_id": "b71622c6073b10a56ce96cabfe2c1eceee390e6ea11b8889cca2b70c06fb2b30",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/space-info.c",
  "human_readable_source": "\n\n#include \"misc.h\"\n#include \"ctree.h\"\n#include \"space-info.h\"\n#include \"sysfs.h\"\n#include \"volumes.h\"\n#include \"free-space-cache.h\"\n#include \"ordered-data.h\"\n#include \"transaction.h\"\n#include \"block-group.h\"\n#include \"zoned.h\"\n#include \"fs.h\"\n#include \"accessors.h\"\n#include \"extent-tree.h\"\n\n \n\nu64 __pure btrfs_space_info_used(struct btrfs_space_info *s_info,\n\t\t\t  bool may_use_included)\n{\n\tASSERT(s_info);\n\treturn s_info->bytes_used + s_info->bytes_reserved +\n\t\ts_info->bytes_pinned + s_info->bytes_readonly +\n\t\ts_info->bytes_zone_unusable +\n\t\t(may_use_included ? s_info->bytes_may_use : 0);\n}\n\n \nvoid btrfs_clear_space_info_full(struct btrfs_fs_info *info)\n{\n\tstruct list_head *head = &info->space_info;\n\tstruct btrfs_space_info *found;\n\n\tlist_for_each_entry(found, head, list)\n\t\tfound->full = 0;\n}\n\n \n#define BTRFS_DEFAULT_ZONED_RECLAIM_THRESH\t\t\t(75)\n\n \nstatic u64 calc_chunk_size(const struct btrfs_fs_info *fs_info, u64 flags)\n{\n\tif (btrfs_is_zoned(fs_info))\n\t\treturn fs_info->zone_size;\n\n\tASSERT(flags & BTRFS_BLOCK_GROUP_TYPE_MASK);\n\n\tif (flags & BTRFS_BLOCK_GROUP_DATA)\n\t\treturn BTRFS_MAX_DATA_CHUNK_SIZE;\n\telse if (flags & BTRFS_BLOCK_GROUP_SYSTEM)\n\t\treturn SZ_32M;\n\n\t \n\tif (fs_info->fs_devices->total_rw_bytes > 50ULL * SZ_1G)\n\t\treturn SZ_1G;\n\n\treturn SZ_256M;\n}\n\n \nvoid btrfs_update_space_info_chunk_size(struct btrfs_space_info *space_info,\n\t\t\t\t\tu64 chunk_size)\n{\n\tWRITE_ONCE(space_info->chunk_size, chunk_size);\n}\n\nstatic int create_space_info(struct btrfs_fs_info *info, u64 flags)\n{\n\n\tstruct btrfs_space_info *space_info;\n\tint i;\n\tint ret;\n\n\tspace_info = kzalloc(sizeof(*space_info), GFP_NOFS);\n\tif (!space_info)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < BTRFS_NR_RAID_TYPES; i++)\n\t\tINIT_LIST_HEAD(&space_info->block_groups[i]);\n\tinit_rwsem(&space_info->groups_sem);\n\tspin_lock_init(&space_info->lock);\n\tspace_info->flags = flags & BTRFS_BLOCK_GROUP_TYPE_MASK;\n\tspace_info->force_alloc = CHUNK_ALLOC_NO_FORCE;\n\tINIT_LIST_HEAD(&space_info->ro_bgs);\n\tINIT_LIST_HEAD(&space_info->tickets);\n\tINIT_LIST_HEAD(&space_info->priority_tickets);\n\tspace_info->clamp = 1;\n\tbtrfs_update_space_info_chunk_size(space_info, calc_chunk_size(info, flags));\n\n\tif (btrfs_is_zoned(info))\n\t\tspace_info->bg_reclaim_threshold = BTRFS_DEFAULT_ZONED_RECLAIM_THRESH;\n\n\tret = btrfs_sysfs_add_space_info_type(info, space_info);\n\tif (ret)\n\t\treturn ret;\n\n\tlist_add(&space_info->list, &info->space_info);\n\tif (flags & BTRFS_BLOCK_GROUP_DATA)\n\t\tinfo->data_sinfo = space_info;\n\n\treturn ret;\n}\n\nint btrfs_init_space_info(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_super_block *disk_super;\n\tu64 features;\n\tu64 flags;\n\tint mixed = 0;\n\tint ret;\n\n\tdisk_super = fs_info->super_copy;\n\tif (!btrfs_super_root(disk_super))\n\t\treturn -EINVAL;\n\n\tfeatures = btrfs_super_incompat_flags(disk_super);\n\tif (features & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS)\n\t\tmixed = 1;\n\n\tflags = BTRFS_BLOCK_GROUP_SYSTEM;\n\tret = create_space_info(fs_info, flags);\n\tif (ret)\n\t\tgoto out;\n\n\tif (mixed) {\n\t\tflags = BTRFS_BLOCK_GROUP_METADATA | BTRFS_BLOCK_GROUP_DATA;\n\t\tret = create_space_info(fs_info, flags);\n\t} else {\n\t\tflags = BTRFS_BLOCK_GROUP_METADATA;\n\t\tret = create_space_info(fs_info, flags);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tflags = BTRFS_BLOCK_GROUP_DATA;\n\t\tret = create_space_info(fs_info, flags);\n\t}\nout:\n\treturn ret;\n}\n\nvoid btrfs_add_bg_to_space_info(struct btrfs_fs_info *info,\n\t\t\t\tstruct btrfs_block_group *block_group)\n{\n\tstruct btrfs_space_info *found;\n\tint factor, index;\n\n\tfactor = btrfs_bg_type_to_factor(block_group->flags);\n\n\tfound = btrfs_find_space_info(info, block_group->flags);\n\tASSERT(found);\n\tspin_lock(&found->lock);\n\tfound->total_bytes += block_group->length;\n\tfound->disk_total += block_group->length * factor;\n\tfound->bytes_used += block_group->used;\n\tfound->disk_used += block_group->used * factor;\n\tfound->bytes_readonly += block_group->bytes_super;\n\tfound->bytes_zone_unusable += block_group->zone_unusable;\n\tif (block_group->length > 0)\n\t\tfound->full = 0;\n\tbtrfs_try_granting_tickets(info, found);\n\tspin_unlock(&found->lock);\n\n\tblock_group->space_info = found;\n\n\tindex = btrfs_bg_flags_to_raid_index(block_group->flags);\n\tdown_write(&found->groups_sem);\n\tlist_add_tail(&block_group->list, &found->block_groups[index]);\n\tup_write(&found->groups_sem);\n}\n\nstruct btrfs_space_info *btrfs_find_space_info(struct btrfs_fs_info *info,\n\t\t\t\t\t       u64 flags)\n{\n\tstruct list_head *head = &info->space_info;\n\tstruct btrfs_space_info *found;\n\n\tflags &= BTRFS_BLOCK_GROUP_TYPE_MASK;\n\n\tlist_for_each_entry(found, head, list) {\n\t\tif (found->flags & flags)\n\t\t\treturn found;\n\t}\n\treturn NULL;\n}\n\nstatic u64 calc_available_free_space(struct btrfs_fs_info *fs_info,\n\t\t\t  struct btrfs_space_info *space_info,\n\t\t\t  enum btrfs_reserve_flush_enum flush)\n{\n\tu64 profile;\n\tu64 avail;\n\tint factor;\n\n\tif (space_info->flags & BTRFS_BLOCK_GROUP_SYSTEM)\n\t\tprofile = btrfs_system_alloc_profile(fs_info);\n\telse\n\t\tprofile = btrfs_metadata_alloc_profile(fs_info);\n\n\tavail = atomic64_read(&fs_info->free_chunk_space);\n\n\t \n\tfactor = btrfs_bg_type_to_factor(profile);\n\tavail = div_u64(avail, factor);\n\n\t \n\tif (flush == BTRFS_RESERVE_FLUSH_ALL)\n\t\tavail >>= 3;\n\telse\n\t\tavail >>= 1;\n\treturn avail;\n}\n\nint btrfs_can_overcommit(struct btrfs_fs_info *fs_info,\n\t\t\t struct btrfs_space_info *space_info, u64 bytes,\n\t\t\t enum btrfs_reserve_flush_enum flush)\n{\n\tu64 avail;\n\tu64 used;\n\n\t \n\tif (space_info->flags & BTRFS_BLOCK_GROUP_DATA)\n\t\treturn 0;\n\n\tused = btrfs_space_info_used(space_info, true);\n\tavail = calc_available_free_space(fs_info, space_info, flush);\n\n\tif (used + bytes < space_info->total_bytes + avail)\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic void remove_ticket(struct btrfs_space_info *space_info,\n\t\t\t  struct reserve_ticket *ticket)\n{\n\tif (!list_empty(&ticket->list)) {\n\t\tlist_del_init(&ticket->list);\n\t\tASSERT(space_info->reclaim_size >= ticket->bytes);\n\t\tspace_info->reclaim_size -= ticket->bytes;\n\t}\n}\n\n \nvoid btrfs_try_granting_tickets(struct btrfs_fs_info *fs_info,\n\t\t\t\tstruct btrfs_space_info *space_info)\n{\n\tstruct list_head *head;\n\tenum btrfs_reserve_flush_enum flush = BTRFS_RESERVE_NO_FLUSH;\n\n\tlockdep_assert_held(&space_info->lock);\n\n\thead = &space_info->priority_tickets;\nagain:\n\twhile (!list_empty(head)) {\n\t\tstruct reserve_ticket *ticket;\n\t\tu64 used = btrfs_space_info_used(space_info, true);\n\n\t\tticket = list_first_entry(head, struct reserve_ticket, list);\n\n\t\t \n\t\tif ((used + ticket->bytes <= space_info->total_bytes) ||\n\t\t    btrfs_can_overcommit(fs_info, space_info, ticket->bytes,\n\t\t\t\t\t flush)) {\n\t\t\tbtrfs_space_info_update_bytes_may_use(fs_info,\n\t\t\t\t\t\t\t      space_info,\n\t\t\t\t\t\t\t      ticket->bytes);\n\t\t\tremove_ticket(space_info, ticket);\n\t\t\tticket->bytes = 0;\n\t\t\tspace_info->tickets_id++;\n\t\t\twake_up(&ticket->wait);\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (head == &space_info->priority_tickets) {\n\t\thead = &space_info->tickets;\n\t\tflush = BTRFS_RESERVE_FLUSH_ALL;\n\t\tgoto again;\n\t}\n}\n\n#define DUMP_BLOCK_RSV(fs_info, rsv_name)\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tstruct btrfs_block_rsv *__rsv = &(fs_info)->rsv_name;\t\t\\\n\tspin_lock(&__rsv->lock);\t\t\t\t\t\\\n\tbtrfs_info(fs_info, #rsv_name \": size %llu reserved %llu\",\t\\\n\t\t   __rsv->size, __rsv->reserved);\t\t\t\\\n\tspin_unlock(&__rsv->lock);\t\t\t\t\t\\\n} while (0)\n\nstatic const char *space_info_flag_to_str(const struct btrfs_space_info *space_info)\n{\n\tswitch (space_info->flags) {\n\tcase BTRFS_BLOCK_GROUP_SYSTEM:\n\t\treturn \"SYSTEM\";\n\tcase BTRFS_BLOCK_GROUP_METADATA | BTRFS_BLOCK_GROUP_DATA:\n\t\treturn \"DATA+METADATA\";\n\tcase BTRFS_BLOCK_GROUP_DATA:\n\t\treturn \"DATA\";\n\tcase BTRFS_BLOCK_GROUP_METADATA:\n\t\treturn \"METADATA\";\n\tdefault:\n\t\treturn \"UNKNOWN\";\n\t}\n}\n\nstatic void dump_global_block_rsv(struct btrfs_fs_info *fs_info)\n{\n\tDUMP_BLOCK_RSV(fs_info, global_block_rsv);\n\tDUMP_BLOCK_RSV(fs_info, trans_block_rsv);\n\tDUMP_BLOCK_RSV(fs_info, chunk_block_rsv);\n\tDUMP_BLOCK_RSV(fs_info, delayed_block_rsv);\n\tDUMP_BLOCK_RSV(fs_info, delayed_refs_rsv);\n}\n\nstatic void __btrfs_dump_space_info(struct btrfs_fs_info *fs_info,\n\t\t\t\t    struct btrfs_space_info *info)\n{\n\tconst char *flag_str = space_info_flag_to_str(info);\n\tlockdep_assert_held(&info->lock);\n\n\t \n\tbtrfs_info(fs_info, \"space_info %s has %lld free, is %sfull\",\n\t\t   flag_str,\n\t\t   (s64)(info->total_bytes - btrfs_space_info_used(info, true)),\n\t\t   info->full ? \"\" : \"not \");\n\tbtrfs_info(fs_info,\n\"space_info total=%llu, used=%llu, pinned=%llu, reserved=%llu, may_use=%llu, readonly=%llu zone_unusable=%llu\",\n\t\tinfo->total_bytes, info->bytes_used, info->bytes_pinned,\n\t\tinfo->bytes_reserved, info->bytes_may_use,\n\t\tinfo->bytes_readonly, info->bytes_zone_unusable);\n}\n\nvoid btrfs_dump_space_info(struct btrfs_fs_info *fs_info,\n\t\t\t   struct btrfs_space_info *info, u64 bytes,\n\t\t\t   int dump_block_groups)\n{\n\tstruct btrfs_block_group *cache;\n\tu64 total_avail = 0;\n\tint index = 0;\n\n\tspin_lock(&info->lock);\n\t__btrfs_dump_space_info(fs_info, info);\n\tdump_global_block_rsv(fs_info);\n\tspin_unlock(&info->lock);\n\n\tif (!dump_block_groups)\n\t\treturn;\n\n\tdown_read(&info->groups_sem);\nagain:\n\tlist_for_each_entry(cache, &info->block_groups[index], list) {\n\t\tu64 avail;\n\n\t\tspin_lock(&cache->lock);\n\t\tavail = cache->length - cache->used - cache->pinned -\n\t\t\tcache->reserved - cache->delalloc_bytes -\n\t\t\tcache->bytes_super - cache->zone_unusable;\n\t\tbtrfs_info(fs_info,\n\"block group %llu has %llu bytes, %llu used %llu pinned %llu reserved %llu delalloc %llu super %llu zone_unusable (%llu bytes available) %s\",\n\t\t\t   cache->start, cache->length, cache->used, cache->pinned,\n\t\t\t   cache->reserved, cache->delalloc_bytes,\n\t\t\t   cache->bytes_super, cache->zone_unusable,\n\t\t\t   avail, cache->ro ? \"[readonly]\" : \"\");\n\t\tspin_unlock(&cache->lock);\n\t\tbtrfs_dump_free_space(cache, bytes);\n\t\ttotal_avail += avail;\n\t}\n\tif (++index < BTRFS_NR_RAID_TYPES)\n\t\tgoto again;\n\tup_read(&info->groups_sem);\n\n\tbtrfs_info(fs_info, \"%llu bytes available across all block groups\", total_avail);\n}\n\nstatic inline u64 calc_reclaim_items_nr(const struct btrfs_fs_info *fs_info,\n\t\t\t\t\tu64 to_reclaim)\n{\n\tu64 bytes;\n\tu64 nr;\n\n\tbytes = btrfs_calc_insert_metadata_size(fs_info, 1);\n\tnr = div64_u64(to_reclaim, bytes);\n\tif (!nr)\n\t\tnr = 1;\n\treturn nr;\n}\n\nstatic inline u64 calc_delayed_refs_nr(const struct btrfs_fs_info *fs_info,\n\t\t\t\t       u64 to_reclaim)\n{\n\tconst u64 bytes = btrfs_calc_delayed_ref_bytes(fs_info, 1);\n\tu64 nr;\n\n\tnr = div64_u64(to_reclaim, bytes);\n\tif (!nr)\n\t\tnr = 1;\n\treturn nr;\n}\n\n#define EXTENT_SIZE_PER_ITEM\tSZ_256K\n\n \nstatic void shrink_delalloc(struct btrfs_fs_info *fs_info,\n\t\t\t    struct btrfs_space_info *space_info,\n\t\t\t    u64 to_reclaim, bool wait_ordered,\n\t\t\t    bool for_preempt)\n{\n\tstruct btrfs_trans_handle *trans;\n\tu64 delalloc_bytes;\n\tu64 ordered_bytes;\n\tu64 items;\n\tlong time_left;\n\tint loops;\n\n\tdelalloc_bytes = percpu_counter_sum_positive(&fs_info->delalloc_bytes);\n\tordered_bytes = percpu_counter_sum_positive(&fs_info->ordered_bytes);\n\tif (delalloc_bytes == 0 && ordered_bytes == 0)\n\t\treturn;\n\n\t \n\tif (to_reclaim == U64_MAX) {\n\t\titems = U64_MAX;\n\t} else {\n\t\t \n\t\tto_reclaim = max(to_reclaim, delalloc_bytes >> 3);\n\t\titems = calc_reclaim_items_nr(fs_info, to_reclaim) * 2;\n\t}\n\n\ttrans = current->journal_info;\n\n\t \n\tif (ordered_bytes > delalloc_bytes && !for_preempt)\n\t\twait_ordered = true;\n\n\tloops = 0;\n\twhile ((delalloc_bytes || ordered_bytes) && loops < 3) {\n\t\tu64 temp = min(delalloc_bytes, to_reclaim) >> PAGE_SHIFT;\n\t\tlong nr_pages = min_t(u64, temp, LONG_MAX);\n\t\tint async_pages;\n\n\t\tbtrfs_start_delalloc_roots(fs_info, nr_pages, true);\n\n\t\t \n\t\tasync_pages = atomic_read(&fs_info->async_delalloc_pages);\n\t\tif (!async_pages)\n\t\t\tgoto skip_async;\n\n\t\t \n\t\tif (async_pages > nr_pages)\n\t\t\tasync_pages -= nr_pages;\n\t\telse\n\t\t\tasync_pages = 0;\n\t\twait_event(fs_info->async_submit_wait,\n\t\t\t   atomic_read(&fs_info->async_delalloc_pages) <=\n\t\t\t   async_pages);\nskip_async:\n\t\tloops++;\n\t\tif (wait_ordered && !trans) {\n\t\t\tbtrfs_wait_ordered_roots(fs_info, items, 0, (u64)-1);\n\t\t} else {\n\t\t\ttime_left = schedule_timeout_killable(1);\n\t\t\tif (time_left)\n\t\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (for_preempt)\n\t\t\tbreak;\n\n\t\tspin_lock(&space_info->lock);\n\t\tif (list_empty(&space_info->tickets) &&\n\t\t    list_empty(&space_info->priority_tickets)) {\n\t\t\tspin_unlock(&space_info->lock);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&space_info->lock);\n\n\t\tdelalloc_bytes = percpu_counter_sum_positive(\n\t\t\t\t\t\t&fs_info->delalloc_bytes);\n\t\tordered_bytes = percpu_counter_sum_positive(\n\t\t\t\t\t\t&fs_info->ordered_bytes);\n\t}\n}\n\n \nstatic void flush_space(struct btrfs_fs_info *fs_info,\n\t\t       struct btrfs_space_info *space_info, u64 num_bytes,\n\t\t       enum btrfs_flush_state state, bool for_preempt)\n{\n\tstruct btrfs_root *root = fs_info->tree_root;\n\tstruct btrfs_trans_handle *trans;\n\tint nr;\n\tint ret = 0;\n\n\tswitch (state) {\n\tcase FLUSH_DELAYED_ITEMS_NR:\n\tcase FLUSH_DELAYED_ITEMS:\n\t\tif (state == FLUSH_DELAYED_ITEMS_NR)\n\t\t\tnr = calc_reclaim_items_nr(fs_info, num_bytes) * 2;\n\t\telse\n\t\t\tnr = -1;\n\n\t\ttrans = btrfs_join_transaction_nostart(root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\tif (ret == -ENOENT)\n\t\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\tret = btrfs_run_delayed_items_nr(trans, nr);\n\t\tbtrfs_end_transaction(trans);\n\t\tbreak;\n\tcase FLUSH_DELALLOC:\n\tcase FLUSH_DELALLOC_WAIT:\n\tcase FLUSH_DELALLOC_FULL:\n\t\tif (state == FLUSH_DELALLOC_FULL)\n\t\t\tnum_bytes = U64_MAX;\n\t\tshrink_delalloc(fs_info, space_info, num_bytes,\n\t\t\t\tstate != FLUSH_DELALLOC, for_preempt);\n\t\tbreak;\n\tcase FLUSH_DELAYED_REFS_NR:\n\tcase FLUSH_DELAYED_REFS:\n\t\ttrans = btrfs_join_transaction_nostart(root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\tif (ret == -ENOENT)\n\t\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\tif (state == FLUSH_DELAYED_REFS_NR)\n\t\t\tnr = calc_delayed_refs_nr(fs_info, num_bytes);\n\t\telse\n\t\t\tnr = 0;\n\t\tbtrfs_run_delayed_refs(trans, nr);\n\t\tbtrfs_end_transaction(trans);\n\t\tbreak;\n\tcase ALLOC_CHUNK:\n\tcase ALLOC_CHUNK_FORCE:\n\t\ttrans = btrfs_join_transaction(root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\tbreak;\n\t\t}\n\t\tret = btrfs_chunk_alloc(trans,\n\t\t\t\tbtrfs_get_alloc_profile(fs_info, space_info->flags),\n\t\t\t\t(state == ALLOC_CHUNK) ? CHUNK_ALLOC_NO_FORCE :\n\t\t\t\t\tCHUNK_ALLOC_FORCE);\n\t\tbtrfs_end_transaction(trans);\n\n\t\tif (ret > 0 || ret == -ENOSPC)\n\t\t\tret = 0;\n\t\tbreak;\n\tcase RUN_DELAYED_IPUTS:\n\t\t \n\t\tbtrfs_run_delayed_iputs(fs_info);\n\t\tbtrfs_wait_on_delayed_iputs(fs_info);\n\t\tbreak;\n\tcase COMMIT_TRANS:\n\t\tASSERT(current->journal_info == NULL);\n\t\t \n\t\ttrans = btrfs_attach_transaction_barrier(root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\tif (ret == -ENOENT)\n\t\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\tret = btrfs_commit_transaction(trans);\n\t\tbreak;\n\tdefault:\n\t\tret = -ENOSPC;\n\t\tbreak;\n\t}\n\n\ttrace_btrfs_flush_space(fs_info, space_info->flags, num_bytes, state,\n\t\t\t\tret, for_preempt);\n\treturn;\n}\n\nstatic inline u64\nbtrfs_calc_reclaim_metadata_size(struct btrfs_fs_info *fs_info,\n\t\t\t\t struct btrfs_space_info *space_info)\n{\n\tu64 used;\n\tu64 avail;\n\tu64 to_reclaim = space_info->reclaim_size;\n\n\tlockdep_assert_held(&space_info->lock);\n\n\tavail = calc_available_free_space(fs_info, space_info,\n\t\t\t\t\t  BTRFS_RESERVE_FLUSH_ALL);\n\tused = btrfs_space_info_used(space_info, true);\n\n\t \n\tif (space_info->total_bytes + avail < used)\n\t\tto_reclaim += used - (space_info->total_bytes + avail);\n\n\treturn to_reclaim;\n}\n\nstatic bool need_preemptive_reclaim(struct btrfs_fs_info *fs_info,\n\t\t\t\t    struct btrfs_space_info *space_info)\n{\n\tu64 global_rsv_size = fs_info->global_block_rsv.reserved;\n\tu64 ordered, delalloc;\n\tu64 thresh;\n\tu64 used;\n\n\tthresh = mult_perc(space_info->total_bytes, 90);\n\n\tlockdep_assert_held(&space_info->lock);\n\n\t \n\tif ((space_info->bytes_used + space_info->bytes_reserved +\n\t     global_rsv_size) >= thresh)\n\t\treturn false;\n\n\tused = space_info->bytes_may_use + space_info->bytes_pinned;\n\n\t \n\tif (global_rsv_size >= used)\n\t\treturn false;\n\n\t \n\tif (used - global_rsv_size <= SZ_128M)\n\t\treturn false;\n\n\t \n\tif (space_info->reclaim_size)\n\t\treturn false;\n\n\t \n\n\tthresh = calc_available_free_space(fs_info, space_info,\n\t\t\t\t\t   BTRFS_RESERVE_FLUSH_ALL);\n\tused = space_info->bytes_used + space_info->bytes_reserved +\n\t       space_info->bytes_readonly + global_rsv_size;\n\tif (used < space_info->total_bytes)\n\t\tthresh += space_info->total_bytes - used;\n\tthresh >>= space_info->clamp;\n\n\tused = space_info->bytes_pinned;\n\n\t \n\tordered = percpu_counter_read_positive(&fs_info->ordered_bytes) >> 1;\n\tdelalloc = percpu_counter_read_positive(&fs_info->delalloc_bytes);\n\tif (ordered >= delalloc)\n\t\tused += fs_info->delayed_refs_rsv.reserved +\n\t\t\tfs_info->delayed_block_rsv.reserved;\n\telse\n\t\tused += space_info->bytes_may_use - global_rsv_size;\n\n\treturn (used >= thresh && !btrfs_fs_closing(fs_info) &&\n\t\t!test_bit(BTRFS_FS_STATE_REMOUNTING, &fs_info->fs_state));\n}\n\nstatic bool steal_from_global_rsv(struct btrfs_fs_info *fs_info,\n\t\t\t\t  struct btrfs_space_info *space_info,\n\t\t\t\t  struct reserve_ticket *ticket)\n{\n\tstruct btrfs_block_rsv *global_rsv = &fs_info->global_block_rsv;\n\tu64 min_bytes;\n\n\tif (!ticket->steal)\n\t\treturn false;\n\n\tif (global_rsv->space_info != space_info)\n\t\treturn false;\n\n\tspin_lock(&global_rsv->lock);\n\tmin_bytes = mult_perc(global_rsv->size, 10);\n\tif (global_rsv->reserved < min_bytes + ticket->bytes) {\n\t\tspin_unlock(&global_rsv->lock);\n\t\treturn false;\n\t}\n\tglobal_rsv->reserved -= ticket->bytes;\n\tremove_ticket(space_info, ticket);\n\tticket->bytes = 0;\n\twake_up(&ticket->wait);\n\tspace_info->tickets_id++;\n\tif (global_rsv->reserved < global_rsv->size)\n\t\tglobal_rsv->full = 0;\n\tspin_unlock(&global_rsv->lock);\n\n\treturn true;\n}\n\n \nstatic bool maybe_fail_all_tickets(struct btrfs_fs_info *fs_info,\n\t\t\t\t   struct btrfs_space_info *space_info)\n{\n\tstruct reserve_ticket *ticket;\n\tu64 tickets_id = space_info->tickets_id;\n\tconst bool aborted = BTRFS_FS_ERROR(fs_info);\n\n\ttrace_btrfs_fail_all_tickets(fs_info, space_info);\n\n\tif (btrfs_test_opt(fs_info, ENOSPC_DEBUG)) {\n\t\tbtrfs_info(fs_info, \"cannot satisfy tickets, dumping space info\");\n\t\t__btrfs_dump_space_info(fs_info, space_info);\n\t}\n\n\twhile (!list_empty(&space_info->tickets) &&\n\t       tickets_id == space_info->tickets_id) {\n\t\tticket = list_first_entry(&space_info->tickets,\n\t\t\t\t\t  struct reserve_ticket, list);\n\n\t\tif (!aborted && steal_from_global_rsv(fs_info, space_info, ticket))\n\t\t\treturn true;\n\n\t\tif (!aborted && btrfs_test_opt(fs_info, ENOSPC_DEBUG))\n\t\t\tbtrfs_info(fs_info, \"failing ticket with %llu bytes\",\n\t\t\t\t   ticket->bytes);\n\n\t\tremove_ticket(space_info, ticket);\n\t\tif (aborted)\n\t\t\tticket->error = -EIO;\n\t\telse\n\t\t\tticket->error = -ENOSPC;\n\t\twake_up(&ticket->wait);\n\n\t\t \n\t\tif (!aborted)\n\t\t\tbtrfs_try_granting_tickets(fs_info, space_info);\n\t}\n\treturn (tickets_id != space_info->tickets_id);\n}\n\n \nstatic void btrfs_async_reclaim_metadata_space(struct work_struct *work)\n{\n\tstruct btrfs_fs_info *fs_info;\n\tstruct btrfs_space_info *space_info;\n\tu64 to_reclaim;\n\tenum btrfs_flush_state flush_state;\n\tint commit_cycles = 0;\n\tu64 last_tickets_id;\n\n\tfs_info = container_of(work, struct btrfs_fs_info, async_reclaim_work);\n\tspace_info = btrfs_find_space_info(fs_info, BTRFS_BLOCK_GROUP_METADATA);\n\n\tspin_lock(&space_info->lock);\n\tto_reclaim = btrfs_calc_reclaim_metadata_size(fs_info, space_info);\n\tif (!to_reclaim) {\n\t\tspace_info->flush = 0;\n\t\tspin_unlock(&space_info->lock);\n\t\treturn;\n\t}\n\tlast_tickets_id = space_info->tickets_id;\n\tspin_unlock(&space_info->lock);\n\n\tflush_state = FLUSH_DELAYED_ITEMS_NR;\n\tdo {\n\t\tflush_space(fs_info, space_info, to_reclaim, flush_state, false);\n\t\tspin_lock(&space_info->lock);\n\t\tif (list_empty(&space_info->tickets)) {\n\t\t\tspace_info->flush = 0;\n\t\t\tspin_unlock(&space_info->lock);\n\t\t\treturn;\n\t\t}\n\t\tto_reclaim = btrfs_calc_reclaim_metadata_size(fs_info,\n\t\t\t\t\t\t\t      space_info);\n\t\tif (last_tickets_id == space_info->tickets_id) {\n\t\t\tflush_state++;\n\t\t} else {\n\t\t\tlast_tickets_id = space_info->tickets_id;\n\t\t\tflush_state = FLUSH_DELAYED_ITEMS_NR;\n\t\t\tif (commit_cycles)\n\t\t\t\tcommit_cycles--;\n\t\t}\n\n\t\t \n\t\tif (flush_state == FLUSH_DELALLOC_FULL && !commit_cycles)\n\t\t\tflush_state++;\n\n\t\t \n\t\tif (flush_state == ALLOC_CHUNK_FORCE && !commit_cycles)\n\t\t\tflush_state++;\n\n\t\tif (flush_state > COMMIT_TRANS) {\n\t\t\tcommit_cycles++;\n\t\t\tif (commit_cycles > 2) {\n\t\t\t\tif (maybe_fail_all_tickets(fs_info, space_info)) {\n\t\t\t\t\tflush_state = FLUSH_DELAYED_ITEMS_NR;\n\t\t\t\t\tcommit_cycles--;\n\t\t\t\t} else {\n\t\t\t\t\tspace_info->flush = 0;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tflush_state = FLUSH_DELAYED_ITEMS_NR;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&space_info->lock);\n\t} while (flush_state <= COMMIT_TRANS);\n}\n\n \nstatic void btrfs_preempt_reclaim_metadata_space(struct work_struct *work)\n{\n\tstruct btrfs_fs_info *fs_info;\n\tstruct btrfs_space_info *space_info;\n\tstruct btrfs_block_rsv *delayed_block_rsv;\n\tstruct btrfs_block_rsv *delayed_refs_rsv;\n\tstruct btrfs_block_rsv *global_rsv;\n\tstruct btrfs_block_rsv *trans_rsv;\n\tint loops = 0;\n\n\tfs_info = container_of(work, struct btrfs_fs_info,\n\t\t\t       preempt_reclaim_work);\n\tspace_info = btrfs_find_space_info(fs_info, BTRFS_BLOCK_GROUP_METADATA);\n\tdelayed_block_rsv = &fs_info->delayed_block_rsv;\n\tdelayed_refs_rsv = &fs_info->delayed_refs_rsv;\n\tglobal_rsv = &fs_info->global_block_rsv;\n\ttrans_rsv = &fs_info->trans_block_rsv;\n\n\tspin_lock(&space_info->lock);\n\twhile (need_preemptive_reclaim(fs_info, space_info)) {\n\t\tenum btrfs_flush_state flush;\n\t\tu64 delalloc_size = 0;\n\t\tu64 to_reclaim, block_rsv_size;\n\t\tu64 global_rsv_size = global_rsv->reserved;\n\n\t\tloops++;\n\n\t\t \n\t\tblock_rsv_size = global_rsv_size +\n\t\t\tdelayed_block_rsv->reserved +\n\t\t\tdelayed_refs_rsv->reserved +\n\t\t\ttrans_rsv->reserved;\n\t\tif (block_rsv_size < space_info->bytes_may_use)\n\t\t\tdelalloc_size = space_info->bytes_may_use - block_rsv_size;\n\n\t\t \n\t\tblock_rsv_size -= global_rsv_size;\n\n\t\t \n\t\tif (delalloc_size > block_rsv_size) {\n\t\t\tto_reclaim = delalloc_size;\n\t\t\tflush = FLUSH_DELALLOC;\n\t\t} else if (space_info->bytes_pinned >\n\t\t\t   (delayed_block_rsv->reserved +\n\t\t\t    delayed_refs_rsv->reserved)) {\n\t\t\tto_reclaim = space_info->bytes_pinned;\n\t\t\tflush = COMMIT_TRANS;\n\t\t} else if (delayed_block_rsv->reserved >\n\t\t\t   delayed_refs_rsv->reserved) {\n\t\t\tto_reclaim = delayed_block_rsv->reserved;\n\t\t\tflush = FLUSH_DELAYED_ITEMS_NR;\n\t\t} else {\n\t\t\tto_reclaim = delayed_refs_rsv->reserved;\n\t\t\tflush = FLUSH_DELAYED_REFS_NR;\n\t\t}\n\n\t\tspin_unlock(&space_info->lock);\n\n\t\t \n\t\tto_reclaim >>= 2;\n\t\tif (!to_reclaim)\n\t\t\tto_reclaim = btrfs_calc_insert_metadata_size(fs_info, 1);\n\t\tflush_space(fs_info, space_info, to_reclaim, flush, true);\n\t\tcond_resched();\n\t\tspin_lock(&space_info->lock);\n\t}\n\n\t \n\tif (loops == 1 && !space_info->reclaim_size)\n\t\tspace_info->clamp = max(1, space_info->clamp - 1);\n\ttrace_btrfs_done_preemptive_reclaim(fs_info, space_info);\n\tspin_unlock(&space_info->lock);\n}\n\n \nstatic const enum btrfs_flush_state data_flush_states[] = {\n\tFLUSH_DELALLOC_FULL,\n\tRUN_DELAYED_IPUTS,\n\tCOMMIT_TRANS,\n\tALLOC_CHUNK_FORCE,\n};\n\nstatic void btrfs_async_reclaim_data_space(struct work_struct *work)\n{\n\tstruct btrfs_fs_info *fs_info;\n\tstruct btrfs_space_info *space_info;\n\tu64 last_tickets_id;\n\tenum btrfs_flush_state flush_state = 0;\n\n\tfs_info = container_of(work, struct btrfs_fs_info, async_data_reclaim_work);\n\tspace_info = fs_info->data_sinfo;\n\n\tspin_lock(&space_info->lock);\n\tif (list_empty(&space_info->tickets)) {\n\t\tspace_info->flush = 0;\n\t\tspin_unlock(&space_info->lock);\n\t\treturn;\n\t}\n\tlast_tickets_id = space_info->tickets_id;\n\tspin_unlock(&space_info->lock);\n\n\twhile (!space_info->full) {\n\t\tflush_space(fs_info, space_info, U64_MAX, ALLOC_CHUNK_FORCE, false);\n\t\tspin_lock(&space_info->lock);\n\t\tif (list_empty(&space_info->tickets)) {\n\t\t\tspace_info->flush = 0;\n\t\t\tspin_unlock(&space_info->lock);\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tif (BTRFS_FS_ERROR(fs_info))\n\t\t\tgoto aborted_fs;\n\t\tlast_tickets_id = space_info->tickets_id;\n\t\tspin_unlock(&space_info->lock);\n\t}\n\n\twhile (flush_state < ARRAY_SIZE(data_flush_states)) {\n\t\tflush_space(fs_info, space_info, U64_MAX,\n\t\t\t    data_flush_states[flush_state], false);\n\t\tspin_lock(&space_info->lock);\n\t\tif (list_empty(&space_info->tickets)) {\n\t\t\tspace_info->flush = 0;\n\t\t\tspin_unlock(&space_info->lock);\n\t\t\treturn;\n\t\t}\n\n\t\tif (last_tickets_id == space_info->tickets_id) {\n\t\t\tflush_state++;\n\t\t} else {\n\t\t\tlast_tickets_id = space_info->tickets_id;\n\t\t\tflush_state = 0;\n\t\t}\n\n\t\tif (flush_state >= ARRAY_SIZE(data_flush_states)) {\n\t\t\tif (space_info->full) {\n\t\t\t\tif (maybe_fail_all_tickets(fs_info, space_info))\n\t\t\t\t\tflush_state = 0;\n\t\t\t\telse\n\t\t\t\t\tspace_info->flush = 0;\n\t\t\t} else {\n\t\t\t\tflush_state = 0;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (BTRFS_FS_ERROR(fs_info))\n\t\t\t\tgoto aborted_fs;\n\n\t\t}\n\t\tspin_unlock(&space_info->lock);\n\t}\n\treturn;\n\naborted_fs:\n\tmaybe_fail_all_tickets(fs_info, space_info);\n\tspace_info->flush = 0;\n\tspin_unlock(&space_info->lock);\n}\n\nvoid btrfs_init_async_reclaim_work(struct btrfs_fs_info *fs_info)\n{\n\tINIT_WORK(&fs_info->async_reclaim_work, btrfs_async_reclaim_metadata_space);\n\tINIT_WORK(&fs_info->async_data_reclaim_work, btrfs_async_reclaim_data_space);\n\tINIT_WORK(&fs_info->preempt_reclaim_work,\n\t\t  btrfs_preempt_reclaim_metadata_space);\n}\n\nstatic const enum btrfs_flush_state priority_flush_states[] = {\n\tFLUSH_DELAYED_ITEMS_NR,\n\tFLUSH_DELAYED_ITEMS,\n\tALLOC_CHUNK,\n};\n\nstatic const enum btrfs_flush_state evict_flush_states[] = {\n\tFLUSH_DELAYED_ITEMS_NR,\n\tFLUSH_DELAYED_ITEMS,\n\tFLUSH_DELAYED_REFS_NR,\n\tFLUSH_DELAYED_REFS,\n\tFLUSH_DELALLOC,\n\tFLUSH_DELALLOC_WAIT,\n\tFLUSH_DELALLOC_FULL,\n\tALLOC_CHUNK,\n\tCOMMIT_TRANS,\n};\n\nstatic void priority_reclaim_metadata_space(struct btrfs_fs_info *fs_info,\n\t\t\t\tstruct btrfs_space_info *space_info,\n\t\t\t\tstruct reserve_ticket *ticket,\n\t\t\t\tconst enum btrfs_flush_state *states,\n\t\t\t\tint states_nr)\n{\n\tu64 to_reclaim;\n\tint flush_state = 0;\n\n\tspin_lock(&space_info->lock);\n\tto_reclaim = btrfs_calc_reclaim_metadata_size(fs_info, space_info);\n\t \n\tif (ticket->bytes == 0) {\n\t\tspin_unlock(&space_info->lock);\n\t\treturn;\n\t}\n\n\twhile (flush_state < states_nr) {\n\t\tspin_unlock(&space_info->lock);\n\t\tflush_space(fs_info, space_info, to_reclaim, states[flush_state],\n\t\t\t    false);\n\t\tflush_state++;\n\t\tspin_lock(&space_info->lock);\n\t\tif (ticket->bytes == 0) {\n\t\t\tspin_unlock(&space_info->lock);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tif (BTRFS_FS_ERROR(fs_info)) {\n\t\tticket->error = BTRFS_FS_ERROR(fs_info);\n\t\tremove_ticket(space_info, ticket);\n\t} else if (!steal_from_global_rsv(fs_info, space_info, ticket)) {\n\t\tticket->error = -ENOSPC;\n\t\tremove_ticket(space_info, ticket);\n\t}\n\n\t \n\tbtrfs_try_granting_tickets(fs_info, space_info);\n\tspin_unlock(&space_info->lock);\n}\n\nstatic void priority_reclaim_data_space(struct btrfs_fs_info *fs_info,\n\t\t\t\t\tstruct btrfs_space_info *space_info,\n\t\t\t\t\tstruct reserve_ticket *ticket)\n{\n\tspin_lock(&space_info->lock);\n\n\t \n\tif (ticket->bytes == 0) {\n\t\tspin_unlock(&space_info->lock);\n\t\treturn;\n\t}\n\n\twhile (!space_info->full) {\n\t\tspin_unlock(&space_info->lock);\n\t\tflush_space(fs_info, space_info, U64_MAX, ALLOC_CHUNK_FORCE, false);\n\t\tspin_lock(&space_info->lock);\n\t\tif (ticket->bytes == 0) {\n\t\t\tspin_unlock(&space_info->lock);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tticket->error = -ENOSPC;\n\tremove_ticket(space_info, ticket);\n\tbtrfs_try_granting_tickets(fs_info, space_info);\n\tspin_unlock(&space_info->lock);\n}\n\nstatic void wait_reserve_ticket(struct btrfs_fs_info *fs_info,\n\t\t\t\tstruct btrfs_space_info *space_info,\n\t\t\t\tstruct reserve_ticket *ticket)\n\n{\n\tDEFINE_WAIT(wait);\n\tint ret = 0;\n\n\tspin_lock(&space_info->lock);\n\twhile (ticket->bytes > 0 && ticket->error == 0) {\n\t\tret = prepare_to_wait_event(&ticket->wait, &wait, TASK_KILLABLE);\n\t\tif (ret) {\n\t\t\t \n\t\t\tremove_ticket(space_info, ticket);\n\t\t\tticket->error = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&space_info->lock);\n\n\t\tschedule();\n\n\t\tfinish_wait(&ticket->wait, &wait);\n\t\tspin_lock(&space_info->lock);\n\t}\n\tspin_unlock(&space_info->lock);\n}\n\n \nstatic int handle_reserve_ticket(struct btrfs_fs_info *fs_info,\n\t\t\t\t struct btrfs_space_info *space_info,\n\t\t\t\t struct reserve_ticket *ticket,\n\t\t\t\t u64 start_ns, u64 orig_bytes,\n\t\t\t\t enum btrfs_reserve_flush_enum flush)\n{\n\tint ret;\n\n\tswitch (flush) {\n\tcase BTRFS_RESERVE_FLUSH_DATA:\n\tcase BTRFS_RESERVE_FLUSH_ALL:\n\tcase BTRFS_RESERVE_FLUSH_ALL_STEAL:\n\t\twait_reserve_ticket(fs_info, space_info, ticket);\n\t\tbreak;\n\tcase BTRFS_RESERVE_FLUSH_LIMIT:\n\t\tpriority_reclaim_metadata_space(fs_info, space_info, ticket,\n\t\t\t\t\t\tpriority_flush_states,\n\t\t\t\t\t\tARRAY_SIZE(priority_flush_states));\n\t\tbreak;\n\tcase BTRFS_RESERVE_FLUSH_EVICT:\n\t\tpriority_reclaim_metadata_space(fs_info, space_info, ticket,\n\t\t\t\t\t\tevict_flush_states,\n\t\t\t\t\t\tARRAY_SIZE(evict_flush_states));\n\t\tbreak;\n\tcase BTRFS_RESERVE_FLUSH_FREE_SPACE_INODE:\n\t\tpriority_reclaim_data_space(fs_info, space_info, ticket);\n\t\tbreak;\n\tdefault:\n\t\tASSERT(0);\n\t\tbreak;\n\t}\n\n\tret = ticket->error;\n\tASSERT(list_empty(&ticket->list));\n\t \n\tASSERT(!(ticket->bytes == 0 && ticket->error));\n\ttrace_btrfs_reserve_ticket(fs_info, space_info->flags, orig_bytes,\n\t\t\t\t   start_ns, flush, ticket->error);\n\treturn ret;\n}\n\n \nstatic inline bool is_normal_flushing(enum btrfs_reserve_flush_enum flush)\n{\n\treturn\t(flush == BTRFS_RESERVE_FLUSH_ALL) ||\n\t\t(flush == BTRFS_RESERVE_FLUSH_ALL_STEAL);\n}\n\nstatic inline void maybe_clamp_preempt(struct btrfs_fs_info *fs_info,\n\t\t\t\t       struct btrfs_space_info *space_info)\n{\n\tu64 ordered = percpu_counter_sum_positive(&fs_info->ordered_bytes);\n\tu64 delalloc = percpu_counter_sum_positive(&fs_info->delalloc_bytes);\n\n\t \n\tif (ordered < delalloc)\n\t\tspace_info->clamp = min(space_info->clamp + 1, 8);\n}\n\nstatic inline bool can_steal(enum btrfs_reserve_flush_enum flush)\n{\n\treturn (flush == BTRFS_RESERVE_FLUSH_ALL_STEAL ||\n\t\tflush == BTRFS_RESERVE_FLUSH_EVICT);\n}\n\n \nstatic inline bool can_ticket(enum btrfs_reserve_flush_enum flush)\n{\n\treturn (flush != BTRFS_RESERVE_NO_FLUSH &&\n\t\tflush != BTRFS_RESERVE_FLUSH_EMERGENCY);\n}\n\n \nstatic int __reserve_bytes(struct btrfs_fs_info *fs_info,\n\t\t\t   struct btrfs_space_info *space_info, u64 orig_bytes,\n\t\t\t   enum btrfs_reserve_flush_enum flush)\n{\n\tstruct work_struct *async_work;\n\tstruct reserve_ticket ticket;\n\tu64 start_ns = 0;\n\tu64 used;\n\tint ret = -ENOSPC;\n\tbool pending_tickets;\n\n\tASSERT(orig_bytes);\n\t \n\tif (current->journal_info) {\n\t\t \n\t\tASSERT(flush != BTRFS_RESERVE_FLUSH_ALL);\n\t\tASSERT(flush != BTRFS_RESERVE_FLUSH_ALL_STEAL);\n\t\tASSERT(flush != BTRFS_RESERVE_FLUSH_EVICT);\n\t}\n\n\tif (flush == BTRFS_RESERVE_FLUSH_DATA)\n\t\tasync_work = &fs_info->async_data_reclaim_work;\n\telse\n\t\tasync_work = &fs_info->async_reclaim_work;\n\n\tspin_lock(&space_info->lock);\n\tused = btrfs_space_info_used(space_info, true);\n\n\t \n\tif (is_normal_flushing(flush) || (flush == BTRFS_RESERVE_NO_FLUSH))\n\t\tpending_tickets = !list_empty(&space_info->tickets) ||\n\t\t\t!list_empty(&space_info->priority_tickets);\n\telse\n\t\tpending_tickets = !list_empty(&space_info->priority_tickets);\n\n\t \n\tif (!pending_tickets &&\n\t    ((used + orig_bytes <= space_info->total_bytes) ||\n\t     btrfs_can_overcommit(fs_info, space_info, orig_bytes, flush))) {\n\t\tbtrfs_space_info_update_bytes_may_use(fs_info, space_info,\n\t\t\t\t\t\t      orig_bytes);\n\t\tret = 0;\n\t}\n\n\t \n\tif (ret && unlikely(flush == BTRFS_RESERVE_FLUSH_EMERGENCY)) {\n\t\tused = btrfs_space_info_used(space_info, false);\n\t\tif (used + orig_bytes <= space_info->total_bytes) {\n\t\t\tbtrfs_space_info_update_bytes_may_use(fs_info, space_info,\n\t\t\t\t\t\t\t      orig_bytes);\n\t\t\tret = 0;\n\t\t}\n\t}\n\n\t \n\tif (ret && can_ticket(flush)) {\n\t\tticket.bytes = orig_bytes;\n\t\tticket.error = 0;\n\t\tspace_info->reclaim_size += ticket.bytes;\n\t\tinit_waitqueue_head(&ticket.wait);\n\t\tticket.steal = can_steal(flush);\n\t\tif (trace_btrfs_reserve_ticket_enabled())\n\t\t\tstart_ns = ktime_get_ns();\n\n\t\tif (flush == BTRFS_RESERVE_FLUSH_ALL ||\n\t\t    flush == BTRFS_RESERVE_FLUSH_ALL_STEAL ||\n\t\t    flush == BTRFS_RESERVE_FLUSH_DATA) {\n\t\t\tlist_add_tail(&ticket.list, &space_info->tickets);\n\t\t\tif (!space_info->flush) {\n\t\t\t\t \n\t\t\t\tmaybe_clamp_preempt(fs_info, space_info);\n\n\t\t\t\tspace_info->flush = 1;\n\t\t\t\ttrace_btrfs_trigger_flush(fs_info,\n\t\t\t\t\t\t\t  space_info->flags,\n\t\t\t\t\t\t\t  orig_bytes, flush,\n\t\t\t\t\t\t\t  \"enospc\");\n\t\t\t\tqueue_work(system_unbound_wq, async_work);\n\t\t\t}\n\t\t} else {\n\t\t\tlist_add_tail(&ticket.list,\n\t\t\t\t      &space_info->priority_tickets);\n\t\t}\n\t} else if (!ret && space_info->flags & BTRFS_BLOCK_GROUP_METADATA) {\n\t\t \n\t\tif (!test_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags) &&\n\t\t    !work_busy(&fs_info->preempt_reclaim_work) &&\n\t\t    need_preemptive_reclaim(fs_info, space_info)) {\n\t\t\ttrace_btrfs_trigger_flush(fs_info, space_info->flags,\n\t\t\t\t\t\t  orig_bytes, flush, \"preempt\");\n\t\t\tqueue_work(system_unbound_wq,\n\t\t\t\t   &fs_info->preempt_reclaim_work);\n\t\t}\n\t}\n\tspin_unlock(&space_info->lock);\n\tif (!ret || !can_ticket(flush))\n\t\treturn ret;\n\n\treturn handle_reserve_ticket(fs_info, space_info, &ticket, start_ns,\n\t\t\t\t     orig_bytes, flush);\n}\n\n \nint btrfs_reserve_metadata_bytes(struct btrfs_fs_info *fs_info,\n\t\t\t\t struct btrfs_block_rsv *block_rsv,\n\t\t\t\t u64 orig_bytes,\n\t\t\t\t enum btrfs_reserve_flush_enum flush)\n{\n\tint ret;\n\n\tret = __reserve_bytes(fs_info, block_rsv->space_info, orig_bytes, flush);\n\tif (ret == -ENOSPC) {\n\t\ttrace_btrfs_space_reservation(fs_info, \"space_info:enospc\",\n\t\t\t\t\t      block_rsv->space_info->flags,\n\t\t\t\t\t      orig_bytes, 1);\n\n\t\tif (btrfs_test_opt(fs_info, ENOSPC_DEBUG))\n\t\t\tbtrfs_dump_space_info(fs_info, block_rsv->space_info,\n\t\t\t\t\t      orig_bytes, 0);\n\t}\n\treturn ret;\n}\n\n \nint btrfs_reserve_data_bytes(struct btrfs_fs_info *fs_info, u64 bytes,\n\t\t\t     enum btrfs_reserve_flush_enum flush)\n{\n\tstruct btrfs_space_info *data_sinfo = fs_info->data_sinfo;\n\tint ret;\n\n\tASSERT(flush == BTRFS_RESERVE_FLUSH_DATA ||\n\t       flush == BTRFS_RESERVE_FLUSH_FREE_SPACE_INODE ||\n\t       flush == BTRFS_RESERVE_NO_FLUSH);\n\tASSERT(!current->journal_info || flush != BTRFS_RESERVE_FLUSH_DATA);\n\n\tret = __reserve_bytes(fs_info, data_sinfo, bytes, flush);\n\tif (ret == -ENOSPC) {\n\t\ttrace_btrfs_space_reservation(fs_info, \"space_info:enospc\",\n\t\t\t\t\t      data_sinfo->flags, bytes, 1);\n\t\tif (btrfs_test_opt(fs_info, ENOSPC_DEBUG))\n\t\t\tbtrfs_dump_space_info(fs_info, data_sinfo, bytes, 0);\n\t}\n\treturn ret;\n}\n\n \n__cold void btrfs_dump_space_info_for_trans_abort(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_space_info *space_info;\n\n\tbtrfs_info(fs_info, \"dumping space info:\");\n\tlist_for_each_entry(space_info, &fs_info->space_info, list) {\n\t\tspin_lock(&space_info->lock);\n\t\t__btrfs_dump_space_info(fs_info, space_info);\n\t\tspin_unlock(&space_info->lock);\n\t}\n\tdump_global_block_rsv(fs_info);\n}\n\n \nu64 btrfs_account_ro_block_groups_free_space(struct btrfs_space_info *sinfo)\n{\n\tstruct btrfs_block_group *block_group;\n\tu64 free_bytes = 0;\n\tint factor;\n\n\t \n\tif (list_empty(&sinfo->ro_bgs))\n\t\treturn 0;\n\n\tspin_lock(&sinfo->lock);\n\tlist_for_each_entry(block_group, &sinfo->ro_bgs, ro_list) {\n\t\tspin_lock(&block_group->lock);\n\n\t\tif (!block_group->ro) {\n\t\t\tspin_unlock(&block_group->lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tfactor = btrfs_bg_type_to_factor(block_group->flags);\n\t\tfree_bytes += (block_group->length -\n\t\t\t       block_group->used) * factor;\n\n\t\tspin_unlock(&block_group->lock);\n\t}\n\tspin_unlock(&sinfo->lock);\n\n\treturn free_bytes;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}