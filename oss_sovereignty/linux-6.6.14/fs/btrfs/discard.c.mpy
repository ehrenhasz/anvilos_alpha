{
  "module_name": "discard.c",
  "hash_id": "c1c15cae966cbd6cf32fa6aad2e26cca5539dea5c15fff46f5579f7ef9580609",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/discard.c",
  "human_readable_source": "\n\n#include <linux/jiffies.h>\n#include <linux/kernel.h>\n#include <linux/ktime.h>\n#include <linux/list.h>\n#include <linux/math64.h>\n#include <linux/sizes.h>\n#include <linux/workqueue.h>\n#include \"ctree.h\"\n#include \"block-group.h\"\n#include \"discard.h\"\n#include \"free-space-cache.h\"\n#include \"fs.h\"\n\n \n\n \n#define BTRFS_DISCARD_DELAY\t\t(120ULL * NSEC_PER_SEC)\n#define BTRFS_DISCARD_UNUSED_DELAY\t(10ULL * NSEC_PER_SEC)\n\n#define BTRFS_DISCARD_MIN_DELAY_MSEC\t(1UL)\n#define BTRFS_DISCARD_MAX_DELAY_MSEC\t(1000UL)\n#define BTRFS_DISCARD_MAX_IOPS\t\t(1000U)\n\n \nstatic int discard_minlen[BTRFS_NR_DISCARD_LISTS] = {\n\t0,\n\tBTRFS_ASYNC_DISCARD_MAX_FILTER,\n\tBTRFS_ASYNC_DISCARD_MIN_FILTER\n};\n\nstatic struct list_head *get_discard_list(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t\t  struct btrfs_block_group *block_group)\n{\n\treturn &discard_ctl->discard_list[block_group->discard_index];\n}\n\n \nstatic bool btrfs_run_discard_work(struct btrfs_discard_ctl *discard_ctl)\n{\n\tstruct btrfs_fs_info *fs_info = container_of(discard_ctl,\n\t\t\t\t\t\t     struct btrfs_fs_info,\n\t\t\t\t\t\t     discard_ctl);\n\n\treturn (!(fs_info->sb->s_flags & SB_RDONLY) &&\n\t\ttest_bit(BTRFS_FS_DISCARD_RUNNING, &fs_info->flags));\n}\n\nstatic void __add_to_discard_list(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t  struct btrfs_block_group *block_group)\n{\n\tlockdep_assert_held(&discard_ctl->lock);\n\tif (!btrfs_run_discard_work(discard_ctl))\n\t\treturn;\n\n\tif (list_empty(&block_group->discard_list) ||\n\t    block_group->discard_index == BTRFS_DISCARD_INDEX_UNUSED) {\n\t\tif (block_group->discard_index == BTRFS_DISCARD_INDEX_UNUSED)\n\t\t\tblock_group->discard_index = BTRFS_DISCARD_INDEX_START;\n\t\tblock_group->discard_eligible_time = (ktime_get_ns() +\n\t\t\t\t\t\t      BTRFS_DISCARD_DELAY);\n\t\tblock_group->discard_state = BTRFS_DISCARD_RESET_CURSOR;\n\t}\n\tif (list_empty(&block_group->discard_list))\n\t\tbtrfs_get_block_group(block_group);\n\n\tlist_move_tail(&block_group->discard_list,\n\t\t       get_discard_list(discard_ctl, block_group));\n}\n\nstatic void add_to_discard_list(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\tstruct btrfs_block_group *block_group)\n{\n\tif (!btrfs_is_block_group_data_only(block_group))\n\t\treturn;\n\n\tspin_lock(&discard_ctl->lock);\n\t__add_to_discard_list(discard_ctl, block_group);\n\tspin_unlock(&discard_ctl->lock);\n}\n\nstatic void add_to_discard_unused_list(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t       struct btrfs_block_group *block_group)\n{\n\tbool queued;\n\n\tspin_lock(&discard_ctl->lock);\n\n\tqueued = !list_empty(&block_group->discard_list);\n\n\tif (!btrfs_run_discard_work(discard_ctl)) {\n\t\tspin_unlock(&discard_ctl->lock);\n\t\treturn;\n\t}\n\n\tlist_del_init(&block_group->discard_list);\n\n\tblock_group->discard_index = BTRFS_DISCARD_INDEX_UNUSED;\n\tblock_group->discard_eligible_time = (ktime_get_ns() +\n\t\t\t\t\t      BTRFS_DISCARD_UNUSED_DELAY);\n\tblock_group->discard_state = BTRFS_DISCARD_RESET_CURSOR;\n\tif (!queued)\n\t\tbtrfs_get_block_group(block_group);\n\tlist_add_tail(&block_group->discard_list,\n\t\t      &discard_ctl->discard_list[BTRFS_DISCARD_INDEX_UNUSED]);\n\n\tspin_unlock(&discard_ctl->lock);\n}\n\nstatic bool remove_from_discard_list(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t     struct btrfs_block_group *block_group)\n{\n\tbool running = false;\n\tbool queued = false;\n\n\tspin_lock(&discard_ctl->lock);\n\n\tif (block_group == discard_ctl->block_group) {\n\t\trunning = true;\n\t\tdiscard_ctl->block_group = NULL;\n\t}\n\n\tblock_group->discard_eligible_time = 0;\n\tqueued = !list_empty(&block_group->discard_list);\n\tlist_del_init(&block_group->discard_list);\n\t \n\tif (queued && !running)\n\t\tbtrfs_put_block_group(block_group);\n\n\tspin_unlock(&discard_ctl->lock);\n\n\treturn running;\n}\n\n \nstatic struct btrfs_block_group *find_next_block_group(\n\t\t\t\t\tstruct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t\tu64 now)\n{\n\tstruct btrfs_block_group *ret_block_group = NULL, *block_group;\n\tint i;\n\n\tfor (i = 0; i < BTRFS_NR_DISCARD_LISTS; i++) {\n\t\tstruct list_head *discard_list = &discard_ctl->discard_list[i];\n\n\t\tif (!list_empty(discard_list)) {\n\t\t\tblock_group = list_first_entry(discard_list,\n\t\t\t\t\t\t       struct btrfs_block_group,\n\t\t\t\t\t\t       discard_list);\n\n\t\t\tif (!ret_block_group)\n\t\t\t\tret_block_group = block_group;\n\n\t\t\tif (ret_block_group->discard_eligible_time < now)\n\t\t\t\tbreak;\n\n\t\t\tif (ret_block_group->discard_eligible_time >\n\t\t\t    block_group->discard_eligible_time)\n\t\t\t\tret_block_group = block_group;\n\t\t}\n\t}\n\n\treturn ret_block_group;\n}\n\n \nstatic struct btrfs_block_group *peek_discard_list(\n\t\t\t\t\tstruct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t\tenum btrfs_discard_state *discard_state,\n\t\t\t\t\tint *discard_index, u64 now)\n{\n\tstruct btrfs_block_group *block_group;\n\n\tspin_lock(&discard_ctl->lock);\nagain:\n\tblock_group = find_next_block_group(discard_ctl, now);\n\n\tif (block_group && now >= block_group->discard_eligible_time) {\n\t\tif (block_group->discard_index == BTRFS_DISCARD_INDEX_UNUSED &&\n\t\t    block_group->used != 0) {\n\t\t\tif (btrfs_is_block_group_data_only(block_group)) {\n\t\t\t\t__add_to_discard_list(discard_ctl, block_group);\n\t\t\t} else {\n\t\t\t\tlist_del_init(&block_group->discard_list);\n\t\t\t\tbtrfs_put_block_group(block_group);\n\t\t\t}\n\t\t\tgoto again;\n\t\t}\n\t\tif (block_group->discard_state == BTRFS_DISCARD_RESET_CURSOR) {\n\t\t\tblock_group->discard_cursor = block_group->start;\n\t\t\tblock_group->discard_state = BTRFS_DISCARD_EXTENTS;\n\t\t}\n\t\tdiscard_ctl->block_group = block_group;\n\t}\n\tif (block_group) {\n\t\t*discard_state = block_group->discard_state;\n\t\t*discard_index = block_group->discard_index;\n\t}\n\tspin_unlock(&discard_ctl->lock);\n\n\treturn block_group;\n}\n\n \nvoid btrfs_discard_check_filter(struct btrfs_block_group *block_group,\n\t\t\t\tu64 bytes)\n{\n\tstruct btrfs_discard_ctl *discard_ctl;\n\n\tif (!block_group ||\n\t    !btrfs_test_opt(block_group->fs_info, DISCARD_ASYNC))\n\t\treturn;\n\n\tdiscard_ctl = &block_group->fs_info->discard_ctl;\n\n\tif (block_group->discard_index > BTRFS_DISCARD_INDEX_START &&\n\t    bytes >= discard_minlen[block_group->discard_index - 1]) {\n\t\tint i;\n\n\t\tremove_from_discard_list(discard_ctl, block_group);\n\n\t\tfor (i = BTRFS_DISCARD_INDEX_START; i < BTRFS_NR_DISCARD_LISTS;\n\t\t     i++) {\n\t\t\tif (bytes >= discard_minlen[i]) {\n\t\t\t\tblock_group->discard_index = i;\n\t\t\t\tadd_to_discard_list(discard_ctl, block_group);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic void btrfs_update_discard_index(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t       struct btrfs_block_group *block_group)\n{\n\tblock_group->discard_index++;\n\tif (block_group->discard_index == BTRFS_NR_DISCARD_LISTS) {\n\t\tblock_group->discard_index = 1;\n\t\treturn;\n\t}\n\n\tadd_to_discard_list(discard_ctl, block_group);\n}\n\n \nvoid btrfs_discard_cancel_work(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t       struct btrfs_block_group *block_group)\n{\n\tif (remove_from_discard_list(discard_ctl, block_group)) {\n\t\tcancel_delayed_work_sync(&discard_ctl->work);\n\t\tbtrfs_discard_schedule_work(discard_ctl, true);\n\t}\n}\n\n \nvoid btrfs_discard_queue_work(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t      struct btrfs_block_group *block_group)\n{\n\tif (!block_group || !btrfs_test_opt(block_group->fs_info, DISCARD_ASYNC))\n\t\treturn;\n\n\tif (block_group->used == 0)\n\t\tadd_to_discard_unused_list(discard_ctl, block_group);\n\telse\n\t\tadd_to_discard_list(discard_ctl, block_group);\n\n\tif (!delayed_work_pending(&discard_ctl->work))\n\t\tbtrfs_discard_schedule_work(discard_ctl, false);\n}\n\nstatic void __btrfs_discard_schedule_work(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t\t  u64 now, bool override)\n{\n\tstruct btrfs_block_group *block_group;\n\n\tif (!btrfs_run_discard_work(discard_ctl))\n\t\treturn;\n\tif (!override && delayed_work_pending(&discard_ctl->work))\n\t\treturn;\n\n\tblock_group = find_next_block_group(discard_ctl, now);\n\tif (block_group) {\n\t\tu64 delay = discard_ctl->delay_ms * NSEC_PER_MSEC;\n\t\tu32 kbps_limit = READ_ONCE(discard_ctl->kbps_limit);\n\n\t\t \n\t\tif (kbps_limit && discard_ctl->prev_discard) {\n\t\t\tu64 bps_limit = ((u64)kbps_limit) * SZ_1K;\n\t\t\tu64 bps_delay = div64_u64(discard_ctl->prev_discard *\n\t\t\t\t\t\t  NSEC_PER_SEC, bps_limit);\n\n\t\t\tdelay = max(delay, bps_delay);\n\t\t}\n\n\t\t \n\t\tif (now < block_group->discard_eligible_time) {\n\t\t\tu64 bg_timeout = block_group->discard_eligible_time - now;\n\n\t\t\tdelay = max(delay, bg_timeout);\n\t\t}\n\n\t\tif (override && discard_ctl->prev_discard) {\n\t\t\tu64 elapsed = now - discard_ctl->prev_discard_time;\n\n\t\t\tif (delay > elapsed)\n\t\t\t\tdelay -= elapsed;\n\t\t\telse\n\t\t\t\tdelay = 0;\n\t\t}\n\n\t\tmod_delayed_work(discard_ctl->discard_workers,\n\t\t\t\t &discard_ctl->work, nsecs_to_jiffies(delay));\n\t}\n}\n\n \nvoid btrfs_discard_schedule_work(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t bool override)\n{\n\tconst u64 now = ktime_get_ns();\n\n\tspin_lock(&discard_ctl->lock);\n\t__btrfs_discard_schedule_work(discard_ctl, now, override);\n\tspin_unlock(&discard_ctl->lock);\n}\n\n \nstatic void btrfs_finish_discard_pass(struct btrfs_discard_ctl *discard_ctl,\n\t\t\t\t      struct btrfs_block_group *block_group)\n{\n\tremove_from_discard_list(discard_ctl, block_group);\n\n\tif (block_group->used == 0) {\n\t\tif (btrfs_is_free_space_trimmed(block_group))\n\t\t\tbtrfs_mark_bg_unused(block_group);\n\t\telse\n\t\t\tadd_to_discard_unused_list(discard_ctl, block_group);\n\t} else {\n\t\tbtrfs_update_discard_index(discard_ctl, block_group);\n\t}\n}\n\n \nstatic void btrfs_discard_workfn(struct work_struct *work)\n{\n\tstruct btrfs_discard_ctl *discard_ctl;\n\tstruct btrfs_block_group *block_group;\n\tenum btrfs_discard_state discard_state;\n\tint discard_index = 0;\n\tu64 trimmed = 0;\n\tu64 minlen = 0;\n\tu64 now = ktime_get_ns();\n\n\tdiscard_ctl = container_of(work, struct btrfs_discard_ctl, work.work);\n\n\tblock_group = peek_discard_list(discard_ctl, &discard_state,\n\t\t\t\t\t&discard_index, now);\n\tif (!block_group || !btrfs_run_discard_work(discard_ctl))\n\t\treturn;\n\tif (now < block_group->discard_eligible_time) {\n\t\tbtrfs_discard_schedule_work(discard_ctl, false);\n\t\treturn;\n\t}\n\n\t \n\tminlen = discard_minlen[discard_index];\n\n\tif (discard_state == BTRFS_DISCARD_BITMAPS) {\n\t\tu64 maxlen = 0;\n\n\t\t \n\t\tif (discard_index != BTRFS_DISCARD_INDEX_UNUSED)\n\t\t\tmaxlen = discard_minlen[discard_index - 1];\n\n\t\tbtrfs_trim_block_group_bitmaps(block_group, &trimmed,\n\t\t\t\t       block_group->discard_cursor,\n\t\t\t\t       btrfs_block_group_end(block_group),\n\t\t\t\t       minlen, maxlen, true);\n\t\tdiscard_ctl->discard_bitmap_bytes += trimmed;\n\t} else {\n\t\tbtrfs_trim_block_group_extents(block_group, &trimmed,\n\t\t\t\t       block_group->discard_cursor,\n\t\t\t\t       btrfs_block_group_end(block_group),\n\t\t\t\t       minlen, true);\n\t\tdiscard_ctl->discard_extent_bytes += trimmed;\n\t}\n\n\t \n\tif (block_group->discard_cursor >= btrfs_block_group_end(block_group)) {\n\t\tif (discard_state == BTRFS_DISCARD_BITMAPS) {\n\t\t\tbtrfs_finish_discard_pass(discard_ctl, block_group);\n\t\t} else {\n\t\t\tblock_group->discard_cursor = block_group->start;\n\t\t\tspin_lock(&discard_ctl->lock);\n\t\t\tif (block_group->discard_state !=\n\t\t\t    BTRFS_DISCARD_RESET_CURSOR)\n\t\t\t\tblock_group->discard_state =\n\t\t\t\t\t\t\tBTRFS_DISCARD_BITMAPS;\n\t\t\tspin_unlock(&discard_ctl->lock);\n\t\t}\n\t}\n\n\tnow = ktime_get_ns();\n\tspin_lock(&discard_ctl->lock);\n\tdiscard_ctl->prev_discard = trimmed;\n\tdiscard_ctl->prev_discard_time = now;\n\t \n\tif (discard_ctl->block_group == NULL)\n\t\tbtrfs_put_block_group(block_group);\n\tdiscard_ctl->block_group = NULL;\n\t__btrfs_discard_schedule_work(discard_ctl, now, false);\n\tspin_unlock(&discard_ctl->lock);\n}\n\n \nvoid btrfs_discard_calc_delay(struct btrfs_discard_ctl *discard_ctl)\n{\n\ts32 discardable_extents;\n\ts64 discardable_bytes;\n\tu32 iops_limit;\n\tunsigned long min_delay = BTRFS_DISCARD_MIN_DELAY_MSEC;\n\tunsigned long delay;\n\n\tdiscardable_extents = atomic_read(&discard_ctl->discardable_extents);\n\tif (!discardable_extents)\n\t\treturn;\n\n\tspin_lock(&discard_ctl->lock);\n\n\t \n\tif (discardable_extents < 0)\n\t\tatomic_add(-discardable_extents,\n\t\t\t   &discard_ctl->discardable_extents);\n\n\tdiscardable_bytes = atomic64_read(&discard_ctl->discardable_bytes);\n\tif (discardable_bytes < 0)\n\t\tatomic64_add(-discardable_bytes,\n\t\t\t     &discard_ctl->discardable_bytes);\n\n\tif (discardable_extents <= 0) {\n\t\tspin_unlock(&discard_ctl->lock);\n\t\treturn;\n\t}\n\n\tiops_limit = READ_ONCE(discard_ctl->iops_limit);\n\n\tif (iops_limit) {\n\t\tdelay = MSEC_PER_SEC / iops_limit;\n\t} else {\n\t\t \n\t\tdelay = 0;\n\t\tmin_delay = 0;\n\t}\n\n\tdelay = clamp(delay, min_delay, BTRFS_DISCARD_MAX_DELAY_MSEC);\n\tdiscard_ctl->delay_ms = delay;\n\n\tspin_unlock(&discard_ctl->lock);\n}\n\n \nvoid btrfs_discard_update_discardable(struct btrfs_block_group *block_group)\n{\n\tstruct btrfs_free_space_ctl *ctl;\n\tstruct btrfs_discard_ctl *discard_ctl;\n\ts32 extents_delta;\n\ts64 bytes_delta;\n\n\tif (!block_group ||\n\t    !btrfs_test_opt(block_group->fs_info, DISCARD_ASYNC) ||\n\t    !btrfs_is_block_group_data_only(block_group))\n\t\treturn;\n\n\tctl = block_group->free_space_ctl;\n\tdiscard_ctl = &block_group->fs_info->discard_ctl;\n\n\tlockdep_assert_held(&ctl->tree_lock);\n\textents_delta = ctl->discardable_extents[BTRFS_STAT_CURR] -\n\t\t\tctl->discardable_extents[BTRFS_STAT_PREV];\n\tif (extents_delta) {\n\t\tatomic_add(extents_delta, &discard_ctl->discardable_extents);\n\t\tctl->discardable_extents[BTRFS_STAT_PREV] =\n\t\t\tctl->discardable_extents[BTRFS_STAT_CURR];\n\t}\n\n\tbytes_delta = ctl->discardable_bytes[BTRFS_STAT_CURR] -\n\t\t      ctl->discardable_bytes[BTRFS_STAT_PREV];\n\tif (bytes_delta) {\n\t\tatomic64_add(bytes_delta, &discard_ctl->discardable_bytes);\n\t\tctl->discardable_bytes[BTRFS_STAT_PREV] =\n\t\t\tctl->discardable_bytes[BTRFS_STAT_CURR];\n\t}\n}\n\n \nvoid btrfs_discard_punt_unused_bgs_list(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_block_group *block_group, *next;\n\n\tspin_lock(&fs_info->unused_bgs_lock);\n\t \n\tlist_for_each_entry_safe(block_group, next, &fs_info->unused_bgs,\n\t\t\t\t bg_list) {\n\t\tlist_del_init(&block_group->bg_list);\n\t\tbtrfs_discard_queue_work(&fs_info->discard_ctl, block_group);\n\t\t \n\t\tbtrfs_put_block_group(block_group);\n\t}\n\tspin_unlock(&fs_info->unused_bgs_lock);\n}\n\n \nstatic void btrfs_discard_purge_list(struct btrfs_discard_ctl *discard_ctl)\n{\n\tstruct btrfs_block_group *block_group, *next;\n\tint i;\n\n\tspin_lock(&discard_ctl->lock);\n\tfor (i = 0; i < BTRFS_NR_DISCARD_LISTS; i++) {\n\t\tlist_for_each_entry_safe(block_group, next,\n\t\t\t\t\t &discard_ctl->discard_list[i],\n\t\t\t\t\t discard_list) {\n\t\t\tlist_del_init(&block_group->discard_list);\n\t\t\tspin_unlock(&discard_ctl->lock);\n\t\t\tif (block_group->used == 0)\n\t\t\t\tbtrfs_mark_bg_unused(block_group);\n\t\t\tspin_lock(&discard_ctl->lock);\n\t\t\tbtrfs_put_block_group(block_group);\n\t\t}\n\t}\n\tspin_unlock(&discard_ctl->lock);\n}\n\nvoid btrfs_discard_resume(struct btrfs_fs_info *fs_info)\n{\n\tif (!btrfs_test_opt(fs_info, DISCARD_ASYNC)) {\n\t\tbtrfs_discard_cleanup(fs_info);\n\t\treturn;\n\t}\n\n\tbtrfs_discard_punt_unused_bgs_list(fs_info);\n\n\tset_bit(BTRFS_FS_DISCARD_RUNNING, &fs_info->flags);\n}\n\nvoid btrfs_discard_stop(struct btrfs_fs_info *fs_info)\n{\n\tclear_bit(BTRFS_FS_DISCARD_RUNNING, &fs_info->flags);\n}\n\nvoid btrfs_discard_init(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_discard_ctl *discard_ctl = &fs_info->discard_ctl;\n\tint i;\n\n\tspin_lock_init(&discard_ctl->lock);\n\tINIT_DELAYED_WORK(&discard_ctl->work, btrfs_discard_workfn);\n\n\tfor (i = 0; i < BTRFS_NR_DISCARD_LISTS; i++)\n\t\tINIT_LIST_HEAD(&discard_ctl->discard_list[i]);\n\n\tdiscard_ctl->prev_discard = 0;\n\tdiscard_ctl->prev_discard_time = 0;\n\tatomic_set(&discard_ctl->discardable_extents, 0);\n\tatomic64_set(&discard_ctl->discardable_bytes, 0);\n\tdiscard_ctl->max_discard_size = BTRFS_ASYNC_DISCARD_DEFAULT_MAX_SIZE;\n\tdiscard_ctl->delay_ms = BTRFS_DISCARD_MAX_DELAY_MSEC;\n\tdiscard_ctl->iops_limit = BTRFS_DISCARD_MAX_IOPS;\n\tdiscard_ctl->kbps_limit = 0;\n\tdiscard_ctl->discard_extent_bytes = 0;\n\tdiscard_ctl->discard_bitmap_bytes = 0;\n\tatomic64_set(&discard_ctl->discard_bytes_saved, 0);\n}\n\nvoid btrfs_discard_cleanup(struct btrfs_fs_info *fs_info)\n{\n\tbtrfs_discard_stop(fs_info);\n\tcancel_delayed_work_sync(&fs_info->discard_ctl.work);\n\tbtrfs_discard_purge_list(&fs_info->discard_ctl);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}