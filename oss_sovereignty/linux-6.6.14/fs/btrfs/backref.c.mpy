{
  "module_name": "backref.c",
  "hash_id": "eef9f2a51e6b5a0c9adc70eab30555694945dc16798f3f9866b4caa4dd023dc9",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/backref.c",
  "human_readable_source": "\n \n\n#include <linux/mm.h>\n#include <linux/rbtree.h>\n#include <trace/events/btrfs.h>\n#include \"ctree.h\"\n#include \"disk-io.h\"\n#include \"backref.h\"\n#include \"ulist.h\"\n#include \"transaction.h\"\n#include \"delayed-ref.h\"\n#include \"locking.h\"\n#include \"misc.h\"\n#include \"tree-mod-log.h\"\n#include \"fs.h\"\n#include \"accessors.h\"\n#include \"extent-tree.h\"\n#include \"relocation.h\"\n#include \"tree-checker.h\"\n\n \n#define BACKREF_FOUND_SHARED     6\n#define BACKREF_FOUND_NOT_SHARED 7\n\nstruct extent_inode_elem {\n\tu64 inum;\n\tu64 offset;\n\tu64 num_bytes;\n\tstruct extent_inode_elem *next;\n};\n\nstatic int check_extent_in_eb(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t      const struct btrfs_key *key,\n\t\t\t      const struct extent_buffer *eb,\n\t\t\t      const struct btrfs_file_extent_item *fi,\n\t\t\t      struct extent_inode_elem **eie)\n{\n\tconst u64 data_len = btrfs_file_extent_num_bytes(eb, fi);\n\tu64 offset = key->offset;\n\tstruct extent_inode_elem *e;\n\tconst u64 *root_ids;\n\tint root_count;\n\tbool cached;\n\n\tif (!ctx->ignore_extent_item_pos &&\n\t    !btrfs_file_extent_compression(eb, fi) &&\n\t    !btrfs_file_extent_encryption(eb, fi) &&\n\t    !btrfs_file_extent_other_encoding(eb, fi)) {\n\t\tu64 data_offset;\n\n\t\tdata_offset = btrfs_file_extent_offset(eb, fi);\n\n\t\tif (ctx->extent_item_pos < data_offset ||\n\t\t    ctx->extent_item_pos >= data_offset + data_len)\n\t\t\treturn 1;\n\t\toffset += ctx->extent_item_pos - data_offset;\n\t}\n\n\tif (!ctx->indirect_ref_iterator || !ctx->cache_lookup)\n\t\tgoto add_inode_elem;\n\n\tcached = ctx->cache_lookup(eb->start, ctx->user_ctx, &root_ids,\n\t\t\t\t   &root_count);\n\tif (!cached)\n\t\tgoto add_inode_elem;\n\n\tfor (int i = 0; i < root_count; i++) {\n\t\tint ret;\n\n\t\tret = ctx->indirect_ref_iterator(key->objectid, offset,\n\t\t\t\t\t\t data_len, root_ids[i],\n\t\t\t\t\t\t ctx->user_ctx);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\nadd_inode_elem:\n\te = kmalloc(sizeof(*e), GFP_NOFS);\n\tif (!e)\n\t\treturn -ENOMEM;\n\n\te->next = *eie;\n\te->inum = key->objectid;\n\te->offset = offset;\n\te->num_bytes = data_len;\n\t*eie = e;\n\n\treturn 0;\n}\n\nstatic void free_inode_elem_list(struct extent_inode_elem *eie)\n{\n\tstruct extent_inode_elem *eie_next;\n\n\tfor (; eie; eie = eie_next) {\n\t\teie_next = eie->next;\n\t\tkfree(eie);\n\t}\n}\n\nstatic int find_extent_in_eb(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t     const struct extent_buffer *eb,\n\t\t\t     struct extent_inode_elem **eie)\n{\n\tu64 disk_byte;\n\tstruct btrfs_key key;\n\tstruct btrfs_file_extent_item *fi;\n\tint slot;\n\tint nritems;\n\tint extent_type;\n\tint ret;\n\n\t \n\tnritems = btrfs_header_nritems(eb);\n\tfor (slot = 0; slot < nritems; ++slot) {\n\t\tbtrfs_item_key_to_cpu(eb, &key, slot);\n\t\tif (key.type != BTRFS_EXTENT_DATA_KEY)\n\t\t\tcontinue;\n\t\tfi = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item);\n\t\textent_type = btrfs_file_extent_type(eb, fi);\n\t\tif (extent_type == BTRFS_FILE_EXTENT_INLINE)\n\t\t\tcontinue;\n\t\t \n\t\tdisk_byte = btrfs_file_extent_disk_bytenr(eb, fi);\n\t\tif (disk_byte != ctx->bytenr)\n\t\t\tcontinue;\n\n\t\tret = check_extent_in_eb(ctx, &key, eb, fi, eie);\n\t\tif (ret == BTRFS_ITERATE_EXTENT_INODES_STOP || ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstruct preftree {\n\tstruct rb_root_cached root;\n\tunsigned int count;\n};\n\n#define PREFTREE_INIT\t{ .root = RB_ROOT_CACHED, .count = 0 }\n\nstruct preftrees {\n\tstruct preftree direct;     \n\tstruct preftree indirect;   \n\tstruct preftree indirect_missing_keys;\n};\n\n \nstruct share_check {\n\tstruct btrfs_backref_share_check_ctx *ctx;\n\tstruct btrfs_root *root;\n\tu64 inum;\n\tu64 data_bytenr;\n\tu64 data_extent_gen;\n\t \n\tint share_count;\n\t \n\tint self_ref_count;\n\tbool have_delayed_delete_refs;\n};\n\nstatic inline int extent_is_shared(struct share_check *sc)\n{\n\treturn (sc && sc->share_count > 1) ? BACKREF_FOUND_SHARED : 0;\n}\n\nstatic struct kmem_cache *btrfs_prelim_ref_cache;\n\nint __init btrfs_prelim_ref_init(void)\n{\n\tbtrfs_prelim_ref_cache = kmem_cache_create(\"btrfs_prelim_ref\",\n\t\t\t\t\tsizeof(struct prelim_ref),\n\t\t\t\t\t0,\n\t\t\t\t\tSLAB_MEM_SPREAD,\n\t\t\t\t\tNULL);\n\tif (!btrfs_prelim_ref_cache)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid __cold btrfs_prelim_ref_exit(void)\n{\n\tkmem_cache_destroy(btrfs_prelim_ref_cache);\n}\n\nstatic void free_pref(struct prelim_ref *ref)\n{\n\tkmem_cache_free(btrfs_prelim_ref_cache, ref);\n}\n\n \nstatic int prelim_ref_compare(struct prelim_ref *ref1,\n\t\t\t      struct prelim_ref *ref2)\n{\n\tif (ref1->level < ref2->level)\n\t\treturn -1;\n\tif (ref1->level > ref2->level)\n\t\treturn 1;\n\tif (ref1->root_id < ref2->root_id)\n\t\treturn -1;\n\tif (ref1->root_id > ref2->root_id)\n\t\treturn 1;\n\tif (ref1->key_for_search.type < ref2->key_for_search.type)\n\t\treturn -1;\n\tif (ref1->key_for_search.type > ref2->key_for_search.type)\n\t\treturn 1;\n\tif (ref1->key_for_search.objectid < ref2->key_for_search.objectid)\n\t\treturn -1;\n\tif (ref1->key_for_search.objectid > ref2->key_for_search.objectid)\n\t\treturn 1;\n\tif (ref1->key_for_search.offset < ref2->key_for_search.offset)\n\t\treturn -1;\n\tif (ref1->key_for_search.offset > ref2->key_for_search.offset)\n\t\treturn 1;\n\tif (ref1->parent < ref2->parent)\n\t\treturn -1;\n\tif (ref1->parent > ref2->parent)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic void update_share_count(struct share_check *sc, int oldcount,\n\t\t\t       int newcount, struct prelim_ref *newref)\n{\n\tif ((!sc) || (oldcount == 0 && newcount < 1))\n\t\treturn;\n\n\tif (oldcount > 0 && newcount < 1)\n\t\tsc->share_count--;\n\telse if (oldcount < 1 && newcount > 0)\n\t\tsc->share_count++;\n\n\tif (newref->root_id == sc->root->root_key.objectid &&\n\t    newref->wanted_disk_byte == sc->data_bytenr &&\n\t    newref->key_for_search.objectid == sc->inum)\n\t\tsc->self_ref_count += newref->count;\n}\n\n \nstatic void prelim_ref_insert(const struct btrfs_fs_info *fs_info,\n\t\t\t      struct preftree *preftree,\n\t\t\t      struct prelim_ref *newref,\n\t\t\t      struct share_check *sc)\n{\n\tstruct rb_root_cached *root;\n\tstruct rb_node **p;\n\tstruct rb_node *parent = NULL;\n\tstruct prelim_ref *ref;\n\tint result;\n\tbool leftmost = true;\n\n\troot = &preftree->root;\n\tp = &root->rb_root.rb_node;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tref = rb_entry(parent, struct prelim_ref, rbnode);\n\t\tresult = prelim_ref_compare(ref, newref);\n\t\tif (result < 0) {\n\t\t\tp = &(*p)->rb_left;\n\t\t} else if (result > 0) {\n\t\t\tp = &(*p)->rb_right;\n\t\t\tleftmost = false;\n\t\t} else {\n\t\t\t \n\t\t\tstruct extent_inode_elem *eie = ref->inode_list;\n\n\t\t\twhile (eie && eie->next)\n\t\t\t\teie = eie->next;\n\n\t\t\tif (!eie)\n\t\t\t\tref->inode_list = newref->inode_list;\n\t\t\telse\n\t\t\t\teie->next = newref->inode_list;\n\t\t\ttrace_btrfs_prelim_ref_merge(fs_info, ref, newref,\n\t\t\t\t\t\t     preftree->count);\n\t\t\t \n\t\t\tupdate_share_count(sc, ref->count,\n\t\t\t\t\t   ref->count + newref->count, newref);\n\t\t\tref->count += newref->count;\n\t\t\tfree_pref(newref);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tupdate_share_count(sc, 0, newref->count, newref);\n\tpreftree->count++;\n\ttrace_btrfs_prelim_ref_insert(fs_info, newref, NULL, preftree->count);\n\trb_link_node(&newref->rbnode, parent, p);\n\trb_insert_color_cached(&newref->rbnode, root, leftmost);\n}\n\n \nstatic void prelim_release(struct preftree *preftree)\n{\n\tstruct prelim_ref *ref, *next_ref;\n\n\trbtree_postorder_for_each_entry_safe(ref, next_ref,\n\t\t\t\t\t     &preftree->root.rb_root, rbnode) {\n\t\tfree_inode_elem_list(ref->inode_list);\n\t\tfree_pref(ref);\n\t}\n\n\tpreftree->root = RB_ROOT_CACHED;\n\tpreftree->count = 0;\n}\n\n \nstatic int add_prelim_ref(const struct btrfs_fs_info *fs_info,\n\t\t\t  struct preftree *preftree, u64 root_id,\n\t\t\t  const struct btrfs_key *key, int level, u64 parent,\n\t\t\t  u64 wanted_disk_byte, int count,\n\t\t\t  struct share_check *sc, gfp_t gfp_mask)\n{\n\tstruct prelim_ref *ref;\n\n\tif (root_id == BTRFS_DATA_RELOC_TREE_OBJECTID)\n\t\treturn 0;\n\n\tref = kmem_cache_alloc(btrfs_prelim_ref_cache, gfp_mask);\n\tif (!ref)\n\t\treturn -ENOMEM;\n\n\tref->root_id = root_id;\n\tif (key)\n\t\tref->key_for_search = *key;\n\telse\n\t\tmemset(&ref->key_for_search, 0, sizeof(ref->key_for_search));\n\n\tref->inode_list = NULL;\n\tref->level = level;\n\tref->count = count;\n\tref->parent = parent;\n\tref->wanted_disk_byte = wanted_disk_byte;\n\tprelim_ref_insert(fs_info, preftree, ref, sc);\n\treturn extent_is_shared(sc);\n}\n\n \nstatic int add_direct_ref(const struct btrfs_fs_info *fs_info,\n\t\t\t  struct preftrees *preftrees, int level, u64 parent,\n\t\t\t  u64 wanted_disk_byte, int count,\n\t\t\t  struct share_check *sc, gfp_t gfp_mask)\n{\n\treturn add_prelim_ref(fs_info, &preftrees->direct, 0, NULL, level,\n\t\t\t      parent, wanted_disk_byte, count, sc, gfp_mask);\n}\n\n \nstatic int add_indirect_ref(const struct btrfs_fs_info *fs_info,\n\t\t\t    struct preftrees *preftrees, u64 root_id,\n\t\t\t    const struct btrfs_key *key, int level,\n\t\t\t    u64 wanted_disk_byte, int count,\n\t\t\t    struct share_check *sc, gfp_t gfp_mask)\n{\n\tstruct preftree *tree = &preftrees->indirect;\n\n\tif (!key)\n\t\ttree = &preftrees->indirect_missing_keys;\n\treturn add_prelim_ref(fs_info, tree, root_id, key, level, 0,\n\t\t\t      wanted_disk_byte, count, sc, gfp_mask);\n}\n\nstatic int is_shared_data_backref(struct preftrees *preftrees, u64 bytenr)\n{\n\tstruct rb_node **p = &preftrees->direct.root.rb_root.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct prelim_ref *ref = NULL;\n\tstruct prelim_ref target = {};\n\tint result;\n\n\ttarget.parent = bytenr;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tref = rb_entry(parent, struct prelim_ref, rbnode);\n\t\tresult = prelim_ref_compare(ref, &target);\n\n\t\tif (result < 0)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (result > 0)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic int add_all_parents(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t   struct btrfs_root *root, struct btrfs_path *path,\n\t\t\t   struct ulist *parents,\n\t\t\t   struct preftrees *preftrees, struct prelim_ref *ref,\n\t\t\t   int level)\n{\n\tint ret = 0;\n\tint slot;\n\tstruct extent_buffer *eb;\n\tstruct btrfs_key key;\n\tstruct btrfs_key *key_for_search = &ref->key_for_search;\n\tstruct btrfs_file_extent_item *fi;\n\tstruct extent_inode_elem *eie = NULL, *old = NULL;\n\tu64 disk_byte;\n\tu64 wanted_disk_byte = ref->wanted_disk_byte;\n\tu64 count = 0;\n\tu64 data_offset;\n\tu8 type;\n\n\tif (level != 0) {\n\t\teb = path->nodes[level];\n\t\tret = ulist_add(parents, eb->start, 0, GFP_NOFS);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\treturn 0;\n\t}\n\n\t \n\teb = path->nodes[0];\n\tif (path->slots[0] >= btrfs_header_nritems(eb) ||\n\t    is_shared_data_backref(preftrees, eb->start) ||\n\t    ref->root_id != btrfs_header_owner(eb)) {\n\t\tif (ctx->time_seq == BTRFS_SEQ_LAST)\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\telse\n\t\t\tret = btrfs_next_old_leaf(root, path, ctx->time_seq);\n\t}\n\n\twhile (!ret && count < ref->count) {\n\t\teb = path->nodes[0];\n\t\tslot = path->slots[0];\n\n\t\tbtrfs_item_key_to_cpu(eb, &key, slot);\n\n\t\tif (key.objectid != key_for_search->objectid ||\n\t\t    key.type != BTRFS_EXTENT_DATA_KEY)\n\t\t\tbreak;\n\n\t\t \n\t\tif (slot == 0 &&\n\t\t    (is_shared_data_backref(preftrees, eb->start) ||\n\t\t     ref->root_id != btrfs_header_owner(eb))) {\n\t\t\tif (ctx->time_seq == BTRFS_SEQ_LAST)\n\t\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\telse\n\t\t\t\tret = btrfs_next_old_leaf(root, path, ctx->time_seq);\n\t\t\tcontinue;\n\t\t}\n\t\tfi = btrfs_item_ptr(eb, slot, struct btrfs_file_extent_item);\n\t\ttype = btrfs_file_extent_type(eb, fi);\n\t\tif (type == BTRFS_FILE_EXTENT_INLINE)\n\t\t\tgoto next;\n\t\tdisk_byte = btrfs_file_extent_disk_bytenr(eb, fi);\n\t\tdata_offset = btrfs_file_extent_offset(eb, fi);\n\n\t\tif (disk_byte == wanted_disk_byte) {\n\t\t\teie = NULL;\n\t\t\told = NULL;\n\t\t\tif (ref->key_for_search.offset == key.offset - data_offset)\n\t\t\t\tcount++;\n\t\t\telse\n\t\t\t\tgoto next;\n\t\t\tif (!ctx->skip_inode_ref_list) {\n\t\t\t\tret = check_extent_in_eb(ctx, &key, eb, fi, &eie);\n\t\t\t\tif (ret == BTRFS_ITERATE_EXTENT_INODES_STOP ||\n\t\t\t\t    ret < 0)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ret > 0)\n\t\t\t\tgoto next;\n\t\t\tret = ulist_add_merge_ptr(parents, eb->start,\n\t\t\t\t\t\t  eie, (void **)&old, GFP_NOFS);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\t\t\tif (!ret && !ctx->skip_inode_ref_list) {\n\t\t\t\twhile (old->next)\n\t\t\t\t\told = old->next;\n\t\t\t\told->next = eie;\n\t\t\t}\n\t\t\teie = NULL;\n\t\t}\nnext:\n\t\tif (ctx->time_seq == BTRFS_SEQ_LAST)\n\t\t\tret = btrfs_next_item(root, path);\n\t\telse\n\t\t\tret = btrfs_next_old_item(root, path, ctx->time_seq);\n\t}\n\n\tif (ret == BTRFS_ITERATE_EXTENT_INODES_STOP || ret < 0)\n\t\tfree_inode_elem_list(eie);\n\telse if (ret > 0)\n\t\tret = 0;\n\n\treturn ret;\n}\n\n \nstatic int resolve_indirect_ref(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t\tstruct btrfs_path *path,\n\t\t\t\tstruct preftrees *preftrees,\n\t\t\t\tstruct prelim_ref *ref, struct ulist *parents)\n{\n\tstruct btrfs_root *root;\n\tstruct extent_buffer *eb;\n\tint ret = 0;\n\tint root_level;\n\tint level = ref->level;\n\tstruct btrfs_key search_key = ref->key_for_search;\n\n\t \n\tif (path->search_commit_root)\n\t\troot = btrfs_get_fs_root_commit_root(ctx->fs_info, path, ref->root_id);\n\telse\n\t\troot = btrfs_get_fs_root(ctx->fs_info, ref->root_id, false);\n\tif (IS_ERR(root)) {\n\t\tret = PTR_ERR(root);\n\t\tgoto out_free;\n\t}\n\n\tif (!path->search_commit_root &&\n\t    test_bit(BTRFS_ROOT_DELETING, &root->state)) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (btrfs_is_testing(ctx->fs_info)) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (path->search_commit_root)\n\t\troot_level = btrfs_header_level(root->commit_root);\n\telse if (ctx->time_seq == BTRFS_SEQ_LAST)\n\t\troot_level = btrfs_header_level(root->node);\n\telse\n\t\troot_level = btrfs_old_root_level(root, ctx->time_seq);\n\n\tif (root_level + 1 == level)\n\t\tgoto out;\n\n\t \n\tif (search_key.type == BTRFS_EXTENT_DATA_KEY &&\n\t    search_key.offset >= LLONG_MAX)\n\t\tsearch_key.offset = 0;\n\tpath->lowest_level = level;\n\tif (ctx->time_seq == BTRFS_SEQ_LAST)\n\t\tret = btrfs_search_slot(NULL, root, &search_key, path, 0, 0);\n\telse\n\t\tret = btrfs_search_old_slot(root, &search_key, path, ctx->time_seq);\n\n\tbtrfs_debug(ctx->fs_info,\n\t\t\"search slot in root %llu (level %d, ref count %d) returned %d for key (%llu %u %llu)\",\n\t\t ref->root_id, level, ref->count, ret,\n\t\t ref->key_for_search.objectid, ref->key_for_search.type,\n\t\t ref->key_for_search.offset);\n\tif (ret < 0)\n\t\tgoto out;\n\n\teb = path->nodes[level];\n\twhile (!eb) {\n\t\tif (WARN_ON(!level)) {\n\t\t\tret = 1;\n\t\t\tgoto out;\n\t\t}\n\t\tlevel--;\n\t\teb = path->nodes[level];\n\t}\n\n\tret = add_all_parents(ctx, root, path, parents, preftrees, ref, level);\nout:\n\tbtrfs_put_root(root);\nout_free:\n\tpath->lowest_level = 0;\n\tbtrfs_release_path(path);\n\treturn ret;\n}\n\nstatic struct extent_inode_elem *\nunode_aux_to_inode_list(struct ulist_node *node)\n{\n\tif (!node)\n\t\treturn NULL;\n\treturn (struct extent_inode_elem *)(uintptr_t)node->aux;\n}\n\nstatic void free_leaf_list(struct ulist *ulist)\n{\n\tstruct ulist_node *node;\n\tstruct ulist_iterator uiter;\n\n\tULIST_ITER_INIT(&uiter);\n\twhile ((node = ulist_next(ulist, &uiter)))\n\t\tfree_inode_elem_list(unode_aux_to_inode_list(node));\n\n\tulist_free(ulist);\n}\n\n \nstatic int resolve_indirect_refs(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t\t struct btrfs_path *path,\n\t\t\t\t struct preftrees *preftrees,\n\t\t\t\t struct share_check *sc)\n{\n\tint err;\n\tint ret = 0;\n\tstruct ulist *parents;\n\tstruct ulist_node *node;\n\tstruct ulist_iterator uiter;\n\tstruct rb_node *rnode;\n\n\tparents = ulist_alloc(GFP_NOFS);\n\tif (!parents)\n\t\treturn -ENOMEM;\n\n\t \n\twhile ((rnode = rb_first_cached(&preftrees->indirect.root))) {\n\t\tstruct prelim_ref *ref;\n\n\t\tref = rb_entry(rnode, struct prelim_ref, rbnode);\n\t\tif (WARN(ref->parent,\n\t\t\t \"BUG: direct ref found in indirect tree\")) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\trb_erase_cached(&ref->rbnode, &preftrees->indirect.root);\n\t\tpreftrees->indirect.count--;\n\n\t\tif (ref->count == 0) {\n\t\t\tfree_pref(ref);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (sc && ref->root_id != sc->root->root_key.objectid) {\n\t\t\tfree_pref(ref);\n\t\t\tret = BACKREF_FOUND_SHARED;\n\t\t\tgoto out;\n\t\t}\n\t\terr = resolve_indirect_ref(ctx, path, preftrees, ref, parents);\n\t\t \n\t\tif (err == -ENOENT) {\n\t\t\tprelim_ref_insert(ctx->fs_info, &preftrees->direct, ref,\n\t\t\t\t\t  NULL);\n\t\t\tcontinue;\n\t\t} else if (err) {\n\t\t\tfree_pref(ref);\n\t\t\tret = err;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tULIST_ITER_INIT(&uiter);\n\t\tnode = ulist_next(parents, &uiter);\n\t\tref->parent = node ? node->val : 0;\n\t\tref->inode_list = unode_aux_to_inode_list(node);\n\n\t\t \n\t\twhile ((node = ulist_next(parents, &uiter))) {\n\t\t\tstruct prelim_ref *new_ref;\n\n\t\t\tnew_ref = kmem_cache_alloc(btrfs_prelim_ref_cache,\n\t\t\t\t\t\t   GFP_NOFS);\n\t\t\tif (!new_ref) {\n\t\t\t\tfree_pref(ref);\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tmemcpy(new_ref, ref, sizeof(*ref));\n\t\t\tnew_ref->parent = node->val;\n\t\t\tnew_ref->inode_list = unode_aux_to_inode_list(node);\n\t\t\tprelim_ref_insert(ctx->fs_info, &preftrees->direct,\n\t\t\t\t\t  new_ref, NULL);\n\t\t}\n\n\t\t \n\t\tprelim_ref_insert(ctx->fs_info, &preftrees->direct, ref, NULL);\n\n\t\tulist_reinit(parents);\n\t\tcond_resched();\n\t}\nout:\n\t \n\tfree_leaf_list(parents);\n\treturn ret;\n}\n\n \nstatic int add_missing_keys(struct btrfs_fs_info *fs_info,\n\t\t\t    struct preftrees *preftrees, bool lock)\n{\n\tstruct prelim_ref *ref;\n\tstruct extent_buffer *eb;\n\tstruct preftree *tree = &preftrees->indirect_missing_keys;\n\tstruct rb_node *node;\n\n\twhile ((node = rb_first_cached(&tree->root))) {\n\t\tstruct btrfs_tree_parent_check check = { 0 };\n\n\t\tref = rb_entry(node, struct prelim_ref, rbnode);\n\t\trb_erase_cached(node, &tree->root);\n\n\t\tBUG_ON(ref->parent);\t \n\t\tBUG_ON(ref->key_for_search.type);\n\t\tBUG_ON(!ref->wanted_disk_byte);\n\n\t\tcheck.level = ref->level - 1;\n\t\tcheck.owner_root = ref->root_id;\n\n\t\teb = read_tree_block(fs_info, ref->wanted_disk_byte, &check);\n\t\tif (IS_ERR(eb)) {\n\t\t\tfree_pref(ref);\n\t\t\treturn PTR_ERR(eb);\n\t\t}\n\t\tif (!extent_buffer_uptodate(eb)) {\n\t\t\tfree_pref(ref);\n\t\t\tfree_extent_buffer(eb);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tif (lock)\n\t\t\tbtrfs_tree_read_lock(eb);\n\t\tif (btrfs_header_level(eb) == 0)\n\t\t\tbtrfs_item_key_to_cpu(eb, &ref->key_for_search, 0);\n\t\telse\n\t\t\tbtrfs_node_key_to_cpu(eb, &ref->key_for_search, 0);\n\t\tif (lock)\n\t\t\tbtrfs_tree_read_unlock(eb);\n\t\tfree_extent_buffer(eb);\n\t\tprelim_ref_insert(fs_info, &preftrees->indirect, ref, NULL);\n\t\tcond_resched();\n\t}\n\treturn 0;\n}\n\n \nstatic int add_delayed_refs(const struct btrfs_fs_info *fs_info,\n\t\t\t    struct btrfs_delayed_ref_head *head, u64 seq,\n\t\t\t    struct preftrees *preftrees, struct share_check *sc)\n{\n\tstruct btrfs_delayed_ref_node *node;\n\tstruct btrfs_key key;\n\tstruct rb_node *n;\n\tint count;\n\tint ret = 0;\n\n\tspin_lock(&head->lock);\n\tfor (n = rb_first_cached(&head->ref_tree); n; n = rb_next(n)) {\n\t\tnode = rb_entry(n, struct btrfs_delayed_ref_node,\n\t\t\t\tref_node);\n\t\tif (node->seq > seq)\n\t\t\tcontinue;\n\n\t\tswitch (node->action) {\n\t\tcase BTRFS_ADD_DELAYED_EXTENT:\n\t\tcase BTRFS_UPDATE_DELAYED_HEAD:\n\t\t\tWARN_ON(1);\n\t\t\tcontinue;\n\t\tcase BTRFS_ADD_DELAYED_REF:\n\t\t\tcount = node->ref_mod;\n\t\t\tbreak;\n\t\tcase BTRFS_DROP_DELAYED_REF:\n\t\t\tcount = node->ref_mod * -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\t\tswitch (node->type) {\n\t\tcase BTRFS_TREE_BLOCK_REF_KEY: {\n\t\t\t \n\t\t\tstruct btrfs_delayed_tree_ref *ref;\n\t\t\tstruct btrfs_key *key_ptr = NULL;\n\n\t\t\tif (head->extent_op && head->extent_op->update_key) {\n\t\t\t\tbtrfs_disk_key_to_cpu(&key, &head->extent_op->key);\n\t\t\t\tkey_ptr = &key;\n\t\t\t}\n\n\t\t\tref = btrfs_delayed_node_to_tree_ref(node);\n\t\t\tret = add_indirect_ref(fs_info, preftrees, ref->root,\n\t\t\t\t\t       key_ptr, ref->level + 1,\n\t\t\t\t\t       node->bytenr, count, sc,\n\t\t\t\t\t       GFP_ATOMIC);\n\t\t\tbreak;\n\t\t}\n\t\tcase BTRFS_SHARED_BLOCK_REF_KEY: {\n\t\t\t \n\t\t\tstruct btrfs_delayed_tree_ref *ref;\n\n\t\t\tref = btrfs_delayed_node_to_tree_ref(node);\n\n\t\t\tret = add_direct_ref(fs_info, preftrees, ref->level + 1,\n\t\t\t\t\t     ref->parent, node->bytenr, count,\n\t\t\t\t\t     sc, GFP_ATOMIC);\n\t\t\tbreak;\n\t\t}\n\t\tcase BTRFS_EXTENT_DATA_REF_KEY: {\n\t\t\t \n\t\t\tstruct btrfs_delayed_data_ref *ref;\n\t\t\tref = btrfs_delayed_node_to_data_ref(node);\n\n\t\t\tkey.objectid = ref->objectid;\n\t\t\tkey.type = BTRFS_EXTENT_DATA_KEY;\n\t\t\tkey.offset = ref->offset;\n\n\t\t\t \n\t\t\tif (sc && count < 0)\n\t\t\t\tsc->have_delayed_delete_refs = true;\n\n\t\t\tret = add_indirect_ref(fs_info, preftrees, ref->root,\n\t\t\t\t\t       &key, 0, node->bytenr, count, sc,\n\t\t\t\t\t       GFP_ATOMIC);\n\t\t\tbreak;\n\t\t}\n\t\tcase BTRFS_SHARED_DATA_REF_KEY: {\n\t\t\t \n\t\t\tstruct btrfs_delayed_data_ref *ref;\n\n\t\t\tref = btrfs_delayed_node_to_data_ref(node);\n\n\t\t\tret = add_direct_ref(fs_info, preftrees, 0, ref->parent,\n\t\t\t\t\t     node->bytenr, count, sc,\n\t\t\t\t\t     GFP_ATOMIC);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t}\n\t\t \n\t\tif (ret && (ret != BACKREF_FOUND_SHARED))\n\t\t\tbreak;\n\t}\n\tif (!ret)\n\t\tret = extent_is_shared(sc);\n\n\tspin_unlock(&head->lock);\n\treturn ret;\n}\n\n \nstatic int add_inline_refs(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t   struct btrfs_path *path,\n\t\t\t   int *info_level, struct preftrees *preftrees,\n\t\t\t   struct share_check *sc)\n{\n\tint ret = 0;\n\tint slot;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key key;\n\tstruct btrfs_key found_key;\n\tunsigned long ptr;\n\tunsigned long end;\n\tstruct btrfs_extent_item *ei;\n\tu64 flags;\n\tu64 item_size;\n\n\t \n\tleaf = path->nodes[0];\n\tslot = path->slots[0];\n\n\titem_size = btrfs_item_size(leaf, slot);\n\tBUG_ON(item_size < sizeof(*ei));\n\n\tei = btrfs_item_ptr(leaf, slot, struct btrfs_extent_item);\n\n\tif (ctx->check_extent_item) {\n\t\tret = ctx->check_extent_item(ctx->bytenr, ei, leaf, ctx->user_ctx);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tflags = btrfs_extent_flags(leaf, ei);\n\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\tptr = (unsigned long)(ei + 1);\n\tend = (unsigned long)ei + item_size;\n\n\tif (found_key.type == BTRFS_EXTENT_ITEM_KEY &&\n\t    flags & BTRFS_EXTENT_FLAG_TREE_BLOCK) {\n\t\tstruct btrfs_tree_block_info *info;\n\n\t\tinfo = (struct btrfs_tree_block_info *)ptr;\n\t\t*info_level = btrfs_tree_block_level(leaf, info);\n\t\tptr += sizeof(struct btrfs_tree_block_info);\n\t\tBUG_ON(ptr > end);\n\t} else if (found_key.type == BTRFS_METADATA_ITEM_KEY) {\n\t\t*info_level = found_key.offset;\n\t} else {\n\t\tBUG_ON(!(flags & BTRFS_EXTENT_FLAG_DATA));\n\t}\n\n\twhile (ptr < end) {\n\t\tstruct btrfs_extent_inline_ref *iref;\n\t\tu64 offset;\n\t\tint type;\n\n\t\tiref = (struct btrfs_extent_inline_ref *)ptr;\n\t\ttype = btrfs_get_extent_inline_ref_type(leaf, iref,\n\t\t\t\t\t\t\tBTRFS_REF_TYPE_ANY);\n\t\tif (type == BTRFS_REF_TYPE_INVALID)\n\t\t\treturn -EUCLEAN;\n\n\t\toffset = btrfs_extent_inline_ref_offset(leaf, iref);\n\n\t\tswitch (type) {\n\t\tcase BTRFS_SHARED_BLOCK_REF_KEY:\n\t\t\tret = add_direct_ref(ctx->fs_info, preftrees,\n\t\t\t\t\t     *info_level + 1, offset,\n\t\t\t\t\t     ctx->bytenr, 1, NULL, GFP_NOFS);\n\t\t\tbreak;\n\t\tcase BTRFS_SHARED_DATA_REF_KEY: {\n\t\t\tstruct btrfs_shared_data_ref *sdref;\n\t\t\tint count;\n\n\t\t\tsdref = (struct btrfs_shared_data_ref *)(iref + 1);\n\t\t\tcount = btrfs_shared_data_ref_count(leaf, sdref);\n\n\t\t\tret = add_direct_ref(ctx->fs_info, preftrees, 0, offset,\n\t\t\t\t\t     ctx->bytenr, count, sc, GFP_NOFS);\n\t\t\tbreak;\n\t\t}\n\t\tcase BTRFS_TREE_BLOCK_REF_KEY:\n\t\t\tret = add_indirect_ref(ctx->fs_info, preftrees, offset,\n\t\t\t\t\t       NULL, *info_level + 1,\n\t\t\t\t\t       ctx->bytenr, 1, NULL, GFP_NOFS);\n\t\t\tbreak;\n\t\tcase BTRFS_EXTENT_DATA_REF_KEY: {\n\t\t\tstruct btrfs_extent_data_ref *dref;\n\t\t\tint count;\n\t\t\tu64 root;\n\n\t\t\tdref = (struct btrfs_extent_data_ref *)(&iref->offset);\n\t\t\tcount = btrfs_extent_data_ref_count(leaf, dref);\n\t\t\tkey.objectid = btrfs_extent_data_ref_objectid(leaf,\n\t\t\t\t\t\t\t\t      dref);\n\t\t\tkey.type = BTRFS_EXTENT_DATA_KEY;\n\t\t\tkey.offset = btrfs_extent_data_ref_offset(leaf, dref);\n\n\t\t\tif (sc && key.objectid != sc->inum &&\n\t\t\t    !sc->have_delayed_delete_refs) {\n\t\t\t\tret = BACKREF_FOUND_SHARED;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\troot = btrfs_extent_data_ref_root(leaf, dref);\n\n\t\t\tif (!ctx->skip_data_ref ||\n\t\t\t    !ctx->skip_data_ref(root, key.objectid, key.offset,\n\t\t\t\t\t\tctx->user_ctx))\n\t\t\t\tret = add_indirect_ref(ctx->fs_info, preftrees,\n\t\t\t\t\t\t       root, &key, 0, ctx->bytenr,\n\t\t\t\t\t\t       count, sc, GFP_NOFS);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t}\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tptr += btrfs_extent_inline_ref_size(type);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int add_keyed_refs(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t  struct btrfs_root *extent_root,\n\t\t\t  struct btrfs_path *path,\n\t\t\t  int info_level, struct preftrees *preftrees,\n\t\t\t  struct share_check *sc)\n{\n\tstruct btrfs_fs_info *fs_info = extent_root->fs_info;\n\tint ret;\n\tint slot;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key key;\n\n\twhile (1) {\n\t\tret = btrfs_next_item(extent_root, path);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t\tif (ret) {\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tslot = path->slots[0];\n\t\tleaf = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(leaf, &key, slot);\n\n\t\tif (key.objectid != ctx->bytenr)\n\t\t\tbreak;\n\t\tif (key.type < BTRFS_TREE_BLOCK_REF_KEY)\n\t\t\tcontinue;\n\t\tif (key.type > BTRFS_SHARED_DATA_REF_KEY)\n\t\t\tbreak;\n\n\t\tswitch (key.type) {\n\t\tcase BTRFS_SHARED_BLOCK_REF_KEY:\n\t\t\t \n\t\t\tret = add_direct_ref(fs_info, preftrees,\n\t\t\t\t\t     info_level + 1, key.offset,\n\t\t\t\t\t     ctx->bytenr, 1, NULL, GFP_NOFS);\n\t\t\tbreak;\n\t\tcase BTRFS_SHARED_DATA_REF_KEY: {\n\t\t\t \n\t\t\tstruct btrfs_shared_data_ref *sdref;\n\t\t\tint count;\n\n\t\t\tsdref = btrfs_item_ptr(leaf, slot,\n\t\t\t\t\t      struct btrfs_shared_data_ref);\n\t\t\tcount = btrfs_shared_data_ref_count(leaf, sdref);\n\t\t\tret = add_direct_ref(fs_info, preftrees, 0,\n\t\t\t\t\t     key.offset, ctx->bytenr, count,\n\t\t\t\t\t     sc, GFP_NOFS);\n\t\t\tbreak;\n\t\t}\n\t\tcase BTRFS_TREE_BLOCK_REF_KEY:\n\t\t\t \n\t\t\tret = add_indirect_ref(fs_info, preftrees, key.offset,\n\t\t\t\t\t       NULL, info_level + 1, ctx->bytenr,\n\t\t\t\t\t       1, NULL, GFP_NOFS);\n\t\t\tbreak;\n\t\tcase BTRFS_EXTENT_DATA_REF_KEY: {\n\t\t\t \n\t\t\tstruct btrfs_extent_data_ref *dref;\n\t\t\tint count;\n\t\t\tu64 root;\n\n\t\t\tdref = btrfs_item_ptr(leaf, slot,\n\t\t\t\t\t      struct btrfs_extent_data_ref);\n\t\t\tcount = btrfs_extent_data_ref_count(leaf, dref);\n\t\t\tkey.objectid = btrfs_extent_data_ref_objectid(leaf,\n\t\t\t\t\t\t\t\t      dref);\n\t\t\tkey.type = BTRFS_EXTENT_DATA_KEY;\n\t\t\tkey.offset = btrfs_extent_data_ref_offset(leaf, dref);\n\n\t\t\tif (sc && key.objectid != sc->inum &&\n\t\t\t    !sc->have_delayed_delete_refs) {\n\t\t\t\tret = BACKREF_FOUND_SHARED;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\troot = btrfs_extent_data_ref_root(leaf, dref);\n\n\t\t\tif (!ctx->skip_data_ref ||\n\t\t\t    !ctx->skip_data_ref(root, key.objectid, key.offset,\n\t\t\t\t\t\tctx->user_ctx))\n\t\t\t\tret = add_indirect_ref(fs_info, preftrees, root,\n\t\t\t\t\t\t       &key, 0, ctx->bytenr,\n\t\t\t\t\t\t       count, sc, GFP_NOFS);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t}\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t}\n\n\treturn ret;\n}\n\n \nstatic bool lookup_backref_shared_cache(struct btrfs_backref_share_check_ctx *ctx,\n\t\t\t\t\tstruct btrfs_root *root,\n\t\t\t\t\tu64 bytenr, int level, bool *is_shared)\n{\n\tconst struct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_backref_shared_cache_entry *entry;\n\n\tif (!current->journal_info)\n\t\tlockdep_assert_held(&fs_info->commit_root_sem);\n\n\tif (!ctx->use_path_cache)\n\t\treturn false;\n\n\tif (WARN_ON_ONCE(level >= BTRFS_MAX_LEVEL))\n\t\treturn false;\n\n\t \n\tASSERT(level >= 0);\n\n\tentry = &ctx->path_cache_entries[level];\n\n\t \n\tif (entry->bytenr != bytenr)\n\t\treturn false;\n\n\t \n\tif (!entry->is_shared &&\n\t    entry->gen != btrfs_root_last_snapshot(&root->root_item))\n\t\treturn false;\n\n\t \n\tif (entry->is_shared &&\n\t    entry->gen != btrfs_get_last_root_drop_gen(fs_info))\n\t\treturn false;\n\n\t*is_shared = entry->is_shared;\n\t \n\tif (*is_shared) {\n\t\tfor (int i = 0; i < level; i++) {\n\t\t\tctx->path_cache_entries[i].is_shared = true;\n\t\t\tctx->path_cache_entries[i].gen = entry->gen;\n\t\t}\n\t}\n\n\treturn true;\n}\n\n \nstatic void store_backref_shared_cache(struct btrfs_backref_share_check_ctx *ctx,\n\t\t\t\t       struct btrfs_root *root,\n\t\t\t\t       u64 bytenr, int level, bool is_shared)\n{\n\tconst struct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_backref_shared_cache_entry *entry;\n\tu64 gen;\n\n\tif (!current->journal_info)\n\t\tlockdep_assert_held(&fs_info->commit_root_sem);\n\n\tif (!ctx->use_path_cache)\n\t\treturn;\n\n\tif (WARN_ON_ONCE(level >= BTRFS_MAX_LEVEL))\n\t\treturn;\n\n\t \n\tASSERT(level >= 0);\n\n\tif (is_shared)\n\t\tgen = btrfs_get_last_root_drop_gen(fs_info);\n\telse\n\t\tgen = btrfs_root_last_snapshot(&root->root_item);\n\n\tentry = &ctx->path_cache_entries[level];\n\tentry->bytenr = bytenr;\n\tentry->is_shared = is_shared;\n\tentry->gen = gen;\n\n\t \n\tif (is_shared) {\n\t\tfor (int i = 0; i < level; i++) {\n\t\t\tentry = &ctx->path_cache_entries[i];\n\t\t\tentry->is_shared = is_shared;\n\t\t\tentry->gen = gen;\n\t\t}\n\t}\n}\n\n \nstatic int find_parent_nodes(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t     struct share_check *sc)\n{\n\tstruct btrfs_root *root = btrfs_extent_root(ctx->fs_info, ctx->bytenr);\n\tstruct btrfs_key key;\n\tstruct btrfs_path *path;\n\tstruct btrfs_delayed_ref_root *delayed_refs = NULL;\n\tstruct btrfs_delayed_ref_head *head;\n\tint info_level = 0;\n\tint ret;\n\tstruct prelim_ref *ref;\n\tstruct rb_node *node;\n\tstruct extent_inode_elem *eie = NULL;\n\tstruct preftrees preftrees = {\n\t\t.direct = PREFTREE_INIT,\n\t\t.indirect = PREFTREE_INIT,\n\t\t.indirect_missing_keys = PREFTREE_INIT\n\t};\n\n\t \n\tif (sc)\n\t\tASSERT(ctx->roots == NULL);\n\n\tkey.objectid = ctx->bytenr;\n\tkey.offset = (u64)-1;\n\tif (btrfs_fs_incompat(ctx->fs_info, SKINNY_METADATA))\n\t\tkey.type = BTRFS_METADATA_ITEM_KEY;\n\telse\n\t\tkey.type = BTRFS_EXTENT_ITEM_KEY;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\tif (!ctx->trans) {\n\t\tpath->search_commit_root = 1;\n\t\tpath->skip_locking = 1;\n\t}\n\n\tif (ctx->time_seq == BTRFS_SEQ_LAST)\n\t\tpath->skip_locking = 1;\n\nagain:\n\thead = NULL;\n\n\tret = btrfs_search_slot(NULL, root, &key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\tif (ret == 0) {\n\t\t \n\t\tASSERT(ret != 0);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\tif (ctx->trans && likely(ctx->trans->type != __TRANS_DUMMY) &&\n\t    ctx->time_seq != BTRFS_SEQ_LAST) {\n\t\t \n\t\tdelayed_refs = &ctx->trans->transaction->delayed_refs;\n\t\tspin_lock(&delayed_refs->lock);\n\t\thead = btrfs_find_delayed_ref_head(delayed_refs, ctx->bytenr);\n\t\tif (head) {\n\t\t\tif (!mutex_trylock(&head->mutex)) {\n\t\t\t\trefcount_inc(&head->refs);\n\t\t\t\tspin_unlock(&delayed_refs->lock);\n\n\t\t\t\tbtrfs_release_path(path);\n\n\t\t\t\t \n\t\t\t\tmutex_lock(&head->mutex);\n\t\t\t\tmutex_unlock(&head->mutex);\n\t\t\t\tbtrfs_put_delayed_ref_head(head);\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t\tspin_unlock(&delayed_refs->lock);\n\t\t\tret = add_delayed_refs(ctx->fs_info, head, ctx->time_seq,\n\t\t\t\t\t       &preftrees, sc);\n\t\t\tmutex_unlock(&head->mutex);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\tspin_unlock(&delayed_refs->lock);\n\t\t}\n\t}\n\n\tif (path->slots[0]) {\n\t\tstruct extent_buffer *leaf;\n\t\tint slot;\n\n\t\tpath->slots[0]--;\n\t\tleaf = path->nodes[0];\n\t\tslot = path->slots[0];\n\t\tbtrfs_item_key_to_cpu(leaf, &key, slot);\n\t\tif (key.objectid == ctx->bytenr &&\n\t\t    (key.type == BTRFS_EXTENT_ITEM_KEY ||\n\t\t     key.type == BTRFS_METADATA_ITEM_KEY)) {\n\t\t\tret = add_inline_refs(ctx, path, &info_level,\n\t\t\t\t\t      &preftrees, sc);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t\tret = add_keyed_refs(ctx, root, path, info_level,\n\t\t\t\t\t     &preftrees, sc);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tASSERT(extent_is_shared(sc) == 0);\n\n\t \n\tif (sc && ctx->bytenr == sc->data_bytenr) {\n\t\t \n\t\tif (sc->data_extent_gen >\n\t\t    btrfs_root_last_snapshot(&sc->root->root_item)) {\n\t\t\tret = BACKREF_FOUND_NOT_SHARED;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tif (sc->ctx->curr_leaf_bytenr == sc->ctx->prev_leaf_bytenr &&\n\t\t    sc->self_ref_count == 1) {\n\t\t\tbool cached;\n\t\t\tbool is_shared;\n\n\t\t\tcached = lookup_backref_shared_cache(sc->ctx, sc->root,\n\t\t\t\t\t\t     sc->ctx->curr_leaf_bytenr,\n\t\t\t\t\t\t     0, &is_shared);\n\t\t\tif (cached) {\n\t\t\t\tif (is_shared)\n\t\t\t\t\tret = BACKREF_FOUND_SHARED;\n\t\t\t\telse\n\t\t\t\t\tret = BACKREF_FOUND_NOT_SHARED;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tbtrfs_release_path(path);\n\n\tret = add_missing_keys(ctx->fs_info, &preftrees, path->skip_locking == 0);\n\tif (ret)\n\t\tgoto out;\n\n\tWARN_ON(!RB_EMPTY_ROOT(&preftrees.indirect_missing_keys.root.rb_root));\n\n\tret = resolve_indirect_refs(ctx, path, &preftrees, sc);\n\tif (ret)\n\t\tgoto out;\n\n\tWARN_ON(!RB_EMPTY_ROOT(&preftrees.indirect.root.rb_root));\n\n\t \n\tnode = rb_first_cached(&preftrees.direct.root);\n\twhile (node) {\n\t\tref = rb_entry(node, struct prelim_ref, rbnode);\n\t\tnode = rb_next(&ref->rbnode);\n\t\t \n\t\tif (ctx->roots && ref->count && ref->root_id && ref->parent == 0) {\n\t\t\t \n\t\t\tret = ulist_add(ctx->roots, ref->root_id, 0, GFP_NOFS);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t\tif (ref->count && ref->parent) {\n\t\t\tif (!ctx->skip_inode_ref_list && !ref->inode_list &&\n\t\t\t    ref->level == 0) {\n\t\t\t\tstruct btrfs_tree_parent_check check = { 0 };\n\t\t\t\tstruct extent_buffer *eb;\n\n\t\t\t\tcheck.level = ref->level;\n\n\t\t\t\teb = read_tree_block(ctx->fs_info, ref->parent,\n\t\t\t\t\t\t     &check);\n\t\t\t\tif (IS_ERR(eb)) {\n\t\t\t\t\tret = PTR_ERR(eb);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tif (!extent_buffer_uptodate(eb)) {\n\t\t\t\t\tfree_extent_buffer(eb);\n\t\t\t\t\tret = -EIO;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tif (!path->skip_locking)\n\t\t\t\t\tbtrfs_tree_read_lock(eb);\n\t\t\t\tret = find_extent_in_eb(ctx, eb, &eie);\n\t\t\t\tif (!path->skip_locking)\n\t\t\t\t\tbtrfs_tree_read_unlock(eb);\n\t\t\t\tfree_extent_buffer(eb);\n\t\t\t\tif (ret == BTRFS_ITERATE_EXTENT_INODES_STOP ||\n\t\t\t\t    ret < 0)\n\t\t\t\t\tgoto out;\n\t\t\t\tref->inode_list = eie;\n\t\t\t\t \n\t\t\t\teie = NULL;\n\t\t\t}\n\t\t\tret = ulist_add_merge_ptr(ctx->refs, ref->parent,\n\t\t\t\t\t\t  ref->inode_list,\n\t\t\t\t\t\t  (void **)&eie, GFP_NOFS);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t\tif (!ret && !ctx->skip_inode_ref_list) {\n\t\t\t\t \n\t\t\t\tASSERT(eie);\n\t\t\t\tif (!eie) {\n\t\t\t\t\tret = -EUCLEAN;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\twhile (eie->next)\n\t\t\t\t\teie = eie->next;\n\t\t\t\teie->next = ref->inode_list;\n\t\t\t}\n\t\t\teie = NULL;\n\t\t\t \n\t\t\tref->inode_list = NULL;\n\t\t}\n\t\tcond_resched();\n\t}\n\nout:\n\tbtrfs_free_path(path);\n\n\tprelim_release(&preftrees.direct);\n\tprelim_release(&preftrees.indirect);\n\tprelim_release(&preftrees.indirect_missing_keys);\n\n\tif (ret == BTRFS_ITERATE_EXTENT_INODES_STOP || ret < 0)\n\t\tfree_inode_elem_list(eie);\n\treturn ret;\n}\n\n \nint btrfs_find_all_leafs(struct btrfs_backref_walk_ctx *ctx)\n{\n\tint ret;\n\n\tASSERT(ctx->refs == NULL);\n\n\tctx->refs = ulist_alloc(GFP_NOFS);\n\tif (!ctx->refs)\n\t\treturn -ENOMEM;\n\n\tret = find_parent_nodes(ctx, NULL);\n\tif (ret == BTRFS_ITERATE_EXTENT_INODES_STOP ||\n\t    (ret < 0 && ret != -ENOENT)) {\n\t\tfree_leaf_list(ctx->refs);\n\t\tctx->refs = NULL;\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int btrfs_find_all_roots_safe(struct btrfs_backref_walk_ctx *ctx)\n{\n\tconst u64 orig_bytenr = ctx->bytenr;\n\tconst bool orig_skip_inode_ref_list = ctx->skip_inode_ref_list;\n\tbool roots_ulist_allocated = false;\n\tstruct ulist_iterator uiter;\n\tint ret = 0;\n\n\tASSERT(ctx->refs == NULL);\n\n\tctx->refs = ulist_alloc(GFP_NOFS);\n\tif (!ctx->refs)\n\t\treturn -ENOMEM;\n\n\tif (!ctx->roots) {\n\t\tctx->roots = ulist_alloc(GFP_NOFS);\n\t\tif (!ctx->roots) {\n\t\t\tulist_free(ctx->refs);\n\t\t\tctx->refs = NULL;\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\troots_ulist_allocated = true;\n\t}\n\n\tctx->skip_inode_ref_list = true;\n\n\tULIST_ITER_INIT(&uiter);\n\twhile (1) {\n\t\tstruct ulist_node *node;\n\n\t\tret = find_parent_nodes(ctx, NULL);\n\t\tif (ret < 0 && ret != -ENOENT) {\n\t\t\tif (roots_ulist_allocated) {\n\t\t\t\tulist_free(ctx->roots);\n\t\t\t\tctx->roots = NULL;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tret = 0;\n\t\tnode = ulist_next(ctx->refs, &uiter);\n\t\tif (!node)\n\t\t\tbreak;\n\t\tctx->bytenr = node->val;\n\t\tcond_resched();\n\t}\n\n\tulist_free(ctx->refs);\n\tctx->refs = NULL;\n\tctx->bytenr = orig_bytenr;\n\tctx->skip_inode_ref_list = orig_skip_inode_ref_list;\n\n\treturn ret;\n}\n\nint btrfs_find_all_roots(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t bool skip_commit_root_sem)\n{\n\tint ret;\n\n\tif (!ctx->trans && !skip_commit_root_sem)\n\t\tdown_read(&ctx->fs_info->commit_root_sem);\n\tret = btrfs_find_all_roots_safe(ctx);\n\tif (!ctx->trans && !skip_commit_root_sem)\n\t\tup_read(&ctx->fs_info->commit_root_sem);\n\treturn ret;\n}\n\nstruct btrfs_backref_share_check_ctx *btrfs_alloc_backref_share_check_ctx(void)\n{\n\tstruct btrfs_backref_share_check_ctx *ctx;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn NULL;\n\n\tulist_init(&ctx->refs);\n\n\treturn ctx;\n}\n\nvoid btrfs_free_backref_share_ctx(struct btrfs_backref_share_check_ctx *ctx)\n{\n\tif (!ctx)\n\t\treturn;\n\n\tulist_release(&ctx->refs);\n\tkfree(ctx);\n}\n\n \nint btrfs_is_data_extent_shared(struct btrfs_inode *inode, u64 bytenr,\n\t\t\t\tu64 extent_gen,\n\t\t\t\tstruct btrfs_backref_share_check_ctx *ctx)\n{\n\tstruct btrfs_backref_walk_ctx walk_ctx = { 0 };\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_trans_handle *trans;\n\tstruct ulist_iterator uiter;\n\tstruct ulist_node *node;\n\tstruct btrfs_seq_list elem = BTRFS_SEQ_LIST_INIT(elem);\n\tint ret = 0;\n\tstruct share_check shared = {\n\t\t.ctx = ctx,\n\t\t.root = root,\n\t\t.inum = btrfs_ino(inode),\n\t\t.data_bytenr = bytenr,\n\t\t.data_extent_gen = extent_gen,\n\t\t.share_count = 0,\n\t\t.self_ref_count = 0,\n\t\t.have_delayed_delete_refs = false,\n\t};\n\tint level;\n\tbool leaf_cached;\n\tbool leaf_is_shared;\n\n\tfor (int i = 0; i < BTRFS_BACKREF_CTX_PREV_EXTENTS_SIZE; i++) {\n\t\tif (ctx->prev_extents_cache[i].bytenr == bytenr)\n\t\t\treturn ctx->prev_extents_cache[i].is_shared;\n\t}\n\n\tulist_init(&ctx->refs);\n\n\ttrans = btrfs_join_transaction_nostart(root);\n\tif (IS_ERR(trans)) {\n\t\tif (PTR_ERR(trans) != -ENOENT && PTR_ERR(trans) != -EROFS) {\n\t\t\tret = PTR_ERR(trans);\n\t\t\tgoto out;\n\t\t}\n\t\ttrans = NULL;\n\t\tdown_read(&fs_info->commit_root_sem);\n\t} else {\n\t\tbtrfs_get_tree_mod_seq(fs_info, &elem);\n\t\twalk_ctx.time_seq = elem.seq;\n\t}\n\n\tctx->use_path_cache = true;\n\n\t \n\tleaf_cached = lookup_backref_shared_cache(ctx, root,\n\t\t\t\t\t\t  ctx->curr_leaf_bytenr, 0,\n\t\t\t\t\t\t  &leaf_is_shared);\n\tif (leaf_cached && leaf_is_shared) {\n\t\tret = 1;\n\t\tgoto out_trans;\n\t}\n\n\twalk_ctx.skip_inode_ref_list = true;\n\twalk_ctx.trans = trans;\n\twalk_ctx.fs_info = fs_info;\n\twalk_ctx.refs = &ctx->refs;\n\n\t \n\tlevel = -1;\n\tULIST_ITER_INIT(&uiter);\n\twhile (1) {\n\t\tconst unsigned long prev_ref_count = ctx->refs.nnodes;\n\n\t\twalk_ctx.bytenr = bytenr;\n\t\tret = find_parent_nodes(&walk_ctx, &shared);\n\t\tif (ret == BACKREF_FOUND_SHARED ||\n\t\t    ret == BACKREF_FOUND_NOT_SHARED) {\n\t\t\t \n\t\t\tret = (ret == BACKREF_FOUND_SHARED) ? 1 : 0;\n\t\t\tif (level >= 0)\n\t\t\t\tstore_backref_shared_cache(ctx, root, bytenr,\n\t\t\t\t\t\t\t   level, ret == 1);\n\t\t\tbreak;\n\t\t}\n\t\tif (ret < 0 && ret != -ENOENT)\n\t\t\tbreak;\n\t\tret = 0;\n\n\t\t \n\t\tif ((ctx->refs.nnodes - prev_ref_count) > 1)\n\t\t\tctx->use_path_cache = false;\n\n\t\tif (level >= 0)\n\t\t\tstore_backref_shared_cache(ctx, root, bytenr,\n\t\t\t\t\t\t   level, false);\n\t\tnode = ulist_next(&ctx->refs, &uiter);\n\t\tif (!node)\n\t\t\tbreak;\n\t\tbytenr = node->val;\n\t\tif (ctx->use_path_cache) {\n\t\t\tbool is_shared;\n\t\t\tbool cached;\n\n\t\t\tlevel++;\n\t\t\tcached = lookup_backref_shared_cache(ctx, root, bytenr,\n\t\t\t\t\t\t\t     level, &is_shared);\n\t\t\tif (cached) {\n\t\t\t\tret = (is_shared ? 1 : 0);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tshared.share_count = 0;\n\t\tshared.have_delayed_delete_refs = false;\n\t\tcond_resched();\n\t}\n\n\t \n\tif (!ctx->use_path_cache) {\n\t\tint i = 0;\n\n\t\tlevel--;\n\t\tif (ret >= 0 && level >= 0) {\n\t\t\tbytenr = ctx->path_cache_entries[level].bytenr;\n\t\t\tctx->use_path_cache = true;\n\t\t\tstore_backref_shared_cache(ctx, root, bytenr, level, ret);\n\t\t\ti = level + 1;\n\t\t}\n\n\t\tfor ( ; i < BTRFS_MAX_LEVEL; i++)\n\t\t\tctx->path_cache_entries[i].bytenr = 0;\n\t}\n\n\t \n\tif (ret >= 0 && shared.self_ref_count > 1) {\n\t\tint slot = ctx->prev_extents_cache_slot;\n\n\t\tctx->prev_extents_cache[slot].bytenr = shared.data_bytenr;\n\t\tctx->prev_extents_cache[slot].is_shared = (ret == 1);\n\n\t\tslot = (slot + 1) % BTRFS_BACKREF_CTX_PREV_EXTENTS_SIZE;\n\t\tctx->prev_extents_cache_slot = slot;\n\t}\n\nout_trans:\n\tif (trans) {\n\t\tbtrfs_put_tree_mod_seq(fs_info, &elem);\n\t\tbtrfs_end_transaction(trans);\n\t} else {\n\t\tup_read(&fs_info->commit_root_sem);\n\t}\nout:\n\tulist_release(&ctx->refs);\n\tctx->prev_leaf_bytenr = ctx->curr_leaf_bytenr;\n\n\treturn ret;\n}\n\nint btrfs_find_one_extref(struct btrfs_root *root, u64 inode_objectid,\n\t\t\t  u64 start_off, struct btrfs_path *path,\n\t\t\t  struct btrfs_inode_extref **ret_extref,\n\t\t\t  u64 *found_off)\n{\n\tint ret, slot;\n\tstruct btrfs_key key;\n\tstruct btrfs_key found_key;\n\tstruct btrfs_inode_extref *extref;\n\tconst struct extent_buffer *leaf;\n\tunsigned long ptr;\n\n\tkey.objectid = inode_objectid;\n\tkey.type = BTRFS_INODE_EXTREF_KEY;\n\tkey.offset = start_off;\n\n\tret = btrfs_search_slot(NULL, root, &key, path, 0, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\n\twhile (1) {\n\t\tleaf = path->nodes[0];\n\t\tslot = path->slots[0];\n\t\tif (slot >= btrfs_header_nritems(leaf)) {\n\t\t\t \n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret) {\n\t\t\t\tif (ret >= 1)\n\t\t\t\t\tret = -ENOENT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\t \n\t\tret = -ENOENT;\n\t\tif (found_key.objectid != inode_objectid)\n\t\t\tbreak;\n\t\tif (found_key.type != BTRFS_INODE_EXTREF_KEY)\n\t\t\tbreak;\n\n\t\tret = 0;\n\t\tptr = btrfs_item_ptr_offset(leaf, path->slots[0]);\n\t\textref = (struct btrfs_inode_extref *)ptr;\n\t\t*ret_extref = extref;\n\t\tif (found_off)\n\t\t\t*found_off = found_key.offset;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n \nchar *btrfs_ref_to_path(struct btrfs_root *fs_root, struct btrfs_path *path,\n\t\t\tu32 name_len, unsigned long name_off,\n\t\t\tstruct extent_buffer *eb_in, u64 parent,\n\t\t\tchar *dest, u32 size)\n{\n\tint slot;\n\tu64 next_inum;\n\tint ret;\n\ts64 bytes_left = ((s64)size) - 1;\n\tstruct extent_buffer *eb = eb_in;\n\tstruct btrfs_key found_key;\n\tstruct btrfs_inode_ref *iref;\n\n\tif (bytes_left >= 0)\n\t\tdest[bytes_left] = '\\0';\n\n\twhile (1) {\n\t\tbytes_left -= name_len;\n\t\tif (bytes_left >= 0)\n\t\t\tread_extent_buffer(eb, dest + bytes_left,\n\t\t\t\t\t   name_off, name_len);\n\t\tif (eb != eb_in) {\n\t\t\tif (!path->skip_locking)\n\t\t\t\tbtrfs_tree_read_unlock(eb);\n\t\t\tfree_extent_buffer(eb);\n\t\t}\n\t\tret = btrfs_find_item(fs_root, path, parent, 0,\n\t\t\t\tBTRFS_INODE_REF_KEY, &found_key);\n\t\tif (ret > 0)\n\t\t\tret = -ENOENT;\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tnext_inum = found_key.offset;\n\n\t\t \n\t\tif (parent == next_inum)\n\t\t\tbreak;\n\n\t\tslot = path->slots[0];\n\t\teb = path->nodes[0];\n\t\t \n\t\tif (eb != eb_in) {\n\t\t\tpath->nodes[0] = NULL;\n\t\t\tpath->locks[0] = 0;\n\t\t}\n\t\tbtrfs_release_path(path);\n\t\tiref = btrfs_item_ptr(eb, slot, struct btrfs_inode_ref);\n\n\t\tname_len = btrfs_inode_ref_name_len(eb, iref);\n\t\tname_off = (unsigned long)(iref + 1);\n\n\t\tparent = next_inum;\n\t\t--bytes_left;\n\t\tif (bytes_left >= 0)\n\t\t\tdest[bytes_left] = '/';\n\t}\n\n\tbtrfs_release_path(path);\n\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\treturn dest + bytes_left;\n}\n\n \nint extent_from_logical(struct btrfs_fs_info *fs_info, u64 logical,\n\t\t\tstruct btrfs_path *path, struct btrfs_key *found_key,\n\t\t\tu64 *flags_ret)\n{\n\tstruct btrfs_root *extent_root = btrfs_extent_root(fs_info, logical);\n\tint ret;\n\tu64 flags;\n\tu64 size = 0;\n\tu32 item_size;\n\tconst struct extent_buffer *eb;\n\tstruct btrfs_extent_item *ei;\n\tstruct btrfs_key key;\n\n\tif (btrfs_fs_incompat(fs_info, SKINNY_METADATA))\n\t\tkey.type = BTRFS_METADATA_ITEM_KEY;\n\telse\n\t\tkey.type = BTRFS_EXTENT_ITEM_KEY;\n\tkey.objectid = logical;\n\tkey.offset = (u64)-1;\n\n\tret = btrfs_search_slot(NULL, extent_root, &key, path, 0, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = btrfs_previous_extent_item(extent_root, path, 0);\n\tif (ret) {\n\t\tif (ret > 0)\n\t\t\tret = -ENOENT;\n\t\treturn ret;\n\t}\n\tbtrfs_item_key_to_cpu(path->nodes[0], found_key, path->slots[0]);\n\tif (found_key->type == BTRFS_METADATA_ITEM_KEY)\n\t\tsize = fs_info->nodesize;\n\telse if (found_key->type == BTRFS_EXTENT_ITEM_KEY)\n\t\tsize = found_key->offset;\n\n\tif (found_key->objectid > logical ||\n\t    found_key->objectid + size <= logical) {\n\t\tbtrfs_debug(fs_info,\n\t\t\t\"logical %llu is not within any extent\", logical);\n\t\treturn -ENOENT;\n\t}\n\n\teb = path->nodes[0];\n\titem_size = btrfs_item_size(eb, path->slots[0]);\n\tBUG_ON(item_size < sizeof(*ei));\n\n\tei = btrfs_item_ptr(eb, path->slots[0], struct btrfs_extent_item);\n\tflags = btrfs_extent_flags(eb, ei);\n\n\tbtrfs_debug(fs_info,\n\t\t\"logical %llu is at position %llu within the extent (%llu EXTENT_ITEM %llu) flags %#llx size %u\",\n\t\t logical, logical - found_key->objectid, found_key->objectid,\n\t\t found_key->offset, flags, item_size);\n\n\tWARN_ON(!flags_ret);\n\tif (flags_ret) {\n\t\tif (flags & BTRFS_EXTENT_FLAG_TREE_BLOCK)\n\t\t\t*flags_ret = BTRFS_EXTENT_FLAG_TREE_BLOCK;\n\t\telse if (flags & BTRFS_EXTENT_FLAG_DATA)\n\t\t\t*flags_ret = BTRFS_EXTENT_FLAG_DATA;\n\t\telse\n\t\t\tBUG();\n\t\treturn 0;\n\t}\n\n\treturn -EIO;\n}\n\n \nstatic int get_extent_inline_ref(unsigned long *ptr,\n\t\t\t\t const struct extent_buffer *eb,\n\t\t\t\t const struct btrfs_key *key,\n\t\t\t\t const struct btrfs_extent_item *ei,\n\t\t\t\t u32 item_size,\n\t\t\t\t struct btrfs_extent_inline_ref **out_eiref,\n\t\t\t\t int *out_type)\n{\n\tunsigned long end;\n\tu64 flags;\n\tstruct btrfs_tree_block_info *info;\n\n\tif (!*ptr) {\n\t\t \n\t\tflags = btrfs_extent_flags(eb, ei);\n\t\tif (flags & BTRFS_EXTENT_FLAG_TREE_BLOCK) {\n\t\t\tif (key->type == BTRFS_METADATA_ITEM_KEY) {\n\t\t\t\t \n\t\t\t\t*out_eiref =\n\t\t\t\t     (struct btrfs_extent_inline_ref *)(ei + 1);\n\t\t\t} else {\n\t\t\t\tWARN_ON(key->type != BTRFS_EXTENT_ITEM_KEY);\n\t\t\t\tinfo = (struct btrfs_tree_block_info *)(ei + 1);\n\t\t\t\t*out_eiref =\n\t\t\t\t   (struct btrfs_extent_inline_ref *)(info + 1);\n\t\t\t}\n\t\t} else {\n\t\t\t*out_eiref = (struct btrfs_extent_inline_ref *)(ei + 1);\n\t\t}\n\t\t*ptr = (unsigned long)*out_eiref;\n\t\tif ((unsigned long)(*ptr) >= (unsigned long)ei + item_size)\n\t\t\treturn -ENOENT;\n\t}\n\n\tend = (unsigned long)ei + item_size;\n\t*out_eiref = (struct btrfs_extent_inline_ref *)(*ptr);\n\t*out_type = btrfs_get_extent_inline_ref_type(eb, *out_eiref,\n\t\t\t\t\t\t     BTRFS_REF_TYPE_ANY);\n\tif (*out_type == BTRFS_REF_TYPE_INVALID)\n\t\treturn -EUCLEAN;\n\n\t*ptr += btrfs_extent_inline_ref_size(*out_type);\n\tWARN_ON(*ptr > end);\n\tif (*ptr == end)\n\t\treturn 1;  \n\n\treturn 0;\n}\n\n \nint tree_backref_for_extent(unsigned long *ptr, struct extent_buffer *eb,\n\t\t\t    struct btrfs_key *key, struct btrfs_extent_item *ei,\n\t\t\t    u32 item_size, u64 *out_root, u8 *out_level)\n{\n\tint ret;\n\tint type;\n\tstruct btrfs_extent_inline_ref *eiref;\n\n\tif (*ptr == (unsigned long)-1)\n\t\treturn 1;\n\n\twhile (1) {\n\t\tret = get_extent_inline_ref(ptr, eb, key, ei, item_size,\n\t\t\t\t\t      &eiref, &type);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (type == BTRFS_TREE_BLOCK_REF_KEY ||\n\t\t    type == BTRFS_SHARED_BLOCK_REF_KEY)\n\t\t\tbreak;\n\n\t\tif (ret == 1)\n\t\t\treturn 1;\n\t}\n\n\t \n\t*out_root = btrfs_extent_inline_ref_offset(eb, eiref);\n\n\tif (key->type == BTRFS_EXTENT_ITEM_KEY) {\n\t\tstruct btrfs_tree_block_info *info;\n\n\t\tinfo = (struct btrfs_tree_block_info *)(ei + 1);\n\t\t*out_level = btrfs_tree_block_level(eb, info);\n\t} else {\n\t\tASSERT(key->type == BTRFS_METADATA_ITEM_KEY);\n\t\t*out_level = (u8)key->offset;\n\t}\n\n\tif (ret == 1)\n\t\t*ptr = (unsigned long)-1;\n\n\treturn 0;\n}\n\nstatic int iterate_leaf_refs(struct btrfs_fs_info *fs_info,\n\t\t\t     struct extent_inode_elem *inode_list,\n\t\t\t     u64 root, u64 extent_item_objectid,\n\t\t\t     iterate_extent_inodes_t *iterate, void *ctx)\n{\n\tstruct extent_inode_elem *eie;\n\tint ret = 0;\n\n\tfor (eie = inode_list; eie; eie = eie->next) {\n\t\tbtrfs_debug(fs_info,\n\t\t\t    \"ref for %llu resolved, key (%llu EXTEND_DATA %llu), root %llu\",\n\t\t\t    extent_item_objectid, eie->inum,\n\t\t\t    eie->offset, root);\n\t\tret = iterate(eie->inum, eie->offset, eie->num_bytes, root, ctx);\n\t\tif (ret) {\n\t\t\tbtrfs_debug(fs_info,\n\t\t\t\t    \"stopping iteration for %llu due to ret=%d\",\n\t\t\t\t    extent_item_objectid, ret);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n \nint iterate_extent_inodes(struct btrfs_backref_walk_ctx *ctx,\n\t\t\t  bool search_commit_root,\n\t\t\t  iterate_extent_inodes_t *iterate, void *user_ctx)\n{\n\tint ret;\n\tstruct ulist *refs;\n\tstruct ulist_node *ref_node;\n\tstruct btrfs_seq_list seq_elem = BTRFS_SEQ_LIST_INIT(seq_elem);\n\tstruct ulist_iterator ref_uiter;\n\n\tbtrfs_debug(ctx->fs_info, \"resolving all inodes for extent %llu\",\n\t\t    ctx->bytenr);\n\n\tASSERT(ctx->trans == NULL);\n\tASSERT(ctx->roots == NULL);\n\n\tif (!search_commit_root) {\n\t\tstruct btrfs_trans_handle *trans;\n\n\t\ttrans = btrfs_attach_transaction(ctx->fs_info->tree_root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tif (PTR_ERR(trans) != -ENOENT &&\n\t\t\t    PTR_ERR(trans) != -EROFS)\n\t\t\t\treturn PTR_ERR(trans);\n\t\t\ttrans = NULL;\n\t\t}\n\t\tctx->trans = trans;\n\t}\n\n\tif (ctx->trans) {\n\t\tbtrfs_get_tree_mod_seq(ctx->fs_info, &seq_elem);\n\t\tctx->time_seq = seq_elem.seq;\n\t} else {\n\t\tdown_read(&ctx->fs_info->commit_root_sem);\n\t}\n\n\tret = btrfs_find_all_leafs(ctx);\n\tif (ret)\n\t\tgoto out;\n\trefs = ctx->refs;\n\tctx->refs = NULL;\n\n\tULIST_ITER_INIT(&ref_uiter);\n\twhile (!ret && (ref_node = ulist_next(refs, &ref_uiter))) {\n\t\tconst u64 leaf_bytenr = ref_node->val;\n\t\tstruct ulist_node *root_node;\n\t\tstruct ulist_iterator root_uiter;\n\t\tstruct extent_inode_elem *inode_list;\n\n\t\tinode_list = (struct extent_inode_elem *)(uintptr_t)ref_node->aux;\n\n\t\tif (ctx->cache_lookup) {\n\t\t\tconst u64 *root_ids;\n\t\t\tint root_count;\n\t\t\tbool cached;\n\n\t\t\tcached = ctx->cache_lookup(leaf_bytenr, ctx->user_ctx,\n\t\t\t\t\t\t   &root_ids, &root_count);\n\t\t\tif (cached) {\n\t\t\t\tfor (int i = 0; i < root_count; i++) {\n\t\t\t\t\tret = iterate_leaf_refs(ctx->fs_info,\n\t\t\t\t\t\t\t\tinode_list,\n\t\t\t\t\t\t\t\troot_ids[i],\n\t\t\t\t\t\t\t\tleaf_bytenr,\n\t\t\t\t\t\t\t\titerate,\n\t\t\t\t\t\t\t\tuser_ctx);\n\t\t\t\t\tif (ret)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (!ctx->roots) {\n\t\t\tctx->roots = ulist_alloc(GFP_NOFS);\n\t\t\tif (!ctx->roots) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tctx->bytenr = leaf_bytenr;\n\t\tret = btrfs_find_all_roots_safe(ctx);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (ctx->cache_store)\n\t\t\tctx->cache_store(leaf_bytenr, ctx->roots, ctx->user_ctx);\n\n\t\tULIST_ITER_INIT(&root_uiter);\n\t\twhile (!ret && (root_node = ulist_next(ctx->roots, &root_uiter))) {\n\t\t\tbtrfs_debug(ctx->fs_info,\n\t\t\t\t    \"root %llu references leaf %llu, data list %#llx\",\n\t\t\t\t    root_node->val, ref_node->val,\n\t\t\t\t    ref_node->aux);\n\t\t\tret = iterate_leaf_refs(ctx->fs_info, inode_list,\n\t\t\t\t\t\troot_node->val, ctx->bytenr,\n\t\t\t\t\t\titerate, user_ctx);\n\t\t}\n\t\tulist_reinit(ctx->roots);\n\t}\n\n\tfree_leaf_list(refs);\nout:\n\tif (ctx->trans) {\n\t\tbtrfs_put_tree_mod_seq(ctx->fs_info, &seq_elem);\n\t\tbtrfs_end_transaction(ctx->trans);\n\t\tctx->trans = NULL;\n\t} else {\n\t\tup_read(&ctx->fs_info->commit_root_sem);\n\t}\n\n\tulist_free(ctx->roots);\n\tctx->roots = NULL;\n\n\tif (ret == BTRFS_ITERATE_EXTENT_INODES_STOP)\n\t\tret = 0;\n\n\treturn ret;\n}\n\nstatic int build_ino_list(u64 inum, u64 offset, u64 num_bytes, u64 root, void *ctx)\n{\n\tstruct btrfs_data_container *inodes = ctx;\n\tconst size_t c = 3 * sizeof(u64);\n\n\tif (inodes->bytes_left >= c) {\n\t\tinodes->bytes_left -= c;\n\t\tinodes->val[inodes->elem_cnt] = inum;\n\t\tinodes->val[inodes->elem_cnt + 1] = offset;\n\t\tinodes->val[inodes->elem_cnt + 2] = root;\n\t\tinodes->elem_cnt += 3;\n\t} else {\n\t\tinodes->bytes_missing += c - inodes->bytes_left;\n\t\tinodes->bytes_left = 0;\n\t\tinodes->elem_missed += 3;\n\t}\n\n\treturn 0;\n}\n\nint iterate_inodes_from_logical(u64 logical, struct btrfs_fs_info *fs_info,\n\t\t\t\tstruct btrfs_path *path,\n\t\t\t\tvoid *ctx, bool ignore_offset)\n{\n\tstruct btrfs_backref_walk_ctx walk_ctx = { 0 };\n\tint ret;\n\tu64 flags = 0;\n\tstruct btrfs_key found_key;\n\tint search_commit_root = path->search_commit_root;\n\n\tret = extent_from_logical(fs_info, logical, path, &found_key, &flags);\n\tbtrfs_release_path(path);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (flags & BTRFS_EXTENT_FLAG_TREE_BLOCK)\n\t\treturn -EINVAL;\n\n\twalk_ctx.bytenr = found_key.objectid;\n\tif (ignore_offset)\n\t\twalk_ctx.ignore_extent_item_pos = true;\n\telse\n\t\twalk_ctx.extent_item_pos = logical - found_key.objectid;\n\twalk_ctx.fs_info = fs_info;\n\n\treturn iterate_extent_inodes(&walk_ctx, search_commit_root,\n\t\t\t\t     build_ino_list, ctx);\n}\n\nstatic int inode_to_path(u64 inum, u32 name_len, unsigned long name_off,\n\t\t\t struct extent_buffer *eb, struct inode_fs_paths *ipath);\n\nstatic int iterate_inode_refs(u64 inum, struct inode_fs_paths *ipath)\n{\n\tint ret = 0;\n\tint slot;\n\tu32 cur;\n\tu32 len;\n\tu32 name_len;\n\tu64 parent = 0;\n\tint found = 0;\n\tstruct btrfs_root *fs_root = ipath->fs_root;\n\tstruct btrfs_path *path = ipath->btrfs_path;\n\tstruct extent_buffer *eb;\n\tstruct btrfs_inode_ref *iref;\n\tstruct btrfs_key found_key;\n\n\twhile (!ret) {\n\t\tret = btrfs_find_item(fs_root, path, inum,\n\t\t\t\tparent ? parent + 1 : 0, BTRFS_INODE_REF_KEY,\n\t\t\t\t&found_key);\n\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t\tif (ret) {\n\t\t\tret = found ? 0 : -ENOENT;\n\t\t\tbreak;\n\t\t}\n\t\t++found;\n\n\t\tparent = found_key.offset;\n\t\tslot = path->slots[0];\n\t\teb = btrfs_clone_extent_buffer(path->nodes[0]);\n\t\tif (!eb) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\tbtrfs_release_path(path);\n\n\t\tiref = btrfs_item_ptr(eb, slot, struct btrfs_inode_ref);\n\n\t\tfor (cur = 0; cur < btrfs_item_size(eb, slot); cur += len) {\n\t\t\tname_len = btrfs_inode_ref_name_len(eb, iref);\n\t\t\t \n\t\t\tbtrfs_debug(fs_root->fs_info,\n\t\t\t\t\"following ref at offset %u for inode %llu in tree %llu\",\n\t\t\t\tcur, found_key.objectid,\n\t\t\t\tfs_root->root_key.objectid);\n\t\t\tret = inode_to_path(parent, name_len,\n\t\t\t\t      (unsigned long)(iref + 1), eb, ipath);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t\tlen = sizeof(*iref) + name_len;\n\t\t\tiref = (struct btrfs_inode_ref *)((char *)iref + len);\n\t\t}\n\t\tfree_extent_buffer(eb);\n\t}\n\n\tbtrfs_release_path(path);\n\n\treturn ret;\n}\n\nstatic int iterate_inode_extrefs(u64 inum, struct inode_fs_paths *ipath)\n{\n\tint ret;\n\tint slot;\n\tu64 offset = 0;\n\tu64 parent;\n\tint found = 0;\n\tstruct btrfs_root *fs_root = ipath->fs_root;\n\tstruct btrfs_path *path = ipath->btrfs_path;\n\tstruct extent_buffer *eb;\n\tstruct btrfs_inode_extref *extref;\n\tu32 item_size;\n\tu32 cur_offset;\n\tunsigned long ptr;\n\n\twhile (1) {\n\t\tret = btrfs_find_one_extref(fs_root, inum, offset, path, &extref,\n\t\t\t\t\t    &offset);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t\tif (ret) {\n\t\t\tret = found ? 0 : -ENOENT;\n\t\t\tbreak;\n\t\t}\n\t\t++found;\n\n\t\tslot = path->slots[0];\n\t\teb = btrfs_clone_extent_buffer(path->nodes[0]);\n\t\tif (!eb) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\tbtrfs_release_path(path);\n\n\t\titem_size = btrfs_item_size(eb, slot);\n\t\tptr = btrfs_item_ptr_offset(eb, slot);\n\t\tcur_offset = 0;\n\n\t\twhile (cur_offset < item_size) {\n\t\t\tu32 name_len;\n\n\t\t\textref = (struct btrfs_inode_extref *)(ptr + cur_offset);\n\t\t\tparent = btrfs_inode_extref_parent(eb, extref);\n\t\t\tname_len = btrfs_inode_extref_name_len(eb, extref);\n\t\t\tret = inode_to_path(parent, name_len,\n\t\t\t\t      (unsigned long)&extref->name, eb, ipath);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\n\t\t\tcur_offset += btrfs_inode_extref_name_len(eb, extref);\n\t\t\tcur_offset += sizeof(*extref);\n\t\t}\n\t\tfree_extent_buffer(eb);\n\n\t\toffset++;\n\t}\n\n\tbtrfs_release_path(path);\n\n\treturn ret;\n}\n\n \nstatic int inode_to_path(u64 inum, u32 name_len, unsigned long name_off,\n\t\t\t struct extent_buffer *eb, struct inode_fs_paths *ipath)\n{\n\tchar *fspath;\n\tchar *fspath_min;\n\tint i = ipath->fspath->elem_cnt;\n\tconst int s_ptr = sizeof(char *);\n\tu32 bytes_left;\n\n\tbytes_left = ipath->fspath->bytes_left > s_ptr ?\n\t\t\t\t\tipath->fspath->bytes_left - s_ptr : 0;\n\n\tfspath_min = (char *)ipath->fspath->val + (i + 1) * s_ptr;\n\tfspath = btrfs_ref_to_path(ipath->fs_root, ipath->btrfs_path, name_len,\n\t\t\t\t   name_off, eb, inum, fspath_min, bytes_left);\n\tif (IS_ERR(fspath))\n\t\treturn PTR_ERR(fspath);\n\n\tif (fspath > fspath_min) {\n\t\tipath->fspath->val[i] = (u64)(unsigned long)fspath;\n\t\t++ipath->fspath->elem_cnt;\n\t\tipath->fspath->bytes_left = fspath - fspath_min;\n\t} else {\n\t\t++ipath->fspath->elem_missed;\n\t\tipath->fspath->bytes_missing += fspath_min - fspath;\n\t\tipath->fspath->bytes_left = 0;\n\t}\n\n\treturn 0;\n}\n\n \nint paths_from_inode(u64 inum, struct inode_fs_paths *ipath)\n{\n\tint ret;\n\tint found_refs = 0;\n\n\tret = iterate_inode_refs(inum, ipath);\n\tif (!ret)\n\t\t++found_refs;\n\telse if (ret != -ENOENT)\n\t\treturn ret;\n\n\tret = iterate_inode_extrefs(inum, ipath);\n\tif (ret == -ENOENT && found_refs)\n\t\treturn 0;\n\n\treturn ret;\n}\n\nstruct btrfs_data_container *init_data_container(u32 total_bytes)\n{\n\tstruct btrfs_data_container *data;\n\tsize_t alloc_bytes;\n\n\talloc_bytes = max_t(size_t, total_bytes, sizeof(*data));\n\tdata = kvmalloc(alloc_bytes, GFP_KERNEL);\n\tif (!data)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (total_bytes >= sizeof(*data)) {\n\t\tdata->bytes_left = total_bytes - sizeof(*data);\n\t\tdata->bytes_missing = 0;\n\t} else {\n\t\tdata->bytes_missing = sizeof(*data) - total_bytes;\n\t\tdata->bytes_left = 0;\n\t}\n\n\tdata->elem_cnt = 0;\n\tdata->elem_missed = 0;\n\n\treturn data;\n}\n\n \nstruct inode_fs_paths *init_ipath(s32 total_bytes, struct btrfs_root *fs_root,\n\t\t\t\t\tstruct btrfs_path *path)\n{\n\tstruct inode_fs_paths *ifp;\n\tstruct btrfs_data_container *fspath;\n\n\tfspath = init_data_container(total_bytes);\n\tif (IS_ERR(fspath))\n\t\treturn ERR_CAST(fspath);\n\n\tifp = kmalloc(sizeof(*ifp), GFP_KERNEL);\n\tif (!ifp) {\n\t\tkvfree(fspath);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tifp->btrfs_path = path;\n\tifp->fspath = fspath;\n\tifp->fs_root = fs_root;\n\n\treturn ifp;\n}\n\nvoid free_ipath(struct inode_fs_paths *ipath)\n{\n\tif (!ipath)\n\t\treturn;\n\tkvfree(ipath->fspath);\n\tkfree(ipath);\n}\n\nstruct btrfs_backref_iter *btrfs_backref_iter_alloc(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_backref_iter *ret;\n\n\tret = kzalloc(sizeof(*ret), GFP_NOFS);\n\tif (!ret)\n\t\treturn NULL;\n\n\tret->path = btrfs_alloc_path();\n\tif (!ret->path) {\n\t\tkfree(ret);\n\t\treturn NULL;\n\t}\n\n\t \n\tret->path->search_commit_root = 1;\n\tret->path->skip_locking = 1;\n\tret->fs_info = fs_info;\n\n\treturn ret;\n}\n\nint btrfs_backref_iter_start(struct btrfs_backref_iter *iter, u64 bytenr)\n{\n\tstruct btrfs_fs_info *fs_info = iter->fs_info;\n\tstruct btrfs_root *extent_root = btrfs_extent_root(fs_info, bytenr);\n\tstruct btrfs_path *path = iter->path;\n\tstruct btrfs_extent_item *ei;\n\tstruct btrfs_key key;\n\tint ret;\n\n\tkey.objectid = bytenr;\n\tkey.type = BTRFS_METADATA_ITEM_KEY;\n\tkey.offset = (u64)-1;\n\titer->bytenr = bytenr;\n\n\tret = btrfs_search_slot(NULL, extent_root, &key, path, 0, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret == 0) {\n\t\tret = -EUCLEAN;\n\t\tgoto release;\n\t}\n\tif (path->slots[0] == 0) {\n\t\tWARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));\n\t\tret = -EUCLEAN;\n\t\tgoto release;\n\t}\n\tpath->slots[0]--;\n\n\tbtrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0]);\n\tif ((key.type != BTRFS_EXTENT_ITEM_KEY &&\n\t     key.type != BTRFS_METADATA_ITEM_KEY) || key.objectid != bytenr) {\n\t\tret = -ENOENT;\n\t\tgoto release;\n\t}\n\tmemcpy(&iter->cur_key, &key, sizeof(key));\n\titer->item_ptr = (u32)btrfs_item_ptr_offset(path->nodes[0],\n\t\t\t\t\t\t    path->slots[0]);\n\titer->end_ptr = (u32)(iter->item_ptr +\n\t\t\tbtrfs_item_size(path->nodes[0], path->slots[0]));\n\tei = btrfs_item_ptr(path->nodes[0], path->slots[0],\n\t\t\t    struct btrfs_extent_item);\n\n\t \n\tif (btrfs_extent_flags(path->nodes[0], ei) & BTRFS_EXTENT_FLAG_DATA) {\n\t\tret = -ENOTSUPP;\n\t\tgoto release;\n\t}\n\titer->cur_ptr = (u32)(iter->item_ptr + sizeof(*ei));\n\n\t \n\tif (iter->cur_ptr >= iter->end_ptr) {\n\t\tret = btrfs_next_item(extent_root, path);\n\n\t\t \n\t\tif (ret > 0) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto release;\n\t\t}\n\t\tif (ret < 0)\n\t\t\tgoto release;\n\n\t\tbtrfs_item_key_to_cpu(path->nodes[0], &iter->cur_key,\n\t\t\t\tpath->slots[0]);\n\t\tif (iter->cur_key.objectid != bytenr ||\n\t\t    (iter->cur_key.type != BTRFS_SHARED_BLOCK_REF_KEY &&\n\t\t     iter->cur_key.type != BTRFS_TREE_BLOCK_REF_KEY)) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto release;\n\t\t}\n\t\titer->cur_ptr = (u32)btrfs_item_ptr_offset(path->nodes[0],\n\t\t\t\t\t\t\t   path->slots[0]);\n\t\titer->item_ptr = iter->cur_ptr;\n\t\titer->end_ptr = (u32)(iter->item_ptr + btrfs_item_size(\n\t\t\t\t      path->nodes[0], path->slots[0]));\n\t}\n\n\treturn 0;\nrelease:\n\tbtrfs_backref_iter_release(iter);\n\treturn ret;\n}\n\n \nint btrfs_backref_iter_next(struct btrfs_backref_iter *iter)\n{\n\tstruct extent_buffer *eb = btrfs_backref_get_eb(iter);\n\tstruct btrfs_root *extent_root;\n\tstruct btrfs_path *path = iter->path;\n\tstruct btrfs_extent_inline_ref *iref;\n\tint ret;\n\tu32 size;\n\n\tif (btrfs_backref_iter_is_inline_ref(iter)) {\n\t\t \n\t\tASSERT(iter->cur_ptr < iter->end_ptr);\n\n\t\tif (btrfs_backref_has_tree_block_info(iter)) {\n\t\t\t \n\t\t\tsize = sizeof(struct btrfs_tree_block_info);\n\t\t} else {\n\t\t\t \n\t\t\tint type;\n\n\t\t\tiref = (struct btrfs_extent_inline_ref *)\n\t\t\t\t((unsigned long)iter->cur_ptr);\n\t\t\ttype = btrfs_extent_inline_ref_type(eb, iref);\n\n\t\t\tsize = btrfs_extent_inline_ref_size(type);\n\t\t}\n\t\titer->cur_ptr += size;\n\t\tif (iter->cur_ptr < iter->end_ptr)\n\t\t\treturn 0;\n\n\t\t \n\t}\n\n\t \n\textent_root = btrfs_extent_root(iter->fs_info, iter->bytenr);\n\tret = btrfs_next_item(extent_root, iter->path);\n\tif (ret)\n\t\treturn ret;\n\n\tbtrfs_item_key_to_cpu(path->nodes[0], &iter->cur_key, path->slots[0]);\n\tif (iter->cur_key.objectid != iter->bytenr ||\n\t    (iter->cur_key.type != BTRFS_TREE_BLOCK_REF_KEY &&\n\t     iter->cur_key.type != BTRFS_SHARED_BLOCK_REF_KEY))\n\t\treturn 1;\n\titer->item_ptr = (u32)btrfs_item_ptr_offset(path->nodes[0],\n\t\t\t\t\tpath->slots[0]);\n\titer->cur_ptr = iter->item_ptr;\n\titer->end_ptr = iter->item_ptr + (u32)btrfs_item_size(path->nodes[0],\n\t\t\t\t\t\tpath->slots[0]);\n\treturn 0;\n}\n\nvoid btrfs_backref_init_cache(struct btrfs_fs_info *fs_info,\n\t\t\t      struct btrfs_backref_cache *cache, int is_reloc)\n{\n\tint i;\n\n\tcache->rb_root = RB_ROOT;\n\tfor (i = 0; i < BTRFS_MAX_LEVEL; i++)\n\t\tINIT_LIST_HEAD(&cache->pending[i]);\n\tINIT_LIST_HEAD(&cache->changed);\n\tINIT_LIST_HEAD(&cache->detached);\n\tINIT_LIST_HEAD(&cache->leaves);\n\tINIT_LIST_HEAD(&cache->pending_edge);\n\tINIT_LIST_HEAD(&cache->useless_node);\n\tcache->fs_info = fs_info;\n\tcache->is_reloc = is_reloc;\n}\n\nstruct btrfs_backref_node *btrfs_backref_alloc_node(\n\t\tstruct btrfs_backref_cache *cache, u64 bytenr, int level)\n{\n\tstruct btrfs_backref_node *node;\n\n\tASSERT(level >= 0 && level < BTRFS_MAX_LEVEL);\n\tnode = kzalloc(sizeof(*node), GFP_NOFS);\n\tif (!node)\n\t\treturn node;\n\n\tINIT_LIST_HEAD(&node->list);\n\tINIT_LIST_HEAD(&node->upper);\n\tINIT_LIST_HEAD(&node->lower);\n\tRB_CLEAR_NODE(&node->rb_node);\n\tcache->nr_nodes++;\n\tnode->level = level;\n\tnode->bytenr = bytenr;\n\n\treturn node;\n}\n\nstruct btrfs_backref_edge *btrfs_backref_alloc_edge(\n\t\tstruct btrfs_backref_cache *cache)\n{\n\tstruct btrfs_backref_edge *edge;\n\n\tedge = kzalloc(sizeof(*edge), GFP_NOFS);\n\tif (edge)\n\t\tcache->nr_edges++;\n\treturn edge;\n}\n\n \nvoid btrfs_backref_cleanup_node(struct btrfs_backref_cache *cache,\n\t\t\t\tstruct btrfs_backref_node *node)\n{\n\tstruct btrfs_backref_node *upper;\n\tstruct btrfs_backref_edge *edge;\n\n\tif (!node)\n\t\treturn;\n\n\tBUG_ON(!node->lowest && !node->detached);\n\twhile (!list_empty(&node->upper)) {\n\t\tedge = list_entry(node->upper.next, struct btrfs_backref_edge,\n\t\t\t\t  list[LOWER]);\n\t\tupper = edge->node[UPPER];\n\t\tlist_del(&edge->list[LOWER]);\n\t\tlist_del(&edge->list[UPPER]);\n\t\tbtrfs_backref_free_edge(cache, edge);\n\n\t\t \n\t\tif (list_empty(&upper->lower)) {\n\t\t\tlist_add_tail(&upper->lower, &cache->leaves);\n\t\t\tupper->lowest = 1;\n\t\t}\n\t}\n\n\tbtrfs_backref_drop_node(cache, node);\n}\n\n \nvoid btrfs_backref_release_cache(struct btrfs_backref_cache *cache)\n{\n\tstruct btrfs_backref_node *node;\n\tint i;\n\n\twhile (!list_empty(&cache->detached)) {\n\t\tnode = list_entry(cache->detached.next,\n\t\t\t\t  struct btrfs_backref_node, list);\n\t\tbtrfs_backref_cleanup_node(cache, node);\n\t}\n\n\twhile (!list_empty(&cache->leaves)) {\n\t\tnode = list_entry(cache->leaves.next,\n\t\t\t\t  struct btrfs_backref_node, lower);\n\t\tbtrfs_backref_cleanup_node(cache, node);\n\t}\n\n\tcache->last_trans = 0;\n\n\tfor (i = 0; i < BTRFS_MAX_LEVEL; i++)\n\t\tASSERT(list_empty(&cache->pending[i]));\n\tASSERT(list_empty(&cache->pending_edge));\n\tASSERT(list_empty(&cache->useless_node));\n\tASSERT(list_empty(&cache->changed));\n\tASSERT(list_empty(&cache->detached));\n\tASSERT(RB_EMPTY_ROOT(&cache->rb_root));\n\tASSERT(!cache->nr_nodes);\n\tASSERT(!cache->nr_edges);\n}\n\n \nstatic int handle_direct_tree_backref(struct btrfs_backref_cache *cache,\n\t\t\t\t      struct btrfs_key *ref_key,\n\t\t\t\t      struct btrfs_backref_node *cur)\n{\n\tstruct btrfs_backref_edge *edge;\n\tstruct btrfs_backref_node *upper;\n\tstruct rb_node *rb_node;\n\n\tASSERT(ref_key->type == BTRFS_SHARED_BLOCK_REF_KEY);\n\n\t \n\tif (ref_key->objectid == ref_key->offset) {\n\t\tstruct btrfs_root *root;\n\n\t\tcur->is_reloc_root = 1;\n\t\t \n\t\tif (cache->is_reloc) {\n\t\t\troot = find_reloc_root(cache->fs_info, cur->bytenr);\n\t\t\tif (!root)\n\t\t\t\treturn -ENOENT;\n\t\t\tcur->root = root;\n\t\t} else {\n\t\t\t \n\t\t\tlist_add(&cur->list, &cache->useless_node);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tedge = btrfs_backref_alloc_edge(cache);\n\tif (!edge)\n\t\treturn -ENOMEM;\n\n\trb_node = rb_simple_search(&cache->rb_root, ref_key->offset);\n\tif (!rb_node) {\n\t\t \n\t\tupper = btrfs_backref_alloc_node(cache, ref_key->offset,\n\t\t\t\t\t   cur->level + 1);\n\t\tif (!upper) {\n\t\t\tbtrfs_backref_free_edge(cache, edge);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tlist_add_tail(&edge->list[UPPER], &cache->pending_edge);\n\t} else {\n\t\t \n\t\tupper = rb_entry(rb_node, struct btrfs_backref_node, rb_node);\n\t\tASSERT(upper->checked);\n\t\tINIT_LIST_HEAD(&edge->list[UPPER]);\n\t}\n\tbtrfs_backref_link_edge(edge, cur, upper, LINK_LOWER);\n\treturn 0;\n}\n\n \nstatic int handle_indirect_tree_backref(struct btrfs_trans_handle *trans,\n\t\t\t\t\tstruct btrfs_backref_cache *cache,\n\t\t\t\t\tstruct btrfs_path *path,\n\t\t\t\t\tstruct btrfs_key *ref_key,\n\t\t\t\t\tstruct btrfs_key *tree_key,\n\t\t\t\t\tstruct btrfs_backref_node *cur)\n{\n\tstruct btrfs_fs_info *fs_info = cache->fs_info;\n\tstruct btrfs_backref_node *upper;\n\tstruct btrfs_backref_node *lower;\n\tstruct btrfs_backref_edge *edge;\n\tstruct extent_buffer *eb;\n\tstruct btrfs_root *root;\n\tstruct rb_node *rb_node;\n\tint level;\n\tbool need_check = true;\n\tint ret;\n\n\troot = btrfs_get_fs_root(fs_info, ref_key->offset, false);\n\tif (IS_ERR(root))\n\t\treturn PTR_ERR(root);\n\tif (!test_bit(BTRFS_ROOT_SHAREABLE, &root->state))\n\t\tcur->cowonly = 1;\n\n\tif (btrfs_root_level(&root->root_item) == cur->level) {\n\t\t \n\t\tASSERT(btrfs_root_bytenr(&root->root_item) == cur->bytenr);\n\t\t \n\t\tif (btrfs_should_ignore_reloc_root(root) && cache->is_reloc) {\n\t\t\tbtrfs_put_root(root);\n\t\t\tlist_add(&cur->list, &cache->useless_node);\n\t\t} else {\n\t\t\tcur->root = root;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tlevel = cur->level + 1;\n\n\t \n\tpath->search_commit_root = 1;\n\tpath->skip_locking = 1;\n\tpath->lowest_level = level;\n\tret = btrfs_search_slot(NULL, root, tree_key, path, 0, 0);\n\tpath->lowest_level = 0;\n\tif (ret < 0) {\n\t\tbtrfs_put_root(root);\n\t\treturn ret;\n\t}\n\tif (ret > 0 && path->slots[level] > 0)\n\t\tpath->slots[level]--;\n\n\teb = path->nodes[level];\n\tif (btrfs_node_blockptr(eb, path->slots[level]) != cur->bytenr) {\n\t\tbtrfs_err(fs_info,\n\"couldn't find block (%llu) (level %d) in tree (%llu) with key (%llu %u %llu)\",\n\t\t\t  cur->bytenr, level - 1, root->root_key.objectid,\n\t\t\t  tree_key->objectid, tree_key->type, tree_key->offset);\n\t\tbtrfs_put_root(root);\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\tlower = cur;\n\n\t \n\tfor (; level < BTRFS_MAX_LEVEL; level++) {\n\t\tif (!path->nodes[level]) {\n\t\t\tASSERT(btrfs_root_bytenr(&root->root_item) ==\n\t\t\t       lower->bytenr);\n\t\t\t \n\t\t\tif (btrfs_should_ignore_reloc_root(root) &&\n\t\t\t    cache->is_reloc) {\n\t\t\t\tbtrfs_put_root(root);\n\t\t\t\tlist_add(&lower->list, &cache->useless_node);\n\t\t\t} else {\n\t\t\t\tlower->root = root;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tedge = btrfs_backref_alloc_edge(cache);\n\t\tif (!edge) {\n\t\t\tbtrfs_put_root(root);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\teb = path->nodes[level];\n\t\trb_node = rb_simple_search(&cache->rb_root, eb->start);\n\t\tif (!rb_node) {\n\t\t\tupper = btrfs_backref_alloc_node(cache, eb->start,\n\t\t\t\t\t\t\t lower->level + 1);\n\t\t\tif (!upper) {\n\t\t\t\tbtrfs_put_root(root);\n\t\t\t\tbtrfs_backref_free_edge(cache, edge);\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tupper->owner = btrfs_header_owner(eb);\n\t\t\tif (!test_bit(BTRFS_ROOT_SHAREABLE, &root->state))\n\t\t\t\tupper->cowonly = 1;\n\n\t\t\t \n\t\t\tif (btrfs_block_can_be_shared(trans, root, eb))\n\t\t\t\tupper->checked = 0;\n\t\t\telse\n\t\t\t\tupper->checked = 1;\n\n\t\t\t \n\t\t\tif (!upper->checked && need_check) {\n\t\t\t\tneed_check = false;\n\t\t\t\tlist_add_tail(&edge->list[UPPER],\n\t\t\t\t\t      &cache->pending_edge);\n\t\t\t} else {\n\t\t\t\tif (upper->checked)\n\t\t\t\t\tneed_check = true;\n\t\t\t\tINIT_LIST_HEAD(&edge->list[UPPER]);\n\t\t\t}\n\t\t} else {\n\t\t\tupper = rb_entry(rb_node, struct btrfs_backref_node,\n\t\t\t\t\t rb_node);\n\t\t\tASSERT(upper->checked);\n\t\t\tINIT_LIST_HEAD(&edge->list[UPPER]);\n\t\t\tif (!upper->owner)\n\t\t\t\tupper->owner = btrfs_header_owner(eb);\n\t\t}\n\t\tbtrfs_backref_link_edge(edge, lower, upper, LINK_LOWER);\n\n\t\tif (rb_node) {\n\t\t\tbtrfs_put_root(root);\n\t\t\tbreak;\n\t\t}\n\t\tlower = upper;\n\t\tupper = NULL;\n\t}\nout:\n\tbtrfs_release_path(path);\n\treturn ret;\n}\n\n \nint btrfs_backref_add_tree_node(struct btrfs_trans_handle *trans,\n\t\t\t\tstruct btrfs_backref_cache *cache,\n\t\t\t\tstruct btrfs_path *path,\n\t\t\t\tstruct btrfs_backref_iter *iter,\n\t\t\t\tstruct btrfs_key *node_key,\n\t\t\t\tstruct btrfs_backref_node *cur)\n{\n\tstruct btrfs_backref_edge *edge;\n\tstruct btrfs_backref_node *exist;\n\tint ret;\n\n\tret = btrfs_backref_iter_start(iter, cur->bytenr);\n\tif (ret < 0)\n\t\treturn ret;\n\t \n\tif (btrfs_backref_has_tree_block_info(iter)) {\n\t\tret = btrfs_backref_iter_next(iter);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\t \n\t\tif (ret > 0) {\n\t\t\tret = -EUCLEAN;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tWARN_ON(cur->checked);\n\tif (!list_empty(&cur->upper)) {\n\t\t \n\t\tASSERT(list_is_singular(&cur->upper));\n\t\tedge = list_entry(cur->upper.next, struct btrfs_backref_edge,\n\t\t\t\t  list[LOWER]);\n\t\tASSERT(list_empty(&edge->list[UPPER]));\n\t\texist = edge->node[UPPER];\n\t\t \n\t\tif (!exist->checked)\n\t\t\tlist_add_tail(&edge->list[UPPER], &cache->pending_edge);\n\t} else {\n\t\texist = NULL;\n\t}\n\n\tfor (; ret == 0; ret = btrfs_backref_iter_next(iter)) {\n\t\tstruct extent_buffer *eb;\n\t\tstruct btrfs_key key;\n\t\tint type;\n\n\t\tcond_resched();\n\t\teb = btrfs_backref_get_eb(iter);\n\n\t\tkey.objectid = iter->bytenr;\n\t\tif (btrfs_backref_iter_is_inline_ref(iter)) {\n\t\t\tstruct btrfs_extent_inline_ref *iref;\n\n\t\t\t \n\t\t\tiref = (struct btrfs_extent_inline_ref *)\n\t\t\t\t((unsigned long)iter->cur_ptr);\n\t\t\ttype = btrfs_get_extent_inline_ref_type(eb, iref,\n\t\t\t\t\t\t\tBTRFS_REF_TYPE_BLOCK);\n\t\t\tif (type == BTRFS_REF_TYPE_INVALID) {\n\t\t\t\tret = -EUCLEAN;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tkey.type = type;\n\t\t\tkey.offset = btrfs_extent_inline_ref_offset(eb, iref);\n\t\t} else {\n\t\t\tkey.type = iter->cur_key.type;\n\t\t\tkey.offset = iter->cur_key.offset;\n\t\t}\n\n\t\t \n\t\tif (exist &&\n\t\t    ((key.type == BTRFS_TREE_BLOCK_REF_KEY &&\n\t\t      exist->owner == key.offset) ||\n\t\t     (key.type == BTRFS_SHARED_BLOCK_REF_KEY &&\n\t\t      exist->bytenr == key.offset))) {\n\t\t\texist = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (key.type == BTRFS_SHARED_BLOCK_REF_KEY) {\n\t\t\tret = handle_direct_tree_backref(cache, &key, cur);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t} else if (key.type == BTRFS_TREE_BLOCK_REF_KEY) {\n\t\t\t \n\t\t\tret = handle_indirect_tree_backref(trans, cache, path,\n\t\t\t\t\t\t\t   &key, node_key, cur);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t\t \n\t}\n\tret = 0;\n\tcur->checked = 1;\n\tWARN_ON(exist);\nout:\n\tbtrfs_backref_iter_release(iter);\n\treturn ret;\n}\n\n \nint btrfs_backref_finish_upper_links(struct btrfs_backref_cache *cache,\n\t\t\t\t     struct btrfs_backref_node *start)\n{\n\tstruct list_head *useless_node = &cache->useless_node;\n\tstruct btrfs_backref_edge *edge;\n\tstruct rb_node *rb_node;\n\tLIST_HEAD(pending_edge);\n\n\tASSERT(start->checked);\n\n\t \n\tif (!start->cowonly) {\n\t\trb_node = rb_simple_insert(&cache->rb_root, start->bytenr,\n\t\t\t\t\t   &start->rb_node);\n\t\tif (rb_node)\n\t\t\tbtrfs_backref_panic(cache->fs_info, start->bytenr,\n\t\t\t\t\t    -EEXIST);\n\t\tlist_add_tail(&start->lower, &cache->leaves);\n\t}\n\n\t \n\tlist_for_each_entry(edge, &start->upper, list[LOWER])\n\t\tlist_add_tail(&edge->list[UPPER], &pending_edge);\n\n\twhile (!list_empty(&pending_edge)) {\n\t\tstruct btrfs_backref_node *upper;\n\t\tstruct btrfs_backref_node *lower;\n\n\t\tedge = list_first_entry(&pending_edge,\n\t\t\t\tstruct btrfs_backref_edge, list[UPPER]);\n\t\tlist_del_init(&edge->list[UPPER]);\n\t\tupper = edge->node[UPPER];\n\t\tlower = edge->node[LOWER];\n\n\t\t \n\t\tif (upper->detached) {\n\t\t\tlist_del(&edge->list[LOWER]);\n\t\t\tbtrfs_backref_free_edge(cache, edge);\n\n\t\t\t \n\t\t\tif (list_empty(&lower->upper))\n\t\t\t\tlist_add(&lower->list, useless_node);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (!RB_EMPTY_NODE(&upper->rb_node)) {\n\t\t\tif (upper->lowest) {\n\t\t\t\tlist_del_init(&upper->lower);\n\t\t\t\tupper->lowest = 0;\n\t\t\t}\n\n\t\t\tlist_add_tail(&edge->list[UPPER], &upper->lower);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (!upper->checked) {\n\t\t\tASSERT(0);\n\t\t\treturn -EUCLEAN;\n\t\t}\n\n\t\t \n\t\tif (start->cowonly != upper->cowonly) {\n\t\t\tASSERT(0);\n\t\t\treturn -EUCLEAN;\n\t\t}\n\n\t\t \n\t\tif (!upper->cowonly) {\n\t\t\trb_node = rb_simple_insert(&cache->rb_root, upper->bytenr,\n\t\t\t\t\t\t   &upper->rb_node);\n\t\t\tif (rb_node) {\n\t\t\t\tbtrfs_backref_panic(cache->fs_info,\n\t\t\t\t\t\tupper->bytenr, -EEXIST);\n\t\t\t\treturn -EUCLEAN;\n\t\t\t}\n\t\t}\n\n\t\tlist_add_tail(&edge->list[UPPER], &upper->lower);\n\n\t\t \n\t\tlist_for_each_entry(edge, &upper->upper, list[LOWER])\n\t\t\tlist_add_tail(&edge->list[UPPER], &pending_edge);\n\t}\n\treturn 0;\n}\n\nvoid btrfs_backref_error_cleanup(struct btrfs_backref_cache *cache,\n\t\t\t\t struct btrfs_backref_node *node)\n{\n\tstruct btrfs_backref_node *lower;\n\tstruct btrfs_backref_node *upper;\n\tstruct btrfs_backref_edge *edge;\n\n\twhile (!list_empty(&cache->useless_node)) {\n\t\tlower = list_first_entry(&cache->useless_node,\n\t\t\t\t   struct btrfs_backref_node, list);\n\t\tlist_del_init(&lower->list);\n\t}\n\twhile (!list_empty(&cache->pending_edge)) {\n\t\tedge = list_first_entry(&cache->pending_edge,\n\t\t\t\tstruct btrfs_backref_edge, list[UPPER]);\n\t\tlist_del(&edge->list[UPPER]);\n\t\tlist_del(&edge->list[LOWER]);\n\t\tlower = edge->node[LOWER];\n\t\tupper = edge->node[UPPER];\n\t\tbtrfs_backref_free_edge(cache, edge);\n\n\t\t \n\t\tif (list_empty(&lower->upper) &&\n\t\t    RB_EMPTY_NODE(&lower->rb_node))\n\t\t\tlist_add(&lower->list, &cache->useless_node);\n\n\t\tif (!RB_EMPTY_NODE(&upper->rb_node))\n\t\t\tcontinue;\n\n\t\t \n\t\tlist_for_each_entry(edge, &upper->upper, list[LOWER])\n\t\t\tlist_add_tail(&edge->list[UPPER],\n\t\t\t\t      &cache->pending_edge);\n\t\tif (list_empty(&upper->upper))\n\t\t\tlist_add(&upper->list, &cache->useless_node);\n\t}\n\n\twhile (!list_empty(&cache->useless_node)) {\n\t\tlower = list_first_entry(&cache->useless_node,\n\t\t\t\t   struct btrfs_backref_node, list);\n\t\tlist_del_init(&lower->list);\n\t\tif (lower == node)\n\t\t\tnode = NULL;\n\t\tbtrfs_backref_drop_node(cache, lower);\n\t}\n\n\tbtrfs_backref_cleanup_node(cache, node);\n\tASSERT(list_empty(&cache->useless_node) &&\n\t       list_empty(&cache->pending_edge));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}