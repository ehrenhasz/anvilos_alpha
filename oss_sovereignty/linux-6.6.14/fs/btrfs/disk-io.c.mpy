{
  "module_name": "disk-io.c",
  "hash_id": "7cdf1bd6c96c09c31d17740fda8c86b9cc7cb0ce53e9ae2e724c08712f37f3b1",
  "original_prompt": "Ingested from linux-6.6.14/fs/btrfs/disk-io.c",
  "human_readable_source": "\n \n\n#include <linux/fs.h>\n#include <linux/blkdev.h>\n#include <linux/radix-tree.h>\n#include <linux/writeback.h>\n#include <linux/workqueue.h>\n#include <linux/kthread.h>\n#include <linux/slab.h>\n#include <linux/migrate.h>\n#include <linux/ratelimit.h>\n#include <linux/uuid.h>\n#include <linux/semaphore.h>\n#include <linux/error-injection.h>\n#include <linux/crc32c.h>\n#include <linux/sched/mm.h>\n#include <asm/unaligned.h>\n#include <crypto/hash.h>\n#include \"ctree.h\"\n#include \"disk-io.h\"\n#include \"transaction.h\"\n#include \"btrfs_inode.h\"\n#include \"bio.h\"\n#include \"print-tree.h\"\n#include \"locking.h\"\n#include \"tree-log.h\"\n#include \"free-space-cache.h\"\n#include \"free-space-tree.h\"\n#include \"check-integrity.h\"\n#include \"rcu-string.h\"\n#include \"dev-replace.h\"\n#include \"raid56.h\"\n#include \"sysfs.h\"\n#include \"qgroup.h\"\n#include \"compression.h\"\n#include \"tree-checker.h\"\n#include \"ref-verify.h\"\n#include \"block-group.h\"\n#include \"discard.h\"\n#include \"space-info.h\"\n#include \"zoned.h\"\n#include \"subpage.h\"\n#include \"fs.h\"\n#include \"accessors.h\"\n#include \"extent-tree.h\"\n#include \"root-tree.h\"\n#include \"defrag.h\"\n#include \"uuid-tree.h\"\n#include \"relocation.h\"\n#include \"scrub.h\"\n#include \"super.h\"\n\n#define BTRFS_SUPER_FLAG_SUPP\t(BTRFS_HEADER_FLAG_WRITTEN |\\\n\t\t\t\t BTRFS_HEADER_FLAG_RELOC |\\\n\t\t\t\t BTRFS_SUPER_FLAG_ERROR |\\\n\t\t\t\t BTRFS_SUPER_FLAG_SEEDING |\\\n\t\t\t\t BTRFS_SUPER_FLAG_METADUMP |\\\n\t\t\t\t BTRFS_SUPER_FLAG_METADUMP_V2)\n\nstatic int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info);\nstatic void btrfs_error_commit_super(struct btrfs_fs_info *fs_info);\n\nstatic void btrfs_free_csum_hash(struct btrfs_fs_info *fs_info)\n{\n\tif (fs_info->csum_shash)\n\t\tcrypto_free_shash(fs_info->csum_shash);\n}\n\n \nstatic void csum_tree_block(struct extent_buffer *buf, u8 *result)\n{\n\tstruct btrfs_fs_info *fs_info = buf->fs_info;\n\tconst int num_pages = num_extent_pages(buf);\n\tconst int first_page_part = min_t(u32, PAGE_SIZE, fs_info->nodesize);\n\tSHASH_DESC_ON_STACK(shash, fs_info->csum_shash);\n\tchar *kaddr;\n\tint i;\n\n\tshash->tfm = fs_info->csum_shash;\n\tcrypto_shash_init(shash);\n\tkaddr = page_address(buf->pages[0]) + offset_in_page(buf->start);\n\tcrypto_shash_update(shash, kaddr + BTRFS_CSUM_SIZE,\n\t\t\t    first_page_part - BTRFS_CSUM_SIZE);\n\n\tfor (i = 1; i < num_pages && INLINE_EXTENT_BUFFER_PAGES > 1; i++) {\n\t\tkaddr = page_address(buf->pages[i]);\n\t\tcrypto_shash_update(shash, kaddr, PAGE_SIZE);\n\t}\n\tmemset(result, 0, BTRFS_CSUM_SIZE);\n\tcrypto_shash_final(shash, result);\n}\n\n \nint btrfs_buffer_uptodate(struct extent_buffer *eb, u64 parent_transid, int atomic)\n{\n\tif (!extent_buffer_uptodate(eb))\n\t\treturn 0;\n\n\tif (!parent_transid || btrfs_header_generation(eb) == parent_transid)\n\t\treturn 1;\n\n\tif (atomic)\n\t\treturn -EAGAIN;\n\n\tif (!extent_buffer_uptodate(eb) ||\n\t    btrfs_header_generation(eb) != parent_transid) {\n\t\tbtrfs_err_rl(eb->fs_info,\n\"parent transid verify failed on logical %llu mirror %u wanted %llu found %llu\",\n\t\t\teb->start, eb->read_mirror,\n\t\t\tparent_transid, btrfs_header_generation(eb));\n\t\tclear_extent_buffer_uptodate(eb);\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic bool btrfs_supported_super_csum(u16 csum_type)\n{\n\tswitch (csum_type) {\n\tcase BTRFS_CSUM_TYPE_CRC32:\n\tcase BTRFS_CSUM_TYPE_XXHASH:\n\tcase BTRFS_CSUM_TYPE_SHA256:\n\tcase BTRFS_CSUM_TYPE_BLAKE2:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \nint btrfs_check_super_csum(struct btrfs_fs_info *fs_info,\n\t\t\t   const struct btrfs_super_block *disk_sb)\n{\n\tchar result[BTRFS_CSUM_SIZE];\n\tSHASH_DESC_ON_STACK(shash, fs_info->csum_shash);\n\n\tshash->tfm = fs_info->csum_shash;\n\n\t \n\tcrypto_shash_digest(shash, (const u8 *)disk_sb + BTRFS_CSUM_SIZE,\n\t\t\t    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE, result);\n\n\tif (memcmp(disk_sb->csum, result, fs_info->csum_size))\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic int btrfs_repair_eb_io_failure(const struct extent_buffer *eb,\n\t\t\t\t      int mirror_num)\n{\n\tstruct btrfs_fs_info *fs_info = eb->fs_info;\n\tint i, num_pages = num_extent_pages(eb);\n\tint ret = 0;\n\n\tif (sb_rdonly(fs_info->sb))\n\t\treturn -EROFS;\n\n\tfor (i = 0; i < num_pages; i++) {\n\t\tstruct page *p = eb->pages[i];\n\t\tu64 start = max_t(u64, eb->start, page_offset(p));\n\t\tu64 end = min_t(u64, eb->start + eb->len, page_offset(p) + PAGE_SIZE);\n\t\tu32 len = end - start;\n\n\t\tret = btrfs_repair_io_failure(fs_info, 0, start, len,\n\t\t\t\tstart, p, offset_in_page(start), mirror_num);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n \nint btrfs_read_extent_buffer(struct extent_buffer *eb,\n\t\t\t     struct btrfs_tree_parent_check *check)\n{\n\tstruct btrfs_fs_info *fs_info = eb->fs_info;\n\tint failed = 0;\n\tint ret;\n\tint num_copies = 0;\n\tint mirror_num = 0;\n\tint failed_mirror = 0;\n\n\tASSERT(check);\n\n\twhile (1) {\n\t\tclear_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);\n\t\tret = read_extent_buffer_pages(eb, WAIT_COMPLETE, mirror_num, check);\n\t\tif (!ret)\n\t\t\tbreak;\n\n\t\tnum_copies = btrfs_num_copies(fs_info,\n\t\t\t\t\t      eb->start, eb->len);\n\t\tif (num_copies == 1)\n\t\t\tbreak;\n\n\t\tif (!failed_mirror) {\n\t\t\tfailed = 1;\n\t\t\tfailed_mirror = eb->read_mirror;\n\t\t}\n\n\t\tmirror_num++;\n\t\tif (mirror_num == failed_mirror)\n\t\t\tmirror_num++;\n\n\t\tif (mirror_num > num_copies)\n\t\t\tbreak;\n\t}\n\n\tif (failed && !ret && failed_mirror)\n\t\tbtrfs_repair_eb_io_failure(eb, failed_mirror);\n\n\treturn ret;\n}\n\n \nblk_status_t btree_csum_one_bio(struct btrfs_bio *bbio)\n{\n\tstruct extent_buffer *eb = bbio->private;\n\tstruct btrfs_fs_info *fs_info = eb->fs_info;\n\tu64 found_start = btrfs_header_bytenr(eb);\n\tu8 result[BTRFS_CSUM_SIZE];\n\tint ret;\n\n\t \n\tif (WARN_ON_ONCE(bbio->file_offset != eb->start))\n\t\treturn BLK_STS_IOERR;\n\tif (WARN_ON_ONCE(bbio->bio.bi_iter.bi_size != eb->len))\n\t\treturn BLK_STS_IOERR;\n\n\tif (test_bit(EXTENT_BUFFER_NO_CHECK, &eb->bflags)) {\n\t\tWARN_ON_ONCE(found_start != 0);\n\t\treturn BLK_STS_OK;\n\t}\n\n\tif (WARN_ON_ONCE(found_start != eb->start))\n\t\treturn BLK_STS_IOERR;\n\tif (WARN_ON(!btrfs_page_test_uptodate(fs_info, eb->pages[0], eb->start,\n\t\t\t\t\t      eb->len)))\n\t\treturn BLK_STS_IOERR;\n\n\tASSERT(memcmp_extent_buffer(eb, fs_info->fs_devices->metadata_uuid,\n\t\t\t\t    offsetof(struct btrfs_header, fsid),\n\t\t\t\t    BTRFS_FSID_SIZE) == 0);\n\tcsum_tree_block(eb, result);\n\n\tif (btrfs_header_level(eb))\n\t\tret = btrfs_check_node(eb);\n\telse\n\t\tret = btrfs_check_leaf(eb);\n\n\tif (ret < 0)\n\t\tgoto error;\n\n\t \n\tif (unlikely(btrfs_header_generation(eb) <= fs_info->last_trans_committed)) {\n\t\tret = -EUCLEAN;\n\t\tbtrfs_err(fs_info,\n\t\t\t\"block=%llu bad generation, have %llu expect > %llu\",\n\t\t\t  eb->start, btrfs_header_generation(eb),\n\t\t\t  fs_info->last_trans_committed);\n\t\tgoto error;\n\t}\n\twrite_extent_buffer(eb, result, 0, fs_info->csum_size);\n\treturn BLK_STS_OK;\n\nerror:\n\tbtrfs_print_tree(eb, 0);\n\tbtrfs_err(fs_info, \"block=%llu write time tree block corruption detected\",\n\t\t  eb->start);\n\t \n\tWARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG) ||\n\t\tbtrfs_header_owner(eb) == BTRFS_TREE_LOG_OBJECTID);\n\treturn errno_to_blk_status(ret);\n}\n\nstatic bool check_tree_block_fsid(struct extent_buffer *eb)\n{\n\tstruct btrfs_fs_info *fs_info = eb->fs_info;\n\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices, *seed_devs;\n\tu8 fsid[BTRFS_FSID_SIZE];\n\n\tread_extent_buffer(eb, fsid, offsetof(struct btrfs_header, fsid),\n\t\t\t   BTRFS_FSID_SIZE);\n\n\t \n\tif (memcmp(fsid, fs_info->fs_devices->metadata_uuid, BTRFS_FSID_SIZE) == 0)\n\t\treturn false;\n\n\tlist_for_each_entry(seed_devs, &fs_devices->seed_list, seed_list)\n\t\tif (!memcmp(fsid, seed_devs->fsid, BTRFS_FSID_SIZE))\n\t\t\treturn false;\n\n\treturn true;\n}\n\n \nint btrfs_validate_extent_buffer(struct extent_buffer *eb,\n\t\t\t\t struct btrfs_tree_parent_check *check)\n{\n\tstruct btrfs_fs_info *fs_info = eb->fs_info;\n\tu64 found_start;\n\tconst u32 csum_size = fs_info->csum_size;\n\tu8 found_level;\n\tu8 result[BTRFS_CSUM_SIZE];\n\tconst u8 *header_csum;\n\tint ret = 0;\n\n\tASSERT(check);\n\n\tfound_start = btrfs_header_bytenr(eb);\n\tif (found_start != eb->start) {\n\t\tbtrfs_err_rl(fs_info,\n\t\t\t\"bad tree block start, mirror %u want %llu have %llu\",\n\t\t\t     eb->read_mirror, eb->start, found_start);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tif (check_tree_block_fsid(eb)) {\n\t\tbtrfs_err_rl(fs_info, \"bad fsid on logical %llu mirror %u\",\n\t\t\t     eb->start, eb->read_mirror);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tfound_level = btrfs_header_level(eb);\n\tif (found_level >= BTRFS_MAX_LEVEL) {\n\t\tbtrfs_err(fs_info,\n\t\t\t\"bad tree block level, mirror %u level %d on logical %llu\",\n\t\t\teb->read_mirror, btrfs_header_level(eb), eb->start);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tcsum_tree_block(eb, result);\n\theader_csum = page_address(eb->pages[0]) +\n\t\tget_eb_offset_in_page(eb, offsetof(struct btrfs_header, csum));\n\n\tif (memcmp(result, header_csum, csum_size) != 0) {\n\t\tbtrfs_warn_rl(fs_info,\n\"checksum verify failed on logical %llu mirror %u wanted \" CSUM_FMT \" found \" CSUM_FMT \" level %d\",\n\t\t\t      eb->start, eb->read_mirror,\n\t\t\t      CSUM_FMT_VALUE(csum_size, header_csum),\n\t\t\t      CSUM_FMT_VALUE(csum_size, result),\n\t\t\t      btrfs_header_level(eb));\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\tif (found_level != check->level) {\n\t\tbtrfs_err(fs_info,\n\t\t\"level verify failed on logical %llu mirror %u wanted %u found %u\",\n\t\t\t  eb->start, eb->read_mirror, check->level, found_level);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tif (unlikely(check->transid &&\n\t\t     btrfs_header_generation(eb) != check->transid)) {\n\t\tbtrfs_err_rl(eb->fs_info,\n\"parent transid verify failed on logical %llu mirror %u wanted %llu found %llu\",\n\t\t\t\teb->start, eb->read_mirror, check->transid,\n\t\t\t\tbtrfs_header_generation(eb));\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tif (check->has_first_key) {\n\t\tstruct btrfs_key *expect_key = &check->first_key;\n\t\tstruct btrfs_key found_key;\n\n\t\tif (found_level)\n\t\t\tbtrfs_node_key_to_cpu(eb, &found_key, 0);\n\t\telse\n\t\t\tbtrfs_item_key_to_cpu(eb, &found_key, 0);\n\t\tif (unlikely(btrfs_comp_cpu_keys(expect_key, &found_key))) {\n\t\t\tbtrfs_err(fs_info,\n\"tree first key mismatch detected, bytenr=%llu parent_transid=%llu key expected=(%llu,%u,%llu) has=(%llu,%u,%llu)\",\n\t\t\t\t  eb->start, check->transid,\n\t\t\t\t  expect_key->objectid,\n\t\t\t\t  expect_key->type, expect_key->offset,\n\t\t\t\t  found_key.objectid, found_key.type,\n\t\t\t\t  found_key.offset);\n\t\t\tret = -EUCLEAN;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif (check->owner_root) {\n\t\tret = btrfs_check_eb_owner(eb, check->owner_root);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\n\n\t \n\tif (found_level == 0 && btrfs_check_leaf(eb)) {\n\t\tset_bit(EXTENT_BUFFER_CORRUPT, &eb->bflags);\n\t\tret = -EIO;\n\t}\n\n\tif (found_level > 0 && btrfs_check_node(eb))\n\t\tret = -EIO;\n\n\tif (ret)\n\t\tbtrfs_err(fs_info,\n\t\t\"read time tree block corruption detected on logical %llu mirror %u\",\n\t\t\t  eb->start, eb->read_mirror);\nout:\n\treturn ret;\n}\n\n#ifdef CONFIG_MIGRATION\nstatic int btree_migrate_folio(struct address_space *mapping,\n\t\tstruct folio *dst, struct folio *src, enum migrate_mode mode)\n{\n\t \n\tif (folio_test_dirty(src))\n\t\treturn -EAGAIN;\n\t \n\tif (folio_get_private(src) &&\n\t    !filemap_release_folio(src, GFP_KERNEL))\n\t\treturn -EAGAIN;\n\treturn migrate_folio(mapping, dst, src, mode);\n}\n#else\n#define btree_migrate_folio NULL\n#endif\n\nstatic int btree_writepages(struct address_space *mapping,\n\t\t\t    struct writeback_control *wbc)\n{\n\tstruct btrfs_fs_info *fs_info;\n\tint ret;\n\n\tif (wbc->sync_mode == WB_SYNC_NONE) {\n\n\t\tif (wbc->for_kupdate)\n\t\t\treturn 0;\n\n\t\tfs_info = BTRFS_I(mapping->host)->root->fs_info;\n\t\t \n\t\tret = __percpu_counter_compare(&fs_info->dirty_metadata_bytes,\n\t\t\t\t\t     BTRFS_DIRTY_METADATA_THRESH,\n\t\t\t\t\t     fs_info->dirty_metadata_batch);\n\t\tif (ret < 0)\n\t\t\treturn 0;\n\t}\n\treturn btree_write_cache_pages(mapping, wbc);\n}\n\nstatic bool btree_release_folio(struct folio *folio, gfp_t gfp_flags)\n{\n\tif (folio_test_writeback(folio) || folio_test_dirty(folio))\n\t\treturn false;\n\n\treturn try_release_extent_buffer(&folio->page);\n}\n\nstatic void btree_invalidate_folio(struct folio *folio, size_t offset,\n\t\t\t\t size_t length)\n{\n\tstruct extent_io_tree *tree;\n\ttree = &BTRFS_I(folio->mapping->host)->io_tree;\n\textent_invalidate_folio(tree, folio, offset);\n\tbtree_release_folio(folio, GFP_NOFS);\n\tif (folio_get_private(folio)) {\n\t\tbtrfs_warn(BTRFS_I(folio->mapping->host)->root->fs_info,\n\t\t\t   \"folio private not zero on folio %llu\",\n\t\t\t   (unsigned long long)folio_pos(folio));\n\t\tfolio_detach_private(folio);\n\t}\n}\n\n#ifdef DEBUG\nstatic bool btree_dirty_folio(struct address_space *mapping,\n\t\tstruct folio *folio)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(mapping->host->i_sb);\n\tstruct btrfs_subpage_info *spi = fs_info->subpage_info;\n\tstruct btrfs_subpage *subpage;\n\tstruct extent_buffer *eb;\n\tint cur_bit = 0;\n\tu64 page_start = folio_pos(folio);\n\n\tif (fs_info->sectorsize == PAGE_SIZE) {\n\t\teb = folio_get_private(folio);\n\t\tBUG_ON(!eb);\n\t\tBUG_ON(!test_bit(EXTENT_BUFFER_DIRTY, &eb->bflags));\n\t\tBUG_ON(!atomic_read(&eb->refs));\n\t\tbtrfs_assert_tree_write_locked(eb);\n\t\treturn filemap_dirty_folio(mapping, folio);\n\t}\n\n\tASSERT(spi);\n\tsubpage = folio_get_private(folio);\n\n\tfor (cur_bit = spi->dirty_offset;\n\t     cur_bit < spi->dirty_offset + spi->bitmap_nr_bits;\n\t     cur_bit++) {\n\t\tunsigned long flags;\n\t\tu64 cur;\n\n\t\tspin_lock_irqsave(&subpage->lock, flags);\n\t\tif (!test_bit(cur_bit, subpage->bitmaps)) {\n\t\t\tspin_unlock_irqrestore(&subpage->lock, flags);\n\t\t\tcontinue;\n\t\t}\n\t\tspin_unlock_irqrestore(&subpage->lock, flags);\n\t\tcur = page_start + cur_bit * fs_info->sectorsize;\n\n\t\teb = find_extent_buffer(fs_info, cur);\n\t\tASSERT(eb);\n\t\tASSERT(test_bit(EXTENT_BUFFER_DIRTY, &eb->bflags));\n\t\tASSERT(atomic_read(&eb->refs));\n\t\tbtrfs_assert_tree_write_locked(eb);\n\t\tfree_extent_buffer(eb);\n\n\t\tcur_bit += (fs_info->nodesize >> fs_info->sectorsize_bits) - 1;\n\t}\n\treturn filemap_dirty_folio(mapping, folio);\n}\n#else\n#define btree_dirty_folio filemap_dirty_folio\n#endif\n\nstatic const struct address_space_operations btree_aops = {\n\t.writepages\t= btree_writepages,\n\t.release_folio\t= btree_release_folio,\n\t.invalidate_folio = btree_invalidate_folio,\n\t.migrate_folio\t= btree_migrate_folio,\n\t.dirty_folio\t= btree_dirty_folio,\n};\n\nstruct extent_buffer *btrfs_find_create_tree_block(\n\t\t\t\t\t\tstruct btrfs_fs_info *fs_info,\n\t\t\t\t\t\tu64 bytenr, u64 owner_root,\n\t\t\t\t\t\tint level)\n{\n\tif (btrfs_is_testing(fs_info))\n\t\treturn alloc_test_extent_buffer(fs_info, bytenr);\n\treturn alloc_extent_buffer(fs_info, bytenr, owner_root, level);\n}\n\n \nstruct extent_buffer *read_tree_block(struct btrfs_fs_info *fs_info, u64 bytenr,\n\t\t\t\t      struct btrfs_tree_parent_check *check)\n{\n\tstruct extent_buffer *buf = NULL;\n\tint ret;\n\n\tASSERT(check);\n\n\tbuf = btrfs_find_create_tree_block(fs_info, bytenr, check->owner_root,\n\t\t\t\t\t   check->level);\n\tif (IS_ERR(buf))\n\t\treturn buf;\n\n\tret = btrfs_read_extent_buffer(buf, check);\n\tif (ret) {\n\t\tfree_extent_buffer_stale(buf);\n\t\treturn ERR_PTR(ret);\n\t}\n\tif (btrfs_check_eb_owner(buf, check->owner_root)) {\n\t\tfree_extent_buffer_stale(buf);\n\t\treturn ERR_PTR(-EUCLEAN);\n\t}\n\treturn buf;\n\n}\n\nstatic void __setup_root(struct btrfs_root *root, struct btrfs_fs_info *fs_info,\n\t\t\t u64 objectid)\n{\n\tbool dummy = test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO, &fs_info->fs_state);\n\n\tmemset(&root->root_key, 0, sizeof(root->root_key));\n\tmemset(&root->root_item, 0, sizeof(root->root_item));\n\tmemset(&root->defrag_progress, 0, sizeof(root->defrag_progress));\n\troot->fs_info = fs_info;\n\troot->root_key.objectid = objectid;\n\troot->node = NULL;\n\troot->commit_root = NULL;\n\troot->state = 0;\n\tRB_CLEAR_NODE(&root->rb_node);\n\n\troot->last_trans = 0;\n\troot->free_objectid = 0;\n\troot->nr_delalloc_inodes = 0;\n\troot->nr_ordered_extents = 0;\n\troot->inode_tree = RB_ROOT;\n\tINIT_RADIX_TREE(&root->delayed_nodes_tree, GFP_ATOMIC);\n\n\tbtrfs_init_root_block_rsv(root);\n\n\tINIT_LIST_HEAD(&root->dirty_list);\n\tINIT_LIST_HEAD(&root->root_list);\n\tINIT_LIST_HEAD(&root->delalloc_inodes);\n\tINIT_LIST_HEAD(&root->delalloc_root);\n\tINIT_LIST_HEAD(&root->ordered_extents);\n\tINIT_LIST_HEAD(&root->ordered_root);\n\tINIT_LIST_HEAD(&root->reloc_dirty_list);\n\tINIT_LIST_HEAD(&root->logged_list[0]);\n\tINIT_LIST_HEAD(&root->logged_list[1]);\n\tspin_lock_init(&root->inode_lock);\n\tspin_lock_init(&root->delalloc_lock);\n\tspin_lock_init(&root->ordered_extent_lock);\n\tspin_lock_init(&root->accounting_lock);\n\tspin_lock_init(&root->log_extents_lock[0]);\n\tspin_lock_init(&root->log_extents_lock[1]);\n\tspin_lock_init(&root->qgroup_meta_rsv_lock);\n\tmutex_init(&root->objectid_mutex);\n\tmutex_init(&root->log_mutex);\n\tmutex_init(&root->ordered_extent_mutex);\n\tmutex_init(&root->delalloc_mutex);\n\tinit_waitqueue_head(&root->qgroup_flush_wait);\n\tinit_waitqueue_head(&root->log_writer_wait);\n\tinit_waitqueue_head(&root->log_commit_wait[0]);\n\tinit_waitqueue_head(&root->log_commit_wait[1]);\n\tINIT_LIST_HEAD(&root->log_ctxs[0]);\n\tINIT_LIST_HEAD(&root->log_ctxs[1]);\n\tatomic_set(&root->log_commit[0], 0);\n\tatomic_set(&root->log_commit[1], 0);\n\tatomic_set(&root->log_writers, 0);\n\tatomic_set(&root->log_batch, 0);\n\trefcount_set(&root->refs, 1);\n\tatomic_set(&root->snapshot_force_cow, 0);\n\tatomic_set(&root->nr_swapfiles, 0);\n\troot->log_transid = 0;\n\troot->log_transid_committed = -1;\n\troot->last_log_commit = 0;\n\troot->anon_dev = 0;\n\tif (!dummy) {\n\t\textent_io_tree_init(fs_info, &root->dirty_log_pages,\n\t\t\t\t    IO_TREE_ROOT_DIRTY_LOG_PAGES);\n\t\textent_io_tree_init(fs_info, &root->log_csum_range,\n\t\t\t\t    IO_TREE_LOG_CSUM_RANGE);\n\t}\n\n\tspin_lock_init(&root->root_item_lock);\n\tbtrfs_qgroup_init_swapped_blocks(&root->swapped_blocks);\n#ifdef CONFIG_BTRFS_DEBUG\n\tINIT_LIST_HEAD(&root->leak_list);\n\tspin_lock(&fs_info->fs_roots_radix_lock);\n\tlist_add_tail(&root->leak_list, &fs_info->allocated_roots);\n\tspin_unlock(&fs_info->fs_roots_radix_lock);\n#endif\n}\n\nstatic struct btrfs_root *btrfs_alloc_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t   u64 objectid, gfp_t flags)\n{\n\tstruct btrfs_root *root = kzalloc(sizeof(*root), flags);\n\tif (root)\n\t\t__setup_root(root, fs_info, objectid);\n\treturn root;\n}\n\n#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\n \nstruct btrfs_root *btrfs_alloc_dummy_root(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root;\n\n\tif (!fs_info)\n\t\treturn ERR_PTR(-EINVAL);\n\n\troot = btrfs_alloc_root(fs_info, BTRFS_ROOT_TREE_OBJECTID, GFP_KERNEL);\n\tif (!root)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t \n\troot->alloc_bytenr = 0;\n\n\treturn root;\n}\n#endif\n\nstatic int global_root_cmp(struct rb_node *a_node, const struct rb_node *b_node)\n{\n\tconst struct btrfs_root *a = rb_entry(a_node, struct btrfs_root, rb_node);\n\tconst struct btrfs_root *b = rb_entry(b_node, struct btrfs_root, rb_node);\n\n\treturn btrfs_comp_cpu_keys(&a->root_key, &b->root_key);\n}\n\nstatic int global_root_key_cmp(const void *k, const struct rb_node *node)\n{\n\tconst struct btrfs_key *key = k;\n\tconst struct btrfs_root *root = rb_entry(node, struct btrfs_root, rb_node);\n\n\treturn btrfs_comp_cpu_keys(key, &root->root_key);\n}\n\nint btrfs_global_root_insert(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct rb_node *tmp;\n\tint ret = 0;\n\n\twrite_lock(&fs_info->global_root_lock);\n\ttmp = rb_find_add(&root->rb_node, &fs_info->global_root_tree, global_root_cmp);\n\twrite_unlock(&fs_info->global_root_lock);\n\n\tif (tmp) {\n\t\tret = -EEXIST;\n\t\tbtrfs_warn(fs_info, \"global root %llu %llu already exists\",\n\t\t\t\troot->root_key.objectid, root->root_key.offset);\n\t}\n\treturn ret;\n}\n\nvoid btrfs_global_root_delete(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\n\twrite_lock(&fs_info->global_root_lock);\n\trb_erase(&root->rb_node, &fs_info->global_root_tree);\n\twrite_unlock(&fs_info->global_root_lock);\n}\n\nstruct btrfs_root *btrfs_global_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t     struct btrfs_key *key)\n{\n\tstruct rb_node *node;\n\tstruct btrfs_root *root = NULL;\n\n\tread_lock(&fs_info->global_root_lock);\n\tnode = rb_find(key, &fs_info->global_root_tree, global_root_key_cmp);\n\tif (node)\n\t\troot = container_of(node, struct btrfs_root, rb_node);\n\tread_unlock(&fs_info->global_root_lock);\n\n\treturn root;\n}\n\nstatic u64 btrfs_global_root_id(struct btrfs_fs_info *fs_info, u64 bytenr)\n{\n\tstruct btrfs_block_group *block_group;\n\tu64 ret;\n\n\tif (!btrfs_fs_incompat(fs_info, EXTENT_TREE_V2))\n\t\treturn 0;\n\n\tif (bytenr)\n\t\tblock_group = btrfs_lookup_block_group(fs_info, bytenr);\n\telse\n\t\tblock_group = btrfs_lookup_first_block_group(fs_info, bytenr);\n\tASSERT(block_group);\n\tif (!block_group)\n\t\treturn 0;\n\tret = block_group->global_root_id;\n\tbtrfs_put_block_group(block_group);\n\n\treturn ret;\n}\n\nstruct btrfs_root *btrfs_csum_root(struct btrfs_fs_info *fs_info, u64 bytenr)\n{\n\tstruct btrfs_key key = {\n\t\t.objectid = BTRFS_CSUM_TREE_OBJECTID,\n\t\t.type = BTRFS_ROOT_ITEM_KEY,\n\t\t.offset = btrfs_global_root_id(fs_info, bytenr),\n\t};\n\n\treturn btrfs_global_root(fs_info, &key);\n}\n\nstruct btrfs_root *btrfs_extent_root(struct btrfs_fs_info *fs_info, u64 bytenr)\n{\n\tstruct btrfs_key key = {\n\t\t.objectid = BTRFS_EXTENT_TREE_OBJECTID,\n\t\t.type = BTRFS_ROOT_ITEM_KEY,\n\t\t.offset = btrfs_global_root_id(fs_info, bytenr),\n\t};\n\n\treturn btrfs_global_root(fs_info, &key);\n}\n\nstruct btrfs_root *btrfs_block_group_root(struct btrfs_fs_info *fs_info)\n{\n\tif (btrfs_fs_compat_ro(fs_info, BLOCK_GROUP_TREE))\n\t\treturn fs_info->block_group_root;\n\treturn btrfs_extent_root(fs_info, 0);\n}\n\nstruct btrfs_root *btrfs_create_tree(struct btrfs_trans_handle *trans,\n\t\t\t\t     u64 objectid)\n{\n\tstruct btrfs_fs_info *fs_info = trans->fs_info;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_root *tree_root = fs_info->tree_root;\n\tstruct btrfs_root *root;\n\tstruct btrfs_key key;\n\tunsigned int nofs_flag;\n\tint ret = 0;\n\n\t \n\tnofs_flag = memalloc_nofs_save();\n\troot = btrfs_alloc_root(fs_info, objectid, GFP_KERNEL);\n\tmemalloc_nofs_restore(nofs_flag);\n\tif (!root)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\troot->root_key.objectid = objectid;\n\troot->root_key.type = BTRFS_ROOT_ITEM_KEY;\n\troot->root_key.offset = 0;\n\n\tleaf = btrfs_alloc_tree_block(trans, root, 0, objectid, NULL, 0, 0, 0,\n\t\t\t\t      BTRFS_NESTING_NORMAL);\n\tif (IS_ERR(leaf)) {\n\t\tret = PTR_ERR(leaf);\n\t\tleaf = NULL;\n\t\tgoto fail;\n\t}\n\n\troot->node = leaf;\n\tbtrfs_mark_buffer_dirty(trans, leaf);\n\n\troot->commit_root = btrfs_root_node(root);\n\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n\n\tbtrfs_set_root_flags(&root->root_item, 0);\n\tbtrfs_set_root_limit(&root->root_item, 0);\n\tbtrfs_set_root_bytenr(&root->root_item, leaf->start);\n\tbtrfs_set_root_generation(&root->root_item, trans->transid);\n\tbtrfs_set_root_level(&root->root_item, 0);\n\tbtrfs_set_root_refs(&root->root_item, 1);\n\tbtrfs_set_root_used(&root->root_item, leaf->len);\n\tbtrfs_set_root_last_snapshot(&root->root_item, 0);\n\tbtrfs_set_root_dirid(&root->root_item, 0);\n\tif (is_fstree(objectid))\n\t\tgenerate_random_guid(root->root_item.uuid);\n\telse\n\t\texport_guid(root->root_item.uuid, &guid_null);\n\tbtrfs_set_root_drop_level(&root->root_item, 0);\n\n\tbtrfs_tree_unlock(leaf);\n\n\tkey.objectid = objectid;\n\tkey.type = BTRFS_ROOT_ITEM_KEY;\n\tkey.offset = 0;\n\tret = btrfs_insert_root(trans, tree_root, &key, &root->root_item);\n\tif (ret)\n\t\tgoto fail;\n\n\treturn root;\n\nfail:\n\tbtrfs_put_root(root);\n\n\treturn ERR_PTR(ret);\n}\n\nstatic struct btrfs_root *alloc_log_tree(struct btrfs_trans_handle *trans,\n\t\t\t\t\t struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root;\n\n\troot = btrfs_alloc_root(fs_info, BTRFS_TREE_LOG_OBJECTID, GFP_NOFS);\n\tif (!root)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\troot->root_key.objectid = BTRFS_TREE_LOG_OBJECTID;\n\troot->root_key.type = BTRFS_ROOT_ITEM_KEY;\n\troot->root_key.offset = BTRFS_TREE_LOG_OBJECTID;\n\n\treturn root;\n}\n\nint btrfs_alloc_log_tree_node(struct btrfs_trans_handle *trans,\n\t\t\t      struct btrfs_root *root)\n{\n\tstruct extent_buffer *leaf;\n\n\t \n\n\tleaf = btrfs_alloc_tree_block(trans, root, 0, BTRFS_TREE_LOG_OBJECTID,\n\t\t\tNULL, 0, 0, 0, BTRFS_NESTING_NORMAL);\n\tif (IS_ERR(leaf))\n\t\treturn PTR_ERR(leaf);\n\n\troot->node = leaf;\n\n\tbtrfs_mark_buffer_dirty(trans, root->node);\n\tbtrfs_tree_unlock(root->node);\n\n\treturn 0;\n}\n\nint btrfs_init_log_root_tree(struct btrfs_trans_handle *trans,\n\t\t\t     struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *log_root;\n\n\tlog_root = alloc_log_tree(trans, fs_info);\n\tif (IS_ERR(log_root))\n\t\treturn PTR_ERR(log_root);\n\n\tif (!btrfs_is_zoned(fs_info)) {\n\t\tint ret = btrfs_alloc_log_tree_node(trans, log_root);\n\n\t\tif (ret) {\n\t\t\tbtrfs_put_root(log_root);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tWARN_ON(fs_info->log_root_tree);\n\tfs_info->log_root_tree = log_root;\n\treturn 0;\n}\n\nint btrfs_add_log_tree(struct btrfs_trans_handle *trans,\n\t\t       struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_root *log_root;\n\tstruct btrfs_inode_item *inode_item;\n\tint ret;\n\n\tlog_root = alloc_log_tree(trans, fs_info);\n\tif (IS_ERR(log_root))\n\t\treturn PTR_ERR(log_root);\n\n\tret = btrfs_alloc_log_tree_node(trans, log_root);\n\tif (ret) {\n\t\tbtrfs_put_root(log_root);\n\t\treturn ret;\n\t}\n\n\tlog_root->last_trans = trans->transid;\n\tlog_root->root_key.offset = root->root_key.objectid;\n\n\tinode_item = &log_root->root_item.inode;\n\tbtrfs_set_stack_inode_generation(inode_item, 1);\n\tbtrfs_set_stack_inode_size(inode_item, 3);\n\tbtrfs_set_stack_inode_nlink(inode_item, 1);\n\tbtrfs_set_stack_inode_nbytes(inode_item,\n\t\t\t\t     fs_info->nodesize);\n\tbtrfs_set_stack_inode_mode(inode_item, S_IFDIR | 0755);\n\n\tbtrfs_set_root_node(&log_root->root_item, log_root->node);\n\n\tWARN_ON(root->log_root);\n\troot->log_root = log_root;\n\troot->log_transid = 0;\n\troot->log_transid_committed = -1;\n\troot->last_log_commit = 0;\n\treturn 0;\n}\n\nstatic struct btrfs_root *read_tree_root_path(struct btrfs_root *tree_root,\n\t\t\t\t\t      struct btrfs_path *path,\n\t\t\t\t\t      struct btrfs_key *key)\n{\n\tstruct btrfs_root *root;\n\tstruct btrfs_tree_parent_check check = { 0 };\n\tstruct btrfs_fs_info *fs_info = tree_root->fs_info;\n\tu64 generation;\n\tint ret;\n\tint level;\n\n\troot = btrfs_alloc_root(fs_info, key->objectid, GFP_NOFS);\n\tif (!root)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = btrfs_find_root(tree_root, key, path,\n\t\t\t      &root->root_item, &root->root_key);\n\tif (ret) {\n\t\tif (ret > 0)\n\t\t\tret = -ENOENT;\n\t\tgoto fail;\n\t}\n\n\tgeneration = btrfs_root_generation(&root->root_item);\n\tlevel = btrfs_root_level(&root->root_item);\n\tcheck.level = level;\n\tcheck.transid = generation;\n\tcheck.owner_root = key->objectid;\n\troot->node = read_tree_block(fs_info, btrfs_root_bytenr(&root->root_item),\n\t\t\t\t     &check);\n\tif (IS_ERR(root->node)) {\n\t\tret = PTR_ERR(root->node);\n\t\troot->node = NULL;\n\t\tgoto fail;\n\t}\n\tif (!btrfs_buffer_uptodate(root->node, generation, 0)) {\n\t\tret = -EIO;\n\t\tgoto fail;\n\t}\n\n\t \n\tif (!test_bit(BTRFS_FS_STATE_DUMMY_FS_INFO, &fs_info->fs_state) &&\n\t    root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID &&\n\t    root->root_key.objectid != BTRFS_TREE_RELOC_OBJECTID &&\n\t    root->root_key.objectid != btrfs_header_owner(root->node)) {\n\t\tbtrfs_crit(fs_info,\n\"root=%llu block=%llu, tree root owner mismatch, have %llu expect %llu\",\n\t\t\t   root->root_key.objectid, root->node->start,\n\t\t\t   btrfs_header_owner(root->node),\n\t\t\t   root->root_key.objectid);\n\t\tret = -EUCLEAN;\n\t\tgoto fail;\n\t}\n\troot->commit_root = btrfs_root_node(root);\n\treturn root;\nfail:\n\tbtrfs_put_root(root);\n\treturn ERR_PTR(ret);\n}\n\nstruct btrfs_root *btrfs_read_tree_root(struct btrfs_root *tree_root,\n\t\t\t\t\tstruct btrfs_key *key)\n{\n\tstruct btrfs_root *root;\n\tstruct btrfs_path *path;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn ERR_PTR(-ENOMEM);\n\troot = read_tree_root_path(tree_root, path, key);\n\tbtrfs_free_path(path);\n\n\treturn root;\n}\n\n \nstatic int btrfs_init_fs_root(struct btrfs_root *root, dev_t anon_dev)\n{\n\tint ret;\n\n\tbtrfs_drew_lock_init(&root->snapshot_lock);\n\n\tif (root->root_key.objectid != BTRFS_TREE_LOG_OBJECTID &&\n\t    !btrfs_is_data_reloc_root(root) &&\n\t    is_fstree(root->root_key.objectid)) {\n\t\tset_bit(BTRFS_ROOT_SHAREABLE, &root->state);\n\t\tbtrfs_check_and_init_root_item(&root->root_item);\n\t}\n\n\t \n\tif (is_fstree(root->root_key.objectid) &&\n\t    btrfs_root_refs(&root->root_item) > 0) {\n\t\tif (!anon_dev) {\n\t\t\tret = get_anon_bdev(&root->anon_dev);\n\t\t\tif (ret)\n\t\t\t\tgoto fail;\n\t\t} else {\n\t\t\troot->anon_dev = anon_dev;\n\t\t}\n\t}\n\n\tmutex_lock(&root->objectid_mutex);\n\tret = btrfs_init_root_free_objectid(root);\n\tif (ret) {\n\t\tmutex_unlock(&root->objectid_mutex);\n\t\tgoto fail;\n\t}\n\n\tASSERT(root->free_objectid <= BTRFS_LAST_FREE_OBJECTID);\n\n\tmutex_unlock(&root->objectid_mutex);\n\n\treturn 0;\nfail:\n\t \n\treturn ret;\n}\n\nstatic struct btrfs_root *btrfs_lookup_fs_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t       u64 root_id)\n{\n\tstruct btrfs_root *root;\n\n\tspin_lock(&fs_info->fs_roots_radix_lock);\n\troot = radix_tree_lookup(&fs_info->fs_roots_radix,\n\t\t\t\t (unsigned long)root_id);\n\troot = btrfs_grab_root(root);\n\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\treturn root;\n}\n\nstatic struct btrfs_root *btrfs_get_global_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t\tu64 objectid)\n{\n\tstruct btrfs_key key = {\n\t\t.objectid = objectid,\n\t\t.type = BTRFS_ROOT_ITEM_KEY,\n\t\t.offset = 0,\n\t};\n\n\tswitch (objectid) {\n\tcase BTRFS_ROOT_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(fs_info->tree_root);\n\tcase BTRFS_EXTENT_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(btrfs_global_root(fs_info, &key));\n\tcase BTRFS_CHUNK_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(fs_info->chunk_root);\n\tcase BTRFS_DEV_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(fs_info->dev_root);\n\tcase BTRFS_CSUM_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(btrfs_global_root(fs_info, &key));\n\tcase BTRFS_QUOTA_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(fs_info->quota_root);\n\tcase BTRFS_UUID_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(fs_info->uuid_root);\n\tcase BTRFS_BLOCK_GROUP_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(fs_info->block_group_root);\n\tcase BTRFS_FREE_SPACE_TREE_OBJECTID:\n\t\treturn btrfs_grab_root(btrfs_global_root(fs_info, &key));\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nint btrfs_insert_fs_root(struct btrfs_fs_info *fs_info,\n\t\t\t struct btrfs_root *root)\n{\n\tint ret;\n\n\tret = radix_tree_preload(GFP_NOFS);\n\tif (ret)\n\t\treturn ret;\n\n\tspin_lock(&fs_info->fs_roots_radix_lock);\n\tret = radix_tree_insert(&fs_info->fs_roots_radix,\n\t\t\t\t(unsigned long)root->root_key.objectid,\n\t\t\t\troot);\n\tif (ret == 0) {\n\t\tbtrfs_grab_root(root);\n\t\tset_bit(BTRFS_ROOT_IN_RADIX, &root->state);\n\t}\n\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\tradix_tree_preload_end();\n\n\treturn ret;\n}\n\nvoid btrfs_check_leaked_roots(struct btrfs_fs_info *fs_info)\n{\n#ifdef CONFIG_BTRFS_DEBUG\n\tstruct btrfs_root *root;\n\n\twhile (!list_empty(&fs_info->allocated_roots)) {\n\t\tchar buf[BTRFS_ROOT_NAME_BUF_LEN];\n\n\t\troot = list_first_entry(&fs_info->allocated_roots,\n\t\t\t\t\tstruct btrfs_root, leak_list);\n\t\tbtrfs_err(fs_info, \"leaked root %s refcount %d\",\n\t\t\t  btrfs_root_name(&root->root_key, buf),\n\t\t\t  refcount_read(&root->refs));\n\t\twhile (refcount_read(&root->refs) > 1)\n\t\t\tbtrfs_put_root(root);\n\t\tbtrfs_put_root(root);\n\t}\n#endif\n}\n\nstatic void free_global_roots(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root;\n\tstruct rb_node *node;\n\n\twhile ((node = rb_first_postorder(&fs_info->global_root_tree)) != NULL) {\n\t\troot = rb_entry(node, struct btrfs_root, rb_node);\n\t\trb_erase(&root->rb_node, &fs_info->global_root_tree);\n\t\tbtrfs_put_root(root);\n\t}\n}\n\nvoid btrfs_free_fs_info(struct btrfs_fs_info *fs_info)\n{\n\tpercpu_counter_destroy(&fs_info->dirty_metadata_bytes);\n\tpercpu_counter_destroy(&fs_info->delalloc_bytes);\n\tpercpu_counter_destroy(&fs_info->ordered_bytes);\n\tpercpu_counter_destroy(&fs_info->dev_replace.bio_counter);\n\tbtrfs_free_csum_hash(fs_info);\n\tbtrfs_free_stripe_hash_table(fs_info);\n\tbtrfs_free_ref_cache(fs_info);\n\tkfree(fs_info->balance_ctl);\n\tkfree(fs_info->delayed_root);\n\tfree_global_roots(fs_info);\n\tbtrfs_put_root(fs_info->tree_root);\n\tbtrfs_put_root(fs_info->chunk_root);\n\tbtrfs_put_root(fs_info->dev_root);\n\tbtrfs_put_root(fs_info->quota_root);\n\tbtrfs_put_root(fs_info->uuid_root);\n\tbtrfs_put_root(fs_info->fs_root);\n\tbtrfs_put_root(fs_info->data_reloc_root);\n\tbtrfs_put_root(fs_info->block_group_root);\n\tbtrfs_check_leaked_roots(fs_info);\n\tbtrfs_extent_buffer_leak_debug_check(fs_info);\n\tkfree(fs_info->super_copy);\n\tkfree(fs_info->super_for_commit);\n\tkfree(fs_info->subpage_info);\n\tkvfree(fs_info);\n}\n\n\n \nstatic struct btrfs_root *btrfs_get_root_ref(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t     u64 objectid, dev_t anon_dev,\n\t\t\t\t\t     bool check_ref)\n{\n\tstruct btrfs_root *root;\n\tstruct btrfs_path *path;\n\tstruct btrfs_key key;\n\tint ret;\n\n\troot = btrfs_get_global_root(fs_info, objectid);\n\tif (root)\n\t\treturn root;\n\n\t \n\tif (!is_fstree(objectid) && objectid != BTRFS_DATA_RELOC_TREE_OBJECTID)\n\t\treturn ERR_PTR(-ENOENT);\nagain:\n\troot = btrfs_lookup_fs_root(fs_info, objectid);\n\tif (root) {\n\t\t \n\t\tASSERT(!anon_dev);\n\t\tif (check_ref && btrfs_root_refs(&root->root_item) == 0) {\n\t\t\tbtrfs_put_root(root);\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\t}\n\t\treturn root;\n\t}\n\n\tkey.objectid = objectid;\n\tkey.type = BTRFS_ROOT_ITEM_KEY;\n\tkey.offset = (u64)-1;\n\troot = btrfs_read_tree_root(fs_info->tree_root, &key);\n\tif (IS_ERR(root))\n\t\treturn root;\n\n\tif (check_ref && btrfs_root_refs(&root->root_item) == 0) {\n\t\tret = -ENOENT;\n\t\tgoto fail;\n\t}\n\n\tret = btrfs_init_fs_root(root, anon_dev);\n\tif (ret)\n\t\tgoto fail;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tkey.objectid = BTRFS_ORPHAN_OBJECTID;\n\tkey.type = BTRFS_ORPHAN_ITEM_KEY;\n\tkey.offset = objectid;\n\n\tret = btrfs_search_slot(NULL, fs_info->tree_root, &key, path, 0, 0);\n\tbtrfs_free_path(path);\n\tif (ret < 0)\n\t\tgoto fail;\n\tif (ret == 0)\n\t\tset_bit(BTRFS_ROOT_ORPHAN_ITEM_INSERTED, &root->state);\n\n\tret = btrfs_insert_fs_root(fs_info, root);\n\tif (ret) {\n\t\tif (ret == -EEXIST) {\n\t\t\tbtrfs_put_root(root);\n\t\t\tgoto again;\n\t\t}\n\t\tgoto fail;\n\t}\n\treturn root;\nfail:\n\t \n\tif (anon_dev)\n\t\troot->anon_dev = 0;\n\tbtrfs_put_root(root);\n\treturn ERR_PTR(ret);\n}\n\n \nstruct btrfs_root *btrfs_get_fs_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t     u64 objectid, bool check_ref)\n{\n\treturn btrfs_get_root_ref(fs_info, objectid, 0, check_ref);\n}\n\n \nstruct btrfs_root *btrfs_get_new_fs_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t u64 objectid, dev_t anon_dev)\n{\n\treturn btrfs_get_root_ref(fs_info, objectid, anon_dev, true);\n}\n\n \nstruct btrfs_root *btrfs_get_fs_root_commit_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t\t struct btrfs_path *path,\n\t\t\t\t\t\t u64 objectid)\n{\n\tstruct btrfs_root *root;\n\tstruct btrfs_key key;\n\n\tASSERT(path->search_commit_root && path->skip_locking);\n\n\t \n\troot = btrfs_get_global_root(fs_info, objectid);\n\tif (root)\n\t\treturn root;\n\n\troot = btrfs_lookup_fs_root(fs_info, objectid);\n\tif (root)\n\t\treturn root;\n\n\tkey.objectid = objectid;\n\tkey.type = BTRFS_ROOT_ITEM_KEY;\n\tkey.offset = (u64)-1;\n\troot = read_tree_root_path(fs_info->tree_root, path, &key);\n\tbtrfs_release_path(path);\n\n\treturn root;\n}\n\nstatic int cleaner_kthread(void *arg)\n{\n\tstruct btrfs_fs_info *fs_info = arg;\n\tint again;\n\n\twhile (1) {\n\t\tagain = 0;\n\n\t\tset_bit(BTRFS_FS_CLEANER_RUNNING, &fs_info->flags);\n\n\t\t \n\t\tif (btrfs_need_cleaner_sleep(fs_info))\n\t\t\tgoto sleep;\n\n\t\t \n\t\tif (!test_bit(BTRFS_FS_OPEN, &fs_info->flags))\n\t\t\tgoto sleep;\n\n\t\tif (!mutex_trylock(&fs_info->cleaner_mutex))\n\t\t\tgoto sleep;\n\n\t\t \n\t\tif (btrfs_need_cleaner_sleep(fs_info)) {\n\t\t\tmutex_unlock(&fs_info->cleaner_mutex);\n\t\t\tgoto sleep;\n\t\t}\n\n\t\tif (test_and_clear_bit(BTRFS_FS_FEATURE_CHANGED, &fs_info->flags))\n\t\t\tbtrfs_sysfs_feature_update(fs_info);\n\n\t\tbtrfs_run_delayed_iputs(fs_info);\n\n\t\tagain = btrfs_clean_one_deleted_snapshot(fs_info);\n\t\tmutex_unlock(&fs_info->cleaner_mutex);\n\n\t\t \n\t\tbtrfs_run_defrag_inodes(fs_info);\n\n\t\t \n\t\tbtrfs_delete_unused_bgs(fs_info);\n\n\t\t \n\t\tbtrfs_reclaim_bgs(fs_info);\nsleep:\n\t\tclear_and_wake_up_bit(BTRFS_FS_CLEANER_RUNNING, &fs_info->flags);\n\t\tif (kthread_should_park())\n\t\t\tkthread_parkme();\n\t\tif (kthread_should_stop())\n\t\t\treturn 0;\n\t\tif (!again) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\tschedule();\n\t\t\t__set_current_state(TASK_RUNNING);\n\t\t}\n\t}\n}\n\nstatic int transaction_kthread(void *arg)\n{\n\tstruct btrfs_root *root = arg;\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct btrfs_trans_handle *trans;\n\tstruct btrfs_transaction *cur;\n\tu64 transid;\n\ttime64_t delta;\n\tunsigned long delay;\n\tbool cannot_commit;\n\n\tdo {\n\t\tcannot_commit = false;\n\t\tdelay = msecs_to_jiffies(fs_info->commit_interval * 1000);\n\t\tmutex_lock(&fs_info->transaction_kthread_mutex);\n\n\t\tspin_lock(&fs_info->trans_lock);\n\t\tcur = fs_info->running_transaction;\n\t\tif (!cur) {\n\t\t\tspin_unlock(&fs_info->trans_lock);\n\t\t\tgoto sleep;\n\t\t}\n\n\t\tdelta = ktime_get_seconds() - cur->start_time;\n\t\tif (!test_and_clear_bit(BTRFS_FS_COMMIT_TRANS, &fs_info->flags) &&\n\t\t    cur->state < TRANS_STATE_COMMIT_PREP &&\n\t\t    delta < fs_info->commit_interval) {\n\t\t\tspin_unlock(&fs_info->trans_lock);\n\t\t\tdelay -= msecs_to_jiffies((delta - 1) * 1000);\n\t\t\tdelay = min(delay,\n\t\t\t\t    msecs_to_jiffies(fs_info->commit_interval * 1000));\n\t\t\tgoto sleep;\n\t\t}\n\t\ttransid = cur->transid;\n\t\tspin_unlock(&fs_info->trans_lock);\n\n\t\t \n\t\ttrans = btrfs_attach_transaction(root);\n\t\tif (IS_ERR(trans)) {\n\t\t\tif (PTR_ERR(trans) != -ENOENT)\n\t\t\t\tcannot_commit = true;\n\t\t\tgoto sleep;\n\t\t}\n\t\tif (transid == trans->transid) {\n\t\t\tbtrfs_commit_transaction(trans);\n\t\t} else {\n\t\t\tbtrfs_end_transaction(trans);\n\t\t}\nsleep:\n\t\twake_up_process(fs_info->cleaner_kthread);\n\t\tmutex_unlock(&fs_info->transaction_kthread_mutex);\n\n\t\tif (BTRFS_FS_ERROR(fs_info))\n\t\t\tbtrfs_cleanup_transaction(fs_info);\n\t\tif (!kthread_should_stop() &&\n\t\t\t\t(!btrfs_transaction_blocked(fs_info) ||\n\t\t\t\t cannot_commit))\n\t\t\tschedule_timeout_interruptible(delay);\n\t} while (!kthread_should_stop());\n\treturn 0;\n}\n\n \nstatic int find_newest_super_backup(struct btrfs_fs_info *info)\n{\n\tconst u64 newest_gen = btrfs_super_generation(info->super_copy);\n\tu64 cur;\n\tstruct btrfs_root_backup *root_backup;\n\tint i;\n\n\tfor (i = 0; i < BTRFS_NUM_BACKUP_ROOTS; i++) {\n\t\troot_backup = info->super_copy->super_roots + i;\n\t\tcur = btrfs_backup_tree_root_gen(root_backup);\n\t\tif (cur == newest_gen)\n\t\t\treturn i;\n\t}\n\n\treturn -EINVAL;\n}\n\n \nstatic void backup_super_roots(struct btrfs_fs_info *info)\n{\n\tconst int next_backup = info->backup_root_index;\n\tstruct btrfs_root_backup *root_backup;\n\n\troot_backup = info->super_for_commit->super_roots + next_backup;\n\n\t \n\tmemset(root_backup, 0, sizeof(*root_backup));\n\n\tinfo->backup_root_index = (next_backup + 1) % BTRFS_NUM_BACKUP_ROOTS;\n\n\tbtrfs_set_backup_tree_root(root_backup, info->tree_root->node->start);\n\tbtrfs_set_backup_tree_root_gen(root_backup,\n\t\t\t       btrfs_header_generation(info->tree_root->node));\n\n\tbtrfs_set_backup_tree_root_level(root_backup,\n\t\t\t       btrfs_header_level(info->tree_root->node));\n\n\tbtrfs_set_backup_chunk_root(root_backup, info->chunk_root->node->start);\n\tbtrfs_set_backup_chunk_root_gen(root_backup,\n\t\t\t       btrfs_header_generation(info->chunk_root->node));\n\tbtrfs_set_backup_chunk_root_level(root_backup,\n\t\t\t       btrfs_header_level(info->chunk_root->node));\n\n\tif (!btrfs_fs_compat_ro(info, BLOCK_GROUP_TREE)) {\n\t\tstruct btrfs_root *extent_root = btrfs_extent_root(info, 0);\n\t\tstruct btrfs_root *csum_root = btrfs_csum_root(info, 0);\n\n\t\tbtrfs_set_backup_extent_root(root_backup,\n\t\t\t\t\t     extent_root->node->start);\n\t\tbtrfs_set_backup_extent_root_gen(root_backup,\n\t\t\t\tbtrfs_header_generation(extent_root->node));\n\t\tbtrfs_set_backup_extent_root_level(root_backup,\n\t\t\t\t\tbtrfs_header_level(extent_root->node));\n\n\t\tbtrfs_set_backup_csum_root(root_backup, csum_root->node->start);\n\t\tbtrfs_set_backup_csum_root_gen(root_backup,\n\t\t\t\t\t       btrfs_header_generation(csum_root->node));\n\t\tbtrfs_set_backup_csum_root_level(root_backup,\n\t\t\t\t\t\t btrfs_header_level(csum_root->node));\n\t}\n\n\t \n\tif (info->fs_root && info->fs_root->node) {\n\t\tbtrfs_set_backup_fs_root(root_backup,\n\t\t\t\t\t info->fs_root->node->start);\n\t\tbtrfs_set_backup_fs_root_gen(root_backup,\n\t\t\t       btrfs_header_generation(info->fs_root->node));\n\t\tbtrfs_set_backup_fs_root_level(root_backup,\n\t\t\t       btrfs_header_level(info->fs_root->node));\n\t}\n\n\tbtrfs_set_backup_dev_root(root_backup, info->dev_root->node->start);\n\tbtrfs_set_backup_dev_root_gen(root_backup,\n\t\t\t       btrfs_header_generation(info->dev_root->node));\n\tbtrfs_set_backup_dev_root_level(root_backup,\n\t\t\t\t       btrfs_header_level(info->dev_root->node));\n\n\tbtrfs_set_backup_total_bytes(root_backup,\n\t\t\t     btrfs_super_total_bytes(info->super_copy));\n\tbtrfs_set_backup_bytes_used(root_backup,\n\t\t\t     btrfs_super_bytes_used(info->super_copy));\n\tbtrfs_set_backup_num_devices(root_backup,\n\t\t\t     btrfs_super_num_devices(info->super_copy));\n\n\t \n\tmemcpy(&info->super_copy->super_roots,\n\t       &info->super_for_commit->super_roots,\n\t       sizeof(*root_backup) * BTRFS_NUM_BACKUP_ROOTS);\n}\n\n \nstatic int read_backup_root(struct btrfs_fs_info *fs_info, u8 priority)\n{\n\tint backup_index = find_newest_super_backup(fs_info);\n\tstruct btrfs_super_block *super = fs_info->super_copy;\n\tstruct btrfs_root_backup *root_backup;\n\n\tif (priority < BTRFS_NUM_BACKUP_ROOTS && backup_index >= 0) {\n\t\tif (priority == 0)\n\t\t\treturn backup_index;\n\n\t\tbackup_index = backup_index + BTRFS_NUM_BACKUP_ROOTS - priority;\n\t\tbackup_index %= BTRFS_NUM_BACKUP_ROOTS;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\troot_backup = super->super_roots + backup_index;\n\n\tbtrfs_set_super_generation(super,\n\t\t\t\t   btrfs_backup_tree_root_gen(root_backup));\n\tbtrfs_set_super_root(super, btrfs_backup_tree_root(root_backup));\n\tbtrfs_set_super_root_level(super,\n\t\t\t\t   btrfs_backup_tree_root_level(root_backup));\n\tbtrfs_set_super_bytes_used(super, btrfs_backup_bytes_used(root_backup));\n\n\t \n\tbtrfs_set_super_total_bytes(super, btrfs_backup_total_bytes(root_backup));\n\tbtrfs_set_super_num_devices(super, btrfs_backup_num_devices(root_backup));\n\n\treturn backup_index;\n}\n\n \nstatic void btrfs_stop_all_workers(struct btrfs_fs_info *fs_info)\n{\n\tbtrfs_destroy_workqueue(fs_info->fixup_workers);\n\tbtrfs_destroy_workqueue(fs_info->delalloc_workers);\n\tbtrfs_destroy_workqueue(fs_info->workers);\n\tif (fs_info->endio_workers)\n\t\tdestroy_workqueue(fs_info->endio_workers);\n\tif (fs_info->rmw_workers)\n\t\tdestroy_workqueue(fs_info->rmw_workers);\n\tif (fs_info->compressed_write_workers)\n\t\tdestroy_workqueue(fs_info->compressed_write_workers);\n\tbtrfs_destroy_workqueue(fs_info->endio_write_workers);\n\tbtrfs_destroy_workqueue(fs_info->endio_freespace_worker);\n\tbtrfs_destroy_workqueue(fs_info->delayed_workers);\n\tbtrfs_destroy_workqueue(fs_info->caching_workers);\n\tbtrfs_destroy_workqueue(fs_info->flush_workers);\n\tbtrfs_destroy_workqueue(fs_info->qgroup_rescan_workers);\n\tif (fs_info->discard_ctl.discard_workers)\n\t\tdestroy_workqueue(fs_info->discard_ctl.discard_workers);\n\t \n\tif (fs_info->endio_meta_workers)\n\t\tdestroy_workqueue(fs_info->endio_meta_workers);\n}\n\nstatic void free_root_extent_buffers(struct btrfs_root *root)\n{\n\tif (root) {\n\t\tfree_extent_buffer(root->node);\n\t\tfree_extent_buffer(root->commit_root);\n\t\troot->node = NULL;\n\t\troot->commit_root = NULL;\n\t}\n}\n\nstatic void free_global_root_pointers(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root, *tmp;\n\n\trbtree_postorder_for_each_entry_safe(root, tmp,\n\t\t\t\t\t     &fs_info->global_root_tree,\n\t\t\t\t\t     rb_node)\n\t\tfree_root_extent_buffers(root);\n}\n\n \nstatic void free_root_pointers(struct btrfs_fs_info *info, bool free_chunk_root)\n{\n\tfree_root_extent_buffers(info->tree_root);\n\n\tfree_global_root_pointers(info);\n\tfree_root_extent_buffers(info->dev_root);\n\tfree_root_extent_buffers(info->quota_root);\n\tfree_root_extent_buffers(info->uuid_root);\n\tfree_root_extent_buffers(info->fs_root);\n\tfree_root_extent_buffers(info->data_reloc_root);\n\tfree_root_extent_buffers(info->block_group_root);\n\tif (free_chunk_root)\n\t\tfree_root_extent_buffers(info->chunk_root);\n}\n\nvoid btrfs_put_root(struct btrfs_root *root)\n{\n\tif (!root)\n\t\treturn;\n\n\tif (refcount_dec_and_test(&root->refs)) {\n\t\tWARN_ON(!RB_EMPTY_ROOT(&root->inode_tree));\n\t\tWARN_ON(test_bit(BTRFS_ROOT_DEAD_RELOC_TREE, &root->state));\n\t\tif (root->anon_dev)\n\t\t\tfree_anon_bdev(root->anon_dev);\n\t\tfree_root_extent_buffers(root);\n#ifdef CONFIG_BTRFS_DEBUG\n\t\tspin_lock(&root->fs_info->fs_roots_radix_lock);\n\t\tlist_del_init(&root->leak_list);\n\t\tspin_unlock(&root->fs_info->fs_roots_radix_lock);\n#endif\n\t\tkfree(root);\n\t}\n}\n\nvoid btrfs_free_fs_roots(struct btrfs_fs_info *fs_info)\n{\n\tint ret;\n\tstruct btrfs_root *gang[8];\n\tint i;\n\n\twhile (!list_empty(&fs_info->dead_roots)) {\n\t\tgang[0] = list_entry(fs_info->dead_roots.next,\n\t\t\t\t     struct btrfs_root, root_list);\n\t\tlist_del(&gang[0]->root_list);\n\n\t\tif (test_bit(BTRFS_ROOT_IN_RADIX, &gang[0]->state))\n\t\t\tbtrfs_drop_and_free_fs_root(fs_info, gang[0]);\n\t\tbtrfs_put_root(gang[0]);\n\t}\n\n\twhile (1) {\n\t\tret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,\n\t\t\t\t\t     (void **)gang, 0,\n\t\t\t\t\t     ARRAY_SIZE(gang));\n\t\tif (!ret)\n\t\t\tbreak;\n\t\tfor (i = 0; i < ret; i++)\n\t\t\tbtrfs_drop_and_free_fs_root(fs_info, gang[i]);\n\t}\n}\n\nstatic void btrfs_init_scrub(struct btrfs_fs_info *fs_info)\n{\n\tmutex_init(&fs_info->scrub_lock);\n\tatomic_set(&fs_info->scrubs_running, 0);\n\tatomic_set(&fs_info->scrub_pause_req, 0);\n\tatomic_set(&fs_info->scrubs_paused, 0);\n\tatomic_set(&fs_info->scrub_cancel_req, 0);\n\tinit_waitqueue_head(&fs_info->scrub_pause_wait);\n\trefcount_set(&fs_info->scrub_workers_refcnt, 0);\n}\n\nstatic void btrfs_init_balance(struct btrfs_fs_info *fs_info)\n{\n\tspin_lock_init(&fs_info->balance_lock);\n\tmutex_init(&fs_info->balance_mutex);\n\tatomic_set(&fs_info->balance_pause_req, 0);\n\tatomic_set(&fs_info->balance_cancel_req, 0);\n\tfs_info->balance_ctl = NULL;\n\tinit_waitqueue_head(&fs_info->balance_wait_q);\n\tatomic_set(&fs_info->reloc_cancel_req, 0);\n}\n\nstatic int btrfs_init_btree_inode(struct super_block *sb)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(sb);\n\tunsigned long hash = btrfs_inode_hash(BTRFS_BTREE_INODE_OBJECTID,\n\t\t\t\t\t      fs_info->tree_root);\n\tstruct inode *inode;\n\n\tinode = new_inode(sb);\n\tif (!inode)\n\t\treturn -ENOMEM;\n\n\tinode->i_ino = BTRFS_BTREE_INODE_OBJECTID;\n\tset_nlink(inode, 1);\n\t \n\tinode->i_size = OFFSET_MAX;\n\tinode->i_mapping->a_ops = &btree_aops;\n\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\n\tRB_CLEAR_NODE(&BTRFS_I(inode)->rb_node);\n\textent_io_tree_init(fs_info, &BTRFS_I(inode)->io_tree,\n\t\t\t    IO_TREE_BTREE_INODE_IO);\n\textent_map_tree_init(&BTRFS_I(inode)->extent_tree);\n\n\tBTRFS_I(inode)->root = btrfs_grab_root(fs_info->tree_root);\n\tBTRFS_I(inode)->location.objectid = BTRFS_BTREE_INODE_OBJECTID;\n\tBTRFS_I(inode)->location.type = 0;\n\tBTRFS_I(inode)->location.offset = 0;\n\tset_bit(BTRFS_INODE_DUMMY, &BTRFS_I(inode)->runtime_flags);\n\t__insert_inode_hash(inode, hash);\n\tfs_info->btree_inode = inode;\n\n\treturn 0;\n}\n\nstatic void btrfs_init_dev_replace_locks(struct btrfs_fs_info *fs_info)\n{\n\tmutex_init(&fs_info->dev_replace.lock_finishing_cancel_unmount);\n\tinit_rwsem(&fs_info->dev_replace.rwsem);\n\tinit_waitqueue_head(&fs_info->dev_replace.replace_wait);\n}\n\nstatic void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)\n{\n\tspin_lock_init(&fs_info->qgroup_lock);\n\tmutex_init(&fs_info->qgroup_ioctl_lock);\n\tfs_info->qgroup_tree = RB_ROOT;\n\tINIT_LIST_HEAD(&fs_info->dirty_qgroups);\n\tfs_info->qgroup_seq = 1;\n\tfs_info->qgroup_ulist = NULL;\n\tfs_info->qgroup_rescan_running = false;\n\tfs_info->qgroup_drop_subtree_thres = BTRFS_MAX_LEVEL;\n\tmutex_init(&fs_info->qgroup_rescan_lock);\n}\n\nstatic int btrfs_init_workqueues(struct btrfs_fs_info *fs_info)\n{\n\tu32 max_active = fs_info->thread_pool_size;\n\tunsigned int flags = WQ_MEM_RECLAIM | WQ_FREEZABLE | WQ_UNBOUND;\n\tunsigned int ordered_flags = WQ_MEM_RECLAIM | WQ_FREEZABLE;\n\n\tfs_info->workers =\n\t\tbtrfs_alloc_workqueue(fs_info, \"worker\", flags, max_active, 16);\n\n\tfs_info->delalloc_workers =\n\t\tbtrfs_alloc_workqueue(fs_info, \"delalloc\",\n\t\t\t\t      flags, max_active, 2);\n\n\tfs_info->flush_workers =\n\t\tbtrfs_alloc_workqueue(fs_info, \"flush_delalloc\",\n\t\t\t\t      flags, max_active, 0);\n\n\tfs_info->caching_workers =\n\t\tbtrfs_alloc_workqueue(fs_info, \"cache\", flags, max_active, 0);\n\n\tfs_info->fixup_workers =\n\t\tbtrfs_alloc_ordered_workqueue(fs_info, \"fixup\", ordered_flags);\n\n\tfs_info->endio_workers =\n\t\talloc_workqueue(\"btrfs-endio\", flags, max_active);\n\tfs_info->endio_meta_workers =\n\t\talloc_workqueue(\"btrfs-endio-meta\", flags, max_active);\n\tfs_info->rmw_workers = alloc_workqueue(\"btrfs-rmw\", flags, max_active);\n\tfs_info->endio_write_workers =\n\t\tbtrfs_alloc_workqueue(fs_info, \"endio-write\", flags,\n\t\t\t\t      max_active, 2);\n\tfs_info->compressed_write_workers =\n\t\talloc_workqueue(\"btrfs-compressed-write\", flags, max_active);\n\tfs_info->endio_freespace_worker =\n\t\tbtrfs_alloc_workqueue(fs_info, \"freespace-write\", flags,\n\t\t\t\t      max_active, 0);\n\tfs_info->delayed_workers =\n\t\tbtrfs_alloc_workqueue(fs_info, \"delayed-meta\", flags,\n\t\t\t\t      max_active, 0);\n\tfs_info->qgroup_rescan_workers =\n\t\tbtrfs_alloc_ordered_workqueue(fs_info, \"qgroup-rescan\",\n\t\t\t\t\t      ordered_flags);\n\tfs_info->discard_ctl.discard_workers =\n\t\talloc_ordered_workqueue(\"btrfs_discard\", WQ_FREEZABLE);\n\n\tif (!(fs_info->workers &&\n\t      fs_info->delalloc_workers && fs_info->flush_workers &&\n\t      fs_info->endio_workers && fs_info->endio_meta_workers &&\n\t      fs_info->compressed_write_workers &&\n\t      fs_info->endio_write_workers &&\n\t      fs_info->endio_freespace_worker && fs_info->rmw_workers &&\n\t      fs_info->caching_workers && fs_info->fixup_workers &&\n\t      fs_info->delayed_workers && fs_info->qgroup_rescan_workers &&\n\t      fs_info->discard_ctl.discard_workers)) {\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic int btrfs_init_csum_hash(struct btrfs_fs_info *fs_info, u16 csum_type)\n{\n\tstruct crypto_shash *csum_shash;\n\tconst char *csum_driver = btrfs_super_csum_driver(csum_type);\n\n\tcsum_shash = crypto_alloc_shash(csum_driver, 0, 0);\n\n\tif (IS_ERR(csum_shash)) {\n\t\tbtrfs_err(fs_info, \"error allocating %s hash for checksum\",\n\t\t\t  csum_driver);\n\t\treturn PTR_ERR(csum_shash);\n\t}\n\n\tfs_info->csum_shash = csum_shash;\n\n\t \n\tswitch (csum_type) {\n\tcase BTRFS_CSUM_TYPE_CRC32:\n\t\tif (!strstr(crypto_shash_driver_name(csum_shash), \"generic\"))\n\t\t\tset_bit(BTRFS_FS_CSUM_IMPL_FAST, &fs_info->flags);\n\t\tbreak;\n\tcase BTRFS_CSUM_TYPE_XXHASH:\n\t\tset_bit(BTRFS_FS_CSUM_IMPL_FAST, &fs_info->flags);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tbtrfs_info(fs_info, \"using %s (%s) checksum algorithm\",\n\t\t\tbtrfs_super_csum_name(csum_type),\n\t\t\tcrypto_shash_driver_name(csum_shash));\n\treturn 0;\n}\n\nstatic int btrfs_replay_log(struct btrfs_fs_info *fs_info,\n\t\t\t    struct btrfs_fs_devices *fs_devices)\n{\n\tint ret;\n\tstruct btrfs_tree_parent_check check = { 0 };\n\tstruct btrfs_root *log_tree_root;\n\tstruct btrfs_super_block *disk_super = fs_info->super_copy;\n\tu64 bytenr = btrfs_super_log_root(disk_super);\n\tint level = btrfs_super_log_root_level(disk_super);\n\n\tif (fs_devices->rw_devices == 0) {\n\t\tbtrfs_warn(fs_info, \"log replay required on RO media\");\n\t\treturn -EIO;\n\t}\n\n\tlog_tree_root = btrfs_alloc_root(fs_info, BTRFS_TREE_LOG_OBJECTID,\n\t\t\t\t\t GFP_KERNEL);\n\tif (!log_tree_root)\n\t\treturn -ENOMEM;\n\n\tcheck.level = level;\n\tcheck.transid = fs_info->generation + 1;\n\tcheck.owner_root = BTRFS_TREE_LOG_OBJECTID;\n\tlog_tree_root->node = read_tree_block(fs_info, bytenr, &check);\n\tif (IS_ERR(log_tree_root->node)) {\n\t\tbtrfs_warn(fs_info, \"failed to read log tree\");\n\t\tret = PTR_ERR(log_tree_root->node);\n\t\tlog_tree_root->node = NULL;\n\t\tbtrfs_put_root(log_tree_root);\n\t\treturn ret;\n\t}\n\tif (!extent_buffer_uptodate(log_tree_root->node)) {\n\t\tbtrfs_err(fs_info, \"failed to read log tree\");\n\t\tbtrfs_put_root(log_tree_root);\n\t\treturn -EIO;\n\t}\n\n\t \n\tret = btrfs_recover_log_trees(log_tree_root);\n\tif (ret) {\n\t\tbtrfs_handle_fs_error(fs_info, ret,\n\t\t\t\t      \"Failed to recover log tree\");\n\t\tbtrfs_put_root(log_tree_root);\n\t\treturn ret;\n\t}\n\n\tif (sb_rdonly(fs_info->sb)) {\n\t\tret = btrfs_commit_super(fs_info);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int load_global_roots_objectid(struct btrfs_root *tree_root,\n\t\t\t\t      struct btrfs_path *path, u64 objectid,\n\t\t\t\t      const char *name)\n{\n\tstruct btrfs_fs_info *fs_info = tree_root->fs_info;\n\tstruct btrfs_root *root;\n\tu64 max_global_id = 0;\n\tint ret;\n\tstruct btrfs_key key = {\n\t\t.objectid = objectid,\n\t\t.type = BTRFS_ROOT_ITEM_KEY,\n\t\t.offset = 0,\n\t};\n\tbool found = false;\n\n\t \n\tif (objectid == BTRFS_CSUM_TREE_OBJECTID &&\n\t    btrfs_test_opt(fs_info, IGNOREDATACSUMS)) {\n\t\tset_bit(BTRFS_FS_STATE_NO_CSUMS, &fs_info->fs_state);\n\t\treturn 0;\n\t}\n\n\twhile (1) {\n\t\tret = btrfs_search_slot(NULL, tree_root, &key, path, 0, 0);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\tif (path->slots[0] >= btrfs_header_nritems(path->nodes[0])) {\n\t\t\tret = btrfs_next_leaf(tree_root, path);\n\t\t\tif (ret) {\n\t\t\t\tif (ret > 0)\n\t\t\t\t\tret = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tret = 0;\n\n\t\tbtrfs_item_key_to_cpu(path->nodes[0], &key, path->slots[0]);\n\t\tif (key.objectid != objectid)\n\t\t\tbreak;\n\t\tbtrfs_release_path(path);\n\n\t\t \n\t\tif (objectid == BTRFS_EXTENT_TREE_OBJECTID)\n\t\t\tmax_global_id = max(max_global_id, key.offset);\n\n\t\tfound = true;\n\t\troot = read_tree_root_path(tree_root, path, &key);\n\t\tif (IS_ERR(root)) {\n\t\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS))\n\t\t\t\tret = PTR_ERR(root);\n\t\t\tbreak;\n\t\t}\n\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n\t\tret = btrfs_global_root_insert(root);\n\t\tif (ret) {\n\t\t\tbtrfs_put_root(root);\n\t\t\tbreak;\n\t\t}\n\t\tkey.offset++;\n\t}\n\tbtrfs_release_path(path);\n\n\tif (objectid == BTRFS_EXTENT_TREE_OBJECTID)\n\t\tfs_info->nr_global_roots = max_global_id + 1;\n\n\tif (!found || ret) {\n\t\tif (objectid == BTRFS_CSUM_TREE_OBJECTID)\n\t\t\tset_bit(BTRFS_FS_STATE_NO_CSUMS, &fs_info->fs_state);\n\n\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS))\n\t\t\tret = ret ? ret : -ENOENT;\n\t\telse\n\t\t\tret = 0;\n\t\tbtrfs_err(fs_info, \"failed to load root %s\", name);\n\t}\n\treturn ret;\n}\n\nstatic int load_global_roots(struct btrfs_root *tree_root)\n{\n\tstruct btrfs_path *path;\n\tint ret = 0;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tret = load_global_roots_objectid(tree_root, path,\n\t\t\t\t\t BTRFS_EXTENT_TREE_OBJECTID, \"extent\");\n\tif (ret)\n\t\tgoto out;\n\tret = load_global_roots_objectid(tree_root, path,\n\t\t\t\t\t BTRFS_CSUM_TREE_OBJECTID, \"csum\");\n\tif (ret)\n\t\tgoto out;\n\tif (!btrfs_fs_compat_ro(tree_root->fs_info, FREE_SPACE_TREE))\n\t\tgoto out;\n\tret = load_global_roots_objectid(tree_root, path,\n\t\t\t\t\t BTRFS_FREE_SPACE_TREE_OBJECTID,\n\t\t\t\t\t \"free space\");\nout:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nstatic int btrfs_read_roots(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *tree_root = fs_info->tree_root;\n\tstruct btrfs_root *root;\n\tstruct btrfs_key location;\n\tint ret;\n\n\tBUG_ON(!fs_info->tree_root);\n\n\tret = load_global_roots(tree_root);\n\tif (ret)\n\t\treturn ret;\n\n\tlocation.type = BTRFS_ROOT_ITEM_KEY;\n\tlocation.offset = 0;\n\n\tif (btrfs_fs_compat_ro(fs_info, BLOCK_GROUP_TREE)) {\n\t\tlocation.objectid = BTRFS_BLOCK_GROUP_TREE_OBJECTID;\n\t\troot = btrfs_read_tree_root(tree_root, &location);\n\t\tif (IS_ERR(root)) {\n\t\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS)) {\n\t\t\t\tret = PTR_ERR(root);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n\t\t\tfs_info->block_group_root = root;\n\t\t}\n\t}\n\n\tlocation.objectid = BTRFS_DEV_TREE_OBJECTID;\n\troot = btrfs_read_tree_root(tree_root, &location);\n\tif (IS_ERR(root)) {\n\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS)) {\n\t\t\tret = PTR_ERR(root);\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n\t\tfs_info->dev_root = root;\n\t}\n\t \n\tret = btrfs_init_devices_late(fs_info);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\troot = btrfs_get_fs_root(tree_root->fs_info,\n\t\t\t\t BTRFS_DATA_RELOC_TREE_OBJECTID, true);\n\tif (IS_ERR(root)) {\n\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS)) {\n\t\t\tret = PTR_ERR(root);\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n\t\tfs_info->data_reloc_root = root;\n\t}\n\n\tlocation.objectid = BTRFS_QUOTA_TREE_OBJECTID;\n\troot = btrfs_read_tree_root(tree_root, &location);\n\tif (!IS_ERR(root)) {\n\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n\t\tset_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);\n\t\tfs_info->quota_root = root;\n\t}\n\n\tlocation.objectid = BTRFS_UUID_TREE_OBJECTID;\n\troot = btrfs_read_tree_root(tree_root, &location);\n\tif (IS_ERR(root)) {\n\t\tif (!btrfs_test_opt(fs_info, IGNOREBADROOTS)) {\n\t\t\tret = PTR_ERR(root);\n\t\t\tif (ret != -ENOENT)\n\t\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tset_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);\n\t\tfs_info->uuid_root = root;\n\t}\n\n\treturn 0;\nout:\n\tbtrfs_warn(fs_info, \"failed to read root (objectid=%llu): %d\",\n\t\t   location.objectid, ret);\n\treturn ret;\n}\n\n \nint btrfs_validate_super(struct btrfs_fs_info *fs_info,\n\t\t\t struct btrfs_super_block *sb, int mirror_num)\n{\n\tu64 nodesize = btrfs_super_nodesize(sb);\n\tu64 sectorsize = btrfs_super_sectorsize(sb);\n\tint ret = 0;\n\n\tif (btrfs_super_magic(sb) != BTRFS_MAGIC) {\n\t\tbtrfs_err(fs_info, \"no valid FS found\");\n\t\tret = -EINVAL;\n\t}\n\tif (btrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP) {\n\t\tbtrfs_err(fs_info, \"unrecognized or unsupported super flag: %llu\",\n\t\t\t\tbtrfs_super_flags(sb) & ~BTRFS_SUPER_FLAG_SUPP);\n\t\tret = -EINVAL;\n\t}\n\tif (btrfs_super_root_level(sb) >= BTRFS_MAX_LEVEL) {\n\t\tbtrfs_err(fs_info, \"tree_root level too big: %d >= %d\",\n\t\t\t\tbtrfs_super_root_level(sb), BTRFS_MAX_LEVEL);\n\t\tret = -EINVAL;\n\t}\n\tif (btrfs_super_chunk_root_level(sb) >= BTRFS_MAX_LEVEL) {\n\t\tbtrfs_err(fs_info, \"chunk_root level too big: %d >= %d\",\n\t\t\t\tbtrfs_super_chunk_root_level(sb), BTRFS_MAX_LEVEL);\n\t\tret = -EINVAL;\n\t}\n\tif (btrfs_super_log_root_level(sb) >= BTRFS_MAX_LEVEL) {\n\t\tbtrfs_err(fs_info, \"log_root level too big: %d >= %d\",\n\t\t\t\tbtrfs_super_log_root_level(sb), BTRFS_MAX_LEVEL);\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (!is_power_of_2(sectorsize) || sectorsize < 4096 ||\n\t    sectorsize > BTRFS_MAX_METADATA_BLOCKSIZE) {\n\t\tbtrfs_err(fs_info, \"invalid sectorsize %llu\", sectorsize);\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (sectorsize > PAGE_SIZE || (sectorsize != SZ_4K && sectorsize != PAGE_SIZE)) {\n\t\tbtrfs_err(fs_info,\n\t\t\t\"sectorsize %llu not yet supported for page size %lu\",\n\t\t\tsectorsize, PAGE_SIZE);\n\t\tret = -EINVAL;\n\t}\n\n\tif (!is_power_of_2(nodesize) || nodesize < sectorsize ||\n\t    nodesize > BTRFS_MAX_METADATA_BLOCKSIZE) {\n\t\tbtrfs_err(fs_info, \"invalid nodesize %llu\", nodesize);\n\t\tret = -EINVAL;\n\t}\n\tif (nodesize != le32_to_cpu(sb->__unused_leafsize)) {\n\t\tbtrfs_err(fs_info, \"invalid leafsize %u, should be %llu\",\n\t\t\t  le32_to_cpu(sb->__unused_leafsize), nodesize);\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (!IS_ALIGNED(btrfs_super_root(sb), sectorsize)) {\n\t\tbtrfs_warn(fs_info, \"tree_root block unaligned: %llu\",\n\t\t\t   btrfs_super_root(sb));\n\t\tret = -EINVAL;\n\t}\n\tif (!IS_ALIGNED(btrfs_super_chunk_root(sb), sectorsize)) {\n\t\tbtrfs_warn(fs_info, \"chunk_root block unaligned: %llu\",\n\t\t\t   btrfs_super_chunk_root(sb));\n\t\tret = -EINVAL;\n\t}\n\tif (!IS_ALIGNED(btrfs_super_log_root(sb), sectorsize)) {\n\t\tbtrfs_warn(fs_info, \"log_root block unaligned: %llu\",\n\t\t\t   btrfs_super_log_root(sb));\n\t\tret = -EINVAL;\n\t}\n\n\tif (memcmp(fs_info->fs_devices->fsid, sb->fsid, BTRFS_FSID_SIZE) != 0) {\n\t\tbtrfs_err(fs_info,\n\t\t\"superblock fsid doesn't match fsid of fs_devices: %pU != %pU\",\n\t\t\t  sb->fsid, fs_info->fs_devices->fsid);\n\t\tret = -EINVAL;\n\t}\n\n\tif (memcmp(fs_info->fs_devices->metadata_uuid, btrfs_sb_fsid_ptr(sb),\n\t\t   BTRFS_FSID_SIZE) != 0) {\n\t\tbtrfs_err(fs_info,\n\"superblock metadata_uuid doesn't match metadata uuid of fs_devices: %pU != %pU\",\n\t\t\t  btrfs_sb_fsid_ptr(sb), fs_info->fs_devices->metadata_uuid);\n\t\tret = -EINVAL;\n\t}\n\n\tif (memcmp(fs_info->fs_devices->metadata_uuid, sb->dev_item.fsid,\n\t\t   BTRFS_FSID_SIZE) != 0) {\n\t\tbtrfs_err(fs_info,\n\t\t\t\"dev_item UUID does not match metadata fsid: %pU != %pU\",\n\t\t\tfs_info->fs_devices->metadata_uuid, sb->dev_item.fsid);\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (btrfs_fs_compat_ro(fs_info, BLOCK_GROUP_TREE) &&\n\t    (!btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE_VALID) ||\n\t     !btrfs_fs_incompat(fs_info, NO_HOLES))) {\n\t\tbtrfs_err(fs_info,\n\t\t\"block-group-tree feature requires fres-space-tree and no-holes\");\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (btrfs_super_bytes_used(sb) < 6 * btrfs_super_nodesize(sb)) {\n\t\tbtrfs_err(fs_info, \"bytes_used is too small %llu\",\n\t\t\t  btrfs_super_bytes_used(sb));\n\t\tret = -EINVAL;\n\t}\n\tif (!is_power_of_2(btrfs_super_stripesize(sb))) {\n\t\tbtrfs_err(fs_info, \"invalid stripesize %u\",\n\t\t\t  btrfs_super_stripesize(sb));\n\t\tret = -EINVAL;\n\t}\n\tif (btrfs_super_num_devices(sb) > (1UL << 31))\n\t\tbtrfs_warn(fs_info, \"suspicious number of devices: %llu\",\n\t\t\t   btrfs_super_num_devices(sb));\n\tif (btrfs_super_num_devices(sb) == 0) {\n\t\tbtrfs_err(fs_info, \"number of devices is 0\");\n\t\tret = -EINVAL;\n\t}\n\n\tif (mirror_num >= 0 &&\n\t    btrfs_super_bytenr(sb) != btrfs_sb_offset(mirror_num)) {\n\t\tbtrfs_err(fs_info, \"super offset mismatch %llu != %u\",\n\t\t\t  btrfs_super_bytenr(sb), BTRFS_SUPER_INFO_OFFSET);\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (btrfs_super_sys_array_size(sb) > BTRFS_SYSTEM_CHUNK_ARRAY_SIZE) {\n\t\tbtrfs_err(fs_info, \"system chunk array too big %u > %u\",\n\t\t\t  btrfs_super_sys_array_size(sb),\n\t\t\t  BTRFS_SYSTEM_CHUNK_ARRAY_SIZE);\n\t\tret = -EINVAL;\n\t}\n\tif (btrfs_super_sys_array_size(sb) < sizeof(struct btrfs_disk_key)\n\t\t\t+ sizeof(struct btrfs_chunk)) {\n\t\tbtrfs_err(fs_info, \"system chunk array too small %u < %zu\",\n\t\t\t  btrfs_super_sys_array_size(sb),\n\t\t\t  sizeof(struct btrfs_disk_key)\n\t\t\t  + sizeof(struct btrfs_chunk));\n\t\tret = -EINVAL;\n\t}\n\n\t \n\tif (btrfs_super_generation(sb) < btrfs_super_chunk_root_generation(sb))\n\t\tbtrfs_warn(fs_info,\n\t\t\t\"suspicious: generation < chunk_root_generation: %llu < %llu\",\n\t\t\tbtrfs_super_generation(sb),\n\t\t\tbtrfs_super_chunk_root_generation(sb));\n\tif (btrfs_super_generation(sb) < btrfs_super_cache_generation(sb)\n\t    && btrfs_super_cache_generation(sb) != (u64)-1)\n\t\tbtrfs_warn(fs_info,\n\t\t\t\"suspicious: generation < cache_generation: %llu < %llu\",\n\t\t\tbtrfs_super_generation(sb),\n\t\t\tbtrfs_super_cache_generation(sb));\n\n\treturn ret;\n}\n\n \nstatic int btrfs_validate_mount_super(struct btrfs_fs_info *fs_info)\n{\n\treturn btrfs_validate_super(fs_info, fs_info->super_copy, 0);\n}\n\n \nstatic int btrfs_validate_write_super(struct btrfs_fs_info *fs_info,\n\t\t\t\t      struct btrfs_super_block *sb)\n{\n\tint ret;\n\n\tret = btrfs_validate_super(fs_info, sb, -1);\n\tif (ret < 0)\n\t\tgoto out;\n\tif (!btrfs_supported_super_csum(btrfs_super_csum_type(sb))) {\n\t\tret = -EUCLEAN;\n\t\tbtrfs_err(fs_info, \"invalid csum type, has %u want %u\",\n\t\t\t  btrfs_super_csum_type(sb), BTRFS_CSUM_TYPE_CRC32);\n\t\tgoto out;\n\t}\n\tif (btrfs_super_incompat_flags(sb) & ~BTRFS_FEATURE_INCOMPAT_SUPP) {\n\t\tret = -EUCLEAN;\n\t\tbtrfs_err(fs_info,\n\t\t\"invalid incompat flags, has 0x%llx valid mask 0x%llx\",\n\t\t\t  btrfs_super_incompat_flags(sb),\n\t\t\t  (unsigned long long)BTRFS_FEATURE_INCOMPAT_SUPP);\n\t\tgoto out;\n\t}\nout:\n\tif (ret < 0)\n\t\tbtrfs_err(fs_info,\n\t\t\"super block corruption detected before writing it to disk\");\n\treturn ret;\n}\n\nstatic int load_super_root(struct btrfs_root *root, u64 bytenr, u64 gen, int level)\n{\n\tstruct btrfs_tree_parent_check check = {\n\t\t.level = level,\n\t\t.transid = gen,\n\t\t.owner_root = root->root_key.objectid\n\t};\n\tint ret = 0;\n\n\troot->node = read_tree_block(root->fs_info, bytenr, &check);\n\tif (IS_ERR(root->node)) {\n\t\tret = PTR_ERR(root->node);\n\t\troot->node = NULL;\n\t\treturn ret;\n\t}\n\tif (!extent_buffer_uptodate(root->node)) {\n\t\tfree_extent_buffer(root->node);\n\t\troot->node = NULL;\n\t\treturn -EIO;\n\t}\n\n\tbtrfs_set_root_node(&root->root_item, root->node);\n\troot->commit_root = btrfs_root_node(root);\n\tbtrfs_set_root_refs(&root->root_item, 1);\n\treturn ret;\n}\n\nstatic int load_important_roots(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_super_block *sb = fs_info->super_copy;\n\tu64 gen, bytenr;\n\tint level, ret;\n\n\tbytenr = btrfs_super_root(sb);\n\tgen = btrfs_super_generation(sb);\n\tlevel = btrfs_super_root_level(sb);\n\tret = load_super_root(fs_info->tree_root, bytenr, gen, level);\n\tif (ret) {\n\t\tbtrfs_warn(fs_info, \"couldn't read tree root\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int __cold init_tree_roots(struct btrfs_fs_info *fs_info)\n{\n\tint backup_index = find_newest_super_backup(fs_info);\n\tstruct btrfs_super_block *sb = fs_info->super_copy;\n\tstruct btrfs_root *tree_root = fs_info->tree_root;\n\tbool handle_error = false;\n\tint ret = 0;\n\tint i;\n\n\tfor (i = 0; i < BTRFS_NUM_BACKUP_ROOTS; i++) {\n\t\tif (handle_error) {\n\t\t\tif (!IS_ERR(tree_root->node))\n\t\t\t\tfree_extent_buffer(tree_root->node);\n\t\t\ttree_root->node = NULL;\n\n\t\t\tif (!btrfs_test_opt(fs_info, USEBACKUPROOT))\n\t\t\t\tbreak;\n\n\t\t\tfree_root_pointers(fs_info, 0);\n\n\t\t\t \n\t\t\tbtrfs_set_super_log_root(sb, 0);\n\n\t\t\t \n\t\t\tbtrfs_set_opt(fs_info->mount_opt, CLEAR_CACHE);\n\n\t\t\tbtrfs_warn(fs_info, \"try to load backup roots slot %d\", i);\n\t\t\tret = read_backup_root(fs_info, i);\n\t\t\tbackup_index = ret;\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tret = load_important_roots(fs_info);\n\t\tif (ret) {\n\t\t\thandle_error = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tret = btrfs_init_root_free_objectid(tree_root);\n\t\tif (ret < 0) {\n\t\t\thandle_error = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tASSERT(tree_root->free_objectid <= BTRFS_LAST_FREE_OBJECTID);\n\n\t\tret = btrfs_read_roots(fs_info);\n\t\tif (ret < 0) {\n\t\t\thandle_error = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tfs_info->generation = btrfs_header_generation(tree_root->node);\n\t\tfs_info->last_trans_committed = fs_info->generation;\n\t\tfs_info->last_reloc_trans = 0;\n\n\t\t \n\t\tif (backup_index < 0) {\n\t\t\tfs_info->backup_root_index = 0;\n\t\t} else {\n\t\t\tfs_info->backup_root_index = backup_index + 1;\n\t\t\tfs_info->backup_root_index %= BTRFS_NUM_BACKUP_ROOTS;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nvoid btrfs_init_fs_info(struct btrfs_fs_info *fs_info)\n{\n\tINIT_RADIX_TREE(&fs_info->fs_roots_radix, GFP_ATOMIC);\n\tINIT_RADIX_TREE(&fs_info->buffer_radix, GFP_ATOMIC);\n\tINIT_LIST_HEAD(&fs_info->trans_list);\n\tINIT_LIST_HEAD(&fs_info->dead_roots);\n\tINIT_LIST_HEAD(&fs_info->delayed_iputs);\n\tINIT_LIST_HEAD(&fs_info->delalloc_roots);\n\tINIT_LIST_HEAD(&fs_info->caching_block_groups);\n\tspin_lock_init(&fs_info->delalloc_root_lock);\n\tspin_lock_init(&fs_info->trans_lock);\n\tspin_lock_init(&fs_info->fs_roots_radix_lock);\n\tspin_lock_init(&fs_info->delayed_iput_lock);\n\tspin_lock_init(&fs_info->defrag_inodes_lock);\n\tspin_lock_init(&fs_info->super_lock);\n\tspin_lock_init(&fs_info->buffer_lock);\n\tspin_lock_init(&fs_info->unused_bgs_lock);\n\tspin_lock_init(&fs_info->treelog_bg_lock);\n\tspin_lock_init(&fs_info->zone_active_bgs_lock);\n\tspin_lock_init(&fs_info->relocation_bg_lock);\n\trwlock_init(&fs_info->tree_mod_log_lock);\n\trwlock_init(&fs_info->global_root_lock);\n\tmutex_init(&fs_info->unused_bg_unpin_mutex);\n\tmutex_init(&fs_info->reclaim_bgs_lock);\n\tmutex_init(&fs_info->reloc_mutex);\n\tmutex_init(&fs_info->delalloc_root_mutex);\n\tmutex_init(&fs_info->zoned_meta_io_lock);\n\tmutex_init(&fs_info->zoned_data_reloc_io_lock);\n\tseqlock_init(&fs_info->profiles_lock);\n\n\tbtrfs_lockdep_init_map(fs_info, btrfs_trans_num_writers);\n\tbtrfs_lockdep_init_map(fs_info, btrfs_trans_num_extwriters);\n\tbtrfs_lockdep_init_map(fs_info, btrfs_trans_pending_ordered);\n\tbtrfs_lockdep_init_map(fs_info, btrfs_ordered_extent);\n\tbtrfs_state_lockdep_init_map(fs_info, btrfs_trans_commit_prep,\n\t\t\t\t     BTRFS_LOCKDEP_TRANS_COMMIT_PREP);\n\tbtrfs_state_lockdep_init_map(fs_info, btrfs_trans_unblocked,\n\t\t\t\t     BTRFS_LOCKDEP_TRANS_UNBLOCKED);\n\tbtrfs_state_lockdep_init_map(fs_info, btrfs_trans_super_committed,\n\t\t\t\t     BTRFS_LOCKDEP_TRANS_SUPER_COMMITTED);\n\tbtrfs_state_lockdep_init_map(fs_info, btrfs_trans_completed,\n\t\t\t\t     BTRFS_LOCKDEP_TRANS_COMPLETED);\n\n\tINIT_LIST_HEAD(&fs_info->dirty_cowonly_roots);\n\tINIT_LIST_HEAD(&fs_info->space_info);\n\tINIT_LIST_HEAD(&fs_info->tree_mod_seq_list);\n\tINIT_LIST_HEAD(&fs_info->unused_bgs);\n\tINIT_LIST_HEAD(&fs_info->reclaim_bgs);\n\tINIT_LIST_HEAD(&fs_info->zone_active_bgs);\n#ifdef CONFIG_BTRFS_DEBUG\n\tINIT_LIST_HEAD(&fs_info->allocated_roots);\n\tINIT_LIST_HEAD(&fs_info->allocated_ebs);\n\tspin_lock_init(&fs_info->eb_leak_lock);\n#endif\n\textent_map_tree_init(&fs_info->mapping_tree);\n\tbtrfs_init_block_rsv(&fs_info->global_block_rsv,\n\t\t\t     BTRFS_BLOCK_RSV_GLOBAL);\n\tbtrfs_init_block_rsv(&fs_info->trans_block_rsv, BTRFS_BLOCK_RSV_TRANS);\n\tbtrfs_init_block_rsv(&fs_info->chunk_block_rsv, BTRFS_BLOCK_RSV_CHUNK);\n\tbtrfs_init_block_rsv(&fs_info->empty_block_rsv, BTRFS_BLOCK_RSV_EMPTY);\n\tbtrfs_init_block_rsv(&fs_info->delayed_block_rsv,\n\t\t\t     BTRFS_BLOCK_RSV_DELOPS);\n\tbtrfs_init_block_rsv(&fs_info->delayed_refs_rsv,\n\t\t\t     BTRFS_BLOCK_RSV_DELREFS);\n\n\tatomic_set(&fs_info->async_delalloc_pages, 0);\n\tatomic_set(&fs_info->defrag_running, 0);\n\tatomic_set(&fs_info->nr_delayed_iputs, 0);\n\tatomic64_set(&fs_info->tree_mod_seq, 0);\n\tfs_info->global_root_tree = RB_ROOT;\n\tfs_info->max_inline = BTRFS_DEFAULT_MAX_INLINE;\n\tfs_info->metadata_ratio = 0;\n\tfs_info->defrag_inodes = RB_ROOT;\n\tatomic64_set(&fs_info->free_chunk_space, 0);\n\tfs_info->tree_mod_log = RB_ROOT;\n\tfs_info->commit_interval = BTRFS_DEFAULT_COMMIT_INTERVAL;\n\tbtrfs_init_ref_verify(fs_info);\n\n\tfs_info->thread_pool_size = min_t(unsigned long,\n\t\t\t\t\t  num_online_cpus() + 2, 8);\n\n\tINIT_LIST_HEAD(&fs_info->ordered_roots);\n\tspin_lock_init(&fs_info->ordered_root_lock);\n\n\tbtrfs_init_scrub(fs_info);\n#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY\n\tfs_info->check_integrity_print_mask = 0;\n#endif\n\tbtrfs_init_balance(fs_info);\n\tbtrfs_init_async_reclaim_work(fs_info);\n\n\trwlock_init(&fs_info->block_group_cache_lock);\n\tfs_info->block_group_cache_tree = RB_ROOT_CACHED;\n\n\textent_io_tree_init(fs_info, &fs_info->excluded_extents,\n\t\t\t    IO_TREE_FS_EXCLUDED_EXTENTS);\n\n\tmutex_init(&fs_info->ordered_operations_mutex);\n\tmutex_init(&fs_info->tree_log_mutex);\n\tmutex_init(&fs_info->chunk_mutex);\n\tmutex_init(&fs_info->transaction_kthread_mutex);\n\tmutex_init(&fs_info->cleaner_mutex);\n\tmutex_init(&fs_info->ro_block_group_mutex);\n\tinit_rwsem(&fs_info->commit_root_sem);\n\tinit_rwsem(&fs_info->cleanup_work_sem);\n\tinit_rwsem(&fs_info->subvol_sem);\n\tsema_init(&fs_info->uuid_tree_rescan_sem, 1);\n\n\tbtrfs_init_dev_replace_locks(fs_info);\n\tbtrfs_init_qgroup(fs_info);\n\tbtrfs_discard_init(fs_info);\n\n\tbtrfs_init_free_cluster(&fs_info->meta_alloc_cluster);\n\tbtrfs_init_free_cluster(&fs_info->data_alloc_cluster);\n\n\tinit_waitqueue_head(&fs_info->transaction_throttle);\n\tinit_waitqueue_head(&fs_info->transaction_wait);\n\tinit_waitqueue_head(&fs_info->transaction_blocked_wait);\n\tinit_waitqueue_head(&fs_info->async_submit_wait);\n\tinit_waitqueue_head(&fs_info->delayed_iputs_wait);\n\n\t \n\tfs_info->nodesize = 4096;\n\tfs_info->sectorsize = 4096;\n\tfs_info->sectorsize_bits = ilog2(4096);\n\tfs_info->stripesize = 4096;\n\n\tfs_info->max_extent_size = BTRFS_MAX_EXTENT_SIZE;\n\n\tspin_lock_init(&fs_info->swapfile_pins_lock);\n\tfs_info->swapfile_pins = RB_ROOT;\n\n\tfs_info->bg_reclaim_threshold = BTRFS_DEFAULT_RECLAIM_THRESH;\n\tINIT_WORK(&fs_info->reclaim_bgs_work, btrfs_reclaim_bgs_work);\n}\n\nstatic int init_mount_fs_info(struct btrfs_fs_info *fs_info, struct super_block *sb)\n{\n\tint ret;\n\n\tfs_info->sb = sb;\n\tsb->s_blocksize = BTRFS_BDEV_BLOCKSIZE;\n\tsb->s_blocksize_bits = blksize_bits(BTRFS_BDEV_BLOCKSIZE);\n\n\tret = percpu_counter_init(&fs_info->ordered_bytes, 0, GFP_KERNEL);\n\tif (ret)\n\t\treturn ret;\n\n\tret = percpu_counter_init(&fs_info->dirty_metadata_bytes, 0, GFP_KERNEL);\n\tif (ret)\n\t\treturn ret;\n\n\tfs_info->dirty_metadata_batch = PAGE_SIZE *\n\t\t\t\t\t(1 + ilog2(nr_cpu_ids));\n\n\tret = percpu_counter_init(&fs_info->delalloc_bytes, 0, GFP_KERNEL);\n\tif (ret)\n\t\treturn ret;\n\n\tret = percpu_counter_init(&fs_info->dev_replace.bio_counter, 0,\n\t\t\tGFP_KERNEL);\n\tif (ret)\n\t\treturn ret;\n\n\tfs_info->delayed_root = kmalloc(sizeof(struct btrfs_delayed_root),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!fs_info->delayed_root)\n\t\treturn -ENOMEM;\n\tbtrfs_init_delayed_root(fs_info->delayed_root);\n\n\tif (sb_rdonly(sb))\n\t\tset_bit(BTRFS_FS_STATE_RO, &fs_info->fs_state);\n\n\treturn btrfs_alloc_stripe_hash_table(fs_info);\n}\n\nstatic int btrfs_uuid_rescan_kthread(void *data)\n{\n\tstruct btrfs_fs_info *fs_info = data;\n\tint ret;\n\n\t \n\tret = btrfs_uuid_tree_iterate(fs_info);\n\tif (ret < 0) {\n\t\tif (ret != -EINTR)\n\t\t\tbtrfs_warn(fs_info, \"iterating uuid_tree failed %d\",\n\t\t\t\t   ret);\n\t\tup(&fs_info->uuid_tree_rescan_sem);\n\t\treturn ret;\n\t}\n\treturn btrfs_uuid_scan_kthread(data);\n}\n\nstatic int btrfs_check_uuid_tree(struct btrfs_fs_info *fs_info)\n{\n\tstruct task_struct *task;\n\n\tdown(&fs_info->uuid_tree_rescan_sem);\n\ttask = kthread_run(btrfs_uuid_rescan_kthread, fs_info, \"btrfs-uuid\");\n\tif (IS_ERR(task)) {\n\t\t \n\t\tbtrfs_warn(fs_info, \"failed to start uuid_rescan task\");\n\t\tup(&fs_info->uuid_tree_rescan_sem);\n\t\treturn PTR_ERR(task);\n\t}\n\n\treturn 0;\n}\n\nstatic int btrfs_cleanup_fs_roots(struct btrfs_fs_info *fs_info)\n{\n\tu64 root_objectid = 0;\n\tstruct btrfs_root *gang[8];\n\tint i = 0;\n\tint err = 0;\n\tunsigned int ret = 0;\n\n\twhile (1) {\n\t\tspin_lock(&fs_info->fs_roots_radix_lock);\n\t\tret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,\n\t\t\t\t\t     (void **)gang, root_objectid,\n\t\t\t\t\t     ARRAY_SIZE(gang));\n\t\tif (!ret) {\n\t\t\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\t\t\tbreak;\n\t\t}\n\t\troot_objectid = gang[ret - 1]->root_key.objectid + 1;\n\n\t\tfor (i = 0; i < ret; i++) {\n\t\t\t \n\t\t\tif (btrfs_root_refs(&gang[i]->root_item) == 0) {\n\t\t\t\tgang[i] = NULL;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t \n\t\t\tgang[i] = btrfs_grab_root(gang[i]);\n\t\t}\n\t\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\n\t\tfor (i = 0; i < ret; i++) {\n\t\t\tif (!gang[i])\n\t\t\t\tcontinue;\n\t\t\troot_objectid = gang[i]->root_key.objectid;\n\t\t\terr = btrfs_orphan_cleanup(gang[i]);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t\tbtrfs_put_root(gang[i]);\n\t\t}\n\t\troot_objectid++;\n\t}\nout:\n\t \n\tfor (; i < ret; i++) {\n\t\tif (gang[i])\n\t\t\tbtrfs_put_root(gang[i]);\n\t}\n\treturn err;\n}\n\n \nvoid btrfs_clear_oneshot_options(struct btrfs_fs_info *fs_info)\n{\n\tbtrfs_clear_opt(fs_info->mount_opt, USEBACKUPROOT);\n\tbtrfs_clear_opt(fs_info->mount_opt, CLEAR_CACHE);\n}\n\n \nint btrfs_start_pre_rw_mount(struct btrfs_fs_info *fs_info)\n{\n\tint ret;\n\tconst bool cache_opt = btrfs_test_opt(fs_info, SPACE_CACHE);\n\tbool rebuild_free_space_tree = false;\n\n\tif (btrfs_test_opt(fs_info, CLEAR_CACHE) &&\n\t    btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {\n\t\trebuild_free_space_tree = true;\n\t} else if (btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE) &&\n\t\t   !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE_VALID)) {\n\t\tbtrfs_warn(fs_info, \"free space tree is invalid\");\n\t\trebuild_free_space_tree = true;\n\t}\n\n\tif (rebuild_free_space_tree) {\n\t\tbtrfs_info(fs_info, \"rebuilding free space tree\");\n\t\tret = btrfs_rebuild_free_space_tree(fs_info);\n\t\tif (ret) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t   \"failed to rebuild free space tree: %d\", ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE) &&\n\t    !btrfs_test_opt(fs_info, FREE_SPACE_TREE)) {\n\t\tbtrfs_info(fs_info, \"disabling free space tree\");\n\t\tret = btrfs_delete_free_space_tree(fs_info);\n\t\tif (ret) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t   \"failed to disable free space tree: %d\", ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tret = btrfs_find_orphan_roots(fs_info);\n\tif (ret)\n\t\tgoto out;\n\n\tret = btrfs_cleanup_fs_roots(fs_info);\n\tif (ret)\n\t\tgoto out;\n\n\tdown_read(&fs_info->cleanup_work_sem);\n\tif ((ret = btrfs_orphan_cleanup(fs_info->fs_root)) ||\n\t    (ret = btrfs_orphan_cleanup(fs_info->tree_root))) {\n\t\tup_read(&fs_info->cleanup_work_sem);\n\t\tgoto out;\n\t}\n\tup_read(&fs_info->cleanup_work_sem);\n\n\tmutex_lock(&fs_info->cleaner_mutex);\n\tret = btrfs_recover_relocation(fs_info);\n\tmutex_unlock(&fs_info->cleaner_mutex);\n\tif (ret < 0) {\n\t\tbtrfs_warn(fs_info, \"failed to recover relocation: %d\", ret);\n\t\tgoto out;\n\t}\n\n\tif (btrfs_test_opt(fs_info, FREE_SPACE_TREE) &&\n\t    !btrfs_fs_compat_ro(fs_info, FREE_SPACE_TREE)) {\n\t\tbtrfs_info(fs_info, \"creating free space tree\");\n\t\tret = btrfs_create_free_space_tree(fs_info);\n\t\tif (ret) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t\"failed to create free space tree: %d\", ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (cache_opt != btrfs_free_space_cache_v1_active(fs_info)) {\n\t\tret = btrfs_set_free_space_cache_v1_active(fs_info, cache_opt);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tret = btrfs_resume_balance_async(fs_info);\n\tif (ret)\n\t\tgoto out;\n\n\tret = btrfs_resume_dev_replace_async(fs_info);\n\tif (ret) {\n\t\tbtrfs_warn(fs_info, \"failed to resume dev_replace\");\n\t\tgoto out;\n\t}\n\n\tbtrfs_qgroup_rescan_resume(fs_info);\n\n\tif (!fs_info->uuid_root) {\n\t\tbtrfs_info(fs_info, \"creating UUID tree\");\n\t\tret = btrfs_create_uuid_tree(fs_info);\n\t\tif (ret) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t   \"failed to create the UUID tree %d\", ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}\n\n \nint btrfs_check_features(struct btrfs_fs_info *fs_info, bool is_rw_mount)\n{\n\tstruct btrfs_super_block *disk_super = fs_info->super_copy;\n\tu64 incompat = btrfs_super_incompat_flags(disk_super);\n\tconst u64 compat_ro = btrfs_super_compat_ro_flags(disk_super);\n\tconst u64 compat_ro_unsupp = (compat_ro & ~BTRFS_FEATURE_COMPAT_RO_SUPP);\n\n\tif (incompat & ~BTRFS_FEATURE_INCOMPAT_SUPP) {\n\t\tbtrfs_err(fs_info,\n\t\t\"cannot mount because of unknown incompat features (0x%llx)\",\n\t\t    incompat);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif ((incompat & BTRFS_FEATURE_INCOMPAT_MIXED_GROUPS) &&\n\t    (fs_info->sectorsize != fs_info->nodesize)) {\n\t\tbtrfs_err(fs_info,\n\"unequal nodesize/sectorsize (%u != %u) are not allowed for mixed block groups\",\n\t\t\tfs_info->nodesize, fs_info->sectorsize);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tincompat |= BTRFS_FEATURE_INCOMPAT_MIXED_BACKREF;\n\n\t \n\tif (fs_info->compress_type == BTRFS_COMPRESS_LZO)\n\t\tincompat |= BTRFS_FEATURE_INCOMPAT_COMPRESS_LZO;\n\telse if (fs_info->compress_type == BTRFS_COMPRESS_ZSTD)\n\t\tincompat |= BTRFS_FEATURE_INCOMPAT_COMPRESS_ZSTD;\n\n\t \n\tif (btrfs_super_nodesize(disk_super) > PAGE_SIZE)\n\t\tincompat |= BTRFS_FEATURE_INCOMPAT_BIG_METADATA;\n\n\tif (compat_ro_unsupp && is_rw_mount) {\n\t\tbtrfs_err(fs_info,\n\t\"cannot mount read-write because of unknown compat_ro features (0x%llx)\",\n\t\t       compat_ro);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (compat_ro_unsupp && btrfs_super_log_root(disk_super) &&\n\t    !btrfs_test_opt(fs_info, NOLOGREPLAY)) {\n\t\tbtrfs_err(fs_info,\n\"cannot replay dirty log with unsupported compat_ro features (0x%llx), try rescue=nologreplay\",\n\t\t\t  compat_ro);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (btrfs_fs_compat_ro(fs_info, BLOCK_GROUP_TREE) &&\n\t    (!btrfs_fs_incompat(fs_info, NO_HOLES) ||\n\t     !btrfs_test_opt(fs_info, FREE_SPACE_TREE))) {\n\t\tbtrfs_err(fs_info,\n\"block-group-tree feature requires no-holes and free-space-tree features\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (fs_info->sectorsize < PAGE_SIZE && btrfs_test_opt(fs_info, SPACE_CACHE)) {\n\t\tbtrfs_warn(fs_info,\n\t\"v1 space cache is not supported for page size %lu with sectorsize %u\",\n\t\t\t   PAGE_SIZE, fs_info->sectorsize);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tspin_lock(&fs_info->super_lock);\n\tbtrfs_set_super_incompat_flags(disk_super, incompat);\n\tspin_unlock(&fs_info->super_lock);\n\n\treturn 0;\n}\n\nint __cold open_ctree(struct super_block *sb, struct btrfs_fs_devices *fs_devices,\n\t\t      char *options)\n{\n\tu32 sectorsize;\n\tu32 nodesize;\n\tu32 stripesize;\n\tu64 generation;\n\tu64 features;\n\tu16 csum_type;\n\tstruct btrfs_super_block *disk_super;\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(sb);\n\tstruct btrfs_root *tree_root;\n\tstruct btrfs_root *chunk_root;\n\tint ret;\n\tint level;\n\n\tret = init_mount_fs_info(fs_info, sb);\n\tif (ret)\n\t\tgoto fail;\n\n\t \n\ttree_root = btrfs_alloc_root(fs_info, BTRFS_ROOT_TREE_OBJECTID,\n\t\t\t\t     GFP_KERNEL);\n\tfs_info->tree_root = tree_root;\n\tchunk_root = btrfs_alloc_root(fs_info, BTRFS_CHUNK_TREE_OBJECTID,\n\t\t\t\t      GFP_KERNEL);\n\tfs_info->chunk_root = chunk_root;\n\tif (!tree_root || !chunk_root) {\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\tret = btrfs_init_btree_inode(sb);\n\tif (ret)\n\t\tgoto fail;\n\n\tinvalidate_bdev(fs_devices->latest_dev->bdev);\n\n\t \n\tdisk_super = btrfs_read_dev_super(fs_devices->latest_dev->bdev);\n\tif (IS_ERR(disk_super)) {\n\t\tret = PTR_ERR(disk_super);\n\t\tgoto fail_alloc;\n\t}\n\n\tbtrfs_info(fs_info, \"first mount of filesystem %pU\", disk_super->fsid);\n\t \n\tcsum_type = btrfs_super_csum_type(disk_super);\n\tif (!btrfs_supported_super_csum(csum_type)) {\n\t\tbtrfs_err(fs_info, \"unsupported checksum algorithm: %u\",\n\t\t\t  csum_type);\n\t\tret = -EINVAL;\n\t\tbtrfs_release_disk_super(disk_super);\n\t\tgoto fail_alloc;\n\t}\n\n\tfs_info->csum_size = btrfs_super_csum_size(disk_super);\n\n\tret = btrfs_init_csum_hash(fs_info, csum_type);\n\tif (ret) {\n\t\tbtrfs_release_disk_super(disk_super);\n\t\tgoto fail_alloc;\n\t}\n\n\t \n\tif (btrfs_check_super_csum(fs_info, disk_super)) {\n\t\tbtrfs_err(fs_info, \"superblock checksum mismatch\");\n\t\tret = -EINVAL;\n\t\tbtrfs_release_disk_super(disk_super);\n\t\tgoto fail_alloc;\n\t}\n\n\t \n\tmemcpy(fs_info->super_copy, disk_super, sizeof(*fs_info->super_copy));\n\tbtrfs_release_disk_super(disk_super);\n\n\tdisk_super = fs_info->super_copy;\n\n\n\tfeatures = btrfs_super_flags(disk_super);\n\tif (features & BTRFS_SUPER_FLAG_CHANGING_FSID_V2) {\n\t\tfeatures &= ~BTRFS_SUPER_FLAG_CHANGING_FSID_V2;\n\t\tbtrfs_set_super_flags(disk_super, features);\n\t\tbtrfs_info(fs_info,\n\t\t\t\"found metadata UUID change in progress flag, clearing\");\n\t}\n\n\tmemcpy(fs_info->super_for_commit, fs_info->super_copy,\n\t       sizeof(*fs_info->super_for_commit));\n\n\tret = btrfs_validate_mount_super(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"superblock contains fatal errors\");\n\t\tret = -EINVAL;\n\t\tgoto fail_alloc;\n\t}\n\n\tif (!btrfs_super_root(disk_super)) {\n\t\tbtrfs_err(fs_info, \"invalid superblock tree root bytenr\");\n\t\tret = -EINVAL;\n\t\tgoto fail_alloc;\n\t}\n\n\t \n\tif (btrfs_super_flags(disk_super) & BTRFS_SUPER_FLAG_ERROR)\n\t\tWRITE_ONCE(fs_info->fs_error, -EUCLEAN);\n\n\t \n\tfs_info->compress_type = BTRFS_COMPRESS_ZLIB;\n\n\n\t \n\tnodesize = btrfs_super_nodesize(disk_super);\n\tsectorsize = btrfs_super_sectorsize(disk_super);\n\tstripesize = sectorsize;\n\tfs_info->dirty_metadata_batch = nodesize * (1 + ilog2(nr_cpu_ids));\n\tfs_info->delalloc_batch = sectorsize * 512 * (1 + ilog2(nr_cpu_ids));\n\n\tfs_info->nodesize = nodesize;\n\tfs_info->sectorsize = sectorsize;\n\tfs_info->sectorsize_bits = ilog2(sectorsize);\n\tfs_info->csums_per_leaf = BTRFS_MAX_ITEM_SIZE(fs_info) / fs_info->csum_size;\n\tfs_info->stripesize = stripesize;\n\n\tret = btrfs_parse_options(fs_info, options, sb->s_flags);\n\tif (ret)\n\t\tgoto fail_alloc;\n\n\tret = btrfs_check_features(fs_info, !sb_rdonly(sb));\n\tif (ret < 0)\n\t\tgoto fail_alloc;\n\n\tif (sectorsize < PAGE_SIZE) {\n\t\tstruct btrfs_subpage_info *subpage_info;\n\n\t\t \n\t\tbtrfs_clear_opt(fs_info->mount_opt, SPACE_CACHE);\n\t\tbtrfs_set_and_info(fs_info, FREE_SPACE_TREE,\n\t\t\t\"forcing free space tree for sector size %u with page size %lu\",\n\t\t\tsectorsize, PAGE_SIZE);\n\n\t\tbtrfs_warn(fs_info,\n\t\t\"read-write for sector size %u with page size %lu is experimental\",\n\t\t\t   sectorsize, PAGE_SIZE);\n\t\tsubpage_info = kzalloc(sizeof(*subpage_info), GFP_KERNEL);\n\t\tif (!subpage_info) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail_alloc;\n\t\t}\n\t\tbtrfs_init_subpage_info(subpage_info, sectorsize);\n\t\tfs_info->subpage_info = subpage_info;\n\t}\n\n\tret = btrfs_init_workqueues(fs_info);\n\tif (ret)\n\t\tgoto fail_sb_buffer;\n\n\tsb->s_bdi->ra_pages *= btrfs_super_num_devices(disk_super);\n\tsb->s_bdi->ra_pages = max(sb->s_bdi->ra_pages, SZ_4M / PAGE_SIZE);\n\n\tsb->s_blocksize = sectorsize;\n\tsb->s_blocksize_bits = blksize_bits(sectorsize);\n\tmemcpy(&sb->s_uuid, fs_info->fs_devices->fsid, BTRFS_FSID_SIZE);\n\n\tmutex_lock(&fs_info->chunk_mutex);\n\tret = btrfs_read_sys_array(fs_info);\n\tmutex_unlock(&fs_info->chunk_mutex);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to read the system array: %d\", ret);\n\t\tgoto fail_sb_buffer;\n\t}\n\n\tgeneration = btrfs_super_chunk_root_generation(disk_super);\n\tlevel = btrfs_super_chunk_root_level(disk_super);\n\tret = load_super_root(chunk_root, btrfs_super_chunk_root(disk_super),\n\t\t\t      generation, level);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to read chunk root\");\n\t\tgoto fail_tree_roots;\n\t}\n\n\tread_extent_buffer(chunk_root->node, fs_info->chunk_tree_uuid,\n\t\t\t   offsetof(struct btrfs_header, chunk_tree_uuid),\n\t\t\t   BTRFS_UUID_SIZE);\n\n\tret = btrfs_read_chunk_tree(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to read chunk tree: %d\", ret);\n\t\tgoto fail_tree_roots;\n\t}\n\n\t \n\tbtrfs_free_extra_devids(fs_devices);\n\tif (!fs_devices->latest_dev->bdev) {\n\t\tbtrfs_err(fs_info, \"failed to read devices\");\n\t\tret = -EIO;\n\t\tgoto fail_tree_roots;\n\t}\n\n\tret = init_tree_roots(fs_info);\n\tif (ret)\n\t\tgoto fail_tree_roots;\n\n\t \n\tret = btrfs_get_dev_zone_info_all_devices(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"zoned: failed to read device zone info: %d\", ret);\n\t\tgoto fail_block_groups;\n\t}\n\n\t \n\tif (fs_info->uuid_root && !btrfs_test_opt(fs_info, RESCAN_UUID_TREE) &&\n\t    fs_info->generation == btrfs_super_uuid_tree_generation(disk_super))\n\t\tset_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &fs_info->flags);\n\n\tret = btrfs_verify_dev_extents(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"failed to verify dev extents against chunks: %d\",\n\t\t\t  ret);\n\t\tgoto fail_block_groups;\n\t}\n\tret = btrfs_recover_balance(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to recover balance: %d\", ret);\n\t\tgoto fail_block_groups;\n\t}\n\n\tret = btrfs_init_dev_stats(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to init dev_stats: %d\", ret);\n\t\tgoto fail_block_groups;\n\t}\n\n\tret = btrfs_init_dev_replace(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to init dev_replace: %d\", ret);\n\t\tgoto fail_block_groups;\n\t}\n\n\tret = btrfs_check_zoned_mode(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to initialize zoned mode: %d\",\n\t\t\t  ret);\n\t\tgoto fail_block_groups;\n\t}\n\n\tret = btrfs_sysfs_add_fsid(fs_devices);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to init sysfs fsid interface: %d\",\n\t\t\t\tret);\n\t\tgoto fail_block_groups;\n\t}\n\n\tret = btrfs_sysfs_add_mounted(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to init sysfs interface: %d\", ret);\n\t\tgoto fail_fsdev_sysfs;\n\t}\n\n\tret = btrfs_init_space_info(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to initialize space info: %d\", ret);\n\t\tgoto fail_sysfs;\n\t}\n\n\tret = btrfs_read_block_groups(fs_info);\n\tif (ret) {\n\t\tbtrfs_err(fs_info, \"failed to read block groups: %d\", ret);\n\t\tgoto fail_sysfs;\n\t}\n\n\tbtrfs_free_zone_cache(fs_info);\n\n\tbtrfs_check_active_zone_reservation(fs_info);\n\n\tif (!sb_rdonly(sb) && fs_info->fs_devices->missing_devices &&\n\t    !btrfs_check_rw_degradable(fs_info, NULL)) {\n\t\tbtrfs_warn(fs_info,\n\t\t\"writable mount is not allowed due to too many missing devices\");\n\t\tret = -EINVAL;\n\t\tgoto fail_sysfs;\n\t}\n\n\tfs_info->cleaner_kthread = kthread_run(cleaner_kthread, fs_info,\n\t\t\t\t\t       \"btrfs-cleaner\");\n\tif (IS_ERR(fs_info->cleaner_kthread)) {\n\t\tret = PTR_ERR(fs_info->cleaner_kthread);\n\t\tgoto fail_sysfs;\n\t}\n\n\tfs_info->transaction_kthread = kthread_run(transaction_kthread,\n\t\t\t\t\t\t   tree_root,\n\t\t\t\t\t\t   \"btrfs-transaction\");\n\tif (IS_ERR(fs_info->transaction_kthread)) {\n\t\tret = PTR_ERR(fs_info->transaction_kthread);\n\t\tgoto fail_cleaner;\n\t}\n\n\tif (!btrfs_test_opt(fs_info, NOSSD) &&\n\t    !fs_info->fs_devices->rotating) {\n\t\tbtrfs_set_and_info(fs_info, SSD, \"enabling ssd optimizations\");\n\t}\n\n\t \n\tif (!(btrfs_test_opt(fs_info, DISCARD_SYNC) ||\n\t      btrfs_test_opt(fs_info, DISCARD_ASYNC) ||\n\t      btrfs_test_opt(fs_info, NODISCARD)) &&\n\t    fs_info->fs_devices->discardable &&\n\t    !btrfs_is_zoned(fs_info)) {\n\t\tbtrfs_set_and_info(fs_info, DISCARD_ASYNC,\n\t\t\t\t   \"auto enabling async discard\");\n\t}\n\n#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY\n\tif (btrfs_test_opt(fs_info, CHECK_INTEGRITY)) {\n\t\tret = btrfsic_mount(fs_info, fs_devices,\n\t\t\t\t    btrfs_test_opt(fs_info,\n\t\t\t\t\tCHECK_INTEGRITY_DATA) ? 1 : 0,\n\t\t\t\t    fs_info->check_integrity_print_mask);\n\t\tif (ret)\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t\"failed to initialize integrity check module: %d\",\n\t\t\t\tret);\n\t}\n#endif\n\tret = btrfs_read_qgroup_config(fs_info);\n\tif (ret)\n\t\tgoto fail_trans_kthread;\n\n\tif (btrfs_build_ref_tree(fs_info))\n\t\tbtrfs_err(fs_info, \"couldn't build ref tree\");\n\n\t \n\tif (btrfs_super_log_root(disk_super) != 0 &&\n\t    !btrfs_test_opt(fs_info, NOLOGREPLAY)) {\n\t\tbtrfs_info(fs_info, \"start tree-log replay\");\n\t\tret = btrfs_replay_log(fs_info, fs_devices);\n\t\tif (ret)\n\t\t\tgoto fail_qgroup;\n\t}\n\n\tfs_info->fs_root = btrfs_get_fs_root(fs_info, BTRFS_FS_TREE_OBJECTID, true);\n\tif (IS_ERR(fs_info->fs_root)) {\n\t\tret = PTR_ERR(fs_info->fs_root);\n\t\tbtrfs_warn(fs_info, \"failed to read fs tree: %d\", ret);\n\t\tfs_info->fs_root = NULL;\n\t\tgoto fail_qgroup;\n\t}\n\n\tif (sb_rdonly(sb))\n\t\tgoto clear_oneshot;\n\n\tret = btrfs_start_pre_rw_mount(fs_info);\n\tif (ret) {\n\t\tclose_ctree(fs_info);\n\t\treturn ret;\n\t}\n\tbtrfs_discard_resume(fs_info);\n\n\tif (fs_info->uuid_root &&\n\t    (btrfs_test_opt(fs_info, RESCAN_UUID_TREE) ||\n\t     fs_info->generation != btrfs_super_uuid_tree_generation(disk_super))) {\n\t\tbtrfs_info(fs_info, \"checking UUID tree\");\n\t\tret = btrfs_check_uuid_tree(fs_info);\n\t\tif (ret) {\n\t\t\tbtrfs_warn(fs_info,\n\t\t\t\t\"failed to check the UUID tree: %d\", ret);\n\t\t\tclose_ctree(fs_info);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tset_bit(BTRFS_FS_OPEN, &fs_info->flags);\n\n\t \n\tif (test_bit(BTRFS_FS_UNFINISHED_DROPS, &fs_info->flags))\n\t\twake_up_process(fs_info->cleaner_kthread);\n\nclear_oneshot:\n\tbtrfs_clear_oneshot_options(fs_info);\n\treturn 0;\n\nfail_qgroup:\n\tbtrfs_free_qgroup_config(fs_info);\nfail_trans_kthread:\n\tkthread_stop(fs_info->transaction_kthread);\n\tbtrfs_cleanup_transaction(fs_info);\n\tbtrfs_free_fs_roots(fs_info);\nfail_cleaner:\n\tkthread_stop(fs_info->cleaner_kthread);\n\n\t \n\tfilemap_write_and_wait(fs_info->btree_inode->i_mapping);\n\nfail_sysfs:\n\tbtrfs_sysfs_remove_mounted(fs_info);\n\nfail_fsdev_sysfs:\n\tbtrfs_sysfs_remove_fsid(fs_info->fs_devices);\n\nfail_block_groups:\n\tbtrfs_put_block_group_cache(fs_info);\n\nfail_tree_roots:\n\tif (fs_info->data_reloc_root)\n\t\tbtrfs_drop_and_free_fs_root(fs_info, fs_info->data_reloc_root);\n\tfree_root_pointers(fs_info, true);\n\tinvalidate_inode_pages2(fs_info->btree_inode->i_mapping);\n\nfail_sb_buffer:\n\tbtrfs_stop_all_workers(fs_info);\n\tbtrfs_free_block_groups(fs_info);\nfail_alloc:\n\tbtrfs_mapping_tree_free(&fs_info->mapping_tree);\n\n\tiput(fs_info->btree_inode);\nfail:\n\tbtrfs_close_devices(fs_info->fs_devices);\n\tASSERT(ret < 0);\n\treturn ret;\n}\nALLOW_ERROR_INJECTION(open_ctree, ERRNO);\n\nstatic void btrfs_end_super_write(struct bio *bio)\n{\n\tstruct btrfs_device *device = bio->bi_private;\n\tstruct bio_vec *bvec;\n\tstruct bvec_iter_all iter_all;\n\tstruct page *page;\n\n\tbio_for_each_segment_all(bvec, bio, iter_all) {\n\t\tpage = bvec->bv_page;\n\n\t\tif (bio->bi_status) {\n\t\t\tbtrfs_warn_rl_in_rcu(device->fs_info,\n\t\t\t\t\"lost page write due to IO error on %s (%d)\",\n\t\t\t\tbtrfs_dev_name(device),\n\t\t\t\tblk_status_to_errno(bio->bi_status));\n\t\t\tClearPageUptodate(page);\n\t\t\tSetPageError(page);\n\t\t\tbtrfs_dev_stat_inc_and_print(device,\n\t\t\t\t\t\t     BTRFS_DEV_STAT_WRITE_ERRS);\n\t\t} else {\n\t\t\tSetPageUptodate(page);\n\t\t}\n\n\t\tput_page(page);\n\t\tunlock_page(page);\n\t}\n\n\tbio_put(bio);\n}\n\nstruct btrfs_super_block *btrfs_read_dev_one_super(struct block_device *bdev,\n\t\t\t\t\t\t   int copy_num, bool drop_cache)\n{\n\tstruct btrfs_super_block *super;\n\tstruct page *page;\n\tu64 bytenr, bytenr_orig;\n\tstruct address_space *mapping = bdev->bd_inode->i_mapping;\n\tint ret;\n\n\tbytenr_orig = btrfs_sb_offset(copy_num);\n\tret = btrfs_sb_log_location_bdev(bdev, copy_num, READ, &bytenr);\n\tif (ret == -ENOENT)\n\t\treturn ERR_PTR(-EINVAL);\n\telse if (ret)\n\t\treturn ERR_PTR(ret);\n\n\tif (bytenr + BTRFS_SUPER_INFO_SIZE >= bdev_nr_bytes(bdev))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (drop_cache) {\n\t\t \n\t\tASSERT(copy_num == 0);\n\n\t\t \n\t\tinvalidate_inode_pages2_range(mapping,\n\t\t\t\tbytenr >> PAGE_SHIFT,\n\t\t\t\t(bytenr + BTRFS_SUPER_INFO_SIZE) >> PAGE_SHIFT);\n\t}\n\n\tpage = read_cache_page_gfp(mapping, bytenr >> PAGE_SHIFT, GFP_NOFS);\n\tif (IS_ERR(page))\n\t\treturn ERR_CAST(page);\n\n\tsuper = page_address(page);\n\tif (btrfs_super_magic(super) != BTRFS_MAGIC) {\n\t\tbtrfs_release_disk_super(super);\n\t\treturn ERR_PTR(-ENODATA);\n\t}\n\n\tif (btrfs_super_bytenr(super) != bytenr_orig) {\n\t\tbtrfs_release_disk_super(super);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\treturn super;\n}\n\n\nstruct btrfs_super_block *btrfs_read_dev_super(struct block_device *bdev)\n{\n\tstruct btrfs_super_block *super, *latest = NULL;\n\tint i;\n\tu64 transid = 0;\n\n\t \n\tfor (i = 0; i < 1; i++) {\n\t\tsuper = btrfs_read_dev_one_super(bdev, i, false);\n\t\tif (IS_ERR(super))\n\t\t\tcontinue;\n\n\t\tif (!latest || btrfs_super_generation(super) > transid) {\n\t\t\tif (latest)\n\t\t\t\tbtrfs_release_disk_super(super);\n\n\t\t\tlatest = super;\n\t\t\ttransid = btrfs_super_generation(super);\n\t\t}\n\t}\n\n\treturn super;\n}\n\n \nstatic int write_dev_supers(struct btrfs_device *device,\n\t\t\t    struct btrfs_super_block *sb, int max_mirrors)\n{\n\tstruct btrfs_fs_info *fs_info = device->fs_info;\n\tstruct address_space *mapping = device->bdev->bd_inode->i_mapping;\n\tSHASH_DESC_ON_STACK(shash, fs_info->csum_shash);\n\tint i;\n\tint errors = 0;\n\tint ret;\n\tu64 bytenr, bytenr_orig;\n\n\tif (max_mirrors == 0)\n\t\tmax_mirrors = BTRFS_SUPER_MIRROR_MAX;\n\n\tshash->tfm = fs_info->csum_shash;\n\n\tfor (i = 0; i < max_mirrors; i++) {\n\t\tstruct page *page;\n\t\tstruct bio *bio;\n\t\tstruct btrfs_super_block *disk_super;\n\n\t\tbytenr_orig = btrfs_sb_offset(i);\n\t\tret = btrfs_sb_log_location(device, i, WRITE, &bytenr);\n\t\tif (ret == -ENOENT) {\n\t\t\tcontinue;\n\t\t} else if (ret < 0) {\n\t\t\tbtrfs_err(device->fs_info,\n\t\t\t\t\"couldn't get super block location for mirror %d\",\n\t\t\t\ti);\n\t\t\terrors++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (bytenr + BTRFS_SUPER_INFO_SIZE >=\n\t\t    device->commit_total_bytes)\n\t\t\tbreak;\n\n\t\tbtrfs_set_super_bytenr(sb, bytenr_orig);\n\n\t\tcrypto_shash_digest(shash, (const char *)sb + BTRFS_CSUM_SIZE,\n\t\t\t\t    BTRFS_SUPER_INFO_SIZE - BTRFS_CSUM_SIZE,\n\t\t\t\t    sb->csum);\n\n\t\tpage = find_or_create_page(mapping, bytenr >> PAGE_SHIFT,\n\t\t\t\t\t   GFP_NOFS);\n\t\tif (!page) {\n\t\t\tbtrfs_err(device->fs_info,\n\t\t\t    \"couldn't get super block page for bytenr %llu\",\n\t\t\t    bytenr);\n\t\t\terrors++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tget_page(page);\n\n\t\tdisk_super = page_address(page);\n\t\tmemcpy(disk_super, sb, BTRFS_SUPER_INFO_SIZE);\n\n\t\t \n\t\tbio = bio_alloc(device->bdev, 1,\n\t\t\t\tREQ_OP_WRITE | REQ_SYNC | REQ_META | REQ_PRIO,\n\t\t\t\tGFP_NOFS);\n\t\tbio->bi_iter.bi_sector = bytenr >> SECTOR_SHIFT;\n\t\tbio->bi_private = device;\n\t\tbio->bi_end_io = btrfs_end_super_write;\n\t\t__bio_add_page(bio, page, BTRFS_SUPER_INFO_SIZE,\n\t\t\t       offset_in_page(bytenr));\n\n\t\t \n\t\tif (i == 0 && !btrfs_test_opt(device->fs_info, NOBARRIER))\n\t\t\tbio->bi_opf |= REQ_FUA;\n\n\t\tbtrfsic_check_bio(bio);\n\t\tsubmit_bio(bio);\n\n\t\tif (btrfs_advance_sb_log(device, i))\n\t\t\terrors++;\n\t}\n\treturn errors < i ? 0 : -1;\n}\n\n \nstatic int wait_dev_supers(struct btrfs_device *device, int max_mirrors)\n{\n\tint i;\n\tint errors = 0;\n\tbool primary_failed = false;\n\tint ret;\n\tu64 bytenr;\n\n\tif (max_mirrors == 0)\n\t\tmax_mirrors = BTRFS_SUPER_MIRROR_MAX;\n\n\tfor (i = 0; i < max_mirrors; i++) {\n\t\tstruct page *page;\n\n\t\tret = btrfs_sb_log_location(device, i, READ, &bytenr);\n\t\tif (ret == -ENOENT) {\n\t\t\tbreak;\n\t\t} else if (ret < 0) {\n\t\t\terrors++;\n\t\t\tif (i == 0)\n\t\t\t\tprimary_failed = true;\n\t\t\tcontinue;\n\t\t}\n\t\tif (bytenr + BTRFS_SUPER_INFO_SIZE >=\n\t\t    device->commit_total_bytes)\n\t\t\tbreak;\n\n\t\tpage = find_get_page(device->bdev->bd_inode->i_mapping,\n\t\t\t\t     bytenr >> PAGE_SHIFT);\n\t\tif (!page) {\n\t\t\terrors++;\n\t\t\tif (i == 0)\n\t\t\t\tprimary_failed = true;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\twait_on_page_locked(page);\n\t\tif (PageError(page)) {\n\t\t\terrors++;\n\t\t\tif (i == 0)\n\t\t\t\tprimary_failed = true;\n\t\t}\n\n\t\t \n\t\tput_page(page);\n\n\t\t \n\t\tput_page(page);\n\t}\n\n\t \n\tif (primary_failed) {\n\t\tbtrfs_err(device->fs_info, \"error writing primary super block to device %llu\",\n\t\t\t  device->devid);\n\t\treturn -1;\n\t}\n\n\treturn errors < i ? 0 : -1;\n}\n\n \nstatic void btrfs_end_empty_barrier(struct bio *bio)\n{\n\tbio_uninit(bio);\n\tcomplete(bio->bi_private);\n}\n\n \nstatic void write_dev_flush(struct btrfs_device *device)\n{\n\tstruct bio *bio = &device->flush_bio;\n\n\tdevice->last_flush_error = BLK_STS_OK;\n\n#ifndef CONFIG_BTRFS_FS_CHECK_INTEGRITY\n\t \n\tif (!bdev_write_cache(device->bdev))\n\t\treturn;\n#endif\n\n\tbio_init(bio, device->bdev, NULL, 0,\n\t\t REQ_OP_WRITE | REQ_SYNC | REQ_PREFLUSH);\n\tbio->bi_end_io = btrfs_end_empty_barrier;\n\tinit_completion(&device->flush_wait);\n\tbio->bi_private = &device->flush_wait;\n\n\tbtrfsic_check_bio(bio);\n\tsubmit_bio(bio);\n\tset_bit(BTRFS_DEV_STATE_FLUSH_SENT, &device->dev_state);\n}\n\n \nstatic bool wait_dev_flush(struct btrfs_device *device)\n{\n\tstruct bio *bio = &device->flush_bio;\n\n\tif (!test_and_clear_bit(BTRFS_DEV_STATE_FLUSH_SENT, &device->dev_state))\n\t\treturn false;\n\n\twait_for_completion_io(&device->flush_wait);\n\n\tif (bio->bi_status) {\n\t\tdevice->last_flush_error = bio->bi_status;\n\t\tbtrfs_dev_stat_inc_and_print(device, BTRFS_DEV_STAT_FLUSH_ERRS);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic int barrier_all_devices(struct btrfs_fs_info *info)\n{\n\tstruct list_head *head;\n\tstruct btrfs_device *dev;\n\tint errors_wait = 0;\n\n\tlockdep_assert_held(&info->fs_devices->device_list_mutex);\n\t \n\thead = &info->fs_devices->devices;\n\tlist_for_each_entry(dev, head, dev_list) {\n\t\tif (test_bit(BTRFS_DEV_STATE_MISSING, &dev->dev_state))\n\t\t\tcontinue;\n\t\tif (!dev->bdev)\n\t\t\tcontinue;\n\t\tif (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||\n\t\t    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))\n\t\t\tcontinue;\n\n\t\twrite_dev_flush(dev);\n\t}\n\n\t \n\tlist_for_each_entry(dev, head, dev_list) {\n\t\tif (test_bit(BTRFS_DEV_STATE_MISSING, &dev->dev_state))\n\t\t\tcontinue;\n\t\tif (!dev->bdev) {\n\t\t\terrors_wait++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||\n\t\t    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))\n\t\t\tcontinue;\n\n\t\tif (wait_dev_flush(dev))\n\t\t\terrors_wait++;\n\t}\n\n\t \n\tif (errors_wait && !btrfs_check_rw_degradable(info, NULL))\n\t\treturn -EIO;\n\n\treturn 0;\n}\n\nint btrfs_get_num_tolerated_disk_barrier_failures(u64 flags)\n{\n\tint raid_type;\n\tint min_tolerated = INT_MAX;\n\n\tif ((flags & BTRFS_BLOCK_GROUP_PROFILE_MASK) == 0 ||\n\t    (flags & BTRFS_AVAIL_ALLOC_BIT_SINGLE))\n\t\tmin_tolerated = min_t(int, min_tolerated,\n\t\t\t\t    btrfs_raid_array[BTRFS_RAID_SINGLE].\n\t\t\t\t    tolerated_failures);\n\n\tfor (raid_type = 0; raid_type < BTRFS_NR_RAID_TYPES; raid_type++) {\n\t\tif (raid_type == BTRFS_RAID_SINGLE)\n\t\t\tcontinue;\n\t\tif (!(flags & btrfs_raid_array[raid_type].bg_flag))\n\t\t\tcontinue;\n\t\tmin_tolerated = min_t(int, min_tolerated,\n\t\t\t\t    btrfs_raid_array[raid_type].\n\t\t\t\t    tolerated_failures);\n\t}\n\n\tif (min_tolerated == INT_MAX) {\n\t\tpr_warn(\"BTRFS: unknown raid flag: %llu\", flags);\n\t\tmin_tolerated = 0;\n\t}\n\n\treturn min_tolerated;\n}\n\nint write_all_supers(struct btrfs_fs_info *fs_info, int max_mirrors)\n{\n\tstruct list_head *head;\n\tstruct btrfs_device *dev;\n\tstruct btrfs_super_block *sb;\n\tstruct btrfs_dev_item *dev_item;\n\tint ret;\n\tint do_barriers;\n\tint max_errors;\n\tint total_errors = 0;\n\tu64 flags;\n\n\tdo_barriers = !btrfs_test_opt(fs_info, NOBARRIER);\n\n\t \n\tif (max_mirrors == 0)\n\t\tbackup_super_roots(fs_info);\n\n\tsb = fs_info->super_for_commit;\n\tdev_item = &sb->dev_item;\n\n\tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n\thead = &fs_info->fs_devices->devices;\n\tmax_errors = btrfs_super_num_devices(fs_info->super_copy) - 1;\n\n\tif (do_barriers) {\n\t\tret = barrier_all_devices(fs_info);\n\t\tif (ret) {\n\t\t\tmutex_unlock(\n\t\t\t\t&fs_info->fs_devices->device_list_mutex);\n\t\t\tbtrfs_handle_fs_error(fs_info, ret,\n\t\t\t\t\t      \"errors while submitting device barriers.\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tlist_for_each_entry(dev, head, dev_list) {\n\t\tif (!dev->bdev) {\n\t\t\ttotal_errors++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||\n\t\t    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))\n\t\t\tcontinue;\n\n\t\tbtrfs_set_stack_device_generation(dev_item, 0);\n\t\tbtrfs_set_stack_device_type(dev_item, dev->type);\n\t\tbtrfs_set_stack_device_id(dev_item, dev->devid);\n\t\tbtrfs_set_stack_device_total_bytes(dev_item,\n\t\t\t\t\t\t   dev->commit_total_bytes);\n\t\tbtrfs_set_stack_device_bytes_used(dev_item,\n\t\t\t\t\t\t  dev->commit_bytes_used);\n\t\tbtrfs_set_stack_device_io_align(dev_item, dev->io_align);\n\t\tbtrfs_set_stack_device_io_width(dev_item, dev->io_width);\n\t\tbtrfs_set_stack_device_sector_size(dev_item, dev->sector_size);\n\t\tmemcpy(dev_item->uuid, dev->uuid, BTRFS_UUID_SIZE);\n\t\tmemcpy(dev_item->fsid, dev->fs_devices->metadata_uuid,\n\t\t       BTRFS_FSID_SIZE);\n\n\t\tflags = btrfs_super_flags(sb);\n\t\tbtrfs_set_super_flags(sb, flags | BTRFS_HEADER_FLAG_WRITTEN);\n\n\t\tret = btrfs_validate_write_super(fs_info, sb);\n\t\tif (ret < 0) {\n\t\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\t\tbtrfs_handle_fs_error(fs_info, -EUCLEAN,\n\t\t\t\t\"unexpected superblock corruption detected\");\n\t\t\treturn -EUCLEAN;\n\t\t}\n\n\t\tret = write_dev_supers(dev, sb, max_mirrors);\n\t\tif (ret)\n\t\t\ttotal_errors++;\n\t}\n\tif (total_errors > max_errors) {\n\t\tbtrfs_err(fs_info, \"%d errors while writing supers\",\n\t\t\t  total_errors);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\n\t\t \n\t\tbtrfs_handle_fs_error(fs_info, -EIO,\n\t\t\t\t      \"%d errors while writing supers\",\n\t\t\t\t      total_errors);\n\t\treturn -EIO;\n\t}\n\n\ttotal_errors = 0;\n\tlist_for_each_entry(dev, head, dev_list) {\n\t\tif (!dev->bdev)\n\t\t\tcontinue;\n\t\tif (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||\n\t\t    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state))\n\t\t\tcontinue;\n\n\t\tret = wait_dev_supers(dev, max_mirrors);\n\t\tif (ret)\n\t\t\ttotal_errors++;\n\t}\n\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\tif (total_errors > max_errors) {\n\t\tbtrfs_handle_fs_error(fs_info, -EIO,\n\t\t\t\t      \"%d errors while writing supers\",\n\t\t\t\t      total_errors);\n\t\treturn -EIO;\n\t}\n\treturn 0;\n}\n\n \nvoid btrfs_drop_and_free_fs_root(struct btrfs_fs_info *fs_info,\n\t\t\t\t  struct btrfs_root *root)\n{\n\tbool drop_ref = false;\n\n\tspin_lock(&fs_info->fs_roots_radix_lock);\n\tradix_tree_delete(&fs_info->fs_roots_radix,\n\t\t\t  (unsigned long)root->root_key.objectid);\n\tif (test_and_clear_bit(BTRFS_ROOT_IN_RADIX, &root->state))\n\t\tdrop_ref = true;\n\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\n\tif (BTRFS_FS_ERROR(fs_info)) {\n\t\tASSERT(root->log_root == NULL);\n\t\tif (root->reloc_root) {\n\t\t\tbtrfs_put_root(root->reloc_root);\n\t\t\troot->reloc_root = NULL;\n\t\t}\n\t}\n\n\tif (drop_ref)\n\t\tbtrfs_put_root(root);\n}\n\nint btrfs_commit_super(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root = fs_info->tree_root;\n\tstruct btrfs_trans_handle *trans;\n\n\tmutex_lock(&fs_info->cleaner_mutex);\n\tbtrfs_run_delayed_iputs(fs_info);\n\tmutex_unlock(&fs_info->cleaner_mutex);\n\twake_up_process(fs_info->cleaner_kthread);\n\n\t \n\tdown_write(&fs_info->cleanup_work_sem);\n\tup_write(&fs_info->cleanup_work_sem);\n\n\ttrans = btrfs_join_transaction(root);\n\tif (IS_ERR(trans))\n\t\treturn PTR_ERR(trans);\n\treturn btrfs_commit_transaction(trans);\n}\n\nstatic void warn_about_uncommitted_trans(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_transaction *trans;\n\tstruct btrfs_transaction *tmp;\n\tbool found = false;\n\n\tif (list_empty(&fs_info->trans_list))\n\t\treturn;\n\n\t \n\tASSERT(test_bit(BTRFS_FS_CLOSING_DONE, &fs_info->flags));\n\tlist_for_each_entry_safe(trans, tmp, &fs_info->trans_list, list) {\n\t\tstruct extent_state *cached = NULL;\n\t\tu64 dirty_bytes = 0;\n\t\tu64 cur = 0;\n\t\tu64 found_start;\n\t\tu64 found_end;\n\n\t\tfound = true;\n\t\twhile (find_first_extent_bit(&trans->dirty_pages, cur,\n\t\t\t&found_start, &found_end, EXTENT_DIRTY, &cached)) {\n\t\t\tdirty_bytes += found_end + 1 - found_start;\n\t\t\tcur = found_end + 1;\n\t\t}\n\t\tbtrfs_warn(fs_info,\n\t\"transaction %llu (with %llu dirty metadata bytes) is not committed\",\n\t\t\t   trans->transid, dirty_bytes);\n\t\tbtrfs_cleanup_one_transaction(trans, fs_info);\n\n\t\tif (trans == fs_info->running_transaction)\n\t\t\tfs_info->running_transaction = NULL;\n\t\tlist_del_init(&trans->list);\n\n\t\tbtrfs_put_transaction(trans);\n\t\ttrace_btrfs_transaction_commit(fs_info);\n\t}\n\tASSERT(!found);\n}\n\nvoid __cold close_ctree(struct btrfs_fs_info *fs_info)\n{\n\tint ret;\n\n\tset_bit(BTRFS_FS_CLOSING_START, &fs_info->flags);\n\n\t \n\tbtrfs_wake_unfinished_drop(fs_info);\n\n\t \n\tcancel_work_sync(&fs_info->reclaim_bgs_work);\n\t \n\tkthread_park(fs_info->cleaner_kthread);\n\n\t \n\tbtrfs_qgroup_wait_for_completion(fs_info, false);\n\n\t \n\tdown(&fs_info->uuid_tree_rescan_sem);\n\t \n\tup(&fs_info->uuid_tree_rescan_sem);\n\n\t \n\tbtrfs_pause_balance(fs_info);\n\n\tbtrfs_dev_replace_suspend_for_unmount(fs_info);\n\n\tbtrfs_scrub_cancel(fs_info);\n\n\t \n\twait_event(fs_info->transaction_wait,\n\t\t   (atomic_read(&fs_info->defrag_running) == 0));\n\n\t \n\tbtrfs_cleanup_defrag_inodes(fs_info);\n\n\t \n\tbtrfs_flush_workqueue(fs_info->endio_write_workers);\n\t \n\tbtrfs_flush_workqueue(fs_info->endio_freespace_worker);\n\tbtrfs_run_delayed_iputs(fs_info);\n\n\tcancel_work_sync(&fs_info->async_reclaim_work);\n\tcancel_work_sync(&fs_info->async_data_reclaim_work);\n\tcancel_work_sync(&fs_info->preempt_reclaim_work);\n\n\t \n\tbtrfs_discard_cleanup(fs_info);\n\n\tif (!sb_rdonly(fs_info->sb)) {\n\t\t \n\t\tbtrfs_delete_unused_bgs(fs_info);\n\n\t\t \n\t\tbtrfs_flush_workqueue(fs_info->delayed_workers);\n\n\t\tret = btrfs_commit_super(fs_info);\n\t\tif (ret)\n\t\t\tbtrfs_err(fs_info, \"commit super ret %d\", ret);\n\t}\n\n\tif (BTRFS_FS_ERROR(fs_info))\n\t\tbtrfs_error_commit_super(fs_info);\n\n\tkthread_stop(fs_info->transaction_kthread);\n\tkthread_stop(fs_info->cleaner_kthread);\n\n\tASSERT(list_empty(&fs_info->delayed_iputs));\n\tset_bit(BTRFS_FS_CLOSING_DONE, &fs_info->flags);\n\n\tif (btrfs_check_quota_leak(fs_info)) {\n\t\tWARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));\n\t\tbtrfs_err(fs_info, \"qgroup reserved space leaked\");\n\t}\n\n\tbtrfs_free_qgroup_config(fs_info);\n\tASSERT(list_empty(&fs_info->delalloc_roots));\n\n\tif (percpu_counter_sum(&fs_info->delalloc_bytes)) {\n\t\tbtrfs_info(fs_info, \"at unmount delalloc count %lld\",\n\t\t       percpu_counter_sum(&fs_info->delalloc_bytes));\n\t}\n\n\tif (percpu_counter_sum(&fs_info->ordered_bytes))\n\t\tbtrfs_info(fs_info, \"at unmount dio bytes count %lld\",\n\t\t\t   percpu_counter_sum(&fs_info->ordered_bytes));\n\n\tbtrfs_sysfs_remove_mounted(fs_info);\n\tbtrfs_sysfs_remove_fsid(fs_info->fs_devices);\n\n\tbtrfs_put_block_group_cache(fs_info);\n\n\t \n\tinvalidate_inode_pages2(fs_info->btree_inode->i_mapping);\n\tbtrfs_stop_all_workers(fs_info);\n\n\t \n\twarn_about_uncommitted_trans(fs_info);\n\n\tclear_bit(BTRFS_FS_OPEN, &fs_info->flags);\n\tfree_root_pointers(fs_info, true);\n\tbtrfs_free_fs_roots(fs_info);\n\n\t \n\tbtrfs_free_block_groups(fs_info);\n\n\tiput(fs_info->btree_inode);\n\n#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY\n\tif (btrfs_test_opt(fs_info, CHECK_INTEGRITY))\n\t\tbtrfsic_unmount(fs_info->fs_devices);\n#endif\n\n\tbtrfs_mapping_tree_free(&fs_info->mapping_tree);\n\tbtrfs_close_devices(fs_info->fs_devices);\n}\n\nvoid btrfs_mark_buffer_dirty(struct btrfs_trans_handle *trans,\n\t\t\t     struct extent_buffer *buf)\n{\n\tstruct btrfs_fs_info *fs_info = buf->fs_info;\n\tu64 transid = btrfs_header_generation(buf);\n\n#ifdef CONFIG_BTRFS_FS_RUN_SANITY_TESTS\n\t \n\tif (unlikely(test_bit(EXTENT_BUFFER_UNMAPPED, &buf->bflags)))\n\t\treturn;\n#endif\n\t \n\tASSERT(trans->transid == fs_info->generation);\n\tbtrfs_assert_tree_write_locked(buf);\n\tif (transid != fs_info->generation) {\n\t\tWARN(1, KERN_CRIT \"btrfs transid mismatch buffer %llu, found %llu running %llu\\n\",\n\t\t\tbuf->start, transid, fs_info->generation);\n\t\tbtrfs_abort_transaction(trans, -EUCLEAN);\n\t}\n\tset_extent_buffer_dirty(buf);\n#ifdef CONFIG_BTRFS_FS_CHECK_INTEGRITY\n\t \n\tif (btrfs_header_level(buf) == 0 && btrfs_check_leaf(buf)) {\n\t\tbtrfs_print_leaf(buf);\n\t\tASSERT(0);\n\t}\n#endif\n}\n\nstatic void __btrfs_btree_balance_dirty(struct btrfs_fs_info *fs_info,\n\t\t\t\t\tint flush_delayed)\n{\n\t \n\tint ret;\n\n\tif (current->flags & PF_MEMALLOC)\n\t\treturn;\n\n\tif (flush_delayed)\n\t\tbtrfs_balance_delayed_items(fs_info);\n\n\tret = __percpu_counter_compare(&fs_info->dirty_metadata_bytes,\n\t\t\t\t     BTRFS_DIRTY_METADATA_THRESH,\n\t\t\t\t     fs_info->dirty_metadata_batch);\n\tif (ret > 0) {\n\t\tbalance_dirty_pages_ratelimited(fs_info->btree_inode->i_mapping);\n\t}\n}\n\nvoid btrfs_btree_balance_dirty(struct btrfs_fs_info *fs_info)\n{\n\t__btrfs_btree_balance_dirty(fs_info, 1);\n}\n\nvoid btrfs_btree_balance_dirty_nodelay(struct btrfs_fs_info *fs_info)\n{\n\t__btrfs_btree_balance_dirty(fs_info, 0);\n}\n\nstatic void btrfs_error_commit_super(struct btrfs_fs_info *fs_info)\n{\n\t \n\tbtrfs_cleanup_transaction(fs_info);\n\n\tmutex_lock(&fs_info->cleaner_mutex);\n\tbtrfs_run_delayed_iputs(fs_info);\n\tmutex_unlock(&fs_info->cleaner_mutex);\n\n\tdown_write(&fs_info->cleanup_work_sem);\n\tup_write(&fs_info->cleanup_work_sem);\n}\n\nstatic void btrfs_drop_all_logs(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *gang[8];\n\tu64 root_objectid = 0;\n\tint ret;\n\n\tspin_lock(&fs_info->fs_roots_radix_lock);\n\twhile ((ret = radix_tree_gang_lookup(&fs_info->fs_roots_radix,\n\t\t\t\t\t     (void **)gang, root_objectid,\n\t\t\t\t\t     ARRAY_SIZE(gang))) != 0) {\n\t\tint i;\n\n\t\tfor (i = 0; i < ret; i++)\n\t\t\tgang[i] = btrfs_grab_root(gang[i]);\n\t\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\n\t\tfor (i = 0; i < ret; i++) {\n\t\t\tif (!gang[i])\n\t\t\t\tcontinue;\n\t\t\troot_objectid = gang[i]->root_key.objectid;\n\t\t\tbtrfs_free_log(NULL, gang[i]);\n\t\t\tbtrfs_put_root(gang[i]);\n\t\t}\n\t\troot_objectid++;\n\t\tspin_lock(&fs_info->fs_roots_radix_lock);\n\t}\n\tspin_unlock(&fs_info->fs_roots_radix_lock);\n\tbtrfs_free_log_root_tree(NULL, fs_info);\n}\n\nstatic void btrfs_destroy_ordered_extents(struct btrfs_root *root)\n{\n\tstruct btrfs_ordered_extent *ordered;\n\n\tspin_lock(&root->ordered_extent_lock);\n\t \n\tlist_for_each_entry(ordered, &root->ordered_extents,\n\t\t\t    root_extent_list)\n\t\tset_bit(BTRFS_ORDERED_IOERR, &ordered->flags);\n\tspin_unlock(&root->ordered_extent_lock);\n}\n\nstatic void btrfs_destroy_all_ordered_extents(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root;\n\tLIST_HEAD(splice);\n\n\tspin_lock(&fs_info->ordered_root_lock);\n\tlist_splice_init(&fs_info->ordered_roots, &splice);\n\twhile (!list_empty(&splice)) {\n\t\troot = list_first_entry(&splice, struct btrfs_root,\n\t\t\t\t\tordered_root);\n\t\tlist_move_tail(&root->ordered_root,\n\t\t\t       &fs_info->ordered_roots);\n\n\t\tspin_unlock(&fs_info->ordered_root_lock);\n\t\tbtrfs_destroy_ordered_extents(root);\n\n\t\tcond_resched();\n\t\tspin_lock(&fs_info->ordered_root_lock);\n\t}\n\tspin_unlock(&fs_info->ordered_root_lock);\n\n\t \n\tbtrfs_wait_ordered_roots(fs_info, U64_MAX, 0, (u64)-1);\n}\n\nstatic void btrfs_destroy_delayed_refs(struct btrfs_transaction *trans,\n\t\t\t\t       struct btrfs_fs_info *fs_info)\n{\n\tstruct rb_node *node;\n\tstruct btrfs_delayed_ref_root *delayed_refs;\n\tstruct btrfs_delayed_ref_node *ref;\n\n\tdelayed_refs = &trans->delayed_refs;\n\n\tspin_lock(&delayed_refs->lock);\n\tif (atomic_read(&delayed_refs->num_entries) == 0) {\n\t\tspin_unlock(&delayed_refs->lock);\n\t\tbtrfs_debug(fs_info, \"delayed_refs has NO entry\");\n\t\treturn;\n\t}\n\n\twhile ((node = rb_first_cached(&delayed_refs->href_root)) != NULL) {\n\t\tstruct btrfs_delayed_ref_head *head;\n\t\tstruct rb_node *n;\n\t\tbool pin_bytes = false;\n\n\t\thead = rb_entry(node, struct btrfs_delayed_ref_head,\n\t\t\t\thref_node);\n\t\tif (btrfs_delayed_ref_lock(delayed_refs, head))\n\t\t\tcontinue;\n\n\t\tspin_lock(&head->lock);\n\t\twhile ((n = rb_first_cached(&head->ref_tree)) != NULL) {\n\t\t\tref = rb_entry(n, struct btrfs_delayed_ref_node,\n\t\t\t\t       ref_node);\n\t\t\trb_erase_cached(&ref->ref_node, &head->ref_tree);\n\t\t\tRB_CLEAR_NODE(&ref->ref_node);\n\t\t\tif (!list_empty(&ref->add_list))\n\t\t\t\tlist_del(&ref->add_list);\n\t\t\tatomic_dec(&delayed_refs->num_entries);\n\t\t\tbtrfs_put_delayed_ref(ref);\n\t\t}\n\t\tif (head->must_insert_reserved)\n\t\t\tpin_bytes = true;\n\t\tbtrfs_free_delayed_extent_op(head->extent_op);\n\t\tbtrfs_delete_ref_head(delayed_refs, head);\n\t\tspin_unlock(&head->lock);\n\t\tspin_unlock(&delayed_refs->lock);\n\t\tmutex_unlock(&head->mutex);\n\n\t\tif (pin_bytes) {\n\t\t\tstruct btrfs_block_group *cache;\n\n\t\t\tcache = btrfs_lookup_block_group(fs_info, head->bytenr);\n\t\t\tBUG_ON(!cache);\n\n\t\t\tspin_lock(&cache->space_info->lock);\n\t\t\tspin_lock(&cache->lock);\n\t\t\tcache->pinned += head->num_bytes;\n\t\t\tbtrfs_space_info_update_bytes_pinned(fs_info,\n\t\t\t\tcache->space_info, head->num_bytes);\n\t\t\tcache->reserved -= head->num_bytes;\n\t\t\tcache->space_info->bytes_reserved -= head->num_bytes;\n\t\t\tspin_unlock(&cache->lock);\n\t\t\tspin_unlock(&cache->space_info->lock);\n\n\t\t\tbtrfs_put_block_group(cache);\n\n\t\t\tbtrfs_error_unpin_extent_range(fs_info, head->bytenr,\n\t\t\t\thead->bytenr + head->num_bytes - 1);\n\t\t}\n\t\tbtrfs_cleanup_ref_head_accounting(fs_info, delayed_refs, head);\n\t\tbtrfs_put_delayed_ref_head(head);\n\t\tcond_resched();\n\t\tspin_lock(&delayed_refs->lock);\n\t}\n\tbtrfs_qgroup_destroy_extent_records(trans);\n\n\tspin_unlock(&delayed_refs->lock);\n}\n\nstatic void btrfs_destroy_delalloc_inodes(struct btrfs_root *root)\n{\n\tstruct btrfs_inode *btrfs_inode;\n\tLIST_HEAD(splice);\n\n\tspin_lock(&root->delalloc_lock);\n\tlist_splice_init(&root->delalloc_inodes, &splice);\n\n\twhile (!list_empty(&splice)) {\n\t\tstruct inode *inode = NULL;\n\t\tbtrfs_inode = list_first_entry(&splice, struct btrfs_inode,\n\t\t\t\t\t       delalloc_inodes);\n\t\t__btrfs_del_delalloc_inode(root, btrfs_inode);\n\t\tspin_unlock(&root->delalloc_lock);\n\n\t\t \n\t\tinode = igrab(&btrfs_inode->vfs_inode);\n\t\tif (inode) {\n\t\t\tunsigned int nofs_flag;\n\n\t\t\tnofs_flag = memalloc_nofs_save();\n\t\t\tinvalidate_inode_pages2(inode->i_mapping);\n\t\t\tmemalloc_nofs_restore(nofs_flag);\n\t\t\tiput(inode);\n\t\t}\n\t\tspin_lock(&root->delalloc_lock);\n\t}\n\tspin_unlock(&root->delalloc_lock);\n}\n\nstatic void btrfs_destroy_all_delalloc_inodes(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root;\n\tLIST_HEAD(splice);\n\n\tspin_lock(&fs_info->delalloc_root_lock);\n\tlist_splice_init(&fs_info->delalloc_roots, &splice);\n\twhile (!list_empty(&splice)) {\n\t\troot = list_first_entry(&splice, struct btrfs_root,\n\t\t\t\t\t delalloc_root);\n\t\troot = btrfs_grab_root(root);\n\t\tBUG_ON(!root);\n\t\tspin_unlock(&fs_info->delalloc_root_lock);\n\n\t\tbtrfs_destroy_delalloc_inodes(root);\n\t\tbtrfs_put_root(root);\n\n\t\tspin_lock(&fs_info->delalloc_root_lock);\n\t}\n\tspin_unlock(&fs_info->delalloc_root_lock);\n}\n\nstatic void btrfs_destroy_marked_extents(struct btrfs_fs_info *fs_info,\n\t\t\t\t\t struct extent_io_tree *dirty_pages,\n\t\t\t\t\t int mark)\n{\n\tstruct extent_buffer *eb;\n\tu64 start = 0;\n\tu64 end;\n\n\twhile (find_first_extent_bit(dirty_pages, start, &start, &end,\n\t\t\t\t     mark, NULL)) {\n\t\tclear_extent_bits(dirty_pages, start, end, mark);\n\t\twhile (start <= end) {\n\t\t\teb = find_extent_buffer(fs_info, start);\n\t\t\tstart += fs_info->nodesize;\n\t\t\tif (!eb)\n\t\t\t\tcontinue;\n\n\t\t\tbtrfs_tree_lock(eb);\n\t\t\twait_on_extent_buffer_writeback(eb);\n\t\t\tbtrfs_clear_buffer_dirty(NULL, eb);\n\t\t\tbtrfs_tree_unlock(eb);\n\n\t\t\tfree_extent_buffer_stale(eb);\n\t\t}\n\t}\n}\n\nstatic void btrfs_destroy_pinned_extent(struct btrfs_fs_info *fs_info,\n\t\t\t\t\tstruct extent_io_tree *unpin)\n{\n\tu64 start;\n\tu64 end;\n\n\twhile (1) {\n\t\tstruct extent_state *cached_state = NULL;\n\n\t\t \n\t\tmutex_lock(&fs_info->unused_bg_unpin_mutex);\n\t\tif (!find_first_extent_bit(unpin, 0, &start, &end,\n\t\t\t\t\t   EXTENT_DIRTY, &cached_state)) {\n\t\t\tmutex_unlock(&fs_info->unused_bg_unpin_mutex);\n\t\t\tbreak;\n\t\t}\n\n\t\tclear_extent_dirty(unpin, start, end, &cached_state);\n\t\tfree_extent_state(cached_state);\n\t\tbtrfs_error_unpin_extent_range(fs_info, start, end);\n\t\tmutex_unlock(&fs_info->unused_bg_unpin_mutex);\n\t\tcond_resched();\n\t}\n}\n\nstatic void btrfs_cleanup_bg_io(struct btrfs_block_group *cache)\n{\n\tstruct inode *inode;\n\n\tinode = cache->io_ctl.inode;\n\tif (inode) {\n\t\tunsigned int nofs_flag;\n\n\t\tnofs_flag = memalloc_nofs_save();\n\t\tinvalidate_inode_pages2(inode->i_mapping);\n\t\tmemalloc_nofs_restore(nofs_flag);\n\n\t\tBTRFS_I(inode)->generation = 0;\n\t\tcache->io_ctl.inode = NULL;\n\t\tiput(inode);\n\t}\n\tASSERT(cache->io_ctl.pages == NULL);\n\tbtrfs_put_block_group(cache);\n}\n\nvoid btrfs_cleanup_dirty_bgs(struct btrfs_transaction *cur_trans,\n\t\t\t     struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_block_group *cache;\n\n\tspin_lock(&cur_trans->dirty_bgs_lock);\n\twhile (!list_empty(&cur_trans->dirty_bgs)) {\n\t\tcache = list_first_entry(&cur_trans->dirty_bgs,\n\t\t\t\t\t struct btrfs_block_group,\n\t\t\t\t\t dirty_list);\n\n\t\tif (!list_empty(&cache->io_list)) {\n\t\t\tspin_unlock(&cur_trans->dirty_bgs_lock);\n\t\t\tlist_del_init(&cache->io_list);\n\t\t\tbtrfs_cleanup_bg_io(cache);\n\t\t\tspin_lock(&cur_trans->dirty_bgs_lock);\n\t\t}\n\n\t\tlist_del_init(&cache->dirty_list);\n\t\tspin_lock(&cache->lock);\n\t\tcache->disk_cache_state = BTRFS_DC_ERROR;\n\t\tspin_unlock(&cache->lock);\n\n\t\tspin_unlock(&cur_trans->dirty_bgs_lock);\n\t\tbtrfs_put_block_group(cache);\n\t\tbtrfs_delayed_refs_rsv_release(fs_info, 1);\n\t\tspin_lock(&cur_trans->dirty_bgs_lock);\n\t}\n\tspin_unlock(&cur_trans->dirty_bgs_lock);\n\n\t \n\twhile (!list_empty(&cur_trans->io_bgs)) {\n\t\tcache = list_first_entry(&cur_trans->io_bgs,\n\t\t\t\t\t struct btrfs_block_group,\n\t\t\t\t\t io_list);\n\n\t\tlist_del_init(&cache->io_list);\n\t\tspin_lock(&cache->lock);\n\t\tcache->disk_cache_state = BTRFS_DC_ERROR;\n\t\tspin_unlock(&cache->lock);\n\t\tbtrfs_cleanup_bg_io(cache);\n\t}\n}\n\nstatic void btrfs_free_all_qgroup_pertrans(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *gang[8];\n\tint i;\n\tint ret;\n\n\tspin_lock(&fs_info->fs_roots_radix_lock);\n\twhile (1) {\n\t\tret = radix_tree_gang_lookup_tag(&fs_info->fs_roots_radix,\n\t\t\t\t\t\t (void **)gang, 0,\n\t\t\t\t\t\t ARRAY_SIZE(gang),\n\t\t\t\t\t\t BTRFS_ROOT_TRANS_TAG);\n\t\tif (ret == 0)\n\t\t\tbreak;\n\t\tfor (i = 0; i < ret; i++) {\n\t\t\tstruct btrfs_root *root = gang[i];\n\n\t\t\tbtrfs_qgroup_free_meta_all_pertrans(root);\n\t\t\tradix_tree_tag_clear(&fs_info->fs_roots_radix,\n\t\t\t\t\t(unsigned long)root->root_key.objectid,\n\t\t\t\t\tBTRFS_ROOT_TRANS_TAG);\n\t\t}\n\t}\n\tspin_unlock(&fs_info->fs_roots_radix_lock);\n}\n\nvoid btrfs_cleanup_one_transaction(struct btrfs_transaction *cur_trans,\n\t\t\t\t   struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_device *dev, *tmp;\n\n\tbtrfs_cleanup_dirty_bgs(cur_trans, fs_info);\n\tASSERT(list_empty(&cur_trans->dirty_bgs));\n\tASSERT(list_empty(&cur_trans->io_bgs));\n\n\tlist_for_each_entry_safe(dev, tmp, &cur_trans->dev_update_list,\n\t\t\t\t post_commit_list) {\n\t\tlist_del_init(&dev->post_commit_list);\n\t}\n\n\tbtrfs_destroy_delayed_refs(cur_trans, fs_info);\n\n\tcur_trans->state = TRANS_STATE_COMMIT_START;\n\twake_up(&fs_info->transaction_blocked_wait);\n\n\tcur_trans->state = TRANS_STATE_UNBLOCKED;\n\twake_up(&fs_info->transaction_wait);\n\n\tbtrfs_destroy_delayed_inodes(fs_info);\n\n\tbtrfs_destroy_marked_extents(fs_info, &cur_trans->dirty_pages,\n\t\t\t\t     EXTENT_DIRTY);\n\tbtrfs_destroy_pinned_extent(fs_info, &cur_trans->pinned_extents);\n\n\tbtrfs_free_all_qgroup_pertrans(fs_info);\n\n\tcur_trans->state =TRANS_STATE_COMPLETED;\n\twake_up(&cur_trans->commit_wait);\n}\n\nstatic int btrfs_cleanup_transaction(struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_transaction *t;\n\n\tmutex_lock(&fs_info->transaction_kthread_mutex);\n\n\tspin_lock(&fs_info->trans_lock);\n\twhile (!list_empty(&fs_info->trans_list)) {\n\t\tt = list_first_entry(&fs_info->trans_list,\n\t\t\t\t     struct btrfs_transaction, list);\n\t\tif (t->state >= TRANS_STATE_COMMIT_PREP) {\n\t\t\trefcount_inc(&t->use_count);\n\t\t\tspin_unlock(&fs_info->trans_lock);\n\t\t\tbtrfs_wait_for_commit(fs_info, t->transid);\n\t\t\tbtrfs_put_transaction(t);\n\t\t\tspin_lock(&fs_info->trans_lock);\n\t\t\tcontinue;\n\t\t}\n\t\tif (t == fs_info->running_transaction) {\n\t\t\tt->state = TRANS_STATE_COMMIT_DOING;\n\t\t\tspin_unlock(&fs_info->trans_lock);\n\t\t\t \n\t\t\twait_event(t->writer_wait,\n\t\t\t\t   atomic_read(&t->num_writers) == 0);\n\t\t} else {\n\t\t\tspin_unlock(&fs_info->trans_lock);\n\t\t}\n\t\tbtrfs_cleanup_one_transaction(t, fs_info);\n\n\t\tspin_lock(&fs_info->trans_lock);\n\t\tif (t == fs_info->running_transaction)\n\t\t\tfs_info->running_transaction = NULL;\n\t\tlist_del_init(&t->list);\n\t\tspin_unlock(&fs_info->trans_lock);\n\n\t\tbtrfs_put_transaction(t);\n\t\ttrace_btrfs_transaction_commit(fs_info);\n\t\tspin_lock(&fs_info->trans_lock);\n\t}\n\tspin_unlock(&fs_info->trans_lock);\n\tbtrfs_destroy_all_ordered_extents(fs_info);\n\tbtrfs_destroy_delayed_inodes(fs_info);\n\tbtrfs_assert_delayed_root_empty(fs_info);\n\tbtrfs_destroy_all_delalloc_inodes(fs_info);\n\tbtrfs_drop_all_logs(fs_info);\n\tmutex_unlock(&fs_info->transaction_kthread_mutex);\n\n\treturn 0;\n}\n\nint btrfs_init_root_free_objectid(struct btrfs_root *root)\n{\n\tstruct btrfs_path *path;\n\tint ret;\n\tstruct extent_buffer *l;\n\tstruct btrfs_key search_key;\n\tstruct btrfs_key found_key;\n\tint slot;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tsearch_key.objectid = BTRFS_LAST_FREE_OBJECTID;\n\tsearch_key.type = -1;\n\tsearch_key.offset = (u64)-1;\n\tret = btrfs_search_slot(NULL, root, &search_key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto error;\n\tBUG_ON(ret == 0);  \n\tif (path->slots[0] > 0) {\n\t\tslot = path->slots[0] - 1;\n\t\tl = path->nodes[0];\n\t\tbtrfs_item_key_to_cpu(l, &found_key, slot);\n\t\troot->free_objectid = max_t(u64, found_key.objectid + 1,\n\t\t\t\t\t    BTRFS_FIRST_FREE_OBJECTID);\n\t} else {\n\t\troot->free_objectid = BTRFS_FIRST_FREE_OBJECTID;\n\t}\n\tret = 0;\nerror:\n\tbtrfs_free_path(path);\n\treturn ret;\n}\n\nint btrfs_get_free_objectid(struct btrfs_root *root, u64 *objectid)\n{\n\tint ret;\n\tmutex_lock(&root->objectid_mutex);\n\n\tif (unlikely(root->free_objectid >= BTRFS_LAST_FREE_OBJECTID)) {\n\t\tbtrfs_warn(root->fs_info,\n\t\t\t   \"the objectid of root %llu reaches its highest value\",\n\t\t\t   root->root_key.objectid);\n\t\tret = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t*objectid = root->free_objectid++;\n\tret = 0;\nout:\n\tmutex_unlock(&root->objectid_mutex);\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}