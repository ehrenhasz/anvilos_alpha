{
  "module_name": "io.c",
  "hash_id": "51f8ef4135c4d56ac7c9fbd669d88cddde0b32cc1cf29c73a122244e10bd7bbe",
  "original_prompt": "Ingested from linux-6.6.14/fs/ubifs/io.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/crc32.h>\n#include <linux/slab.h>\n#include \"ubifs.h\"\n\n \nvoid ubifs_ro_mode(struct ubifs_info *c, int err)\n{\n\tif (!c->ro_error) {\n\t\tc->ro_error = 1;\n\t\tc->no_chk_data_crc = 0;\n\t\tc->vfs_sb->s_flags |= SB_RDONLY;\n\t\tubifs_warn(c, \"switched to read-only mode, error %d\", err);\n\t\tdump_stack();\n\t}\n}\n\n \n\nint ubifs_leb_read(const struct ubifs_info *c, int lnum, void *buf, int offs,\n\t\t   int len, int even_ebadmsg)\n{\n\tint err;\n\n\terr = ubi_read(c->ubi, lnum, buf, offs, len);\n\t \n\tif (err && (err != -EBADMSG || even_ebadmsg)) {\n\t\tubifs_err(c, \"reading %d bytes from LEB %d:%d failed, error %d\",\n\t\t\t  len, lnum, offs, err);\n\t\tdump_stack();\n\t}\n\treturn err;\n}\n\nint ubifs_leb_write(struct ubifs_info *c, int lnum, const void *buf, int offs,\n\t\t    int len)\n{\n\tint err;\n\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tif (c->ro_error)\n\t\treturn -EROFS;\n\tif (!dbg_is_tst_rcvry(c))\n\t\terr = ubi_leb_write(c->ubi, lnum, buf, offs, len);\n\telse\n\t\terr = dbg_leb_write(c, lnum, buf, offs, len);\n\tif (err) {\n\t\tubifs_err(c, \"writing %d bytes to LEB %d:%d failed, error %d\",\n\t\t\t  len, lnum, offs, err);\n\t\tubifs_ro_mode(c, err);\n\t\tdump_stack();\n\t}\n\treturn err;\n}\n\nint ubifs_leb_change(struct ubifs_info *c, int lnum, const void *buf, int len)\n{\n\tint err;\n\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tif (c->ro_error)\n\t\treturn -EROFS;\n\tif (!dbg_is_tst_rcvry(c))\n\t\terr = ubi_leb_change(c->ubi, lnum, buf, len);\n\telse\n\t\terr = dbg_leb_change(c, lnum, buf, len);\n\tif (err) {\n\t\tubifs_err(c, \"changing %d bytes in LEB %d failed, error %d\",\n\t\t\t  len, lnum, err);\n\t\tubifs_ro_mode(c, err);\n\t\tdump_stack();\n\t}\n\treturn err;\n}\n\nint ubifs_leb_unmap(struct ubifs_info *c, int lnum)\n{\n\tint err;\n\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tif (c->ro_error)\n\t\treturn -EROFS;\n\tif (!dbg_is_tst_rcvry(c))\n\t\terr = ubi_leb_unmap(c->ubi, lnum);\n\telse\n\t\terr = dbg_leb_unmap(c, lnum);\n\tif (err) {\n\t\tubifs_err(c, \"unmap LEB %d failed, error %d\", lnum, err);\n\t\tubifs_ro_mode(c, err);\n\t\tdump_stack();\n\t}\n\treturn err;\n}\n\nint ubifs_leb_map(struct ubifs_info *c, int lnum)\n{\n\tint err;\n\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tif (c->ro_error)\n\t\treturn -EROFS;\n\tif (!dbg_is_tst_rcvry(c))\n\t\terr = ubi_leb_map(c->ubi, lnum);\n\telse\n\t\terr = dbg_leb_map(c, lnum);\n\tif (err) {\n\t\tubifs_err(c, \"mapping LEB %d failed, error %d\", lnum, err);\n\t\tubifs_ro_mode(c, err);\n\t\tdump_stack();\n\t}\n\treturn err;\n}\n\nint ubifs_is_mapped(const struct ubifs_info *c, int lnum)\n{\n\tint err;\n\n\terr = ubi_is_mapped(c->ubi, lnum);\n\tif (err < 0) {\n\t\tubifs_err(c, \"ubi_is_mapped failed for LEB %d, error %d\",\n\t\t\t  lnum, err);\n\t\tdump_stack();\n\t}\n\treturn err;\n}\n\nstatic void record_magic_error(struct ubifs_stats_info *stats)\n{\n\tif (stats)\n\t\tstats->magic_errors++;\n}\n\nstatic void record_node_error(struct ubifs_stats_info *stats)\n{\n\tif (stats)\n\t\tstats->node_errors++;\n}\n\nstatic void record_crc_error(struct ubifs_stats_info *stats)\n{\n\tif (stats)\n\t\tstats->crc_errors++;\n}\n\n \nint ubifs_check_node(const struct ubifs_info *c, const void *buf, int len,\n\t\t     int lnum, int offs, int quiet, int must_chk_crc)\n{\n\tint err = -EINVAL, type, node_len;\n\tuint32_t crc, node_crc, magic;\n\tconst struct ubifs_ch *ch = buf;\n\n\tubifs_assert(c, lnum >= 0 && lnum < c->leb_cnt && offs >= 0);\n\tubifs_assert(c, !(offs & 7) && offs < c->leb_size);\n\n\tmagic = le32_to_cpu(ch->magic);\n\tif (magic != UBIFS_NODE_MAGIC) {\n\t\tif (!quiet)\n\t\t\tubifs_err(c, \"bad magic %#08x, expected %#08x\",\n\t\t\t\t  magic, UBIFS_NODE_MAGIC);\n\t\trecord_magic_error(c->stats);\n\t\terr = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\ttype = ch->node_type;\n\tif (type < 0 || type >= UBIFS_NODE_TYPES_CNT) {\n\t\tif (!quiet)\n\t\t\tubifs_err(c, \"bad node type %d\", type);\n\t\trecord_node_error(c->stats);\n\t\tgoto out;\n\t}\n\n\tnode_len = le32_to_cpu(ch->len);\n\tif (node_len + offs > c->leb_size)\n\t\tgoto out_len;\n\n\tif (c->ranges[type].max_len == 0) {\n\t\tif (node_len != c->ranges[type].len)\n\t\t\tgoto out_len;\n\t} else if (node_len < c->ranges[type].min_len ||\n\t\t   node_len > c->ranges[type].max_len)\n\t\tgoto out_len;\n\n\tif (!must_chk_crc && type == UBIFS_DATA_NODE && !c->mounting &&\n\t    !c->remounting_rw && c->no_chk_data_crc)\n\t\treturn 0;\n\n\tcrc = crc32(UBIFS_CRC32_INIT, buf + 8, node_len - 8);\n\tnode_crc = le32_to_cpu(ch->crc);\n\tif (crc != node_crc) {\n\t\tif (!quiet)\n\t\t\tubifs_err(c, \"bad CRC: calculated %#08x, read %#08x\",\n\t\t\t\t  crc, node_crc);\n\t\trecord_crc_error(c->stats);\n\t\terr = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\treturn 0;\n\nout_len:\n\tif (!quiet)\n\t\tubifs_err(c, \"bad node length %d\", node_len);\nout:\n\tif (!quiet) {\n\t\tubifs_err(c, \"bad node at LEB %d:%d\", lnum, offs);\n\t\tubifs_dump_node(c, buf, len);\n\t\tdump_stack();\n\t}\n\treturn err;\n}\n\n \nvoid ubifs_pad(const struct ubifs_info *c, void *buf, int pad)\n{\n\tuint32_t crc;\n\n\tubifs_assert(c, pad >= 0);\n\n\tif (pad >= UBIFS_PAD_NODE_SZ) {\n\t\tstruct ubifs_ch *ch = buf;\n\t\tstruct ubifs_pad_node *pad_node = buf;\n\n\t\tch->magic = cpu_to_le32(UBIFS_NODE_MAGIC);\n\t\tch->node_type = UBIFS_PAD_NODE;\n\t\tch->group_type = UBIFS_NO_NODE_GROUP;\n\t\tch->padding[0] = ch->padding[1] = 0;\n\t\tch->sqnum = 0;\n\t\tch->len = cpu_to_le32(UBIFS_PAD_NODE_SZ);\n\t\tpad -= UBIFS_PAD_NODE_SZ;\n\t\tpad_node->pad_len = cpu_to_le32(pad);\n\t\tcrc = crc32(UBIFS_CRC32_INIT, buf + 8, UBIFS_PAD_NODE_SZ - 8);\n\t\tch->crc = cpu_to_le32(crc);\n\t\tmemset(buf + UBIFS_PAD_NODE_SZ, 0, pad);\n\t} else if (pad > 0)\n\t\t \n\t\tmemset(buf, UBIFS_PADDING_BYTE, pad);\n}\n\n \nstatic unsigned long long next_sqnum(struct ubifs_info *c)\n{\n\tunsigned long long sqnum;\n\n\tspin_lock(&c->cnt_lock);\n\tsqnum = ++c->max_sqnum;\n\tspin_unlock(&c->cnt_lock);\n\n\tif (unlikely(sqnum >= SQNUM_WARN_WATERMARK)) {\n\t\tif (sqnum >= SQNUM_WATERMARK) {\n\t\t\tubifs_err(c, \"sequence number overflow %llu, end of life\",\n\t\t\t\t  sqnum);\n\t\t\tubifs_ro_mode(c, -EINVAL);\n\t\t}\n\t\tubifs_warn(c, \"running out of sequence numbers, end of life soon\");\n\t}\n\n\treturn sqnum;\n}\n\nvoid ubifs_init_node(struct ubifs_info *c, void *node, int len, int pad)\n{\n\tstruct ubifs_ch *ch = node;\n\tunsigned long long sqnum = next_sqnum(c);\n\n\tubifs_assert(c, len >= UBIFS_CH_SZ);\n\n\tch->magic = cpu_to_le32(UBIFS_NODE_MAGIC);\n\tch->len = cpu_to_le32(len);\n\tch->group_type = UBIFS_NO_NODE_GROUP;\n\tch->sqnum = cpu_to_le64(sqnum);\n\tch->padding[0] = ch->padding[1] = 0;\n\n\tif (pad) {\n\t\tlen = ALIGN(len, 8);\n\t\tpad = ALIGN(len, c->min_io_size) - len;\n\t\tubifs_pad(c, node + len, pad);\n\t}\n}\n\nvoid ubifs_crc_node(struct ubifs_info *c, void *node, int len)\n{\n\tstruct ubifs_ch *ch = node;\n\tuint32_t crc;\n\n\tcrc = crc32(UBIFS_CRC32_INIT, node + 8, len - 8);\n\tch->crc = cpu_to_le32(crc);\n}\n\n \nint ubifs_prepare_node_hmac(struct ubifs_info *c, void *node, int len,\n\t\t\t    int hmac_offs, int pad)\n{\n\tint err;\n\n\tubifs_init_node(c, node, len, pad);\n\n\tif (hmac_offs > 0) {\n\t\terr = ubifs_node_insert_hmac(c, node, len, hmac_offs);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tubifs_crc_node(c, node, len);\n\n\treturn 0;\n}\n\n \nvoid ubifs_prepare_node(struct ubifs_info *c, void *node, int len, int pad)\n{\n\t \n\tubifs_prepare_node_hmac(c, node, len, 0, pad);\n}\n\n \nvoid ubifs_prep_grp_node(struct ubifs_info *c, void *node, int len, int last)\n{\n\tuint32_t crc;\n\tstruct ubifs_ch *ch = node;\n\tunsigned long long sqnum = next_sqnum(c);\n\n\tubifs_assert(c, len >= UBIFS_CH_SZ);\n\n\tch->magic = cpu_to_le32(UBIFS_NODE_MAGIC);\n\tch->len = cpu_to_le32(len);\n\tif (last)\n\t\tch->group_type = UBIFS_LAST_OF_NODE_GROUP;\n\telse\n\t\tch->group_type = UBIFS_IN_NODE_GROUP;\n\tch->sqnum = cpu_to_le64(sqnum);\n\tch->padding[0] = ch->padding[1] = 0;\n\tcrc = crc32(UBIFS_CRC32_INIT, node + 8, len - 8);\n\tch->crc = cpu_to_le32(crc);\n}\n\n \nstatic enum hrtimer_restart wbuf_timer_callback_nolock(struct hrtimer *timer)\n{\n\tstruct ubifs_wbuf *wbuf = container_of(timer, struct ubifs_wbuf, timer);\n\n\tdbg_io(\"jhead %s\", dbg_jhead(wbuf->jhead));\n\twbuf->need_sync = 1;\n\twbuf->c->need_wbuf_sync = 1;\n\tubifs_wake_up_bgt(wbuf->c);\n\treturn HRTIMER_NORESTART;\n}\n\n \nstatic void new_wbuf_timer_nolock(struct ubifs_info *c, struct ubifs_wbuf *wbuf)\n{\n\tktime_t softlimit = ms_to_ktime(dirty_writeback_interval * 10);\n\tunsigned long long delta = dirty_writeback_interval;\n\n\t \n\tdelta *= 10ULL * NSEC_PER_MSEC / 10ULL;\n\n\tubifs_assert(c, !hrtimer_active(&wbuf->timer));\n\tubifs_assert(c, delta <= ULONG_MAX);\n\n\tif (wbuf->no_timer)\n\t\treturn;\n\tdbg_io(\"set timer for jhead %s, %llu-%llu millisecs\",\n\t       dbg_jhead(wbuf->jhead),\n\t       div_u64(ktime_to_ns(softlimit), USEC_PER_SEC),\n\t       div_u64(ktime_to_ns(softlimit) + delta, USEC_PER_SEC));\n\thrtimer_start_range_ns(&wbuf->timer, softlimit, delta,\n\t\t\t       HRTIMER_MODE_REL);\n}\n\n \nstatic void cancel_wbuf_timer_nolock(struct ubifs_wbuf *wbuf)\n{\n\tif (wbuf->no_timer)\n\t\treturn;\n\twbuf->need_sync = 0;\n\thrtimer_cancel(&wbuf->timer);\n}\n\n \nint ubifs_wbuf_sync_nolock(struct ubifs_wbuf *wbuf)\n{\n\tstruct ubifs_info *c = wbuf->c;\n\tint err, dirt, sync_len;\n\n\tcancel_wbuf_timer_nolock(wbuf);\n\tif (!wbuf->used || wbuf->lnum == -1)\n\t\t \n\t\treturn 0;\n\n\tdbg_io(\"LEB %d:%d, %d bytes, jhead %s\",\n\t       wbuf->lnum, wbuf->offs, wbuf->used, dbg_jhead(wbuf->jhead));\n\tubifs_assert(c, !(wbuf->avail & 7));\n\tubifs_assert(c, wbuf->offs + wbuf->size <= c->leb_size);\n\tubifs_assert(c, wbuf->size >= c->min_io_size);\n\tubifs_assert(c, wbuf->size <= c->max_write_size);\n\tubifs_assert(c, wbuf->size % c->min_io_size == 0);\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tif (c->leb_size - wbuf->offs >= c->max_write_size)\n\t\tubifs_assert(c, !((wbuf->offs + wbuf->size) % c->max_write_size));\n\n\tif (c->ro_error)\n\t\treturn -EROFS;\n\n\t \n\tsync_len = ALIGN(wbuf->used, c->min_io_size);\n\tdirt = sync_len - wbuf->used;\n\tif (dirt)\n\t\tubifs_pad(c, wbuf->buf + wbuf->used, dirt);\n\terr = ubifs_leb_write(c, wbuf->lnum, wbuf->buf, wbuf->offs, sync_len);\n\tif (err)\n\t\treturn err;\n\n\tspin_lock(&wbuf->lock);\n\twbuf->offs += sync_len;\n\t \n\tif (c->leb_size - wbuf->offs < c->max_write_size)\n\t\twbuf->size = c->leb_size - wbuf->offs;\n\telse if (wbuf->offs & (c->max_write_size - 1))\n\t\twbuf->size = ALIGN(wbuf->offs, c->max_write_size) - wbuf->offs;\n\telse\n\t\twbuf->size = c->max_write_size;\n\twbuf->avail = wbuf->size;\n\twbuf->used = 0;\n\twbuf->next_ino = 0;\n\tspin_unlock(&wbuf->lock);\n\n\tif (wbuf->sync_callback)\n\t\terr = wbuf->sync_callback(c, wbuf->lnum,\n\t\t\t\t\t  c->leb_size - wbuf->offs, dirt);\n\treturn err;\n}\n\n \nint ubifs_wbuf_seek_nolock(struct ubifs_wbuf *wbuf, int lnum, int offs)\n{\n\tconst struct ubifs_info *c = wbuf->c;\n\n\tdbg_io(\"LEB %d:%d, jhead %s\", lnum, offs, dbg_jhead(wbuf->jhead));\n\tubifs_assert(c, lnum >= 0 && lnum < c->leb_cnt);\n\tubifs_assert(c, offs >= 0 && offs <= c->leb_size);\n\tubifs_assert(c, offs % c->min_io_size == 0 && !(offs & 7));\n\tubifs_assert(c, lnum != wbuf->lnum);\n\tubifs_assert(c, wbuf->used == 0);\n\n\tspin_lock(&wbuf->lock);\n\twbuf->lnum = lnum;\n\twbuf->offs = offs;\n\tif (c->leb_size - wbuf->offs < c->max_write_size)\n\t\twbuf->size = c->leb_size - wbuf->offs;\n\telse if (wbuf->offs & (c->max_write_size - 1))\n\t\twbuf->size = ALIGN(wbuf->offs, c->max_write_size) - wbuf->offs;\n\telse\n\t\twbuf->size = c->max_write_size;\n\twbuf->avail = wbuf->size;\n\twbuf->used = 0;\n\tspin_unlock(&wbuf->lock);\n\n\treturn 0;\n}\n\n \nint ubifs_bg_wbufs_sync(struct ubifs_info *c)\n{\n\tint err, i;\n\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tif (!c->need_wbuf_sync)\n\t\treturn 0;\n\tc->need_wbuf_sync = 0;\n\n\tif (c->ro_error) {\n\t\terr = -EROFS;\n\t\tgoto out_timers;\n\t}\n\n\tdbg_io(\"synchronize\");\n\tfor (i = 0; i < c->jhead_cnt; i++) {\n\t\tstruct ubifs_wbuf *wbuf = &c->jheads[i].wbuf;\n\n\t\tcond_resched();\n\n\t\t \n\t\tif (mutex_is_locked(&wbuf->io_mutex))\n\t\t\tcontinue;\n\n\t\tmutex_lock_nested(&wbuf->io_mutex, wbuf->jhead);\n\t\tif (!wbuf->need_sync) {\n\t\t\tmutex_unlock(&wbuf->io_mutex);\n\t\t\tcontinue;\n\t\t}\n\n\t\terr = ubifs_wbuf_sync_nolock(wbuf);\n\t\tmutex_unlock(&wbuf->io_mutex);\n\t\tif (err) {\n\t\t\tubifs_err(c, \"cannot sync write-buffer, error %d\", err);\n\t\t\tubifs_ro_mode(c, err);\n\t\t\tgoto out_timers;\n\t\t}\n\t}\n\n\treturn 0;\n\nout_timers:\n\t \n\tfor (i = 0; i < c->jhead_cnt; i++) {\n\t\tstruct ubifs_wbuf *wbuf = &c->jheads[i].wbuf;\n\n\t\tmutex_lock_nested(&wbuf->io_mutex, wbuf->jhead);\n\t\tcancel_wbuf_timer_nolock(wbuf);\n\t\tmutex_unlock(&wbuf->io_mutex);\n\t}\n\treturn err;\n}\n\n \nint ubifs_wbuf_write_nolock(struct ubifs_wbuf *wbuf, void *buf, int len)\n{\n\tstruct ubifs_info *c = wbuf->c;\n\tint err, n, written = 0, aligned_len = ALIGN(len, 8);\n\n\tdbg_io(\"%d bytes (%s) to jhead %s wbuf at LEB %d:%d\", len,\n\t       dbg_ntype(((struct ubifs_ch *)buf)->node_type),\n\t       dbg_jhead(wbuf->jhead), wbuf->lnum, wbuf->offs + wbuf->used);\n\tubifs_assert(c, len > 0 && wbuf->lnum >= 0 && wbuf->lnum < c->leb_cnt);\n\tubifs_assert(c, wbuf->offs >= 0 && wbuf->offs % c->min_io_size == 0);\n\tubifs_assert(c, !(wbuf->offs & 7) && wbuf->offs <= c->leb_size);\n\tubifs_assert(c, wbuf->avail > 0 && wbuf->avail <= wbuf->size);\n\tubifs_assert(c, wbuf->size >= c->min_io_size);\n\tubifs_assert(c, wbuf->size <= c->max_write_size);\n\tubifs_assert(c, wbuf->size % c->min_io_size == 0);\n\tubifs_assert(c, mutex_is_locked(&wbuf->io_mutex));\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tubifs_assert(c, !c->space_fixup);\n\tif (c->leb_size - wbuf->offs >= c->max_write_size)\n\t\tubifs_assert(c, !((wbuf->offs + wbuf->size) % c->max_write_size));\n\n\tif (c->leb_size - wbuf->offs - wbuf->used < aligned_len) {\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\tcancel_wbuf_timer_nolock(wbuf);\n\n\tif (c->ro_error)\n\t\treturn -EROFS;\n\n\tif (aligned_len <= wbuf->avail) {\n\t\t \n\t\tmemcpy(wbuf->buf + wbuf->used, buf, len);\n\t\tif (aligned_len > len) {\n\t\t\tubifs_assert(c, aligned_len - len < 8);\n\t\t\tubifs_pad(c, wbuf->buf + wbuf->used + len, aligned_len - len);\n\t\t}\n\n\t\tif (aligned_len == wbuf->avail) {\n\t\t\tdbg_io(\"flush jhead %s wbuf to LEB %d:%d\",\n\t\t\t       dbg_jhead(wbuf->jhead), wbuf->lnum, wbuf->offs);\n\t\t\terr = ubifs_leb_write(c, wbuf->lnum, wbuf->buf,\n\t\t\t\t\t      wbuf->offs, wbuf->size);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\tspin_lock(&wbuf->lock);\n\t\t\twbuf->offs += wbuf->size;\n\t\t\tif (c->leb_size - wbuf->offs >= c->max_write_size)\n\t\t\t\twbuf->size = c->max_write_size;\n\t\t\telse\n\t\t\t\twbuf->size = c->leb_size - wbuf->offs;\n\t\t\twbuf->avail = wbuf->size;\n\t\t\twbuf->used = 0;\n\t\t\twbuf->next_ino = 0;\n\t\t\tspin_unlock(&wbuf->lock);\n\t\t} else {\n\t\t\tspin_lock(&wbuf->lock);\n\t\t\twbuf->avail -= aligned_len;\n\t\t\twbuf->used += aligned_len;\n\t\t\tspin_unlock(&wbuf->lock);\n\t\t}\n\n\t\tgoto exit;\n\t}\n\n\tif (wbuf->used) {\n\t\t \n\t\tdbg_io(\"flush jhead %s wbuf to LEB %d:%d\",\n\t\t       dbg_jhead(wbuf->jhead), wbuf->lnum, wbuf->offs);\n\t\tmemcpy(wbuf->buf + wbuf->used, buf, wbuf->avail);\n\t\terr = ubifs_leb_write(c, wbuf->lnum, wbuf->buf, wbuf->offs,\n\t\t\t\t      wbuf->size);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\twbuf->offs += wbuf->size;\n\t\tlen -= wbuf->avail;\n\t\taligned_len -= wbuf->avail;\n\t\twritten += wbuf->avail;\n\t} else if (wbuf->offs & (c->max_write_size - 1)) {\n\t\t \n\t\tdbg_io(\"write %d bytes to LEB %d:%d\",\n\t\t       wbuf->size, wbuf->lnum, wbuf->offs);\n\t\terr = ubifs_leb_write(c, wbuf->lnum, buf, wbuf->offs,\n\t\t\t\t      wbuf->size);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\twbuf->offs += wbuf->size;\n\t\tlen -= wbuf->size;\n\t\taligned_len -= wbuf->size;\n\t\twritten += wbuf->size;\n\t}\n\n\t \n\tn = aligned_len >> c->max_write_shift;\n\tif (n) {\n\t\tint m = n - 1;\n\n\t\tdbg_io(\"write %d bytes to LEB %d:%d\", n, wbuf->lnum,\n\t\t       wbuf->offs);\n\n\t\tif (m) {\n\t\t\t \n\t\t\tm <<= c->max_write_shift;\n\t\t\terr = ubifs_leb_write(c, wbuf->lnum, buf + written,\n\t\t\t\t\t      wbuf->offs, m);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t\twbuf->offs += m;\n\t\t\taligned_len -= m;\n\t\t\tlen -= m;\n\t\t\twritten += m;\n\t\t}\n\n\t\t \n\t\tn = 1 << c->max_write_shift;\n\t\tmemcpy(wbuf->buf, buf + written, min(len, n));\n\t\tif (n > len) {\n\t\t\tubifs_assert(c, n - len < 8);\n\t\t\tubifs_pad(c, wbuf->buf + len, n - len);\n\t\t}\n\n\t\terr = ubifs_leb_write(c, wbuf->lnum, wbuf->buf, wbuf->offs, n);\n\t\tif (err)\n\t\t\tgoto out;\n\t\twbuf->offs += n;\n\t\taligned_len -= n;\n\t\tlen -= min(len, n);\n\t\twritten += n;\n\t}\n\n\tspin_lock(&wbuf->lock);\n\tif (aligned_len) {\n\t\t \n\t\tmemcpy(wbuf->buf, buf + written, len);\n\t\tif (aligned_len > len) {\n\t\t\tubifs_assert(c, aligned_len - len < 8);\n\t\t\tubifs_pad(c, wbuf->buf + len, aligned_len - len);\n\t\t}\n\t}\n\n\tif (c->leb_size - wbuf->offs >= c->max_write_size)\n\t\twbuf->size = c->max_write_size;\n\telse\n\t\twbuf->size = c->leb_size - wbuf->offs;\n\twbuf->avail = wbuf->size - aligned_len;\n\twbuf->used = aligned_len;\n\twbuf->next_ino = 0;\n\tspin_unlock(&wbuf->lock);\n\nexit:\n\tif (wbuf->sync_callback) {\n\t\tint free = c->leb_size - wbuf->offs - wbuf->used;\n\n\t\terr = wbuf->sync_callback(c, wbuf->lnum, free, 0);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tif (wbuf->used)\n\t\tnew_wbuf_timer_nolock(c, wbuf);\n\n\treturn 0;\n\nout:\n\tubifs_err(c, \"cannot write %d bytes to LEB %d:%d, error %d\",\n\t\t  len, wbuf->lnum, wbuf->offs, err);\n\tubifs_dump_node(c, buf, written + len);\n\tdump_stack();\n\tubifs_dump_leb(c, wbuf->lnum);\n\treturn err;\n}\n\n \nint ubifs_write_node_hmac(struct ubifs_info *c, void *buf, int len, int lnum,\n\t\t\t  int offs, int hmac_offs)\n{\n\tint err, buf_len = ALIGN(len, c->min_io_size);\n\n\tdbg_io(\"LEB %d:%d, %s, length %d (aligned %d)\",\n\t       lnum, offs, dbg_ntype(((struct ubifs_ch *)buf)->node_type), len,\n\t       buf_len);\n\tubifs_assert(c, lnum >= 0 && lnum < c->leb_cnt && offs >= 0);\n\tubifs_assert(c, offs % c->min_io_size == 0 && offs < c->leb_size);\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tubifs_assert(c, !c->space_fixup);\n\n\tif (c->ro_error)\n\t\treturn -EROFS;\n\n\terr = ubifs_prepare_node_hmac(c, buf, len, hmac_offs, 1);\n\tif (err)\n\t\treturn err;\n\n\terr = ubifs_leb_write(c, lnum, buf, offs, buf_len);\n\tif (err)\n\t\tubifs_dump_node(c, buf, len);\n\n\treturn err;\n}\n\n \nint ubifs_write_node(struct ubifs_info *c, void *buf, int len, int lnum,\n\t\t     int offs)\n{\n\treturn ubifs_write_node_hmac(c, buf, len, lnum, offs, -1);\n}\n\n \nint ubifs_read_node_wbuf(struct ubifs_wbuf *wbuf, void *buf, int type, int len,\n\t\t\t int lnum, int offs)\n{\n\tconst struct ubifs_info *c = wbuf->c;\n\tint err, rlen, overlap;\n\tstruct ubifs_ch *ch = buf;\n\n\tdbg_io(\"LEB %d:%d, %s, length %d, jhead %s\", lnum, offs,\n\t       dbg_ntype(type), len, dbg_jhead(wbuf->jhead));\n\tubifs_assert(c, wbuf && lnum >= 0 && lnum < c->leb_cnt && offs >= 0);\n\tubifs_assert(c, !(offs & 7) && offs < c->leb_size);\n\tubifs_assert(c, type >= 0 && type < UBIFS_NODE_TYPES_CNT);\n\n\tspin_lock(&wbuf->lock);\n\toverlap = (lnum == wbuf->lnum && offs + len > wbuf->offs);\n\tif (!overlap) {\n\t\t \n\t\tspin_unlock(&wbuf->lock);\n\t\treturn ubifs_read_node(c, buf, type, len, lnum, offs);\n\t}\n\n\t \n\trlen = wbuf->offs - offs;\n\tif (rlen < 0)\n\t\trlen = 0;\n\n\t \n\tmemcpy(buf + rlen, wbuf->buf + offs + rlen - wbuf->offs, len - rlen);\n\tspin_unlock(&wbuf->lock);\n\n\tif (rlen > 0) {\n\t\t \n\t\terr = ubifs_leb_read(c, lnum, buf, offs, rlen, 0);\n\t\tif (err && err != -EBADMSG)\n\t\t\treturn err;\n\t}\n\n\tif (type != ch->node_type) {\n\t\tubifs_err(c, \"bad node type (%d but expected %d)\",\n\t\t\t  ch->node_type, type);\n\t\tgoto out;\n\t}\n\n\terr = ubifs_check_node(c, buf, len, lnum, offs, 0, 0);\n\tif (err) {\n\t\tubifs_err(c, \"expected node type %d\", type);\n\t\treturn err;\n\t}\n\n\trlen = le32_to_cpu(ch->len);\n\tif (rlen != len) {\n\t\tubifs_err(c, \"bad node length %d, expected %d\", rlen, len);\n\t\tgoto out;\n\t}\n\n\treturn 0;\n\nout:\n\tubifs_err(c, \"bad node at LEB %d:%d\", lnum, offs);\n\tubifs_dump_node(c, buf, len);\n\tdump_stack();\n\treturn -EINVAL;\n}\n\n \nint ubifs_read_node(const struct ubifs_info *c, void *buf, int type, int len,\n\t\t    int lnum, int offs)\n{\n\tint err, l;\n\tstruct ubifs_ch *ch = buf;\n\n\tdbg_io(\"LEB %d:%d, %s, length %d\", lnum, offs, dbg_ntype(type), len);\n\tubifs_assert(c, lnum >= 0 && lnum < c->leb_cnt && offs >= 0);\n\tubifs_assert(c, len >= UBIFS_CH_SZ && offs + len <= c->leb_size);\n\tubifs_assert(c, !(offs & 7) && offs < c->leb_size);\n\tubifs_assert(c, type >= 0 && type < UBIFS_NODE_TYPES_CNT);\n\n\terr = ubifs_leb_read(c, lnum, buf, offs, len, 0);\n\tif (err && err != -EBADMSG)\n\t\treturn err;\n\n\tif (type != ch->node_type) {\n\t\tubifs_errc(c, \"bad node type (%d but expected %d)\",\n\t\t\t   ch->node_type, type);\n\t\tgoto out;\n\t}\n\n\terr = ubifs_check_node(c, buf, len, lnum, offs, 0, 0);\n\tif (err) {\n\t\tubifs_errc(c, \"expected node type %d\", type);\n\t\treturn err;\n\t}\n\n\tl = le32_to_cpu(ch->len);\n\tif (l != len) {\n\t\tubifs_errc(c, \"bad node length %d, expected %d\", l, len);\n\t\tgoto out;\n\t}\n\n\treturn 0;\n\nout:\n\tubifs_errc(c, \"bad node at LEB %d:%d, LEB mapping status %d\", lnum,\n\t\t   offs, ubi_is_mapped(c->ubi, lnum));\n\tif (!c->probing) {\n\t\tubifs_dump_node(c, buf, len);\n\t\tdump_stack();\n\t}\n\treturn -EINVAL;\n}\n\n \nint ubifs_wbuf_init(struct ubifs_info *c, struct ubifs_wbuf *wbuf)\n{\n\tsize_t size;\n\n\twbuf->buf = kmalloc(c->max_write_size, GFP_KERNEL);\n\tif (!wbuf->buf)\n\t\treturn -ENOMEM;\n\n\tsize = (c->max_write_size / UBIFS_CH_SZ + 1) * sizeof(ino_t);\n\twbuf->inodes = kmalloc(size, GFP_KERNEL);\n\tif (!wbuf->inodes) {\n\t\tkfree(wbuf->buf);\n\t\twbuf->buf = NULL;\n\t\treturn -ENOMEM;\n\t}\n\n\twbuf->used = 0;\n\twbuf->lnum = wbuf->offs = -1;\n\t \n\tsize = c->max_write_size - (c->leb_start % c->max_write_size);\n\twbuf->avail = wbuf->size = size;\n\twbuf->sync_callback = NULL;\n\tmutex_init(&wbuf->io_mutex);\n\tspin_lock_init(&wbuf->lock);\n\twbuf->c = c;\n\twbuf->next_ino = 0;\n\n\thrtimer_init(&wbuf->timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\twbuf->timer.function = wbuf_timer_callback_nolock;\n\treturn 0;\n}\n\n \nvoid ubifs_wbuf_add_ino_nolock(struct ubifs_wbuf *wbuf, ino_t inum)\n{\n\tif (!wbuf->buf)\n\t\t \n\t\treturn;\n\n\tspin_lock(&wbuf->lock);\n\tif (wbuf->used)\n\t\twbuf->inodes[wbuf->next_ino++] = inum;\n\tspin_unlock(&wbuf->lock);\n}\n\n \nstatic int wbuf_has_ino(struct ubifs_wbuf *wbuf, ino_t inum)\n{\n\tint i, ret = 0;\n\n\tspin_lock(&wbuf->lock);\n\tfor (i = 0; i < wbuf->next_ino; i++)\n\t\tif (inum == wbuf->inodes[i]) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\tspin_unlock(&wbuf->lock);\n\n\treturn ret;\n}\n\n \nint ubifs_sync_wbufs_by_inode(struct ubifs_info *c, struct inode *inode)\n{\n\tint i, err = 0;\n\n\tfor (i = 0; i < c->jhead_cnt; i++) {\n\t\tstruct ubifs_wbuf *wbuf = &c->jheads[i].wbuf;\n\n\t\tif (i == GCHD)\n\t\t\t \n\t\t\tcontinue;\n\n\t\tif (!wbuf_has_ino(wbuf, inode->i_ino))\n\t\t\tcontinue;\n\n\t\tmutex_lock_nested(&wbuf->io_mutex, wbuf->jhead);\n\t\tif (wbuf_has_ino(wbuf, inode->i_ino))\n\t\t\terr = ubifs_wbuf_sync_nolock(wbuf);\n\t\tmutex_unlock(&wbuf->io_mutex);\n\n\t\tif (err) {\n\t\t\tubifs_ro_mode(c, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}