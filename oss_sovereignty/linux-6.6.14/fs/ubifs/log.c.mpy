{
  "module_name": "log.c",
  "hash_id": "82bbf5902b5a1e3c49d52ec06c82016cf0527ac48fd616935f339f34c5a33166",
  "original_prompt": "Ingested from linux-6.6.14/fs/ubifs/log.c",
  "human_readable_source": "\n \n\n \n\n#include \"ubifs.h\"\n\nstatic int dbg_check_bud_bytes(struct ubifs_info *c);\n\n \nstruct ubifs_bud *ubifs_search_bud(struct ubifs_info *c, int lnum)\n{\n\tstruct rb_node *p;\n\tstruct ubifs_bud *bud;\n\n\tspin_lock(&c->buds_lock);\n\tp = c->buds.rb_node;\n\twhile (p) {\n\t\tbud = rb_entry(p, struct ubifs_bud, rb);\n\t\tif (lnum < bud->lnum)\n\t\t\tp = p->rb_left;\n\t\telse if (lnum > bud->lnum)\n\t\t\tp = p->rb_right;\n\t\telse {\n\t\t\tspin_unlock(&c->buds_lock);\n\t\t\treturn bud;\n\t\t}\n\t}\n\tspin_unlock(&c->buds_lock);\n\treturn NULL;\n}\n\n \nstruct ubifs_wbuf *ubifs_get_wbuf(struct ubifs_info *c, int lnum)\n{\n\tstruct rb_node *p;\n\tstruct ubifs_bud *bud;\n\tint jhead;\n\n\tif (!c->jheads)\n\t\treturn NULL;\n\n\tspin_lock(&c->buds_lock);\n\tp = c->buds.rb_node;\n\twhile (p) {\n\t\tbud = rb_entry(p, struct ubifs_bud, rb);\n\t\tif (lnum < bud->lnum)\n\t\t\tp = p->rb_left;\n\t\telse if (lnum > bud->lnum)\n\t\t\tp = p->rb_right;\n\t\telse {\n\t\t\tjhead = bud->jhead;\n\t\t\tspin_unlock(&c->buds_lock);\n\t\t\treturn &c->jheads[jhead].wbuf;\n\t\t}\n\t}\n\tspin_unlock(&c->buds_lock);\n\treturn NULL;\n}\n\n \nstatic inline long long empty_log_bytes(const struct ubifs_info *c)\n{\n\tlong long h, t;\n\n\th = (long long)c->lhead_lnum * c->leb_size + c->lhead_offs;\n\tt = (long long)c->ltail_lnum * c->leb_size;\n\n\tif (h > t)\n\t\treturn c->log_bytes - h + t;\n\telse if (h != t)\n\t\treturn t - h;\n\telse if (c->lhead_lnum != c->ltail_lnum)\n\t\treturn 0;\n\telse\n\t\treturn c->log_bytes;\n}\n\n \nvoid ubifs_add_bud(struct ubifs_info *c, struct ubifs_bud *bud)\n{\n\tstruct rb_node **p, *parent = NULL;\n\tstruct ubifs_bud *b;\n\tstruct ubifs_jhead *jhead;\n\n\tspin_lock(&c->buds_lock);\n\tp = &c->buds.rb_node;\n\twhile (*p) {\n\t\tparent = *p;\n\t\tb = rb_entry(parent, struct ubifs_bud, rb);\n\t\tubifs_assert(c, bud->lnum != b->lnum);\n\t\tif (bud->lnum < b->lnum)\n\t\t\tp = &(*p)->rb_left;\n\t\telse\n\t\t\tp = &(*p)->rb_right;\n\t}\n\n\trb_link_node(&bud->rb, parent, p);\n\trb_insert_color(&bud->rb, &c->buds);\n\tif (c->jheads) {\n\t\tjhead = &c->jheads[bud->jhead];\n\t\tlist_add_tail(&bud->list, &jhead->buds_list);\n\t} else\n\t\tubifs_assert(c, c->replaying && c->ro_mount);\n\n\t \n\tc->bud_bytes += c->leb_size - bud->start;\n\n\tdbg_log(\"LEB %d:%d, jhead %s, bud_bytes %lld\", bud->lnum,\n\t\tbud->start, dbg_jhead(bud->jhead), c->bud_bytes);\n\tspin_unlock(&c->buds_lock);\n}\n\n \nint ubifs_add_bud_to_log(struct ubifs_info *c, int jhead, int lnum, int offs)\n{\n\tint err;\n\tstruct ubifs_bud *bud;\n\tstruct ubifs_ref_node *ref;\n\n\tbud = kmalloc(sizeof(struct ubifs_bud), GFP_NOFS);\n\tif (!bud)\n\t\treturn -ENOMEM;\n\tref = kzalloc(c->ref_node_alsz, GFP_NOFS);\n\tif (!ref) {\n\t\tkfree(bud);\n\t\treturn -ENOMEM;\n\t}\n\n\tmutex_lock(&c->log_mutex);\n\tubifs_assert(c, !c->ro_media && !c->ro_mount);\n\tif (c->ro_error) {\n\t\terr = -EROFS;\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (empty_log_bytes(c) - c->ref_node_alsz < c->min_log_bytes) {\n\t\tdbg_log(\"not enough log space - %lld, required %d\",\n\t\t\tempty_log_bytes(c), c->min_log_bytes);\n\t\tubifs_commit_required(c);\n\t\terr = -EAGAIN;\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (c->bud_bytes + c->leb_size - offs > c->max_bud_bytes) {\n\t\tdbg_log(\"bud bytes %lld (%lld max), require commit\",\n\t\t\tc->bud_bytes, c->max_bud_bytes);\n\t\tubifs_commit_required(c);\n\t\terr = -EAGAIN;\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tif (c->bud_bytes >= c->bg_bud_bytes &&\n\t    c->cmt_state == COMMIT_RESTING) {\n\t\tdbg_log(\"bud bytes %lld (%lld max), initiate BG commit\",\n\t\t\tc->bud_bytes, c->max_bud_bytes);\n\t\tubifs_request_bg_commit(c);\n\t}\n\n\tbud->lnum = lnum;\n\tbud->start = offs;\n\tbud->jhead = jhead;\n\tbud->log_hash = NULL;\n\n\tref->ch.node_type = UBIFS_REF_NODE;\n\tref->lnum = cpu_to_le32(bud->lnum);\n\tref->offs = cpu_to_le32(bud->start);\n\tref->jhead = cpu_to_le32(jhead);\n\n\tif (c->lhead_offs > c->leb_size - c->ref_node_alsz) {\n\t\tc->lhead_lnum = ubifs_next_log_lnum(c, c->lhead_lnum);\n\t\tubifs_assert(c, c->lhead_lnum != c->ltail_lnum);\n\t\tc->lhead_offs = 0;\n\t}\n\n\tif (c->lhead_offs == 0) {\n\t\t \n\t\terr = ubifs_leb_unmap(c, c->lhead_lnum);\n\t\tif (err)\n\t\t\tgoto out_unlock;\n\t}\n\n\tif (bud->start == 0) {\n\t\t \n\t\terr = ubifs_leb_map(c, bud->lnum);\n\t\tif (err)\n\t\t\tgoto out_unlock;\n\t}\n\n\tdbg_log(\"write ref LEB %d:%d\",\n\t\tc->lhead_lnum, c->lhead_offs);\n\terr = ubifs_write_node(c, ref, UBIFS_REF_NODE_SZ, c->lhead_lnum,\n\t\t\t       c->lhead_offs);\n\tif (err)\n\t\tgoto out_unlock;\n\n\terr = ubifs_shash_update(c, c->log_hash, ref, UBIFS_REF_NODE_SZ);\n\tif (err)\n\t\tgoto out_unlock;\n\n\terr = ubifs_shash_copy_state(c, c->log_hash, c->jheads[jhead].log_hash);\n\tif (err)\n\t\tgoto out_unlock;\n\n\tc->lhead_offs += c->ref_node_alsz;\n\n\tubifs_add_bud(c, bud);\n\n\tmutex_unlock(&c->log_mutex);\n\tkfree(ref);\n\treturn 0;\n\nout_unlock:\n\tmutex_unlock(&c->log_mutex);\n\tkfree(ref);\n\tkfree(bud);\n\treturn err;\n}\n\n \nstatic void remove_buds(struct ubifs_info *c)\n{\n\tstruct rb_node *p;\n\n\tubifs_assert(c, list_empty(&c->old_buds));\n\tc->cmt_bud_bytes = 0;\n\tspin_lock(&c->buds_lock);\n\tp = rb_first(&c->buds);\n\twhile (p) {\n\t\tstruct rb_node *p1 = p;\n\t\tstruct ubifs_bud *bud;\n\t\tstruct ubifs_wbuf *wbuf;\n\n\t\tp = rb_next(p);\n\t\tbud = rb_entry(p1, struct ubifs_bud, rb);\n\t\twbuf = &c->jheads[bud->jhead].wbuf;\n\n\t\tif (wbuf->lnum == bud->lnum) {\n\t\t\t \n\t\t\tc->cmt_bud_bytes += wbuf->offs - bud->start;\n\t\t\tdbg_log(\"preserve %d:%d, jhead %s, bud bytes %d, cmt_bud_bytes %lld\",\n\t\t\t\tbud->lnum, bud->start, dbg_jhead(bud->jhead),\n\t\t\t\twbuf->offs - bud->start, c->cmt_bud_bytes);\n\t\t\tbud->start = wbuf->offs;\n\t\t} else {\n\t\t\tc->cmt_bud_bytes += c->leb_size - bud->start;\n\t\t\tdbg_log(\"remove %d:%d, jhead %s, bud bytes %d, cmt_bud_bytes %lld\",\n\t\t\t\tbud->lnum, bud->start, dbg_jhead(bud->jhead),\n\t\t\t\tc->leb_size - bud->start, c->cmt_bud_bytes);\n\t\t\trb_erase(p1, &c->buds);\n\t\t\t \n\t\t\tlist_move(&bud->list, &c->old_buds);\n\t\t}\n\t}\n\tspin_unlock(&c->buds_lock);\n}\n\n \nint ubifs_log_start_commit(struct ubifs_info *c, int *ltail_lnum)\n{\n\tvoid *buf;\n\tstruct ubifs_cs_node *cs;\n\tstruct ubifs_ref_node *ref;\n\tint err, i, max_len, len;\n\n\terr = dbg_check_bud_bytes(c);\n\tif (err)\n\t\treturn err;\n\n\tmax_len = UBIFS_CS_NODE_SZ + c->jhead_cnt * UBIFS_REF_NODE_SZ;\n\tmax_len = ALIGN(max_len, c->min_io_size);\n\tbuf = cs = kmalloc(max_len, GFP_NOFS);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tcs->ch.node_type = UBIFS_CS_NODE;\n\tcs->cmt_no = cpu_to_le64(c->cmt_no);\n\tubifs_prepare_node(c, cs, UBIFS_CS_NODE_SZ, 0);\n\n\terr = ubifs_shash_init(c, c->log_hash);\n\tif (err)\n\t\tgoto out;\n\n\terr = ubifs_shash_update(c, c->log_hash, cs, UBIFS_CS_NODE_SZ);\n\tif (err < 0)\n\t\tgoto out;\n\n\t \n\n\tlen = UBIFS_CS_NODE_SZ;\n\tfor (i = 0; i < c->jhead_cnt; i++) {\n\t\tint lnum = c->jheads[i].wbuf.lnum;\n\t\tint offs = c->jheads[i].wbuf.offs;\n\n\t\tif (lnum == -1 || offs == c->leb_size)\n\t\t\tcontinue;\n\n\t\tdbg_log(\"add ref to LEB %d:%d for jhead %s\",\n\t\t\tlnum, offs, dbg_jhead(i));\n\t\tref = buf + len;\n\t\tref->ch.node_type = UBIFS_REF_NODE;\n\t\tref->lnum = cpu_to_le32(lnum);\n\t\tref->offs = cpu_to_le32(offs);\n\t\tref->jhead = cpu_to_le32(i);\n\n\t\tubifs_prepare_node(c, ref, UBIFS_REF_NODE_SZ, 0);\n\t\tlen += UBIFS_REF_NODE_SZ;\n\n\t\terr = ubifs_shash_update(c, c->log_hash, ref,\n\t\t\t\t\t UBIFS_REF_NODE_SZ);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tubifs_shash_copy_state(c, c->log_hash, c->jheads[i].log_hash);\n\t}\n\n\tubifs_pad(c, buf + len, ALIGN(len, c->min_io_size) - len);\n\n\t \n\tif (c->lhead_offs) {\n\t\tc->lhead_lnum = ubifs_next_log_lnum(c, c->lhead_lnum);\n\t\tubifs_assert(c, c->lhead_lnum != c->ltail_lnum);\n\t\tc->lhead_offs = 0;\n\t}\n\n\t \n\terr = ubifs_leb_unmap(c, c->lhead_lnum);\n\tif (err)\n\t\tgoto out;\n\n\tlen = ALIGN(len, c->min_io_size);\n\tdbg_log(\"writing commit start at LEB %d:0, len %d\", c->lhead_lnum, len);\n\terr = ubifs_leb_write(c, c->lhead_lnum, cs, 0, len);\n\tif (err)\n\t\tgoto out;\n\n\t*ltail_lnum = c->lhead_lnum;\n\n\tc->lhead_offs += len;\n\tubifs_assert(c, c->lhead_offs < c->leb_size);\n\n\tremove_buds(c);\n\n\t \n\tc->min_log_bytes = 0;\n\nout:\n\tkfree(buf);\n\treturn err;\n}\n\n \nint ubifs_log_end_commit(struct ubifs_info *c, int ltail_lnum)\n{\n\tint err;\n\n\t \n\tmutex_lock(&c->log_mutex);\n\n\tdbg_log(\"old tail was LEB %d:0, new tail is LEB %d:0\",\n\t\tc->ltail_lnum, ltail_lnum);\n\n\tc->ltail_lnum = ltail_lnum;\n\t \n\tc->min_log_bytes = c->leb_size;\n\n\tspin_lock(&c->buds_lock);\n\tc->bud_bytes -= c->cmt_bud_bytes;\n\tspin_unlock(&c->buds_lock);\n\n\terr = dbg_check_bud_bytes(c);\n\tif (err)\n\t\tgoto out;\n\n\terr = ubifs_write_master(c);\n\nout:\n\tmutex_unlock(&c->log_mutex);\n\treturn err;\n}\n\n \nint ubifs_log_post_commit(struct ubifs_info *c, int old_ltail_lnum)\n{\n\tint lnum, err = 0;\n\n\twhile (!list_empty(&c->old_buds)) {\n\t\tstruct ubifs_bud *bud;\n\n\t\tbud = list_entry(c->old_buds.next, struct ubifs_bud, list);\n\t\terr = ubifs_return_leb(c, bud->lnum);\n\t\tif (err)\n\t\t\treturn err;\n\t\tlist_del(&bud->list);\n\t\tkfree(bud->log_hash);\n\t\tkfree(bud);\n\t}\n\tmutex_lock(&c->log_mutex);\n\tfor (lnum = old_ltail_lnum; lnum != c->ltail_lnum;\n\t     lnum = ubifs_next_log_lnum(c, lnum)) {\n\t\tdbg_log(\"unmap log LEB %d\", lnum);\n\t\terr = ubifs_leb_unmap(c, lnum);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\nout:\n\tmutex_unlock(&c->log_mutex);\n\treturn err;\n}\n\n \nstruct done_ref {\n\tstruct rb_node rb;\n\tint lnum;\n};\n\n \nstatic int done_already(struct rb_root *done_tree, int lnum)\n{\n\tstruct rb_node **p = &done_tree->rb_node, *parent = NULL;\n\tstruct done_ref *dr;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tdr = rb_entry(parent, struct done_ref, rb);\n\t\tif (lnum < dr->lnum)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (lnum > dr->lnum)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\treturn 1;\n\t}\n\n\tdr = kzalloc(sizeof(struct done_ref), GFP_NOFS);\n\tif (!dr)\n\t\treturn -ENOMEM;\n\n\tdr->lnum = lnum;\n\n\trb_link_node(&dr->rb, parent, p);\n\trb_insert_color(&dr->rb, done_tree);\n\n\treturn 0;\n}\n\n \nstatic void destroy_done_tree(struct rb_root *done_tree)\n{\n\tstruct done_ref *dr, *n;\n\n\trbtree_postorder_for_each_entry_safe(dr, n, done_tree, rb)\n\t\tkfree(dr);\n}\n\n \nstatic int add_node(struct ubifs_info *c, void *buf, int *lnum, int *offs,\n\t\t    void *node)\n{\n\tstruct ubifs_ch *ch = node;\n\tint len = le32_to_cpu(ch->len), remains = c->leb_size - *offs;\n\n\tif (len > remains) {\n\t\tint sz = ALIGN(*offs, c->min_io_size), err;\n\n\t\tubifs_pad(c, buf + *offs, sz - *offs);\n\t\terr = ubifs_leb_change(c, *lnum, buf, sz);\n\t\tif (err)\n\t\t\treturn err;\n\t\t*lnum = ubifs_next_log_lnum(c, *lnum);\n\t\t*offs = 0;\n\t}\n\tmemcpy(buf + *offs, node, len);\n\t*offs += ALIGN(len, 8);\n\treturn 0;\n}\n\n \nint ubifs_consolidate_log(struct ubifs_info *c)\n{\n\tstruct ubifs_scan_leb *sleb;\n\tstruct ubifs_scan_node *snod;\n\tstruct rb_root done_tree = RB_ROOT;\n\tint lnum, err, first = 1, write_lnum, offs = 0;\n\tvoid *buf;\n\n\tdbg_rcvry(\"log tail LEB %d, log head LEB %d\", c->ltail_lnum,\n\t\t  c->lhead_lnum);\n\tbuf = vmalloc(c->leb_size);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\tlnum = c->ltail_lnum;\n\twrite_lnum = lnum;\n\twhile (1) {\n\t\tsleb = ubifs_scan(c, lnum, 0, c->sbuf, 0);\n\t\tif (IS_ERR(sleb)) {\n\t\t\terr = PTR_ERR(sleb);\n\t\t\tgoto out_free;\n\t\t}\n\t\tlist_for_each_entry(snod, &sleb->nodes, list) {\n\t\t\tswitch (snod->type) {\n\t\t\tcase UBIFS_REF_NODE: {\n\t\t\t\tstruct ubifs_ref_node *ref = snod->node;\n\t\t\t\tint ref_lnum = le32_to_cpu(ref->lnum);\n\n\t\t\t\terr = done_already(&done_tree, ref_lnum);\n\t\t\t\tif (err < 0)\n\t\t\t\t\tgoto out_scan;\n\t\t\t\tif (err != 1) {\n\t\t\t\t\terr = add_node(c, buf, &write_lnum,\n\t\t\t\t\t\t       &offs, snod->node);\n\t\t\t\t\tif (err)\n\t\t\t\t\t\tgoto out_scan;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase UBIFS_CS_NODE:\n\t\t\t\tif (!first)\n\t\t\t\t\tbreak;\n\t\t\t\terr = add_node(c, buf, &write_lnum, &offs,\n\t\t\t\t\t       snod->node);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto out_scan;\n\t\t\t\tfirst = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tubifs_scan_destroy(sleb);\n\t\tif (lnum == c->lhead_lnum)\n\t\t\tbreak;\n\t\tlnum = ubifs_next_log_lnum(c, lnum);\n\t}\n\tif (offs) {\n\t\tint sz = ALIGN(offs, c->min_io_size);\n\n\t\tubifs_pad(c, buf + offs, sz - offs);\n\t\terr = ubifs_leb_change(c, write_lnum, buf, sz);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t\toffs = ALIGN(offs, c->min_io_size);\n\t}\n\tdestroy_done_tree(&done_tree);\n\tvfree(buf);\n\tif (write_lnum == c->lhead_lnum) {\n\t\tubifs_err(c, \"log is too full\");\n\t\treturn -EINVAL;\n\t}\n\t \n\tlnum = write_lnum;\n\tdo {\n\t\tlnum = ubifs_next_log_lnum(c, lnum);\n\t\terr = ubifs_leb_unmap(c, lnum);\n\t\tif (err)\n\t\t\treturn err;\n\t} while (lnum != c->lhead_lnum);\n\tc->lhead_lnum = write_lnum;\n\tc->lhead_offs = offs;\n\tdbg_rcvry(\"new log head at %d:%d\", c->lhead_lnum, c->lhead_offs);\n\treturn 0;\n\nout_scan:\n\tubifs_scan_destroy(sleb);\nout_free:\n\tdestroy_done_tree(&done_tree);\n\tvfree(buf);\n\treturn err;\n}\n\n \nstatic int dbg_check_bud_bytes(struct ubifs_info *c)\n{\n\tint i, err = 0;\n\tstruct ubifs_bud *bud;\n\tlong long bud_bytes = 0;\n\n\tif (!dbg_is_chk_gen(c))\n\t\treturn 0;\n\n\tspin_lock(&c->buds_lock);\n\tfor (i = 0; i < c->jhead_cnt; i++)\n\t\tlist_for_each_entry(bud, &c->jheads[i].buds_list, list)\n\t\t\tbud_bytes += c->leb_size - bud->start;\n\n\tif (c->bud_bytes != bud_bytes) {\n\t\tubifs_err(c, \"bad bud_bytes %lld, calculated %lld\",\n\t\t\t  c->bud_bytes, bud_bytes);\n\t\terr = -EINVAL;\n\t}\n\tspin_unlock(&c->buds_lock);\n\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}