{
  "module_name": "xfs_log_priv.h",
  "hash_id": "80ded0fc799d7d8ae63d22e378aeada26f84824c8d90ce6e5e3e34e0910c8557",
  "original_prompt": "Ingested from linux-6.6.14/fs/xfs/xfs_log_priv.h",
  "human_readable_source": "\n \n#ifndef\t__XFS_LOG_PRIV_H__\n#define __XFS_LOG_PRIV_H__\n\n#include \"xfs_extent_busy.h\"\t \n\nstruct xfs_buf;\nstruct xlog;\nstruct xlog_ticket;\nstruct xfs_mount;\n\n \nstatic inline uint xlog_get_client_id(__be32 i)\n{\n\treturn be32_to_cpu(i) >> 24;\n}\n\n \nenum xlog_iclog_state {\n\tXLOG_STATE_ACTIVE,\t \n\tXLOG_STATE_WANT_SYNC,\t \n\tXLOG_STATE_SYNCING,\t \n\tXLOG_STATE_DONE_SYNC,\t \n\tXLOG_STATE_CALLBACK,\t \n\tXLOG_STATE_DIRTY,\t \n};\n\n#define XLOG_STATE_STRINGS \\\n\t{ XLOG_STATE_ACTIVE,\t\"XLOG_STATE_ACTIVE\" }, \\\n\t{ XLOG_STATE_WANT_SYNC,\t\"XLOG_STATE_WANT_SYNC\" }, \\\n\t{ XLOG_STATE_SYNCING,\t\"XLOG_STATE_SYNCING\" }, \\\n\t{ XLOG_STATE_DONE_SYNC,\t\"XLOG_STATE_DONE_SYNC\" }, \\\n\t{ XLOG_STATE_CALLBACK,\t\"XLOG_STATE_CALLBACK\" }, \\\n\t{ XLOG_STATE_DIRTY,\t\"XLOG_STATE_DIRTY\" }\n\n \n#define XLOG_ICL_NEED_FLUSH\t(1u << 0)\t \n#define XLOG_ICL_NEED_FUA\t(1u << 1)\t \n\n#define XLOG_ICL_STRINGS \\\n\t{ XLOG_ICL_NEED_FLUSH,\t\"XLOG_ICL_NEED_FLUSH\" }, \\\n\t{ XLOG_ICL_NEED_FUA,\t\"XLOG_ICL_NEED_FUA\" }\n\n\n \n#define XLOG_TIC_PERM_RESERV\t(1u << 0)\t \n\n#define XLOG_TIC_FLAGS \\\n\t{ XLOG_TIC_PERM_RESERV,\t\"XLOG_TIC_PERM_RESERV\" }\n\n \n\n#define XLOG_STATE_COVER_IDLE\t0\n#define XLOG_STATE_COVER_NEED\t1\n#define XLOG_STATE_COVER_DONE\t2\n#define XLOG_STATE_COVER_NEED2\t3\n#define XLOG_STATE_COVER_DONE2\t4\n\n#define XLOG_COVER_OPS\t\t5\n\ntypedef struct xlog_ticket {\n\tstruct list_head\tt_queue;\t \n\tstruct task_struct\t*t_task;\t \n\txlog_tid_t\t\tt_tid;\t\t \n\tatomic_t\t\tt_ref;\t\t \n\tint\t\t\tt_curr_res;\t \n\tint\t\t\tt_unit_res;\t \n\tchar\t\t\tt_ocnt;\t\t \n\tchar\t\t\tt_cnt;\t\t \n\tuint8_t\t\t\tt_flags;\t \n\tint\t\t\tt_iclog_hdrs;\t \n} xlog_ticket_t;\n\n \ntypedef struct xlog_in_core {\n\twait_queue_head_t\tic_force_wait;\n\twait_queue_head_t\tic_write_wait;\n\tstruct xlog_in_core\t*ic_next;\n\tstruct xlog_in_core\t*ic_prev;\n\tstruct xlog\t\t*ic_log;\n\tu32\t\t\tic_size;\n\tu32\t\t\tic_offset;\n\tenum xlog_iclog_state\tic_state;\n\tunsigned int\t\tic_flags;\n\tvoid\t\t\t*ic_datap;\t \n\tstruct list_head\tic_callbacks;\n\n\t \n\tatomic_t\t\tic_refcnt ____cacheline_aligned_in_smp;\n\txlog_in_core_2_t\t*ic_data;\n#define ic_header\tic_data->hic_header\n#ifdef DEBUG\n\tbool\t\t\tic_fail_crc : 1;\n#endif\n\tstruct semaphore\tic_sema;\n\tstruct work_struct\tic_end_io_work;\n\tstruct bio\t\tic_bio;\n\tstruct bio_vec\t\tic_bvec[];\n} xlog_in_core_t;\n\n \nstruct xfs_cil;\n\nstruct xfs_cil_ctx {\n\tstruct xfs_cil\t\t*cil;\n\txfs_csn_t\t\tsequence;\t \n\txfs_lsn_t\t\tstart_lsn;\t \n\txfs_lsn_t\t\tcommit_lsn;\t \n\tstruct xlog_in_core\t*commit_iclog;\n\tstruct xlog_ticket\t*ticket;\t \n\tatomic_t\t\tspace_used;\t \n\tstruct xfs_busy_extents\tbusy_extents;\n\tstruct list_head\tlog_items;\t \n\tstruct list_head\tlv_chain;\t \n\tstruct list_head\ticlog_entry;\n\tstruct list_head\tcommitting;\t \n\tstruct work_struct\tpush_work;\n\tatomic_t\t\torder_id;\n\n\t \n\tstruct cpumask\t\tcil_pcpmask;\n};\n\n \nstruct xlog_cil_pcp {\n\tint32_t\t\t\tspace_used;\n\tuint32_t\t\tspace_reserved;\n\tstruct list_head\tbusy_extents;\n\tstruct list_head\tlog_items;\n};\n\n \nstruct xfs_cil {\n\tstruct xlog\t\t*xc_log;\n\tunsigned long\t\txc_flags;\n\tatomic_t\t\txc_iclog_hdrs;\n\tstruct workqueue_struct\t*xc_push_wq;\n\n\tstruct rw_semaphore\txc_ctx_lock ____cacheline_aligned_in_smp;\n\tstruct xfs_cil_ctx\t*xc_ctx;\n\n\tspinlock_t\t\txc_push_lock ____cacheline_aligned_in_smp;\n\txfs_csn_t\t\txc_push_seq;\n\tbool\t\t\txc_push_commit_stable;\n\tstruct list_head\txc_committing;\n\twait_queue_head_t\txc_commit_wait;\n\twait_queue_head_t\txc_start_wait;\n\txfs_csn_t\t\txc_current_sequence;\n\twait_queue_head_t\txc_push_wait;\t \n\n\tvoid __percpu\t\t*xc_pcp;\t \n} ____cacheline_aligned_in_smp;\n\n \n#define\tXLOG_CIL_EMPTY\t\t1\n#define XLOG_CIL_PCP_SPACE\t2\n\n \n#define XLOG_CIL_SPACE_LIMIT(log)\t\\\n\tmin_t(int, (log)->l_logsize >> 3, BBTOB(XLOG_TOTAL_REC_SHIFT(log)) << 4)\n\n#define XLOG_CIL_BLOCKING_SPACE_LIMIT(log)\t\\\n\t(XLOG_CIL_SPACE_LIMIT(log) * 2)\n\n \nstruct xlog_grant_head {\n\tspinlock_t\t\tlock ____cacheline_aligned_in_smp;\n\tstruct list_head\twaiters;\n\tatomic64_t\t\tgrant;\n};\n\n \nstruct xlog {\n\t \n\tstruct xfs_mount\t*l_mp;\t         \n\tstruct xfs_ail\t\t*l_ailp;\t \n\tstruct xfs_cil\t\t*l_cilp;\t \n\tstruct xfs_buftarg\t*l_targ;         \n\tstruct workqueue_struct\t*l_ioend_workqueue;  \n\tstruct delayed_work\tl_work;\t\t \n\tlong\t\t\tl_opstate;\t \n\tuint\t\t\tl_quotaoffs_flag;  \n\tstruct list_head\t*l_buf_cancel_table;\n\tint\t\t\tl_iclog_hsize;   \n\tint\t\t\tl_iclog_heads;   \n\tuint\t\t\tl_sectBBsize;    \n\tint\t\t\tl_iclog_size;\t \n\tint\t\t\tl_iclog_bufs;\t \n\txfs_daddr_t\t\tl_logBBstart;    \n\tint\t\t\tl_logsize;       \n\tint\t\t\tl_logBBsize;     \n\n\t \n\twait_queue_head_t\tl_flush_wait ____cacheline_aligned_in_smp;\n\t\t\t\t\t\t \n\tint\t\t\tl_covered_state; \n\txlog_in_core_t\t\t*l_iclog;        \n\tspinlock_t\t\tl_icloglock;     \n\tint\t\t\tl_curr_cycle;    \n\tint\t\t\tl_prev_cycle;    \n\tint\t\t\tl_curr_block;    \n\tint\t\t\tl_prev_block;    \n\n\t \n\t \n\tatomic64_t\t\tl_last_sync_lsn ____cacheline_aligned_in_smp;\n\t \n\tatomic64_t\t\tl_tail_lsn ____cacheline_aligned_in_smp;\n\n\tstruct xlog_grant_head\tl_reserve_head;\n\tstruct xlog_grant_head\tl_write_head;\n\n\tstruct xfs_kobj\t\tl_kobj;\n\n\t \n\txfs_lsn_t\t\tl_recovery_lsn;\n\n\tuint32_t\t\tl_iclog_roundoff; \n\n\t \n\tstruct rw_semaphore\tl_incompat_users;\n};\n\n \n#define XLOG_ACTIVE_RECOVERY\t0\t \n#define XLOG_RECOVERY_NEEDED\t1\t \n#define XLOG_IO_ERROR\t\t2\t \n#define XLOG_TAIL_WARN\t\t3\t \n\nstatic inline bool\nxlog_recovery_needed(struct xlog *log)\n{\n\treturn test_bit(XLOG_RECOVERY_NEEDED, &log->l_opstate);\n}\n\nstatic inline bool\nxlog_in_recovery(struct xlog *log)\n{\n\treturn test_bit(XLOG_ACTIVE_RECOVERY, &log->l_opstate);\n}\n\nstatic inline bool\nxlog_is_shutdown(struct xlog *log)\n{\n\treturn test_bit(XLOG_IO_ERROR, &log->l_opstate);\n}\n\n \nstatic inline void\nxlog_shutdown_wait(\n\tstruct xlog\t*log)\n{\n\twait_var_event(&log->l_opstate, xlog_is_shutdown(log));\n}\n\n \nextern int\nxlog_recover(\n\tstruct xlog\t\t*log);\nextern int\nxlog_recover_finish(\n\tstruct xlog\t\t*log);\nextern void\nxlog_recover_cancel(struct xlog *);\n\nextern __le32\t xlog_cksum(struct xlog *log, struct xlog_rec_header *rhead,\n\t\t\t    char *dp, int size);\n\nextern struct kmem_cache *xfs_log_ticket_cache;\nstruct xlog_ticket *xlog_ticket_alloc(struct xlog *log, int unit_bytes,\n\t\tint count, bool permanent);\n\nvoid\txlog_print_tic_res(struct xfs_mount *mp, struct xlog_ticket *ticket);\nvoid\txlog_print_trans(struct xfs_trans *);\nint\txlog_write(struct xlog *log, struct xfs_cil_ctx *ctx,\n\t\tstruct list_head *lv_chain, struct xlog_ticket *tic,\n\t\tuint32_t len);\nvoid\txfs_log_ticket_ungrant(struct xlog *log, struct xlog_ticket *ticket);\nvoid\txfs_log_ticket_regrant(struct xlog *log, struct xlog_ticket *ticket);\n\nvoid xlog_state_switch_iclogs(struct xlog *log, struct xlog_in_core *iclog,\n\t\tint eventual_size);\nint xlog_state_release_iclog(struct xlog *log, struct xlog_in_core *iclog,\n\t\tstruct xlog_ticket *ticket);\n\n \nstatic inline void\nxlog_crack_atomic_lsn(atomic64_t *lsn, uint *cycle, uint *block)\n{\n\txfs_lsn_t val = atomic64_read(lsn);\n\n\t*cycle = CYCLE_LSN(val);\n\t*block = BLOCK_LSN(val);\n}\n\n \nstatic inline void\nxlog_assign_atomic_lsn(atomic64_t *lsn, uint cycle, uint block)\n{\n\tatomic64_set(lsn, xlog_assign_lsn(cycle, block));\n}\n\n \nstatic inline void\nxlog_crack_grant_head_val(int64_t val, int *cycle, int *space)\n{\n\t*cycle = val >> 32;\n\t*space = val & 0xffffffff;\n}\n\nstatic inline void\nxlog_crack_grant_head(atomic64_t *head, int *cycle, int *space)\n{\n\txlog_crack_grant_head_val(atomic64_read(head), cycle, space);\n}\n\nstatic inline int64_t\nxlog_assign_grant_head_val(int cycle, int space)\n{\n\treturn ((int64_t)cycle << 32) | space;\n}\n\nstatic inline void\nxlog_assign_grant_head(atomic64_t *head, int cycle, int space)\n{\n\tatomic64_set(head, xlog_assign_grant_head_val(cycle, space));\n}\n\n \nint\txlog_cil_init(struct xlog *log);\nvoid\txlog_cil_init_post_recovery(struct xlog *log);\nvoid\txlog_cil_destroy(struct xlog *log);\nbool\txlog_cil_empty(struct xlog *log);\nvoid\txlog_cil_commit(struct xlog *log, struct xfs_trans *tp,\n\t\t\txfs_csn_t *commit_seq, bool regrant);\nvoid\txlog_cil_set_ctx_write_state(struct xfs_cil_ctx *ctx,\n\t\t\tstruct xlog_in_core *iclog);\n\n\n \nvoid xlog_cil_flush(struct xlog *log);\nxfs_lsn_t xlog_cil_force_seq(struct xlog *log, xfs_csn_t sequence);\n\nstatic inline void\nxlog_cil_force(struct xlog *log)\n{\n\txlog_cil_force_seq(log, log->l_cilp->xc_current_sequence);\n}\n\n \nstatic inline void\nxlog_wait(\n\tstruct wait_queue_head\t*wq,\n\tstruct spinlock\t\t*lock)\n\t\t__releases(lock)\n{\n\tDECLARE_WAITQUEUE(wait, current);\n\n\tadd_wait_queue_exclusive(wq, &wait);\n\t__set_current_state(TASK_UNINTERRUPTIBLE);\n\tspin_unlock(lock);\n\tschedule();\n\tremove_wait_queue(wq, &wait);\n}\n\nint xlog_wait_on_iclog(struct xlog_in_core *iclog);\n\n \nstatic inline bool\nxlog_valid_lsn(\n\tstruct xlog\t*log,\n\txfs_lsn_t\tlsn)\n{\n\tint\t\tcur_cycle;\n\tint\t\tcur_block;\n\tbool\t\tvalid = true;\n\n\t \n\tcur_cycle = READ_ONCE(log->l_curr_cycle);\n\tsmp_rmb();\n\tcur_block = READ_ONCE(log->l_curr_block);\n\n\tif ((CYCLE_LSN(lsn) > cur_cycle) ||\n\t    (CYCLE_LSN(lsn) == cur_cycle && BLOCK_LSN(lsn) > cur_block)) {\n\t\t \n\t\tspin_lock(&log->l_icloglock);\n\t\tcur_cycle = log->l_curr_cycle;\n\t\tcur_block = log->l_curr_block;\n\t\tspin_unlock(&log->l_icloglock);\n\n\t\tif ((CYCLE_LSN(lsn) > cur_cycle) ||\n\t\t    (CYCLE_LSN(lsn) == cur_cycle && BLOCK_LSN(lsn) > cur_block))\n\t\t\tvalid = false;\n\t}\n\n\treturn valid;\n}\n\n \nstatic inline void *\nxlog_kvmalloc(\n\tsize_t\t\tbuf_size)\n{\n\tgfp_t\t\tflags = GFP_KERNEL;\n\tvoid\t\t*p;\n\n\tflags &= ~__GFP_DIRECT_RECLAIM;\n\tflags |= __GFP_NOWARN | __GFP_NORETRY;\n\tdo {\n\t\tp = kmalloc(buf_size, flags);\n\t\tif (!p)\n\t\t\tp = vmalloc(buf_size);\n\t} while (!p);\n\n\treturn p;\n}\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}