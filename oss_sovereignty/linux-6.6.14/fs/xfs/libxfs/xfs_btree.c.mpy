{
  "module_name": "xfs_btree.c",
  "hash_id": "1209f4d7b1d4a464fddeb0339b1cc30fa289e1fbcf993c07ef743b7eb418628d",
  "original_prompt": "Ingested from linux-6.6.14/fs/xfs/libxfs/xfs_btree.c",
  "human_readable_source": "\n \n#include \"xfs.h\"\n#include \"xfs_fs.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_format.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_bit.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_inode.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_buf_item.h\"\n#include \"xfs_btree.h\"\n#include \"xfs_errortag.h\"\n#include \"xfs_error.h\"\n#include \"xfs_trace.h\"\n#include \"xfs_alloc.h\"\n#include \"xfs_log.h\"\n#include \"xfs_btree_staging.h\"\n#include \"xfs_ag.h\"\n#include \"xfs_alloc_btree.h\"\n#include \"xfs_ialloc_btree.h\"\n#include \"xfs_bmap_btree.h\"\n#include \"xfs_rmap_btree.h\"\n#include \"xfs_refcount_btree.h\"\n\n \nstatic const uint32_t xfs_magics[2][XFS_BTNUM_MAX] = {\n\t{ XFS_ABTB_MAGIC, XFS_ABTC_MAGIC, 0, XFS_BMAP_MAGIC, XFS_IBT_MAGIC,\n\t  XFS_FIBT_MAGIC, 0 },\n\t{ XFS_ABTB_CRC_MAGIC, XFS_ABTC_CRC_MAGIC, XFS_RMAP_CRC_MAGIC,\n\t  XFS_BMAP_CRC_MAGIC, XFS_IBT_CRC_MAGIC, XFS_FIBT_CRC_MAGIC,\n\t  XFS_REFC_CRC_MAGIC }\n};\n\nuint32_t\nxfs_btree_magic(\n\tint\t\t\tcrc,\n\txfs_btnum_t\t\tbtnum)\n{\n\tuint32_t\t\tmagic = xfs_magics[crc][btnum];\n\n\t \n\tASSERT(magic != 0);\n\treturn magic;\n}\n\n \nstatic inline xfs_failaddr_t\nxfs_btree_check_lblock_siblings(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\txfs_fsblock_t\t\tfsb,\n\t__be64\t\t\tdsibling)\n{\n\txfs_fsblock_t\t\tsibling;\n\n\tif (dsibling == cpu_to_be64(NULLFSBLOCK))\n\t\treturn NULL;\n\n\tsibling = be64_to_cpu(dsibling);\n\tif (sibling == fsb)\n\t\treturn __this_address;\n\tif (level >= 0) {\n\t\tif (!xfs_btree_check_lptr(cur, sibling, level + 1))\n\t\t\treturn __this_address;\n\t} else {\n\t\tif (!xfs_verify_fsbno(mp, sibling))\n\t\t\treturn __this_address;\n\t}\n\n\treturn NULL;\n}\n\nstatic inline xfs_failaddr_t\nxfs_btree_check_sblock_siblings(\n\tstruct xfs_perag\t*pag,\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\txfs_agblock_t\t\tagbno,\n\t__be32\t\t\tdsibling)\n{\n\txfs_agblock_t\t\tsibling;\n\n\tif (dsibling == cpu_to_be32(NULLAGBLOCK))\n\t\treturn NULL;\n\n\tsibling = be32_to_cpu(dsibling);\n\tif (sibling == agbno)\n\t\treturn __this_address;\n\tif (level >= 0) {\n\t\tif (!xfs_btree_check_sptr(cur, sibling, level + 1))\n\t\t\treturn __this_address;\n\t} else {\n\t\tif (!xfs_verify_agbno(pag, sibling))\n\t\t\treturn __this_address;\n\t}\n\treturn NULL;\n}\n\n \nxfs_failaddr_t\n__xfs_btree_check_lblock(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tint\t\t\tlevel,\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = cur->bc_mp;\n\txfs_btnum_t\t\tbtnum = cur->bc_btnum;\n\tint\t\t\tcrc = xfs_has_crc(mp);\n\txfs_failaddr_t\t\tfa;\n\txfs_fsblock_t\t\tfsb = NULLFSBLOCK;\n\n\tif (crc) {\n\t\tif (!uuid_equal(&block->bb_u.l.bb_uuid, &mp->m_sb.sb_meta_uuid))\n\t\t\treturn __this_address;\n\t\tif (block->bb_u.l.bb_blkno !=\n\t\t    cpu_to_be64(bp ? xfs_buf_daddr(bp) : XFS_BUF_DADDR_NULL))\n\t\t\treturn __this_address;\n\t\tif (block->bb_u.l.bb_pad != cpu_to_be32(0))\n\t\t\treturn __this_address;\n\t}\n\n\tif (be32_to_cpu(block->bb_magic) != xfs_btree_magic(crc, btnum))\n\t\treturn __this_address;\n\tif (be16_to_cpu(block->bb_level) != level)\n\t\treturn __this_address;\n\tif (be16_to_cpu(block->bb_numrecs) >\n\t    cur->bc_ops->get_maxrecs(cur, level))\n\t\treturn __this_address;\n\n\tif (bp)\n\t\tfsb = XFS_DADDR_TO_FSB(mp, xfs_buf_daddr(bp));\n\n\tfa = xfs_btree_check_lblock_siblings(mp, cur, level, fsb,\n\t\t\tblock->bb_u.l.bb_leftsib);\n\tif (!fa)\n\t\tfa = xfs_btree_check_lblock_siblings(mp, cur, level, fsb,\n\t\t\t\tblock->bb_u.l.bb_rightsib);\n\treturn fa;\n}\n\n \nstatic int\nxfs_btree_check_lblock(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tint\t\t\tlevel,\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = cur->bc_mp;\n\txfs_failaddr_t\t\tfa;\n\n\tfa = __xfs_btree_check_lblock(cur, block, level, bp);\n\tif (XFS_IS_CORRUPT(mp, fa != NULL) ||\n\t    XFS_TEST_ERROR(false, mp, XFS_ERRTAG_BTREE_CHECK_LBLOCK)) {\n\t\tif (bp)\n\t\t\ttrace_xfs_btree_corrupt(bp, _RET_IP_);\n\t\treturn -EFSCORRUPTED;\n\t}\n\treturn 0;\n}\n\n \nxfs_failaddr_t\n__xfs_btree_check_sblock(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tint\t\t\tlevel,\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = cur->bc_mp;\n\tstruct xfs_perag\t*pag = cur->bc_ag.pag;\n\txfs_btnum_t\t\tbtnum = cur->bc_btnum;\n\tint\t\t\tcrc = xfs_has_crc(mp);\n\txfs_failaddr_t\t\tfa;\n\txfs_agblock_t\t\tagbno = NULLAGBLOCK;\n\n\tif (crc) {\n\t\tif (!uuid_equal(&block->bb_u.s.bb_uuid, &mp->m_sb.sb_meta_uuid))\n\t\t\treturn __this_address;\n\t\tif (block->bb_u.s.bb_blkno !=\n\t\t    cpu_to_be64(bp ? xfs_buf_daddr(bp) : XFS_BUF_DADDR_NULL))\n\t\t\treturn __this_address;\n\t}\n\n\tif (be32_to_cpu(block->bb_magic) != xfs_btree_magic(crc, btnum))\n\t\treturn __this_address;\n\tif (be16_to_cpu(block->bb_level) != level)\n\t\treturn __this_address;\n\tif (be16_to_cpu(block->bb_numrecs) >\n\t    cur->bc_ops->get_maxrecs(cur, level))\n\t\treturn __this_address;\n\n\tif (bp)\n\t\tagbno = xfs_daddr_to_agbno(mp, xfs_buf_daddr(bp));\n\n\tfa = xfs_btree_check_sblock_siblings(pag, cur, level, agbno,\n\t\t\tblock->bb_u.s.bb_leftsib);\n\tif (!fa)\n\t\tfa = xfs_btree_check_sblock_siblings(pag, cur, level, agbno,\n\t\t\t\tblock->bb_u.s.bb_rightsib);\n\treturn fa;\n}\n\n \nSTATIC int\nxfs_btree_check_sblock(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tint\t\t\tlevel,\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = cur->bc_mp;\n\txfs_failaddr_t\t\tfa;\n\n\tfa = __xfs_btree_check_sblock(cur, block, level, bp);\n\tif (XFS_IS_CORRUPT(mp, fa != NULL) ||\n\t    XFS_TEST_ERROR(false, mp, XFS_ERRTAG_BTREE_CHECK_SBLOCK)) {\n\t\tif (bp)\n\t\t\ttrace_xfs_btree_corrupt(bp, _RET_IP_);\n\t\treturn -EFSCORRUPTED;\n\t}\n\treturn 0;\n}\n\n \nint\nxfs_btree_check_block(\n\tstruct xfs_btree_cur\t*cur,\t \n\tstruct xfs_btree_block\t*block,\t \n\tint\t\t\tlevel,\t \n\tstruct xfs_buf\t\t*bp)\t \n{\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\treturn xfs_btree_check_lblock(cur, block, level, bp);\n\telse\n\t\treturn xfs_btree_check_sblock(cur, block, level, bp);\n}\n\n \nbool\nxfs_btree_check_lptr(\n\tstruct xfs_btree_cur\t*cur,\n\txfs_fsblock_t\t\tfsbno,\n\tint\t\t\tlevel)\n{\n\tif (level <= 0)\n\t\treturn false;\n\treturn xfs_verify_fsbno(cur->bc_mp, fsbno);\n}\n\n \nbool\nxfs_btree_check_sptr(\n\tstruct xfs_btree_cur\t*cur,\n\txfs_agblock_t\t\tagbno,\n\tint\t\t\tlevel)\n{\n\tif (level <= 0)\n\t\treturn false;\n\treturn xfs_verify_agbno(cur->bc_ag.pag, agbno);\n}\n\n \nstatic int\nxfs_btree_check_ptr(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr,\n\tint\t\t\t\tindex,\n\tint\t\t\t\tlevel)\n{\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tif (xfs_btree_check_lptr(cur, be64_to_cpu((&ptr->l)[index]),\n\t\t\t\tlevel))\n\t\t\treturn 0;\n\t\txfs_err(cur->bc_mp,\n\"Inode %llu fork %d: Corrupt btree %d pointer at level %d index %d.\",\n\t\t\t\tcur->bc_ino.ip->i_ino,\n\t\t\t\tcur->bc_ino.whichfork, cur->bc_btnum,\n\t\t\t\tlevel, index);\n\t} else {\n\t\tif (xfs_btree_check_sptr(cur, be32_to_cpu((&ptr->s)[index]),\n\t\t\t\tlevel))\n\t\t\treturn 0;\n\t\txfs_err(cur->bc_mp,\n\"AG %u: Corrupt btree %d pointer at level %d index %d.\",\n\t\t\t\tcur->bc_ag.pag->pag_agno, cur->bc_btnum,\n\t\t\t\tlevel, index);\n\t}\n\n\treturn -EFSCORRUPTED;\n}\n\n#ifdef DEBUG\n# define xfs_btree_debug_check_ptr\txfs_btree_check_ptr\n#else\n# define xfs_btree_debug_check_ptr(...)\t(0)\n#endif\n\n \nvoid\nxfs_btree_lblock_calc_crc(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\tstruct xfs_buf_log_item\t*bip = bp->b_log_item;\n\n\tif (!xfs_has_crc(bp->b_mount))\n\t\treturn;\n\tif (bip)\n\t\tblock->bb_u.l.bb_lsn = cpu_to_be64(bip->bli_item.li_lsn);\n\txfs_buf_update_cksum(bp, XFS_BTREE_LBLOCK_CRC_OFF);\n}\n\nbool\nxfs_btree_lblock_verify_crc(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\n\tif (xfs_has_crc(mp)) {\n\t\tif (!xfs_log_check_lsn(mp, be64_to_cpu(block->bb_u.l.bb_lsn)))\n\t\t\treturn false;\n\t\treturn xfs_buf_verify_cksum(bp, XFS_BTREE_LBLOCK_CRC_OFF);\n\t}\n\n\treturn true;\n}\n\n \nvoid\nxfs_btree_sblock_calc_crc(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\tstruct xfs_buf_log_item\t*bip = bp->b_log_item;\n\n\tif (!xfs_has_crc(bp->b_mount))\n\t\treturn;\n\tif (bip)\n\t\tblock->bb_u.s.bb_lsn = cpu_to_be64(bip->bli_item.li_lsn);\n\txfs_buf_update_cksum(bp, XFS_BTREE_SBLOCK_CRC_OFF);\n}\n\nbool\nxfs_btree_sblock_verify_crc(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_btree_block  *block = XFS_BUF_TO_BLOCK(bp);\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\n\tif (xfs_has_crc(mp)) {\n\t\tif (!xfs_log_check_lsn(mp, be64_to_cpu(block->bb_u.s.bb_lsn)))\n\t\t\treturn false;\n\t\treturn xfs_buf_verify_cksum(bp, XFS_BTREE_SBLOCK_CRC_OFF);\n\t}\n\n\treturn true;\n}\n\nstatic int\nxfs_btree_free_block(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp)\n{\n\tint\t\t\terror;\n\n\terror = cur->bc_ops->free_block(cur, bp);\n\tif (!error) {\n\t\txfs_trans_binval(cur->bc_tp, bp);\n\t\tXFS_BTREE_STATS_INC(cur, free);\n\t}\n\treturn error;\n}\n\n \nvoid\nxfs_btree_del_cursor(\n\tstruct xfs_btree_cur\t*cur,\t\t \n\tint\t\t\terror)\t\t \n{\n\tint\t\t\ti;\t\t \n\n\t \n\tfor (i = 0; i < cur->bc_nlevels; i++) {\n\t\tif (cur->bc_levels[i].bp)\n\t\t\txfs_trans_brelse(cur->bc_tp, cur->bc_levels[i].bp);\n\t\telse if (!error)\n\t\t\tbreak;\n\t}\n\n\t \n\tASSERT(cur->bc_btnum != XFS_BTNUM_BMAP || cur->bc_ino.allocated == 0 ||\n\t       xfs_is_shutdown(cur->bc_mp) || error != 0);\n\tif (unlikely(cur->bc_flags & XFS_BTREE_STAGING))\n\t\tkmem_free(cur->bc_ops);\n\tif (!(cur->bc_flags & XFS_BTREE_LONG_PTRS) && cur->bc_ag.pag)\n\t\txfs_perag_put(cur->bc_ag.pag);\n\tkmem_cache_free(cur->bc_cache, cur);\n}\n\n \nint\t\t\t\t\t \nxfs_btree_dup_cursor(\n\tstruct xfs_btree_cur *cur,\t\t \n\tstruct xfs_btree_cur **ncur)\t\t \n{\n\tstruct xfs_buf\t*bp;\t\t \n\tint\t\terror;\t\t \n\tint\t\ti;\t\t \n\txfs_mount_t\t*mp;\t\t \n\tstruct xfs_btree_cur *new;\t\t \n\txfs_trans_t\t*tp;\t\t \n\n\ttp = cur->bc_tp;\n\tmp = cur->bc_mp;\n\n\t \n\tnew = cur->bc_ops->dup_cursor(cur);\n\n\t \n\tnew->bc_rec = cur->bc_rec;\n\n\t \n\tfor (i = 0; i < new->bc_nlevels; i++) {\n\t\tnew->bc_levels[i].ptr = cur->bc_levels[i].ptr;\n\t\tnew->bc_levels[i].ra = cur->bc_levels[i].ra;\n\t\tbp = cur->bc_levels[i].bp;\n\t\tif (bp) {\n\t\t\terror = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp,\n\t\t\t\t\t\t   xfs_buf_daddr(bp), mp->m_bsize,\n\t\t\t\t\t\t   0, &bp,\n\t\t\t\t\t\t   cur->bc_ops->buf_ops);\n\t\t\tif (error) {\n\t\t\t\txfs_btree_del_cursor(new, error);\n\t\t\t\t*ncur = NULL;\n\t\t\t\treturn error;\n\t\t\t}\n\t\t}\n\t\tnew->bc_levels[i].bp = bp;\n\t}\n\t*ncur = new;\n\treturn 0;\n}\n\n \n\n \nstatic inline size_t xfs_btree_block_len(struct xfs_btree_cur *cur)\n{\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS)\n\t\t\treturn XFS_BTREE_LBLOCK_CRC_LEN;\n\t\treturn XFS_BTREE_LBLOCK_LEN;\n\t}\n\tif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS)\n\t\treturn XFS_BTREE_SBLOCK_CRC_LEN;\n\treturn XFS_BTREE_SBLOCK_LEN;\n}\n\n \nstatic inline size_t xfs_btree_ptr_len(struct xfs_btree_cur *cur)\n{\n\treturn (cur->bc_flags & XFS_BTREE_LONG_PTRS) ?\n\t\tsizeof(__be64) : sizeof(__be32);\n}\n\n \nSTATIC size_t\nxfs_btree_rec_offset(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn)\n{\n\treturn xfs_btree_block_len(cur) +\n\t\t(n - 1) * cur->bc_ops->rec_len;\n}\n\n \nSTATIC size_t\nxfs_btree_key_offset(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn)\n{\n\treturn xfs_btree_block_len(cur) +\n\t\t(n - 1) * cur->bc_ops->key_len;\n}\n\n \nSTATIC size_t\nxfs_btree_high_key_offset(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn)\n{\n\treturn xfs_btree_block_len(cur) +\n\t\t(n - 1) * cur->bc_ops->key_len + (cur->bc_ops->key_len / 2);\n}\n\n \nSTATIC size_t\nxfs_btree_ptr_offset(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn,\n\tint\t\t\tlevel)\n{\n\treturn xfs_btree_block_len(cur) +\n\t\tcur->bc_ops->get_maxrecs(cur, level) * cur->bc_ops->key_len +\n\t\t(n - 1) * xfs_btree_ptr_len(cur);\n}\n\n \nunion xfs_btree_rec *\nxfs_btree_rec_addr(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn,\n\tstruct xfs_btree_block\t*block)\n{\n\treturn (union xfs_btree_rec *)\n\t\t((char *)block + xfs_btree_rec_offset(cur, n));\n}\n\n \nunion xfs_btree_key *\nxfs_btree_key_addr(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn,\n\tstruct xfs_btree_block\t*block)\n{\n\treturn (union xfs_btree_key *)\n\t\t((char *)block + xfs_btree_key_offset(cur, n));\n}\n\n \nunion xfs_btree_key *\nxfs_btree_high_key_addr(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn,\n\tstruct xfs_btree_block\t*block)\n{\n\treturn (union xfs_btree_key *)\n\t\t((char *)block + xfs_btree_high_key_offset(cur, n));\n}\n\n \nunion xfs_btree_ptr *\nxfs_btree_ptr_addr(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tn,\n\tstruct xfs_btree_block\t*block)\n{\n\tint\t\t\tlevel = xfs_btree_get_level(block);\n\n\tASSERT(block->bb_level != 0);\n\n\treturn (union xfs_btree_ptr *)\n\t\t((char *)block + xfs_btree_ptr_offset(cur, n, level));\n}\n\nstruct xfs_ifork *\nxfs_btree_ifork_ptr(\n\tstruct xfs_btree_cur\t*cur)\n{\n\tASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\n\n\tif (cur->bc_flags & XFS_BTREE_STAGING)\n\t\treturn cur->bc_ino.ifake->if_fork;\n\treturn xfs_ifork_ptr(cur->bc_ino.ip, cur->bc_ino.whichfork);\n}\n\n \nSTATIC struct xfs_btree_block *\nxfs_btree_get_iroot(\n\tstruct xfs_btree_cur\t*cur)\n{\n\tstruct xfs_ifork\t*ifp = xfs_btree_ifork_ptr(cur);\n\n\treturn (struct xfs_btree_block *)ifp->if_broot;\n}\n\n \nstruct xfs_btree_block *\t\t \nxfs_btree_get_block(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\tlevel,\t \n\tstruct xfs_buf\t\t**bpp)\t \n{\n\tif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    (level == cur->bc_nlevels - 1)) {\n\t\t*bpp = NULL;\n\t\treturn xfs_btree_get_iroot(cur);\n\t}\n\n\t*bpp = cur->bc_levels[level].bp;\n\treturn XFS_BUF_TO_BLOCK(*bpp);\n}\n\n \nSTATIC int\t\t\t\t \nxfs_btree_firstrec(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\tlevel)\t \n{\n\tstruct xfs_btree_block\t*block;\t \n\tstruct xfs_buf\t\t*bp;\t \n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\tif (xfs_btree_check_block(cur, block, level, bp))\n\t\treturn 0;\n\t \n\tif (!block->bb_numrecs)\n\t\treturn 0;\n\t \n\tcur->bc_levels[level].ptr = 1;\n\treturn 1;\n}\n\n \nSTATIC int\t\t\t\t \nxfs_btree_lastrec(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\tlevel)\t \n{\n\tstruct xfs_btree_block\t*block;\t \n\tstruct xfs_buf\t\t*bp;\t \n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\tif (xfs_btree_check_block(cur, block, level, bp))\n\t\treturn 0;\n\t \n\tif (!block->bb_numrecs)\n\t\treturn 0;\n\t \n\tcur->bc_levels[level].ptr = be16_to_cpu(block->bb_numrecs);\n\treturn 1;\n}\n\n \nvoid\nxfs_btree_offsets(\n\tuint32_t\tfields,\t\t \n\tconst short\t*offsets,\t \n\tint\t\tnbits,\t\t \n\tint\t\t*first,\t\t \n\tint\t\t*last)\t\t \n{\n\tint\t\ti;\t\t \n\tuint32_t\timask;\t\t \n\n\tASSERT(fields != 0);\n\t \n\tfor (i = 0, imask = 1u; ; i++, imask <<= 1) {\n\t\tif (imask & fields) {\n\t\t\t*first = offsets[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\t \n\tfor (i = nbits - 1, imask = 1u << i; ; i--, imask >>= 1) {\n\t\tif (imask & fields) {\n\t\t\t*last = offsets[i + 1] - 1;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nint\nxfs_btree_read_bufl(\n\tstruct xfs_mount\t*mp,\t\t \n\tstruct xfs_trans\t*tp,\t\t \n\txfs_fsblock_t\t\tfsbno,\t\t \n\tstruct xfs_buf\t\t**bpp,\t\t \n\tint\t\t\trefval,\t\t \n\tconst struct xfs_buf_ops *ops)\n{\n\tstruct xfs_buf\t\t*bp;\t\t \n\txfs_daddr_t\t\td;\t\t \n\tint\t\t\terror;\n\n\tif (!xfs_verify_fsbno(mp, fsbno))\n\t\treturn -EFSCORRUPTED;\n\td = XFS_FSB_TO_DADDR(mp, fsbno);\n\terror = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp, d,\n\t\t\t\t   mp->m_bsize, 0, &bp, ops);\n\tif (error)\n\t\treturn error;\n\tif (bp)\n\t\txfs_buf_set_ref(bp, refval);\n\t*bpp = bp;\n\treturn 0;\n}\n\n \n \nvoid\nxfs_btree_reada_bufl(\n\tstruct xfs_mount\t*mp,\t\t \n\txfs_fsblock_t\t\tfsbno,\t\t \n\txfs_extlen_t\t\tcount,\t\t \n\tconst struct xfs_buf_ops *ops)\n{\n\txfs_daddr_t\t\td;\n\n\tASSERT(fsbno != NULLFSBLOCK);\n\td = XFS_FSB_TO_DADDR(mp, fsbno);\n\txfs_buf_readahead(mp->m_ddev_targp, d, mp->m_bsize * count, ops);\n}\n\n \n \nvoid\nxfs_btree_reada_bufs(\n\tstruct xfs_mount\t*mp,\t\t \n\txfs_agnumber_t\t\tagno,\t\t \n\txfs_agblock_t\t\tagbno,\t\t \n\txfs_extlen_t\t\tcount,\t\t \n\tconst struct xfs_buf_ops *ops)\n{\n\txfs_daddr_t\t\td;\n\n\tASSERT(agno != NULLAGNUMBER);\n\tASSERT(agbno != NULLAGBLOCK);\n\td = XFS_AGB_TO_DADDR(mp, agno, agbno);\n\txfs_buf_readahead(mp->m_ddev_targp, d, mp->m_bsize * count, ops);\n}\n\nSTATIC int\nxfs_btree_readahead_lblock(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlr,\n\tstruct xfs_btree_block\t*block)\n{\n\tint\t\t\trval = 0;\n\txfs_fsblock_t\t\tleft = be64_to_cpu(block->bb_u.l.bb_leftsib);\n\txfs_fsblock_t\t\tright = be64_to_cpu(block->bb_u.l.bb_rightsib);\n\n\tif ((lr & XFS_BTCUR_LEFTRA) && left != NULLFSBLOCK) {\n\t\txfs_btree_reada_bufl(cur->bc_mp, left, 1,\n\t\t\t\t     cur->bc_ops->buf_ops);\n\t\trval++;\n\t}\n\n\tif ((lr & XFS_BTCUR_RIGHTRA) && right != NULLFSBLOCK) {\n\t\txfs_btree_reada_bufl(cur->bc_mp, right, 1,\n\t\t\t\t     cur->bc_ops->buf_ops);\n\t\trval++;\n\t}\n\n\treturn rval;\n}\n\nSTATIC int\nxfs_btree_readahead_sblock(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlr,\n\tstruct xfs_btree_block *block)\n{\n\tint\t\t\trval = 0;\n\txfs_agblock_t\t\tleft = be32_to_cpu(block->bb_u.s.bb_leftsib);\n\txfs_agblock_t\t\tright = be32_to_cpu(block->bb_u.s.bb_rightsib);\n\n\n\tif ((lr & XFS_BTCUR_LEFTRA) && left != NULLAGBLOCK) {\n\t\txfs_btree_reada_bufs(cur->bc_mp, cur->bc_ag.pag->pag_agno,\n\t\t\t\t     left, 1, cur->bc_ops->buf_ops);\n\t\trval++;\n\t}\n\n\tif ((lr & XFS_BTCUR_RIGHTRA) && right != NULLAGBLOCK) {\n\t\txfs_btree_reada_bufs(cur->bc_mp, cur->bc_ag.pag->pag_agno,\n\t\t\t\t     right, 1, cur->bc_ops->buf_ops);\n\t\trval++;\n\t}\n\n\treturn rval;\n}\n\n \nSTATIC int\nxfs_btree_readahead(\n\tstruct xfs_btree_cur\t*cur,\t\t \n\tint\t\t\tlev,\t\t \n\tint\t\t\tlr)\t\t \n{\n\tstruct xfs_btree_block\t*block;\n\n\t \n\tif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    (lev == cur->bc_nlevels - 1))\n\t\treturn 0;\n\n\tif ((cur->bc_levels[lev].ra | lr) == cur->bc_levels[lev].ra)\n\t\treturn 0;\n\n\tcur->bc_levels[lev].ra |= lr;\n\tblock = XFS_BUF_TO_BLOCK(cur->bc_levels[lev].bp);\n\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\treturn xfs_btree_readahead_lblock(cur, lr, block);\n\treturn xfs_btree_readahead_sblock(cur, lr, block);\n}\n\nSTATIC int\nxfs_btree_ptr_to_daddr(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr,\n\txfs_daddr_t\t\t\t*daddr)\n{\n\txfs_fsblock_t\t\tfsbno;\n\txfs_agblock_t\t\tagbno;\n\tint\t\t\terror;\n\n\terror = xfs_btree_check_ptr(cur, ptr, 0, 1);\n\tif (error)\n\t\treturn error;\n\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tfsbno = be64_to_cpu(ptr->l);\n\t\t*daddr = XFS_FSB_TO_DADDR(cur->bc_mp, fsbno);\n\t} else {\n\t\tagbno = be32_to_cpu(ptr->s);\n\t\t*daddr = XFS_AGB_TO_DADDR(cur->bc_mp, cur->bc_ag.pag->pag_agno,\n\t\t\t\tagbno);\n\t}\n\n\treturn 0;\n}\n\n \nSTATIC void\nxfs_btree_readahead_ptr(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_ptr\t*ptr,\n\txfs_extlen_t\t\tcount)\n{\n\txfs_daddr_t\t\tdaddr;\n\n\tif (xfs_btree_ptr_to_daddr(cur, ptr, &daddr))\n\t\treturn;\n\txfs_buf_readahead(cur->bc_mp->m_ddev_targp, daddr,\n\t\t\t  cur->bc_mp->m_bsize * count, cur->bc_ops->buf_ops);\n}\n\n \nSTATIC void\nxfs_btree_setbuf(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\tlev,\t \n\tstruct xfs_buf\t\t*bp)\t \n{\n\tstruct xfs_btree_block\t*b;\t \n\n\tif (cur->bc_levels[lev].bp)\n\t\txfs_trans_brelse(cur->bc_tp, cur->bc_levels[lev].bp);\n\tcur->bc_levels[lev].bp = bp;\n\tcur->bc_levels[lev].ra = 0;\n\n\tb = XFS_BUF_TO_BLOCK(bp);\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tif (b->bb_u.l.bb_leftsib == cpu_to_be64(NULLFSBLOCK))\n\t\t\tcur->bc_levels[lev].ra |= XFS_BTCUR_LEFTRA;\n\t\tif (b->bb_u.l.bb_rightsib == cpu_to_be64(NULLFSBLOCK))\n\t\t\tcur->bc_levels[lev].ra |= XFS_BTCUR_RIGHTRA;\n\t} else {\n\t\tif (b->bb_u.s.bb_leftsib == cpu_to_be32(NULLAGBLOCK))\n\t\t\tcur->bc_levels[lev].ra |= XFS_BTCUR_LEFTRA;\n\t\tif (b->bb_u.s.bb_rightsib == cpu_to_be32(NULLAGBLOCK))\n\t\t\tcur->bc_levels[lev].ra |= XFS_BTCUR_RIGHTRA;\n\t}\n}\n\nbool\nxfs_btree_ptr_is_null(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr)\n{\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\treturn ptr->l == cpu_to_be64(NULLFSBLOCK);\n\telse\n\t\treturn ptr->s == cpu_to_be32(NULLAGBLOCK);\n}\n\nvoid\nxfs_btree_set_ptr_null(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_ptr\t*ptr)\n{\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\tptr->l = cpu_to_be64(NULLFSBLOCK);\n\telse\n\t\tptr->s = cpu_to_be32(NULLAGBLOCK);\n}\n\n \nvoid\nxfs_btree_get_sibling(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tunion xfs_btree_ptr\t*ptr,\n\tint\t\t\tlr)\n{\n\tASSERT(lr == XFS_BB_LEFTSIB || lr == XFS_BB_RIGHTSIB);\n\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tif (lr == XFS_BB_RIGHTSIB)\n\t\t\tptr->l = block->bb_u.l.bb_rightsib;\n\t\telse\n\t\t\tptr->l = block->bb_u.l.bb_leftsib;\n\t} else {\n\t\tif (lr == XFS_BB_RIGHTSIB)\n\t\t\tptr->s = block->bb_u.s.bb_rightsib;\n\t\telse\n\t\t\tptr->s = block->bb_u.s.bb_leftsib;\n\t}\n}\n\nvoid\nxfs_btree_set_sibling(\n\tstruct xfs_btree_cur\t\t*cur,\n\tstruct xfs_btree_block\t\t*block,\n\tconst union xfs_btree_ptr\t*ptr,\n\tint\t\t\t\tlr)\n{\n\tASSERT(lr == XFS_BB_LEFTSIB || lr == XFS_BB_RIGHTSIB);\n\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tif (lr == XFS_BB_RIGHTSIB)\n\t\t\tblock->bb_u.l.bb_rightsib = ptr->l;\n\t\telse\n\t\t\tblock->bb_u.l.bb_leftsib = ptr->l;\n\t} else {\n\t\tif (lr == XFS_BB_RIGHTSIB)\n\t\t\tblock->bb_u.s.bb_rightsib = ptr->s;\n\t\telse\n\t\t\tblock->bb_u.s.bb_leftsib = ptr->s;\n\t}\n}\n\nvoid\nxfs_btree_init_block_int(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_btree_block\t*buf,\n\txfs_daddr_t\t\tblkno,\n\txfs_btnum_t\t\tbtnum,\n\t__u16\t\t\tlevel,\n\t__u16\t\t\tnumrecs,\n\t__u64\t\t\towner,\n\tunsigned int\t\tflags)\n{\n\tint\t\t\tcrc = xfs_has_crc(mp);\n\t__u32\t\t\tmagic = xfs_btree_magic(crc, btnum);\n\n\tbuf->bb_magic = cpu_to_be32(magic);\n\tbuf->bb_level = cpu_to_be16(level);\n\tbuf->bb_numrecs = cpu_to_be16(numrecs);\n\n\tif (flags & XFS_BTREE_LONG_PTRS) {\n\t\tbuf->bb_u.l.bb_leftsib = cpu_to_be64(NULLFSBLOCK);\n\t\tbuf->bb_u.l.bb_rightsib = cpu_to_be64(NULLFSBLOCK);\n\t\tif (crc) {\n\t\t\tbuf->bb_u.l.bb_blkno = cpu_to_be64(blkno);\n\t\t\tbuf->bb_u.l.bb_owner = cpu_to_be64(owner);\n\t\t\tuuid_copy(&buf->bb_u.l.bb_uuid, &mp->m_sb.sb_meta_uuid);\n\t\t\tbuf->bb_u.l.bb_pad = 0;\n\t\t\tbuf->bb_u.l.bb_lsn = 0;\n\t\t}\n\t} else {\n\t\t \n\t\t__u32 __owner = (__u32)owner;\n\n\t\tbuf->bb_u.s.bb_leftsib = cpu_to_be32(NULLAGBLOCK);\n\t\tbuf->bb_u.s.bb_rightsib = cpu_to_be32(NULLAGBLOCK);\n\t\tif (crc) {\n\t\t\tbuf->bb_u.s.bb_blkno = cpu_to_be64(blkno);\n\t\t\tbuf->bb_u.s.bb_owner = cpu_to_be32(__owner);\n\t\t\tuuid_copy(&buf->bb_u.s.bb_uuid, &mp->m_sb.sb_meta_uuid);\n\t\t\tbuf->bb_u.s.bb_lsn = 0;\n\t\t}\n\t}\n}\n\nvoid\nxfs_btree_init_block(\n\tstruct xfs_mount *mp,\n\tstruct xfs_buf\t*bp,\n\txfs_btnum_t\tbtnum,\n\t__u16\t\tlevel,\n\t__u16\t\tnumrecs,\n\t__u64\t\towner)\n{\n\txfs_btree_init_block_int(mp, XFS_BUF_TO_BLOCK(bp), xfs_buf_daddr(bp),\n\t\t\t\t btnum, level, numrecs, owner, 0);\n}\n\nvoid\nxfs_btree_init_block_cur(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp,\n\tint\t\t\tlevel,\n\tint\t\t\tnumrecs)\n{\n\t__u64\t\t\towner;\n\n\t \n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\towner = cur->bc_ino.ip->i_ino;\n\telse\n\t\towner = cur->bc_ag.pag->pag_agno;\n\n\txfs_btree_init_block_int(cur->bc_mp, XFS_BUF_TO_BLOCK(bp),\n\t\t\t\txfs_buf_daddr(bp), cur->bc_btnum, level,\n\t\t\t\tnumrecs, owner, cur->bc_flags);\n}\n\n \nSTATIC int\nxfs_btree_is_lastrec(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tint\t\t\tlevel)\n{\n\tunion xfs_btree_ptr\tptr;\n\n\tif (level > 0)\n\t\treturn 0;\n\tif (!(cur->bc_flags & XFS_BTREE_LASTREC_UPDATE))\n\t\treturn 0;\n\n\txfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\n\tif (!xfs_btree_ptr_is_null(cur, &ptr))\n\t\treturn 0;\n\treturn 1;\n}\n\nSTATIC void\nxfs_btree_buf_to_ptr(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp,\n\tunion xfs_btree_ptr\t*ptr)\n{\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\tptr->l = cpu_to_be64(XFS_DADDR_TO_FSB(cur->bc_mp,\n\t\t\t\t\txfs_buf_daddr(bp)));\n\telse {\n\t\tptr->s = cpu_to_be32(xfs_daddr_to_agbno(cur->bc_mp,\n\t\t\t\t\txfs_buf_daddr(bp)));\n\t}\n}\n\nSTATIC void\nxfs_btree_set_refs(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp)\n{\n\tswitch (cur->bc_btnum) {\n\tcase XFS_BTNUM_BNO:\n\tcase XFS_BTNUM_CNT:\n\t\txfs_buf_set_ref(bp, XFS_ALLOC_BTREE_REF);\n\t\tbreak;\n\tcase XFS_BTNUM_INO:\n\tcase XFS_BTNUM_FINO:\n\t\txfs_buf_set_ref(bp, XFS_INO_BTREE_REF);\n\t\tbreak;\n\tcase XFS_BTNUM_BMAP:\n\t\txfs_buf_set_ref(bp, XFS_BMAP_BTREE_REF);\n\t\tbreak;\n\tcase XFS_BTNUM_RMAP:\n\t\txfs_buf_set_ref(bp, XFS_RMAP_BTREE_REF);\n\t\tbreak;\n\tcase XFS_BTNUM_REFC:\n\t\txfs_buf_set_ref(bp, XFS_REFC_BTREE_REF);\n\t\tbreak;\n\tdefault:\n\t\tASSERT(0);\n\t}\n}\n\nint\nxfs_btree_get_buf_block(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr,\n\tstruct xfs_btree_block\t\t**block,\n\tstruct xfs_buf\t\t\t**bpp)\n{\n\tstruct xfs_mount\t*mp = cur->bc_mp;\n\txfs_daddr_t\t\td;\n\tint\t\t\terror;\n\n\terror = xfs_btree_ptr_to_daddr(cur, ptr, &d);\n\tif (error)\n\t\treturn error;\n\terror = xfs_trans_get_buf(cur->bc_tp, mp->m_ddev_targp, d, mp->m_bsize,\n\t\t\t0, bpp);\n\tif (error)\n\t\treturn error;\n\n\t(*bpp)->b_ops = cur->bc_ops->buf_ops;\n\t*block = XFS_BUF_TO_BLOCK(*bpp);\n\treturn 0;\n}\n\n \nSTATIC int\nxfs_btree_read_buf_block(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr,\n\tint\t\t\t\tflags,\n\tstruct xfs_btree_block\t\t**block,\n\tstruct xfs_buf\t\t\t**bpp)\n{\n\tstruct xfs_mount\t*mp = cur->bc_mp;\n\txfs_daddr_t\t\td;\n\tint\t\t\terror;\n\n\t \n\tASSERT(!(flags & XBF_TRYLOCK));\n\n\terror = xfs_btree_ptr_to_daddr(cur, ptr, &d);\n\tif (error)\n\t\treturn error;\n\terror = xfs_trans_read_buf(mp, cur->bc_tp, mp->m_ddev_targp, d,\n\t\t\t\t   mp->m_bsize, flags, bpp,\n\t\t\t\t   cur->bc_ops->buf_ops);\n\tif (error)\n\t\treturn error;\n\n\txfs_btree_set_refs(cur, *bpp);\n\t*block = XFS_BUF_TO_BLOCK(*bpp);\n\treturn 0;\n}\n\n \nvoid\nxfs_btree_copy_keys(\n\tstruct xfs_btree_cur\t\t*cur,\n\tunion xfs_btree_key\t\t*dst_key,\n\tconst union xfs_btree_key\t*src_key,\n\tint\t\t\t\tnumkeys)\n{\n\tASSERT(numkeys >= 0);\n\tmemcpy(dst_key, src_key, numkeys * cur->bc_ops->key_len);\n}\n\n \nSTATIC void\nxfs_btree_copy_recs(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_rec\t*dst_rec,\n\tunion xfs_btree_rec\t*src_rec,\n\tint\t\t\tnumrecs)\n{\n\tASSERT(numrecs >= 0);\n\tmemcpy(dst_rec, src_rec, numrecs * cur->bc_ops->rec_len);\n}\n\n \nvoid\nxfs_btree_copy_ptrs(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_ptr\t*dst_ptr,\n\tconst union xfs_btree_ptr *src_ptr,\n\tint\t\t\tnumptrs)\n{\n\tASSERT(numptrs >= 0);\n\tmemcpy(dst_ptr, src_ptr, numptrs * xfs_btree_ptr_len(cur));\n}\n\n \nSTATIC void\nxfs_btree_shift_keys(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_key\t*key,\n\tint\t\t\tdir,\n\tint\t\t\tnumkeys)\n{\n\tchar\t\t\t*dst_key;\n\n\tASSERT(numkeys >= 0);\n\tASSERT(dir == 1 || dir == -1);\n\n\tdst_key = (char *)key + (dir * cur->bc_ops->key_len);\n\tmemmove(dst_key, key, numkeys * cur->bc_ops->key_len);\n}\n\n \nSTATIC void\nxfs_btree_shift_recs(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_rec\t*rec,\n\tint\t\t\tdir,\n\tint\t\t\tnumrecs)\n{\n\tchar\t\t\t*dst_rec;\n\n\tASSERT(numrecs >= 0);\n\tASSERT(dir == 1 || dir == -1);\n\n\tdst_rec = (char *)rec + (dir * cur->bc_ops->rec_len);\n\tmemmove(dst_rec, rec, numrecs * cur->bc_ops->rec_len);\n}\n\n \nSTATIC void\nxfs_btree_shift_ptrs(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_ptr\t*ptr,\n\tint\t\t\tdir,\n\tint\t\t\tnumptrs)\n{\n\tchar\t\t\t*dst_ptr;\n\n\tASSERT(numptrs >= 0);\n\tASSERT(dir == 1 || dir == -1);\n\n\tdst_ptr = (char *)ptr + (dir * xfs_btree_ptr_len(cur));\n\tmemmove(dst_ptr, ptr, numptrs * xfs_btree_ptr_len(cur));\n}\n\n \nSTATIC void\nxfs_btree_log_keys(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp,\n\tint\t\t\tfirst,\n\tint\t\t\tlast)\n{\n\n\tif (bp) {\n\t\txfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\n\t\txfs_trans_log_buf(cur->bc_tp, bp,\n\t\t\t\t  xfs_btree_key_offset(cur, first),\n\t\t\t\t  xfs_btree_key_offset(cur, last + 1) - 1);\n\t} else {\n\t\txfs_trans_log_inode(cur->bc_tp, cur->bc_ino.ip,\n\t\t\t\txfs_ilog_fbroot(cur->bc_ino.whichfork));\n\t}\n}\n\n \nvoid\nxfs_btree_log_recs(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp,\n\tint\t\t\tfirst,\n\tint\t\t\tlast)\n{\n\n\txfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\n\txfs_trans_log_buf(cur->bc_tp, bp,\n\t\t\t  xfs_btree_rec_offset(cur, first),\n\t\t\t  xfs_btree_rec_offset(cur, last + 1) - 1);\n\n}\n\n \nSTATIC void\nxfs_btree_log_ptrs(\n\tstruct xfs_btree_cur\t*cur,\t \n\tstruct xfs_buf\t\t*bp,\t \n\tint\t\t\tfirst,\t \n\tint\t\t\tlast)\t \n{\n\n\tif (bp) {\n\t\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\t\tint\t\t\tlevel = xfs_btree_get_level(block);\n\n\t\txfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\n\t\txfs_trans_log_buf(cur->bc_tp, bp,\n\t\t\t\txfs_btree_ptr_offset(cur, first, level),\n\t\t\t\txfs_btree_ptr_offset(cur, last + 1, level) - 1);\n\t} else {\n\t\txfs_trans_log_inode(cur->bc_tp, cur->bc_ino.ip,\n\t\t\txfs_ilog_fbroot(cur->bc_ino.whichfork));\n\t}\n\n}\n\n \nvoid\nxfs_btree_log_block(\n\tstruct xfs_btree_cur\t*cur,\t \n\tstruct xfs_buf\t\t*bp,\t \n\tuint32_t\t\tfields)\t \n{\n\tint\t\t\tfirst;\t \n\tint\t\t\tlast;\t \n\tstatic const short\tsoffsets[] = {\t \n\t\toffsetof(struct xfs_btree_block, bb_magic),\n\t\toffsetof(struct xfs_btree_block, bb_level),\n\t\toffsetof(struct xfs_btree_block, bb_numrecs),\n\t\toffsetof(struct xfs_btree_block, bb_u.s.bb_leftsib),\n\t\toffsetof(struct xfs_btree_block, bb_u.s.bb_rightsib),\n\t\toffsetof(struct xfs_btree_block, bb_u.s.bb_blkno),\n\t\toffsetof(struct xfs_btree_block, bb_u.s.bb_lsn),\n\t\toffsetof(struct xfs_btree_block, bb_u.s.bb_uuid),\n\t\toffsetof(struct xfs_btree_block, bb_u.s.bb_owner),\n\t\toffsetof(struct xfs_btree_block, bb_u.s.bb_crc),\n\t\tXFS_BTREE_SBLOCK_CRC_LEN\n\t};\n\tstatic const short\tloffsets[] = {\t \n\t\toffsetof(struct xfs_btree_block, bb_magic),\n\t\toffsetof(struct xfs_btree_block, bb_level),\n\t\toffsetof(struct xfs_btree_block, bb_numrecs),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_leftsib),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_rightsib),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_blkno),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_lsn),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_uuid),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_owner),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_crc),\n\t\toffsetof(struct xfs_btree_block, bb_u.l.bb_pad),\n\t\tXFS_BTREE_LBLOCK_CRC_LEN\n\t};\n\n\tif (bp) {\n\t\tint nbits;\n\n\t\tif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS) {\n\t\t\t \n\t\t\tif (fields == XFS_BB_ALL_BITS)\n\t\t\t\tfields = XFS_BB_ALL_BITS_CRC;\n\t\t\tnbits = XFS_BB_NUM_BITS_CRC;\n\t\t} else {\n\t\t\tnbits = XFS_BB_NUM_BITS;\n\t\t}\n\t\txfs_btree_offsets(fields,\n\t\t\t\t  (cur->bc_flags & XFS_BTREE_LONG_PTRS) ?\n\t\t\t\t\tloffsets : soffsets,\n\t\t\t\t  nbits, &first, &last);\n\t\txfs_trans_buf_set_type(cur->bc_tp, bp, XFS_BLFT_BTREE_BUF);\n\t\txfs_trans_log_buf(cur->bc_tp, bp, first, last);\n\t} else {\n\t\txfs_trans_log_inode(cur->bc_tp, cur->bc_ino.ip,\n\t\t\txfs_ilog_fbroot(cur->bc_ino.whichfork));\n\t}\n}\n\n \nint\t\t\t\t\t\t \nxfs_btree_increment(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tint\t\t\t*stat)\t\t \n{\n\tstruct xfs_btree_block\t*block;\n\tunion xfs_btree_ptr\tptr;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\terror;\t\t \n\tint\t\t\tlev;\n\n\tASSERT(level < cur->bc_nlevels);\n\n\t \n\txfs_btree_readahead(cur, level, XFS_BTCUR_RIGHTRA);\n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, level, bp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\t \n\tif (++cur->bc_levels[level].ptr <= xfs_btree_get_numrecs(block))\n\t\tgoto out1;\n\n\t \n\txfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\n\tif (xfs_btree_ptr_is_null(cur, &ptr))\n\t\tgoto out0;\n\n\tXFS_BTREE_STATS_INC(cur, increment);\n\n\t \n\tfor (lev = level + 1; lev < cur->bc_nlevels; lev++) {\n\t\tblock = xfs_btree_get_block(cur, lev, &bp);\n\n#ifdef DEBUG\n\t\terror = xfs_btree_check_block(cur, block, lev, bp);\n\t\tif (error)\n\t\t\tgoto error0;\n#endif\n\n\t\tif (++cur->bc_levels[lev].ptr <= xfs_btree_get_numrecs(block))\n\t\t\tbreak;\n\n\t\t \n\t\txfs_btree_readahead(cur, lev, XFS_BTCUR_RIGHTRA);\n\t}\n\n\t \n\tif (lev == cur->bc_nlevels) {\n\t\tif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE)\n\t\t\tgoto out0;\n\t\tASSERT(0);\n\t\terror = -EFSCORRUPTED;\n\t\tgoto error0;\n\t}\n\tASSERT(lev < cur->bc_nlevels);\n\n\t \n\tfor (block = xfs_btree_get_block(cur, lev, &bp); lev > level; ) {\n\t\tunion xfs_btree_ptr\t*ptrp;\n\n\t\tptrp = xfs_btree_ptr_addr(cur, cur->bc_levels[lev].ptr, block);\n\t\t--lev;\n\t\terror = xfs_btree_read_buf_block(cur, ptrp, 0, &block, &bp);\n\t\tif (error)\n\t\t\tgoto error0;\n\n\t\txfs_btree_setbuf(cur, lev, bp);\n\t\tcur->bc_levels[lev].ptr = 1;\n\t}\nout1:\n\t*stat = 1;\n\treturn 0;\n\nout0:\n\t*stat = 0;\n\treturn 0;\n\nerror0:\n\treturn error;\n}\n\n \nint\t\t\t\t\t\t \nxfs_btree_decrement(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tint\t\t\t*stat)\t\t \n{\n\tstruct xfs_btree_block\t*block;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\terror;\t\t \n\tint\t\t\tlev;\n\tunion xfs_btree_ptr\tptr;\n\n\tASSERT(level < cur->bc_nlevels);\n\n\t \n\txfs_btree_readahead(cur, level, XFS_BTCUR_LEFTRA);\n\n\t \n\tif (--cur->bc_levels[level].ptr > 0)\n\t\tgoto out1;\n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, level, bp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\t \n\txfs_btree_get_sibling(cur, block, &ptr, XFS_BB_LEFTSIB);\n\tif (xfs_btree_ptr_is_null(cur, &ptr))\n\t\tgoto out0;\n\n\tXFS_BTREE_STATS_INC(cur, decrement);\n\n\t \n\tfor (lev = level + 1; lev < cur->bc_nlevels; lev++) {\n\t\tif (--cur->bc_levels[lev].ptr > 0)\n\t\t\tbreak;\n\t\t \n\t\txfs_btree_readahead(cur, lev, XFS_BTCUR_LEFTRA);\n\t}\n\n\t \n\tif (lev == cur->bc_nlevels) {\n\t\tif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE)\n\t\t\tgoto out0;\n\t\tASSERT(0);\n\t\terror = -EFSCORRUPTED;\n\t\tgoto error0;\n\t}\n\tASSERT(lev < cur->bc_nlevels);\n\n\t \n\tfor (block = xfs_btree_get_block(cur, lev, &bp); lev > level; ) {\n\t\tunion xfs_btree_ptr\t*ptrp;\n\n\t\tptrp = xfs_btree_ptr_addr(cur, cur->bc_levels[lev].ptr, block);\n\t\t--lev;\n\t\terror = xfs_btree_read_buf_block(cur, ptrp, 0, &block, &bp);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\txfs_btree_setbuf(cur, lev, bp);\n\t\tcur->bc_levels[lev].ptr = xfs_btree_get_numrecs(block);\n\t}\nout1:\n\t*stat = 1;\n\treturn 0;\n\nout0:\n\t*stat = 0;\n\treturn 0;\n\nerror0:\n\treturn error;\n}\n\nint\nxfs_btree_lookup_get_block(\n\tstruct xfs_btree_cur\t\t*cur,\t \n\tint\t\t\t\tlevel,\t \n\tconst union xfs_btree_ptr\t*pp,\t \n\tstruct xfs_btree_block\t\t**blkp)  \n{\n\tstruct xfs_buf\t\t*bp;\t \n\txfs_daddr_t\t\tdaddr;\n\tint\t\t\terror = 0;\n\n\t \n\tif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    (level == cur->bc_nlevels - 1)) {\n\t\t*blkp = xfs_btree_get_iroot(cur);\n\t\treturn 0;\n\t}\n\n\t \n\tbp = cur->bc_levels[level].bp;\n\terror = xfs_btree_ptr_to_daddr(cur, pp, &daddr);\n\tif (error)\n\t\treturn error;\n\tif (bp && xfs_buf_daddr(bp) == daddr) {\n\t\t*blkp = XFS_BUF_TO_BLOCK(bp);\n\t\treturn 0;\n\t}\n\n\terror = xfs_btree_read_buf_block(cur, pp, 0, blkp, &bp);\n\tif (error)\n\t\treturn error;\n\n\t \n\tif (xfs_has_crc(cur->bc_mp) &&\n\t    !(cur->bc_ino.flags & XFS_BTCUR_BMBT_INVALID_OWNER) &&\n\t    (cur->bc_flags & XFS_BTREE_LONG_PTRS) &&\n\t    be64_to_cpu((*blkp)->bb_u.l.bb_owner) !=\n\t\t\tcur->bc_ino.ip->i_ino)\n\t\tgoto out_bad;\n\n\t \n\tif (be16_to_cpu((*blkp)->bb_level) != level)\n\t\tgoto out_bad;\n\n\t \n\tif (level != 0 && be16_to_cpu((*blkp)->bb_numrecs) == 0)\n\t\tgoto out_bad;\n\n\txfs_btree_setbuf(cur, level, bp);\n\treturn 0;\n\nout_bad:\n\t*blkp = NULL;\n\txfs_buf_mark_corrupt(bp);\n\txfs_trans_brelse(cur->bc_tp, bp);\n\treturn -EFSCORRUPTED;\n}\n\n \nSTATIC union xfs_btree_key *\nxfs_lookup_get_search_key(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tint\t\t\tkeyno,\n\tstruct xfs_btree_block\t*block,\n\tunion xfs_btree_key\t*kp)\n{\n\tif (level == 0) {\n\t\tcur->bc_ops->init_key_from_rec(kp,\n\t\t\t\txfs_btree_rec_addr(cur, keyno, block));\n\t\treturn kp;\n\t}\n\n\treturn xfs_btree_key_addr(cur, keyno, block);\n}\n\n \nint\t\t\t\t\t \nxfs_btree_lookup(\n\tstruct xfs_btree_cur\t*cur,\t \n\txfs_lookup_t\t\tdir,\t \n\tint\t\t\t*stat)\t \n{\n\tstruct xfs_btree_block\t*block;\t \n\tint64_t\t\t\tdiff;\t \n\tint\t\t\terror;\t \n\tint\t\t\tkeyno;\t \n\tint\t\t\tlevel;\t \n\tunion xfs_btree_ptr\t*pp;\t \n\tunion xfs_btree_ptr\tptr;\t \n\n\tXFS_BTREE_STATS_INC(cur, lookup);\n\n\t \n\tif (XFS_IS_CORRUPT(cur->bc_mp, cur->bc_nlevels == 0))\n\t\treturn -EFSCORRUPTED;\n\n\tblock = NULL;\n\tkeyno = 0;\n\n\t \n\tcur->bc_ops->init_ptr_from_cur(cur, &ptr);\n\tpp = &ptr;\n\n\t \n\tfor (level = cur->bc_nlevels - 1, diff = 1; level >= 0; level--) {\n\t\t \n\t\terror = xfs_btree_lookup_get_block(cur, level, pp, &block);\n\t\tif (error)\n\t\t\tgoto error0;\n\n\t\tif (diff == 0) {\n\t\t\t \n\t\t\tkeyno = 1;\n\t\t} else {\n\t\t\t \n\n\t\t\tint\thigh;\t \n\t\t\tint\tlow;\t \n\n\t\t\t \n\t\t\tlow = 1;\n\t\t\thigh = xfs_btree_get_numrecs(block);\n\t\t\tif (!high) {\n\t\t\t\t \n\t\t\t\tif (level != 0 || cur->bc_nlevels != 1) {\n\t\t\t\t\tXFS_CORRUPTION_ERROR(__func__,\n\t\t\t\t\t\t\tXFS_ERRLEVEL_LOW,\n\t\t\t\t\t\t\tcur->bc_mp, block,\n\t\t\t\t\t\t\tsizeof(*block));\n\t\t\t\t\treturn -EFSCORRUPTED;\n\t\t\t\t}\n\n\t\t\t\tcur->bc_levels[0].ptr = dir != XFS_LOOKUP_LE;\n\t\t\t\t*stat = 0;\n\t\t\t\treturn 0;\n\t\t\t}\n\n\t\t\t \n\t\t\twhile (low <= high) {\n\t\t\t\tunion xfs_btree_key\tkey;\n\t\t\t\tunion xfs_btree_key\t*kp;\n\n\t\t\t\tXFS_BTREE_STATS_INC(cur, compare);\n\n\t\t\t\t \n\t\t\t\tkeyno = (low + high) >> 1;\n\n\t\t\t\t \n\t\t\t\tkp = xfs_lookup_get_search_key(cur, level,\n\t\t\t\t\t\tkeyno, block, &key);\n\n\t\t\t\t \n\t\t\t\tdiff = cur->bc_ops->key_diff(cur, kp);\n\t\t\t\tif (diff < 0)\n\t\t\t\t\tlow = keyno + 1;\n\t\t\t\telse if (diff > 0)\n\t\t\t\t\thigh = keyno - 1;\n\t\t\t\telse\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (level > 0) {\n\t\t\t \n\t\t\tif (diff > 0 && --keyno < 1)\n\t\t\t\tkeyno = 1;\n\t\t\tpp = xfs_btree_ptr_addr(cur, keyno, block);\n\n\t\t\terror = xfs_btree_debug_check_ptr(cur, pp, 0, level);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\n\t\t\tcur->bc_levels[level].ptr = keyno;\n\t\t}\n\t}\n\n\t \n\tif (dir != XFS_LOOKUP_LE && diff < 0) {\n\t\tkeyno++;\n\t\t \n\t\txfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\n\t\tif (dir == XFS_LOOKUP_GE &&\n\t\t    keyno > xfs_btree_get_numrecs(block) &&\n\t\t    !xfs_btree_ptr_is_null(cur, &ptr)) {\n\t\t\tint\ti;\n\n\t\t\tcur->bc_levels[0].ptr = keyno;\n\t\t\terror = xfs_btree_increment(cur, 0, &i);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1))\n\t\t\t\treturn -EFSCORRUPTED;\n\t\t\t*stat = 1;\n\t\t\treturn 0;\n\t\t}\n\t} else if (dir == XFS_LOOKUP_LE && diff > 0)\n\t\tkeyno--;\n\tcur->bc_levels[0].ptr = keyno;\n\n\t \n\tif (keyno == 0 || keyno > xfs_btree_get_numrecs(block))\n\t\t*stat = 0;\n\telse if (dir != XFS_LOOKUP_EQ || diff == 0)\n\t\t*stat = 1;\n\telse\n\t\t*stat = 0;\n\treturn 0;\n\nerror0:\n\treturn error;\n}\n\n \nunion xfs_btree_key *\nxfs_btree_high_key_from_key(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_key\t*key)\n{\n\tASSERT(cur->bc_flags & XFS_BTREE_OVERLAPPING);\n\treturn (union xfs_btree_key *)((char *)key +\n\t\t\t(cur->bc_ops->key_len / 2));\n}\n\n \nSTATIC void\nxfs_btree_get_leaf_keys(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tunion xfs_btree_key\t*key)\n{\n\tunion xfs_btree_key\tmax_hkey;\n\tunion xfs_btree_key\thkey;\n\tunion xfs_btree_rec\t*rec;\n\tunion xfs_btree_key\t*high;\n\tint\t\t\tn;\n\n\trec = xfs_btree_rec_addr(cur, 1, block);\n\tcur->bc_ops->init_key_from_rec(key, rec);\n\n\tif (cur->bc_flags & XFS_BTREE_OVERLAPPING) {\n\n\t\tcur->bc_ops->init_high_key_from_rec(&max_hkey, rec);\n\t\tfor (n = 2; n <= xfs_btree_get_numrecs(block); n++) {\n\t\t\trec = xfs_btree_rec_addr(cur, n, block);\n\t\t\tcur->bc_ops->init_high_key_from_rec(&hkey, rec);\n\t\t\tif (xfs_btree_keycmp_gt(cur, &hkey, &max_hkey))\n\t\t\t\tmax_hkey = hkey;\n\t\t}\n\n\t\thigh = xfs_btree_high_key_from_key(cur, key);\n\t\tmemcpy(high, &max_hkey, cur->bc_ops->key_len / 2);\n\t}\n}\n\n \nSTATIC void\nxfs_btree_get_node_keys(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tunion xfs_btree_key\t*key)\n{\n\tunion xfs_btree_key\t*hkey;\n\tunion xfs_btree_key\t*max_hkey;\n\tunion xfs_btree_key\t*high;\n\tint\t\t\tn;\n\n\tif (cur->bc_flags & XFS_BTREE_OVERLAPPING) {\n\t\tmemcpy(key, xfs_btree_key_addr(cur, 1, block),\n\t\t\t\tcur->bc_ops->key_len / 2);\n\n\t\tmax_hkey = xfs_btree_high_key_addr(cur, 1, block);\n\t\tfor (n = 2; n <= xfs_btree_get_numrecs(block); n++) {\n\t\t\thkey = xfs_btree_high_key_addr(cur, n, block);\n\t\t\tif (xfs_btree_keycmp_gt(cur, hkey, max_hkey))\n\t\t\t\tmax_hkey = hkey;\n\t\t}\n\n\t\thigh = xfs_btree_high_key_from_key(cur, key);\n\t\tmemcpy(high, max_hkey, cur->bc_ops->key_len / 2);\n\t} else {\n\t\tmemcpy(key, xfs_btree_key_addr(cur, 1, block),\n\t\t\t\tcur->bc_ops->key_len);\n\t}\n}\n\n \nvoid\nxfs_btree_get_keys(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_block\t*block,\n\tunion xfs_btree_key\t*key)\n{\n\tif (be16_to_cpu(block->bb_level) == 0)\n\t\txfs_btree_get_leaf_keys(cur, block, key);\n\telse\n\t\txfs_btree_get_node_keys(cur, block, key);\n}\n\n \nstatic inline bool\nxfs_btree_needs_key_update(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tptr)\n{\n\treturn (cur->bc_flags & XFS_BTREE_OVERLAPPING) || ptr == 1;\n}\n\n \nSTATIC int\n__xfs_btree_updkeys(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tstruct xfs_btree_block\t*block,\n\tstruct xfs_buf\t\t*bp0,\n\tbool\t\t\tforce_all)\n{\n\tunion xfs_btree_key\tkey;\t \n\tunion xfs_btree_key\t*lkey;\t \n\tunion xfs_btree_key\t*hkey;\n\tunion xfs_btree_key\t*nlkey;\t \n\tunion xfs_btree_key\t*nhkey;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\tptr;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_OVERLAPPING);\n\n\t \n\tif (level + 1 >= cur->bc_nlevels)\n\t\treturn 0;\n\n\ttrace_xfs_btree_updkeys(cur, level, bp0);\n\n\tlkey = &key;\n\thkey = xfs_btree_high_key_from_key(cur, lkey);\n\txfs_btree_get_keys(cur, block, lkey);\n\tfor (level++; level < cur->bc_nlevels; level++) {\n#ifdef DEBUG\n\t\tint\t\terror;\n#endif\n\t\tblock = xfs_btree_get_block(cur, level, &bp);\n\t\ttrace_xfs_btree_updkeys(cur, level, bp);\n#ifdef DEBUG\n\t\terror = xfs_btree_check_block(cur, block, level, bp);\n\t\tif (error)\n\t\t\treturn error;\n#endif\n\t\tptr = cur->bc_levels[level].ptr;\n\t\tnlkey = xfs_btree_key_addr(cur, ptr, block);\n\t\tnhkey = xfs_btree_high_key_addr(cur, ptr, block);\n\t\tif (!force_all &&\n\t\t    xfs_btree_keycmp_eq(cur, nlkey, lkey) &&\n\t\t    xfs_btree_keycmp_eq(cur, nhkey, hkey))\n\t\t\tbreak;\n\t\txfs_btree_copy_keys(cur, nlkey, lkey, 1);\n\t\txfs_btree_log_keys(cur, bp, ptr, ptr);\n\t\tif (level + 1 >= cur->bc_nlevels)\n\t\t\tbreak;\n\t\txfs_btree_get_node_keys(cur, block, lkey);\n\t}\n\n\treturn 0;\n}\n\n \nSTATIC int\nxfs_btree_updkeys_force(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel)\n{\n\tstruct xfs_buf\t\t*bp;\n\tstruct xfs_btree_block\t*block;\n\n\tblock = xfs_btree_get_block(cur, level, &bp);\n\treturn __xfs_btree_updkeys(cur, level, block, bp, true);\n}\n\n \nSTATIC int\nxfs_btree_update_keys(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel)\n{\n\tstruct xfs_btree_block\t*block;\n\tstruct xfs_buf\t\t*bp;\n\tunion xfs_btree_key\t*kp;\n\tunion xfs_btree_key\tkey;\n\tint\t\t\tptr;\n\n\tASSERT(level >= 0);\n\n\tblock = xfs_btree_get_block(cur, level, &bp);\n\tif (cur->bc_flags & XFS_BTREE_OVERLAPPING)\n\t\treturn __xfs_btree_updkeys(cur, level, block, bp, false);\n\n\t \n\txfs_btree_get_keys(cur, block, &key);\n\tfor (level++, ptr = 1; ptr == 1 && level < cur->bc_nlevels; level++) {\n#ifdef DEBUG\n\t\tint\t\terror;\n#endif\n\t\tblock = xfs_btree_get_block(cur, level, &bp);\n#ifdef DEBUG\n\t\terror = xfs_btree_check_block(cur, block, level, bp);\n\t\tif (error)\n\t\t\treturn error;\n#endif\n\t\tptr = cur->bc_levels[level].ptr;\n\t\tkp = xfs_btree_key_addr(cur, ptr, block);\n\t\txfs_btree_copy_keys(cur, kp, &key, 1);\n\t\txfs_btree_log_keys(cur, bp, ptr, ptr);\n\t}\n\n\treturn 0;\n}\n\n \nint\nxfs_btree_update(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_rec\t*rec)\n{\n\tstruct xfs_btree_block\t*block;\n\tstruct xfs_buf\t\t*bp;\n\tint\t\t\terror;\n\tint\t\t\tptr;\n\tunion xfs_btree_rec\t*rp;\n\n\t \n\tblock = xfs_btree_get_block(cur, 0, &bp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, 0, bp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\t \n\tptr = cur->bc_levels[0].ptr;\n\trp = xfs_btree_rec_addr(cur, ptr, block);\n\n\t \n\txfs_btree_copy_recs(cur, rp, rec, 1);\n\txfs_btree_log_recs(cur, bp, ptr, ptr);\n\n\t \n\tif (xfs_btree_is_lastrec(cur, block, 0)) {\n\t\tcur->bc_ops->update_lastrec(cur, block, rec,\n\t\t\t\t\t    ptr, LASTREC_UPDATE);\n\t}\n\n\t \n\tif (xfs_btree_needs_key_update(cur, ptr)) {\n\t\terror = xfs_btree_update_keys(cur, 0);\n\t\tif (error)\n\t\t\tgoto error0;\n\t}\n\n\treturn 0;\n\nerror0:\n\treturn error;\n}\n\n \nSTATIC int\t\t\t\t\t \nxfs_btree_lshift(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tint\t\t\t*stat)\t\t \n{\n\tstruct xfs_buf\t\t*lbp;\t\t \n\tstruct xfs_btree_block\t*left;\t\t \n\tint\t\t\tlrecs;\t\t \n\tstruct xfs_buf\t\t*rbp;\t\t \n\tstruct xfs_btree_block\t*right;\t\t \n\tstruct xfs_btree_cur\t*tcur;\t\t \n\tint\t\t\trrecs;\t\t \n\tunion xfs_btree_ptr\tlptr;\t\t \n\tunion xfs_btree_key\t*rkp = NULL;\t \n\tunion xfs_btree_ptr\t*rpp = NULL;\t \n\tunion xfs_btree_rec\t*rrp = NULL;\t \n\tint\t\t\terror;\t\t \n\tint\t\t\ti;\n\n\tif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    level == cur->bc_nlevels - 1)\n\t\tgoto out0;\n\n\t \n\tright = xfs_btree_get_block(cur, level, &rbp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, right, level, rbp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\t \n\txfs_btree_get_sibling(cur, right, &lptr, XFS_BB_LEFTSIB);\n\tif (xfs_btree_ptr_is_null(cur, &lptr))\n\t\tgoto out0;\n\n\t \n\tif (cur->bc_levels[level].ptr <= 1)\n\t\tgoto out0;\n\n\t \n\terror = xfs_btree_read_buf_block(cur, &lptr, 0, &left, &lbp);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\tlrecs = xfs_btree_get_numrecs(left);\n\tif (lrecs == cur->bc_ops->get_maxrecs(cur, level))\n\t\tgoto out0;\n\n\trrecs = xfs_btree_get_numrecs(right);\n\n\t \n\tlrecs++;\n\trrecs--;\n\n\tXFS_BTREE_STATS_INC(cur, lshift);\n\tXFS_BTREE_STATS_ADD(cur, moves, 1);\n\n\t \n\tif (level > 0) {\n\t\t \n\t\tunion xfs_btree_key\t*lkp;\t \n\t\tunion xfs_btree_ptr\t*lpp;\t \n\n\t\tlkp = xfs_btree_key_addr(cur, lrecs, left);\n\t\trkp = xfs_btree_key_addr(cur, 1, right);\n\n\t\tlpp = xfs_btree_ptr_addr(cur, lrecs, left);\n\t\trpp = xfs_btree_ptr_addr(cur, 1, right);\n\n\t\terror = xfs_btree_debug_check_ptr(cur, rpp, 0, level);\n\t\tif (error)\n\t\t\tgoto error0;\n\n\t\txfs_btree_copy_keys(cur, lkp, rkp, 1);\n\t\txfs_btree_copy_ptrs(cur, lpp, rpp, 1);\n\n\t\txfs_btree_log_keys(cur, lbp, lrecs, lrecs);\n\t\txfs_btree_log_ptrs(cur, lbp, lrecs, lrecs);\n\n\t\tASSERT(cur->bc_ops->keys_inorder(cur,\n\t\t\txfs_btree_key_addr(cur, lrecs - 1, left), lkp));\n\t} else {\n\t\t \n\t\tunion xfs_btree_rec\t*lrp;\t \n\n\t\tlrp = xfs_btree_rec_addr(cur, lrecs, left);\n\t\trrp = xfs_btree_rec_addr(cur, 1, right);\n\n\t\txfs_btree_copy_recs(cur, lrp, rrp, 1);\n\t\txfs_btree_log_recs(cur, lbp, lrecs, lrecs);\n\n\t\tASSERT(cur->bc_ops->recs_inorder(cur,\n\t\t\txfs_btree_rec_addr(cur, lrecs - 1, left), lrp));\n\t}\n\n\txfs_btree_set_numrecs(left, lrecs);\n\txfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS);\n\n\txfs_btree_set_numrecs(right, rrecs);\n\txfs_btree_log_block(cur, rbp, XFS_BB_NUMRECS);\n\n\t \n\tXFS_BTREE_STATS_ADD(cur, moves, rrecs - 1);\n\tif (level > 0) {\n\t\t \n\t\tfor (i = 0; i < rrecs; i++) {\n\t\t\terror = xfs_btree_debug_check_ptr(cur, rpp, i + 1, level);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t}\n\n\t\txfs_btree_shift_keys(cur,\n\t\t\t\txfs_btree_key_addr(cur, 2, right),\n\t\t\t\t-1, rrecs);\n\t\txfs_btree_shift_ptrs(cur,\n\t\t\t\txfs_btree_ptr_addr(cur, 2, right),\n\t\t\t\t-1, rrecs);\n\n\t\txfs_btree_log_keys(cur, rbp, 1, rrecs);\n\t\txfs_btree_log_ptrs(cur, rbp, 1, rrecs);\n\t} else {\n\t\t \n\t\txfs_btree_shift_recs(cur,\n\t\t\txfs_btree_rec_addr(cur, 2, right),\n\t\t\t-1, rrecs);\n\t\txfs_btree_log_recs(cur, rbp, 1, rrecs);\n\t}\n\n\t \n\tif (cur->bc_flags & XFS_BTREE_OVERLAPPING) {\n\t\terror = xfs_btree_dup_cursor(cur, &tcur);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\ti = xfs_btree_firstrec(tcur, level);\n\t\tif (XFS_IS_CORRUPT(tcur->bc_mp, i != 1)) {\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto error0;\n\t\t}\n\n\t\terror = xfs_btree_decrement(tcur, level, &i);\n\t\tif (error)\n\t\t\tgoto error1;\n\n\t\t \n\t\terror = xfs_btree_update_keys(tcur, level);\n\t\tif (error)\n\t\t\tgoto error1;\n\n\t\txfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\n\t}\n\n\t \n\terror = xfs_btree_update_keys(cur, level);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\tcur->bc_levels[level].ptr--;\n\n\t*stat = 1;\n\treturn 0;\n\nout0:\n\t*stat = 0;\n\treturn 0;\n\nerror0:\n\treturn error;\n\nerror1:\n\txfs_btree_del_cursor(tcur, XFS_BTREE_ERROR);\n\treturn error;\n}\n\n \nSTATIC int\t\t\t\t\t \nxfs_btree_rshift(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tint\t\t\t*stat)\t\t \n{\n\tstruct xfs_buf\t\t*lbp;\t\t \n\tstruct xfs_btree_block\t*left;\t\t \n\tstruct xfs_buf\t\t*rbp;\t\t \n\tstruct xfs_btree_block\t*right;\t\t \n\tstruct xfs_btree_cur\t*tcur;\t\t \n\tunion xfs_btree_ptr\trptr;\t\t \n\tunion xfs_btree_key\t*rkp;\t\t \n\tint\t\t\trrecs;\t\t \n\tint\t\t\tlrecs;\t\t \n\tint\t\t\terror;\t\t \n\tint\t\t\ti;\t\t \n\n\tif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    (level == cur->bc_nlevels - 1))\n\t\tgoto out0;\n\n\t \n\tleft = xfs_btree_get_block(cur, level, &lbp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, left, level, lbp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\t \n\txfs_btree_get_sibling(cur, left, &rptr, XFS_BB_RIGHTSIB);\n\tif (xfs_btree_ptr_is_null(cur, &rptr))\n\t\tgoto out0;\n\n\t \n\tlrecs = xfs_btree_get_numrecs(left);\n\tif (cur->bc_levels[level].ptr >= lrecs)\n\t\tgoto out0;\n\n\t \n\terror = xfs_btree_read_buf_block(cur, &rptr, 0, &right, &rbp);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\trrecs = xfs_btree_get_numrecs(right);\n\tif (rrecs == cur->bc_ops->get_maxrecs(cur, level))\n\t\tgoto out0;\n\n\tXFS_BTREE_STATS_INC(cur, rshift);\n\tXFS_BTREE_STATS_ADD(cur, moves, rrecs);\n\n\t \n\tif (level > 0) {\n\t\t \n\t\tunion xfs_btree_key\t*lkp;\n\t\tunion xfs_btree_ptr\t*lpp;\n\t\tunion xfs_btree_ptr\t*rpp;\n\n\t\tlkp = xfs_btree_key_addr(cur, lrecs, left);\n\t\tlpp = xfs_btree_ptr_addr(cur, lrecs, left);\n\t\trkp = xfs_btree_key_addr(cur, 1, right);\n\t\trpp = xfs_btree_ptr_addr(cur, 1, right);\n\n\t\tfor (i = rrecs - 1; i >= 0; i--) {\n\t\t\terror = xfs_btree_debug_check_ptr(cur, rpp, i, level);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t}\n\n\t\txfs_btree_shift_keys(cur, rkp, 1, rrecs);\n\t\txfs_btree_shift_ptrs(cur, rpp, 1, rrecs);\n\n\t\terror = xfs_btree_debug_check_ptr(cur, lpp, 0, level);\n\t\tif (error)\n\t\t\tgoto error0;\n\n\t\t \n\t\txfs_btree_copy_keys(cur, rkp, lkp, 1);\n\t\txfs_btree_copy_ptrs(cur, rpp, lpp, 1);\n\n\t\txfs_btree_log_keys(cur, rbp, 1, rrecs + 1);\n\t\txfs_btree_log_ptrs(cur, rbp, 1, rrecs + 1);\n\n\t\tASSERT(cur->bc_ops->keys_inorder(cur, rkp,\n\t\t\txfs_btree_key_addr(cur, 2, right)));\n\t} else {\n\t\t \n\t\tunion xfs_btree_rec\t*lrp;\n\t\tunion xfs_btree_rec\t*rrp;\n\n\t\tlrp = xfs_btree_rec_addr(cur, lrecs, left);\n\t\trrp = xfs_btree_rec_addr(cur, 1, right);\n\n\t\txfs_btree_shift_recs(cur, rrp, 1, rrecs);\n\n\t\t \n\t\txfs_btree_copy_recs(cur, rrp, lrp, 1);\n\t\txfs_btree_log_recs(cur, rbp, 1, rrecs + 1);\n\t}\n\n\t \n\txfs_btree_set_numrecs(left, --lrecs);\n\txfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS);\n\n\txfs_btree_set_numrecs(right, ++rrecs);\n\txfs_btree_log_block(cur, rbp, XFS_BB_NUMRECS);\n\n\t \n\terror = xfs_btree_dup_cursor(cur, &tcur);\n\tif (error)\n\t\tgoto error0;\n\ti = xfs_btree_lastrec(tcur, level);\n\tif (XFS_IS_CORRUPT(tcur->bc_mp, i != 1)) {\n\t\terror = -EFSCORRUPTED;\n\t\tgoto error0;\n\t}\n\n\terror = xfs_btree_increment(tcur, level, &i);\n\tif (error)\n\t\tgoto error1;\n\n\t \n\tif (cur->bc_flags & XFS_BTREE_OVERLAPPING) {\n\t\terror = xfs_btree_update_keys(cur, level);\n\t\tif (error)\n\t\t\tgoto error1;\n\t}\n\n\t \n\terror = xfs_btree_update_keys(tcur, level);\n\tif (error)\n\t\tgoto error1;\n\n\txfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\n\n\t*stat = 1;\n\treturn 0;\n\nout0:\n\t*stat = 0;\n\treturn 0;\n\nerror0:\n\treturn error;\n\nerror1:\n\txfs_btree_del_cursor(tcur, XFS_BTREE_ERROR);\n\treturn error;\n}\n\n \nSTATIC int\t\t\t\t\t \n__xfs_btree_split(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tunion xfs_btree_ptr\t*ptrp,\n\tunion xfs_btree_key\t*key,\n\tstruct xfs_btree_cur\t**curp,\n\tint\t\t\t*stat)\t\t \n{\n\tunion xfs_btree_ptr\tlptr;\t\t \n\tstruct xfs_buf\t\t*lbp;\t\t \n\tstruct xfs_btree_block\t*left;\t\t \n\tunion xfs_btree_ptr\trptr;\t\t \n\tstruct xfs_buf\t\t*rbp;\t\t \n\tstruct xfs_btree_block\t*right;\t\t \n\tunion xfs_btree_ptr\trrptr;\t\t \n\tstruct xfs_buf\t\t*rrbp;\t\t \n\tstruct xfs_btree_block\t*rrblock;\t \n\tint\t\t\tlrecs;\n\tint\t\t\trrecs;\n\tint\t\t\tsrc_index;\n\tint\t\t\terror;\t\t \n\tint\t\t\ti;\n\n\tXFS_BTREE_STATS_INC(cur, split);\n\n\t \n\tleft = xfs_btree_get_block(cur, level, &lbp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, left, level, lbp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\txfs_btree_buf_to_ptr(cur, lbp, &lptr);\n\n\t \n\terror = cur->bc_ops->alloc_block(cur, &lptr, &rptr, stat);\n\tif (error)\n\t\tgoto error0;\n\tif (*stat == 0)\n\t\tgoto out0;\n\tXFS_BTREE_STATS_INC(cur, alloc);\n\n\t \n\terror = xfs_btree_get_buf_block(cur, &rptr, &right, &rbp);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\txfs_btree_init_block_cur(cur, rbp, xfs_btree_get_level(left), 0);\n\n\t \n\tlrecs = xfs_btree_get_numrecs(left);\n\trrecs = lrecs / 2;\n\tif ((lrecs & 1) && cur->bc_levels[level].ptr <= rrecs + 1)\n\t\trrecs++;\n\tsrc_index = (lrecs - rrecs + 1);\n\n\tXFS_BTREE_STATS_ADD(cur, moves, rrecs);\n\n\t \n\tlrecs -= rrecs;\n\txfs_btree_set_numrecs(left, lrecs);\n\txfs_btree_set_numrecs(right, xfs_btree_get_numrecs(right) + rrecs);\n\n\t \n\tif (level > 0) {\n\t\t \n\t\tunion xfs_btree_key\t*lkp;\t \n\t\tunion xfs_btree_ptr\t*lpp;\t \n\t\tunion xfs_btree_key\t*rkp;\t \n\t\tunion xfs_btree_ptr\t*rpp;\t \n\n\t\tlkp = xfs_btree_key_addr(cur, src_index, left);\n\t\tlpp = xfs_btree_ptr_addr(cur, src_index, left);\n\t\trkp = xfs_btree_key_addr(cur, 1, right);\n\t\trpp = xfs_btree_ptr_addr(cur, 1, right);\n\n\t\tfor (i = src_index; i < rrecs; i++) {\n\t\t\terror = xfs_btree_debug_check_ptr(cur, lpp, i, level);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t}\n\n\t\t \n\t\txfs_btree_copy_keys(cur, rkp, lkp, rrecs);\n\t\txfs_btree_copy_ptrs(cur, rpp, lpp, rrecs);\n\n\t\txfs_btree_log_keys(cur, rbp, 1, rrecs);\n\t\txfs_btree_log_ptrs(cur, rbp, 1, rrecs);\n\n\t\t \n\t\txfs_btree_get_node_keys(cur, right, key);\n\t} else {\n\t\t \n\t\tunion xfs_btree_rec\t*lrp;\t \n\t\tunion xfs_btree_rec\t*rrp;\t \n\n\t\tlrp = xfs_btree_rec_addr(cur, src_index, left);\n\t\trrp = xfs_btree_rec_addr(cur, 1, right);\n\n\t\t \n\t\txfs_btree_copy_recs(cur, rrp, lrp, rrecs);\n\t\txfs_btree_log_recs(cur, rbp, 1, rrecs);\n\n\t\t \n\t\txfs_btree_get_leaf_keys(cur, right, key);\n\t}\n\n\t \n\txfs_btree_get_sibling(cur, left, &rrptr, XFS_BB_RIGHTSIB);\n\txfs_btree_set_sibling(cur, right, &rrptr, XFS_BB_RIGHTSIB);\n\txfs_btree_set_sibling(cur, right, &lptr, XFS_BB_LEFTSIB);\n\txfs_btree_set_sibling(cur, left, &rptr, XFS_BB_RIGHTSIB);\n\n\txfs_btree_log_block(cur, rbp, XFS_BB_ALL_BITS);\n\txfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS | XFS_BB_RIGHTSIB);\n\n\t \n\tif (!xfs_btree_ptr_is_null(cur, &rrptr)) {\n\t\terror = xfs_btree_read_buf_block(cur, &rrptr,\n\t\t\t\t\t\t\t0, &rrblock, &rrbp);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\txfs_btree_set_sibling(cur, rrblock, &rptr, XFS_BB_LEFTSIB);\n\t\txfs_btree_log_block(cur, rrbp, XFS_BB_LEFTSIB);\n\t}\n\n\t \n\tif (cur->bc_flags & XFS_BTREE_OVERLAPPING) {\n\t\terror = xfs_btree_update_keys(cur, level);\n\t\tif (error)\n\t\t\tgoto error0;\n\t}\n\n\t \n\tif (cur->bc_levels[level].ptr > lrecs + 1) {\n\t\txfs_btree_setbuf(cur, level, rbp);\n\t\tcur->bc_levels[level].ptr -= lrecs;\n\t}\n\t \n\tif (level + 1 < cur->bc_nlevels) {\n\t\terror = xfs_btree_dup_cursor(cur, curp);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\t(*curp)->bc_levels[level + 1].ptr++;\n\t}\n\t*ptrp = rptr;\n\t*stat = 1;\n\treturn 0;\nout0:\n\t*stat = 0;\n\treturn 0;\n\nerror0:\n\treturn error;\n}\n\n#ifdef __KERNEL__\nstruct xfs_btree_split_args {\n\tstruct xfs_btree_cur\t*cur;\n\tint\t\t\tlevel;\n\tunion xfs_btree_ptr\t*ptrp;\n\tunion xfs_btree_key\t*key;\n\tstruct xfs_btree_cur\t**curp;\n\tint\t\t\t*stat;\t\t \n\tint\t\t\tresult;\n\tbool\t\t\tkswapd;\t \n\tstruct completion\t*done;\n\tstruct work_struct\twork;\n};\n\n \nstatic void\nxfs_btree_split_worker(\n\tstruct work_struct\t*work)\n{\n\tstruct xfs_btree_split_args\t*args = container_of(work,\n\t\t\t\t\t\tstruct xfs_btree_split_args, work);\n\tunsigned long\t\tpflags;\n\tunsigned long\t\tnew_pflags = 0;\n\n\t \n\tif (args->kswapd)\n\t\tnew_pflags |= PF_MEMALLOC | PF_KSWAPD;\n\n\tcurrent_set_flags_nested(&pflags, new_pflags);\n\txfs_trans_set_context(args->cur->bc_tp);\n\n\targs->result = __xfs_btree_split(args->cur, args->level, args->ptrp,\n\t\t\t\t\t args->key, args->curp, args->stat);\n\n\txfs_trans_clear_context(args->cur->bc_tp);\n\tcurrent_restore_flags_nested(&pflags, new_pflags);\n\n\t \n\tcomplete(args->done);\n\n}\n\n \nSTATIC int\t\t\t\t\t \nxfs_btree_split(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tunion xfs_btree_ptr\t*ptrp,\n\tunion xfs_btree_key\t*key,\n\tstruct xfs_btree_cur\t**curp,\n\tint\t\t\t*stat)\t\t \n{\n\tstruct xfs_btree_split_args\targs;\n\tDECLARE_COMPLETION_ONSTACK(done);\n\n\tif (cur->bc_btnum != XFS_BTNUM_BMAP ||\n\t    cur->bc_tp->t_highest_agno == NULLAGNUMBER)\n\t\treturn __xfs_btree_split(cur, level, ptrp, key, curp, stat);\n\n\targs.cur = cur;\n\targs.level = level;\n\targs.ptrp = ptrp;\n\targs.key = key;\n\targs.curp = curp;\n\targs.stat = stat;\n\targs.done = &done;\n\targs.kswapd = current_is_kswapd();\n\tINIT_WORK_ONSTACK(&args.work, xfs_btree_split_worker);\n\tqueue_work(xfs_alloc_wq, &args.work);\n\twait_for_completion(&done);\n\tdestroy_work_on_stack(&args.work);\n\treturn args.result;\n}\n#else\n#define xfs_btree_split\t__xfs_btree_split\n#endif  \n\n\n \nint\t\t\t\t\t\t \nxfs_btree_new_iroot(\n\tstruct xfs_btree_cur\t*cur,\t\t \n\tint\t\t\t*logflags,\t \n\tint\t\t\t*stat)\t\t \n{\n\tstruct xfs_buf\t\t*cbp;\t\t \n\tstruct xfs_btree_block\t*block;\t\t \n\tstruct xfs_btree_block\t*cblock;\t \n\tunion xfs_btree_key\t*ckp;\t\t \n\tunion xfs_btree_ptr\t*cpp;\t\t \n\tunion xfs_btree_key\t*kp;\t\t \n\tunion xfs_btree_ptr\t*pp;\t\t \n\tunion xfs_btree_ptr\tnptr;\t\t \n\tint\t\t\tlevel;\t\t \n\tint\t\t\terror;\t\t \n\tint\t\t\ti;\t\t \n\n\tXFS_BTREE_STATS_INC(cur, newroot);\n\n\tASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\n\n\tlevel = cur->bc_nlevels - 1;\n\n\tblock = xfs_btree_get_iroot(cur);\n\tpp = xfs_btree_ptr_addr(cur, 1, block);\n\n\t \n\terror = cur->bc_ops->alloc_block(cur, pp, &nptr, stat);\n\tif (error)\n\t\tgoto error0;\n\tif (*stat == 0)\n\t\treturn 0;\n\n\tXFS_BTREE_STATS_INC(cur, alloc);\n\n\t \n\terror = xfs_btree_get_buf_block(cur, &nptr, &cblock, &cbp);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\tmemcpy(cblock, block, xfs_btree_block_len(cur));\n\tif (cur->bc_flags & XFS_BTREE_CRC_BLOCKS) {\n\t\t__be64 bno = cpu_to_be64(xfs_buf_daddr(cbp));\n\t\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\t\tcblock->bb_u.l.bb_blkno = bno;\n\t\telse\n\t\t\tcblock->bb_u.s.bb_blkno = bno;\n\t}\n\n\tbe16_add_cpu(&block->bb_level, 1);\n\txfs_btree_set_numrecs(block, 1);\n\tcur->bc_nlevels++;\n\tASSERT(cur->bc_nlevels <= cur->bc_maxlevels);\n\tcur->bc_levels[level + 1].ptr = 1;\n\n\tkp = xfs_btree_key_addr(cur, 1, block);\n\tckp = xfs_btree_key_addr(cur, 1, cblock);\n\txfs_btree_copy_keys(cur, ckp, kp, xfs_btree_get_numrecs(cblock));\n\n\tcpp = xfs_btree_ptr_addr(cur, 1, cblock);\n\tfor (i = 0; i < be16_to_cpu(cblock->bb_numrecs); i++) {\n\t\terror = xfs_btree_debug_check_ptr(cur, pp, i, level);\n\t\tif (error)\n\t\t\tgoto error0;\n\t}\n\n\txfs_btree_copy_ptrs(cur, cpp, pp, xfs_btree_get_numrecs(cblock));\n\n\terror = xfs_btree_debug_check_ptr(cur, &nptr, 0, level);\n\tif (error)\n\t\tgoto error0;\n\n\txfs_btree_copy_ptrs(cur, pp, &nptr, 1);\n\n\txfs_iroot_realloc(cur->bc_ino.ip,\n\t\t\t  1 - xfs_btree_get_numrecs(cblock),\n\t\t\t  cur->bc_ino.whichfork);\n\n\txfs_btree_setbuf(cur, level, cbp);\n\n\t \n\txfs_btree_log_block(cur, cbp, XFS_BB_ALL_BITS);\n\txfs_btree_log_keys(cur, cbp, 1, be16_to_cpu(cblock->bb_numrecs));\n\txfs_btree_log_ptrs(cur, cbp, 1, be16_to_cpu(cblock->bb_numrecs));\n\n\t*logflags |=\n\t\tXFS_ILOG_CORE | xfs_ilog_fbroot(cur->bc_ino.whichfork);\n\t*stat = 1;\n\treturn 0;\nerror0:\n\treturn error;\n}\n\n \nSTATIC int\t\t\t\t \nxfs_btree_new_root(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\t*stat)\t \n{\n\tstruct xfs_btree_block\t*block;\t \n\tstruct xfs_buf\t\t*bp;\t \n\tint\t\t\terror;\t \n\tstruct xfs_buf\t\t*lbp;\t \n\tstruct xfs_btree_block\t*left;\t \n\tstruct xfs_buf\t\t*nbp;\t \n\tstruct xfs_btree_block\t*new;\t \n\tint\t\t\tnptr;\t \n\tstruct xfs_buf\t\t*rbp;\t \n\tstruct xfs_btree_block\t*right;\t \n\tunion xfs_btree_ptr\trptr;\n\tunion xfs_btree_ptr\tlptr;\n\n\tXFS_BTREE_STATS_INC(cur, newroot);\n\n\t \n\tcur->bc_ops->init_ptr_from_cur(cur, &rptr);\n\n\t \n\terror = cur->bc_ops->alloc_block(cur, &rptr, &lptr, stat);\n\tif (error)\n\t\tgoto error0;\n\tif (*stat == 0)\n\t\tgoto out0;\n\tXFS_BTREE_STATS_INC(cur, alloc);\n\n\t \n\terror = xfs_btree_get_buf_block(cur, &lptr, &new, &nbp);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\tcur->bc_ops->set_root(cur, &lptr, 1);\n\n\t \n\tblock = xfs_btree_get_block(cur, cur->bc_nlevels - 1, &bp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, cur->bc_nlevels - 1, bp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\txfs_btree_get_sibling(cur, block, &rptr, XFS_BB_RIGHTSIB);\n\tif (!xfs_btree_ptr_is_null(cur, &rptr)) {\n\t\t \n\t\tlbp = bp;\n\t\txfs_btree_buf_to_ptr(cur, lbp, &lptr);\n\t\tleft = block;\n\t\terror = xfs_btree_read_buf_block(cur, &rptr, 0, &right, &rbp);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\tbp = rbp;\n\t\tnptr = 1;\n\t} else {\n\t\t \n\t\trbp = bp;\n\t\txfs_btree_buf_to_ptr(cur, rbp, &rptr);\n\t\tright = block;\n\t\txfs_btree_get_sibling(cur, right, &lptr, XFS_BB_LEFTSIB);\n\t\terror = xfs_btree_read_buf_block(cur, &lptr, 0, &left, &lbp);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\tbp = lbp;\n\t\tnptr = 2;\n\t}\n\n\t \n\txfs_btree_init_block_cur(cur, nbp, cur->bc_nlevels, 2);\n\txfs_btree_log_block(cur, nbp, XFS_BB_ALL_BITS);\n\tASSERT(!xfs_btree_ptr_is_null(cur, &lptr) &&\n\t\t\t!xfs_btree_ptr_is_null(cur, &rptr));\n\n\t \n\tif (xfs_btree_get_level(left) > 0) {\n\t\t \n\t\txfs_btree_get_node_keys(cur, left,\n\t\t\t\txfs_btree_key_addr(cur, 1, new));\n\t\txfs_btree_get_node_keys(cur, right,\n\t\t\t\txfs_btree_key_addr(cur, 2, new));\n\t} else {\n\t\t \n\t\txfs_btree_get_leaf_keys(cur, left,\n\t\t\txfs_btree_key_addr(cur, 1, new));\n\t\txfs_btree_get_leaf_keys(cur, right,\n\t\t\txfs_btree_key_addr(cur, 2, new));\n\t}\n\txfs_btree_log_keys(cur, nbp, 1, 2);\n\n\t \n\txfs_btree_copy_ptrs(cur,\n\t\txfs_btree_ptr_addr(cur, 1, new), &lptr, 1);\n\txfs_btree_copy_ptrs(cur,\n\t\txfs_btree_ptr_addr(cur, 2, new), &rptr, 1);\n\txfs_btree_log_ptrs(cur, nbp, 1, 2);\n\n\t \n\txfs_btree_setbuf(cur, cur->bc_nlevels, nbp);\n\tcur->bc_levels[cur->bc_nlevels].ptr = nptr;\n\tcur->bc_nlevels++;\n\tASSERT(cur->bc_nlevels <= cur->bc_maxlevels);\n\t*stat = 1;\n\treturn 0;\nerror0:\n\treturn error;\nout0:\n\t*stat = 0;\n\treturn 0;\n}\n\nSTATIC int\nxfs_btree_make_block_unfull(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\tlevel,\t \n\tint\t\t\tnumrecs, \n\tint\t\t\t*oindex, \n\tint\t\t\t*index,\t \n\tunion xfs_btree_ptr\t*nptr,\t \n\tstruct xfs_btree_cur\t**ncur,\t \n\tunion xfs_btree_key\t*key,\t \n\tint\t\t\t*stat)\n{\n\tint\t\t\terror = 0;\n\n\tif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    level == cur->bc_nlevels - 1) {\n\t\tstruct xfs_inode *ip = cur->bc_ino.ip;\n\n\t\tif (numrecs < cur->bc_ops->get_dmaxrecs(cur, level)) {\n\t\t\t \n\t\t\txfs_iroot_realloc(ip, 1, cur->bc_ino.whichfork);\n\t\t\t*stat = 1;\n\t\t} else {\n\t\t\t \n\t\t\tint\tlogflags = 0;\n\n\t\t\terror = xfs_btree_new_iroot(cur, &logflags, stat);\n\t\t\tif (error || *stat == 0)\n\t\t\t\treturn error;\n\n\t\t\txfs_trans_log_inode(cur->bc_tp, ip, logflags);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\t \n\terror = xfs_btree_rshift(cur, level, stat);\n\tif (error || *stat)\n\t\treturn error;\n\n\t \n\terror = xfs_btree_lshift(cur, level, stat);\n\tif (error)\n\t\treturn error;\n\n\tif (*stat) {\n\t\t*oindex = *index = cur->bc_levels[level].ptr;\n\t\treturn 0;\n\t}\n\n\t \n\terror = xfs_btree_split(cur, level, nptr, key, ncur, stat);\n\tif (error || *stat == 0)\n\t\treturn error;\n\n\n\t*index = cur->bc_levels[level].ptr;\n\treturn 0;\n}\n\n \nSTATIC int\nxfs_btree_insrec(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\tlevel,\t \n\tunion xfs_btree_ptr\t*ptrp,\t \n\tunion xfs_btree_rec\t*rec,\t \n\tunion xfs_btree_key\t*key,\t \n\tstruct xfs_btree_cur\t**curp,\t \n\tint\t\t\t*stat)\t \n{\n\tstruct xfs_btree_block\t*block;\t \n\tstruct xfs_buf\t\t*bp;\t \n\tunion xfs_btree_ptr\tnptr;\t \n\tstruct xfs_btree_cur\t*ncur = NULL;\t \n\tunion xfs_btree_key\tnkey;\t \n\tunion xfs_btree_key\t*lkey;\n\tint\t\t\toptr;\t \n\tint\t\t\tptr;\t \n\tint\t\t\tnumrecs; \n\tint\t\t\terror;\t \n\tint\t\t\ti;\n\txfs_daddr_t\t\told_bn;\n\n\tncur = NULL;\n\tlkey = &nkey;\n\n\t \n\tif (!(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    (level >= cur->bc_nlevels)) {\n\t\terror = xfs_btree_new_root(cur, stat);\n\t\txfs_btree_set_ptr_null(cur, ptrp);\n\n\t\treturn error;\n\t}\n\n\t \n\tptr = cur->bc_levels[level].ptr;\n\tif (ptr == 0) {\n\t\t*stat = 0;\n\t\treturn 0;\n\t}\n\n\toptr = ptr;\n\n\tXFS_BTREE_STATS_INC(cur, insrec);\n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\told_bn = bp ? xfs_buf_daddr(bp) : XFS_BUF_DADDR_NULL;\n\tnumrecs = xfs_btree_get_numrecs(block);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, level, bp);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\tif (ptr <= numrecs) {\n\t\tif (level == 0) {\n\t\t\tASSERT(cur->bc_ops->recs_inorder(cur, rec,\n\t\t\t\txfs_btree_rec_addr(cur, ptr, block)));\n\t\t} else {\n\t\t\tASSERT(cur->bc_ops->keys_inorder(cur, key,\n\t\t\t\txfs_btree_key_addr(cur, ptr, block)));\n\t\t}\n\t}\n#endif\n\n\t \n\txfs_btree_set_ptr_null(cur, &nptr);\n\tif (numrecs == cur->bc_ops->get_maxrecs(cur, level)) {\n\t\terror = xfs_btree_make_block_unfull(cur, level, numrecs,\n\t\t\t\t\t&optr, &ptr, &nptr, &ncur, lkey, stat);\n\t\tif (error || *stat == 0)\n\t\t\tgoto error0;\n\t}\n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\tnumrecs = xfs_btree_get_numrecs(block);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, level, bp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\t \n\tXFS_BTREE_STATS_ADD(cur, moves, numrecs - ptr + 1);\n\n\tif (level > 0) {\n\t\t \n\t\tunion xfs_btree_key\t*kp;\n\t\tunion xfs_btree_ptr\t*pp;\n\n\t\tkp = xfs_btree_key_addr(cur, ptr, block);\n\t\tpp = xfs_btree_ptr_addr(cur, ptr, block);\n\n\t\tfor (i = numrecs - ptr; i >= 0; i--) {\n\t\t\terror = xfs_btree_debug_check_ptr(cur, pp, i, level);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t}\n\n\t\txfs_btree_shift_keys(cur, kp, 1, numrecs - ptr + 1);\n\t\txfs_btree_shift_ptrs(cur, pp, 1, numrecs - ptr + 1);\n\n\t\terror = xfs_btree_debug_check_ptr(cur, ptrp, 0, level);\n\t\tif (error)\n\t\t\tgoto error0;\n\n\t\t \n\t\txfs_btree_copy_keys(cur, kp, key, 1);\n\t\txfs_btree_copy_ptrs(cur, pp, ptrp, 1);\n\t\tnumrecs++;\n\t\txfs_btree_set_numrecs(block, numrecs);\n\t\txfs_btree_log_ptrs(cur, bp, ptr, numrecs);\n\t\txfs_btree_log_keys(cur, bp, ptr, numrecs);\n#ifdef DEBUG\n\t\tif (ptr < numrecs) {\n\t\t\tASSERT(cur->bc_ops->keys_inorder(cur, kp,\n\t\t\t\txfs_btree_key_addr(cur, ptr + 1, block)));\n\t\t}\n#endif\n\t} else {\n\t\t \n\t\tunion xfs_btree_rec             *rp;\n\n\t\trp = xfs_btree_rec_addr(cur, ptr, block);\n\n\t\txfs_btree_shift_recs(cur, rp, 1, numrecs - ptr + 1);\n\n\t\t \n\t\txfs_btree_copy_recs(cur, rp, rec, 1);\n\t\txfs_btree_set_numrecs(block, ++numrecs);\n\t\txfs_btree_log_recs(cur, bp, ptr, numrecs);\n#ifdef DEBUG\n\t\tif (ptr < numrecs) {\n\t\t\tASSERT(cur->bc_ops->recs_inorder(cur, rp,\n\t\t\t\txfs_btree_rec_addr(cur, ptr + 1, block)));\n\t\t}\n#endif\n\t}\n\n\t \n\txfs_btree_log_block(cur, bp, XFS_BB_NUMRECS);\n\n\t \n\tif (bp && xfs_buf_daddr(bp) != old_bn) {\n\t\txfs_btree_get_keys(cur, block, lkey);\n\t} else if (xfs_btree_needs_key_update(cur, optr)) {\n\t\terror = xfs_btree_update_keys(cur, level);\n\t\tif (error)\n\t\t\tgoto error0;\n\t}\n\n\t \n\tif (xfs_btree_is_lastrec(cur, block, level)) {\n\t\tcur->bc_ops->update_lastrec(cur, block, rec,\n\t\t\t\t\t    ptr, LASTREC_INSREC);\n\t}\n\n\t \n\t*ptrp = nptr;\n\tif (!xfs_btree_ptr_is_null(cur, &nptr)) {\n\t\txfs_btree_copy_keys(cur, key, lkey, 1);\n\t\t*curp = ncur;\n\t}\n\n\t*stat = 1;\n\treturn 0;\n\nerror0:\n\tif (ncur)\n\t\txfs_btree_del_cursor(ncur, error);\n\treturn error;\n}\n\n \nint\nxfs_btree_insert(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\t*stat)\n{\n\tint\t\t\terror;\t \n\tint\t\t\ti;\t \n\tint\t\t\tlevel;\t \n\tunion xfs_btree_ptr\tnptr;\t \n\tstruct xfs_btree_cur\t*ncur;\t \n\tstruct xfs_btree_cur\t*pcur;\t \n\tunion xfs_btree_key\tbkey;\t \n\tunion xfs_btree_key\t*key;\n\tunion xfs_btree_rec\trec;\t \n\n\tlevel = 0;\n\tncur = NULL;\n\tpcur = cur;\n\tkey = &bkey;\n\n\txfs_btree_set_ptr_null(cur, &nptr);\n\n\t \n\tcur->bc_ops->init_rec_from_cur(cur, &rec);\n\tcur->bc_ops->init_key_from_rec(key, &rec);\n\n\t \n\tdo {\n\t\t \n\t\terror = xfs_btree_insrec(pcur, level, &nptr, &rec, key,\n\t\t\t\t&ncur, &i);\n\t\tif (error) {\n\t\t\tif (pcur != cur)\n\t\t\t\txfs_btree_del_cursor(pcur, XFS_BTREE_ERROR);\n\t\t\tgoto error0;\n\t\t}\n\n\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto error0;\n\t\t}\n\t\tlevel++;\n\n\t\t \n\t\tif (pcur != cur &&\n\t\t    (ncur || xfs_btree_ptr_is_null(cur, &nptr))) {\n\t\t\t \n\t\t\tif (cur->bc_ops->update_cursor)\n\t\t\t\tcur->bc_ops->update_cursor(pcur, cur);\n\t\t\tcur->bc_nlevels = pcur->bc_nlevels;\n\t\t\txfs_btree_del_cursor(pcur, XFS_BTREE_NOERROR);\n\t\t}\n\t\t \n\t\tif (ncur) {\n\t\t\tpcur = ncur;\n\t\t\tncur = NULL;\n\t\t}\n\t} while (!xfs_btree_ptr_is_null(cur, &nptr));\n\n\t*stat = i;\n\treturn 0;\nerror0:\n\treturn error;\n}\n\n \nSTATIC int\nxfs_btree_kill_iroot(\n\tstruct xfs_btree_cur\t*cur)\n{\n\tint\t\t\twhichfork = cur->bc_ino.whichfork;\n\tstruct xfs_inode\t*ip = cur->bc_ino.ip;\n\tstruct xfs_ifork\t*ifp = xfs_ifork_ptr(ip, whichfork);\n\tstruct xfs_btree_block\t*block;\n\tstruct xfs_btree_block\t*cblock;\n\tunion xfs_btree_key\t*kp;\n\tunion xfs_btree_key\t*ckp;\n\tunion xfs_btree_ptr\t*pp;\n\tunion xfs_btree_ptr\t*cpp;\n\tstruct xfs_buf\t\t*cbp;\n\tint\t\t\tlevel;\n\tint\t\t\tindex;\n\tint\t\t\tnumrecs;\n\tint\t\t\terror;\n#ifdef DEBUG\n\tunion xfs_btree_ptr\tptr;\n#endif\n\tint\t\t\ti;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\n\tASSERT(cur->bc_nlevels > 1);\n\n\t \n\tlevel = cur->bc_nlevels - 1;\n\tif (level == 1)\n\t\tgoto out0;\n\n\t \n\tblock = xfs_btree_get_iroot(cur);\n\tif (xfs_btree_get_numrecs(block) != 1)\n\t\tgoto out0;\n\n\tcblock = xfs_btree_get_block(cur, level - 1, &cbp);\n\tnumrecs = xfs_btree_get_numrecs(cblock);\n\n\t \n\tif (numrecs > cur->bc_ops->get_dmaxrecs(cur, level))\n\t\tgoto out0;\n\n\tXFS_BTREE_STATS_INC(cur, killroot);\n\n#ifdef DEBUG\n\txfs_btree_get_sibling(cur, block, &ptr, XFS_BB_LEFTSIB);\n\tASSERT(xfs_btree_ptr_is_null(cur, &ptr));\n\txfs_btree_get_sibling(cur, block, &ptr, XFS_BB_RIGHTSIB);\n\tASSERT(xfs_btree_ptr_is_null(cur, &ptr));\n#endif\n\n\tindex = numrecs - cur->bc_ops->get_maxrecs(cur, level);\n\tif (index) {\n\t\txfs_iroot_realloc(cur->bc_ino.ip, index,\n\t\t\t\t  cur->bc_ino.whichfork);\n\t\tblock = ifp->if_broot;\n\t}\n\n\tbe16_add_cpu(&block->bb_numrecs, index);\n\tASSERT(block->bb_numrecs == cblock->bb_numrecs);\n\n\tkp = xfs_btree_key_addr(cur, 1, block);\n\tckp = xfs_btree_key_addr(cur, 1, cblock);\n\txfs_btree_copy_keys(cur, kp, ckp, numrecs);\n\n\tpp = xfs_btree_ptr_addr(cur, 1, block);\n\tcpp = xfs_btree_ptr_addr(cur, 1, cblock);\n\n\tfor (i = 0; i < numrecs; i++) {\n\t\terror = xfs_btree_debug_check_ptr(cur, cpp, i, level - 1);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\txfs_btree_copy_ptrs(cur, pp, cpp, numrecs);\n\n\terror = xfs_btree_free_block(cur, cbp);\n\tif (error)\n\t\treturn error;\n\n\tcur->bc_levels[level - 1].bp = NULL;\n\tbe16_add_cpu(&block->bb_level, -1);\n\txfs_trans_log_inode(cur->bc_tp, ip,\n\t\tXFS_ILOG_CORE | xfs_ilog_fbroot(cur->bc_ino.whichfork));\n\tcur->bc_nlevels--;\nout0:\n\treturn 0;\n}\n\n \nSTATIC int\nxfs_btree_kill_root(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp,\n\tint\t\t\tlevel,\n\tunion xfs_btree_ptr\t*newroot)\n{\n\tint\t\t\terror;\n\n\tXFS_BTREE_STATS_INC(cur, killroot);\n\n\t \n\tcur->bc_ops->set_root(cur, newroot, -1);\n\n\terror = xfs_btree_free_block(cur, bp);\n\tif (error)\n\t\treturn error;\n\n\tcur->bc_levels[level].bp = NULL;\n\tcur->bc_levels[level].ra = 0;\n\tcur->bc_nlevels--;\n\n\treturn 0;\n}\n\nSTATIC int\nxfs_btree_dec_cursor(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tint\t\t\t*stat)\n{\n\tint\t\t\terror;\n\tint\t\t\ti;\n\n\tif (level > 0) {\n\t\terror = xfs_btree_decrement(cur, level, &i);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\t*stat = 1;\n\treturn 0;\n}\n\n \nSTATIC int\t\t\t\t\t \nxfs_btree_delrec(\n\tstruct xfs_btree_cur\t*cur,\t\t \n\tint\t\t\tlevel,\t\t \n\tint\t\t\t*stat)\t\t \n{\n\tstruct xfs_btree_block\t*block;\t\t \n\tunion xfs_btree_ptr\tcptr;\t\t \n\tstruct xfs_buf\t\t*bp;\t\t \n\tint\t\t\terror;\t\t \n\tint\t\t\ti;\t\t \n\tunion xfs_btree_ptr\tlptr;\t\t \n\tstruct xfs_buf\t\t*lbp;\t\t \n\tstruct xfs_btree_block\t*left;\t\t \n\tint\t\t\tlrecs = 0;\t \n\tint\t\t\tptr;\t\t \n\tunion xfs_btree_ptr\trptr;\t\t \n\tstruct xfs_buf\t\t*rbp;\t\t \n\tstruct xfs_btree_block\t*right;\t\t \n\tstruct xfs_btree_block\t*rrblock;\t \n\tstruct xfs_buf\t\t*rrbp;\t\t \n\tint\t\t\trrecs = 0;\t \n\tstruct xfs_btree_cur\t*tcur;\t\t \n\tint\t\t\tnumrecs;\t \n\n\ttcur = NULL;\n\n\t \n\tptr = cur->bc_levels[level].ptr;\n\tif (ptr == 0) {\n\t\t*stat = 0;\n\t\treturn 0;\n\t}\n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\tnumrecs = xfs_btree_get_numrecs(block);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, level, bp);\n\tif (error)\n\t\tgoto error0;\n#endif\n\n\t \n\tif (ptr > numrecs) {\n\t\t*stat = 0;\n\t\treturn 0;\n\t}\n\n\tXFS_BTREE_STATS_INC(cur, delrec);\n\tXFS_BTREE_STATS_ADD(cur, moves, numrecs - ptr);\n\n\t \n\tif (level > 0) {\n\t\t \n\t\tunion xfs_btree_key\t*lkp;\n\t\tunion xfs_btree_ptr\t*lpp;\n\n\t\tlkp = xfs_btree_key_addr(cur, ptr + 1, block);\n\t\tlpp = xfs_btree_ptr_addr(cur, ptr + 1, block);\n\n\t\tfor (i = 0; i < numrecs - ptr; i++) {\n\t\t\terror = xfs_btree_debug_check_ptr(cur, lpp, i, level);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t}\n\n\t\tif (ptr < numrecs) {\n\t\t\txfs_btree_shift_keys(cur, lkp, -1, numrecs - ptr);\n\t\t\txfs_btree_shift_ptrs(cur, lpp, -1, numrecs - ptr);\n\t\t\txfs_btree_log_keys(cur, bp, ptr, numrecs - 1);\n\t\t\txfs_btree_log_ptrs(cur, bp, ptr, numrecs - 1);\n\t\t}\n\t} else {\n\t\t \n\t\tif (ptr < numrecs) {\n\t\t\txfs_btree_shift_recs(cur,\n\t\t\t\txfs_btree_rec_addr(cur, ptr + 1, block),\n\t\t\t\t-1, numrecs - ptr);\n\t\t\txfs_btree_log_recs(cur, bp, ptr, numrecs - 1);\n\t\t}\n\t}\n\n\t \n\txfs_btree_set_numrecs(block, --numrecs);\n\txfs_btree_log_block(cur, bp, XFS_BB_NUMRECS);\n\n\t \n\tif (xfs_btree_is_lastrec(cur, block, level)) {\n\t\tcur->bc_ops->update_lastrec(cur, block, NULL,\n\t\t\t\t\t    ptr, LASTREC_DELREC);\n\t}\n\n\t \n\tif (level == cur->bc_nlevels - 1) {\n\t\tif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) {\n\t\t\txfs_iroot_realloc(cur->bc_ino.ip, -1,\n\t\t\t\t\t  cur->bc_ino.whichfork);\n\n\t\t\terror = xfs_btree_kill_iroot(cur);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\n\t\t\terror = xfs_btree_dec_cursor(cur, level, stat);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t\t*stat = 1;\n\t\t\treturn 0;\n\t\t}\n\n\t\t \n\t\tif (numrecs == 1 && level > 0) {\n\t\t\tunion xfs_btree_ptr\t*pp;\n\t\t\t \n\t\t\tpp = xfs_btree_ptr_addr(cur, 1, block);\n\t\t\terror = xfs_btree_kill_root(cur, bp, level, pp);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t} else if (level > 0) {\n\t\t\terror = xfs_btree_dec_cursor(cur, level, stat);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t}\n\t\t*stat = 1;\n\t\treturn 0;\n\t}\n\n\t \n\tif (xfs_btree_needs_key_update(cur, ptr)) {\n\t\terror = xfs_btree_update_keys(cur, level);\n\t\tif (error)\n\t\t\tgoto error0;\n\t}\n\n\t \n\tif (numrecs >= cur->bc_ops->get_minrecs(cur, level)) {\n\t\terror = xfs_btree_dec_cursor(cur, level, stat);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\treturn 0;\n\t}\n\n\t \n\txfs_btree_get_sibling(cur, block, &rptr, XFS_BB_RIGHTSIB);\n\txfs_btree_get_sibling(cur, block, &lptr, XFS_BB_LEFTSIB);\n\n\tif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) {\n\t\t \n\t\tif (xfs_btree_ptr_is_null(cur, &rptr) &&\n\t\t    xfs_btree_ptr_is_null(cur, &lptr) &&\n\t\t    level == cur->bc_nlevels - 2) {\n\t\t\terror = xfs_btree_kill_iroot(cur);\n\t\t\tif (!error)\n\t\t\t\terror = xfs_btree_dec_cursor(cur, level, stat);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tASSERT(!xfs_btree_ptr_is_null(cur, &rptr) ||\n\t       !xfs_btree_ptr_is_null(cur, &lptr));\n\n\t \n\terror = xfs_btree_dup_cursor(cur, &tcur);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\tif (!xfs_btree_ptr_is_null(cur, &rptr)) {\n\t\t \n\t\ti = xfs_btree_lastrec(tcur, level);\n\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto error0;\n\t\t}\n\n\t\terror = xfs_btree_increment(tcur, level, &i);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto error0;\n\t\t}\n\n\t\ti = xfs_btree_lastrec(tcur, level);\n\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto error0;\n\t\t}\n\n\t\t \n\t\tright = xfs_btree_get_block(tcur, level, &rbp);\n#ifdef DEBUG\n\t\terror = xfs_btree_check_block(tcur, right, level, rbp);\n\t\tif (error)\n\t\t\tgoto error0;\n#endif\n\t\t \n\t\txfs_btree_get_sibling(tcur, right, &cptr, XFS_BB_LEFTSIB);\n\n\t\t \n\t\tif (xfs_btree_get_numrecs(right) - 1 >=\n\t\t    cur->bc_ops->get_minrecs(tcur, level)) {\n\t\t\terror = xfs_btree_lshift(tcur, level, &i);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t\tif (i) {\n\t\t\t\tASSERT(xfs_btree_get_numrecs(block) >=\n\t\t\t\t       cur->bc_ops->get_minrecs(tcur, level));\n\n\t\t\t\txfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\n\t\t\t\ttcur = NULL;\n\n\t\t\t\terror = xfs_btree_dec_cursor(cur, level, stat);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto error0;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\trrecs = xfs_btree_get_numrecs(right);\n\t\tif (!xfs_btree_ptr_is_null(cur, &lptr)) {\n\t\t\ti = xfs_btree_firstrec(tcur, level);\n\t\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\t\terror = -EFSCORRUPTED;\n\t\t\t\tgoto error0;\n\t\t\t}\n\n\t\t\terror = xfs_btree_decrement(tcur, level, &i);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\t\terror = -EFSCORRUPTED;\n\t\t\t\tgoto error0;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (!xfs_btree_ptr_is_null(cur, &lptr)) {\n\t\t \n\t\ti = xfs_btree_firstrec(tcur, level);\n\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto error0;\n\t\t}\n\n\t\terror = xfs_btree_decrement(tcur, level, &i);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\ti = xfs_btree_firstrec(tcur, level);\n\t\tif (XFS_IS_CORRUPT(cur->bc_mp, i != 1)) {\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto error0;\n\t\t}\n\n\t\t \n\t\tleft = xfs_btree_get_block(tcur, level, &lbp);\n#ifdef DEBUG\n\t\terror = xfs_btree_check_block(cur, left, level, lbp);\n\t\tif (error)\n\t\t\tgoto error0;\n#endif\n\t\t \n\t\txfs_btree_get_sibling(tcur, left, &cptr, XFS_BB_RIGHTSIB);\n\n\t\t \n\t\tif (xfs_btree_get_numrecs(left) - 1 >=\n\t\t    cur->bc_ops->get_minrecs(tcur, level)) {\n\t\t\terror = xfs_btree_rshift(tcur, level, &i);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t\tif (i) {\n\t\t\t\tASSERT(xfs_btree_get_numrecs(block) >=\n\t\t\t\t       cur->bc_ops->get_minrecs(tcur, level));\n\t\t\t\txfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\n\t\t\t\ttcur = NULL;\n\t\t\t\tif (level == 0)\n\t\t\t\t\tcur->bc_levels[0].ptr++;\n\n\t\t\t\t*stat = 1;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tlrecs = xfs_btree_get_numrecs(left);\n\t}\n\n\t \n\txfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\n\ttcur = NULL;\n\n\t \n\tASSERT(!xfs_btree_ptr_is_null(cur, &cptr));\n\n\tif (!xfs_btree_ptr_is_null(cur, &lptr) &&\n\t    lrecs + xfs_btree_get_numrecs(block) <=\n\t\t\tcur->bc_ops->get_maxrecs(cur, level)) {\n\t\t \n\t\trptr = cptr;\n\t\tright = block;\n\t\trbp = bp;\n\t\terror = xfs_btree_read_buf_block(cur, &lptr, 0, &left, &lbp);\n\t\tif (error)\n\t\t\tgoto error0;\n\n\t \n\t} else if (!xfs_btree_ptr_is_null(cur, &rptr) &&\n\t\t   rrecs + xfs_btree_get_numrecs(block) <=\n\t\t\tcur->bc_ops->get_maxrecs(cur, level)) {\n\t\t \n\t\tlptr = cptr;\n\t\tleft = block;\n\t\tlbp = bp;\n\t\terror = xfs_btree_read_buf_block(cur, &rptr, 0, &right, &rbp);\n\t\tif (error)\n\t\t\tgoto error0;\n\n\t \n\t} else {\n\t\terror = xfs_btree_dec_cursor(cur, level, stat);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\treturn 0;\n\t}\n\n\trrecs = xfs_btree_get_numrecs(right);\n\tlrecs = xfs_btree_get_numrecs(left);\n\n\t \n\tXFS_BTREE_STATS_ADD(cur, moves, rrecs);\n\tif (level > 0) {\n\t\t \n\t\tunion xfs_btree_key\t*lkp;\t \n\t\tunion xfs_btree_ptr\t*lpp;\t \n\t\tunion xfs_btree_key\t*rkp;\t \n\t\tunion xfs_btree_ptr\t*rpp;\t \n\n\t\tlkp = xfs_btree_key_addr(cur, lrecs + 1, left);\n\t\tlpp = xfs_btree_ptr_addr(cur, lrecs + 1, left);\n\t\trkp = xfs_btree_key_addr(cur, 1, right);\n\t\trpp = xfs_btree_ptr_addr(cur, 1, right);\n\n\t\tfor (i = 1; i < rrecs; i++) {\n\t\t\terror = xfs_btree_debug_check_ptr(cur, rpp, i, level);\n\t\t\tif (error)\n\t\t\t\tgoto error0;\n\t\t}\n\n\t\txfs_btree_copy_keys(cur, lkp, rkp, rrecs);\n\t\txfs_btree_copy_ptrs(cur, lpp, rpp, rrecs);\n\n\t\txfs_btree_log_keys(cur, lbp, lrecs + 1, lrecs + rrecs);\n\t\txfs_btree_log_ptrs(cur, lbp, lrecs + 1, lrecs + rrecs);\n\t} else {\n\t\t \n\t\tunion xfs_btree_rec\t*lrp;\t \n\t\tunion xfs_btree_rec\t*rrp;\t \n\n\t\tlrp = xfs_btree_rec_addr(cur, lrecs + 1, left);\n\t\trrp = xfs_btree_rec_addr(cur, 1, right);\n\n\t\txfs_btree_copy_recs(cur, lrp, rrp, rrecs);\n\t\txfs_btree_log_recs(cur, lbp, lrecs + 1, lrecs + rrecs);\n\t}\n\n\tXFS_BTREE_STATS_INC(cur, join);\n\n\t \n\txfs_btree_set_numrecs(left, lrecs + rrecs);\n\txfs_btree_get_sibling(cur, right, &cptr, XFS_BB_RIGHTSIB);\n\txfs_btree_set_sibling(cur, left, &cptr, XFS_BB_RIGHTSIB);\n\txfs_btree_log_block(cur, lbp, XFS_BB_NUMRECS | XFS_BB_RIGHTSIB);\n\n\t \n\txfs_btree_get_sibling(cur, left, &cptr, XFS_BB_RIGHTSIB);\n\tif (!xfs_btree_ptr_is_null(cur, &cptr)) {\n\t\terror = xfs_btree_read_buf_block(cur, &cptr, 0, &rrblock, &rrbp);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\txfs_btree_set_sibling(cur, rrblock, &lptr, XFS_BB_LEFTSIB);\n\t\txfs_btree_log_block(cur, rrbp, XFS_BB_LEFTSIB);\n\t}\n\n\t \n\terror = xfs_btree_free_block(cur, rbp);\n\tif (error)\n\t\tgoto error0;\n\n\t \n\tif (bp != lbp) {\n\t\tcur->bc_levels[level].bp = lbp;\n\t\tcur->bc_levels[level].ptr += lrecs;\n\t\tcur->bc_levels[level].ra = 0;\n\t}\n\t \n\telse if ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) ||\n\t\t   (level + 1 < cur->bc_nlevels)) {\n\t\terror = xfs_btree_increment(cur, level + 1, &i);\n\t\tif (error)\n\t\t\tgoto error0;\n\t}\n\n\t \n\tif (level > 0)\n\t\tcur->bc_levels[level].ptr--;\n\n\t \n\n\t \n\t*stat = 2;\n\treturn 0;\n\nerror0:\n\tif (tcur)\n\t\txfs_btree_del_cursor(tcur, XFS_BTREE_ERROR);\n\treturn error;\n}\n\n \nint\t\t\t\t\t \nxfs_btree_delete(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\t*stat)\t \n{\n\tint\t\t\terror;\t \n\tint\t\t\tlevel;\n\tint\t\t\ti;\n\tbool\t\t\tjoined = false;\n\n\t \n\tfor (level = 0, i = 2; i == 2; level++) {\n\t\terror = xfs_btree_delrec(cur, level, &i);\n\t\tif (error)\n\t\t\tgoto error0;\n\t\tif (i == 2)\n\t\t\tjoined = true;\n\t}\n\n\t \n\tif (joined && (cur->bc_flags & XFS_BTREE_OVERLAPPING)) {\n\t\terror = xfs_btree_updkeys_force(cur, 0);\n\t\tif (error)\n\t\t\tgoto error0;\n\t}\n\n\tif (i == 0) {\n\t\tfor (level = 1; level < cur->bc_nlevels; level++) {\n\t\t\tif (cur->bc_levels[level].ptr == 0) {\n\t\t\t\terror = xfs_btree_decrement(cur, level, &i);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto error0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t*stat = i;\n\treturn 0;\nerror0:\n\treturn error;\n}\n\n \nint\t\t\t\t\t \nxfs_btree_get_rec(\n\tstruct xfs_btree_cur\t*cur,\t \n\tunion xfs_btree_rec\t**recp,\t \n\tint\t\t\t*stat)\t \n{\n\tstruct xfs_btree_block\t*block;\t \n\tstruct xfs_buf\t\t*bp;\t \n\tint\t\t\tptr;\t \n#ifdef DEBUG\n\tint\t\t\terror;\t \n#endif\n\n\tptr = cur->bc_levels[0].ptr;\n\tblock = xfs_btree_get_block(cur, 0, &bp);\n\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, 0, bp);\n\tif (error)\n\t\treturn error;\n#endif\n\n\t \n\tif (ptr > xfs_btree_get_numrecs(block) || ptr <= 0) {\n\t\t*stat = 0;\n\t\treturn 0;\n\t}\n\n\t \n\t*recp = xfs_btree_rec_addr(cur, ptr, block);\n\t*stat = 1;\n\treturn 0;\n}\n\n \nSTATIC int\nxfs_btree_visit_block(\n\tstruct xfs_btree_cur\t\t*cur,\n\tint\t\t\t\tlevel,\n\txfs_btree_visit_blocks_fn\tfn,\n\tvoid\t\t\t\t*data)\n{\n\tstruct xfs_btree_block\t\t*block;\n\tstruct xfs_buf\t\t\t*bp;\n\tunion xfs_btree_ptr\t\trptr;\n\tint\t\t\t\terror;\n\n\t \n\txfs_btree_readahead(cur, level, XFS_BTCUR_RIGHTRA);\n\tblock = xfs_btree_get_block(cur, level, &bp);\n\n\t \n\terror = fn(cur, level, data);\n\tif (error)\n\t\treturn error;\n\n\t \n\txfs_btree_get_sibling(cur, block, &rptr, XFS_BB_RIGHTSIB);\n\tif (xfs_btree_ptr_is_null(cur, &rptr))\n\t\treturn -ENOENT;\n\n\t \n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tif (be64_to_cpu(rptr.l) == XFS_DADDR_TO_FSB(cur->bc_mp,\n\t\t\t\t\t\t\txfs_buf_daddr(bp)))\n\t\t\treturn -EFSCORRUPTED;\n\t} else {\n\t\tif (be32_to_cpu(rptr.s) == xfs_daddr_to_agbno(cur->bc_mp,\n\t\t\t\t\t\t\txfs_buf_daddr(bp)))\n\t\t\treturn -EFSCORRUPTED;\n\t}\n\treturn xfs_btree_lookup_get_block(cur, level, &rptr, &block);\n}\n\n\n \nint\nxfs_btree_visit_blocks(\n\tstruct xfs_btree_cur\t\t*cur,\n\txfs_btree_visit_blocks_fn\tfn,\n\tunsigned int\t\t\tflags,\n\tvoid\t\t\t\t*data)\n{\n\tunion xfs_btree_ptr\t\tlptr;\n\tint\t\t\t\tlevel;\n\tstruct xfs_btree_block\t\t*block = NULL;\n\tint\t\t\t\terror = 0;\n\n\tcur->bc_ops->init_ptr_from_cur(cur, &lptr);\n\n\t \n\tfor (level = cur->bc_nlevels - 1; level >= 0; level--) {\n\t\t \n\t\terror = xfs_btree_lookup_get_block(cur, level, &lptr, &block);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\t \n\t\tif (level > 0) {\n\t\t\tunion xfs_btree_ptr     *ptr;\n\n\t\t\tptr = xfs_btree_ptr_addr(cur, 1, block);\n\t\t\txfs_btree_readahead_ptr(cur, ptr, 1);\n\n\t\t\t \n\t\t\txfs_btree_copy_ptrs(cur, &lptr, ptr, 1);\n\n\t\t\tif (!(flags & XFS_BTREE_VISIT_LEAVES))\n\t\t\t\tcontinue;\n\t\t} else if (!(flags & XFS_BTREE_VISIT_RECORDS)) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tdo {\n\t\t\terror = xfs_btree_visit_block(cur, level, fn, data);\n\t\t} while (!error);\n\n\t\tif (error != -ENOENT)\n\t\t\treturn error;\n\t}\n\n\treturn 0;\n}\n\n \nstruct xfs_btree_block_change_owner_info {\n\tuint64_t\t\tnew_owner;\n\tstruct list_head\t*buffer_list;\n};\n\nstatic int\nxfs_btree_block_change_owner(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tvoid\t\t\t*data)\n{\n\tstruct xfs_btree_block_change_owner_info\t*bbcoi = data;\n\tstruct xfs_btree_block\t*block;\n\tstruct xfs_buf\t\t*bp;\n\n\t \n\tblock = xfs_btree_get_block(cur, level, &bp);\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS) {\n\t\tif (block->bb_u.l.bb_owner == cpu_to_be64(bbcoi->new_owner))\n\t\t\treturn 0;\n\t\tblock->bb_u.l.bb_owner = cpu_to_be64(bbcoi->new_owner);\n\t} else {\n\t\tif (block->bb_u.s.bb_owner == cpu_to_be32(bbcoi->new_owner))\n\t\t\treturn 0;\n\t\tblock->bb_u.s.bb_owner = cpu_to_be32(bbcoi->new_owner);\n\t}\n\n\t \n\tif (!bp) {\n\t\tASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\n\t\tASSERT(level == cur->bc_nlevels - 1);\n\t\treturn 0;\n\t}\n\n\tif (cur->bc_tp) {\n\t\tif (!xfs_trans_ordered_buf(cur->bc_tp, bp)) {\n\t\t\txfs_btree_log_block(cur, bp, XFS_BB_OWNER);\n\t\t\treturn -EAGAIN;\n\t\t}\n\t} else {\n\t\txfs_buf_delwri_queue(bp, bbcoi->buffer_list);\n\t}\n\n\treturn 0;\n}\n\nint\nxfs_btree_change_owner(\n\tstruct xfs_btree_cur\t*cur,\n\tuint64_t\t\tnew_owner,\n\tstruct list_head\t*buffer_list)\n{\n\tstruct xfs_btree_block_change_owner_info\tbbcoi;\n\n\tbbcoi.new_owner = new_owner;\n\tbbcoi.buffer_list = buffer_list;\n\n\treturn xfs_btree_visit_blocks(cur, xfs_btree_block_change_owner,\n\t\t\tXFS_BTREE_VISIT_ALL, &bbcoi);\n}\n\n \nxfs_failaddr_t\nxfs_btree_lblock_v5hdr_verify(\n\tstruct xfs_buf\t\t*bp,\n\tuint64_t\t\towner)\n{\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\n\tif (!xfs_has_crc(mp))\n\t\treturn __this_address;\n\tif (!uuid_equal(&block->bb_u.l.bb_uuid, &mp->m_sb.sb_meta_uuid))\n\t\treturn __this_address;\n\tif (block->bb_u.l.bb_blkno != cpu_to_be64(xfs_buf_daddr(bp)))\n\t\treturn __this_address;\n\tif (owner != XFS_RMAP_OWN_UNKNOWN &&\n\t    be64_to_cpu(block->bb_u.l.bb_owner) != owner)\n\t\treturn __this_address;\n\treturn NULL;\n}\n\n \nxfs_failaddr_t\nxfs_btree_lblock_verify(\n\tstruct xfs_buf\t\t*bp,\n\tunsigned int\t\tmax_recs)\n{\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\txfs_fsblock_t\t\tfsb;\n\txfs_failaddr_t\t\tfa;\n\n\t \n\tif (be16_to_cpu(block->bb_numrecs) > max_recs)\n\t\treturn __this_address;\n\n\t \n\tfsb = XFS_DADDR_TO_FSB(mp, xfs_buf_daddr(bp));\n\tfa = xfs_btree_check_lblock_siblings(mp, NULL, -1, fsb,\n\t\t\tblock->bb_u.l.bb_leftsib);\n\tif (!fa)\n\t\tfa = xfs_btree_check_lblock_siblings(mp, NULL, -1, fsb,\n\t\t\t\tblock->bb_u.l.bb_rightsib);\n\treturn fa;\n}\n\n \nxfs_failaddr_t\nxfs_btree_sblock_v5hdr_verify(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\tstruct xfs_perag\t*pag = bp->b_pag;\n\n\tif (!xfs_has_crc(mp))\n\t\treturn __this_address;\n\tif (!uuid_equal(&block->bb_u.s.bb_uuid, &mp->m_sb.sb_meta_uuid))\n\t\treturn __this_address;\n\tif (block->bb_u.s.bb_blkno != cpu_to_be64(xfs_buf_daddr(bp)))\n\t\treturn __this_address;\n\tif (pag && be32_to_cpu(block->bb_u.s.bb_owner) != pag->pag_agno)\n\t\treturn __this_address;\n\treturn NULL;\n}\n\n \nxfs_failaddr_t\nxfs_btree_sblock_verify(\n\tstruct xfs_buf\t\t*bp,\n\tunsigned int\t\tmax_recs)\n{\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\txfs_agblock_t\t\tagbno;\n\txfs_failaddr_t\t\tfa;\n\n\t \n\tif (be16_to_cpu(block->bb_numrecs) > max_recs)\n\t\treturn __this_address;\n\n\t \n\tagbno = xfs_daddr_to_agbno(mp, xfs_buf_daddr(bp));\n\tfa = xfs_btree_check_sblock_siblings(bp->b_pag, NULL, -1, agbno,\n\t\t\tblock->bb_u.s.bb_leftsib);\n\tif (!fa)\n\t\tfa = xfs_btree_check_sblock_siblings(bp->b_pag, NULL, -1, agbno,\n\t\t\t\tblock->bb_u.s.bb_rightsib);\n\treturn fa;\n}\n\n \nunsigned int\nxfs_btree_compute_maxlevels(\n\tconst unsigned int\t*limits,\n\tunsigned long long\trecords)\n{\n\tunsigned long long\tlevel_blocks = howmany_64(records, limits[0]);\n\tunsigned int\t\theight = 1;\n\n\twhile (level_blocks > 1) {\n\t\tlevel_blocks = howmany_64(level_blocks, limits[1]);\n\t\theight++;\n\t}\n\n\treturn height;\n}\n\n \nunsigned long long\nxfs_btree_calc_size(\n\tconst unsigned int\t*limits,\n\tunsigned long long\trecords)\n{\n\tunsigned long long\tlevel_blocks = howmany_64(records, limits[0]);\n\tunsigned long long\tblocks = level_blocks;\n\n\twhile (level_blocks > 1) {\n\t\tlevel_blocks = howmany_64(level_blocks, limits[1]);\n\t\tblocks += level_blocks;\n\t}\n\n\treturn blocks;\n}\n\n \nunsigned int\nxfs_btree_space_to_height(\n\tconst unsigned int\t*limits,\n\tunsigned long long\tleaf_blocks)\n{\n\t \n\tunsigned long long\tnode_blocks = 2;\n\tunsigned long long\tblocks_left = leaf_blocks - 1;\n\tunsigned int\t\theight = 1;\n\n\tif (leaf_blocks < 1)\n\t\treturn 0;\n\n\twhile (node_blocks < blocks_left) {\n\t\tblocks_left -= node_blocks;\n\t\tnode_blocks *= limits[1];\n\t\theight++;\n\t}\n\n\treturn height;\n}\n\n \nSTATIC int\nxfs_btree_simple_query_range(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*low_key,\n\tconst union xfs_btree_key\t*high_key,\n\txfs_btree_query_range_fn\tfn,\n\tvoid\t\t\t\t*priv)\n{\n\tunion xfs_btree_rec\t\t*recp;\n\tunion xfs_btree_key\t\trec_key;\n\tint\t\t\t\tstat;\n\tbool\t\t\t\tfirstrec = true;\n\tint\t\t\t\terror;\n\n\tASSERT(cur->bc_ops->init_high_key_from_rec);\n\tASSERT(cur->bc_ops->diff_two_keys);\n\n\t \n\tstat = 0;\n\terror = xfs_btree_lookup(cur, XFS_LOOKUP_LE, &stat);\n\tif (error)\n\t\tgoto out;\n\n\t \n\tif (!stat) {\n\t\terror = xfs_btree_increment(cur, 0, &stat);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\n\twhile (stat) {\n\t\t \n\t\terror = xfs_btree_get_rec(cur, &recp, &stat);\n\t\tif (error || !stat)\n\t\t\tbreak;\n\n\t\t \n\t\tif (firstrec) {\n\t\t\tcur->bc_ops->init_high_key_from_rec(&rec_key, recp);\n\t\t\tfirstrec = false;\n\t\t\tif (xfs_btree_keycmp_gt(cur, low_key, &rec_key))\n\t\t\t\tgoto advloop;\n\t\t}\n\n\t\t \n\t\tcur->bc_ops->init_key_from_rec(&rec_key, recp);\n\t\tif (xfs_btree_keycmp_gt(cur, &rec_key, high_key))\n\t\t\tbreak;\n\n\t\t \n\t\terror = fn(cur, recp, priv);\n\t\tif (error)\n\t\t\tbreak;\n\nadvloop:\n\t\t \n\t\terror = xfs_btree_increment(cur, 0, &stat);\n\t\tif (error)\n\t\t\tbreak;\n\t}\n\nout:\n\treturn error;\n}\n\n \nSTATIC int\nxfs_btree_overlapped_query_range(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*low_key,\n\tconst union xfs_btree_key\t*high_key,\n\txfs_btree_query_range_fn\tfn,\n\tvoid\t\t\t\t*priv)\n{\n\tunion xfs_btree_ptr\t\tptr;\n\tunion xfs_btree_ptr\t\t*pp;\n\tunion xfs_btree_key\t\trec_key;\n\tunion xfs_btree_key\t\trec_hkey;\n\tunion xfs_btree_key\t\t*lkp;\n\tunion xfs_btree_key\t\t*hkp;\n\tunion xfs_btree_rec\t\t*recp;\n\tstruct xfs_btree_block\t\t*block;\n\tint\t\t\t\tlevel;\n\tstruct xfs_buf\t\t\t*bp;\n\tint\t\t\t\ti;\n\tint\t\t\t\terror;\n\n\t \n\tlevel = cur->bc_nlevels - 1;\n\tcur->bc_ops->init_ptr_from_cur(cur, &ptr);\n\terror = xfs_btree_lookup_get_block(cur, level, &ptr, &block);\n\tif (error)\n\t\treturn error;\n\txfs_btree_get_block(cur, level, &bp);\n\ttrace_xfs_btree_overlapped_query_range(cur, level, bp);\n#ifdef DEBUG\n\terror = xfs_btree_check_block(cur, block, level, bp);\n\tif (error)\n\t\tgoto out;\n#endif\n\tcur->bc_levels[level].ptr = 1;\n\n\twhile (level < cur->bc_nlevels) {\n\t\tblock = xfs_btree_get_block(cur, level, &bp);\n\n\t\t \n\t\tif (cur->bc_levels[level].ptr >\n\t\t\t\t\tbe16_to_cpu(block->bb_numrecs)) {\npop_up:\n\t\t\tif (level < cur->bc_nlevels - 1)\n\t\t\t\tcur->bc_levels[level + 1].ptr++;\n\t\t\tlevel++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (level == 0) {\n\t\t\t \n\t\t\trecp = xfs_btree_rec_addr(cur, cur->bc_levels[0].ptr,\n\t\t\t\t\tblock);\n\n\t\t\tcur->bc_ops->init_high_key_from_rec(&rec_hkey, recp);\n\t\t\tcur->bc_ops->init_key_from_rec(&rec_key, recp);\n\n\t\t\t \n\t\t\tif (xfs_btree_keycmp_lt(cur, high_key, &rec_key))\n\t\t\t\tgoto pop_up;\n\t\t\tif (xfs_btree_keycmp_ge(cur, &rec_hkey, low_key)) {\n\t\t\t\terror = fn(cur, recp, priv);\n\t\t\t\tif (error)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcur->bc_levels[level].ptr++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tlkp = xfs_btree_key_addr(cur, cur->bc_levels[level].ptr, block);\n\t\thkp = xfs_btree_high_key_addr(cur, cur->bc_levels[level].ptr,\n\t\t\t\tblock);\n\t\tpp = xfs_btree_ptr_addr(cur, cur->bc_levels[level].ptr, block);\n\n\t\t \n\t\tif (xfs_btree_keycmp_lt(cur, high_key, lkp))\n\t\t\tgoto pop_up;\n\t\tif (xfs_btree_keycmp_ge(cur, hkp, low_key)) {\n\t\t\tlevel--;\n\t\t\terror = xfs_btree_lookup_get_block(cur, level, pp,\n\t\t\t\t\t&block);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n\t\t\txfs_btree_get_block(cur, level, &bp);\n\t\t\ttrace_xfs_btree_overlapped_query_range(cur, level, bp);\n#ifdef DEBUG\n\t\t\terror = xfs_btree_check_block(cur, block, level, bp);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n#endif\n\t\t\tcur->bc_levels[level].ptr = 1;\n\t\t\tcontinue;\n\t\t}\n\t\tcur->bc_levels[level].ptr++;\n\t}\n\nout:\n\t \n\tif (cur->bc_levels[0].bp == NULL) {\n\t\tfor (i = 0; i < cur->bc_nlevels; i++) {\n\t\t\tif (cur->bc_levels[i].bp) {\n\t\t\t\txfs_trans_brelse(cur->bc_tp,\n\t\t\t\t\t\tcur->bc_levels[i].bp);\n\t\t\t\tcur->bc_levels[i].bp = NULL;\n\t\t\t\tcur->bc_levels[i].ptr = 0;\n\t\t\t\tcur->bc_levels[i].ra = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn error;\n}\n\nstatic inline void\nxfs_btree_key_from_irec(\n\tstruct xfs_btree_cur\t\t*cur,\n\tunion xfs_btree_key\t\t*key,\n\tconst union xfs_btree_irec\t*irec)\n{\n\tunion xfs_btree_rec\t\trec;\n\n\tcur->bc_rec = *irec;\n\tcur->bc_ops->init_rec_from_cur(cur, &rec);\n\tcur->bc_ops->init_key_from_rec(key, &rec);\n}\n\n \nint\nxfs_btree_query_range(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_irec\t*low_rec,\n\tconst union xfs_btree_irec\t*high_rec,\n\txfs_btree_query_range_fn\tfn,\n\tvoid\t\t\t\t*priv)\n{\n\tunion xfs_btree_key\t\tlow_key;\n\tunion xfs_btree_key\t\thigh_key;\n\n\t \n\txfs_btree_key_from_irec(cur, &high_key, high_rec);\n\txfs_btree_key_from_irec(cur, &low_key, low_rec);\n\n\t \n\tif (!xfs_btree_keycmp_le(cur, &low_key, &high_key))\n\t\treturn -EINVAL;\n\n\tif (!(cur->bc_flags & XFS_BTREE_OVERLAPPING))\n\t\treturn xfs_btree_simple_query_range(cur, &low_key,\n\t\t\t\t&high_key, fn, priv);\n\treturn xfs_btree_overlapped_query_range(cur, &low_key, &high_key,\n\t\t\tfn, priv);\n}\n\n \nint\nxfs_btree_query_all(\n\tstruct xfs_btree_cur\t\t*cur,\n\txfs_btree_query_range_fn\tfn,\n\tvoid\t\t\t\t*priv)\n{\n\tunion xfs_btree_key\t\tlow_key;\n\tunion xfs_btree_key\t\thigh_key;\n\n\tmemset(&cur->bc_rec, 0, sizeof(cur->bc_rec));\n\tmemset(&low_key, 0, sizeof(low_key));\n\tmemset(&high_key, 0xFF, sizeof(high_key));\n\n\treturn xfs_btree_simple_query_range(cur, &low_key, &high_key, fn, priv);\n}\n\nstatic int\nxfs_btree_count_blocks_helper(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel,\n\tvoid\t\t\t*data)\n{\n\txfs_extlen_t\t\t*blocks = data;\n\t(*blocks)++;\n\n\treturn 0;\n}\n\n \nint\nxfs_btree_count_blocks(\n\tstruct xfs_btree_cur\t*cur,\n\txfs_extlen_t\t\t*blocks)\n{\n\t*blocks = 0;\n\treturn xfs_btree_visit_blocks(cur, xfs_btree_count_blocks_helper,\n\t\t\tXFS_BTREE_VISIT_ALL, blocks);\n}\n\n \nint64_t\nxfs_btree_diff_two_ptrs(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*a,\n\tconst union xfs_btree_ptr\t*b)\n{\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\treturn (int64_t)be64_to_cpu(a->l) - be64_to_cpu(b->l);\n\treturn (int64_t)be32_to_cpu(a->s) - be32_to_cpu(b->s);\n}\n\nstruct xfs_btree_has_records {\n\t \n\tunion xfs_btree_key\t\tstart_key;\n\tunion xfs_btree_key\t\tend_key;\n\n\t \n\tconst union xfs_btree_key\t*key_mask;\n\n\t \n\tunion xfs_btree_key\t\thigh_key;\n\n\tenum xbtree_recpacking\t\toutcome;\n};\n\nSTATIC int\nxfs_btree_has_records_helper(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_rec\t*rec,\n\tvoid\t\t\t\t*priv)\n{\n\tunion xfs_btree_key\t\trec_key;\n\tunion xfs_btree_key\t\trec_high_key;\n\tstruct xfs_btree_has_records\t*info = priv;\n\tenum xbtree_key_contig\t\tkey_contig;\n\n\tcur->bc_ops->init_key_from_rec(&rec_key, rec);\n\n\tif (info->outcome == XBTREE_RECPACKING_EMPTY) {\n\t\tinfo->outcome = XBTREE_RECPACKING_SPARSE;\n\n\t\t \n\t\tif (xfs_btree_masked_keycmp_lt(cur, &info->start_key, &rec_key,\n\t\t\t\t\tinfo->key_mask))\n\t\t\treturn -ECANCELED;\n\t} else {\n\t\t \n\t\tkey_contig = cur->bc_ops->keys_contiguous(cur, &info->high_key,\n\t\t\t\t\t&rec_key, info->key_mask);\n\t\tif (key_contig == XBTREE_KEY_OVERLAP &&\n\t\t\t\t!(cur->bc_flags & XFS_BTREE_OVERLAPPING))\n\t\t\treturn -EFSCORRUPTED;\n\t\tif (key_contig == XBTREE_KEY_GAP)\n\t\t\treturn -ECANCELED;\n\t}\n\n\t \n\tcur->bc_ops->init_high_key_from_rec(&rec_high_key, rec);\n\tif (xfs_btree_masked_keycmp_gt(cur, &rec_high_key, &info->high_key,\n\t\t\t\tinfo->key_mask))\n\t\tinfo->high_key = rec_high_key;  \n\n\treturn 0;\n}\n\n \nint\nxfs_btree_has_records(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_irec\t*low,\n\tconst union xfs_btree_irec\t*high,\n\tconst union xfs_btree_key\t*mask,\n\tenum xbtree_recpacking\t\t*outcome)\n{\n\tstruct xfs_btree_has_records\tinfo = {\n\t\t.outcome\t\t= XBTREE_RECPACKING_EMPTY,\n\t\t.key_mask\t\t= mask,\n\t};\n\tint\t\t\t\terror;\n\n\t \n\tif (!cur->bc_ops->keys_contiguous) {\n\t\tASSERT(0);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\txfs_btree_key_from_irec(cur, &info.start_key, low);\n\txfs_btree_key_from_irec(cur, &info.end_key, high);\n\n\terror = xfs_btree_query_range(cur, low, high,\n\t\t\txfs_btree_has_records_helper, &info);\n\tif (error == -ECANCELED)\n\t\tgoto out;\n\tif (error)\n\t\treturn error;\n\n\tif (info.outcome == XBTREE_RECPACKING_EMPTY)\n\t\tgoto out;\n\n\t \n\tif (xfs_btree_masked_keycmp_ge(cur, &info.high_key, &info.end_key,\n\t\t\t\tmask))\n\t\tinfo.outcome = XBTREE_RECPACKING_FULL;\n\nout:\n\t*outcome = info.outcome;\n\treturn 0;\n}\n\n \nbool\nxfs_btree_has_more_records(\n\tstruct xfs_btree_cur\t*cur)\n{\n\tstruct xfs_btree_block\t*block;\n\tstruct xfs_buf\t\t*bp;\n\n\tblock = xfs_btree_get_block(cur, 0, &bp);\n\n\t \n\tif (cur->bc_levels[0].ptr < xfs_btree_get_numrecs(block))\n\t\treturn true;\n\n\t \n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\treturn block->bb_u.l.bb_rightsib != cpu_to_be64(NULLFSBLOCK);\n\telse\n\t\treturn block->bb_u.s.bb_rightsib != cpu_to_be32(NULLAGBLOCK);\n}\n\n \nint __init\nxfs_btree_init_cur_caches(void)\n{\n\tint\t\terror;\n\n\terror = xfs_allocbt_init_cur_cache();\n\tif (error)\n\t\treturn error;\n\terror = xfs_inobt_init_cur_cache();\n\tif (error)\n\t\tgoto err;\n\terror = xfs_bmbt_init_cur_cache();\n\tif (error)\n\t\tgoto err;\n\terror = xfs_rmapbt_init_cur_cache();\n\tif (error)\n\t\tgoto err;\n\terror = xfs_refcountbt_init_cur_cache();\n\tif (error)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\txfs_btree_destroy_cur_caches();\n\treturn error;\n}\n\n \nvoid\nxfs_btree_destroy_cur_caches(void)\n{\n\txfs_allocbt_destroy_cur_cache();\n\txfs_inobt_destroy_cur_cache();\n\txfs_bmbt_destroy_cur_cache();\n\txfs_rmapbt_destroy_cur_cache();\n\txfs_refcountbt_destroy_cur_cache();\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}