{
  "module_name": "xfs_btree_staging.c",
  "hash_id": "4ce39f612e65a74a1b83ddb659ee4b4ef107d5be7c0cda8a2402b4438c189e6d",
  "original_prompt": "Ingested from linux-6.6.14/fs/xfs/libxfs/xfs_btree_staging.c",
  "human_readable_source": "\n \n#include \"xfs.h\"\n#include \"xfs_fs.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_format.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_bit.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_inode.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_btree.h\"\n#include \"xfs_trace.h\"\n#include \"xfs_btree_staging.h\"\n\n \n\n \nSTATIC struct xfs_btree_cur *\nxfs_btree_fakeroot_dup_cursor(\n\tstruct xfs_btree_cur\t*cur)\n{\n\tASSERT(0);\n\treturn NULL;\n}\n\n \nSTATIC int\nxfs_btree_fakeroot_alloc_block(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*start_bno,\n\tunion xfs_btree_ptr\t\t*new_bno,\n\tint\t\t\t\t*stat)\n{\n\tASSERT(0);\n\treturn -EFSCORRUPTED;\n}\n\n \nSTATIC int\nxfs_btree_fakeroot_free_block(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp)\n{\n\tASSERT(0);\n\treturn -EFSCORRUPTED;\n}\n\n \nSTATIC void\nxfs_btree_fakeroot_init_ptr_from_cur(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_ptr\t*ptr)\n{\n\tstruct xbtree_afakeroot\t*afake;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\n\tafake = cur->bc_ag.afake;\n\tptr->s = cpu_to_be32(afake->af_root);\n}\n\n \n\n \nSTATIC void\nxfs_btree_afakeroot_set_root(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr,\n\tint\t\t\t\tinc)\n{\n\tstruct xbtree_afakeroot\t*afake = cur->bc_ag.afake;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\tafake->af_root = be32_to_cpu(ptr->s);\n\tafake->af_levels += inc;\n}\n\n \nvoid\nxfs_btree_stage_afakeroot(\n\tstruct xfs_btree_cur\t\t*cur,\n\tstruct xbtree_afakeroot\t\t*afake)\n{\n\tstruct xfs_btree_ops\t\t*nops;\n\n\tASSERT(!(cur->bc_flags & XFS_BTREE_STAGING));\n\tASSERT(!(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE));\n\tASSERT(cur->bc_tp == NULL);\n\n\tnops = kmem_alloc(sizeof(struct xfs_btree_ops), KM_NOFS);\n\tmemcpy(nops, cur->bc_ops, sizeof(struct xfs_btree_ops));\n\tnops->alloc_block = xfs_btree_fakeroot_alloc_block;\n\tnops->free_block = xfs_btree_fakeroot_free_block;\n\tnops->init_ptr_from_cur = xfs_btree_fakeroot_init_ptr_from_cur;\n\tnops->set_root = xfs_btree_afakeroot_set_root;\n\tnops->dup_cursor = xfs_btree_fakeroot_dup_cursor;\n\n\tcur->bc_ag.afake = afake;\n\tcur->bc_nlevels = afake->af_levels;\n\tcur->bc_ops = nops;\n\tcur->bc_flags |= XFS_BTREE_STAGING;\n}\n\n \nvoid\nxfs_btree_commit_afakeroot(\n\tstruct xfs_btree_cur\t\t*cur,\n\tstruct xfs_trans\t\t*tp,\n\tstruct xfs_buf\t\t\t*agbp,\n\tconst struct xfs_btree_ops\t*ops)\n{\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\tASSERT(cur->bc_tp == NULL);\n\n\ttrace_xfs_btree_commit_afakeroot(cur);\n\n\tkmem_free((void *)cur->bc_ops);\n\tcur->bc_ag.agbp = agbp;\n\tcur->bc_ops = ops;\n\tcur->bc_flags &= ~XFS_BTREE_STAGING;\n\tcur->bc_tp = tp;\n}\n\n \n\n \nvoid\nxfs_btree_stage_ifakeroot(\n\tstruct xfs_btree_cur\t\t*cur,\n\tstruct xbtree_ifakeroot\t\t*ifake,\n\tstruct xfs_btree_ops\t\t**new_ops)\n{\n\tstruct xfs_btree_ops\t\t*nops;\n\n\tASSERT(!(cur->bc_flags & XFS_BTREE_STAGING));\n\tASSERT(cur->bc_flags & XFS_BTREE_ROOT_IN_INODE);\n\tASSERT(cur->bc_tp == NULL);\n\n\tnops = kmem_alloc(sizeof(struct xfs_btree_ops), KM_NOFS);\n\tmemcpy(nops, cur->bc_ops, sizeof(struct xfs_btree_ops));\n\tnops->alloc_block = xfs_btree_fakeroot_alloc_block;\n\tnops->free_block = xfs_btree_fakeroot_free_block;\n\tnops->init_ptr_from_cur = xfs_btree_fakeroot_init_ptr_from_cur;\n\tnops->dup_cursor = xfs_btree_fakeroot_dup_cursor;\n\n\tcur->bc_ino.ifake = ifake;\n\tcur->bc_nlevels = ifake->if_levels;\n\tcur->bc_ops = nops;\n\tcur->bc_flags |= XFS_BTREE_STAGING;\n\n\tif (new_ops)\n\t\t*new_ops = nops;\n}\n\n \nvoid\nxfs_btree_commit_ifakeroot(\n\tstruct xfs_btree_cur\t\t*cur,\n\tstruct xfs_trans\t\t*tp,\n\tint\t\t\t\twhichfork,\n\tconst struct xfs_btree_ops\t*ops)\n{\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\tASSERT(cur->bc_tp == NULL);\n\n\ttrace_xfs_btree_commit_ifakeroot(cur);\n\n\tkmem_free((void *)cur->bc_ops);\n\tcur->bc_ino.ifake = NULL;\n\tcur->bc_ino.whichfork = whichfork;\n\tcur->bc_ops = ops;\n\tcur->bc_flags &= ~XFS_BTREE_STAGING;\n\tcur->bc_tp = tp;\n}\n\n \n\n \nstatic void\nxfs_btree_bload_drop_buf(\n\tstruct list_head\t*buffers_list,\n\tstruct xfs_buf\t\t**bpp)\n{\n\tif (*bpp == NULL)\n\t\treturn;\n\n\tif (!xfs_buf_delwri_queue(*bpp, buffers_list))\n\t\tASSERT(0);\n\n\txfs_buf_relse(*bpp);\n\t*bpp = NULL;\n}\n\n \nSTATIC int\nxfs_btree_bload_prep_block(\n\tstruct xfs_btree_cur\t\t*cur,\n\tstruct xfs_btree_bload\t\t*bbl,\n\tstruct list_head\t\t*buffers_list,\n\tunsigned int\t\t\tlevel,\n\tunsigned int\t\t\tnr_this_block,\n\tunion xfs_btree_ptr\t\t*ptrp,  \n\tstruct xfs_buf\t\t\t**bpp,  \n\tstruct xfs_btree_block\t\t**blockp,  \n\tvoid\t\t\t\t*priv)\n{\n\tunion xfs_btree_ptr\t\tnew_ptr;\n\tstruct xfs_buf\t\t\t*new_bp;\n\tstruct xfs_btree_block\t\t*new_block;\n\tint\t\t\t\tret;\n\n\tif ((cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) &&\n\t    level == cur->bc_nlevels - 1) {\n\t\tstruct xfs_ifork\t*ifp = xfs_btree_ifork_ptr(cur);\n\t\tsize_t\t\t\tnew_size;\n\n\t\tASSERT(*bpp == NULL);\n\n\t\t \n\t\tnew_size = bbl->iroot_size(cur, nr_this_block, priv);\n\t\tifp->if_broot = kmem_zalloc(new_size, 0);\n\t\tifp->if_broot_bytes = (int)new_size;\n\n\t\t \n\t\txfs_btree_init_block_int(cur->bc_mp, ifp->if_broot,\n\t\t\t\tXFS_BUF_DADDR_NULL, cur->bc_btnum, level,\n\t\t\t\tnr_this_block, cur->bc_ino.ip->i_ino,\n\t\t\t\tcur->bc_flags);\n\n\t\t*bpp = NULL;\n\t\t*blockp = ifp->if_broot;\n\t\txfs_btree_set_ptr_null(cur, ptrp);\n\t\treturn 0;\n\t}\n\n\t \n\txfs_btree_set_ptr_null(cur, &new_ptr);\n\tret = bbl->claim_block(cur, &new_ptr, priv);\n\tif (ret)\n\t\treturn ret;\n\n\tASSERT(!xfs_btree_ptr_is_null(cur, &new_ptr));\n\n\tret = xfs_btree_get_buf_block(cur, &new_ptr, &new_block, &new_bp);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (*blockp)\n\t\txfs_btree_set_sibling(cur, *blockp, &new_ptr, XFS_BB_RIGHTSIB);\n\txfs_btree_bload_drop_buf(buffers_list, bpp);\n\n\t \n\txfs_btree_init_block_cur(cur, new_bp, level, nr_this_block);\n\txfs_btree_set_sibling(cur, new_block, ptrp, XFS_BB_LEFTSIB);\n\n\t \n\t*bpp = new_bp;\n\t*blockp = new_block;\n\txfs_btree_copy_ptrs(cur, ptrp, &new_ptr, 1);\n\treturn 0;\n}\n\n \nSTATIC int\nxfs_btree_bload_leaf(\n\tstruct xfs_btree_cur\t\t*cur,\n\tunsigned int\t\t\trecs_this_block,\n\txfs_btree_bload_get_record_fn\tget_record,\n\tstruct xfs_btree_block\t\t*block,\n\tvoid\t\t\t\t*priv)\n{\n\tunsigned int\t\t\tj;\n\tint\t\t\t\tret;\n\n\t \n\tfor (j = 1; j <= recs_this_block; j++) {\n\t\tunion xfs_btree_rec\t*block_rec;\n\n\t\tret = get_record(cur, priv);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tblock_rec = xfs_btree_rec_addr(cur, j, block);\n\t\tcur->bc_ops->init_rec_from_cur(cur, block_rec);\n\t}\n\n\treturn 0;\n}\n\n \nSTATIC int\nxfs_btree_bload_node(\n\tstruct xfs_btree_cur\t*cur,\n\tunsigned int\t\trecs_this_block,\n\tunion xfs_btree_ptr\t*child_ptr,\n\tstruct xfs_btree_block\t*block)\n{\n\tunsigned int\t\tj;\n\tint\t\t\tret;\n\n\t \n\tfor (j = 1; j <= recs_this_block; j++) {\n\t\tunion xfs_btree_key\tchild_key;\n\t\tunion xfs_btree_ptr\t*block_ptr;\n\t\tunion xfs_btree_key\t*block_key;\n\t\tstruct xfs_btree_block\t*child_block;\n\t\tstruct xfs_buf\t\t*child_bp;\n\n\t\tASSERT(!xfs_btree_ptr_is_null(cur, child_ptr));\n\n\t\tret = xfs_btree_get_buf_block(cur, child_ptr, &child_block,\n\t\t\t\t&child_bp);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tblock_ptr = xfs_btree_ptr_addr(cur, j, block);\n\t\txfs_btree_copy_ptrs(cur, block_ptr, child_ptr, 1);\n\n\t\tblock_key = xfs_btree_key_addr(cur, j, block);\n\t\txfs_btree_get_keys(cur, child_block, &child_key);\n\t\txfs_btree_copy_keys(cur, block_key, &child_key, 1);\n\n\t\txfs_btree_get_sibling(cur, child_block, child_ptr,\n\t\t\t\tXFS_BB_RIGHTSIB);\n\t\txfs_buf_relse(child_bp);\n\t}\n\n\treturn 0;\n}\n\n \nSTATIC unsigned int\nxfs_btree_bload_max_npb(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_bload\t*bbl,\n\tunsigned int\t\tlevel)\n{\n\tunsigned int\t\tret;\n\n\tif (level == cur->bc_nlevels - 1 && cur->bc_ops->get_dmaxrecs)\n\t\treturn cur->bc_ops->get_dmaxrecs(cur, level);\n\n\tret = cur->bc_ops->get_maxrecs(cur, level);\n\tif (level == 0)\n\t\tret -= bbl->leaf_slack;\n\telse\n\t\tret -= bbl->node_slack;\n\treturn ret;\n}\n\n \nSTATIC unsigned int\nxfs_btree_bload_desired_npb(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_bload\t*bbl,\n\tunsigned int\t\tlevel)\n{\n\tunsigned int\t\tnpb = xfs_btree_bload_max_npb(cur, bbl, level);\n\n\t \n\tif (level == cur->bc_nlevels - 1)\n\t\treturn max(1U, npb);\n\n\treturn max_t(unsigned int, cur->bc_ops->get_minrecs(cur, level), npb);\n}\n\n \nSTATIC void\nxfs_btree_bload_level_geometry(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_bload\t*bbl,\n\tunsigned int\t\tlevel,\n\tuint64_t\t\tnr_this_level,\n\tunsigned int\t\t*avg_per_block,\n\tuint64_t\t\t*blocks,\n\tuint64_t\t\t*blocks_with_extra)\n{\n\tuint64_t\t\tnpb;\n\tuint64_t\t\tdontcare;\n\tunsigned int\t\tdesired_npb;\n\tunsigned int\t\tmaxnr;\n\n\tmaxnr = cur->bc_ops->get_maxrecs(cur, level);\n\n\t \n\tdesired_npb = xfs_btree_bload_desired_npb(cur, bbl, level);\n\t*blocks = div64_u64_rem(nr_this_level, desired_npb, &dontcare);\n\t*blocks = max(1ULL, *blocks);\n\n\t \n\tnpb = div64_u64_rem(nr_this_level, *blocks, blocks_with_extra);\n\tif (npb > maxnr || (npb == maxnr && *blocks_with_extra > 0)) {\n\t\t(*blocks)++;\n\t\tnpb = div64_u64_rem(nr_this_level, *blocks, blocks_with_extra);\n\t}\n\n\t*avg_per_block = min_t(uint64_t, npb, nr_this_level);\n\n\ttrace_xfs_btree_bload_level_geometry(cur, level, nr_this_level,\n\t\t\t*avg_per_block, desired_npb, *blocks,\n\t\t\t*blocks_with_extra);\n}\n\n \nstatic void\nxfs_btree_bload_ensure_slack(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\t*slack,\n\tint\t\t\tlevel)\n{\n\tint\t\t\tmaxr;\n\tint\t\t\tminr;\n\n\tmaxr = cur->bc_ops->get_maxrecs(cur, level);\n\tminr = cur->bc_ops->get_minrecs(cur, level);\n\n\t \n\tif (*slack < 0)\n\t\t*slack = maxr - ((maxr + minr) >> 1);\n\n\t*slack = min(*slack, maxr - minr);\n}\n\n \nint\nxfs_btree_bload_compute_geometry(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_btree_bload\t*bbl,\n\tuint64_t\t\tnr_records)\n{\n\tuint64_t\t\tnr_blocks = 0;\n\tuint64_t\t\tnr_this_level;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\n\t \n\tcur->bc_nlevels = cur->bc_maxlevels - 1;\n\txfs_btree_bload_ensure_slack(cur, &bbl->leaf_slack, 0);\n\txfs_btree_bload_ensure_slack(cur, &bbl->node_slack, 1);\n\n\tbbl->nr_records = nr_this_level = nr_records;\n\tfor (cur->bc_nlevels = 1; cur->bc_nlevels <= cur->bc_maxlevels;) {\n\t\tuint64_t\tlevel_blocks;\n\t\tuint64_t\tdontcare64;\n\t\tunsigned int\tlevel = cur->bc_nlevels - 1;\n\t\tunsigned int\tavg_per_block;\n\n\t\txfs_btree_bload_level_geometry(cur, bbl, level, nr_this_level,\n\t\t\t\t&avg_per_block, &level_blocks, &dontcare64);\n\n\t\tif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) {\n\t\t\t \n\t\t\tif (level != 0 && nr_this_level <= avg_per_block) {\n\t\t\t\tnr_blocks++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tcur->bc_nlevels++;\n\t\t\tASSERT(cur->bc_nlevels <= cur->bc_maxlevels);\n\t\t\txfs_btree_bload_level_geometry(cur, bbl, level,\n\t\t\t\t\tnr_this_level, &avg_per_block,\n\t\t\t\t\t&level_blocks, &dontcare64);\n\t\t} else {\n\t\t\t \n\t\t\tif (nr_this_level <= avg_per_block) {\n\t\t\t\tnr_blocks++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tcur->bc_nlevels++;\n\t\t\tASSERT(cur->bc_nlevels <= cur->bc_maxlevels);\n\t\t}\n\n\t\tnr_blocks += level_blocks;\n\t\tnr_this_level = level_blocks;\n\t}\n\n\tif (cur->bc_nlevels > cur->bc_maxlevels)\n\t\treturn -EOVERFLOW;\n\n\tbbl->btree_height = cur->bc_nlevels;\n\tif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE)\n\t\tbbl->nr_blocks = nr_blocks - 1;\n\telse\n\t\tbbl->nr_blocks = nr_blocks;\n\treturn 0;\n}\n\n \nint\nxfs_btree_bload(\n\tstruct xfs_btree_cur\t\t*cur,\n\tstruct xfs_btree_bload\t\t*bbl,\n\tvoid\t\t\t\t*priv)\n{\n\tstruct list_head\t\tbuffers_list;\n\tunion xfs_btree_ptr\t\tchild_ptr;\n\tunion xfs_btree_ptr\t\tptr;\n\tstruct xfs_buf\t\t\t*bp = NULL;\n\tstruct xfs_btree_block\t\t*block = NULL;\n\tuint64_t\t\t\tnr_this_level = bbl->nr_records;\n\tuint64_t\t\t\tblocks;\n\tuint64_t\t\t\ti;\n\tuint64_t\t\t\tblocks_with_extra;\n\tuint64_t\t\t\ttotal_blocks = 0;\n\tunsigned int\t\t\tavg_per_block;\n\tunsigned int\t\t\tlevel = 0;\n\tint\t\t\t\tret;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\n\tINIT_LIST_HEAD(&buffers_list);\n\tcur->bc_nlevels = bbl->btree_height;\n\txfs_btree_set_ptr_null(cur, &child_ptr);\n\txfs_btree_set_ptr_null(cur, &ptr);\n\n\txfs_btree_bload_level_geometry(cur, bbl, level, nr_this_level,\n\t\t\t&avg_per_block, &blocks, &blocks_with_extra);\n\n\t \n\tfor (i = 0; i < blocks; i++) {\n\t\tunsigned int\t\tnr_this_block = avg_per_block;\n\n\t\t \n\t\tif (i < blocks_with_extra)\n\t\t\tnr_this_block++;\n\n\t\tret = xfs_btree_bload_prep_block(cur, bbl, &buffers_list, level,\n\t\t\t\tnr_this_block, &ptr, &bp, &block, priv);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\ttrace_xfs_btree_bload_block(cur, level, i, blocks, &ptr,\n\t\t\t\tnr_this_block);\n\n\t\tret = xfs_btree_bload_leaf(cur, nr_this_block, bbl->get_record,\n\t\t\t\tblock, priv);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\t \n\t\tif (i == 0)\n\t\t\txfs_btree_copy_ptrs(cur, &child_ptr, &ptr, 1);\n\t}\n\ttotal_blocks += blocks;\n\txfs_btree_bload_drop_buf(&buffers_list, &bp);\n\n\t \n\tfor (level = 1; level < cur->bc_nlevels; level++) {\n\t\tunion xfs_btree_ptr\tfirst_ptr;\n\n\t\tnr_this_level = blocks;\n\t\tblock = NULL;\n\t\txfs_btree_set_ptr_null(cur, &ptr);\n\n\t\txfs_btree_bload_level_geometry(cur, bbl, level, nr_this_level,\n\t\t\t\t&avg_per_block, &blocks, &blocks_with_extra);\n\n\t\t \n\t\tfor (i = 0; i < blocks; i++) {\n\t\t\tunsigned int\tnr_this_block = avg_per_block;\n\n\t\t\tif (i < blocks_with_extra)\n\t\t\t\tnr_this_block++;\n\n\t\t\tret = xfs_btree_bload_prep_block(cur, bbl,\n\t\t\t\t\t&buffers_list, level, nr_this_block,\n\t\t\t\t\t&ptr, &bp, &block, priv);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\n\t\t\ttrace_xfs_btree_bload_block(cur, level, i, blocks,\n\t\t\t\t\t&ptr, nr_this_block);\n\n\t\t\tret = xfs_btree_bload_node(cur, nr_this_block,\n\t\t\t\t\t&child_ptr, block);\n\t\t\tif (ret)\n\t\t\t\tgoto out;\n\n\t\t\t \n\t\t\tif (i == 0)\n\t\t\t\txfs_btree_copy_ptrs(cur, &first_ptr, &ptr, 1);\n\t\t}\n\t\ttotal_blocks += blocks;\n\t\txfs_btree_bload_drop_buf(&buffers_list, &bp);\n\t\txfs_btree_copy_ptrs(cur, &child_ptr, &first_ptr, 1);\n\t}\n\n\t \n\tif (cur->bc_flags & XFS_BTREE_ROOT_IN_INODE) {\n\t\tASSERT(xfs_btree_ptr_is_null(cur, &ptr));\n\t\tcur->bc_ino.ifake->if_levels = cur->bc_nlevels;\n\t\tcur->bc_ino.ifake->if_blocks = total_blocks - 1;\n\t} else {\n\t\tcur->bc_ag.afake->af_root = be32_to_cpu(ptr.s);\n\t\tcur->bc_ag.afake->af_levels = cur->bc_nlevels;\n\t\tcur->bc_ag.afake->af_blocks = total_blocks;\n\t}\n\n\t \n\tret = xfs_buf_delwri_submit(&buffers_list);\n\tif (ret)\n\t\tgoto out;\n\tif (!list_empty(&buffers_list)) {\n\t\tASSERT(list_empty(&buffers_list));\n\t\tret = -EIO;\n\t}\n\nout:\n\txfs_buf_delwri_cancel(&buffers_list);\n\tif (bp)\n\t\txfs_buf_relse(bp);\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}