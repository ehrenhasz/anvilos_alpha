{
  "module_name": "xfs_btree.h",
  "hash_id": "4ee0bb712806886b415966210a55c83db6436a8013d35d1774cc571de9a8ae92",
  "original_prompt": "Ingested from linux-6.6.14/fs/xfs/libxfs/xfs_btree.h",
  "human_readable_source": " \n \n#ifndef __XFS_BTREE_H__\n#define\t__XFS_BTREE_H__\n\nstruct xfs_buf;\nstruct xfs_inode;\nstruct xfs_mount;\nstruct xfs_trans;\nstruct xfs_ifork;\nstruct xfs_perag;\n\n \nunion xfs_btree_ptr {\n\t__be32\t\t\ts;\t \n\t__be64\t\t\tl;\t \n};\n\n \nunion xfs_btree_key {\n\tstruct xfs_bmbt_key\t\tbmbt;\n\txfs_bmdr_key_t\t\t\tbmbr;\t \n\txfs_alloc_key_t\t\t\talloc;\n\tstruct xfs_inobt_key\t\tinobt;\n\tstruct xfs_rmap_key\t\trmap;\n\tstruct xfs_rmap_key\t\t__rmap_bigkey[2];\n\tstruct xfs_refcount_key\t\trefc;\n};\n\nunion xfs_btree_rec {\n\tstruct xfs_bmbt_rec\t\tbmbt;\n\txfs_bmdr_rec_t\t\t\tbmbr;\t \n\tstruct xfs_alloc_rec\t\talloc;\n\tstruct xfs_inobt_rec\t\tinobt;\n\tstruct xfs_rmap_rec\t\trmap;\n\tstruct xfs_refcount_rec\t\trefc;\n};\n\n \n#define\tXFS_LOOKUP_EQ\t((xfs_lookup_t)XFS_LOOKUP_EQi)\n#define\tXFS_LOOKUP_LE\t((xfs_lookup_t)XFS_LOOKUP_LEi)\n#define\tXFS_LOOKUP_GE\t((xfs_lookup_t)XFS_LOOKUP_GEi)\n\n#define\tXFS_BTNUM_BNO\t((xfs_btnum_t)XFS_BTNUM_BNOi)\n#define\tXFS_BTNUM_CNT\t((xfs_btnum_t)XFS_BTNUM_CNTi)\n#define\tXFS_BTNUM_BMAP\t((xfs_btnum_t)XFS_BTNUM_BMAPi)\n#define\tXFS_BTNUM_INO\t((xfs_btnum_t)XFS_BTNUM_INOi)\n#define\tXFS_BTNUM_FINO\t((xfs_btnum_t)XFS_BTNUM_FINOi)\n#define\tXFS_BTNUM_RMAP\t((xfs_btnum_t)XFS_BTNUM_RMAPi)\n#define\tXFS_BTNUM_REFC\t((xfs_btnum_t)XFS_BTNUM_REFCi)\n\nuint32_t xfs_btree_magic(int crc, xfs_btnum_t btnum);\n\n \n#define\tXFS_BB_MAGIC\t\t(1u << 0)\n#define\tXFS_BB_LEVEL\t\t(1u << 1)\n#define\tXFS_BB_NUMRECS\t\t(1u << 2)\n#define\tXFS_BB_LEFTSIB\t\t(1u << 3)\n#define\tXFS_BB_RIGHTSIB\t\t(1u << 4)\n#define\tXFS_BB_BLKNO\t\t(1u << 5)\n#define\tXFS_BB_LSN\t\t(1u << 6)\n#define\tXFS_BB_UUID\t\t(1u << 7)\n#define\tXFS_BB_OWNER\t\t(1u << 8)\n#define\tXFS_BB_NUM_BITS\t\t5\n#define\tXFS_BB_ALL_BITS\t\t((1u << XFS_BB_NUM_BITS) - 1)\n#define\tXFS_BB_NUM_BITS_CRC\t9\n#define\tXFS_BB_ALL_BITS_CRC\t((1u << XFS_BB_NUM_BITS_CRC) - 1)\n\n \n#define XFS_BTREE_STATS_INC(cur, stat)\t\\\n\tXFS_STATS_INC_OFF((cur)->bc_mp, (cur)->bc_statoff + __XBTS_ ## stat)\n#define XFS_BTREE_STATS_ADD(cur, stat, val)\t\\\n\tXFS_STATS_ADD_OFF((cur)->bc_mp, (cur)->bc_statoff + __XBTS_ ## stat, val)\n\nenum xbtree_key_contig {\n\tXBTREE_KEY_GAP = 0,\n\tXBTREE_KEY_CONTIGUOUS,\n\tXBTREE_KEY_OVERLAP,\n};\n\n \nstatic inline enum xbtree_key_contig xbtree_key_contig(uint64_t x, uint64_t y)\n{\n\tx++;\n\tif (x < y)\n\t\treturn XBTREE_KEY_GAP;\n\tif (x == y)\n\t\treturn XBTREE_KEY_CONTIGUOUS;\n\treturn XBTREE_KEY_OVERLAP;\n}\n\nstruct xfs_btree_ops {\n\t \n\tsize_t\tkey_len;\n\tsize_t\trec_len;\n\n\t \n\tstruct xfs_btree_cur *(*dup_cursor)(struct xfs_btree_cur *);\n\tvoid\t(*update_cursor)(struct xfs_btree_cur *src,\n\t\t\t\t struct xfs_btree_cur *dst);\n\n\t \n\tvoid\t(*set_root)(struct xfs_btree_cur *cur,\n\t\t\t    const union xfs_btree_ptr *nptr, int level_change);\n\n\t \n\tint\t(*alloc_block)(struct xfs_btree_cur *cur,\n\t\t\t       const union xfs_btree_ptr *start_bno,\n\t\t\t       union xfs_btree_ptr *new_bno,\n\t\t\t       int *stat);\n\tint\t(*free_block)(struct xfs_btree_cur *cur, struct xfs_buf *bp);\n\n\t \n\tvoid\t(*update_lastrec)(struct xfs_btree_cur *cur,\n\t\t\t\t  const struct xfs_btree_block *block,\n\t\t\t\t  const union xfs_btree_rec *rec,\n\t\t\t\t  int ptr, int reason);\n\n\t \n\tint\t(*get_minrecs)(struct xfs_btree_cur *cur, int level);\n\tint\t(*get_maxrecs)(struct xfs_btree_cur *cur, int level);\n\n\t \n\tint\t(*get_dmaxrecs)(struct xfs_btree_cur *cur, int level);\n\n\t \n\tvoid\t(*init_key_from_rec)(union xfs_btree_key *key,\n\t\t\t\t     const union xfs_btree_rec *rec);\n\tvoid\t(*init_rec_from_cur)(struct xfs_btree_cur *cur,\n\t\t\t\t     union xfs_btree_rec *rec);\n\tvoid\t(*init_ptr_from_cur)(struct xfs_btree_cur *cur,\n\t\t\t\t     union xfs_btree_ptr *ptr);\n\tvoid\t(*init_high_key_from_rec)(union xfs_btree_key *key,\n\t\t\t\t\t  const union xfs_btree_rec *rec);\n\n\t \n\tint64_t (*key_diff)(struct xfs_btree_cur *cur,\n\t\t\t    const union xfs_btree_key *key);\n\n\t \n\tint64_t (*diff_two_keys)(struct xfs_btree_cur *cur,\n\t\t\t\t const union xfs_btree_key *key1,\n\t\t\t\t const union xfs_btree_key *key2,\n\t\t\t\t const union xfs_btree_key *mask);\n\n\tconst struct xfs_buf_ops\t*buf_ops;\n\n\t \n\tint\t(*keys_inorder)(struct xfs_btree_cur *cur,\n\t\t\t\tconst union xfs_btree_key *k1,\n\t\t\t\tconst union xfs_btree_key *k2);\n\n\t \n\tint\t(*recs_inorder)(struct xfs_btree_cur *cur,\n\t\t\t\tconst union xfs_btree_rec *r1,\n\t\t\t\tconst union xfs_btree_rec *r2);\n\n\t \n\tenum xbtree_key_contig (*keys_contiguous)(struct xfs_btree_cur *cur,\n\t\t\t       const union xfs_btree_key *key1,\n\t\t\t       const union xfs_btree_key *key2,\n\t\t\t       const union xfs_btree_key *mask);\n};\n\n \n#define LASTREC_UPDATE\t0\n#define LASTREC_INSREC\t1\n#define LASTREC_DELREC\t2\n\n\nunion xfs_btree_irec {\n\tstruct xfs_alloc_rec_incore\ta;\n\tstruct xfs_bmbt_irec\t\tb;\n\tstruct xfs_inobt_rec_incore\ti;\n\tstruct xfs_rmap_irec\t\tr;\n\tstruct xfs_refcount_irec\trc;\n};\n\n \nstruct xfs_btree_cur_ag {\n\tstruct xfs_perag\t\t*pag;\n\tunion {\n\t\tstruct xfs_buf\t\t*agbp;\n\t\tstruct xbtree_afakeroot\t*afake;\t \n\t};\n\tunion {\n\t\tstruct {\n\t\t\tunsigned int\tnr_ops;\t \n\t\t\tunsigned int\tshape_changes;\t \n\t\t} refc;\n\t\tstruct {\n\t\t\tbool\t\tactive;\t \n\t\t} abt;\n\t};\n};\n\n \nstruct xfs_btree_cur_ino {\n\tstruct xfs_inode\t\t*ip;\n\tstruct xbtree_ifakeroot\t\t*ifake;\t \n\tint\t\t\t\tallocated;\n\tshort\t\t\t\tforksize;\n\tchar\t\t\t\twhichfork;\n\tchar\t\t\t\tflags;\n \n#define\tXFS_BTCUR_BMBT_WASDEL\t\t(1 << 0)\n\n \n#define\tXFS_BTCUR_BMBT_INVALID_OWNER\t(1 << 1)\n};\n\nstruct xfs_btree_level {\n\t \n\tstruct xfs_buf\t\t*bp;\n\n\t \n\tuint16_t\t\tptr;\n\n\t \n#define XFS_BTCUR_LEFTRA\t(1 << 0)  \n#define XFS_BTCUR_RIGHTRA\t(1 << 1)  \n\tuint16_t\t\tra;\n};\n\n \nstruct xfs_btree_cur\n{\n\tstruct xfs_trans\t*bc_tp;\t \n\tstruct xfs_mount\t*bc_mp;\t \n\tconst struct xfs_btree_ops *bc_ops;\n\tstruct kmem_cache\t*bc_cache;  \n\tunsigned int\t\tbc_flags;  \n\txfs_btnum_t\t\tbc_btnum;  \n\tunion xfs_btree_irec\tbc_rec;\t \n\tuint8_t\t\t\tbc_nlevels;  \n\tuint8_t\t\t\tbc_maxlevels;  \n\tint\t\t\tbc_statoff;  \n\n\t \n\tunion {\n\t\tstruct xfs_btree_cur_ag\tbc_ag;\n\t\tstruct xfs_btree_cur_ino bc_ino;\n\t};\n\n\t \n\tstruct xfs_btree_level\tbc_levels[];\n};\n\n \nstatic inline size_t\nxfs_btree_cur_sizeof(unsigned int nlevels)\n{\n\treturn struct_size_t(struct xfs_btree_cur, bc_levels, nlevels);\n}\n\n \n#define XFS_BTREE_LONG_PTRS\t\t(1<<0)\t \n#define XFS_BTREE_ROOT_IN_INODE\t\t(1<<1)\t \n#define XFS_BTREE_LASTREC_UPDATE\t(1<<2)\t \n#define XFS_BTREE_CRC_BLOCKS\t\t(1<<3)\t \n#define XFS_BTREE_OVERLAPPING\t\t(1<<4)\t \n \n#define XFS_BTREE_STAGING\t\t(1<<5)\n\n#define\tXFS_BTREE_NOERROR\t0\n#define\tXFS_BTREE_ERROR\t\t1\n\n \n#define\tXFS_BUF_TO_BLOCK(bp)\t((struct xfs_btree_block *)((bp)->b_addr))\n\n \nxfs_failaddr_t __xfs_btree_check_lblock(struct xfs_btree_cur *cur,\n\t\tstruct xfs_btree_block *block, int level, struct xfs_buf *bp);\nxfs_failaddr_t __xfs_btree_check_sblock(struct xfs_btree_cur *cur,\n\t\tstruct xfs_btree_block *block, int level, struct xfs_buf *bp);\n\n \nint\nxfs_btree_check_block(\n\tstruct xfs_btree_cur\t*cur,\t \n\tstruct xfs_btree_block\t*block,\t \n\tint\t\t\tlevel,\t \n\tstruct xfs_buf\t\t*bp);\t \n\n \nbool\t\t\t\t\t \nxfs_btree_check_lptr(\n\tstruct xfs_btree_cur\t*cur,\t \n\txfs_fsblock_t\t\tfsbno,\t \n\tint\t\t\tlevel);\t \n\n \nbool\t\t\t\t\t \nxfs_btree_check_sptr(\n\tstruct xfs_btree_cur\t*cur,\t \n\txfs_agblock_t\t\tagbno,\t \n\tint\t\t\tlevel);\t \n\n \nvoid\nxfs_btree_del_cursor(\n\tstruct xfs_btree_cur\t*cur,\t \n\tint\t\t\terror);\t \n\n \nint\t\t\t\t\t \nxfs_btree_dup_cursor(\n\tstruct xfs_btree_cur\t\t*cur,\t \n\tstruct xfs_btree_cur\t\t**ncur); \n\n \nvoid\nxfs_btree_offsets(\n\tuint32_t\t\tfields,\t \n\tconst short\t\t*offsets, \n\tint\t\t\tnbits,\t \n\tint\t\t\t*first,\t \n\tint\t\t\t*last);\t \n\n \nint\t\t\t\t\t \nxfs_btree_read_bufl(\n\tstruct xfs_mount\t*mp,\t \n\tstruct xfs_trans\t*tp,\t \n\txfs_fsblock_t\t\tfsbno,\t \n\tstruct xfs_buf\t\t**bpp,\t \n\tint\t\t\trefval,\t \n\tconst struct xfs_buf_ops *ops);\n\n \nvoid\t\t\t\t\t \nxfs_btree_reada_bufl(\n\tstruct xfs_mount\t*mp,\t \n\txfs_fsblock_t\t\tfsbno,\t \n\txfs_extlen_t\t\tcount,\t \n\tconst struct xfs_buf_ops *ops);\n\n \nvoid\t\t\t\t\t \nxfs_btree_reada_bufs(\n\tstruct xfs_mount\t*mp,\t \n\txfs_agnumber_t\t\tagno,\t \n\txfs_agblock_t\t\tagbno,\t \n\txfs_extlen_t\t\tcount,\t \n\tconst struct xfs_buf_ops *ops);\n\n \nvoid\nxfs_btree_init_block(\n\tstruct xfs_mount *mp,\n\tstruct xfs_buf\t*bp,\n\txfs_btnum_t\tbtnum,\n\t__u16\t\tlevel,\n\t__u16\t\tnumrecs,\n\t__u64\t\towner);\n\nvoid\nxfs_btree_init_block_int(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_btree_block\t*buf,\n\txfs_daddr_t\t\tblkno,\n\txfs_btnum_t\t\tbtnum,\n\t__u16\t\t\tlevel,\n\t__u16\t\t\tnumrecs,\n\t__u64\t\t\towner,\n\tunsigned int\t\tflags);\n\n \nint xfs_btree_increment(struct xfs_btree_cur *, int, int *);\nint xfs_btree_decrement(struct xfs_btree_cur *, int, int *);\nint xfs_btree_lookup(struct xfs_btree_cur *, xfs_lookup_t, int *);\nint xfs_btree_update(struct xfs_btree_cur *, union xfs_btree_rec *);\nint xfs_btree_new_iroot(struct xfs_btree_cur *, int *, int *);\nint xfs_btree_insert(struct xfs_btree_cur *, int *);\nint xfs_btree_delete(struct xfs_btree_cur *, int *);\nint xfs_btree_get_rec(struct xfs_btree_cur *, union xfs_btree_rec **, int *);\nint xfs_btree_change_owner(struct xfs_btree_cur *cur, uint64_t new_owner,\n\t\t\t   struct list_head *buffer_list);\n\n \nvoid xfs_btree_lblock_calc_crc(struct xfs_buf *);\nbool xfs_btree_lblock_verify_crc(struct xfs_buf *);\nvoid xfs_btree_sblock_calc_crc(struct xfs_buf *);\nbool xfs_btree_sblock_verify_crc(struct xfs_buf *);\n\n \nvoid xfs_btree_log_block(struct xfs_btree_cur *, struct xfs_buf *, uint32_t);\nvoid xfs_btree_log_recs(struct xfs_btree_cur *, struct xfs_buf *, int, int);\n\n \nstatic inline int xfs_btree_get_numrecs(const struct xfs_btree_block *block)\n{\n\treturn be16_to_cpu(block->bb_numrecs);\n}\n\nstatic inline void xfs_btree_set_numrecs(struct xfs_btree_block *block,\n\t\tuint16_t numrecs)\n{\n\tblock->bb_numrecs = cpu_to_be16(numrecs);\n}\n\nstatic inline int xfs_btree_get_level(const struct xfs_btree_block *block)\n{\n\treturn be16_to_cpu(block->bb_level);\n}\n\n\n \n#define\tXFS_EXTLEN_MIN(a,b)\tmin_t(xfs_extlen_t, (a), (b))\n#define\tXFS_EXTLEN_MAX(a,b)\tmax_t(xfs_extlen_t, (a), (b))\n#define\tXFS_AGBLOCK_MIN(a,b)\tmin_t(xfs_agblock_t, (a), (b))\n#define\tXFS_AGBLOCK_MAX(a,b)\tmax_t(xfs_agblock_t, (a), (b))\n#define\tXFS_FILEOFF_MIN(a,b)\tmin_t(xfs_fileoff_t, (a), (b))\n#define\tXFS_FILEOFF_MAX(a,b)\tmax_t(xfs_fileoff_t, (a), (b))\n#define\tXFS_FILBLKS_MIN(a,b)\tmin_t(xfs_filblks_t, (a), (b))\n#define\tXFS_FILBLKS_MAX(a,b)\tmax_t(xfs_filblks_t, (a), (b))\n\nxfs_failaddr_t xfs_btree_sblock_v5hdr_verify(struct xfs_buf *bp);\nxfs_failaddr_t xfs_btree_sblock_verify(struct xfs_buf *bp,\n\t\tunsigned int max_recs);\nxfs_failaddr_t xfs_btree_lblock_v5hdr_verify(struct xfs_buf *bp,\n\t\tuint64_t owner);\nxfs_failaddr_t xfs_btree_lblock_verify(struct xfs_buf *bp,\n\t\tunsigned int max_recs);\n\nunsigned int xfs_btree_compute_maxlevels(const unsigned int *limits,\n\t\tunsigned long long records);\nunsigned long long xfs_btree_calc_size(const unsigned int *limits,\n\t\tunsigned long long records);\nunsigned int xfs_btree_space_to_height(const unsigned int *limits,\n\t\tunsigned long long blocks);\n\n \ntypedef int (*xfs_btree_query_range_fn)(struct xfs_btree_cur *cur,\n\t\tconst union xfs_btree_rec *rec, void *priv);\n\nint xfs_btree_query_range(struct xfs_btree_cur *cur,\n\t\tconst union xfs_btree_irec *low_rec,\n\t\tconst union xfs_btree_irec *high_rec,\n\t\txfs_btree_query_range_fn fn, void *priv);\nint xfs_btree_query_all(struct xfs_btree_cur *cur, xfs_btree_query_range_fn fn,\n\t\tvoid *priv);\n\ntypedef int (*xfs_btree_visit_blocks_fn)(struct xfs_btree_cur *cur, int level,\n\t\tvoid *data);\n \n#define XFS_BTREE_VISIT_RECORDS\t\t(1 << 0)\n \n#define XFS_BTREE_VISIT_LEAVES\t\t(1 << 1)\n \n#define XFS_BTREE_VISIT_ALL\t\t(XFS_BTREE_VISIT_RECORDS | \\\n\t\t\t\t\t XFS_BTREE_VISIT_LEAVES)\nint xfs_btree_visit_blocks(struct xfs_btree_cur *cur,\n\t\txfs_btree_visit_blocks_fn fn, unsigned int flags, void *data);\n\nint xfs_btree_count_blocks(struct xfs_btree_cur *cur, xfs_extlen_t *blocks);\n\nunion xfs_btree_rec *xfs_btree_rec_addr(struct xfs_btree_cur *cur, int n,\n\t\tstruct xfs_btree_block *block);\nunion xfs_btree_key *xfs_btree_key_addr(struct xfs_btree_cur *cur, int n,\n\t\tstruct xfs_btree_block *block);\nunion xfs_btree_key *xfs_btree_high_key_addr(struct xfs_btree_cur *cur, int n,\n\t\tstruct xfs_btree_block *block);\nunion xfs_btree_ptr *xfs_btree_ptr_addr(struct xfs_btree_cur *cur, int n,\n\t\tstruct xfs_btree_block *block);\nint xfs_btree_lookup_get_block(struct xfs_btree_cur *cur, int level,\n\t\tconst union xfs_btree_ptr *pp, struct xfs_btree_block **blkp);\nstruct xfs_btree_block *xfs_btree_get_block(struct xfs_btree_cur *cur,\n\t\tint level, struct xfs_buf **bpp);\nbool xfs_btree_ptr_is_null(struct xfs_btree_cur *cur,\n\t\tconst union xfs_btree_ptr *ptr);\nint64_t xfs_btree_diff_two_ptrs(struct xfs_btree_cur *cur,\n\t\t\t\tconst union xfs_btree_ptr *a,\n\t\t\t\tconst union xfs_btree_ptr *b);\nvoid xfs_btree_get_sibling(struct xfs_btree_cur *cur,\n\t\t\t   struct xfs_btree_block *block,\n\t\t\t   union xfs_btree_ptr *ptr, int lr);\nvoid xfs_btree_get_keys(struct xfs_btree_cur *cur,\n\t\tstruct xfs_btree_block *block, union xfs_btree_key *key);\nunion xfs_btree_key *xfs_btree_high_key_from_key(struct xfs_btree_cur *cur,\n\t\tunion xfs_btree_key *key);\ntypedef bool (*xfs_btree_key_gap_fn)(struct xfs_btree_cur *cur,\n\t\tconst union xfs_btree_key *key1,\n\t\tconst union xfs_btree_key *key2);\n\nint xfs_btree_has_records(struct xfs_btree_cur *cur,\n\t\tconst union xfs_btree_irec *low,\n\t\tconst union xfs_btree_irec *high,\n\t\tconst union xfs_btree_key *mask,\n\t\tenum xbtree_recpacking *outcome);\n\nbool xfs_btree_has_more_records(struct xfs_btree_cur *cur);\nstruct xfs_ifork *xfs_btree_ifork_ptr(struct xfs_btree_cur *cur);\n\n \nstatic inline bool\nxfs_btree_keycmp_lt(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2)\n{\n\treturn cur->bc_ops->diff_two_keys(cur, key1, key2, NULL) < 0;\n}\n\nstatic inline bool\nxfs_btree_keycmp_gt(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2)\n{\n\treturn cur->bc_ops->diff_two_keys(cur, key1, key2, NULL) > 0;\n}\n\nstatic inline bool\nxfs_btree_keycmp_eq(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2)\n{\n\treturn cur->bc_ops->diff_two_keys(cur, key1, key2, NULL) == 0;\n}\n\nstatic inline bool\nxfs_btree_keycmp_le(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2)\n{\n\treturn !xfs_btree_keycmp_gt(cur, key1, key2);\n}\n\nstatic inline bool\nxfs_btree_keycmp_ge(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2)\n{\n\treturn !xfs_btree_keycmp_lt(cur, key1, key2);\n}\n\nstatic inline bool\nxfs_btree_keycmp_ne(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2)\n{\n\treturn !xfs_btree_keycmp_eq(cur, key1, key2);\n}\n\n \nstatic inline bool\nxfs_btree_masked_keycmp_lt(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2,\n\tconst union xfs_btree_key\t*mask)\n{\n\treturn cur->bc_ops->diff_two_keys(cur, key1, key2, mask) < 0;\n}\n\nstatic inline bool\nxfs_btree_masked_keycmp_gt(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2,\n\tconst union xfs_btree_key\t*mask)\n{\n\treturn cur->bc_ops->diff_two_keys(cur, key1, key2, mask) > 0;\n}\n\nstatic inline bool\nxfs_btree_masked_keycmp_ge(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2,\n\tconst union xfs_btree_key\t*mask)\n{\n\treturn !xfs_btree_masked_keycmp_lt(cur, key1, key2, mask);\n}\n\n \nstatic inline bool\nxfs_btree_islastblock(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel)\n{\n\tstruct xfs_btree_block\t*block;\n\tstruct xfs_buf\t\t*bp;\n\n\tblock = xfs_btree_get_block(cur, level, &bp);\n\n\tif (cur->bc_flags & XFS_BTREE_LONG_PTRS)\n\t\treturn block->bb_u.l.bb_rightsib == cpu_to_be64(NULLFSBLOCK);\n\treturn block->bb_u.s.bb_rightsib == cpu_to_be32(NULLAGBLOCK);\n}\n\nvoid xfs_btree_set_ptr_null(struct xfs_btree_cur *cur,\n\t\tunion xfs_btree_ptr *ptr);\nint xfs_btree_get_buf_block(struct xfs_btree_cur *cur,\n\t\tconst union xfs_btree_ptr *ptr, struct xfs_btree_block **block,\n\t\tstruct xfs_buf **bpp);\nvoid xfs_btree_set_sibling(struct xfs_btree_cur *cur,\n\t\tstruct xfs_btree_block *block, const union xfs_btree_ptr *ptr,\n\t\tint lr);\nvoid xfs_btree_init_block_cur(struct xfs_btree_cur *cur,\n\t\tstruct xfs_buf *bp, int level, int numrecs);\nvoid xfs_btree_copy_ptrs(struct xfs_btree_cur *cur,\n\t\tunion xfs_btree_ptr *dst_ptr,\n\t\tconst union xfs_btree_ptr *src_ptr, int numptrs);\nvoid xfs_btree_copy_keys(struct xfs_btree_cur *cur,\n\t\tunion xfs_btree_key *dst_key,\n\t\tconst union xfs_btree_key *src_key, int numkeys);\n\nstatic inline struct xfs_btree_cur *\nxfs_btree_alloc_cursor(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\txfs_btnum_t\t\tbtnum,\n\tuint8_t\t\t\tmaxlevels,\n\tstruct kmem_cache\t*cache)\n{\n\tstruct xfs_btree_cur\t*cur;\n\n\tcur = kmem_cache_zalloc(cache, GFP_NOFS | __GFP_NOFAIL);\n\tcur->bc_tp = tp;\n\tcur->bc_mp = mp;\n\tcur->bc_btnum = btnum;\n\tcur->bc_maxlevels = maxlevels;\n\tcur->bc_cache = cache;\n\n\treturn cur;\n}\n\nint __init xfs_btree_init_cur_caches(void);\nvoid xfs_btree_destroy_cur_caches(void);\n\n#endif\t \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}