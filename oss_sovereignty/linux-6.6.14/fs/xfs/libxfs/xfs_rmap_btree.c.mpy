{
  "module_name": "xfs_rmap_btree.c",
  "hash_id": "dc20114117fb8f29be84c211b9b9d6f1dfa25b321afd4427e4f7eca30c27d498",
  "original_prompt": "Ingested from linux-6.6.14/fs/xfs/libxfs/xfs_rmap_btree.c",
  "human_readable_source": "\n \n#include \"xfs.h\"\n#include \"xfs_fs.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_format.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_alloc.h\"\n#include \"xfs_btree.h\"\n#include \"xfs_btree_staging.h\"\n#include \"xfs_rmap.h\"\n#include \"xfs_rmap_btree.h\"\n#include \"xfs_trace.h\"\n#include \"xfs_error.h\"\n#include \"xfs_extent_busy.h\"\n#include \"xfs_ag.h\"\n#include \"xfs_ag_resv.h\"\n\nstatic struct kmem_cache\t*xfs_rmapbt_cur_cache;\n\n \n\nstatic struct xfs_btree_cur *\nxfs_rmapbt_dup_cursor(\n\tstruct xfs_btree_cur\t*cur)\n{\n\treturn xfs_rmapbt_init_cursor(cur->bc_mp, cur->bc_tp,\n\t\t\t\tcur->bc_ag.agbp, cur->bc_ag.pag);\n}\n\nSTATIC void\nxfs_rmapbt_set_root(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr,\n\tint\t\t\t\tinc)\n{\n\tstruct xfs_buf\t\t*agbp = cur->bc_ag.agbp;\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tint\t\t\tbtnum = cur->bc_btnum;\n\n\tASSERT(ptr->s != 0);\n\n\tagf->agf_roots[btnum] = ptr->s;\n\tbe32_add_cpu(&agf->agf_levels[btnum], inc);\n\tcur->bc_ag.pag->pagf_levels[btnum] += inc;\n\n\txfs_alloc_log_agf(cur->bc_tp, agbp, XFS_AGF_ROOTS | XFS_AGF_LEVELS);\n}\n\nSTATIC int\nxfs_rmapbt_alloc_block(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*start,\n\tunion xfs_btree_ptr\t\t*new,\n\tint\t\t\t\t*stat)\n{\n\tstruct xfs_buf\t\t*agbp = cur->bc_ag.agbp;\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tstruct xfs_perag\t*pag = cur->bc_ag.pag;\n\tint\t\t\terror;\n\txfs_agblock_t\t\tbno;\n\n\t \n\terror = xfs_alloc_get_freelist(pag, cur->bc_tp, cur->bc_ag.agbp,\n\t\t\t\t       &bno, 1);\n\tif (error)\n\t\treturn error;\n\n\ttrace_xfs_rmapbt_alloc_block(cur->bc_mp, pag->pag_agno, bno, 1);\n\tif (bno == NULLAGBLOCK) {\n\t\t*stat = 0;\n\t\treturn 0;\n\t}\n\n\txfs_extent_busy_reuse(cur->bc_mp, pag, bno, 1, false);\n\n\tnew->s = cpu_to_be32(bno);\n\tbe32_add_cpu(&agf->agf_rmap_blocks, 1);\n\txfs_alloc_log_agf(cur->bc_tp, agbp, XFS_AGF_RMAP_BLOCKS);\n\n\txfs_ag_resv_rmapbt_alloc(cur->bc_mp, pag->pag_agno);\n\n\t*stat = 1;\n\treturn 0;\n}\n\nSTATIC int\nxfs_rmapbt_free_block(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_buf\t\t*agbp = cur->bc_ag.agbp;\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tstruct xfs_perag\t*pag = cur->bc_ag.pag;\n\txfs_agblock_t\t\tbno;\n\tint\t\t\terror;\n\n\tbno = xfs_daddr_to_agbno(cur->bc_mp, xfs_buf_daddr(bp));\n\ttrace_xfs_rmapbt_free_block(cur->bc_mp, pag->pag_agno,\n\t\t\tbno, 1);\n\tbe32_add_cpu(&agf->agf_rmap_blocks, -1);\n\txfs_alloc_log_agf(cur->bc_tp, agbp, XFS_AGF_RMAP_BLOCKS);\n\terror = xfs_alloc_put_freelist(pag, cur->bc_tp, agbp, NULL, bno, 1);\n\tif (error)\n\t\treturn error;\n\n\txfs_extent_busy_insert(cur->bc_tp, pag, bno, 1,\n\t\t\t      XFS_EXTENT_BUSY_SKIP_DISCARD);\n\n\txfs_ag_resv_free_extent(pag, XFS_AG_RESV_RMAPBT, NULL, 1);\n\treturn 0;\n}\n\nSTATIC int\nxfs_rmapbt_get_minrecs(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel)\n{\n\treturn cur->bc_mp->m_rmap_mnr[level != 0];\n}\n\nSTATIC int\nxfs_rmapbt_get_maxrecs(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel)\n{\n\treturn cur->bc_mp->m_rmap_mxr[level != 0];\n}\n\n \nstatic inline __be64 ondisk_rec_offset_to_key(const union xfs_btree_rec *rec)\n{\n\treturn rec->rmap.rm_offset & ~cpu_to_be64(XFS_RMAP_OFF_UNWRITTEN);\n}\n\nSTATIC void\nxfs_rmapbt_init_key_from_rec(\n\tunion xfs_btree_key\t\t*key,\n\tconst union xfs_btree_rec\t*rec)\n{\n\tkey->rmap.rm_startblock = rec->rmap.rm_startblock;\n\tkey->rmap.rm_owner = rec->rmap.rm_owner;\n\tkey->rmap.rm_offset = ondisk_rec_offset_to_key(rec);\n}\n\n \nSTATIC void\nxfs_rmapbt_init_high_key_from_rec(\n\tunion xfs_btree_key\t\t*key,\n\tconst union xfs_btree_rec\t*rec)\n{\n\tuint64_t\t\t\toff;\n\tint\t\t\t\tadj;\n\n\tadj = be32_to_cpu(rec->rmap.rm_blockcount) - 1;\n\n\tkey->rmap.rm_startblock = rec->rmap.rm_startblock;\n\tbe32_add_cpu(&key->rmap.rm_startblock, adj);\n\tkey->rmap.rm_owner = rec->rmap.rm_owner;\n\tkey->rmap.rm_offset = ondisk_rec_offset_to_key(rec);\n\tif (XFS_RMAP_NON_INODE_OWNER(be64_to_cpu(rec->rmap.rm_owner)) ||\n\t    XFS_RMAP_IS_BMBT_BLOCK(be64_to_cpu(rec->rmap.rm_offset)))\n\t\treturn;\n\toff = be64_to_cpu(key->rmap.rm_offset);\n\toff = (XFS_RMAP_OFF(off) + adj) | (off & ~XFS_RMAP_OFF_MASK);\n\tkey->rmap.rm_offset = cpu_to_be64(off);\n}\n\nSTATIC void\nxfs_rmapbt_init_rec_from_cur(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_rec\t*rec)\n{\n\trec->rmap.rm_startblock = cpu_to_be32(cur->bc_rec.r.rm_startblock);\n\trec->rmap.rm_blockcount = cpu_to_be32(cur->bc_rec.r.rm_blockcount);\n\trec->rmap.rm_owner = cpu_to_be64(cur->bc_rec.r.rm_owner);\n\trec->rmap.rm_offset = cpu_to_be64(\n\t\t\txfs_rmap_irec_offset_pack(&cur->bc_rec.r));\n}\n\nSTATIC void\nxfs_rmapbt_init_ptr_from_cur(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_ptr\t*ptr)\n{\n\tstruct xfs_agf\t\t*agf = cur->bc_ag.agbp->b_addr;\n\n\tASSERT(cur->bc_ag.pag->pag_agno == be32_to_cpu(agf->agf_seqno));\n\n\tptr->s = agf->agf_roots[cur->bc_btnum];\n}\n\n \nstatic inline uint64_t offset_keymask(uint64_t offset)\n{\n\treturn offset & ~XFS_RMAP_OFF_UNWRITTEN;\n}\n\nSTATIC int64_t\nxfs_rmapbt_key_diff(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key)\n{\n\tstruct xfs_rmap_irec\t\t*rec = &cur->bc_rec.r;\n\tconst struct xfs_rmap_key\t*kp = &key->rmap;\n\t__u64\t\t\t\tx, y;\n\tint64_t\t\t\t\td;\n\n\td = (int64_t)be32_to_cpu(kp->rm_startblock) - rec->rm_startblock;\n\tif (d)\n\t\treturn d;\n\n\tx = be64_to_cpu(kp->rm_owner);\n\ty = rec->rm_owner;\n\tif (x > y)\n\t\treturn 1;\n\telse if (y > x)\n\t\treturn -1;\n\n\tx = offset_keymask(be64_to_cpu(kp->rm_offset));\n\ty = offset_keymask(xfs_rmap_irec_offset_pack(rec));\n\tif (x > y)\n\t\treturn 1;\n\telse if (y > x)\n\t\treturn -1;\n\treturn 0;\n}\n\nSTATIC int64_t\nxfs_rmapbt_diff_two_keys(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*k1,\n\tconst union xfs_btree_key\t*k2,\n\tconst union xfs_btree_key\t*mask)\n{\n\tconst struct xfs_rmap_key\t*kp1 = &k1->rmap;\n\tconst struct xfs_rmap_key\t*kp2 = &k2->rmap;\n\tint64_t\t\t\t\td;\n\t__u64\t\t\t\tx, y;\n\n\t \n\tASSERT(!mask || mask->rmap.rm_startblock);\n\n\td = (int64_t)be32_to_cpu(kp1->rm_startblock) -\n\t\t     be32_to_cpu(kp2->rm_startblock);\n\tif (d)\n\t\treturn d;\n\n\tif (!mask || mask->rmap.rm_owner) {\n\t\tx = be64_to_cpu(kp1->rm_owner);\n\t\ty = be64_to_cpu(kp2->rm_owner);\n\t\tif (x > y)\n\t\t\treturn 1;\n\t\telse if (y > x)\n\t\t\treturn -1;\n\t}\n\n\tif (!mask || mask->rmap.rm_offset) {\n\t\t \n\t\tASSERT(!mask || mask->rmap.rm_owner);\n\n\t\tx = offset_keymask(be64_to_cpu(kp1->rm_offset));\n\t\ty = offset_keymask(be64_to_cpu(kp2->rm_offset));\n\t\tif (x > y)\n\t\t\treturn 1;\n\t\telse if (y > x)\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic xfs_failaddr_t\nxfs_rmapbt_verify(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\tstruct xfs_perag\t*pag = bp->b_pag;\n\txfs_failaddr_t\t\tfa;\n\tunsigned int\t\tlevel;\n\n\t \n\tif (!xfs_verify_magic(bp, block->bb_magic))\n\t\treturn __this_address;\n\n\tif (!xfs_has_rmapbt(mp))\n\t\treturn __this_address;\n\tfa = xfs_btree_sblock_v5hdr_verify(bp);\n\tif (fa)\n\t\treturn fa;\n\n\tlevel = be16_to_cpu(block->bb_level);\n\tif (pag && xfs_perag_initialised_agf(pag)) {\n\t\tif (level >= pag->pagf_levels[XFS_BTNUM_RMAPi])\n\t\t\treturn __this_address;\n\t} else if (level >= mp->m_rmap_maxlevels)\n\t\treturn __this_address;\n\n\treturn xfs_btree_sblock_verify(bp, mp->m_rmap_mxr[level != 0]);\n}\n\nstatic void\nxfs_rmapbt_read_verify(\n\tstruct xfs_buf\t*bp)\n{\n\txfs_failaddr_t\tfa;\n\n\tif (!xfs_btree_sblock_verify_crc(bp))\n\t\txfs_verifier_error(bp, -EFSBADCRC, __this_address);\n\telse {\n\t\tfa = xfs_rmapbt_verify(bp);\n\t\tif (fa)\n\t\t\txfs_verifier_error(bp, -EFSCORRUPTED, fa);\n\t}\n\n\tif (bp->b_error)\n\t\ttrace_xfs_btree_corrupt(bp, _RET_IP_);\n}\n\nstatic void\nxfs_rmapbt_write_verify(\n\tstruct xfs_buf\t*bp)\n{\n\txfs_failaddr_t\tfa;\n\n\tfa = xfs_rmapbt_verify(bp);\n\tif (fa) {\n\t\ttrace_xfs_btree_corrupt(bp, _RET_IP_);\n\t\txfs_verifier_error(bp, -EFSCORRUPTED, fa);\n\t\treturn;\n\t}\n\txfs_btree_sblock_calc_crc(bp);\n\n}\n\nconst struct xfs_buf_ops xfs_rmapbt_buf_ops = {\n\t.name\t\t\t= \"xfs_rmapbt\",\n\t.magic\t\t\t= { 0, cpu_to_be32(XFS_RMAP_CRC_MAGIC) },\n\t.verify_read\t\t= xfs_rmapbt_read_verify,\n\t.verify_write\t\t= xfs_rmapbt_write_verify,\n\t.verify_struct\t\t= xfs_rmapbt_verify,\n};\n\nSTATIC int\nxfs_rmapbt_keys_inorder(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*k1,\n\tconst union xfs_btree_key\t*k2)\n{\n\tuint32_t\t\tx;\n\tuint32_t\t\ty;\n\tuint64_t\t\ta;\n\tuint64_t\t\tb;\n\n\tx = be32_to_cpu(k1->rmap.rm_startblock);\n\ty = be32_to_cpu(k2->rmap.rm_startblock);\n\tif (x < y)\n\t\treturn 1;\n\telse if (x > y)\n\t\treturn 0;\n\ta = be64_to_cpu(k1->rmap.rm_owner);\n\tb = be64_to_cpu(k2->rmap.rm_owner);\n\tif (a < b)\n\t\treturn 1;\n\telse if (a > b)\n\t\treturn 0;\n\ta = offset_keymask(be64_to_cpu(k1->rmap.rm_offset));\n\tb = offset_keymask(be64_to_cpu(k2->rmap.rm_offset));\n\tif (a <= b)\n\t\treturn 1;\n\treturn 0;\n}\n\nSTATIC int\nxfs_rmapbt_recs_inorder(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_rec\t*r1,\n\tconst union xfs_btree_rec\t*r2)\n{\n\tuint32_t\t\tx;\n\tuint32_t\t\ty;\n\tuint64_t\t\ta;\n\tuint64_t\t\tb;\n\n\tx = be32_to_cpu(r1->rmap.rm_startblock);\n\ty = be32_to_cpu(r2->rmap.rm_startblock);\n\tif (x < y)\n\t\treturn 1;\n\telse if (x > y)\n\t\treturn 0;\n\ta = be64_to_cpu(r1->rmap.rm_owner);\n\tb = be64_to_cpu(r2->rmap.rm_owner);\n\tif (a < b)\n\t\treturn 1;\n\telse if (a > b)\n\t\treturn 0;\n\ta = offset_keymask(be64_to_cpu(r1->rmap.rm_offset));\n\tb = offset_keymask(be64_to_cpu(r2->rmap.rm_offset));\n\tif (a <= b)\n\t\treturn 1;\n\treturn 0;\n}\n\nSTATIC enum xbtree_key_contig\nxfs_rmapbt_keys_contiguous(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2,\n\tconst union xfs_btree_key\t*mask)\n{\n\tASSERT(!mask || mask->rmap.rm_startblock);\n\n\t \n\tASSERT(!mask || (!mask->rmap.rm_owner && !mask->rmap.rm_offset));\n\n\treturn xbtree_key_contig(be32_to_cpu(key1->rmap.rm_startblock),\n\t\t\t\t be32_to_cpu(key2->rmap.rm_startblock));\n}\n\nstatic const struct xfs_btree_ops xfs_rmapbt_ops = {\n\t.rec_len\t\t= sizeof(struct xfs_rmap_rec),\n\t.key_len\t\t= 2 * sizeof(struct xfs_rmap_key),\n\n\t.dup_cursor\t\t= xfs_rmapbt_dup_cursor,\n\t.set_root\t\t= xfs_rmapbt_set_root,\n\t.alloc_block\t\t= xfs_rmapbt_alloc_block,\n\t.free_block\t\t= xfs_rmapbt_free_block,\n\t.get_minrecs\t\t= xfs_rmapbt_get_minrecs,\n\t.get_maxrecs\t\t= xfs_rmapbt_get_maxrecs,\n\t.init_key_from_rec\t= xfs_rmapbt_init_key_from_rec,\n\t.init_high_key_from_rec\t= xfs_rmapbt_init_high_key_from_rec,\n\t.init_rec_from_cur\t= xfs_rmapbt_init_rec_from_cur,\n\t.init_ptr_from_cur\t= xfs_rmapbt_init_ptr_from_cur,\n\t.key_diff\t\t= xfs_rmapbt_key_diff,\n\t.buf_ops\t\t= &xfs_rmapbt_buf_ops,\n\t.diff_two_keys\t\t= xfs_rmapbt_diff_two_keys,\n\t.keys_inorder\t\t= xfs_rmapbt_keys_inorder,\n\t.recs_inorder\t\t= xfs_rmapbt_recs_inorder,\n\t.keys_contiguous\t= xfs_rmapbt_keys_contiguous,\n};\n\nstatic struct xfs_btree_cur *\nxfs_rmapbt_init_common(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_perag\t*pag)\n{\n\tstruct xfs_btree_cur\t*cur;\n\n\t \n\tcur = xfs_btree_alloc_cursor(mp, tp, XFS_BTNUM_RMAP,\n\t\t\tmp->m_rmap_maxlevels, xfs_rmapbt_cur_cache);\n\tcur->bc_flags = XFS_BTREE_CRC_BLOCKS | XFS_BTREE_OVERLAPPING;\n\tcur->bc_statoff = XFS_STATS_CALC_INDEX(xs_rmap_2);\n\tcur->bc_ops = &xfs_rmapbt_ops;\n\n\tcur->bc_ag.pag = xfs_perag_hold(pag);\n\treturn cur;\n}\n\n \nstruct xfs_btree_cur *\nxfs_rmapbt_init_cursor(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buf\t\t*agbp,\n\tstruct xfs_perag\t*pag)\n{\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tstruct xfs_btree_cur\t*cur;\n\n\tcur = xfs_rmapbt_init_common(mp, tp, pag);\n\tcur->bc_nlevels = be32_to_cpu(agf->agf_levels[XFS_BTNUM_RMAP]);\n\tcur->bc_ag.agbp = agbp;\n\treturn cur;\n}\n\n \nstruct xfs_btree_cur *\nxfs_rmapbt_stage_cursor(\n\tstruct xfs_mount\t*mp,\n\tstruct xbtree_afakeroot\t*afake,\n\tstruct xfs_perag\t*pag)\n{\n\tstruct xfs_btree_cur\t*cur;\n\n\tcur = xfs_rmapbt_init_common(mp, NULL, pag);\n\txfs_btree_stage_afakeroot(cur, afake);\n\treturn cur;\n}\n\n \nvoid\nxfs_rmapbt_commit_staged_btree(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buf\t\t*agbp)\n{\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tstruct xbtree_afakeroot\t*afake = cur->bc_ag.afake;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\n\tagf->agf_roots[cur->bc_btnum] = cpu_to_be32(afake->af_root);\n\tagf->agf_levels[cur->bc_btnum] = cpu_to_be32(afake->af_levels);\n\tagf->agf_rmap_blocks = cpu_to_be32(afake->af_blocks);\n\txfs_alloc_log_agf(tp, agbp, XFS_AGF_ROOTS | XFS_AGF_LEVELS |\n\t\t\t\t    XFS_AGF_RMAP_BLOCKS);\n\txfs_btree_commit_afakeroot(cur, tp, agbp, &xfs_rmapbt_ops);\n}\n\n \nstatic inline unsigned int\nxfs_rmapbt_block_maxrecs(\n\tunsigned int\t\tblocklen,\n\tbool\t\t\tleaf)\n{\n\tif (leaf)\n\t\treturn blocklen / sizeof(struct xfs_rmap_rec);\n\treturn blocklen /\n\t\t(2 * sizeof(struct xfs_rmap_key) + sizeof(xfs_rmap_ptr_t));\n}\n\n \nint\nxfs_rmapbt_maxrecs(\n\tint\t\t\tblocklen,\n\tint\t\t\tleaf)\n{\n\tblocklen -= XFS_RMAP_BLOCK_LEN;\n\treturn xfs_rmapbt_block_maxrecs(blocklen, leaf);\n}\n\n \nunsigned int\nxfs_rmapbt_maxlevels_ondisk(void)\n{\n\tunsigned int\t\tminrecs[2];\n\tunsigned int\t\tblocklen;\n\n\tblocklen = XFS_MIN_CRC_BLOCKSIZE - XFS_BTREE_SBLOCK_CRC_LEN;\n\n\tminrecs[0] = xfs_rmapbt_block_maxrecs(blocklen, true) / 2;\n\tminrecs[1] = xfs_rmapbt_block_maxrecs(blocklen, false) / 2;\n\n\t \n\treturn xfs_btree_space_to_height(minrecs, XFS_MAX_CRC_AG_BLOCKS);\n}\n\n \nvoid\nxfs_rmapbt_compute_maxlevels(\n\tstruct xfs_mount\t\t*mp)\n{\n\tif (!xfs_has_rmapbt(mp)) {\n\t\tmp->m_rmap_maxlevels = 0;\n\t\treturn;\n\t}\n\n\tif (xfs_has_reflink(mp)) {\n\t\t \n\t\tmp->m_rmap_maxlevels = xfs_btree_space_to_height(mp->m_rmap_mnr,\n\t\t\t\tmp->m_sb.sb_agblocks);\n\t} else {\n\t\t \n\t\tmp->m_rmap_maxlevels = xfs_btree_compute_maxlevels(\n\t\t\t\tmp->m_rmap_mnr, mp->m_sb.sb_agblocks);\n\t}\n\tASSERT(mp->m_rmap_maxlevels <= xfs_rmapbt_maxlevels_ondisk());\n}\n\n \nxfs_extlen_t\nxfs_rmapbt_calc_size(\n\tstruct xfs_mount\t*mp,\n\tunsigned long long\tlen)\n{\n\treturn xfs_btree_calc_size(mp->m_rmap_mnr, len);\n}\n\n \nxfs_extlen_t\nxfs_rmapbt_max_size(\n\tstruct xfs_mount\t*mp,\n\txfs_agblock_t\t\tagblocks)\n{\n\t \n\tif (mp->m_rmap_mxr[0] == 0)\n\t\treturn 0;\n\n\treturn xfs_rmapbt_calc_size(mp, agblocks);\n}\n\n \nint\nxfs_rmapbt_calc_reserves(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_perag\t*pag,\n\txfs_extlen_t\t\t*ask,\n\txfs_extlen_t\t\t*used)\n{\n\tstruct xfs_buf\t\t*agbp;\n\tstruct xfs_agf\t\t*agf;\n\txfs_agblock_t\t\tagblocks;\n\txfs_extlen_t\t\ttree_len;\n\tint\t\t\terror;\n\n\tif (!xfs_has_rmapbt(mp))\n\t\treturn 0;\n\n\terror = xfs_alloc_read_agf(pag, tp, 0, &agbp);\n\tif (error)\n\t\treturn error;\n\n\tagf = agbp->b_addr;\n\tagblocks = be32_to_cpu(agf->agf_length);\n\ttree_len = be32_to_cpu(agf->agf_rmap_blocks);\n\txfs_trans_brelse(tp, agbp);\n\n\t \n\tif (xfs_ag_contains_log(mp, pag->pag_agno))\n\t\tagblocks -= mp->m_sb.sb_logblocks;\n\n\t \n\t*ask += max(agblocks / 100, xfs_rmapbt_max_size(mp, agblocks));\n\t*used += tree_len;\n\n\treturn error;\n}\n\nint __init\nxfs_rmapbt_init_cur_cache(void)\n{\n\txfs_rmapbt_cur_cache = kmem_cache_create(\"xfs_rmapbt_cur\",\n\t\t\txfs_btree_cur_sizeof(xfs_rmapbt_maxlevels_ondisk()),\n\t\t\t0, 0, NULL);\n\n\tif (!xfs_rmapbt_cur_cache)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid\nxfs_rmapbt_destroy_cur_cache(void)\n{\n\tkmem_cache_destroy(xfs_rmapbt_cur_cache);\n\txfs_rmapbt_cur_cache = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}