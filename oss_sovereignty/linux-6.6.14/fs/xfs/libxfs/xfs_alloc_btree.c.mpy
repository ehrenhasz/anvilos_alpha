{
  "module_name": "xfs_alloc_btree.c",
  "hash_id": "3f3a8959dfa11b3b937a1a1ddcff69ad138c4b3443b1c8752290655f02eec552",
  "original_prompt": "Ingested from linux-6.6.14/fs/xfs/libxfs/xfs_alloc_btree.c",
  "human_readable_source": "\n \n#include \"xfs.h\"\n#include \"xfs_fs.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_format.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_btree.h\"\n#include \"xfs_btree_staging.h\"\n#include \"xfs_alloc_btree.h\"\n#include \"xfs_alloc.h\"\n#include \"xfs_extent_busy.h\"\n#include \"xfs_error.h\"\n#include \"xfs_trace.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_ag.h\"\n\nstatic struct kmem_cache\t*xfs_allocbt_cur_cache;\n\nSTATIC struct xfs_btree_cur *\nxfs_allocbt_dup_cursor(\n\tstruct xfs_btree_cur\t*cur)\n{\n\treturn xfs_allocbt_init_cursor(cur->bc_mp, cur->bc_tp,\n\t\t\tcur->bc_ag.agbp, cur->bc_ag.pag, cur->bc_btnum);\n}\n\nSTATIC void\nxfs_allocbt_set_root(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*ptr,\n\tint\t\t\t\tinc)\n{\n\tstruct xfs_buf\t\t*agbp = cur->bc_ag.agbp;\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tint\t\t\tbtnum = cur->bc_btnum;\n\n\tASSERT(ptr->s != 0);\n\n\tagf->agf_roots[btnum] = ptr->s;\n\tbe32_add_cpu(&agf->agf_levels[btnum], inc);\n\tcur->bc_ag.pag->pagf_levels[btnum] += inc;\n\n\txfs_alloc_log_agf(cur->bc_tp, agbp, XFS_AGF_ROOTS | XFS_AGF_LEVELS);\n}\n\nSTATIC int\nxfs_allocbt_alloc_block(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_ptr\t*start,\n\tunion xfs_btree_ptr\t\t*new,\n\tint\t\t\t\t*stat)\n{\n\tint\t\t\terror;\n\txfs_agblock_t\t\tbno;\n\n\t \n\terror = xfs_alloc_get_freelist(cur->bc_ag.pag, cur->bc_tp,\n\t\t\tcur->bc_ag.agbp, &bno, 1);\n\tif (error)\n\t\treturn error;\n\n\tif (bno == NULLAGBLOCK) {\n\t\t*stat = 0;\n\t\treturn 0;\n\t}\n\n\tatomic64_inc(&cur->bc_mp->m_allocbt_blks);\n\txfs_extent_busy_reuse(cur->bc_mp, cur->bc_ag.pag, bno, 1, false);\n\n\tnew->s = cpu_to_be32(bno);\n\n\t*stat = 1;\n\treturn 0;\n}\n\nSTATIC int\nxfs_allocbt_free_block(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_buf\t\t*agbp = cur->bc_ag.agbp;\n\txfs_agblock_t\t\tbno;\n\tint\t\t\terror;\n\n\tbno = xfs_daddr_to_agbno(cur->bc_mp, xfs_buf_daddr(bp));\n\terror = xfs_alloc_put_freelist(cur->bc_ag.pag, cur->bc_tp, agbp, NULL,\n\t\t\tbno, 1);\n\tif (error)\n\t\treturn error;\n\n\tatomic64_dec(&cur->bc_mp->m_allocbt_blks);\n\txfs_extent_busy_insert(cur->bc_tp, agbp->b_pag, bno, 1,\n\t\t\t      XFS_EXTENT_BUSY_SKIP_DISCARD);\n\treturn 0;\n}\n\n \nSTATIC void\nxfs_allocbt_update_lastrec(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst struct xfs_btree_block\t*block,\n\tconst union xfs_btree_rec\t*rec,\n\tint\t\t\t\tptr,\n\tint\t\t\t\treason)\n{\n\tstruct xfs_agf\t\t*agf = cur->bc_ag.agbp->b_addr;\n\tstruct xfs_perag\t*pag;\n\t__be32\t\t\tlen;\n\tint\t\t\tnumrecs;\n\n\tASSERT(cur->bc_btnum == XFS_BTNUM_CNT);\n\n\tswitch (reason) {\n\tcase LASTREC_UPDATE:\n\t\t \n\t\tif (ptr != xfs_btree_get_numrecs(block))\n\t\t\treturn;\n\t\tlen = rec->alloc.ar_blockcount;\n\t\tbreak;\n\tcase LASTREC_INSREC:\n\t\tif (be32_to_cpu(rec->alloc.ar_blockcount) <=\n\t\t    be32_to_cpu(agf->agf_longest))\n\t\t\treturn;\n\t\tlen = rec->alloc.ar_blockcount;\n\t\tbreak;\n\tcase LASTREC_DELREC:\n\t\tnumrecs = xfs_btree_get_numrecs(block);\n\t\tif (ptr <= numrecs)\n\t\t\treturn;\n\t\tASSERT(ptr == numrecs + 1);\n\n\t\tif (numrecs) {\n\t\t\txfs_alloc_rec_t *rrp;\n\n\t\t\trrp = XFS_ALLOC_REC_ADDR(cur->bc_mp, block, numrecs);\n\t\t\tlen = rrp->ar_blockcount;\n\t\t} else {\n\t\t\tlen = 0;\n\t\t}\n\n\t\tbreak;\n\tdefault:\n\t\tASSERT(0);\n\t\treturn;\n\t}\n\n\tagf->agf_longest = len;\n\tpag = cur->bc_ag.agbp->b_pag;\n\tpag->pagf_longest = be32_to_cpu(len);\n\txfs_alloc_log_agf(cur->bc_tp, cur->bc_ag.agbp, XFS_AGF_LONGEST);\n}\n\nSTATIC int\nxfs_allocbt_get_minrecs(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel)\n{\n\treturn cur->bc_mp->m_alloc_mnr[level != 0];\n}\n\nSTATIC int\nxfs_allocbt_get_maxrecs(\n\tstruct xfs_btree_cur\t*cur,\n\tint\t\t\tlevel)\n{\n\treturn cur->bc_mp->m_alloc_mxr[level != 0];\n}\n\nSTATIC void\nxfs_allocbt_init_key_from_rec(\n\tunion xfs_btree_key\t\t*key,\n\tconst union xfs_btree_rec\t*rec)\n{\n\tkey->alloc.ar_startblock = rec->alloc.ar_startblock;\n\tkey->alloc.ar_blockcount = rec->alloc.ar_blockcount;\n}\n\nSTATIC void\nxfs_bnobt_init_high_key_from_rec(\n\tunion xfs_btree_key\t\t*key,\n\tconst union xfs_btree_rec\t*rec)\n{\n\t__u32\t\t\t\tx;\n\n\tx = be32_to_cpu(rec->alloc.ar_startblock);\n\tx += be32_to_cpu(rec->alloc.ar_blockcount) - 1;\n\tkey->alloc.ar_startblock = cpu_to_be32(x);\n\tkey->alloc.ar_blockcount = 0;\n}\n\nSTATIC void\nxfs_cntbt_init_high_key_from_rec(\n\tunion xfs_btree_key\t\t*key,\n\tconst union xfs_btree_rec\t*rec)\n{\n\tkey->alloc.ar_blockcount = rec->alloc.ar_blockcount;\n\tkey->alloc.ar_startblock = 0;\n}\n\nSTATIC void\nxfs_allocbt_init_rec_from_cur(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_rec\t*rec)\n{\n\trec->alloc.ar_startblock = cpu_to_be32(cur->bc_rec.a.ar_startblock);\n\trec->alloc.ar_blockcount = cpu_to_be32(cur->bc_rec.a.ar_blockcount);\n}\n\nSTATIC void\nxfs_allocbt_init_ptr_from_cur(\n\tstruct xfs_btree_cur\t*cur,\n\tunion xfs_btree_ptr\t*ptr)\n{\n\tstruct xfs_agf\t\t*agf = cur->bc_ag.agbp->b_addr;\n\n\tASSERT(cur->bc_ag.pag->pag_agno == be32_to_cpu(agf->agf_seqno));\n\n\tptr->s = agf->agf_roots[cur->bc_btnum];\n}\n\nSTATIC int64_t\nxfs_bnobt_key_diff(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key)\n{\n\tstruct xfs_alloc_rec_incore\t*rec = &cur->bc_rec.a;\n\tconst struct xfs_alloc_rec\t*kp = &key->alloc;\n\n\treturn (int64_t)be32_to_cpu(kp->ar_startblock) - rec->ar_startblock;\n}\n\nSTATIC int64_t\nxfs_cntbt_key_diff(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key)\n{\n\tstruct xfs_alloc_rec_incore\t*rec = &cur->bc_rec.a;\n\tconst struct xfs_alloc_rec\t*kp = &key->alloc;\n\tint64_t\t\t\t\tdiff;\n\n\tdiff = (int64_t)be32_to_cpu(kp->ar_blockcount) - rec->ar_blockcount;\n\tif (diff)\n\t\treturn diff;\n\n\treturn (int64_t)be32_to_cpu(kp->ar_startblock) - rec->ar_startblock;\n}\n\nSTATIC int64_t\nxfs_bnobt_diff_two_keys(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*k1,\n\tconst union xfs_btree_key\t*k2,\n\tconst union xfs_btree_key\t*mask)\n{\n\tASSERT(!mask || mask->alloc.ar_startblock);\n\n\treturn (int64_t)be32_to_cpu(k1->alloc.ar_startblock) -\n\t\t\tbe32_to_cpu(k2->alloc.ar_startblock);\n}\n\nSTATIC int64_t\nxfs_cntbt_diff_two_keys(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*k1,\n\tconst union xfs_btree_key\t*k2,\n\tconst union xfs_btree_key\t*mask)\n{\n\tint64_t\t\t\t\tdiff;\n\n\tASSERT(!mask || (mask->alloc.ar_blockcount &&\n\t\t\t mask->alloc.ar_startblock));\n\n\tdiff =  be32_to_cpu(k1->alloc.ar_blockcount) -\n\t\tbe32_to_cpu(k2->alloc.ar_blockcount);\n\tif (diff)\n\t\treturn diff;\n\n\treturn  be32_to_cpu(k1->alloc.ar_startblock) -\n\t\tbe32_to_cpu(k2->alloc.ar_startblock);\n}\n\nstatic xfs_failaddr_t\nxfs_allocbt_verify(\n\tstruct xfs_buf\t\t*bp)\n{\n\tstruct xfs_mount\t*mp = bp->b_mount;\n\tstruct xfs_btree_block\t*block = XFS_BUF_TO_BLOCK(bp);\n\tstruct xfs_perag\t*pag = bp->b_pag;\n\txfs_failaddr_t\t\tfa;\n\tunsigned int\t\tlevel;\n\txfs_btnum_t\t\tbtnum = XFS_BTNUM_BNOi;\n\n\tif (!xfs_verify_magic(bp, block->bb_magic))\n\t\treturn __this_address;\n\n\tif (xfs_has_crc(mp)) {\n\t\tfa = xfs_btree_sblock_v5hdr_verify(bp);\n\t\tif (fa)\n\t\t\treturn fa;\n\t}\n\n\t \n\tlevel = be16_to_cpu(block->bb_level);\n\tif (bp->b_ops->magic[0] == cpu_to_be32(XFS_ABTC_MAGIC))\n\t\tbtnum = XFS_BTNUM_CNTi;\n\tif (pag && xfs_perag_initialised_agf(pag)) {\n\t\tif (level >= pag->pagf_levels[btnum])\n\t\t\treturn __this_address;\n\t} else if (level >= mp->m_alloc_maxlevels)\n\t\treturn __this_address;\n\n\treturn xfs_btree_sblock_verify(bp, mp->m_alloc_mxr[level != 0]);\n}\n\nstatic void\nxfs_allocbt_read_verify(\n\tstruct xfs_buf\t*bp)\n{\n\txfs_failaddr_t\tfa;\n\n\tif (!xfs_btree_sblock_verify_crc(bp))\n\t\txfs_verifier_error(bp, -EFSBADCRC, __this_address);\n\telse {\n\t\tfa = xfs_allocbt_verify(bp);\n\t\tif (fa)\n\t\t\txfs_verifier_error(bp, -EFSCORRUPTED, fa);\n\t}\n\n\tif (bp->b_error)\n\t\ttrace_xfs_btree_corrupt(bp, _RET_IP_);\n}\n\nstatic void\nxfs_allocbt_write_verify(\n\tstruct xfs_buf\t*bp)\n{\n\txfs_failaddr_t\tfa;\n\n\tfa = xfs_allocbt_verify(bp);\n\tif (fa) {\n\t\ttrace_xfs_btree_corrupt(bp, _RET_IP_);\n\t\txfs_verifier_error(bp, -EFSCORRUPTED, fa);\n\t\treturn;\n\t}\n\txfs_btree_sblock_calc_crc(bp);\n\n}\n\nconst struct xfs_buf_ops xfs_bnobt_buf_ops = {\n\t.name = \"xfs_bnobt\",\n\t.magic = { cpu_to_be32(XFS_ABTB_MAGIC),\n\t\t   cpu_to_be32(XFS_ABTB_CRC_MAGIC) },\n\t.verify_read = xfs_allocbt_read_verify,\n\t.verify_write = xfs_allocbt_write_verify,\n\t.verify_struct = xfs_allocbt_verify,\n};\n\nconst struct xfs_buf_ops xfs_cntbt_buf_ops = {\n\t.name = \"xfs_cntbt\",\n\t.magic = { cpu_to_be32(XFS_ABTC_MAGIC),\n\t\t   cpu_to_be32(XFS_ABTC_CRC_MAGIC) },\n\t.verify_read = xfs_allocbt_read_verify,\n\t.verify_write = xfs_allocbt_write_verify,\n\t.verify_struct = xfs_allocbt_verify,\n};\n\nSTATIC int\nxfs_bnobt_keys_inorder(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*k1,\n\tconst union xfs_btree_key\t*k2)\n{\n\treturn be32_to_cpu(k1->alloc.ar_startblock) <\n\t       be32_to_cpu(k2->alloc.ar_startblock);\n}\n\nSTATIC int\nxfs_bnobt_recs_inorder(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_rec\t*r1,\n\tconst union xfs_btree_rec\t*r2)\n{\n\treturn be32_to_cpu(r1->alloc.ar_startblock) +\n\t\tbe32_to_cpu(r1->alloc.ar_blockcount) <=\n\t\tbe32_to_cpu(r2->alloc.ar_startblock);\n}\n\nSTATIC int\nxfs_cntbt_keys_inorder(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*k1,\n\tconst union xfs_btree_key\t*k2)\n{\n\treturn be32_to_cpu(k1->alloc.ar_blockcount) <\n\t\tbe32_to_cpu(k2->alloc.ar_blockcount) ||\n\t\t(k1->alloc.ar_blockcount == k2->alloc.ar_blockcount &&\n\t\t be32_to_cpu(k1->alloc.ar_startblock) <\n\t\t be32_to_cpu(k2->alloc.ar_startblock));\n}\n\nSTATIC int\nxfs_cntbt_recs_inorder(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_rec\t*r1,\n\tconst union xfs_btree_rec\t*r2)\n{\n\treturn be32_to_cpu(r1->alloc.ar_blockcount) <\n\t\tbe32_to_cpu(r2->alloc.ar_blockcount) ||\n\t\t(r1->alloc.ar_blockcount == r2->alloc.ar_blockcount &&\n\t\t be32_to_cpu(r1->alloc.ar_startblock) <\n\t\t be32_to_cpu(r2->alloc.ar_startblock));\n}\n\nSTATIC enum xbtree_key_contig\nxfs_allocbt_keys_contiguous(\n\tstruct xfs_btree_cur\t\t*cur,\n\tconst union xfs_btree_key\t*key1,\n\tconst union xfs_btree_key\t*key2,\n\tconst union xfs_btree_key\t*mask)\n{\n\tASSERT(!mask || mask->alloc.ar_startblock);\n\n\treturn xbtree_key_contig(be32_to_cpu(key1->alloc.ar_startblock),\n\t\t\t\t be32_to_cpu(key2->alloc.ar_startblock));\n}\n\nstatic const struct xfs_btree_ops xfs_bnobt_ops = {\n\t.rec_len\t\t= sizeof(xfs_alloc_rec_t),\n\t.key_len\t\t= sizeof(xfs_alloc_key_t),\n\n\t.dup_cursor\t\t= xfs_allocbt_dup_cursor,\n\t.set_root\t\t= xfs_allocbt_set_root,\n\t.alloc_block\t\t= xfs_allocbt_alloc_block,\n\t.free_block\t\t= xfs_allocbt_free_block,\n\t.update_lastrec\t\t= xfs_allocbt_update_lastrec,\n\t.get_minrecs\t\t= xfs_allocbt_get_minrecs,\n\t.get_maxrecs\t\t= xfs_allocbt_get_maxrecs,\n\t.init_key_from_rec\t= xfs_allocbt_init_key_from_rec,\n\t.init_high_key_from_rec\t= xfs_bnobt_init_high_key_from_rec,\n\t.init_rec_from_cur\t= xfs_allocbt_init_rec_from_cur,\n\t.init_ptr_from_cur\t= xfs_allocbt_init_ptr_from_cur,\n\t.key_diff\t\t= xfs_bnobt_key_diff,\n\t.buf_ops\t\t= &xfs_bnobt_buf_ops,\n\t.diff_two_keys\t\t= xfs_bnobt_diff_two_keys,\n\t.keys_inorder\t\t= xfs_bnobt_keys_inorder,\n\t.recs_inorder\t\t= xfs_bnobt_recs_inorder,\n\t.keys_contiguous\t= xfs_allocbt_keys_contiguous,\n};\n\nstatic const struct xfs_btree_ops xfs_cntbt_ops = {\n\t.rec_len\t\t= sizeof(xfs_alloc_rec_t),\n\t.key_len\t\t= sizeof(xfs_alloc_key_t),\n\n\t.dup_cursor\t\t= xfs_allocbt_dup_cursor,\n\t.set_root\t\t= xfs_allocbt_set_root,\n\t.alloc_block\t\t= xfs_allocbt_alloc_block,\n\t.free_block\t\t= xfs_allocbt_free_block,\n\t.update_lastrec\t\t= xfs_allocbt_update_lastrec,\n\t.get_minrecs\t\t= xfs_allocbt_get_minrecs,\n\t.get_maxrecs\t\t= xfs_allocbt_get_maxrecs,\n\t.init_key_from_rec\t= xfs_allocbt_init_key_from_rec,\n\t.init_high_key_from_rec\t= xfs_cntbt_init_high_key_from_rec,\n\t.init_rec_from_cur\t= xfs_allocbt_init_rec_from_cur,\n\t.init_ptr_from_cur\t= xfs_allocbt_init_ptr_from_cur,\n\t.key_diff\t\t= xfs_cntbt_key_diff,\n\t.buf_ops\t\t= &xfs_cntbt_buf_ops,\n\t.diff_two_keys\t\t= xfs_cntbt_diff_two_keys,\n\t.keys_inorder\t\t= xfs_cntbt_keys_inorder,\n\t.recs_inorder\t\t= xfs_cntbt_recs_inorder,\n\t.keys_contiguous\t= NULL,  \n};\n\n \nSTATIC struct xfs_btree_cur *\nxfs_allocbt_init_common(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_perag\t*pag,\n\txfs_btnum_t\t\tbtnum)\n{\n\tstruct xfs_btree_cur\t*cur;\n\n\tASSERT(btnum == XFS_BTNUM_BNO || btnum == XFS_BTNUM_CNT);\n\n\tcur = xfs_btree_alloc_cursor(mp, tp, btnum, mp->m_alloc_maxlevels,\n\t\t\txfs_allocbt_cur_cache);\n\tcur->bc_ag.abt.active = false;\n\n\tif (btnum == XFS_BTNUM_CNT) {\n\t\tcur->bc_ops = &xfs_cntbt_ops;\n\t\tcur->bc_statoff = XFS_STATS_CALC_INDEX(xs_abtc_2);\n\t\tcur->bc_flags = XFS_BTREE_LASTREC_UPDATE;\n\t} else {\n\t\tcur->bc_ops = &xfs_bnobt_ops;\n\t\tcur->bc_statoff = XFS_STATS_CALC_INDEX(xs_abtb_2);\n\t}\n\n\tcur->bc_ag.pag = xfs_perag_hold(pag);\n\n\tif (xfs_has_crc(mp))\n\t\tcur->bc_flags |= XFS_BTREE_CRC_BLOCKS;\n\n\treturn cur;\n}\n\n \nstruct xfs_btree_cur *\t\t\t \nxfs_allocbt_init_cursor(\n\tstruct xfs_mount\t*mp,\t\t \n\tstruct xfs_trans\t*tp,\t\t \n\tstruct xfs_buf\t\t*agbp,\t\t \n\tstruct xfs_perag\t*pag,\n\txfs_btnum_t\t\tbtnum)\t\t \n{\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tstruct xfs_btree_cur\t*cur;\n\n\tcur = xfs_allocbt_init_common(mp, tp, pag, btnum);\n\tif (btnum == XFS_BTNUM_CNT)\n\t\tcur->bc_nlevels = be32_to_cpu(agf->agf_levels[XFS_BTNUM_CNT]);\n\telse\n\t\tcur->bc_nlevels = be32_to_cpu(agf->agf_levels[XFS_BTNUM_BNO]);\n\n\tcur->bc_ag.agbp = agbp;\n\n\treturn cur;\n}\n\n \nstruct xfs_btree_cur *\nxfs_allocbt_stage_cursor(\n\tstruct xfs_mount\t*mp,\n\tstruct xbtree_afakeroot\t*afake,\n\tstruct xfs_perag\t*pag,\n\txfs_btnum_t\t\tbtnum)\n{\n\tstruct xfs_btree_cur\t*cur;\n\n\tcur = xfs_allocbt_init_common(mp, NULL, pag, btnum);\n\txfs_btree_stage_afakeroot(cur, afake);\n\treturn cur;\n}\n\n \nvoid\nxfs_allocbt_commit_staged_btree(\n\tstruct xfs_btree_cur\t*cur,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buf\t\t*agbp)\n{\n\tstruct xfs_agf\t\t*agf = agbp->b_addr;\n\tstruct xbtree_afakeroot\t*afake = cur->bc_ag.afake;\n\n\tASSERT(cur->bc_flags & XFS_BTREE_STAGING);\n\n\tagf->agf_roots[cur->bc_btnum] = cpu_to_be32(afake->af_root);\n\tagf->agf_levels[cur->bc_btnum] = cpu_to_be32(afake->af_levels);\n\txfs_alloc_log_agf(tp, agbp, XFS_AGF_ROOTS | XFS_AGF_LEVELS);\n\n\tif (cur->bc_btnum == XFS_BTNUM_BNO) {\n\t\txfs_btree_commit_afakeroot(cur, tp, agbp, &xfs_bnobt_ops);\n\t} else {\n\t\tcur->bc_flags |= XFS_BTREE_LASTREC_UPDATE;\n\t\txfs_btree_commit_afakeroot(cur, tp, agbp, &xfs_cntbt_ops);\n\t}\n}\n\n \nstatic inline unsigned int\nxfs_allocbt_block_maxrecs(\n\tunsigned int\t\tblocklen,\n\tbool\t\t\tleaf)\n{\n\tif (leaf)\n\t\treturn blocklen / sizeof(xfs_alloc_rec_t);\n\treturn blocklen / (sizeof(xfs_alloc_key_t) + sizeof(xfs_alloc_ptr_t));\n}\n\n \nint\nxfs_allocbt_maxrecs(\n\tstruct xfs_mount\t*mp,\n\tint\t\t\tblocklen,\n\tint\t\t\tleaf)\n{\n\tblocklen -= XFS_ALLOC_BLOCK_LEN(mp);\n\treturn xfs_allocbt_block_maxrecs(blocklen, leaf);\n}\n\n \n#define XFS_MAX_FREESP_RECORDS\t((XFS_MAX_AG_BLOCKS + 1) / 2)\n\n \nunsigned int\nxfs_allocbt_maxlevels_ondisk(void)\n{\n\tunsigned int\t\tminrecs[2];\n\tunsigned int\t\tblocklen;\n\n\tblocklen = min(XFS_MIN_BLOCKSIZE - XFS_BTREE_SBLOCK_LEN,\n\t\t       XFS_MIN_CRC_BLOCKSIZE - XFS_BTREE_SBLOCK_CRC_LEN);\n\n\tminrecs[0] = xfs_allocbt_block_maxrecs(blocklen, true) / 2;\n\tminrecs[1] = xfs_allocbt_block_maxrecs(blocklen, false) / 2;\n\n\treturn xfs_btree_compute_maxlevels(minrecs, XFS_MAX_FREESP_RECORDS);\n}\n\n \nxfs_extlen_t\nxfs_allocbt_calc_size(\n\tstruct xfs_mount\t*mp,\n\tunsigned long long\tlen)\n{\n\treturn xfs_btree_calc_size(mp->m_alloc_mnr, len);\n}\n\nint __init\nxfs_allocbt_init_cur_cache(void)\n{\n\txfs_allocbt_cur_cache = kmem_cache_create(\"xfs_bnobt_cur\",\n\t\t\txfs_btree_cur_sizeof(xfs_allocbt_maxlevels_ondisk()),\n\t\t\t0, 0, NULL);\n\n\tif (!xfs_allocbt_cur_cache)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid\nxfs_allocbt_destroy_cur_cache(void)\n{\n\tkmem_cache_destroy(xfs_allocbt_cur_cache);\n\txfs_allocbt_cur_cache = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}