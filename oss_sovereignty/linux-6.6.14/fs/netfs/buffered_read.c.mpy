{
  "module_name": "buffered_read.c",
  "hash_id": "66b78f4e9624fbc7fd03ed63114188cca860176f95c316f226d0a0b692ec1590",
  "original_prompt": "Ingested from linux-6.6.14/fs/netfs/buffered_read.c",
  "human_readable_source": "\n \n\n#include <linux/export.h>\n#include <linux/task_io_accounting_ops.h>\n#include \"internal.h\"\n\n \nvoid netfs_rreq_unlock_folios(struct netfs_io_request *rreq)\n{\n\tstruct netfs_io_subrequest *subreq;\n\tstruct folio *folio;\n\tpgoff_t start_page = rreq->start / PAGE_SIZE;\n\tpgoff_t last_page = ((rreq->start + rreq->len) / PAGE_SIZE) - 1;\n\tsize_t account = 0;\n\tbool subreq_failed = false;\n\n\tXA_STATE(xas, &rreq->mapping->i_pages, start_page);\n\n\tif (test_bit(NETFS_RREQ_FAILED, &rreq->flags)) {\n\t\t__clear_bit(NETFS_RREQ_COPY_TO_CACHE, &rreq->flags);\n\t\tlist_for_each_entry(subreq, &rreq->subrequests, rreq_link) {\n\t\t\t__clear_bit(NETFS_SREQ_COPY_TO_CACHE, &subreq->flags);\n\t\t}\n\t}\n\n\t \n\tsubreq = list_first_entry(&rreq->subrequests,\n\t\t\t\t  struct netfs_io_subrequest, rreq_link);\n\tsubreq_failed = (subreq->error < 0);\n\n\ttrace_netfs_rreq(rreq, netfs_rreq_trace_unlock);\n\n\trcu_read_lock();\n\txas_for_each(&xas, folio, last_page) {\n\t\tloff_t pg_end;\n\t\tbool pg_failed = false;\n\t\tbool folio_started;\n\n\t\tif (xas_retry(&xas, folio))\n\t\t\tcontinue;\n\n\t\tpg_end = folio_pos(folio) + folio_size(folio) - 1;\n\n\t\tfolio_started = false;\n\t\tfor (;;) {\n\t\t\tloff_t sreq_end;\n\n\t\t\tif (!subreq) {\n\t\t\t\tpg_failed = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!folio_started && test_bit(NETFS_SREQ_COPY_TO_CACHE, &subreq->flags)) {\n\t\t\t\tfolio_start_fscache(folio);\n\t\t\t\tfolio_started = true;\n\t\t\t}\n\t\t\tpg_failed |= subreq_failed;\n\t\t\tsreq_end = subreq->start + subreq->len - 1;\n\t\t\tif (pg_end < sreq_end)\n\t\t\t\tbreak;\n\n\t\t\taccount += subreq->transferred;\n\t\t\tif (!list_is_last(&subreq->rreq_link, &rreq->subrequests)) {\n\t\t\t\tsubreq = list_next_entry(subreq, rreq_link);\n\t\t\t\tsubreq_failed = (subreq->error < 0);\n\t\t\t} else {\n\t\t\t\tsubreq = NULL;\n\t\t\t\tsubreq_failed = false;\n\t\t\t}\n\n\t\t\tif (pg_end == sreq_end)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (!pg_failed) {\n\t\t\tflush_dcache_folio(folio);\n\t\t\tfolio_mark_uptodate(folio);\n\t\t}\n\n\t\tif (!test_bit(NETFS_RREQ_DONT_UNLOCK_FOLIOS, &rreq->flags)) {\n\t\t\tif (folio_index(folio) == rreq->no_unlock_folio &&\n\t\t\t    test_bit(NETFS_RREQ_NO_UNLOCK_FOLIO, &rreq->flags))\n\t\t\t\t_debug(\"no unlock\");\n\t\t\telse\n\t\t\t\tfolio_unlock(folio);\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\ttask_io_account_read(account);\n\tif (rreq->netfs_ops->done)\n\t\trreq->netfs_ops->done(rreq);\n}\n\nstatic void netfs_cache_expand_readahead(struct netfs_io_request *rreq,\n\t\t\t\t\t loff_t *_start, size_t *_len, loff_t i_size)\n{\n\tstruct netfs_cache_resources *cres = &rreq->cache_resources;\n\n\tif (cres->ops && cres->ops->expand_readahead)\n\t\tcres->ops->expand_readahead(cres, _start, _len, i_size);\n}\n\nstatic void netfs_rreq_expand(struct netfs_io_request *rreq,\n\t\t\t      struct readahead_control *ractl)\n{\n\t \n\tnetfs_cache_expand_readahead(rreq, &rreq->start, &rreq->len, rreq->i_size);\n\n\t \n\tif (rreq->netfs_ops->expand_readahead)\n\t\trreq->netfs_ops->expand_readahead(rreq);\n\n\t \n\tif (rreq->start  != readahead_pos(ractl) ||\n\t    rreq->len != readahead_length(ractl)) {\n\t\treadahead_expand(ractl, rreq->start, rreq->len);\n\t\trreq->start  = readahead_pos(ractl);\n\t\trreq->len = readahead_length(ractl);\n\n\t\ttrace_netfs_read(rreq, readahead_pos(ractl), readahead_length(ractl),\n\t\t\t\t netfs_read_trace_expanded);\n\t}\n}\n\n \nvoid netfs_readahead(struct readahead_control *ractl)\n{\n\tstruct netfs_io_request *rreq;\n\tstruct netfs_inode *ctx = netfs_inode(ractl->mapping->host);\n\tint ret;\n\n\t_enter(\"%lx,%x\", readahead_index(ractl), readahead_count(ractl));\n\n\tif (readahead_count(ractl) == 0)\n\t\treturn;\n\n\trreq = netfs_alloc_request(ractl->mapping, ractl->file,\n\t\t\t\t   readahead_pos(ractl),\n\t\t\t\t   readahead_length(ractl),\n\t\t\t\t   NETFS_READAHEAD);\n\tif (IS_ERR(rreq))\n\t\treturn;\n\n\tif (ctx->ops->begin_cache_operation) {\n\t\tret = ctx->ops->begin_cache_operation(rreq);\n\t\tif (ret == -ENOMEM || ret == -EINTR || ret == -ERESTARTSYS)\n\t\t\tgoto cleanup_free;\n\t}\n\n\tnetfs_stat(&netfs_n_rh_readahead);\n\ttrace_netfs_read(rreq, readahead_pos(ractl), readahead_length(ractl),\n\t\t\t netfs_read_trace_readahead);\n\n\tnetfs_rreq_expand(rreq, ractl);\n\n\t \n\twhile (readahead_folio(ractl))\n\t\t;\n\n\tnetfs_begin_read(rreq, false);\n\treturn;\n\ncleanup_free:\n\tnetfs_put_request(rreq, false, netfs_rreq_trace_put_failed);\n\treturn;\n}\nEXPORT_SYMBOL(netfs_readahead);\n\n \nint netfs_read_folio(struct file *file, struct folio *folio)\n{\n\tstruct address_space *mapping = folio_file_mapping(folio);\n\tstruct netfs_io_request *rreq;\n\tstruct netfs_inode *ctx = netfs_inode(mapping->host);\n\tint ret;\n\n\t_enter(\"%lx\", folio_index(folio));\n\n\trreq = netfs_alloc_request(mapping, file,\n\t\t\t\t   folio_file_pos(folio), folio_size(folio),\n\t\t\t\t   NETFS_READPAGE);\n\tif (IS_ERR(rreq)) {\n\t\tret = PTR_ERR(rreq);\n\t\tgoto alloc_error;\n\t}\n\n\tif (ctx->ops->begin_cache_operation) {\n\t\tret = ctx->ops->begin_cache_operation(rreq);\n\t\tif (ret == -ENOMEM || ret == -EINTR || ret == -ERESTARTSYS)\n\t\t\tgoto discard;\n\t}\n\n\tnetfs_stat(&netfs_n_rh_readpage);\n\ttrace_netfs_read(rreq, rreq->start, rreq->len, netfs_read_trace_readpage);\n\treturn netfs_begin_read(rreq, true);\n\ndiscard:\n\tnetfs_put_request(rreq, false, netfs_rreq_trace_put_discard);\nalloc_error:\n\tfolio_unlock(folio);\n\treturn ret;\n}\nEXPORT_SYMBOL(netfs_read_folio);\n\n \nstatic bool netfs_skip_folio_read(struct folio *folio, loff_t pos, size_t len,\n\t\t\t\t bool always_fill)\n{\n\tstruct inode *inode = folio_inode(folio);\n\tloff_t i_size = i_size_read(inode);\n\tsize_t offset = offset_in_folio(folio, pos);\n\tsize_t plen = folio_size(folio);\n\n\tif (unlikely(always_fill)) {\n\t\tif (pos - offset + len <= i_size)\n\t\t\treturn false;  \n\t\tzero_user_segment(&folio->page, 0, plen);\n\t\tfolio_mark_uptodate(folio);\n\t\treturn true;\n\t}\n\n\t \n\tif (offset == 0 && len >= plen)\n\t\treturn true;\n\n\t \n\tif (pos - offset >= i_size)\n\t\tgoto zero_out;\n\n\t \n\tif (offset == 0 && (pos + len) >= i_size)\n\t\tgoto zero_out;\n\n\treturn false;\nzero_out:\n\tzero_user_segments(&folio->page, 0, offset, offset + len, plen);\n\treturn true;\n}\n\n \nint netfs_write_begin(struct netfs_inode *ctx,\n\t\t      struct file *file, struct address_space *mapping,\n\t\t      loff_t pos, unsigned int len, struct folio **_folio,\n\t\t      void **_fsdata)\n{\n\tstruct netfs_io_request *rreq;\n\tstruct folio *folio;\n\tpgoff_t index = pos >> PAGE_SHIFT;\n\tint ret;\n\n\tDEFINE_READAHEAD(ractl, file, NULL, mapping, index);\n\nretry:\n\tfolio = __filemap_get_folio(mapping, index, FGP_WRITEBEGIN,\n\t\t\t\t    mapping_gfp_mask(mapping));\n\tif (IS_ERR(folio))\n\t\treturn PTR_ERR(folio);\n\n\tif (ctx->ops->check_write_begin) {\n\t\t \n\t\tret = ctx->ops->check_write_begin(file, pos, len, &folio, _fsdata);\n\t\tif (ret < 0) {\n\t\t\ttrace_netfs_failure(NULL, NULL, ret, netfs_fail_check_write_begin);\n\t\t\tgoto error;\n\t\t}\n\t\tif (!folio)\n\t\t\tgoto retry;\n\t}\n\n\tif (folio_test_uptodate(folio))\n\t\tgoto have_folio;\n\n\t \n\tif (!netfs_is_cache_enabled(ctx) &&\n\t    netfs_skip_folio_read(folio, pos, len, false)) {\n\t\tnetfs_stat(&netfs_n_rh_write_zskip);\n\t\tgoto have_folio_no_wait;\n\t}\n\n\trreq = netfs_alloc_request(mapping, file,\n\t\t\t\t   folio_file_pos(folio), folio_size(folio),\n\t\t\t\t   NETFS_READ_FOR_WRITE);\n\tif (IS_ERR(rreq)) {\n\t\tret = PTR_ERR(rreq);\n\t\tgoto error;\n\t}\n\trreq->no_unlock_folio\t= folio_index(folio);\n\t__set_bit(NETFS_RREQ_NO_UNLOCK_FOLIO, &rreq->flags);\n\n\tif (ctx->ops->begin_cache_operation) {\n\t\tret = ctx->ops->begin_cache_operation(rreq);\n\t\tif (ret == -ENOMEM || ret == -EINTR || ret == -ERESTARTSYS)\n\t\t\tgoto error_put;\n\t}\n\n\tnetfs_stat(&netfs_n_rh_write_begin);\n\ttrace_netfs_read(rreq, pos, len, netfs_read_trace_write_begin);\n\n\t \n\tractl._nr_pages = folio_nr_pages(folio);\n\tnetfs_rreq_expand(rreq, &ractl);\n\n\t \n\tfolio_get(folio);\n\twhile (readahead_folio(&ractl))\n\t\t;\n\n\tret = netfs_begin_read(rreq, true);\n\tif (ret < 0)\n\t\tgoto error;\n\nhave_folio:\n\tret = folio_wait_fscache_killable(folio);\n\tif (ret < 0)\n\t\tgoto error;\nhave_folio_no_wait:\n\t*_folio = folio;\n\t_leave(\" = 0\");\n\treturn 0;\n\nerror_put:\n\tnetfs_put_request(rreq, false, netfs_rreq_trace_put_failed);\nerror:\n\tif (folio) {\n\t\tfolio_unlock(folio);\n\t\tfolio_put(folio);\n\t}\n\t_leave(\" = %d\", ret);\n\treturn ret;\n}\nEXPORT_SYMBOL(netfs_write_begin);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}