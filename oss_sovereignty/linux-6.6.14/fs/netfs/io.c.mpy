{
  "module_name": "io.c",
  "hash_id": "146ccdeca02646c03119174391a4e54585d111fc80d3850c48acae80af6244a5",
  "original_prompt": "Ingested from linux-6.6.14/fs/netfs/io.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/export.h>\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include <linux/pagemap.h>\n#include <linux/slab.h>\n#include <linux/uio.h>\n#include <linux/sched/mm.h>\n#include <linux/task_io_accounting_ops.h>\n#include \"internal.h\"\n\n \nstatic void netfs_clear_unread(struct netfs_io_subrequest *subreq)\n{\n\tstruct iov_iter iter;\n\n\tiov_iter_xarray(&iter, ITER_DEST, &subreq->rreq->mapping->i_pages,\n\t\t\tsubreq->start + subreq->transferred,\n\t\t\tsubreq->len   - subreq->transferred);\n\tiov_iter_zero(iov_iter_count(&iter), &iter);\n}\n\nstatic void netfs_cache_read_terminated(void *priv, ssize_t transferred_or_error,\n\t\t\t\t\tbool was_async)\n{\n\tstruct netfs_io_subrequest *subreq = priv;\n\n\tnetfs_subreq_terminated(subreq, transferred_or_error, was_async);\n}\n\n \nstatic void netfs_read_from_cache(struct netfs_io_request *rreq,\n\t\t\t\t  struct netfs_io_subrequest *subreq,\n\t\t\t\t  enum netfs_read_from_hole read_hole)\n{\n\tstruct netfs_cache_resources *cres = &rreq->cache_resources;\n\tstruct iov_iter iter;\n\n\tnetfs_stat(&netfs_n_rh_read);\n\tiov_iter_xarray(&iter, ITER_DEST, &rreq->mapping->i_pages,\n\t\t\tsubreq->start + subreq->transferred,\n\t\t\tsubreq->len   - subreq->transferred);\n\n\tcres->ops->read(cres, subreq->start, &iter, read_hole,\n\t\t\tnetfs_cache_read_terminated, subreq);\n}\n\n \nstatic void netfs_fill_with_zeroes(struct netfs_io_request *rreq,\n\t\t\t\t   struct netfs_io_subrequest *subreq)\n{\n\tnetfs_stat(&netfs_n_rh_zero);\n\t__set_bit(NETFS_SREQ_CLEAR_TAIL, &subreq->flags);\n\tnetfs_subreq_terminated(subreq, 0, false);\n}\n\n \nstatic void netfs_read_from_server(struct netfs_io_request *rreq,\n\t\t\t\t   struct netfs_io_subrequest *subreq)\n{\n\tnetfs_stat(&netfs_n_rh_download);\n\trreq->netfs_ops->issue_read(subreq);\n}\n\n \nstatic void netfs_rreq_completed(struct netfs_io_request *rreq, bool was_async)\n{\n\ttrace_netfs_rreq(rreq, netfs_rreq_trace_done);\n\tnetfs_clear_subrequests(rreq, was_async);\n\tnetfs_put_request(rreq, was_async, netfs_rreq_trace_put_complete);\n}\n\n \nstatic void netfs_rreq_unmark_after_write(struct netfs_io_request *rreq,\n\t\t\t\t\t  bool was_async)\n{\n\tstruct netfs_io_subrequest *subreq;\n\tstruct folio *folio;\n\tpgoff_t unlocked = 0;\n\tbool have_unlocked = false;\n\n\trcu_read_lock();\n\n\tlist_for_each_entry(subreq, &rreq->subrequests, rreq_link) {\n\t\tXA_STATE(xas, &rreq->mapping->i_pages, subreq->start / PAGE_SIZE);\n\n\t\txas_for_each(&xas, folio, (subreq->start + subreq->len - 1) / PAGE_SIZE) {\n\t\t\tif (xas_retry(&xas, folio))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (have_unlocked && folio_index(folio) <= unlocked)\n\t\t\t\tcontinue;\n\t\t\tunlocked = folio_index(folio);\n\t\t\tfolio_end_fscache(folio);\n\t\t\thave_unlocked = true;\n\t\t}\n\t}\n\n\trcu_read_unlock();\n\tnetfs_rreq_completed(rreq, was_async);\n}\n\nstatic void netfs_rreq_copy_terminated(void *priv, ssize_t transferred_or_error,\n\t\t\t\t       bool was_async)\n{\n\tstruct netfs_io_subrequest *subreq = priv;\n\tstruct netfs_io_request *rreq = subreq->rreq;\n\n\tif (IS_ERR_VALUE(transferred_or_error)) {\n\t\tnetfs_stat(&netfs_n_rh_write_failed);\n\t\ttrace_netfs_failure(rreq, subreq, transferred_or_error,\n\t\t\t\t    netfs_fail_copy_to_cache);\n\t} else {\n\t\tnetfs_stat(&netfs_n_rh_write_done);\n\t}\n\n\ttrace_netfs_sreq(subreq, netfs_sreq_trace_write_term);\n\n\t \n\tif (atomic_dec_and_test(&rreq->nr_copy_ops))\n\t\tnetfs_rreq_unmark_after_write(rreq, was_async);\n\n\tnetfs_put_subrequest(subreq, was_async, netfs_sreq_trace_put_terminated);\n}\n\n \nstatic void netfs_rreq_do_write_to_cache(struct netfs_io_request *rreq)\n{\n\tstruct netfs_cache_resources *cres = &rreq->cache_resources;\n\tstruct netfs_io_subrequest *subreq, *next, *p;\n\tstruct iov_iter iter;\n\tint ret;\n\n\ttrace_netfs_rreq(rreq, netfs_rreq_trace_copy);\n\n\t \n\tatomic_inc(&rreq->nr_copy_ops);\n\n\tlist_for_each_entry_safe(subreq, p, &rreq->subrequests, rreq_link) {\n\t\tif (!test_bit(NETFS_SREQ_COPY_TO_CACHE, &subreq->flags)) {\n\t\t\tlist_del_init(&subreq->rreq_link);\n\t\t\tnetfs_put_subrequest(subreq, false,\n\t\t\t\t\t     netfs_sreq_trace_put_no_copy);\n\t\t}\n\t}\n\n\tlist_for_each_entry(subreq, &rreq->subrequests, rreq_link) {\n\t\t \n\t\twhile (!list_is_last(&subreq->rreq_link, &rreq->subrequests)) {\n\t\t\tnext = list_next_entry(subreq, rreq_link);\n\t\t\tif (next->start != subreq->start + subreq->len)\n\t\t\t\tbreak;\n\t\t\tsubreq->len += next->len;\n\t\t\tlist_del_init(&next->rreq_link);\n\t\t\tnetfs_put_subrequest(next, false,\n\t\t\t\t\t     netfs_sreq_trace_put_merged);\n\t\t}\n\n\t\tret = cres->ops->prepare_write(cres, &subreq->start, &subreq->len,\n\t\t\t\t\t       rreq->i_size, true);\n\t\tif (ret < 0) {\n\t\t\ttrace_netfs_failure(rreq, subreq, ret, netfs_fail_prepare_write);\n\t\t\ttrace_netfs_sreq(subreq, netfs_sreq_trace_write_skip);\n\t\t\tcontinue;\n\t\t}\n\n\t\tiov_iter_xarray(&iter, ITER_SOURCE, &rreq->mapping->i_pages,\n\t\t\t\tsubreq->start, subreq->len);\n\n\t\tatomic_inc(&rreq->nr_copy_ops);\n\t\tnetfs_stat(&netfs_n_rh_write);\n\t\tnetfs_get_subrequest(subreq, netfs_sreq_trace_get_copy_to_cache);\n\t\ttrace_netfs_sreq(subreq, netfs_sreq_trace_write);\n\t\tcres->ops->write(cres, subreq->start, &iter,\n\t\t\t\t netfs_rreq_copy_terminated, subreq);\n\t}\n\n\t \n\tif (atomic_dec_and_test(&rreq->nr_copy_ops))\n\t\tnetfs_rreq_unmark_after_write(rreq, false);\n}\n\nstatic void netfs_rreq_write_to_cache_work(struct work_struct *work)\n{\n\tstruct netfs_io_request *rreq =\n\t\tcontainer_of(work, struct netfs_io_request, work);\n\n\tnetfs_rreq_do_write_to_cache(rreq);\n}\n\nstatic void netfs_rreq_write_to_cache(struct netfs_io_request *rreq)\n{\n\trreq->work.func = netfs_rreq_write_to_cache_work;\n\tif (!queue_work(system_unbound_wq, &rreq->work))\n\t\tBUG();\n}\n\n \nstatic void netfs_rreq_short_read(struct netfs_io_request *rreq,\n\t\t\t\t  struct netfs_io_subrequest *subreq)\n{\n\t__clear_bit(NETFS_SREQ_SHORT_IO, &subreq->flags);\n\t__set_bit(NETFS_SREQ_SEEK_DATA_READ, &subreq->flags);\n\n\tnetfs_stat(&netfs_n_rh_short_read);\n\ttrace_netfs_sreq(subreq, netfs_sreq_trace_resubmit_short);\n\n\tnetfs_get_subrequest(subreq, netfs_sreq_trace_get_short_read);\n\tatomic_inc(&rreq->nr_outstanding);\n\tif (subreq->source == NETFS_READ_FROM_CACHE)\n\t\tnetfs_read_from_cache(rreq, subreq, NETFS_READ_HOLE_CLEAR);\n\telse\n\t\tnetfs_read_from_server(rreq, subreq);\n}\n\n \nstatic bool netfs_rreq_perform_resubmissions(struct netfs_io_request *rreq)\n{\n\tstruct netfs_io_subrequest *subreq;\n\n\tWARN_ON(in_interrupt());\n\n\ttrace_netfs_rreq(rreq, netfs_rreq_trace_resubmit);\n\n\t \n\tatomic_inc(&rreq->nr_outstanding);\n\n\t__clear_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags);\n\tlist_for_each_entry(subreq, &rreq->subrequests, rreq_link) {\n\t\tif (subreq->error) {\n\t\t\tif (subreq->source != NETFS_READ_FROM_CACHE)\n\t\t\t\tbreak;\n\t\t\tsubreq->source = NETFS_DOWNLOAD_FROM_SERVER;\n\t\t\tsubreq->error = 0;\n\t\t\tnetfs_stat(&netfs_n_rh_download_instead);\n\t\t\ttrace_netfs_sreq(subreq, netfs_sreq_trace_download_instead);\n\t\t\tnetfs_get_subrequest(subreq, netfs_sreq_trace_get_resubmit);\n\t\t\tatomic_inc(&rreq->nr_outstanding);\n\t\t\tnetfs_read_from_server(rreq, subreq);\n\t\t} else if (test_bit(NETFS_SREQ_SHORT_IO, &subreq->flags)) {\n\t\t\tnetfs_rreq_short_read(rreq, subreq);\n\t\t}\n\t}\n\n\t \n\tif (atomic_dec_and_test(&rreq->nr_outstanding))\n\t\treturn true;\n\n\twake_up_var(&rreq->nr_outstanding);\n\treturn false;\n}\n\n \nstatic void netfs_rreq_is_still_valid(struct netfs_io_request *rreq)\n{\n\tstruct netfs_io_subrequest *subreq;\n\n\tif (!rreq->netfs_ops->is_still_valid ||\n\t    rreq->netfs_ops->is_still_valid(rreq))\n\t\treturn;\n\n\tlist_for_each_entry(subreq, &rreq->subrequests, rreq_link) {\n\t\tif (subreq->source == NETFS_READ_FROM_CACHE) {\n\t\t\tsubreq->error = -ESTALE;\n\t\t\t__set_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags);\n\t\t}\n\t}\n}\n\n \nstatic void netfs_rreq_assess(struct netfs_io_request *rreq, bool was_async)\n{\n\ttrace_netfs_rreq(rreq, netfs_rreq_trace_assess);\n\nagain:\n\tnetfs_rreq_is_still_valid(rreq);\n\n\tif (!test_bit(NETFS_RREQ_FAILED, &rreq->flags) &&\n\t    test_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags)) {\n\t\tif (netfs_rreq_perform_resubmissions(rreq))\n\t\t\tgoto again;\n\t\treturn;\n\t}\n\n\tnetfs_rreq_unlock_folios(rreq);\n\n\tclear_bit_unlock(NETFS_RREQ_IN_PROGRESS, &rreq->flags);\n\twake_up_bit(&rreq->flags, NETFS_RREQ_IN_PROGRESS);\n\n\tif (test_bit(NETFS_RREQ_COPY_TO_CACHE, &rreq->flags))\n\t\treturn netfs_rreq_write_to_cache(rreq);\n\n\tnetfs_rreq_completed(rreq, was_async);\n}\n\nstatic void netfs_rreq_work(struct work_struct *work)\n{\n\tstruct netfs_io_request *rreq =\n\t\tcontainer_of(work, struct netfs_io_request, work);\n\tnetfs_rreq_assess(rreq, false);\n}\n\n \nstatic void netfs_rreq_terminated(struct netfs_io_request *rreq,\n\t\t\t\t  bool was_async)\n{\n\tif (test_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags) &&\n\t    was_async) {\n\t\tif (!queue_work(system_unbound_wq, &rreq->work))\n\t\t\tBUG();\n\t} else {\n\t\tnetfs_rreq_assess(rreq, was_async);\n\t}\n}\n\n \nvoid netfs_subreq_terminated(struct netfs_io_subrequest *subreq,\n\t\t\t     ssize_t transferred_or_error,\n\t\t\t     bool was_async)\n{\n\tstruct netfs_io_request *rreq = subreq->rreq;\n\tint u;\n\n\t_enter(\"[%u]{%llx,%lx},%zd\",\n\t       subreq->debug_index, subreq->start, subreq->flags,\n\t       transferred_or_error);\n\n\tswitch (subreq->source) {\n\tcase NETFS_READ_FROM_CACHE:\n\t\tnetfs_stat(&netfs_n_rh_read_done);\n\t\tbreak;\n\tcase NETFS_DOWNLOAD_FROM_SERVER:\n\t\tnetfs_stat(&netfs_n_rh_download_done);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (IS_ERR_VALUE(transferred_or_error)) {\n\t\tsubreq->error = transferred_or_error;\n\t\ttrace_netfs_failure(rreq, subreq, transferred_or_error,\n\t\t\t\t    netfs_fail_read);\n\t\tgoto failed;\n\t}\n\n\tif (WARN(transferred_or_error > subreq->len - subreq->transferred,\n\t\t \"Subreq overread: R%x[%x] %zd > %zu - %zu\",\n\t\t rreq->debug_id, subreq->debug_index,\n\t\t transferred_or_error, subreq->len, subreq->transferred))\n\t\ttransferred_or_error = subreq->len - subreq->transferred;\n\n\tsubreq->error = 0;\n\tsubreq->transferred += transferred_or_error;\n\tif (subreq->transferred < subreq->len)\n\t\tgoto incomplete;\n\ncomplete:\n\t__clear_bit(NETFS_SREQ_NO_PROGRESS, &subreq->flags);\n\tif (test_bit(NETFS_SREQ_COPY_TO_CACHE, &subreq->flags))\n\t\tset_bit(NETFS_RREQ_COPY_TO_CACHE, &rreq->flags);\n\nout:\n\ttrace_netfs_sreq(subreq, netfs_sreq_trace_terminated);\n\n\t \n\tu = atomic_dec_return(&rreq->nr_outstanding);\n\tif (u == 0)\n\t\tnetfs_rreq_terminated(rreq, was_async);\n\telse if (u == 1)\n\t\twake_up_var(&rreq->nr_outstanding);\n\n\tnetfs_put_subrequest(subreq, was_async, netfs_sreq_trace_put_terminated);\n\treturn;\n\nincomplete:\n\tif (test_bit(NETFS_SREQ_CLEAR_TAIL, &subreq->flags)) {\n\t\tnetfs_clear_unread(subreq);\n\t\tsubreq->transferred = subreq->len;\n\t\tgoto complete;\n\t}\n\n\tif (transferred_or_error == 0) {\n\t\tif (__test_and_set_bit(NETFS_SREQ_NO_PROGRESS, &subreq->flags)) {\n\t\t\tsubreq->error = -ENODATA;\n\t\t\tgoto failed;\n\t\t}\n\t} else {\n\t\t__clear_bit(NETFS_SREQ_NO_PROGRESS, &subreq->flags);\n\t}\n\n\t__set_bit(NETFS_SREQ_SHORT_IO, &subreq->flags);\n\tset_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags);\n\tgoto out;\n\nfailed:\n\tif (subreq->source == NETFS_READ_FROM_CACHE) {\n\t\tnetfs_stat(&netfs_n_rh_read_failed);\n\t\tset_bit(NETFS_RREQ_INCOMPLETE_IO, &rreq->flags);\n\t} else {\n\t\tnetfs_stat(&netfs_n_rh_download_failed);\n\t\tset_bit(NETFS_RREQ_FAILED, &rreq->flags);\n\t\trreq->error = subreq->error;\n\t}\n\tgoto out;\n}\nEXPORT_SYMBOL(netfs_subreq_terminated);\n\nstatic enum netfs_io_source netfs_cache_prepare_read(struct netfs_io_subrequest *subreq,\n\t\t\t\t\t\t       loff_t i_size)\n{\n\tstruct netfs_io_request *rreq = subreq->rreq;\n\tstruct netfs_cache_resources *cres = &rreq->cache_resources;\n\n\tif (cres->ops)\n\t\treturn cres->ops->prepare_read(subreq, i_size);\n\tif (subreq->start >= rreq->i_size)\n\t\treturn NETFS_FILL_WITH_ZEROES;\n\treturn NETFS_DOWNLOAD_FROM_SERVER;\n}\n\n \nstatic enum netfs_io_source\nnetfs_rreq_prepare_read(struct netfs_io_request *rreq,\n\t\t\tstruct netfs_io_subrequest *subreq)\n{\n\tenum netfs_io_source source;\n\n\t_enter(\"%llx-%llx,%llx\", subreq->start, subreq->start + subreq->len, rreq->i_size);\n\n\tsource = netfs_cache_prepare_read(subreq, rreq->i_size);\n\tif (source == NETFS_INVALID_READ)\n\t\tgoto out;\n\n\tif (source == NETFS_DOWNLOAD_FROM_SERVER) {\n\t\t \n\t\tif (subreq->len > rreq->i_size - subreq->start)\n\t\t\tsubreq->len = rreq->i_size - subreq->start;\n\n\t\tif (rreq->netfs_ops->clamp_length &&\n\t\t    !rreq->netfs_ops->clamp_length(subreq)) {\n\t\t\tsource = NETFS_INVALID_READ;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (WARN_ON(subreq->len == 0))\n\t\tsource = NETFS_INVALID_READ;\n\nout:\n\tsubreq->source = source;\n\ttrace_netfs_sreq(subreq, netfs_sreq_trace_prepare);\n\treturn source;\n}\n\n \nstatic bool netfs_rreq_submit_slice(struct netfs_io_request *rreq,\n\t\t\t\t    unsigned int *_debug_index)\n{\n\tstruct netfs_io_subrequest *subreq;\n\tenum netfs_io_source source;\n\n\tsubreq = netfs_alloc_subrequest(rreq);\n\tif (!subreq)\n\t\treturn false;\n\n\tsubreq->debug_index\t= (*_debug_index)++;\n\tsubreq->start\t\t= rreq->start + rreq->submitted;\n\tsubreq->len\t\t= rreq->len   - rreq->submitted;\n\n\t_debug(\"slice %llx,%zx,%zx\", subreq->start, subreq->len, rreq->submitted);\n\tlist_add_tail(&subreq->rreq_link, &rreq->subrequests);\n\n\t \n\tsource = netfs_rreq_prepare_read(rreq, subreq);\n\tif (source == NETFS_INVALID_READ)\n\t\tgoto subreq_failed;\n\n\tatomic_inc(&rreq->nr_outstanding);\n\n\trreq->submitted += subreq->len;\n\n\ttrace_netfs_sreq(subreq, netfs_sreq_trace_submit);\n\tswitch (source) {\n\tcase NETFS_FILL_WITH_ZEROES:\n\t\tnetfs_fill_with_zeroes(rreq, subreq);\n\t\tbreak;\n\tcase NETFS_DOWNLOAD_FROM_SERVER:\n\t\tnetfs_read_from_server(rreq, subreq);\n\t\tbreak;\n\tcase NETFS_READ_FROM_CACHE:\n\t\tnetfs_read_from_cache(rreq, subreq, NETFS_READ_HOLE_IGNORE);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn true;\n\nsubreq_failed:\n\trreq->error = subreq->error;\n\tnetfs_put_subrequest(subreq, false, netfs_sreq_trace_put_failed);\n\treturn false;\n}\n\n \nint netfs_begin_read(struct netfs_io_request *rreq, bool sync)\n{\n\tunsigned int debug_index = 0;\n\tint ret;\n\n\t_enter(\"R=%x %llx-%llx\",\n\t       rreq->debug_id, rreq->start, rreq->start + rreq->len - 1);\n\n\tif (rreq->len == 0) {\n\t\tpr_err(\"Zero-sized read [R=%x]\\n\", rreq->debug_id);\n\t\tnetfs_put_request(rreq, false, netfs_rreq_trace_put_zero_len);\n\t\treturn -EIO;\n\t}\n\n\tINIT_WORK(&rreq->work, netfs_rreq_work);\n\n\tif (sync)\n\t\tnetfs_get_request(rreq, netfs_rreq_trace_get_hold);\n\n\t \n\tatomic_set(&rreq->nr_outstanding, 1);\n\tdo {\n\t\tif (!netfs_rreq_submit_slice(rreq, &debug_index))\n\t\t\tbreak;\n\n\t} while (rreq->submitted < rreq->len);\n\n\tif (sync) {\n\t\t \n\t\tfor (;;) {\n\t\t\twait_var_event(&rreq->nr_outstanding,\n\t\t\t\t       atomic_read(&rreq->nr_outstanding) == 1);\n\t\t\tnetfs_rreq_assess(rreq, false);\n\t\t\tif (!test_bit(NETFS_RREQ_IN_PROGRESS, &rreq->flags))\n\t\t\t\tbreak;\n\t\t\tcond_resched();\n\t\t}\n\n\t\tret = rreq->error;\n\t\tif (ret == 0 && rreq->submitted < rreq->len) {\n\t\t\ttrace_netfs_failure(rreq, NULL, ret, netfs_fail_short_read);\n\t\t\tret = -EIO;\n\t\t}\n\t\tnetfs_put_request(rreq, false, netfs_rreq_trace_put_hold);\n\t} else {\n\t\t \n\t\tif (atomic_dec_and_test(&rreq->nr_outstanding))\n\t\t\tnetfs_rreq_assess(rreq, false);\n\t\tret = 0;\n\t}\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}