{
  "module_name": "inode.c",
  "hash_id": "dca75b90db12c1f81cda52841cdffcc19b92d54229d03de0a49dc746e4121cb3",
  "original_prompt": "Ingested from linux-6.6.14/fs/ext2/inode.c",
  "human_readable_source": "\n \n\n#include <linux/time.h>\n#include <linux/highuid.h>\n#include <linux/pagemap.h>\n#include <linux/dax.h>\n#include <linux/blkdev.h>\n#include <linux/quotaops.h>\n#include <linux/writeback.h>\n#include <linux/buffer_head.h>\n#include <linux/mpage.h>\n#include <linux/fiemap.h>\n#include <linux/iomap.h>\n#include <linux/namei.h>\n#include <linux/uio.h>\n#include \"ext2.h\"\n#include \"acl.h\"\n#include \"xattr.h\"\n\nstatic int __ext2_write_inode(struct inode *inode, int do_sync);\n\n \nstatic inline int ext2_inode_is_fast_symlink(struct inode *inode)\n{\n\tint ea_blocks = EXT2_I(inode)->i_file_acl ?\n\t\t(inode->i_sb->s_blocksize >> 9) : 0;\n\n\treturn (S_ISLNK(inode->i_mode) &&\n\t\tinode->i_blocks - ea_blocks == 0);\n}\n\nstatic void ext2_truncate_blocks(struct inode *inode, loff_t offset);\n\nvoid ext2_write_failed(struct address_space *mapping, loff_t to)\n{\n\tstruct inode *inode = mapping->host;\n\n\tif (to > inode->i_size) {\n\t\ttruncate_pagecache(inode, inode->i_size);\n\t\text2_truncate_blocks(inode, inode->i_size);\n\t}\n}\n\n \nvoid ext2_evict_inode(struct inode * inode)\n{\n\tstruct ext2_block_alloc_info *rsv;\n\tint want_delete = 0;\n\n\tif (!inode->i_nlink && !is_bad_inode(inode)) {\n\t\twant_delete = 1;\n\t\tdquot_initialize(inode);\n\t} else {\n\t\tdquot_drop(inode);\n\t}\n\n\ttruncate_inode_pages_final(&inode->i_data);\n\n\tif (want_delete) {\n\t\tsb_start_intwrite(inode->i_sb);\n\t\t \n\t\tEXT2_I(inode)->i_dtime\t= ktime_get_real_seconds();\n\t\tmark_inode_dirty(inode);\n\t\t__ext2_write_inode(inode, inode_needs_sync(inode));\n\t\t \n\t\tinode->i_size = 0;\n\t\tif (inode->i_blocks)\n\t\t\text2_truncate_blocks(inode, 0);\n\t\text2_xattr_delete_inode(inode);\n\t}\n\n\tinvalidate_inode_buffers(inode);\n\tclear_inode(inode);\n\n\text2_discard_reservation(inode);\n\trsv = EXT2_I(inode)->i_block_alloc_info;\n\tEXT2_I(inode)->i_block_alloc_info = NULL;\n\tif (unlikely(rsv))\n\t\tkfree(rsv);\n\n\tif (want_delete) {\n\t\text2_free_inode(inode);\n\t\tsb_end_intwrite(inode->i_sb);\n\t}\n}\n\ntypedef struct {\n\t__le32\t*p;\n\t__le32\tkey;\n\tstruct buffer_head *bh;\n} Indirect;\n\nstatic inline void add_chain(Indirect *p, struct buffer_head *bh, __le32 *v)\n{\n\tp->key = *(p->p = v);\n\tp->bh = bh;\n}\n\nstatic inline int verify_chain(Indirect *from, Indirect *to)\n{\n\twhile (from <= to && from->key == *from->p)\n\t\tfrom++;\n\treturn (from > to);\n}\n\n \n\n \n\nstatic int ext2_block_to_path(struct inode *inode,\n\t\t\tlong i_block, int offsets[4], int *boundary)\n{\n\tint ptrs = EXT2_ADDR_PER_BLOCK(inode->i_sb);\n\tint ptrs_bits = EXT2_ADDR_PER_BLOCK_BITS(inode->i_sb);\n\tconst long direct_blocks = EXT2_NDIR_BLOCKS,\n\t\tindirect_blocks = ptrs,\n\t\tdouble_blocks = (1 << (ptrs_bits * 2));\n\tint n = 0;\n\tint final = 0;\n\n\tif (i_block < 0) {\n\t\text2_msg(inode->i_sb, KERN_WARNING,\n\t\t\t\"warning: %s: block < 0\", __func__);\n\t} else if (i_block < direct_blocks) {\n\t\toffsets[n++] = i_block;\n\t\tfinal = direct_blocks;\n\t} else if ( (i_block -= direct_blocks) < indirect_blocks) {\n\t\toffsets[n++] = EXT2_IND_BLOCK;\n\t\toffsets[n++] = i_block;\n\t\tfinal = ptrs;\n\t} else if ((i_block -= indirect_blocks) < double_blocks) {\n\t\toffsets[n++] = EXT2_DIND_BLOCK;\n\t\toffsets[n++] = i_block >> ptrs_bits;\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else if (((i_block -= double_blocks) >> (ptrs_bits * 2)) < ptrs) {\n\t\toffsets[n++] = EXT2_TIND_BLOCK;\n\t\toffsets[n++] = i_block >> (ptrs_bits * 2);\n\t\toffsets[n++] = (i_block >> ptrs_bits) & (ptrs - 1);\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else {\n\t\text2_msg(inode->i_sb, KERN_WARNING,\n\t\t\t\"warning: %s: block is too big\", __func__);\n\t}\n\tif (boundary)\n\t\t*boundary = final - 1 - (i_block & (ptrs - 1));\n\n\treturn n;\n}\n\n \nstatic Indirect *ext2_get_branch(struct inode *inode,\n\t\t\t\t int depth,\n\t\t\t\t int *offsets,\n\t\t\t\t Indirect chain[4],\n\t\t\t\t int *err)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tIndirect *p = chain;\n\tstruct buffer_head *bh;\n\n\t*err = 0;\n\t \n\tadd_chain (chain, NULL, EXT2_I(inode)->i_data + *offsets);\n\tif (!p->key)\n\t\tgoto no_block;\n\twhile (--depth) {\n\t\tbh = sb_bread(sb, le32_to_cpu(p->key));\n\t\tif (!bh)\n\t\t\tgoto failure;\n\t\tread_lock(&EXT2_I(inode)->i_meta_lock);\n\t\tif (!verify_chain(chain, p))\n\t\t\tgoto changed;\n\t\tadd_chain(++p, bh, (__le32*)bh->b_data + *++offsets);\n\t\tread_unlock(&EXT2_I(inode)->i_meta_lock);\n\t\tif (!p->key)\n\t\t\tgoto no_block;\n\t}\n\treturn NULL;\n\nchanged:\n\tread_unlock(&EXT2_I(inode)->i_meta_lock);\n\tbrelse(bh);\n\t*err = -EAGAIN;\n\tgoto no_block;\nfailure:\n\t*err = -EIO;\nno_block:\n\treturn p;\n}\n\n \n\nstatic ext2_fsblk_t ext2_find_near(struct inode *inode, Indirect *ind)\n{\n\tstruct ext2_inode_info *ei = EXT2_I(inode);\n\t__le32 *start = ind->bh ? (__le32 *) ind->bh->b_data : ei->i_data;\n\t__le32 *p;\n\text2_fsblk_t bg_start;\n\text2_fsblk_t colour;\n\n\t \n\tfor (p = ind->p - 1; p >= start; p--)\n\t\tif (*p)\n\t\t\treturn le32_to_cpu(*p);\n\n\t \n\tif (ind->bh)\n\t\treturn ind->bh->b_blocknr;\n\n\t \n\tbg_start = ext2_group_first_block_no(inode->i_sb, ei->i_block_group);\n\tcolour = (current->pid % 16) *\n\t\t\t(EXT2_BLOCKS_PER_GROUP(inode->i_sb) / 16);\n\treturn bg_start + colour;\n}\n\n \n\nstatic inline ext2_fsblk_t ext2_find_goal(struct inode *inode, long block,\n\t\t\t\t\t  Indirect *partial)\n{\n\tstruct ext2_block_alloc_info *block_i;\n\n\tblock_i = EXT2_I(inode)->i_block_alloc_info;\n\n\t \n\tif (block_i && (block == block_i->last_alloc_logical_block + 1)\n\t\t&& (block_i->last_alloc_physical_block != 0)) {\n\t\treturn block_i->last_alloc_physical_block + 1;\n\t}\n\n\treturn ext2_find_near(inode, partial);\n}\n\n \nstatic int\next2_blks_to_allocate(Indirect * branch, int k, unsigned long blks,\n\t\tint blocks_to_boundary)\n{\n\tunsigned long count = 0;\n\n\t \n\tif (k > 0) {\n\t\t \n\t\tif (blks < blocks_to_boundary + 1)\n\t\t\tcount += blks;\n\t\telse\n\t\t\tcount += blocks_to_boundary + 1;\n\t\treturn count;\n\t}\n\n\tcount++;\n\twhile (count < blks && count <= blocks_to_boundary\n\t\t&& le32_to_cpu(*(branch[0].p + count)) == 0) {\n\t\tcount++;\n\t}\n\treturn count;\n}\n\n \nstatic int ext2_alloc_blocks(struct inode *inode,\n\t\t\text2_fsblk_t goal, int indirect_blks, int blks,\n\t\t\text2_fsblk_t new_blocks[4], int *err)\n{\n\tint target, i;\n\tunsigned long count = 0;\n\tint index = 0;\n\text2_fsblk_t current_block = 0;\n\tint ret = 0;\n\n\t \n\ttarget = blks + indirect_blks;\n\n\twhile (1) {\n\t\tcount = target;\n\t\t \n\t\tcurrent_block = ext2_new_blocks(inode, goal, &count, err, 0);\n\t\tif (*err)\n\t\t\tgoto failed_out;\n\n\t\ttarget -= count;\n\t\t \n\t\twhile (index < indirect_blks && count) {\n\t\t\tnew_blocks[index++] = current_block++;\n\t\t\tcount--;\n\t\t}\n\n\t\tif (count > 0)\n\t\t\tbreak;\n\t}\n\n\t \n\tnew_blocks[index] = current_block;\n\n\t \n\tret = count;\n\t*err = 0;\n\treturn ret;\nfailed_out:\n\tfor (i = 0; i <index; i++)\n\t\text2_free_blocks(inode, new_blocks[i], 1);\n\tif (index)\n\t\tmark_inode_dirty(inode);\n\treturn ret;\n}\n\n \n\nstatic int ext2_alloc_branch(struct inode *inode,\n\t\t\tint indirect_blks, int *blks, ext2_fsblk_t goal,\n\t\t\tint *offsets, Indirect *branch)\n{\n\tint blocksize = inode->i_sb->s_blocksize;\n\tint i, n = 0;\n\tint err = 0;\n\tstruct buffer_head *bh;\n\tint num;\n\text2_fsblk_t new_blocks[4];\n\text2_fsblk_t current_block;\n\n\tnum = ext2_alloc_blocks(inode, goal, indirect_blks,\n\t\t\t\t*blks, new_blocks, &err);\n\tif (err)\n\t\treturn err;\n\n\tbranch[0].key = cpu_to_le32(new_blocks[0]);\n\t \n\tfor (n = 1; n <= indirect_blks;  n++) {\n\t\t \n\t\tbh = sb_getblk(inode->i_sb, new_blocks[n-1]);\n\t\tif (unlikely(!bh)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto failed;\n\t\t}\n\t\tbranch[n].bh = bh;\n\t\tlock_buffer(bh);\n\t\tmemset(bh->b_data, 0, blocksize);\n\t\tbranch[n].p = (__le32 *) bh->b_data + offsets[n];\n\t\tbranch[n].key = cpu_to_le32(new_blocks[n]);\n\t\t*branch[n].p = branch[n].key;\n\t\tif ( n == indirect_blks) {\n\t\t\tcurrent_block = new_blocks[n];\n\t\t\t \n\t\t\tfor (i=1; i < num; i++)\n\t\t\t\t*(branch[n].p + i) = cpu_to_le32(++current_block);\n\t\t}\n\t\tset_buffer_uptodate(bh);\n\t\tunlock_buffer(bh);\n\t\tmark_buffer_dirty_inode(bh, inode);\n\t\t \n\t\tif (S_ISDIR(inode->i_mode) && IS_DIRSYNC(inode))\n\t\t\tsync_dirty_buffer(bh);\n\t}\n\t*blks = num;\n\treturn err;\n\nfailed:\n\tfor (i = 1; i < n; i++)\n\t\tbforget(branch[i].bh);\n\tfor (i = 0; i < indirect_blks; i++)\n\t\text2_free_blocks(inode, new_blocks[i], 1);\n\text2_free_blocks(inode, new_blocks[i], num);\n\treturn err;\n}\n\n \nstatic void ext2_splice_branch(struct inode *inode,\n\t\t\tlong block, Indirect *where, int num, int blks)\n{\n\tint i;\n\tstruct ext2_block_alloc_info *block_i;\n\text2_fsblk_t current_block;\n\n\tblock_i = EXT2_I(inode)->i_block_alloc_info;\n\n\t \n\t \n\n\t*where->p = where->key;\n\n\t \n\tif (num == 0 && blks > 1) {\n\t\tcurrent_block = le32_to_cpu(where->key) + 1;\n\t\tfor (i = 1; i < blks; i++)\n\t\t\t*(where->p + i ) = cpu_to_le32(current_block++);\n\t}\n\n\t \n\tif (block_i) {\n\t\tblock_i->last_alloc_logical_block = block + blks - 1;\n\t\tblock_i->last_alloc_physical_block =\n\t\t\t\tle32_to_cpu(where[num].key) + blks - 1;\n\t}\n\n\t \n\n\t \n\tif (where->bh)\n\t\tmark_buffer_dirty_inode(where->bh, inode);\n\n\tinode_set_ctime_current(inode);\n\tmark_inode_dirty(inode);\n}\n\n \nstatic int ext2_get_blocks(struct inode *inode,\n\t\t\t   sector_t iblock, unsigned long maxblocks,\n\t\t\t   u32 *bno, bool *new, bool *boundary,\n\t\t\t   int create)\n{\n\tint err;\n\tint offsets[4];\n\tIndirect chain[4];\n\tIndirect *partial;\n\text2_fsblk_t goal;\n\tint indirect_blks;\n\tint blocks_to_boundary = 0;\n\tint depth;\n\tstruct ext2_inode_info *ei = EXT2_I(inode);\n\tint count = 0;\n\text2_fsblk_t first_block = 0;\n\n\tBUG_ON(maxblocks == 0);\n\n\tdepth = ext2_block_to_path(inode,iblock,offsets,&blocks_to_boundary);\n\n\tif (depth == 0)\n\t\treturn -EIO;\n\n\tpartial = ext2_get_branch(inode, depth, offsets, chain, &err);\n\t \n\tif (!partial) {\n\t\tfirst_block = le32_to_cpu(chain[depth - 1].key);\n\t\tcount++;\n\t\t \n\t\twhile (count < maxblocks && count <= blocks_to_boundary) {\n\t\t\text2_fsblk_t blk;\n\n\t\t\tif (!verify_chain(chain, chain + depth - 1)) {\n\t\t\t\t \n\t\t\t\terr = -EAGAIN;\n\t\t\t\tcount = 0;\n\t\t\t\tpartial = chain + depth - 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tblk = le32_to_cpu(*(chain[depth-1].p + count));\n\t\t\tif (blk == first_block + count)\n\t\t\t\tcount++;\n\t\t\telse\n\t\t\t\tbreak;\n\t\t}\n\t\tif (err != -EAGAIN)\n\t\t\tgoto got_it;\n\t}\n\n\t \n\tif (!create || err == -EIO)\n\t\tgoto cleanup;\n\n\tmutex_lock(&ei->truncate_mutex);\n\t \n\tif (err == -EAGAIN || !verify_chain(chain, partial)) {\n\t\twhile (partial > chain) {\n\t\t\tbrelse(partial->bh);\n\t\t\tpartial--;\n\t\t}\n\t\tpartial = ext2_get_branch(inode, depth, offsets, chain, &err);\n\t\tif (!partial) {\n\t\t\tcount++;\n\t\t\tmutex_unlock(&ei->truncate_mutex);\n\t\t\tgoto got_it;\n\t\t}\n\n\t\tif (err) {\n\t\t\tmutex_unlock(&ei->truncate_mutex);\n\t\t\tgoto cleanup;\n\t\t}\n\t}\n\n\t \n\tif (S_ISREG(inode->i_mode) && (!ei->i_block_alloc_info))\n\t\text2_init_block_alloc_info(inode);\n\n\tgoal = ext2_find_goal(inode, iblock, partial);\n\n\t \n\tindirect_blks = (chain + depth) - partial - 1;\n\t \n\tcount = ext2_blks_to_allocate(partial, indirect_blks,\n\t\t\t\t\tmaxblocks, blocks_to_boundary);\n\t \n\terr = ext2_alloc_branch(inode, indirect_blks, &count, goal,\n\t\t\t\toffsets + (partial - chain), partial);\n\n\tif (err) {\n\t\tmutex_unlock(&ei->truncate_mutex);\n\t\tgoto cleanup;\n\t}\n\n\tif (IS_DAX(inode)) {\n\t\t \n\t\tclean_bdev_aliases(inode->i_sb->s_bdev,\n\t\t\t\t   le32_to_cpu(chain[depth-1].key),\n\t\t\t\t   count);\n\t\t \n\t\terr = sb_issue_zeroout(inode->i_sb,\n\t\t\t\tle32_to_cpu(chain[depth-1].key), count,\n\t\t\t\tGFP_NOFS);\n\t\tif (err) {\n\t\t\tmutex_unlock(&ei->truncate_mutex);\n\t\t\tgoto cleanup;\n\t\t}\n\t}\n\t*new = true;\n\n\text2_splice_branch(inode, iblock, partial, indirect_blks, count);\n\tmutex_unlock(&ei->truncate_mutex);\ngot_it:\n\tif (count > blocks_to_boundary)\n\t\t*boundary = true;\n\terr = count;\n\t \n\tpartial = chain + depth - 1;\t \ncleanup:\n\twhile (partial > chain) {\n\t\tbrelse(partial->bh);\n\t\tpartial--;\n\t}\n\tif (err > 0)\n\t\t*bno = le32_to_cpu(chain[depth-1].key);\n\treturn err;\n}\n\nint ext2_get_block(struct inode *inode, sector_t iblock,\n\t\tstruct buffer_head *bh_result, int create)\n{\n\tunsigned max_blocks = bh_result->b_size >> inode->i_blkbits;\n\tbool new = false, boundary = false;\n\tu32 bno;\n\tint ret;\n\n\tret = ext2_get_blocks(inode, iblock, max_blocks, &bno, &new, &boundary,\n\t\t\tcreate);\n\tif (ret <= 0)\n\t\treturn ret;\n\n\tmap_bh(bh_result, inode->i_sb, bno);\n\tbh_result->b_size = (ret << inode->i_blkbits);\n\tif (new)\n\t\tset_buffer_new(bh_result);\n\tif (boundary)\n\t\tset_buffer_boundary(bh_result);\n\treturn 0;\n\n}\n\nstatic int ext2_iomap_begin(struct inode *inode, loff_t offset, loff_t length,\n\t\tunsigned flags, struct iomap *iomap, struct iomap *srcmap)\n{\n\tunsigned int blkbits = inode->i_blkbits;\n\tunsigned long first_block = offset >> blkbits;\n\tunsigned long max_blocks = (length + (1 << blkbits) - 1) >> blkbits;\n\tstruct ext2_sb_info *sbi = EXT2_SB(inode->i_sb);\n\tbool new = false, boundary = false;\n\tu32 bno;\n\tint ret;\n\tbool create = flags & IOMAP_WRITE;\n\n\t \n\tif ((flags & IOMAP_DIRECT) &&\n\t    (first_block << blkbits) < i_size_read(inode))\n\t\tcreate = 0;\n\n\t \n\tif ((flags & IOMAP_WRITE) && offset + length > i_size_read(inode))\n\t\tiomap->flags |= IOMAP_F_DIRTY;\n\n\tret = ext2_get_blocks(inode, first_block, max_blocks,\n\t\t\t&bno, &new, &boundary, create);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tiomap->flags = 0;\n\tiomap->offset = (u64)first_block << blkbits;\n\tif (flags & IOMAP_DAX)\n\t\tiomap->dax_dev = sbi->s_daxdev;\n\telse\n\t\tiomap->bdev = inode->i_sb->s_bdev;\n\n\tif (ret == 0) {\n\t\t \n\t\tif (!create && (flags & IOMAP_WRITE) && (flags & IOMAP_DIRECT))\n\t\t\treturn -ENOTBLK;\n\t\tiomap->type = IOMAP_HOLE;\n\t\tiomap->addr = IOMAP_NULL_ADDR;\n\t\tiomap->length = 1 << blkbits;\n\t} else {\n\t\tiomap->type = IOMAP_MAPPED;\n\t\tiomap->addr = (u64)bno << blkbits;\n\t\tif (flags & IOMAP_DAX)\n\t\t\tiomap->addr += sbi->s_dax_part_off;\n\t\tiomap->length = (u64)ret << blkbits;\n\t\tiomap->flags |= IOMAP_F_MERGED;\n\t}\n\n\tif (new)\n\t\tiomap->flags |= IOMAP_F_NEW;\n\treturn 0;\n}\n\nstatic int\next2_iomap_end(struct inode *inode, loff_t offset, loff_t length,\n\t\tssize_t written, unsigned flags, struct iomap *iomap)\n{\n\t \n\tif ((flags & IOMAP_DIRECT) && (flags & IOMAP_WRITE) && written == 0)\n\t\treturn -ENOTBLK;\n\n\tif (iomap->type == IOMAP_MAPPED &&\n\t    written < length &&\n\t    (flags & IOMAP_WRITE))\n\t\text2_write_failed(inode->i_mapping, offset + length);\n\treturn 0;\n}\n\nconst struct iomap_ops ext2_iomap_ops = {\n\t.iomap_begin\t\t= ext2_iomap_begin,\n\t.iomap_end\t\t= ext2_iomap_end,\n};\n\nint ext2_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,\n\t\tu64 start, u64 len)\n{\n\tint ret;\n\n\tinode_lock(inode);\n\tlen = min_t(u64, len, i_size_read(inode));\n\tret = iomap_fiemap(inode, fieinfo, start, len, &ext2_iomap_ops);\n\tinode_unlock(inode);\n\n\treturn ret;\n}\n\nstatic int ext2_read_folio(struct file *file, struct folio *folio)\n{\n\treturn mpage_read_folio(folio, ext2_get_block);\n}\n\nstatic void ext2_readahead(struct readahead_control *rac)\n{\n\tmpage_readahead(rac, ext2_get_block);\n}\n\nstatic int\next2_write_begin(struct file *file, struct address_space *mapping,\n\t\tloff_t pos, unsigned len, struct page **pagep, void **fsdata)\n{\n\tint ret;\n\n\tret = block_write_begin(mapping, pos, len, pagep, ext2_get_block);\n\tif (ret < 0)\n\t\text2_write_failed(mapping, pos + len);\n\treturn ret;\n}\n\nstatic int ext2_write_end(struct file *file, struct address_space *mapping,\n\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\tstruct page *page, void *fsdata)\n{\n\tint ret;\n\n\tret = generic_write_end(file, mapping, pos, len, copied, page, fsdata);\n\tif (ret < len)\n\t\text2_write_failed(mapping, pos + len);\n\treturn ret;\n}\n\nstatic sector_t ext2_bmap(struct address_space *mapping, sector_t block)\n{\n\treturn generic_block_bmap(mapping,block,ext2_get_block);\n}\n\nstatic int\next2_writepages(struct address_space *mapping, struct writeback_control *wbc)\n{\n\treturn mpage_writepages(mapping, wbc, ext2_get_block);\n}\n\nstatic int\next2_dax_writepages(struct address_space *mapping, struct writeback_control *wbc)\n{\n\tstruct ext2_sb_info *sbi = EXT2_SB(mapping->host->i_sb);\n\n\treturn dax_writeback_mapping_range(mapping, sbi->s_daxdev, wbc);\n}\n\nconst struct address_space_operations ext2_aops = {\n\t.dirty_folio\t\t= block_dirty_folio,\n\t.invalidate_folio\t= block_invalidate_folio,\n\t.read_folio\t\t= ext2_read_folio,\n\t.readahead\t\t= ext2_readahead,\n\t.write_begin\t\t= ext2_write_begin,\n\t.write_end\t\t= ext2_write_end,\n\t.bmap\t\t\t= ext2_bmap,\n\t.direct_IO\t\t= noop_direct_IO,\n\t.writepages\t\t= ext2_writepages,\n\t.migrate_folio\t\t= buffer_migrate_folio,\n\t.is_partially_uptodate\t= block_is_partially_uptodate,\n\t.error_remove_page\t= generic_error_remove_page,\n};\n\nstatic const struct address_space_operations ext2_dax_aops = {\n\t.writepages\t\t= ext2_dax_writepages,\n\t.direct_IO\t\t= noop_direct_IO,\n\t.dirty_folio\t\t= noop_dirty_folio,\n};\n\n \nstatic inline int all_zeroes(__le32 *p, __le32 *q)\n{\n\twhile (p < q)\n\t\tif (*p++)\n\t\t\treturn 0;\n\treturn 1;\n}\n\n \n\nstatic Indirect *ext2_find_shared(struct inode *inode,\n\t\t\t\tint depth,\n\t\t\t\tint offsets[4],\n\t\t\t\tIndirect chain[4],\n\t\t\t\t__le32 *top)\n{\n\tIndirect *partial, *p;\n\tint k, err;\n\n\t*top = 0;\n\tfor (k = depth; k > 1 && !offsets[k-1]; k--)\n\t\t;\n\tpartial = ext2_get_branch(inode, k, offsets, chain, &err);\n\tif (!partial)\n\t\tpartial = chain + k-1;\n\t \n\twrite_lock(&EXT2_I(inode)->i_meta_lock);\n\tif (!partial->key && *partial->p) {\n\t\twrite_unlock(&EXT2_I(inode)->i_meta_lock);\n\t\tgoto no_top;\n\t}\n\tfor (p=partial; p>chain && all_zeroes((__le32*)p->bh->b_data,p->p); p--)\n\t\t;\n\t \n\tif (p == chain + k - 1 && p > chain) {\n\t\tp->p--;\n\t} else {\n\t\t*top = *p->p;\n\t\t*p->p = 0;\n\t}\n\twrite_unlock(&EXT2_I(inode)->i_meta_lock);\n\n\twhile(partial > p)\n\t{\n\t\tbrelse(partial->bh);\n\t\tpartial--;\n\t}\nno_top:\n\treturn partial;\n}\n\n \nstatic inline void ext2_free_data(struct inode *inode, __le32 *p, __le32 *q)\n{\n\text2_fsblk_t block_to_free = 0, count = 0;\n\text2_fsblk_t nr;\n\n\tfor ( ; p < q ; p++) {\n\t\tnr = le32_to_cpu(*p);\n\t\tif (nr) {\n\t\t\t*p = 0;\n\t\t\t \n\t\t\tif (count == 0)\n\t\t\t\tgoto free_this;\n\t\t\telse if (block_to_free == nr - count)\n\t\t\t\tcount++;\n\t\t\telse {\n\t\t\t\text2_free_blocks (inode, block_to_free, count);\n\t\t\t\tmark_inode_dirty(inode);\n\t\t\tfree_this:\n\t\t\t\tblock_to_free = nr;\n\t\t\t\tcount = 1;\n\t\t\t}\n\t\t}\n\t}\n\tif (count > 0) {\n\t\text2_free_blocks (inode, block_to_free, count);\n\t\tmark_inode_dirty(inode);\n\t}\n}\n\n \nstatic void ext2_free_branches(struct inode *inode, __le32 *p, __le32 *q, int depth)\n{\n\tstruct buffer_head * bh;\n\text2_fsblk_t nr;\n\n\tif (depth--) {\n\t\tint addr_per_block = EXT2_ADDR_PER_BLOCK(inode->i_sb);\n\t\tfor ( ; p < q ; p++) {\n\t\t\tnr = le32_to_cpu(*p);\n\t\t\tif (!nr)\n\t\t\t\tcontinue;\n\t\t\t*p = 0;\n\t\t\tbh = sb_bread(inode->i_sb, nr);\n\t\t\t  \n\t\t\tif (!bh) {\n\t\t\t\text2_error(inode->i_sb, \"ext2_free_branches\",\n\t\t\t\t\t\"Read failure, inode=%ld, block=%ld\",\n\t\t\t\t\tinode->i_ino, nr);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\text2_free_branches(inode,\n\t\t\t\t\t   (__le32*)bh->b_data,\n\t\t\t\t\t   (__le32*)bh->b_data + addr_per_block,\n\t\t\t\t\t   depth);\n\t\t\tbforget(bh);\n\t\t\text2_free_blocks(inode, nr, 1);\n\t\t\tmark_inode_dirty(inode);\n\t\t}\n\t} else\n\t\text2_free_data(inode, p, q);\n}\n\n \nstatic void __ext2_truncate_blocks(struct inode *inode, loff_t offset)\n{\n\t__le32 *i_data = EXT2_I(inode)->i_data;\n\tstruct ext2_inode_info *ei = EXT2_I(inode);\n\tint addr_per_block = EXT2_ADDR_PER_BLOCK(inode->i_sb);\n\tint offsets[4];\n\tIndirect chain[4];\n\tIndirect *partial;\n\t__le32 nr = 0;\n\tint n;\n\tlong iblock;\n\tunsigned blocksize;\n\tblocksize = inode->i_sb->s_blocksize;\n\tiblock = (offset + blocksize-1) >> EXT2_BLOCK_SIZE_BITS(inode->i_sb);\n\n#ifdef CONFIG_FS_DAX\n\tWARN_ON(!rwsem_is_locked(&inode->i_mapping->invalidate_lock));\n#endif\n\n\tn = ext2_block_to_path(inode, iblock, offsets, NULL);\n\tif (n == 0)\n\t\treturn;\n\n\t \n\tmutex_lock(&ei->truncate_mutex);\n\n\tif (n == 1) {\n\t\text2_free_data(inode, i_data+offsets[0],\n\t\t\t\t\ti_data + EXT2_NDIR_BLOCKS);\n\t\tgoto do_indirects;\n\t}\n\n\tpartial = ext2_find_shared(inode, n, offsets, chain, &nr);\n\t \n\tif (nr) {\n\t\tif (partial == chain)\n\t\t\tmark_inode_dirty(inode);\n\t\telse\n\t\t\tmark_buffer_dirty_inode(partial->bh, inode);\n\t\text2_free_branches(inode, &nr, &nr+1, (chain+n-1) - partial);\n\t}\n\t \n\twhile (partial > chain) {\n\t\text2_free_branches(inode,\n\t\t\t\t   partial->p + 1,\n\t\t\t\t   (__le32*)partial->bh->b_data+addr_per_block,\n\t\t\t\t   (chain+n-1) - partial);\n\t\tmark_buffer_dirty_inode(partial->bh, inode);\n\t\tbrelse (partial->bh);\n\t\tpartial--;\n\t}\ndo_indirects:\n\t \n\tswitch (offsets[0]) {\n\t\tdefault:\n\t\t\tnr = i_data[EXT2_IND_BLOCK];\n\t\t\tif (nr) {\n\t\t\t\ti_data[EXT2_IND_BLOCK] = 0;\n\t\t\t\tmark_inode_dirty(inode);\n\t\t\t\text2_free_branches(inode, &nr, &nr+1, 1);\n\t\t\t}\n\t\t\tfallthrough;\n\t\tcase EXT2_IND_BLOCK:\n\t\t\tnr = i_data[EXT2_DIND_BLOCK];\n\t\t\tif (nr) {\n\t\t\t\ti_data[EXT2_DIND_BLOCK] = 0;\n\t\t\t\tmark_inode_dirty(inode);\n\t\t\t\text2_free_branches(inode, &nr, &nr+1, 2);\n\t\t\t}\n\t\t\tfallthrough;\n\t\tcase EXT2_DIND_BLOCK:\n\t\t\tnr = i_data[EXT2_TIND_BLOCK];\n\t\t\tif (nr) {\n\t\t\t\ti_data[EXT2_TIND_BLOCK] = 0;\n\t\t\t\tmark_inode_dirty(inode);\n\t\t\t\text2_free_branches(inode, &nr, &nr+1, 3);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase EXT2_TIND_BLOCK:\n\t\t\t;\n\t}\n\n\text2_discard_reservation(inode);\n\n\tmutex_unlock(&ei->truncate_mutex);\n}\n\nstatic void ext2_truncate_blocks(struct inode *inode, loff_t offset)\n{\n\tif (!(S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t    S_ISLNK(inode->i_mode)))\n\t\treturn;\n\tif (ext2_inode_is_fast_symlink(inode))\n\t\treturn;\n\n\tfilemap_invalidate_lock(inode->i_mapping);\n\t__ext2_truncate_blocks(inode, offset);\n\tfilemap_invalidate_unlock(inode->i_mapping);\n}\n\nstatic int ext2_setsize(struct inode *inode, loff_t newsize)\n{\n\tint error;\n\n\tif (!(S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t    S_ISLNK(inode->i_mode)))\n\t\treturn -EINVAL;\n\tif (ext2_inode_is_fast_symlink(inode))\n\t\treturn -EINVAL;\n\tif (IS_APPEND(inode) || IS_IMMUTABLE(inode))\n\t\treturn -EPERM;\n\n\tinode_dio_wait(inode);\n\n\tif (IS_DAX(inode))\n\t\terror = dax_truncate_page(inode, newsize, NULL,\n\t\t\t\t\t  &ext2_iomap_ops);\n\telse\n\t\terror = block_truncate_page(inode->i_mapping,\n\t\t\t\tnewsize, ext2_get_block);\n\tif (error)\n\t\treturn error;\n\n\tfilemap_invalidate_lock(inode->i_mapping);\n\ttruncate_setsize(inode, newsize);\n\t__ext2_truncate_blocks(inode, newsize);\n\tfilemap_invalidate_unlock(inode->i_mapping);\n\n\tinode->i_mtime = inode_set_ctime_current(inode);\n\tif (inode_needs_sync(inode)) {\n\t\tsync_mapping_buffers(inode->i_mapping);\n\t\tsync_inode_metadata(inode, 1);\n\t} else {\n\t\tmark_inode_dirty(inode);\n\t}\n\n\treturn 0;\n}\n\nstatic struct ext2_inode *ext2_get_inode(struct super_block *sb, ino_t ino,\n\t\t\t\t\tstruct buffer_head **p)\n{\n\tstruct buffer_head * bh;\n\tunsigned long block_group;\n\tunsigned long block;\n\tunsigned long offset;\n\tstruct ext2_group_desc * gdp;\n\n\t*p = NULL;\n\tif ((ino != EXT2_ROOT_INO && ino < EXT2_FIRST_INO(sb)) ||\n\t    ino > le32_to_cpu(EXT2_SB(sb)->s_es->s_inodes_count))\n\t\tgoto Einval;\n\n\tblock_group = (ino - 1) / EXT2_INODES_PER_GROUP(sb);\n\tgdp = ext2_get_group_desc(sb, block_group, NULL);\n\tif (!gdp)\n\t\tgoto Egdp;\n\t \n\toffset = ((ino - 1) % EXT2_INODES_PER_GROUP(sb)) * EXT2_INODE_SIZE(sb);\n\tblock = le32_to_cpu(gdp->bg_inode_table) +\n\t\t(offset >> EXT2_BLOCK_SIZE_BITS(sb));\n\tif (!(bh = sb_bread(sb, block)))\n\t\tgoto Eio;\n\n\t*p = bh;\n\toffset &= (EXT2_BLOCK_SIZE(sb) - 1);\n\treturn (struct ext2_inode *) (bh->b_data + offset);\n\nEinval:\n\text2_error(sb, \"ext2_get_inode\", \"bad inode number: %lu\",\n\t\t   (unsigned long) ino);\n\treturn ERR_PTR(-EINVAL);\nEio:\n\text2_error(sb, \"ext2_get_inode\",\n\t\t   \"unable to read inode block - inode=%lu, block=%lu\",\n\t\t   (unsigned long) ino, block);\nEgdp:\n\treturn ERR_PTR(-EIO);\n}\n\nvoid ext2_set_inode_flags(struct inode *inode)\n{\n\tunsigned int flags = EXT2_I(inode)->i_flags;\n\n\tinode->i_flags &= ~(S_SYNC | S_APPEND | S_IMMUTABLE | S_NOATIME |\n\t\t\t\tS_DIRSYNC | S_DAX);\n\tif (flags & EXT2_SYNC_FL)\n\t\tinode->i_flags |= S_SYNC;\n\tif (flags & EXT2_APPEND_FL)\n\t\tinode->i_flags |= S_APPEND;\n\tif (flags & EXT2_IMMUTABLE_FL)\n\t\tinode->i_flags |= S_IMMUTABLE;\n\tif (flags & EXT2_NOATIME_FL)\n\t\tinode->i_flags |= S_NOATIME;\n\tif (flags & EXT2_DIRSYNC_FL)\n\t\tinode->i_flags |= S_DIRSYNC;\n\tif (test_opt(inode->i_sb, DAX) && S_ISREG(inode->i_mode))\n\t\tinode->i_flags |= S_DAX;\n}\n\nvoid ext2_set_file_ops(struct inode *inode)\n{\n\tinode->i_op = &ext2_file_inode_operations;\n\tinode->i_fop = &ext2_file_operations;\n\tif (IS_DAX(inode))\n\t\tinode->i_mapping->a_ops = &ext2_dax_aops;\n\telse\n\t\tinode->i_mapping->a_ops = &ext2_aops;\n}\n\nstruct inode *ext2_iget (struct super_block *sb, unsigned long ino)\n{\n\tstruct ext2_inode_info *ei;\n\tstruct buffer_head * bh = NULL;\n\tstruct ext2_inode *raw_inode;\n\tstruct inode *inode;\n\tlong ret = -EIO;\n\tint n;\n\tuid_t i_uid;\n\tgid_t i_gid;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\tif (!(inode->i_state & I_NEW))\n\t\treturn inode;\n\n\tei = EXT2_I(inode);\n\tei->i_block_alloc_info = NULL;\n\n\traw_inode = ext2_get_inode(inode->i_sb, ino, &bh);\n\tif (IS_ERR(raw_inode)) {\n\t\tret = PTR_ERR(raw_inode);\n \t\tgoto bad_inode;\n\t}\n\n\tinode->i_mode = le16_to_cpu(raw_inode->i_mode);\n\ti_uid = (uid_t)le16_to_cpu(raw_inode->i_uid_low);\n\ti_gid = (gid_t)le16_to_cpu(raw_inode->i_gid_low);\n\tif (!(test_opt (inode->i_sb, NO_UID32))) {\n\t\ti_uid |= le16_to_cpu(raw_inode->i_uid_high) << 16;\n\t\ti_gid |= le16_to_cpu(raw_inode->i_gid_high) << 16;\n\t}\n\ti_uid_write(inode, i_uid);\n\ti_gid_write(inode, i_gid);\n\tset_nlink(inode, le16_to_cpu(raw_inode->i_links_count));\n\tinode->i_size = le32_to_cpu(raw_inode->i_size);\n\tinode->i_atime.tv_sec = (signed)le32_to_cpu(raw_inode->i_atime);\n\tinode_set_ctime(inode, (signed)le32_to_cpu(raw_inode->i_ctime), 0);\n\tinode->i_mtime.tv_sec = (signed)le32_to_cpu(raw_inode->i_mtime);\n\tinode->i_atime.tv_nsec = inode->i_mtime.tv_nsec = 0;\n\tei->i_dtime = le32_to_cpu(raw_inode->i_dtime);\n\t \n\tif (inode->i_nlink == 0 && (inode->i_mode == 0 || ei->i_dtime)) {\n\t\t \n\t\tret = -ESTALE;\n\t\tgoto bad_inode;\n\t}\n\tinode->i_blocks = le32_to_cpu(raw_inode->i_blocks);\n\tei->i_flags = le32_to_cpu(raw_inode->i_flags);\n\text2_set_inode_flags(inode);\n\tei->i_faddr = le32_to_cpu(raw_inode->i_faddr);\n\tei->i_frag_no = raw_inode->i_frag;\n\tei->i_frag_size = raw_inode->i_fsize;\n\tei->i_file_acl = le32_to_cpu(raw_inode->i_file_acl);\n\tei->i_dir_acl = 0;\n\n\tif (ei->i_file_acl &&\n\t    !ext2_data_block_valid(EXT2_SB(sb), ei->i_file_acl, 1)) {\n\t\text2_error(sb, \"ext2_iget\", \"bad extended attribute block %u\",\n\t\t\t   ei->i_file_acl);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\n\tif (S_ISREG(inode->i_mode))\n\t\tinode->i_size |= ((__u64)le32_to_cpu(raw_inode->i_size_high)) << 32;\n\telse\n\t\tei->i_dir_acl = le32_to_cpu(raw_inode->i_dir_acl);\n\tif (i_size_read(inode) < 0) {\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\tei->i_dtime = 0;\n\tinode->i_generation = le32_to_cpu(raw_inode->i_generation);\n\tei->i_state = 0;\n\tei->i_block_group = (ino - 1) / EXT2_INODES_PER_GROUP(inode->i_sb);\n\tei->i_dir_start_lookup = 0;\n\n\t \n\tfor (n = 0; n < EXT2_N_BLOCKS; n++)\n\t\tei->i_data[n] = raw_inode->i_block[n];\n\n\tif (S_ISREG(inode->i_mode)) {\n\t\text2_set_file_ops(inode);\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &ext2_dir_inode_operations;\n\t\tinode->i_fop = &ext2_dir_operations;\n\t\tinode->i_mapping->a_ops = &ext2_aops;\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (ext2_inode_is_fast_symlink(inode)) {\n\t\t\tinode->i_link = (char *)ei->i_data;\n\t\t\tinode->i_op = &ext2_fast_symlink_inode_operations;\n\t\t\tnd_terminate_link(ei->i_data, inode->i_size,\n\t\t\t\tsizeof(ei->i_data) - 1);\n\t\t} else {\n\t\t\tinode->i_op = &ext2_symlink_inode_operations;\n\t\t\tinode_nohighmem(inode);\n\t\t\tinode->i_mapping->a_ops = &ext2_aops;\n\t\t}\n\t} else {\n\t\tinode->i_op = &ext2_special_inode_operations;\n\t\tif (raw_inode->i_block[0])\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   old_decode_dev(le32_to_cpu(raw_inode->i_block[0])));\n\t\telse \n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   new_decode_dev(le32_to_cpu(raw_inode->i_block[1])));\n\t}\n\tbrelse (bh);\n\tunlock_new_inode(inode);\n\treturn inode;\n\t\nbad_inode:\n\tbrelse(bh);\n\tiget_failed(inode);\n\treturn ERR_PTR(ret);\n}\n\nstatic int __ext2_write_inode(struct inode *inode, int do_sync)\n{\n\tstruct ext2_inode_info *ei = EXT2_I(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tino_t ino = inode->i_ino;\n\tuid_t uid = i_uid_read(inode);\n\tgid_t gid = i_gid_read(inode);\n\tstruct buffer_head * bh;\n\tstruct ext2_inode * raw_inode = ext2_get_inode(sb, ino, &bh);\n\tint n;\n\tint err = 0;\n\n\tif (IS_ERR(raw_inode))\n \t\treturn -EIO;\n\n\t \n\tif (ei->i_state & EXT2_STATE_NEW)\n\t\tmemset(raw_inode, 0, EXT2_SB(sb)->s_inode_size);\n\n\traw_inode->i_mode = cpu_to_le16(inode->i_mode);\n\tif (!(test_opt(sb, NO_UID32))) {\n\t\traw_inode->i_uid_low = cpu_to_le16(low_16_bits(uid));\n\t\traw_inode->i_gid_low = cpu_to_le16(low_16_bits(gid));\n \n\t\tif (!ei->i_dtime) {\n\t\t\traw_inode->i_uid_high = cpu_to_le16(high_16_bits(uid));\n\t\t\traw_inode->i_gid_high = cpu_to_le16(high_16_bits(gid));\n\t\t} else {\n\t\t\traw_inode->i_uid_high = 0;\n\t\t\traw_inode->i_gid_high = 0;\n\t\t}\n\t} else {\n\t\traw_inode->i_uid_low = cpu_to_le16(fs_high2lowuid(uid));\n\t\traw_inode->i_gid_low = cpu_to_le16(fs_high2lowgid(gid));\n\t\traw_inode->i_uid_high = 0;\n\t\traw_inode->i_gid_high = 0;\n\t}\n\traw_inode->i_links_count = cpu_to_le16(inode->i_nlink);\n\traw_inode->i_size = cpu_to_le32(inode->i_size);\n\traw_inode->i_atime = cpu_to_le32(inode->i_atime.tv_sec);\n\traw_inode->i_ctime = cpu_to_le32(inode_get_ctime(inode).tv_sec);\n\traw_inode->i_mtime = cpu_to_le32(inode->i_mtime.tv_sec);\n\n\traw_inode->i_blocks = cpu_to_le32(inode->i_blocks);\n\traw_inode->i_dtime = cpu_to_le32(ei->i_dtime);\n\traw_inode->i_flags = cpu_to_le32(ei->i_flags);\n\traw_inode->i_faddr = cpu_to_le32(ei->i_faddr);\n\traw_inode->i_frag = ei->i_frag_no;\n\traw_inode->i_fsize = ei->i_frag_size;\n\traw_inode->i_file_acl = cpu_to_le32(ei->i_file_acl);\n\tif (!S_ISREG(inode->i_mode))\n\t\traw_inode->i_dir_acl = cpu_to_le32(ei->i_dir_acl);\n\telse {\n\t\traw_inode->i_size_high = cpu_to_le32(inode->i_size >> 32);\n\t\tif (inode->i_size > 0x7fffffffULL) {\n\t\t\tif (!EXT2_HAS_RO_COMPAT_FEATURE(sb,\n\t\t\t\t\tEXT2_FEATURE_RO_COMPAT_LARGE_FILE) ||\n\t\t\t    EXT2_SB(sb)->s_es->s_rev_level ==\n\t\t\t\t\tcpu_to_le32(EXT2_GOOD_OLD_REV)) {\n\t\t\t        \n\t\t\t\tspin_lock(&EXT2_SB(sb)->s_lock);\n\t\t\t\text2_update_dynamic_rev(sb);\n\t\t\t\tEXT2_SET_RO_COMPAT_FEATURE(sb,\n\t\t\t\t\tEXT2_FEATURE_RO_COMPAT_LARGE_FILE);\n\t\t\t\tspin_unlock(&EXT2_SB(sb)->s_lock);\n\t\t\t\text2_sync_super(sb, EXT2_SB(sb)->s_es, 1);\n\t\t\t}\n\t\t}\n\t}\n\t\n\traw_inode->i_generation = cpu_to_le32(inode->i_generation);\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tif (old_valid_dev(inode->i_rdev)) {\n\t\t\traw_inode->i_block[0] =\n\t\t\t\tcpu_to_le32(old_encode_dev(inode->i_rdev));\n\t\t\traw_inode->i_block[1] = 0;\n\t\t} else {\n\t\t\traw_inode->i_block[0] = 0;\n\t\t\traw_inode->i_block[1] =\n\t\t\t\tcpu_to_le32(new_encode_dev(inode->i_rdev));\n\t\t\traw_inode->i_block[2] = 0;\n\t\t}\n\t} else for (n = 0; n < EXT2_N_BLOCKS; n++)\n\t\traw_inode->i_block[n] = ei->i_data[n];\n\tmark_buffer_dirty(bh);\n\tif (do_sync) {\n\t\tsync_dirty_buffer(bh);\n\t\tif (buffer_req(bh) && !buffer_uptodate(bh)) {\n\t\t\tprintk (\"IO error syncing ext2 inode [%s:%08lx]\\n\",\n\t\t\t\tsb->s_id, (unsigned long) ino);\n\t\t\terr = -EIO;\n\t\t}\n\t}\n\tei->i_state &= ~EXT2_STATE_NEW;\n\tbrelse (bh);\n\treturn err;\n}\n\nint ext2_write_inode(struct inode *inode, struct writeback_control *wbc)\n{\n\treturn __ext2_write_inode(inode, wbc->sync_mode == WB_SYNC_ALL);\n}\n\nint ext2_getattr(struct mnt_idmap *idmap, const struct path *path,\n\t\t struct kstat *stat, u32 request_mask, unsigned int query_flags)\n{\n\tstruct inode *inode = d_inode(path->dentry);\n\tstruct ext2_inode_info *ei = EXT2_I(inode);\n\tunsigned int flags;\n\n\tflags = ei->i_flags & EXT2_FL_USER_VISIBLE;\n\tif (flags & EXT2_APPEND_FL)\n\t\tstat->attributes |= STATX_ATTR_APPEND;\n\tif (flags & EXT2_COMPR_FL)\n\t\tstat->attributes |= STATX_ATTR_COMPRESSED;\n\tif (flags & EXT2_IMMUTABLE_FL)\n\t\tstat->attributes |= STATX_ATTR_IMMUTABLE;\n\tif (flags & EXT2_NODUMP_FL)\n\t\tstat->attributes |= STATX_ATTR_NODUMP;\n\tstat->attributes_mask |= (STATX_ATTR_APPEND |\n\t\t\tSTATX_ATTR_COMPRESSED |\n\t\t\tSTATX_ATTR_ENCRYPTED |\n\t\t\tSTATX_ATTR_IMMUTABLE |\n\t\t\tSTATX_ATTR_NODUMP);\n\n\tgeneric_fillattr(&nop_mnt_idmap, request_mask, inode, stat);\n\treturn 0;\n}\n\nint ext2_setattr(struct mnt_idmap *idmap, struct dentry *dentry,\n\t\t struct iattr *iattr)\n{\n\tstruct inode *inode = d_inode(dentry);\n\tint error;\n\n\terror = setattr_prepare(&nop_mnt_idmap, dentry, iattr);\n\tif (error)\n\t\treturn error;\n\n\tif (is_quota_modification(&nop_mnt_idmap, inode, iattr)) {\n\t\terror = dquot_initialize(inode);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\tif (i_uid_needs_update(&nop_mnt_idmap, iattr, inode) ||\n\t    i_gid_needs_update(&nop_mnt_idmap, iattr, inode)) {\n\t\terror = dquot_transfer(&nop_mnt_idmap, inode, iattr);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\tif (iattr->ia_valid & ATTR_SIZE && iattr->ia_size != inode->i_size) {\n\t\terror = ext2_setsize(inode, iattr->ia_size);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\tsetattr_copy(&nop_mnt_idmap, inode, iattr);\n\tif (iattr->ia_valid & ATTR_MODE)\n\t\terror = posix_acl_chmod(&nop_mnt_idmap, dentry, inode->i_mode);\n\tmark_inode_dirty(inode);\n\n\treturn error;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}